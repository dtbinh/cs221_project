Journal of Artificial Intelligence Research 34 (2009) 521–567

Submitted 09/08; published 04/09

An Anytime Algorithm for Optimal Coalition Structure Generation
Talal Rahwan
Sarvapali D. Ramchurn
Nicholas R. Jennings

TR @ ECS . SOTON . AC . UK
SDR @ ECS . SOTON . AC . UK
NRJ @ ECS . SOTON . AC . UK

School of Electronics and Computer Science,
University of Southampton, Southampton, SO17 1BJ, U.K.

Andrea Giovannucci

AGIOVANNUCCI @ IUA . UPF. EDU

SPECS Laboratory, Pompeu Fabra University, Barcelona, Spain.

Abstract
Coalition formation is a fundamental type of interaction that involves the creation of coherent
groupings of distinct, autonomous, agents in order to efficiently achieve their individual or collective goals. Forming effective coalitions is a major research challenge in the field of multi-agent
systems. Central to this endeavour is the problem of determining which of the many possible
coalitions to form in order to achieve some goal. This usually requires calculating a value for every possible coalition, known as the coalition value, which indicates how beneficial that coalition
would be if it was formed. Once these values are calculated, the agents usually need to find a
combination of coalitions, in which every agent belongs to exactly one coalition, and by which the
overall outcome of the system is maximized. However, this coalition structure generation problem
is extremely challenging due to the number of possible solutions that need to be examined, which
grows exponentially with the number of agents involved. To date, therefore, many algorithms have
been proposed to solve this problem using different techniques — ranging from dynamic programming, to integer programming, to stochastic search — all of which suffer from major limitations
relating to execution time, solution quality, and memory requirements.
With this in mind, we develop an anytime algorithm to solve the coalition structure generation problem. Specifically, the algorithm uses a novel representation of the search space, which
partitions the space of possible solutions into sub-spaces such that it is possible to compute upper
and lower bounds on the values of the best coalition structures in them. These bounds are then
used to identify the sub-spaces that have no potential of containing the optimal solution so that they
can be pruned. The algorithm, then, searches through the remaining sub-spaces very efficiently
using a branch-and-bound technique to avoid examining all the solutions within the searched subspace(s). In this setting, we prove that our algorithm enumerates all coalition structures efficiently
by avoiding redundant and invalid solutions automatically. Moreover, in order to effectively test
our algorithm we develop a new type of input distribution which allows us to generate more reliable benchmarks compared to the input distributions previously used in the field. Given this new
distribution, we show that for 27 agents our algorithm is able to find solutions that are optimal in
0.175% of the time required by the fastest available algorithm in the literature. The algorithm is
anytime, and if interrupted before it would have normally terminated, it can still provide a solution
that is guaranteed to be within a bound from the optimal one. Moreover, the guarantees we provide
on the quality of the solution are significantly better than those provided by the previous state of
the art algorithms designed for this purpose. For example, for the worst case distribution given 25
agents, our algorithm is able to find a 90% efficient solution in around 10% of time it takes to find
the optimal solution.
c
2009
AI Access Foundation. All rights reserved.

R AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGS

1. Introduction
Multi-agent systems are considered an important and rapidly expanding area of research in artificial
intelligence. This is due to its natural fit to many real-world scenarios, and its wide variety of applications (Jennings, 2001). Now, typically, the agents in a multi-agent system need to be organized
such that the roles, relationships, and authority structures that govern their behaviour are clearly
defined (Horling & Lesser, 2005). Different organizational paradigms include hierarchies, teams,
federations, and many others, each with its own strengths and weaknesses, making it more suitable for some problems, and less suitable for others. Among the organizational paradigms that are
becoming increasingly important is that of coalitions. Coalitions can be distinguished from other
organizations by being goal-directed and short-lived; i.e. the coalitions are formed with a purpose
in mind, and are dissolved when that purpose no longer exists, or when they cease to suit their
designed purpose, or when the profitability is lost as agents depart (Horling & Lesser, 2005). Another defining feature is that within each coalition, the agents coordinate their activities in order to
achieve the coalition’s goal(s), but no coordination takes place among agents belonging to different
coalitions (except if the coalitions’ goals interact). Moreover, the organizational structure within
each coalition is usually flat (although there could be a coalition leader acting as a representative for
the group as a whole).
The area of coalition formation has received considerable attention in recent research, and has
proved to be useful in a number of real-world scenarios and multi-agent systems. For example, in
e-commerce, buyers can form coalitions to purchase a product in bulk and take advantage of price
discounts (Tsvetovat, Sycara, Chen, & Ying, 2000). In e-business, groups of agents can be formed
in order to satisfy particular market niches (Norman, Preece, Chalmers, Jennings, Luck, Dang,
Nguyen, V. Deora, Gray, & Fiddian, 2004). In distributed sensor networks, coalitions of sensors can
work together to track targets of interest (Dang, Dash, Rogers, & Jennings, 2006). In distributed
vehicle routing, coalitions of delivery companies can be formed to reduce the transportation costs by
sharing deliveries (Sandholm & Lesser, 1997). Coalition formation can also be used for information
gathering, where several information servers form coalitions to answer queries (Klusch & Shehory,
1996).
Generally speaking, the coalition formation process can be viewed as being composed of the
three main activities that are outlined below (Sandholm, Larson, Andersson, Shehory, & Tohme,
1999):
1. Coalition Value Calculation: In this context, a number of coalition formation algorithms
have been developed to determine which of the potential coalitions should actually be formed.
To do so, they typically calculate a value for each coalition, known as the coalition value,
which provides an indication of the expected outcome that could be derived if that coalition
was formed. Then, having computed all the coalition values, the decision about the optimal
coalition(s) to form can be taken. The way this value is calculated depends on the problem
under investigation.
In an electronic marketplace, for example, the value of a coalition of buyers can be calculated
as the difference between the sum of the reservation costs of the coalition members and the
minimum cost needed to satisfy the requests of all the members (Li & Sycara, 2002). In
information gathering, the coalition value can be designed to represent a measure of how
closely the information agents’ domains are related (Klusch & Shehory, 1996). In cases where
the agents’ rationality is bounded due to computational complexity, the value of a coalition
522

A N A NYTIME A LGORITHM FOR O PTIMAL C OALITION S TRUCTURE G ENERATION

may represent the best outcome it can achieve given limited computational resources for
solving the problem (Sandholm & Lesser, 1997).
2. Coalition Structure Generation: Having computed the coalition values, the coalition structure generation (CSG) problem involves partitioning the set of agents into exhaustive and
disjoint coalitions so as to maximize social welfare. Such a partition is called a coalition
structure. For example, given a set of agents A = {a1 , a2 , a3 }, there exist five possible coalition structures: {{a1 } , {a2 } , {a3 }}, {{a1 } , {a2 , a3 }}, {{a2 } , {a1 , a3 }}, {{a3 } , {a1 , a2 }},
{{a1 , a2 , a3 }}.
It is usually assumed that every coalition performs equally well, given any coalition structure
containing it (i.e. the value of a coalition does not depend on the actions of non-members).
Such settings are known as characteristic function games (CFGs), where the value of a coalition is given by a characteristic function. Many, but clearly not all, real-world multi-agent
problems happen to be CFGs (Sandholm et al., 1999).
Note that an optimal solution to the CSG problem is one that maximizes the social welfare.
Now, unlike a cooperative environment where the agents are mainly concerned with maximizing the social welfare, the agents in a selfish environment are only concerned with maximizing
their own utility. This, however, does not mean that a CSG algorithm cannot be applied in
selfish multi-agent systems. This is because the designer of such systems is usually concerned with raising the overall efficiency of the system and, in many cases, this corresponds
to maximizing the social welfare. To this end, the designer needs to design an enforcement
mechanism that motivates the agents to join the optimal coalition structure and, in order to do
so, he first needs to know what that structure is. Moreover, knowing the value of the optimal
coalition structure, or knowing a value that is within a bound from that optimal, allows the
designer to evaluate the relative effectiveness of the coalition structure currently formed in
the system.
3. Pay-off Distribution: Having determined which coalitions should be formed, it is important
to determine the rewards that each agent should get in order for the coalitions to be stable.
Here, stability refers to the state where the agents have no incentive to deviate from the coalitions to which they belong (or little incentive in weaker types of stability). This is desirable
because it ensures that the agents will devote their resources to their chosen coalition rather
than negotiating with, and moving to, other coalitions. This ensures that the coalitions can
last long enough to actually achieve their goals. The analysis of such incentives has long
been studied within the realm of cooperative game theory. In this context, many solutions
have been proposed based on different stability concepts. These include the Core, the Shapley value, and the Kernel (more details can be found in the paper by Osborne & Rubinstein,
1994). Moreover, schemes have been developed to transfer non-stable pay-off distributions
to stable ones while keeping the coalition structure unchanged (Kahan & Rapoport, 1984,
provide a comprehensive review on stability concepts and transfer schemes in game theory).
Note, however, that the agents in a cooperative environment have no incentive to dissolve a
coalition that improves the performance of the system as a whole. Therefore, pay-off distribution is less important, and the main concern is generating a coalition structure so as to
maximize the social welfare.
523

R AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGS

One of the most challenging of all of these activities is that of coalition structure generation, and this
n
is due to the number of possible solutions which grows exponentially (in O(nn ) and ω(n 2 ) with
the number of agents involved (n)). More specifically, it has been proved that finding an optimal
coalition structure is NP-complete (Sandholm et al., 1999). To combat this complexity, a number
of algorithms have been developed in the past few years, using different search techniques (e.g.
dynamic programming, integer programming, and stochastic search). These algorithms, however,
suffer from major limitations that make them either inefficient or inapplicable, particularly given
larger numbers of agents (see Section 2 for more details).
This motivates our aim to develop an efficient algorithm for searching the space of possible
coalition structures. In more detail, given a CFG setting, we wish to develop an algorithm that
satisfies the following properties:
1. Optimality: When run to completion, the algorithm must always be able return a solution that
maximizes the social welfare.
2. Ability to prune: the algorithm must be able to identify the sub-spaces that have no potential
of containing an optimal solution so that they can be pruned from the search space. This
property is critical given the exponential nature of the problem (e.g. given 20 agents, the
number of possible coalition structures is 51,724,158,235,372).
3. Discrimination: the algorithm must be able to verify, during the search, that it has found an
optimal solution, instead of proceeding with the search in the hope that a better solution can
be found.
4. Anytime: the algorithm should be able to quickly return an initial solution, and then improve
on the quality of this solution as it searches more of the space, until it finds an optimal one.
This is particularly important since the agents might not always have sufficient time to run the
algorithm to completion, especially given the exponential size of the search space. Moreover,
being anytime makes the algorithm more robust against failure; if the execution is stopped
before the algorithm would have normally terminated, then it would still provide the agents
with a solution that is better than the initial solution, or any other intermediate one.
5. Worst Case Guarantees: the algorithm should be able to provide worst-case guarantees on the
quality of its solution. Otherwise, the generated solution could always be arbitrarily worse
than the optimal one. Such guarantees are important when trading off between the solution
quality and the search time. For example, if the quality of the current solution is known to
be no worse than, say, 95% of the optimal one, and if there is still a significant portion of the
space left to be searched, then the agents might decide that it is not worthwhile to carry on
with the search. Obviously, the better the guarantees, the more likely it is that the agents will
decide to stop searching for a better solution.
Against the research aims outlined above, this paper makes the following contributions to the state
of the art in coalition structure generation:
1. We provide a new representation of the space of possible coalition structures. This representation partitions the space into much smaller, disjoint sub-spaces that can be explored
524

A N A NYTIME A LGORITHM FOR O PTIMAL C OALITION S TRUCTURE G ENERATION

independently to find an optimal solution. As opposed to the other widely-used representation (Sandholm et al., 1999; Dang & Jennings, 2004), by which the coalition structures are
categorized based on the number of coalitions they contain, our representation categorizes the
coalition structures into sub-spaces based on the sizes of the coalitions they contain. A key
advantage of this representation is that, immediately after scanning the input to the algorithm
(i.e. the coalition values), we can compute the average value of the coalition structures within
each sub-space. Moreover, by scanning the input, we can also compute an upper and a lower
bound on the value of the best coalition structure that could be found in each of these subspaces. Then, by comparing these bounds, it is possible to identify the sub-spaces that have
no potential of containing an optimal solution so that they can be pruned. A second major
advantage of this representation is that it allows the agents to analyse the trade-off between
the size of (i.e. the number of coalition structures within) a sub-space and the improvement
it may bring to the current solution by virtue of its bounds. Hence, rather than constraining
the solution to fixed sizes, as Shehory and Kraus (1998) do, agents using our representation
can make a more informed decision about the sizes of coalitions to choose (since each of the
sub-spaces are defined by the sizes of coalitions within the coalition structures).
2. We develop a novel, anytime, integer-partition based algorithm (called IP) for coalitions structure generation which uses the representation discussed above, and provides very high guarantees on the quality of its solutions very quickly. Moreover, IP is guaranteed to return an
optimal solution when run to completion.
3. We prove that our algorithm is able to enumerate coalition structures efficiently by avoiding
redundant and invalid solutions. Our enumeration technique also allows us to apply branchand-bound to reduce the amount of search needed.
4. While many CSG algorithms in the literature have been evaluated using the input distributions
that were defined by Larson and Sandholm (2000), we prove that these distributions are biased
as far as the CSG problem is concerned. Moreover, we propose a new distribution and prove
that it tackles this problem, making it much more suitable for evaluating CSG algorithms in
general.
5. When evaluating the time required to return an optimal solution, we compare IP with the
fastest algorithm guaranteed to return an optimal solution (i.e. the Improved Dynamic Programming (IDP) algorithm by Rahwan & Jennings, 2008b). This comparison shows that IP
is significantly faster. In more detail, IP is empirically shown to find an optimal solution in
0.175% of the time taken by IDP given 27 agents.
6. We benchmark IP against previous anytime algorithms (Sandholm et al., 1999; Dang & Jennings, 2004), and show that it provides significantly better guarantees on the quality of the
solutions it generates over time. In more detail, we empirically show that, for various numbers of agents, the quality of its initial solution (i.e. the solution found after scanning the
input) is usually guaranteed to be at least 40% of the optimal, as opposed to n2 (which means
for example, 10% for 20 agents and 8% for 25 agents) for both Sandholm et al.’s algorithm
and Dang and Jennings’s algorithm. For the standard distributions with which we evaluate
our algorithm, we also find that it usually terminates by searching only minute portions of the
525

R AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGS

search space and generates near-optimal solutions (i.e. > 90% of the optimal) by searching
even smaller portions of the search space (i.e. on average around 0.0000002% of the search
space). This is a tremendous improvement over the aforementioned algorithms which could
guarantee solutions higher than 50% of the optimal only after searching the whole space.
Note that this is a significantly revised and extended version of previous papers (Rahwan, Ramchurn, Dang, & Jennings, 2007a; Rahwan, Ramchurn, Giovannucci, Dang, & Jennings, 2007b).
Specifically, we provide in this paper a more comprehensive review of the available algorithms in
the CSG literature. We also provide a detailed analysis of our IP algorithm, describe the pseudo code
of all the functions used in IP, and prove the correctness of the function that searches the different
sub-spaces. A mathematical proof is also provided regarding the way the size of a sub-space is computed. Moreover, we question the validity of the standard value distributions that are used in the
literature, and propose a new value distribution (called NDCS) that is more suitable for evaluating
CSG algorithms. Finally, we benchmark our algorithm against the improved dynamic programming
algorithm (IDP) by Rahwan and Jennings (2008b) (instead of the standard DP algorithm).
The remainder of the paper is organized as follows. In Section 2, we describe the algorithms
that are currently available for solving the coalition structure generation problem, and discuss their
relative advantages and limitations. In Section 3, we present our novel representation of the search
space and, in Section 4, we present our integer-partition based algorithm (IP), showing how it identifies the sub-spaces that can be pruned, and how it searches through the remaining ones without
going through invalid or redundant coalition structures, using a branch-and-bound technique. Section 5 provides an empirical evaluation of the algorithm, and benchmarks it against the current state
of the art in the CSG literature. Section 6 concludes the paper and outlines future work. We also
provide, in the appendices, a summary of the main notations employed, as well as detailed proofs
of the theorems provided in the paper.

2. Related Work
Previous algorithms that have been designed for the coalition structure generation problem can be
classified into two main categories:
• Exact algorithms1 – using heuristics, integer programming, or dynamic programming.
• Non-exact algorithms – using genetic algorithms, or limiting the search space in some way.
Next, we discuss both the advantages and the limitations of the algorithms that fall within each
of these classes. Throughout the paper, we denote by n the number of agents, and by A =
{a1 , a2 , · · · , an } the set of agents. Moreover, we define an order over the agents in A as follows:
∀ai , aj ∈ A, ai < aj iff i < j, and ai = aj iff i = j. In other words, we have: a1 < a2 < · · · < an .
Finally, we denote by v(C) the value of coalition C, and V (CS) the value of coalition structure CS.
2.1 Exact Algorithms for Coalition Structure Generation
There are very few exact algorithms for coalition structure generation. Those that have been developed can be distinguished based on whether they use dynamic programming or heuristics. In what
1. Recall that an exact algorithm is one that always returns an optimal solution if it exists (Evans & Minieka, 1992).

526

A N A NYTIME A LGORITHM FOR O PTIMAL C OALITION S TRUCTURE G ENERATION

follows, we outline their features and discuss how they relate to our ultimate goal of developing an
efficient, anytime, optimal coalition structure generation algorithm.
2.1.1 DYNAMIC P ROGRAMMING
Here we consider computationally efficient algorithms designed to return an optimal solution. Note
that the emphasis, here, is on providing a guarantee on the performance of the algorithm in worstcase scenarios. In this context, Yeh (1986) developed a dynamic programming algorithm to solve
the complete set partitioning problem. A very similar algorithm was later developed by Rothkopf,
Pekec, and Harstad (1995) to solve the winner determination problem in combinatorial auctions.
These algorithms can be directly applied to find optimal coalition structures, since the problems
they were originally designed to solve are very similar to the CSG problem.2 Also note that both
of these algorithms use basically the same technique and, therefore, have the same computational
complexity. Thus, throughout this paper, we do not distinguish between them, and refer to both as
the dynamic programming (DP) algorithm. The biggest advantage of this algorithm is that it runs
in O(3n ) time (Rothkopf et al., 1995). This is significantly less than exhaustive enumeration of all
coalition structures (which is O(nn )). In fact, DP is polynomial in the size of the input. This is
because the input includes 2n − 1 values, and the following holds:
O(3n ) = O(2(log2 3)n ) = O((2n )log2 3 )
Therefore, the computational complexity of the algorithm is O(y log2 3 ), where y is the number
of values in the input. While, on the one hand, no other algorithm in the literature is guaranteed to
find an optimal coalition structure in polynomial time (in the size of the input), on the other hand,
the main limitation of DP is that it does not generate solutions anytime, and has a large memory
requirement. Specifically, it requires maintaining three tables in memory containing 2n entries
each.
More recently, Rahwan and Jennings (2008b) developed an Improved Dynamic Programming
algorithm (called IDP) that performs fewer operations and requires less memory than DP (e.g. given
25 agents, it performs only 38.7% of the operations, and requires 66.6% of the memory in the worst
case, and 33.3% in the best). However, IDP does not return solutions anytime. As mentioned earlier,
this is undesirable, especially given large numbers of agents, because the time required to return the
optimal solution might be longer than the time available to the agents.
2.1.2 A NYTIME A LGORITHMS W ITH W ORST C ASE G UARANTEES
Sandholm et al. (1999) were the first to introduce an anytime algorithm for coalition structure generation that establishes bounds on the quality of the solution found so far. They view the coalition
structure generation process as a search in what they call the coalition structure graph (see Figure
1). In this undirected graph, every node represents a possible coalition structure. The nodes are
categorized into n levels, noted as LV1 , · · · , LVn where level LVi contains the coalition structures
that contain i coalitions. The arcs represent mergers of two coalitions when followed upwards, and
splits of a coalition into two coalitions when followed downwards.
2. This is because they both involve partitioning a set of elements into subsets based on the weights that are associated
to every possible subset.

527

R AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGS

Figure 1: The coalition structure graph for 4 agents.
Sandholm et al. (1999) have proved that, in order to establish a bound on the quality of a coalition structure, it is sufficient to search through the first two levels of the coalition structure graph. In
this case, the bound β would be equal to n, and the number of searched coalition structures would
be 2n−1 . They have also proved that this bound is tight; meaning that no better bound exists for
this search. Moreover, they have proved that no other search algorithm (other than the one that
searches the first two levels) can establish any bound while searching only 2n−1 coalition structures
or fewer. This is because, in order to establish a bound, one needs to go through a subset of coalition structures in which every coalition appears at least once.3 This implies that the smallest subset
of coalition structures to be searched before a bound can be established is the one in which every
coalition appears exactly once, and the only subset in which this occurs is the one containing all the
coalition structures that belong to the first two levels of the graph.
If the first two levels have been searched, and additional time remains, then it would be desirable
to lower the bound with further search. Sandholm et al. (1999) have developed an algorithm for this
purpose. Basically, the algorithm searches the remaining levels one by one, starting from the bottom
level, and moving upwards in the graph. Moreover, Sandholm et al. have also proved that the bound
β is improved whenever the algorithm finishes searching a particular level. What is interesting here
is that, by searching the bottom level (which only contains one coalition structure) the bound drops
in half (i.e. β = n2 ). Then, roughly speaking, the divisor in the bound increases by one every time
3. Otherwise, if a coalition did not appear in any of these coalition structures, and if the value of this coalition happened to be arbitrarily better than the value of other coalitions, then every coalition structure containing it would be
arbitrarily better than those that do not.

528

A N A NYTIME A LGORITHM FOR O PTIMAL C OALITION S TRUCTURE G ENERATION

two more levels are searched, but seeing only one more level helps very little (Sandholm et al.,
1999).4
This algorithm has the advantage of being anytime, and being able to provide worst case guarantees on the quality of the solution found so far. However, the algorithm has two major limitations:
• The algorithm needs to search through the entire search space in order for the bound to
become 1. In other words, to return a solution that is guaranteed to be optimal, the algorithm
simply performs a brute-force search. As discussed in Section 1, this is intractable even for
small numbers of agents.
• The bounds provided by the algorithm might be too large for practical use. For example,
given n = 24, and given that the algorithm has finished searching levels LV1 , LV2 , and LV24
(which contain 8,388,609 coalition structures) the bound would be β = n/2 = 12. This
means that, in the worst case, the optimal solution can be 12 times better than the current
solution. In other words, the value of the current solution is only guaranteed to be no worse
than 8.33% of the value of the optimal solution. After that, in order to reduce the bound to
β = n/4, four more levels need to be searched, namely LV23 , LV22 , LV21 , and LV20 . In
other words, after searching an additional 119,461,563 coalition structures, the value of the
solution is only guaranteed to be no worse than 16.66% of the optimal value. Similarly, to
reduce the bound to β = n/6, the algorithm needs to search an additional 22,384,498,067,085
coalition structures only to guarantee that the value of the solution is no worse than 25% of
the optimal value. Moreover, the guarantee does not go beyond 50% until the entire space has
been searched.
Given the limitations of Sandholm et al.’s (1999) algorithm, Dang and Jennings (2004) developed
an anytime algorithm that can also establish a bound on the quality of the solution found so far, but
that uses a different search method. In more detail, the algorithm starts by searching the top two
levels, as well as the bottom one (as Sandholm et al.’s algorithm does). After that, however, instead
of searching through the remaining levels one by one (as Sandholm et al. do), the algorithm searches
through specific subsets of the remaining levels. Figure 2 compares the performance of both algorithms, and, by looking at this figure, we can see that neither of the two algorithms significantly
outperforms the other.
Note, however, that both algorithms were not meant for the case where the entire space will
eventually be searched. This is because if we had enough time to perform this search, then we
would have used the dynamic programming algorithm, which performs this search much quicker.
Instead, these algorithms were mainly developed for the cases where the space is too large to be
fully searched, even when the dynamic programming algorithm is being used.
Having discussed two algorithms that use similar techniques (i.e. by Sandholm et al., 1999 and
Dang & Jennings, 2004), we now discuss a different approach that can also provide solutions anytime, and can establish worst-case guarantees on the quality of its solution. This involves the use of
standard problem solving techniques that rely on general purpose solvers. In more detail, the coalition structure generation problem can be formulated as a binary integer programming problem (or
˚nˇ ¨n˝
4. To be more precise, depending on the number of agents and the level searched, the bound will either be m
or m
where m = 2, 3, · · · , n. However, to ease the discussion and without loss of generality, we will assume throughout
n
the paper that the bound is simply m
.

529

R AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGS

Figure 2: Given 24 agents, the figure shows, on a log scale, a comparison between the bound provided by Sandholm et al. (1999) and that provided by Dang and Jennings (2004), given
different numbers of searched coalition structures.

a 0-1 integer programming problem), since any variable representing a possible coalition can either
take a value of 1 (indicating that it belongs to the formed coalition structure) or 0 (indicating that it
doesn’t). Specifically, given n agents, the integer model for the CSG problem can be formulated as
follows:
Maximize

2n
P

v(Ci ) · xi

i=1

subject to Z · X = eT
X ∈ {1, 0}n
where Z is an n × 2n matrix of zeros and ones, X is a vector containing 2n binary variables,
and eT is the vector of n ones. In more detail, every line in Z represents an agent, and every column
represents a possible coalition. As for X, having an element xi = 1 corresponds to coalition Ci
being selected in the coalition structure. The first constraint ensures that the selected coalitions are
both disjoint and exhaustive.
Such an integer programming problem is typically solved by applying linear relaxation coupled
with branch-and-bound (Hillier & Lieberman, 2005). However, the main disadvantage of this approach is the huge memory requirement, which make it only applicable for small numbers of agents
(see Section 5 for more details).
530

A N A NYTIME A LGORITHM FOR O PTIMAL C OALITION S TRUCTURE G ENERATION

2.2 Non-Exact Algorithms for Coalition Structure Generation
These algorithms do not provide any guarantees on finding an optimal solution, nor do they provide
worst-case guarantees on the quality of their solutions. Instead, they simply return “good” solutions.
However, it is the fact that they can return a solution very quickly, compared to other algorithms, that
often makes this class of algorithms more applicable, particularly given larger numbers of agents.
Generally speaking, as long as there is some regularity in the search space (i.e., the evaluation
function is not arbitrary), genetic algorithms have the potential to detect that regularity and hence
find the coalition structures that perform relatively effectively. To this end, Sen and Dutta (2000)
developed a genetic algorithm for coalition structure generation. The algorithm starts with an initial
set of candidate solutions (i.e. a set of coalition structures) called a population, which then gradually evolves towards better solutions. This is done in three main steps: evaluation, selection, and
re-combination. In more detail, the algorithm evaluates every member of the current population,
selects members based on their evaluation, and constructs new members from the selected ones by
exchanging and modifying their contents. More details on the implementation can be found in the
paper by Sen and Dutta (2000). The main advantage of this algorithm is that it can return solutions
anytime, and that it scales up well with the increase in the number of agents. However, the main
limitation is that the solutions it provides are not guaranteed to be optimal, or even guaranteed to be
within a finite bound from the optimal. Moreover, even if the algorithm happens to find an optimal
solution, it is not possible to verify this fact.
Another algorithm that belongs to this class of algorithms is the one developed by Shehory and
Kraus (1998). This algorithm is greedy and operates in a decentralized manner. The heuristics
they propose (in order to reduce the complexity of finding an optimal coalition structure) involve
adding constraints on the size of the coalitions that are allowed to be formed. Specifically, only the
coalitions up to a size q < n are taken into consideration. The main advantage of this algorithm is
that it can take into consideration overlapping coalitions.5 Moreover, Shehory and Kraus prove that
the solution they provide is guaranteed to be within a bound from the optimal solution. However,
by optimal, they mean the best possible combination of all permitted coalitions. On the other hand,
the algorithm provides no guarantees on the quality of its solutions compared to the actual optimal
that could be found if all coalitions were taken into consideration.
To summarize, as discussed earlier, the main limitation of these algorithms is that they provide
no guarantees on the solutions they generate while they search or when they terminate. However,
these algorithms scale up well with the increase in the number of agents, making them particularly
suitable for the cases where the number of agents is so large that no algorithm with exponential
complexity can be executed in time.
After discussing the different approaches to the coalition structure generation problem, we can
see that each of these approaches suffers from major limitations, making it either inefficient or
inapplicable. This motivates our aim to develop more efficient CSG algorithms that can be applied
to a wider range of problems, while taking into consideration the objectives outlined in Section
1. With this in mind, we first present in Section 3 a novel representation of the search space, and
then present in Section 4 a novel algorithm that belongs to the first class of the aforementioned
classification. As we will show, this algorithm avoids all the limitations that exist in state-of-the-art
5. A solution containing overlapping coalitions means that the agents may participate in more than one coalition at the
same time.

531

R AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGS

algorithms belonging to this class, and meets all of the design objectives placed in Section 1 on CSG
algorithms.

3. Search Space Representation
In this section, we describe our novel representation of the search space (i.e. the space of possible
coalition structures). Recall that the space representation employed by most existing anytime algorithms is an undirected graph (see Figure 1 for an example), where the vertices represent coalition
structures (Sandholm et al., 1999; Dang & Jennings, 2004). This representation, however, forces all
possible solutions to be explored in order to guarantee that the optimal one has been found. Given
this, we believe an ideal representation of the search space should allow the computation of solutions anytime, while establishing bounds on their quality, and should allow the pruning of the space
to speed up the search. With this objective in mind, in this section we describe just such a representation. In particular, it supports an efficient search for the following reasons. First, it partitions
the space into smaller, independent, sub-spaces for which we can identify upper and lower bounds,
and thus, compute a bound on the solutions found during the search. Second, we can prune most
of these sub-spaces since we can identify the ones that cannot contain a solution better than the
best one found so far. Third, since the representation pre-determines the size of coalitions present
in each sub-space, agents can balance their preference for certain coalition sizes against the cost
of computing the solution for these sub-spaces. Next, we formally define our representation of the
search space, describe its algebraic properties, and describe how to compute worst case bounds on
the quality of the solution that our representation allows us to generate.
3.1 Partitioning the Search Space
We partition the search space P by defining sub-spaces that contain coalition structures that are
similar according to some criterion. The particular criterion we specify here is based on the integer
partitions of the number of agents.6 Recall that an integer partition of n is a multiset of positive
integers that add up to exactly n (Andrews & Eriksson, 2004). For example, given n = 4, the
five distinct partitions are: [4], [3, 1], [2, 2], [2, 1, 1], and [1, 1, 1, 1].7 It can easily be shown that the
different ways to partition a set of n elements can be directly mapped to the integer partitions of
n, where the parts of the integer partition correspond to the cardinalities of the subsets (i.e. the
sizes of the coalitions) within the set partition (i.e. coalition structure). For instance, the coalition
structures {{a1 , a2 }, {a3 }, {a4 }} and {{a4 , a1 }, {a2 }, {a3 }} can be mapped to the integer partition
[2, 1, 1] since they each contain one coalition of size 2, and two coalitions of size 1. We define the
aforementioned mapping by the function F : P → G, where G is the set of integer partitions of n.
Thus, F defines an equivalence relation ∼ on P such that CS ∼ CS 00 iff F (CS) = F (CS 00 ) (i.e.
the sizes of the coalitions in CS are the same as those in CS 00 ). Given this, the pre-image8 of an
integer partition G, noted as PG = F −1 [{G}], contains all the coalition structures that correspond
6. Other criteria could be developed to further partition the space into smaller sub-spaces, but the one we develop here
allows us to choose coalition structures with certain properties as we show later.
7. For presentation clarity, square brackets are used throughout the paper (instead of the curly ones) to distinguish
between multisets and sets.
8. Recall that the pre-image or inverse image of G ⊆ G under F : P → G is the subset of P defined by F −1 [{G}] =
{CS ∈ P|F (CS) = G}.

532

A N A NYTIME A LGORITHM FOR O PTIMAL C OALITION S TRUCTURE G ENERATION

to the same integer partition G. Every such pre-image represents a sub-space in our representation.
This implies that the number of sub-spaces in our representation is the same as the number of
possible integer partitions, which grows exponentially with n. This number, however, remains
insignificant compared to the number of possible coalitions and coalition structures (e.g., given
24 agents, the number of possible integer partitions is only 1575, while the number of possible
coalitions is 16777215, and the number of possible coalition structures is nearly 4.4 × 1017 ).
We categorize the sub-spaces into levels based on the number of parts within the integer partitions. Specifically, level Pi = {PG : |G| = i} contains all the sub-spaces that correspond to an
integer partition with i parts (see Figure 3 for an example of 4 agents).9 In what follows, we show
how to compute bounds for the sub-spaces (PG : G ∈ G) in our representation.

Figure 3: An example of our representation of the search space given 4 agents.

3.2 Computing Bounds for Sub-spaces
For each sub-space PG , it is possible to compute an upper and a lower bound on the value of the
best10 coalition structure that could be found in it. To this end, let Ls be the list of coalitions
of size s, and let maxs , mins , and avgs , be the maximum, minimum, and average value of the
coalitions in Ls respectively. Moreover, given
Q an integer partition G, let TG be the Cartesian product
of the lists Ls : s ∈ G. That is, TG = s∈G (Ls )G(s) , where G(s) is the multiplicity of s in
9. Note that the levels in our representation are basically the same as those that appear in the coalition structure graph,
except that the coalition structures within each level are now categorized into sub-spaces. In other words, the coalition
structures that belong to the sub-spaces in Pi are the same as those that belong to LVi .
10. Throughout this paper, a coalition structure is described as being “the best” if it has the highest value.

533

R AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGS

G. For example, given G = [5, 4, 4, 4, 1, 1], we have TG = (L5 )1 × (L4 )3 × (L1 )2 . Note that
TG contains many combinations of coalitions that are considered invalid coalition structures. This
is because some of the coalitions within these combinations may overlap. For example, T[2,1,1]
contains the following combination, {{a1 , a2 }, {a1 },{a3 }}, which is not a valid coalition structure
because agent a1 appears in two coalitions. Now, if we consider the value of each element (i.e.
combination of coalitions) in TG to be the sum of the values of all the coalitions in that element,
then the maximum
value that an element in TG can take, denoted M AXG , is computed as follows:
P
M AXG = s∈G maxs × G(s). Based on this, it is easy to demonstrate that M AXG is an upper
bound on the value of the best coalition structure in PG (since PG is a subset of TG ).
Similarly, the minimum
value that an element in TG can take, denoted M ING , is computed as
P
follows: M ING =
s∈G mins × G(s). Although this could intuitively be considered a lower
bound on the value of the best coalition structure (i.e. solution) in PG , we show that it is actually
possible to compute a higher (i.e. better) lower bound than M ING .
In more detail, let AV GG be the average value of all the coalition structures in PG . Then,
AV GG would be a lower bound on the value of the best coalition structure in PG (since an average
is always greater than, or equal to, a minimum). The key point to note, here, is that we can compute
AV GG without having to go through any of the coalition structures in PG . Instead, we can compute
it by simply summing the averages of the coalition lists (see Theorem 1), and these averages can
be computed immediately after scanning the input, which is significantly smaller than the space of
possible coalition structures.
Theorem 1. Let G = [g1 , · · · , gi , · · · , g|G| ] be an integer partition, and let AV GG be the average
of the values of all the coalition structures in PG . Also, let avggi be the average of the values of all
the coalitions in Lgi . Then, the following holds:
AV GG =

|G|
X

avggi

i=1

Proof. See Appendix B.
Having described our novel representation of the search space, we present (in the following section)
an anytime algorithm that uses this representation to search through the possible coalitions structures
to eventually find an optimal one.

4. Solving the Coalition Structure Generation Problem
Assuming that the value of every coalition C is given by a characteristic function
v(C) ∈ R, and
P
that the value of every coalition structure is given by the function V (CS) = C∈CS v(C), our goal
is to search through the set of possible coalition structures, noted as P, in order to find an optimal
coalition structure which is computed as:
CS ∗ = arg max V (CS)
CS∈P

(1)

given v(C) for all C ∈ 2A \{∅}. Note that, in this section, the terms “coalition structure” and
“solution” will be used interchangeably.
Basically, our novel anytime Integer-Partition based algorithm (which we call IP) consists of the
following two main steps:
534

A N A NYTIME A LGORITHM FOR O PTIMAL C OALITION S TRUCTURE G ENERATION

1. Scanning the input in order to compute the bounds (i.e. M AXG and AV GG ) for every subspace PG — while doing so, we can (at a very small cost):
(a) find the best coalition structures within particular sub-spaces.
(b) prune other sub-spaces based on their upper-bounds.
(c) establish a worst-case bound on the quality of the best solution found so far.
2. Searching within the remaining sub-spaces — the techniques we use allow us to:
(a) avoid making unnecessary comparisons between coalitions to generate valid coalition
structures (i.e. those that contain disjoint coalitions).
(b) avoid computing the same coalition structure more than once.
(c) apply branch-and-bound to further reduce the amount of search to be done.
The following sub-sections describe each of the aforementioned steps in more detail. To this end,
we will use CS 0 to denote the best coalition structure found so far, and G 0 ⊆ G to denote the integer
partitions that represent the sub-spaces that have not been searched.
4.1 Scanning the Input
The input to the coalition structure generation problem is the value associated to each coalition,
i.e. v(C) for all C ∈ 2A \{∅}. One way of representing this input is to use a table containing
every coalition along with its value. Another way is to agree on an ordering of the coalitions, and
to use a list containing only the values of these ordered coalitions (i.e. the first value in the list
corresponds to the first coalition, the second value corresponds to the second coalition, and so on).
We use the latter representation since it does not require maintaining the coalitions themselves in
memory. In more detail, we assume that the input is given as follows: v(Ls ) ∀s ∈ {1, 2, . . . , n},
where v(Ls ) is a list containing the values of all the coalitions of size s. Moreover, we assume
that the coalitions in Ls are ordered lexicographically. For example, coalition {a1 , a2 , a4 } has its
elements ordered according to their indices, and the coalition itself is found above {a1 , a2 , a3 } and
below {a1 , a3 , a4 } in the list L3 (this is depicted in Figure 4). This ordering can easily be generated
using the techniques that are used by Rahwan and Jennings (2007). Next, we describe the individual
steps of the algorithm that depicts the scanning process (see Algorithm 1).
At first, we scan the value of the one coalition of size n (i.e. the grand coalition). This would
be the value of the only coalition structure in P[n] (which is the only sub-space in P1 ). After that,
we scan the values of all the coalitions of size 1 (i.e. singleton coalitions), and by summing these
values, we get the value of the only coalition structure in P[1,1,...,1] (which is the only sub-space in
Pn ). At this point (step 1), it is possible to compute the best coalition structure found so far (i.e.
CS 0 ).
Having searched through levels P1 and Pn , we now show how to search through level P2 at
a very low cost while scanning the input. To this end, let G 2 = {G ∈ G : |G| = 2} be the set
of integer partitions that contain two parts each. Then, as a result of the assumed ordering of the
b in a coalition structure CS = {C, C}
b are always
input, any two complementary coalitions C and C
diametrically positioned in the coalition lists L|C| and L|Cb| , and that happens even if |C| = |C 0 |. For
example, given 6 agents, the coalitions {a1 } and {a2 , a3 , a4 , a5 , a6 } are diametrically positioned in
535

R AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGS

Algorithm 1 : scanAndSearch() – scan the input, generate initial solutions and bounds.
Require: n, {v(Ls )}s∈{1,2,...,n}
1: CS 0 ← arg maxCS∈{ {a1 ,...,an }, {{a1 },...,{an }} } V (CS)
2: for s = 1 to b n
2 c do
3:
sb ← n − s
4:
if s = sb {if cycling through the same list.} then
5:
end = b|v(Ls )|/2c
6:
else
7:
end = |v(Ls )|
8:
end if
9:
Set maxs , maxsb, vmax to −∞ , and set sums , sumsb to 0
10:
for x = 1 to end {cycle through the lists v(Ls ) and v(Lsb).} do
11:
x
b ← |v(Ls )| − x + 1
12:
v ← v(Ls )x , vb ← v(Lsb)xb {extract element at x, xb from v(Ls ), v(Lsb).}
13:
if vmax < v + vb then
14:
vmax ← v + vb
15:
xmax = x {record the index in v(Ls ) at which v is located.}
16:
end if
17:
if maxs < v then
18:
maxs ← v {record the maximum value in v(Ls ).}
19:
end if
20:
if maxsb < vb then
21:
maxsb ← vb {record the maximum value in v(Lsb).}
22:
end if
23:
sums ← sums + v , sumsb ← sumsb + vb
24:
end for
25:
x
bmax ← |v(Ls )| − xmax + 1
26:
if V (CS 0 ) < V ({Lxs max , Lxsbbmax }) then
27:
CS 0 ← {Lxs max , Lxsbbmax } {update the best coalition structure found so far.}
28:
end if
29:
avgs ← sums /|v(Ls )| , avgsb ← sumsb/|v(Lsb)| {compute averages.}
30: end for
31: G 0 ← G \ G 2
32: for G ∈ G 0 {compute upper and lower bounds for each sub-space in G 0 .} do
P
33:
M AXG ←P s∈G maxs · G(s)
34:
AV GG ← s∈G avgs · G(s)
35: end for
36: U B ∗ ← max[ V (CS 0 ), maxG∈G 0 [M AXG ] ]
37: LB ∗ ← max[ V (CS 0 ), maxG∈G 0 [AV GG ] ]
38:

G 0 ← prune(G 0 , {M AXG }G∈G 0 , LB ∗ )

{prune the sub-spaces that have an upper

∗

bound lower than LB .}
39:

β ← min[ n/2 , U B ∗ /V (CS 0 ) ] {compute a worst-case bound on V (CS 0 ).}

40:

return CS 0 , β, {maxs }s∈{1,...,n} , G 0 , {M AXG }G∈G 0 , {AV GG }G∈G 0

536

A N A NYTIME A LGORITHM FOR O PTIMAL C OALITION S TRUCTURE G ENERATION

the lists L1 and L5 respectively, and the coalitions {a1 , a2 , a3 } and {a4 , a5 , a6 } are diametrically
positioned in the list L3 (see Figure 4 for an example of 6 agents).

Figure 4: An example of the assumed ordering of the coalition lists.
Based on this, for every integer partition G = [g1 , g2 ] ∈ G 2 , we compute the values of all the
coalition structures in PG by simply summing the values of the coalitions as we scan the lists v(Lg1 )
and v(Lg2 ), starting at different extremities for each list. Once these lists have been scanned (steps
10 to 24), it is possible to obtain the two values of which the sum is maximized. Moreover, it is
possible to obtain the indices in the lists at which these values are located (see how xmax and x
bmax
are computed in steps 15 and 25 respectively). Then, by obtaining these indices, we know where
in Lg1 and Lg2 to find the two coalitions that belong to the best coalition structure in P[g1 ,g2 ] (this
comes from the fact that the position of any value in v(Ls ) : s ∈ {1, ..., n} is exactly the position
of the corresponding coalition in Ls ).
Note, however, that the input includes only v(Lg1 ) and v(Lg2 ) (i.e. it does not include Lg1 and
Lg2 ). For this reason, an algorithm is required that can return a coalition C given its position in the
ordered list L|C| . Rahwan and Jennings (2007) have developed a polynomial-time algorithm that
does exactly that. Therefore, we use it to find the required coalitions and compose the best coalition
structure in P{g1 ,g2 } (see steps 26 and 27).11
While scanning v(Lg1 ) and v(Lg2 ), we also compute maxg1 and maxg2 (steps 17 to 22), as
well as avgg1 and avgg2 (step 29). Note that, in Algorithm 1, we scan v(Ls ) and v(Ln−s ) for all
s ∈ {1, . . . , b n2 c} and this implies that maxs and avgs are computed for all s ∈ {1, . . . , n}. Also
note that this whole process is linear in the size of the input (i.e. O(y) where y = 2n − 1 is the size
of the input).
11. By Lxs we mean that we extract the element at position x from Ls .

537

R AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGS

Having computed maxs and avgs for every size s, we can now compute upper and lower bounds
for every sub-space (as in steps 32 to 34). By using these bounds, it is possible to compute an upper
bound U B ∗ and a lower bound LB ∗ on the value of the optimal coalition structure (see steps 36 and
37). Hence, every sub-space PG that has an upper bound M AXG < LB ∗ can be pruned straight
away. The prune function (used in step 38) is implemented as in Algorithm 2.
Algorithm 2 :prune(G 0 , {M AXG }G∈G 0 , υ) – prune sub-spaces.
1: for G ∈ G 0 do
2:
if M AXG ≤ υ {if the upper bound of PG is lower than υ.}
3:
G 0 ← G 0 \ G {remove G.}
4:
end if
5: end for
6: return G 0

then

Another advantage of our scanning procedure is that it allows us to compute a worst-case bound
B∗
β on the value of CS 0 as follows: β = min( n2 , V U(CS
0 ) ) (see step 39). This comes from the fact
Sandholm et al. (1999) have proved that the value of the best coalition structure in levels LV1 , LV2
and LVn (corresponding to P1 , P2 , and Pn respectively) is within a bound n2 from the optimal.
So far, by only scanning the input, we have calculated maxs and avgs for all s ∈ {1, . . . , n},
we have searched levels P1 , P2 , Pn , we have calculated M AXG and AV GG for all the sub-spaces
within the remaining levels (i.e. P3 , ..., Pn−1 ), we have pruned some of these sub-spaces, and we
have established a worst-case bound β on the quality of the best solution found so far. Moreover, it
is possible to specify a bound β ∗ ≥ 1 within which any solution is acceptable. In more detail, if the
best solution found so far fits within the specified bound (i.e. if β ≤ β ∗ ) then no further search is
required. Otherwise, the sub-spaces that have not been pruned (if there are any) must be searched.
Next, we specify how this search is done.
4.2 Selecting and Searching a Sub-Space
Given the set of sub-spaces left after scanning the input, we select a sub-space to be searched, and
we find the best coalition structure in it. After that, we prune all the remaining sub-spaces that have
an upper bound lower than the best value found so far. This process of selecting, searching, and
pruning, is repeated until either of the following termination conditions is reached:
• The best coalition structure found so far fits within the specified bound β ∗ .
• All the remaining sub-spaces have either been searched or pruned.
This can be seen in Algorithm 3. Basically, the algorithm works as follows. A sub-space PG00 is
selected to be searched (step 2).12 Once PG00 has been searched (step 3), it is removed from the set
of remaining sub-spaces (step 4). After that, we check whether CS 0 has been modified during the
search (step 5), and, if that is the case, then every sub-space with an upper bound lower than V (CS 0 )
is pruned (step 6).13 U B ∗ and β are then updated in steps 8 and 9 respectively, and if the current
12. In step 2, we actually select an integer partition, but this implies that the corresponding sub-section is to be searched.
13. Checking whether CS 0 belongs to PG00 can easily be done by checking whether the sizes of the coalitions in CS 0
match the parts in G00 .

538

A N A NYTIME A LGORITHM FOR O PTIMAL C OALITION S TRUCTURE G ENERATION

best solution fits within the specified bound β ∗ then it is returned (steps 10 and 11). Otherwise, this
whole process is repeated given the remaining sub-spaces (if there are any). In what follows, we
further elaborate on the sub-space selection strategy and the sub-space search algorithm since these
are the key parts of this algorithm.
Algorithm 3 :searchSpace() – search, or prune, the remaining sub-spaces.
Require: G 0 , {M AXG }G∈G 0 , A, β ∗
1: while G 0 6= ∅ do
2:
Select G00 {select the integer partition that represents the next sub-space
to be searched.}
3:
4:

−→
CS 0 ← searchList(G00 , 1, 1, A, CS 0 , CS) {search within PG00 and update CS 0 .}
G 0 ← G 0 \ G00
{remove PG00 from the list of sub-spaces that are yet to be
searched.}

5:
6:

if CS 0 ∈ PG00 {If CS 0 has been modified while searching PG00 .} then
G 0 ← prune(G 0 , {M AXG }G∈G 0 , V (CS 0 ))
{prune the sub-spaces that have
upper bounds lower than V (CS 0 ).}

7:
8:

end if
U B ∗ ← max[ V (CS 0 ), maxG∈G 0 [M AXG ] ] {update the upper bound on the value
of the optimal coalition structure(s).}

9:
10:
11:
12:
13:
14:

∗

B
0
β ← min[ V U(CS
0 ) , β] {update the worst-case bound on V (CS ).}

if β ≤ β ∗ {if CS 0 is within the specified bound from the optimal.} then
return CS 0
end if
end while
return CS 0

4.2.1 S ELECTING A S UB -S PACE
It can easily be seen that, unless we search the sub-spaces that have an upper bound greater than
V (CS 0 ), we cannot verify that CS 0 is an optimal solution. This implies that β remains greater than
1 until the following sub-spaces are searched: {PG : M AXG ≥ V (CS ∗ )}. This can be done by
selecting the next sub-space to be searched using the following selection rule:
Select G = arg max(M AXG )
G∈G 0

As a result of this selection strategy, all sub-spaces with an upper bound lower than V (CS ∗ ) will
not be searched and these can constitute a significant portion of the search space (see Section 5.3
for more details). Another result is that it will always be beneficial to search a sub-space, even if
that sub-space does not contain a better solution than the one found so far. This is because the above
selection strategy ensures that U B ∗ is reduced whenever a sub-space is searched, and this improves
the worst-case guarantee β on the quality of the current best solution.
Note that this selection rule is mainly for the cases where an optimal solution is sought. In case
we are after a near-optimal solution where a bound β ∗ > 1 is specified (e.g., β ∗ = 1.05 means
that the solution sought needs to have a value that is at least 95% of the optimal one), then other
539

R AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGS

selection rules may be used. For example, one could select to search the smallest sub-space that
∗
could, potentially, give a value greater than or equal to UβB∗ (hoping to find an acceptable solution
in the least amount of search). This can be expressed as:
Select G =

arg min
∗

(|PG |)

G∈G 0 :U BG ≥ UβB∗

where |PG | is the size of (i.e. the number of coalition structures in) PG . More specifically, |PG | is
computed as follows:
Theorem 2. Let G = [g1 , . . . , g|G| ] be an integer partition, and let |PG | be the number of coalition
structures in PG . Moreover, let Csn be the binomial coefficient,14 and let E(G) be the underlying
set of G.15 Then, the following holds:
n−(g1 +...+g|G|−1 )

1
Cgn × Cgn−g
× . . . × Cg|G|
2
Q
|PG | = 1
s∈E(G) G(s)!

Proof. See Appendix C.
The key point to note is that, given our representation, we can specify β ∗ in cases where computing the optimal solution would be too costly and, given this, we can modify the selection rule
accordingly to speed up the search.
Another advantage of being able to control the sub-spaces to be searched is that the agents can
choose what types of coalition structures to build according to their computational resources or
private preferences. For example, it has been argued that the computation time could be reduced if
we limit the size of the coalitions that can be formed (Shehory & Kraus, 1998). However, this is a
very costly, self-imposed constraint since it possibly means neglecting a number of highly efficient
solutions. Instead, by using IP, it is possible to determine, ex-ante (i.e. before performing the
search), which sub-spaces are most promising according to their upper and lower bounds. Therefore
the computation time can be focused on these sub-spaces and the gains can be traded-off against the
computation time.
In some other cases, agents may need to form q coalitions (Shehory & Kraus, 1995). For
example, they may need to perform q tasks and therefore need to divide up into q teams to perform
these tasks separately. Moreover, they may wish to have coalitions with a maximum size of z as
they may have certain constraints on the amount of resources available to each coalition. By using
our representation, such preferences can be naturally expressed and the search can be directed to fit
these preferences transparently. Formally, our search space can easily be redefined as follows:
G 00 = {G ∈ G : |G| = m ∧ ∀g ∈ G : |g| ≤ z}
In all the above cases where agents can express preferences for coalition structures of certain
sizes, they can now, a priori, balance such preferences with the quality of the solutions that can be
14. Recall that the binomial coefficient represents the number of possible combinations of size s taken from n elements,
n!
and is computed as follows: Csn = k!(n−k)!
, where n! is the factorial of n.
15. Recall that the underlying set E(G) of a multiset G is a subset of G in which each element in G appears only once
in E(G). For example, {1, 2} is the underlying set of [1, 1, 2].

540

A N A NYTIME A LGORITHM FOR O PTIMAL C OALITION S TRUCTURE G ENERATION

obtained. This is because we are able to determine the worst-case bound from the optimal that the
U B∗
search of a given sub-space will generate (i.e. AV
GG ). We next describe how we search through the
chosen sub-space.
4.2.2 S EARCHING A S UB -S PACE
Given an integer partition G = [g1 , g2 , · · · , g|G| ] ∈ G, we need to cycle through the coalition
structures that belong to PG in order to find the best one. Here, without loss of generality, we
assume that g1 ≤ g2 ≤ · · · , ≤ g|G| . Perhaps the most obvious way of performing this cyclation



−→
process is shown in Figure 5. Here, a variable CS = C1 , C2 , · · · , C|G| is used to cycle though
the coalition structures in PG as follows. First, C1 is assigned to one of the coalitions in Lg1 . After
that, C2 is used to cycle through Lg2 until a coalition that does not overlap with C1 is found. After
that, C3 is used to cycle through Lg3 until a coalition that does not overlap with {C1 , C2 } is found.
−→
−→
This is repeated until every Ck ∈ CS is assigned to a coalition in Lgk . In this case, CS would be
a valid coalition structure belonging to PG . The value of this coalition structure is then calculated
−→
and compared with the maximum value found so far. After that, the coalitions in CS are updated
−→
so as to set CS to another coalition structure in PG . Here, a coalition Ck is only updated once we
have examined all the possible instances of Ck+1 , . . . , , C|G| that do not overlap with {C1 , . . . , Ck }.
For example, in Figure 5, we only update C2 (step 5 in the figure) once we have examined all the
possible instances of C3 that do not overlap with {C1 , C2 } (steps 2, 3, 4 in the figure). This ensures
−→
that CS is assigned to different coalition structures, and that, eventually, every possible coalition
structure in PG is examined.
Next, we show how this process can be done without storing any of the lists Lg1 , Lg2 , · · · , Lg|G|
in memory. To this end, let LCgnk : 1 ≤ gk ≤ n be the list of combinations of size gk that are
taken from the set {1, 2, · · · , n}, where the combinations are ordered lexicographically in the list.
Given this, both LCgnk and Lgk contain the subsets of size gk that are taken from a set of size n. The
only difference is that LCgnk is a list of combinations of numbers while Lgk is a list of coalitions of
agents. Now, Rahwan and Jennings (2007) have shown how to cycle through the combinations in
LCgnk without storing the entire list in memory. Instead, only one combination is stored at a time.
This is based on the assumed ordering which implies that the last combination in LCgnk is always:
{1, 2, · · · , gk }. This
ordering
also implies that, given any combination located at index x in the list,


where 1 < x ≤ LCgnk , it is possible to compute the combination located at index x − 1 (for more
details, see the paper by Rahwan & Jennings, 2007). Hence, in order to go through the coalitions in
Lgk , we use a variable Mk to cycle16 through the combinations in LCgnk and, for every instance of
Mk , we extract the corresponding coalition Ck ∈ Lgk using the following operation:
Ck = {ai ∈ A | i ∈ Mk }

(2)

For example, given that Mk = {2, 4, 5}, the corresponding coalition would be {a2 , a4 , a5 }. Since
there is a direct mapping (as defined by equation 2) from every combination in LCgnk to a coalition
in Lgk , then, by having Mk cycle through every combination in LCgnk , we cycle through all the
coalitions in Lgk .
16. This can be done by initializing Mk to the last combination in LCgnk (i.e. to {1, 2, · · · , gk }), and then iteratively
shifting Mk up in the list as in the paper by Rahwan and Jennings (2007), until every combination in LCgnk is
examined.

541

R AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGS

Figure 5: A naı̈ve cyclation process for cycling through the coalition structures in a sub-space.
542

A N A NYTIME A LGORITHM FOR O PTIMAL C OALITION S TRUCTURE G ENERATION

Intuitively, this naı̈ve cyclation process, which we call NCP, can be viewed as being efficient.
After all, what we need is to find the coalition structure in PG that has the maximum value, and
NCP guarantees to find such a coalition structure. However, it suffers from the following major
limitations:
1. NCP works by searching through the ordered sets in TG — the Cartesian product of the lists
Ls : s ∈ G — in order to find those that belong to PG (i.e. those that contain disjoint
coalitions). This is a major limitation since the space of coalition structures is already exponentially large, and it would be counter-intuitive to search for it in an even bigger space.
For example, given 28 agents, the number of coalition structures in P[1,2,3,4,5,6,7] is only
7.8 × 10−9 % of the number of ordered sets in T[1,2,3,4,5,6,7] . Note that the difference in size
between the two spaces grows exponentially with the number of agents involved.
2. Although NCP does not generate the same ordered set twice, it generates multiple ordered sets
containing the same coalitions, but ordered differently. For example, given A = {a1 , · · · , a7 }
and G = [2, 2, 3], NCP generates the following ordered sets, h{a1 , a2 }, {a3 , a4 }, {a5 , a6 , a7 }i
and h{a3 , a4 }, {a1 , a2 }, {a5 , a6 , a7 }i, which correspond to the same coalition structure. Note
that we need to find the best coalition structure and, in order to do so, it is sufficient to examine
the value of every coalition structure once. In other words, any operation that results in the
same coalition structure being generated more than once is considered redundant.
What would be desirable, then, is to find a way to cycle through the lists Lg1 , . . . , Lg|G| such that
only valid combinations are generated. In other words, it would be desirable if Ck only cycles
through the valid coalitions in Lgk , rather than going through every coalition in Lgk and verifying
whether it overlaps with {C1 , . . . , Ck−1 }. Moreover, in order to avoid performing any redundant
operations, it would be desirable if the cyclation process is guaranteed not to go through the same
coalition structure more than once. Algorithm 4 describes a novel cyclation process that meets these
requirements.
The basic idea is to use the searchList function to cycle through the coalitions in Lg1 . For
each of these coalitions, searchList is called recursively17 to cycle through the coalitions in Lg2
that do not overlap with the first coalition (i.e. the one taken from Lg1 ). Similarly, while cycling
through Lg2 , searchList is called recursively to cycle through the coalitions in Lg3 that do not
overlap with the first two coalitions, and so on. This is repeated until searchList is called to
−→
cycle through the coalitions in Lg|G| , in which case we have a valid coalition structure (denoted CS
−→
in Algorithm 4) that belongs to PG . Then, if CS has a value that is greater than V (CS 0 ) then CS 0
is updated accordingly. The remainder of this section describes how Algorithm 4 avoids generating
invalid or redundant coalition structures without making any comparison between coalitions. It also
describes how the algorithm applies a branch-and-bound technique to speed up the search.
Avoiding invalid coalition structures: Given G = [g1 , . . . , g|G| ], we define the following ordered
sets of agents: A1 , A2 , · · · , A|G| , where A1 contains n agents, and Ak : 2 ≤ k ≤ |G| contains
Pk−1
n − i=1
gi agents. Moreover, we assume that the agents in Ak : 1 ≤ k ≤ |G| are ordered
17. searchList is not actually implemented in our code as a recursive function (due to the inefficiency of recursive
functions in general). However, to make Algorithm 4 easier to understand, the recursive form of the algorithm is
presented in the paper.

543

R AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGS

−→
Algorithm 4 :searchList(G, k, α, Ak , CS 0 , CS) – search a sub-space.
Require: {maxs }s∈{1,··· ,n} , {v(Ls )}s∈{1,··· ,n} , U B ∗ , β ∗
1: if k > 1 and gk 6= gk−1 {if the size is not being repeated.} then
2:
α ← 1 {reset α.}
3: end if
Pk
|A |
4: for Mk ∈ LCgk k such that α ≤ Mk,1 ≤ n + 1 −
i=1 (gk × G(gk )) do
5:
6:
7:
8:
9:

Ck ← {Ak,i | i ∈ Mk } {extract Ck given Mk and Ak .}
−→
if k = |G| and V (CS 0 ) < V (CS) then
−→
CS 0 ← CS {update
the current best.}
P
P
else if V (CS 0 ) < s∈{g1 ,··· ,gk } v(Cs ) + s∈{gk+1 ,··· ,gn } maxs {branch only if there
is potential of finding a coalition structure better than CS 0 .} then
−→
CS 0 ← searchList(G, k + 1, Mk,1 , A \ C, CS 0 , CS)
{branch to next
coalition.}

10:
11:

end if
B∗
if V U(CS
≤ β ∗ or V (CS 0 ) = M AXG
0)

{stop if the required solution has

been found or if the current best is equal to the upper bound of this
sub-space.}

return
end if
14: end for
15: return CS 0

12:

then

CS 0

13:

ascendingly based on their indices in A (e.g. if Ak contains agents a5 , a7 , and a2 , then the order
would be Ak = ha2 , a5 , a7 i). In other words, we assume that: Ak,1 < Ak,2 < · · · < Ak,|Ak | , where
Ak,i is the ith agent in Ak .18 Now, given a number of coalitions C1 , C2 , · · · , Cgk−1 taken from the
lists Lg1 , Lg2 , · · · , Lgk−1 respectively, we show how to cycle through the coalitions in Lgk that do
not overlap with any of the aforementioned ones, and that is without storing Lgk in memory. In
more detail, this can be done using the following modifications over NCP:
• Instead of using Mk to cycle through the combinations in LCgnk (as in NCP), we use it to
|A |

cycle through the combinations in LCgk k .
• For any given instance of Mk , we extract the corresponding coalition Ck ∈ Lgk using the
following operation: Ck = {Ak,i | i ∈ Mk } (see step 5 of Algorithm 4). For example, given
Mk = {1, 3, 5}, the corresponding coalition does not contain agents a1 , a3 , and a5 (as in
NCP). Instead, it contains the 1st , the 3rd , and the 5th element of Ak .
These differences ensure that Mk cycles through all the possible coalitions of size gk that are taken
from Ak (instead of those taken from A). Based on this, if we set Ak = A\{C1 , · · · , Ck−1 }, then
we ensure that every instance of Ck does not overlap with any of the coalitions C1 , · · · , Ck−1 .
Figure 6 shows an example given A = A1 = {a1 , a2 , a3 , a4 , a5 , a6 , a7 } and G = [2, 2, 3]. As
can be seen, having M1 = {1, 6} implies that C1 contains the 1st and 6th agents in A1 (i.e. it implies
18. Recall that we define an order over the agents in A such that, for any two agents ai , aj ∈ A, we have ai < aj iff
i < j. For more details, see Section 2.

544

A N A NYTIME A LGORITHM FOR O PTIMAL C OALITION S TRUCTURE G ENERATION

that C1 = {a1 , a6 }). By knowing the agents that belong to C1 , we can then assign A2 to those that
do not belong to C1 , i.e. A2 = {a2 , a3 , a4 , a5 , a7 } (see how the agents in A2 are ordered based on
their indices in A). As mentioned earlier, M2 would then cycle through all the possible coalitions of
size 2 out of A2 , and none of these coalitions would overlap with C1 . Similarly, having M2 = {3, 5}
implies that C2 contains the 3rd and 5th elements of A2 (i.e. it implies that C2 = {a4 , a7 }), and by
knowing the agents that belong to C2 , we can then assign A3 to those that do not belong to C1 or
C2 (i.e. A3 = {a2 , a3 , a5 }), and so on.

Figure 6: Example of our novel cyclation process, given A = {a1 , a2 , a3 , a4 , a5 , a6 , a7 } and G =
[2, 2, 3].

The modified cyclation process (MCP), which we describe above, generates all the coalition
structures in PG (see Theorem 3), and that is without performing any comparison between the
coalitions.
Theorem 3. Given an integer partition G ∈ G, every coalition structure in PG is generated by
MCP.
Proof. See Appendix D.
Note, however, that MCP suffers from the same limitation of NCP in that it could generate the
same coalition structure more than once (e.g. given G = [2, 2, 3], both h{a1 , a2 }, {a3 , a4 }, {a5 , a6 , a7 }i
and h{a3 , a4 }, {a1 , a2 }, {a5 , a6 , a7 }i are generated by MCP). Next, we show how this can be
avoided.

545

R AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGS

Avoiding redundant coalition structures: We note that, by using MCP, the same coalition structure can only be generated twice if there are repeated parts in the integer partition
G (e.g.  G =


[1, 2, 2, 3] or G = [1, 4, 4, 4, 6]). This is because MCP generates ordered sets C1 , · · · , C|G| containing disjoint coalitions of which the sizes match the parts in G (i.e. |Ck | = gk ∈ {1, · · · , |G|}).
−→
−→
Based on this, if an ordered set CS is generated by MCP, then, any other ordered set CS 0 that
−→
contains the same coalitions but with a different order (compared to CS) will also be generated by
MCP as long as the sizes of the coalitions match the parts in G. This, of course, can only happen if
we have gk = gj : k 6= j. Based on this, MCP only needs to be modified for the cases where there
are repeated parts in G.19 This modification is done as follows:
|A |

• While cycling through the combinations in LCgk k , ensure
Pk that the first (i.e. smallest) element
in Mk (denoted Mk,1 ) satisfies: α ≤ Mk,1 ≤ n + 1 − i=1 (gk × G(gk )), where α = Mk−1,1
if gk = gk−1 , and α = 1 otherwise (see step 4 of Algorithm 4).
This is illustrated in Figure 6 using the connected boxes. In more detail, M1 only cycles through the
combinations in LC27 that are contained in boxes (e.g. it does not cycle through combinations {5, 6},
{5, 7}, and {6, 7}). Moreover, M2 only cycles through the combinations in LC25 that are contained
in boxes connected to the one in which M1 is currently cycling. This modification ensures that
Mk+1,1 ≥ Mk,1 when gk+1 = gk . For example, while M1 is cycling through the box in LC27
containing the combinations in which the smallest element is 3, we have M1,1 = 3. In this case, M2
only cycles through the boxes in LC25 containing the combinations in which the smallest element is
3 or 4 (see how these boxes are connected in Figure 6), and this ensures that M2,1 ≥ M1,1 .
The final cyclation process (FCP), which we describe above, generates every coalition structure
in PG exactly once.
Theorem 4. Given an integer partition G ∈ G, every coalition structure in PG is generated exactly
once by FCP.
Proof. See Appendix E.
Note, however, that given the exponential size of PG , it would be more desirable if we can avoid
generating any coalition structure with no potential of having a value greater than the maximum one
found so far. Next, we show how this can be done using a branch-and-bound technique.
Applying Branch-and-Bound: As mentioned earlier, when cycling through the coalition structures
in PG , we only update Ck once we have examined all the possible instances of {Ck+1 , . . . , C|G| }
that do not overlap with {C1 , . . . , Ck }. In other words, we only update Ck once we have examined
all the possible coalition structures that start with {C1 , . . . , Ck }. However, if we knew that none of
these coalition structures could have a value greater than the maximum value found so far, then we
could update Ck straight away (i.e. without having to go through any of the possible instances of
{Ck+1 , . . . , C|G| }). In order to do so, we calculate an upper bound on the values of the coalitions
that can be added to {C1 , . . . , Ck }. Specifically, having computed maxs for every possible coalition
19. Note that most of the coalition structures usually contain repeated coalition sizes (e.g. 99.6% of them given 20
agents).

546

A N A NYTIME A LGORITHM FOR O PTIMAL C OALITION S TRUCTURE G ENERATION

of size s ∈ {1, 2, . . . , n}, we can then calculate such an upper bound, denoted M AX[gk+1 ,...,g|G| ] ,
as follows:
M AX[gk+1 ,...,g|G| ] =

|G|
X

maxgi

i=k+1

Now, if we define VP({C1 , · · · , Ck }) as the sum of the values of coalitions C1 , · · · , Ck (that is,
k
V (C1 , . . . , Ck ) =
i=1 v(Ci )), then V ({C1 , ..., Ck }) + M AX[gk+1 ,...,g|G| ] represents an upper
bound on the value of the coalition structure that could be obtained with a coalition structure starting
with {C1 , · · · , Ck } and ending with coalition sizes [gk+1 , . . . , g|G| ].
Hence, having V (CS 0 ) ≥ V ({C1 , ..., Ck }) + M AX[gk+1 ,...,g|G| ] implies that none of the coalition structures that start with {C1 , ..., Ck } and end with coalitions of sizes: gk+1 , ..., g|G| has a
value greater than V (CS 0 ) (this is checked in step 8 of Algorithm 4). On the other hand, having
V (CS 0 ) < V ({C1 , . . . , Ck }) + M AX[gk+1 ,...,g|G| ] implies that there could be a coalition structure
that starts with {C1 , · · · , Ck } and is better than the current best coalition. However, this still does
not necessarily imply that all of these coalition structures need to be examined. This is because,
when the algorithm moves to the next list, it may find that there are certain coalition structures that
are not better than the current best. Formally, for every coalition Cj : k < j < |G|, we can still have:
V (CS 0 ) > V ({C1 , ..., Cj }) + M AX[gj+1 ,...,g|G| ] . Figure 7 illustrates how this branch-and-bound
technique is applied while searching a sub-space.

Figure 7: Applying branch-and-bound while searching through the coalition structures in a subspace.

547

R AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGS

5. Performance Evaluation
In this section, we empirically evaluate the IP algorithm, and benchmark it against the state of the
art in the literature. Since IP’s ability to prune the space depends on the closeness of the upper and
lower bounds to the actual optimal value, and since this closeness is determined by the spread of the
distribution of the coalition values, it is crucial that IP is tested against different value distributions.
Moreover, we aim to evaluate the ability of our algorithm to generate solutions anytime and to zoom
in on very high quality solutions rapidly.
In what follows, we first discuss the validity and properties of the different value distributions
that we use to test the algorithm (Section 5.1). Then, we benchmark our algorithm against the fastest
available algorithm in the literature (i.e. IDP) using the aforementioned distributions (Section 5.2).
Finally, we empirically evaluate the efficiency and effectiveness of our algorithm in generating
solutions anytime (Section 5.3).
5.1 Benchmarking
The common practice in benchmarking search heuristics is to choose some standard instances of
the problem and compare the various algorithms that exist without giving them a priori knowledge
of the type of input they are presented with. The standard instances for the coalition structure
generation problems have been defined and used by Larson and Sandholm (2000) namely:20
1. Normal: v(C) ∼ |C| × N (µ, σ 2 ) where µ = 1 and σ = 0.1.
2. Uniform: v(C) ∼ |C| × U (a, b) where a = 0 and b = 1.
While we use the above distributions to benchmark our algorithm, we also question the validity of
these distributions. This is because, in our previous work (Rahwan et al., 2007b), we noted that the
normal and uniform distributions tend to generate solutions with small numbers of coalitions. However, we now show that, if the coalition values are picked from the Normal or Uniform distributions
(scaled by the size of the coalition), then the resulting distribution of the coalition structure values
is biased (see Theorem 5). Given this, experiments defined according to the Normal and Uniform
distributions could favour some algorithms over others.
Theorem 5. If the coalition values were taken from a normal distribution as follows: ∀C ⊆
A, v(C) ∼ |C| × N (µ, σ 2 ), or if they were taken from a uniform distribution as follows: ∀C ⊆
A, v(C) ∼ |C| × U (a, b), then, given any coalition structure CS 0 : |CS 0 | > 1, there exists another
coalition structure CS 00 : |CS 00 | < |CS 0 | such that:


P V (CS 00 ) = V (CS ∗ ) > P V (CS 0 ) = V (CS ∗ )
That is, the probability of CS 00 being an optimal coalition structure is greater than that of CS 0 .
Proof. See Appendix F.
20. Their sub and super-additive distributions are also studied in the literature, but in such cases it is usually known a
priori that the distribution of coalition values is actually of these types (in which case it is known a priori what the
optimal coalition structure is). Moreover, previous results on these distributions have not produced very interesting
insights (Rahwan et al., 2007b) and so we do not experiment with these.

548

A N A NYTIME A LGORITHM FOR O PTIMAL C OALITION S TRUCTURE G ENERATION

To remedy this, we propose a new input distribution that is tailored specifically to the CSG problem. This distribution, which we define as NDCS (Normally Distributed Coalition Structures), is
constructed by generating coalition values in the following way:
NDCS: v(C) ∼ N (µ, σ 2 ), where µ = |C| and σ =

p
|C|.

In this case, it turns out that the value of every possible coalition structure is independently
drawn from the same normal distribution which leads us to the following theorem:
p
Theorem 6. Iff we have: ∀C ⊆ A, v(C) ∼ N (µ, σ 2 ), where µ = |C| and σ = |C|, then the
following holds:
∀CS ∈ P, V (CS) ∼ N (|A| , |A|)
Proof. See Appendix G.
Since the NDCS distribution ensures that every coalition structure value is drawn from the same
distribution, it ensures that the search space is not biased. Thus, the efficiency of search algorithms
in finding the optimal coalition structure is more strongly tested than in the other cases.
Using the above input distributions, we benchmark our algorithm against the other state-of-theart algorithm, namely IDP (see Section 2). Note that we do not experiment with the other anytime
algorithms since they need to search the whole space to find the optimal value and this is generally
not feasible within reasonable time, even for small numbers of agents. Also, it was shown by
Rahwan et al. (2007b) that industrial strength software such as CPLEX cannot handle inputs of
more than 18 agents since it runs out of memory and therefore we do not run experiments with it
here. On all our graphs we plot the 95% confidence interval at every point (given 800 runs for 15 to
20 agents and 100 runs for 21 to 25 agents).21
5.2 Experiment 1: Optimality
In this experiment, we compare the algorithms’ performances given different numbers of agents
(from 15 to 27). The time to find the optimal coalition structure is measured in terms of clock time
(in milliseconds) on an Intel 2.6GHz Quad Core PC with 3Gigabytes of RAM. The algorithms are
coded using JAVA 1.6. The running times are plotted on a log scale in Figure 8.22 We note as IP-X
the application of IP to distribution X, where X can be NDCS, Normal, or Uniform (as described
above). As can be seen, IP finds the optimal coalition structure significantly faster than IDP for all
distributions. In the best case (Uniform for 27 agents) IP is 570 times better than IDP (i.e. it takes
0.175% of the time taken by IDP) and in the worst case (NDCS for 16 agents) it is 1.7 times faster
than IDP. It can also be seen that the performance of IP is the slowest given the NDCS distribution
(compared to IP-Normal and IP-Uniform). To determine the cause for this, we first discuss the two
main problems that can affect the performance of IP:
21. By plotting the 95% confidence interval, we aim to check statistical significance of the difference between the means
taken at each point across different series. Thus, if two points from two different series have overlapping confidence
intervals, it is equivalent to saying that the null hypothesis is validated (i.e. the means are not significantly different)
for a t-test with α = 0.05. If the confidence intervals do not overlap, then the means are significantly different.
22. The running time for IDP is deterministic since it runs in O(3n ). Hence, we recorded its running time for up to 25
agents and extrapolated the results to 27 agents.

549

R AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGS

Figure 8: Time to find the optimal solution for IDP, IP applied to NDCS, Normal, and Uniform
distributions.

1. Pruning sub-spaces: the higher the upper bounds of sub-spaces and the lower the value of the
optimal coalition structure, the harder it is to prune sub-spaces. This can be deduced from
the pruning function we use in Algorithm 2. Moreover, the bigger the sub-spaces with higher
upper bounds, the longer the algorithm will take to find the optimal solution. This is because
the algorithm always has to search the sub-space with the highest upper bound to check that
the solution it has found is optimal.
2. Branch-and-bound: the higher the upper bounds of sub-spaces and the lower the optimal
coalition structure value, the harder it is to prune with branch-and-bound. This can be deduced
from the pruning applied in step 8 of Algorithm 4. This is because, when applying branchand-bound within a sub-space P{g1 ,g2 ,...,gn } , the current best solution CS 0 is compared against
the sum of coalition values and the maximum value of coalitions of the remaining coalition
sizes as follows:
if V (CS 0 ) >

X
C∈{Lg1 ,··· ,Lgk }

v(C)+

X

maxg then move to next coalition structure

g∈{gk+1 ,··· ,gn }

Now, if the best solution is very low compared to the upper bound, that is:
X
V (CS 0 ) << U BG =
maxg
g∈{g1 ,··· ,gn }

then, branch-and-bound has to be applied deeper (i.e. increasing variable k in the condition
above) in the sub-space in order to make sure that the coalition structure being evaluated is
not optimal. Hence, in the worst case it would have to search the whole sub-space (i.e. apply
step 9 in Algorithm 4 on increasing values of k up to n).
550

A N A NYTIME A LGORITHM FOR O PTIMAL C OALITION S TRUCTURE G ENERATION

In order to see how these different issues affect the performance of our algorithm with respect to
different distributions, we recorded the value of the optimal coalition structure and the upper bounds
of all the sub-spaces (given 21 agents) and averaged them over 20 runs.23 We also exactly recorded
the size of each sub-space (i.e. in the number of coalition structures per sub-space). The results are
plotted in Figure 9. We note the following for each distribution:

Figure 9: Top: upper bounds and optimal coalition structure value, bottom: size of sub-spaces.
Note that the values in the bottom graph are plotted on a log scale. Points with the
same abscissa on the two graphs correspond to the same sub-space. The arrows show the
direction of the search for each distribution.

• NDCS: The biggest sub-spaces are the ones with the highest upper bounds. Hence, it is
much harder to prune large portions of the search space. Moreover, the average optimal
23. The values of the upper bounds and the average optimal coalition structure were rounded and scaled to ease the
explanation and to have a clearer plot.

551

R AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGS

coalition structure value is relatively low compared to the upper bounds of the bigger subspaces. Hence, applying branch-and-bound in this distribution is very hard.
• Normal: The smaller sub-spaces are the ones with the highest upper bounds. Hence, pruning
large portions of the space can easily be done by searching smaller sub-spaces in which good
solutions are. Moreover, the value of the optimal coalition structure tends to be higher than
the upper bounds of most large sub-spaces, and relatively close to the highest upper bounds.
Hence, it is easier for branch-and-bound to prune large portions of the sub-spaces.
• Uniform: The upper bounds of most sub-spaces are relatively high compared to those of other
distributions (i.e. they are close to the highest upper bound). In fact, the upper bounds are
actually nearly equal to the average optimal solution and this allows the algorithm to prune
most of the sub-spaces as soon as it has found an optimal solution, and this happens almost
immediately after scanning the input.
Finally, note that Figure 9 shows the portion of the space that will be avoided given the selection
strategy described earlier in Section 4.2. In more detail, recall that this strategy is guaranteed to
avoid searching the sub-spaces that have an upper bound lower that V (CS ∗ ). As can be seen from
the figure, many of the sub-spaces (in the case of NDCS and Uniform distributions) have an upper
bound lower than V (CS ∗ ), although most of these sub-spaces are relatively small. Moreover, in the
case of the Normal distribution, almost all the sub-spaces have an upper bound lower than V (CS ∗ ),
most of which are among the largest ones!
Having studied the performance of IP in terms of completion time, we next focus on studying
its ability to generate solutions anytime.
5.3 Experiment 2: Anytime Quality
In this experiment, we further evaluate the anytime property of our algorithm, and that is by recording the value of the solutions that were generated before returning the guaranteed optimal one. In
particular, we recorded two indicative measures of the quality of the solutions. First, we computed
the ratio between the value of the current best solution and the optimal solution (obtained at the end
(CS 0 )
of the run). This ratio is noted as ropt = VV (CS
∗ ) . This measure shows how effective the algorithm
is at zooming on good solutions. Second, we recorded the ratio rbound between the value of the cur0)
rent best solution and the upper bound on the optimal value (i.e. rbound = V U(CS
B ∗ ). This measure
is the theoretical guarantee that the algorithm places on the quality of the solution (see Section 4.1).
Ideally, the algorithm should be able to minimise the difference between ropt and rbound in minimal
time.
The results are plotted in Figure 10 for the distributions: NDCS, Normal, and Uniform.24 We
discuss the results for each of the distributions in turn.
• NDCS: As can be seen, the algorithm very high quality guarantees (i.e. rbound > 90%) in
less than half of the time required to find the optimal solution. It also produces a very high
quality solutions (i.e. ropt > 90%) within less than 10% of the time required to terminate.
24. The points plotted are averages computed over 500 runs for 19 agents and 22 agents, and 100 runs for 25 agents. The
error bars depict the 95% confidence interval for each of the intervals over which results are recorded.

552

A N A NYTIME A LGORITHM FOR O PTIMAL C OALITION S TRUCTURE G ENERATION

Figure 10: Quality (ropt ) and bound (rbound ) for the generated solution. In all cases, the x-axis
represents the time (in milliseconds) and the y-axis represents the ratio of the solution
to the optimal.
553

R AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGS

• Normal: In this case, our algorithm is able to come up with guaranteed high quality solutions
much faster than for the NDCS distribution. Moreover, in this case, very high quality solutions
(i.e. ropt > 90%) can be guaranteed (i.e. rbound > 90%) in less than 10% of the time to
find the optimal value. This results from the fact that the upper bounds are not as far from the
optimal value as in the NDCS case.
• Uniform: As expected from earlier results presented in Section 5.2, the algorithm generates
very high quality solutions (i.e. ropt ≈ 100%) faster than for the other distributions (shortly
after scanning the input). Moreover, the solutions can be guaranteed to be near-optimal (i.e.
rbound > 99%) within 15% of the time to find the optimal.
Next, we compare the worst-case guarantees that are provided by IP with those provided by Sandholm et al.’s (1999) and Dang and Jennings’s (2004) algorithms (see Figure 11). As can be seen,
our algorithm significantly outperforms both Dang and Jennings’s and Sandholm et al.’s for all distributions. In particular, after scanning the input, IP is able to guarantee that its solution is nearly
40% (in the worst case) of the optimal compared to below 10% for the other algorithms. Moreover,
our guarantee usually reaches 100% after searching minute portions of the search space (on average
around 0.0000019% for the hardest distribution), while the guarantees provided by other algorithms
do not go beyond 50% until the whole space has been searched. Also note that we generate very
high quality solutions (i.e. > 90%) by searching even smaller portions of the of the search space
(on average around 0.0000002% for the hardest distribution). Thus, in actual computational time,
for 25 agents for example, we are able to return a solution that is guaranteed to be higher than 90%
of the optimal in around 250 seconds in the worst case and 300 milliseconds in the best case.

6. Conclusions and Future Work
Coalition formation, the process by which a group of software agents come together and agree to
coordinate and cooperate in the performance of a set of tasks, is an important form of interaction in
multi-agent systems. Such coalitions can improve the performance of the individual agents and/or
the system as a whole, especially when tasks cannot be performed by a single agent, or when a group
of agents performs the tasks more efficiently. One of the most challenging problems that arise in
the coalition formation process is that of coalition structure generation, which involves partitioning
the set of agents into exhaustive and disjoint coalitions such that the social welfare is maximized.
In this paper, we have developed and evaluated an anytime integer-partition based algorithm (called
IP) that finds optimal solutions much faster than any previous algorithm designed for this purpose.
The strength of our approach is founded upon two main components:
• We use a novel representation of the search space which partitions it into smaller, disjoint
sub-spaces that can be explored independently to find optimal solutions. This representation,
which is based on the integer partitions of the number of agents involved, allows the agents
to balance the trade-offs between their preferences for certain coalition sizes against the computation required to find the solution. Moreover, such trade-offs can be made in an informed
manner since we can compute bounds on sub-spaces of the search space. These bounds allow us to prune the search space and guarantee the quality of the solution found during the
search. They may also, depending on the distribution of the input values, allow us to obtain
the optimal solution almost immediately after scanning the input.
554

A N A NYTIME A LGORITHM FOR O PTIMAL C OALITION S TRUCTURE G ENERATION

Figure 11: Worst case bounds generated by IP using the Normal and NDCS distributions compared
to Sandholm et al.’s (1999) and Dang and Jennings’s (2004) algorithms for 25 agents.
The results for the Uniform distribution are trivial since IP on average finds the optimal
almost immediately after scanning the input. Note that error bars have been omitted
from the IP results for reasons of clarity.

555

R AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGS

• We devise a technique that allows us to cycle through the coalition structures within a given
sub-space. Unlike a naı̈ve cyclation technique that generates combinations of coalitions, and
verifies whether each of these combinations is a valid coalition structure, our cyclation technique only generates valid ones (thus, avoiding the search through the space of possible combinations of coalitions, which is exponentially larger than the space of coalition structures).
In addition, the cyclation technique does not perform any redundant operations since it avoids
generating the same coalition structure more than once. Finally, by applying a branch-andbound technique, we are able to identify the coalition structures that cannot improve on the
quality of the solution found so far, and thus, avoid generating them.
Altogether, these components allow us to make significant performance gains over other existing
approaches. In more detail, the experiments show that IP avoids searching most of the search space,
and therefore, requires significantly less time, compared to the other algorithms, in order to return
an optimal solution. For example, IP outperforms IDP by orders of magnitude (0.175% of the
time taken by IDP for 27 agents in the best case). Moreover, if IP is interrupted before an optimal
value is found, it can still return solutions that are very close to the optimal (usually above 95% of
the optimal), with very high worst-case guarantees on them (usually above 90%). These solutions
are always better (above 40% of the optimal right after scanning the input) than those returned by
Sandholm et al.’s (1999) and Dang and Jennings’s (2004) algorithms (i.e. less than 10% of the
optimal). These algorithms also have to search a large portion of the search space before being
able to get better guarantees while our algorithm is able to prune and find near-optimal solutions
relatively quickly (above 90% of the optimal within 10% of the time to find the optimal solution for
25 agents).
A number of important extensions to IP could be envisaged. For example, we have recently
combined the IDP algorithm with IP (IP-IDP) (Rahwan & Jennings, 2008a) and will explore other
approaches including linear programming techniques to improve the bounds used in IP. However,
these extensions have to deal with an exponential input (i.e. 2n memory locations at least for n
agents) as we do in IP. Therefore, it is important to develop techniques that will extend our approach in order to minimise cycling through all coalition values as the number of agents increases.
This will require adapting our cyclation technique and the bound computation. Hence, in future
work, we will need to devise representations for sub-spaces that allow us to cycle more intelligently
over larger inputs and develop new techniques to compute bounds to be used by our branch-andbound algorithm. In trying to adapt our approach to other problems, we also aim to determine the
degree to which IP can be used to solve other common incomplete set partitioning problems which
occur in combinatorial auctions (Rothkopf et al., 1995) or crew scheduling (Hoffman & Padberg,
1993). Finally, we aim to see whether the patterns that we exploit in our algorithm also arise in
other combinatorial optimisation problems that have been studied in the area of combinatorics (e.g.,
Kreher & Stinson, 1998; Papadimitriou & Steiglitz, 1998).

7. Acknowledgments
The research in this paper was undertaken as part of the ALADDIN (Autonomous Learning Agents
for Decentralised Data and Information Systems) project and is jointly funded by a BAE Systems
and EPSRC (Engineering and Physical Research Council) strategic partnership (EP/C548051/1).
Andrea Giovannucci was funded by the Juan de la Cierva programme (JCI-2008-03006) and the
EU funded Synthetic Forager project (ICT-217148-SF). We also wish to thank Professor Tuomas
556

A N A NYTIME A LGORITHM FOR O PTIMAL C OALITION S TRUCTURE G ENERATION

Sandholm for his comments, as well as the anonymous reviewers for their valuable comments on
previous versions of the paper. We are also very grateful to Dr. Viet Dung Dang for his contributions
to earlier versions of the paper. Finally, we wish to thank to Dr. W. T. Luke Teacy for his help with
some of the proofs and the anonymous reviewers for their very constructive comments.

557

R AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGS

Appendix A. Summary of Notation

A
ai
n
C
|C|
v(C)
CS
V (CS)
CS ∗
U B∗
LB ∗
CS 0
β
β∗
LCsi
Ls
v(Ls )
maxs
mins
avgs
P
Pi
LVi
G
G(s)
E(G)
G
G2
TG
PG
M AXG
M ING
AV GG
F
−→
CS
Mk
Ak
Csn
P (x)
IDP
N (µ, σ 2 )
U (a, b)
ropt
rbound

The set of agents.
An agent in A.
The number of agents in A.
A coalition.
The cardinality of C.
The value of C.
A coalition structure.
The value of CS.
An optimal coalition structure.
The upper bound on V (CS ∗ ).
The lower bound on V (CS ∗ ).
The best coalition structure found so far.
The bound on the quality of the best solution found so far.
The bound within which any solution is acceptable.
The list of possible combinations of size s taken from the set {1, 2, . . . , i}.
The list of coalitions of size s ordered lexicographically.
A list containing the values of all the coalitions in Ls .
The maximum value of the coalitions in Ls .
The minimum value of the coalitions in Ls .
The average value of the coalitions in Ls .
The set of possible coalition structures.
The ith level in our representation of the space of possible coalition structures.
The ith level of the coalition structure graph.
An integer partition of n.
The multiplicity of s in G.
The underlying set of G.
The set of possible integer partitions of n.
The set of possible integer partitions of n that contain two parts each.
The Cartesian product of the lists Ls : s ∈ G.
The sub-space (in our space representation) that corresponds to G (i.e. the pre-image of G under F ).
The maximum value of the elements in TG .
The minimum value of the elements in TG .
The average value of the elements in TG .
A function that maps a coalition structure CS to an integer partition G such that: ∀C ∈ CS, ∃g ∈ G : |C| = g.
A variable used to cycle through the coalition structures in PG .
A variable used to cycle through a list of combinations of size gk .
An ordered set containing the agents that are not members of C1 , . . . , Ck−1 .
The binomial coefficient (i.e. the number of possible combinations of size s taken from n elements).
The probability of x.
The improved dynamic programming algorithm.
Normal distribution with mean µ and variance σ 2 .
Continuous Uniform distribution on the interval [a, b].
The ratio between the value of the current best solution and the value of the optimal solution.
The ratio between the value of the current best solution and the upper bound on the value of the optimal
solution.

558

A N A NYTIME A LGORITHM FOR O PTIMAL C OALITION S TRUCTURE G ENERATION

Appendix B. Proof of Theorem 1.
Let Ḡ = [g1 , g2 , . . . , g|G| ] contain the 
elements of G with
 a natural ordering on them, and let PḠ
return all ordered coalition structures C1 , C2 , . . . , C|G| : Ci ∈ Lgi , where the order of the coalitions within the coalition structure is taken into consideration. For example, given n = 4 and G =
[1, 1, 2], we have two ordered coalition structures: h{a1 }, {a2 }, {a3 , a4 }i and h{a2 }, {a1 }, {a3 , a4 }i
in PḠ that correspond to one coalition structure: {{a1 }, {a2 }, {a3 , a4 }} in PG . Now, since the number of repetitions of each coalition structure in PḠ is the same25 (e.g., in the above example with
Ḡ = [1, 1, 2], all coalition structures in PG will appear twice in PḠ ), then we have:
AV GG = AV GḠ

(3)

where AV GḠ is the average value of the coalition structures in PḠ . Now, if we define Nn (g1 , g2 , . . . , g|G| )
as the number of ordered coalition structures in PḠ , then we have:
AV GḠ =

X
1
V (CS)
Nn (g1 , g2 , . . . , g|G| )
CS∈PḠ

=

X
1
Nn (g1 , g2 , . . . , g|G| )

X

v(C)

CS∈PḠ C∈CS

Moreover, for every coalition C ∈ Lgi , there are: Nn−gi (g1 , g2 , . . . , gi−1 , gi+1 , . . . , g|G| ) ordered
coalition structures where C happens to be the ith coalition. Based on this, we have:
Nn (g1 , g2 , . . . , g|G| ) = |Lgi | × Nn−gi (g1 , . . . , gi−1 , gi+1 , . . . , g|G| )

(4)

Similarly, the number of times that v(C) occurs in the ith position of the sum of all coalition values
in PḠ is Nn−gi (g1 , . . . , gi−1 , gi+1 , . . . , g|G| ). Given this, we next compute AV GḠ as follows:

AV GḠ =

|G|
X
X
1
Nn−gi (g1 , . . . , gi−1 , gi+1 , . . . , g|G| ) × v(C)
Nn (g1 , g2 , . . . , g|G| )
i=1 C∈Lgi

|G|

=

X X Nn−gi (g1 , . . . , gi−1 , gi+1 , . . . , g|G| )
× v(C)
Nn (g1 , g2 , . . . , g|G| )
i=1 C∈Lgi

|G|
X
X

1
× v(C) (following equation (4))
|Lgi |
i=1 C∈Lgi


|G|
X
X
 1
=
× v(C)
|Lgi |
=

i=1

=

|G|
X

C∈Lgi

avggi

i=1

25. Specifically, a coalition structure is repeated x! times if it contains x coalitions of the same size.

559

R AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGS

Based on this, as well as (3), we find that:
AV GG =

|G|
X

avggi

i=1



Appendix C. Proof of Theorem 2.
Generally speaking, given a set B ⊆ A, the number of possible combinations of size s out of
|A|−|B|
the set B̄ = A\B is equal to Cs
. Based on this, for every coalition C of size g1 , there are
n−g1
Cg2
coalitions of size g2 that do not overlap with it. Similarly, for every i disjoint coalitions
n−(g +g +...+gi )
(C1 , C2 , . . . , Ci ) of sizes g1 , g2 , . . . , gi respectively, there are Cgi+1 1 2
coalitions of size
gi+1 that do not overlap with the union C1 ∪ C2 ∪ . . . ∪ Ci .
Based on this, if TG is the cartesian product of the lists Lgi : gi ∈ G, and T̂G is a subset of TG
that contains only the elements (i.e. the combinations of coalitions) in which no coalitions overlap,
then the number of elements in T̂G can be computed as follows:
 
n−(g1 +...+g|G|−1 )
 
1
× . . . × Cg|G|
(5)
T̂G  = Cgn1 × Cgn−g
2
Moreover, note that any combination of coalitions {C1 , C2 , . . . , C|G| }, such that ∀i ∈ {1, 2, . . . , |G|} :
|Ci | = gi , appears exactly once in PG (since it is considered a unique coalition structure) but could
appear more than once in T̂G (since the ordering of the coalitions matters in the elements of T̂G ). In
particular, if gi appears x times in G, then every coalition structure in PG corresponds to x! elements
in T̂G , where the coalitions of size gi are ordered differently in each of these elements. For example,
given G = [1, 2, 2, 2, 5], size 2 appears 3 times in G and this means that every coalition structure
{C1 , C2 , C3 , C4 , C5 } ∈ PG corresponds to 3! elements in T̂G (since 3! is the number of possible
permutations of C2 , C3 , C4 ). This can be generalized as follows:
 
 
T̂G 
∀G = [g1 , g2 , . . . , g|G| ] ∈ G, |PG | =
(6)
G(g1 )! × G(g2 )! × . . . × G(g|G| )!
where G(gi ) denotes the multiplicity of gi in G. Then, from (5) and (6), we find that:
n−(g1 +...+g|G|−1 )

1
Cgn1 × Cgn−g
× . . . × Cg|G|
2
Q
|PG | =
s∈E(G) G(s)!

where E(G) is the underlying set of G.


Appendix D. Proof of Theorem 3.
Given an integer partition G = [g1 , . . . , g|G| ] ∈ G, we need to prove that all the coalition structures
in PG are generated by MCP. Without loss of generality, we will assume that the parts in G are in
560

A N A NYTIME A LGORITHM FOR O PTIMAL C OALITION S TRUCTURE G ENERATION

increasing order. That is:
g1 ≤ g2 ≤ . . . ≤ g|G|

(7)

Now, the way MCP works is by generating ordered sets of coalitions such that, for every ordered set,
the first coalition belongs to Lg1 and the second belongs to Lg2 and so on. Moreover, the way these
ordered sets are generated ensures that the coalitions in each of the ordered sets do not overlap. In
other words, MCP generates a subset of TG , denoted T̂G , which is defined as follows:26
T̂G =





	
C1 , ..., C|G| | ∀i ∈ {1, ..., |G|}, Ci ⊆ A and |Ci | = gi and ∀j ∈ {1, ..., |G|} : j 6= i, Ci ∩ Cj = ∅

Then, given a coalition structure CS ∈ PG , let T̂GCS be a subset of T̂G containing all the ordered
sets that correspond to CS. That is:
CS
T̂G
=

E
o
nD
C1 , ..., C|G| | ∀i ∈ {1, ..., |G|}, Ci ∈ CS and |Ci | = gi and ∀j ∈ {1, ..., |G|} : j 6= i, Ci ∩ Cj = ∅

(8)
{{a },{a2 },{a3 ,a4 }}

1
For example, T̂[1,1,2]

= {h{a1 }, {a2 }, {a3 , a4 }i , h{a2 }, {a1 }, {a3 , a4 }i}. Next, given



any coalition structure CS ∈ PG , we will prove that |T̂GCS | ≥ 1. To this end, let C1 , C2 , . . . , C|G|
be an ordering on the coalitions that belong to CS. Then, from (7) and (8), we can see that:






C1 , C2 , . . . , C|G| ∈ T̂GCS iff |C1 | ≤ |C2 | ≤ . . . ≤ C|G| 

(9)



Now since there is at least one way of ordering the coalitions in CS such that |C1 | ≤ ... ≤ C|G| ,
then there is at least one ordered set in T̂GCS . In other words, |T̂GCS | ≥ 1. This, in turn, implies that
every coalition structure in PG is generated by MCP.


Appendix E. Proof of Theorem 4.
Given an integer partition G = [g1 , . . . , g|G| ] ∈ G, let TeG be the set of ordered sets that are generated
by FCP. Moreover, given a coalition structure CS ∈ PG , let TeGCS be a subset of TeG containing all
the ordered sets that correspond to CS. That is:
n

o

TeGCS = C1 , C2 , . . . , C|G| ∈ TeG | ∀i ∈ {1, 2, . . . , |G|}, Ci ∈ CS
Next, we will prove that |TeGCS | = 1. We define T̂G and T̂GCS as in Appendix D. We also assume,
without loss of generality, that the order in (7) holds. Note that, if G(gi ) = 1 ∀i ∈ {1, . . . , |G|},
then there is no difference between the way FCP works and the way MCP works.27 On the other
hand, if there exists i ∈ {1, ..., |G|} such that G(gi ) > 1, then the only difference between FCP and
MCP is that FCP avoids some of the coalition structures that are generated by MCP. This implies
26. Recall that TG is the cartesian product of the lists: Ls : s ∈ G.
27. Recall that G(gi ) is the multiplicity of gi in G.

561

R AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGS

that:

if G(gi ) = 1 ∀i ∈ {1, . . . , |G|} then TeG = T̂G and ∀CS ∈ PG , TeGCS = T̂GCS
else TeG ⊆ T̂G and ∀CS ∈ PG , TeGCS ⊆ T̂GCS

(10)
(11)




Now, given a coalition structure CS ∈ PG , let C1 , C2 , . . . , C|G| be defined as in Appendix D (i.e.
it is an ordering on the coalitions that belong to CS). Then, from (9), we find that the number of
ordered sets in T̂GCS is equal
 to the
 number of possible ways of ordering the coalitions in CS such

that: |C1 | ≤ |C2 | ≤ ... ≤ C|G| . Based on this, as well as (10) and (11), we distinguish between
two cases:

• If G(gi ) = 1 ∀i ∈ {1, ..., |G|}, then there
 would
 only be one possible way of ordering the

coalitions in CS such that |C1 | ≤ ... ≤ C|G|  (because every coalition in CS has a unique
size). This implies that |T̂GCS | = 1, and from (10), we find that |TeGCS | = 1.
• If ∃i ∈ {1, ..., |G|} : G(gi ) > 1, thenthere would be multiple ways of ordering the coalitions
in CS such that |C1 | ≤ ... ≤ C|G| , which implies that |T̂GCS | > 1. However, from (11),
we know that TeGCS is a subset of T̂GCS . Then, by proving that TeGCS contains exactly one of
the ordered sets in T̂GCS , we prove that |TeGCS | = 1. To be more precise, in case we have:
|Cx | = |Cx+1 | = ... = |Cx+y |, then every possible permutation of those coalitions will be
generated by MCP, and we need to prove that only one of them will be generated by FCP.
Based on this, if we denote by ck the smallest28 agent in Ck , then it is sufficient to prove that
FCP only generates the one permutation that satisfies: cx < cx+1 < ... < cx+y . Note that the
agents in Ak are ordered such that Ak,1 < Ak,2 < · · · < Ak,|Ak | . Based on this, if ck = Ak,i ,
then there are i − 1 agents in Ak that are smaller than ck , and since Ak+1 = Ak \Ck , then
there are i − 1 agents in Ak+1 that are smaller than ck . Therefore, to ensure that ck < ck+1 , it
is sufficient to generate Ck+1 such that it does not contain the first (i.e. smallest) i − 1 agents
of Ak+1 . For example, given Ak = ha1 , a4 , a5 , a7 , a8 , a9 i and Mk = {3, 5}, we would have
Ck = {a5 , a8 } and ck = Ak,3 . This implies that Ak+1 contains two agents that are smaller
than ck (namely, agents a1 and a4 ). Therefore, to ensure that ck < ck+1 , it is sufficient to
generate Ck+1 such that it does not contain the first (i.e. smallest) two agents in Ak+1 . This
can be done by ensuring that Mk+1 does not contain elements 1 or 2. In other words, it can
be done by ensuring that Mk+1,1 ≥ Mk,1 , which is a direct result of the way FCP is modified.
By proving that |TeGCS | = 1 for all CS ∈ PG , we prove that FCP generates every coalition structure
in PG exactly once.

28. Recall that, for any two agents ai , aj ∈ A, we say that ai is smaller than aj if and only if i < j. This comes from
the assumed ordering over the set of agents (see Section 2 for more detail).

562

A N A NYTIME A LGORITHM FOR O PTIMAL C OALITION S TRUCTURE G ENERATION

Appendix F. Proof of Theorem 5
We will first prove Theorem 5 for the normal distribution case (i.e. the case where ∀C ⊆ A, v(C) ∼
|C|×N (µ, σ 2 )). Specifically, we will show how the coalition structures that contain fewer coalitions
are more likely to be optimal. In order to prove this, we will first prove the following lemma which
deals with properties of the normal distribution.
Lemma 1. For any given value r ∈ R, and for any two random variables Xa ∼ N (µ, σa 2 ) and
Xb ∼ N (µ, σb 2 ) such that σa < σb , the following holds:
P (Xa > r) < P (Xb > r)

(12)

Proof. Given r ∈ R, let Φµ,σa2 (r) and Φµ,σ2 (r) be the cumulative distribution functions of
b
N (µ, σa 2 ) and N (µ, σb 2 ) respectively. That is,



1
r−µ
√
Φµ,σa2 (r) =
1 + erf
2
σa 2
1
Φµ,σ2 (r) =
b
2




r−µ
√
1 + erf
σb 2

RM
2
where erf(M ) = √2π 0 e−t is the error function. Then, in order to prove that the inequality in
(12) holds, it is sufficient to prove that:
Φµ,σa2 (r) > Φµ,σ2 (r)

(13)

b

To this end, given that σa < σb , the following holds, where abs(M ) is the absolute value of M :




r−µ
r−µ
√
√
abs
> abs
σa 2
σb 2
This, in turn, implies that:

erf

r−µ
√
σa 2




> erf

r−µ
√
σb 2



Based on this, as well as the fact that erf(M ) ≥ 0, we deduce that (13) holds.

Based on the above lemma, and given a coalition structure CS 0 : |CS 0 | > 1, we will prove that
there exists another coalition structure CS 00 : |CS 00 | < |CS 0 | such that:


P V (CS 00 ) = V (CS ∗ ) > P V (CS 0 ) = V (CS ∗ )
In more detail, let CS 0 = {Cx1 , · · · , Cxα , Cy1 , · · · , Cyβ } and CS 00 = {Cx , Cy1 , · · · , Cyβ } such
that Cx = Cx1 ∪ · · · ∪ Cxα . Then, based on the properties of the normal distribution, we have:


v(Cx ) ∼ N |Cx | × µ, |Cx |2 × σ 2
(14)
563

R AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGS

and:


(15)
v(Cx1 ) + · · · + v(Cxα ) ∼ N (|Cx1 | + · · · + |Cxα |) × µ, (|Cx1 |2 + · · · + |Cxα |2 ) × σ 2
2 denote the mean and variance of the distriNow, given a coalition structure CS, let µCS and σCS
bution of V (CS). Then, based on (14) and (15), we have:

X

µCS 00 = (|Cx | × µ) +

(|C| × µ)

C∈CS 00 \{Cx }

X

2
2
2
σCS
00 = (|Cx | × σ ) +

(|C| × σ)2

C∈CS 00 \{Cx }

and we have:
X

µCS 0 = ((|Cx1 | + · · · + |Cxα |) × µ) +

C∈CS 0 \{C



2
σCS
(|Cx1 |2 + · · · + |Cxα |2 ) × σ 2 +
0 =

(|C| × µ)

x1 ,··· ,Cxα }

X

(|C| × σ)2

C∈CS 0 \{Cx1 ,··· ,Cxα }

Since |Cx | = |Cx1 | + · · · + |Cxα |, and since CS 00 \ {Cx } = CS 0 \ {Cx1 , · · · , Cxα }, we can see that
the distribution of V (CS 00 ) and V (CS 0 ) only differ by the way their variances differ. Note that:
|Cx |2 = (|Cx1 | + · · · + |Cxα |)2 > |Cx1 |2 + · · · + |Cxα |2
2
2
This implies that σCS
0 < σCS 00 . Therefore, based on Lemma 1, we find that for any value r ∈ R:

P (V (CS 0 ) > r) < P (V (CS 00 ) > r)
In other words, it is more likely for CS 00 to have a value greater than r, which implies that it is more
likely for CS 00 to be the optimal coalition structure.
Having proved Theorem 5 for the normal distribution case, we will now give the intuition behind the
proof for the uniform distribution case (i.e. the case where ∀C ⊆ A, v(C) ∼ |C|×U (a, b)). Specifically, assuming that CS 0 and CS 00 are defined as above, we would have v(Cx ) ∼ |Cx | × U (a, b)
and, for any coalition C ∈ {Cx1 , · · · , Cxα }, we would have v(C) ∼ |C| × U (a, b). Then, it is easy
to verify that P (v(Cx ) ≤ r) is less than P (v(Cx1 ) + · · · + v(Cxα ) ≤ r) for high values of r. The
intuition behind this difference in probabilities is that the sum of Uniformly distributed variables
(called a Uniform Sum distribution) results in a distribution giving lower probability to low and
high values, and higher probability to middle ranged values. Instead, for a uniformly distributed
variable, all values are equally probable. Therefore, given a Uniform Sum distribution and a Uniform distribution with the same minimum and maximum values, the Uniform distribution will give
a higher probability to higher values. Hence, the above proof holds for the Uniform distribution as
well.

564

Appendix G. Proof of Theorem 6.
Given the following:
∀C ⊆ A, v(C) ∼ N (|C| , |C|)

(16)

we need to prove that the value of every coalition structure is independently drawn from the same
normal distribution. Specifically, we will prove that the following holds:
∀CS ∈ P, V (CS) ∼ N (|A| , |A|)

(17)

From the properties of the normal distribution, we know that, for any two independent random
variables, x and y such that x ∼ N (µx , σx 2 ) and y ∼ N (µy , σy 2 ), we have:
(x + y) ∼ N (µx + µy , σx 2 + σy 2 )

(18)

Then, based on (16) and (18), any two coalition values, v(C1 ) and v(C2 ), satisfy the following
(since they are independent random variables):
(v(C1 ) + v(C2 )) ∼ N (|C1 | + |C2 | , |C1 | + |C2 |)
This implies that the following is true:
!
∀CS ∈ P,

X

v(C)

!
∼N

C∈CS

X

|C| ,

C∈CS

X

|C|

(19)

C∈CS

Finally, note that we assume the following:
∀CS ∈ P, V (CS) =

X

v(C)

(20)

C∈CS

∀CS ∈ P, ∀C, C 0 ∈ CS, C ∩ C 0 = ∅

(21)

Then, from (19), (20), and (21), we find that:
∀CS ∈ P, V (CS) ∼ N (|∪C∈CS | , |∪C∈CS |)
which implies that (17) holds since ∪C∈CS = A.


References
Andrews, G., & Eriksson, K. (2004). Integer Partitions. Cambridge University Press, Cambridge,
UK.
Dang, V. D., & Jennings, N. R. (2004). Generating coalition structures with finite bound from the optimal guarantees. In Proceedings of the Third International Joint Conference on Autonomous
Agents and Multi-Agent Systems (AAMAS-04), pp. 564–571.

R AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGS

Dang, V. D., Dash, R. K., Rogers, A., & Jennings, N. R. (2006). Overlapping coalition formation for
efficient data fusion in multi-sensor networks. In Proceedings of The Twenty First National
Conference on Artificial Intelligence (AAAI-06), pp. 635–640.
Evans, J., & Minieka, E. (1992). Optimization Algorithms for Networks and Graphs, 2nd edition.
Marcel Dekker, New York, USA.
Hillier, F. S., & Lieberman, G. J. (2005). Introduction to operations research. McGraw-Hill, New
York, USA.
Hoffman, K. L., & Padberg, M. (1993). Solving airline crew scheduling problems by branch-andcut. Management Science, 39(6), 657–682.
Horling, B., & Lesser, V. (2005). A survey of multi-agent organizational paradigms. The Knowledge
Engineering Review, 19(4), 281–316.
Jennings, N. R. (2001). An agent-based approach for building complex software systems. Communications of the ACM, 44(4), 35–41.
Kahan, J., & Rapoport, A. (1984). Theories of Coalition Formation. Lawrence Erlbaum Associates
Publishers, New Jersey, USA.
Klusch, M., & Shehory, O. (1996). A polynomial kernel-oriented coalition formation algorithm for
rational information agents. In Proceedings of Second International Conference on MultiAgent Systems (ICMAS-96), pp. 157–164.
Kreher, D. L., & Stinson, D. R. (1998). Combinatorial Algorithms: Generation, Enumeration, and
Search (Discrete Mathematics and its applications). CRC Press.
Larson, K., & Sandholm, T. (2000). Anytime coalition structure generation: an average case study.
Journal of Experimental and Theoretical Artificial Intelligence, 12(1), 23–42.
Li, C., & Sycara, K. P. (2002). Algorithm for combinatorial coalition formation and payoff division
in an electronic marketplace. In Proceedings of the First International Joint Conference on
Autonomous Agents and Multiagent Systems (AAMAS-02), pp. 120–127.
Norman, T. J., Preece, A. D., Chalmers, S., Jennings, N. R., Luck, M., Dang, V. D., Nguyen, T. D.,
V. Deora, J. S., Gray, W. A., & Fiddian, N. J. (2004). Agent-based formation of virtual
organisations. International Journal of Knowledge Based Systems, 17(2–4), 103–111.
Osborne, M. J., & Rubinstein, A. (1994). A Course in Game Theory. MIT Press, Cambridge MA,
USA.
Papadimitriou, C. H., & Steiglitz, K. (1998). Combinatorial Optimization: Algorithms and Complexity. Dover Publications.
Rahwan, T., & Jennings, N. R. (2007). An algorithm for distributing coalitional value calculations
among cooperative agents. Artificial Intelligence, 171(8–9), 535–567.
Rahwan, T., & Jennings, N. R. (2008a). Coalition structure generation: dynamic programming
meets anytime optimisation. In Proceedings of the Twenty Third Conference on Artificial
Intelligence (AAAI-08), pp. 156–161.
Rahwan, T., & Jennings, N. R. (2008b). An improved dynamic programming algorithm for coalition
structure generation. In Proceedings of the Seventh International Conference on Autonomous
Agents and Multi-Agent Systems (AAMAS-08), pp. 1417–1420.
566

A N A NYTIME A LGORITHM FOR O PTIMAL C OALITION S TRUCTURE G ENERATION

Rahwan, T., Ramchurn, S. D., Dang, V. D., & Jennings, N. R. (2007a). Near-optimal anytime
coalition structure generation. In Proceedings of the Twentieth International Joint Conference
on Artificial Intelligence (IJCAI-07), pp. 2365–2371.
Rahwan, T., Ramchurn, S. D., Giovannucci, A., Dang, V. D., & Jennings, N. R. (2007b). Anytime
optimal coalition structure generation. In Proceedings of the Twenty Second Conference on
Artificial Intelligence (AAAI-07), pp. 1184–1190.
Rothkopf, M. H., Pekec, A., & Harstad, R. M. (1995). Computationally manageable combinatorial
auctions. Management Science, 44(8), 1131–1147.
Sandholm, T. W., Larson, K., Andersson, M., Shehory, O., & Tohme, F. (1999). Coalition structure
generation with worst case guarantees. Artificial Intelligence, 111(1–2), 209–238.
Sandholm, T. W., & Lesser, V. R. (1997). Coalitions among computationally bounded agents. Artificial Intelligence, 94(1), 99–137.
Sen, S., & Dutta, P. (2000). Searching for optimal coalition structures. In Proceedings of the Sixth
International Conference on Multi-Agent Systems (ICMAS-00), pp. 286–292.
Shehory, O., & Kraus, S. (1995). Task allocation via coalition formation among autonomous agents.
In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence
(IJCAI-95), pp. 655–661.
Shehory, O., & Kraus, S. (1998). Methods for task allocation via agent coalition formation. Artificial
Intelligence, 101(1–2), 165–200.
Tsvetovat, M., Sycara, K. P., Chen, Y., & Ying, J. (2000). Customer coalitions in the electronic
marketplace. In Proceedings of the Fourth International Conference on Autonomous Agents
(AA-01), pp. 263–264.
Yeh, D. Y. (1986). A dynamic programming approach to the complete set partitioning problem. BIT
Numerical Mathematics, 26(4), 467–474.

567

Journal of Artificial Intelligence Research 34 (2009) 637-674

Submitted 07/08; published 04/09

Sentence Compression as Tree Transduction
Trevor Cohn

tcohn@inf.ed.ac.uk

Mirella Lapata

mlap@inf.ed.ac.uk

School of Informatics
University of Edinburgh
10 Crichton Street Edinburgh EH8 10AB, UK

Abstract
This paper presents a tree-to-tree transduction method for sentence compression. Our
model is based on synchronous tree substitution grammar, a formalism that allows local
distortion of the tree topology and can thus naturally capture structural mismatches. We
describe an algorithm for decoding in this framework and show how the model can be
trained discriminatively within a large margin framework. Experimental results on sentence
compression bring significant improvements over a state-of-the-art model.

1. Introduction
Recent years have witnessed increasing interest in text-to-text generation methods for many
natural language processing applications, ranging from text summarisation to question answering and machine translation. At the heart of these methods lies the ability to perform
rewriting operations. For instance, text simplification identifies which phrases or sentences
in a document will pose reading difficulty for a given user and substitutes them with simpler alternatives (Carroll, Minnen, Pearce, Canning, Devlin, & Tait, 1999; Chandrasekar &
Srinivas, 1996). In question answering, questions are often paraphrased in order to achieve
more flexible matching with potential answers (Lin & Pantel, 2001; Hermjakob, Echihabi,
& Marcu, 2002). Another example concerns reformulating written language so as to render
it more natural sounding for speech synthesis applications (Kaji, Okamoto, & Kurohashi,
2004).
Sentence compression is perhaps one of the most popular text-to-text rewriting methods.
The aim is to produce a summary of a single sentence that retains the most important
information while remaining grammatical (Jing, 2000). The appeal of sentence compression
lies in its potential for summarization and more generally for document compression, e.g., for
displaying text on small screens such as mobile phones or PDAs (Vandeghinste & Pan,
2004). Much of the current work in the literature focuses on a simplified formulation of the
compression task which does not allow any rewriting operations other than word deletion.
Given an input source sentence of words x = x1 , x2 , . . . , xn , a target compression y is formed
by removing any subset of these words (Knight & Marcu, 2002).
Despite being restricted to word deletion, the compression task remains challenging from
a modeling perspective. Figure 1 illustrates a source sentence and its target compression
taken from one of the compression corpora used in our experiments (see Section 5 for details).
In this case, a hypothetical compression system must apply a series of rewrite rules in order
c
2009
AI Access Foundation. All rights reserved.

Cohn & Lapata

S
S

S

S

S

S

S

VP
WHNP
RB

WP

exactly what

NP

VP
NP

NNS

WHNP

VBD PRP CC

records

WP

NP

WHNP

NP

VBN

WP

NNS

VBP

VBN

involved

what

records

are

involved

NNS VBP

made it and which ones are

VP
VP

(a) Source

VP

(b) Target

Figure 1: Example of sentence compression showing the source and target trees. The bold
source nodes show the terminals that need to be removed to produce the target
string.

WHNP
RB

S

WHNP

WP

WP

NP

S

NP
NP

VP
ε

ε
(1)

ε

(2)

(3)

S
S

VP

WHNP S

VP
VP

S
WHNP

CC

S
S

WHNP

S and

S
NP

VP

ε
(4)

(5)

Figure 2: Example transduction rules, each displayed as a pair of tree fragments. The left
(source) fragment is matched against a node in the source tree, and the matching
part is then replaced by the right (target) fragment. Dotted lines denote variable
correspondences, and  denotes node deletion.

to obtain the target, e.g., delete the leaf nodes exactly and and, delete the subtrees made it
and which ones, and merge the subtrees corresponding to records and are involved. More
concretely, the system must have access to rules like those shown in Figure 2. The rules
are displayed as a pair of tree fragments where the left fragment corresponds to the source
and the right to the target. For instance, rule (1) states that a wh-noun phrase (WHNP)
consisting of an adverb (RB) and a wh-pronoun (WP) (e.g., exactly what) can be rewritten
as just a wh-pronoun (without the adverb). There are two things to note here. First,
syntactic information plays an important role, since deletion decisions are not limited to
individual words but often span larger constituents. Secondly, there can be a large number
of compression rules of varying granularity and complexity (see rule (5) in Figure 2).
Previous solutions to the compression problem have been cast mostly in a supervised
learning setting (for unsupervised methods see Clarke & Lapata, 2008; Hori & Furui, 2004;
Turner & Charniak, 2005). Sentence compression is often modeled in a generative framework
638

Sentence Compression as Tree Transduction

where the aim is to estimate the joint probability P (x, y) of source sentence x having
the target compression y (Knight & Marcu, 2002; Turner & Charniak, 2005; Galley &
McKeown, 2007). These approaches essentially learn rewrite rules similar to those shown
in Figure 4 from a parsed parallel corpus and subsequently use them to find the best
compression from the set of all possible compressions for a given sentence. Other approaches
model compression discriminatively as subtree deletion (Riezler, King, Crouch, & Zaenen,
2003; Nguyen, Horiguchi, Shimazu, & Ho, 2004; McDonald, 2006).
Despite differences in formulation, existing models are specifically designed with sentence compression in mind and are not generally applicable to other tasks requiring more
complex rewrite operations such as substitutions, insertions, or reordering. A common
assumption underlying previous work is that the tree structures representing the source
sentences and their target compressions are isomorphic, i.e., there exists an edge-preserving
bijection between the nodes in the two trees. This assumption is valid for sentence compression but does not hold for other rewriting tasks. Consequently, sentence compression
models are too restrictive; they cannot be readily adapted to other generation problems
since they are not able to handle structural and lexical divergences. A related issue concerns the deletion operations themselves which often take place without considering the
structure of the target compression (the goal is to generate a compressed string rather than
the tree representing it). Without a syntax-based language model (Turner & Charniak,
2005) or an explicit generation mechanism that licenses tree transformations there is no
guarantee that the compressions will have well-formed syntactic structures. And it will not
be straightforward to process them for subsequent generation or analysis tasks.
In this paper we present a sentence compression model that is not deletion-specific but
can account for ample rewrite operations and scales to other rewriting tasks. We formulate
the compression problem as tree-to-tree rewriting using a synchronous grammar (with rules
like those shown in Figure 2). Specifically, we adopt the synchronous tree substitution
grammar (STSG) formalism (Eisner, 2003) which can model non-isomorphic tree structures
while having efficient inference algorithms. We show how such a grammar can be induced
from a parallel corpus and propose a discriminative model for the rewriting task which
can be viewed as a weighted tree-to-tree transducer. Our learning framework makes use of
the large margin algorithm put forward by Tsochantaridis, Joachims, Hofmann, and Altun
(2005) which efficiently learns a prediction function to minimize a given loss function. We
also develop an appropriate algorithm that can be used in both training (i.e., learning the
model weights) and decoding (i.e., finding the most plausible compression under the model).
Beyond sentence compression, we hope that some of the work described here might be of
relevance to other tasks involving structural matching (see the discussion in Section 8).
The remainder of this paper is structured as follows. Section 2 provides an overview
of related work. Section 3 presents the STSG framework and the compression model we
employ in our experiments. Section 5 discusses our experimental set-up and Section 6
presents our results. Discussion of future work concludes the paper.

2. Related Work
Synchronous context-free grammars (SCFGs, Aho & Ullman, 1969) are a generalization
of the context-free grammar (CFG) formalism to simultaneously produce strings in two
639

Cohn & Lapata

languages. They have been used extensively in syntax-based statistical MT. Examples
include inversion transduction grammar (Wu, 1997), head transducers (Alshawi, Bangalore,
& Douglas, 2000), hierarchical phrase-based translation (Chiang, 2007), and several variants
of tree transducers (Yamada & Knight, 2001; Grael & Knight, 2004).
Sentence compression bears some resemblance to machine translation. Instead of translating from one language into another, we are translating long sentences into shorter ones
within the same language. It is therefore not surprising that previous work has also adopted
SCFGs for the compression task. Specifically, Knight and Marcu (2002) proposed a noisychannel formulation of sentence compression. Their model consists of two components: a
language model P (y) whose role is to guarantee that the compression output is grammatical and a channel model P (x|y) capturing the probability that the source sentence x is
an expansion of the target compression y. Their decoding algorithm searches for the compression y which maximizes P (y)P (x|y). The channel model is a stochastic SCFG, the
rules of which are extracted from a parsed parallel corpus and their weights estimated using
maximum likelihood. Galley and McKeown (2007) show how to obtain improved SCFG
probability estimates through Markovization. Turner and Charniak (2005) note that SCFG
rules are not expressive enough to model structurally complicated compressions as they
are restricted to trees of depth 1. They remedy this by supplying their synchronous grammar with a set of more general “special” rules. For example, they allow rules of the form
hNP,NPi → h[NP NP 1 CC NP 2 ], NP 1 i (boxed subscripts are added to distinguish between
the two NPs).
Our own work formulates sentence compression in the framework of synchronous treesubstitution grammar (STSG, Eisner, 2003). STSG allows to describe non-isomorphic tree
pairs (the grammar rules can comprise trees of arbitrary depth) and is thus suited to textrewriting tasks which typically involve a number of local modifications to the input text.
Especially if each modification can be described succinctly in terms of syntactic transformations, such as dropping an adjectival phrase or converting a passive verb phrase into active
form. STSG is a restricted version of synchronous tree adjoining grammar (STAG, Shieber
& Schabes, 1990) without an adjunction operation. STAG affords mild context sensitivity,
however at increased cost of inference. SCFG and STSG are weakly equivalent, that is, their
string languages are identical but they do not produce equivalent tree pairs. For example,
in Figure 2, rules (1)–(4) can be expressed as SCFG rules, but rule (5) cannot because
both the source and target fragments are two level trees. In fact it would be impossible to
describe the trees in Figure 1 using a SCFG. Our grammar rules are therefore more general
than those obtained by Knight and Marcu (2002) and can account for more elaborate tree
divergences. Moreover, by adopting a more expressive grammar formalism, we can naturally model syntactically complex compressions without having to specify additional rules
(as in Turner & Charniak, 2005).
A synchronous grammar will license a large number of compressions for a given source
tree. Each grammar rule typically has a score from which the overall score of a compression y for sentence x can be derived. Previous work estimates these scores generatively as
discussed above. We opt for a discriminative training procedure which allows for the incorporation of all manner of powerful features. We use the large margin technique proposed
by Tsochantaridis et al. (2005). The framework is attractive in that it supports a configurable loss function, which describes the extent to which a predicted target tree differs from
640

Sentence Compression as Tree Transduction

the reference tree. By devising suitable loss functions the model can be straightforwardly
adapted to text rewriting tasks besides sentence compression.
McDonald (2006) also presents a sentence compression model that uses a discriminative
large margin algorithm. The model has a rich feature set defined over compression bigrams
including parts of speech, parse trees, and dependency information, without however making explicit use of a synchronous grammar. Decoding in this model amounts to finding the
combination of bigrams that maximize a scoring function defined over adjacent words in
the compression and the intervening words which were dropped. Our model differs from
McDonald’s in two important respects. First, we can capture more complex tree transformations that go beyond bigram deletion. Being tree-based, our decoding algorithm is
better able to preserve the grammaticality of the compressed output. Second, the treebased representation allows greater modeling flexibility, e.g., by defining a wide range of
loss functions over the tree or its string yield. In contrast, McDonald can only define loss
functions over the final compression.
Although the bulk of research on sentence compression relies on parallel corpora for
modeling purposes, a few approaches use no training data at all or a small amount. An
example is in the work of Hori and Furui (2004), who propose a model for automatically
transcribed spoken text. Their method scores candidate compressions using a language
model combined with a significance score (indicating whether a word is topical or not),
and a score representing the speech recognizer’s confidence in transcribing a given word
correctly. Despite being conceptually simple and knowledge lean, their model operates at
the word level. Since it does not take syntax into account, it has no means of deleting
constituents spanning several subtrees (e.g., relative clauses). Clarke and Lapata (2008)
show that such unsupervised models can be greatly improved when linguistically motivated
constraints are used during decoding.

3. Problem Formulation
As mentioned earlier, we formulate sentence compression as a tree-to-tree rewriting problem
using a weighted synchronous grammar coupled with a large margin training process. Our
model learns from a parallel corpus of input (uncompressed) and output (compressed) pairs
(x1 , y1 ), . . . , (xn , yn ) to predict a target labeled tree y from a source labeled tree x. We
capture the dependency between x and y as a weighted STSG which we define in the
following section. Section 3.2 discusses how we extract such a grammar from a parallel
corpus. Each rule has a score, as does each ngram in the output tree, from which the
overall score of a compression y for sentence x can be derived. We introduce our scoring
function in Section 3.3 and explain our training algorithm in Section 3.5. In this framework
decoding amounts to finding the best target tree licensed by the grammar given a source
tree. We present a chart-based decoding algorithm in Section 3.4.
3.1 Synchronous Grammar
A synchronous grammar defines a space of valid source and target tree pairs, much as a
regular grammar defines a space of valid trees. Synchronous grammars can be treated as tree
transducers by reasoning over the space of possible sister trees for a given tree, that is, all
the trees which can be produced alongside the given tree. This is essentially a transducer
641

Cohn & Lapata

Algorithm 1 Generative process for creating a pair of trees.
initialize source tree, x = RS
initialize target tree, y = RT
initialize stack of frontier nodes, F = [(RS , RT )]
for all node pairs, (vS , vT ) ∈ F do
choose a rule hvS , vT i → hα, γ, ∼i
rewrite node vS in x as α
rewrite node vT in y as γ
for all variables, u ∈ ∼ do
find aligned child nodes, (cS , cT ), under vS and vT corresponding to u
push (cS , cT ) on to F
end for
end for
x and y are now complete

which takes a tree as input and produces a tree as output. The grammar rules specify
the steps taken by the transducer in recursively mapping tree fragments of the input tree
into fragments in the target tree. From the many families of synchronous grammars (see
Section 2), we elect to use a synchronous tree-substitution grammar (STSG). This is one
of the simpler formalisms, and consequently has efficient inference algorithms, while still
being complex enough to model a rich suite of tree edit operations.
A STSG is a 7-tuple, G = (NS , NT , ΩS , ΩT , P, RS , RT ) where N are the non-terminals
and Ω are the terminals, with the subscripts S and T indicating source and target respectively, P are the productions and RS ∈ NS and RT ∈ NT are the distinguished root symbols.
Each production is a rewrite rule for two aligned non-terminals X ∈ NS and Y ∈ NT in the
source and target:
hX, Y i → hα, γ, ∼i
(1)
where α and γ are elementary trees rooted with the symbols X and Y respectively. Note
that a synchronous context free grammar (SCFG) limits α and γ to one level elementary
trees, but is otherwise identical to a STSG, which imposes no such limits. Non-terminal
leaves of the elementary trees are referred to as frontier nodes or variables. These are the
points of recursion in the transductive process. A one-to-one alignment between the frontier
nodes in α and γ is specified by ∼. The alignment can represent deletion (or insertion) by
aligning a node with the special  symbol, which indicates that the node is not present in
the other tree. Only nodes in α can be aligned to , which allows for subtrees to be deleted
during transduction. We disallow the converse, -aligned nodes in γ, as these would license
unlimited insertion in the target tree, independently of the source tree. This capability
would be of limited use for sentence compression, while also increasing the complexity of
inference.
The grammar productions can be used in a generative setting to produce pairs of trees,
or in a transductive setting to produce a target tree when given a source tree. Algorithms 1
and 2 present pseudo-code for both processes. The generative process (Algorithm 1) starts
with the two root symbols and applies a production which rewrites the symbols as the
production’s elementary trees. These elementary trees might contain frontier nodes, in
642

Sentence Compression as Tree Transduction

Algorithm 2 The transduction of a source tree into a target tree.
Require: complete source tree, x, with root node labeled RS
initialize target tree, y = RT
initialize stack of frontier nodes, F = [(root(x), RT )]
for all node pairs, (vS , vT ) ∈ F do
choose a rule hvS , vT i → hα, γ, ∼i where α matches the sub-tree rooted at vS in x
rewrite vT as γ in y
for all variables, u ∈ ∼ do
find aligned child nodes, (cS , cT ), under vS and vT corresponding to u
push (cS , cT ) on to F
end for
end for
y is now complete

which case the aligned pairs of frontier nodes are pushed on to the stack, and later rewritten
using another production. The process continues in a recursive fashion until the stack is
empty — there are no frontier nodes remaining —, at which point the two trees are complete.
The sequence of rewrite rules are referred to as a derivation, from which the source and
target tree can be recovered deterministically.
Our model uses a STSG in a transductive setting, where the source tree is given and it
is only the target tree that is generated. This necessitates a different rewriting process, as
shown in Algorithm 2. We start with the source tree, and RT , the target root symbol, which
is aligned to the root node of the source, denoted root(x). Then we choose a production to
rewrite the pair of aligned non-terminals such that the production’s source side, α, matches
the source tree. The target symbol is then rewritten using γ. For each variable in α the
matching node in the source and its corresponding leaf node in the target tree are pushed
on to the stack for later processing.1 The process repeats until the stack is empty, and
therefore the source tree has been covered. We now have a complete target tree. As before
we use the term derivation to refer to this sequence of production applications. The target
string is the yield of the target tree, given by reading the non-terminals from the tree in a
left to right manner.
Let us consider again the compression example from Figure 1. The tree editing rules from
Figure 2 are encoded as STSG productions in Figure 3 (see rules (1)–(5)). Production (1),
reproduces tree pair (1) from Figure 2, production (2) tree pair (2), and so on. The notation
in Figure 3 (primarily for space reasons) uses brackets ([]) to indicate constituent boundaries.
Brackets surround a constituent’s non-terminal and its child nodes, which can each be
terminals, non-terminals or bracketed subtrees. The boxed indices are short-hand notation
for the alignment, ∼. For example, in rule (1) they specify that the two WP non-terminals
are aligned and the RB node occurs only in the source tree (i.e., heads a deleted subtree). The grammar rules allow for differences in non-terminal category between the source
and target, as seen in rules (2)–(4). They also allow arbitrarily deep elementary trees,
1. Special care must be taken for  aligned variables. Nodes in α which are -aligned signify that the source
sub-tree below this point can be deleted without affecting the target tree. For this reason we can safely
ignore source nodes deleted in this manner.

643

Cohn & Lapata

(1)
(2)
(3)
(4)
(5)
(6)
(7)
(8)
(9)
(10)
(11)
(12)

hWHNP, WHNPi
hS, NPi
hS, VPi
hS̄, VPi
hS, Si
hWP, WPi
hNP, NPi
hNNS, NNSi
hVP, VPi
hVBP, VBPi
hVP, VPi
hVBN, VBNi

Rules which perform major tree edits
→ h[WHNP RB  WP 1 ], [WHNP WP 1 ]i
→ h[S NP 1 VP  ], NP 1 i
→ h[S NP  VP 1 ], VP 1 i
→ h[S̄ WHNP  S 1 ], VP 1 i
→ h[S [S̄ WHNP 1 S 2 ] [CC and] S̄ 3 ], [S WHNP 1 [S NP 2 VP 3 ]]i
Rules which preserve the tree structure
→ h[WP what], [WP what]i
→ h[NP NNS 1 ], [NP NNS 1 ]i
→ h[NNS records], [NNS records]i
→ h[VP VBP 1 VP 2 ], [VP VBP 1 VP 2 ]i
→ h[VBP are], [VBP are]i
→ h[VP VBN 1 ], [VP VBN 1 ]i
→ h[VBN involved], [VBN involved]i

Figure 3: The rules in a Synchronous Tree Substitution Grammar (STSG) capable of generating the sentence pair from Figure 1. Equivalently, this grammar defines a
transducer which can convert the source tree (Figure 1(a)) into the target tree
(Figure 1(b)). Each rule rewrites a pair of non-terminals into a pair of subtrees,
shown in bracketed notation.

as evidenced by rule (5) which is has trees of depth two. Rules (6)–(12) complete the
toy grammar which describes the tree pair from Figure 1. These rules copy parts of the
source tree into the target, be they terminals (e.g., rule (6)) or internal nodes with children
(e.g., rule (9)).
Figure 4 shows how this grammar can be used to transduce the source tree into the
target tree from Figure 1. The first few steps of the derivation are also shown graphically in Figure 5. We start with the source tree, and seek to transduce its root symbol
into the target root symbol, denoted S/S. The first rule to be applied is rule (5) in Figure 3; its source side, α = [S [S̄ WHNP S] [CC and] S̄], matches the root of source tree
and it has the requisite target category, Y = S. The matching part of the source tree
is rewritten using the rule’s target elementary tree, γ = [S WHNP [S NP VP]]. The three
three variables are now annotated to reflect the category transformations required for each
node, WHNP/WHNP, S/NP and S̄/VP. The process now continues for the leftmost of these
nodes, labeled WHNP/WHNP. Rule (1) (from Figure 3) is then applied, which deletes the
node’s left child, shown as RB/, and retains its right child. The subsequent rule completes
the transduction of the WHNP node by matching the string ‘exactly’. The algorithm continues to visit each variable node and finishes when there are no variable nodes remaining,
resulting in the desired target tree.
3.2 Grammar
The previous section outlined the STSG formalism we employ in our sentence compression
model, save one important detail: the grammar itself. For example, we could obtain a
644

Sentence Compression as Tree Transduction

[S/S [S̄ [WHNP exactly what] [S [NP records] [VP made it]]]
[CC and] [S̄ [WHNP which] [S [NP ones] [VP are involved]]]]
⇒5
[S [WHNP/WHNP [RB exactly] [WP what]] [S [S/NP [NP records] [VP made it]]
[S̄/VP [WHNP which] [S [NP ones] [VP are involved]]]]]
⇒1
[S [WHNP [WP/WP what]] [S [S/NP [NP records] [VP made it]]
[S̄/VP [WHNP which] [S [NP ones] [VP are involved]]]]]
⇒6
[S [WHNP [WP what]] [S [S/NP [NP records] [VP [VBD made] [NP [PRP it]]]]]
[S̄/VP [WHNP which] [S [NP ones] [VP [VBP are] [VP [VBN involved]]]]]]]
⇒2
[S [WHNP [WP what]] [S [NP [NNS/NNS records]]
[S̄/VP [WHNP which] [S [NP ones] [VP are involved]]]]]
⇒8
[S [WHNP [WP what]] [S [NP [NNS records]]]
[S̄/VP [WHNP which] [S [NP ones] [VP are involved]]]]
⇒4
[S [WHNP what] [S [NP records] [S/VP [NP ones] [VP are involved]]]]
⇒3
[S [WHNP what] [S [NP records] [VP/VP [VP [VBP are] [VP [VBN involved]]]]]]
⇒9
[S [WHNP what] [S [NP records] [VP [VBP/VBP are] [VP/VP [VBN involved]]]]]
⇒10 [S [WHNP what] [S [NP records] [VP [VBP are] [VP/VP [VBN involved]]]]]
⇒11 [S [WHNP what] [S [NP records] [VP [VBP are] [VP [VBN/VBN involved]]]]]
⇒12 [S [WHNP [WP what]] [S [NP [NNS records]] [VP [VBP are] [VP [VBN involved]]]]]

Figure 4: Derivation of example sentence pair from Figure 1. Each line shows a rewrite step,
denoted ⇒i where the subscript i identifies which rule was used. The frontier
nodes are shown in bold with X/Y indicating that symbol X must be transduced
into Y in subsequent steps. For the sake of clarity, some internal nodes have been
omitted.

synchronous grammar by hand, automatically from a corpus, or by some combination. Our
only requirement is that the grammar allows the source trees in the training set to be
transduced into their corresponding target trees. For maximum generality, we devised an
automatic method to extract a grammar from a parsed, word-aligned parallel compression
corpus. The method maps the word alignment into a constituent level alignment between
nodes in the source and target trees. Pairs of aligned subtrees are next generalized to create
tree fragments (elementary trees) which form the rules of the grammar.
The first step of the algorithm is to find the constituent alignment, which we define as
the set of source and target constituent pairs whose yields are aligned to one another under
the word alignment. We base our approach on the alignment template method (Och & Ney,
2004), which uses word alignments to define alignments between ngrams (called phrases in
the SMT literature). This method finds pairs of ngrams where at least one word in one
of the ngrams is aligned to a word in the other, but no word in either ngram is aligned to
a word outside the other ngram. In addition, we require that these ngrams are syntactic
constituents. More formally, we define constituent alignment as:
C = {(vS , vT ), (∃(s, t) ∈ A ∧ s ∈ Y (vS ) ∧ t ∈ Y (vT ))∧

(2)

(@(s, t) ∈ A ∧ (s ∈ Y (vS ) Y t ∈ Y (vT )))}
where vS and vT are source and target tree nodes (subtrees), A = {(s, t)} is the set of word
alignments (pairs of word-indices), Y (·) returns the yield span for a subtree (the minimum
and maximum word index in its yield) and Y is the exclusive-or operator. Figure 6 shows
645

Cohn & Lapata

S

S

S

S
S

S
VP

WHNP

NP

RB

WP

NNS

exactly

what

records

VP
NP

WHNP

VBD PRP CC
made

it

and

WP
which

NP

VP

NNS VBP
ones

are

VBN
involved

S

S

S

S
S
VP

WHNP

NP

RB

WP

NNS

exactly

what

records

WHNP

S
NP

made

NP

VP
WHNP

VBD PRP CC
it

and

WP
which

NP
are

VBN
involved

S

S

S

S
S

NP

RB

WP

NNS

exactly

what

records

WHNP

S
VP

WHNP

WHNP

VBD PRP CC
made

it

and

WP
which

NP

VP

NNS VBP
ones

S

WP NP VP

VP
NP

VP

VP

NNS VBP
ones

S

are

VBN
involved

Figure 5: Graphical depiction of the first two steps of the derivation in Figure 4. The source
tree is shown on the left and the partial target tree on the right. Variable nodes
are shown in bold face and dotted lines show their alignment.

the word alignment and the constituent alignments that are licensed for the sentence pair
from Figure 1.
The next step is to generalize the aligned subtree pairs by replacing aligned child subtrees
with variable nodes. For example, in Figure 6 when we consider the pair of aligned subtrees
[S̄ which ones are involved] and [VP are involved], we could extract the rule:
hS̄,VPi → h[S̄ [WHNP [WP which]] [S [NP [NNS ones] [VP [VBP are] [VP [VBN involved]]]]]],
[VP [VBP are] [VP [VBN involved]]]i

(3)

However, this rule is very specific and consequently will not be very useful in a transduction
model. In order for it to be applied, we must see the full S̄ subtree, which is highly unlikely
to occur in another sentence. Ideally, we should generalize the rule so as to match many
more source trees, and thereby allow transduction of previously unseen structures. In the
example, the node pairs labeled (VP1 , VP1 ), (VBP, VBP), (VP2 , VP2 ) and (VBN, VBN)
can all be generalized as these nodes are aligned constituents (subscripts added to distinguish
646

Sentence Compression as Tree Transduction

S
S

S
S

S
VP

WHNP

NP

NP

VP
WHNP NP

VP

RB
WP NNS VBD PRP CC WP NNS VBP VBN
exactly what records made it
and which ones are involved
S
S
VP
WHNP NP
VP
WP NNS VBP VBN
what records are involved

Figure 6: Tree pair with word alignments shown as a binary matrix. A dark square indicates
an alignment between the words on its row and column. The overlaid rectangles
show constituent alignments which are inferred from the word alignment.

between the two VP nodes). In addition, the nodes WHNP, WP, NP and NNS in the source
are unaligned, and therefore can be generalized using -alignment to signify deletion. If we
were to perform all possible generalizations for the above example,2 we would produce the
rule:
hS̄,VPi → h[S̄ WHNP  S 1 ], VP 1 i
(4)
There are many other possible rules which can be extracted by applying different legal
combinations of the generalizations (there are 45 in total for this example).
Algorithm 3 shows how the minimial (most general) rules are extracted.3 This results
in the minimal set of synchronous rules which can describe each tree pair.4 These rules are
minimal in the sense that they cannot be made smaller (e.g., by replacing a subtree with
a variable) while still honoring the word-alignment. Figure 7 shows the resulting minimal
set of synchronous rules for the example from Figure 6. As can be seen from the example,
many of the rules extracted are overly general. Ideally, we would extract every rule with
every legal combination of generalizations, however this leads to a massive number of rules
— exponential in the size of the source tree. We address this problem by allowing a limited
number of generalizations to be ‘skipped’ in the extraction process. This is equivalent to
altering lines 4 and 7 in Algorithm 3 to first make a non-deterministic decision whether to
match or ignore the match and continue descending the source tree. The recursion depth
limits the number of matches that can be ignored in this way. For example, if we allow one
2. Where some generalizations are mutually exclusive, we take the highest match in the trees.
3. The non-deterministic matching step in line 8 allows the matching of all options individually. This
is implemented as a mutually recursive function which replicates the algorithm state to process each
different match.
4. Algorithm 3 is an extension of Galley, Hopkins, Knight, and Marcu’s (2004) technique for extracting a
SCFG from a word-aligned corpus consisting of (tree, string) pairs.

647

Cohn & Lapata

Algorithm 3 extract(x, y, A): extracts minimal rules from constituent-aligned trees
Require: source tree, x, target tree, y, and constituent-alignment, A
1: initialize source and target sides of rule, α = x, γ = y
2: initialize frontier alignment, ∼= ∅
3: for all nodes vS ∈ α, top-down do
4:
if vS is null-aligned then
5:
∼←∼ ∪(vS , )
6:
delete children of a
7:
else if vS is aligned to some target node(s) then
8:
choose target node, vT
{non-deterministic choice}
9:
call extract(vS , vT , A)
10:
∼←∼ ∪(vS , vT )
11:
delete children of vS
12:
delete children of vT
13:
end if
14: end for
15: emit rule hroot(α), root(γ)i → hα, γ, ∼i
level of recursion when extracting rules from the (S̄, VP) pair from Figure 6, we get the
additional rules:
hS̄,VPi → h[S̄ [WHNP WP  ] S 1 ], VP 1 i
hS̄,VPi → h[S̄ WHNP  [S NP  VP 1 ]], VP 1 i
while at two levels of recursion, we also get:
hS̄,VPi → h[S̄ [WHNP [WP which]] S 1 ], VP 1 i
hS̄,VPi → h[S̄ [WHNP [WP which]] [S NP  VP 1 ]], VP 1 i
hS̄,VPi → h[S̄ WHNP  [S [NP NNS  ] VP 1 ]], VP 1 i
hS̄,VPi → h[S̄ WHNP  [S NP  [VP VBD 1 VP 2 ]]], [VBD 1 VBD 2 ]i
Compared to rule (4) we can see that the specialized rules above add useful structure
and lexicalisation, but are still sufficiently abstract to generalize to new sentences, unlike
rule (3). The number of rules is exponential in the recursion depth, but with fixed a depth
it is polynomial in the size of the source tree fragment. We set the recursion depth to a
small number (one or two) in our experiments.
There is no guarantee that the induced rules will have good coverage on unseen trees.
Tree fragments containing previously unseen terminals or non-terminals, or even an unseen
sequence of children for a parent non-terminal, cannot be matched by any grammar productions. In this case the transduction algorithm (Algorithm 2) will fail as it has no way
of covering the source tree. However, the problem can be easily remedied by adding new
rules to the grammar to allow the source tree to be fully covered.5 For each node in the
5. There are alternative, equally valid, techniques for improving coverage which simplify the syntax trees.
For example, this can be done explicitly by binarizing large productions (e.g., Petrov, Barrett, Thibaux,
& Klein, 2006) or implicitly with a Markov grammar over grammar productions (e.g., Collins, 1999).

648

Sentence Compression as Tree Transduction

hS,Si
hWHNP,WHNPi
hWP,WPi
hS,NPi
hNP,NPi
hNNS,NNSi
hS̄,VPi
hS,VPi
hVP,VPi
hVBP,VBPi
hVP,VPi
hVBN,VBNi

→
→
→
→
→
→
→
→
→
→
→
→

h[S [S̄ WHNP 1 S 2 ] CC  S̄ 3 ], [S WHNP 1 [S NP 2 VP 3 ]]i
h[WHNP RB  WP 1 ], [WHNP WP 1 ]i
h[WP what], [WP what]i
h[S NP 1 VP  ], NP 1 i
h[NP NNS 1 ], [NP NNS 1 ]i
h[NNS records], [NNS records]i
h[S̄ WHNP  S 1 ], VP 1 i
h[S NP  VP 1 ], VP 1 i
h[VP VBP 1 VP 2 ], [VP VBP 1 VP 2 ]i
h[VBP are], [VBP are]i
h[VP VBN 1 ], [VP VBN 1 ]i
h[VBN involved], [VBN involved]i

Figure 7: The minimal set of STSG rules extracted from the aligned trees in Figure 6.

source tree, a rule is created to copy that node and its child nodes into the target tree. For
example, if we see the fragment [NP DT JJ NN] in the source tree, we add the rule:

hNP,NPi → h[NP DT 1 JJ 2 NN 3 ], [NP DT 1 JJ 2 NN 3 ]i

With these rules, each source node is copied into the target tree, and therefore the transduction algorithm can trivially recreate the original tree. Of course, the other grammar
rules can work in conjunction with the copying rules to produce other target trees.
While the copy rules solve the coverage problem on unseen data, they do not solve the
related problem of under-compression. This occurs when there are unseen CFG productions
in the source tree and therefore the only applicable grammar rules are copy rules, which
copy all child nodes into the target. None of the child subtrees can be deleted unless the
parent node can itself deleted by a higher-level rule, in which case all the children are
deleted. Clearly, it would add considerable modelling flexibility to be able to delete some,
but not all, of the children. For this reason, we add explicit deletion rules for each source
CFG production which allow subsets of the child nodes to be deleted in a linguistically
plausible manner.
The deletion rules attempt to preserve the most important child nodes. We measure
importance using the head-finding heuristic from Collins’ parser (Appendix A, Collins,
1999). Collins’ method finds the single head child of a CFG production using hand-coded
tables for each non-terminal type. As we desire a set of child nodes, we run the algorithm to
find all matches rather than stopping after the first match. The order in which each match
is found is used as a ranking of the importance of each child. The ordered list of child nodes
is then used to create synchronous rules which retain head 1, heads 1–2, . . . , all heads.
649

Cohn & Lapata

For the fragment [NP DT JJ NN], the heads are found in the following order (NN, DT,
JJ). Therefore we create rules to retain children (NN); (DT, NN) and (DT, JJ, NN):
hNP,NPi → h[NP DT  JJ  NN 1 ], [NP NN 1 ]i
hNP,NNi → h[NP DT  JJ  NN 1 ], NN 1 i
hNP,NPi → h[NP DT 1 JJ  NN 2 ], [NP DT 1 NN 2 ]i
hNP,NPi → h[NP DT 1 JJ 2 NN 3 ], [NP DT 1 JJ 2 NN 3 ]i
Note that when only one child remains, the rule is also produced without the parent node,
as seen in the second rule above.
3.3 Linear Model
While an STSG defines a transducer capable of mapping a source tree into many possible
target trees, it is of little use without some kind of weighting towards grammatical trees
which have been constructed using sensible STSG productions and which yield fluent compressed target sentences. Ideally the model would define a scoring function over target
trees or strings, however we instead operate on derivations. In general, there may be many
derivations which all produce the same target tree, a situation referred to as spurious ambiguity. To fully account for spurious ambiguity would require aggregating all derivations
which produce the same target tree. This would break the polynomial-time dynamic program used for inference, rendering inference problem NP-complete (Knight, 1999). To this
end, we define a scoring function over derivations:
score(d; w) = hΨ(d), wi

(5)

where d is a derivation6 consisting of a sequence of rules, w are the model parameters,
Ψ is a vector-valued feature function and the operator h·, ·i is the inner product. The
parameters, w, are learned during training, described in Section 3.5.
The feature function, Ψ, is defined as:
X
X
Ψ(d) =
φ(r, source(d)) +
ψ(m, source(d))
(6)
r∈d

m∈ngrams(d)

where r are the rules of a derivation, ngrams(d) are the ngrams in the yield of the target
tree and φ is a feature function returning a vector of feature values for each rule. Note that
the feature function has access to not only the rule, r, but also the source tree, source(d),
as this is a conditional model and therefore doing so has no overhead in terms of modeling
assumptions or the complexity of inference.
In the second summand in (6), m are the ngrams in the yield of the target tree and ψ is
a feature function over these ngrams. Traditional (weighted) synchronous grammars only
allow features which decompose with the derivation (i.e., can be expressed using the first
summand in (6)). However, this is a very limiting requirement, as the ngram features
allow the modeling of local coherence and are commonly used in the sentence compression
literature (Knight & Marcu, 2002; Turner & Charniak, 2005; Galley & McKeown, 2007;
6. The derivation, d, fully specifies both the source, x = source(d), and the target tree, y = target(d).

650

Sentence Compression as Tree Transduction

Clarke & Lapata, 2008; Hori & Furui, 2004; McDonald, 2006). For instance, when deleting
a sub-tree with left and right siblings, it is critical to know not only that the new siblings
are in a grammatical configuration, but also that their yield still forms a coherent string.
For this reason, we allow ngram features, specifically the conditional log-probability of
an ngram language model. Unfortunately, this comes at a price as the ngram features
significantly increase the complexity of inference used for training and decoding.
3.4 Decoding
Decoding aims to find the best target tree licensed by the grammar given a source tree.
As mentioned above, we deal with derivations in place of target trees. Decoding finds the
maximizing derivation, d∗ , of:
d∗ =

argmax

score(d; w)

(7)

d:source(d)=x

where x is the (given) source tree, source(d) extracts the source tree from the derivation d
and score is defined in (5). The maximization is performed over the space of derivations
for the given source tree, as defined by the transduction process shown in Algorithm 2.
The maximization problem in (7) is solved using the chart-based dynamic program
shown in Algorithm 4. This extends earlier inference algorithms for weighted STSGs (Eisner, 2003) which assume that the scoring function must decompose with the derivation,
i.e., features apply to rules but not to terminal ngrams. Relaxing this assumption leads to
additional complications and increased time and space complexity. This is equivalent to using as our grammar the intersection between the original grammar and an ngram language
model, as explained by Chiang (2007) in the context of string transduction with an SCFG.
The algorithm defines a chart, C, to record the best scoring (partial) target tree for each
source node vS and with root non-terminal t. The back-pointers, B, record the maximizing
rule and store pointers to the child chart cells filling each variable in the rule. The chart is
also indexed by the n − 1 terminals at the left and right edges of the target tree’s yield to
allow scoring of ngram features.7 The terminal ngrams provide sufficient context to evaluate
ngram features overlapping the cell’s boundary when the chart cell is combined in another
rule application (this is the operation performed by the boundary-ngrams function on line
15). This is best illustrated with an example. Using trigram features, n = 3, if a node were
rewritten as [NP the fast car] then we must store the ngram context (the fast, fast car) in
its chart entry. Similarly [VP skidded to a halt] would have ngram context (skidded to, a
halt). When applying a parent rule [S NP VP] which rewrites these two trees as adjacent
siblings we need to find the ngrams on the boundary between the NP and VP. These can
be easily retrieved from the two chart cells’ contexts. We combine the right edge of the NP
context, ‘fast car’, with the left edge of the VP context, ‘skidded to’, to get the two trigrams
‘fast car skidded’ and ‘car skidded to’. The other trigrams — ‘the fast car’, ‘skidded to
a’ and ‘to a halt’ — will have already been evaluated in the child chart cells. The new
combined S chart cell is now given the context (the fast, a halt) by taking the left and right
7. Strictly speaking, only the terminals on the right edge are required for a compression model which would
create the target string in a left-to-right manner. However, our algorithm is more general in that it
allows reordering rules such as hPP,PPi → h[PP IN 1 NP 2 ], [PP NP 2 IN 1 ]i. Such rules are required for
most other text-rewriting tasks besides sentence compression.

651

Cohn & Lapata

Algorithm 4 Exact chart based decoding algorithm.
Require: complete source tree, x, with root node labeled RS
1: let C[v, t, l] ∈ R be a chart representing the score of the best derivation transducing the
tree rooted at v to a tree with root category t and ngram context l
2: let B[v, t, l] ∈ (P, x × NT × L) be the corresponding back-pointers, each consisting of
a production and the source node, target category and ngram context for each of the
production’s variables
3: initialize chart, C[∗, ∗, ∗] = −∞
4: initialize back-pointers, B[∗, ∗, ∗] = none
5: for all source nodes, vS ∈ x, bottom-up do
6:
for all rules, r = hvS , Y i → hα, γ, ∼i where α matches the sub-tree rooted at vS do
7:
let m be the target ngrams wholly contained in γ
8:
let features vector, Ψ ← φ(r, x) + ψ(m, x)
9:
let l be an empty ngram context
10:
let score, q ← 0
11:
for all variables, u ∈ ∼ do
12:
find source child node, cu , under vS corresponding to u
13:
let tu be the non-terminal for target child node under γ corresponding to u
14:
choose child chart entry, qu = C[cu , tu , lu ]
{non-deterministic choice of lu }
15:
let m ← boundary-ngrams(r, lu )
16:
update features, Ψ ← Ψ + ψ(m, x)
17:
update ngram context, l ← merge-ngram-context(l, lu )
18:
update score, q ← q + qu
19:
end for
20:
update score, q ← q + hΨ, wi
21:
if q > C[vS , Y, l] then
22:
update chart, C[vS , Y, l] ← q
23:
update back-pointers, B[vS , Y, l] ← (r, {(cu , tu , lu )∀u})
24:
end if
25:
end for
26: end for
27: find best root chart entry, l∗ ← argmaxl C[root(x), RT , l]
28: create derivation, d, by traversing back-pointers from B[root(x), RT , l∗ ]

edges of the two child cells. This merging process is performed by the merge-ngram-context
function on line 17. Finally we add artificial root node to the target tree with n − 1 artificial
start terminals and one end terminal. This allows the ngram features to be applied over
boundary ngrams at the beginning and end of the target string.
The decoding algorithm processes the source tree in a post-order traversal, finding the
set of possible trees and their ngram contexts for each source node and inserting these into
the chart. The rules which match the node are processed in lines 6–24. The feature vector,
Ψ, is calculated on the rule and the ngrams therein (line 8), and for ngrams bordering child
cells filling the rule’s variables (line 16). Note that the feature vector only includes those
features specific to the rule and the boundary ngrams, but not those wholly contained in
652

Sentence Compression as Tree Transduction

the child cell. For this reason the score is the sum of the scores for each child cell (line
18) and the feature vector and the model weights (line 20). The new ngram context, l, is
calculated by combining the rule’s frontier and the ngram contexts of the child cells (line
17). Finally the chart entry for this node is updated if the score betters the previous value
(lines 21–24).
When choosing the child chart cell entry in line 14, there can be many different entries
each with a different ngram context, lu . This affects the ngram features, ψ, and consequently
the ngram context, l, and the score, q, for the rule. The non-determinism means that every
combination of child chart entries are chosen for each variable, and these combinations are
then evaluated and inserted into the chart. The number of combinations is the product of
the number of child chart entries for each variable. This can be bounded by O(|TT |2(n−1)V )
where |TT | is the size of the target lexicon and V is the number of variables. Therefore the
asymptotic time complexity of decoding is the O(SR|TT |2(n−1)V ) where S are the number
of source nodes and R is the number of matching rules for each node. This high complexity
clearly makes exact decoding infeasible, especially so when either n or V are large.
We adopt a popular approach in syntax-inspired machine translation to address this
problem (Chiang, 2007). Firstly, we use a beam-search, which limits the number of different
ngram contexts stored in each chart cell to a constant, W . This changes the base in
the complexity term, leading to an improved O(SRW V ) but which is still exponential in
the number of variables. In addition, we use Chiang’s cube-pruning heuristic to further
limit the number of combinations. Cube-pruning uses a heuristic scoring function which
approximates the conditional log-probability from a ngram language model with the logprobability from a unigram model.8 This allows us to visit the combinations in best-first
order under the heuristic scoring function until the beam is filled.The beam is then rescored
using the correct scoring function. This can be done cheaply in O(W V ) time, leading to an
overall time complexity of decoding to O(SRW V ). We refer the interested reader to the
work of Chiang (2007) for further details.
3.5 Training
We now turn to the problem of how derivations are scored in our model. For a given source
tree, the space of sister target trees implied by the synchronous grammar is often very large,
and the majority of these trees are ungrammatical or poor compressions. It is the job of
the training algorithm to find weights such that the reference target trees have high scores
and the many other target trees licensed by the grammar are given lower scores.
As explained in Section 3.3 we define a scoring function over derivations. This function
was given in (5) and (7), and is reproduced below:
f (d; w) =

argmax hw, Ψ(d)i

(8)

d:source(d)=x

Equation (8) finds the best scoring derivation, d, for a given source, x, under a linear model.
Recall that y is a derivation which generates the source tree x and a target tree. The goal
8. We use the conditional log-probability of an ngram language model as our only ngram feature. In order to
use other ngram features, such as binary identity features for specific ngrams, it would first be advisable to
construct an approximation which decomposes with the derivation for use in the cube-pruning heuristic.

653

Cohn & Lapata

of the training procedure is to find a parameter vector w which satisfies the condition:
∀i, ∀d : source(d) = xi ∧ d 6= di : hw, Ψ(di ) − Ψ(d)i ≥ 0

(9)

where xi , di are the ith training source tree and reference derivation. This condition states
that for all training instances the reference derivation is at least as high scoring as any
other derivations. Ideally, we would also like to know the extent to which a predicted target
tree differs from the reference tree. For example, a compression that differs from the gold
standard with respect to one or two words should be treated differently from a compression
that bears no resemblance to it. Another important factor is the length of the compression.
Compressions whose length is similar to the gold standard should be be preferable to longer
or shorter output. A loss function ∆(yi , y) quantifies the accuracy of prediction y with
respect to the true output value yi .
There are a plethora of different discriminative training frameworks which can optimize
a linear model. Possibilities include perceptron training (Collins, 2002), log-linear optimisation of the conditional log-likelihood (Berger, Pietra, & Pietra, 1996) and large margin
methods. We base our training on Tsochantaridis et al.’s (2005) framework for learning
Support Vector Machines (SVMs) over structured output spaces, using the SVMstruct implementation.9 The framework supports a configurable loss function which is particularly
appealing in the context of sentence compression and more generally text-to-text generation. It also has an efficient training algorithm and powerful regularization. The latter is
is critical for discriminative models with large numbers of features, which would otherwise
over-fit the training sample at the expense of generalization accuracy. We briefly summarize
the approach below; for a more detailed description we refer the interested reader to the
work of Tsochantaridis et al. (2005).
Traditionally SVMs learn a linear classifier that separates two or more classes with the
largest possible margin. Analogously, structured SVMs attempt to separate the correct
structure from all other structures with a large margin. The learning objective for the
structured SVM uses the soft-margin formulation which allows for errors in the training set
via the slack variables, ξi :
n

1
CX
min ||w||2 +
ξ i , ξi ≥ 0
w,ξ 2
n

(10)

i=1

∀i, ∀d : source(d) = xi ∧ y 6= di : hw, Ψ(di ) − Ψ(d)i ≥ ∆(di , d) − ξi
The slack variables, ξi , are introduced here for each training example, xi and C is a constant
that controls the trade-off between training error minimization and margin maximization.
Note that slack variables are combined with the loss incurred in each of the linear constraints. This means that a high loss output must be separated by a larger margin than
a low loss output, or have a much larger slack variable to satisfy the constraint. Alternatively, the loss function can be used to rescale the slack parameters, in which case the
constraints in (10) are replaced with hw, Ψ(di ) − Ψ(d)i ≥ 1 − ∆(dξii ,d) . Margin rescaling is
theoretically less desirable as it is not scale invariant, and therefore requires the tuning of
an additional hyperparameter compared to slack rescaling. However, empirical results show
9. http://svmlight.joachims.org/svm_struct.html

654

Sentence Compression as Tree Transduction

little difference between the two rescaling methods (Tsochantaridis et al., 2005). We use
margin rescaling for the practical reason that it can be approximated more accurately than
can slack rescaling by our chart based inference method.
The optimization problem in (10) is approximated using an algorithm proposed by
Tsochantaridis et al. (2005). The algorithm finds a small set of constraints from the fullsized optimization problem that ensures a sufficiently accurate solution. Specifically, it
constructs a nested sequence of successively tighter relaxation of the original problem using
a (polynomial time) cutting plane algorithm. For each training instance, the algorithm
keeps track of the selected constraints defining the current relaxation. Iterating through
the training examples, it proceeds by finding the output that most radically violates a
constraint. In our case, the optimization crucially relies on finding the derivation which is
both high scoring and has high loss compared to the gold standard. This requires finding
the maximizer of:
H(d) = ∆(d∗ , d) − hw, Ψ(di ) − Ψ(d)i

(11)

The search for the maximizer of H(d) in (11) can be performed by the decoding algorithm presented in Section 3.4 with some extensions. Firstly, by expanding (11) to
H(d) = ∆(d∗ , d) − hΨ(di ), wi + hΨ(d), wi we can see that the second term is constant with
respect to d, and thus does not influence the search. The decoding algorithm maximizes
the last term, so all that remains is to include the loss function into the search process.
Loss functions
which decompose
with the rules or target ngrams in the derivation,
P
P
∗
∗ , r) +
∆
(d
∆(d∗ , d) =
n∈ngrams(d) ∆N (d , n), can be easily integrated into the
r∈d R
decoding algorithm. This is done by adding the partial loss, ∆R (d∗ , r) + ∆N (d∗ , n) to each
rule’s score in line 20 of Algorithm 4 (the ngrams are recovered from the ngram contexts in
the same manner used to evaluate the ngram features).
However, many of our loss functions do not decompose with the rules or the ngrams. In
order to calculate these losses the chart must be stratified by the loss function’s arguments
(Joachims, 2005). For example, unigram precision measures the ratio of correctly predicted
tokens to total predicted tokens and therefore its loss arguments are the pair of counts,
(T P, F P ), for true and false positives. They are initialized to (0, 0) and are then updated
for each rule used in a derivation. This equates to checking whether each target terminal is in
the reference string and incrementing the relevant value. The chart is extended (stratified)
to store the loss arguments in the same way that ngram contexts are stored for decoding.
This means that a rule accessing a child chart cell can get multiple entries, each with
different loss argument values as well as multiple ngram contexts (line 14 in Algorithm
4). The loss argument for a rule application is calculated from the rule itself and the loss
arguments of its children. This is then stored in the chart and the back-pointer list (lines
22–23 in Algorithm 4). Although this loss can only be evaluated correctly for complete
derivations, we also evaluate the loss on partial derivations as part of the cube-pruning
heuristic. Losses with a large space of argument values will be more coarsely approximated
by the beam search, which prunes the number of chart entries to a constant size. For this
reason, we have focused mainly on simple loss functions which have a relatively small space
of argument values, and also use a wide beam during the search (200 unique items or 500
items, whichever comes first).
655

Cohn & Lapata

Algorithm 5 Find the gold standard derivation for a pair of trees (i.e., alignment).
Require: source tree, x, and target tree, y
1: let C[vS , vT ] ∈ R be a chart representing the maximum number of rules used to align
nodes vS ∈ x and vT ∈ y
2: let B[vS , vT ] ∈ (P, x × y) be the corresponding back-pointers, consisting of a production
and a pair aligned nodes for each of the production’s variables
3: initialize chart, C[∗, ∗] = −∞
4: initialize back-pointers, B[∗, ∗] = none
5: for all source nodes, vS ∈ x, bottom-up do
6:
for all rules, r = hvS , Y i → hα, γ, ∼i where α matches the sub-tree rooted at vS do
7:
for all target nodes, vT ∈ y, matching γ do
8:
let rule count, j ← 1
9:
for all variables, u ∈ ∼ do
10:
find aligned child nodes, (cS , cT ), under vS and vT corresponding to u
11:
update rule count, j ← j + C[cS , cT ]
12:
end for
13:
if n greater than previous value in chart then
14:
update chart, C[vS , vT ] ← j
15:
update back-pointers, B[vS , vT ] ← (r, {(cS , cT )∀u})
16:
end if
17:
end for
18:
end for
19: end for
20: if C[root(x), root(y)] 6= −∞ then
21:
success; create derivation by traversing back-pointers from B[root(x), root(y)]
22: end if
In our discussion so far we have assumed that we are given a gold standard derivation, yi
glossing over the issue of how to find it. Spurious ambiguity in the grammar means that
there are often many derivations linking the source and target, none of which are clearly
‘correct’. We select the derivation using the maximum number of rules, each of which will be
small, and therefore should provide maximum generality.10 This is found using Algorithm 5,
a chart-based dynamic program similar to the alignment algorithm for inverse transduction
grammars (Wu, 1997). The algorithm has time complexity O(S 2 R) where S is the size of
the larger of the two trees and R is the number of rules which can match a node.
3.6 Loss Functions
The training algorithm described above is highly modular and in theory can support a wide
range of loss functions. There is no widely accepted evaluation metric for text compression. A zero-one loss would be straightforward to define but inappropriate for our problem,
10. We also experimented with other heuristics, including choosing the derivation at random and selecting
the derivation with the maximum or minimum score under the model (all using the same search algorithm
but with a different objective). Of these, only the maximum scoring derivation was competitive with the
maximum rules heuristic.

656

Sentence Compression as Tree Transduction

as it would always penalize target derivations that differ even slightly from the reference
derivation. Ideally, we would like a loss with a wider scoring range that can discriminate
between derivations that differ from the reference. Some of these may be good compressions whereas others may be entirely ungrammatical. For this reason we have developed
a range of loss functions which draw inspiration from various metrics used for evaluating
text-to-text rewriting tasks such as summarization and machine translation.
Loss functions are defined over derivations and can look at any item accessible including
tokens, ngrams and CFG rules. Our first class of loss functions calculates the Hamming
distance between unordered bags of items. It measures the number of predicted items that
did not appear in the reference, along with a penalty for short output:
∆hamming (d∗ , d) = F P + max (l − (T P + F P ), 0)

(12)

where T P and F P are the number of true and false positives, respectively, when comparing
the predicted target, dT , with the reference, d∗T , and l is the length of the reference. We
include the second term to penalize overly short output as otherwise predicting very little
or nothing would incur no penalty.
We have created three instantiations of the loss function in (12) over: 1) tokens,
2) ngrams (n ≤ 3), and 3) CFG productions. In each case, the loss argument space is
quadratic in the size of the source tree. Our Hamming ngram loss is an attempt at defining
a loss function similar to BLEU (Papineni, Roukos, Ward, & Zhu, 2002). The latter is
defined over documents rather than individual sentences, and is thus not directly applicable
to our problem. Now, since these losses all operate on unordered bags they may reward
erroneous predictions, for example, a permutation of the reference tokens will have zero
token-loss. This is less of a problem for the CFG and ngram losses whose items overlap,
thereby encoding a partial order. Another problem with the loss functions just described is
that they do not penalize multiply predicting an item that occurred only once in the reference. This could be a problem for function words which are common in most sentences.
Therefore we developed two additional loss functions which take multiple predictions into
account. The first measures the edit distance — the number of insertions and deletions —
between the predicted and the reference compressions, both as bags-of-tokens. In contrast
to the previous loss functions, it requires the true positive counts to be clipped to the
number of occurrences of each type in the reference. The edit distance is given by:
X
∆edit (d∗ , d) = p + r − 2
min(pi , qi )
(13)
i

where p and q denote the number of target tokens in the predicted tree, target(d), and
reference, y∗ = target(d∗ ), respectively, and pi and qi are the counts for type i. The loss
arguments for the edit distance consist of a vector of counts for each item type in the
reference, {pi , ∀i}. The space of possible values is exponential in the size of the source tree,
compared to quadratic for the Hamming losses. Consequently, we expect beam search to
result in many more search errors when using the edit distance loss.
Our last loss function is the F1 measure, a harmonic mean between precision and recall,
measured over bags-of-tokens. As with the edit distance, its calculation requires the counts
to be clipped to the number of occurrences of each terminal type in the reference. We
657

Cohn & Lapata

Ref:
Pred:

[S [WHNP [WP what]] [S [NP [NNS records]] [VP [VBP are] [VP [VBN involved]]]]]
[S [WHNP [WP what]] [S [NP [NNS ones]] [VP [VBP are] [VBN involved]]]]
Loss
Token Hamming
3-gram Hamming
CFG Hamming
Edit distance
F1

Arguments
T P = 3, F P = 1
T P = 8, F P = 5
T P = 8, F P = 1
p = (1, 0, 1, 1, 1)
p = (1, 0, 1, 1, 1)

Value
1/4
5/14
1/9
2
1/4

Table 1: Loss arguments and values for the example predicted and reference compressions.
Note that loss values should not be compared between different loss functions;
these values are purely illustrative.

therefore use the same loss arguments for its calculation. The F1 loss is given by:
∆F1 (d∗ , d) = 1 −
P

min(p ,q )

2 × precision × recall
precision + recall
P

(14)

min(p ,q )

where precision = i p i i and recall = i q i i . As F1 shares the same arguments
with the edit distance loss, it also has the same exponential space of loss argument values
and will consequently be subject to severe pruning during the beam search used in training.
To illustrate the above loss functions, we present an example in Table 1. Here, the
prediction (Pred) and reference (Ref) have the same length (4 tokens), identical syntactic
structure, but differ by one word (ones versus records). Correspondingly, there are three
correct tokens and one incorrect, which forms the arguments for the token Hamming loss,
resulting in a loss of 1/4. The ngram loss is measured for n ≤ 3 and the start and end of the
string are padded with special symbols to allow evaluation of the boundary ngrams. The
CFG loss records only one incorrect CFG production (the preterminal [NNS ones]) from the
total of nine productions. The last two losses use the same arguments: a vector with values
for the counts of each reference type. The first four cells correspond to what, records, are
and involved, the last cell records all other types. For the example, the edit distance is two
(one deletion and one insertion) while the F1 loss is 1/4 (precision and recall are both 3/4).

4. Features
Our feature space is defined over source trees, x, and target derivations, d. We devised two
broad classes of features, applying to grammar rules and to ngrams of target terminals. We
defined only a single ngram feature, the conditional log-probability of a trigram language
model. This was trained on the BNC (100 million words) using the SRI Language Modeling
toolkit (Stolcke, 2002), with modified Kneser-Ney smoothing.
For each rule hX,Y i → hα, γ, ∼i, we extract features according to the templates detailed
below. Our templates give rise to binary indicator features, except where explicitly stated.
These features perform a boolean test, returning value 1 when the test succeeds and 0
otherwise. An example rule and its corresponding features are shown in Table 2.
658

Sentence Compression as Tree Transduction

Type: Whether the rule was extracted from the training set, created as a copy rule and/or
created as a delete rule. This allows the model to learn a preference for each of the
three sources of grammar rules (see row Type in Table 2)
Root: The root categories of the source, X, and target, Y , and their conjunction, X ∧ Y
(see rows Root in Table 2).
Identity: The source side, α, target side, γ, and the full rule, (α, γ, ∼). This allows the
model to learn weights on individual rules or those sharing an elementary tree. Another feature checks if the rule’s source and target elementary trees are identical, α = γ
(see rows Identity in Table 2).
Unlexicalised Identity: The identity feature templates above are replicated for unlexicalised elementary trees, i.e., with the terminals removed from their frontiers (see
rows UnlexId in Table 2).
Rule count: This feature is always 1, allowing the model to count the number of rules
used in a derivation (see row Rule count in Table 2).
Word count: Counts the number of terminals in γ, allowing a global preference for
shorter or longer output. Additionally, we record the number of terminals in the
source tree, which can be used with the target terminal count to find the number of
deleted terminals (see rows Word count in Table 2).
Yield: These features compare the terminal yield of the source, Y (α), and target, Y (γ).
The first feature checks the identity of two sequences, Y (α) ∧ Y (γ). We use identity
features for each terminal in both yields, and for each terminal only in the source (see
rows Yield in Table 2). We also replicate these feature templates for the sequence of
non-terminals on the frontier (pre-terminals or variable non-terminals).
Length: Records the difference in the lengths of the frontiers of α and γ, and whether
the target’s frontier is shorter than that of the source (see rows Length in Table 2).
The features listed above are defined for all the rules in the grammar. This includes
the copy and delete rules, as described in Section 3.2, which were added to address the
problem of unseen words or productions in the source trees at test time. Many of these
rules can not be applied to the training set, but will receive some weight because they share
features with rules that can be used in training. However, in training the model learns to
disprefer these coverage rules as they are unnecessary to model the training set, which can
be described perfectly using the extracted transduction rules. Our dual use of the training
set for grammar extraction and parameter estimation results in a bias against the coverage
rules. The bias could be addressed by extracting the grammar from a separate corpus, in
which case the coverage rules would then be useful in modeling both the training set and the
testing sets. However, this solution has its own problems, namely that many of the target
trees in the training may not longer be reachable. This bias and its possible solutions is an
interesting research problem and deserves further work.
659

Cohn & Lapata

Rule: hNP,NNSi → h[NP CD  ADJP  [NNS activists]], [NNS activists]i
Type
type = training set
1
Root
X = NP
1
Root
Y = NNS
1
Root
X = NP ∧ Y = NNS
1
Identity
α = [NP CD ADJP [NNS activists]]
1
Identity
γ = [NNS activists]
1
Identity α = [NP CD  ADJP  [NNS activists]] ∧ γ = [NNS activists]
1
UnlexId.
unlex. α = [NP CD ADJP NNS]
1
UnlexId.
unlex. γ = NNS
1
UnlexId.
unlex. α = [NP CD  ADJP  NNS] ∧ γ = NNS
1
Rule count
–
1
Word count
target terminals
1
Word count
source terminals ≥ 1∗
Yield
source = [‘activists’] ∧ target = [‘activists’]
1
Yield
terminal ‘activists’ in both source and target
1
Yield
non-terms. source = [CD, ADJP, NNS] ∧ target = [NNS]
1
Yield
non-terminal CD in source and not target
1
Yield
non-terminal ADJP in source and not target
1
Yield
non-terminal NNS in both source and target
1
Length
difference in length
2
Length
target shorter
1
Table 2: Features instantiated for the synchronous rule shown above. Only features with
non-zero values are displayed. ∗ The number of source terminals is calculated using
the source tree at the time the rule is applied.

5. Experimental Set-up
In this section we present our experimental set-up for assessing the performance of the
sentence compression model described above. We give details of the corpora used, briefly
introduce McDonald’s (2006) model used for comparison with our approach, and explain
how system output was evaluated.
5.1 Corpora
We evaluated our system on three publicly available corpora. The first is the Ziff-Davis
corpus, a popular choice in the sentence compression literature. The corpus originates
from a collection of news articles on computer products. It was created automatically by
matching sentences that occur in an article with sentences that occur in an abstract (Knight
& Marcu, 2002). The other two corpora11 were created manually; annotators were asked to
produce target compressions by deleting extraneous words from the source without changing
the word order (Clarke & Lapata, 2008). One corpus was sampled from written sources,
11. Available from http://homepages.inf.ed.ac.uk/s0460084/data/.

660

Sentence Compression as Tree Transduction

Corpus
CLspoken
CLwritten
Ziff-Davis

Articles
50
82
–

Sentences
1370
1433
1084

Training
882
908
1020

Development
78
63
32

Testing
410
462
32

Table 3: Sizes of the various corpora, measured in articles or sentence pairs. The data split
into training, development and testing sets is measured in sentence pairs.

the British National Corpus (BNC) and the American News Text corpus, whereas the other
was created from manually transcribed broadcast news stories. We will henceforth refer
to these two corpora as CLwritten and CLspoken, respectively. The sizes of these three
corpora are shown in Table 3.
These three corpora pose different challenges to a hypothetical sentence compression
system. Firstly, they are representative of different domains and text genres. Secondly,
they have different compression requirements. The Ziff-Davis corpus is more aggressively
compressed in comparison to CLspoken and CLwritten (Clarke & Lapata, 2008). As CLspoken is a speech corpus, it often contains incomplete and ungrammatical utterances and
speech artefacts such as disfluencies, false starts and hesitations. Its utterances have varying lengths, some are very wordy whereas others cannot be reduced any further. This means
that a compression system should leave some sentences uncompressed. Finally, we should
note the CLwritten has on average longer sentences than Ziff-Davis or CLspoken. Parsers
are more likely to make mistakes on long sentences which could potentially be problematic
for syntax-based systems like the one presented here.
Although our model is capable of performing any editing operation, such as reordering
or substitution, it will not learn to do so from the training corpora. These corpora contain
only deletions, and therefore the model will not learn transduction rules encoding, e.g.,
reordering. Instead the rules encode only the deleting and inserting terminals and restructuring internal nodes of the syntax tree. However, the model is capable general text
rewriting, and given the appropriate training set will learn to perform these additional
edits. This is demonstrated by our recent results from adapting the model to abstractive
compression (Cohn & Lapata, 2008), where any edit is permitted, not just deletion.
Our experiments on CLspoken and CLwritten followed Clarke and Lapata’s (2008) partition of training, test, and development sets. The partition sizes are shown in Table 3. In
the case of the Ziff-Davis corpus, Knight and Marcu (2002) had not defined a development
set. Therefore we randomly selected (and held-out) 32 sentence pairs from their training
set to form our development set.
5.2 Comparison with State-of-the-Art
We evaluated our results against McDonald’s (2006) discriminative model. In this approach,
sentence compression is formalized as a classification task: pairs of words from the source
sentence are classified as being adjacent or not in the target compression. Let x = x1 , . . . , xN
denote a source sentence with a target compression y = y1 , . . . , yM where each yi occurs
in x. The function L(yi ) ∈ {1 . . . N } maps word yi the target to the index of the word in
661

Cohn & Lapata

the source (subject to the constraint that L(yi ) < L(yi+1 )). McDonald defines the score of
a compression y for a sentence x as the dot product between a high dimensional feature
representation, f , over bigrams and a corresponding weight vector, w,
score(x, y; w) =

M
X

hw, f (x, L(yj−1 ), L(yj ))i

(15)

i=2

Decoding in this framework amounts to finding the combination of bigrams that maximize
the scoring function in (15). The maximization is solved using a semi-Markov Viterbi
algorithm (McDonald, 2006).
The model parameters are estimated using the Margin Infused Relaxed Algorithm
(MIRA Crammer & Singer, 2003), a discriminative large-margin online learning technique.
McDonald (2006) uses a similar loss function to our Hamming loss (see (12)) but without
an explicit length penalty. This loss function counts the number of words falsely retained or
dropped in the predicted target relative to the reference. McDonald employs a rich feature
set defined over words, parts of speech, phrase structure trees, and dependencies. These are
gathered over adjacent words in the compression and the words which were dropped.
Clarke and Lapata (2008) reformulate McDonald’s (2006) model in the context of integer
linear programming (ILP) and augment it with constraints ensuring that the compressed
output is grammatically and semantically well formed. For example, if the target sentence
has negation, this must be included in the compression; If the source verb has a subject,
this must also be retained in the compression. They generate and solve an ILP for every
source sentence using the branch-and-bound algorithm. Since they obtain performance
improvements over McDonald’s model on several corpora, we also use it for comparison
against our model.
To summarize, we believe that McDonald’s (2006) model is a good basis for comparison
for several reasons. First, it is has good performance, and can be treated as a state-of-theart model. Secondly, it is similar to our model in many respects – its training algorithm
and feature space – but differs in one very important respect: compression is performed
on strings and not trees. McDonald’s system does make use of syntax trees, but only
peripherally via the feature set. In contrast, the syntax tree is an integral part of our
model.
5.3 Evaluation
In line with previous work we assessed our model’s output by eliciting human judgments.
Following Knight and Marcu (2002), we conducted two separate experiments. In the first
experiment participants were presented with a source sentence and its target compression
and asked to rate how well the compression preserved the most important information from
the source sentence. In the second experiment, they were asked to rate the grammaticality
of the compressed outputs. In both cases they used a five point rating scale where a high
number indicates better performance. We randomly selected 20 sentences from the test
portion of each corpus. These sentences were compressed automatically by our system and
McDonald’s (2006) system. We also included gold standard compressions. Our materials
thus consisted of 180 (20 × 3 × 3) source-target sentences. A Latin square design ensured
that subjects did not see two different compressions of the same sentence. We collected
662

Sentence Compression as Tree Transduction

ratings from 30 unpaid volunteers, all self reported native English speakers. Both studies
were conducted over the Internet using WebExp,12 a software package for running Internetbased experiments.
We also report results using F1 computed over grammatical relations (Riezler et al.,
2003). Although F1 conflates grammaticality and importance into a single score, it nevertheless has been shown to correlate reliably with human judgments (Clarke & Lapata,
2006). Furthermore, it can be usefully employed during development for feature engineering and parameter optimization experiments. We measured F1 over directed and labeled
dependency relations. For all models the compressed output was parsed using the RASP
dependency parser (Briscoe & Carroll, 2002). Note that we could extract dependencies directly from the output of our model since it generates trees in addition to strings. However,
we refrained from doing this in order to compare all models on an equal footing.

6. Results
The framework presented in Section 3 is quite flexible. Depending on the grammar extraction strategy, choice of features, and loss function, different classes of models can be derived.
Before presenting our results on the test set we discuss the specific model employed in our
experiments and explain how its parameters were instantiated.
6.1 Model Selection
All our parameter tuning and model selection experiments were conducted on the development set of the CLspoken corpus. We obtained syntactic analyses for source and target
sentences with Bikel’s (2002) parser. The corpus was automatically aligned using an algorithm which finds the set of deletions which transform the source into the target. This is
equivalent to the minimum edit distance script when only deletion operations are permitted.
As expected, the predicted parse trees contained a number of errors, although we did
not have gold standard trees with which to quantify this error or its effect on prediction
output. We did notice, however, that errors in the source trees in the test set did not always
negatively affect the performance of the model. In many instances the model was able to
recover from these errors and still produce good output compressions. Of these recoveries,
most cases involved either deleting the erroneous structure or entirely preserving it. While
this often resulted in a poor output tree, the string yield was acceptable in most cases. Less
commonly, the model corrected the errors in the source using tree transformation rules.
These rules were acquired from the training set where there were errors in the source tree
but not in the test tree. For example, one transformation allows a prepositional phrase to
be moved from a high VP attachment to an object NP attachment.
We obtained a synchronous tree substitution grammar from the CLspoken corpus using
the method described in Section 3.2. We extracted all maximally general synchronous rules.
These were complemented with specified rules allowing recursion up to one ancestor for any
given node.13 Grammar rules were represented by the features described in Section 4.
An important parameter in our modeling framework is the choice of loss function. We
12. See http://www.webexp.info/.
13. Rules were pruned so as to have no more than 5 variables and 15 nodes.

663

Cohn & Lapata

Losses
Hamming (tokens)
Hamming (ngram)
Hamming (CFG)
Edit Distance
F1
Reference

Rating
3.38
3.28
3.22
3.30
3.15
4.28

Std. dev
1.05
1.13
0.91
1.20
1.13
0.70

Table 4: Mean ratings on system output (CLspoken development set) while using different
loss functions.

evaluated the loss functions presented in Section 3.6 as follows. We performed a grid search
for the hyper-parameters (a regularization parameter and a feature scaling parameter, which
balances the magnitude of the feature vectors with the scale of the loss function)14 which
minimized the relevant loss on the development set, and used the corresponding system
output. The gold standard derivation was selected using the maximum number of rules
heuristic, as described in Section 3.5. The beam was limited to 100 unique items or 200 items
in total. The grammar was filtered to allow no more than 50 target elementary trees for
every source elementary tree.
We next asked two human judges to rate on a scale of 1 to 5 the system’s compressions
when optimized for the different loss functions. To get an idea of the quality of the output
we also included human-authored reference compressions. Sentences given high numbers
were both grammatical and preserved the most important information. The mean ratings
are shown in Table 4. As can be seen the differences among the losses are not very large,
and the standard deviation is high. The Hamming loss over tokens performed best with a
mean rating of 3.38, closely followed by the edit distance (3.30). We chose the former over
the latter as it is less coarsely approximated during search. All subsequent experiments
report results using the token-based Hamming loss.
We also wanted to investigate how the synchronous grammar influences performance.
The default system described above used general rules together with specialized rules where
the recursion depth was limited to one. We also experimented with a grammar that uses
specialised rules with a maximum recursion depth of two and a grammar that uses solely the
maximally general rules. In Table 5 we report the average compression rate, relations-based
F1 and the Hamming loss over tokens for these different grammars. We see that adding
the specified rules allows for better F1 (and loss) despite the fact that the search space
remains the same. We observe a slight degradation in performance moving to depth ≤ 2
rules. This is probably due to the increase in spurious ambiguity affecting search quality,
and also allowing greater overfitting of the training data. The number of transduction rules
in the grammar also grows substantially with the increased depth – from 20,764 for the
maximally general extraction technique to 33,430 and 62,116 for specified rules with depth
14. We found that setting the regularization parameter C = 0.01 and the scaling parameter to 1 generally
yields good performance across loss functions.

664

Sentence Compression as Tree Transduction

Model
max general rules
depth ≤ 1-specified rules∗
depth ≤ 2-specified rules
max rules∗
max scoring
unigram LM
bigram LM
trigram LM∗
all features∗
only rule features
only token features

Compression rate
80.79
79.72
79.71
79.72
81.03
76.83
83.12
79.72
79.72
83.06
85.10

Relations F1
65.04
68.56
66.44
68.56
65.54
59.05
67.71
68.56
68.56
67.51
68.31

Loss
341
315
328
315
344
336
317
315
315
346
341

Table 5: Parameter exploration and feature ablation studies (CLspoken development set).
The default system is shown with an asterisk.

≤ 1 and ≤ 2, respectively. The growth in grammar size is exponential in the specification
depth and therefore only small values should be used.
We also inspected the rules obtained with the maximally general extraction technique
to better assess how our rules differ from those obtained from a vanilla SCFG (see Knight &
Marcu, 2002). Many of these rules (12%) have deeper structure and therefore would not be
licensed by an SCFG. This is due to structural divergences between the source and target
syntax trees in the training set. A further 13% of the rules describe a change of syntactic
category (X 6= Y ), and therefore only the remaining 76% of the rules would be allowable in
Knight and Marcu’s transducer. The proportion of SCFG rules decreases substantially as
the rule specification depth is increased.
Recall from Section 3.3 that our scoring function is defined over derivations rather than
target trees or strings, and that we treat the derivation using the maximum number of rules
as the gold standard derivation. As a sanity check, we also experimented with selecting the
derivation with the maximum score under the model. The results in Table 5 indicate that
the latter strategy is not as effective as selecting the derivation with the maximum number
of rules. Again we conjecture this is due to overfitting. As the training data is used to
extract the grammar, the derivations with the maximum score may consist of rules with
rare features which model the data well but do not generalize to unseen instances.
Finally, we conducted a feature ablation study to assess which features are more useful
to our task. We were particularly interested to see if the ngram features would bring
any benefit, especially since they increase computational complexity during decoding and
training. We experimented with a unigram, bigram, and trigram language model. Note that
the unigram language model is not as computationally expensive as the other two models
because there is no need to record ngram contexts in the chart. As shown in Table 5, the
unigram language model is substantially worse than the bigram and trigram which deliver
similar performances. We also examined the impact of the other features by grouping them
into two broad classes, those defined over rules and those defined over tokens. Our aim was
to see whether the underlying grammar (represented by rule-based features) contributes
665

Cohn & Lapata

to better compression output. The results in Table 5 reveal that the two feature groups
perform comparably. However, the model using only token-based features tends to compress
less. These features are highly lexicalized, and the model is not able to generalize well on
unseen data. In conclusion, the full feature set does better on all counts than the two
ablation sets, with a better compression rate.
The results reported have all been measured over string output. This was done by first
stripping the tree structure from the compression output, reparsing, extracting dependency
relations and finally comparing to the dependency relations in the reference. However, we
may wish to measure the quality of the trees themselves, not just their string yield. A
simple way to measure this15 would be to extract dependency relations directly from the
phrase-structure tree output.16 Compared to dependencies extracted from the predicted
parses using Bikel’s (2002) parser on the output string, we observe that the relation F1
score increases uniformly for all tasks, by between 2.50% and 4.15% absolute. Therefore
the system’s tree output better encodes the syntactic dependencies than the tree resulting
from re-parsing the string output. If the system is part of a NLP pipeline, and its output
is destined for down-stream processing, then having an accurate syntax tree is extremely
important. This is also true for related tasks where the desired output is a tree, e.g.,
semantic parsing.

7. Model Comparison
In this section we present our results on the test set using the best performing model from
the previous section. This model uses a grammar with unlexicalized and lexicalized rules
(recursion depth 1), a Hamming loss based on tokens, and all the features from Section 4.
The model was trained separately on each corpus (training portion). We first discuss our
results using relations F1 and then move on to the human study.
Table 6 illustrates the performance of our model (Transducer1) on CLspoken, CLwritten, and Ziff Davis. We also report results on the same corpora using McDonald’s (2006)
model (McDonald) and the improved version (Clarke ILP) put forward by Clarke and
Lapata (2008). We also present the compression rate for each system and the reference gold
standard. In all cases our tree transducer model outperforms McDonald’s original model
and the improved ILP-based version.
Nevertheless, it may be argued that our model has an unfair advantage here since it
tends to compress less than the other models, and is therefore less likely to make many
mistakes. To ensure that this is not the case, we created a version of our model with a
compression rate similar to McDonald. This can be done relatively straightforwardly
by manipulating the length penalty of the Hamming loss. The smaller the penalty the
more words the model will tend to drop. Therefore, we varied the length penalty (and
hyper-parameters) on the development set in order to obtain a compression rate similar to
15. We could alternatively measure other tree metrics, such as tree edit distance. However, the standard
measures used in parser evaluation (e.g., EVALB) would not be suitable, as they assume that the parse
yield is fixed. In our case the reference target string is often different to the system’s output.
16. We extract dependency relations with the conversion tool from the CoNLL 2007 shared task, available
at http://nlp.cs.lth.se/pennconverter/.

666

Sentence Compression as Tree Transduction

Model
Transducer1
Transducer2
McDonald
Clarke ILP
Reference

CLspoken
Compression rate
82.30
69.89
68.56
77.70
76.11

Relations F1
66.63
59.58
47.48
54.12
–

Model
Transducer1
Transducer2
McDonald
Clarke ILP
Reference

CLwritten
Compression rate
76.52
61.09
60.12
71.99
70.24

Relations F1
58.02
49.48
48.39
54.84
–

Model
Transducer1
McDonald
Clarke ILP
Reference

Ziff Davis
Compression rate
67.45
66.26
48.67
56.61

Relations F1
56.55
54.12
46.77
–

Table 6: Results on CLspoken, CLwritten, and Ziff Davis corpus (testing set); compression
rate and relations-based F1.

McDonald.17 This model was then applied to the test set and its performance is shown
in Table 6 as Transducer2. We refrained from doing this on Ziff-Davis, since our original
transducer obtained a compression rate comparable to McDonald (67.45 vs. 66.26). As
can be seen, Transducer2 yields a better F1 on CLspoken and CLwritten. The differences
in F1 are statistically significant using the the Wilcoxon test (p < 0.01). Transducer1
numerically outperforms McDonald on Ziff-Davis, however the difference is not significant
(the Ziff-Davis test set consists solely of 32 sentences).
We next consider the results of our judgment elicitation study which assesses in more
detail the quality of the generated compressions. Recall that our participants judge compressed output on two dimensions, grammaticality and importance. We compared the
output of our system (Transducer2 on CLspoken and CLwritten and Transducer1 on
Ziff-Davis) against the output of McDonald (2006) and the reference gold standard. Table 7
illustrates examples of the compressions our participants saw.
17. We matched the compression rate of McDonald by scaling the length penalty by 0.50 and 0.25 for the
CLwritten and CLspoken corpora, respectively. Another way to control the compression rate would be
to modify our chart-based decoder in a fashion similar to McDonald (2006). However, we leave this to
future work.

667

Cohn & Lapata

S: I just wish my parents and my other teachers could be like this teacher, so
we could communicate.
M: I wish my teachers could be like this teacher.
T: I wish my teachers could be like this, so we could communicate.
R: I wish my parents and other teachers could be like this, so we could
communicate.
S: The Treasury is refusing to fund a further phase of the city technology
colleges.
M: The Treasury is refusing to fund a further colleges.
T: The Treasury is refusing to fund the city technology colleges.
R: The Treasury is refusing to fund further the city technology colleges.
S: Apparel makers use them to design clothes and to quickly produce and
deliver the best-selling garments.
M: Apparel makers use them to design clothes and to produce and deliver the
best-selling garments.
T: Apparel makers use them to design clothes.
R: Apparel makers use them to design clothes.
S: Earlier this week, in a conference call with analysts, the bank said it boosted
credit card reserves by $350 million.
M: Earlier said credit card reserves by $350 million.
T: In a conference call with analysts, the bank boosted card reserves by $350
million.
R: In a conference call with analysts the bank said it boosted credit card
reserves by $350 million.
Table 7: Compression examples from CLspoken, CLwritten, and Ziff-Davis (S: source sentence, M: McDonald, 2006, T: transducer, R: reference gold standard)

Table 8 shows the mean ratings18 for each system (and the reference) on CLspoken,
CLwritten, and Ziff-Davis. We carried out an Analysis of Variance (Anova) to examine
the effect of system type (McDonald, Transducer, Reference) on the compression ratings. The Anova revealed a reliable effect on all three corpora. We used post-hoc Tukey
tests to examine whether the mean ratings for each system differed significantly (p < 0.01).
On the CLspoken corpus the Transducer is perceived as significantly better than McDonald, both in terms of grammaticality and importance. We obtain the same result for
the CLwritten corpus. The two systems achieve similar performances on Ziff-Davis (the
grammaticality and importance score do not differ significantly). Ziff-Davis seems to be
a less challenging corpus than CLspoken or CLwritten and less likely to highlight differences among systems. For example, Turner and Charniak (2005) present several variants of
the noisy-channel model, all of which achieve compressions of similar quality on Ziff-Davis
(grammaticality ratings varied by only ±0.13 and informativeness ratings ±0.31 in their
human evaluation). In most cases the Transducer and McDonald yield significantly
18. All statistical tests reported subsequently were done using the mean ratings.

668

Sentence Compression as Tree Transduction

Model
Transducer
McDonald
Reference

CLspoken
Grammaticality
4.18∗
2.74†
4.58

Importance
3.98∗
2.51†
4.22

Model
Transducer
McDonald
Reference

CLwritten
Grammaticality
4.06†∗
3.05†
4.52

Importance
3.21†∗
2.82†
3.70

Model
Transducer
McDonald
Reference

Ziff-Davis
Grammaticality
4.07†
3.98†
4.65

Importance
3.23†
3.22†
4.12

Table 8: Mean ratings on compression output elicited by humans (∗ : sig. diff. from McDonald (α < 0.01); † : sig. diff. from Reference (α < 0.01); using post-hoc Tukey
tests)

worse performance than the Reference, save one exception. On the CLspoken corpus, there
is no significant difference between the Transducer and the gold standard.
These results indicate that our highly expressive framework is a good model for sentence compression. Under several experimental conditions, across different domains, we
obtain better performance than previous work. Importantly, the model described here is
not compression-specific, it could be easily adapted to other tasks, corpora or languages (for
which syntactic analysis tools are available). Being supervised, the model learns to fit the
compression rate of the training data. In this sense, it is somewhat inflexible as it cannot
easily adapt to a specific rate given by a user or imposed by an application (e.g., when
displaying text on small screens). Nevertheless, compression rate can be indirectly manipulated by adopting loss functions that encourage or discourage compression or directly
during decoding by stratifying the chart for length (McDonald, 2006).

8. Conclusions
In this paper we have formulated sentence compression as a tree-to-tree rewriting task.19
We developed a system that licenses the space of all possible rewrites using a tree substitution grammar. Each grammar rule is assigned a weight which is learned discriminatively
within a large margin model (Tsochantaridis et al., 2005). A specialized algorithm is used to
learn the model weights and find the best scoring compression under the model. We argue
19. The source code is freely available from http://homepages.inf.ed.ac.uk/tcohn/t3.

669

Cohn & Lapata

that the proposed framework is appealing for several reasons. The synchronous grammar
provides expressive power to capture rewrite operations that go beyond word deletion such
as reordering, changes in non-terminal categories and lexical substitution. Since it is not
deletion-specific, the model could be ported to other rewriting tasks (see Cohn & Lapata,
2008, for an example) without the overhead of devising new algorithms for decoding or
training. Moreover, the discriminative nature of the learning algorithm allows for the incorporation of all manner of powerful features. The rich feature space in conjunction with
the choice of an appropriate loss function afford greater flexibility in fitting the empirical
data for different domains or tasks.
We evaluated our model on three compression corpora (CLspoken, CLwritten, and ZiffDavis) and showed that in most cases it yields results superior to state-of-the-art (McDonald, 2006). Our experiments were also designed to assess several aspects of the proposed
framework such as the complexity of the synchronous grammar, the choice of loss function,
the effect of various features, and the quality of the generated tree output. We observed
performance improvements by allowing maximally general grammar rules to be specified
once, producing larger and more lexicalized rules. This concurs with Galley and McKeown
(2007) who also find that lexicalization yields better compression output. The choice of
loss function appears to have less of an effect. We devised three classes of loss functions
based on Hamming distance, Edit distance and F1 score. Overall, the simple token-based
Hamming loss achieved the best results. We conjecture that this is due to its simplicity – it
can be evaluated more precisely than many of the other loss functions and isn’t affected by
poor parser output. Our feature ablation study revealed that ngram features are beneficial,
mirroring a similar finding in the machine translation literature (Chiang, 2007). Finally, we
found that the trees created by our generation algorithm are more accurate compared to the
output of a parser applied to the string output. This augurs well for use in a cascaded NLP
pipeline, where other systems use the compression output as input for further processing,
and can potentially make better use of the system output.
Future extensions are many and varied. An obvious extension concerns porting the
framework to other rewriting applications such as document summarization (Daumé III &
Marcu, 2002) or machine translation (Chiang, 2007). Initial work (Cohn & Lapata, 2008)
shows that the tree-to-tree transduction model presented here can be easily adapted to a
sentence abstraction task where compression takes place using rewrite operations that are
not restricted to word deletion. Examples include substitution, reordering, and insertion.
Other future directions involve more detailed feature engineering, including source conditioned features and ngram features besides the language model. More research is needed
to establish suitable loss functions for compression and other rewriting tasks. In particular
it should be interesting to experiment with loss functions that incorporate a wider range
of linguistic features beyond parts of speech. Examples include losses based on parse trees
and semantic similarity. Finally, the experiments presented in this work use a grammar
acquired from the training corpus. However, there is nothing inherent in our formalization
that restricts us to this particular grammar. We therefore plan to investigate the potential of our method with unsupervised or semi-supervised grammar induction techniques for
other rewriting tasks including paraphrase generation and machine translation.
670

Sentence Compression as Tree Transduction

Acknowledgments
We are grateful to Philip Blunsom for insightful comments and suggestions and to the
anonymous referees whose feedback helped to substantially improve the present paper.
Special thanks to James Clarke for sharing his implementations of Clarke and Lapata’s
(2008) and McDonald’s (2006) models with us. We acknowledge the support of EPSRC
(grants GR/T04540/01 and GR/T04557/01). This work has made use of the resources
provided by the Edinburgh Compute and Data Facility (ECDF). The ECDF is partially
supported by the eDIKT initiative. A preliminary version of this work was published in the
proceedings of EMNLP/CoNLL 2007.

References
Aho, A. V., & Ullman, J. D. (1969). Syntax directed translations and the pushdown assembler. Journal of Computer and System Sciences, 3, 37–56.
Alshawi, H., Bangalore, S., & Douglas, S. (2000). Learning dependency translation models
as collections of finite state head transducers. Computational Linguistics, 26 (1), 45–
60.
Berger, A. L., Pietra, S. A. D., & Pietra, V. J. D. (1996). A maximum entropy approach
to natural language processing. Computational Linguistics, 22 (1), 39–71.
Bikel, D. (2002). Design of a multi-lingual, parallel-processing statistical parsing engine.
In Proceedings of the 2nd International Conference on Human Language Technology
Research, pp. 24–27, San Diego, CA.
Briscoe, E. J., & Carroll, J. (2002). Robust accurate statistical annotation of general text. In
Proceedings of the Third International Conference on Language Resources and Evaluation, pp. 1499–1504, Las Palmas, Gran Canaria.
Carroll, J., Minnen, G., Pearce, D., Canning, Y., Devlin, S., & Tait, J. (1999). Simplifying
text for language impaired readers. In Proceedings of the 9th Conference of the European Chapter of the Association for Computational Linguistics, pp. 269–270, Bergen,
Norway.
Chandrasekar, R., & Srinivas, C. D. B. (1996). Motivations and methods for text simplification. In Proceedings of the 16th International Conference on Computational
Linguistics, pp. 1041–1044, Copenhagen, Danemark.
Chiang, D. (2007). Hierarchical phrase-based translation. Computational Linguistics, 33 (2),
201–228.
Clarke, J., & Lapata, M. (2006). Models for sentence compression: A comparison across
domains, training requirements and evaluation measures. In Proceedings of the 21st
International Conference on Computational Linguistics and 44th Annual Meeting of
the Association for Computational Linguistics, pp. 377–384, Sydney, Australia.
Clarke, J., & Lapata, M. (2008). Global inference for sentence compression: An integer linear
programming approach. Journal of Artificial Intelligence Research, 31, 399–429.
671

Cohn & Lapata

Cohn, T., & Lapata, M. (2008). Sentence compression beyond word deletion. In Proceedings of the 22nd International Conference on Computational Linguistics, pp. 137–144,
Manchester, UK.
Collins, M. (2002). Discriminative training methods for hidden Markov models: theory and
experiments with perceptron algorithms. In Proceedings of the 2002 Conference on
Empirical Methods in Natural Language Processing, pp. 1–8, Morristown, NJ.
Collins, M. J. (1999). Head-driven statistical models for natural language parsing. Ph.D.
thesis, University of Pennsylvania, Philadelphia, PA.
Crammer, K., & Singer, Y. (2003). Ultraconservative online algorithms for multiclass problems. Machine Learning, 3, 951–999.
Daumé III, H., & Marcu, D. (2002). A noisy-channel model for document compression.
In Proceedings of the 40th Annual Meeting of thev Association for Computational
Linguistics, pp. 449–456, Philadelphia, PA.
Eisner, J. (2003). Learning non-isomorphic tree mappings for machine translation. In The
Companion Volume to the Proceedings of 41st Annual Meeting of the Association for
Computational Linguistics, pp. 205–208, Sapporo, Japan.
Galley, M., Hopkins, M., Knight, K., & Marcu, D. (2004). What’s in a translation rule?.
In Proceedings of the 2004 Human Language Technology Conference of the North
American Chapter of the Association for Computational Linguistics, pp. 273–280,
Boston, MA.
Galley, M., & McKeown, K. (2007). Lexicalized Markov grammars for sentence compression.
In Proceedings of Human Language Technologies 2007: The Conference of the North
American Chapter of the Association for Computational Linguistics, pp. 180–187,
Rochester, NY.
Grael, J., & Knight, K. (2004). Training tree transducers. In Proceedings of the 2004 Human
Language Technology Conference of the North American Chapter of the Association
for Computational Linguistics, pp. 105–112, Boston, MA.
Hermjakob, U., Echihabi, A., & Marcu, D. (2002). Natural language based reformulation
resource and wide exploitation for question answering. In Proceedings of 11th Text
Retrieval Conference, Gaithersburg, MD.
Hori, C., & Furui, S. (2004). Speech summarization: an approach through word extraction
and a method for evaluation. IEICE Transactions on Information and Systems, E87D(1), 15–25.
Jing, H. (2000). Sentence reduction for automatic text summarization. In Proceedings of
the 6th Applied Natural Language Processing Conference, pp. 310–315, Seattle, WA.
Joachims, T. (2005). A support vector method for multivariate performance measures. In
Proceedings of the 22nd International Conference on Machine Learning, pp. 377–384,
Bonn, Germany.
Kaji, N., Okamoto, M., & Kurohashi, S. (2004). Paraphrasing predicates from written
language to spoken language using the web. In Proceedings of the 2004 Human Language Technology Conference of the North American Chapter of the Association for
Computational Linguistics, pp. 241–248, Boston, MA.
672

Sentence Compression as Tree Transduction

Knight, K. (1999). Decoding complexity in word-replacement translation models. Computational Linguistics, 25 (4), 607–615.
Knight, K., & Marcu, D. (2002). Summarization beyond sentence extraction: a probabilistic
approach to sentence compression. Artificial Intelligence, 139 (1), 91–107.
Lin, D., & Pantel, P. (2001). Discovery of inference rules for question answering. Natural
Language Engineering, 7 (4), 342–360.
McDonald, R. (2006). Discriminative sentence compression with soft syntactic constraints.
In Proceedings of the 11th Conference of the European Chapter of the Association for
Computational Linguistics, pp. 297–304, Trento, Italy.
Nguyen, M. L., Horiguchi, S., Shimazu, A., & Ho, B. T. (2004). Example-based sentence
reduction using the hidden markov model. ACM Transactions on Asian Language
Information Processing, 3 (2), 146–158.
Och, F. J., & Ney, H. (2004). The alignment template approach to statistical machine
translation. Computational Linguistics, 30 (4), 417–449.
Papineni, K., Roukos, S., Ward, T., & Zhu, W.-J. (2002). BLEU: a method for automatic
evaluation of machine translation. In Proceedings of the 40th Annual Meeting of thev
Association for Computational Linguistics, pp. 311–318, Philadelphia, PA.
Petrov, S., Barrett, L., Thibaux, R., & Klein, D. (2006). Learning accurate, compact, and
interpretable tree annotation. In Proceedings of the 21st International Conference on
Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pp. 433–440, Sydney, Australia.
Riezler, S., King, T. H., Crouch, R., & Zaenen, A. (2003). Statistical sentence condensation
using ambiguity packing and stochastic disambiguation methods for lexical-functional
grammar. In Proceedings of the 2003 Human Language Technology Conference of
the North American Chapter of the Association for Computational Linguistics, pp.
118–125, Edmonton, Canada.
Shieber, S., & Schabes, Y. (1990). Synchronous tree-adjoining grammars. In Proceedings of the 13th International Conference on Computational Linguistics, pp. 253–258,
Helsinki, Finland.
Stolcke, A. (2002). SRILM – an extensible language modeling toolkit. In Proceedings of the
International Conference on Spoken Language Processing, Denver, CO.
Tsochantaridis, I., Joachims, T., Hofmann, T., & Altun, Y. (2005). Large margin methods
for structured and interdependent output variables. Journal of Machine Learning
Research, 6, 1453–1484.
Turner, J., & Charniak, E. (2005). Supervised and unsupervised learning for sentence
compression. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics, pp. 290–297, Ann Arbor, MI.
Vandeghinste, V., & Pan, Y. (2004). Sentence compression for automated subtitling: A
hybrid approach. In Text Summarization Branches Out: Proceedings of the ACL-04
Workshop, pp. 89–95, Barcelona, Spain.
673

Cohn & Lapata

Wu, D. (1997). Stochastic inversion transduction grammars and bilingual parsing of parallel
corpora. Computational Linguistics, 23 (3), 377–404.
Yamada, K., & Knight, K. (2001). A syntax-based statistical translation model. In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics,
pp. 523–530, Toulouse, France.

674

Journal of Artificial Intelligence Research 34 (2009) 133-164

Submitted 07/08; published 03/09

Generic Preferences over Subsets of Structured Objects
Maxim Binshtok
Ronen I. Brafman

MAXIMBI @ CS . BGU . AC . IL
BRAFMAN @ CS . BGU . AC . IL

Computer Science Department
Ben-Gurion University, Israel

Carmel Domshlak

DCARMEL @ IE . TECHNION . AC . IL

Faculty of Industrial Engineering and Management
Technion, Israel

Solomon E. Shimony

SHIMONY @ CS . BGU . AC . IL

Computer Science Department
Ben-Gurion University, Israel

Abstract
Various tasks in decision making and decision support systems require selecting a preferred
subset of a given set of items. Here we focus on problems where the individual items are described
using a set of characterizing attributes, and a generic preference specification is required, that is,
a specification that can work with an arbitrary set of items. For example, preferences over the
content of an online newspaper should have this form: At each viewing, the newspaper contains a
subset of the set of articles currently available. Our preference specification over this subset should
be provided offline, but we should be able to use it to select a subset of any currently available
set of articles, e.g., based on their tags. We present a general approach for lifting formalisms
for specifying preferences over objects with multiple attributes into ones that specify preferences
over subsets of such objects. We also show how we can compute an optimal subset given such a
specification in a relatively efficient manner. We provide an empirical evaluation of the approach
as well as some worst-case complexity results.

1. Introduction
Work on reasoning with preferences focuses mostly on the task of recognizing preferred elements
within a given set. However, another problem of interest is that of selecting an optimal subset of
elements. Optimal subset selection is an important problem with many applications: the choice of
feature subsets in machine learning, selection of a preferred bundle of goods (as in, e.g., a home
entertainment system), finding the best set of items to display on the user’s screen, selecting the best
set of articles for a newspaper or the best members for a committee, etc.
Earlier work on this problem has mostly focused on the question of how one can construct an
ordering over subsets of elements given an ordering over the elements of the set (Barberà, Bossert,
& Pattanaik, 2004). The main distinction made has been between sets of items that are mutually
exclusive, in the sense that only one can eventually materialize, and sets in which the items will
jointly materialize. Our formalism is agnostic on this issue, although we are clearly motivated by
the latter case. As Barberà et al. note, most past work focused on the case of mutually exclusive
elements. This, for example, would be the case if we are selecting a set of alternatives from which
some decision-maker (or nature) will ultimately choose only one (e.g., courses of action). However,

©2009 AI Access Foundation. All rights reserved.

B INSHTOK , B RAFMAN , D OMSHLAK , & S HIMONY

there is a substantial body of work on the latter setting in which items might materialize jointly, and
individual items are preferentially comparable.
This paper focuses on a somewhat different context for set-preference specification. First, we
assume that the items from which our subsets are composed are structured, in the sense that some set
of attributes is associated with them. For example, if the items are movies, these attributes could be
the genre, language, year, director; if the “items” are politicians, the attributes could be the political
views of the politicians on various topics, their party affiliation, their level of experience. Second,
we require a generic preference specification, in the sense that it can be used with diverse collections
of items. For example, if we are specifying guidelines for the composition of some committee, these
guidelines are generic, and can be used to induce a preference relation over subsets of any given set
of politicians, provided that the set of attributes is fixed. Third, we do not assume any preferential
ordering over the individual items, although that can certainly be captured by one of the attributes
describing the items.
An instructive example of the type of domain we have in mind is that of personalized online
newspapers. First, the problem of selection for a newspaper is one of subset selection – we have
to select a subset of the set of available articles to place in the newspaper. Second, the database
of articles is constantly changing. Therefore, an approach that requires explicitly specifying preferences for the inclusion of each specific item is inappropriate, both because the number of such
items is very large, and because this would require us to constantly change the preference specification as the set of items changes. Finally, we would not want to base our approach on a method for
transforming an ordering over items into an ordering over subsets of items, because we do not want
to have to rank each item, and because there are obvious instances of complementarity and substitutability. For instance, even if I prefer articles on Britney Spears to articles on any other topic, two
very similar articles about her may be less interesting than a set comprising one about her and one
about the Spice Girls.1
One recent work that considers a similar setting is that of desJardins and Wagstaff (2005), which
works by specifying preferences over more abstract properties of sets. In particular, desJardins and
Wagstaff offer a formalism for preference specification in which users can specify their preferences
about the set of values each attribute attains within the selected set of items. One could assert
whether the values attained by an attribute on the selected subset should be diverse or concentrated
around some specific value. In addition, desJardins and Wagstaff also suggest a heuristic search
algorithm for finding good, though not necessarily optimal, such sets of items.
In this work, we present a more general, two-tiered approach for dealing with set preferences in
the above setting. This approach combines a language for specifying certain types of set properties,
and an arbitrary preference specification language for expressing preferences over single, attributed
items. The basic idea is to first specify the set properties we care about, and then specify preferences
over the values of these properties. Such a specification induces a preference ordering over sets
based on the values these sets provide to the properties of interest. We believe that the suggested
approach is both intuitive and powerful. Although in this paper we focus on a particular set of
properties for which we have devised a relatively efficient optimization algorithm, in its most general
form, this two-tiered approach generalizes the approach of desJardins and Wagstaff (2005) because
diversity and specificity are just two set properties. In principle, one can express both more general
1. We realize that common rules of rationality may not apply to users with such preferences.

134

G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS

properties referring to multiple attributes, as well as more general conditional preferences over the
values of these properties.
Essentially, our approach re-states the problem of specifying preferences over sets in terms used
to specify preferences over single items. In our formulation, “items” stand for the possible sets,
and attributes of such “items” are their (user-defined) set-property values. Thus, in principle, this
approach allows us to re-use any formalism for specifying preferences over single items. In this paper we will consider two specific instantiations of such a formalism: qualitative preferences based
on CP or TCP-nets (Boutilier, Brafman, Domshlak, Hoos, & Poole, 2004; Brafman, Domshlak, &
Shimony, 2006a), and quantitative preferences represented as generalized additively independent
(GAI) value functions (Bacchus & Grove, 1995; Fishburn, 1969). The algorithm we suggest for
computing an optimal subset given qualitative preferences is based on a similar optimization algorithm for TCP-nets. But because the number of “items” in our case is very large, this algorithm is
modified substantially to exploit the special structure of these “items”. These modifications enable
us to compute an optimal subset faster.

2. Specifying Set Preferences
The formalism we use for set-preference specification makes one fundamental assumption: the
items from which sets of interest are built are described in terms of some attributes, and the values
of these attributes are what distinguishes different items. We shall use S to denote the set of individual items, and X to denote the set of attributes describing these items. For example, imagine that
the “items” in question are US senate members, and the attributes and their values are: Party affiliation (Republican, Democrat), Views (liberal, conservative, ultra conservative), and Experience
(experienced, inexperienced).
2.1 From Properties of Items to Properties of Item Sets
Given the set X of item-describing attributes, first, we can already talk about more complex item
properties, e.g., “senate members with liberal views”, or “inexperienced, conservative senate members”. More formally, let X be the union of the attribute domains, that is,
X = {X = x | X ∈ X , x ∈ Dom(X)} ,
and let LX be the propositional language defined over X with the usual logical operators. LX
provides us with a language for describing complex properties of individual items. Since items in S
can be viewed as models of LX , we can write o |= ϕ whenever o ∈ S and o is an item that satisfies
the property ϕ ∈ LX .
Given the language LX , we can now specify arbitrary properties of item sets based on the
attribute values of items in a set, such as the property of having at least two Democrats, or having
more Democrats than Republicans. More generally, given any item property ϕ ∈ LX , we can
talk about the number of items in a set that have property ϕ, which we denote by |ϕ|(S), that
is, |ϕ|(S) = |{o ∈ S|o |= ϕ}|. Often the set S is implicitly defined, and we simply write |ϕ|.
Thus, |Experience=experienced|(S) is the number of experienced members in S. Often, we simply
abbreviate this as |experienced|.
While |ϕ|(·) is an integer-valued property of sets, we can also specify boolean set properties as
follows: h|ϕ| REL ki, where ϕ ∈ LX , REL is a relational operator over integers, and k ∈ Z∗ is a
135

B INSHTOK , B RAFMAN , D OMSHLAK , & S HIMONY

non-negative integer. This property is satisfied by a set S if |{o ∈ S|o |= ϕ}| REL k. In our running
example we use the following three set properties:
• P1 : h|Party affiliation = Republican ∨ Political view = conservative| ≥ 2i
• P2 : h|Experience = experienced| ≥ 2i
• P3 : h|Political view = liberal| ≥ 1i
P1 is satisfied (only) by sets with at least two members that are either Republican or conservative.
P2 is satisfied by sets with at least 2 experienced members. P3 is satisfied by sets with at least one
liberal.
We can also write h|ϕ| REL |ψ|i, with a similar interpretation. For example, h|Republican| >
|Democrat|i holds for sets containing more Republicans than Democrats. An even more general
language could include arithmetic operators (e.g., require twice as many Republicans as Democrats)
and aggregate functions (e.g., the average number of years on the job). All these are instances of
the general notion of specifying properties of sets as a function of the attribute values of the set’s
members. In this paper, we focus on the above language with the relational operators restricted to
equalities and inequalities. We do so because having a clear, concrete setting eases the presentation,
and because restricting the language allows us to provide more efficient subset-selection algorithms.
Indeed, many of the ideas we present here apply to more general languages. In particular, this
generality holds both for the overall preference-specification methodology, and for the search-overCSPs technique for computing optimal subsets introduced later in the paper. However, the more
specific techniques we use to implement these ideas, such as bounds generation, and the specific
translation of properties into CSPs, rely heavily on the use of specific, more restrictive languages.
Finally, we note an important property of our preference specification approach of being independent of the actual set of items available at the moment. This generality is important for many
applications where the same reasoning about set preferences must be performed on different, and
often initially unknown sets of items. For example, this is the case with specifying guidelines for
selecting articles for an online newspaper, or for selecting a set of k results for an information query.
2.2 Reasoning with Set Preferences
Once we have specified the set properties of interest, we can define preferences over the values of
these properties using any preference specification formalism. Here we discuss two specific formalisms, namely TCP-nets (Brafman et al., 2006a), an extension of CP-nets (Boutilier et al., 2004),
and Generalized Additively Independent (GAI)-value functions (Bacchus & Grove, 1995; Fishburn,
1969). The former is a formalism for purely qualitative preference specification, yielding a partial
preference order over the objects of interest. The latter is a quantitative specification formalism that
can represent any value function.
Let P = {P1 , . . . , Pk } be some collection of set properties. A TCP-net over P captures statements of the following two types:
(1) Conditional Value Preference Statements. “If Pi1 = pi1 ∧ · · · ∧ Pij = pij then Pl = pl is
preferred to Pl = p0l .” That is, when Pi1 , . . . , Pij have a certain value, we prefer one value for
Pl to another value for Pl .

136

G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS

(2) Relative Importance Statements. “If Pi1 = pi1 ∧ · · · ∧ Pij = pij then Pl is more important than
Pm .” That is, when Pi1 , . . . , Pij have a certain value, we prefer a better value for Pl even if we
have to compromise on the value of Pm .
Each such statement allows us to compare between certain pairs of item sets as follows:
- The statement “if Pi1 = pi1 ∧ · · · ∧ Pij = pij then Pl = pl is preferred to Pl = p0l ” implies
that given any two sets S, S 0 for which (1) Pi1 = pi1 ∧ · · · ∧ Pij = pij holds, (2) S satisfies
Pl = pl and S 0 satisfies Pl = p0l , and (3) S and S 0 have identical values on all properties
except Pl , we have that S is preferred to S 0 .
- The statement “if Pi1 = pi1 ∧ · · · ∧ Pij = pij then Pl is more important than Pm ” implies
that given any two sets S, S 0 for which (1) Pi1 = pi1 ∧ · · · ∧ Pij = pij holds, (2) S has a more
preferred value for Pl , and (3) S and S 0 have identical values on all attributes except Pl and
Pm , we have that S is preferred to S 0 . (Notice that we do not care about the value of Pm if Pl
is improved.)
We refer the reader to the work of Brafman et al. (2006a) for more details on TCP-nets, their
graphical structure, their consistency, etc. The algorithms in this paper, when used with TCP-nets,
assume an acyclic TCP-net Brafman et al.. The latter property ensures both consistency of the
provided preferences, as well as existence of certain “good” orderings of P with respect to the
TCP-net.
As an example, consider the following preferences of the president for forming a committee.
He prefers at least two members that are either Republican or conservative, that is, he prefers P1
to P1 unconditionally. (Depending on the context, we use P to denote both the property P and the
value P = true. We use P to denote P = false.) If P1 holds, he prefers P2 over P2 (that is, at least
two experienced members), so that the committee recommendations carry more weight. If P1 holds,
he prefers P2 to P2 (that is, all but one are inexperienced) so that it would be easier to influence
their decision. The president unconditionally prefers to have at least one liberal, that is, he prefers
P3 to P3 , so as to give the appearance of balance. However, P3 is less important than both P1 and
P2 . There is an additional “external” constraint (or possibly a preference) that the total number of
members be three.2
GAI value functions map the elements of interest (item sets in our case) into real values quantifying theP
relative desirability of these elements. Structure-wise, GAI value functions have the form
U (S) = i=1,...,n Ui (Pi (S)), where each Pi ⊂ P is a subset of properties. For example, the President’s preferences imply the following GAI structure: U (S) = U1 (P1 (S), P2 (S)) + U2 (P3 (S))
because the President’s conditional preferences over P2 ’s value tie P1 and P2 together, but are independent of P3 ’s value. U1 would capture the weight of this conditional preference, combined
with the absolute preference for P1 ’s value. U2 would represent the value of property P3 . We
might quantify these preferences as follows: U1 (P1 , P2 ) = 10, U1 (P1 , P2 ) = 8, U1 (P1 , P2 ) = 2,
U1 (P1 , P2 ) = 5; while U2 (P3 ) = 1, U2 (P3 ) = 0. Of course, infinitely many other quantifications
are possible.
2. Some external constraints, such as this cardinality constraint, can be modeled as a preference with high
value/importance. In fact, this is how we model cardinality constraints in our implementation.

137

B INSHTOK , B RAFMAN , D OMSHLAK , & S HIMONY

1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:

Q ← {∅}
Sopt ← ∅
while Q contains a set S such that UB(S) > Value(Sopt ) do
S ← argmaxS 0 ∈Q UB(S 0 )
Q ← QS
\ {S 0 | LB(Sopt ) ≥ UB(S 0 )}
Q ← Q {S ∪ {o} | o ∈ S \ S}
S ← argmaxS 0 ∈Q Value(S 0 )
if Value(S) > Value(Sopt ) then
Sopt ← S
end if
end while
return Sopt
Figure 1: Subset-space branch-and-bound search for an optimal subset of available items S.

3. Finding an Optimal Subset
In general, given a preference specification and a set S of available items, our goal is to find an
optimal subset Sopt ⊆ S with respect to the preference specification. That is, for any other set
S 0 ⊆ S, we have that the properties Sopt satisfies are no less desirable than the properties S 0 satisfies.
We now consider two classes of algorithms for finding such an optimal subset. These two classes
of algorithm differ in the space in which they search. In the next section, we describe a comparative
empirical evaluation of these algorithms. For our running example we use the following set of
available items S:
o1
o2
o3
o4

Republican
Republican
Democrat
Democrat

conservative
ultra conservative
conservative
liberal

inexperienced
experienced
experienced
experienced

3.1 Searching in Sets Space
The most obvious approach for generating an optimal subset is to search directly in the space of
subsets. A priori this approach is not too attractive, and indeed, we shall see later that our implementation of this approach did not scale up. However, given that often we are interested in sets of
small size and that heuristics can be used to enhance search quality, we thought it is worth exploring
this approach.
A branch-and-bound (B&B) algorithm in the space of sets is depicted in Figure 1. For each set
S, the algorithm assumes access to an upper bound UB(S) and to a lower bound LB(S) estimates on
the maximal value of a superset of S. The algorithm maintains a queue Q of sets, and this queue is
initialized to contain only the empty set. At each step, the algorithm selects a highest upper-bound
set S from the queue. Next, the algorithm removes from Q all sets S 0 with upper bound UB(S 0 )
being at most as good as the lower bound LB(S) of the selected set S, and adds to Q all the minimal
(that is, one-item) extensions of S. The latter sets correspond to the successors of S in the search
space. Different implementations of the algorithm differ in how they sort the queue. The best-first
version depicted in the pseudo-code sorts the queue according to a heuristic value of the set, and in
138

G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS

our case this heuristic is an upper bound on the value of the set’s supersets. In contrast, the depthfirst version always positions the children of the newly expanded node at the front of the queue. We
implemented and tested both versions.
The method used to generate bounds for a set S must depend on the actual preference representation formalism, as well as on the type of set properties being used, and the idea is more natural
given a quantitative value function. For a lower bound LB(S) we can use the actual value Value(S)
of S. Note that it is possible that all descendants of S will have lower values because, in general,
set-properties may not be monotonic (e.g., “average value higher than 5.”) However, since S itself
is a possible solution, this is a valid lower bound.
For an upper bound, we proceed as follows: First, we consider which set-property values are
consistent with S. That is, for each set property, we examine what values S and any of its supersets
can potentially provide to that property. For example, consider P2 and suppose S contains a single
experienced member. So currently, P2 holds. However, we can satisfy P2 if we add one more
experienced member. Thus, both values of P2 are consistent with S. In contrast, if we had two
experienced members in S, then P2 is inconsistent with S because no matter who we add to S,
we can never satisfy P2 . Next, given such sets of possible set-properties’ values with respect to
the set S, we can bound the value of S and of any of its supersets by maximizing values locally.
Specifically, in a GAI value function, we can look at each local function Ui , and consider which
assignment to it, from among the consistent values, would maximize Ui . Clearly, this may result
in an overall value overestimation, since we do not know whether these “locally optimizing” joint
assignments are consistent. Similar ideas can be used with other quantitative representations, as
in various soft-constraint formalisms (Bistarelli, Fargier, Montanari, Rossi, Schiex, & Verfaillie,
1999).
Consider our running example with the GAI value function as at the end of Section 2, and
consider searching for an optimal subset of S = {o1 , o2 , o3 , o4 } using a depth-first version of B&B.
We start with the empty set, and the property values provided by the empty set are P1 , P2 , P3 . Thus,
the lower bound LB(∅), which is the value of the empty-set, is 5. For the upper bound UB(∅), we
consider the best property values that are individually consistent with the extensions of ∅, which
are P1 , P2 , P3 , and their accumulative value is 11. Sopt is also initialized to the empty set, and
next we generate all of the children of the (only possible) selected set ∅, which are all singleton
sets: {o1 }, {o2 }, {o3 }, {o4 }. Except for {o4 }, they all have lower and upper bounds identical to
those of the empty set, and are inserted into the queue. {o4 } has a lower bound of 6 and the upper
bound is 11. Suppose {o1 } is the first queue element, and we select it for expansion. This results in
adding {o1 , o2 }, {o1 , o3 }, {o1 , o4 } into the queue, and the lower and upper bounds of these sets are
(8, 11), (8, 11), (6, 11), respectively. Next, the set {o1 , o2 } is examined with respect to the current
Sopt = ∅, and Sopt is assigned to {o1 , o2 }. Since we assumed here a depth-first version of B&B we
proceed with expanding {o1 , o2 }, obtaining {o1 , o2 , o3 }, {o1 , o2 , o4 } with lower and upper bounds
being, respectively, (10, 11) and (11, 11). With a lower bound of 11 for {o1 , o2 , o4 } we can prune
away all the rest of the nodes in the queue, and we are done.
An important issue for depth-first B&B is the order in which sets are generated. In our implementation, at each node in the search space, the items in S are ordered according to the sum of the
value of the properties they can help satisfy. For example, initially, a conservative member such as
o1 could help us satisfy P1 .
In contrast to quantitative preference representation formalisms, qualitative preferences typically induce a partial ordering over property collections. In this case, it is harder to generate strict
139

B INSHTOK , B RAFMAN , D OMSHLAK , & S HIMONY

upper and lower bounds – as they must be comparable to any possible solution. One way to handle
this is to linearize the ordering and require the stronger property of optimality with respect to the
resulting total order. Here, TCP-nets present themselves as a good choice because there is an efficient and simple way of generating a value function consistent with an acyclic TCP-net (Brafman
& Domshlak, 2008). This value function retains the structure of the original network which is important to make the bounds computation efficient (notably, each Ui depends on a small number of
property values).
3.2 Searching over CSPs
The attractiveness of the item subsets is evaluated in terms of a fixed collection of set-properties P,
and thus different sets that provide all identical property values are equivalent from our perspective.
The immediate conclusion is that considering separately such preferentially equivalent subsets of
available items S is redundant. To remove this redundancy, we suggest an alternative method in
which we search directly over set-property value combinations. Of course, the problem is that given
a set-property value combination, it is not obvious whether we can find an actual subset of S that
has such a combination of properties. To answer this question, we generate a CSP that is satisfiable
if and only if there exists a subset of S with the considered set-property values. The overall search
procedure schematically works as follows.
1. Systematically generate combinations of set-property values.
2. For each such combination, search for a subset of S providing that combination of setproperty values.
3. Output a subset of S satisfying an optimal (achievable) combination of set-property values.
To make this approach as efficient as possible, we have to do two things, namely:
(1) Find a way to prune sub-optimal set-property value combinations as early as possible.
(2) Given a set-property value combination, quickly determine whether a subset of S satisfies this
combination.
Considering the first task, let P1 , . . . , Pk be an ordering of the set-properties P.3 Given such
an ordering of P, we incrementally generate a tree of property combinations. The root of that tree
corresponds to an empty assignment to P. For each node n corresponding to a partial assignment
P1 = p1 , . . . , Pj = pj , and for every possible value pj+1 of the property Pj+1 , the tree contains
a child of n corresponding to the partial assignment P1 = p1 , . . . , Pj = pj , Pj+1 = pj+1 . The
tree leaves correspond to (all) complete assignments to P. Such a tree for our running example
is depicted in Figure 2. Note that, implicitly, each node in this tree is associated with a (possibly
empty) set of subsets of S, notably, the subsets that provide the set-property value combination
associated with that node.
In our search for an optimal set, we expand this tree of set-property value combinations while
trying to expand as few tree nodes as possible by pruning certain value combinations of P as either
3. Throughout this paper, we will assume that in preference specifications using TCP nets, there are only conditional
preference (CP) arcs, and importance arcs, but no conditional importance (CI) arcs. While our scheme and implementations allow these arcs, CI arcs force the ordering of the set properties to be dynamic, as it may depend on value
assignments to previous properties. For clarity of exposition, we thus preferred not to present these technical details.

140

G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS

∅

P¯1

P1

P1 P2 P3

P¯1 P¯2

P1 P¯2

P1 P2
P1 P2 P¯3

P1 P¯2 P3 P1 P¯2 P¯3

P¯1 P¯2 P3

P¯1 P2

P¯1 P¯2 P¯3 P¯1 P2 P3

P¯1 P2 P¯3

Figure 2: Illustration of a search tree for our running example.
sub-optimal with respect to set preferences, or unsatisfiable with respect to S. A standard way
to do this is, again, by using a branch-and-bound search procedure, and this requires from us to
derive effective upper and lower bounds on the value of the best subset satisfying a partial value
combination for P. In addition, the order we associate with properties and their values affects our
pruning ability throughout the search process. To get the most leverage out of our bounds, we
would like to explore the children of a node in the decreasing order of their purported attractiveness.
Moreover, when fixing the ordering of the set-properties themselves, we would like properties that
can potentially contribute more to appear earlier in this ordering. For instance, P1 ’s value in our
running example has a greater influence on the overall attractiveness of a subset than the value of
P2 , and thus P1 should better be branched on first. In addition, P1 is preferred to be true, and thus
the subtree corresponding to P1 = true should better be explored first. Similarly, P2 is preferred to
be true when P1 = true, and preferred to be false, otherwise. This ordering is reflected in the tree
in Figure 2, for a left to right pre-order traversal of the tree.
Now, let us consider the second task of determining whether a subset of S satisfies a given setproperty value combination. Given such a partial assignment α to P, we set up the following CSP.
First, the CSP has a boolean variable xi for every available item oi ∈ S. In our example, the CSP
contains the variables x1 , . . . , x4 for items o1 , . . . , o4 respectively. Intuitively, xi = 1 encodes oi
being a part of our (searched for) subset of S, whereas xi = 0 means that oi is not in that subset.
Next, we translate every set-property value in α into a certain constraint on these variables. For
instance, if α[P1 ] = true, the constraint C1 : x1 + x2 + x3 ≥ 2 is added to the CSP. Note that
C1 explicitly encodes the requirement (of P1 = true) for the subset to have at least two of the
elements that satisfy Republican ∨ conservative. That is because {o1 , o2 , o3 } are all the candidates
in S that are either Republican or conservative. Alternately, if α[P1 ] = f alse, then the constraint
C1 : x1 + x2 + x3 < 2 is added to the CSP. Finally, if α does not specify a value for P1 , then no
constraints related to P1 should be added at all. Likewise, for α[P2 ] = true and α[P3 ] = true we
would add the constraints C2 : x2 + x3 + x4 ≥ 2 and C3 : x4 ≥ 1, respectively. In general, it
is not hard to verify that the CSP constructed this way for a concrete item set S and a set-property
value combination α is solvable if and only if S has a subset satisfying α. Moreover, if this CSP is
solvable, then any of its solutions explicitly provides us with such a subset of S.
It is worth briefly pointing out the difference between the CSPs we generate here and the more
typical CSPs usually discussed in the literature. Most work on general CSPs deals with constraints
141

B INSHTOK , B RAFMAN , D OMSHLAK , & S HIMONY

over small, typically just two-variable, subsets of problem variables. In contrast, the constraints
in the CSPs generated in our optimization process are global, with each constraint being possibly defined over all the CSP variables. Yet another special property of CSPs constructed for our
purposes is that there is a sense in which it is meaningful to talk about partial assignments in our
context—unassigned variables can always be regarded de facto as if assigned the value “0” since
the corresponding items, by default, do not belong to the subset we search for.
Because partial assignments to set-properties P map to CSPs, each node in our tree of setproperty value combinations maps to a CSP, and the entire tree can be viewed as a tree of CSPs.
The important property of this tree-of-CSPs is that the children of each CSP node are CSPs obtained
by adding one additional constraint to the parent CSP, notably the constraint corresponding to the
additional property value that we want the set to satisfy. This implies that if some CSP node in
the tree is unsatisfiable, then all of its descendants are unsatisfiable as well. In fact, we can make
a stronger use of the nature of this search tree, recognizing that we can reuse the work done on a
parent node to speed up the solution of its children. To see the latter, consider some CSP C in our
tree-of-CSPs, some child CSP C 0 of C , and let S ⊆ S be a solution to C . As C 0 extends C with
a constraint C, any subset S 0 ⊆ S ruled out by C will be also ruled out by C 0 . Hence, if solving
C and C 0 considers subsets of S in the same order (that is, by using the same ordering over set
elements), then solving C 0 can start from the leaf node corresponding to S, the solution generated
for C . Moreover, if a constraint C represents a boolean set property, and S is not a solution to
C 0 = C ∪ {C}, then S has to be a solution to C ∪ {¬C}, which is the sibling of C 0 . Using these
ideas, we share the work done on different CSP nodes of our tree-of-CSPs. In fact, when all set
properties are boolean, this approach needs to backtrack over each property at most once (we call
this property “limited backtracking”), thereby considerably improving the empirical performance
of the algorithm.
The overall branch-and-bound algorithm in the space of CSPs is depicted in Figure 3. As is,
the algorithm is formulated for the case of quantitative preference formalisms. The formulation
of the algorithm for the qualitative case is essentially the same, with minor technical differences
and an important computational property. For CP/TCP-nets, we can guarantee that only limited
backtracking is required if we follow the following guidelines. First, we must order the variables
(line 1) in an order consistent with the topology of the network. Note that for TCP-nets, this ordering
may be conditional, that is, the order of two variables may vary depending on the value of some of
the earlier variables. Second, in line 2, the property values must be (possibly partially) ordered
from best to worst, given the values of the parent properties (which must be and will be instantiated
earlier). In that case, the first satisfiable set of properties constitutes an optimal choice (Brafman
et al., 2006a). Assuming we solve intermediate nodes in the tree-of-CSPs, we know that we should
backtrack at most once in each level assuming boolean set-properties, but, again, more backtracks
may occur with integer-valued properties.
The node data structure used by the algorithm has two attributes. For a search node n,
• n.α captures a partial assignment to the set-properties P associated with the node n, and
• n.S captures a subset of S satisfying n.α if such exists, and otherwise has the value false.
The functions Value, LB, and UB have the same semantics as in the subset-space search algorithm
in Figure 1. In the pseudocode we assume a fixed ordering over set-property values (line 2), but
one can vary it depending on earlier values (and we exploit that in our implementation). Finally, the
142

G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS

1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:

Fix an ordering over set-properties P
Fix an ordering over the values of each set property P ∈ P
Fix an ordering over all available items S
Q ← {n[∅; ∅]}
Sopt ← ∅
while Q is not empty do
n ← pop(Q)
construct-and-solve-csp(n)
if n.S 6= f alse and UB(n.S) > Value(Sopt ) then
if Value(n.S) > Value(Sopt ) then
Sopt ← n.S
end if
Let P be the highest-ordered set property unassigned by n.α
for each possible value p of P do
n0 ← [n.α ∪ {P = p}; n.S]
Q ← Q ∪ {n0 }
. The position of n0 in Q depends on the search strategy
end for
end if
end while
return Sopt
Figure 3: CSP-space branch-and-bound search for an optimal subset of available items S.

pseudo-code leaves open the choice of search strategy for used by the branch-and-bound, and this
choice is fully captured by the queue insertion strategy in line 16.
To illustrate the flow of the algorithm, let us consider again our running example. Recall that
the example already has a requirement for the discovered subset to be of size 3, and this translates
into a constraint C : x1 + x2 + x3 + x4 = 3. The first CSP we consider has {C, C1 } as its only
constraints. Assume the CSP variables are ordered as {x1 , x2 , x3 , x4 }, with value 1 preceding value
0 for all xi . In that case, the first solution we find is S1 : x1 = 1, x2 = 1, x3 = 1, x4 = 0. Our
next CSP adds the constraint C2 . When solving this CSP, we continue to search (using the same
order on the xi ’s and their values) from the current solution S1 , which turns out to satisfy C2 as
well. Thus, virtually no effort is required to solve this CSP. Next, we want to also satisfy C3 . This
set of constraints corresponds to a leaf node in the tree-of-CSPs which corresponds to the complete
assignment P1 P2 P3 to the set-properties. Our current item set Sopt = S1 does not have a liberal,
so we have to continue to the assignment S2 : x1 = 1, x2 = 1, x3 = 0, x4 = 1 (requiring us to
backtrack in the CSP-solution space over the assignments to x4 and x3 ). We now have a set that
satisfies the properties in the leftmost leaf node in our tree-of-CSPs. If we can prove that this setproperty value combination is optimal using our upper/lower bounds, we are done. Otherwise, we
need to explore additional nodes in our tree-of-CSPs. In the latter case, the next CSP will correspond
to P1 , P2 , P3 , with constraints {C, C1 , C2 , C3 }. However, we already have a solution to this node,
and it is exactly S1 . To see that, note that S1 was a solution to the parent of our current CSP, but
it was not a solution to its sibling {C, C1 , C2 , C3 }. Hence, since P3 is a boolean property, S1 must
satisfy {C, C1 , C2 , C3 }.

143

B INSHTOK , B RAFMAN , D OMSHLAK , & S HIMONY

3.3 Solving the underlying CSPs
Our algorithm for solving the intermediate CSPs is based on the well known backtrack-search algorithm, first presented by Prosser (1993) in a simple iterative form. At the same time, we have
adapted both the algorithm and some well known enhancements in CSP solving (such as NoGood
recording and forward checking (FC)) to the specifics of the CSPs in our setting.
Initially, variables and their values are statically ordered from the most to least constrained
(although we also discuss a few experiments performed with dynamic variable/value ordering). Our
motivation for static ordering is two-fold. First, because the constraints are very much global, we
can do the ordering at a preprocessing stage. Second, as discussed in the previous section, static
ordering allows us to better utilize solutions of CSPs when solving descendent CSPs.
The basic backtrack algorithm, which on its own, unsurpisingly performs quite poorly in our
setting, is refined by utilizing the following observations and techniques.
• Monotonicity of improving constraints. If the operator of the constraint is “=” and there
are more items having the constrained property already in the current partial solution, then
one cannot satisfy the constraint by making additional assignments. The same property holds
for the constraint operators “< ” and “≤”. Using this observation, it is possible to detect the
need to backtrack early on in the search.
• Forward Checking. A certain type of “forward checking” can be performed for our constraints. Clearly, if satisfying some constraint requires at least k items to be added to the
subset, and the number of remaining items that satisfy the desired property is less than k, then
the search algorithm must backtrack.
• “Can/Must” strategy. The “can/must” strategy corresponds to a more advanced check of the
interactions between the constraints. The idea is quite simple: if (i) at least p items must be
added to the constructed subset to satisfy the constraint Ci , (ii) at most q items can be added
to the constructed subset without violating another constraint Cj , (iii) all the items that can
be added and have the property constrained by Ci also have the property constrained by Cj ,
and, finally, (iv) p > q, then both Ci and Cj cannot be satisfied simultaneously. Moreover, no
further assignments to yet unassigned variables can resolve this conflict, and thus the situation
is a dead end. This kind of reasoning allows discovery of such barren nodes quite early in the
search, pruning large portions of the search tree. To reason correctly about the “can/must”
strategy, we have to maintain a data structure of unique items for each pair of constraints, as
well as to keep track of the number of remaining items that influence property constrained by
Ci and do not influence properties constrained by Cj .
As an example, assume we are in the middle of the search and we have two set properties:
SP1 : |A1 = a| ≥ 5 and SP2 : |A2 = b| ≤ 3. Suppose that we have already picked 3 items
that influence SP1 and 2 items that influence SP2 . As a result, to satisfy SP1 , we must add
at least another two items that influence it and to satisfy SP2 we can add at most one item
that influences SP2 . If all the items that we can choose from {ok ...on } have a value “a” for
the attribute A1 and value “b” for the attribute A2 , then obviously we cannot satisfy both SP1
and SP2 within this setting, and thus we should backtrack.
Finally, below we discuss recording NoGoods, an improvement of the basic backtracking algorithm
that proved to have the most impact in our setting.
144

G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS

3.3.1 N O G OOD R ECORDING
The standard definition of a NoGood in the CSP literature is that of a partial assignment that cannot
be extended into a full solution of the problem. Once we learn a NoGood, we can use it to prune
certain paths in the search tree. The smaller the NoGood, the more occasions we can use it, the
greater its pruning power. Thus, it is of interest to recognize minimal NoGoods, and different
techniques have been developed to perform NoGood resolution in order to produce the best and most
general NoGoods possible (see, e.g., Dechter, 1990; Schiex & Verfaillie, 1993; Dago & Verfaillie,
1996).
As noted earlier, the CSPs we generate differ significantly from the more typical binary CSPs.
Consequently, the NoGood recording algorithm has to be adapted accordingly. In particular, because our constraints are global, it makes sense to try generating NoGoods that are global, too.
Thus, instead of recording assignments to variables, we record the influence of the current assignment on the constraints. Every variable influences a set of constraints.4 Thus, as a NoGood, we
store the influence the set selected so far has on all the constraints. Specifically, suppose we have
generated the set S1 , and recognized that it is not extensible into a set satisfying the constraints.
(This immediately follows from the fact that we backtracked over this set.) We now generate a NoGood N that records for each property associated with each constraint, how many items satisfying
that property occur in S1 . Now, suppose we encounter a different set S2 that has the same effect
N on the constraints. If there are fewer options to extend S2 than there are to extend S1 , we know
that S2 , as well, cannot be extended into a solution. However, if there are more options to extend
S2 than S1 , we cannot conclude that S2 is a NoGood at this point. In order to better quantify the
options that were available to extend S1 we record, beyond the actual NoGood N , the level (depth)
in the assignment tree at which it was generated. Given that the CSP solver uses a static variable
ordering, we know that if we encounter a set S that generates the same properties as the NoGood
N , at a level no higher than that of S1 , we can safely prune its extensions. The reason for that is,
there are no additional extension options available for S than there were for S1 .
The correctness of the NoGood recording mechanism proposed here depends on having a static
variable ordering, as well as a specific value ordering for all the variables in the CSP, namely,
h1, 0i. To show correctness, we should note that a NoGood can be used only after it is recorded.
Consequently, any node using a NoGood would be to the right in the search tree of a node the
NoGood was recorded at. Here we would like to stress again that, since the constraints are global,
it does not matter which items are added to the subset, but rather what influence these items had on
the constraints. Any two sets having exactly the same influence on the constraints are identical with
respect to the optimization process.
3.3.2 S EARCH A LGORITHM
The procedure depicted in Figure 4 extends the basic backtrack algorithm by a subroutine C AN I M PROVE which can be altered to include any combination of the in-depth checks discussed earlier,
to utilize early conflict detection techniques, including the NoGoods check. Also added is a call to
the A DD N O G OOD subroutine for recording NoGoods while backtracking. P and n, the generated
instance of a CSP problem with variables indexed from 1 to |S| and the node in the tree-space search
4. We assume without loss of generality that every item in the set of available items influences at least one constraint in
the constraint set C , since items that influence no constraint can be safely eliminated.

145

B INSHTOK , B RAFMAN , D OMSHLAK , & S HIMONY

respectively, are the inputs to the procedure. The algorithm systematically tries to assign values to
the problem variables, backtracking and recording NoGoods when facing a dead end.
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:

consistent ← n.S satisfies n.α
while not(consistent) do


if H AS VALUES(P .vars[i]) and C AN I MPROVE(P ) then
P.i ← L ABEL(P.i, consistent) . If current CSP variable has available values, try to set, update consistency
else

A
DD N O G OOD (P ,i)
. Record NoGood


P.i ← U NLABEL(P.i)
. Backtrack
end if
if P.i = 0 then
. If backtracked over the first indexed variable — no solution available
return false
end if
end while
return true
Figure 4: Conflict backtrack algorithm with NoGood recording

4. Experimental Results
We evaluate the different algorithms using a subset of the movie database publicly available from
imdb.com. We simulated a scenario of selecting movies for a three-day film festival according to
organizers preferences. Three models of growing complexity have been engineered to reflect the
preferences of the organizers; these models are defined in terms of 5, 9, and 14 set-properties, respectively. In addition, the total number of films is constrained to be 5 (which we actually modeled
using a very strong preference). Figure 5 depicts the list P14 of the 14 properties and their alterations; P5 and P9 consist of the corresponding prefixes (SP1 through SP5 , and SP1 through SP9 ,
respectively) of P14 . To produce even more complex problem instances that cause many backtracks
in the space of set-property assignments we slightly altered the 14-properties model, creating two
0 and P 00 .
additional models that are denoted henceforth as P14
14
4.1 Preference Specification
Figure 6 provides a verbal description of qualitative preferences for the film festival program which
we used in our experiments. Figure 7 depicts a TCP-net that encodes these preferences in terms of
the more concrete set-properties listed in Figure 5. For the experiments with GAI value functions,
these preferences were quantified by compiling this TCP-net into a GAI value function that orders
the items consistently with that TCP-net (Brafman & Domshlak, 2008). The task in our empirical
evaluation was to find an optimal subset of a set of available movies S ∈ {S400 , S1000 , S1600 , S3089 },
where Si corresponds to a set of i movies, and that with respect to each of the five models of
preferences over sets. All the experiments were conducted using Pentium 3.4 GHz processor with
2GB memory running Java 1.5 under Windows XP Professional. The runtimes reported in the tables
below are all in seconds, with “–” indicating process incompletion after four hours.

146

G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS

SP1 = h|Year ≥ 2002| = 5i
SP2 = h|Genre = Comedy| ≥ 2i
SP3 = h|Genre = Thriller| ≤ 3i
SP4 = h|Genre = Family| > 1i
SP5 = h|Color = B&W| > 1i
SP6 = h|Director = Spielberg| ≥ 1i
SP6 ∗ = h|Director = Spielberg| ≤ 1i
SP7 = h|Sound = Mono| ≥ 2i
SP8 = h|Genre = War ∨ Genre = Film-noir| = 0i

SP8 ∗ = h|Genre = War ∨ Genre = Film-noir| ≥ 4i
SP8 ∗∗ = h|Genre = Film-noir| ≥ 4i
SP9 = h|Location = North America| > 1i
SP10 = h|Actor = Famous ∨ Actress = Famous| = 5i
SP11 = h|Actress = Famous| ≥ 2i
SP12 = h|Genre = Drama| ≥ 2i
SP13 = h|Release Date < 1970| ≤ 1i
SP14 = h|Net Profit ≥ 1000000| ≥ 2i
SP14 ∗∗ = h|Net Profit ≥ 1000000| ≥ 5i

Figure 5: Set-properties used in modeling user preferences in the movies selection domain.
∗

0
Alteration of P14 , to achieve more backtracking - denoted as P14

∗∗

0
00
Further alteration of P14
to achieve even more backtracking - denoted as P14

1. I prefer new movies to old movies, and therefore prefer that all movies be from 2002 or later, and this is important
to me.
2. I love comedies, thrillers and family movies.
3. I prefer not to have too many movies in black and white (not more than one such movie).
4. If all the movies are new (after 2002) then I would prefer to have at least 2 comedies.
5. If I can find at least 2 comedies then I also prefer to have more than 1 family movie, but less then 3 thrillers.
However having the right number of family movies is more important to me than having the right number of
thrillers.
6. If not all the movies are new, I prefer to have at least 2 movies in black and white for the vintage touch.
7. If not all the movies are new, I prefer at least one movie to be directed by Steven Spielberg, but otherwise, I don’t
like his newer films
8. If the previous condition holds, then the number of movies with mono sound may be greater than 2.
9. I prefer not to have any war films or film-noir in the festival. However if this condition can not be satisfied,
then I prefer not to have any films that were filmed in North America and this is more important to me than my
preferences about the movie being in color or in B&W.
10. To draw more attention, I prefer all 5 movies to have famous actors or actresses.
11. To highlight female roles, I prefer at least 2 movies with a famous actress.
12. I prefer to have at least 2 dramas because people tend to think dramas are more sophisticated movies than any
other genre.
13. I prefer to have at least one classical movie.
14. I prefer to have at least one commercially successful movie, i.e. a movie whose net profit was more than one
million dollars.

Figure 6: Informal description of the assumed preferences for selecting a set of movies for a film
festival program.

First, our initial experiments quickly showed that the search in the space of subsets (Table 1)
does not scale up. With just over 20 elements, it did not converge to an optimal solution within an
hour, even when the preference specification involved only 5 set-properties. This outcome holds for
all combinations of qualitative and quantitative preference specifications, depth-first and best-first
schemes of branch-and-bound, and queue ordering based on set’s upper bound, lower bound, and

147

B INSHTOK , B RAFMAN , D OMSHLAK , & S HIMONY

weighted combinations of both. Table 1 provides a snapshot of the corresponding results for a TCPnet specified over nine set properties. The table describes the total number of subsets generated
until an optimal subset was found (see the column “Subset until Sopt ”), the total number of subsets
generated until the optimal subset was recognized as optimal (under “Subsets generated”). DFS appears to be much more effective than BFS, but the branching factor of larger databases overwhelms
this approach. Also, it may be thought that with larger databases it should be easier to quickly
generate good sets, but we found that for moderately larger (e.g,. 25+) and much larger (e.g., 3000)
datasets, this approach is too slow. Various improvements may be possible, but given the much
better performance of the other approach discussed later, they are unlikely to make a difference.

SP2 : SP4 ≻ SP4
SP2 : SP4 ≻ SP4

SP2 : SP3 ≻ SP3
SP2 : SP3 ≻ SP3

SP1 : SP2 ≻ SP2
SP1 : SP2 ≻ SP2

SP1 ≻ SP1

SP3

SP2

SP1

SP4

SP5

SP6

SP8

SP1 ∧ SP6
SP1 ∧ SP6
SP1 ∧ SP6
SP1 ∧ SP6

:
:
:
:

SP7
SP7
SP7
SP7

SP9

SP14

SP7 ∧ SP9
SP7 ∧ SP9
SP7 ∧ SP9
SP7 ∧ SP9

:
:
:
:

SP14
SP14
SP14
SP14

SP8 : SP9 ≻ SP9
SP8 : SP9 ≻ SP9

SP8 ∧ SP9
SP8 ∧ SP9
SP8 ∧ SP9
SP8 ∧ SP9

:
:
:
:

SP12
SP12
SP12
SP12

≻ SP12
≻ SP12
≻ SP12
≻ SP12

SP12

≻ SP7
≻ SP7
≻ SP7
≻ SP7

SP1 : SP6 ≻ SP6
SP1 : SP6 ≻ SP6

SP1 : SP5 ≻ SP5
SP1 : SP5 ≻ SP5

SP8 ≻ SP8

SP7

SP13

SP11

SP9 : SP13 ≻ SP13
SP9 : SP13 ≻ SP13

SP10 : SP11 ≻ SP11
SP10 : SP11 ≻ SP11

≻ SP14
≻ SP14
≻ SP14
≻ SP14

SP10
SP14 : SP10 ≻ SP10
SP14 : SP10 ≻ SP10

Figure 7: TCP-net model of preference over sets of movies for the film festival program.
Next, we consider the CSP-space branch-and-bound search. In particular, here we compared
between the two variants of this approach that use dynamic and static variable and value orderings.
In what follows, these two variants are denoted as BB-D and BB-S, respectively. While static
variable/value orderings are usually considered to be a weaker approach to CSP solving, earlier
we have shown that, in our domain, static ordering allows for certain optimizations that have a
potential to improve the efficiency of the overall problem solving. In particular, static variable
ordering allows to record global NoGoods as described in Section 3.3.1; the results for algorithms
that record NoGoods are denoted by a name suffix “+ng”. In addition, we have tried to share

148

G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS

S8
S8
S10
S10
S15
S15
S20
S20

Method
BFS
DFS
BFS
DFS
BFS
DFS
BFS
DFS

Subsets until Sopt
18
83
40
672
7879
11434
28407
28407

Subsets generated
4075
630
15048
2935
104504
30547
486079
231616

Time (sec)
0.56
0.19
2.34
0.47
68.23
3.13
1584.67
28.578

Table 1: A snapshot of the results for subsets-space search. The preferences here are specified by a
TCP-net over nine set properties.
Method

S400

S1000

S1600

S3089

P5
P5
P5
P5
P5

BB-D
BB-S
BB-S+inc
BB-S+ng
BB-S+ng+inc

0.3
0.14
0.05
0.17
0.05

0.77
0.14
0.1
0.1
0.11

1.30
0.17
0.12
0.15
0.13

4.02
0.25
0.18
0.21
0.19

P9
P9
P9
P9
P9

BB-D
BB-S
BB-S+inc
BB-S+ng
BB-S+ng+inc

0.43
0.14
0.06
0.17
0.06

1.42
0.24
0.14
0.25
0.14

2.42
0.26
0.17
0.34
0.18

6.58
0.34
0.15
0.35
0.17

P14
P14
P14
P14
P14

BB-D
BB-S
BB-S+inc
BB-S+ng
BB-S+ng+inc

0.66
0.17
0.06
0.3
0.1

2.03
0.43
0.15
0.57
0.19

4.69
1.09
0.43
1.06
0.38

14.92
0.78
0.5
0.95
0.54

0
P14
0
P14
0
P14
0
P14

BB-S
BB-S+inc
BB-S+ng
BB-S+ng+inc

6.5
2.1
16.1
4.68

27.1
27
19.4
18.4

278
259
54.8
76.3

–
–
230.2
210.8

00
P14
00
P14
00
P14
00
P14
00
P14

BB-D
BB-S
BB-S+inc
BB-S+ng
BB-S+ng+inc

4113.48
101.4
81.03
110
107.9

–
5370
5523
269.9
266.8

–
16306
16643
646.1
646.8

–
–
–
3335
3013

Set-properties

Table 2: Empirical results of evaluating the CSP-space search procedures with qualitative preference specification using TCP-nets.

information between consecutive CSP problem instances while doing the search in the tree of CSPs;
the algorithms adopting this technique are denoted by a name suffix “+inc”.
Table 2 depicts the results of the evaluation of all variants of the CSP-space branch-and-bound
search algorithm (Figure 3). First, the table shows that the overhead of maintaining NoGoods does
not pay off for the simple preference specifications. However, for the more complex problems requiring more intense CSP solving, the use of NoGood recording proved to be very useful, letting us

149

B INSHTOK , B RAFMAN , D OMSHLAK , & S HIMONY

Method

S400

S1000

S1600

S3089

P5
P9

BB-S
BB-S

0.24
0.16

0.14
0.25

0.17
0.28

0.26
0.41

P14
P14

BB-S+inc
BB-S+ng+inc

38.91
19

2376.40
160.53

–
494.98

–
1349.9

Set-properties

Table 3: Results for the CSP-space search with quantitative preference specification using GAI
value functions.

solve previously unsolvable instances. Next, the reader may notice from the table that, at least for
the problems used in our tests, the contribution of the incremental approach is not substantial. For
instance, NoGood recording by itself seems to contribute much more to the efficiency of the optimization process. Moreover, for the more complex problems, switching to the incremental version
sometimes even leads to performance degradation. It appears that the overhead of maintaining and
copying the partial solution in these cases does not pay off.
Our next set of experiments mirrored the first one, but now with GAI value functions instead
of the purely qualitative TCP-nets. The GAI functions were obtained by properly quantifying the
qualitative preferences used for the first tests. Table 3 provides a representative snapshots of the
results. With value functions over set-properties P5 and P9 the basic branch-and-bound algorithm
with static variable/value orderings performs and scales up (with growing set of alternatives S) quite
well. With the more complex value functions over the larger set of properties P14 the performance
significantly degrades, and even the incrementality-enhanced algorithm cannot solve problem instances with more than 1000 CSP variables. On the other hand, adding NoGoods recording proves
to dramatically improve the performance, leading to solving even the largest problem instances.
Tables 2 and 3 suggest a qualitative difference in the performance of the CSP-space search with
quantitative and qualitative preference representation models. There are good reasons to expect
such behavior. First, compact qualitative models of preference may (and typically do) admit more
than one optimal (that is, non-dominated) solution. That, in principle, makes finding one such
optimal solution easier. Second, if the preferences are captured by a TCP-net, then there are variable
orderings ensuring that the first solution found will be an optimal one. In contrast, with GAI value
functions, after we generate an optimal solution, typically we still have to explore the search tree to
prove that no better solution exists. In the worst case, we have to explore the entire tree of CSPs,
forcing us to explore a number of CSPs that is exponential in |P|.
In summary, the first conclusion to be taken from our experiments is that subsets-space search
fails to escape the trap of the large branching factor, while the stratified procedures for CSP-space
search show a much higher potential. On the problems that require little backtracking in the space of
CSPs, the latter procedures are actually very effective for both TCP-net and GAI function preference
specification. Obviously, if the procedure is forced to explore many different CSPs, the performance
unavoidably degrades. We note that, on larger databases, such backtracks often indicate an inherent
conflict between desirable set-properties, and such conflicts might possibly be recognized and resolved off-line. In this work we do not investigate this issue, leaving it as an optional direction for
future improvement.
The rather non-trivial example used in this section provides the reader also with the opportunity
to assess the suitability of different preference specification languages. For example, although we

150

G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS

used boolean-valued set properties, it may be argued that some of our natural-language preference
statements would better be expressed using integer-valued set properties. Similarly, users may find
that some other preference specification formalism, such as soft-constraints (Bistarelli et al., 1999),
can more naturally capture these natural language preferences. This is an opportunity for us to
reemphasize that while, for obvious reasons, we had to focus on a concrete choice of language, we
believe that the two-tiered approach suggested here is far more general.

5. Complexity Analysis
Though reasonable runtimes have been obtained by us empirically with search over CSPs, both
algorithm classes described above have a worst-case exponential running time. This begs the question of whether the problem itself is computationally hard. Obviously, with external constraints,
subset optimization is NP-hard. Below we show that even without external constraints, the problem
typically remains NP-hard, even with significant restrictions on the problem.
Naturally, the complexity of subset selection depends on the precise nature of the preference
specification formalism used. Most of the results presented here assume TCP-net-based specification. Hardness results for this model immediately apply to the GAI model, based on an existing
reduction (Brafman & Domshlak, 2008). In some cases, problems that are tractable under the TCPnet model become NP-hard when a GAI model is used, instead. Thus, unless stated otherwise, we
assume henceforth that preferences over properties are specified by a TCP-net.
In analyzing the complexity of the problem we consider the following problem parameters:
• n, the overall number of items in the data set.
• a, the number of attributes of the items.
• m, the number of set properties, i.e. number of nodes in the TCP-net.
• k, maximal property formula size, defined as the number of logical connectives (and, or, not)
in the formula.
• d maximum attribute domain size, i.e. the maximum number of distinct values for each
attribute.
• µ, the number of times an attribute value can appear in the dataset.
5.1 NP-Hard Classes
Theorem 1. When using TCP-based preferences over set properties, finding an optimal subset of a
given set of items (POS) is NP-hard even if the items are described only in terms of binary-valued
attributes, and all the set properties are atomic (that is, we have d = 2 and k = 0).
Proof. The proof is by a polynomial reduction from the well-known NP-hard Vertex Cover (VC)
problem. Given a graph G = (V, E), a vertex cover of G is a vertex subset V 0 ⊆ V covering all the
edges in the graph, that is, for every edge e ∈ E, there is a vertex v ∈ V 0 such that e is incident on
v. The optimization version of VC corresponds to finding a minimal size vertex cover of G.
Given an VC problem instance G = (V, E), we construct a POS problem instance by specifying a TCP-net N and an item set S as follows. For each vertex v ∈ V we create an item o (denoted
151

B INSHTOK , B RAFMAN , D OMSHLAK , & S HIMONY

Pe1 ≻ Pe1

Pe2 ≻ Pe2

Pe3 ≻ Pe3

Pe1

Pe2

Pe3

Pek ≻ Pek
...

Pek

SUM
SUM = 0 ≻ SUM=1 ≻ SUM=2 ≻ . . . ≻ SUM=n

Figure 8: TCP-net in the reduction from VC to POS in the proof of Theorem 1.
by ov ), and thus we have |S| = |V | = n items. For each edge e ∈ E we define an attribute X
(denoted by Xe ), and thus we have |X | = |E| = a attributes. All the attributes in X are defined
to have a binary, {0, 1}, domain. For each item ov , the value of each attribute Xe is ov [Xe ] = 1
if and only if e is incident on v in G. Next, for each edge e ∈ E, we define a binary set property
Pe = h|Xe | > 0i that takes the value true if and only if at least one item in the selected subset provides the value 1 to the attribute Xe . In addition, we define a single multi-valued empty set property
SUM ≡ h||i5 . The domain of the SUM property is defined to be the integer-value range [0..n].
Note that, by construction, the properties utilize only one attribute per property, and thus no logical
connectives, providing us with k = 0. The preferences over these set properties are
1. For each binary property Pe , the preference is for the value true, that is, Pe  Pe .
2. For the empty property SUM we simply prefer smaller values, that is
(SUM = 0)  (SUM=1)  (SUM=2)  . . .  (SUM=n)
The only edges in the TCP-net N , depicted in Figure 8, are the importance arcs from each Pe to
SUM, meaning that we would rather have to temporize in the value of the SUM property than have
any of the Pe being f alse.
Proposition 1 ensures that any optimal subset in the POS problem constructed as above always
corresponds to a proper vertex cover of G.
Proposition 1. For any subset S of S that is undominated with respect to the constructed TCP-net
N , and every edge e ∈ E, we have Pe (S) = true.
Proof. Given an undominated (with respect to N ) subset S ⊆ S, let Pe be a set property such that
Pe (S) = f alse. By construction, there exists an item o ∈ S such that o[Xe ] = 1. Considering
S 0 = S ∪ {o}, we have S 0 being preferred to S with respect to N because (i) S and S 0 provide
exactly the same values to all the set properties except for Pe and SUM, (ii) S provides a preferred
5. Since the formula ϕ inside this set property is degenerate, and in fact equivalent to h|true|i, every item in the selection
set will have to comply with it. This set property is the simplest implementation of a counter

152

G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS

value to SUM while S 0 provides a preferred value to Pe , and (iii) preferential improvement of Pe
dominates that of SUM. Thus S 0 dominates S, contradicting the assumption that S is undominated.
Lemma 1. For any subset S of S that is undominated with respect to the constructed TCP-net N ,
there exists a vertex cover VS of G with |VS | = |S|.
Proof. The proof is straightforward. Let VS = {v | ov ∈ S}. Because S is undominated with
respect to N , from Proposition 1 we have Pe (S) = true for all binary “edge-related” properties
Pe . In turn, Pe (S) = true implies that o[Xe ] = 1 for at least one item o ∈ S. By the construction,
o[Xe ] = 1 if and only if vertex v covers edge e. Together with the mapping between the vertices V
and items S being bijective, the latter implies |VS | = |S|.
Lemma 2. There exists a minimal vertex cover of G of size s if and only if there exists a subset
S ⊆ S undominated with respect to N such that SUM(S) = s.
Proof. Let S be an undominated subset of S with |S| = s. By construction, we have Pe (S) = true
for all binary set properties Pe , and SUM(S 0 ) = s. By Lemma 1, there exists a vertex cover VS
of G with |VS | = s. Suppose to the contrary that VS is not minimal, that is, there exists a vertex
cover V 0 of G with |V 0 | < s. Now, construct the subset S 0 = {ov | v ∈ V 0 }. Since the mapping
between S and V is bijective, we have |S 0 | = |V 0 | < s, and thus SUM(S 0 ) < s. Likewise, by
construction of our set properties and V 0 being a vertex cover, we have Pe (S) = true for all Pe .
This, however, implies that S 0 is preferred to S with respect to N , contradicting the statement that
S is undominated.
Theorem 1 now follows immediately from Lemma 2 and the fact that the reduction is clearly
polynomial.
Theorem 2. Given TCP-based preferences over set properties, finding an optimal subset of a given
set of items (POS) is NP-hard even if the items are described in terms of a single attribute, all the
set properties are binary-valued, each containing at most 2 logical connectives (that is, we have
a = 1 and k = 2).
Proof. The proof is by a polynomial reduction from k-SAT, for any k ≥ 3. Given a k-SAT problem
instance over propositional variables V and logical formula Φ, we construct a POS problem instance by specifying a TCP-net N and an item set S as follows. For each variable v ∈ V , construct
an item ov and an item ov̄ , and thus S contains an item for every possible literal in the formula. The
value of the only attribute X is defined as follows: for each item ol , we have A(ol ) = l (where l is a
literal, either v or v̄, for all v ∈ V ). The binary set properties P for the TCP-net N are now defined
as follows.
• Properties ensuring that a variable assignment is legitimate. For each variable v ∈ V ,

Pv =h|X = v ∨ X = v̄| = 1i,
that is, for any S ⊆ S, Pv (S) = true if and only if S contains exactly one of the items
{ov , ov̄ }.
153

B INSHTOK , B RAFMAN , D OMSHLAK , & S HIMONY

• Properties ensuring that Φ is satisfied. For each clause C = (l1 ∨ l2 ∨ l3 ∨ ...) ∈ Φ:
PC =h|X = l1 ∨ X = l2 ∨ X = l3 ∨ ...| ≥ 1i
that is, for any S ⊆ S, PC (S) = true if and only if S contains at least one item corresponding
to a literal in C.
Finally, to complete the preference specification, we make all properties independent (that is, the
TCP-net has no edges), and for each of the properties we prefer value true to value false.
To illustrate the above construction, consider a 3-SAT formula Φ = (x ∨ y ∨ z) ∧ (y) ∧ (x ∨ z).
For this formula, the construction leads to
item
ox
ox
oy
oy
oz
oz

X
x
x̄
y
ȳ
z
z̄

Set properties:
Px =h|X = x ∨ X = x| = 1i
Py =h|X = y ∨ X = y| = 1i
Pz =h|X = z ∨ X = z| = 1i
PC1 =h|X = x ∨ X = y ∨ X = z| ≥ 1i
PC2 =h|X = y| ≥ 1i
PC3 =h|X = x ∨ X = z| ≥ 1i

We now show that finding an undominated subset of S with respect to N as above is equivalent
to finding a satisfying assignment to Φ. Let S ⊆ S be undominated with respect to N . We can show
that S provides value true to all set propositions Pv and PC (in this case we call S an ultimately
preferred subset) if and only if Φ is satisfiable.
First, let S be an ultimately preferred subset of S. Given such S, we can construct a mapping
A : V 7→ {true, f alse} such that A(v) = true if ov ∈ S, and A(v) = f alse if ov̄ ∈ S. Note
that A is well-defined because, for an ultimately preferred subset S, all Pv (S) = true, and thus,
for each v ∈ V , exactly one item from {ov , ov̄ } is present in S. Clearly, A is a legal assignment for
Φ. In addition, we have all PC (S) = true. Thus, for each clause C ∈ Φ, at least one item with
X = li ∈ C belongs to S. By construction, this implies that A satisfies all the clauses in Φ, and
thus Φ is satisfiable.
Converesly, suppose that S ⊆ S is preferentially undominated with respect to N , but is not
ultimately preferred. If our POS problem has such an undominated subset S, we show that Φ is
unsatisfiable. Assuming the contrary, let A be a satisfying assignment of Φ. Given A, we construct
a subset SA ⊆ S as SA = {ol | literal l ∈ A}, and show that SA dominates S with respect to N
(contradicting the assumed undominance of S, and finalizing the proof of Theorem 2).
By construction, since A is a legal assignment to V , we have Pv (SA ) = true for all set properties Pv . Also, since A is a satisfying assignment for Φ, we have PC (SA ) = true for all set
properties PC . Therefore, SA is actually an ultimately preferred subset of S. Finally, since all the
set properties P are preferentially independent in N , and value true is always preferred to value
f alse for all the set properties, we have that SA dominates S with respect to N .
Notice that Theorems 1 and 2 do not subsume each other. Theorem 1 poses no restriction on the
number of item attributes in the problem instance, but does restrict the domain of all the attributes.
Theorem 2 restricts the number of attributes to 1, but has no restriction on the domain size of this
attribute, and its restriction on the property size is looser than that imposed in Theorem 1.
154

G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS

Finally, we note that tightening the condition of Theorem 2, by allowing only at most 1 connective in each set-property definition prevents us from using the same reduction as in the proof
of Theorem 2 because the respectibe satisfiability problems would be the polynomial-time solvable
2-SAT problems. Our conjecture, however, is that this fragment of POS is still NP-hard. In fact, in
Section 5.3 we show that the corresponding fragment of POS with the GAI preference specification
(instead of TCP-nets) is indeed NP-hard.
5.2 Tractable Classes
Several tractable classes of POS, obtained by further restricting the problem class discussed in
Theorem 2, and characterized by single-attribute item description (that is, a = 1), are discussed
below. In both trivially tractable (Section 5.2.1) and non-trivially tractable (Section 5.2.2) cases, we
assume that the relational symbols are either equalities or inequalities, that in the specification of
a property only equalities (“attribute = value”) are used, and in addition we do not allow an empty
set property to be specified. The latter restriction is due to the fact that the empty set property is
somewhat special, as it enriches the descriptive power by allowing one to simulate an additional
attribute in certain cases, and the single-attribute restriction is crucial for our tractability result.
Before we proceed with the actual results, note that, with a single-attribute item description, no
two set properties can be in a conflict that demands backtracking while choosing items (i.e. during
CSP solution). To illustrate such conflicts, consider the following examples.
1.

1.a h|A = ai | ≤ 5i
1.b h|A = ai | ≤ 3i

Set property 1.a is redundant, subsumed by 1.b

2.

2.a h|A = as | = 5i
2.b h|A = as | > 6i

One of these set properties must be false.

3.

3.a h|A = al | < 7i
3.b h|A = al | ≥ 9i

One of these set properties must be false.

All such conflicts between set-properties can be resolved offline, prior to the actual process of subset
selection, totally disregarding the available items. Hence, within the process of subset selection, we
assume that there are no conflicts between set properties. Consequently, subset selection can be
done in a greedy manner.
5.2.1 T RIVIALLY T RACTABLE C LASS
Theorem 3. Finding an optimal subset of a given set of items (POS) with respect to a TCP-net
preference specification is in P if the items are described in terms of a single attribute, and all the
set properties are atomic (that is, we have a = 1 and k = 0).
An algorithm for the problem class in Theorem 3 is depicted in Figure 9. The algorithm runs in
time O(m2 n), where m is the number of set properties and n is the number of available items S.
The for loop in line 4 of the algorithm iterates over all the set properties, each time checking compatibility with the previously considered properties, which requires Θ(m2 ) time. The procedures
G ET S ATISFYING S ET (·) and H AS S ATISFYING S ET (·) have to process each item in S only once.
Hence, the total running time of the algorithm is O(m2 n).6
6. This runtime analysis does not include the ordering of the TCP-net variables that is assumed to be given. One way to
do that would be a topological sort of the net, that obviously can be done in polynomial time.

155

B INSHTOK , B RAFMAN , D OMSHLAK , & S HIMONY

1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:

Sopt ← ∅
Fix a preference ordering over set properties P
Pass ← ∅
for each property P ∈ P do
while (not (P .isSatisfied)) do
if P is in conflict with Pass then
Set next value to P w.r.t. Pass
else
if H AS S ATISFYING S ET(P ) then
Sopt ← Sopt ∪ G ET S ATISFYING S ET(P )
P .isSatisfied ← true
Pass ← Pass ∪ {P }
end if
end if
end while
end for
return Sopt
procedure G ET S ATISFYING S ET(P )
S←∅
for each item o ∈ S do
if o has the property value defined by P then
S ← S ∪ {o}
end if
if |S| P .op P .cardinality then
return S
end if
end for
end procedure

. Offline conflict resolution

. If cardinality of S satisfies P

Figure 9: A polynomial-time algorithm for the POS problems with TCP-net preference specification, single-attribute item description, and all the set properties being atomic (that is,
a = 1 and k = 0).

5.2.2 N ON -T RIVIALLY T RACTABLE C LASS
At the end of Section 5.1 we have mentioned that the complexity of POS under limiting the setproperty description to at most one logical connective is still an open problem. If, however, we
impose the limitations summarized in Table 4, we can show that the problem becomes tractable.
Theorem 4. Finding an optimal subset of a given set of items (POS) with respect to a TCP-net
preference specification is in P if it is restricted as in Table 4.
First we should discuss the implicit limitations (or special problem properties) that are imposed
by the explicit limitations listed in Table 4.
156

G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS

1. All the items have only one attribute (a = 1)
2. All the property formulas have at most 1 connective (k = 1), and are positive (that is, we
disallow negation)
3. The empty property is disallowed
4. The number of attribute value appearances is limited to at most µ = 1 (that is, values in the
attribute domain cannot be repeated)
Table 4: Characteristics of the tractable subclass of POS presented in Section 5.2.2.
1. The restriction to at most one attribute-value appearance in the data set provides a one-toone correspondence between attribute values and items in S. This means that each item can
uniquely represent a specific attribute-value combination, and vice versa.
2. The restriction to a single-attribute item description renders the “∧” connective redundant.
That is because the properties using the “∧” logical connective can only be of the form:
X = xi ∧ X = xj .
(Without loss of generality we assume i 6= j, or otherwise we can simply drop one of the
terms.) These properties obviously cannot be satisfied because no item can have two different
values for the only attribute X. In fact, set properties defined this way are equivalent to a
property that is always f alse.
3. The only relevant cardinalities for the set properties are [0..2]. A property defined using only
one connective with the restriction on the number of repetitions is not expressive enough to
state a set property involving more than 2 items. If the value in a set property:
h|A = ai ∨ A = aj |

op

valuei

is greater than 2, and op ∈ {≥, >}, then again it cannot be satisfied. If the op of a property is
≤ or <, and the value is greater than 2, then it can be substituted by an effectively equivalent
set property with op being ≤ and value = 2 .
The algorithm for the problem class in Theorem 4 is depicted in Figure 10. This algorithm bears
some similarity to the algorithm in Figure 9, except that here the procedures G ET S ATISFYING S ET
and H AS S ATISFYING S ET reason simultaneously about satisfaction of collections of set-property
values, and do that by utilizing 2-SAT solving. Specifically, in Table 5 we show how any valid
property in such a POS problem can be translated into a 2-SAT CNF formula. In Lemma 3 we
prove the correctness of this translation. We should note that by using 2-SAT we can have an
answer to the question “Is there a subset of items satisfying some already evaluated set-property
values”. The procedures G ET S ATISFYING S ET and H AS S ATISFYING S ET use the aforementioned
reduction to 2-SAT to provide the answer in polynomial time.
Lemma 3. There is a subset S satisfying all the property-values Pass if and only if there is a
satisfying assignment A to the 2-SAT formula constructed from Pass .
157

B INSHTOK , B RAFMAN , D OMSHLAK , & S HIMONY

h|X
h|X
h|X
h|X
h|X
h|X

= xi | > 2i ⇒ infeasible
= xi | ≥ 2i ⇒ infeasible
= xi | ≥ 1i ⇒ substituted by
= xi | = 1i and translated to (vi ) clause
= xi | ≥ 0i ⇒ translated to (vi ∨ v¯i ) clause
= xi | = 0i ⇒ translated to (v¯i ) clause
Properties having 0 logical connectives

h|X = xi ∨ X = xj | > 2i ⇒ infeasible
h|X = xi ∨ X = xj | ≥ 2i ⇒ substituted by
h|X = xi ∨ X = xj | = 2i and translated to (vi )
and (vj ) clauses
h|X = xi ∨ X = xj | ≥ 1i ⇒ translated to
(vi ∨ vj ) clause
h|X = xi ∨ X = xj | = 1i ⇒ translated to
(vi ∨ vj ) and (v¯i ∨ v¯j ) clauses
h|X = xi ∨ X = xj | ≥ 0i ⇒ translated to
(v¯i ∨ v¯j ) clause
h|X = xi ∨ X = xj | = 0i ⇒ translated to (v¯i )
and (v¯j ) clauses
Properties having 1 logical connective

Table 5: Translation of the set properties for the POS subclass in Section 5.2.2 to 2-SAT.
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:

Fix a preference ordering over set properties P
Sopt ← ∅
Pass ← ∅
for each property P ∈ P do
while (not (P .isSatisfied)) do
Set next value to P w.r.t. Pass
if H AS S ATISFYING S ET(Pass ) then
Sopt ← G ET S ATISFYING S ET(Pass )
P .isSatisfied ← true
Pass ← Pass ∪ {P }
end if
end while
end for
return Sopt

. Use reduction to 2-SAT
. Use reduction to 2-SAT

Figure 10: A poly-time algorithm for the POS problems with TCP-net preference specification,
and characteristics as in Table 4.

Proof. By construction, we have an injective correspondence between the properties in the POS
problem and clauses in the 2-SAT problem. Every property P ∈ P injectively corresponds to a
certain clause ϕP . Every item o ∈ S injectively corresponds to a propositional variable vi ∈ V .
Thus, the correspondence between the selected subset S and the assignment A is simply
vi = true ⇔ o ∈ S.

158

(1)

G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS

Because the translation is injective and rather straightforward (without introducing any auxiliary
clauses or properties), it is trivial that S is a subset that satisfies all the properties in Pass if and only
if A is an assignment that satisfies all the clauses in the corresponding 2-SAT formula.
The above shows correctness of the algorithm in Figure 10, and finalizes the proof of Theorem 4.
5.3 Complexity of POS: TCP-nets vs. GAI Preference Specification
With the restrictions as in Table 4 we were able to show that the POS problem with TCP-net
preference specification is tractable by reduction to 2-SAT, because there is no need to backtrack
while searching in the attribute value space. An interesting question is, what if the specification
were done using GAI functions?
Theorem 5. Finding an optimal subset of a given set of items (POS) with respect to a GAI preference specification is NP-hard even if the items are described in terms of a single attribute, all the set
properties are binary-valued, each containing at most 1 logical connective (that is, we have a = 1
and k = 1).
Proof. The proof is by a polynomial reduction from MAX-2SAT. As far as item definitions and
properties are concerned, the reduction is essentially the same as the reduction from k-SAT in the
proof of Theorem 2. That is, for each variable v ∈ V , construct an item ov and an item ov̄ . The
value of the only attribute X is defined as follows: for item ol , we have A(ol ) = l (where l is a
literal, either v or v̄, for all v ∈ V ). Set properties are also as in the proof of Theorem 2, but now
they are limited to only 2 variables per clauses (re-stated for convenience below):
• For each variable v ∈ V :

Pv =h|X = v ∨ X = v̄| = 1i,
that is, properties ensuring that a variable assignment is legitimate.
• For each clause C = (l1 ∨ l2 ) ∈ Φ:

PC =h|X = l1 ∨ X = l2 | ≥ 1i,
that is, properties ensuring that Φ is satisfied.
The value function specification is such that legitimate variable assignments are enforced, and a
larger number of clauses satisfied is preferred. This is achieved by using an additively independent
value function (i.e., where each factor contains a single variable), with values being as follows.
Each clause-satisfying property has a value of 1 for being true, and 0 for being f alse. Each literalsatisfying property has a value of 0 for being true, and a negative value of −2m for being f alse,
where m is the number of clauses.
Lemma 4. Given a GAI value function and item set S constructed as above for a 2-CNF formula
Φ, there exists a subset S ⊆ S with value of U (S) = p if and only if there exists an assignment A
satisfying p clauses in Φ.
159

B INSHTOK , B RAFMAN , D OMSHLAK , & S HIMONY

Proof. Let S be any subset of S that has non-negative value. This implies by construction (since
there are only m clause-satisfying properties PC ) that all literal-satisfying properties must be true
for S, and the respective assignment AS can be constructed as in Equation 1. Conversely, let A
be a legitimate assignment to the variables V . One can define a corresponding set SA , for which
(by construction) all properties Pv are true. Also, observe that by construction the number of PC
set properties that are true on SA is the same as the number of clauses satisfied by the assignment
A.
The theorem follows immediately from the properties of the construction of the set properties
and preferences.
At the end of Section 5.1 we have noted that if the restrictions on the problem parameters are
more severe than in Theorem 2, by limiting the number of logical connectives per set property to
at most 1, we can no longer show whether the problem is tractable or NP-hard under the TCPnet preference specification. However, Theorem 5 shows that, with preferences specified using a
GAI value function, the problem is in fact NP-hard. Moreover, the problem class from Theorem
5 subsumes the class from Theorem 4, and thus provides an additional result showing that even
though with the TCP-net specification the respective problem is tractable, with a GAI preference
specification it becomes NP-hard.

6. Related Work
In the introduction, we mentioned the closely related work of desJardins and Wagstaff (2005). In
that approach, the motivation to provide the user with a diverse collection of values is either to
reflect the set of possible choices better for applications where the user must eventually select a
single item, or when the diversity of the selected set is an objective on its own. The work of Price
and Messinger (2005) is explicitly concerned with this problem. Specifically, they consider the
problem of recommending items to a user, and view it as a type of subset selection problem. For
example, suppose we want to recommend a digital camera to a user. We have a large set of available
cameras, and we are able to recommend k cameras. Price and Messinger consider the question
of how to select this set, proposing that the candidate set will maximize the expected value of the
user’s choice from this set. They suggest a concrete algorithmic approach for handling this problem.
The input to their problem is some form of partial representation of the user’s preferences (which
can be diverse, as in our work) and naturally, the concrete techniques are different from ours. Both
these papers share the assumption on ranking sets, common to most previous work as discussed
by Barberà et al. (2004), that ultimately one item will be selected from this set. However, they
do not necessarily start out with an initial ranking over single items, and as in our case, the work
of desJardins and Wagstaff utilizes the attribute value of items in the selection process.
Earlier work on ranking subsets was motivated by problems such as the college admissions
problem (Gale & Shapley, 1962), where we need to select the best set of fixed cardinality among a
pool of college candidates. The admissions officer has various criteria for a good class of students
and wishes to come up with an optimal choice. Some of the key questions that concerned this line
of work were what are good properties of such set rankings and whether they have some simple
representation. An example of a property of the set ranking that may be desirable is the following:
given a set S, if we replace some member c ∈ S with some other member c0 to obtain the set S 0 ,
and c0 is preferred to c, then S 0 is preferred to S. An example of a representation of the ranking
160

G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS

is an additive representation where items are associated with real values and one set is preferred to
another if the sum of its elements’ values is larger. It would be interesting to study similar question
in our context of structured objects.
This question of ranking sets appears in other areas, such as logics of preference and likelihood.
For example, the main question considered by Halpern (1997) is how to construct an ordering over
formulas based on an ordering over truth assignments. Formulas are associated with the set of
worlds in which they are satisfied, and hence, the question of comparing the likelihood of formulas
ψ and φ corresponds to that of ranking their respective set of models given the initial ranking on
single models. Much work on non-monotonic logics uses Shoham’s preference semantics (Shoham,
1987), and semantically, such work (see, e.g., Kraus, Lehmann, & Magidor, 1990) can be viewed as
attempting to answer the opposite question – define a ranking over single truth assignments given
some, possibly partial, ordering over formulas, i.e., sets of models.
A number of lines of work are related to our specification and solution methods. The first is
the work on Russian Doll Search (RDS), a well known algorithm for combinatorial optimization,
originally presented by Verfaillie, Lemaı̂tre, and Schiex (1996) as an efficient algorithm for Constraint Optimization Problems (COP). The idea behind the approach is to solve consecutively harder
problems. Initially, the problem is solved while considering only one variable. The optimal result
provides a lower bound. Each iteration, additional variables are considered, until eventually the original problem is solved. By using the lower bound obtained from the previous iteration (and other
optimizations) this technique is often able to solve the original problem more efficiently. Recently
Rollon and Larrosa (2007) extended Russian Doll Search to support multi-objective optimization
problems. In a multi-objective optimization problem the goal is to optimize several parameters
(attributes) of the variables in the problem. Usually all the parameters cannot be simultaneously
optimized. The technique of Rollon and Larrosa involves incremental solution with more and more
objectives included, and, in this sense, it is related to our search over CSPs approach in which we
incrementally consider more and more set properties. Indeed, different desirable set properties can
be viewed as different objectives.
Another related area is that of Pseudo-Boolean Constraint (PBC) Satisfaction Problems (Sheini
& Sakallah, 2005). A PBC has the form:
X
wi li ≥ k.
i

Here the li ’s are literals and we interpret their values as being either 0 (false) or 1 (true); the wi are
real-valued coefficients; and k is an integer. Thus Pseudo-Boolean CSPs are a special form of integer programs, and can nicely represent the cardinality constraints we generate. Thus, one option for
solving the type of CSPs generated here would be using a dedicated PBC solver. We run several popular PBC solvers on the satisfiability instances generated during the optimization: Pueblo (Sheini &
Sakallah, 2005), MiniSat (Eén & Sörensson, 2005), and Galena (Dixon & Ginsberg, 2002). These
solvers showed comparable results for satisfiable cases, while for the unsatisfiable cases, the PBC
solvers showed better performance. This appears to be due to their use of linear programming as a
preliminary test for satisfiability.
Another line of work that bears important connection to ours is that of winner determination
in combinatorial auctions. In regular auctions, bidders bid for a single item. In combinatorial auctions, bidders bid on bundles of items. Thus, bidders must provide their preferences over different
subsets of the set of auctioned items. The goal in combinatorial auctions is to allocate the set of
161

B INSHTOK , B RAFMAN , D OMSHLAK , & S HIMONY

goods to different bidders in the best manner (e.g., maximizing the payment to the seller or maximizing total welfare). This differs from the problem of selecting a single optimal subset with which
we are concerned. However, in both cases, preferences over subsets must be provided to the optimization algorithm. As the number of subsets is exponential in the number of items, researchers in
combinatorial auctions have sought bidding languages that can succinctly describe preferences of
interest (Boutilier & Hoos, 2001; Nisan, 2006). What distinguishes our specification approach is
its reliance on the existence of item features and the desire to provide a generic specification that
does not depend on the concrete set of items. Work in combinatorial auctions also attempts to break
the specification in some way. This is typically done by specifying values for small bundles and
providing rules for deriving the value of larger sets from the values of the smaller sets.

7. Conclusion
We suggested a simple, yet general approach to lifting any attribute-based preference specification
formalism to one for specifying preferences over sets. We then focused one instantiation of this idea
via a concrete language for specifying set properties, and suggested two methods for computing an
optimal subset given such a specification. One method is based on searching the space of explicit
subsets, while the other searches over implicit subsets represented as CSPs. Both search spaces
are meaningful regardless of the specific underlying preference specification algorithm although the
precise search and bounds generation method will vary. We focused on two concrete and popular
specification formalisms, one qualitative and one quantitative, on which we experiment and provide complexity results. Although the problem is generally NP-hard, as expected, the experimental
results are quite encouraging.
We wish to reemphasize that other choices, both for the set property language and the preference specification formalism are possible, and may be more appropriate in various cases. Indeed,
an interesting topic for future research would be to see which choices fit best some natural application areas; whether and how the algorithm presented in this paper can be modified to handle such
languages; and how the complexity of the optimal subset selection problem is affected by such
choices.
Though incremental search over CSPs appears to be the better method for optimal subset selection, it leaves a few questions open. First, it is an interesting question whether an efficient NoGood
recording scheme that does not rely on static variable and value orderings exists. Intuitively, such
a scheme should exist since the CSPs generated can be efficiently encoded into SAT as a boolean
CNF formula (Bailleux & Boufkhad, 2004; Eén & Sörensson, 2005), and clause learning is a well
known technique in SAT solving. Second, we have seen that while the incremental approach usually
improves the overall performance, its contribution is not substantial and what really improves the
performance is better individual CSP solving. This begs two questions: (1) Can we better utilize solutions across CSPs, and (2) Would representing and solving the CSPs generated as pseudo-boolean
CSPs (Manquinho & Roussel, 2006) or SAT instances lead to faster solution times? Naturally,
alternative approaches are also feasible.
Finally, in various applications, the set of elements gradually changes, and we need to adapt
the selected subset to these changes. An example is when we use this approach to choose the
most interesting current articles, and new articles constantly appear. It is likely that in this case the
preferred set is similar to the current set, and we would like to formulate an incremental approach
that adapts to such changes quickly.

162

G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS

Acknowledgments
Preliminary versions of this work appeared in (Brafman, Domshlak, Shimony, & Silver, 2006b;
Binshtok, Brafman, Shimony, Mani, & Boutilier, 2007). The authors wish to thank our anonymous
reviewers for their useful comments and suggestions. Brafman was supported in part by NSF grant
IIS-0534662, Brafman and Domshlak were supported by the COST action IC0602, Binshtok, Brafman and Shimony were supported by Deutsche Telekom Laboratories at Ben-Gurion University, by
the Paul Ivanier Center for Robotics Research and Production Management, and by the Lynn and
William Frankel Center for Computer Science.

References
Bacchus, F., & Grove, A. (1995). Graphical models for preference and utility. In Proceedings of
the 11th Annual Conference on Uncertainty in Artificial Intelligence (UAI), pp. 3–10, San
Francisco, CA.
Bailleux, O., & Boufkhad, Y. (2004). Full CNF encoding: The counting constraints case. In The 7th
International Conference on Theory and Applications of Satisfiability Testing (SAT), Vancouver, BC, Canada.
Barberà, S., Bossert, W., & Pattanaik, P. K. (2004). Handbook of Utility Theory. Volume II: Extensions, chap. Ranking Sets of Objects, pp. 893–977. Kluwer Academic Publishers.
Binshtok, M., Brafman, R. I., Shimony, S. E., Mani, A., & Boutilier, C. (2007). Computing optimal
subsets. In Proceedings of the 22nd National Conference on Artificial Intelligence (AAAI),
pp. 1231–1236, Vancouver, BC, Canada.
Bistarelli, S., Fargier, H., Montanari, U., Rossi, F., Schiex, T., & Verfaillie, G. (1999). Semiringbased CSPs and valued CSPs: Frameworks, properties, and comparison. Constraints, 4(3),
275–316.
Boutilier, C., Brafman, R., Domshlak, C., Hoos, H., & Poole, D. (2004). CP-nets: A tool for representing and reasoning about conditional ceteris paribus preference statements. Journal of
Artificial Intelligence Research, 21, 135–191.
Boutilier, C., & Hoos, H. H. (2001). Bidding languages for combinatorial auctions. In Proceedings
of the 17th International Joint Conference on Artificial Intelligence (IJCAI), pp. 1211–1217,
Seattle, WS.
Brafman, R. I., Domshlak, C., & Shimony, S. E. (2006a). On graphical modeling of preference and
importance. Journal of Artificial Intelligence Research, 25, 389–424.
Brafman, R. I., Domshlak, C., Shimony, S. E., & Silver, Y. (2006b). Preferences over sets. In
Proceedings of the 21st National Conference on Artificial Intelligence (AAAI).
Brafman, R. I., & Domshlak, C. (2008). Graphically structured value-function compilation. Artificial Intelligence, 172, 325–349.
Dago, P., & Verfaillie, G. (1996). Nogood recording for valued constraint satisfaction problems. In
ICTAI, pp. 132–139.
Dechter, R. (1990). Enhancement schemes for constraint processing: Backjumping, learning, and
cutset decomposition. Artif. Intell., 41(3), 273–312.
163

B INSHTOK , B RAFMAN , D OMSHLAK , & S HIMONY

desJardins, M., & Wagstaff, K. (2005). DD-PREF: A language for expressing preferences over
sets. In Proceedings of the 20th National Conference on Artificial Intelligence (AAAI), pp.
620–626, Pittsburgh, PA, USA.
Dixon, H. E., & Ginsberg, M. L. (2002). Inference methods for a pseudo-Boolean satisfiability
solver. In Proceedings of the 18th National Conference on Artificial Intelligence (AAAI), pp.
635–640, Edmonton, Canada.
Eén, N., & Sörensson, N. (2005). Translating pseudo-boolean constraints into SAT. Journal on
Satisability, Boolean Modeling and Computation (JSAT), 2, 1–26.
Fishburn, P. C. (1969). Utility Theory for Decision Making. John Wiley & Sons.
Gale, D., & Shapley, L. S. (1962). College admissions and the stability of marriage. American
Mathematical Monthly, 69, 9–15.
Halpern, J. (1997). Defining relative likelihood in partially-ordered preferential structures. Journal
of Artificial Intelligence Research, 7, 1–24.
Kraus, S., Lehmann, D., & Magidor, M. (1990). Nonmonotonic reasoning, preferential models and
cumulative logics. Artificial Intelligence, 44, 167–207.
Manquinho, V. M., & Roussel, O. (2006). The first evaluation of pseudo-boolean solvers. Journal
on Satisability, Boolean Modeling and Computation (JSAT), 2, 103–143.
Nisan, N. (2006). Bidding languages for combinatorial auctions. In Cramton, P., Shoham, Y., &
Steinberg, R. (Eds.), Combinatorial Auctions, chap. 2. MIT Press.
Price, B., & Messinger, P. (2005). Optimal recommendation sets: Covering uncertainty over user
preferences. In Proceedings of the 20th National Conference on Artificial Intelligence (AAAI),
pp. 541–548, Pittsburgh, PA.
Prosser, P. (1993). Hybrid algorithms for the constraint satisfaction problem. Computational Intelligence, 9, 268–299.
Rollon, E., & Larrosa, J. (2007). Multi-objective Russian Doll Search. In Proceedings of the 22nd
National Conference on Artificial Intelligence (AAAI), pp. 249–254, Vancouver, BS, Canada.
Schiex, T., & Verfaillie, G. (1993). Nogood recording for static and dynamic constraint satisfaction
problems. In ICTAI, pp. 48–55.
Sheini, H. M., & Sakallah, K. A. (2005). Pueblo: A modern pseudo-boolean SAT solver. In Proceedings of the Conference on Design, Automation and Test in Europe (DATE), pp. 684–685.
Shoham, Y. (1987). A semantics approach to non-monotonic logics. In Proceedings of the 10th
International Joint Conference on Artificial Intelligence (IJCAI), pp. 388–392, Milan, Italy.
Verfaillie, G., Lemaı̂tre, M., & Schiex, T. (1996). Russian Doll Search for solving constraint optimization problems. In Proceedings of the 13th National Conference on Artificial Intelligence
(AAAI), pp. 181–187, Portland, OR.

164

Journal of Artificial Intelligence Research 34 (2009) 391–442

Submitted 07/08; published 03/09

Solving #S AT and Bayesian Inference with Backtracking Search
Fahiem Bacchus
Shannon Dalmao
Toniann Pitassi

FBACCHUS @ CS . TORONTO . EDU
TONI @ CS . TORONTO . EDU

Department of Computer Science
University of Toronto
Toronto, Ontario
Canada, M5S 3G4

Abstract
Inference in Bayes Nets (BAYES) is an important problem with numerous applications in probabilistic reasoning. Counting the number of satisfying assignments of a propositional formula
(#S AT) is a closely related problem of fundamental theoretical importance. Both these problems,
and others, are members of the class of sum-of-products (S UM P ROD) problems. In this paper
we show that standard backtracking search when augmented with a simple memoization scheme
(caching) can solve any sum-of-products problem with time complexity that is at least as good
any other state-of-the-art exact algorithm, and that it can also achieve the best known time-space
tradeoff. Furthermore, backtracking’s ability to utilize more flexible variable orderings allows us to
prove that it can achieve an exponential speedup over other standard algorithms for S UM P ROD on
some instances.
The ideas presented here have been utilized in a number of solvers that have been applied to
various types of sum-of-product problems. These system’s have exploited the fact that backtracking
can naturally exploit more of the problem’s structure to achieve improved performance on a range
of problem instances. Empirical evidence of this performance gain has appeared in published works
describing these solvers, and we provide references to these works.

1. Introduction
Probabilistic inference in Bayesian Networks (BAYES) is an important and well-studied problem
with numerous practical applications in probabilistic reasoning (Pearl, 1988). Counting the number
of satisfying assignments of a propositional formula (#S AT) is also a well-studied problem that is
of fundamental theoretical importance. These two problems are known to be closely related. In
particular, the decision versions of both #S AT and BAYES are #P-complete (Valiant, 1979b, 1979a;
Roth, 1996), and there are natural polynomial-time reductions from each problem to the other
(Darwiche, 2002; Sang, Beame, & Kautz, 2005b; Chavira, Darwiche, & Jaeger, 2006).
A more direct relationship between these two problems arises from the observation that they
are both instances of the more general “sum of products” problem (S UM P ROD). Perhaps the most
fundamental algorithm for S UM P ROD (developed in a general way by Dechter 1999) is based on
the idea of eliminating the variables of the problem one by one following some fixed order. This
algorithm is called variable elimination (VE), and it is the core notion in many state-of-the-art exact
algorithms for S UM P ROD (and BAYES).
SAT, the problem of determining whether or not a propositional formula has any satisfying
assignments, is also an instance of S UM P ROD, and the original Davis-Putnam algorithm (DP) for
determining satisfiability (Davis & Putnam, 1960) which uses ordered resolution is a version of
c
2009
AI Access Foundation. All rights reserved.

BACCHUS , DALMAO , & P ITASSI

variable elimination. However, DP is never used in practice as its performance is far inferior to
modern versions of the backtracking search based DPLL algorithm (Davis, Logemann, & Loveland,
1962). In fact DP is provably less powerful than modern versions of DPLL equipped with clause
learning (Hertel, Bacchus, Pitassi, & van Gelder, 2008).
This performance gap naturally raises the question of whether or not backtracking search could
be used to solve other types of S UM P ROD problems more efficiently than variable elimination. In
this paper, we present a general algorithmic framework for using backtrack search methods (specifically DPLL) to solve S UM P ROD and related problems.1 We first show that a straightforward adaptation of backtracking for solving S UM P ROD is insufficient. However, by examining the sources
of inefficiency we are able to develop some simple caching schemes that allow our backtracking
algorithm, #DPLL-Cache, to achieve the same performance guarantees as state-of-the-art exact algorithms for S UM P ROD, in terms of both time and space. Furthermore, we prove that backtracking’s
natural additional flexibility allows it to sometimes achieve an exponential speedup over other existing algorithms. Specifically, we present a family of S UM P ROD instances where #DPLL-Cache
achieves an exponential speedup over the original versions of three prominent algorithms for S UM P ROD.
Besides these theoretical results, there are also good reasons to believe that backtracking based
algorithms have the potential to perform much better than their worst case guarantees on problems
that arise from real domains. In fact, subsequent work has investigated the practical application of
the ideas presented here to the problem of counting satisfying assignments, BAYES, and constraint
optimization with very successful results (Sang, Bacchus, Beame, Kautz, & Pitassi, 2004; Sang
et al., 2005b; Sang, Beame, & Kautz, 2005a, 2007; Davies & Bacchus, 2007; Kitching & Bacchus,
2008).
An outline of the paper follows. In Section 2, we define S UM P ROD ; demonstrate that #S AT ,
BAYES, and other important problems are instances of this class of problems; discuss various graphtheoretic notions of width that can be used to characterize the complexity of algorithms for S UM P ROD; and review some core state-of-the-art exact algorithms for S UM P ROD. In Section 3, we
discuss DPLL-based algorithms with caching for solving #S AT and S UM P ROD and provide worst
case complexity bounds for these algorithms. These bounds are the same as the best time and space
guarantees achieved by currently known algorithms. In Section 4, we provide a framework for
comparing our algorithms with other algorithms for S UM P ROD and prove that with caching DPLL
can efficiently simulate known exact algorithms while sometimes achieving super-polynomially
superior performance. In Section 5 we discuss some of the work that has used our algorithmic
ideas to build practical solvers for various problems. Finally, we provide some closing remarks in
Section 6.

2. Background
In this section, we first define the sum-of-products (S UM P ROD) class of problems, and then illustrate how BAYES, #S AT, and some other important problems are instances of S UM P ROD. As we
will show in the rest of the paper, backtracking search equipped with different caching schemes is
1. The notion of “backtracking” over a previous set of commitments can be utilized in other contexts, including in other
algorithms for S UM P ROD. However, here we are referring to the standard algorithmic paradigm of backtracking
search that explores a single tree of partial variable assignments in a depth-first manner. This algorithm has an
extensive history that stretches back over a hundred years (Bitner & Reingold, 1975).

392

BACKTRACKING S EARCH

FOR

#SAT AND BAYES

well suited for solving S UM P ROD. The key computational structure that is exploited by all algorithms for S UM P ROD is then explained and the graph theoretic notion of width that captures this
structure is identified. Different notions of “width” exist, and we present three different definitions
and show that they all yield essentially equivalent measures of complexity. The different definitions
are however very useful in that different algorithms are most easily analyzed using different definitions of width. Finally, we briefly review some of the most important exact algorithms for solving
S UM P ROD and related problems.
2.1 Sum-of-Products
Dechter (1999) has been shown that BAYES and many other problems are instances of a more
general problem called S UM P ROD (sum-of-products). An instance of S UM P ROD is defined by
the tuple hV, F, ⊕, ⊗i, where V is a set of discrete valued variables {X1 , . . . , Xn }, F is a set of
functions {f1 , . . . , fm } with each fi defined over some set of variables Ei ⊆ V, ⊕ is an addition
operator, and ⊗ is a multiplication operator. The range of the functions in F depends on the problem,
with ⊕ and ⊗ being operators over that range such that both are commutative, associative, and ⊗
distributes over ⊕. Typical examples involve functions that range over the boolean domain, with
⊕ being disjunction ∨ and ⊗ being conjunction ∧, or over the reals, with ⊕ and ⊗ being ordinary
addition and multiplication.
Definition 1 (S UM P ROD) Given hV, F, ⊕, ⊗i the S UM P ROD problem is to compute
MM
X1 X2

···

m
MO

fi (Ei ),

Xn i=1

i.e., the sum (⊕) over all values (assignments) of the variables V of the product (⊗) of the functions
F evaluated at those assignments.
A number of well known problems are instances of S UM P ROD. We describe some of them
below.
2.1.1 BAYES :
BAYES is the problem of computing probabilities in a Bayesian Network (BN). Developed by Pearl
(1988), a Bayesian network is a triple (V, E, P) where (V, E) describes a directed acyclic graph,
in which the nodes V = {X1 , . . . , Xn } represent discrete random variables, edges represent direct
correlations between the variables, and associated with each random variable Xi is a conditional
probability table CPT (or function), fi (Xi , π(Xi )) ∈ P, that specifies the conditional distribution of
Xi given assignments of values to its parents π(Xi ) in (V, E). A BN represents a joint distribution
over the random variables V in which the probability of any assignment (x1 , . . . , xn ) to the variables
Q
is given by the equation Pr (x1 , . . . , xn ) = ni=1 fi (xi , π(xi )), where fi (xi , π(xi )) is fi evaluated
at this particular assignment.
The generic BAYES problem is to compute the posterior distribution of a variable Xi given a
particular assignment to some of the other variables α: i.e., Pr (Xi |α). Since Xi has only a finite set
of k values, this problem can be further reduced to that of computing the k values Pr (Xi = dj ∧ α),
j = 1, . . . , k and then normalizing them so that they sum to 1. The values Pr (Xi = dj ∧ α) can
be computed by making all of the assignments in α as well as Xi = dj , and then summing out the
393

BACCHUS , DALMAO , & P ITASSI

other variables from the joint distribution Pr (x1 , . . . , xn ). Given the above product decomposition
of Pr (x1 , . . . , xn ), this is equivalent to reducing the functions fi ∈ P by setting the variables
assigned in α and Xi = dj , and then summing their product over the remaining variables; i.e., it is
an instance of S UM P ROD.
Computing all Marginals It is common when solving BAYES to want to compute all marginals.
That is, instead of wanting to compute just the marginal Pr(Xi |α) for one particular variable Xi ,
we want to compute the marginal for all variables not instantiated by α.
2.1.2 M ARKOV R ANDOM F IELDS
Markov Random Fields or Markov Networks (MN) (Preston, 1974; Spitzer, 1971) are similar to
Bayesian Networks in that they also define a joint probability distribution over a set of discrete
random variables V = {X1 , . . . , Xn } using a set of functions fi , called potentials, each over some
set of variables Ei ⊆ V. In particular, the probability of any assignment (x1 , . . . , xn ) to the variables
is given by the normalized product of the fi evaluated at the values specified by the assignment:
Q
i fi (Ei [x1 , . . . , xn ]). The difficulty is to compute the partition function, or normalizing constant:
Z=

X

···

m
XY

fi (Ei ).

Xn i=1

X1

Computing the partition function is thus an instance of S UM P ROD.
2.1.3 M OST P ROBABLE E XPLANATION
Most Probable Explanation (MPE) is the problem of finding the most probable complete assignment
to the variables in a Bayes net (or Markov net) that agrees with a fixed assignment to a subset of the
variables (the evidence). If the evidence, α, is an instantiation of the variables in E ⊂ V, then MPE
is the problem of computing
max
V −E

m
Y

fi |α (Ei − E),

i=1

where fi |α is the reduction of the function fi by the instantiations α to the variables in E (yielding
a function over the variables Ei − E).
2.1.4 S AT
Let V = {X1 , X2 , . . . , Xn } be a collection of n Boolean variables, and let φ(V) be a k-CNF
Boolean formula on these variables with m clauses {c1 , . . . , cm }. An assignment α to the Boolean
variables V is satisfying if it makes the formula True (i.e., φ(α) = 1). S AT asks, given a Boolean
formula φ(V) in k-CNF, does it have a satisfying assignment? By viewing each clause ci as being a
function of its variables Ei (i.e., it maps an assignment to these variables to TRUE if that assignment
satisfies the clause and to FALSE otherwise), we can see that S AT is equivalent to the instance of
S UM P ROD hV, {c1 , . . . , cm }, ∨, ∧i:
_
X1

···

m
_^

Xn i=1

394

ci (Ei ).

BACKTRACKING S EARCH

FOR

#SAT AND BAYES

2.1.5 #S AT
Given a k-CNF formula φ(V) on the boolean variables V = {X1 , . . . , Xn }, as above, #S AT is
the problem of determining the number of satisfying assignments for φ. By viewing each clause
ci as being a function from its variables Ei to {0, 1} (i.e., it maps satisfying assignments to 1
and falsifying assignments to 0), we can see that #S AT is equivalent to the instance of S UM P ROD
hV, {c1 , . . . , cm }, +, ×i:
X

···

X1

2.1.6 O PTIMIZATION

WITH

m
XY

ci (Ei ).

Xn i=1

D ECOMPOSED O BJECTIVE F UNCTIONS

Let V = {X1 , . . . , Xn } be a collection of finite valued variables, the optimization task is to find
an assignment of values to these variables that maximizes some objective function O(V) (i.e., a
function that maps every complete assignment to the variables to a real value). In many problems
O can be decomposed into a sum of sub-objective functions {f1 , . . . , fm } with each fi being a
function of some subset of the variables Ei . This problem can then be cast as the S UM P ROD
instance hV, {f1 , . . . , fm }, max, +i
max · · · max
X1

Xn

m
X

fi (Ei ).

i=1

2.2 The Computational Complexity of S UM P ROD
S UM P ROD is a computationally difficult problem. For example, #S AT is known to be complete for
the complexity class #P (Valiant, 1979b, 1979a) as is BAYES (Roth, 1996). Many special cases that
are easy for S AT remain hard for #S AT, e.g., Valiant showed that the decision version of #S AT is #P
hard even when the clause size, k, is 2, and Roth (1996) showed that the problem is hard to even
approximate in many cases where S AT is easy, e.g., when φ(V) is monotone, or Horn, or 2-CNF.
Despite this worst case intractability, algorithms for S UM P ROD, e.g., the variable elimination
algorithm presented by Dechter (1999), can be successful in practice. The key structure exploited
by this algorithm, and by most algorithms, is that the functions fi of many S UM P ROD problems are
often relatively local and fairly independent. That is, it is often the case that the sets of variables
Ei that each function fi depends on are small, so that each function is dependent only on a small
“local” set of the variables, and that these sets share only a few variables with each other, so that the
functions fi are fairly independent of each other. The graph theoretic notion of Tree Width is used
to make these intuitions precise.
2.3 Complexity Measures and Tree width
There is a natural hypergraph, H = (V, E), corresponding to any instance hV, F, ⊕, ⊗i of S UM P ROD. In the hypergraph, V corresponds to the set V of variables, and for every function fi with
domain set Ei , there is a corresponding hyperedge, Ei .
The “width” of this hypergraph is the critical measure of complexity for essentially all state-ofthe-art algorithms for #S AT , BAYES, and S UM P ROD. There are three different (and well known)
notions of width that we will define in this section. We will also show that these different notions of
width are basically equivalent. These equivalences are known, although we need to state them and
395

BACCHUS , DALMAO , & P ITASSI

prove some basic properties, in order to analyze our new algorithms, and to relate them to standard
algorithms.
Definition 2 (Branch width) Let H = (V, E) be a hypergraph. A branch decomposition of H is
a binary tree T such that each node of T is labelled with a subset of V . There are |E| many leaves
of T , and their labels are in one-to-one correspondence with the hyperedges E. For any other node
n in T , let A denote the union of the leaf labeling of the subtree rooted at n, and let B denote the
union of the labelings of the rest of the leaves. Then the label for n is the set of all vertices v that
are in the intersection of A and B. The branch width of a branch decomposition T for H is the
maximum size of any labeling in T . The branch width of H is the minimum branch width over all
branch decompositions of H.
Example 1 Figure 1 shows a particular branch decomposition Tbd for the hypergraph H = (V, E)
where V = {1, 2, 3, 4, 5} and E = {{1, 2, 3}, {1, 4}, {2, 5}, {3, 5}, {4, 5}}. Tbd has branch width
3.
{}
H
 HH
HH



{3, 4, 5}

{3, 4, 5}

H
 H

H

HH

{2, 3, 4}

{2, 5}

{3, 5}

{4, 5}

H

H

H

{1, 2, 3}

{1, 4}

Figure 1: A branch decomposition of branch width 3 for H = {(1, 2, 3), (1, 4), (2, 5), (3, 5),
(4, 5)}.

Definition 3 (Elimination width) Let H = (V, E) be a hypergraph, and let π = v1π , . . . , vnπ be an
ordering of the vertices in V , where viπ is the ith element in the ordering. This induces a sequence
of hypergraphs Hn , Hn−1 , . . . , H1 where H = Hn and Hi−1 is obtained from Hi as follows. All
edges in Hi containing viπ are merged into one edge and then viπ is removed. Thus the underlying
π . The induced width of H under π is the size of the largest edge in
vertices of Hi are v1π , . . . vi−1
all the hypergraphs Hn , . . . , H1 . The elimination width of H is the minimum induced width over
all orderings π.
Example 2 Under the ordering π = h1, 2, 3, 4, 5i the hypergraph H of Example 1 produces the
following sequence of hypergraphs:
H5 = {(1, 2, 3), (1, 4), (2, 5), (3, 5), (4, 5)}
H4 = {(2, 3, 4), (2, 5), (3, 5), (4, 5)}
H3 = {(3, 4, 5), (3, 5), (4, 5)}
H2 = {(4, 5), (4, 5)}
H1 = {(5)}
396

BACKTRACKING S EARCH

FOR

#SAT AND BAYES

The induced width of H under π is 3—the edges (1, 2, 3) ∈ H1 , (2, 3, 4) ∈ H2 and (3, 4, 5) ∈ H3
all achieve this size.
Tree width is the third notion of width.
Definition 4 (Tree width) Let H = (V, E) be a hypergraph. A tree decomposition of H is a
binary tree T such that each node of T is labelled with a subset of V in the following way. First,
for every hyperedge e ∈ E, some leaf node in T must have a label that contains e. Secondly, given
labels for the leaf nodes every internal node n contains v ∈ V in its label if and only if n is on a path
between two leaf nodes l1 and l2 whose labels contain v.2 The tree width of a tree decomposition
T for H is the maximum size of any labeling in T minus 1, and the tree width of H is the minimum
tree width over all tree decompositions of H.
Example 3 Figure 2 shows Ttd a tree decomposition for H of Example 1. Ttd has tree width 3.
{3, 4, 5}
H
 HH
HH



{2, 3, 4, 5}
H
HH


{1, 2, 3, 4}

{2, 5}

{3, 4, 5}
HH

{3, 5}

{4, 5}

H

H

H

{1, 2, 3}

{1, 4}

Figure 2: Tree decomposition of tree width for 3 for H of Example 1.
The next three lemmas show that these three notions are basically equivalent. The proofs of
Lemmas 2 and 3 are given in the appendix.
Lemma 1 (Robertson & Seymour, 1991) Let H be a hypergraph. Then the branch width of H is
at most the tree width of H plus 1, and the tree width of H is at most 2 times the branch width of H.
Lemma 2 Let H = (V, E) be a hypergraph with a tree decomposition of width w. Then there is an
elimination ordering π of the vertices V such that the induced width of H under π is at most w.
Lemma 3 Let H be a hypergraph with elimination width at most w. Then H has a tree decomposition of tree width at most w.
Letting TW (H), BW (H), and EW (H) represent the tree width, branch width and elimination
width of the hypergraph H, the above lemmas give the following relationship between these three
notions of width: for all hypergraphs H
BW (H) − 1 ≤ TW (H) = EW (H) ≤ 2BW (H).
2. Since the labels of internal nodes are determined by the labels of the leaf nodes in this way, it can be seen that for any
pair of nodes n1 and n2 in the tree decomposition every node lying on the path between them must contain v in its
label if v appears in both n1 ’s and n2 ’s labels. This is commonly known as the running intersection property of tree
decompositions.

397

BACCHUS , DALMAO , & P ITASSI

{4, 5}
H
 HH
H


{3, 4, 5}

{4, 5}

H
H

HH


{2, 3, 4, 5}

{3, 5}

H
 H

H

{1, 2, 3, 4}

{2, 5}

H

H

H

{1, 2, 3}

{1, 4}

Figure 3: Tree decomposition of the hypergraph H of Example 1 that has been constructed from
the ordering π = h1, 2, 3, 4, 5i.

Example 4 The tree decomposition Ttd of H = {(1, 2, 3), (1, 4), (2, 5), (3, 5), (4, 5)} given in Figure 2 has the property that it has tree width no more than twice the branch width of the branch
decomposition Tbd of H given in Figure 1. From Ttd we can obtain the ordering π = h1, 2, 3, 4, 5i
that was used in Example 2. (The proof of Lemma 2, given in the appendix, shows how a elimination ordering can be constructed from a tree-decomposition.) As shown in Example 2, π has
induced width 3, equal to the tree width of tree decomposition Ttd from which it was constructed.
Finally, from the ordering π we can construct a new tree decomposition for H shown in Figure 3.
(The proof of Lemma 3 shows how a tree decomposition can be constructed from an elimination
ordering). π has induced width 3 and, as indicated by Lemma 3 the tree decomposition constructed
from it has equal tree width of 3.
It can be noted that our definition of tree decompositions varies slightly from other definitions
that appear in the literature, e.g., (Bodlaender, 1993). Following Robertson and Seymour (1991)
we have defined tree decompositions over hypergraphs, rather than over graphs, and we have made
two extra restrictions so as to simplify the proofs of our results. First, we have restricted tree
decompositions to be binary trees, and second we have required that each hyperedge be contained
in the label of some leaf node of the tree decomposition. Usually tree decompositions are not
restricted to be binary trees, and only require that each hyperedge be contained in some node’s label
(not necessarily a leaf node).
It is not difficult to show that any tree decomposition that fails to satisfy our two restrictions
can be converted to a tree decomposition satisfying these restrictions without changing its width.
However, it is more straight forward to observe that with or without these two restrictions tree width
is equal to elimination width. Hence, our restrictions do not change the tree width.
2.4 Exact Algorithms for S UM P ROD
Next we briefly review three prominent exact algorithms for BAYES. These algorithms solve the
more general problem S UM P ROD. All of these algorithms are in fact nondeterministic algorithms
that should be considered to be families of procedures, each member of which is a particular deterministic realization.
398

BACKTRACKING S EARCH

FOR

#SAT AND BAYES

2.4.1 VARIABLE E LIMINATION :
Variable or bucket elimination (VE) (Dechter, 1999) is a fundamental algorithm for S UM P ROD.
Variable elimination begins by choosing an elimination ordering, π for the variables V = {X1 ,
. . ., Xn }: Xπ(1) , . . ., Xπ(n) . (This is the nondeterministic part of the computation). In the first
phase, all functions involving Xπ(1) , are collected together in the set FXπ(1) , and a new function,
F1 is computed by “summing out” Xπ(1) . The new function sums the product of all the functions in
FXπ(1) over all of Xπ(1) ’s values. Specifically, F1 is a function of all of the variables of the functions
in FXπ(1) except for Xπ(1) , and its value on any assignment α to these variables is
F1 (α) =

X

Y

f (α, Xπ(1) = d).

d∈vals(Xπ(1) ) f ∈FXπ(1)

Summing out Xπ(1) induces a new hypergraph, H1 , where the hyperedges corresponding to the set
of functions FXπ(1) are replaced by a single hyperedge corresponding to the new function F1 . The
process then continues to sum out Xπ(2) from H1 and so on until all n variables are summed out.
Note that the sequence of hypergraphs generated by summing out the variables according to π is the
same the sequence of hypergraphs that defines the induced width of π (Definition 3).
The original Davis-Putnam algorithm (Davis & Putnam, 1960) based on ordered resolution is an
instance of variable elimination. Consider applying variable elimination to the formulation of S AT
given above. For S AT, the new functions Fi computed at each stage need only preserve whether or
not the product of the functions in FXπ(i) is 0 or 1, the exact number of satisfying assignments need
not remembered. This can be accomplished by representing the Fi symbolically as a set of clauses.
Furthermore, this set of clauses can be computed by generating all clauses that can be obtained
by resolving on Xπ(i) , and then discarding all old clauses containing Xπ(i) . This resolution step
corresponds to the summing out operation, and yields precisely the Davis-Putnam (DP) algorithm
for satisfiability.3
2.4.2 R ECURSIVE C ONDITIONING :
Recursive conditioning (RC) (Darwiche, 2001) is another type of algorithm for S UM P ROD. Let
S = hV, F, ⊕, ⊗i be an instance of S UM P ROD and H be its underlying hypergraph. RC is a
divide and conquer algorithm that instantiates the variables of V so as to break the problem into
disjoint components. It then proceeds to solve these components independently. The original spaceefficient version of recursive conditioning, as specified by Darwiche (2001), begins with a branch
decomposition T of H of width w and depth d, and an initially empty set of instantiated variables
ρ. (Choosing T is the nondeterministic part of the computation.) We call this algorithm RC-Space
and show it in Algorithm 1.
The branch decomposition T specifies a recursive decomposition of the problem and is used by
RC-Space as follows. Let label (n) be the label of a node in T , and let ST be the S UM P ROD problem
defined by the variables and functions contained in T . (In the initial call T is the complete branch
decomposition containing all variables and functions of S, so that initially ST = S). Starting at r,
the root of T , RC-Space solves the reduced S UM P ROD ST |ρ∪α for all assignments α to the variables
3. Rish and Dechter (2000) have previously made a connection between DP and variable elimination. They were thus
able to show, that DP runs in time nO(1) 2O(w) , where w is the branch width of the underlying hypergraph of the SAT
instance.

399

BACCHUS , DALMAO , & P ITASSI

in label (left(r)) ∩ label (right(r)) not yet instantiated by ρ, where left(r) and right (r) are the left
and right children of r. The sum over all such α is the solution to the inputed instance ST |ρ .
Each α renders the set of functions in the subtree below leftChild (r) (i.e., the leaf labels) disjoint
from the functions below rightChild (r). Thus for each α, RC-Space can independently solve the
subproblems specified by leftChild (r)|ρ∪α and rightChild (r)|ρ∪α (i.e., the sum of the products
of all of the functions below the left/right subtree conditioned on the instantiations in ρ ∪ α) and
multiply their answers to obtain the solution to ST |ρ∪α . At the leaf nodes, the function fi associated
with that node has had all of its variables instantiated, so the algorithm can simply “LOOKUP” fi ’s
current value.
Algorithm 1: RC-Space—Linear Space Recursive Conditioning
1
2
3
4
5
6
7
8
9
10
11

RC-Space (T, ρ)
begin
if T is a leaf node then
return LOOKUP(value of function labeling the leaf node)
p = 0; r = root (T )
~x = variables in label (left(r)) ∩ label (right(r)) uninstantiated by ρ
forall α ∈ {instantiations of ~x} do
p = p + RC-Space (leftChild (T ), ρ ∪ α) × RC-Space (rightChild (T ), ρ ∪ α)
end
return p
end

A less space-efficient but more time-efficient version of recursive conditioning, called RCCache, caches intermediate values that can be reused to reduce the computation. Algorithm 2
shows the RC-Cache algorithm. Like RC-Space, each invocation of RC-Cache solves the subproblem specified by the variables and functions contained in the passed subtree T . Since the functions
below T only share the variables in label (root(T )) with variables outside of T , only the instantiations in the subset, y, of ρ intersecting label (root(T )) can affect the form of this subproblem.
Hence, RC-Cache will return the same answer if invoked with the same T and same y, even if other
assignments in ρ have changed. RC-Cache, can thus use T and y to index a cache, storing the computed result in the cache (line 13) and returning immediately if the answer is already in the cache
(line 7).
Propagation Since RC instantiates the problem’s variables, propagation can be employed. That
is, RC can perform additional inference to compute some of the implicit effects each assignment
has on the remaining problem ST |ρ∪α . For example, if the functions of the S UM P ROD problem
are all clauses (e.g., when solving #S AT) unit propagation can be performed. Propagation can
make recursive conditioning more effective. For example, if one of the remaining clauses becomes
falsified through unit propagation, recursive conditioning can immediately move on to the next
instantiation of the variables ~x. Similarly, unit propagation can force the value of variables that will
be encountered in subsequent recursive calls, thus reducing the number of different instantiations α
that must be attempted in that recursive call. It can be noted that propagation does not reduce the
worst case complexity of the algorithm, as on some S UM P ROD problems propagation is ineffective.
It can however improve the algorithm’s efficiency on some families of problems.
400

BACKTRACKING S EARCH

FOR

#SAT AND BAYES

Algorithm 2: RC-Cache—Recursive Conditioning with caching
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15

RC-Cache (T, ρ)
begin
if T is a leaf node then
return LOOKUP(value of function labeling the leaf node)
y = ρ ∩ label (root(T ))
if InCache(T, y) then
return GetValue(T, y)
p = 0; r = root (T )
~x = variables in label (left(r)) ∩ label (right(r)) uninstantiated by ρ
forall α ∈ {instantiations of ~x} do
p = p + RC-Cache (leftChild (T ), ρ ∪ α) × RC-Cache (rightChild (T ), ρ ∪ α)
end
AddToCache((T ,y), p)
return p
end

RC-Cache+ A simple extension of RC that is used in practice is to set the variables ~x ⊆
label (left(r) ∩ label (right (r)) (line 10 of Algorithm 2) iteratively rather than all at once. That
is, rather than iterate over all complete assignments α to ~x we can instantiate these variables one at
a time, performing propagation after each assignment. This can make propagation more effective,
since, e.g., an empty clause might be detected after instantiating only a subset of the variables in ~x
and thus the number of iterations of the for loop might be reduced.
Once the variables of ~x are being set iteratively the order in which they are assigned can vary.
Furthermore, the order of assignment can vary dynamically. That is, depending on how the values assigned to the first k variables of ~x, the algorithm can make different choices as to which
unassigned variable of ~x to assign next.
We call the extension of RC-Cache that uses incremental assignments and dynamic variable ordering within set ~x, RC-Cache+ . That is RC-Cache+ uses the same caching scheme as RC-Cache,
but has more flexibility in its variable ordering. It should be noted however, that RC-Cache+ does
not have complete freedom in its variable ordering. It must still follow the inputed branch decomposition T . That is, the variable chosen must come from the set ~x ⊆ label (left(r)) ∩ label (right (r)).
This is in contrast with the DPLL based algorithms we present in the next section, which are always
free to choose any remaining unassigned variable as the next variable to assign.
Space-Time Tradeoff RC has the attractive feature that it can achieve a non-trivial space-time
tradeoff, taking less time if it caches its recursively computed values (RC-Cache), or taking less
space without caching (RC-Space). In fact, Darwiche and Allen (2002) show that there is a smooth
tradeoff that can be achieved, with RC-Space and RC-Cache at the two extremes.
The DPLL based algorithms presented here share a number of features with RC; they also reduce
and decompose the input problem by making instantiations, gain efficiency by caching, and achieve
a similar space-time tradeoff. However, our algorithms are based on the paradigm of backtracking,
rather than divide and conquer. In particular, they explore a single backtracking tree in which
the decomposed subproblems are not solved separately but rather can be solved in any interleaved
401

BACCHUS , DALMAO , & P ITASSI

fashion. As a result, they are not limited to following the decomposition scheme specified by a fixed
branch decomposition. As we will see, the limitation of a static decomposition scheme means that
RC-Space and RC-Cache must perform exponentially worse than our algorithms on some instances.
2.4.3 AND/OR S EARCH :
In more recent work Dechter and Mateescu (2007) have shown that the notion of AND/OR search
spaces (Nilsson, 1980) can be applied to formalize the divide and conquer approach to S UM P ROD
problems utilized by RC. In this formulation the structure that guides the AND/OR search algorithm
is a pseudo tree. (Choosing the pseudo tree is the nondeterministic part of the computation.)
Definition 5 (Primal Graph) The primal graph of a hypergraph H is an undirected graph G that
has the same vertices as H and has an edge connecting two vertices if and only if those two vertices
appear together in some hyperedge of H.
Definition 6 (Pseudo Tree) Given an undirected graph G with vertices and edges (V, EG ), a pseudo
tree for G is a directed rooted tree T with vertices and edges (V, ET ) (i.e., the same set of vertices as
G), such that any edge e that is in G but not in T must connect a vertex in T to one of its ancestors.
That is, e = (v1 , v2 ) ∧ e ∈ EG ∧ e 6∈ ET implies that either v1 is an ancestor of v2 in T or v2 is an
ancestor of v1 in T .
This implies that there is no edge of G connecting vertices lying in different subtrees of T .
Given a S UM P ROD problem S = hV, F, ⊕, ⊗i with underlying hypergraph H, we can form G, the
primal graph of H. The vertices of G are the variables of the problem V and any pair of variables
that appear together in some function of F will be connected by an edge in G. A pseudo tree T for
G will then have the property that two vertices of T (variables of S) can only appear in functions of
F with their ancestors or their descendants, they cannot appear in functions with their siblings nor
with their ancestor’s siblings nor with the descendants of such siblings.
This implies that once a variable v and all of its ancestors in T have been instantiated, the variables contained in its children subtrees become disconnected. That is, the variables in these subtrees
no longer appear in functions together, and the resulting subproblems can be solved independently.
The AND/OR search algorithm utilizes this fact to solve these subproblems independently, just like
recursive conditioning.
Example 5 Given the hypergraph H = (V, E) where V = {1, 2, 3, 4, 5} and E = {{1, 2, 3},
{1, 4},{2, 5}, {3, 5}}, the primal graph of H is G = (V, EG ) where EG = {(1, 2), (1, 3), (2, 3),
(1, 4), (2, 5), (3, 5)}. H, its primal graph G, and a pseudo tree for G are shown in Figure 4. The
dotted lines shown on the pseudo tree are the edges of G that are not in the pseudo tree. As can be
seen from the diagram these edges connect nodes only with their ancestors.
The space efficient version of the AND/OR-Space search algorithm (Dechter & Mateescu,
2007) is shown in Algorithm 3. It solves the S UM P ROD instance S = hV, F, ⊕, ⊗i, taking as
input a pseudo tree for the problem T (i.e., the hypergraph for S is converted to a primal graph
G, and T is a pseudo tree for G), and an initially empty set of instantiated variables ρ. The algorithm solves a sub-problem of the original instance S reduced by the instantiations ρ, S|ρ . The
sub-problem being solved is defined by the functions of S|ρ that are over the variables contained in
the passed sub-tree T . Initially, with ρ being empty and T being the original pseudo tree containing
all variables, the algorithm solves the original problem S.
402

BACKTRACKING S EARCH

FOR

#SAT AND BAYES

1
1

2

3

1

2

3
4

4

5

Hypergraph

4

5

2
3
5

Primal Graph
Pseudo Tree

Figure 4: The hypergraph, primal graph, and a pseudo tree for Example 5.

The nodes of the pseudo tree T are variables of the problem S, and we also attach to each node
n of T a set of functions fns(n). A function f of F is in fns(n) if and only if (a) n is in the scope of
f and (b) all other variables in the scope of f are ancestors of n in T . This means that f will have a
fully instantiated set of arguments when AND/OR search instantiates the node (variable) n.
Algorithm 3: AND/OR-Space—Linear Space AND/OR search
1
2
3
4
5
6
7
8
9
10

AND/OR-Space (T, ρ)
begin
p = 0; r = root (T )
STr = set of subtrees below r
forall d ∈ {instantiations of r} do
Q
α = f ∈fns(r) LOOKUP(value of f on ρ ∪ {r = d})
Q
p = p + α × T ′ ∈STr AND/OR-Space (T ′ , ρ ∪ {r = d})
end
return p
end

The algorithm operates on the variable r that is the root of the pseudo tree T . For each instantiation of r the algorithm computes α, the product of the functions in F that have now become fully
instantiated by the assignment to r, i.e., those in fns(r). It then invokes a separate recursion for each
child of r passing the subtree rooted by that child to the recursive call. AND/OR search exploits
decomposition through these separate recursions. If r has only one child, then the problem is not
decomposed—there is only the single reduced subproblem that has resulted from instantiating r.
Like RC, AND/OR search can be made more time efficient at the expense of using more space.
Algorithm 4 shows the caching version AND/OR-Cache (called AND/OR graph search by Dechter
and Mateescu (2007)). Let label (n) for any node n in the pseudo tree T be the set of ancestors
of n that appear in some function with n or with some descendant of n in T . It is only the instantiations to label (n) that can affect the functions over the variables in the subtree rooted by n.
Hence, label (n) plays the same role as the root label of the passed branch decomposition in RCCache: only instantiations to these variables can affect the subproblem currently being computed.
403

BACCHUS , DALMAO , & P ITASSI

Hence, like RC-Cache, AND/OR-Cache can use the instantiations in the subset, y, of ρ intersecting
label (root(T )) along with T to index a cache.
Finally, as with RC-Cache+ , propagation can be used to decrease the number of branches that
AND/OR search needs to explore. For example, the recursive calls over the children of r can be
terminated when one of these calls returns the value zero.
Algorithm 4: AND/OR-Cache—AND/OR search with caching
1
2
3
4
5
6
7
8
9
10
11
12
13

AND/OR-Cache (T, ρ)
begin
p = 0; r = root (T )
y = ρ ∩ label (root (T ))
if InCache(T, y) then
return GetValue(T, y)
STr = set of subtrees below r
forall d ∈ {instantiations of r} do
Q
α = f ∈fns(r) LOOKUP(value of f on ρ ∪ {r = d})
Q
p = p + α × T ′ ∈STr AND/OR-Cache (T ′ , ρ ∪ {r = d})
end
return p
end

AND/OR-Cache+ Some variable order dynamism can be employed during AND/OR search. In
particular, the variables along any chain in the pseudo tree T can be reordered without affecting
the decompositions specified by T . A chain is a sub-path of T such that none of its nodes, except
perhaps the last, have more than one child. In Figure 4 nodes 2, 3, and 5 form a chain. The resultant
extension, AND/OR-Cache+ , can dynamically chose to next instantiate any of the variables in
the chain that starts at the root of its passed pseudo tree T . (Marinescu and Dechter (2006) refer
to AND/OR-Cache+ as “AND/OR with partial variable ordering”. However they did not utilize
caching in their version of the algorithm.)
It will then pass the rest of the chain (and the nodes below) to its next recursive call, or if the
chosen variable was the last in the chain it will invoke a separate recursive call for each child. Like
RC-Cache+ , AND/OR-Cache+ does not have complete freedom in its choice of variable—it must
chose a variable from the top most chain. Furthermore, AND/OR-Cache+ can only use its caching
scheme at the bottom of each chain (i.e., after all variables in the chain have been instantiated) since
its cache requires that the same set of variables be instantiated. This makes AND/OR-Cache+ very
similar to RC-Cache+ .
2.4.4 OTHER E XACT A LGORITHMS
The algorithm most commonly used for BAYES is the join tree algorithm (Lauritzen & Spiegelhalter, 1988), which can also be adapted to solve other kinds of S UM P ROD problems. The join-tree
algorithm first organizes the primal graph of the S UM P ROD problem into a tree by clustering the
variables, and it then performs message passing on the tree where the messages are computed by a
variable elimination process. In the context of BAYES the main advantage of join-tree algorithms is
404

BACKTRACKING S EARCH

FOR

#SAT AND BAYES

that they compute all marginals. That is they compute the posterior probability of all of the variables
given some evidence.
In contrast, the default version of variable elimination computes only the posterior distribution
for a single variable. However, Kask et al. (2005) show how the join-tree algorithm can be reduced
to a version of VE that remembers some of its intermediate results and runs in the same time and
space as VE. Hence, all of the results we state here comparing VE with our new backtracking based
algorithms also hold for the join tree algorithm.
Computing all Marginals All of the algorithms described above, i.e., VE, RC, and AND/OR
search, can be modified to compute all marginals when solving BAYES without any change to their
worst case complexity. In particular, besides the results of Kask et al. (2005), Darwiche (2001) has
shown that RC can compute all marginals on BAYES problems with an extra bottom up traversal
of its search tree—at most doubling its run time. The same technique can be applied to AND/OR
search algorithms. For the DPLL algorithms we present here, Sang et al. (2005b) have given an
even simpler scheme for modifying them so that they can computing all marginals. Sang et al.’s
scheme involves maintaining some extra information during search and does not require an extra
traversal of the search tree.
Another algorithm that has now been mostly superseded is cut-set conditioning (Pearl, 1988).
Here the idea is to identify a subset of variables which when set reduce the underlying hypergraph
of the S UM P ROD into a tree. The reduced S UM P ROD can then be easily solved. However, the
approach requires trying all possible instantiations of the cut-set yielding a runtime that is usually
worse than RC-Cache. Nevertheless, cutset conditioning can potentially be applied in conjunction
with other exact algorithms (Mateescu & Dechter, 2005).
Finally, an important early algorithm called DDP was presented by Bayardo and Pehoushek
(2000). This was a version of DPLL that utilized dynamic decomposition for solving #S AT. In
terms of the algorithms discussed above, AND/OR-Space can be viewed as being an version of
DDP that utilizes a pseudo tree to guide its variable ordering. In the original presentation of DDP,
any variable ordering could be used including dynamic variable orderings. The search continued
until the problem was decomposed into independent components (tested for during search) at which
point a separate recursion was used to solve each component. Hence, the DDP explored an AND/OR
search tree, however this tree need not correspond to any pseudo tree over the original problem.
(The DVO and DSO AND/OR search schemes presented by Mateescu and Dechter (2005) are also
versions of DDP run with particular variable ordering heuristics). In comparison with the algorithms
we present in the next section, Bayardo and Pehoushek (2000) did not provide a complexity analysis
of DDP, DDP did not use caching to enhance its performance, and DDP still has less flexibility in its
variable ordering. In particular, once the problem has been split into independent components the
search must solve these components sequentially in separate recursions. Inside each recursion the
search can only branch on the variables of the current component. That is, DDP cannot interleave
the solution of these components like the DPLL algorithms we present here.
2.5 Complexity Analysis
All known algorithms for BAYES, #S AT and S UM P ROD run in exponential-time in the worst case.
However, when the branch width of the underlying hypergraph of the instance, w, is small, the
some of the above algorithms are much more efficient. It can be shown that the algorithms VE, RCCache and AND/OR-Cache discussed above run in time and space nO(1) 2O(w) . We note that the
405

BACCHUS , DALMAO , & P ITASSI

complexity of these algorithms is usually given in terms of tree width or elimination width, and not
branch width. However, by Lemmas 1, 2, and 3, these concepts are equivalent to within a factor of
2, and therefore the asymptotic complexity can equivalently be stated in terms of any of these three
notions of width (tree width, branch width, or elimination width). For analyzing our backtracking
algorithms, branch width is be somewhat more natural, and for this reason we have chosen to state
all complexity results in terms of branch width.
The runtime of the variable elimination algorithm is easily seen to be at most nO(1) 2O(w) . To
see this, notice that the algorithm proceeds in n stages, removing one variable at each stage. Suppose that the algorithm is run on some variable ordering that has elimination width v. The algorithm
removes the ith variable during the ith stage. At the ith stage, all functions involving this variable
are merged to obtain a new function. As indicated in Section 2.4.1, computing the new function
involves iterating overall possible instantiations of its variables. The runtime of this stage is therefore exponential in the number of underlying variables of the new function, which is bounded by v.
Thus, the runtime of the algorithm is bounded by nO(1) 2O(v) . Now by Lemmas 1 and 2 and 3, if the
elimination width is v, then the branch width is at most v + 1, and therefore the overall runtime is
as claimed. It can also be noted that since the new function must be stored, the space complexity of
variable elimination is the same as its time complexity, i.e., nO(1) 2O(w) .
It has also been shown that the run times of RC-Cache and RC-Cache+ are bounded by nO(1) 2O(w)
(Darwiche, 2001). Further, there is a nice time-space tradeoff. That is, the space-efficient implementation of RC, RC-Space, runs in time 2O(w log n) but needs only space linear in the size of the
input, where as RC-Cache has space complexity equal to its time complexity, nO(1) 2O(w) . We will
present proofs showing that our DPLL based algorithms can achieve the same time and time/space
bounds; our proofs give the bounds for RC-Space, RC-Cache, and RC-Cache+ as special cases.
Finally, it has been shown that AND/OR-Space runs in time 2O(w log n) (Dechter & Mateescu,
2007). Specifically, Dechter and Mateescu show that AND/OR-Space runs in time exponential in the
height of its inputed pseudo tree, and Bayardo and Miranker (1995) show that this height is bounded
w log n. Lemma 1 then shows that the bound also holds for branch width. Similarly, Dechter and
Mateescu (2007) show that AND/OR-Cache runs in time and space bounded by nO(1) 2O(w) by
exploiting the very close relationship between pseudo trees and elimination orders.
Making the algorithms deterministic. As stated above, all of these algorithms are in fact nondeterministic algorithms each requiring a different nondeterministically determined input. Hence, the
stated complexity bounds mean that there exists some choice of nondeterministic input (i.e., some
variable ordering for VE, some branch decomposition for RC, and some pseudo tree for AND/OR
search) with which the algorithm can achieve the stated complexity bound.
However, to achieve this runtime in practice, we will need to be able to find such a good branch
decomposition (variable ordering, pseudo tree) efficiently. Unfortunately, the general problem of
computing an optimal branch decomposition (i.e., one that has width equal to the branch width of
H) is NP-complete. However, Robertson and Seymour (1995) present an algorithm for computing
a branch decomposition with branch width that is within a factor of 2 of optimal and that runs in
time nO(1) 2O(w) , where w is the branch width of H. By first running this deterministic algorithm
to compute a good branch decomposition, one can obtain deterministic versions of RC-Cache and
RC-Cache+ that run in time and space nO(1) 2O(w) , as well as a deterministic version of RC-Space
that runs in linear space and time 2O(w log n) . These deterministic versions no longer require access
to a nondeterministically determined choice to achieve their stated runtimes.
406

BACKTRACKING S EARCH

FOR

#SAT AND BAYES

Algorithm 5: DPLL for SAT
1
2
3
4
5
6
7
8
9
10

DPLL (φ)
begin
if φ has no clauses then
return TRUE
else if φ contains an empty clause then
return FALSE
else
choose a variable x that appears in φ
return (DPLL(φ|x=0 ) ∨ DPLL(φ|x=1 ))
end

Similarly with a nearly optimal branch decomposition, we can use Lemmas 1-3 to find a nearly
optimal elimination ordering, and thus can obtain a deterministic version of the variable elimination
algorithm that runs in time and space nO(1) 2O(w) . And finally, from that nearly optimal elimination
ordering the bucket-tree construction of Dechter and Mateescu (2007) can be used to construct a
nearly optimal pseudo tree, and thus we can obtain a deterministic version of AND/OR-Space that
runs in linear space and time 2O(w log n) , and a deterministic version of AND/OR-Cache that runs in
time and space nO(1) 2O(w) .

3. Using DPLL for #S AT and S UM P ROD
Now we present our methods for augmenting backtracking search with different caching schemes
so that it can solve S UM P ROD with time and space guarantees at least as good as the other exact
algorithm for S UM P ROD. For ease in presentation we present DPLL-based algorithms for solving
#S AT, and derive complexity results for these algorithms. Later we will discuss how the algorithms
and complexity results can be applied to other instances of S UM P ROD (like BAYES).
3.1 DPLL and #DPLL:
DPLL is a nondeterministic algorithm for S AT, that has also been used to solve various generalizations of S AT, including #S AT (Dubois, 1991; Zhang, 1996; Birnbaum & Lozinskii, 1999; Littman,
Majercik, & Pitassi, 2001). DPLL solves S AT by performing a depth-first search in the space of
partial instantiations (i.e., it is a standard backtracking search algorithm). The nondeterministic part
of the computation is lies in the choice of which variable to query (i.e., instantiate) next during its
search. It operates on S AT problems encoded in clause form (CNF).
The standard DPLL algorithm for solving S AT is given in Algorithm 5. We use the notation
φ|x=0 or φ|x=1 to denote the new CNF formula obtained from reducing φ by setting the variable x
to 0 or 1. Reducing φ by x = 1 (x = 0) involves removing from φ all clauses containing x (¬x)
and removing the falsified ¬x (x) from all remaining clauses.
DPLL is a nondeterministic procedure that generates a decision tree representing the underlying
CNF formula. For solving S AT, the decision tree is traversed in a depth-first manner until either a
satisfying path is encountered, or until the whole tree is traversed (and all paths falsify the formula).
The nondeterminism of the algorithm occurs in the choice of variable on line 8. In practice this
407

BACCHUS , DALMAO , & P ITASSI

Algorithm 6: #DPLL for #S AT (no caching)
1
2
3
4
5
6
7
8
9
10

#DPLL (φ)
// Returns the probability of φ
begin
if φ has no clauses then
return 1
else if φ contains an empty clause then
return 0
else
choose a variable x that appears in φ
return ( 12 #DPLL(φ|x=0 ) + 21 #DPLL(φ|x=1 ))
end

nondeterminism is typically resolved via some heuristic choice. Also, the algorithm utilizes early
termination of the disjunctive test on line 9; i.e., if the first test returns TRUE the second recursive
call is not made. Thus, the algorithm stops on finding the first satisfying path.
Note that we do not require that DPLL perform unit propagation. In particular, unit propagation
can always be realized through the choice of variable at line 8. In particular, if we force DPLL to
always chose a variable that appears in a unit clause of φ whenever one exists, this will have the
same effect as forcing DPLL to perform unit propagation after every variable instantiation. That is,
after a variable is chosen, and instantiated to one of its values, the input CNF φ will be reduced. The
reduced formula, φ|x=0 or φ|x=1 , passed to the next recursive call may contain unit clauses. With
unit propagation, the variables in these clauses would be instantiated so as to satisfy the unit clauses.
If instead, we force one of these variable to be chosen next, one instantiation would immediately
fail due to the generation of an empty clause, while the other would instantiate the variable to the
same value as unit propagation. Hence, since we analyze DPLL as a nondeterministic algorithm,
this includes those deterministic realizations that perform unit propagation.
A simple modification of DPLL allows it to count all satisfying assignments. Algorithm 6 gives
the #DPLL algorithm for counting. The algorithm actually computes the probability of the set of
satisfying assignments under the uniform distribution. Hence, the number of satisfying assignments
can be obtained by multiplying this probability by 2n , where n is the number of variables in φ. The
alternative would be to return 2 raised to the number of unset variables whenever φ has no clauses
(line 4) and not multiply the recursively computed counts by 21 (line 9).
Known exponential worst-case time bounds for DPLL also apply to #DPLL: for unsatisfiable
formulas, both algorithms have to traverse an entire decision tree before terminating. Although this
decision tree can be small (e.g., when an immediate contradiction is detected), for some families of
formulas the decision tree must be large. In particular, it is implicit in the results of Haken (1985)
that any decision tree for the formulas encoding the (negation of the) propositional pigeonhole
principle has exponential size, and thus DPLL and #DPLL must take exponential-time on these
examples. This lower bound does not, however, help us discriminate between algorithms since
all known algorithms for #S AT and BAYES take exponential-time in the worst-case. Nevertheless,
#DPLL requires exponential time even on instances that can be efficiently solved by competing
algorithms for S UM P ROD. To see this, consider a 3CNF formula over 3n variables consisting of
408

BACKTRACKING S EARCH

FOR

#SAT AND BAYES

n clauses that share no variables. Any complete decision tree has exponential size, and therefore
#DPLL will require exponential time. In contrast, since this formula has low tree width it can be
solved in polynomial time by VE, RC, or AND/OR search.
3.2 DPLL with Caching:
Given that the obvious application of DPLL to solve S UM P ROD can give exponentially worse
performance than the standard algorithms, we now examine ways of modifying DPLL so that it
can solve #S AT (and thus BAYES and S UM P ROD) more efficiently. To understand the source of
#DPLL’s inefficiency consider the following example.
Example 6 The following diagram shows a run of #DPLL on φ = {(w ∨ x)(y ∨ z)}. Each node
shows the variable to be branched on, and the current formula #DPLL is working on. The left hand
branches correspond to setting the branch variable to FALSE, while on the right the variable is set
to TRUE. The empty formula is indicated by {}, while a formula containing the empty clause is
indicated by {()}. The diagram shows that #DPLL encounters and solves the subproblem {(y ∨ z)}
twice: once along the path (w = 0, x = 1) and again along the path (w = 1). Note that in this
example unit propagation is realized by the choice of variable ordering—after w is set to FALSE,
#DPLL chooses to instantiate the variable x since that variable appears in a unit clause.
w:{(x ∨ w))(y ∨ z)}
H
 HH

HH

HH


H

x:{(x)(y ∨ z)}

y:{(y ∨ z)}

H
 HH

HH


H
 HH

0:{()}

y:{(y ∨ z)}
H

H

H

z:{(z)}

z:{(z)}

1:{}

HH

0:{()}

1:{}

1:{}

HH

0:{()}

1:{}

If one considers the above example of applying #DPLL to disjoint sets of clauses, it becomes
clear that in some formulas #DPLL can encounter the same subproblem an exponential number of
times.
3.2.1 DPLL

WITH

S IMPLE C ACHING (#DPLL-S IMPLE C ACHE )

One way to prevent this duplication is to apply memoization. As indicated in Example 6, associated
with every node in the DPLL tree is a formula f such that the subtree rooted at this node is trying
to compute the number of satisfying assignments to f . When performing a depth-first search of
the tree, we can keep a cache that contains all formulas f that have already been solved, and upon
reaching a new node of the tree we can avoid traversing its subtree if the value of its corresponding
formula is already stored in the cache.
In Example 6 we would cache {(y ∨ z)}, when we solve it along the path (w = 0, x = 1)
thereby avoid traversing the subtree below (w = 1).
409

BACCHUS , DALMAO , & P ITASSI

Algorithm 7: #DPLL algorithm with simple caching (#DPLL-SimpleCache)
1
2
3

4
5
6
7
8
9
10

#DPLL-SimpleCache (φ)
// Returns the probability of φ
begin
if InCache(φ) then
// Also detects obvious formulas.
return GetValue(φ)
else
choose a variable x that appears in φ
val = 12 #DPLL-SimpleCache (φ|x=0 ) + 21 #DPLL-SimpleCache (φ|x=1 )
AddToCache(φ,val )
return val
end

The above form of caching, which we will call simple caching (#DPLL-SimpleCache) can be
easily implemented as shown in Algorithm 7.4 As with #DPLL, #DPLL-SimpleCache returns the
probability of its input formula φ; multiplying this by 2n gives the number of satisfying assignments.
In addition to formulas stored in the cache there are also the following obvious formulas whose
value is easy to compute. (1) The empty formula {} containing no clauses has value 1. (2) Any
formula containing the empty clause has value 0. Obvious formulas can be treated as if they are
implicitly stored in the cache (they need not be explicitly stored in the cache, rather their values can
be computed as required).
The following (low complexity) subroutines are used to access the cache. (1) AddToCache(φ, r):
adds to the cache the fact that formula φ has value r. (2) InCache(φ): takes as input a formula φ
and returns true if φ is in the cache. (3) GetValue(φ): takes as input a formula φ known to be in the
cache and returns its stored value. There are various ways of computing a cache key from φ. For
example, φ can be maintained as a sorted set of sorted clauses, and then cached as if it was a text
string. Such a caching scheme has nO(1) complexity.
Surprisingly, simple caching, does reasonably well. The following theorem shows that simple
caching achieves runtime bounded by 2O(w log n) , where w is the underlying branch width. As with
our complexity analysis of earlier algorithms presented in Section 2.5, the simple caching algorithm
can also be made deterministic by first computing a branch decomposition that is within a factor
of 2 of optimal (using the Robertson-Seymour algorithm), and then running #DPLL-SimpleCache
with a variable ordering determined by this branch decomposition.
Theorem 1 For solving #S AT with n variables, there is an execution of #DPLL-SimpleCache that
runs in time bounded by 2O(w log n) where w is the underlying branch width of the instance. Furthermore, the algorithm can be made deterministic with the same time guarantees.
Although the theorem shows that #DPLL-SimpleCache does fairly well, its performance is not
quite as good as the best S UM P ROD algorithms (which run in time nO(1) 2O(w) ).
4. Simple caching has been utilized before (Majercik & Littman, 1998), but without theoretical analysis.

410

BACKTRACKING S EARCH

FOR

#SAT AND BAYES

Algorithm 8: #DPLL algorithm with component caching (#DPLL-Cache)
1
2
3

4
5
6
7
8
9
10
11
12
13
14
15
16

#DPLL-Cache (Φ)
// Returns the probability of the set of disjoint formulas Φ
begin
if InCache(Φ) then
// Also detects obvious formulas.
return GetValue(Φ)
else
Ψ = RemoveCachedComponents(Φ)
choose a variable x that appears in some component φ ∈ Ψ
Ψ− = ToComponents(φ|v=0 )
#DPLL-Cache (Ψ − {φ} ∪ Ψ− )
Ψ+ = ToComponents(φ|v=1 )
#DPLL-Cache (Ψ − {φ} ∪ Ψ+ )
AddToCache(φ, 21 GetValue(Ψ− ) + 12 GetValue(Ψ+ ))
if #DPLL-Space then
RemoveFromCache(Ψ− ∪ Ψ+ )
return GetValue(Φ)
end

3.2.2 DPLL

WITH

C OMPONENT C ACHING (#DPLL-C ACHE )

Now we show that a more sophisticated caching scheme allows #DPLL to perform as well as the
best known algorithms. We call the new algorithm #DPLL-Cache, and its implementation is given
in Algorithm 8.
In the algorithm we generalize the cache to deal with sets of formulas. First, we say that a
(single) formula φ is known if its value is stored in the cache or it is an obvious formula (and its
value is implicitly stored in the cache). Given a set of formulas Φ we say that the set is known if
either every φ ∈ Φ is known, or there is some φ ∈ Φ whose value is known to be zero. In both cases
we say that Φ’s value is equal to the product of the values of the φ ∈ Φ.
Now we generalize some of the cache access subroutines. (1) InCache(Φ) is generalized so that
it can take as input a set of formulas Φ. It returns true if Φ is known as just defined. (2) Similarly
GetValue(Φ) is generalized to take sets of formulas as input. It returns the product of the cached
values of the formulas φ ∈ Φ.
The intuition behind #DPLL-Cache is to recognize that as variables are set the input formula
may become broken up into disjoint components, i.e., sets of clauses that share no variables with
each other. Since these components share no variables we can compute the number of solutions to
each component and multiply the answers to obtain the total solution count. Thus, it is intended
that GetValue be called with a set of disjoint components Φ. In that case it will correctly return the
solution count for Φ—i.e., the product of the solution counts for each φ ∈ Φ.
The algorithm creates a standard DPLL tree, however it caches component formulas as their
values are computed. It keeps its input in decomposed form as a set of disjoint components, and
if any of these components are already in the cache (and thus their value is known) it can remove
411

BACCHUS , DALMAO , & P ITASSI

these parts of the input—reducing the size of the problem it still has to solve and avoiding having
to resolve these components.
The new algorithm uses the previously defined cache access subroutines along with two additional (low complexity) subroutines. (1) ToComponents(φ): takes as input a formula φ, breaks it
up into a set of minimal sized disjoint components, and returns this set. (2) RemoveCachedComponents(Φ): returns the input set of formulas Φ with all known formulas removed. The input to
#DPLL-Cache is always set of disjoint formulas. Hence, to run #DPLL-Cache on the input formula
φ we initially make the call #DPLL-Cache (ToComponents(φ)).
ToComponents simply computes the connected components of the primal graph generated by
φ. That is, in this graph all of the variables of φ are nodes, and two nodes are connected if and only
if the corresponding variables appear together (in any polarity) in a clause of φ. Each connected
component of this primal graph (which can be computed with a simple depth-first traversal of the
graph Cormen, Leiserson, Rivest, & Stein, 2001), defines a set of variables whose clauses form an
independent component of φ.
Each call of #DPLL-Cache completes with the solution of the unknown components from the
set of inputed components Φ. If all components of Φ are known the product of the values of these
components will be returned at line 4. Otherwise the input set of components is reduced by removing all known components (line 6), which must leave at least one unknown component and
potentially reduces the size of the remaining problem to be solved. Then a variable from some unsolved component is chosen and is branched on. Since the variable only appears in the component
φ its assignment can only affect φ. In particular, its assignment might break φ into smaller components (line 8 and 11). The recursive call will solve all components it is passed, so after the two
recursive calls the value of φ can be computed and cached (line 12). Finally, since all components
in the inputed set Φ are now solved its value can be retrieved from the cache and returned.
Example 7 Figure 5 illustrates the behavior of #DPLL-Cache on the formula φ = {(a, b, c, x),
(¬a, b, c), (a, ¬b, c), (d, e, f, x), (¬d, e, f ), (d, ¬e, f )}. Although the problem could be solved
with a simpler search tree, we use a variable ordering that generates a more interesting behavior.
Each node shows the variable to be branched on, and the current set of components #DPLLCache is working on. The known components (i.e., those already in the cache) are marked with an
asterisk (∗ ). The branch variables are set to FALSE on the left branch and TRUE on the right branch.
The empty formula is indicated by {}, while a formula containing the empty clause is indicated
by {()}. To simply the diagram we use unit propagation to simplify the formula after the branch
variable is set. This avoids the insertion into the diagram of nodes where unit clause variables are
branched on. Finally, note that known formulas are removed before a recursive call is made, as per
line 6 of Algorithm 8).
At the root, once x has been set to false, φ is broken up into two components φa,b,c = {(a, b, c),
(¬a, b, c), (a, ¬b, c)}, and φd,e,f = {(d, e, f ), (¬d, e, f ), (d, ¬e, f )}. The search tree demonstrates
that it does not matter how the search interleaves branching on variables from different components,
the components will still be solved independently. We see that the leftmost node in the tree that
branches on f succeeds in solving the component {(e, f ), (¬e, f )}. This component is then added
to the cache. Similarly, the parent node that branches on b solves the component {(b, c), (¬b, c)}.
(The subcomponents Ψ− and Ψ+ generated by setting b, lines 8 and 11 of Algorithm 8, and performing unit propagation are equal to the empty formula, {}, and thus are known). On backtrack
to d, the alternate value for d does not affect the component {(b, c), (¬b, c)}, so its value can be
retrieved from the cache leaving only the component {(e, f )} to be solved. Branching on e solves
412

BACKTRACKING S EARCH

FOR

#SAT AND BAYES

x:{φ}
HH
HH

HH

H
  
..
φa,b,c ,
a:
.
φd,e,f
H
 HH

HH


HH


HH



 H


{(b, c)},
{(b, c), (¬b, c)},
b:
d:
φd,e,f
φd,e,f ∗
H
H
n 
o∗ nH o∗
 HH

H
{}
{}

H
HH

HH





{(b, c), (¬b, c)}∗ ,
{(b, c), (¬b, c)},
e:
b:
{(e, f )}
{(e, f ), (¬e, f )}
HH
HH

H


   	∗H
  	∗ 
{}
{}
f:
{(e, f ), (¬e, f )}∗
{(e, f ), (¬e, f )}
H

H
n  o nH o
{}∗
{()}∗

H
n 
o∗ nH o∗
{}
{}

Figure 5: Search Space of #DPLL-Cache

this component. Backtracking to d we have that both {(e, f )} and {(e, f ), (¬e, f )} are solved, so
φd,e,f ’s value can be computed and placed in the cache. On backtracking to a, the alternate value
for a does not affect the component φd,e,f , so its value can be retrieved from the cache leaving
only the component {(b, c)} to be solved. Branching on b solves this component, after which both
{(b, c)} and {(b, c), (¬b, c)} are solved so φa,b,c ’s value can be computed and placed in the cache.
The search can then backtrack to try setting x to TRUE.
We can obtain the following upper bound on the runtime of #DPLL-Cache.
Theorem 2 For solving #S AT on n variables, there exists an execution of #DPLL-Cache that runs in
time bounded by nO(1) 2O(w) where w is the underlying branch width of the instance. Furthermore,
the algorithm can be made deterministic with the same time guarantees (as discussed in Section 2.5).
So we see that #DPLL-Cache can achieve the same level of performance as the best S UM P ROD
algorithms.
Finally, there is a third variant of #DPLL with caching, #DPLL-Space , that achieves a nontrivial time-space tradeoff. This algorithm is the natural variant of #DPLL-Cache, modified to remove
cached values so that only linear space is consumed. The algorithm utilizes one additional subroutine. (6) RemoveFromCache(Φ): takes as input a set of formulas (a set of components) and removes
all of them from the cache. After splitting a component with a variable instantiation and computing
the value of each part, #DPLL-Space cleans up the cache by removing all of these sub-components,
so that only the value of the whole component is retained. Specifically, #DPLL-Space is exactly like
#DPLL-Cache, except that it calls RemoveFromCache(Ψ− ∪ Ψ+ ) just before returning (line 14).
413

BACCHUS , DALMAO , & P ITASSI

Theorem 3 For solving #S AT on n variables, there is an execution of #DPLL-Space that uses only
space linear in the instance size and runs in time bounded by 2O(w log n) where w is the underlying
branch width of the instance. Furthermore, the algorithm can be made deterministic with the same
time and space guarantees.
The proofs of Theorems 1–3 are given in the appendix.
3.3 Using DPLL Algorithms for Other Instances of S UM P ROD:
The DPLL algorithms described in this section can be easily modified to solve other instances of
S UM P ROD. However, since #S AT is #P complete many instances of S UM P ROD can also be solved
by simply encoding them in #S AT. For example, this approach is readily applicable to BAYES and
has proved to be empirically successful (Sang et al., 2005b). Furthermore, the encoding provided
by Sang et al. (2005b) achieves the same complexity guarantees as standard algorithms for BAYES.
(That is, the CNF encoding has tree width no greater than the original Bayes Net). Note that this
encoding assigns non-uniform probabilities to values of the variables. That is, for variable x the
probability of x = 0 might not be equal to the probability of x = 1. This is easily accommodated
in our algorithms: instead of multiplying the value returned by each recursive call by 21 we simply
multiply it by the probability of the corresponding variable value (i.e., by Pr (x = 0) or Pr (x = 1)).
On the other hand, if conversion to #S AT is inapplicable or undesirable the algorithms can
be modified to solve other instances of S UM P ROD directly. For S UM P ROD, we want to compute
L Nm
L
j=1 fj (Ej ). DPLL chooses a variable, Xi , and for each value d of Xi it recursively
Xn
X1 . . .
solves the reduced problem F|Xi =d . (Hence, instead of a binary decision tree it builds a k-ary tree).
The reduced problem F|Xi =d is to compute
M
X1

...

M M

Xi−1 Xi+1

...

m
MO

fj (Ej )|Xi =d ,

Xm j=1

where fj (Ej )|Xi =d is fj reduced by setting Xi = d. #DPLL-SimpleCache caches the solution to
the reduced problem to avoid recomputing it. For example, it can remember the reduced problem by
remembering which of the original functions in F remain (i.e., have not been reduced to a constant
value) and the set of assignments that reduced these remaining functions. #DPLL-Cache caches
the solution to components of the reduced problem. For example, it can remember a component by
remembering the set of original functions that form the component along with the set of assignments
that reduced these functions. It can compute the current components by finding the connected
components of the primal graph generated from the hypergraph of the S UM P ROD instance with
all instantiated variables removed. It is a straightforward adaptation to show that the above three
theorems continue to hold for #DPLL, #DPLL-Cache, and #DPLL-Space so modified to solve S UM P ROD.
Algorithm 9 shows how #DPLL-Cache, for example, can be modified to solve general S UM P ROD problems. The algorithm takes as input a set of components Φ, just like #DPLL-Cache,
initially containing the components of the original problem. In the algorithm fns(x) denotes the set
of functions of the original problem that (a) contain x in their scope, and (b) are fully instantiated
by the instantiation of x.
414

BACKTRACKING S EARCH

FOR

#SAT AND BAYES

Algorithm 9: S UM P ROD-DPLL-Cache algorithm for arbitrary S UM P ROD problems
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16

S UM P ROD-DPLL-Cache (Φ)
begin
if InCache(Φ) then
return GetValue(Φ)
else
Ψ = RemoveCachedComponents(Φ)
choose a variable x that appears in some component φ ∈ Ψ
p=0
foreach d ∈ domain of x do
Φd = ToComponents(φ|x=d )
Q
α = f ∈fns(x) LOOKUP(value of f on ρ ∪ {x = d})
p = p + α × S UM P ROD-DPLL-Cache(Φ − {φ} ∪ Φd )
end
AddToCache(φ, p)
return GetValue(Φ)
end

4. Comparing Algorithms for BAYES and #S AT
In this section, we will prove that our DPLL based algorithms are at least as powerful as the standard
complete algorithms for solving #S AT, and that they are provable more powerful than many of
them on some instances. This last feature is important as it means that solving S UM P ROD using
DPLL augmented with caching can in some cases solve problems that are beyond the reach of many
standard complete algorithms.
As mentioned earlier, the algorithms for S UM P ROD as well as our new DPLL-based algorithms,
are actually nondeterministic algorithms that require some nondeterministically chosen input. (This
input can be viewed as being a sequence of bits). For VE, the nondeterministic bits encode an elimination ordering; for RC, the nondeterministic bits encode a branch decomposition; for AND/OR
search the nondeterministic bits encode a pseudo tree; and for our DPLL based algorithms, the
nondeterministic bits encode the underlying decision tree indicating which variable will be queried
next in the backtracking process. Thus when comparing the “power” of these algorithms we must
be careful about how the nondeterminism is resolved. For example, VE operating with a very bad
elimination ordering cannot be expected to run as efficiently as #DPLL-Cache operating with a
very good branching strategy. First we present some definitions which allow us to state our results
precisely.
Definition 7 Let f be a CNF formula. Define Time[VE](f ) to be the minimal runtime of any variable elimination algorithm for solving #S AT for f , over all choices of elimination orderings for f .
Similarly define Time[A](f ), for A equal to RC-Cache, RC-Space, RC-Cache+ , AND/OR-Space,
AND/OR-Cache, AND/OR-Cache+ , #DPLL-Cache, and #DPLL-Space. (For example, Time[RCCache](f ) is the minimal runtime of the RC-Cache algorithm solving #S AT for f , over all possible
branch decompositions of f .)

415

BACCHUS , DALMAO , & P ITASSI

Definition 8 Let A and B be two nondeterministic algorithms for #S AT. Then we will say that A
polynomial-time simulates B if there is a fixed polynomial p such that for every CNF formula f
Time[A](f ) ≤ p(Time[B](f )).
The following theorem shows that RC-Cache and RC-Cache+ polynomially simulate VE. The
proof of this theorem is implicit in the results of Darwiche (2001).
Theorem 4 Both RC-Cache and RC-Cache+ polynomially simulate VE.
Now we prove that DPLL with caching is as powerful as previous algorithms.
Theorem 5 #DPLL-Cache polynomially simulates RC-Cache, RC-Cache+ , AND/OR-Cache,
AND/OR-Cache+ , and VE. #DPLL-Space polynomially simulates RC-Space, AND/OR-Space and
DDP.5
The proof of this theorem is given in the appendix. It should be noted that the proof also
implies that there is a deterministic version of #DPLL-Cache that has time (and space) complexity that is at least as good as any deterministic realization of RC-Cache, RC-Cache+ , AND/ORCache, AND/OR-Cache+ , or VE. Similarly, there is a deterministic version of #DPLL-Space that
has time (and space) complexity that is at least as good as any deterministic realization of RC-Space,
AND/OR-Space and DDP.
Now we prove that DPLL with caching can in some cases run super-polynomially faster than
previous algorithms. The proof is given in the appendix.
Theorem 6 None of RC-Space, RC-Cache, AND/OR-Cache, AND/OR-Space or VE can polynomially simulate #DPLL-Cache, #DPLL-Space, or #DPLL.
This theorem shows that #DPLL-Cache/Space has a basic advantage over the other standard
algorithms for S UM P ROD. That is, on some problems RC, AND/OR search, and VE will all require
time super-polynomially greater than #DPLL-Cache no matter what branch decomposition, pseudo
tree, or variable ordering they are supplied with, even when caching is utilized. The proof of this
theorem shows that the advantage of #DPLL-Cache arises from its ability to utilize dynamic variable orderings, where each branch can order the variables differently. The flexibility of a dynamic
variable ordering for these instances gives rise to increased opportunities for contradictions thereby
significantly decreasing the overall runtime.
We note that Theorem 6 does not cover those algorithms that have more flexibility in their
variable ordering, i.e., AND/OR-Cache+ , RC-Cache+ , and DDP. It is an open problem whether or
not #DPLL-Cache is superpolynomially faster than these algorithms on some instances, although
we conjecture that Theorem 6 is also true for these algorithms.
In particular, note that #DPLL-Cache still has greater flexibility in its variable ordering than any
of these algorithms. None of these algorithms have complete flexibility in their variable ordering.
AND/OR-Cache+ must select an uninstantiated variable from the chain that starts at the root of its
passed pseudo tree; RC-Cache+ must select an uninstantiated variable from the intersection of the
labels of the left and right children of the root of its passed branch decomposition; and DDP must
select an uninstantiated variable from the component it is currently solving. In contrast #DPLLCache can select any uninstantiated variable.
5. DDP is the algorithm presented by Bayardo and Pehoushek (2000).

416

BACKTRACKING S EARCH

FOR

#SAT AND BAYES

The difficulty with proving Theorem 6 for these other algorithms is that all of them can tradeoff flexibility in their variable ordering with their ability to decompose the problem. The clearest
example of this occurs with AND/OR-Cache+ . If AND/OR-Cache+ is passed a pseudo tree that is
simply a single chain of variables, it will have complete flexibility in its variable ordering, but at the
same time it will never decompose the problem. Similarly, if RC-Cache+ is provided with a branch
decomposition that has large labels it will have more flexibility in its variable ordering, but will be
less effective in decomposing the problem. For the family of problems used to prove Theorem 6
only flexibility in the variable ordering is needed to achieve a superpolynomial speedup, and thus
for example AND/OR-Cache+ can achieve this speedup by completely sacrificing decomposition.
#DPLL-Cache can manage the tradeoff between flexibility in variable ordering and decomposing the problem in more sophisticated ways. For example, it has the ability to use a variable
ordering that encourages decomposition in some parts of its search tree while using a different variable orderings in other parts of its search tree. For instance, the Cachet system, which is based on
#DPLL-Cache, employs a heuristic that dynamically trades off a variable’s ability to decompose the
problem with its ability to refute the current subtree (Sang et al., 2005a). (It employs a weighted
average of the number of clauses the variable will satisfy and the variable’s VSID score Moskewicz,
Madigan, Zhao, Zhang, & Malik, 2001). #DPLL-Cache also has the ability to interleave the solving
of its current set of components by successively choosing variables from different components. To
extend Theorem 6 to cover AND/OR-Cache+ , RC-Cache+ and DDP a family of problems exploiting these features of #DPLL-Cache would have to be developed.

5. Impact on Practice
Some of the results of this paper were first presented in a conference paper (Bacchus, Dalmao, &
Pitassi, 2003), and since that time a number of works have been influenced by the algorithmic ideas
presented here.
The Cachet system (Sang et al., 2004, 2005a) is a state of the art #S AT solver directly based
on the results presented here. Cachet like our #DPLL-Cache algorithm, is based on the ideas of
dynamic decomposition into components and caching of component solutions. It was an advance
over previous #S AT solvers in its use of caching to remember previously solved components and
in its integration of clause learning. The previous best #S AT solver, the DDP solver (Bayardo
& Pehoushek, 2000), also performed dynamic component detection but had neither component
caching nor clause learning. Our results highlighted the importance of component caching and the
possibility of basing a #S AT solver on a standard DPLL implementation thus making the integration
of clause learning feasible.
Cachet resolved a number of issues in making the algorithms we presented here practical. This
included practical ways of implementing the caching of components including a method for efficiently computing a key that could be used for cache lookup. (This method was subsequently
improved by Thurley, 2006). The Cachet system has also been used to solve BAYES, most probable
explanation (MPE), and weighted MAX-SAT problems by encoding these problems as weighted
#S AT problems (Sang et al., 2005b, 2007). This approach has proved to be very successful, especially for BAYES where it is often much superior to standard BAYES algorithms. The applications
of #S AT and the Cachet system for BAYES has been further advanced by Li et al. (2006, 2008).
It should also be noted that practical #S AT solving and its applications to other problems like
BAYES has also been advanced during this period by work on the RC algorithm and its application
417

BACCHUS , DALMAO , & P ITASSI

to compiling CNF into representations on which model counting is tractable, e.g., (Darwiche, 2004;
Chavira & Darwiche, 2006, 2008). This work has also illustrated the value of converting various
problems into weighted #S AT instances, and the utilization of techniques like clause learning (in
this case integrated into a RC style algorithm). There has also been considerable work advancing AND/OR search, e.g., (Dechter & Mateescu, 2004; Marinescu & Dechter, 2006; Dechter &
Mateescu, 2007).
One difference between the Cachet system and the RC and AND/OR search based systems mentioned above is that Cachet utilized a dynamic decomposition scheme. In particular, Cachet used a
dynamic variable ordering heuristic that attempts to trade off a variable’s ability to decompose the
problem with its ability to refute the current subtree. Because the variable ordering was dynamically
determined during search, Cachet cannot predict what components will be generated during search.
Hence it has to examine the current component (i.e., the component containing the variable just
instantiated) to discover the new components generated. Thus Cachet utilized an approach like that
specified in Algorithm 8 where a function like ToComponents is invoked on newly reduced component (see line 8). ToComponents must do a linear computation to find the new components (e.g., a
depth-first search or a union-find algorithm). In addition, for each component it must examine the
clauses contained in the component to compute a cache key.
In contrast, RC and AND/OR search take as input a static or precomputed decomposition
scheme (i.e., a branch decomposition or a pseudo tree). Hence, they are able to find components
without doing any extra work during search, and are able to more efficiently compute cache keys for
these components. For example, with AND/OR search, the algorithm simply follows the supplied
pseudo tree. When the variable V along with all variables on the path from the root to V have
been instantiated, AND/OR search knows that the variables in each subtree rooted by a child of V
forms an independent component. Hence, it can “detect” these components during search in constant time. Similarly, it need not examine the clauses over the variables in these new components to
compute a cache key. Instead it can compute a cache key from the node of the pseudo tree that roots
the component and the set of instantiations of the parents of that root that appear in clauses with
the variables of the component. Note that, the set of parents whose instantiations are relevant can
be computed before search so that all that has to be done during search is to look up their current
values.
Thus, by using a static decomposition scheme RC and AND/OR search can gain efficiency
over Cachet. However, these statically computed decompositions are not always as effective as the
dynamic scheme employed by Cachet. First, it can be useful to override the precomputed decomposition scheme so as to drive the search towards contradictions. This is the gist of Theorem 6 which
shows that more dynamic flexibility in variable ordering can provide superpolynomial reductions in
the size of the explored search tree by better exploiting such contradictions. Second, static decompositions cannot account for the different values of the variables. That is, the formula that arises
after instantiating a variable V to 0 can be quite different from the formula that arises after instantiating V to 1. This difference can negatively affect the performance of RC and AND/OR search
in at least a couple of ways: components might be generated that are not predicted by the static
decomposition scheme and thus the static scheme might not fully exploit decomposition; and due to
the specific changes to the formula generated by particular instantiations, the static decomposition
scheme might be inappropriate for much of the search space.
In practice, Cachet displays a performance that is at least as good as systems built using the
RC algorithm, and in some cases its performance is superior (see the empirical results presented
418

BACKTRACKING S EARCH

FOR

#SAT AND BAYES

by Sang et al., 2004, 2005a). It should also be noted that #DPLL-Cache can easily utilize a static
decomposition scheme and gain all of the efficiencies of such schemes. For example, if provided
with a pseudo tree #DPLL-Cache can follow any ordering of the variables in that pseudo tree under
which parents are always instantiated before their children. Like AND/OR search it will know that
the children of any node in the pseudo tree each root an independent component, so it also will be
able to detect these components in constant time. Furthermore, it would be able to utilize the more
efficient caching scheme of AND/OR search. In this case its advantage over AND/OR search would
be that it would have the freedom to interleave the solving of its components.6
In more recent work our algorithms have also been applied to optimization problems (Kitching
& Bacchus, 2008). This work involved adding branch and bound techniques to the decomposition
and component caching described in #DPLL-Cache. During branch and bound dynamic variable
ordering can be very effective. In particular, one wants to branch on variables that will drive the
value of the current path towards a better value as this can generate a global bound that can be more
effective in pruning the rest of the search space. The empirical results of Kitching and Bacchus
(2008) show that the added flexibility of #DPLL-Cache can sometimes yield significant performance improvements over AND/OR search even when the extra flexibility of AND/OR-Cache+ is
exploited.

6. Final Remarks
In this paper we have studied DPLL with caching, analyzing the performance of various types
of caching for #S AT. Our results apply immediately to a number of instances of the S UM P ROD
problem including BAYES, since #S AT is complete for the class #P. However, our proofs can also
be modified without much difficulty so that our complexity results apply directly to any problem in
S UM P ROD.
More sophisticated caching methods have also been explored for solving S AT by Beame et al.
(2003) who showed that some of these methods can considerably increase the power of DPLL.
However, these more sophisticated caching methods are currently not practical due to their large
overheads. In other related work, one of the results of Aleknovich and Razborov (2002) showed that
SAT could be solved in time nO(1) 2O(w) . Our results extend this to any problem in S UM P ROD—as
shown in Section 2.1 SAT is an instance of S UM P ROD.
We have proved that from a theoretical point of view, #DPLL-Cache is just as efficient in terms
of time and space as other state-of-the-art exact algorithms for S UM P ROD. Moreover, we have
shown that on specific instances, #DPLL-Cache substantially outperforms the basic versions of
these other algorithms. The empirical results presented in the works described in Section 5 indicate
that these advantages can often be realized in practice and that on some problems our DPLL based
algorithms can yield significant performance improvements.
There are a number of reasons why our DPLL based algorithms can outperform traditional
algorithms for S UM P ROD. Algorithms like VE and the join tree algorithm (which is used in many
BAYES inference systems), take advantage of the global structure of interconnections between the
functions as characterized by the tree width or branch width of the instance. Our DPLL algorithms
however, can also naturally exploit the internal or local structure within the functions. This is
accomplished by instantiating variables and reducing the functions accordingly. This can lead to
6. Marinescu and Dechter (2007) present a method for searching an AND/OR tree in a best-first manner. This method
can also interleave the solving of components, but in general best-first search has exponential space overheads.

419

BACCHUS , DALMAO , & P ITASSI

improvements especially when the functions are encoded in a way to expose more of the function’s
internal structure, such as an encoding by sets of clauses (e.g., see Li et al., 2008). There are two
prominent examples of structure that can be exploited by DPLL.
First, some of the subproblems might contain zero valued functions. In this case our algorithms
need not recurse further—the reduced subproblem must have value 0.7 In VE the corresponding
situation occurs when one of the intermediate functions, Fi , produced by summing out some of the
variables, has value 0 for some setting of its inputs. In VE there is no obvious way of fully exploiting
this situation. VE can achieve some gains by ignoring those parts of Fi ’s domain that map to 0
when Fi appears in a product with other functions. However, it can still expend considerable effort
computing some other intermediate function Fj many of whose non-zero values might in fact be
irrelevant because they will eventually be multiplied by zero values from Fi .
Second, it can be that some of the input functions become constant prior to all of their variables
being set (e.g., a clause might become equivalent to TRUE because one of its literals has become
true), or they might become independent of some of their remaining variables. This means the subproblems f |xi =1 and f |xi =0 might have quite different underlying hypergraphs. Our DPLL-based
algorithms can take advantage of this fact, since they work on these reduced problems separately.
For example, our algorithms are free to use dynamic variable orderings, where a different variable
ordering is used solving each subproblem. VE, on the other hand, does not decompose the problem
in this way, and hence cannot take advantage of this structure.
In BAYES this situation corresponds to context-specific independence where the random variable X might be dependent on the set of variables W, Y, Z when considering all possible assignments to these variables (so f (X, W, Y, Z) is one of the input functions), but when W = True it
might be that X becomes independent of Y (i.e., f (X, W, Y, Z)|W =1 might be a function F (X, Z)
rather than F (X, Y, Z)). Previously only ad-hoc methods have been proposed (Boutilier, Friedman,
Goldszmidt, & Koller, 1996) to take advantage of this kind of structure.
It should be noted however, that when the problem’s functions have little or internal structure
VE can be significantly more efficient than any of the other algorithms (RC, AND/OR search and
our DPLL algorithms). VE only uses simple multiplication and summation operations and does
have any of the overheads involved with instantiating variables and exploring an AND/OR search
tree or backtracking tree.
RC and AND/OR search share some of the same advantages over VE. However, they do not have
as much flexibility as our DPLL algorithms. We have shown in Theorem 6 that fully exploiting the
zero valued functions can in some instances require dynamic variable orderings that lie outside of
the range of the basic versions of RC and AND/OR search. Although our proof does not cover the
enhanced versions of RC and AND/OR (RC-Cache+ and AND/OR-Cache+ ), we have pointed out
that even these versions do not have the same flexibility as our DPLL algorithms. In practice, the
empirical evidence provided by the Cachet system (Sang et al., 2004, 2005a) and by the branch
and bound system described by Kitching and Bacchus (2008) support our belief that this added
flexibility can be important in practice.
The exploitation of context-specific independence also poses some problems for RC and AND/OR
search algorithms. In particular, the static decomposition schemes they employ are incapable of
fully exploiting this structure—as pointed out above the underlying hypergraphs of the subproblems arising from different instantiations can be radically different. However, although our DPLL
7. For #S AT this corresponds to the situation where a clause becomes empty.

420

BACKTRACKING S EARCH

FOR

#SAT AND BAYES

algorithms are in principle able to exploit such structure, it remains an open problem to find practical
ways to accomplishing this. Specifically, when a decomposition scheme is computed prior to search
sophisticated (and computationally complex) algorithms can be utilized. It is difficult to overcome
the overhead of such methods when they are used dynamically during search (although see Li and
van Beek 2004 for some work in this direction). The development of methods that are light weight
enough to use during search and are still effective for selecting decomposition promoting variables
remains an open problem.
Finally, as shown in the proof of Theorem 5, RC and AND/OR search possess no intrinsic
advantages over our DPLL algorithms except perhaps conceptually simplicity. The proof shows
that our DPLL algorithms can simulate RC and AND/OR search in such a way that no additional
computation is required. Furthermore, as pointed out in the Section 5 our algorithms are also able
to utilize static decomposition schemes obtaining the same efficiency gains as RC and AND/OR
search.
Recently, several papers (Sanner & McAllester, 2005; Mateescu & Dechter, 2007) have made
significant progress on developing more compact representations for functions (rather than tabular
form), thereby potentially enhancing all of the algorithms discussed in this paper (VE, RC, etc.) by
allowing them to exploit additional local structure within the functions. An interesting future step
would be to combine the unique dynamic features of #DPLL-Cache with one of these promising
compact function representations to try to further improve S UM P ROD algorithms.
Acknowledgments This research funded by governments of Ontario and Canada through their
NSERC and PREA programs. Some of the results of this paper were presented in an earlier conference paper (Bacchus et al., 2003). We thank Michael Littman for valuable conversations.

Appendix A. Proofs
A.1 Lemmas Relating Branch Width, Tree Width, and Elimination Width
Lemma 2 Let H = (V, E) be a hypergraph with a tree-decomposition of width w. Then there is
an ordering π of the vertices V such that the induced width of H under π is at most w.
Proof: Let H = (V, E) be a hypergraph of tree width w and let Ttd be a tree decomposition
that achieves width w. That is, the maximum sized label of Ttd is of size w + 1. We can assume
without loss of generality that the labels of the leaves of Ttd are in a one-to-one correspondence
with the edges of H. For an arbitrary node m in Ttd , let label (m) be the set of vertices in the label
of m, Am be the tree rooted at m, vertices(m) be the union of the labels of the leaf nodes in Am
(i.e., the hyperedges of H appearing below Am ), and depth(m) be the distance from m to the root.
Let x be any vertex of H, and let leaves(x) be the set of leaves of Ttd that contain x in their
label. We define node(x) to be the deepest common ancestor in Ttd of all the nodes in leaves(x),
and the depth of a vertex, depth(x), to be depth(node(x)). Note that x ∈ label (node(x)), since
the path from the left-most leaf in leaves(x) to the right-most leaf must pass through node(x); and
that x does not appear in the label of any node outside of the subtree rooted at node(x), since no
leaf outside of this subtree contains x.
Finally let π = x1 , . . . , xn be any ordering of the vertices such that if depth(y) < depth(x),
then y must precede x in the ordering. We use the notation y <π x to indicate that y precedes x in
421

BACCHUS , DALMAO , & P ITASSI

the ordering π (and thus y will be eliminated after x). We claim that the induced width of π is at
most the width of Ttd , i.e., w.
Consider Anode(x) , the subtree rooted at node(x), and vertices(node (x)), the union of the labels
of the leaves of Anode (x) . We make the following observations about these vertices.
1. If y ∈ vertices(node (x)) and y <π x, then y labels node(x) and node(y) must be ancestor
of node(x) (or equal). y <π x implies that depth(y) ≤ depth(x). There must be a path from
the leaf in Anode(x) containing y to node(y), and since node (y) is at least as high as node(x)
the path must go through node(x) (or we must have node(x) = node(y)). In either case
y ∈ label (node(x)).
2. If y ∈ vertices(node(x)) and y >π x then node(y) must lie inside Anode(x) and node(y)
must be a descendant of node(x) (or equal). y >π x implies that depth(y) ≥ depth(x).
There must be a path from the leaf in A containing y to node(y), and since node(y) is at
least as deep at node(x) there must either be a further path from node(y) to node(x), or
node(y) = node(x).
Note further that condition 2 implies that if y >π x and y appears in the subtree below node(x),
then all hyperedges in the original hypergraph H containing y must also be in the subtree below
node(x).
We claim that the hyperedge produced at stage i in the elimination process when xi is eliminated
is contained in label (node(xi )). Since the size of this set is bounded by w + 1, we thus verify that
the induced width of π is bounded by w (note that the hyperedge produced in elimination does not
contain xi where as label (node(xi )) does).
The base case is when x1 is eliminated. All hyperedges containing x1 are contained in the subtree below node(x1 ), thus the hyperedge created when x1 is eliminated is contained in vertices(node (x1 )).
All other vertices in vertices(node (x1 )) follow x1 in the ordering so by the above they must label
node(x1 ) and vertices(node(x1 )) ⊆ label (node(x1 )).
When xi is eliminated there are two types of hyperedges that might be unioned together: (a)
those hyperedges containing xi that were part of the original hypergraph H, and (b) those hyperedges containing xi that were produced as x1 , . . . , xi−1 were eliminated. For the original hyperedges, all these are among the leaves below node(xi ), and thus are contained in vertices(node(xi )).
For a new hyperedge produced by eliminating one of the previous variables, say the variable y, the
hyperedge it produced is contained in label (node (y)) by induction, which in turn is contained in
vertices(node(y)). If y is in the subtree below node(x) we get that this hyperedge is contained in
vertices(node(x)) since this is a superset of vertices(node (y)). Otherwise, node(y) lies in another
part of the tree, and its label cannot contain x (no node outside the subtree below node(x) has x in
its label). Thus the hyperedge created when it is eliminated also cannot contain xi .
In sum the hyperedge created when xi is eliminated is contained in vertices(node(xi )), since
all of the hyperedges containing xi at this stage are in this set. Furthermore, all vertices x1 , . . . , xi−1
are removed from this hyperedge, thus it contains only variables following xi in the ordering. Hence,
by (1) above this hyperedge is contained in label (node(xi )). 2
Lemma 3 Let H be a hypergraph with elimination width at most w. Then H has a tree-decomposition
of tree width at most w.
422

BACKTRACKING S EARCH

FOR

#SAT AND BAYES

Proof: (Proof of Lemma 3) Let π = x1 , . . . xn be an elimination ordering for H. Then we will
construct a tree decomposition for H using π as follows. Initially, we have |E| trees, each of size
1, one corresponding to each edge e ∈ E. We first merge the trees containing xn into a bigger tree,
Tn , leaving us with a new, smaller set of trees. Then we merge the trees containing xn−1 into a
bigger tree, Tn−1 . We continue in this way until we have formed a single tree, T . Now fill in the
labels for all intermediate vertices of T so that the tree is a tree-decomposition. That is, if m and
n are two leaves of T and they both contain some vertex v, then every node along the path from m
to n must also contain v in its label. It is not too hard to see that for each xi , the tree Ti (created
when merging the trees containing xi ) has the property that the label of its root (which connects it
with the rest of T ) is contained in ei ∪ xi , where ei is the hyperedge created when xi is eliminated.
Basically, all nodes with xj , j > i, are already contained in Ti so xi does not need to label Ti ’s root.
Furthermore, if xj j < i is contained in Ti ’s root label, then xj must have been in some original
hyperedge with a variable xk k ≥ i: thus xj would have appeared in the hyperedge ei generated
when xi was eliminated.
Hence the tree width of the final tree T can be no larger than the induced width of π. 2
A.2 Complexity Results for Caching Versions of DPLL
For the proof of theorems 1 and 2 we will need some common notation and definitions. Let f be
k-CNF formula with n variables and m clauses, let H be the underlying hypergraph associated with
f with branch width w. By the results of Darwiche (2001), there is a branch decomposition of
H of depth O(log m) and width O(w). Also by the results of Robertson and Seymour (1995), it
is possible to find a branch decomposition, Tbd , such that Tbd has branch width O(w) and depth
O(log m), in time nO(1) 2O(w) . Thus our main goal for each of the three theorems will be to prove
the stated time and space bounds for our DPLL-based procedures, when they are run on a static
ordering that is easily obtainable from Tbd .
Recall that the leaves of Tbd are in one-to-one correspondence with the clauses of f . We will
number the vertices of Tbd according to a depth-first preorder traversal of Tbd . For a vertex numbered
i, let fi denote the subformula of f consisting of the conjunction of all clauses corresponding to the
leaves of the tree rooted at i. Let Vars(fi ) be the set of variables in the (sub)formula fi . Recall
that in a branch decomposition the label of each vertex i, label (i), is the set of variables in the
intersection of Vars(fi ) and Vars(f −fi ). Each node i in Tbd partitions the clauses of f into three
sets of clauses: fi , fiL , and fiR , where fiL is the conjunction of clauses at the leaves of Tbd to the
left of fi , and fiR is the conjunction of clauses at the leaves to the right of fi .
All of our DPLL caching algorithms achieve the stated run time bounds by querying the variables in a specific, static variable ordering. That is, down any branch of the DPLL decision tree,
DT , the same variables are instantiated in the same order. (In contrast a dynamic variable ordering allows DPLL to decide which variable to query next based on the assignments that have been
made before. Thus different branches can query the variables in a different order.). The variable
ordering used in DT is determined by the depth-first pre-ordering of the vertices in the branch decomposition Tbd and by the labeling of these vertices. Let (i, 1), . . . , (i, ji ) denote the variables in
label (i) that do not appear in the label of an earlier vertex of Tbd . Note that since the width of Tbd
is w, ji ≤ w for all i. Let 1, . . . , z be the sequence of vertex numbers of Tbd . Then our DPLL algorithm will query the variables underlying f in the following static order: π = h(i1 , 1), (i1 , 2), . . . ,
(i1 , j1 ), (i2 , 1), . . . , (i2 , j2 ), . . . , (is , 1), . . . , (is , js )i i1 < i2 < . . . < is ≤ z, and j1 , . . . , js ≤ w.
423

BACCHUS , DALMAO , & P ITASSI

Note that for some vertices i of Tbd , nothing will be queried since all of the variables in its label may
have occurred in the labels of earlier vertices. Our notation allows for these vertices to be skipped.
The underlying complete decision tree, DT , created by our DPLL algorithms on input f is thus a
tree with j1 + j2 + . . . + js = n levels. The levels are grouped into s layers, with the ith layer
consisting of ji levels. Note that there are 2l nodes at level l in DT , and we will identify a particular
node at level l by (l, ρ) where ρ is a particular assignment to the first l variables in the ordering, or
by ((q, r), ρ), where (q, r) is the lth pair in the ordering π, and ρ is as before.
The DPLL algorithms carry out a depth-first traversal of DT , keeping formulas in the cache
that have already been solved along the way. (For #DPLL-SimpleCache, the formulas stored in
the cache are of the form f |ρ , and for #DPLL-Cache and #DPLL-Space, the formulas stored are
various components of ToComponents(f |ρ ).) If the algorithm ever hits a node where the formula
to be computed has already been solved, it can avoid that computation, and thus it does not do a
complete depth-first search of DT but rather it does a depth-first search of a pruned version of DT .
For our theorems, we want to get an upper bound on the size of the pruned tree actually searched by
the algorithm.
Theorem 1 For solving #S AT with n variables, there is an execution of #DPLL-SimpleCache that
runs in time bounded by 2O(w log n) where w is the underlying branch width of the instance. Furthermore, the algorithm can be made deterministic with the same time guarantees.
Proof: We want to show that the size of the subtree of DT searched by #DPLL-SimpleCache
is at most 2O(w log n) . When backtracking from a particular node (l, ρ) = ((q, r), ρ) at level l in DT ,
the formula put in the cache, if it is not already known, is of the form f |ρ . (Recall ρ is a setting to the
first l variables.) However, we will see that although there are 2l different ways to set ρ, the number
of distinct formulas of this form is actually much smaller than 2l . Consider a partial assignment, ρ,
where we have set all variables up to and including (q, r), for some q ≤ is and some r ≤ jq . The
number of variables set by ρ (the length of ρ) is j1 + j2 + . . . + jq−1 + r.
Let ρ− denote the partial assignment that is consistent with ρ where only the variables in ρ that
came from the labels of the vertices on the path from the root of Tbd up to and including vertex q
are set. The idea is that ρ− is a reduction of ρ, where ρ− has removed the assignments of ρ that are
irrelevant to fq and fqR .
Consider what happens when the DPLL algorithm reaches a particular node ((q, r), ρ) at level
l of DT . At that point the algorithm is solving the subproblem f |ρ , and thus, once we backtrack to
this node, f |ρ = fqL |ρ ∧ fq |ρ ∧ fqR |ρ is placed in the cache, if it is not already known. Note that all
variables in the subformula fqL are set by ρ, and thus either fqL |ρ = 0, in which case nothing new
is put in the cache, or fqL |ρ = 1 in which case f |ρ = fq |ρ ∧ fqR |ρ = fq |ρ− ∧ fqR |ρ− is put in the
cache. Thus, the set of distinct subformulas placed in the cache at level l = (q, r) is at most the
set of all subformulas of the form fq |ρ− ∧ fqR |ρ− , where ρ− is a setting to all variables in the labels
from the root to vertex q, plus the variables (q, 1), ..., (q, r). There are at most d · w such variables,
where q has depth d in Tbd (each label has at most w variables since this is the width of Tbd ). Hence
the total number of such ρ− ’s is at most 2(w·d) . This implies that the number of subtrees in DT at
level l + 1 that are actually traversed by #DPLL-SimpleCache is at most 2 · 2w·d = 2O(w·d) , where
d is the depth of node q in Tbd . Let t be the number of nodes in DT that are actually traversed by
#DPLL-SimpleCache. Then, t is at most n2O(w·log n) , since t is the sum of the number of nodes
visited at every level of DT and for each node q in Tbd d ∈ O(log m) = O(log n).
424

BACKTRACKING S EARCH

FOR

#SAT AND BAYES

Accounting for the time to search the cache, the overall runtime of #DPLL-SimpleCache is at
most t2 , where again t is the number of nodes in DT that are traversed by the algorithm. Thus,
#DPLL-SimpleCache runs in time (n2O(w·log n) )2 = 2O(w·log n) . 2
Theorem 2 For solving #S AT on n variables, there exists an execution of #DPLL-Cache that runs in
time bounded by nO(1) 2O(w) where w is the underlying branch width of the instance. Furthermore,
the algorithm can be made deterministic with the same time guarantees.
Proof: We prove the theorem by placing a bound on the number of times #DPLL-Cache can
branch on any variable xl . Using the notation specified above, xl corresponds to some pair (q, r) in
the ordering π used by #DPLL-Cache. That is, xl is the r’th new variable in the label of vertex q of
the branch decomposition Tbd .
When #DPLL-Cache utilizes the static ordering π, it branches on, or queries, the variables
according to that order, always reducing the component containing the variable xi that is currently due to be queried. However, since previously cached components are always removed (by
RemoveCachedComponents in the algorithm), it can be that when it is variable xi ’s turn to be
queried, there is no component among the active components that contains xi . In this case, #DPLLCache simply moves on to the next variable in the ordering, continuing to advance until it finds
the first variable that does appear in some active component. It will then branch on that variable
reducing the component it appears in, leaving the other components unaltered.
This implies that at any time when #DPLL-Cache selects xl as the variable to next branch on it
must be the case that (1) xl appears in an active component. In particular the value of this component
is not already in the cache. And (2) no variable prior to xl in the ordering π appears in an active
component. All of these variables have either been assigned a particular value by previous recursive
invocations, or the component they appeared in has been removed because its value was already in
the cache.
In the branch decomposition Tbd let p be q’s parent (q must have a parent since the root has
an empty label). We claim that whenever #DPLL-Cache selects xl as the next variable to branch
on, the active component containing xl must be a component in the reduction of fp whose form is
determined solely by the settings of the variables in p and the r variables of q that have already been
set. If this is the case, then there can be at most 2(w+r) = 2O(w) different components that xl can
appear in, and hence #DPLL-Cache can branch on xl at most 2O(w) times as each time one more of
these components gets stored in the cache.
Now we prove the claim. The label of q consists of variables appearing in p’s label and variables
appearing in the label of q’s sibling. Since all of the variables in label (p) have been set, q and its
sibling must now have an identical set of unqueried variables in their labels. Hence, q must be the
left child of p as by the time the right child is visited in the ordering, xl will have already been
queried. Thus, at the time xl is queried, fp will have been affected only by the current setting of
label (p) (as these are the only variables it shares with the rest of the formula) and the first r queried
variables from label (q). That is, fp can be in at most 2(w+r) different configurations, and thus the
component containing xl can also be in at most this many different configurations.
Thus with n variables we obtain a bound on the number of branches in the decision tree explored
by #DPLL-Cache of n2O(w) . As in the proof of the previous theorem, the overall runtime is at most
quadratic in the number of branches traversed, to give the claimed bound of nO(1) 2O(w) . 2

425

BACCHUS , DALMAO , & P ITASSI

Theorem 3 For solving #S AT on n variables, there is an execution of #DPLL-Space that uses only
space linear in the instance size and runs in time bounded by 2O(w log n) where w is the underlying
branch width of the instance. Furthermore, the algorithm can be made deterministic with the same
time and space guarantees.
Proof: For this proof, it will be more natural to work with a tree decomposition rather than a
branch decomposition.
Let f be a k-CNF formula with n variables and m clauses and let H be the underlying hypergraph associated with f . We begin with a tree decomposition Ttd of depth O(log m) and width
O(w) (computable in time nO(1) 2O(w) ). We can assume without loss of generality that the leaves
of Ttd are in one-to-one correspondence with the clauses of f . Each node i in Ttd partitions f into
three disjoint sets of clauses: fi , the conjunction of clauses at the leaves of the subtree of Ttd rooted
at i, fiL , the conjunction of clauses of the leaves of Ttd to the left of fi , and fiR , the conjunction of
clauses of the leaves of Ttd to the right of fi . #DPLL-Space will query the variables associated with
the labels of Ttd according to the depth-first preorder traversal. Let the variables in label (i) not appearing in an earlier label on the path from the root to node i be denoted by S(i) = (i, 1), . . . , (i, ji ).
If i is a non-leaf node with j and k being its left and right children, then the variables in S(i) are
exactly the variables that occur in both fj and fk but that do not occur outside of fi . If we let c
be the total number of nodes in Ttd , then #DPLL-Space will query the variables underlying f in
the following static order: S(1), S(2), . . . , S(c), where some S(i) may be empty. The underlying
decision tree, DT , created by #DPLL-Space is a complete tree with n levels. As before we will
identify a particular node s at level l of DT by s = (l, ρ) where ρ is a particular assignment to the
first l variables in the ordering, or by s = ((q, r), ρ) (the r th variable in S(q)).
#DPLL-Space carries out a depth-first traversal of DT , storing the components of formulas in
the cache as they are solved. However, now components of formulas are also popped from the cache
so that the total space ever utilized is linear. If the algorithm hits a node where all of the components
of the formula to be computed are known, it can avoid traversing the subtree rooted at that node.
Thus it searches a pruned version of DT .
During the (pruned) depth-first traversal of DT , each edge that is traversed is traversed twice,
once in each direction. At a given time t in the traversal, let E = E1 ∪ E2 be the set of edges that
have been traversed, where E1 are the edges that have only been traversed in the forward direction,
and E2 are the edges that have been traversed in both directions. The edges in E1 constitute a partial
path p starting at the root of DT . Each edge in p is labeled by either 0 or 1. Let p1 , . . . , pk be the
set of all subpaths of p (beginning at the root) that end in a 1-edge. Let ρ1 , . . . , ρk be subrestrictions
corresponding to p1 , . . . , pk except that the last variable that was originally assigned a 1 is now
assigned a 0. For example, if p is (x1 = 0, x3 = 1, x4 = 0, x5 = 1, x6 = 0, x2 = 0), then
ρ1 = (x1 = 0, x3 = 0), and ρ2 = (x1 = 0, x3 = 1, x4 = 0, x5 = 0). Then the information that is
in the cache at time t contains ToComponents(f |ρi ), i ≤ k.
For a node q of Ttd and corresponding subformula fq , the context of fq is a set of variables
defined as follows. Let (q1 , . . . , qd ) denote the vertices in Ttd on the path from the root to q (excluding q itself). Then the context of fq is the set Context (fq ) = S(q1 ) ∪ S(q2 ) ∪ . . . ∪ S(qd ).
Intuitively, the context of fq is the set of all variables that are queried at nodes that lie along the path
to q. Note that when we reach level l = (q, 1) in DT , where the first variable of S(q) is queried,
we have already queried many variables, including all the variables in Context(fq ). Thus the set
of all variables queried up to level l = (q, 1) can be partitioned into two groups relative to fq : the
426

BACKTRACKING S EARCH

FOR

#SAT AND BAYES

irrelevant variables, and the set Context(fq ) of relevant variables. We claim that at an arbitrary
level l = (q, r) in DT , the only nodes at level l that are actually traversed are those nodes ((q, r), ρ)
where all irrelevant variables in ρ (with respect to fq ) are set to 0. The total number of such nodes
at level l = (q, r) is at most 2|Context(fq )|+r which is at most 2w log n . Since this will be true for all
levels, the total number of nodes in DT that are traversed is bounded by n2w log n . Thus, all that
remains is to prove our claim.
Consider some node s = ((q, r), α) in DT . That is, α = α1 α2 . . . αq−1 b1 . . . br−1 , where for
each i, αi is an assignment to the variables in S(i), and b1 . . . br−1 is an assignment to the first r − 1
variables in S(q). Let the context of fq be S(q1 ) ∪ . . . ∪ S(qd ), d ≤ log n. Now suppose that α
assigns a 1 to some non-context (irrelevant) variable, and say the first such assignment occurs at αut ,
the tth variable in αu , u ≤ q − 1. We want to show that the algorithm never traverses s.
Associated with α is a partial path in DT ; we will also call this partial path α. Consider the
subpath/subassignment p of α up to and including αut = 1. If α is traversed, then we start by
traversing p. Since the last bit of p is 1 (i.e., αut = 1) when we get to this point, we have stored
in the cache ToComponents(f |ρ ) where ρ is exactly like p except that the last bit, αut , is zero. Let
j be the first node in q1 , q2 , . . . qd with the property that the set of variables S(j) are not queried
in p. (On the path to q in Ttd , j is the first node along this path such that the variables in S(j) are
not queried in p.) Then ToComponents(f |ρ ) consists of three parts: (a) ToComponents(fjL |ρ ), (b)
ToComponents(fj |ρ ), and (c) ToComponents(fjR |ρ ).
Now consider the path p′ that extends p on the way to s in DT , where p′ is the shortest subpath of
α where all of the variables S(i) for i < j have been queried. The restriction corresponding to p′ is a
refinement of p where all variables in S(1)∪S(2)∪. . . S(j−1) are set. Since we have already set everything that occurs before j, we will only go beyond p′ if some component of ToComponents(f |p′ )
is not already in the cache. ToComponents(f |p′ ) consists of three parts: (a) ToComponents(fjL |p′ ),
(b) ToComponents(fj |p′ ), and (c) ToComponents(fjR |p′ ). Because we have set everything that occurs before j, all formulas in (a) will be known. Since p′ and ρ agree on all variables that are relevant
to fj , ToComponents(fj |p′ ) = ToComponents(fj |ρ ) and hence these formulas in (b) in the cache.
Similarly all formulas in (c) are in the cache since ToComponents(fjR |p′ ) = ToComponents(fjR |ρ ).
Thus all components of ToComponents(f |p′ ) are in the cache, and hence we have shown that we
never traverse beyond p′ and hence never traverse s. Therefore the total number of nodes traversed
at any level l = (q, r) is at most 2wd , where d is the depth of q in Ttd , as desired. This yields an
overall runtime of 2O(w log n) .
It is left to argue that the space used is linear in the instance size. The total number of formulas
that are ever stored in the cache simultaneously is linear in the depth of the tree decomposition,
which is O(log m). Since we store each restricted formula f |ρ by storing the associated restriction
ρ, the total space ever used is O(n log m), which is linear in the input size. 2
A.3 Comparing Algorithms for BAYES and #S AT
Before proving the next theorem, we first discuss in more detail the structure of the search space
explored by various versions of RC, AND/OR search and DDP. All of these algorithms operate
in the same way. They instantiate variables and when the problem decomposes into independent
components they solve these components in separate recursions. Hence, when solving any CNF
formula f they all generate some AND/OR search tree (Dechter & Mateescu, 2007).
427

BACCHUS , DALMAO , & P ITASSI

The AND/OR search tree AO generated when one of the above algorithms solves the #S AT
instance f (a CNF formula), is a rooted tree. Each node n of AO is labeled by a formula n.f and
the subtree below n is generated when solving n.f . The root of A0 is labeled by the original formula
f . There are four different types of nodes in AO:
Query nodes. Each query node q has an associated variable q.var and two children corresponding
to the two possible instantiations of q.var . That is, its children are labeled by the formulas
q.f |q.var =0 and q.f |q.var =1 . A query node q is generated by the search algorithm whenever
it chooses to instantiate q.var and then executes recursive calls on the two resultant reduced
formulas.
AND nodes. Each AND node, a, has a query node as its parent, and has one or more children
all of which are query nodes. An AND node is generated by the search algorithm when it
decomposes the current formula into two or more independent components following the instantiation of the parent query node’s variable. Each of these components will then be solved
in one of the subtrees rooted by the AND node’s children. If a.f splits into the components
V
fi , i = 1, . . . , k, then a.f = i fi , and the i’th child of a is labeled by fi . Note that the fi
share no variables. Hence, the set of query node variables that appear in the subtree below
the i-th child of a are disjoint from the set of query node variables appearing below the j-th
child of a for all j 6= i.
Failure nodes. These are leaf nodes of the tree that are labeled with a formula containing the empty
clause. If caching is being used, failure nodes might also be labeled by a formula in the cache
that has already been shown to be unsatisfiable.
Satisfying nodes. These are leaf nodes of the tree that are labeled with a formula containing no
clauses. If caching is being used, satisfying nodes might also be labeled by a satisfiable
formula in the cache whose model count is already know.
Figure 6 shows an example AND/OR search tree.
Each node n of the AO also has a value, n.value, computed by the algorithm that generates it.
Here we only need to distinguish between zero values n.value = 0, and non-zero values denoted
by n.value = 1. Every satisfying node has value 1, and every failure node has value 0. A query
node has value 1 if and only if at least one of its children has value 1, and an AND node has value
1 if and only if all of its children have value 1. For example, in Figure 6 AND node D has value
0, while query node 2 has value 1. Note that all of the children of an AND node in AO must have
value 1 except possibly the right most child. The algorithms generating AO all terminate the search
below an AND node as soon as they discover a value 0 child—this implies that the AND node has
value 0. It can be seen that n.value = 0 if n.f is unsatisfiable and n.value = 1 if n.f is satisfiable.
Given any node n of AO, let AO(n) be the AND/OR subtree of AO rooted by n. Each satisfying
assignment ρ of n’s formula n.f defines a solution subtree S(n) of AO(n). In particular, S(n) is
a connected subtree of AO(n) rooted by n such that (1) if q is a query node in S(n) then S(n)
also contains the child of q corresponding to the assignment made by ρ (i.e., if ρ[q.var ] is the value
assigned to q.var in ρ, then S(n) will contain the child labeled by the formula q.f |q.var =ρ[q.var] ),
(2) if a is an AND node in S(n) then S(n) contains all children of a, and (3) S contains no failure
nodes. For example, a solution subtree of the AND/OR tree shown in Figure 6 (i.e., a solution
subtree of the root node) is formed by the leaf nodes b, c, f, and l; the query nodes 1, 2, 3, 4, 5, 6,
428

BACKTRACKING S EARCH

FOR

#SAT AND BAYES

1

11

2

A

16

D

n
3

8

6

12

13

!

E

u
7

B

!

C

e
4

5

c

d

o

17

!

!

i

j

19

p
q

h

15

18

g

!

b

m

10

9

f
a

14

l

r

s

!

t

x

y

z

!

v

k

w

F il
Failure
node
d
!

Satisfying node
Query node
AND node
d

Figure 6: An example AND/OR search tree with query nodes numbered 1–19, leaf nodes (both
failure and satisfying) numbered a–z, and AND nodes labeled A–E.

7, and 8; and the AND nodes A, and B. In particular, the left value of query nodes 1, 2, 3, 5, 6, 7
and 8, along with the right value of query node 4 satisfy all clauses of the formula 1.f . A solution
subtree of AO(n) exists if and only if n.value = 1.
Finally, in an AND/OR search tree we say that a query node whose parent is an AND node is
a component root. We also classify the root node as a component root. In Figure 6 query nodes 1
(the root node), 3, 6, 8, 4, 5, 9, 10, 12, 13, 17, and 19 are component roots.
Theorem 5 #DPLL-Cache polynomially simulates RC-Cache, RC-Cache+ , AND/OR-Cache,
AND/OR-Cache+ , and VE. #DPLL-Space polynomially simulates RC-Space, AND/OR-Space and
DDP.
Proof: Since RC-Cache polynomially simulates VE we can ignore VE in our proof: showing that
#DPLL-Cache polynomially simulates RC-Cache also shows that it polynomially simulates VE.
Also we assume in our proof that if any of these algorithms use unit propagation, then so does
#DPLL-Cache/Space. As explained in Section 3.1, #DPLL-Cache/Space without unit propagation
can polynomially simulate versions of #DPLL-Cache/Space using unit propagation.
429

BACCHUS , DALMAO , & P ITASSI

Each of the stated algorithms will generate an AND/OR search tree when solving a CNF formula
f . To prove the theorem we first show how any AND/OR search tree solving f can be converted
into a partial DPLL decision tree, DT , that is no bigger. Then we show that our DPLL algorithms
can solve f using DT to guide its variable ordering. Thus, we obtain the result that the minimal
runtime for any of the stated algorithms, which must result in the generation of some AND/OR
search tree AOmin , can also be achieved by our DPLL algorithms. In particular, when run on the
partial decision tree constructed from AOmin , our DPLL algorithms will achieve a polynomially
similar runtime. (This suffices to prove the theorem, as we need only show the existence of an
execution of our DPLL algorithms achieving this run time.)
To make the distinction between the AND/OR search tree and the constructed partial decision
tree clear, we will use the suffixes ao and dt to indicate elements of the AND/OR tree and decision
tree respectively.
DPLL decision trees contain only query variables, satisfying nodes, and failure nodes, where
satisfying and failure nodes are both leaf nodes. We construct a partial decision tree DT from an
AND/OR tree AO by expanding the left most solution subtree S(nao ) below every node nao ∈ AO
with nao .value = 1 into a linear sequence of query variables in DT using a depth-first ordering
of the query variables in S(nao ). For nodes nao ∈ AO with nao .value = 0 the same expansion is
attempted, but in this case it will result in a sequence of query nodes that terminate at failure nodes.
Every node qdt in DT has a pointer, dt→ao(qdt ) to a node qao in AO, at the end of the construction these pointers establish a map between the nodes in DT and the nodes in AO. Initially, the root
of DT has a pointer to the root of AO. Then, for any node qdt ∈ DT :
1. If dt→ao(qdt ) is a query node qao in AO, then make qdt a query node and create a left and
right child, ldt and rdt , for qdt in DT . We make qdt query the same variable as qao (i.e.,
qdt .var = qao .var ), and set its children to point to the children of qao (i.e., dt→ao(ldt ) and
dt→ao(rdt ) are set to the left and right children of qao in AO).
2. If dt→ao(qdt ) is an AND node aao in AO, then we reset dt→ao(qdt ) to be the left most child
of aao in AO. We then apply the first rule above, and continue.
3. If dt→ao(qdt ) is a failure node in AO then we set qdt to be a failure node. In this case qdt has
no children.
4. If dt→ao(qdt ) is a satisfying node in AO then we examine the path ρao in AO from the root
to dt→ao(qdt ). Let rao be the last component root on ρao that has a right sibling.
(a) If such an rao exists, and no node on the path from rao to dt→ao(qdt ) in AO is the right
child of a query node whose left child has value 1, then we reset dt→ao(qdt ) to be the
leftmost right sibling of rao . This node is also a component root, and hence it is a query
node in AO. We then apply the first rule above, and continue.
(b) Otherwise (either rao does not exist or there is some node on the path from rao that is
the right child of a query node whose left child has value 1), we make qdt a satisfying
node. In this case qdt has no children.
Rule 4 of the construction is where we convert the leftmost solution subtree below each node nao
in AO into a sequence of query nodes in DT by performing a depth-first traversal of this solution
subtree. In particular, in this solution subtree the leftmost right sibling of the deepest component
430

BACKTRACKING S EARCH

FOR

#SAT AND BAYES

1

11

2

3

16

12

n
4

!

13o

17

p

e
14

5b

u

15

18

a

x
6c

d
7

!

!

q

r

19v

s

t

w

9

y
!

8f

g

z

10i

h
!

l

m

j

k
Failure node
!

Satisfying node
Query node

Figure 7: The partial DPLL decision tree constructed from the AND/OR search tree of Figure 6.
Each query and leaf nodes n is numbered with the number of the corresponding node,
dt→ao(n), in the AND/OR search tree.

root is the depth-first successor of the satisfying leaf node. The condition that no node on route
to that sibling is the right child of a query node whose left child has value 1 ensures that we only
perform a depth-first traversal along the leftmost solution subtree and not along subsequent solution
subtrees. Figure 7 shows the partial decision tree that would be constructed from the AND/OR
search tree of Figure 6.
In the diagram, satisfying nodes whose pointers are reset to the next component root using
rule 4a, are numbered with the corresponding query node in the AND/OR tree followed by the
leaf label of the corresponding satisfying node. For example, node 5b in the Figure 7 represents
satisfying child b of node 4 in Figure 6 that has been redirected to its depth-first successor node 5
(the leftmost right sibling of the deepest component root 4).
As another example, in the AND/OR tree, the right child of node 6 is the AND node C. Hence, in
the decision tree, the right child of the corresponding query node 6, becomes query node 9 which is
the leftmost child of node C (rule 2). Furthermore, when we reach satisfying node j in the AND/OR
tree, we can proceed no further and hence the left child of query node 10 in the decision tree becomes
a terminal satisfying node (rule 3). In particular, although the path from the root to node 10 in the
AND/OR tree contains a component root with a right sibling, namely node 6, this path also contains
the node C that is the right child of a query node (node 6) whose left child (node 7) has value 1.
431

BACCHUS , DALMAO , & P ITASSI

There are two things to note. First, at any node ndt of DT all variables instantiated on the path
ρao in A0 from the root to dt→ao(n) have been instantiated to the same values on the path ρdt in
DT from the root to ndt . Since Rules 3 and 4b terminate paths, all nodes on ρdt are inserted only
by Rules 1, 2, and 4b. Rules 1 and 2 only insert nodes on ρdt whose parents are already on ρdt , and
Rule 1 ensures that the values assigned are the same as those in AO. Finally, Rule 4a only inserts a
node adt on ρdt if one of dt→ao(adt )’s siblings is already on ρdt , and hence that sibling’s (and a’s)
parent must already be on ρdt .
Second, no variable is queried twice along any path of DT . That is, no node ndt in DT has
an ancestor n′dt with ndt .var = n′dt .var . Again any path ρdt in DT is grown only by applications
of Rules 1, 2, and 4a. Since no path in AO queries the same variable twice, Rules 1 and 2 must
preserve this condition. Similarly Rule 4a moves to a new component root aao , and the set of query
variables at and below aao in AO is disjoint with the set of query variables already appearing in ρdt .
Using the above, from the AND/OR search tree AO generated by any of the algorithms RCSpace, AND/OR-Space or DDP when solving the formula f , we can construct a corresponding
partial decision tree DT . Now we show that #DPLL-Space can solve f by exploring a search tree
that is no larger than DT . Note that DT is itself no larger than AO, hence this will show that
#DPLL-Space can solve f with a polynomially similar run time, proving that it can polynomially
simulate RC-Space, AND/OR-Space and DDP. (Note that the run time of all of these algorithms is
polynomially related to the size of the search trees they explore.)
We execute #DPLL-Space using the variable ordering specified in DT . That is, starting at the
root rdt of DT , #DPLL-Space will always query the variable of the current node of DT , ndt .var ,
and then descend to ndt ’s left child. When it backtracks to ndt it will then descend to the right child.
Hence, we only need to show that #DPLL-Space must backtrack if it reaches a leaf of DT . That is,
it explores a search tree that is no larger than DT .
First, if #DPLL-Space reaches a failure node of DT it must detect an empty clause and backtrack. By Rule 3 of the construction any failure node fdt of DT must correspond to a failure node
dt→ao(fdt ) in AO. Since all variables instantiated on the path in AO from the root to dt→ao(fdt )
are instantiated to the same values on the path in DT from the root to fdt , we see that if an empty
clause was detected in AO at dt→ao(fdt ) then #DPLL-Space must also detect an empty clause
at fdt . (Note that if the algorithm that generated AO used unit propagation, then we assume that
#DPLL-Space does as well).
Second, if #DPLL-Space reaches a satisfying node sdt of DT it must detect that all of its current
set of components are solved and backtrack (line 4 of Algorithm 8). Let ρdt be the path in DT from
the root to sdt , ρao be the path in AO from dt→ao(sdt ) to the root, and crdt be a node on ρdt such
that dt→ao(crdt ) is a component root in AO (we say that crdt is a component root on ρdt ). We
claim that (a) if lao is a left sibling of dt→ao(crdt ) in AO, then there exists a node ldt on ρdt such
that dt→ao(ldt ) = lao , and lao .f is satisfied by ρdt ; (b) if rao is a right sibling of dt→ao(crdt ) in
AO then rao .f is in #DPLL-Space’s cache.
Given claim (a) the only clauses of the original formula not yet satisfied by ρdt are clauses from
rao .f for those nodes rao in AO that are right siblings of some component root crdt on ρdt (i.e.,
rao is a right sibling of component root dt→ao(crdt ) in AO). When #DPLL-Space arrived at crdt ,
prior to reaching sdt , all variables in AO on the path from the root to dt→ao(crdt ) have already
been instantiated to the same values on ρdt . Thus, if pao is dt→ao(crdt )’s parent in AO, #DPLLSpace would have recognized that rao .f was a separate component once it instantiated pao .var , and
it would have added rao .f to its list of components (at line 8 or 11 of Algorithm 8). Note that,
432

BACKTRACKING S EARCH

FOR

#SAT AND BAYES

once solved rao .f would not be removed from #DPLL-Space’s cache until it backtracks to undo the
instantiation of pao .var . (At which point the solution all of pao ’s children would be combined to
yield a solution to pao .f ).
Furthermore, following the variable ordering specified in DT , #DPLL-Space would not instantiate any of the variables in r.f along the path ρdt . Hence, any component that is on #DPLL-Space’s
list of components when it reaches ns must be equal to rao .f for some right sibling rao of a component root on ρdt , and by claim (b) will be removed by the call to RemoveCachedComponents(Φ)
(line 6). This will leave #DPLL-Space with an empty list of components to solve, and hence it must
backtrack at sdt .
Now we prove the claims. For (a) we see that DT will always visit the children of an AND node
in AO in a left to right order. That is, before inserting a component root crdt on its path, it must
first visit all left siblings lao of dt→ao(crdt ). After inserting ldt on its path (with dt→ao(ldt ) = lao ),
it will instantiate ldt and then start to query the nodes under lao searching alternate instantiations
to these variables until it is able to traverse a leftmost solution subtree of AO(lao ). This traversal
results in the insertion into the path of a solution to lao .f , after which DT inserts crdt on its path
using Rule 4a.
For (b) we observe that sdt is a satisfying node in DT only through the application of Rule 4b.
Hence there are two possible cases. First, it can be that none of the component roots on ρdt have a
right sibling. In this case every clause of the original formula is satisfied and #DPLL-Space must
backtrack. For example, in Figure 7 this occurs at leaf nodes l and y.
Otherwise, let crdt be a component root on ρdt such that dt→ao(crdt ) has a right sibling in AO,
and let ndt be the first node on ρdt following crdt such that (i) ndt ’s successor on ρdt is its right
child, and (ii) dt→ao(ndt ) has a left child in AO with value 1. Such a node ndt must exist, else sdt
would not have been a leaf node of DT by Rule 4a. When #DPLL-Space arrived at node crdt it
would have rao .f on its list of components for all right siblings rao of dt→ao(crdt ). There might
also be other unsolved components on this list. All of these components, however, must be equal
to rao .f for some right sibling rao of a component root on ρdt preceding crdt , and must have been
placed on the list of components prior to #DPLL-Space reaching crdt . Then, when #DPLL-Space
arrived at ndt it would have taken the left branch first. Thus it would have previously been invoked
with all of these right sibling components on its component list.
When #DPLL-Space is invoked with a list of components it either solves every component,
placing them in its cache and keeping them there until it backtracks to the node where they were
first placed on its list, or it discovers that one of these components is unsatisfiable. If one of the
components is unsatisfiable, it will immediately backtrack to the point where that component was
first placed on its list. In particular, all recursive calls where the list of components contains a known
unsatisfiable component will return immediately since the call to InCache(Φ) will detect that the
list of components has product equal to zero.
Hence, on taking the left branch at ndt , #DPLL-Space, will have on its list of components,
components of the form rao .f for right siblings of component roots above ndt on ρdt , and also lao .f
where lao is the left child of dt→ao(ndt ) in AO. Since lao has value 1, lao .f is satisfiable, and either
#DPLL-Space will solve all its components, placing their value in its cache, or it will discover that
one of the components rao .f is unsatisfiable and will backtrack without visiting sdt . Therefore, if it
does visit sdt it would have solved all components that could potentially be on its list of components,
and these components would still be in is cache since they were placed on the list before arriving at
sdt .
433

BACCHUS , DALMAO , & P ITASSI

This shows that #DPLL-Space polynomially simulates RC-Space, AND/OR-Space and DDP.
RC-Cache and AND/OR-Cache gain over RC-Space and AND/OR-Space by not having to solve
some components more than once. That is, when they arrive at a node nao in their generated
AND/OR tree AO, if nao .f has been solved before they can immediately backtrack.
#DPLL-Cache gains the same efficiency over #DPLL-Space. In particular, it need never solve
the same component more than once. Using caching to removing previously solved components
from its list of components gives rise to the same savings that are realized by adding caching to
AND/OR or RC. Formally, the same construction of a partial decision tree DT can be used. In
AO we mark all nodes where search is terminated by a cache hit as a satisfying node (if the cached
formula is satisfiable) or as a failure node (if the cached formula is unsatisfiable). Now, for example,
AND nodes can have satisfying or failure nodes as children when those components have been
solved before. Applying our construction to AO gives rise to a partial decision tree DT , and it
can then be shown that #DPLL-Cache using DT to guide its variable choices will explore a search
tree that is about the same size as DT . This proves that #DPLL-Cache polynomially simulates
RC-Cache and AND/OR-Cache.
The only subtle point is that #DPLL-Cache might not solve a component at the same point
in its search. In particular, if a component φ first appears on #DPLL-Cache’s list of components
with a previously added unsatisfiable component, #DPLL-Cache will backtrack without solving φ.
Following DT , #DPLL-Cache will only do enough work to find φ’s first solution, after which it
will proceed to the other components on its list. During its search for φ’s first solution, it will cache
all unsatisfiable reductions of φ found during this search. Thus, the next time it encounters φ it can
follow the same variable ordering and not do any extra work: the cached unsatisfiable reductions
will immediately prune all paths leading to failure and it can proceed directly to the first solution
to φ. If the other components on its list are all satisfiable, it will eventually backtrack to this first
solution and then continue to solve φ. Hence, although #DPLL-Cache might encounter φ many
times before solving it, each such encounter, except for the first, require adding to its search tree
only a number of nodes linear in the number of variables in φ. The number of nodes added by
the first encounter, where the φ’s first solution is found, and the encounter where it finally solves
φ, together equal the number of nodes required in AO to solve φ. Hence, the “encounters without
solving” do not increase the size of #DPLL-Cache’s search tree by more than a polynomial.
Finally, we note that the construction given accommodates the use of dynamic variable orderings
where the order of variables varies from branch to branch in the AND/OR search tree. (Varying
the value assigned along the left and right branch of each query variable is also accommodated).
That is, the proof also shows that #DPLL-Cache polynomially simulates AND/OR-Cache+ and
RC-Cache+ . 2
Theorem 6 None of RC-Space, RC-Cache, AND/OR-Cache, AND/OR-Space or VE can polynomially simulate #DPLL-Cache, #DPLL-Space, or #DPLL.
To prove this theorem we first observe that from a result of Johannsen (Johannsen, 2001),
#DPLL-Cache, #DPLL-Space, and #DPLL can all solve the negation of the propositional stringof-pearls principle (Bonet, Esteban, Galesi, & Johannsen, 1998) in time nO(log n) , when run with a
dynamic variable ordering. Then we prove (in Theorem 7) that all of the other algorithms require
time exponential in n on this problem. Hence, none of these algorithms can polynomially simulate
#DPLL (or the stronger #DPLL-Space or #DPLL-Cache).
434

BACKTRACKING S EARCH

FOR

#SAT AND BAYES

The string-of-pearls principle, introduced in a different form by Clote and Setzer (1998) and
explicitly by Bonet et al. (1998) is as follows. From a bag of m pearls, which are colored red and
blue, n pearls are chosen and placed on a string. The string-of-pearls principle says that if the first
pearl in the string is red and the last one is blue, then there must be a red-blue or blue-red pair of
pearls side-by-side somewhere on the string. The negation of the principle, Sm,n , is expressed with
variables pi,j and pj for i ∈ [n] and j ∈ [m] where pi,j represents whether pearl j is mapped to
vertex i on the string, and pj represents whether pearl j is colored blue (pj = 0) or red (pj = 1).
The clauses of SPm,n are as follows.
(1) Each hole gets at least one pearl: ∨m
j=1 pi,j , i ∈ [n].
(2) Each hole gets at most one pearl: (¬pi,j ∨ ¬pi,j ′ ), i ∈ [n] j ∈ [m] ,j ′ ∈ [m], j 6= j ′ .
(3) A pearl goes to at most one hole: (¬pi,j ∨ ¬pi′ ,j ), i ∈ [n], i′ ∈ [n], i 6= i′ , j ∈ [m].
(4) The leftmost hole gets assigned a red pearl and the rightmost hole gets assigned a blue pearl:
(¬p1,j ∨ pj ) and (¬pn,j ∨ ¬pj ), j ∈ [m].
(5) Any two adjacent holes get assigned pearls of the same color: (¬pi,j ∨ ¬pi+1,j ′ ∨ ¬pj ∨ pj ′ ),
1 ≤ i < n, j ∈ [m], j ′ ∈ [m], j 6= j ′ , and (¬pi,j ∨ ¬pi+1,j ′ ∨ pj ∨ ¬pj ′ ), 1 ≤ i < n, j ∈ [m],
j ′ ∈ [m], j 6= j ′ .
Johannsen (Johannsen, 2001) shows that SPn,n has quasipolynomial size tree resolution proofs.
It follows that #DPLL, #DPLL-Space and #DPLL-Cache can solve SPn,n in quasipolynomial time.
Lemma 4 (Johannsen, 2001) SPn,n can be solved in time nO(log n) by #DPLL, #DPLL-Space, and
#DPLL-Cache.
Theorem 7 Let ǫ = 1/5. Any of the algorithms RC-Space, RC-Cache, AND/OR-Cache, AND/ORǫ
Space, VE, or #DPLL-Cache using a static variable ordering, require time 2n to solve SPn,n .
Proof: It can be seen from the proof of Theorem 5 that #DPLL-Cache using a static variable
ordering can polynomially simulate all of the stated algorithms.
ǫ
Hence, it suffices to prove that #DPLL-Cache under any static ordering requires time 2n for
SPm,n , m = n. By a static ordering, we mean that the variables are queried according to this
ordering as long as they are mentioned in the current formula. That is, we allow a variable to be
skipped over if it is irrelevant to the formula currently under consideration. We will visualize SPn,n
as a bipartite graph, with n vertices on the left, and n pearls on the right. There is a pearl variable
pj corresponding to each of the n pearls, and an edge variable pi,j for every vertex-pearl pair. (Note
that there are no variables corresponding to the vertices but we will still refer to them.)
Fix a particular total ordering of the underlying n2 + n variables, θ1 , θ2 , . . . , θl . For a pearl j,
let fanin t (j) equal the number of edge variables pk,j incident with pearl j that are one of the first
t variables queried. Similarly, for a vertex i, let fanin t (i) equal the number of edge variables pi,k
incident with vertex i that are one of the first t variables queried. For a set of pearls S, let fanin t (S)
equal the number of edge variables pk,j incident with some pearl j ∈ S that are one of the first t
variables queried. Similarly for a set of vertices S, fanin t (S) equals the number of edge variables
pi,k incident with some vertex i ∈ S that are one of the first t variables queried. Let edgest (j) and
435

BACCHUS , DALMAO , & P ITASSI

edgest (S) be defined similarly although now it is the set of such edges rather than the number of
such edges. It should be clear from the context whether the domain objects are pearls or vertices.
We use a simple procedure, based on the particular ordering of the variables, for marking each
pearl with either a C or with an F as follows. In this procedure, a pearl may at some point be marked
with a C and then later overwritten with an F; however, once a pearl is marked with an F, it remains
an F for the duration of the procedure. If a pearl j is marked with a C at some particular point in
time, t, this means that at this point, the color of the pearl has already been queried, and fanin t (j)
is less than nδ , δ = 2/5. If a pearl j is marked with an F at some particular point in time t, it means
that at this point fanin t (j) is at least nδ . (The color of j may or may not have been queried.) If a
pearl j is unmarked at time t, this means that its color has not yet been queried, and fanin t (j) is
less than nδ .
For l from 1 to n2 +n, we do the following. If the lth variable queried is a pearl variable (θl = pj
for some j), and less than nδ edges pi,j incident to j have been queried so far, then mark pj with
a C. Otherwise, if the lth variable queried is an edge variable (θl = pi,j ) and fanin l (j) ≥ nδ , then
mark pearl j with an F (if not already marked with an F). Otherwise, leave pearl j unmarked.
Eventually every pearl will become marked F. Consider the first time t∗ where we have either
a lot of C’s, or a lot of F’s. More precisely, let t∗ be the first time where either there are exactly
nǫ C’s (and less than this many F’s) or where there are exactly nǫ F’s (and less than this many
C’s.) If exactly nǫ C’s occurs first, then we will call this case (a). Extend t∗ to t∗a as follows.
Let θt∗ +1 , . . . , θt∗ +c be the largest segment of variables that are all pearl variables pj such that j
is already marked with an F. Then t∗a = t∗ + c. Notice that the query immediately following θt∗a
is either a pearl variable pj that is currently unmarked, or an edge variable. On the other hand, if
exactly nǫ F’s occurs first, then we will call this case (b). Again, extend t∗ to t∗b to ensure that the
query immediately following θt∗b is either a pearl variable pj that is currently unmarked, or is an
edge variable.
The intuition is that in case (a) (a lot of C’s), a lot of pearls are colored prematurely–that is,
before we know what position they are mapped to–and hence a lot of queries must be asked. For
case (b) (a lot of F’s), a lot of edge variables are queried thus again a lot of queries will be asked.
We now proceed to prove this formally.
We begin with some notation and definitions. Let f = SPn,n , and let Vars(f ) denote the
set of all variables underlying f . A restriction ρ is a partial assignment of some of the variables
underlying f to either 0 or to 1. If a variable x is unassigned by ρ, we denote this by ρ(x) = ∗. Let
T be the DPLL tree based on the variable ordering θ. That is, T is a decision tree where variable θi
is queried at level i of T . Recall that corresponding to each node v of T is a formula f |ρ where ρ is
the restriction corresponding to the partial path from the root of T to v. The tree T is traversed by a
depth-first search. For each vertex v with corresponding path p that is traversed, we check to see if
f |p is already in the cache. If it is, then there is no need to traverse the subtree rooted below v. If
it is not yet in the cache, then we traverse the left subtree of v, followed by the right subtree of v.
After both subtrees have been traversed, we then pop back up to v, and store f |p in the cache. This
induces an ordering on the vertices (and corresponding paths) of T that are traversed—whenever
we pop back up to a vertex v (and thus, we can store its value in the cache), we put v (p) at the end
of the current order.
Lemma 5 Let f be SPn,n and let π be a static ordering of the variables. Let ρ be a partial restriction
of the variables. Then the runtime of #DPLL-Cache on (f, ρ) is not less than the runtime of #DPLLCache on (f |ρ , π ′ ), where π ′ is the ordering of the unassigned variables consistent with π.
436

BACKTRACKING S EARCH

FOR

#SAT AND BAYES

Lemma 6 For any restriction ρ, if f |ρ 6= 0 and ρ(pi,j ) = ∗, then pi,j occurs in f |ρ .
Proof: Consider the clause Ci = (pi,1 ∨ . . . ∨ pi,m ) in f . Since pi,j is in this clause, if pi,j
does not occur in f |ρ , then Ci |ρ must equal 1. Thus there exists j ′ 6= j such that ρ(pi,j ′ ) = 1. But
then the clause (¬pi,j ∨ ¬pi,j ′ )|ρ = ¬pi,j and thus pi,j does not disappear from f |ρ . 2
Corollary 1 Let θ be a total ordering of Vars(f ). Let ρ, ρ′ be partial restrictions such that ρ sets
exactly θ1 , . . . , θq and ρ′ sets exactly θ1 , . . . , θq′ , q ′ < q. Suppose that there exists θk = pi,j such
that ρ sets θk but ρ′ (θk ) = ∗. Then either f |ρ = 0 or f |ρ′ = 0 or f |ρ 6= f |ρ′ .
Case (a). Let θ be a total ordering to Vars(f ) such that case (a) holds. Let P C denote the set of
exactly nǫ pearls that are marked C and let P F denote the set of less than nǫ pearls (disjoint from
P C ) that are marked F. Note that (the color of) all pearls in P C have been queried by time t∗a ; the
color of the pearls in P F may be queried by time t∗a , and the color of all pearls in P − P C − P F
have not been queried by time t∗a . Note further that the total number of edges pi,j that have been
queried is at most nǫ+δ + n1+ǫ ≤ 2n1+ǫ .
ǫ
We will define a partial restriction, Ma , to all but 2n of the variables in θ1 , . . . , θt∗a as follows.
For each j ∈ P F , fix a one-to-one mapping from P F to [n] such that range(j) ∈ edgest∗a (j) for
each j. For each j ∈ P C , for any variable pi,j queried in θ1 , . . . θt∗a , set pi,j to 0. For any vertex i
such that all variables pi,j have been queried in θ1 , . . . , θt∗a , map i to exactly one pearl j such that
pj ∈ P − P C − P F . There are at most 2nǫ such i. (This can be arbitrary as long as it is consistent
with the one-to-one mapping already defined on P F .) For all remaining pj ∈ P − P C − P F that
have not yet been mapped to, set all queried variables pi,j to 0. For all pearls pj in P F that have
been queried in θ1 , . . . , θt∗a , assign a fixed color to each such pearl (all Red or all Blue) so that the
smallest Red/Blue gap is as large as possible. Note that the gap will be of size at least n1−ǫ . Ma
sets all variables in θ1 , . . . θt∗a except for the variables pj , j ∈ P C . Since there are nǫ such variables,
ǫ
the number of restrictions ρ to θ1 , . . . , θt∗a consistent with Ma is exactly 2n . Let S denote this set
of restrictions.
Let f ′ = f |Ma and let θ ′ be be the ordering on the unassigned variables consistent with θ. (The
set of unassigned variables is: pj , for j ∈ P C , plus all variables in θk , k > t∗a .) Let T ′ be the DPLL
tree corresponding to θ ′ for solving f ′ . By Lemma 5, it suffices to show that #DPLL-Cache when
ǫ
run on inputs f ′ and T ′ , takes time at least 2n .
Note that the first nǫ variables queried in T ′ are the pearl variables in P C , and thus the set of all
ǫ
n
2 paths of height exactly nǫ in T ′ correspond to the set S of all possible settings to these variables.
ǫ
We want to show that for each vertex v of height nǫ in T ′ (corresponding to each of the 2n settings
of all variables in P C ), that v must be traversed by #DPLL-Cache, and thus the runtime is at least
ǫ
2n .
Fix such a vertex v, and corresponding path ρ ∈ S. If v is not traversed, then there is some
ρ′ ⊆ ρ and some σ such that σ occurs before ρ′ in the ordering, and such that f ′ |σ = f ′ |ρ′ . We want
to show that this cannot happen. There are several cases to consider.
1a. Suppose that |σ| ≤ nǫ and σ 6= ρ′ . Then both ρ′ and σ are partial assignments to some of the
variables in P C that are inconsistent with one another. It is easy to check that in this case,
f ′ |ρ′ 6= f ′ |σ .
2a. Suppose that |σ| > nǫ , and the (nǫ + 1)st variable set by σ is an edge variable pi,j . Because
|ρ′ | ≤ nǫ , ρ′ (pi,j ) = ∗. By Corollary 1, it follows that f ′ |ρ′ 6= f ′ |σ .
437

BACCHUS , DALMAO , & P ITASSI

3a. Suppose that |σ| > nǫ and the (nǫ + 1)st variable set by σ is a pearl variable pj . (Again, we
know that pj is unset by ρ′ .) Since this is case (a), we can assume that pj ∈ P − P C − P F .
Call a vertex i bad if P − P F − P C ⊂ edgest∗a (i). If i is bad, then fanin t∗a (i) is greater
than n − 2nǫ ≥ n/2. Since the total number of edges queried is at most 2n1+ǫ , if follows
that the number of bad vertices is at most 4nǫ . This implies that we can find a pair i, i + 1 of
vertices and a pearl j ′ such that: (1) pi,j is not queried in θ1 , . . . , θt∗a ; (2) pi+1,j ′ is not queried
in θ1 , . . . , θt∗a ; (3) pj ′ is in P − P C − P F and thus pj ′ is also not queried. Thus the clause
(¬pi,j ∨ ¬pj ∨ ¬pi+1,j ′ ∨ pj ′ )|ρ′ does not disappear or shrink in f ′ |ρ′ , and thus f ′ |ρ′ 6= f ′ |σ .
Case (b). Let θ be a total ordering to Vars(f ) such that case (b) holds. Now let P C denote the set
of less than nǫ pearls marked C and let P F denote the set of exactly nǫ pearls marked F.
ǫ
We define a partial restriction Mb to all but 2n of the variables in θ1 , . . . , θt∗ as follows. Call a
vertex i full if all variables pi,j have been queried in θ1 , . . . , θt∗b . There are at most nǫ full vertices.
For each j ∈ P F , we will fix a pair of vertices Fj = (ij , i′j ) in [n]. Let the union of all nǫ sets Fj be
denoted by F . F has the following properties. (1) For each j, no element of Fj is full; (2) For each
j ∈ P F , Fj ∈ edgest∗b (j); and (3) every two distinct elements in F are at least distance 4 apart.
Since f anint∗b (j) ≥ nδ , and δ = 2/5 > ǫ, it is possible to find such sets Fj satisfying these criteria.
For each pi,j queried in θ1 , . . . θt∗b , where j ∈ P F and i 6∈ Fj , Mb will set pi,j to 0. For each
j ∈ P C , and for any variable pi,j queried in θ1 , . . . θt∗b , set pi,j to 0. For any full vertex i , map i
to exactly one pearl j such that pj ∈ P − P C − P F . (Again this can be arbitrary as long as it is
consistent with a one-to-one mapping.) For the remaining pj ∈ P − P C − P F that have not yet
been mapped to, set all queried variables pi,j to 0. For all pearls pj in P C , color them Red. For all
pearls pj in P F that have been queried, assign a fixed color to each pearl.
The only variables that were queried in θ1 , . . . θt∗b and that are not set by Mb are the edge
ǫ
variables, pi,j , where j ∈ P F , and i ∈ Fj . Let S denote the set of all 2n settings of these edge
variables such that each j ∈ P F is mapped to exactly one element in Fj . Let f ′ = f |Mb and let
T ′ be the DPLL tree corresponding to θ ′ for solving f ′ , where θ ′ is the ordering on the unassigned
variables consistent with θ. By Lemma 5, it suffices to show that #DPLL-Cache on f ′ and T ′ takes
ǫ
time at least 2n .
Note that the first 2nǫ variables queried in T ′ are the variables Pij ,j , Pi′j ,j , j ∈ P F . The
only nontrivial paths of height 2nǫ in T ′ are those were each j ∈ P F is mapped to exactly one
vertex in Fj , since otherwise the formula f ′ is set to 0. Thus, the nontrivial paths in T ′ of height
2nǫ correspond to S. We want to show that for each such nontrivial vertex v of height 2nǫ in T ′
(corresponding to each of the restrictions in S), that v must be traversed by #DPLL-Cache, and thus
ǫ
the runtime is at least 2n .
Fix a vertex v and corresponding path ρ ∈ S. Again we want to show that for any ρ′ ⊆ ρ, and
σ where σ occurs before ρ′ in the ordering, that f ′ |ρ′ 6= f ′ |σ . There are three cases to consider.
1b. Suppose that |σ| ≤ 2nǫ . If σ is nontrivial, then both ρ′ and σ are partial mappings of the pearls
j in P F to Fj , that are inconsistent with one another. It is easy to check that in this case
f ′ |σ 6= f ′ |ρ′ .
2b. Suppose that |σ| > 2nǫ and the (2nǫ + 1)st variable set by σ is an edge variable pi,j . Because
|ρ′ | ≤ 2nǫ , ρ′ (pi,j ) = ∗. By Corollary 1, it follows that f ′ |σ 6= f ′ |ρ′ .
438

BACKTRACKING S EARCH

FOR

#SAT AND BAYES

3b. Suppose that |σ| > 2nǫ and the (2nǫ + 1)st variable set by σ is a pearl variable pj . By the
definition of t∗b , we can assume that pj ∈ P − P C − P F . By reasoning similar to case 3a, can
find vertices i, i+1, and pearl j ′ ∈ P −P C −P F such that none of the variable pi,j , pi+1,j , pj ′
are queried in θ1 , . . . , θt∗b . Thus the clause (¬pi,j ∨ ¬pj ∨ ¬pi+1,j ′ ∨ pj ′ )|ρ′ does not disappear
to shrink in f ′ |ρ′ 1, and therefore f ′ |ρ′ 6= f ′ |σ .
ǫ

Thus for each of the two cases, #DPLL-Cache on f ′ and T ′ takes time at least 2n and thus
ǫ
#DPLL-Cache on f and T takes time at least 2n . 2

References
Aleknovich, A., & Razborov, A. (2002). Satisfiability, Branch-width and Tseitin Tautologies. In
Annual IEEE Symposium on Foundations of Computer Science (FOCS), pp. 593–603.
Bacchus, F., Dalmao, S., & Pitassi, T. (2003). Algorithms and Complexity Results for #SAT
and Bayesian Inference. In Annual IEEE Symposium on Foundations of Computer Science
(FOCS), pp. 340–351.
Bayardo, R. J., & Pehoushek, J. D. (2000). Counting Models using Connected Components. In
Proceedings of the AAAI National Conference (AAAI), pp. 157–162.
Bayardo, R. J., & Miranker, D. P. (1995). On the space-time trade-off in solving Constraint Satisfaction Problems. In Proceedings of the International Joint Conference on Artificial Intelligence
(IJCAI), pp. 558–562.
Beame, P., Impagliazzo, R., Pitassi, T., & Segerlind, N. (2003). Memoization and DPLL: Formula
Caching Proof Systems. In IEEE Conference on Computational Complexity, pp. 248–264.
Birnbaum, E., & Lozinskii, E. L. (1999). The good old Davis Putnam procedure helps counting
models. J. Artif. Intell. Research (JAIR), 10, 457–477.
Bitner, J. R., & Reingold, E. (1975). Backtracking programming techniques. Communications of
the ACM, 18(11), 651–656.
Bodlaender, H. L. (1993). A tourist guide through Treewidth. Acta Cybernetica, 11(1–2), 1–21.
Bonet, M., Esteban, J. L., Galesi, N., & Johannsen, J. (1998). Exponential separations between
restricted resolution and cutting planes proof systems. In Annual IEEE Symposium on Foundations of Computer Science (FOCS), pp. 638–647.
Boutilier, C., Friedman, N., Goldszmidt, M., & Koller, D. (1996). Context-specific independence in
Bayesian Networks. In Uncertainty in Artificial Intelligence, Proceedings of Annual Conference (UAI), pp. 115–123.
Chavira, M., & Darwiche, A. (2006). Encoding CNFs to empower component analysis. In Theory
and Applications of Satisfiability Testing (SAT), pp. 61–74.
Chavira, M., & Darwiche, A. (2008). On probabilistic inference by weighted model counting.
Artificial Intelligence, 172(6-7), 772–799.
Chavira, M., Darwiche, A., & Jaeger, M. (2006). Compiling relational bayesian networks for exact
inference. Int. J. Approx. Reasoning, 42(1-2), 4–20.
Clote, P., & Setzer, A. (1998). On PHP, st-connectivity and odd charged graphs. In Proof Complexity
and Feasible Arithmetics, Vol. 39 of DIMACS Series, pp. 93–117. AMS.
439

BACCHUS , DALMAO , & P ITASSI

Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2001). Introduction to Algorithms. 2nd
Edition. McGraw Hill.
Darwiche, A., & Allen, D. (2002). Optimal time-space tradeoff in probabilistic inference. In European Workshop on Probabilistic Graphical Models. Available at www.cs.ucla.edu/˜darwiche.
Darwiche, A. (2001). Recursive conditioning. Artificial Intelligence, 126, 5–41.
Darwiche, A. (2002). A logical approach to factoring belief networks. In Proceedings of the International Conference on Principles of Knowledge Representation and Reasoning, pp. 409–420.
Darwiche, A. (2004). New advances in compiling CNF into decomposable negation normal form.
In Proceedings of the European Conference on Artificial Intelligence (ECAI), pp. 328–332.
Davies, J., & Bacchus, F. (2007). Using more reasoning to improve #SAT solving. In Proceedings
of the AAAI National Conference (AAAI), pp. 185–190.
Davis, M., Logemann, G., & Loveland, D. (1962). A machine program for theorem-proving. Communications of the ACM, 4, 394–397.
Davis, M., & Putnam, H. (1960). A computing procedure for quantification theory. Journal of the
ACM, 7, 201–215.
Dechter, R. (1999). Bucket elimination: A unifying framework for reasoning. Artificial Intelligence,
113, 41–85.
Dechter, R., & Mateescu, R. (2004). Mixtures of deterministic-probabilistic networks and their
AND/OR search space. In Uncertainty in Artificial Intelligence, Proceedings of Annual Conference (UAI), pp. 120–129.
Dechter, R., & Mateescu, R. (2007). AND/OR search spaces for graphical models. Artificial Intelligence, 171(2-3), 73–106.
Dubois, O. (1991). Counting the number of solutions for instances of satisfiability. Theoretical
Computer Science, 81, 49–64.
Haken, A. (1985). The intractability of resolution. Theoretical Computer Science, 39, 297–305.
Hertel, P., Bacchus, F., Pitassi, T., & van Gelder, A. (2008). Clause learning can effectively psimulate general propositional resolution. In Proceedings of the AAAI National Conference
(AAAI).
Johannsen, J. (2001). Exponential incomparability of tree-like and ordered resolution. Unpublished manuscript, available at http://www.tcs.informatik.uni-muenchen.
de/˜jjohanns/notes.html.
Kask, K., Dechter, R., Larrosa, J., & Dechter, A. (2005). Unifying tree decompositions for reasoning
in graphical models. Artificial Intelligence, 166(1-2), 165–193.
Kitching, M., & Bacchus, F. (2008). Exploiting decomposition in constraint optimization problems.
In Proceedings of Principles and Practice of Constraint Programming (CP), pp. 478–492.
Lauritzen, S., & Spiegelhalter, D. (1988). Local computation with probabilities on graphical structures and their application to expert systems. Journal of the Royal Statistical Society Series
B, 50(2), 157–224.
440

BACKTRACKING S EARCH

FOR

#SAT AND BAYES

Li, W., & van Beek, P. (2004). Guiding real-world sat solving with dynamic hypergraph separator decomposition. In Proceedings of the International Conference on Tools with Artificial
Intelligence (ICTAI), pp. 542–548.
Li, W., van Beek, P., & Poupart, P. (2006). Performing incremental Bayesian Inference by dynamic
model counting. In Proceedings of the AAAI National Conference (AAAI), pp. 1173–1179.
Li, W., van Beek, P., & Poupart, P. (2008). Exploiting causal independence using weighted model
counting. In Proceedings of the AAAI National Conference (AAAI).
Littman, M. L., Majercik, S. M., & Pitassi, T. (2001). Stochastic boolean satisfiability. J. Automated
Reasoning, 27(3), 251–296.
Majercik, S. M., & Littman, M. L. (1998). Maxplan: A new approach to probabilistic planning. In
Proceedings of the International Conference on Artificial Intelligence Planning and Scheduling (AIPS), pp. 86–93.
Marinescu, R., & Dechter, R. (2006). Dynamic orderings for AND/OR branch-and-bound search
in graphical models. In Proceedings of the European Conference on Artificial Intelligence
(ECAI), pp. 138–142.
Marinescu, R., & Dechter, R. (2007). Best-first AND/OR search for graphical models. In Proceedings of the AAAI National Conference (AAAI), pp. 1171–1176.
Mateescu, R., & Dechter, R. (2007). AND/OR multi-valued decision diagrams for weighted graphical models. In Uncertainty in Artificial Intelligence, Proceedings of Annual Conference
(UAI).
Mateescu, R., & Dechter, R. (2005). AND/OR cutset conditioning. In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI), pp. 230–235.
Moskewicz, E., Madigan, C., Zhao, M., Zhang, L., & Malik, S. (2001). Chaff: Engineering an
efficient sat solver. In Proc. of the Design Automation Conference (DAC).
Nilsson, N. J. (1980). Principles of Artificial Intelligence. Tioga.
Pearl, J. (1988). Probabilistic Reasoning in Intelligent Systems (2nd edition). Morgan Kaufmann,
San Mateo, CA.
Preston, C. (1974). Gibbs States on Countable Sets. Cambridge University Press.
Rish, I., & Dechter, R. (2000). Resolution versus search: Two strategies for SAT. Journal of
Automated Reasoning, 24(1), 225–275.
Robertson, N., & Seymour, P. (1991). Graph minors X. obstructions to tree-decomposition. Journal
of Combinatorial Theory, Series B, 52, 153–190.
Robertson, N., & Seymour, P. (1995). Graph minors XIII. the disjoint paths problem. Journal of
Combinatorial Theory, Series B, 63, 65–110.
Roth, D. (1996). On the hardness of approximate reasoning. Artificial Intelligence, 82(1–2), 273–
302.
Sang, T., Bacchus, F., Beame, P., Kautz, H. A., & Pitassi, T. (2004). Combining component caching
and clause learning for effective model counting. In Theory and Applications of Satisfiability
Testing (SAT).
441

BACCHUS , DALMAO , & P ITASSI

Sang, T., Beame, P., & Kautz, H. A. (2005a). Heuristics for fast exact model counting. In Theory
and Applications of Satisfiability Testing (SAT), pp. 226–240.
Sang, T., Beame, P., & Kautz, H. A. (2005b). Performing Bayesian Inference by weighted model
counting. In Proceedings of the AAAI National Conference (AAAI), pp. 475–482.
Sang, T., Beame, P., & Kautz, H. A. (2007). A dynamic approach for MPE and weighted MAXSAT. In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI),
pp. 173–179.
Sanner, P., & McAllester, D. (2005). Affine algebraic decision diagrams (aadds) and their applications to structured probabilistic inference. In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI), pp. 1384–1390.
Spitzer, F. L. (1971). Markov random fields and Gibbs ensembles. American Mathematical Monthly,
78, 142–54.
Thurley, M. (2006). sharpSAT—Counting models with advanced component caching and implicit
BCP. In Theory and Applications of Satisfiability Testing (SAT), pp. 424–429.
Valiant, L. G. (1979a). The complexity of enumeration and reliability problems. SIAM Journal of
Computing, 9, 410–421.
Valiant, L. G. (1979b). The Complexity of Computing the Permanent. Theoretical Computer Science, 8, 189–201.
Zhang, W. (1996). Number of models and satisfiability of sets of clauses. Theoretical Computer
Science, 155, 277–288.

442

Journal of Artificial Intelligence Research 34 (2009) 569-603

Submitted 07/08; published 04/09

Learning Document-Level Semantic Properties
from Free-Text Annotations
S.R.K. Branavan
Harr Chen
Jacob Eisenstein
Regina Barzilay

BRANAVAN @ CSAIL . MIT. EDU
HARR @ CSAIL . MIT. EDU
JACOBE @ CSAIL . MIT. EDU
REGINA @ CSAIL . MIT. EDU

Computer Science and Artificial Intelligence Laboratory
Massachusetts Institute of Technology
77 Massachusetts Avenue, Cambridge MA 02139

Abstract
This paper presents a new method for inferring the semantic properties of documents by leveraging free-text keyphrase annotations. Such annotations are becoming increasingly abundant due
to the recent dramatic growth in semi-structured, user-generated online content. One especially
relevant domain is product reviews, which are often annotated by their authors with pros/cons
keyphrases such as “a real bargain” or “good value.” These annotations are representative of the
underlying semantic properties; however, unlike expert annotations, they are noisy: lay authors
may use different labels to denote the same property, and some labels may be missing. To learn
using such noisy annotations, we find a hidden paraphrase structure which clusters the keyphrases.
The paraphrase structure is linked with a latent topic model of the review texts, enabling the system to predict the properties of unannotated documents and to effectively aggregate the semantic
properties of multiple reviews. Our approach is implemented as a hierarchical Bayesian model with
joint inference. We find that joint inference increases the robustness of the keyphrase clustering and
encourages the latent topics to correlate with semantically meaningful properties. Multiple evaluations demonstrate that our model substantially outperforms alternative approaches for summarizing
single and multiple documents into a set of semantically salient keyphrases.

1. Introduction
Identifying the document-level semantic properties implied by a text is a core problem in natural
language understanding. For example, given the text of a restaurant review, it would be useful to
extract a semantic-level characterization of the author’s reaction to specific aspects of the restaurant, such as food and service quality (see Figure 1). Learning-based approaches have dramatically
increased the scope and robustness of such semantic processing, but they are typically dependent on
large expert-annotated datasets, which are costly to produce (Zaenen, 2006).
We propose to use an alternative source of annotations for learning: free-text keyphrases produced by novice users. As an example, consider the lists of pros and cons that often accompany
reviews of products and services. Such end-user annotations are increasingly prevalent online, and
they grow organically to keep pace with subjects of interest and socio-cultural trends. Beyond such
pragmatic considerations, free-text annotations are appealing from a linguistic standpoint because
they capture the intuitive semantic judgments of non-specialist language users. In many real-world
datasets, these annotations are created by the document’s original author, providing a direct window
into the semantic judgments that motivated the document text.

c
2009
AI Access Foundation. All rights reserved.

B RANAVAN , C HEN , E ISENSTEIN , & BARZILAY

pros/cons: great nutritional value
... combines it all: an amazing product, quick and friendly service, cleanliness, great nutrition ...
pros/cons: a bit pricey, healthy
... is an awesome place to go if you are health conscious. They have some really great low calorie dishes
and they publish the calories and fat grams per serving.

Figure 1: Excerpts from online restaurant reviews with pros/cons phrase lists. Both reviews assert
that the restaurant serves healthy food, but use different keyphrases. Additionally, the
first review discusses the restaurant’s good service, but is not annotated as such in its
keyphrases.

The major obstacle to the computational use of such free-text annotations is that they are inherently noisy — there is no fixed vocabulary, no explicit relationship between annotation keyphrases,
and no guarantee that all relevant semantic properties of a document will be annotated. For example,
in the pros/cons annotations accompanying the restaurant reviews in Figure 1, the same underlying
semantic idea is expressed in different ways through the keyphrases “great nutritional value” and
“healthy.” Additionally, the first review discusses quality of service, but is not annotated as such.
In contrast, expert annotations would replace synonymous keyphrases with a single canonical label, and would fully label all semantic properties described in the text. Such expert annotations
are typically used in supervised learning methods. As we will demonstrate in the paper, traditional
supervised approaches perform poorly when free-text annotations are used instead of clean, expert
annotations.
This paper demonstrates a new approach for handling free-text annotation in the context of a
hidden-topic analysis of the document text. We show that regularities in the text can clarify noise
in the annotations — for example, although “great nutritional value” and “healthy” have different
surface forms, the text in documents that are annotated by these two keyphrases will likely be
similar. By modeling the relationship between document text and annotations over a large dataset,
it is possible to induce a clustering over the annotation keyphrases that can help to overcome the
problem of inconsistency. Our model also addresses the problem of incompleteness — when novice
annotators fail to label relevant semantic topics — by estimating which topics are predicted by the
document text alone.
Central to this approach is the idea that both document text and the associated annotations reflect
a single underlying set of semantic properties. In the text, the semantic properties correspond to the
induced hidden topics — this is similar to the growing body of work on latent topic models, such as
latent Dirichlet allocation (LDA; Blei, Ng, & Jordan, 2003). However, unlike existing work on topic
modeling, we tie hidden topics in the text with clusters of observed keyphrases. This connection is
motivated by the idea that both the text and its associated annotations are grounded in a shared set
of semantic properties. By modeling these properties directly, we ensure that the inferred hidden
topics are semantically meaningful, and that the clustering over free-text annotations is robust to
noise.
Our approach takes the form of a hierarchical Bayesian framework, and includes an LDA-style
component in which each word in the text is generated from a mixture of multinomials. In addition, we also incorporate a similarity matrix across the universe of annotation keyphrases, which is

570

L EARNING D OCUMENT-L EVEL S EMANTIC P ROPERTIES FROM F REE -T EXT A NNOTATIONS

constructed based on the orthographic and distributional features of the keyphrases. We model this
matrix as being generated from an underlying clustering over the keyphrases, such that keyphrases
that are clustered together are likely to produce high similarity scores. To generate the words in each
document, we model two distributions over semantic properties — one governed by the annotation
keyphrases and their clusters, and a background distribution to cover properties not mentioned in the
annotations. The latent topic for each word is drawn from a mixture of these two distributions. After
learning model parameters from a noisily-labeled training set, we can apply the model to unlabeled
data.
We build a system that extracts semantic properties from reviews of products and services. This
system uses as training corpus that includes user-created free-text annotations of the pros and cons
in each review. Training yields two outputs: a clustering of keyphrases into semantic properties, and
a topic model that is capable of inducing the semantic properties of unlabeled text. The clustering
of annotation keyphrases is relevant for applications such as content-based information retrieval,
allowing users to retrieve documents with semantically relevant annotations even if their surface
forms differ from the query term. The topic model can be used to infer the semantic properties of
unlabeled text.
The topic model can also be used to perform multi-document summarization, capturing the key
semantic properties of multiple reviews. Unlike traditional extraction-based approaches to multidocument summarization, our induced topic model abstracts the text of each review into a representation capturing the relevant semantic properties. This enables comparison between reviews even
when they use superficially different terminology to describe the same set of semantic properties.
This idea is implemented in a review aggregation system that extracts the majority sentiment of
multiple reviewers for each product or service. An example of the output produced by this system
is shown in Figure 6. This system is applied to reviews in 480 product categories, allowing users
to navigate the semantic properties of 49,490 products based on a total of 522,879 reviews. The
effectiveness of our approach is confirmed by several evaluations.
For the summarization of both single and multiple documents, we compare the properties inferred by our model with expert annotations. Our approach yields substantially better results than
alternatives from the research literature; in particular, we find that learning a clustering of free-text
annotation keyphrases is essential to extracting meaningful semantic properties from our dataset.
In addition, we compare the induced clustering with a gold standard clustering produced by expert
annotators. The comparison shows that tying the clustering to the hidden topic model substantially
improves its quality, and that the clustering induced by our system coheres well with the clustering
produced by expert annotators.
The remainder of the paper is structured as follows. Section 2 compares our approach with previous work on topic modeling, semantic property extraction, and multi-document summarization.
Section 3 describes the properties of free-text annotations that motivate our approach. The model
itself is described in Section 4, and a method for parameter estimation is presented in Section 5.
Section 6 describes the implementation and evaluation of single-document and multi-document
summarization systems using these techniques. We summarize our contributions and consider directions for future work in Section 7. The code, datasets and expert annotations used in this paper
are available online at http://groups.csail.mit.edu/rbg/code/precis/.

571

B RANAVAN , C HEN , E ISENSTEIN , & BARZILAY

2. Related Work
The material presented in this section covers three lines of related work. First, we discuss work
on Bayesian topic modeling that is related to our technique for learning from free-text annotations.
Next, we discuss state-of-the-art methods for identifying and analyzing product properties from
the review text. Finally, we situate our summarization work in the landscape of prior research on
multi-document summarization.
2.1 Bayesian Topic Modeling
Recent work in the topic modeling literature has demonstrated that semantically salient topics can
be inferred in an unsupervised fashion by constructing a generative Bayesian model of the document text. One notable example of this line of research is Latent Dirichlet Allocation (LDA; Blei
et al., 2003). In the LDA framework, semantic topics are equated to latent distributions of words
in a text; thus, each document is modeled as a mixture of topics. This class of models has been
used for a variety of language processing tasks including topic segmentation (Purver, Körding,
Griffiths, & Tenenbaum, 2006), named-entity resolution (Bhattacharya & Getoor, 2006), sentiment
ranking (Titov & McDonald, 2008b), and word sense disambiguation (Boyd-Graber, Blei, & Zhu,
2007).
Our method is similar to LDA in that it assigns latent topic indicators to each word in the
dataset, and models documents as mixtures of topics. However, the LDA model is unsupervised,
and does not provide a method for linking the latent topics to external observed representations of
the properties of interest. In contrast, our model exploits the free-text annotations in our dataset to
ensure that the induced topics correspond to semantically meaningful properties.
Combining topics induced by LDA with external supervision was first considered by Blei and
McAuliffe (2008) in their supervised Latent Dirichlet Allocation (sLDA) model. The induction of
the hidden topics is driven by annotated examples provided during the training stage. From the perspective of supervised learning, this approach succeeds because the hidden topics mediate between
document annotations and lexical features. Blei and McAuliffe describe a variational expectationmaximization procedure for approximate maximum-likelihood estimation of the model’s parameters. When tested on two polarity assessment tasks, sLDA shows improvement over a model in
which topics where induced by an unsupervised model and then added as features to a supervised
model.
The key difference between our model and sLDA is that we do not assume access to clean
supervision data during training. Since the annotations provided to our algorithm are free-text in
nature, they are incomplete and fraught with inconsistency. This substantial difference in input
structure motivates the need for a model that simultaneously induces the hidden structure in freetext annotations and learns to predict properties from text.
2.2 Property Assessment for Review Analysis
Our model is applied to the task of review analysis. Traditionally, the task of identifying the properties of a product from review texts has been cast as an extraction problem (Hu & Liu, 2004; Liu,
Hu, & Cheng, 2005; Popescu, Nguyen, & Etzioni, 2005). For example, Hu and Liu (2004) employ
association mining to identify noun phrases that express key portions of product reviews. The polarity of the extracted phrases is determined using a seed set of adjectives expanded via WordNet

572

L EARNING D OCUMENT-L EVEL S EMANTIC P ROPERTIES FROM F REE -T EXT A NNOTATIONS

relations. A summary of a review is produced by extracting all property phrases present verbatim in
the document.
Property extraction was further refined in O PINE (Popescu et al., 2005), another system for
review analysis. O PINE employs a novel information extraction method to identify noun phrases
that could potentially express the salient properties of reviewed products; these candidates are then
pruned using WordNet and morphological cues. Opinion phrases are identified using a set of handcrafted rules applied to syntactic dependencies extracted from the input document. The semantic
orientation of properties is computed using a relaxation labeling method that finds the optimal assignment of polarity labels given a set of local constraints. Empirical results demonstrate that O PINE
outperforms Hu and Liu’s system in both opinion extraction and in identifying the polarity of opinion words.
These two feature extraction methods are informed by human knowledge about the way opinions
are typically expressed in reviews: for Hu and Liu (2004), human knowledge is encoded using
WordNet and the seed adjectives; for Popescu et al. (2005), opinion phrases are extracted via handcrafted rules. An alternative approach is to learn the rules for feature extraction from annotated
data. To this end, property identification can be modeled in a classification framework (Kim &
Hovy, 2006). A classifier is trained using a corpus in which free-text pro and con keyphrases are
specified by the review authors. These keyphrases are compared against sentences in the review
text; sentences that exhibit high word overlap with previously identified phrases are marked as pros
or cons according to the phrase polarity. The rest of the sentences are marked as negative examples.
Clearly, the accuracy of the resulting classifier depends on the quality of the automatically induced annotations. Our analysis of free-text annotations in several domains shows that automatically mapping from even manually-extracted annotation keyphrases to a document text is a difficult
task, due to variability in keyphrase surface realizations (see Section 3). As we argue in the rest of
this paper, it is beneficial to explicitly address the difficulties inherent in free-text annotations. To
this end, our work is distinguished in two significant ways from the property extraction methods described above. First, we are able to predict properties beyond those that appear verbatim in the text.
Second, our approach also learns the semantic relationships between different keyphrases, allowing
us to draw direct comparisons between reviews even when the semantic ideas are expressed using
different surface forms.
Working in the related domain of web opinion mining, Lu and Zhai (2008) describe a system
that generates integrated opinion summaries, which incorporate expert-written articles (e.g., a review from an online magazine) and user-generated “ordinary” opinion snippets (e.g., mentions in
blogs). Specifically, the expert article is assumed to be structured into segments, and a collection of
representative ordinary opinions is aligned to each segment. Probabilistic Latent Semantic Analysis
(PLSA) is used to induce a clustering of opinion snippets, where each cluster is attached to one
of the expert article segments. Some clusters may also be unaligned to any segment, indicating
opinions that are entirely unexpressed in the expert article. Ultimately, the integrated opinion summary is this combination of a single expert article with multiple user-generated opinion snippets that
confirm or supplement specific segments of the review.
Our work’s final goal is different — we aim to provide a highly compact summary of a multitude of user opinions by identifying the underlying semantic properties, rather than supplementing
a single expert article with user opinions. We specifically leverage annotations that users already
provide in their reviews, thus obviating the need for an expert article as a template for opinion inte-

573

B RANAVAN , C HEN , E ISENSTEIN , & BARZILAY

gration. Consequently, our approach is more suitable for the goal of producing concise keyphrase
summarizations of user reviews, particularly when no review can be taken as authoritative.
The work closest in methodology to our approach is a review summarizer developed by Titov
and McDonald (2008a). Their method summarizes a review by selecting a list of phrases that
express writers’ opinions in a set of predefined properties (e.g.,, food and ambiance for restaurant
reviews). The system has access to numerical ratings in the same set of properties, but there is no
training set providing examples of appropriate keyphrases to extract. Similar to sLDA, their method
uses the numerical ratings to bias the hidden topics towards the desired semantic properties. Phrases
that are strongly associated with properties via hidden topics are extracted as part of a summary.
There are several important differences between our work and the summarization method of
Titov and McDonald. Their method assumes a predefined set of properties and thus cannot capture
properties outside of that set. Moreover, consistent numerical annotations are required for training,
while our method emphasizes the use of free-text annotations. Finally, since Titov and McDonald’s
algorithm is extractive, it does not facilitate property comparison across multiple reviews.
2.3 Multidocument Summarization
This paper also relates to a large body of work in multi-document summarization. Researchers
have long noted that a central challenge of multi-document summarization is identifying redundant
information over input documents (Radev & McKeown, 1998; Carbonell & Goldstein, 1998; Mani
& Bloedorn, 1997; Barzilay, McKeown, & Elhadad, 1999). This task is of crucial significance
because multi-document summarizers operate over related documents that describe the same facts
multiple times. In fact, it is common to assume that repetition of information among related sources
is an indicator of its importance (Barzilay et al., 1999; Radev, Jing, & Budzikowska, 2000; Nenkova,
Vanderwende, & McKeown, 2006). Many of these algorithms first cluster sentences together, and
then extract or generate sentence representatives for the clusters.
Identification of repeated information is equally central in our approach — our multi-document
summarization method only selects properties that are stated by a plurality of users, thereby eliminating rare and/or erroneous opinions. The key difference between our algorithm and existing summarization systems is the method for identifying repeated expressions of a single semantic property.
Since most of the existing work on multi-document summarization focuses on topic-independent
newspaper articles, redundancy is identified via sentence comparison. For instance, Radev et al.
(2000) compare sentences using cosine similarity between corresponding word vectors. Alternatively, some methods compare sentences via alignment of their syntactic trees (Barzilay et al., 1999;
Marsi & Krahmer, 2005). Both string- and tree-based comparison algorithms are augmented with
lexico-semantic knowledge using resources such as WordNet.
The approach described in this paper does not perform comparisons at the sentence level. Instead, we first abstract reviews into a set of properties and then compare property overlap across
different documents. This approach relates to domain-dependent approaches for text summarization (Radev & McKeown, 1998; White, Korelsky, Cardie, Ng, Pierce, & Wagstaff, 2001; Elhadad
& McKeown, 2001). These methods identify the relations between documents by comparing their
abstract representations. In these cases, the abstract representation is constructed using off-the-shelf
information extraction tools. A template specifying what types of information to select is crafted
manually for a domain of interest. Moreover, the training of information extraction systems requires
a corpus manually annotated with the relations of interest. In contrast, our method does not require

574

L EARNING D OCUMENT-L EVEL S EMANTIC P ROPERTIES FROM F REE -T EXT A NNOTATIONS

Incompleteness
Property
Good food
Good service
Good price
Bad food
Bad service
Bad price
Average

Recall

Precision

F-score

0.736
0.329
0.500
0.516
0.475
0.690
0.578

0.968
0.821
0.707
0.762
0.633
0.645
0.849

0.836
0.469
0.586
0.615
0.543
0.667
0.688

Inconsistency
Keyphrase Top Keyphrase
Count
Coverage %
23
38.3
27
28.9
20
41.8
16
23.7
20
22.0
15
30.6
22.6
33.6

Table 1: Incompleteness and inconsistency in the restaurant domain, for six major properties prevalent in the reviews. The incompleteness figures are the recall, precision, and F-score of the
author annotations (manually clustered into properties) against the gold standard property
annotations. Inconsistency is measured by the number of different keyphrase realizations
with at least five occurrences associated with each property, and the percentage frequency
with which the most commonly occurring keyphrases is used to annotate a property. The
averages in the bottom row are weighted according to frequency of property occurrence.

manual template specification or corpora annotated by experts. While the abstract representations
that we induce are not as linguistically rich as extraction templates, they nevertheless enable us to
perform in-depth comparisons across different reviews.

3. Analysis of Free-Text Keyphrase Annotations
In this section, we explore the characteristics of free-text annotations, aiming to quantify the degree
of noise observed in this data. The results of this analysis motivate the development of the learning
algorithm described in Section 4.
We perform this investigation in the domain of online restaurant reviews using documents downloaded from the popular Epinions1 website. Users of this website evaluate products by providing
both a textual description of their opinion, as well as concise lists of keyphrases (pros and cons)
summarizing the review. Pros/cons keyphrases are an appealing source of annotations for online
review texts. However, they are contributed independently by multiple users and are thus unlikely
to be as clean as expert annotations. In our analysis, we focus on two features of free-text annotations: incompleteness and inconsistency. The measure of incompleteness quantifies the degree of
label omission in free-text annotations, while inconsistency reflects the variance of the keyphrase
vocabulary used by various annotators.
To test the quality of these user-generated annotations, we compare them against “expert” annotations produced in a more systematic fashion. This annotation effort focused on six properties
that were commonly mentioned by the review authors, specifically those shown in Table 1. Given
a review and a property, the task is to assess whether the review’s text supports the property. These
annotations were produced by two judges guided by a standardized set of instructions. In contrast
to author annotations from the website, the judges conferred during a training session to ensure consistency and completeness. The two judges collectively annotated 170 reviews, with 30 annotated
1. http://www.epinions.com/

575

B RANAVAN , C HEN , E ISENSTEIN , & BARZILAY

Property: good price
relatively inexpensive, dirt cheap, relatively cheap, great price, fairly priced, well priced, very reasonable
prices, cheap prices, affordable prices, reasonable cost

Figure 2: Examples of the many different paraphrases related to the property good price that appear
in the pros/cons keyphrases of reviews used for our inconsistency analysis.

by both. Cohen’s Kappa, a measure of inter-annotator agreement that ranges from zero to one, is
0.78 on this joint set, indicating high agreement (Cohen, 1960). On average, each review text was
annotated with 2.56 properties.
Separately, one of the judges also standardized the free-text pros/cons annotations for the same
170 reviews. Each review’s keyphrases were matched to the same six properties. This standardization allows for direct comparison between the properties judged to be supported by a review’s
text and the properties described in the same review’s free-text annotations. We find that many semantic properties that were judged to be present in the text were not user annotated — on average,
the keyphrases expressed 1.66 relevant semantic properties per document, while the text expressed
2.56 properties. This gap demonstrates the frequency with which authors omitted relevant semantic
properties from their review annotations.
3.1 Incompleteness
To measure incompleteness, we compare the properties stated by review authors in the form of
pros and cons against those stated only in the review text, as judged by expert annotators. This
comparison is performed using precision, recall and F-score. In this setting, recall is the proportion
of semantic properties in the text for which the review author also provided at least one annotation
keyphrase; precision is the proportion of keyphrases that conveyed properties judged to be supported
by the text; and F-score is their harmonic mean. The results of the comparison are summarized in
the left half of Table 1.
These incompleteness results demonstrate the significant discrepancy between user and expert
annotations. As expected, recall is quite low; more than 40% of property occurrences are stated in
the review text without being explicitly mentioned in the annotations. The precision scores indicate
that the converse is also true, though to a lesser extent — some keyphrases will express properties
not mentioned in text.
Interestingly, precision and recall vary greatly depending on the specific property. They are
highest for good food, matching the intuitive notion that high food quality would be a key salient
property of a restaurant, and thus more likely to be mentioned in both text and annotations. Conversely, the recall for good service is lower — for most users, high quality of service is apparently
not a key point when summarizing a review with keyphrases.
3.2 Inconsistency
The lack of a unified annotation scheme in the restaurant review dataset is apparent — across all
reviewers, the annotations feature 26,801 unique keyphrase surface forms over a set of 49,310 total
keyphrase occurrences. Clearly, many unique keyphrases express the same semantic property — in
Figure 2, good price is expressed in ten different ways. To quantify this phenomenon, the judges
576

L EARNING D OCUMENT-L EVEL S EMANTIC P ROPERTIES FROM F REE -T EXT A NNOTATIONS

Figure 3: Cumulative occurrence counts for the top ten keyphrases associated with the good service
property. The percentages are out of a total of 1,210 separate keyphrase occurrences for
this property.

manually clustered a subset of the keyphrases associated with the six previously mentioned properties. Specifically, 121 keyphrases associated with the six major properties were chosen, accounting
for 10.8% of all keyphrase occurrences.
We use these manually clustered annotations to examine the distributional pattern of keyphrases
that describe the same underlying property, using two different statistics. First, the number of
different keyphrases for each property gives a lower bound on the number of possible paraphrases.
Second, we measure how often the most common keyphrase is used to annotate each property,
i.e., the coverage of that keyphrase. This metric gives a sense of how diffuse the keyphrases within
a property are, and specifically whether one single keyphrase dominates occurrences of the property.
Note that this value is an overestimate of the true coverage, since we are only considering a tenth of
all keyphrase occurrences.
The right half of Table 1 summarizes the variability of property paraphrases. Observe that each
property is associated with numerous paraphrases, all of which were found multiple times in the
actual keyphrase set. Most importantly, the most frequent keyphrase accounted for only about a third
of all property occurrences, strongly suggesting that targeting only these labels for learning is a very
limited approach. To further illustrate this last point, consider the property of good service, whose
keyphrase realizations’ distributional histogram appears in Figure 3. The cumulative percentage
frequencies of the most frequent keyphrases associated with this property are plotted. The top four
keyphrases here account for only three quarters of all property occurrences, even within the limited
set of keyphrases we consider in this analysis, motivating the need for aggregate consideration of
keyphrases.
In the next section, we introduce a model that induces a clustering among keyphrases while
relating keyphrase clusters to the text, directly addressing these characteristics of the data.

577

B RANAVAN , C HEN , E ISENSTEIN , & BARZILAY

ψ
x
s
h
η
λ
c
φ
z
θ
w

–
–
–
–
–
–
–
–
–
–
–

keyphrase cluster model
keyphrase cluster assignment
keyphrase similarity values
document keyphrases
document keyphrase topics
probability of selecting η instead of φ
selects between η and φ for word topics
background word topic model
word topic assignment
language models of each topic
document words

ψ ∼ Dirichlet(ψ0 )
x` ∼ Multinomial(ψ)
(
Beta(α= ) if x` = x`0
s`,`0 ∼
Beta(α6= ) otherwise
T

ηd = [ηd,1 . . . ηd,K ]

(
where ηd,k ∝

1


if x` = k for any l ∈ hd
otherwise

λd ∼ Beta(λ0 )
cd,n ∼ Bernoulli(λd )
φd ∼ Dirichlet(φ0 )
(
Multinomial(ηd ) if cd,n = 1
zd,n ∼
Multinomial(φd ) otherwise
θk ∼ Dirichlet(θ0 )
wd,n ∼ Multinomial(θzd,n )

Figure 4: The plate diagram for our model. Shaded circles denote observed variables, and squares
denote hyperparameters. The dotted arrows indicate that η is constructed deterministically from x and h. We use  to refer to a small constant probability mass.

578

L EARNING D OCUMENT-L EVEL S EMANTIC P ROPERTIES FROM F REE -T EXT A NNOTATIONS

4. Model Description
We present a generative Bayesian model for documents annotated with free-text keyphrases. Our
model assumes that each annotated document is generated from a set of underlying semantic topics.
Semantic topics generate the document text by indexing a language model; in our approach, they are
also associated with clusters of keyphrases. In this way, the model can be viewed as an extension
of Latent Dirichlet Allocation (Blei et al., 2003), where the latent topics are additionally biased
toward the keyphrases that appear in the training data. However, this coupling is flexible, as some
words are permitted to be drawn from topics that are not represented by the keyphrase annotations.
This permits the model to learn effectively in the presence of incomplete annotations, while still
encouraging the keyphrase clustering to cohere with the topics supported by the document text.
Another critical aspect of our model is that we desire the ability to use arbitrary comparisons
between keyphrases, in addition to information about their surface forms. To accommodate this
goal, we do not treat the keyphrase surface forms as generated from the model. Rather, we acquire
a real-valued similarity matrix across the universe of possible keyphrases, and treat this matrix
as generated from the keyphrase clustering. This representation permits the use of surface and
distributional features for keyphrase similarity, as described in Section 4.1.
An advantage of hierarchical Bayesian models is that it is easy to change which parts of the
model are observed and which parts are hidden. During training, the keyphrase annotations are
observed, so that the hidden semantic topics are coupled with clusters of keyphrases. To account for
words not related to semantic topics, some topics may not have any associated keyphrases. At test
time, the model is presented with documents for which the keyphrase annotations are hidden. The
model is evaluated on its ability to determine which keyphrases are applicable, based on the hidden
topics present in the document text.
The judgment of whether a topic applies to a given unannotated document is based on the probability mass assigned to that topic in the document’s background topic distribution. Because there
are no annotations, the background topic distribution should capture the entirety of the document’s
topics. For the task involving reviews of products and services, multiple topics may accompany each
document. In this case, each topic whose probability is above a threshold (tuned on the development
set) is predicted as being supported.
4.1 Keyphrase Clustering
To handle the hidden paraphrase structure of the keyphrases, one component of the model estimates
a clustering over keyphrases. The goal is to obtain clusters where each cluster correspond to a welldefined semantic topic — e.g., both “healthy” and “good nutrition” should be grouped into a single
cluster. Because our overall joint model is generative, a generative model for clustering could easily
be integrated into the larger framework. Such an approach would treat all of the keyphrases in each
cluster as being generated from a parametric distribution. However, this representation would not
permit many powerful features for assessing the similarity of pairs of keyphrases, such as string
overlap or keyphrase co-occurrence in a corpus (McCallum, Bellare, & Pereira, 2005).
For this reason, we represent each keyphrase as a real-valued vector rather than as its surface
form. The vector for a given keyphrase includes the similarity scores with respect to every other observed keyphrase (the similarity scores are represented by s in Figure 4). We model these similarity
scores as generated by the cluster memberships (represented by x in Figure 4). If two keyphrases

579

B RANAVAN , C HEN , E ISENSTEIN , & BARZILAY

Lexical

The cosine similarity between the surface forms of two keyphrases, represented as word frequency vectors.

Co-occurrence

Each keyphrase is represented as a vector of co-occurrence values. This
vector counts how many times other keyphrases appear in documents
annotated with this keyphrase. For example, the similarity vector for
“good food” may include an entry for “very tasty food,” the value of
which would be the number of documents annotated with “good food”
that contain “very tasty food” in their text. The similarity between two
keyphrases is then the cosine similarity of their co-occurrence vectors.

Table 2: The two sources of information used to compute the similarity matrix for our experiments.
The final similarity scores are linear combinations of these two values. Note that cooccurrence similarity contains second-order co-occurrence information.

Figure 5: A surface plot of the keyphrase similarity matrix from a set of restaurant reviews, computed according to Table 2. Red indicates high similarity, whereas blue indicates low
similarity. In this diagram, the keyphrases have been grouped according to an expertcreated clustering, so keyphrases of similar meaning are close together. The strong series
of similarity “blocks” along the diagonal hint at how this information could induce a
reasonable clustering.

580

L EARNING D OCUMENT-L EVEL S EMANTIC P ROPERTIES FROM F REE -T EXT A NNOTATIONS

are clustered together, their similarity score is generated from a distribution encouraging high similarity; otherwise, a distribution encouraging low similarity is used.2
The features used for producing the similarity matrix are given in Table 2, encompassing lexical
and distributional similarity measures. Our implemented system takes a linear combination of these
two data sources, weighting both sources equally. The resulting similarity matrix for keyphrases
from the restaurant domain is shown in Figure 5.
As described in the next section, when clustering keyphrases, our model takes advantage of the
topic structure of documents annotated with those keyphrases, in addition to information about the
individual keyphrases themselves. In this sense, it differs from traditional approaches for paraphrase
identification (Barzilay & McKeown, 2001; Lin & Pantel, 2001).
4.2 Document Topic Modeling
Our analysis of the document text is based on probabilistic topic models such as LDA (Blei et al.,
2003). In the LDA framework, each word is generated from a language model that is indexed by the
word’s topic assignment. Thus, rather than identifying a single topic for a document, LDA identifies
a distribution over topics. High probability topic assignments will identify compact, low-entropy
language models, so that the probability mass of the language model for each topic is divided among
a relatively small vocabulary.
Our model operates in a similar manner, identifying a topic for each word, denoted by z in
Figure 4. However, where LDA learns a distribution over topics for each document, we deterministically construct a document-specific topic distribution from the clusters represented by the
document’s keyphrases — this is η in the figure. η assigns equal probability to all topics that are
represented in the keyphrase annotations, and very small probability to other topics. Generating the
word topics in this way ties together the clustering and language models.
As noted above, sometimes the keyphrase annotation does not represent all of the semantic
topics that are expressed in the text. For this reason, we also construct another “background” distribution φ over topics. The auxiliary variable c indicates whether a given word’s topic is drawn
from the distribution derived from annotations, or from the background model. Representing c as
a hidden variable allows us to stochastically interpolate between the two language models φ and
η. In addition, any given document will most likely also discuss topics that are not covered by
any keyphrase. To account for this, the model is allowed to leave some of the clusters empty, thus
leaving some of the topics to be independent of all the keyphrases.
4.3 Generative Process
Our model assumes that all observed data is generated through a stochastic process involving hidden
parameters. In this section, we formally specify this generative process. This specification guides
inference of the hidden parameters based on observed data, which are the following:
• For each of the L keyphrases, a vector s` of length L denoting a pairwise similarity score in
the interval [0, 1] to every other keyphrase.
• For each document d, its bag of words wd of length Nd . The nth word of d is wd,n .
2. Note that while we model each similarity score as an independent draw; clearly this assumption is too strong, due to
symmetry and transitivity. Models making similar assumptions about the independence of related hidden variables
have previously been shown to be successful (for example, Toutanova & Johnson, 2008).

581

B RANAVAN , C HEN , E ISENSTEIN , & BARZILAY

• For each document d, a set of keyphrase annotations hd , which includes index ` if the document was annotated with keyphrase `.
• The number of clusters K, which should be large enough to encompass topics with actual
clusters of keyphrases, as well as word-only topics.
These observed variables are generated according to the following process:
1. Draw a multinomial distribution ψ over the K keyphrase clusters from a symmetric Dirichlet
prior with parameter ψ0 .3
2. For ` = 1 . . . L:
(a) Draw the `th keyphrase’s cluster assignment x` from Multinomial(ψ).
3. For (`, `0 ) = (1 . . . L, 1 . . . L):
(a) If x` = x`0 , draw s`,`0 from Beta(α= ) ≡ Beta(2, 1), encouraging scores to be biased
toward values close to one.
(b) If x` 6= x`0 , draw s`,`0 from Beta(α6= ) ≡ Beta(1, 2), encouraging scores to be biased
toward values close to zero.
4. For k = 1 . . . K:
(a) Draw language model θk from a symmetric Dirichlet prior with parameter θ0 .
5. For d = 1 . . . D:
(a) Draw a background topic model φd from a symmetric Dirichlet prior with parameter φ0 .
(b) Deterministically construct an annotation topic model ηd , based on keyphrase cluster
assignments x and observed document annotations hd . Specifically, let H be the set of
topics represented by phrases in hd . Distribution ηd assigns equal probability to each
element of H, and a very small probability mass to other topics.4
(c) Draw a weighted coin λd from Beta(λ0 ), which will determine the balance between
annotation ηd and background topic models φd .
(d) For n = 1 . . . Nd :
i. Draw a binary auxiliary variable cd,n from Bernoulli(λd ), which determines whether
the topic of the word wd,n is drawn from the annotation topic model ηd or the background model φd .
ii. Draw a topic assignment zd,n from the appropriate multinomial as indicated by
cd,n .
iii. Draw word wd,n from Multinomial(θzd,n ), that is, the language model indexed by
the word’s topic.
3. Variables subscripted with zero are fixed hyperparameters.
4. Making a hard assignment of zero probability to the other topics creates problems for parameter estimation. A
probability of 10−4 was assigned to all topics not represented by the keyphrase cluster memberships.

582

L EARNING D OCUMENT-L EVEL S EMANTIC P ROPERTIES FROM F REE -T EXT A NNOTATIONS

5. Parameter Estimation
To make predictions on unseen data, we need to estimate the parameters of the model. In Bayesian
inference, we estimate the distribution for each parameter, conditioned on the observed data and
hyperparameters. Such inference is intractable in the general case, but sampling approaches allow
us to approximately construct distributions for each parameter of interest.
Gibbs sampling is perhaps the most generic and straightforward sampling technique. Conditional distributions are computed for each hidden variable, given all the other variables in the model.
By repeatedly sampling from these distributions in turn, it is possible to construct a Markov chain
whose stationary distribution is the posterior of the model parameters (Gelman, Carlin, Stern, &
Rubin, 2004). The use of sampling techniques in natural language processing has been previously
investigated by many researchers, including Finkel, Grenager, and Manning (2005) and Goldwater,
Griffiths, and Johnson (2006).
We now present sampling equations for each of the hidden variables in Figure 4. The prior over
keyphrase clusters ψ is sampled based on the hyperprior ψ0 and the keyphrase cluster assignments
x. We write p(ψ | . . .) to mean the probability conditioned on all the other variables.
p(ψ | . . .) ∝ p(ψ | ψ0 )p(x | ψ),
Y
= p(ψ | ψ0 )
p(x` | ψ)
`

= Dirichlet(ψ; ψ0 )

Y

Multinomial(x` ; ψ)

`

= Dirichlet(ψ; ψ 0 ),
where ψi0 is ψ0 + count(x` = i). This conditional distribution is derived based on the conjugacy of
the multinomial to the Dirichlet distribution. The first line follows from Bayes’ rule, and the second
line from the conditional independence of cluster assignments x given keyphrase distribution ψ.
Resampling equations for φd and θk can be derived in a similar manner:
p(φd | . . .) ∝ Dirichlet(φd ; φ0d ),
p(θk | . . .) ∝ Dirichlet(θk ; θk0 ),
P
0 =θ +
where φ0d,i = φ0 + count(zn,d = i ∧ cn,d = 0) and θk,i
0
d count(wn,d = i ∧ zn,d = k). In
0
building the counts for φi , we consider only cases in which cn,d = 0, indicating that the topic zn,d
is indeed drawn from the background topic model φd . Similarly, when building the counts for θk0 ,
we consider only cases in which the word wd,n is drawn from topic k.
To resample λ, we employ the conjugacy of the Beta prior to the Bernoulli observation likelihoods, adding counts of c to the prior λ0 .
p(λd | . . .) ∝ Beta(λd ; λ0d ),

 P
count(c
=
1)
d,n
0
n
.
where λd = λ0 + P
n count(cd,n = 0)

583

B RANAVAN , C HEN , E ISENSTEIN , & BARZILAY

The keyphrase cluster assignments are represented by x, whose sampling distribution depends
on ψ, s, and z, via η:
p(x` | . . .) ∝ p(x` | ψ)p(s | x` , x−` , α)p(z | η, ψ, c)



D Y
Y
Y
∝ p(x` | ψ) 
p(s`,`0 | x` , x`0 , α) 
p(zd,n | ηd )
`0 6=`

d cd,n =1


= Multinomial(x` ; ψ) 

Y



D Y
Y
Beta(s`,`0 ; αx` ,x`0 ) 
Multinomial(zd,n ; ηd ) .

`0 6=`

d cd,n =1

The leftmost term of the above equation is the prior on x` . The next term encodes the dependence
of the similarity matrix s on the cluster assignments; with slight abuse of notation, we write αx` ,x`0
to denote α= if x` = x`0 , and α6= otherwise. The third term is the dependence of the word topics
zd,n on the topic distribution ηd . We compute the final result of this probability expression for each
possible setting of x` , and then sample from the normalized multinomial.
The word topics z are sampled according to the topic distribution ηd , the background distribution
φd , the observed words w, and the auxiliary variable c:
p(zd,n | . . .) ∝ p(zd,n | φ, ηd , cd,n )p(wd,n | zd,n , θ)
(
Multinomial(zd,n ; ηd )Multinomial(wd,n ; θzd,n )
=
Multinomial(zd,n ; φd )Multinomial(wd,n ; θzd,n )

if cd,n = 1,
otherwise.

As with x, each zd,n is sampled by computing the conditional likelihood of each possible setting
within a constant of proportionality, and then sampling from the normalized multinomial.
Finally, we sample the auxiliary variable cd,n , which indicates whether the hidden topic zd,n is
drawn from ηd or φd . c depends on its prior λ and the hidden topic assignments z:
p(cd,n | . . .) ∝ p(cd,n | λd )p(zd,n | ηd , φd , cd,n )
(
Bernoulli(cd,n ; λd )Multinomial(zd,n ; ηd )
=
Bernoulli(cd,n ; λd )Multinomial(zd,n ; φd )

if cd,n = 1,
otherwise.

Again, we compute the likelihood of cd,n = 0 and cd,n = 1 within a constant of proportionality, and
then sample from the normalized Bernoulli distribution.
Finally, our model requires values for fixed hyperparameters θ0 , λ0 , ψ0 , and φ0 , which are tuned
in the standard way based on development set performance. Appendix C lists the hyperparameters
values used for each domain in our experiments.
One of the main applications of our model is to predict the properties supported by documents
that are not annotated with keyphrases. At test time, we would like to compute a posterior estimate
of φd for an unannotated test document d. Since annotations are not present, property prediction is
based only on the text component of the model. For this estimate, we use the same Gibbs sampling
procedure, restricted to zd,n and φd , with the stipulation that cd,n is fixed at zero so that zd,n is
always drawn from φd . In particular, we treat the language models as known; to more accurately
integrate over all possible language models, we use the final 1000 samples of the language models
from training as opposed to using a point estimate. For each topic, if its probability in φd exceeds a
certain threshold, that topic is predicted. This threshold is tuned independently for each topic on a
development set. The empirical results we present in Section 6 are obtained in this manner.
584

L EARNING D OCUMENT-L EVEL S EMANTIC P ROPERTIES FROM F REE -T EXT A NNOTATIONS

Figure 6: Summary of reviews for the movie Pirates of the Caribbean: At World’s End on P R ÉCIS.
This summary is based on 27 documents. The list of pros and cons are generated automatically using the system described in this paper. The generation of numerical ratings is
based on the algorithm described in Snyder and Barzilay (2007).

6. Evaluation of Summarization Quality
Our model for document analysis is implemented in P R ÉCIS,5 a system that performs single- and
multi-document review summarization. The goal of P R ÉCIS is to provide users with effective access
to review data via mobile devices. P R ÉCIS contains information about 49,490 products and services
ranging from childcare products to restaurants and movies. For each of these products, the system
contains a collection of reviews downloaded from consumer websites such as Epinions, CNET,
and Amazon. P R ÉCIS compresses data for each product into a short list of pros and cons that
are supported by the majority of reviews. An example of a summary of 27 reviews for the movie
Pirates of the Caribbean: At World’s End is shown in Figure 6. In contrast to traditional multidocument summarizers, the output of the system is not a sequence of sentences, but rather a list of
phrases indicative of product properties. This summarization format follows the format of pros/cons
summaries that individual reviewers provide on multiple consumer websites. Moreover, the brevity
of the summary is particularly suitable for presenting on small screens such as those of mobile
devices.
To automatically generate the combined pros/cons list for a product or service, we first apply our
model to each review. The model is trained independently for each product domain (e.g., movies)
using a corresponding subset of reviews with free-text annotations. These annotations also provide
a set of keyphrases that contribute to the clusters associated with product properties. Once the
5. P R ÉCIS is accessible at http://groups.csail.mit.edu/rbg/projects/precis/.

585

B RANAVAN , C HEN , E ISENSTEIN , & BARZILAY

model is trained, it labels each review with a set of properties. Since the set of possible properties
is the same for all reviews of a product, the comparison among reviews is straightforward — for
each property, we count the number of reviews that support it, and select the property as part of a
summary if it is supported by the majority of the reviews. The set of semantic properties is converted
into a pros/cons list by presenting the most common keyphrase for each property.
This aggregation technology is applicable in two scenarios. The system can be applied to unannotated reviews, inducing semantic properties from the document text; this conforms to the traditional way in which learning-based systems are applied to unlabeled data. However, our model
is valuable even when individual reviews do include pros/cons keyphrase annotations. Due to the
high degree of paraphrasing, direct comparison of keyphrases is challenging (see Section 3). By
inferring a clustering over keyphrases, our model permits comparison of keyphrase annotations on
a more semantic level.
The remainder of this section provides a set of evaluations of our model’s ability to capture the
semantic content of document text and keyphrase annotations. Section 6.1 describes an evaluation
of our system’s ability to extract meaningful semantic summaries from individual documents, and
also assesses the quality of the paraphrase structure induced by our model. Section 6.2 extends this
evaluation to our system’s ability to summarize multiple review documents.
6.1 Single-Document Evaluation
First, we evaluate our model with respect to its ability to reproduce the annotations present in individual documents, based on the document text. We compare against a wide variety of baselines and
variations of our model, demonstrating the appropriateness of our approach to this task. In addition,
we explicitly evaluate the quality of the paraphrase structure induced by our model by comparing
against a gold standard clustering of keyphrases provided by expert annotators.
6.1.1 E XPERIMENTAL S ETUP
In this section, we describe the datasets and evaluation techniques used for experiments with our
system and other automatic methods. We also comment on how hyperparameters are tuned for our
model, and how sampling is initialized.
Statistic
# of reviews
avg. review length
avg. keyphrases / review

Restaurants
5735
786.3
3.42

Cell Phones
1112
1056.9
4.91

Digital Cameras
3971
1014.2
4.84

Table 3: Statistics of the datasets used in our evaluations
Data Sets We evaluate our system on reviews from three domains: restaurants, cell phones, and
digital cameras. These reviews were downloaded from the Epinions website; we used user-authored
pros and cons associated with reviews as keyphrases (see Section 3). Statistics for the datasets are
provided in Table 3. For each of the domains, we selected 50% of the documents for training.
We consider two strategies for constructing test data. First, we consider evaluating the semantic
properties inferred by our system against expert annotations of the semantic properties present in
each document. To this end, we use the expert annotations originally described in Section 3 as a test

586

L EARNING D OCUMENT-L EVEL S EMANTIC P ROPERTIES FROM F REE -T EXT A NNOTATIONS

set;6 to reiterate, these were annotations of 170 reviews in the restaurant domain, of which we now
hold out 50 as a development set. The review texts were annotated with six properties according to
standardized guidelines. This strategy enforces consistency and completeness in the ground truth
annotations, differentiating them from free-text annotations.
Unfortunately, our ability to evaluate against expert annotations is limited by the cost of producing such annotations. To expand evaluation to other domains, we use the author-written keyphrase
annotations that are present in the original reviews. Such annotations are noisy — while the presence
of a property annotation on a document is strong evidence that the document supports the property,
the inverse is not necessarily true. That is, the lack of an annotation does not necessarily imply that
its respective property does not hold — e.g., a review with no good service-related keyphrase may
still praise the service in the body of the document.
For experiments using free-text annotations, we overcome this pitfall by restricting the evaluation of predictions of individual properties to only those documents that are annotated with that
property or its antonym. For instance, when evaluating the prediction of the good service property,
we will only select documents which are either annotated with good service or bad service-related
keyphrases.7 For this reason, each semantic property is evaluated against a unique subset of documents. The details of these development and test sets are presented in Appendix A.
To ensure that free-text annotations can be reliably used for evaluation, we compare with the
results produced on expert annotations whenever possible. As shown in Section 6.1.2, the free-text
evaluations produce results that cohere well with those obtained on expert annotations, suggesting
that such labels can be used as a reasonable proxy for expert annotation evaluations.
Evaluation Methods Our first evaluation leverages the expert annotations described in Section 3.
One complication is that expert annotations are marked on the level of semantic properties, while
the model makes predictions about the appropriateness of individual keyphrases. We address this
by representing each expert annotation with the most commonly-observed keyphrase from the
manually-annotated cluster of keyphrases associated with the semantic property. For example, an
annotation of the semantic property good food is represented with its most common keyphrase realization, “great food.” Our evaluation then checks whether this keyphrase is within any of the clusters
of keyphrases predicted by the model.
The evaluation against author free-text annotations is similar to the evaluation against expert
annotations. In this case, the annotation takes the form of individual keyphrases rather than semantic
properties. As noted, author-generated keyphrases suffer from inconsistency. We obtain a consistent
evaluation by mapping the author-generated keyphrase to a cluster of keyphrases as a determined
by the expert annotator, and then again selecting the most common keyphrase realization of the
cluster. For example, the author may use the keyphrase “tasty,” which maps to the semantic cluster
good food; we then select the most common keyphrase realization, “great food.” As in the expert
evaluation, we check whether this keyphrase is within any of the clusters predicted by the model.
Model performance is quantified using recall, precision, and F-score. These are computed in
the standard manner, based on the model’s representative keyphrase predictions compared against
the corresponding references. Approximate randomization (Yeh, 2000; Noreen, 1989) is used for
statistical significance testing. This test repeatedly performs random swaps of individual results
6. The expert annotations are available at http://groups.csail.mit.edu/rbg/code/precis/.
7. This determination is made by mapping author keyphrases to properties using an expert-generated gold standard
clustering of keyphrases. It is much cheaper to produce an expert clustering of keyphrases than to obtain expert
annotations of the semantic properties in every document.

587

B RANAVAN , C HEN , E ISENSTEIN , & BARZILAY

from each candidate system, and checks whether the resulting performance gap remains at least
as large. We use this test because it is valid for comparing nonlinear functions of random variables, such as F-scores, unlike other common methods such as the sign test. Previous work that
used this test include evaluations at the Message Understanding Conference (Chinchor, Lewis, &
Hirschman, 1993; Chinchor, 1995); more recently, Riezler and Maxwell (2005) advocated for its
use in evaluating machine translation systems.
Parameter Tuning and Initialization To improve the model’s convergence rate, we perform two
initialization steps for the Gibbs sampler. First, sampling is done only on the keyphrase clustering
component of the model, ignoring document text. Second, we fix this clustering and sample the
remaining model parameters. These two steps are run for 5,000 iterations each. The full joint model
is then sampled for 100,000 iterations. Inspection of the parameter estimates confirms model convergence. On a 2GHz dual-core desktop machine, a multithreaded C++ implementation of model
training takes about two hours for each dataset.
Our model needs to be provided with the number of clusters K.8 We set K large enough for the
model to learn effectively on the development set. For the restaurant data we set K to 20. For cell
phones and digital cameras, K was set to 30 and 40, respectively. These values were tuned using the
development set. However, we found that as long as K was large enough to accommodate a significant number of keyphrase clusters, and a few additional to account for topics with no keyphrases,
the specific value of K does not affect the model’s performance. All other hyperparameters were
adjusted based on development set performance, though tuning was not extensive.
As previously mentioned, we obtain document properties by examining the probability mass of
the topic distribution assigned to each property. A probability threshold is set for each property via
the development set, optimizing for maximum F-score.
6.1.2 R ESULTS
In this section, we report the performance of our model, comparing it with an array of increasingly
sophisticated baselines and model variations. We first demonstrate that learning a clustering of annotation keyphrases is crucial for accurate semantic prediction. Next, we investigate the impact of
paraphrasing quality on model accuracy by considering the expert-generated gold standard clustering of keyphrases as another comparison point; we also consider alternative automatically computed
sources of paraphrase information.
For ease of comparison, the results of all the experiments are shown in Table 5 and Table 6, with
a summary of the baselines and model variations in Table 4.
Comparison against Simple Baselines Our first evaluation compares our model to four naı̈ve
baselines. All four treat keyphrases as independent, ignoring their latent paraphrase structure.
• Random: Each keyphrase is supported by a document with probability of one half. The
results of this baseline are computed in expectation, rather than actually run. This baseline
is expected to have a recall of 0.5, because in expectation it will select half of the correct
keyphrases. Its precision is the average proportion of annotations in the test set against the
number of possible annotations. That is, in a test set of size n with m properties, if property
8. This requirement could conceivably be removed by modeling the cluster indices as being drawn from a Dirichlet
process prior.

588

L EARNING D OCUMENT-L EVEL S EMANTIC P ROPERTIES FROM F REE -T EXT A NNOTATIONS

Random

Each keyphrase is supported by a document with probability of one half.

Keyphrase in text

A keyphrase is supported by a document if it appears verbatim in the text.

Keyphrase classifier

A separate support vector machine classifier is trained for each keyphrase.
Positive examples are documents that are labeled by the author with the
keyphrase; all other documents are considered to be negative examples. A
keyphrase is supported by a document if that keyphrase’s classifier returns a
positive prediction.

Heuristic keyphrase
classifier

Similar to keyphrase classifier, except heuristic methods are used in an attempt to reduce noise from the training documents. Specifically we wish to
remove sentences that discuss other keyphrases from the positive examples.
The heuristic removes from the positive examples all sentences that have no
word overlap with the given keyphrase.

Model cluster in text

A keyphrase is supported by a document if it or any of its paraphrases appear
in the text. Paraphrasing is based on our model’s keyphrase clusters.

Model cluster classifier

A separate classifier is trained for each cluster of keyphrases. Positive examples are documents that are labeled by the author with any keyphrase from
the cluster; all other documents are negative examples. All keyphrases of
a cluster are supported by a document if that cluster’s classifier returns a
positive prediction. Keyphrase clustering is based on our model.

Heuristic model cluster
classifier

Similar to model cluster classifier, except heuristic methods are used to reduce noise from the training documents. Specifically we wish to remove
from the positive examples sentences that discuss keyphrases from other
clusters. The heuristic removes from the positive examples all sentences
that have no word overlap with any of the keyphrases from the given cluster.
Keyphrase clustering is based on our model.

Gold cluster model

A variation of our model where the clustering of keyphrases is fixed to an
expert-created gold standard. Only the text modeling parameters are learned.

Gold cluster in text

Similar to model cluster in text, except the clustering of keyphrases is according to the expert-produced gold standard.

Gold cluster classifier

Similar to model cluster classifier, except the clustering of keyphrases is
according to the expert-produced gold standard.

Heuristic gold cluster
classifier

Similar to heuristic model cluster classifier, except the clustering of
keyphrases is according to the expert-produced gold standard.

Independent cluster model

A variation of our model where the clustering of keyphrases is first learned
from keyphrase similarity information only, separately from the text. The
resulting independent clustering is then fixed while the text modeling parameters are learned. This variation’s key distinction from our full model is
the lack of joint learning of keyphrase clustering and text topics.

Independent cluster in text

Similar to model cluster in text, except that the clustering of keyphrases is
according to the independent clustering.

Independent cluster
classifier

Similar to model cluster classifier, except that the clustering of keyphrases
is according to the independent clustering.

Heuristic independent
cluster classifier

Similar to heuristic model cluster classifier, except the clustering of
keyphrases is according to the independent clustering.

Table 4: A summary of the baselines and variations against which our model is compared.
589

B RANAVAN , C HEN , E ISENSTEIN , & BARZILAY

Method
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16

Our model
Random
Keyphrase in text
Keyphrase classifier
Heuristic keyphrase classifier
Model cluster in text
Model cluster classifier
Heuristic model cluster classifier
Gold cluster model
Gold cluster in text
Gold cluster classifier
Heuristic gold cluster classifier
Independent cluster model
Independent cluster in text
Independent cluster classifier
Heuristic independent cluster classifier

Recall
0.920
0.500
0.048
0.769
0.839
0.227
0.721
0.731
0.936
0.339
0.693
1.000
0.745
0.220
0.586
0.592

Restaurants
Prec. F-score
0.353 0.510
0.346 0.409 ∗
0.500 0.087 ∗
0.353 0.484 ∗
0.340 0.484 ∗
0.385 0.286 ∗
0.402 0.516
0.366 0.488 ∗
0.344 0.502
0.360 0.349 ∗
0.366 0.479 ∗
0.326 0.492 
0.363 0.488 
0.340 0.266 ∗
0.384 0.464 ∗
0.386 0.468 ∗

Table 5: Comparison of the property predictions made by our model and a series of baselines and
model variations in the restaurant domain, evaluated against expert semantic annotations.
The results are divided according to experiment. The methods against which our model
has significantly better results using approximate randomization are indicated with ∗ for
p ≤ 0.05, and  for p ≤ 0.1.

590

L EARNING D OCUMENT-L EVEL S EMANTIC P ROPERTIES FROM F REE -T EXT A NNOTATIONS

Method
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16

Our model
Random
Keyphrase in text
Keyphrase classif.
Heur. keyphr. classif.
Model cluster in text
Model cluster classif.
Heur. model classif.
Gold cluster model
Gold cluster in text
Gold cluster classif.
Heur. gold classif.
Indep. cluster model
Indep. cluster in text
Indep. cluster classif.
Heur. indep. classif.

Recall
0.923
0.500
0.077
0.905
0.997
0.416
0.859
0.910
0.992
0.541
0.865
0.997
0.984
0.382
0.753
0.881

Restaurants
Prec. F-score
0.623 0.744
0.500 0.500 ∗
0.906 0.142 ∗
0.527 0.666 ∗
0.497 0.664 ∗
0.613 0.496 ∗
0.711 0.778 †
0.567 0.698 ∗
0.500 0.665 ∗
0.604 0.571 ∗
0.720 0.786 †
0.499 0.665 ∗
0.528 0.687 ∗
0.569 0.457 ∗
0.696 0.724
0.478 0.619 ∗

Recall
0.971
0.500
0.171
1.000
0.845
0.829
0.876
1.000
0.924
0.914
0.810
0.969
0.838
0.724
0.638
1.000

Cell Phones
Prec. F-score
0.537 0.692
0.489 0.494 ∗
0.529 0.259 ∗
0.500 0.667
0.474 0.607 ∗
0.547 0.659 
0.561 0.684
0.464 0.634 
0.561 0.698
0.497 0.644 ∗
0.559 0.661
0.468 0.631 
0.564 0.674
0.481 0.578 ∗
0.472 0.543 ∗
0.464 0.634 

Digital Cameras
Recall Prec. F-score
0.905 0.586 0.711
0.500 0.501 0.500 ∗
0.715 0.642 0.676 ∗
0.942 0.540 0.687 
0.845 0.531 0.652 ∗
0.812 0.596 0.687 ∗
0.927 0.568 0.704
0.942 0.568 0.709
0.962 0.510 0.667 ∗
0.903 0.522 0.661 ∗
0.874 0.674 0.761
0.971 0.508 0.667 ∗
0.945 0.519 0.670 ∗
0.469 0.476 0.473 ∗
0.496 0.588 0.538 ∗
0.969 0.501 0.660 ∗

Table 6: Comparison of the property predictions made by our model and a series of baselines and
model variations in three product domains, as evaluated against author free-text annotations. The results are divided according to experiment. The methods against which our
model has significantly better results using approximate randomization are indicated with
∗ for p ≤ 0.05, and  for p ≤ 0.1. Methods which perform significantly better than our
model with p ≤ 0.05 are indicated with †.

591

B RANAVAN , C HEN , E ISENSTEIN , & BARZILAY

P
ni
i appears ni times, then expected precision is m
i=1 mn . For instance, for the restaurants
gold standard evaluation, the six tested properties appeared a total of 249 times over 120
documents, yielding an expected precision of 0.346.
• Keyphrase in text: A keyphrase is supported by a document if it appears verbatim in the
text. Precision should be high while recall will be low, because the model is unable to detect
paraphrases of the keyphrase in the text. For instance, for the first review from Figure 1,
“cleanliness” would be supported because it appears in the text; however, “healthy” would
not be supported, even though the synonymous “great nutrition” does appear.
• Keyphrase classifier:9 A separate discriminative classifier is trained for each keyphrase. Positive examples are documents that are labeled by the author with the keyphrase; all other documents are considered to be negative examples. Consequently, for any particular keyphrase,
documents labeled with synonymous keyphrases would be among the negative examples. A
keyphrase is supported by a document if that keyphrase’s classifier returns a positive prediction.
We use support vector machines, built using SVMlight (Joachims, 1999) with the same features
as our model, i.e.,word counts.10 To partially circumvent the imbalanced positive/negative
data problem, we tuned prediction thresholds on a development set to maximize F-score, in
the same manner that we tuned thresholds for our model.
• Heuristic keyphrase classifier: This baseline is similar to keyphrase classifier above, but attempts to mitigate some of the noise inherent in the training data. Specifically, any given
positive example document may contain text unrelated to the given keyphrase. We attempt
to reduce this noise by removing from the positive examples all sentences that have no word
overlap with the given keyphrase. A keyphrase is supported by a document if that keyphrase’s
classifier returns a positive prediction.11
Lines 2-5 of Tables 5 and 6 present these results, using both gold annotations and the original
authors’ annotations for testing. Our model outperforms these three baselines in all evaluations with
strong statistical significance.
The keyphrase in text baseline fares poorly: its F-score is below the random baseline in three
of the four evaluations. As expected, the recall of this baseline is usually low because it requires
keyphrases to appear verbatim in the text. The precision is somewhat better, but the presence of
a significant number of false positives indicates that the presence of a keyphrase in the text is not
necessarily a reliable indicator of the associated semantic property.
Interestingly, one domain in which keyphrase in text does perform well is digital cameras. We
believe that this is because of the prevalence of specific technical terms in the keyphrases used in
this domain, such as “zoom” and “battery life.” Such technical terms are also frequently used in the
review text, making the recall of keyphrase in text substantially higher in this domain than in the
other evaluations.
9. Note that the classifier results reported in the initial publication (Branavan, Chen, Eisenstein, & Barzilay, 2008) were
obtained using the default parameters of a maximum entropy classifier. Tuning the classifier’s parameters allowed us
to significantly improve performance of all classifier baselines.
10. In general, SVMs have the additional advantage of being able to incorporate arbitrary features, but for the sake of
comparison we restrict ourselves to using the same features across all methods.
11. We thank a reviewer for suggesting this baseline.

592

L EARNING D OCUMENT-L EVEL S EMANTIC P ROPERTIES FROM F REE -T EXT A NNOTATIONS

The keyphrase classifier baseline outperforms the random and keyphrase in text baselines, but
still achieves consistently lower performance than our model in all four evaluations. Notably, the
performance of heuristic keyphrase classifier is worse than keyphrase classifier except in one case.
This alludes to the difficulty of removing the noise inherent in the document text.
Overall, these results indicate that methods which learn and predict keyphrases without accounting for their intrinsic hidden structure are insufficient for optimal property prediction. This leads us
toward extending the present baselines with clustering information.
It is important to assess the consistency of the evaluation based on free-text annotations (Table 6) with the evaluation that uses expert annotations (Table 5). While the absolute scores on the
expert annotations dataset are lower than the scores with free-text annotations, the ordering of performance between the various automatic methods is the same across the two evaluation scenarios.
This consistency is maintained in the rest of our experiments as well, indicating that for the purpose
of relative comparison between the different automatic methods, our method of evaluating with
free-text annotations is a reasonable proxy for evaluation on expert-generated annotations.
Comparison against Clustering-based Approaches The previous section demonstrates that our
model outperforms baselines that do not account for the paraphrase structure of keyphrases. We
now ask whether it is possible to enhance the baselines’ performance by augmenting them with the
keyphrase clustering induced by our model. Specifically, we introduce three more systems, none of
which are “true” baselines, since they all use information inferred by our model.
• Model cluster in text: A keyphrase is supported by a document if it or any of its paraphrases
appears in the text. Paraphrasing is based on our model’s clustering of the keyphrases. The
use of paraphrasing information enhances recall at the potential cost of precision, depending
on the quality of the clustering. For example, assuming “healthy” and “great nutrition” are
clustered together, the presence of “healthy” in the text would also indicate support for “great
nutrition,” and vice versa.
• Model cluster classifier: A separate discriminative classifier is trained for each cluster of
keyphrases. Positive examples are documents that are labeled by the author with any keyphrase
from the cluster; all other documents are negative examples. All keyphrases of a cluster are
supported by a document if that cluster’s classifier returns a positive prediction. Keyphrase
clustering is based on our model. As with keyphrase classifier, we use support vector machines trained on word count features, and we tune the prediction thresholds for each individual cluster on a development set.
Another perspective on model cluster classifier is that it augments the simplistic text modeling
portion of our model with a discriminative classifier. Discriminative training is often considered to be more powerful than equivalent generative approaches (McCallum et al., 2005),
leading us to expect a high level of performance from this system.
• Heuristic model cluster classifier: This method is similar to model cluster classifier above,
but with additional heuristics used to reduce the noise inherent in the training data. Positive
example documents may contain text unrelated to the given cluster. To reduce this noise,
sentences that have no word overlap with any of the cluster’s keyphrases are removed. All
keyphrases of a cluster are supported by a document if that cluster’s classifier returns a positive prediction. Keyphrase clustering is based on our model.
593

B RANAVAN , C HEN , E ISENSTEIN , & BARZILAY

Lines 6-8 of Tables 5 and 6 present results for these methods. As expected, using a clustering
of keyphrases with the baseline methods substantially improves their recall, with low impact on
precision. Model cluster in text invariably outperforms keyphrase in text — the recall of keyphrase in
text is improved by the addition of clustering information, though precision is worse in some cases.
This phenomenon holds even in the cameras domain, where keyphrase in text already performs well.
However, our model still significantly outperforms model cluster in text in all evaluations.
Adding clustering information to the classifier baseline results in performance that is sometimes
better than our model’s. This result is not surprising, because model cluster classifier gains the
benefit of our model’s robust clustering while learning a more sophisticated classifier for assigning
properties to texts. The resulting combined system is more complex than our model by itself, but
has the potential to yield better performance. On the other hand, using a simple heuristic to reduce
the noise present in the training data consistently hurts the performance of the classifier, possibly
due to the reduction in the amount of training data.
Overall, the enhanced performance of these methods, in contrast to the keyphrase baselines, is
aligned with previous observations in entailment research (Dagan, Glickman, & Magnini, 2006),
confirming that paraphrasing information contributes greatly to improved performance in semantic
inference tasks.
The Impact of Paraphrasing Quality The previous section demonstrates one of the central
claims of this paper: accounting for paraphrase structure yields substantial improvements in semantic inference when using noisy keyphrase annotations. A second key aspect of our research is
the idea that clustering quality benefits from tying the clusters to hidden topics in the document
text. We evaluate this claim by comparing our model’s clustering against an independent clustering
baseline. We also compare against a “gold standard” clustering produced by expert human annotators. To test the impact of these clustering methods, we substitute the model’s inferred clustering
with each alternative and examine how the resulting semantic inferences change. This comparison
is performed for the semantic inference mechanism of our model, as well as for the model cluster
in text, model cluster classifier and heuristic model cluster classifier baselines.
To add a “gold standard” clustering to our model, we replace the hidden variables that correspond to keyphrase clusters with observed values that are set according to the gold standard clustering.12 The only parameters that are trained are those for modeling text. This model variation, gold
cluster model, predicts properties using the same inference mechanism as the original model. The
baseline variations gold cluster in text, gold cluster classifier and heuristic gold cluster classifier are
likewise derived by substituting the automatically computed clustering with gold standard clusters.
An additional clustering is obtained using only the keyphrase similarity information. Specifically, we modify our original model so that it learns the keyphrase clustering in isolation from the
text, and only then learns the property language models. In this framework, the keyphrase clustering
is entirely independent of the review text, because the text modeling is learned with the keyphrase
clustering fixed. We refer to this modification of the model as independent cluster model. Because
our model treats the document text as a mixture of latent topics, this is reminiscent of models such
as supervised latent Dirichlet allocation (sLDA; Blei & McAuliffe, 2008), with the labels acquired
by performing a clustering across keyphrases as a preprocessing step. As in the previous experiment, we introduce three new baseline variations — independent cluster in text, independent cluster
classifier and heuristic independent cluster classifier.
12. The gold standard clustering was created as part of the evaluation procedure described in Section 6.1.1.

594

L EARNING D OCUMENT-L EVEL S EMANTIC P ROPERTIES FROM F REE -T EXT A NNOTATIONS

Lines 9-16 of Tables 5 and 6 present the results of these experiments. The gold cluster model
produces F-scores comparable to our original model, providing strong evidence that the clustering
induced by our model is of sufficient quality for semantic inference. The application of the expertgenerated clustering to the baselines (lines 10, 11 and 12) yields less consistent results, but overall
this evaluation provides little reason to believe that performance would be substantially improved
by obtaining a clustering that was closer to the gold standard.
The independent cluster model consistently reduces performance with respect to the full joint
model, supporting our hypothesis that joint learning gives rise to better prediction. The independent
clustering baselines, independent cluster in text, independent cluster classifier and heuristic independent cluster classifier (lines 14 to 16), are also worse than their counterparts that use the model
clustering (lines 6 to 8). This observation leads us to conclude that while the expert-annotated
clustering does not always improve results, the independent clustering always degrades them. This
supports our view that joint learning of clustering and text models is an important prerequisite for
better property prediction.
Clustering
Model clusters
Independent clusters

Restaurants
0.914
0.892

Cell Phones
0.876
0.759

Digital Cameras
0.945
0.921

Table 7: Rand Index scores of our model’s clusters, learned from keyphrases and text jointly, compared against clusters learned only from keyphrase similarity. Evaluation of cluster quality
is based on the gold standard clustering.

Another way of assessing the quality of each automatically-obtained keyphrase clustering is
to quantify its similarity to the clustering produced by the expert annotators. For this purpose we
use the Rand Index (Rand, 1971), a measure of cluster similarity. This measure varies from zero
to one, with higher scores indicating greater similarity. Table 7 shows the Rand Index scores for
our model’s full joint clustering, as well as the clustering obtained from independent cluster model.
In every domain, joint inference produces an overall clustering that improves upon the keyphrasesimilarity-only approach. These scores again confirm that joint inference across keyphrases and
document text produces a better clustering than considering features of the keyphrases alone.
6.2 Summarizing Multiple Reviews
Our last experiment examines the multi-document summarization capability of our system. We
study our model’s ability to aggregate properties across a set of reviews, compared to baselines that
aggregate by directly using the free-text annotations.
6.2.1 DATA AND E VALUATION
We selected 50 restaurants, with five user-written reviews for each restaurant. Ten annotators were
asked to annotate the reviews for five restaurants each, comprising 25 reviews per annotator. They
used the same six salient properties and the same annotation guidelines as in the previous restaurant
annotation experiment (see Section 3). In constructing the ground truth, we label properties that are
supported in at least three of the five reviews.

595

B RANAVAN , C HEN , E ISENSTEIN , & BARZILAY

Method
Our model
Keyphrase aggregation
Model cluster aggregation
Gold cluster aggregation
Indep. cluster aggregation

Recall
0.905
0.036
0.238
0.226
0.214

Prec.
0.325
0.750
0.870
0.826
0.720

F-score
0.478
0.068 ∗
0.374 ∗
0.355 ∗
0.330 ∗

Table 8: Comparison of the aggregated property predictions made by our model and a series of
baselines that use free-text annotations. The methods against which our model has significantly better results using approximate randomization are indicated with ∗ for p ≤ 0.05.

We make property predictions on the same set of reviews with our model and the baselines
presented below. For the automatic methods, we register a prediction if the system judges the
property to be supported on at least two of the five reviews.13 The recall, precision, and F-score are
computed over these aggregate predictions, against the six salient properties marked by annotators.
6.2.2 AGGREGATION A PPROACHES
In this evaluation, we run the trained version of our model as described in Section 6.1.1. Note that
keyphrases are not provided to our model, though they are provided to the baselines.
The most obvious baseline for summarizing multiple reviews would be to directly aggregate
their free-text keyphrases. These annotations are presumably representative of the review’s semantic
properties, and unlike the review text, keyphrases can be matched directly with each other. Our first
baseline applies this notion directly:
• Keyphrase aggregation: A keyphrase is supported for a restaurant if at least two out of its five
reviews are annotated verbatim with that keyphrase.
This simple aggregation approach has the obvious downside of requiring very strict matching between independently authored reviews. For that reason, we consider extensions to this aggregation
approach that allow for annotation paraphrasing:
• Model cluster aggregation: A keyphrase is supported for a restaurant if at least two out of
its five reviews are annotated with that keyphrase or one of its paraphrases. Paraphrasing is
according to our model’s inferred clustering.
• Gold cluster aggregation: Same as model cluster aggregation, but using the expert-generated
clustering for paraphrasing.
• Independent cluster aggregation: Same as model cluster aggregation, but using the clustering
learned only from keyphrase similarity for paraphrasing.
13. When three corroborating reviews are required, the baseline systems produce very few positive predictions, leading
to poor recall. Results for this setting are presented in Appendix B.

596

L EARNING D OCUMENT-L EVEL S EMANTIC P ROPERTIES FROM F REE -T EXT A NNOTATIONS

6.2.3 R ESULTS
Table 8 compares the baselines against our model. Our model outperforms all of the annotationbased baselines, despite not having access to the keyphrase annotations. Notably, keyphrase aggregation performs very poorly, because it makes very few predictions, as a result of its requirement
of exact keyphrase string match. As before, the inclusion of keyphrase clusters improves the performance of the baseline models. However, the incompleteness of the keyphrase annotations (see
Section 3) explains why the recall scores are still low compared to our model. By incorporating
document text, our model obtains dramatically improved recall, at the cost of reduced precision,
ultimately yielding a significantly improved F-score.
These results demonstrate that review summarization benefits greatly from our joint model of the
review text and keyphrases. Naı̈ve approaches that consider only keyphrases yield inferior results,
even when augmented with paraphrase information.

7. Conclusions and Future Work
In this paper, we have shown how free-text keyphrase annotations provided by novice users can
be leveraged as a training set for document-level semantic inference. Free-text annotations have
the potential to vastly expand the set of training data available to developers of semantic inference
systems; however, as we have shown, they suffer from lack of consistency and completeness. We
overcome these problems by inducing a hidden structure of semantic properties, which correspond
both to clusters of keyphrases and hidden topics in the text. Our approach takes the form of a
hierarchical Bayesian model, which addresses both the text and keyphrases jointly.
Our model is implemented in a system that successfully extracts semantic properties of unannotated restaurant, cell phone, and camera reviews, empirically validating our approach. Our experiments demonstrate the necessity of handling the paraphrase structure of free-text keyphrase
annotations; moreover, they show that a better paraphrase structure is learned in a joint framework
that also models the document text. Our approach outperforms competitive baselines for semantic
property extraction from both single and multiple documents. It also permits aggregation across
multiple keyphrases with different surface forms for multi-document summarization.
This work extends an actively growing literature on document topic modeling. Both topic modeling and paraphrasing posit a hidden layer that captures the relationship between disparate surface
forms: in topic modeling, there is a set of latent distributions over lexical items, while paraphrasing
is represented by a latent clustering over phrases. We show these two latent structures can be linked,
resulting in increased robustness and semantic coherence.
We see several avenues of future work. First, our model draws substantial power from features that measure keyphrase similarity. This ability to use arbitrary similarity metrics is desirable;
however, representing individual similarity scores as random variables is a compromise, as they are
clearly not independent. We believe that this problem could be avoided by modeling the generation
of the entire similarity matrix jointly.
A related approach would be to treat the similarity matrix across keyphrases as an indicator of
covariance structure. In such a model, we would learn separate language models for each keyphrase,
but keyphrases that are rated as highly similar would be constrained to induce similar language
models. Such an approach might be possible in a Gaussian process framework (Rasmussen &
Williams, 2006).

597

B RANAVAN , C HEN , E ISENSTEIN , & BARZILAY

Currently the focus of our model is to identify the semantic properties expressed in a given
document, which allows us to produce a summary of those properties. However, as mentioned in
Section 3, human authors do not give equal importance to all properties when producing a summary
of pros and cons. One possible extension of this work would be to explicitly model the likelihood
of each topic being annotated in a document. We might then avoid the current post-processing step
that uses property-specific thresholds to compute final predictions from the model output.
Finally, we have assumed that the semantic properties themselves are unstructured. In reality,
properties are related in interesting ways. Trivially, in the domain of reviews it would be desirable
to model antonyms explicitly, e.g., no restaurant review should be simultaneously labeled as having
good and bad food. Other relationships between properties, such as hierarchical structures, could
also be considered. This suggests possible connections to the correlated topic model of Blei and
Lafferty (2006).

Bibliographic Note
Portions of this work were previously presented in a conference publication (Branavan et al., 2008).
The current article extends this work in several ways, most notably: the development and evaluation
of a multi-document review summarization system that uses semantic properties induced by our
method (Section 6.2); a detailed analysis of the distributional properties of free-text annotations
(Section 3); and an expansion of the evaluation to include an additional domain and sets of baselines
not considered in the original paper (Section 6.1.1).

Acknowledgments
The authors acknowledge the support of National Science Foundation (NSF) CAREER grant IIS0448168, the Microsoft Research New Faculty Fellowship, the U.S. Office of Naval Research
(ONR), Quanta Computer, and Nokia Corporation. Harr Chen is supported by the National Defense Science and Engineering and NSF Graduate Fellowships. Thanks to Michael Collins, Zoran
Dzunic, Amir Globerson, Aria Haghighi, Dina Katabi, Kristian Kersting, Terry Koo, Yoong Keok
Lee, Brian Milch, Tahira Naseem, Dan Roy, Christina Sauper, Benjamin Snyder, Luke Zettlemoyer,
and the journal reviewers for helpful comments and suggestions. We also thank Marcia Davidson
and members of the NLP group at MIT for help with expert annotations. Any opinions, findings,
conclusions or recommendations expressed in this article are those of the authors, and do not necessarily reflect the views of NSF, Microsoft, ONR, Quanta, or Nokia.

598

L EARNING D OCUMENT-L EVEL S EMANTIC P ROPERTIES FROM F REE -T EXT A NNOTATIONS

Appendix A. Development and Test Set Statistics
Table 9 lists the semantic properties for each domain and the number of documents that are used
for evaluating each of these properties. As noted in Section 6.1.1, the gold standard evaluation is
complete, testing every property with each document. Conversely, the free-text evaluations for each
property only use documents that are annotated with the property or its antonym — this is why the
number of documents differs for each semantic property.
Domain
Restaurants (gold)
Restaurants

Cell Phones

Cameras

Property
All properties
Good food
Bad food
Good price
Bad price
Good service
Bad service
Good reception
Bad reception
Good battery life
Poor battery life
Good price
Bad price
Small
Large
Good price
Bad price
Good battery life
Poor battery life
Great zoom
Limited zoom

Development documents
50

Test Documents
120

88

179

31

66

69

140

33

67

59

120

28

57

84

168

56

113

51

102

34

69

Table 9: Breakdown by property for the development and test sets used for the evaluations in section 6.1.2.

599

B RANAVAN , C HEN , E ISENSTEIN , & BARZILAY

Appendix B. Additional Multiple Review Summarization Results
Table 10 lists results of the multi-document experiment, with a variation on the aggregation —
we require each automatic method to predict a property for three of five reviews to predict that
property for the product, rather than two as presented in Section 6.2. For the baseline systems, this
change causes a precipitous drop in recall, leading to F-score results that are substantially worse
than those presented in Section 6.2.3. In contrast, the F-score for our model is consistent across
both evaluations.
Method
Our model
Keyphrase aggregation
Model cluster aggregation
Gold cluster aggregation
Indep. cluster aggregation

Recall
0.726
0.000
0.024
0.036
0.036

Prec.
0.365
0.000
1.000
1.000
1.000

F-score
0.486
0.000 ∗
0.047 ∗
0.068 ∗
0.068 ∗

Table 10: Comparison of the aggregated property predictions made by our model and a series of
baselines that only use free-text annotations. Aggregation requires three of five reviews
to predict a property, rather than two as in Section 6.2. The methods against which our
model has significantly better results using approximate randomization are indicated with
∗ for p ≤ 0.05.

Appendix C. Hyperparameter Settings
Table 11 lists the values of hyperparameters θ0 , ψ0 , and φ0 used in all experiments for each domain.
These values were arrived at through tuning on the development set. In all cases, λ0 was set to
(1, 1), making Beta(λ0 ) the uniform distribution.
Hyperparameters
θ0
ψ0
φ0

Restaurants
0.0001
0.001
0.001

Cell Phones
0.0001
0.0001
0.0001

Cameras
0.0001
0.1
0.001

Table 11: Values of the hyperparameters used for each domain across all experiments.

600

L EARNING D OCUMENT-L EVEL S EMANTIC P ROPERTIES FROM F REE -T EXT A NNOTATIONS

References
Barzilay, R., McKeown, K., & Elhadad, M. (1999). Information fusion in the context of multidocument summarization. In Proceedings of ACL, pp. 550–557.
Barzilay, R., & McKeown, K. R. (2001). Extracting paraphrases from a parallel corpus. In Proceedings of ACL, pp. 50–57.
Bhattacharya, I., & Getoor, L. (2006). A latent Dirichlet model for unsupervised entity resolution.
In Proceedings of the SIAM International Conference on Data Mining.
Blei, D. M., & Lafferty, J. D. (2006). Correlated Topic Models. In Advances in NIPS, pp. 147–154.
Blei, D. M., & McAuliffe, J. (2008). Supervised topic models. In Advances in NIPS, pp. 121–128.
Blei, D. M., Ng, A. Y., & Jordan, M. I. (2003). Latent Dirichlet allocation. Journal of Machine
Learning Research, 3, 993–1022.
Boyd-Graber, J., Blei, D., & Zhu, X. (2007). A topic model for word sense disambiguation. In
Proceedings of EMNLP, pp. 1024–1033.
Branavan, S. R. K., Chen, H., Eisenstein, J., & Barzilay, R. (2008). Learning document-level semantic properties from free-text annotations. In Proceedings of ACL, pp. 263–271.
Carbonell, J., & Goldstein, J. (1998). The use of MMR, diversity-based reranking for reordering
documents and producing summaries. In Proceedings of ACM SIGIR, pp. 335–336.
Chinchor, N. (1995). Statistical significance of MUC-6 results. In Proceedings of the 6th Conference
on Message Understanding, pp. 39–43.
Chinchor, N., Lewis, D. D., & Hirschman, L. (1993). Evaluating message understanding systems:
An analysis of the third message understanding conference (MUC-3). Computational Linguistics, 19(3), 409–449.
Cohen, J. (1960). A coefficient of agreement for nominal scales. Educational and Psychological
Measurement, 20(1), 37–46.
Dagan, I., Glickman, O., & Magnini, B. (2006). The PASCAL recognising textual entailment challenge. Lecture Notes in Computer Science, 3944, 177–190.
Elhadad, N., & McKeown, K. R. (2001). Towards generating patient specific summaries of medical
articles. In Proceedings of NAACL Workshop on Automatic Summarization, pp. 32–40.
Finkel, J. R., Grenager, T., & Manning, C. (2005). Incorporating non-local information into information extraction systems by Gibbs sampling. In Proceedings of ACL, pp. 363–370.
Gelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (2004). Bayesian Data Analysis (2nd edition).
Texts in Statistical Science. Chapman & Hall/CRC.
Goldwater, S., Griffiths, T. L., & Johnson, M. (2006). Contextual dependencies in unsupervised
word segmentation. In Proceedings of ACL, pp. 673–680.
Hu, M., & Liu, B. (2004). Mining and summarizing customer reviews. In Proceedings of SIGKDD,
pp. 168–177.
Joachims, T. (1999). Making Large-Scale Support Vector Machine Learning Practical, pp. 169–184.
MIT Press.

601

B RANAVAN , C HEN , E ISENSTEIN , & BARZILAY

Kim, S.-M., & Hovy, E. (2006). Automatic identification of pro and con reasons in online reviews.
In Proceedings of COLING/ACL, pp. 483–490.
Lin, D., & Pantel, P. (2001). Discovery of inference rules for question-answering. Natural Language
Engineering, 7(4), 343–360.
Liu, B., Hu, M., & Cheng, J. (2005). Opinion observer: Analyzing and comparing opinions on the
web. In Proceedings of WWW, pp. 342–351.
Lu, Y., & Zhai, C. (2008). Opinion integration through semi-supervised topic modeling. In Proceedings of WWW, pp. 121–130.
Mani, I., & Bloedorn, E. (1997). Multi-document summarization by graph search and matching. In
Proceedings of AAAI, pp. 622–628.
Marsi, E., & Krahmer, E. (2005). Explorations in sentence fusion. In Proceedings of the European
Workshop on Natural Language Generation, pp. 109–117.
McCallum, A., Bellare, K., & Pereira, F. (2005). A conditional random field for discriminativelytrained finite-state string edit distance. In Proceedings of UAI, pp. 388–395.
Nenkova, A., Vanderwende, L., & McKeown, K. (2006). A compositional context sensitive multidocument summarizer: exploring the factors that influence summarization. In Proceedings of
SIGIR, pp. 573–580.
Noreen, E. (1989). Computer-Intensive Methods for Testing Hypotheses: An Introduction. John
Wiley and Sons.
Popescu, A.-M., Nguyen, B., & Etzioni, O. (2005). OPINE: Extracting product features and opinions from reviews. In Proceedings of HLT/EMNLP, pp. 339–346.
Purver, M., Körding, K. P., Griffiths, T. L., & Tenenbaum, J. B. (2006). Unsupervised topic modelling for multi-party spoken discourse. In Proceedings of COLING/ACL, pp. 17–24.
Radev, D., Jing, H., & Budzikowska, M. (2000). Centroid-based summarization of multiple documents: Sentence extraction, utility-based evaluation and user studies. In Proceedings of
ANLP/NAACL Summarization Workshop.
Radev, D., & McKeown, K. (1998). Generating natural language summaries from multiple on-line
sources. Computational Linguistics, 24(3), 469–500.
Rand, W. M. (1971). Objective criteria for the evaluation of clustering methods. Journal of the
American Statistical Association, 66(336), 846–850.
Rasmussen, C. E., & Williams, C. K. I. (2006). Gaussian Processes for Machine Learning. MIT
Press.
Riezler, S., & Maxwell, J. T. (2005). On some pitfalls in automatic evaluation and significance
testing for MT. In Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation
Measures for Machine Translation and/or Summarization, pp. 57–64.
Snyder, B., & Barzilay, R. (2007). Multiple aspect ranking using the good grief algorithm. In
Proceedings of NAACL/HLT, pp. 300–307.
Titov, I., & McDonald, R. (2008a). A joint model of text and aspect ratings for sentiment summarization. In Proceedings of ACL, pp. 308–316.

602

L EARNING D OCUMENT-L EVEL S EMANTIC P ROPERTIES FROM F REE -T EXT A NNOTATIONS

Titov, I., & McDonald, R. (2008b). Modeling online reviews with multi-grain topic models. In
Proceedings of WWW, pp. 111–120.
Toutanova, K., & Johnson, M. (2008). A Bayesian LDA-based model for semi-supervised part-ofspeech tagging. In Advances in NIPS, pp. 1521–1528.
White, M., Korelsky, T., Cardie, C., Ng, V., Pierce, D., & Wagstaff, K. (2001). Multi-document
summarization via information extraction. In Proceedings of HLT, pp. 1–7.
Yeh, A. (2000). More accurate tests for the statistical significance of result differences. In Proceedings of COLING, pp. 947–953.
Zaenen, A. (2006). Mark-up barking up the wrong tree. Computational Linguistics, 32(4), 577–580.

603

Journal of Artificial Intelligence Research 34 (2009) 339-389

Submitted 06/08; published 03/09

Identification of Pleonastic It Using the Web
Yifan Li
Petr Musilek
Marek Reformat
Loren Wyard-Scott

yifan@ece.ualberta.ca
musilek@ece.ualberta.ca
reform@ece.ualberta.ca
wyard@ece.ualberta.ca

Department of Electrical and Computer Engineering
University of Alberta
Edmonton, AB T6G 2V4 Canada

Abstract
In a significant minority of cases, certain pronouns, especially the pronoun it, can
be used without referring to any specific entity. This phenomenon of pleonastic pronoun
usage poses serious problems for systems aiming at even a shallow understanding of natural
language texts. In this paper, a novel approach is proposed to identify such uses of it: the
extrapositional cases are identified using a series of queries against the web, and the cleft
cases are identified using a simple set of syntactic rules. The system is evaluated with four
sets of news articles containing 679 extrapositional cases as well as 78 cleft constructs. The
identification results are comparable to those obtained by human efforts.

1. Introduction
Anaphora resolution, which associates a word or phrase (the anaphor) with a previously
mentioned entity (the antecedent), is an active field of Natural Language Processing (NLP)
research. It has an important role in many applications where a non-trivial level of understanding of natural language texts is desired, most notably in information extraction and
machine translation. To illustrate, an information extraction system trying to keep track
of corporate activities may find itself dealing with news such as ‘Microsoft today announced
that it is adopting XML as the default file format for the next major version of its Microsoft
Office software . . . ’ It would be impossible to provide any insight into what Microsoft’s
intention is without associating the pronominal anaphors it and its with their antecedent,
Microsoft.
Adding to the already complex problem of finding the correct antecedent, pronouns are
not always used in the same fashion as shown in the earlier example. It is well-known
that some pronouns, especially it, can occur without referring to a nominal antecedent, or
any antecedent at all. Pronouns used without an antecedent, often referred to as being
pleonastic or structural, pose a serious problem for anaphora resolution systems. Many
anaphora resolution systems underestimate the issue and choose not to implement a specific
module to handle pleonastic pronouns but instead have their input ‘sanitized’ manually to
exclude such cases. However, the high frequency of pronoun usage in general and pleonastic
cases in particular warrants that the phenomenon deserves more serious treatment. The
pronoun it, which accounts for most of the pleonastic pronoun usages, is by far the most
frequently used of all pronouns in the British National Corpus (BNC). In the Wall Street
Journal Corpus (WSJ; Marcus, Marcinkiewicz, & Santorini, 1993), upon which this study
©2009 AI Access Foundation. All rights reserved.

Li, Musilek, Reformat, & Wyard-Scott

is based, it accounts for more than 30% of personal pronoun usage. The percentage of
cases where it lacks a nominal antecedent is also significant: previous studies have reported
figures between 16% and 50% (Gundel, Hedberg, & Zacharski, 2005) while our own analysis
based upon the WSJ corpus results in a value around 25%, more than half of which are
pleonastic cases.
Applying criteria similar to those established by Gundel et al. (2005), the usage of it
can be generally categorized as follows. The instances of it being analyzed are shown in
italics; and the corresponding antecedents, extraposed clauses, and clefted constituents are
marked by underlining.
1. Referential with nominal antecedent
[0006:002]1 The thrift holding company said it expects to obtain regulatory approval
and complete the transaction by year-end.
where it refers to the thrift holding company.
2. Referential with clause antecedent
[0041:029] He was on the board of an insurance company with financial problems, but
he insists he made no secret of it.
where it refers to the fact that the person was on the board of an insurance company.
[0102:002-003] Everyone agrees that most of the nation’s old bridges need to be
repaired or replaced. But there’s disagreement over how to do it.
where it, together with do, refers to the action of repairing or replacing the bridge.
3. No antecedent – Pleonastic
(a) Extraposition
[0034:020] But it doesn’t take much to get burned.
where the infinitive clause to get burned is extraposed and its original position
filled with an expletive it. The equivalent non-extraposed sentence is ‘But to get
burned doesn’t take much.’
[0037:034] It’s a shame their meeting never took place.
The equivalent non-extraposed sentence is ‘That their meeting never took place
is a shame.’
(b) Cleft2
[0044:026] And most disturbing, it is educators, not students, who are blamed
for much of the wrongdoing.
The equivalent non-cleft version is ‘And most disturbing, educators, not students,
are blamed for much of the wrongdoing.’
1

All example sentences are selected from the WSJ corpus, with locations encoded in the format [article:sentence].
2
Some claim that cleft pronouns should not be classified as expletive (Gundel, 1977; Hedberg, 2000).
Nevertheless, this does not change the fact that the pronouns do not have nominal antecedents; hence clefts
are included in this analysis.

340

Identification of Pleonastic It Using the Web

[0591:021] It is partly for this reason that the exchange last week began trading
in its own stock “basket” product . . .
The equivalent non-cleft version is ‘The exchange last week began trading in its
own stock basket product partly for this reason.’
(c) Local Situation
[0207:037] It was not an unpleasant evening . . .
This category consists of it instances related to weather, time, distance, and other
information about the local situation. Since the texts reviewed in this study lack
instances of other subtypes, only weather and time cases are discussed.
4. Idiomatic
[0010:010] The governor couldn’t make it, so the lieutenant governor welcomed the
special guests.
This paper focuses on pleonastic cases (the third category), where each subclass carries
its unique syntactic and/or semantic signatures. The idiomatic category, while consisting of
non-anaphoric cases as well, is less coherent and its identification is much more subjective
in nature, making it a less attractive target.
This paper is organized as follows: Section 2 provides a brief survey of related work
toward both classification of it and identification of pleonastic it; Section 3 proposes a
web-based approach for identification of pleonastic it; Section 4 demonstrates the proposed
method with a case study; Section 5 follows with evaluation; and finally, Section 6 discusses
the findings and presents ideas for future work.

2. Previous Work
As Evans (2001) pointed out, usage of it is covered in most serious surveys of English
grammar, some of which (e.g. Sinclair, 1995) also provide classifications based on semantic
categories. In a recent study, Gundel et al. (2005) classify third-person personal pronouns
into the following comprehensive hierarchy:
• Noun phrase (NP) antecedent
• Inferrable
• Non-NP antecedent
– Fact
– Situation

– Proposition
– Reason

– Activity

– Event

– Full cleft
– Atmospheric

– Truncated cleft
– Other pleonastic

• Pleonastic
– Full extraposition
– Truncated extraposition
• Idiom
• Exophoric
• Indeterminate
341

Li, Musilek, Reformat, & Wyard-Scott

Without going into the details of each category, it is apparent from the length of the
list that the phenomenon of pleonastic it, and more generally pronouns without explicit
nominal antecedents, have been painstakingly studied by linguists. However, despite being
identified as one of the open issues of anaphora resolution (Mitkov, 2001), work on automatic
identification of pleonastic it is relatively scarce. To date, existing studies in the area fall
into one of two categories: one wherein a rule-based approach is used, and the other using
a machine-learning approach.

2.1 Rule-based Approaches
Paice and Husk (1987) together with Lappin and Leass (1994) provide examples of rulebased systems that make use of predefined syntactic patterns and word lists. The Paice
and Husk approach employs bracketing patterns such as it . . . to and it . . . who to meet
the syntactic restrictions of extraposition and cleft. The matched portions of sentences are
then evaluated by further rules represented by word lists. For example, the it . . . to rule
prescribes that one of the ‘task status’ words, such as good or bad, must be present amid
the construct. In order to reduce false positives, general restrictions are applied on sentence
features such as construct length and intervening punctuation.
Lappin and Leass’s (1994) approach employs a set of more detailed rules such as It is
Modaladj that S and It is Cogv-ed that S, where Modaladj and Cogv are predefined
lists of modal adjectives (e.g. good and useful ) and cognitive verbs (e.g. think and believe),
respectively. Compared to Paice and Husk’s (1987) approach, this method is much more
restrictive, especially in its rigidly-specified grammatical constraints. For example, it is
not clear from the original Lappin and Leass paper whether the system would be able to
recognize sentences such as [0146:014] ‘It isn’t clear, however, whether . . . ’ despite its claim
that the system takes syntactic variants into consideration.
Lappin and Leass’s (1994) approach is part of a larger system, and no evaluation is
provided. The Paice and Husk (1987) approach, on the other hand, evaluates impressively.
It has an accuracy of 93.9% in determining pleonastic constructs on the same data used for
rule development, without using part-of-speech tagging or parsing.
Both rule-based systems rely on patterns to represent syntactic constraints and word
lists to represent semantic constraints. This makes them relatively easy to implement and
maintain. However, these features also make them less scalable – when challenged with
large and unfamiliar corpora, their accuracies deteriorate. For example, Paice and Husk
(1987) noticed nearly a 10% decrease in accuracy when rules developed using one subset
of the corpus are applied to another subset without modifications. Boyd, Gegg-Harrison,
and Byron (2005) also observed a significant performance penalty when the approach was
applied to a different corpus. In other words, rule-based systems can only be as good as they
are designed to be. Denber (1998) suggested using WordNet (Fellbaum, 1998) to extend
the word lists, but it is doubtful how helpful this would be considering the enormous number
of possible words that are not included in existing lists and the number of inapplicable words
that will be identified by such an approach.
342

Identification of Pleonastic It Using the Web

2.2 Machine-learning Approaches
Recent years have seen a shift toward machine-learning approaches, which shed new light on
the issue. Studies by Evans (2001, 2000) and Boyd et al. (2005) are examples of this class.
Both systems employ memory-based learning on grammatical feature vectors; Boyd et al.’s
approach also includes a decision tree algorithm that produces less ideal results. In his
attempt to place uses of it into seven categories, including pleonastic and nominal anaphoric
among others, Evans uses 35 features to encode information such as position/proximity,
lemmas, and part-of-speech, related to both the pronoun and other components of interest,
such as words and noun phrases, in the sentence. Evans reported 73.38% precision and
69.25% recall for binary classification of pleonastic cases, and an overall binary classification
accuracy of 71.48%. In a later study featuring MARS3 , a fully automatic pronoun resolution
system that employs the same approach, Mitkov, Evans, and Orasan (2002) reported a
significantly higher binary classification accuracy of 85.54% when the approach is applied
to technical manuals.
Boyd et al.’s (2005) approach targets pleonastic it alone. It uses 25 features, most
of which concern lengths of specific syntactic structures; also included are part-of-speech
information and lemmas of verbs. The study reports an overall precision of 82% and recall
of 71%, and, more specifically, recalls on extrapositional and cleft constructs of 81% and
45%, respectively.
In addition, Clemente, Torisawa, and Satou (2004) used support vector machines with a
feature-set similar to that proposed by Evans (2001) to analyze biological and medical texts,
and reported an overall accuracy of 92.7% – higher than that of their own memory-based
learning implementation. Ng and Cardie (2002) built a decision tree for binary anaphoricity
classification on all types of noun phrases (including pronouns) using the C4.5 induction
algorithm. Ng and Cardie reported overall accuracies of 86.1% and 84.0% on the MUC-6
and MUC-7 data sets. Categorical results, however, are not reported and it is not possible
to determine the system’s performance on pronouns. Using automatically induced rules,
Müller (2006) reported an overall accuracy of 79.6% when detecting non-referential it in
spoken dialogs. An inter-annotator agreement study conducted in the same paper indicates
that it is difficult even for humans to classify instances of it in spoken dialogs. This finding
is supported by our own experiences.
Machine-learning approaches are able to partly circumvent the restrictions imposed by
fixed word lists or rigid grammatical patterns through learning. However, their advantage
also comes with a price – training is required in the initial development phase and for
different corpora re-training is preferable since lemmas are part of the feature sets. Since
the existing approaches fall within the area of supervised learning (i.e. training data need
to be manually classified), the limited number of lemmas they gather from training may
lead to degraded performance in unfamiliar circumstances. Moreover, the features used
during learning are unable to reliably capture the subtleties of the original sentences, especially when considering non-technical documents. For example, the quantitative features
frequently used in machine-learning approaches, such as position and distance, become less
reliable when sentences contain a large number of adjuncts. Additionally, the meanings of
lemmas are often domain-dependent and can vary with their local structural and lexical
3

Available online at http://clg.wlv.ac.uk/demos/MARS/

343

Li, Musilek, Reformat, & Wyard-Scott

environment – such nuances cannot be captured by the lemma features alone. In short,
while machine-learning approaches generally deliver better performance classifying it than
their rule-based counterparts do, they have their own inherent problems.

3. A Web Based Approach
Both syntactic patterns and semantics of various clause constituents play important roles in
determining if a third-person personal pronoun is pleonastic. The role of grammar is quite
obvious since both extrapositions and clefts must follow the grammatical patterns by which
they are defined. For example, the most commonly seen type of it-extraposition follows the
pattern:
it + copula + status + subordinate clause
[0089:017] It
is
easy
to see why the ancient art is on the ropes.
In contrast, the role semantics plays here is a little obscure until one sits down and starts
to “dream up exceptions” (Paice & Husk, 1987) analogous to [0074:005] ‘ . . . it has taken
measures to continue shipments during the work stoppage.’ vis-à-vis [0367:044] ‘ . . . it didn’t
take a rocket scientist to change a road bike into a mountain bike . . . ’, where referential
and pleonastic cases share the same syntactic structure. Despite its less overt role, failure
to process semantic information can result in a severe degradation of performance. This
observation is supported by the word-list-based systems’ dramatic decay in accuracy when
they are confronted with text other than that they obtained their word lists from.
Like every other classification system, the proposed system strives to cover as many cases
as possible and at the same time perform classification as accurately as possible. To achieve
this, it attempts to make good use of both syntactic and semantic information embedded
in sentences. A set of relaxed yet highly relevant syntactic patterns is first applied to the
input text to filter out the syntactically inviable cases. Unlike the matching routines of some
previous approaches, this process avoids detailed specification of syntactic patterns. Instead,
it tries to include every piece of text containing a construct of possible interest. Different
levels of semantic examinations are performed for each subtype of pleonastic constructs.
For reasons discussed later in Section 3.2.2, semantic analysis is not performed on clefts.
A WordNet-based analysis is used to identify weather/time cases because among the
samples examined during the system’s development stage, cases pertaining to this class are
relatively uniform in their manner of expression. For the most complex and populous class,
the extrapositions, candidates are subjected to a series of tests performed as queries against
the web. Results of the queries provide direct evidence of how a specific configuration of
clause constituents is generally used.
The reason that such a corpus-based approach is chosen versus applying manually constructed knowledge sources, such as a word list or WordNet, is fourfold:
1. Manually constructed knowledge sources, regardless of how comprehensive they are,
contain only a small portion of general world knowledge. In the particular settings
of this study, general world knowledge is used for making judgements such as which
words are allowed to serve as the matrix verb of an extraposition, and even more
subtle, which specific sense of a word is permitted.
344

Identification of Pleonastic It Using the Web

2. Manually compiled knowledge sources are subject to specific manners of organization
that may not satisfy the system’s needs. Taking WordNet as an example, it identifies
a large number of various relationships among entities, but the information is mainly
organized along the axes of synonyms, hypernyms (kind-of relationship), and holonyms
(part-of relationship) etc., while it is the surroundings of a particular word that are
of more interest to this study.
3. Natural languages are evolving quickly. Taking English as an example, each year new
words are incorporated into the language4 and the rules of grammar have not been
immune to changes either. Using a large and frequently-updated corpus such as the
web allows the system to automatically adapt to changes in language.
4. Most importantly, corpora collect empirical evidence of language usage. When the
sample size is large enough, as in the case of the web, statistics on how a specific
construct is generally used in corpora can be employed as an indicator of its speaker’s
intention.
The proposed approach is also inspired by Hearst’s (1992) work on mining semantic
relationships using text patterns, and many other quests that followed in the same direction (Berland & Charniak, 1999; Poesio, Ishikawa, im Walde, & Vieira, 2002; Markert,
Nissim, & Modjeska, 2003; Cimiano, Schmidt-Thieme, Pivk, & Staab, 2005). Unlike these
investigations that focus on the semantic relationship among noun phrases, the pleonastic
pronoun identification problem mandates more complex queries to be built according to
the original sentences. However, the binary nature of the problem also makes it simpler to
apply comparative analysis on results of multiple queries, which, in turn, leads to better
immunity to noise.
Figure 1 illustrates the general work flow of the proposed system. A sentence is first
preprocessed to obtain a dependency tree with part-of-speech tags, which is then passed
on to the syntactic filtering component to determine whether minimum grammatical requirements of the pleonastic constructs are met. It is also during the syntactic filtering
process that clefts and weather/time expressions are identified using syntactic cues and the
WordNet respectively. The candidate extrapositions are thereafter used to instantiate
various queries on search engines; the results returned from the queries serve as parameters
for the final decision-making mechanism.
3.1 Preprocessing
The preprocessing component transforms the syntactic information embedded in natural
language texts into machine-understandable structures. During the preprocessing stage,
each word is assigned a part-of-speech tag, and the whole sentence is parsed using a dependency grammar (DG) parser. For simplicity’s sake, the current system is designed to use the
WSJ corpus, which is already tagged and parsed with context-free grammar (CFG). A head
percolation table similar to that proposed by Collins (1999) is used to obtain the head component of each phrase. The rest of the phrase constituents are then rearranged under the
4
Metcalf and Barnhart (1999) have compiled a chronicle of many important additions to the vocabulary
of American English.

345

Li, Musilek, Reformat, & Wyard-Scott

Figure 1: Illustration of the system work flow broken into three processing stages – preprocessing, syntactic filtering, and web-based analysis.

head component to form the dependency tree using a procedure detailed by Xia and Palmer
(2001). Figure 2 illustrates the syntactic structure of a sentence in the WSJ corpus. Both
the original CFG parse tree and the derived dependency structure are shown side-by-side.
Head entities are underlined in the CFG diagram and circled in the DG diagram.

Figure 2: Illustration of a sentence’s syntactic structure, both as annotated in the WSJ
corpus (left) and after head percolation (right).

346

Identification of Pleonastic It Using the Web

As shown in Figure 2, the function tags (e.g. SBJ, TMP, and CLR) and tracing information
present in the context-free parse tree are not ported to the dependency tree. This is because
real-world parsers usually do not produce such tags. Except this deliberate omission, both
parse trees contain essentially the same information, only presented in different manners.
In this study, dependency structure is preferred over the more popular phrase structure
mainly because of its explicit marking of both the head components and the complementing/modifying relationships among various components. This feature is very helpful for
instantiating the search-engine queries.
3.2 Syntactic Filtering
The syntactic filtering process determines whether a clause meets the grammatical requirements of an extraposition or cleft construct by matching the clause against their respective
syntactic patterns.
3.2.1 Extrapositions
It-extrapositions occur when a clause is dislocated out of its ordinary position and replaced
with it. An it-extraposition usually follows the pattern:
matrix clause
z

 }|



 noun phrase




adjective phrase
be
+



prepositional phrase
itsubject +







verb phrase

|

{z

matrix verb phrase

 {

 







+ extraposed clause






}

(1)

This pattern summarizes the general characteristics of subject it-extrapositions, where the
pronoun it assumes the subject position. When the matrix verb (the verb following it) is
the main copula to be, which serves to equate or associate the subject and an ensuing logical
predicate, it must be followed by either a noun phrase, an adjective phrase, or a prepositional
phrase.5 There is no special requirement for the matrix verb phrase otherwise. Similarly,
there is almost no restriction placed upon the extraposed clause except that a full clause
should either be introduced without a complementizer (e.g. [0037:034] ‘It’s a shame their
meeting never took place.’) or led by that, whether, if, or one of the wh-adverbs (e.g.
how, why, when, etc.). These constraints are developed by generalizing a small portion of
the WSJ corpus and are largely in accordance with the patterns identified by Kaltenböck
(2005). Compared to the patterns proposed by Paice and Husk (1987), which also cover
cases such as it . . . to , it . . . that and it . . . whether , they allow for a broader range
of candidates by considering sentences that are not explicitly marked (such as [0037:034]).
The above configuration covers sentences such as:
5
Other copula verbs do not receive the same treatment. This arrangement is made to accommodate
cases where verbs such as to seem and to appear are immediately followed by an extraposed clause.

347

Li, Musilek, Reformat, & Wyard-Scott

[0529:009] Since the cost of transporting gas is so important to producers’ ability to sell it, it helps to have input and access to transportation
companies.
[0037:034] It’s a shame their meeting never took place.
[0360:036] It is insulting and demeaning to say that scientists “needed new crises
to generate new grants and contracts . . .6
[0336:019] It won’t be clear for months whether the price increase will stick.
Except in the case of the last sentence, the above constructs are generally overlooked by
the previous rule-based approaches identified in Section 2.1. As the last sample sentence
illustrates, the plus sign (+) in the pattern serves to indicate a forthcoming component
rather than suggest two immediately adjacent components.
Some common grammatical variants of the pattern are also recognized by the system,
including questions (both direct and indirect), inverted sentences, and parenthetical expressions (Paice & Husk, 1987). This further expands the pattern’s coverage to sentences such
as:
[0772:006] I remembered how hard it was for an outsider to become accepted . . .
[0562:015] “The sooner our vans hit the road each morning, the easier it is for
us to fulfill that obligation.”
[0239:009] Americans it seems have followed Malcolm Forbes’s hot-air lead and
taken to ballooning in a heady way.
Aside from being the subject of the matrix clause, extrapositional it can also appear in
the object position. The system described here captures three flavors of object extraposition.
The first type consists of instances of it followed by an object complement:
[0044:014] Mrs. Yeargin was fired and prosecuted under an unusual South
Carolina law that makes it a crime to breach test security.
In this case the system inserts a virtual copula to be between the object it and the object
complement (a crime), making the construct applicable to the pattern of subject extraposition. For example, the underlined part of the prior example translates into ‘it is a crime
to breach test security’.
The other two kinds of object extraposition are relatively rare:
• Object of verb (without object complement)
[0114:007] Speculation had it that the company was asking $100 million for an operation said to be losing about $20 million a year . . .
• Object of preposition
[1286:054] They should see to it that their kids don’t play truant . . .
These cases cannot be analyzed within the framework of subject extraposition and thus
must be approached with a different pattern:
verb + [preposition] it object + full clause

(2)

6
Neither insulting nor demeaning is in Paice and Husk’s (1987) list of ‘task status words’ and therefore
cannot activate the it . . . to pattern.

348

Identification of Pleonastic It Using the Web

The current system requires that the full clauses start with a complementizer that. This
restriction, however, is included only to simplify implementation. Although in object expositions it is more common to have clauses led by that, full clauses without a leading
complementizer are also acceptable.
According to Kaltenböck’s (2005) analysis there are special cases in which noun phrases
appear as an extraposed component, such as ‘It’s amazing the number of theologians that
sided with Hitler.’ He noted that these noun phrases are semantically close to subordinate
interrogative clauses and can therefore be considered a marginal case of extraposition. However, no such cases were found in the corpus during the annotation process and they are
consequently excluded from this study.
3.2.2 Cleft
It-clefts are governed by a slightly more restricted grammatical pattern. Following Hedberg
(1990), it-clefts can be expressed as follows:
it subject + copula + clefted constituent + cleft clause

(3)

The cleft clause must be finite (i.e. a full clause or a relative clause); and the clefted constituents are restricted to either noun phrases, clauses, or prepositional phrases.7 Examples
of sentences meeting these constraints include:
[0296:029] “It’s the total relationship that is important.”
[0267:030] It was also in law school that Mr. O’Kicki and his first wife had the
first of seven daughters.
[0121:048] “If the market goes down, I figure it’s paper profits I’m losing.”
In addition, another non-canonical and probably even marginal case is also identified as a
cleft:
[0296:037] I really do not understand how it is that Filipinos feel so passionately
involved in this father figure that they want to dispose of and yet they
need.
Text following the structure of this sample, where a wh-adverb immediately precedes it, is
captured using the same syntactic pattern by appending a virtual prepositional phrase to
the matrix copula (e.g. ‘for this reason’), as if the missing information has already been
given.
Each of the examples above represents a possible syntactic construct of it-clefts. While
it is difficult to tell the second and the third cases apart from their respective extrapositional
counterparts, it is even more difficult to differentiate the first case from an ordinary copula
sentence with a restrictive relative clause (RRC). For example, the following sentence,
[0062:012] “It’s precisely the kind of product that’s created the municipal landfill
monster,” the editors wrote.
and its slightly modified version,
[0062:012´] “It’s this kind of product that’s created the municipal landfill monster,” the editors wrote.
7
Adjective and adverb phrases are also possible but they are relatively less frequent and are excluded
from this analysis.

349

Li, Musilek, Reformat, & Wyard-Scott

are similar in construction. However, the latter is considered a cleft construct while the
first is an RRC construct. To make things worse, and as pointed out by many (e.g. Boyd
et al., 2005, p.3, example 5), sometimes it is impossible to make such a distinction without
resorting to the context of the sentence.
Fortunately, in the majority of cases the syntactic features, especially those of the clefted
constituent, provide some useful cues. In an it-cleft construct, the cleft clause does not constitute a head-modifier relationship with the clefted constituent, but instead forms an existential and exhaustive presupposition8 (Davidse, 2000; Hedberg, 2000; Lambrecht, 2001).
For example, ‘I figure it’s paper profits I’m losing.’ implies that in the context there is something (and only one thing) that the speaker is going to lose, and further associates ‘paper
profits’ with it. This significant difference in semantics often leaves visible traces on the syntactic layer, some of which, such as the applicability of proper nouns as clefted constituents,
are obvious. Others are less obvious. The system utilizes the following grammatical cues
when deciding if a construct is an it-cleft9 :
• For the clefted constituent:
– Proper nouns10 or pronouns, which cannot be further modified by an RRC;
– Common nouns without determiner, which generally refer to kinds11 ;
– Plurals, which violate number agreement;
– Noun phrases that are grounded with demonstratives or possessives, or that are
modified by RRCs, which unambiguously identify instances, making it unnecessary in most cases to employ an RRC;
– Noun phrases grounded with the definite determiner the, and modified by an
of -preposition whose object is also a noun phrase grounded with the or is in
plural. These constructs are usually sufficient for introducing uniquely identifiable entities (through association), thus precluding the need for additional RRC
modifiers. The words kind, sort, and their likes are considered exceptions of this
rule;
– Adverbial constructs that usually do not appear as complements. For example,
phrases denoting location (here, there etc.) or a specific time (today, yesterday
etc.), or a clause led by when; and
– Full clauses, gerunds, and infinitives.
• For the subordinate clause:
– Some constructs appear awkward to be used as an RRC. For example, one would
generally avoid using sentences such as ‘it is a place that is dirty’, as there are
8

This applies to canonical clefts, which do not include the class represented by [0267:030].
A construct is considered an it-cleft if any of the conditions are met.
10
There are exceptional cases where proper names are used with additional determiners and RRC modifiers, such as in ‘the John who was on TV last night’, c.f. Sloat’s (1969) account.
11
The validity of this assertion is under debate (Krifka, 2003). Nevertheless, considering the particular
syntactic setting in discussion, it is highly unlikely that bare noun phrases are used to denote specific
instances.
9

350

Identification of Pleonastic It Using the Web

better alternatives. In the current implementation two patterns are considered
inappropriate for RRCs, especially in the syntactic settings described in Equation 3: A) the subordinate verb phrase consists of only a copula verb and an
adjective; and B) the subordinate verb phrase consists of no element other than
the verb itself.
• Combined:
– When the clefted constituent is a prepositional phrase and the subordinate clause
is a full clause, such as in the case of [0267:030], the construct is classified as a
cleft12 .
Some of these rules are based on heuristics and may have exceptions, making them less
ideal guidelines. Moreover, as mentioned earlier, there are cleft cases that cannot be told
apart from RRCs by any grammatical means. However, experiments show that these rules
are relatively accurate and provide appropriate coverage, at least for the WSJ corpus.
3.2.3 Additional Filters
Aside from the patterns described in earlier sections, a few additional filters are installed
to eliminate some semantically unfit constructs and therefore reducing the number of trips
to search engines. The filtering rules are as follows:
• For a clause to be identified as a subordinate clause and subsequently processed for
extraposition or cleft, the number of commas, dashes and colons between the clause
and it should be either zero or more than one, a rule adopted from Paice and Husk’s
(1987) proposal.
• Except the copula to be, sentences with matrix verbs appearing in their perfect tense
are not considered for either extraposition or cleft.
• When it is the subject of multiple verb phrases, the sentence is not considered for
either extraposition or cleft.
• Sentences having a noun phrase matrix logical predicate together with a subordinate
relative clause are not considered for extraposition.
• Sentences having both a matrix verb preceded by modal auxiliaries could or would
and a subordinate clause led by if or a wh-adverb are not considered for extraposition.
For example, [0013:017] ‘ . . . it could complete the purchase by next summer if its bid
is the one approved by . . . ’ is not considered for extraposition.
Except for the first, these rules are optional and can be deactivated in case they introduce
false-negatives.
3.3 Using the Web as a Corpus
The first question regarding using the web as a corpus is whether it can be regarded as a
corpus at all. As Kilgarriff and Grefenstette (2003) pointed out, following the definition of
12
In case it is not a cleft, chances are that it is an extraposition. This assumption, therefore, does not
affect the overall binary classification.

351

Li, Musilek, Reformat, & Wyard-Scott

corpus-hood that ‘a corpus is a collection of texts when considered as an object of language
or literary study’, the answer is yes. With the fundamental problem resolved, what remains
is to find out whether the web can be an effective tool for NLP tasks.
As a corpus, the web is far from being well-balanced or error-free. However, it has
one feature in which no other corpus can be even remotely comparable – its size. No one
knows exactly how big it is, but each of the major search engines already indexes billions
of pages. Indeed, the web is so large that sometimes a misspelled word can yield tens of
thousands of results (try the word neglectible). This sends out a mixed signal about using
the web as a corpus: on the good side, even relatively infrequent terms yield sizable results;
on the bad side, the web introduces much more noise than manually-compiled corpora do.
In Markert and Nissim’s (2005) recent study evaluating different knowledge sources for
anaphora resolution, the web-based method achieves far higher recall ratio than those that
are BNC- and WordNet-based, while at the same time yielding slightly lower precision.
Similar things can be said about the web’s diverse and unbalanced composition, which
means that it can be used as a universal knowledge source – only if one can manage not to
get overwhelmed by non-domain-specific information.
That being said, it is still very hard to overstate the benefits that the web offers. As the
largest collection of electronic texts in natural language, it not only hosts a good portion
of general world knowledge, but also stores this information using the very syntax that
defines our language. In addition, it is devoid of the systematic noise introduced into
manually-constructed knowledge sources during the compilation process (e.g. failure to
include less frequent items or inflexible ways of information organization). Overall, the web
is a statistically reliable instrument for analyzing various semantic relationships stored in
natural languages by means of examples.
As also suggested by Kilgarriff (2007) and many others, it is technically more difficult
to exploit the web than to use a local corpus and it can often be dangerous to rely solely
on statistics provided by commercial search engines. This is mainly due to the fact that
commercial search engines are not designed for corpus research. Worse, some of their design
goals even impede such uses. For example, search engines skew the order of results using a
number of different factors in order to provide users with the ‘best’ results. Combined with
this is the fact that they only return results up to certain thresholds, making it essentially
impossible to get unbiased results. Other annoyances include unreliable result counts, lack
of advanced search features13 , and unwillingness to provide unrestricted access to their
APIs. Before a new search engine specifically designed for corpus research is available, it
seems we will have to work around some of those restrictions and live with the rest.
3.4 Design of Search Engine Queries
As discussed in previous sections, it-extrapositions cannot be reliably identified using syntactic signatures alone or in combination with synthetic knowledge bases. To overcome the
artificial limitations imposed by knowledge sources, the proposed system resorts to the web
for the necessary semantic information.
13
For example, the wildcard (∗) feature on Google, which could be immensely useful for query construction, no longer restricts its results to single words since 2003; Yahoo’s ability to support alternate words
within quoted texts is limited, while MSN does not offer that feature at all.

352

Identification of Pleonastic It Using the Web

The system employs three sets of query patterns: the what-cleft, the comparative expletive test, and the missing-object construction. Each set provides a unique perspective of
the sentence in question. The what-cleft pattern is designed to find out if the sentence under investigation has a valid what-cleft counterpart. Since it-extrapositions and what-clefts
are syntactically compatible (as shown in Section 3.4.1) and valid readings can usually be
obtained by transformations from one construct to the other, the validity of the what-cleft
is indicative of whether or not the original sentence is extrapositional. The comparative
expletive test patterns are more straightforward – they directly check whether the instance
of it can be replaced by other entities that cannot be used expletively in the same context as
that of an extrapositional it. If the alternate construct is invalid, the original sentence can
be determined as expletive. The third set of patterns are supplemental. They are intended
only for identifying the relatively rare phenomenon of missing-object construction, which
may not be reliably handled by the previous pattern sets.
Designing the appropriate query patterns is the most important step in efforts to exploit
large corpora as knowledge sources. For complex queries against the web, it is especially
important to suppress unwanted uses of certain components, which could result from different word senses, different sentence configuration, or a speaker’s imperfect command of the
language. For example, the query “it is a shame that” could return both a valid extrapositional construct and an RRC such as ‘It is a shame that is perpetuated in his life’; and the
query “what is right is that” could return both valid what-clefts and sentences such as ‘Why
we ought to do what is right is that . . . ’ This study employs three different approaches to
curb unwanted results:
• The first and most important measure is comparative analysis – pairs of similarlyconstructed queries are sent out to the search engine and the ratios of result counts
are used for the decision. This method is effective for problems caused by both different
sentence configuration and bad language usage, since generally neither contribute a
fraction of results large enough to significantly affect the ratio. The method also
provides a normalized view of the web because what is of interest to this study is not
exactly how frequently a specific construct is used, but whether it is more likely to
carry a specific semantic meaning when it is used.
• The second measure is to use stubs in query patterns, as detailed in the following
sections. Stubs help ensure that the outcomes of queries are syntactically and semantically similar to the original sentences and partly resolve the problems caused by
word sense difference.
• Finally, when it is infeasible to use comparative analysis, part of the query results are
validated to obtain an estimated number of valid results.
3.4.1 Query Pattern I: The What-cleft
The first query pattern,
What + verb phrase + copula + stub

(4)

is a what-(pseudo-)cleft construct that encompasses matrix-level information found in an
it-extraposition. The pattern is obtained using a three-step transformation as illustrated
353

Li, Musilek, Reformat, & Wyard-Scott

below:

1)

2)

3)

it + verb phrase + clause
It
is easy
to see why the ancient art is on the ropes. [0089:017]
⇓
clause
+
verb phrase
To see why the ancient art is on the ropes is easy.
⇓
What + verb phrase + copula + clause
What is easy
is
to see why the ancient art is on the ropes.
⇓
What + verb phrase + copula + stub
is
to
What is easy

(5)

Step 1 transforms the original sentence (or clause) to the corresponding non-extraposition
form by removing the pronoun it and restoring the information to the canonical subjectverb-complement order. In the above example, the clause to see . . . is considered the real
subject and is moved back to its canonical position. The non-extraposition form is subsequently converted during step 2 to a what-cleft that highlights its verb phrase. Finally, in
step 3, the subordinate clause is reduced into a stub to enhance the pattern’s coverage. The
choice of stub depends on the structure of the original subordinate clause: to is used when
the original subordinate clause is an infinitive, a gerund, or a for . . . infinitive construct14 .
For the rest of the cases, the original complementizer, or that, in the case where there is
no complementizer, is used as stub. The use of a stub in the pattern imposes a syntactic
constraint, in addition to the ones prescribed by the pronoun what and the copula is, that
demands a subordinate clause be present in query results. The choice of stubs also reflects,
to a certain degree, the semantics of the original texts and therefore can be seen as a weak
semantic constraint.
Below are a few other examples of the what-cleft transformation:
[0059:014] It remains unclear whether the bond issue will be rolled over. ⇒
What remains unclear is whether
[0037:034] It’s a shame their meeting never took place. ⇒
What is a shame is that
The what-cleft pattern only identifies whether the matrix verb phrase is capable of
functioning as a constituent in an it-extraposition. Information in the subordinate clauses is
discarded because this construct is used relatively infrequently and adding extra restrictions
to the query will prohibit it from yielding results in many cases.
Some it-extraposition constructs such as ‘it appears that . . . ’ and ‘it is said that . . . ’
do not have a valid non-extraposition counterpart, but the what-cleft versions often bear
certain degrees of validity and queries instantiated from the pattern will often yield results
(albeit not many) from reputable sources. It is also worth noting that although the input
and output constructs of the transformation are syntactically compatible, they are not
necessarily equivalent in terms of givenness (whether and how information in one sentence
14
According to Hamawand (2003), the for . . . infinitive construct carries distinct semantics; reducing it to
the infinitive alone changes its function. However, with only a few exceptional cases, we find this reduction
generally acceptable. i.e. The lost semantics does not affect the judgment of expletiveness.

354

Identification of Pleonastic It Using the Web

has been entailed by previous discourse). Kaltenböck (2005) noted that the percentage
of extrapositional it constructs carrying new information varies greatly depending on the
category of the text. In contrast, a what-cleft generally expresses new information in the
subordinate clause. The presupposed contents in the two constructs are different, too.
What-clefts, according to Gundel (1977), from which the it-clefts are derived, have the
same existential and exhaustive presuppositions carried by their it-cleft counterparts. On
the other hand, the it-extrapositions, which are semantically identical to their corresponding
non-extrapositions, lack such presuppositions or, at most, imply them at a weaker strength
(Geurts & van der Sandt, 2004). These discrepancies hint that a derived what-cleft is a
‘stronger’ expression than the original extraposition, which may have been why queries
instantiated from the pattern tend to yield considerably less results.
Another potential problem with this pattern is its omission of the subordinate verb,
which occasionally leads to false positives. For example, it does not differentiate between
‘it helps to have input and access to transportation companies’ and ‘it helps expand our
horizon’. This deficiency is accommodated by additional query patterns.
3.4.2 Query Pattern II: Comparative Expletiveness Test
The second group of patterns provides a simplified account of the original text in a few
different flavors. After execution, the results from individual queries are compared to assess
the expletiveness of the subject pronoun. This set of patterns takes the following general
form:
pronoun + verb phrase + simplified extraposed clause
(6)
The only difference among individual patterns lies in the choice of the matrix clause subject
pronoun: it, which, who, this, and he. When the patterns are instantiated and submitted to
a search engine, the number of hits obtained from the it version should by far outnumber
that of the other versions combined if the original text is an it-extraposition; otherwise the
number of hits should be at least comparable. This behavior reflects the expletive nature of
the pronoun in an it-extraposition, which renders the sentence invalid when it is replaced
with other pronouns that have no pleonastic use.
A simplified extraposed clause can take a few different forms depending on its original
structure:
Original Structure
infinitive (to meet you)
for . . . infinitive15 (for him to see the document)
gerund (meeting you)
full clause led by complementizer
(it is a shame that their meeting never took place)
full clause without complementizer
(it is a shame their meeting never took place)

Simplified
infinitive + stub
infinitive + stub
gerund + stub
complementizer + stub
that + stub

Table 1: Simplification of extraposed clause
15
The for . . . passive-infinitive is transformed into active voice (e.g. ‘for products to be sold ’→‘to sell
products’).

355

Li, Musilek, Reformat, & Wyard-Scott

Similar to the case of Pattern I, the stub is used both as a syntactic constraint and a
semantic cue. Depending on the type of search engine, the stub can be either the, which
is the most widely used determiner, or a combination of various determiners, personal
pronouns and possessive pronouns, all of which indicate a subsequent noun phrase. In the
case that an infinitive construct involves a subordinate clause led by a wh-adverb or that,
the complementizer is used as stub. This arrangement guarantees that the results returned
from the query conform to the original text syntactically and semantically. A null value
should be used for stubs in an object position if the original text lacks a nominal object.
To illustrate the rules of transformation, consider the following sentence:
[0044:010] “My teacher said it was OK for me to use the notes on the test,” he
said.
The relevant part of the sentence is:
it + verb phrase + clause
it
was OK
for me to use the notes on the test
Applying the clause simplification rules, the first query is obtained:
it + verb phrase + simplified clause
it
was OK
to use the
The second query is generated by simply replacing the pronoun it with an alternative
pronoun:
alternative pronoun + verb phrase + simplified clause
he
was OK
to use the
Google reports 94,200 hits for the it query, while only one page is found using the alternative
query. Since the pronoun it can be used in a much broader context, replacing it with he
alone hardly makes a balanced comparison. Instead, the combination of which, who, this,
and he is used, as illustrated in the following examples:
[0044:010] “My teacher said it was OK for me to use the notes on the test,” he
said.
⇒
)
(
it
was ok to use the
which/who/this/he
[0089:017] It
( is easy to see why the
) ancient art is on the ropes. ⇒
it
is easy to see why
which/who/this/he
A special set of patterns is used for object extrapositions16 to accommodate their unique
syntactic construct:
verb + [preposition] pronoun + that + stub

(7)

Stubs are chosen according to the same rules for the main pattern set, however only one
alternative pronoun – them – is used.
16
Instances containing object complements are treated under the framework of subject extraposition and
are not included here.

356

Identification of Pleonastic It Using the Web

[0114:007] Speculation had it that the company was asking $100 million for an
operation
said)to be losing about $20 million a year . . . ⇒
(
it
had
that the
them
3.4.3 Query Pattern III: Missing-object Construction
One search engine annoyance is that they ignore punctuation marks. This means one
can only search for text that matches a specific pattern string, but not sentences that
end with a pattern string. The stubs used in Pattern II are generally helpful for excluding sentences that are semantically incompatible with the original from the search
results. However, under circumstances where no stub is attached to the queries (where the
query results should ideally consist of only sentences that end with the query string), the
search engine may produce more results than needed. Sentences conforming to the pattern
it + copula + missing-object construction, such as (referring to a book) ‘it is easy to
read’, present one such situation. What is unique about the construction – and why special
treatment is needed – is that a missing-object construction usually has an it-extraposition
counterpart in which the object is present, for example ‘it is easy to read the book ’. Since
the missing-object constructions are virtually the same (only shorter) as their extrapositional counterparts, there is a good chance for them to be identified as extrapositions. The
following are some additional examples of the missing-object construction:
[0290:025] Where non-violent civil disobedience is the centerpiece, rather than
a lawful demonstration that may only attract crime, it is difficult to
justify.
[0018:024-025] No price for the new shares has been set. Instead, the companies
will leave it up to the marketplace to decide.
[0111:005] He declined to elaborate, other than to say, “It just seemed the right
thing to do at this minute.
Two sets of patterns are proposed17 to identify the likes of the foregoing examples. The
first pattern, the compound adjective test, is inspired by Nanni’s (1980) study considering
the easy-type adjective followed by an infinitive (also commonly termed tough construction)
as a single complex adjective. The pattern takes the form
stub + adjectivebase -to -verb

(8)

where the stub, serving to limit the outcome of the query to noun phrases, takes a combination of determiners or a/an alone; the original adjective is also converted to its base form
adjectivebase if it is in comparative or superlative form. Expanding on Nanni’s original
claims, the pattern can be used to evaluate all adjectives18 as well as constructs furnished
with for . . . infinitive complements. The following example demonstrates the pattern’s
usage:
17

Preliminary experiments have confirmed the effectiveness of the patterns. However, due to sparseness
of samples belonging to this class, they are not included in the reported evaluation.
18
This is based on the observation that compounds such as ‘ready-to-fly’ (referring to model aircrafts)
exist, and that it is hard to obtain a complete enumeration of the easy-type adjectives.

357

Li, Musilek, Reformat, & Wyard-Scott

[0258:024] The machine uses a single processor, which makes it easier to program
than competing machines using several processors. ⇒
an easy-to-program
The second set consists of two patterns used for comparative analysis with the same
general profile:
that + verbgerund + stub
(9)
where verbgerund is the gerund form of the original infinitive. The complementizer that is
used for the sole purpose of ensuring that verbgerund appears as the subject of a subordinate
clause in all sentences returned by the queries. In other words, phrases such as ‘computer
programming’ and ‘pattern matching’ are excluded. For the first pattern, the stub is a
combination of prepositions (currently in and from are chosen); for the second one, a
combination of determiners or the alone is used. For example:
[0258:024] The machine uses a single processor, which makes it easier to program
than competing machines
using)several processors. ⇒
(
in|from
that programming
the
This set of patterns tests the transitivity of the verb in a semantic environment similar
to that of the original sentence. If the verb is used transitively more often, the pattern
with determiners should yield more results, and vice versa. As supported by all preceding
sample sentences, a usually-transitive verb used without an object19 is a good indicator of
missing-object construction and the sentence should be diagnosed as referential.
3.4.4 Query Instantiation
Patterns must be instantiated with information found in original sentences before they are
submitted to a search engine. Considering the general design principles of the system, it is
not advisable to instantiate the patterns with original texts – doing so significantly reduces
the queries’ coverage. Instead, the object of the matrix verb phrase is truncated and the
matrix verb expanded in order to obtain the desired level of coverage.
The truncation process provides different renditions based on the structure of the original
object:
• Adjective phrases:
Only the head word is used. When the head word is modified by not or too, the
modifier is also retained in order to better support the too . . . to construct and to
maintain compatibility with the semantics of the original text.
• Common noun phrases:
– with a possessive ending/pronoun, or an of -preposition:
The phrase is replaced by $PRPS$ plus the head word. $PRPS$ is either a list of
possessive pronouns or one of those more widely used, depending on caliber of
the search engine used. For example, ‘his location’ can be expanded to ‘its | my
| our | his | her | their | your location’.
19
An omitted object of a preposition (e.g. ‘It is difficult to account for.’) has the same effect, but it is
identifiable through syntactic means alone.

358

Identification of Pleonastic It Using the Web

– with determiners:
The phrase is replaced by a choice of $DTA$, $DTTS$, $DTTP$, or a combination
of $DTA$ and $DTTS$, plus the head word. $DTA$ is a list of (or one of the)
general determiners (i.e. a, an, any etc.). $DTTS$ refers to the combination of
the definite article the and the singular demonstratives this and that. $DTTP$ is
the plural counterpart of $DTTS$. The choice is based on the configuration of
the original text so as to maintain semantic compatibility.
– without determiner:
Only the head word is used.
• Proper nouns and pronouns:
The phrase is replaced by $PRP$, which is a list of (or one of the) personal pronouns.
• Prepositional phrases:
The object of the preposition is truncated in a recursive operation.
• Numeric values:
The phrase ‘a lot’ is used instead.
Matrix verbs are expanded to include both the simple past tense and the third person singular present form with the aid of WordNet and some generic patterns. Where
applicable, particles such as out and up also remain attached to the verb.
Generally speaking, truncation and expansion are good ways of boosting the patterns’
coverage. However, the current procedures of truncation are still crude, especially in
their handling of complex phrases. For example, the phrase ‘a reckless course of action’
([0198:011]) yields ‘$PRPS$ course’, which results in a total loss of the original semantics.
Further enhancements of the truncation process may improve the performance but the
improvement will likely be limited due to the endless possibilities of language usage and
constraints imposed by search engines.
Aside from truncating and expanding the original texts, a stepped-down version of
Pattern II, denoted Pattern II0 , is also provided to further enhance the system’s coverage.
The current scheme is to simply replace the extraposed clause with a new stub – to – if the
original extraposed clause is an infinitive, a for . . . infinitive, or a gerund construct. For
example,
[0089:017] It
( is easy to see why the
) ancient art is on the ropes. ⇒
it
is easy to
which/who/this/he
In other situations, no downgraded version is applied.
3.5 Binary Classification of It-extraposition
Five factors are taken into consideration when determining whether the sentence in question
is an it-extraposition:
Estimated popularity of the what-cleft construct (query Pattern I)
denoted as
W = nw × vw
359

Li, Musilek, Reformat, & Wyard-Scott

where nw is the number of results reported by the search engine, and vw is the
percentage of valid instances within the first batch of snippets (usually 10, depending
on the search engine service) returned with the query. Validation is performed with
a case-sensitive regular expression derived from the original query. Since the whatcleft pattern is capitalized at the beginning, the regular expression only looks for
instances appearing at the beginning of a sentence. It is particularly important to
validate the results of what-cleft queries because some search engines can produce
results based on their own interpretation of the original query. For example, Google
returns pages containing “What’s found is that” for the query “What found is that”,
which might be helpful for some but is counterproductive for the purpose of this
study.
Result of the comparative expletiveness test (query Pattern II)
denoted as
nX
r=
nit
where nit is the number of results obtained from the original it version of the query,
and nX is the total number of results produced by replacing it with other pronouns
such as which and who. The smaller the ratio r is, the more likely that the sentence
being investigated is an extraposition. Extrapositional sentences usually produce
an r value of 0.1 or less. When both versions of the query yield insufficient results
(max(nit , nX ) < Nmin ), r takes the value Rscarce = 1000. Since it-extrapositions
are relatively rare, it is better to assume that a sentence is not extrapositional when
there is insufficient data to judge otherwise. In the case where nX is sufficient but the
it version of the query produces no result (nX >= Nmin AND nit = 0), r takes the
value Rzero = 100. Values of Rzero and Rscarce are large numbers chosen arbitrarily,
mainly for visualization purposes. In other words both Rzero and Rscarce hint that
the sentence is probably not extrapositional, however neither indicates the degree of
likelihood.
Result of the stepped-down
comparative expletiveness test
n0
0
0
denoted as r0 = nX
0 , where nit and nX are the number of results returned from the
it
it version and the alternate version of the stepped-down queries (c.f. Section 3.4.4,
Page 359). The stepped-down queries are ‘simplified’ versions of the queries used to
calculate r. Due to this simplification, r0 is usually more sensitive to extrapositions.
However not all queries have stepped-down versions, in which case the original queries
are reused, causing r0 = r. Similar to the way r is defined, r0 also takes the values
Rscarce and Rzero in special situations.
Synthesized expletiveness
A new variable R is defined based on the values of r, nit , nX , and r0 :
(

R=

r, if max(nit , nX ) ≥ Nmin ,
r0 , if max(nit , nX ) < Nmin .

If the original queries yield enough results, R takes the value of r since the original
queries better preserve sentence context and are generally more accurate. However,
360

Identification of Pleonastic It Using the Web

when original queries fail, the system resorts to the back-up method of using the
stepped-down queries and bases its judgement on their results instead. Overall, R
can be seen as a synthesized indicator of how the subject pronoun is generally used
in a similar syntactic and semantic setting to that of the original sentence.
Syntactic structure of the sentence
denoted as S, a binary variable indicating if the sentence under investigation belongs
to a syntactic construct that is more prone to generating false-positives. On average
the what-cleft queries yield fewer results and are less reliable since they cannot be
used to provide comparative ratios. However, they are still useful as the last line of
defence to curb the impacts of certain syntactic constructs that repeatedly cause the
comparative expletive tests to produce false-positives. Currently only one construct
is identified – the it verb infinitive construct, as in ‘it helps to have input from
everyone’ and ‘it expects to post the results tomorrow ’. Therefore,
(

S=

TRUE, if sentence matches it verb infinitive,
FALSE, otherwise.

The final binary classification of it-extraposition, E, is defined as follows:
(

E=

((R < Rexp ) AND (W > Nmin )), if S = TRUE,
(R < Rexp ),
if S = FALSE.

(10)

where Nmin and Rexp , set to 10 and 0.15 respectively in this study, are threshold constants
chosen based upon empirical observations. In other words, the system recognizes an instance of it as extrapositional if it is unlikely (by comparing R to Rexp ) that an alternative
pronoun is used in its place under the same syntactic and semantic settings. For it verb
infinitive constructs, it is also required that the sentence has a viable what-cleft variant
(by comparing W to Nmin ).
It is worth noting that today’s major commercial search engines do not return the exact
number of results for a query but rather their own estimates. The negative effect of this is
somewhat mitigated by basing the final decision on ratios instead of absolute numbers.

4. Case Study
To better illustrate the system work flow, two sample sentences are selected from the WSJ
corpus to be taken through the whole process. The first sample, [0231:015], is classified as
an it-extraposition; the other, [0331:033] (with the preceding sentence providing context),
is a referential case with a nominal antecedent. Some particulars of the implementation are
also discussed here.
[0231:015] A fund manager at a life-insurance company said three factors make
it difficult to read market direction.
[0331:032-033] Her recent report classifies the stock as a “hold.” But it appears
to be the sort of hold one makes while heading for the door.
361

Li, Musilek, Reformat, & Wyard-Scott

4.1 Syntactic Filtering
First, the syntactic structures of each sentence are identified and dependencies among the
constituents are established, as shown in Figures 3 and 4.

Figure 3: Syntactic structure of [0231:015] (fragment)

Figure 4: Syntactic structure of [0331:033] (fragment). Readings A and B, as indicated in
the DG parse tree, are discussed in the text.

362

Identification of Pleonastic It Using the Web

In sample sentence [0231:015], the expletive it appears as the object of the verb makes and
is followed by the object complement difficult, therefore a virtual copula (tagged VBX) is
created in the dependency tree in order to treat it under the same framework as subject
it-extrapositions. For [0331:033], two different readings are produced – one by assuming
appears to be the matrix verb (reading A, c.f. Figure 4), the other by taking be (reading
B). This is accomplished by ‘drilling’ down the chain of verbs beginning with the parent
verb of the it node. Once at the top of the chain, the system starts a recursive process to
find verbs and infinitives that are directly attached to the current node and moves down to
the newly found node. The process is interrupted if the current verb node is furnished with
elements other than verbal or adverbial complements/modifiers.
During the filtering process, various components of the sentences are identified, as listed
in Table 2.

Sentence
0231:015
0331:033
0331:033

Reading
A
B

Matrix
Verb
Object
be
difficult
appears
be
sort

Conjunction

THAT

Subordinate
Subject Verb
Object
to read direction
to be
sort
One

Table 2: Component breakdown of the case study samples

4.2 Pattern Instantiation
Using the components identified in Table 2, five queries are generated for each reading,
as listed in Tables 3-5. Patterns II0 -it and II0 -others refer to the stepped-down versions
(c.f. Section 3.4.4, Page 359) of II-it and II-others respectively. The queries shown here are
generated specifically for Google and take advantage of features only available in Google. To
use an alternative search engine such as Yahoo, the component expansions and determiner
lists have to be turned off, and separate queries need to be prepared for individual pronouns.
In order to get accurate results, the queries must be enclosed in double quotes before they
are sent to search engines.

Pattern
I
II-it
II-others
II0 -it
II0 -others

Query
what is|was|’s difficult is|was to
it is|was|’s difficult to read the|a|an|no|this|these|their|his|our
which|this|who|he is|was|’s difficult to read the|a|an|no|this|these|
their|his|our
it is|was|’s difficult to
which|this|who|he is|was|’s difficult to
Table 3: Queries for [0231:015]
363

Results
1060
3960
153
6.3 × 106
1.5 × 105

Li, Musilek, Reformat, & Wyard-Scott

Pattern
I
II-it
II-others
II0 -it
II0 -others

Query
what appears|appeared is|was to
it appears|appeared to be the|a|an|no|this|these|their|his|our
which|this|who|he appears|appeared to be the|a|an|no|this|these|
their|his|our
it appears|appeared to
which|this|who|he appears|appeared to

Results
44
7.5 × 104
3.2 × 105
2.2 × 106
2.6 × 106

Table 4: Queries for [0331:033], Reading A

Pattern
I
II-it
II-others
II0 -it
II0 -others

Query
what is|was|’s its|my|our|his|her|their|your sort is|was that
it is|was|’s its|my|our|his|her|their|your sort that the|a|an|no|
this|these|they|we|he|their|his|our
which|this|who|he is|was|’s its|my|our|his|her|their|your sort that
the|a|an|no|this|these|they|we|he|their|his|our
Same as II-it
Same as II-others

Results
0
0
0
0
0

Table 5: Queries for [0331:033], Reading B
4.3 Query Results and Classification
For every reading, the number of results for each of the five queries (nw for Pattern I;
nit for II-it; nX for II-others; n0it for II0 -it; and n0X for II0 -others) is obtained from the
search engine; the first 10 results for the what-cleft query are also validated to obtain the
estimated percentage (vw ) of valid constructs. W (= nw × vw ), r(= nX /nit ), r0 (= n0X /n0it ),
and R (choosing between either r or r0 depending on whether max(nit , nX ) ≥ 10) are then
calculated accordingly, as recorded in Table 6.
Query
[0231:015]
[0331:033].A
[0331:033].B

nw
1060
44
0

vw
70%
0%
-

nit
3960
7.5E4
0

nX
153
3.2E5
0

n0it
6.3E6
2.2E6
0

n0X
1.5E5
2.6E6
0

W
742
0
0

r
0.04
4.3
1000

r0
0.02
1.2
1000

R
0.04
4.3
1000

Table 6: Query results for the case study sample sentences
What appears suspicious is that vw is set to 0 for reading [0331:033].A, which means no
valid instances are found. A quick look at the returned snippets reveals that, indeed, none
of the 10 snippets has the queried contents at the beginning of sentence. Also note that for
reading [0331:033].B, both r and r0 , and consequently R have all been set to Rscarce = 1000
since no query produced enough results.
It can be decided from Table 2 that readings [0231:015] and [0331:033].B do not bear
the it verb infinitive construct, hence S = FALSE; and for [0331:033].A S = TRUE.
Applying Equation 10 in Section 3.5, for [0231:015] and [0331:033].B, the final classification
364

Identification of Pleonastic It Using the Web

E is only based on whether R is sufficiently small (R < 0.15). For [0331:033].A, the system
also needs to check whether the what-cleft query returned sufficient valid results (W > 10).
The final classifications are listed in Table 7.
Sentence
[0231:015]
[0331:033]
[0331:033]

Reading
A
B

W
742
0
0

S
FALSE
TRUE
FALSE

R
0.04
4.3
1000

Ereading
YES
NO
NO

E
YES
NO

Table 7: Final binary classification of the case study sample sentences
Since neither readings of [0331:033] are classified as such, the sentence is not an it-extraposition
construct.

5. Evaluation
In order to provide a comprehensive picture of the system’s performance, a twofold assessment is used. In the first evaluation, the system is exposed to the same sentence collection
that assisted its development. Accordingly, results obtained from this evaluation reflect,
to a certain degree, the system’s optimal performance. The second evaluation aims at revealing the system’s performance on unfamiliar texts by running the developed system on
a random dataset drawn from the rest of the corpus. Two additional experiments are also
conducted to provide an estimation of the system’s performance over the whole corpus.
Three performance measures are used throughout the section: precision, recall, and the
balanced F-measure (van Rijsbergen, 1979). Precision is defined as the ratio of correctly
classified instances in a specific category (or a collection of categories) to the number of
instances identified by the system as belonging to the category (categories). In other words,
P
precision is calculated as P = T PT+F
P , where T P and F P are the number of true positives
and false positives respectively. Recall is defined as the ratio of correctly classified instances
in a specific category (or a collection of categories) to the total number of instances in the
P
category (categories), or R = T PT+F
N , where F N denotes the number of false negatives.
Finally, the F-measure is the weighted harmonic mean of precision and recall used to indicate
a system’s overall performance. When precision and recall are weighted equally, as used in
R
this study, the balanced F-measure is defined as F = P2P+R
.
Following Efron and Tibshirani’s (1993) Bootstrap method, 95% confidence intervals
are obtained using the 2.5th and 97.5th percentiles of the bootstrap replicates and are
provided alongside the system performance figures to indicate their reliability. The number
of replicates is arbitrarily set at B = 9999, which is much greater than the commonly
suggested value of 1000 (e.g., see Davison & Hinkley, 1997; Efron & Tibshirani, 1993)
because pleonastic instances are sparse. In the case that a precision or recall value is 100%,
the bootstrap percentile method reports an interval of 100%-100%, which makes little sense.
Therefore, in this situation the adjusted Wald interval (Agresti & Coull, 1998) is presented
instead. When two systems are compared, an approximate randomization test (Noreen,
1989) similar to that used by Chinchor (1992) is performed to determine if the difference is
of statistical significance. The significance level α = 0.05 and number of shuffles R = 9999,
both chosen arbitrarily, are used where significance tests are performed.
365

Li, Musilek, Reformat, & Wyard-Scott

5.1 Development Dataset
For the purpose of this study, the first 1000 occurrences of it from the WSJ corpus have been
manually annotated by the authors20 . A part of the set has also been inspected in order
to determine the values of the constants specified in Section 3.5, and to develop the surface
structure processor. The annotation process is facilitated by a custom-designed utility that
displays each sentence within its context represented by a nine-sentence window containing
the six immediately preceding sentences, the original, and the two sentences that follow.
Post-annotation review indicates that this presentation of corpus sentences worked well.
Except for a few (less than 0.5%) cases, the authors found no need to resort to broader
contexts to understand a sentence; and under no circumstances were valid antecedents
located outside the context window while no antecedent was found within it.
Category
Nominal Antecedent
Clause Antecedent
Extraposition
Cleft
Weather/Time
Idiom
Other
Grand Total

Instances
756
60
118
13
9
18
26
1000

Percentage
75.60%
6.00%
11.80%
1.30%
0.90%
1.80%
2.60%
100.00%

Table 8: Profile of the development dataset according to the authors’ annotation
Table 8 summarizes the distribution of instances in the dataset according to the authors’
consensus. The category labeled ‘Other’ consists mostly of instances that do not fit well
into any other categories, e.g. when the identified nominal antecedent is in plural or the
antecedent is inferred, as well as certain confusing instances. Out of the twenty-six instances,
only two might be remotely recognized as one of the types that interests this study:
[0101:007] And though the size of the loan guarantees approved yesterday is significant, recent experience with a similar program in Central America
indicates that it could take several years before the new Polish government can fully use the aid effectively.
[0296:048] It’s just comic when they try to pretend they’re still the master race.
Neither instance can be identified as anaphoric. However, the first construct has neither a
valid non-extraposition version nor a valid what-cleft version, making it difficult to justify
as an extraposition, while the it in the second case is considered to refer to the atmosphere
aroused by the action detailed in the when-clause.
In order to assess whether the pleonastic categories are well-defined and the ability of
ordinary language users to identify pleonastic instances, two volunteers, both native English
speakers, are invited to classify the it instances in the development dataset. To help them
concentrate on the pleonastic categories, the volunteers are only required to assign each
instance to one of the following categories: referential, extraposition, cleft, weather/time,
20

Annotations are published as an online appendix at http://www.ece.ualberta.ca/~musilek/pleo.

zip.

366

Identification of Pleonastic It Using the Web

and idiom. The referential category covers instances with both nominal antecedents and
clause antecedents, as well as instances with inferrable antecedents. Table 9 outlines both
annotators’ performance in reference to the authors’ consensus. The degree of agreement
between the annotators, measured by the kappa coefficient (κ; Cohen, 1960), is also given
in the same table.
Category

Precision

Referential
99.38%
Extraposition
82.54%
Cleft
38.46%
Weather/Time 66.67%
Idiom
39.39%
Overall Accuracy/κ

Volunteer 1
Recall F-measure

95.49%
88.14%
76.92%
44.44%
72.22%
93.50%

97.40%
85.25%
51.28%
53.33%
50.98%

Precision

96.38%
88.68%
72.73%
75.00%
50.00%

Volunteer 2
Recall F-measure

98.10%
79.66%
61.54%
33.33%
61.11%
94.20%

97.23%
83.93%
66.67%
46.15%
55.00%

κa
.749
.795
.369
-.005
.458
.702

a

Except for the Weather/Time category (p = 0.5619), all κ values are statistically significant at p <
0.0001.

Table 9: Performance of the volunteer annotators on the development dataset (evaluated
using the authors’ annotation as reference) and the degree of inter-annotator agreement measured by Cohen’s kappa (κ). The authors’ annotations are refitted to
the simplified annotation scheme used by the volunteers.
There are many factors contributing to the apparently low κ values in Table 9, most
notably the skewed distribution of the categories and inappropriate communication of the
classification rules. As Di Eugenio and Glass (2004) and others pointed out, skewed distribution of the categories has a negative effect on the κ value. Since the distribution of
the it instances in the dataset is fairly unbalanced, the commonly-accepted guideline for
interpreting κ values (κ > 0.67 and κ > 0.8 as thresholds for tentative and definite conclusions respectively; Krippendorff, 1980) may not be directly applicable in this case. In
addition, the classification rules are communicated to the annotators orally through examples and some of the not-so-common cases, such as the object it-extrapositions, might not
have been well understood by both annotators. Another interesting note about the results
is that there is a strong tendency for both annotators (albeit on different cases) to classify
it-clefts as it-extrapositions. Rather than taking this as a sign that the cleft category is not
well-defined, we believe it reflects the inherent difficulties in identifying instances pertaining
to the category.
5.2 Baselines
Two baselines are available for comparison – the WSJ annotation, which is done manually
and provided with the corpus; and the results from a replication of Paice and Husk’s (1987)
algorithm (PHA). It should be cautioned that, given the subjectivity of the issues discussed
in this paper and lack of consensus on certain topics in the field of linguistics, recall ratios of
the presented baseline results and the forthcoming results of the proposed system should not
be compared quantitatively. For example, the original Paice and Husk algorithm does not
recognize certain types of object extrapositions and does not always distinguish between
367

Li, Musilek, Reformat, & Wyard-Scott

individual types of pleonastic it; and the WSJ corpus has neither special annotation for
parenthetical it (c.f. Section 3.2.1, Page 348, [0239:009]) nor an established annotation
policy for certain types of object extrapositions (Bies, Ferguson, Katz, & MacIntyre, 1995).
No attempts have been made to correct these issues.
Table 10 summarizes the performance of the baselines on the development dataset. As
expected, Paice and Husk’s (1987) algorithm does not perform very well since the WSJ
articles are very different from, and tend to be more sophisticated than, the technical
essays that the algorithm was designed for. Compared to the originally reported precision
of 93% and recall of 96%, the replicated PHA yields only 54% and 75% respectively on the
development dataset. The performance of the replica is largely in line with what Boyd et al.
(2005) obtained from their implementation of the same algorithm on a different dataset.

Measurement
Reference
Identified by Baseline
Baseline True Positives
Precision
Recall
F-measure

WSJ Annotation
Extraposition
Cleft
118
13
88
12
87b
12
98.86%
100%
73.73% 92.31%
84.47% 96.00%

Replicated PHA
Overalla
140
194
105
54.12%
75.00%
62.87%

a

Includes clefts, extrapositions, and time/weather cases.
Based on manual inspection, two cases originally annotated as extrapositional in WSJ are
determined as inappropriate. See discussions below.
b

Table 10: Performance of the baselines on the development dataset, evaluated against the
authors’ annotation.
The 31 (118 − 87) extrapositional cases that are not annotated in WSJ can be broken
down into the following categories followed by their respective number of instances:
Category
Unrecognized
Object without complement
Parenthetical
Inappropriate non-extraposition
Agentless passive
it seems/appears . . .
it be worth . . .
Others
Valid non-extraposition
too . . . to
Others
Total

Items
3
1
2
18
9
4
2
3
10
2
8
31

Table 11: Profile of the false negatives in the WSJ annotation in reference to the authors’
annotation
368

Identification of Pleonastic It Using the Web

By stating that the ‘Characteristic of it extraposition is that the final clause can replace
it’, Bies et al. (1995) define the class in the narrowest sense. Since interpretation of the
definition is entirely a subjective matter, there is no way of determining the real coverage
of the annotations. However, from the portions of the corpus that have been reviewed, the
practice of annotation is not entirely consistent.
Two sentences are marked as extraposition in the corpus but the annotators’ consensus
indicates otherwise. Considering the ‘golden standard’ status of the WSJ corpus, they are
also listed here:
[0277:040] Moreover, as a member of the Mitsubishi group, which is headed by
one of Japan’s largest banks, it is sure to win a favorable loan.
[0303:006] It is compromises such as this that convince Washington’s liberals
that if they simply stay the course, this administration will stray
from its own course on this and other issues.
The first sentence is considered dubious and most likely referring to the company that is a
member of the Mitsubishi group. The second one is considered a cleft and is actually also
marked as cleft in the corpus. Since it is the only case in the corpus with both annotations,
the extraposition marking was considered a mistake and was manually removed.
The Paice and Husk (1987) algorithm suffers from false-positive it . . . that and it . . . to
construct detection, which may be fixed by incorporating part-of-speech and phrase structure information together with additional rules. However, such fixes will greatly complicate
the original system.
5.3 Results
On the development dataset, results produced by the proposed system are as follows:
Extraposition
118
116
113

Cleft
13
13
13

Weather/Time
9
10
9

Overalla
140
139
136

Precision
95% C.I.b

97.41%
94.07-100.00%

100.00%
79.74-100.00%

90.00%
66.67-100.00%

97.84%
95.21-100.00%

Recall
95% C.I.b

95.76%
91.79-99.12%

100.00%
79.74-100.00%

100.00%
73.07-100.00%

97.14%
93.98-99.34%

F-measure
95% C.I.

96.58%
93.98-98.72%

100.00%
-

94.74%
80.00-100.00%

97.49%
95.45-99.21%

Measurement
Reference
Identified
True Positives

a
b

Combining extraposition, cleft, and weather/time into one category.
Adjusted Wald intervals are reported for extreme measurements.

Table 12: Performance of the system on the development dataset, evaluated using the authors’ annotation as reference.

369

Li, Musilek, Reformat, & Wyard-Scott

Further statistical significance tests reveal more information regarding the system’s performance in comparison to that of the two volunteers and the baselines:
• Compared to both volunteer annotators, the system’s better performance in all three
pleonastic categories is statistically significant.
• In the extraposition category, the difference between the WSJ annotation’s (higher)
precision and that of the system is not statistically significant.
• Compared to Paice and Husk’s (1987) algorithm, the system’s higher precision is
statistically significant.

Target System
Volunteer 1
Volunteer 2
WSJ Annotation
Replicated PHA

Extraposition

Cleft

Weather/Time

F-measure+ /p < .001 F-measure+ /p < .001 F-measure+ /p = .033
F-measure+ /p < .001 F-measure+ /p = .007 F-measure+ /p = .025
Precision− /p = .630 F-measure+ /p = 1.00
(All Categories) Precision+ /p < .001

Table 13: Results of the statistical significance tests presented in the format
Test Statisticsign /p-value. A plus sign (+ ) indicates that our system performs
better on the reported measurement; otherwise a minus sign (− ) is used. If fair
comparisons can be made for both precision and recall, the F-measure is used as
the test statistic; otherwise the applicable measurement is reported.

Using the authors’ annotation as reference, the system outperforms both human volunteers. While higher performance is usually desirable, in this particular case, it could
indicate possible problems in the design of the experiment. Since the English language is
not only used by its speakers but also shaped by the same group of people, it is impractical to have a system that ‘speaks better English’ than its human counterparts do. One
plausible clue to the paradox is that an analytic approach is needed to gain insight into
the issue of pronoun classification, but the casual English speakers do not see it from that
perspective. As Green and Hecht (1992) and many others indicated, capable users of a
language do not necessarily have the ability to formulate linguistic rules. However, these
kinds of analytic skills is a prerequisite in order to explicitly classify a pronoun into one of
the many categories. Thus, the true performance of casual speakers can only be measured
by their ability to comprehend or produce the various pleonastic constructs. In addition,
other factors, such as time constraints and imperfections in how the category definitions
are conveyed, may also play a role in limiting the volunteers’ performance. The authors’
annotation, on the other hand, is much less influenced by such issues and is therefore considered expert opinion in this experiment. As shown in Section 5.2, the WSJ annotation of
extrapositions and clefts, which is also considered expert opinion, is highly compatible with
that of the authors. The differences between the two annotations can mostly be attributed
to the narrower definition of extraposition adopted by the WSJ annotators. Therefore, the
WSJ annotation’s precision of 98.86% for extrapositions (when verified against the authors’
370

Identification of Pleonastic It Using the Web

annotation) is probably a more appropriate hint of the upper-limit for practically important
system performance.
In the extraposition category, 279 individual cases passed the syntactic filters and were
evaluated by search engine queries. Results of queries are obtained from Google through its
web service, the Google SOAP21 Search API. All three (116 − 113) cases of false-positives
are caused by missing-object constructions and can be corrected using the patterns detailed
in Section 3.4.3.
The five (118 − 113) false-negative cases are listed below:
[0283:013] The newspaper said it is past time for the Soviet Union to create
unemployment insurance and retraining programs like those of the
West.
[0209:040] “It’s one thing to say you can sterilize, and another to then successfully pollinate the plant,” he said.
[0198:011] Sen. Kennedy said . . . but that it would be a “reckless course of
action” for President Bush to claim the authority without congressional approval.
[0290:049] Worse, it remained to a well-meaning but naive president of the
United States to administer the final infamy upon those who fought
and died in Vietnam.
[0085:047] “It’s not easy to roll out something that comprehensive, and make
it pay,” Mr. Jacob says.
Sentence [0283:013] is misplaced as weather/time. Sentence [0209:040] is not properly handled by the syntactic processing subcomponent. Sentences [0198:011] and [0290:049] involve
complex noun phrases (underlined) at the object position of the matrix verbs – it is very
difficult to reduce them to something more generic, such as the head noun only or a pronoun, and still remain confident that the original semantics are maintained. The last case,
sentence [0085:047], fails because the full queries (containing part of the subordinate clause)
failed to yield enough results and the stepped-down versions are overwhelmed by noise.
The last four false-negatives are annotated correctly in the WSJ corpus. The system’s
recall ratio on the 87 verified WSJ extraposition annotations is therefore 95.40%, comparable
to the overall recall.
5.4 System Performance on Parser Output
Thus far, the system has been evaluated based on the assumption that the underlying
sentences are tagged and parsed with (almost) perfect accuracy. Much effort has been
made to reduce such dependency. For example, tracing information and function tags in the
original phrase structures are deliberately discarded; and the system also tries to search for
possible extraposed or cleft clauses that are marked as complements to the matrix object.
However, deficiencies in tagging and parsing may still impact the system’s performance.
Occasionally, even the ‘golden standard’ manual markups appear problematic and happen
to get in the way of the task.
21

The Simple Object Access Protocol is an XML-based message protocol for web services.

371

Li, Musilek, Reformat, & Wyard-Scott

It is therefore necessary to evaluate the system on sentences that are automatically
tagged and parsed in order to answer the question of how well it would perform in the
real world. Two state-of-the-art parsers are employed for this study: the reranking parser
by Charniak and Johnson (2005), and the Berkeley parser by Petrov, Barrett, Thibaux,
and Klein (2006). The system’s performance on their respective interpretations of the
development dataset sentences are reported in Tables 14 and 15. Table 16 further compares
the system’s real-world performance to the various baselines.
Measurement
Reference
Identified
True Positives
Precision
95% C.I.b
Recall
95% C.I.b
F-measure
95% C.I.
a
b

Extraposition
118
114
110
96.49%
92.68-99.20%
93.22%
88.43-97.41%
94.83%
91.60-97.49%

Cleft
13
12
12
100.00%
78.40-100.00%
92.31%
73.33-100.00%
96.00%
84.62-100.00%

Weather/Time
9
10
9
90.00%
66.67-100.00%
100.00%
73.07-100.00%
94.74%
80.00-100.00%

Overalla
140
136
132
97.06%
93.92-99.32%
94.29%
90.18-97.81%
95.65%
93.08-97.90%

Combining extraposition, cleft, and weather/time into one category.
Adjusted Wald intervals are reported for extreme measurements.

Table 14: Performance of the system on the development dataset parsed by the Charniak
parser, using the authors’ annotation as reference.

Extraposition
118
114
111

Cleft
13
11
10

Weather/Time
9
9
8

Overalla
140
134
130

Precision
95% C.I.

97.37%
94.07-100.00%

90.91%
70.00-100.00%

88.89%
62.50-100.00%

97.01%
93.81-99.32%

Recall
95% C.I.

94.07%
89.47-98.18%

76.92%
50.00-100.00%

88.89%
62.50-100.00%

92.86%
88.44-96.91%

F-measure
95% C.I.

95.69%
92.75-98.17%

83.33%
62.50-96.55%

88.89%
66.67-100.00%

94.89%
92.02-97.35%

Measurement
Reference
Identified
True Positives

a

Combining extraposition, cleft, and weather/time into one category.

Table 15: Performance of the system on the development dataset parsed by the Berkeley
parser, using the authors’ annotation as reference.

372

Identification of Pleonastic It Using the Web

Comparing System Performance On Charniak Parser Output to:
Target System
Extraposition
Cleft
Weather/Time
−
−
System w/o Parser F-measure /p = .131 F-measure /p = 1.00 F-measure= /p = 1.00
Volunteer 1
F-measure+ /p = .001 F-measure+ /p < .001 F-measure+ /p = .030
Volunteer 2
F-measure+ /p < .001 F-measure+ /p = .041 F-measure+ /p = .021
WSJ Annotation
Precision− /p = .368 F-measure= /p = 1.00
Replicated PHA
(All Categories) Precision+ /p < .001
Comparing System Performance On Berkeley Parser Output to:
Target System
Extraposition
Cleft
Weather/Time
−
−
System w/o Parser F-measure /p = .380 F-measure /p = .128 F-measure− /p = 1.00
Volunteer 1
F-measure+ /p < .001 F-measure+ /p = .014 F-measure+ /p = .061
Volunteer 2
F-measure+ /p < .001 F-measure+ /p = .314 F-measure+ /p = .046
WSJ Annotation
Precision− /p = .627 F-measure− /p = .374
Replicated PHA
(All Categories) Precision+ /p < .001
Table 16: Results of the statistical significance tests comparing the system’s performance
on parser output to that of various other systems, presented in the format
Test Statisticsign /p-value. A plus sign (+ ) indicates that the proposed system
performs better than the target system on the reported measurement; an equal
sign (= ) indicates a tie; otherwise a minus sign (− ) is used. If fair comparisons
can be made for both precision and recall, the F-measure is used as the test
statistic; otherwise the applicable measurement is reported.

Further significance tests reveal that:
• using a parser has no statistically significant influence on the system’s performance;
• the system outperforms both volunteer annotators in identifying it-extrapositions;
• regardless of the parser used, the difference between the system’s performance and
that of the WSJ annotation is not statistically significant; and
• regardless of the parser used, the system outperforms the Paice and Husk (1987)
algorithm.
5.5 Correlation Analysis for Extrapositions
Figures 5 through 8 illustrate the correlation between the decision factors and the true
expletiveness of the pronoun it in question. All 279 items that passed the initial syntactic
filtering process are included in the dataset with the first 116 being extrapositional and
the rest separated by a break on the X-axis. This arrangement is made in order to better
visualize the contrast between the positive group and the negative group. In Figures 6
through 8, different grey levels are used to indicate the number of results returned by
queries – the darker the shade, the more popular the construct in question is on the web.
The constant Rexp = 0.15 is also indicated with a break on the Y-axis.
373

Li, Musilek, Reformat, & Wyard-Scott

As illustrated, all factors identified in Section 3.5 are good indicators of expletiveness. W
(Figure 5) is the weakest of the four factors due to the number of false positives produced by
incorrect language usage. This is clear evidence that the web is noisier than ordinary corpora
and that the results counts from the web may not be appropriate as the sole decision-making
factor. In comparison, r (Figure 6) has almost perfect correlation with the expletiveness
of instances. However, full versions of the queries usually return fewer results and in many
cases yield too few results for expletive cases (unfilled items plotted on top of the graph
indicate cases that do not have enough results, c.f. Section 3.5). The stepped-down versions
of the queries (Figure 7), while being less accurate by themselves, serve well when used as
‘back up’, as illustrated by the R plot (Figure 8). Part of the false-positive outliers on the
R plot are produced by full queries for expressions that are habitually associated with it,
such as [0135:002] ‘ . . . said it expects to post sales in the current fiscal year . . . ’. When
used with a pronoun, these expressions usually describe information quoted from a person
or organization already named earlier in the same sentence, making it a more natural
choice of subject pronoun. Normally the problematic expressions take the form of verb
infinitive-complement, i.e. S=TRUE. According to the decision process described in
Section 3.5, W is also considered in this situation, which effectively eliminates such noise.

374

Identification of Pleonastic It Using the Web

Figure 5: A scatter plot illustrating the correlation between W (the estimated number of
valid results returned by the what-cleft queries) and the expletiveness of the it
instance. The extrapositional instances are arranged on the left side of the plot
and the rest of the cases are on the right. If a query returns no valid results, the
corresponding item is shown as a hollow circle on the bottom of the plot.

375

Li, Musilek, Reformat, & Wyard-Scott

Number
of
Results

Figure 6: A scatter plot illustrating the correlation between r (the ratio of the hit count
produced by the expression with substitute pronouns to that of the original expression) and the expletiveness of the it instance. The extrapositional instances
are arranged on the left side of the plot and the rest of the cases are to the right.
The items are shaded according to the hit counts produced by the corresponding
original expressions. If a query returns insufficient results, the corresponding item
is shown as a hollow unshaded circle on the top of the plot.

376

Identification of Pleonastic It Using the Web

Number
of
Results

Figure 7: A scatter plot illustrating the correlation between r0 (similar to r but for the
stepped-down queries) and the expletiveness of the it instance. The extrapositional instances are arranged on the left side of the plot and the rest of the cases
are to the right. The items are shaded according to the hit counts produced by
the corresponding original expressions. If a query returns insufficient results, the
corresponding item is shown as a hollow unshaded circle on the top of the plot.

377

Li, Musilek, Reformat, & Wyard-Scott

Number
of
Results

Figure 8: A scatter plot illustrating the correlation between R (synthesized expletiveness;
it takes the value of r if the more complex queries produce enough results, and
takes the value of r0 when they fail to do so) and the expletiveness of the it
instance. The extrapositional instances are arranged on the left side of the plot
and the rest of the cases are to the right. The items are shaded according to the
hit counts produced by the corresponding original expressions. If a query returns
insufficient results, the corresponding item is shown as a hollow unshaded circle
on the top of the plot.

5.6 Generalization Study
In order to evaluate how well the system generalizes, 500 additional sample sentences are
randomly selected from the rest of the WSJ corpus as the test dataset. The distribution of
instances is comparable to that of the development dataset, as shown in Table 17.
378

Identification of Pleonastic It Using the Web

Category
Nominal Antecedent
Clause Antecedent
Extraposition
Cleft
Weather/Time
Idiom
Other
Grand Total

Instances
375
24
63
8
6
11
13
500

Percentage
75.00%
4.80%
12.60%
1.60%
1.20%
2.20%
2.60%
100.00%

Table 17: Profile of the test dataset according to the authors’ annotation
As shown in Table 18, the overall level of inter-annotator agreement is slightly higher
than that of the development dataset. Except for the idiom category, categorical κ values
are also higher than their counterparts on the development dataset. This discrepancy is
most likely due to chance, since the two volunteers worked independently and started from
different datasets (Volunteer 1 started from the development dataset and Volunteer 2 started
from the test dataset).
Category

Precision

Referential
98.48%
Extraposition
87.10%
Cleft
29.41%
Weather/Time 100.00%
Idiom
31.82%
Overall Accuracy/κ
a

Volunteer 1
Recall F-measure

95.12%
85.71%
62.50%
50.00%
53.85%
91.80%

96.77%
86.40%
40.00%
66.67%
40.00%

Precision

97.30%
80.00%
57.14%
100.00%
47.06%

Volunteer 2
Recall F-measure

96.83%
82.54%
50.00%
50.00%
61.54%
92.80%

97.07%
81.25%
53.33%
66.67%
53.33%

κa
.797
.811
.490
.665
.280
.720

All κ values are statistically significant at p < 0.0001.

Table 18: Performance of the volunteer annotators on the test dataset (evaluated using the
authors’ annotation as reference) and the degree of inter-annotator agreement
measured by Cohen’s kappa (κ). The authors’ annotations are refitted to the
simplified annotation scheme used by the volunteers.

Measurement
Reference
Identified by Baseline
Baseline True Positives
Precision
Recall
F-measure
a

WSJ Annotation
Extraposition
Cleft
63
8
54
6
52
6
96.30% 100.00%
82.54%
75.00%
88.89%
85.71%

Replicated PHA
Overalla
77
97
55
56.70%
71.43%
63.22%

Includes clefts, extrapositions, and time/weather cases.

Table 19: Performance of the baselines on the test dataset, evaluated against the authors’
annotation.
379

Li, Musilek, Reformat, & Wyard-Scott

Table 19 summarizes the performance of the baselines on the test dataset. The two
(54 − 52) false-positive extrapositions from the WSJ annotation are listed below together
with their respective context:
[1450:054-055] Another solution cities might consider is giving special priority
to police patrols of small-business areas. For cities losing business to
suburban shopping centers, it may be a wise business investment to
help keep those jobs and sales taxes within city limits.
[1996:061-062] You think you can go out and turn things around. It’s a tough
thing when you can’t.
The first case is considered referential, and the it in the second case is believed to refer to
a hypothetical situation introduced by the when-clause.
5.6.1 Performance Analysis
On the test dataset, the system is able to maintain its precision; it exhibits slight deterioration in recall but the overall performance is still within expectations. The findings are
summarized in Table 20.
Extraposition
63
60
58

Cleft
8
6
6

Weather/Time
6
7
6

Overalla
77
73
70

Precision
95% C.I.b

96.67%
91.38-100.00%

100.00%
64.26-100%

85.71%
50.00-100.00%

95.89%
90.77-100.00%

Recall
95% C.I.b

92.06%
84.85-98.25%

75.00%
40.00-100.00%

100.00%
64.26-100.00%

90.91%
84.15-97.01%

F-measure
95% C.I.

94.31%
89.60-98.11%

85.71%
57.14-100.00%

92.31%
66.67-100.00%

93.33%
88.75-97.10%

Measurement
Reference
Identified
True Positives

a
b

Combining extraposition, cleft, and weather/time into one category.
Adjusted Wald intervals are reported for extreme measurements.

Table 20: Performance of the system on the test dataset, evaluated using the authors’
annotation as reference.

149 instances were evaluated for extraposition using queries, covering 62 of the 63 extrapositions. The excluded case is introduced in the form of a direct question, whose particulars
the syntactic processing subsystem is not prepared for. Of the other four false negatives,
three involve noun phrases at the matrix object position. One of the two clefts that are not
recognized arises out of imperfect processing in the corpus. In addition, the false positive
in the weather/time category is caused by the verb ‘hail ’, which was treated as a noun by
the system.
All five (63 − 58) false-negative extraposition cases are annotated in the corpus and the
WSJ annotation agrees with the six clefts identified by the proposed system. Thus the
380

Identification of Pleonastic It Using the Web

system’s recall ratio on the verified WSJ annotations is 90.38% for extraposition and 100%
for cleft.
Target System
Volunteer 1
Volunteer 2
WSJ Annotation
Replicated PHA

Extraposition

Cleft

Weather/Time

F-measure+ /p = .041 F-measure+ /p = .005 F-measure+ /p = .248
F-measure+ /p = .002 F-measure+ /p = .119 F-measure+ /p = .254
Precision− /p = .697 F-measure= /p = 1.00
(All Categories) Precision+ /p < .001

Table 21: Results of the statistical significance tests, presented in the format
Test Statisticsign /p-value. A plus sign (+ ) indicates that our system performs
better on the reported measurement; an equal sign (= ) indicates a tie; otherwise
a minus sign (− ) is used. If fair comparisons can be made for both precision
and recall, the F-measure is used as the test statistic; otherwise the applicable
measurement is reported.

Measurement
Reference
Identified
True Positives

Performance on Charniak Parser Output
Extraposition
Cleft Weather/Time
63
8
6
58
7
7
55
6
6

Overalla
77
72
67

Precision
95% C.I.

94.83%
88.24-100.00%

85.71%
50.00-100.00%

85.71%
50.00-100.00%

93.06%
86.36-98.51%

Recall
95% C.I.b

87.30%
78.26-95.08%

75.00%
37.50-100.00%

100.00%
64.26-100.00%

87.01%
78.95-94.12%

F-measure
95% C.I.

90.91%
84.75-95.77%

80.00%
50.00-100.00%

92.31%
66.67-100.00%

89.93%
84.30-94.57%

Performance on Berkeley Parser Output
Extraposition
Cleft Weather/Time
63
8
6
58
5
7
56
5
6

Overalla
77
70
67

Measurement
Reference
Identified
True Positives
Precision
95% C.I.b

96.55%
91.11-100.00%

100.00%
59.90-100.00%

85.71%
50.00-100.00%

95.71%
90.28-100.00%

Recall
95% C.I.b

88.89%
80.60-96.23%

62.50%
25.00-100.00%

100.00%
64.26-100.00%

87.01%
79.22-93.90%

F-measure
95% C.I.

92.56%
87.14-96.97%

76.92%
40.00-100.00%

92.31%
66.67-100.00%

91.16%
85.94-95.52%

a
b

Combining extraposition, cleft, and weather/time into one category.
Adjusted Wald intervals are reported for extreme measurements.

Table 22: Performance of the system on the test dataset using parser-generated output,
evaluated using the authors’ annotation as reference.
381

Li, Musilek, Reformat, & Wyard-Scott

Results of the significance tests, summarized in Table 21, reveal the following additional
information about the system’s performance on the test dataset:
• the system’s higher performance in recognizing it-extrapositions than both volunteers
is statistically significant;
• in the extraposition category, the difference between WSJ annotation’s (higher) precision and that of the system is not statistically significant; and
• the system outperforms the Paice and Husk (1987) algorithm, and the difference is
statistically significant.
Tables 22 and 23 outline the system’s performance on the test dataset when parsers
are used. Again, both parsers cause slight deteriorations in system performance. However,
such changes are not statistically significant. With either parser used, the system is able to
perform as well as the WSJ annotations.
Comparing System Performance On Charniak Parser Output to:
Target System
Extraposition
Cleft
Weather/Time
−
−
System w/o Parser F-measure /p = .125 F-measure /p = 1.00 F-measure= /p = 1.00
Volunteer 1
F-measure+ /p = .298 F-measure+ /p = .013 F-measure+ /p = .247
Volunteer 2
F-measure+ /p = .022 F-measure+ /p = .269 F-measure+ /p = .246
WSJ Annotation
Precision− /p = .886 F-measure− /p = 1.00
Replicated PHA
(All Categories) Precision+ /p < .001
Comparing System Performance On Berkeley Parser Output to:
Target System
Extraposition
Cleft
Weather/Time
System w/o Parser F-measure− /p = .501 F-measure− /p = 1.00 F-measure= /p = 1.00
Volunteer 1
F-measure+ /p = .131 F-measure+ /p = .035 F-measure+ /p = .256
Volunteer 2
F-measure+ /p = .009 F-measure+ /p = .308
F-measure+ /p = .27
−
−
WSJ Annotation
Precision /p = .809 F-measure /p = 1.00
Replicated PHA
(All Categories) Precision+ /p < .001
Table 23: Results of the statistical significance tests comparing the system’s performance
on parser output to that of various other systems, presented in the format
Test Statisticsign /p-value. A plus sign (+ ) indicates that the source system performs better on the reported measurement; an equal sign (= ) indicates a tie;
otherwise a minus sign (− ) is used. If fair comparisons can be made for both
precision and recall, the F-measure is used as the test statistic; otherwise the
applicable measurement is reported.

5.6.2 Estimated System Performance on the Whole Corpus
The relative sparseness of clefts makes it hard to assess the real effectiveness of the proposed
approach. To compensate for this, an approximate study is conducted. First, it instances in
the whole corpus are processed automatically using the proposed approach. The identified
382

Identification of Pleonastic It Using the Web

cleft instances are then merged with those that are already annotated in the corpus to
form an evaluation dataset of 84 sentences, which is subsequently verified manually. 76
instances out of the 84 are considered to be valid cleft constructs by the authors. Respective
performances of the proposed approach and the WSJ annotation are reported in Table 24;
the differences are not statistically significant.
System
WSJ

Proposed
Approach

Total
76

Identified
66

Common
Precision
63
95.45%
95% C.I.: 89.55-100.00%

Recalla
82.94%
74.32-90.79%

F-measurea
88.73%
82.86-93.79%

76

75

70
93.33%
95% C.I.: 87.50-98.65%

92.11%
85.53-97.40%

92.72%
87.84-96.65%

a

The reported recall ratios and F-measures are for the synthetic dataset only and cannot be extended
to the whole corpus.

Table 24: Estimated system performance on it-cleft identification over the entire corpus
Three of the false positives produced by the proposed approach are actually extrapositions22 , which is expected (c.f. Footnote 12, Page 351). Thus, in a binary classification
of pleonastic it, items in the cleft category will have higher contributions to the overall
precision than they do for their own category. Until the whole corpus is annotated, it is
impossible to obtain precise recall figures of either the WSJ annotations or the proposed
approach. However, since the rest of the corpus (other than the synthetic dataset) does not
contain any true positives for either system and contains the same number of false-negatives
for both systems, the proposed system will maintain a higher recall ratio than that of the
WSJ annotations on the whole corpus.
A similar experiment is conducted for extrapositions using sentences that are already
annotated in the corpus. All 656 annotated extrapositional it instances are manually verified
and 637 (97.10%) of them turn out to be valid cases. The system produced queries for 623
instances and consequently recognized 575 of them, translating into 90.27% (95% C.I. 89.0193.56%) recall ratio on the verified annotations. Given the fact that on both the development
dataset and the test dataset the proposed system yields slightly higher recall on the whole
dataset than it does on the subsets identified by WSJ annotations, its performance for
extrapositions on the whole WSJ corpus is likely to remain above 90% in recall.
Similar to the situation in the test based on random cases, a large portion of falsepositives are contributed by imperfect handling of both surface structures and noun phrases
in the matrix object position, particularly in the form of it takes/took . . . to . . . From
additional experiments, it seems that this particular construct can be addressed with a
different pattern, what/whatever it takes to verb, which eliminates the noun phrase.
Alternatively, the construct could possibly be assumed as extrapositional without issuing
queries at all.
22
This kind of cleft can be separated from extrapositions using an additional pattern that attaches the
prepositional phrase to the subordinate verb. However, the number of samples are too few to justify its
inclusion in the study.

383

Li, Musilek, Reformat, & Wyard-Scott

6. Discussion
In this paper a novel pleonastic-it identification system is proposed. Unlike its precursors,
the system classifies extrapositions by submitting queries to the web and analyzing returned
results. A set of rules are also proposed for classification of clefts, whose particular manner
of composition makes it more difficult to apply the web-based approach. Components of the
proposed system are simple and their effectiveness should be independent of the type of text
being processed. As shown in the generalization tests, the system maintains its precision
while recall degrades by only a small margin when confronted with unfamiliar texts. This
is an indication that the general principles behind the system are not over-fitted to the text
from which they were derived. Overall, when evaluated on WSJ news articles – which can
be considered a ‘difficult’ type of nonfiction – the system is capable of producing results
that are on par with or only slightly inferior to that of casually trained humans.
The system’s success has important implications beyond the particular problem of
pleonastic-it identification. First, it shows that the web can be used to answer linguistic questions that are based upon more than just simplistic semantic relationships. Second,
the comparative study is an effective means to get highly accurate results from the web despite the fact that it is noisier than the manually compiled corpora. In addition, the success
of the simple guidelines used in identifying clefts may serve as evidence that a speaker’s
intention can be heavily reflected by the surface structures of her utterance, in a bid to
make it distinguishable from similarly constructed sentences.
Some problems are left unaddressed in the current study, most notably the handling
of complex noun phrases and prepositional phrases. Generally speaking, its approach to
query instantiation is somewhat crude. To solve the noun-phrase issue, a finer-grained query
downgrading is proposed, viz. first to supply the query with the original noun phrase, then
the head noun, and finally the adjective that modifies the head noun, if there is one. The
effectiveness of this approach is to be determined. As discussed in Section 5.6.2, a special
rule can be used for the verb take. This, however, may open the door to exception-based
processing, which contradicts the principle of the system to provide a unified approach to
pleonastic pronoun identification. Overall, much more data and further experiments are
needed before the query instantiation procedures can be finalized.
Aside from the two sets of patterns that are currently in use, other information can
be used to assess the validity of a possible extraposition. For example, in extrapositions
the matrix verbs are much more likely to remain in present tense than past tense, the
noun phrases (if any) at the matrix object position are more likely to be indefinite, and
the extraposed clauses are generally longer than the matrix verb phrases. A fuzzy-based
decision system with multiple input variables could possibly provide significant performance
gains.
Although the system is able to yield reasonable performances on the output of either
parser tested, both of them introduce additional errors to the final results. On the combined
dataset of development and test items, both parsers cause statistically significant deteriorations in performance at a significance level of 0.1 (Charniak parser: p=0.008 for F-measure
on extrapositions; p=0.071 for F-measure on clefts). It is possible that incorporating a
pattern-based method will compensate for the problems caused by imperfect parsing and
further improve recall ratios; however, more data is needed to confirm this.
384

Identification of Pleonastic It Using the Web

Another concern is that the syntactic processing component used in the system is limited.
This limitation, caused by the designer’s lack of exposure to a large variety of different
constructs, is essentially different from the problem imposed by the limited number of
patterns in some previous systems. Eventually, for the proposed system, this limitation can
be eliminated. To illustrate, the current design is not able to correctly process sentences like
what difference does it make which I buy; however, it only takes minor effort to correct this
by upgrading the subsystem so that it recognizes pre-posed objects. Each such upgrade,
which may be performed manually or even automatically through some machine-learning
approaches, solves one or more syntactic problems and moves the system closer to being able
to recognize all grammatically valid constructs. In contrast, it will take considerably more
effort to patch the rigidly defined rules or to upgrade the word lists before the rule-based
systems can achieve comparable performances.
During the writing of this article, Google deprecated their SOAP-based search API. This
move makes it technically difficult to precisely replicate the results reported in this study
since other search engines lack the ability to process alternate expressions (i.e. WordA OR
WordB ) embedded within a quoted query. To use a different search engine, the matrix verbs
should not be expanded but should instead be converted to their respective third-person
singular present form only. Stubs should also be in their simplest form only, as described
in earlier sections. From preliminary experiments it also seems possible to replace the
combination of which/who/this/he with they alone, plus some necessary changes to maintain
number agreement among the constituents of the queries. These changes may have some
negative effects on the final outcome of the system, but they are unlikely to be severe.
Like most other NLP tasks, classifying the usage of it is inherently difficult, even for
human annotators who already have some knowledge about the problem – it is one thing
to speak the language, and another to then clearly explain the rationale behind a specific
construct. Although it is widely accepted that an extrapositional it is expletive, the line
between extrapositional cases and referential ones can sometimes be very thin. This is
clearly manifested by the existence of truncated extrapositions (Gundel et al., 2005), which
obviously have valid referential readings. Similar things can be said about the relationship
among all three pleonastic categories as well as idioms. For example, Paice and Husk classify
‘it remains to . . . ’ as an idiom while the same construct is classified as an extraposition
in our evaluations. Aside from applying the syntactic guidelines proposed in this study, it
is assumed during the annotation process that an extraposition should have either a valid
non-extraposed reading or a valid what-cleft reading. It is also assumed that a cleft should
generate a valid non-clefted reading by joining the clefted constituent directly to the cleft
clause without any leading relative pronoun or adverb. In light of the subjective nature
of the problem, our annotations are published on the web as an online appendix to better
serve readers.

References
Agresti, A., & Coull, B. A. (1998). Approximate is better than “exact” for interval estimation of binomial proportions. The American Statistician, 52 (2), 119–126.
Berland, M., & Charniak, E. (1999). Finding parts in very large corpora. In Proceedings of the 37th annual meeting of the Association for Computational Linguistics on
385

Li, Musilek, Reformat, & Wyard-Scott

Computational Linguistics, pp. 57–64.
Bies, A., Ferguson, M., Katz, K., & MacIntyre, R. (1995). Bracketing guidelines for Treebank II style. Tech. rep. MS-CIS-95-06, Department of Computer and Information
Science, University of Pennsylvania.
Boyd, A., Gegg-Harrison, W., & Byron, D. (2005). Identifying non-referential it: A machine
learning approach incorporating linguistically motivated patterns. In Proceedings of
the ACL Workshop on Feature Engineering for Machine Learning in Natural Language
Processing, pp. 40–47. Association for Computational Linguistics.
Charniak, E., & Johnson, M. (2005). Coarse-to-fine n-best parsing and maxent discriminative reranking. In Proceedings of the 43rd Annual Meeting of the Association for
Computational Linguistics (ACL05), pp. 173–180, Morristown, NJ, USA. Association
for Computational Linguistics.
Chinchor, N. (1992). The statistical significance of the MUC-4 results. In Proceedings of
the 4th conference on Message understanding (MUC4), pp. 30–50, San Mateo, CA.
Morgan Kaufmann.
Cimiano, P., Schmidt-Thieme, L., Pivk, A., & Staab, S. (2005). Learning taxonomic relations from heterogeneous evidence. In Buitelaar, P., Cimiano, P., & Magnini, B.
(Eds.), Ontology Learning from Text: Methods, Applications and Evaluation, Frontiers in Artificial Intelligence and Applications, pp. 59–73. IOS Press, Amsterdam.
Clemente, J. C., Torisawa, K., & Satou, K. (2004). Improving the identification of nonanaphoric it using support vector machines. In Proceedings of the International
Joint Workshop on Natural Language Processing in Biomedicine and its Applications
(NLPBA/BioNLP04).
Cohen, J. (1960). A coefficient of agreement for nominal scales. Educational and Psychological Measurement, 20 (1), 37–46.
Collins, M. (1999). Head-Driven Statistical Models for Natural Language Parsing. Ph.D.
thesis, University of Pennsylvania.
Davidse, K. (2000). A constructional approach to clefts. Linguistics, 38 (6), 1101–1131.
Davison, A. C., & Hinkley, D. V. (1997). Bootstrap Methods and Their Application. Cambridge series on statistical and probabilistic mathematics. Cambridge University Press,
Cambridge, UK.
Denber, M. (1998). Automatic resolution of anaphora in English. Tech. rep., Eastman
Kodak Co.
Di Eugenio, B., & Glass, M. (2004). The kappa statistic: a second look. Computational
Linguistics, 30 (1), 95–101.
Efron, B., & Tibshirani, R. (1993). An Introduction to the Bootstrap. Chapman and Hall,
New York, USA.
Evans, R. (2000). A comparison of rule-based and machine learning methods for identifying
non-nominal it. In Christodoulakis, D. (Ed.), Proceedings of the 2nd International
Conference on Natural Language Processing (NLP00), Vol. 1835 of Lecture Notes in
Computer Science, pp. 233–241, Berlin. Springer.
386

Identification of Pleonastic It Using the Web

Evans, R. (2001). Applying machine learning toward an automatic classification of it.
Literary and Linguistic Computing, 16 (1), 45–57.
Fellbaum, C. (Ed.). (1998). WordNet: An Electronic Lexical Database. The MIT Press,
Cambridge, Mass., USA.
Geurts, B., & van der Sandt, R. (2004). Interpreting focus. Theoretical Linguistics, 30 (1),
1–44.
Green, P. S., & Hecht, K. (1992). Implicit and explicit grammar: An empirical study. Applied
Linguistics, 13 (2), 168–184.
Gundel, J., Hedberg, N., & Zacharski, R. (2005). Pronouns without NP antecedents: How
do we know when a pronoun is referential?. In Branco, A., McEnery, T., & Mitkov,
R. (Eds.), Anaphora Processing: Linguistic, Cognitive and Computational Modelling,
pp. 351–364. John Benjamins, Amsterdam, The Netherlands.
Gundel, J. K. (1977). Where do cleft sentences come from?. Language, 53 (3), 543–559.
Hamawand, Z. (2003). For-to complement clauses in English: A cognitive grammar analysis.
Studia Linguistica, 57 (3), 171–192.
Hearst, M. A. (1992). Automatic acquisition of hyponyms from large text corpora. In
Proceedings of the 14th international conference on Computational Linguistics, pp.
539–545.
Hedberg, N. (1990). The Discourse Function of Cleft Sentences in English. Ph.D. thesis,
University of Minnesota.
Hedberg, N. (2000). The referential status of clefts. Language, 76 (4), 891–920.
Kaltenböck, G. (2005). It-extraposition in English: A functional view. International Journal
of Corpus Linguistics, 10 (2), 119–159.
Kilgarriff, A. (2007). Googleology is bad science. Computational Linguistics, 33 (1), 147–151.
Kilgarriff, A., & Grefenstette, G. (2003). Introduction to the special issue on the Web as
corpus. Computational Linguistics, 29 (3), 333–347.
Krifka, M. (2003). Bare NPs: Kind-referring, indefinites, both, or neither?. In Proceedings of
Semantics and Linguistic Theory (SALT) XIII, New York, USA. CLC Publications.
Krippendorff, K. (1980). Content Analysis: An Introduction to Methodology. Sage Publications, Inc., Beverly Hills, USA.
Lambrecht, K. (2001). A framework for the analysis of cleft constructions. Linguistics,
39 (3), 463–516.
Lappin, S., & Leass, H. J. (1994). An algorithm for pronominal anaphora resolution. Computational Linguistics, 20 (4), 535–561.
Marcus, M. P., Marcinkiewicz, M. A., & Santorini, B. (1993). Building a large annotated
corpus of English: the Penn Treebank. Computational Linguistics, 19 (2), 313–330.
Markert, K., & Nissim, M. (2005). Comparing knowledge sources for nominal anaphora
resolution. Computational Linguistics, 31 (3), 367–402.
387

Li, Musilek, Reformat, & Wyard-Scott

Markert, K., Nissim, M., & Modjeska, N. N. (2003). Using the web for nominal anaphora
resolution. In Dale, R., van Deemter, K., & Mitkov, R. (Eds.), Proceedings of the
EACL Workshop on the Computational Treatment of Anaphora, pp. 39–46.
Metcalf, A., & Barnhart, D. K. (1999). America in So Many Words: Words That Have
Shaped America. Houghton Mifflin, Boston, USA.
Mitkov, R. (2001). Outstanding issues in anaphora resolution. In Gelbukh, A. (Ed.),
Proceedings of the 2nd International Conference on Computational Linguistics and
Intelligent Text Processing (CICLing01), Vol. 2004 of Lecture Notes in Computer
Science, pp. 110–125, Berlin. Springer.
Mitkov, R., Evans, R., & Orasan, C. (2002). A new, fully automatic version of Mitkov’s
knowledge-poor pronoun resolution method. In Gelbukh, A. F. (Ed.), Proceedings of
the 3rd International Conference on Computational Linguistics and Intelligent Text
Processing (CICLing02), Vol. 2276 of Lecture Notes in Computer Science, pp. 168–186,
London, UK. Springer-Verlag.
Müller, C. (2006). Automatic detection of nonreferential it in spoken multi-party dialog.
In Proceedings of the 11th Conference of the European Chapter of the Association for
Computational Linguistics (EACL06), pp. 49–56.
Nanni, D. L. (1980). On the surface syntax of constructions with easy-type adjectives.
Language, 56 (3), 568–581.
Ng, V., & Cardie, C. (2002). Identifying anaphoric and non-anaphoric noun phrases to
improve coreference resolution. In Proceedings of the 19th international conference on
Computational linguistics (COLING02), pp. 1–7, Morristown, NJ, USA. Association
for Computational Linguistics.
Noreen, E. W. (1989). Computer-Intensive Methods for Testing Hypotheses : An Introduction. Wiley-Interscience, New York, USA.
Paice, C. D., & Husk, G. D. (1987). Towards the automatic recognition of anaphoric
features in english text: the impersonal pronoun “it”. Computer Speech & Language,
2 (2), 109–132.
Petrov, S., Barrett, L., Thibaux, R., & Klein, D. (2006). Learning accurate, compact, and
interpretable tree annotation. In Proceedings of the 21st International Conference
on Computational Linguistics and the 44th annual meeting of the ACL (ACL06), pp.
433–440, Morristown, NJ, USA. Association for Computational Linguistics.
Poesio, M., Ishikawa, T., im Walde, S. S., & Vieira, R. (2002). Acquiring lexical knowledge
for anaphora resolution. In Proceedings of the Third International Conference on
Language Resources and Evaluation, pp. 1220–1224.
Sinclair, J. (Ed.). (1995). Collins COBUILD English Grammar. Harper Collins, London,
U.K.
Sloat, C. (1969). Proper nouns in English. Language, 45 (1), 26–30.
van Rijsbergen, C. J. (1979). Information Retrieval (2nd edition). Butterworth-Heinemann,
Newton, MA, USA.
388

Identification of Pleonastic It Using the Web

Xia, F., & Palmer, M. (2001). Converting dependency structures to phrase structures.
In Proceedings of the first international conference on Human language technology
research (HLT01), pp. 1–5, Morristown, NJ, USA. Association for Computational
Linguistics.

389

Journal of Artificial Intelligence Research 34 (2009) 209-253

Submitted 06/2008; published 03/2009

Mechanisms for Making Crowds Truthful
Radu Jurca

radu.jurca@gmail.com

Google Inc., Switzerland

Boi Faltings

boi.faltings@epfl.ch

Ecole Polytechnique Fédérale de Lausanne (EPFL)
Artificial Intelligence Laboratory (LIA)
CH-1015 Lausanne, Switzerland

Abstract
We consider schemes for obtaining truthful reports on a common but hidden signal
from large groups of rational, self-interested agents. One example are online feedback
mechanisms, where users provide observations about the quality of a product or service
so that other users can have an accurate idea of what quality they can expect. However,
(i) providing such feedback is costly, and (ii) there are many motivations for providing
incorrect feedback.
Both problems can be addressed by reward schemes which (i) cover the cost of obtaining
and reporting feedback, and (ii) maximize the expected reward of a rational agent who
reports truthfully. We address the design of such incentive-compatible rewards for feedback
generated in environments with pure adverse selection. Here, the correlation between the
true knowledge of an agent and her beliefs regarding the likelihoods of reports of other
agents can be exploited to make honest reporting a Nash equilibrium.
In this paper we extend existing methods for designing incentive-compatible rewards
by also considering collusion. We analyze different scenarios, where, for example, some or
all of the agents collude. For each scenario we investigate whether a collusion-resistant,
incentive-compatible reward scheme exists, and use automated mechanism design to specify
an algorithm for deriving an efficient reward mechanism.

1. Introduction
An increasing number of applications of artificial intelligence extract knowledge from large
groups of agents, also termed the wisdom of the crowds. One example are online feedback forums (also known as reputation mechanisms) for obtaining information about the
products or services. The testimonies of previous buyers disclose hidden, experience-related
(Parasuraman, Zeithaml, & Berry, 1985), product attributes such as quality, reliability,
ease of use, etc., that can only be observed after the purchase. This previously unavailable
information allows the buyers to make better, more efficient decisions, and eliminates some
of the problems that would otherwise lead to the collapse of online markets1 .
Recent studies, however, raise important questions regarding the ability of existing reputation mechanisms to reflect the real quality of a product. First, the absence of clear
incentives drives only some of the users to voice their opinions. For example, Hu, Pavlou,
1. Akerlof (1970) warns about the “Market of Lemons”, where asymmetric information drives all, except
the worst quality sellers out of the market.
c
°2009
AI Access Foundation. All rights reserved.

Jurca & Faltings

and Zhang (2006) and Admati and Pfleiderer (2000) show that Amazon2 ratings of books
or CDs follow with great probability bi-modal, U-shaped distributions where most of the
ratings are either very good, or very bad. As controlled experiments on the same items
reveal normally distributed opinions, the authors conclude that users with a moderate outlook are unlikely to report. Talwar, Jurca, and Faltings (2007) identify another factor that
promotes rating, namely the desire to contribute with something new to the previously
submitted reports. In both cases, the reputation mechanism collects an unrepresentative
sample of reviews that is not necessarily informative for the average user.
Second, and even more distressful, some users intentionally lie in order to gain external
benefits from the distorted reputation. Harmon (2004) reports that some authors write fake
reviews on Amazon in order to boost the sale of their own books, or to trash the reputation
of competing titles. White (1999) describes manipulation techniques for pushing songs up
the charts, and Elliott (2006) and Keates (2007) identify problems associated to fake hotel
reviews on the travel reputation site TripAdvisor.com. Although we still see high levels
of altruistic (i.e., honest) reporting, the increasing awareness that gains can be made by
manipulating online reputation will likely attract more dishonest reporting in the future.
Both problems can be solved if the reputation mechanism rewards users for reporting
feedback. First, the reward should cover the cost of reporting, so that more users leave
feedback and allow the reputation mechanism to estimate more precisely the quality of
products or services. Second, honest feedback should yield higher rewards than lying, so
that rational agents find in in their best interest to be truthful. This technique is not limited
to reputation mechanisms, but applies more generally to any setting where a private signal
is inferred from reports by a crowd of self-interested rational agents.
The reader might already ask whether or not it is reasonable to assume that explicit
payments 3 will incentivise users to change their reporting behavior. Although humans are
known to sometimes act irrationally, there are many examples of online systems where rewards have successfully promoted the elicitation of private information. Prediction markets,
for example, consistently outperform traditional prediction tools (Figlewski, 1979; Pennock,
Debnath, Glover, & Giles, 2002) and users seem to be equally motivated by fake or real
money (Servan-Schreiber, Wolfers, Pennock, & Galebach, 2004). Another example is the
ESP Game4 which extracted an impressive volume of image tags by rewarding players with
virtual points. Moreover, the future online economy is likely to contain increasing numbers of automated agents, which by design, will be programmed to behave rationally and
maximize their utility.
Fundamental results in the mechanism design literature (d’Aspremont & Grard-Varet,
1979; Crémer & McLean, 1985) show that side payments can be designed to create the
incentive for agents to reveal their private opinions truthfully. The best such payment
schemes have been constructed based on proper scoring rules (Kandori & Matsushima, 1998;
Johnson, Pratt, & Zeckhauser, 1990; Clemen, 2002), and exploit the correlation between
the observations of different buyers about the same good.
2. http://www.amazon.com
3. The term payments is general and includes non-monetary rewards such as preferential access to resources,
social status or bonus “points”.
4. http://www.espgame.org/

210

Mechanisms for Making Crowds Truthful

Miller, Resnick, and Zeckhauser (2005) adapt these results to online feedback forums
characterized by pure adverse selection. In such environments, buyers observe the same
innate quality attributes of the products or the service providers, possibly with some noise.
The role of the reputation mechanism is signaling, i.e. to aggregate reports of the buyers
into accurate estimates of these attributes. Examples of such a situation are product rating
forums such as Amazon, ePinions or Bizrate, and most services that are provided through
machines or networks in an anonymous fashion.
In contrast reputation mechanisms can also be used in a sanctioning role to counter moral
hazard. This exists in environments where the provider can vary the quality attributes for
each particular buyer in a strategic manner. The role of the reputation mechanism is to
spread information about seller misbehavior and increase its cost to make it unattractive.
An example of such an environment are seller ratings in online marketplaces.
The two roles of reputation are complementary, and solve the two important problems associated with online markets (Dellarocas, 2006). The signaling role acts against
information asymmetries, and allows agents to accurately identify capable partners. The
sanctioning role, on the other hand, acts against cheating incentives and encourages honest
behavior.
Like Miller et al. (2005), we concentrate in this paper on pure signaling mechanisms and
ignore the effects associated with moral hazard. A set of users is assumed to experience the
same product or service, possibly with some noise, and later report the privately perceived
quality signal to a central reputation mechanism. The product or service is assumed to have
consistent quality over time, so that the quality observed by different users can be modeled
as randomly drawn from the same distribution. These assumptions are quite common for
services delivered by automated systems like web services or intelligent agents, where failures
and degradation in performance are due to random events that have not been planned by
a strategic operator.
The reputation mechanism scores every submitted feedback by comparing it with another report (called the reference report) submitted by a different user about the same
good. Miller et al. (2005) prove the existence of general incentive-compatible payments
where honest reporting is a Nash equilibrium, and the expected reward is large enough to
cover the effort of reporting.
Intuitively, incentive-compatible payments exploit the correlation between the private
signal observed by an agent, and the agent’s beliefs regarding the reference report. Different
quality signals trigger different updates of the agent’s private beliefs (by Bayes’ Law), and
thus modify the agent’s expectations regarding the value of the reference report. By paying
reporters according to how well their submitted feedback improves the public predictor of
the reference report (tested against the actual reference report, assumed honest), agents
have the incentive to “align” the public predictor to their private beliefs, and thus report
the truth. Honest reporting becomes a Nash equilibrium.
Unfortunately, honest reporting is not the only Nash Equilibrium (NE) of such a mechanism. Jurca and Faltings (2005) show that all binary incentive-compatible payment mechanisms using a single reference report have several equilibria; moreover, at least one lying
equilibrium gives the agents higher expected payoffs than the truthful NE. This brings
forth the problem of collusion, as rational agents could potentially coordinate on a lying
equilibrium that gives them a higher payoff than the honest equilibrium.
211

Jurca & Faltings

The simplest such lying equilibrium is for all agents to always report the same, thus
leading to perfect prediction of the reference reports. As any product or service in the real
world will have occasional defects, truthful reporting will always be a noisy predictor of the
reference report, and thus not be able to match the payoff of the lying strategy.
We overcome this problem by using not a single but several reference reports. We start
from the observation that in the real world, even the most perfect products or services
will occasionally be defective. Thus, we should reward reports that predict this slightly
imperfect situation. The key idea is to score a report against a set of at least 4 reference
reports, and to reward a report according to the distribution of these reference reports,
without considering their order. By giving a higher reward for matching all but one of the
reference reports, it is possible to give a higher expected payoff to the truthful reporting
equilibrium.
As it is difficult to see how to scale the rewards to obtain this characteristic, we use
automated mechanism design (Conitzer & Sandholm, 2002) to compute the rewards that
satisfy the criteria. This technique has been first applied to this problem by Jurca and
Faltings (2006) to compute the minimal payments required to ensure honest reporting of
reputation information. Jurca and Faltings (2007a) augment the technique by formulating
the requirement of collusion safety as additional constraints on the desired mechanism. This
paper extends our previous work by presenting a unified framework for designing incentivecompatible, collusion resistant rewards in a broader set of collusion scenarios.
More concretely, we vary the complexity of the collusion scenario along three dimensions.
First, we consider the size of the coalition, and study what happens when all or only some of
the agents can become part of a lying coalition. The complexity of coordination is the second
dimension, and we consider cases where colluders have or not the necessary sophistication
to coordinate on different reporting strategies. Finally, the third dimension addresses the
transfer of utilities and includes the settings where colluders can make or not side-payments
to other colluders.
However, not all combinations are formally treated; some contain contradictory assumptions (e.g., if colluders are assumed capable of side-payments, they should also be assumed
capable to coordinate on different strategies) or lead to trivial impossibility results (e.g., collusion resistance is clearly impossible when one strategic agent controls all online identities,
exactly the scenario where all agents collude and may transfer payments among themselves).
This paper proceeds as follows. Section 2 formally introduces our model, Section 3
introduces incentive-compatible payment mechanisms and presents some of their properties. Section 4 addresses the design of collusion-resistant reward mechanisms for different
scenarios. Finally we discuss related work and future directions to improve our results.

2. The Model
We consider an online market where a number of rational buyers (or agents) experience
the same product (or service). The quality of the product remains fixed, and defines the
product’s (unknown) type. Θ is the finite set of possible types, and θ denotes a member of
this set. We assume that all buyers share
P a common belief regarding the prior probability
P r[θ], that the product is of type θ. θ∈Θ P r[θ] = 1.
212

Mechanisms for Making Crowds Truthful

After the purchase, every buyer perceives a binary signal about the quality (i.e., true
type) of the product. 1 denotes the high quality signal and captures the satisfaction of
the buyer with the product. 0, on the other hand, denotes the low quality signal, or
the buyer’s dissatisfaction with the product. Every product type is characterized by a
different probability distribution over the signals perceived by the buyers. Let P r[1|θ] be
the probability that the buyer of a product of type θ is satisfied (i.e., observes the quality
signal 1). P r[1|θ1 ] 6= P r[1|θ2 ] for all θ1 6= θ2 ∈ Θ, and P r[1|·] is assumed common knowledge.
To make it simpler for the reader to follow the formal notation, we will present a
numerical example. The same example will extended as we introduce new notation, and
will serve in the subsequent sections to illustrate our results.
Example. Alice, the owner of an old house, needs some plumbing work done. She knows
there are good (type θG ) and bad (type θB ) plumbers, such that good plumbers provide high
quality service with much higher probability: e.g., P r[1|θG ] = 0.9 and P r[1|θB ] = 0.15. Alice
picks the plumber from the Yellow Pages, and given the reputation of the source, she believes
that the plumber, Bob, is likely to be good: e.g., P r[θG ] = 0.8 and P r[θB ] = 0.2. Therefore,
Alice expects to get good service with probability P r[θG ]P r[1|θG ] + P r[θB ]P r[1|θB ] = 0.75.
A central reputation mechanism asks every buyer to submit feedback. Buyers are assumed rational, and
to report ª
the truth. The set of pure reporting strategies
©¡not constrained
¢
of a buyer is S ¡= s(0), s(1)
|s(0),
s(1)
∈
Q
2 , where Q2 = {0, 1} is the set of quality sig¢
nals, and s = s(0), s(1) denotes the strategy according to which the buyer announces
s(0) ∈ Q2 when she observes low quality, and s(1) ∈ Q2 when she observes high quality.
We will often call the reports 0 and 1 the negative, respectively the positive report.
To ease the notation, we name the four members of the set S as the honest strategy (s̄),
the lying strategy (slie ), the always reporting one strategy (spos ) and the always reporting
0 strategy (sneg ):
• s̄ = (0, 1) the buyer reports 0 when she observes low quality and 1 when she observes
high quality;
• slie = (1, 0) the buyer reports 1 when she observes low quality and 0 when she observes
high quality;
• spos = (1, 1) the buyer reports 1 regardless of her observation;
• sneg = (0, 0) the buyer reports 0 regardless of her observation;
The reputation mechanism rewards buyers for the submitted reports. The payment
received by buyer i can depend on any information available to the reputation mechanism:
namely, the reports submitted by other buyers, and the common knowledge regarding the
environment (probability distribution over types, and conditional probability distributions
of quality signals). We assume the reputation mechanism updates the public reputation
information with batches of N reports. The agents that submitted the N reports in the
same batch are assumed to have had access to the same public information, which motivates
the common priors assumption from the beginning of the section. For the rest of the paper
will analyze reward mechanisms that work on static sets of N reports; in real settings,
213

Jurca & Faltings

however, the same mechanisms will be designed over and over again for all batches of size
N.
Note that the reputation mechanism (i) does not know the true type of the product,
and (ii) cannot purchase the product in order to get some first-hand experience regarding
its quality.
Discarding from the notation the dependence on the common knowledge, a payment
mechanism (employed by the reputation mechanism) is a function τ : Q2 × (Q2 )N −1 → R+ ,
where τ (ri , r−i ) ≥ 0 is the amount paid to buyer i when she reports ri ∈ Q2 and the other
N − 1 buyers report r−i ∈ (Q2 )N −1 . The reports r−i are also called the reference reports
of agent i, since they constitute the reference for computing the payment for agent i. We
constrain payments to be non-negative as most online forums cannot impose punishments
on the reporters.
The order of reports is not important, therefore we can simplify the payment mechanism
∗ ) for all r
∗
by assuming that τ (ri , r−i ) = τ (ri , r−i
−i and r−i that contain the same number of
positive reports. A more compact description of the payment mechanism is thus given by
the amounts τ (r, n) where n ∈ {0, 1, . . . , N − 1} is the number of positive reports submitted
by the reference reporters.
The payoff expected by agent i depends on the distribution of the reference reports. If
the other agents report honestly, the distribution of the reference reports can be computed
from the prior beliefs, and the true observation, oi ∈ Q2 of agent i. The probability that
exactly n positive reports were submitted by the other N − 1 agents is:
P r[n|oi ] =

X

P r[n|θ]P r[θ|oi ];

(1)

θ∈Θ

where P r[n|θ] is the binomial probability distribution function, and P r[θ|oi ] can be computed from Bayes’ Law:
³ N −1 ´
¡
¢N −1−n
P r[1|θ]n 1 − P r[1|θ]
;
n
X
P r[oi |θ]P r[θ]
P [θ|oi ] =
; P r[oi ] =
P r[oi |θ]P r[θ];
P r[oi ]
P r[n|θ] =

θ∈Θ

Example. Once Bob the plumber gets the work done, Alice observes the result and learns
something new about Bob’s type. If Alice sees good work, her posterior belief regarding the
type of Bob will be P r[θG |1] = 1−P r[θB |1] = 0.96 (computed by Bayes’ Law), and therefore,
Alice will believe that some other client will get good service from Bob with probability:
P r[1|1] = P r[1|θG ]P r[θG |1] + P r[1|θB ]P r[θB |1] = 0.87. On the other hand, if Alice is not
happy with the work done by Bob, her posterior belief will be: P r[θG |0] = 1 − P r[θB |0] =
0.32, and she will expect another client to receive good service from Bob with probability:
P r[1|0] = P r[1|θG ]P r[θG |0] + P r[1|θB ]P r[θB |0] = 0.39.
The reputation mechanism offers Alice the following reward scheme: “the report is paid
only if it matches the reference report. A negative report is paid $2.62, while a positive report
is paid $1.54”. Consequently, this reward scheme can be formally described as τ (0, 0) = 2.62,
τ (1, 1) = 1.54, and τ (1, 0) = τ (0, 1) = 0. Assuming that the reference report is truthful,
one can easily verify that Alice maximizes her expected payment by reporting the truth: If
Alice experiences good service from the plumber, she expects that some other client also gets
214

Mechanisms for Making Crowds Truthful

good service with probability 87%. Assuming that the other client reports truthfully, Alice’s
expected payment is: .87·1.54+.13·0 = 1.34 if she reports good service, or .87·0+.13·2.62 =
0.34 if she reports bad service; Likewise, if Alice experiences bad service, she expects that
the reference report will be negative with probability 1 − .39 = .61. In this case, her expected
payment is: .39 · 1.54 + .61 · 0 = 0.6 if she reports good service, or .39 · 0 + .61 · 2.62 = 1.6 if
she reports bad service. In both cases, honest reporting is better than lying by $1.
The numerical example above specifies payments in dollars but does not mention the
value of the service that is the object of the reputation report. We specifically avoid the dependence of the reward mechanism on the value of the goods traded in the market. Instead,
we will relate the rewards to the marginal gain for telling the truth, and the monetary unit
is defined as the minimum expected loss of an agent that miss-reports instead of telling the
truth.
A strategy profile s is a vector (si )i=1,...,N , prescribing the reporting strategy si ∈ S for
each agent i. We will sometimes use the notation s = (si , s−i ), where s−i is the strategy
profile for all agents except i; i.e., s−i = (sj ), for j = 1, . . . , i − 1, i + 1, . . . , N . Given the
profile of reporting strategies (si , s−i ), let µ[n, s−i ] describe the belief of agent i regarding
the distribution of the reference reports, when:
• n out of the other N − 1 agents observe the high quality signal, 1
• the other N − 1 agents are reporting according to the strategy profile s−i ;
Given n and s−i , agent i believes with probability µ[n, s−i ](x) that x reference reports are
positive. If si (oi ) ∈ Q2 is the value of the report prescribed by strategy si given the true
observation oi , the expected payoff to agent i is:
V (si , s−i |oi ) =

N
−1
X

P r[n|oi ]

n=0

N
−1
X

¡
¢
µ[n, s−i ](x)τ si (oi ), x ;

(2)

x=0

Throughout this paper we will restrict our attention to pure reporting strategies and
pure strategy equilibria. The reason behind this choice is grounded in practical considerations: mixed strategies and mixed strategy equilibria are more complex and difficult to
understand, and therefore unlikely to be observed in practical applications. Acknowledging
the limitations brought in by this assumption, we still believe our results are valuable for a
number of practical scenarios.

3. Incentive-Compatible Payment Mechanisms
In this section we study general payment mechanisms that are incentive-compatible, without
worrying about collusion resistance. A payment mechanism is incentive-compatible when
honest reporting is a Nash Equilibrium (NE): i.e., no agent can gain by lying when other
agents report honestly. Formally, let (s̄i , s̄−i ) be the strategy profile where all agents report
honestly. It is optimal for agent i to report the truth if and only if, for any observation oi ,
the honest report maximizes the agent’s expected payoff:
V (s̄i , s̄−i |oi ) > V (si , s̄−i |oi ); ∀si ∈ S \ {s̄}, oi ∈ Q2 ;

Since reference reports are truthful, the expected payoff to agent i is:
V (s̄i , s̄−i |oi ) =

N
−1
X
n=0

215

P r[n|oi ]τ (oi , n);

Jurca & Faltings

and the incentive-compatibility constraints become:
N
−1
X

P r[n|oi ]τ (oi , n) >

n=0

N
−1
X

P r[n|oi ]τ (1 − oi , n); ∀oi ∈ Q2 ;

(3)

n=0

Practical mechanisms, however, need to offset lying incentives by offering certain margins
for truth-telling. Honest reporting must be better than lying by at least some margin Λ,
chosen by the mechanism designer to offset the external benefits an agent might obtain
by lying. Rewriting (3) to account for the margin Λ, an incentive-compatible payment
mechanism satisfies the constraints:
N
−1
X

³
´
P r[n|1] τ (1, n) − τ (0, n) ≥ Λ;

n=0
N
−1
X

³
´
P r[n|0] τ (0, n) − τ (1, n) ≥ Λ;

(4)

n=0

formalizing the intuition that it is more profitable to report positively (respectively negatively) when observing high (respectively low) quality.
Kandori and Matsushima (1998), and Miller et al. (2005) show that it is possible to
construct payment mechanisms that satisfy the constraints in (4), based on scoring rules.
Jurca and Faltings (2006) build on this existence result and describe an algorithm that
computes the optimal (i.e., budget minimizing) payment mechanism. We will use this
latter approach in this paper, for the obvious practical advantages of designing an incentive
compatible reputation mechanism as cheaply as possible.
The expected payment to an honest reporter (in the truthful NE) is the weighted sum
between the expected payment to an agent that truthfully reports 1, and the expected
payment to an agent that truthfully reports 0:
N
−1
N
−1
h
i
X
X
E V (s¯i , s̄−i ) = P r[1]
P r[n|1]τ (1, n) + P r[0]
P r[n|0]τ (0, n);
n=0

(5)

n=0

where P r[1] (respectively P r[0]) are the prior probabilities
P that the agent will perceive high
(respectively low) quality, and are defined as: P r[oi ] = θ∈Θ P r[oi |θ]P r[θ].
The payment scheme that minimizes the budget required to pay for one honest report
therefore solves the linear optimization problem:
LP 3.1.
N
−1
N
−1
h
i
X
X
min E V (s¯i , s̄−i ) = P r[1]
P r[n|1]τ (1, n) + P r[0]
P r[n|0]τ (0, n);
n=0

s.t.

N
−1
X

n=0

³

´
P r[n|1] τ (1, n) − τ (0, n) ≥ Λ;

n=0
N
−1
X

³
´
P r[n|0] τ (0, n) − τ (1, n) ≥ Λ;

n=0

τ (0, n), τ (1, n) ≥ 0; ∀n = {0, 1, . . . , N − 1};

216

Mechanisms for Making Crowds Truthful

Although numerical algorithms can efficiently solve LP 3.1, the analytical solution helps
us gain additional insights about the structure of incentive-compatible payment mechanisms.
It turns out that LP 3.1 has a simple solution:
Proposition 3.1. The incentive-compatible payment scheme that minimizes the expected
payment to an honest reporter (defined by LP 3.1) is:
τ (0, n) = 0, ∀n 6= 0;

τ (1, n) = 0, ∀n 6= N − 1

P r[N − 1|0] + P r[N − 1|1]
;
P r[N − 1|1]P r[0|0] − P r[N − 1|0]P r[0|1]
P r[0|0] + P r[0|1]
τ (1, N − 1) = Λ
;
P r[N − 1|1]P r[0|0] − P r[N − 1|0]P r[0|1]

τ (0, 0) = Λ

Proof.
The optimal payment mechanism is symmetric and rewards perfect consensus among
reporters: i.e., an agent gets rewarded only if her report agrees with the report of all other
agents. The reason why consensus rewards are optimal comes from the structure of the
incentive compatible constraints. Clearly there must be at least two positive payments: one
rewarding a negative report for some configuration of reference reports, the other rewarding
a positive report for some other configuration of reference reports. This proof (the full
details are available in Appendix A) shows that it is enough to have only these two positive payments, and that the corresponding configurations of reference reports must reflect
consensus.
The first part is intuitively simpler to motivate. The properties of Bayesian updates
makes it such that there always exist n1 and n2 such that P r[n1 |0] > P r[n1 |1] and
P r[n2 |1] > P r[n2 |0] (e.g., the configuration where n1 other agents report 1 becomes more
probable after a negative experience, while the configuration where n2 other agents report
1 becomes more likely after a positive experience). With potentially infinite payments, the
fact that n1 and n2 exist makes it possible to satisfy all incentive compatible constraints;
therefore the payment mechanism with only two positive payments for τ (0, n1 ) and τ (1, n2 )
is incentive compatible. The formal proof in Appendix A uses the dual formulation to show
the same thing.
The second part of the proof shows that the expected payment is minimized if the
scheme rewards consensus (i.e., n1 = 0 and n2 = N − 1). The dual of LP 3.1 reveals
that the expected payment to an agent is proportional to the ratios P r[n1 |1]/P r[n1 |0] and
P r[n2 |0]/P r[n2 |1]. These ratios reflect the relative change of the agent’s beliefs following
the subjective private experience. e.g., P r[n1 |1]/P r[n1 |0] reflects the relative change for the
belief that n1 other agents report 1, given a positive as opposed to a negative experience.
Likewise, P r[n2 |0]/P r[n2 |1] is the relative change for the belief that n2 other agents report
1, given a negative as opposed to a positive experience. The following lemma shows that
these ratios (and therefore the expected payment to an agent) are minimized when n1 = 0
and n2 = N − 1.
Lemma 3.1. Given any set of types Θ, probability distributions P r[1|θ], prior belief over
P r[n+1|1]
types P r[θ] and number of agents N , we have PP r[n|1]
r[n|0] < P r[n+1|0] for all n = 0 . . . N − 1.
217

Jurca & Faltings

The full proof of the Lemma is also provided in Appendix A.

¤

mechanisms5

All payment
that satisfy the incentive compatibility constraints have a
similar property: there must be at least two values of the reference reports, n1 < n2 , such
that:
τ (0, n1 ) > τ (1, n2 )
τ (1, n2 ) > τ (0, n2 );

The requirement n1 < n2 is a direct consequence of the Lemma 3.1. When τ (0, n1 ) and
τ (1, n2 ) are scaled appropriately6 , a rational agent prefers the ‘bet’ on n1 when she observes
low quality, and the ‘bet’ on n2 when she observes high quality.
It is exactly this property that makes it impossible to design an incentive-compatible
mechanism that has honest reporting as the unique NE with only one reference report
(Jurca & Faltings, 2005). n1 and n2 are constrained to take the values 0, respectively 1, and
τ (0, 0) > τ (0, 1), τ (1, 1) > τ (1, 0), as illustrated by the example in Section 2. Therefore, the
constant reporting strategies of always reporting 0 or 1 are also Nash Equilibria. Moreover,
since the expected payment to an honest reporter is a linear combination between τ (0, 0) and
τ (1, 1), at least one of the constant reporting equilibrium generates a higher payoff to the
reporters than the honest equilibrium. Hence the vulnerability of the payment mechanism
to lying colluders.
Using several reference reports does not, by default, eliminate this problem. The result of
Proposition 3.1 shows that the incentive-compatible constraints alone, also generate reward
schemes that are vulnerable to conformity rating (i.e, everybody reports the same thing).
In most cases, nevertheless, payment schemes based on several reference reports are not
constrained to reward agreement, so one could specify further conditions, which added to
the design problem generate collusion-resistant mechanisms. This is what we will do in
the next section. We assume there are N > 2 agents in the system and analyze what
supplementary constraints can be added to the design problem in order to deter collusion.
We consider several collusion scenarios, and whenever possible we present an algorithm that
outputs the reward mechanism that is both incentive-compatible and collusion-resistant.

4. Collusion-resistant, Incentive-compatible Rewards
The ideal reward mechanism deters any coalition, no matter how big, even when every colluder may use a different strategy and side-payments are possible. Such a mechanism, unfortunately, is trivially impossible: given that all agents may collude and use side-payments
to subsidize the agents that might otherwise quit the coalition, the payment mechanism
doesn’t have any leverage to encourage honest reporting. Whatever the payment scheme,
the coalition will adopt the strategy that maximizes the total revenue, regardless of the
truth.
Positive results may be obtained only by imposing further restrictions on possible lying
coalitions. The first restriction is that not all agents can collude. Some agents are altruistic
in nature and report honestly for moral or social reasons. Other agents are not aware of
5. One might wish, for example, to design a mechanism that minimizes the expected
budget
¡ paid to all N
PN
buyers. In this case,
the
objective
function
of
the
problem
LP
3.1
is:
B
=
P
r[n]
n · τ (1, n − 1) +
n=0
¢
(N − n) · τ (0, n) , where P r[n] is the prior probability that n out of N buyers observe high quality;
6. τ (1, n1 ) and τ (0, n2 ) will typically be 0

218

Mechanisms for Making Crowds Truthful

collusion opportunities, or cannot be contacted by a forming coalition. Social or legal norms
against collusion may furthermore create prejudices that deter some agents from entering
the coalition.
The second restriction addresses the complexity of the coordination among colluders.
Symmetric collusion strategies prescribe that all colluders are reporting according to the
same strategy. The coordination on symmetric strategies is very simple, and requires one
anonymous access to a publicly available source of information that specifies the colluding
strategy. Intuitively, the role of the coordination device may be played by a public blog
which analyzes the mechanisms and informs potential colluders on the most profitable
symmetric colluding strategy. Asymmetric collusion strategies, on the other hand, require
significantly more complex coordination. Since every colluder may use a different reporting
strategy, the coordination device must know the identity of the colluder before instructing
on a collusion strategy. This is often unfeasible, either because colluders might not want to
reveal their identity and thus create a trace of their misbehavior, or because identity of the
colluders cannot be known at all before the actual reporting takes place.
The third restriction addresses the availability of side-payments between colluders (or
transferable utilities). Even when the rewards offered by the reputation mechanism are
monetary, the kind of micro-payments that would be required among the colluders are
difficult and expensive to implement. Side-payments are even less feasible when the rewards
offered by the reputation mechanism are in kind, or in some currency under the control of
the reputation mechanism (e.g., Yahoo points or Slashdot karma cannot be transferred
even if users wanted to). The conversion of such subjective resources to real money that
can afterwards be transferred is even more difficult than the transfer itself.
One notable exception where side-payments are feasible is when the same strategic entity
controls a number of online identities, or “sybils” (Cheng & Friedman, 2005). Here, the
controlling agent is interested in maximizing his overall revenue (i.e., the sum of the revenues
obtained by the sybils), so side-payments do not have to physically occur7 .
To summarize, we address collusion scenarios where:
• all or only some of the agents can become part of a lying coalition,
• colluders can coordinate or not on using different strategies,
• colluders can make or not side-payments to other colluders.
From the remaining seven restricted collusion scenarios (see Table 1) we are only addressing five. We exclude the settings where utilities can be transferred but the coalition
is restricted to symmetric strategies. As discussed in the previous paragraph, transferable
utilities are mostly characteristic of sybil attacks, where the same strategic agent controls
several online identities. We believe it is unreasonable to assume that the strategic agent
cannot coordinate the online identities it controls on asymmetric strategy profiles.
For all scenarios involving non-transferable utilities, collusion resistance can emerge as
a consequence of having honest reporting as the only (or an attractive enough) equilibrium.
7. Whenever rewards are non-monetary, the overall utility of the controlling agent is usually less than the
sum of utilities of the sybils. On Slashdot, for example, ten users with bad karma are not worth as one
user with good karma. Nevertheless, we will keep for simplicity the assumption of additive utilities for
the controlling agent.

219

Jurca & Faltings

all agents
collude
some agents
collude

Non-Transferable Utilities
symmetric
asymmetric
strategies
strategies
Section 4.1

Section 4.2

Section 4.3

Section 4.4

Transferable Utilities
symmetric
asymmetric
strategies
strategies
unreasonable impossible
to
assumption
prevent collusion
unreasonable
Section 4.5
assumption

Table 1: Different collusion scenarios.

When all agents may collude, an honest reporting dominant equilibrium is impossible.
Therefore, we will resort to designing reward schemes where honest reporting is a unique
Nash equilibrium, or a Pareto-optimal Nash equilibrium. When only a fraction of the agents
may collude (non-colluders are assumed to report honestly) we also consider designing
rewards that make honest reporting the dominant strategy for the colluders. The following
subsections address each one collusion scenario, and describe possible methods for designing
collusion-resistant, incentive-compatible reward mechanisms.
4.1 Full Coalitions on Symmetric Strategies, Non-Transferable Utilities
We assume that agents (i) can only coordinate once (before any of them purchases the
product) on the same (pure) reporting strategy, and (ii) cannot make side-payments from
one to another. This simple form of coordination between colluders considerably simplifies
the problem of the mechanism designer; the only supplementary constraint on the incentivecompatible payment mechanism is to ensure that none of the pure symmetric strategy
profiles is a NE.
4.1.1 Unique Nash equilibrium.
The set of pure strategies is finite (and contains 3 lying strategies) therefore we can exhaustively enumerate the constraints that prevent the corresponding symmetric lying strategy
profiles to be NE:
• spos (always reporting 1) is not NE when a rational agent would rather report 0 instead
of 1 given that all other agents follow spos :
τ (0, N − 1) > τ (1, N − 1);

(6)

• sneg (always reporting 0) is not NE when a rational agent would rather report 1
instead of 0 given that all other agents follow sneg ;
τ (1, 0) > τ (0, 0);

(7)

• slie is not NE when at least one agent (either observing 1 or 0) would rather report
the truth. Given that other agents always lie, N − 1 − n reference reports will be
positive whenever n high quality signals were actually observed:
220

Mechanisms for Making Crowds Truthful

either

N
−1
X

¡
¢
P r[n|0] τ (0, N − 1 − n) − τ (1, N − 1 − n) > 0;

n=0

or

N
−1
X

¡
¢
P r[n|1] τ (1, N − 1 − n) − τ (0, N − 1 − n) > 0;

(8)

n=0

The objective function (5), and the constraints (4), (6), (7) and (8) define the optimal
incentive-compatible payment mechanism that is also collusion-resistant in the sense explained in the beginning of this section (i.e., honest reporting is the unique pure-strategy
symmetric NE). To compute the payments, the mechanism designer must solve two linear
optimization problems, one corresponding to each branch of the constraint (8).
Proposition 4.1. Collusion-resistant, incentive-compatible rewards require minimum N =
4 agents.
Proof. This Proposition is a direct consequence of Proposition 3.1, once we consider the
supplementary constraints (7) and (6) that prevent high rewards on unanimous agreement.
As we discussed in the proof of Proposition 3.1, any incentive compatible reward mechanism
requires two distinct configuration of reference reports – denoted n1 and n2 – such that:
• under the configuration n1 (i.e., n1 reference reports are positive) an agent reporting
0 is rewarded more than an agent reporting 1: e.g., τ (0, n1 ) > τ (1, n1 )
• under the configuration n2 (i.e., n2 reference reports are positive) an agent reporting
1 is rewarded more than an agent reporting 0: e.g., τ (1, n2 ) > τ (0, n2 )
• n1 < n2 (proven by Lemma 3.1)
The collusion on the positive report (all agents report 1) can be prevented only if n2 6= N −1,
because otherwise τ (1, N − 1) would be greater than τ (1, N − 1), and spos would be a NE.
Likewise, the collusion on the negative report (all agents report 0) can be prevented only
if n1 6= 0 because otherwise τ (0, 0) > τ (1, 0), and sneg would be a NE. Unless N ≥ 4 the
constraints n1 6= 0; n1 < n2 and n2 6= N − 1 cannot be simultaneously satisfied. In other
words, there must exist a rich enough set of possible configuration of reference reports in
¤
order to satisfy both collusion resistance and incentive compatible constraints.
Taking the plumber example described in Section 2 and N = 4 agents, the conditional
distribution of the reference reports can be computed according to Eq. (1):
0
1

P r[0|·]
0.4179
0.0255

P r[1|·]
0.2297
0.0389

P r[2|·]
0.1168
0.2356

P r[3|·]
0.2356
0.7

When the experience is negative, the two types (θG and θB ) become almost equally likely
in the agent’s private belief. The mix between the distribution of reference reports induced
by the two types generates the U-shaped distribution described by the first row of the
table. However, when the experience is positive, the good type becomes dominant, and the
distribution of reference reports is almost entirely dictated by P r[n|θG ] (the second row of
the table). The optimal collusion-resistant, incentive-compatible payment mechanism are
the following:
221

Jurca & Faltings

τ (·, ·)
0
1

0
0
ε

1
12.37
0

2
0
6.29

3
ε
0

where ε is a small positive value, and the guaranteed margin for truth-telling is Λ = 1. For
any N > 4 the payment mechanism looks the same and rewards a report if all but one of
the other agents agree with the submitted report. In the same time, opposing consensus is
rewarded by a small amount ε.
Payments with exactly the same structure represent a general solution of the design
problem in this context. Moreover, the payments always exist:
Proposition 4.2. Given any set of types Θ, probability distributions P r[1|θ], prior belief
over types P r[θ], and number of agents N ≥ 4, the following payment system has honest
reporting as the unique symmetric NE:
τ (0, n) = 0, ∀n 6= 1, N − 1; τ (1, n) = 0, ∀n 6= 0, N − 2; τ (0, N − 1) = τ (1, 0) = ε

P r[1|1]

 Λ P r[1|0]P r[1|1]−P r[N −2|0]P r[N −2|1] if condition A
P r[1|0]
Λ P r[N −2|0]P r[N −2|1]−P r[1|0]P r[1|1] if condition B
τ (0, 1) =


P r[N −2|1]+P r[N −2|0]
Λ P r[1|0]P
otherwise
r[N −2|1]−P r[N −2|0]P r[1|1]

P r[N −2|1]

 Λ P r[1|0]P r[1|1]−P r[N −2|0]P r[N −2|1] if condition A
P r[N −2|0]
Λ P r[N −2|0]P r[N
if condition B
τ (1, N − 2) =
−2|1]−P r[1|0]P r[1|1]


P r[1|1]+P r[1|0]
Λ P r[1|0]P r[N −2|1]−P r[N −2|0]P r[1|1] otherwise

P r[1|0]P r[1|1] > P r[N − 2|0]P r[N − 2|1]


P r[N − 2|1] > P r[1|1]
A=
P r[N − 2|1]2 − P r[1|1]2 > P r[1|0]P r[1|1] − P r[N − 2|0]P r[N − 2|1]


P r[N − 2|0]P r[N − 2|1] > P r[1|0]P r[1|1]
^


P r[1|0] > P r[N − 2|0]
B=
P r[1|0]2 − P r[N − 2|0]2 > P r[N − 2|0]P r[N − 2|1] − P r[1|0]P r[1|1]


^

Proof. It is straight-forward to check that for ε small enough, the payments described in
the proposition verify the constraints (4), (6) and (7). Moreover, these payments minimize
the expected payment to an honest reporter.
¤
4.1.2 Pareto-optimal Nash equilibrium.
A less strict notion of collusion resistance requires honest reporting to be a Pareto-optimal
NE. The intuition is that any stable (i.e., equilibrium) coalition will necessarily make some
colluders worse off than in the honest equilibrium. Assuming non-transferable utilities,
colluders that benefit from the coalition cannot subsidize the ones that make a loss, and
hopefully, the latter will refuse to join the coalition in the first place. As we will see towards
the end of this subsection, payment mechanisms where honesty is a Pareto-optimal NE will
be significantly cheaper than the payments designed to have a unique honest NE.
The payment mechanism that has honest reporting as a Pareto-optimal equilibrium
solves the following optimization problem:
222

Mechanisms for Making Crowds Truthful

LP 4.1.
N
−1
N
−1
h
i
X
X
min E V (s¯i , s̄−i ) = P r[1]
P r[n|1]τ (1, n) + P r[0]
P r[n|0]τ (0, n);
n=0

s.t.

N
−1
X

n=0

³

´
P r[n|1] τ (1, n) − τ (0, n) ≥ Λ;

n=0
N
−1
X

³
´
P r[n|0] τ (0, n) − τ (1, n) ≥ Λ;

n=0

£
¤
τ (1, N − 1) < E V (s̄i , s̄−i ) ;
£
¤
τ (0, 0) < E V (s̄i , s̄−i ) ;
¡
¢

 PN −1
_
n=0 P r[n|0]¡τ (0, N − 1 − n) − τ (1, N − 1 − n)¢ > 0
P
N −1


P r[n|1]¤ τ (1, N
£n=0 lie
£ − 1 − n)¤− τ (0, N − 1 − n) > 0
lie
E V (si , s−i ) < E V (s̄i , s̄−i ) ;
τ (0, n), τ (1, n) ≥ 0; ∀n = {0, 1, . . . , N − 1};

The first two constraints make honest reporting a Nash equilibrium. The next two
constraints prevent lying colluders on spos or sneg to get higher rewards than in the honest
equilibrium. These constraints are always easier to satisfy than the constraints (6), (7)
which prevent equilibria on spos and sneg . The last constraint requires that the symmetric
profile where every agent lies is either not a NE, or that it generates an expected payoff
lower than the honest equilibrium. The expected payoff to an agent reporting according to
slie when everybody else reports according to slie is:
−1 ³
´
£
¤ NX
lie
E V (slie
P r[n|0]P r[0]τ (1, N − 1 − n) + P r[n|1]P r[1]τ (0, N − 1 − n) ;
i , s−i ) =
n=0

One remark about LP 4.1 is that it is not always optimal to only consider the constraint
that limits the expected payoff of a colluder on slie below the expected payoff obtained in
the honest equilibrium (i.e., the third inequality of the disjunctive constraint of LP 4.1).
Numerical simulations performed on random problems show that for 40- 50% of the problems
the collusion-resistant payments are cheaper by eliminating altogether the symmetric lying
equilibrium on slie : i.e., either the first, or the second inequality from the last constraint of
LP 4.1 are easier to satisfy than the third inequality.
In either case, the resulting optimal payments have the following structure:
£
¤
• τ (0, 0) = τ (1, N − 1) = E V (s̄i , s̄−i ) − ε. These values prevent the lying coalitions
on spos or sneg to Pareto-dominate the honest reporting equilibrium;
• τ (0, 1) > 0 and τ (1, N − 2) > 0 are scaled to satisfy the incentive-compatibility
constraints, and the “easiest” of the three inequalities that prevent a coalition on slie ;
• the other payments are 0.
For the plumber example in Section 2 the payments are the following:
τ (·, ·)
0
1

0
1.30
0

1
4.52
0
223

2
0
1.26

3
0
1.30

Jurca & Faltings

These payments are much smaller than the ones generated by a mechanism where honest
reporting is the unique equilibrium. We therefore observe a fundamental tradeoff between
the strongness of collusion resistance guarantees offered by the mechanism, and the price
the mechanism has to pay to enforce these guarantees. For the collusion scenario described
in this section, Proposition 4.2 shows that it is always possible to design a mechanism
where honest reporting is the unique equilibrium. Nevertheless, a mechanism where honest
reporting is just Pareto-optimal, not unique, can be significantly cheaper. We will see the
same tradeoff in all subsequent scenarios.
Before we move on to the next collusion scenario, let us briefly analyze the influence of N
(i.e., the number of reports available to the mechanism) on the properties of the mechanism.
Jurca and Faltings (2006) show that the incentive-compatibility constraints are easier to
satisfy when N becomes larger. Intuitively, this property is a consequence of the structure of
the design problem: the number of constraints in LP 3.1 is independent on N , however, the
number of variables increases with N . Therefore, the dual of LP 3.1 has a constant number
of variables, but an increasing number of constraints. Moreover, the constraints of the dual
are also harder to satisfy, which means that the maximization objective of the dual can only
decrease with N . Hence the objective of the primal, i.e., the cost of the mechanism, also
decreases with N . Without going into the technical details, the same is true for collusionresistant mechanisms: for larger values of N , the collusion-resistance constraints become
easier to satisfy and the mechanism has a lower cost. All subsequent sections will maintain
this property: more information helps the mechanism designer to specify better targeted
rewards, which in turn decreases the total cost of the mechanism.
4.2 Full Coalitions on Asymmetric Strategies, Non-Transferable Utilities
The next collusion scenario we are considering is when all N agents can coordinate on
asymmetric collusion strategies, without being able to make side-payments from one to
another. Each of the N agents can have a different reporting strategy, and the collusion
strategy profile is denoted by s = (si ), i = 1, . . . , N , where si ∈ S is the reporting strategy
of agent i.
We distinguish between two cases, when the communication (and therefore the coordination on the collusion strategy profile) happens before or after the agents perceive the
quality signals from the product they purchase. In the latter case, no payment scheme can
satisfy the incentive-compatibility constraints. In the former case, honest reporting can
never be a unique Nash equilibrium of the mechanism; however, honest reporting can be a
Pareto-optimal Nash equilibrium.
Proposition 4.3. When agents communicate and coordinate their reports after perceiving
the quality signals, strict incentive-compatible payment mechanisms do not exist.
Proof. Consider two settings, that are identical except for the observation of agent i. In
setting I, agent i observes oi = 0, in setting II, agent i observes oi = 1; in both settings the
other agents observe n high quality signals. An incentive-compatible mechanism requires i
to report 0 in setting I, and 1 in setting II. Assume all other agents report truthfully; during
the communication phase (happening after signals have been perceived) agent i learns in
both settings that the reference reports contain n positive reports. An incentive-compatible
payment mechanism requires that:
224

Mechanisms for Making Crowds Truthful

• τ (0, n) > τ (1, n) - honest reporting is strictly better for i in setting I ;
• τ (1, n) > τ (0, n) - honest reporting is strictly better for i in setting II;
Clearly this is impossible.

¤

The previous proposition formalizes the intuition that truth-telling may only be an exante Nash equilibrium. The reference reports must be unknown to the agent in order to
allow the design of incentive-compatible payments.
4.2.1 Unique Nash equilibrium.
When the communication takes place before the agents observe the signals, incentivecompatible payments do exist, but always accept other Nash equilibria where agents lie:
Proposition 4.4. When agents communicate and coordinate their reports before perceiving
the quality signals, no payment mechanism has a unique honest reporting Nash equilibrium.
Proof. The proof shows that a full coalition can always find a profile of constant reporting
strategies, s = (si ), i = 1, . . . , N , si ∈ {sneg , spos } that is a NE.
We define the family of reporting strategy profiles s(n) = (si ) where n out of N agents
always report 1, and the other N − n agents always report 0: i.e.,
si = spos , ∀i ∈ A1 ; si = sneg , ∀i ∈ A0 ;
|A1 | = n, |A2 | = N − n;
A1 ∩ A0 = ∅; A1 ∪ A0 = {1, 2, . . . , N };

(9)

Assume that the payment mechanism defined by τ (·, ·) accepts honest reporting as
the unique NE. We have seen in Section 3 that the incentive-compatible constraints (4)
imply the existence of n1 < n2 ∈ {0, 1, . . . , N − 1} such that τ (0, n1 ) > τ (1, n1 ), and
τ (1, n2 ) > τ (0, n2 ).
With non-transferable utilities, the strategy profile s(n2 + 1) is not a NE if and only if
one of the n2 + 1 agents that should report 1 would rather report 0:
τ (0, n2 ) > τ (1, n2 );

or one of the N − n2 − 1 agents that should report 0 would rather report 1:
τ (1, n2 + 1) > τ (0, n2 + 1);

The first inequality cannot be true by the choice of n2 ; therefore, it must be that
τ (1, n2 + 1) > τ (0, n2 + 1).
Similarly, s(n2 + 2) is not a NE iff either τ (0, n2 + 1) > τ (1, n2 + 1) (impossible), or
τ (1, n2 + 2) > τ (0, n2 + 2). Continuing this argument we find that τ (1, N − 1) > τ (0, N − 1)
which makes s(N ) (i.e., all agents report 1) a Nash equilibrium. Hence the result of the
proposition.
¤
Proposition 4.4 holds regardless the number of reports, N , available to the reputation
mechanism. The proof shows that all incentive-compatible reward schemes have the property that for some n ∈ {0, . . . , N − 1}, either τ (1, n) > 0 and τ (1, n + 1) < τ (0, n + 1), or
225

Jurca & Faltings

τ (1, N − 1) > 0. In the first case, the coalition can adopt the lying strategy where n + 1
agents always report 1, and N −n−1 agents always report 0. The structure of the payments
makes such a coalition stable, as no agent finds it profitable to deviate from the coalition.
In the second case the payment scheme is vulnerable to everybody always reporting 1.
4.2.2 Pareto-optimal Nash equilibrium.
While lying equilibria always exist in this scenario, they do not necessarily Pareto-dominate
the honest reporting NE. Take for example the incentive-compatible payments that solve
LP 3.1, with the additional constraints that τ (0, 0) = 0 and τ (1, N − 1) = 0. A stable
coalition can form on the strategy profiles s(n2 + 1) or s(n1 ), where n2 + 1 (respectively n1 )
agents always report 1 and the others always report 0 regardless of their observation. This
equilibrium, however, does not Pareto-dominate the truthful one: the agents that report 0
do not get any reward, whereas they do get rewarded in the honest equilibrium.
The payment mechanism can be further improved by setting τ (0, n1 −1) = τ (1, n2 +1) =
ε, where ε is some small positive value. This modification eliminates the equilibria s(n2 + 1)
and s(n1 ) and instead introduces the equilibria s(n2 +2) and s(n1 −1). Both these equilibria
are extremely unattractive (some agents get paid ε, while others don’t get paid at all) and
are dominated by the honest equilibrium.
Proposition 4.5. Given the set of types Θ, the conditional probabilities P r[1|θ], the prior
belief over types P r[θ], and N = 4 agents, the following payment scheme has honest reporting
as a Pareto-optimal Nash equilibrium:
τ (·, ·)
0
1

0
ε
0

1
x>0
0

2
0
y>0

3
0
ε

The values x and y depend on the probabilities P r[1|θ] and P r[θ], and ε has a small positive
value.
Proof. The payments here are similar to those of Proposition 4.2 except that consensus is
rewarded with some small amount ε instead of being discouraged. In this way the mechanism
has only three NE: honest reporting, always reporting 1 or always reporting 0. Both lying
equilibria, however, generate much lower revenues (assuming, of course, that ε is small
enough); therefore, honest reporting is a Pareto-optimal equilibrium. The proof that the
mechanism has only 3 NE is based on brute force: for x and y taking the values specified in
Proposition 4.2, we verify that no other strategy profile is a NE. The details are presented
in Appendix B.
¤
For general reward mechanisms based on N > 4 reports, honest reporting can become
a Pareto-optimal NE by considering all lying strategy profiles, s, and adding to the design
problem either of the following linear constraints:
V (si , s−i |oi ) < V (s∗i , s−i |oi ) for some i, oi and s∗i ;
£
¤
£
¤
E V (si , s−i ) < E V (s̄i , s̄−i ) for some i;

(10)

The first constraint ensures that the strategy profile s is not a NE, and consists of a disjunction of at most 8 linear inequalities: for each reporting strategy si = (si (0), si (1)) ∈ S,
226

Mechanisms for Making Crowds Truthful

the agent reporting according to si has the incentive to deviate either when observing 0, or
when observing 1. There are four strategies in S and only one possible deviation for each
observed signal, hence the 8 inequalities. The second constraint ensures that s does not
Pareto-dominate the honest equilibrium, and consists of a similar disjunction of at most 4
inequalities. Note that any two strategy profiles that represent different permutations of the
same set of N reporting strategies will generate the same constraints. Therefore, there are
³ N +3 ´
different constraints imposing honesty as a Pareto-optimal NE, each consisting
3
of a disjunction of at most 12 linear inequations. The resulting optimization problem is a
disjunctive linear program which can be transformed into a mixed integer linear program
(Sherali & Shetty, 1980).
Unfortunately, the complexity of the resulting optimization problem is exponential in
the number N of reporters considered by the payment mechanism. Since the payment
mechanism depends on the current belief over the types θ, the reputation mechanism might
be required to frequently update the payments in order to reflect the changing beliefs. For
large values of N this is clearly infeasible.
We therefore consider a special family of payment mechanisms that can be designed
efficiently to make honest reporting a Pareto-optimal NE. The basic idea is to consider
payments similar to those from Proposition 4.5, that reward a report only when all but
one of the reference reports agree. Consensus on the positive or negative feedback is also
rewarded by a small amount ε, but all other payments are zero:
τ (·, ·)
0
1

0
ε
0

1
x>0
0

2. . . N-3
0. . . 0
0. . . 0

N-2
0
y>0

N-1
0
ε

Figure 1: Payment mechanism for N > 4 agents.
The payment mechanism now depends on only 2 parameters, x and y that must be scaled
to prevent any other lying strategy profile to become a NE Pareto-dominating the honest
equilibrium. Note that no strategy profile where more than one agent reports according
to spos or sneg can become a successful collusion strategy. If at least two agents always
report 1, none of the other agents will ever want to report 0 (as τ (0, n) = 0 for any n ≥ 2).
Similarly if at least two agents always report 0, none of the other agents will ever want
to report 1. Nevertheless, both consensus equilibria yield very small payoffs, significantly
lower than the payoff of the honest reporting equilibrium.
Following the intuition from the proof of Proposition 4.5, many of the remaining lying
strategy profiles cannot be a NE regardless of the values of x and y. Let us consider the set
of potential lying equilibrium strategy profiles:
S̃ = {(n0 × sneg , n1 × spos , n̄ × s̄, nl × slie )| n0 + n1 + n̄ + nl = N };

(11)

where n0 ∈ {0, 1} agents always report 0, n1 ∈ {0, 1} agents always report 1, n̄ ∈
/ {N −1, N }
agents report honestly and nl agents always lie. The cardinality of S̃ is 4(N −1). The profile
s ∈ S̃ is a NE if and only if for any strategy si ∈ s, the agent reporting according to si does
not have the incentive to deviate to another reporting strategy given that all other agents
keep reporting according to s−i . Let oi ∈ Q2 be the signal observed by agent i. The report
227

Jurca & Faltings

prescribed by strategy si is ri = si (oi ) ∈ Q2 , and given that ε is small enough to be ignored,
the expected payoff to agent i is:
P r[1|oi , s−i ] · x if ri = 0
P r[N − 2|oi , s−i ] · y if ri = 1

where P r[1|oi , s−i ] and P r[N − 2|oi , s−i ] are the probabilities that exactly 1, respectively
N − 2 of the other N − 1 agents will report positively given the observation oi and the
strategy profile s−i .
The deviation to reporting 1 − ri is not profitable for some observation oi if and only if:
P r[1|oi , s−i ] · x − P r[N − 2|oi , s−i ] · y > 0 if ri = 0
P r[N − 2|oi , s−i ] · y − P r[1|oi , s−i ] · x > 0 if ri = 1

The conditions that make s a NE can therefore be expressed as a set of at most 8
inequalities with the following structure:
aj x − bj y > 0; aj , bj > 0
−ak x + bk y > 0; ak , bk > 0
b

If maxj ajj > mink abkk the above system of inequations is infeasible, so that for any positive
values of x and y the corresponding strategy profile s can not be a NE. However, when
b
maxj ajj < mink abkk , there are values of x and y which can make s a NE, and therefore, in
the design problem we must specify a constraint that prevents s from Pareto-dominating
the honest NE. The corresponding constraint will be a disjunction of inequalities: 2 for
restricting x and y to values that do not make s a NE, at most 3 that limit the expected
payments of colluders below the expected payment of the honest equilibrium.
Since there are 4(N − 1) potential lying strategy profiles, the optimization problem
defining x and y can have up to 4N −2 constraints: 2 linear incentive-compatible constraints
and up to 4(N − 1) disjunctive linear constraints. The transformation to a mixed integer
linear program involves adding up to 4(N − 1) integer variables, which in the worst case,
can result in exponential-time (in N ) complexity of the design problem.
Fortunately, we can eliminate most of the strategy profiles in S̃ analytically. It turns
out that the payment mechanism from Figure 1 does not accept as a Nash Equilibrium
any strategy profile where at lest one agent reports truthfully and another agent reports
according to slie :
Proposition 4.6. Let s = (n0 × sneg , n1 × spos , n̄ × s̄, nl × slie ) ∈ S̃ be a strategy profile
where n0 agents always report 0, n1 agents always report 1, n̄ agents report honestly and nl
agents always lie. If (n̄ 6= 0 ∧ nl 6= 0) or (n0 = 1 ∧ n1 = 1), s cannot be a Nash equilibrium
of the payment mechanism described in Figure 1.
Proof. For the reasons explained above, we have restricted the number of agents always
reporting 0 or 1 to the following cases: (i) n0 = 0, n1 = 0, (ii) n0 = 1, n1 = 0, (iii)
n0 = 0, n1 = 1 and (iv) n0 = 1, n1 = 1. For all cases, we consider strategy profiles where
n̄ ≥ 1 agents are honest, and the remaining agents lie according to slie . For each such profile
we show that no values of x and y can simultaneously satisfy the equilibrium constraints of
both an honest and a lying agent. Moreover, when n0 = n1 = 1 we show that the strategy
228

Mechanisms for Making Crowds Truthful

profiles where all other agents are honest or all other agents lie, cannot be Nash equilibria.
The technical details of the proof are given in Appendix C.
¤
The remaining lying strategy profiles to be considered for computing the values of x and
y are the following:

• s1 = (N × slie ) when all agents lie; the constraints to prevent this equilibrium are also
considered in LP 4.1;
¡
¢
• s2 = sneg , (N − 1) × slie when one agent always reports 0, and all other agents lie;
¡
¢
• s3 = spos , (N − 1) × slie when one agent always reports 1, and all other agents lie;

A solution for x and y can therefore be found in constant time.
4.3 Partial Coalitions on Symmetric Strategies, Non-Transferable Utilities
In this section we move our attention from full to partial coalitions, where not all agents
can become part of a lying coalition. The non-colluders are assumed to report honestly, and
their reports can be used by the mechanism to deter any “partial” lying coalition. Jurca
and Faltings (2005) show that trusted reports (reports trusted to be true) are useful in
preventing lying coalitions; nevertheless, an important difference from our previous work,
is that here, honest reports cannot be identified and selectively used by the reputation
mechanism.
4.3.1 Unique and Pareto-otpimal Nash equilibrium.
We start as in Section 4.1, by assuming only symmetric collusion strategies and no sidepayments available among colluders. The number of colluders is Ncol < N , and the remaining N̄ = N − Ncol report honestly. There are 3 symmetric pure lying strategies,
and appropriate constraints can ensure that none of them becomes a Nash equilibrium, or
Pareto-dominates the honest equilibrium.
Concretely, let P¯r[·|·] be the probability distribution of the reports submitted by noncolluders, such that P¯r[n|oi ] is the probability that n out of N̄ agents report positively given
the observation oi ∈ Q2 . Likewise, let Pˆr[·|·] be the probability distribution of the reports
submitted by the other colluders: i.e., Pˆr[n|oi ] is the probability that n out of Ncol − 1
colluders report positively.
The payment scheme that makes honest reporting the unique Nash equilibrium for the
colluders and minimizes the expected payment to an honest reporter solves the following
optimization problem:
229

Jurca & Faltings

min
s.t.

£
¤
E V (s̄i , s̄−i ) ;
N
X

¡
¢
P r[n|0] τ (0, n) − τ (1, n) ≥ Λ;

n=0
N
X

¡
¢
P r[n|1] τ (1, n) − τ (0, n) ≥ Λ;

n=0
N̄
_ ³X
oi ∈Q2

n=0

N̄
_ ³X
oi ∈Q2

´
¡
¢
P¯r[n|oi ] τ (0, n) − τ (1, n) < 0

n=0

N̄
_ ³X
oi ∈Q2

´
¡
¢
P¯r[n|oi ] τ (1, n + Ncol − 1) − τ (0, n + Ncol − 1) < 0

P¯r[n|oi ]

n=0

Ncol −1

X

´
¡
¢
Pˆr[Ncol − 1 − x|oi ] τ (1 − oi , n + x) − τ (oi , n + x) < 0

x=0

τ (0, n), τ (1, n) ≥ 0; ∀n = {0, 1, . . . , N − 1};

where besides the first two incentive-compatibility constraints, the third, forth and fifth
constraints encourage deviations from the symmetric collusion on spos , sneg and slie respectively. The resulting optimization problem is a disjunctive linear program.
Finally, honest reporting can be made a Pareto-optimal equilibrium by modifying the
optimization problem such that the disjunctive constraints preventing an equilibrium on
the lying symmetric strategies, also specify inequalities for limiting the payoff received by
a colluder below the expected payment of an honest reporter:
• colluders on spos gain less than in the honest equilibrium:
N̄
X

£
¤
P¯r[n|oi ]τ (1, n + Ncol − 1) < E V (s̄i , s̄−i ) ;

n=0

• colluders on spos gain less than in the honest equilibrium:
N̄
X

£
¤
P¯r[n|oi ]τ (0, n) < E V (s̄i , s̄−i ) ;

n=0

• colluders on slie expect to gain less than in the honest equilibrium:
X
oi =0,1

P r[oi ]

N̄
X
n=0

P¯r[n|oi ]

NX
col −1

£
¤
Pˆr[Ncol − 1 − x|oi ]τ (1 − oi , n + x) < E V (s̄i , s̄−i ) ;

x=0

Our numerical simulation show that the optimization problem defined above always
accepts a solution. We therefore conjecture that it is always possible to design incentivecompatible, collusion resistant rewards under the restrictions discussed in this section. A
formal proof of this result remains for future work.
4.4 Partial Coalitions on Asymmetric Strategies, Non-Transferable Utilities
As opposed to Section 4.3, in this section we consider a more practical scenario where
colluders can also employ asymmetric lying strategies: i.e., all strategy profiles s = (si ),
230

Mechanisms for Making Crowds Truthful

i = 1, . . . Ncol . Side payments are not allowed among colluders, and we are only concerned
with the equilibrium for the Ncol agents that can become part of the coalition; the remaining
N̄ = N − Ncol agents are assumed to report honestly.
4.4.1 Unique and Pareto-optimal Nash equilibrium.
The mechanism that makes honest reporting the only Nash equilibrium follows the guidelines derived in Proposition 4.5 for the scenario where all agents can collude: namely the
reputation mechanism must consider N = 4 reports, the mechanism rewards consensus
with a small positive payment ε, and otherwise pays a report if and only if three out of
four reports agree. The proof of Proposition 4.5 shows that such a payment scheme accepts
three Nash equilibria:
• all agents report honestly,
• all agents always reports 0, and
• all agents always report 1.
.
The restriction made in this section that at least one other does not become part of the
coalition (and thus reports the truth) restricts the set of equilibria to only one, where all
agents report truthfully. Even when the remaining three agents collude, the only NE under
the payment mechanism described by Proposition 4.5 is to report the truth.
General payment mechanisms based on N > 4 agents can be designed following the
same methodology as in Section 4.2: we will consider all strategy profiles the colluders can
use, and add constraints to the design problem such that (i) no lying strategy profile is a
NE, or (ii) no NE lying strategy profile Pareto-dominates the honest reporting NE.
Concretely, let SNcol be the set of strategy profiles the colluders can use:
SNcol = {(n0 × sneg , n1 × spos , n̄ × s̄, nl × slie )|n0 + n1 + n̄ + nl = Ncol }

where s = (n0 × sneg , n1 × spos , n̄ × s̄, nl × slie ) ∈ SNcol is the strategy profile where n0 out
of Ncol colluders always report 0, n1 colluders always report 1, n̄ colluders report honestly,
and nl colluders always lie. When colluders report according to the strategy profile s, let
(s, s̄) = (n0 × sneg , n1 × spos , (n̄ + N̄ ) × s̄, nl × slie ) be the strategy profile used by the N
agents, where the N̄ = N − Ncol non-colluders report honestly.
Honest reporting is the unique Nash equilibrium for colluders if and only if:
¡
¢
¡
¢
V si , (s−i , s̄)|oi < V s∗i , (s−i , s̄)|oi

(12)

for some colluder i and observation oi . Similarly, s does not Pareto-dominate the honest
reporting equilibrium if:
h ¡
£
¤
¢i
E V si , (s−i , s̄) < E V (s̄i , s̄−i )

(13)

for some colluder i.
Let’s compare the constraints expressed above with the similar constraints from Section
4.2 described by Eq. (10). We note two important differences. First, the inequalities apply
231

Jurca & Faltings

only to the Ncol colluders, not to the entire set of agents, so that a strategy profile that
is not a NE for the N agents, might still be a Nash equilibrium for colluders. Take, for
example, the case where all colluders lie: i.e., s = (Ncol × slie ). The strategy profile of all
agents is therefore (s, s̄) = (Ncol × slie , N̄ × s̄). It may well be possible that:
• a lying colluder finds it optimal to report according to slie given that N̄ agents report
honestly and Ncol − 1 agents report lies;
• an honest reporter would rather file a negative report after a positive experience, given
that N̄ − 1 agents report honestly and Ncol agents lie.
So (s, s̄) is not a NE when considering all agents, but it is an equilibrium for the subset of
colluders. Similarly, it is possible that colluders gain better under (s, s̄) and honest reporters
gain less, such that (s, s̄) Pareto-dominates the honest equilibrium for the colluders, but not
for all agents. The constraints (12) and (13) are therefore stricter than their counterparts
(10), as non-colluders are assumed to unconditionally report the truth without taking into
account the actions of a lying coalition.
Second, we can separately consider the constraint (12), when honest reporting is to be
enforced as the unique NE for colluders, or the disjunction of constraints (12) and (13),
when honest reporting is to be enforced as a Pareto-optimal NE for colluders. The presence
of honest reports makes it possible to design payment mechanisms where honesty is the
unique NE, an alternative that was not available under the assumptions of Section 4.2. In
both cases, the constraints preventing lying equilibria (or preventing lying equilibria from
dominating the honest equilibrium) can be represented by a disjunction of linear inequalities,
and consequently, by a conjunction of mixed integer linear constraints. The resulting design
problem is a MILP, and, as discussed in Section 4.2, has a worst-time complexity that grows
exponentially with the number N of agents.
As in Section 4.2, we can use the payment mechanism from Figure 1 to reduce the
complexity of the design problem when honest reporting is the unique or a Pareto-optimal
NE. From Proposition 4.6, we know that:
• in any NE, at most one colluder reports according to sneg or spos ;
• an honest reporter and a liar cannot both regard their strategies as optimal given that
at most one of the other agents reports according to sneg or spos
Therefore, the remaining colluding strategy profiles that must be considered when designing the payments x and y are the following:
• (Ncol × slie ) when all colluders lie;
• (sneg , (Ncol − 1) × slie ) when one colluder always reports 0 and the others always lie;
• (spos , (Ncol − 1) × slie ) when one colluder always reports 1 and the others always lie;

232

Mechanisms for Making Crowds Truthful

4.4.2 Stronger equilibrium notion.
Before evaluating the reward mechanisms that accepts a unique or a Pareto-optimal honest
reporting Nash equilibrium, let us note that the subgame restricted to the strategies of the
Ncol colluders accepts a stronger equilibrium concept than Nash equilibrium. When the
fraction of colluders is small enough, the available honest reports can make it such that
any colluder has the incentive to report honestly no matter what the other colluders are
reporting. We abuse the notation slightly and call this equilibrium a dominant equilibrium.
Nevertheless, honest reporting is a dominant strategy only given the N̄ honest reporters.
If P¯r[·|·] describes the probability distribution of the N̄ honest reports, and c is the
number of positive reports submitted by the other Ncol − 1 colluders, the payments τ (·, ·)
that make honest reporting the dominant strategy, and minimize the payment to an honest
reporter, are defined by the following optimization problem:
LP 4.2.
N
−1
N
−1
X
X
£
¤
min E V (s̄i , s̄−i ) = P r[1]
P r[n|1]τ (1, n) + P r[0]
P r[n|0]τ (0, n);
n=0

s.t.

N̄
X

n=0

¡
¢
P¯r[n|0] τ (0, n + c) − τ (1, n + c) ≥ Λ;

n=0
N̄
X

¡
¢
P¯r[n|1] τ (1, n + c) − τ (0, n + c) ≥ Λ;

n=0

∀c ∈ {0, . . . Ncol − 1},
τ (0, n), τ (1, n) ≥ 0; ∀n = {0, 1, . . . , N − 1};

The remaining question is how large may the colluding fraction be, such that collusionresistant, incentive-compatible mechanisms exist.

Proposition 4.7. When more than half of the agents collude, (i.e., Ncol > N/2), no
incentive-compatible payment mechanism can make truth-telling the dominant strategy for
the colluders.

Proof. The intuition behind the proof is the following: When Ncol > N/2, the Ncol − 1
colluders submit at least as many reports as the remaining N − Ncol honest reporters.
Therefore, any sequence of honest reports, can be ‘corrected’ by a carefully chosen sequence
of colluding reports, such that lying is profitable.
Formally, let us extract from the system of inequalities defined in LP 4.2, the subset
corresponding to c = {0, . . . , N̄ }. This subset exists since N̄ < Ncol − 1. Let us form the
233

Jurca & Faltings

following optimization problem:
min

P r[1]

N
−1
X

P r[n|1]τ (1, n) + P r[0]

n=0
N̄
X

s.t.

N
−1
X

P r[n|0]τ (0, n);

n=0

¡
¢
P¯r[n|0] τ (0, n + c) − τ (1, n + c) ≥ Λ; ∀c = 0 . . . N̄

n=0
N̄
X

¡
¢
P¯r[n|1] τ (1, n + c) − τ (0, n + c) ≥ Λ; ∀c = 0 . . . N̄

n=0

τ (0, n), τ (1, n) ≥ 0; ∀n = {0, 1, . . . , N − 1};

Let yc0 and yc1 be the dual variables corresponding to the constraints where the colluding
agents report c positive signals, and the agent observes 0, respectively 1. The dual problem
becomes:
Ncol −1

max

Λ

X

(yc0 + yc1 );

c=0

s.t.

n
X
c=0
n
X

P¯r[n − c|0]yc0 − P¯r[n − c|1]yc1 ≤ P r[0]P r[n|0]; ∀n = 0 . . . N̄
P¯r[n − c|1]yc1 − P¯r[n − c|0]yc0 ≤ P r[1]P r[n|1]; ∀n = 0 . . . N̄

c=0
N̄
X

P¯r[N̄ + 1 − c|0]yc0 − P¯r[N̄ + 1 − c|1]yc1 ≤ P r[0]P r[N̄ + n + 1|0]; ∀n = 0 . . . N̄

c=n+1
N̄
X

P¯r[N̄ + 1 − c|1]yc1 − P¯r[N̄ + 1 − c|0]yc0 ≤ P r[1]P r[N̄ + n + 1|1]; ∀n = 0 . . . N̄

c=n+1

One can easily verify that the dual problem accepts as solutions:
yc1 = P¯r[c|0] · const,
yc0 = P¯r[c|1] · const;

(14)

for any positive constants. The dual problem is therefore unbounded, which makes the
primal infeasible.
¤
The bound from Proposition 4.7 is also tight. Consider the numerical example from Section 2, and assume the reputation mechanism has N = 4 reports. The following payments
are resistant to the collusion of Ncol = 2 agents:
τ (·, ·)
0
1

0
1.575
0

1
3.575
0

2
0
2.203

3
0
0.943

For example, if Alice observes 1, reporting 1 is better than reporting 0 for any report of
the other colluder:
P¯r[0|1]τ (1, 0) + P¯r[1|1]τ (1, 1) + P¯r[2|1]τ (1, 2) = 1.715;
P¯r[0|1]τ (0, 0) + P¯r[1|1]τ (0, 1) + P¯r[2|1]τ (0, 2) = 0.715;
P¯r[0|1]τ (1, 1) + P¯r[1|1]τ (1, 2) + P¯r[2|1]τ (1, 3) = 1.138;
P¯r[0|1]τ (0, 1) + P¯r[1|1]τ (0, 2) + P¯r[2|1]τ (0, 3) = 0.138;
234

Mechanisms for Making Crowds Truthful

where P¯r[0|1] = 0.0385, P¯r[1|1] = 0.1830 and P¯r[2|1] = 0.7785 are the probabilities that
0, 1, or 2 out of the N̄ = 2 non-colluders report positively, given that Alice observed high
quality.
In the general case, the design problem has 2Ncol different constraints, and therefore,
we should expect the budget required by the reputation mechanism to grow with Ncol .
We resort to numerical simulations and study the average cost of an incentive-compatible,
collusion-resistant reputation mechanism as the fraction of colluders increases. We randomly
generated 5000 problems as follows:
• the set of possible types is randomly chosen between 2 and 20;
• for each type, θ, the probability, P r[1|θ], that the buyers observe high quality is
randomly chosen between 0 and 1;
• we consider reward mechanisms for 5, 10, 15, 20 and 25 agents.
For each problem and every number of agents we varied the number of colluders from 1 to
N/2. Figure 2 plots the average normalized cost of the collusion-resistant mechanism as
a function of the colluding fraction, Ncol /N . One can see that collusion resistance comes
almost for free as long as less than one third of the population colludes. Above this bound
the cost increases exponentially, which makes most such mechanisms impractical.

average normalized cost

15
N=10
N=15
N=20
N=25
10

5

0
0

0.1

0.2
0.3
colluding fraction

0.4

0.5

Figure 2: The average cost of the mechanism as we increase the colluding fraction. The cost
is normalized to the cost of the corresponding incentive-compatible mechanism
that is not collusion-resistant.

Figure 2 seems to contradict the observation made in Section 4.1 that the mechanism
has lower cost for higher values of N . However, when the same costs are plotted on a
235

Jurca & Faltings

horizontal axis describing the absolute (not the relative) number of colluders, the order of
the lines is reversed: the red line showing the cost of a mechanism with the smallest number
of reference reports (N = 10) has the highest values.
We also used numerical simulations to investigate the tightness of the bound set by
Proposition 4.7. Table 2 presents the distribution of the maximum collusion threshold for
the randomly generated problems. For more than 95% of the problems we were actually able
max = bN/2c
to compute payment mechanisms that resist the maximum coalition size Ncol
described by Proposition 4.7. There are some settings, however, where the mechanism is
vulnerable to coalition fractions that are significantly smaller than one half. The sufficient
conditions that characterize the settings that accept robust mechanisms with exactly one
half of colluders is subject to future research.

max = bN/2c.
Table 2: Distribution of the maximum coalition bound. Ncol
max = 2
N = 5, Ncol
max = 5
N = 10, Ncol
max = 7
N = 15, Ncol
max = 10
N = 20, Ncol
max = 12
N = 25, Ncol

Distribution of max coalition size (in %) over
max , N max − 1, . . . , 1]
[Ncol
col
[99.98, 0.02]
[99.5, 0.36, 0.1, 0.04, 0]
[98.88, 0.54, 0.38, 0.08, 0.1, 0.02, 0]
[97.1, 0.86, 0.78, 0.56, 0.34, 0.2, 0.1, 0.04, 0.02, 0]
[96.3, 0.98, 0.76, 0.58, 0.48, 0.4, 0.24, 0.1, 0.1, 0.04, 0.02, 0]

We also compared the performance of the reward mechanisms that employ different
equilibrium concepts. Figure 3 compares the average normalized cost of a collusion-resistant
payment mechanism when honest reporting is: (i) the dominant strategy, (ii) the unique
NE, or (iii) the Pareto-optimal NE. The plots were generated by solving 100 randomly
generated problems, for N = 10 and N = 15 agents. Computing the payment mechanism
which satisfies the constraints (12) and (13) requires significantly more time, hence the
lower number of generated problems. Moreover, the capabilities of our solver were exceeded
for payments using more than 15 agents. Nevertheless, the loss in computational efficiency
is clearly rewarded by both lower cost of the mechanism, and coverage of greater coalitions.
4.5 Partial Coalitions on Asymmetric Strategies, Transferable Utilities
As a last scenario we assume that one strategic agent controls a number of fake online
identities, or sybils. From the agent’s perspective, the individual revenues obtained by each
sybil is irrelevant; the objective of the agent is to maximize the cumulated revenue obtained
by all sybils.
The fact that utilities are transferable makes the problem of the mechanism designer
significantly harder. In all previous scenarios, the constraints that made an incentivecompatible mechanism collusion-resistant ensured that lying coalitions are either unstable
or unprofitable. However, transferable utilities allow some colluders to subsidize others,
such that non-equilibrium colluding strategies can still exist. Therefore, the necessary (and
sufficient) condition for collusion resistance in this context requires that the cumulated
revenue of the coalition is maximized when reporting the truth.
236

Mechanisms for Making Crowds Truthful

2.5

2.2
Dominant EQ
Unique NEQ
Pareto−optimal NEQ

2

average normalized cost

average normalized cost

2

Dominant EQ
Unique NEQ
Pareto−optimal NEQ
1.5

1

1.8
1.6
1.4
1.2
1
0.8
0.6

0.5
1

2

3

4
5
6
number of colluders

7

8

9

2

(a) N=10 agents

4

6
8
10
number of colluders

12

14

(b) N=15 agents

Figure 3: Average normalized cost of collusion-resistant payment mechanism. Different
equilibrium concepts.

Another difference from the settings in Sections 4.2 and 4.4 is that colluders coordinate
their reporting strategy after observing the quality signals. This assumption is supported
by the interpretation that one strategic entity controls several fake online identities.
Concretely, we are looking for a payment mechanism with the following property: whenever Ncol colluding agents observe c high quality signals, their cumulated revenue is maximized when reporting c positive reports. An underlying assumption is that non-colluders
(the other N̄ = N − Ncol agents) are reporting honestly. The revenue of the coalition that
reports r (out of Ncol ) can be computed as follows. The r colluders that report positively
are rewarded τ (1, r − 1 + n), while the Ncol − r colluders that report negatively are rewarded
τ (0, r + n); n is the number of positive reports submitted by the (honest) non-colluders.
The expected revenue of the coalition is therefore:
V (r|c) =

N̄
X

³
´
P¯r[n|c] r · τ (1, r − 1 + n) + (Ncol − r) · τ (0, r + n) ;

(15)

n=0

where P¯r[n|c] is the probability that n out of N̄ honest agents report positively, given that
c out of Ncol colluders observed high quality signals.
Honest reporting is the best strategy for the coalition, when for all c ∈ {0, . . . Ncol },
arg maxr V (r|c) = c:
N̄
X
n=0

³
P¯r[n|c] c · τ (1, c − 1 + n) + (Ncol − c) · τ (0, c + n) − r · τ (1, r − 1 + n)
´

(16)

− (Ncol − r) · τ (0, r + n) ≥ Λ; ∀r 6= c ∈ {0, . . . Ncol }

The cheapest incentive-compatible, collusion-resistant payment mechanism minimizes
the objective function (5) under the linear constraints (16):
237

Jurca & Faltings

LP 4.3.
N
−1
N
−1
h
i
X
X
min E V (s̄i , s̄−i ) = P r[1]
P r[n|1]τ (1, n) + P r[0]
P r[n|0]τ (0, n);
n=0

s.t.

n=0

(16) is true, ∀c, r ∈ {0, . . . Ncol }, c 6= r
τ (0, n), τ (1, n) ≥ 0; ∀n = {0, 1, . . . , N − 1};

For the example described in Section 2, assuming that Alice controls Ncol = 3 different
online identities that may submit feedback about Bob, the following payments based on
N = 6 reports deter Alice from lying:
τ (·, ·)
0
1

0
20.85
45.54

1
0
28.78

2
0
0

3
0
0

4
4.40
0

5
9.98
4.31

Even if Alice controlled Ncol = 5 out of the N = 6 reports, we can still find payments
that make honest reporting rational. These payments, however, are significantly higher:
τ (·, ·)
0
1

0
3455
1530

1
0
5569

2
1378
4674

3
615
3736

4
0
0

5
1125
2585

It turns out that for the general case, one honest report is enough to allow the design
of incentive-compatible payments that also deter sybil attacks of size N − 1. An example
of such payments are presented in the proposition below:
Proposition 4.8. Given the set of types Θ, the conditional probabilities P r[1|θ], the prior
belief over types P r[θ] and a number N of reports, the following payments encourage honest
reporting from a strategic agent who controls N − 1 different reports:
SR(0, 0)
SR(1, 0)
SR(1, N − 1)
; τ (0, 1) =
; τ (1, N ) =
;
Ncol
Ncol
Ncol
(x + 1)SR(1, x) − xSR(0, x + 1)
τ (0, x + 1) =
; x = 1...N − 1
Ncol
(N − 1 − x)SR(0, x + 1) − (N − 2 − x)SR(1, x)
τ (1, x) =
; x = 1...N − 1
Ncol
τ (0, 0) =

where SR(i, j), i ∈ {0, 1}, j = {0, . . . , N − 1} is a proper scoring rule: e.g., SR(i, j) =
log(P¯r[i|j]).
Proof. The expected payment of an agent who controls N − 1 different identities, observes
c out of N − 1 positive signals and reports r positive reports to the reputation mechanism
can be computed as in Eq. (15):
³
´
V (r|c) = P r[0|c] r · τ (1, r − 1) + (N − 1 − r) · τ (0, r) +
³
´
P r[1|c] r · τ (1, r) + (N − 1 − r) · τ (0, r + 1)
= . . . = P r[0|c]SR(0, r) + P r[1|c]SR(1, r);
238

Mechanisms for Making Crowds Truthful

which by the definition of a proper scoring rule is strictly maximized when r = c: i.e.
V (c|c) − V (r|c) > 0 for all r 6= c. By scaling the scoring rule appropriately (i.e., multiplication and addition with a constant), honest reporting can be made better by lying with at
least the margin Λ.
¤
Proposition 4.8 grantees the existence of incentive-compatible collusion resistant rewards
when all but one report are controlled by the same strategic agent. However, as we have seen
for the example in Section 2, such payments can be very expensive, and hence unpractical.
We therefore used numerical simulations to evaluate the marginal cost of increasing collusion
resistance, as we increase the number of colluders (i.e., reports controlled by the same agent).
As in Section 4.4, we generated 5000 random problems and computed the optimal payments
for N = 5,10,15,20 and 25 reports. For each case, we gradually increased the coalition size
(i.e., Ncol ) from 1 to N − 1.
Figure 4 plots the average normalized cost of the collusion-resistant mechanism as a
function of the coalition fraction. The cost grows exponentially once the coalition fraction
covers more than one half of the entire population. This behavior was also observed in Section 4.4 when we evaluated the cost of incentive-compatible, collusion-resistant mechanisms
in the absence of transferable utilities (Figure 2). However, the payments required under the
assumption of non-transferable utilities are significantly smaller than the payments derived
in this section for settings with transferable utilities.

average normalized cost

15
N=10
N=15
N=20
N=25
10

5

0
0

0.2

0.4
0.6
colluding fraction

0.8

1

Figure 4: The average cost of the mechanism as we increase the colluding fraction (setting
with transferable utilities). The cost is normalized to the cost of the corresponding
incentive-compatible mechanism that is not collusion resistant.

239

Jurca & Faltings

The mechanisms defined in the present and the previous sections assume that the mechanism designer knows the total number of colluders. Formally, a mechanism designed to
be robust against the collusion of Ncol agents is not necessarily robust against all coalition
sizes smaller than Ncol . Take for example the mechanism defined by Proposition 4.8: a
strategic agent that controls less than N − 1 identities observes less than N − 1 quality
signals, and therefore has less precise beliefs about the signals received (and reported) by
the non-colluders. These noisy beliefs make it such that in some cases, a smaller coalition
may regard a certain lying strategy as more profitable than honest reporting. There is one
caveat, however: the colluders know that their lying strategy is provably inefficient had
they had access to more information (i.e., the remaining up to N − 1 reports). We therefore believe that for all practical purposes, a mechanism designed to be robust against Ncol
colluders will effectively deter all coalitions smaller than Ncol .

5. Related Work
One interesting alternative to payment schemes that encourage honest feedback is to develop
mechanisms that make it in the best interest of the providers to truthfully reveal their hidden
quality attributes. The truthful declaration of quality eliminates the need for reputation
mechanisms and significantly reduces the cost of trust management.
Braynov and Sandholm (2002), for example, consider exchanges of goods for money and
prove that a market in which agents are trusted to the degree they deserve to be trusted
is equally efficient as a market with complete trustworthiness. By scaling the amount of
the traded product, the authors prove that it is possible to make it rational for sellers to
truthfully declare their trustworthiness. However, the assumptions made about the trading
environment (i.e. the form of the cost function and the selling price which is supposed to
be smaller than the marginal cost) are not common in most electronic markets.
Another interesting work that addresses the trustworthiness of reputation information is
the Goodwill Hunting mechanism by Dellarocas (2002). The mechanism works for eBay-like
markets and provides a way to make sellers indifferent between lying or truthfully declaring
the quality of the good offered for sale. The particularity of this work is that the goods are
advertised to the buyers through the reputation mechanism, which can modify the asking
price initially set by the seller. The reputation mechanism thus compensates the momentary
gains or losses made by the seller from misstating the quality of the good, and creates an
equilibrium where all sellers find it rational to truthfully announce the quality. A major
advantage of the mechanism is that it works even when the sellers offer various goods with
different values.
Mechanisms for encouraging honest reporting are also present in a number of commercial
applications. The most famous is perhaps the ESP Game (von Ahn & Dabbish, 2004),
designed to encourage human users to label web images. The game8 pairs two users at
random, and shows them the same image. Each player must individually write tags about
the image, without being able to see the tags written by the partner. As soon as the two
player write the same tag, they gain points and can pass to the next picture. The goal is to
get as many points as possible in a fixed amount of time. Intuitively, this game has a very
simple strategy: players must write as many correct tags as possible, since the image they
8. http://www.espgame.org

240

Mechanisms for Making Crowds Truthful

see is the only synchronization device that allows them to reach agreement on a tag. The
game is very successful, and the authors claim that in this way, all images on the web can
be tagged in several months.
The incentive mechanism behind the ESP game has, however, several problems. First,
it is vulnerable to cheating strategies where a group of players agree to reach agreement on
a very simple tag like “a” or “the”. This strategy could be posted to a popular blog and
exposed rapidly to the ESP players. These simple collusion strategies will give colluders
a significant competitive advantage, at the detriment of the game designers who collect
only garbage tags. The problem can be partly addressed by “taboo” lists containing all
confirmed tags which were already submitted about the picture.
The second problem is that rewards are equal for all possible tags. For a Picasso, the
players that match on the tag “painting” are equally rewarded as the players who correctly
identify that the painting is a Picasso. This gives incentives to the players to concentrate
on the simplest possible tags like “person”, “man”, “woman”, etc, without spending effort
to provide more informative tags. This problem has been partly corrected by the Google
Image Labeler9 , a franchise of the ESP Game, which rewards players inversely proportional
to the frequency of the tag they agree on. However, the exact algorithm for computing the
rewards is not public. Yahoo! is also known to use a version of the ESP Game to tag their
collection of images.
Another example of a commercial application using payment mechanisms to encourage
honest reporting is Amazon’s Mechanical Turk10 . The role of the system is to provide a
marketplace in which human users can solve tasks that are very difficult for machines, but
easy for people (i.e., short translations, tagging, face recognition, natural language search,
etc). Task owners can pay the workers for answering their tasks, and can also specify
payment rules: e.g., a worker gets paid (or receives a bonus) only if the answer is confirmed
by a different worker solving the same task.
A number of feedback forums reward raters independently based on the impact of their
reviews on the other users. ePinion.com, for example, has professional reviewers who get
paid depending on the votes expressed by normal users, and on the purchases made after
reading the reviews. Another example is the startup Friend2Friend.com11 who allows users
to gain commissions by recommending products to their friends.
Central to the results of this paper is the principle of automated mechanism design
(AMD). The mechanism is created automatically (using optimization algorithms) for the
specific problem instance, given the specific information available to the mechanism designer. The idea has important advantages since (a) it can be used to address classes
of problems for which there are no known manually designed mechanisms, (b) it can circumvent impossibility results by restricting the mechanism to one particular setting, (c) it
can generate better mechanisms by capitalizing on the specific information available in the
present setting, and (d) it shifts the effort of mechanism design to a machine.
Since first introduced by Conitzer and Sandholm (2002), AMD was used to generate
several impressive results. Conitzer and Sandholm (2003a) (a) reinvented the Mayerson
auction which maximizes the seller’s expected revenue in a single-object auction, (b) created
9. http://images.google.com/imagelabeler/
10. http://www.mturk.com/mturk/welcome
11. http://www.friend2friend.com/

241

Jurca & Faltings

expected revenue maximizing combinatorial auctions, and (c) created optimal mechanisms
for a public good problem. Guo and Conitzer (2007) use AMD to optimally redistribute the
payments generated by the VCG mechanism, Conitzer and Sandholm (2007) incrementally
design incentive compatible mechanisms, while Hajiaghayi, Kleinberg, and Sandholm (2007)
focus on AMD for online settings. Conitzer and Sandholm (2003b) show that the AMD
can potentially be exponentially faster for settings with structured preferences that allow
a concise representation of the input. Conitzer and Sandholm (2004) describe an efficient
algorithm for AMD when the mechanism is deterministic, does not allow payments and there
is only one type-reporting agent. AMD can also be used to design multi-stage mechanisms
that reduce the burden of information elicitation by querying the agents only for relevant
information (Sandholm, Conitzer, & Boutilier, 2007). The results of this paper add to this
already long list of results obtained through AMD.
The results of Section 4 are mostly related to the literature on implementation theory
and incentive contracts for principle-(multi)agent settings. The main goal of implementation theory is to characterize the space of social choice rules that are implementable by
some mechanism given a game-theoretic equilibrium concept. For complete information settings, well established results characterize the necessary and sufficient conditions for a social
choice rule (SCR) to be implementable in dominant strategy or in Nash equilibrium. For
example, SCRs can be implemented in dominant strategies only if they are strategy-proof
(Gibbard, 1973), while the SCRs that can be Nash-implemented must satisfy the property
of monotonicity and no veto power (Maskin, 1999). Unfortunately, SCRs of practical interest do not satisfy the monotonicity requirement. Fortunately, non-monotonic SCRs can be
implemented in undominated Nash equilibria (Palfrey & Srivastava, 1991), or in subgame
perfect equilibria by multi-stage mechanisms. Another relaxation that extends the set of
implementable SCRs is to consider virtual implementation, where the socially optimal outcome is required to occur only with probability close to one (Matsushima, 1988; Abreu &
Sen, 1991).
In environments with incomplete information agents have private information that is
not shared by other agents. The truthful revelation of the private information can only be
ensured by social choice rules that are Bayesian incentive-compatible. Moreover, a Bayesian
monotonicity condition is necessary for Bayesian implementation (Jackson, 1991). Moore
and Repullo (2005) characterize SCRs that can be virtually Bayesian implemented in pure
strategies, and derive the necessary and sufficient conditions of incentive compatibility and
virtual monotonicity.
However, applying the implementation theory to the feedback reporting setting (an
environment with incomplete information) provides nothing more than the constraints on
the payment function such that honest reporting is the unique Bayesian Nash equilibrium.
In implementation theory terms, the set of possible world states consists of all combinations
of N privately perceived quality signal (one signal for each agent). The outcome space
contains all possible sets of N feedback reports and all possible combinations of N positive
payments made to the N agents. The desirable SCR contains all social choice functions
that map the possible states of the world (i.e., the set of privately perceived signals) to
the outcomes where the reported feedback correspond to the privately perceived signals).
Implementation theory tells that the SCR must be incentive compatible (i.e., the social
choice functions prescribe outcomes where the payments to the agents make them truthfully
242

Mechanisms for Making Crowds Truthful

reveal their private information) and Bayesian monotone (i.e., the social choice functions
prescribe outcomes where the payments received by the agents make honest reporting the
unique equilibrium). The results of Section 4 translate these requirements into practical
constraints that allow the computation of payment functions (and therefore social choice
functions) that are Bayesian Nash implementable.
A number of papers discuss incentive contracts that a principal should offer to several
agents whose effort levels are private. The reward received by each agent depends on the
output observed by the principal, and on the declarations of other agents. Holmström
(1982), Ma (1988), and Li and Balachandran (2000) show that efficient contracts exist that
are also incentive-compatible and collusion-proof. While the feedback reporting problem is
similar, it differs in one major aspect: the reputation mechanism designer (i.e., the principal)
does not observe a direct signal which is correlated to the reporters’ (i.e., agents’) private
information.

6. Discussion and Future Work
Throughout this paper we only considered pure reporting strategies. Extending our results
to mixed -strategy equilibria remains an open question, and poses non-trivial computational
problems: the constraints required to prevent mixed equilibria are no longer linear, and this
significantly increases the complexity of the design problem.
In this paper we limit our investigation to binary settings where the quality signal
observed by the agents and the feedback reported to the reputation mechanism is either 0
or 1. While the extension to n-ary feedback is conceptually straight-forward (see Appendix
D), the resulting mechanism design problem becomes exponentially more complex as we
increase the number of possible feedback values. It remains a challenge for future work
to design efficient algorithms that are able to quickly compute incentive-compatible and
collusion-resistant reward mechanisms for non-binary feedback.
Another challenge is to relax the requirement of common prior information. The model
we introduce in Section 2 assumes that all agents share the same prior beliefs regarding the
probability of positive or negative feedback. Jurca and Faltings (2007b) show that incentive
compatible reward schemes can still be designed when agents have small amounts of private
information. However, the same methodology cannot be easily extended to also address
collusion.
Yet another direction for future research is to design payment mechanisms that are
resistant against more complex collusion scenarios, where, for example, several strategic
agents, each controlling several fake identities, try to manipulate the reporting mechanism.
We believe, however, that there are many practical scenarios where the techniques we
presented in this paper can be successfully used to ensure safety against collusion. One
example is the monitoring of service quality. Jurca, Binder, and Faltings (2007) describe
a framework for monitoring the quality of web service based on client feedback. The idea
is to estimate the quality delivered by a service provider directly from the reports of the
clients. This approach is much cheaper and more precise when compared to traditional
monitoring devices that proxy and analyze the communication between the client and the
server. Nevertheless, the mechanism must provide incentives for honest reporting which
also discourage lying coalitions. The feedback in such settings is often binary, and specifies
243

Jurca & Faltings

whether or not a certain service level agreements (SLA) has been met by the provider. The
quality of a provider is than defined by its capacity to fulfill the SLA, and usually becomes
public information. The quality at time t defines the priors for designing the mechanism at
time t + 1, and it is quite natural that the majority of the clients will consider these priors
to be public knowledge.
Many tasks on Amazon’s Mechanical Turk also fit the model we used in this paper. For
example, certain tasks ask human raters to specify whether two descriptions refer to the
same item or not. In other tasks, raters must vote thumbs up or down for a piece of news, or
must tag photographs that contain a certain visual clue, such as a human face. The answer
to all these tasks can be modeled by a binary feedback signal (e.g., items are the same or
not, positive or negative vote, a photograph contains or not a human face) and the answers
of different users may be considered as conditionally independent given the description of
the task. Moreover, these conditional probabilities may quite often be assumed common
knowledge: for example, the assumption that 98% of the raters will correctly identify a
human face in a decent quality photograph, is not only natural, but is also likely to be a
belief of most internet-savvy humans.
More generally, we believe our techniques can be useful in providing incentives for human
raters to label training data for supervised machine learning algorithms. Many practical
classifiers are binary (e.g., a photograph contains or not a certain feature, a word is misspelled or not) or composed of other binary classifiers (e.g., recognizing a hand-written
digit). A framework similar to the Mechanical Turk can harvest the power of the crowds to
produce extensive training sets for different algorithms.
Another potential application can be the collaborative question answering forums like
Yahoo! Answers. In such forums users may post questions that remain open for a predefined
period of time. During this period, other users can write new answers, or vote for existing
answers. The voting mechanism is essential for differentiating good from bad answers,
and proper incentives may ensure higher participation and more accurate results. These
forums are especially vulnerable to collusion, since the author providing the best answer is
often rewarded by the forum with points, public recognition, or other benefits. The biggest
challenge in such contexts is to obtain accurate estimates on the different probabilities that
enter the design problem. For example, the prior probability of a high quality answer can be
estimated from the history of the site. On the other hand, the conditional probability that a
user will find a given answer as high quality is more complicated to estimate. For example,
the mechanism designer might use a natural language processing algorithm to figure out a
degree of matching between the question and the answer. The designer could also search for
documents that contain keywords related to the question and to the answer, and analyze
these documents to refine the matching degree of an answer to the given question. General
user statistics can also be factored in to estimate the likelihood that a random user will find
a given answer useful. Although these estimates will inevitably be noisy, they might work
well enough for the average user.
If our results can be fully extended to feedback sets of arbitrary size, the techniques
of this paper will be relevant for most feedback reporting scenarios. To mention just one
supplementary examples, the ESP game, where every photo tag can be assumed to be drawn
from a finite set of concepts, and the conditional probabilities of seeing a certain tag can be
244

Mechanisms for Making Crowds Truthful

Non-Transferable Utilities
symmetric
asymmetric
strategies
strategies

all agents
collude
some agents
collude

-unique honest NE;
-Pareto-optimal
honest NE
-unique honest NE;
-Pareto-optimal
honest NE

-Pareto-optimal
honest NE
-unique honest NE;
-Pareto-optimal
honest NE;
-sometimes honest
dominant strategy
);
(not if Ncol ≥ N
2

Transferable Utilities
symmetric
asymmetric
strategies
strategies
unreasonable
assumption

impossible to prevent collusion

unreasonable
assumption

-(sybil
attack),
the
coalition
maximizes its revenue by reporting
honestly;

Table 3: Summary of results.

estimated by using word frequencies in different languages, image recognition techniques,
and historical data regarding the distribution of tags in similar photos.

7. Conclusion
As online feedback and reputation become increasingly important sources of information,
explicit measures must guarantee that honest reporting is in the best interest of the participants. Previous work shows that it is possible to construct payment mechanisms that
make honest reporting a Nash equilibrium, because agents expect to get rewarded more for
a truthful report than for a lie. Unfortunately, such mechanisms also have other equilibria
where reporters lie. This creates collusion opportunities, since several agents can coordinate
their lies in order to improve their revenues.
In this paper we addressed the design of incentive-compatible payments that are also
resistant to collusion. We consider different collusion scenarios where (i) all or only some
of the agents collude, (ii) colluders can coordinate on symmetric or asymmetric strategy
profiles, and (iii) colluders can transfer or not payments to each other. Table 3 summarizes
the results obtained for each scenario.
In Section 4.1 we assume that all agents may collude but cannot make side-payments to
each other. We showed that incentive-compatible payments can be efficiently constructed
such that honest reporting is the unique pure strategy symmetric NE, or a Pareto-optimal
pure symmetric NE. In Section 4.2 we keep the same assumptions, but investigate asymmetric collusion strategies. We find that any incentive-compatible payment mechanism also
accepts asymmetric lying equilibria. Nevertheless, there are payment mechanisms where
honest reporting is a Pareto-optimal NE.
Sections 4.3 and 4.4 assume that only a fraction of the agents may collude, and that noncolluders report honestly. If colluders can only coordinate on symmetric strategy profiles
and they cannot make side-payments to each other, payments always exist such that honest
reporting can be made the unique NE or (with lower payments) a Pareto-optimal NE.
If colluders can coordinate on asymmetric strategies (Section 4.4), payments can still be
devised that make honest reporting the unique or Pareto-optimal NE. If less than one half
the population can collude, then payments can sometimes be devised that make honest
reporting a dominant strategy. Numerical simulations, however, show that the payments
245

Jurca & Faltings

required to deter coalition fractions greater than one third become exponentially expensive.
Finally, Section 4.5 describes incentive-compatible payments that are resistant to sybil
attacks: i.e., the same strategic agents creates several fake identities in order to manipulate
the payment mechanism. The designer can ensure that the set of reports submitted by
the coalition reflects the aggregated experience of the coalitions. Individual colluders do
not necessarily report the truth, but overall, the reputation mechanism obtains correct
information.

Acknowledgments
The authors wish to thank the anonymous reviewers for their helpful comments and suggestions.

Appendix A. Proof of Proposition 3.1
For solving LP 3.1, let us write the corresponding dual problem:
max Λy0 + Λy1 ;
s.t.
P r[n|0]y0 − P r[n|1]y1 ≤ P r[0]P r[n|0]
P r[n|1]y1 − P r[n|0]y0 ≤ P r[1]P r[n|1]
∀n ∈ {0, . . . , N − 1};

where y0 (respectively y1 ) is the dual variable corresponding to the constraint where the
agent observes 0 (respectively 1). By dividing the first set of constraints by P r[n|0] and the
second set of constraints by P r[n|1], we have:
y0 − y1 P r[n|1]/P r[n|0] ≤ P r[0], ∀n ∈ {0, . . . , N − 1};
y1 − y0 P r[n|0]/P r[n|1] ≤ P r[1], ∀n ∈ {0, . . . , N − 1};

Clearly, among the 2(N − 1) constraints of the dual problem, only two are active, correP r[n|0]
sponding to: n1 = arg minn PP r[n|1]
r[n|0] , and n2 = arg minn P r[n|1] . It follows that only two of
the variables of LP 3.1 have non-zero values (i.e., τ (0, n1 ) 6= 0 and τ (1, n2 ) 6= 0), and they
satisfy the linear equations:
P r[n1 |0]τ (0, n1 ) − P r[n2 |0]τ (1, n2 ) = Λ;
−P r[n1 |1]τ (0, n1 ) + P r[n2 |1]τ (1, n2 ) = Λ;

The remaining part of the proof is to show that n1 = 0 and n2 = N − 1. For that, we
P r[n+1|1]
will prove that PP r[n|1]
r[n|0] < P r[n+1|0] for all n = 0, 1, . . . , N − 2.
246

Mechanisms for Making Crowds Truthful

P r[n|1]P r[n + 1|0] − P r[n|0]P r[n + 1|1] =

³X

P r[θ]

θ∈Θ

´³ X
´
P r[1|θ]
P r[0|θ]
P r[n|θ]
P r[θ]
P r[n + 1|θ] −
P r[1]
P r[0]
θ∈Θ

³X

´³ X
´
P r[0|θ]
P r[1|θ]
P r[θ]
P r[θ]
P r[n|θ]
P r[n + 1|θ]
P
r[0]
P
r[1]
θ∈Θ
θ∈Θ

=

³X

P r[θ]

θ∈Θ

³X

´³ X
P r[1|θ]
P r[0|θ]
(N − 1 − n)P r[1|θ] ´
P r[n|θ]
P r[θ]
P r[n|θ]
−
P r[1]
P r[0]
(n + 1)P r[0|θ]
θ∈Θ

´³ X
P r[0|θ]
P r[1|θ]
(N − 1 − n)P r[1|θ] ´
P r[θ]
P r[n|θ]
P r[n|θ]
P r[0]
P r[1]
(n + 1)P r[0|θ]
θ∈Θ
θ∈Θ
Ã
³
´
X
2
(N − 1 − n)
=
P r[θ]P r[1|θ]P r[n|θ] −
(n + 1)P r[1]P r[0]
θ∈Θ
!
³X
´³ X
´
P r[1|θ]2
P r[θ]P r[0|θ]P r[n|θ]
P r[θ]
P r[n|θ]
< 0;
P r[0|θ]
θ∈Θ
θ∈Θ
P r[θ]

p
by the√Cauchy-Schwartz inequality applied to the vectors ( P r[θ]P r[0|θ]P r[n|θ])θ∈Θ and
P r[1|θ] P r[θ]P r[n|θ]
√
(
)θ∈Θ .
P r[0|θ]

Appendix B. Proof of Proposition 4.5
The idea of the proof is to show that we can find the positive values x and y such that the
payment scheme defined in Proposition 4.5 has only three NE: honest reporting, everybody
reporting 0 or everybody reporting 1.
No NE where n agents report according to slie and 4 − n agents report honestly. From
Proposition 4.2 we know that x and y can be found to prevent an equilibrium where all
agents lie. Similarly, the incentive-compatible constraints ensure that a strategy profile
where one agent always lies and three agents always report the truth cannot be a NE. Let
us show that the profile s = (3 × slie , s̄) where three agents lie and one agent reports the
truth. The honest reporter observing a low quality signal will report honestly if and only
if:
P r[2|0]x − P r[1|0]y > 0;

The same honest agent reports a positive report after observing high quality if and only if:
−P r[2|1]x + P r[1|1]y > 0;
P r[1|1]
However, by Lemma 3.1 we have PP r[1|0]
r[2|0] > P r[2|1] , so the two inequalities can never be
simultaneously satisfied.
Consider the profile s = (2 × slie , 2 × s̄) where two agents lie and two agents report the
truth is not NE. One honest reporter reports the truth if and only if:

(3P r[3|0] + 2P r[1|0])x − (3P r[0|0] + 2P r[2|0])y > 0;
−(3P r[3|1] + 2P r[1|1])x + (3P r[0|1] + 2P r[2|1])y > 0;

A liar, on the other hand, reports according to slie if and only if:
(3P r[0|1] + 2P r[2|1])x − (3P r[3|1] + 2P r[1|1])y > 0;
−(3P r[0|0] + 2P r[2|0])x + (3P r[3|0] + 2P r[1|0])y > 0;
247

Jurca & Faltings

All 4 inequalities are satisfied if and only if
3P r[3|1] + 2P r[1|1] < 3P r[0|1] + 2P r[2|1];
3P r[0|0] + 2P r[2|0] < 3P r[3|0] + 2P r[1|0];

which is impossible.
No NE where one agent always reports 1, n agents report according to slie and 3 − n
agents report honestly. Clearly, when all 3 agents report honestly, the agent always reporting
1 has the incentive to deviate and report 0 after observing low quality. Consider the strategy
profile s = (spos , 2 × s̄, slie ) where one agent reports according to spos , two agents report
honestly and one agent reports according to slie . For the liar, slie is an equilibrium iff:
−Pˆr[0|0]x + Pˆr[1|0]y > 0;
Pˆr[0|1]x − Pˆr[1|1]y > 0;

where Pˆr[n|oi ] is the probability that n out of the 2 honest reporters will observe 1, given
ˆ

ˆ

the observation oi ∈ Q2 . By Lemma 3.1, we have Pˆr[1|1] > Pˆr[1|0] , so the above inequations
P r[0|1]
P r[0|0]
cannot hold simultaneously.
Consider the strategy profile s = (spos , s̄, 2 × slie ) where one agent reports according
to spos , one agent reports honestly and two agents report according to slie . The agent
reporting honestly, does so iff:
Pˆr[2|0]x − Pˆr[0|0]y > 0;
−Pˆr[2|1]x + Pˆr[0|1]y > 0;

where Pˆr[n|oi ] is the probability that n out of the 2 liars observe 1, given the observation
oi ∈ Q2 . This is impossible since by Lemma 3.1

Pˆr[0|0]
Pˆr[2|0]

>

Pˆr[0|1]
.
Pˆr[2|1]

¡ neg
¢
lie , (3−n)× s̄
Similar
techniques
can
be
used
to
prove
that
no
strategy
profile
s
,
n×s
¡
¢
or sneg , spos , n × slie , (2 − n) × s̄ can be NE. Therefore, the only constraint (besides the
incentive-compatibility constraints) acting on the payments x and y is intended to prevent
the all lying equilibrium. x and y take exactly the values described by Proposition 4.2.

Appendix C. Proof of Proposition 4.6
¡
¢
Consider the strategy profile s = n̄ × s̄, (N − n̄) × slie ∈ S̃ where n̄ ≥ 1 agents report
honestly, and the others always lie. If s were a NE, an honest reporter must expect a
higher payment by reporting the truth, while a liar must expect a higher payment by lying.
Consider an honest reporter observing 0. She will report a negative signal if and only if
P r[r−i = 1|0]x > P r[r−i = N − 2|0]y, where P r[r−i = 1|0] and P r[r−i = N − 2|0] are
the probabilities that exactly 1, respectively N − 2 of the remaining N − 1 agents report
positive signals. Exactly one of the other agents reports a positive signal when:
• all but one of the other honest reporters observes low quality, and all liars observe
high quality, or
• all honest reporters observe low quality, and all but one of the liars observe high
quality.
248

Mechanisms for Making Crowds Truthful

P r[r−i = 1|0] =

X

P r[θ|0]

θ∈Θ

X
θ∈Θ

³ n̄ − 1 ´
³ N − n̄ ´
P r[1|θ]P r[0|θ]n̄−2
P r[1|θ]N −n̄ +
1
N − n̄

³ n̄ − 1 ´
³
´
N − n̄
P r[θ|0]
P r[0|θ]n̄−1
P r[1|θ]N −n̄−1 P r[0|θ]
0
N − n̄ − 1

(n̄ − 1)!(N − n̄ + 1)!
(n̄)!(N − n̄)!
P r[N − n̄ + 1|0] +
P r[N − n̄ − 1|0]
(N − 1)!
(N − 1)!
³
´
(n̄ − 1)!(N − n̄)!
=
(N − n̄ + 1)P r[N − n̄ + 1|0] + n̄P r[N − n̄ − 1|0] ;
(N − 1)!
=

Similarly,
P r[r−i = N − 2|0] =

´
(n̄ − 1)!(N − n̄)! ³
(N − n̄ + 1)P r[n̄ − 2|0] + n̄P r[n̄|0] ;
(N − 1)!

Hence the honest reporter has the incentive to truthfully submit a negative report if and
only if:
³
´
³
´
(N − n̄ + 1) P r[N − n̄ + 1|0]x − P r[n̄ − 2|0]y + n̄ P r[N − n̄ − 1|0]x − P r[n̄|0]y > 0;

On the other hand, the honest reporter will submit a positive report after observing a high
quality signal if and only if:
³
´
³
´
(N − n̄ + 1) P r[n̄ − 2|1]y − P r[N − n̄ + 1|1]x + n̄ P r[n̄|1]y − P r[N − n̄ − 1|1]x > 0;

Exactly the same reasoning leads to the following two inequations for the liar:
³
´
³
´
(N − n̄) P r[n̄ − 1|0]y − P r[N − n̄|0]x + (n̄ + 1) P r[n̄ + 1|0]y − P r[N − n̄ − 2|0]x > 0;
³
´
³
´
(N − n̄) P r[N − n̄|1]x − P r[n̄ − 1|1]y + (n̄ + 1) P r[N − n̄ − 2|1]x − P r[n̄ + 1|1]y > 0;

There exist x and y such that the four inequalities are satisfied in the same time only if:
(N − n̄ + 1)P r[n̄ − 2|0] + n̄P r[n̄|0]
(N − n̄ + 1)P r[n̄ − 2|1] + n̄P r[n̄|1]
<
(N − n̄ + 1)P r[N − n̄ + 1|0] + n̄P r[N − n̄ − 1|0]
(N − n̄ + 1)P r[N − n̄ + 1|1] + n̄P r[N − n̄ − 1|1]
(N − n̄)P r[n̄ − 1|0] + (n̄ + 1)P r[n̄ + 1|0]
(N − n̄)P r[n̄ − 1|1] + (n̄ + 1)P r[n̄ + 1|1]
<
(N − n̄)P r[N − n̄|1] + (n̄ + 1)P r[N − n̄ − 2|1]
(N − n̄)P r[N − n̄|0] + (n̄ + 1)P r[N − n̄ − 2|0]

or equivalently:
(N − n̄ + 1)P r[n̄ − 2|0] + n̄P r[n̄|0]
(N − n̄ + 1)P r[N − n̄ + 1|0] + n̄P r[N − n̄ − 1|0]
<
(N − n̄ + 1)P r[n̄ − 2|1] + n̄P r[n̄|1]
(N − n̄ + 1)P r[N − n̄ + 1|1] + n̄P r[N − n̄ − 1|1]
(N − n̄)P r[n̄ − 1|1] + (n̄ + 1)P r[n̄ + 1|1]
(N − n̄)P r[N − n̄|1] + (n̄ + 1)P r[N − n̄ − 2|1]
<
(N − n̄)P r[n̄ − 1|0] + (n̄ + 1)P r[n̄ + 1|0]
(N − n̄)P r[N − n̄|0] + (n̄ + 1)P r[N − n̄ − 2|0]

However, one can show that:
(N − n̄ + 1)P r[n̄ − 2|0] + n̄P r[n̄|0]
(N − n̄)P r[N − n̄|1] + (n̄ + 1)P r[N − n̄ − 2|1]
<
(N − n̄)P r[N − n̄|0] + (n̄ + 1)P r[N − n̄ − 2|0]
(N − n̄ + 1)P r[n̄ − 2|1] + n̄P r[n̄|1]

and
(N − n̄ + 1)P r[N − n̄ + 1|0] + n̄P r[N − n̄ − 1|0]
(N − n̄)P r[n̄ − 1|1] + (n̄ + 1)P r[n̄ + 1|1]
<
(N − n̄ + 1)P r[N − n̄ + 1|1] + n̄P r[N − n̄ − 1|1]
(N − n̄)P r[n̄ − 1|0] + (n̄ + 1)P r[n̄ + 1|0]

249

Jurca & Faltings

which means that the honest reporter and the liar cannot both believe that their strategies
are optimal (given the strategies of the other agents).
Consider the strategy profile s = (sneg , n̄ × s̄, N − n̄ − 1 × slie ) ∈ S̃ where one agent
always reports 0, n̄ ≥ 1 agents report honestly, and N − n̄ − 1 ≥ 1 agents always lie. An
honest reporter and a liar both believe that s is a NE if and only if:
³

´
n̄P¯r[N − n̄ − 2|0] + (N − n̄)P¯r[N − n̄|0] x − P¯r[n̄ − 1|0]y
³
´
− n̄P¯r[N − n̄ − 2|1] + (N − n̄)P¯r[N − n̄|1] x + P¯r[n̄ − 1|1]y
³
´
− (n̄ + 1)P¯r[N − n̄ − 3|0] + (N − n̄ − 1)P¯r[N − n̄ − 1|0] x + P¯r[n̄|0]y
³
´
(n̄ + 1)P¯r[N − n̄ − 3|1] + (N − n̄ − 1)P¯r[N − n̄ − 1|1] x − P¯r[n̄|1]y

>0
>0
(17)
>0
>0

where P¯r[j|oi ] is the probability that j out of N − 2 agents observe high quality signals,
given the observation oi .
Nevertheless,
P¯r[n̄ − 1|0]
P¯r[n̄|0]
< ¯
P¯r[n̄|1]
P r[n̄ − 1|1]

and
n̄P¯r[N − n̄ − 2|0] + (N − n̄)P¯r[N − n̄|0]
(n̄ + 1)P¯r[N − n̄ − 3|0] + (N − n̄ − 1)P¯r[N − n̄ − 1|0]
<
n̄P¯r[N − n̄ − 2|1] + (N − n̄)P¯r[N − n̄|1]
(n̄ + 1)P¯r[N − n̄ − 3|1] + (N − n̄ − 1)P¯r[N − n̄ − 1|1]

which means that the inequalities in (17) can never be simultaneously satisfied.
Using exactly the same technique one can show that:
¡
¢
• s = spos , n̄ × s̄, (N − n̄ − 1) × slie ∈ S̃ where one agent always reports 0, n̄ ≥ 1 agents
report honestly, and N − n̄ − 1 ≥ 1 agents always lie is not a NE;
¡
¢
• s = sneg , spos , n̄ × s̄, (N − n̄ − 2) × slie ∈ S̃ where one agent always reports 0, one
agent always reports 1, n̄ ≥ 0 agents report honestly, and N − n̄ − 1 ≥ 0 agents always
lie is not a NE.

Appendix D. Extending the results to n-ary feedback
We have assumed so far that agent can observe and report only two signals: 0 or 1. The
framework can be extended to n-ary feedback by imposing supplementary constraints on
the design problems. For example, let’s assume the set of quality signals (and feedback
reports) contains M elements: Q = {q1 , q2 , . . . qM }. The incentive compatibility constraints
equivalent to (4) become:
³
´
X
P r[r−i |qj ] τ (qj , r−i ) − τ (qk , r−i ) ≥ Λ; ∀qj , qk ∈ Q;
r−i ∈Q(N −1)

where qj ∈ Q is the signal actually observed by agent i, qk ∈ Q is every other lie agent i
could report, and r−i ∈ Q(N −1) is the configuration of the other N − 1 reference reports.
When compared to (4) three observations become apparent. First, the 2 constraints for
the binary feedback case must be replaced by M (M − 1) constraints for the n-ary feedback
250

Mechanisms for Making Crowds Truthful

setting. Second, the ’size’ of each constraint grows from a sum of N terms to a sum of
M −1
CN
+M −2 terms (all possible unordered sequences of N − 1 signals drawn from Q). Finally,
M −1
the reward mechanism is defined by M · CN
+M −2 payments instead of 2N .
All other constraints will suffer a similar blowup, which makes the design problem for
the general n-ary feedback case significantly harder to solve.

References
Abreu, D., & Sen, A. (1991). Virtual Implementation in Nash Equilibria. Econometrica,
59, 997–1022.
Admati, A., & Pfleiderer, P. (2000). Noisytalk.com: Broadcasting opinions in a noisy environment. Working Paper 1670R, Stanford University.
Akerlof, G. A. (1970). The market for ’lemons’: Quality uncertainty and the market mechanism. The Quarterly Journal of Economics, 84 (3), 488–500.
Braynov, S., & Sandholm, T. (2002). Incentive Compatible Mechanism for Trust Revelation.
In Proceedings of the AAMAS, Bologna, Italy.
Cheng, A., & Friedman, E. (2005). Sybilproof reputation mechanisms. In Proceeding of the
Workshop on Economics of Peer-to-Peer Systems (P2PECON), pp. 128–132.
Clemen, R. T. (2002). Incentive contracts and strictly proper scoring rules. Test, 11,
167–189.
Conitzer, V., & Sandholm, T. (2002). Complexity of mechanism design. In Proceedings of
the Uncertainty in Artificial Intelligence Conference (UAI).
Conitzer, V., & Sandholm, T. (2003a). Applications of Automated Mechanism Design. In
Proceedings of the the UAI-03 Bayesian Modeling Applications Workshop.
Conitzer, V., & Sandholm, T. (2003b). Automated Mechanism Design with a Structured
Outcome Space..
Conitzer, V., & Sandholm, T. (2004). An Algorithm for Automatically Designing Deterministic Mechanisms without Payments. In Proceedings of the AAMAS-04.
Conitzer, V., & Sandholm, T. (2007). Incremental Mechanism Design. In Proceedings of
the IJCAI.
Crémer, J., & McLean, R. P. (1985). Optimal Selling Strategies under Uncertainty for a
Discriminating Monopolist When Demands Are Interdependent. Econometrica, 53 (2),
345–61.
d’Aspremont, C., & Grard-Varet, L.-A. (1979). Incentives and Incomplete Information.
Journal of Public Economics, 11, 25–45.
Dellarocas, C. (2002). Goodwill Hunting: An Economically Efficient Online Feedback. In
Padget, J., & et al. (Eds.), Agent-Mediated Electronic Commerce IV. Designing Mechanisms and Systems, Vol. LNCS 2531, pp. 238–252. Springer Verlag.
Dellarocas, C. (2006). Strategic Manipulation of Internet Opinion Forums: Implications for
Consumers and Firms. Management Science, 52 (10), 1577–1593.
251

Jurca & Faltings

Elliott, C. (2006). Hotel Reviews Online: In Bed With Hope, Half-Truths and Hype. The
New York Times.
Figlewski, S. (1979). Subjective information and market efficiency in a betting market. The
Journal of Political Economy, 87 (1), 75–88.
Gibbard, A. (1973). Manipulation of Voting Schemes: A General Result. Econometrica, 41,
587–601.
Guo, M., & Conitzer, V. (2007). Worst-Case Optimal Redistribution of VCG Payments. In
Proceedings of EC’07, pp. 30–39.
Hajiaghayi, M., Kleinberg, R., & Sandholm, T. (2007). Automated Online Mechanism
Design and Prophet Inequalities. In Proceedings of AAAI’07.
Harmon, A. (2004). Amazon Glitch Unmasks War of Reviewers. The New York Times.
Holmström, B. (1982). Moral Hazard in Teams. Bell Journall of Economics, 13, 324–340.
Hu, N., Pavlou, P., & Zhang, J. (2006). Can Online Reviews Reveal a Product’s True
Quality?. In Proceedings of ACM Conference on Electronic Commerce (EC 06).
Jackson, M. O. (1991). Bayesian Implementation. Econometrica, 59, 461–477.
Johnson, S., Pratt, J., & Zeckhauser, R. (1990). Efficiency Despite Mutually Payoff-Relevant
Private Information: The Finite Case. Econometrica, 58, 873–900.
Jurca, R., Binder, W., & Faltings, B. (2007). Reliable QoS Monitoring Based on Client
Feedback. In Proceedings of the 16th International World Wide Web Conference
(WWW07), pp. 1003–1011, Banff, Canada.
Jurca, R., & Faltings, B. (2005). Enforcing Truthful Strategies in Incentive Compatible
Reputation Mechanisms. In Internet and Network Economics (WINE’05), Vol. 3828
of LNCS, pp. 268–277. Springer-Verlag.
Jurca, R., & Faltings, B. (2006). Minimum Payments that Reward Honest Reputation
Feedback. In Proceedings of the ACM Conference on Electronic Commerce (EC’06),
pp. 190–199, Ann Arbor, Michigan, USA.
Jurca, R., & Faltings, B. (2007a). Collusion Resistant, Incentive Compatible Feedback
Payments. In Proceedings of the ACM Conference on Electronic Commerce (EC’07),
pp. 200–209, San Diego, USA.
Jurca, R., & Faltings, B. (2007b). Robust Incentive-Compatible Feedback Payments. In
Fasli, M., & Shehory, O. (Eds.), Trust, Reputation and Security: Theories and Practice,
Vol. LNAI 4452, pp. 204–218. Springer-Verlag, Berlin Heidelberg.
Kandori, M., & Matsushima, H. (1998). Private observation, communication and collusion.
Econometrica, 66 (3), 627–652.
Keates, N. (2007). Deconstructing TripAdvisor. The Wall Street Journal, page W1.
Li, S., & Balachandran, K. (2000). Collusion proof transfer payment schemes with multiple
agents. Review of Quantitative Finance and Accounting, 15, 217–233.
Ma, C. (1988). Unique implementation of incentive contracts with many agents. Review of
Economic Studies, 555–572.
252

Mechanisms for Making Crowds Truthful

Maskin, E. (1999). Nash Equilibrium and Welfare Optimality. Review of Economic Studies,
66, 23–28.
Matsushima, H. (1988). A New Approach to the Implementation Problem. Journal of
Economic Theory, 45, 128–144.
Miller, N., Resnick, P., & Zeckhauser, R. (2005). Eliciting Informative Feedback: The PeerPrediction Method. Management Science, 51, 1359 –1373.
Moore, J., & Repullo, R. (2005). A characterization of virtual Bayesian implementation.
Games and Economic Behavior, 50, 312–331.
Palfrey, T., & Srivastava, S. (1991). Nash-implementation using Undominated Strategies.
Econometrica, 59, 479–501.
Parasuraman, A., Zeithaml, V., & Berry, L. (1985). A Conceptual Model of Service Quality
and Its Implications for Future Research. Journal of Marketing, 49, 41–50.
Pennock, D., Debnath, S., Glover, E., & Giles, C. (2002). Modeling information incorporation in markets with application to detecting and explaining events. In Proc. of the
18th Conf. on Uncertainty in Artifcial Intelligence, pp. 405–411.
Sandholm, T., Conitzer, V., & Boutilier, C. (2007). Automated Design of Multistage Mechanisms. In Proceedings of IJCAI’07.
Servan-Schreiber, E., Wolfers, J., Pennock, D., & Galebach, B. (2004). Prediction markets:
Does money matter. Electronic Markets, 14 (3).
Sherali, H., & Shetty, C. (1980). Optimization with Disjunctive Constraints. SpringerVerlag.
Talwar, A., Jurca, R., & Faltings, B. (2007). Understanding User Behavior in Online Feedback Reporting. In Proceedings of the ACM Conference on Electronic Commerce
(EC’07), pp. 134–142, San Diego, USA.
von Ahn, L., & Dabbish, L. (2004). Labeling Images with a Computer Game. In Proceedings
of ACM CHI.
White, E. (1999). Chatting a Singer Up the Pop Charts. The Wall Street Journal.

253

Journal of Artificial Intelligence Research 34 (2009) 499-520

Submitted 10/08; published 3/09

Exploiting Single-Cycle Symmetries in
Continuous Constraint Problems
Vicente Ruiz de Angulo
Carme Torras

ruiz@iri.upc.edu
torras@iri.upc.edu

Institut de Robòtica i Informàtica Industrial (CSIC-UPC)
Llorens i Artigas 4-6, 08028-Barcelona, Spain.
WWW home page: www.iri.upc.edu

Abstract
Symmetries in discrete constraint satisfaction problems have been explored and exploited in the last years, but symmetries in continuous constraint problems have not received the same attention. Here we focus on permutations of the variables consisting of
one single cycle. We propose a procedure that takes advantage of these symmetries by
interacting with a continuous constraint solver without interfering with it. A key concept
in this procedure are the classes of symmetric boxes formed by bisecting a n-dimensional
cube at the same point in all dimensions at the same time. We analyze these classes and
quantify them as a function of the cube dimensionality. Moreover, we propose a simple
algorithm to generate the representatives of all these classes for any number of variables at
very high rates. A problem example from the chemical field and the cyclic n-roots problem
are used to show the performance of the approach in practice.

1. Introduction
Symmetry exploitation in discrete constraint satisfaction problems (CSPs) has received a
great deal of attention lately. Since CSPs are usually solved using AI search algorithms, the
approaches dealing with symmetries fall into two groups: those that entail reformulating the
problem or adding constraints before search (Flener, Frisch, Hnich, Kiziltan, & Miguel, 2002;
Puget, 2005), and those that break symmetries along the search (Meseguer & Torras, 2001;
Gent, 2002). Permutations of variables, and interchangeability of values are commonly
addressed symmetries for which a repertoire of techniques have been developed, most of
them relying on computational group theory.
On the contrary, symmetries have been largely disregarded in continuous constraint
solving, despite the important growth in both theory and applications that this field has
recently experienced (Sam-haroud & Faltings, 1996; Benhamou & Goualard, 2000; Jermann
& Trombettoni, 2003; Porta, Ros, Thomas, & Torras, 2005). Continuous (or numerical)
constraint solving is often tackled using Branch-and-Prune (B&P) algorithms (Hentenryck,
Mcallester, & Kapur, 1997; Vu, Silaghi, Sam-Haroud, & Faltings, 2005), which iteratively
locate solutions inside an initial domain box, by alternating box subdivision (branching)
and box reduction (pruning) steps.
Motivated by a molecular conformation problem, in this paper we deal with the most
simple type of box symmetry, namely that in which some domain variables (i.e., box dimensions) undergo a single-cycle permutation leaving the constraints invariant. To be clear, if
the cycle involves n variables, our algorithm handles the n − 1 symmetries (excluding the
c
2009
AI Access Foundation. All rights reserved.

Ruiz de Angulo & Torras

identity) generated by this cycle by composition. Since the computational gain will be
shown to be roughly proportional to n, the longest cycle appearing in the problem formulation should be chosen as input to our algorithm.
This single-cycle permutation that leaves the constraints unchanged is a form of constraint symmetry in the terminology introduced by Cohen, Jeavons, Jefferson, Petrie, and
Smith (2006). Note that any constraint symmetry is also a solution symmetry, but not the
other way around. Thus, the symmetries we deal with are a subset of all possible solution
symmetries; the advantage is that they can be assessed (although perhaps are difficult to
find) from the problem formulation, therefore being operative.
Our approach to exploit symmetries in continuous constraint problems requires the
initial domain for the symmetric variables to be an n-cube, as it starts by subdividing this
cube at the same point along all dimensions at once. Since box symmetry is a transitive
relation, the subboxes resulting from the subdivision fall into equivalence classes. Then, a
B&P algorithm (or any similar continuous constraint solver) is called on only the subboxes
that are representatives of each symmetry equivalence class. Finally, for each solution found,
all its symmetric ones are generated. Note that symmetry handling doesn’t interfere with
the inside workings of the constraint solver.

2. Symmetry in Continuous Constraint Problems
We are interested in solving the following general continuous Constraint Satisfaction Problem (continuous CSP): Find all points x = (x1 , . . . , xn ) lying in an initial box of Rn satisfying
the constraints f1 (x) ∈ C1 , . . . , fm (x) ∈ Cm , where fi is a function fi : Rn → R, and Ci is
an interval in R.
The only particular feature that we require of a Continuous Constraint Solver (CCS)
is that it has to work with an axis-aligned box in Rn as input. Also, we assume that the
CCS returns solution boxes. Note that a CCS returning solution points is a limit case still
contained in our framework.
We say that a function s : Rn → Rn is a point symmetry of the problem if there exists an
associated permutation σ ∈ Σm such that fi (x) = fσ(i) (s(x)) and Ci = Cσ(i) , ∀i = 1, . . . , m.
We consider symmetry as a property that relates points that are equivalent as regards to a
continuous CSP. Concretely, from the above definition one can conclude that
• x is a solution to the problem iff s(x) is a solution to the problem.
Let s and t be two symmetries of a continuous CSP with associated permutations σs
and σt . It is easy to see that the composition of symmetries s(t(·)) is also a symmetry with
associated permutation σs (σt (·)).
An interesting type of symmetries are permutations (bijective functions of a set onto
itself) of the components of x. Let D be a finite set. A cycle of length k is a permutation
ψ such that there exist distinct elements a1 , . . . ak ∈ D such that ψ(ai ) = ψ(a(i+1)mod k )
and ψ(z) = z for any other element z ∈ D. Such a cycle is represented as (a1 , . . . ak ).
Every permutation can be expressed as a composition of disjoint cycles (i.e, cycles without
common elements), which is unique up to the order of the factors. Composition of cycles is
represented as concatenation, as for example (a1 , . . . ak )(b1 , . . . bl ). In this paper we focus
on a particular type of permutations, namely those constituted by a single cycle. In its
500

Exploiting Single-Cycle Symmetries

simplest form1 , this is s(x1 , x2 , . . . xn ) = (xθ(1) , xθ(2) , . . . xθ(n) ) = (x2 , x3 ...xn , x1 ), where
θ(i) = (i + 1) mod n.
Example: n = 3, m = 4, x = (x1 , x2 , x3 ) ∈ [−1, 1] × [−1, 1] × [−1, 1],
f1 (x) :

x21 + x22 + x23 ∈ [5, 5] ≡ x21 + x22 + x23 = 5

f2 (x) :

2x1 − x2 ∈ [0, ∞] ≡ 2x1 − x2 > 0

f3 (x) :

2x2 − x3 ∈ [0, ∞] ≡ 2x2 − x3 > 0

f4 (x) :

2x3 − x1 ∈ [0, ∞] ≡ 2x3 − x1 > 0

There exists a symmetry s(x1 , x2 , x3 ) = (x2 , x3 , x1 ), for which there is no need of reordering the variables. The constraint permutation associated to s is σ(1) = 1, σ(2) = 3,
σ(3) = 4, and σ(4) = 2.
Generally there is not a unique symmetry for a given problem. If there exists a symmetry
s, then for example s2 (x) = s(s(x)) is another symmetry. In general, using the convention of
denoting s0 (x) the identity mapping, {si (x), i = 0 . . . n−1} is the set of different symmetries
that can be obtained composing s(x) with itself, while for i > n we have that si (x) =
si mod n (x). Thus, a single-cycle symmetry generates by composition n − 1 symmetries,
excluding the trivial identity mapping. Some of them may have different numbers of cycles.
Imagine for example that in a continuous CSP with n = 4 the permutation of variables (1
2 3 4) is a symmetry. Then, the permutation obtained by composing it twice, (1 3)(2 4),
is also a symmetry of the problem, but has a different number of cycles, and the longest
cycle has length two instead of four. Besides, the former permutation cannot be generated
from the latter. The algorithm presented in this paper deals with all the compositions
of a single-cycle symmetry, even if some of them are not single-cycle symmetries. The
gain obtained with the proposed algorithm will be shown to be roughly proportional to
the number of different compositions of the selected symmetry. Therefore, when several
single-cycle symmetries exist in a continuous CSP problem, the algorithm should be used
with that generating the most symmetries by composition, i.e., with that having the longest
cycle. Note that the single-cycle permutations we are dealing with need not encompass all
the problem variables, since the the remaining ones will be considered fixed (unitary cycles).

3. Box Symmetry
Since continuous constraint solvers work with boxes, we turn our attention now to the set
of points symmetric to those belonging to a box B ⊆ Rn . 2
Let s be a single-cycle symmetry corresponding to the circular variable shifting θ introduced in the preceding section, and B = [x1 , x1 ]×. . .×[xn , xn ] a box in Rn . The box symme1. In general, the variables must be arranged in a suitable order before one can apply the circular shifting. Thus, the general form of a single-cycle symmetry is s(x) = h−1 (g(h(x))), where
h(x1 , . . . xn ) = (xφ(1) , . . . , xφ(n) ), φ ∈ Σn is a general permutation that orders the variables, and
g(x1 , . . . , xn ) = (xθ(1) , . . . xθ(n) ) is the circular shifting above. Thus, the cycle ψ defining the symmetry can be expressed as ψ = φ−1 (θ(φ(·))). Since the reordering does not change substantially the
presented concepts and algorithms, we have simplified notation in the paper by assuming that the order
of the component variables is the appropriate one, i.e., that ψ = θ .
2. This set {s(x) s.t. x ∈ B} is also a box if s(x) = (s1 (x), . . . , sn (x)) = (g1 (xφ(1) ), . . . , gn (xφ(n) )), where
si is the i-th component of s, φ is an arbitrary permutation, and gi : R → R is any function such that if
I is an interval of R then {gi (x) s.t. x ∈ I} is also an interval of R.

501

Ruiz de Angulo & Torras

try function S is defined as S(B) = {s(x) s.t. x ∈ B} = [xθ(1) , xθ(1) ] × . . . × [xθ(n) , xθ(n) ] =
[x2 , x2 ] × . . . × [xn , xn ] × [x1 , x1 ]. The box symmetry function has also an associated constraint permutation σ, which is the same associated to s. S i will denote S composed i
times. We say, then, that B1 and B2 are symmetric boxes if there exists i s.t. S i (B1 ) = B2 .
Box symmetry is an equivalence relation defining symmetry equivalence classes. Let
R(B) be the set of different boxes in the symmetry class of B, R(B) = {S i (B), i ∈ {0, . . . , n−
1}}. For instance, for box B 0 = [0, 4] × [2, 5] × [2, 5] × [0, 4] × [2, 5] × [2, 5], R(B 0 ) is composed
of S 0 (B 0 ) = B 0 , S 1 (B 0 ) = [2, 5]×[2, 5]×[0, 4]×[2, 5]×[2, 5]×[0, 4] and S 2 (B 0 ) = [2, 5]×[0, 4]×
[2, 5]×[2, 5]×[0, 4]×[2, 5]. Note that S 3 (B 0 ) is again B 0 itself and that subsequent applications
of box symmetry would repeat the same sequence of boxes. We define the period P (B) of
a box B as P (B) = |R(B)|. It is easily shown that R(B) = {S i (B), i ∈ {0, . . . , P (B) − 1}}.
For example, for box B 0 , R(B 0 ) = {S 0 (B 0 ), S 1 (B 0 ), S 2 (B 0 )} and P (B 0 ) = 3.
Box symmetry has implications for the continuous CSP, which are a direct consequence
of the point symmetry case:
• If there is no solution inside a box B, there is no solution inside any of its symmetric
boxes either.
• A box B∫ ⊆ B is a solution iff S i (B∫ ) ⊆ S i (B) is a solution box for all i ∈ {1 . . . P (B) −
1}.
Sketch of proof for the first statement: Assume there is no solution inside B and there is
some solution xsol inside S i (B). By definition of box symmetry there exists a point x0sol ∈ B
such that xsol = si (x0sol ). Using the property highlighted in Section 2 we deduce that x0sol
must be also a solution, which contradicts the hypothesis.
Sketch of proof for the second statement: A solution box is a box with at least a solution
point inside. Assume B∫ ⊆ B is a solution box containing the solution point xsol . Inside
S i (B∫ ) there is the point si (xsol ) that, by the property highlighted in Section 2, must be
also a solution. Conversely, assume now that S i (B∫ ) ⊆ B is a solution box. Thus it contains
at least a solution point, xsol . By definition of symmetric box, this point has a symmetric
point x0sol ∈ B∫ such that xsol = si (x0sol ). Using the property in Section 2 again we conclude
that x0sol must be also a solution and, thus, B∫ is a solution box.
Both statements can be rephrased as follows :
• If the set of solution boxes contained in a box B is SolSet, the set of solution boxes
contained in its symmetric box S i (B) is {S i (B∫ ) s.t. B∫ ∈ SolSet}
This means that once the solutions inside B have been found, the solutions inside its
symmetric boxes S i (B), i ∈ {1 . . . P (B) − 1} are available without hard calculations. In the
following sections we will show how to exploit this property to save much computing time
in a meta-algorithm that uses a CCS as a tool without interfering with it.
3.1 Box Symmetry Classes Obtained by Bisecting a n-cube
The algorithm we will propose to exploit box symmetry makes use of the symmetry classes
formed by bisecting a n-dimensional cube I n (i.e., of period 1) in all dimensions at the
same time and at the same point, resulting in 2n boxes. We will denote L and H the
two subintervals into which the original range I is divided. For example, for n = 2, we
502

Exploiting Single-Cycle Symmetries

have the following set of boxes {L × L, L × H, H × L, H × H} whose periods are 1, 2,
2 and 1, respectively. And their symmetry classes are: {L × L}, {L × H, H × L}, and
{H × H}. Representing the two intervals L and H as 0 and 1, respectively, and dropping
the × symbol, the sub-boxes can be coded as binary numbers. Let SRn be the set of
representatives, formed by choosing the smallest box in binary order from each class. For
example, SR2 = {00, 01, 11}. Note that the cube I n to be partitioned can be thought of
as the the set of binary numbers of length n, and that SRn is nothing more than a subset
whose elements are different under circular shift.
The algorithm for exploiting symmetries and the way it uses SRn are explained in the
next section. Afterwards, in Sections 6 and 7, we study how many components SRn has,
how they are distributed and, more importantly, how can they be generated.

4. Algorithm to Exploit Box Symmetry
Algorithm 1: CSym1 algorithm.
Input: A n-cube, [xl , xh ] × · · · × [xl , xh ].
A single-cycle box symmetry, S.
A Continuous Constraint Solver, CCS.
Output: A set of boxes covering all solutions.

5

SolutionBoxSet ← EmptySet
x∗ ← SelectBisectionPoint(xl , xh )
foreach b ∈ SRn do
B ← GenerateSubBox(b, xl , xh , x∗ )
SolutionBoxSet ← SolutionBoxSet ∪ ProcessRepresentative(B)

6

return SolutionBoxSet

1
2
3
4

The symmetry exploitation algorithm we propose uses the CCS as an external routine.
The internals of the CCS must not be modified or known.
The idea is to first divide the initial box into a number of symmetry classes. Next, one
needs to process only a representative of each class with the CCS. At the end, by applying
box symmetries to the solution boxes obtained in this way, one would get all the solutions
lying in the space covered by the whole classes, i.e., the initial box. The advantage of this
procedure is that the CCS would have to process only a fraction of the initial box. Assuming
that the initial box is a n-cube covering the same interval [xl , xh ] in all dimensions, we can
directly apply the classes associated to SRn . A procedure to exploit single-cycle symmetries
in this way is presented in Algorithm 1.
Since SRn is a set of codes —not real boxes— we need a translation of the codes into
boxes for the given initial box. The operator GenerateSubBox(b, xl , xh , x∗ ) returns the
box V = V1 × · · · × Vn corresponding to code b = b1 . . . bn when [xl , xh ] is the range of the
initial box in all dimensions and x∗ is the point in which this interval is bisected:
(
[xl , x∗ ] if bi = 0,
Vi =
(1)
[x∗ , xh ] if bi = 1.
503

Ruiz de Angulo & Torras

The point x∗ calculated by SelectBisectionPoint(xl , xh ) can be any such that xl <
< xh , but a reasonable one is (xl + xh )/2. The iterations over line 4 generate a set of
representative boxes such that, together with their symmetries, cover the initial n-cube.
ProcessRepresentative(B) returns all the solution boxes associated to B, that is, the
solutions inside R(B), or still in other words, the solutions inside B and inside its symmetric
boxes. ProcessRepresentative(B) is based on the property stated at the end of Section
3, which allows to obtain all the solutions in the class of B by processing only B with the
CCS. SolSet is the set of solutions found inside the representative box of the class, B.
ApplySymmetry(SolSet, S i ) calculates the set of solutions of box S i (B) by applying S i
to each of the boxes in SolSet. Since the number of symmetries of B is P (B), the benefits
of exploiting the symmetries of a class representative is proportional to its period.
x∗

Algorithm 2: The ProcessRepresentative function.
Input: A box, B.
A single-cycle box symmetry, S.
A Continuous Constraint Solver, CCS.
Output: The set of solution boxes contained in B and its symmetric boxes.

4

SolSet ← CCS(B)
T otalSolSet ← SolSet
for i=1: P (B) − 1 do
T otalSolSet ← T otalSolSet ∪ ApplySymmetry(SolSet, S i )

5

return T otalSolSet

1
2
3

The correctness of the algorithm is easy to check. The set of boxes in which it searches explicitly or implicitly (by means of symmetry) for solutions is U = {R(B) s.t. B is a representative}.
In fact, U is the set of boxes formed by bisecting the initial box in all dimensions at the same
time and at the same point. U covers the whole initial box and, thus, the algorithm finds
all the solutions of the problem. Moreover, it finds each solution box only once, because
the boxes in U do not have any volume in common (they share at most a “wall”).
4.1 Discussion on the Efficiency of CSYM1
The CSym1 algorithm launches the CCS algorithm on |SRn | small boxes instead of on only
the original large one. Three factors affect its efficiency as compared to that of the standard
approach:
1. Fraction of domain processed. Only a fraction of the original domain is directly
dealt with by the CCS. This fraction is a function of the periods of the SRn components. One element of period p represents a class formed by p boxes, only one of
which is processed with the CCS. Since all the boxes of the classes are of equal size,
the above fraction can be calculated by dividing the number of representatives by the
n|
P |SRn |
total number of boxes in the classes, |SR
2n =
P (B) . The expected time gain
P

B∈SRn

P (B)

n
is the inverse of this quantity, B∈SR
denoted by IFDP (Inverse of the Fraction
|SRn |
of Domain Processed). When n grows (see Section 6), the majority of the elements

504

Exploiting Single-Cycle Symmetries

of SRn have period n, and thus IFDP tends to n. However, for low n, IFDP can
be significantly smaller than n. This is the main factor determining the efficiency of
CSym1.
2. Smaller processed boxes. Since the CCS initial boxes using CSym1 are 2n times
smaller than the original initial box, the average size of the boxes processed by the
CCS is also smaller than in the standard case. Prune (box reduction or contraction)
step is carried out more quickly on smaller boxes in Branch-and-Prune algorithms.
In fact, best Branch-and-Prune algorithms have box contraction operators exhibiting
second-order convergence, but this contraction rate requires small enough boxes to
hold in practice.
3. Number of representatives. There is a disadvantage in fractioning excessively
the initial domain. We can see this by noting that, using the original large initial
box, if a contraction operator lowers the upper bound of a symmetric variable, this
information could be used to lower the upper bound of the same variable in many
representative boxes in SRn . As commented above, this contraction operator would
act more strongly on the representatives themselves, but the “loss of parallelization”
effect is anyway present. This factor is irrelevant for small-length cycle symmetries,
say up to n = 6, because |SRn | is very small (see Section 6 again) as compared to the
number of boxes that a CCS must process in general. However, when n approaches
20, the number of representatives begins to become overwhelming.

5. Two Illustrative Examples
The two problems below have been solved with the Branch-and-Prune CCS presented by
Porta, Ros, Thomas, Corcho, Canto, and Perez (2008). It is a polytope-based method
similar to that of Sherbrooke E. C. (1993) with global consistency, which exhibits quadratic
convergence. The machine used to carry out all the experiments in the paper is a 2.5 Ghz
G5 Apple computer.
5.1 Cycloheptane
Molecules can be modeled as mechanical chains by making some reasonable approximations.
If two atoms are joined by a chemical bond, one can assume that there is a rigid link between
them. Thus, the first approximation is that bond lengths are constant. The second one
is that the angles between two consecutive bonds are also constant. In other words, the
distances between the atoms in any subchain of three atoms are assumed to be constant. All
configurations of the atoms of the molecule that satisfy these distance constraints, sometimes
denoted rigid-geometry hypothesis, are valid conformations of the molecule in a kinematic
sense. The constraints induced by the rigid-geometry hypothesis are particularly strong
when the molecule topology forms loops, as in cycloalkanes. The problem of finding all
valid conformations of a molecule can be formulated as a distance-geometry (Blumenthal,
1953) problem in which some distances between points (atoms) are fixed and known, and
one must find the set of values of unknown (variable) distances that are compatible with
the embedding of the points in R3 . The unknown distances can be found by solving a set
505

Ruiz de Angulo & Torras

of constraints consisting of equalities or inequalities of determinants formed with subsets of
the fixed and variable distances (Blumenthal, 1953).

d2
d3

d1
d7

d5

d6

d4

Figure 1: Cycloheptane. Disks represent carbon atoms. Constant and variable distances
between atoms are represented with continuous and dashed lines, respectively.

Figure 2: Three-dimensional projection of the cycloheptane solutions. The lightest (yellow)
boxes are the solutions found inside the representatives using the CCS (line 1 in
Algorithm 2). The other colored boxes are the solutions obtained by applying
symmetries to the yellow boxes (line 4 in Algorithm 2).

Figure 1 displays the known and unknown distances of the cycloheptane, a molecule basically composed of a ring of seven carbon atoms. The distance between two consecutive atoms
of the ring is constant and equal everywhere. The distance between two atoms connected to
506

Exploiting Single-Cycle Symmetries

a same atom is also known and constant no matter the atoms. The problem in underconstrained, having an infinite number of solutions of dimensionality 1. The problem has several
symmetries. We use one of them, s(d1 , . . . , d7 ) = (dθ(1) , dθ(2) , . . . , dθ(7) ) = (d2 , d3 . . . , d7 , d1 ).
The length of the only cycle of this symmetry is n = 7, for which IFDP is 6.4.
The number of boxes processed using the raw CCS without symmetry handling is 1269,
while using CSym1 the total number is 196, giving a ratio of 6.47 ≈ IFDP. The problem is
solved in 4.64 minutes using CSym1, which compares very favorably with the 31.6 minutes
spent when using the algorithm of Porta et al. (2008) alone, a reduction by a factor of 6.81,
slightly greater than IFDP. This means that, although the number of representatives begins
to be relevant (|SR7 | = 20), factor 2 in Section 4.1 is more determining than factor 3 in
the same section, since the (small) time overhead introduced by handling box symmetries
is also included in the reported time. Figure 2 shows a projection into d1 , d2 and d3 of the
solutions obtained using CSym1. The solutions were found inside five representative boxes
of period seven, containing 16, 1, 4, 64 and 1 solution boxes, respectively, at the chosen level
of resolution. The total number of solutions boxes is therefore 7(16+1+4+64+1)= 602.
5.2 Cyclic n-roots Problem
The following polynomial equation system is the n = 5 instance of the so-called cyclic
n-roots problem as described by Björck and Fröberg (1991).

x1 + x2 + x3 + x4 + x5 = 0
x1 x2 + x2 x3 + x3 x4 + x4 x5 + x5 x1 = 0
x1 x2 x3 + x2 x3 x4 + x3 x4 x5 + x4 x5 x1 + x5 x1 x2 = 0
x1 x2 x3 x4 + x2 x3 x4 x5 + x3 x4 x5 x1 + x4 x5 x1 x2 + x5 x1 x2 x3 = 0

(2)

x1 x2 x3 x4 x5 − 1 = 0

There are ten real solutions to this problem. The system has a single-cycle symmetry:
s(x1 , . . . , x5 ) = (x2 , x3 , x4 , x5 , x1 ), as well as a multiple-cycle symmetry not considered in
this paper. Thus, the cycle length is n = 5, |SR5 | = 8, and the IFDP is 4. When running
the CCS alone using as initial box [−10, 10]5 , the number of processed boxes is 399, while
exploiting the aforementioned symmetry with the CSym1 algorithm this number reduces
to 66. In the last case, two solutions were found in a representative box of period 5, which
through symmetry led to the ten solutions. Running times are 16.86 seconds (CCS alone)
and 2.08 seconds (CSym1) giving a gain of more than eight. This is the double of the IFDP,
which highlights the benefits that factor 2 in Section 4.1 can bring to the efficacy of the
approach. The number of representatives is very small compared to the number of boxes
processed by the CCS alone, making factor 3 in Section 4.1 irrelevant in this case.
Table 1 contains the results for n=4 to n=8 of the cyclic n-roots problem in the [−10, 10]n
domain, except for n=8 for which the domain was [−5, 5]8 . For n=4 and n=8 there is a
continuum of solutions which, with the chosen resolution, produces 992 and 2435 solution
boxes, respectively. Because of this, the number of processed boxes for n=5 is smaller
than for n=4, but logically smaller also than for n=6 to n=8. Two observations can be
507

Ruiz de Angulo & Torras

IFDP
number of processed boxes CCS alone
number of processed boxes CSym1
rate of processed boxes
time CCS alone
time CSym1
time gain CSym1

n=4

n=5

n= 6

n=7

2.7
1855
500
3.7
12.0
3.0
4.0

4.0
399
66
6.0
16.9
2.1
8.1

4.5
3343
510
6.6
642.0
95.8
6.7

6.4
38991
5070
7.7
20442.0
2689.7
7.6

n=8
(reduced domain)
7.1
108647
13304
8.2
227355.2
27296.5
8.3

Table 1: Results for the n-cyclic roots problem. Times are given in seconds.

made. First, the time gains are always higher than the corresponding IFDP’s, implying a
preponderance of factor 2 in Section 4.1 over factor 3. Second, the time gain follows rather
accurately the rate between the number of processed boxes using the CCS alone and using
CSym1.
Tests on the cyclic n-roots problem using a classical CCSP solver, RealPaver (Granvilliers & Benhamou, 2006), have been carried out (Jermann, 2008). The results are preliminary and difficult to expose concisely, since there is a great variability depending on issues
such as the pruning method used (RealPaver offers several options) and how the problem
is coded (factorized or not). In every case, however, we have observed time gains greater
than expected by the IFDP.

6. Analysis of SRn : Counting the Number of Classes
Let us define some quantities of interest:
-Nn : Number of elements of SRn .
-FP n : Number of elements of SRn that correspond to full-period boxes, i.e., boxes of period
n.
-Nnm : Number of elements of SRn having m 1’s.
-FP nm : Number of elements of SRn that correspond to full-period boxes having m 1’s.
Polya’s theorem (Polya & Read, 1987) could be used to determine some of these quantities for a given n by building a possibly huge polynomial and elucidating some of its
coefficients. We present a simpler way of calculating them and, at the same time, make the
reader familiar with the concepts that will be used in our algorithm to generate SRn .
We begin by looking for the expression of FP n . When any number of 1’s is allowed,
the total number of binary numbers is 2n . The only periods that can exist in these binary
numbers are divisors of n. Thus, the following equation holds:
X

p FP p = 2n .

p∈div(n)

Segregating p = n,
508

(3)

Exploiting Single-Cycle Symmetries

X

n FP n +

p FP p = 2n ,

(4)

p
FP p .
n

(5)

p∈div(n), p<n

and solving for FP n :
FP n =

2n
−
n

X
p∈div(n), p<n

This recurrence has a simple baseline condition: FP 1 = 2.
Then, Nn follows easily from
Nn =

X

FP p .

(6)

p∈div(n)

Segregating p = n, a more efficient formula is obtained:
Nn =

2n
+
n

X
p∈div(n), p<n

n−p
FP p .
n

(7)

This formula is valid for n > 1. The remaining case is N1 = 2.

n
We will use similar techniques to obtain FP nm and Nnm . There are m
binary numbers
having m 1’s and n − m 0’s. Some of these binary numbers are circular shifts of others
(like 011010 and 110100). The number of shifted versions of a binary number is the period
of the box being represented by the binary number. For example, 1010, of period 2, has
only another shifted version, 0101. A binary number representing a box of period p can be
n
seen as a concatenation of n/p numbers of length n/p
= p and period p. This means that
m
these “concatenated” numbers are full-period, and they have n/p
1’s. Thus, the number of
binary numbers of period p when shifted numbers are counted as the same (i.e., the number
n
m . Only common divisors of n and m, which we denote
of classes of period p) is FP n/p
n/p
div(n, m), can be periods. Since there are p shifted versions of each binary number having
period p, we can write
 
X
n
n
m =
p FP n/p
.
(8)
n/p
m
p∈div(n,m)

With a change of variable f = n/p we get
X
f ∈div(n,m)

n
FP nf mf =
f

 
n
.
m

(9)

Note that the index of the summation goes through the same values as before. We can
segregate the case f = 1 from the summand,
 
X
n
n
n FP nm +
FP nf mf =
,
(10)
f
m
f ∈div(n,m), f >1

and, finally, we obtain
509

Ruiz de Angulo & Torras

FP nm =

n
m



n

FP nf mf

X

−

f

f ∈div(n,m), f >1

.

(11)

This is a recurrence relation from which FP nm can be computed using the following
baseline conditions:
(
0
=
1

FP nn , FP n0

if n > 1
if n = 1

(12)

Nnm is obtained adding up the number of classes of each period:
Nnm =

X

FP nf mf .

(13)

f ∈div(n,m)

Segregating again f = 1, a more efficient formula is obtained:
Nnm =

 
n
+
m

X

n
)FP nf mf ,
f

(14)

(1 − p)FP p mp ,

(15)

(1 −

f ∈div(n,m), f >1

then carrying out the change of variable p = n/f :
Nnm =

 
n
+
m

X

n

p∈div(n,m), p<n

Note the change in the summation range. This equation is valid whenever m > 0 and
m < n. Otherwise, Nnm = 1.
It is possible to extend the concept of FP n (and FP nm ) to reflect the number of members
p
):
of SRn having period p (and m 1’s), which we denote Nnp (Nnm
Nnp

p
Nnm

(
0
=
FP p

if p ∈
/ div(n)
otherwise

(
0
=
FP p, mp
n

if p ∈
/ div(n, m)
otherwise

(16)

(17)

Figure 3(a) displays the number of classes (Nn ) as a function of n. The curve indicates
an exponential-like behavior. This is confirmed in Figure 3(b) using a larger logarithmic
scale, in which the curve appears almost perfectly linear. Figure 4 is an example of the
distribution of classes by period for n = 12. Figure 5 shows the percentage of full-period
classes in SRn (100 Nnn /Nn ). One can see that the percentage of classes with period different
from n is significant for low n, but approaches quickly 0 as n grows. Finally, Figures 6(a)
and 6(b) display the distribution of the classes in SRn by number of 1’s for n = 12 and
n = 100, respectively. The majority of the classes concentrates in an interval in the middle
of the graphic, around n/2. This interval becomes relatively smaller when n grows.
510

number of classes of symmetric boxes

350
300
250
200
150
100
50
0

2

4

6

8

10

12

1x1011
1x1010
1x109
1x108
1x107
1x106
1x105
1x104
1x103
1x102
1x101
1

0

5

box dimensionality (i.e., number of variables)

10

15

20

25

30

(b)

Figure 3: Number of elements of SRn as a function of n.

100

10

1

1

2

3

4

35

box dimensionality (i.e., number of variables)

(a)

number of classes of symmetric boxes

number of classes of symmetric boxes

Exploiting Single-Cycle Symmetries

5

6

7

8

9

10

11

12

box period

Figure 4: Number of elements of SR12 distributed by period.

511

40

Ruiz de Angulo & Torras

7. Generating SRn , the Classes of Symmetric Boxes
The naive procedure to obtain SRn would initially generate all boxes originated by bisecting
a n-dimensional cube at the same point in all dimensions at the same time. Then, one should
check each of the boxes in this set to detect whether it is a circular shift of some of the
others. The complete process of generating SRn in this way involves a huge number of
operations even for rather small dimensions. Although the SRn for a few n’s could be precomputed and stored in a database, we suggest here an algorithm capable of calculating
SRn on the fly without significant computational overhead.

percentage of full-period classes

100

80

60

40

20

0
2

4

6

8

10

12

14

16

18

20

box dimensionality (i.e., number of variables)

Figure 5: Percentage of full-period elements in SRn as a function of n.

number of classes of symmetric boxes

number of classes of symmetric boxes

As made for counting, we distinguish different subsets of SRn on the basis of the number
of 1’s and the period:
-SRnm : Subset of the elements of SRn having m 1’s.
-SRpnm : Subset of the elements of SRn having m 1’s and period p.
–SRpn : Subset of the elements of SRn having period p.
From a global point of view, the generation of SRn is carried out as follows. First,
SRn0 is generated, which is constituted always by a unique member. Afterwards, all SRnm

70
60
50
40
30
20
10
0

0

2

4

6

8

10

12

1x1027
8x1026
6x1026
4x1026
2x1026

0

0

20

40

60

80

100

number of 1´s in the code

number of 1´s in the code

(a)

(b)

Figure 6: Number of elements of SRn distributed by number of 1’s. (a) n =12. (b) n=100.

512

Exploiting Single-Cycle Symmetries

for m = 1 . . . n are generated. The generation of SRnm is divided in each of the SRpnm ,
p ∈ div(n, m), that compose it. The algorithm ClassGen described below generates all
full-period representatives for any given number of variables n > 1 and number of ones
m > 0, i.e., it generates SRnnm . The representatives of a lower period p ∈ div(n, m) are
obtained by concatenating one same block n/p = f times. Therefore, in order to obtain
SRpnm , we generate SRpp m with our same algorithm, and then concatenate their elements
f

f times. Thus, without loss of generality, in what follows we describe the workings of the
algorithm ClassGen when it computes codes of full period, namely n.
We use a compact coding of the binary numbers representing the boxes consisting in
ordered lists or chains of numbers. The first number of the code is the number of 0’s
appearing before the first 1 in the binary number. The i-th number of the code for i > 1 is
the number of 0’s between the (i−1)-th and the i-th 1’s of the binary number. For example,
the number 0100010111 is codified as 13100. The length of this numerical codification is
the number of 1’s of the codified binary number, which has been denoted by m.
There are binary numbers that cannot be codified in this way, because their last digit
is 0. But, except for the all zero’s case, there is always an element of its class that can be
codified correctly (for example 0011 is an element of the class of 0110). As our objective is
to have only a representative of each class, this is rather an advantage, because half of the
boxes are already eliminated from the very beginning. The all zero’s box, SRn0 , is common
to every n, and will be generated separately, as already mentioned.
The codification allows to determine if a box is full-period in the same way as in the
binary representation: the box has period n iff after a number of circular shifts lower than
the length of the numerical chain the result is never equal to the original. For instance, the
example above is full-period, but 22, corresponding to 001001, is not. The only difference
is that, in the new representation, at most m shifts must be compared.
The code of a box can be seen as a number of base n − m. In a full-period box, the m
circular shifts of the code are different numbers, and can be arranged in strictly increasing
numerical order. We will take as representative box of a class the largest element of the
class when expressed as a code (which is the smallest when expressed as a binary number).
For example, the class of 130 has two other elements that can be represented by our coding,
013 and 301, the latter being the chosen representative of the class.
Note that a box belonging to SRnm has n − m 0’s or, equivalently, the sum of the
components of the code is n − m.
The output of the algorithm are all codes of length m, whose sum of components is
n − m, and which are both representatives of a class and full-period. Codes of length m
whose components sum up a desired number are rather easy to generate systematically.
The representativeness and full-period conditions are more difficult to guarantee efficiently.
We can handle them by exploiting the properties of our codes stated below, which make
use of the definition of i-compability.
We say that a code is i-compatible or compatible for position i if a sub-chain of it
beginning at position i > 1 and ending at the last position m (thus of length m − i + 1)
is strictly smaller in numerical terms than the sub-chain of the same length beginning at
the first position. For example, 423423 is compatible for positions 2 and 3, but it is not
4-compatible.
513

Ruiz de Angulo & Torras

Property 1 A code is a class representative and it is full-period iff it is i-compatible for
all i s.t. 1 < i 6 m.
Thus, instead of comparing chains of length m (i.e., the code and its shifted versions),
we can determine the code validity comparing shorter sub-chains. A second property helps
us to devise a still faster and simpler algorithm:
Property 2 If a code is i-compatible and the sub-chain from position i to i + l is equal to
the sub-chain from position 1 to 1 + l then the code is also compatible for positions i + 1
through i + l.

Algorithm 3: CodeValidity algorithm.
Input: A code of length m expressed as an array, A.
Output: A boolean value indicating whether the code is valid, i.e., whether it is
full-period and a class representative.
1
2
3
4
5
6
7
8
9
10

i←2
ctrol ← 1
V alidCode ← True
while V alidCode & i < m do
if A[i] > A[ctrol] then V alidCode ← F alse
else if A[i] < A[ctrol] then ctrol ← 1
else ctrol ← ctrol + 1;
i←i+1

/* A[i] = A[ctrol] */

if A[m] ≥ A[ctrol] then V alidCode ← F alse
return ValidCode

This property is interesting because it permits checking the validity of the code by
travelling along it at most once, as shown in Algorithm 3. The trick is that when the decision
of i-compatibility is being delayed because position i and the following numbers are the same
as those at the beginning of the string, if it finally resolves positively, the compatibility for
the intermediate numbers is also guaranteed. Hence, i-compatibility is either resolved with
a simple comparison or it requires l comparisons. In the latter case, either the compatibility
of l positions is also resolved (if the outcome is positive) or compatibility of intermediate
positions doesn’t matter (because the outcome is negative and, thus, the code can be labelled
non valid without further checks). A ctrol variable is in charge of maintaining the last index
of the “head” sub-chain that is being compared in the current compatibility check. When
examining the compatibility of the current position i, if its value is lower than that of the
ctrol position, the code is for sure i-compatible and therefore we must only worry about
(i + 1)-compatibility by back-warding ctrol to the first position. If the value of the ctrol
position is equal to that of the current position i, the compatibility of position i is still to be
ascertained, and we continue advancing the current and the ctrol positions until the equality
disappears. In other words, the only condition that must be fulfilled for non rejecting as
invalid a code at position i is that
514

Exploiting Single-Cycle Symmetries

Algorithm 4: ClassGen algorithm.
Input: The sum of the numbers that remain to be written on the right (from
position pos to m), sum.
The index of the next position to be written, pos.
The index of the current control element, whose value cannot be surpassed in
the
next position, ctrol.
The length of the code, m.
Array where class codes are being generated, A.
Output: A set of codes representing classes, SR.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18

SR ← EmptySet
if pos = m then
if sum < A[ctrol] then
A[m] ← sum
SR ← {A};

/* otherwise, SR will remain EmptySet */

else
if pos = 1 then
LowerLimit = dsum/me
U pperLimit ← sum
else
LowerLimit = 0
U pperLimit ← Minimum(A[ctrol], sum)
for i = U pperLimit to LowerLimit do
A[pos] ← i
if i = A[ctrol]Sand pos 6= 1 then
/* i = A[ctrol] = U pperLimit */
SR ← SR ClassGen(sum − i, pos + 1, ctrol + 1, m, A)
else
/* i < A[ctrol] or pos = 1 */
S
SR ← SR ClassGen(sum − i, pos + 1, 1, m, A)

19
20

return SR

A[i] 6 A[ctrol],

(18)

a condition that is transformed into A[i] < A[ctrol] when i = m to resolve the last of the
pending compatibility checks. As an aside, note that our codes are more general than the
raw binary numbers, and that representativeness and full-periodness are defined in the same
way for both. Therefore, the three properties and the CodeValidity algorithm apply also
to the raw binary numbers.
A rather direct way to generate SRnnm would be to generate all the codes of length
m whose sum of components is n − m (the number of zero’s when expressed as a binary
number) and then filter each of them with CodeValidity. Instead, we have taken a more
515

Ruiz de Angulo & Torras

efficient approach, generating only the codes that satisfy the conditions that need to be
checked explicitly in CodeValidity. Therefore, Algorithm 3 (presented only for clarity
purposes) is not used.
Our main procedure to obtain all full-period representatives having m 1’s, i.e., SRnnm ,
is the recursive program presented in Algorithm 4. ClassGen(n − m, 1, 1, m, A), where A
is an array of length m, must be called to obtain SRnnm , for any given n > 1, m > 0. Each
call to the procedure writes a single component of the code at the position of A indicated
by the parameter pos, beginning with pos = 1, which is subsequently incremented at each
recursive call. The recursion finishes at the rightmost end of the code, when pos = m. The
first parameter, sum, is the sum of the components of the code that remain to be written.
The range of values written at each position pos is limited by LowerLimit and U pperLimit,
except for the last position m. In the following we show the correctness of the algorithm
by verifying that these limits are chosen to satisfy the two requirements of the code:
• The sum of the numbers of any code completed by the algorithm must be n−m. First,
recall that the initial call to the algorithm is done using a parameter sum = n − m.
In any position 1 ≤ pos < m the number to be written must be greater than or
equal to the sum of the numbers still to be written, quantity represented by sum, so
that in subsequent positions it will be possible to write positive integers, or at least
zeros. This condition is imposed to U pperLimit in line 9 for pos = 1 and in line 12
(juxtaposed to code validity conditions) for 1 < pos < m. The number written at
pos is substracted from the sum parameter in the next recursive call. Finally, for
pos = m, the only possibility to satisfy the sum condition is to assign the value of
sum to the last element of the code.
• The code validity conditions, just as in CodeValidity, are that the number to be
written in position pos must be smaller than or equal to A[ctrol] for 1 < pos < m,
and strictly lower than A[ctrol] for pos = m. These conditions are reflected in the
U pperLimit assignments made in lines 12 and 3, respectively. LowerLimit is usually
(pos < 1, line 4) set to the smallest possible element of the codes, 0. But at the
beginning of the code (pos = 1, line 8) a more tight value can be chosen since, for
a value lower than the upper rounded value dsum/me, there is no way to distribute
what remains of sum among the other positions of the code without putting a value
greater than the initial one, which would make any such code non-representative.
The maintenance of the ctrol variable is similar to that within the CodeValidity
algorithm: if we write in pos something strictly minor than A[ctrol], ctrol is back-warded
to the first position. Otherwise, ctrol is incremented by 1 for the next recursive call to write
pos + 1.
The output of the algorithm is a list of valid codes in decreasing numerical order. For
instance, the output obtained when requesting SR993 with ClassGen(6, 1, 1, 3, A) is: {600,
510, 501, 420, 411, 402, 330, 321, 312}. In this example, the only case in which the recursion
arrives to pos = m without returning a valid code is the frustrated code 222, whose last
number is not written because the code is not full-period.
Figure 7 displays quantitative results that reflect the efficiency of ClassGen. The
dashed line accounts for the complete times required to generate all the class representatives
516

Exploiting Single-Cycle Symmetries

total time
millions of representatives per second

1.4

20

1.2

1
15
0.8
10

0.6

total time (seconds)

number of representatives (millions/second)

25

0.4

5

0.2
0
5

10

15

20

25

30

0

dimensionality (number of variables)

Figure 7: Total time (dashed line) to generate SRn , and rates of generation (continuous
line) of class representatives as a function of n.

SRn for n = 2 to n = 30. It is worth noting that only SR30 requires more than a second to be
entirely generated. The continuous line encodes the division of |SRn | by the time required
to generate SRn , measured in millions of class representatives generated by second. It is
evident that the efficiency of ClassGen is very high and that it even grows slightly with
n. This behavior shows that the dead-ends in the recursion are statistically insignificant,
which proves the tightness of the bounds used to enforce the values of the code numbers.

8. Conclusions
We have approached the problem of exploiting symmetries in continuous constraint satisfaction problems using continuous constraint solvers. Our approach is general and can make
use of any box-oriented CCS as a black-box procedure. The particular symmetries we have
tackled are single-cycle permutations of the problem variables.
The suggested strategy is to bisect the domain, the n-cube initial box, simultaneously
in all dimensions at the same point. This forms a set of boxes that can be grouped in box
symmetry classes. A representative of each class is selected to be processed by the CCS
and all the symmetries of the representative are applied to the resulting solutions.
In this way, the solutions within the whole initial domain are found, while having processed only a fraction of it —the set of representatives— with the CCS. The time savings
obtained by processing a representative and applying its symmetries to the solutions tend
to be proportional to the number of symmetric boxes of the representative. Therefore, symmetry exploitation is complete for full-period representatives, since they have the maximum
number of symmetric boxes. Another factor that improves the efficiency above what could
517

Ruiz de Angulo & Torras

be expected by these considerations is the smaller average size of the boxes processed by
the CCS with our approach.
We have also studied the automatic generation of the classes resulting from bisecting a
n-cube and analyzed their numerical properties. The algorithm for generating the classes
is very powerful, eliminating the convenience of any pre-calculated table. The numerical
analysis of the classes revealed that the average number of symmetries of the class representatives tends quickly to n as the number of variables, n, grows. This is good news,
since n is the maximum number of symmetries attainable with single-cycle symmetries of
n variables, leading to time reductions by a factor close to n. Nevertheless, for small n
there is still a significant fraction of the representatives not having the maximum number
of symmetries. Another weakness of the proposed strategy is the exponential growth in the
number of classes as a function of n.
The problems with small and large n should be tackled with a more refined subdivision
of the initial domain in box symmetry classes, which is left for near future work. We are
also currently approaching the extension of this work to deal with permutations of the
problem variables composed of several cycles. Another complementary research line is the
addition of constraints before the search with the CCS. These constraints will be specific for
each symmetry class. Finally, the extension to Branch-and-Bound algorithms for nonlinear
optimization could be envisaged.

Acknowledgments
This is an extended version of work presented at CP 2007 (Ruiz de Angulo & Torras, 2007).
The authors acknowledge support from the Generalitat de Catalunya under the consolidated
Robotics group, the Spanish Ministry of Science and Education, under the project DPI200760858, and the “Comunitat de Treball dels Pirineus” under project 2006ITT-10004.

References
Benhamou, F., & Goualard, F. (2000). Universally quantified interval constraints. In
Springer-Verlag (Ed.), CP ’02: Proceedings of the 6th International Conference on
Principles and Practice of Constraint Programming, pp. 67–82.
Björck, G., & Fröberg, R. (1991). A faster way to count the solutions of inhomogeneous
systems of algebraic equations, with applications to cyclic n-roots. J. Symb. Comput.,
12 (3), 329–336.
Blumenthal, L. (1953). Theory and aplications of distance geometry. Oxford University
Press.
Cohen, D., Jeavons, P., Jefferson, C., Petrie, K. E., & Smith, B. M. (2006). Symmetry
definitions for constraint satisfaction problems. Constraints, 11 (2-3), 115–137.
Flener, P., Frisch, A., Hnich, B., Kiziltan, Z., & Miguel, I. (2002). Breaking row and column
symmetries in matrix models. In CP ’02: Proceedings of the 8th International Conference on Principles and Practice of Constraint Programming, pp. 462–476. Springer.
518

Exploiting Single-Cycle Symmetries

Gent, I. P. (2002). Groups and constraints: Symmetry breaking during search. In In
Proceedings of CP-02, LNCS 2470, pp. 415–430. Springer.
Granvilliers, L., & Benhamou, F. (2006). Realpaver: An interval solver using constraint
satisfaction techniques. ACM Trans. on Mathematical Software, 32, 138–156.
Hentenryck, P. V., Mcallester, D., & Kapur, D. (1997). Solving polynomial systems using
a branch and prune approach. SIAM Journal on Numerical Analysis, 34, 797–827.
Jermann, C., & Trombettoni, G. (2003). Inter-block backtracking : Exploiting the structure in continuous csps. In In: 2nd International Workshop on Global Constrained
Optimization and Constraint Satisfaction, pp. 15–30. Springer.
Jermann, C. (2008). Personal communication..
Meseguer, P., & Torras, C. (2001). Exploiting symmetries within constraint satisfaction
search. Artif. Intell., 129 (1-2), 133–163.
Polya, G., & Read, R. (1987). Combinatorial enumeration of groups, graphs and chemical
compounds. Springer-Verlag.
Porta, J. M., Ros, L., Thomas, F., Corcho, F., Canto, J., & Perez, J. (2008). Complete
maps of molecular loop conformational spaces. Journal of Computational Chemistry,
29 (1), 144–155.
Porta, J. M., Ros, L., Thomas, F., & Torras, C. (2005). A branch-and-prune solver for
distance constraints. IEEE Trans. on Robotics, 21, 176–187.
Puget, J.-F. (2005). Symmetry breaking revisited. Constraints, 10 (1), 23–46.
Ruiz de Angulo, V., & Torras, C. (2007). Exploiting single-cycle symmetries in branchand-prune algorithms. In CP ’07: Proceedings of the 13th International Conference
on Principles and Practice of Constraint Programming, pp. 864–871.
Sam-haroud, D., & Faltings, B. (1996). Consistency techniques for continuous constraints.
Constraints, 1, 85–118.
Sherbrooke E. C., P. N. M. (1993). Computation of the solution of nonlinear polynomial
systems. Computer Aided Geometric Design, 10, 379–405.
Vu, X.-H., Silaghi, M., Sam-Haroud, D., & Faltings, B. (2005). Branch-and-prune search
strategies for numerical constraint solving. Tech. rep. LIA-Report 7, Swiss Federal
Institute of Technology (EPFL).

519

Journal of Artificial Intelligence Research 34 (2009) 1-25

Submitted 04/08; published 1/09

Interactive Policy Learning through
Confidence-Based Autonomy
Sonia Chernova
Manuela Veloso

soniac@cs.cmu.edu
veloso@cs.cmu.edu

Computer Science Dept.
Carnegie Mellon University
Pittsburgh, PA USA

Abstract
We present Confidence-Based Autonomy (CBA), an interactive algorithm for policy
learning from demonstration. The CBA algorithm consists of two components which take
advantage of the complimentary abilities of humans and computer agents. The first component, Confident Execution, enables the agent to identify states in which demonstration
is required, to request a demonstration from the human teacher and to learn a policy based
on the acquired data. The algorithm selects demonstrations based on a measure of action
selection confidence, and our results show that using Confident Execution the agent requires fewer demonstrations to learn the policy than when demonstrations are selected by
a human teacher. The second algorithmic component, Corrective Demonstration, enables
the teacher to correct any mistakes made by the agent through additional demonstrations
in order to improve the policy and future task performance. CBA and its individual components are compared and evaluated in a complex simulated driving domain. The complete
CBA algorithm results in the best overall learning performance, successfully reproducing
the behavior of the teacher while balancing the tradeoff between number of demonstrations
and number of incorrect actions during learning.

1. Introduction
Learning from demonstration is a growing area of artificial intelligence research that explores
techniques for programming autonomous agents by demonstrating the desired behavior or
task. In demonstration-based approaches, a teacher, typically a human, shows the agent
how to perform the task. The agent records the demonstrations as sequences of stateaction pairs, from which it then learns a policy that reproduces the observed behavior.
Many learning from demonstration approaches are inspired by the way humans and animals
teach each other, aiming to provide an intuitive method to transfer human task knowledge
to autonomous systems. Compared to exploration-based methods, demonstration learning
often reduces the learning time and eliminates the frequently difficult task of defining a
detailed reward function (Smart, 2002; Schaal, 1997).
In this article, we present an interactive demonstration learning algorithm, ConfidenceBased Autonomy (CBA), which enables an agent to learn a policy through interaction with
a human teacher. In this learning approach, the agent begins with no initial knowledge and
learns a policy incrementally through demonstrations acquired as it practices the task. Each
demonstration consists of a training point representing the correct action to be performed
in a particular state. The agent’s state is represented using an n-dimensional feature vector
c
2009
AI Access Foundation. All rights reserved.

Chernova & Veloso

that can be composed of continuous or discrete values. The agent’s actions are bound to a
finite set A of action primitives, the basic actions that can be combined together to perform
the overall task. Given a sequence of demonstrations (si , ai ), with state si and teacherselected action ai ∈ A, the goal is for the agent to learn to imitate the teacher’s behavior
by generalizing from the demonstrations and learning a policy mapping from all possible
states to actions in A.
The method for gathering demonstrations is at the heart of all demonstration learning
algorithms. CBA performs this function through two algorithmic components: Confident
Execution, which enables the agent to select demonstrations in real time as it interacts
with the environment using automatically calculated confidence thresholds, and Corrective Demonstration, which enables the teacher to improve the learned policy and correct
mistakes through additional demonstrations. The complete Confidence-Based Autonomy
algorithm provides a fast and intuitive method for policy learning, incorporating shared
decision making between the learner and the teacher. In our experimental evaluation, we
highlight the strengths of both learning components and compare learning performance of
five different demonstration selection techniques. Our results indicate that in a complex
domain, the Confident Execution algorithm reduces the number of demonstrations required
to learn the task compared to demonstration selection performed by the human teacher.
Additionally, we find that the teacher’s ability to correct mistakes performed by the agent
is critical for optimizing policy performance.
In Section 2, we discuss related work in learning from demonstration. We then present
an overview of the complete Confidence-Based Autonomy learning algorithm in Section 3,
followed by detailed descriptions of the Confident Execution and Corrective Demonstration
components in Sections 4 and 5, respectively. In Section 6, we present an experimental
evaluation of the complete algorithm and its components in a complex simulated driving
domain. Section 7 presents a summary and discussion of possible extensions to this work.

2. Related Work
A wide variety of algorithms for policy learning from demonstration have been proposed
within the machine learning and robotics communities. Within the context of reinforcement
learning (Sutton & Barto, 1998), demonstration has been viewed as a source of reliable
information that can be used to accelerate the learning process. A number of approaches
for taking advantage of this information have been developed, such as deriving or modifying
the reward function based on demonstrations (Thomaz & Breazeal, 2006; Abbeel & Ng,
2004; Papudesi, 2002; Atkeson & Schaal, 1997), and using the demonstration experiences
to prime the agent’s value function or model (Takahashi, Hikita, & Asada, 2004; Price &
Boutilier, 2003; Smart, 2002; Schaal, 1997).
Demonstration has also been coupled with supervised learning algorithms for policy
learning, including Locally Weighted Regression for low level skill acquisition (Grollman &
Jenkins, 2007; Browning, Xu, & Veloso, 2004; Smart, 2002), Bayesian networks for high level
behaviors (Lockerd & Breazeal, 2004; Inamura, Inaba, & Inoue, 1999), and the k-nearest
neighbors algorithm for fast-paced games and robot navigation tasks (Saunders, Nehaniv,
& Dautenhahn, 2006; Bentivegna, Ude, Atkeson, & Cheng, 2004). A recent survey covers
2

Interactive Policy Learning through Confidence-Based Autonomy

these and other demonstration learning algorithms in detail (Argall, Chernova, Browning,
& Veloso, 2009).
In addition to policy learning from demonstration, several areas of research have also
explored algorithms for demonstration selection. Within machine learning research, active
learning (Blum & Langley, 1997; Cohn, Atlas, & Ladner, 1994) enables a learner to query
an expert and obtain labels for unlabeled training examples. Aimed at domains in which
a large quantity of data is available but labeling is expensive, active learning directs the
expert to label the more informative examples with the goal of minimizing the number of
queries. In the context of reinforcement learning, the ‘Ask For Help’ framework enables an
agent to request advice from other agents when it is “confused” about what action to take,
an event characterized by relatively equal quality estimates for all possible actions in a given
state (Clouse, 1996). Similarly motivated techniques have been used in robotics to identify
situations in which a robot should request a demonstration from its teacher (Grollman &
Jenkins, 2007; Lockerd & Breazeal, 2004; Nicolescu, 2003; Inamura et al., 1999). Most
closely related to our work is the Dogged Learning algorithm (Grollman & Jenkins, 2007),
a confidence-based learning approach for teaching low-level robotic skills. In this algorithm,
the robot indicates to the teacher its certainty in performing various elements of the task.
The teacher may then choose to provide additional demonstrations based on this feedback.
While similarly motivated, our work differs from the Dogged Learning algorithm in a number
of ways, most important of which are our use of classification instead of regression in policy
learning, and our algorithm’s ability to adjust the confidence threshold to the data instead
of using a fixed value.

3. Confidence-Based Autonomy Overview
The Confence-Based Autonomy algorithm enables a human user to train a task policy
through demonstration. The algorithm consists of two components:
• Confident Execution (CE): an algorithm that enables the agent to learn a policy based
on demonstrations obtained by regulating its autonomy and requesting help from the
teacher. Demonstrations are selected based on automatically calculated classification
confidence thresholds.
• Corrective Demonstration (CD): an algorithm that enables the teacher to improve
the learned policy by correcting mistakes made by the agent through supplementary
demonstrations.
Figure 1 shows the interaction between these components. Using the Confident Execution algorithm, the agent selects states for demonstration in real time as it interacts with
the environment, targeting states that are unfamiliar or in which the current policy action is
uncertain. At each timestep, the algorithm evaluates the agent’s current state and actively
decides between autonomously executing the action selected by its policy and requesting
an additional demonstration from the human teacher.
We assume the underlying model of the agent’s task to be an MDP. The agent’s policy
is represented and learned using supervised learning based on training data acquired from
the demonstrations. Confidence-Based Autonomy can be combined with any supervised
3

Chernova & Veloso

Figure 1: Confidence-Based Autonomy learning process.
learning algorithm that provides a measure of confidence in its classification. The policy
is represented by classifier C : s → (a, c, db), trained using state vectors si as inputs, and
actions ai as labels. For each classification query, the model returns the model-selected
action a ∈ A, action selection confidence c, and the decision boundary db with the highest
confidence for the query (e.g. Gaussian component for GMMs).
To effectively select demonstrations, the learner must be able to autonomously identify
situations in which a demonstration will provide useful information and improve the policy.
Confident Execution selects between agent autonomy and a request for demonstration based
on the measure of action-selection confidence c returned by the classifier. Given the current
state of the learner, the algorithm queries the policy to obtain its confidence in selecting
an action for that state, and regulates its autonomy based on this confidence. The learner
executes the returned action ap if confidence c is above a threshold τ , which is determined
by the decision boundary of the classifier, db. Confidence below this threshold indicates that
the agent is uncertain about which action to take, so it seeks help from the teacher in the
form of a demonstration. Receiving an additional demonstration, ad , in a low confidence
situation improves the policy, leading to increased confidence, and therefore autonomy, in
future similar states. As more training data becomes available, the quality of the policy
improves and the autonomy of the agent increases until the entire task can be performed
without help from the teacher. In Section 4 we compare two methods of using classification
confidence to select states for demonstration.
Using the Confident Execution algorithm, the agent incrementally acquires demonstrations as it explores its environment. As it practices its task, the agent uses the policy it
learned up to that point to make decisions between demonstration and autonomous execution. However, by relying on the policy before learning is complete, the algorithm is likely
4

Interactive Policy Learning through Confidence-Based Autonomy

to make mistakes due to factors such as overgeneralization of the classifier or incomplete
data in some area of the state space. To address this problem this article introduces the
second algorithmic component, Corrective Demonstration, which allows the teacher to provide corrections for the agent’s mistakes. Using this method, when an incorrect action is
observed, the teacher provides an additional demonstration to the agent indicating which
action should have been executed in its place. In addition to indicating that the wrong action was selected, this method also provides the algorithm with the correct action to perform
in its place, ac . The correction is therefore more informative than negative reinforcement
or punishment techniques common in other algorithms, leading the agent to learn quickly
from its mistakes.
Together, Confident Execution and Corrective Demonstration form an interactive learning algorithm in which the learner and human teacher play complimentary roles. The learner
is able to identify states in which demonstration is required; in fact, our results show that the
algorithm is able to do this better than the human teacher due to differences in perception
and representation abilities. The teacher, on the other hand, possesses expert knowledge
of the overall task, which is applied to performing demonstrations and spotting execution
mistakes. This is a function the agent cannot perform on its own as it has not yet learned
the desired behavior. In this way, Confidence-Based Autonomy takes advantage of the
complimentary abilities of both human and agent. Sections 4 and 5 present the Confident
Execution and Corrective Demonstration components in detail.

4. Confident Execution Algorithm
Confident Execution is an policy learning algorithm in which the agent must select demonstration examples, in real time, as it interacts with the environment. At each timestep, the
algorithm uses thresholds to determine whether a demonstration of the correct action in
the agent’s current state will provide useful information and improve the agent’s policy. If
demonstration is required, the agent requests help from the teacher, and updates its policy based on the resulting action label. Otherwise the agent continues to perform its task
autonomously based on its policy.
There are two distinct situations in which the agent requires help from the teacher,
unfamiliar states and ambiguous states. An unfamiliar state occurs when the agent encounters a situation that is significantly different from any previously demonstrated state,
as represented by the outlying points in Figure 2. While we do not want to demonstrate
every possible state, and therefore need our model to generalize, we would like to prevent
over-generalization to truly different states.
Ambiguous states occur when the agent is unable to select between multiple actions with
certainty. This situation can result when demonstrations of different actions from similar
states make accurate classification impossible, as in the region of overlapping data classes in
Figure 2. In these cases, additional demonstrations may help to disambiguate the situation.
The goal of the Confident Execution algorithm is to divide the state space into regions
of high confidence (autonomous execution) and low confidence (demonstration) such that
unfamiliar and ambiguous regions fall into the low confidence areas. Given a world state,
two evaluation criteria are used to select between demonstration and autonomy:
5

Chernova & Veloso

• Nearest Neighbor distance: Given d = N earestN eighbor(s), the distance from the
current state to the nearest (most similar) training datapoint, the agent may act
autonomously if d is below the distance threshold τdist .
• Classification confidence: Given c, the classification confidence of the current state,
the agent may act autonomously if the value of c is above the confidence threshold
τconf .
The methods for calculating thresholds τdist and τconf are presented in Sections 4.1 and 4.2.
In this section, we continue the discussion of the Confident Execution algorithm assuming
that these values are given.
Algorithm 1 presents the details of the Confident Execution algorithm. We assume no
preexisting knowledge about the task, and initialize the algorithm with an empty set of
training points T . Since a classifier is not initially available, threshold τconf is initialized
to infinity to ensure that the agent is controlled through demonstration during the initial
learning stage. Distance threshold τdist is initialized to 0.
The main learning algorithm consists of a loop (lines 4-20), each iteration of which
represents a single timestep. The behavior of the algorithm is determined by whether the
agent is currently executing an action. If an action is in progress, the algorithm performs
no additional computation during this timestep (line 20). Once an action is complete, the
algorithm evaluates its state to determine the next action to perform (lines 6-18).
Evaluation begins by obtaining the agent’s current state in the environment (line 6).
This information is then used to calculate the nearest neighbor distance and to query the
learned classifier C to obtain policy action ap and confidence c. These values are then
compared to the confidence and distance thresholds to decide between demonstration and
autonomy (line 9). If similar states have previously been observed, and the learned model is
confident in its selection, the algorithm finishes the timestep by initiating the autonomous

Figure 2: Outlying points and regions of overlapping data classes represent unfamiliar and
ambiguous state regions, respectively.

6

Interactive Policy Learning through Confidence-Based Autonomy

Algorithm 1 Confident Execution Algorithm
1: T ← {}
2: τconf ← inf
3: τdist ← 0
4: while true do
5:
if actionComplete then
6:
s ← GetSensorData()
7:
d = NearestNeighbor(s)
8:
(ap , c, db) ← C(s)
9:
if c > τconf and d < τdist then
10:
ExecuteAction(ap )
11:
else
12:
RequestDemonstration()
13:
ad ← GetTeacherAction()
14:
if ad 6= N U LL then
15:
T ← T ∪ {(s, ad )}
16:
C ← UpdateClassifier(T )
17:
(τconf , τdist ) ← UpdateThresholds()
18:
ExecuteAction(ad )
19:
else
20:
//do nothing

execution of the policy selected action ap (line 10). Otherwise it initiates a request for
teacher demonstration (lines 12-18).
The agent requests a demonstration by pausing and indicating to the teacher that a
demonstration is required. Note that we assume the domain allows the agent to pause
execution. Following a demonstration request, the algorithm checks whether a demonstration has been performed (lines 13-14). If the teacher’s response is available, a new training
datapoint consisting of the current state and the corresponding demonstrated action ad is
added to the training set (line 15). The model classifier is then retrained, and the threshold
values updated, before executing the teacher selected action (lines 16-18).
If the teacher’s response is not immediately available, the timestep terminates and the
whole process is repeated at the next iteration. The agent again senses its state, performs
the threshold comparison and checks for a demonstration. This non-blocking mechanism
enables the agent to wait for a demonstration from the teacher without losing awareness
of its surroundings. In cases where the agent’s environment is dynamic, maintaining up
to date information is important as the state may change in the time between the initial
request and the demonstration. Associating the action label with the agent’s most recent
state, the one the teacher is most likely responding to, is therefore critical to learning an
accurate model. Additionally, changes in the environment can result in the agent attaining
a high confidence state without any actions of its own. In these cases, autonomous execution
of the task is automatically resumed. In summary, once a demonstration request is made,
no further actions are taken by the agent until either a demonstration is received from the
teacher, or changes in the environment result in a high confidence state.
7

Chernova & Veloso

Using this approach, Confident Execution enables the agent to incrementally acquire
demonstrations representing the desired behavior. As more datapoints are acquired, fewer
states distant from the training data are encountered, the performance and classification
confidence improve, and the autonomy of the agent increases. Task learning is complete
once the agent is able to repeatedly perform the desired behavior without requesting demonstrations. In the following sections we present the methods for calculating the distance and
confidence thresholds.
4.1 Distance Threshold
The purpose of the distance threshold is to evaluate the similarity between the agent’s
current state and previous demonstrations. Our evaluation metric uses the nearest neighbor
distance, defined as a the Euclidian distance between a query and the closest point in the
dataset. For each agent state query, we obtain its nearest neighbor distance representing the
most similar previously demonstrated state. This value is then compared to the distance
threshold τdist .
The value of the distance threshold τdist is calculated as a function of the average nearest
neighbor distance across the dataset of demonstrations. Evaluating the average similarity
between states provides the algorithm with a domain-independent method for detecting
outliers, points unusually far from previously encountered states. For trials in this article,
the value of τdist was set to three times the average nearest neighbor distance across the
dataset.
An alternate method for detecting outliers would be to use classification confidence and
request demonstrations in low confidence states. However, situations can arise in which
confidence is not directly correlated with state similarity. For example, for many classifiers
a set of datapoints encircling an empty region, similar to the shape of a donut, would result
in the highest classification confidence being associated with the empty center region far
from previous demonstrations. Distance provides a reliable prediction of similarity, even in
these cases.
4.2 Confidence Threshold
The confidence threshold is used to select regions of uncertainty in which points from
multiple classes overlap. From the agent’s perspective, points in these regions represent
demonstrations of two distinct actions from states that appear similar, and are difficult
to distinguish based on the sensor data. This problem frequently arises in demonstration
learning for a number of reasons, such as the teacher’s inability to demonstrate the task
consistently, noise in the sensor readings, or an inconsistency between the agent’s and
teacher’s sensing abilities. We would like to set the confidence threshold to a value that
prevents either model from classifying the overlapping region with high confidence1 . In the
following section we will discuss the use and limitations of a single fixed threshold value.
We then present an algorithm for using multiple adjustable thresholds in Section 4.2.2.
1. See Section 7.2 for further discussion of these data regions.

8

Interactive Policy Learning through Confidence-Based Autonomy

(a)

(b)

(c)

Figure 3: Examples of fixed threshold failure cases: (a) Fully separable data classes with an
overly conservative threshold value (b) Overlapping data classes with an overly
general threshold value (c) Data classes with different distributions and common
threshold value

4.2.1 Single Fixed Threshold
A single, fixed confidence threshold value provides a simple mechanism to approximate the
high confidence regions of the state space. Previous algorithms utilizing a classification confidence threshold for behavior arbitration have all used a manually-selected single threshold
value (Inamura et al., 1999; Lockerd & Breazeal, 2004; Grollman & Jenkins, 2007). However, choosing an appropriate value can be difficult for a constantly changing dataset and
model. Figure 3 presents examples of three frequently encountered problems.
Figure 3(a) presents a case in which two action classes are distinct and fully separable. A
model trained on this dataset is able to classify the points with complete accuracy, without
misclassifications. However, the current threshold value classifies only 72% of the points
with high confidence, marking the remaining 28% of the points as uncertain. In this case,
a lower threshold value would be preferred that would allow the model to generalize more
freely. The resulting larger high confidence region would reduce the number of redundant
demonstrations without increasing the classification error rate of either data class.
Figure 3(b) presents an example of the opposite case, in which a stricter threshold value
would be preferred. In this example the data classes overlap, resulting in a middle region
in which points cannot be classified with high accuracy. A higher threshold value would
prevent the classification of points in this region into either data class, initiating instead a
request for demonstration that would allow the teacher to disambiguate the situation.
Figure 3(c) presents a case in which the datapoints of the two data classes have very
different distributions. While the fixed threshold value is appropriate for the left class, 42%
of the points in the right class are labeled as low confidence.
Classification of complex multi-class data depends upon multiple decision boundaries.
Using the same value for all decision boundaries can exacerbate the problems highlighted
above, as a single value often cannot be found that constrains model classification in some
areas while allowing generalization in others. The resulting effect is that the agent requests
too many demonstrations about things it already knows, and too few demonstrations about
unlearned behavior. To address this problem, we present an algorithm for calculating a
unique threshold value for each decision boundary.
9

Chernova & Veloso

(a)

(b)

(c)

Figure 4: Autonomy threshold calculation: (a) Example dataset, with highlighted overlapping region (b) Learned decision boundary, misclassified points marked with
confidence values (c) Learned threshold values for each data class, a low confidence region containing most of the overlapping points remains in the center.

4.2.2 Multiple Adjustable Thresholds
In this section, we contribute an algorithm for calculating a confidence threshold for each
decision boundary, customized to its unique distribution of points. In our analysis, we
assume that we are able to query the classifier and obtain a confidence score representing
the likelihood that a particular input belongs within a specified decision boundary.
The algorithm begins by dividing the dataset into a training and test set and training the
classifier C. The resulting learned model is used to classify the withheld test set, for which
the correct action labels are known. The algorithm then calculates a unique confidence
threshold for each decision boundary based on the confidence scores of misclassified points.
Given the confidence scores of a set of points mistakenly classified by a decision boundary,
we assume that future classifications with confidences at or below these values are likely to
be misclassifications as well. The threshold is therefore calculated as a function of these
confidence scores.
Specifically, we define a classified point as the tuple (o, a, am , c), where o is the original
observation, a is the demonstrated action label, am is the model-selected action, and c
is the model action confidence. Let Mi = {(o, ai , am , c)|am 6= ai } be the set of all points
mistakenly classified by decision boundary i. The confidence threshold
Pvalue is set to the
Mi

c

average classification confidence of the misclassified points: τconf i = |Mi | . We take the
average to avoid overfitting to noisy data. Other values, based on the maximum or standard
deviation, can be used if a more conservative estimate is required. A threshold value of 0
indicates that no misclassifications occurred and the model is able to generalize freely.
Figure 4 presents an example of the threshold calculation process. Figure 4(a) presents
a small sample dataset, the rectangular box in the figure highlights a region of the state
space in which points from both classes overlap. Figure 4(b) shows the learned decision
boundary (in this case a SVM) separating our two data classes. Six misclassified points are
marked with the (mis-)classification confidences returned by the model. Misclassified points
on each side of the decision boundary will be used to calculate the respective confidence
thresholds. Figure 4(c) shows the confidence threshold lines and values based on the above
10

Interactive Policy Learning through Confidence-Based Autonomy

(a)

(b)

(c)

Figure 5: Multiple adjustable thresholds applied to the failure cases shown in Figure 3.

calculations. The resulting low confidence region in the middle of the image captures most
of the noisy datapoints.
Given this multi-threshold approach, classification of new points is performed by first
selecting the action class with the highest confidence for the query. The comparison on
line 9 of Algorithm 1 is then performed using the threshold of the decision boundary with
the highest confidence for the query. Using this method, the threshold value of the most
likely decision boundary to represent the point is used to decide between demonstration
and autonomy.
Figure 5 shows how the example failure cases discussed in Section 4.2.1 are addressed
by the multi-thresholded approach. Customizing the threshold value to each unique data
distribution enables the algorithm to correctly classify 100% of the points in Figures 5(a)
and (c). Since there are no misclassifications, the model generalizes freely in these examples.
For the dataset in Figure 5(b), in which perfect classification is not possible, the confidence
thresholds are set such that the overlapping region falls into a low confidence area. This
example uses a Gaussian mixture model, in which the elliptical confidence gradient around
the mean results in a large low confidence area even far from the overlapping region. Other
classification methods, such as Support Vector Machines, do not have this drawback.
The presented multi-threshold approach is algorithm independent, and Figure 6 presents
classification results of four different classification methods: Gaussian mixture models, random forests (RF), Support Vector Machine with a quadratic kernel, and SVM with a radial
basis function (RBF) kernel. The table below summarizes the classification performance of
each algorithm and lists the threshold values for each of the models.
Algorithm
GMM
RF
SVM quad.
SVM RBF

Correct-Misclas.-Unclass.
98.6% – 0.4% – 1.0%
99.1% – 0.1% – 0.8%
98.5% – 0.1% – 1.4%
98.9% – 0.1% – 1.0%

Thresholds
(0, 0, 0.012)
(0.14, -0.355)
(335.33, -68.77)
(0.825, -0.268)

Table 1: Classifier comparison.

11

Chernova & Veloso

(a) Gaussian mixture model

(b) Random Forest

(c) SVM (quadratic)

(d) SVM (RBF)

Figure 6: Classification of dataset into high and low confidence regions using different classification methods.

5. Corrective Teacher Demonstration
The presented Confident Execution algorithm enables the agent to identify unfamiliar and
ambiguous states and prevents autonomous execution in these situations. However, states
in which an incorrect action is selected with high confidence for autonomous execution
still occur, typically due to over-generalization of the classifier. In this article we present
the Corrective Demonstration algorithm which, coupled with Confident Execution, enables
the teacher to correct mistakes made by the agent. Algorithm 2 combines Corrective
Demonstration (lines denoted by ⋆) with Confident Execution and presents the complete
Confidence-Based Autonomy algorithm.
The Corrective Demonstration technique comes into play each time the agent executes
an autonomous action. As an action is selected for autonomous execution, the algorithm
records the agent’s state that led to this decision and saves this value within the variable sc
(line 11). During the execution of an autonomously selected action, the algorithm checks
for a teacher demonstration at every timestep (lines 22-23). If a corrective demonstration is
made, a new training datapoint consisting of the recorded demonstration state sc and the
corrective action ac is added to the training set (line 24). The classifier and thresholds are
then retrained using the new information.
12

Interactive Policy Learning through Confidence-Based Autonomy

Algorithm 2 Confidence-Based Autonomy algorithm: Confident Execution and Corrective
Demonstration
1: T ← {}
2: τconf ← inf
3: τdist ← 0
4: while true do
5:
s ← GetSensorData()
6:
if actionComplete then
7:
(ap , c, db) ← C(s)
8:
d = NearestNeighbor(s)
9:
if c > τconf and d < τdist then
10:
ExecuteAction(ap )
11:
sc ← s
⋆
12:
else
13:
RequestDemonstration()
14:
ad ← GetTeacherAction()
15:
if ad 6= N U LL then
16:
T ← T ∪ {(s, ad )}
17:
C ← UpdateClassifier(T )
18:
(τconf , τdist ) ← UpdateThresholds()
19:
ExecuteAction(ad )
20:
else
21:
if autonomousAction then
⋆
22:
ac ← GetTeacherAction()
⋆
23:
if ac 6= N U LL then
⋆
24:
T ← T ∪ {(sc , ac )}
⋆
25:
C ← UpdateClassifier(T )
⋆
26:
(τconf , τdist ) ← UpdateThresholds()
⋆

Using this algorithm, the teacher observes the autonomous execution of the agent and
corrects any incorrect actions. Unlike our previous demonstration technique in which the
agent was given the next action to perform, the correction is performed with relation to
the agent’s previous state at which the mistake was made. For example, when observing
a driving agent approaching too close behind another car, the teacher is able to indicate
that instead of continuing to drive forward, the agent should have been merging into the
passing lane. In this way, in addition to indicating that the wrong action was performed,
Corrective Demonstration also provides the algorithm with the action that should have
been performed in its place. This technique is more effective than negative reinforcement,
or punishment, techniques common in other algorithms, leading the agent to learn quickly
from its mistakes.
13

Chernova & Veloso

Figure 7: Screenshot of the driving simulator. The agent, the black car currently in the
center lane, drives at a fixed speed and must navigate around other cars to avoid
collisions. The road consists of five lanes: three traffic lanes and two shoulder
lanes.

6. Evaluation and Comparison
In this section we present an evaluation and comparison of the complete Confidence-Based
Autonomy algorithm and its components in simulated car driving domain (Abbeel & Ng,
2004), shown in Figure 7.
6.1 Domain Description
In the driving domain, the agent represents a car driving on a busy highway. The
learner’s car travels at a fixed speed of 60 mph, while all other cars move in their lanes
at predetermined speeds between 20 and 40 mph. The road has three normal lanes and
a shoulder lane on both sides; the agent is allowed to drive on the shoulder to pass other
cars, but cannot go further off-road. Since the learner cannot change its speed, it must
navigate between other cars and use the shoulder lanes to avoid collision. The agent is
limited to three actions: remaining in the current lane, or shifting one lane to the left or
right of the current position (A = {forward,left,right}). The teacher demonstrates the task
through a keyboard interface. The simulator has a framerate of 5 fps and is paused during
demonstration requests.
The agent’s state is represented by: s = {l, dl , dc , dr }. State feature l is a discrete value
symbolizing the agent’s current lane number. The remaining three features, denoted by
the letter d, represent the distance to the nearest car in each of the three driving lanes
(left, center and right). The distance features are continuously valued in the [-25,25] range;
note that the nearest car in a lane can be behind the agent. Distance measurements are
corrupted by noise to create a more complex testing environment. The agent’s policy is
relearned each time 10 new demonstrations are acquired.
The driving domain presents a varied and challenging environment; if car distances were
to be discretized by rounding to the nearest integer value, the domain would contain over
600,000 possible states. Due to the complexity of the domain, the agent requires a large
14

Interactive Policy Learning through Confidence-Based Autonomy

number of demonstrations to initialize the classifier, resulting in nearly constant demonstration requests early in the training process. To simplify the task of the teacher, we add
a short 300 datapoint, or approximately 60 second, non-interactive driving demonstration
session to initialize the learning process. While this learning stage is not required, it simplifies the task of the teacher for whom continuous demonstration is preferred over frequent
pauses for demonstration requests.
The performance of each learning algorithm was evaluated each time 100 new demonstrations were acquired. For each evaluation, the agent drove for 1000 timesteps over a road
segment with a fixed and consistent traffic pattern. This road segment was not used for
training, instead each algorithm was trained using a randomly generated car traffic pattern.
Since the algorithm aims to imitate the behavior of the expert, no ‘true’ reward function
exists to evaluate the performance of a given policy. We present two domain-specific evaluation metrics that capture the key characteristics of the driving task. Our first evaluation
metric is the agent’s lane preference, or the proportion of the time the agent spends in each
lane over the course of a trial. This metric provides an estimate of the similarity in driving
styles. Since the demonstrated behavior attempts to navigate the domain without collisions,
our second evaluation metric is the number of collisions caused by the agent. Collisions are
measured as the percentage of the total timesteps that the agent spends in contact with
another car. Always driving straight and colliding with every car in the middle lane results
in a 30% collision rate.
6.2 Experimental Results
We present the performance evaluation and comparison of the following demonstration
selection techniques:
• T G – Teacher-guided, all demonstrations selected by the teacher without any confidence feedback from the algorithm and without the ability to perform retroactive
corrections
• CES – Confident Execution, all demonstrations selected by the agent using a single
fixed confidence threshold
• CEM – Confident Execution, all demonstrations selected by the agent using multiple
adjustable confidence thresholds
• CD – Corrective Demonstration, all demonstrations selected by the teacher and performed as corrections in response to mistakes made by the agent
• CBA – The complete Confidence-Based Autonomy algorithm combining Confident
Execution using multiple adjustable confidence thresholds with Corrective Demonstration
For each demonstration selection method, the underlying policy of the agent was learned
using multiple Gaussian mixture models, one for each action class (Chernova & Veloso,
2007). Videos of the driving task are available at www.cs.cmu.edu/∼soniac.
Figure 8 presents performance results of the five algorithms with respect to the above
defined lane preference and collision metrics. We describe and discuss all elements of the
15

Chernova & Veloso

Figure 8: Evaluation of the agent’s driving performance at 100-demonstration intervals for
each of the five demonstration selection methods. The bar graphs indicate the
percentage of time the agent spent in each road lane. Values under each bar
indicate the percentage of collision timesteps accrued over the evaluation trial.
The teacher performance bar on the right of the figure shows the teacher’s driving
lane preference and collision rate over the evaluation road segment. The goal is
for each algorithm to achieve performance similar to that of the teacher.

16

Interactive Policy Learning through Confidence-Based Autonomy

figure in detail in the following sections. For each evaluation, the figure presents a bar
representing a composite graph showing the percentage of time spent by the agent in each
lane. The value above the bar indicates the number of demonstrations upon which the
evaluated policy is based. The value below the bar indicates the percentage of incurred
collisions during the evaluation.
The bar on the right of the figure shows the performance of the teacher over the evaluation road segment. This evaluation indicates that the teacher prefers to drive in the center
and left lanes, followed in preference by the left shoulder, right shoulder and right lane. The
teacher also successfully avoids all collisions, resulting in a collision rate of 0%. The goal of
the learning algorithm is to achieve a driving lane pattern similar to that of the teacher and
also without collisions. Note that, as described in the previous section, policy learning was
initialized with the same 300-demonstration dataset for all algorithms. This initialization
results in identical performance across all algorithms for this initial learning segment.
6.2.1 T G Demonstration Selection
The top row in Figure 8 summarizes the performance of the teacher-guided demonstration
selection approach. In this approach, the teacher performed training by alternating between
observing the performance of the agent and selecting demonstrations that, in her opinion,
would improve driving performance. The teacher selected all training examples without
receiving feedback about action selection confidence, and without the ability to provide
corrective demonstrations for incorrect actions that were already executed by the agent.
Instead, the teacher was required to anticipate what data would improve the policy. The
training process was terminated once the teacher saw no further improvement in agent
performance.
Figure 8 shows the results of the agent’s performance evaluations at 100-demonstration
intervals throughout the learning process. The similarity in the driving lane preference
of the agent improves slowly over the course of the learning, with significant fluctuations.
For example, after 500 demonstrations, the agent’s preference is to drive on the empty left
shoulder, thereby incurring few collisions. One hundred demonstrations later, the policy
has shifted to prefer the center lane. However, the agent has not yet learned to avoid other
cars, resulting in a 38.8% collision rate. The policy stabilizes after approximately 1100
demonstrations, representing a driving style similar to that of the teacher, with a small
number of collisions. Without confidence feedback from the agent, it is difficult for the
teacher to select an exact termination point for the learning. Training continued until,
after 1300 demonstrations, the learner’s policy showed little improvement. The final policy
resulted in a lane preference very similar to that of the expert, but with a 2.7% collision
rate.
6.2.2 CES Demonstration Selection
The second row in Figure 8 presents the results of the Confident Execution algorithm with
a single autonomy threshold. In this demonstration selection approach, all demonstrations
were selected by the agent and learning terminated once the agent stopped requesting
demonstrations and performed all actions autonomously. The autonomy threshold value
17

Chernova & Veloso

was selected by hand and evaluated in multiple performance trials. Results of the best fixed
threshold are presented.
Compared to the teacher-guided approach, the policy learned using the CES algorithm
stabilizes quickly, achieving performance similar to the teacher’s after only 700 demonstrations. The number of collisions is again low but persistent, even as the agent gains full
confidence and stops requesting demonstrations after 1008 demonstrations. The final lane
preference was again similar to that of the expert, with a collision rate of 3.8%.
6.2.3 CEM Demonstration Selection
The third row in Figure 8 presents the results of the Confident Execution algorithm with
multiple autonomy thresholds, which were calculated using the algorithm presented in Section 4.2.2. Of all the demonstration selection methods, CEM required the fewest number of
demonstrations to learn the task, completing learning after only 504 demonstrations. This
result indicates that the use of multiple adjustable thresholds successfully focuses demonstration selection on informative areas of the state space while greatly reducing the number
of redundant demonstrations. Throughout the learning process, the number of Gaussian
components within the model varied between 9 and 41. This large variation highlights the
importance of automating the threshold calculation process, since hand-selecting individual
thresholds for each component would be impractical. The lane preference of the final policy
was again similar to that of the expert. However, the agent still maintained a small collision
rate of 1.9%.
6.2.4 CD Demonstration Selection
The evaluation of the first three algorithms highlights the difficulty of the driving problem.
Each of the approaches was able to select demonstrations that resulted in a policy that
mimics the overall driving style of the teacher. However, all of the policies resulted in
a small number of collisions, which typically occurred when the agent merged too close
to another vehicle and touched its bumper. Such mistakes are difficult to correct using
the techniques evaluated so far. Even within the teacher guided demonstration selection
method, in which the human teacher has full control of the demonstration training data,
by the time the collision has been observed the incorrect decision had already been made
by the algorithm. Instead, retroactive demonstration is required to correct already made
mistakes, as in the Corrective Demonstration algorithm.
In the fourth row of Figure 8 we present our evaluation of demonstration selection
using only the Corrective Demonstration algorithm. In this approach, all demonstrations
were selected by the teacher as corrections in response to mistakes made by the agent.
Behavior corrected by the teacher included collisions, as well as incorrect lane preference
(e.g. always driving on the shoulder) and rapid oscillations between lanes. To enable the
teacher to accurately perform corrections, the simulation was slowed from 5 to 2 frames
per second. Learning was terminated once the agent required no further corrections. As
shown in Figure 8, the complete training process using Corrective Demonstration took 547
demonstrations, achieving a final policy that correctly imitates the teacher’s driving style
with a 0% collision rate. In the following section, we discuss how this performance compares
to the complete CBA algorithm.
18

Interactive Policy Learning through Confidence-Based Autonomy

6.2.5 CBA Demonstration Selection
The final row in Figure 8 presents the evaluation of the complete Confidence-Based Autonomy algorithm, which combines CEM with CD. Using this approach, learning is complete
once the agent no longer requests demonstrations and is able to perform the driving task
without collisions. Using CBA the agent required a total of 703 demonstrations to learn
the task, successfully learning to navigate the highway without collisions.
We analyze the impact of the two CBA learning components by comparing the number
and distribution of demonstrations acquired by each algorithm during the learning process.
In this section we refer to the learning components of CBA as CBA-CE and CBA-CD
to differentiate from the algorithm evaluations presented in previous sections. Note that
the behavior of the Confident Execution component is dependent upon the method used
to set the autonomy thresholds. In this evaluation we use multiple adjustable thresholds
calculated as the average value of misclassified points.
In Figure 9(a), each datapoint along the x-axis represents the number of demonstrations
requested using CBA-CE (top) and initiated by the teacher using CBA-CD (bottom) during
a 100-timestep interval, or approximately 40 seconds of simulator runtime (excluding pauses
for demonstration requests). Since the first three 100-demonstration timesteps consist entirely of non-interactive demonstration, the values for these timesteps are 100 and, due to
scaling, exceed the bounds of the graph. Figure 9(b) shows how the cumulative number of
demonstrations for each component, and in total, grows with respect to training time. The
complete training process lasts approximately an hour and a half.
Analysis of these graphs shows that most demonstrations occur early in the training
process. Importantly, Confident Execution accounts for 83% of the total number of demon-

(a)

(b)

Figure 9: (a) Timeline showing how the number of demonstrations initiated by the agent
through Confident Execution (top) and initiated by the teacher through Corrective Demonstrations (bottom) changes over the course of the training. (b) The
cumulative number of demonstrations acquired by each component, and in total,
over time.

19

Chernova & Veloso

strations, indicating that the agent guides most of the learning. Most of these demonstration requests occur during the first few minutes of training when the agent encounters
many novel states and the classification confidence remains low. The agent requires few
corrections during this stage because many mistakes are prevented by requesting a demonstration instead of performing a low confidence action. Corrective Demonstration plays its
greatest role towards the end of training process, where it accounts for 73% of the final
100 demonstrations. At this stage in the learning the agent’s action selection confidence is
high enough that it rarely asks for demonstrations. Its policy already closely imitates the
teacher’s driving style but a small number of collisions remain. Corrective Demonstration
enables the teacher to fine-tune the policy and eliminate all collisions. This result highlights
the importance of Corrective Demonstration, whether alone or in conjunction with another
selection technique, for optimizing policy performance.
While CBA achieves similar final performance compared to the CD algorithm evaluated
in the previous section, it requires approximately 150 additional demonstrations to learn this
policy. The additional demonstrations can be attributed to Confident Execution demonstration requests that served to increase the classification confidence but did not change the
outcome of the agent’s action. Viewed another way, these datapoints correspond to states
in which the agent would have performed the correct action even if it had not asked for a
demonstration. From this result it appears that allowing the agent to make mistakes and
correcting them after the fact, as done in the CD evaluation, may be the best demonstration
selection approach with respect to the performance metrics defined above and the overall
number of demonstrations.
However, eliminating the ability to request demonstrations and utilizing only retroactive correction has several drawbacks, namely requiring constant and full attention from the
teacher, and, most importantly, requiring our agent to make many mistakes before it learns
the correct policy. By comparison, the CBA algorithm enables the agent to request demonstrations in low confidence states, thereby avoiding many incorrect actions. Our original
lane preference and collision metrics do not take this difference into account as they focus
only on the final policy performance of the agent.
To evaluate the difference between these algorithms, we additionally examine the number
of collisions each agent incurs over the course of the learning. Using the CD algorithm,
the agent incurs 48% more collisions (278 vs. 188) during training than by using CBA.
Therefore, by allowing the agent to request demonstrations in low-confidence states, the
CBA algorithm requires a slightly greater number of demonstrations while greatly reducing
the number of incorrect actions performed during learning. The reduction in the number
of action errors is significant due to its importance for many learning domains, especially
robotic applications in which such errors may pose dangers to the system.
In summary, our evaluation has shown that the ability to retroactively correct mistakes
is crucial to optimizing the policy and eliminating all collisions. The best performance
was achieved by the Corrective Demonstration and Confidence-Based Autonomy methods,
with CD requiring fewer demonstrations but incurring a greater number of collisions during
training. The choice between CD and CBA can therefore be viewed as a tradeoff between
the number of demonstrations and the frequency of undesired actions during training. In
fact, CD is a special case of CBA in which the autonomy threshold is set to classify all
points with high confidence. Adjusting the selectiveness of the CBA autonomy thresholds
20

Interactive Policy Learning through Confidence-Based Autonomy

could, therefore, provide the user with a sliding control mechanism that effects the agent’s
tendency to perform autonomous actions versus demonstration requests. Importantly, we
note that the overall number of demonstrations required by either approach is less than the
teacher-guided method and only a tiny fraction of the overall state space.

7. Discussion
In this section, we discuss several promising directions for future work, as well as a number
of existing extensions to the presented learning methods.
7.1 Evaluation with Non-Technical Users
The presented demonstration learning algorithm provides a fast and intuitive method for
programming and adapting the behavior of autonomous agents. We believe that its general
representation and classifier-independent approach makes CBA usable for a wide range of
applications. One particular application of interest is the use of demonstration learning to
enable non-technical users to program autonomous agents. We believe that CBA would be
highly suitable for this application as it does not assume that the teacher has any technical
knowledge about policy learning, requiring only that the teacher be an expert at the task.
The results presented in this article were obtained using only a single teacher, one of the
authors. Additional studies could evaluate algorithm usability and performance for a wider
user base, and non-programmers in particular.
7.2 Representation of Action Choices
Demonstration-based learning provides a natural and intuitive interface for transferring human task knowledge to autonomous agents. However, when operating in rich environments,
agents inevitably face situations in which multiple actions are equivalently applicable. For
example, an agent that encounters an obstacle directly in its path has the option of moving
left or right to avoid it. If the surrounding space is empty, both directions are equally valid
for performing the desired task. Human demonstrators faced with a choice of equivalent
actions typically do not perform demonstrations consistently, instead selecting among the
applicable actions arbitrarily each time the choice is encountered. As a result, training
data obtained by the agent lacks consistency, such that identical, or nearly identical, states
are associated with different actions. In the presented CBA algorithm, such inconsistent
demonstrations would result in a persistent region of low confidence, leading the agent to
repeatedly request demonstrations within the inconsistent domain region. We have successfully extended CBA to identify regions of the state space with conflicting demonstrations
and represent the choice between multiple actions explicitly within the agent’s policy (Chernova & Veloso, 2008a).
7.3 Improvement Beyond Teacher Performance
The policy learned by the Confidence-Based Autonomy algorithm is inherently limited by
the quality of the demonstrations provided by the human teacher. Assuming that the
teacher is an expert at the task, our approach aims to imitate the behavior of the teacher.
However, in many domains teacher demonstrations may be suboptimal and limited by
21

Chernova & Veloso

human ability. Several demonstration learning approaches have been developed that enable
an agent to learn from its own experiences in addition to demonstrations, thereby improving
performance beyond the abilities of the teacher (Stolle & Atkeson, 2007; Smart, 2002).
Extending the CBA algorithm to include similar capability remains a promising direction
for future work. Possible approaches include incorporating a high-level feedback (Argall,
Browning, & Veloso, 2007) or reward signal (Thomaz & Breazeal, 2006) from the teacher,
as well as filtering noisy or inaccurate demonstrations.
7.4 Policy Use After Learning
The CBA algorithm considers learning to be complete once the agent is able to perform
the required behavior, repeatedly and correctly, without requesting further demonstrations
and requiring corrections. Once policy learning is complete, the standard procedure for the
vast majority of policy learning algorithms is to turn off the learning process and freeze
the policy. While this approach can also be used with our algorithm, we propose that
the continuing use of the Confident Execution component may have long-term benefits
beyond policy learning. In particular, the algorithm’s ability to identify anomalous states
may enable the agent to detect and notify the user of system errors and unexpected input.
While further studies are needed to evaluate this use of the algorithm, we believe that such
a mechanism would provide a useful safety feature for long-term autonomous operation at
a negligible cost of performing the threshold comparison at each timestep.
7.5 Richer Interaction
The presented demonstration learning approach relies on a limited form of interaction between the agent and teacher. The agent requests demonstrations from the teacher, while
the teacher responds with a single recommended action. While this level of interaction
is typical of traditional active learning approaches, it fails to take full advantage of the
vast task knowledge that the teacher possesses. We believe that extending the algorithm
to include richer interaction abilities could provide a faster and more intuitive training
method. Many promising directions for future research exist in this area. For example,
developing a domain-independent dialog exchange between the agent and teacher that incorporates clarification questions and high level advice could speed up learning and enable
the agent to represent the high level goals of the task. The ability to play back or “rewind”
demonstration sequences would additionally enable both teacher and agent to reexamine
and reevaluate past learning experiences.
7.6 Application to Single-Robot and Multi-Robot Systems
Learning from demonstration techniques have been extensively studied within the robotics
community due to their interactive nature and fast learning times. In other work, we have
shown the CBA algorithm to be highly effective in learning a variety of single-robot tasks
(Chernova & Veloso, 2007, 2008a).
Furthermore, many complex tasks require the collaboration of multiple robots. Up
to now, one of the greatest challenges preventing most demonstration learning algorithms
from generalizing to multi-robot domains has been the problem of limited human attention,
22

Interactive Policy Learning through Confidence-Based Autonomy

the fact that the teacher is not able to pay attention to, and interact with, all robots at
the same time. Based on the CBA algorithm, we have developed the first multi-robot
demonstration learning system that addresses the limited human attention problem by
taking advantage of the fact that the Confident Execution component of CBA prevents the
autonomous execution of actions in low-confidence states (Chernova & Veloso, 2008b). Our
flexMLfD system utilizes individual instances of CBA for each robot, such that each learner
acquires a unique set of demonstrations and learns an individual task policy. By preventing
autonomous execution in low-confidence states, CBA makes each learner robust to periods
of teacher neglect, allowing multiple robots to be taught at the same time.

8. Conclusion
In this article we presented Confidence-Based Autonomy, an interactive algorithm for policy
learning through demonstration. Using this algorithm, an agent incrementally learns an
action policy from demonstrations acquired as it practices the task. The CBA algorithm
contains two methods for obtaining demonstrations. The Confident Execution component
enables the agent to select demonstrations in real time as it interacts with the environment,
using confidence and distance thresholds to target states that are unfamiliar or in which
the current policy action is uncertain. The Corrective Demonstration component allows
the teacher to additionally perform corrective demonstrations when an incorrect action is
selected by the agent. The teacher retroactively provides demonstrations for specific error
cases instead of attempting to anticipate errors ahead of time. Combined, these techniques
provide a fast and intuitive approach for policy learning, incorporating shared decision
making between the learner and the teacher.
Experimentally, we used a complex simulated driving domain to compare five methods
of selecting demonstration training data: manual data selection by the teacher, confidencebased selection using a single fixed threshold, confidence-based selection using multiple
automatically calculated thresholds, corrective demonstration, and confidence-based selection combined with corrective demonstration. Based on our evaluation, we conclude that
all confidence-based methods were able to select more informative demonstrations than the
human teacher. Of the single and multiple threshold approaches, the multiple adjustable
threshold technique required significantly fewer demonstrations by focusing onto regions of
uncertainty and reducing the number of redundant datapoints. The best final policy performance, however, was achieved by the Corrective Demonstration and complete ConfidenceBased Autonomy algorithms, both of which achieved a lane preference similar to that of the
teacher without any collisions. Together, these demonstration selection algorithms represent
the tradeoff between the number of demonstrations and the frequency of undesired actions
during training. While Corrective Demonstration required slightly fewer demonstrations to
learn the final policy, compared to CBA it resulted in a significant increase in the number
of errors made by the agent over the course of the learning process. The CBA algorithm,
therefore, provides the best demonstration selection method for domains in which incorrect
actions are not desirable during the training process.
23

Chernova & Veloso

Acknowledgments
This research was partially sponsored by the Department of the Interior, National Business
Center under contract no. NBCHD030010 and SRI International under subcontract no.
03-000211, and by BBNT Solutions under subcontract no. 950008572, via prime Air Force
contract no. SA-8650-06-C-7606. The views and conclusions contained in this document
are those of the authors and should not be interpreted as representing the official policies,
either expressed or implied, of any sponsoring institution, the U.S. government or any other
entity. Additional thanks to Paul Rybski for making his simulation package available.

References
Abbeel, P., & Ng, A. (2004). Apprenticeship learning via inverse reinforcement learning.
In Proceedings of the International Conference on Machine Learning, New York, NY,
USA. ACM Press.
Argall, B., Chernova, S., Browning, B., & Veloso, M. (2009). A survey of robot learning
from demonstration. Robotics and Autonomous Systems, to appear.
Argall, B., Browning, B., & Veloso, M. (2007). Learning from demonstration with the critique of a human teacher. In Second Annual Conference on Human-Robot Interactions
(HRI ’07), Arlington, Virginia.
Atkeson, C. G., & Schaal, S. (1997). Robot learning from demonstration. In Proceedings
of the International Conference on Machine Learning, pp. 12–20, San Francisco, CA,
USA. Morgan Kaufmann Publishers Inc.
Bentivegna, D. C., Ude, A., Atkeson, C. G., & Cheng, G. (2004). Learning to act from
observation and practice. International Journal of Humanoid Robotics, 1 (4).
Blum, A. L., & Langley, P. (1997). Selection of relevant features and examples in machine
learning. Artificial Intelligence, 97 (1-2), 245–271.
Browning, B., Xu, L., & Veloso, M. (2004). Skill acquisition and use for a dynamicallybalancing soccer robot. In Proceedings of Nineteenth National Conference on Artificial
Intelligence, pp. 599–604.
Chernova, S., & Veloso, M. (2007). Confidence-based policy learning from demonstration
using gaussian mixture models. In Proceedings of the International Conference on
Autonomous Agents and Multiagent Systems, pp. 1–8.
Chernova, S., & Veloso, M. (2008a). Learning equivalent action choices from demonstration.
In In Proceedings of the International Conference on Intelligent Robots and Systems,
pp. 1216–1221.
Chernova, S., & Veloso, M. (2008b). Teaching collaborative multi-robot tasks through
demonstration. In Proceedings of the IEEE-RAS International Conference on Humanoid Robots.
Clouse, J. A. (1996). On integrating apprentice learning and reinforcement learning. Ph.D.
thesis, University of Massachisetts, Department of Computer Science.
Cohn, D., Atlas, L., & Ladner, R. (1994). Improving generalization with active learning.
Machine Learning, 15 (2), 201–221.
24

Interactive Policy Learning through Confidence-Based Autonomy

Grollman, D., & Jenkins, O. (2007). Dogged learning for robots. In IEEE International
Conference on Robotics and Automation, pp. 2483–2488.
Inamura, T., Inaba, M., & Inoue, H. (1999). Acquisition of probabilistic behavior decision model based on the interactive teaching method. In Proceedings of the Ninth
International Conference on Advanced Robotics, pp. 523–528.
Lockerd, A., & Breazeal, C. (2004). Tutelage and socially guided robot learning. In Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems,
pp. 3475–3480.
Nicolescu, M. N. (2003). A framework for learning from demonstration, generalization and
practice in human-robot domains. Ph.D. thesis, University of Southern California.
Papudesi, V. (2002). Integrating advice with reinforcement learning. Master’s thesis, University of Texas at Arlington.
Price, B., & Boutilier, C. (2003). Accelerating reinforcement learning through implicit
imitation.. Journal of Artificial Intelligence Research, 19, 569–629.
Saunders, J., Nehaniv, C. L., & Dautenhahn, K. (2006). Teaching robots by moulding behavior and scaffolding the environment. In Proceeding of the 1st ACM SIGCHI/SIGART
conference on Human-robot interaction, pp. 118–125, New York, NY, USA. ACM
Press.
Schaal, S. (1997). Learning from demonstration. In Advances in Neural Information Processing Systems, pp. 1040–1046. MIT press.
Smart, W. D. (2002). Making Reinforcement Learning Work on Real Robots. Ph.D. thesis,
Department of Computer Science, Brown University, Providence, RI.
Stolle, M., & Atkeson, C. G. (2007). Knowledge transfer using local features. In Proceedings of IEEE International Symposium on Approximate Dynamic Programming and
Reinforcement Learning, pp. 26–31.
Sutton, R., & Barto, A. (1998). Reinforcement Learning: An Introduction. MIT Press,
Cambridge, MA.
Takahashi, Y., Hikita, K., & Asada, M. (2004). A hierarchical multi-module learning system
based on self-interpretation of instructions by coach. In Proceedings of RoboCup 2003:
Robot Soccer World Cup VII, pp. 576– 583.
Thomaz, A. L., & Breazeal, C. (2006). Reinforcement learning with human teachers: Evidence of feedback and guidance with implications for learning performance. In Proceedings of the Twenty-First Conference on Artificial Intelligence, pp. 1000–1005.

25

Journal of Artificial Intelligence Research 34 (2009) 707-755

Submitted 08/08; published 04/09

Efficient Informative Sensing using Multiple Robots
Amarjeet Singh
Andreas Krause
Carlos Guestrin
William J. Kaiser

AMARJEET @ EE . UCLA . EDU
KRAUSEA @ CALTECH . EDU
GUESTRIN @ CS . CMU . EDU
KAISER @ EE . UCLA . EDU

Abstract
The need for efficient monitoring of spatio-temporal dynamics in large environmental applications, such as the water quality monitoring in rivers and lakes, motivates the use of robotic sensors
in order to achieve sufficient spatial coverage. Typically, these robots have bounded resources, such
as limited battery or limited amounts of time to obtain measurements. Thus, careful coordination of
their paths is required in order to maximize the amount of information collected, while respecting
the resource constraints. In this paper, we present an efficient approach for near-optimally solving the NP-hard optimization problem of planning such informative paths. In particular, we first
develop eSIP (efficient Single-robot Informative Path planning), an approximation algorithm for
optimizing the path of a single robot. Hereby, we use a Gaussian Process to model the underlying phenomenon, and use the mutual information between the visited locations and remainder of
the space to quantify the amount of information collected. We prove that the mutual information
collected using paths obtained by using eSIP is close to the information obtained by an optimal
solution. We then provide a general technique, sequential allocation, which can be used to extend
any single robot planning algorithm, such as eSIP, for the multi-robot problem. This procedure
approximately generalizes any guarantees for the single-robot problem to the multi-robot case. We
extensively evaluate the effectiveness of our approach on several experiments performed in-field
for two important environmental sensing applications, lake and river monitoring, and simulation
experiments performed using several real world sensor network data sets.

1. Introduction
Global climate change and corresponding impetus on sustainable practices for environment-related
activities has brought forth the challenging task of observing natural phenomena exhibiting dynamics in both space and time. Observing and characterizing these dynamics with high fidelity will
be critical for answering several questions related to policy issues for monitoring and control and
understanding biological effects on activity of microbes and other organisms living in (or dependent
on) these environments. Monitoring algal bloom growth in lakes and salt concentration in rivers, as
illustrated in Fig. 1, are specific examples of related phenomena of interest to biologists and other
environment scientists (MacIntyre, 1993; Ishikawa & Tanaka, 1993; MacIntyre, Romero, & Kling,
2002).
Monitoring environmental phenomena, such as algal bloom growth in a lake, requires measuring physical processes, such as nutrient concentration, wind effects and solar radiation, among
others, across the entire spatial domain. One option to acquire data about such processes would be
to statically deploy a set of sensing buoys (Reynolds-Fleming, Fleming, & Luettich, 2004). Due to
the large spatial extent of the observed phenomena, this approach would require a large number of
sensors in order to obtain high fidelity data. The spatio-temporal dynamics in these environments

c
2009
AI Access Foundation. All rights reserved.

S INGH , K RAUSE , G UESTRIN & K AISER

(a) Confluence of San Joaquin and Merced River

(b) Lake Fulmor, San Jacinto mountain reserve

Figure 1: Deployment sites used for performing path planning in-field.
motivate the use of actuated sensors – robots carrying sensors together with an efficient approach
for planning the paths of these actuated sensors. These actuated sensors have been used in the past
(Dhariwal et al., 2006) for measuring the phenomena at various locations and hence providing the
biologists with critical information about the state of the lake.
Typically however, such robots have strict resource constraints, such as storage battery energy,
that limits the distance they can travel or the number of measurements they can acquire before the
observed phenomena varies significantly. These constraints necessitate careful motion planning for
the robots – coordinating their paths in order to maximize the amount of collected information,
while satisfying the given resource constraints. In this paper, we tackle this important problem of
seeking informative paths for a collection of robots, subject to constraints on the cost incurred by
each robot, e.g. due to limited battery capacity.
In order to optimize the paths of these robots, we first need to quantify the informativeness of
any particular chosen path. In this work, we adopt an approach from spatial statistics and employ
probabilistic models of the spatial phenomena. Using these models, informativeness can be viewed
in terms of the uncertainty about our prediction of the phenomena at unobserved locations, given
the observations made by the mobile robots at a subset of locations (the selected path). In particular, we use a rich class of probabilistic models called Gaussian Processes (GPs) (Rasmussen &
Williams, 2006) that has been shown to accurately model many spatial phenomena (Cressie, 1991),
and apply the mutual information (MI) criterion (Caselton & Zidek, 1984) to quantify the reduction
in uncertainty achieved through selected robot paths.
Unfortunately, the problem of finding an optimal collection of paths, maximizing the mutual
information criterion, is an NP-hard search problem, which is typically intractable even for small
spatial phenomena. In this paper, we will develop an approximation algorithm which efficiently
finds a provably near-optimal solution to this optimization problem. The key insight which will
allow us to obtain such an algorithm is that the mutual information (and several other notions of
informativeness (as discussed in Krause and Guestrin, 2007) satisfies submodularity, an intuitive
diminishing returns property - making a new observation helps more if we have made only a few
observations so far, and less if we have already made many observations (Krause et al., 2008).
The problem of optimizing the path of a single robot to maximize a submodular function over
the visited locations was studied by Chekuri and Pal (2005), who developed an algorithm, recursivegreedy, with strong theoretical approximation guarantees. Unfortunately, the running time of their
708

E FFICIENT I NFORMATIVE S ENSING USING M ULTIPLE ROBOTS

approach is quasi-polynomial: it scales as M log M , for M possible sensing locations. This property
makes the algorithm impractical for most environmental sensing applications, with typical numbers
(M ) of observation locations reaching to several hundreds and more. In this paper, we present two
techniques – spatial decomposition and branch and bound search – for overcoming these limitations of the recursive-greedy approach of Chekuri et al., making it practical for real world sensing
problems. We call this efficient approach for single robot path planning eSIP (efficient Single-robot
Informative Path planning).
We then provide a general approach, sequential-allocation, which can be used to extend any
single robot algorithm, such as eSIP, to the multi-robot setting. We furthermore prove that this
generalization only leads to minimal reduction (independent of the number of mobile robots) of the
approximation guarantee provided by the single robot algorithm. We combine eSIP with sequentialallocation to develop the first efficient path planning algorithm (eMIP) that coordinates multiple
robots, each having a resource constraint, in order to obtain highly informative paths, i.e. paths that
maximize any given submodular function, such as mutual information. By exploiting submodularity, we prove strong theoretical approximation guarantees for our algorithm.
We extensively evaluate the effectiveness of our approach on several experiments performed
in-field for two important environmental sensing applications, lake and river monitoring. The river
campaign was executed at the confluence of two rivers, Merced river and San Joaquin river, in California from August 7-11, 2007. Fig. 1a displays an aerial view of the San Joaquin deployment site.
The lake campaign was executed at a lake located at the University of California, Merced campus
from August 10-11, 2007. Fig. 1b displays an aerial view of lake Fulmor. In both campaigns, the
Networked Info Mechanical System (NIMS) (Jordan et al., 2007), a cable based robotic system, was
used to perform path planning while observing a two dimensional vertical plane (cross-section). In
addition to analyzing data from these deployments, we provide extensive experimental analysis of
our algorithm on several real world sensor network data sets, including the data collected using a
robotic boat at lake Fulmor (Dhariwal et al., 2006).
This manuscript is organized as follows. We formally introduce the Multi-robot Informative
Path Planning (MIPP) problem in Section 2. In Section 3, we discuss the sequential-allocation
approach for extending any single robot path planning algorithm to the multi-robot setting while
preserving approximation guarantees. We then review the recursive-greedy algorithm proposed by
Chekuri et al. (Section 5), an example of such a single-robot algorithm. Subsequently, we present
our spatial decomposition (Section 6) and branch and bound techniques (Section 7) which drastically improve the running time of recursive-greedy and make it practical for real world sensing
applications. In Section 8, we evaluate our approach through in-field experiments as well as in simulations on real world sensing datasets. In Section 9, we review related work, and we present our
conclusions in Section 10. The proofs for all our results are presented in the Appendix.

2. The Multi-robot Informative Path Planning Problem
We now formally define the Multi-robot Informative Path Planning (MIPP) problem. We assume
that the spatial domain of the phenomenon is discretized into finitely many sensing locations V. For
each subset A ⊆ V, let I(A) denote the sensing quality, i.e. the informativeness, of observing the
phenomenon at locations A. Details on appropriate choices for the sensing quality I are given below.
We also associate with each location v ∈ V, a sensing cost C(v) > 0, quantifying the expenses of
obtaining a measurement at location v. When traveling between two locations, u and v, a robot in-

709

S INGH , K RAUSE , G UESTRIN & K AISER

curs a traveling cost C(u, v) > 0. A robot traverses a path in this space: an s–t-path P is a sequence
of l locations starting at node s, and finishing at t. The cost C(P) of path P = (s = vP
1 , v 2 , . . . , vl =
l−1
t) is the sum of sensing costs and traveling costs along the path, i.e. C(P) =
i=2 C(vi ) +
Pl
C(v
,
v
).
In
the
case
l
=
2,
cost
of
the
path
P
will
only
involve
traveling
cost
between the
i−1 i
i=2
starting and finishing locations C(s, t). We will use the notation P to both refer to the sequence of
nodes in the path, and to the subset of sensing locations P ⊆ V (ignoring their sequence). For a collection of k paths P = {P1 , . . . , Pk }, one for each robot, I(P) = I(P1 ∪ · · · ∪ Pk ) denotes the sensing quality of the paths, which quantifies the amount of information collected by the k paths. The
goal of the MIPP problem is to find a collection P of k paths, with specified starting and finishing
location si and ti (not necessarily different), such that each path has bounded cost C(Pi ) ≤ B for
some specified budget B, and that the paths are the most informative, i.e. I(P) is as large as possible.
Formally, the problem can be defined as:
max I(∪ki=1 Pi ); subject to C(Pi ) ≤ B, ∀ i ∈ {1, . . . , k}.

Pi ⊆V

(1)

In our lake monitoring example with the goal of performing surface monitoring using boats,
we first discretized the two-dimensional surface of the lake into finitely many sensing locations (as
depicted in Fig. 1b). For the single robot scenario, we then seek to find the most informative path
P1 (in terms of predicting the algal bloom content) starting from location s and finishing in location
t. The experiment cost C(vi ) corresponds to the energy required for making chlorophyll and related
measurements (indicators of amount of algal bloom). The traveling cost C(vi−1 , vi ) corresponds to
the energy consumption when traveling from location vi−1 to vi . The budget B quantifies the total
energy stored in the boat’s battery.
2.1 Quantifying Informativeness:
How can we quantify the sensing quality I? To model spatial phenomena, a common approach in
spatial statistics is to use a rich class of probabilistic models called Gaussian Processes (GPs, c.f.,
Rasmussen and Williams, 2006). Such models associate a random variable Xv with each location
v ∈ V. The joint distribution P (XV ) can then be used to quantify uncertainty in the prediction
P (XV\A | XA = xA ) of phenomena at unobserved locations XV\A , after making observations
XA = xA at a small subset A of locations. To quantify this uncertainty we use, for example,
the mutual information (MI) criterion (as discussed by Caselton and Zidek, 1984). For a set of
locations, P, the MI criterion is defined as:
MI(A) ≡ H(XV\A ) − H(XV\A | XA )

(2)

where H(XV\A ) is the entropy of the unobserved locations V \ A, and H(XV\A | XA ) is the
conditional entropy of locations V \ A after sensing at locations A. Hence mutual information
measures the reduction in uncertainty at the unobserved locations. Therefore, in our lake monitoring
example, we would like to select the locations that most reduce the uncertainty in the algal bloom
content prediction for the lake environment. Conveniently, in a GP, the mutual information criterion
can be computed efficiently and analytically (Caselton & Zidek, 1984). The effectiveness of mutual
information to select informative sensing locations was studied by Krause et al. (2008). Several
alternative information criteria such as entropy (Ko et al., 1995), information disk model (Bai et al.,
2006) and alphabetical optimality criterion such as A-, D- and E-optimal have also been used to
associate sensing quality with observation locations in related problem domain.
710

E FFICIENT I NFORMATIVE S ENSING USING M ULTIPLE ROBOTS

2.2 Submodularity:
Even if we do not consider the constraints on the length of the paths of the robots, the problem
of selecting locations that maximize mutual information is NP-hard (Krause et al., 2008). Hence,
in general, we most likely cannot expect to be able to efficiently find the optimal set of locations.
Instead, our goal will be to efficiently find near-optimal solutions, for which the sensing quality
(e.g. mutual information), is provably close to the optimal sensing quality.
The key observation, which will allow us to obtain such strong approximation guarantees, is
that mutual information satisfies the following diminishing returns property (Krause et al., 2008):
The more locations we have already sensed, the less information we will gain by sensing a new
location. This intuition is formalized by the concept of submodularity: A function f is submodular
(Nemhauser et al., 1978) if:
∀A ⊆ B ⊆ V and s ∈ V \ B; f (A ∪ s) − f (A) ≥ f (B ∪ s) − f (B).

(3)

Another intuitive property is that sensing quality is monotonic1 , which means that I(A) ≤ I(B) for
all A ⊆ B ⊆ V. Hence, as we select more and more sensing locations, we will collect more and
more information. Lastly, mutual information is normalized, i.e. I(∅) = 0.
We thus define our MIPP problem as the problem of optimizing paths of length at most B for
k robots, such that the selected sensing locations maximize a normalized, monotonic submodular function I(·). This definition of the MIPP problem allows our approach to be applied to any
monotonic submodular objective function, not just mutual information. This generalization is very
useful, as several other notions of informativeness can be shown to satisfy submodularity (Krause
& Guestrin, 2007).
2.3 Online vs Offline Path Planning:
Many robotic path planning applications, such as search and rescue, involve uncertain environments
with complex dynamics that can only be partially observed. Informative path planning – selecting
the best locations to observe subject to given sensing constraints, in such uncertain environments
necessitates a trade off between exploration (gathering information about the environment) and
exploitation (using the current belief about the state of the environment most effectively). We distinguish two different classes of algorithms: nonadaptive (offline) algorithms, that plan and commit
to the paths before any observations are made, and adaptive (online) algorithms, that update and
replan as new information is collected. Both the online and offline settings are NP-hard optimization problems. In this paper, we only discuss the approximation algorithms for the offline setting
that exploit the known belief about the environment for efficient path planning. We plan to work towards extending our approach for an exploration-exploitation trade-off to incorporate online model
adaptation in the future.

3. Approximation Algorithm for MIPP
The problem of optimizing the path of a single robot (i.e. k = 1) to maximize a submodular function of the visited locations, constrained by an upper bound (B) on the path cost, was first studied
by Chekuri and Pal (2005). We will review their recursive-greedy algorithm in detail in Section 5.
1. This monotonicity holds only approximately for mutual information (Krause et al., 2008), which however is sufficient
for all purposes of this paper.

711

S INGH , K RAUSE , G UESTRIN & K AISER

1

Algorithm:sequential-allocation

Input: B, k, starting / finishing locations s1 , . . . , sk , t1 , . . . , tk , V
Output: A set of informative paths P1 , . . . , Pn
2 begin
3
A0 ← ∅;
4
for 1 ≤ i ≤ k do
// Performing path planning for the ith robot
5
Pi ← SP P (si , ti , B, Ai−1 , V);
// Committing to the previously selected locations
6
Ai ← Ai−1 ∪ Pi ;
7
return P1 , . . . , Pk ;
8 end
Algorithm 1: Sequential allocation algorithm for multi robot path planning using any single robot path planning algorithm SPP. Output set of paths P1 , . . . , Pk provides an approximation guarantee of 1 + η where η is the
approximation guarantee of single robot path planning algorithm SP P .

In our lake monitoring problem, we seek to plan multiple paths, one for each robot. One possibility is to apply the single-path algorithm to the product graph, i.e. plan a path over tuples of
locations simultaneously representing the locations of all robots. However, such straightforward
application of the single-robot planning algorithm would lead to an increase in running time which
is exponential in the number of robots, and therefore intractable in practice. We are not aware
of any sub-exponential approximation algorithm for this challenging multiple-robot path planning
problem. In this paper, we present a simple algorithm for the multi-robot scenario that can exploit
any approximation algorithm for the single robot case, such as the recursive-greedy algorithm, as
discussed by Chekuri and Pal (2005), and (almost) preserve the approximation guarantee, while
avoiding the exponential increase in running time.
Our algorithm, sequential-allocation, successively applies the single robot path planning algorithm k times to get the paths for k robots. Hereby, when planning the jth path, the approach takes
into account the locations already selected by the previous j − 1 paths. Committing to the (approximately) best possible path at each stage before moving on to the next stage makes our approach
“greedy” in terms of paths.
The pseudocode of the algorithm is presented in Algorithm 1 and Fig. 2 illustrates the approach
for three robots. The algorithm takes as input the budget constraint B, number of available robots
k, starting and finishing location for each available robot s1 , . . . , sk , t1 , . . . , tk and the complete set
of discrete observation locations V to select from. Let us assume that we have a single robot path
planning algorithm, SP P , that takes as input a starting location si , a finishing location ti , budget
constraint B, a set of locations already selected for observation and a set of possible observation
locations that can be visited. In Fig. 2, all the three robots have same starting and finishing location.
While planning the path for the first robot (i = 1), the input set of already selected observation
locations is empty. At each subsequent stage, we commit to the locations selected in all the previous
stages and pass the already observed locations as input to our next call to SP P . Let Ai−1 be the locations already visited by paths P1 , . . . , Pi−1 , and A0 = ∅. Then the residual information, IAi−1 for
a path P over unvisited locations is defined as IAi−1 (P) = I(Ai−1 ∪P)−I(Ai−1 ). It can be verified
that if I is a normalized, monotonic and submodular function, then so is the residual information
712

E FFICIENT I NFORMATIVE S ENSING USING M ULTIPLE ROBOTS

Figure 2: Illustration of sequential allocation algorithm for three robots, each with the same starting and finishing
location.

IAi−1 . Thus, at stage i we use SP P to find the most informative path with respect to the modified
residual sensing quality function. In Fig. 2, when planning P2 , locations selected for P1 are considered and the sensing quality function used is IP1 . Similarly, while evaluating the path P3 , locations
selected for P1 and P2 are taken into account and the sensing quality function used is IP1 ∪P2 .
Perhaps surprisingly, this straight-forward “greedy” sequential allocation approach is guaranteed to perform almost as well as the black box algorithm used for path planning. More formally,
assume we have an η -approximate algorithm for the single robot problem, i.e. an algorithm which,
starting with budget B and a monotonic submodular function f , is guaranteed to find a path recovering at least a fraction of 1/η of the optimal information achievable with the same budget. In
this case, the following theorem proves that the sequential allocation procedure has approximation
guarantee close to η as well:
Theorem 1. Let η be the approximation guarantee for the single path instance of the informative
path planning problem. Then our sequential-allocation algorithm achieves an approximation guarantee of (1 + η) for the MIPP problem. In the special case, where all robots have the same starting
(si = sj , ∀i, j) and finishing locations (ti = tj , ∀i, j), the approximation guarantee improves to
1/(1 − exp (−1/η)) ≤ 1 + η.
The work by Blum et al. (2003) proved Theorem 1 for the special case of additive (modular)
sensing quality functions. In this paper, we extend their result to general submodular functions.
As an example of an η-approximate algorithm for the single robot problem, in the next section,
we review the recursive-greedy algorithm as proposed by Chekuri and Pal (2005). This algorithm
has an approximation guarantee η of O(log2 |P ∗ |), where |P ∗ | is the number of locations visited
by an optimal solution P ∗ . Hence, for this algorithm, the performance guarantee obtained for the
MIPP problem through sequential allocation is O(log2 |P ∗ |) as well2 .
2. In order to apply sequential allocation to the recursive-greedy algorithm, we can, when planning the ith path, simply
pass the set of nodes visited by the previous i − 1 paths as the input parameter R, as is illustrated in Algorithm 2.

713

S INGH , K RAUSE , G UESTRIN & K AISER

(a)

(b)

(c)

(d)

Figure 3: Illustration of performance of simple greedy approaches compared to an optimal approach.

4. A Note on Greedy Path Planning
The work by Krause et al. (2008) considered the sensor placement problem, where a subset A ⊆ V
of k locations is selected in order to maximize the mutual information, without considering path
costs. By exploiting the submodularity property of MI, they proved that if the discretization V is
fine enough and the GP satisfies mild regularity conditions, greedily selecting locations based on
this criterion is near-optimal. More specifically, the greedy algorithm (which we call GreedySubset
in the following), after selecting the first i locations Ai , picks the location with maximum residual
information i.e. vi+1 = argmaxv IAi ({v}) and sets Ai+1 = Ai ∪ {vi+1 }. GreedySubset hence
iteratively adds locations which increase mutual information the most. Using a result proposed by
Nemhauser et al. (1978) on the performance of the greedy algorithm for submodular functions,
the work by Krause et al. (2008) showed that GreedySubset selects sets which achieve mutual
information of at least (1 − 1/e) OPT −ε, where OPT is the optimal mutual information among
all sets of the same size, and ε is a small error incurred due to the discretization.
The strong performance of the greedy algorithm in the unconstrained (no traveling costs between locations) case motivates the question of whether a simple greedy approach could perform
well in the more complex path planning setting considered in this paper. While it is difficult to
give a general impossibility statement for such a question, several natural extensions of the greedy
algorithm can be shown to perform arbitrarily badly.
For example, consider a setting where we define the cost C(A) of a set of nodes as the cost
of the cheapest path connecting the nodes A. Assuming locations Ai have already been picked,
a natural extension of the greedy algorithm will be to add a location v which most improves the
benefit-cost ratio
IA (v)
v ∗ = argmax i
,
v∈V\A CAi (v)
714

E FFICIENT I NFORMATIVE S ENSING USING M ULTIPLE ROBOTS

where CAi (v) = C(Ai ∪ {v}) − C(Ai ) is the increase in cost after adding v to the already selected
locations Ai .
Fig. 3 shows a small example illustrating that this intuitive greedy procedure can perform arbitrarily poorly compared to an optimal approach. The example is illustrated in Fig. 3a, with s as
both the starting and the finishing location and 2B as the total available budget. The reward associated with each observation location is displayed in parenthesis with the corresponding locations.
For the ease of illustration, we assume that the reward associated with each observation location is
some modular function (instead of a submodular function). Traveling cost is associated with the
corresponding edges in the example. Starting at location s, possible options for the first observation
location are to select either of o1 , g1 or t. Observation location o1 will lead to a cluster of n (=
B/) locations each separated by a traveling cost  and with an associated reward of 1 (except o1
that has an associated reward of ). o1 is separated from g1 by a traveling cost of B/2 while the
rest of the locations in the cluster are assumed to be unreachable from any other location outside the
cluster. Observation location g1 will lead to a series of m (= B/) locations, each separated from
the previous one by  traveling cost and with an associated reward of 2.
As illustrated in Fig. 3b, an optimal approach would select o1 as the first location, paying a
traveling cost of B/2 and earning a very small reward . Once the robot observes o1 , it can then
observe the rest of (B/ − 1) locations in the cluster, each providing a reward of 1 and return back to
s while spending a total of 2B as the traveling cost. Thus, the total reward collected by an optimal
approach, for this example, will be 1(B/ − 1) + .
As illustrated in Fig. 3c, a “greedy” approach based on the reward-cost ratio will select g1 as the
first observation location (with the highest reward to cost ratio of 2). Since o1 is at a distance B/2
away from g1 and only provides a reward of , this approach will continue along the series, observing all the locations till gm and returning back to s. Total reward collected by such an approach will
be 2B. On the other hand, a simple “greedy” approach based on reward (as illustrated in Fig. 3d)
will simply select t as the first observation location and return back to s, collecting a total reward
of 1. Since the ratio B/ can be arbitrarily large as  → 0, the reward collected by simple intuitive
greedy approaches (2B or 1) can be arbitrarily poor when compared to the reward collected by an
optimal approach (1(B/ − 1) + ).
Although, the reward function considered in the example was assumed to be a modular function, the submodular optimal reward can also be arbitrarily large, compared to submodular reward
collected by simple greedy approaches (the difference between the submodular and modular reward
will depend on the correlation of the selected observation locations). This insight necessitates the
development of more complex algorithms for path planning as considered in this paper.

5. The Recursive-greedy Algorithm
We will now review the recursive-greedy algorithm as proposed by Chekuri and Pal, since it forms
the basis for our efficient single robot path planning approach. The basic strategy of the algorithm
is a divide-and-conquer approach. Any path from the starting location (s) to finishing location (t)
has a middle location (vm ) such that there are same number of locations (or different by at most 1)
on either side of vm in the s − t path. Thus, the problem of finding a s − t path can be divided into
two smaller subproblems of finding smaller subpaths (s − vm and vm − t) and then concatenating
these small subpaths. While having the same number of locations, the subpaths on either side of the
middle node can have different costs, i.e. the budget for the total path has to be split into two smaller

715

S INGH , K RAUSE , G UESTRIN & K AISER

1

Algorithm:recursive-greedy (RG)

Input: s,t,B,R,iter
Output: An informative path P
2 begin
3
if c(s, t) > B then
4
return Infeasible;
5
P ← s, t;
6
Base case: iter=0 return P;
7
m ← fR (P);
// Trying each location as middle node
8
foreach vm ∈ V do
// Trying all possible budget splits
9
for 1 ≤ B1 ≤ B do
// Planning subpath on one side of the middle node
10
P1 ← RG(s, vm , B1 , R, iter − 1);
// Planning subpath on other side of the middle node,
committing to nodes selected in first subpath
11
P2 ← RG(vm , t, B − B1 , R ∪ P1 , iter − 1);
12
if fR (P1 ∪ P2 ) > m then
13
P ← P1 ∪ P2 ;
14
m ← fR (P);
15
return P;
16 end
Algorithm 2: Recursive greedy algorithm for single robot instance of MIPP as proposed by Chekuri and Pal
(2005). Output path P provides an approximation guarantee of IX (P) ≥ IX (P ∗ )/ d1 + log ke, where I represent
the submodular reward function, P ∗ represent an optimal path and k represent the number of nodes in the optimal
path.

budgets (not necessarily equal), one for each subpath. Searching for the best middle location and
trying all possible budget splits on either side of the middle location, while optimizing the complete
s − t path, would result in an exhaustive search for the optimal solution and therefore will be prohibitively expensive. Instead of performing this exhaustive search, the recursive-greedy algorithm
follows a simple greedy strategy, wherein for each of the possible budget splits and each possible
middle nodes considered, one can first plan the optimal subpath on one side of the middle location,
then commit to the planned subpath and optimize for the subpath on the other side. Such a path,
consisting of independently optimized subpath s−vm and a subpath vm −t optimized subject to observation locations already selected in s − vm , may result in a suboptimal s − t path. Nonetheless,
Chekuri and Pal proved that such a path has an approximation guarantee of O(log2 |P ∗ |), where
|P ∗ | is the number of locations visited by an optimal solution P ∗ .
In order to implement such a greedy approach, the recursive calls planning the second subpath will – similarly as done in sequential allocation – optimize a residual reward function which
measures the incremental gain taking into account the information already obtained by the locations selected in the first subpath. More formally, let the set P1 refer to the locations selected in
the first subpath, and consider the residual submodular function fP1 over a set of locations A as
716

E FFICIENT I NFORMATIVE S ENSING USING M ULTIPLE ROBOTS

fP1 (A) = f (A ∪ P1 ) − f (P1 ). If P2 is the set of locations in the second subpath, then it holds that
f (P1 ) + fP1 (P2 ) = f (P1 ∪ P2 ). Hence, if the first recursive call (with submodular function f )
returns path P1 , and the second recursive call (with submodular function fP1 ) returns path P2 , then
the sum of the scores of the subproblems exactly equals the score of the concatenated path.
Let us now formalize the intuitive description of the recursive-greedy algorithm. The pseudocode of the algorithm is presented in Algorithm 2. The inputs to the algorithm are a starting
location s, a finishing location t, an upper bound on the path cost B, a parameter R that defines the
residual for the submodular function such that the function that needs to be maximized is defined as
fR (P) = f (P ∪ R) − f (R), and a parameter i that represents the recursion depth. The maximum
number of locations that can be selected at each stage is calculated using the recursion depth as 2i .
In the base case (recursion depth i = 0), the algorithm simply returns the path P = (s, t) (if the
cost c(s, t) ≤ B).
In the recursive case, the algorithm searches for a s − t path with maximum reward by iterating
over all possible locations (that can be reached with given budget constraint) as middle locations
(Line 8), i.e. locations that could possibly split the required path into two subpaths with equal number of locations on either side. For each such middle location, the algorithm explores all possible
splits of available budget (Line 9) across the two subpaths on either side of the middle location.
Reducing the recursion depth by 1, for each subpath, ensures that the same number of locations are
selected on either side of the middle location. However, before exploring the second subpath, the
algorithm commits to the locations selected in the first subpath by passing them as input through
the “residual” parameter (Line 11). The two subpaths found in such a way are then concatenated to
provide a complete s − t path. The algorithm stores the best possible s − t path over the already
searched problem space, replacing it with a better path whenever such a path is found.
5.1 Structure of the Search Problem
It is instructive to consider the recursive structure generated by the recursive-greedy algorithm.
Fig. 4 illustrates an example of such a structure when running recursive-greedy for our lake sensing
application with the given starting (s) and finishing (t) location and an upper bound on the path cost
(B). The search using recursive-greedy can be represented graphically as a sum-max tree. At the
root is a max node representing the objective of finding a s − t path with maximum possible reward,
while the cost of the path is bounded by budget B. For each such max node, the children in the
search tree represent sum nodes corresponding to sum of rewards collected from the two subpaths
on either side of the middle location. Therefore, at the end of the first iteration, the graphical representation will have a max node as root with several sum nodes as children, for each feasible middle
location and each possible budget splits around that middle location. A partial tree at the end of first
iteration is shown in Fig. 4a.
For each sum node, formed at the end of the first iteration, the algorithm is then applied recursively on the left subpath. Thus the first step of second iteration seeks to find a s − vm path with
maximum possible reward under the budget constraint corresponding to the respective budget split
for the sum node. Then, their approach commits to the selected locations on the left side, and recurses on the right subpath (to search for a vm − t path), given these selected locations. As a result,
each sum node will have two max nodes as children, each representing an objective to find a subpath
of maximum reward on either side of the selected middle location. This algorithm is “greedy” in
that it commits to the locations selected in the first subpath before optimizing the second subpath.

717

S INGH , K RAUSE , G UESTRIN & K AISER

(a) recursive-greedy during first iteration

(b) recursive-greedy during second iteration

Figure 4: Illustration of recursive greedy algorithm, as proposed by Chekuri and Pal, for the lake sensing application.
Sum-max tree presents the graphical representation of the problem space.

A partial tree at the end of second iteration is shown in Fig. 4b. Despite the greedy nature, the
recursive-greedy approach provides the following approximation guarantee:
Theorem 2. (Chekuri & Pal, 2005) Let P ∗ = (s = v0 , v1 , . . . , vk = t) be an optimal s-t-path
solution. Let P be the path returned by RG(s, t, B, R, i). If i ≥ d1 + log ke, then IX (P) ≥
IX (P ∗ )/ d1 + log ke.
1
Hence, the recursive-greedy solution P obtains at least a fraction of d1+log
of the optimal
2 ke
information, where k ≤ n, i.e. the total number of locations traversed by the optimal path will be
smaller than the total number of locations in the discretized spatial domain. Referring back to Theorem 1, for the MIPP problem using recursive-greedy as the single robot path planning approach,
η = d1 + log ke.

5.2 Running Time
By inspecting the recursive structure, the running time of the recursive-greedy algorithm can be seen
to be quasi-polynomial. More specifically, the running time of the algorithm is O((M B)O(log2 M ) ),
where B is the budget constraint and M = |V| is the total number of possible observation locations.
So, even for a small problem with M = 64 locations, the exponent will be 6, resulting in a very
large computation time, making the algorithm impractical for observing several real world physical
processes.
The large computational effort required by recursive-greedy can be attributed to two issues: 1)
the large branching factor at each of the max nodes of the recursion tree (sum nodes for each possible
middle node and each possible budget split across that middle node) and 2) (possibly) unnecessary
recursion while exploring subtrees in problem space that can not provide us with an improved reward compared to current best solution. In the following sections, we propose two complementary
approaches (can be used independently of the others) which are intended to ameliorate these concerns: a spatial decomposition technique, and a branch and bound approach. Spatial decomposition
718

E FFICIENT I NFORMATIVE S ENSING USING M ULTIPLE ROBOTS

Starting node s

Starting cell Cs

Ending node t

Ending cell Ct

Cs

Middle cell Cm
Ct
P1, budget = B’
P2, budget = Be–B’

Incoming
path P1

a

b

(a) Spatial decomposition of the phenomenon

d

c

Smoothed path

Exiting path
P2

Cell center

(b) Cell paths and travel within cells

(c) Cell paths and path smoothing

Figure 5: Illustration of spatial decomposition in recursive-eSIP using surface sensing in lake environment as an
example. The sensing domain ((a), top) is decomposed into a grid of cells ((a), bottom). recursive-eSIP jointly optimizes
over cell-paths ((b), top) and allocations of experiments in the cells ((b), bottom). Within the cells, locations are connected
to cell center. recursive-eSIP concatenates paths between-cell and within cell paths ((c), top) and finally heuristics are
applied in eMIP to smooth the path ((c), bottom).
(discussed in Section 6) seeks to reduce the high branching factor (i.e. the number of sum nodes
in the search tree) by clustering the sensing locations and then running the recursive-greedy over
these clusters instead of actual sensing locations. Branch and bound (discussed in Section 7) seeks
to avoid unnecessary recursion by maintaining a lower and an upper bound on the possible reward
from a subtree in the search tree and pruning the tree accordingly. These two approaches, together
with sequential-allocation (discussed in Section 3) provide an efficient algorithm for multi robot
informative path planning.

6. Spatial Decomposition – Approximating MIPP as SD-MIPP
In this section, we explain in detail the process of spatial decomposition and the corresponding improvements in running time achieved through this process. Our approach assumes that the traveling
cost between arbitrary locations is given by their euclidean distance.
An intuitive approach for improving the running time is to spatially decompose the sensing
region into smaller sub-regions, each containing a cluster of sensing locations. We can thus think
about planning informative paths as deciding which sub-regions to explore, and then deciding which
locations to sense within these sub-regions. The idea of exploring the sub-regions motivates the
decomposition of the sensing domain into smaller regions (cells). We can then run the recursivegreedy algorithm on these cells instead of the actual sensing locations. Since the size of each cellular
region is small, traveling cost within each cell can be ignored3 . Once we ignore the traveling cost
within the cells, sensing locations inside the selected cells can be chosen using the GreedySubset
approach (as proposed by Krause et al., 2008), taking advantage of its strong approximation guar3. There may be robotic platforms where non-holonomic motion constraints will make small motions much more challenging and thus traveling cost for smaller distances within a cell may become non-negligible. For such systems,
with large traveling cost for smaller motions, some system specific constraints may be possible to account for while
performing cellular decomposition or the greedy algorithm may be constrained to not select locations that are “too”
close).

719

S INGH , K RAUSE , G UESTRIN & K AISER

antee in an unconstrained setting as discussed in Section 4. Fig. 5 presents an illustration of our
approach and is explained as follows:
1. We decompose the sensing region, containing finitely many discrete sensing locations (c.f.,
e = {C1 , C2 , . . . , CN } (c.f., Fig. 5a,
Fig. 5a, top), into a collection of non-overlapping cells V
bottom). The distance between two cells is defined as the distance between the centroids
of these cells. Each cell Ci contains a set of locations vi ∈ V, representing sensing locations, such that the coordinates of these locations, in a euclidean metric space, lie within the
boundary of the containing cell.
2. We approximate the original MIPP problem with the spatially decomposed MIPP problem, or
e In SD-MIPP, we jointly optimize over cell-paths in V
e (c.f., Fig. 5b,
SD-MIPP problem on V.
top) using the recursive-greedy algorithm, and over the allocation of observations within the
cells visited by the paths using the GreedySubset algorithm. Thus, when allocating measurements to a cell, we ignore the traveling cost within the cell (c.f., Fig. 5b, bottom). Since
the cells are not very large, this simplification only leads to a small additional cost when the
SD-MIPP solution is transformed back to the original MIPP problem.
3. We transfer the (approximate) SD-MIPP solution, consisting of a cell-path and an allocation
of observations to cells (c.f., Fig. 5c, top), back to the original MIPP problem. We then smooth
the path (c.f., Fig. 5c, bottom) using heuristics, e.g. the tour-opt heuristics as discussed by
Lin (1965).
Dual optimization of cell paths and budget allocation for observations within each visited cell
motivated splitting the available budget Be into a budget Bt for traveling between the cells and a budget Be for making experiments at sensing locations within the visited cells. Such a split can be easily
incorporated in recursive-greedy algorithm as well but was not required as the paths in recursivegreedy were optimized over observation locations and not cells containing these locations. Formally,
the SD-MIPP problem is the following: We want to find a path PC∗ = (Cs = Ci1 , . . . , Cil = Ct ),
for each robot i with starting cell Cs containing the starting node s and finishing cell Ct containing
the finishing node t, with a travel cost of at most Bt . This travel budget is measured in terms of
distances between centers of visited cells, and the cost of traveling within the cells is defined as 0.
In addition, for each visited cell Cij in PC∗ , we want to select a set of sensing locations Aij , such that
the total experimental cost (for making observations within the visited cells) is upper bounded by
Be , i.e. C(Ai1 ∪ · · · ∪ Ail ) ≤ Be , and that the information I(Ai1 ∪ · · · ∪ Ail ) is as large as possible.
The optimal SD-MIPP solution uses the optimal split of the budget Be into Bt and Be . To simplify
the presentation, we rescale the costs such that the cells form a uniform grid of quadratic cells with
width L, and assume that the sensing cost Cexp is constant over all locations. These assumptions
can easily be relaxed, but they allow us to relate the path costs to the number of cells traversed, to
simplify the discussion.
The following lemma states that there exists an SD-MIPP version (PC∗ ) of the MIPP-optimal
path (P ∗ ), with (almost) the same cost, and the same information.
Lemma 3. Let P ∗ = (s = v0 , v1 , . . . , vl = t) be an optimal s-t-path solution to MIPP, constrained
by budget B. Then there exists a corresponding SD-MIPP path PC∗ = (Cs = Ci1 , . . . , Cil = Ct ),
√
traversing through locations Ai1 ∪ · · · ∪ Ail , with budget Be of at most 2 2B + 4L collecting the
same information.

720

E FFICIENT I NFORMATIVE S ENSING USING M ULTIPLE ROBOTS

Algorithm: eMIP
e k, starting / finishing locations s1 , . . . , sk , t1 , . . . , tk
Input: B,
Output: A collection of informative paths P1 , . . . , Pk
2 begin
3
Perform spatial decomposition into cells;
4
Find starting and ending cells Csi and Cti ;
5
R ← ∅;
// Path planning for each robot
6
for i = 1 to k do
// Trying different combination of traveling and
experimental budget
e do
for iter = 0 to blog2 Bc
7
iter
e
8
Be ← B − 2 ;
0
9
Piter
←recursive-eSIP (Csi , Cti ,Be ,R,iter);
0
10
Smooth Piter
using tour-opt heuristics;
0 );
11
Pi ← argmaxiter I(Piter
12
R ← R ∪ Pi ;
13
return P1 , . . . , Pk ;
14 end
Algorithm 3: eMIP algorithm for informative multi robot path planning. Procedure from Line 7 to Line 11
1

effectively implements eSIP algorithm. eSIP is then repeated (Line 6) using sequential allocation described in
Section 3 (Line 6) to get paths for each robot i.

We now present an algorithm for finding an approximately optimal solution to SD-MIPP, and
then we show that this solution √
gives us an approximate solution to the original MIPP problem, with
just slightly increased cost of 2 2B + 4L, for ensuring that the optimal solution for MIPP exists in
the corresponding SD-MIPP setting.
6.1 Algorithm for SD-MIPP
e and then smooths out the paths over the
Our eMIP algorithm solves the SD-MIPP problem on V
selected observation locations to provide a solution to MIPP. Let us first clarify the algorithmic
nomenclature specifically:
• recursive-eSIP: implements an approach similar to recursive-greedy for selecting a path over
e and greedily selects the observation locations within each visited cell using GreedySubset;
V
• eSIP: iterates through different values of traveling budget by calling recursive-eSIP with corresponding values of input Be and i and smoothing the output path from recursive-eSIP using
tour-opt heuristics;
• eMIP: effectively implements sequential-allocation with eSIP as the single robot path planning algorithm
The complete algorithm works as follows: An outer loop (Line 6 in Algorithm 3) implements
the sequential allocation algorithm for performing path planning for multiple robots. The procedure
721

S INGH , K RAUSE , G UESTRIN & K AISER

inside the outer loop (Line 7 to Line 11 in Algorithm 3) implements the eSIP algorithm. This procedure iterates through different combination of traveling and experimental budget, allocating Bt
(= 2iter ) out of the total budget Be for traveling between the cells, and Be (= Be − Bt ) for making experiments within the visited cells. Stepping through Bt in powers of 2 results in faster performance
(log2 Be instead of Be iterations). If we increase the input budget Be by a factor of 2, the exponential
increase in traveling budget is guaranteed to try traveling budget, Bt (= 2iter ≥ BtApp ) where BtApp
is the traveling budget for the best approximation path. Since the overall budget Be is increased by a
factor of 2, the remaining experimental budget is also guaranteed to be more than the experimental
budget corresponding to the best approximation path. Therefore, exponential increase in traveling
budget will only increase the required budget Be by at most a factor of 2. The eSIP procedure then
calls recursive-eSIP (explained in Algorithm 4), selecting the cells to visit, and greedily allocating
observations in the visited cells. Finally, the eSIP procedure calls tour-opt heuristics to smooth the
output path from recursive-eSIP.
The recursive-eSIP procedure takes as input a starting cell Cs , a finishing cell Ct , an experimental budget Be , a residual R indicating the locations visited thus far (initially passed empty from
eMIP), and a maximum recursion depth, iter (initially passed log2 Bt from eMIP). We then:
1. Iterate through all possible choices of middle cells Cm (such that there are, almost, equal
fe (of the available experimental
number of cells on either side of Cm ) and budget splits B
budget Be ) to spend for making experiments on the subpaths from Cs to Cm and Cm to Ct
fe can either be linearly (more accurate) or exponentially
(c.f., Fig. 5b). The budget splits B
(faster) spaced, as described below.
2. Recursively find a subpath P1 from Cs to Cm , constrained by budget B 0 , leaving the remaining
budget (Be − B 0 ) for the other subpath P2 . Reducing recursion depth (iter) by 1, for each
of the subpaths P1 and P2 , ensures that equal number of cells are visited on either side Cm .
The lowest level of recursion depth 0 signifies the cell selected for the corresponding path.
At the lowest recursion level, we then use the GreedySubset algorithm (c.f., Section 4) to
select the sensing locations based on the residual information function IR and constrained by
budget B 0 . As an illustration, the black locations in the middle cell Cm in Fig. 5b bottom,
are selected by the GreedySubset algorithm with budget B 0 = 4 such that they provide the
maximum improvement in mutual information.
3. We then commit to the locations selected in P1 , and recursively find a subpath P2 from
Cm to Ct , with experimental budget Be − B 0 . Committing to the locations selected in P1
requires that we greedily select the sensing locations at lowest recursion level based on the
residual information function IR∪P1 .
4. Finally, we concatenate the locations obtained in P1 and P2 to output the best path from the
algorithm (c.f., Fig. 5c, top).

6.2 Linear vs. Exponential Budget Splits
Step 1 of the recursive-eSIP procedure (as explained in Section 6.1) considers different budget splits
fe to the left and right subpaths. Similar to the recursive greedy algorithm, one can choose
B0 ∈ B
fe = {0, 1, 2, 3, . . . , Be −1, Be } to be linearly spaced. Since the branching factor is proportional to
B
the number of considered splits, linear budget splits leads to a large amount of computation effort.
722

E FFICIENT I NFORMATIVE S ENSING USING M ULTIPLE ROBOTS

1

2
3
4
5
6
7

8
9

10
11
12
13
14
15

Algorithm: recursive-eSIP
Input: Cs , Ct , Be , R, iter
Output: An informative path P from Cs to Ct
begin
if (d(Cs , Ct ) > 2iter L) then return Infeasible;
// Greedy node selection within starting and finishing cell
P ← GreedySubsetBe ,R (vi : vi ∈ Cs ∪ Ct );
if (iter = 0) then return P;
reward ← IR (P);
// Trying each cell as middle cell
foreach Cm ∈ C do
// Trying each possible budget split
fe do
for B 0 ∈ B
// Planning subpath on one side of the middle cell
P1 ← recursive-eSIP (Cs , Cm , B 0 , R, iter − 1);
// Planning subpath on other side of the middle cell
while committing to nodes selected in first subpath
P2 ← recursive-eSIP (Cm , Ct , Be − B 0 , R ∪ P1 , iter − 1);
if (IR (P1 .P2 ) > reward) then
P ← P1 .P2 ;
reward ← IR (P);
return P;
end
Algorithm 4: recursive-eSIP procedure for path planning.

fe = {0, 20 , 21 , 22 , . . . , 2log2 Be } ∪ {Be , Be −
An alternative is to consider only exponential splits: B
0
1
2
2 , Be−2 , Be−2 , . . . , 0}. In this case, the branching factor is only logarithmic in the experimental
budget. Even though we are not guaranteed to find the same solutions as with linear budget splits,
we can both theoretically (as given by Lemmas 4 and 7) and empirically (as illustrated in Fig. 14c
and 14d) show that the performance only gets slightly worse in this case, compared to a significant
improvement in running time. In addition to these two ways of splitting the budget, we also confe = {0, 20 , 21 , 22 , . . . , 2log2 Be }), which further
sidered one-sided exponential budget splits (i.e. B
reduces the branching factor by a factor of 2 compared to the exponential splits defined above. Although we do not provide theoretical guarantees for this third possibility, we experimentally found
it to perform very well (c.f., Section 8).
6.3 Algorithmic Guarantees
Our algorithm is greedy in two ways:
• At recursion depth 0, the sensing locations are selected greedily based on the mutual information criterion.
• Before exploring the subpath P2 , recursive-eSIP procedure commits to the locations selected
in subpath P1 .
723

S INGH , K RAUSE , G UESTRIN & K AISER

Due to the these greedy steps, recursive-eSIP is an approximation algorithm and does not necessarily find an optimal solution. The following lemma, however, guarantees a performance bound
for the path output by the eSIP procedure:
Lemma 4. Let PC∗ = (Cs = C1 , . . . , Ck = Ct ) be an optimal solution for single robot instance
e where an optimal set of locations are selected within each
of SD-MIPP, constrained by budget B,
b be the solution returned for eSIP. Then I(P)
b ≥ 1−1/e I(P ∗ ).
visited cell Cj . Let P
C
1+log k
2

6.4 Solving the MIPP Problem
Now, we need to transfer the approximately optimal solution obtained for SD-MIPP back to MIPP.
A path over cells, with observation locations selected greedily within each visited cell, is transformed into a path over observation locations by connecting all locations selected in cell Cij to the
cell’s center, (as indicated in Fig. 5b bottom), then connecting all selected centers to a path (Fig. 5c
top), and finally expanding the resulting tree into a tour by traversing the tree twice (by traversing
each edge of the tree once in each direction, a set of nodes connected by a tree can be converted
into a set of nodes connected by a path). This traversal results in a tour which is at most twice as
long as the shortest tour connecting the selected vertices. (Of course, an even better solution can be
obtained by applying an improved approximation algorithm for TSP, such as the algorithm proposed
by Christofides, 1976). The following Theorem completes the analysis of our algorithm:
Theorem 5. Let P ∗ be the optimal solution for the single robot instance of the MIPP problem with
b achieving an information
budget constraint B. Then, our eSIP algorithm will find a solution P
√
√
1−1/e
∗ ), whose cost is no more than 2(2 2B + 4L)(1 + L 2 ) in
b ≥
value of at least I(P)
I(P
1+log2 N
Cexp
√
√
fe and no more than 2(2 2B + 4L)(1 + L 2 )N log2 32 in the
the case of linear budget split for B
Cexp

fe .
case of exponential budget split for B
The performance guarantee is w.r.t. the number of cells N instead of the number M of sensing
locations, as was the case in the work by Chekuri and Pal (2005). However, the input budget
constraint is violated by an amount based on the size of cells during the spatial decomposition. This
violation in input budget constraint leads to a tradeoff between computation effort and additional
cost incurred that can be tuned based on specific application requirements. If the size of the cell is
small (in the limit reducing each cell to each observation location), the number of cells will be large
and will result in higher computation time with reduced additional cost. On the other hand, if the
size of the cell is large, the computation time will be small and the algorithm needs to pay higher
additional traveling cost.
Running time analysis of eSIP is straightforward. The algorithm calls the routine recursive-eSIP
log2 B times. If TI is the time to evaluate the mutual information I, then the time for computing
greedy subset Tgs (Line 4, Algorithm 4) is O(NC2 TI ), where NC is the maximum number of
locations per cell. At each recursion step we try all the cells that can be reached with the available traveling budget (Line 7, Algorithm 4). For the possible experimental budget split, we try all
fe among the two subpaths P1 and P2 (Line 8,
(linearly or exponentially spaced) splits of Be ∈ B
e The following proposition states the
Algorithm 4). The recursion depth would be log2 (min(N, B)).
running time for eSIP:

724

E FFICIENT I NFORMATIVE S ENSING USING M ULTIPLE ROBOTS

Proposition 6. The worst case running
 time of eSIP for linearly spaced splits of the experimental
budget is O Tgs log2 B(N B)log2 N , while for the exponentially spaced splits of the experimental
budget it is O Tgs log2 B(2N log2 B)log2 N
Comparing this running time to the recursive-greedy algorithm (O((M B)O(log2 M ) )), we note
a reduction from B to log2 B in the base, and log of the number of locations (log2 M ) to log of the
number of cells (log2 N ) in the exponent. These two improvements turn the impractical recursivegreedy approach into a much more viable algorithm.
Varying the number of cells (and correspondingly the size of each cell) results in a trade-off
between the computation effort and the traveling cost within the cell that is ignored by the eSIP
algorithm. Proposition 6 states that the computation effort is directly proportional to the number
of cells “N”. Therefore as we increase the number of cells, corresponding computation effort for
the eSIP algorithm will also increase. On the other hand, reducing the number of cells will result
in increasing the size of each of the cell. Since eSIP algorithm ignores the traveling cost within
the cell, larger cell size will imply larger traveling cost ignored by the eSIP algorithm and hence
larger overshoot in the cost of the resultant output path over the input budget B. Lemma 3 states the
corresponding additional cost incurred by the output path calculated using eSIP algorithm in terms
of the cell size “L”. Based on the specific application requirements, one can decide the appropriate number of cells and fine tune the trade-off between computation effort and additional path cost
incurred. Fig. 14f shows that the corresponding collected reward did not vary significantly as we
varied the number of cells for the application of observing temperature in a lake environment.

7. Branch and Bound
The spatial decomposition technique effectively enables a trade-off between running time complexity and achieved approximation guarantee. However, the eSIP algorithm still has to solve a
super-polynomial, albeit sub-exponential, search problem. In the following, we describe several
branch and bound techniques which allow further reduction in the computation effort making our
approach tractable for real world sensing experiments.
7.1 Problem Representation
The specific structure of the search space representation motivated many of the proposed branch and
bound approaches. Similarly to the recursive structure of the recursive-greedy algorithm (discussed
in Section 5), the recursive-eSIP problem structure can also be represented as a sum-max tree, as
shown in Fig. 6a. A small difference exists in the selection of observation locations along the
solution path. In the case of recursive-greedy, each of the sum nodes traversed in the selected
path represents a physical observation location. However, in the case of recursive-eSIP, each sum
node in the selected path represents a cell in the corresponding traversed path. The observation
locations at the sum node are selected greedily, within the corresponding cell, based on the available
experimental budget. Using the sum-max tree problem structure, we now explain the proposed
branch and bound approaches to prune parts of the tree that will not provide any further improvement
over the currently known best solution path. All of the proposed branch and bound techniques are
outlined in the recursive-eSIP procedure presented in Algorithm 5.

725

S INGH , K RAUSE , G UESTRIN & K AISER

1

Algorithm: recursive-eSIP with branch and bound
Input: Cs , Ct , Be , R, iter, rewardLB, α
Output: An informative path P from Cs to Ct

2
3
4
5
6
7
8
9
10

begin
if (d(Cs , Ct ) > 2iter L) then
return Infeasible
P ← GreedySubsetBe ,R (vi : vi ∈ Cs ∪ Ct );
if (iter = 0) then
return P
f ilterCells ← ∪Ci ∀Ci s.t. d(Cs , Ci ) ≤ 2iter L/2 and d(Ci , Ct ) ≤ 2iter L/2 ;
foreach Cm ∈ f ilterCells do
fe do
for B 0 ∈ B

12

// Calculating upper bound using GreedySubset
U BP1 ← calculateU B(Cs , Cm , B 0 , iter − 1, R);
U BP2 ← calculateU B(Cs , Cm , Be − B 0 , iter − 1, R);

13

if ((U BP1 + U BP2 ) > α ∗ rewardLB) then

11

15

// Calculating lower bound for P1
heurP1 ← heuristicOP(Cs , Cm , B 0 , R, iter − 1);
LBP1 ← max(IR (heurP1 ), rewardLB − U BP2 );

16

// Recursive search for P1
P1 ← recursive-eSIP (Cs , Cm , B 0 , R, iter − 1, LBP1 , α);

14

18

// Calculating lower bound for P2
heurP2 ← heuristicOP(Cm , Ct , Be − B 0 , R ∪ P1 , iter − 1);
LBP2 ← max(IR∪P1 (heurP2 ), rewardLB − IR (P1 ));

19

// Recursive search for P2
P2 ← recursive-eSIP (Cm , Ct , Be − B 0 , R ∪ P1 , iter − 1, LBP2 , α);

17

if (Iresid (P1 .P2 ) > rewardLB) then
P ← P1 .P2 ;
rewardLB ← Iresid (P1 .P2 );

20
21
22
23
24

return P;
end

Algorithm 5: recursive-eSIP procedure with branch and bound approaches for efficient path planning. Each
procedure corresponds to a max node in the search space with input rewardLB representing the calculated lower
bound. A sum node in the search space effectively combines the recursive calls to each of the subpaths (implemented in Line 16 and Line 19). Since recursion reduces the traveling budget (2iter L) by half, the initial pruning in
Line 8 removes the cells that can not be reached in the next recursion step. Line 15 and Line 18 calculate the lower
bound for subpaths on either side of the selected middle cell. Input α represents the scaling factor for one of the
b ≥ 1−1/e I(P ∗ )
sub-approximation heuristics. Approximation guarantee for the output path P is given as I(P)
1+log2 N
∗
where I is the submodular reward function and P is the optimal path.

726

E FFICIENT I NFORMATIVE S ENSING USING M ULTIPLE ROBOTS

(a) sum-max tree

(b) Pruning of sum nodes

(c) Tighter lower bounds

Figure 6: Illustration of our branch & bound approach. (a) shows the sum-max tree representing the search space. Each
max node selects a middle cell and a budget allocation, and each sum node combines two subpaths on either side of the
selected middle cell. (b) shows how upper bound at a sum node (e.g. a value of 18 at Sum2 ), when smaller than the
lower bound of the parent max node (e.g. a value of 20 for Max1 ) can be used to prune branches in the search tree. (c)
shows how lower bound at a max nodes is tightened (e.g. a value of 7 at Max6 is improved to 9 using upper bound of 11
at sibling M axn7 and lower bound of 20 at grandparent Max1 ) to allow further pruning which otherwise may not have
been possible (e.g. pruning of Sum4 with upper bound value of 8).

7.2 Efficient Search of the Problem Space
In a naive implementation of recursive-eSIP, the entire recursion tree would eventually be traversed.
However, many of the considered subpaths may be highly suboptimal. Several heuristics have been
proposed in the past for similar path planning problem with empirical efficiency claims, but without
any approximation guarantee. We use one such heuristic (c.f., Chao et al., 1996, hereafter referred
to as heuristicOP) to calculate a solution path satisfying the budget constraints, while trying to maximize the collected reward. Since such a path can be efficiently calculated with small computation
effort, we use this path as an initial known solution. The total reward collected in this path is used as
an input lower bound (input variable rewardLB in Algorithm 5) for the root max node. Since the
computation effort associated with heuristicOP is small, it is also used at the rest of the max nodes
in the search tree to calculate the lower bound for these nodes (discussed in detail in Section 7.2.2).
For each of the child sum nodes, an upper bound for the collected reward is calculated by exploiting the submodularity of the reward function (procedure calculateU B called in Line 11 and 12
727

S INGH , K RAUSE , G UESTRIN & K AISER

1

Algorithm:calculateUB

Input: Cs , Ct , Be , iter, R
Output: An upper bound UB on information gain
2 begin
// Selecting set of reachable cells
3
possibleCells ← ∪Ci ∀Ci s.t. d(Cs , Ci ) + d(Ci , Ct ) ≤ 2iter L ;
// Greedy node selection within reachable cells
4
P ← GreedySubsetBe ,R (vi : vi ∈ possibleCells);
5
UB ← Iresid (P);
6
return U B;
7 end
Algorithm 6: Procedure for calculating upper bound at max nodes. Upper bound of child max nodes is added
to obtain upper bound at parent sum node.

in Algorithm 5 and explained in detail in Algorithm 6). We then only need to process the sum node
children with upper bounds greater than the current best solution (Line 13 in Algorithm 5). The
current best solution for the parent max node is updated when the collected reward from any of the
child sum nodes is greater than the previously known best solution reward (Line 20 in Algorithm 5).
Fig. 6b presents a graphical illustration of this concept. After completely exploring branch
Sum1 , the current best solution of value 20 is updated as a lower bound for Max1 . A smaller lower
bound (18) at Sum2 results in pruning of sub-branch rooted at Sum2 . However, nodes such as Sum3
with upper bound (24) higher than the current best solution (20), need to be explored further as they
can potentially provide a solution path with a better reward than the current best solution.
7.2.1 U PPER B OUND ON THE Sum N ODES
Algorithm 6 presents the calculateUB procedure for obtaining an upper bound on the collected
reward at each max node and is used in recursive-eSIP (Line 11, 12 in Algorithm 5) for pruning the
search space. The upper bound at a sum node is calculated by adding the upper bound of each of the
child max nodes. We calculate the upper bounds by relaxing the path constraints, and then finding
an optimal set of reachable locations for each path (P1 and P2 ). Since this problem itself is NPhard, we exploit the submodularity of reward function and approximate it using the GreedySubset
algorithm. Fig. 7 illustrates an example of calculating the upper bound. We first calculate the set
of reachable locations w.r.t. the remaining traveling budget. These locations are contained within
the cells Ci reachable from cells Cs and Ct (Line 3 in Algorithm 6). Such a boundary for reachable
locations is illustrated by an ellipse in Fig. 7.
Then, we run the GreedySubset algorithm to greedily select best possible Be locations from all
the possible reachable locations (Line 4 of Algorithm 6). As an example, Vi and Vj are selected
using GreedySubset in Fig. 7. Since GreedySubset guarantees a constant factor (1−1/e) approximation (Nemhauser et al., 1978), multiplying the resulting information value by (1 − 1/e)−1 provides
an upper bound on the information achievable by the path (and hence the corresponding max child
node). Therefore, in Fig. 7 the reward collected from locations Vi (MI(Vi )) and Vj (MI(Vj )) when
multiplied by the factor (1 − 1/e)−1 provides upper bound for the collected reward. However, since
the path cost constraint are relaxed, the total cost of observing Vi and Vj (dsi + dij + djt ) may be

728

E FFICIENT I NFORMATIVE S ENSING USING M ULTIPLE ROBOTS

Figure 7: Illustration of calculating upper bound using GreedySubset.
more than the available budget B. In Fig. 6c, for example, we use calculateUB to get upper bounds
13 for Max6 and 11 for Max7 , resulting in an upper bound of 13 + 11 = 24 for Sum3 4 .
7.2.2 L OWER B OUND ON THE Max N ODES :
Effective pruning of subtree rooted at sum nodes would require calculating the lower bounds for the
parent max node efficiently. One way to calculate such lower bounds is by exploring one branch
completely (as explained in Section 7.2). This procedure will be computationally expensive. Instead, we implement two other ways for acquiring such lower bounds faster: Using heuristicOP 5
(as explained above for obtaining the initial best solution), and based on the current best solution of
the grandparent max node. We then use the larger of two different lower bounds.
Fig. 6c illustrates the graphical presentation of the procedure for calculating the lower bounds
using the current best solution of the grandparent max node. We call this procedure altLB. We calculate an upper bound (exploiting the submodularity) of 11 for Max7 node. For the node Max6 , since
the grandparent node Max1 has a lower bound of 20, the subtree rooted at Max6 has to provide a
reward of at least 9 (20 - 11) to be explored further. The lower bound of value 9 calculated using
altLB is tighter than the lower bound provided by the heuristic (7), and enabled pruning of branch
Sum4 (with upper bound 8).
Lines 15 and 18 in Algorithm 5 illustrate the altLB procedure. While using altLB, the lower
bound for subpath P1 (in Line 15), is calculated using the upper bound of subpath P2 . On the other
hand, while calculating the lower bound using altLB for subpath P2 (in Line 18), the exact reward
from P1 (IR (P1 )) is used instead of the upper bound. Since the actual reward is always tighter than
the calculated upper bound, the lower bound calculated for subpath P2 (using altLB) will be tighter
than the lower bound calculated for subpath P1 . This motivates exploring the subpath with higher
experimental budget first such that the upper bound for the unexplored subpath (with lower experimental budget) is tighter making the lower bound for the first subpath tighter6 . The heuristic for
4. We can even compute tighter online bounds for maximizing monotonic submodular functions, as discussed
by Nemhauser et al. (1978).
5. heuristicOP was only proposed for modular functions but we found it to provide good solution paths even in the
submodular setting.
6. We note that with higher experimental budget, GreedySubset (used to calculate the upper bound) can potentially
select more locations that are far apart (since the path cost constraint are ignored). When path cost constraint is
incorporated, such locations will become infeasible and will make the upper bound loose.

729

S INGH , K RAUSE , G UESTRIN & K AISER

exploring the subpath with higher experimental budget first was also exploited to further improve
the computation effort.
Maintaining a lower bound at each node in the search tree also makes our approach anytime,
i.e. the search can be terminated at any point even before it is completed. The current best solution
from the graph already searched will be available after this early termination. Early termination is
particularly advantageous in scenarios when it is required to obtain the best possible path traversed
by the robot with a hard upper bound on the available time to calculate such a path.
7.2.3 N ODE O RDERING
The illustration in Fig. 6b demonstrates that a better currently known solution will likely help in
increased pruning of the search tree. In order to improve the current best solution faster, at each
max node we explore the sum nodes in the decreasing order of their upper bounds. The intuitive
idea is that a higher upper bound is a likely indicator for higher reward value. Thus the upper bound
in Line 11 and 12 in Algorithm 5 can be calculated separately and the rest of the computation (in
loops implemented in Line 9 and 10 in Algorithm 5) can then be executed in decreasing order of
upper bound. Such an approach is similar to node ordering that is employed to improve the pruning
efficiency of Depth First Branch and Bound (DFBnB) (Zhang & Korf, 1995).
7.2.4 S UB - APPROXIMATION
Upper and lower bounds derived as explained above can potentially be loose. We can address this
issue, and further trade off collected information with improved execution time, by introducing
several sub-approximation heuristics. As a first heuristic, once the node ordering is performed, we
explore only the top K sum nodes. This heuristic, termed as sub-approximation (Ibaraki et al.,
1983), is found to be effective in practice.
As a second heuristic, instead of comparing the lower bound of a parent max node directly with
the upper bound from the child sum nodes (when deciding which subproblems to prune), we scale
up the lower bound by a factor of α > 1 (Line 13 of Algorithm 5). This scaling often allows us
to prune many branches that would not have been pruned otherwise. Unfortunately, this optimistic
pruning can also potentially cause us to prune branches that should not have been pruned, and decrease the information collected by the algorithm. In practice, for sufficiently small α values, this
procedure can speed up the algorithm significantly, without much effect on the quality of the solution. This performance comparison for both computation effort and collected reward using several
real world sensing datasets is discussed in Section 8.2.

8. Experimental Results
We performed several experiments both in-field as well as in simulation (using real world sensing
datasets) to demonstrate the usefulness of our proposed algorithm for several diverse environmental
sensing applications. In-field experiments were performed using the Networked InfoMechanical
System (NIMS) (Jordan et al., 2007), a tethered robotic system. Real world sensing datasets used
for performing scaling and multi robot experiments in simulation were collected using either a
network of static sensors or a robotic boat.

730

E FFICIENT I NFORMATIVE S ENSING USING M ULTIPLE ROBOTS

(a) Schematic representation of the system

(b) Image captured while performing path planning

Figure 8: Aquatic based NIMS (NIMS-AQ)is a platform in the NIMS family used for performing path planning in the
lake environment.

8.1 In-field Experiments
Several experiments were performed in-field to demonstrate the applicability of modeling a phenomenon as a Gaussian Process and using eMIP to perform path planning for diverse aquatic sensing applications. These include a river monitoring application with the objective of studying salt
concentration, and lake monitoring for several applications of interest to limnologists. In each of
these applications, NIMS was used to monitor a cross-section (two dimensional vertical plane in an
environment) in the aquatic environment. The phenomenon of interest is then modeled as a Gaussian Process and we use the mutual information criterion as submodular reward function, quantifying the informativeness of observation locations. The learned Gaussian Process model and mutual
information objective are then provided as input to eMIP and the subset of locations as output by the
algorithm are subsequently observed, again using NIMS as the robotic platform. In order to quantify
the efficiency of our approach, we predict the phenomenon at unobserved locations and compute the
root mean square (RMS) error between the predicted phenomenon and the ground truth (calculated
by observing at all the uniformly spaced locations before and after the path planning experiment).
8.1.1 ROBOTIC P LATFORM :
The Aquatic Networked InfoMechanical Systems platform (NIMS-AQ) is the latest in the family of
NIMS systems (Jordan et al., 2007; Pon et al., 2005; Borgstrom et al., 2006), developed specifically
for aquatic applications and used during the lake deployment. The family of NIMS systems had
been successfully deployed for several terrestrial and aquatic sensing applications. In 2006 alone,
NIMS was used in several successful campaigns in forests (La Selva, Costa Rica and James Reserve,
California), rivers (San Joaquin, California and Medea Creek, California), lake (Lake Fulmor, California), and mountain ecosystems (White Mountains, California),
Fig. 8a displays the schematic view of the system. The basic infrastructure of the system includes a rigid sensing tower supported by two Hobie FloatCat pontoons7 in a catamaran configuration. An actuation module resides on top of the sensing tower that drives the horizontal cable
and vertical payload cable (horizontal and vertical motion respectively) across a cross-section of the
aquatic environment. Power for the system is provided by two deep cycle marine batteries housed
on top of the pontoons. The horizontal drive cable is kept center-aligned to the craft by using guide
7. Developed by Hobie Cat Company.

731

S INGH , K RAUSE , G UESTRIN & K AISER

(a) Observed distribution during a raster scan on August 11

(b) Predicted distribution after observing at locations
as output by eMIP

Figure 9: Distribution of electrical conductivity (microSiemens per centimeter) as observed at the confluence of San
Joaquin river, California. Points represent observation locations during the corresponding experiment.

pulleys that can be repositioned based on the type of aquatic environment in which NIMS-AQ is
sampling (flowing or still water conditions). Fig. 8b shows NIMS-AQ performing path planning in
the lake environment.
8.1.2 S ENSING IN A R IVER E NVIRONMENT
The first in-field application of our approach was executed at the confluence of two distinct rivers,
Merced river and San Joaquin river, in California from August 7-11, 2007 (hereafter referred to as
San Joaquin deployment). Fig. 1a displays an aerial view of the San Joaquin deployment site. The
scientific objective at the confluence zone is to characterize the transport and mixing phenomena
at the confluence of two distinct rivers – Merced river (relatively low salinity) and the agricultural
drainage-impacted San Joaquin River (relatively high salinity) by observing several parameters that
may indicate the mixing behavior of the two streams. Such river observations are useful for answering important questions pertaining to the spatio-temporal variability of velocity and water quality
dynamics resulting from pollutant inputs, hydrodynamic mixing regimes, and biogeochemical cycling processes that are themselves distributed in time and space. Understanding such mixing patterns are important for policy issues related to water distribution from river ecosystems (Brekke
et al., 2004).
The total width of the observed cross-section was 40 meters with the maximum depth of 1.4 meters (closer to the middle of the cross-section). Several experiments had been executed in the past
to characterize the mixing phenomena at this confluence site (Singh et al., 2007a; Harmon et al.,
2007). Primary experimental design during these campaigns comprised of making observations at
uniformly spaced locations in a two dimensional cross-section (hereafter referred to as raster scan)
and repeating these experiments several times to understand the spatial and temporal dynamics in
the environment. Each of these experiments took several hours, thus restricting the experiments to
a very small number of cross-sections (one or two) within the limited deployment time. However,
a detailed understanding of the confluence environment would require observing multiple crosssections, within the limited time frame. This necessitates the use of an adaptive sampling approach
that can model the observed phenomenon, make observations at a small number of locations based
on that model and then effectively predict the phenomenon at the unobserved locations.

732

E FFICIENT I NFORMATIVE S ENSING USING M ULTIPLE ROBOTS

Mixing patterns were characterized at the confluence by observing electrical conductivity that
indicated the amount of salt concentration in the water. Fig. 9a displays typical distribution at a
cross-section in the confluence zone with x-axis representing the distance along the cross-section
and y-axis representing the depth. Low concentration of electrical conductivity towards the lower
x values is contributed by clear water from the Merced river with the other end displaying high
concentration of salts carried by the San Joaquin river. We first use the data from one such raster
scan performed on the first day of the deployment (displaying similar characteristics) to learn a
non-stationary Gaussian Process model, using a covariance function parameterization as described
by Krause and Guestrin (2007). The parameters are chosen by maximizing the marginal likelihood (Rasmussen & Williams, 2006). This non-stationary process was learned by dividing the
complete region into smaller sub-regions and combining the locally-stationary GPs from each of
these sub regions.
A total of 114 locations were observed during the raster scan and used for learning the GP
model. A set of 16 locations was selected out of the total of 114 (14%) using the eMIP algorithm
with the starting and finishing location on either end of the cross-section as displayed in Fig. 9a.
This set of 16 observation locations was then observed over the next few days. With the required
dwelling time8 of 30 seconds for observing electrical conductivity, large reduction in number of observation locations resulted in a significant reduction in experimental time as well (14% compared
to the raster scan).
Since the environmental phenomena exhibit spatial and temporal dynamics, we performed raster
scans before and after our experiment to get a measure of ground truth for electrical conductivity.
The predicted electrical conductivity, as computed after making the observations at the subset of 16
locations selected using eMIP, is then compared with this ground truth. Fig. 9b displays the predicted distribution of specific conductivity with points representing the observed locations as output
by eMIP. Fig. 9a displays the distribution as observed using raster scan performed just before the
path planning experiment.
The RMS error between the predicted distribution and the raster scan performed before the path
planning experiment was 45.99 µS/cm. On the other hand, the RMS error between the predicted
distribution and the raster scan performed after the path planning experiment was 53.87 µS/cm.
The RMS error between the two raster scans performed before and after the path planning experiment, indicating the temporal variation in the environment, was 57.55 µS/cm. Low RMS error for
our predicted distribution, when compared with the RMS error between the raster scans performed
before and after the path planning experiment clearly indicates the effectiveness of our approach
for modeling and path planning in such environments. Path planning experiments performed during
other days also demonstrated similar prediction accuracy, while maintaining the significant reduction in total experimental time.
8.1.3 S ENSING IN A L AKE E NVIRONMENT
The second set of in-field experiments was executed at a lake on the campus of University of California, Merced from August 10-11, 2007 (hereafter referred to as lake deployment). This site was
chosen based on its convenience for being accessibly located on the university campus and its similarity to several other lakes that are of interest for diverse limnology applications, including the
study for growth patterns of “algal bloom”. Nuisance algal bloom can impair the beneficial use of
8. Time for which the sensor has to be kept static to get an accurate measurement.

733

S INGH , K RAUSE , G UESTRIN & K AISER

(a) Observed distribution during a raster scan on August 11

(b) Predicted distribution after observing at locations
as output by eMIP

Figure 10: Distribution of temperature (o C) at the little on UC Merced campus. Points represent observation locations
during the corresponding experiment.

aquatic systems, by blocking sunlight to underwater vegetation, consuming oxygen in the water,
and producing surface scum and odors. The growth pattern of algal bloom in a lake is dependent
on the spatial and temporal dynamics of temperature, dissolved nutrients and light occurring in different layers of its environment. Thus, temperature is one of the critical parameter to observe in
the lake environment as it controls several physical processes occurring in such low flow aquatic
environments (in contrast to the San Joaquin river environment where there is considerable water
flow).
The total width of the observed cross-section was 70 meters, with a maximum depth of up to
1.81 meters. Similarly to the San Joaquin deployment, we first learned the non-stationary GP model
using the temperature data from one of the raster scans performed on August 10. Fig. 10a displays
a typical surface distribution of temperature as observed during the raster scan at the lake. A total of
89 locations were observed during the raster scan. A set of 15 locations was selected out of these 89
locations (17%) using the eMIP algorithm with the starting and ending location on either end of the
cross-section as displayed in Fig. 10a. This set of 15 observation locations was then observed the
next day using NIMS as the robotic platform. Similar to San Joaquin deployment, we performed
raster scans before and after our experiment to get a measure of ground truth for the temperature
distribution. The predicted temperature, as computed after making the observations at the subset of
locations selected using eMIP, is then compared with this ground truth. With a smaller dwelling time
of 10 seconds (required for measuring temperature) and having to cover the entire length of the lake
cross-section, the reduction in experimental time was 50% (when compared with the raster scan).
Fig. 10b displays the predicted distribution of temperature with points representing the observed
locations as output by eMIP. Fig. 10a displays the distribution as observed using raster scan performed after the path planning experiment. The RMS error between the predicted distribution and
the raster scan performed after the path planning experiment was 0.73 o C. On the other hand, the
RMS error between the predicted distribution and the raster scan performed before the path planning
experiment was 0.82 o C. The RMS error between the two raster scans performed before and after
the path planning experiment, indicating the temporal variation in the environment, was 1.25 o C.
The low RMS error between the predicted distribution and the raster scans, in comparison with the
temporal variation exhibited by the lake environment, indicates the effectiveness of our approach in
the low-flow lake environment as well.
734

E FFICIENT I NFORMATIVE S ENSING USING M ULTIPLE ROBOTS

8.2 Experiments on Sensing Datasets
Several experiments were performed in simulation using real world sensing datasets to analyze the
scaling of our algorithm for different approaches such as varying the experimental cost, exponential
increase in budget split, varying the size of the cells of the spatial decomposition and comparison of
several heuristics, among others. Three different datasets, collected from real world sensing applications, were used for these experiments. The first dataset consists of measurements of the temperature
in Lake Fulmor, James Reserve (hereafter referred to as lake temperature dataset). Fig. 1b displays
the aerial view of Lake Fulmor. A robotic boat, part of Networked Aquatic Microbial Observing
System (NAMOS) (Dhariwal et al., 2006), was used to collect the surface temperature data around
the lake, of width around 50 meters and length around 250 meters. As discussed earlier, understanding temperature distribution is of prime importance in limnology since it governs several physical
phenomena occurring in the lake environment, including the growth of algal bloom.
The average speed of the boat was approximately 0.4 m/s. Half of the total measurements (218
different sensing locations) were used to learn a nonstationary Gaussian Process model by maximizing the marginal likelihood (Rasmussen & Williams, 2006), and the remaining measurements
were used for experimentation. We divided the lake into 22 cells (except during the experiments for
studying the effect of changing the size of the cell in spatial decomposition), with distance between
adjacent cell approximately 21 meters. Based on the average speed, and motivated by a typical
measurement duration of roughly 25 seconds, we set the experiment cost to be 10.5 meters (except
during the experiment for understanding the effect of scaling the experimental cost).
As our second dataset, we used data from an existing deployment of 52 wireless sensor motes
to learn the amount of temperature variability at the Intel Research Laboratory, Berkeley (hereafter
referred to as Berkeley temperature dataset). These sensing locations lie within a bounding region of
length 45 meters and width 40 meters. We divided the complete region into a uniform grid containing 20 equal sized cells, and determined the experimental cost to be 9 meters (approximate distance
to travel between adjacent cells). We learned a GP model as discussed by Krause et al. (2006).
Finally, we explored the performance of our algorithm on a precipitation dataset collected from
167 regions of equal area, approximately 50 km apart, during the years 1949-1994. We followed the
preprocessing and model learning described in the work by Krause et al. (2008). The large physical
spread of the sensing regions makes this dataset unconventional for a mobile robot path planning
application. To avoid this unrealistic scenario, we normalized the coordinates of the regions to lie
within a bounding region of length 7 meters and width 9 meters, while keeping the actual sensing
data observed at each location. We then divided the complete region into a uniform grid of 20 cells
with experimental cost as 1.4 meters (approximate traveling distance between adjacent cells).
For each of the plots comparing the performance of our algorithm, x-axis represent the total
cost of the path including both the traveling cost between the selected locations and the sensing
cost at each selected location (translated into distance as discussed above). When comparing the
computation effort as a measure of performance, in seconds, y-axis is drawn in logarithmic scale.
The computation effort is for running the code implemented in Matlab on a 3.2 GHz dual processor
core with 4 GB RAM. When comparing the collected reward as a measure of performance, y-axis
represent the mutual information (submodular reward function) collected by making observations
at the selected locations.

735

5

10

10

Recursive
greedy

4

10

Collected Reward

Execution Time (seconds)

S INGH , K RAUSE , G UESTRIN & K AISER

3

10

2

10

eMIP

1

10

0

10
60

Recursive
greedy

8

6

eMIP

4
60

80
100 120 140 160
Cost of output path (meters)

80

100

120

140

160

Cost of output path (meters)

(a) Comparison of computation effort

(b) Comparison of collected reward

Figure 11: Comparison of eMIP and recursive-greedy on a subset of Berkeley temperature dataset with 23 sensing

5

15

10

No sub−approximation
Sub−approx: 10%

No sub−approximation
Collected Reward

Execution Time (seconds)

locations.

Sub−approx: 10%

Sub−approx: 20%
Best Possible 20
subproblems

0

10
200

250

300

350

400

Sub−approx: 20%

10

5

Best possible 20
subproblems
0
200

450

250

300

Uniform density

350

400

450

Cost of output path(meters)

Cost of output path(meters)

(a) Comparison of computation effort

(b) Comparison of collected reward

Figure 12: Comparison of computation effort and collected reward for several sub-approximation heuristics used to
improve the running time of eMIP on lake temperature dataset. Significant improvement in execution time was observed,
particularly for longer paths, without significant reduction in collected reward.

8.2.1 C OMPARISON WITH R ECURSIVE - GREEDY A LGORITHM :
To compare the performance of our approach with the recursive-greedy algorithm, as proposed by
Chekuri et al., we selected a subset of 23 locations from the total of 52 locations from the Berkeley
temperature dataset. A small subset of locations was selected since the running time of recursivegreedy is quasi-polynomial and was very large for the complete dataset. Fig. 11a and Fig. 11b
display the comparison in the computation effort and collected reward on this smaller dataset for
the two algorithms. As is evident from the plots, our approach provides significant improvement in
running time (of several orders of magnitude at higher budget values) with (almost) the same collected reward. Since the recursive greedy algorithm is essentially a search procedure with greedily
restricted search space, this result also indicates that an exhaustive search over all paths is intractable
for even a small real world sensing problem. The sudden jump in execution time of eMIP in Fig. 11a
at budget = 100 meters is due to an additional iteration step (c.f., Line 7 in Algorithm 3) added due
to the increase in the input budget constraint. Thereafter, additional increase in budget only results in increase in experimental budget. Since the recursive-eSIP computes efficiently for such a
small problem, additional increase in experimental budget does not increase the computation effort
significantly.

736

E FFICIENT I NFORMATIVE S ENSING USING M ULTIPLE ROBOTS

300

Distance (meters)

250

Lake Boundary
Starting
Location

200
Cells
150

eMIP Path

100
50
0
0

Possible observation
locations
50

100
150
200
Distance (meters)

250

300

Figure 13: Illustration of a path selected using eMIP on lake temperature dataset.
8.2.2 C OMPARISON WITH U NIFORM S AMPLE S PACING :
We compared the performance of eMIP with a simple uniform sample spacing algorithm, referred
to as Uniform density. For the case of Uniform density, starting and finishing at given locations,
we greedily select two observation locations within each of the nearest cells and compute the corresponding path cost and path reward. Uniform density algorithm will output the best possible path
amongst all possible simple uniform sample spacing algorithms due to greedy observation selection
within each cell. Fig. 12b, compares the collected reward for Uniform density with eMIP for the
lake temperature dataset. Increased collected reward by eMIP, compared to Uniform density, empirically justifies the complexity of eMIP. Additionally, eMIP also provides a strong approximation
guarantee which is not possible for any uniform sample spacing algorithm. Fig. 13 illustrates a
path selected by eMIP for the lake temperature dataset, demonstrating that eMIP does not tend to
cause uniform sample spacing. For a few of the traversed cells, there was no location selected for
observation, while for others as many as three observation locations were selected from within the
cell.
8.2.3 C OMPARISON OF S UB - APPROXIMATION H EURISTICS :
Various sub-approximation heuristics discussed in Section 7 were compared empirically to analyze
their utility in improving the execution time and the corresponding reduction in collected reward,
if any. As is displayed in Fig. 12a that compares these heuristics for computation effort, each of
these sub-approximation heuristic provides improvement in the execution time over the scenario
when all branch and bound heuristics other than sub-approximation heuristics were used. The most
improvement at higher values of input budget was observed when the lower bound is increased by
a factor of α(= 1.2 or 20%). Fig. 12b displays the corresponding comparison of these heuristics
for collected reward. It was interesting to observe that none of the sub-approximation approaches
resulted in considerable reduction in collected reward.

737

5

10

8

Cost = 1.12

4

Cost = 0.56
Collected Reward

Execution Time (seconds)

S INGH , K RAUSE , G UESTRIN & K AISER

Cost = 0.84

10

Cost = 0.56

3

10

Cost = 1.4
2

10
15

20
25
Cost of output path (meters)

Cost = 0.84
6
Cost = 1.12
5

5

14

Collected Reward

Linear variation
4

Exponential variation
from both ends

3

10

30

Exponential variation
from both ends

12

Linear variation
10

8

Exponential increase from 0
2

10
200

Exponential variation from 0
250

300

350

400

6
200

450

250

300

350

400

450

Cost of output path(meters)

Cost of output path(meters)

(c) Computation effort with variation in experimental
budget split using lake temperature dataset

(d) Collected reward with variation in experimental budget split using lake temperature dataset

5

10

20

Grid: 20 cells
4

Collected Reward

Execution Time (seconds)

20
25
Cost of output path (meters)

(b) Collected reward with variation in sensing cost using
precipitation dataset

10

10

Cost = 1.4

4
3
15

30

(a) Computation effort with variation in sensing cost using precipitation dataset

Execution Time (seconds)

7

Grid: 14 cells

10

3

10

2

10

Grid: 22 cells

0

Grid: 22 cells

10

Grid: 20 cells

5

Grid: 33 cells

1

10

Grid: 14 cells
15

200

400

600

0
0

800

Grid: 33 cells
200

400

600

800

Cost of output path(meters)

Cost of output path(meters)

(e) Computation effort with variation in grid size for
spatial decomposition using lake temperature dataset

(f) Collected reward with variation in grid size for spatial decomposition using lake temperature dataset

Figure 14: Comparison of collected reward and computation effort with variation in several approaches used in eMIP.

738

E FFICIENT I NFORMATIVE S ENSING USING M ULTIPLE ROBOTS

8.2.4 VARIATION IN S ENSING C OST:
Fig. 14a and Fig. 14b compare the computation effort and collected reward as the sensing cost is
varied for the precipitation dataset. With the reduction in experimental cost, more locations were
observed for the same total input budget resulting in increased collected reward. However, for each
of the experiments, the computation effort was approximately the same. Due to the diversity in
environmental applications, the sensing cost will depend on the sensors (settling time) and the scale
of dynamics occurring in the observed phenomena. This experiment indicates that eMIP can be used
over a diverse range of sensing costs, as per the demands of diverse environmental applications.
8.2.5 VARIATION IN E XPERIMENTAL B UDGET S PLIT:
As discussed in Section 6, the strategy of exponentially increasing the experimental budget split
results in an increased additional path length required to guarantee the approximation factor for
the collected reward. We performed several experiments with the available datasets to analyze the
empirical performance of increasing the budget splits exponentially. Fig. 14c and Fig. 14d compares
the computation effort and collected reward for linear increase, one sided exponential variation
from 0 and two-sided exponential variation from both 0 and budget B for the lake temperature
dataset. Since a smaller number of budget splits are considered in recursive-eSIP in the case of an
exponential increase, the computation effort will be smaller as compared to the linear increase in
the budget splits. Interestingly, there was very small reduction in collected reward, for only a few
budget values, when the exponential increase was employed. Hence, even though the theoretical
approximation guarantee with exponential increase in experimental budget is weaker, empirically
the collected reward for both the linear and exponential increase in budget splits was found to be
comparable over a wide range of input budgets.
8.2.6 A NALYSIS OF S PATIAL D ECOMPOSITION :
As discussed in Section 6, the conversion of an SD-MIPP solution (a cell path) into a solution for
MIPP (a path over observation locations) will result in additional path length exceeding the input
budget B. This additional path length will depend on the size of the cell (or size of the grid covering
the complete spatial domain) in SD-MIPP problem and will result in trade-off with the computation
effort. Variation in grid-size will result in corresponding variation in the traveling cost between the
neighboring cells. This will result in an opportunity to travel more cells for a denser grid with the
same input budget constraint. However, to keep the experimental cost constant across the varying
grid size (since the experiment cost only depends on observed phenomena and is independent of
the spatial decomposition), it was scaled accordingly, in proportion to the traveling cost between
the neighboring cells. Fig. 14f compares the collected reward for varying grid sizes on the lake
temperature dataset, changing the grid size from 14 to 33 cells. It is interesting to observe that such
a change in grid size had (almost) negligible effect on the collected reward. On the other hand,
such increase in grid density resulted in a larger number of cells over which path planning is to be
performed thus leading to increased computation effort for the same input budget. The comparison
of the computation effort for the varying grid size is displayed in Fig. 14e. Note the drastic increase
in computation time as the grid discretization is made finer.

739

16

20

3 Robots

Total RMS Error

Total Collected Reward

S INGH , K RAUSE , G UESTRIN & K AISER

15

2 Robots
10

14
2 Robots

12
3 Robots

10

1 Robot
5
200

250

300

350

400

8
200
250
300
350
400
450
Average cost of output path per robot (meters)

450

Average cost of output path per robot (meters)

(a) Collected reward for same starting location

(b) RMS error for same starting location
15

25

3 Robots

Total RMS Error

Total Collected Reward

1 Robot

20

2 Robots
15

Single Robot
10
5
200

250

300

350

5

2 Robots

3 Robots

0
250
300
350
400
450
Average cost of output path per robot (meters)

400

Average cost of output path per robot (meters)

(c) Collected reward for different starting location

Start 3

10

1 Robot

(d) RMS error for different starting location

Boundary

Cells

1

33

Start 2

73

Start 1

Robot-2
Robot-1

Robot-3

(e) Paths selected using MIPP

Figure 15: Analysis of experiments performed for multiple robots with different (optimized) starting location using the
lake temperature dataset.

8.2.7 M ULTI - ROBOT E XPERIMENTS
We evaluated the performance of our eMIP multi-robot algorithm in simulation using several sensing datasets. Fig. 15 displays the empirical analysis of several experiments using the lake temperature dataset. The first experiment was performed with each robot starting from the same starting
location. Fig. 15a and Fig. 15b display the collected reward and root mean square (RMS) error
when the number of robots were varied from one to three. Due to the sequential-allocation ap-

740

E FFICIENT I NFORMATIVE S ENSING USING M ULTIPLE ROBOTS

proach (wherein we remove the locations that are already selected before selecting the locations for
the next robot) and “information never hurts” principle, collected reward increases as the number
of robots were increased and hence the corresponding root mean square error for prediction at the
unobserved locations gets reduced. However, the incremental change in performance from one to
two robots was larger than the incremental change from two to three robots, which is expected from
the submodularity (diminishing returns) property of mutual information.
Fig. 15c and Fig. 15d display the collected reward and RMS error when a different starting location is chosen for each robot. In this scenario, a set of four starting locations is pre-determined
with each location at one end of the lake (see for reference Fig. 15e where three of the four starting
locations are marked). The starting location for each of the three robots was selected greedily based
on the collected information. With a different starting location selected on the opposite end of the
lake for the second robot, the incremental change in collected reward (and corresponding decrease
in root mean square error) as the number of robots was increased from one to two is much higher
than the corresponding change when the same starting location was chosen for the second robot
as well. However, similar to the scenario with same starting location, the incremental change as
the number of robots was increased from one to two is higher as compared to when the number
of robots was increased from two to three (due to submodularity of mutual information). Fig. 15e
illustrates the selected paths for each of the three robots as selected using eMIP.

9. Related Work
There is a large body of related work both in the theory of path planning and its applications. Approximation algorithms have been proposed for several related problems. Variants of path planning
have been studied in the field of Operations Research as the Traveling Salesman Problem (TSP)
or the Vehicle Routing Problem (VRP). In robotics, several path planning approaches have been
studied for applications such as Simultaneous Localization and Mapping (SLAM) and search and
exploration. In sensor networks and geostatistics, a closely related work studies optimal placement
of static sensors modeling the phenomenon as Gaussian Processes. Several adaptive sampling approaches have been studied to decide on the subset of locations to observe in order to understand the
phenomenon dynamics effectively. In addition, similar approaches are explored for planning paths
for mobile robots acting as data mules, collecting data sampled by the network of static sensors.
9.1 Operations Research
An interesting special case of the MIPP problem is given in the case where each node has a fixed
reward, and the goal is to find a path that maximizes the sum of these rewards (Traveling Salesman
Problem with Profits, TSPP, Feillet et al., 2005). Such a sum of rewards is a modular (additive)
function, which is a special case of submodular functions. A subcategory of TSPP is an optimization problem defined to maximize the collected reward while keeping the associated cost less than
some given budget B. This was studied as Orienteering Problem (OP) or selective TSP (Laporte &
Martello, 1990), or Maximum Collection Problem (Kataoka & Morito, 1988) in the literature. The
additivity assumption made in the orienteering problem is very unrealistic in our informative path
planning setting, as it assumes that the information provided by adjacent locations is independent,
whereas we would typically expect a strong amount of correlation. In fact, if the observations were
all independent, there would be no point in selecting observations for spatial prediction. In this

741

S INGH , K RAUSE , G UESTRIN & K AISER

paper, we hence study the more general orienteering problem with submodular reward functions,
proposed earlier as Submodular Orienteering Problem (Chekuri & Pal, 2005).
9.1.1 M ULTIPLE - PATH E XTENSIONS :
The extension of TSPP to multiple paths was studied as Vehicle Routing Problem with Profits
(VRPP) in the literature. Like TSPP, several variants of VRPP have been previously considered.
The Prize Collecting VRP (PCVRP) (Tang & Wang, 2006) is a class of VRPP where the objective is to determine a subset of all customers to visit so as to minimize the total distance traveled,
minimize the vehicles used and maximize the collected reward. The multi-robot version of the OP
(in the case of additive reward functions) was studied as the Team Orienteering Problem by I-Ming
et al. (1996) and Multiple Tour Maximum Collection Problem by Butt and Ryan (1999).
9.1.2 K NOWN A PPROXIMATIONS FOR THE O RIENTEERING P ROBLEM :
The OP is known to be NP-hard (Golden et al., 1987). Several versions of the OP studied in the
literature can be classified into those for which the starting (and the finishing) location (root) is
pre-specified or not. For the case of the unrooted OP (when no starting location is specified), the approximation guarantees known for Prize Collecting TSP and k-TSP can be easily extended (Johnson
et al., 2000). There are several constant factor approximations known for the PC-TSP and k-TSP
problems with the best one being a 2 approximation (Garg, 2005). However the same extension does
not apply for the rooted version of the problem as the best path for the unrooted version may not
contain the root and may be far away from the root thus leading to violation of the budget constraint.
For the rooted OP, Arkin et al. (1998) gave a (2 + ) approximation for the OP in geometric
settings. Blum et al. (2003) gave the first constant factor approximation for the rooted OP in general
undirected graphs. They also extended their algorithm for multi-path OP. The running time of their
algorithm, though polynomial, is very large (more specifically, O(πn5 log( 1 )) where π is the total
reward in the path). Recently Chekuri et al. (2008) gave a polynomial time algorithm for the OP in
undirected graphs with an improved approximation guarantee of (2 + ). Our problem formulation
with specified starting location (s) and finishing location (t) falls under the category of rooted OP
with submodular (non-additive) reward function.
Another classification of OP can be done based on the symmetry of the space of the possible
locations. All of the above approximation guarantees hold true on symmetric spaces (undirected
graphs). Obtaining good approximation algorithm for the directed (asymmetric) orienteering problem was stated as an open problem by Blum et al. (2003). Chekuri and Pal (2005) gave the first
approximation algorithm with O(log n) guarantee that runs in quasi-polynomial running time. The
running time was recently improved independently by two different works (Chekuri et al., 2008;
Nagarajan & Ravi, 2007), each proposing a poly-time approximation algorithm providing an approximation guarantee of O(log2 n), though using different approaches. The metric space conversion procedure used during our spatial decomposition approach limits eMIP to symmetric spaces
only.
9.1.3 S EQUENTIAL A LLOCATION :
Blum et al. (2003) proposed a sequential allocation approach to extend algorithms for single-robot
orienteering to the multiple robot setting, but only for the special case of additive (modular) reward
functions. In this paper, we generalize their result to submodular reward functions. After the initial
742

E FFICIENT I NFORMATIVE S ENSING USING M ULTIPLE ROBOTS

version of this paper was published (Singh et al., 2007b), we realized that our sequential-allocation
procedure is an instance of maximizing a submodular function subject to a matroid constraint (Calinescu et al., 2007). We can define a partition matroid on the disjoint union M = M1 ∪ · · · ∪ Mk
of k ground sets Mi , one for each robot. Each set Mi contains all feasible paths for robot i. The
collection I ⊆ 2M of all subsets P ∈ I such that |P ∩ Mi | ≤ 1 (i.e. each P corresponds to
a collection of paths, with the constraint that we can pick at most one from each set Mi ) forms
independent sets of the partition matroid. Hence, the problem of finding a collection of maximally
informative paths is the problem of finding an independent set of a matroid maximizing a submodular function. Current work in progress by Goundan and Schulz (2008) provides general results on
the performance of a sequential allocation procedure in such a setting, which can be used to prove
the same sequential allocation results originally presented by Singh et al. (2007b).
9.2 Robotic Applications
There is considerable work in path planning in the robotics community for several applications,
including simultaneous localization and mapping (SLAM) and search and exploration. Several
different approaches have been studied for each of these applications, including auction based algorithms, data-adaptive approaches and information gain based algorithms.
9.2.1 S IMULTANEOUS L OCALIZATION AND M APPING :
The goal of Simultaneous Localization And Mapping (SLAM) is to build maps of an environment
by performing an exploration of the environment with an objective to estimate the robot position
and world features simultaneously. Several approaches optimizing different objective functions had
been proposed to perform path planning for SLAM. Bourgault et al. (2002) proposed an exploration
framework using an occupancy grid (OG) environment model (performing spatial decomposition of
the observed environment) with an objective to maximize mutual information over the OG map.
Stachniss et al. (2005) developed a greedy algorithm for selecting the next location to visit to
maximize information gain about the map.
In contrast to such approaches, Sim and Roy (2005) attempted to optimize the entire trajectory, not just the next step, but their algorithm introduces some approximations without theoretical bounds. Simmons et al. (2000) proposed a distributed approach for exploration and mapping
with multiple robots by minimizing the overlap in information gain amongst multiple robots. They
provided quantitative results from simulation but did not provide any theoretical bounds for their
approach. There is little work in SLAM setting with an upper bound on the total cost of the path. In
addition, we are not aware of any approaches to SLAM which carry approximation guarantees for
either the single or multi-robot cases. An interesting direction for future work would be to analyze
the applicability of our approach to the SLAM setting.
9.2.2 S EARCH AND E XPLORATION :
The search and exploration application involves path planning for a robot with the goal of searching
for a moving target(s) in a given environment, e.g. target surveillance in security applications and
patient tracking in health care domain. Performing path planning using stochastic inference provides
advantage of robustness to sensing and motion uncertainty though with an added complexity of computational intractability. Roy and Earnest (2006) proposed an approach to effectively compute the
trajectories for target tracking based on maximizing mutual information (evaluated using the change
743

S INGH , K RAUSE , G UESTRIN & K AISER

in variance of the probability distribution). They used a particle filter approach, performing clustering over the particles followed by path planning over these clusters. Lau et al. (2006) formulated the
target tracking in indoor environments as a generalization of an NP-complete optimal searcher path
(OSP) problem (Trummel & Weisinger, 1986). They sought to optimize the probability of detection
within a given time horizon while accounting for the undetected target probability that is a function
of previously visited locations during the search. They used several branch and bound approaches
to speed up the search process. The objective of maximizing information gain subject to the budget
constraints on the path cost makes eMIP a suitable candidate for performing path planning for such
problems.
Ryan (2008) used an approach of partitioning the search space into subgraphs for multi-robot
path planning. We take a conceptually similar approach, also reducing the search space by decomposing the space into regions and then performing path planning over those regions. However, we
address more complex utility functions, such as quantifying the informativeness of visited locations
and are not limited to specific graph structures such as stacks, halls, cliques, rings as is the case in
the work of Ryan (2008). Recently, Thompson and Wettergreen (2008) used our eMIP algorithm
for near-term path planning while performing autonomous exploration of surficial units at Amboy
Crater in Mojave desert, California.
9.2.3 P LANNING S YSTEMS AND A PPLICATIONS :
Certain applications in robotic path planning used plan graphs (Blum & Furst, 1997) to compute
an estimate of the resources and time required to achieve goals from states encountered in the
search process. In the case of over-subscription planning problem – wherein only a subset of goals
that can be accomplished within the limited time or resources available for the planning system,
the work by Smith (2004) used an orienteering heuristic to provide an ordered set of goals to be
considered by the planner. Briel et al. (2004) proposed several heuristics for efficiently solving
the over-subscription planning problem. However, in each of the earlier proposed heuristics, the
reward function considered is modular (additive). eMIP can be used to efficiently solve the oversubscription planning problem in the submodular setting with strong approximation guarantees.
9.3 Sensor Networks
Phenomenon modeling to decide on the optimal placement of a set of static sensors is well studied
in the sensor networks and geostatistics communities. Gaussian Process models for spatial phenomena had been studied extensively (Cressie, 1991). Guestrin et al. (2005) proved that, in the case
of phenomena governed by Gaussian Process models, selecting the placement of sensors greedily
based on mutual information is near-optimal. Krause et al. (2006) extended this work to include
communication cost between sensors while optimizing the sensor placement. In the communication constrained setting, similar to the path planning problem considered in this paper, the greedy
algorithm performs badly, and more involved algorithms have to be developed. Batalin et al. (2004)
showed that combining the static and mobile sensing devices, even in a simple scenario, can result
in significant improvement in sensing performance. In such a scenario, where a combination of
static and mobile sensing devices are available, several approaches for optimal placement of static
sensors can be combined with eMIP to observe a given phenomenon efficiently.

744

E FFICIENT I NFORMATIVE S ENSING USING M ULTIPLE ROBOTS

9.3.1 DATA C OLLECTION FROM A S ENSOR N ETWORK :
A different scenario where a mobile robot can be combined with a network of static sensors is to
improve the lifetime of the sensor network by performing the tours for collecting the data sampled
by the static network. Somasundara et al. (2007) showed that the problem of collecting the data
when the environment shows both spatial and temporal dynamics is NP-complete and provided an
integer linear programming formulation for the same. They compared the performance of several
heuristics in simulation for both single and multi-robot scenario. Meliou et al. (2007) proposed a
nonmyopic approach for the application of data gathering tours using an algorithm for submodular
orienteering (SOP) as a black box. They provided strong approximation guarantees and extensive
empirical evaluation that indicates the applicability of their approach for such applications. In this
setting, eMIP can be used as an orienteering algorithm to provide a better approximation guarantee
in addition to improved running time.
9.3.2 A DAPTIVE S AMPLING FOR E NVIRONMENTAL A PPLICATIONS :
Recent advances in robotics have opened up opportunities for high fidelity monitoring of dynamic
environmental sensing applications. Rahimi et al. (2004) explored several policies for adaptively
sampling the environment. Singh et al. (2006) proposed a multiscale adaptive sampling approach
with uniformly sampling the environment in the first stage followed by sampling at locations in order
to minimize the mean square error the most. They also extended their approach for multiple robots,
although without providing any theoretical bounds. Using several in-field experiments as well as
simulations using real world sensing datasets, we demonstrate here that several such environmental
phenomenon can be effectively sampled adaptively using eMIP.

10. Conclusions and Future Work
In this paper, we presented eSIP, an approximation algorithm for efficient planning of informative
paths. eSIP near-optimally solves the NP-hard problem of maximizing the collected information
with an upper bound on path-cost. Our eSIP algorithm builds on the recursive-greedy algorithm of
Chekuri and Pal (2005). eSIP preserves the approximation guarantees of recursive-greedy, while
overcoming its computational intractability through spatial-decomposition and several branch and
bound approaches. We also presented a general approach, sequential-allocation, which extends any
single-robot algorithm, such as eSIP, to the multiple-robot setting while providing a provably strong
approximation guarantee.
We also provide extensive empirical evaluation to demonstrate the effectiveness of our approach
for real world sensing applications. We performed several in-field experiments for two important
environmental sensing applications – lake monitoring (at a small lake at UC Merced campus) and
river monitoring (at San Joaquin river, California). The Networked Info Mechanical System (NIMS)
was used as the robotic system for performing path planning during each of these deployments to
demonstrate the practicality of our algorithm. We also performed extensive simulation experiments
using several real world sensor network data sets. With global climate change and corresponding
impetus on sustainable practices, we expect that such efficient path planning approaches can help
address the challenge of monitoring environment-related activities effectively.
In the future, we plan to explore the applicability of our algorithm in other application domains
such as SLAM and search and rescue. We plan to work towards understanding the limitations of

745

S INGH , K RAUSE , G UESTRIN & K AISER

learning a static GP model in real world scenarios, and extend our approach for online model adaptation.

Acknowledgments
We would like to thank Maxim Batalin for helpful discussions, Bin Zhang for providing the lake
data set and Michael Stealey, Henry Pai and Victor Chen for help during the river and lake deployment. This work was partially supported by NSF Grants No. CNS-0509383, CNS-0625518, CNS0331481, ANI-00331481, CCR-0120778, ECCS-0725441, ONR MURI W911NF0710287 and a
gift from Intel. Carlos Guestrin was partly supported by an Alfred P. Sloan Fellowship and an IBM
Faculty Fellowship. Andreas Krause was partially supported by a Microsoft Research Graduate
Fellowship.

APPENDIX
Theorem-1. Let η be the approximation guarantee for the single path instance of the informative
path planning problem. Then our sequential-allocation algorithm achieves an approximation guarantee of (1 + η) for the MIPP problem. In the special case, where all robots have the same starting
(si = sj , ∀i, j) and finishing locations (ti = tj , ∀i, j), the approximation guarantee improves to
1/(1 − exp (−1/η)) ≤ 1 + η.
Proof of Theorem 1. For the case when all the robots start and finish at the same location, let Π
be the total reward collected by the optimal solution. Additionally, define Πi to be the difference
between the reward collected by the optimal solution, and by the approximation algorithm, at the
end of stage i. Hence, Π0 = Π.
Let Ai = P1 ∪ · · · ∪ Pi be the nodes selected by the approximation algorithm up to stage i
(A0 = ∅), and let P ∗ = {P1∗ , . . . , Pk∗ } denote the collection of paths chosen in the optimal solution.
) − f (Ai ) = Πi
Consider the residual reward fAi . We find fAi (P ∗ ) = f (Ai ∪ P ∗ ) − f (Ai ) ≥ f (P ∗ P
due to monotonicity of f . If there were no path Pj∗ with fAi (Pj∗ ) ≥ k1 Πi , then j fAi (Pj∗ ) <
Πi = fAi (P ∗ ), contradicting the monotonic submodularity of fAi . Hence there is such a path Pj∗
with fAi (Pj∗ ) ≥ k1 Πi , and thus the approximation algorithm is guaranteed to find a path Pi such
1
that fAi (Pi ) ≥ ηk
Πi .
The difference in the reward collected by the optimal solution and the reward collected by
Algorithm 1 after stage i + 1 is at most:
Πi+1 ≤ (1 − 1/ηk)Πi ,
≤ (1 − 1/ηk)i+1 Π.
Thus after k stages, the difference in the reward is bounded by Πk ≤ (1−1/ηk)k Π ≤ exp (−1/η)Π.
Hence, the reward collect by Algorithm 1 is at least (1 − exp (−1/η)) times the optimal reward,
resulting in approximation factor of 1/(1 − exp (−1/η)).
For the case when each robot has different starting and finishing location, let Pi∗ be the set
of nodes visited by the optimal path at stage i. Let Oi be the set of nodes visited by the optimal
path until stage i, i.e., Oi = ∪ij=1 Pj∗ , with O0 = ∅ and O1 = P1∗ . The reward collected by the
746

E FFICIENT I NFORMATIVE S ENSING USING M ULTIPLE ROBOTS

approximation algorithm at stage i can be bounded as:
fAi−1 (Pi ) ≥ 1/η(fAi−1 (Pi∗ )).
After k stages, the total collected reward can be given as:
k
X

k
X
fAi−1 (Pi ) ≥ 1/η(
fAi−1 (Pi∗ )).

i=1

(4)

i=1

Since the left hand side is a telescopic sum, we get:
k
X

fAi−1 (Pi ) = f (∪ki=1 Pi ) = f (Ak ).

(5)

i=1

On the right hand side (RHS):
k
X
R.H.S. = 1/η(
fAi−1 (Pi∗ )),
i=1
k
X
= 1/η( (f (Pi∗ ∪ Ai−1 ) − f (Ai−1 ))).
i=1

Adding Oi−1 to both the terms and using the submodularity property, we get
k
X
R.H.S. ≥ 1/η( (f (Oi ∪ Ai−1 ) − f (Oi−1 ∪ Ai−1 ))),
i=1

= 1/η [f (O1 ) − 0 + f (O2 ∪ A1 ) − f (O1 ∪ A1 ) + · · · + f (Ok ∪ Ak−1 ) − f (Ok−1 ∪ Ak−1 )] .
Rearranging the terms, we get:
"
R.H.S. ≥ 1/η f (Ok ∪ Ak−1 ) −

k−1
X

#
(f (Oi ∪ Ai ) − f (Oi ∪ Ai−1 )) .

i=1

Using the monotonicity (f (Ok ∪ Ak−1 ) ≥ f (Ok )) and submodularity of f ( f (Oi ∪ Ai ) − f (Oi ∪
Ai−1 ) ≤ f (Ai ) − f (Ai−1 )), we get
"
#
k−1
X
R.H.S. ≥ 1/η f (Ok ) −
(f (Ai ) − f (Ai−1 )) ,
i=1

= 1/η [f (Ok ) − f (Ak−1 )] .
Using the monotonicity (f (Ak ) ≥ f (Ak−1 )), we get
R.H.S. ≥ 1/η [f (Ok ) − f (Ak )] .
Substituting Equation (5) and (6) into Equation (4), we get:
f (Ak ) ≥ 1/η [f (Ok ) − f (Ak )] ,
747

(6)

S INGH , K RAUSE , G UESTRIN & K AISER

and thus:
f (Ak ) ≥ 1/(η + 1)f (Ok ).
resulting in an approximation guarantee of (1 + η).
The above theorem and proof is inspired by the proof of multi-path orienteering provided
by Blum et al. (2003).
Lemma 3. Let P ∗ = (s = v0 , v1 , . . . , vl = t) be an optimal s-t-path solution to MIPP, constrained by budget B. Then there exists a corresponding SD-MIPP path PC∗ = (Cs = Ci1 , . . . , Cin =
√
Ct ), traversing through locations Ai1 ∪ · · · ∪ Ail , with budget Be of at most 2 2B + 4L collecting
the same information.
Proof of Lemma 3. Let P ∗ be the optimal path for MIPP, constrained by budget B. We need to ensure that when MIPP is transformed into SD-MIPP, with PC∗ as the corresponding optimal solution,
we have enough budget such that PC∗ is feasible in the new problem domain. To recall, for the
new problem domain, SD-MIPP, traveling to a new cell costs L (distance between the centroids of
adjacent cells), irrespective of the sensing location within the cell.

L

1

2

4

3

5
6

Figure 16: Illustration for the increased budget requirement for SD-MIPP.
For the corresponding SD-MIPP, an optimal path may just make 4 experiments in 4 different
cells (Cells 1,2,3 and 4 in Fig. 16) sharing a common vertex, with each sensing location in different
cell close to the common vertex, while only requiring an infinitesimally small traveling cost. Increasing the budget by 4L accounts for this case. Furthermore, by paying only an additional cost
L for traveling between the two corners of an edge of a cell, PC∗ can make experiments at 2 new
cells (Cells 5,6 in Fig. 16. Thus, the total number of cells visited by the PC∗ is upper bounded by
2(B/L) + 4. Hence, a budget of 2B + 4L suffices to render PC∗ a feasible SD-MIPP solution. Now
to convert MIPP from the two-dimensional
Euclidean distance into the corresponding L1 distance,
√
the budget needs to be increased to 2B to ensure that P ∗ is feasible in the L1 metric. Accounting
for the conversion from Euclidean distance into L1 , the total budget B̃ required
for SD-MIPP, to
√
ensure the feasibility of the optimal solution in MIPP, is upper bounded by 2 2B + 4L.
Lemma 4. Let PC∗ = (Cs = C1 , . . . , Ck = Ct ) be an optimal solution for single robot instance
e where an optimal set of locations are selected within each
of SD-MIPP, constrained by budget B,
b
b ≥ 1−1/e I(P ∗ ).
visited cell Cj . Let P be the solution returned for eSIP. Then I(P)
C
1+log k
2

Proof of Lemma 4. We will prove this by induction on the length n of the optimal path. Let Fg (=
(1 − 1/e)) be the constant factor due to the greedy selection of sensing locations within each cell.
748

E FFICIENT I NFORMATIVE S ENSING USING M ULTIPLE ROBOTS

Also assume Be be the budget constraint for SD-MIPP problem. For the case n = 1, iter = 0
and Algorithm 4 will select the greedy subset of nodes from the set Cs = Ct . This will give an
approximation guarantee of Fg (Krause et al., 2008) compared to the optimal set of the same number
of observations selected in this cell (and hence of the information obtained by the optimal SD-MIPP
path visiting only this cell).
Now, assuming the induction hypothesis holds for n = k/2, we get:
Fg
IX (P ∗ ),
(1 + log(k/2))
Fg
≥
IX (P ∗ ).
log k

IX (P) ≥

This will hold true for traveling budget of Bek/2 and experimental budget up to Be − Bek/2 . Let us
now analyze the case n = k. Let P1∗ be the optimal path from Cs to Ck/2 constrained by budget B 0 .
Since we increase the experimental budget split linearly, B 0 will vary from 0 to Be − Bek , where Bek is
the traveling cost for visiting k cells. Since this cost will be less than Be − Bek/2 , using the induction
hypothesis,
Fg
IX (P1∗ ).
(7)
IX (P1 ) ≥
log k
Similarly, with X 0 = X ∪ P1 following approximation guarantee holds true for P2 :
IX 0 (P2 ) ≥

Fg
IX 0 (P2∗ ).
log k

By definition of our submodular function:
IX 0 (P2∗ ) = I(P2∗ ∪ P1 ∪ X) − I(P1 ∪ X),
= IX (P1 ∪ P2∗ ) − IX (P1 ).
Substituting in (8), we get
IX 0 (P2 ) ≥

Fg
(IX (P1 ∪ P2∗ ) − IX (P1 )).
log k

Using monotonicity of I,
IX 0 (P2 ) ≥

Fg
(IX (P2∗ ) − IX (P)).
log k

Adding this to (7), we finally get:
Fg
(IX (P1∗ ) + IX (P2∗ ) − IX (P)),
log k
(Fg + log k) IX (P) ≥ Fg (IX (P1∗ ) + IX (P2∗ )),
IX (P) ≥

(1 + log k) IX (P) ≥ Fg (IX (P1∗ ) + IX (P2∗ )).
Since IX is a submodular function,
(1 + log k) IX (P) ≥ Fg (IX (P ∗ )),
Fg
(IX (P ∗ )).
IX (P) ≥
1 + log k

749

(8)

S INGH , K RAUSE , G UESTRIN & K AISER

The above proof is inspired by the analysis of the recursive greedy algorithm for submodular
orienteering proposed by Chekuri and Pal (2005).
In the case of exponential budget splits, the budget needs to be increased, albeit sub-linearly:
Lemma 7. Let PC∗ = (Cs = Ci1 , . . . , CiN = Ct ) be an optimal SD-MIPP solution constrained
e Let P be the solution returned by eMIP with exponential splits of the experimental
by budget B.
3
e Then I(P) ≥ 1−1/e I(P ∗ ).
budget, started with increased budget N log2 2 B.
C
1+log N
Proof of Lemma 7. The set of paths which eMIP considers under exponential splits – let us call
them exponential paths – is in general a strict subset of the linear paths considered under linear
splits. The proof of Lemma 4 indeed shows that the path returned by eMIP achieves at most a factor
1−1/e
1+log N less information than the optimal exponential path. We need to show that increasing the
3
budget by a factor of N log2 2 Be guarantees that the optimal linear path is a feasible exponential path.
Every exponential path can be represented by a complete binary tree, whereby every internal node at
a given level in the tree corresponds to a choice of middle node and experimental budget allocation
to the left and right sub-path at the corresponding recursion level. Further, every leaf in the tree
corresponds to a set of observations selected in a visited cell. Consider the tree T ∗ representing the
e At each inner node, the restriction to exponential splits can lead to
optimal linear path with budget B.
a situation, where either the left or right sub-path receives less experimental budget than allocated
by the optimal path. Our proof strategy is to turn T ∗ into a new tree T 0 , which selects the same
observations and corresponds to a valid exponential path. In order to achieve this, we will annotate
each inner node v, which receives Bv experimental budget in the optimal linear allocation, by a
new feasible exponential budget Bv0 ≥ Bv . It then suffices to show that for the root R it holds that
0 ≤ (n)log2 3/2 B = (3/2)log2 n B . Label the edges of T ∗ with 0 and 1, such that the sub-path
BR
R
R
corresponding to the edge labeled with 1 receives the smaller part of the linear budget split. Hence,
e
a leaf v on a path with k ones receives at most Bv ≤ (1/2)k of the total linear budget requirement B.
m
0
0
Let us derive the bounds Bv bottom up. We prove by induction that Bv ≤ (3/2) Bv where m is the
height of v (distance from the leaves). This will suffice the condition Br0 ≤ (3/2)log2 n Br , that we
want to prove. For the leaves v clearly Bv0 = Bv is sufficient, since no further split is done and hence
the reward collected by both linear and exponential split will be same. Let v be an inner node with
children l and r, where w.l.o.g., the left child l is annotated by 0. By construction, Br ≤ Bv /2. By
induction hypothesis, Bl0 ≤ (3/2)m−1 Bl , and Br0 ≤ (3/2)m−1 Br . If we choose Bv0 = Bl0 + 2Br0 ,
then we can find a feasible exponential budget split allocating at least Bl0 to l and Br0 to r. This
split will require increasing the budget exponentially till we suffice r and allocating the rest to l.
To ensure that we always have a budget split that suffice r with exponential budget irrespective
of whether it represents P1 or P2 , we need to do exponential splits from both sides, trying both
exponential increase from 0 (Bexp ) and Bv − Bexp for the cases when r represents P1 and P2
respectively. Now we have Bv0 ≤ (3/2)m−1 Bl + 2(3/2)m−1 Br = (3/2)m−1 Bv + (3/2)m−1 Br ≤
(3/2)m Bv .
Theorem 5. Let P ∗ be the optimal solution for the single robot instance of the MIPP problem
b achieving an information
with budget constraint B. Then, our eSIP algorithm will find a solution P
√
√
1−1/e
2
∗
b
) in
value of at least I(P) ≥ 1+log N I(P ), whose cost is no more than 2(2 2B + 4L)(1 + L Cexp
2
√
√
3
fe and no more than 2(2 2B + 4L)(1 + L 2 )N log2 2 in the
the case of linear budget split for B
Cexp

fe .
case of exponential budget split for B
750

E FFICIENT I NFORMATIVE S ENSING USING M ULTIPLE ROBOTS

Proof of Theorem 5. Let B̃ be the budget requirement for SD-MIPP according to Lemma 4 (or
Lemma 7 in the case of exponential splits) and P be the corresponding solution returned by eMIP.
Let Cexp be the cost of making an observation at each sensing location. Maximum number of
sensing locations visited by P will be CB̃
. Since we do not account for traveling to the sensing
exp
locations, an additional cost equivalent to traveling from the centroid of the visited cells to the
corresponding sensing location is to be paid when the solution from SD-MIPP is transformed
back to
√
get the solution for MIPP. For each sensing location, a maximum additional cost of L 2 is incurred
for traveling to the sensing location and returning back to the centroid, where L is the length of the
cell. Thus the additional cost for the
solution path for MIPP problem, transformed from SD-MIPP
√
2
problem is upper bounded by B̃L
Cexp . Since eMIP only considers exponential budget splits into
traveling and experimental budget, an increase of the budget by another factor of 2 guarantees that
the split defined by the optimal MIPP solution is feasible. Combining this analysis with Lemma 3
and Lemma 4 completes the proof.

References
Arkin, E. M., Mitchell, J. S. B., & Narasimhan, G. (1998). Resource-constrained geometric network
optimization. In Symposium on Computational Geometry, pp. 307–316.
Bai, X., Kumar, S., Xua, D., Yun, Z., & Lai, T. H. (2006). Deploying wireless sensors to achieve
both coverage and connectivity. In Proceedings of the 7th ACM international symposium on
Mobile ad hoc networking and computing, pp. 131–142.
Batalin, M. A., Rahimi, M., Yu, Y., Liu, D., Kansal, A., Sukhatme, G. S., Kaiser, W. J., Hansen, M.,
Pottie, G. J., Srivastava, M., & Estrin, D. (2004). Call and response: experiments in sampling
the environment. In Proceedings of the 2nd international conference on Embedded networked
sensor systems, pp. 25–38.
Blum, A., Chawla, S., Karger, D. R., Lane, T., Meyerson, A., & Minkoff, M. (2003). Approximation
algorithms for orienteering and discounted-reward tsp. In Annual Symposium on Foundation
of Computer Science (FOCS), p. 46.
Blum, A. L., & Furst, M. L. (1997). Fast planning through planning graph analysis. Artificial
Intelligence, 90, 1636–1642.
Borgstrom, P. H., Stealey, M. J., Batalin, M. A., & Kaiser, W. J. (2006). NIMS3D: A novel rapidly
deployable robot for 3-dimensional applications. In IEEE/RSJ International Conference on
Intelligent Robots and Systems, Beijing, China.
Bourgault, F., Makarenko, A., Williams, S., Grocholsky, B., & Durrant-Whyte, H. (2002). Information based adaptive robotic exploration. In IEEE/RSJ International Conference on Intelligent
Robots and Systems (IROS), pp. 540–545.
Brekke, L. D., Miller, N. L., Bashford, K. E., Quinn, N. W., & Dracup, J. A. (2004). Climate change
impacts uncertainty for water resources in the san joaquin river basin, california. Journal of
the American water resource association, 40, 149–164.
Briel, M. V. D., Sanchez, R., Do, M. B., & Kambhampati, S. (2004). Effective approaches for partial
satisfaction (over-subscription) planning. In In AAAI, pp. 562–569. AAAI Press.

751

S INGH , K RAUSE , G UESTRIN & K AISER

Butt, S. E., & Ryan, D. M. (1999). An optimal solution procedure for the multiple tour maximum
collection problem using column generation. Computers and Operations Research, 26, 427–
441.
Calinescu, G., Chekuri, C., Pl, M., & Vondrk, J. (2007). Maximizing a submodular set function subject to a matroid constraint (extended abstract). In Integer Programming and Combinatorial
Optimization (IPCO), Vol. 4513 of Lecture Notes in Computer Science, pp. 182–196.
Caselton, W., & Zidek, J. (1984). Optimal monitoring network design. Statistics and Probability
Letters.
Chao, I.-M., Golden, B. L., & Wasil, E. A. (1996). A fast and effective heuristic for the orienteering
problem. European Journal of Operations Research, 88, 475–489.
Chekuri, C., Korula, N., & Pál, M. (2008). Improved algorithms for orienteering and related problems. In Proc. 19th Annual ACM-SIAM Symposium on Discrete Algorithms (SODA’08).
SIAM. To appear.
Chekuri, C., & Pal, M. (2005). A recursive greedy algorithm for walks in directed graphs. In Annual
Symposium on Foundation of Computer Science (FOCS), pp. 245–253.
Christofides, N. (1976). Worst-case analysis of a new heuristic for the traveling salesman problem.
Tech report,CMU.
Cressie, N. A. C. (1991). Statistics for Spatial Data. Wiley.
Dhariwal, A., Zhang, B., Stauffer, B., Oberg, C., Sukhatme, G. S., Caron, D. A., & Requicha, A. A.
(2006). Networked aquatic microbial observing system. In IEEE International Conference
on Robotics and Automation (ICRA).
Feillet, D., Dejax, P., & Gendreau, M. (2005). Traveling salesman problem with profits. Transportation Science, 39(2), 188–205.
Garg, N. (2005). Saving an epsilon: a 2-approximation for the k-mst problem in graphs. In ACM
Symposium on Theory of Computing (STOC), pp. 396–402.
Golden, B., Levy, L., & Vohra, R. (1987). The orienteering problem. Naval Research Logistics, 34,
307–318.
Goundan, P. R., & Schulz, A. S. (2008). Revisiting the greedy approach to submodular set function
maximization.. Working paper, MIT.
Guestrin, C., Krause, A., & Singh, A. P. (2005). Near-optimal sensor placements in gaussian processes. In International Conference on Machine Learning (ICML).
Harmon, T. C., Ambrose, R. F., Gilbert, R. M., Fisher, J. C., Stealey, M., & Kaiser, W. J. (2007).
High-resolution river hydraulic and water quality characterization using rapidly deployable
networked infomechanical systems (NIMS RD). Environmental Engineering Science, 24(2),
151–159.
I-Ming, C., Golden, B., & Wasil, E. (1996). The team orienteering problem. European Journal of
Operation Research, 88, 464–474.
Ibaraki, T., Muro, S., Murakami, T., & Hasegawa, T. (1983). Using branch-and-bound algorithms to
obtain suboptimal solutions. Mathematical Methods of Operations Research, 27(1), 177–202.

752

E FFICIENT I NFORMATIVE S ENSING USING M ULTIPLE ROBOTS

Ishikawa, T., & Tanaka, M. (1993). Diurnal stratification and its effects on wind-induced currents
and water qualities in lake kasumigaura, japan. Journal of Hydraulic Research, 31(3), 307–
322.
Johnson, D. S., Minkoff, M., & Phillips, S. (2000). The prize collecting steiner tree problem: theory
and practice. In Symposium on Discrete Algorithms (SODA), pp. 760–769.
Jordan, B. L., Batalin, M. A., & Kaiser, W. J. (2007). NIMS RD: A rapidly deployable cable based
robot. In IEEE International Conference on Robotics and Automation (ICRA), Rome, Italy.
Kataoka, S., & Morito, S. (1988). An algorithm for the single constraint maximum collection
problem. Journal of the Operational Research Society of Japan, 31, 515–530.
Ko, C.-W., Lee, J., & Queyranne, M. (1995). An exact algorithm for maximum entropy sampling.
Operations Research, 43(4), 684–691.
Krause, A., & Guestrin, C. (2007). Near-optimal observation selection using submodular functions.
In AAAI Nectar track.
Krause, A., Singh, A., & Guestrin, C. (2008). Near-optimal sensor placements in Gaussian processes: Theory, efficient algorithms and empirical studies. In Journal of Machine Learning
and Research (JMLR), Vol. 9, pp. 235–284.
Krause, A., & Guestrin, C. (2007). Nonmyopic active learning of gaussian processes: an
exploration-exploitation approach. In International Conference on Machine Learning
(ICML), pp. 449–456.
Krause, A., Guestrin, C., Gupta, A., & Kleinberg, J. (2006). Near-optimal sensor placements: Maximizing information while minimizing communication cost. In Proceedings of the fifth international conference on Information processing in sensor networks (IPSN), pp. 2–10.
Laporte, G., & Martello, S. (1990). The selective travelling salesman problem. Discrete Applied
Mathematics, 26, 193–207.
Lau, H., Huang, S., & Dissanayake, G. (2006). Probabilistic search for a moving target in an
indoor environment. In IEEE/RSJ International Conference on Intelligent Robots and Systems
(IROS), pp. 3393–3398.
Lin, S. (1965). Computer solutions of the traveling salesman problem. Bell System Technical
Journal, 44, 2245–2269.
MacIntyre, S. (1993). Vertical mixing in a shallow, eutrophic lake: Possible consequences for the
light climate of phytoplankton. Limnology and Oceanography, 38(4), 798–817.
MacIntyre, S., Romero, J. R., & Kling, G. W. (2002). Spatial-temporal variability in surface layer
deepening and lateral advection in an embayment of lake victoria, east africa. Limnology and
Oceanography, 47(3), 656–671.
Meliou, A., Krause, A., Guestrin, C., & Hellerstein, J. M. (2007). Nonmyopic informative path
planning in spatio-temporal models. In Association for Advancement of Artificial Intelligence
(AAAI), pp. 602–607.
Nagarajan, V., & Ravi, R. (2007). Poly-logarithmic approximation algorithms for directed vehicle
routing problems. In Proc. 10th Internat. Workshop on Approximation Algorithms for Combinatorial Optimization Problems (APPROX’07), Vol. 4627 of LNCS, pp. 257–270. Springer.
753

S INGH , K RAUSE , G UESTRIN & K AISER

Nemhauser, G., Wolsey, L., & Fisher, M. (1978). An analysis of the approximations for maximizing
submodular set functions. Mathematical Programming, 14, 265–294.
Pon, R., Batalin, M., Gordon, J., Rahimi, M., Kaiser, W., Sukhatme, G., Srivastava, M., & Estrin,
D. (2005). Networked infomechanical systems: A mobile wireless sensor network platform.
In Proceedings of the fifth international conference on Information processing in sensor networks (IPSN), pp. 376–381.
Rahimi, M., Pon, R., Kaiser, W., Sukhatme, G., Estrin, D., & Srivastava, M. (2004). Adaptive
sampling for environmental robotics. In IEEE International Conference on Robotics and
Automation (ICRA).
Rasmussen, C. E., & Williams, C. K. (2006). Gaussian Process for Machine Learning. Adaptive
Computation and Machine Learning. MIT Press.
Reynolds-Fleming, J. V., Fleming, J. G., & Luettich, R. A. (2004). Portable autonomous vertical
profiler for estuarine applications. Estuaries, 25, 142–147.
Roy, N., & Earnest, C. (2006). Dynamic action spaces for information gain maximization in search
and exploration. In American Control Conference.
Ryan, M. R. K. (2008). Exploiting subgraph structure in multi-robot path planning. In Journal of
Artificial Intelligence and Research (JAIR), Vol. 31, pp. 497–542.
Sim, R., & Roy, N. (2005). Global a-optimal robot exploration in slam. In IEEE International
Conference on Robotics and Automation (ICRA).
Simmons, R. G., Apfelbaum, D., Burgard, W., Fox, D., Moors, M., Thrun, S., & Younes, H. (2000).
Coordination for multi-robot exploration and mapping. In Association for Advancement of
Artificial Intelligence (AAAI), pp. 852–858.
Singh, A., Nowak, R., & Ramanathan, P. (2006). Active learning for adaptive mobile sensing networks. In Proceedings of the fifth international conference on Information processing in
sensor networks (IPSN), pp. 60–68.
Singh, A., Batalin, M. A., Chen, V., Stealey, M. J., Jordan, B., Fisher, J., Harmon, T., Hansen, M., &
Kaiser, W. J. (2007a). Autonomous robotic sensing experiments at san joaquin river. In IEEE
International Conference on Robotics and Automation (ICRA), pp. 4987–4993, Rome, Italy.
Singh, A., Krause, A., Guestrin, C., Kaiser, W. J., & Batalin, M. A. (2007b). Efficient planning of
informative paths for multiple robots. In International Joint Conference on Artificial Intelligence (IJCAI), pp. 2204–2211, Hyderabad, India.
Smith, D. E. (2004). Choosing objectives in over-subscription planning. In International Conference
on Automated Planning and Scheduling (ICAPS).
Somasundara, A. A., Ramamoorthy, A., & Srivastava, M. B. (2007). Mobile element scheduling
with dynamic deadlines. In IEEE Transactions on Mobile Computing, Vol. 6, pp. 395–410.
Stachniss, C., Grisetti, G., & Burgard, W. (2005). Information gain-based exploration using raoblackwellized particle filters. In Robotics Science and Systems (RSS).
Tang, L., & Wang, X. (2006). Iterated local search algorithm based on very large-scale neighborhood for prize-collecting vehicle routing problem. The International Journal of Advanced
Manufacturing Technology, 1–13.
754

E FFICIENT I NFORMATIVE S ENSING USING M ULTIPLE ROBOTS

Thompson, D. R., & Wettergreen, D. (2008). Intelligent maps for autonomous kilometer-scale science survey. In International Symposium on Artificial Intelligence, Robotics and Automation
in Space (iSAIRAS).
Trummel, K. E., & Weisinger, J. R. (1986). The complexity of the optimal searcher path problem.
Operations Research, 34(2), 324–327.
Zhang, W., & Korf, R. E. (1995). Performance of linear-space search algorithms. Artificial Intelligence, 79(2), 241–292.

755

Journal of Artificial Intelligence Research 34 (2009) 605–635

Submitted 11/08; published 04/09

Inferring Shallow-Transfer Machine Translation Rules
from Small Parallel Corpora
Felipe Sánchez-Martı́nez
Mikel L. Forcada

fsanchez@dlsi.ua.es
mlf@dlsi.ua.es

Departament de Llenguatges i Sistemes Informàtics
Universitat d’Alacant, E-03071 Alacant (Spain)

Abstract
This paper describes a method for the automatic inference of structural transfer rules
to be used in a shallow-transfer machine translation (MT) system from small parallel
corpora. The structural transfer rules are based on alignment templates, like those used in
statistical MT. Alignment templates are extracted from sentence-aligned parallel corpora
and extended with a set of restrictions which are derived from the bilingual dictionary of
the MT system and control their application as transfer rules. The experiments conducted
using three different language pairs in the free/open-source MT platform Apertium show
that translation quality is improved as compared to word-for-word translation (when no
transfer rules are used), and that the resulting translation quality is close to that obtained
using hand-coded transfer rules. The method we present is entirely unsupervised and
benefits from information in the rest of modules of the MT system in which the inferred
rules are applied.

1. Introduction
Machine translation (MT) may be defined as the use of a computer to translate a text from
one natural language, the source language (SL), into another, the target language (TL). MT
is difficult mainly because natural languages are highly ambiguous and also because two
languages do not always express the same content in the same way (Arnold, 2003).
The different ways in which the MT problem has been approached may be classified
according to the nature of the knowledge used in the development of the MT system. From
this point of view, one can distinguish between corpus-based and rule-based approaches;
although, hybrid approaches are also possible.
Corpus-based approaches to MT, such as example-based MT (EBMT; Nagao, 1984;
Carl & Way, 2003) and statistical MT (SMT; Brown et al., 1993; Knight, 1999), use large
collections of parallel texts as the source of knowledge from which the engine learns how to
perform translations. A parallel text is a text in one language together with its translation
into another language; a large collection of parallel texts is usually referred as a parallel
corpus. Although corpus-based approaches to MT have grown in interest over the last
years, they require large amounts, in the order of tens of millions of words, of parallel
text to achieve reasonable translation quality (Och, 2005). Such a vast amount of parallel
corpora is not available for many under-resourced language pairs demanding MT services.
Rule-based MT (RBMT) systems use knowledge in the form of rules explicitly coded by
human experts that attempt to codify the translation process. RBMT systems heavily depend on linguistic knowledge, such as morphological and bilingual dictionaries (containing
c
2009
AI Access Foundation. All rights reserved.

Sánchez-Martı́nez & Forcada

SL
text

Analysis

SL IR

Transfer

TL IR

Generation

TL
text

Figure 1: Scheme of a general transfer-based MT system.

lexical, syntactic and even semantic information), part-of-speech disambiguation rules or
manually disambiguated corpora, and a large set of rules. The process of building a RBMT
system involves considerable human effort in order to develop the necessary linguistic resources (Arnold, 2003).
Generally, RBMT systems work by parsing (or analyzing) the SL text, usually creating
an intermediate (symbolic) representation (IR), from which the text in the TL is generated (Hutchins & Somers, 1992). According to the nature of the IR used, an RBMT system
may be said to be either interlingua or transfer-based. An interlingua MT system uses a
single IR that is independent of the languages involved in the translation; the advantage
of using a language-independent IR is that no transfer module needs to be developed for
each new language pair; as a disadvantage such an IR used is difficult to design and hard to
implement, even more so, for open-domain tasks. In contrast, a transfer-based MT system
uses two IRs, one for each of the languages involved; this has the advantage of easing the
design and development of the IRs used, but at the cost of having to develop a transfer
module for each new language pair.
Transfer-based MT systems usually work by applying, in addition to lexical transfer
mappings, a set of structural transfer rules to the SL IR created during the analysis, in
order to transform it into the TL IR from which the TL text is finally generated (see
Figure 1). The level of analysis, and therefore the degree of abstraction provided by the IR,
varies depending on how related the languages involved are. Translating between “distant”
languages (such as English and Japanese) requires deep analysis (syntactic and semantic),
while the translation between related languages (for example between Romance languages)
can be achieved with shallow parsing. We will call this last type of transfer-based systems
shallow-transfer MT systems.
1.1 Overview
This paper focuses on the automatic inference from small parallel corpora of the set of structural (shallow-)transfer rules that are used by shallow-transfer RBMT systems to convert
a SL IR into the TL IR from which the TL text is generated. The development of such
transfer rules requires qualified people to code them manually; therefore, their automatic
inference may save part of this human effort. The method we present is entirely unsupervised and benefits from information in the rest of modules of the MT system in which the
inferred rules are applied, in line with the method proposed by Sánchez-Martı́nez et al.
(2008) to train part-of-speech taggers in an unsupervised way for their use in MT.
In our approach an existing bilingual dictionary is used to guide the inference of structural transfer rules (see below), and bilingual entries for that dictionary are not learned.
This is because our approach is aimed at the inference of transfer rules from small parallel
corpora1 for their application in open-domain tasks. Note that small parallel corpora may
1. Small compared to the size of corpora commonly used to build corpus-based MT systems (Och, 2005).

606

Inferring Shallow-Transfer MT Rules from Small Parallel Corpora

be insufficient to obtain wide-coverage bilingual dictionaries, as demonstrated by the results
obtained when translating through a state-of-the-art SMT system trained on the same small
parallel corpora (see section 5). Notice that manually building a bilingual dictionary for a
language pair is usually much easier than developing shallow structural transfer rules for it,
moreover, the former task can be partially automated.
The method we propose for the automatic inference of shallow-transfer rules from parallel corpora is based on the alignment template (AT) approach initially proposed for its
use in the SMT framework (Och, 2002; Och & Ney, 2004). An AT can be defined as a
generalization performed over aligned phrase2 pairs (or translation units) by using word
classes.
To adapt the AT approach to the RBMT framework, ATs are extended with a set of
restrictions that control their application as structural shallow-transfer rules. To that end:
• the bilingual dictionary of the RBMT system in which the inferred rules will be
integrated is used to ensure that the lexical content of each bilingual phrase pair
extracted from the training corpus (see section 2.2) can be reproduced by the MT
system;
• linguistically motivated word classes are used to generalize the extracted bilingual
phrase pairs, deriving ATs from them; and,
• a set of restrictions, derived from the bilingual dictionary of the RBMT system, is
attached to each AT to control its application as part of a transfer rule; this extension
of the definition of AT will be called extended AT.
Once these extended ATs have been extracted from the training corpora, transfer rules are
generated from them. In the experiments reported in section 5, shallow-transfer rules to be
used by the Apertium MT engine (see appendix A) are generated directly in Apertium’s
XML-based structural transfer language. An interesting property of the inferred rules is
that they are human-readable and may, therefore, be edited by human experts to improve
their performance or supplemented with new rules; MT developers can use this method to
infer an initial set of rules and then improve them by focusing on the more difficult issues.
Both this method (Sánchez-Martı́nez & Forcada, 2007) and its predecessor (SánchezMartı́nez & Ney, 2006) have already been presented in conferences; here, we explain the
method in more detail, test it on two additional language pairs and use training corpora of
different sizes so as to evaluate the impact of size on translation quality. Moreover, in this
paper we perform a more detailed analysis of the inferred rules and the results obtained;
to that end, we provide confidence intervals, which allow for a better interpretation of the
results achieved. We will also discuss the process followed to build the parallel corpora used
to learn transfer rules.
2. For the purpose of this paper, and to stick to the terminology used by Och and Ney (2004) in the
definition of AT and by most SMT practitioners, by phrase we refer to any text segment, not necessarily
a well-formed syntactic constituent.

607

Sánchez-Martı́nez & Forcada

1.2 Related Work
There have been other attempts to learn automatically or semi-automatically the structural
transformations needed to produce correct translations into the TL. Those approaches can
be classified according to the translation framework to which the learned rules are applied.
Some approaches learn transfer rules to be used in RBMT. Probst et al. (2002) and
Lavie et al. (2004) developed a method to learn transfer rules for MT involving underresourced languages (such as Quechua) with very limited resources. To this end, a small
parallel corpus (of a few thousand sentences) is built with the help of a small set of bilingual
speakers of the two languages. The parallel corpus is obtained by translating a controlled
corpus from the language with more resources (English or Spanish) into the under-resourced
language by means of an elicitation tool. This tool is also used to graphically annotate the
word alignments between the two sentences. Finally, hierarchical syntactic rules, which
can be seen as constituting a context-free transfer grammar, are inferred from the aligned
parallel corpus.
Menezes and Richardson (2001) propose a method to infer transfer mappings (rules)
between source and target languages. Prior to the acquisition of the transfer mappings, they
align the nodes of the source and target parse trees by using an existing bilingual lexicon in
which they look for word correspondences. Then, following a best-first strategy and using
an small alignment grammar their method aligns the remaining (not-aligned) nodes. Once
the alignments between the nodes of both parse trees have been obtained, frequencies are
computed and sufficient context is retained to disambiguate between competing mappings
at translation time. Our approach greatly differs from the one by Menezes and Richardson:
(i) because they use a syntactic parser, a bilingual dictionary and an alignment grammar
to obtain the word alignments from the sentence-aligned parallel corpus, while we only use
statistical methods; (ii) because of how they use the bilingual dictionary, we use it to discard
useless bilingual phrases and to derive restrictions to control the application of ATs, not
for the computation of the word alignments; and (iii) because in our approach there is no
ambiguity to solve at translation time.
Caseli et al. (2006) propose a method to infer bilingual resources (structural transfer
rules and bilingual dictionaries) to be used in shallow-transfer MT from aligned parallel
corpora. Previously to the generation of transfer rules, alignment blocks (sequences of
aligned words) are built from the translation examples found in the parallel corpus by
considering three different types of word alignments according to their geometry (crossings,
unaligned words, etc.). Then, shallow-transfer rules are built in a three-step procedure. In
the first step, they identify the patterns in two phases, monolingual and bilingual; then in
a second step their method generates shallow-transfer rules by deriving monolingual and
bilingual constraints, that can also be seen as the rule itself; finally, in a third step the rules
are filtered in order to solve the ambiguity caused by rules matching the same SL sequence
of words. The inferred rules are human-readable, as are those inferred with the method we
propose, and may therefore be also edited by human experts. Our approach differs from
that of Caseli et al. in how rules are induced: while our approach uses bilingual phrase
pairs without being concerned about the type of alignments between the words, the way in
which Caseli et al. induce rules depends on the type of the alignment blocks. In addition,
our approach does not ever produce more than one rule matching the same sequence of
608

Inferring Shallow-Transfer MT Rules from Small Parallel Corpora

SL items, and therefore no ambiguity needs to be solved. Furthermore, we do not infer a
bilingual dictionary; instead, we use an existing bilingual dictionary to guide the inference
of shallow-transfer rules, and to control the application of the inferred rules.
In the EBMT framework, some researchers have dealt with the problem of inferring a
kind of translation rules called translation templates (Kaji et al., 1992; Brown, 1999; Cicekli
& Güvenir, 2001). A translation template can be defined as a bilingual pair of sentences in
which corresponding units (words or phrases) are coupled and replaced by variables. Liu
and Zong (2004) provide an interesting review of the different research works dealing with
translation templates. Brown (1999) uses a parallel corpus and some linguistic knowledge
in the form of equivalence classes (both syntactic and semantic) to perform a generalization
over the bilingual examples collected. The method works by replacing each word by its
corresponding equivalence class and then using a set of grammar rules to replace patterns
of words and tokens by more general tokens. Cicekli and Güvenir formulate the acquisition
of translation templates as a machine learning problem, in which the translation templates
are learned from the differences and similarities observed in a set of different translation
examples, using no morphological information at all. Kaji et al. use a bilingual dictionary
and a syntactic parser to determine the correspondences between translation units while
learning the translation templates. Our approach differs from those applied in the EBMT
framework because, on the one hand, the transfer rules generated through the method
we propose are mainly based on lexical forms (consisting of lemma, lexical category and
morphological inflection information) and, on the other hand, because they are flatter,
less structured and non-hierarchical, which makes them suitable for shallow-transfer MT.
Moreover, the way in which translation rules are chosen for application greatly differs from
how they are chosen in the EBMT framework.
Finally, in the SMT framework the use of AT (Och & Ney, 2004) can be seen as an
integration of translation rules into statistical translation models, since an AT is a generalization or an abstraction, of the transformations to apply when translating SL into TL by
using word classes.
The rest of the paper is organized as follows: the next section reviews the alignment
template (AT) approach; section 3 explains how ATs are extended with a set of restrictions
in order to use them to generate shallow-transfer rules to be used in RBMT (section 4).
Section 5 describes the experiments conducted and the results achieved. Finally, section 6
discusses the method described and outlines future research lines.

2. The Alignment Template Approach
The alignment template (AT) approach (Och, 2002; Och & Ney, 2004) was introduced in
the SMT framework as one of the feature functions in the maximum entropy model (Och
& Ney, 2002) to try to generalize the knowledge learned for a specific phrase to similar
phrases.
An AT performs a generalization over bilingual phrase pairs using word classes instead
of words. An AT z = (Sm , Tn , A) consists of a sequence Sm of m SL word classes, a sequence
Tn of n TL word classes, and a set of pairs A = {(i, j) : i ∈ [1, n] ∧ j ∈ [1, m]} with the
alignment information between the TL and SL word classes in the two sequences.
609

Sánchez-Martı́nez & Forcada

met
been
not
has
request
personal
my
a
mi ión nal no ha ido ch
e
c o
s sf
ti ers
e
ti
p p
sa

Figure 2: Alignment between the words in the English sentence my personal request has not been
met and those in the Spanish sentence mi petición personal no ha sido satisfecha. The alignment
information is represented as a binary matrix.

Learning a set of ATs from a sentence-aligned parallel corpus consists of: (i) the computation of the word alignments, (ii) the extraction of bilingual phrase pairs, and (iii) the
generalization of such bilingual phrase pairs by using word classes instead of the words
themselves.
2.1 Word Alignments
A variety of methods, statistical (Och & Ney, 2003) or hybrid (Caseli et al., 2005),3 may be
used to compute word alignments from a (sentence-aligned) parallel corpus. In the experiments reported in section 5, word alignments are obtained by training classical statistical
translation models to translate from language L1 to language L2 (and vice versa) and then
computing the Viterbi alignments under the previously estimated translation models. The
Viterbi alignment between SL and TL sentences is defined as the alignment whose probability is maximal under the translation models previously estimated. The resulting Viterbi
alignments A1 and A2 (one for each translation direction) are symmetrized through the
refined intersection method proposed by Och and Ney (2003, p. 33). Symmetrization is
needed in order to allow a SL word to be aligned with more than one TL word; otherwise,
wrong alignments are obtained when a SL word actually corresponds to more than one TL
word.
Figure 2 shows the word alignment in a Spanish–English sentence pair. The alignment
information is represented as a binary matrix in which a value of 1 (large black squares)
means that the words at the corresponding positions are aligned; analogously, a value of 0
(small black squares) means that the words are not aligned.

3. Caseli et al.’s (2005) method is hybrid because prior to the application of heuristics, it uses a statistical
tool (NATools) to obtain a probabilistic bilingual dictionary (Simões & Almeida, 2003).

610

Inferring Shallow-Transfer MT Rules from Small Parallel Corpora

2.1.1 Training
In order to train the translation models and to calculate the Viterbi alignments of each pair
of aligned sentences found in the training corpus the free/open-source GIZA++ toolkit4 (Och
& Ney, 2003) is used with default parameters.
The computation of the word alignments consists of:
1. training the IBM model 1 (Brown et al., 1993) for 5 iterations; in this model, word
order does not affect the alignment probabilities;
2. training the HMM alignment model (Vogel et al., 1996) for 5 iterations; this alignment
model has the property of making alignment probabilities explicitly dependent on the
alignment position of the previous word;
3. training the IBM model 3 (Brown et al., 1993) for 5 iterations; in this model, the
probability of an alignment depends on the positions of the aligned words and on the
length of SL and TL sentences. In addition, IBM model 3 also introduces fertilities;
the fertility of a word is defined as the number of aligned words in the other language.
And finally,
4. training the IBM model 4 (Brown et al., 1993) for 5 iterations; this model is identical
to IBM model 3 except for the fact that it models the reordering of phrases that may
be moved around as units.
Note that after obtaining the Viterbi alignments these statistical translation models are no
longer used.
2.2 Extraction of Bilingual Phrase Pairs
Bilingual phrase pairs are automatically extracted from the word-aligned sentence pairs.
Usually, the extraction of bilingual phrase pairs (Zens et al., 2002) is performed by considering all possible pairs below a certain length and ensuring that: (i) all words are consecutive,
and (ii) words within the bilingual phrase pair are not aligned with words from outside.
The set BP(wS J1 , wT I1 , A) of bilingual phrases that are extracted from the word-aligned
sentence pair (wS1 , . . . , wSJ ), (wT1 , . . . , wTI ) may be formally expressed as follows:
, wT i+n
):
BP(wS J1 , wT I1 , A) = {(wS j+m
j
i
∀(i0 , j 0 ) ∈ A : j ≤ j 0 ≤ j + m ⇔ i ≤ i0 ≤ i + n}.

However, in our approach bilingual phrase pairs are also required to have their first and last
words on both sides (source and target) aligned with at least one word in the other side.5
Integrating these additional constraints, previous equation may be rewritten as:
, wT i+n
):
BP(wS J1 , wT I1 , A) = {(wS j+m
j
i
4. http://www.fjoch.com/GIZA++.html
5. Experiments conducted without such requirement show a significant degradation of the translation quality achieved with the inferred rules.

611

Sánchez-Martı́nez & Forcada

(∀(i0 , j 0 ) ∈ A : j ≤ j 0 ≤ j + m ⇔ i ≤ i0 ≤ i + n)
∧ (∃k ∈ [i, i + n] : (wSj , wTk ) ∈ A)
∧ (∃k 0 ∈ [i, i + n] : (wSj+m , wTk0 ) ∈ A)
∧ (∃l ∈ [j, j + m] : (wSl , wTi ) ∈ A)
∧ (∃l0 ∈ [j, j + m] : (wSl0 , wTi+n ) ∈ A)}.
Figure 3 shows the set bilingual phrase pairs with more than one SL word extracted from
the word-aligned Spanish–English sentence pair shown in Figure 2.
2.3 Generalization
The generalization of the bilingual phrase pairs is simply done by using word classes instead
of the words themselves; to that end, a function that maps single words into word classes
is defined. The use of word classes allows the description of word reorderings, preposition
changes and other divergences between SL and TL. Och and Ney (2004) use automatically
obtained (Och, 1999) word classes to extract ATs for SMT. However, for RBMT, linguistically motivated word classes related to those used by the remaining modules in the MT
system must be used (see section 3.1).

3. Alignment Templates for Shallow-Transfer Machine Translation
To apply the AT approach in a shallow-transfer MT system, the parallel corpus from which
the ATs are learned must be in the intermediate representation (IR) used by the translation
engine. In shallow-transfer MT the transformations to apply are mainly related to lexical
forms; therefore, the IR used by the translation engine usually consists of lemma, lexical
category and morphological inflection information for each word.
In order to convert the parallel corpus into the IR used by the engine, the analysis
modules (morphological analyzers and part-of-speech taggers) of the engine are used to
analyze both sides of the parallel corpus before computing the word alignments. After
analyzing both sides of the parallel corpus we have, for each word, its lemma, lexical category
and morphological inflection information. Note that generalizations are performed after
word alignments and bilingual phrase pair extraction by using word classes based on that
morphological information (see next section).
3.1 Word-Class Definition
As the transformations to apply are mainly based on the lexical category and inflection
information of SL and TL words, the function that maps words into word classes will map
each word into a word class representing its lexical category and morphological inflection
information (such as verb, preterite tense, third person, plural).
Using the lexical category and morphological inflection information to define the set
of word classes allows the method to learn general syntactic rules such as reordering and
agreement rules, and verb tense changes, among others. However, in order to learn lexical
changes, such as preposition changes or auxiliary verb usage, some words will be assigned
single-word classes representing a lexical form, as discussed next.
612

Inferring Shallow-Transfer MT Rules from Small Parallel Corpora

request
personal
n l
ió ona
c
ti rs
pe pe

been
not
has

not
has

met
been

a
doech
i
s sf
ti
sa

no ha

not
has
request
no ha ido personal
s
n l o a
ió ona n h
c
ti rs
pe pe

not
has
request
personal
my
mi ión nal no ha
c o
ti ers
e
p p
been
not
has
request
personal
my
mi ión nal no ha ido
c o
s
ti ers
e
p p

request
personal
my
mi ión nal
c o
ti ers
e
p p
met
been
not
has
a
no ha ido ch
e
s sf
ti
sa

been
not
has
request
personal
ón al no ha do
ci son
si
i
t er
e
p p
met
been
not
has
request
personal
a
ón nal no ha do ch
i
i
e
c o
s sf
ti ers
e
ti
p p
sa

Figure 3: Set of bilingual phrase pairs (see section 2.2) extracted from the word-aligned Spanish–
English sentence pair shown in Figure 2. Note that bilingual phrase pairs containing only one word
and the whole word-aligned sentence pair have been omitted.

613

Sánchez-Martı́nez & Forcada

São Paulo
a
estar
van
n n o
ro e ul
e
Pa
vi
u
o
t
Sã
es

(noun.loc)
a-(pr)
(verb.inf)
anar-(vaux.pres.3rd.pl)

)
pl r) c)
d. n -(p .lo
r
t.3 e oun
re
(n
p
.

(v

b
er

R = {w1 =verb.*, w3 =noun.*}
Figure 4: Example of a Spanish–Catalan bilingual phrase (left), the corresponding AT (right)
obtained when each word is replaced by its corresponding word class, and TL restrictions (see
section 3.2) for the Spanish-to-Catalan translation. Words in boldface correspond to lexicalized
categories (see section 3.1). Word classes in the horizontal axis correspond to the SL (Spanish) and
in the vertical axis to the TL (Catalan).

3.1.1 Lexicalized Categories
A set of (lexicalized) categories usually involved in lexical changes such as prepositions and
auxiliary verbs may be provided. For those words whose lexical category is in the set of
lexicalized categories (from now on, lexicalized words) the lemma is also used when defining
the word class they belong to. In this way, lexicalized words are placed in single-word
classes representing a particular lexical form. For example, if prepositions are considered
lexicalized categories, words to and for would be in different word classes, even if they have
the same lexical category and morphological inflection information, whereas words book and
house would be in the same word class (noun, singular).
Typically the set of lexicalized categories is a subset of the set of closed categories, that
is, those that do not grow by addition of new words to the lexicon: pronouns, auxiliary
verbs, prepositions, conjunctions, etc. The most typical lexicalized words are prepositions,
as they usually have many different translations depending on the SL context.
Figure 4 shows an example of a Spanish–Catalan bilingual phrase and the generalization performed when each word is replaced by its corresponding word class; words in
boldface correspond to lexicalized categories. The AT shown in Figure 4 generalizes, on
the one hand, the use of the auxiliary Catalan verb anar to express the past perfect
(preterite) tense and, on the other hand, the preposition change when it refers to a location name, such as the name of a city or a country. Note that lexicalized words (e.g.
anar-(vaux.pres.3rd.pl), en-(pr)) coexist in the same AT with non-lexicalized categories (e.g. (verb.inf), (noun.loc)) without distinction.
3.2 Extending the Definition of Alignment Template
In section 2 an AT was defined as a tuple z = (Sm , Tn , A) in which only the alignment A
between SL and TL word classes was considered. Here the definition of AT is extended to
z = (Sm , Tn , A, R), where a set of restrictions, R, over the TL inflection information of the
non-lexicalized categories, is added to control its application as part of a transfer rule.
614

Inferring Shallow-Transfer MT Rules from Small Parallel Corpora

(adj.m.sg)
(noun.m.sg)
el-(art.m.sg)
)
g) g )
.s .f.s .f.sg
f
.
rt un dj
-(a no (a
el (

R = {w2 =noun.m.*, w3 =adj.*}
Figure 5: Spanish–Catalan AT and TL restrictions over the inflection information for the Spanishto-Catalan translation (see section 3.2).

3.2.1 TL Restrictions
When translating (see section 4.3.1), that is, when applying the inferred ATs, the TL
inflection information of non-lexicalized words is taken from the corresponding (aligned)
TL word class in the AT being applied, not from the bilingual dictionary; because of this,
restrictions are needed in order to prevent an AT to be applied in certain conditions that
would produce an incorrect translation.
To illustrate the need for such restrictions let us consider what would happen when
translating the Spanish phrase la silla roja 6 into Catalan by applying the extended AT
shown in Figure 5, which should not be applied in this case. This AT generalizes the
propagation of the masculine gender to the article and the adjective when translating a SL
(Spanish) noun that is feminine singular in the SL (same with the article and the adjective)
and has a masculine equivalent into Catalan, which is not the case of silla. After applying
the extended AT in Figure 5, the morphological generator (see Appendix A) has to inflect the
lexical form cadira-(noun.m.sg), which does not exist in Catalan,7 as cadira is feminine.
By taking into account some restrictions over the TL inflection information, such as the one
referring to w2 in the extended AT in Figure 5, we prevent the application of an AT if its
application would produce an incorrect lexical form to inflect, as in the running example.
TL restrictions are obtained from the bilingual dictionary of the MT system in which
the inferred transfer rules will be integrated. Bilingual dictionaries may explicitly code all
the inflection information of the translation of each SL lexical form, or only the inflection
information that changes from one language to the other. TL restrictions could be derived
from both kinds of bilingual dictionaries; however, their extraction is easier in the second
case, that is, if only changes in the inflection information are explicitly coded.
For the experiments (see section 5) the Apertium MT platform has been used; in Apertium bilingual dictionaries, only changes in inflection information are explicitly coded. The
following two examples show, on the one hand, a Spanish–Catalan bilingual entry and, on
the other hand, the restriction over the TL inflection information for the Spanish-to-Catalan
translation derived for that bilingual entry:8
6. Translated into English as the red chair.
7. Note that the lexical category and morphological inflection information of the TL lexical form to inflect
has been taken from the TL part of the AT.
8. Lemmas between tags <l> and </l> (left) correspond to Spanish words; analogously, lemmas between
tags <r> and </r> (right) correspond to Catalan words. Lexical category and inflection information is
coded through the tag <s> (symbol ), the first one being the lexical category.

615

Sánchez-Martı́nez & Forcada

• Bilingual entry without any change in inflection information
<e><p>
<l>castigo<s n="noun"/></l>
<r>càstig<s n="noun"/></r>
</p></e>
Restriction: w=noun.*
• Bilingual entry in which the gender changes from feminine (Spanish) to masculine
(Catalan)
<e><p>
<l>calle<s n="noun"/><s n="f"/></l>
<r>carrer<s n="noun"/><s n="m"/></r>
</p></e>
Restriction: w=noun.m.*
As can be seen, restrictions provide the lexical category and morphological inflection information that the lexical form should have at translation time after looking it up in the
bilingual dictionary; the star at the end of each restriction means that the rest of inflection information is not restricted. The second bilingual entry would be responsible of the
restrictions attached to w2 in the AT shown in Figure 5. That AT can only be applied if
the noun (w2 ) is masculine in the TL (see next section to know how ATs are applied); note
that the inflection information of w3 is not restricted at all; this is because w3 refers to an
adjective that can be both masculine and feminine, as its gender depends on the gender of
the noun it qualifies.

4. Generation of Apertium Transfer Rules
This section describes the automatic generation of Apertium structural shallow-transfer
rules; note, however, that the generation of transfer rules for other shallow-transfer MT
systems would also be feasible by following the approach presented here.
The structural transfer in Apertium (see appendix A) uses finite-state pattern matching
to detect, in the usual left-to-right, longest-match way, fixed-length patterns of lexical forms
to process and performs the corresponding transformations. A (generic) shallow-transfer
rule consists of a sequence of lexical forms to detect and the transformations that need to
be applied to them.
4.1 Discarding Useless Bilingual Phrase Pairs
Not all bilingual phrase pairs are useful in the inference of transfer rules, since the generalization that would be performed from some of them cannot be used in RBMT; more
precisely, bilingual phrase pairs satisfying one or both of the following conditions are useless,
and therefore, discarded:
616

Inferring Shallow-Transfer MT Rules from Small Parallel Corpora

• SL and TL non-lexicalized words are not aligned. When translating a SL nonlexicalized word (see next section) the inflection information is taken from the aligned
TL word class, therefore the corresponding alignment must exist.
• the bilingual phrase pair cannot be reproduced by the MT system in which the transfer rules will be used. This happens when the translation equivalent in the bilingual
dictionary differs from the one observed in the bilingual phrase. Note that TL restrictions are extracted from the bilingual dictionary, and if translation equivalents do not
agree the extracted AT could end up having a set of restrictions making no sense at
all.
4.2 Selecting the Alignment Templates to Use
To decide which ATs to take into account for the generation of rules, the method is provided
with a frequency count threshold. ATs whose frequency count is below this threshold are
discarded. In the experiments, two different ways of interpreting the frequency count have
been tested:
• to use directly the frequency count c, and
• to use a modified frequency count c0 = c(1 + log(l)), where l stands for the length of
the SL part of the AT.
The second approach aims at solving the problem caused by the fact that longer ATs have
lower frequency counts but may be more accurate as they take more context into account.
A similar approach was used by (Mikheev, 1996) in his work on learning part-of-speech
guessing rules to favor longer suffixes over shorter ones.
4.3 Rule Generation
A rule consists of a set U of extended ATs with the same sequence of SL word classes, but
different sequences of TL word classes, different alignment information or different set of
TL restrictions. Formally this may be expressed as follows:
U = {(Sm , Tn , A, R) ∈ Z : Sm = S U },

(1)

where Z refers to the whole set of ATs and S U to the sequence of SL word classes that all
ATs in U have in common. Note that each rule matches a different sequence S U of SL word
classes and, therefore, there is no ambiguity in the application of the shallow-transfer rules
at translation time.
Each rule U is coded in Apertium’s XML-based transfer language. The code generated
for each rule applies always the most frequent AT in U that satisfies the TL restrictions R;
therefore, competing ATs are selected according to their frequency. A “default” AT, which
translates word for word, is always added with the lowest frequency count. This AT has
no TL restrictions and is the one applied when none of the remaining ATs can be applied
because their TL restrictions are not met.
To check if the restrictions over the TL inflection information of an AT are met, the
translation of each non-lexicalized word is retrieved from the bilingual dictionary; then, the
617

Sánchez-Martı́nez & Forcada

retrieved morphological attributes (lexical category and inflection information) are compared with those specified by the corresponding restriction; the AT will be applicable if all
restrictions hold.
4.3.1 Application of an Alignment Template
The code generated in the Apertium’s XML-based transfer language that applies an AT is
guided by the sequence Tn of TL word classes. The actions to perform for each unit in Tn
depend on the type of its word class:

• if the word class corresponds to a non-lexicalized word, the translation of the lemma
of the aligned SL (non-lexicalized) word is retrieved by looking it up in the bilingual dictionary; then, the lexical category and morphological inflection information
provided by the TL word class are attached to the translated lemma;

• if the word class corresponds to a lexicalized word, it is introduced as is; remember that
word classes belonging to lexicalized words represent complete lexical forms consisting
of lemma, lexical category and morphological inflection information.

Note that the information about SL lexicalized words is not taken into account when applying a given AT (just when detecting it).
The following example illustrates how the AT shown in Figure 4 would be applied
in order to translate from Spanish to Catalan the input text vivieron en Francia.9 This
text segment, after morphological analysis and part-of-speech tagging, is transformed by
the MT engine into the SL IR vivir -(verb.pret.3rd.pl) en-(pr) Francia-(noun.loc),
which becomes the input to the structural transfer module. The AT is applied in the order
specified in its TL part. For the word classes corresponding to non-lexicalized words, the
aligned SL words are translated into TL (Catalan) by looking them up in the bilingual
dictionary: vivir is translated as viure and Francia is translated as França. Then, the
inflection information provided by the TL part of the AT (see Figure 4) is attached to each
translated lemma. Finally, word classes corresponding to lexicalized words are just copied to
the output as they appear in the TL part of the AT. For the running example the structural
transfer output would be the TL IR anar -(vaux.pres.3rd.pl) viure-(verb.inf) a-(pr)
França-(noun.loc), which the morphological generation module would transform into the
Catalan phrase van viure a França.

9. Translated into English as They lived in France.

618

Inferring Shallow-Transfer MT Rules from Small Parallel Corpora

5. Experiments
The approach presented in this paper has been tested on both translation directions of
the Spanish–Catalan (es-ca) and Spanish–Galician (es-gl) language pairs, and on the
Spanish-to-Portuguese (es-pt) translation.10,11
The parallel corpora used for training are from different sources. The Spanish–Catalan
parallel corpora come from El Periódico de Catalunya,12 a daily newspaper published both
in Catalan and Spanish; the Spanish–Galician parallel corpora come from Diario Oficial de
Galicia,13 the official publication of the autonomous government of Galicia published both
in Galician and Spanish; the Spanish–Portuguese parallel corpora come from The JRCAcquis Multilingual Parallel Corpus (Steinberger et al., 2006)14 which contains European
Union (EU) law applicable in the EU member states.
To test the importance of the amount of parallel corpora available for training we have
used corpora of different sizes. More precisely, we have used training corpora of around
0.25, 0.5, 1.0, 1.5, and 2.0 million words in each language. The corpora were built in such a
way that, for the same language pair, the larger corpora include the shorter ones. Note that
word alignments have been computed from each different training corpus in isolation before
the extraction of the extended ATs that are then used in the inference of shallow-transfer
rules.
As was explained in section 3.1, a set of categories usually involved in lexical changes
needs to be provided for the definition of word classes so as to learn not only syntactic
transformations, but also lexical transformations. To that end, a small set of eight to ten
lexicalized categories is used for each language. The most common lexicalized categories
are: prepositions, pronouns, determiners, subordinate conjunctions, relatives, modal verbs
and auxiliary verbs.
The length of the bilingual phrase pairs extracted and used to obtain the ATs has been
restricted to a maximum of 7 SL words for all the experiments. Remember from section 2.2
that to extract bilingual phrases from a pair of word-aligned sentences all possible pairs
(within a certain length) are considered; by restricting that length we are making the
problem computationally affordable.
With respect to the frequency count threshold used to select the set of ATs to take into
account (see section 4.2), we have tested frequency count thresholds between 5 and 40 for
all translation tasks and AT selection criteria. The frequency count used in the evaluation
is the one giving the best translation edit rate (TER; Snover et al., 2006) when translating
a corpus, similar to the one used for testing, with 1 000 sentences (see Table 1); in Table 5
(page 627) we provide the thresholds used when the rules are inferred from the corpus with
2.0 million words in each language.
10. All linguistic data used can be freely downloaded from http://sf.net/projects/apertium, packages
apertium-es-ca-1.0.2 (around 12 800 bilingual entries), apertium-es-gl-1.0.4 (around 10 800 bilingual entries) and apertium-es-pt-0.9.2 (around 11 000 bilingual entries); the number of bilingual entries
reported correspond to lemma-based entries.
11. A possible criticism here is that we have not used a standard translation task to test our approach; we
have not done so because the Apertium linguistic resources (morphological and bilingual dictionaries)
necessary for those standard tasks were not available.
12. http://www.elperiodico.com
13. http://www.xunta.es/diario-oficial
14. http://wt.jrc.it/lt/Acquis/

619

Sánchez-Martı́nez & Forcada

Language pair

sentences

es-ca

1 000

es-gl

1 000

es-pt

1 000

words
es: 22 583
ca: 22 451
es: 22 698
gl: 20 970
es: 23 561
pt: 22 941

Table 1: Number of sentences and number of words in each language for the different corpora used
to select the frequency count threshold used in the evaluation. The threshold finally used depends
on the translation task; see Table 5 on page 627 to know which threshold has been used for each
translation task when the rules are inferred from the parallel corpus with 2.0 million words in each
language.

5.1 Evaluation
The performance of the presented approach is compared to that of the same MT system
when no transfer rules are used at all (word-for-word MT), to that of the same MT system when using the hand-coded transfer rules,15 and to that of using a state-of-the-art
SMT system trained using the same parallel corpora. For the latter we have used the
free/open-source SMT toolkit Moses (Koehn et al., 2007) and the SRILM language modelling toolkit (Stolcke, 2002). The training of the SMT system was done as follows:16 First,
the translation model was trained using the 90% of the training corpus. Then, a 5-gram
language model was trained using the SRILM toolkit with the whole training corpus. Finally, the minimum error “rate” training algorithm (Och, 2003) used the remaining 10%
of the training corpus to adjust the weight of each feature.17 The features used by the
SMT system are those used by Moses by default: 5 phrase-table features (source-to-target
and target-to-source phrase translation probabilities, source-to-target and target-to-source
lexical weightings, and phrase penalty), a distance-based cost (total number of word movements), the sentence word count, and the TL model.
Translation performance is evaluated using two different measures; on the one hand,
the translation edit rate (TER; Snover et al., 2006), and on the other hand, the bilingual
evaluation understudy (BLEU; Papineni et al., 2002); in both cases the same evaluation
corpora have been used and the confidence intervals of the measures being reported are
given (see below).
5.1.1 Confidence intervals
Confidence intervals of MT quality measures are calculated through the bootstrap resampling method as described by Koehn (2004). In general, the bootstrap resampling method
consists of estimating the precision of sample statistics (in our case, translation quality
measures) by randomly resampling with replacement (that is, allowing repetitions) from
the full set of samples (Efron & Tibshirani, 1994); in MT, sentences and their respective
15. Those in the corresponding Apertium language packages.
16. For detailed training instructions visit http://www.statmt.org/wmt09/baseline.html.
17. The minimum error “rate” training used BLEU as an evaluation measure.

620

Inferring Shallow-Transfer MT Rules from Small Parallel Corpora

Language pair

sentences

es-ca

2 400

es-gl

2 450

es-pt

2 000

words
es: 55 064
ca: 54 730
es: 55 826
gl: 51 603
es: 55 814
pt: 53 762

Table 2: Number of sentences and number of words in each language for the different test corpora
used for evaluation.

reference translations. This method has the property that no assumptions are made about
the underlying distribution of the variable, in our case, the MT quality measure.
The calculation of the confidence intervals consists of the following steps:
1. the translation performance is evaluated a large number of times, in our experiments
1 000 times, using randomly chosen sentences from the test corpus, and their counterpart sentences in the reference corpus;
2. all the calculated measures are sorted in ascending order; and
3. the top q% and the bottom q% elements are removed from that list.
After that, the remaining values are in the interval [a, b]. This interval approximates with
probability 1 − 2q/100 the range of values in which the quality measure being reported lies
for test corpora with a number of sentences equal to that used to carry out the evaluation.
5.1.2 Evaluation corpora
Table 2 shows the number of sentences and the number of SL and TL words of the different
test corpora used for the evaluation of the inferred rules for each translation being considered. These test corpora come from independent parallel corpora, from a different source,
with no relation to those used for training. More precisely, the test corpora for Spanish–
Catalan and Spanish–Galician comes from Revista Consumer Eroski (Alcázar, 2005),18 a
magazine addressed to consumers published in Spanish, Catalan, Galician and Basque; the
test corpora for Spanish–Portuguese comes from the shared evaluation task of the 2008
workshop on SMT.19
5.2 Results
Figure 6 shows the TER and BLEU scores, together with their respective 95% confidence
intervals, achieved for each translation direction of the Spanish–Catalan language pair when
using training corpora of different sizes. The error rates reported are: (a) the results when
the frequency count is directly used to select the set of ATs to use for the rules generation,
(b) the results achieved by a state-of-the-art SMT system trained on the same corpora, (c)
18. http://revista.consumer.es
19. http://www.statmt.org/wmt08/wmt08-eval.tar.gz

621

Sánchez-Martı́nez & Forcada

Catalan (SL)
... els gossos catalogats de perillosos han
de tenir una assegurança ...
... es va descobrir en el cacauet ...
... va tenir un infart de miocardi ...
... els fonaments cientı́fics per considerar
funcionals diversos aliments són ...
... l’enveja no es manifesta ...
... cal preservar-lo de la llum ...

Spanish (TL)
... los perros catalogados de peligrosos
deben φ tener seguro ...
.. se φ descubrió en el cacahuete ...
... φ tuvo un infarto de miocardio ...
los fundamentos cientı́ficos para considerar funcionales varios alimentos son ...
la envidia no se manifiesta ...
... hay que preservarlos de la luz ...

Table 3: Translation examples for the Catalan-to-Spanish translation. The translations reported
are those produced when using the automatically inferred rules; words in boldface indicate changes
with respect to a word-for-word translation; φ indicates a word deleted with respect to a word-forword translation.

the results achieved when using hand-coded transfer rules, and (d) the results of a wordfor-word translation (when no structural transformations are applied). The results achieved
when the modified frequency count described in section 4.2 is used to select the set of ATs
to use are not reported since they are indistinguishable in practice from those achieved by
using directly the frequency count; for this reason, they will not be considered in the rest
of the experiments. Notice that in all cases, except for the SMT results, the same linguistic
data (morphological and bilingual dictionaries) have been used. Some Catalan-to-Spanish
translations produced by the automatically inferred rules are shown in Table 3.
Results in Figure 6 show that, as expected, the translation quality achieved by the
inferred transfer rules is better than that of a word-for-word translation, even when a small
parallel corpus with around 0.5 million words in each language is used; note however, that
in the case of the Spanish-to-Catalan translation confidence intervals overlap for a training
corpus of 0.25, 0.5 and 1.0 million words, the overlap being smaller for the latter.
Results in Figure 6 also show that a SMT system performs worse than the rules automatically inferred from the same parallel corpus and even worse than a word-for-word
translation. This is because the training corpora we have used are not large enough to learn
a wide-coverage bilingual lexicon and, consequently, most of the words to translate are unknown to the SMT system. Remember that our approach only learns transfer rules from
the parallel corpus, not bilingual entries, and that the same bilingual dictionary is used by
the hand-coded rules, the automatically inferred rules and the word-for-word translation.
In section 5.2.1 (page 626) we discuss the results achieved by the SMT system when the
bilingual dictionary in the corresponding Apertium package is added to the SMT training
data.
Figure 7 shows, for each translation direction of the Spanish–Galician language pair,
the same MT quality measures and for the same translation setups reported for Spanish–
Catalan in Figure 6.
The Spanish–Galician language pair shows results in agreement to those obtained for
Spanish–Catalan; however, the improvement on the Galician-to-Spanish translation quality,
compared to word-for-word translation, is smaller. In addition, the improvement obtained in
the case of Spanish–Catalan by increasing the amount of corpora used for training is greater
622

Inferring Shallow-Transfer MT Rules from Small Parallel Corpora

Spanish to Catalan
28

72
70
BLEU (% of words)

26
TER (% of words)

74

AT-count
SMT
hand
w4w

24
22
20
18

68
66
64
62
60
AT-count
SMT
hand
w4w

58
16

56

14

54
0.25 0.5

1
1.5
Millions of words

2

0.25 0.5

1
1.5
Millions of words

2

Catalan to Spanish
26

72
70
BLEU (% of words)

24
TER (% of words)

74

AT-count
SMT
hand
w4w

22
20
18

68
66
64
62
60
58

AT-count
SMT
hand
w4w

56

16

54
14

52
0.25 0.5

1
1.5
Millions of words

2

0.25 0.5

1
1.5
Millions of words

2

Figure 6: TER and BLEU scores (vertical axis), with their respective 95% confidence intervals,
for each translation direction of the Spanish–Catalan language pair when using training corpora of
different sizes (horizontal axis). AT-count refers to the result achieved when the count is directly
used to select the set of ATs to use; SMT refers to the result achieved by a state-of-the-art SMT
system trained on the same parallel corpora; hand refers to the results achieved when hand-coded
transfer rules are used; w4w (“word for word”) refers to the result achieved when no transfer rules
are used.

623

Sánchez-Martı́nez & Forcada

Spanish to Galician
26

74
72
BLEU (% of words)

24
TER (% of words)

76

AT-count
SMT
hand
w4w

22
20
18
16

70
68
66
64
62
60

AT-count
SMT
hand
w4w

58

14

56

12

54
0.25 0.5

1
1.5
Millions of words

2

0.25 0.5

1
1.5
Millions of words

2

Galician to Spanish
24

76
74
BLEU (% of words)

22
TER (% of words)

78

AT-count
SMT
hand
w4w

20
18
16

72
70
68
66
64
62

AT-count
SMT
hand
w4w

60

14

58
12

56
0.25 0.5

1
1.5
Millions of words

2

0.25 0.5

1
1.5
Millions of words

2

Figure 7: TERs and BLEU scores (vertical axis), with their respective 95% confidence interval,
for each translation direction of the Spanish–Galician language pair when using training corpora
of different sizes (horizontal axis). The measures reported correspond to the results achieved when
using different MT setups (as described in Figure 6).

624

Inferring Shallow-Transfer MT Rules from Small Parallel Corpora

Spanish to Portuguese
70

66

26
BLEU (% of words)

68
TER (% of words)

28

AT-count
SMT
hand
w4w

64
62
60
58

24
22
20
18
AT-count
SMT
hand
w4w

56
16

54
52

14
0.25 0.5

1
1.5
Millions of words

2

0.25 0.5

1
1.5
Millions of words

2

Figure 8: TER and BLEU scores (vertical axis), with their respective 95% confidence intervals,
for the Spanish–to-Portuguese translation when using training corpora of different sizes (horizontal
axis). The measures reported correspond to the results achieved when using different MT setups
(see Figure 6).

than that of Spanish–Galician, as shown by the slope of the curve. This is because the
significant frequent patterns which can be learned from the training corpora are selected very
early. Note that our method is unlikely to perform worse than word-for-word translation
(when no rules are used).
Concerning the Spanish-to-Portuguese translation, Figure 8 shows the TER and BLEU
scores achieved for the different sizes of training corpora used. Notice that the automatically
inferred rules perform better than the word-for-word translation, although their confidence
intervals show a large overlap. It is worth mentioning that the confidence intervals obtained
for the hand-coded transfer rules also overlap with those of the automatically inferred rules
and the word-for-word translation. As in the rest of experiments the SMT system performs
worse because the training corpus is not large enough to learn a wide-coverage bilingual
lexicon.
The difference between the results achieved when using hand-coded transfer rules and
that of using no rules at all (word-for-word translation) is very small compared to the rest of
translation tasks considered in this paper. Moreover, the TER and BLEU scores obtained
are very poor although Spanish and Portuguese are two related languages, and, therefore,
translating between them should not be such a difficult task. Indeed, an evaluation of
the hand-coded transfer rules performed using an evaluation corpus in which the reference
translation is a post-edited (corrected) version of the MT output produced with the same
hand-coded rules shows a TER below 10%.
The poor results obtained for the Spanish-to-Portuguese may be explained by the fact
that the evaluation corpus, as well as the training corpora used, may have not been built
by translating one language (say Spanish or Portuguese) into the other, but by translating
625

Sánchez-Martı́nez & Forcada

es-ca
ca-es
es-gl
gl-es
es-pt

AT-count
TER
OOV (%)
[15.8, 16.7]
4.3%
[15.0, 15.9]
4.9%
[14.7, 15.6]
9.3%
[13.9, 14.7]
10.2%
[54.2, 56.0]
3.8%

SMT+dictionary
TER
OOV (%)
[18.0, 19.0]
3.4%
[15.5, 16.4]
3.8%
[16.2, 17.1]
6.9%
[13.6, 14.4]
8.2%
[57.2, 59.0]
3.1%

SMT
TER
OOV (%)
[20.1, 21.2]
5.7%
[17.7, 18.7]
6.1%
[19.1, 20.0]
18.7%
[18.0, 18.8]
21.1%
[62.4, 64.1]
12.6%

Table 4: 95% confidence intervals for the TER and ratio of out-of-vocabulary (OOV) words when
the test corpus is translated: with the rules automatically obtained from parallel corpora (AT-count),
with a SMT system trained with the same parallel corpora (SMT), and with a SMT system trained on
the same parallel corpora plus the corresponding Apertium bilingual dictionary (SMT+dictionary).
The data reported correspond to the case in which the training corpus has 2.0 million words in each
language.

from a third language (possibly English or French).20 This causes the reference translation
to be very different compared to the translations automatically performed, thus giving very
high TERs. On the other hand, this may also cause the alignments obtained from the
training corpora to be unreliable, as shown by the percentage of discarded bilingual phrase
pairs. This percentage is, for all training corpora, around 54% for the Spanish-to-Portuguese
translation, about 22% for the Spanish–Catalan language pairs, and around 20% for the
Spanish–Galician language pair.
5.2.1 Adding the bilingual dictionary to the SMT training data
With the aim of testing whether the difference in the translation performance between
the shallow-transfer rules and the SMT system is due to the fact that Apertium uses a
wide-coverage, manually-built bilingual dictionary, we have added the bilingual dictionary
in the corresponding Apertium package to the SMT training data (Tyers et al., 2009).21 It
is worth noting that adding the bilingual dictionary to the training corpus does not only
improve the vocabulary coverage of the SMT systems inferred, but also helps the word
alignment process by adding word-to-word alignment, which gives an additional advantage
to the SMT system with respect other systems; the bilingual dictionary has not been added
to corpus used to learn the AT used for the automatic inference of shallow-transfer rules.
Table 4 shows the 95% confidence intervals for the TER and the ratio of out-of-vocabulary
(OOV) words when the test corpus is translated by means of Apertium with the shallowtransfer rules automatically obtained form the parallel corpus with 2.0 million words in
each language (AT-count); when it is translated using a SMT system trained on this same
parallel corpus (SMT); and, when it is translated with a SMT system trained with a par20. Remember that the training corpora contains European Union law and that the evaluation corpus comes
from the European Parliament proceedings.
21. Apertium bilingual dictionaries contain lemma-based bilingual entries which have been expanded to
include all possible inflected forms before adding them to the SMT training data. After inflecting all
the lemma-based bilingual entries the bilingual dictionary added to the SMT training data consists of
(approximately) 1.8 million entries for Spanish–Catalan, 1.2 million entries for Spanish–Galician, and
0.9 million entries for Spanish–Portuguese.

626

Inferring Shallow-Transfer MT Rules from Small Parallel Corpora

es-ca
ca-es
es-gl
gl-es
es-pt

freq.
count
8
14
13
6
25

number
of rules
32 165
17 930
14 764
28 573
5 402

rules
used
8 133
6 785
3 777
4 898
2 636

% used
25.3%
37.8%
25.6%
17.1%
48.8%

% performing
word-for-word
2.77%
2.08%
1.16%
1.51%
1.18%

Table 5: For each translation task, the following data are shown: the frequency count threshold
used, the number of rules generated, the number (and percentage of rules) that are used in the
translation of the corresponding evaluation corpus, and the percentage of rule applications that end
up performing a word-for-word translation. The data reported correspond to the rules obtained
from the training corpora with 2.0 million words in each language.

allel corpus containing the original corpus with 2.0 million words in each language plus the
corresponding Apertium bilingual dictionary (SMT+dictionary).
The results in Table 4 show that, as expected, the SMT results improve when the
bilingual dictionary is added to the training corpus; note however, that the results obtained
for es-ca, ca-es, es-gl, and es-pt are still worse than those achieved by the automatically
inferred rules, although the ca-es “SMT+dictionary” confidence interval shows a large
overlap with that of the automatically inferred rules. The only translation task in which
the “SMT+dictionary” system provides better results than the automatically inferred rules
is the gl-es task, although its confidence interval overlaps with that of the automatically
inferred rules. In all cases the ratio of OOV words for “SMT+dictionary” is below that of
the automatically inferred rules because some words not present in the bilingual dictionary
do appear in the training corpus.
5.2.2 Analysis of the inferred rules
Table 5 shows, for each translation task, the frequency count threshold used in the generation of rules, the number of rules obtained and the number of them that are used in
the translation of the corresponding evaluation corpus; remember that the frequency count
threshold used in each translation task is the one minimizing the TER when translating the
corpora described in Table 1. The data reported in Table 5 correspond to the rules inferred
with the largest training corpora (2.0 million word in each language). Note that the number
of inferred rules varies depending on the translation task; for instance, the number of rules
for es-ca is around twice the number of rules for ca-es, this is because to produce the
minimum TER less rules happen to be needed in the case of ca-es.
The data in Table 5 reveal, on the one hand, that the percentage of rules finally used
to translate the corresponding evaluation corpus varies depending on the translation task,
and, on the other hand, that the percentage of rules that end up applying the “default”
AT (which performs a word-for-word translation, see section 4) depends on the translation
task, although it is always below 3%.
Figure 9 shows for the Spanish-to-Catalan translation, on top, the number of rules
obtained and the number of rules used in the translation of the evaluation corpus, all
627

Sánchez-Martı́nez & Forcada

grouped by rule length (number of SL word classes); and, at the bottom, the number of
rule applications and the number of rule applications that end up performing a word-forword translation (apply the “default” AT); in the generation of the rules a frequency count
threshold of 8 was used. Notice that there are rules of unit length, i.e. rules that process
only a single SL word class: they are needed because the bilingual dictionary leaves some
translation decisions open, such as the gender and number of some words that can be
both masculine and feminine, or singular and plural, in the TL. The data in that figure
correspond to the rules inferred form the largest training corpora used; in any case, with
the rest of training corpora, a similar behaviour is obtained; the same happens with the
remaining translation tasks.
Figure 9 shows that most of the rules generated process SL patterns of only 3 or 4 word
classes; the number of rules processing 7 SL word classes being very low. Remember that
for the extraction of bilingual phrase pairs their length was restricted to 7 SL words.
Finally, it is worth mentioning that the number of inferred rules is very high compared to
the number of hand-coded rules. Note, however, that automatically inferred rules are more
specific and lexicalized than hand-coded ones. Hand-coded rules use macros and complex
control flow statements which allow them to treat more phenomena in the same rule.

6. Discussion
This paper has focused on the inference of structural transfer rules to be used in MT, and
more precisely on the inference of shallow-transfer rules. It describes how to extend the AT
approach introduced in the SMT framework in order to use it to generate shallow-transfer
rules to be used in RBMT. To this end, a very small amount of linguistic information, in
addition to the linguistic data used by the MT engine, has been used in order to learn not
only syntactic changes, but also lexical changes to apply when translating SL texts into TL.
This linguistic information consists of a small set of lexical categories involved in lexical
changes (prepositions, pronouns, etc.) and can easily be provided by an expert.
The approach has been tested using data from three existing language pairs of the
free/open-source shallow-transfer MT engine Apertium; more precisely, the presented approach has been tested on both translation directions of the Spanish–Catalan and Spanish–
Galician languages pairs, and on the Spanish-to-Portuguese translation. For each language
pair, training corpora of different sizes have been used so as to test the importance of the
size of training corpora available.
The evaluation has been done, in all cases, by using independent parallel corpora, coming
from an independent source, with no relation with the parallel corpora used for training. In
the evaluation the translation quality achieved by the automatically inferred rules has been
compared to that of using hand-coded shallow-transfer rules, to that of a word-for-word
translation, and to that of using a state-of-the-art SMT system trained on the same parallel
corpora. In all cases the automatically inferred rules perform better than the SMT system;
moreover, when the Apertium bilingual dictionary is added to the SMT training data only
one translation task performed slightly better than the automatically inferred rules. Notice
that our approach, unlike that by Caseli et al. (2006), is aimed at learning shallow-transfer
rules, not bilingual entries, and that we have used the bilingual dictionary provided by the
corresponding Apertium language-pair package.
628

Inferring Shallow-Transfer MT Rules from Small Parallel Corpora

Rules generated and actually used on the test corpus
12000

rules generated
rules used

Number of rules

10000

8000

6000

4000

2000

0
1

2
3
4
5
6
Rule length (number of SL word classes)

7

Rule applications and applications end up word for word on the test corpus
7000

rule applications
rules perform word-for-word

6000

Number of rules

5000
4000
3000
2000
1000
0
1

2
3
4
5
6
Rule length (number of SL word classes)

7

Figure 9: For the Spanish-to-Catalan translation, rules generated and used in the translation of
the corresponding evaluation corpus (top), and number of rule applications and number of those
applications that end up performing a word-for-word translation (bottom). Reported data are
grouped by rule length (number of SL word classes).

629

Sánchez-Martı́nez & Forcada

The evaluation of the inferred rules for both translation directions of the Spanish–
Catalan and the Spanish–Galician language pairs show an improvement in the translation
quality as compared to word-for-word translation, even when a very small parallel corpus
is used. In the case of the Spanish-to-Portuguese translation, there is a very small improvement: confidence intervals show a large overlap.
To our knowledge, this is the first time that the AT approach is extended for its use in
RBMT; an important property of the inferred rules is that they can be edited by human
experts so as to improve them. This means that developers of RBMT systems can use
this method to obtain a set of initial transfer rules that can be then refined by linguists;
proceeding in this way, human experts can focus on the more difficult issues of writing
accurate transfer rules for MT, as most of the required rules are automatically obtained
from parallel corpora. From our point of view, this is a great advantage over other corpusbased approaches to MT, such as SMT, because, in our approach, automatically generated
rules can coexist with hand-coded ones.
With respect to the parallel corpus used for training, the results achieved by the inferred
rules for the Spanish-to-Portuguese translation show that the procedure followed to build
the parallel corpus, that is, the way in which the translation from one language into the
other one is performed, deserves special attention. In our opinion, it may be concluded
that parallel corpora that have been built by translating from a third language may not be
appropriate for the task of inferring rules to be used in RBMT, especially if the languages
involved are closely related and the third language is not.
It must be mentioned that software implementing the method described in this paper has
been released as free/open-source software under the GNU GPL license22 and can be freely
downloaded from http://apertium.sf.net, package name apertium-transfer-tools.
The public availability of the source code ensures the reproducibility of all the experiments
conducted and allows other researchers to improve the approach discussed here, saving
them from having to implement the algorithms all over again. In addition, the method
has been implemented in such a way that it integrates with the Apertium free/open-source
MT platform (see appendix A); this benefits, on the one hand, other research that uses
Apertium as a research platform, and on the other hand, people developing new language
pairs for Apertium.
We plan to improve the generated rules by using linguistic criteria for the extraction
of the bilingual phrase pairs that are generalized to ATs. Note that in the experiments
reported in this paper bilingual phrase pairs are extracted from the training corpus without
worrying whether they are well-formed syntactic constituents or not. We also plan to study
how to use lexicalized categories in a more flexible way. It would be of interest to have
context-dependent lexicalized categories, that is, categories which are lexicalized only in
some contexts, while not in others; this would improve the generalization performed by the
extended ATs and reduce the number of inferred rules.
Another improvement we plan to achieve is the extension of the present approach so
that rules for translation between less-related language pairs can be inferred. Recently, the
transfer in Apertium has been extended to translate between more divergent languages by
splitting the structural transference phase into 3 stages: the first one detects word patterns
22. http://www.gnu.org/licenses/gpl-2.0.html

630

Inferring Shallow-Transfer MT Rules from Small Parallel Corpora

lexical
transfer
l
postmorph.
part-of-speech
morph.
struct.
SL
TL
→
→
→
→
→
→
generator
analyzer
tagger
generator
transfer
text
text
Figure 10: Main modules of the free/open-source shallow-transfer MT engine Apertium used in
the experiments (see appendix A).

called chunks; the second one operates with sequences of chunks; finally, the third one makes
some “finishing” operations within the chunks detected in the first stage. Our approach
could be extended by detecting chunks in the training parallel corpus using linguistic criteria
as mentioned in the previous paragraph, or using the “Marker Hypothesis” (Green, 1979),
as done by Gough and Way (2004), and then extracting ATs based on chunk classes instead
of word classes, as it is done now. In any case, it would be worth testing the method in its
present for the translation between less-related languages by using longer ATs and larger
training corpora.

Acknowledgments
Work funded by the Spanish Ministry of Education and Science and the European Social Fund through research grant BES-2004-4711, by the Spanish Ministry of Industry,
Tourism and Commerce through projects TIC2003-08681-C02-01, FIT340101-2004-3 and
FIT-350401-2006-5, and by the Spanish Ministry of Education and Science through project
TIN2006-15071-C03-01. The authors thank the anonymous referees for suggesting significant improvements to this paper and Francis Tyers for proof-reading it.

Appendix A. The Apertium Machine Translation Platform
This appendix briefly describes the free/open-source shallow-transfer MT engine Apertium23 (Armentano-Oller et al., 2006) used for the experiments. Apertium follows the
shallow-transfer approach shown in Figure 10:
• A morphological analyzer which tokenizes the text in surface forms and delivers, for
each surface form, one or more lexical forms consisting of lemma, lexical category and
morphological inflection information.
• A part-of-speech tagger (categorial disambiguator) which chooses, using a first-order
hidden Markov model (Cutting et al., 1992; Baum & Petrie, 1966), one of the lexical
forms corresponding to an ambiguous surface form.
• A lexical transfer module which reads each SL lexical form and delivers the corresponding TL lexical form by looking it up in a bilingual dictionary.
23. The MT engine, documentation, and linguistic data for different language pairs can be downloaded from
http://apertium.sf.net.

631

Sánchez-Martı́nez & Forcada

• A structural transfer module (parallel to the lexical transfer) which uses a finite-state
chunker to detect patterns, such as “article–noun–adjective”, of lexical forms which
need to be processed for word reorderings, agreement, etc., and then performs these
operations. This is the module that applies the structural transfer rules automatically
inferred from parallel corpora using the method in this paper.
• A morphological generator which delivers a TL surface form for each TL lexical form,
by suitably inflecting it.
• A post-generator which performs orthographic operations such as contractions (e.g.
Spanish de+el → del ) and apostrophations (e.g. Catalan el+institut → l’institut).
The Apertium MT engine is completely independent from the linguistic data used to
translate for a given language pair. Linguistic data is coded using XML-based formats,24
which allows for easy data transformation and maintenance.

References
Alcázar, A. (2005). Towards linguistically searchable text. In Proceedings of BIDE (BilbaoDeusto) Summer School of Linguistics 2005, Bilbao. Universidad de Deusto.
Armentano-Oller, C., Carrasco, R. C., CorbÃ-Bellot, A. M., Forcada, M. L., Ginestı́-Rosell,
M., Ortiz-Rojas, S., Pérez-Ortiz, J. A., Ramı́rez-Sánchez, G., Sánchez-Martı́nez, F., &
Scalco, M. A. (2006). Open-source Portuguese-Spanish machine translation. In Computational Processing of the Portuguese Language, Proceedings of the 7th International
Workshop on Computational Processing of Written and Spoken Portuguese, PROPOR
2006, Vol. 3960 of Lecture Notes in Computer Science, pp. 50–59. Springer-Verlag.
Arnold, D. (2003). Why translation is difficult for computers. In Computers and Translation:
A translator’s guide. Benjamins Translation Library.
Baum, L. E., & Petrie, T. (1966). Statistical inference for probabilistic functions of finite
state Markov chains. The Annals of Mathematical Statistics, 37 (6), 1554–1563.
Brown, P. F., Pietra, S. A. D., Pietra, V. J. D., & Mercer, R. L. (1993). The mathematics
of statistical machine translation: Parameter estimation. Computational Linguistics,
19 (2), 263–311.
Brown, R. D. (1999). Adding linguistic knowledge to a lexical example-based translation
system. In Proceedings of the Eighth International Conference on Theoretical and
Methodological Issues in Machine Translation (TMI-99), pp. 22–32.
Carl, M., & Way, A. (Eds.). (2003). Recent Advances in Example-Based Machine Translation, Vol. 21. Springer.
Caseli, H. M., Nunes, M. G. V., & Forcada, M. L. (2005). LIHLA: A lexical aligner based on
language-independent heuristics. In Anais do V Encontro Nacional de InteligÃa ncia
Artificial (ENIA 2005), pp. 641–650.
24. The XML formats (http://www.w3.org/XML/) for each type of linguistic data are defined through
conveniently-designed XML document-type definitions (DTDs) which may be found inside the Apertium
package.

632

Inferring Shallow-Transfer MT Rules from Small Parallel Corpora

Caseli, H. M., Nunes, M. G. V., & Forcada, M. L. (2006). Automatic induction of bilingual resources from aligned parallel corpora: application to shallow-transfer machine
translation. Machine Translation, 20 (4), 227–245. Published in 2008.
Cicekli, I., & Güvenir, H. A. (2001). Learning translation templates from bilingual translation examples. Applied Intelligence, 15 (1), 57–76.
Cutting, D., Kupiec, J., Pedersen, J., & Sibun, P. (1992). A practical part-of-speech tagger. In Proceedings of the Third Conference on Applied Natural Language Processing.
Association for Computational Linguistics, pp. 133–140.
Efron, B., & Tibshirani, R. J. (1994). An introduction to the Bootstrap. CRC Press.
Gough, N., & Way, A. (2004). Robust large-scale EBMT with marker-based segmentation.
In Proceedings of the 10th International Conference on Theoretical and Methodological
Issues in Machine Translation, pp. 95–104, Baltimore, MD.
Green, T. (1979). The necessity of syntax markers. Two experiments with artificial languages. Journal of Verbal Learning and Behavior, 18, 481–496.
Hutchins, W. J., & Somers, H. L. (1992). An Introduction to Machine Translation. Academic
Press.
Kaji, H., Kida, Y., & Morimoto, Y. (1992). Learning translation templates from bilingual
text. In Proceedings of the 14th Conference on Computational Linguistics, pp. 672–
678. Association for Computational Linguistics.
Knight, K. (1999). A statistical machine translation tutorial workbook. 35 pages. (http:
//www.isi.edu/natural-language/mt/wkbk.rtf).
Koehn, P. (2004). Statistical significance tests for machine translation evaluation. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pp.
388–395.
Koehn, P., Hoang, H., Birch, A., Callison-Burch, C., Federico, M., Bertoldi, N., Cowan, B.,
Shen, W., Moran, C., Zens, R., Dyer, C., Bojar, O., Constantin, A., & Herbst, E.
(2007). Moses: Open source toolkit for statistical machine translation. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL),
demonstration session.
Lavie, A., Probst, K., Peterson, E., Vogel, S., Levin, L., Font-Llitjós, A., & Carbonell,
J. (2004). A trainable transfer-based machine translation approach for languages
with limited resources. In Proceedings of Workshop of the European Association for
Machine Translation (EAMT-2004).
Liu, Y., & Zong, C. (2004). The technical analysis on translation templates. In Proceedings
of the IEEE International Conference on Systems, Man & Cybernetics (SMC), pp.
4799–4803. IEEE.
Menezes, A., & Richardson, S. D. (2001). A best-first alignment algorithm for automatic
extraction of transfer mappings from bilingual corpora. In Proceedings of the ACL
Workshop on data-driven machine translation, pp. 39–46.
633

Sánchez-Martı́nez & Forcada

Mikheev, A. (1996). Unsupervised learning of word-category guessing rules. In Proceedings
of the Thirty-Fourth Annual Meeting of the Association for Computational Linguistics,
pp. 327–333.
Nagao, M. (1984). A framework of a mechanical translation between English and Japanese
by analogy principle. In Elithorn, A., & Banerji, R. (Eds.), Artifical and Human
Intelligence, pp. 173–180. North-Holland.
Och, F. J. (1999). An efficient method for determining bilingual word classes. In EACL’99:
Ninth Conference of the European Chapter of the Association for Computational Lingustics, pp. 71–76.
Och, F. J. (2002). Statistical machine translation: From single-word models to alignment
templates. Ph.D. thesis, RWTH Aachen University. (http://www-i6.informatik.
rwth-aachen.de/publications/download/520/Och--2002.pdf).
Och, F. J. (2003). Minimum error rate training in statistical machine translation. In
41st Annual Meeting of the Association for Computational Linguistics, pp. 160–167,
Sapporo, Japan.
Och, F. J. (2005). Statistical machine translation: Foundations and recent advances. Tutorial
at MT Summit X. (http://www.mt-archive.info/MTS-2005-Och.pdf).
Och, F. J., & Ney, H. (2002). Discriminative training and maximum entropy models for
statistical machine translation. In Proceedings of the 40th Annual Meeting of the
Association for Computational Lingustics (ACL), pp. 295–302.
Och, F. J., & Ney, H. (2003). A systematic comparison of various statistical alignment
models. Computational Linguistics, 29 (1), 19–51.
Och, F. J., & Ney, H. (2004). The alignment template approach to statistical machine
translation. Computational Linguistics, 30 (4), 417–449.
Papineni, K., Roukos, S., Ward, T., & Zhu, W. J. (2002). BLEU: a method for automatic evaluation of machine translation. In Proceeding of 40th Annual meeting of the
Association for Computational Linguistics, pp. 311–318.
Probst, K., Levin, L., Peterson, E., Lavie, A., & Carbonell, J. (2002). MT for minority
languages using elicitation-based learning of syntactic transfer rules. Machine Translation, 17 (4), 245–270.
Sánchez-Martı́nez, F., & Forcada, M. L. (2007). Automatic induction of shallow-transfer
rules for open-source machine translation. In Proceedings of the 11th Conference on
Theoretical and Methodological Issues in Machine Translation (TMI 2007), pp. 181–
190.
Sánchez-Martı́nez, F., & Ney, H. (2006). Using alignment templates to infer shallow-transfer
machine translation rules. In Lecture Notes in Computer Science 4139, Proceedings of
FinTAL, 5th International Conference on Natural Language Processing, pp. 756–767.
Sánchez-Martı́nez, F., Pérez-Ortiz, J. A., & Forcada, M. L. (2008). Using target-language
information to train part-of-speech taggers for machine translation. Machine Translation, 22 (1-2), 29–66.
634

Inferring Shallow-Transfer MT Rules from Small Parallel Corpora

Simões, A., & Almeida, J. (2003). NATools - a statistical word aligner workbench. Procesamiento del Lenguaje Natural, 31, 217–224.
Snover, M., Dorr, B., Schwartz, R., Micciulla, L., & Makhoul, J. (2006). A study of translation edit rate with targeted human annotation. In Proceedings of the 7th Conference
of the Association for Machine Translation in the Americas, “Visions for the Future
of Machine Translation”, pp. 223–231, Cambridge, MA, USA.
Steinberger, R., Pouliquen, B., Widiger, A., Ignat, C., Erjavec, T., Tufis, D., & Varga, D.
(2006). The JRC-Acquis: A multilingual aligned parallel corpus with 20+ languages.
In Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC).
Stolcke, A. (2002). SRILM – an extensible language modeling toolkit. In Proceedings of the
International Conference on Spoken Language Processing, pp. 901–904, Denver, CO.
Tyers, F. M., Dugast, L., & Park, J. (2009). Rule-based augmentation of training data
in Breton–French statistical machine translation. In Proceedings of the 13th Annual
Conference of the European Associtation for Machine Translation, Barcelona, Spain.
In press.
Vogel, S., Ney, H., & Tillmann, C. (1996). HMM-based word alignment in statistical translation. In COLING ’96: The 16th International Conference on Computational Linguistics, pp. 836–841.
Zens, R., Och, F. J., & Ney, H. (2002). Phrase-based statistical machine translation. In KI
2002: Advances in Artificial Intelligence: Proceedings 25th Annual German Conference
on AI, Vol. 2479 of Lecture Notes in Computer Science, pp. 18–32. Springer-Verlag.

635

Journal of Artificial Intelligence Research 34 (2009) 757–821

Submitted 11/08; published 04/09

Conservative Inference Rule
for Uncertain Reasoning under Incompleteness
Marco Zaffalon

zaffalon@idsia.ch

Galleria 2
IDSIA
CH-6928 Manno (Lugano), Switzerland

Enrique Miranda

mirandaenrique@uniovi.es

Department of Statistics and Operations Research
University of Oviedo
C-Calvo Sotelo, s/n
33007 Oviedo, Spain

Abstract
In this paper we formulate the problem of inference under incomplete information in
very general terms. This includes modelling the process responsible for the incompleteness,
which we call the incompleteness process. We allow the process’ behaviour to be partly
unknown. Then we use Walley’s theory of coherent lower previsions, a generalisation of the
Bayesian theory to imprecision, to derive the rule to update beliefs under incompleteness
that logically follows from our assumptions, and that we call conservative inference rule.
This rule has some remarkable properties: it is an abstract rule to update beliefs that can be
applied in any situation or domain; it gives us the opportunity to be neither too optimistic
nor too pessimistic about the incompleteness process, which is a necessary condition to
draw reliable while strong enough conclusions; and it is a coherent rule, in the sense that it
cannot lead to inconsistencies. We give examples to show how the new rule can be applied
in expert systems, in parametric statistical inference, and in pattern classification, and
discuss more generally the view of incompleteness processes defended here as well as some
of its consequences.

1. Introduction
We consider a very general inference problem: we want to draw conclusions Z from the
observation of facts Y . Here Z and Y are variables that are related, in the sense that
observing the value y of Y in Y may change our beliefs about which value z the target
variable Z assumes in Z.1
Although apparently simple, the above setting already captures the main features of
many important problems, such as making inference in expert systems, learning the values
of some statistical parameters from data, learning from data how to classify new objects
into one out of a set of preestablished categories (i.e., doing so-called pattern classification),
and others.
1. Throughout the paper, we shall maintain the convention of using capital letters for variables, the corresponding calligraphic letters for their spaces of possibilities, and lower-case letters for the elements of
such spaces.
c
2009
AI Access Foundation. All rights reserved.

Zaffalon & Miranda

(V )isit to Asia

Smo(K)ing

+

?

Tu(B)erculosis

Lung cance(R)

s

Bronc(H)itis

s +

B (O)r R

+

s=

Abnorma(L) X-rays

Dyspne(A)

Figure 1: The Bayesian network called Asia. The letters in parentheses denote the variables
corresponding to the nodes. Each variable, say X, is binary with states x0 for
‘yes’ and x00 for ‘no’.

Let us make this more concrete with the help of the graphical language of Bayesian
networks (Pearl, 1988):2 consider the well-known ‘Asia’ net displayed in Figure 1, which
is intended to model an artificial medical problem. The nodes of a Bayesian network are
variables and the arcs model probabilistic dependencies between them; each node holds the
probability distribution of the node itself given any joint state of the parent nodes. The
probabilities making up these distributions are also called the parameters of the network.
Now, if we assume that the network (both the graph and the parameters) is provided
by a domain expert, then we are in the field of expert systems. Say that the network is
used for diagnosing lung cancer; in this case R is the target node while the others are used
to predict the value of R. Therefore in this case Z corresponds to R and Y is the vector
(V, K, B, H, O, L, A). In another situation, we may want to infer some of the parameters
from data. For example, denote by Θ the chance that there is tuberculosis conditional on
a recent visit to Asia, and say that there is a sample D of joint values of B and V from
which we wish to infer the value of Θ. In this problem of so-called parametric inference,
Z corresponds to Θ and Y to the sample D. Finally, say that our goal is to use the Asia
net to learn from data how to diagnose lung cancer, i.e., to predict the state of R for the
next patient we see, whom we characterise by the vector (V, K, B, H, O, L, A). In this case
2. The results in the present paper are not restricted to the case of Bayesian networks, but since they can
be applied to Bayesian networks, we often use them to convey the intuition more easily.

758

Conservative Inference Rule

we need to collect, in a data set D, the values of all the variables in the network for the
past patients. This data set is exploited to infer the parameters of the Asia net, which is
then used for classification by predicting the value of R as in the case of expert systems.
Therefore, when the focus is on pattern classification, Z corresponds to the so-called class
variable, namely R, while Y is the tuple (D, V, K, B, H, O, L, A).
The common feature of all the previous examples is that observing Y is useful for
inferring Z, and indeed this is the reason why Y has been introduced in the model. But
there is a subtle point about observing Y that is important to realise: very often, the
observation of a fact does not coincide with the fact itself. For example, consider again the
Asia network, focusing on the problem of parametric inference: in this case, it may well
happen that we make mistakes while collecting the values of B and V in a sample; we might
for instance mix up some ‘yes’ values with ‘no’ values. It is useful to regard this situation as
related to two levels of information: the latent level of the actual sample that records the
right values of the variables, and the manifest level of the observed sample, which is related
to, but does not necessarily coincide with the actual sample, and which is going to be used
for the inference. We can exploit the paradigm based on the latent and the manifest level
more generally as a powerful conceptual tool. For instance, when we use the Asia network
as an expert system, it may be the case that for a certain patient characterised by the vector
of values (v 0 , k 00 , b00 , h00 , o0 , l0 , a0 ), it is only possible to access the values of the variables H and
A. Therefore our observation of the characteristics of the patient will be (?, ?, ?, h00 , ?, ?, a0 ),
where we denote the symbol of missing value by a question mark. Again, we can think of
the former vector as latent and the latter as manifest. More generally speaking, the idea
underlying the present discussion is that the devices that we use to observe Y , whatever
they are, may not let us see Y exactly as it is.
In order to account for this problem, we explicitly model the observation of Y by a
new variable W , taking values in a finite set W of possible observations. We call W the
observation of Y . In our previous terminology, W is a manifest variable while Y is a latent
one. In other words, we regard W as the output of the process of observing facts, which
is called the observational process in this paper (other authors call it the measurement
process). We can think of many different types of observational processes. In this paper
we restrict the attention to the special case of observational processes called incompleteness
processes (IPs). IPs are processes that lead to set-valued observations by coarsening facts.
A special case of IPs are missingness processes, i.e., those that turn some facts into their
entire possibility space.
For example, the process that prevented some of the variables from being observed in
the expert system case is a coarsening process: it has turned the fact (v 0 , k 00 , b00 , h00 , o0 , l0 , a0 )
into the observation (?, ?, ?, h00 , ?, ?, a0 ), which can be regarded as the set of the 25 complete
vectors obtained by replacing the question marks with values of the unobserved variables
in all the possible ways. On the other hand, if we take the fact under consideration to be
a single variable, say V , then the process that makes V not observed is just a missingness
process as writing a question mark is equivalent to writing the entire possibility space for
such a variable.3
3. With IPs it makes sense to introduce the additional variable W even only because the incomplete
observations are not in the possibility space for Y ; in the case of the Asia net, this happens because

759

Zaffalon & Miranda

Missing or coarsened data are indeed a commonplace with expert systems, because
the evidence on which an inference task is based is usually incomplete. But they arise
frequently also in many other fields; in data mining, just to mention one, missing data are
a pervasive problem in applications as well as an important theoretical area of research. In
other words, the challenges posed by IPs are widespread. This also means that the problem
of incomplete information appears to be a fundamental component of the general task of
uncertain reasoning; it is conceptually deep and leads to complicated problems in practice.
Moreover, while we have powerful theoretical tools for the general task of uncertain
reasoning, such as Bayes rule and its generalisations, there are few tools for uncertain
reasoning under incompleteness in the general case. Currently, the most popular approach
is based on the assumption that the IP produces incompleteness by coarsening facts at
random, which means non-selectively. The assumption that models non-selectiveness is
called coarsening at random (or CAR, see Gill et al., 1997), or missing at random (or
MAR, see Little & Rubin, 1987) in the special case of missingness processes (see also Jaeger,
2008). CAR implies that the incompleteness is non-informative and can be ignored; it thus
creates the formal basis for applying the methods developed for complete information to
the incomplete case. For example, if we assume that the vector (?, ?, ?, h00 , ?, ?, a0 ) has been
created by a CAR IP, then we are allowed to infer the value of R on the sole basis of the subvector (h00 , a0 ); more precisely, if we aim at computing the posterior probability of R = r0 ,
CAR allows us to write P (R = r0 |W = (?, ?, ?, h00 , ?, ?, a0 )) = P (R = r0 |H = h00 , A = a0 ).
But this is not the case in general.
In fact, incompleteness may well be informative. For example, in the Asia network, it
may be the case that the information on whether or not a person has been to Asia is not
provided with the same frequency in the two groups. This is an example of incompleteness
generated within a communication protocol, where giving or not some information is a key
part of the communication. This somewhat selective way of reporting information, albeit
very frequent, is not compatible with the CAR assumption. This was pointed out long ago
by Shafer (1985), who also has outlined the implications as well as the complications for
uncertain reasoning: among these, the fact that modelling IPs can be a very difficult task.
More recently, it has been used to argue against the frequent use of CAR (Grünwald &
Halpern, 2003); by now there is a large agreement in the scientific community that CAR is
strong, and hence inappropriate in many situations (see Manski, 2003).
De Cooman and Zaffalon (2004) tried to remedy this by an approach to IPs alternative
to CAR that is based on coherent lower previsions (Walley, 1991), i.e., closed convex sets
of probabilities also called credal sets by Levi (1980). This has led to a rule for updating
beliefs under incomplete information in expert systems called the conservative updating rule
(CUR).
If we regard CAR as the most optimistic approach to incomplete information, CUR
should be regarded as the most pessimistic: it does not assume nearly anything about
the IP, and in practice it leads to inference based on working with the set of all facts
consistent with (i.e., all the completions of) the incomplete information at hand. In
the previous example in which we wish to compute the posterior probability of R = r0 ,
CUR leads us to consider all the 25 completions of the vector (?, ?, ?, h00 , ?, ?, a0 ), i.e.,
the symbol ‘?’ is not a possible value for any variable; observations that contain question marks must
necessarily be in the possibility space of W .

760

Conservative Inference Rule

(v, k, b, h00 , o, l, a0 ), v ∈ V, k ∈ K, b ∈ B, o ∈ O, l ∈ L, and to compute for each of
them P (r0 |v, k, b, h00 , o, l, a0 ). The posterior inference is then summarised by the lower and
upper probabilities P (R = r0 |W = (?, ?, ?, h00 , ?, ?, a0 )) := minv,k,b,o,l P (r0 |v, k, b, h00 , o, l, a0 )
and P (R = r0 |W = (?, ?, ?, h00 , ?, ?, a0 )) := maxv,k,b,o,l P (r0 |v, k, b, h00 , o, l, a0 ). In other words,
the inference is imprecise, i.e., the width of the interval determined by the lower and upper probabilities does not need to be zero, as a logical consequence of the ignorance CUR
assumes about the IP. As an interesting side remark, CUR is as flexible as CAR in dealing
with incomplete data: both of them eventually lead to conclusions that depend only on the
Y variable. The W variable at a certain point of the derivation cancels out.
CUR has some drawbacks. It forces us to always assume ignorance about the IP, even
when we know that the process is CAR, for instance. This could be the case of the previous
example in which we might know that the variables B, O, L are subject to a CAR IP; by
using CUR we should be obliged to ignore this information and take all of their completions,
as above; and this would lead to inference that is much too weak. Furthermore, CUR has
been developed for expert systems only. It cannot be applied to parametric inference when
the parameter space is infinite, and some other limitation in the assumptions leading to
CUR may sometimes prevent it from being applied more generally.
This paper is an attempt to get the best out of CAR and CUR. We assume that the IP
is actually made of two parts, one that acts as a CAR process and another that is unknown
to us. Then we use the theory of coherent lower previsions to derive the corresponding rule,
which we call the conservative inference rule (CIR).
CIR has the following properties:
• Much like traditional, CAR-based, updating, and unlike CUR, it is a rule for the
abstract task of updating beliefs on the basis of observations. As such, it can be
applied in every situation. With CIR, different applications follow by simply giving
different meanings to facts Y , observations W , and to the quantity Z in which we are
interested.
• CIR allows all the variables involved in an analysis, except for W and Y , to take values
from infinite spaces (CUR allows only finite spaces). This allows us to easily focus
on statistical problems where the goal of inference is often the value of a continuous
parameter, or in problems where we also use auxiliary continuous variables that are
later ‘marginalised’ out to build our model.
• It can deal with incomplete observations, not only missing ones as CUR.
• Finally, and importantly, CIR is shown to lead to self-consistent (or coherent) inference
in the strong sense of Walley (1991, Section 7.1.4(b)).
CIR leads to treat the information made incomplete by the CAR IP similarly to the traditional updating, and that subject to the unknown one similarly to CUR. As an example, consider again the vector (?, ?, ?, h00 , ?, ?, a0 ) by assuming that the variables B, O, L are subject
to a CAR IP and V, K to an IP whose behaviour is unknown to us. CIR leads to the following
posterior lower and upper probabilities for R = r0 : P (R = r0 |W = (?, ?, ?, h00 , ?, ?, a0 )) :=
minv,k P (r0 |v, k, h00 , a0 ) and P (R = r0 |W = (?, ?, ?, h00 , ?, ?, a0 )) := maxv,k P (r0 |v, k, h00 , a0 ).
If, in addition, we know that only two completions of V, K make sense, say (v 0 , k 00 ) and
761

Zaffalon & Miranda

(v 00 , k 0 ) (this means that the unknown IP is a coarsening rather than a missingness process),
the ability of CIR to deal with coarsening processes allows it to take advantage of such an
information, leading to the more informative lower and upper probabilities obtained optimising only over those two completions. Furthermore, CIR leads to inference that is based,
as its predecessors, only on facts, not on the W variable.
The organisation of the material in this paper follows an attept to make the paper accessible also to the readers that prefer not to go into the formal proofs behind CIR. In
particular, the paper is logically divided in two parts. The first part, up to and including
Section 5, is intended to describe what can be obtained by CIR and its scope of application. Therefore this part briefly gives some introductory material that is needed to define
CIR, such as some notions of coherent lower previsions in Section 2 and of incompleteness
processes in Section 3. The definition of CIR is given in Section 4. We discuss its significance and compare it with CUR in Section 4.1. Then we show how CIR can be applied to
probabilistic expert systems (Section 5.1), parametric inference (Section 5.2), and pattern
classification (Section 5.3), each time giving also an example. In this first part we also discuss a number of properties and consequences of the wider view of IPs that we are defending
here (e.g., Sections 5.2.2–5.2.3). Some of these (Section 5.3.2) are particularly important
for data mining; this depends on the fact that it is usually not possible to learn about the
IP from data, and yet the inferences we do may critically depend on it.
The second part of this paper is more technical as it works out the foundations of CIR.
To this aim, we first give advanced notions about coherent lower previsions in Section 6,
such as updating, independence, and coherence in the sense of Walley (1991). Then we
state a number of probabilistic assumptions in Section 7.1, including CAR, discuss them in
Section 7.2 (CAR is also discussed further in Appendix A) and derive CIR in Section 7.3.
The parts that are even more technical, and which are needed to show that applying CIR
cannot lead to inconsistencies, are relegated to Appendix B.

2. Coherent Lower Previsions
We give a short introduction to the concepts and results from the behavioural theory of
imprecise probabilities that we shall need to introduce the conservative inference rule. We
refer the reader to the work of Walley (1991) for an in-depth study of coherent lower
previsions, and to the paper by Miranda (2008) for a survey of the theory.
Consider a possibility space Ω. It may represent for instance the set of possible outcomes
ω of an experiment. In the theory of coherent lower previsions, the beliefs about the
likelihood of these outcomes are represented by means of lower previsions of gambles on Ω:
Definition 1 Given a possibility space Ω, a gamble is a bounded real-valued function on
Ω. The set of all gambles on Ω is denoted by L(Ω). A lower prevision P is a real functional
defined on some set of gambles K ⊆ L(Ω).
A gamble f represents a random reward, which depends on the a priori unknown value ω
of Ω. A lower prevision P on a set of gambles K represents a subject’s supremum acceptable
buying prices for these gambles, in the sense that for all  > 0 and all f in K, the subject
is disposed to accept the uncertain reward f − P (f ) + , where P (f ) and  can also be seen
762

Conservative Inference Rule

as constant gambles that are identically equal to the real values P (f ) and , respectively.4
Intuitively, lower previsions represent lower expectations of gambles: our subject should be
disposed to buy a gamble for anything smaller than the expected reward; however, his lack
of knowledge about the probability of the different rewards may enable him only to give a
lower bound for this expectation, accepting then any buying price smaller than this bound.
The bound is his lower prevision for the gamble.
We shall use IA to denote a special type of gamble: the indicator function of the set A,
i.e., the function whose value is 1 for the elements of A and 0 elsewhere. We shall sometimes
use the notation P (A) for the lower prevision P (IA ) when no confusion is possible.
Consider variables X1 , . . . , Xn , taking values in the sets X1 , . . . , Xn , respectively. For
any subset J ⊆ {1, . . . , n} we shall denote by XJ the (new) variable
XJ := (Xj )j∈J ,
which takes values in the product space
XJ := ×j∈J Xj .
We shall also use the notation X n for X{1,...,n} . We identify the possibility space Ω with
X n.
Definition 2 Let J be a subset of {1, . . . , n}, and let πJ : X n → XJ be the so-called
projection operator, i.e., the operator that drops the elements of a vector in X n that do
not correspond to indexes in J. A gamble f on X n is called XJ -measurable when for all
x, y ∈ X n , πJ (x) = πJ (y) implies that f (x) = f (y). We shall denote by KJ the set of
XJ -measurable gambles.
This notion means that the value f takes depends only on the components of x ∈ X n
that belong to the set J.5
There is a one-to-one correspondence between the XJ -measurable gambles on X n and
the gambles on XJ : given an XJ -measurable gamble f on X n , we can define f 0 on XJ by
f 0 (x) := f (x0 ), where x0 is any element in πJ−1 (x); conversely, given a gamble g on XJ , the
gamble g 0 on X n given by g 0 (x) := g(πJ (x)) is XJ -measurable.
Let O be a subset of {1, . . . , n}, and let P (XO ) be a lower prevision on the set KO
of XO -measurable gambles. We say that P is coherent if and only if the following three
conditions hold for all f, g ∈ KO , and λ > 0:
(C1) P (f ) ≥ inf f .
(C2) P (λf ) = λP (f ).
4. We say then that the gamble f − P (f ) +  is desirable for our subject, and that f − P (f ) is almostdesirable. It follows from this interpretation that the set of desirable (resp., almost-desirable) gambles
should be closed under addition and multiplication by non-negative reals, and that a gamble f that
dominates a desirable gamble g should also be desirable (resp., almost-desirable).
5. This notion is related to the common notion of measurability as it implies that the gamble f : X n → R
is indeed a measurable mapping if we consider the σ-field {πJ−1 (A) : A ⊆ XJ } on the initial space and
any σ-field in the final space.

763

Zaffalon & Miranda

(C3) P (f + g) ≥ P (f ) + P (g).
Coherence means that a subject cannot raise the lower prevision P (f ) of a gamble by
considering the acceptable buying transactions that are implied by other gambles in the
domain.
Remark 1 (Coherent upper previsions) Although for most of the paper we shall work
with coherent lower previsions, or supremum acceptable buying prices, we shall also use at
times the so-called coherent upper previsions. The upper prevision of a gamble f , P (f ),
represents the infimum acceptable selling price for f for our subject, in the sense that for
any  > 0 the transaction P (f ) − f +  is desirable for him.
Taking into account this interpretation, it follows that the upper and lower previsions
must be conjugate functions, in the sense that P (f ) = −P (−f ) for all gambles f . This is
why we shall work almost exclusively with lower previsions, and use upper previsions only
to refer to their conjugate functions when this helps to simplify the notation. Finally, we
say that an upper prevision is coherent if so is its conjugate lower prevision. ♦
It is important at this point to introduce a particular case of coherent lower previsions
that will be of special interest for us: linear previsions.
Definition 3 A lower prevision P (XO ) on the set KO is linear if and only if it is coherent
and P (f + g) = P (f ) + P (g) for all f, g ∈ KO .
Linear previsions correspond to the case where a subject’s supremum acceptable buying
price (lower prevision) coincides with his infimum acceptable selling price (or upper prevision) for every gamble on the domain. When a coherent lower prevision P (XO ) is linear,
we denote it by P (XO ). A linear prevision corresponds to the expectation operator (with
respect to the Dunford integral, see the book by Bhaskara Rao & Bhaskara Rao, 1983) with
respect to a finitely additive probability.
One interesting feature of linear previsions allows us to easily characterise coherence.
Definition 4 P (XO ) is said to dominate P (XO ) if P (f ) ≥ P (f ) for every XO -measurable
gamble f .
A lower prevision P (XO ) is coherent if and only if it is the lower envelope of a closed6
and convex7 set of dominating linear previsions, which we denote by M(P (XO )). It follows
also that P (XO ) is the lower envelope of the set of extreme points of M(P (XO )). We denote
the set of extreme points of M(P (XO )) by ext(M(P (XO )).
Example 1 Assume that our subject has the information that the outcome of the variables
in XO belongs to some finite subset A of XO , and nothing more. Then he should model these
beliefs by the so-called vacuous lower prevision P A (XO ) given by P A (f ) := minω∈A f (ω)
for every f ∈ KO . The set M(P A (XO )) of dominating linear previsions corresponds to the
6. In the weak* topology, which is the smallest topology for which all the evaluation functionals given by
f (P ) := P (f ), where f ∈ L(Ω), are continuous.
7. That is, for all linear previsions P1 , P2 in the set and all α ∈ (0, 1), the linear prevision αP1 + (1 − α)P2
also belongs to this set.

764

Conservative Inference Rule

finitely additive probabilities P (XO ) satisfying the constraint P (A) = 1. Among these, the
extreme points are the degenerate probability measures with respect to some ω ∈ A, and it
follows that any linear prevision in M(P A (XO )) is a convex combination of these. ♦
Consider now two disjoint subsets O, I of {1, . . . , n}, with O 6= ∅. P (XO |XI ) represents
a subject’s behavioural dispositions about the gambles that depend on the outcome of the
variables {Xk , k ∈ O}, after coming to know the outcome of the variables {Xk , k ∈ I}. As
such, it is defined on the set of gambles that depend on the values of the variables in O ∪ I
only,8 i.e., on the set KO∪I of the XO∪I -measurable gambles on X n . Given such a gamble f
and x ∈ XI , P (f |XI = x) represents a subject’s supremum acceptable buying price for the
gamble f , if he came to know that the variable XI took the value x (and nothing else). We
can thus consider the gamble P (f |XI ) on XI , that on x ∈ XI takes the value P (f |XI = x).
Definition 5 The functional P (·|XI ) that maps a gamble f in its domain KO∪I to the
gamble P (f |XI ) is called a conditional lower prevision.
This definition is well posed as the sets {πI−1 (x) : x ∈ XI } form a partition of X n . When
there is no possible confusion about the variables involved in the lower prevision, we shall
use the notation P (f |x) for P (f |XI = x). In particular, P (y|x) will mean P (Iy |x) for all
pairs of values x, y.
In Walley’s theory a conditional lower prevision P (XO |XI ) defined on KO∪I is required to
be self-consistent, or separately coherent. Separate coherence means on the one hand that if
a subject knows that the variable XI has taken the value x, he cannot raise the (conditional)
lower prevision P (f |x) of a gamble by considering the acceptable buying transactions that
are implied by other gambles in the domain, and on the other hand that he should bet at
any odds on the event that XI = x after having observed it.
In this case, where the domain is a linear set of gambles, the definition is the following:
Definition 6 The conditional lower prevision P (XO |XI ) is separately coherent if and only
if for all x ∈ XI , f, g ∈ KO∪I , and λ > 0:
(SC1) P (f |x) ≥ inf ω∈π−1 (x) f (ω).
I

(SC2) P (λf |x) = λP (f |x).
(SC3) P (f + g|x) ≥ P (f |x) + P (g|x).
Using these conditions, we see more clearly that a separately coherent conditional lower
prevision can also be regarded as a lower bound for a conditional expectation. It also follows
that if I = ∅, separate coherence coincides with the notion of coherence introduced above.
Given a separately coherent conditional lower prevision P (XO |XI ) with domain KO∪I ,
we can see P (XO |x) as defined on the set of XO -measurable gambles, because for any f ∈
KO∪I , P (f |x) = P (g|x), where g is the XO -measurable gamble given by g(w) = f (πI c (w), x)
for all w ∈ X n .
8. We refer to the work by Miranda and De Cooman (2005) and Walley (1991) for more general definitions
of the following notions in this section in terms of partitions, and for domains that are not necessarily
(these) linear sets of gambles.

765

Zaffalon & Miranda

As with the unconditional case, we can also consider conditional upper previsions, which
represent our subject’s infimum acceptable selling prices for the gambles f in KO∪I , after
coming to know the value of the variables in XI (and nothing else). We have P (f |x) =
−P (−f |x) for all gambles f . Similarly, a conditional lower prevision P (XO |XI ) on the
set KO∪I is linear if and only if it is separately coherent and P (f + g|x) = P (f |x) +
P (g|x) for all x ∈ XI and f, g ∈ KO∪I . Conditional linear previsions correspond to the
case where a subject’s supremum acceptable buying price (lower prevision) coincides with
his infimum acceptable selling price (or upper prevision) for every gamble in the domain.
When a separately coherent conditional lower prevision P (XO |XI ) is linear, we denote it
by P (XO |XI ).
A conditional lower prevision P (XO |XI ) dominates P (XO |XI ) if P (f |x) ≥ P (f |x)
for every XO∪I -measurable gamble f and every x ∈ XI . A conditional lower prevision
P (XO |XI ) is separately coherent if and only if it is the lower envelope of a closed and
convex set of dominating conditional linear previsions, which we denote by M(P (XO |XI )).
This is a bit of an abuse of notation, since actually for every x ∈ XI the set M(P (XO |x))
is a set of linear previsions. It follows also that P (XO |XI ) is the lower envelope of the set
of extreme points of M(P (XO |XI )), where we say that P (XO |XI ) is an extreme point of
M(P (XO |XI )) when for every x ∈ XI , P (XO |x) is an extreme point of the closed convex set
M(P (XO |x)). We denote the set of extreme points of M(P (XO |x)) by ext(M(P (XO |x))).
Example 2 Consider the following experiment: a subject throws a coin; if it lands on heads,
he selects a ball from an urn with red and white balls of unknown composition; if it lands on
tails, he selects a ball from an urn with red and blue balls also of unknown composition. Let
X1 be the result of the first experiment, with values in {heads, tails}, and X2 be the color
of the ball drawn in the second experiment, with values in {red, white, blue}.
We may model this using the conditional prevision P (X2 |X1 ) where P (X2 |X1 = heads)
is vacuous on {red, white}, and P (X2 |X1 = tails) is vacuous on {red, blue}. The extreme
points of M(P (X2 |X1 )) are the conditional previsions P (X2 |X1 ), where P (X2 |heads) is
degenerate on either red or white, and P (X2 |tails) is degenerate on either red or blue. ♦

3. The Basic Setting
In this section we introduce the basic assumptions about the spaces considered in our model
and about the incompleteness process.
3.1 The Domain
As we mentioned in the Introduction, in this paper we consider the problem of drawing
conclusions about the value that a target variable Z takes in Z from information about of
the value that another variable Y takes in a set Y. In this paper we shall assume that the
set Y is finite, but the set Z of possible values for the target variable Z can be infinite.
3.2 The Incompleteness Process
It is not uncommon that the devices that we use to get information about Y , whatever they
are, may not let us see Y exactly as it is. Because of this, we explicitly model the observation
766

Conservative Inference Rule

of Y by a new variable W , taking values in the finite set W of possible observations. We call
W the observation of Y . W represents the outcome of the observational process. In this
paper we focus on the observational processes called incompleteness processes, which can
not only turn a fact into its entire possibility space, but also into other nonempty subsets
of the possibility space.
Remark 2 (Concerning the W variable) We remark that it is necessary to introduce
the variable W even if it is quite a common habit in applications to deal only with the
variables Z and Y . The possibility to drop W depends on the assumptions done. For
instance, if we assume CAR/MAR then the W variable at a certain point of the derivation
cancels out, leading to formulae that only involve Z and Y . But one should not confuse
the operational procedures with the theoretical representation needed for the derivation of a
rule. The theoretical derivation has to take into account that the latent level of information,
represented by Y , does not need to coincide with the manifest level, namely W , and hence
that we need to model the process that leads from Y to W . This is also necessary because
there are assumptions other than those made in this paper that do not lead eventually to
drop W . Moreover, the distinction between the latent and the manifest level is not a new
proposal at all: on the contrary, it is present, somewhat implicitly, even in the original works
about MAR (Little & Rubin, 1987) and fully explicitly in more recent works (Grünwald &
Halpern, 2003).♦
We focus now on representing the IP. We start by characterising the IP for Y by a so-called
multi-valued map ΓY (this idea of modelling the IP through a multi-valued map goes back
essentially to Strassen, 1964). ΓY is what connects facts with observations: for all y ∈ Y,
ΓY gives us the set Γ(y) ⊆ W of observations into which the IP may turn fact y. We require
such a set to be nonempty:
y ∈ Y ⇒ Γ(y) 6= ∅.
(IP1)
Take for example the Asia network. If the fact under consideration is the instance y :=
(v 0 , k 00 , b00 , h00 , o0 , l0 , a0 ) of the vector (V, K, B, H, O, L, A), taken to be equal to Y , then Γ(y)
represents the set of all the incomplete instances that may be generated by the IP starting
from y. For instance, the IP may be such that Γ(y) is equal to the set of 27 incomplete
instances obtained from (v 0 , k 00 , b00 , h00 , o0 , l0 , a0 ) by giving the possibility to replace the values
in the vector with question marks in all the possible ways.
ΓY makes it possible to associate, to each observation w ∈ W, the set of facts that may
originate it: i.e.,
{w}∗ := {y ∈ Y : w ∈ Γ(y)}.
In the Asia network, our observation might be w = (?, ?, ?, h00 , ?, ?, a0 ). If Γ(y) is defined
as above, then {w}∗ is the set of the 25 completions of (?, ?, ?, h00 , ?, ?, a0 ). Γ(y) might also
be defined differently, for instance by allowing only for some replacements of values in the
vector y with question marks (the possibility to replace values with question marks might
also depend on the values that some variables in the vector take jointly). In this case
{w}∗ would be a subset of the 25 completions. What is important is that the set {w}∗
does not allow us to identify the value of Y uniquely, unless it is a singleton. This tells
us that IPs are observational processes that produce W by coarsening Y , i.e., by yielding
an observation w corresponding to a set {w}∗ of possible values for Y that we expect to
767

Zaffalon & Miranda

encompass y (this expectation will be formalised in Section 7.1.2). It follows that IPs
are a generalisation of the, perhaps more popular, missingness processes, which consider
only two possibilities: either {w}∗ is a singleton or it is Y, in which case Y is said to be
missing. In the case of the Asia net, we could characterise a missingness process by writing
Γ(y) = {(v, k, b, h, o, l, a), (?, ?, ?, ?, ?, ?, ?)} for all y = (v, k, b, h, o, l, a) ∈ Y.9 If {w}∗ = ∅,
w cannot be produced by any y ∈ Y, and can therefore be eliminated from W without any
further consequences; we shall henceforth assume that
w ∈ W ⇒ {w}∗ 6= ∅.

(IP2)

Finally, we define for each w ∈ W the set of facts of which w is the only compatible
observation:
{w}∗ := {y ∈ Y : Γ(y) = {w}}.
3.3 Refining Facts, Observations, and the Incompleteness Process
In this section, we add some structure to the incompleteness process by representing it as
the combination of two different incompleteness processes, which act on different parts of
a fact. We model these two parts by writing Y := (Ȳ , Ŷ ), where Ȳ and Ŷ are two new
variables, with values in Ȳ and Ŷ, respectively, such that Y = Ȳ × Ŷ. In an analogous way,
we regard the observation W of Y as the observation W̄ of Ȳ jointly with the observation
Ŵ of Ŷ , and hence write W := (W̄ , Ŵ ). Here again, W̄ and Ŵ are two new variables, with
values in W̄ and Ŵ, respectively, such that W = W̄ × Ŵ.
The additional variables introduced indeed allow us to think of two new IPs: the first acts
on variable Ȳ , leading to observation W̄ , and thus is characterised by a certain multi-valued
map ΓȲ ; the second acts on variable Ŷ , leading to observation Ŵ , and is characterised by
another multi-valued map ΓŶ . We call them the unknown IP and the CAR IP, respectively,
as by the former we aim at modelling an IP whose behaviour is unknown to us and by the
latter a CAR IP.
Assuming that
y ∈ Y ⇒ Γ(y) = Γ(ȳ) × Γ(ŷ)
(IP3)
allows us to regard the two IPs, taken together, as the single incompleteness process introduced in Section 3.2, i.e., the one that maps (Ȳ , Ŷ ) = Y into (W̄ , Ŵ ) = W . From now on,
we call this the overall IP. Assumption (IP3) follows as a consequence of our intention to
model problems where there are two IPs which observe different parts of a fact and therefore
do not interact. This is discussed at some length at the end of Section 7.2.
We now impose some assumptions about the unknown and the CAR IP. Consider the
sets {w̄}∗ , {w̄}∗ , {ŵ}∗ , and {ŵ}∗ , defined in the obvious way on the basis of ΓȲ and ΓŶ .
The following assumptions resemble Assumptions (IP1)–(IP2) and are motivated by the
same arguments:
ȳ ∈ Ȳ ⇒ Γ(ȳ) 6= ∅
(IP4)
9. To avoid confusion, it may be worth outlining that whether a process is a coarsening or a missingness
process depends on what we focus on. In the case of the Asia network, for instance, the process can be a
missingness process for each single variable of the net (i.e., it yields either the value of the variable or a
question mark) and simultaneously be a coarsening process for the vector of variables (in the sense that
it does not only yield the vector of values or the vector made entirely of question marks).

768

Conservative Inference Rule

ŷ ∈ Ŷ ⇒ Γ(ŷ) 6= ∅

(IP5)

w̄ ∈ W̄ ⇒ {w̄}∗ 6= ∅

(IP6)

ŵ ∈ Ŵ ⇒ {ŵ}∗ 6= ∅.

(IP7)

We also impose an additional requirement on the unknown IP:
w̄ ∈ W̄ ⇒ {w̄}∗ = ∅.

(IP8)

We do so as a means to start implementing the idea that there is ignorance about the
procedure used by the unknown IP to select an observation starting from a fact.
Having Γ(y) = Γ(ȳ) × Γ(ŷ) for all y ∈ Y implies that {w}∗ = {w̄}∗ × {ŵ}∗ and {w}∗ =
{w̄}∗ × {ŵ}∗ for all w ∈ W. This shows that (IP4)–(IP7) imply (IP1)–(IP2).

4. The Conservative Inference Rule
The notations introduced so far finally allow us to write the definition of the conservative
inference rule. To this extent, we assume that we have beliefs about (Z, Y ) in the form of
a joint lower prevision P 1 .
Definition 7 (Conservative inference rule) Consider a gamble g on Z and w ∈ W,
and assume that P 1 ({w}∗ ) > 0. Let {w̄}∗1 := {ȳ ∈ {w̄}∗ : P 1 (ȳ, {ŵ}∗ ) > 0}, and define
R(g|ȳ, {ŵ}∗ ) :=

inf

P ≥P 1 :P (ȳ,{ŵ}∗ )>0

P (g|ȳ, {ŵ}∗ )

for all ȳ ∈ {w̄}∗1 . Then we let
R(g|w) := min ∗ R(g|ȳ, {ŵ}∗ ).

(CIR)

ȳ∈{w̄}1

Later, in Section 7.3, we shall see that this definition actually follows as a theorem under a
certain number of assumptions.
Let us clarify the intuition behind the definition of R(g|w). Our goal is to update beliefs
about a certain function g of Z once we make the observation w about Y . Remember that
w can be regarded as the pair (w̄, ŵ), where w̄ is the part of the observation originated
by the unknown IP and ŵ that originated by the CAR IP. The conservative inference
rule prescribes to update beliefs by adopting the lower prevision R(g|w) computed as in
Formula (CIR). This means (i) to consider all the completions ȳ of w̄ with the property
that the conditioning event (Ȳ = ȳ, Ŷ ∈ {ŵ}∗ ) has positive upper probability under P 1 ;
(ii) to compute our updated beliefs under each of these events: we can do this by applying
Bayes’ rule to each linear prevision that dominates P 1 and for which the event has positive
probability, so as to create a set of posterior linear previsions whose lower envelope is
R(g|ȳ, {ŵ}∗ ); finally, to define the lower prevision R(g|w) as the minimum of the lower
previsions obtained under all the completions considered. This minimum, in particular, has
the meaning to be as conservative as possible with respect to the data that has been made
incomplete by the unknown IP: we deal with them by considering all the complete data that
could have been there before the IP started operating. On the other hand, the data subject
to the CAR IP are treated as usual, that is, by conditioning on the set of completions {ŵ}∗ .
769

Zaffalon & Miranda

4.1 Significance of the Conservative Inference Rule
We can think of CIR as a generalisation of two kinds of updating rules. It generalises the
traditional updating rule, the one that, for instance, prescribes discarding missing observations. CIR coincides with such a rule in the case the IP is made only of the CAR component.
On the other hand, if there is no CAR component, and the overall IP is unknown, CIR is
similar to (but more powerful than) the so-called conservative updating rule (CUR) proposed by De Cooman and Zaffalon (2004). When both components are present, CIR acts
as a mix of traditional updating and CUR.
As CUR, CIR is an imprecise-probability rule: it generally leads to lower and upper
expectations, and partially determined decisions. This follows, in part, as it allows P 1 to
be imprecise. Yet, even if we take that to be a linear prevision P1 , CIR turns out to be
an imprecise-probability rule: imprecision arises as a logical consequence of our ignorance
about the unknown IP.
4.1.1 Comparison with CUR
It is instructive to analyse more deeply the difference between CIR and CUR. To this extent,
let us first give the definition of CUR using the notation introduced so far:
Definition 8 (Conservative updating rule) Assume that Z is a finite set, that Y = Ȳ
and W = W̄ , that is, that the overall IP is entirely unknown. Furthermore, assume that ΓȲ
is originated by missing values: this means that if we regard Ȳ as vector-valued, each of its
components is either observed precisely or it is missing. Assume also that P 1 (ȳ) > 0 for all
ȳ ∈ {w̄}∗ . For every gamble g on Z, define
R(g|ȳ) :=

inf

P ≥P 1 :P (ȳ)>0

P (g|ȳ)

for all ȳ ∈ {w̄}∗ . Then we let
R(g|w̄) := min R(g|ȳ).
ȳ∈{w̄}∗

(CUR)

The major differences between CIR and CUR are discussed below.
• The first difference is that CUR allows only the unknown IP to be present. In doing
so, CUR does not model beliefs stronger than ignorance about the IP, for which CURbased inferences will be more conservative than necessary. CIR tries to remedy this by
allowing for mixed states of knowledge made of ignorance and CAR. This makes CIR
a flexible rule that should lead to strong enough conclusions in many applications.
• The by far most important difference between CIR and CUR is the generality of application. The theory used to derive CUR is restricted to the case when P 1 is directly
assessed rather than obtained through a number of conditional and unconditional
lower previsions, possibly together with some notion of independence. This is the
case, for instance, of statistical inference which involves using a certain number of
lower previsions to model prior knowledge and the likelihood function and some notion of independence (or exchangeability) to build P 1 . Although one can apply CUR
also in these more general and common conditions, its theory does not guarantee
770

Conservative Inference Rule

that CUR leads to self-consistent inference in those cases. CIR, on the other hand,
is shown in Sections 7.3 to lead to coherent inference under a very wide spectrum of
conditions, which should cover nearly all the practical situations. This means that
applying CIR always leads to probabilities that are self-consistent as well as consistent
with the original assessments. (Observe that since CUR is a special case of CIR, our
proofs finally show that CUR also leads to self-consistent inference.) In other words,
CIR is more much than CUR a rule for the general task of updating beliefs based on
the observation of facts. In this, it is similar in spirit to traditional updating, which
we typically use in every situation: e.g., in the case of expert systems as well as to
update our beliefs given data in problems of statistical inference. With CIR, different
applications follow by simply giving different meanings to facts (Ȳ , Ŷ ), observations
(W̄ , Ŵ ), and to the quantity Z in which we are interested. Section 5 will give examples
to show how this is done in a variety of cases.
There are three further characteristics that make CIR more flexible than CUR.
• The first is that CIR allows the target space to be infinite, while CUR was defined
only for the case of finite spaces.
• The second is that CIR deals with general incompleteness processes, while CUR only
with the special case of processes that may originate missing information for the
variables under consideration. This is related to the restriction about ΓȲ mentioned
in the definition of CUR. This characteristic of CIR is important when aiming to
obtain as strong conclusions as possible: by taking advantage of partially observed
facts, CIR leads in general to stronger conclusions than CUR.
• The third is somewhat more technical. CUR requires that every element in {w̄}∗
is given positive upper probability. CIR requires this only for the entire set {w̄}∗ .
The difference is important in practice. To see this, consider that in applications it
is quite common to represent deterministic relations among variables by degenerate
probabilities equal to zero or one. These relations naturally give rise to zero upper
probabilities: every joint state of the variables that does not satisfy the relation has
zero upper probability by definition. CUR cannot be used in these applications. CIR
can, and it simply leads to neglect the states with zero upper probabilities: more
precisely, given an observation (w̄, ŵ), it leads to consider only the compatible facts
(ȳ, {ŵ}∗ ) for which it is possible to condition on them as they are given positive upper
probability, or, in other words, such that ȳ ∈ {w̄}∗1 .
Section 5.1 will show how some of these differences between CIR and CUR impact on
an example.
4.1.2 Originality of CIR
Something interesting to note is that CIR, such as traditional updating and CUR, is based
only on the variables Z and Y : i.e., for applying CIR one does not need to consider the
W -variables. This makes CIR particularly simple to use. Another consideration concerns
originality: to the best of our knowledge, CIR appears here for the first time. There are
771

Zaffalon & Miranda

contributions in the literature similar to CIR for the case of statistical model learning from
samples made incomplete by an unknown missingness process (e.g., Manski, 2003; Ramoni
& Sebastiani, 2001; Zaffalon, 2002). This is not surprising, as the intuition to take all the
completions of an incomplete sample is actually very natural. But we are not aware of any
work proposing, and especially deriving, an abstract and general rule to update beliefs from
incomplete information such as CIR.

5. Applications
In the following sections we shall show how CIR leads easily to several different rules according to the applications under study, and in doing so we present a number of examples.
To make things simpler we do not go in the details of the multi-valued maps used; we shall
only take W̄ to be the set of all the nonempty subsets of Ȳ, and assume that the hypotheses
done throughout the paper hold. We adopt similar considerations for the CAR IP.
5.1 CIR for Expert Systems
Probabilistic expert systems represent the key quantities in a domain by a vector of variables,
which in this section are assumed to take values from finite spaces. One or more of these
variables are the target, i.e., the variables that are the objective of inference. The remaining
ones are introduced to the extent of inferring the value of the target.
The Asia network in Figure 1 represents a well-known artificial example of expert system
in the medical domain. It is supposed that an expert has provided the graph as well as
the probabilities that define the Asia network, as reported in Table 1. If we want to use
the network to make diagnosis, we first choose a target node, such as R or B. Then we
collect information about the patient, as well as the results of medical tests, such as X-rays,
and make it available to the network by instantiating the related nodes in the graph to the
observed values. Finally, we query the network to update the probability of the target node
given the evidence inserted.
But usually not all the nodes, apart from the target node, are instantiated as some
values are missing, and the way the network has to compute belief updating depends on
our assumptions about them. The traditional way entails marginalising them out and it
is equivalent to assuming that they are subject to a MAR process. This is the special
case of CIR obtained by dropping the unknown IP. The general version of CIR offers more
flexibility in their treatment, and can produce a very different solution, as we illustrate by
an example below. In it we also use coarsened observations so as to show how set-valued
observations may enter the picture of probabilistic inference both in the CIR and in the
CAR case.
Example 3 Say that you are a senior doctor at a hospital and find on your desk a report
from a junior colleague about a certain patient he visited. The patient came to the hospital
under a state of dyspnea (A = a0 ). Your colleague visited the patient and did not find
any sign of bronchitis (H = h00 ). He also made some questions to the patient to collect
background information. He remembered that he had to ask something about smoking as
well as about some recent trip to Asia; but in the end he was not clear nor determinate
enough and he got to know only that the patient was concerned with only one of the two
772

Conservative Inference Rule

V = v0

0.01

K = k0

0.5

B=

b0

v0
0.05

v 00
0.01

R=

r0

k0
0.1

k 00
0.01

H = h0

k0
0.6

k 00
0.3

O = o0

b0 r0
1

b0 r00
1

L=

l0

o0
0.98

o00
0.05

A=

a0

o0 h0
0.9

o0 h00
0.7

b00 r0
1

b00 r00
0

o00 h0
0.8

o00 h00
0.1

Table 1: Asia example: probabilities for each variable (first column) in the graph conditional
on the values of the parent variables. The state ‘prime’ corresponds to ‘yes’.

773

Zaffalon & Miranda

things. Your unexperienced colleague thought then the situation was not serious and sent
the patient back home. You are instead a bit more cautious. In fact you suspect that the
patient might have hidden some information for privacy reasons, although you recognise
that you do not know these reasons. Overall, you are implicitly assuming the existence of
an unknown IP for the variables V and K that leads to {w̄}∗ = {(v 0 , k 00 ), (v 00 , k 0 )}, where we
denote by w̄ the value of W̄ that corresponds to the observation of (V, K). In other words
you regard (v 0 , k 00 ) and (v 00 , k 0 ) as the only two possible completions for the information that
you lack about (V, K).
Let us make two remarks before proceeding: (i) that the unknown IP is a coarsening
process, not just a missingness process, and this is what allows us to restrict the completions
of (V, K) only to two elements; and (ii) that despite the name the unknown IP is (also very)
informative when we use coarsened rather than missing values.
You finally judge the remaining variables to be subject to a MAR IP. This is very reasonable as your colleague simply decided not to have the patient do any test. In this case the
probability of missingness is one independently of the actual values of the variables under
consideration. It is instructive to stress that in this case the MAR IP is just your colleague.
At this point you are ready to do some diagnosis. You first run an algorithm for Bayesian
nets using the completion (v 0 , k 00 ), obtaining that the posterior probability for cancer is 0.052
and that for tuberculosis is 0.258; then you run the algorithm once more, in this case using
the completion (v 00 , k 0 ), which leads to 0.423 for the updated probability of cancer and 0.042
for that of tuberculosis. Now the question is that the first run suggests that you should
diagnose tuberculosis, and the second that you should diagnose cancer. Since you have no
idea about which one is the right completion of (V, K), you admit that you are not able
to discriminate between tuberculosis and cancer at this time. In other words, your model
is telling you that the information you have is too weak to draw any useful conclusion,
and is implicitly suggesting to collect stronger information. In order to do so, you invite
the patient for a next visit, explaining the importance of knowing whether he has been to
Asia, something that he actually confirms, thus letting you know eventually that V = v 0 and
K = k 00 . Your updated probabilities are then 0.052 for cancer and 0.258 for tuberculosis. On
this basis, you ask the patient to undergo X-rays, which turn out to be abnormal (L = l0 ),
leading to 0.151 and 0.754, respectively, as probabilities for cancer and tuberculosis, and you
diagnose tuberculosis.
Consider what might happen by assuming all the variables to be subject to a CAR/MAR
IP, as it is common with Bayesian nets. In that case, the information you have initially is
that A = a0 , H = h00 , and that (V, K) ∈ {(v 0 , k 00 ), (v 00 , k 0 )}. It is just CAR that allows us to
forget about W̄ and to write down that (V, K) belongs to {(v 0 , k 00 ), (v 00 , k 0 )}. This event is
easy to incorporate in a Bayesian network: it is enough to insert a new node in the Asia
network that is child of both V and K and that is in state ‘yes’ with probability one if and
only if (V, K) ∈ {(v 0 , k 00 ), (v 00 , k 0 )}. This new node is then instantiated in state ‘yes’. At this
point, running an algorithm for Bayesian nets yields that the probabilities for cancer and
tuberculosis conditional on A = a0 , H = h00 , and (V, K) ∈ {(v 0 , k 00 ), (v 00 , k 0 )}, are 0.418 and
0.045, respectively. This would make you suspect that there is cancer; moreover, it might
well induce you to take the following erroneous course of reasoning: ‘since the probability
of cancer is that high even without knowing the exact values of V and K, trying to obtain
that information is a waste of time; I must rather focus on more concrete evidence such
774

Conservative Inference Rule

as X-rays to make my diagnosis.’ But obtaining the positive X-rays test (L = l0 ) would
enforce your beliefs even more by raising the probability of cancer up to 0.859, leading you
to a mistaken diagnosis. ♦
These considerations are not limited to expert systems based on precise probability; completely analogous considerations would be done in the case of expert systems that model
knowledge using closed convex sets of mass functions (or, equivalently, by the coherent lower
prevision which is their lower envelope) for which CIR is also suited. Credal networks, for
example, provide such modelling capabilities (Cozman, 2000, 2005).
It is easy to rephrase expert system models in the setting of this paper. Say that
the expert system is based on the vector of variables (Z, Ȳ1 , . . . , Ȳm , Ŷ1 , . . . , Ŷn ), where Z
is the target variable, and the others are those subject to the unknown and the CAR
IP, respectively. Then it is sufficient to write Ȳ := (Ȳ1 , . . . , Ȳm ), Ŷ := (Ŷ1 , . . . , Ŷn ), and
to consider that a set M of joint mass functions for (Z, Y ), or equivalently the lower
prevision P 1 made by taking its lower envelope, is given. Doing inference with an expert
system, in quite a general form, corresponds then to compute R(g|w̄, ŵ), where w̄ is now
the observation of the Ȳ vector and ŵ that of the Ŷ vector.
We consider some cases to make things clearer. At an extreme, which we already
mentioned, there is the case m = 0, which means that there is only the CAR IP. The
updating rule that follows from CIR is then the traditional updating: R(g|ŵ) = R(g|{ŵ}∗ ).
Say that, to be even more specific, g is the indicator function Iz of some z ∈ Z, and that
0
0
{ŵ}∗ = {(ŷ1 , . . . , ŷj , ŷj+1
, . . . , ŷn0 ) ∈ Ŷ : ŷj+1
∈ Ŷj+1 , . . . , ŷn0 ∈ Ŷn )}, i.e., that the first
j variables of Ŷ are observed precisely, while the others are missing. The updating rule
becomes:
R(g|{ŵ}∗ ) = R(Iz |ŷ1 , . . . , ŷj , Ŷj+1 , . . . , Ŷn ) = R(Iz |ŷ1 , . . . , ŷj ),
which is equal to inf P ≥P 1 :P (ŷ1 ,...,ŷj )>0 P (z|ŷ1 , . . . , ŷj ). The latter is an updating rule implemented by credal networks; and if P 1 is a linear prevision, it is the rule used with Bayesian
networks.
Consider now the other extreme: n = 0, i.e., when there is only the unknown IP.
Similarly to the previous case, say that g is the indicator function for z; and that {w̄}∗ =
0 , . . . , ȳ 0 ) ∈ Ȳ : ȳ 0
0
{(ȳ1 , . . . , ȳi , ȳi+1
m
i+1 ∈ Ȳi+1 , . . . , ȳm ∈ Ȳm )}. CIR becomes then R(g|w̄) =
minȳi+1 ∈Ȳi+1 ,...,ȳm ∈Ȳm inf P ≥P 1 :P (ȳ1 ,...,ȳm )>0 P (z|ȳ1 , . . . , ȳm ). This case nearly coincides with
the conservative updating rule proposed by De Cooman and Zaffalon (2004), with the
differences already discussed in Section 4.1. These differences are important: for instance,
that CUR cannot deal with coarsened observations makes it impossible to use it to model
the observation in Example 3. Some of them would even prevent CUR from being applied
more generally to the example: on the one hand, the presence of the logical ‘or’ gate in
the Asia network creates states of zero upper probability (e.g., B = b0 , R = r0 , O = o00 )
that are incompatible with the assumptions underlying CUR; on the other, since domain
knowledge (i.e., the Asia net) is built out of a number of conditional mass functions, we
cannot guarantee that CUR leads to self-consistent inference as its proof does not deal with
such an extended case. We know that CIR instead does lead to self-consistent inference as
a consequence of Corollary 3 in Appendix B.
When neither m nor n are equal to zero, CIR becomes a mix of the two extreme cases
just illustrated, as in the example: it leads to treat the variables subject to the CAR IP by
775

Zaffalon & Miranda

the traditional updating, while treating those subject to the unknown IP similarly to what
CUR does. Mixing the two things has the advantage of greater expressivity: it allows us to
represent beliefs about the overall IP that are in between the two extremes.
We conclude this section by briefly discussing the problem of doing computations with
CIR and its special case CUR.
In the context of doing classification with Bayesian nets according to CUR, Antonucci
and Zaffalon (2007) have proved an NP-hardness result, as well as given an exact algorithm.
The algorithm is a variant of the variable elimination algorithm that has a better complexity
than the traditional algorithms on Bayesian nets (implicitly using CAR): it works in linear
time not only on polytree networks (i.e., those for which there is at most one path between
any two nodes in the graph after dropping the orientation of the arcs) but also on a number
of more general nets; on the remaining ones it takes exponential time. Moreover, in another
paper, Antonucci and Zaffalon (2006) have shown that when there are missing observations
the problem of CIR-updating in Bayesian nets and that of traditional (i.e., MAR-based)
updating in credal nets are equivalent. This is exploited in a recent paper (Antonucci &
Zaffalon, 2008, Section 9) to show the NP-hardness of CIR-updating in Bayesian nets, and
to give a procedure to solve such a problem via existing algorithms for credal nets. The idea
behind such a procedure is relatively straightforward, and it takes inspiration from a method
proposed by Pearl (1988, Section 4.3) to represent an instantiated node in a Bayesian net
using an equivalent formulation: the formulation is based on removing the instantiation from
the node and on adding a dummy child to it that is actually instantiated to a certain value.
This approach is basically taken as it is for CIR-updating in the case of a node missing in
an unknown way; CIR imposes to deal with it by considering all its possible instantiations.
Considering the dummy-child method for each of them is shown to be equivalent to using
a single imprecise-probability dummy child that is instantiated to a unique value. In this
way the node that was originally missing in an unknown way can be treated as a node
missing at random, while the dummy child is simply an instantiated imprecise-probability
node. As a consequence, the original Bayesian net becomes a credal network and our task
becomes the computation of MAR-based updating on such a net. Since there are already
many algorithms designed for this task, the described transformation allows one to solve the
CIR-updating problem via known algorithms for the MAR-updating problem on credal nets.
Yet, MAR-updating on credal networks is a more difficult problem than MAR-updating on
Bayesian nets, as it is NP-hard also on polytrees (De Campos & Cozman, 2005). Therefore
CIR-updating appears to be more demanding than MAR- or CUR-updating. This is not
necessarily going to be a problem in practice as approximate algorithms for credal nets
nowadays allow one to solve updating problems on large-scale networks (e.g., Antonucci
et al., 2008).
5.2 CIR for Parametric Statistical Inference
In a statistical problem of parametric inference, we are given a sample that we use to update
our beliefs about a so-called parameter, say Θ, with values θ ∈ T . The admissible values
for Θ index a family of data generation models that we consider possible for the problem
under consideration. Here we do not exclude the possibility of this set being infinite, as it
is often the case in statistics.
776

Conservative Inference Rule

In this setting, a fact is thus the true, and hence complete, sample. We represent it as
the following vector of variables:


D1
 D2 


(1)
Y :=  .  .
.
 . 
DN
The elements of a sample are also called units of data. We assume from now on, that the
variables Di have the same space of possibilities for every i.
We can exemplify the problem of parametric statistical inference by focusing once again
on the Asia Bayesian network in Figure 1: a frequent step in the construction of Bayesian
nets is the inference of the network parameters from a data set. Say, for instance, that we
are interested in evaluating the chance Θ that a person suffers from tuberculosis if we know
that the same person has made a recent visit to Asia. To this extent we might exploit a
data set for the variables B and V , such as the one below:




y := 




(b0 , v 0 )
(b0 , v 00 )
(b0 , v 00 )
(b00 , v 00 )
(b00 , v 0 )
(b00 , v 0 )





,




(2)

for which we assume in addition that the data have been generated according to an identical
and independently distributed (IID) process.
We can do parametric inference relying on the tools of Bayesian statistics. This means
to compute the posterior linear prevision (i.e., the posterior expectation) P (g|y), for a
certain function g : T → R. This is obtained integrating the posterior density function for
Θ, obtained in turn by Bayes’ rule applied to a prior density function, and the likelihood
function (or likelihood ) L(θ) := P (y|θ).
In this case, a common choice for the prior would be a Beta density for Θ: Bs,t0 (θ) ∝
0
0
θst −1 (1 − θ)s(1−t )−1 , where s and t0 are positive real hyper-parameters that are respectively
the overall strength of the prior knowledge and the prior expectation of Θ. In the case of
0
the data set (2), this choice leads to a posterior expectation for Θ that is equal to 1+st
3+s .
0
Setting s := 1 and t0 := 1/2, namely, Perks’ prior (see Perks, 1947), we obtain 1+st
3+s = 0.375,
which can be regarded as an approximation to the true parameter value.
Imprecise probability approaches to parametric inference often extend Bayesian statistical methods by working with a set of prior density functions, and by updating each of them
by Bayes’ rule, whenever possible, using the same likelihood function, thus obtaining a set
of posteriors. An example is the imprecise Dirichlet model proposed by Walley (1996a). In
our notation and terminology, this means that in the imprecise case parametric inference is
based on the unconditional lower prevision P 1 (Θ, Y ), obtained by means of the prior P 1 (Θ)
and the likelihood P (Y |Θ) through a rule called marginal extension, that is updated into
the posterior lower prevision R(Θ|Y ) by a procedure called regular extension. Marginal and
regular extension will be introduced more precisely in Section 6.
777

Zaffalon & Miranda

In the previous example related to the data set (2) where the variables are binary, the
imprecise Dirichlet model is called imprecise Beta model (Bernard, 1996), and can be easily
applied as follows. The idea is to consider the set of all the Beta densities with fixed prior
strength, say s = 1: i.e., the set of all Bs,t0 such that s = 1 and t0 ∈ (0, 1).10 This set can be
regarded as a single imprecise prior that only states that the prior probability for category
b0 lies in (0, 1), which seems a more reasonable way to model a state of prior ignorance about
Θ than a Bayesian prior, such as Perks’ above. This imprecise prior leads to an imprecise
0
posterior expectation for Θ: to compute it, it is enough to reconsider the expression 1+st
3+s
and let t0 take all the values in (0, 1); this leads to the interval [0.25, 0.50] that is delimited by
0
0
0
the lower and the upper posterior probabilities obtained from 1+st
3+s when t = 0 and t = 1,
respectively. Again, this ‘interval estimate’11 appears to be much more reasonable and
reliable than the precise posterior expectation obtained by the Bayesian approach, taking
especially into account that the sample available to infer the parameter under consideration
has size three!
But in real problems we often face the further complication of having to deal with
incompleteness in statistical data: rather than a complete sample y, we may be given an
incomplete sample w, i.e., one that corresponds to a set {w}∗ of complete samples. The
set {w}∗ arises as a consequence of missingness or partial observability of some values. The
data set (2) might for instance be turned by an incompleteness process into the following
incomplete data set:
 0 0 
(b , v )
 (b0 , v 00 ) 


 (b0 , ?) 

(3)
w := 
 (b00 , v 00 )  .


 (b00 , ?) 
(?, v 0 )
In this example {w}∗ is the set of the eight complete data sets that are obtained by replacing
the question marks in all the possible ways.
The question is then how to do parametric inference with an incomplete sample. We
represent each unit in Vector (1) by regarding the generic variable Di as the pair (Ȳi , Ŷi ),
and let Ȳ := (Ȳ1 , . . . , ȲN ), Ŷ := (Ŷ1 , . . . , ŶN ), so that Y = (Ȳ , Ŷ ).
Now it is easy to use CIR to address the question of parametric inference with incomplete
data, if we know that Ŷ is subject to a CAR IP, and we do not know the IP that acts on
Ȳ . Observing that Θ plays the role of Z, we obtain that CIR prescribes using the following
rule: R(g|w) = minȳ∈{w̄}∗1 R(g|ȳ, {ŵ}∗ ), which rewrites also as
R(g|w̄, ŵ) = min ∗
ȳ∈{w̄}1

inf

P ≥P 1 :P (ȳ,{ŵ}∗ )>0

P (g|ȳ, {ŵ}∗ ),

(4)

10. The reason why we exclude the extreme points of the interval is to avoid creating conditioning events with
zero lower probability and have to discuss their implications. In the present setup this is not restrictive,
as it can be shown that the closed interval would eventually lead to the same inferences.
11. It is important to be aware that these intervals are conceptually very different tools from Bayesian
credible intervals, which arise out of second-order information about a chance. The present intervals
arise only out of ignorance about the unknown IP, something that makes a set of IPs be consistent
with our assumptions and about which we have no second-order information. Stated differently, the
counterpart of these intervals in the precise case are the point estimates, not the credible intervals,
which should instead be compared with imprecise credible intervals (e.g., see Walley, 1996a, Section 3).

778

Conservative Inference Rule

because imprecision on (Θ, Y ) originates via prior imprecision only. We prove in Corollary 4
in Appendix B that this rule leads to self-consistent inference.
We can regard the lower expectation in Equation (4) as arising from two kinds of imprecise beliefs. The first are beliefs about Θ that we model by the lower prevision P 1 (Θ). The
remaining beliefs are embodied by the likelihood function. This is imprecise knowledge, too,
since there are actually multiple likelihood functions, because of the unknown IP, and we
model them using the different conditional previsions P (Θ|ȳ, {ŵ}∗ ) for ȳ ∈ {w̄}∗1 . In other
words, working with incomplete data according to CIR is equivalent to working with the set
of posteriors that arise by applying Bayes’ rule, whenever possible, to each prior-likelihood
pair in the model.
In the case of the data set (2), we might know that in order to create the incomplete
sample (3) out of it, the variable B has been subject to a MAR missingness process, while
we might not know what kind of missingness process has acted on variable V ; in this
case, the generic unit i of (2) can be written as the pair (ŷi , ȳi ). Say that we focus
again on computing the posterior expectation for Θ, chosen to be that a person suffers
from tuberculosis if we know that the same person has made a recent visit to Asia. Say
also that we use Perks’ prior as we did before in the Bayesian case, in order not to get
distracted in the discussion by prior imprecision. In this case, the outer minimum in (4)
corresponds to minimising over the four completions for variable V ; the following infimum
corresponds to take into account Perks’ prior. The four completions mentioned above give
rise to four different data sets that contain a single missing value in the last unit. For each of
them, we can compute the lower probability for the category b0 conditional on v 0 , using the
Expectation-Maximisation algorithm (Dempster, Laird, & Rubin, 1977) together with Perk’s
prior, obtaining four values: 0.63, 0.87, 0.50, 0.83 (these values are rounded to the second
digit). The lower probability is then their minimum: 0.5; analogously, their maximum is the
upper probability: 0.87. We can again think of these two values as delimiting an interval
for the probability under consideration: [0.5, 0.87]. The width of this interval reflects our
ignorance about the missingness process for V .
We consider now the Bayesian case, using for both B and V the MAR assumption, as
it is very common when learning parameters from data sets. In this case, the ExpectationMaximisation algorithm together with Perks’ prior yields an estimate for the probability
equal to 0.86. Apart from the unrealistic precision of this estimate obtained from such a
small data set, we can observe that using MAR has arbitrarily led us very close to the upper
extreme of the interval [0.5, 0.87]. This is even more questionable when we consider that
the Bayesian estimate from the complete data set (2) was close to the lower extreme.
In summary, by using CIR we are able to obtain interval estimates that are arguably
more realistic than the point estimates provided by more traditional methods when the
MAR assumption is not justified. This also follows by exploiting the option given by CIR
to use models of prior knowledge that carefully model the available information, or the
absence of information, such as the imprecise Dirichlet model.
Finally, as the example illustrates, working with multiple likelihoods is a consequence
of taking all the possible completions of the incomplete part of the sample subject to the
unknown IP. This is a very intuitive procedure; therefore, it is not surprising that analogous
procedures have already been advocated with missing data in the context of robust statistical inference (see, e.g., Manski, 2003; Ramoni & Sebastiani, 2001; Zaffalon, 2002). Actually,
779

Zaffalon & Miranda

the discussion in this (and the following) section can be regarded as a formal justification
of the cited approaches from the point of view of the theory of coherent lower previsions.
It can also be regarded as a generalisation of some of those approaches in that it considers
the joint presence of the CAR and the unknown IP, and because it allows one to work with
incomplete rather than missing data.
5.2.1 IID+ID Case
In the previous section, we have not made hypotheses about the generation of the complete
sample. However, in practice it is very frequent to deal with independent and identically
distributed data (also called multinomial data), and indeed we have already assumed IID
for the data in (2). With multinomial data, the units are identically distributed conditional
on θ, and this helps simplifying the developments. Call D the space of possibilities common
to the units. When we assume that D is finite (as we shall do in our derivation of the CIR
rule in Section 7.3), the parameter Θ is defined as the vector [Θd ]d∈D , where the generic
element Θd represents the aleatory probability of D = d. It follows that θ ∈ T is the vector
[θd ]d∈D , whose generic element θd is P (d|θ); and that T is a subset of the |D|-dimensional
unit simplex. Taking into account that
QNunits are also independent conditional on θ, it
follows that the likelihood factorises as i=1 θdi .
When complete data are IID, it may be reasonable to assume that also the overall IP is
independently distributed (ID). Such an assumption allows us to represent the observation
of the complete sample as a vector, i.e., as an incomplete sample:


W1
 W2 


W :=  .  .
 .. 
WN
Here the generic unit Wi is the observation of Di . Remember that we regard Di as the
pair (Ȳi , Ŷi ); as a consequence, we also regard Wi as the pair of variables (W̄i , Ŵi ), with
W̄i and Ŵi the observations of Ȳi and Ŷi , respectively. Finally, let W̄ := (W̄1 , W̄2 , . . . , W̄N )
and Ŵ := (Ŵ1 , Ŵ2 , . . . , ŴN ). For an example it is sufficient to consider the data set in (3),
which is just an instance of W in the current language; and its generic unit i is an instance
of Wi = (W̄i , Ŵi ), where W̄i corresponds to variable V and Ŵi to B.
Using the newly introduced notation, the form that CIR takes is the following (with
obvious meaning of the symbols):
R(g|w̄, ŵ) =

min

(ȳ1 ,...,ȳN )∈{w̄}∗1

R(g|ȳ1 , . . . , ȳN , {ŵ1 }∗ , . . . , {ŵN }∗ ),

(5)

where R(g|ȳ1 , . . . , ȳN , {ŵ1 }∗ , . . . , {ŵN }∗ ) is equal to
inf

P ≥P 1 ,P (ȳ1 ,...,ȳN ,{ŵ1 }∗ ,...,{ŵN }∗ )>0

P (g|ȳ1 , . . . , ȳN , {ŵ1 }∗ , . . . , {ŵN }∗ ).

That this rule leads to self-consistent inference is established in Corollary 4 in Appendix B.
Moreover, the new formulation shows that the ID assumption for the incompleteness process leads in practice to inhibiting certain types of coarsening: those that create logical
780

Conservative Inference Rule

‘connections’ between different units. On the one hand, this confirms the expressive power
of coarsening. On the other, it suggests that in applications it might be easier to forget
about the ID assumption and simply focus on the specification of the kind of coarsening
behaviour. This approach appears to be more intuitive and hence more accessible especially
to people with little experience in statistics that might be involved in the analysis.
5.2.2 Full IID Case?
Is it reasonable to assume that an IP is identically distributed besides independently distributed? And what are the consequences of such an assumption?
We start by addressing the second question. Under IID for complete data, the generic
element d ∈ D has a fixed aleatory probability, which we denoted by Θd . Call W the space
of possibilities common to the variables Wi , i = 1, . . . , N . Under IID for the IP, the generic
element w of W has a fixed aleatory probability to be produced conditional on d, let us
d . It follows that w has a fixed unconditional aleatory probability to be produced:
call it ΦP
w
Ψw := d∈D Θd · Φdw , which means that the process that produces elements of W is also
multinomial. This seems to considerably simplify the setup considered so far, and can thus
be regarded as an advantage of the full IID assumption (this advantage has clear practical
consequences in the case of pattern classification, as illustrated in Section 5.3.2.)
On the other hand, and here we turn to address the first question, the possible advantages seem to be dwarfed by the strength of the assumption itself. It is indeed questionable
that such an assumption may be largely valid in applications. IPs are often generated by
sophisticated behaviour patterns that involve humans, or other complex agents, and that
can be regarded as protocols of communications. In this case giving or not giving some
information is a fundamental and an intelligent part of the communication. Assuming in
this case that the IP is IID, seems to be too much of a strong assumption. In fact, there is
a fundamental difference between data-generating processes (giving rise to Z and Y ) and
observational processes (giving rise to W ). We believe that the essence of this difference
is that in a number of cases it does not make much sense to assume that an observational
process is identically distributed, while IID does make sense, or is at least a reasonable
approximation for many data-generating processes.
5.2.3 CAR Units
Having considered the IID+ID setup in Section 5.2.1 gives us the opportunity to slightly
extend the analysis done so far. The idea is that the since the overall IP does not need to
be identically distributed, it may happen to act as a CAR process for some units. Say that
a certain unit 0 is entirely coarsened at random. The question is what form takes CIR now.
This is easy to see by defining Ȳ := (Ȳ1 , . . . , ȲN ), Ŷ := (D0 , Ŷ1 , . . . , ŶN ), and the
corresponding observation variables W̄ := (W̄1 , . . . , W̄N ), Ŵ := (W0 , Ŵ1 , . . . , ŴN ), which
lead to the following rule:

R(g|w̄, ŵ) =

min

(ȳ1 ,...,ȳN )∈{w̄}∗1

R(g|ȳ1 , . . . , ȳN , {w0 }∗ , {ŵ1 }∗ , . . . , {ŵN }∗ ).
781

Zaffalon & Miranda

In particular, if Unit 0 is missing, i.e., {w0 }∗ = D, the rule prescribes to discard such a unit
from consideration:
R(g|w̄, ŵ) =

min

(ȳ1 ,...,ȳN )∈{w̄}∗1

R(g|ȳ1 , . . . , ȳN , {ŵ1 }∗ , . . . , {ŵN }∗ ).

This observation is particularly important for applications because it may well be the case
that in practice some units are entirely missing in a non-selective way. CIR tells us that all
such units, as Unit 0 above, are not going to alter our beliefs about Z.
The situation is obviously different if some units are turned into missing units by an
unknown process; in this case there is no justification to discard them. The correct way
to proceed is to make those missing values part of the observed data, and then to apply
CIR again. This would lead us to consider all the completions of such missing units into
account.
5.3 CIR for Pattern Classification
This section focuses on problems of pattern classification, a special case of so-called predictive
inference. Loosely speaking, this kind of inference is concerned with predicting future
elements of a sequence based on the available part of the sequence itself. In a classification
problem, the available sequence is represented by the following matrix:


C1 F1
 C2 F2 


(6)
 ..
..  .
 .
. 
CN

FN

The generic line i, or unit i, of the matrix represents an object described by a pair of
variables that we relabel as Di := (Ci , Fi ) to be consistent with the notation used for
parametric inference. Variable Ci represents a characteristic of the object in which we are
interested, and that we call class. Denote the set of classes by C. By definition of pattern
classification, C is a finite set. Variable Fi represents some features of the object that are
informative about the class.
We can try to make this more clear by an example focused again on the Asia network.
Say that we have a data set that records the state of the variables in the Asia network for
a number of persons. Say also that we are interested in classifying people as smokers or
nonsmokers. In this case, the value of Ci , i.e., the class variable for the i-th person in the
data set, is the state of variable K in the Asia network for person i. Variable Fi is then the
vector of all the remaining variables in the Asia network for such a person; in other words,
Fi represents the profile of person i in the data set.
Now we consider the next element in the sequence, represented as the further unit
DN +1 := (CN +1 , FN +1 ), also called the unit to classify. In the previous example, DN +1
would be the next person we see. The goal of classification is to predict the value that
CN +1 assumes given values of all the other variables; in the example this amounts to
predict whether the next person is smoker or not given the profile of that person, and the
relationship between profiles and classes that is suggested by the historical data. In other
words, in this framework CN +1 is Z and (D1 , . . . , DN , FN +1 ) is Y .
782

Conservative Inference Rule

Predicting the class c0 for CN +1 can be regarded as an action with uncertain reward gc0 ,
whose value gc0 (c) depends on the value c that CN +1 actually assumes. In the case of precise
probability, the optimal prediction is a class copt that maximises the expected reward:
P (gcopt |d1 , . . . , dN , fN +1 ) ≥ P (gc0 |d1 , . . . , dN , fN +1 ),

c0 ∈ C.

The previous expression is equivalent to the next:
P (gcopt − gc0 |d1 , . . . , dN , fN +1 ) ≥ 0,

c0 ∈ C.

This is very similar to the expression used with imprecise probability: in this case an optimal
class is one that is undominated, i.e., such that for all c0 ∈ C:12
P (gcopt − gc0 |d1 , . . . , dN , fN +1 ) > 0.
Despite the similarity in notation, it is important to realise that there is a fundamental
difference in the two cases: precise probability always leads to a determinate prediction,
imprecise probability does not. With imprecise probability there is a progression according
to which stronger beliefs lead to less indeterminate decisions, up to completely determined
ones (see the paper by De Cooman & Zaffalon, 2004, Section 2.10, for a wider discussion of
decision making with imprecise probability).
The discussion up to this point has highlighted that both with precise and with imprecise
probabilities, predictions are based on (upper, and hence lower) previsions of functions
g : C → R. In order to address the issue of incompleteness in pattern classification, we can
therefore, without loss of generality, restrict the attention to the task of updating beliefs
about CN +1 .
This task is usually regarded as made of two distinct steps. The first is concerned
with learning from a sample, represented here by Matrix (6), a probabilistic model of the
relationship between features and classes. The second is applying the model to the observed
value fN +1 of FN +1 in order to finally compute the (lower) prevision of a gamble g.
We illustrate the two steps in the case of IID data; more general cases can be treated
analogously.
In the Bayesian framework, the first step is often done in a way similar to parametric
inference. One defines a family of density functions that may be responsible for producing
the units of data, indexes them by the admissible values θ ∈ T of a (usually continuous)
parameter Θ, and then assesses a prior density for Θ. The prior and the likelihood lead
via Bayes’ rule to the posterior density for Θ conditional on (d1 , . . . , dN ). The second step
corresponds to use such a posterior together with the density (or the mass function) for
DN +1 conditional on Θ, to obtain (integrating Θ out) the so-called predictive posterior:
i.e., the mass function for CN +1 conditional on (d1 , . . . , dN , fN +1 ), which embodies the
wanted probabilistic model of the relationship between features and classes. Computing
the posterior prevision P (g|d1 , . . . , dN , fN +1 ) is trivial at that point.
The situation is similar in the imprecise case, with the difference that using a set of
prior densities, i.e., a lower prior P 1 (Θ), leads to a lower predictive prevision:
P (g|d1 , . . . , dN , fN +1 ) :=

inf

P ≥P 1 :P (d1 ,...,dN ,fN +1 )>0

P (g|d1 , . . . , dN , fN +1 ).

12. Walley (1991) calls maximality the related decision criterion. See the work of Troffaes (2007) for a
comparison with other criteria.

783

Zaffalon & Miranda

Now we are ready to address the issue of incomplete data using CIR. We must first
define the variables that are subject to the CAR and the unknown IP. With respect to
feature variables, we assume that the generic variable Fi (i = 1, . . . , N + 1) is equal to the
pair (F̄i , F̂i ), with the usual meaning of the symbols. Define the vectors Ȳ and Ŷ as Ȳ :=
(C1 , F̄1 , . . . , CN , F̄N , F̄N +1 ), Ŷ := (F̂1 , . . . , F̂N , F̂N +1 ). To make things more readable, we
also define Ȳi := (Ci , F̄i ), Ŷi := F̂i , for all i = 1, . . . , N ; and ȲN +1 := F̄N +1 , ŶN +1 := F̂N +1 .
There is obviously arbitrariness in the above definitions of the vectors Ȳ and Ŷ , and
it might well be the case that some applications require different choices. The present
definitions are only done for illustrative purposes.
With the above definitions, CIR leads to the following rule to update beliefs about g:
R(g|w̄, ŵ) = min(ȳ1 ,...,ȳN +1 )∈{w̄}∗1 inf P ≥P 1 :P (ȳ1 ,...,ȳN +1 ,{ŵ1 }∗ ,...,{ŵN +1 }∗ )>0
P (g|ȳ1 , . . . , ȳN +1 , {ŵ1 }∗ , . . . , {ŵN +1 }∗ ).

(7)

Corollary 5 proves that this rule leads to self-consistent inference. Equation (7) states that
one should consider (i) the set of possible completions of the part of the observed sample
∗
originated by the unknown IP, ×N
i=1 {w̄i }1 ; (ii) the set of possible completions of the part of
the unit to classify originated by the unknown IP, {w̄N +1 }∗1 ; and (iii) the set of (possible)
precise priors, which are those dominating our prior lower prevision P 1 (Θ). For each of the
above choices, the problem becomes the computation of the posterior expectation of g as
in a single Bayesian (i.e., precise-probability) classifier. When we consider all the possible
choices in (i)–(iii) above, working with (7) amounts to work with a set of Bayesian classifiers.
The set of posterior expectations originated by the Bayesian classifiers is summarised in (7)
as a lower expectation.
We can look at the problem also from another point of view. Imprecision that produces
the lower expectation (7) can be regarded as originated by three components. The first is
the presence of multiple priors. The second is the presence of multiple likelihoods, each of
which is consistent with a certain completion of the part of the sample originated by the
unknown IP. The third component is the set-valued observation of the part F̄N +1 of the
features of the unit to classify, which we can regard as an imprecise description of the object
to classify.
5.3.1 An Example
Let us focus again on the initial example in Section 5.3 in which we were interested in
classifying people as either smokers or nonsmokers. To make things easier, we take gc0 to
be the 0-1 loss function, i.e., we compute posterior probabilities rather than expectations
in order to issue a classification. Moreover, we take the graph of the Asia net to represent
the probabilistic dependencies between the variables involved (yet, we do not assume the
net parameters to be given, as learning the parameters from data is part of the inferential
task of classification that we have to solve). To make the example more handy, we assume
that for all the people we want to classify we miss information about the variables V , B,
O, L and A in the Asia net, and that this missingness is MAR: that is, these variables
constitute F̂N +1 . This implies, through (7), that we can actually discard variables V , B,
O, L and A from consideration: we can equivalently work out our inference task by relying
only on a learning set for the variables K, R and H alone. This holds because working
784

Conservative Inference Rule

with (7) amounts to work with a set of Bayesian classifiers, and the above property holds
for each of them.13 As a consequence, it turns out that the only portion of the Asia net
which is relevant for the classification is that displayed in Figure 2. Such a structure, with

Smo(K)ing

+

s

Lung cance(R)

Bronc(H)itis

Figure 2: The naive sub-network of the Asia net related to the variables K, R and H.
the feature variables represented as disconnected children of the class variable is called a
naive network. When we use it as a precise-probability classifier, it is best known as naive
Bayes classifier (Duda & Hart, 1973).
Say that our learning set, originated by an IID process, is the following:








d¯ := 








(r0 , h00 , k 0 )
(r0 , h00 , k 0 )
(r0 , h0 , k 0 )
(r0 , h0 , k 0 )
(r00 , h0 , k 0 )
(r00 , h0 , k 00 )
(r00 , h0 , k 00 )
(r00 , h00 , k 00 )
(r00 , h00 , k 00 )
(r0 , h00 , k 00 )









.








This data set is characterised by a strong positive relationship between smoking and cancer
and a weak positive relationship between smoking and bronchitis. Learning naive Bayes
from d¯ and applying the model to the four joint instances of the feature variables, we
obtain the following predictions:


(r0 , h0 , k 0 )
 (r0 , h00 , k 0 ) 


(8)
 (r00 , h0 , k 00 )  ,
(r00 , h00 , k 00 )
where we have used Perks’ prior for naive Bayes14 in the above experiments. If we replace
such a prior with an imprecise one, we obtain an extension of naive Bayes to imprecise
13. A proof in relationship with a specific classifier can be found in the work by Corani and Zaffalon (2008,
Section 3.1.2).
14. Modified as described by Zaffalon (2001, Section 5.2) (refer to Perks’ prior defined ‘in analogy with the
IDM’ in that section) to make the comparison easier.

785

Zaffalon & Miranda

probability. If we moreover define such a prior P 1 (Θ) so as to model a state of prior
ignorance, similarly to what we have done in the case of parametric inference, we obtain an
imprecise-probability classifier that is an instance of the so-called naive credal classifier 2
(or NCC2, see Corani & Zaffalon, 2008). We can reinterpret NCC2 as a set of naive Bayes
classifiers. In the present case, we have a classifier per each precise prior consistent with
(i.e., dominating) the imprecise one.
The way NCC2 issues a classification on a specific instance of R and H can be understood
easily in terms of the set of naive Bayes classifiers to which it corresponds: the classification
of NCC2 is the union of the classes issued by all the naive Bayes classifiers in the set.15
This means that if all the naive Bayes classifiers issue the same class, then the classification
of NCC2 is determinate, i.e., made of a single class. Otherwise, when there is disagreement
among the naive Bayes classifiers, then NCC2 issues the entire set K, i.e., an indeterminate
classification.16
¯ we obtain again the determinate predictions
If we infer NCC2 from the learning set d,
17
reported in (8): this means that the information in the data is strong enough to smooth
the contribution of each precise prior used by NCC2 in favor of a single class.
We can move to more interesting examples by introducing missing values. Consider the
following two instances to classify that are missing the information about cancer:


(?, h0 )
.
(9)
(?, h00 )
The treatment of these instances will be very different from naive Bayes to NCC2. NCC2
can naturally embed our assumption that R and H are made missing by an unknown
process, and deal with it by considering the two completions of the question mark in each
instance. In other words, the classification of NCC2 will be not only, as before, equal to the
union of the classes delivered by the equivalent set of naive Bayes classifiers, but the union
will also be taken with respect to the two completions of the instance to classify. On the
other hand, naive Bayes will have to assume MAR to deal with the incomplete instances,
and this will lead it to discard R from the conditioning variables.
The classifications issued by naive Bayes and NCC2 are respectively:

 

(?, h0 , k 0 )
(?, h0 , K)
,
.
(?, h00 , k 00 )
(?, h00 , K)
In other words, for naive Bayes knowing the state of bronchitis is sufficient to determine
whether a person is smoker or not, despite the weak relationship in the learning set between
those two characteristics; NCC2 is more cautious and believes that it is not possible to
determine the smoking state because it is missing, not necessarily in an ignorable way,
the value of a very important predictor variable. On the other hand, it can be checked
that if the missing variable is H instead of R, both naive Bayes and NCC2 agree that the
15. This is the case because the class variable is binary.
16. This total indeterminacy is a consequence of the class variable being binary; in other cases the output set
of classes can be any subset of classes, not only the least informative one. In these cases, the classification
is only partially indeterminate, and carries therefore useful information.
17. The predictions of NCC2 can be computed by an open-source software freely available at the address
http://www.idsia.ch/∼giorgio/jncc2.html.

786

Conservative Inference Rule

prediction should be determinate: knowing that a person has cancer tells us that the person
is a smoker, and vice versa.
The situation can become even more critical for naive Bayes if we use an incomplete
¯ such as
learning set w̄d¯ := (w̄1 , . . . , w̄N ) rather than d,








w̄d¯ := 








(r0 , h00 , k 0 )
(r0 , h00 , k 0 )
(r0 , ?, k 0 )
(r0 , ?, k 0 )
(r00 , ?, k 0 )
(r00 , h0 , k 00 )
(r00 , h0 , k 00 )
(r00 , ?, k 00 )
(r00 , ?, k 00 )
(r0 , ?, k 00 )









.








We have originated this data set from d¯ by turning some values of H into missing so that
the complete portion of the data set suggests that H is a very good predictor for K. This is
going to be a problem for naive Bayes, because it has still to deal with the incompleteness
assuming MAR, which leads it to compute the counts from the learning set discarding the
missing values. NCC2, on the other hand, implicitly considers all the complete data sets
that are consistent with w̄d¯. Therefore in this case NCC2 can be regarded as the set of naive
Bayes classifiers that are obtained by considering all the precise priors previously described
in relationship with NCC2 and all the likelihoods that arise from the complete data sets
consistent with w̄d¯.
Running both classifiers to predict the class of the units in (9), we obtain that naive
Bayes predicts that the first person is not a smoker and that the second is, in both cases
with posterior probability equal to 0.90 ! NCC2, more reasonably, outputs K in both cases,
as a way to say that there is not information enough to make any reliable prediction. This
example also points out that NCC2 correctly suspends the judgment even on instances on
which precise models such as naive Bayes are actually very confident (for more details about
this point, see Section 4.4 in the paper by Corani & Zaffalon, 2008).
5.3.2 On the Failure of Empirical Evaluations
Consider the question of the IID vs. the ID assumption for an IP, as discussed in Section 5.2.2, but placed here in the context of classification. To make things easier, we focus
on finite possibility spaces, and assume in addition that the CAR IP is not present and that
the classes are always observed precisely (i.e., as singletons).
The first interesting thing to note is the following. Recall that imposing the full IID
assumption (i.e., IID both for the data-generating process and the IP) implies that the
(set-valued) observations can be regarded as the outcomes of a multinomial process. This,
together with the fact that the classes are always observed precisely, enables us to discard
the Y -variables from consideration: they are not necessary because one can learn the relationship between the classes and the features directly by using the W -variables. To make
this more clear, consider the case of incomplete samples originated by missing values. The
787

Zaffalon & Miranda

full IID assumption implies in this case that one is allowed to regard the symbol ‘?’ of missing value as a further possible value, and to proceed with the traditional learning methods
for the case of complete samples. This shows that the full IID assumption in classification
makes CIR collapse to the traditional updating rule, although applied to the W -variables.
This makes things easier to deal with, and can thus be regarded as an advantage of the
full IID assumption in classification. But we have already argued that the IID assumption
for an IP is strong, and so we turn to consider the weaker ID assumption also for pattern
classification, that we consider more tenable.
Let us focus on a very simple classification setting where the complete data are generated
in an IID way, and where the IP is ID. The problem is to predict the class of the unit
to classify given its features and the previous units (1, . . . , N ). As already mentioned in
Section 5.3, this is usually done in the precise case by following a maximum expected utility
approach. Call a model that acts in such a way a precise classifier.
It is common practice with precise classifiers to measure their accuracy empirically. In its
simplest form, this is obtained by randomly splitting the available data into a learning and
a test set, by inferring the classifier from the former and testing it on the latter. This simple,
yet powerful, idea is responsible for much of the success and popularity of classification, as
it enables one to be relatively confident about how well a classifier performs on previously
unseen data. Unfortunately, this key characteristic is lost when we cannot assume that the
unknown IP is IID.
To see why, consider (for all i = 1, . . . , N + 1) a Boolean class variable Ci and two
Boolean feature variables Ai and Bi , such that Fi = F̄i = (Ai , Bi ). Assume that the class is
the result of the exclusive logical disjunction of the two attributes: i.e., the class equals one
if and only if either the first or the second attribute equals one, but not both. Assume that
the complete data are eventually turned into incomplete data by an (unknown) IP whose
only action is to make Bi missing if and only if (Ai , Bi ) = (1, 0), for all i. Let WAi and
WBi be the observation variables for Ai and Bi , respectively. The IP is then characterised
by P (WBi =?|Ai = 1, Bi = 0) = 1, so that observing the pattern (WAi = 1, WBi =?)
implies Ci = 1 with certainty. In these conditions, any precise classifier is clearly expected
to learn that BN +1 being missing is irrelevant to predict CN +1 , whose value coincides with
the value of AN +1 . Since this is true for all the available data, partitioning them into
learning and test set will do nothing but confirm it: the prediction accuracy on the pattern
(WAN +1 = 1, WBN +1 =?) will be perfect, i.e., 100%. But the IP is not identically distributed,
and it happens that when the classifier is put to work in an operative environment, the IP
changes, in particular by making Bi missing if and only if (Ai , Bi ) = (1, 1); or, in other
words: P (WBi =?|Ai = 1, Bi = 1) = 1. Once put to work in practice, the classifier will be
always wrong on the pattern (WAN +1 = 1, WBN +1 =?), the prediction accuracy dropping to
0%.
Of course the example is designed so as to illustrate an extreme situation. However,
experiments on real data sets done without using such an extreme unknown IP, as reported
by Corani and Zaffalon (2008, Section 4.6), show that this phenomenon can indeed severely
bias the empirical measures of performance. This appears to point to a fact: that empirical
evaluations are doomed to failure in general when the data are made incomplete by a nonIID unknown process.
788

Conservative Inference Rule

These considerations may have profound implications for classification, and more generally for data analysis. These fields of scientific research rest on two fundamental pillars: (i)
that the assumptions made to develop a certain model (e.g., a classifier) are tenable; and (ii)
that empirical evaluations are reliable. The crucial point is that both pillars may be very
fragile with incomplete data, so being unable to sustain credible models and conclusions.
The way left to cope with such critical issues seems necessarily to rely on doing tenable
assumptions. This involves recognising that the incompleteness process may not be IID.

6. Advanced Notions about Coherent Lower Previsions
We introduce some advanced notions about coherent lower previsions that we need in the
rest of the paper, and in particular for the derivation of CIR in Section 7.
6.1 Coherence of a Number of Conditional Lower Previsions
Reconsider the setup introduced in Section 2 made of variables X1 , . . . , Xn about which a
subject expresses beliefs. In practice, he can provide assessments for any disjoint subsets
O, I of {1, . . . , n}; it is thus not uncommon to model a subject’s beliefs using a finite number
of different conditional lower previsions. Formally, we are going to consider what we shall
call collections of conditional lower previsions.
Definition 9 Let P 1 (XO1 |XI1 ), . . . , P m (XOm |XIm ) be conditional lower previsions with respective domains K1 , . . . , Km ⊆ L(X n ), where Kj is the set of XOj ∪Ij -measurable gambles,18
for j = 1, . . . , m. This is called a collection on X n when for each j1 6= j2 in {1, . . . , m},
either Oj1 6= Oj2 or Ij1 6= Ij2 .
This means that we do not have two different conditional lower previsions giving information
about the same set of variables XO , conditional on the same set of variables XI .
Even if all the conditional lower previsions in a collection are separately coherent, they do
not need to be coherent with one another, so that a collection could still express inconsistent
beliefs. To be able to model this joint coherence, we first introduce some new concepts.
Remember that we use IA to denote the indicator function of the set A, i.e., the function
whose value is 1 for the elements of A and 0 elsewhere.
Definition 10 For all gambles f in the domain KO∪I of the conditional lower prevision
P (XO |XI ), and all x ∈ XI , we shall denote by G(f |x) the gamble that takes
P the value
n
Iπ−1 (x) (y)(f (y)−P (f |x)) for all y ∈ X , and by G(f |XI ) the gamble equal to x∈XI G(f |x).
I

These are (almost-)desirable gambles for our subject: under the behavioural interpretation of P (f |x) as the supremum acceptable buying price for f contingent on x, the gamble
G(f |x)+Iπ−1 (x) is equivalent to buying f for the price P (f |x)−, provided that XI = x, and
I
is therefore desirable. Since this happens for  arbitrarily
P small, we deduce that the transaction G(f |x) is almost-desirable. That G(f |XI ) = x∈XI G(f |x) is also almost-desirable
follows from the rationality principle that a sum of gambles which are almost-desirable for
our subject should also be almost-desirable.19
18. We use Kj instead of KOj ∪Ij in order to alleviate the notation when no confusion is possible about which
variables are involved.
19. In the case of an infinite XI we need to add another rationality principle (Walley, 1991, Sect. 6.3.3).

789

Zaffalon & Miranda

Definition 11 The XI -support S(f ) of a gamble f in KO∪I is given by
S(f ) := {πI−1 (x) : x ∈ XI , f Iπ−1 (x) 6= 0},

(10)

I

i.e., it is the set of conditioning events for which the restriction of f is not identically zero.
Definition 12 Let P 1 (XO1 |XI1 ), . . . , P m (XOm |XIm ) be separately coherent. They are coherent when for all fj ∈ Kj , j = 1, . . . , m, j0 ∈ {1, . . . , m}, f0 ∈ Kj0 , z0 ∈ XIj0 , there is
some B ∈ {πI−1
(z0 )} ∪ ∪m
j=1 Sj (fj ) such that
j0


m
X
sup 
Gj (fj |XIj ) − Gj0 (f0 |z0 ) (x) ≥ 0,
x∈B

j=1

where Sj (fj ) is the XIj -support of fj , as defined by Equation (10).
We restrict the supremum to a subset of X n because a gamble f ≤ 0 such that f < 0
on some subset A of X n should not be desirable for our subject.
The notion in Definition 12 is sometimes also called joint (or strong) coherence. It is the
strongest notion of self-consistency in Walley’s theory, and can be regarded as the unique
axiom of such a theory. The intuition behind this notion is that we should not be able
to raise the conditional lower prevision for a gamble taking into account the acceptable
transactions implicit in the other conditional previsions. Let us make this clearer. Assume
Definition 12 fails, and that there is some δ > 0 such that


m
X

Gj (fj |XIj ) − Gj0 (f0 |z0 ) (x) ≤ −δ < 0,
(11)
j=1

(z0 )} ∪ ∪m
for every x in B ∈ {πI−1
j=1 Sj (fj ). As a consequence,
j
0

Gj0 (f0 |z0 ) − δIz0 = Iz0 (f0 − (P j0 (f0 |z0 ) + δ)) ≥

m
X

Gj (fj |XIj ),

j=1

(z0 )} ∪
taking into account that the inequality holds trivially on the elements outside {πI−1
j0
m
∪j=1 Sj (fj ), and that on this class it is a consequence of Equation (11). But since the righthand side is a sum of almost-desirable gambles, this means that the left-hand side should
also be almost-desirable. This means that any price strictly smaller than P j0 (f0 |z0 ) + δ
should be an acceptable buying price for the gamble f0 , conditional on z0 . This contradicts
the interpretation of P j0 (f0 |z0 ) as the supremum acceptable buying price.
Example 4 (Walley, 1991, Example 7.3.5) Let X1 , X2 be two random variables taking
values in X1 = X2 = {1, 2, 3}, and assume that we make the somewhat contradictory assessments X1 = 1 ⇒ X2 = 1, X1 = 2 ⇒ X2 = 2, X2 = 1 ⇒ X1 = 2, X2 = 2 ⇒ X1 = 1
and X1 = 3 ⇔ X2 = 3. These assessments can be modelled by the conditional previsions
P (X1 |X2 ) and P (X2 |X1 ) given by
P (f |X2 = 1) = f (2, 1), P (f |X2 = 2) = f (1, 2), P (f |X2 = 3) = f (3, 3)
P (f |X1 = 1) = f (1, 1), P (f |X1 = 2) = f (2, 2), P (f |X1 = 3) = f (3, 3)
790

Conservative Inference Rule

for any gamble f on X1 × X2 . To see that they are not coherent, consider the gambles
f1 = I{(1,2),(2,1)} , f2 = I{(1,1),(2,2)} , f3 = 0. It follows from Equation (10) that S1 (f2 ) =
{{1} × X2 , {2} × X2 } and S2 (f1 ) = {X1 × {1}, X1 × {2}}. Then
G(f1 |X2 ) + G(f2 |X1 ) − G(f3 |X1 = 1) = G(f1 |X2 ) + G(f2 |X1 ) < 0
on the set {(x1 , x2 ) ∈ B for some B ∈ S1 (f2 ) ∪ S2 (f1 ) ∪ {π1−1 (1)}} = X1 × X2 \ {(3, 3)}. ♦
6.2 Coherence Graphs
A collection of lower previsions can be given a graphical representation that we call a coherence graph (Miranda & Zaffalon, 2009). A coherence graph is a directed graph made of two
types of nodes: actual and dummy nodes. Dummy nodes are in one-to-one correspondence
with the lower previsions in the collection; actual nodes represent the variables X1 , . . . , Xn .
s

s

?

K

?

V

s
?

s


R

B

s
U

H

w s

? - s
s
?
?

O

A

L

Figure 3: The coherence graph originated by the A1+ -representable collection: P 1 (V ),
P 2 (K), P 3 (B|V ), P 4 (R|K), P 5 (H|K), P 6 (O|B, R), P 7 (L|O), P 8 (A|O, H).
Figure 3 shows the coherence graph for the conditional distributions owned by the nodes
of the Asia network which we represent as lower previsions, i.e., P 1 (V ), P 2 (K), P 3 (B|V ),
P 4 (R|K), P 5 (H|K), P 6 (O|B, R), P 7 (L|O), P 8 (A|O, H). In order to avoid confusion, we
stress that a coherence graph can be built out of any set of lower previsions, not just those
arising from graphical models. We use the Asia network here only for illustrative purposes.
Moreover, in building the coherence graph from the Asia net, we completely disregard any
independence information coded by the net, and we focus only on the list of conditional
distributions. Also, the coherence graph is the same irrespective of whether the conditional
assessments are linear or not.
We adopt some conventions to display a coherence graph: we denote actual nodes with
the same letter of the corresponding variable; dummy nodes are instead denoted by black
solid circles and are not labelled. Finally, for a dummy node with both a single parent and
a single child, we do not show the arrow entering the node, so as to make the graph simpler
to see.
A collection of lower previsions is turned into a coherence graph by turning each of
its lower previsions into a subgraph called a D-structure: a directed graph consisting of a
dummy node, its directed predecessors (i.e., its parents) and successors (i.e., its children),
791

Zaffalon & Miranda

and the arcs connecting the dummy node to its parents and children. The parents of the
dummy node are the actual nodes corresponding to the variables on the right-hand side
of the conditioning bar of the prevision related to the dummy node. The children are
the actual nodes corresponding to the variables on the left-hand side of the conditioning
bar. For example, the D-structure for P 1 (V ) is the subgraph in Figure 3 consisting of V ,
its dummy parent, and the arc connecting them; the D-structure for P 6 (O|B, R) is the
subgraph consisting of the actual nodes B, R, O, the dummy that is child of the first two
and parent of the last one, and the three arcs connecting them.
In order to distinguish a coherence graph from other graphical models such as Bayesian
nets, note that in a coherence graph we cannot deduce independence between nodes in the
graph: for instance, in Figure 3 we cannot conclude that the variables L, A are independent
given O, H. The reason is that we can have instances of conditional previsions with this
very same coherence graph for which the variables L and A are dependent.
Coherence graphs can have different forms, and each of these forms has some implication
on the coherence of the related collection of lower previsions. In this paper we focus on
coherence graphs called of type A1+ : these coherence graphs are acyclic and have the
property that each actual node in the graph has exactly one parent. This is indeed the case
of the graph in Figure 3. A more general class of graphs is A1 graphs, which is defined
similarly to the A1+ case but with the difference that each actual node in the graph is
required to have at most one parent.
When a coherence graph is of type A1+ (resp. A1), we say that the related collection of
lower prevision is A1+ -representable (resp. A1-representable). A1-representable collections
are interesting because the separate coherence of the lower previsions in the collection is
equivalent to their joint coherence, as shown by Miranda and Zaffalon (2009, Proposition 4).
This means that A1-representable collections are known to be coherent irrespective of the
numbers that make up their lower previsions, provided that they give rise to separately
coherent lower previsions.
6.3 Updating Coherent Lower Previsions
One updating rule that can be used with lower previsions is the regular extension:
Definition 13 Let P be a coherent lower prevision, f ∈ KO∪I and x ∈ XI an element for
which P (x) > 0, where P is the n
conjugate upper prevision derived
o from P . The regular
P (f Ix )
extension R(f |x) is R(f |x) := inf P (x) : P ∈ M(P ), P (x) > 0 .
Recall that M(P ) is the set of linear previsions P with domain L(X n ) that dominate P .
When XI is finite and P (x) > 0 for all x ∈ XI , the conditional lower prevision R(XO |XI )
defined by regular extension is coherent with P . The definition shows that the regular
extension also has a nice sensitivity analysis interpretation: i.e., applying Bayes rule to
the dominating linear previsions whenever possible. Perhaps for this reason, the regular
extension has been proposed and used a number of times in the literature as an updating
rule (e.g., De Campos, Lamata, & Moral, 1990; De Cooman & Zaffalon, 2004; Fagin &
Halpern, 1991; Jaffray, 1992; Walley, 1981, 1991, 1996b).
Example 5 Assume we know that a coin is loaded, in the sense that it either always lands
on heads or on tails, but we do not know on which. Let Xi be the outcome of a throw for
792

Conservative Inference Rule

i = 1, 2. Our beliefs about (X1 , X2 ) may be modelled by the vacuous lower prevision P on
{(heads, heads), (tails, tails)}. If we apply regular extension to define R(X2 |X1 ), we obtain
R(X2 = heads|X1 = heads) = 1, R(X2 = tails|X1 = tails) = 1,
taking into account that P (heads, heads) + P (tails, tails) = 1 for any linear prevision P ∈
M(P ). ♦
6.4 Products of Conditional Lower Previsions
We shall later use a generalisation of the marginal extension theorem (Walley, 1991, Theorem 6.7.2) established by Miranda and De Cooman (2007).
Definition 14 Let P 1 (XO1 ), P 2 (XO2 |XI2 ), . . . , P m (XOm |XIm ) be separately coherent conditional lower previsions with respective domains K1 , . . . , Km , where I1 = ∅ and Ij =
n
∪j−1
i=1 (Ii ∪ Oi ) = Ij−1 ∪ Oj−1 for j = 2, . . . , m. Their marginal extension to L(X ) is
given by
P (f ) = P 1 (P 2 (. . . (P m (f |XIm )| . . . )|XI2 )),
and it is the smallest unconditional coherent lower prevision which is (jointly) coherent with
P 1 (XO1 ), P 2 (XO2 |XI2 ), P 3 (XO3 |XI3 ), . . . , P m (XOm |XIm ).
To see that the above definition makes sense, note that for any gamble f on X n ,
P m (f |XIm ) is a gamble on XIm , and hence belongs to the domain of P m−1 (XOm−1 |XIm−1 );
then P m−1 (P m (f |XIm )|XIm−1 ) is a gamble on XIm−1 which belongs therefore to the domain
of P m−2 (XOm−2 |XIm−2 ); and by repeating the argument, P 2 (. . . (P m (f |XIm )| . . . )|XI2 ) is a
gamble on XI2 = XO1 which belongs to the domain of the unconditional prevision P 1 .
The idea behind the construction of the marginal extension is that, when we have
hierarchical information, the way to combine it into a joint prevision is to follow the order in
which this information is structured. It reduces, for instance, to the law of total probability
in the case of linear previsions and finite spaces. But it is applicable in more general
situations: when we combine a finite number of previsions, and not only two of them; when
we are dealing with infinite spaces; and when we have lower previsions instead of linear
ones.
We give next a notion of conditional independence for coherent lower previsions that we
shall use in the following.
Definition 15 Consider three variables, Xi , Xj , Xk , and a coherent conditional lower prevision P (Xi , Xj |Xk ). Xi and Xj are strongly independent conditional on Xk if Xi and Xj
are stochastically independent given Xk for all the extreme points of M(P (Xi , Xj |xk )) and
for all xk ∈ Xk .
The previous definition allows joint beliefs to be created out of marginal ones, as it is common with independence in precise probability: consider the coherent conditional lower previsions P i (Xi |Xk ) and P j (Xj |Xk ). We build their so-called strong product P sp (Xi , Xj |Xk ),
793

Zaffalon & Miranda

i.e., the least-committal lower prevision that follows from them and the assumption of strong
independence, as the lower envelope of the following set:
Msp :=

{P (Xi , Xj |Xk ) := Pi (Pj (Xj |Xi , Xk )|Xk ) s.t.∀xk ∈ Xk ,
Pi (Xi |xk ) ∈ ext(M(P i (Xi |xk ))), P (Xj |xk ) ∈ ext(M(P j (Xj |xk )),
and ∀xi ∈ Xi , Pj (Xj |xi , xk ) := P (Xj |xk )},

where Pj (Xj |Xi , Xk ) is defined using stochastic independence, and the linear prevision
P (Xi , Xj |Xk ) is obtained by applying the marginal extension theorem.
Strong independence is a relatively straightforward generalisation of stochastic independence to imprecision. It is also a notion that can immediately be given a sensitivity
analysis interpretation: since for every xk ∈ Xk each extreme point of M(P sp (Xi , Xj |xk ))
satisfies stochastic independence, we can interpret P sp (Xi , Xj |Xk ) as a model arising from
partial knowledge of an underlying linear prevision P (Xi , Xj |Xk ) which is known to satisfy
stochastic independence. In other words, P sp (Xi , Xj |Xk ) could be regarded as obtained
by listing a number of candidate linear previsions P (Xi , Xj |Xk ), each of which satisfies
stochastic independence, and by taking their lower envelope.
It should also be remarked that in the imprecise case, where we work with sets of probabilities or previsions, there is not a unique extension of the notion of stochastic independence
of probability measures (see Campos & Moral, 1995; Couso et al., 2000; or Miranda, 2008,
Section 4). The notion we have just considered is the strongest, and therefore more informative, of the possibilities considered in the references above.20
A notion alternative to strong independence is for instance epistemic irrelevance as
proposed by Walley (1991, Section 9.1.1).
Definition 16 Given the coherent lower previsions P i (Xi |Xj , Xk ) and P i (Xi |Xk ), we say
that Xj is epistemically irrelevant to Xi conditional on Xk if it holds that P i (Xi |Xj , Xk ) =
P i (Xi |Xk ).
Epistemic irrelevance is naturally suited for a behavioural interpretation: Xj is irrelevant
to Xi given Xk because in the context of Xk the beliefs of a subject about Xi , expressed
by the coherent lower prevision P i (Xi |Xk ), do not change after getting to know the value
of Xj . A sensitivity analysis interpretation of epistemic irrelevance is not possible in general because for a joint created out of marginal information and epistemic irrelevance, the
related extreme points do not necessarily satisfy stochastic independence. In fact, strong
independence implies epistemic irrelevance while the converse implication does not hold.
Moreover, irrelevance is an asymmetric notion: knowing that Xj is irrelevant to Xi does
not imply that Xi is irrelevant to Xj . One can create a symmetric notion of epistemic independence (see, e.g., Walley, 1991; Miranda, 2008) by requiring that both Xj is irrelevant
to Xi and Xi is irrelevant to Xj ; still, strong independence implies epistemic independence
but the other way around does not hold.
Strong independence can be expressed by means of epistemic irrelevance together with
a further requirement. Consider P i (Xi |Xk ) and P j (Xj |Xk ); we want to create their strong
20. This is related to the fact that it never holds that all the precise previsions in a convex set with more
than one element satisfy stochastic independence; therefore requiring it for the extreme points of the
credal set, which are the ones keeping all the behavioural information, amounts to go as far as possible
on the direction to independence.

794

Conservative Inference Rule

product using epistemic irrelevance. We first write that P j (Xj |Xi , Xk ) = P j (Xj |Xk ), as
strong independence implies epistemic irrelevance. Then we apply the marginal extension
theorem to create the so-called irrelevant product P ip (Xi , Xj |Xk ) = P i (P j (Xj |Xi , Xk )|Xk ),
which is the least committal lower prevision that follows from the marginals and the assumption of epistemic irrelevance. In terms of the sets of dominating linear previsions, the
marginal extension theorem states that P ip (Xi , Xj |Xk ) is the lower envelope of the set
Mip :=

{P (Xi , Xj |Xk ) = Pi (Pj (Xj |Xi , Xk )|Xk ) : ∀xi ∈ Xi , xk ∈ Xk ,
Pi (Xi |xk ) ∈ ext(M(P i (Xi |xk ))), Pj (Xj |xi , xk ) ∈ ext(M(P j (Xj |xi , xk )))}.

Even if for all xk ∈ Xk the sets ext(M(P j (Xj |xi , xk ))), xi ∈ Xi , are identical to one another
because of the irrelevance condition, when building a joint prevision P (Xi , Xj |Xk ) we are
not forced to choose the same extreme point in each of them. This is just what makes the
difference between Mip and Msp , and in fact we can write Msp in a way more similar to
Mip as follows:
Msp :=

{P (Xi , Xj |Xk ) = Pi (Pj (Xj |Xi , Xk )|Xk ) : ∀xi ∈ Xi , xk ∈ Xk ,
Pi (Xi |xk ) ∈ ext(M(P i (Xi |xk ))), Pj (Xj |xi , xk ) ∈ ext(M(P j (Xj |xi , xk )))
s.t. Pj (Xj |x0i , xk ) = Pj (Xj |x00i , xk ) if x0i = x00i }.

In other words, we can think of the strong product as obtained by the same procedure that
we use for the irrelevant product, with the additional requirement that for each xk ∈ Xk ,
the extreme points chosen in ext(M(P j (Xj |xi , xk ))), xi ∈ Xi , must coincide every time.
We shall use this observation in Section 7.1.3.

7. Derivation of CIR
In the next sections we state a number of assumptions, discuss them, and eventually use
them to derive CIR.
7.1 Modelling Beliefs
Our aim in this section is to represent our beliefs about the vector (Z, Y, W ). We intend
to model beliefs using coherent lower previsions. We refer to Sections 2 and 6 and, more
generally, to the book by Walley (1991) for the concepts and results we shall need.
A way to represent beliefs about (Z, Y, W ) is through a coherent lower prevision on L(Z×
Y ×W), representing our joint beliefs about these variables. But, as with precise probability,
it is often easier to build joint models out of the composition of simpler conditional and
unconditional models. We shall therefore start by focusing on the following lower previsions,
which we illustrate for clarity by a coherence graph in Figure 4:
(LP1) A coherent lower prevision, denoted by P 1 , on the set of XZ,Y -measurable gambles;
(LP2) A separately coherent conditional lower prevision P 2 (W̄ |Z, Y ) on the set of XZ,Y,W̄ measurable gambles, modelling our beliefs about W̄ given the value (z, y) taken by
(Z, Y ).
795

Zaffalon & Miranda

s
)

Z

?

Ȳ

j?
s
?

W̄

q

Ŷ
q?
z
s
*
?

Ŵ

Figure 4: The coherence graph for the initial conditional lower previsions that express beliefs about (Z, Y, W ).

(LP3) A conditional lower prevision P 3 (Ŵ |Z, Y, W̄ ) on L(Z × Y × W), representing our
beliefs about Ŵ given the value that (Z, Y, W̄ ) takes.
The coherent lower prevision P 1 is intended to express our beliefs about the domain of
interest, which is modeled by the variables Z and Y . In other words, by P 1 we express
our beliefs about facts. The conditional lower prevision P 2 (W̄ |Z, Y ) is concerned with
our beliefs about the unknown incompleteness process. Finally, by the conditional lower
prevision P 3 (Ŵ |Z, Y, W̄ ) we express our beliefs about the CAR incompleteness process.
How exactly this is done is detailed in the next sections. For the moment, we are going
to build a joint coherent lower prevision for (Z, Y, W ) out of the lower previsions listed
in (LP1)–(LP3). This is done by the marginal extension theorem introduced in Section 6.4.
In the present case, the generalised marginal extension theorem states that the lower
prevision P given by
P (f ) = P 1 (P 2 (P 3 (f |Z, Y, W̄ )|Z, Y ))
for all gambles f on Z × Y × W is the smallest (using the point-wise ordering of lower
previsions) coherent lower prevision on L(Z × Y × W) that is jointly coherent with the
lower previsions listed in (LP1)–(LP3). This implies, for example, that P coincides with
the coherent lower prevision P 1 on its domain. Because it is the smallest lower prevision
to be coherent with our assessments, P captures the behavioural implications present in
P 1 , P 2 (W̄ |Z, Y ) and P 3 (Ŵ |Z, Y, W̄ ), without making any additional assumptions; we shall
therefore use it as the model of our beliefs about the vector (Z, Y, W ).
P is also the lower envelope of the closed and convex set M(P ) of dominating linear
previsions. It will be useful for the purposes of this paper to construct this set explicitly.
Consider the set
(
)
X
M0 := P : P (g) = P1 (hg ), hg (z, y) :=
g(z, y, w)P2 (w̄|z, y)P3 (ŵ|z, y, w̄) ,
(12)
w

for all g ∈ L(Z, Y, W), where P1 ∈ ext(M(P 1 )), P2 (W̄ |z, y) ∈ ext(M(P 2 (W̄ |z, y))) and
P3 (Ŵ |z, y, w̄) ∈ ext(M(P 3 (Ŵ |z, y, w̄))) for any (z, y, w) ∈ Z × Y × W. Then M(P ) =
CH(M0 ), where the operator CH(·) stands for convex closure. As a consequence, P can
be calculated as the lower envelope of the class M0 .
796

Conservative Inference Rule

7.1.1 Domain Beliefs
Consider variables Z and Y , which represent facts. Beliefs about facts, in the form of a
coherent lower prevision P 1 , are specific of the domain under consideration; for this reason,
we call them domain beliefs. In the case of the Asia network, P 1 would correspond simply
to the joint mass function coded by the network itself.
We shall impose only a minimal assumption about domain beliefs, just because P 1 must
be as flexible a tool as possible in order to express beliefs in a wide range of domains. This
task will be postponed after focusing on a very different kind of beliefs, which we call beliefs
about the incompleteness process.
7.1.2 Beliefs about the Incompleteness Process
These are naturally of a conditional type: they formalise what we believe about the ‘modus
operandi’ of the overall IP, i.e., the procedure by which it turns facts into observations.
We represent these beliefs through assumptions to be satisfied by the conditional lower
prevision P 2 (W̄ |Z, Y ), related to the unknown IP, and P 3 (Ŵ |Z, Y, W̄ ), related to the CAR
IP. We start with the unknown IP.
The unknown IP has been introduced to formalise the idea of an incompleteness process
about which we are nearly ignorant. The term ‘nearly’ is there to emphasise that, despite a
deep kind of ignorance, something is assumed to be known about the unknown IP. For one
thing, it produces incompleteness only on the basis of Ȳ . More formally, we assume that
there is a separately coherent conditional lower prevision P 2 (W̄ |Ȳ ) such that
P 2 (f |z, y) = P 2 (f |ȳ)

(BIP1)

for all XW̄ ,Y,Z -measurable gambles f and any (z, y) in (Z, Y).
(BIP1) states that observing different values for Z and Ŷ does not change our beliefs about
W̄ , once we know what value Ȳ takes in Ȳ. This assumption turns the coherence graph in
Figure 4 into that of Figure 5. Assumption (BIP1) arises somewhat naturally within our
interpretation of IPs as observational processes, in which we regard the unknown IP just
as a process that takes Ȳ in input and outputs W̄ . Still, it is an important assumption for
the following developments, and is therefore discussed in some detail in Section 7.2.
s
)

Z

?

Ȳ

s
?

W̄

q

Ŷ
q?
z
s
*
?

Ŵ

Figure 5: The coherence graph in Figure 4 after the application of Assumption (BIP1).
797

Zaffalon & Miranda

The second thing that we assume about the unknown IP is related to the perfection of
the multi-valued map ΓȲ :21
(BIP2)
ȳ ∈ Ȳ ⇒ P 2 (Γ(ȳ)c |ȳ) = 0.
In other words, by this assumption we practically exclude the possibility that for some
ȳ ∈ Ȳ, the unknown IP may lead to observations outside Γ(ȳ). Note that for this to be well
defined, it is important to assume that Γ(ȳ) is nonempty as required by (IP4). Remember
that, here and elsewhere, we use P to refer to the conjugate upper prevision of P ; see
Remark 1 for more details.
Nothing more is assumed about the unknown IP. We are then led to introduce some
assumptions about the CAR IP, of which the first two are analogous to (BIP1) and (BIP2),
respectively. The first one is the existence of a separately coherent conditional lower prevision P 3 (Ŵ |Ŷ ) such that
P 3 (f |z, y, w̄) = P 3 (f |ŷ)
(BIP3)
for all XW,Y,Z -measurable gambles f and (z, y, w̄) in (Z, Y, W̄). This assumption turns the
coherence graph in Figure 5 into that of Figure 6.
s
)

Z

?

Ȳ

s
?

W̄

q

Ŷ
s
?

Ŵ

Figure 6: The coherence graph in Figure 5 after the application of Assumption (BIP3).
The second is an assumption of perfection of the multi-valued map ΓŶ :
ŷ ∈ Ŷ ⇒ P 3 (Γ(ŷ)c |ŷ) = 0.

(BIP4)

Again, this assumption is made possible by (IP5).
Now we assume something more substantial about the CAR IP. Indeed, the CAR IP
has been introduced to model a process that produces incompleteness in a random fashion,
that is to say, in a way that is not related to the underlying value that Ŷ takes in Ŷ. We
model this belief as follows:
ŵ ∈ Ŵ, ŷ ∈ {ŵ}∗ ⇒ P 3 (ŵ|ŷ) = P 3 (ŵ|ŷ) = αŵ ,
(BIP5)
P
where the αŵ ’s are positive constants that satisfy ŵ∈Γ(ŷ) αŵ = 1, where the restriction
ŵ ∈ Γ(ŷ) is justified by (BIP4).
This assumption is usually called coarsening at random (or CAR, see Gill et al., 1997).
In the special case of missingness processes, one usually refers to CAR as missing at random
(or MAR, see Little & Rubin, 1987). CAR/MAR is probably the most frequently imposed
21. It could be argued that this assumption and the corresponding one for the CAR IP, that is, (BIP4), follow
from the definition of the multi-valued maps. This nevertheless, we state the assumptions explicitly for
clarity.

798

Conservative Inference Rule

assumption on IPs in the literature; it embodies the idea that an IP is non-selective (or
non-malicious) in producing observations. Together with (BIP4), it makes the conditional
prevision P 3 (Ŵ |Ŷ ) precise: i.e., our beliefs about the CAR IP are determinate (they are
then the conditional expectation with respect to a probability distribution). An important
point is that we must require explicitly that ΓŶ be compatible with the CAR assumption
(see Appendix A for details); this leads to an assumption about ΓŶ other than those reported
in Section 3.3: we assume that
ΓŶ leads through (BIP5) to an admissible system of linear constraints,

(IP9)

that is, one that has a solution.
Now that we have characterised the unknown and the CAR IPs, we have also to determine the way in which they interact to make up the overall IP; we do this by imposing an
assumption of strong independence, as introduced in Section 6.4:
W̄ and Ŵ are strongly independent conditional on Y.

(BIP6)

This assumption is discussed in Section 7.2.22
7.1.3 Joint Beliefs
In this section we aim at constructing the joint coherent lower prevision P mentioned at the
beginning of Section 7.1. To do that, we need first to find explicit representations for the
assessments related to the unknown and the CAR IP, on the basis of Assumptions (BIP1)–
(BIP6). The joint will be constructed then using the marginal extension theorem mentioned
at the beginning of the section, and taking into account the assumption of strong independence (BIP6).
Consider the unknown IP. Assumption (BIP1) allows us to focus our attention on the
conditional lower prevision P 2 (W̄ |Ȳ ). Thanks to Assumption (BIP2), we know that for
any ȳ in Ȳ, P 2 (W̄ |ȳ) gives lower probability one to Γ(ȳ). Since we know nothing else, we
take P 2 (W̄ |ȳ) to be the least-committal such lower prevision, i.e., the smallest separately
coherent conditional lower prevision that assigns probability one to Γ(ȳ). Such a lower
prevision is also called vacuous relative to Γ(ȳ), and is given by P 2 (f |ȳ) = min{f (w̄, ȳ) :
w̄ ∈ Γ(ȳ)} for any XW̄ ,Ȳ -measurable gamble f .23
22. There are similarities between the model developed in this section and the more traditional hidden
Markov models (see for instance Rabiner, 1989). First, both focus on the distinction between the two
levels of information, the latent and the manifest one, as discussed in the Introduction. For this reason
both are concerned with an explicit representation of the observational process, which is what relates
the W and the Y variables, and which in our case coincides with the incompleteness process. If we refer
to Figure 6, to make things more concrete, we see that the W -variables are manifest and they depend
directly only on the related hidden Y -variables. This is a common representation in hidden Markov
models. Second, Assumption (BIP6) could be interpreted as a kind of Markovianity property. Yet, there
are also differences: a major one is the two W -variables are not related to an order (such as a time order),
and more generally that we are not explicitly representing any order in our model. Another is that we
quantify the probabilistic information of an observation conditional on the related hidden variable by a
set of conditional mass functions rather than a single one. This gives us more expressivity and is the key
to model the unknown IP.
23. It follows from this that the implication in (BIP2) is actually an equivalence.

799

Zaffalon & Miranda

Using indicator functions, we can easily write the extreme points of M(P 2 (W̄ |ȳ)). Let
Iγ̄ : W̄ → {0, 1} be the indicator function for γ̄ ∈ Γ(ȳ). We write Iγ̄ rather than I{γ̄} to
simplify notation. Then ext(M(P 2 (W̄ |ȳ))) = {Iγ̄ : γ̄ ∈ Γ(ȳ)}. This concludes the definition
of P 2 (W̄ |ȳ) and also of P 2 (W̄ |z, y), given that they coincide. Yet, when dealing with
P 2 (W̄ |z, y), we shall use a slightly different formulation: ext(M(P 2 (W̄ |z, y)) = {Iγ̄(z,y) :
γ̄(z, y) ∈ Γ(ȳ)}. The reason is that the extended notation γ̄(z, y) allows us to know, in
addition to the vertex, the value (z, y) on which we focus, and, consequently, that we focus
on the specific lower prevision P 2 (W̄ |z, y). Hence, we shall see γ̄ as a mapping from Z × Y
to W̄ such that for any (z, y), γ̄(z, y) belongs to Γ(ȳ).
The situation is somewhat easier with the CAR IP. Similarly to the previous case,
we know that we can restrict our attention to the conditional lower prevision P 3 (Ŵ |Ŷ ),
thanks to (BIP3). But we also know that the conditional lower prevision P 3 (Ŵ |Ŷ ) is
actually precise (we shall denote it by P3 (Ŵ |Ŷ ) from now on), and P3 (Ŵ |ŷ) consists of the
single mass function determined by Assumption (BIP5): i.e., the mass function that assigns
probability P (ŵ|ŷ) = αŵ I{ŵ}∗ (ŷ) to the generic element ŵ ∈ Ŵ.
At this point we can define the coherent lower prevision P that models our beliefs about
the value that (Z, Y, W ) assume jointly. We do this by rewriting Expression (12) according
to the previous arguments and using in addition (BIP6):
M0 := {P : P (g) = P1 (hg ), hg (z, y) =

P

w

αŵ g(z, y, w)Iγ̄(z,y) (w̄)I{w̄}∗ (ȳ)I{ŵ}∗ (ŷ),

P1 ∈ ext(M(P 1 )), γ̄(z, y) ∈ Γ(ȳ) s.t. γ̄(z, y) = γ̄(z 0 , y 0 ) if ȳ = ȳ 0 ,
(z, y, w) ∈ Z × Y × W},

(13)

where we have introduced the new term I{w̄}∗ (ȳ). Such a term is actually redundant, and
is introduced only because it is convenient for the next developments. To see that it is
redundant, note that I{w̄}∗ (ȳ) = 0 implies that w̄ ∈
/ Γ(ȳ) and hence, since γ̄(z, y) ∈ Γ(ȳ) by
definition, we have that Iγ̄(z,y) (w̄) = 0. The usage of (BIP6), on the other hand, leads to the
more substantial introduction of the requirement that γ̄(z, y) = γ̄(z 0 , y 0 ) when ȳ = ȳ 0 . This
is needed to represent strong independence by means of epistemic irrelevance, as discussed
at the end of Section 6.4. The lower envelope P of the set M0 thus constructed is therefore
called the strong product of the assessments P 1 (Z, Y ), P 2 (W̄ |Ȳ ), P3 (Ŵ |Ŷ ).
That the strong product is a coherent lower prevision, which is also coherent with
P 1 (Z, Y ), P 2 (W̄ |Ȳ ), P3 (Ŵ |Ŷ ), follows from Corollary 1 in Appendix B. Importantly, this
is also the case if the coherent lower prevision P 1 (Z, Y ) is constructed in a modular way
from smaller pieces of information (i.e., as a joint which is coherent with a number of smaller
pieces of information), provided that the coherence graph representing them is A1+ ; such
a situation is very often the case. It is the case, for instance, for all the the examples in
Sections 5.1–5.3, as shown by Corollaries 3–5 in Appendix B.
7.1.4 An Assumption about Domain Beliefs
Recall that we have introduced W as a way to model observations, and hence our beliefs
should be consistent with the possibility of doing such an observation. To this extent, it
seems necessary that we at least believe that {w}∗ can be produced:
w ∈ W ⇒ P ({w}∗ ) > 0,
800

(DB1)

Conservative Inference Rule

taking into account that coherence implies that P ({w}∗ ) = P 1 ({w}∗ ). Assumption (DB1)
is equivalent to the existence of an extreme point P1 of M(P 1 ) such that P1 ({w}∗ ) > 0. The
following proposition shows that this assumption is sufficient to make our beliefs consistent
with the possibility to do the observation w.
Proposition 1 Assumption (DB1) implies that P (w) := P (Z, Y, w) > 0.
Proof. Let P1 be an extreme point of M(P 1 ) satisfying P1 ({w}∗ ) > 0, which exists by
Equation (DB1), and take γ̄(z, y) = w̄ for any ȳ ∈ {w̄}∗ . The joint P constructed from
Equation (13) satisfies P (w) = αŵ P1 ({w}∗ ) > 0. Hence, P (w) > 0. 2
7.2 Assumptions Discussed
We now discuss (BIP1), (BIP5) and (BIP6) in more detail. The other assumptions are quite
weak and relatively easy to accept. Assumptions (BIP2) and (BIP4) may be exceptions as
it makes sense to consider IPs that are imperfect (or that can lie), but this is out of the
scope of the present paper.
We start with Assumption (BIP5), i.e., CAR. CAR models a process that does not
coarsen facts with a specific purpose. CAR excludes in this way many common and important processes. Consider the medical domain, for example, focusing on a diagnostic
application. A fact in this case might describe information about a patient, such as gender,
age, lifestyle, and also the results of medical tests. Conclusions would be made by the
possible diseases. The IP in this case (at least part of it) often results from the interaction
between the doctor and the patient; indeed, there is usually a systematic bias in reporting,
and asking for, symptoms that are present instead of symptoms that are absent; and a
bias to report, and ask for, urgent symptoms more than others (Peot & Shachter, 1998).
Furthermore, a doctor typically prescribes only a subset of the possible diagnostic tests,
according to personal views and cost/benefit criteria.24 Overall, the process described is
non-CAR by definition, because the incompleteness arises following patterns that do depend
on the specific facts under consideration.
Descriptions such as the one above support the idea that CAR is strong by means of
informal arguments. But also on the formal level, recent research has suggested that CAR
should be assumed to hold less frequently that it appears to be in practice (Grünwald &
Halpern, 2003); and one should also remember that there is no way to test CAR statistically
(Manski, 2003), so that there is always some degree of arbitrariness in assuming it. All of
this should be taken into account in order to put CAR in a more balanced perspective.
This is not to say that CAR should be rejected a priori, as there are situations when CAR
is completely justified. Consider one notable example: the case when we know that Ŷ is
missing with probability equal to one. In this case the related IP clearly satisfies MAR: the
probability of missingness is one irrespective of the value of Ŷ . More broadly speaking, MAR
holds for processes that produce missingness in an unintentional way. In these cases, not
24. This seems to support the idea that we shall hardly get ever rid of incompleteness: often, incompleteness
does not happen by mistake, rather, it is generated deliberately. In these cases it actually represents
patterns of knowledge (indeed, one can often tell what disease a patient was, or was not, suspected to
have by looking only at the medical tests that a doctor did, and did not, prescribe). In this sense, it
seems that incompleteness is doomed to be deeply rooted to many, if not most, real problems; and as
such, it appears to be a fundamental, and indissoluble, component of uncertain reasoning.

801

Zaffalon & Miranda

assuming MAR would lead to results that are far too weak. The CAR IP in the modelling
framework presented in Section 7.1.2 is designed just to account for these situations: i.e., to
provide one with some flexibility in stating beliefs about the incompleteness process without
having to adopt necessarily a worst-case approach (as opposed to the best case embodied
by CAR/MAR), of the kind of the unknown IP.
The unknown IP is designed to model one’s ignorance about an incompleteness process.
It makes sense to adopt a conservative approach to model IPs in practice, for two specific
reasons: first, IPs may be very difficult processes to model. They are a special case of
observational processes, which often result from by human-to-human interaction, or by
other complex factors; in a number of cases they can actually be regarded as the result of a
communication protocol. The medical example above is intended to illustrate just this. It is
not saying anything new: the difficulty in modelling IPs has been pointed out already long
ago (Shafer, 1985; Grünwald & Halpern, 2003). But IPs are difficult objects to handle also
for a second reason: IP models can be tightly dependent on specific situations. Consider
the medical example: again different doctors typically ask different questions to diagnose
a disease, even in the same hospital. By changing hospital, one can find entirely different
procedures to diagnose the same disease, as the procedures depend on the local culture, on
the money available to make the tests, and which ones, or the local time constraints. In
other words, even if one is able to model an IP for a specific situation, that model may no
longer be appropriate when another doctor is in charge of doing the diagnosis, or when one
tries to apply the IP model to another hospital, perhaps in another country. In summary,
modelling the IP (especially in a precise way) may present serious practical difficulties,
as, in contrast with domain beliefs (e.g., medical knowledge), the way information can be
accessed may well depend on the particular environment where a system will be used; and
this means that models of the IP may not be easily reusable, and may therefore be costly.
These arguments support considering a conservative approach to model the IP that
can be effectively implemented, and this is the reason for introducing the unknown IP in
Section 7.1.2. Recall that the unknown IP is actually only nearly unknown, because we
require that (BIP1) holds. On the other hand, observe that by dropping (BIP1) we could
draw only vacuous conclusions about Z. To see this, suppose that you want to predict
the probability of Z = z given a certain observation w. Assume from now to the end
of the section that there is no CAR IP, in order to make things easier. Then without
assuming (BIP1), we could not exclude the possibility that the IP produces w if and only
if Z 6= z, so that the probability of Z = z is zero. In the same way, we could not exclude
the possibility that the IP produces w if and only if Z = z, so that the probability of Z = z
is one. Of course, all the intermediate randomised cases would also be possible, so that the
probability would be vacuous. This is to emphasise, perhaps not surprisingly, that complete
ignorance about an IP is not consistent with the possibility of drawing useful conclusions.
Having said this, it is still useful to wonder whether (BIP1) is reasonable in the present
setup. This is easier to do if we rewrite (BIP1) in a somewhat more natural form. We focus
on the special case where the spaces of possibilities are finite and we have precise beliefs
about the unknown IP. We can then multiply both sides of the equation P (w|z, y) = P (w|y)
by the conditional probability of z given y, obtaining P (z, w|y) = P (z|y)P (w|y). The new
equation states that variables Z and W are independent conditional on Y . In other words,
the original assumption is then equivalent to saying that if we already know fact y, making
802

Conservative Inference Rule

the observation w is completely superfluous for predicting the target variable. This appears
to be nothing else but the precise characterisation of the problems of incomplete or missing
information: these problems are characterised by the fact that when something that can be
missing is actually measured, the problem of missing information disappears. If this were
not the case, the observation w would not only carry information about z via its implications
on the fact y: it would say something about z also on its own. But this means that some
information useful to predict the target variable has not been included in the definition of
the possible facts (see the work by De Cooman & Zaffalon, 2004 for further discussion about
an assumption called MDI that is related to the assumption under consideration).
We conclude this section discussing Assumption (BIP6), namely the strong independence
of W̄ and Ŵ conditional on Y . We discuss this assumption because one could in principle
consider weaker notions of independence to replace strong independence.
The reason why we have used strong independence is that for the kind of general framework that we have developed it is technically quite difficult to embed other judgments of
independence of W̄ and Ŵ conditional on Y . On the other hand, the problem with strong
independence is that it does not easily lend itself to a full behavioural interpretation unlike other notions, such as epistemic irrelevance or independence. And we acknowledge
that the behavioural interpretation is important both as a way to guide the mathematical
developments and when one comes to decision making.
Yet, one could argue that the inference rule, CIR, that follows from our assumptions is
the weakest possible one (if we exclude the rule that leads to vacuous posterior expectations
and that does not lead to any informative conclusion) for the part related to the unknown
IP, because it leads to consider all the replacements for the missing information as the
possible latent data. Therefore one could conjecture that by replacing strong independence
of W̄ and Ŵ conditional on Y with a weaker notion of independence, the inference rule
could either stay the same or lead to vacuous inferences. Whatever the outcome, the choice
of strong independence would be even more reasonable.
7.3 Derivation of CIR
In order to formulate the basic problem of this paper in a sufficiently general way, we focus
on the problem of updating beliefs about a generic function g : Z → R, to posterior beliefs
conditional on W = w. In the precise case, this would be done by computing
P (g|w) =

P (gIw )
,
P (w)

provided that P (w) > 0.
Something similar can be done in the imprecise case, but in such a case it not uncommon
for P (w) to be zero. In that case, we should obtain an infinite number of conditional lower
previsions which are coherent with P (W ). This has been already discussed by De Cooman
and Zaffalon (2004), who proposed the regular extension as a more effective updating rule.
This is a very natural choice also under the sensitivity analysis interpretation of coherent
lower previsions, as pointed out in Section 6.3, and is therefore also the choice that we
pursue. Using the regular extension entails an additional rationality assumption that is
reported by Walley (1991, Appendix J3); its coherence with the unconditional lower prevision it is derived from is trivial in the present context, where W is finite (see Appendix B
803

Zaffalon & Miranda

for more details). We also recall that if P (w) > 0, the regular extension provides the only
coherent updated lower prevision.
The form of the CIR rule given in Definition 7 in Section 4 is derived in the next theorem.
It is important to remark that for this theorem to hold, we need to require that the space Ȳ
of the unknown IP be finite, while this is not necessary for all the other results we establish
in Appendix B. The reason for this is that when Ȳ is infinite the class {w̄}∗1 that we define
in the theorem may be empty for some w̄ in W̄, making the rule inapplicable.
Theorem 1 (Conservative inference rule theorem) Consider a gamble g on Z and
w ∈ W. Let {w̄}∗1 := {ȳ ∈ {w̄}∗ : P 1 (ȳ, {ŵ}∗ ) > 0}, and let us define the regular extension
R(g|ȳ, {ŵ}∗ ) =

inf

P ≥P 1 :P (ȳ,{ŵ}∗ )>0

P (g|ȳ, {ŵ}∗ )

for all ȳ ∈ {w̄}∗1 . Then
R(g|w) = E 1 (g|w) := min ∗ R(g|ȳ, {ŵ}∗ ).
ȳ∈{w̄}1

Proof. First of all, for any prevision P constructed using Equation (13),
X
X
P (w) = αŵ
P (ȳ, {ŵ}∗ ) = αŵ
P (ȳ, {ŵ}∗ ),

(14)

ȳ∈{w̄}∗ ,γ̄(z,y)=w̄

ȳ∈Ȳ,γ̄(z,y)=w̄

for any w ∈ W, where the second equality follows from Assumption (BIP2), and also taking
into account that the mapping γ̄ depends only on the value of Ȳ . Similarly, we also have
X
X
P (gIȳ,{ŵ}∗ ) = αŵ
P (gIȳ,{ŵ}∗ )
P (gIw ) = αŵ
ȳ∈{w̄}∗ ,γ̄(z,y)=w̄

ȳ∈Ȳ,γ̄(z,y)=w̄

for any w ∈ W and any gamble g on Z.
Fix w ∈ W, and define M := {P ≥ P 1 : P (w) > 0}, M1 := {P ≥ P 1 : P (ȳ, {ŵ}∗ ) >
0 for some ȳ ∈ {w̄}∗ }. For all gambles g on Z, R(g|w) = inf{P (g|w) : P ∈ M} and
E 1 (g|w) = inf{P (g|ȳ, {ŵ}∗ ) : P ∈ M1 }.
We start proving that E 1 (g|w) ≥ R(g|w). For this, we are going to prove that for any
ȳ ∈ {w̄}∗ and any P ∈ M1 such that P (ȳ, {ŵ}∗ ) > 0 there is some P 0 ∈ M such that
P 0 (g|w) ≤ P (g|ȳ, {ŵ}∗ ). Consider then such P , and let P1 be its restriction to L(Z × Y).
Then P1 ≥ P 1 . Let γ̄ be a mapping such that γ̄(z, y) = w̄ and γ̄(z 0 , y 0 ) 6= w̄ when ȳ 0 6= ȳ.
We can construct such a mapping because by Assumption (IP8) the set {w̄}∗ is empty, and
0
therefore for every ȳ 0 ∈ {w̄}∗ there is some w̄ 6= w̄ such that ȳ 0 ∈ {w̄0 }∗ . Let P 0 ≥ P be
the joint prevision constructed from P1 and γ̄ using Equation (13). Taking into account
Equation (14), we see that this prevision satisfies P 0 (w) = αŵ P 0 (ȳ, {ŵ}∗ ) = αŵ P (ȳ, {ŵ}∗ ) >
0. As a consequence,
P 0 (g|w) =

αw P 0 (gIȳ,{ŵ}∗ )
P (gIȳ,{ŵ}∗ )
P 0 (gIw )
=
=
= P (g|ȳ, {ŵ}∗ ),
P 0 (w)
αw P 0 (ȳ, {ŵ}∗ )
P (ȳ, {ŵ}∗ )

where the last equality holds because P (ȳ, {ŵ}∗ ) > 0. Hence, we deduce that E 1 (g|w) ≥
R(g|w).
804

Conservative Inference Rule

We show now the converse inequality. We are going to prove that for any P ∈ M there
is some P 0 ∈ M1 such that P (g|w) ≥ P 0 (g|y, {w̄}∗ ). Consider P ∈ M.
P
P
αŵ ȳ∈{w̄}∗ ,γ̄(z,y)=w̄ P (gIȳ,{ŵ}∗ )
P (gIw )
ȳ∈{w̄}∗ ,γ̄(z,y)=w̄ P (gIȳ,{ŵ}∗ )
P
P
=
P (g|w) =
=
.
∗
P (w)
αŵ ȳ∈{w̄}∗ ,γ̄(z,y)=w̄ P (ȳ, {ŵ}∗ )
ȳ∈{w̄}∗ ,γ̄(z,y)=w̄ P (ȳ, {ŵ} )
Define I := {ȳ ∈ {w̄}∗ s.t. P (ȳ, {ŵ}∗ ) > 0, γ̄(z, y) = w̄}. Since P (w) > 0, it follows
from Equation (14) that this set is nonempty, and the above equality can be expressed as
P
ȳ∈I P (gIȳ,{ŵ}∗ )
P (g|w) = P
.
∗
ȳ∈I P (ȳ, {ŵ} )
Applying Lemma 3 in the Appendix we deduce the existence of ȳ1 ∈ I such that
P
P (gIȳ1 ,{ŵ}∗ )
ȳ∈{w̄}∗ ,γ̄(z,y)=w̄ P (gIȳ,{ŵ}∗ )
≤ P
.
∗
∗
P (ȳ1 , {ŵ} )
ȳ∈{w̄}∗ ,γ̄(z,y)=w̄ P (ȳ, {ŵ} )
Let P1 be the restriction of P to L(Z × Y). Consider a mapping γ̄ such that γ̄(z, y) = w̄
when ȳ = ȳ1 and γ̄(z 0 , y 0 ) 6= w̄ for any other y 0 . We can construct such a mapping because
by Assumption (IP8) the set {w̄}∗ is empty, and therefore for every ȳ 0 ∈ {w̄}∗ there is some
0
w̄ 6= w̄ such that ȳ 0 ∈ {w̄0 }∗ . Let P 0 ≥ P be the joint prevision constructed from P1 and γ̄
using Equation (13). This prevision satisfies P 0 (ȳ1 , {ŵ}∗ ) = P (ȳ1 , {ŵ}∗ ) > 0. Moreover,
P
P 0 (gIȳ1 ,{ŵ}∗ )
P (gIȳ1 ,{ŵ}∗ )
ȳ∈{w̄}∗ ,γ̄(z,y)=w̄ P (gIȳ,{ŵ}∗ )
0
∗
P
P (g|ȳ1 , {ŵ} ) = 0
= P (g|w),
=
≤
∗
P (ȳ1 , {ŵ}∗ )
P (ȳ1 , {ŵ}∗ )
ȳ∈{w̄}∗ ,γ̄(z,y)=w̄ P (ȳ, {ŵ} )
where the second equality follows because P 0 = P = P1 on L(Z × Y). We deduce from this
E 1 (g|w) ≤ R(g|w) and as a consequence they are equal. 2
An important point is whether the lower prevision defined by the CIR rule in this
theorem is going to be coherent with the initial assessments: P 1 (Z, Y ), P 2 (W̄ |Ȳ ), P3 (Ŵ |Ŷ ).
We want this to be the case as we want CIR to lead to self-consistent inference. This question
is given a positive answer by Theorem 3 in Appendix B.
Moreover, from this theorem we also deduce (in its subsequent Corollary 2) that coherence will also be maintained under much more general conditions: on the one hand,
for some of the examples of application of the CIR rule discussed in Sections 5.1–5.3,
P 1 (Z, Y ) is obtained by making the strong product of a number of conditional lower previsions P 1 (XO1 |XI1 ), . . . , P m (XOm |XIm ). Here we consider a set of variables of interest
{X1 , . . . , Xn } that contains {Z, Y } and does not include W . We assume moreover that
the coherence graph associated to P 1 (XO1 |XI1 ), . . . , P m (XOm |XIm ) is A1+ , from which it
m
follows (see Appendix B) that ∪m
i=1 (Ii ∪ Oi ) = ∪i=1 Oi = {1, . . . , n}. An instance of such a
situation is given in Figure 7.
Corollary 2 in Appendix B shows that coherence also holds in this more general situation.
On the other hand, the corollary also proves that coherence is maintained if we apply
the regular extension to a finite number of conditioning events, thus actually creating an
additional finite number of coherent lower previsions out of the original assessments: all of
these assessments are going to be jointly coherent. This is another important result as in
practice one indeed often conditions on a number of events. These theoretical results give
us guarantees that the CIR rule is ‘well-behaved.’
805

Zaffalon & Miranda

R

B

H

w s

? - s
s
?
?

O

Y

Z

Figure 7: A more general model.

8. Conclusions
In this paper we have introduced a new rule to update beliefs under incompleteness that we
have called conservative inference rule (CIR). CIR has been designed by explicitly taking
into consideration the problem of modelling the process that makes our observations incomplete, and that we have called the incompleteness process (or IP). We have represented
such a process as made of two sub-processes, one that is non-selective and another that
is unknown to us. As a consequence, CIR deals differently with data that are known to
be coarsened at random from the other ones. In the first case CIR treats them using the
CAR/MAR assumption, in the other by taking all the completions of the incomplete data.
CIR can be regarded as a generalisation of both the traditional, Bayesian rule to update
beliefs and of the recently proposed conservative updating rule (De Cooman & Zaffalon,
2004). CIR is a generalisation of these two rules as it enables one to consider mixed situations. This should make of CIR quite a flexible rule in applications. Moreover, this
enables CIR to avoid the risk of being overconfident about the IP, which is a problem for
the traditional updating, as well as to avoid being over-pessimistic as it may happen with
the conservative updating rule.
CIR is also a very general rule. It can be used with coarsened or missing data, in
statistics as well as in expert systems, and it can be applied to predict the state of a
target variable irrespective of the cardinality of its space of possibilities. We have indeed
tried to illustrate these characteristics using a number of application domains. Moreover,
using some examples we have shown that CIR makes quite a difference with the traditional
CAR/MAR-based way of dealing with incomplete data: in these examples the traditional
updating is shown to lead to conclusions that are hardly justifiable from the evidence at
hand, and, even worse, can do it in such a way that a user may not realise this. In these
cases CIR is instead naturally more cautious and clearly communicates to a user that there
are limits to the strength of the possible conclusions, as a logical consequence of the strength
(or weakness) of the available information.
Finally, CIR has some nice theoretical properties, most notably that it is a coherent rule.
Loosely speaking, this means that by using CIR it is not possible to give rise to probabilistic
inconsistencies. As it can be seen from Theorem 3 in Appendix B, the assumptions we
require for coherence of CIR are fairly general: if our initial assessments are of a special
kind, which we have characterised using a graphical structure called a coherence graph of
type A1+ , then we require only that some of the possibility spaces involved in the analysis
are finite and that the conditioning events in these spaces have positive upper probability.
806

Conservative Inference Rule

These hypotheses guarantee that we can use Walley’s notion of regular extension to update
our beliefs and that the assessments thus obtained are coherent with our initial assessments.
We should like to conclude this section commenting also a bit on some of the assumptions
we have considered in the construction of our model and in some open problems that we
can derive from this work.
One point is the requirement that some of the spaces of possibilities be finite. This could
be relaxed by taking into account that a conditional prevision defined by regular extension
can be coherent with the unconditional it is derived from even in the infinite case. However,
we cannot guarantee that the third point of Lemma 2 in Appendix B holds in these more
general situations, and this point is necessary for the proof of Theorem 3. This is related to
the notion of conglomerability discussed in much detail by Walley (1991). An open problem
would be to extend our results to more general situations by addressing the question of
conglomerability. On the other hand, as we said, our results are applicable even if the
target space Z of our variable of interest, Z, is infinite. This has allowed us, for instance, to
model parametric inference in the case where the parameter space is infinite, as discussed in
Section 5.2. Moreover, we are not assuming that the upper probability of the values of Z is
positive, and this allows us to include the case where our prior beliefs about the parameter
are precise and the parameter space is infinite, which coincides with the traditional setup.
Another important point is our assumption on the domains of our lower previsions:
we have required for instance that P 1 (Z, Y ) is defined on the set of all XZ∪Y -measurable
gambles. Similar considerations have been made for P 2 (W̄ |Ȳ ) and P 3 (Ŵ |Ŷ ). When these
requirements are not met, we can still apply our results by extending our assessments
using the notion of natural extension given by Walley (1991). It is easy to see that these
extensions will satisfy the hypotheses of our theorems. These considerations allow us to
cover in particular the case where we have lower probabilities instead of lower previsions.
An interesting feature of the CIR rule derived in Theorem 1 is that it allows us to
make the passage from the updated information about Z knowing the observation W to the
information about Z knowing the value that Y takes. We think that the key for this is that
we are using only vacuous and linear previsions to express the information that Y provides
about W , i.e., that the components of the incompleteness process are either unknown or
random. It is an open problem to determine whether there are other possibilities allowing
us to have an analogous property. Similarly, it would be interesting to study if the other
assumptions in the incompleteness process can be weakened.
To conclude, CIR is a new rule to update beliefs under incompleteness, it is very general,
and is based on solid theoretical foundations. It gives us for the first time the opportunity to
avoid being both too optimistic and too pessimistic about the incompleteness process, thus
creating a basis to draw credible and strong enough conclusions in a number of applications.
This is not to say that we regard CIR as the last word in the subject. On the contrary, it
seems to us that research on IPs has so far only scratched the surface of uncertain reasoning
under incompleteness. In particular, there will be probably a number of applications where
rules stronger than CIR (yet based on more tenable assumption than traditional updating)
are needed. Developing these rules appears to be an important research avenue. Such an
investigation will probably have to be directed primarily at creating new assumptions about
IPs that make the resulting rule stronger while still general enough. A way to do this could
be using as a starting point the the framework developed here. In particular, one could
807

Zaffalon & Miranda

take Assumptions (IP1)–(IP9), (BIP3)–(BIP6) and (DB1) as they are, while strengthening
those related to the unknown IP, that is, (BIP1) and (BIP2). Then the machinery used
to derive CIR could be used again to derive the new rule that follows from the stronger
assumptions. Which new assumptions to impose and whether or not they will lead to a rule
that is useful while not too domain-specific is matter for future investigation.

Acknowledgments
Preliminary work on the topic of this paper appeared in the proceedings of ISIPTA ’05:
the fourth International Symposium on Imprecise Probabilities and Their Applications
(Zaffalon, 2005). We should like to thank the reviewers of this paper for comments that
helped improve its clarity and readability. This work was partially supported by the Swiss
NSF grants n. 200020-116674/1 and 200020-121785/1, and by the projects TIN2008-06796C04-01, MTM2007-61193.

Appendix A. On the CAR Assumption (IP9)
It is important to realise that not all the multi-valued maps ΓŶ are consistent with the
CAR assumption. Here is an example: take Ŷ := {1, 2, 3, 4}, Ŵ := {a, b, c}, and define the
multi-valued map by ΓŶ (1) := {a, b}, ΓŶ (2) := {b, c}, ΓŶ (3) := {a, c}, ΓŶ (4) := {a, b, c}.
By (BIP5), we should have then P3 (a|1) = P3 (a|3) = P3 (a|4) = αa , P3 (b|1) = P3 (b|2) =
P3 (b|4) = αb , and P3 (c|2) = P3 (c|3) = P3 (c|4) = αc . Requiring in addition the nonnegativity of the probabilities and that the conditional mass functions be normalised, leads
to the following system of linear constraints:
αa + αb = 1
αb + αc = 1
αa + αc = 1
αa + αb + αc = 1
αa , αb , αc ≥ 0.
This system has no solution, as adding the first three equations we deduce that αa +αb +αc =
1.5, which is incompatible with the fourth equation. Therefore there is no CAR process
consistent with ΓŶ as defined above.
The example shows that in order to define ΓŶ properly, we need to add (IP9) as a
further assumption to (IP5) and (IP7): that the system of linear constraints originated by
ΓŶ through (BIP5) has a solution, namely, that it is admissible. Checking admissibility is
easy because Ŷ is finite and hence so is the number of constraints in the system; this allows
one to use standard techniques from linear programming to solve the problem.
The example also points to another question, which concerns its relationship with Gill
et al.’s well-known ‘CAR is everything’ theorem (Gill et al., 1997, Section 2). Loosely
speaking, such a theorem states, in a precise probability context, that it is always possible
to define a CAR process; and the example seems to contradict the theorem.
In order to show that there is actually no contradiction, we need to represent the example
in the setup of Gill et al.’s paper, which is focused on random sets. This means that they
808

Conservative Inference Rule

regard Ŵ as a variable that takes values from the powerset of Ŷ, and hence that the CAR
IP is intended as a function that maps elements of Ŷ into subsets of Ŷ itself.
To make the transition, we identify each element of ŵ ∈ Ŵ with the corresponding
set {ŵ}∗ ; in our example, the possible values of Ŵ , interpreted as a random set, are then
{1, 3, 4}, {1, 2, 4}, and {2, 3, 4}. The intuition here is that the element 1 of Ŷ can be
coarsened by the CAR IP into the set {1, 3, 4} or {1, 2, 4}; the element 2 into {1, 2, 4} or
{2, 3, 4}; the element 3 into {1, 3, 4} or {2, 3, 4}; and the element 4 into {1, 3, 4}, {1, 2, 4}
or {2, 3, 4}. For the correspondence to be really consistent, we also need to make sure that
zero probability is assigned to all the elements of the power set of Ŷ that do not correspond
to any of the sets {ŵ}∗ , ŵ ∈ Ŵ; this is necessary because of (BIP4) and because Gill et al.’s
setup does not explicitly use the notion of multi-valued mapping. With this background we
can take a closer look at the relationship between the example and Gill et al.’s theorem.
What the theorem states, in our language, is that no matter how Ŵ is distributed,
one can find an unconditional mass function for Ŷ and a CAR process that lead Ŵ to be
distributed in the same way. But if we select an unconditional mass function for the random
set Ŵ that respects the constraint of assigning zero probabilities as above, we are actually
implementing the multi-valued map of the example, and we know that there is no CAR
process consistent with it.
The key to solve the paradox is that Gill et al. allow the CAR-IP probabilities P3 (Ŷ 0 |ŷ)
to be non-zero for any set Ŷ 0 ⊆ Ŷ that includes ŷ, not only for the sets determined by the
multi-valued map, as we do. This freedom makes it possible to always find a CAR process.
Consider again the example above, and assume that Ŵ is distributed uniformly over the
three sets {1, 3, 4}, {1, 2, 4}, {2, 3, 4}: i.e., each of them is assigned probability equal to 13 .
We can make this choice consistent with a CAR process by choosing α{1,3,4} := α{1,2,4} :=
α{2,3,4} := 13 (i.e., αa := αb := αc := 31 ) if, in addition, we set α{1} := α{2} := α{3} := 13 ,
i.e., if we allow the CAR process to be able to potentially output other three sets. But
since we know that the three other sets cannot be really returned, we are obliged to also
set P (1) := P (2) := P (3) := 0, thus solving the problem, although arguably in a somewhat
artificial way.
Indeed, since we are forced to set to zero the probability of some elements in Ŷ, one
might wonder why those elements have to be included in the set Ŷ. Precisely this observation
has been already used as a source of criticism of Gill et al.’s ‘CAR is everything’ theorem
(Grünwald & Halpern, 2003, Section 4.4), leading the authors of the latter paper to say
that in these cases it is like if there is actually no CAR process. Our formulation based on
the multi-valued map simply confirms this statement in an alternative way.

Appendix B. Coherence of CIR
In this appendix, we are going to prove that the assessments in the construction of the
conservative inference rule satisfy the notion of coherence and moreover that they are also
coherent with any probabilistic assessment that we deduce from them using CIR. In doing
so, we want to cover also the case where the unconditional prevision P 1 (Z, Y ) is constructed
from a number of other conditional and unconditional previsions, which is a very typical
case in practice. We shall use the notations established in Section 2 and Section 6. We
809

Zaffalon & Miranda

consider then variables X1 , . . . , Xn taking values in respective sets X1 , . . . , Xn , and take a
collection of conditional previsions P 1 (XO1 |XI1 ), . . . , P m (XOm |XIm ).
We start with a lemma that shows that A1 graphs naturally entail a notion of order of
the corresponding lower previsions: in particular, that it is possible to permute the indexes
of the lower previsions in such a way that the only admissible paths between two dummy
nodes are those in which the index of the origin precedes that of the destination.25
Lemma 1 If the coherence graph of {P 1 (XO1 |XI1 ), . . . , P m (XOm |XIm )} is A1, then we
may assume without loss of generality that for any k = 1, . . . , m, Ok ∩ (∪k−1
i=1 Ii ) = ∅.
Proof. We start proving that Ok ∩ (∪m
i=1 Ii ) = ∅ for some k. Assume ex-absurdo that this
does not hold. Then for any k ∈ {1, . . . , m} there is some f (k) 6= k such that Ok ∩ If (k) 6= ∅.
Define z0 := 1, zk := f (zk−1 ) ∀k ≥ 1. It must be {zk } ∩ {z0 , . . . , zk−1 } = ∅ for all k ≥ 1, or
we should establish a cycle in the coherence graph, contradicting thus that it is A1. Hence,
|{z0 , z1 , . . . , zk−1 }| = k for all k ≥ 1, and this means that zm does not exist, or, equivalently,
that Ozm−1 ∩ Ii = ∅ ∀i = 1, . . . , m. Hence, there is some k such that Ok ∩ (∪m
i=1 Ii ) = ∅. We
can assume without loss of generality that k = m.
We prove now that there is some k 6= m such that Ok ∩(∪m−1
i=1 Ii ) = ∅. Assume ex-absurdo
that this does not hold. Then for all k ∈ {1, . . . , m − 1} there is some g(k) 6= k, m such that
Ok ∩ Ig(k) 6= ∅. Define z0 := 1, zk := g(zk−1 ) ∀k ≥ 1. It must be {zk } ∩ {z0 , . . . , zk−1 } = ∅
for all k ≥ 1, or we should establish a cycle in the coherence graph, contradicting thus that
it is A1. Hence, |{z0 , z1 , . . . , zk−1 }| = k for all k ≥ 1, and this means that zm−1 does not
exist, or, equivalently, that Ozm−2 ∩ Ii = ∅ ∀i = 1, . . . , m − 1. Hence, there is some k 6= m
such that Ok ∩ (∪m−1
i=1 Ii ) = ∅. We can assume without loss of generality that k = m − 1.
A similar reasoning allows us to deduce the existence of an order ≺ in {1, . . . , m} such
that Ok ∩ (∪j≺k Ij ) = ∅ for all k = 1, . . . , m. Finally we assume without loss of generality
that this order coincides with the natural order. 2
Now we restrict the attention to the particular case of A1+ graphs. From Lemma 1, if
a collection P 1 (XO1 |XI1 ), . . . , P m (XOm |XIm ) is A1+ -representable, we can assume without
loss of generality that I1 = ∅. Let A1 := ∅, Aj := ∪j−1
i=1 (Ii ∪ Oi ) for j = 2, . . . , m + 1, and let
P 0j (XOj |XAj ∪Ij ) be given on the set Hj of XAj+1 -measurable gambles for j = 1, . . . , m by
P 0j (f |z) := P j (f (z, ·)|πIj (z))
for all z ∈ XAj ∪Ij and all f ∈ Hj . Since P j (XOj |XIj ) is separately coherent for j =
1, . . . , m, so is P 0j (XOj |XAj ∪Ij ). Moreover, thanks to Lemma 1 and that {O1 , . . . , Om }
forms a partition of {1, . . . , n} when we focus on A1+ graphs, the sets of indexes of the
conditional variables in P 01 (XO1 ), . . . , P 0m (XOm |XAm ∪Im ) form an increasing sequence and
hence they satisfy the hypotheses of the generalised marginal extension theorem. As a
consequence, P 01 (XO1 ), . . . , P 0m (XOm |XAm ∪Im ) are also coherent.
A similar reasoning shows that if we take for j = 1, . . . , m a conditional linear prevision
0 (X
Pj0 (XOj |XAj ∪Ij ) that dominates P 0j (XOj |XAj ∪Ij ), then P10 (XO1 ), . . . , Pm
Om |XAm ∪Im ) are
jointly coherent. Moreover, since {O1 , . . . , Om } is a partition of {1, . . . , n}, Theorem 3 by
25. This order notion is similar to the graph-theoretic notion of topological ordering, but here it is applied
only to the dummy nodes.

810

Conservative Inference Rule

Miranda and De Cooman (2007) implies that the only prevision P on X n which is coherent
0 (X
with the assessments P10 (XO1 ), . . . , Pm
Om |XAm ∪Im ) is
0
P (f ) = P10 (P20 (. . . (Pm
(f |XAm ∪Im )| . . . )|XA2 ∪I2 )).

(15)

0 (X
In other words, P10 (XO1 ), . . . , Pm
Om |XAm ∪Im ) give rise to a unique joint lower prevision.

Definition 17 Assume that Pλ (XOj |XAj ∪Ij ) dominates P 0j (XOj |XAj ∪Ij ) for all λ ∈ Λ and
all j = 1, . . . , m and
inf Pλ (XOj |XAj ∪Ij ) = P 0j (XOj |XAj ∪Ij ).
λ∈Λ

The coherent lower prevision P defined as P := inf λ∈Λ Pλ , where Pλ is the coherent prevision
determined by Pλ (XO1 ), . . . , Pλ (XOm |XAm ∪Im ) and Equation (15), is called a lower envelope
model.
Intuitively, a lower envelope model is a joint lower prevision that is built out of a number
of conditional and unconditional assessments. The interest in lower envelope models arises
because it is a very common practice to build joint models out of smaller conditional and
unconditional ones, and then to use the joint model to draw some conclusions. Lower
envelope models abstract this procedure in the general case of coherent lower previsions.
As particular cases of lower envelope models, we can consider the following:
1. If for each j = 1, . . . , m we consider all the Pλ (XOj |XAj ∪Ij ) in M(P 0j (XOj |XAj ∪Ij )),
then P is the marginal extension of P 01 (XO1 ), . . . , P 0m (XOm |XAm ∪Im ).
2. If for j = 1, . . . , m we take all the Pλ (XOj |XAj ∪Ij ) in the set of extreme points of
M(P 0j (XOj |XAj ∪Ij )), with the additional requirement that Pλ (XOj |z) = Pλ (XOj |z 0 )
if πIj (z) = πIj (z 0 ), then the lower envelope model P is called the strong product of
P 1 (XO1 ), . . . , P m (XOm |XIm ).
In this paper, we make our inferences using the strong product. From the results by Miranda and De Cooman (2007), if we let Pj (XOj |XIj ) be an extreme point of M(P j (XOj |XIj ))
for j = 1, . . . , m and we build a linear prevision P in the manner described above, then
P, P1 (XO1 |XA1 ∪I1 ), . . . , Pm (XOm |XAm ∪Im ) are coherent. Moreover, we deduce the following:
Theorem 2 Let P 1 (XO1 ), . . . , P m (XOm |XIm ) be an A1+ -representable collection, and let
P be a lower envelope model associated to it. Then P , P 1 (XO1 ), . . . , P m (XOm |XIm ) are
coherent.
Proof. It is a consequence of the marginal extension theorem by Miranda and De Cooman
(2007) that for any λ ∈ Λ the previsions Pλ , Pλ (XO1 |XA1 ∪I1 ), . . . , Pλ (XOm |XAm ∪Im ) are coherent. Applying Theorem 8.1.6 in Walley (1991), we deduce that the lower envelopes of
these families, which are the lower previsions P , P 01 (XO1 |XA1 ∪I1 ), . . . , P 0m (XOm |XAm ∪Im ),
are also coherent. The result now follows applying that any gamble f in Kj belongs to Hj ,
and that P 0j (f |XAj ∪Ij )(x) = P 0j (f (πAj ∪Ij (x), ·)|πAj ∪Ij (x)) = P j (f (πIj (x), ·)|πIj (x)) for all
x ∈ X n. 2
We have the following useful corollary of this theorem:
811

Zaffalon & Miranda

Corollary 1 Let P be the strong product of P 1 (Z, Y ), P 2 (W̄ |Ȳ ), P3 (Ŵ |Ŷ ), constructed in
Section 7.1.3. P is coherent and it is also jointly coherent with the original assessments
P 1 (Z, Y ), P 2 (W̄ |Ȳ ), P3 (Ŵ |Ŷ ). This holds also if P 1 (Z, Y ) is constructed as a joint which is
coherent with a number of smaller pieces of information, provided that the coherence graph
representing them is A1+ .
Proof. That P is a coherent lower prevision follows because it is the lower envelope
of a set of linear previsions. Its coherence with P 1 (Z, Y ), P 2 (W̄ |Ȳ ), P3 (Ŵ |Ŷ ) follows from
Theorem 2, because the coherence graph of P 1 (Z, Y ), P 2 (W̄ |Ȳ ), P3 (Ŵ |Ŷ ) is A1+ , as it
is evident from Figure 6. In the more general situation when P 1 (Z, Y ) is constructed
in a modular way the result follows similarly as the coherence graph representing these
assessments together with P 2 (W̄ |Ȳ ), P3 (Ŵ |Ŷ ) will also be A1+ . 2
We prove next that if we use regular extension to derive new conditional previsions
P m+1 (XOm+1 |XIm+1 ), . . . , P m+k (XOm+k |XIm+k ) from the strong product P , these conditional previsions are coherent with all the initial assessments. For this, we need to establish
first the following:
Lemma 2 Let P , P (XO |XI ) be coherent unconditional and conditional previsions, with XI
finite. Let R(XO |XI ) be defined from P using regular extension for z ∈ XI when P (z) > 0,
and be equal to P (XO |z) when P (z) = 0. Then:
1. P , R(XO |XI ) are coherent.
2. R(XO |XI ) ≥ P (XO |XI ).
3. For any P ≥ P , there is some P (XO |XI ) which is coherent with P and dominates
P (XO |XI ).
Proof. Since XI is a finite set, we can apply Theorem 6.5.4 in the book of Walley
(1991) to deduce that the coherence of P , R(XO |XI ) is equivalent to P (Iz (f − R(f |z))) = 0
for all z ∈ XI .26 If P (z) = 0, this is trivial. If P (z) > 0, it follows from Walley (1991,
Appendix J3).
For the second statement, consider some z in XI with P (z) > 0, and f ∈ KO∪I . Assume
ex-absurdo that R(f |z) < P (f |z). It follows from the definition of the regular extension
that there is some P ≥ P such that P (z) > 0 and P (f |z) < P (f |z). Since P (z) > 0,
it follows from the generalised Bayes rule that P (f |z) is the unique value satisfying 0 =
P (Iz (f −P (f |z))). As a consequence, given P (f |z) > P (f |z), we have that Iz (f −P (f |z)) ≥
Iz (f − P (f |z)), whence
0 = P (Iz (f − P (f |z))) ≥ P (Iz (f − P (f |z))) ≥ P (Iz (f − P (f |z)) = 0,
using that since P , P (XO |XI ) are coherent they satisfy the generalised Bayes rule. But this
implies that P (Iz (f − P (f |z))) = P (Iz (f − P (f |z))) = 0, and then there are two different
values of µ for which P (Iz (f − µ)) = 0. This is a contradiction.
26. This is called the generalised Bayes rule. When P (x) > 0, there is a unique value for which P (G(f |x)) =
P (Ix (f − P (f |x))) = 0 holds.

812

Conservative Inference Rule

We finally establish the third statement. Consider P ≥ P , and z ∈ XI . If P (z) > 0,
then for any f ∈ KO∪I P (f |z) is uniquely determined by the generalised Bayes rule and
dominates the regular extension R(f |z). Hence, P (f |z) ≥ R(f |z) ≥ P (f |z), where the
last inequality follows from the second statement. Finally, if P (z) = 0, taking any element
P (XO |z) of M(P (XO |z)) we have that P (Iz (f − P (f |z))) = 0 for all f ∈ KO∪I . This
completes the proof. 2
Before we establish our next result, we need to introduce a consistency notion for conditional lower previsions that is less restrictive than coherence:
Definition 18 Let P 1 (XO1 |XI1 ), . . . , P m (XOm |XIm ) be separately coherent conditional previsions. They are weakly coherent when for all fj ∈ Kj , j = 1, . . . , m, j0 ∈ {1, . . . , m},
f0 ∈ Kj0 , z0 ∈ XIj0 ,


m
X
sup 
Gj (fj |XIj ) − Gj0 (f0 |z0 ) (x) ≥ 0.

x∈X n

(16)

j=1

The intuition behind this notion is that our subject should not raise the conditional
lower prevision P j0 (f0 |z0 ), which represents his supremum acceptable buying price for f0
contingent on z0 , in any positive , using the desirable gambles G1 (f1 |XI1 ),. . . ,Gm (fm |XIm ).
The difference with the notion of (strong) coherence is that the supremum of sum in Equation (16) is required to be non-negative over the whole space X n , and not necessarily when
at least one of the summands is non-zero. This implies that the condition holds trivially
for gambles f0 , f1 , . . . , fm for which there are elements w ∈ X n which do not belong to any
set in {πI−1
(z0 )} ∪ ∪m
j=1 Sj (fj ).
j0
From Miranda and Zaffalon (2009, Theorem 1), P 1 (XO1 |XI1 ), . . . , P m (XOm |XIm ) are
weakly coherent if and only if there is a joint lower prevision P (X1 , . . . , Xn ) that is pairwise
coherent with each conditional lower prevision P j (XOj |XIj ) in the collection. Similar results
hold in the case where we focus on collections made of linear previsions, with the difference
that the joint whose existence is equivalent to weak coherence is linear, too. However, under
the behavioural interpretation, a number of weakly coherent conditional lower previsions can
still present some forms of inconsistency; see Walley (1991, Example 7.3.5) for an example
and Walley (1991, Chapter 7), Walley, Pelessoni, and Vicig (2004), Miranda (2009) for some
discussion.
Theorem 3 Let P 1 (XO1 |XI1 ), . . . , P m (XOm |XIm ) be separately coherent conditional lower
previsions whose associated coherence graph is A1+ . Let P be their strong product. Consider
disjoint Om+j , Im+j for j = 1, . . . , k. Assume that XIm+j is finite for j = 1, . . . , k and that
P (z) > 0 for all z ∈ XIm+j , and define P m+j (XOm+j |XIm+j ) using regular extension for
j = 1, . . . , k. Then
P , P 1 (XO1 |XI1 ), . . . , P m+k (XOm+k |XIm+k ) are coherent.
Proof. Let M denote the set of linear previsions constructed by combining the extreme
points of M(P j (XOj |XIj )), j = 1, . . . , m, in the manner described by Equation (15). The
strong product P is the lower envelope of M.
813

Zaffalon & Miranda

Since XIm+j is finite for j = 1, . . . , k, it follows from [Appendix J3] in the book of Walley
(1991) that P and P m+j (XOm+j |XIm+j ) are coherent. Applying Theorem 1 by Miranda and
Zaffalon (2009), we deduce that the previsions P , P 1 (XO1 |XI1 ), . . . , P m+k (XOm+k |XIm+k )
are weakly coherent. Hence, Theorem 7.1.5 by Walley (1991) implies that it suffices to
show that P 1 (XO1 |XI1 ), . . . , P m+k (XOm+k |XIm+k ) are coherent. Consider fi ∈ Ki for i =
1, . . . , m + k, j0 ∈ {1, . . . , m + k}, z0 ∈ XIj0 , f0 ∈ Kj0 , and let us prove that
sup

"m+k
X

ω∈B

#
[fi − P i (XOi |XIi )] − Iz0 (f0 − P j0 (f0 |z0 )) (ω) ≥ 0

(17)

i=1

for some B ∈ {πI−1
(z0 )} ∪ ∪m+k
i=1 Si (fi ).
j0
Assume first that j0 ∈ {m + 1, . . . , m + k}. If Equation (17) does not hold, there is some
δ > 0 such that
#
"m+k
X
sup
[fi − P i (XOi |XIi )] − Iz0 (f0 − P j0 (f0 |z0 )) (ω) = −δ < 0.
ω∈πI−1 (z0 )

i=1

j0

Since P (z0 ) > 0 by assumption, it follows from the definition of the regular extension that
there is some P in M such that P (z0 ) > 0 and Pj0 (f0 |z0 ) − P j0 (f0 |z0 ) < 2δ . From the
definition of the elements of M, there are Pi (XOi |XIi ) in M(P i (XOi |XIi )), i = 1, . . . , m,
such that P is coherent with Pi (XOi |XIi ) for i = 1, . . . , m. On the other hand, applying
Lemma 2, for any j = 1, . . . , k, there is a conditional prevision Pm+j (XOm+j |XIm+j ) that
dominates P m+j (XOm+j |XIm+j ) and is coherent with P . Note that Pj0 (XOj0 |z0 ) is uniquely
determined from P by Bayes’s rule because P (z0 ) > 0.
Using these conditional previsions, we deduce that for any ω ∈ X n ,
"m+k
#
X
[fi − Pi (XOi |XIi )] − Iz0 (f0 − Pj0 (f0 |z0 )) (ω)
i=1
"m+k
X

≤

i=1

whence

"m+k
X

#

δ
[fi − P i (XOi |XIi )] − Iz0 (f0 − P j0 (f0 |z0 )) (ω) + ,
2
#

[fi − Pi (XOi |XIi )] − Iz0 (f0 − Pj0 (f0 |z0 )) (ω) ≤ −

i=1

δ
2

πI−1
(z0 ).
j0

P
for any ω ∈
Let us denote g := m+k
i=1 [fi − Pi (XOi |XIi )] − Iz0 (f0 − Pj0 (f0 |z0 )). The
coherence of P, Pj (XOj |XIj ) for j = 1, . . . , m + k implies that P (g) = 0. But then we also
have P (g) ≤ P (gIz0 ) ≤ − 2δ P (z0 ) < 0, where the first inequality holds because g ≤ 0 since
we are assuming that Equation (17) does not hold. This is a contradiction.
Assume next that j0 ∈ {1, . . . , m}, and let us prove the existence of a linear prevision
Q ∈ M and conditional previsions Pj (XOj |XIj ) in M(P j (XOj |XIj )) coherent with Q for
j = 1, . . . , m + k such that Pj0 (f0 |z0 ) = P j0 (f0 |z0 ) and Q(B) > 0 for some B ∈ {πI−1
(z0 )} ∪
j
0

∪m+k
i=1 Si (fi ).
814

Conservative Inference Rule

• Assume first that P (z0 ) > 0. Then there is some P in M such that P (z0 ) > 0.
This prevision is determined by (and therefore coherent with) conditional previsions
P1 (XO1 |XI1 ), . . . , Pm (XOm |XIm ), where Pi (XOi |XIi ) belongs to M(P i (XOi |XIi )) for
i = 1, . . . , m.
Let Pj00 (XOj0 |XIj0 ) be an extreme point of M(P j0 (XOj0 |XIj0 )) such that Pj00 (f0 |z0 ) =
P (f0 |z0 ), and let Q be the element of M determined by the conditional previsions
P1 (XO1 |XI1 ), . . . , Pj00 (XOj0 |XIj0 ), . . . , Pm (XOm |XIm ). Since the coherence graph of
P 1 (XO1 |XI1 ), . . . , P m (XOm |XIm ) is A1, Lemma 1 implies that we can assume without loss of generality that for all k = 1, . . . , m, Ok ∩ (∪k−1
i=1 Ii ) = ∅. Since moreover {O1 , . . . , Om } forms a partition of {1, . . . , n}, we deduce that Ii ⊆ ∪i−1
j=1 Oj for
0 −1
Oj , whence the value of Q on XIj0 -measurable
i = 1, . . . , n. In particular, Ij0 ⊆ ∪jj=1
gambles is uniquely determined by P1 (XO1 |XI1 ), . . . , Pj0 −1 (XOj0 −1 |XIj0 −1 ). As a consequence, Q(z0 ) = P (z0 ) > 0.

Consider now conditional previsions Pm+j (XOm+j |XIm+j ) which are pairwise coherent
with Q and dominate P m+j (XOm+j |XIm+j ) for j = 1, . . . , k. There are such previsions
because of Lemma 2. The previsions
Q, P1 (XO1 |XI1 ), . . . , Pj00 (XOj0 |XIj0 ), . . . , Pm (XOm |XIm ),
Pm+1 (XOm+1 |XIm+1 ), . . . , Pm+k (XOm+k |XIm+k )
satisfy the conditions stated above, with B = πI−1
(z0 ).
j
0

• If P (z0 ) = 0, there are two possibilities: either fm+1 = · · · = fm+k = 0, and then
Equation (17) holds because P 1 (XO1 |XI1 ), . . . , P m (XOm |XIm ) are coherent; or there
is some j1 ∈ {1, . . . , k} such that fm+j1 6= 0. In that case, we consider a set B ∈
Sm+j1 (fm+j1 ). This set is of the form B = πI−1
(z1 ) for some z1 ∈ XIm+j1 . Because
m+j
1

P (z1 ) > 0 by assumption, there is some Q ∈ M such that Q(z1 ) > 0. From the
definition of M, there are Pi (XOi |XIi ) in M(P i (XOi |XIi )), i = 1, . . . , m, such that
Q is coherent with Pi (XOi |XIi ) for i = 1, . . . , m. Consider a prevision Pj00 (XOj0 |z0 )
in M(P j0 (XOj0 |z0 )) such that Pj00 (f0 |z0 ) = P j0 (f0 |z0 ), and define the conditional
prevision Pj00 (XOj0 |XIj0 ) by
Pj00 (f |z)

(
Pj00 (f |z0 ) if z = z0
=
Pj0 (f |z0 ) otherwise.
0

Since Q(z0 ) = P (z0 ) = 0, given any f ∈ Kj0 Q(Pj0 (f |XIj0 )) = Q(Pj0 (f |XIj0 )) =
Q(f ), where the last equality follows from the coherence of Q and Pj0 (XOj0 |XIj0 ).
Hence, Q and Pj00 (XOj0 |XIj0 ) are coherent. On the other hand, applying Lemma 2,
for all j = 1, . . . , k, there is Pm+j (XOm+j |XIm+j ) ≥ P m+j (XOm+j |XIm+j ) that is
coherent with Q. From all this we deduce that
Q, P1 (XO1 |XI1 ), . . . , Pj00 (XOj0 |XIj0 ), . . . , Pm+k (XOm+k |XIm+k )
satisfy the above stated conditions, with B = πI−1
(z1 ).
m+j
1

815

Zaffalon & Miranda

If we now take these previsions, we deduce that for all ω ∈ X n ,
#
"m+k
X
[fi − Pi (XOi |XIi )] − Iz0 (f0 − Pj0 (f0 |z0 )) (ω)
i=1
"m+k
X

≤

#
[fi − P i (XOi |XIi )] − Iz0 (f0 − P j0 (f0 |z0 )) (ω).

i=1

Pm+k
Let us denote g :=
i=1 [fi − Pi (XOi |XIi )] − Iz0 (f0 − Pj0 (f0 |z0 )). The coherence of Q
and Pj (XOj |XIj ) for j = 1, . . . , m + k implies that Q(g) = 0. Consider the set B ∈
{πI−1
(z0 )} ∪ ∪m+k
i=1 Si (fi ) for which Q(B) > 0. If Equation (17) does not hold, then there
j0
must be some δ > 0 s.t. supω∈B g(ω) = −δ < 0. Since it also follows that g(ω) ≤ 0, we
deduce that Q(g) ≤ Q(gIB ) ≤ −δQ(B) < 0. This is a contradiction.
We conclude from this that Equation (17) holds and as a consequence the previsions
P , P 1 (XO1 |XI1 ),. . . ,P m+k (XOm+k |XIm+k ) are coherent. 2
Next we use the results above to apply the CIR rule in more general frameworks. This is
necessary for some of the examples of application of the CIR rule discussed in Sections 5.1–
5.3.
Corollary 2 Let {X1 , . . . , Xn } be a set of variables that contains {Z, Y } and does not
include W . Assume that the coherence graph associated to P 1 (XO1 |XI1 ),. . . , P m (XOm |XIm )
is A1+ . Let P be the strong product of
P 1 (XO1 |XI1 ), . . . , P m (XOm |XIm ), P (Ŵ |Ŷ ), P (W̄ |Ȳ ).
Assume that XIm+j is finite for j = 1, . . . , k and that P (z) > 0 for all z ∈ XIm+j , and define
P m+j (XOm+j |XIm+j ) using regular extension for j = 1, . . . , k. Then:
(i) P , P 1 (XO1 |XI1 ), . . . , P m (XOm+k |XIm+k ), P (Ŵ |Ŷ ), P (W̄ |Ȳ ) are coherent.
(ii) If P (Z|W ) is one of the previsions we derive from the strong product P using regular
extension, then P (Z|W ) satisfies Equation (CIR).
Proof. First of all, P 1 (XO1 |XI1 ), . . . , P m (XOm |XIm ), P (Ŵ |Ŷ ), P (W̄ |Ȳ ) satisfy the hypotheses of Theorem 2: their associated coherence graph is A1+ and {W, XO1 , . . . , XOm }
is our set of variables of interest. Hence, their strong product P is coherent with all
these assessments. If moreover we use regular extension to build the updated models
P m+j (XOm+j |XIm+j ) using regular extension for j = 1, . . . , k, it follows from Theorem 3
that the conditional lower previsions P m+1 (XOm+j |XIm+1 ), . . . , P m+k (XOm+k |XIm+k ) are
coherent with P , P 1 (XO1 |XI1 ), . . . , P m (XOm |XIm ), P (Ŵ |Ŷ ), P (W̄ |Ȳ ).
Secondly, the strong product P coincides with the one we obtain using the unconditional lower prevision P (XO1 , . . . , XOm ) which we obtain by making the strong product of P 1 (XO1 |XI1 ), . . . , P m (XOm |XIm ) on the one hand and the conditional assessments
P (Ŵ |Ŷ ), P (W̄ |Ȳ ) on the other hand: from the results by Miranda and De Cooman (2007),
the extreme points of the set M(P (XO1 , . . . , XOm )) are obtained by applying marginal
extension on the extreme points of M(P 1 (XO1 |XI1 )),. . . ,M(P m (XOm |XIm )). Hence, the
updated prevision P (Z|W ) we obtain by regular extension also satisfies Equation (CIR) in
this case. 2
816

Conservative Inference Rule

Corollary 3 Updating a credal network a finite number of times by CIR leads to coherent
inference.
Proof. It is enough to observe that the probabilistic assessments used to build credal
networks lead to an A1+ coherence graph, as detailed in Theorem 8 by Miranda and Zaffalon
(2009), and that such a graph, supplemented with the parts for P (W̄ |Ȳ ) and P (Ŵ |Ŷ ),
remains an A1+ graph. The result follows then by Corollary 2. 2
Corollary 4 Doing parametric inference a finite number of times by CIR according to
Rules (4) and (5) leads to coherent inference.
Proof. The coherence of Rule (4) is ensured by Corollary 2 since the coherence graph
of the overall assessments used is A1+ , as shown in Figure 8. The same holds for Rule (5)
s
?

Θs
/

R

Ȳ

Ŷ

W̄

Ŵ

s
?

s
?

Figure 8: The coherence graph for parametric statistical inference.
once we observe that also in this case the related coherence graph is A1+ , as illustrated in
Figure 9. 2
s
?

Θ
s
/

Ȳ1

s
?

W̄1

js

R

Ŷ1

...

Ŵ1

...

s
?

/

ȲN

R

W̄N

ŴN

s
?

ŶN

s
?

Figure 9: The coherence graph for parametric statistical inference in the IID+ID case.
Corollary 5 Computing a finite number of posterior predictive lower previsions by CIR for
classification according to Rule (7) leads to coherent inference.
Proof. The coherence of Rule (7) is ensured by Corollary 2 since the coherence graph of
the overall assessments used is A1+ , as shown in Figure 10. 2
817

Zaffalon & Miranda

s
?

Θ
s9
/

Ȳ1

s
?

W̄1

zs

?
s

R

Ŷ1

...

Ŵ1

...

s
?

/

/

R

ȲN

R

ŶN

ȲN +1

W̄N

ŴN

W̄N +1 ŴN +1

s
?

s
?

s
?

ŶN +1

q

Z

s
?

Figure 10: The coherence graph for pattern classification in the IID+ID case.
Lemma 3 Consider bj ≥ 0, cj > 0 for j = 1, . . . , n. Then there is some j1 such that
!
Pn
bj
j=1 bj
Pn
≥ 1.
(18)
cj1
j=1 cj
PProof. Assume ex-absurdo that
cjP n
k=1 bk
< bj , and by making the
n
k=1 ck

that

Equation (18) does not hold. Then for any j = 1, . . . , m,
sum over all j on both sides of the inequality we obtain

P
n
n
n
X
X
X
cj nk=1 bk
Pn
=
bk <
bj ,
k=1 ck
j=1

k=1

j=1

a contradiction. 2

References
Antonucci, A., & Zaffalon, M. (2006). Equivalence between Bayesian and credal nets on
an updating problem. In Lawry, J., Miranda, E., Bugarin, A., Li, S., Gil, M. A.,
Grzegorzewski, P., & Hryniewicz, O. (Eds.), Proceedings of the third international
conference on Soft Methods in Probability and Statistics, pp. 223–230, Netherlands.
Springer.
Antonucci, A., & Zaffalon, M. (2007). Fast algorithms for robust classification with Bayesian
nets. International Journal of Approximate Reasoning, 44 (3), 200–223.
Antonucci, A., & Zaffalon, M. (2008). Decision-theoretic specification of credal networks: a
unified language for uncertain modeling with sets of Bayesian networks. International
Journal of Approximate Reasoning, 49 (2), 345–361.
Antonucci, A., Zaffalon, M., Sun, Y., & de Campos, C. P. (2008). Generalized loopy 2U: a
new algorithm for approximate inference in credal networks. In Jaeger, M., & Nielsen,
T. D. (Eds.), Proceedings of the fourth European Workshop on Probabilistic Graphical
Models, pp. 17–24.
Bernard, J.-M. (1996). Bayesian interpretation of frequentist procedures for a Bernoulli
process. The American Statistician, 50 (1), 7–13.
818

Conservative Inference Rule

Bhaskara Rao, K. P. S., & Bhaskara Rao, M. (1983). Theory of Charges. Academic Press,
London.
Campos, L., & Moral, S. (1995). Independence concepts for convex sets of probabilities. In
Besnard, P., & Hanks, S. (Eds.), UAI-95, pp. 108–115, San Mateo. Morgan Kaufmann.
Corani, G., & Zaffalon, M. (2008). Learning reliable classifiers from small or incomplete
data sets: the naive credal classifier 2. Journal of Machine Learning Research, 9,
581–621.
Couso, I., Moral, S., & Walley, P. (2000). A survey of concepts of independence for imprecise
probability. Risk, Decision and Policy, 5, 165–181.
Cozman, F. G. (2000). Credal networks. Artificial Intelligence, 120 (2), 199–233.
Cozman, F. G. (2005). Graphical models for imprecise probabilities. International Journal
of Approximate Reasoning, 39 (2–3), 167–184.
De Campos, C. P., & Cozman, F. G. (2005). The inferential complexity of bayesian and
credal networks. In IJCAI-05, pp. 1313–1318. IJCAI.
De Campos, L. M., Lamata, M. T., & Moral, S. (1990). The concept of conditional fuzzy
measures. International Journal of Intelligent Systems, 5, 237–246.
De Cooman, G., & Zaffalon, M. (2004). Updating beliefs with incomplete observations.
Artificial Intelligence, 159 (1–2), 75–125.
Dempster, A. P., Laird, N. M., & Rubin, D. B. (1977). Maximum likelihood from incomplete
data via the EM algorithm. Journal of the Royal Statistical Society, 39 (1), 1–38.
Duda, R. O., & Hart, P. E. (1973). Pattern Classification and Scene Analysis. Wiley, New
York.
Fagin, R., & Halpern, J. Y. (1991). A new approach to updating beliefs. In Bonissone,
P. P., Henrion, M., Kanal, L. N., & Lemmer, J. F. (Eds.), Uncertainty in Artificial
Intelligence, Vol. 6, pp. 347–374. North-Holland, Amsterdam.
Gill, R., Van der Laan, M., & Robins, J. (1997). Coarsening at random: characterisations,
conjectures and counter-examples. In Lin, D.-Y. (Ed.), Proceedings of the first Seattle
Conference on Biostatistics, pp. 255–294. Springer.
Grünwald, P., & Halpern, J. (2003). Updating probabilities. Journal of Artificial Intelligence
Research, 19, 243–278.
Jaeger, M. (2008). Ignorability in statistical and probabilistic inference. Journal of Artificial
Intelligence Research, 24, 889–917.
Jaffray, J.-Y. (1992). Bayesian updating and belief functions. IEEE Transactions on Systems, Man and Cybernetics, 22, 1144–1152.
Levi, I. (1980). The Enterprise of Knowledge. MIT Press, London.
Little, R. J. A., & Rubin, D. B. (1987). Statistical Analysis with Missing Data. Wiley, New
York.
Manski, C. F. (2003). Partial Identification of Probability Distributions. Springer-Verlag,
New York.
819

Zaffalon & Miranda

Miranda, E. (2008). A survey of the theory of coherent lower previsions. International
Journal of Approximate Reasoning, 48 (2), 628–658.
Miranda, E. (2009). Updating coherent previsions on finite spaces. Fuzzy Sets and Systems,
160 (9), 1286–1307.
Miranda, E., & De Cooman, G. (2005). Coherence and independence in non-linear spaces.
Tech. rep., Universidad Rey Juan Carlos, Spain. Downloadable at the address
http://bellman.ciencias.uniovi.es/∼emiranda/.
Miranda, E., & De Cooman, G. (2007). Marginal extension in the theory of coherent lower
previsions. International Journal of Approximate Reasoning, 46 (1), 188–225.
Miranda, E., & Zaffalon, M. (2009). Coherence graphs. Artificial Intelligence, 137 (1),
104–144.
Pearl, J. (1988). Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. Morgan Kaufmann, San Mateo.
Peot, M. A., & Shachter, R. D. (1998). Learning from what you don’t observe. In Cooper,
G. F., & Moral, S. (Eds.), Uncertainty in Artificial Intelligence (Proceedings of the
Fourteenth Conference), pp. 439–446. Morgan Kaufmann Publishers, San Francisco,
CA.
Perks, W. (1947). Some observations on inverse probability including a new indifference
rule. J. Inst. Actuar., 73, 285–312.
Rabiner, L. (1989). A tutorial on hidden markov models and selected applications in speech
recognition. Proceedings of the IEEE, 77 (2), 257–286.
Ramoni, M., & Sebastiani, P. (2001). Robust learning with missing data. Machine Learning,
45 (2), 147–170.
Shafer, G. (1985). Conditional probability. International Statistical Review, 53, 261–277.
Strassen, V. (1964). Meßfehler und Information. Zeitschrift für Wahrscheinlichkeitstheorie
und Verwandte Gebiete, 2, 273–305.
Troffaes, M. C. M. (2007). Decision making under uncertainty using imprecise probabilities:
an introductory overview. International Journal of Approximate Reasoning, 45 (1),
17–29.
Walley, P. (1981). Coherent lower (and upper) probabilities. Tech. rep. Statistics Research
Report 22, University of Warwick, Coventry.
Walley, P. (1991). Statistical Reasoning with Imprecise Probabilities. Chapman and Hall,
New York.
Walley, P. (1996a). Inferences from multinomial data: learning about a bag of marbles. J.
R. Statist. Soc. B, 58 (1), 3–57.
Walley, P. (1996b). Measures of uncertainty in expert systems. Artificial Intelligence, 83 (1),
1–58.
Walley, P., Pelessoni, R., & Vicig, P. (2004). Direct algorithms for checking consistecy
and making inferences for conditional probability assessments. Journal of Statistical
Planning and Inference, 126 (1), 119–151.
820

Conservative Inference Rule

Zaffalon, M. (2001). Statistical inference of the naive credal classifier. In De Cooman, G.,
Fine, T. L., & Seidenfeld, T. (Eds.), ISIPTA ’01: Proceedings of the Second International Symposium on Imprecise Probabilities and Their Applications, pp. 384–393,
The Netherlands. Shaker.
Zaffalon, M. (2002). Exact credal treatment of missing data. Journal of Statistical Planning
and Inference, 105 (1), 105–122.
Zaffalon, M. (2005). Conservative rules for predictive inference with incomplete data. In
Cozman, F. G., Nau, R., & Seidenfeld, T. (Eds.), ISIPTA ’05: Proceedings of the
Fourth International Symposium on Imprecise Probabilities and Their Applications,
pp. 406–415, Manno, Switzerland. SIPTA.

821

Journal of Artificial Intelligence Research 34 (2009) 675-706

Submitted 11/08; published 04/09

Planning over Chain Causal Graphs for Variables with
Domains of Size 5 Is NP-Hard
Omer Giménez

omer.gimenez@upc.edu

Dept. de Llenguatges i Sistemes Informàtics
Universitat Politècnica de Catalunya
Jordi Girona, 1-3
08034 Barcelona, Spain

Anders Jonsson

anders.jonsson@upf.edu

Dept. of Information and Communication Technologies
Universitat Pompeu Fabra
Roc Boronat, 138
08018 Barcelona, Spain

Abstract
Recently, considerable focus has been given to the problem of determining the boundary
between tractable and intractable planning problems. In this paper, we study the complexity of planning in the class Cn of planning problems, characterized by unary operators and
directed path causal graphs. Although this is one of the simplest forms of causal graphs a
planning problem can have, we show that planning is intractable for Cn (unless P = NP),
even if the domains of state variables have bounded size. In particular, we show that plan
existence for Ckn is NP-hard for k ≥ 5 by reduction from Cnf-Sat. Here, k denotes the
upper bound on the size of the state variable domains. Our result reduces the complexity
gap for the class Ckn to cases k = 3 and k = 4 only, since C2n is known to be tractable.

1. Introduction
There is an ongoing effort in the planning community to determine the complexity of different classes of planning problems. Known tractable classes are usually characterized by
a simple causal graph structure accompanied by additional restrictions on variables and
operators. However, the boundary between tractable and intractable planning problems is
still not clearly established. The present paper contributes a novel complexity result for
a class of planning problems with simple causal graph structure from the literature, in an
effort to reduce this complexity gap.
The problem of determining tractable classes of planning problems is not purely of theoretical interest. For instance, complex planning problems can be projected onto tractable
fragments of planning problems to generate heuristics to be used during search (Katz &
Domshlak, 2008b). Also, the causal graph heuristic (Helmert, 2006) exploits the hierarchical structure of a planning problem by transforming it into a more tractable form: first, it
translates propositional variables into multi-valued variables, a process that simplifies the
causal graph of the problem; then, it keeps relaxing the problem until the causal graph
becomes acyclic.
The present paper aims to study the complexity of planning problems in the class Cn ,
defined by Domshlak and Dinitz (2001). The class Cn contains planning problems with
c
2009
AI Access Foundation. All rights reserved.

Giménez & Jonsson

Ckn
k=2
k ∈ {3, 4}
k≥5

Plan generation
P
EXP
EXP

Macro plan generation
P
?
Intractable

Plan existence
P
?
NP-hard

Table 1: Overview of the complexity results for the class Ckn .

multi-valued variables and chain causal graphs, i.e., the causal graph is just a directed path
(implying that operators are unary). The notation n indicates that the number of state
variables is unbounded. In particular, we study the complexity of plan existence for Cn ,
i.e., determining whether or not there exists a plan that solves a planning problem in Cn .
Even though planning problems in Cn exhibit an extremely basic form of causal structure, i.e., linear dependence between state variables, solving planning problems in Cn is not
necessarily tractable, even if we impose additional restrictions. Let Ckn be the subclass of
Cn for which state variables have domains of size at most k. It is known that class C2n is
polynomial-time solvable (Brafman & Domshlak, 2003) and that plan existence for class
Cn is NP-hard (Giménez & Jonsson, 2008a). Our aim is to study the complexity of plan
existence for those classes in between, namely Ckn for k ≥ 3.
Domshlak and Dinitz (2001) showed that there are solvable instances of C3n that require
exponentially long plans. This means that there is no polynomial-time plan generation
algorithm for Ckn with k ≥ 3, as was the case for C2n . However, this does not rule out the
existence of a polynomial-time algorithm that determines plan existence for class Ckn , or
even an algorithm that generates plans in some succinct form, like those of Jonsson (2007)
and Giménez and Jonsson (2008a). This is not incompatible with Cn being NP-hard.
In this paper, we prove that plan existence for the class Ckn is NP-hard for k ≥ 5.
In other words, even if the causal graph is a directed path and the domains of the state
variables are restricted to contain no more than 5 values, deciding whether or not a plan
exists for solving the corresponding planning problem is NP-hard. Our result implies that it
is not sufficient for a planning problem to exhibit linear variable dependence and restricted
variable domain sizes; additional restrictions are necessary to make planning tractable.
Table 1 shows an overview of the complexity results for the class Ckn to date. By
“Macro plan generation” we mean any algorithm for generating a compact representation
of the solution, such as in the work of Jonsson (2007) and Giménez and Jonsson (2008a).
The “Intractable” result for this column means that the complexity is yet unknown but
cannot be in P unless P = NP (else plan existence would be in P). The row for k = 2 is due
to Brafman and Domshlak (2003), the column for plan generation is due to Domshlak and
Dinitz (2001), and the contributions of the present paper are marked in boldface. Note that
the novel result subsumes that of Giménez and Jonsson (2008a), who showed NP-hardness
for k = O(n).
This paper is organized as follows. In Section 2 we relate our results to previous work,
and in Section 3 we introduce the notation used throughout. In Section 4 we give formal
proof of a reduction from Cnf-Sat to planning problems in C11
n . The main result, a
5
reduction from Cnf-Sat to planning problems in Cn , is then proved in Section 5. Although
11
the result for C5n subsumes that for C11
n , we believe that the intuitive idea behind the Cn
676

Chain Causal Graphs with Domains of Size 5

reduction is easier to understand, and may be of interest for anyone trying to prove hardness
results under similar circumstances. In Section 6 we discuss the complexity of the remaining
classes C3n and C4n .
We also prove the correctness of a third reduction, this time from Cnf-Sat to C7n , in
7
Appendix A. The reductions for C11
n and Cn previously appeared in a conference paper
(Giménez & Jonsson, 2008b), and the present paper provides formal proof of their correctness.

2. Related Work
The complexity of planning has been studied extensively over the last twenty years (Bylander, 1994; Chapman, 1987; Erol, Nau, & Subrahmanian, 1995). Many tractable classes of
planning problems exploit the notion of a causal graph in one way or another. Knoblock
(1994) is usually credited with introducing the causal graph in his work on hierarchical
planning. Williams and Nayak (1997) required planning problems to have acyclic causal
graphs in an effort to ensure tractability. Jonsson and Bäckström (1998) defined the class
3S of planning problems, also with acyclic causal graphs, and showed that plan existence
is tractable for this class.
Domshlak and Dinitz (2001) introduced the class Cn of planning problems studied in
this paper, as well as several related classes, all of which have a particular causal graph
structure. Brafman and Domshlak (2003) designed a polynomial-time algorithm for solving planning problems with binary state variables and polytree causal graphs of bounded
indegree, proving that planning is tractable for the class C2n . Brafman and Domshlak
(2006) presented complexity results related to the tree-width of the causal graph. Katz
and Domshlak (2008a) used causal graph structure to prove several complexity results for
optimal planning.
Jonsson (2007) and Giménez and Jonsson (2008a) designed polynomial-time algorithms
that solve planning problems with restricted causal graphs by generating a hierarchy of
macros. Recently, Chen and Giménez (2008) showed that the complexity of planning is
intractable unless the size of the largest connected component of the causal graph is bounded
by a constant. Consequently, causal graph structure alone is not enough to guarantee
tractability, implying that additional restrictions are needed.

3. Notation
Throughout the paper, we use [i..n] to denote the set {i, . . . , n}.
Let V be a set of state variables, and let D(v) be the finite domain of state variable
v ∈ V . We define a state s as a function on V that maps each state variable v ∈ V to
a value s(v) ∈ D(v) in its domain. A partial state p is a function on a subset Vp ⊆ V of
state variables that maps each state variable v ∈ Vp to p(v) ∈ D(v). We frequently use the
notation (v1 = x1 , . . . , vk = xk ) to denote a partial state p defined by Vp = {v1 , . . . , vk } and
p(vi ) = xi for each vi ∈ Vp .
A planning problem is a tuple P = hV, init, goal, Ai, where V is the set of variables, init
is an initial state, goal is a partial goal state, and A is a set of operators. An operator
a = hpre(a); post(a)i ∈ A consists of a partial state pre(a) called the pre-condition and a
677

Giménez & Jonsson

v1

v2

v3

v4

v5

Figure 1: Example causal graph of a planning problem in the class Ck5 .
partial state post(a) called the post-condition. Operator a is applicable in any state s such
that s(v) = pre(a)(v) for each v ∈ Vpre(a) , and applying operator a in state s results in a
new state s′ such that s′ (v) = post(a)(v) if v ∈ Vpost(a) and s′ (v) = s(v) otherwise.
A partial plan Π for planning problem P is a sequence of operators a1 , . . . , ak ∈ Ak ,
k ≥ 0, such that a1 is applicable in the initial state init and, for each i ∈ [2..k], ai is
applicable following the application of a1 , . . . , ai−1 starting in init. Note that a partial plan
does not necessarily solve P . A plan Π for solving P is a partial plan such that the goal
state goal is satisfied following the application of a1 , . . . , ak . P is solvable if and only if
there exists such a plan Π.
The causal graph of a planning problem P is a directed graph (V, E) with the state
variables as nodes. There is an edge (u, v) ∈ E if and only if u 6= v and there exists an
operator a ∈ A such that u ∈ Vpre(a) ∪ Vpost(a) and v ∈ Vpost(a) . Figure 1 shows an example
causal graph in the form of a directed path. The structure of the causal graph implies that
each operator a ∈ A is unary, i.e., the post-condition of a is specified on a single variable
v, and the pre-condition of a is specified on (at most) v and its predecessor v ′ in the causal
graph.
In this paper we study the class Ckn of planning problems, defined as follows:
Definition 3.1. A planning problem P belongs to the class Ckn if and only if the causal
graph of P is a directed path and, for each v ∈ V , |D(v)| ≤ k.
For planning problems in Ckn , the domain transition graph, or DTG, of a state variable
v is a labelled, directed graph (D(v), E ′ ) with the values in the domain of v as nodes.
There is an edge (x, y) ∈ E ′ with label l ∈ D(v ′ ) if and only if there exists an operator
hv ′ = l, v = x; v = yi in A, where v ′ is the predecessor of v in the causal graph. An edge
without label indicates that the pre-condition of the corresponding operator is defined on v
alone. An edge with more than one label indicates the existence of multiple operators with
the same pre- and post-condition on v but different pre-conditions on v ′ .

4. C11
n Is NP-hard
In this section we prove that C11
n is NP-hard by reduction from Cnf-Sat. In other words,
to every CNF formula F we associate a planning instance P11 (F ) of C11
n such that P11 (F )
is solvable if and only if F is satisfiable. We first describe the planning problem P11 (F ),
then explain the intuitive idea behind the reduction, and finally provide formal proof of its
correctness.
Let F = C1 ∧ · · · ∧ Ck be a CNF formula on k clauses and n variables x1 , . . . , xn . We
define the planning problem P11 (F ) = (V, init, goal, A) as follows. The variable set V is
{si | i ∈ [1..2n − 1]} ∪ {vs } ∪ {vij | i ∈ [1..k], j ∈ [1..n]} ∪ {ve } ∪ {ei | i ∈ [1..2n − 1]},
with domains D(si ) = D(ei ) = D(ve ) = {0, 1} for i ∈ [1..2n − 1], D(vs ) = {0, 1, x}, and
D(vij ) = {gx , g0 , g1 , ax , a0 , a1 , b0 , b1 , cx , c0 , c1 } for i ∈ [1..k], j ∈ [1..n]. The initial state is
defined by init(si ) = init(ei ) = init(ve ) = 0, i ∈ [1..2n − 1], init(vs ) = x, and init(vij ) = ax
678

Chain Causal Graphs with Domains of Size 5

s1

s2n−1

vs

v1n

v11

vk1

vkn

ve

e1

e2n−1

Figure 2: Causal graph of the planning problem P11 (F ).
0
1
1

0

0
0

1

0
1

1

x
1
0

0 0

1
1

Figure 3: DTGs of the variables s1 , s2 , . . . , s2n−1 , vs .
for i ∈ [1..k], j ∈ [1..n], and the goal state is a partial state defined by goal(vin ) = gx for
each i ∈ [1..k], goal(ve ) = 0, and goal(ei ) = (i mod 2) for each i ∈ [1..2n − 1].
Before providing a formal definition of the operators in A, we give an intuitive overview
of the planning problem P11 (F ). To do this, we present the causal graph of P11 (F ) as well
as the DTGs of each state variable. A reader who is only interested in the formal proof
of the correctness of the reduction may skip to Section 4.2, where we introduce the formal
definitions of operators in order to prove several theoretical properties of P11 (F ).
4.1 Intuition
The planning problem P11 (F ) associated to each CNF formula F consists of three parts, each
with a clearly defined role. The three parts are illustrated in Figure 2, showing the causal
graph of P11 (F ). The first part of P11 (F ) corresponds to state variables s1 , . . . , s2n−1 , vs ,
the second part corresponds to state variables v11 , . . . , v1n , . . . , vk1 , . . . , vkn , and the third
part corresponds to state variables ve , e1 , . . . , e2n−1 . The role of the first part is to generate
a message corresponding to an assignment to the variables of the CNF formula F . The
role of the second part is to verify whether this assignment satisfies each clause Ci , and to
remember this fact (using a value of state variable vin ). Finally, the role of the third part
is to make sure that the message is propagated all the way to the end of the chain.
The DTGs of state variables s1 , . . . , s2n−1 , vs appear in Figure 3. These state variables
are used to generate an assignment σ to the variables x1 , . . . , xn of the CNF formula F . To
do this, the operators of P11 (F ) are defined in such a way that the value of vs can change
from x to either 0 or 1, while from 0 or 1 it can only change back to x. Thus, by applying
the operators of P11 (F ) it is possible to generate a sequence x, m1 , x, . . . , x, mn , x of values
of vs , where mj ∈ {0, 1} for each j ∈ [1..n].
We define a message m as the sequence m1 , . . . , mn of n symbols (either 0 or 1) corresponding to a sequence of values of vs . In what follows, we refer to these symbols as the
“bits” of the message. The value x is used as a separator to distinguish between consecutive
bits of the message. Given a message m, the assignment σ is defined as σ(xj ) = mj for
each j ∈ [1..n]. Thus, the assignment to x1 is determined by the first choice of whether to
change the value of vs from x to 0 or 1, and so on. The only purpose of the remaining state
variables si of the first part is to restrict the message m to contain no more than n bits.
679

Giménez & Jonsson

(a)

(b)
a0

g0

a0

g0

c0

b0

c0

b0
a0,b0,g0

0

0

x
0

gx
1

ax

1

x
cx

x

gx
a1,b1,g1

1

x

ax,cx,gx

a0,b0,g0

x

ax,cx,gx

ax
ax,cx,gx

a0,b0,g0

ax,cx,gx

a1,b1,g1

ax,cx,gx

cx

x
a1,b1,g1

g1

a1

c1

b1

g1

a1

b1

ax,cx,gx
c1

(c)
a0

g0
a0,b0
c0,g0

cx,gx g
0
gx

c1,g1

cx,gx g1

ax

a1,b1
g1

c0

b0
ax,cx

c0

c0

cx

c1

cx

ax,cx
a1

cx

cx

c1
b1

cx
c1

Figure 4: DTGs of (a) v11 , (b) vi1 for i > 1, and (c) vij for j > 1. Dashed edges are
explained in the text.

The DTGs of state variables vij , i ∈ [1..k] and j ∈ [1..n], appear in Figure 4. The
dashed edges in the DTGs indicate that the corresponding operators depend on the CNF
formula F . For example, if the assignment σ(x1 ) = 1 satisfies the clause C1 , the edge from
v11 = ax with label 1 in Figure 4(a) points to g1 , else it points to b1 . Likewise, if σ(x1 ) = 0
satisfies C1 , the edge from v11 = ax with label 0 points to g0 , else it points to b0 .
Recall that the role of the second part is to check whether the assignment σ generated
by the first part satisfies the CNF formula F . For each clause Ci and each variable xj of
F , the main function of state variable vij is to check whether the assignment σ(xj ) = mj
satisfies Ci . To do this, state variable vij acts as a finite state automaton that propagates
each bit of the message m while keeping track of when the j-th bit of the message arrives.
Since the domain size of state variables is restricted, there is no way for vij to count the
number of bits it has received. Instead, the fact that the j-th bit has arrived is indicated
to it by vi(j−1) . Moreover, the last state variable vin for each clause Ci has to remember
whether or not Ci has been satisfied by the assignment to some variable xj .
In summary, each state variable vij in the second part performs the following functions
through its values and operators:
1. Propagate the message m generated by vs .
2. Check whether the assignment to xj (the j-th bit of m) satisfies the clause Ci .
680

Chain Causal Graphs with Domains of Size 5

0

0
a0,a1,
b0,b1, 0
g0,g1

ax
cx
gx
1

0
1

1

0

1
1

Figure 5: The domain transition graph of the variables ve , e1 , . . . , e2n−1 .
3. Remember whether Ci was satisfied by the assignment to some xl , l ≤ j.
4. If j < n and Ci has been satisfied, propagate this fact.
5. If j < n, let vi(j+1) know when the (j + 1)-th bit of the message has arrived.
Note that the third function is only strictly necessary for j = n. However, including it for
all state variables makes the reduction more compact because of symmetry.
Next, we briefly describe how vij implements each of these functions. Each value in
the domain of vij has subscript 0, 1, or x. To propagate the message, vij always moves
to a value whose subscript matches that of its predecessor (in the case of v11 , its subscript
should match the value of vs ). Unless Ci is satisfied by the assignment to xl , l < j, the
value of vij remains in the subdomain {a0 , a1 , ax } prior to the arrival of the j-th bit.
The clause Ci is encoded into the dashed edges of the DTGs of variables vij . These
operators are such that when the j-th bit mj arrives, vij moves from ax to gmj if the
assignment σ(xj ) = mj satisfies Ci , and to bmj otherwise. The fact that the value of vij
is in the subdomain {g0 , g1 , gx } indicates that Ci was satisfied by the assignment to some
xl , l ≤ j. This fact is propagated all the way to vin since each subsequent state variable
for Ci is forced to move to a value in the subdomain {g0 , g1 , gx } whenever the value of its
predecessor is in {g0 , g1 , gx }. Whether or not a clause Ci has been satisfied is checked by
defining a goal state vin = gx .
Finally, if j < n and vij moves to bmj , then vi(j+1) moves to amj . From there, vij has
no choice but to move to cx , causing vi(j+1) to return to ax . When the next bit arrives, vij
moves to either c0 or c1 , correctly indicating to vi(j+1) that the (j + 1)-th bit has arrived.
Consequently, vi(j+1) moves to either g0 (g1 ) or b0 (b1 ), depending on whether or not the
assignment to xj+1 satisfies Ci . Hence, the values of type b are used to delay the transition
of vi(j+1) from a value of type a to either b or g. This is the mechanism that allows a
variable vij to react to the j-th bit. For each clause Ci , the operators for vi1 are defined
such that vi1 always reacts to the first bit.
The DTGs of state variables ve , e1 , . . . , e2n−1 appear in Figure 5. The function of these
state variables is to make sure that all n bits of the message m are propagated to the end
of the causal graph. A state variable (strictly speaking, a planner solving the planning
problem) is never forced to select an operator, so it can choose not to propagate a bit of the
message and instead wait for the next bit to arrive before acting. In turn, this may cause
another state variable to incorrectly conclude that a clause has (not) been satisfied. The
variables of the third part prevent this from happening, since the goal state is defined in
such a way that it cannot be reached unless all bits of the message arrive at the end of the
causal graph.
681

Giménez & Jonsson

Variable
s1
si ,
i ∈ [2..2n − 1]
vs

Operator
hs1 = 0; s1 = 1i
hsi−1 = 0, si = 0; si = 1i
hsi−1 = 1, si = 1; si = 0i
hs2n−1 = 0, vs = x; vs = mi
hs2n−1 = 1, vs = m; vs = xi

Qualifier

m ∈ {0, 1}
m ∈ {0, 1}

Table 2: Operators for the variables s1 , s2 , . . . , s2n−1 , vs .

4.2 Formal Proof
In this section, we prove that C11
n is NP-hard by showing that the planning problem P11 (F )
is solvable if and only if the formula F has a satisfying assignment. To start with, we provide
formal definitions of the operators of P11 (F ). The operators for s1 , . . . , s2n−1 , vs appear in
Table 2, and the corresponding DTGs appear in Figure 3. The operators for variables vij ,
i ∈ [1..k] and j ∈ [1..n], appear in Table 3, and the DTGs appear in Figure 4. Finally, the
operators for ve , e1 , . . . , e2n−1 appear in Table 4, and the DTGs appear in Figure 5.
To reduce the space requirement we use shorthand in the definitions of operators. In
other words, hv ′ = m, v = c; v = mi, m ∈ {a, b}, denotes the existence of two operators
hv ′ = a, v = c; v = ai and hv ′ = b, v = c; v = bi. Similarly, hv ′ ∈ {a, b}, v = c; v = di denotes
the existence of two operators hv ′ = a, v = c; v = di and hv ′ = b, v = c; v = di. For state
variables vij we also introduce reference numbers that allow us to easily refer to operators.
Furthermore, some operators are conditional on properties of the CNF formula F ; such
an operator only exists if the indicated property is satisfied. For example, the operator
hv22 = c0 , v23 = ax ; v23 = g0 i only exists if the clause C2 is satisfied by x3 , and the operator
hv22 = c0 , v23 = ax ; v23 = b0 i only exists if C2 is not satisfied by x3 . We use the set notation
xj ∈ Ci to denote that the literal xj appears in the clause Ci .
The proof is organized as follows. We begin with a series of technical definitions and
lemmas (4.1–4.6) related to the operators and their implications. Definition 4.7 then introduces the notion of admissible plans, and Lemma 4.8 states that any plan for solving P11 (F )
has to be admissible. Next, Lemma 4.10 establishes that any admissible plan corresponds
to an assignment to the variables of the CNF formula F , and that all operator choices of the
plan are forced given this assignment. Finally, Lemma 4.13 determines the exact sequence
of values taken on by each state variable during the execution of an admissible plan, making
it possible to check whether the goal state is reached at the end of the execution. Theorem
4.14 then concludes that the only admissible plans solving P11 (F ) are those corresponding
to satisfying assignments of F .
Definition 4.1. Given a partial plan Π for P11 (F ) and a variable v ∈ V , Π(v) is the number
of times the value of v is changed by operators in Π.
Lemma 4.2. For each partial plan Π for P11 (F ), it holds that
• Π(si ) ≤ i for i ∈ [1..2n − 1], and
• Π(vs ) ≤ 2n.
682

Chain Causal Graphs with Domains of Size 5

Variable
v11

vi1 ,
i ∈ [2..k]

vij ,
i ∈ [1..k],
j ∈ [2..n]

Ref.
(1)
(2)
(3)
(4)
(5)
(6)
(7)
(8)
(9)
(1)
(2)
(3)
(4)
(5)
(6)
(7)
(8)
(9)
(10)
(11)
(12)
(13)
(14)
(15)
(16)
(17)
(18)
(19)
(20)
(21)

Operator
hvs = 1, v11 = ax ; v11 = g1 i
hvs = 1, v11 = ax ; v11 = b1 i
hvs = 0, v11 = ax ; v11 = g0 i
hvs = 0, v11 = ax ; v11 = b0 i
hvs = m, v11 = cx ; v11 = cm i
hvs = m, v11 = gx ; v11 = gm i
hvs = x, v11 = bm ; v11 = cx i
hvs = x, v11 = cm ; v11 = cx i
hvs = x, v11 = gm ; v11 = gx i
hv(i−1)n ∈ {a1 , b1 , g1 }, vi1 = ax ; vi1 = g1 i
hv(i−1)n ∈ {a1 , b1 , g1 }, vi1 = ax ; vi1 = b1 i
hv(i−1)n ∈ {a0 , b0 , g0 }, vi1 = ax ; vi1 = g0 i
hv(i−1)n ∈ {a0 , b0 , g0 }, vi1 = ax ; vi1 = b0 i
hv(i−1)n ∈ {am , bm , gm }, vi1 = cx ; vi1 = cm i
hv(i−1)n ∈ {am , bm , gm }, vi1 = gx ; vi1 = gm i
hv(i−1)n ∈ {ax , cx , gx }, vi1 = bm ; vi1 = cx i
hv(i−1)n ∈ {ax , cx , gx }, vi1 = cm ; vi1 = cx i
hv(i−1)n ∈ {ax , cx , gx }, vi1 = gm ; vi1 = gx i
hvi(j−1) = c1 , vij = ax ; vij = g1 i
hvi(j−1) = c1 , vij = ax ; vij = b1 i
hvi(j−1) = c0 , vij = ax ; vij = g0 i
hvi(j−1) = c0 , vij = ax ; vij = b0 i
hvi(j−1) ∈ {am , bm }, vij = ax ; vij = am i
hvi(j−1) = gm , vij = ax ; vij = gm i
hvi(j−1) = cm , vij = cx ; vij = cm i
hvi(j−1) ∈ {cm , gm }, vij = gx ; vij = gm i
hvi(j−1) ∈ {ax , cx }, vij = am ; vij = ax i
hvi(j−1) = cx , vij = bm ; vij = cx i
hvi(j−1) = cx , vij = cm ; vij = cx i
hvi(j−1) ∈ {cx , gx }, vij = gm ; vij = gx i

Qualifier
x1 ∈ C1
x1 ∈
/ C1
x1 ∈ C1
x1 ∈
/ C1
m ∈ {0, 1}
m ∈ {0, 1}
m ∈ {0, 1}
m ∈ {0, 1}
m ∈ {0, 1}
x1 ∈ Ci
x1 ∈
/ Ci
x1 ∈ Ci
x1 ∈
/ Ci
m ∈ {0, 1}
m ∈ {0, 1}
m ∈ {0, 1}
m ∈ {0, 1}
m ∈ {0, 1}
xj ∈ Ci
xj ∈
/ Ci
xj ∈ Ci
xj ∈
/ Ci
m ∈ {0, 1}
m ∈ {0, 1}
m ∈ {0, 1}
m ∈ {0, 1}
m ∈ {0, 1}
m ∈ {0, 1}
m ∈ {0, 1}
m ∈ {0, 1}

Table 3: Operators for the variables v11 , . . . , vkn .

Variable
ve

hvkn

e1
ei , i ∈ [2..2n − 1]

Operator
∈ {a0 , a1 , b0 , b1 , g0 , g1 }, ve
hvkn ∈ {ax , cx , gx }, ve
hve = 1, e1
hve = 0, e1
hei−1 = 1, ei
hei−1 = 0, ei

= 0; ve = 1i
= 1; ve = 0i
= 0; e1 = 1i
= 1; e1 = 0i
= 0; ei = 1i
= 1; ei = 0i

Table 4: Operators for the variables ve , e1 , . . . , e2n−1 .

683

Giménez & Jonsson

Proof. By induction on i. For i = 1, variable s1 can only change once, so Π(s1 ) ≤ 1. For
i ∈ [2..2n − 1], it follows from inspection of the operators that we cannot change the value
of si twice without changing the value of si−1 once in between (the operator for setting si
to 1 has si−1 = 0 as a pre-condition, and the operator for resetting si to 0 has si−1 = 1
as a pre-condition). Since we can change the value of si once in the initial state without
first changing the value of si−1 , it follows that Π(si ) ≤ Π(si−1 ) + 1 ≤ (i − 1) + 1 = i by
induction. The same argument holds for variable vs and its predecessor s2n−1 , so Π(vs ) ≤
Π(s2n−1 ) + 1 ≤ (2n − 1) + 1 = 2n.
Lemma 4.3. For each partial plan Π for P11 (F ) and each vij , i ∈ [1..k] and j ∈ [1..n], it
holds that Π(vij ) ≤ Π(v ′ ), where v ′ is the predecessor of vij in the causal graph.
Proof. Just as before, it follows by inspection of the operators that we cannot change the
value of vij twice without changing the value of v ′ in between. To see this, note that the
subscript of each value in D(vij ) is either x, 0, or 1. An operator for vij either changes
its value from one with subscript x to one with subscript 0 (1), if v ′ also has a value with
subscript 0 (1), or from one with subscript 0 (1) to one with subscript x, if v ′ also has a value
with subscript x (the same argument holds for v11 , although the values of its predecessor
vs are x, 0, and 1 without subscripts).
Note that the value of vij cannot change in the initial state without first changing the
value of v ′ , since v ′ has to have a value with subscript 0 or 1 for the value of vij to change
from its initial value ax . Consequently, the value of vij cannot change more times than the
value of v ′ , so Π(vij ) ≤ Π(v ′ ) as claimed.
Lemma 4.4. For each vij , i ∈ [1..k] and j ∈ [1..n], and each partial state (v ′ = x, vij = y),
where v ′ is the predecessor of vij in the causal graph, there is at most one applicable operator
for changing the value of vij .
Proof. By inspecting the operators it is easy to see that each pair of operators for vij have
different pre-conditions. The only exception to this rule are operators that do not exist
simultaneously due to properties of the CNF formula F (e.g. operators (1) and (2)).
Lemma 4.5. For each partial plan Π for P11 (F ), it holds that
• Π(ve ) ≤ Π(vkn ),
• Π(e1 ) ≤ Π(ve ), and
• Π(ei ) ≤ Π(ei−1 ) for i ∈ [2..2n − 1].
Proof. Let v be a variable among ve , e1 , . . . , e2n−1 , and let v ′ be its predecessor in the causal
graph. As before, we cannot change the value of v twice without changing the value of v ′
once in between. If v ∈ {e1 , . . . , e2n−1 }, the operator setting v to 1 requires v ′ = 1, and the
operator resetting v to 0 requires v ′ = 0. For v = ve , the operator setting v to 1 requires
v ′ to have a value with subscript 0 or 1, while the operator resetting v to 0 requires v ′ to
have a value with subscript x. Note that, in either case, we cannot change the value of v in
the initial state without first changing the value of v ′ . Thus, Π(v) ≤ Π(v ′ ) for each of these
variables, as claimed.
684

Chain Causal Graphs with Domains of Size 5

We now turn to the problem of finding a plan Π that solves P11 (F ).
Lemma 4.6. Let Π be a plan that solves P11 (F ). Then
• Π(ei ) ≥ 2n − i for i ∈ [1..2n − 1], and
• Π(ve ) ≥ 2n.
Proof. By descending induction on i. For i = 2n − 1, goal(e2n−1 ) = 1, so the value of
e2n−1 has to change at least once from its initial value init(e2n−1 ) = 0, implying Π(e2n−1 ) ≥
1 = 2n − (2n − 1). For i ∈ [1..2n − 2], assume that Π(ei+1 ) ≥ 2n − (i + 1) holds by
induction. From Lemma 4.5 it follows that Π(ei ) ≥ Π(ei+1 ) ≥ 2n − (i + 1). However,
since goal(ei ) 6= goal(ei+1 ) and since Π solves P11 (F ), it follows that Π(ei ) 6= Π(ei+1 ).
Hence Π(ei ) > Π(ei+1 ), from which it follows that Π(ei ) ≥ 2n − i, as claimed. The same
argument applies to e1 and its predecessor ve , since goal(ve ) = 0 6= 1 = goal(e1 ), yielding
Π(ve ) ≥ 2n.
Definition 4.7. An admissible plan Π for planning problem P11 (F ) is a partial plan such
that Π(si ) = i, Π(vs ) = Π(v11 ) = . . . = Π(vkn ) = Π(ve ) = 2n, and Π(ei ) = 2n − i, for each
i ∈ [1..2n − 1].
Lemma 4.8. Any plan Π that solves P11 (F ) is admissible.
Proof. By Lemmas 4.3 and 4.5 we have that Π(vs ) ≥ Π(v11 ) ≥ · · · ≥ Π(vkn ) ≥ Π(ve ). But,
by Lemmas 4.2 and 4.6, all these values are equal to 2n, since 2n ≥ Π(vs ) and Π(ve ) ≥ 2n.
From the proof of Lemma 4.2 we have that Π(si ) ≤ Π(si−1 ) + 1, i ∈ [2..2n − 1], and
Π(vs ) ≤ Π(s2n−1 ) + 1, which together with Lemma 4.2 and Π(vs ) = 2n implies Π(si ) = i,
i ∈ [1..2n − 1]. From the proof of Lemma 4.6 we have that Π(ve ) > Π(e1 ), Π(ei ) > Π(ei+1 ),
i ∈ [1..2n − 2], and Π(e2n−1 ) ≥ 1, which together with Lemma 4.6 and Π(ve ) = 2n implies
Π(ei ) = 2n − i, i ∈ [1..2n − 1].
Please note that the converse of Lemma 4.8 is not true, that is, not all admissible plans
do solve the planning problem P11 (F ).
As a consequence of Lemma 4.8, to find a plan that solves P11 (F ) we only need to
consider admissible plans. In particular, an admissible plan changes the value of variable vs
exactly 2n times, generating a sequence of 2n + 1 values. Note that the value of vs always
changes from x to either 0 or 1, and then back to x.
Definition 4.9. Let Π be an admissible plan, and let x, m1 , x, . . . , x, mn , x be the sequence
of 2n + 1 values that variable vs takes on during the execution of Π, where mj ∈ {0, 1} for
each j ∈ [1..n]. We use mΠ to denote the message m1 , . . . , mn induced by Π, and we use
σΠ to denote the formula assignment σΠ (xj ) = mj for each j ∈ [1..n].
As it turns out, the operators that are part of an admissible plan Π are completely
determined by the message mΠ induced by Π.
Lemma 4.10. Let Π be an admissible plan for P11 (F ) and let mΠ be its induced message.
The operators in Π for changing the value of variable vij , i ∈ [1..k] and j ∈ [1..n], as well
as the sequence of values that variable vij takes on during the execution of Π, are completely
determined by mΠ .
685

Giménez & Jonsson

Proof. For each v ∈ {v11 , . . . , vkn }, let v ′ be its causal graph predecessor. From the proof of
Lemma 4.3 we know that we cannot change the value of v twice without changing the value
of v ′ in between, and that in the initial state, we have to change the value of v ′ before we can
change the value of v. From the definition of admissible we know that Π(v ′ ) = Π(v) = 2n.
The only way an admissible plan can change the value of v 2n times without changing the
value of v ′ more than 2n times is to first change the value of v ′ , then v, then v ′ , and so on.
Now, from Lemma 4.4 we know that, given a partial state (v ′ = x, v = y), there is at
most one applicable operator for changing the value of v. Thus, each time the admissible
plan changes the value of v for some value of v ′ , there is at most one operator for doing so.
The plan has no choice but to select this operator since it is not allowed to change the value
of v ′ again before changing the value of v. Consequently, if the sequence of values taken
on by v ′ is completely determined, the operators for v, as well as the sequence of values
it takes on, are completely determined also. The proof follows by a double induction on i
and j, since the sequence of values taken on by vs (the predecessor of v11 ) is completely
determined by the message mΠ .
It follows from Lemma 4.10 that the only relevant “degree of freedom” of an admissible
plan Π is selecting the elements of the message mΠ , by repeatedly deciding whether to move
to vs = 0 or vs = 1 from vs = x. Once mΠ has been selected, all other operator choices are
forced, else the plan is not admissible. In particular, for each message mΠ there is a unique
state s such that executing any admissible plan starting from init results in s. It remains
to determine whether this unique state matches the goal state.
Remark. Note that Lemma 4.10 does not mention the operator order of an admissible plan.
Indeed, we can change the order of the operators of an admissible plan without making the
plan inadmissible. As an example, let v1 , v2 , and v3 be three consecutive variables in the
causal graph, and let ha11 , a12 , a13 , a21 , a22 , a23 i be a subsequence of operators for changing their
values, such that aji is the j-th operator for changing the value of vi . Then the subsequence
i
ha11 , a12 , a21 , a13 , a22 , a23 i achieves the same result. As long as the partial order haji , aji+1 , aj+1
i
is respected for each i and j, we can change the operator order as we please.
We proceed to determine the sequence of values that variable vij , i ∈ [1..k] and j ∈
[1..n], takes on during the execution of an admissible plan Π with induced message mΠ .
First, we define the satisficing index of clauses, and the sequence of values of a plan.
Definition 4.11. Let Π be an admissible plan with induced message mΠ = m. For each
clause Ci , let the satisficing index Ti ∈ [1..n+1] be the smallest number such that σΠ (xTi ) =
mTi satisfies Ci . If no such number exists, Ti = n + 1.
Definition 4.12. Let Π be an admissible plan. For each clause Ci and each t ∈ [1..2n + 1],
let the sequence of values Qti (Π) be the vector of n values representing, for each variable
vij , j ∈ [1..n], the t-th value taken on by vij during the execution of Π.
The following lemma is key to understanding the idea behind the reduction for C11
n , since
it specifies the sequences of values that an admissible plan induces during its execution.
Lemma 4.13. Let σ be an assignment to variables x1 , . . . , xn of formula F .
686

Chain Causal Graphs with Domains of Size 5

1) Existence. There exists an admissible plan Π of planning problem P11 (F ) with induced assignment σΠ = σ.
2) Claim. Let Qti be the sequences of values described in Part 3) of this lemma. All
admissible plans Π with σΠ = σ have the same sequences of values Qti (Π) = Qti , for
all i ∈ [1..k] and t ∈ [1..2n + 1].
3) Sequence of values. The sequence of values Qti , for i ∈ [1..k] and t ∈ [1..2n + 1],
is as follows.
a) If j < Ti , then
n−j

j−1

z }| {
c x · · · cx
Qi2j−1 =
2j
Qi = cmj · · · cmj
2j+1
=
c x · · · cx
Qi

ax
bmj
cx

z }| {
ax · · · ax
amj · · · amj
ax · · · ax

ax
gmj
gx

z }| {
ax · · · ax
gmj · · · gmj
gx · · · gx

b) If j = Ti , then
n−j

j−1

Qi2j−1
Q2j
i
Q2j+1
i

z }| {
c x · · · cx
=
= cmj · · · cmj
=
c x · · · cx

c) If j > Ti , then
j−Ti

n−j

z }| {
gx · · · gx
gmj · · · gmj
gx · · · gx

z }| {
gx · · · gx
gmj · · · gmj
gx · · · gx

Ti −1

Qi2j−1
Q2j
i
Q2j+1
i

z }| {
=
c x · · · cx
= cmj · · · cmj
=
c x · · · cx

gx
gmj
gx

Proof. Before proving the lemma, we must check that the definition of Qti given in Part 3
is consistent. This is necessary due to the overlapping of the statements, namely, for every
odd t other than 1 and 2n + 1, the sequence Qti is defined twice, once as Qi2j−1 for j = ⌈ 2t ⌉,
′
and another time as Qi2j +1 for j ′ = ⌊ 2t ⌋. However, these sequences of values are well-defined
′ +1
because the definitions of Qi2j−1 and Q2j
match for any combination of j and j ′ = j − 1,
i
as shown in the following table.
′

j

Qi2j +1 = Qi2j−1

Case (a)

z }| { z }| {
cx · · · cx ax · · · ax

Case (b)

z }| { z }| {
cx · · · cx ax · · · ax

Case (c)

z }| { z }| {
cx · · · cx gx · · · gx

Case (c)

z }| { z }| {
cx · · · cx gx · · · gx

j′

j′

1 < j < Ti :

Case (a)

j′

1 < j = Ti :

Case (a)

Ti −1

j = Ti + 1 ≤ n:

Case (b)

Ti −1

Ti + 1 < j ≤ n:

Case (c)

687

n−j ′

n−j ′

n−Ti +1
n−Ti +1

Giménez & Jonsson

Now, we prove Parts 2 and 3 of the lemma. Assume Π is an admissible plan with induced
assignment σΠ = σ. The proof proceeds by a double induction on i and j. In particular,
2j+1
we prove the validity of the three statements of type Qi2j−1 , Q2j
, assuming that all
i , Qi
′
′
t
′
statements of type Qi′ (for any i < i and any t) and that all statements of type Qi2j −1 , Q2j
i
′
and Qi2j +1 (for any j ′ < j) already hold. We first prove the validity of Qi2j−1 . For j = 1,
Qi2j−1 = Q1i = ax · · · ax in Cases (a) and (b) corresponds to the initial state of vi1 , . . . , vin
(note that Case (c) cannot hold for j = 1). When j > 1 we know that, since the statements
′
are consistent, Qi2j−1 = Qi2j +1 for j ′ = j − 1, hence the correctness of Qi2j−1 follows by
induction on j.
2j+1
Next, we prove the statements relative to Q2j
. Consider the variable v ′ that
i and Qi
precedes vi1 in the causal graph, and values number 2j − 1, 2j, and 2j + 1 it takes on
during the execution of Π. If i = 1, then v ′ = vs and the values are x, mj , x. If i > 1,
then v ′ = v(i−1)n and, by induction on i, the values are ax , amj , ax if j < Ti−1 and j < n;
ax , bmj , cx if j = n < Ti−1 ; ax , gmj , gx if j = Ti−1 ; or gx , gmj , gx if j > Ti−1 .
The proof is divided into 6 parts, depending on the values of j and Ti .
I) 1 = j < Ti . Consider the following table, where we write m instead of mj = m1 to
simplify the notation.
v′
vi1
2j − 1
{x, ax , gx }
ax
{m, am , bm , gm } ·
2j
2j + 1 {x, ax , cx , gx }
·

vi2
ax
·
·

···
···
···
···

vin
ax
·
·

The three rows of the table correspond to values number 2j − 1, 2j, and 2j + 1 of
variables v ′ , vi1 , . . . , vin . The first column corresponds to the possible values that the
predecessor v ′ of vi1 can take on. The first row is given by Qi2j−1 , while the second
2j+1
and third rows, to be filled, correspond to Q2j
.
i and Qi
Let A2j be the operator causing the 2j-th value of vi1 . According to the previous
table, the pre-condition of A2j must be compatible with
hv ′ ∈ {m1 , am1 , bm1 , gm1 }, vi1 = ax i
that is, the values of variables v ′ and vi1 when A2j is applied. Since Ti > 1, σΠ (x1 ) =
m1 does not satisfy clause Ci , so the operator A2j must be one of those labelled (2)
and (4) in Table 3. (Only one of these operators is applicable, depending on the value
of m1 and whether v ′ is vs or v(i−1)n .) In either case, the application of A2j causes
the value of vi1 to become bm1 , so we can fill in a blank in the previous table.
v′
vi1
vi2
2j − 1
{x, ax , gx }
ax
ax
2j
{m, am , bm , gm } bm (2, 4) ·
2j + 1 {x, ax , cx , gx }
·
·

···
···
···
···

vin
ax
·
·

In the same way, we can check that A2j+1 , the operator causing the (2j + 1)-th value
of vi1 , must be one of those labelled (7) in Table 3; the new value of vi1 is cx . As for
688

Chain Causal Graphs with Domains of Size 5

the remaining variables, it is easy to check that variables vi2 , . . . , vin become am1 , due
to operators of type (14), and then become ax , due to operators of type (18). The
table is now complete:
v′
vi1
vi2 · · · vin
2j − 1
{x, ax , gx }
ax
ax · · · ax
2j
{m, am , bm , gm } bm (2, 4) am · · · am (14)
2j + 1 {x, ax , cx , gx }
cx (7)
ax · · · ax (18)
This shows that Case (a) of Lemma 4.13 holds when j = 1 and Ti > 1.
II) 1 = j = Ti . The proof is similar to that of Case (I). Since Ti = 1, σΠ (x1 ) = m1
satisfies clause Ci . As a result, the admissible operators for causing the 2j-th value
of vi1 are now those labelled (1) and (3). In either case, the value of vi1 becomes gm1 .
Consequently, the admissible operators for vi2 , . . . , vin are different from before. This
is the resulting table:
v′
vi1
vi2 · · · vin
2j − 1
{x, ax , gx }
ax
ax · · · ax
2j
{m, am , bm , gm } gm (1, 3) gm · · · gm (15)
2j + 1 {x, ax , cx , gx }
gx (9)
gx · · · gx (21)
III) 1 < j < Ti . In this case, as in the remaining ones, we just show the resulting table.
We always write m = mj . In what follows, we omit the column for v ′ since its possible
values are always the same.
vi1
vi2 · · · vi(j−1)
vij
vi(j+1) · · · vin
2j − 1 cx
c x · · · cx
ax
ax · · · ax
cm (5)
cm · · · cm (16) bm (11, 13)
am · · · am (14)
2j
2j + 1 cx (8)
cx · · · cx (20) cx (19)
ax · · · ax (18)
IV) 1 < j = Ti .
vi1
vi2 · · · vi(j−1)
vij
vi(j+1) · · · vin
2j − 1 cx
c x · · · cx
ax
ax · · · ax
cm (5)
cm · · · cm (16) gm (10, 12)
gm · · · gm (15)
2j
2j + 1 cx (8)
cx · · · cx (20) gx (21)
gx · · · gx (21)
V) 1 = Ti < j.
vi1
vi2 · · · vin
2j − 1 gx
gx · · · gx
2j
gm (6) gm · · · gm (17)
2j + 1 gx (9) gx · · · gx (21)
VI) 1 < Ti < j.
vi1
vi2 · · · vi(Ti −1)
viTi · · · vin
2j − 1 cx
c x · · · cx
gx · · · gx
2j
cm (5)
cm · · · cm (16) gm · · · gm (17)
cx · · · cx (20) gx · · · gx (21)
2j + 1 cx (8)
689

Giménez & Jonsson

It just remains to check that Case (a) of Lemma 4.13 follows from parts (I) and (III),
Case (b) from parts (II) and (IV), and Case (c) from parts (V) and (VI). This proves Part
2 and 3 of the lemma.
Finally, note that the existence of an admissible plan Π directly follows from the previous
discussion, since we have always specified which operators should be used in every situation,
and not just assumed their existence. This proves Part 1 of the lemma.
Theorem 4.14. There exists a plan that solves the planning problem P11 (F ) if and only if
there exists an assignment σ that satisfies the CNF formula F .
Proof. ⇐: Given an assignment σ that satisfies F , construct an admissible plan Π whose
induced formula assignment σΠ equals σ, by choosing the sequence of values of vs accordingly. It follows that Ti ≤ n for each clause Ci , since there exists a variable xj such that
σΠ (xj ) = mj satisfies Ci . Then, Q2n+1
has the form indicated in Case (b) or (c) of Lemma
i
4.13. In either case, the (2n + 1)-th value of variable vin is gx , as required by the goal state.
The plan Π thus solves P11 (F ).
⇒: Let Π be a plan that solves the planning problem P11 (F ). By Lemma 4.8 the plan Π
is admissible. We show by contradiction that σ = σΠ satisfies F . Assume not. Then there
exists a clause Ci not satisfied by σ, implying Ti = n + 1. Since n < Ti , the (2n + 1)-th
value of variable vin is cx according to Case (a) of Lemma 4.13. This contradicts Π solving
P11 (F ), since the goal value of vin is not cx but gx .
Proposition 4.15. Plan existence for C11
n is NP-hard.
Proof. The largest variable domains of the planning problem P11 (F ) are those of variables
v11 , . . . , vkn , which contain 11 values. The proof follows immediately from the well-known
NP-hardness of Cnf-Sat, Theorem 4.14, and the fact that we can produce the planning
problem P11 (F ) in polynomial time given the CNF formula F .
4.3 Example
We illustrate the reduction using a small example CNF formula F = (x1 ∨ x2 ) on one
clause and two variables x1 and x2 . The variable set of the corresponding planning problem
P11 (F ) is V = {s1 , s2 , s3 , vs , v11 , v12 , ve , e1 , e2 , e3 }. An admissible plan Π can induce any of
four different messages (0, 0), (0, 1), (1, 0), and (1, 1). Only the message (0, 0) corresponds
to an assignment that does not satisfy F . A plan Π that solves P11 (F ) with induced
message (0, 1) appears in Table 5. Note that, following execution of the plan, the goal state
goal = (v12 = gx , ve = 0, e1 = 1, e2 = 0, e3 = 1) is satisfied as desired; the last value change
of each variable appearing in the goal state is marked using boldface.

5. C5n Is NP-hard
In this section, we describe a reduction from Cnf-Sat to C5n . To each CNF formula F we
associate a planning problem P5 (F ). For each clause Ci and variable xj of F , P5 (F ) contains
1 , with domain D(v 1 ) = {a , a , a , b }, and v 2 , with domain D(v 2 ) =
two state variables vij
x 0 1 x
ij
ij
ij
2 , so D(v 2 ) = {a , b , b }. The
{ax , a0 , a1 , b0 , b1 }. The values a0 and a1 are omitted for vin
x 0 1
in
690

Chain Causal Graphs with Domains of Size 5

..
.
hs1 = 0, s2 = 0; s2 = 1i
hs2 = 1, s3 = 1; s3 = 0i
hs3 = 0, vs = x; vs = 1i
hvs = 1, v11 = cx ; v11 = c1 i
hv11 = c1 , v12 = ax ; v12 = g1 i
hv12 = g1 , ve = 0; ve = 1i
hve = 1, e1 = 0; e1 = 1i
hs1 = 0; s1 = 1i
hs1 = 1, s2 = 1; s2 = 0i
hs2 = 0, s3 = 0; s3 = 1i
hs3 = 1, vs = 1; vs = xi
hvs = x, v11 = c1 ; v11 = cx i
hv11 = cx , v12 = g1 ; v12 = gx i
hv12 = gx , ve = 1; ve = 0i

hs3 = 0, vs = x; vs = 0i
hvs = 0, v11 = ax ; v11 = b0 i
hv11 = b0 , v12 = ax ; v12 = a0 i
hv12 = a0 , ve = 0; ve = 1i
hve = 1, e1 = 0; e1 = 1i
he1 = 1, e2 = 0; e2 = 1i
he2 = 1, e3 = 0; e3 = 1i
hs2 = 0, s3 = 0; s3 = 1i
hs3 = 1, vs = 0; vs = xi
hvs = x, v11 = b0 ; v11 = cx i
hv11 = cx , v12 = a0 ; v12 = ax i
hv12 = ax , ve = 1; ve = 0i
hve = 0, e1 = 1; e1 = 0i
he1 = 0, e2 = 1; e2 = 0i
..
.

Table 5: A plan that solves the planning problem P11 (F ) for the example formula F .
(a)

(b)

(c)

(d)

a0

a0

a0

a0
a0

x

0

b0

x

ax

bx

ax

x

x

b1

ax

ax b0

ax

ax b1

bx
ax

ax
a1

1

ax a0

ax

a1

ax bx

ax

ax
a1

a1

b0
a0

ax
a0

bx

ax

(e)
b0
ax bx

a1

ax a1
a1

ax bx
b1

ax bx

a1
b1

1 , (b) v 1 , i > 1, (c) v 1 , j > 1, (d) v 2 , j < n, (e) v 2 .
Figure 6: DTGs of (a) v11
i1
ij
ij
in

state variables s1 , . . . , s2n−1 , vs , ve , e1 , . . . , e2n−1 , as well as their domains and corresponding
2 .
operators, are the same as before, except the predecessor of ve is now vkn
1 ) = init(v 2 ) = a , i ∈ [1..k] and
The initial state on the new state variables is init(vij
x
ij
1
j ∈ [1..n], and the goal state is goal(vi1 ) = ax , i ∈ [1..k]. Table 6 lists the operators for
1 and v 2 , i ∈ [1..k] and j ∈ [1..n], and Figure 6 shows the corresponding DTGs.
variables vij
ij
Table 6 also lists the new operators for variable ve , which have different pre-conditions now
2 .
that the predecessor of ve is vkn
5.1 Intuition
The reduction for C5n is based on the following idea: instead of using an explicit value to
remember that a clause has been satisfied, the goal is to remain in the initial value ax .
This way we were able to reduce the size of the variable domains needed for the reduction.
Somewhat surprisingly, the new reduction uses fewer total operators than that for C11
n .
691

Giménez & Jonsson

Variable
1
v11

1,
vi1
i ∈ [2..k]
1,
vij
i ∈ [1..k],
j ∈ [2..n]
2,
vij
i ∈ [1..k],
j ∈ [1..n − 1]

2 ,
vin
i ∈ [1..k]

ve

Ref.
(1)
(2)
(3)
(4)
(5)
(6)
(7)
(8)
(9)
(10)
(11)
(12)
(13)
(14)
(15)
(16)
(17)
(18)
(19)
(20)
(21)
(22)

Operator
1 = a ; v1 = a i
hvs = m, v11
x 11
m
1 = a ; v1 = a i
hvs = x, v11
m 11
x
1 = a ; v1 = b i
hvs = x, v11
m 11
x
1 = a ; v1 = a i
2
= bm , vi1
hv(i−1)n
x i1
m
2
1 = a ; v1 = a i
hv(i−1)n
= ax , vi1
x
m i1
2
1 = a ; v1 = b i
hv(i−1)n
= ax , vi1
m i1
x
1 = a ; v1 = a i
2
= am , vij
hvi(j−1)
m
x ij
2
1 = a ; v1 = a i
hvi(j−1)
= ax , vij
m ij
x
1 = b ; v1 = a i
2
= bm , vij
hvi(j−1)
m
x ij
1
1
2
hvi(j−1) = ax , vij = am ; vij = bx i
1 = a , v2 = a ; v2 = a i
hvij
m
x ij
m ij
1 = a , v2 = a ; v2 = a i
hvij
x
x ij
m ij
2
2
1
hvij = am , vij = ax ; vij = bm i
1 = a , v2 = b ; v2 = a i
hvij
x
x ij
1 ij
1 = b , v2 = b ; v2 = a i
hvij
x ij
1 ij
x
1 = a , v2 = b ; v2 = a i
hvij
x ij
0 ij
x
1 = b , v2 = b ; v2 = a i
hvij
x ij
0 ij
x
1 = a , v2 = a ; v2 = b i
hvin
m
x in
m in
1 = a , v2 = b ; v2 = a i
hvin
x in
1 in
x
1 = b , v2 = b ; v2 = a i
hvin
x
1 in
x in
1 = a , v2 = b ; v2 = a i
hvin
x
x in
0 in
1 = b , v2 = b ; v2 = a i
hvin
x
0 in
x in
2 = b , v = 0; v = 1i
hvkn
m e
e
2 = a , v = 1; v = 0i
hvkn
x e
e

Qualifier
m ∈ {0, 1}
m ∈ {0, 1}
m ∈ {0, 1}
m ∈ {0, 1}
m ∈ {0, 1}
m ∈ {0, 1}
m ∈ {0, 1}
m ∈ {0, 1}
m ∈ {0, 1}
m ∈ {0, 1}
m ∈ {0, 1}
m ∈ {0, 1}
m ∈ {0, 1}
xn−j+1 ∈ Ci
xn−j+1 ∈
/ Ci
xn−j+1 ∈ Ci
xn−j+1 ∈
/ Ci
m ∈ {0, 1}
x1 ∈ Ci
x1 ∈
/ Ci
x1 ∈ Ci
x1 ∈
/ Ci
m ∈ {0, 1}

1 , v 2 , and v , i ∈ [1..k] and j ∈ [1..n].
Table 6: Operators for variables vij
e
ij

692

Chain Causal Graphs with Domains of Size 5

Our reduction for C5n also uses another new idea. In the reduction for C11
n , information
was propagated forward, i.e., variable vij changed its value according to the value of its
predecessor vi(j−1) . The reduction for C5n , however, is constructed such that some information is propagated forward (in particular, the bits of the message) but other information
is propagated backwards (the index of the bit we are currently checking). The planning
problem is arranged such that a variable v may have several applicable operators, but only
one of them satisfies the pre-condition of an applicable action for its successor v ′ . The result
is that the value of v at time t + 1 depends on the value of v ′ at time t.
We explain the planning problem P5 (F ) in a bit more detail. Due to the backward
propagation mechanism, the bits of the message are checked in reverse order. In other
words, vin now checks the first bit, vi(n−1) checks the second bit, and vi1 checks the n-th
2 is to check whether the (n − j + 1)-th bit satisfies the clause C ,
bit. The purpose of vij
i
1 is to inform v 2
whereas the purpose of vij
that
the
(n
−
j
+
2)-th
bit
has
arrived.
i(j−1)
1 also keeps track of whether C has been satisfied after the first (n − j + 1)
Implicitly, vij
i
bits.
Assume without loss of generality that the message is 0 · · · 0. Let us see what happens
if the corresponding assignment does not satisfy the clause Ci . Upon arrival of the first bit,
2 has to move to b . This requires v 1 = a as a pre-condition, which in
state variable vin
0
0
in
l , j ∈ [1..n − 1] and l ∈ {1, 2}, to be in a . Next, v 2 has
turn requires state variables vij
0
in
1 = b . In turn, this requires state
to move back to ax , which requires the pre-condition vin
x
l , j ∈ [1..n − 1] and l ∈ {1, 2}, to be in a . When v 1 moves again it is from b
variables vij
x
x
in
2
to a0 , requiring vi(n−1) = b0 as a pre-condition.
1 is in b following the (n−j +1)We see that, as long as the clause remains unsatisfied, vij
x
1 is in b following the last bit. Assume now that the
th bit. In particular, this means vi1
x
2 moves from b to a , this requires v 1 to
(n − j + 1)-th bit satisfies clause Ci . When vij
0
x
ij
1
move to ax instead of bx . From there, there is no way for vi(j−1)
to be in bx following the
1 will be in a following the last bit, satisfying the goal
(n − j + 2)-th bit. In particular, vi1
x
state.
5.2 Formal Proof
The proof for C5n is organized much in the same way as that for C11
n . Note that variables
s1 , . . . , s2n−1 , vs , ve , e1 , . . . , e2n−1 are the same as before, so Lemmas 4.2 and 4.6 still apply
to P5 (F ). It is easy to check that Lemmas 4.3, 4.5 and 4.8 also hold for P5 (F ). However,
Lemma 4.4 no longer holds, since several operators share the same preconditions, namely
operators (2) and (3), (5) and (6), (8) and (10), and (11) and (13). In spite of this, the
operators and sequences of values of an admissible plan Π are completely determined by its
induced message mΠ , just as for P11 (F ) (as shown in Lemma 4.10):
Lemma 5.1. Let Π be an admissible plan for P5 (F ) and let mΠ be its induced message. The
l , i ∈ [1..k], j ∈ [1..n], and l ∈ {1, 2},
operators in Π for changing the value of variable vij
l takes on during the execution of Π, are
as well as the sequence of values that variable vij
completely determined by mΠ .
1 , and assume without loss of generality that its value is a .
Proof. First consider variable v11
0
1 , namely (2), changing its value to
Given (vs = x), there are two applicable operators for v11

693

Giménez & Jonsson

ax , and (3), changing its value to bx . At first sight, an admissible plan Π can choose either.
2 in between each pair of
However, for Π to be admissible, it has to change the value of v11
1 . Note that when v 1 = a , v 2 can have either of two values, namely
value changes for v11
0
11
11
2 is a , the only admissible operator for v 2 is (12), which has
a0 or b0 . If the value of v11
0
11
1 = a . Thus, if Π changes the value of v 1 to b it is no longer admissible,
pre-condition v11
x
x
11
2 is b , the correct choice depends on the
so it has to choose operator (2). If the value of v11
0
2 is (16) with
CNF formula F . If xn satisfies clause C1 , the only admissible operator for v11
1 = a , so Π should choose operator (2). Otherwise, the only admissible
pre-condition v11
x
2
1 = b , so Π should choose operator (3). In
operator for v11 is (17) with pre-condition is v11
x
2 .
1
either case, the operator choice for v11 is forced given the value of v11
1 , i ∈ [2..k], v 1 , i ∈ [1..k] and j ∈ [2..k],
The same reasoning applies to variables vi1
ij
2 , i ∈ [1..k] and j ∈ [1..n − 1], and the corresponding operators that share the same
and vij
pre-conditions. The only degree of freedom of an admissible plan is selecting its induced
message mΠ by choosing the operators for vs accordingly. The remaining operator choices
and, consequently, sequences of values are completely determined by the induced message
mΠ .
We now prove a lemma similar to Lemma 4.13, establishing the sequence of values taken
on by state variables in P5 (F ) during the execution of an admissible plan.
Definition 5.2. Let Π be an admissible plan for P5 (F ). For each clause Ci and each
t ∈ [1..2n + 1], let the sequence of values Qti (Π) be the vector of 2n elements representing,
l , j ∈ [1..n] and l ∈ {1, 2}, the t-th value taken on by variable v l during
for each variable vij
ij
l ]. We define the diagonal value
the execution of Π. Let us denote this value by Qt (Π)[vij
1
qji (Π), for i ∈ [1..k] and j ∈ [1..n], as the value Q2j+1 (Π)[vi(n−j+1)
].
Lemma 5.3. Let σ be an assignment to variables x1 , . . . , xn of formula F .
1) Existence. There exists an admissible plan Π of planning problem P5 (F ) with induced
assignment σΠ = σ.
2) Claim. Let qji be as described in Part 3) of this lemma. All admissible plans Π with
σΠ = σ have the same diagonal values qji (Π) = qji for each i ∈ [1..k] and j ∈ [1..n].
3) Diagonal values. The diagonal values qji , for i ∈ [1..k] and j ∈ [1..n], are as
follows.
a) If j < Ti , then qji = bx .
b) If j ≥ Ti , then qji = ax .
Proof. Note that, according to Lemma 5.1, not only the diagonal values qji (Π), but also the
full sequences of values Qti (Π), are completely determined for an admissible plan Π. We
have to prove, then, that admissible plans exist for any assignment σ, as claimed in Part 1,
and that the diagonal values match the expression given in Part 3. We prove these two facts
by doing a careful, general analysis of the planning problem P5 (F ), and then explaining
how this analysis implies the lemma. Incidentally, the sequences of values Qti (Π) can also
694

Chain Causal Graphs with Domains of Size 5

be obtained from our analysis; we do not study them because they are not important for
our purposes.
l be some variable of P (F ). Clearly, the
Let Π be an admissible plan, and let v = vij
5
t
subscript of the t-th value Q (Π)[v] that v takes on depends on the parity of t, since all
operators affecting v change its subscript from x to m = {0, 1} and from there back to x.
Namely, the subscript of Qt (Π)[v] is x if t = 2p − 1, and m if t = 2p, where m is the p-th
bit of the message mΠ .
1,
Now, for some j ∈ [2..n − 1] and i ∈ [1..k], consider the t-th values that variables vij
2 , v1
vij
i(j+1) take on, for t = 2p − 1, 2p, 2p + 1. The previous observation on the subscripts
implies that we (trivially) know something about these values.
1 ] Qt (Π)[v 2 ] Qt (Π)[v 1
Qt (Π)[vij
ij
i(j+1) ]
t = 2p − 1 {ax , bx }
ax
{ax , bx }
t = 2p
am
{am , bm }
am
t = 2p + 1 {ax , bx }
ax
{ax , bx }
1
] affects the other values on the diagonal,
We study how the value Q2p−1 (Π)[vi(j+1)
2p−1
1
2p+1
1
2p
2
(Π)[vi(j+1)
] = ax , then we can check there
(Π)[vij ]. If Q
namely Q (Π)[vij ] and Q
is only one possible outcome.
1
2]
1]
Rule I
]
Qt (Π)[vi(j+1)
Qt (Π)[vij
Qt (Π)[vij
t = 2p − 1 {ax , bx }
ax
ax
t = 2p
am
am
(11)
am
(7)
t = 2p + 1
ax
(8)
ax
(12)
{ax , bx }

That is, a value of type ax is propagated along the diagonal to another value ax . We
call this Propagation Rule I.
1
] = bx . In this
Now we study which are the possible outcomes when Q2p−1 (Π)[vi(j+1)
2p
2
2p+1
1
case, the other values Q (Π)[vij ] and Q
(Π)[vij ] on the diagonal depend on whether
the p-th bit m of the message mΠ is such that clause Ci is satisfied by xn−j+1 = m (c.f.
operators (14)–(17) and (18)–(22) in Table 6). If Ci is satisfied by xn−j+1 = m, it follows
that these values must be bm and ax . This is Propagation Rule II.
1]
2]
1
Rule II
Qt (Π)[vij
Qt (Π)[vij
Qt (Π)[vi(j+1)
]
t = 2p − 1 {ax , bx }
ax
bx
am
bm
(13)
am
(9)
t = 2p
t = 2p + 1
ax
(8)
ax
(14, 16)
{ax , bx }

On the contrary, if clause Ci is not satisfied, then these values must be bm and bx . We
call this Propagation Rule III.
1
2]
1]
Rule III Qt (Π)[vij
Qt (Π)[vi(j+1)
]
Qt (Π)[vij
t = 2p − 1 {ax , bx }
ax
bx
t = 2p
am
bm
(13)
am
(9)
t = 2p + 1
bx
(10)
ax
(15, 17)
{ax , bx }

695

Giménez & Jonsson

Finally, let us consider the cases j = 1 and j = n, which have not been treated in the
2 do not have values of type a . Also note that
previous analysis. Note that variables vin
m
1 cannot take on value b at time t < 2n + 1, for then it cannot change further,
variables vi1
x
since the pre-conditions of operators (1)–(3), if i = 1, or (4)–(6), if i ∈ [2..k], are not
1 = b . Thus, the only possible outcome for these two variables when
compatible with vi1
x
p < n is the following.
1
2 ]
1 ]
]
Qt (Π)[v(i+1)1
Qt (Π)[vin
Qt (Π)[vin
t = 2p − 1 {ax , bx }
ax
ax
t = 2p
am
bm
(18)
am
(4)
ax
(19, 21; 20, 22)
ax
(5)
t = 2p + 1 {ax , bx } (8; 10)
1
] can be either ax or bx , using operators
Note that, when p = n, the value Q2p+1 (Π)[v(i+1)1
1 , where
(5) and (6). The reader can check that a similar analysis applies to variable v11
operators (1)–(3) take the role of operators (4)–(6).
Let us summarize the previous analysis in the following table.

t=1
t=2
t=3
t=4
..
.

1
2
1
vi1
vi1
vi2
···
ax ax ax · · ·
am
ax
am
..
.

t = 2n − 2 am
t = 2n − 1 ax
t = 2n
am
t = 2n + 1 ∗

∗

···

1 v2
2
1
vin
vi(n−1)
vi(n−1)
in
ax
ax ax ax
bm
ax
bm
..
.

∗

bm
ax
bm
∗ ax

The first row in the previous table contains the initial state of the planning problem: all
variables are set to ax . The leftmost column and the rightmost column contain the values
1 and v 2 . Then, the values b of the right column are propagated
taken on by variables vi1
m
in
along the diagonals using the three propagation rules already discussed: a value of type a
yields more values of type a according to Rule I; a value of type b yields a value of type
a if the clause is satisfied by Rule II, and of type b if it is not satisfied, by Rule III. The
same applies when propagating the values of the first row: since they are all of type a, all
values of the top-left triangle are of type a, according to Rule I. Note also that the longest
diagonal coincides with the diagonal values qji of Definition 5.2.
After this discussion we proceed to prove the lemma. Let σ be an assignment of formula
F . The existence of a plan Π with σΠ = σ is implied from the analysis already done on the
l ], since we have shown which operators can be used in each case to produce
values Qt [vij
the actual changes of value.
1 ],
Finally, consider the diagonal values qji (Π) for j = 1, . . . , n, that is, the values Q3 (Π)[vin
5
1
2n+1
1
Q (Π)[vi(n−1) ], . . ., Q
(Π)[vi1 ]. Let j < Ti as in Case (a), that is, the first j bits of the
message mΠ , when assigned to variables x1 , . . . , xj , do not satisfy clause Ci . Consequently,
i
2j+1 (Π)[v 1
1 ], q i = Q5 (Π)[v 1
the diagonal values q1i = Q3 (Π)[vin
2
i(n+1−j) ] must
i(n−1) ], . . ., qj = Q
696

Chain Causal Graphs with Domains of Size 5

all be bx , according to Rule III. On the contrary, if we assume j ≥ Ti as in Case (b), then
it follows that qpi = bx for p < Ti due to Rule III, that qpi = ax for p = Ti due to Rule II,
and that qpi = ax for j ≥ p > Ti due to Rule I.
Theorem 5.4. There exists a valid plan for solving the planning problem P5 (F ) if and only
if there exists an assignment σ that satisfies the CNF formula F .
Proof. ⇐: By Lemma 5.3, the existence of an assignment σ that satisfies F implies that all
admissible plans Π with σΠ = σ satisfy qji (Π) = qji . Since Ti ≤ n for all i ∈ [1..k], it follows
that qni = ax , as required by the goal state of P5 (F ). The plan Π thus solves P5 (F ).
⇒: Let Π be a plan solving the planning problem P5 (F ). Since Lemma 4.8 holds
for P5 (F ), the plan Π is admissible. We show by contradiction that σ = σΠ satisfies F .
Assume not. Then there exists a clause Ci not satisfied by σ. Thus, Lemma 5.3 implies that
1 following the execution of Π is b .
qji (Π) = bx for all j ∈ [1..n]. In particular, the value of vi1
x
1)=a .
This contradicts Π solving P5 (F ), since bx is different from the goal state goal(vi1
x
Proposition 5.5. Plan existence for C5n is NP-hard.
Proof. The largest variable domains of the planning problem P5 (F ) are those of variables
2 , i ∈ [1..k] and j ∈ [1..n − 1], which contain 5 values. The proof follows immediately
vij
from the NP-hardness of Cnf-Sat, Theorem 5.4, and the fact that we can produce the
planning problem P5 (F ) in polynomial time given the CNF formula F .

6. Discussion
In this paper, we have shown that the problem of determining whether a solution plan exists
for planning problems in the class Ckn is NP-hard whenever k ≥ 5. In contrast, Brafman
and Domshlak (2003) developed a polynomial-time algorithm for generating plans that solve
planning problems in the class C2n . What can be said about the intermediate cases, namely
Ckn for k ∈ {3, 4}? In what follows, we sketch some arguments for and against tractability
of these cases. Although the discussion is mostly based on intuition gained from studying
these classes, it might prove helpful for someone trying to determine their complexity.
On one hand, it seems likely to us that plan existence for C4n is also NP-hard. Our
reduction for C5n only uses one type of state variable whose domain is larger than 4, namely
2 . Finding a reduction for C4 seems possible, although it will likely be difficult since the
vij
n
available options become increasingly restricted as the state variable domains get smaller.
In particular, we tried but failed to find a reduction for C4n .
Domshlak and Dinitz (2001) showed that there exist planning problems in C3n with
exponential length minimal solutions. Although this often indicates that a planning class
is difficult, it does not imply that plan existence is intractable. This is exemplified by
Jonsson and Bäckström (1998) who define a class of planning problems with exponential
length minimal solutions but where plan existence could be checked in polynomial time.
The present authors (Giménez & Jonsson, 2008a) showed that even plan generation for
this particular class could be done in polynomial time, if the resulting plans are given in a
compact format such as macros.
A second argument in favor of the hardness of C3n is that there may be multiple ways
to transition between two values of a variable. For example, consider a planning problem
697

Giménez & Jonsson

such that there are two actions for changing the value of a variable v from 0 to 1, namely
a = hv ′ = 0, v = 0; v = 1i and a′ = hv ′ = 1, v = 0; v = 1i. Since variables can have 3 values,
it is possible that neither v ′ = 0 nor v ′ = 1 hold in the current state. A planner would
thus have to choose whether to satisfy v ′ = 0 or v ′ = 1. In contrast, for C2n the same two
actions could be replaced by a single action hv = 0; v = 1i since one of a and a′ is always
applicable. As a consequence, even if the minimal plan length is bounded for a planning
problem in C3n , there may be exponentially many plans of that length (in fact, this is the
main idea behind our reductions).
Another observation regards the number of possible domain transition graphs for each
state variable. For each k ≥ 2, it is possible to show that a state variable in Ckn may have
2
2k (k−1) distinct domain transition graphs. In other words, the number of graphs grows
exponentially in k. In particular, while state variables in C2n can only have 24 = 16 distinct
graphs, the same number for C3n is 218 . Although a large number of possibilities does not
guarantee hardness, it is clear that the expressive power of C3n is much higher than that of
C2n .
The evidence provided above suggests that C3n is significantly harder than C2n . However,
we are not sure that C3n is hard enough to be intractable. State variables with just three
values do not lend themselves well to the type of reduction we have presented, since just
propagating the message requires three values. If there is such a reduction for C3n , the idea
underlying it may not be the message-passing mechanism we have exploited. On the other
hand, maybe there is some way to determine plan existence of C3n in polynomial time. Such
an algorithm would take into consideration the multiple (but finite) combinations of domain
transition graphs of three values, as well as any inherent structure of the graphs. We know
that the expressive power of domain transition graphs of 5 values is just too large to handle
in polynomial time; maybe this is not the case when using just 3 values.

Acknowledgments
This work was partially funded by APIDIS and MEC grant TIN2006-15387-C03-03.

Appendix A. C7n Is NP-hard
In this appendix, we describe how to modify the reduction for C11
n so that the resulting
planning problem, which we call P7 (F ), only needs variable domains of size 7. This reduction previously appeared in a conference paper (Giménez & Jonsson, 2008b), but without
proof. The main idea of the reduction is the same, but the construction used to check
if the assignment σΠ satisfies a clause Ci is more involved. Previously, we used n variables {vij }j∈[1 . . n] whose role was, essentially, to check whether the j-th bit σΠ (xj ) of the
propagated message satisfies Ci . In the modified reduction, each variable vij is replaced
1 , v 2 , and v 3 , that collectively play the same role. The variables
by three variables vij
ij
ij
s1 , . . . , s2n−1 , vs , ve , e1 , . . . , e2n−1 , as well as their domains and corresponding operators, are
3 .
the same as before, except the predecessor of ve is now vkn
1 ) = D(v 3 ) = {a , a , a , b , b , b , g } and
The domains of these new variables are D(vij
x 0 1 x 0 1 x
ij
2
D(vij ) = {gx , g0 , g1 , ax , a0 , a1 , bx } for each i ∈ [1..k], j ∈ [1..n]. The initial state on these
1 ) = init(v 2 ) = init(v 3 ) = a , i ∈ [1..k] and j ∈ [1..n], and the goal
variables is init(vij
x
ij
ij
698

Chain Causal Graphs with Domains of Size 5

Variable
1
v11

1,
vi1
i ∈ [2..k]

1,
vij
i ∈ [1..k],
j ∈ [2..n]

Ref.
(1)
(2)
(3)
(4)
(5)
(6)
(7)
(1)
(2)
(3)
(4)
(5)
(6)
(7)
(8)
(9)
(10)
(11)
(12)
(13)
(14)
(15)
(16)
(17)

Operator
1 = a ; v1 = g i
hvs = 1, v11
x
x 11
1 = a ; v1 = b i
hvs = 1, v11
x 11
1
1 = a ; v1 = g i
hvs = 0, v11
x
x 11
1 = a ; v1 = b i
hvs = 0, v11
x 11
0
1 = g ; v1 = b i
hvs = m, v11
x 11
m
1 = b ; v1 = b i
hvs = m, v11
x 11
m
1 = b ; v1 = b i
hvs = x, v11
m 11
x
3
1 = a ; v1 = g i
hv(i−1)n
∈ {a1 , b1 }, vi1
x
x i1
1 = a ; v1 = b i
3
∈ {a1 , b1 }, vi1
hv(i−1)n
x i1
1
1
1
3
hv(i−1)n ∈ {a0 , b0 }, vi1 = ax ; vi1 = gx i
3
1 = a ; v1 = b i
hv(i−1)n
∈ {a0 , b0 }, vi1
x i1
0
3
1 = g ; v1 = b i
hv(i−1)n
∈ {am , bm }, vi1
x i1
m
3
1 = b ; v1 = b i
hv(i−1)n
∈ {am , bm }, vi1
x i1
m
1
1
3
hv(i−1)n ∈ {ax , bx }, vi1 = bm ; vi1 = bx i
3
1 = a ; v1 = g i
hvi(j−1)
= b1 , vij
x ij
x
1
1
3
hvi(j−1) = b1 , vij = ax ; vij = b1 i
3
1 = a ; v1 = g i
hvi(j−1)
= b0 , vij
x ij
x
1 = a ; v1 = b i
3
= b0 , vij
hvi(j−1)
x ij
0
3
1 = a ; v1 = g i
hvi(j−1)
= gx , vij
x ij
x
1
1
3
hvi(j−1) = am , vij = ax ; vij = am i
3
1 = g ; v1 = b i
hvi(j−1)
= bm , vij
m
x ij
3
1 = b ; v1 = b i
hvi(j−1) = bm , vij
x ij
m
3
1 = a ; v1 = a i
hvi(j−1)
∈ {ax , bx }, vij
x
m ij
1 = b ; v1 = b i
3
= bx , vij
hvi(j−1)
m ij
x

Qualifier
x1 ∈ C1
x1 ∈
/ C1
x1 ∈ C1
x1 ∈
/ C1
m ∈ {0, 1}
m ∈ {0, 1}
m ∈ {0, 1}
x1 ∈ Ci
x1 ∈
/ Ci
x1 ∈ Ci
x1 ∈
/ Ci
m ∈ {0, 1}
m ∈ {0, 1}
m ∈ {0, 1}
xj ∈ Ci
xj ∈
/ Ci
xj ∈ Ci
xj ∈
/ Ci
m ∈ {0, 1}
m ∈ {0, 1}
m ∈ {0, 1}
m ∈ {0, 1}
m ∈ {0, 1}

1 , i ∈ [1..k] and j ∈ [1..n].
Table 7: Operators for variables vij

2 ) = g , i ∈ [1..k]. Table 7 shows the operators for variables v 1 , i ∈ [1..k]
state is goal(vin
x
ij
2 and v 3 , i ∈ [1..k] and
and j ∈ [1..n], and Table 8 shows the operators for variables vij
ij
j ∈ [1..n]. Figures 7 and 8 shows the corresponding domain transition graphs. Table 8 also
shows the new operators for variable ve , which have different pre-conditions now that the
3 .
predecessor of ve is vkn

A.1 Intuition
The intuition behind the reduction for C7n is largely the same as that for C11
n . The planning
problem P7 (F ) corresponding to a CNF formula F consists of three parts, the first and
third being identical to those of P11 (F ). Thus, the difference lies in the second part. Recall
that in the reduction for C11
n , for each clause Ci and each variable xj of F , the planning
problem P11 (F ) contains a state variable vij that performs the following functions:
1. Propagate the message m generated by vs .
699

Giménez & Jonsson

Variable
2,
vij
i ∈ [1..k],
j ∈ [1..n]

Ref.
(18)
(19)
(20)
(21)
(22)
(23)
(24)
(25)
(26)
(27)
(28)
(29)
(30)
(31)

3,
vij
i ∈ [1..k],
j ∈ [1..n]

ve

Operator
1 ∈ {a , b }, v 2 = a ; v 2 = a i
hvij
m m
x ij
m
ij
1 = g , v2 = a ; v2 = g i
hvij
x
x ij
x ij
1 = b , v2 = g ; v2 = g i
hvij
m ij
x ij
m
1 = b , v2 = b ; v2 = a i
hvij
m
x ij
m ij
1 = a , v2 = a ; v2 = a i
hvij
x ij
m ij
x
1 = b , v2 = a ; v2 = b i
hvij
x
m ij
x ij
1 = b , v2 = g ; v2 = g i
hvij
x ij
m ij
x
2 = a , v3 = a ; v3 = a i
hvij
m ij
x ij
m
2 = g , v3 = a ; v3 = g i
hvij
x
x ij
x ij
2 = g , v3 = g ; v3 = b i
hvij
m ij
x ij
m
2 ∈ {a , g }, v 3 = b ; v 3 = b i
hvij
m
x ij
m m
ij
2 = a , v3 = a ; v3 = a i
hvij
x ij
m ij
x
3
3
2
hvij = bx , vij = am ; vij = bx i
2 ∈ {b , g }, v 3 = b ; v 3 = b i
hvij
x
x x
m ij
ij
3
hvkn ∈ {a0 , a1 , b0 , b1 }, ve = 0; ve = 1i
3 ∈ {a , b }, v = 1; v = 0i
hvkn
x x
e
e

Qualifier
m ∈ {0, 1}
m ∈ {0, 1}
m ∈ {0, 1}
m ∈ {0, 1}
m ∈ {0, 1}
m ∈ {0, 1}
m ∈ {0, 1}
m ∈ {0, 1}
m ∈ {0, 1}
m ∈ {0, 1}
m ∈ {0, 1}
m ∈ {0, 1}

2 , v 3 , and v , i ∈ [1..k] and j ∈ [1..n].
Table 8: Operators for variables vij
e
ij

(a)

(b)

(c)

b0

b0

a0

0
ax

0

0
bx

gx
1

x

ax
1

1

a0
a0,b0 b0

a0,b0

x

gx

a1, b1

a1, b1

ax
bx

b0

bx

ax

gx

a1
b1

ax
bx

b1
ax,bx

b1

b0
ax,bx

a0

b1

b0

b0

bx
bx

gx
b1

bx

b1

a1
a1

b1

1 , (b) v 1 for i ∈ [2..k], (c) v 1 for i ∈ [1..k], j ∈ [2..n].
Figure 7: DTGs of (a) v11
ij
i1

2. Check whether the assignment to xj (the j-th bit of m) satisfies the clause Ci .
3. Remember whether Ci was satisfied by the assignment to some xl , l ≤ j.
4. If j < n and Ci has been satisfied, propagate this fact.
5. If j < n, let vi(j+1) know when the (j + 1)-th bit of the message has arrived.
The first and fourth function is to propagate information and thus has to be performed
by all state variables if information is not to be lost. However, the other functions can be
performed by different state variables. The idea behind the reduction for C7n is to split vij
1 , that performs the second function, v 2 , that performs the third,
into three variables: vij
ij
3
and vij , that performs the fifth.
700

Chain Causal Graphs with Domains of Size 5

(a)

(b)
a0

g0
b0

a0
bx

bx
a0,b0
gx

gx

g1

b0

ax

bx

ax
a1,b1

b1

bx

ax

a1

a0

ax

b0

bx

g0
a0,g0

ax

bx

gx

bx,gx
bx

gx
bx,gx

ax

b1

a1
a1

bx

a1,g1

g1
b1

2 and (b) v 3 for i ∈ [1..k], j ∈ [1..n].
Figure 8: DTGs of (a) vij
ij

Just as before, the message m is propagated using the subscripts of values in the domains
1 moves
of state variables. When the j-th bit mj of the message arrives, state variable vij
1 moves
from ax to gx if the assignment σ(xj ) = mj satisfies Ci , and to bmj otherwise. If vij
to gx , it is forced to move to bmj next, forgetting that Ci was satisfied. However, while the
1 is g , all subsequent state variables for C can also move to g , propagating the
value of vij
x
i
x
2 is able to remember that
fact that Ci has been satisfied. Consequently, state variable vin
Ci has been satisfied by remaining within the subdomain {g0 , g1 , gx }.
1 moves to b , causing v 2 and v 3 to move to a .
If σ(xj ) = mj does not satisfy Ci , vij
mj
mj
ij
ij
1
3
2
1
From there, vij , vij , and vij all move to bx . When the next bit arrives, vij moves to b0 (b1 ),
2 to move to a (a ) and v 3 to b (b ). This indicates to v 1
causing vij
0
1
0
1
ij
i(j+1) that the (j + 1)-th
bit has arrived, causing it to act accordingly. Just as before, the operators are defined such
1 always reacts to the first bit for each clause C .
that vi1
i
A.2 Formal Proof
Since variables s1 , . . . , s2n−1 , vs , ve , e1 , . . . , e2n−1 are the same as before, Lemmas 4.2 and
4.6 both apply to P7 (F ). However, Lemma 4.3 is violated since it is sometimes possible
to change the value of a variable twice without changing the value of its predecessor (e.g.
using operators (1) and (5)). Consequently, Lemma 4.8, which states that all plans that
solve P11 (F ) are admissible, no longer holds for P7 (F ).
l ) for variables in the middle of
To prove equivalent lemmas for P7 (F ), we redefine Π(vij
the causal graph:
l , i ∈ [1..k], j ∈ [1..n], and
Definition A.1. Given a partial plan Π and variable vij
l ) be the number of subscript changes of v l during the execution of Π.
l ∈ {1, 2, 3}, let Π(vij
ij
l , i ∈ [1..k], j ∈ [1..n], and
Lemma A.2. For each partial plan Π for P7 (F ) and each vij
l ) ≤ Π(v ′ ), where v ′ is the predecessor of v l in the causal
l ∈ {1, 2, 3}, it holds that Π(vij
ij
graph.
l . Each operator that
Proof. Follows immediately from inspection of the operators for vij
l
changes the subscript of vij to z ∈ {0, 1, x} has a pre-condition on v ′ with subscript z (or
1 and its predecessor v ). There are operators for changing the value
value z in the case of v11
s
1 to g that have a pre-condition on v ′ with a subscript (or value) different from x, but
of vij
x
1 since their pre-condition on v 1 is a .
these operators do not change the subscript of vij
x
ij

701

Giménez & Jonsson

3 ).
Lemma A.3. For each partial plan Π for P7 (F ), Π(ve ) ≤ Π(vkn
3 ) denotes
Proof. Note that Π(ve ) still denotes the number of value changes of ve , while Π(vkn
3 . Each time we change the value of v we need to
the number of subscript changes of vkn
e
3
change the subscript of vkn in between. In addition, the first value change of ve requires a
3 different from that in the initial state. Thus, Π(v ) ≤ Π(v 3 ).
subscript for vkn
e
kn

Definition A.4. An admissible plan Π for planning problem P7 (F ) is a partial plan such
1 ) = . . . = Π(v 3 ) = Π(v ) = 2n, and Π(e ) = 2n − i, for each
that Π(si ) = i, Π(vs ) = Π(v11
e
i
kn
i ∈ [1..2n − 1].
Lemma A.5. Any plan Π that solves the planning problem P7 (F ) is admissible.
1 ) ≥ · · · ≥ Π(v 3 ) ≥ Π(v ). We
Proof. By Lemmas A.2 and A.3 we have that Π(vs ) ≥ Π(v11
e
kn
can now use Lemmas 4.2 and 4.6 and apply the same reasoning as in the proof of Lemma
4.8.
l exactly 2n
In other words, an admissible plan has to change the subscript of each vij
l an extra time by moving through g . However,
times, although it can change the value of vij
x
l ), we cannot prove an equivalent of Lemma 4.10 for
even with the new definition of Π(vij
l , l ∈ {1, 2}, can choose not to follow its predecessor to g without
P7 (F ), since a variable vij
x
making the plan inadmissible. Consequently, the sequences of values Qti (Π) of an admissible
plan Π are no longer completely determined by the induced message mΠ . Nevertheless, we
can still prove a lemma similar to Lemma 4.13.

Definition A.6. Let Π be an admissible plan. For each clause Ci and each t ∈ [1..2n + 1],
let the sequence of values Qti (Π) be the vector of 3n elements representing, for each variable
l , j ∈ [1..n] and l ∈ {1, 2, 3}, the first value following the (t − 1)-th subscript change of
vij
l during the execution of Π.
vij
Lemma A.7. Let σ be an assignment of variables x1 , . . . , xn of formula F .
1) Existence. There exists an admissible plan Π of planning problem P7 (F ) with induced
assignment σΠ = σ.
2) Claim. Let Qti be the sequences of values described in Part 3) of this lemma. If σ
satisfies F , then there exists an admissible plan Π with σΠ = σ such that Qti (Π) = Qti ,
for all t ∈ [1..2n+1] and i ∈ [1..k]. If σ does not satisfy clause Ci , then all admissible
plans Π with σΠ = σ have Qti (Π) = Qti , for all t ∈ [1..2k + 1].
3) Sequence of values. The sequence of values Qti , for i ∈ [1..k] and t ∈ [1..2n + 1],
is as follows.
a) If j < Ti , then
j−1

Qi2j−1
Q2j
i
Q2j+1
i

n−j
}|
{
z
z
}|
{
bx bx bx · · · bx bx bx
ax ax ax
ax ax ax · · · ax ax ax
=
= bm am bm · · · bm am bm bm am am am am am · · · am am am
=
bx bx bx · · · bx bx bx
bx bx bx
ax ax ax · · · ax ax ax

702

Chain Causal Graphs with Domains of Size 5

b) If j = Ti , then
j−1

Qi2j−1
Q2j
i
2j+1
Qi

n−j
z
}|
{
z
}|
{
=
bx bx bx · · · bx bx bx
ax ax ax
ax ax ax · · · ax ax ax
= bm am bm · · · bm am bm bm gm bm bm gm bm · · · bm gm bm
=
bx bx bx · · · bx bx bx
bx gx bx
bx gx bx · · · bx gx bx

c) If j > Ti , then
j−Ti

Ti −1

Qi2j−1
Q2j
i
2j+1
Qi

n−j

z
z
}|
{
}|
{
}|
{
z
bx gx bx · · · bx gx bx bx gx bx bx gx bx · · · bx gx bx
= bx bx bx · · · bx bx bx
= bm am bm · · · bm am bm bm gm bm · · · bm gm bm bm gm bm bm gm bm · · · bm gm bm
= bx bx bx · · · bx bx bx
bx gx bx · · · bx gx bx bx gx bx bx gx bx · · · bx gx bx

Proof. Note the similarity of this lemma with Lemma 4.13. As before, we must show that
there are operators, this time in Tables 7 and 8, whose post-conditions equal the values
2j+1
given by Qi2j−1 , Q2j
. Again, we must check for consistency in the statements
i and Qi
2j ′ +1
2j−1
′
with j = j − 1. This implies, as in Lemma 4.13, that the statements
and Qi
of Qi
for Qi2j−1 are valid, due to the initial state being ax · · · ax and by induction on j. It just
2j+1
remains to show that the statements for Q2j
are also valid.
i and Qi
The proof is divided into the same six parts as that of Lemma 4.13. Note that, in
contrast to that lemma, here we aim to show that, when σ satisfies F , there exists an
admissible plan with given Qti , not that all admissible plans have this form. This is because
sometimes during the execution of the plan more than one operator could have been chosen,
and the resulting plan would still be admissible. In the tables that follow, which are alike
to those in the proof of Lemma 4.13, we only indicate the operator choice that leads to the
desired Qti , and we use boldface to remark that these operators are not “forced”. We add
an extra row to the tables to indicate that sometimes we need to apply two operators for
each variable before changing its subscript. These disparities with respect to Lemma 4.13
only occur in parts II and IV of the proof, which require Ti ≤ n, that is, σ satisfying clause
Ci , for some fixed i. Thus, when σ does not satisfy clause Ci , all admissible plans Π have
the same sequences of values Qti for each t ∈ [1..2n + 1].
I) 1 = j < Ti .
1 v2 v3
1 v 2 v 3 |k ∈ [2..n]
vi1
vik
i1 i1
ik ik
2j − 1 ax ax ax
ax ax ax
2j
bm am am (2, 4; 18; 25) am am am (13; 18; 25)
ax ax ax (16; 22; 29)
2j + 1 bx bx bx (7; 23; 30)

II) 1 = j = Ti .
1 v2 v3
1 v 2 v 3 |k ∈ [2..n]
vi1
vik
i1 i1
ik ik
2j − 1 ax ax ax
ax ax ax
gx gx gx (1, 3; 19; 26)
gx gx gx (12; 19; 26)
2j
bm gm bm (5; 20; 27)
bm gm bm (14; 20; 27)
bx gx bx (7; 24; 31)
bx gx bx (17; 24; 31)
2j + 1

703

Giménez & Jonsson

III) 1 < j < Ti .
1 v 2 v 3 |k ∈ [1..j − 1] v 1 v 2 v 3
1 v 2 v 3 |k ∈ [j + 1..n]
vik
vik
ij ij ij
ik ik
ik ik
2j − 1
b x bx bx
ax ax ax
ax ax ax
2j
bm am bm (6, 15; 21; 28) bm am am (9, 11; 18; 25) am am am (13; 18; 25)
bx bx bx (7, 17; 23; 31)
bx bx bx (17; 23; 30)
ax ax ax (16; 22; 29)
2j + 1

IV) 1 < j = Ti .
1 v 2 v 3 |k ∈ [1..j − 1] v 1 v 2 v 3
1 v 2 v 3 |k ∈ [j + 1..n]
vik
vik
ij ij ij
ik ik
ik ik
2j − 1
b x bx bx
ax ax ax
ax ax ax
bm am bm (6, 15; 21; 28) gx gx gx (8, 10; 19; 26)
gx gx gx (12; 19; 26)
2j
bm am bm
bm gm bm (14; 20; 27)
bm gm bm (14; 20; 27)
2j + 1
bx bx bx (7, 17; 23; 31)
bx gx bx (17; 24; 31)
bx gx bx (17; 24; 31)

V) 1 = Ti < j.
1 v 2 v 3 |k ∈ [2..n]
1 v2 v3
vik
vi1
i1 i1
ik ik
2j − 1
bx gx bx
bx gx bx
2j
bm gm bm (6; 20; 28) bm gm bm (15; 20; 28)
2j + 1
bx gx bx (7; 24; 31)
bx gx bx (17; 24; 31)

VI) 1 < Ti < j.
1 v 2 v 3 |k ∈ [1..T − 1] v 1 v 2 v 3 |k ∈ [T ..n]
vik
i
i
ik ik
ik ik ik
2j − 1
bx bx bx
bx gx bx
2j
bm am bm (6, 15; 21; 28)
bm gm bm (15; 20; 28)
2j + 1
bx bx bx (7, 17; 23; 31)
bx gx bx (17; 24; 31)

Theorem A.8. There exists a plan that solves the planning problem P7 (F ) if and only if
there exists an assignment σ that satisfies the CNF formula F .
Proof. ⇐: Given an assignment σ that satisfies F , construct an admissible plan whose
induced formula assignment σΠ equals σ, by choosing the sequence of values of vs accordingly. It follows that for each clause Ci , Ti ≤ n, since there exists a variable xj such that
σΠ (xj ) = mj satisfies Ci . Since n ≥ Ti , there exists an admissible plan Π for which Qi2n+1
has the form indicated in Case (b) or (c) of Lemma A.7. In either case, the (2n + 1)-th
2 is g , as required by the goal state. The plan Π thus solves P (F ).
value of variable vin
x
7
⇒: Let Π be a plan that solves the planning problem P7 (F ). By Lemma A.5 the plan
Π is admissible. We show by contradiction that σ = σΠ satisfies F . Assume not. Then
there exists a clause Ci not satisfied by σ. Thus, Lemma A.7 applies to the sequence of
2 following the execution
values Q2n+1
of Π. In particular, this means that the value of vin
i
of Π is bx according to Case (a) of the lemma. This contradicts Π solving P7 (F ), since bx
2 )=g .
is different from the goal state goal(vin
x
Proposition A.9. Plan existence for C7n is NP-hard.
704

Chain Causal Graphs with Domains of Size 5

Proof. The largest variable domains of the planning problem P7 (F ) are those of variables
1 , . . . , v 3 , which contain 7 values. The proof follows immediately from the NP-hardness
v11
kn
of Cnf-Sat, Theorem A.8, and the fact that we can produce the planning problem P7 (F )
in polynomial time given a CNF formula F .

References
Brafman, R., & Domshlak, C. (2003). Structure and Complexity in Planning with Unary
Operators. Journal of Artificial Intelligence Research, 18, 315–349.
Brafman, R., & Domshlak, C. (2006). Factored Planning: How, When, and When Not. In
Proceedings of the 21st National Conference on Artificial Intelligence, pp. 809–814.
Bylander, T. (1994). The computational complexity of propositional STRIPS planning.
Artificial Intelligence, 69, 165–204.
Chapman, D. (1987). Planning for conjunctive goals. Artificial Intelligence, 32(3), 333–377.
Chen, H., & Giménez, O. (2008). Causal Graphs and Structurally Restricted Planning. In
Proceedings of the 18th International Conference on Automated Planning and Scheduling, pp. 36–43.
Domshlak, C., & Dinitz, Y. (2001). Multi-Agent Off-line Coordination: Structure and Complexity. In Proceedings of the 6th European Conference on Planning, pp. 277–288.
Erol, K., Nau, D., & Subrahmanian, V. (1995). Complexity, Decidability and Undecidability
Results for Domain-Independent Planning. Artificial Intelligence, 76(1-2), 75–88.
Giménez, O., & Jonsson, A. (2008a). The Complexity of Planning Problems with Simple
Causal Graphs. Journal of Artificial Intelligence Research, 31, 319–351.
Giménez, O., & Jonsson, A. (2008b). In Search of the Tractability Boundary of Planning
Problems. In Proceedings of the 18th International Conference on Automated Planning
and Scheduling, pp. 99–106.
Helmert, M. (2006). The Fast Downward Planning System. Journal of Artificial Intelligence
Research, 26, 191–246.
Jonsson, A. (2007). The Role of Macros in Tractable Planning Over Causal Graphs. In
Proceedings of the 20th International Joint Conference on Artificial Intelligence, pp.
1936–1941.
Jonsson, P., & Bäckström, C. (1998). Tractable plan existence does not imply tractable
plan generation. Annals of Mathematics and Artificial Intelligence, 22(3–4), 281–296.
Katz, M., & Domshlak, C. (2008a). New Islands of Tractability of Cost-Optimal Planning.
Journal of Artificial Intelligence Research, 32, 203–288.
Katz, M., & Domshlak, C. (2008b). Structural Patterns Heuristics via Fork Decompositions. In Proceedings of the 18th International Conference on Automated Planning
and Scheduling, pp. 182–189.
Knoblock, C. (1994). Automatically generating abstractions for planning. Artificial Intelligence, 68(2), 243–302.
705

Giménez & Jonsson

Williams, B., & Nayak, P. (1997). A reactive planner for a model-based executive. In
Proceedings of the 15th International Joint Conference on Artificial Intelligence, pp.
1178–1185.

706

Journal of Artificial Intelligence Research 34 (2009) 297-337

Submitted 06/08; published 03/09

Monte Carlo Sampling Methods for Approximating
Interactive POMDPs
Prashant Doshi

PDOSHI @ CS . UGA . EDU

Department of Computer Science
University of Georgia
415 Boyd GSRC
Athens, GA 30602

Piotr J. Gmytrasiewicz

PIOTR @ CS . UIC . EDU

Department of Computer Science
University of Illinois at Chicago
851 S. Morgan St
Chicago, IL 60607

Abstract
Partially observable Markov decision processes (POMDPs) provide a principled framework
for sequential planning in uncertain single agent settings. An extension of POMDPs to multiagent
settings, called interactive POMDPs (I-POMDPs), replaces POMDP belief spaces with interactive
hierarchical belief systems which represent an agent’s belief about the physical world, about beliefs
of other agents, and about their beliefs about others’ beliefs. This modification makes the difficulties of obtaining solutions due to complexity of the belief and policy spaces even more acute. We
describe a general method for obtaining approximate solutions of I-POMDPs based on particle filtering (PF). We introduce the interactive PF, which descends the levels of the interactive belief
hierarchies and samples and propagates beliefs at each level. The interactive PF is able to mitigate the belief space complexity, but it does not address the policy space complexity. To mitigate
the policy space complexity – sometimes also called the curse of history – we utilize a complementary method based on sampling likely observations while building the look ahead reachability
tree. While this approach does not completely address the curse of history, it beats back the curse’s
impact substantially. We provide experimental results and chart future work.

1. Introduction
Interactive POMDPs (I-POMDPs) (Gmytrasiewicz & Doshi, 2005; Seuken & Zilberstein, 2008)
are a generalization of POMDPs to multiagent settings and offer a principled decision-theoretic
framework for sequential decision making in uncertain multiagent settings. I-POMDPs are applicable to autonomous self-interested agents who locally compute what actions they should execute
to optimize their preferences given what they believe while interacting with others with possibly
conflicting objectives. Though POMDPs can be used in multiagent settings, it is so only under
the strong assumption that the other agent’s behavior be adequately represented implicitly (say, as
noise) within the POMDP model (see Boutilier, Dean, & Hanks, 1999; Gmytrasiewicz & Doshi,
2005, for examples). The approach adopted in I-POMDPs is to expand the traditional state space
to include models of other agents. Some of these models are the sophisticated intentional models,
which ascribe beliefs, preferences, and rationality to others and are analogous to the notion of agent
c
2009
AI Access Foundation. All rights reserved.

D OSHI & G MYTRASIEWICZ

types in Bayesian games (Harsanyi, 1967; Mertens & Zamir, 1985). Other models, such as finite
state machines, do not ascribe beliefs or rationality to other agents and we call them subintentional
models. An agent’s beliefs within I-POMDPs are called interactive beliefs, and they are nested
analogously to the hierarchical belief systems considered in game theory (Mertens & Zamir, 1985;
Brandenburger & Dekel, 1993; Heifetz & Samet, 1998; Aumann, 1999), in theoretical computer
science (Fagin, Halpern, Moses, & Vardi, 1995) and to the hyper-priors in hierarchical Bayesian
models (Gelman, Carlin, Stern, & Rubin, 2004). Since the interactive beliefs may be infinitely
nested, Gmytrasiewicz and Doshi (2005) defined finitely nested I-POMDPs as computable specializations of the infinitely nested ones. Solutions of finitely nested I-POMDPs map an agent’s states
of belief about the environment and other agents’ models to policies. Consequently, I-POMDPs
find important applications in agent, human, and mixed agent-human environments. Some potential
applications include path planning in multi-robot environments, coordinating troop movements in
battlefields, planning the course of a treatment in a multi-treatment therapy, and explaining commonly observed social behaviors (Doshi, Zeng, & Chen, 2007).
However, optimal decision making in uncertain multiagent settings is computationally very hard
requiring significant time and memory resources. For example, the problem of solving decentralized POMDPs has been shown to lie in the NEXP-complete class (Bernstein, Givan, Immerman, &
Zilberstein, 2002). Expectedly, exact solutions of finitely nested I-POMDPs are difficult to compute
as well, due to two primary sources of intractability: (i) The complexity of the belief representation which is proportional to the dimensions of the belief simplex, sometimes called the curse of
dimensionality. (ii) The complexity of the space of policies, which is proportional to the number of
possible future beliefs, also called the curse of history.
Both these sources of intractability exist in POMDPs also (see Pineau, Gordon, & Thrun, 2006;
Poupart & Boutilier, 2004) but the curse of dimensionality is especially more acute in I-POMDPs.
This is because in I-POMDPs the complexity of the belief space is even greater; the beliefs may
include beliefs about the physical environment, and possibly the agent’s beliefs about other agents’
beliefs, about their beliefs about others’, and so on. Thus, a contributing factor to the curse of
dimensionality is the level of belief nesting that is considered. As the total number of agent models
grows exponentially with the increase in nesting level, so does the solution complexity.
We observe that one approach to solving a finitely nested I-POMDP is to investigate collapsing the model to a traditional POMDP, and utilize available approximation methods that apply to
POMDPs. However, the transformation into a POMDP is not straightforward. In particular, it does
not seem possible to model the update of other agents’ nested beliefs as a part of the transition function in the POMDP. Such a transition function would include nested beliefs and require solutions
of others’ models in defining it, and thus be quite different from the standard ones to which current
POMDP approaches apply.
In this article, we present the first set of generally applicable methods for computing approximately optimal policies for the finitely nested I-POMDP framework while demonstrating computational savings. Since an agent’s belief is defined over other agents’ models, which may be a complex
infinite space, sampling methods which are able to approximate distributions over large spaces to arbitrary accuracy are a promising approach. We adopt the particle filter (Gordon, Salmond, & Smith,
1993; Doucet, Freitas, & Gordon, 2001) as our point of departure. There is growing empirical evidence (Koller & Lerner, 2001; Daum & Huang, 2002) that particle filters are unable to significantly
reduce the adverse impact of increasing state spaces. Specifically, the number of particles needed to
maintain the error from the exact state estimation increases as the number of dimensions increase.
298

M ONTE C ARLO S AMPLING M ETHODS FOR A PPROXIMATING I-POMDP S

However, the rate of convergence of the approximate posterior to the true one is independent of the
dimensions of the state space (Crisan & Doucet, 2002) under weak assumptions. In other words,
while we may need more particles to maintain error as the state space increases, the rate at which the
error reduces remains unchanged, regardless of the state space. Furthermore, sampling approaches
allow us to focus resources on the regions of the state space that are considered more likely in an
uncertain environment, providing a strong potential for computational savings.
We generalize the particle filter, and more specifically the bootstrap filter (Gordon et al., 1993),
to the multiagent setting, resulting in the interactive particle filter (I-PF). The generalization is not
trivial: We do not simply treat the other agent as an automaton whose actions follow a fixed and
known distribution. Rather, we consider the case where other agents are intentional – they possess beliefs, capabilities and preferences. Subsequently, the propagation step in the I-PF becomes
more complicated than in the standard PF. In projecting the subject agent’s belief over time, we
must project the other agent’s belief, which involves predicting its action and anticipating its observations. Mirroring the hierarchical character of interactive beliefs, the interactive particle filtering
involves sampling and propagation at each of the hierarchical levels of the beliefs. We empirically
demonstrate the ability of the I-PF to flexibly approximate the state estimation in I-POMDPs, and
show the computational savings obtained in comparison to a regular grid based implementation.
However, as we sample an identical number of particles at each nesting level, the total number of
particles and the associated complexity, continues to grow exponentially with the nesting level.
We combine the I-PF with value iteration on sample sets thereby providing a general way to
solve finitely nested I-POMDPs. Our approximation method is anytime and is applicable to agents
that start with a prior belief and optimize over finite horizons. Consequently, our method finds applications for online plan computation. We derive error bounds for our approach that are applicable
to singly-nested I-POMDPs and discuss the difficulty in generalizing the bounds to multiply nested
beliefs. We empirically demonstrate the performance and computational savings obtained by our
method on standard test problems as well as a larger uninhabited aerial vehicle (UAV) reconnaissance problem.
While the I-PF is able to flexibly mitigate the belief space complexity, it does not address the policy space complexity. In order to mitigate the curse of history, we present a complementary method
based on sampling observations while building the look ahead reachability tree during value iteration. This translates into considering only those future beliefs during value iteration that an agent
is likely to have from a given belief. This approach is similar in spirit to the sparse sampling
techniques used in generating partial look ahead trees for action selection during reinforcement
learning (Kearns, Mansour, & Ng, 2002; Wang, Lizotte, Bowling, & Schuurmans, 2005) and for
online planning in POMDPs (Ross, Pineau, Paquet, & Chaib-draa, 2008). While these approaches
were applied in single agent reinforcement learning problems, we focus on a multiagent setting
and recursively apply the technique to solve models of all agents at each nesting level. Observation sampling was also recently utilized in DEC-POMDPs (Seuken & Zilberstein, 2007), where it
was shown to improve the performance on large problems. We note that this approach does not
completely address the curse of history, but beats back its impact on the difficulty of computing
the I-POMDP solutions, substantially. We report on the additional computational savings obtained
when we combine this method with the I-PF, and provide empirical results in support.
Rest of this article is structured in the following manner. We review the various state estimation methods and their relevance, and the use of particle filters in previous works in Section 2. In
Section 3, we review the traditional particle filtering technique concentrating on bootstrap filters in
299

D OSHI & G MYTRASIEWICZ

particular. We briefly outline the finitely nested I-POMDP framework in Section 4 and the multiagent tiger problem used for illustration in Section 5. In Section 6, we discuss representations for the
nested beliefs and the inherent difficulty in formulating them. In order to facilitate understanding,
we give a decomposition of the I-POMDP belief update in Section 7. We then present the I-PF that
approximates the finitely nested I-POMDP belief update in Section 8. This is followed by a method
that utilizes the I-PF to compute solutions to I-POMDPs, in Section 9. We also comment on the
asymptotic convergence and compute error bounds of our approach. In Section 10, we report on
the performance of our approximation method on simple and larger test problems. In Section 11,
we provide a technique for mitigating the curse of history, and report on some empirical results.
Finally, we conclude this article and outline future research directions in Section 12.

2. Related Work
Several approaches to nonlinear Bayesian estimation exist. Among these, the extended Kalman filter (EKF) (Sorenson, 1985), is most popular. The EKF linearises the estimation problem so that the
Kalman filter can be applied. The required probability density function (p.d.f.) is still approximated
by a Gaussian, which may lead to filter divergence, and therefore an increase in the error. Other
approaches include the Gaussian sum filter (Sorenson & Alspach, 1971), and superimposing a grid
over the state space with the belief being evaluated only over the grid points (Kramer & Sorenson,
1988). In the latter approach, the choice of an efficient grid is non-trivial, and the method suffers
from the curse of dimensionality: The number of grid points that must be considered is exponential
in the dimensions of the state space. Recently, techniques that utilize Monte Carlo (MC) sampling
for approximating the Bayesian state estimation problem have received much attention. These techniques are general enough, in that, they are applicable to both linear, as well as, non-linear problem
dynamics, and the rate of convergence of the approximation error to zero is independent of the dimensions of the underlying state space. Among the spectrum of MC techniques, two that have been
particularly well-studied in sequential settings are Markov chain Monte Carlo (MCMC) (Hastings,
1970; Gelman et al., 2004), and particle filters (Gordon et al., 1993; Doucet et al., 2001). Approximating the I-POMDP belief update using the former technique, may turn out to be computationally
exhaustive. Specifically, MCMC algorithms that utilize rejection sampling (e.g. Hastings, 1970)
may cause a large number of intentional models to be sampled, solved, and rejected, before one
is utilized for propagation. In addition, the complex estimation process in I-POMDPs makes the
task of computing the acceptance ratio for rejection sampling computationally inefficient. Although
Gibbs sampling (Gelman et al., 2004) avoids rejecting samples, it would involve sampling from a
conditional distribution of the physical state given the observation history and model of other, and
from the distribution of the other’s model given the physical state. However, these distributions are
neither efficient to compute nor easy to derive analytically. Particle filters need not reject solved
models and compute a new model in replacement, propagating all solved models over time and
resampling them. They are intuitively amenable to approximating the I-POMDP belief update and
produce reasonable approximations of the posterior while being computationally feasible.
Particle filters previously have been successfully applied to approximate the belief update in
continuous state space single agent POMDPs (Thrun, 2000; Poupart, Ortiz, & Boutilier, 2001).
While Thrun (2000) integrates particle filtering with Q-learning to learn the policy, Poupart et
al. (2001) assume the prior existence of an exact value function and present an error bound analysis of substituting the POMDP belief update with particle filters. Loosely related to our work are
300

M ONTE C ARLO S AMPLING M ETHODS FOR A PPROXIMATING I-POMDP S

the sampling algorithms that appear in (Ortiz & Kaelbling, 2000) for selecting actions in influence
diagrams, but this work does not focus on sequential decision making. In the multiagent setting, particle filters have been employed for collaborative multi-robot localization (Fox, Burgard, Kruppa,
& Thrun, 2000). In this application, the emphasis was on predicting the position of the robot, and
not the actions of the other robots, which is a critical step in our approach. Additionally, to facilitate fast localization, beliefs of other robots encountered during motion were considered to be fully
observable to enable synchronization.
Within the POMDP literature, approaches other than sampling methods have also appeared that
address the curse of dimensionality. An important class of such algorithms prescribe substituting
the complex belief space with a simpler subspace (Bertsekas, 1995; Tsitsiklis & Roy, 1996; Poupart
& Boutilier, 2003; Roy, Gordon, & Thrun, 2005). The premise of these methods is that the beliefs – distributions over all the physical states – contain more information than required in order
to plan near-optimally. Poupart and Boutilier (2003) use Krylov subspaces (Saad, 1996) to directly
compress the POMDP model, and analyze the effect of the compression on the decision quality.
To ensure lossless compression, i.e. the decision quality at each compressed belief is not compromised, the transition and reward functions must be linear. Roy et al. (2005) proposed using principal
component analysis (Collins, Dasgupta, & R.E.Schapire, 2002) to uncover a low dimensional belief
subspace that usually encompasses a robot’s potential beliefs. The method is based on the observation that beliefs along many real-world trajectories exhibit only a few degrees of freedom. The
effectiveness of these methods is problem specific; indeed, it is possible to encounter problems
where no substantial belief compression may occur. When applied to the I-POMDP framework, the
effectiveness of the compression techniques would depend, for example, on the existence of agent
models whose likelihoods within the agent’s belief do not change after successive belief updates
or on the existence of correlated agent models. Whether such models exist in practice is a topic of
future work.
Techniques that address the curse of history in POMDPs also exist. Poupart and Boutilier (2004)
generate policies via policy iteration using finite state controllers with a bounded number of nodes.
Pineau et al. (2006) perform point-based value iteration (PBVI) by selecting a small subset of reachable belief points at each step from the belief simplex and planning only over these belief points.
Doshi and Perez (2008) outline the challenges and develop PBVI for I-POMDPs. Though our
method of mitigating the curse of history is conceptually close to point based selection methods, we
focus on plan computation when the initial belief is known while the previously mentioned methods
are typically utilized for offline planning. An approximate way of solving POMDPs online is the
RTBSS approach (Paquet, Tobin, & Chaib-draa, 2005; Ross et al., 2008) that adopts the branch-andbound technique for pruning the look ahead reachability tree. This approach focuses on selecting
the best action to expand which is complementary to our approach of sampling the observations.
Further, its extension to the multiagent setting as formalized by I-POMDPs may not be trivial due
to the need for a bounding heuristic function whose formulation in multiagent settings remains to
be investigated.

3. Background: Particle Filter for the Single Agent Setting
To act rationally in uncertain settings, agents need to track the evolution of the state over time,
based on the actions they perform and the available observations. In single agent settings, the
state estimation is usually accomplished with a technique called the Bayes filter (Russell & Norvig,
301

D OSHI & G MYTRASIEWICZ

2003). A Bayes filter allows the agent to maintain a belief about the state of the world at any given
time, and update this belief each time an action is performed and new sensory information arrives.
The convenience of this approach lies in the fact that the update is independent of the past percepts
and action sequences. This is because the agent’s belief is a sufficient statistic: it fully summarizes
all of the information contained in past actions and observations.
The operation of a Bayes filter can be decomposed into a two-step process:
• Prediction: When an agent performs a new action, at−1 , its prior belief state is updated:
Z
t t−1 t−1
P r(s |a , b ) =
bt−1 (st−1 )T (st |st−1 , at−1 )dst−1
(1)
st−1

• Correction: Thereafter, when an observation, ot , is received, the intermediate belief state,
P r(·|at−1 , bt−1 ), is corrected:
P r(st |ot , at−1 , bt−1 ) = αO(ot |st , at−1 )P r(st |at−1 , bt−1 )

(2)

where α is the normalizing constant, T is the transition function that gives the uncertain effect
of performing an action on the physical state, and O is the observation function which gives
the likelihood of receiving an observation from a state on performing an action.
Particle filters (PF) (Gordon et al., 1993; Doucet et al., 2001) are specific implementations
of Bayes filters tailored toward making Bayes filters applicable to non-linear dynamic systems.
Rather than sampling directly from the target distribution which is often difficult, PFs adopt the
method of importance sampling (Geweke, 1989), which allows samples to be drawn from a more
tractable distribution called the proposal distribution, π. For example, if P r(S t |ot , at−1 , bt−1 ) is
the target posterior distribution, and π(S t |ot , at−1 , bt−1 ) the proposal distribution, and the support
of π(S t |ot , at−1 , bt−1 ) includes the support of P r(S t |ot , at−1 , bt−1 ), we can approximate the target
posterior by sampling N i.i.d. particles {s(n) , n = 1...N } according to π(S t |ot , at−1 , bt−1 ) and
assigning to each particle a normalized importance weight:
w(s
e (n) )
P r(s(n) |ot , at−1 , bt−1 )
w(n) = PN
where w(s
e (n) ) =
π(s(n) |ot , at−1 , bt−1 )
e (n) )
n=1 w(s

Each true probability, P r(s|ot , at−1 , bt−1 ), is then approximated by:
t

t−1

P rN (s|o , a

t−1

,b

)=

N
X

w(n) δD (s − s(n) )

n=1
a.s.

where δD (·) is the Dirac-delta function. As N → ∞, P rN (s|ot , at−1 , bt−1 ) → P r(s|ot , at−1 , bt−1 ).
When applied recursively over several steps, importance sampling leads to a large variance in the
weights. To avoid this degeneracy, Gordon et al. (1993) suggested inserting a resampling step,
which would increase the population of those particles that had high importance weights. This has
the beneficial effect of focusing the particles in the high likelihood regions supported by the observations and increasing the tracking ability of the PF. Since particle filtering extends importance
sampling sequentially and appends a resampling step, it has also been called sequential importance
sampling and resampling (SISR).
302

M ONTE C ARLO S AMPLING M ETHODS FOR A PPROXIMATING I-POMDP S

The general algorithm for the particle filtering technique is given by Doucet et al. (2001). We
concentrate on a specific implementation of this algorithm, that has previously been studied under
various names such as MC localization, survival of the fittest, and the bootstrap filter. The implementation maintains a set of N particles denoted by ebt−1 independently sampled from the prior,
bt−1 , and takes an action and observation as input. Each particle is then propagated forwards in time,
using the transition kernel T of the environment. Each particle is then weighted by the likelihood
of perceiving the observation from the state that the particle represents, as given by the observation
function O. This is followed by the (unbiased) resampling step, in which particles are picked proportionately to their weights, and a uniform weight is subsequently attached to each particle. We
outline the algorithm of the bootstrap filter in Fig. 1. Crisan and Doucet (2002) outline a rigorous
proof of the convergence of this algorithm toward the true posterior as N → ∞.
Function PARTICLEFILTER(ebt−1 , at−1 , ot ) returns ebt
1. ebtmp ← φ, ebt ← φ
Importance Sampling
2. for all s(n),t−1 ∈ ebt−1 do
3.
Sample s(n),t ∼ T (S t |at−1 , s(n),t−1 )
4.
Weight s(n),t with the importance weight:
w
e(n) = O(ot |s(n),t , at−1 )
∪
5. ebtmp ← (s(n),t , w
e(n) )
P
(n) = 1
6. Normalize all w
e(n) so that N
n=1 w
Selection
7. Resample with replacement N particles {s(n),t , n = 1...N }
from the set ebtmp according to the importance weights.
8. ebt ← {s(n),t , n = 1...N }
9. return ebt
end function
Figure 1: The particle filtering algorithm for approximating the Bayes filter.
Let us understand the working of the PF in the context of a simple example – the single agent
tiger problem (Kaelbling, Littman, & Cassandra, 1998). The single agent tiger problem resembles
a game show in which the agent has to choose to open one of two doors behind which lies either a
valuable prize or a dangerous tiger. Apart from actions that open doors, the subject has the option of
listening for the tiger’s growl coming from the left, or the right door. However, the subject’s hearing
is imperfect, with given percentages (say, 15%) of false positive and false negative occurrences.
Following Kaelbling et al. (1998), we assume that the value of the prize is 10, that the pain associated
with encountering the tiger can be quantified as -100, and that the cost of listening is -1.
Let the agent have a prior belief according to which it is uninformed about the location of the
tiger. In other words, it believes with a probability of 0.5 that the tiger is behind the left door (TL),
and with a similar probability that the tiger is behind the right door (TR). We will see how the agent
approximately updates its belief using the particle filter when, say, it listens (L) and hears a growl
from the left (GL). Fig. 2 illustrates the particle filtering process. Since the agent is uninformed
about the tiger’s location, we start with an equal number of particles (samples) denoting TL (lightly
303

D OSHI & G MYTRASIEWICZ

GL
~t-1
bi

~ tmp
bi

Propagate

Weight

~t
bi

Resample

L
Correction step

Prediction step

Figure 2: Particle filtering for state estimation in the single agent tiger problem. The light and dark
particles denote the states TL and TR respectively. The particle filtering process consists
of three steps: Propagation (line 3 of Fig. 1), Weighting (line 4), and Resampling (line 7).

shaded) and TR (darkly shaded). The initial sample set is approximately representative of the agent’s
prior belief of 0.5. Since listening does not change the location of the tiger, the composition of the
sample set remains unchanged after propagation. On hearing a growl from the left, the light particles
denoting TL will be tagged with a larger weight (0.85) because they are more likely to be responsible
for GL, than the dark particles denoting TR (0.15). Here, the size of the particle is proportional to
the weight attached to the particle. Finally, the resampling step yields the sample set at time step t,
which contains more particles denoting TL than TR. This sample set approximately represents the
updated belief of 0.85 of the agent that the tiger is behind the left door. Note that the propagation
carries out the task of prediction as shown in Eq. 1 approximately, while the correction step (Eq. 2)
is approximately performed by weighting and resampling.

4. Overview of Finitely Nested I-POMDPs
I-POMDPs (Gmytrasiewicz & Doshi, 2005) generalize POMDPs to handle multiple agents. They do
this by including models of other agents in the state space. We focus on finitely nested I-POMDPs
here, which are the computable counterparts of I-POMDPs in general. For simplicity of presentation
let us consider an agent, i, that is interacting with one other agent, j. The arguments generalize to a
setting with more than two agents in a straightforward manner.
Definition 1 (I-POMDPi,l ). A finitely nested interactive POMDP of agent i, I-POMDPi,l , is:
I-POMDPi,l = hISi,l , A, Ti , Ωi , Oi , Ri i
where:
• ISi,l is a set of interactive states defined as ISi,l = S × Mj,l−1 , l ≥ 1, and ISi,0 = S,1 where S
is the set of states of the physical environment, and Mj,l−1 is the set of possible models of agent j.
1. If there are more agents participating in the interaction, K > 2, then ISi,l = S ×K−1
j=1 Mj,l−1

304

M ONTE C ARLO S AMPLING M ETHODS FOR A PPROXIMATING I-POMDP S

Each model, mj,l−1 ∈ Mj,l−1 , is defined as a triple, mj,l−1 = hhj , fj , Oj i, where fj : Hj → ∆(Aj )
is agent j’s function, assumed computable, which maps possible histories of j’s observations, Hj ,
to distributions over its actions. hj is an element of Hj , and Oj is a function, also computable,
specifying the way the environment is supplying the agent with its input. For simplicity, we may
write model mj,l−1 as mj,l−1 = hhj , m
b j i, where m
b j consists of fj and Oj .

A specific class of models are the (l − 1)th level intentional models, Θj,l−1 , of agent j: θj,l−1 =
hbj,l−1 , A, Ωj , Tj , Oj , Rj , OCj i. bj,l−1 is agent j’s belief nested to the level l−1, bj,l−1 ∈ ∆(ISj,l−1 ),
and OCj is j’s optimality criterion. Rest of the notation is standard. We may rewrite θj,l−1 as,
b j includes all elements of the intentional model other than the
θj,l−1 = hbj,l−1 , θbj i, where θbj ∈ Θ
belief and is called the agent j’s frame. The intentional models are analogous to types as used in
Bayesian games (Harsanyi, 1967).
As mentioned by Gmytrasiewicz and Doshi (2005), we may also ascribe the subintentional
models, SMj , which constitute the remaining models in Mj,l−1 . Examples of subintentional models
are finite state controllers and fictitious play models (Fudenberg & Levine, 1998). While we do not
consider these models here, they could be accommodated in a straightforward manner.
In order to promote understanding, let us define the finitely nested interactive state space in an
inductive manner:
ISi,0 = S,
Θj,0 = {hbj,0 , θbj i : bj,0 ∈ ∆(ISj,0 ), A = Aj },
ISi,1 = S × Θj,0 ,
Θj,1 = {hbj,1 , θbj i : bj,1 ∈ ∆(ISj,1 )},
ISi,l

.
.
.
= S × Θj,l−1 , Θj,l

.
.
.
= {hbj,l , θbj i : bj,l ∈ ∆(ISj,l )}.

Recursive characterizations of state spaces analogous to above have appeared previously in the
game-theoretic literature (Mertens & Zamir, 1985; Brandenburger & Dekel, 1993; Battigalli &
Siniscalchi, 1999) where they have led to the definitions of hierarchical belief systems. These have
been proposed as mathematical formalizations of type spaces in Bayesian games. Additionally,
the nested beliefs are, in general, analogous to hierarchical priors utilized for Bayesian analysis of
hierarchical data (Gelman et al., 2004). Hierarchical priors arise when unknown priors are assumed
to be drawn from a population distribution, whose parameters may themselves be unknown thereby
motivating a higher level prior.
• A = Ai × Aj is the set of joint moves of all agents.
• Ti is a transition function, Ti : S ×A×S → [0, 1] which describes the results of the agent’s actions
on the physical states of the world. (It is assumed that actions can directly change the physical state
only, see Gmytrasiewicz & Doshi, 2005).
• Ωi is the set of agent i’s observations.
• Oi is an observation function, Oi : S × A × Ωi → [0, 1] which gives the likelihood of perceiving
observations in the state resulting from performing the action. (It is assumed that only the physical
state is directly observable, and not the models of the other agent.)
• Ri is defined as, Ri : ISi × A → R. While an agent is allowed to have preferences over physical
states and models of other agents, usually only the physical state will matter.
305

D OSHI & G MYTRASIEWICZ

4.1 Belief Update
Analogous to POMDPs, an agent within the I-POMDP framework also updates its belief as it acts
and observes. However, there are two differences that complicate a belief update in multiagent
settings, when compared to single agent ones. First, since the state of the physical environment
depends on the actions performed by both agents, the prediction of how the physical state changes
has to be made based on the predicted actions of the other agent. The probabilities of other’s actions
are obtained based on its models. Second, changes in the models of the other agent have to be
included in the update. Specifically, since the other agent’s model is intentional the update of the
other agent’s beliefs due to its new observation has to be included. In other words, the agent has to
update its beliefs based on what it anticipates that the other agent observes and how it updates. The
belief update function for an agent in the finitely nested I-POMDP framework is:
R

bti (ist ) = α

ist−1 :θbjt−1 =θbjt

t−1 )
bt−1
i,l (is

P

at−1
j

t−1
t t−1 , ot ) T (st−1 , at−1 , st )
P r(at−1
i
i
j |θj,l−1 ) Oi (s , a

P
t−1 t
t t−1 , ot ) d ist−1
t
× δD (SEθbt (bt−1
j
j,l−1 , aj , oj ) − bj,l−1 ) Oj (s , a
otj

j

(3)
where α is the normalization constant, δD is the Dirac-delta function, SEθbt (·) is an abbreviation
j

t−1
t−1
denoting the belief update, and P r(at−1
is Bayes rational for the
j |θj,l−1 ) is the probability that aj
t−1
agent described by θj,l−1 .
If j is also modeled as an I-POMDP, then i’s belief update invokes j’s belief update (via the term
t−1 t
SEθbt (bt−1
j,l−1 , aj , oj )), which in turn invokes i’s belief update and so on. This recursion in belief
j

nesting bottoms out at the 0th level. At this level, belief update of the agent reduces to a POMDP
based belief update. 2 For an illustration of the belief update, additional details on I-POMDPs, and
how they compare with other multiagent planning frameworks, see (Gmytrasiewicz & Doshi, 2005).
In a manner similar to the belief update in POMDPs, the following proposition holds for the
I-POMDP belief update. The proposition results from noting that Eq. 3 expresses the belief in
terms of parameters of the previous time step only. A complete proof of the belief update and this
proposition is given by Gmytrasiewicz and Doshi (2005).

Proposition 1. (Sufficiency) In a finitely nested I-POMDPi,l of agent i, i’s current belief, i.e., the
probability distribution over the set S × Θj,l−1 , is a sufficient statistic for the past history of i’s
observations.
4.2 Value Iteration
Each level l belief state in I-POMDPi,l has an associated value reflecting the maximum payoff the
agent can expect in this belief state:

R
t
ERi (is, ai )bi,l (is)d is+
U (hbi,l , θbi i) = max
ai ∈Ai
is∈ISi,l

(4)
P
t−1
b
γ
P r(oi |ai , bi,l )U (hSEθbi (bi,l , ai , oi ), θi i)
oi ∈Ωi

2. The 0th level model is a POMDP: Other agent’s actions are treated as exogenous events and folded into T, O, and R.

306

M ONTE C ARLO S AMPLING M ETHODS FOR A PPROXIMATING I-POMDP S

P
where, ERi (is, ai ) = aj Ri (is, ai , aj )P r(aj |θj,l−1 ) (since is = (s, θj,l−1 )).
Eq. 4 is a basis for value iteration in I-POMDPs, and can be succinctly rewritten as U t =
HU t−1 , where H is commonly known as the value backup operator. Analogous to POMDPs, H
is both isotonic and contracting, thereby making the value iteration convergent (Gmytrasiewicz &
Doshi, 2005).
Agent i’s optimal action, a∗i , for the case of finite horizon with discounting, is an element of the
set of optimal actions for the belief state, OP T (θi ), defined as:

OP T (hbi,l , θbi i) = argmax
ai ∈Ai



R

ERi (is, ai )bi,l (is)d is+

is∈ISi,l

γ

P

oi ∈Ωi


b
P r(oi |ai , bi,l )U (hSEθbi (bi,l , ai , oi ), θi i)

(5)

5. Example: The Multiagent Tiger Problem
To illustrate our approximation methods, we utilize the multiagent tiger problem as an example. The
multiagent tiger problem is a generalization of the single agent tiger problem outlined in Section 3
to the multiagent setting. For the sake of simplicity, we restrict ourselves to a two-agent setting, but
the problem is extensible to more agents in a straightforward way.
In the two-agent tiger problem, each agent may open doors or listen. To make the interaction
more interesting, in addition to the usual observation of growls, we added an observation of door
creaks, which depends on the action executed by the other agent. Creak right (CR) is likely due to
the other agent having opened the right door, and similarly for creak left (CL). Silence (S) is a good
indication that the other agent did not open doors and listened instead. We assume that the accuracy
of creaks is 90%, while the accuracy of growls is 85% as before. Again, the tiger location is chosen
randomly in the next time step if any of the agents opened any doors in the current step. We also
assume that the agent’s payoffs are analogous to the single agent version. Note that the result of
this assumption is that the other agent’s actions do not impact the original agent’s payoffs directly,
but rather indirectly by resulting in states that matter to the original agent. Table 1 quantifies these
factors.
When an agent makes its choice in the multiagent tiger problem, it may find it useful to consider
what it believes about the location of the tiger, as well as whether the other agent will listen or
open a door, which in turn depends on the other agent’s beliefs, preferences and capabilities. In
particular, if the other agent were to open any of the doors, the tiger’s location in the next time
step would be chosen randomly. The information that the agent had about the tiger’s location till
then, would reduce to zero. We simplify the situation somewhat by assuming that all of the agent
j’s properties, except for beliefs, are known to i, and that j’s time horizon is equal to i’s. In other
words, i’s uncertainty pertains only to j’s beliefs and not to its frame.

6. Representing Prior Nested Beliefs
As we mentioned, there is an infinity of intentional models of an agent. Since an agent is unaware
of the true models of interacting agents ex ante, it must maintain a belief over all possible candidate
models. The complexity of this space precludes practical implementations of I-POMDPs for all
307

D OSHI & G MYTRASIEWICZ

hai , aj i
hOL, ∗i
hOR, ∗i
h∗, OLi
h∗, ORi
hL, Li
hL, Li

State
*
*
*
*
TL
TR

TL
0.5
0.5
0.5
0.5
1.0
0

TR
0.5
0.5
0.5
0.5
0
1.0

hai , aj i
hOR, ORi
hOL, OLi
hOR, OLi
hOL, ORi
hL, Li
hL, ORi
hOR, Li
hL, OLi
hOL, Li

Transition function: Ti = Tj

TL
10
-100
10
-100
-1
-1
10
-1
-100

TR
-100
10
-100
10
-1
-1
-100
-1
10

hai , aj i
hOR, ORi
hOL, OLi
hOR, OLi
hOL, ORi
hL, Li
hL, ORi
hOR, Li
hL, OLi
hOL, Li

TL
10
-100
-100
10
-1
10
-1
-100
-1

TR
-100
10
10
-100
-1
-100
-1
10
-1

Reward functions of agents i and j

hai , aj i
hL, Li
hL, Li
hL, OLi
hL, OLi
hL, ORi
hL, ORi
hOL, ∗i
hOR, ∗i

State
TL
TR
TL
TR
TL
TR
∗
∗

h GL, CL i
0.85*0.05
0.15*0.05
0.85*0.9
0.15*0.9
0.85*0.05
0.15*0.05
1/6
1/6

h GL, CR i
0.85*0.05
0.15*0.05
0.85*0.05
0.15*0.05
0.85*0.9
0.15*0.9
1/6
1/6

h GL, S i
0.85*0.9
0.15*0.9
0.85*0.05
0.15*0.05
0.85*0.05
0.15*0.05
1/6
1/6

h GR, CL i
0.15*0.05
0.85*0.05
0.15*0.9
0.85*0.9
0.15*0.05
0.85*0.05
1/6
1/6

h GR, CR i
0.15*0.05
0.85*0.05
0.15*0.05
0.85*0.05
0.15*0.9
0.85*0.9
1/6
1/6

h GR, S i
0.15*0.9
0.85*0.9
0.15*0.05
0.85*0.05
0.15*0.05
0.85*0.05
1/6
1/6

hai , aj i
hL, Li
hL, Li
hOL, Li
hOL, Li
hOR, Li
hOR, Li
h∗, OLi
h∗, ORi

State
TL
TR
TL
TR
TL
TR
∗
∗

h GL, CL i
0.85*0.05
0.15*0.05
0.85*0.9
0.15*0.9
0.85*0.05
0.15*0.05
1/6
1/6

h GL, CR i
0.85*0.05
0.15*0.05
0.85*0.05
0.15*0.05
0.85*0.9
0.15*0.9
1/6
1/6

h GL, S i
0.85*0.9
0.15*0.9
0.85*0.05
0.15*0.05
0.85*0.05
0.15*0.05
1/6
1/6

h GR, CL i
0.15*0.05
0.85*0.05
0.15*0.9
0.85*0.9
0.15*0.05
0.85*0.05
1/6
1/6

h GR, CR i
0.15*0.05
0.85*0.05
0.15*0.05
0.85*0.05
0.15*0.9
0.85*0.9
1/6
1/6

h GR, S i
0.15*0.9
0.85*0.9
0.15*0.05
0.85*0.05
0.15*0.05
0.85*0.05
1/6
1/6

Observation functions of agents i and j.
Table 1: Transition, reward, and observation functions for the multiagent tiger problem.

but the simplest settings. Approximations based on sampling use a finite set of sample points to
represent a complete belief state.
In order to sample from nested beliefs we first need to represent them. Agent i’s level 0 belief,
def

bi,0 ∈ ∆(S), is a vector of probabilities over each physical state: bi,0 = h pi,0 (s1 ), pi,0 (s2 ),
. . ., pi,0 (s|S| ) i. The first and second subscripts of bi,0 denote the agent and the level of nesting,
P|S|
respectively. Since belief is a probability distribution, q=1 pi,0 (sq ) = 1. We refer to this constraint
P|S|−1
as the simplex constraint. As we may write, pi,0 (s|S| ) = 1 − q=1 pi,0 (sq ), subsequently, only
|S| − 1 probabilities are needed to specify a level 0 belief.
For the tiger problem, let s1 = T L and s2 = T R. An example level 0 belief of i for the tiger
def

problem, bi,0 = hpi,0 (T L), pi,0 (T R)i, is h0.7, 0.3i that assigns a probability of 0.7 to T L and 0.3
to T R. Knowing pi,0 (T L) is sufficient for a complete specification of the level 0 belief.
308

M ONTE C ARLO S AMPLING M ETHODS FOR A PPROXIMATING I-POMDP S

Agent i’s first level belief, bi,1 ∈ ∆(S × Θj,0 ), is a vector of densities over j’s level 0 beliefs,
one for each combination of state and j’s frame and possibly distinct from each other. Hence,
hs,θbj i

0.506

0.504

0.504

<TR,m’>
<TR, θ ’>
(p )
j,0
(p

j,0

)

0.506

0.5
0.498

pp i,1i,1

θ ’>

0.502

<TL,

p p<TL,m’>
(p
(p ) )
j,0
i,1 i,1
j,0

b |
|S||Θ
hs,θb i
hs,θb i
j
b j | such densities: bi,1 def
there are |S||Θ
= h pi,1 j 1 , pi,1 j 2 , . . ., pi,1
i, where hs, θbj ik ,
b j | is a particular state and j’s frame combination. Because of the simplex conk = 1, . . . , |S||Θ
straint, the sum of integrals of the level 1 densities over the level 0 beliefs must be 1. We observe
that the level 1 densities may be represented using any family of probability distributions such as
exponential family (Dobson, 2002) or polynomials that allow approximation of any function up to
arbitrary accuracy. As such, the densities could exhibit any shape given that they satisfy the simplex
constraint.

0.502
0.5
0.498
0.496

0.496

0.494

0.494
0

0.2

0.4
0.6
p
(TL)
j,0

0.8

0

1

0.2

0.4
p

0.6

j,0

0.8

1

0.8

1

(TL)

0.8

0.8

0.7

0.7

<TR, θ ’>
pp<TR,m’>
(p (p) )
i,1
j,0 j,0
i,1

<TL,m’>
θ’> (p )
p<TL,
p
(p )
i,1 i,1
j,0j,0

(a)

0.6
0.5
0.4
0.3
0.2

0.6
0.5
0.4
0.3
0.2
0.1

0.1

0

0
0

0.2

0.4
p

0.6

j,0

0.8

0

1

0.2

0.4
p

(TL)

0.6

j,0

(TL)

(b)

Figure 3: Example level 1 beliefs of i in the two-agent tiger problem. (a) According to this belief,
i is uninformed of j’s level 0 beliefs. Since the marginal of each plot is 0.5, i is also
unaware of the location of the tiger. (b) Agent i believes that j likely knows the location
R 0.5 hT L,θb′ i
R 1 hT L,θb′ i
of the tiger ( 0 pi,1
(pj,0 )dpj,0 ≪ 0.5 pi,1
(pj,0 )dpj,0 ), though i itself is unaware
of it as the marginal of each plot is 0.5.

def

hT L,θb′ i

hT R,θb′ i

An example level 1 belief of i, bi,1 = hpi,1 j , pi,1 j i, in the tiger problem is one according
to which i is uninformed about j’s level 0 beliefs and about the location of the tiger (see Fig. 3(a)).
The superscript, θbj′ , is agent j’s frame that is known to i. Another example level 1 belief of i is one
according to which it believes that j likely knows the location of the tiger (Fig. 3(b)).
Agent i’s second level belief, bi,2 ∈ ∆(S × Θj,1 ), is a vector of densities over j’s level 1 beliefs
for each state and j’s intentional frame. In comparison to level 0 and level 1 beliefs, representing doubly-nested beliefs and beliefs with deeper nestings is not trivial. This is because these are
distributions over density functions whose representations need not be finite. For example, let j’s
309

D OSHI & G MYTRASIEWICZ

singly-nested belief densities be represented using the family of polynomials. Then, i’s doublynested belief over j’s densities is a vector of normalized mathematical functions of variables where
the variables are the parameters of lower-level densities. Because the lower level densities are polynomials which could be of any degree and therefore any number of coefficients, the functions that
represent doubly-nested beliefs may have an indefinite number of variables. Thus computable representations of i’s level 2 beliefs are not trivially obtained. We formalize this observation using
Proposition 2, which shows that multiply-nested beliefs are necessarily partial functions that fail to
assign a probability to some elements (lower level beliefs) in their domain.
Proposition 2. Agent i’s multiply nested belief, bi,l , l ≥ 2, is strictly a partial recursive function.
Proof. We briefly revisit the definition of nested beliefs: bi,l ∈ ∆(ISi,l ) = ∆(S × Θj,l−1 ) = ∆(S ×
b j i), where Bj,l−1 is the level l − 1 belief simplex and Θ
b j is the set of frames of j. As
hBj,l−1 , Θ
b j i). Because the state and frame spaces are
the basis case, let l = 2, then bi,2 ∈ ∆(S × hBj,1 , Θ
discrete, bi,2 may be represented using a collection of density functions on j’s beliefs, one for each
hs,θb i

discrete state and j’s frame combination, pi,2 j (bj,1 ), where bj,1 ∈ Bj,1 . Notice that, bj,1 being
singly-nested, is itself a collection of densities over j’s level 0 beliefs, one for each state and i’s
def

hs,θb i

hs,θbi i|S||Θ
b

hs,θb i

|

i
frame combination. Thus, as mentioned before let bj,1 = h pj,1 i 1 , pj,1 i 2 , . . ., pj,1
i.
Recall from Section 4 that the models and therefore the belief density functions are assumed

hs,θbi i1

computable. Let x be the program of length in bits, l(x), that encodes, say pj,1
g. Then define the complexity of the density function,
g(x) =

hs,θb i
pj,1 i 1 }.

hs,θb i
pj,1 i 1 ,

as:

, in the language

hs,θb i
Cg (pj,1 i 1 )

= min {l(x) :

Cg (·) is the minimum length program in language g that computes the argument.3
hs,θ̂ i

We observe that l(x) is proportional to the number of parameters that describe pj,1 i 1 . Because the
number of parameters of a density need not be bounded, l(x) and consequently the complexity of
the density may not be finite. Intuitively, this is equivalent to saying that the density could have
“any shape”.
hs,θbj i

Assume, by way of contradiction, that the level 2 density function, pi,2
hs,θ̂ i
pi,2 j

is a total recursive

is total, T will halt on all
function. Construct a Turing machine, T , that computes it. Because
inputs. Specifically, T will read the set of symbols on its input tape that describe the level 1 density
function (the program, x), and once it has finished reading it halts and leaves a number between 0
and 1 on the output tape. This number is the output of the density function encoded by T . Note that
T does not execute the input program x, but simply parses it to enable identification. Thus T is not
a universal Turing machine. As we mentioned previously, the minimum length program (and hence
the complexity) that encodes the level l density function may be infinite. Thus the size of the set of
symbols on the input tape of T , l(x), may be infinite, and T may not halt. But this is a contradiction.
hs,θb i

Thus, pi,2 j is a partial recursive function.
The argument may be extended inductively to further levels of nesting.
As multiply-nested beliefs in their general form are partial recursive functions that are not defined for every possible lower level belief in their domain, restrictions on the complexity of the
3. Note that the complexity, Cg , is within a constant of the Kolmogorov complexity (Li & Vitanyi, 1997) of the density
bi i1
hs,θ

function, pj,1

.

310

M ONTE C ARLO S AMPLING M ETHODS FOR A PPROXIMATING I-POMDP S

nested beliefs (where complexity is as defined in Proposition 2) are needed to allow for computability and so that they are well-defined. One way is to focus our attention on limited representations
involving a bounded number of parameters.
Because of these complications, a general-purpose language for representing nested beliefs is
beyond the scope of this article and we do not attempt it here; it is a topic of continuing investigations. Instead, we utilize specific examples of doubly-nested and more deeply nested beliefs for our
experiments in the remainder of this article.

7. Decomposing the I-POMDP Belief Update
Analogous to Eqs. 1 and 2 of the Bayes filter, we decompose the I-POMDP belief update into two
steps. The decomposition not only facilitates a better understanding of the belief update, but also
plays a pivotal role in the development of the approximation.
t−1
• Prediction: When an agent, say i, performs an action at−1
i , and agent j performs aj , the
predicted belief state is:

t−1 t−1
P r(ist |at−1
i , aj , bi,l ) =

R

t−1
bt−1 (ist−1 )P r(at−1
j |θj,l−1 )
IS t−1 :θbjt−1 =θbjt i,l
P
t−1 t
t t−1 t−1 t
×Ti (st−1 , at−1
otj Oj (s , ai , aj , oj )
i , aj , s )
t−1 t
t
t−1
×δD (SEθbt (bt−1
j,l−1 , aj , oj ) − bj,l−1 ) d is
j

(6)

where δD is the Dirac-delta function, SEθbt (·) is an abbreviation for the belief update, P r(at−1
j
j

t−1
t−1
| θj,l−1
) is the probability that at−1
is Bayes rational for the agent described by θj,l−1
.
j

• Correction: When agent i perceives an observation, oti , the corrected belief state is a weighted
sum of the predicted belief states for each possible action of j:
t−1
P r(ist |oti , at−1
i , bi,l ) = α

X

t−1 t
t t−1 t−1 t−1
Oi (st , at−1
i , aj , oi )P r(is |ai , aj , bi,l )

(7)

at−1
j

where α is the normalizing constant.
Equations 6 and 7 along with Proposition 1 may be seen as a generalization of the single agent
Bayes filter (see Section 3) to the multiagent setting. At a general level, these equations represent
an application of the update of hierarchical priors given observed data (Gelman et al., 2004) to the
problem of state estimation in multiagent settings.

8. Interactive Particle Filter for the Multiagent Setting
We presented the algorithm for the traditional bootstrap filter in Section 3. As we mentioned before,
the bootstrap filter is a MC sampling based randomized implementation of the POMDP belief update
(Bayes filter). We generalize this implementation so as to approximate the I-POMDP belief update
steps presented previously in Section 7.
311

D OSHI & G MYTRASIEWICZ

8.1 Description
Our generalization of the PF to the multiagent case, which we call an interactive particle filter
(I-PF), similar to the basic PF, involves the key steps of importance sampling and selection. The
resulting algorithm inherits the convergence properties of the original algorithm (Doucet et al.,
2001). Specifically, the approximate posterior belief generated by the filter converges to the truth
(as computed by Eqs. 6 and 7) as the number of particles (N ) tends to infinity. Note that the presence
of other agents does not affect the convergence because, (a) the exact belief update that provides the
stationary point similarly reasons about the presence of other agents, and (b) we explicitly model
other agents’ actions due to which the nonstationarity in the environment vanishes.
The extension of the PF to the multiagent setting turns out to be nontrivial because we are
faced with predicting the other agent’s action(s), which requires us to deal with an interactive belief
hierarchy. Analogously to the I-POMDP belief update, the I-PF reduces to the traditional PF when
there is only one agent in the environment.
The I-PF, described in Fig. 4, requires an initial set of N particles, ebt−1
k,l , that is approximately
t−1
representative of the agent’s prior belief, along with the action, ak , the observation, otk , and the
level of belief nesting, l > 0. As per our convention, k will stand for either agent i or j, and −k for
(n)
the other agent, j or i, as appropriate. Each particle, isk , in the sample set represents the agent’s
possible interactive state, in which the other agent’s belief may itself be a set of particles. Formally,
(n)
(n)
(n)
(n)
(n)
(n)
isk = hs(n) , θ−k i, where θ−k = heb−k,l−1 , θb−k i. Note that ebk,0 is a probability distribution over
the physical state space.
We generate ebt−1
k,l by sampling N particles from the prior nested belief. Given a prior nested
belief, this is a simple recursive procedure that first uses the marginals over the physical states and
frames at the current nesting level to sample the state and frame of the other agent. We then sample
N particles from the density over the lower level beliefs, conditioned on the sampled state and frame
combination. If the belief is multiply nested, this operation is recursively performed bottoming out
at the lowest level where the other agent’s flat (level 0) beliefs are sampled.
The interactive particle filtering proceeds by propagating each particle forward in time. However, as opposed to the traditional particle filtering, this is not a one-step process: (i) In order to
perform the propagation, other agent’s action must be known. As the model ascribed to the other
agent is intentional, this is obtained by solving the other agent’s model (using the algorithm APPROXPOLICY described later in Section 9) to find a distribution over its actions, from which its
action is sampled (lines 3–4 in Fig. 4). Specifically, if OPT is the set of optimal actions obtained
by solving the model, then P r(a−k ) = |OP1 T | if a−k is in OPT, 0 otherwise. (ii) Additionally,
analogous to the exact belief update, for each of the other agent’s possible observations, we must
update its model (line 6). Because the model is intentional, we must update its belief state. If l > 1,
updating the other agent’s belief requires recursively invoking the I-PF for performing its belief update (lines 12–14). This recursion in depth of the belief nesting terminates when the level of nesting
becomes one, and a LEVEL0BELIEFUPDATE, described in Fig. 5, is performed (lines 8–10).4 In
addition to using the agent’s own observation for weighting, the other agent’s observations also participate in the weighting process (lines 15–16). The latter allows us to distinguish j’s beliefs that are
more likely given the physical state. Though the propagation and weighting steps generate |Ω−k |N
appropriately weighted particles, we resample N particles out of these (line 19), using an unbiased
4. If the physical state space is also continuous or very large, then we would replace the level 0 belief update with a
traditional particle filter. However, in doing so, we would loose the theoretical bounds given in Section 9.1

312

M ONTE C ARLO S AMPLING M ETHODS FOR A PPROXIMATING I-POMDP S

t−1 t−1 t
Function I-PARTICLEFILTER (ebk,l
, ak , ok , l > 0) returns ebtk,l
tmp
t
e
e
1. bk,l ← φ, bk,l ← φ
Importance Sampling
(n),t−1
(n),t−1
t−1
2. for all isk
= hs(n),t−1 , θ−k
i ∈ ebk,l
do
(n),t−1
(n),t−1
3.
P r(A−k |θ−k
) ← APPROXPOLICY(θ−k
, l − 1)
(n),t−1
t−1
4.
Sample a−k
∼ P r(A−k |θ−k
)
// Sample other agent’s action
t−1 (n),t−1
5.
Sample s(n),t ∼ Tk (S t |akt−1 , a−k
,s
) // Sample the physical state
t
6.
for all o−k ∈ Ω−k do
// Update other agent’s belief
7.
if (l = 1) then
// I-POMDP is singly nested
(n),t
(n),t−1 t−1 t
8.
b−k,0 ← LEVEL0BELIEFUPDATE(b−k,0 , a−k
, o−k )
(n),t
(n),t b(n)
9.
θ−k ← hb−k,0 , θ−k i
(n),t
(n),t
10.
isk
← hs(n),t , θ−k i
11.
else
// I-POMDP is multiply nested
(n),t
(n),t−1 t−1 t
e
e
12.
b−k,l−1 ← I-PARTICLEFILTER(b−k,l−1 , a−k , o−k , l − 1)
(n),t
(n),t
(n)
13.
θ−k ← h eb−k,l−1 , θb−k i
(n),t
(n),t
14.
isk
← hs(n),t , θ−k i
(n),t
(n)
t−1
15.
Weight isk : wt ← O−k (ot−k |s(n),t , akt−1 , a−k
)
(n)
(n)
t (n),t t−1 t−1
16.
Adjust weight: wt ← wt × Ok (ok |s
, ak , a−k )
∪
(n),t
(n)
ebtmp ←
17.
(isk , wt )
k,l
PN
(n)
(n)
18. Normalize all wt so that n=1 wt = 1
Selection
(n),t
19. Resample with replacement N particles {isk , n = 1...N }
tmp
from the set ebk,l according to the importance weights.
(n),t
e
20. btk,l ← {isk , n = 1...N }
21. return ebtk,l
end function

Figure 4: Interactive particle filtering for approximating the I-POMDP belief update. A nesting of
filters is used to update all levels of the belief. k denotes either agent i or j, and −k the
other agent, j or i, as appropriate. Also see Fig. 6 for a visualization.

resampling scheme. Lines 2–15 represent a simulation of the prediction step (Eq. 6), while lines
16–20 are the simulated implementation of the correction step (Eq. 7).
An alternative approach within the propagation step is to sample the other agent’s observation
because it is a hidden variable. We may then update its belief given the sampled observation.
Although statistically equivalent to our approach, it involves an additional step of sampling, which
further contributes to the sources of error in the I-PF. In particular, for lesser number of particles,
other agent’s beliefs resulting from low probability observations may not appear in the resampled
posterior. This is because other agent’s low probability observations are less likely to be sampled.
Because the original agent’s observation is independent of the other’s belief, particles with identical
physical states but different beliefs of the other are weighted equally. As the beliefs resulting from
low probability observations are less frequent in the sample set, they are less likely to be picked
in the resampled posterior. In comparison, weighting using the other agent’s observation removes
313

D OSHI & G MYTRASIEWICZ

t−1 t−1 t
Function LEVEL0BELIEFUPDATE (bk,0
, ak , ok ) returns btk,0
t−1
t−1
1. P r(a−k ) ← 1/a−k
// Other agent’s action as noise
2. for all st ∈ S do
3.
sum ← 0
4.
for all st−1 ∈ S do
5.
P r(st |st−1 , akt−1 ) ← 0
t−1
6.
for all a−k
∈ A−k do
// Marginalize noise
+
t−1
t−1
7.
P r(st |st−1 , akt−1 ) ← Tk (st |st−1 , akt−1 , a−k
)P r(a−k
)
+
t t−1 t−1 t−1 t−1
8.
sum ← P r(s |s , ak )bk (s )
9.
P r(otk |st , akt−1 ) ← 0
t−1
10.
for all a−k
∈ A−k do
// Marginalize noise
t−1
t t t−1 +
t t t−1 t−1
11.
P r(ok |s , ak ) ← Ok (ok |s , ak , a−k )P r(a−k
)
t
t
t t t−1
12.
bk,0 (s ) ← P r(ok |s , ak )× sum
13. Normalize the belief, btk
14. return btk
end function

Figure 5: The level 0 belief update which is similar to the exact POMDP belief update with the
other agent’s actions treated as noise. As an example, the noise may simply be a uniform
distribution over the other agent’s actions.

the intermediate sampling step and a source of error but at the expense of temporarily generating a
larger number of particles. Based on a preference for reduced approximation error or computational
efficiency, one of the two alternative steps may be used.
A visualization of our I-PF implementation is shown in Fig. 6. Note that the number of particles
grows exponentially with the nesting level, due to which the approach becomes intractable for a
larger number of levels. A method to limit the number of particles as we descend through the
nesting level is needed to address this source of complexity. This is one line of our future work.
Notice that the I-PF could also be viewed as a recursive implementation of an approximately
Rao-Blackwellised particle filter (RBPF) (Doucet, de Freitas, Murphy, & Russell, 2000), where
the conditional distribution over models is itself updated using a RBPF. Doshi (2007) presented a
Rao-Blackwellised I-PF (RB-IPF), where the conditional distribution is updated using a variational
Kalman filter. Although the performance of the RB-IPF improves on the I-PF, it is restricted to prior
beliefs that are Gaussian and could not be generalized to beyond a single level of nesting.
8.2 Illustration of the I-PF
We illustrate the operation of the I-PF using the multiagent tiger problem introduced in Section 5.
For the sake of simplicity we consider i’s prior belief to be singly nested, i.e. l = 1. The procedure is
recursively performed for more deeply nested beliefs. Let i be uninformed about j’s level 0 beliefs,
and about the location of the tiger (see Fig. 3(a)). We demonstrate the operation of the I-PF for the
case when i listens (L) and hears a growl from the left and no creaks, hGL,Si.
In Fig. 7, we show the initial sample set, ebt−1
i,1 , consisting of N = 2 particles that is approximately representative of i’s singly-nested beliefs. Since we assume that j’s frame is known, each
314

M ONTE C ARLO S AMPLING M ETHODS FOR A PPROXIMATING I-POMDP S

t

time
depth

ok
b

t−1

b

tmp

b

k,l

k,l

Propagation

Weight

t

k,l

Resample

t−1

ak

b

(n),t−1

b

−k,l−1

(n) (n)

(n) (n)

s , θ −k ,

s , θ −k ,
b (n),t−1

b (n),t

k,l−2

k,l−2

(n) (n)

(n) (n)

s, θ k ,

s, θ k ,
b (n),t

b (n),t−1

k,1

k,1

Level 1

(n),t

−k,l−1

(n) (n)

(n) (n)

s, θ k,

s, θ k,

t−1

b −k

t

b −k

Figure 6: An illustration of the nesting in the I-PF. Colors black and gray distinguish filtering for
the two agents. Because the propagation step involves updating the other agent’s beliefs,
we perform particle filtering on its beliefs. The filtering terminates when it reaches the
level 1 nesting, where a level 0 belief update is performed for the other agent.

~ t-1
b i,1
t-1
<st- 1 = TL, b j,0
= 0.5>

<st- 1 = TR, b t-1
j,0 = 0.5>

ait-1 =L

Figure 7: An initial sample set of 2 particles that is approximately representative of bt−1
i,1 shown in
Fig. 3(a).

particle is an interactive state consisting of the tiger’s location and j’s level 0 belief. Let a belief of
0.5 of j be sampled from each of the flat line densities.
315

D OSHI & G MYTRASIEWICZ

~ t-1
bi,1
<st- 1 = TL, b t-1
j,0 = 0.5>

a t-1
j =L

<st- 1 = TR, b t-1
j,0 = 0.5>

a t-1
j =L
a t-1
i =L

Figure 8: The initial sample set with j’s optimal action shown for each particle.
As we mentioned before, the propagation of the particles from time step t − 1 to t is a two-step
process. As the first step, we solve j’s POMDP to compute its optimal action when its belief is 0.5.
j’s action is to listen since it does know the location of the tiger. We depict this in Fig. 8.
~ t-1
b i,1

Propagation
L,GR
L,GL

t
< st = TL , b j,0
= 0.15>

1 . Sample s t ~ T(S|st-1 ,ait-1 ,ajt-1 )
t
2 . forall otj bj,0
= SEj (bj,0t -1,ajt-1 ,ojt )
t
t
= 0.85>
< s = TL, bj,0

L,GR

a t-1
i =L

t
t
< s = TR, bj,0
= 0.85>

L,GL
t
t
< s = TR, b j,0
= 0.15>

Figure 9: The propagation of the particles from time step t − 1 to time step t. It involves sampling
the next physical state and updating j’s beliefs by anticipating its observations (denoted
using dashed arrows). Because j may receive any one of two observations, there are 4
particles in the propagated sample set.

The second step of the propagation is to sample the next physical state for each particle using
the transition function. Since both i and j listen, the location of the tiger remains unchanged. Next,
we must update j’s beliefs. We do this by anticipating what j might observe, and updating its belief
exactly given its optimal action of listening. Since j could receive one of two possible observations
– GL or GR – each particle ”splits” into two. This is shown using the dashed arrows going from
particles in the initial sample set to the particles in the propagated sample set, in Fig. 9. When j
hears a GL, its updated belief is 0.85 (that the tiger is behind the left door), otherwise it is 0.15 when
it hears a GR. If the level of belief nesting is greater than one, j’s belief update would be performed
by recursively invoking the interactive particle filter on j’s beliefs.
316

M ONTE C ARLO S AMPLING M ETHODS FOR A PPROXIMATING I-POMDP S

oit =GL,S

~ t-1
bi,1
Propagation

~
bi,1 tmp
Weighting

t
< s = TL , bj,0t = 0.15>
w = 0.15*0. 765 = 0. 115

t

< s = TL , bj,0t = 0.85>
w = 0.85*0. 765 = 0. 650
t
< s = TR , bj,0t = 0.85>
w = 0.15*0. 135 = 0. 020

ait-1 =L

<st- 1 = TR , bj,0t = 0.15>
w = 0.85*0. 135 = 0. 115

Figure 10: The weighting step is a two step process: Each particle is first weighted with the likelihood with which j receives its observations, followed by adjusting this weight using the
probability of i making its observation of hGL,Si. Note that resulting weights as shown
are not normalized.

As part of the weighting, we will first weight each particle with the probability of j receiving
its observations. Particles with larger weights contain beliefs of j that are more likely. Thereafter,
we will scale this weight with the probability of i observing a growl from the left and no creaks,
hGL,Si. To understand the weighting process, let’s focus on a single particle. Weighting for the
remaining particles is analogous.
We consider the particle on the top right in the sample set, ebtmp
i,1 , shown in Fig. 10. Agent j’s
level 0 belief of 0.85 in this particle is due to j hearing a growl from the left on listening. The
probability of j making this observation as given by its observation function, when the tiger is on
the left is 0.85. We will adjust this weight with the probability of i perceiving hGL,Si when the tiger
is on the left and both agents are listening. This probability as given by i’s observation function
is 0.765 (see Table 1). The final weight attached to this particle is 0.65. Note that the weights as
shown in Fig. 10 are not normalized. After normalization i’s belief that the tiger is on the left is
0.85 (obtained by adding the normalized weights for particles that have st =TL), and 0.15 for tiger
on the right. We note that this conforms to our expectations.
The final step of the I-PF is an unbiased resampling of the particles using the weights as the
distribution. To prevent an exponential growth in the number of particles 5 , we resample N particles
resulting in the sample set, ebti,1 , that is approximately representative of the exactly updated belief.
When i’s belief is nested to deeper levels, the above mentioned example forms the bottom step
of the recursive filtering process.
8.3 Performance of the I-PF
As part of our empirical investigation of the performance of the I-PF, we show, using a standard
pseudo-distance metric and visually, that it approximates the exact state estimation closely. We
5. After t propagation steps, there will be N |Ωj |t particles in the sample set.

317

D OSHI & G MYTRASIEWICZ

o it =GL,S

~
bi,1t-1
Propagation

~
bi,1 tmp
Weighting

~
bi,1t
Resampling

t
< s = TL , bj,0t = 0.85>

t
< s = TL , bj,0t = 0.85>

t-1

ai =L

Figure 11: The final step is an unbiased resampling using the weights as the distribution.
begin by utilizing extended versions of standard test problems and proceed to demonstrate the performance on a larger problem.
8.3.1 M ULTIAGENT T IGER AND M ACHINE M AINTENANCE P ROBLEMS
For our analysis, we first utilize the two-agent tiger problem that has two physical states, as described in Section 5, and a two-agent version of the machine maintenance problem (MM) (Smallwood & Sondik, 1973) described in detail in Appendix A, that has three physical states. While these
problems have few physical states, the interactive state space tends to get large as it includes models
of the other agent. Due to an absence of other general approximation techniques for I-POMDPs,
we use a grid based numerical integration implementation of the exact filter as the baseline approximation for comparison. We obtained the points for numerical integration by superimposing regular
grids of differing resolutions on the interactive state space.
The lineplots in Fig. 12 show that the quality of the I-PF based approximation, as measured by
KL-Divergence becomes better as the number of particles increases, for both the problem domains.
This remains true for both level 1 and 2 beliefs. KL-Divergence measures the difference between
the two probability distributions by giving the relative entropy of the filtered posterior with respect
to the near-exact one as obtained from the numerical integration. Note that the performance of the IPF remains consistent over both the two-state tiger and the three-state MM problem. However, level
2 belief approximations require considerably more particles as compared to level 1 approximations,
to achieve similar performance, indicating that the performance of the I-PF is affected by the level of
nesting. Each data point in the lineplots is the average of 10 runs of the I-PF on multiple prior belief
states. In the case of the tiger problem, the posterior used for comparison is the one that is obtained
after agent i listens and hears a growl from the left and no creaks. For the MM problem, the posterior
obtained after i manufactures and perceives no defect in the product, is used for comparison. Two
of the prior level 1 beliefs of agent i when playing the tiger problem are those shown in Fig. 3. We
considered a level 2 belief according to which agent i is unaware of the tiger’s location and believes
with equal probabilities that either of the level 1 beliefs shown in Fig. 3 are likely. We utilized
analogous beliefs for the machine maintenance problem.
A comparison of the run times of the I-POMDP belief update implemented using grid based
numerical integration and the I-PF is shown in Table. 2. We varied the number of grid points and
318

M ONTE C ARLO S AMPLING M ETHODS FOR A PPROXIMATING I-POMDP S

Multiagent Tiger

Multiagent Machine Maintenance

600
Level 1
Level 2

Level 1
Level 2

600
KL-Divergence

KL-Divergence

500
400
300
200
100

500
400
300
200
100

0

0
10

100

1000

10000

10

No. of Particles (N)

100

1000

10000

No. of Particles (N)

(i)

(ii)

Figure 12: Anytime performance of the I-PF as a function of the number of particles, on (i) multiagent tiger problem, (ii) multiagent machine maintenance problem. The performance
of the I-PF significantly improves with an increase in the number of particles leading
toward convergence to the true posterior. The vertical bars are the standard deviations.

Belief

Problem
Multiagent
Tiger

Level
1
Multiagent
MM

Multiagent
Tiger
Level
2
Multiagent
MM

Method
I-PF
Grid
based
I-PF
Grid
based
I-PF
Grid
based
I-PF
Grid
based

N=500
0.148s
± 0.001s
21.65s
± 0.18s
0.452s
± 0.009s
1m 0.28s
± 0.21s
2m 23.28s
± 1.1s
34m 40.36s
± 0.55s
1m 37.59s
± 0.17s
24m 55.33s
± 4.77s

N=1000
0.332s
± 0.007s
1m 25.19s
1.02s
0.931s
± 0.0146s
3m 27.87s
± 0.13s
11m 41.30s
± 1.52s
77m 2.9s
± 4.88s
8m 27.29s
± 1.65s
56m 21.97s
± 5.73s

Table 2: Comparison of the average running times of our grid based numerical integration and I-PF
implementations on the same platform (Pentium IV, 1.7GHz, 512MB RAM, Linux).

the number of particles in the two implementations, respectively. As we use initial beliefs that are
flat, having the same number of grid points and particles provides for a comparable approximation
quality. The I-PF implementation significantly outperforms the numerical integration based implementation, while providing the comparable performance quality. Additionally, the run times of the
grid based implementation increase significantly more when we move from the two-state tiger prob319

D OSHI & G MYTRASIEWICZ

lem to the three-state MM problem, in comparison to the increase for the I-PF for level 1 beliefs.
Since the level 1 multiagent tiger model has 6 observations in comparison to 2 for the multiagent
MM, the run times decrease as we move from the tiger to the MM problem for level 2 beliefs.
Despite using an equal number of grid points and particles, the reduced run time of the I-PF
in comparison to the grid based approach is due to: (i) iterating over all grid points in order to
obtain the belief over each interactive state under consideration. In contrast, the I-PF iterates over
all particles at each level once – propagating and weighting them to obtain the posterior; (ii) the
I-PF solves the models approximately in comparison to solving them exactly over the grid points;
and (iii) while the grid based belief update considers all the optimal actions for a model, the I-PF
samples a single action from the distribution and propagates the corresponding particle using this
action.
Level 1 Beliefs in the Multiagent Tiger Problem
Exact
Particle Filter

Exact
Particle Filter

Pr(TL,b_j)

Pr(TR,b_j)

Pr (TL,p )

Pr (TR,p )

j

j

25

5

20

4

15

3

10

2

5

1

0

0
3

3

2.5
0

2.5
0

2

0.2

Prb_j(TL)
j

0.8

Time steps (T)

0.4

1.5

0.6

2

0.2

Time steps (T)

0.4

Prb_jj (TL)

1 1

1.5

0.6
0.8

1 1

Figure 13: The exact and approximate p.d.f.s after successive filtering steps. The peaks of the
approximate p.d.f.s align correctly with those of the exact p.d.f.s, and the areas under
the approximate and exact p.d.f.s are approximately equal.

In order to assess the quality of the approximations after successive belief updates, we graphed
the probability density functions produced by the I-PF and the exact belief update. The densities
arising after each of three filtering steps on the level 1 belief of agent i (Fig. 3(a)) in the tiger
problem, are shown in Fig. 13. Each approximate p.d.f. is the average of 10 runs of the I-PF
which contained 5000 particles, and is shaped using a standard Gaussian kernel. Gmytrasiewicz
and Doshi (2005) provide an explanation of the exact I-POMDP belief update shown here. Briefly,
as the prior belief is a flat line, the posterior becomes segmented where the segments correspond to
beliefs of j that are likely based on the predicted action and anticipated observations of j. The height
of a segment is proportional to the likelihood of j’s possible observation. The action and observation
sequence followed was hL, GL, Si, hL, GL, Si, hOR, GL, Si. As can be seen, the I-PF produces a
good approximation of the true densities.
320

M ONTE C ARLO S AMPLING M ETHODS FOR A PPROXIMATING I-POMDP S

8.3.2 A UAV R ECONNAISSANCE P ROBLEM
Unmanned agents such as UAVs are finding important applications in tasks such as fighting forest
fires (Casbeer, Beard, McLain, Sai-Ming, & Mehra, 2005; Sarris, 2001), law enforcement (Murphy
& Cycon, 1998) and reconnaissance in warfare. The agents must operate in complex environments
characterized by multiple parameters that affect their decisions, including, particularly in warfare,
other agents who may have antagonistic preferences. The task is further complicated because the
agent may possess noisy sensors and unreliable actuators.
We consider the task of a UAV i which performs low-altitude reconnaissance of a potentially
hostile theater that may be populated by other agents with conflicting objectives that serve as ground
reconnaissance targets (see Fig. 14(a)). To facilitate our analysis, we divide the UAV’s operating
theater into a 3×3 grid of sectors and consider a ground reconnaissance target (T ), which could be
located in any of the 9 sectors. For example, the target could be a terrorist who may be hiding in a
safe house located in each sector. Of course, the UAV is unaware of which sector contains T , but
is aware of its own location. To assist in its goal of spotting T by moving to the sector containing
it, the UAV may receive a noisy communication which informs it about the rows (similar colored
sectors in Fig. 14) that likely contain T , though with some uncertainty. The UAV has the option
of moving in any of the four cardinal directions to the adjacent sector, or hovering in its current
location and listening for more communications.
The target T may be informed (by its collaborators) that it could be in danger of being spotted
by the UAV although with high uncertainty, in which case T may move to an adjacent or diagonal
sector. Note that the actions of both, the UAV and agent T may affect the physical state of the
problem. We formulate the decision problem of the UAV below:
• A physical state, s={rowi , sidei or centeri , rowT , sideT or centerT }, where rowi and sidei or
centeri indicate the row location of UAV i and whether the UAV is located in the side columns or the
center column, respectively; • The joint action space, A = Ai ×AT , where Ai = {moveN ,. . .,moveW ,
listen} and AT = {moveN ,. . .,moveW ,listen}. Here, movex moves the UAV or the target in the direction indicated by x, and listen denotes the act of receiving communications about the location of
T or the UAV; • Observation space of the UAV is, Ωi = {top-row (TR), center-row (CR), bottomrow (BR)}, where for example, TR indicates that the corresponding target is in one of the three
sectors in the top row; • Transition function is, Ti : S × A × S → [0, 1]. Ti models the fact
that the UAV and the target move deterministically to a surrounding sector; • Observation function,
Oi : S × A × Ωi → [0, 1] gives the likelihood that the UAV will be informed of the correct row
in which the target is located; and • Reward function, Ri : S × A → [0, 1] formalizes the goal of
spotting the reconnaissance target. If the UAV moves to a sector containing a target , we assume
that the target is spotted and the game ends.
Because the target may move, it is beneficial for i to anticipate T ’s actions. Thus, the UAV
tracks some possible beliefs that T may have about the location of the UAV. We assume that the
UAV is aware of T ’s objectives that conflict with its own, the probabilities of its observations, and
therefore T ’s frame. We point out the size and complexity of this problem, involving 36 physical
states, 5 actions and 3 observations for each agent.
Analogously to the previous problem sets, we measured the quality of the estimation provided
by the I-PF for this larger problem. In Fig. 14(b), we show the KL-Divergence of the approximate
distribution as the number of particles allocated to the I-PF are increased. The KL-Divergence
decreases rapidly as we increase the number of particles for both level 1 and 2 beliefs. However,
321

D OSHI & G MYTRASIEWICZ

1600
Level 1
Level 2

1400
KL-Divergence

T

1200
1000
800
600
400
200

i

0
10

(a)

100
1000
No. of Particles (N)

10000

(b)
Belief
Level
1

Level
2

Method
I-PF
Grid
based
I-PF

N=500
2.929s
± 0.894s
3m 37.07s
± 4.22s
N=100
2m 55.52s
± 25.61s

N=1000
5.251s
± 0.492s
7m 16.42s
± 0.27s
N=200
11m 10.43s
± 56.724s

(c)
Figure 14: (a) The operating theater of the UAV i. The problem may be flexibly scaled by adding
more targets and sectors. (b) The posterior obtained from the I-PF approaches the exact
as the number of particles increase. (c) Comparison of the average running times of our
numerical integration and I-PF implementations on the same platform (Xeon, 3.0GHz,
2GB RAM, Linux).

notice that the magnitude of the divergence is larger for lower numbers of particles in comparison to
the previous problems. This is, in part, due to the larger state space of the problem and demonstrates
that the I-PF does not fully address the curse of dimensionality. Thus, many more particles are
needed to reach comparable levels of divergence. We also show a comparison of the run times
of the I-POMDP belief update implemented using the I-PF and grid based numerical integration
in the table in Fig. 14(c). An identical number of particles and grid points were selected, which
provided comparable qualities of the estimations. We were unable to run the numerical integration
implementation for level 2 beliefs for this problem.

9. Value Iteration on Sample Sets
Because the I-PF represents the belief of agent i, bi,l , using a set of N particles, ebi,l , a value function
e denote the required backup operator,
backup operator which operates on samples is needed. Let H
322

M ONTE C ARLO S AMPLING M ETHODS FOR A PPROXIMATING I-POMDP S

e the approximate value function, then the backup operation, U
et = H
eU
e t−1 , is:
and U


X
1 X
(n)
t−1
t e
e
e
b
b
e
e
ERi (is , ai )+γ
P r(oi |ai , bi,l )U (hI-PF(bi,l , ai , oi ), θi i)
U (hbi,l , θi i) = max
ai ∈Ai N
oi ∈Ωi

is(n) ∈ebi,l

(8)
where
=
γ is the discount factor and I-PF(·) is the
algorithm shown in Fig. 4. The set of optimal action(s) at a given approximate belief, OPT(hebi,l , θbj i),
ERi (is(n) , ai )

P

(n) , a , a )P r(a |θ (n) ),
i j
j j
aj Ri (s

is then calculated by returning the action(s) that have the maximum value:

P
P
1
OP T (hebi,l , θbi i) = argmax
P r(oi |ai , ebi,l )
ERi (is(n) , ai ) + γ
N
ai ∈Ai

is(n) ∈ebi,l


t
e (hI-PF(ebi,l , ai , oi ), θbi i)
×U

oi ∈Ωi

(9)

Equations 8 and 9 are analogous to Eqs. 4 and 5 respectively, with exact integration replaced by
e → H as
Monte Carlo integration, and the exact belief update replaced with the I-PF. Note that H
N → ∞.
The algorithm for computing an approximately optimal finite horizon policy tree given an initial
belief using value iteration when l > 0 is shown in Fig. 18 in Appendix B.
9.1 Convergence and Error Bounds
The use of randomizing techniques such as PFs means that value iteration does not necessarily
converge. This is because, unlike the exact belief update, posteriors generated by the PF with
finitely many particles are not guaranteed to be identical for identical input. The non-determinism
e as N → ∞. 6
of the approximate belief update rules out isotonicity and contraction for H
Our inability to guarantee convergence of value iteration implies that we must approximate an
infinite horizon policy with the approximately optimal finite horizon policy. Let U ∗ be the value
e t be the value of the approximate and U t be the value
of the optimal infinite horizon policy, U
of the optimal t-horizon policy tree. Then the error bound (using the supremum norm || · ||) is,
e t || = ||U ∗ − U t + U t − U
e t || ≤ ||U ∗ − U t || + ||U t − U
e t || (triangle inequality). Note that the
||U ∗ − U
∗
t
t
∗
0
first term, ||U − U ||, is bounded by γ ||U − U ||. The bound for the second term is calculated
below:
e t − U t ||
E t = ||U
eU
e t−1 − HU t−1 ||
= ||H
eU
e t−1 − H U
e t−1 + H U
e t−1 − HU t−1 ||
= ||H
(add zero)
t−1
t−1
t−1
t−1
e
e
e
e
≤ ||H U
− H U || + ||H U
− HU || (triangle inequality)
eU
e t−1 − H U
e t−1 || + γ||U
e t−1 − U t−1 ||
≤ ||H
(contracting H)
t−1
t−1
t−1
e
e
e
≤ ||H U
− H U || + γE

eU
e t−1 − H U
e t−1 ||. In the analysis that follows we focus
We turn our attention to calculating ||H
e t−1 , U
et = H
eU
e t−1 , and bi,1 be the singly nested belief where
on level 1 beliefs. Let U̇ t = H U

6. One may turn PFs into deterministic belief update operators (de-randomization) by generating several posteriors from
the same input. A representative posterior is then formed by taking a convex combination of the different posteriors.
For example, Thrun (2000) uses a k-nearest neighborhood approach for this purpose.

323

D OSHI & G MYTRASIEWICZ

e t |. Let α
the worst error is made: bi,1 = argmax |U̇ t − U
e be the policy tree (alpha vector) that is
bi,1 ∈Bi,1

optimal at ebi,1 (the sampled estimate of bi,1 ), and α̇ be the policy tree that is optimal at bi,1 . We will
use Chernoff-Hoeffding (C-H) upper bounds (Theorem A.1.4, pg 265 in Alon & Spencer, 2000) 7 ,
a well-known tool for analyzing randomized algorithms, to derive a confidence threshold 1 − δ at
e t , is within 2ǫ of the true estimate U̇ t (= E[α̇]):
which the observed estimate, U
α̇
α
e

We may write,

e t > U̇ t + ǫ) ≤ e−2N ǫ2 /(eαmax −eαmin )2
P r(U
α̇
α
e
e t < U̇ t − ǫ) ≤ e−2N ǫ2 /(eαmax −eαmin )2
P r(U
α̇
α
e

e t > U̇ t + ǫ OR U
e t < U̇ t − ǫ) = P r(U
e t > U̇ t + ǫ) + P r(U
e t < U̇ t − ǫ)
P r(U
α̇
α̇
α̇
α̇
α
e
α
e
α
e
α
e
t
t
t
t
e > U̇ + ǫ AND U
e < U̇ − ǫ)
−P r(U
α̇
α̇
α
e
α
e

As the last term is zero, the equation becomes:

e t < U̇α̇t − ǫ) ≤ 2e−2N ǫ2 /(eαmax −eαmin )2
e t > U̇α̇t + ǫ OR U
P r(U
α
e
α
e

e t > U̇ t + ǫ OR U
e t < U̇ t − ǫ) with 1 − P r(U̇ t − ǫ ≤ U
e t ≤ U̇ t + ǫ). After
We may replace P r(U
α̇
α̇
α̇
α̇
α
e
α
e
α
e
some simple operations, the above inequality becomes:
e t ≤ U̇α̇t + ǫ) ≥ 1 − 2e−2N ǫ2 /(eαmax −eαmin )2
P r(U̇α̇t − ǫ ≤ U
α
e

e t is within 2ǫ of the true estimate U̇ t , be at least 1 − δ. Then we have:
Let the probability that U
α̇
α
e
2 /(e
α

1 − δ = 1 − 2e−2N ǫ

αmin )
max −e

2

With a confidence probability of at least 1 − δ, the error bound is:
ǫ=

r

(e
αmax − α
emin )2 ln(2/δ)
2N

(10)

−Rmin
where α
emax − α
emin may be loosely upper bounded as Rmax1−γ
. Note that Eq. 10 can also be
used to derive the number of particles, N , for some given δ and ǫ. To get the desired bound, we note
that with at least probability 1 − δ our error bound is 2ǫ and with probability at most δ the worst
eU
e t−1 − H U
e t−1 || ≤ (1 − δ)2ǫ + δ Rmax −Rmin . The
possible suboptimal behavior may result: ||H
1−γ
final error bound now obtains:
−Rmin
E t ≤ (1 − δ)2ǫ + δ Rmax1−γ
+ γE t−1
t

)
min )(1−γ
+ δ (Rmax −R
= (1 − δ) 2ǫ(1−γ
1−γ
(1−γ)2

t)

(geometric series)

(11)

where ǫ is as defined in Eq. 10.
7. At horizon t, samples in ebi,1 are i.i.d. However, at horizons less than t, the samples are generated by the I-PF and
exhibit limited statistical independence, but independent research (Schmidt, Siegel, & Srinivasan, 1995) reveals that
C-H bounds still apply.

324

M ONTE C ARLO S AMPLING M ETHODS FOR A PPROXIMATING I-POMDP S

Proposition 3 (Error Bound). For a singly nested t-horizon I-POMDPi,1 , the error introduced by
our approximation technique is upper bounded and is given by:
e t − U t || ≤ (1 − δ)
||U

2ǫ(1 − γ t )
(Rmax − Rmin )(1 − γ t )
+δ
1−γ
(1 − γ)2

where ǫ is as defined in Eq. 10.

At levels of belief nesting greater than one, j’s beliefs are also approximately represented using
samples. Hence the approximation error is not only due to the sampling, but also due to the possible
incorrect prediction of j’s actions based on its approximate beliefs. Since even a slight deviation
from the exact belief may lead to an action that turns out to be the worst in value when compared
to the optimal action, it seems difficult to derive bounds that are useful – tighter than the usual
−Rmin
difference between the best and worst possible behavior ( Rmax
) – for this case.
(1−γ)2
9.2 Computational Savings
Since the complexity of solving I-POMDPs is dominated by the complexity of solving the models
of other agents we analyze the reduction in the number of agent models that must be solved. In a
K+1-agent setting with the number of particles bounded by N at each level, each particle in ebt−1
k,l
of level l contains K models all of level l − 1. Solution of each of these level l − 1 models requires
solution of the lower level models recursively. The upper bound on the number of models that
are solved is O((KN )l−1 ). Given that there are K level l − 1 models in a particle, and N such
possibly distinct particles, we need to solve O((KN )l ) models. Our upper bound on the number
of models to be solved is polynomial in K for a fixed nesting level. This can be contrasted with
O((K|Θ∗ |K )l ) models that need to be solved in the exact case, which is exponential in K. Here,
among the spaces of models of all agents, Θ∗ is the largest space and is theoretically countably
infinite. Typically, N ≪ |Θ∗ |K , resulting in a substantial reduction in computation. However, note
that the total number of particles is exponential in the nesting level, l. This makes solutions for large
nesting levels still intractable.

10. Empirical Performance
The goal of our experimental analysis is to demonstrate empirically, (a) the reduction in error with
increasing sample complexity, and (b) savings in computation time when the approximation technique is used. We again use the multiagent tiger problem introduced previously, and a multiagent
version of the machine maintenance (MM) problem (see Appendix A) as test problems. While
the single-agent versions of these problems are simple, their multiagent versions are sufficiently
complex so as to motivate the use of approximation techniques to solve them. Additionally, we
demonstrate that our approach scales to larger problems by applying it to the UAV reconnaissance
problem as well.
10.1 Multiagent Tiger and Machine Maintenance Problems
To demonstrate the reduction in error, we construct performance profiles showing an increase in
performance as more computational resources – in this case particles – are allocated to the approximation algorithm. In Figs. 15(a) and (c) we show the performance profile curves when agent i’s
prior belief is the level 1 belief described previously in Fig. 3(a), and suitably modified for the MM
325

D OSHI & G MYTRASIEWICZ

Multiagent Tiger Problem
0
Expected Reward

Expected Reward

0
-5
-10
-15
-20
-25

-5
-10
-15
-20
-25

-30

-30
1

10
100
1000
No. of Particles (N)

H=2:Exact
H=2:Approx

1

H=3:Exact
H=3:Approx

10
No. of Particles (N)

H=2:Exact
H=2:Approx

100

H=3:Exact
H=3:Approx

(a)

(b)
Multiagent Machine Maintenance Problem
1
Expected Reward

Expected Reward

1
0.5
0
-0.5
-1

0.5
0
-0.5
-1

1

10
100
1000
No. of Particles (N)

H=2:Exact
H=2:Approx

10000

H=3:Exact
H=3:Approx

1

10
No. of Particles (N)

H=2:Exact
H=2:Approx

(c)

100

H=3:Exact
H=3:Approx

(d)

Figure 15: Anytime performance profiles: The multiagent tiger problem using the (a) level 1, and
(b) level 2 belief as the prior for agent i. The multiagent MM using the (c) level 1, and
(d) level 2 belief as i’s prior. The approximate policies gradually improve as we employ
an increasing number of particles.

problem. As expected the average rewards for both, horizon 2 and 3 approach the optimal expected
reward as the number of particles increases. We show the analogous plots for a level 2 belief in
Figs. 15(b) and (d). In each of these cases the average of the rewards accumulated by i over a 2 and
3 horizon policy tree (computed using the APPROXPOLICY algorithm in Fig. 18) while playing
against agent j in simulated tiger and MM problems were plotted. To compensate for the randomness in sampling, we generated i’s policy tree 10 times independently of each other, and averaged
326

M ONTE C ARLO S AMPLING M ETHODS FOR A PPROXIMATING I-POMDP S

over 100 runs each time. Within each run, the location of the tiger and j’s prior beliefs were sampled
according to i’s prior belief. j’s policy was then computed using the algorithm in Fig. 18.
Problem

Error

Multiagent
tiger

Obs.
Et
Worst
Obs.
Et
Worst

Multiagent
MM

t=2
N=100 N=1000
5.61
0
64.73
41.53
209.00
0.28
0.23
4.58
2.05
8.84

t=3
N=100 N=1000
4.39
2.76
120.90
77.57
298.10
0.46
0.40
8.79
3.64
12.61

Table 3: Comparison of the worst case observed errors, our theoretical error bounds and the trivial
−Rmin
error bound ( Rmax
).
(1−γ)2

In Table 3, we compare the empirically determined error bound – difference between the optimal
expected reward and the worst observed expected reward – with the theoretical error bound (δ=0.1,
γ=0.9) from Section 9.1, for horizons 2 and 3. The theoretical error bounds appear loose due to the
worst-case nature of our analysis but (expectedly) are much tighter than the trivial worst bounds,
and become better as the number of particles increases.
Problem
Multiagent
tiger

Method
Grid
SB

Multiagent
MM

Grid
SB

t=2
37.84s
± 0.6s
1.44s
± 0.05s
5m 26.57s
± 0.07s
5.75s
± 0.01s

Run times
t=3
t=4
11m 22.25s
*
± 1.34s
1m 44.29s 19m 16.88s
± 0.6s
± 17.5s
20m 45.69s
*
± 0.29s
34.52s
3m 24.9s
± 0.01s
± 0.04s

t=5
*
*
*
17m 58.39s
± 0.57s

Table 4: Run times on a Pentium IV 2.0 GHz, 2.0GB RAM and Linux. * = program ran out of
memory.

Table 4 compares the average run times of our sample-based approach (SB) with the grid based
approach, for computing policy trees of different horizons starting from the level 1 belief. The
values of the policy trees generated by the two approaches were similar. The run times demonstrate
the impact of the curse of dimensionality on the grid based method as shown by the higher run times
for the MM problem in comparison to the tiger problem. Our I-PF based implementation though
not immune to this curse reduces its impact, but is affected by the curse of history, as illustrated by
the higher run times for the tiger problem (branching factor of the reachability tree: |Ai ||Ωi | = 18)
compared to the MM problem (branching factor:|Ai ||Ωi | = 8). We were unable to compute the
solutions using the grid based implementation for both the problems for horizons beyond 3.
327

D OSHI & G MYTRASIEWICZ

Expected Reward

12
10
8
6
4
2

Problem

Method

UAV
Recon.

SB

Run times
t=2
t=3
8m 50.03s 20m 59.23s
± 5.26s
± 4.09s

0
10

100

1000

No. of Particles (N)
H=2:Approx

H=3:Approx

(a)

(b)

Figure 16: (a) Anytime performance profile for the UAV reconnaissance problem for horizons 2
and 3. Notice that the profile flattens when the number of particles reaches 1,000 and
greater, thereby indicating that the corresponding average reward is close to optimal.
(b) Run times for obtaining a policy on a Xeon 3.0 GHz, 2.0GB RAM and Linux. For
horizon 2, we used 500 particles while 100 particles were used for horizon 3. As we
see in (a), rewards of policies at these numbers of particles are not much less than the
converged values.

10.2 UAV Reconnaissance Problem
We evaluate the performance of our approach on the UAV reconnaissance problem, which we introduced previously in Section 8.3. As we mentioned, this is a larger problem consisting of 36 physical
states, 5 actions and 3 observations. We show the level 1 performance profile for this problem in
Fig. 16(a) for horizons 2 and 3. Due to the size of the problem, we were unable to compute the
exact value of the optimal policies. As before, each data point is the average reward obtained by
simulating a horizon 2 or 3 policy in a two-agent setting. Agent i’s initial belief is one according
to which it is uncertain about the physical state and models of the other agent. We observe that the
profiles tend to flatten as the number of particles increases. The corresponding expected reward is
therefore close to the optimal value of the policies.
We also show the time taken to generate a good quality horizon 2 and 3 policy on average.
They indicate that while it is indeed possible to obtain (approximate) policies for large problems,
the times needed are somewhat large. Notice that these times are significantly greater than the run
times for the multiagent tiger and MM problems. This is, in part, due to the larger state space and,
as we show later in this article, in part due to the larger numbers of actions and observations of each
agent.

11. Sampling the Look Ahead Reachability Tree
Although we were able to solve I-POMDPs for large state spaces, we were unable to generate
solutions for large horizons. The main reason for this is the exponential growth of the look ahead
reachability tree with increasing horizons; we referred to this as the curse of history. At some
time step t, there could be (|Ai ||Ωi |)t−1 reachable belief states of the agent i. For example, in the
328

M ONTE C ARLO S AMPLING M ETHODS FOR A PPROXIMATING I-POMDP S

multiagent tiger problem, at the second time step there could be 18 possible belief states, 324 of
them at the third time step, and more than 0.1 million at the fifth time step.
To mitigate the curse of history, we reduce the branching factor of the look ahead reachability
tree by sampling from the possible observations that the agent may receive. While this approach
does not completely address the curse of history, it beats back the impact of this curse substantially.
During the reachability tree expansion phase, the agent’s actions are used to propagate its belief.
t−1
et−1
Observations are then sampled at each propagated belief, oti ∼ P r(Ωi |at−1
i , bi,l ) where b̃i,l is
the propagated belief. During the value iteration phase, value is backed up the (possibly) partial
reachability tree, and the agent performs the action that is optimal at the root node of the tree. For
convenience, let us label this approach as reachability tree sampling (RTS).
RTS shares its conceptual underpinnings with the belief expansion models of PBVI (Pineau
et al., 2006), but differs in that our method is applicable to online policy tree generation for IPOMDPs, compared to PBVI’s use in offline policy generation for POMDPs. It is also similar to
the sparse sampling technique proposed for selecting actions for exploration during reinforcement
learning (Kearns et al., 2002) and for online planning in POMDPs (Ross et al., 2008) by sampling
the look ahead trees. A distinction is that we focus on sampling observations given the propagated
multiagent beliefs, while the latter approaches focused on settings of single agent learning. Consequently, the process of computing the sampling distribution and the experimental settings differ.
11.1 Computational Savings
We consider the computational savings that result from sampling observations in the look ahead
reachability tree. If we are sampling NΩi < |Ωi | observations at each propagated belief within
the reachability tree, then at some time step t, we will obtain (|Ai ||NΩi |)t−1 possible belief states,
assuming the worst case occurs and we end up sampling NΩi distinct observations. This is in
comparison to the (|Ai ||Ωi |)t−1 belief states in the complete reachability tree. Typically, as our
experiments demonstrate, the number of distinct sampled observations is less than |Ωi |, resulting in
significant computational savings.
Method
SB-No-RTS
SB-RTS

t=2
1.44s
± 0.05s
0.86s
± 0.02s

t=3
1m 44.29s
± 0.6s
15.17s
± 1.6s

Run times
t=4
t=5
19m 16.88s
*
± 17.5s
2m 52.9s
4m 13.43s
± 6.51s
± 27.51s

t=6
*

t=7
*

7m 29.9s
± 47.98s

11m 51.57s
± 20.05s

Table 5: Run times for the multiagent tiger problem on a Pentium IV 2.0 GHz, 2.0GB RAM and
Linux. * = program ran out of memory.

As an illustration of the computational savings we compare the run times of computing the
policy tree for the multiagent tiger (Table 5) and the UAV reconnaissance (Table 6) problems for
singly-nested beliefs. We compare value iteration in which the reachability tree is sampled (SBRTS) with value iteration that does no reachability tree sampling (SB-No-RTS), the algorithm for
which is given in Fig. 18. For SB-RTS in the multiagent tiger problem, we sampled eight times from
the observation distribution up to the fifth horizon and six times thereafter. For both the algorithms,
we used a similar number of particles in the I-PF. As the tiger problem has a total of 6 observations,
329

D OSHI & G MYTRASIEWICZ

not only does the SB-RTS compute the policy faster, we were able to compute it up to seven time
horizons. When compared with the performance of SB-No-RTS, these results demonstrate that the
approach of sampling the reachability tree could yield significant computational savings.
Method
SB-No-RTS
SB-RTS

t=2
8m 50.03s
± 5.26s
8m 23.86s
± 20.46s

Run times
t=3
20m 59.23s
± 4.09s
19m 25.54s
± 89.08s

t=4
*
121m 16.2s
± 592s

Table 6: Run times for the UAV reconnaissance problem on a Xeon 3.0 GHz, 2.0GB RAM and
Linux. * = program ran out of memory.

However, as we see in Table 6, the approach does not yield significant savings in the context
of the UAV problem for small horizons. Because the space of observations in the problem is small
(3 distinct observations), a majority of these are often selected on sampling. Hence, for smaller
horizons such as 2 and 3, we did not observe a significant decrease in the size of the look ahead
reachability tree. However, the reduction in the look ahead trees for horizon 4 is enough to allow
the computation of the corresponding policy, though the run time is considerable. We were unable
to obtain it for the case with no RTS. Thus, the UAV problem reveals an important limitation of this
technique – it may not provide significant computational savings when the space of observations is
small, particularly for small horizons.
11.2 Empirical Performance
We present the performance profiles in Fig. 17 for the multiagent tiger problem when partial look
ahead reachability trees are built by sampling the observations. Similar to our previous experiments,
the performance profiles reflect the average of the rewards accumulated by following the action
prescribed by the root of the approximate policy tree that is built online. We plot the average reward
accumulated by i over 10 independent trials consisting of 100 runs each, as the number of the
observation samples, NΩi are gradually increased. Within each run, the location of the tiger and
j’s prior beliefs were sampled according to i’s prior level 1 belief. Since we have combined RTS
with the I-PF, in addition to varying NΩi , we also vary the number of particles, Np , employed to
approximate the beliefs. As expected of performance profiles, the expected reward initially increases
sharply, before flattening out as NΩi becomes large and the sampled observation distribution reaches
the true one. Reflecting intuition, the plots for Np = 100 exhibit slightly better expected rewards on
average than those for Np = 50. While the increase is not large, we note that it is consistent across
all observation samples. We also obtained the average reward over a similar number of trials when a
random policy (null hypothesis) is used for i. For horizon 3, the random policy gathered an average
reward of -84.785 (± 37.9847), and -108.5 (± 41.56) for horizon 4. Even for a small number of
observation samples, RTS does significantly better than the random policy thereby demonstrating
the usefulness of partial tree expansion. However, we note that a random policy is a poor baseline
for comparison and is used due to an absence of other similar approximations for I-POMDPs.
330

M ONTE C ARLO S AMPLING M ETHODS FOR A PPROXIMATING I-POMDP S

Multiagent Tiger Problem
0
Expected Reward

Expected Reward

0
-5
-10
-15
-20

-5
-10
-15
-20
-25

Np=50
Np=100

-25

Np=50
Np=100

-30
2

4

8

16

2

No. of Obs. Samples

4

8

16

No. of Obs. Samples

(a)

(b)

Figure 17: Performance profiles for the multiagent tiger problem for (a) horizon 3, and for (b)
horizon 4 when the look ahead tree is built by sampling observations.

Due to the small number of observations in the MM and UAV reconnaissance problems, we did
not observe significant increases in the expected reward as more observations are sampled. Hence,
we do not show the performance profiles for these problems.
We observed that the empirical expected reward is close to the optimal expected reward when
only a few distinct observations were sampled while building the reachability tree. This observation when combined with the computational savings demonstrated in Section 11.1 indicate that our
approximation approach is viable. Additionally, by varying the parameters Np and NΩi , we can
flexibly, though only partially, control the effects of both the curses of dimensionality and history,
respectively, on the solutions according to the application requirements. An interesting line of future
work is to investigate the interplay of these parameters.

12. Discussion
We described randomized methods for obtaining approximate solutions to finitely nested I-POMDPs
based on a novel generalization of particle filtering to multiagent settings. The generalization is
not straightforward because we are confronted with an interactive belief hierarchy in multiagent
settings. We proposed the interactive particle filter which descends the levels of interactive belief
hierarchies, and samples and propagates beliefs at each level. While sampling methods such as
particle filters are unable to completely avoid the curse of dimensionality, they serve to focus the
computational resources on those elements of the model that matter the most to the agent.
However, the interactive particle filter does not address the policy space complexity. Though
value iteration using sample sets is not guaranteed to converge asymptotically, we established useful error bounds for singly-nested I-POMDPs. Their generalization to multiply-nested beliefs has
proved to be difficult but we continue to investigate it. We provided performance profiles for the
multiagent tiger and the machine maintenance problems, and demonstrated scalability using the
larger UAV reconnaissance problem.
The experiments show that the approach saves on computation over the space of models but it
does not scale (usefully) to large values of time horizons and needs to be combined with methods
331

D OSHI & G MYTRASIEWICZ

that deal with the curse of history. In order to reduce the impact of the curse of history, we proposed
to sample observations while constructing the look ahead tree during the reachability analysis phase
of policy computation. This sparse sampling technique effectively reduces the branching factor of
the tree and allows computation of solutions for larger horizons as we demonstrated.
A method to further scale the approximation technique is to pick a subset of actions in addition to
sampling the observations while building the reachability tree. This further dampens the exponential
growth of the reachability tree with increasing horizons, and permits solutions for larger horizons.
However, this approach must be used cautiously – we do not want to leave out critical actions from
the policy.
Specific approaches to speeding up the computation also remain to be explored. As we mentioned, the number of particles in the interactive particle filter grows exponentially with the number
of nesting levels. In this regard, can we assign monotonically decreasing number of particles to
represent beliefs nested at deeper levels exploiting an insight from cognitive psychology that beliefs
nested at deeper levels are less likely to influence the optimal policy? Thus, if we decrease the particles sampled at the rate of r < 1, there will be no more than Np /(1 − r) particles in total, resulting
in computational savings.
Finally, in regards to the appropriate strategy level to use for nested models, we note the analogy with classical POMDPs, and the amount of detail and modeling information included therein.
Adding more nested level of modeling is analogous to including more details in the POMDP formulation. Then, the solution to an I-POMDP is optimal given the level of detail included in the model,
just like for classical POMDPs.

Acknowledgments
This research is supported in part by grant #FA9550-08-1-0429 from AFOSR and in part by grants
IRI-9702132 and IRI-0119270 from NSF. Versions of parts of this article have previously appeared
in (Doshi & Gmytrasiewicz, 2005a) and in (Doshi & Gmytrasiewicz, 2005b). We acknowledge all
the reviewers for their useful comments.

Appendix A. Multiagent Machine Maintenance Problem
We extend the traditional single agent version of the machine maintenance (MM) problem (Smallwood & Sondik, 1973) to a two-agent cooperative version. The original MM problem involved a
machine containing two internal components operated by a single agent. Either one or both components of the machine may fail spontaneously after each production cycle. If an internal component
has failed, then there is some chance that when operating upon the product, it will cause the product
to be defective. The agent may choose to manufacture the product (M) without examining it, examine the product (E), inspect the machine (I), or repair it (R) before the next production cycle. On an
examination of the product, the subject may find it to be defective. Of course, if more components
have failed, then the probability that the product is defective is greater.
The transition function, observation functions, and the reward functions for the two agents, i
and j, are as shown in Table 7. Apart from including two agents that operate on the machine during
the production cycle, we increased the nondeterminism of the original problem to make it more
realistic. This also has the beneficial effect of producing a richer policy structure.
332

M ONTE C ARLO S AMPLING M ETHODS FOR A PPROXIMATING I-POMDP S

hai , aj i
State not-defective defective
hM,M/Ei
*
0.5
0.5
hM,I/Ri
*
0.95
0.05
hE,M/Ei 0-fail
0.75
0.25
hE,M/Ei 1-fail
0.5
0.5
hE,M/Ei 2-fail
0.25
0.75
hE,I/Ri
*
0.95
0.05
hI/R,*i
*
0.95
0.05
hai , aj i
State not-defective defective
hM/E,Mi
*
0.5
0.5
hI/R,Mi
*
0.95
0.05
hM/E,Ei 0-fail
0.75
0.25
hM/E,Ei 1-fail
0.5
0.5
hM/E,Ei 2-fail
0.25
0.75
hI/R,Ei
*
0.95
0.05
h*,I/Ri
*
0.95
0.05
Observation functions for agents i and j.

hai , aj i
State 0-fail 1-fail 2-fail
hM/E,M/Ei 0-fail 0.81
0.18
0.01
hM/E,M/Ei 1-fail
0.0
0.9
0.1
hM/E,M/Ei 2-fail
0.0
0.0
1.0
hM,I/Ri
0-fail
1.0
0.0
0.0
hM,I/Ri
1-fail 0.95
0.05
0.0
hM,I/Ri
2-fail 0.95
0.0
0.05
hE,I/Ri
0-fail
1.0
0.0
0.0
hE,I/Ri
1-fail 0.95
0.05
0.0
hE,I/Ri
2-fail 0.95
0.0
0.05
hI/R,*i
0-fail
1.0
0.0
0.0
hI/R,*i
1-fail 0.95
0.05
0.0
hI/R,*i
2-fail 0.95
0.0
0.05
Transition function for agents i and j: Ti = Tj

hai , aj i
hM,Mi
hM,Ei
hM,Ii
hM,Ri
hE,Mi
hE,Ei
hE,Ii
hE,Ri
hI,Mi
hI,Ei
hI,Ii
hI,Ri
hR,Mi
hR,Ei
hR,Ii
hR,Ri

0-fail
1.805
1.555
0.4025
-1.0975
1.5555
1.305
0.1525
-1.3475
0.4025
0.1525
-1.0
-2.5
-1.0975
-1.3475
-2.5
-4

1-fail 2-fail
hai , aj i
0-fail
0.95
0.5
hM,Mi
1.805
0.7
0.25
hM,Ei
1.555
-1.025 -2.25
hM,Ii
0.4025
-1.525 -1.75
hM,Ri -1.0975
0.7
0.25
hE,Mi
1.555
0.45
0.0
hE,Ei
1.305
-1.275
-2.5
hE,Ii
0.1525
-1.775
-2.0
hE,Ri
-1.3475
-1.025 -2.25
hI,Mi
0.4025
-1.275
-2.5
hI,Ei
0.1525
-3.00
-5.00
hI,Ii
-1.0
-3.5
-4.5
hI,Ri
-2.5
-1.525 -1.75
hR,Mi -1.0975
-1.775
-2.0
hR,Ei
-1.3475
-3.5
-4.5
hR,Ii
-2.5
-4
-4
hR,Ri
-4
Reward functions for agents i and j.

1-fail
0.95
0.7
-1.025
-1.525
0.7
0.45
-1.275
-1.775
-1.025
-1.275
-3.00
-3.5
-1.525
-1.775
-3.5
-4

2-fail
0.5
0.25
-2.25
-1.75
0.25
0.0
-2.5
-2.0
-2.25
-2.5
-5.00
-4.5
-1.75
-2.0
-4.5
-4

Table 7: Transition, observation and reward functions for the multiagent MM problem.

Appendix B. Algorithm for Value Iteration on Sample Sets
We show the algorithm for computing an approximately optimal finite horizon policy tree given an
initial belief using value iteration when l > 0. When l = 0, the algorithm reduces to the POMDP
policy tree computation which is carried out exactly.8 The algorithm consists of the usual two steps:
compute the look ahead reachability tree for horizon T as part of the reachability analysis (see
Section 17.5 of Russell & Norvig, 2003) in lines 2-6 and perform value backup on the reachability
8. For large problems, exact POMDP solutions may be replaced with approximate ones. But in doing so, our error
bounds will no longer be applicable and those of the approximation technique will have to be considered.

333

D OSHI & G MYTRASIEWICZ

tree, in lines 7-28. The value of the beliefs at the leaves of the reachability tree is simply the one-step
expected reward resulting from the best action.
Function APPROXPOLICY(θk , l > 0) returns ∆(Ak )
(n)
(n)
1. eb0k,l ← {isk , n = 1...N |isk ∼ bk,l ∈ θk }
//Initial sampled belief
Reachability Analysis
2. reach(0) ← eb0k,l
3. for t ← 1 to T − 1 do
4.
reach(t) ← φ
t−1
5.
for all ebk,l
∈ reach(t − 1), ak ∈ Ak , ok ∈ Ωk do
∪
t−1
6.
reach(t) ← I-PARTICLEFILTER(ebk,l
, ak , ok , l)
Dynamic Programming
7. for t ← T − 1 downto 0 do
8.
for all ebtk,l ∈ reach(t) do
e T −t (h ebt , θbk i) ← −∞, OPT(h ebt , θbk i) ← φ
9.
U
k,l
k,l
10.
for all ak ∈ Ak do
e T −t (hebt , θbk i) ← 0
11.
U
ak
k,l
(n),t
(n)
12.
for all isk
= hs(n),t , θ−k i ∈ ebtk,l do
(n)
(n)
13.
P r(A−k |θ−k ) ← APPROXPOLICY(θ−k , l − 1)
14.
for all a−k ∈ A−k do
+ 1
(n)
(n),t
e T −t (hebt , θbk i) ←
, ak , a−k )P r(a−k |θ−k )
15.
U
ak
k,l
N R(s
16.
if (t < T ) then
17.
for all ok ∈ Ωk do
18.
sum ← 0, ebt+1
k,l ← reach(t + 1)[|Ωk |ak + ok ]
(n),t
(n)
19.
for all isk
= hs(n),t , θ−k i ∈ ebtk,l do
(n)
(n)
20.
P r(A−k |θ−k ) ← APPROXPOLICY(θ−k , l − 1)
t+1
21.
for all a−k ∈ A−k , s
∈ Sk do
+
(n)
t+1
22.
sum ← Ok (ok |s , ak , a−k )P r(is(n),t+1 |is(n),t , ak , a−k )P r(a−k |θ−k )
+
e T −t−1 (ebt+1 )
e T −t (hebt , θbk i) ←
γ × N1 × sum × U
23.
U
ak
k,l
k,l
e T −t (hebt , θbk i)) then
eaT −t (hebt , θbk i) ≥ previously best U
24.
if new value U
k,l
k,l
k
e T −t (hebt , θbk i) > U
e T −t (hebt , θbk i) then
25.
if (U
ak
k,l
k,l
e T −t (hebt , θbk i) ← U
e T −t (hebt , θbk i)
26.
U
ak
k,l
k,l
t
27.
OPT(hebk,l , θbk i) ← φ
∪
28.
OPT(hebtk,l , θbk i) ← ak
29. for all ak ∈ Ak do
30.
if (ak ∈ OPT(heb0k,l , θbk i) then
1
31.
P r(ak |θk ) ←
|OPT(heb0k,l ,θbk i)|
32.
else
33.
P r(ak |θk ) ← 0
34. return P r(Ak |θk )

Figure 18: Computing an approximately optimal finite horizon policy tree given a model containing
an initial sampled belief. When l = 0, the exact POMDP policy tree is computed.

334

M ONTE C ARLO S AMPLING M ETHODS FOR A PPROXIMATING I-POMDP S

References
Alon, N., & Spencer, J. (2000). The Probabilistic Method. John Wiley and Sons.
Aumann, R. J. (1999). Interactive epistemology i: Knowledge. International Journal of Game
Theory, 28, 263–300.
Battigalli, P., & Siniscalchi, M. (1999). Hierarchies of conditional beliefs and interactive epistemology in dynamic games. Journal of Economic Theory, 88(1), 188–230.
Bernstein, D. S., Givan, R., Immerman, N., & Zilberstein, S. (2002). The complexity of decentralized control of markov decision processes. Mathematics of Operations Research, 27(4),
819–840.
Bertsekas, D. (1995). Dynamic Programming and optimal control. Athena Scientific.
Boutilier, C., Dean, T., & Hanks, S. (1999). Decision-theoretic planning: Structural assumptions
and computational leverage. Journal of Artificial Intelligence Research, 11, 1–94.
Brandenburger, A., & Dekel, E. (1993). Hierarchies of beliefs and common knowledge. Journal of
Economic Theory, 59, 189–198.
Casbeer, D., Beard, R., McLain, T., Sai-Ming, L., & Mehra, R. (2005). Forest fire monitoring with
multiple small uavs. In American Control Conference, pp. 3530–3535.
Collins, M., Dasgupta, S., & R.E.Schapire (2002). A generalization of principal component analysis
to the exponential family. In Neural Information Processing Systems (NIPS), pp. 617–624.
Crisan, D., & Doucet, A. (2002). A survey of convergence results on particle filtering methods for
practitioners. IEEE Transactions on Signal Processing, 50(3), 736–746.
Daum, F., & Huang, J. (2002). Mysterious computational complexity of particle filters. In Conference on Signal and Data Processing of Small Targets, SPIE Proceedings Series, pp. 418–426,
Orlando, FL.
Dobson, A. (2002). An Introduction to Generalized Linear Models, 3rd Ed. Chapman and Hall.
Doshi, P. (2007). Improved state estimation in multiagent settings with continuous or large dscrete
state spaces. In Twenty Second Conference on Artificial Intelligence (AAAI), pp. 712–717.
Doshi, P., & Gmytrasiewicz, P. J. (2005a). Approximating state estimation in multiagent settings
using particle filters. In Autonomous Agents and Multi-agent Systems Conference (AAMAS),
pp. 320–327.
Doshi, P., & Gmytrasiewicz, P. J. (2005b). A particle filtering based approach to approximating
interactive pomdps. In Twentieth National Conference on Artificial Intelligence (AAAI), pp.
969–974.
Doshi, P., & Perez, D. (2008). Generalized point based value iteration for interactive pomdps. In
Twenty Third Conference on Artificial Intelligence (AAAI), pp. 63–68.
Doshi, P., Zeng, Y., & Chen, Q. (2007). Graphical models for online solutions to interactive pomdps.
In Autonomous Agents and Multiagent Systems Conference (AAMAS), pp. 809–816, Honolulu, Hawaii.
Doucet, A., de Freitas, N., Murphy, K., & Russell, S. (2000). Rao-blackwellised particle filtering
for dynamic bayesian networks. In Uncertainty in Artificial Intelligence (UAI), pp. 176–183.
335

D OSHI & G MYTRASIEWICZ

Doucet, A., Freitas, N. D., & Gordon, N. (2001). Sequential Monte Carlo Methods in Practice.
Springer Verlag.
Fagin, R., Halpern, J., Moses, Y., & Vardi, M. (1995). Reasoning about Knowledge. MIT Press.
Fox, D., Burgard, W., Kruppa, H., & Thrun, S. (2000). A probabilistic approach to collaborative
multi-robot localization. Autonomous Robots on Heterogenous Multi-Robot Systems, 8(3),
325–344.
Fudenberg, D., & Levine, D. K. (1998). The Theory of Learning in Games. MIT Press.
Gelman, A., Carlin, J., Stern, H., & Rubin, D. (2004). Bayesian Data Analysis, Second Edition.
Chapman and Hall/CRC.
Geweke, J. (1989). Bayesian inference in econometric models using monte carlo integration. Econometrica, 57, 1317–1339.
Gmytrasiewicz, P., & Doshi, P. (2005). A framework for sequential planning in multiagent settings.
Journal of Artificial Intelligence Research, 24, 49–79.
Gordon, N., Salmond, D., & Smith, A. (1993). Novel approach to non-linear/non-gaussian bayesian
state estimation. IEEE Proceedings-F, 140(2), 107–113.
Harsanyi, J. C. (1967). Games with incomplete information played by bayesian players. Management Science, 14(3), 159–182.
Hastings, W. K. (1970). Monte carlo sampling methods using markov chains and their applications.
Biometrika, 57, 97–109.
Heifetz, A., & Samet, D. (1998). Topology-free typology of beliefs. Journal of Economic Theory,
82, 324–341.
Kaelbling, L., Littman, M., & Cassandra, A. (1998). Planning and acting in partially observable
stochastic domains. Artificial Intelligence, 101, 99–134.
Kearns, M., Mansour, Y., & Ng, A. (2002). A sparse sampling algorithm for near-optimal planning
in large markov decision processes. Machine Learning, 49, 193–208.
Koller, D., & Lerner, U. (2001). Sampling in factored dynamic systems. In Doucet, A., Freitas,
N. D., & Gordon, N. (Eds.), Sequential Monte Carlo Methods in Practice. Springer.
Kramer, S. C., & Sorenson, H. (1988). Recursive bayesian estimation using piecewise constant
approximations. Automatica, 24, 789–801.
Li, M., & Vitanyi, P. (1997). An Introduction to Kolmogorov Complexity and its Applications.
Springer.
Mertens, J., & Zamir, S. (1985). Formulation of bayesian analysis for games with incomplete
information. International Journal of Game Theory, 14, 1–29.
Murphy, D., & Cycon, J. (1998). Applications for mini vtol uav for law enforcement. In SPIE
3577:Sensors, C3I, Information, and Training Technologies for Law Enforcement.
Ortiz, L., & Kaelbling, L. (2000). Sampling methods for action selection in influence diagrams. In
Seventeenth National Conference on Artificial Intelligence (AAAI), pp. 378–385, Austin, TX.
Paquet, S., Tobin, L., & Chaib-draa, B. (2005). An online pomdp algorithm for complex multiagent
environments. In International Conference on Autonomous Agents and Multiagent Systems
(AAMAS), pp. 970–977, Utrecht, Netherlands.
336

M ONTE C ARLO S AMPLING M ETHODS FOR A PPROXIMATING I-POMDP S

Pineau, J., Gordon, G., & Thrun, S. (2006). Anytime point-based value iteration for large pomdps.
Journal of Artificial Intelligence Research, 27, 335–380.
Poupart, P., & Boutilier, C. (2003). Value-directed compression in pomdps. In Neural Information
Processing Systems (NIPS), pp. 1547–1554.
Poupart, P., & Boutilier, C. (2004). Vdcbpi: An approximate algorithm scalable for large-scale
pomdps. In Neural Information Processing Systems (NIPS), pp. 1081–1088.
Poupart, P., Ortiz, L., & Boutilier, C. (2001). Value-directed sampling methods for belief monitoring
in pomdps. In Uncertainty in Artificial Intelligence (UAI), pp. 453–461.
Ross, S., Pineau, J., Paquet, S., & Chaib-draa, B. (2008). Online planning algorithms for pomdps.
Journal of Artificial Intelligence Research (JAIR), 32, 663–704.
Roy, N., Gordon, G., & Thrun, S. (2005). Finding approximate pomdp solutions through belief
compression. Journal of Artificial Intelligence Research (JAIR), 23, 1 – 40.
Russell, S., & Norvig, P. (2003). Artificial Intelligence: A Modern Approach (Second Edition).
Prentice Hall.
Saad, Y. (1996). Iterative Methods for Sparse Linear Systems. PWS, Boston.
Sarris, Z. (2001). Survey of uav applications in civil markets. In IEEE Mediterranean Conference
on Control and Automation, p. 11.
Schmidt, J. P., Siegel, A., & Srinivasan, A. (1995). Chernoff-hoeffding bounds for applications with
limited independence. SIAM Journal on Discrete Mathematics, 8(2), 223–250.
Seuken, S., & Zilberstein, S. (2007). Improved memory bounded dynamic programming for decentralized pomdps. In Uncertainty in Artificial Intelligence (UAI), pp. 2009–2015.
Seuken, S., & Zilberstein, S. (2008). Formal models and algorithms for decentralized decision
making under uncertainty. Journal of Autonomous Agents and Multiagent Systems, 17(2),
190–250.
Smallwood, R., & Sondik, E. (1973). The optimal control of partially observable markov decision
processes over a finite horizon. Operations Research, 21, 1071–1088.
Sorenson, H. W., & Alspach, D. L. (1971). Recursive bayesian estimation using gaussian sums.
Automatica, 7, 465–479.
Sorenson, H. W. (Ed.). (1985). Kalman Filtering: Theory and Application. IEEE Press, New York.
Thrun, S. (2000). Monte carlo pomdps. In Neural Information Processing Systems (NIPS), pp.
1064–1070.
Tsitsiklis, J., & Roy, B. V. (1996). Feature-based methods for large scale dynamic programming.
Machine Learning, 22, 59–94.
Wang, T., Lizotte, D., Bowling, M., & Schuurmans, D. (2005). Bayesian sparse sampling for online
reward optimization. In International Conference on Machine Learning (ICML), pp. 956–
963.

337

Journal of Artificial Intelligence Research 34 (2009) 61-88

Submitted 04/08; published 02/09

Asynchronous Forward Bounding for Distributed COPs
Amir Gershman
Amnon Meisels
Roie Zivan

AMIRGER @ CS . BGU . AC . IL
AM @ CS . BGU . AC . IL
ZIVANR @ CS . BGU . AC . IL

Department of Computer Science,
Ben-Gurion University of the Negev,
Beer-Sheva, 84-105, Israel

Abstract
A new search algorithm for solving distributed constraint optimization problems (DisCOPs)
is presented. Agents assign variables sequentially and compute bounds on partial assignments
asynchronously. The asynchronous bounds computation is based on the propagation of partial
assignments. The asynchronous forward-bounding algorithm (AFB) is a distributed optimization
search algorithm that keeps one consistent partial assignment at all times. The algorithm is described in detail and its correctness proven. Experimental evaluation shows that AFB outperforms
synchronous branch and bound by many orders of magnitude, and produces a phase transition as
the tightness of the problem increases. This is an analogous effect to the phase transition that has
been observed when local consistency maintenance is applied to MaxCSPs. The AFB algorithm is
further enhanced by the addition of a backjumping mechanism, resulting in the AFB-BJ algorithm.
Distributed backjumping is based on accumulated information on bounds of all values and on processing concurrently a queue of candidate goals for the next move back. The AFB-BJ algorithm is
compared experimentally to other DisCOP algorithms (ADOPT, DPOP, OptAPO) and is shown to
be a very efficient algorithm for DisCOPs.

1. Introduction
The Distributed Constraint Optimization Problem (DisCOP) is a general framework for distributed
problem solving that has a wide range of applications in Multi-Agent Systems and has generated
significant interest from researchers (Modi, Shen, Tambe, & Yokoo, 2005; Zhang, Xing, Wang, &
Wittenburg, 2005; Petcu & Faltings, 2005a; Mailler & Lesser, 2004; Ali, Koenig, & Tambe, 2005;
Silaghi & Yokoo, 2006). DisCOPs are composed of agents, each holding one or more variables.
Each variable has a domain of possible value assignments. Constraints among variables (possibly
held by different agents) assign costs to combinations of value assignments. Agents assign values to
their variables and communicate with each other, attempting to generate a solution that is globally
optimal with respect to the costs of the constraints (Modi et al., 2005; Petcu & Faltings, 2004).
There is a wide scope of motivation for research on DisCOP, since distributed COPs are an
elegant model for many every day combinatorial problems that are distributed by nature. Take for
example a large hospital that is composed of many wards. Each ward constructs a weekly timetable
assigning its nurses to shifts. The construction of a weekly timetable involves solving a constraint
optimization problem for each ward. Some of the nurses in every ward are qualified to work in
the Emergency Room. Hospital regulations require a certain number of qualified nurses (e.g. for
Emergency Room) in each shift. This imposes constraints among the timetables of different wards
and generates a complex Distributed COP (Solotorevsky, Gudes, & Meisels, 1996).
c
2009
AI Access Foundation. All rights reserved.

G ERSHMAN , M EISELS , & Z IVAN

Another example is the sensor networks tracking problem (Zhang, Xing, Wang, & Wittenburg,
2003; Zhang et al., 2005), in which the task is to assign sensors to tracking targets, such that the
maximal number of the targets will be tracked by the sensor collection. This too can be solved using
the DisCOP model.
DisCOP modeling can also solve problems like log based reconciliation (Chong & Hamadi,
2006), in which copies of a data base exist in several physical locations. Users perform actions on
these data base copies, each user on its own local copy. The actions cause the data base to change,
so only initially all copies are identical, but later actions change some of them and they are no longer
identical. Logs of all user actions are kept. The problem is how to merge these logs, into a single log
that keeps as many of the actions as possible. It is not always possible to keep all local logs intact,
since actions are constrained with other actions (for example you can not reconcile the deletion of
an item from the database and a later print or update of it).
DisCOPs represent real life problems that cannot or should not be solved centrally for several
reasons, among them are lack of autonomy, single point of failure and privacy of agents. In the
hospital wards example, wards want to maintain a degree of autonomy over their local problems
involving the constraints of every single nurse. In the sensor example, the sensors have a very small
memory and computing power and therefore cannot solve the problem in a centralized fashion. In
the database example, centralization is possible, but issues such as network bottleneck, computing
power and single point of failure encourage looking for a distributed solution.
The present paper proposes a new distributed search algorithm for DisCOPs, Asynchronous
Forward-Bounding (AFB). In the AFB algorithm agents assign their variables and generate a partial
solution sequentially. The innovation of the proposed algorithm lies in propagating partial solutions asynchronously. Propagation of partial solutions enables asynchronous updating of bounds on
their cost, and early detection of a need to backtrack, hence the algorithm’s name AFB. This form
of propagating bounds asynchronously turns out to generate a very efficient form of concurrent
computation by all the participating agents. More efficient than algorithms that use asynchronous
assignment processes, especially on hard instances of DisCOPs.
The overall framework of the AFB algorithm is based on a Branch and Bound scheme. Agents
extend a partial solution as long as the lower bound on its cost does not exceed the global bound,
which is the cost of the best solution found so far. In the proposed AFB algorithm, the state of the
search process is represented by a data structure called Current Partial Assignment (CPA). The CPA
starts empty at some initializing agent that records its assignments on it and sends it to the next agent.
The cost of a CPA is the sum on the costs of constraints it includes. Besides the current assignment
cost, the agents maintain on a CPA a lower bound which is updated according to information they
receive from yet unassigned agents. Each agent which receives the CPA, adds assignments of its
local variables to the partial assignment on the received CPA, if an assignment with a lower bound
smaller than the current global upper bound can be found. Otherwise, it backtracks by sending the
CPA to a former agent to revise its assignment.
An agent that succeeds to extend the assignment on the CPA sends forward copies of the updated
CPA, requesting all unassigned agents to compute lower bound estimations on the cost of the partial
assignment. The assigning agent will receive these estimations asynchronously over time and use
them to update the lower bound of the CPA.
Gathering updated lower bounds from future assigning agents, may enable an agent to discover
that the lower bound of the CPA it sent forward is higher than the current upper bound (i.e. inconsistent). This discovery triggers the creation of a new CPA which is a copy of the CPA it sent
forward. The agent resumes the search by trying to replace its inconsistent assignment. The time
62

A SYNCHRONOUS F ORWARD B OUNDING FOR D ISTRIBUTED COP S

stamp mechanism proposed by Nguyen, Sam-Hroud, and Faltings (2004) and used by Meisels and
Zivan (2007) is used by agents to determine the most updated CPA and to discard obsolete CPAs.
The concurrency of the AFB algorithm is achieved by the fact that forward-bounding is performed concurrently and asynchronously by all agents. This form of asynchronicity is similar to
that employed by the Asynchronous Forward-Checking (AFC) algorithm for distributed constraint
satisfaction problems (DisCSPs) (Meisels & Zivan, 2006; Meseguer & Jimenez, 2000). When AFB
is enhanced with backjumping (Zivan & Meisels, 2007), the resulting algorithm performs concurrently distributed forward bounding and backjumping and prunes the search space of DisCOPs very
efficiently. This is demonstrated by the extensive experimental evaluation in Section 6 where AF B
demonstrates a phase transition on randomly generated DisCOPs (Larrosa & Schiex, 2004). The
extensive evaluation includes comparisons of the performance of AF B to that of the best DisCOP
search algorithms. These include asynchronous branch and bound like ADOPT (Modi et al., 2005),
as well as algorithms that are based on other principles - DPOP (Petcu & Faltings, 2005a) that uses
two passes on a pseudo-tree and Opt AP O,that divides the DisCOP into sub-problems (Mailler &
Lesser, 2004).
The plan of the paper is as follows. Distributed Constraint Optimization are presented in Section 2. In Section 3, the AF B algorithm in full details is presented. In Section 4 a version of the
AF B algorithm which is enhanced with conflict directed backjumping (CBJ) is presented. A correctness proof of the AF B algorithm is presented in Section 5. In Section 6 an extensive empirical
evaluation of the AF B algorithm is presented. AF B is compared with the state of the art DisCOP
algorithms, ADOP T which like AF B does not include centralization of the problem’s data and
DP OP and Opt AP O (Petcu & Faltings, 2005a; Mailler & Lesser, 2004), which are based on very
different principles. Our Conclusions are presented in Section 7.

2. Distributed Constraint Optimization
Formally, a DisCOP is a tuple < A, X , D, R >. A is a finite set of agents A1 , A2 , ..., An . X is a
finite set of variables X1 ,X2 ,...,Xm . Each variable is held by a single agent (an agent may hold more
than one variable). D is a set of domains D1 , D2 ,...,Dm . Each domain Di contains the finite set of
values which can be assigned to variable Xi . R is a set of relations (constraints). Each constraint
C ∈ R defines a none-negative cost for every possible value combination of a set of variables, and
is of the form C : Di1 × Di2 × . . . × Dik → R+ ∪ {0}. A binary constraint refers to exactly two
variables and is of the form Cij : Di × Dj → R+ ∪ {0}. A binary DisCOP is a DisCOP in which
all constraints are binary. An assignment (or a label) is a pair including a variable, and a value from
that variable’s domain. A partial assignment (PA) is a set of assignments, in which each variable
appears at most once. vars(PA) is the set of all variables that appear in PA, vars(P A) = {Xi |
∃a ∈ Di ∧ (Xi , a) ∈ P A}. A constraint C ∈ R of the form C : Di1 × Di2 × . . . × Dik → R+ ∪ {0}
is applicable to PA if Xi1 , Xi2 , . . . , Xik ∈ vars(P A). The cost of a partial assignment PA is the
sum of all applicable constraints to PA over the assignments in PA. A full assignment is a partial
assignment that includes all the variables (vars(P A) = X ). The goal is to find a full assignment of
minimal cost.
In this paper, we will assume each agent owns a single variable, and use the term “agent”
and “variable” interchangeably, and assume agent Ai holds variable Xi (Modi et al., 2005; Petcu &
Faltings, 2005a; Mailler & Lesser, 2004). We will assume that constraints are at most binary and the
delay in delivering a message is finite (Yokoo, 2000a; Modi et al., 2005). Furthermore, we assume
a static final order on the agents, known to all agents participating in the search process (Yokoo,
63

G ERSHMAN , M EISELS , & Z IVAN

Figure 1: An example DisCOP. Each variable has two values R and B, all constraints are of the
same form as shown in the table to the left.

2000a). These assumptions are commonly used by DisCSP and DisCOP algorithms (Yokoo, 2000a;
Modi et al., 2005).
Example 1 An example of a DisCOP is presented in figure 1. There are 4 variables, each variable
is held by a different agent. The domains of all variables contain exactly the two values R and B.
Lines between variables represent (binary) constraints. The cost of these constraints is shown in the
table to the left. A partial assignment of {(X1 , R)} has a cost of zero, since there is no constraint
applicable to it. A partial assignment of {(X1 , R), (X4 , R)} also has a cost of zero, since there is
no constraint applicable to it. A partial assignment of {(X1 , R), (X2 , R)} has a cost of two, due to
the constraint C1,2 . A partial assignment of {(X1 , R), (X2 , R), (X3 , B)} has a cost of four, due to
the constraints C1,2 , C2,3 , C1,3 . One solution is {(X1 , R), (X2 , B), (X3 , R), (X4 , R)} which has a
cost of five. This is a solution since there is no other full assignment of lower cost.

3. Asynchronous Forward Bounding
In the AFB algorithm a single most up-to-date current partial assignment is passed among the agents.
Agents assign their variables only when they hold the up-to-date CPA.
The CPA is a unique message that is passed between agents, and carries the partial assignment
that agents attempt to extend into a complete and optimal solution by assigning their variables on
it. The CPA also carries the accumulated cost of constraints between all assignments it contains, as
well as a unique time-stamp.
Due to the asynchronous nature of the algorithm, multiple CPAs may be present at any instant,
however only a single CPA includes the most update to date partial assignment. This CPA has the
highest timestamp.
Only one agent performs an assignment on a single CPA at any time. Copies of the CPA are
sent forward and are concurrently processed by multiple agents. Each unassigned agent computes a
lower bound on the cost of assigning a value to its variable, and sends this bound back to the agent
64

A SYNCHRONOUS F ORWARD B OUNDING FOR D ISTRIBUTED COP S

which performed the assignment. The assigning agent uses these bounds to prune sub-spaces of the
search-space which do not contain a full assignment with a cost lower than the best full assignment
found so far. A total order among agents is assumed (A1 is assumed to be the first agent in the order,
and An is assumed to be the last).
In more detail, every agent that adds its assignment to the CPA sends forward copies of the CPA,
in messages we term FB CPA, to all agents whose assignments are not yet on the CPA. An agent
receiving an FB CPA message computes a lower bound on the cost increment caused by adding
an assignment to its variable. This estimated cost is sent back to the agent who sent the FB CPA
message via FB ESTIMATE messages. The computation of this bound is detailed in section 3.1.
Notice that it is possible that the assigning agent already sent its CPA forward by the time the
estimations are received. Should the estimations indicate that the CPA exceeds the bound, the agent
will generate a new CPA, with a different local assignment (and a higher timestamp associated
with it) and continue the search with this new CPA. The timestamping mechanism insures that
the obsolete CPA will (eventually) be discarded regardless of its current location. The timestamp
mechanism is described in section 3.3.
3.1 AFB - Computing the Lower Bound Estimation On Cost Increment
The computation of the lower bound on the cost increment caused by adding an assignment to the
agent’s local variable is done as follows.
Denote by cost((i, v), (j, u)) the cost of assigning Ai = v and Aj = u. For each agent Ai and
each value in its domain v ∈ Di , we denote the minimal cost of the assignment (i,v) incurred by
an agent Aj by hj (v) = minu∈Dj (cost((i, v), (j, u))). We define h(v), the total cost of assigning
the value v, to be the sum of hj (v) over all j > i. Intuitively, h(v) is a lower bound on the cost
of constraints involving the assignment Ai = v and all agents Aj such that j > i. Note that this
bound can be computed once per agent, since it is independent of the assignments of higher priority
agents.
An agent Ai , which receives an F B CP A message, can compute for every v ∈ Di both the
cost increment of assigning v as its value, i.e. the sum of the cost that v has with the assignments
included in the CP A, and h(v). The sum of these, is denoted by f (v). The lowest calculated f (v)
among all values v ∈ Di is chosen to be the lower bound estimation on the cost increment by agent
Ai .
Figure 2 presents a constraint network. Large ovals represent variables while small circles represent values. In the presented constraint network, A1 already assigned the value v1 and A2 , A3 , A4
are unassigned. Let us assume that the cost of every constraint is one. The cost of v3 will increase
by one due to its constraint with the current assignment thus f (v3 ) = 1. Since v4 is constrained with
both v8 and v9 , assigning this value will trigger a cost increment when A4 performs an assignment.
Therefore h(v4 ) = 1 is an admissible lower bound of the cost of the constraints between this value
and lower priority agents. Since v4 does not conflict with assignments on the CPA, f (v4 ) = 1 as
well. f (v5 ) = 3 because this assignment conflicts with the assignment on the CPA and in addition
conflicts with all the values of the two remaining agents.
Since h(v) takes into account only constraints of Ai with lower priority agents (Aj s.t. j > i),
unassigned lower priority agents do not need to estimate their cost of constraints with Ai . Therefore,
these estimations can be accumulated and summed up by the agent which initiated the forward
bounding process to compute a lower bound on the cost of a complete assignment extended from
the CPA.
65

G ERSHMAN , M EISELS , & Z IVAN

Figure 2: A simple DisCOP, demonstration
More formally we can define:
Definition 1 CPA is the current partial assignment, containing the assignments made by agents
A1 , . . . , Ai−1 .
Let us define the notions of past, local and future costs in definitions 2, 3 and 4.
Definition 2 PC (Past-Cost) is the added cost of assignments made by higher priority agents on the
CPA (the costs incurred by agents A1 , . . . , Ai−1 .
Definition 3 LC(v) (Local-Cost) is the cost incurred to the CPA if Ai would assign the value v and
add it to the CPA. Therefore,
X
LC(v) =
cost((i, v), (j, w))
(Aj ,w)∈CP A

Definition 4 FC(v) (Future-Cost) is the sum of all lower bounds on cost increments caused by
agents Ai+1 , . . . , An for the CPA with the additional assignment of Ai = v.
X
F C(v) =
minw∈Dj (f (w)), s.t Ai = v added to CP A
j>i

The above definitions allow us to compute a lower bound on the cost of any full assignment
extended from the CPA, and use this bound in order to prune parts of the search space. An agent
(Ai ) which receives the CPA, can question, what be its lower bound if it would be extended with
an assignment of Ai = v. PC and LC(v) are both known to the agent, and FC(v) can be computed
over time, by requesting future agents (lower priority agents) to compute their lower bounds and
send them back to Ai . The sum PC + LC(v) + FC(v) composes this lower bound, and can be used
to prune search spaces. This can happen when the agent knows that a full assignment was already
66

A SYNCHRONOUS F ORWARD B OUNDING FOR D ISTRIBUTED COP S

found with cost lower than this sum, and therefore exploring this search-space would not lead to
any better cost solutions.
Thus, asynchronous forward bounding enables agents an early detection of partial assignments
that cannot be extended into complete assignments with cost smaller than the known upper bound,
and initiate backtracks as early as possible.
3.2 AFB - Algorithm Description
The AFB algorithm is run on each of the agents in the DisCOP. Each agent first calls the procedure
init and then responds to messages until it receives a T ERM IN AT E message. The algorithm
is presented in Figure 3.1. The computation of bounds, and the time-stamping mechanism are not
shown, as they are explained in the text.
In the initialization, each agent updates B to be the cost of the best full assignment found so far
and since no such assignment was found, it is set to infinity (line 1). Only the first agent (A1 ) creates
an empty CPA and then begins the search process by calling assign CPA (lines 3-4), in order to find
a value assignment for its variable.
An agent receiving a CPA (when received CPA MSG), first makes sure it is relevant. The time
stamp mechanism is used to determine the relevance of the CPA and will be explained in Section 3.3.
If the CPA’s time-stamp reveals that it is not the most up to date CPA, the message is discarded.
In such a case, the agent processing the message has already received a message implying that an
assignment of some agent which has a higher priority than itself, has been changed. When the
message is not discarded, the agent saves the received PA in its local CPA variable (line 7). Then,
the agent checks that the received PA (without an assignment to its own variable) does not exceed
the allowed cost B (lines 8-10). If it does not exceed the bound, it tries to assign a value to its
variable (or replace its existing assignment in case it has one already) by calling assign CPA (line
13). If the bound is exceeded, a backtrack is initiated (line 11) and the CPA is sent to a higher
priority agent, since the cost is already too high (even without an assignment to its variable).
Procedure assign CPA attempts to find a value assignment, for the current agent, within the
bounds of the current CPA. First, estimates related to prior assignments are cleared (line 19). Next,
the agent attempts to assign every value in its domain it did not already try. If the CPA arrived
without an assignment to its variable, it tries every value in its domain. Otherwise, the search for
such a value is continued from the value following the last assigned value. The assigned value must
be such that the sum of the cost of the CPA and the lower bound of the cost increment caused by
the assignment will not exceed the upper bound B (lines 20-22). If no such value is found, then
the assignment of some higher priority agent must be altered, and so backtrack is called (line 23).
Otherwise, the agent assigns the selected value on the CPA.
When the agent is the last agent (An ), a complete assignment has been reached, with an accumulated cost lower than B, and it is broadcasted to all agents (line 27). This broadcast will inform
the agents of the new bound for the cost of a full assignment, and cause them to update their upper
bound B.
The agent holding the CPA (An ) continues the search, by updating its bound B, and calling
assign CPA (line 29). The current value will not be picked by this call, since the CPA’s cost with
this assignment is now equal to B, and the procedure requires the cost to be lower than B. So the
agent will continue the search, testing other values, and backtracking in case they do not lead to
further improvement.
67

G ERSHMAN , M EISELS , & Z IVAN

procedure init:
1. B ← ∞
2. if (Ai = A1 )
3.
generate CP A()
4.
assign CP A()
when received (FB CPA, Aj , P A)
5. f ← estimation based on the received P A.
6. send (F B EST IM AT E, f , P A, Ai ) to Aj
when received (CPA MSG, P A)
7. CP A ← P A
8. T empCP A ← P A
9. if T empCP A contains an assignment to Ai , remove it
10. if (T empCP A.cost ≥ B)
11.
backtrack()
12. else
13. assign CP A()
when received (FB ESTIMATE, estimate, P A , Aj )
14. save estimate
15. if ( CPA.cost + all saved estimates) ≥ B )
16. assign CP A()
when received (NEW SOLUTION, P A)
17. B CP A ← P A
18. B ← P A.cost
procedure assign CPA:
19. clear estimations
20. if CP A contains an assignment Ai = w, remove it
21. iterate (from last assigned value) over Di until found
v ∈ Di s.t. CP A.cost + f (v) < B
22. if no such value exists
23.
backtrack()
24. else
25.
assign Ai = v
26. if CP A is a full assignment
27.
broadcast (NEW SOLUTION, CPA )
28.
B ← CP A.cost
29.
assign CP A()
30. else
31.
send(CPA MSG, CPA) to Ai+1
32.
forall j > i
33.
send(FB CPA, Ai , CPA) to Aj
procedure backtrack:
34. clear estimates
35. if (Ai = A1 )
36.
broadcast(TERMINATE)
37. else
38.
send(CPA MSG, CPA) to Ai−1

Figure 3: The procedures of the AFB Algorithm

68

A SYNCHRONOUS F ORWARD B OUNDING FOR D ISTRIBUTED COP S

When the agent holding the CPA is not the last agent (line 30), the CPA is sent forward to the
next unassigned agent, for additional value assignment (line 31). Concurrently, forward bounding
requests (i.e. FB CPA messages) are sent to all lower priority agents (lines 32-33).
An Agent receiving a forward bounding request (when received FB CPA) from agent Aj , again
uses the time-stamp mechanism to ignore irrelevant messages. Only if the message is relevant, then
the agent computes its estimate (lower bound) of the cost incurred by the lowest cost assignment to
its variable (line 5). The exact computation of this estimation was described in Section 3.1 (it is the
minimal f (v) over all v ∈ Di ). This estimation is then attached to the message and sent back to the
sender, as a FB ESTIMATE message.
An agent receiving a bound estimation (when received FB ESTIMATE) from a lower priority
agent Aj (in response to a forward bounding message) ignores it if it is an estimate to an already
abandoned partial assignment (identified by using the time-stamp mechanism). Otherwise, it saves
this estimate (line 14) and checks if this new estimate causes the current partial assignment to exceed
the bound B (line 15). In such a case, the agent calls assign CP A (line 16) in order to change its
value assignment (or backtrack in case a valid assignment cannot be found).
The call to backtrack is made whenever the current agent cannot find a valid value (i.e. below
the bound B). In such a case, the agent clears its saved estimates, and sends the CPA backwards to
agent Ai−1 (line 38). If the agent is the first agent (nowhere to backtrack to), the terminate broadcast
ends the search process in all agents (line 36). The algorithm then reports that the optimal solution
has a cost of B, and the full assignment with such a cost is B CP A.
3.3 The Time-Stamp Mechanism
As mentioned previously, AFB uses a time-stamp mechanism (Nguyen et al., 2004; Meisels &
Zivan, 2007) to determine the relevance of the CPA. The requirements from this mechanism are
that given two messages with two different partial assignments, it must determine which one of
them is obsolete. An obsolete partial assignment is one that was abandoned by the search process
because one of the assigned agents has changed its assignment. This requirement is accomplished by
the time-stamping mechanism in the following way. Each agent keeps a local running-assignment
counter. Whenever it performs an assignment it increments its local counter. Whenever it sends
a message containing its assignment, the agent copies its current counter onto the message. Each
message holds a vector containing the counters of the agents it passed through. The i-th element
of the vector corresponds to Ai ’s counter. This vector is in fact the time-stamp. A lexicographical
comparison of two such vectors will reveal which time-stamp is more up-to-date.
Each agent saves a copy of what it knows to be the most up-to-date time-stamp. When receiving
a new message with a newer time-stamp, the agent updates its local saved “latest” time-stamp.
Suppose agent Ai receives a message with a time-stamp that is lexicographically smaller than the
locally saved “latest”, by comparing the first i − 1 elements of the vector. This means that the
message was based on a combination of assignments which was already abandoned and this message
is discarded. Only when the message’s time-stamp in the first i − 1 elemental is equal or greater
than the locally saved ”best” time-stamp is the message processed further.
The vector’s counters might appear to require a lot of space, as the number of assignments can
grow exponentially in the number of agents. However, if the agent (Ai ) resets its local counter to
zero each time the assignments of higher priority agents are altered, the counters will remain small
(log of the size of the value domain), and the mechanism will remain correct.
69

G ERSHMAN , M EISELS , & Z IVAN

3.4 AFB - Example Run
Suppose we run AFB on the DisCOP in figure 1. X1 will create an empty CPA, assign its first value
R and pass the CPA to X2 . The CPA will travel from X2 , to X3 and finally to X4 , with each agent
assigning its first value (R) on it along the way until finally at X4 we will have a full assignment
with total accumulated cost of 8. This cost will be broadcasted to all agents (line 27 in figure 3.1) as
the new upper bound (instead of infinity). Next, X4 will call the assign CP A procedure (line 29).
This call will result in a new assignment for X4 , with the value B, since the resulting full assignment
will have a cost of only 7. This will cause another broadcast update of the upper bound and another
call to assign CP A. In this next call, X4 will have an empty domain and be forced to backtrack the
CPA to X3 . This CPA contains the assignments X1 = X2 = X3 = R, with a total accumulated cost
of 6 which is below the upper bound. Therefore X3 will call its assign CP A (line 13). Examining
its remaining values, X3 explores the assignment of B which will result in a CPA with a cost of 4
(line 21), which is below the current upper bound B. The CPA is sent to X4 (line 31). X4 calls the
assign CP A procedure (line 13). The value R will result in a CPA with a cost of 6, which is better
than the upper bound B of 7, and therefore is broadcasted (line 27). The next value, B, explored
by X4 results in a CPA with cost 5, which is also broadcasted. The CPA is sent backwards to X3 .
X3 has no more values to try, so it also backtracks the CPA, to X2 . X2 assigns its next value, B,
and sends the CPA to X3 . In addition X2 also sends copies of the CPA in FB CPA messages to X3
and X4 (line 33). If X3 now receives this FB CPA, it computes an estimation of 3 (because if X3 is
R then it would increase this CPA’s cost by 3 and if it were B it would increase it by 4), and sends
this information back to X2 (line 6). Suppose X4 also receives his F B CP A, it then replies with
an estimation of 1. While the CPA explores the sub-search in which X2 = B (passing between X3
and X4 ), these estimations arrive at X2 . X2 saves these estimations and adds them up. This leads to
the discovery that a backtrack is needed, since the CPA’s cost is 1 (because X1 = R, X2 = B) with
the additional estimations of 4 results in a sum equal to the upper bound B (line 15). Therefore,
X2 abandons its assignment and attempts to assign its next value (calling assign CP A - line 16).
Since X2 has no values, this call results in a backtrack (line 23). The CPA sent from this backtrack
has a higher timestamp value than the CPA previously sent forward by X2 , and the former CPA
would eventually be discarded.
3.5 Discussion - Concurrency, Robustness, Privacy and Asynchronicity
At any point in time during the run of AFB, there is a single most-up-to-date CPA in the system.
Each agent adds an assignment when it holds it, so assignments are performed sequentially. One
might think that this would necessarily result in poor performance, as the search process does not try
to take advantage of the existing multiple computational resources available to it. The concurrency
of AFB comes from the use of the forward-bounding mechanism. While the CPA is held by one
agent, many copies of it are sent forward, and a collection of agents compute concurrently lower
bounds for that CPA. When the CPA advances to the next agent, again this process repeats, and so
the unassigned agents are constantly kept working, either when they receive the CPA, or when they
need to compute bounds for some other partial assignment.
This degree of asynchronicity is similar to that employed by the Asynchronous Forward-Checking
AFC algorithm for DisCSPs (Meseguer & Jimenez, 2000; Meisels & Zivan, 2006). AFC performs
a similar process in which the agents receive ”forward-checking” messages by agents which performed assignments. The unassigned agents perform forward-checking (checking they have at least
one value which is consistent with all previous assignments). In AFB these agents compute a lower
70

A SYNCHRONOUS F ORWARD B OUNDING FOR D ISTRIBUTED COP S

bound on their local cost increment due to all assignments made by previous agents. Due to this
similarity we named our algorithm Asynchronous Forward-Bounding.
AFB’s approach is quite different from that used by asynchronous assignments algorithms such
as ADOPT or ABT (Modi et al., 2005; Bessiere, Maestre, Brito, & Meseguer, 2005). In these
algorithms the search process attempts to perform assignments concurrently by the collection of
agents. Since many agents are assigning their variables simultaneously, there is a probability that
must be handled by the algorithm, that the current agent’s view of assignments made by other agents
is incorrect. This is due to the fact that agents concurrently alter their assignments. The algorithm
must be able to deal with this uncertainty.
A search process which performs assignments asynchronously may be expected to save time
since agents need not wait for all assignments of past agents to reach them, as is done by a sequentially assigning algorithm. However, asynchronously assigning algorithms must also deal with
inconsistencies caused by message delay. For example, if several higher priority agents change
their assignments and only some of the messages are received (the others are delayed) computation
performed will be based on this inconsistent agent view. This type of scenario, which has computation based on an inconsistent partial assignment, is completely avoided by sequentially assigning
algorithms.
One variation of the AFB algorithm has agents which sent out FB-CPA messages, send these
messages only to the subset of the target agents which have a direct constraint with the sending
agent. This may be useful if the communication between agents is limited (agents may only communicate with agents with whom they have a direct conflict) and would keep the algorithm correct.
This change may have two effects. First, less agents will return bounds to the sending agents. These
bounds can be significant (greater than zero) since they take into account constraints with assignments of previous agents (which they may be conflicted with) and also constraints between the
receiving agent and agents of lower priority (constraint between unassigned agents). Receiving less
lower bounds would not invalidate the correctness of the algorithm but it may cause the search process to needlessly explore sub-spaces which could have been discovered to be dead-ends. Second,
the detection of obsolete CPAs may be delayed since less agents receive a higher timestamp (which
the FB-CPA may contain). The mechanism would remain correct since eventually another FB-CPA
or the CPA itself would reach an agent which did not receive the FB-CPA, however this may take
more time than a single ”cycle” of messages (in other words, more time than the travel time of a
single message between two agents). The AFB algorithm was intentionally presented as an algorithm which sends out FB messages to all unassigned agents, since no constraint on communication
between agents is assumed. In case such constraints exist, or one attempts to reduce the number of
messages sent by the algorithm, this variation should be explored.
Privacy is considered one of the main motivations for solving problems distributively. The common model for distributed search algorithms on DisCSPs and DisCOPs enables assignments and
Nogoods to be passed among agents (Yokoo, Ishida, Durfee, & Kuwabara, 1992; Yokoo, 2000b;
Bessiere et al., 2005; Modi et al., 2005; Zivan & Meisels, 2006; Meisels & Zivan, 2007). AF B follows the model proposed by Yokoo, sending assignments forward and bounds on partial assignments
(N ogoods) backwards. An additional privacy drawback of AF B is the fact that agents can learn
about the assignments of non neighboring agents via CPAs which they receive from their neighbors.
This problem can be easily solved in AF B by a simple use of encryption. If every pair neighboring
agents will share an encryption key, then an agent would be able to learn only the assignments of
its neighbors when it receives a CPA. Such use of limited encryption in DisCOP algorithms was
recently proposed for DP OP by (Greenstadt, Grosz, & Smith, 2007).
71

G ERSHMAN , M EISELS , & Z IVAN

If, due to privacy, the constraints are partially known so that between two constrained agents,
only a part of the constraint is known to each of the constrained agents, then the bound computation
mechanism must be adjusted in AFB. These type of constraints were discussed for DisCSP algorithms (Brito, Meisels, Meseguer, & Zivan, 2008). To the best of our knowledge, no DisCOP solver
so far has handled such constraints. This remains an interesting possible extension to AFB as part
of future work.
Robustness is another important aspect of a distributed search algorithm. We assumed that all
messages are delivered in the order in which they are sent and no messages are lost. However if
message passing is susceptible to losses or corruption of the data, AFB may not terminate (if, say, the
CPA message is lost). It is also possible that the local data held by some agents will be corrupt (due
to some mechanical failure for example). A solution would be to build a self-stabilizing algorithm.
Self stabilization in distributed systems (Dijkstra, 1974) is the ability of a system to respond to
transient failures by eventually reaching and maintaining a legal state. A self stabilizing version
was shown for a simple DFS algorithm for DisCSPs (Collin, Dechter, & Katz, 1999). Based on
that self-stabilizing DFS algorithm, a self-stabilizing version of DPOP was developed (Petcu &
Faltings, 2005b). However these are the only self-stabilizing DisCSP/DisCOP solvers to the best
of the authors’ knowledge. Clearly, a more thorough study of robustness and self-stabilization is
required for DisCOP algorithms.
To conclude, The AFB algorithm includes concurrent computation by multiple agents, without
having to deal with the uncertainty that comes with asynchronous assignments. Each agent that
receives a message containing a partial assignment knows with certainty that the given partial assignment is the one it was supposed to receive, and not a result of a network delay inconsistency.
Therefore, AFB has both concurrent computation and the certainty of working with consistent partial assignments. This results in a much better performance on hard instances of random DisCOPs,
as will be demonstrated in the empirical evaluation in section 6.

4. AFB with CBJ
In both centralized and distributed CSPs backjumping can be accomplished by maintaining data
structures that allow an agent to deduce who is the latest agent (in the order in which assignments
were made) whose changed assignment could possibly lead to a solution. Once such an agent is
found, the assignments of all following agents are unmade and the search process “backjumps” to
that agent (Prosser, 1993).
A similar process can be designed for branch and bound based solvers for COPs and DisCOPs.
Consider a sequence of assignments by the agents A1 , A2 , A3 , A4 , A5 where A5 determined that
none of its possible value assignments can lead to a full assignment with a cost lower than the cost
of the best full assignment found so far. Clearly, A5 must backtrack.
In chronological backtracking, the search process would simply return to the previous agent,
namely A4 , and have it change its assignment. However, A5 can sometimes determine that no value
change of A4 would suffice to reach a full assignment with a lower cost. Intuitively, A5 can safely
backjump to A3 , if it can compute a lower bound on the cost of a full assignment extended from the
assignments of A1 , A2 and A3 , and show that this bound is greater or equal to the cost of the best
full assignment found so far. This is the intuitive basis of how backjumping can be added to AFB.
More formally, let us consider a scenario in which Ai decides to backtrack, and the cost of the
best full assignment found so far is B (e.g. the upper bound of the current state of the search). The
current partial assignment includes the assignments of agents A1 , ..., Ai−1 .
72

A SYNCHRONOUS F ORWARD B OUNDING FOR D ISTRIBUTED COP S

Definition 5 CPA[1..k] is the set of assignments made by agents A1 , . . . , Ak in the current partial
assignment. We define CP A[1..0] = {}.
Definition 6 FA[k] is the set of all full assignments, which include all the assignments appearing
in CPA[1..k]. In other words, this set contains all full assignments which can be extended from the
assignments appearing in CPA[1..k]. Naturally, FA[0] is the set of all possible full assignments.
On a backtrack, instead of simply backtracking to the previous agent, Ai performs the following
actions: It computes a lower bound on the cost of any full assignment in FA[i-2]. If this bound is
smaller than B, it backtracks to Ai−1 just like it would do in chronological backtracking. However,
if this bound is greater or equal to B, then backtracking to Ai−1 would do little good. No value
change of Ai−1 alone could result in a full assignment of cost lower than B. As a result, Ai knows
it can safely backjump to Ai−2 . It may be possible for Ai to backjump even further, depending on
the lower bound on the cost of any full assignment in
FA[i-3]. If this bound is smaller than B, it backjumps to Ai−2 . Otherwise, it knows it can safely
backjump to Ai−3 . Similar checks can be made about the necessity to backjump further.
The backjumping procedure relies on the computation of lower bounds for sets of full assignments (FA[k]). Next, we will show how can Ai compute such lower bounds. Let us define the
notions of past, local and future costs in definitions 7, 8 and 9.
Definition 7 PC (Past-Costs) is a vector of size n+1, in which the k-th element (0 ≤ k ≤ n) is
equal to the cost of CPA[1..k].
Definition 8 LC(v) (Local-Costs) is a vector of size n + 1 computed by Ai and held by it, in which
the k-th element (0 ≤ k ≤ n) is
X
LC(v)[k] =
cost(Ai = v, Aj = vj )
(Aj ,vj )∈CP A s.t j≤k

Since the CPA held by Ai only includes assignments of A1 , . . . , Ai−1 , then
∀j ≥ i, LC(v)[i − 1] = LC(v)[j]
Intuitively, LC(v)[i] is the accumulated cost of the value v of Ai , with respect to all assignments in
CPA[1..i].
Definition 9 FCj (v) (Future-Costs) is a vector of size n+1, in which the k-th element (0 ≤ k ≤ n)
contains a lower bound on the cost of assigning a value to Aj with respect to the partial assignment CPA[1..k]. Assume this structure is held by agent Ai . If k ≥ i then CPA[1..k] contains the
assignment Ai = v, but for k < i the value v of Ai is irrelevant as it does not appear in CPA[1..k].
The above vectors provide additive lower bounds on full assignments that start with the current
CPA up to k, FA[k]. PC[k] isPthe exact cost of the first k assignments, LC(v)[k] is the exact cost of
the assignment Ai = v, and j>i F Cj (v)[k] is a lower bound on the assignments of Ai+1 , ..., An .
Therefore, the sum
X
FALB(v)[k] = LC(v)[k] + P C[k] +
F Cj (v)[k]
j>i

73

G ERSHMAN , M EISELS , & Z IVAN

Figure 4: An example DisCOP
is a Full Assignment Lower Bound on the cost of any full assignment extended from CPA[1..k] in
which Ai = v.
FA[k] contains all full assignments extended from CPA[1..k], and is not limited to assignments
in which Ai = v. If we go over all FALB(v)[k], for all possible values v ∈ Di we produce a lower
bound on any assignment in FA[k].
Definition 10 FALB[k] = minv∈Di (F ALB(v)[k]).
FALB[k] is a lower bound on the cost of any full assignment extended from CPA[1..k].
In a distributed branch and bound algorithm, this bound is computed by Ai . PC - the cost
of previous agents is sent along with their value assignment messages to Ai . LC(v) - the cost of
assigning v to Ai can be computed by Ai . Ai requests all agents ordered after it, Aj (j > i), to
compute FCj and send the results back to Ai . This is part of the already existing AFB mechanism
for forward bounding.
In the AFB algorithm (Gershman, Meisels, & Zivan, 2007) Ai already requests unassigned
agents to compute lower bounds on the CPA and send back the results. The additional bounds
needed for backjumping can be easily added to the existing AFB framework.
4.1 A Backjumping Example
To demonstrate the backjumping possibility, consider the DisCOP in Figure 4 (again, large ovals
represent variables while small circles represent values). Let us assume that the search begins with
A1 assigning “a” as its value and sending the CP A forward to A2 . A2 , A3 , A4 , and A5 all assign
the value “a” and we get a full assignment with cost 12. The search continues, and after fully
exploring the sub-space in which A1 = a, A2 = a, the best assignment found is A1 = a, A2 =
a, A3 = b, A4 = a, A5 = b with a total cost of B=6. Assume that A3 is now holding the CP A
after receiving it from some future agent (A4 or A5 ). A3 has exhausted its value domain and must
backtrack. It computes:
F ALB(a)[1] = P C[1] + LC(a)[1] + (F C4 (a)[1] + F C5 (a)[1])
74

A SYNCHRONOUS F ORWARD B OUNDING FOR D ISTRIBUTED COP S

= 0 + 2 + (3 + 2) = 7
F ALB(b)[1] = P C[1] + LC(b)[1] + (F C4 (b)[1] + F C5 (b)[1])
= 0 + 1 + (3 + 2) = 6
F ALB[1] = min(F ALB(a)[1], F LAB(b)[1]) = 6
F ALB[1] ≥ B, therefore A3 knows that any full assignment extended from {A1 = a} would cost
at least 6. A full assignment with that cost was already discovered, so there is no need to explore
the rest of this sub-space, and it can safely backjump the search process back to A1 , to change its
value to “b”. Backtracking to A2 leaves the search process within the {A1 = a} sub-space, which
A3 knows cannot lead to a full assignment with a lower cost.
4.2 The AFB-BJ Algorithm
The AFB-BJ algorithm is run on each of the agents in the DisCOP. Each agent first calls the procedure init and then responds to messages until it receives a TERMINATE message. The algorithm is
presented in figures 5 and 6. As in pure AFB, a timestamping mechanism is used on all messages.
The same timestamping mechanism used by AFB is used in AFB-BJ to determine which messages are relevant and which are obsolete. For simplicity we choose to omit the pseudo-code detailing the calculation of LC, PC, FC and FALB, as they were described in Section 4.1.
The algorithm starts by each agent calling init and then awaiting messages until termination.
At first, each agent updates B to be the cost of the best full assignment found so far and since no
such assignment was found, it is set to infinity (line 1). Only the first agent (A1 ) creates an empty
CPA and then begins the search process by calling assign CPA (lines 3-4), in order to find a value
assignment for its variable.
An agent receiving a CPA (when received CPA MSG), checks the time-stamp associated with
it. An out of date CP A is discarded. When the message is not discarded, the agent saves the
received PA in its local CPA variable (line 7). In case the CPA was received from a higher priority
agent, the estimations of future agents in F Cj are no longer relevant and are discarded, and the
domain values must be reordered by their updated cost (lines 9-11). Then, the agent attempts to
assign its next value by calling assign CPA (line 16) or to backtrack if needed (line 14).
Procedure assign CPA attempts to find a value assignment, for the current agent. The assigned
value must be such that the sum of the cost of the CPA and the lower bound of the cost increment
caused by the assignment will not exceed the upper bound B (lines 23). If no such value is found,
then the assignment of some higher priority agent must be altered, so backtrack is called (line 25).
When a full assignment is found which is better than the best full assignment known so far, it is
broadcast to all agents (line 29). After succeeding to assign a value, the CPA is sent forward to the
next unassigned agent (line 33). Concurrently, forward bounding requests (i.e. FB CPA messages)
are sent to all lower priority agents (lines 34-35).
An agent receiving a bound estimation (when received FB ESTIMATE) from a lower priority
agent Aj (in response to a forward bounding message) ignores it if it is an estimate to an already
abandoned partial assignment (identified using the time-stamp mechanism). Otherwise, it saves this
estimate (line 17) and checks if this new estimate causes the current partial assignment to exceed
the bound B (line 18). In such a case, the agent calls assign CP A (line 19) in order to change its
value assignment (or backtrack in case a valid assignment cannot be found).
75

G ERSHMAN , M EISELS , & Z IVAN

procedure init:
1. B ← ∞
2. if (Ai = A1 )
3.
generate CP A()
4.
assign CP A()
when received (FB CPA, Aj , P A)
5. V ← estimation vector for each PA[1..k] (0 ≤ k ≤ n)
6. send (F B EST IM AT E, V , P A, Ai ) to Aj
when received (CPA MSG, P A, Aj )
7. CP A ← P A
8. T empCP A ← P A
9. if (j = i − 1)
10. ∀j re-initialize F Cj (v)
11. reorder domain values v ∈ Di by LC(v)[i] (from low to high)
12. if (T empCP A contains an assignment to Ai ) remove it
13. if (T empCP A.cost ≥ B)
14. backtrack()
15. else
16. assign CP A()
when received (FB ESTIMATE, V , P A , Aj )
17. F Cj (v) ← V
18. if ( FALB(v)[i] ≥ B )
19. assign CP A()
when received (NEW SOLUTION, P A)
20. B CP A ← P A
21. B ← P A.cost
Figure 5: Initialization and message handling procedures of the AFB-BJ Algorithm

The call to backtrack is made whenever the current agent cannot find a valid value (i.e. below
the bound B). In such a case, the agent calls backtrackTo() to compute to which agent the CPA
should be sent, and backtracks the search process (by sending the CPA) back to that agent. If the
agent is the first agent (nowhere to backtrack to), the terminate broadcast ends the search process
in all agents (line 37). The algorithm then reports that the optimal solution has a cost of B, and the
full assignment corresponding to this cost is B CP A.
The function backtrackTo computes to which agent the CPA should be sent. This is the kernel
of the backjumping (BJ) mechanism. It goes over all candidates, from j − 1 down to 1, looking
for the first agent it finds that has a chance of reaching a full assignment with a lower cost than
B. FALB(v)[j-1] is a lower bound on the cost of a full assignment extended from CPA[1..j-1], and
PC[j]-PC[j-1] is the cost added to that CPA by Aj ’s assignment. Since Aj picked the lowest cost
value in its domain (its domain was ordered in line 11), the addition of these two components
76

A SYNCHRONOUS F ORWARD B OUNDING FOR D ISTRIBUTED COP S

procedure assign CPA:
22. if CP A contains an assignment Ai = w, remove it
23. iterate (from last assigned value) over Di until the first value satisfying
v ∈ Di s.t. CP A.cost + f (v) < B
24. if no such value exists
25.
backtrack()
26. else
27.
assign Ai = v
28.
if CP A is a full assignment
29.
broadcast (NEW SOLUTION, CPA )
30.
B ← CP A.cost
31.
assign CP A()
32.
else
33.
send(CPA MSG, CPA, Ai ) to Ai+1
34.
forall j > i
35.
send(FB CPA, Ai , CPA) to Aj
procedure backtrack:
36. if (Ai = A1 )
37.
broadcast(TERMINATE)
38. else
39.
j ← backtrackTo()
40.
remove assignments of Aj+1 , .., Ai from CP A
41.
send(CPA MSG, CPA, Ai ) to Aj
function backtrackTo:
42. for j = i − 1 downto 1
43.
foreach v ∈ Di
44.
if ( FALB(v)[j-1] + (PC[j] - PC[j-1]) < B )
45.
return j
46. broadcast(TERMINATE)
Figure 6: The assigning and backtracking procedures of the AFB-BJ Algorithm.
produces a more accurate lower bound on the cost of a full assignment extended from CPA[1..j-1].
This can be safely added to the FALB since the it adds a lower bound on the cost increment by an
agent for which the FALB did not include a lower bound.
Example 2 In the example presented in section 4.1, when A3 computed the FALB(b)[1] it added
the past costs of the partial assignments (cost incurred by A1 ), the local cost of A3 , and a lower
bound on the cost increment by future agents (A4 and A5 ). To this sum we can safely add the cost
added by A2 if we know that A2 picked its lowest cost assignment.
This addition helps tighten the FALB and reduce search. If this combined bound is not smaller
than B, then surely any combination of assignments made by Aj and any following agent could
only raise the cost, which is already too high. In case even backjumping back to A1 will not prove
helpful, the search process is terminated (line 46).
77

G ERSHMAN , M EISELS , & Z IVAN

5. Correctness of AFB
In order to prove correctness for AF B two claims must be established. First, that the algorithm
terminates and second that when the algorithm terminates its global upper bound B is the cost of
the optimal solution. To prove termination one can show that the AF B algorithm never goes into
an endless loop. To prove the last statement it is enough to show that the same partial assignment
cannot be generated more than once.
Lemma 1 The AF B algorithm never generates two identical CPAs.
Assume by negation that Ai is the highest priority agent (first in the order of assignments)
that generates a CPA for the second time. Now lets consider all possible events that immediately
preceded this creation.
Case 1 - Ai received a CPA message from a lower priority agent. Let us denote that agent as Aj ,
where j > i. When Ai received this message, he executed lines 7-13 (see Figure 3.1). The procedure
backtrack in line 14 was not executed since we know Ai generated a CPA, and that procedure would
not do so. Therefore line 16 was executed, and the procedure assign CPA was invoked. Ai executed
lines 22-24. Line 25 was not executed since invoking the backtrack procedure could not lead to
the creation of the CPA. Therefore, in line 24 a value as described in line 23 was found to exist.
Line 23 searches for a value in Ai ’s remaining value domain, not exploring any value previously
attempted for the current set of assignments of higher priority agents. Since we assumed Ai to
be the highest priority agent that generates a CPA for the second time, this combination of higher
priority assignments did not repeat itself. Therefore, since Ai received the current set of higher
priority assignments Ai does not re-pick any local value, and the set of high priority assignments
did not repeat itself, therefore Ai cannot pick a value that would generate the same CPA for the
second time.
Case 2 - Ai received a CPA message from a higher priority agent. Let us denote that agent as
Aj , where j < i. Since we assumed Ai to be the highest priority agent that generates a CPA for
the second time, this combination of higher priority assignments did not repeat itself. Therefore any
value Ai would assign next would generate a unique CPA, one which he could not have generated
before.
Case 3 - Ai received a CPA message from itself. This cannot be since Ai never sends such a
message to itself.
Case 4 - Ai received an FB ESTIMATE message from Aj . j > i since FB ESTIMATE are
only sent in response to FB CPA messages. Which are only sent (line 34) to agents of lower priority
than Ai . Since this message caused the creation of a CPA, the condition in line 19 must have been
evaluated to be true, and the procedure assign CPA in line 19 invoked. Similar to case 1, lines 22-24
were executed and line 25 was not. Similar to case 1, a value was found in line 23. This value does
not repeat any value previously picked under the current set of higher priority agent assignments.
This is the only time the agent received such current set of higher priority agent assignments due to
the assumption that Ai is the first to generate a CPA twice.
Case 5 - the procedure init was invoked. This cannot be since no CPAs were previously generated, any CPA generated now must be unique.
No other events could have immediately preceded the creation of the second identical CPA,
therefore it is impossible for this event to occur. This completes the proof of the lemma.
Termination follows immediately from Lemma 1.

78

A SYNCHRONOUS F ORWARD B OUNDING FOR D ISTRIBUTED COP S

Next, one needs to prove that upon termination the complete assignment, corresponding to the
optimal solution, is in B CP A (see Figure 3.1). There is only one point of termination for the
AF B algorithm, in procedure backtrack. So, one needs to prove that during search no partial
assignment that can lead to a solution of lower cost than B is discarded. Let us consider all possible
cases where an agent discards a CPA, changes a value or skips over a value and let us show that
this cannot be. Skipping over or changing a value is only done inside the procedure assign CPA
in lines 22-24. If v is a value that is skipped over, then by the condition itself in line 23 it holds
that CP A.cost + f (v) ≥ B. Since B ≥ B CP A, CP A.cost + f (v) ≥ B ≥ B CP A and this
means that v could not possibly lead to a solution of cost lower than B CP A at termination. Let
us consider all possible cases in which a value is changed. This only occurs inside the procedure
assign CPA. Let us then consider all possible cases in which this procedure is invoked that result in
a value change.
Case 1 - invoking assign CPA from the init procedure (line 4). No solution could be lost since
this is the very first assignment performed, no part of the search space is skipped over by this
assignment.
Case 2 - invoking assign CPA from inside the assign CPA procedure (line 31). This happens
when a new best (so far) solution was found. obviously changing the assignment now would not lose
this solution since it is saved and broadcasted as the new current solution. It will only be discarded
if a better solution is later found.
Case 3 - invoking assign CPA following a received FB ESTIMATE message (line 19). The
current partial assignment can be safely discarded, knowing that no solution will be lost since the
condition in line 18 indicated that the current partial assignment has a lower bound that exceeds the
best solution found so far.
Case 4 - invoking assign CPA following a received CPA MSG message (line 16) from Aj where
j > i. This means the CPA returned from a backtrack after fully exploring the current sub-space,
and therefore changing the current assignment would not lead to any potential solution lost.
Case 5 - invoking assign CPA following a received CPA MSG message (line 16) from Aj where
j < i. This means that the CPA was received from a higher priority agent. Ai did not yet pick an
assignment, so any assignment it will make will not lose out on any potential solutions.
Therefore, any value skipped over and any change to the CPA will not lead to the loss of a
potential solution. The only remaining event that may lead to a solution being skipped over is a
CPA being discarded. This is done by the time-stamping mechanism and only occurs when the
agent knows of the existence of a more up-to-date CPA. That CPA was created because some agent
changed its assignment by calling assign CPA. We showed that in such a case no better solution can
be lost, therefore it is safe to discard the CPA.
In conclusion, in any event a value is skipped over or changed or a CPA is discarded, no possible better solution is lost. Therefore at termination, the AFB algorithm reports the best solution
possible. This completes the correctness proof of the AF B algorithm. 
In order to prove the correctness of the AFB-BJ algorithm we first prove the correctness of the proposed backjumping method and then show that its combination with AFB does not violate AFB’s
correctness which has been proven.
In order to prove the correctness of the backjumping method one need only show that none
of the agents’ assignments that the algorithm backjumps over, can lead to a solution with a lower
cost than the current upper bound. The condition for performing backjumping over an agent Aj
(line 44) is that the lower bound on the cost of a full assignment extended from the assignments of
79

G ERSHMAN , M EISELS , & Z IVAN

Figure 7: Total non-concurrent computational steps by AFB, ADOPT and SBB on low density
(p1 =0.4) Max-DisCSP

A1 , .., Aj−1 and of the assignment cost of Aj exceeds the global upper bound B. Since Aj picked
the lowest cost value in its remaining domain (as the domain is ordered), extending the assignments
of A1 , .., Aj−1 must lead to a cost greater or equal to B. Therefore, backjumping back to Aj−1
cannot discard any potentially lower cost solutions. This completes the correctness proof of the
AFB-BJ backjumping (function backtrackTo) method.
Assuming the correctness of AFB, in order to prove the correctness of the composite algorithm
AFB-BJ it is enough to prove the consistency of the lower bounds computed by the agents in AFBBJ. The lower bounds computed by AFB-BJ include FC, LC and PC as described in section 4. PC
is contained in the CPA, and is updated by any agent that receives it and adds an assignment (not
shown in the code). LC(v) is computed by the current agent Ai whenever it assigns v as its value
assignment. FCj is computed by Aj in line 5 (in figure 5), and is sent back to Ai in line 6. Ai
receives and saves this in line 17. The lower bounds contained inside these vectors are correct
because PC was exactly calculated when holding the CPA, LC was exactly calculated by the current
agent Ai , and the bounds in FCj are the same bounds computed in AFB which were proven to be
correct lower bounds for the assignment of Aj . The FCj bounds are accurate and based on the
current partial assignment since the timestamp mechanism prevents processing of bounds which are
based on an obsolete CPA. Whenever the CPA is altered by some higher priority agent, the previous
bounds are cleared (line 10 of figure 5). This completes the correctness proof of AF B − BJ. 

6. Experimental Evaluation
All experiments were performed on a simulator in which agents are simulated by threads which
communicate only through message passing. The Distributed Optimization problems used in all of
the presented experiments are random Max-DisCSPs. The network of constraints, in each of the
experiments, is generated randomly by selecting the probability p1 of a constraint among any pair
of variables and the probability p2 , for the occurrence of a violation (a non zero cost) among two
assignments of values to a constrained pair of variables. Such uniform random constraints networks
of n variables, d values in each domain, a constraints density of p1 and tightness p2 are commonly
used in experimental evaluations of CSP algorithms (cf. (Prosser, 1996)). Max-CSPs are commonly
used in experimental evaluations of constraint optimization problems (COPs) (Larrosa & Schiex,
80

A SYNCHRONOUS F ORWARD B OUNDING FOR D ISTRIBUTED COP S

Figure 8: Total number of messages sent by AFB, ADOPT and SBB on low density (p1 =0.4) MaxDisCSP

(a)

(b)

Figure 9: (a) Number of none-concurrent steps performed by ADOPT, AFB, AFB-minC and AFBBJ for high density Max-DisCSP (p1 = 0.7). (b) A closer look at p2 > 0.9

2004). Other experimental evaluations of DisCOPs include graph coloring problems (Modi et al.,
2005; Zhang et al., 2005), which are a subclass of Max-DisCSP.
In order to evaluate the performance of distributed algorithms, two independent measures of
performance are used - run time, in the form of non-concurrent steps of computation (Zivan &
Meisels, 2006b), and communication load, in the form of the total number of messages sent (Lynch,
1997; Yokoo, 2000a).
In the first set of experiments, the performance of AF B is compared to that of two algorithms.
The synchronous B&B algorithm (SBB) (Hirayama & Yokoo, 1997) and the asynchronous distributed optimization algorithm (ADOP T ) (Modi et al., 2005). Figure 7 presents the average runtime in number of non-concurrent computation steps, on randomly generated Max-DisCSPs with
n = 10 agents, domain size d = 10, and a constraint tightness of p1 = 0.4. Figure 8 compares the
81

G ERSHMAN , M EISELS , & Z IVAN

(a)

(b)

Figure 10: (a) Number of messages sent by ADOPT, AFB, AFB-minC and AFB-BJ for high density
Max-DisCSP (p1 = 0.7). (b) A closer look at p2 > 0.9

same algorithms on the same problems by the total number of messages sent. From these figures
it is clear that ADOPT outperforms the basic algorithm SBB, in accordance with the past experimental evaluation of these two algorithms (Modi et al., 2005). It is also clear that AFB outperforms
ADOPT by a large margin for tight (high p2 ) problems. This is true for both measures.
The second set of experiments includes the ADOPT algorithm and three versions of the AFB algorithm: AFB, AFB-minC - a variation of AFB which includes dynamic ordering of values based on
minimal cost (of the current CPA), and AFB-BJ which is the composite backjumping and forwardbounding algorithm. AFB-BJ uses the same value ordering heuristic as AFB-minC. This was selected in order to show that the improved performance of AFB-BJ does indeed arise from the backjumping feature and not from the value ordering heuristic.
Figure 9 presents the average run-time in number of non-concurrent computation steps, of all
the algorithms: ADOPT, AFB, AFB-minC and AFB-BJ, on Max-DisCSPs with n = 10 agents,
domain size d = 10, and a constraint density of p1 = 0.7. Asynchronous optimization (ADOPT) is
much slower than the standard version of AFB. Also clear from this figure, is that the value ordering
heuristic greatly improves AFB’s performance. The added backjumping improves the performance
much further. The RHS of the figure provides a “zoom in” on the section of the graph between
p2 = 0.9 and p2 = 0.98. For such tight problems, ADOPT did not terminate in a reasonable
amount of time and had to be terminated manually (and thus is missing from the graph).
For tightness values that are higher than p2 > 0.9 AFB and its variants demonstrate a “phase
transition”. This “phase transition” behavior of the AFB algorithms is very similar to that of lookahead algorithms on centralized Max-CSPs (Larrosa & Meseguer, 1996; Larrosa & Schiex, 2004).
Our explanation for this “phase transition” is that problem difficulty increase exponentially with
tightness but only up to some point. When the problem becomes over-constrained such that many
combinations produce the highest cost possible all these combinations are in fact equal in quality,
and can be easily pruned by an intelligent search.
82

A SYNCHRONOUS F ORWARD B OUNDING FOR D ISTRIBUTED COP S

Figure 11: Number of Non-Concurrent Constraint Checks (NCCCs) performed by several DisCOP
solvers for high density Max-DisCSP (p1 = 0.7) in both linear scale (top) and logarithmic scale (bottom)

Figure 10 presents the total number of messages sent by each of the algorithms. The results
of this measurement closely match the results of run-time, as measured by non-concurrent steps.
83

G ERSHMAN , M EISELS , & Z IVAN

Figure 12: Number of Non-Concurrent Constraint Checks (NCCCs) performed by several DisCOP
solvers for low density MaxDisCSP (p1 = 0.4) in logarithmic scale

We can see that ADOPT has an exponentially rapid growth of messages. The explanation for this
growth is simple. Following each message an agent receives in ADOPT, several VALUE messages
are sent to lower priority agents, and a single COST message is sent to a higher priority agent (Modi
et al., 2005). On the average, at least two messages are sent for every message received, therefore
the total number of messages in the system increases exponentially over time.
The third batch of experiments, includes a comparison with two additional DisCOP solvers DPOP (Petcu & Faltings, 2005a) and OptAPO (Mailler & Lesser, 2004). DPOP performs only a
linear number of computational steps, but each step performs an exponential number of computations. The number of messages in DPOP is linear (2n) in the number of agents. Similar to ADOPT,
DPOP also uses a pseudo-tree ordering of the agents and so we use the same ordering for both
algorithms. OptAPO performs a partial centralization of the problem, and has agents that solve a
part of the problem they are in charge of. Therefore, for both algorithms, evaluation measures that
use the number of (non-concurrent) computational steps are inappropriate, since the steps can be
exponentially time consuming. For this reason, the performance of all algorithms must be evaluated by a different metric. The canonical choice is the number of non-concurrent constraint checks
(N CCCs). This implementation independent measure includes the computations performed within
every single step (Zivan & Meisels, 2006b, 2006a, 2006). The number of messages sent is also not
a good measure in this case, since DPOP sends out exponentially large messages (but only a linear
number of them) while the other algorithms send out an exponential amount of messages but of
only linear size. Thus we only present the results using the N CCCs metric. We repeat the experimental setup of the previous experiment on randomly generated problems, and report the total
number of non-concurrent constraint checks (NCCCs) in figure 11. The results are presented in
both logarithmic and linear scales.
In this experiment OptAPO, SBB and ADOPT did not terminate in a reasonable time on some
of the harder problem instances and are therefore partially absent in the graphs. The computation
84

A SYNCHRONOUS F ORWARD B OUNDING FOR D ISTRIBUTED COP S

in DPOP is composed of each agent sending out a message containing its subtree’s optimal cost
for every possible combination of higher priority constrained agents. For a given constraint density
the size of the message each agent sends would not be effected by changing the constraint tightness. Therefore, the computation performed by each agent is unaffected by changing the constraint
tightness (p2 ). DPOP’s run time is expected to remain roughly the same for all tightness values in
our experiment. For problems with a low constraint tightness DPOP’s performance is poor when
compared to the rest of the algorithms. However, as problem tightness increases the gap between
DPOP’s run time and the rest of the algorithms narrows, until at p2 = 0.9 DPOP and OptAPO and
SBB have roughly the same run time. At p2 = 0.99 DPOP outperforms ADOPT, OptAPO and SBB
(which did not terminate). AFB and its variants outperform DPOP for the whole range of constraint
tightness by orders of magnitude. OptAPO appears to perform only slightly better than SBB and
AFB clearly outperforms it by orders of magnitude. AFB and its variations produce the same ”phase
transition” as reported in previous experiments, and AF B − BJ comes out as the best performing
algorithm for solving random DisCOPs.
The results for a similar experiment in low density (p1 = 0.4) Max-DisCSPs are presented in
figure 12 (notice the logarithmic scale). As in high density problems, DPOP performance is unaffected by the problem tightness, producing roughly similar results for all tightness values. At
low tightness values, OptAPO and AFB are vastly superior to DPOP while OptAPO slightly outperforms AFB. As tightness increases, OptAPO increases exponentially in run-time to become the
worst performing algorithm. AFB outperforms DPOP at all tightness values except at p2 = 0.9.

7. Conclusions
The Asynchronous Forward-Bounding algorithm (AF B) uses asynchronous and concurrent constraint propagation on top of the distributed Branch and Bound scheme. In its forward-bounding
protocol AF B maintains local consistency, and prevents exploration of ”dead-ends” of the searchspace. The run-time and network load of AFB were evaluated by an asynchronous simulator on
randomly generated M ax − DisCSP s. The results of this evaluation revealed a phase-transition
in AF B’s performance, as the tightness of the problems increased beyond some point. No other
DisCOP solver was reported to display such a behavior. A similar phase-transition was previously
reported for centralized COP solvers, as part of the work of Larrosa et. al. (Larrosa & Meseguer,
1996; Larrosa & Schiex, 2004). The phase-transition observed there is reported to occur only by
COP solvers, that enforce a strong enough form of local consistency (Larrosa & Meseguer, 1996;
Larrosa & Schiex, 2004). We therefore attribute this behavior of AFB to its concurrent enforcement
of local consistency.
AF B can be extended. One extension is to include a value ordering heuristic. A good ordering heuristic is the minimum-cost heuristic, where values with lower cost due to assignments of
higher priority agents are selected first. We named this version of the algorithm AFB-minC. In the
experiments, the use of this heuristic substantially improved the performance of AF B.
A further extension of AF B enhanced it with a backjumping mechanism. By adding a small
amount of information to the bounding messages, agents which detect that the lower bound of the
current partial assignment is too large (i.e. the state is inconsistent and backtracking is required)
are now able to check whether backtracking to the previous agent will indeed help to reduce the
lower bound so that the resulting partial assignment is consistent. Otherwise, the search process
backtracks even further. The resulting algorithm, AFB-BJ, performs significantly better than the
other versions of AFB. By comparing AFB-minC and AFB-BJ, it was shown that the backjumping
85

G ERSHMAN , M EISELS , & Z IVAN

does indeed affect performance, and the improvement over standard AF B is not only a result of the
addition of the ordering heuristic.
The AF B algorithm was compared to two algorithms that are based on the branch & bound
mechanism in its distributed form - ADOPT and SBB (Yokoo, 2000b; Modi et al., 2005). The
experimental evaluation clearly demonstrates a substantial difference in performance between the
algorithms. Asynchronous distributed optimization (ADOP T ) outperforms SBB, but AF B outperforms ADOP T by a large margin in both measures of performance. To the best of our knowledge this is the only evaluation of ADOP T on increasingly tighter problems. Other experimental
evaluations measured ADOP T ’s scalability (by increasing the number of variables) and not by increasing the difficulty (tightness) of problems of a fixed size. The exponential growth of the number
of messages in ADOP T is also apparent in Figures 8 and 10(a). Outperforming AF B are the two
extended versions of AF B, AFB-minC and AFB-BJ, with AFB-BJ having the best performance.
The proposed value ordering heuristic improves performance, and when adding the backjumping
mechanism on top of that, performance is even further enhanced.
Although AF B and ADOP T perform concurrent computation the nature of concurrency used
by them is very different. Concurrency in ADOP T is achieved by performing asynchronous assignments. In such an algorithm each agent picks its value assignment and is free to change it at
any time. Multiple agents may change their assignments concurrently. Asynchronous assignments
introduce some degree of uncertainty with regard to the consistency of the current partial assignment as known to an agent. In fact, there are scenarios in which an agent may base its computation
on an inconsistent partial assignment, which is a combination of assignments performed by higher
priority agents that are not aware of each other’s most-up-to-date assignment.
Two algorithms that were used for comparisons with AF B - ADOP T and DP OP - use the
pseudo-tree ordering of agents, which allows independent subproblems to be solved concurrently.
A good pseudo-tree ordering can be problematic to find (it is NP-hard to find the optimal ordering),
and sometimes even the best ordering is not good enough, due to the structure of the specific problem. Overall, these orderings become less useful when dealing with problems with high constraint
density.
In order to further evaluate the performance of AFB, it was compared and tested against two
additional DisCOP algorithms. Both DPOP and OptAPO do not use branch and bound to find an
optimal solution. The DPOP algorithm delivers all possible partial assignments up the pseudo-tree
and performs an exponential number of constraints checks in two passes over the pseudo-tree (Petcu
& Faltings, 2005a). OptAPO partitions the DisCOP into sub-problems, each solved by a mediator
of that sub-problem (Mailler & Lesser, 2004). The performance of these algorithms is expected to
be different than algorithms that use branch & bound search. In fact, the performance of DPOP
on randomly generated DisCOPs is independent of the tightness of the problems. The results of
extensive empirical evaluations of all algorithms on random DisCOPs are described in section 6
and are conclusive. The AFB algorithm is the best performing DisCOP algorithm on randomly
generated DisCOPs in both measures of performance. It performs less non-concurrent constraints
checks and it sends a smaller number of messages.
In essence, the idea behind AF B can be summed up as follows - run a sequential assignment
optimization process and concurrently run in parallel many additional processes that check the consistency of the partial assignment. The main search process is slow. At any point in time only one
agent holds the current partial assignment in order to extend it. Concurrency is achieved via the
forward bounding, which is performed concurrently.
86

A SYNCHRONOUS F ORWARD B OUNDING FOR D ISTRIBUTED COP S

The results of the experimental evaluation show that adding concurrent maintenance of bounds
to a sequential assignment process results in an efficient optimization algorithm (AF B). This algorithm outperforms all other concurrent algorithms on the hard instances of random DisCOPs.

References
Ali, S. M., Koenig, S., & Tambe, M. (2005). Preprocessing techniques for accelerating the DCOP
algorithm ADOPT.. In AAMAS, pp. 1041–1048.
Bessiere, C., Maestre, A., Brito, I., & Meseguer, P. (2005). Asynchronous Backtracking without
adding links: a new member in the ABT Family. Artificial Intelligence, 161:1-2, 7–24.
Brito, I., Meisels, A., Meseguer, P., & Zivan, R. (2008). Distributed Constraint Satisfaction with
Partially Known Constraints. Constraints, in press.
Chong, Y., & Hamadi, Y. (2006). Distributed Log-based Reconciliation. In Proc. ECAI-06, pp.
108–113.
Collin, Z., Dechter, R., & Katz, S. (1999). Self-Stabilizing Distributed Constraint Satisfaction.
Chicago Journal of Theoretical Computer Science, 5.
Dijkstra, E. W. (1974). Self-stabilizing systems in spite of distributed control. Commun. ACM,
17(11), 643–644.
Gershman, A., Meisels, A., & Zivan, R. (2007). Asynchronous Forward-Bounding with Backjumping. In Distributed Constraints Reasonning workshop, IJCAI-2007 Hyderabad, India.
Greenstadt, R., Grosz, B., & Smith, M. D. (2007). SSDPOP: improving the privacy of DCOP
with secret sharing. In AAMAS ’07: Proceedings of the 6th international joint conference on
Autonomous agents and multiagent systems, pp. 1–3 New York, NY, USA. ACM.
Hirayama, K., & Yokoo, M. (1997). Distributed Partial Constraint Satisfaction Problem.. In CP,
pp. 222–236.
Larrosa, J., & Meseguer, P. (1996). Phase transition in MAX-CSP. In Proc. ECAI-96 Budapest.
Larrosa, J., & Schiex, T. (2004). Solving Weighted CSP by Maintaining Arc Consistency.. Artificial
Intelligence, 159, 1–26.
Lynch, N. A. (1997). Distributed Algorithms. Morgan Kaufmann Series.
Mailler, R., & Lesser, V. (2004). Solving Distributed Constraint Optimization Problems Using
Cooperative Mediation. In Proceedings of the Third International Joint Conference on Autonomous Agents and MultiAgent Systems (AAMAS’04), pp. 438–445. ACM.
Meisels, A., & Zivan, R. (2006). Asynchronous Forward-checking for Distributed CSPs. Constraints, 16, 132–156.
Meisels, A., & Zivan, R. (2007). Asynchronous Forward-checking for Distributed CSPs. Constraints, 12(1).
Meseguer, P., & Jimenez, M. A. (2000). Distributed Forward Checking. In Proc. CP-2000 Workshop
on Distributed Constraint Satisfaction Singapore.
Modi, P. J., Shen, W., Tambe, M., & Yokoo, M. (2005). ADOPT: asynchronous distributed constraints optimization with quality guarantees. Artificial Intelligence, 161:1-2, 149–180.
87

G ERSHMAN , M EISELS , & Z IVAN

Nguyen, T., Sam-Hroud, D., & Faltings, B. (2004). Dynamic Distributed Backjumping. In Proc.
5th workshop on distributed constraints reasoning DCR-04 Toronto.
Petcu,

A., & Faltings, B. (2004).
A value ordering heuristic for distributed resource allocation.
In Proc. CSCLP04, Lausanne, Switzerland
http://liawww.epfl.ch/Publications/Archive/Petcu2004.pdf.

Petcu, A., & Faltings, B. (2005a). A Scalable Method for Multiagent Constraint Optimization.. In
Proc. IJCAI-05, pp. 266–271.
Petcu, A., & Faltings, B. (2005b). S-DPOP: Superstabilizing, Fault-containing Multiagent Combinatorial Optimization. In Proceedings of the National Conference on Artificial Intelligence,
AAAI-05, pp. 449–454.
Prosser, P. (1993). Hybrid Algorithms for the Constraint Satisfaction Problem. Computational
Intelligence, 9, 268–299.
Prosser, P. (1996). An Empirical Study of Phase Transitions in Binary Constraint Satisfaction Problems. Artificial Intelligence, 81, 81–109.
Silaghi, M. C., & Yokoo, M. (2006). Nogood based asynchronous distributed optimization
(ADOPT-ng).. In Proc. AAMAS06, pp. 1389–1396.
Solotorevsky, G., Gudes, E., & Meisels, A. (1996). Modeling and Solving Distributed Constraint
Satisfaction Problems (DCSPs). In Constraint Processing-96, pp. 561–2 New Hamphshire.
Yokoo, M. (2000a). Algorithms for Distributed Constraint Satisfaction: A Review. Autonomous
Agents & Multi-Agent Sys., 3, 185–207.
Yokoo, M. (2000b). Distributed Constraint Satisfaction Problems. Springer Verlag.
Yokoo, M., Ishida, T., Durfee, E., & Kuwabara, K. (1992). Distributed Constraint Satisfaction for
Formalizing Distributed Problem Solving. In IEEE Intern. Conf. Distrb. Comp. Sys., pp. 614
– 621.
Zhang, W., Xing, Z., Wang, G., & Wittenburg, L. (2003). An analysis and application of distributed
constraint satisfaction and optimization algorithms in sensor networks. In Proc. 2nd Intern.
Joint Conf. on Autonomous Agents & Multi-Agent Systems (AAMAS-03), pp. 185–192 Melbourne, Australia.
Zhang, W., Xing, Z., Wang, G., & Wittenburg, L. (2005). Distributed stochastic search and distributed breakout: properties, comparishon and applications to constraints optimization problems in sensor networks. Artificial Intelligence, 161:1-2, 55–88.
Zivan, R., & Meisels, A. (2006). Dynamic Ordering for Asynchronous Backtracking on DisCSPs.
Constraints, 11, 179–197.
Zivan, R., & Meisels, A. (2007). Conflict directed Backjumping for MaxCSPs. In IJCAI-2007
Hyderabad, India.
Zivan, R., & Meisels, A. (2006a). Concurrent search for distributed CSPs.. Artif. Intell., 170(4-5),
440–461.
Zivan, R., & Meisels, A. (2006b). Message delay and DisCSP search algorithms. Annals of Mathematics and Artificial Intelligence, 46(4), 415–439.

88

Journal of Artificial Intelligence Research 34 (2009) 165–208

Submitted 07/08; published 03/09

Behavior Bounding:
An Efficient Method for High-Level Behavior Comparison
Scott Wallace

wallaces@vancouver.wsu.edu

Washington State University Vancouver
14204 NE Salmon Creek Avenue
Vancouver, WA 98686

Abstract
In this paper, we explore methods for comparing agent behavior with human behavior to
assist with validation. Our exploration begins by considering a simple method of behavior
comparison. Motivated by shortcomings in this initial approach, we introduce behavior
bounding, an automated model-based approach for comparing behavior that is inspired,
in part, by Mitchell’s Version Spaces. We show that behavior bounding can be used to
compactly represent both human and agent behavior. We argue that relatively low amounts
of human effort are required to build, maintain, and use the data structures that underlie
behavior bounding, and we provide a theoretical basis for these arguments using notions of
PAC Learnability. Next, we show empirical results indicating that this approach is effective
at identifying differences in certain types of behaviors and that it performs well when
compared against our initial benchmark methods. Finally, we demonstrate that behavior
bounding can produce information that allows developers to identify and fix problems in
an agent’s behavior much more efficiently than standard debugging techniques.

1. Introduction
Over the past few decades, intelligent systems have been asked to perform increasingly
complex and mission critical tasks in domains such as medical diagnosis (Shortliffe, 1987)
and simulated aerial combat (Jones et al., 1999). Despite a number of successes, these
complex agents have yet to become fully integrated into mainstream software. Much of this
impasse may be attributable to the fact that developing these agents is often extremely
time consuming and expensive.
Development requires three high-level steps: specification, implementation, and validation. The difficulties associated with each step are determined by the properties of the agent
and the task it is intended to perform. In this paper, we focus on a class of agents we term
interactive human-level agents. Such agents are typified by training simulations in which
agents participate in mixed human-computer teams to accomplish a particular training objective (e.g., Swartout et al., 2001; Traum et al., 2003; Jones et al., 1999; Rickel et al., 2002).
In these domains, the agent plays a role normally fulfilled by an expert human who may not
be available for all training episodes. These agents are distinguished by three properties.
First, the agent’s performance is judged based on its ability to behave as a human expert
would behave in a similar situation. Such a design criterion is often particularly important
in training simulations where agents operate as part of a mixed human-computer team playing a role that is normally occupied by another person. Second, like humans themselves,
interactive human-level agents must interact with an external, and typically very complex,

c
2009
AI Access Foundation. All rights reserved.

Wallace

environment in order to perform many of their tasks. Finally, unlike the situation faced in
other design problems, complete specifications for correct behavior are often impracticable
if not impossible to obtain. This, unfortunately, is a well documented property of many
systems built to model human domain experts (e.g., Tsai, Vishnuvajjala, & Zhang, 1999;
Weitzel & Kerschberg, 1989; Lee & O’Keefe, 1994; Menzies, 1999). For interactive humanlevel agents, the specification of how a task should be performed typically comes directly
from the human domain expert, and as a result, comparing the agent’s behavior with this
gold standard is the only way to determine if the design criteria have been met.
A good example of an interactive human-level agent is TacAir-Soar (Jones et al., 1999).
TacAir-Soar flies virtual military planes as part of a simulated training exercise. Teammates
may be other TacAir-Soar agents or human counterparts. Because the agents are intended
to be used when there are not enough human participants for a complex exercise, these
agents must model expert-level behavior very closely so as to achieve the same training
results as if a fully human team was used. Thus, it is not acceptable for the agents simply
to achieve correct final states (e.g., by shooting down the enemy planes). Instead, the
agent must pursue a trajectory through the state/action space that emulates the human’s
trajectory (behavior). As in most complex domains, meeting this requirement is challenging
because the expert may perform the task differently on different occasions.
For many human-level agents, the development steps of specification and implementation
are often woven together during knowledge acquisition—the process through which the
developer interviews a human expert to identify and encode the parameters for correct
behavior. Often, this process involves exposing the rules or procedures that govern how
the expert decomposes a task into a series of goals, subgoals and primitive actions (task
decomposition). Once these rules or procedures have been elicited, the developer can encode
that knowledge in a form that is usable by the underlying agent architecture.
This traditional approach of knowledge acquisition is rarely free of errors. The process
of task decomposition works well enough to identify the relationships between task goals
and subgoals that it is considered a useful means of both acquiring and encoding task
knowledge (e.g., Lee & O’Keefe, 1994; Yen & Lee, 1993; Yost, 1996). However, at a finer
level of granularity, knowledge acquisition is highly prone to errors. In part, this is due
to the fact that the human participants are stretched beyond their areas of expertise. For
the domain expert, this means communicating how tasks should be performed instead of
simply performing them. For the engineer, this means understanding the problem space well
enough to determine how to translate the expert’s descriptions into instructions that can be
interpreted by the computer and that can be applied to appropriate situations. Although
alternative methods of knowledge acquisition have been proposed and tested within a limited
setting (e.g., van Lent & Laird, 1999), for the most part they have not been incorporated
into widespread use. As a result, developing complex intelligent agents remains a time
consuming and difficult process.
A distinguishing characteristic of the work presented here is the previous stated assumption that correct specifications are difficult or impossible to obtain. This is in contrast to
the majority of recent agent validation approaches using model checking or temporal logic
(e.g., Bordini, Fisher, Visser, & Wooldridge, 2004, 2006; Fisher, 2005). These systems seek
to identify implementation errors by proving whether a particular implementation upholds
strict logical constraints (specifications). The underlying assumption in model checking is
166

Behavior Bounding: An Efficient Method for High-Level Behavior Comparison

that errors originate in the implementation—not in the specification. If this assumption is
violated, the system must be tested against a gold standard of behavior to ensure correctness as the specification cannot be fully trusted. In this sense, the testing methods proposed
in the paper can be viewed as a complementary approach for achieving the same objective:
a correctly functioning agent.
Our work is further distinguished from typical machine learning approaches because
we are interested in creating artifacts that can help a person validate an existing agent’s
behavior—we do not necessarily need to learn how to produce the behavior. Our approach
is intended for applications in which current learning systems are unable to perform well
or are untrusted by the end users. We will revisit our distinction from traditional machine
learning approaches again in Sections 4 and 10.
1.1 From Manual to Semi-Automated Behavior Comparison
The standard approach to test-based validation requires that both the knowledge developer and the domain expert monitor the agent’s behavior in a large number of scenarios
(Kirani, Zualkernan, & Tsai, 1994; Tsai et al., 1999). Although standard, it is clear that
this approach has a number of significant drawbacks. Principal among these is that the
participation of two humans is required to assess the agent’s performance in each test. By
the time validation takes place, however, gross inadequacies in the agent’s behavior will
have been corrected. Thus, although it is very likely that some errors will still exist, their
manifestations will probably be relatively few and far between. This means that much of the
time spent on validation will not be useful for identifying problems in the agent’s behavior.
To improve upon the standard validation approach, a semi-automated method that
makes more efficient use of the domain expert and the developer’s time would be highly
desirable as it could substantially decrease the cost of testing. In this paper, we explore
the issue of how to meaningfully compare two actors’ trajectories through state/action/goal
space (i.e., their behavior) given a set of examples.
Comparison, in this paper, simply means identifying how the actors’ trajectories are
similar or different to one another. Thus, we are interested in a comparison that goes well
beyond simply indicating if two actors achieved the same final states. Rather, it should take
into account the actions performed and the motivations behind these actions. This could
be done simply by comparing observed trajectories directly, or by inferring a general model
for the actors’ trajectories and comparing these models. In either case, a key challenge is
that we are interested in producing artifacts that are easy for a human to interpret and
could be used to assist her in tasks such as validation.
The potential uses of behavior comparison extend well beyond agent validation and into
many other tasks where humans may want to know how two actors perform tasks differently. Scoring a modified (non-speech based) Turing test, for example, requires humans to
perform a comparison between two actors’ behavior. Similarly, consider a human supervisor
examining a student’s performance on a lesson with an intelligent tutoring or training system. The examination and review could be facilitated if the tutoring system were capable
of comparing how the student’s behavior differed from an internal gold standard and could
then relay this information to the instructor in a manner that was easy to interpret. In each
of these applications, the basic process for comparing behavior and the artifacts produced

167

Wallace

remains constant. The differences stem only from the source of behavior (e.g., human or
machine, expert or novice) and how the results are used (to identify programming errors,
to score a test, or to evaluate a student’s performance). For simplicity and cohesiveness,
this paper will focus on using behavior comparisons to aid the agent validation problem,
but the discussion and results can also be applied to other tasks as well.
1.2 Outline
In the remainder of this paper, we examine two methods for comparing interactive goaloriented behavior such as that exhibited by human-level agents and their human counterparts. We begin by describing a primitive representation of behavior upon which we
can build our comparison methods. Next, we describe a simple sequence-based comparison, but deficiencies with this method lead us to examine more sophisticated model-based
approaches.
The main contributions of this paper are fourfold. First, in Section 4, we identify the requirements of a useful comparison system. Then, beginning in Section 5, we describe a novel
model-based approach for comparing two actors’ behavior. This approach, called behavior
bounding, uses a hierarchical behavior representation that can be built from observations of
human or computer-agent behavior. Third, we demonstrate that behavior bounding meets
the requirements of a useful behavior comparison system and support these claims with
both theoretical and empirical evidence. Finally, we show that information from behavior
bounding’s comparison can significantly aid the process of identifying problems in an agent’s
behavior, thus speeding agent validation by a significant factor.

2. Behavior Traces
At its most primitive, behavior can be represented as a trajectory though state/action/goal
space that we will refer to as a behavior trace. A behavior trace is a sequence of tuples
B = ((s, G, a)0 , (s, G, a)1 , . . . , (s, G, A)n ) in which each tuple (s, G, a)i indicates the environmental state (s), the goals being pursued by the actor (G), and the action being performed
(a) at the ith sampling point. The actor’s goals are not directly observable and must be
explicitly provided by the actor performing the task. Goals are important for our purposes
because we are not only interested in what the actors do, but we are also interested in the
motivation behind their actions.
In this project, we make three main assumptions about the nature of the actor’s goals.
First, we assume that the actor’s goals are part of the actor’s internal state. These goals
are not simply given by the task description. Although the task certainly informs goal
selection, these goals arise from the interactions between the agent’s internal desires and the
environmental situations encountered during the task. Second, we assume that the actor’s
goals can change as the environment changes and as the task moves toward completion. This
means that goals can be used to structure the agent’s task into subtasks and that appropriate
goals and subgoals will generally differ during distinct phases of the task. Third, we assume
that the actor’s choice of goals (and actions) is based upon a static set of knowledge. That
is, the agent does not learn.
Note that as we have defined it, the behavior trace does not give complete information
about the agent’s internal state. Indeed, the actor is likely to perform a potentially large
168

Behavior Bounding: An Efficient Method for High-Level Behavior Comparison

amount of reasoning in order to select G or a. For example, the actor may perform an
expected utility calculation or a look-ahead search. However, this process and any information that is not explicitly represented in G or a is completely absent from the behavior
trace. Although this provides us with only a limited amount of information with which to
perform a behavior comparison, it also ensures that it will be possible to collect behavior
from either human or computer agent actors.
Behavior capture is the process of collecting information from an actor to build a behavior trace. As noted above, limiting the information in a behavior trace is critical to ensure
that behavior capture is possible. The state and action portion of the behavior trace can be
captured simply by observing the actor perform the specified task. Depending on whether
the actor is human or a computer agent, the way in which the actor records how goals
change during a task will vary. For the computer agent, (G, s) pairs can simply be written to a file during task performance. For a human expert, goal annotations can be made
verbally during task performance or immediately following task completion as suggested by
van Lent and Laird (1999).

3. Sequence-Based Comparison
A simple approach to comparing the actors’ behavior can be performed with the following
steps:
Acquire a set of behavior traces from the human expert and the agent for the specified task.
These sets, H and A, represent the human expert’s and agent’s behavior respectively
over a number of different trials.
Extract relevant symbols from the behavior traces. Some information gathered through
observation may be irrelevant for detecting errors. For example, if the human expert’s
behavior never changes given different values of the state symbol z, then z is likely
to be irrelevant for detecting errors. In this step, the salient symbols from the sets H
and A are used to create two new sets of sequences H ∗ and A∗ .
Compare each sequence a ∈ A∗ , to the contents of H ∗ . Compute the minimal number of
edit operations (insert, delete, modify) that would be required to transform a into h,
where h is the sequence in H ∗ that is initially most similar to a. Each edit operation
indicates a potential error.
Report all deviations (after removing any redundancies) between the human’s and agent’s
behavior. This report summarizes all potential errors.
This simple approach performs a more detailed analysis of behavior than simply checking
that the agent and the expert reach the same final (goal) state. In this way, the agent’s
externally observable behavior as well as some aspects of its internal reasoning process can
be inspected to ensure consistency with the human expert’s. In addition, this methodology
has the ability to identify a large number of possible errors because it has access to all the
salient properties of the behavior trace. However, this simple approach also suffers from a
number of potentially serious flaws.

169

Wallace

1. The actors’ behavior is represented as a set of sequences. As the complexity of the
domain increases it is likely that two effects will be noticed: the average length of
sequences in H ∗ and A∗ will grow (i.e., the complex tasks will take longer to solve),
and these sequences will be composed of a larger number of symbols (e.g., the state
space will become richer). The number of distinct sequences with lengths between
P max
lmin and lmax and composed of s symbols grows as ll=l
sl . Thus, enumerating
min
this space is likely to be infeasible. Moreover, because interactive human-level agents
can typically solve problems in a number of different ways, and typically operate
within complex domains, it is likely that the sequential approach described in this
section will be particularly susceptible to this effect.
2. The sequence based comparison fails to make any assumptions about how the actors’
behavior may be constrained. That is, the sequential behavior representation provides
no method for expressing a priori knowledge about how symbols can be placed relative
to one another within a particular sequence. Instead, the representation is completely
unconstrained; sequences of length l can be constructed by making l independent
symbol selections. Although this makes it possible to use this simple approach with
any variety of behavior (even behavior that is completely unstructured), it also makes
it impossible to leverage regularities that might exist in a large classes of goal directed
tasks (such as the fact that unlocking a door must always be accomplished before the
door is opened).

4. Model Based Approaches
To improve upon the simple sequence-based method of error detection, we propose a comparison method that leverages an abstract representation of the actors’ behavior. We call
such methods model-based because they do not compare instances of the actors’ behavior directly (as the simple sequential approach would). Instead, these methods compare
abstract representations of the actor’s behavior (models), to identify similarities and differences in the underlying behavior. Central to any such approach are the considerations
that influenced the model’s design. Our choice of models is guided by the following design
requirements:
Low Complexity The behavior model must be significantly less complex than the representations that define the agent itself. If this requirement is violated, two problems
may result. First, constructing the model (either by hand, or automatically through
some observational framework) is likely to be as difficult as constructing the agent’s
knowledge base. Second, understanding the model and the behavior it represents
is likely to be no easier than examining the agent’s internal representation. If the
comparison is being used to validate the agent’s underlying knowledge base, this is
clearly undesirable as it results in a recursive validation problem. However, we can
achieve this low complexity requirement by using a model that represents behavior at
a relatively high level of abstraction compared to the agent’s internal implementation.
Low Human Effort The human effort required to build the behavior model must remain
low. We have argued that one of the main uses of the behavior comparison would be to
170

Behavior Bounding: An Efficient Method for High-Level Behavior Comparison

reduce the cost of validating a human-level agent. If the low human effort requirement
is violated, the original validation costs (due, for example, to the time requirements
of examining numerous test scenarios) have simply been replaced with new costs,
resulting in no net benefit. We can achieve this low cost requirement by using an
automated system to build behavior representations from a series of observations
with little or no human supervision.
Compatibility It must be possible to build and use the behavior model with both human
actors and software agents. As we discussed in previous sections, behavior comparison
has a number of potential applications, but many rely on being able to examine both
human and software agent behavior. Thus, the contents of our model must be limited
to data that can be collected from either of these types of participants. In Section 2,
we described how behavior traces could be collected from both human actors and
computer agents. As a result, we can achieve this requirement by using a model that
is built from behavior traces.
Efficiency The computational costs associated with building and using the model must
not become infeasible as the complexity of the domain increases. Although a primary
motivation of automated behavior comparison is to replace human effort with computational effort, we must be careful to construct the model in such a way that it does
not become impossible to use. We can achieve this requirement by using an abstract
model of the actors’ behavior that does not grow directly as a function of the number
of behaviors it encapsulates.
Efficacy A good model must be effective at identifying similarities and differences between
two actors’ behavior. This is perhaps the most basic requirement we have presented.
However, the desire for an effective model that captures all the subtleties of an actor’s
behavior is likely to be in direct conflict with the previously presented requirements.
As a result, a good model must balance its need to represent actors’ behavior precisely
and thus to be able to distinguish all similarities and differences in their behavior
with the other overall needs. Unfortunately, there can be little a priori assurance that
a particular model will be effective. This requirement must be addressed through
theoretical and empirical testing once the model has been implemented.
Note that unlike any traditional machine learning tasks, we do not necessarily need to
produce a model that can be used to perform the task. That is, we do not need to learn
a policy or a set of plan operators. As described above, there is a trade-off between the
model’s efficacy and its complexity. At one end of this spectrum are executable models
of the task. Here, efficacy is maximized, but the model would be necessarily complex and
would likely be more difficult for a human to use to validate behavior than if they were
looking directly at hand coded rules or procedures. Such models are certainly valuable if
the goal is to learn behavior directly from a set of examples, and a variety of approaches
have been pursued in the machine learning literature; the most closely related are discussed
later in Section 10. Our approach, however, attempts to target a different point in the
efficacy/complexity spectrum where the model cannot perfectly describe many complex
tasks, but as a result the model can be examined much more quickly than the agent’s
171

Wallace

internal implementation. Thus, while the standard approach in machine learning literature
is to empirically evaluate a learned model by comparing it to an optimal model or to a
hand-coded model, here we are interested in something else: namely, whether our model
can maintain efficacy in complex environments and whether it can improve a person’s ability
to quickly uncover and fix problems in existing agents. In Sections 8.2 and 9 we examine
these issues.
4.1 Model-Based Diagnosis
Prior work in model-based diagnosis (e.g., Anrig & Kohlas, 2002; Lucas, 1998) has examined
how to detect errors given a model of correct behavior. In general, however, the models in
these systems are relatively complicated and intended to identify problems with mechanical
or solid state devices as opposed to software agents. The CLIPS-R (Murphy & Pazzani,
1994) system was designed expressly to ensure correct software agent behavior, and bears
some similarity to our approach.
In CLIPS-R, the behavior model consists of a set of tuples (S i , CSf , CE ), each of which
specifies the initial world state (S i ), a set of constraints describing acceptable final world
states (CSf ), and execution constraints (CE ) which must be met as the task is being performed. Final state constraints indicate facts about the environment or the agent that must
be either true or false once the task is complete (e.g., (not (gas-empty car))). Note that
the final state constraints define a behavior model in the classical planning sense; there is
no description of what sequence of events should lead to the final state. This information is
provided by the execution constraints (C E ), which are represented as a finite state machine
describing acceptable orderings of the agent’s observable actions. Execution constraints can
be used to describe relationships between these actions. For example, a constraint might
specify that the action unlock-door should always proceed open-door. Superficially, the
requirements for the CLIPS-R approach seem relatively simple to meet. However, two
serious problems exist.
First, specifying the exact set of execution constraints required for correct operation is
very similar to writing the conditions of rules. If the execution constraints govern behavior
at a very fine level of granularity, it is likely that they will be similarly difficult to design
and validate as the agent’s rule base itself (a recursive validation problem). In this case,
the requirements of low complexity and low human effort would be violated. On the other
hand, if they constrain behavior at a higher level of granularity, such as the task level, the
efficacy requirement is called into question: will they be powerful enough to work in the
complex environments of human-level agents?
A second serious problem arises because the CLIPS-R approach provides little guidance
as to how to determine appropriate constraints, especially appropriate execution constraints.
The benefits of the approach hinge completely on the developer’s ability to enumerate
adequate and appropriate execution constraints for any particular task. Yet if the developer
can enumerate the constraints required to judge whether the agent’s behavior is correct,
why were they not included in the agent’s knowledge base directly?
It should be noted that although the problems mentioned above may be encountered
when CLIPS-R is used with any particular agent, they are likely to become most obvious
(and problematic) as the complexity of the agent and domain increases. As already noted,

172

Behavior Bounding: An Efficient Method for High-Level Behavior Comparison

these are exactly the types of agents and environments that interest us, and so the concerns
raised above are particularly salient for our work with interactive human-level agents. In
contrast, the original CLIPS-R work (Murphy & Pazzani, 1994) examines the system’s
ability to correctly identify flaws in two very simple agents whose knowledge bases contain
nine and fifteen rules respectively. Both agents examined in the CLIPS-R work performed
tasks that were more akin to classification than they were to the highly interactive tasks
that interest us.

5. Behavior Bounding
As an improvement to CLIPS-R and to the simple method presented in Section 3, our
approach to behavior comparison, called behavior bounding, automatically and efficiently
builds concise high-level models of both the human expert’s and agent’s behavior by examining behavior traces to meet the first three requirements described in Section 4. The
human expert’s behavior model is used to identify boundaries on acceptable behavior in
a manner reminiscent of Mitchell’s Version Spaces (Mitchell, 1982). Potential errors are
reported by comparing the model of agent behavior to these boundaries. Behavior bounding can be used to identify programming errors in the agent’s knowledge base and can also
identify discrepancies between the expert’s explanation of how the task should be performed
and how the expert actually performs the task. This is in contrast to a high-level model
built similarly to the agent’s knowledge base (as, presumably, in CLIPS-R) using indirect
information such as interviews to determine what constraints should be met during task
performance.
5.1 The Hierarchical Model
Behavior bounding leverages the assumption that although knowledge acquisition is highly
prone to errors with respect to the details of how a task should be performed, high-level
information (specifically general relationships between goals, sub-goals and primitive actions) is much more reliable. Behavior bounding’s hierarchical behavior representation is
inspired by the hierarchical models used in And/Or trees, HTN planning (Erol, Hendler,
& Nau, 1994) and GOMS modeling (John & Kieras, 1996) to encode the variety of ways
in which particular tasks can be accomplished. Conceptually, behavior bounding encodes
three relationships. First, it identifies decomposition relationships between goals, sub-goals
and primitive actions. Second, it identifies ordering relationships between nodes in the
hierarchy. Finally, behavior bounding identifies how goals and actions are instantiated by
saving generalized parameters (i.e., features from the internal or world state that are directly
associated with the goals and actions begin pursued).
The hierarchical behavior representation (HBR) used in our approach is an And/Or
tree with binary temporal constraints representing the relationships between the actor’s
goals and actions. In this representation, internal nodes correspond to goals and leaves
correspond to primitive actions. A node’s children indicate the set of sub-goals or primitive
actions that are relevant to accomplishing the specified goal.
Figure 1 illustrates a small subsection of a hierarchical behavior representation. Goal
nodes are drawn with ovals and primitive actions with rectangles. And constraints are
represented in the standard fashion with an arc across all child nodes; temporal constraints
173

Wallace

Fly-Mission

Achieve-Waypoint

Set
Altitude

Compute
Heading

Return-to-Base

Set
Heading

Contact
Tower

Set
VHF

Set
UHF

Contact
Teammates

Ensure
Adequate
Fuel

Send
Message

Figure 1: A Hierarchical Behavior Representation

are represented with directed arcs between sibling nodes. Note that total order between
siblings is possible but not required by the representation. The semantics of Or nodes in
our representation does not necessarily indicate that only one subgoal (or action) is required
to accomplish a given goal. Rather, the Or node indicates simply that the complete set of
subgoals (or actions) is not always required to accomplish the task. Thus, the semantics of
Or nodes does not preclude the use of temporal relations; they merely state the order that
multiple goals/actions occur if indeed more than one is pursued.
The HBR can be viewed as a simple constraint model based on observations of the
actor’s behavior. It encodes some of the same relationships that Fisher uses in his temporal
logic models of agents (Fisher, 2005): namely step rules (what goals/actions to expect next);
and sometimes rules (what goals/actions to expect in the future). As a result, the HBR
could be used as a source for the types of temporal logic constraints required for model
checking when (as in the case of human-level agents) the expert is not capable of providing
such logical constraints directly.
5.2 Building the HBR from Behavior Traces: An Overview
In Section 6 we present a detailed explanation of how a HBR is acquired from behavior
traces along with the underlying algorithm. Here, we present a conceptual overview of this
process by describing how the partial behavior trace on the left-hand side of Figure 2 is
used to build the HBR on the right side of the same figure.
Initially, we begin with an empty HBR. The behavior trace (Figure 2, left hand side)
is processed in a single pass, reading from beginning to end. As new goals and actions are
174

Behavior Bounding: An Efficient Method for High-Level Behavior Comparison

encountered, nodes are added to the hierarchical representation. The hierarchy of goals
the actor is currently pursuing is indicated in this behavior trace by each line’s level of
indentation. In this example, the goal stack is generated incrementally beginning with
the selection of a top-level goal that is decomposed into a lower-level goal before again
begin decomposed into a series of primitive actions. A goal is considered completed when
it is no longer a member of the actor’s goal stack. For example, in Figure 2, the goal
Achieve-Waypoint is completed when the actor commits to performing a new goal at the
same level of abstraction (i.e., when the goal Return-to-Base is selected). As the behavior
trace is processed, the requirements for goal completion are tracked including the subgoals
necessary to accomplish the current goal and their ordering as well as the parameters of
the goal and its respective subgoals. These requirements are represented as the descendants
in the hierarchy and the constraints between them. Note that if an action or subgoal is
encountered in multiple contexts (as a descendant of two or more distinct parents) the HBR
will create a node for each such context. This is appropriate as the parameters associated
with the goal/action and its interaction with sibling goals/actions will likely depend on its
higher-level context.
This generation process results in the HBR on the right-hand side of Figure 2 (note
that the parameters associated with each goal and action, and listed in the behavior trace
segment, are not displayed to improve the clarity of the figure). Here goal nodes (ovals)
with children are all of type And. In addition, all siblings are totally ordered as indicated
by temporal constraints (directed arcs between siblings). The highly constrained nature of
this HBR (And goals and total ordering) is typical of representations built from a single
behavior trace. As more behavior traces are used to generate the structure, the HBR is
generalized to cover all input observations.
At a structural or topological level, generalization occurs in two ways. The first is when
an And constraint is turned into an Or constraint. In our example, Achieve-Waypoint
is an And goal because every time it was observed, it was completed by pursuing all
three of the subgoals: Set-Altitude; Compute-Heading; and Set-Heading. If a second
behavior trace indicated that Achieve-Waypoint was successfully completed by performing
only the subgoal Set-Heading, then Achieve-Waypoint would become an Or node to
correspondingly indicate that it does not require all subgoals to be accomplished.
Similarly, generalization of binary temporal constraints occurs as needed to represent the observed orderings of goals and actions. Returning to our example in Figure 2,
Achieve-Waypoint was observed to occur only once. Thus, its representation in the HBR
indicates a total order between its three subgoals. If Achieve-Waypoint were performed
a second time with a new sequence of these same three subgoals, the ordering constraints
within the HBR would change. For example, if Achieve-Waypoint were performed by
pursing: Compute-Heading; Set-Altitude; and Set-Heading, in that order, the temporal
constraint between Set-Altitude and Compute-Heading would be removed. This process of building the HBR and the underlying algorithm will be discussed in more detail in
Section 6.
Generalization also occurs for the parameters associated with each goal or action, effectively expanding the set of parameters associated with each node as more and more obser-

175

Wallace

Set goal: Fly-Mission
Set goal parameter: (altitude 30000)
Set goal parameter: (patrol-speed 800)
Set goal: Achieve-Waypoint
Set goal parameter: (waypoint AZ-12)
Set goal parameter: (threat-level low)
Set goal parameter: (ETA 10 minutes)
Action: (set-altitude 30000)
Action: (compute-heading AZ-12)
Action: (set-heading)
Set goal: Return-to-Base
...

Fly-Mission

Achieve-Waypoint

Set
Altitude

Compute
Heading

Return-to-Base

Set
Heading

Figure 2: Constructing the hierarchical behavior representation from a behavior trace
vations are made1 . Consider Figure 2 where the parameter associated with Set-Altitude
is 30000. If we later see Set-Altitude performed with the parameter 20000, the HBR
will contain the generalization of these two observations, namely that Set-Altitude can
have parameters in the range 20000–30000. Each parameter associated with a goal or action is generalized to cover observations in the behavior traces. For numerical parameters,
generalization is performed by expanding the acceptable range to include the new value.
For symbolic parameters, generalization is performed by adding the new symbol to a set of
acceptable values.
5.3 Representational Simplicity
The HBR discussed above is clearly a much less complex representation of behavior than
most agents’ underlying knowledge base. Indeed, the hierarchical structure ensures that
constraints cannot be formed between arbitrary goals or actions. This property also means
that the HBR may be less complex even than the model used by CLIPS-R, which allows
an arbitrary finite state machine to describe the acceptable sequences of external actions.
Behavior bounding ensures a high-level model of behavior by abstracting away internal
data-structures the agent may use to perform the task if they cannot be represented by the
hierarchy. While it is possible to store arbitrarily complex information in the HBR, it is
unlikely to happen in practice. Consider, for example, depth first search which uses an an
open list to discriminate between alternative behaviors. While the final result of the search
(a goal or action) is naturally captured by the HBR, forcing the HBR to capture the details
of the search is impractical as it requires pushing all information captured by the open list
into the goal hierarchy.
More specifically, consider an agent using search to select between two potential actions: Set-Altitude; and Set-Heading. First, note that the search process itself would
only be represented in behavior bounding’s HBR if the agent explicitly made searching a
goal. However, even if Search was an explicit goal, information about the open-list (states
that still need to be tested) would only be available to the HBR if it was made an ex1. For the purposes of this paper, parameter generalization is less interesting than structural generalization.
We include this brief discussion mainly for completeness.

176

Behavior Bounding: An Efficient Method for High-Level Behavior Comparison

plicit parameter of the goal. Even this formulation, however, would leave a large amount
of information about the search process unrepresented in the HBR. Specifically, because
search is encapsulated as a single goal without any substructure, it would be impossible
to determine the manner in which various search nodes were visited. In order to represent
this information, we would need to push all the relevant data structures (in this case the
open-list) into the goal hierarchy itself. Thus, we would need to create explicit goals for
each (state, open-list) pair. This approach of pushing arbitrary information into the goal
hierarchy is clearly both undesirable and unlikely to occur frequently in any well designed
agent. Thus, we can be reasonably certain that behavior bounding’s HBR will always be a
high-level, abstract, representation of the agent’s (or actor’s) behavior.
The representational limitations of the HBR leads us to ask: if the agent’s behavior
can be represented using such a simple structure, why was it not programmed in this
representation to begin with? The hypothesis here is not that this representation is sufficient
to completely capture the agent’s behavior, nor is it sufficient to generate behavior. Most
human-level agents rely on intermediate data-structures that are not available through the
environment or through the structure of the goal hierarchy (for example agents that use
look-ahead to select the next goal or action, or perform an expected utility calculation).
Rather, our hypothesis is that the representation provided by behavior bounding is sufficient
to identify a large class of errors in agent behavior without sacrificing efficiency. Moreover,
we hypothesize that behavior bounding can help identify potential problem spots in the
agent’s knowledge (e.g., the ordering of actions in a specific goal) even if an exact error
cannot be identified.
5.4 Representational Assumptions
In contrast to the behavior representation used for the simple comparison described in
Section 3, the HBR makes three strong assumptions about the organization of the actors’
knowledge and the effects of this organization on the actors’ behavior. These assumptions
increase the efficiency and efficacy of error detection for certain types of human-level agents.
The first assumption used by behavior bounding is that the actor’s goals are organized
hierarchically, with more abstract goals located toward the top of the tree. Hierarchical task
structure is exploited by a number of agents and agent architectures, thus this assumption
is not particularly limiting. We also assume that at any point in the problem solving
process the actor pursues a set of goals belonging to different levels in the hierarchy. This
set, referred to as the goal stack, corresponds to a path in the hierarchy beginning at the
top node and descending to the most concrete sub-goal that is currently being pursued by
the actor. The goal stack assumption implies that concurrent goals (two or more goals
simultaneously pursued at the same depth of the hierarchy) cannot be modeled explicitly
by the HBR. One way to circumvent this limitation is to implement concurrent goals as
nested goals. Because our test architecture (Soar) does not directly support concurrent
goals, this is the approach typically taken to achieve such behavior. As we will see in
Section 8.2.5, this approach does allow us to create and use a HBR but may also result in
some representational problems. The hierarchical goal assumptions described above provide
the important benefit of constraining acceptable orderings of goal and actions that an agent
may pursue. This property will be analyzed in more detail in Section 8.1.

177

Wallace

The second assumption leveraged by behavior bounding relates to the independence
of goals. In the HBR, temporal constraints can only be formed between sibling nodes,
and And/Or classification determines which of a node’s children must be performed for a
particular task. This makes it is easy to constrain the way a particular goal is achieved, but
difficult to represent constraints between arbitrary parts of the hierarchy. Although this
may cause problems with some agent implementations, this property has significant benefits.
Most importantly, it decreases the number of observations that are required to build the
model. Consider a task that requires completing two goals, each of which could be fulfilled
in four distinct ways. The behavior is represented as an ordered pair (a 1 , a2 ) indicating the
action taken to fulfill goals one and two respectively. A sequential representation that makes
no assumptions about goal independence (such as the one described in Section 3) would
require sixteen distinct observations to cover the acceptable behavior space (one for each
distinct (a1 , a2 ) pair). In contrast, behavior bounding would only require four observations
so long as the set of observations included every possible value of a 1 and every possible
value of a2 2 . This impact on efficiency is significant and is the direct result of leveraging
the assumption about how goals are likely to add regular structure to an actor’s behavior.
Finally, recall from Section 5.1 the third assumption upon which behavior bounding is
built. This is that knowledge acquisition is relatively reliable for correctly identifying the
general goal/subgoal relationships an expert uses to perform the target task even though this
same process of knowledge acquisition is very prone to errors when attempting to identify
all the rules necessary to encode the task. This assumption provides a justification for
using a behavior representation that focuses on the relationships between goals, subgoals
and primitive actions while purposefully neglecting much of the internal information an
actor may use to select her behavior.
The net effect of building the HBR based on these assumptions is a model that meets
the criteria set forth in Section 4. The model is likely to be much more concise than the
agent’s implementation (low complexity)—we are not learning complete plan operators, but
instead a generalization of the actor’s trajectories through goal/action space. In addition,
the HBR can be generated automatically by examining an actor’s behavior traces thus
meeting our second requirement (low human effort). Because the behavior traces can be
captured from either human or computer agent actors, the HBR meets the third requirement
(compatibility). In the following sections, we will present the method behavior bounding
uses the HBR to perform comparisons. In addition, we will examine the remaining two
requirements of an ideal model-based approach (efficiency and efficacy) in detail.

6. Learnability
In this section, we examine two aspects of behavior bounding’s hierarchical representation:
the effort required to create and maintain it, and its ability to represent behavior efficiently.
Both of these requirements are addressed by the overall learnability of the representation.
That is, if the representation can be learned from observations (as we have suggested), then
it requires human effort only to initiate the learning process. If the learning procedure is
efficient, and the data structure’s growth is limited, we can further say that the hierarchy
2. Thus, if a1 , a2 ∈ {1, 2, 3, 4} then the pairs (1, 1), (2, 2), (3, 3), (4, 4), would be sufficient to cover the
acceptable behavior space in behavior bounding but not in the sequential representation.

178

Behavior Bounding: An Efficient Method for High-Level Behavior Comparison

represents behavior efficiently and thus meets the fourth requirement (efficiency) outlined
in Section 4.
Create-Hierarchy(B, H)
1 W ← empty tree
2 lastStk ← nil // previous goal/action stack
3 for each (s, G, a) in B
4 do
5
for i = 0 to length[lastStk]
6
do
7
if Goal-Completed(lastStk[i])
8
then hg ← Find-Node(H, lastStk[i])
9
if hg = nil
10
then
11
Add-SubTree(H, Parent(lastStk[i]), lastStk[i])
12
else
13
Generalize(H, hg , W, lastStk[i])
14
for each gi in [G, a]
15
do
16
pg ← Parent(gi )
17
wg ← Find-Node(W, pg , gi )
18
if wg = nil
19
then
20
wg ← Add-Node(W, pg , gi )
21
Constrain-Children(W, pg )
22
else
23
if Out-of-Order(W, pg , wg )
24
then Update-Constraints(W, pg , wg )
25
Generalize(wg , gi )
26
lastStk ← [G, a]
27 return H
Figure 3: The Create-Hierarchy algorithm
In Section 5.2 we presented an overview of the process behind building the HBR from
a behavior trace. The Create-Hierarchy algorithm (Figure 3) specifies this process explicitly. The algorithm takes two arguments as input: B, a behavior trace; and H, a HBR
representing previously observed behavior (or nil if no behavior has yet been observed).
Create-Hierarchy returns a new HBR covering the behavior in H and the new observation B. Thus, calling this procedure with a single behavior trace B and H ←nil generates
a hierarchical representation of a single behavior trace by examining the way in which goals
decompose into subgoals and primitive actions during task performance. Iteratively calling
Create-Hierarchy with different behavior traces will augment and generalize H until it
covers all of the example traces. This algorithm can be executed in O(lN 2 ) time where l

179

Wallace

is the (maximum) length of the behavior trace and N is the number of nodes in the goal
hierarchy.
Classifying the sample complexity of our hierarchical representation is straightforward.
From Haussler’s equation (Haussler, 1988; Mitchell, 1997), we know that the number of
training examples required for a consistent learner to learn any target concept (with probability (1 − δ) and error bound ) in its hypothesis space (H) is m where:
1
1
ln(|H|) + ln
m≥

δ


 

(1)

The HBR can be viewed as an ordered tuple P = (p 1 , p2 , . . . , p|N | ) where each pi is
itself a tuple containing the type of the node i (either And or Or) as well as a list
L = (l1 , l2 , . . . , l|N | ) such that la = 1 iff gi is ordered before la . Note that since ordering
constraints only occur between siblings, the length of the list L would only need to be
2
length |N | in the degenerate case. The size of this hypothesis space is bounded by 2 |N |+|N |
in the worst case, but based on the shape of the hierarchy may be much smaller. Substituting the size of the hypothesis space back into Equation 1 we find that m does indeed grow
polynomially:
1
1
(|N |2 + |N |) ln(2) + ln
(2)

δ
This indicates that the required sample size is polynomial with respect to the number
of goals in the hierarchy (|N |). This, together with the fact that the time required to
incorporate a new behavior trace into the learned HBR is also polynomial in |N |, shows
that our representation is PAC-Learnable. This means that the HBR efficiently represents
aggregate behavior as well an individual instance of behavior, thus meeting our fourth
requirement.
m≥



 

7. Identifying Errors
In general, we can view a behavior comparison method as an algorithm which divides the
space of possible behaviors into two regions: behaviors that are likely to be consistent with
the expert, and behaviors that are likely to be inconsistent with the expert. The simple
comparison method described in Section 3 does this by enumerating consistent behaviors.
The model used in behavior bounding, however, allows us to divide the space of possible
behaviors more efficiently and into more refined regions without enumerating their contents.
Intuitively, the idea is to organize HBRs into a lattice; individual points in this lattice are
then used to define boundaries between different quality behaviors in a manner reminiscent
of Mitchell’s Version Spaces (Mitchell, 1982).
Recall that the hierarchical behavior representation is a hierarchy with nodes corresponding to goals, subgoals and primitive actions. Nodes are linked hierarchically based on
the goal/subgoal decomposition relationships observed in behavior traces. The HBR can
be viewed as consisting of two parts:
1. The basic structure which is a hierarchy of nodes that are labeled with the names
of goals, subgoals and actions and are connected by parent/child relationships in a
manner that corresponds to the observed behavior.
180

Behavior Bounding: An Efficient Method for High-Level Behavior Comparison

2. A set of constraints that are imposed upon the nodes in the basic structure. Constraints include the And/Or typing of nodes, binary temporal constraints, and constraints on the allowable parameter space of any goal, subgoal, or action.
Because the constraints are formed through a specific to general learning algorithm, the
generalization process creates a lattice of HBRs that are related in the following manner: 1)
they share the same basic structure; and 2) they differ in the specificity of their constraints.
Thus, the hierarchical behavior representation allows us to define an ordering from specific
to general over the space of behavior hierarchies by starting with a maximally constrained
hierarchy (at the top) and iteratively removing constraints until none remain.
Behavior bounding leverages this ordering over hierarchies to efficiently partition the
behavior space into different regions. The process begins by using traces of expert behavior (the specification) to create a corresponding HBR. Once created, we can identify the
node it occupies in this ordered space (call this node A in Figure 4). This node (the upper
boundary node) allows us to easily determine if the agent’s behavior is likely to be correct.
By definition, correct behavior must be consistent with expert behavior. An agent whose
behavior representation is a specialization of the expert’s (i.e., lies above A in the generalization lattice) exhibits behavior that is consistent with the expert’s and is therefore likely
to be correct. As in the sequential approach to behavior comparison, the upper boundary
node allows us to partition the behavior space into two regions: correct, and incorrect.
A second partition is formed by the node representing the completely unconstrained
version of the expert’s goal hierarchy. This node is illustrated at the bottom of Figure 4 (labeled B). It contains the basic structure (goal/subgoal relationships) for what may constitute
acceptable agent behavior and as a result could be used to identify behavior representations
that are known to be incorrect (because the agent’s behavior hierarchy is topologically inconsistent with the expert’s behavior hierarchy). Such representations would have a goal
decomposition structure that was inconsistent with (i.e., contained different parent/child relationships than) this lower boundary (nodes in the right side of Figure 4 labeled as neither
more nor less specific than A).
Together, the upper and lower boundaries create three regions in the behavior space.
Nodes that are a specialization of the expert’s behavior (above the upper boundary node)
correspond to behavior that is very likely to be correct. Nodes that are not a specialization
of the unconstrained version of the expert’s goal hierarchy (the lower boundary node) correspond to behaviors that are known to be incorrect. The region between the upper and
lower boundary nodes corresponds to behavior that is likely to be incorrect but perhaps
with a lower probability than the region below the lower boundary node 3 .
Mitchell (1997) defines the version space as a subset of hypotheses (from a hypothesis
space) that are consistent with a given set of training examples. By ordering the hypothesis
space from specific to general, Mitchell’s learning algorithm (Mitchell, 1982, 1997) identifies
the version space without enumerating its contents. Instead, the version space is represented
by the concepts (hypotheses in the ordered hypothesis space) that form its upper and lower
3. Here we assume that it is easier to ensure that the HBR reflects the correct agent topology than it is
to ensure constraints on the upper boundary node’s HBR are adequately generalized. In practice, the
degree to which this assumption holds will depend on properties of the agent and on how the HBR
corresponding to the lower boundary node was formed (see Section 11 for an alternative method).

181

Wallace

boundaries. These are the S-Set and G-Set that specify the most specific hypotheses
and most general hypotheses in the version space respectively. As training examples are
obtained, the S-Set becomes progressively more general while the G-Set becomes increasingly specific until both converge on the correct hypothesis.
Just as Mitchell’s S-Set and G-Set are used to delimit a set of consistent hypotheses
without enumerating them, the upper and lower boundary nodes in our approach serve
a similar purpose. The upper boundary node (UBN) plays a similar role to the S-Set.
However, while the S-Set is used to incrementally converge on the correct hypothesis (and
in doing so becomes increasingly general), the upper boundary node is viewed as the correct
hypothesis. Thus the UBN’s value is in delimiting the portion of the lattice that is consistent
with its specification. The lower boundary node, on the other hand, plays a similar role to
the G-Set. But, while the G-Set identifies hypotheses inconsistent with training data, the
lower boundary node simply identifies HBRs that are not in the same lattice because they
have a distinct topological structure.
Once these boundaries have been established, we can quickly determine whether any
arbitrary HBR is a specialization of either boundary node. This analysis, which can clearly
be done in polynomial time with respect to the number of distinct goals, subgoals, and
actions, allows us to quickly determine the degree to which the behaviors of two actors are,
or are not, consistent with one another. The inconsistencies uncovered in this process form
the basis of behavior bounding’s error report and can be displayed in either a standard text
format or visually using a graphical user interface. For the remainder of this paper, we will
use terminology appropriate for comparing two actors playing the roles of either expert or
novice. The actor referred to as the expert represents the correct behavior specification.
The actor referred to as the novice we expect to exhibit partially incorrect behavior. As
described in Section 1, these roles could be played by either software agents or humans
depending on the situation at hand.

8. Error Identification Efficacy
At this point, we have provided a good deal of support for behavior bounding and its
HBR by presenting analytical arguments on its behalf. The final criteria that must be
addressed is its efficacy with respect to identifying errors. To do this, we will examine two
components of the HBR. First, we will provide analytic results indicating the effectiveness of
the unconstrained hierarchical representation (the lower boundary) at identifying behavior
that is known to be incorrect. Second, we will provide empirical evidence that behavior
bounding as a whole is effective at distinguishing between correct and incorrect behavior.
8.1 The Lower Boundary Node
At first glance, it is not obvious how much behavior can be classified by the lower boundary
node. Without And/Or constraints or binary temporal constraints, the lower boundary
node only specifies which subgoals belong to which goals. Through this specification, the
lower boundary node constrains the set of allowable goal/sub-goal/action sequences. The
effectiveness of this simple constraint mechanism is quite surprising.
Consider an unconstrained behavior representation with branching factor b and depth
d. Without loss of generality, assume that the nodes are uniquely labeled. For simplicity,
182

Behavior Bounding: An Efficient Method for High-Level Behavior Comparison

Specific
G1
SG1,2

SG1,1

A1

A2

Behavior Representations
Inconsistent with A and B

A3

A

G1
SG1,1

A1

SG1,2

A2

A3

G1
G1
A1

SG1,2

SG1,1

A3

A5

A7

B
A1

A2

A3

General

Figure 4: Imposing Order on the Behavior Space

1e+06

B=2
B=4
B=6

Maximum Sequences (log(log(y))

100000
10000
1000
100
10
1
0.1
2

3

4
5
6
Depth of Hierarchy

7

8

Figure 5: Filtering Capability of the Lower Boundary Node

183

Wallace

also assume that at any level in this hierarchy, the actor completes its current goal before
starting the next goal. Then, we could define an actor’s behavior as a sequence of symbols
chosen from the lowest level of the unconstrained hierarchy. For behavior sequences of
P
j
length bd , in which no symbol is repeated, there are b! s |s = d−1
j=0 b possible sequences that
are consistent with the goal decomposition of the unconstrained hierarchy. In contrast,
there are bd ! sequences in which the symbols may be placed without necessarily conforming
to the unconstrained hierarchy. For hierarchical structures of reasonable size, this makes
the lower boundary node effective at filtering an exponential number of potential behavior
sequences. For example, in a small hierarchical structure of depth 4 and branching factor
2, only 1 in approximately 6.4 · 108 of the possible sequences of length 16 are consistent
with the goal decomposition specified by the unconstrained hierarchy. Figure 5 illustrates
the filtering capability of the lower boundary node. The x-axis of the figure indicates the
depth of the hierarchy and lines are plotted for branching factors 2,4, and 6. The y-axis
indicates the ratio of possible sequences accepted by a goal hierarchy to the number of total
possible sequences for an unconstrained symbol set of the same size; note that the y-axis is
doubly-logarithmic (log log(y) is plotted).
Although the lower boundary node is an extremely simple data structure, the information it stores is of significant value. Used alone, it can identify a very large (exponentially
increasing) number of behavior sequences as inconsistent with the expert’s goal decomposition structure and therefore incorrect.
8.2 Empirical Evaluation
Our empirical study has two aims. First, we want to determine whether behavior bounding
identifies errors in agent behavior well enough to be considered useful for the purposes of
validation. Second, we want to compare behavior bounding’s effectiveness to that of the
simple sequential approaches described in Section 3. To this end, we implemented behavior bounding along with two versions of the sequential approach to serve as benchmarks.
The first benchmark, M1 , extracts the sequence of actions A = (a 0 , a1 , . . . , an ) from the
behavior trace B = ((s, G, a)0 , (s, G, a)1 , . . . , (s, G, a)n ) while the second benchmark, M2 ,
extracts the sequence of goals G = (G 0 , G1 , . . . , gn ) from B. In both cases comparison is
performed by computing the minimal edit distance between two behavior traces. Remember
that the sequential methods are not particularly efficient representations; they can grow exponentially in the length of the behavior trace and have an exponential sample complexity.
However, for this same reason, they do make interesting benchmarks of efficacy.
Performance is judged based on ability to: 1) correctly identify errors in agent behavior;
2) identify all errors that have occurred; and 3) produce minimal amounts of spurious
information when reporting errors. To make such an assessment, we must compare the
errors identified by the automated comparison to a record of errors that were manually
identified and known to have actually occurred. This requires a manual inspection of the
behavior traces and a taxonomic classification of possible differences. In the following
subsections we begin by describing how errors are classified and then move on to discuss
the experimental method and assessment process in detail.

184

Behavior Bounding: An Efficient Method for High-Level Behavior Comparison

8.2.1 Behavioral Differences
At the simplest level, all differences (potential errors) can be identified by a single discrepancy between two particular symbols in the behavior traces such as a particular pair of
goals or actions. This type of mismatch can occur in one of three ways. As before, we will
refer to desired behavior as being captured in the expert’s behavior traces, while untrusted
or imperfect behavior is captured in the novice’s behavior traces.
Commission If the novice’s behavior trace and the expert’s behavior trace both contain
a goal or action symbol at the specified location but these goals or actions are inconsistent, an error of commission has occurred. For example, consider an agent flying a
tactical military aircraft patrolling the air space between two waypoints. Assume the
specification for correct behavior dictates that agent travel between the way-points
until an enemy aircraft is spotted at which point the agent should contact the command center to receive clearance to engage the enemy. In this situation, an error of
commission would occur if the agent contacts his wingman instead of the command
center and then proceeds to enter the engagement.
Omission If the expert’s behavior trace contains a goal or action symbol where there
is no corresponding symbol in the novice’s behavior trace, this error is an omission.
Following the example above, an omission would occur if the agent immediately begins
to engage the enemy without interjecting any other substitute goal or action to replace
the missing call to the command center.
Intrusion The final simple error type, intrusion, is identical to omission except that the
goal or action symbol occurs in the novice’s behavior trace but not in the expert’s
behavior trace. An intrusion would occur if the agent contacts the command center
and receives clearance to engage the enemy but then proceeds to continue to the
waypoint before returning back to engage the enemy.
In our experiments, it was often relatively straightforward to classify errors into these
three categories. However, in some situations there were enough differences between the two
actors’ behavior that it was difficult to determine whether a deviation was a commission
or one of the other forms. In such situations, we marked the error as belonging to either
category and considered it acceptable for a comparison method to identify it as either form.
When more than one of the simple errors listed above occurs, it may be possible to
identify a relationship between them. We call such related errors compound errors and note
that uncovering a single compound error is preferable to identifying many simple errors
because the compound error is a more concise description of the underlying problem. Note
that clearly we cannot consider all possible relationships between multiple errors as this
would have problematic computational implications. Rather, we are interested in relationships that occur frequently in practice. We identify two such compound errors. The first
is a misplacement error in which two goal or action symbols are transposed in the novice’s
behavior trace; often this is due to incomplete specification of the constraints for one or
both of the goals or actions that take part in the error. The second is a duplication error
in which one or more goal or action symbols reoccurs inappropriately. In computer agents,

185

Wallace

E1 is a Primary (P)
Mismatch Error (M)

E2 & E3: are both
Commission Errors
(C), that together
create E1. They are
also Primary Errors
in a causal chain.

Salience

E1 (P,M)

E2 (P,C)

E4 (S,C)

E5 (S,I)

E3 (P,C)

E6 (S,I)

E7 (S,I)

E3 gives rise to 3
Secondary Errors
(S) all of which
happen to be
Intrusions (I)

Figure 6: Multiple related errors result in a salience hierarchy

this type of error often occurs because the termination condition for a particular goal or
action is incorrectly specified.
Errors can also occur among subsequences in the behavior trace. This typically happens
after the novice begins to pursue an incorrect goal. In such a situation, there is a causal
relationship between the initial error and the sequence of errors that follows. We define two
more error forms based on these attributes: a primary error is the first in a causally linked
sequence of errors, secondary errors are subsequent errors in such a sequence. Although
problems in their own right, secondary errors can be corrected simply by correcting the
primary error. Often these occur because a higher level goal was incorrectly selected and
naturally led to an entire sequence of incorrect behavior.
Just as compound errors are more salient than simple errors because they concisely
describe multiple simple errors as well as the interactions between them, a primary error
is more salient than the secondary errors that follow. Note that since a single error can
act as both a primary and secondary error (if a hierarchy of cascading errors occurs),
the primary/secondary relationship creates a corresponding salience hierarchy. Figure 6
illustrates this relationship. Towards the top are primary compound errors and toward the
bottom are secondary individual errors. Correcting an error at any level in the hierarchy
will also resolve all descendant errors.
8.2.2 Method
Ideally, an empirical evaluation would directly examine how much human effort is saved by
using the behavior comparison methods during the development of a number of complex
human-level agents. However, developing the complex agents we’re interested in is a time
consuming task and developing multiple independent versions is beyond the scope of this
experiment. Instead, we have selected an approach that identifies the effectiveness of error
detection methods without directly examining development time. Using our method, we
evaluate the effectiveness of each error detection method by examining its ability to identify
different types of errors in development versions (novice versions) of a particular agent. By
examining the number of true errors detected, as well as false negatives and false positives,
186

Behavior Bounding: An Efficient Method for High-Level Behavior Comparison

1. Acquire a specification of correct (expert) behavior.
2. Construct a set of flawed novice agents.
3. Identify general differences by comparing the expert’s and the novice’s
knowledge.
4. Acquire suitable behavior traces from the expert and novice.
5. Manually catalog errors in each novice behavior trace.
6. Construct individual experiments by partitioning behavior traces into
multiple groups.
7. Evaluate how well each error detection method identifies the cataloged
errors.
Figure 7: An overview of the steps in our evaluation process

we can obtain a measure of the relative strengths and weakness of each approach without
directly examining how development time is impacted in a ongoing project. Our evaluation
process is described by seven high level steps outlined in Figure 7 and described in detail
below.
Our evaluation begins with a specification of correct behavior. Under normal development circumstances, the specification of correctness would be the domain expert’s behavior. For our experiments, however, we replace the domain expert with a correctly specified
expert-level agent, E, whose behavior we will attempt to reproduce. The idea of replacing
the human expert with a software agent may initially seem counterintuitive. After all, our
research seeks, in large part, to make it easier to create agents that reproduce human behavior, not the behavior of other software agents. However, this approach offers significant
advantages over other evaluations methods.
The first advantage gained by replacing the human domain expert with an expertlevel agent is that we can ensure that both the expert-level agent and the novice agent
(the agent that is being validated) represent their knowledge in a similar manner. This
provides a means of determining how the expert’s and novice’s behavior differ that might
not otherwise be available—not only can we examine instances of the actors’ behavior to
determine differences, but we can also directly compare the knowledge that guides their
behavior. This attribute is important for conducting performance assessments.
The second advantage gained by replacing the human expert with a software agent
is that we can test an error detection method’s efficacy without being influenced by the
complications of the knowledge acquisition process. Moreover, since we ultimately believe
that many aspects of human-level behavior can be duplicated by software agents, replacing
the human expert with an expert-level software agent should not change the generality of
our measurements. On the other hand, by examining behavior that is already encoded in
the software agent’s knowledge, there is the potential that this methodology will bias us

187

Wallace

toward examining behaviors that are easy to encode in software as opposed to the complete
breadth of human behavior.
Our expert-level agents, as well as the novice agents described below were implemented
with Soar (Laird, Newell, & Rosenbloom, 1987), a forward-chaining rule based system. Soar
provides natural constructs for defining the goal-subgoal relationships required by behavior bounding. In addition, Soar provides a programming interface that allows behavior
traces to be captured easily. Although Soar is naturally compatible with behavior bounding, it is by no means the only agent architecture that fits this criteria. Most rule based
systems can use task decomposition as a basis for problem solving even if the goal hierarchy must be implemented in the agent’s working memory. Such an agent design is easily
done in CLIPS (Giarratano & Riley, 1998) as demonstrated by Wallace and Laird (2000).
Apart from rule-based systems, many other agent architectures allow developers to define
an agent’s knowledge base and behavior using task decomposition relations. Two such
examples are PRS (Ingrand, Georgeff, & Rao, 1992) and PRODIGY (Veloso et al., 1995).
Given the expert-level agent (E), we begin the second step by constructing novice agents
(N0 , . . . , Nn ) which are partially correct implementations of the final desired behavior. The
novices are only partially correct since they pursue different sequences of goals and actions
than the expert-level agent. These differences arise because the novice-level agents do not
have the same knowledge as the expert-level agent. Instead, some portion of the novice’s
knowledge base has been purposely corrupted. Each expert/novice pair (E, N i ) will later
be examined by the comparison methods to identify similarities and differences between the
actors’ behavior.
Novices can be constructed in a number of different ways, but we focus on novices that
are generated by introducing random changes into the expert-level agent. Introducing random changes helps to ensure that we examine a wide range of possible errors and that
we minimize the potential to bias the experiments’ results. Moreover, by effectively maintaining a large body of shared knowledge between the expert and the novice agents, it is
straightforward to map the novice agent’s correct knowledge onto the expert’s knowledge as
well as to isolate problematic knowledge to a specific portion of the novice’s knowledge base.
This allows us to take maximum advantage of the fact that we are using an expert-level
agent as opposed to a human domain expert and mitigates some of the complications that
arise when counting elements in the confusion matrix.
The major drawback of constructing novice-level agents in this fashion is that it is
unclear whether the manner in which we manipulate the agent’s knowledge base is representative of flaws that would occur naturally during the development process. If our
comparison methods examined the novice-level agent’s knowledge base directly, this would
indeed be a serious concern. However, all of our comparison methods identify errors
phenomenologically—by examining the agent’s behavior. As a result, the main concern
should be that the novice-level agents we construct generate the same types of observable
errors as development version of these agents. Our novice-level agents create flaws that cover
all the error types we identified in Section 8.2.1. Thus, we should have a high degree of
confidence that the changes we introduced in the following experiments do represent many
of the observable errors we would expect to see in an actual development environment.
Once we have constructed a set of novice-level agents, we must determine the exact
set of behavioral errors they are capable of producing. This third step requires careful
188

Behavior Bounding: An Efficient Method for High-Level Behavior Comparison

manual examination of the knowledge used by, and the behavior produced by, both the
novice and the expert. We begin the process of documenting errors by analyzing how
the novice’s knowledge differs from the expert’s knowledge. Based on this analysis, we can
often identify general situations in which the novice’s behavior will diverge from the expert’s
behavior. These general situations provide a high-level description about the errors that
will arise. For example, we might be able to determine that the novice will fail to perform
a specific action when trying to accomplish a particular goal, or that it might pursue a goal
on inappropriate occasions. However, if we consider how difficult it can be to predict the
behavior of an intelligent agent simply by examining its knowledge, it is not surprising that
in many cases it is hard to determine the exact forms in which each of these general errors
may manifest using information about the differences in the agents’ knowledge alone. Some
of this information will require examinations of the behavior traces collected in the next
step.
The fourth step is to acquire concrete examples of both the expert’s and novice’s behavior
by gathering the behavior traces, BT E and BTNi , that will be used to compare the agents’
behavior. In most situations including those examined in this study, human-level agents will
be capable of performing their specified task in many different ways. In order to examine a
significant range of these behaviors, traces are selected randomly from this pool of possible
behaviors and then examined to ensure that two properties hold: 1) no two behavior traces
are identical; and 2) all of the predicted errors actually occur in at least one of the novice’s
behavior trace.
While we are examining the novice’s behavior traces to ensure that the second property
holds, we can also perform the fifth step in our process by cataloging the specific form or
forms in which each error manifests. In this way, we annotate all of the attributes of the error
(e.g., whether it is primary or secondary, omission or commission). This includes details that
may not have been clear during the initial assessment of how both actor’s knowledge differed
(step 3). The information cataloged during this process will be used later to determine the
set of errors that were and were not detected by a particular approach.
Cataloging which errors occur in each behavior trace is an extremely tedious process
representing the bulk of the experimental effort. As a result, we try to maximize our use
of each behavior trace by constructing families of individual experiments to evaluate the
impact of different sets of observational data without capturing and inspecting new behavior
traces.
Instead of simply running one experiment for each (E, N i ) pair, we run multiple experiments using different subsets of our observational data. This process begins after the
actor pair (E, Ni ) has been selected and after the behavior traces, BT Ni and BTE , have
been captured and inspected. At this point, we split the observations into a number of
subsets: nij ⊂ BTNi and ek ⊂ BTE to form individual experiments. A single experiment
consists of examining each comparison method’s performance on a pair of these subsets (n ij
and ek ). A family of experiments contains the experiments that compare all n ij to all ek
for a particular novice/expert pair. Thus, comparing four expert/novice pairs results in
four experiment families although the total number of individual experiments may be much
larger. By constructing experiment families in the way, we are able to examine the impact
of different observational data without being overwhelmed by the manual inspection task.

189

Wallace

At this point we are ready to begin evaluating each of the individual error detection
methods. It is important to recall that any error detection method that relies on examining
examples of behavior suffers from the potential problem that unless an error manifests in the
examples that are being examined, it cannot be detected. Thus, the goal of our experiments
is to determine how many of the errors that occur in the novice behavior traces can be
identified by a particular error detection method. Because our validation approach relies
on testing, we cannot hope to identify errors that do not occur in the captured behavior
traces.
Given two sets of behavior traces, one corresponding to the expert-level agent and the
other corresponding to the novice agents, the automated error detection method examines
these traces and prepares a report indicating similarities and differences in the behaviors.
This report will be more or less useful depending on how well the error detection method
performs. By definition, the expert-level agent is the standard of correct behavior, so
any true differences are instances of inappropriate behavior or errors. By examining the
information in the report, we determine whether any of the information in the summary
maps on to error forms identified in the manual examination of the novice’s behavior traces.
If so, these are instances of true positives (correctly detected errors) that improve the error
detection method’s performance score. At the same time we also want to identify how many
true negatives (as well as false positives and false negatives) have been identified. Used in
a real validation setting, as opposed to an evaluation setting, the process would be much
the same. The critical difference is that determining whether information in the summary
maps to true errors or to false positives would be likely to require additional investigation
either by manually examining some examples of behavior or by examining the novice agent’s
knowledge base.
8.2.3 Counting Errors
Because the error forms identified in Section 8.2.1 do not form sets with mutually exclusive
membership and because some forms are more salient than others, we must be careful
how true and false positives and negatives are calculated. Consider, for example, a highlevel error description such as The pilot does not always contact the control tower prior to
initiating a landing. Suppose that this error manifests in two ways: by the pilot failing to
contact the control tower completely, or by the pilot contacting the control tower after the
landing has been initiated. Depending on the circumstances, these manifestations may take
the form of an omission in the first case, and as an omission plus an intrusion in the second
case. In addition, since the second case involves an action being moved to an inappropriate
location in the agent’s behavior sequence, it is also an instance of a misplacement error.
This means that depending on the set of behavior traces being examined, the high level
error may manifest as just a single simple error (perhaps an omission), or as a set of three
errors (two simple errors and a misplacement). Exactly how we calculate what errors were
and were not recognized depends both on what errors manifest in the behavior traces, and
what errors are detected by the automated system.
Our approach to counting can be generalized by the following rules:

190

Behavior Bounding: An Efficient Method for High-Level Behavior Comparison

• If only simple errors (omission, commission, intrusion) are detected, count each as a
true or false positive depending on whether they correspond to actual errors in the
novice’s behavior.
• If compound errors (duplication, misplacement) are detected correctly, count true positives for the compound error and all of the simple errors that comprise the compound
error. If the compound error is detected incorrectly count it as a false positive.
• If a primary error (first error in a causal string) is detected correctly, count true
positives for the primary error and all of the secondary errors (subsequent errors in a
causal string) that are causally linked to it.
• False negatives are counted first by finding the set of errors that were not identified by
the error detection method. The count is then incremented by the minimum number
of additional errors required to cover all true errors.
One of the side effects of our counting method is that the number of errors reported
(RP ) by an error detection method may no longer be the sum of FP + TP. Instead,
one piece of information in the report can map to multiple true positives, thus TP ≥
RP − FP. To illustrate differences of brevity between reports that identify similar numbers
of true positives, we introduce the metric Report Density which we will use to assess each
comparison method’s performance.
Report Density =

TP
RP

Because report density makes no reference to the number of errors that go unidentified
by a particular behavior comparison metric, a complete assessment requires the use of a
second metric. For our experiments, we use sensitivity which is calculated as follows:
Sensitivity =

TP
TP + FN

Sensitivity measurements fall in the range [0, 1]. As sensitivity goes to one, all errors
are identified by information in the summary. Conversely, as sensitivity goes to zero, no
errors are identified by the data in the summary. Thus, we favor comparison methods
which can obtain higher report density without sacrificing sensitivity. In the following two
subsections we put the experimental framework and assessment metrics described thus far
to use evaluating the performance of behavior bounding and the benchmark sequential
methods in two distinct domains.
8.2.4 Object Retrieval Domain
Our first test environment is a simulated object retrieval domain in which an agent must
navigate a grid-based world to find and collect a pre-specified object (initial results appear in Wallace & Laird, 2003). This environment is relatively simple because it is both
discrete (no real valued sensors) and deterministic (no exogenous events). In addition,
agents operating in this environment generate behavior sequences of relatively short length:

191

Wallace

1

BB
action
goal

Sensitiviy

0.8
0.6
0.4
0.2
0
1

2

3

4

5

6

7

Experiment Family

Figure 8: Sensitivity in the object retrieval domain

Expert Behavior
P
A

P

P
A

P

P
B

P
B

P

Novice Behavior

P
A

P

A

B

P
A

P

P
A

P

P
B

P

P
B

P
B

P

P
A

P

A

B

P
A

Figure 9: Limitations of behavior bounding’s HBR in experiment family seven

approximately 20 to 30 goal or action elements are generated and the agent visits approximately 65 states. The agent’s complete goal hierarchy has a maximum depth of 5 and
contains 32 goal and action nodes together. Although this environment is simple in many
ways, it does serve as a reasonable test for behavior bounding. Critically, correct behavior
in the object retrieval domain requires reasoning (e.g., route planning) that relies on data
structures that are not fully represented within the goal/sub-goal hierarchy.
Figure 8 illustrates the sensitivity across the seven experiment families in the object
retrieval domain (ordering in the figure is arbitrary). The figure illustrates two main phenomena. The first and most obvious is that overall, behavior bounding is better at identifying behavior errors than either the goal or action based sequential comparison methods.
In fact, behavior bounding equals or betters the sensitivity of the combined action and goal
sequence described in Section 3 on all but the final experiment family. The poor performance on this final experiment family is the second phenomena. This is due to limitations
of the hierarchical representation itself which we discuss below.

192

Behavior Bounding: An Efficient Method for High-Level Behavior Comparison

8

BB
action
goal

Report Density

7
6
5
4
3
2
1
0
1

2

3

4

5

6

7

Experiment Family

Figure 10: Report Density in the object retrieval domain

In the seventh experiment family, the expert’s behavior contains traces in which a particular goal is decomposed in two ways. For simplicity, we’ll call this problematic goal P .
The first way the expert completes P is by pursuing two subgoals, A and B, in the following
sequence: A, B, A. The second decomposition is performed by pursuing these same subgoals but in the simplified sequence: A, B. Importantly, the expert will never attempt the
following decomposition: P → B, A. However, when the first behavior trace is processed
to form the hierarchical behavior representation, over-generalization occurs. As discussed
previously, the HBR contains only a single node to represent each instance of identically
named goals with the same lineage. Thus when the first trace, containing the decomposition
P → A, B, A, is processed, only three nodes are formed—one for P , A, and B respectively.
To accommodate the fact that A is observed to occur both before and after B, temporal
constraints are completely generalized between these two nodes. This situation is illustrated
on the left hand side of Figure 9. Unfortunately, this behavior representation fails to capture
the fact that the expert would never perform P → B, A. Thus, when the novice’s behavior
traces are processed (illustrated on the right hand side of Figure 9), it is of little surprise
that the same HBR is produced and no differences are detected between the expert and the
novice. In contrast, this error is readily identified by the goal-based benchmark approach
(M2 ). We could address this particular problem using a modified version of the HBR as we
will describe in Section 11.2. However, even this approach requires some additional changes
to the agent’s internal representation for this particular behavior to be encoded correctly.
Behavior bounding’s ability to detect errors while maintaining very concise reports is
illustrated by its relatively high report density (see Figure 10). Recall that report density
measures the amount of useful information in an error detection method’s summary. Scores
of one indicate that on average one error could be detected for each discrepancy indicated
in the summary; scores less than one indicate the summary contains false positives. Report
density scores higher than one are also possible but only when reports remain exceedingly
concise by identifying high-level errors that correspond to multiple low-level errors. Because
of behavior bounding’s ability to concisely represent relationships between goals via decomposition and ordering constraints, it is well suited to identifying misplacement and goal-level

193

Wallace

1

BB
action
goal

Sensitiviy

0.8
0.6
0.4
0.2
0
1

2

3

4

5

6

Experiment Family

Figure 11: Sensitivity in the MOUT domain

primary errors. Moreover, because the structures being compared are relatively small (compared to the set of sequences being compared in the sequential approach) behavior bounding
can maintain a relatively low false positive count.
Behavior bounding’s performance in the object-retrieval environment is encouraging.
Overall, it performs well against the benchmark sequential comparison approaches even
though its internal representation of behavior is constrained by our desires to maintain
efficiency across environments of differing complexity.
8.2.5 MOUT Domain
In contrast to the object retrieval domain, the MOUT Environment represents a significant
increase in overall complexity. The environment is built on top of Unreal, a commercial 3-D
video game. It is continuous, non-deterministic (exogenous events occur frequently) and
has much longer sequence lengths than the object retrieval domain: between 30 and 200
goal/action elements are generated and the agent visits approximately 4000 distinct states
per behavior trace (the state typically changes many times between the selection of a new
goal or action). The goal hierarchy for the MOUT domain is larger than for the object
retrieval domain containing 44 nodes and a maximum depth of 6. Equally important to the
added complexity of this environment is the fact that MOUT was built independently from
our research into behavior comparison techniques. Thus, it provides an important reference
point for judging the overall effectiveness of our techniques.
Figure 11 illustrates behavior bounding’s sensitivity compared to that of the sequential
approaches. Results here are not particularly dramatic, but behavior bounding does have
fewer instances of zero sensitivity (inability to identify any errors) than either of the sequential approaches. In addition, this figure points out the inherent scaling problems associated
with the sequential method and illustrates their dramatic effects in more complicated environments. Experiment families three and six where behavior bounding’s sensitivity drops
to zero are worthy of note. Here, errors are again due to one aspect of the hierarchical
behavior representation becoming over-generalized.

194

Behavior Bounding: An Efficient Method for High-Level Behavior Comparison

0.3

BB
action
goal

Report Density

0.25
0.2
0.15
0.1
0.05
0
1

2

3

4

5

6

Experiment Family

Figure 12: Report Density in the MOUT domain

Some of behavior bounding’s strengths are better illustrated when we examine report
density, as in Figure 12. Compared against either of the sequential approaches, behavior
bounding’s report density is exceedingly high. In cases where true errors are detected, the
report density averages near 0.20, detecting about one true error for every five differences
reported in the summary. Even though report density is lower than in the relatively simple
object-retrieval domain, it is still high enough to be useful for testing an agent’s knowledge
base. Equally worthy of note is the fact that even when the two benchmarks methods were
more sensitive than behavior bounding, the usefulness of their error reports are questionable
at best due to the exceedingly low report density.
Although behavior bounding clearly outperformed the sequential methods in the MOUT
domain, there is obvious room for improvement. To identify why its efficacy was low
compared to the object-retrieval domain, we looked back at the domain itself and at the
novice-level agents that we examined.
One noticeable source of false positives was due to so called floating operators. Floating
operators are not performed in service of their parent goal. Essentially, they are goals
or actions that occur opportunistically, potentially at any location in the goal hierarchy
in order to respond to the dynamics of the environment without explicitly suspending or
canceling the agent’s other goals. In other agent architectures, floating operators may be
better described as concurrent top-level goals. Soar does not support concurrent goals,
however, and floating operators are the prevailing method for this encoding this type of
opportunistic behavior.
Because floating operators do not work in service of their parent goal, they effectively
break the paradigm of the hierarchical behavior representation and their effects can be
twofold. First, they are likely to cause over-generalization by inappropriately changing the
parent’s node type from And to Or. Second, if limited observations are available, floating
operators can result in representations of the novice agent’s behavior that are inconsistent
with the structure of the expert’s behavior representation (i.e., the floating operator may
be observed in different parts of the expert’s and novice’s hierarchy). This situation will

195

Wallace

0.7

BB (if)
BB

Report Density

0.6
0.5
0.4
0.3
0.2
0.1
0
1

2

3

4

5

6

Experiment Family

Figure 13: Report Density in the MOUT domain ignoring floating operators

result in a behavior representation that fails to satisfy the basic structure requirements of
the lower boundary node.
There are a number of potential methods that could be used to circumvent these problems. One method would be to create a level of indirection between the expert’s native
behavior representation and what is presented in the behavior traces. Through some preprocessing of the behavior traces, it would be possible to modify the topology of the expert’s
goal hierarchy so that floating operators no longer appeared (i.e., so they were mapped to
static locations in the hierarchy). Although this could help circumvent the issues with floating operators, it may require significant engineering resources to process the behavior traces.
More importantly, however, this introduces another source for errors and confusion and is
probably best avoided as a result. Another approach would be to tag floating operators
so they could be treated differently by the Create-Hierarchy algorithm 4 . This would
increase the initial cost of using behavior bounding to validate an agent but it is likely
that this cost would remain minor. A third method is simply to ignore floating operators
altogether. Although this, of course, has the potential of reducing the number of errors that
can be detected, it is also likely to have a significant payoff in terms of reducing false positives. Moreover, because floating operators do not fit naturally into behavior bounding’s
structure, it is likely that errors that do occur in the floating operators might be missed
even if they were included in the HBR.
Figure 13 illustrates the effect on report density when floating operators are ignored
(note change of scale on y-axis). As expected, the number of false positives is reduced, thus
increasing the report density on all experiment families other than 3 and 6 (where no errors
are correctly identified with either method). Although the effect is somewhat subtle, it does
raise the average report density (excluding experiment families 3 and 6) by nearly a factor
of 2, from 0.18 to 0.35, an effect that makes the already acceptable error summary more
useful.
4. While it may be possible to tag floating operators automatically based on where they occur in the goal
hierarchy and by what generalizations they cause, it would be safest to require the knowledge engineer
to provide the tags before the behavior comparison was performed.

196

Behavior Bounding: An Efficient Method for High-Level Behavior Comparison

Modification
Manifestation
Distinct Behaviors
Consistent BTs
Avg. BT Length

Expert

Novice-A

Novice-B

N/A
N/A
4
N/A
67

New Proposal
Intrusion
12
4
69

Missing Preference
Commission
8
4
68

Table 1: Properties of expert & novice agents in the validation efficacy test

9. Efficacy as a Validation Tool
We have shown that behavior bounding has acceptable performance in two domains of
distinct complexity and argued that it would be well suited for detecting errors in many
other goal oriented environments. However, up to this point, we have only hypothesized
that the error reports provided by behavior bounding will decrease validation cost; we have
not provided any direct evidence.
To substantiate this claim, we performed an experiment in which five human participants
attempted to find and correct flaws in an agent’s behavior both with and without information from behavior bounding’s error report 5 . As in previous experiments, agents were
implemented in the Soar architecture. Each participant was a member of the Soar research
group with at least six months of Soar programming experience. Participants identified two
behavior flaws: one with, and one without the aid of behavior bounding’s error report. In
the unaided situation, participants relied on standard debugging tools and techniques that
they were already in the practice of using. Once the flaw was identified, the participants
corrected the agents’ knowledge using VisualSoar, the standard Soar development environment. In the aided situation, participants were given behavior bounding’s error report to
help make sense of the agent’s behavior. Thus, in the experiments presented below, there
are two conditions: aided, and unaided. Condition is a within-subject variable, which is to
say that each participant experiences both.
Our test-bed agent was taken from the object retrieval domain discussed in Section 8.2.4.
The initial setup followed similar lines as our earlier experiments. We began by constructing
an expert-level agent that exhibited “correct” behavior. This agent could perform its task
in four distinct but similar ways and required 78 Soar rules to encode. Note that in normal
use, observations of correct behavior are likely to come from human experts. However, by
creating a correct agent first, it is possible to describe precisely how flawed agents differ
from the ideal (both in behavior and in their implementation). This property is critical for
the experiment.
After creating the expert-level agent, we constructed two novice-level agents (Novice-A
and Novice-B). The participants’ task was to identify and correct any behavioral differences
between the novice agents and the expert-level agent. Because each participant would
validate both novice agents (using a different method for each one), one of our primary
5. Initial results reported by Wallace (2007).

197

Wallace

desires was to construct novice-level agents in such a way that they would be similarly
difficult to validate. To help ensure that this was the case, we limited the differences in
the novice’s and expert’s knowledge to a single rule. In the case of Novice-A, one rule was
added that resulted in the agent performing a different sequence of actions than the expert.
In the case of Novice-B, a preference rule was removed resulting in two discrepancies: one
in the parameters of the agent’s internal goal, and another in the parameters of the agent’s
primitive action. Aside from the differences mentioned above, the behavior of both novicelevel agents was similar to that of the expert in all other respects.
Table 1 illustrates some of the important properties of the expert-level and novice-level
agents. The first and second rows indicate the change that we made to construct each of
the novice agents and the form of error that results from these changes. The third row
indicates how many distinct behavior traces each agent is capable of generating. This value
is important because it gives an indication of how many behavior traces the user might
need to examine in order to get a good understanding of the range of behavior each agent
is capable of producing. The fourth row indicates how many of the novice’s behavior traces
were consistent with expert behavior traces (i.e., error free). Finally, the fifth row indicates
the average length of each agent’s behavior trace. This gives some indication as to how
much information must be examined in each instance of behavior.
It is worth noting that the flaws introduced into these agents are minor by most standards. In this experiment, flawed behavior does not result in deadlocks or infinite loops.
Indeed, when viewed in the classical sense, these agents are not necessarily “flawed”. They
are successful in achieving the desired final state (finding the lost object). However, the
agents do not pursue the same trajectories through state/action/goal space, and the participants’ task is to determine how these trajectories differ and then find and correct the
fault that causes the difference.
Because none of the participants had used, or even seen, the graphical behavior comparisons generated by behavior bounding, they were given a short, 15 minute, tutorial to
become familiar with the graphical behavior summary provided by our interface. In addition, participants were asked to read a short summary that provided a description of the
debugging task, a summary of the agent’s behavior, and a plain English description of some
salient goals and actions that would be pursued during task performance. This overview
was intended to familiarize the users with the agents and the domain without requiring each
participant to build their own agent from the ground up.
At this point, participants were randomly assigned an agent to validate. We attempted
to mitigate bias by varying the order in which the aided and unaided tests were presented as
well as the pairing between the agent and the validation method. For each experiment, we
asked the participants to indicate when they were ready to modify the agent’s knowledge
and to articulate what changes they believed were required. This allowed us to measure the
amount of time needed to identify the behavioral flaw as well as the total time required to
correct the agent’s behavior.
During the first phase of the debugging session, participants identified how the novice
agent’s behavior differed from the standard set by the correct expert-level agent. In the
unaided situation, no specific instructions were given on how to identify errors. Participants
were free to look for errors using whatever debugging techniques they had developed in the
course of working with Soar. Similarly, in the aided situation no specific instructions on
198

Behavior Bounding: An Efficient Method for High-Level Behavior Comparison

35

Identify
Correct
Only Fix

30

Unaided

25
20
15
10
5
0
0

5

10

15
20
Aided

25

30

35

Figure 14: Time required to identify and correct errors using two techniques

how to identify errors were given. Participants generalized their tutorial experience to
interpret the information in behavior bounding’s error report and to identify what changes
would be required to make the flawed agents behave correctly. In both situations, when the
participant correctly identified the error in the flawed agent’s behavior (e.g., by saying “The
novice does not always perform action X before action Y”), the elapsed time was recorded.
We call this the time required to identify the error.
The second phase of the debugging session began once the participant determined that
they were ready to try modifying the flawed agent’s knowledge in order to correct the
observed error. Regardless of whether the error was identified using standard techniques or
behavior bounding in the first phase, participants used the VisualSoar editing environment
(a standard part of Soar’s development environment) for this portion of the task. Once
the participant had made changes, they re-examined the novice agent’s behavior to ensure
that the problem had in fact been corrected. When the participant was confident that the
problem was resolved, the clock was stopped and the time spent from the beginning of
phase one until the end of phase two was recorded as the time needed to correct the agent’s
behavior6 .
Figure 14 shows the time spent by each participant on both the aided and unaided tasks
and highlights the benefits of behavior bounding. The x-coordinate indicates time spent
debugging in the aided situation when information from behavior bounding’s error summary
was used while the y-coordinate indicates time spent in the unaided situation when only
6. There were no cases in which the participant believed the agent’s behavior had been corrected when in
fact errors remained.

199

Wallace

the participant’s normal debugging techniques were used. Three sets of points are plotted:
time to identify the error; time to correct the error; and time required only for the fix (i.e.,
the difference between time to correct and time to identify). The line y = x is also plotted
for reference; points that lie to the left of this line indicate that the participant performed
better (i.e., faster) in the aided situation.
The cluster of points nearest to the origin (labeled “only fix” in the legend) indicate
that behavior bounding had little if any effect on the time required to fix the agent’s
knowledge error once it was identified. Instead, behavior bounding’s impact, as expected,
comes from the reduction in time required to identify the error. This leads to a reduction
in the overall time required for the validation task. A paired t-test was used to determine
statistical significance of each of the three timed operations illustrated in the figure. Not
surprisingly, the test confirms a statistically significant performance advantage is gained
by using information from behavior bounding on both the time to identify and time to
correct the error (p = .0006, p = .0002 respectively). The paired t-test does not indicate a
statistically significant difference in the times required simply to fix the error for the aided
and unaided situations (p = .85), again matching expectations.
From this data, it seems safe to conclude that the error report provided by behavior
bounding does, in fact, provide information that is both relevant to identifying differences
between two agents’ behavior and useful in isolating faulty knowledge. Although on one
level these results may be considered best cases because we constructed errors that we
believed would demonstrate the effectiveness of behavior bounding, there are a number of
reasons why these results may be on the conservative side of optimistic.
First, we would expect the HBR to be more useful as the complexity of the domain
and of the agent’s behavior increases—developers wishing to examine raw behavior traces
will need to look at longer traces and more traces for complex environments whereas with
the HBR, they only need to view one data structure. Second, the test conducted above is
clearly influenced by the design of behavior bounding’s user interface. We conducted no
formal experiments to increase the quality of the interface, so it is quite possible that future
implementations would be capable of delivering information more effectively to the user,
thus producing an increase in efficiency.

10. Related Work
As noted previously in Section 4, a number of other areas of artificial intelligence, particularly machine learning have addressed problems closely related to those we examined here.
In the following subsections, we briefly comment on some of the most salient areas.
10.1 Plan Recognition
The behavior comparison we have described is related to keyhole plan recognition (Albrecht,
Zukerman, & Nicholson, 1998), or more closely, to the team monitoring by overhearing
work of Kaminka, Pynadath, and Tambe (2002). In team monitoring, the objective is to
determine what task an agent or set of agents is performing given limited observations of
their actions and the communications that pass between them. Plan recognition is possible, in part, because a complete team-level plan allows the monitoring system to identify
the agent’s goals as observational information is acquired. When enough information is ob200

Behavior Bounding: An Efficient Method for High-Level Behavior Comparison

tained, a single plan can be identified and ascribed to the agent(s). In behavior comparison,
the objective is similar. The salient difference between our work and plan recognition is
that we are not given the plan library; instead we are attempting to recreate a model of its
execution through a series of observations in order to determine whether both actors will
pursue their goals in the same manner (i.e., have the same plan library).
10.2 Learning By Observation
A number of systems (e.g, van Lent & Laird, 1999; Wang, 1995; Konik & Laird, 2006)
have also been developed to learn procedural rules or plan operators from observations
of expert behavior. Wang’s OBSERVER (Wang, 1995) learns STRIPS style operators;
van Lent’s KnoMic (van Lent & Laird, 1999) learns production rules for the Soar agent
architecture and Konik’s system (Konik & Laird, 2006) creates first order logic rules that
are later converted into Soar productions. All three systems use similar behavior traces as
our approach, although Wang’s OBSERVER works only with primitive actions so there is
no notion of non-atomic goals and thus no need to annotate them in the behavior traces.
Of these systems, Konik’s has been demonstrated within the most complex domain (a 3-D
virtual environment in which an agent must learn to successfully navigate a series of rooms).
The key difference between our approach and theirs lies in the fundamental premise.
While we are interested in learning a simple and concise model of behavior that an outside
third-party can use to validate an existing (but untrusted) agent, these systems aim to
learn the agent’s knowledge altogether. While learning complete task knowledge is clearly
an important goal for the community, there remain a set of important task domains (e.g.,
military and mission critical applications) where learned systems are often treated with
skepticism and human coded systems are still preferred. The approach we have described,
however, could be useful to help bridge this gap by allowing skeptical parties to validate
the behavior of learned systems. Thus, while it may seem on the surface that by solving
the “learning executable task knowledge” problem one also solves the behavior comparison
problem we have outlined, that is not the case—in mission critical applications, the agent’s
behavior still requires validation and a human in the loop to “sign off” on its correctness.
Moreover, when knowledge is learned instead of engineered, the validation task is likely to
become much more difficult as there is no one to document the system or to field questions
about the function of any particular component.
10.3 Hierarchical Reinforcement Learning
Reinforcement Learning seeks to provide methods by which an agent can learn to approximate an optimal behavioral strategy while interacting with its environment. In reinforcement learning, optimality is defined by a reward function that is outside of the agent’s
control (it is part of the environment) and the agent learns through interaction with the
environment how to maximize this function. Traditional (flat) approaches to reinforcement
learning such as Q-Learning (Watkins & Dayan, 1992) may require a long training time to
converge on an optimal policy. Price and Boutilier (2003) show how reinforcement learning
can be facilitated by observing a mentor perform a task while Hierarchical Reinforcement
Learning (Dietterich, 2000; Andre & Russell, 2002; Marthi, Russell, Latham, & Guestrin,

201

Wallace

2005) seeks, in part, to reduce the complexity of the learning problem with the use of
external domain knowledge in the form of a programmer-defined action hierarchy.
Both traditional Reinforcement Learning (RL) and Hierarchical Reinforcement Learning (HRL) differ significantly from our approach in three fundamental ways. First, as
with the method described in the previous subsection, the goal in (H)RL is to learn an
executable model for behavior, not a model that can be used to help validate a system.
Second, in (H)RL, models are learned via interaction with the environment and with an
environmentally defined reward function. Instead, we are interested in learning directly
from observation of expert behavior without experimental interaction in the environment.
Finally, unlike both RL and HRL, we do not assume the existence of a reward function and
moreover we are not interested in optimal behavior in any sense other than close approximation to human behavior.
Aside from these important differences, there is a commonality between Hierarchal Reinforcement Learning and our approach that stems from the behavior model. An open issue
in Dietterich’s presentation of MAXQ (Dietterich, 2000) and restated by Barto and Mahadevan (2003) is whether the programmer-supplied information (the MAXQ task-graph)
in Hierarchical Reinforcement Learning could be acquired automatically. Each subtask M i
in a MAXQ task-graph is a three tuple hT i , Ai , R̃i i. Ti (si ) partitions the state space into
active states Si and terminal states Ti (a subtask can only be executed if the current state
is in Si ). Ai is a set of actions that can be performed to achieve the subtask and R̃i (s0 |s, a)
is a pseudo reward function indicating how desirable each terminal state is for this subtask.
Our approach could be used to help construct part of the MAXQ task graph directly
from observations. First, the goal/subgoal hierarchy we build can be used directly to identify
Ai , the set of actions that can be performed in each subtask. Second, some task parameters
that we learn are tied to information in the state (this relation can be observed directly in
the behavior trace). This information combined with the temporal constraints we learn for
all goal/action nodes could be used to identify some of the conditions when a task could
be entered (some properties of the active states identified by the predicate T i ). Together
this could help construct the MAX-Q task graph based on observations of an expert’s
performance.
10.4 Inverse Reinforcement Learning
Inverse Reinforcement Learning (IRL) (e.g., Abbeel & Ng, 2004; Ramachandran & Amir,
2007) attempts to reconstruction an implicit reward function given a set of example behaviors. IRL in combination with RL has been used in simple domains to reproduce behavior
for which there is no explicit reward function. This would permit a system to, for example,
learn to model a human expert’s behavior by 1) reconstructing the expert’s implicit reward
function by observing example behaviors and then 2) interacting with the environment to
generate a policy that maximizes this implicit reward. Together, these technologies provide
a potentially powerful alternative to the learning by observation methods described previously. However, to the best of our knowledge IRL has not yet been demonstrated within
a hierarchical setting, and so the learning by observation methods still present the current
state of the art for learning hierarchical task knowledge.

202

Behavior Bounding: An Efficient Method for High-Level Behavior Comparison

11. Extensions to Behavior Bounding and Future Directions
Our experiments with behavior bounding have all yielded encouraging results. Yet, in
the complex MOUT domain, our results do leave room for improvement. In Section 5,
we noted some of the representational limitations of behavior bounding’s HBR. Here, we
examine extensions to behavior bounding that could positively affect its performance and
briefly describe a promising direction for future work. We leave the implementation of these
extensions and detailed discussion as future work.
11.1 Manual Definition of Lower Boundary Node
By itself, the lower boundary is a minimal specification of the parameters necessary for
correct behavior. That is, it does not contain all the constraints required to discriminate
between correct and incorrect behavior. Although we have suggested that the lower boundary node is easily formed by completely generalizing the upper boundary node, a better
approach may be to construct it manually.
The hierarchy represented by the lower boundary node simply identifies the space of
potentially acceptable goal decompositions. As a result, it would be logical to create this
structure early in the design phase as expert knowledge is being acquired for the agent.
Lee and O’Keefe (1994) as well as Yen and Lee (1993) have argued independently that
constructing an overview of the ways in which goals decompose into sub-goals and primitive
actions is an important step in knowledge acquisition. Moreover, they argue that identifying
the relationship between goals, sub-goals and primitive actions helps to organize the agent’s
knowledge and serves as a foundation for further knowledge acquisition. Thus, it may be the
case that constructing the lower boundary node manually is a process that introduces little
or no additional effort on the part of the domain expert and the knowledge engineer. In
fact, it may actually benefit knowledge acquisition by making the process more structured
and directed.
If constructing the lower boundary node by hand is a relatively low cost process, it is
reasonable to ask how this manual effort could be leveraged to improve behavior bounding’s
performance. One such use of the manually constructed HBR is to help validate the agent’s
design early during the implementation process. It is generally believed that the earlier
validation can take place, the less costly it will be. By constructing the lower boundary
by hand, it may be possible to identify whether the agent adheres to these constraints
by statically analyzing its knowledge—without needing to see the agent interact with the
environment.
11.2 Sometimes/Always Constraints
Another potentially useful modification to the HBR would be to change the association
of the node type constraints. In the current version of behavior bounding, And and Or
constraints are associated with parent goal nodes. Alternatively, we might associate similar
labels with the child nodes such as Sometimes and Always. Although the change is subtle,
it would offer modestly more representational power. The semantics of And and Or nodes
are easily covered: an And node is simply one in which all children are Always while an
Or node is one in which all children are Sometimes. The semantics of Sometimes and

203

Wallace

Always also make it possible to encapsulate new decomposition relations that do not occur
with the And/Or relation.
Recall the problematic behavior in Section 8.2.4 where the HBR fails to correctly encode
the proper decomposition relations (specifically that goal P can decompose into subgoals
A, B, A or into subgoals A, B but not into B, A). Sometimes/Always constraints can
encode this decomposition, albeit only if an additional layer of subgoal is added to the
task specification. By introducing two new subgoals so that P decomposes into C ∗ , D 7 and
C decomposes into A∗ , B ∗ while D decomposes into A∗ , we would be able to encode the
correct behavioral patterns with respect to P, A, and B with the only caveat of having to
interject two new goals C and D. Of course, the point of this discussion is not to justify
such ad-hoc modifications to the task structure, but rather to show a concrete instance
where Sometimes/Always constraints may add beneficial representational power.
Sometimes/Always constraints have no effect on the learnability or construction cost
of the HBR. And while we have not tested this modification in detail, preliminary results
in the MOUT data sets do indicate a minor improvement in performance for this domain.
11.3 Additional Enhancements
Two additional enhancements to the HBR are also left as future work. The first is the ability
to deal with concurrent goals or actions. As Soar does not support concurrent operators,
this cannot be tested within our exiting system. However, if such support were added to
the HBR, it may be possible to avoid some of the issues associated with floating events
encountered in the MOUT domain. The second enhancement would be to allow more than
one node to be constructed to represent a given action/goal within a particular context.
In the current representation, there are no two sibling nodes with the same name (there is
exactly one node to represent all identically named goal/actions within any context). While
this keeps the representation simple, it also can be held responsible for some representational
problems like the one discussed in Section 8.2.4. The disadvantage of this approach is that
it is unclear when new nodes should be added to the hierarchy. If a new node is added each
time a goal/action is pursued, then the hierarchy grows much more rapidly (directly as a
function of the length of the behavior tracing) increasing the computational complexity and
decreasing the rate of generalization.
11.4 Behavior Bounding in the Runtime Environment
A promising direction for additional future work is to use the ideas presented in this paper,
specifically the constraints contained in the upper-boundary node’s behavior representation, to monitor an agent’s behavior at runtime. This approach, which we have recently
begun to explore, provides a mechanism for determining when an agent may be making
inappropriate decisions (Wallace, 2005b, 2005a). Inconsistencies between an agent’s desired
course of action and the constraints specified by the upper boundary node could be used
to enforce social policies such as interaction protocols between groups of agents or to dynamically adjust an agent’s degree of autonomy if it begins to make questionably choices.
Moreover, the high-level constraints specified by the hierarchical behavior model require
7.

∗

indicates an ALWAYS node

204

Behavior Bounding: An Efficient Method for High-Level Behavior Comparison

no direct knowledge of the agent’s underlying implementation language (only of its goal
decomposition). This means that our approach could also be used as a safeguard against
implementation errors in agents built by third parties that may not have been adequately
validated.

12. Contributions
We have introduced behavior bounding, a model-based approach for comparing two actors’
behavior. This novel approach uses a hierarchical behavior representation motivated by
the desire to build a high-level model of behavior from observations of either human or
computer agent performance that is efficient to create and maintain and effective in use.
We have demonstrated how behavior bounding meets these requirements by providing both
theoretical and empirical support for these claims. Finally, we have shown that information from behavior bounding’s comparison can significantly aid the process of identifying
problems in an agent’s behavior, thus speeding knowledge-base validation by a significant
factor.

Acknowledgments
I would like to thank John Laird for his help in reviewing early versions of this paper, along
with members of the UM Soar research group who participated in the user study. Portions of
this work were supported by the Office of Naval Research under contract N61339-99-C-0104.

References
Abbeel, P., & Ng, A. Y. (2004). Apprenticeship learning via inverse reinforcement learning.
In Proceedings of the Twenty First International Conference on Machine Learning,
pp. 1–8.
Albrecht, D. W., Zukerman, I., & Nicholson, A. E. (1998). Bayesian models for keyhole
plan recognition in an adventure game. User Modeling and User-Adapted Interaction,
8 (1-2), 5–47.
Andre, D., & Russell, S. J. (2002). State abstraction for programmable reinforcement
learning agents. In Proceedings of the Eighteenth National Conference on Artificial
Intelligence, pp. 119–125.
Anrig, B., & Kohlas, J. (2002). Model-based reliability and diagnostic: A common framework for reliability and diagnostics. In Stumptner, M., & Wotawa, F. (Eds.), DX’02
Thirteenth International Workshop on Principles of Diagnosis, pp. 129–136, Semmering, Austria.
Barto, A. G., & Mahadevan, S. (2003). Recent advances in hierarchical reinforcement
learning. Discrete Event Dynamic Systems: Theory and Applications, 13, 343–379.
Bordini, R. H., Fisher, M., Visser, W., & Wooldridge, M. (2004). State-space reduction
techniques in agent verification. In AAMAS ’04: Proceedings of the Third International
Joint Conference on Autonomous Agents and Multiagent Systems, pp. 896–903.
205

Wallace

Bordini, R. H., Fisher, M., Visser, W., & Wooldridge, M. (2006). Verifying multi-agent
programs by model checking. Autonomous Agents and Multi-Agent Systems, 12, 239–
256.
Dietterich, T. G. (2000). Hierarchical reinforcement learning with the MAXQ function
decomposition. Journal of Artificial Intelligence Research, 13, 227–303.
Erol, K., Hendler, J., & Nau, D. S. (1994). HTN planning: Complexity and expressivity. In
Proceedings of the Twelfth National Conference on Artificial Intelligence, pp. 1123–
1128. AAAI Press/MIT Press.
Fisher, M. (2005). Temporal development methods for agent-based systems. Autonomous
Agents and Multi-Agent Systems, 10, 41–66.
Giarratano, J., & Riley, G. (1998). Expert Systems: Principles and Programming. PWS
Publishing Co., Boston, MA.
Haussler, D. (1988). Quantifying inductive bias: AI learning algorithms and Valiant’s learning framework.. Artificial Intelligence, 36, 177–221.
Ingrand, F. F., Georgeff, M. P., & Rao, A. S. (1992). An architecture for real-time reasoning
and system control. IEEE Expert, 7 (6), 33–44.
John, B. E., & Kieras, D. E. (1996). The GOMS family of user interface analysis techniques:
Comparison and contrast. ACM Transactions on Computer–Human Interaction, 3 (4),
320–351.
Jones, R. M., Laird, J. E., Nielsen, P. E., Coulter, K. J., Kenny, P., & Koss, F. V. (1999).
Automated intelligent pilots for combat flight simulation. AI Magazine, 20 (1), 27–42.
Kaminka, G. A., Pynadath, D. V., & Tambe, M. (2002). Monitoring teams by overhearing:
A multi-agent plan-recognition approach. Journal of Artificial Intelligence Research,
17, 83–135.
Kirani, S. H., Zualkernan, I. A., & Tsai, W.-T. (1994). Evaluation of expert system testing
methods. Communications of the ACM, 37 (11), 71–81.
Konik, T., & Laird, J. E. (2006). Learning goal hierarchies from structured observations
and expert annotations. Machine Learning, 64 (1–3), 263–287.
Laird, J. E., Newell, A., & Rosenbloom, P. S. (1987). Soar: An architecture for general
intelligence. Artificial Intelligence, 33 (1), 1–64.
Lee, S., & O’Keefe, R. M. (1994). Developing a strategy for expert system verification and
validation. IEEE Transactions on Systems, Man and Cybernetics, 24 (4), 643–655.
Lucas, P. (1998). Analysis of notions of diagnosis. Artificial Intelligence, 105, 295–343.
Marthi, B., Russell, S., Latham, D., & Guestrin, C. (2005). Concurrent hierarchical reinforcement learning. In Proceedings of the International Joint Conference on Artificial
Intelligence 2005, pp. 779–785.
Menzies, T. (1999). Knowledge maintenance: the state of the art. The Knowledge Engineering Review, 14 (1), 1–46.
Mitchell, T. M. (1982). Generalization as search. Artificial Intelligence, 18 (2), 203–226.

206

Behavior Bounding: An Efficient Method for High-Level Behavior Comparison

Mitchell, T. M. (1997). Machine Learning. McGraw-Hill.
Murphy, P. M., & Pazzani, M. J. (1994). Revision of production system rule-bases. In
Proceedings of the Eleventh International Conference on Machine Learning, pp. 199–
207. Morgan Kaufmann.
Price, B., & Boutilier, C. (2003). Accelerating reinforcement learning through implicit
imitation. Journal of Artificial Intelligence Research, 19, 569–629.
Ramachandran, D., & Amir, E. (2007). Bayesian inverse reinforcement learning. In Proceedings of the International Joint Conference on Artificial Intelligence 2007, pp. 2586–
2591.
Rickel, J., Marcella, S., Gratch, J., Hill, R., Traum, D., & Swartout, W. (2002). Toward
a new generation of virtual humans for interactive experiences. IEEE Intelligent
Systems, 17 (4), 32–38.
Shortliffe, E. H. (1987). Computer programs to support clinical decision making. Journal
of the American Medical Association, 258 (1), 61–66.
Swartout, W., Hill, R., Gratch, J., Johnson, W. L., Kyriakakis, C., LaBore, C., Lindheim,
R., Marsella, S., Miraglia, D., Moore, B., Morie, J., Rickel, J., Thiebaux, M., Tuh,
L., Whitney, R., & Douglas, J. (2001). Toward the holodeck: Integrating graphics,
sound, character and story. In Proceedings of the Fifth International Conference on
Autonomous Agents, pp. 409–416.
Traum, D., Rickel, J., Gratch, J., & Marsella, S. (2003). Negotiation over tasks in hybrid
human-agent teams for simulation-based training. In AAMAS ’03: Proceedings of
the Second International Joint Conference on Autonomous Agents and Multiagent
Systems, pp. 441–448.
Tsai, W.-T., Vishnuvajjala, R., & Zhang, D. (1999). Verification and validation of
knowledge-based systems. IEEE Transactions on Knowledge and Data Engineering,
11 (1), 202–212.
van Lent, M. C., & Laird, J. E. (1999). Learning hierarchical performance knowledge
by observation. In Proceedings of the 1999 International Conference on Machine
Learning, pp. 229–238.
Veloso, M., Carbonell, J., Perez, A., Borrajo, D., Fink, E., & Blythe, J. (1995). Integrating planning and learning: The PRODIGY architecture. Journal of Theoretical and
Experimental Artificial Intelligence, 7 (1), 81–120.
Wallace, S. A. (2005a). Abstract behavior representations for self-assessment. In AAAI
Spring Symposium on Meta-Cognition in Computation (ASSMC 2005). AAAI Technical Report SS-05-04., pp. 120–125.
Wallace, S. A. (2005b). S-Assess: A library for self-assessment. In Proceedings of the Fourth
International Conference on Autonomous Agents and Multiagent Systems (AAMAS05), pp. 256–263.
Wallace, S. A. (2007). Enabling trust with behavior metamodels. In AAAI Spring Symposium on Interaction Challenges for Intelligent Agents (ASSICIA 2007). AAAI Technical Report SS-07-04., pp. 124–131.
207

Wallace

Wallace, S. A., & Laird, J. E. (2000). Toward a methodology for AI architecture evaluation:
Comparing Soar and CLIPS. In Jennings, N., & Lespérance, Y. (Eds.), Intelligent
Agents VI — Proceedings of the Sixth International Workshop on Agent Theories,
Architectures, and Languages (ATAL-99), Lecture Notes in Artificial Intelligence, pp.
117–131. Springer-Verlag, Berlin.
Wallace, S. A., & Laird, J. E. (2003). Behavior Bounding: Toward effective comparisons of
agents & humans. In Proceedings of the Eighteenth International Joint Conference on
Artificial Intelligence, pp. 727–732.
Wang, X. (1995). Learning by observation and practice: An incremental approach for planning operator acquisition. In Proceedings of the Twelfth International Conference on
Machine Learning, pp. 549–557.
Watkins, C. J. C. H., & Dayan, P. (1992). Q-learning. Machine Learning, 8, 279–292.
Weitzel, J. R., & Kerschberg, L. (1989). Developing knowledge-based systems: Reorganizing
the system development life cycle. Communications of the ACM, 32 (4), 482–488.
Yen, J., & Lee, J. (1993). A task-based methodology for specifying expert systems. IEEE
Expert, 8 (1), 8–15.
Yost, G. R. (1996). Implementing the Sisyphus-93 task using Soar/TAQL. International
Journal of Human-Computer Studies, 44, 281–301.

208

Journal of Artificial Intelligence Research 34 (2009) 443-498

Submitted 08/08; published 03/09

Wikipedia-based Semantic Interpretation
for Natural Language Processing
Evgeniy Gabrilovich
Shaul Markovitch

gabr@yahoo-inc.com
shaulm@cs.technion.ac.il

Department of Computer Science
Technion—Israel Institute of Technology
Technion City, 32000 Haifa, Israel

Abstract
Adequate representation of natural language semantics requires access to vast amounts
of common sense and domain-specific world knowledge. Prior work in the field was based
on purely statistical techniques that did not make use of background knowledge, on limited
lexicographic knowledge bases such as WordNet, or on huge manual efforts such as the
CYC project. Here we propose a novel method, called Explicit Semantic Analysis (ESA),
for fine-grained semantic interpretation of unrestricted natural language texts. Our method
represents meaning in a high-dimensional space of concepts derived from Wikipedia, the
largest encyclopedia in existence. We explicitly represent the meaning of any text in terms
of Wikipedia-based concepts. We evaluate the effectiveness of our method on text categorization and on computing the degree of semantic relatedness between fragments of natural
language text. Using ESA results in significant improvements over the previous state of
the art in both tasks. Importantly, due to the use of natural concepts, the ESA model is
easy to explain to human users.

1. Introduction
Recent proliferation of the World Wide Web, and common availability of inexpensive storage
media to accumulate over time enormous amounts of digital data, have contributed to the
importance of intelligent access to this data. It is the sheer amount of data available that
emphasizes the intelligent aspect of access—no one is willing to or capable of browsing
through but a very small subset of the data collection, carefully selected to satisfy one’s
precise information need.
Research in artificial intelligence has long aimed at endowing machines with the ability
to understand natural language. One of the core issues of this challenge is how to represent language semantics in a way that can be manipulated by computers. Prior work on
semantics representation was based on purely statistical techniques, lexicographic knowledge, or elaborate endeavors to manually encode large amounts of knowledge. The simplest
approach to represent the text semantics is to treat the text as an unordered bag of words,
where the words themselves (possibly stemmed) become features of the textual object. The
sheer ease of this approach makes it a reasonable candidate for many information retrieval
tasks such as search and text categorization (Baeza-Yates & Ribeiro-Neto, 1999; Sebastiani,
2002). However, this simple model can only be reasonably used when texts are fairly long,
and performs sub-optimally on short texts. Furthermore, it does little to address the two
main problems of natural language processing (NLP), polysemy and synonymy.
c
°2009
AI Access Foundation. All rights reserved.

Gabrilovich & Markovitch

Latent Semantic Analysis (LSA) (Deerwester, Dumais, Furnas, Landauer, & Harshman,
1990) is another purely statistical technique, which leverages word co-occurrence information from a large unlabeled corpus of text. LSA does not use any explicit human-organized
knowledge; rather, it “learns” its representation by applying Singular Value Decomposition
(SVD) to the words-by-documents co-occurrence matrix. LSA is essentially a dimensionality reduction technique that identifies a number of most prominent dimensions in the data,
which are assumed to correspond to “latent concepts”. Meanings of words and documents
are then represented in the space defined by these concepts.
Lexical databases such as WordNet (Fellbaum, 1998) or Roget’s Thesaurus (Roget, 1852)
encode important relations between words such as synonymy, hypernymy, and meronymy.
Approaches based on such resources (Budanitsky & Hirst, 2006; Jarmasz, 2003) map text
words into word senses, and use the latter as concepts. However, lexical resources offer
little information about the different word senses, thus making word sense disambiguation
nearly impossible to achieve. Another drawback of such approaches is that creation of
lexical resources requires lexicographic expertise as well as a lot of time and effort, and consequently such resources cover only a small fragment of the language lexicon. Specifically,
such resources contain few proper names, neologisms, slang, and domain-specific technical
terms. Furthermore, these resources have strong lexical orientation in that they predominantly contain information about individual words, but little world knowledge in general.
Being inherently limited to individual words, these approaches require an extra level of
sophistication to handle longer texts (Mihalcea, Corley, & Strapparava, 2006); for example,
computing the similarity of a pair of texts amounts to comparing each word of one text to
each word of the other text.
Studies in artificial intelligence have long recognized the importance of knowledge for
problem solving in general, and for natural language processing in particular. Back in the
early years of AI research, Buchanan and Feigenbaum (1982) formulated the knowledge as
power hypothesis, which postulated that “The power of an intelligent program to perform
its task well depends primarily on the quantity and quality of knowledge it has about that
task.”
When computer programs face tasks that require human-level intelligence, such as natural language processing, it is only natural to use an encyclopedia to endow the machine
with the breadth of knowledge available to humans. There are, however, several obstacles
on the way to using encyclopedic knowledge. First, such knowledge is available in textual
form, and using it may require natural language understanding, a major problem in its own
right. Furthermore, even language understanding may not be enough, as texts written for
humans normally assume the reader possesses a large amount of common-sense knowledge,
which is omitted even from most detailed encyclopedia articles (Lenat, 1997). Thus, there
is a circular dependency—understanding encyclopedia articles requires natural language
understanding capabilities, while the latter in turn require encyclopedic knowledge. To
address this situation, Lenat and his colleagues launched the CYC project, which aims to
explicitly catalog the common sense knowledge of the humankind.
We developed a new methodology that makes it possible to use an encyclopedia directly,
without the need for manually encoded common-sense knowledge. Observe that an encyclopedia consists of a large collection of articles, each of which provides a comprehensive
exposition focused on a single topic. Thus, we view an encyclopedia as a collection of con444

Wikipedia-based Semantic Interpretation

cepts (corresponding to articles), each accompanied with a large body of text (the article
contents). We propose to use the high-dimensional space defined by these concepts in order
to represent the meaning of natural language texts. Compared to the bag of words and LSA
approaches, using these concepts allows the computer to benefit from huge amounts of world
knowledge, which is normally accessible to humans. Compared to electronic dictionaries and
thesauri, our method uses knowledge resources that are over an order of magnitude larger,
and also uniformly treats texts that are arbitrarily longer than a single word. Even more
importantly, our method uses the body of text that accompanies the concepts in order to
perform word sense disambiguation. As we show later, using the knowledge-rich concepts
addresses both polysemy and synonymy, as we no longer manipulate mere words. We call
our method Explicit Semantic Analysis (ESA), as it uses knowledge concepts explicitly
defined and manipulated by humans.
Our approach is applicable to many NLP tasks whose input is a document (or shorter
natural language utterance), and the output is a decision based on the document contents.
Examples of such tasks are information retrieval (whether the document is relevant), text
categorization (whether the document belongs to a certain category), or comparing pairs of
documents to assess their similarity.1
Observe that documents manipulated in these tasks are given in the same form as the
encyclopedic knowledge we intend to use—plain text. It is this key observation that allows us
to circumvent the obstacles we enumerated above, and use the encyclopedia directly, without
the need for deep language understanding or pre-cataloged common-sense knowledge. We
quantify the degree of relevance of each Wikipedia concept to the input text by comparing
this text to the article associated with the concept.
Let us illustrate the importance of external knowledge with a couple of examples. Without using external knowledge (specifically, knowledge about financial markets), one can infer
little information from a very brief news title “Bernanke takes charge”. However, using the
algorithm we developed for consulting Wikipedia, we find that the following concepts are
highly relevant to the input: Ben Bernanke, Federal Reserve, Chairman of the
Federal Reserve, Alan Greenspan (Bernanke’s predecessor), Monetarism (an economic theory of money supply and central banking), inflation and deflation. As another
example, consider the title “Apple patents a Tablet Mac”. Without deep knowledge of hitech industry and gadgets, one finds it hard to predict the contents of the news item. Using
Wikipedia, we identify the following related concepts: Apple Computer2 , Mac OS (the
Macintosh operating system) Laptop (the general name for portable computers, of which
Tablet Mac is a specific example), Aqua (the GUI of Mac OS X), iPod (another prominent product by Apple), and Apple Newton (the name of Apple’s early personal digital
assistant).
For ease of presentation, in the above examples we only showed a few concepts identified
by ESA as the most relevant for the input. However, the essence of our method is representing the meaning of text as a weighted combination of all Wikipedia concepts. Then,
1. Thus, we do not consider tasks such as machine translation or natural language generation, whose output
includes a new piece of text based on the input.
2. Note that we correctly identify the concept representing the computer company (Apple Computer)
rather than the fruit (Apple).

445

Gabrilovich & Markovitch

depending on the nature of the task at hand we either use these entire vectors of concepts,
or use a few most relevant concepts to enrich the bag of words representation.
The contributions of this paper are twofold. First, we propose a new methodology
to use Wikipedia for enriching representation of natural language texts. Our approach,
named Explicit Semantic Analysis, effectively capitalizes on human knowledge encoded in
Wikipedia, leveraging information that cannot be deduced solely from the input texts being
processed. Second, we evaluate ESA on two commonly occurring NLP tasks, namely, text
categorization and computing semantic relatedness of texts. In both tasks, using ESA
resulted in significant improvements over the existing state of the art performance.
Recently, ESA was used by other researchers in a variety of tasks, and consistently proved
to be superior to approaches that do not explicitly used large-scale repositories of human
knowledge. Gurevych, Mueller, and Zesch (2007) re-implemented our ESA approach for the
German-language Wikipedia, and found it to be superior for judging semantic relatedness of
words compared to a system based on the German version of WordNet (GermaNet). Chang,
Ratinov, Roth, and Srikumar (2008) used ESA for a text classification task without explicit
training set, learning only from the knowledge encoded in Wikipedia. Milne and Witten
(2008) found ESA to compare favorably to approaches that are solely based on hyperlinks,
thus confirming that the wealth of textual descriptions in Wikipedia is exlicitly superior to
using structural information alone.

2. Explicit Semantic Analysis
What is the meaning of the word “cat”? One way to interpret the word “cat” is via an
explicit definition: a cat is a mammal with four legs, which belongs to the feline species,
etc. Another way to interpret the meaning of “cat” is by the strength of its association with
concepts that we know: “cat” relates strongly to the concepts “feline” and “pet”, somewhat
less strongly to the concepts “mouse” and “Tom & Jerry”, etc.
We use this latter association-based method to assign semantic interpretation to words
and text fragments. We assume the availability of a vector of basic concepts, C1 , . . . , Cn , and
we represent each text fragment t by a vector of weights, w1 , . . . , wn , where wi represents the
strength of association between t and Ci . Thus, the set of basic concepts can be viewed as a
canonical n-dimensional semantic space, and the semantics of each text segment corresponds
to a point in this space. We call this weighted vector the semantic interpretation vector of
t.
Such a canonical representation is very powerful, as it effectively allows us to estimate
semantic relatedness of text fragments by their distance in this space. In the following
section we describe the two main components of such a scheme: the set of basic concepts,
and the algorithm that maps text fragments into interpretation vectors.
2.1 Using Wikipedia as a Repository of Basic Concepts
To build a general semantic interpreter that can represent text meaning for a variety of
tasks, the set of basic concepts needs to satisfy the following requirements:
1. It should be comprehensive enough to include concepts in a large variety of topics.
446

Wikipedia-based Semantic Interpretation

2. It should be constantly maintained so that new concepts can be promptly added as
needed.
3. Since the ultimate goal is to interpret natural language, we would like the concepts
to be natural, that is, concepts recognized and used by human beings.
4. Each concept Ci should have associated text di , so that we can determine the strength
of its affinity with each term in the language.
Creating and maintaining such a set of natural concepts requires enormous effort of many
people. Luckily, such a collection already exists in the form of Wikipedia, which is one of the
largest knowledge repositories on the Web. Wikipedia is available in dozens of languages,
while its English version is the largest of all, and contains 300+ million words in nearly
one million articles, contributed by over 160,000 volunteer editors. Even though Wikipedia
editors are not required to be established researchers or practitioners, the open editing approach yields remarkable quality. A recent study (Giles, 2005) found Wikipedia accuracy to
rival that of Encyclopaedia Britannica. However, Britannica is about an order of magnitude
smaller, with 44 million words in 65,000 articles (http://store.britannica.com, visited
on February 10, 2006).
As appropriate for an encyclopedia, each article comprises a comprehensive exposition
of a single topic. Consequently, we view each Wikipedia article as defining a concept that
corresponds to each topic. For example, the article about artificial intelligence defines the
concept Artificial Intelligence, while the article about parasitic extraction in circuit
design defines the concept Layout extraction.3 The body of the articles is critical in our
approach, as it allows us to compute the affinity between the concepts and the words of the
input texts.
An important advantage of our approach is thus the use of vast amounts of highly organized human knowledge. Compared to lexical resources such as WordNet, our methodology
leverages knowledge bases that are orders of magnitude larger and more comprehensive.
Importantly, the Web-based knowledge repositories we use in this work undergo constant
development so their breadth and depth steadily increase over time. Compared to Latent
Semantic Analysis, our methodology explicitly uses the knowledge collected and organized
by humans. Our semantic analysis is explicit in the sense that we manipulate manifest concepts grounded in human cognition, rather than “latent concepts” used by LSA. Therefore,
we call our approach Explicit Semantic Analysis (ESA).
2.2 Building a Semantic Interpreter
Given a set of concepts, C1 , . . . , Cn , and a set of associated documents, d1 , . . . , dn , we build
a sparse table T where each of the n columns corresponds to a concept, and each of the rows
S
corresponds to a word that occurs in i=1...n di . An entry T [i, j] in the table corresponds
to the TFIDF value of term ti in document dj
T [i, j] = tf (ti , dj ) · log

n
,
dfi

3. Here we use the titles of articles as a convenient way to refer to the articles, but our algorithm treats
the articles as atomic concepts.

447

Gabrilovich & Markovitch

where term frequency is defined as
(

tf (ti , dj ) =

1 + log count(ti , dj ), if count(ti , dj ) > 0
,
0,
otherwise

and dfi = |{dk : ti ∈ dk }| is the number of documents in the collection that contain the
term ti (document frequency).
Finally, cosine normalization is applied to each row to disregard differences in document
length:
T [i, j]
T [i, j] ← pPr
,
2
l=1 T [i, j]
where r is the number of terms.
The semantic interpretation of a word ti is obtained as row i of table T . That is, the
meaning of a word is given by a vector of concepts paired with their TFIDF scores, which
reflect the relevance of each concept to the word.
The semantic interpretation of a text fragment, ht1 , . . . , tk i, is the centroid of the vectors
representing the individual words. This definition allows us to partially perform word sense
disambiguation. Consider, for example, the interpretation vector for the term “mouse”. It
has two sets of strong components, which correspond to two possible meanings: “mouse (rodent)” and “mouse (computing)”. Similarly, the interpretation vector of the word “screen”
has strong components associated with “window screen” and “computer screen”. In a text
fragment such as “I purchased a mouse and a screen”, summing the two interpretation vectors will boost the computer-related components, effectively disambiguating both words.
Table T can also be viewed as an inverted index, which maps each word into a list
of concepts in which it appears. Inverted index provides for very efficient computation of
distance between interpretation vectors.
Given the amount of information encoded in Wikipedia, it is essential to control the
amount of noise present in its text. We do so by discarding insufficiently developed articles,
and by eliminating spurious association between articles and words. This is done by setting
to zero the weights of those concepts whose weights for a given term are too low (see
Section 3.2.3).
2.3 Using the Link Structure
It is only natural for an electronic encyclopedia to provide cross-references in the form of
hyperlinks. As a result, a typical Wikipedia article has many more links to other entries
than articles in conventional printed encyclopedias.
This link structure can be used in a number of ways. Observe that each link is associated
with an anchor text (clickable highlighted phrase). The anchor text is not always identical
to the canonical name of the target article, and different anchor texts are used to refer
to the same article in different contexts. For example, anchor texts pointing at Federal
Reserve include “Fed”, “U.S. Federal Reserve Board”, “U.S. Federal Reserve System”,
“Board of Governors of the Federal Reserve”, “Federal Reserve Bank”, “foreign reserves”
and “Free Banking Era”. Thus, anchor texts provide alternative names, variant spellings,
and related phrases for the target concept, which we use to enrich the article text for the
target concept.
448

Wikipedia-based Semantic Interpretation

Furthermore, inter-article links often reflect important relations between concepts that
correspond to the linked articles. We explore the use of such relations for feature generation
in the next section.
2.3.1 Second-order Interpretation
Knowledge concepts can be subject to many relations, including generalization, meronymy
(“part of”), holonymy and synonymy, as well as more specific relations such as “capital of”,
“birthplace/birthdate of” etc. Wikipedia is a notable example of a knowledge repository
that features such relations, which are represented by the hypertext links between Wikipedia
articles.
These links encode a large amount of knowledge, which is not found in article texts.
Consequently, leveraging this knowledge is likely to lead to better interpretation models. We
therefore distinguish between first-order models, which only use the knowledge encoded in
Wikipedia articles, and second-order models, which also incorporate the knowledge encoded
in inter-article links. Similarly, we refer to the information obtained through inter-article
links as second-order information.
As a rule, the presence of a link implies some relation between the concepts it connects.
For example, the article on the United States links to Washington, D.C. (country
capital) and North America (the continent where the country is situated). It also links
to a multitude of other concepts, which are definitely related to the source concept, albeit it
is more difficult to define those relations; these links include United States Declaration
of Independence, President of the United States, and Elvis Presley.
However, our observations reveal that the existence of a link does not always imply the
two articles are strongly related.4 In fact, many words and phrases in a typical Wikipedia
article link to other articles just because there are entries for the corresponding concepts.
For example, the Education subsection in the article on the United States has gratuitous
links to concepts High school, College, and Literacy rate. Therefore, in order to
use Wikipedia links for semantic interpretation, it is essential to filter the linked concepts
according to their relevance to the text fragment being interpreted.
An intuitive way to incorporate concept relations is to examine a number of top-scoring
concepts,
and Eto boost the scores of the concepts linked from them. Let ESA(1) (t) =
D
(1)
(1)
w1 , . . . , wn be the interpretation vector of term t. We define the second-level interpretation of term t as
D

(2)

ESA(2) (t) = w1 , . . . , wn(2)
where
(2)

wi

(1)

= wi

X

+α·

E

(1)

wj

{j|∃link(cj ,ci )}

Using α < 1 ensures that the linked concepts are taken with reduced weights. In our
experiments we used α = 0.5.
4. The opposite is also true—the absence of a link may simply be due to an oversight. Adafre and de Rijke
(2005) studied the problem of discovering missing links in Wikipedia.

449

Gabrilovich & Markovitch

2.3.2 Concept Generality Filter
Not all the new concepts identified through links are equally useful. Relevance of the newly
added concepts is certainly important, but is not the only criterion. Suppose that we
are given an input text “Google search”. Which additional concept is likely to be more
useful to characterize the input: Nigritude ultramarine (a specially crafted meaningless
phrase used in a search engine optimization contest) or Website? Now suppose the input is
“artificial intelligence” — which concept is likely to contribute more to the representation
of this input, John McCarthy (computer scientist) or Logic? We believe that in both
examples, the second concept would be more useful because it is not overly specific.
Consequently, we conjecture that we should add linked concepts sparingly, taking only
those that are “more general” than the concepts that triggered them. But how can we judge
the generality of concepts? While this may be tricky to achieve in the general case (no pun
intended), we propose the following task-oriented criterion. Given two concepts ca and cb ,
we compare the numbers of links pointing at them. Then, we say that ca is “more general”
than cb if its number of incoming links is at least an order of magnitude larger, that is, if
log10 (#inlinks(ca )) − log10 (#inlinks(cb )) > 1.
We show examples of additional concepts identified using inter-article links in Section 4.5.1. In Section 4.5.4 we evaluate the effect of using inter-article links as an additional
knowledge source. In this section we also specifically examine the effect of only using more
general linked concepts (i.e., adding concepts that are more general than the concepts that
triggered them).

3. Using Explicit Semantic Analysis for Computing Semantic
Relatedness of Texts
In this section we discuss the application of our semantic interpretation methodology to
automatic assessment of semantic relatedness of words and texts.5
3.1 Automatic Computation of Semantic Relatedness
How related are “cat” and “mouse”? And what about “preparing a manuscript” and “writing an article”? The ability to quantify semantic relatedness of texts underlies many fundamental tasks in computational linguistics, including word sense disambiguation, information
retrieval, word and text clustering, and error correction (Budanitsky & Hirst, 2006). Reasoning about semantic relatedness of natural language utterances is routinely performed by
humans but remains an unsurmountable obstacle for computers. Humans do not judge text
relatedness merely at the level of text words. Words trigger reasoning at a much deeper
level that manipulates concepts—the basic units of meaning that serve humans to organize
and share their knowledge. Thus, humans interpret the specific wording of a document
in the much larger context of their background knowledge and experience. Lacking such
elaborate resources, computers need alternative ways to represent texts and reason about
them.
Explicit Semantic Analysis represents text as interpretation vectors in the high-dimensional space of concepts. With this representation, computing semantic relatedness of texts
5. Preliminary results of this research have been reported by Gabrilovich and Markovitch (2007a).

450

Wikipedia-based Semantic Interpretation

Building Semantic Interpreter

word1
wordi

Building weighted
inverted index
Wikipedia

wordn

Weighted list
of concepts
(= Wikipedia
articles)

Weighted
inverted index

Using Semantic Interpreter

Text1

Semantic
interpreter

Vector
comparison

Relatedness
estimation

Text2
Weighted
vector of
Wikipedia
concepts

Figure 1: Knowledge-based semantic interpreter

simply amounts to comparing their vectors. Vectors could be compared using a variety
of metrics (Zobel & Moffat, 1998); we use the cosine metric throughout the experiments
reported in this paper. Figure 1 illustrates this process.
3.2 Implementation Details
We used Wikipedia snapshot as of November 11, 2005. After parsing the Wikipedia XML
dump, we obtained 1.8 Gb of text in 910,989 articles. Although Wikipedia has almost a
million articles, not all of them are equally useful for feature generation. Some articles correspond to overly specific concepts (e.g., Metnal, the ninth level of the Mayan underworld),
or are otherwise unlikely to be useful for subsequent text categorization (e.g., specific dates
or a list of events that happened in a particular year). Other articles are just too short,
so we cannot reliably classify texts onto the corresponding concepts. We developed a set
of simple heuristics for pruning the set of concepts, by discarding articles that have fewer
than 100 non stop words or fewer than 5 incoming and outgoing links. We also discard articles that describe specific dates, as well as Wikipedia disambiguation pages, category pages
and the like. After the pruning, 171,332 articles were left that defined concepts used for
feature generation. We processed the text of these articles by first tokenizing it, removing
stop words and rare words (occurring in fewer than 3 articles), and stemmed the remaining
words; this yielded 296,157 distinct terms.
451

Gabrilovich & Markovitch

3.2.1 Preprocessing of Wikipedia XML Dump
Wikipedia data is publicly available online at http://download.wikimedia.org. All the
data is distributed in XML format, and several packaged versions are available: article texts,
edit history, list of page titles, interlanguage links etc. In this project, we only use the article
texts, but ignore the information on article authors and page modification history. Before
building the semantic interpreter, we perform a number of operations on the distributed
XML dump:
• We simplify the original XML by removing all those fields that are not used in feature
generation, such as author ids and last modification times.
• Wikipedia syntax defines a proprietary format for inter-article links, whereas the name
of the article referred to is enclosed in brackets (e.g., “[United States]”). We map
all articles to numeric ids, and for each article build a list of ids of the articles it refers
to. We also count the number of incoming and outgoing links for each article.
• Wikipedia defines a redirection mechanism, which maps frequently used variant names
of entities into canonical names. For examples, United States of America is
mapped to United States. We resolve all such redirections during initial preprocessing.
• Another frequently used mechanism is templates, which allows articles to include
frequently reused fragments of text without duplication, by including pre-defined and
optionally parameterized templates on the fly. To speed up subsequent processing, we
resolve all template inclusions at the beginning.
• We also collect all anchor texts that point at each article.
This preprocessing stage yields a new XML file, which is then used for building the feature
generator.
3.2.2 The Effect of Knowledge Breadth
Wikipedia is being constantly expanded with new material as volunteer editors contribute
new articles and extend the existing ones. Consequently, we conjectured that such addition
of information should be beneficial for ESA, as it would rely on a larger knowledge base.
To test this assumption, we also acquired a newer Wikipedia snapshot as of March 26,
2006. Table 1 presents a comparison in the amount of information between two Wikipedia
snapshots we used. The number of articles shown in the table reflects the total number
of articles as of the date of the snapshot. The next table line (the number of concepts
used) reflects the number of concepts that remained after the pruning as explained in the
beginning of Section 3.2.
In the following sections we will confirm that using a larger knowledge base is beneficial
for ESA, by juxtaposing the results obtained with the two Wikipedia snapshots. Therefore,
no further dimensionality reduction is performed, and each input text fragment is represented in the space of up to 171,332 features (or 241,393 features in the case of the later
Wikipedia snapshot); of course, many of the features will have zero values, so the feature
vectors are sparse.
452

Wikipedia-based Semantic Interpretation

Combined article text
Number of articles
Concepts used
Distinct terms

Wikipedia snapshot
as of November 11, 2005
1.8 Gb
910,989
171,332
296,157

Wikipedia snapshot
as of March 23, 2006
2.9 Gb
1,187,839
241,393
389,202

Table 1: Comparison of two Wikipedia snapshots
3.2.3 Inverted Index Pruning
We eliminate spurious association between articles and words by setting to zero the weights
of those concepts whose weights for a given term are too low.
The algorithm for pruning the inverted index operates as follows. We first sort all the
concepts for a given word according to their TFIDF weights in decreasing order. We then
scan the resulting sequence of concepts with a sliding window of length 100, and truncate
the sequence when the difference in scores between the first and last concepts in the window
drops below 5% of the highest-scoring concept for this word (which is positioned first in the
sequence). This technique looks for fast drops in the concept scores, which would signify
that the concepts in the tail of the sequence are only loosely associated with the word (i.e.,
even though the word occurred in the articles corresponding to these concepts, it its not
truly characteristic of the article contents). We evaluated more principled approaches such
observing the values of the first and second derivatives, but the data seemed to be too
noisy for reliable estimation of derivatives. Other researchers studied the use of derivatives
in similar contexts (e.g., Begelman, Keller, & Smadja, 2006), and also found that the
derivative alone is not sufficient, hence they found it necessary to estimate the magnitude
of peaks by other means. Consequently, we opted to use the simple and efficient metric.
The purpose of such pruning is to eliminate spurious associations between concepts and
terms, and is mainly beneficial for pruning the inverted index entries for very common
words that occur in many Wikipedia articles. Using the above criteria, we analyzed the
inverted index for the Wikipedia version dated November 11, 2005 (see Section 3.2.2). For
the majority of terms, there were either fewer than 100 concepts with non-zero weight, or
the concept-term weights decreased gracefully and did not qualify for pruning. We pruned
the entries of 4866 terms out of the total of 296,157 terms. Among the terms whose concept
vector was pruned, the term “link” had the largest number of concepts with non-zero
weight—106,988—of which we retained only 838 concepts (0.8%); as another example, the
concept vector for the term “number” was pruned from 52,244 entries down to 1360 (2.5%).
On the average, 24% of concepts have been retained. The pruning rates for the second
Wikipedia version (dated March 23, 2006) have been similar to these.
3.2.4 Processing Time
Using world knowledge requires additional computation. This extra computation includes
the (one-time) preprocessing step where the semantic interpreter is built, as well as the
actual mapping of input texts into interpretation vectors, performed online. On a standard workstation, parsing the Wikipedia XML dump takes about 7 hours, and building the
453

Gabrilovich & Markovitch

semantic interpreter takes less than an hour. After the semantic interpreter is built, its
throughput (i.e., the generation of interpretation vectors for textual input) is several hundred words per second. In the light of the improvements computing semantic relatedness
and in text categorization accuracy that we report in Sections 3 and 4, we believe that the
extra processing time is well compensated for.
3.3 Empirical Evaluation of Explicit Semantic Analysis
Humans have an innate ability to judge semantic relatedness of texts. Human judgements
on a reference set of text pairs can thus be considered correct by definition, a kind of “gold
standard” against which computer algorithms are evaluated. Several studies measured
inter-judge correlations and found them to be consistently high (Budanitsky & Hirst, 2006;
Jarmasz, 2003; Finkelstein, Gabrilovich, Matias, Rivlin, Solan, Wolfman, & Ruppin, 2002a),
r = 0.88 − 0.95. These findings are to be expected—after all, it is this consensus that allows
people to understand each other. Consequently, our evaluation amounts to computing the
correlation of ESA relatedness scores with human judgments.
To better evaluate Wikipedia-based semantic interpretation, we also implemented a semantic interpreter based on another large-scale knowledge repository—the Open Directory
Project (ODP, http://www.dmoz.org), which is the largest Web directory to date. In the case
of ODP, concepts Ci correspond to categories of the directory (e.g., Top/Computers/Artificial Intelligence), and text di associated with each concept is obtained by pooling
together the titles and descriptions of the URLs catalogued under the corresponding category. Interpretation of a text fragment amounts to computing a weighted vector of ODP
concepts, ordered by their affinity to the input text. We built the ODP-based semantic
interpreter using an ODP snapshot as of April 2004. Further implementation details can
be found in our previous work (Gabrilovich & Markovitch, 2005, 2007b).
3.3.1 Test Collections
In this work, we use two datasets that to the best of our knowledge are the largest publicly
available collections of their kind.6 For both test collections, we use the correlation of
computer-assigned scores with human scores to assess the algorithm performance.
To assess word relatedness, we use the WordSimilarity-353 collection (Finkelstein et al.,
2002a; Finkelstein, Gabrilovich, Matias, Rivlin, Solan, Wolfman, & Ruppin, 2002b), which
contains 353 noun pairs representing various degrees of similarity.7 Each pair has 13–
16 human judgements made by individuals with university degrees having either mothertongue-level or otherwise very fluent command of the English language. Word pairs were
assigned relatedness scores on the scale from 0 (totally unrelated words) to 10 (very much
related or identical words). Judgements collected for each word pair were then averaged to
6. Recently, Zesch and Gurevych (2006) discussed automatic creation of datasets for assessing semantic
similarity. However, the focus of their work was on automatical generation of a set of sufficiently
diverse word pairs, thus relieving the humans of the need to construct word lists manually. Obviously,
establishing the “gold standard” semantic relatedness for each word pair is still performed manually by
human judges.
7. Some previous studies (Jarmasz & Szpakowicz, 2003) suggested that the word pairs comprising this
collection might be culturally biased.

454

Wikipedia-based Semantic Interpretation

produce a single relatedness score.8 Spearman’s rank-order correlation coefficient was used
to compare computed relatedness scores with human judgements; being non-parametric,
Spearman’s correlation coefficient is considered to be much more robust than Pearson’s
linear correlation. When comparing our results to those of other studies, we have computed
the Spearman’s correlation coefficient with human judgments based on their raw data.
For document similarity, we used a collection of 50 documents from the Australian
Broadcasting Corporation’s news mail service (Lee, Pincombe, & Welsh, 2005; Pincombe,
2004). The documents were between 51 and 126 words long, and covered a variety of topics.
The judges were 83 students from the University of Adelaide, Australia, who were paid a
small fee for their work. These documents were paired in all possible ways, and each of the
1,225 pairs has 8–12 human judgements (averaged for each pair). To neutralize the effects
of ordering, document pairs were presented in random order, and the order of documents
within each pair was randomized as well. When human judgements have been averaged for
each pair, the collection of 1,225 relatedness scores have only 67 distinct values. Spearman’s
correlation is not appropriate in this case, and therefore we used Pearson’s linear correlation
coefficient.
Importantly, instructions for human judges in both test collections specifically directed
the participants to assess the degree of relatedness of words and texts involved. For example,
in the case of antonyms, judges were instructed to consider them as “similar” rather than
“dissimilar”.
3.3.2 Prior Work
A number of prior studies proposed a variety of approaches to computing word similarity
using WordNet, Roget’s thesaurus, and LSA. Table 2 presents the results of applying these
approaches to the WordSimilarity-353 test collection.
Jarmasz (2003) replicated the results of several WordNet-based methods, and compared
them to a new approach based on Roget’s Thesaurus. Hirst and St-Onge (1998) viewed
WordNet as a graph, and considered the length and directionality of the graph path connecting two nodes. Leacock and Chodorow (1998) also used the length of the shortest graph
path, and normalized it by the maximum taxonomy depth. Jiang and Conrath (1997), and
later Resnik (1999), used the notion of information content of the lowest node subsuming two given words. Lin (1998b) proposed a computation of word similarity based on
the information theory. See (Budanitsky & Hirst, 2006) for a comprehensive discussion of
WordNet-based approaches to computing word similarity.
According to Jarmasz (2003), Roget’s Thesaurus has a number of advantages compared
to WordNet, including links between different parts of speech, topical groupings, and a variety of relations between word senses. Consequently, the method developed by the authors
using Roget’s as a source of knowledge achieved much better results than WordNet-based
methods. Finkelstein et al. (2002a) reported the results of computing word similarity using
8. Finkelstein et al. (2002a) report inter-judge agreement of 0.95 for the WordSimilarity-353 collection. We
have also performed our own assessment of the inter-judge agreement for this dataset. Following Snow,
O’Connor, Jurafsky, and Ng (2008), we divided the human judges into two sets and averaged the numeric
judgements for each word pair among the judges in the set, thus yielding a (353 element long) vector of
average judgments for each set. Spearman’s correlation coefficient between the vectors of the two sets
was 0.903.

455

Gabrilovich & Markovitch

an LSA-based model (Deerwester et al., 1990) trained on the Grolier Academic American Encyclopedia. Recently, Hughes and Ramage (2007) proposed a method for computing semantic relatedness using random graph walks; their results on the WordSimilarity353 dataset are competitive with those reported by Jarmasz (2003) and Finkelstein et al.
(2002a).
Strube and Ponzetto (2006) proposed an alternative approach to computing word similarity based on Wikipedia, by comparing articles in whose titles the words occur. We discuss
this approach in greater detail in Section 5.1.
Prior work on assessing the similarity of textual documents was based on comparing
the documents as bags of words, as well as on LSA. Lee et al. (2005) compared a number
of approaches based on the bag of words representation, which used both binary and tfidf
representation of word weights and a variety of similarity measures (correlation, Jaccard,
cosine, and overlap). The authors also implemented an LSA-based model trained on a set
of news documents from the Australian Broadcasting Corporation (test documents whose
similarity was computed came from the same distribution). The results of these experiments
are reported in Table 3.
3.3.3 Results
To better understand how Explicit Semantic Analysis works, let us consider similarity computation for pairs of actual phrases. For example, given two phrases “scientific article” and
“journal publication”, ESA determines that the following Wikipedia concepts are found
among the top 20 concepts for each phrase: Scientific journal, Nature (journal),
Academic publication, Science (journal), and Peer review. When we compute
similarity of “RNA” and “DNA”, the following concepts are found to be shared among
the top 20 lists: Transcription (genetics), Gene, RNA, and Cell (biology). It is
the presence of identical concepts among the top concepts characterizing each phrase that
allows ESA to establish their semantic similarity.
Table 2 shows the results of applying our methodology to estimating relatedness of
individual words, with statistically significant improvements shown in bold. The values
shown in the table represent Spearman’s correlation between the human judgments and
the relatedness scores produced by the different methods. Jarmasz (2003) compared the
performance of 5 WordNet-based metrics, namely, those proposed by Hirst and St-Onge
(1998), Jiang and Conrath (1997), Leacock and Chodorow (1998), Lin (1998b), and Resnik
(1999). In Table 2 we report the performance of the best of these metrics, namely, those
by Lin (1998b) and Resnik (1999). In the WikiRelate! paper (Strube & Ponzetto, 2006),
the authors report results of as many as 6 different method variations, and again we report
the performance of the best one (based on the metric proposed by Leacock and Chodorow,
1998).
As we can see, both ESA techniques yield substantial improvements over previous state
of the art results. Notably, ESA also achieves much better results than another recently
introduce method based on Wikipedia (Strube & Ponzetto, 2006). We provide a detailed
comparison of our approach with this latter work in Section 5.1. Table 3 shows the results
for computing relatedness of entire documents. In both tables, we show the statistical
significance of the difference between the performance of ESA-Wikipedia (March 26, 2006
456

Wikipedia-based Semantic Interpretation

Algorithm

WordNet-based techniques (Jarmasz, 2003)
Roget’s Thesaurus-based technique (Jarmasz, 2003)
LSA (Finkelstein et al., 2002a)
WikiRelate! (Strube & Ponzetto, 2006)
MarkovLink (Hughes & Ramage, 2007)
ESA-Wikipedia (March 26, 2006 version)
ESA-Wikipedia (November 11, 2005 version)
ESA-ODP

Spearman’s
correlation with
human judgements
0.35
0.55
0.56
0.50
0.55
0.75
0.74
0.65

Stat.
significance
(p-value)
4 · 10−16
1.3 · 10−6
3.4 · 10−6
8 · 10−9
1.6 · 10−6
–
–
0.0044

Table 2: Spearman’s rank correlation of word relatedness scores with human judgements
on the WordSimilarity-353 collection
Algorithm

Bag of words (Lee et al., 2005)
LSA (Lee et al., 2005)
ESA-Wikipedia (March 26, 2006 version)
ESA-Wikipedia (November 11, 2005 version)
ESA-ODP

Pearson’s
correlation with
human judgements
0.1–0.5
0.60
0.72
0.71
0.69

Stat.
significance
(p-value)
4 · 10−19
5 · 10−8
–
–
0.07

Table 3: Pearson’s correlation of text relatedness scores with human judgements on Lee et
al.’s document collection

version) and that of other algorithms9 by using Fisher’s z-transformation (Press, Teukolsky,
Vetterling, & Flannery, 1997, Section 14.5).
On both test collections, Wikipedia-based semantic interpretation is superior to the
ODP-based one; in the word relatedness task, this superiority is statistically significant at
p < 0.005. We believe that two factors contribute to this phenomenon. First, axes of a
multi-dimensional interpretation space should ideally be as independent as possible. The
hierarchical organization of the Open Directory reflects the generalization relation between
concepts and obviously violates this independence requirement. Second, to increase the
amount of training data for building the ODP-based semantic interpreter, we crawled all the
URLs listed in the ODP. This allowed us to increase the amount of textual data by several
orders of magnitude, but also brought about a non-negligible amount of noise, which is
common in Web pages. On the other hand, Wikipedia articles are virtually noise-free, and
9. Whenever a range of values is available, we compared ESA-Wikipedia with the best-performing method
in the range.

457

Gabrilovich & Markovitch

mostly qualify as Standard Written English. Thus, the textual descriptions of Wikipedia
concepts are arguably more focused than those of the ODP concepts.
It is also essential to note that in both experiments, using a newer Wikipedia snapshot
leads to better results (although the difference between the performance of two versions is
admittedly small).
We evaluated the effect of using second-order interpretation for computing semantic
relatedness of texts, but it only yielded negligible improvements. We hypothesize that the
reason for this finding is that computing semantic relatedness essentially uses all available
Wikipedia concepts, so second-order interpretation can only slightly modify the weights
of existing concepts. In the next section, which describes the application of ESA to text
categorization, we trim the interpretation vectors for the sake of efficiency, and only consider
a few highest-scoring concepts for each input text fragment. In this scenario, secondorder interpretation does have a positive effect and actually improves the accuracy of text
categorization (Section 4.5.4). This happens because only a few selected Wikipedia concepts
are used to augment text representation, and the second-order approach selectively adds
highly related concepts identified by analyzing Wikipedia links.

4. Using Explicit Semantic Analysis for Text Categorization
In this section we evaluate the benefits of using external knowledge for text categorization.10
4.1 Background on Text Categorization
Text categorization (TC) deals with assigning category labels to natural language documents. Categories come from a fixed set of labels (possibly organized in a hierarchy) and
each document may be assigned one or more categories. Text categorization systems are
useful in a wide variety of tasks, such as routing news and e-mail to appropriate corporate
desks, identifying junk email, or correctly handling intelligence reports.
The majority of existing text classification systems represent text as a bag of words, and
use a variant of the vector space model with various weighting schemes (Salton & McGill,
1983). Thus, the features commonly used in text classification are weighted occurrence
frequencies of individual words. State-of-the-art systems for text categorization use a variety
of induction techniques, such as support vector machines, k-nearest neighbor algorithm,
and neural networks. The bag of words (BOW) method is very effective in easy to medium
difficulty categorization tasks where the category of a document can be identified by several
easily distinguishable keywords. However, its performance becomes quite limited for more
demanding tasks, such as those dealing with small categories or short documents.
There have been various attempts to extend the basic BOW approach. Several studies
augmented the bag of words with n-grams (Caropreso, Matwin, & Sebastiani, 2001; Peng
& Shuurmans, 2003; Mladenic, 1998; Raskutti, Ferra, & Kowalczyk, 2001) or statistical
language models (Peng, Schuurmans, & Wang, 2004). Others used linguistically motivated
features based on syntactic information, such as that available from part-of-speech tagging
or shallow parsing (Sable, McKeown, & Church, 2002; Basili, Moschitti, & Pazienza, 2000).
Additional studies researched the use of word clustering (Baker & McCallum, 1998; Bekker10. Preliminary results of this research have been reported by Gabrilovich and Markovitch (2006).

458

Wikipedia-based Semantic Interpretation

man, 2003; Dhillon, Mallela, & Kumar, 2003), neural networks (Jo, 2000; Jo & Japkowicz,
2005; Jo, 2006), as well as dimensionality reduction techniques such as LSA (Deerwester
et al., 1990; Hull, 1994; Zelikovitz & Hirsh, 2001; Cai & Hofmann, 2003). However, these
attempts had mostly limited success.
We believe that the bag of words approach is inherently limited, as it can only use those
pieces of information that are explicitly mentioned in the documents, and only if the same
vocabulary is consistently used throughout. The BOW approach cannot generalize over
words, and consequently words in the testing document that never appeared in the training
set are necessarily ignored. Nor can synonymous words that appear infrequently in training
documents be used to infer a more general principle that covers all the cases. Furthermore,
considering the words as an unordered bag makes it difficult to correctly resolve the sense
of polysemous words, as they are no longer processed in their native context. Most of these
shortcomings stem from the fact that the bag of words method has no access to the wealth
of world knowledge possessed by humans, and is therefore easily puzzled by facts and terms
that cannot be easily deduced from the training set.
4.2 Using ESA for Feature Generation
We propose a solution that augments the bag of words with knowledge-based features.
Given a document to be classified, we would like to use ESA to represent the document
text in the space of Wikipedia concepts. However, text categorization is crucially different
from computing semantic relatedness (cf. Section 3) in two important respects.
First, computing semantic relatedness is essentially a “one-off” task, that is, given
a particular pair of text fragments, we need to quantify their relatedness with no prior
examples for this specific task. In such cases, the very words of the text fragments are likely
to be of marginal usefulness, especially when the two fragments are one word long. This
happens because all the data available to us is limited to the two input fragments, which in
most cases share few words, if at all.
On the other hand, in supervised text categorization, one is usually given a collection
of labeled text documents, from which one can induce a text categorizer. Consequently,
words that occur in the training examples can serve as valuable features—this is how the
bag of words approach was born. As we have observed in an earlier work (Gabrilovich
& Markovitch, 2005, 2007b), it is ill-advised to completely replace the bag of words with
generated concepts, and instead it is advantageous to enrich the bag of words. Rather, we
opt to augment the bag of words with carefully selected knowledge concepts, which become
new features of the document. We refer to this process as feature generation, because we
actually construct new document features beyond those in the bag of words.
Second, enriching document representation for text categorization with all possible
Wikipedia concepts is extremely expensive computationally, because a machine learning
classifier will be learned in the augmented feature space. Such a representation obviously
takes a lot of storage space, and cannot be processed efficiently because of the multitude of
the concepts involved (whose number can easily reach hundreds of thousands). Therefore,
in the text categorization task, we prune the interpretation vectors to only retain a number
of highest-scoring concepts for each input text fragment.

459

Gabrilovich & Markovitch

Using the multi-resolution approach to feature generation We believe that considering the document as a single unit can often be misleading: its text might be too diverse
to be readily mapped to the right set of concepts, while notions mentioned only briefly may
be overlooked. Instead, we partition the document into a series of non-overlapping segments
(called contexts), and then generate features at this finer level. Each context is mapped
into a number of Wikipedia concepts in the knowledge base, and pooling these concepts
together to describe the entire document results in multi-faceted classification. This way,
the resulting set of concepts represents the various aspects or sub-topics covered by the
document.
Potential candidates for such contexts are simple sequences of words, or more linguistically motivated chunks such as sentences or paragraphs. The optimal resolution for document segmentation can be determined automatically using a validation set. In our earlier work (Gabrilovich & Markovitch, 2005, 2007b), we proposed a more principled multiresolution approach that simultaneously partitions the document at several levels of linguistic abstraction (windows of words, sentences, paragraphs, up to taking the entire document
as one big chunk), and performs feature generation at each of these levels. We rely on the
subsequent feature selection step to eliminate extraneous features, preserving only those
that genuinely characterize the document.
It is essential to emphasize that using the multi-resolution approach only makes sense
when interpretation vectors are pruned to only retain a number of highest-scoring concepts for each context. As explained above, this is exactly the case for text categorization.
Without such pruning, producing interpretation vectors for each context and then summing
them up would be equivalent to simply multiplying the weight of each concept by a constant
factor. In order to explain why the situation is different in the presence of pruning, let us
consider an example. Suppose we have a long document that only mentions a particular
topic T in its last paragraph. Since this topic is not central to the document, the N topscoring concepts in the document’s interpretation vector I are unlikely to cover this topic.
Although T is likely to be covered by other concepts in I, those concepts have lower weight
in I and are going to be pruned. However, if we produce interpretation vectors also for
each paragraph of the document, and retain N highest-scoring concepts of each, then the
concepts generated for the last paragraph will cover T . Consequently, T will have representation in the joined set of concepts generated for the document. In many text categorization
tasks, documents are labeled with a particular topic even if they mention the topic briefly,
hence generating features describing such topics is very important.
Feature generation Feature generation is performed prior to text categorization. Each
document is transformed into a series of local contexts, which are then represented as
interpretation vectors using ESA. The top ten concepts of all the vectors are pooled together,
and give rise to the generated features of the document, which are added to the bag of words.
Since concepts in our approach correspond to Wikipedia articles, constructed features also
correspond to the articles. Thus, a set of features generated for a document can be viewed
as representing a set of Wikipedia articles that are most relevant to the document contents.
The constructed features are used in conjunction with the original bag of words. The
resulting set optionally undergoes feature selection, and the most discriminative features
are retained for document representation.
460

Wikipedia-based Semantic Interpretation

Basic
features

Feature
selection

Selected
features

Labeled
documents

Feature
valuation

Induction
algorithm

Classifier

Classifier

Classified
documents

Labeled
feature
vectors

Training

Testing
Testing
documents

Feature
valuation

Figure 2: Standard approach to text categorization.

Feature generation
Feature
construction

Feature
selection

Generated
features

Wikipedia
Labeled
documents

Feature
valuation

Induction
algorithm

Classifier

Labeled
feature
vectors

Figure 3: Induction of text classifiers using the proposed framework for feature generation.

Figure 2 depicts the standard approach to text categorization. Figure 3 outlines the
proposed feature generation framework; observe that the “Feature generation” box replaces
the “Feature selection” box framed in bold in Figure 2.
It is essential to note that we do not use the encyclopedia to simply increase the amount
of the training data for text categorization; neither do we use it as a text corpus to collect
word co-occurrence statistics. Rather, we use the knowledge distilled from the encyclopedia
to enrich the representation of documents, so that a text categorizer is induced in the
augmented, knowledge-rich feature space.
461

Gabrilovich & Markovitch

4.3 Test Collections
This section gives a brief description of the test collections we used to evaluate our methodology. We provide a much more detailed description of these test collections in Appendix B.
1. Reuters-21578 (Reuters, 1997) is historically the most often used dataset in text categorization research. Following common practice, we used the ModApte split (9603 training,
3299 testing documents) and two category sets, 10 largest categories and 90 categories with
at least one training and testing example.
2. 20 Newsgroups (20NG) (Lang, 1995) is a well-balanced dataset of 20 categories
containing 1000 documents each.
3. Movie Reviews (Movies) (Pang, Lee, & Vaithyanathan, 2002) defines a sentiment
classification task, where reviews express either positive or negative opinion about the
movies. The dataset has 1400 documents in two categories (positive/negative)
4. Reuters Corpus Volume I (RCV1) (Lewis, Yang, Rose, & Li, 2004) has over
800,000 documents. To speed up the experiments, we used a subset of RCV1 with 17,808 training documents (dated 20–27/08/96) and 5,341 testing ones (28–31/08/96). Following
Brank, Grobelnik, Milic-Frayling, and Mladenic (2002), we used 16 Topic and 16 Industry
categories that constitute representative samples of the full groups of 103 and 354 categories,
respectively. We also randomly sampled the Topic and Industry categories into 5 sets of
10 categories each.11
5. OHSUMED (Hersh, Buckley, Leone, & Hickam, 1994) is a subset of MEDLINE, which
contains 348,566 medical documents. Each document contains a title, and about two-thirds
(233,445) also contain an abstract. Each document is labeled with an average of 13 MeSH12
categories (out of total 14,000). Following Joachims (1998), we used a subset of documents
from 1991 that have abstracts, taking the first 10,000 documents for training and the next
10,000 for testing. To limit the number of categories for the experiments, we randomly
generated 5 sets of 10 categories each.13
Using these 5 datasets allows us to comprehensively evaluate the performance of our
approach. Specifically, comparing 20 Newsgroups and the two Reuters datasets (Reuters21578 and Reuters Corpus Volume 1), we observe that the former is substantially more
noisy since the data has been obtained from Usenet newsgroups, while the Reuters datasets
are significantly cleaner. The Movie Reviews collection presents an example of sentiment
classification, which is different from standard (topical) text categorization. Finally, the
OHSUMED dataset presents an example of a very comprehensive taxonomy of over 14,000
categories. As we explain the next section, we also used this dataset to create a collection
of labeled short texts, which allowed us to quantify the performance of our method on such
texts.
Short Documents We also derived several datasets of short documents from the test
collections described above. Recall that about one-third of OHSUMED documents have
titles but no abstract, and can therefore be considered short documents “as-is.” We used
the same range of documents as defined above, but considered only those without abstracts;
this yielded 4,714 training and 5,404 testing documents. For all other datasets, we created
11. The full definition of the category sets we used is available in Table 8 (see Section B.4).
12. http://www.nlm.nih.gov/mesh
13. The full definition of the category sets we used is available in Table 9 (see Section B.5).

462

Wikipedia-based Semantic Interpretation

a short document from each original document by taking only the title of the latter (with
the exception of Movie Reviews, where documents have no titles).
It should be noted, however, that substituting a title for the full document is a poor
man’s way to obtain a collection of classified short documents. When documents were first
labeled with categories, the human labeller saw each document in its entirety. In particular,
a category might have been assigned to a document on the basis of facts mentioned in its
body, even though the information may well be missing from the (short) title. Thus, taking
all the categories of the original documents to be “genuine” categories of the title is often
misleading. However, because we know of no publicly available test collections of short
documents, we decided to construct datasets as explained above. Importantly, OHSUMED
documents without abstracts have been classified as such by humans; working with the
OHSUMED-derived dataset can thus be considered a “pure” experiment.
4.4 Experimentation Procedure
We used support vector machines14 as our learning algorithm to build text categorizers, since
prior studies found SVMs to have the best performance for text categorization (Sebastiani,
2002; Dumais, Platt, Heckerman, & Sahami, 1998; Yang & Liu, 1999). Following established
practice, we use the precision-recall break-even point (BEP) to measure text categorization
performance. BEP is defined in terms of the standard measures of precision and recall,
where precision is the proportion of true document-category assignments among all assignments predicted by the classifier, and recall is the proportion of true document-category
assignments that were also predicted by the classifier. It is obtained by either tuning the
classifier so that precision is equal to recall, or sampling several (precision, recall) points
that bracket the expected BEP value and then interpolating (or extrapolating, in the event
that all the sampled points lie on the same side).
For the two Reuters datasets and OHSUMED we report both micro- and macro-averaged
BEP, since their categories differ in size significantly. Micro-averaged BEP operates at the
document level and is primarily affected by categorization performance on larger categories.
On the other hand, macro-averaged BEP averages results for individual categories, and thus
small categories with few training examples have large impact on the overall performance.
For both Reuters datasets (Reuters-21578 and RCV1) and OHSUMED we used a fixed
train/test split as defined in Section 4.3, and consequently used macro sign test (S-test)
(Yang & Liu, 1999) to assess the statistical significance of differences in classifier performance. For 20NG and Movies we performed 4-fold cross-validation, and used paired t-test to
assess the significance. We also used the non-parametric Wilcoxon signed-ranks test (Demsar, 2006) to compare the baseline and the FG-based classifiers over multiple data sets. In
the latter case, the individual measurements taken are the (micro- or macro-averaged) BEP
values observed on each dataset.
14. We used the SVM light implementation (Joachims, 1999) with the default parameters. In our earlier
work on feature selection (Gabrilovich & Markovitch, 2004), we conducted a thorough experimentation
with a wide range of values of the C parameter, and found it not to be of any major importance for
these datasets; consequently, we leave this parameter at its default setting as well.

463

Gabrilovich & Markovitch

4.4.1 Text Categorization Infrastructure
We conducted the experiments using a text categorization platform of our own design and
development named Hogwarts 15 (Davidov, Gabrilovich, & Markovitch, 2004). We opted
to build a comprehensive new infrastructure for text categorization, as surprisingly few software tools are publicly available for researchers, while those that are available allow only
limited control over their operation. Hogwarts facilitates full-cycle text categorization
including text preprocessing, feature extraction, construction, selection and weighting, followed by actual classification with cross-validation of experiments. The system currently
provides XML parsing, part-of-speech tagging (Brill, 1995), sentence boundary detection,
stemming (Porter, 1980), WordNet (Fellbaum, 1998) lookup, a variety of feature selection
algorithms, and TFIDF feature weighting schemes. Hogwarts has over 250 configurable
parameters that control its modus operandi in minute detail. Hogwarts interfaces with
SVM, KNN and C4.5 text categorization algorithms, and computes all standard measures
of categorization performance. Hogwarts was designed with a particular emphasis on
processing efficiency, and portably implemented in the ANSI C++ programming language
and C++ Standard Template Library. The system has built-in loaders for Reuters-21578
(Reuters, 1997), RCV1 (Lewis et al., 2004), 20 Newsgroups (Lang, 1995), Movie Reviews
(Pang et al., 2002), and OHSUMED (Hersh et al., 1994), while additional datasets can be
easily integrated in a modular way.
Each document undergoes the following processing steps. Document text is first tokenized, and title words are replicated twice to emphasize their importance. Then, stop
words, numbers and mixed alphanumeric strings are removed, and the remaining words
are stemmed. The bag of words is next merged with the set of features generated for the
document by analyzing its contexts as explained in Section 4.2, and rare features occurring
in fewer than 3 documents are removed.
Since earlier studies found that most BOW features are indeed useful for SVM text
categorization16 (Joachims, 1998; Rogati & Yang, 2002; Brank et al., 2002; Bekkerman,
2003; Leopold & Kindermann, 2002; Lewis et al., 2004), we take the bag of words in its
entirety (with the exception of rare features removed in the previous step). The generated
features, however, undergo feature selection using the information gain criterion.17 Finally,
feature weighting is performed using the “ltc” TF.IDF function (logarithmic term frequency
and inverse document frequency, followed by cosine normalization) (Salton & Buckley, 1988;
Debole & Sebastiani, 2003).
4.4.2 Baseline Performance of Hogwarts
We now demonstrate that the performance of basic text categorization in our implementation (column “Baseline” in Table 4) is consistent with the state of the art as reflected in
other published studies (all using SVM). On Reuters-21578, Dumais et al. (1998) achieved
15. Hogwarts School of Witchcraft and Wizardry is the educational institution attended by Harry Potter
(Rowling, 1997).
16. Gabrilovich and Markovitch (2004) described a class of problems where feature selection from the bag
of words actually improves SVM performance.
17. Of course, feature selection is performed using only the training set of documents.

464

Wikipedia-based Semantic Interpretation

micro-BEP of 0.920 for 10 categories and 0.870 for all categories. On 20NG18 , Bekkerman
(2003) obtained BEP of 0.856. Pang et al. (2002) obtained accuracy of 0.829 on Movies19 .
The minor variations in performance are due to differences in data preprocessing in the
different systems; for example, for the Movies dataset we worked with raw HTML files
rather than with the official tokenized version, in order to recover sentence and paragraph
structure for contextual analysis. For RCV1 and OHSUMED, direct comparison with published results is more difficult because we limited the category sets and the date span of
documents to speed up experimentation.
4.4.3 Using the Feature Generator
The core engine of Explicit Semantic Analysis was implemented as explained in Section 3.2.
We used the multi-resolution approach to feature generation, classifying document contexts at the level of individual words, complete sentences, paragraphs, and finally the entire
document.20 For each context, features were generated from the 10 best-matching concepts
produced by the feature generator.
4.5 Wikipedia-based Feature Generation
In this section, we report the results of an experimental evaluation of our methodology.
4.5.1 Qualitative Analysis of Feature Generation
We now study the process of feature generation on a number of actual examples.
Feature Generation per se To illustrate our approach, we show features generated for
several text fragments. Whenever applicable, we provide short explanations of the generated
concepts; in most cases, the explanations are taken from Wikipedia (Wikipedia, 2006).
• Text: “Wal-Mart supply chain goes real time”
Top 10 generated features: (1) Wal-Mart; (2) Sam Walton; (3) Sears Holdings
Corporation; (4) Target Corporation; (5) Albertsons; (6) ASDA; (7) RFID; (8)
Hypermarket; (9) United Food and Commercial Workers; (10) Chain store
Selected explanations: (2) Wal-Mart founder; (5) prominent competitors of WalMart; (6) a Wal-Mart subsidiary in the UK; (7) Radio Frequency Identification, a
technology that Wal-Mart uses very extensively to manage its stock; (8) superstore
(a general concept, of which Wal-Mart is a specific example); (9) a labor union that
18. For comparison with the results reported by Bekkerman (2003) we administered a single test run (i.e.,
without cross-validation), taking the first 3/4 of postings in each newsgroup for training, and the rest
for testing.
19. For comparison with the results reported by Pang et al. (2002) we administered a single test run (i.e.,
without cross-validation), taking the first 2/3 of the data for each opinion type for training, and the rest
for testing.
20. The 20NG dataset is an exception, owing to its high level of intrinsic noise that renders identification
of sentence boundaries extremely unreliable, and causes word-level feature generation to produce too
many spurious classifications. Consequently, for this dataset we restrict the multi-resolution approach
to individual paragraphs and the entire document only.

465

Gabrilovich & Markovitch

has been trying to organize Wal-Mart’s workers; (10) a general concept, of which
Wal-Mart is a specific example
• It is particularly interesting to juxtapose the features generated for fragments that
contain ambiguous words. To this end, we show features generated for two phrases
that contain the word “bank” in two different senses, “Bank of America” (financial
institution) and “Bank of Amazon” (river bank). As can be readily seen, our feature generation methodology is capable of performing word sense disambiguation by
considering ambiguous words in the context of their neighbors.
– Text: “Bank of America”
Top 10 generated features: (1) Bank; (2) Bank of America; (3) Bank of
America Plaza (Atlanta); (4) Bank of America Plaza (Dallas); (5) MBNA
(a bank holding company acquired by Bank of America); (6) VISA (credit
card); (7) Bank of America Tower, New York City; (8) NASDAQ; (9) MasterCard; (10) Bank of America corporate Center
– Text: “Bank of Amazon”
Top 10 generated features: (1) Amazon River; (2) Amazon Basin; (3) Amazon Rainforest; (4) Amazon.com; (5) Rainforest; (6) Atlantic Ocean; (7)
Brazil; (8) Loreto Region (a region in Peru, located in the Amazon Rainforest);
(9) River; (10) Economy of Brazil
• Our method, however, is not 100% accurate, and in some cases it generates features
that are only somewhat relevant or even irrelevant to the input text. As an example, we show the outcome of feature generation for the title of our earlier article
(Gabrilovich & Markovitch, 2006). For each concept, we show a list of input words
that triggered it (the words are stemmed and sorted in the decreasing order of their
contribution).
Text: “Overcoming the Brittleness Bottleneck using Wikipedia: Enhancing Text Categorization with Encyclopedic Knowledge”
Top 10 generated features:
1. Encyclopedia (encyclopedia, knowledge, Wikipedia, text)
2. Wikipedia (Wikipedia, enhance, encyclopedia, text)
3. Enterprise content management (category, knowledge, text, overcome, enhance)
4. Performance problem (bottleneck, category, enhance)
5. Immanuel Kant (category, knowledge, overcome)
6. Tooth enamel (brittleness, text, enhance)
7. Lucid dreaming (enhance, text, knowledge, category)
8. Bottleneck (bottleneck)
9. Java programming language (category, bottleneck, enhance)
466

Wikipedia-based Semantic Interpretation

10. Transmission Control Protocol (category, enhance, overcome)
Some of the generated features are clearly relevant to the input, such as Encyclopedia,
Wikipedia, and Enterprise content management. Others, however, are spurious,
such as Tooth enamel or Transmission Control Protocol. Since the process of
feature generation relies on the bag of words for matching concepts to the input text, it
suffers from the BOW shortcomings we mentioned above (Section 4.1). Consequently,
some features are generated because the corresponding Wikipedia articles just happen
to share words with the input text, even though these words are not characteristic
of the article as a whole. As explained above, our method can successfully operate
in the presence of such extraneous features due to the use of feature selection. This
way, generated features that are not informative for predicting document categories
are filtered out, and only informative features are actually retained for learning the
classification model.
Using Inter-article Links for Generating Additional Features In Section 1, we
presented an algorithm that generates additional features using inter-article links as relations between concepts. In what follows, we show a series of text fragments, where for
each fragment we show (a) features generated with the regular FG algorithm, (b) features
generated using Wikipedia links, and (c) more general features generated using links. As
we can see from the examples, the features constructed using the links are often relevant to
the input text.
• Text: “Google search”
Regular feature generation: (1) Search engine; (2) Google Video; (3) Google;
(4) Google (search); (5) Google Maps; (6) Google Desktop; (7) Google (verb);
(8) Google News; (9) Search engine optimization; (10) Spamdexing (search engine
spamming)
Features generated using links: (1) PageRank; (2) AdWords; (3) AdSense; (4)
Gmail; (5) Google Platform; (6) Website; (7) Sergey Brin; (8) Google bomb; (9)
MSN Search; (10) Nigritude ultramarine (a meaningless phrase used in a search
engine optimization contest in 2004)
More general features only: (1) Website; (2) Mozilla Firefox; (3) Portable
Document Format; (4) Algorithm; (5) World Wide Web
• Text: “programming tools”
Regular feature generation: (1) Tool; (2) Programming tool; (3) Computer
software; (4) Integrated development environment; (5) Computer-aided software engineering; (6) Macromedia Flash; (7) Borland; (8) Game programmer;
(9) C programming language; (10) Performance analysis
Features generated using links: (1) Compiler; (2) Debugger; (3) Source code;
(4) Software engineering; (5) Microsoft; (6) Revision control; (7) Scripting
language; (8) GNU; (9) Make; (10) Linux
More general features only: (1) Microsoft; (2) Software engineering; (3)
Linux; (4) Compiler; (5) GNU
467

Gabrilovich & Markovitch

4.5.2 The Effect of Feature Generation
Table 4 shows the results of using Wikipedia-based feature generation, with significant
improvements (p < 0.05) shown in bold. The different rows of the table correspond to
the performance on different datasets and their subsets, as defined in Section 4.3. We
consistently observed larger improvements in macro-averaged BEP, which is dominated by
categorization effectiveness on small categories. This goes in line with our expectations
that the contribution of encyclopedic knowledge should be especially prominent for categories with few training examples. Categorization performance was improved for virtually
all datasets, with notable improvements of up to 30.4% for RCV1 and 18% for OHSUMED.
Using the Wilcoxon test, we found that the Wikipedia-based classifier is significantly superior to the baseline with p < 10−5 in both micro- and macro-averaged cases. These results
clearly demonstrate the advantage of knowledge-based feature generation.
In our prior work (Gabrilovich & Markovitch, 2005, 2007b), we have also performed
feature generation for text categorization using an alternative source of knowledge, namely,
the Open Directory Project (ODP). The results of using Wikipedia are competitive with
those using ODP, with a slight advantage of Wikipedia. Observe also that Wikipedia is
constantly updated by numerous volunteers around the globe, while the ODP is virtually
frozen nowadays. Hence, in the future we can expect to obtain further improvements by
using newer versions of Wikipedia.
The Effect of Knowledge Breadth We also examined the effect of performing feature
generation using a newer Wikipedia snapshot, as explained in Section 3.2.2. Appendix A
reports the results of this experiment, which show a small but consistent improvement due
to using a larger knowledge base.
4.5.3 Classifying Short Documents
We conjectured that Wikipedia-based feature generation should be particularly useful for
classifying short documents.
Table 5 presents the results of this evaluation on the datasets defined in Section 4.3.
In the majority of cases, feature generation yielded greater improvement on short documents than on regular documents. Notably, the improvements are particularly high for
OHSUMED, where “pure” experimentation on short documents is possible (see Section 4.3).
According to the Wilcoxon test, the Wikipedia-based classifier is significantly superior to
the baseline with p < 2 · 10−6 . These findings confirm our hypothesis that encyclopedic knowledge should be particularly useful when categorizing short documents, which are
inadequately represented by the standard bag of words.
4.5.4 Using Inter-article links as Concept Relations
Using inter-article links for generating additional features, we observed further improvements in text categorization performance on short documents. As we can see in Table 6,
in the absolute majority of cases using links to generate more general features only is a
superior strategy. As we explain in Section 2.3, inter-article links can be viewed as relations
between concepts represented by the articles. Consequently, using these links allows us to
468

Wikipedia-based Semantic Interpretation

Dataset

Baseline
micro macro
BEP BEP
Reuters-21578 (10 cat.) 0.925 0.874
Reuters-21578 (90 cat.) 0.877 0.602
RCV1 Industry-16
0.642 0.595
RCV1 Industry-10A
0.421 0.335
RCV1 Industry-10B
0.489 0.528
RCV1 Industry-10C
0.443 0.414
RCV1 Industry-10D
0.587 0.466
RCV1 Industry-10E
0.648 0.605
RCV1 Topic-16
0.836 0.591
RCV1 Topic-10A
0.796 0.587
RCV1 Topic-10B
0.716 0.618
RCV1 Topic-10C
0.687 0.604
RCV1 Topic-10D
0.829 0.673
RCV1 Topic-10E
0.758 0.742
OHSUMED-10A
0.518 0.417
OHSUMED-10B
0.656 0.500
OHSUMED-10C
0.539 0.505
OHSUMED-10D
0.683 0.515
OHSUMED-10E
0.442 0.542
20NG
0.854
Movies
0.813

Wikipedia
micro macro
BEP BEP
0.932 0.887
0.883 0.603
0.645 0.617
0.448 0.437
0.523 0.566
0.468 0.431
0.595 0.459
0.641 0.612
0.843 0.661
0.798 0.682
0.723 0.656
0.699 0.618
0.839 0.688
0.765 0.755
0.538 0.492
0.667 0.534
0.545 0.522
0.692 0.546
0.462 0.575
0.862
0.842

Improvement
micro macro
BEP
BEP
+0.8% +1.5%
+0.7% +0.2%
+0.5% +3.7%
+6.4% +30.4%
+7.0% +7.2%
+5.6% +4.1%
+1.4% -1.5%
-1.1% +1.2%
+0.8% +11.8%
+0.3% +16.2%
+1.0% +6.1%
+1.7% +2.3%
+1.2% +2.2%
+0.9% +1.8%
+3.9% +18.0%
+1.7% +6.8%
+1.1% +3.4%
+1.3% +6.0%
+4.5% +6.1%
+1.0%
+3.6%

Table 4: The effect of feature generation for long documents

469

Gabrilovich & Markovitch

Dataset

Baseline
micro macro
BEP BEP
Reuters-21578 (10 cat.) 0.868 0.774
Reuters-21578 (90 cat.) 0.793 0.479
RCV1 Industry-16
0.454 0.400
RCV1 Industry-10A
0.249 0.199
RCV1 Industry-10B
0.273 0.292
RCV1 Industry-10C
0.209 0.199
RCV1 Industry-10D
0.408 0.361
RCV1 Industry-10E
0.450 0.410
RCV1 Topic-16
0.763 0.529
RCV1 Topic-10A
0.718 0.507
RCV1 Topic-10B
0.647 0.560
RCV1 Topic-10C
0.551 0.471
RCV1 Topic-10D
0.729 0.535
RCV1 Topic-10E
0.643 0.636
OHSUMED-10A
0.302 0.221
OHSUMED-10B
0.306 0.187
OHSUMED-10C
0.441 0.296
OHSUMED-10D
0.441 0.356
OHSUMED-10E
0.164 0.206
20NG
0.699

Wikipedia
micro macro
BEP BEP
0.877 0.793
0.803 0.506
0.481 0.437
0.293 0.256
0.337 0.363
0.294 0.327
0.452 0.379
0.474 0.434
0.769 0.542
0.725 0.544
0.643 0.564
0.573 0.507
0.735 0.563
0.670 0.653
0.405 0.299
0.383 0.256
0.528 0.413
0.460 0.402
0.219 0.280
0.749

Improvement
micro
macro
BEP
BEP
+1.0%
+2.5%
+1.3% +5.6%
+5.9% +9.2%
+17.7% +28.6%
+23.4% +24.3%
+40.7% +64.3%
+10.8% +5.0%
+5.3% +5.9%
+0.8%
+2.5%
+1.0% +7.3%
-0.6%
+0.7%
+4.0% +7.6%
+0.8% +5.2%
+4.2% +2.7%
+34.1% +35.3%
+25.2% +36.9%
+19.7% +39.5%
+4.3% +12.9%
+33.5% +35.9%
+7.1%

Table 5: Feature generation for short documents

470

Wikipedia-based Semantic Interpretation

Dataset

Baseline

micro
BEP
Reuters-21578 (10 cat.) 0.868
Reuters-21578 (90 cat.) 0.793
RCV1 Industry-16
0.454
RCV1 Topic-16
0.763
20NG
0.699
Dataset
Reuters-21578 (10 cat.)
Reuters-21578 (90 cat.)
RCV1 Industry-16
RCV1 Topic-16
20NG

–
–
–
–
–

macro
BEP
0.774
0.479
0.400
0.529

–
–
–
–

Wikipedia

Wikipedia
+ links

micro macro
BEP BEP
0.877 0.793
0.803 0.506
0.481 0.437
0.769 0.542
0.749
Improvement
over baseline
+1.0% +2.5%
+1.3% +5.6%
+5.9% +9.2%
+0.8% +2.5%
+7.1%

micro macro
BEP BEP
0.878 0.796
0.804 0.506
0.486 0.445
0.769 0.539
0.753
Improvement
over baseline
+1.2% +2.8%
+1.4% +5.6%
+7.1% +11.3%
+0.8% +1.9%
+7.7%

Wikipedia
+ links
(more general
features only)
micro macro
BEP
BEP
0.880 0.801
0.809 0.507
0.488 0.444
0.775 0.545
0.756
Improvement
over baseline
+1.4% +3.5%
+2.0% +5.8%
+7.5% +11.0%
+1.6% +3.0%
+8.1%

Table 6: Feature generation for short documents using inter-article links
identify additional concepts related to the context being analyzed, which leads to better
representation of the context with additional relevant generated features.

5. Related Work
This section puts our methodology in the context of related prior work.
In the past, there have been a number of attempts to represent the meaning of natural
language texts. Early research in computational linguistics focused on deep natural language
understanding, and strived to represent text semantics using logical formulae (Montague,
1973). However, this task proved to be very difficult and little progress has been made to
develop comprehensive grammars for non-trivial fragments of the language. Consequently,
the mainstream research effectively switched to more statistically-based methods (Manning
& Schuetze, 2000).
Although few of these studies tried to explicitly define semantic representation, their
modus operandi frequently induces a particular representation system. Distributional similarity methods (Lee, 1999) compute the similarity of a pair of words w1 and w2 by comparing
the distributions of other words given these two, e.g., by comparing vectors of probabilities P (v|w1 ) and P (v|w2 ) for a large vocabulary V of words (v ∈ V ). Therefore, these
techniques can be seen as representing the meaning of a word w as a vector of conditional
probabilities of other words given w. Dagan, Marcus, and Markovitch (1995) refined this
technique by considering co-occurrence probabilities of a word with its left and right contextual neighbors. For example, the word “water” would be represented by a vector of its
left neighbors such as “drink”, “pour”, and “clean”, and the vector of right neighbors such
as “molecule”, “level”, and “surface”. Lin (1998a) represented word meaning by considering syntactic roles of other words that co-occur with it in a sentence. For example, the
471

Gabrilovich & Markovitch

semantics of the word “water” would be represented by a vector of triples such as (water,
obj-of, drink) and (water, adj-mod, clean). Qiu and Frei (1993) proposed a method
for concept-based query expansion; however, they expanded queries with additional words
rather than with features corresponding to semantic concepts.
Latent Semantic Analysis is probably the most similar method in prior research, as it
does explicitly represents the meaning of a text fragment. LSA does so by manipulating
a vector of so-called latent concepts, which are obtained through SVD decomposition of a
word-by-document matrix of the training corpus. CYC (Lenat, 1995; Lenat, Guha, Pittman,
Pratt, & Shepherd, 1990) represents semantics of words through an elaborate network of
interconnected and richly-annotated concepts.
In contrast, our method represents the meaning of a piece of text as a weighted vector
of knowledge concepts. Importantly, entries of this vector correspond to unambiguous
human-defined concepts rather than plain words, which are often ambiguous. Compared to
LSA, our approach benefits from large amounts of manually encoded human knowledge, as
opposed to defining concepts using statistical analysis of a training corpus. Compared to
CYC, our approach streamlines the process of semantic interpretation that does not depend
on manual encoding of inference rules. With the exception of LSA, most prior approaches
to semantic interpretation explicitly represent semantics of individual words, and require an
extra level of sophistication to represent longer texts. Conversely, our approach represents
the meaning of texts in a uniform way regardless of their length.
5.1 Semantic Similarity and Semantic Relatedness
In this study we deal with “semantic relatedness” rather than “semantic similarity” or
“semantic distance”, which are also often used in the literature. In their extensive survey of
relatedness measures, Budanitsky and Hirst (2006) argued that the notion of relatedness is
more general than that of similarity, as the former subsumes many different kind of specific
relations, including meronymy, antonymy, functional association, and others. They further
maintained that computational linguistics applications often require measures of relatedness
rather than the more narrowly defined measures of similarity. For example, word sense
disambiguation can use any related words from the context, and not merely similar words.
Budanitsky and Hirst (2006) also argued that the notion of semantic distance might be
confusing due to the different ways it has been used in the literature.
Our approach to estimating semantic relatedness of words is somewhat reminiscent of
distributional (or co-occurrence) similarity (Lee, 1999; Dagan, Lee, & Pereira, 1999). Indeed, we compare the meanings of words by comparing the occurrence patterns across a
large collection of natural language documents. However, the compilation of these documents is not arbitrary, rather, the documents are aligned with encyclopedia articles, while
each of them is focused on a single topic. Furthermore, distributional similarity methods
are inherently suitable for comparing individual words, while our method can compute
similarity of arbitrarily long texts.
Prior work in the field mostly focused on semantic similarity of words, using R&G
(Rubenstein & Goodenough, 1965) list of 65 word pairs and M&C (Miller & Charles, 1991)
list of 30 word pairs. When only the similarity relation is considered, using lexical resources
was often successful enough, reaching the Pearson’s correlation of 0.70–0.85 with human
472

Wikipedia-based Semantic Interpretation

judgements (Budanitsky & Hirst, 2006; Jarmasz, 2003). In this case, lexical techniques
even have a slight edge over ESA-Wikipedia, whose correlation with human scores is 0.723
on M&C and 0.816 on R&G. 21 However, when the entire language wealth is considered
in an attempt to capture more general semantic relatedness, lexical techniques yield substantially inferior results (see Table 2). WordNet-based technique, which only consider the
generalization (“is-a”) relation between words, achieve correlation of only 0.33–0.35 with
human judgements (Budanitsky & Hirst, 2006; Jarmasz, 2003). Jarmasz & Szpakowicz’s
ELKB system (Jarmasz, 2003) based on Roget’s Thesaurus (Roget, 1852) achieves a higher
correlation of 0.55 due to its use of a richer set if relations.
Studying semantic similarity and relatedness of words is related to assessing similarity
of relations. An example of this task is to establish that word pairs carpenter:wood and
mason:stone are relationally similar, as the words in both pairs stand in the same relation
(profession:material). State of the art results on relational similarity are based on Latent
Relational Analysis (Turney, 2006, 2005).
Sahami and Heilman (2006) proposed to use the Web as a source of additional knowledge
for measuring similarity of short text snippets. To this end, they defined a kernel function
that sends two snippets as queries to a search engine, and compares the bags of words for
the two sets of returned documents. A major limitation of this technique is that it is only
applicable to short texts, because sending a long text as a query to a search engine is likely
to return few or even no results at all. On the other hand, our approach is applicable to
text fragments of arbitrary length. Additional studies that explored the Web to gather
information for computing word similarity include (Turney, 2001) and (Metzler, Dumais, &
Meek, 2007). The main difference between these works and our method is that the latter
uses a structured representation of human knowledge defined by Wikipedia concepts.
The above-mentioned based techniques are inherently limited to individual words, and
their adaptation for comparing longer texts requires an extra level of complexity (Mihalcea
et al., 2006). In contrast, our method treats both words and texts in essentially the same
way.
Strube and Ponzetto (2006) also used Wikipedia for computing semantic relatedness.
However, their method, called WikiRelate!, is radically different from ours. Given a pair of
words w1 and w2 , WikiRelate! searches for Wikipedia articles, p1 and p2 , that respectively
contain w1 and w2 in their titles. Semantic relatedness is then computed based on various
distance measures between p1 and p2 . These measures either rely on the texts of the
pages, or path distances within the category hierarchy of Wikipedia. Our approach, on the
other hand, represents each word as a weighted vector of Wikipedia concepts. Semantic
relatedness is then computed by comparing the two concept vectors.
Thus, the differences between the two approaches are:
1. WikiRelate! can only process words that actually occur in titles of Wikipedia articles.
ESA only requires that the word appears within the text of Wikipedia articles.
2. WikiRelate! is limited to single words while ESA can compare texts of any length.
21. WikiRelate! (Strube & Ponzetto, 2006) achieved relatively low scores of 0.31–0.54 on these domains.

473

Gabrilovich & Markovitch

3. WikiRelate! represents the semantics of a word by either the text of the article
associated with it, or by the node in the category hierarchy. ESA has a much more
structured semantic representation consisting of a vector of Wikipedia concepts.
Indeed, as we have shown in Section 3.3, the richer representation of ESA yields much better
results.
5.2 Feature Generation for Text Categorization
To date, quite a few attempts have been made to deviate from the orthodox bag of words
paradigm, usually with limited success. In particular, representations based on phrases
(Lewis, 1992; Dumais et al., 1998; Fuernkranz, Mitchell, & Riloff, 1998), named entities
(Kumaran & Allan, 2004), and term clustering (Lewis & Croft, 1990; Bekkerman, 2003)
have been explored. However, none of these techniques could possibly overcome the problem
underlying the various examples we reviewed in this paper—lack of world knowledge.
Feature generation techniques were found useful in a variety of machine learning tasks
(Markovitch & Rosenstein, 2002; Fawcett, 1993; Matheus, 1991). These techniques search
for new features that describe the target concept better than the ones supplied with the
training instances. A number of proposed feature generation algorithms (Pagallo & Haussler, 1990; Matheus & Rendell, 1989; Hu & Kibler, 1996; Murphy & Pazzani, 1991; Hirsh
& Japkowicz, 1994) led to significant improvements in performance over a range of classification tasks. However, even though feature generation is an established research area in
machine learning, only a few works have applied it to text processing (Kudenko & Hirsh,
1998; Mikheev, 1998; Cohen, 2000; Scott, 1998; Scott & Matwin, 1999). In contrast to our
approach, these techniques did not use any exogenous knowledge.
In our prior work (Gabrilovich & Markovitch, 2005, 2007b), we assumed the external
knowledge is available in the form of a generalization hierarchy, and used the Open Directory
Project as an example. This method, however, had a number of drawbacks, which can be
corrected by using Wikipedia.
First, requiring the knowledge repository to define an “is-a” hierarchy limits the choice of
appropriate repositories. Moreover, hierarchical organization embodies only one particular
relation between the nodes (generalization), while numerous other relations, such as relatedness, meronymy/holonymy and chronology, are ignored. Second, large-scale hierarchies
tend to be extremely unbalanced, so that the relative size of some branches is disproportionately large or small due to peculiar views of the editors. Such phenomena are indeed
common in the ODP. For example, the Top/Society branch is heavily dominated by one
of its children—Religion and Spirituality; the Top/Science branch is dominated by its
Biology child; a considerable fraction of the mass of Top/Recreation is concentrated in
Pets. Finally, to learn the scope of every ODP concept, short textual descriptions of the
concepts were augmented by crawling the Web sites cataloged in the ODP. This procedure
allowed us to accumulate many gigabytes worth of textual data, but at a price, as texts
obtained from the Web are often quite far from formal writing and plagued with noise.
Crawling a typical Web site often brings auxiliary material that has little to do with the
site theme, such as legal disclaimers, privacy statements, and help pages.
In this paper we proposed to use world knowledge encoded in Wikipedia, which is arguably the largest knowledge repository on the Web. Compared to the ODP, Wikipedia
474

Wikipedia-based Semantic Interpretation

possesses several advantageous properties. First, its articles are much cleaner than typical
Web pages, and mostly qualify as standard written English. Although Wikipedia offers
several orthogonal browsing interfaces, their structure is fairly shallow, and we propose to
treat Wikipedia as having essentially no hierarchy. This way, mapping tex fragments onto
relevant Wikipedia concepts yields truly multi-faceted classification of the text, and avoids
the problem of unbalanced hierarchy branches. Moreover, by not requiring the knowledge
repository to be hierarchically organized, our approach is suitable for new domains, for
which no ontology is available. Finally, Wikipedia articles are heavily cross-linked, in a way
reminiscent of linking on the Web. We conjectured that these links encode many interesting relations between the concepts, and constitute an important source of information in
addition to the article texts. We explored using inter-article links in Section 4.5.4.
5.2.1 Feature Generation Using Electronic Dictionaries
Several studies performed feature construction using the WordNet electronic dictionary
(Fellbaum, 1998) and other domain-specific dictionaries (Scott, 1998; Scott & Matwin,
1999; Urena-Lopez, Buenaga, & Gomez, 2001; Wang, McKay, Abbass, & Barlow, 2003;
Bloehdorn & Hotho, 2004).
Scott and Matwin (1999) attempted to augment the conventional bag-of-words representation with additional features, using the symbolic classification system Ripper (Cohen,
1995). This study evaluated features based on syntactically22 and statistically motivated
phrases, as well as on WordNet synsets 23 . In the latter case, the system performed generalizations using the hypernym hierarchy of WordNet, and completely replaced a bag of words
with a bag of synsets. While using hypernyms allowed Ripper to produce more general
and more comprehensible rules and achieved some performance gains on small classification tasks, no performance benefits could be obtained for larger tasks, which even suffered
from some degradation in classification accuracy. Consistent with other published findings
(Lewis, 1992; Dumais et al., 1998; Fuernkranz et al., 1998), the phrase-based representation
also did not yield any significant performance benefits over the bag-of-words approach.24
Urena-Lopez et al. (2001) used WordNet in conjunction with Rocchio (Rocchio, 1971)
and Widrow-Hoff (Lewis, Schapire, Callan, & Papka, 1996; Widrow & Stearns, 1985, Chapter 6) linear classifiers to fine-tune the category vectors. Wang et al. (2003) used Medical
Subject Headings (MeSH, 2003) to replace the bag of words with canonical medical terms;
Bloehdorn and Hotho (2004) used a similar approach to augment Reuters-21578 documents
with WordNet synsets and OHSUMED medical documents with MeSH terms.
It should be noted, however, that WordNet was not originally designed to be a powerful
knowledge base, but rather a lexical database more suitable for peculiar lexicographers’
needs. Specifically, WordNet has the following drawbacks when used as a knowledge base
for text categorization:
22. Identification of syntactic phrases was performed using a noun phrase extractor built on top of a part of
speech tagger (Brill, 1995).
23. A synset is WordNet notion for a sense shared by a group of synonymous words.
24. Sebastiani (2002) casts the use of bag of words versus phrases as utilizing lexical semantics rather than
compositional semantics. Interestingly, some bag-of-words approaches (notably, KNN) may be considered
context-sensitive as they do not assume independence between either features (terms) or categories (Yang
& Pedersen, 1997).

475

Gabrilovich & Markovitch

• WordNet has a fairly small coverage—for the test collections we used in this paper, up
to 50% of their unique words are missing from WordNet. In particular, many proper
names, slang and domain-specific technical terms are not included in WordNet, which
was designed as a general-purpose dictionary.
• Additional information about synsets (beyond their identity) is very limited. This is
because WordNet implements a differential rather than constructive lexical semantics
theory, so that glosses that accompany the synsets are mainly designed to distinguish
the synsets rather than provide a definition of the sense or concept. Usage examples
that occasionally constitute part of the gloss serve the same purpose. Without such
auxiliary information, reliable word sense disambiguation is almost impossible.
• WordNet was designed by professional linguists who are trained to recognize minute
differences in word senses. As a result, common words have far too many distinct
senses to be useful in information retrieval (Mihalcea, 2003); for example, the word
“make” has as many as 48 senses as a verb alone. Such fine-grained distinctions
between synsets present an additional difficulty for word sense disambiguation.
Both our approach and the techniques that use WordNet manipulate a collection of
concepts. However, there are a number of crucial differences. All previous studies only
performed feature generation for individual words only. Our approach can handle arbitrarily long or short text fragments alike. Considering words in context allows our approach
to perform word sense disambiguation. Approaches using WordNet cannot achieve disambiguation because information about synsets is limited to merely a few words, while in
Wikipedia concepts are associated with huge amounts of text. Even for individual words,
our approach provides much more sophisticated mapping of words to concepts, through the
analysis of the large bodies of texts associated with concepts. This allows us to represent the
meaning of words (or texts) as a weighted combination of concepts, while mapping a word
in WordNet amounts to simple lookup, without any weights. Furthermore, in WordNet
the senses of each word are mutually exclusive. In our approach, concepts reflect different
aspects of the input, thus yielding weighted multi-faceted representation of the text.
In Appendix D we illustrate the limitations of WordNet on a specific example, where
we juxtapose WordNet-based and Wikipedia-based representation.
5.2.2 Using Unlabeled Examples
To the best of our knowledge, with the exception of the above studies that used WordNet,
there have been no attempts to date to automatically use large-scale repositories of structured background knowledge for feature generation. An interesting approach to using nonstructured background knowledge was proposed by Zelikovitz and Hirsh (2000). This work
uses a collection of unlabeled examples as intermediaries in comparing testing examples
with the training ones. Specifically, when an unknown test instance does not appear to
resemble any labeled training instances, unlabeled examples that are similar to both may
be used as “bridges.” Using this approach, it is possible to handle the situation where the
training and the test document have few or no words in common. The unlabeled documents
are utilized to define a cosine similarity metric, which is then used by the KNN algorithm
for actual text categorization. This approach, however, suffers from efficiency problems, as
476

Wikipedia-based Semantic Interpretation

looking for intermediaries to compare every two documents makes it necessary to explore a
combinatorial search space.
In a subsequent paper, Zelikovitz and Hirsh (2001) proposed an alternative way to use
unlabeled documents as background knowledge. In this work, unlabeled texts are pooled
together with the training documents to compute a Latent Semantic Analysis (LSA) (Deerwester et al., 1990) model. LSA analyzes a large corpus of unlabeled text, and automatically
identifies so-called “latent concepts” using Singular Value Decomposition. The resulting
LSA metric then facilitates comparison of test documents to training documents. The addition of unlabeled documents significantly increases the amount of data on which word
co-occurrence statistics is estimated, thus providing a solution to text categorization problems where training data is particularly scarce. However, subsequent studies found that
LSA can rarely improve the strong baseline established by SVM, and often even results in
performance degradation (Wu & Gunopulos, 2002; Liu, Chen, Zhang, Ma, & Wu, 2004).
In contrast to LSA, which manipulates virtual concepts, our methodology relies on using
concepts identified and described by humans.

6. Conclusions
In this paper we proposed Explicit Semantic Analysis—a semantic interpretation methodology for natural language processing. In order to render computers with knowledge about
the world, we use Wikipedia to build a semantic interpreter, which represents the meaning
of texts in a very high-dimensional space of knowledge-based concepts. These concepts correspond to Wikipedia articles, and our methodology provides a fully automatic way to tap
into the collective knowledge of tens and hundreds of thousands of people. The conceptbased representation of text contains information that cannot be deduced from the input
text alone, and consequently supersedes the conventional bag of words representation.
We believe the most important aspects of the proposed approach are its ability to
address synonymy and polysemy, which are arguably the two most important problems
in NLP. Thus, the two texts can discuss the same topic using different words, and the
conventional bag of words approach will not be able to identify this commonality. On the
other hand, the mere fact that the two texts contain the same word does not necessarily
imply that they discuss the same topic, since that word could be used in the two texts in two
different meanings. We believe that our concept-based representation allows generalizations
and refinements to partially address synonymy and polysemy.
Consider, for example, the following text fragment (taken from Appendix C): “A group
of European-led astronomers has made a photograph of what appears to be a planet orbiting
another star. If so, it would be the first confirmed picture of a world beyond our solar
system.” The fifth concept generated for this fragment is Extrasolar planet, which is
exactly the topic of this text, even though these words are not mentioned in the input.
The other generated concepts (e.g., Astronomy and Planetary orbit) are also highly
characteristic of astronomy-related texts. Such additions enrich the text representation, and
increase the chances of finding common features between texts. It is also essential to note
that, of course, not all the generated concepts need to match features of other documents.
Even if some of the concepts match, we gain valuable insights about the document contents.
477

Gabrilovich & Markovitch

We succeeded to make automatic use of an encyclopedia without deep language understanding, specially crafted inference rules or relying on additional common-sense knowledge
bases. This was made possible by applying standard text classification techniques to match
document texts with relevant Wikipedia articles.
Empirical evaluation confirmed the value of Explicit Semantic Analysis for two common tasks in natural language processing. Compared with the previous state of the art,
using ESA results in significant improvements in automatically assessing semantic relatedness of words and texts. Specifically, the correlation of computed relatedness scores with
human judgements increased from r = 0.56 to 0.75 (Spearman) for individual words and
from r = 0.60 to 0.72 (Pearson) for texts. In contrast to existing methods, ESA offers a
uniform way for computing relatedness of both individual words and arbitrarily long text
fragments. Using ESA to perform feature generation for text categorization yielded consistent improvements across a diverse range of datasets. Recently, the performance of the
best text categorization systems became similar, and previous work mostly achieved small
improvements. Using Wikipedia as a source of external knowledge allowed us to improve
the performance of text categorization across a diverse collection of datasets.
It should be noted that although a recent study (Giles, 2005) found Wikipedia accuracy to rival that of Encyclopaedia Britannica, arguably not all the Wikipedia articles are
of equally high quality. On the one hand, Wikipedia has the notion of featured articles
(http://en.wikipedia.org/wiki/Featured Article), which “are considered to be the
best articles in Wikipedia, as determined by Wikipedia’s editors.” Currently, fewer than
0.1% of articles achieve this status. On the other hand, many articles are incomplete (socalled stubs), or might even contain information that is incorrect or that does not represent
a consensus among the editors. Yet in other cases, Wikipedia content might be prone to
spamming, despite the editorial process that attempts to review recent changes. We believe
our method is not overly susceptible to such cases, as long as the majority of the content
is correct. Arguably, except for outright vandalism, most spamming would likely modify
articles to contain information that is related to the topic of the article, but not important
or not essential for the majority of readers. As long as this newly added content remains
relevant to the gist of the article, our method will likely be able to correctly determine those
input texts that the article is relevant for. However, a proper evaluation of the robustness
of our method in the presence of imperfect content is beyond the scope of this article.
We believe that this research constitutes a step towards enriching natural language
processing with humans’ knowledge about the world. We hope that Explicit Semantic
Analysis will also be useful for other NLP tasks beyond computing semantic relatedness
and text categorization, and we intend to investigate this in our future work. Recently, we
have used ESA to improve the performance of conventional information retrieval (Egozi,
Gabrilovich, & Markovitch, 2008). In that work, we augmented both queries and documents
with generated features, such that documents were indexed in the augmented space of words
and concepts. Potthast, Stein, and Anderka (2008) and Sorg and Cimiano (2008) adapted
ESA for multi-lingual and cross-lingual information retrieval.
In another recent study, Gurevych et al. (2007) applied our methodology to computing
word similarity in German, and also to an information retrieval task that searched job
descriptions given a user’s description of her career interests, and found our method superior
to a WordNet-based approach. Importantly, this study also confirms that our method
478

Wikipedia-based Semantic Interpretation

can be easily adapted to languages other than English, by using the version of Wikipedia
corresponding to the desired target language.
In our future work, we also intend to apply ESA to word sense disambiguation. Current
approaches to word sense disambiguation represent contexts that contain ambiguous words
using the bag of words augmented with part-of-speech information. We believe representation of such contexts can be greatly improved if we use feature generation to map such
contexts into relevant knowledge concepts. Anecdotal evidence (such as the examples presented in Section 4.5.1) implies our method has promise for improving the state of the art in
word sense disambiguation. In this work we capitalized on inter-article links of Wikipedia
in several ways, and in our future work we intend to investigate more elaborate techniques
for leveraging the high degree of cross-linking between Wikipedia articles.
The Wiki technology underlying the Wikipedia project is often used nowadays in a variety of open-editing initiatives. These include corporate intranets that use Wiki as a primary
documentation tool, as well as numerous domain-specific encyclopedias on topics ranging
from mathematics to Orthodox Christianity.25 Therefore, we believe our methodology can
also be used for augmenting document representation in many specialized domains. It is
also essential to note that Wikipedia is available in numerous languages, while different
language versions are cross-linked at the level of concepts. We believe this information
can be leveraged to use Wikipedia-based semantic interpretation for improving machine
translation.
This work proposes a methodology for Explicit Semantic Analysis using Wikipedia.
However, ESA can also be implemented using other repositories of human knowledge that
satisfy the requirements listed in Section 2.1. In Section 3.3 we reported the results of
building an ESA-based semantic interpreter using the Open Directory Project (Gabrilovich
& Markovitch, 2005, 2007b). Zesch, Mueller, and Gurevych (2008) proposed to use Wiktionary for computing semantic relatedness. In our future work, we intend to implement
ESA using additional knowledge repositories.
Finally, for readers interested in using Wikipedia in their own work, the main software
deliverable of the described work is the Wikipedia preprocessor (WikiPrep), available online
as part of the SourceForge open-source project at http://wikiprep.sourceforge.net.

Acknowledgments
We thank Michael D. Lee and Brandon Pincombe for making available their document similarity data. We also thank Deepak Agarwal for advice on assessing statistical significance
of results in computing semantic relatedness. This work was partially supported by funding
from the EC-sponsored MUSCLE Network of Excellence.
The first author’s current address is Yahoo! Research, 2821 Mission College Blvd, Santa
Clara, CA 95054, USA.

25. See http://en.wikipedia.org/wiki/Category:Online encyclopedias for a longer list of examples.

479

Gabrilovich & Markovitch

Appendix A. The effect of knowledge breadth in text categorization
In this appendix, we examine the effect of performing feature generation using a newer
Wikipedia snapshot, as defined in Section 3.2.2. As we can see from Table 7, using the
larger amount of knowledge leads on average to greater improvements in text categorization performance. Although the difference between the performance of the two versions is
admittedly small, it is consistent across datasets (a similar situation happens when assessing
the role of external knowledge for computing semantic relatedness, see Section 3.3.3).

Dataset

Baseline

micro
BEP
Reuters-21578 (10 cat.) 0.925
Reuters-21578 (90 cat.) 0.877
RCV1 Industry-16
0.642
RCV1 Industry-10A 0.421
RCV1 Industry-10B 0.489
RCV1 Industry-10C 0.443
RCV1 Industry-10D 0.587
RCV1 Industry-10E 0.648
RCV1 Topic-16
0.836
RCV1 Topic-10A
0.796
RCV1 Topic-10B
0.716
RCV1 Topic-10C
0.687
RCV1 Topic-10D
0.829
RCV1 Topic-10E
0.758
OHSUMED-10A
0.518
OHSUMED-10B
0.656
OHSUMED-10C
0.539
OHSUMED-10D
0.683
OHSUMED-10E
0.442
20NG
0.854
Movies
0.813
Average

macro
BEP
0.874
0.602
0.595
0.335
0.528
0.414
0.466
0.605
0.591
0.587
0.618
0.604
0.673
0.742
0.417
0.500
0.505
0.515
0.542

Wikipedia
(26/03/06)
micro macro
BEP BEP
0.935 0.891
0.883 0.600
0.648 0.616
0.457 0.450
0.527 0.559
0.458 0.424
0.607 0.448
0.649 0.607
0.842 0.659
0.802 0.689
0.725 0.660
0.697 0.627
0.838 0.687
0.762 0.752
0.545 0.490
0.667 0.529
0.553 0.527
0.694 0.550
0.461 0.588
0.859
0.850

Improvement
(26/03/06)
micro macro
BEP
BEP
+1.1% +1.9%
+0.7% -0.3%
+0.9% +3.5%
+8.6% +34.3%
+7.8% +5.9%
+3.4% +2.4%
+3.4% -3.9%
+0.2% +0.3%
+0.7% +11.5%
+0.8% +17.4%
+1.3% +6.8%
+1.5% +3.8%
+1.1% +2.1%
+0.5% +1.3%
+5.2% +17.5%
+1.7% +5.8%
+2.6% +4.4%
+1.6% +6.8%
+4.3% +8.5%
+0.6%
+4.5%
+2.50% +6.84%

Improvement
(05/11/05)
micro macro
BEP
BEP
+0.8% +1.5%
+0.7% +0.2%
+0.5% +3.7%
+6.4% +30.4%
+7.0% +7.2%
+5.6% +4.1%
+1.4% -1.5%
-1.1% +1.2%
+0.8% +11.8%
+0.3% +16.2%
+1.0% +6.1%
+1.7% +2.3%
+1.2% +2.2%
+0.9% +1.8%
+3.9% +18.0%
+1.7% +6.8%
+1.1% +3.4%
+1.3% +6.0%
+4.5% +6.1%
+1.0%
+3.6%
+2.11% +6.71%

Table 7: The effect of feature generation using a newer Wikipedia snapshot (dated
March 26, 2006)

480

Wikipedia-based Semantic Interpretation

Appendix B. Test Collections for Text Categorization
This Appendix provides detailed description of the test collections we used to evaluate
knowledge-based feature generation for text categorization.
B.1 Reuters-21578
This data set contains one year worth of English-language stories distributed over the
Reuters newswire in 1986–1987, and is arguably the most often used test collection in
text categorization research. Reuters-21578 is a cleaned version of the earlier release named
Reuters-22173, which contained errors and duplicate documents.
The collection contains 21578 documents (hence the name) in SGML format. Of those,
12902 documents are categorized, i.e., assigned a category label or marked as not belonging
to any category. Other documents do not have an explicit classification; that is, they can
reasonably belong to some categories (judged by their content), but are not marked so. Several train/test splits of the collection has been defined, of which ModApte (Modified Apte)
is the most commonly used one. The ModApte split divides the collection chronologically,
and allocates the first 9603 documents for training, and the rest 3299 documents for testing.
The documents are labeled with 118 categories; there are 0–16 labels per document, with
the average of 1.04. The category distribution is extremely skewed: the largest category
(“earn”) has 3964 positive examples, while 16 categories have only one positive example.
Several category sets were defined for this collection:
• 10 largest categories (“earn”, “acq”, “money-fx”, “grain”, “crude”, “trade”, “interest”, “ship”, “wheat”, “corn”).
• 90 categories with at least one document in the training set and one in the testing set
(Yang, 2001).
• Galavotti, Sebastiani, and Simi (2000) used a set of 115 categories with at least one
training example (three categories, “cottonseed”, “f-cattle” and “sfr” have no training
examples under the ModApte split).
• The full set of 118 categories with at least one positive example either in the training
or in the testing set.
Following common practice, we used the ModApte split and two category sets, 10 largest
categories and 90 categories with at least one training and testing example.
B.2 20 Newsgroups (20NG)
The 20 Newsgroups collection (Lang, 1995) is comprised of 19997 postings to 20 Usenet
newsgroups. Most documents have a single label, defined as the name of the newsgroup
it was sent to; about 4% of documents have been cross-posted, and hence have several
labels. Each newsgroup contains exactly 1000 positive examples, with the exception of
“soc.religion.christian” which contains 997.
Some categories are quite close in scope, for example, “comp.sys.ibm.pc.hardware” and
“comp.sys.mac.hardware”, or “talk.religion.misc” and “soc.religion.christian”. A document
481

Gabrilovich & Markovitch

posted to a single newsgroup may be reasonably considered appropriate for other groups too
(the author may have simply not known of other similar groups, and thus not cross-posted
the message); this naturally poses additional difficulty for classification.
It should be noted that Internet news postings are very informal, and therefore the documents frequently contain non-standard and abbreviated words, foreign words, and proper
names, as well as a large amount of markup characters (used for attribution of authorship
or for message separation).
B.3 Movie Reviews
The Movie Reviews collection (Pang et al., 2002) presents an example of sentiment classification, which is different from standard (topical) text categorization. The collection
contains 1400 reviews of movies, half of which express positive sentiment (opinion) about
the movie, and half negative. The reviews were collected from the “rec.arts.movies.reviews”
newsgroup, archived at the Internet Movie Database (IMDB, http://www.imdb.com). The
classification problem in this case is to determine the semantic orientation of the document, rather than to relate its content to one of the predefined topics. This problem is
arguably more difficult than topical text categorization, since the notion of semantic orientation is quite general. We saw this collection as an opportunity to apply feature generation
techniques to this new task.
Recent works on semantic orientation include (Turney & Littman, 2002; Turney, 2002;
Pang et al., 2002).26 The two former studies used unsupervised learning techniques based
on latent semantic indexing, estimating semantic distance between a given document and
two reference words that represent polar opinions, namely, “excellent” and “poor”. The
latter work used classical TC techniques.
B.4 Reuters Corpus Version 1 (RCV1)
RCV1 is the newest corpus released by Reuters (Lewis et al., 2004; Rose, Stevenson, &
Whitehead, 2002). It is considerably larger than its predecessor, and contains over 800,000
news items, dated between August 20, 1996 and August 19, 1997. The stories are labeled
with 3 category sets, Topics, Industries and Regions.
• Topics are most close in nature to the category set of the old Reuters collection
(Reuters-21578). There are 103 topic codes, with 3.24 categories per document on
the average. The topics are organized in a hierarchy, and the Hierarchy Policy required that if a category is assigned to a document, all its ancestors in the hierarchy
should be assigned as well. As a result, as many as 36% of all Topic assignments
26. The field of genre classification, which attempts to establish the genre of document, is somewhat related
to sentiment classification. Examples of possible genres are radio news transcripts and classified advertisements. The work by Dewdney, VanEss-Dykema, and MacMillan (2001) cast this problem as text
categorization, using presentation features in addition to words. Their presentation features included
part of speech tags and verb tenses, as well as mean and variance statistics of sentence and word length,
punctuation usage, and the amount of whitespace characters. Using support vector machines for actual
classification, the authors found that the performance due to the presentation features alone was at least
as good as that achieved with plain words, and that the combined feature set usually resulted in an
improvement of several percentage points.

482

Wikipedia-based Semantic Interpretation

are due to the four most general categories, CCAT, ECAT, GCAT, and MCAT. Consequently, the micro-averaged performance scores are dominated by these categories
(Lewis et al., 2004), and macro-averaging becomes of interest.27 The Minimum Code
Policy required that each document was assigned at least one Topic and one Region
code.
• Industries are more fine-grained than Topics, and are therefore harder for classification. These categories are also organized in a hierarchy, although the Hierarchy
Policy was only partially enforced for them. There are 351,761 documents labeled
with Industry codes.
• Region codes correspond to geographical places, and are further subdivided into countries, regional groupings and economic groupings. Lewis et al. (2004) argue that
Region codes might be more suitable for named entity recognition than for text categorization.
In our experiments we used Topic and Industry categories. Due to the sheer size of the
collection, processing all the categories in each set would be unreasonably long, allowing to
conduct only few experiments. To speed up experimentation, we used a subset of the corpus
with 17,808 training documents (dated August 20–27, 1996) and 5341 testing documents
(dated August 28–31, 1996). Following the scheme introduced by Brank et al. (2002), we
used 16 Topic and 16 Industry categories, which constitute a representative sample of the
full groups of 103 and 354 categories, respectively. We also randomly sampled the Topic
and Industry categories into 5 sets of 10 categories each. Table 8 gives the full definition of
the category sets we used.
As noted by Lewis et al. (2004), the original RCV1 distribution contains a number of
errors; in particular, there are documents that do not conform to either Minimum Code or
Hierarchy Policy, or labeled with erratic codes. Lewis et al. (2004) proposed a procedure
to correct these errors, and defined a new version of the collection, named RCV1-v2 (as
opposed to the original distribution, referred to as RCV1-v1 ). All our experiments are
based on RCV1-v2.
B.5 OHSUMED
OHSUMED (Hersh et al., 1994) is a subset of the MEDLINE database, which contains
348,566 references to documents published in medical journals over the period of 1987–1991.
Each reference contains the publication title, and about two-thirds (233,445) also contain
an abstract. Each document is labeled with several MeSH categories (MeSH, 2003). There
are over 14,000 distinct categories in the collection, with an average of 13 categories per
document. OHSUMED is frequently used in information retrieval and text categorization
research.
Following Joachims (1998), we used a subset of documents from 1991 that have abstracts,
taking the first 10,000 documents for training and the next 10,000 for testing. To limit the
number of categories for the experiments, we randomly generated 5 sets of 10 categories
each. Table 9 gives the full definition of the category sets we used.
27. This is why micro-averaged scores for Topic codes are so much higher than macro-averaged ones, see
Section 4.4.2.

483

Gabrilovich & Markovitch

Set name
Topic-16
Topic-10A
Topic-10B
Topic-10C
Topic-10D
Topic-10E
Industry-16

Industry-10A
Industry-10B
Industry-10C
Industry-10D
Industry-10E

Categories comprising the set
e142, gobit, e132, c313, e121, godd, ghea, e13, c183, m143,
gspo, c13, e21, gpol, m14, c15
e31, c41, c151, c313, c31, m13, ecat, c14, c331, c33
m132, c173, g157, gwea, grel, c152, e311, c21, e211, c16
c34, c13, gtour, c311, g155, gdef, e21, genv, e131, c17
c23, c411, e13, gdis, c12, c181, gpro, c15, g15, c22
c172, e513, e12, ghea, c183, gdip, m143, gcrim, e11, gvio
i81402, i79020, i75000, i25700, i83100, i16100, i1300003, i14000,
i3302021, i8150206, i0100132, i65600, i3302003, i8150103, i3640010,
i9741102
i47500, i5010022, i3302021, i46000, i42400, i45100, i32000, i81401,
i24200, i77002
i25670, i61000, i81403, i34350, i1610109, i65600, i3302020, i25700,
i47510, i9741110
i25800, i41100, i42800, i16000, i24800, i02000, i34430, i36101,
i24300, i83100
i1610107, i97400, i64800, i0100223, i48300, i81502, i34400, i82000,
i42700, i81402
i33020, i82003, i34100, i66500, i1300014, i34531, i16100, i22450,
i22100, i42900

Table 8: Definition of RCV1 category sets used in the experiments

Appendix C. Additional Examples of Feature Generation for Text
Categorization
In this Appendix, we list a number of additional feature generation examples.
• Text: ‘The development of T-cell leukaemia following the otherwise successful treatment of three patients with X-linked severe combined immune deficiency (X-SCID)
in gene-therapy trials using haematopoietic stem cells has led to a re-evaluation of
this approach. Using a mouse model for gene therapy of X-SCID, we find that the
corrective therapeutic gene IL2RG itself can act as a contributor to the genesis of
T-cell lymphomas, with one-third of animals being affected. Gene-therapy trials for
X-SCID, which have been based on the assumption that IL2RG is minimally oncogenic,
may therefore pose some risk to patients.”
Top 10 generated features: (1) Leukemia; (2) Severe combined immunodeficiency; (3) Cancer; (4) Non-Hodgkin lymphoma; (5) AIDS; (6) ICD-10 Chapter
II: Neoplasms; Chapter III: Diseases of the blood and blood-forming organs,
and certain disorders involving the immune mechanism; (7) Bone marrow transplant; (8) Immunosuppressive drug; (9) Acute lymphoblastic leukemia; (10) Multiple sclerosis

Selected explanations: (4) a particular cancer type; (6) a disease code of the ICD—
International Statistical Classification of Diseases and Related Health Problems
• Text: “Scientific methods in biology”
484

Wikipedia-based Semantic Interpretation

Set name
OHSUMED-10A

OHSUMED-10B

OHSUMED-10C

OHSUMED-10D

OHSUMED-10E

Categories comprising the set
(parentheses contain MeSH identifiers)
B-Lymphocytes (D001402);
Metabolism, Inborn Errors (D008661);
Creatinine (D003404); Hypersensitivity (D006967);
Bone Diseases, Metabolic (D001851); Fungi (D005658);
New England (D009511); Biliary Tract (D001659);
Forecasting (D005544); Radiation (D011827)
Thymus Gland (D013950); Insurance (D007341);
Historical Geographic Locations (D017516);
Leukocytes (D007962); Hemodynamics (D006439);
Depression (D003863); Clinical Competence (D002983);
Anti-Inflammatory Agents, Non-Steroidal (D000894);
Cytophotometry (D003592); Hydroxy Acids (D006880)
Endothelium, Vascular (D004730);
Contraceptives, Oral, Hormonal (D003278);
Acquired Immunodeficiency Syndrome (D000163);
Gram-Positive Bacteria (D006094); Diarrhea (D003967);
Embolism and Thrombosis (D016769);
Health Behavior (D015438); Molecular Probes (D015335);
Bone Diseases, Developmental (D001848);
Referral and Consultation (D012017)
Antineoplastic and Immunosuppressive Agents (D000973);
Receptors, Antigen, T-Cell (D011948);
Government (D006076); Arthritis, Rheumatoid (D001172);
Animal Structures (D000825); Bandages (D001458);
Italy (D007558); Investigative Techniques (D008919);
Physical Sciences (D010811); Anthropology (D000883)
HTLV-BLV Infections (D006800);
Hemoglobinopathies (D006453); Vulvar Diseases (D014845);
Polycyclic Hydrocarbons, Aromatic (D011084);
Age Factors (D000367); Philosophy, Medical (D010686);
Antigens, CD4 (D015704);
Computing Methodologies (D003205);
Islets of Langerhans (D007515); Regeneration (D012038)

Table 9: Definition of OHSUMED category sets used in the experiments

485

Gabrilovich & Markovitch

Top 10 generated features: (1) Biology; (2) Scientific classification; (3) Science; (4) Chemical biology; (5) Binomial nomenclature; (6) Nature (journal);
(7) Social sciences; (8) Philosophy of biology; (9) Scientist; (10) History of
biology
Selected explanations: (5) the formal method of naming species in biology
• Text: “With quavering voices, parents and grandparents of those killed at the World
Trade Center read the names of the victims in a solemn recitation today, marking the
third anniversary of the terror attacks. The ceremony is one of many planned in the
United States and around the world to honor the memory of the nearly 3,000 victims
of 9/11.”
Top 10 generated features: (1) September 11, 2001 attack memorials and services; (2) United Airlines Flight 93; (3) Aftermath of the September 11, 2001
attacks; (4) World Trade Center; (5) September 11, 2001 attacks; (6) Oklahoma City bombing; (7) World Trade Center bombing; (8) Arlington National
Cemetery; (9) World Trade Center site; (10) Jewish bereavement
Selected explanations: (2) one of the four flights hijacked on September 11, 2001;
(6) a terrorist attack in Oklahoma City in 1995; (8) American military cemetery
• Text: “U.S. intelligence cannot say conclusively that Saddam Hussein has weapons
of mass destruction, an information gap that is complicating White House efforts
to build support for an attack on Saddam’s Iraqi regime. The CIA has advised top
administration officials to assume that Iraq has some weapons of mass destruction.
But the agency has not given President Bush a “smoking gun,” according to U.S.
intelligence and administration officials.”
Top 10 generated features: (1) Iraq disarmament crisis; (2) Yellowcake forgery; (3) Senate Report of Pre-War Intelligence on Iraq; (4) Iraq and weapons
of mass destruction; (5) Iraq Survey Group; (6) September Dossier; (7) Iraq
war; (8) Scott Ritter; (9) Iraq War Rationale; (10) Operation Desert Fox
Selected explanations: (2) falsified intelligence documents about Iraq’s alleged
attempt to purchase yellowcake uranium; (6) a paper on Iraq’s weapons of mass
destruction published by the UK government in 2002; (8) UN weapons inspector in
Iraq; (10) US and UK joint military campaign in Iraq in 1998
• As another example, consider a pair of contexts that contain the word “jaguar”, the
first one contains this ambiguous word in the sense of a car model, and the second
one—in the sense of an animal.
– Text: “Jaguar car models”
Top 10 generated features: (1) Jaguar (car); (2) Jaguar (S-Type); (3)
Jaguar X-type; (4) Jaguar E-Type; (5) Jaguar XJ; (6) Daimler Motor Company; (7) British Leyland Motor Corporation; (8) Luxury vehicles; (9) V8
engine; (10) Jaguar Racing
Top 10 generated features: (2), (3), (4), (5) — particular Jaguar car models;
(6) a car manufacturing company that became a part of Jaguar in 1960; (7)
486

Wikipedia-based Semantic Interpretation

another vehicle manufacturing company that merged with Jaguar; (9) an internal
combustion engine used in some Jaguar car models; (10) a Formula One team
used by Jaguar to promote its brand name
– Text: “Jaguar (Panthera onca)”
Top 10 generated features: (1) Jaguar; (2) Felidae; (3) Black panther;
(4) Leopard; (5) Puma; (6) Tiger; (7) Panthera hybrid; (8) Cave lion; (9)
American lion; (10) Kinkajou
Top 10 generated features: (2) a family that include lions, tigers, jaguars,
and other related feline species; (10) another carnivore mammal
We also show here a number of examples for generating features using inter-article links.
• Text: “artificial intelligence”
Regular feature generation: (1) Artificial intelligence; (2) A.I. (film); (3)
MIT Computer Science and Artificial Intelligence Laboratory; (4) Artificial
life; (5) Strong AI; (6) Swarm intelligence; (7) Computer Science; (8) Frame
problem; (9) Cognitive science; (10) Carl Hewitt
Features generated using links: (1) Robot; (2) John McCarthy (computer scientist); (3) Artificial consciousness; (4) Marvin Minsky; (5) Planner programming language; (6) Actor model (a model of concurrent computation formulated
by Carl Hewitt and his colleagues); (7) Logic; (8) Scientific Community Metaphor;
(9) Natural language processing; (10) Lisp programming language
More general features only: (1) Robot; (2) Massachusetts Institute of Technology; (3) Psychology; (4) Consciousness; (5) Lisp programming language
• Text: “A group of European-led astronomers has made a photograph of what appears
to be a planet orbiting another star. If so, it would be the first confirmed picture of a
world beyond our solar system.”
Regular feature generation: (1) Planet; (2) Solar system; (3) Astronomy; (4)
Planetary orbit; (5) Extrasolar planet; (6) Pluto; (7) Jupiter; (8) Neptune; (9)
Minor planet; (10) Mars
Features generated using links: (1) Asteroid; (2) Earth; (3) Oort cloud (a
postulated cloud of comets); (4) Comet; (5) Sun; (6) Saturn; (7) Moon; (8) Mercury
(planet); (9) Asteroid belt; (10) Orbital period
More general features only: (1) Earth; (2) Moon; (3) Asteroid; (4) Sun; (5)
National Aeronautics and Space Administration
• Text: “Nearly 70 percent of Americans say they are careful about what they eat, and
even more say diet is essential to good health, according to a new nationwide health
poll in which obesity ranked second among the biggest health concerns.”
Regular feature generation: (1) Veganism; (2) Vegetarianism; (3) Obesity; (4)
Atkins Nutritional Approach; (5) Binge eating disorder; (6) Dick Gregory; (7)
Nutrition; (8) Super Size Me; (9) Health insurance; (10) Eating disorder
487

Gabrilovich & Markovitch

Selected explanations: (1) a philosophy of avoiding animal-derived food; (6) an
American nutritionist; (7) a documentary film about an individual who eats only
McDonald’s fast food for one full month.
Features generated using links: (1) Raw food diet; (2) Diabetes mellitus; (3)
Healthy eating; (4) Body mass index; (5) Omega-3 fatty acid (an important nutritional component); (6) Dieting; (7) Milk; (8) United States28 ; (9) Hypertension;
(10) Egg (food)
More general features only: (1) United States; (2) Diabetes mellitus; (3) Cancer; (4) Food; (5) McDonald’s

Appendix D. Comparing Knowledge Sources for Feature Generation:
Wikipedia versus WordNet
To demonstrate the shortcomings of WordNet as a source for knowledge-based feature generation, we juxtapose WordNet-based and Wikipedia-based feature generation for a sample
sentence examined in Section 4.5.1 (we repeat the Wikipedia context classifications for
readers’ convenience).
We used WordNet version 1.6. In what follows, WordNet synsets are denoted with curly
braces, and noun and verb synsets are followed by their immediate hypernym (more general
synset), if applicable.
• Text: “Wal-Mart supply chain goes real time”
• Most relevant Wikipedia classifications:
– Wal-Mart
– Sam Walton — Wal-Mart founder
– Sears Holdings Corporation, Target Corporation, Albertsons — prominent competitors of Wal-Mart
– RFID — Radio Frequency Identification, a technology that Wal-Mart uses very
extensively to manage its stock
– Hypermarket — superstore, a general concept of which Wal-Mart is a specific
example
– United Food and Commercial Workers — a labor union that has been trying
to organize Wal-Mart’s workers
• WordNet :
– {Wal-Mart} → { }; (word not found in WordNet)
– {supply} → {indefinite quantity}; {supply} → {economic process}; {provision,
providing, supply supplying} → {activity};
28. This classification is quite interesting, as the issue discussed in the input text fragment is very characteristic of the American life style.

488

Wikipedia-based Semantic Interpretation

– {supply provide, render, furnish} → {give}; {issue, supply} → {distribute};
{provide, supply ply, cater} → {give}; {add, append, supply} → {state, say,
tell};
– {chain, concatenation} → {series}; {chain, chemical chain} → {unit, building
block}; {chain} → {ligament}; {chain} → {business, concern, business concern,
business organization}; {chain} → {restraint, constraint}; {chain} → {linear
unit}; {range, mountain range, range of mountains, chain, mountain chain,
chain of maountains} → {geological formation, geology, formation}; {iron, irons,
chain, chains} → {shackle, bond, hamper, trammel, trammels}; {chain, string,
strand} → {necklace};
– {chain} → {fasten, fix, secure};
– {go, spell, tour, turn} → {shift, work shift, duty period}; {crack, fling, go, pass,
whirl, offer} → {attempt, effort, endeavor, endeavour, try}; {go, go game} →
{board game};
– {travel, move, go, locomote}; {go, proceed, move} → {act, move}; (28 more
verb senses omitted for brevity)
– {real number, real}; {real (Spanish coin)};
– {real, existent}; {real (no less than what is stated)}; {real, true}; {real (not to
be taken lightly)}; {real, tangible}; {actual, genuine, literal, real}; {real (economics)}; {substantial, real, material}; {real (of property)}; {veridical, real};
{real (founded on practical matters)};
– {very, really, real, rattling};
– {time, clip} → {case, instance, example}; {time} → {time period, period,
period of time, amount of time}; {time} → {moment, minute, second, instant}; {time} → {abstraction}; {clock time, time} → {reading, meter reading}; {fourth dimension, time} → {dimension}; {time} → {experience}; {meter,
time} → {rhythmicity}; {prison term, sentence, time} → {term};
– {clock, time} → {quantify, measure}; {time} → {schedule}; {time} →
{determine, shape, influence, regulate}; {time} → {adjust, set};
Evidently, WordNet classifications are overly general and diverse because context words
cannot be properly disambiguated. Furthermore, owing to lack of proper names, WordNet
cannot possibly provide the wealth of information encoded in Wikipedia, which easily overcomes the drawbacks of WordNet. The methodology we proposed does not suffer from the
above shortcomings.

489

Gabrilovich & Markovitch

References
Adafre, S. F., & de Rijke, M. (2005). Discovering missing links in Wikipedia. In Proceedings
of the Workshop on Link Discovery: Issues, Approaches and Applications (LinkKDD2005), pp. 90–97.
Baeza-Yates, R., & Ribeiro-Neto, B. (1999). Modern Information Retrieval. Addison Wesley,
New York, NY.
Baker, D., & McCallum, A. K. (1998). Distributional clustering of words for text classification. In Croft, B., Moffat, A., Van Rijsbergen, C. J., Wilkinson, R., & Zobel, J. (Eds.),
Proceedings of the 21st ACM International Conference on Research and Development
in Information Retrieval, pp. 96–103, Melbourne, AU. ACM Press, New York, US.
Basili, R., Moschitti, A., & Pazienza, M. T. (2000). Language-sensitive text classification.
In Proceedings of RIAO-00, 6th International Conference “Recherche d’Information
Assistee par Ordinateur”, pp. 331–343, Paris, France.
Begelman, G., Keller, P., & Smadja, F. (2006). Automated tag clustering: Improving search
and exploration in the tag space. In Proceedings of the Collaborative Web Tagging
Workshop, in conjunction with the 15th International World Wide Web Conference,
Edinburgh, Scotland.
Bekkerman, R. (2003). Distributional clustering of words for text categorization. Master’s
thesis, Technion.
Bloehdorn, S., & Hotho, A. (2004). Boosting for text classification with semantic features.
In Proceedings of the MSW 2004 Workshop at the 10th ACM SIGKDD Conference
on Knowledge Discovery and Data Mining, pp. 70–87.
Brank, J., Grobelnik, M., Milic-Frayling, N., & Mladenic, D. (2002). Interaction of feature
selection methods and linear classification models. In Workshop on Text Learning
held at ICML-2002.
Brill, E. (1995). Transformation-based error-driven learning and natural language processing: A case study in part of speech tagging. Computational Linguistics, 21 (4),
543–565.
Buchanan, B. G., & Feigenbaum, E. (1982). Forward. In Davis, R., & Lenat, D. (Eds.),
Knowledge-Based Systems in Artificial Intelligence. McGraw-Hill.
Budanitsky, A., & Hirst, G. (2006). Evaluating wordnet-based measures of lexical semantic
relatedness. Computational Linguistics, 32 (1), 13–47.
Cai, L., & Hofmann, T. (2003). Text categorization by boosting automatically extracted
concepts. In Proceedings of the 26th International Conference on Research and Development in Information Retrieval, pp. 182–189.
Caropreso, M. F., Matwin, S., & Sebastiani, F. (2001). A learner-independent evaluation of
the usefulness of statistical phrases for automated text categorization. In Chin, A. G.
(Ed.), Text Databases and Document Management: Theory and Practice, pp. 78–102.
Idea Group Publishing, Hershey, US.
490

Wikipedia-based Semantic Interpretation

Chang, M.-W., Ratinov, L., Roth, D., & Srikumar, V. (2008). Importance of semantic
representation: Dataless classification. In Proceedings of the 23rd AAAI Conference
on Artificial Intelligence, pp. 830–835.
Cohen, W. W. (1995). Fast effective rule induction. In Proceedings of the 12th International
Conference on Machine Learning (ICML-95), pp. 115–123.
Cohen, W. W. (2000). Automatically extracting features for concept learning from the web.
In Proceedings of the 17th International Conference on Machine Learning.
Dagan, I., Lee, L., & Pereira, F. C. N. (1999). Similarity-based models of word cooccurrence
probabilities. Machine Learning, 34 (1–3), 43–69.
Dagan, I., Marcus, S., & Markovitch, S. (1995). Contextual word similarity and estimation
from sparse data. Computer Speech and Language, 9 (2), 123–152.
Davidov, D., Gabrilovich, E., & Markovitch, S. (2004). Parameterized generation of labeled
datasets for text categorization based on a hierarchical directory. In Proceedings of
the 27th ACM International Conference on Research and Development in Information
Retrieval, pp. 250–257.
Debole, F., & Sebastiani, F. (2003). Supervised term weighting for automated text categorization. In Proceedings of SAC-03, 18th ACM Symposium on Applied Computing,
pp. 784–788.
Deerwester, S., Dumais, S., Furnas, G., Landauer, T., & Harshman, R. (1990). Indexing by
latent semantic analysis. Journal of the American Society for Information Science,
41 (6), 391–407.
Demsar, J. (2006). Statistical comparison of classifiers over multiple data sets. Journal of
Machine Learning Research, 7, 1–30.
Dewdney, N., VanEss-Dykema, C., & MacMillan, R. (2001). The form is the substance:
Classification of genres in text. In Workshop on HLT and KM held at ACL-2001.
Dhillon, I., Mallela, S., & Kumar, R. (2003). A divisive information-theoretic feature clustering algorithm for text classification. Journal of Machine Learning Research, 3,
1265–1287.
Dumais, S., Platt, J., Heckerman, D., & Sahami, M. (1998). Inductive learning algorithms
and representations for text categorization. In Proceedings of the 7th ACM International Conference on Information and Knowledge Management, pp. 148–155.
Egozi, O., Gabrilovich, E., & Markovitch, S. (2008). Concept-based feature generation and
selection for information retrieval. In AAAI’08.
Fawcett, T. (1993). Feature Discovery for Problem Solving Systems. Ph.D. thesis, UMass.
Fellbaum, C. (Ed.). (1998). WordNet: An Electronic Lexical Database. MIT Press, Cambridge, MA.
Finkelstein, L., Gabrilovich, E., Matias, Y., Rivlin, E., Solan, Z., Wolfman, G., & Ruppin,
E. (2002a). Placing search in context: The concept revisited. ACM Transactions on
Information Systems, 20 (1), 116–131.
491

Gabrilovich & Markovitch

Finkelstein, L., Gabrilovich, E., Matias, Y., Rivlin, E., Solan, Z., Wolfman, G., & Ruppin,
E. (2002b). WordSimilarity-353 test collection..
Fuernkranz, J., Mitchell, T., & Riloff, E. (1998). A case study in using linguistic phrases
for text categorization on the WWW. In Sahami, M. (Ed.), Learning for Text Categorization: Proceedings of the 1998 AAAI/ICML Workshop, pp. 5–12. AAAI Press,
Madison, Wisconsin.
Gabrilovich, E., & Markovitch, S. (2004). Text categorization with many redundant features:
Using aggressive feature selection to make SVMs competitive with C4.5. In Proceedings
of the 21st International Conference on Machine Learning, pp. 321–328.
Gabrilovich, E., & Markovitch, S. (2005). Feature generation for text categorization using world knowledge. In Proceedings of the 19th International Joint Conference on
Artificial Intelligence, pp. 1048–1053, Edinburgh, Scotand.
Gabrilovich, E., & Markovitch, S. (2006). Overcoming the brittleness bottleneck using
Wikipedia: Enhancing text categorization with encyclopedic knowledge. In Proceedings of the 21st National Conference on Artificial Intelligence, pp. 1301–1306.
Gabrilovich, E., & Markovitch, S. (2007a). Computing semantic relatedness using wikipediabased explicit semantic analysis. In Proceedings of the 20th International Joint Conference on Artificial Intelligence, pp. 1606–1611.
Gabrilovich, E., & Markovitch, S. (2007b). Harnessing the expertise of 70,000 human editors: Knowledge-based feature generation for text categorization. Journal of Machine
Learning Research, 8, 2297–2345.
Galavotti, L., Sebastiani, F., & Simi, M. (2000). Experiments on the use of feature selection
and negative evidence in automated text categorization. In Borbinha, J., & Baker, T.
(Eds.), Proceedings of ECDL-00, 4th European Conference on Research and Advanced
Technology for Digital Libraries, pp. 59–68, Lisbon, Portugal.
Giles, J. (2005). Internet encyclopaedias go head to head. Nature, 438, 900–901.
Gurevych, I., Mueller, C., & Zesch, T. (2007). What to be? — electronic career guidance
based on semantic relatedness. In Proceedings of the 45th Annual Meeting of the
Association for Computational Linguistics.
Hersh, W., Buckley, C., Leone, T., & Hickam, D. (1994). OHSUMED: An interactive
retrieval evaluation and new large test collection for research. In Proceedings of the
17th ACM International Conference on Research and Development in Information
Retrieval, pp. 192–201.
Hirsh, H., & Japkowicz, N. (1994). Bootstrapping training-data representations for inductive
learning: “a case study in molecular biology”. In Proceedings of the Twelfth National
Conference on Artificial Intelligence, pp. 639–644.
Hirst, G., & St-Onge, D. (1998). Lexical chains as representations of context for the detection
and correction of malapropisms. In WordNet: An Electronic Lexical Database, pp.
305–332. MIT Press, Cambridge, MA.
Hu, Y.-J., & Kibler, D. (1996). A wrapper approach for constructive induction. In The
Thirteenth National Conference on Artificial Intelligence, pp. 47–52.
492

Wikipedia-based Semantic Interpretation

Hughes, T., & Ramage, D. (2007). Lexical semantic relatedness with random graph walks. In
Proceedings of the Conference on Empirical Methods in Natural Language Processing
(EMNLP).
Hull, D. A. (1994). Improving text retrieval for the routing problem using latent semantic
indexing. In Croft, W. B., & Van Rijsbergen, C. J. (Eds.), Proceedings of the 17th ACM
International Conference on Research and Development in Information Retrieval, pp.
282–289, Dublin, Ireland. Springer Verlag, Heidelberg, Germany.
Jarmasz, M. (2003). Roget’s thesaurus as a lexical resource for natural language processing.
Master’s thesis, University of Ottawa.
Jarmasz, M., & Szpakowicz, S. (2003). Roget’s thesaurus and semantic similarity. In
Proceedings of the International Conference on Recent Advances in Natural Language
Processing, pp. 111–120.
Jiang, J. J., & Conrath, D. W. (1997). Semantic similarity based on corpus statistics and
lexical taxonomy. In Proceedings of the 10th International Conference on Research on
Computational Linguistics, pp. 57–63.
Jo, T. (2000). Neurotextcategorizer: A new model of neural network for text categorization.
In Proceedings of the International Conference of Neural Information Processing, pp.
280–285, Taejon, South Korea.
Jo, T. (2006). Dynamic Document Organization using Text Categorization and Text Clustering. Ph.D. thesis, University of Ottawa.
Jo, T., & Japkowicz, N. (2005). Text clustering using NTSO. In Proceedings of the International Joint Conference on Neural Networks, pp. 558–563.
Joachims, T. (1998). Text categorization with support vector machines: Learning with many
relevant features. In Proceedings of the European Conference on Machine Learning,
pp. 137–142.
Joachims, T. (1999). Making large-scale SVM learning practical. In Schoelkopf, B., Burges,
C., & Smola, A. (Eds.), Advances in Kernel Methods – Support Vector Learning, pp.
169–184. The MIT Press.
Kudenko, D., & Hirsh, H. (1998). Feature generation for sequence categorization. In Proceedings of the 15th Conference of the American Association for Artificial Intelligence,
pp. 733–738.
Kumaran, G., & Allan, J. (2004). Text classification and named entities for new event
detection. In Proceedings of the 27th ACM International Conference on Research and
Development in Information Retrieval, pp. 297–304.
Lang, K. (1995). Newsweeder: Learning to filter netnews. In Proceedings of the 12th International Conference on Machine Learning, pp. 331–339.
Leacock, C., & Chodorow, M. (1998). Combining local context and WordNet similarity for
word sense identification. In WordNet: An Electronic Lexical Database, pp. 265–283.
MIT Press, Cambridge, MA.
Lee, L. (1999). Measures of distributional similarity. In Proceedings of the 37th Annual
Meeting of the ACL, pp. 25–32.
493

Gabrilovich & Markovitch

Lee, M. D., Pincombe, B., & Welsh, M. (2005). A comparison of machine measures of text
document similarity with human judgments. In 27th Annual Meeting of the Cognitive
Science Society (CogSci2005), pp. 1254–1259.
Lenat, D. B. (1995). CYC: A large-scale investment in knowledge infrastructure. Communications of the ACM, 38 (11).
Lenat, D. B. (1997). From 2001 to 2001: Common sense and the mind of HAL. In HAL’s
Legacy, pp. 194–209. The MIT Press.
Lenat, D. B., Guha, R. V., Pittman, K., Pratt, D., & Shepherd, M. (1990). CYC: Towards
programs with common sense. Communications of the ACM, 33 (8).
Leopold, E., & Kindermann, J. (2002). Text categorization with support vector machines:
How to represent texts in input space. Machine Learning, 46, 423–444.
Lewis, D. D. (1992). An evaluation of phrasal and clustered representations on a text
categorization task. In Proceedings of the 15th ACM International Conference on
Research and Development in Information Retrieval, pp. 37–50.
Lewis, D. D., & Croft, W. B. (1990). Term clustering of syntactic phrases. In Proceedings of
the 13th ACM International Conference on Research and Development in Information
Retrieval, pp. 385–404.
Lewis, D. D., Schapire, R. E., Callan, J. P., & Papka, R. (1996). Training algorithms for
linear text classifiers. In Proceedings of the 19th ACM International Conference on
Research and Development in Information Retrieval, pp. 298–306.
Lewis, D. D., Yang, Y., Rose, T., & Li, F. (2004). RCV1: A new benchmark collection for
text categorization research. Journal of Machine Learning Research, 5, 361–397.
Lin, D. (1998a). Automatic retrieval and clustering of similar words. In Proceedings of the
17th International Conference on Computational Linguistics and 36th Annual Meeting
of the Association for Computational Linguistics, pp. 768–774.
Lin, D. (1998b). An information-theoretic definition of word similarity. In Proceedings of
the 15th International Conference on Machine Learning, pp. 296–304.
Liu, T., Chen, Z., Zhang, B., Ma, W.-y., & Wu, G. (2004). Improving text classification
using local latent semantic indexing. In ICDM’04, pp. 162–169.
Manning, C. D., & Schuetze, H. (2000). Foundations of Statistical Natural Language Processing. The MIT Press.
Markovitch, S., & Rosenstein, D. (2002). Feature generation using general constructor
functions. Machine Learning, 49 (1), 59–98.
Matheus, C. J. (1991). The need for constructive induction. In Birnbaum, L., & Collins, G.
(Eds.), Proceedings of the Eighth International Workshop on Machine Learning, pp.
173–177.
Matheus, C. J., & Rendell, L. A. (1989). Constructive induction on decision trees. In
Proceedings of the 11th International Conference on Artificial Intelligence, pp. 645–
650.
494

Wikipedia-based Semantic Interpretation

MeSH (2003). Medical subject headings (MeSH).
http://www.nlm.nih.gov/mesh.

National Library of Medicine.

Metzler, D., Dumais, S., & Meek, C. (2007). Similarity measures for short segments of text.
In Proceedings of the 29th European Conference on Information Retrieval, pp. 16–27.
Mihalcea, R. (2003). Turning wordnet into an information retrieval resource: Systematic
polysemy and conversion to hierarchical codes. International Journal of Pattern Recognition and Artificial Intelligence (IJPRAI), 17 (1), 689–704.
Mihalcea, R., Corley, C., & Strapparava, C. (2006). Corpus-based and knowledge-based
measures of text semantic similarity. In AAAI’06, pp. 775–780.
Mikheev, A. (1998). Feature lattices and maximum entropy models. In Proceedings of the
17th International Conference on Computational Linguistics, pp. 848–854.
Miller, G. A., & Charles, W. G. (1991). Contextual correlates of semantic similarity. Language and Cognitive Processes, 6 (1), 1–28.
Milne, D., & Witten, I. (2008). An effective, low-cost measure of semantic relatedness
obtained from wikipedia links. In Proceedings of the AAAI-08 Workshop on Wikipedia
and Artificial Intelligence, in conjunction with 23rd AAAI Conference on Artificial
Intelligence.
Mladenic, D. (1998). Turning Yahoo into an automatic web-page classifier. In Proceedings
of 13th European Conference on Artificial Intelligence, pp. 473–474.
Montague, R. (1973). The proper treatment of quantification in ordinary English. In
Hintikka, J., Moravcsik, J., & Suppes, P. (Eds.), Approaches to Natural Language, pp.
373–398. Reidel, Dordrecht.
Murphy, P. M., & Pazzani, M. J. (1991). ID2-of-3: Constructive induction of M-of-N concepts for discriminators in decision trees. In Proceedings of the 8th International
Conference on Machine Learning, pp. 183–188. Morgan Kaufmann.
Pagallo, G., & Haussler, D. (1990). Boolean feature discovery in empirical learning. Machine
Learning, 5 (1), 71–99.
Pang, B., Lee, L., & Vaithyanathan, S. (2002). Thumbs up? Sentiment classification using
machine learning techniques. In Proceedings of the Conference on Empirical Methods
in Natural Language Processing, pp. 79–86.
Peng, F., Schuurmans, D., & Wang, S. (2004). Augmenting naive Bayes classifiers with
statistical language models. Information Retrieval, 7 (3-4), 317–345.
Peng, F., & Shuurmans, D. (2003). Combining naive Bayes and n-gram language models
for text classification. In Proceedings of the 25th European Conference on Information
Retrieval Research (ECIR-03), pp. 335–350.
Pincombe, B. (2004). Comparison of human and latent semantic analysis (LSA) judgements
of pairwise document similarities for a news corpus. Tech. rep. DSTO-RR-0278, Information Sciences Laboratory, Defence Science and Technology Organization, Department of Defense, Australian Government.
Porter, M. (1980). An algorithm for suffix stripping. Program, 14 (3), 130–137.
495

Gabrilovich & Markovitch

Potthast, M., Stein, B., & Anderka, M. (2008). A wikipedia-based multilingual retrieval
model. In European Conference on Information Retrieval.
Press, W. H., Teukolsky, S. A., Vetterling, W. T., & Flannery, B. P. (1997). Numerical
Recipes in C: The Art of Scientific Computing. Cambridge University Press.
Qiu, Y., & Frei, H. (1993). Concept based query expansion. In Proceedings of the ACM
International Conference on Research and Development in Information Retrieval.
Raskutti, B., Ferra, H., & Kowalczyk, A. (2001). Second order features for maximizing
text classification performance. In De Raedt, L., & Flach, P. (Eds.), Proceedings of
the European Conference on Machine Learning (ECML), Lecture notes in Artificial
Intelligence (LNAI) 2167, pp. 419–430. Springer-Verlag.
Resnik, P. (1999). Semantic similarity in a taxonomy: An information-based measure and
its application to problems of ambiguity in natural language. Journal of Artificial
Intelligence Research, 11, 95–130.
Reuters (1997). Reuters-21578 text categorization test collection, Distribution 1.0. Reuters.
daviddlewis.com/resources/testcollections/reuters21578.
Rocchio, J. J. (1971). Relevance feedback in information retrieval. In The SMART Retrieval
System: Experiments in Automatic Document Processing, pp. 313–323. Prentice Hall.
Rogati, M., & Yang, Y. (2002). High-performing feature selection for text classification. In
Proceedings of the International Conference on Information and Knowledge Management (CIKM’02), pp. 659–661.
Roget, P. (1852). Roget’s Thesaurus of English Words and Phrases. Longman Group Ltd.
Rose, T., Stevenson, M., & Whitehead, M. (2002). The Reuters Corpus Volume 1—from
yesterday’s news to tomorrow’s language resources. In Proceedings of the Third International Conference on Language Resources and Evaluation, pp. 7–13.
Rowling, J. (1997). Harry Potter and the Philosopher’s Stone. Bloomsbury.
Rubenstein, H., & Goodenough, J. B. (1965). Contextual correlates of synonymy. Communications of the ACM, 8 (10), 627–633.
Sable, C., McKeown, K., & Church, K. W. (2002). NLP found helpful (at least for one
text categorization task). In Conference on Empirical Methods in Natural Language
Processing, pp. 172–179.
Sahami, M., & Heilman, T. (2006). A web-based kernel function for measuring the similarity
of short text snippets. In WWW’06, pp. 377–386. ACM Press.
Salton, G., & Buckley, C. (1988). Term weighting approaches in automatic text retrieval.
Information Processing and Management, 24 (5), 513–523.
Salton, G., & McGill, M. (1983).
McGraw-Hill.

An Introduction to Modern Information Retrieval.

Scott, S. (1998). Feature engineering for a symbolic approach to text classification. Master’s
thesis, U. Ottawa.
Scott, S., & Matwin, S. (1999). Feature engineering for text classification. In Proceedings
of the 16th International Conference on Machine Learning, pp. 379–388.
496

Wikipedia-based Semantic Interpretation

Sebastiani, F. (2002). Machine learning in automated text categorization. ACM Computing
Surveys, 34 (1), 1–47.
Snow, R., O’Connor, B., Jurafsky, D., & Ng, A. Y. (2008). Cheap and fast - but is it good?
evaluating non-expert annotations for natural language tasks. In Proceedings of the
Conference on Empirical Methods in Natural Language Processing.
Sorg, P., & Cimiano, P. (2008). Cross-lingual information retrieval with explicit semantic
analysis. In Working Notes for the CLEF Workshop.
Strube, M., & Ponzetto, S. P. (2006). WikiRelate! Computing semantic relatedness using
Wikipedia. In AAAI’06, pp. 1419–1424, Boston, MA.
Turney, P. (2002). Thumbs up or thumbs down? Semantic orientation applied to unsupervised classification of reviews. In Proceedings of the 40th Annual Meeting of the
Association of Computational Linguistics, pp. 417–424.
Turney, P. (2005). Measuring semantic similarity by latent relational analysis. In Proceedings
of the Nineteenth International Joint Conference on Artificial Intelligence (IJCAI-05),
pp. 1136–1141, Edinburgh, Scotland.
Turney, P. (2006). Similarity of semantic relations. Computational Linguistics, 32 (3), 379–
416.
Turney, P., & Littman, M. L. (2002). Unsupervised learning of semantic orientation from
a hundred-billion-word corpus. Tech. rep. ERB-1094, National Research Council
Canada.
Turney, P. D. (2001). Mining the web for synonyms: PMI-IR versus LSA on TOEFL. In
Proceedings of the Twelfth European Conference on Machine Learning, pp. 491–502.
Urena-Lopez, A., Buenaga, M., & Gomez, J. M. (2001). Integrating linguistic resources in
TC through WSD. Computers and the Humanities, 35, 215–230.
Wang, B. B., McKay, R., Abbass, H. A., & Barlow, M. (2003). A comparative study for
domain ontology guided feature extraction. In Proceedings of the 26th Australian
Computer Science Conference (ASCS-2003), pp. 69–78.
Widrow, B., & Stearns, S. (1985). Adaptive Signal Processing. Prentice Hall.
Wikipedia (2006). Wikipedia, the free encyclopedia.. http://en.wikipedia.org.
Wu, H., & Gunopulos, D. (2002). Evaluating the utility of statistical phrases and latent
semantic indexing for text classification. In IEEE International Conference on Data
Mining, pp. 713–716.
Yang, Y. (2001). A study on thresholding strategies for text categorization. In Proceedings
of the 24th International Conference on Research and Development in Information
Retrieval, pp. 137–145.
Yang, Y., & Liu, X. (1999). A re-examination of text categorization methods. In Proceedings
of the 22nd International Conference on Research and Development in Information
Retrieval, pp. 42–49.
Yang, Y., & Pedersen, J. (1997). A comparative study on feature selection in text categorization. In Proceedings of the 14th International Conference on Machine Learning,
pp. 412–420.
497

Gabrilovich & Markovitch

Zelikovitz, S., & Hirsh, H. (2000). Improving short-text classification using unlabeled background knowledge to assess document similarity. In Proceedings of the 17th International Conference on Machine Learning, pp. 1183–1190.
Zelikovitz, S., & Hirsh, H. (2001). Using LSI for text classification in the presence of
background text. In Proceedings of the Conference on Information and Knowledge
Management, pp. 113–118.
Zesch, T., & Gurevych, I. (2006). Automatically creating datasets for measures of semantic
relatedness. In Proceedings of the ACL Workshop on Linguistic Distances, pp. 16–24,
Sydney, Australia.
Zesch, T., Mueller, C., & Gurevych, I. (2008). Using wiktionary for computing semantic
relatedness. In Proceedings of the 23rd AAAI Conference on Artificial Intelligence,
pp. 861–866.
Zobel, J., & Moffat, A. (1998). Exploring the similarity space. ACM SIGIR Forum, 32 (1),
18–34.

498

Journal of Artificial Intelligence Research 34 (2009) 255-296

Submitted 10/08; published 03/09

Unsupervised Methods for Determining Object and Relation
Synonyms on the Web
Alexander Yates

yates@temple.edu

Temple University
Computer and Information Sciences
1805 N. Broad St.
Wachman Hall 303A
Philadelphia, PA 19122

Oren Etzioni

etzioni@cs.washington.edu

University of Washington
Computer Science and Engineering
Box 352350
Seattle, WA 98195-2350

Abstract
The task of identifying synonymous relations and objects, or synonym resolution, is
critical for high-quality information extraction. This paper investigates synonym resolution in the context of unsupervised information extraction, where neither hand-tagged
training examples nor domain knowledge is available. The paper presents a scalable, fullyimplemented system that runs in O(KN log N ) time in the number of extractions, N , and
the maximum number of synonyms per word, K. The system, called Resolver, introduces
a probabilistic relational model for predicting whether two strings are co-referential based
on the similarity of the assertions containing them. On a set of two million assertions
extracted from the Web, Resolver resolves objects with 78% precision and 68% recall,
and resolves relations with 90% precision and 35% recall. Several variations of Resolver’s
probabilistic model are explored, and experiments demonstrate that under appropriate
conditions these variations can improve F1 by 5%. An extension to the basic Resolver
system allows it to handle polysemous names with 97% precision and 95% recall on a data
set from the TREC corpus.

1. Introduction
Web Information Extraction (WIE) systems (Zhu, Nie, Wen, Zhang, & Ma, 2005; Agichtein,
2006; Etzioni, Cafarella, Downey, Kok, Popescu, Shaked, Soderland, Weld, & Yates, 2005)
extract assertions that describe a relation and its arguments from Web text. For example:
(is capital of, D.C., United States)

WIE systems can extract hundreds of millions of assertions containing millions of different strings from the Web (e.g., the TextRunner system by Banko, Cafarella, Soderland,
Broadhead, & Etzioni, 2007). One problem that becomes a real challenge at this scale
is that WIE systems often extract assertions that describe the same real-world object or
relation using different names. For example, a WIE system might also extract
c
2009
AI Access Foundation. All rights reserved.

Yates & Etzioni

(is capital city of, Washington, U.S.)

which describes the same relationship as above but contains a different name for the relation
and each argument.
Synonyms are prevalent in text, and the Web corpus is no exception. Our data set
of two million assertions extracted from a Web crawl contained over a half-dozen different
names each for the United States and Washington, D.C., and three for the is capital of
relation. The top 80 most commonly extracted objects had an average of 2.9 extracted
names per entity, and several had as many as 10 names. The top 100 most commonly
extracted relations had an average of 4.9 synonyms per relation.
We refer to the problem of identifying synonymous object and relation names as synonym
resolution. Previous techniques have focused on one particular aspect of the problem, either
objects or relations. In addition, these techniques often depend on a large set of training
examples, or are tailored to a specific domain by assuming knowledge of the domain’s
schema. Due to the number and diversity of the relations extracted, these techniques are
not feasible for WIE systems. Schemata are not available for the Web, and hand-labeling
training examples for each relation would require a prohibitive manual effort.
In response, we present Resolver, a novel, domain-independent, unsupervised synonym
resolution system that applies to both objects and relations. Resolver clusters synonymous names together using a probabilistic model informed by string similarity and the
similarity of the assertions containing the names. Its similarity metric outperforms those
used by similar systems for cross-document entity coreference (e.g., Mann & Yarowsky,
2003) and paraphrase discovery (Lin & Pantel, 2001; Hasegawa, Sekine, & Grishman, 2004)
on their respective tasks of object and relation synonym resolution. The key questions
answered by Resolver include:
1. Is it possible to effectively cluster strings in a large set of extractions into sets of
synonyms without using domain knowledge, manually labeled training data, or other
external resources that are unavailable in the context of Web Information Extraction?
Experiments below include an empirical demonstration that Resolver can resolve
objects with 78% precision and 68% recall, and relations with 90% precision and 35%
recall.
2. How can we scale synonym resolution to large, high-dimensional data sets? Resolver
provides a scalable clustering algorithm that runs in time O(KN log N ) in the number
of extractions, N , and the maximum number of synonyms per word, K. In theory it
compares well with even fast approximate solutions for clustering large data sets in
large-dimensional spaces, and in practice Resolver has been successfully run on a
set of assertions extracted from over 100 million Web pages.
3. How can we formalize unsupervised synonym resolution, and is there a practical benefit
to doing so? Resolver provides an unsupervised, generative probabilistic model
for predicting whether two object or relation names co-refer, and experiments show
that this significantly outperforms previous metrics for distributional similarity. In
particular, it outperforms a related metric based on mutual information (Lin & Pantel,
2001) by 193% in AUC on object clustering, and by 121% on relation clustering.
256

Unsupervised Methods for Determining Object and Relation Synonyms

4. Is it possible to use the special properties of functions and inverse functions to improve
the precision of a synonym resolution algorithm? The basic version of Resolver’s
probabilistic model for object synonymy is independent of the relation in the extraction. However, it is intuitively clear that certain relations, especially functions
and inverse functions, provide especially strong evidence for and against synonymy.
Several extensions to the Resolver system show that without hurting recall, the
precision of object merging can be improved by 3% using functions.
5. Can Resolver handle polysemous names, which have different meanings in different
contexts? While the basic version of Resolver assumes that every name has a single
meaning, we present an extension to the basic system that is able to automatically
handle polysemous names. On a manually-cleaned data set of polysemous named
entities from the TREC corpus, Resolver achieves a precision of 97.3% and a recall
of 94.7% in detecting proper noun coreference relationships, and is able to outperform
previous work in accuracy while requiring only a large, unannotated corpus as input.
The next section discusses previous work in synonym resolution. Section 3 describes
the problem of synonym resolution formally and introduces notation and terminology that
will be used throughout. Section 4 introduces Resolver’s probabilistic model. Section
5 describes Resolver’s clustering algorithm. Section 6 presents experiments with the
basic Resolver system that compare its performance with the performance of previous
work in synonym resolution. Section 7 describes several extensions to the basic Resolver
system, together with experiments illustrating the gains in precision and recall. Section
8 develops an extension to Resolver that relaxes the assumption that every string has
a single referent, and it compares Resolver experimentally to previous work in crossdocument entity resolution. Finally, Section 9 discusses conclusions and areas for future
work.

2. Previous Work
Synonym resolution encompasses two tasks, finding synonyms for extracted objects and
relations. Synonym resolution for objects is very similar to the task of cross-document
entity resolution (Bagga & Baldwin, 1998), in which the objective is to cluster occurrences
of named entities from multiple documents into coreferential groups. Pedersen and Kulkarni
(Pedersen & Kulkarni, 2007; Kulkarni & Pedersen, 2008) cluster people’s names in Web
documents and in emails using agglomerative clustering and a heuristic similarity function.
Li, Morie, and Roth (2004a, 2004b) use an Expectation-Maximization with a graphical
model and databases of common nicknames, honorifics, titles, etc.to achieve high accuracy
on a cross-document entity resolution task. Mann and Yarowsky (2003) use a combination of
extracted features and term vectors including proper names in context to cluster ambiguous
names on the Web. They use the Cosine Similarity Metric (Salton & McGill, 1983) together
with hierarchical agglomerative clustering. Resolver’s main contribution to this body of
work is that it proposes a new, formal similarity measure that works for both objects and
relations, and it demonstrates both theoretically and empirically that it can scale up to
millions of extractions. The Web People Search Task (WEPS) (Artile, Sekine, & Gonzalo,
2008), part of SemEval 2007, involved 16 systems trying to determine clusters of documents
257

Yates & Etzioni

containing references to the same entity for ambiguous person names like “Kennedy.” In
Section 6, we show that Resolver significantly outperforms the Cosine Similarity Metric
in clustering experiments. Further experiments below (Section 8) show that Resolver is
able to achieve similar, slightly higher performance than Li et al. on their dataset, while
not relying on any resources besides a large corpus.
Coreference resolution systems, like synonym resolution systems, try to merge references
to the same object, and they apply to arbitrary noun phrases rather than just to named
entities. Because of the difficulty of this general problem, most work has considered techniques informed by parsers (e.g., Lappin & Leass, 1994) or training data (e.g., Ng & Cardie,
2002; McCarthy & Lehnert, 1995). Cardie and Wagstaff (1999) use a set of extracted grammatical and semantic features and an ad-hoc clustering algorithm to perform unsupervised
coreference resolution, achieving better performance on the MUC-6 coreference task than a
supervised system. More recently, Haghighi and Klein (2007) use a graphical model combining local salience features and global entity features to perform unsupervised coreference,
achieving an F1 score of 70.1 on MUC-6. Two systems use automatically extracted information to help make coreference resolution decisions, much like Resolver does. Kehler,
Appelt, Taylor, and Simma (2004) use statistics over automatically-determined predicateargument structures to compare contexts between pronouns and their potential antecedents.
They find that adding this information to a system that relies on morpho-syntactic evidence
for pronoun resolution provides little or no benefit. Bean and Riloff (2004) use targeted
extraction patterns to find semantic constraints on the relationship between pronouns and
their antecedents, and show that they can use these to improve an anaphora-resolution
system. Coreference resolution is a more difficult and general task than synonym resolution
for objects since it deals with arbitrary types of noun phrases. However, systems for coreference resolution also have more information available to them in the form of local sequence
and salience information, which is lost in the extraction process, and they do not address
relation synonymy.
Synonym resolution for relations is often called paraphrase discovery or paraphrase acquisition in NLP literature (e.g., Barzilay & Lee, 2003; Sekine, 2005). Previous work in
this area (Barzilay & Lee, 2003; Barzilay & McKeown, 2001; Shinyama & Sekine, 2003;
Pang, Knight, & Marcu, 2003) has looked at the use of parallel, aligned corpora, such as
multiple translations of the same text or multiple news reports of the same story, to find
paraphrases. Brockett and Dolan (2005) have used manually-labeled data to train a supervised model of paraphrases. The PASCAL Recognising Textual Entailment Challenge
(Dagan, Glickman, & Magnini, 2006) proposes the task of recognizing when two sentences
entail one another, given manually labeled training data, and many authors have submitted
responses to this challenge. Resolver avoids the use of labor-intensive resources, and relies
solely on automatically acquired extractions from a large corpus.
Several unsupervised systems for paraphrase discovery have focused on using corpusbased techniques to cluster synonymous relations. Sekine (2005) uses a heuristic similarity
measure to cluster relations. Davidov and Rappoport (2008) use a heuristic clustering
method to find groups of relation patterns that can be used to extract instances. Hasegawa
et al. (2004) automatically extract relationships from a large corpus and cluster relations,
using the Cosine Similarity Metric (Salton & McGill, 1983) and a hierarchical clustering
technique like Resolver’s. The DIRT system (Lin & Pantel, 2001) uses a similarity mea258

Unsupervised Methods for Determining Object and Relation Synonyms

sure based on mutual information statistics to identify relations that are similar to a given
one. Resolver provides a formal probabilistic model for its similarity technique, and it
applies to both objects and relations. Section 4.3 contains a fuller description of the differences between Resolver and DIRT, and Section 6 describes experiments which show
Resolver’s superior performance in precision and recall over clustering using the mutual
information similarity metric employed by DIRT, as well as the Cosine Similarity Metric.
Resolver’s method of determining the similarity between two strings is an example
of a broad class of metrics called distributional similarity metrics (Lee, 1999), but it has
significant advantages over traditional distributional similarity metrics for the synonym
resolution task. All of these metrics are based on the underlying assumption, called the
Distributional Hypothesis, that “Similar objects appear in similar contexts.” (Hindle, 1990)
Previous distributional similarity metrics, however, have been designed for comparing words
based on terms appearing in the same document, rather than extracted properties. This has
two important consequences: first, extracted properties are by nature sparser because they
appear only in a narrow window around words and because they consist of longer strings
(at the very least, pairs of words); second, each extracted shared property provides stronger
evidence for synonymy than an arbitrary word that appears together with each synonym,
because the extraction mechanism is designed to find meaningful relationships. Resolver’s
metric is designed to take advantage of the relational model provided by Web Information
Extraction. Section 4.3 more fully describes the difference between Resolver’s metric
and the Cosine Similarity Metric (Salton & McGill, 1983), an example of a traditional
distributional similarity metric. Experiments in Section 6 demonstrate that Resolver
outperforms the Cosine Similarity Metric.
There are many unsupervised approaches for object resolution in databases, but unlike
our algorithm these approaches depend on a known, fixed, and generally small schema.
Ravikumar and Cohen (2004) present an unsupervised approach to object resolution using Expectation-Maximization on a hierarchical graphical model. Several other recent approaches leverage domain-specific information and heuristics for object resolution. For
example, many (Dong, Halevy, & Madhavan, 2005; Bhattacharya & Getoor, 2005, 2006)
rely on evidence from observing which strings appear as arguments to the same relation
simultaneously (e.g., co-authors of the same publication). While this is useful information
when resolving authors in the citation domain, it is rare to find relations with similar properties in extracted assertions. None of these approaches applies to the problem of resolving
relations. Winkler (1999) provides a survey of this area. Several supervised learning techniques make entity resolution decisions (Kehler, 1997; McCallum & Wellner, 2004; Singla
& Domingos, 2006), but of course these systems depend on the availability of training data,
and even on a significant number of labeled examples per relation of interest.
One promising new approach to clustering in a relational domain is the Multiple Relational Clusterings (MRC) algorithm (Kok & Domingos, 2007). This approach, though
not specific to synonym resolution, can find synonyms in a set of unlabeled, relational extractions without domain-specific heuristics. The approach is quite recent, and so far no
detailed experimental comparison has been conducted.
Resolver’s probabilistic model is partly inspired by the ball-and-urns abstraction of
information extraction presented by Downey, Etzioni, and Soderland (2005) Resolver’s
task and probability model are different from theirs, but many of the same modeling as259

Yates & Etzioni

sumptions (such as the independence of extractions) are made in both cases to simplify the
derivation of the models.
Previous work on Resolver (Yates & Etzioni, 2007) discussed the basic version of
the probabilistic model and initial experimental results. This work expands on the previous work in that it includes a new experimental comparison with an established mutual
information-based similarity metric; a new extension to the basic system (property weighting); full proofs for three claims; and a description of a fast algorithm for calculating the
Extracted Shared Property model.

3. The Formal Synonym Resolution Problem
A synonym resolution system for WIE takes a set of extractions as input and returns a
set of clusters, with each cluster containing synonymous object strings or relation strings.
More precisely, the input is a data set D containing extracted assertions of the form a =
(r, o1 , . . . , on ), where r is a relation string and each oi is an object string representing the
arguments to the relation. Throughout this work, all assertions are assumed to be binary,
so n = 2.
The output of a synonym resolution system is a clustering, or set of clusters, of the
strings in D. Let S be the set of all distinct strings in D. A clustering of S is a set C ⊂ 2S
such that all the clusters in C are distinct, and they cover the whole set:
[
=S
c∈C

∀c1 , c2 ∈ C. c1 ∩ c2 = ∅
Each cluster in the output clustering constitutes the system’s conjecture that all strings
inside the cluster are synonyms, and no string outside that cluster is a synonym of any
string in the cluster.
3.1 The Single-Sense Assumption
The formal representation of synonym resolution described above makes an important simplifying assumption: it is assumed that every string belongs to exactly one cluster. In
language, however, strings often have multiple meanings; i.e., they are polysemous. Polysemous strings cannot be adequately represented using a clustering in which each string
belongs to exactly one cluster. For most of this paper, we will make the single-sense assumption, but Section 8 illustrates an extension to Resolver that does away with this
assumption.
As an example of the representational trouble posed by polysemy, consider the name
“President Roosevelt.” In certain contexts, this name is synonymous with “President
Franklin D. Roosevelt,” and in other contexts it is synonymous with “President Theodore
Roosevelt.” However, “President Franklin D. Roosevelt” is never synonymous with “President Theodore Roosevelt.” There is no clustering of the three names, using the notion of
clustering described above, such that all synonymy relationships are accurately represented.
Others have described alternate kinds of clustering that take polysemy into account. For
example, “soft clustering” allows a string to be assigned to as many different clusters as it
260

Unsupervised Methods for Determining Object and Relation Synonyms

has senses. One variation on this idea is to assign a probability distribution to every string,
describing the prior probability that the string belongs in each cluster (Li & Abe, 1998;
Pereira, Tishby, & Lee, 1993). Both of these representations capture only prior information
about strings. That is, they represent the idea that a particular string can belong to a
cluster, or the probability that it belongs to a cluster, but not whether a particular instance
of the string actually does belong to a cluster. A third type of clustering, the most explicit
representation, stores each instance of a string separately. Each string instance is assigned to
the cluster that is most appropriate for the instance’s context. Word sense disambiguation
systems that assign senses from WordNet (Miller, Beckwith, Fellbaum, Gross, & Miller.,
1990) implicitly use this kind of clustering (e.g., Ide & Veronis, 1998; Sinha & Mihalcea,
2007).
3.2 Subproblems in Synonym Resolution
The synonym resolution problem can be divided into two subproblems: first, how to measure
the similarity, or probability of synonymy, between pairs of strings in S; and second, how
to form clusters such that all of the elements in each cluster have high similarity to one
another, and relatively low similarity to elements in other clusters.
Resolver uses a generative, probabilistic model for finding the similarity between
strings. For strings si and sj , let Ri,j be the random variable for the event that si and
f
t denote the event that R
sj refer to the same entity. Let Ri,j
i,j is true, and Ri,j denote
the event that it is false. Let Dx denote the set of extractions in D which contain string
t |D , D ) for
x. Given D and S, the first subtask of synonym resolution is to find P (Ri,j
si
sj
all pairs si and sj . The second subtask takes S and the probability scores for pairs of
strings from S as input. Its output is a clustering of S. Sections 4 and 5 cover Resolver’s
solutions to each subtask respectively.

4. Models for String Comparisons
Our probabilistic model provides a formal, rigorous method for resolving synonyms in the
absence of training data. It has two sources of evidence: the similarity of the strings
themselves (i.e., edit distance) and the similarity of the assertions they appear in. This
second source of evidence is sometimes referred to as distributional similarity (Hindle, 1990).
Section 4.1 presents a simple model for predicting whether a pair of strings are synonymous based on string similarity. Section 4.2 then presents a model called the Extracted
Shared Property (ESP) Model for predicting whether a pair of strings co-refer based on
their distributional similarity. Section 4.3 compares the ESP model with other methods for
computing distributional similarity to give an intuition for how it behaves. Finally, Sections 4.4 and 4.5 present a method for combining the ESP model and the string similarity
model to come up with an overall prediction for synonymy decisions between two clusters
of strings.
4.1 String Similarity Model
Many objects appear with multiple names that are substrings, acronyms, abbreviations, or
other simple variations of one another. Thus string similarity can be an important source of
261

Yates & Etzioni

evidence for whether two strings co-refer (Cohen, 1998). Resolver’s probabilistic String
Similarity Model (SSM) assumes a similarity function sim(s1 , s2 ): ST RIN G × ST RIN G →
[0, 1]. The model sets the probability of s1 co-referring with s2 to a smoothed version of
the similarity:
α ∗ sim(s1 , s2 ) + 1
t
P (Ri,j
|sim(s1 , s2 )) =
α+β
As α increases, the probability estimate transitions from 1/β (at α = 0) to the value of the
similarity function (for very large α). The particular choice of α and β make little difference
to Resolver’s results, as long as they are chosen such that the resulting probability can
never be one or zero. In the experiments below, α = 20 and β = 5. The Monge-Elkan string
similarity function (Monge & Elkan, 1996) is used for objects, and the Levenshtein string
edit-distance function is used for relations (Cohen, Ravikumar, & Fienberg, 2003).
4.2 The Extracted Shared Property Model
The Extracted Shared Property Model (ESP) outputs the probability that two strings corefer based on the similarity of the extracted assertions in which they appear. For example,
if the extractions (invented, Newton, calculus) and (invented, Leibniz, calculus) both
appeared in the data, then Newton and Leibniz would be judged to have similar contexts in
the extracted data.
More formally, let a pair of strings (r, s) be called a property of an object string o if
there is an assertion (r, o, s) ∈ D or (r, s, o) ∈ D. A pair of strings (s1 , s2 ) is an instance
of a relation string r if there is an assertion (r, s1 , s2 ) ∈ D. Equivalently, the property
p = (r, s) applies to o, and the instance i = (s1 , s2 ) belongs to r. The ESP model outputs
the probability that two strings co-refer based on how many properties (or instances) they
share.
As an example, consider the strings Mars and Red Planet, which appear in our data 659
and 26 times respectively. Out of these extracted assertions, they share four properties. For
example, (lacks, Mars, ozone layer) and (lacks, Red Planet, ozone layer) both appear
as assertions in our data. The ESP model determines the probability that Mars and Red
Planet refer to the same entity after observing k, the number of properties that apply to
both; n1 , the total number of extracted properties for Mars; and n2 , the total number of
extracted properties for Red Planet.
ESP models the extraction of assertions as a generative process, much like the URNS
model (Downey et al., 2005). For each string si , a certain number, Pi , of properties of the
string are written on balls and placed in an urn. Extracting ni assertions that contain si
amounts to selecting a subset of size ni from these labeled balls.1 Properties in the urn are
called potential properties to distinguish them from extracted properties.
To model synonymy decisions, ESP uses a pair of urns, containing Pi and Pj balls
respectively, for the two strings si and sj . Some subset of the Pi balls have the exact same
labels as an equal-sized subset of the Pj balls. Let the size of this subset be Si,j . Crucially,
the ESP model assumes that synonymous strings share as many potential properties as
possible, though only a few of the potential properties will be extracted for both. For non1. Unlike the URNS model, balls are drawn without replacement. The TextRunner data contains only
one mention of any extraction, so drawing without replacement tends to model the data more accurately.

262

Unsupervised Methods for Determining Object and Relation Synonyms

synonymous strings, the set of shared potential properties is a strict subset of the potential
properties of each string. Thus the central modeling choice in the ESP model is: if si and
t ) then the number of shared potential properties (S ) is
sj are synonymous (i.e., Ri,j = Ri,j
i,j
equal to the number of potential properties in the smaller urn (min(Pi , Pj )), and if the two
f
strings are not synonymous (Ri,j = Ri,j
) then the number of shared potential properties is
strictly less than the number of properties in the smaller urn (Si,j < min(Pi , Pj )).
The ESP model makes several simplifying assumptions in order to make probability
predictions. As is suggested by the ball-and-urn abstraction, it assumes that each ball
for a string is equally likely to be selected from its urn. Because of data sparsity, almost
all properties are very rare, so it would be difficult to get a better estimate for the prior
probability of selecting a particular potential property. Second, balls are drawn from one
urn independent of draws from any other urn. And finally, it assumes that without knowing
the value of k, every value of Si,j is equally likely, since we have no better information.
t ). The derivation is
Given these assumptions, we can derive an expression for P (Ri,j
sketched
  below; see Appendix A for a complete derivation. First, note that there are
P i Pj
ni nj total ways of extracting ni and nj assertions for si and sj . Given a particular value
of Si,j , the number of ways in which ni and nj assertions can be extracted such that they
share exactly k is given by
Count(k, ni , nj |Pi , Pj , Si,j ) =

Si,j
k

By our assumptions,

P

r,s≥0

P (k|ni , nj , Pi , Pj , Si,j ) =

Si,j −k
r+s



r+s
r



Pi −Si,j  Pj −Si,j 
ni −(k+r) nj −(k+s)

Count(k, ni , nj |Pi , Pj , Si,j )
 
Pi P j
ni

(1)

(2)

nj

Let Pmin = min(Pi , Pj ). The result below follows from Bayes’ Rule and our assumptions
above:
Proposition 1 If two strings si and sj have Pi and Pj potential properties (or instances),
and they appear in extracted assertions Di and Dj such that |Di | = ni and |Dj | = nj , and
they share k extracted properties (or instances), the probability that si and sj co-refer is:
t
P (Ri,j
|Di , Dj , Pi , Pj ) =

P (k|ni , nj , Pi , Pj , Si,j = Pmin )
X
P (k|ni , nj , Pi , Pj , Si,j )

(3)

Si,j
k≤Si,j ≤Pmin

Substituting equation 2 into equation 3 gives us a complete expression for the probability
we are looking for.
t depends on two hidden parameters, P and P . Since
Note that the probability for Ri,j
i
j
in unsupervised synonym resolution there is no labeled data to estimate these parameters
from, these parameters are tied to the number of times the respective strings si and sj are
extracted: Pi = N × ni . The discussion of experimental methods in Section 6 explains how
the parameter N is set.
Appendix B illustrates a technique for calculating the ESP model efficiently.
263

Yates & Etzioni

4.3 Comparison of ESP with Other Distributional Similarity Metrics
The Discovery of Inference Rules from Text (DIRT) (Lin & Pantel, 2001) system is the
most similar previous work to Resolver in its goals, but DIRT’s similarity metric is very
different from ESP. Like ESP, DIRT operates over triples of extracted strings and produces
similarity scores for relations by comparing the distributions of one relation’s arguments
to another’s. The DIRT system, however, has its own extraction mechanism based on a
dependency parser. Here we focus on the differences in the two systems’ similarity metrics,
and compare performance on the same set of extracted triples produced by TextRunner,
since the extracted triples used by DIRT were not available to us. We refer to the mutualinformation-based similarity metric employed by the DIRT system as sM I . It is important
to note that sM I as we describe it here is our own implementation of the similarity metric
described by Lin and Pantel (2001), and is not the complete DIRT system.
We now briefly describe sM I as it applies to a set of extractions. sM I originally was
applied to only relation strings, and for simplicity we describe it that way here, but it
is readily generalized to a metric for computing the similarity between two argument-1
strings or two argument-2 strings. For notational convenience, let Dx=s be the set of
extractions that contain string s at position x. For example, D2=Einstein would contain
the extraction (discovered, Einstein, Relativity), but not the extraction (talked with,
Bohr, Einstein). Similarly, let Dx=s1 ,y=s2 be the set of extractions that contain s1 and
s2 at positions x and y respectively. Finally, let the projection of a set of extractions
D = {(d1 , d2 , d3 )} onto one of its dimensions x be given by:
projx (D) = {s|∃d1 ,d2 ,d3 .dx = s ∧ (d1 , d2 , d3 ) ∈ D}
sM I uses a mutual information score to determine how much weight to give to each
string in the set of extractions during its similarity computation. For a string s at position
x, the mutual information between it and a relation r at position 1 is given by:


|D1=r,x=s | × |D|
mi1,x (r, s) = log
|D1=r | × |Dx=s |
sM I calculates the similarity between two relations by first calculating the similarity
between the sets of first arguments to the relations, and then the similarity between the
sets of second arguments. Let r1 and r2 be two relations, and let the position of the
argument being compared be x. The similarity function used is:
X
mi1,x (r1 , a) + mi1,x (r2 , a)
simx (r1 , r2 ) =

a∈projx (D1=r1 )∩projx (D1=r2 )

X

mi1,x (r1 , a) +

X

mi1,x (r2 , a)

a∈projx (D1=r2 )

a∈projx (D1=r1 )

The final similarity score for two relations is the geometric average of the similarity scores
for each argument:
p
sM I (r1 , r2 ) = sim2 (r1 , r2 ) × sim3 (r1 , r2 )
(4)
Applying the sM I metric to entities rather than relations simply requires projecting onto
different dimensions of the relevant tuple sets.
264

Unsupervised Methods for Determining Object and Relation Synonyms

The most significant difference between the sM I similarity metric and the ESP model is
that the sM I metric compares the x arguments from one relation to the x arguments of the
other, and then compares the y arguments from one relation to the y arguments of the other,
and finally combines the scores. In contrast, ESP compares the (x, y) argument pairs of one
relation to the (x, y) pairs of the other. While the sM I metric has the advantage that it is
more likely to find matches between two relations in sparse data, it has the disadvantage
that the matches it does find are not necessarily strong evidence for synonymy. In effect, it is
capturing the intuition that synonyms have the same argument types for their domains and
ranges, but it is certainly possible for non-synonyms to have similar domains and ranges.
Antonyms are an obvious example. Synonyms are not defined by their domains and ranges,
but rather by the mapping between them, and ESP better captures the similarity in this
mapping. Experiments below (Section 6) compare the ESP as a similarity metric against
sM I , as given in Equation 4.
As previously mentioned, there is a large body of previous work on similarity metrics
(e.g., Lee, 1999). We now compare ESP with one of the more popular of these metrics,
the Cosine Similarity Metric (CSM), which has previously been used in synonym resolution
work (Mann & Yarowsky, 2003; Hasegawa et al., 2004). Like most traditional distributional
similarity metrics, CSM operates over context vectors, rather than extracted triples. However, the ESP model is very similar to CSM in this regard. For each extracted string, it in
effect creates a binary vector of properties, ones representing properties that apply to the
string and zeros representing those that do not. For example, the string Einstein would
have a context vector with a one in the position for the property (discovered, Relativity),
and a zero in the position for the property (invented, light bulb). Both ESP and CSM
calculate similarities by comparing these vectors.
The specific metric used to compute CSM for two vectors ~x and ~y is given by:
simCSM (~x, ~y ) =
=

~x · ~y
||~x|| × ||~y ||
P
yi
i xiq
qP
P 2
2
i xi ×
i yi

Often, techniques like term weighting or TFIDF (Salton & McGill, 1983) are used with CSM
to create vectors that are not boolean, but rather have dimensions with different weights
according to how informative those dimensions are. We experimented with TFIDF-like
weighting schemes, where the number of times an extraction was extracted is used as the
term frequency, and the number of different strings a property applies to is used as the
document frequency. However, we found that these weighting schemes had negative effects
on performance, so from here on we ignore them. For two boolean vectors, CSM reduces to
a simple computation on the number of shared properties k and the number of extractions
for each string, n1 and n2 respectively. It is given by:
simCSM −boolean (~x, ~y ) = √

k
n1 n2

(5)

CSM determines how similar two context vectors are in each dimension, and then adds
the scores up in a weighted sum. In contrast, ESP is highly non-linear in the number
265

Yates & Etzioni

Similarity

of shared properties. As the number of matching contexts grows, the weight for each
additional matching context also grows. Figure 1 compares the behavior of ESP and CSM
as the number of shared properties between two strings increases. Holding the number of
extractions fixed and assuming boolean vectors for CSM, it behaves as a linear function
of the number of shared properties. On the other hand, the ESP has the shape of a
thresholding function: it has a very low value until a threshold point around k = 10, at
which point its probability estimate starts increasing rapidly. The effect is that ESP has
much lower similarity scores than CSM for small numbers of matching contexts, and much
higher scores for larger numbers of matching contexts. The threshold at which it switches
depends on n1 and n2 , as well as P1 and P2 , but we can show experimentally that our
method for estimating P1 and P2 , though simple, can be effective. Experiments in Section
6 compare the ESP model with CSM, as computed using Equation 5.

CSM
ESP

0

5

10

15

20

Number of shared properties

Figure 1: The behavior of the Extracted Shared Property (ESP) model and the Cosine
Similarity Model (CSM) as the number of shared properties between two
strings varies. The graph shows similarity results using two hypothetical strings with
20 extracted properties each. For ESP, the property multiple is N = 2. We removed
scale from the y axis, since the scales for the two metrics are not directly comparable,
but the shape of the curves remains the same.

4.4 Combining the Evidence
For each potential synonymy relationship, Resolver considers two pieces of probabilistic
e be the evidence for ESP, and let E s be the evidence for SSM. Our
evidence. Let Ei,j
i,j
method for combining the two uses the Naı̈ve Bayes assumption that each piece of evidence
266

Unsupervised Methods for Determining Object and Relation Synonyms

is conditionally independent, given the synonymy relationship:
s
e
s
e
P (Ei,j
, Ei,j
|Ri,j ) = P (Ei,j
|Ri,j )P (Ei,j
|Ri,j )

(6)

Given this simplifying assumption, we can combine the evidence to find the probability
of a coreference relationship by applying Bayes’ Rule to both sides (we omit the i, j indices
for brevity):
P (Rt |E s )P (Rt |E e )(1 − P (Rt ))
(7)
P (Rt |E s , E e ) = P
i
s
i
e
i
i∈{t,f } P (R |E )P (R |E )(1 − P (R ))
4.5 Comparing Clusters of Strings

Our algorithm merges clusters of strings with one another, using the above models. However,
these models give probabilities for synonymy decisions between two individual strings, not
two clusters of strings.
We have experimented with several different methods of determining the probability of
synonymy from the individual probability scores for each pair of strings, one taken from each
cluster. Initially, we followed the work of Snow, Jurafsky, and Ng (2006) in incorporating
transitive closure constraints in probabilistic modeling, and we made the same independence
assumptions. This approach provides a formal probabilistic framework for the problem that
is simple and efficient to calculate. In other experiments, we found that simply taking the
mean or geometric mean (or even the harmonic mean) of the string pair scores provided
slightly improved results. For completeness, we now provide a brief explanation of the
probabilistic method for combining string pair scores into cluster pair scores.
Let a clustering be a set of synonymy relationships between pairs of strings such that
the synonymy relationships obey the transitive closure property. We let the probability of
a set of assertions D given a clustering C be:
P (D|C) =

Y

t ∈C
Ri,j

t
P (Di ∪ Dj |Ri,j
)×

Y

f
Ri,j
∈C

f
)
P (Di ∪ Dj |Ri,j

(8)

The metric used to determine if two clusters should be merged is the likelihood ratio, or
the probability for the set of assertions given the merged clusters over the probability given
the original clustering. Let C 0 be a clustering that differs from C only in that two clusters
in C have been merged in C 0 , and let ∆C be the set of synonymy relationships in C 0 that
are true, but the corresponding ones in C are false. This metric is given by:
0

Q

t ∈∆C
Ri,j

P (D|C )/P (D|C) = Q

t |D ∪ D )(1 − P (Rt ))
P (Ri,j
i
j
i,j

t ∈∆C (1
Ri,j

t |D ∪ D ))P (Rt )
− P (Ri,j
i
j
i,j

(9)

t |D ∪ D ) may be supplied by SSM, ESP, or the combination
The probability P (Ri,j
i
j
model. In our experiments, we let the prior for the SSM model be 0.5. For the ESP and
1
t )=
combined models, we set the prior to P (Ri,j
min(Pi ,Pj ) , where Pi and Pj are the number
of potential properties for si and sj respectively.

267

Yates & Etzioni

5. Resolver’s Clustering Algorithm
Synonym resolution for the Web requires a clustering algorithm that can scale to a huge
number of strings in a sparse, high-dimensional space. Those requirements are difficult for
any clustering algorithm. On the other hand, very few words have more than a handful of
synonyms, so clusters tend to be quite small. Greedy agglomerative approaches are wellsuited to this type of clustering problem, since they start with the smallest possible clusters
and merge them as needed.
The Resolver clustering algorithm is a version of greedy agglomerative clustering,
with a key modification that allows it to scale to sparse, high-dimensional spaces and huge
numbers of elements. A standard greedy clustering algorithm begins by comparing each pair
of data points, and then greedily merges the closest pair. The biggest hurdle to scaling such
an algorithm is that the initial step of comparing every pair of data points requires O(N 2 )
comparisons for N points. Several proposed techniques have been able to speed up this
process in practice by filtering out some of the initial pairs of points to be compared; we build
on this work to provide a novel technique with a new bound of O(N log N ) comparisons,
under very mild assumptions.
Our algorithm is outlined in Figure 2. It begins by calculating similarity scores between
pairs of strings, in steps 1-4. Then the scores are sorted and the best cluster pairs are merged
until no pair of clusters has a score above threshold. The novel part of the algorithm, step
4, compares pairs of clusters that share the same property, as long as no more than M ax
clusters share that same property. This step limits the number of comparisons made between
clusters, and it is the reason for the algorithm’s improved efficiency, as explained below.
This algorithm compares every pair of clusters that have the potential to be merged,
assuming two properties of the data. First, it assumes that pairs of clusters with no shared
properties are not worth comparing. Since the number of shared properties is a key source
of evidence for our approach, these clusters almost certainly will not be merged, even if
they are compared, so the assumption is quite reasonable. Second, the approach assumes
that clusters sharing only properties that apply to very many strings (at least M ax) need
not be compared. Since properties shared by many strings provide little evidence that the
strings are synonymous, this assumption is reasonable for synonym resolution.
We use M ax = 50 in our experiments. Less than 0.1% of the distinct properties are
thrown out using this cutoff, but because these discarded properties apply to many strings
(at least M ax), and because the number of comparisons grows with the square of the
number of strings that a property applies to, the restriction drastically cuts down on the
total number of comparisons made. Table 1 shows the number of comparisons made by the
naı̈ve method of comparing all pairs of strings in a set of over 2 million extractions, and
the number of comparisons that Resolver makes in these experiments. Our algorithm
achieves a reduction by a factor of 136 for objects and 486 for relations in the number of
comparisons made. An unoptimized implementation of Resolver is able to cluster the
strings in these extractions in approximately 30 minutes. Resolver was also run on a
larger set containing over 100 million extractions and over 1 million distinct strings, and
was able to cluster these in approximately 3.5 days on a single machine.
268

Unsupervised Methods for Determining Object and Relation Synonyms

E := {e = (r, a, b)|(r, a, b) is an extracted assertion}
S := {s|s appears as a relation or argument string in E}
Cluster := {}
Elements := {}
1. For each s ∈ S:
Cluster[s] := new cluster id
Elements[Cluster[s]] := {s}
2. Scores := {}, Index := {}
3. For each e = (r, a, b) ∈ E:
property := (a, b)
Index[property] := Index[property] ∪ {Cluster[r]}
property := (r, a)
Index[property] := Index[property] ∪ {Cluster[b]}
property := (r, b)
Index[property] := Index[property] ∪ {Cluster[a]}
4. For each property p ∈ Index:
If |Index[p]| < Max:
For each pair {c1 , c2 } ⊂ Index[p]:
Scores[{c1 , c2 }] := similarity(c1 , c2 )
5. Repeat until no merges can be performed:
Sort Scores
U sedClusters := {}
Repeat until Scores is empty or top score < T hreshold:
{c1 , c2 } := removeT opP air(Scores)
If neither c1 nor c2 is in U sedClusters:
Elements[c1 ] := Elements[c1 ] ∪ Elements[c2 ]
For each e ∈ Elements[c2 ]:
Cluster[e] := c1
delete c2 from Elements
U sedClusters := U sedClusters ∪ {c1 , c2 }
Repeat steps 2-4 to recalculate Scores
Figure 2: Resolver’s Clustering Algorithm
5.1 Algorithm Analysis
Let D be the set of extracted assertions. The following analysis2 shows that one iteration
of merges takes time O(|D| log |D|). Let N C be the number of comparisons between strings
in step 4. To simplify the analysis, we consider only those properties that contain a relation
string and an argument 1 string. Let P roperties be the set of all such properties that
apply to fewer than M ax strings, and let Stringsp be the set of all strings that a particular
2. If the M ax parameter is allowed to vary with log |D|, rather than remaining constant, the same analysis
leads to a slightly looser bound that is still better than O(|D|2 ).

269

Yates & Etzioni

Num. Strings

Compare All

Resolver

Speedup

9,797
10,151

47,985,706
51,516,325

352,177
105,915

136x
486x

Objects
Relations

Table 1: Resolver’s clustering algorithm cuts down on the number of comparisons made
between pairs of strings when clustering a data set of 2.1 million TextRunner
extractions. “Compare All” lists the number of comparisons that would be
made if every string were compared to every other one. Resolver reduces comparisons between object strings by a factor of 136 compared to this baseline,
and comparisons between relations strings by a factor of 486.

property p applies to. The number of comparisons is given by the size of the union of
the set of comparisons made for each property, which is upper-bounded by the sum of the
maximum number of comparisons made for each property:




[



{pair = {s1 , s2 }|pair ⊂ Stringsp }
NC = 

p∈P roperties
X
≤
|{pair = {s1 , s2 }|pair ⊂ Stringsp }|
p∈P roperties

X

=

p∈P roperties

|Stringsp | × (|Stringsp | − 1)
2

Since each Stringsp contains at most M ax elements, we can upper-bound this expression
by
NC ≤

X

p∈P roperties

|Stringsp | × (M ax − 1)
2

=

(M ax − 1)
×
2

≤

(M ax − 1)
× |D|
2

X

p∈P roperties

|Stringsp |

P
The last step bounds p |Stringsp | with |D|, since the number
P of extractions is equal to
the number of times that each property is extracted. Since p |Stringsp | is summing only
over properties that apply to fewer than M ax strings, |D| may be greater than this sum.
Overall, the analysis shows that N C is linear in |D|. Note that in general this bound is
quite loose because most properties apply to only a small number of strings, far fewer than
M ax.
Step 5 requires time O(|D| log |D|) to sort the comparison scores and perform one iteration of merges. If the largest cluster has size K, in the worst case the algorithm will take
270

Unsupervised Methods for Determining Object and Relation Synonyms

K iterations (and in the best case it will take log K). In our experiments, the algorithm
never took more than 9 iterations.
The analysis thus far has related the computational complexity to |D|, the size of the
input data set of extractions. Most existing techniques, however, have been analyzed in
terms of |S|, the number of distinct strings to be clustered. In order to relate the two
kinds of analysis, we observe that linguistic data naturally obeys a Zipf distribution for the
frequency of its distinct strings. That is, the most common
 string appears many times in the
1 z
extractions; the next-most common appears roughly
times as often for some parameter
2

1 z
z; the next most common appears roughly 3 times as often; and so on. The parameter z is
known as the Zipf parameter, and for naturally-occurring text it has typically been observed
to be around 1 (Zipf, 1932; Manning & Schuetze, 1999). If we can characterize the Zipf
distribution for the input data set of extractions, we can rewrite
P the number of extractions
|D| in terms of the number of distinct strings |S|, since |D| = s∈S frequency(s). Following
this line of thought to its conclusion, we find that when z < 1, as it is for our data set,
|D| grows linearly with |S|, and a complexity of O(|D| log |D|) is equivalent to a complexity
of O(|S| log |S|). When z = 1, O(|D| log |D|) is equivalent to a bound of O(|S| log2 |S|).
And when z > 1, the bound is O(|S|z log |S|). Not until z = 2 is the asymptotic bound of
O(|S|2 log |S|) worse than the O(|S|2 ) bound for comparing all string pairs, and such a high
value of z is highly unlikely for naturally occurring text. For more details and a complete
analysis, see Appendix C.
5.2 Relation to Other Speed-Up Techniques
McCallum, Nigam, and Ungar (2000) proposed a widely-used technique for pre-processing
a data set to reduce the number of comparisons made during clustering. They use a cheap
comparison metric to place objects into overlapping “canopies,” and then use a more expensive metric to cluster objects appearing in the same canopy. The Resolver clustering
algorithm is in fact an adaptation of the canopy method: like the Canopies method, it
uses an index to eliminate many of the comparisons that would otherwise need to be made.
Our method adds the restriction that strings are not compared when they share only highfrequency properties. The Canopy method works well on high-dimensional data with many
clusters, which is the case with our problem. Our contribution has been to observe that if
we restrict comparisons in a novel and well-justified way, we can obtain a new theoretical
bound on the complexity of clustering text data.
The merge/purge algorithm (Hernandez & Stolfo, 1995) assumes the existence of a
particular attribute such that when the data set is sorted on this attribute, matching pairs
will all appear within a narrow window of one another. This algorithm is O(M log M ) where
M is the number of distinct strings. However, there is no attribute or set of attributes that
comes close to satisfying this assumption in the context of domain-independent information
extraction.
Resolver’s clustering task can in part be reduced to a task of nearest-neighbor search,
for which several recent systems have developed fast new algorithms. The reduction works
as follows: the nearest-neighbor retrieval techniques can be used to find the most similar
string for every distinct string in the corpus, and then Resolver’s merge criteria can decide
which of these M pairs to actually merge. Several of the fastest nearest-neighbor techniques
271

Yates & Etzioni

perform approximate nearest-neighbor search: given an error tolerance , such techniques
will return a neighbor for a query node q that is at most 1 +  times as far from q as the
true nearest neighbor of q.
Examples of nearest-neighbor techniques can be divided into those that use hash-based
or tree-based indexing schemes. Locality-Sensitive Hashing uses a combination of hashing
1
functions to retrieve approximate nearest neighbors in time O(n 1+ ) for error tolerance .
So if for a given query point q we are willing to accept neighbors that are at a distance of
at most twice the distance of its true nearest neighbor ( = 2), then the running time will
√
1
be O(n 2 ) = O( n) to find a single nearest neighbor (Gionis, Indyk, & Motwani, 1999).
More recently, tree-based index structures such as metric cover trees (Beygelzimer, Kakade,
& Langford, 2006) and hybrid spill trees (Liu, Moore, Gray, & Yang, 2004), have offered
competitive or even better performance than Locality-Sensitive Hashing. The tree-based
algorithms have a complexity of O(d log n), where d is the dimensionality of the space, to find
a single nearest neighbor. Metric trees offer exact nearest-neighbor search, and spill trees
offer faster search in practice at the cost of finding approximate solutions and using more
space for their index. These indexing schemes are powerful tools for nearest-neighbor search,
but their dependence on the dimensionality of the space makes it costly to apply them in our
case. Resolver operates in a space of hundreds of thousands of dimensions (the number
of distinct extract properties), while the fastest of these techniques have been applied to
spaces of around a few thousand dimensions (Liu et al., 2004). Resolver determines the
exact nearest neighbor, and in fact the exact distance between all relevant pairs of points
under the mild assumptions stated above, while operating in a huge-dimensional space.

5.3 Resolver Implementation
Resolver currently exists as a Java package containing 23,338 lines of code. It has separate
modules for calculating the Extracted Shared Property Model and the String Similarity
Model, as well as for clustering extractions. The basic version of the system accepts a file
containing tuples of strings as input, one tuple per line. Optionally, it accepts manually
labeled clusters as input as well, and will use those to output precision and recall scores. The
output of the system is two files containing all object clusters and relation clusters of size
two or more, respectively. Optionally, the system also outputs precision and recall scores.
Several other options allow the user to run extensions to the basic Resolver system, which
are discussed below in Section 7.
Resolver is currently a part of the TextRunner demonstration system. The demonstration system is available for keyword searches over the Web at
http://www.cs.washington.edu/research/textrunner/. This demonstration system contains
extractions from several hundred million Web documents. The extractions were fed into
Resolver and the resulting clusters were added to the TextRunner index so that keyword searches return results for any member of the cluster containing the keyword being
searched for, and the displayed results are condensed such that members of the same cluster
are not repeated.
272

Unsupervised Methods for Determining Object and Relation Synonyms

6. Experiments
Several experiments below test Resolver and ESP, and demonstrate their improvement
over related techniques in paraphrase discovery, sM I (Lin & Pantel, 2001) and the Cosine
Similarity Metric (CSM) (Salton & McGill, 1983; Hasegawa et al., 2004; Mann & Yarowsky,
2003). The first experiment compares the performance of the various similarity metrics,
and shows that Resolver’s output clusters are significantly better than ESP’s or SSM’s,
and that ESP’s clusters are in turn significantly better than sM I ’s or CSM’s. The second
experiment measures the sensitivity of the ESP model to its hidden parameter, and shows
that for a very wide range of parameter settings, it is able to outperform both the sM I and
CSM models.
6.1 Experimental Setup
The models are tested on a data set of 2.1 million assertions extracted from a Web crawl.
All models run over all assertions, but compare only those objects or relations that appear
at least 25 times in the data, to give the distributional similarity models sufficient data for
estimating similarity. Although this restriction limits the applicability of Resolver, we
note that it is intuitive that this should be necessary for unsupervised clustering, since such
systems by definition start with no knowledge about a string. They must see some number of
examples before it is reasonable to expect them to make decisions about them. We also note
that Downey, Schoenmackers, and Etzioni (2007) have shown for a different problem how
bootstrapping techniques can leverage performance on high-frequency examples to build
accurate models for low-frequency items.
Only proper nouns3 are compared, and only those relation strings that contain no punctuation or capital letters are compared. This helps to restrict the experiment to strings
that are less prone to extraction errors. However, the models do use the other strings as
features. In all, the data contains 9,797 distinct proper object strings and 10,151 distinct
proper relation strings that appear at least 25 times. We created a gold standard data set
by manually clustering a subset of 6,000 object and 2,000 relation strings. In total, our gold
standard data sets contains 318 true object clusters and 330 true relation clusters with at
least 2 elements each.
As noted previously (Section 3.1), polysemous strings pose a particular representational
trouble for creating a gold standard data set, since there is no correct clustering that captures all of the synonymy relationships for polysemous strings, in general. We adopted the
following data-oriented strategy: polysemous strings were not clustered with other strings
unless there was a match for every sense of the strings that appeared in the data. For
example, there have been two U.S. Presidents named “Roosevelt”: Theodore Roosevelt and
Franklin Delano Roosevelt. After applying the criterion above, the gold standard data contained a cluster for FDR and President Franklin Roosevelt, since both referred to Franklin
Delano Roosevelt unambiguously in this dataset. Likewise, President Theodore Roosevelt
and Teddy Roosevelt were put into their own cluster. The terms Roosevelt and President
Roosevelt, however, were used in various places to refer to both men, and so they could not
3. The following heuristic was used to detect proper nouns: if the string consisted of only alphabetic
characters, whitespace, and periods, and if the first character of every word is capitalized, it is considered
a proper noun. Otherwise, it is not.

273

Yates & Etzioni

be clustered with either the Franklin Roosevelt cluster or the Theodore Roosevelt cluster.
Since they had the same set of senses in the data, the gold standard contained a separate
cluster containing just these two strings. Section 8.2 describes an extension to Resolver
that handles polysemous names. Our criterion for polysemy prevented 480 potential merges
in our gold standard data set between object clusters that might be synonymous. The prevented merges usually affected acronyms, first names, and words like “Agency” that might
refer to a number of institutions, and they represent less than 10% of the strings in the gold
standard object data set.
In addition to a gold standard data set for evaluation, we manually created a data
set of development data containing 5 correct pairs of objects, 5 correct pairs of relations,
and also 5 examples of incorrect pairs for each. These 20 examples were not used in the
evaluation data. The development data was used to estimate a value for the ESP model’s
hidden parameter N , called its property multiple (see Section 4.2). We used a simple hillclimbing search procedure to find a value for N separately for objects and relations, and
found that N = 30 worked best for objects on development data, and N = 500 for relations.
Although the amount of data required to set this parameter effectively is very small, it is
nevertheless an important topic for future work to come up with a method that will estimate
this parameter in a completely unsupervised manner in order to fully automate Resolver.
For our comparisons, we calculated the Cosine Similarity Metric (CSM) using the technique described in Section 4.3 and Equation 5, and the sM I metric as defined in Equation
4.
6.2 Clustering Analysis
Our first experiment compares the precision and recall of clusterings output by five similarity
metrics: two kinds of previous work used in paraphrase discovery, CSM and sM I ; two
components of Resolver, ESP and SSM; and the full Resolver system.
The precision and recall of a clustering is measured as follows: hypothesis clusters are
matched with gold clusters such that each hypothesis cluster matches no more than one
gold cluster, and vice versa. This mapping is computed so that the number of elements in
hypothesis clusters that intersect with elements in the matching gold clusters is maximized.
All such intersecting elements are marked correct. Any elements in a hypothesis cluster
that do not intersect with the corresponding gold cluster are marked incorrect, or irrelevant
if they do not appear in the gold clustering at all. Likewise, gold cluster elements are
marked as found if the matching hypothesis cluster contains the same element, or not found
otherwise. The precision is defined as the number of correct hypothesis elements in clusters
containing at least two relevant (correct or incorrect) elements, divided by the total number
of relevant hypothesis elements in clusters containing at least two relevant items. The recall
is defined as the number of found gold elements in gold clusters of size at least two, divided
by the total number of gold elements in clusters of size at least two. We consider only
clusters of size two or more in order to focus on the interesting cases.
Each model requires a threshold parameter to determine which scores are suitable for
merging. For these experiments we arbitrarily chose a threshold of 3 for the ESP model
(that is, the data needs to be 3 times more likely given the merged cluster than the unmerged
clusters in order to perform the merge) and chose thresholds for the other models by hand
274

Unsupervised Methods for Determining Object and Relation Synonyms

Objects
Model
CSM
sM I
ESP
SSM
Resolver

Prec.
0.51
0.52
0.56
0.62
0.71

Rec.
0.36
0.38
0.41
0.53
0.66

Relations
F1
0.42
0.44
0.47
0.57
0.68

Prec.
0.62
0.61
0.79
0.85
0.90

Rec.
0.29
0.28
0.33
0.25
0.35

F1
0.40
0.38
0.47
0.39
0.50

Table 2: Comparison of the cosine similarity metric (CSM), sM I , Resolver components
(SSM and ESP), and the Resolver system. Bold indicates the score is significantly
different from the score in the row above at p < 0.05 using the chi-squared test with one
degree of freedom. Using the same test, Resolver is also significantly different from ESP,
sM I , and CSM in recall on objects, and from sM I , CSM and SSM in recall on relations.
Resolver’s F1 on objects is a 19% increase over SSM’s F1. Resolver’s F1 on relations
is a 28% increase over SSM’s F1. No significance tests were performed on the F1 values.

so that the difference between them and ESP would be roughly even between precision and
recall, although for relations it was harder to improve the recall. Table 2 shows the precision
and recall of our models.
6.3 Sensitivity Analysis
The ESP model requires a parameter for the number of potential properties of a string, but
the performance of ESP is not strongly sensitive to the exact value of this parameter. As
described in Section 4.2, we assume that the number of potential properties is a multiple
N of the number of extractions for a string. In the above experiments, we chose values of
N = 30 for objects and N = 500 for relations, since they worked well on held-out data.
However, as Tables 3 and 4 show, the actual values of these parameters may vary in a large
range, while still enabling ESP to outperform sM I and CSM.
In these experiments, we measured precision and recall for just the similarity metrics,
without performing any clustering. We used the similarity metrics to sort the pairs of strings
(but only those pairs that share at least some property) in descending order of similarity.
We then place a threshold T on the similarity, and measure precision as the number of
correct synonym pairs with similarity greater than T divided by the total number of pairs
with similarity greater than T . We measure recall by the number of correct synonym pairs
with similarity greater than T divided by the total number of correct synonym pairs. By
varying T , we can create a precision-recall curve and measure the area underneath the
curve.
These tables highlight two significant results. First, for both objects and relations the
ESP model outperforms CSM and sM I by a large amount for parameter settings that vary
by close to a factor of two in either direction from the value we determined on development
data. Thus although we required a small amount of data to determine a value for this
parameter, the performance of ESP is not overly sensitive to the exact value. Second, the
275

Yates & Etzioni

Metric

AUC

Fraction of Max. AUC

Improvement over Baseline

CSM
sM I
ESP-10
ESP-30
ESP-50
ESP-90
SSM
Resolver

0.0061
0.0083
0.019
0.024
0.022
0.018
0.18
0.22

0.011
0.014
0.033
0.041
0.037
0.031
0.31
0.38

-21%
0%
136%
193%
164%
121%
0%
23%

Table 3: Area Under the precision-recall Curve (AUC) for object synonymy. The ESP
model significantly outperforms sM I and CSM in AUC for a wide range of parameter settings. Likewise, Resolver significantly outperforms SSM in AUC.
The maximum possible AUC is less than one because many correct string pairs share no
properties, and are therefore not compared by the clustering algorithm. The third column
shows the score as a fraction of the maximum possible area under the curve, which for
objects is 0.57. The improvement over baseline column shows how much the ESP curves
improve over sM I , and how much Resolver improves over SSM.

Metric

AUC

Fraction of Max. AUC

Improvement over Baseline

CSM
sM I
ESP-50
ESP-250
ESP-500
ESP-900
SSM
Resolver

0.0035
0.0044
0.0048
0.0087
0.0096
0.010
0.022
0.029

0.034
0.042
0.046
0.083
0.093
0.098
0.24
0.31

-19%
0%
9.5%
98%
121%
133%
0%
31%

Table 4: Area Under the precision-recall Curve (AUC) for relation synonymy. The
ESP model significantly outperforms sM I and CSM in AUC for a wide range
of parameter settings. Likewise, Resolver significantly outperforms SSM in
AUC. The maximum possible area is less than one because many correct string pairs
share no properties, and are therefore not compared by the clustering algorithm. The
third column shows the score as a fraction of the maximum possible area under the curve,
which for relations is 0.094. The improvement over baseline shows how much the ESP
curves improve over sM I , and how much Resolver improves over SSM.

276

Unsupervised Methods for Determining Object and Relation Synonyms

ESP model clearly provides a significant boost to the performance of the SSM model, as
Resolver’s performance significantly improves over SSM’s.
6.4 Discussion
In all experiments, ESP outperforms both CSM and sM I . The sensitivity analysis shows
that this remains true for a wide range of hidden parameters for ESP, for both objects and
relations. Moreover, ESP’s improvement over the comparison metrics holds true when the
metrics are used in clustering the data. sM I ’s performance is largely the same as CSM in
every experiment. Somewhat surprisingly, sM I performs worse on relation clustering than
on object clustering, even though it is designed for relation similarity.
The results show that the three distributional similarity models perform below the SSM
model on its own for both objects and relations, both in the similarity experiments and
the clustering experiments. The one exception is in the clustering experiment for relations,
where SSM had a poor recall, and thus had lower F1 score than ESP and CSM. This is to
be expected, since ESP, sM I , and CSM make predictions based on a very noisy signal. For
example, Canada shares more properties with United States in our data than U.S. does,
even though Canada appears less often than U.S. Importantly, though, there is a significant
improvement in both precision and recall when using a combined model over using SSM
alone. Resolver’s F1 is 19% higher than SSM’s on objects, and 28% higher on relations
in the clustering experiments.
Interestingly, the distributional similarity metrics (ESP, sM I , and CSM) perform significantly worse in the task of ranking string pairs than in the clustering task. One reason
is that the task of ranking string pairs does not measure performance when comparing a
cluster of two strings against a cluster of two other strings. In a greedy clustering process
such as the one used by Resolver, large groups of correct clusters can be formed as long
as the similarity metrics rank some correct pair of strings near the top, and are able to
improve their estimates of similarity when comparing clusters. This issue requires further
investigation.
There is clearly room for improvement on the synonym resolution task. Error analysis
shows that most of Resolver’s mistakes are due to three kinds of errors:
1. Extraction errors. For example, US News gets extracted separately from World Report,
and then Resolver clusters them together because they share almost all of the same
properties.
2. Similarity vs. Identity. For example, Larry Page and Sergey Brin get merged, as do
Angelina Jolie and Brad Pitt, and Asia and Africa.
3. Multiple word senses. For example, there are two President Bushes; also, there are
many terms like President and Army that can refer to multiple distinct entities.
Extraction systems are improving their accuracy over time, and we do not further address
these errors. The next two sections develop techniques to address the second and third of
these kinds of errors, respectively.
277

Yates & Etzioni

7. Similar and Identical Pairs
As the error analysis above suggests, similar objects that are not exact synonyms make up
a large fraction of Resolver’s errors. This section describes three techniques for dealing
with such errors.
For example, Resolver is likely to make a mistake with the pair Virginia and West
Virginia. They share many properties because they have the same type (U.S. states), and
they have high string similarity. Perhaps the easiest approach for determining that these
two are not synonymous is simply to collect more data about them. While they are highly
similar, they will certainly not share all of their properties; they have different governors, for
example. However, for highly similar pairs such as these two, the amount of data required
to decide that they are not identical may be huge, and simply unavailable.
Fortunately, there are more sophisticated techniques for making decisions with the available data. One approach is to consider the distribution of words that occur between candidate synonyms. Similar words are likely to be separated by conjunctions (e.g., “Virginia
and West Virginia”) and domain-specific relations that hold between two objects of the
same type (e.g., “Virginia is larger than West Virginia”). On the other hand, synonyms
are more likely to be separated by highly specialized phrases such as “a.k.a.” Section 7.1
describes a method for using this information to distinguish between similar and identical
pairs.
A second approach is to consider how candidate synonyms behave in the context of
relations with special distributions, like functions or inverse functions. For example, the
“x is capital of y” relation is an inverse function: every y argument has at most one x
argument4 . If capitals are extracted for both West Virginia and Virginia, then they may
be ruled out as a synonymous pair when the capitals are seen to be different. On the other
hand, if Virginia and VA share the same capital, that is much stronger evidence that the two
are the same than if they shared some other random property, such as that a town called
Springfield is located there. Section 7.2 describes a method for eliminating similar pairs
because they have different values for the same function or inverse function, and Section
7.3 illustrates a technique for assigning different weights to different evidence based on how
close to functional the property is. Section 7.4 gives results for each of these techniques.
7.1 Web Hitcounts for Synonym Discovery
While names for two similar objects may often appear together in the same sentence, it is
relatively rare for two different names of the same object to appear in the same sentence.
Moreover, synonymous pairs tend to appear in idiosyncratic contexts that are quite different
from the contexts seen between similar pairs. Resolver exploits this fact by querying the
Web to determine how often a pair of strings appears together in certain contexts in a large
corpus. When the hitcount is high, Resolver can prevent the merge.
Specifically, given a candidate synonym pair s1 and s2 , the Coordination-Phrase Filter
uses a discriminator phrase (Etzioni et al., 2005) of the form “s1 and s2 ”. It then computes
4. It is also a function.

278

Unsupervised Methods for Determining Object and Relation Synonyms

a variant of pointwise mutual information, given by
coordination score(s1 , s2 ) =

hits(s1 and s2 )2
hits(s1 ) × hits(s2 )

The filter removes from consideration any candidate pair for which the coordination score
is above a threshold, which is determined on a small development set. The results of
coordination-phrase filtering are presented below.
The Coordination-Phrase Filter uses just one possible context between candidate synonym pairs. A simple extension is to use multiple discriminator phrases that include common context phrases like “or” and “unlike.” A more complex approach could measure
the distribution of words found between a candidate pair, and compare that distribution
with the distributions found between known similar or known identical pairs. These are
important avenues for further investigation.
One drawback of this approach is that it requires text containing a pair of objects in
close proximity. For a pair of rare strings, such data will be extremely unlikely to occur —
this type of test exacerbates the data sparsity problem. The following two sections describe
two techniques that do not suffer from this particular problem.
7.2 Function Filtering
Functions and inverse functions can help to distinguish between similar and identical pairs.
For example, Virginia and West Virginia have different capitals: respectively, Richmond
and Charleston. If both of these facts are extracted, and if Resolver knows that the
capital of relation is an inverse function, it ought to prevent Virginia and West Virginia
from merging.
Given a candidate synonym pair x1 and x2 , the Function Filter prevents merges between
strings that have different values for the same function. More precisely, it decides that two
strings y1 and y2 match if their string similarity is above a high threshold. It prevents a
merge between x1 and x2 if there exists a function f and extractions f (x1 , y1 ) and f (x2 , y2 ),
and there are no such extractions such that y1 and y2 match (and vice versa for inverse
functions). Experiments described in Section 7.4 show that the Function Filter can improve
the precision of Resolver without significantly affecting its recall.
The Function Filter requires knowledge about which relations are actually functions or
inverse functions. Others have investigated techniques for determining such properties of
relations automatically (Popescu, 2007); in the experiments, a pre-defined list of functions
is used. Table 5 lists the set of functions used in the experiments for the Function Filter.
These functions were selected by manually inspecting a set of 500 common relations from
TextRunner’s extractions, and selecting those that were reliably functional. Only a few
met the criteria, partly because of polysemy in the data, and partly because of extraction
noise.
7.3 Function Weighting
While the Function Filter uses functions and inverse functions as negative evidence, it
is also possible to use them as positive evidence. For example, the relation married is
not strictly one-to-one, but for most people the set of spouses is very small. If a pair of
279

Yates & Etzioni

is capital of
named after
headquartered in
was born in

is capital city of
was named after
is headquartered in
was born on

Table 5: The set of functions used by the Function Filter.

strings are extracted with the same spouse—e.g., FDR and President Roosevelt share the
property (married, Eleanor Roosevelt)—this is far stronger evidence that the two strings
are identical than if they shared some random property, such as (spoke to, reporters).
There are several possibilities for incorporating this insight into Resolver. First, any
such technique will need some method for estimating the “function-ness” of a property, or
how close the property is to being functional. We define the degree of a relation to be the
number of y values that are expected to hold true for a given x value. We call a property
high-degree if it is expected to apply to many strings (highly non-functional), and low-degree
if it is expected to apply to few strings (close to functional).
The degree of a property may be estimated from the relation involved in the property
and the set of extractions for that relation, or it may be based on how many objects
the property applies to. For example, if there are 100 unique extractions for the married
relation, and there are 80 unique x argument strings in those 100 extractions, then on
average each x string participates in 100/80 = 1.25 married relations. One method might
assign every property containing the married relation this statistic as the degree. On the
other hand, suppose there are two extractions for the property (married, John Smith). A
second method is to assign a degree of 2 to this property.
There are also two possible ways to incorporate the degree information into the ESP
model. The ESP model may be altered so that it directly models the degrees of the properties during the process of selecting balls from urns, but this vastly complicates the model
and may make it much more computationally expensive. A second option is to reweight
the number of shared properties between strings based on a TF-IDF style weighting of the
properties, and calculate the ESP model using this parameter instead. This requires modifying the ESP model so that it can handle non-integer values for the number of shared
properties.
In experiments so far, one set of these options was explored, while others remain for
future investigation. The Weighted Extracted Shared Property Model (W-ESP) sets the
degree of a property to be the number of extractions for that property. Second, if strings
si and sj share all properties p ∈ P , it sets the value for the number of shared properties
between si and sj to be
X

p∈P

1
degree(p)

The ESP model has been changed to handle continuous values for the number of shared
properties by changing all factorials to gamma functions, and using Stirling’s approximation
whenever possible.
280

Unsupervised Methods for Determining Object and Relation Synonyms

Model

Prec.

Rec.

F1

Resolver
Resolver
Resolver
Resolver
Resolver

0.71
0.74
0.78
0.71
0.78

0.66
0.66
0.68
0.65
0.68

0.68
0.70
0.73
0.68
0.73

+
+
+
+

Function Filtering
Coordination Phrase Filtering
Weighted ESP
Function and Coord. Phrase Filtering

Table 6: Comparison of object merging results for the Resolver system, Resolver plus
Function Filtering, Resolver plus Coordination-Phrase Filtering, Resolver
using the Weighted Extracted Shared Property Model, and Resolver plus both
types of filtering. Bold indicates the score is significantly different from Resolver’s
score at p < 0.05 using the chi-squared test with one degree of freedom. Resolver+
Coordination Phrase Filtering’s F1 on objects is a 28% increase over SSM’s F1, and a 7%
increase over Resolver’s F1.

Unlike the Function Filter, the W-ESP model does not require additional knowledge
about which relations are functional. And unlike the Coordination-Phrase Filter, it does
not require Web hitcounts or a training phase. It works on extracted data, as is.
7.4 Experiments
The extensions to Resolver attempt to address the confusion between similar and identical
pairs. Experiments with the extensions, using the same datasets and metrics as in Section 6
demonstrate that the Function Filter (FF) and the Coordination-Phrase Filter (CPF) boost
Resolver’s precision. Unfortunately, the W-ESP model yielded essentially no improvement
of Resolver.
Table 6 contains the results of our experiments. With coordination-phrase filtering,
Resolver’s F1 is 28% higher than SSM’s on objects, and 6% higher than Resolver’s F1
without filtering. While function filtering is a promising idea, FF provides a smaller benefit
than CPF on this dataset, and the merges that it prevents are, with a few exceptions,
a subset of the merges prevented by CPF. This is in part due to the limited number of
functions available in the data.
Both the Function Filter and the Coordination-Phrase Filter consistently blocked merges
between highly similar countries, continents, planets, and people in our data, as well as some
other smaller classes. The biggest difference is that CPF more consistently has hitcounts
for the similar pairs that tend to be confused with identical pairs. Perhaps as the amount
of extracted data grows, more functions and extractions with functions will be extracted,
allowing the Function Filter to improve.
Part of the appeal of the W-ESP model is that it requires none of the additional inputs
that the other two models require, and it applies to each property, rather than to a subset
of the relations like the Function Filter. Like TFIDF weighting for the Cosine Similarity
Metric, the W-ESP model uses information about the distribution of the properties in the
data to weight each property. For the data extracted by TextRunner, neither W-ESP
nor TFIDF weighting seems to have a positive effect. More experiments are required to test
281

Yates & Etzioni

whether W-ESP might prove more beneficial on other data sets where TFIDF does have a
positive effect.

8. Resolver and Cross-Document Entity Resolution
Up to this point, we have made the single-sense assumption, or the assumption that every
token has exactly one meaning. While this assumption is defensible in small domains,
where named entities and relations rarely have multiple meanings, even there it can cause
problems: for example, the names Clinton and Bush each refer to two major players in
American politics, as well as a host of other people. When extractions are taken from
multiple domains, this assumption becomes more and more problematic.
We now describe a refinement of the Resolver system that handles the task of CrossDocument Entity Resolution (Bagga & Baldwin, 1998), in which tokens or names may have
multiple referents, depending on context. An experiment below compares Resolver with
an existing entity resolution system (Li et al., 2004a), and demonstrates that Resolver can
handle polysemous named entities with high accuracy. This extension could theoretically
be applied to highly polysemous tokens such as common nouns, but this has not yet been
empirically demonstrated.
8.1 Clustering Polysemous Names with Resolver
Recall that the synonym resolution task is defined as finding clusters in the set of distinct
strings S found in a set of extractions D (Section 3). Cross-Document Entity Resolution
differs from synonym resolution in that it requires a clustering of the set of all string
occurrences, rather than the set of distinct strings. For example, suppose a document
contains two occurrences of the token DP, one where it means “Design Pattern” and one
where it means “Dynamic Programming.” Synonym resolution systems treat DP as a single
item, and will implicitly cluster both occurrences of DP together. A Cross-Document Entity
Resolution system treats each occurrence of DP separately, and therefore has the potential
to put each occurrence in a separate cluster when they mean different things. In this way,
a Cross-Document Entity Resolution system has the potential to handle polysemous names
correctly.
Because of the change in task definition, the sources of evidence for similarity are sparser.
For each occurrence of a named entity in its input, Resolver has just a single TextRunner extraction describing the occurrence. To achieve reasonable performance, it needs
more information about the context in which a named entity appears. We change Resolver’s representation of entity occurrences to include the nearest E named entities in
the text surrounding the occurrence. That is, each entity occurrence x is represented as
a set of named entities y, where y appears among the nearest E entities in the text surrounding x. Suppose, for instance, that e1 is an occurrence of DP with Bellman and Viterbi
in its context, and e2 is another occurrence with OOPSLA and Factory in its context. e1
would be represented by the set {Bellman, Viterbi}, and e2 would be represented by the set
{Factory, OOPSLA}.
Table 7 summarizes the major ways in which we extended Resolver to handle polysemous names. With these extensions in place, Resolver can proceed to cluster occurrences
of entities more or less the same way that it clusters entity names for synonym resolution.
282

Unsupervised Methods for Determining Object and Relation Synonyms

Original Resolver

Extended Resolver

Input

A set of distinct strings S, and
for each s ∈ S, a set of extracted properties of s.

SSM Compares
ESP Compares
Output

Character sequences
Sets of extracted properties
A clustering of the set of distinct strings S

A bag of string occurrences O,
and for each occurrence o ∈ O,
a set of named entities appearing close to o in context.
Character sequences
Sets of named entities
A clustering of the set of string
occurrences O

Table 7: The differences between the original Resolver system and the extended Resolver system for handling polysemous names.

The SSM model works as above, and the ESP model calculates probabilities of coreference
based on sets of named entities in context rather than extracted properties. The clustering
algorithm eliminates comparisons between occurrences that share no part of their contexts,
or only very common contextual elements. In the end, Resolver produces sets of coreferential entity occurrences, which can be used to annotate extractions containing these entity
occurrences for coreference relationships.
8.2 Experiment with Cross-Document Entity Resolution
We tested Resolver’s ability to handle polysemous names on a data set of 300 documents from 1998-2000 New York Times articles in the TREC corpus (Voorhees, 2002). Li
et al. (2004b) automatically ran a named-entity tagger on these documents and manually
corrected them to identify approximately 4,000 occurrences of people’s names. They then
manually annotated the occurrences to form a gold standard set of coreferential clusters.
For each named entity occurrence in this data set, we extracted the set of the closest E
named entities, with E set to 100, to represent the context for the named entity occurrence.
We then ran Resolver to cluster the entity occurrences. We set ESP’s latent parameter N
to 30, as in the experiments above. We did not have any development data to set the merge
threshold, so we used the following strategy: we arbitrarily picked a single occurrence of a
common name from this data set (Al Gore), found a somewhat uncommon variant of the
name (Vice President Al Gore), and set the threshold at a value just below the similarity
score for this pair (7.5). For every round of merging in Resolver’s clustering algorithm,
we filtered the top 20 proposed merges using the Coordination Phrase Filter, with the same
threshold as used in the previous experiments.
Li et al. propose a generative model of entity coreference that we compare against. Their
model requires databases of information about titles, first names, last names, genders, nicknames, and common transformations of these attributes of people’s names to help compute
the probability of coreference. It uses Expectation-Maximization over the given data set
to compute parameters, and an inference algorithm that is O(N 2 ) in the number of word
occurrences N . Full details are provided by Li et al. (2004b).
283

Yates & Etzioni

Resolver
Li et al.

Precision

Recall

F1

97.3
91.5

94.7
94.0

96.0
92.7

Table 8: Resolver outperforms the system by Li et al. on a Cross-Document Entity Resolution task involving polysemous people’s names. Differences are statistically
significant for both precision and recall using the two-tailed Chi-Square test
with one degree of freedom (p < 0.01, α = 910.9 for precision and α = 20.6 for
recall).

Following Li et al., we evaluate clusters using precision and recall calculated as follows:
let Op be the set of entity occurrence pairs that are predicted to be coreferential (i.e., they
belong to the same cluster), and let Oa denote the set of correct coreferential pairs, as
|Op ∩Oa |
|Op ∩Oa |
calculated from the manual clustering. Then precision P = |O
, recall R = |O
,
p|
a|
R
and F1 = P2P+R
.
Table 8 shows the results of running Resolver on this data set, as well as the best
results reported by Li et al. (2004b) on the same data. 5 In follow-up work, Li et al. (2004a)
demonstrate that their unsupervised model outperforms three supervised techniques that
learn parameters for how much different attributes (first name, honorifics, etc.) contribute
to the similarity of occurrence pairs.
In terms of absolute performance, Resolver is quite accurate in dealing with the polysemous names in this data set. Its performance on this data set is significantly higher than
on TextRunner extractions, partly because it has extra information available in terms of
the contexts of occurrences, and partly because it is starting out with manually labelled
named entities, rather than noisy extractions.
Resolver’s precision is significantly higher than Li et al.’s, with roughly equal recall.
Because of the large sample sizes, the differences in precision and recall are both statistically significant (two-tailed Chi-Square test with one degree of freedom, p < 0.01). In
comparison with Li et al.’s system, Resolver’s SSM model is much less sophisticated, but
it compensates by using Web data and a strong measure of distributional similarity. It does
not need to rely on manually curated databases for expert knowledge about the domain, or
in this case, the similarity of people’s names.

9. Conclusion and Future Work
We have shown that the unsupervised and scalable Resolver system is able to find clusters
of coreferential object names in extracted relations with a precision of 78% and a recall of
5. In follow-up work, Li et al. (2004a) report an F1 score of 95.1 for this task using what appears to be the
same model and the same data, but the result is calculated by testing the model on 6 random splits of
the data and averaging the score. We do not have access to these random splits. One possible reason
that the reported results are different is that splitting up the test data reduces the number of coreference
relations that need to be found and the potential number of incorrect coreference relations that can cause
a system confusion.

284

Unsupervised Methods for Determining Object and Relation Synonyms

68% with the aid of coordination-phrase filtering, and can find clusters of coreferential
relation names with precision of 90% and recall of 35%. We have demonstrated significant
improvements over using existing similarity metrics for this task by employing a novel
probabilistic model of synonymy. On a much cleaner set of extractions from the TREC
corpus, we demonstrated that Resolver was able to achieve 97% precision and 95% recall
by employing an extension that allowed it to cluster different senses of the same name into
different groups.
Perhaps the most critical aspect to extending Resolver is refining its ability to handle
polysemy. Further experiments are needed to test its ability to handle new types of polysemous named entities and extracted data that has not been manually cleaned, as is the
case for Li et al.’s data. In addition, we plan to incorporate the ESP model into a system
for unsupervised coreference resolution, including common nouns and pronouns. We will
extend the model to include aspects of local salience, which can be important in coreference
decisions for noun phrases other than proper names.
Currently we are setting the ESP model’s single hidden parameter using a development
set. While the required amount of data is very small, the model might be more accurate
and easier to use if the hidden parameter were set by sampling the data, rather than using
a development set that must be manually assembled. That is, Resolver could inspect a
substantial portion of the data, and then measure how often new properties appear in the
remaining data. The rate of appearance of new properties should offer a strong signal for
how to set the hidden parameter.
Several extensions to Resolver have dealt with ruling out highly similar non-synonyms
(Section 7), with varying degrees of success at boosting Resolver’s precision. We have also
considered another extension to Resolver that seeks to use “mutual recursion” to boost
recall, much like semi-supervised information extraction techniques use “mutual bootstrapping” between entities and patterns to increase recall (Riloff & Jones, 1999). The method
begins by clustering objects, then clusters relations using the merged object clusters as
properties (rather than the raw object strings), then clusters objects again using relation
clusters as properties, and so on. Although we have so far been unable to boost the performance of Resolver using this technique on TextRunner data, experiments on artificial
simulations suggest that under suitable conditions, mutual recursion could boost recall by
as much as 16%. It remains an important area of future work to determine if there is
natural data for which this technique is indeed useful, and to investigate other methods for
increasing Resolver’s recall.

Acknowledgments
This research was supported in part by Temple University, NSF grants IIS-0535284 and
IIS-0312988, ONR grant N00014-08-1-0431 as well as gifts from Google, and was carried
out at the University of Washington’s Turing Center and Temple University’s Center for
Information Science and Technology. We would like to thank the anonymous reviewers and
the JAIR associate editor in charge of this paper for their helpful comments and suggestions.
We would also like to thank the KnowItAll group at the University of Washington for
their feedback and support.
285

Yates & Etzioni

Appendix A. Derivation of the Extracted Shared Property Model
The Extracted Shared Property (ESP) Model is introduced in Section 4. It is a method for
calculating the probability that two strings are synonymous, given that they share a certain
number of extractions in a data set. This appendix gives a derivation of the model.
Let si and sj be two strings, each with a set of extracted properties Ei and Ej . Let Ui
and Uj be the set of potential properties for each string, contained in their respective urns.
Let Si,j be the number of properties shared between the two urns, or |Ui ∩ Uj |. Let Ri,j
t
be the random variable for the synonymy relationship between si and sj , with Ri,j = Ri,j
f
denoting the event that they are, and Ri,j
that they are not. The ESP model states that the
t is the probability of selecting the observed number of matching properties
probability of Ri,j
from two urns containing all matching properties, divided by the probability of selecting the
observed number of matching properties from two urns which may contain some matching
and some non-matching properties:

Proposition 2 If two strings si and sj have |Ui | = Pi and |Uj | = Pj potential properties
(or instances), with min(Pi , Pj ) = Pmin ; and they appear in extracted assertions Ei and Ej
such that |Ei | = ni and |Ej | = nj ; and they share k extracted properties (or instances), the
probability that si and sj co-refer is:
t
P (Ri,j
|Ei , Ej , Pi , Pj ) =
Pmin
k

P

 Pj −Pmin 

r+s Pi −Pmin
ni −(k+r) nj −(k+s)
r

 Pi −Si,j  Pj −Si,j 
Si,j  P
Si,j −k r+s
r,s≥0
r+s
r
k
ni −(k+r) nj −(k+s)

P

k≤Si,j ≤Pmin

r,s≥0

Si,j −k
r+s



(10)

The ESP model makes several simplifying assumptions:
1. Balls are drawn from the urns without replacement.
2. Draws from one urn are independent of draws from any other urn.
3. Each ball for a string is equally likely to be selected from its urn: if U = {u1 , . . . , um }
and X denotes a random draw from U , P (X = ui ) = |U1 | for every ui .
4. The prior probability for Si,j , given the number of properties in Ui and Uj , is uniform:
∀0≤s≤min(Pi ,Pj ) P (Si,j = s|Pi , Pj ) = min(Pi1,Pj )+1
5. Given extracted properties for two strings and the number of potential properties for
each, the probability of synonymy depends only on the number of extracted properties
for each, and the number of shared properties in the extractions:
t |E , E , P , P ) = P (Rt |k, n , n , P , P ).
P (Ri,j
i j
i
j
i
j
i
j
i,j
6. Two strings are synonymous if and only if they share as many potential properties as
t ≡ (|U ∩ U | = min(P , P )).
possible: Ri,j
i
j
i
j
Before proving Proposition 2, we prove a simple property of urns under the assumptions
above.
286

Unsupervised Methods for Determining Object and Relation Synonyms

Lemma 1 Given n draws without replacement from an urn containing a set of properties
U , the probability of selecting a particular set S ⊂ U is |U1 | if |S| = n, and zero otherwise.
( |S| )
Proof of Lemma 1: Let U = {u1 , . . . , um } denote the elements of U , and let X1 , . . . , Xn
denote the independent draws from the urn. If n = 1, then P (S = {ui }) = P (X1 = ui ) = |U1 |
by assumption 3 above. Now suppose that n = n0 , and that the lemma holds for every
n 0 < n0 .
P (S = {x1 , . . . , xn0 |xi ∈ U }) =

X

=

X

i

i

=

P (S n0 −1 = {x1 , . . . , xi−1 , xi+1 , . . . , xn0 }) ×
P (Xn = xi )
1
1

|U |
|U | − n0 + 1
n0 −1

X (n0 − 1)!(|U | − n0 + 1)!
|U |!

i

=
=
=

1
|U | − n0 + 1

n0 (n0 − 1)!(|U | − n0 + 1)(|U | − n0 )!
|U |!(|U | − n0 + 1)
n0 !(|U | − n0 )!
|U |!
1

|U |
n0

2

Proof of Proposition 2:
t |E , E , P , P ), into something that
We begin by transforming the desired expression, P (Ri,j
i
j
i
j
can be derived from the urn model. By assumptions 5 and 6, we get
t
P (Ri,j
|Ei , Ej , Pi , Pj ) = P (Si,j = Pmin |k, ni , nj , Pi , Pj )

(11)

Then, by applying Bayes Rule, we get
P (Si,j = Pmin |k, ni , nj , Pi , Pj ) =
P (k|Si,j = Pmin , ni , nj , Pi , Pj )P (Si,j = Pmin |ni , nj , Pi , Pj )
P
k≤Si,j ≤Pmin P (k|ni , nj , Pi , Pj )P (Si,j |ni , nj , Pi , Pj )

(12)

Since we have assumed a uniform prior for Si,j (assumption 4), the prior terms vanish,
leaving
P (k|Si,j = Pmin , ni , nj , Pi , Pj )
t
P (Ri,j
|Ei , Ej , Pi , Pj ) = P
(13)
k≤Si,j ≤Pmin P (k|ni , nj , Pi , Pj )
The second step of the derivation is to find a suitable expression for
P (k|Si,j , ni , nj , Pi , Pj )
287

Yates & Etzioni

The probability can be written out fully as:
X
P (k|Si,j , ni , nj , Pi , Pj ) =

Ei ⊂Ui :|Ei |=ni
Ej ⊂Uj :|Ej |=nj
|Ei ∩Ej |=k

X

Ei ⊂Ui :|Ei |=ni
Ej ⊂Uj :|Ej |=nj

P (Ei , Ej |Si,j , ni , nj , Pi , Pj )

P (Ei , Ej |Si,j , ni , nj , Pi , Pj )

(14)

By assumption 2, P (Ei , Ej ) = P (Ei )P (Ej ). By Lemma 1, all P (Ei ) terms are equal, since
they are all sets of size ni , and likewise for P (Ej ) terms. Thus, to get the desired probability
expression, we simply need to count the number of ways of taking subsets from the two
urns such that they share k properties.
X
1
P (k|Si,j , ni , nj , Pi , Pj ) =

Ei ⊂Ui :|Ei |=ni
Ej ⊂Uj :|Ej |=nj
|Ei ∩Ej |=k

X

1

(15)

Ei ⊂Ui :|Ei |=ni
Ej ⊂Uj :|Ej |=nj

=
There are

Pi
ni



Count(k, ni , nj |Si,j , Pi , Pj )
Count(ni , nj |Si,j , Pi , Pj )

(16)

ways of picking each set Ei , so
Count(ni , nj |Si,j , Pi , Pj ) =

  
Pi
Pj
ni
nj

(17)

To complete the derivation, we need an expression for Count(k, ni , nj | Si,j , Pi , Pj ). This
involves splitting the relevant sets into several parts. First Ui and Uj each contain some
shared and unshared properties. Let Ti,j = Ui ∩Uj , Vi = Ui −Ti,j , and Vj = Uj −Ti,j . Second,
the selected sets from each urn, Ei and Ej , each have properties that come from the set of
shared properties and the set of unshared properties. Let K = Ei ∩ Ej , Fi = (Ei ∩ Ti,j ) − K,
and Fj = (Ej ∩ Ti,j ) − K.
With these sets defined, each set Ei and Ej is composed of three distinct subsets: the
shared subset (K); a subset also selected from the shared potential properties, Ti,j , but
which is not shared (Fi and Fj ); and the remaining elements, which are chosen from the
complements of the shared properties (Vi and Vj ). Since the subsets are distinct, we can
count them separately and multiply the results to arrive at the final count.
The number of ways of selecting the shared subset is clearly Ski,j . The sizes of Fi and
Fj are unknown, however, so we must sum over all possibilities. Let r = |Fi |, and s = |Fj |.
There are Si,j − k remaining shared potential
 properties in Ti,j from which to choose the
r + s elements of Fi and Fj , and then r+s
ways to split the two into distinct subsets.
s
There are ni − (k + r) elements left to choose in Ei , and nj − (k + s) elements left to choose
in Ej . These must be selected from the unshared potential properties in Vi and Vj , which
have sizes Pi − Si,j and Pj − Si,j respectively. Putting these pieces together, we have
288

Unsupervised Methods for Determining Object and Relation Synonyms

Count(k, ni , nj |Si,j , Pi , Pj ) =







Pj − Si,j
r+s
Pi − Si,j
Si,j X Si,j − k
ni − (k + r) nj − (k + s)
r+s
s
k
r,s

(18)

The ranges for r and s are somewhat involved. They must obey the following constraints:
1. r, s ≥ 0
2. r ≥ ni − k − Pi + Si,j
3. s ≥ nj − k − Pj + Si,j
4. r ≤ ni − k
5. s ≤ nj − k
6. r + s ≤ Si,j − k
Plugging Equation 18 into Equation 16, and that in turn into Equation 13 yields the
desired result. 2

Appendix B. Fast Calculation of the Extracted Shared Property Model
The ESP model can be expensive to calculate if done the wrong way. We use two techniques
to speed up the calculation immensely. For reference, the full formulation of the model is:
t
P (Ri,j
|k, ni , nj , Pi , Pj ) =
Pmin
k

P

 Pj −Pmin 

r+s Pi −Pmin
ni −(k+r) nj −(k+s)
r

 Pi −Si,j  Pj −Si,j 
Si,j  P
Si,j −k r+s
r,s≥0
r+s
r
k
ni −(k+r) nj −(k+s)

P

k≤Si,j ≤Pmin

r,s≥0

Si,j −k
r+s



(19)

Note that the equation involves three sums, ranging over O(Pmin ), O(ni ), and O(nj ) values
respectively. In effect, this is O(n3 ) in the number of extractions for a string. Furthermore,
each step requires the expensive operation of calculating binomial coefficients. Fortunately,
there are several easy ways to drastically speed up this calculation.
First, Stirling’s approximation can be used to calculate factorials (and therefore the
binomial function). Stirling’s approximation is given by:
s 
 n
1
n
n! ≈ π 2n +
3
en
To avoid underflow and overflow errors, log probabilities are used everywhere possible. This
calculation can then be done using a few simple multiplications and logarithm calculations.
Stirling’s formula converges to n! like O( n1 ); in practice it proved to be accurate enough of
an approximation of n! for n > 100. In ESP’s implementation, all other values of n! are
calculated once, and stored for future use.
289

Yates & Etzioni

Second, the calculation of P (k|n1 , n2 , P1 , P2 ) can be sped up by simplifying the expression to get rid of two of the sums. The result is the following equivalent expression, assuming
without loss of generality that P2 ≤ P1 :
P (k|n1 , n2 , P1 , P2 ) =

P2 +1
n2 +1

 Pn2

r
r=k k
 
P2 P1
n2 n1



P1 −r
n1 −k



(20)

This simplification removes two of the sums, and therefore changes the complexity of calculating ESP from O(P2 n2 n1 ) to O(n2 ). This was sufficient for our data set, but on larger
data sets it might be necessary to introduce sampling techniques to improve the efficiency
even further.

Appendix C. A Better Bound on the Number of Comparisons Made by
the Resolver Clustering Algorithm
Section 4 showed that the Resolver clustering algorithm initially makes O(N log N ) comparisons between strings in the data, where N is the number of extractions. Heuristic methods like the Canopies method (McCallum et al., 2000) require O(M 2 ) comparisons, where
M is the number of distinct strings in the data. We claim that O(N log N ) is asymptotically
better than O(M 2 ) for Zipf-distributed data.
Zipf-distributed data is controlled by a shape parameter, which we call z. The claim
above holds true for any shape parameter z < 2, as shown below. Fortunately, in natural
data the shape parameter is usually very close to z = 1, and in Resolver data it was
observed to be z < 1.
Let S be the set of distinct strings in a set of extractions D. For each s ∈ P
S, let freq(s)
denote the number of times that s appears in the extractions. Thus |D| = s∈S freq(s).
Let M = |S| and N = |D|.
Proposition 3 If S has an observed Zipf distribution with shape parameter z, then
1. if z < 1, N = Θ(M )
2. if z = 1, N = Θ(M log M )
3. if z > 1, N = Θ(M z )
Proof: Let s1 , . . . , sM be the elements of S in rank order from highest frequency string
(s1 ) to lowest frequency string (sM ). Since S has an observed Zipf distribution with shape
z
parameter z, freq(si ) = Miz . Given the assumptions, z and M determine the number of
extractions made:
X
NM,z =
freq(s)
(21)
s∈S

X Mz
iz

=

1≤i≤M

290

(22)

Unsupervised Methods for Determining Object and Relation Synonyms

We can build a recurrence relation for the value of N as M changes (holding z constant)
by noting that
N2M,z =

X

1≤i≤2M

= (2M )z

(2M )z
iz
X 1

1≤i≤M

iz

(23)
+ (2M )z

= 2z NM,z + fz (M )

X

M +1≤i≤2M

1
iz

(24)
(25)

P
)z
where fz (M ) = M +1≤i≤2M (2M
iz .
There are two important properties of fz (M ).
z

)
z
1. Note that every term in the sum for fz (M ) is less than (2M
M z = 2 . Thus fz (M ) is
bounded above by 2z · M , so if z is held constant, fz (M ) = O(M ).

2. Every term in the sum is at least 1, so fz (M ) ≥ M and fz (M ) = Ω(M ); combining
these two facts yields fz (M ) = Θ(M ).
These two properties of fz (M ) will be used below.
We can now use the recurrence relation and the Master Recurrence Theorem (Cormen,
Leiserson, & Rivest, 1990) to prove the three claims of the proposition. For reference, the
Master Recurrence Theorem states the following:
Theorem 1 Let a ≥ 1 and b ≥ 1 be constants, let f (n) be a function, and let T (n) be
defined on the non-negative integers by the recurrence
T (n) = aT (n/b) + f (n)
Then T(n) can be bounded asymptotically as follows.
1. If f (n) = O(nlogb a− ) for some constant  > 0, then T (n) = Θ(nlogb a )
2. If f (n) = Θ(nlogb a ), then T (n) = Θ(nlogb a log n)
3. If f (n) = Ω(nlogb a+ ), for some constant  > 0, and if af (n/b) ≤ cf (n) for some
constant c < 1 and all sufficiently large n, then T (n) = Θ(f (n)).
First consider the case where z > 1. The recurrence for NM,z can clearly be made to fit
the form for Theorem 1 by setting a = 2z , b = 2, and f = fz (M ). Since fz (M ) is bounded
above by 2z · M = O(M ), it is also clearly bounded above by O(M logb a− ) = O(M z− ),
where we can take  to be anything in (0, z − 1). Thus the case one of Theorem 1 applies,
and NM,z = Θ(M logb a ) = Θ(M z ).
Next consider the case where z = 1. Since fz=1 (M ) = Θ(M ) and Θ(M logb a ) = Θ(M ),
case two of Theorem 1 applies. Thus NM,z=1 = Θ(M logb a log M ) = Θ(M log M ).
Finally, consider the case where z < 1. Unfortunately, the regularity condition in case
3 of Theorem 1 does not hold for fz (M ). Instead of using Theorem 1, we resort to a proof
by induction.
291

Yates & Etzioni

Specifically, we show by induction that whenever z < 1 and M ≥ 2, NM,z ≤ c · M , where
z
2z
c = Max( 2 2+1 , 2−2
z ). First, consider the case where M = 2:
2
X
2z

N2,z =

i=1
z

iz

= 2 +1
2z + 1
·2
=
2
≤ c·M
We now prove the induction case.
NM,z ≤ 2z NM/2,z + fz (M/2)
≤ 2z cM/2 + fz (M/2)
z

(by the induction hypothesis)

z

≤ 2 cM/2 + 2 M/2

= cM · (2z−1 + 2z−1 /c)
2 − 2z
)
≤ cM · (2z−1 + 2z−1
2z
= cM

(by the definition of c)

2
The data used in Resolver experiments in Section 4 had a shape parameter z < 1, so
the bound on the number of comparisons made was O(N log N ) = O(M log M ). For z = 1,
the bound is O(N log N ) = O(M log M log(M log M )) = O(M log2 M ). For z > 1, the
bound is O(M z log M ). Not until z = 2 would the asymptotic performance of O(M 2 log M )
have been worse than O(M 2 ). If past experience is any guide, such a high value for z is
unlikely for extractions from naturally occurring text.

References
Agichtein, E. (2006). Web Information Extraction and User Information Needs: Towards
Closing the Gap. IEEE Data Engineering Bulletin issue on Web-Scale Data, Systems,
and Semantics, December.
Artile, J., Sekine, S., & Gonzalo, J. (2008). Web people search: results of the first evaluation
and the plan for the second. In Proceeding of the 17th international conference on
World Wide Web.
Bagga, A., & Baldwin, B. (1998). Entity-based cross-document coreferencing using the
vector space model. In COLING-ACL.
Banko, M., Cafarella, M. J., Soderland, S., Broadhead, M., & Etzioni, O. (2007). Open
information extraction from the web. In IJCAI.
292

Unsupervised Methods for Determining Object and Relation Synonyms

Barzilay, R., & Lee, L. (2003). Learning to Paraphrase: An Unsupervised Approach Using
Multiple-Sequence Alignment. In Proc. of NAACL-HLT.
Barzilay, R., & McKeown, K. (2001). Extracting paraphrases from a parallel corpus. In
Proceedings of ACL/EACL.
Bean, D., & Riloff, E. (2004). Unsupervised learning of contextual role knowledge for
coreference resolution. In Proceedings of the Annual Meeting of the North American
Chapter of the Association for Computational Linguistics (HLT/NAACL).
Beygelzimer, A., Kakade, S., & Langford, J. (2006). Cover trees for nearest neighbor. In
Proceeings of the 23rd International Conference on Machine Learning (ICML).
Bhattacharya, I., & Getoor, L. (2005). Relational Clustering for Multi-type Entity Resolution. In 11th ACM SIGKDD Workshop on Multi Relational Data Mining.
Bhattacharya, I., & Getoor, L. (2006). Query-time entity resolution. In KDD.
Brockett, C., & Dolan, W. B. (2005). Support vector machines for paraphrase identification
and corpus construction. In International Workshop on Paraphrasing.
Cardie, C., & Wagstaff, K. (1999). Noun Phrase Coreference as Clustering. In Proceedings
of the Joint Conference on Empirical Methods in Natural Language Processing and
Very Large Corpora.
Cohen, W. W. (1998). Providing database-like access to the web using queries based on
textual similarity. In Proceedings of the ACM SIGMOD International Conference on
Management of Data.
Cohen, W., Ravikumar, P., & Fienberg, S. (2003). A comparison of string distance metrics
for name-matching tasks. In IIWeb.
Cormen, T. H., Leiserson, C. E., & Rivest, R. L. (1990). Introduction to Algorithms. The
MIT Press.
Dagan, I., Glickman, O., & Magnini, B. (2006). The PASCAL Recognising Textual Entailment Challenge. Lecture Notes in Computer Science, 3944, 177–190.
Davidov, D., & Rappoport, A. (2008). Unsupervised Discovery of Generic Relationships
Using Pattern Clusters and its Evaluation by Automatically Generated SAT Analogy
Questions. In Proceedings of the ACL.
Dong, X., Halevy, A., & Madhavan, J. (2005). Reference reconciliation in complex information spaces. In SIGMOD.
Downey, D., Etzioni, O., & Soderland, S. (2005). A Probabilistic Model of Redundancy in
Information Extraction. In IJCAI.
Downey, D., Schoenmackers, S., & Etzioni, O. (2007). Sparse information extraction: Unsupervised language models to the rescue. In ACL.
293

Yates & Etzioni

Etzioni, O., Cafarella, M., Downey, D., Kok, S., Popescu, A., Shaked, T., Soderland, S.,
Weld, D., & Yates, A. (2005). Unsupervised named-entity extraction from the web:
An experimental study. Artificial Intelligence, 165 (1), 91–134.
Gionis, A., Indyk, P., & Motwani, R. (1999). Similarity search in high dimensions via
hashing. In Proceedings of the 25th Conference on Very Large Databases (VLDB).
Haghighi, A., & Klein, D. (2007). Unsupervised Coreference Resolution in a Nonparametric
Bayesian Model. In Proceedings of the ACL.
Hasegawa, T., Sekine, S., & Grishman, R. (2004). Discovering relations among named
entities from large corpora. In Proceedings of the ACL.
Hernandez, M. A., & Stolfo, S. J. (1995). The merge/purge problem for large databases.
In SIGMOD.
Hindle, D. (1990). Noun classification from predicage-argument structures. In ACL.
Ide, N., & Veronis, J. (1998). Word Sense Disambiguation: The State of the Art. Computational Linguistics, 24 (1), 1–40.
Kehler, A. (1997). Probabilistic coreference in information extraction. In EMNLP.
Kehler, A., Appelt, D., Taylor, L., & Simma, A. (2004). The (non)utility of predicateargument frequencies for pronoun interpretation. In Proceedings of the Annual Meeting of the North American Chapter of the Association for Computational Linguistics
(HLT/NAACL).
Kok, S., & Domingos, P. (2007). Statistical predicate invention. In Proceedings of the
Twenty-Fourth International Conference on Machine Learning.
Kulkarni, A., & Pedersen, T. (2008). Name Discrimination and Email Clustering Using
Unsupervised Clustering of Similar Contexts. Journal of Intelligent Systems (Special
Issue: Recent Advances in Knowledge-Based Systems and Their Applications), 17 (13), 37–50.
Lappin, S., & Leass, H. J. (1994). An algorithm for pronominal anaphora resolution. Computational Linguistics, 20 (4), 535–561.
Lee, L. (1999). Measures of distributional similarity. In Proceedings of the 37th ACL.
Li, H., & Abe, N. (1998). Word clustering and disambiguation based on co-occurence data.
In COLING-ACL, pp. 749–755.
Li, X., Morie, P., & Roth, D. (2004a). Identification and tracing of ambiguous names:
Discriminative and generative approaches. In Proceedings of the National Conference
on Artificial Intelligence (AAAI), pp. 419–424.
Li, X., Morie, P., & Roth, D. (2004b). Robust reading: Identification and tracing of
ambiguous names. In Proc. of the Annual Meeting of the North American Association
of Computational Linguistics (NAACL), pp. 17–24.
294

Unsupervised Methods for Determining Object and Relation Synonyms

Lin, D., & Pantel, P. (2001). DIRT – Discovery of Inference Rules from Text. In KDD.
Liu, T., Moore, A. W., Gray, A., & Yang, K. (2004). An investigation of practical approximate nearest neighbor algorithms. In Proceedings of the 22nd Annual Conference on
Neural Information Processing Systems (NIPS).
Mann, G., & Yarowsky, D. (2003). Unsupervised personal name disambiguation. In CoNLL.
Manning, C. D., & Schuetze, H. (1999). Foundations of Statistical Natural Language Processing. The MIT Press.
McCallum, A., Nigam, K., & Ungar, L. (2000). Efficient clustering of high-dimensional data
sets with application to reference matching. In KDD.
McCallum, A., & Wellner, B. (2004). Conditional models of identity uncertainty with
application to noun coreference. In NIPS.
McCarthy, J., & Lehnert, W. (1995). Using decision trees for coreference resolution. In
Proceedings of the Fourteenth International Conference on Artificial Intelligence.
Miller, G. A., Beckwith, R., Fellbaum, C., Gross, D., & Miller., K. J. (1990). Introduction
to WordNet: An on-line lexical database. International Journal of Lexicography, 3(4),
235–312.
Monge, A. E., & Elkan, C. (1996). The Field Matching Problem: Algorithms and Applications. In Knowledge Discovery and Data Mining, pp. 267–270.
Ng, V., & Cardie, C. (2002). Improving machine learning approaches to coreference resolution. In ACL.
Pang, B., Knight, K., & Marcu, D. (2003). Syntax-based alignment of multiple translations: Extracting paraphrases and generating new sentences. In Proceedings of
HLT/NAACL.
Pedersen, T., & Kulkarni, A. (2007). Unsupervised Discrimination of Person Names in Web
Contexts. In Proceedings of the Eighth International Conference on Intelligent Text
Processing and Computational Linguistics.
Pereira, F., Tishby, N., & Lee, L. (1993). Distributional clustering of English words. In
Proceedings of the 31st ACL.
Popescu, A.-M. (2007). Information Extraction from Unstructured Web Text. Ph.D. thesis,
University of Washington.
Ravikumar, P., & Cohen, W. W. (2004). A hierarchical graphical model for record linkage.
In UAI.
Riloff, E., & Jones, R. (1999). Learning Dictionaries for Information Extraction by Multilevel Bootstrapping. In Proceedings of the Sixteenth National Conference on Artificial
Intelligence, pp. 474–479.
295

Yates & Etzioni

Salton, G., & McGill, M. (1983). Introduction to Modern Information Retrieval. McGrawHill.
Sekine, S. (2005). Automatic Paraphrase Discovery based on Context and Keywords between NE Pairs. In International Workshop on Paraphrasing.
Shinyama, Y., & Sekine, S. (2003). Paraphrase acquisition for information extraction. In
International Workshop on Paraphrasing.
Singla, P., & Domingos, P. (2006). Entity Resolution with Markov Logic. In ICDM.
Sinha, R., & Mihalcea, R. (2007). Unsupervised graph-based word sense disambiguation
using measures of word semantic similarity. In Proceedings of the IEEE International
Conference on Semantic Computing (ICSC 2007).
Snow, R., Jurafsky, D., & Ng, A. Y. (2006). Semantic taxonomy induction from heterogenous evidence. In COLING/ACL.
Voorhees, E. (2002). Overview of the TREC-2002 question-answering track. In TREC.
Winkler, W. (1999). The state of record linkage and current research problems. Tech. rep.,
U.S. Bureau of the Census, Washington, D.C.
Yates, A., & Etzioni, O. (2007). Unsupervised resolution of objects and relations on the
web. In Proceedings of HLT-NAACL.
Zhu, J., Nie, Z., Wen, J.-R., Zhang, B., & Ma, W.-Y. (2005). 2D Conditional Random Fields
for Web Information Extraction. In Proceedings of the 22nd International Conference
on Machine Learning.
Zipf, G. K. (1932). Selective Studies and the Principle of Relative Frequency in Language.

296

Journal of Artificial Intelligence Research 34 (2009) 89-132

Submitted 8/08; published 2/09

Policy Iteration for Decentralized Control of
Markov Decision Processes
Daniel S. Bernstein

bern@cs.umass.edu

Christopher Amato

camato@cs.umass.edu

Department of Computer Science
University of Massachusetts
Amherst, MA 01003 USA

Eric A. Hansen

hansen@cse.msstate.edu

Department of CS and Engineering
Mississippi State University
Mississippi State, MS 39762 USA

Shlomo Zilberstein

shlomo@cs.umass.edu

Department of Computer Science
University of Massachusetts
Amherst, MA 01003 USA

Abstract
Coordination of distributed agents is required for problems arising in many areas, including multi-robot systems, networking and e-commerce. As a formal framework for such
problems, we use the decentralized partially observable Markov decision process (DECPOMDP). Though much work has been done on optimal dynamic programming algorithms
for the single-agent version of the problem, optimal algorithms for the multiagent case have
been elusive. The main contribution of this paper is an optimal policy iteration algorithm
for solving DEC-POMDPs. The algorithm uses stochastic finite-state controllers to represent policies. The solution can include a correlation device, which allows agents to correlate
their actions without communicating. This approach alternates between expanding the
controller and performing value-preserving transformations, which modify the controller
without sacrificing value. We present two efficient value-preserving transformations: one
can reduce the size of the controller and the other can improve its value while keeping the
size fixed. Empirical results demonstrate the usefulness of value-preserving transformations
in increasing value while keeping controller size to a minimum. To broaden the applicability of the approach, we also present a heuristic version of the policy iteration algorithm,
which sacrifices convergence to optimality. This algorithm further reduces the size of the
controllers at each step by assuming that probability distributions over the other agents’
actions are known. While this assumption may not hold in general, it helps produce higher
quality solutions in our test problems.

1. Introduction
Markov decision processes (MDPs) provide a useful framework for solving problems of
sequential decision making under uncertainty. In some settings, agents must base their
decisions on partial information about the system state. In that case, it is often better to use
the more general framework of partially observable Markov decision processes (POMDPs).
Even more general are problems in which a team of decision makers, each with its own
c
2009
AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

Bernstein, Amato, Hansen, & Zilberstein

local observations, must act together. Domains in which these types of problems arise
include networking, multi-robot coordination, e-commerce, and space exploration systems.
The decentralized partially observable Markov decision process (DEC-POMDP) provides
an effective framework to model such problems. Though this model has been recognized for
decades (Witsenhausen, 1971), there has been little work on provably optimal algorithms
for it.
On the other hand, POMDPs have been studied extensively over the past few decades
(Smallwood & Sondik, 1973; Simmons & Koenig, 1995; Cassandra, Littman, & Zhang, 1997;
Hansen, 1998a; Bonet & Geffner, 2000; Poupart & Boutilier, 2003; Feng & Zilberstein, 2004;
Smith & Simmons, 2005; Smith, Thompson, & Wettergreen, 2007). It is well known that
a POMDP can be reformulated as an equivalent belief-state MDP. A belief-state MDP
cannot be solved in a straightforward way using MDP methods because it has a continuous
state space. However, Smallwood and Sondik showed how to implement value iteration by
exploiting the piecewise linearity and convexity of the value function. This work opened the
door for many algorithms, including approximate approaches and policy iteration algorithms
in which the policy is represented using a finite-state controller.
Extending dynamic programming for POMDPs to the multiagent case is not straightforward. For one thing, it is not clear how to define a belief state and consequently form a
belief-state MDP. With multiple agents, each agent has uncertainty about the observations
and beliefs of the other agents. Furthermore, the finite-horizon DEC-POMDP problem
with just two agents is complete for a higher complexity class than the single-agent version
(Bernstein, Givan, Immerman, & Zilberstein, 2002), indicating that these are fundamentally
different problems.
In this paper, we describe an extension of the policy iteration algorithm for single agent
POMDPs to the multiagent case. As in the single agent case, our algorithm converges
in the limit, and thus serves as the first nontrivial optimal algorithm for infinite-horizon
DEC-POMDPs. A few optimal approaches (Hansen, Bernstein, & Zilberstein, 2004; Szer,
Charpillet, & Zilberstein, 2005) and several approximate algorithms have been developed for
finite-horizon DEC-POMDPs (Peshkin, Kim, Meuleau, & Kaelbling, 2000; Nair, Pynadath,
Yokoo, Tambe, & Marsella, 2003; Emery-Montemerlo, Gordon, Schnieder, & Thrun, 2004;
Seuken & Zilberstein, 2007), but only locally optimal algorithms have been proposed for
the infinite-horizon case (Bernstein, Hansen, & Zilberstein, 2005; Szer & Charpillet, 2005;
Amato, Bernstein, & Zilberstein, 2007).
In our algorithmic framework, policies are represented using stochastic finite-state controllers. A simple way to implement this is to give each agent its own local controller. In
this case, the agents’ policies are all independent. A more general class of policies includes
those which allow agents to share a common source of randomness without sharing observations. We define this class formally, using a shared source of randomness called a correlation
device. The use of correlated stochastic policies in the DEC-POMDP context is novel. The
importance of correlation has been recognized in the game theory community (Aumann,
1974), but there has been little work on algorithms for finding correlated policies.
Each iteration of the algorithm consists of two phases. These are exhaustive backups,
which add nodes to the controller, and value-preserving transformations, which change the
controller without sacrificing value. We first provide a novel exposition of existing single90

Policy Iteration for DEC-POMDPs

agent algorithms using this two-phase view, and then we go on to describe the multiagent
extension.
There are many possibilities for value-preserving transformations. In this paper, we
describe two different types, both of which can be performed efficiently using linear programming. The first type allows us to remove nodes from the controller, and the second
allows us to improve the value of the controller while keeping its size fixed. Our empirical
results demonstrate the usefulness of value-preserving transformations in obtaining high
values while keeping controller size to a minimum.
We note that this work serves to unify and generalize previous work on dynamic programming for DEC-POMDPs. The first algorithm for the finite-horizon case (Hansen et al., 2004)
can be extended to the infinite-horizon case and viewed as interleaving exhaustive backups
and controller reductions. The bounded policy iteration algorithm for DEC-POMDPs (Bernstein et al., 2005), which extends a POMDP algorithm proposed by Poupart and Boutilier
(2003), can be viewed through the lens of our framework as repeated application of a specific
value-preserving transformation.
Because the optimal algorithm will not usually be able to return an optimal solution
in practice, we also introduce a heuristic version of the policy iteration algorithm. This
approach makes use of initial state information to focus policy search and further reduces
controller size at each step. To accomplish this, a forward search from the initial state
distribution is used to construct a set of belief points an agent would visit assuming the
other agents use given fixed policies. This search is conducted for each agent and then policy
iteration takes place while using the belief points to guide the removal of controller nodes.
The assumption that other agents use fixed policies causes the algorithm to no longer be
optimal, but it performs well in practice. We show that more concise and higher-valued
solutions can be produced compared to the optimal method before resources are exhausted.
The remainder of the paper is organized as follows. Section 2 introduces the formal
models of sequential decision making. Section 3 contains a novel presentation of existing
dynamic programming algorithms for POMDPs. In section 4, we present an extension of
policy iteration for POMDPs to the DEC-POMDP case, along with a convergence proof.
We discuss the heuristic version of policy iteration in section 5, followed by experiments
using policy iteration and heuristic policy iteration in section 6. Finally, section 7 contains
the conclusion and a discussion of possible future work.

2. Formal Model of Distributed Decision Making
We begin with a description of the formal framework upon which our work is based. This
framework extends the well-known Markov decision process to allow for distributed policy
execution. We also define an optimal solution for this model and discuss two different
representations for these solutions.
2.1 Decentralized POMDPs
A decentralized partially observable Markov decision process (DEC-POMDP) is defined for~ T, R, Ω,
~ Oi, where
mally as a tuple hI, S, A,
• I is a finite set of agents.
91

Bernstein, Amato, Hansen, & Zilberstein

Agent
Agent
a

s, r
System

a1

Agent
a

System

o, r
System

o1, r

a2

o2, r
Agent

(a)

(b)

(c)

Figure 1: (a) Markov decision process. (b) Partially observable Markov decision process.
(c) Decentralized partially observable Markov decision process with two agents.

• S is a finite set of states, with distinguished initial state s0 .
~ = ×i∈I Ai is a set of joint actions, where Ai is the set of actions for agent i.
• A
~ → ∆S is the state transition function, defining the distributions of states
• T : S×A
that result from starting in a given state and each agent performing an action.
~ → < is the reward function for the set of agents for each set of joint actions
• R : S ×A
and each state.
~ = ×i∈I Ωi is a set of joint observations, where Ωi contains observations for agent i.
• Ω
~ × S → ∆Ω
~ is an observation function, defining the distributions of observations
• O:A
for the set of agents that result from each agent performing an action and ending in
a given state.
The special case of a DEC-POMDP in which there is only one agent is called a partially
observable Markov decision process (POMDP).
In this paper, we consider the case in which the process unfolds over an infinite sequence
of stages. At each stage, all agents simultaneously select an action, and each receives the
global reward based on the reward function and a local observation based on the observation
function. Thus, the transitions, rewards and observations depend on the actions of all
agents, but each agent must act based only on local observations. This is illustrated in
Figure 1. The objective of the agents is to maximize the expected discounted sum of
rewards that are received, thus it is a cooperative framework. We denote the discount
factor β and require that 0 ≤ β < 1.
In a DEC-POMDP, the decisions of each agent affect all the agents in the domain, but
due to the decentralized nature of the model each agent must choose actions based solely on
local information. Because each agent receives a separate observation that does not usually
provide sufficient information to efficiently reason about the other agents, solving a DECPOMDP optimally becomes very difficult. For example, each agent may receive a different
92

Policy Iteration for DEC-POMDPs

(a)

(b)

Figure 2: A set of horizon three policy trees (a) and two node stochastic controllers (b) for
a two agent DEC-POMDP.

piece of information that does not allow a common state estimate or any estimate of the
other agents’ decisions to be calculated. These single estimates are crucial in single agent
problems, as they allow the agent’s history to be summarize concisely, but they are not
generally available in DEC-POMDPs. This is seen in the complexity of the finite-horizon
problem with at least two agents, which is NEXP-complete (Bernstein et al., 2002) and
thus in practice may require double exponential time. Like the infinite-horizon POMDP,
optimally solving an infinite-horizon DEC-POMDP is undecidable as it may require infinite
resources, but our method is able to provide a solution within  of the optimal with finite
time and memory. Nevertheless, introducing multiple decentralized agents causes a DECPOMDP to be significantly more difficult than a single agent POMDP.
2.2 Solution Representations
A local policy for an agent is a mapping from local action and observation histories to actions
while a joint policy is a set of policies, one for each agent in the problem. As mentioned
above, an optimal solution for a DEC-POMDP is the joint policy that maximizes the
expected sum of rewards that are received over the finite or infinite steps of the problem.
In infinite-horizon problems, the rewards are discounted to maintain a finite sum. Thus, an
optimal solution is a joint policy that provides the highest value starting at the given initial
state of the problem.
For finite-horizon problems, local policies can be represented using a policy tree as seen
in Figure 2a. Actions are represented by the arrows or stop figures (where each agent can
move in the given direction or stay where it is) and observations are labeled “wl” and “wr”
for seeing a wall on the left or the right respectively. Using this representation, an agent
takes the action defined at the root node and then after seeing an observation, chooses the
next action that is defined by the respective branch. This continues until the action at a
leaf node is executed. For example, agent 1 would first move left and then if a wall is seen
on the right, the agent would move left again. If a wall is now seen on the left, the agent
does not move on the final step. A policy tree is a record of the the entire local history for
an agent up to some fixed horizon and because each tree is independent of the others it can
93

Bernstein, Amato, Hansen, & Zilberstein

be executed in a decentralized manner. While this representation is useful for finite-horizon
problems, infinite-horizon problems would require trees of infinite height.
Another option used in this paper is to condition action selection on some internal
memory state. These solutions can be represented as a set of local finite-state controllers
(seen in Figure 2b). The controllers operate in a very similar way to the policy trees in
that there is a designated initial node and following the action selection at that node, the
controller transitions to the next node depending on the observation seen. This continues for
the infinite steps of the problem. Throughout this paper, controller states will be referred
to as nodes to help distinguish them from system states.
An infinite number of nodes may be required to define an optimal infinite-horizon DECPOMDP policy, but we will discuss a way to produce solutions within  of the optimal
with a fixed number of nodes. While deterministic action selection and node transitions are
sufficient to define this -optimal policy, when memory is limited stochastic action selection
and node transition may be beneficial. A simple example illustrating this for POMDPs
is given by Singh (1994), which can be easily extended to DEC-POMDPs. Intuitively,
randomness can help an agent to break out of costly loops that result from forgetfulness.
A formal description of stochastic controllers for POMDPs and DEC-POMDPs is given
in sections 3.2.1 and 4.1.1 respectively, but an example can be seen in Figure 2b. Agent 2
begins at node 1 and moves up with probability 0.89 and stays in place with probability
0.11. If the agent stayed in place and a wall was then seen on the left (observation “wl”), on
the next step, the controller would transition to node 1 and the agent would use the same
distribution of actions again. If a wall was seen on the right instead (observation “wr”),
there is a 0.85 probability that the controller will transition back to node 1 and a 0.15
probability that the controller will transition to node 2 for the next step. The finite-state
controller allows an infinite-horizon policy to be represented compactly by remembering
some aspects of the agent’s history without representing the entire local history.

3. Centralized Dynamic Programming
In this section, we cover the main concepts involved in dynamic programming for the single agent case. This will provide a foundation for the multiagent dynamic programming
algorithm described in the following section.
3.1 Value Iteration for POMDPs
Value iteration can be used to solve POMDPs optimally. This algorithm is more complicated
than its MDP counterpart, and does not have efficiency guarantees. However, in practice
it can provide significant leverage in solving POMDPs.
We begin by explaining how every POMDP has an equivalent MDP with a continuous
state space. Next, we describe how the value functions for this MDP have special structure
that can be exploited. These ideas are central to the value iteration algorithm.
3.1.1 Belief State MDPs
A convenient way to summarize the observation history of an agent in a POMDP is through
a belief state, which is a distribution over system states. As it receives observations, the
94

Policy Iteration for DEC-POMDPs

agent can update its belief state and then remove its observations from memory. Let b
denote a belief state, and let b(s) represent the probability assigned to state s by b. If an
agent chooses action a from belief state b and subsequently observes o, each component of
the successor belief state obeys the equation
P
P (o|a, s0 ) s∈S P (s0 |s, a)b(s)
0 0
b (s ) =
,
P (o|b, a)
where

"
P (o|b, a) =

X

#
0

P (o|a, s )

s0 ∈S

X

0

P (s |s, a)b(s) .

s∈S

Note that this is a simple application of Bayes’ rule.
It was shown by Astrom (1965) that a belief state constitutes a sufficient statistic for
the agent’s observation history, and it is possible to define an MDP over belief states as
follows. A belief-state MDP is a tuple hΠ, A, T, Ri, where
• Π is the set of distributions over S.
• A is the set of actions (same as before).
• T (b, a, b0 ) is the transition function, defined as
X
T (b, a, b0 ) =
P (b0 |b, a, o)P (o|b, a).
o∈O

• R(b, a) is a reward function, defined as
R(b, a) =

X

b(s)R(s, a).

s∈S

When combined with belief-state updating, an optimal solution to this MDP can be used
as an optimal solution to the POMDP from which it was constructed. However, since the
belief state MDP has a continuous, |S|-dimensional state space, traditional MDP techniques
are not immediately applicable.
Fortunately, dynamic programming can be used to find a solution to the belief state
MDP. The key result in making dynamic programming practical was proved by Smallwood
and Sondik (1973), who showed that the Bellman operator preserves piecewise linearity and
convexity of a value function. Starting with a piecewise linear and convex representation of
V t , the value function V t+1 is piecewise linear and convex, and can be computed in finite
time.
To represent a piecewise linear and convex value function, one need only store the value
of each facet for each system state. Denoting the set of facets Γ, we can store |Γ| |S|dimensional vectors of real values.PFor any single vector, γ ∈ Γ, we can define its value at
the belief state b with V (b, γ) = s∈S b(s)γ(s). Thus, to go from a set of vectors to the
value of a belief state, we use the equation
X
V (b) = max
b(s)γ(s).
γ

s∈S

95

Bernstein, Amato, Hansen, & Zilberstein

s1

s1

s2
(a)

s2
(b)

Figure 3: A piecewise linear and convex value function for a POMDP with two states (a)
and a non-minimal representation of a piecewise linear and convex value function
for a POMDP (b).

Figure 3a shows a piecewise linear and convex value function for a POMDP with two states.
Smallwood and Sondik proved that the optimal value function for a finite-horizon
POMDP is piecewise linear and convex. The optimal value function for an infinite-horizon
POMDP is convex, but may not be piecewise linear. However, it can be approximated
arbitrarily closely by a piecewise linear and convex value function, and the value iteration
algorithm constructs closer and closer approximations, as we shall see.
3.1.2 Pruning Vectors
Every piecewise linear and convex value function has a minimal set of vectors Γ that represents it. Of course, it is possible to use a non-minimal set to represent the same function.
This is illustrated in Figure 3b. Note that the removal of certain vectors does not change
the value of any belief state. Vectors such as these are not necessary to keep in memory.
Formally, we say that a vector γ is dominated if for all belief states b, there is a vector
γ̂ ∈ Γ \ γ such that V (b, γ) ≤ V (b, γ̂).
Because dominated vectors are not necessary, it would be useful to have a method for
removing them. This task is often called pruning, and has an efficient algorithm based
on linear programming. For a given vector γ, the linear program in Table 1 determines
whether γ is dominated. If variables can be found to make  positive, then adding γ to the
set improves the value function at some belief state. If not, then γ is dominated.
This gives rise to a simple algorithm for pruning a set of vectors Γ̃ to obtain a minimal
set Γ. The algorithm loops through Γ̃, removes each vector γ ∈ Γ̃, and solves the linear
program using γ and Γ̃ \ γ. If γ is not dominated, then it is returned to Γ̃.
It turns out that there is an equivalent way to characterize dominance that can be useful.
Recall that for a vector to be dominated, there does not have to be a single vector that has
value at least as high for all states. It is sufficient for there to exist a set of vectors such
that for all belief states, one of the vectors in the set has value at least as high as the vector
in question.
96

Policy Iteration for DEC-POMDPs

Variables: , b(s)
Objective: Maximize .
Improvement constraints:
X

∀γ̂

b(s)γ̂(s) +  ≤

s

X

b(s)γ(s)

s

Probability constraints:
X

∀s

b(s) = 1,

b(s) ≥ 0

s

Table 1: The linear program for testing whether a vector γ is dominated.

γ1

γ2
convex combination
γ3

s1

s2

Figure 4: The dual interpretation of dominance. Vector γ3 is dominated at all belief states
by either γ1 or γ2 . This is equivalent to the existence of a convex combination of
γ1 and γ2 which dominates γ3 for all belief states.

It can be shown that such a set exists if and only if there is some convex combination
of vectors that has value at least as high as the vector in question for all states. This is
shown graphically in Figure 4. If we take the dual of the linear program for dominance
given in the previous section, we get a linear program for which the solution is a vector of
probabilities for the convex combination. This dual view of dominance was first used in a
POMDP context by Poupart and Boutilier (2003), and is useful for policy iteration, as will
be explained later.
3.1.3 Dynamic Programming Update
In this section, we describe how to implement a dynamic programming update to go from a
value function Vt to a value function Vt+1 . In terms of implementation, our aim is to take
a minimal set of vectors Γt that represents Vt and produce a minimal set of vectors Γt+1
that represents Vt+1 .
97

Bernstein, Amato, Hansen, & Zilberstein

Each vector that could potentially be included in Γt+1 represents the value of an action a
and assignment of vectors in Γt to observations. A combination of an action and transition
rule will hereafter be called a one-step policy. The value vector for a one-step policy can
be determined by considering the action taken, the resulting state transitioned to and
observation seen and the value of the assigned vector at step t. This is given via the
equation
X
γit+1 (s) = R(s, α(i)) + β
P (s0 |s, α(i))P (o|α(i), s0 )γτt (i,o) (s0 ),
s0 ,o

where i is the index of the vector, α(i) is its action, and τ (i, o) is the index of the vector in
Γt to which to transition upon receiving observation o and β is the discount factor. More
details on the derivation and use of this formula are provided by Zhang and Zhang (2001).
There are |A||Γt ||Ω| possible one-step policies. A simple way to construct Γt+1 is to
evaluate all possible one-step policies and then apply a pruning algorithm such as Lark’s
method (Lark III, 1990). Evaluating the entire set of one-step policies will hereafter be
called performing an exhaustive backup. It turns out that there are ways to perform a
dynamic programming update without first performing an exhaustive backup. Below we
describe two approaches to doing this.
The first approach uses the fact that it is simple to find the optimal vector for any
particular belief state. For a belief state b, an optimal action can be determined via the
equation
"
#
X
P (o|b, a)V t (T (b|a, o)) .
α = argmaxa∈A R(b, a) + β
o∈Ω

For each observation o, there is a subsequent belief state, which can be computed using
Bayes’ rule. To get an optimal transition rule, τ (o), we take the optimal vector for the
belief state corresponding to o.
Since the backed-up value function has finitely many vectors, there must be a finite set
of belief states for which backups must be performed. Algorithms which identify these belief
states include Smallwood and Sondik’s “one-pass” algorithm (1973), Cheng’s linear support
and relaxed region algorithms (Cheng, 1988), and Kaelbling, Cassandra and Littman’s
Witness algorithm (1998).
The second approach is based on generating and pruning sets of vectors. Instead of
generating all vectors and then pruning, these techniques attempt to prune during the generation phase. The first algorithm along these lines was the incremental pruning algorithm
(Cassandra et al., 1997). Recently, improvements have been made to this approach (Zhang
& Lee, 1998; Feng & Zilberstein, 2004, 2005).
It should be noted that there are theoretical complexity barriers for DP updates. Littman
et al. (1995) showed that under certain widely believed complexity theoretic assumptions,
there is no algorithm for performing a DP update that is worst-case polynomial in all the
quantities involved. Despite this fact, dynamic programming updates have been successfully implemented as part of the value iteration and policy iteration algorithms, which will
be described in the subsequent sections.
98

Policy Iteration for DEC-POMDPs

3.1.4 Value Iteration
To implement value iteration, we simply start with an arbitrary piecewise linear and convex
value function, and proceed to perform DP updates. This corresponds to value iteration in
the equivalent belief state MDP, and thus converges to an -optimal value function after a
finite number of iterations.
Value iteration returns a value function, but a policy is needed for execution. As in the
MDP case, we can use one-step lookahead, using the equation
"
#
X
X
δ(b) = argmaxa∈A
R(s, a)b(s) + β
P (o|b, a)V (τ (b, o, a)) ,
s∈S

o∈Ω

where τ (b, o, a) is the belief state resulting from starting in belief state b, taking action a,
and receiving observation o. We note that a state estimator must be used as well to track
the belief state. Using the fact that each vector corresponds to a one-step policy, we can
extract a policy from the value of the vectors:
!
X
δ(b) = α argmaxk
b(s)γk (s)
s

While the size of the resulting set of dominant vectors may remain exponential, in many
cases it is much smaller. This can significantly simplify computation.
As in the completely observable case, the Bellman residual provides a bound on the
distance to optimality. Recall that the Bellman residual is the maximum distance across all
belief states between the value functions of successive iterations. It is possible to find the
maximum distance between two piecewise linear and convex functions in polynomial time
with an algorithm that uses linear programming (Littman et al., 1995).
3.2 Policy Iteration for POMDPs
With value iteration, a POMDP is viewed as a belief-state MDP, and a policy is a mapping
from belief states to actions. An early policy iteration algorithm developed by Sondik used
this policy representation (Sondik, 1978), but it was very complicated and did not meet
with success in practice. We shall describe a different approach that has performed better
on test problems. With this approach, a policy is represented as a finite-state controller.
3.2.1 Finite-State Controllers
Using a finite-state controller, an agent has a finite number of internal states. Its actions
are based only on its internal state, and transitions between internal states occur when
observations are received. Internal states provide agents with a kind of memory, which can
be crucial for difficult POMDPs. Of course, an agent’s memory is limited by the number
of internal states it possesses. In general, an agent cannot remember its entire history of
observations, as this would require infinitely many internal states. An example of a finitestate controller can be seen by considering only one agent’s controller in Figure 2b. The
operation of a single controller is the same as that for each agent in the decentralized case.
We formally define a controller as a tuple hQ, Ω, A, ψ, ηi, where
99

Bernstein, Amato, Hansen, & Zilberstein

• Q is a finite set of controller nodes.
• Ω is a set of inputs, taken to be the observations of the POMDP.
• A is a set of outputs, taken to be the actions of the POMDP.
• ψ : Q → ∆A is an action selection function, defining the distribution of actions
selected at each node.
• η : Q × A × Ω → ∆Q is a transition function, defining the distribution of resulting
nodes for each initial node and action taken.
For each state and starting node of the controller, there is an expected discounted sum
of rewards over the infinite horizon. It can be computed using the following system of linear
equations, one for each s ∈ S and q ∈ Q:


X
X
V (s, q) =
P (a|q) R(s, a) + β
P (o, s0 |s, a)P (q 0 |q, a, o)V (s0 , q 0 ) .
s0 ,o,q 0

a

Where P (a|q) is the probability action a will be taken in node q and P (q 0 |q, a, o) is the
probability the controller will transition to node q 0 from node q after action a was taken
and o was observed.
We sometimes refer to the value of the controller at a belief state. For a belief state b,
this is defined as
X
V (b) = max
b(s)V (s, q).
q

s

Thus, it is assumed that, given an initial state distribution, the controller is started in the
node which maximizes value from that distribution. Once execution has begun, however,
there is no belief state updating. In fact, it is possible for the agent to encounter the same
belief state twice and be in a different internal state each time.
3.2.2 Algorithmic Framework
We will describe the policy iteration algorithm in abstract terms, focusing on the key components necessary for convergence. In subsequent sections, we present different possibilities
for implementation.
Policy iteration takes as input an arbitrary finite-state controller. The first phase of an
iteration consists of evaluating the controller, as described above. Recall that value iteration
was initialized with an arbitrary piecewise linear and convex value function, represented by
a set of vectors. In policy iteration, the piecewise linear and convex value function arises
out of evaluation of the controller. Each controller node has a value when paired with each
state. Thus, each node has a corresponding vector and thus a linear value function over
belief state space. Choosing the best node for each belief state yields a piecewise linear and
convex value function.
The second phase of an iteration is the dynamic programming update. In value iteration, an update produces an improved set of vectors, where each vector corresponds to
a deterministic one-step policy. The same set of vectors is produced in this case, but the
100

Policy Iteration for DEC-POMDPs

Input: A finite state controller, and a parameter .
1. Evaluate the finite-state controller by solving a system of linear equations.
2. Perform a dynamic programming update to add a set of deterministic nodes to the
controller.
3. Perform value-preserving transformations on the controller.
4. Calculate the Bellman residual. If it is less than (1 − β)/2β, then terminate.
Otherwise, go to step 1.
Output: An -optimal finite-state controller.
Table 2: Policy Iteration for POMDPs.
actions and transition rules for the one-step policy cannot be removed from memory. Each
new vector is actually a node that gets added to the controller. All of the probability distributions for the added nodes are deterministic. That is, a exhaustive backup in this context
creates a new node for each possible action and possible combinations of observations and
deterministic transitions into the current controller. This results in the same one-step policies being considered as in the dynamic programming update described above. As there
are |A||Γt ||Ω| possible one-step polices, this number also defines the number of new nodes
added to the controller after an exhaustive backup.
Finally, additional operations are performed on the controller. There are many such
operations, and we describe two possibilities in the following section. The only restriction
placed on these operations is that they do not decrease the value for any belief state. Such
an operation is denoted a value-preserving transformation.
The complete algorithm is outlined in Table 2. It is guaranteed to converge to a finitestate controller that is -optimal for all belief states within a finite number of steps. Furthermore, the Bellman residual can be used to obtain a bound on the distance to optimality,
as with value iteration.
3.2.3 Controller Reductions
In performing a DP update, potential nodes that are dominated do not get added to the
controller. However, after the update is performed, some of the old nodes may have become
dominated. These nodes cannot simply be removed, however, as other nodes may transition
into them. This is where the dual view of dominance is useful. Recall that if a node is
dominated, then there is a convex combination of other nodes with value at least as high
from all states. Thus, we can remove the dominated node and merge it into the dominating
convex combination by changing transition probabilities accordingly. This operation was
proposed by Poupart and Boutilier (2003) and built upon earlier work by Hansen (1998b).
Formally, a controller reduction attempts to replace a node q ∈ Q with a distribution
P (q̂) over nodes q̂ ∈ Q \ q such that for all s ∈ S,
X
V (s, q) ≤
P (q̂)V (s, q̂).
q̂∈Q\q

101

Bernstein, Amato, Hansen, & Zilberstein

Variables: , x(γ̂)
Objective: Maximize 
Improvement constraints:
∀s

V (s, γ) +  ≤

X

x(γ̂)V (s, γ̂)

γ̂

Probability constraints:
X

∀γ̂

x(γ̂) = 1,

x(γ̂) ≥ 0

γ̂

Table 3: The dual linear program for testing dominance for the vector γ. The variable x(γ̂)
represents P (γ̂).

This can be achieved by solving the linear program in Table 3. As nodes are used rather
than vectors, we replace x(γ̂) with x(q̂) in the dual formulation which provides a probability distribution of nodes which dominate node q. Rather than transitioning into q, this
distribution can then be used instead. It can be shown that if such a distribution is found
and used for merging, the resulting controller is a value-preserving transformation of the
original one.
3.2.4 Bounded Backups
In the previous section, we described a way to reduce the size of a controller without
sacrificing value. The method described in this section attempts to increase the value of
the controller while keeping its size fixed. It focuses on one node at a time, and attempts to
change the parameters of the node such that the value of the controller is at least as high
for all belief states. The idea for this approach originated with Platzman (1980), and was
made efficient by Poupart and Boutilier (2003).
In this method, a node q is chosen, and parameters for the conditional distribution
P (a, q 0 |q, o) are to be determined. Determining these parameters works as follows. We
assume that the original controller will be used from the second step on, and try to replace
the parameters for q with better ones for just the first step. In other words, we look for
parameters which satisfy the following inequality:


X
X
V (s, q) ≤
P (a|q) R(s, a) + β
P (q 0 |q, a, o)P (o, s0 |s, a)V (s0 , q 0 )
a

s0 ,o,q 0

for all s ∈ S. Note that the inequality is always satisfied by the original parameters.
However, it is often possible to get an improvement.
The new parameters can be found by solving a linear program, as shown in Table 4.
Note that the size of the linear program is polynomial in the sizes of the POMDP and the
controller. We call this process a bounded backup because it acts like a dynamic programming
102

Policy Iteration for DEC-POMDPs

Variables: , x(a), x(a, o, q 0 )
Objective: Maximize 
Improvement constraints:

∀s

V (s, q) +  ≤

X



x(a)R(s, a) + β

x(a) = 1,

∀a, o

X

x(a, o, q 0 ) = x(a)

q0

a

∀a

x(a, o, q 0 )P (o, s0 |s, a)V (s0 , q 0 )

s0 ,o,q 0

a

Probability constraints:
X

X

x(a) ≥ 0,

∀a, o, q 0

x(a, o, q 0 ) ≥ 0

Table 4: The linear program to be solved for a bounded backup. The variable x(a) represents P (a|q), and the variable x(a, o, q 0 ) represents P (a, q 0 |q, o).

backup with memory constraints. To see this, consider the set of nodes generated by a DP
backup. These nodes dominate the original nodes across all belief states, so for every
original node, there must be a convex combination of the nodes in this set that dominate
the original node for all states. A bounded backup finds such a convex combination.
It can be shown that a bounded backup yields a value-preserving transformation. Repeated application of bounded backups can lead to a local optimum, at which none of the
nodes can be improved any further. Poupart and Boutilier (2003) showed that a local optimum has been reached when each node’s value function is touching the value function
produced by performing a full DP backup. This is illustrated in Figure 5.

4. Decentralized Dynamic Programming
In the previous section, we presented dynamic programming for POMDPs. A key part of
POMDP theory is the fact that every POMDP has an equivalent belief-state MDP. No
such result is known for DEC-POMDPs, making it difficult to generalize value iteration to
the multiagent case. This lack of a shared belief-state requires a new set of tools to be
developed for solving DEC-POMDP. As a step in this direction, we were able to develop an
optimal policy iteration algorithm for DEC-POMDPs that includes the POMDP version as
a special case. This algorithm is the focus of the section.
We first show how to extend the definition of a stochastic controller to the multiagent
case. Multiagent controllers include a correlation device, which is a source of randomness
shared by all the agents. This shared randomness increases solution quality while minimally
increasing representation size without adding communication. As in the single agent case,
policy iteration alternates between exhaustive backups and value-preserving transforma103

Bernstein, Amato, Hansen, & Zilberstein

value function after
DP update
value function for
controller

s1

s2

Figure 5: A local optimum for bounded backups. The solid line is the value function for the
controller, and the dotted line is the value function for the controller that results
from a full DP update.

tions. A convergence proof is given, along with efficient transformations that extend those
presented in the previous section.
4.1 Correlated Finite-State Controllers
The joint policy for the agents is represented using a stochastic finite-state controller for
each agent. In this section, we first define a type of controller in which the agents act
independently. We then provide an example demonstrating the utility of correlation, and
show how to extend the definition of a controller to allow for correlation among agents.
4.1.1 Local Finite-State Controllers
In a local controller, the agent’s node is based on the local observations received, and the
agent’s action is based on the current node. These local controllers are defined in the same
way as the POMDP controllers above, with each agent possessing its own controller that
operates independently of the others. As before, stochastic transitions and action selection
are allowed.
We formally define a local controller for agent i as a tuple hQi , Ωi , Ai , ψi , ηi i, where
• Qi is a finite set of controller nodes.
• Ωi is a set of inputs, taken to be the local observations for agent i.
• Ai is a set of outputs, taken to be the actions for agent i.
• ψi : Qi → ∆Ai is an action selection function for agent i, defining the distribution of
actions selected at each node of that agent’s controller.
• ηi : Qi × Ai × Ωi → ∆Qi is a transition function for agent i, defining the distribution
of resulting nodes for each initial node and action taken of that agent’s controller.
The functions ψi and ηi parameterize the conditional distribution P (ai , qi0 |qi , oi ) which represents the combined action selection and node transition probability for agent i. When
104

Policy Iteration for DEC-POMDPs

AB
BA
BB

AA

AA
AB
BA

+R

–R

–R

s1

s2

+R

BB

Figure 6: A DEC-POMDP for which a correlated joint policy yields more reward than the
optimal independent joint policy.

taken together, the agents’ controllers determine the conditional distribution P (~a, ~q 0 |~q, ~o).
This is denoted an independent joint controller. In the following subsection, we show that
independence can be limiting.
4.1.2 The Utility of Correlation
The joint controllers described above do not allow the agents to correlate their behavior
via a shared source of randomness. We will use a simple example to illustrate the utility
of correlation in partially observable domains where agents have limited memory. This
example generalizes the one given by Singh (1994) to illustrate the utility of stochastic
policies in partially observable settings containing a single agent.
Consider the DEC-POMDP shown in Figure 6. This problem has two states, two agents,
and two actions per agent (A and B). The agents each have only one observation, and
thus cannot distinguish between the two states. For this example, we will consider only
memoryless policies.
Suppose that the agents can independently randomize their behavior using distributions
P (a1 ) and P (a2 ). If the agents each choose either A or B according to a uniform distribution,
then they receive an expected reward of − R2 per time step, and thus an expected long-term
−R
reward of 2(1−β)
. It is straightforward to show that no independent policy yields higher
reward than this one for all states.
Next, let us consider the even larger class of policies in which the agents may act in a
correlated fashion. In other words, we consider all joint distributions P (a1 , a2 ). Consider
the policy that assigns probability 21 to the pair AA and probability 12 to the pair BB. This
yields an average reward of 0 at each time step and thus an expected long-term reward of
0. The difference between the rewards obtained by the independent and correlated policies
can be made arbitrarily large by increasing R.
105

Bernstein, Amato, Hansen, & Zilberstein

4.1.3 Correlated Joint Controllers
In the previous subsection, we established that correlation can be useful in the face of
limited memory. In this subsection, we extend our definition of a joint controller to allow for
correlation among the agents. To do this, we introduce an additional finite-state machine,
called a correlation device, that provides extra signals to the agents at each time step. The
device operates independently of the DEC-POMDP process, and thus does not provide
agents with information about the other agents’ observations. In fact, the random numbers
necessary for its operation could be determined prior to execution time and made available
to all agents.
Formally, a correlation device is a tuple hQc , ψc i, where Qc is a set of nodes and ψc :
Qc → ∆Qc is a state transition function. At each step, the device undergoes a transition,
and each agent observes its state.
We must modify the definition of a local controller to take the state of the correlation
device as input. Now, a local controller for agent i is a conditional distribution of the
form P (ai , qi0 |qc , qi , oi ). The correlation device together with the local controllers form a
joint conditional distribution P (~a, ~q 0 |~q, ~o), where ~q = hqc , q1 , . . . , qn i. We will refer to this
as a correlated joint controller. Note that a correlated joint controller with |Qc | = 1 is
effectively an independent joint controller. Figure 7 contains a graphical representation of
the probabilistic dependencies in a correlated joint controller.
The value function for a correlated joint controller can be computed by solving the
~
following system of linear equations, one for each s ∈ S and ~q ∈ Q:

V (s, ~q) =

X



P (~a|~q) R(s, ~a) + β

X

P (s0 , ~o|s, ~a)P (~q 0 |~q, ~a, ~o)V (s0 , ~q 0 ) .

s0 ,~
o,~
q0

~a

We sometimes refer to the value of the controller for an initial state distribution. For a
distribution b, this is defined as
V (b) = max
q~

X

b(s)V (s, ~q).

s

It is assumed that, given an initial state distribution, the controller is started in the joint
node which maximizes value from that distribution.
It is worth noting that correlation can increase the value of a set of fixed-size controllers,
but this same value can be achieved by a larger set of uncorrelated controllers. Thus,
correlation is a way to make better use of limited representation size, but is not required
to produce a set of optimal controllers. This is formalized by the following theorem, which
is proved in Appendix A. The theorem asserts the existence of uncorrelated controllers;
determining how much extra memory is needed to replace a correlation device remains an
open problem.
Theorem 1 Given an initial state and a correlated joint controller, there always exists
some finite-size joint controller without a correlation device that produces at least the same
value for the initial state.
106

Policy Iteration for DEC-POMDPs

a1

q1

q2

a2

q’2

o2

qc
o1

q’1

Figure 7: A graphical representation of the probabilistic dependencies in a correlated joint
controller for two agents.

In the example above, higher value can be achieved with two node uncorrelated controllers for each agent. If the problem starts in s1 , the first node for each agent would choose
A and transition to the second node which would choose B. The second node would then
transition back to the first node. The resulting policy consists of the agents alternating
R
between choosing AA and BB, producing an expected long-term reward of 1−β
which is
higher than the correlated one node policy value of 0. Thus, doubling memory for each
agent in this problem is sufficient to remove the correlation device.
4.2 Policy Iteration
In this section, we describe the policy iteration algorithm. We first extend the definitions of
exhaustive backup and value-preserving transformation to the multiagent case. Following
that, we provide a description of the complete algorithm, along with a convergence proof.
4.2.1 Exhaustive Backups
We introduced exhaustive backups in the section on dynamic programming for POMDPs.
We stated that one way to implement a DP update was to perform an exhaustive backup,
and then prune dominated nodes that were created. More efficient implementations were
described thereafter. These implementations involved interleaving pruning with node generation.
For the multiagent case, it is an open problem whether pruning can be interleaved
with node generation. Nodes can be removed, as we will show in a later subsection, but for
convergence we require exhaustive backups. We do not define DP updates for the multiagent
case, and instead make exhaustive backups a central component of our algorithm.
An exhaustive backup adds nodes to the local controllers for all agents at once, and
leaves the correlation device unchanged. For each agent i, |Ai ||Qi ||Ωi | nodes are added
to the
Q local controller, one for each one-step policy. Thus, the joint controller grows by
|Qc | i |Ai ||Qi ||Oi | joint nodes.
Note that repeated application of exhaustive backups amounts to a brute force search
in the space of deterministic policies. This converges to optimality, but is obviously quite
inefficient. As in the single agent case, we must modify the joint controller in between
107

Bernstein, Amato, Hansen, & Zilberstein

adding new nodes. For convergence, these modifications must preserve value in a sense that
will be made formal in the following section.
4.2.2 Value-Preserving Transformations
We now extend the definition of a value-preserving transformation to the multiagent case.
In the following subsection, we show how this definition allows for convergence to optimality
as the number of iterations grows.
The dual interpretation of dominance is helpful in understanding multiagent valuepreserving transformations. Recall that for a POMDP, we say that a node is dominated if
there is a convex combination of other nodes with value at least as high for all states. Though
we defined a value-preserving transformation in terms of the value function across belief
states, we could have equivalently defined it so that every node in the original controller
has a dominating convex combination in the new controller.
For the multiagent case, we do not have the concept of a belief state MDP, so we take
the second approach mentioned above. In particular, we require that dominating convex
combinations exist for nodes of all the local controllers and the correlation device. A transformation of a controller C to a controller D qualifies as a value-preserving transformation
if C ≤ D, where ≤ is defined below.
~ and R,
~ respectively. We
Consider correlated joint controllers C and D with node sets Q
say that C ≤ D if there exist mappings fi : Qi → ∆Ri for each agent i and fc : Qc → ∆Rc
such that
X
V (s, ~q) ≤
P (~r|~q)V (s, ~r)
~
r

~ Note that this relation is transitive as further value-preserving
for all s ∈ S and ~q ∈ Q.
transformations of D will also be value-preserving transformations of C.
~ → ∆R.
~ Examples
We sometimes describe the fi and fc as a single mapping f : Q
of efficient value-preserving transformations are given in a later section. In the following subsection, we show that alternating between exhaustive backups and value-preserving
transformations yields convergence to optimality.
4.2.3 Algorithmic Framework
The policy iteration algorithm is initialized with an arbitrary correlated joint controller. In
the first part of an iteration, the controller is evaluated via the solution of a system of linear
equations. Next, an exhaustive backup is performed to add nodes to the local controllers.
Finally, value-preserving transformations are performed.
In contrast to the single agent case, there is no Bellman residual for testing convergence to -optimality. We resort to a simpler test for -optimality based on the discount
rate and the number of iterations so far. Let |Rmax | be the largest absolute value of an
immediate reward possible in the DEC-POMDP. Our algorithm terminates after iteration
t+1 |R
max |
t if β 1−β
≤ . At this point, due to discounting, the value of any policy after step t is
less than . Justification for this test is provided in the convergence proof. The complete
algorithm is sketched in Table 5.
Before proving convergence, we state a key lemma regarding the ordering of exhaustive
backups and value-preserving transformations. Its proof is deferred to the Appendix.
108

Policy Iteration for DEC-POMDPs

Input: A correlated joint controller, and a parameter .
1. Evaluate the correlated joint controller by solving a system of linear equations.
2. Perform an exhaustive backup to add deterministic nodes to the local controllers.
3. Perform value-preserving transformations on the controller.
t+1

|Rmax |
4. If β 1−β
≤ , where t is the number of iterations so far, then terminate. Else go
to step 1.

Output: A correlated joint controller that is -optimal for all states.
Table 5: Policy Iteration for DEC-POMDPs.
Lemma 1 Let C and D be correlated joint controllers, and let Ĉ and D̂ be the results of
performing exhaustive backups on C and D, respectively. Then Ĉ ≤ D̂ if C ≤ D.
Thus, if there is a value-preserving transformation mapping controller C to D and both are
exhaustively backed up, then there is a value-preserving transformation mapping controller
Ĉ to D̂. This allows value-preserving transformations to be performed before exhaustive
backups, while ensuring that value is not lost after the backup. We can now state and prove
the main convergence theorem for policy iteration.
Theorem 2 For any , policy iteration returns a correlated joint controller that is -optimal
for all initial states in a finite number of iterations.
Proof: Repeated application of exhaustive backups amounts to a brute force search in
the space of deterministic joint policies. Thus, after t exhaustive backups, the resulting
controller is optimal for t steps from any initial state. Let t be an integer large enough that
β t+1 |Rmax |
≤ . Then any possible discounted sum of rewards after t time steps is small
1−β
enough that optimality over t time steps implies -optimality over the infinite horizon.
Now recall the above lemma, which states that performing value-preserving transformations before a backup provides at least as much value as just performing a backup. By an
inductive argument, performing t steps of policy iteration is a value-preserving transformation of the result of t exhaustive backups. We have argued that for large enough t, the value
of the controller resulting from t exhaustive backups is within  of optimal for all states.
Thus, the result of t steps of policy iteration is also within  of optimal for all states. 2
4.3 Efficient Value-Preserving Transformations
In this section, we describe how to extend controller reductions and bounded backups
to the multiagent case. We will show that both of these operations are value-preserving
transformations.
4.3.1 Controller Reductions
Recall that in the single agent case, a node can be removed if for all belief states, there is
another node with value at least as high. The equivalent dual interpretation is that a node
109

Bernstein, Amato, Hansen, & Zilberstein

can be removed is there exists a convex combination of other nodes with value at least as
high across the entire state space.
Using the dual interpretation, we can extend this to a rule for removing nodes in the
multiagent case. The rule applies to removing nodes either from a local controller or from the
correlation device. Intuitively, in considering the removal of a node from a local controller
or the correlation device, we consider the nodes of the other controllers to be part of the
hidden state.
More precisely, suppose we are considering removing node qi from agent i’s local controller. To do this, we need to find a distribution P (q̂i ) over nodes q̂i ∈ Qi \ qi such that for
all s ∈ S, q−i ∈ Q−i , and qc ∈ Qc ,
V (s, qi , q−i , qc ) ≤

X

P (q̂i )V (s, q̂i , q−i , qc ).

q̂i

where Q−i represents the set of nodes for the other agents. Finding such a distribution
can be formulated as a linear program, as shown in Table 6a. In this case, success is
finding parameters such that  ≥ 0. The linear program is polynomial in the sizes of the
DEC-POMDP and controllers, but exponential in the number of agents.
If we are successful in finding parameters that make  ≥ 0, then we can merge the
dominated node into the convex combination of other nodes by changing all incoming links
to the dominated controller node to be redirected based on the distribution P (q̂i ). At this
point, there is no chance of ever transitioning into qi , and thus it can be removed.
The rule for the correlation device is very similar. Suppose that we are considering the
removal of node qc . In this case, we need to find a distribution P (q̂c ) over nodes q̂c ∈ Qc \ qc
~
such that for all s ∈ S and ~q ∈ Q,
V (s, ~q, qc ) ≤

X

P (q̂c )V (s, ~q, q̂c ).

q̂c

~ for the set of tuples of local controller nodes,
Note that we abuse notation here and use Q
excluding the nodes for the correlation device. As in the previous case, finding parameters
can done using linear programming. This is shown in Table 6b. This linear program is also
polynomial in the the sizes of the DEC-POMDP and controllers, but exponential in the
number of agents.
We have the following theorem, which states that controller reductions are value-preserving
transformations.
Theorem 3 Any controller reduction applied to either a local node or a node of the correlation device is a value-preserving transformation.
Proof: Suppose that we have replaced an agent i node qi with a distribution over nodes
in Qi \ qi . Let us take fi to be the identity map for all nodes except qi , which will map to
the new distribution. We take fc to be the identity map, and we take fj to be the identity
map for all j 6= i. This yields a complete mapping f . We must now show that f satisfies
the condition given in the definition of a value-preserving transformation.
110

Policy Iteration for DEC-POMDPs

(a) Variables: , x(q̂i )
Objective: Maximize 
Improvement constraints:
∀s, q−i , qc

V (s, qi , q−i , qc ) +  ≤

X

x(q̂i )V (s, q̂i , q−i , qc )

q̂i

Probability constraints:
X

∀q̂i

x(q̂i ) = 1,

x(q̂i ) ≥ 0

q̂i

(b) Variables: , x(qc )
Objective: Maximize 
Improvement constraints:
∀s, ~q V (s, ~q, qc ) +  ≤

X

x(q̂c )V (s, ~q, q̂c )

qˆc

Probability constraints:
X

∀q̂c

x(q̂c ) = 1,

x(q̂c ) ≥ 0

q̂c

Table 6: (a) The linear program to be solved to find a replacement for agent i’s node qi .
The variable x(q̂i ) represents P (q̂i ). (b) The linear program to be solved to find a
replacement for the correlation node qc . The variable x(q̂c ) represents P (q̂c ).

Let Vo be the value function for the original controller, and let Vn be the value function
for the controller with qi removed. A controller reduction requires that
Vo (s, ~q) ≤

X

P (~r|~q)Vo (s, ~r)

~
r

~ Thus, we have
for all s ∈ S and ~q ∈ Q.

Vo (s, ~q) =

X

P (~a|~q) R(s, a) + β


X

P (~q 0 |~q, ~a, ~o)P (s0 , ~o|s, ~a)Vo (s0 , ~q 0 )

s0 ,~
o,~
q0

~a


≤

X
~a

P (~a|~q) R(s, a) + β


X

P (~q 0 |~q, ~a, ~o)P (s0 , ~o|s, ~a)

s0 ,~
o,~
q0

111

X
~
r0

P (~r|~q)Vo (s, ~r 0 )

Bernstein, Amato, Hansen, & Zilberstein


=

X

P (~a|~q) R(s, a) + β


X

P (~q 0 |~q, ~a, ~o)P (s0 , ~o|s, ~a)P (~r|~q)Vo (s, ~r 0 )

s0 ,~
o,~
q 0 ,~
r0

~a

~ Notice that the formula on the right is the Bellman operator
for all s ∈ S and ~q ∈ Q.
for the new controller, applied to the old value function. Denoting this operator Tn , the
system of inequalities implies that Tn Vo ≥ Vo . By monotonicity, we have that for all k ≥ 0,
Tnk+1 (Vo ) ≥ Tnk (Vo ). Since Vn = limk→∞ Tnk (Vo ), we have that Vn ≥ Vo . This is sufficient
for f to satisfy the condition in the definition of value-preserving transformation.
The argument for removing a node of the correlation device is almost identical to the
one given above. 2
4.3.2 Bounded Dynamic Programming Updates
In the previous section, we described a way to reduce the size of a controller without
sacrificing value. Recall that in the single agent case, we could also use bounded backups
to increase the value of the controller while keeping its size fixed. This technique can
be extended to the multiagent case. As in the previous section, the extension relies on
improving a single local controller or the correlation device, while viewing the nodes of the
other controllers as part of the hidden state.
We first describe in detail how to improve a local controller. To do this, we choose an
agent i, along with a node qi . Then, for each oi ∈ Ωi , we search for new parameters for the
conditional distribution P (ai , qi0 |qi , oi ).
The search for new parameters works as follows. We assume that the original controller
will be used from the second step on, and try to replace the parameters for qi with better
ones for just the first step. In other words, we look for parameters satisfying the following
inequality:


X
X
V (s, ~q) ≤
P (~a|~q) R(s, a) + β
P (~q 0 |~q, ~a, ~o)P (s0 , ~o|s, ~a)V (s0 , ~q 0 )
~a

s0 ,~
o,~
q0

for all s ∈ S, q−i ∈ Q−i , and qc ∈ Qc . The search for new parameters can be formulated as a
linear program, as shown in Table 7a. Its size is polynomial in the sizes of the DEC-POMDP
and the joint controller, but exponential in the number of agents.
The procedure for improving the correlation device is very similar to the procedure for
improving a local controller. We first choose a device node qc , and consider changing its
parameters for just the first step. We look for parameters satisfying the following inequality:


X
X
P (~a|~q) R(s, a) + β
P (~q 0 |~q, ~a, ~o)P (s0 , ~o|s, ~a)V (s0 , ~q 0 )
V (s, ~q) ≤
~a

s0 ,~
o,~
q0

~
for all s ∈ S and ~q ∈ Q.
As in the previous case, the search for parameters can be formulated as a linear program.
This is shown in Table 7b. This linear program is also polynomial in the sizes of the DECPOMDP and joint controller, but exponential in the number of agents.
The following theorem states that bounded backups preserve value.
112

Policy Iteration for DEC-POMDPs

(a) Variables: , x(qc , ai ), x(qc , ai , oi , qi0 )
Objective: Maximize 
Improvement constraints:
∀s, q−i , qc

X

V (s, ~q, qc ) +  ≤

P (a−i |qc , q−i )[x(qc , ai )R(s, ~a) +

~a

β

X

0
x(c, ai , oi , qi0 )P (q−i
|qc , q−i , a−i , o−i )

s0 ,~
o,~
q 0 ,qc0

· P (~o, s0 |s, ~a)P (qc0 |qc )V (s0 , ~q 0 , qc0 )]

Probability constraints:
X
∀qc
x(qc , ai ) = 1,

∀qc , ai , oi

x(qc , ai , oi , qi0 ) = x(qc , ai )

qi0

ai

∀qc , ai

X

x(qc , ai ) ≥ 0,

∀qc , ai , oi , qi0

x(qc , ai , oi , qi0 ) ≥ 0

(b) Variables: , x(qc0 )
Objective: Maximize 
Improvement constraints:
∀s, ~q V (s, ~q, qc ) +  ≤

X

P (~a|qc , ~q)[R(s, ~a) + β

X

P (~q 0 |qc , ~q, ~a, ~o)

s0 ,~
o,~
q 0 ,qc0

~a
0

· P (s , ~o|s, ~a)x(qc0 )V (s0 , ~q 0 , qc0 )]

Probability constraints:
∀qc0

X

x(qc0 ) = 1,

∀qc0

x(qc0 ) ≥ 0

qc0

Table 7: (a) The linear program used to find new parameters for agent i’s node qi . The
variable x(qc , ai ) represents P (ai |qi , qc ), and the variable x(qc , ai , oi , qi0 ) represents
P (ai , qi0 |qc , qi , oi ). (b) The linear program used to find new parameters for the
correlation device node qc . The variable x(qc0 ) represents P (qc0 |qc ).

113

Bernstein, Amato, Hansen, & Zilberstein

Theorem 4 Performing a bounded backup on a local controller or the correlation device
produces a new correlated joint controller which is a value-preserving transformation of the
original.
Proof: Consider the case in which some node qi of agent i’s local controller is changed.
We define f to be a deterministic mapping from nodes in the original controller to the
corresponding nodes in the new controller.
Let Vo be the value function for the original controller, and let Vn be the value function
for the new controller. Recall that the new parameters for P (ai , qi0 |qc , qi , oi ) must satisfy
the following inequality for all s ∈ S, q−i ∈ Q−i , and qc ∈ Qc :


X
X
Vo (s, ~q) ≤
P (~a|~q) R(s, a) + β
P (~q 0 |~q, ~a, ~o)P (s0 , ~o|s, ~a)Vo (s0 , ~q 0 ) .
~a

s0 ,~
o,~
q0

Notice that the formula on the right is the Bellman operator for the new controller, applied
to the old value function. Denoting this operator Tn , the system of inequalities implies
that Tn Vo ≥ Vo . By monotonicity, we have that for all k ≥ 0, Tnk+1 (Vo ) ≥ Tnk (Vo ). Since
Vn = limk→∞ Tnk (Vo ), we have that Vn ≥ Vo . Thus, the new controller is a value-preserving
transformation of the original one.
The argument for changing nodes of the correlation device is almost identical to the one
given above. 2
4.4 Open Issues
We noted at the beginning of the section that there is no known way to convert a DECPOMDP into an equivalent belief-state MDP. Despite this fact, we were able to develop
a provably convergent policy iteration algorithm. However, the policy iteration algorithm
for POMDPs has other desirable properties besides convergence, and we have not yet been
able to extend these to the multiagent case. Two such properties are described below.
4.4.1 Error Bounds
The first property is the existence of a Bellman residual. In the single agent case, it
is possible to compute a bound on the distance to optimality using two successive value
functions. In the multiagent case, policy iteration produces a sequence of controllers, each
of which has a value function. However, we do not have a way to obtain an error bound
from these value functions. For now, to bound the distance to optimality, we must consider
the discount rate and the number of iterations completed.
4.4.2 Avoiding Exhaustive Backups
In performing a DP update for POMDPs, it is possible to remove certain nodes from
consideration without first generating them. In Section 3, we gave a high-level description
of a few different approaches to doing this. For DEC-POMDPs, however, we did not define
a DP update and instead used exhaustive backups as the way to expand a controller. Since
exhaustive backups are expensive, it would be useful to extend the more sophisticated
pruning methods for POMDPs to the multiagent case.
114

Policy Iteration for DEC-POMDPs

Input: A joint controller, the desired number of centralized belief points k, initial state
b0 and fixed policy for each agent πi .
1. Starting from b0 , sample a set of k belief points for each agent assuming the other
agents use their fixed policy.
2. Evaluate the joint controller by solving a system of linear equations.
3. Perform an exhaustive backup to add deterministic nodes to the local controllers.
4. Retain nodes that contribute the highest value at each of the belief points.
5. For each agent, replace nodes that have lower value than some combination of other
nodes at each belief point.
6. If controller sizes and parameters do not change then terminate. Else go to step 2.
Output: A new joint controller based on the sampled centralized belief points.
Table 8: Heuristic Policy Iteration for DEC-POMDPs.

Unfortunately, in the case of POMDPs, the proofs of correctness for these methods all
use the fact that there exists a Bellman equation. Roughly speaking, this equation allows us
to determine whether a potential node is dominated by just analyzing the nodes that would
be its successors. Because we do not currently have an analog of the Bellman equation for
DEC-POMDPs, we have not been able to generalize these results.
There is one exception to the above statement, however. When an exhaustive backup
has been performed for all agents except one, then a type of belief state space can be
constructed for the agent in question using the system states and the nodes for the other
agents. The POMDP node generation methods can then be applied to just that agent. In
general, though, it seems difficult to rule out a node for one agent before generating all the
nodes for the other agents.

5. Heuristic Policy Iteration
While the optimal policy iteration method shows how a set of controllers with value arbitrarily close to optimal can be found, the resulting controllers may be very large and many
unnecessary nodes may be generated along the way. This is exacerbated by the fact that
the algorithm cannot take advantage of an initial state distribution and must attempt to
improve the controller for any initial state. As a way to combat these disadvantages, we
have developed a heuristic version of policy iteration that removes nodes based on their
value only at a given set of centralized belief points. We call these centralized belief points
because they are distributions over the system state that in general could only be known
by full observability of the problem. As a result, the algorithm will no longer be optimal,
but it can often produce more concise controllers with higher solution quality for a given
initial state distribution.
115

Bernstein, Amato, Hansen, & Zilberstein

5.1 Directed Pruning
Our heuristic policy iteration algorithm uses sets of belief points to direct the pruning process of our algorithm. There are two main advantages of this approach: it allows simultaneous pruning for all agents and it focuses the controller on certain areas of the belief space.
We first discuss the benefits of simultaneous pruning and then mention the advantages of
focusing on small areas of the belief space.
As mentioned above, the pruning method used by the optimal algorithm will not always
remove all nodes that could be removed from all the agents’ controllers without losing
value. Because pruning requires each agent to consider the controllers of other agents, after
nodes are removed for one agent, the other agents may be able to prune other nodes. Thus
pruning must cycle through the agents and ceases when no agent can remove any further
nodes. This is both time consuming and causes the controller to be much larger than it
needs to be.
Like the game theoretic concept of incredible threats1 , a set of suboptimal policies for
an agent may be useful only because other agents may employ similarly suboptimal policies. That is, because pruning is conducted for each agent while holding the other agents’
policies fixed, polices that are useful for any set of other agent policies are retained, no
matter the quality of these other agent policies. Some of an agent’s policies may only be
retained because they have the highest value when used in conjunction with other suboptimal policies of the other agents. In these cases, only by removing the set of suboptimal
policies simultaneously can controller size be reduced while at least maintaining value. This
simultaneous pruning could further reduce controller sizes and thus increase scalability and
solution quality. While it may be possible to define a value-preserving transformation for
these problems, finding a nontrivial automated way to do so while maintaining the optimality of the algorithm remains an open question.
The advantage of considering a smaller part of the state space has already been shown
to produce drastic performance increases in POMDPs (Ji, Parr, Li, Liao, & Carin, 2007;
Pineau, Gordon, & Thrun, 2003) and finite-horizon DEC-POMDPs (Seuken & Zilberstein,
2007; Szer & Charpillet, 2006). For POMDPs, a problem with many states has a belief
space with large dimensionality, but many parts may never be visited by an optimal policy.
Focusing on a subset of belief states can allow a large part of the state space to be ignored
without significant loss of solution quality.
The problem of having a large state space is compounded in the DEC-POMDP case.
Not only is there uncertainty about the state, but also about the policies of the other agents.
As a consequence, the generalized belief space which includes all possible distributions over
states of the system and current policies of the other agents must be considered to guarantee
optimality. This results in a huge space which contains many unlikely states and policies.
The uncertainty about which policies other agents may utilize does not allow belief updates
to normally be calculated for DEC-POMDPs, but as we showed above, it can be done by
assuming a probability distribution over actions of the other agents. This limits the number
of policies that need to be considered by all agents and if the distributions are chosen well,
may permit a high-valued solution to be found.
1. An incredible threat is an irrational strategy that the agent knows it will receive a lower value by choosing
it. While it is possible the agent will choose the incredible threat strategy, it is irrational to do so.

116

Policy Iteration for DEC-POMDPs

Variables: , x(q̂i ) and for each belief point b
Objective: Maximize 
Improvement constraints:

∀b, q−i

X

X

b(s)
x(q̂i )V (q̂i , q−i , s) − V (~q, s) ≥ 

s

X

Probability constraints:

q̂i

x(q̂i ) = 1 and ∀q̂i x(qi ) ≥ 0

q̂i

Table 9: The linear program used to determine if a node q for agent i is dominated at
each point b and all initial nodes of the other agents’ controllers. As node q
may be dominated by a distribution of nodes, variable x(q̂i ) represents P (q̂i ), the
probability of starting in node q̂ for agent i.

5.2 Belief Set Generation
As mentioned above, our heuristic policy iteration algorithm constructs sets of belief points
for each agent which are later used to evaluate the joint controller and remove dominated
nodes. To generate the belief point set, we start at the initial state and by making assumptions about the other agents, we can calculate the resulting belief state for each action and
observation pair of an agent. By fixing the policies for the other agents, this belief state update can be calculated in a way very similar to that described for POMDPs in section 3.1.1.
This procedure can be repeated from each resulting belief state until a desired number of
points is generated or no new points are visited.
More formally, we assume the other agents have a fixed distribution of action choice for
each system state. That is, if we know P (~a−i |s) then we can determine the probability any
state results given a belief point and an agent’s action and observation. The derivation of
the likelihood of state s0 , given the belief state b, and agent i’s action ai and observation oi
is shown below.

P (s0 |ai , oi , b) =

X

P (s0 , ~a−i , ~o−i , s|ai , oi , b)

~a−i ,~
o−i ,s

o|s, b, ~a, s0 )P (s0 , s, ~a, b)
~a−i ,~
o−i ,s P (~

P
=

P (oi , ai , b)
o|s, ~a, s0 )P (s0 |s, ~a, b)P (~a, s, b)
~a−i ,~
o−i ,s P (~

P
=

P (oi , ai , b)
o|s, ~a, s0 )P (s0 |s, ~a)P (~a−i |a, s, b)P (~a, s, b)
~a−i ,~
o−i ,s P (~

P
=

P (oi , ai , b)
0 )P (s0 |s, ~
P
(~
o
|s,
~
a
,
s
a)P (~a−i |ai , s, b)P (s|ai , b)P (ai , b)
~a−i ,~
o−i ,s

P
=

P (oi , ai , b)
117

Bernstein, Amato, Hansen, & Zilberstein

P
=

o|s, ~a, s
~a−i ,~
o−i ,s P (~

0 )P (s0 |s, ~
a)P (~a−i |s)b(s)

P (oi |ai , b)

where
X

P (oi |ai , b) =

P (~o|s, ~a, s0 )P (s0 |s, ~a)P (~a−i |s)b(s)

a−i ,o−i ,s,s0

Thus, given the action probabilities for the other agents, −i, and the transition and observation models of the system, a belief state update can be calculated.
5.3 Algorithmic Framework
We provide a formal description of our approach in Table 8. Given the desired number
of belief points, k, and random action and observation selection for each agent, the sets
of points are generated as described above. The search begins at the initial state of the
problem and continues until the given number of points is obtained. If no new points are
found, this process can be repeated to ensure a diverse set is produced. The arbitrary initial
controller is evaluated and the value at each state and for each initial node of any agent’s
controller is retained. The exhaustive backup procedure is exactly the same as the one used
in the optimal algorithm, but updating the controller takes place in two steps. First, for
each of the k belief points, the highest-valued set of initial nodes is found. To accomplish
this, the value of beginning at each combination of nodes for all agents is calculated for each
of these k points and the best combination is kept. This allows nodes that do not contribute
to any of these values to be simultaneously pruned. Next, each node of each agent is pruned
using the linear program shown in Table 9. If a distribution of nodes for the given agent has
higher value at each of the belief points for any initial nodes of the other agents’ controllers,
it is pruned and replaced with that distribution. The new controllers are then evaluated
and the value is compared with the value of the previous controller. This process of backing
up and pruning continues while the controller parameters continue to change.
Similar to how bounded policy updates can be used in conjunction with pruning in the
optimal policy iteration algorithm, a nonlinear programming approach (Amato et al., 2007)
can be used to improve solution quality for the heuristic case. To accomplish this, instead of
optimizing the controller for just the initial belief state of the problem, all the belief points
being considered are used. A simple way to achieve this is to maximize over the sum of
the values of the initial nodes of the controllers weighted by the probabilities given for each
point. This approach can be used after each pruning step and may further improve value
of the controllers.

6. Dynamic Programming Experiments
This section describes the results of experiments performed using policy iteration. Because
of the flexibility of the algorithm, it is impossible to explore all possible ways of implementing
it. However, we did experiment with a few different implementation strategies to gain an
idea of how the algorithm works in practice. All of these experiments were run on a 3.40GHz
Intel Pentium 4 with 2GB of memory. Three main sets of experiments were performed on
a single set of test problems.
118

Policy Iteration for DEC-POMDPs

Our first set of experiments focused on exhaustive backups and controller reductions.
The results confirm that value improvement can be obtained through iterated application of
these two operations. Further improvement is demonstrated by also incorporating bounded
updates. However, because exhaustive backups are expensive, the algorithm was unable to
complete more than a few iterations on any of our test problems.
In the second set of experiments, we addressed the complexity issues by using only
bounded backups, and no exhaustive backups. With bounded backups, we were able to
obtain higher-valued controllers while keeping memory requirements fixed. We examined
how the sizes of the initial local controllers and the correlation device affected the value of
the final solution.
The third set of experiments examined the complexity issues caused by exhaustive backups by using the point-based heuristic. This allowed our heuristic policy iteration algorithm
to complete more iterations than the optimal algorithm and in doing so, increased solution
quality of the largest solvable controllers. By incorporating Amato et al.’s NLP approach,
the heuristic algorithm becomes slightly less scalable than with heuristic pruning alone, but
the amount of value improvement per step increases. This causes the resulting controllers
in each domain to have the highest value of any approach.
6.1 Test Domains
In this section, we describe three test domains, ordered by the size of the problem representation. For each problem, the transition function, observation function, and reward
functions are described. In addition, an initial state is specified. Although policy iteration
does not require an initial state as input, one is commonly assumed and is used by the
heuristic version of the algorithm. A few different initial states were tried for each problem,
and qualitatively similar results were obtained. In all domains, a discount factor of 0.9 was
utilized.
As a very loose upper bound, the centralized policy was calculated for each problem in
which all agents share their observations with a central agent and decisions for all agents are
made by the central agent. This results in a POMDP with the same number of states, but
the action and observation sets are Cartesian products of the agents action and observation
sets. The value of this POMDP policy is provided below, but because DEC-POMDP policies
are more constrained, the optimal value may be much lower.
Two Agent Tiger Problem
The two agent tiger problem consists of 2 states, 3 actions and 2 observations (Nair et al.,
2003). The domain includes two doors, one of which leads to a tiger and the other to a large
treasure. Each agent may open one of the doors or listen. If either agent opens the door
with the tiger behind it, a large penalty is given. If the door with the treasure behind it is
opened and the tiger door is not, a reward is given. If both agents choose the same action
(i.e., both opening the same door) a larger positive reward or a smaller penalty is given to
reward cooperation. If an agent listens, a small penalty is given and an observation is seen
that is a noisy indication of which door the tiger is behind. While listening does not change
the location of the tiger, opening a door causes the tiger to be placed behind one of the
119

Bernstein, Amato, Hansen, & Zilberstein

door with equal probability. The problem begins with the tiger equally likely to be located
behind either door. The optimal centralized policy for this problem has value 59.817.
Meeting on a Grid
In this problem, with 16 states, 5 actions and 4 observations, two robots must navigate on a
two-by-two grid. Each robot can only sense whether there are walls to its left or right, and
their goal is to spend as much time as possible on the same square as the other agent. The
actions are to move up, down, left, or right, or to stay on the same square. When a robot
attempts to move to an open square, it only goes in the intended direction with probability
0.6, otherwise it either goes in another direction or stays in the same square. Any move
into a wall results in staying in the same square. The robots do not interfere with each
other and cannot sense each other. The reward is 1 when the agents share a square, and
0 otherwise. The initial state places the robots diagonally across from each other and the
optimal centralized policy for this problem has value 7.129.
Box Pushing Problem
This problem, with 100 states, 4 actions and 5 observations consists of two agents that
get rewarded by pushing different boxes (Seuken & Zilberstein, 2007). The agents begin
facing each other in the bottom corners of a four-by-three grid with the available actions of
turning right, turning left, moving forward or staying in place. There is a 0.9 probability
that the agent will succeed in moving and otherwise will stay in place, but the two agents
can never occupy the same square. The middle row of the grid contains one large box in the
middle of two small boxes. The small boxes can be moved by a single agent, but the large
box can only be moved by both agents pushing at the same time. The upper row of the
grid is considered the goal row, which the boxes are pushed into. The possible deterministic
observations for each agent consist of seeing an empty space, a wall, the other agent, a small
box or the large box. A reward of 100 is given if both agents push the large box to the
goal row and 10 is given for each small box that is moved to the goal row. A penalty of -5
is given for each agent that cannot move and -0.1 is given for each time step. Once a box
is moved to the goal row, the environment resets to the original start state. The optimal
centralized policy for this problem has value 183.936.
6.2 Exhaustive Backups and Controller Reductions
In this section, we present the results of using exhaustive backups together with controller
reductions. For each domain, the initial controllers for each agent contained a single node
with a self loop, and there was no correlation device. For each problem, the first action
of the problem description was used. This resulted in the repeated actions of opening the
left door in the two agent tiger problem, moving up in the meeting on a grid problem and
turning left in the box pushing problem. The reason for starting with the smallest possible
controllers was to see how many iterations we could complete before running out of memory.
On each iteration, we performed an exhaustive backup, and then alternated between
agents, performing controller reductions until no more nodes could be removed. For bounded
dynamic programming results, after the reductions were completed bounded updates were
also performed for all agents. For these experiments, we attempted to improve the nodes of
120

Policy Iteration for DEC-POMDPs

Iteration
0
1
2
3

Two Agent Tiger, |S| = 2, |Ai | = 3, |Ωi | = 2
Exhaustive Sizes
Controller Reductions
Bounded Updates
(1, 1)
-150 (1,1 in 1s)
-150 (1,1 in 1s)
(3, 3)
-137 (3,3 in 1s)
-20 (3,3 in 12s)
(27, 27)
-117.8 (15, 15 in 7s)
-20 (15, 15 in 89s)
(2187, 2187)
-98.9 (255, 255 in 1301s) -20* (255, 255 in 3145s)

Iteration
0
1
2

Meeting on a Grid, |S| = 16, |Ai | = 5, |Ωi | = 4
Exhaustive Sizes
Controller Reductions
Bounded Updates
(1, 1)
2.8 (1,1 in 1s)
2.8 (1,1 in 1s)
(5, 5)
3.4 (5,5 in 7s)
3.8 (5,5 in 145s)
(3125, 3125)
3.7 (80,80 in 821s)
4.78* (125,125 in 1204s)

Iteration
0
1
2

Box Pushing, |S| = 100, |Ai | = 4, |Ωi | = 5
Exhaustive Sizes
Controller Reductions
Bounded Updates
(1, 1)
-2 (1,1 in 4s)
-2 (1,1 in 53s)
(4, 4)
-2 (2,2 in 108s)
6.3 (2,2 in 132s)
(4096, 4096)
12.8 (9,9 in 755s)
42.7* (16,17 in 714s)

Table 10: Results of applying exhaustive backups, controller reductions and bounded updates to our test problems. The second column contains the sizes of the controllers
if only exhaustive backups had been performed. The third column contains the
resulting value, sizes of the controllers, and time required for controller reductions
to be performed on each iteration. The fourth column displays these same quantities with bounded updates also being used. The * denotes that a backup and
pruning were performed, but bounded updates exhausted the given resources.

each agent in turn until value could not be improved for any node of any agent. For each
iteration, we recorded the sizes of the controllers produced, and noted what the sizes would
be if no controller reductions had been performed. In addition, we recorded the value from
the initial state and the total time taken to reach the given result.
The results are shown in Table 10. Because exhaustive backups add many nodes, we
were unable to complete many iterations without exceeding memory limits. As expected,
the smallest problem led to the largest number of iterations being completed. Although
we could not complete many iterations before running out of memory, the use of controller
reductions led to significantly smaller controllers compared to the approach of just applying
exhaustive backups. Incorporating bounded updates requires some extra time, but is able
to improve the value produced at each step, causing substantial improvement in some cases.
It is also interesting to notice that the controller sizes when using bounded updates are
not always the same as when only controller reductions are completed. This can be seen
after two iterations in both the meeting on a grid and box pushing problems. This can
occur because the bounded updates change node value and thus change the number and
location of the nodes that are pruned. In the box pushing problem, the two agents also
121

Bernstein, Amato, Hansen, & Zilberstein

have different size controllers after two steps. This can occur, even in symmetric problems,
when a set of actions is only necessary for a single agent.
6.3 Bounded Dynamic Programming Updates
As we saw from the previous experiments, exhaustive backups can fill up memory very
quickly. This leads naturally to the question of how much improvement is possible without
exhaustive backups. In this section, we describe an experiment in which we repeatedly
applied bounded backups, which left the size of the controller fixed. We experimented with
different starting sizes for the local controllers and the correlation device.
We define a trial run of the algorithm as follows. At the start of a trial run, a size is
chosen for each of the local controllers and the correlation device. The action selection and
transition functions are initialized to be deterministic, with the outcomes drawn according
to a uniform distribution. A step consists of choosing a node uniformly at random from the
correlation device or one of the local controllers, and performing a bounded backup on that
node. After 200 steps, the run is considered over. In practice, we found that values often
stabilized in fewer steps.
We varied the sizes of the local controllers while maintaining the same number of nodes
for each agent, and we varied the size of the correlation device from 1 to 2. For each domain,
we increased number of nodes until the required number of steps could not be completed
in under four hours. In general, runs required significantly less time to terminate. For each
combination of sizes, we performed 20 trial runs and recorded the best value over all runs.
For each of the three problems, we were able to obtain solutions with higher value than
with exhaustive backups. Thus, we see that even though repeated application of bounded
backups does not have an optimality guarantee, it can be competitive with an algorithm that
does. However, it should be noted that we have not performed an exhaustive comparison.
We could have made different design decisions for both approaches concerning the starting
controllers, the order in which nodes are considered, and other factors.
Besides comparing to the exhaustive backup approach, we wanted to examine the effect
of the sizes of the local controllers and the correlation device on value. Figure 8 shows
a graph of best values plotted against controller size. We found that, for the most part,
the value increases when we increase the size of the correlation device from one node to
two nodes (essentially moving from independent to correlated). It is worth noting that the
solution quality had somewhat high variance in each problem, showing that setting good
initial parameters is important for high-valued solutions.
For small controllers, the best value tends to increase with controller size. However, for
very large controllers, this not always the case. This can be explained by considering how a
bounded backup works. For new node parameters to be acceptable, they must not decrease
the value for any combination of states, nodes for the other controllers, and nodes for the
correlation device. This becomes more difficult as the numbers of nodes increase, and thus
it is easier to get stuck in a local optimum. This can be readily seen in the two agent tiger
problem and to some extent the meeting on a grid problem. Memory was exhausted before
this phenomenon takes place in the box pushing problem.
122

Policy Iteration for DEC-POMDPs

(a)

(b)

(c)
Figure 8: Best value per trial run plotted against the size of the local controllers, for (a)
the two agent tiger problem, (b) the meeting in a grid problem and (c) the box
pushing problem. The solid line represents independent controllers (a correlation
device with one node), and the dotted line represents a joint controller including a
two-node correlation device. Times ranged from under 1s for one node controllers
without correlation to four hours for the largest controller found with correlation
in each problem.

6.4 Heuristic Dynamic Programming Updates
As observed above, the optimal dynamic programming approach can only complete a small
number of backups before resources are exhausted. Similarly, using bounded updates with
fixed size controllers can generate high value solutions, but it can be difficult to pick the
correct controller size and initial parameters. As an alternative to the other approaches, we
also present experiments using our heuristic dynamic programming algorithm.
Like the optimal policy iteration experiments, we initialized single node controllers for
each agent with self loops and no correlation device. The same first actions were used as
above and backups were performed until memory was exhausted. The set of belief points
for each problem was generated given the initial state distribution and a distribution of
actions for the other agents. For the meeting on a grid and box pushing problems, it was
123

Bernstein, Amato, Hansen, & Zilberstein

assumed that all agents chose any action with equal probability regardless of state. For the
two agent tiger problem, it was assumed that for any state agents listen with probability 0.8
and open each door with probability 0.1. This simple heuristic policy was chosen to allow
more of the state space to be sampled by our search. The number of belief points used for
the two agent tiger and meeting on a grid problems was ten and twenty points were used
for the box pushing problem.
For each iteration, we performed an exhaustive backup and then pruned controllers as
described in steps four and five of Table 8. All the nodes that contributed to the highest
value for each belief point were retained and then each node was examined using the linear
program in Table 9. For results with the NLP approach, we also improved the set of
controllers after heuristic pruning by optimizing a nonlinear program whose objective was
the sum of the values of the initial nodes weighted by the belief point probabilities. We
report the value produced by the optimal and heuristic approaches for each iteration that
could be completed in under four hours and with the memory limits of the machine used.
The nonlinear optimization was performed on the NEOS server, which provides a set of
machines with varying CPU speeds and memory limitations.
The values for each iteration of each problem are given in Figure 9. We see the heuristic policy iteration (HPI) methods are able to complete more iterations than the optimal
methods and as a consequence produce higher values. In fact, the results from HPI are
almost always exactly the same as those for the optimal policy iteration algorithm without
bounded updates for all iterations that can be completed by the optimal approach. Thus,
improvement occurs primarily due to the larger number of backups that can be performed.
We also see that while incorporating bounded updates improves value for the optimal
algorithm, incorporating the NLP approach into the heuristic approach produces even higher
value. Optimizing the NLP requires a small time overhead, but substantially increases
value on each iteration. This results in the highest controller value in each problem. Using
the NLP also allows our heuristic policy iteration to converge to a six node controller for
each agent in the two agent tiger problem. Unfortunately, this solution is known to be
suboptimal. As an heuristic algorithm, this is not unexpected, and it should be noted that
even suboptimal solutions by the heuristic approach outperform all other methods in all
our test problems.
6.5 Discussion
We have demonstrated how policy iteration can be used to improve both correlated and
independent joint controllers. We showed that using controller reductions together with
exhaustive backups is more efficient in terms of memory than using exhaustive backups
alone. However, due to the complexity of exhaustive backups, even that approach could
only complete a few iterations on each of our test problems.
Using bounded backups alone provided a good way to deal with the complexity issues.
With bounded backups, we were able to find higher-valued policies than with the previous
approach. Through our experiments, we were able to understand how the sizes of the local
controllers and correlation device affect the final values obtained.
With our heuristic policy iteration algorithm, we demonstrated further improvement by
dealing with some of the complexity issues. The heuristic approach is often able to continue
124

Policy Iteration for DEC-POMDPs

(a)

(b)

(c)
Figure 9: Comparison of the dynamic programming algorithms on (a) the two agent tiger
problem, (b) the meeting in a grid problem and (c) the box pushing problem.
The value produced by policy iteration with and without bounded backups as
well as our heuristic policy iteration with and without optimizing the NLP were
compared on each iteration until the time or memory limit was reached.

improving solution quality past the point where the optimal algorithm exhausts resources.
More efficient use of this limited representation size is achieved by incorporating the NLP
approach as well. In fact, the heuristic algorithm with NLP improvements at each step
provided results that are at least equal to the highest value obtained in each problem and
sometimes were markedly higher than the other approaches. Furthermore, as far as we
know, these results are the highest published values for all three of the test domains.

7. Conclusion
We present a policy iteration algorithm for DEC-POMDPs. The algorithm uses a novel policy representation consisting of stochastic finite-state controllers for each agent along with
a correlation device. We define value-preserving transformations and show that alternating
between exhaustive backups and value-preserving transformations leads to convergence to
125

Bernstein, Amato, Hansen, & Zilberstein

optimality. We also extend controller reductions and bounded backups from the single agent
case to the multiagent case. Both of these operations are value-preserving transformations
and are provably efficient. Finally, we introduced a heuristic version of our algorithm which
is more scalable and produces higher values on our test problems. Our algorithm serves as
the first nontrivial exact algorithm for DEC-POMDPs, and provides a bridge to the large
body of work on dynamic programming for POMDPs.
Our work provides a solid foundation for solving DEC-POMDPs, but much work remains
in addressing more challenging problem instances. We focused on solving general DECPOMDPs, but the efficiency of our approaches could be improved by using structure found
in certain problems. This would allow specialized representations and solution techniques
to be incorporated. Below we describe some key challenges of our general approach, along
with some preliminary algorithmic ideas to extend our work on policy iteration.
Approximation with Error Bounds Often, strict optimality requirements cause computational difficulties. A good compromise is to search for policies that are within some
bound of optimal. Our framework is easily generalized to allow for this.
Instead of a value-preserving transformation, we could define an -value-preserving transformation, which insures that the value at all states decreases by at most . We can perform
such transformations with no modifications to any of our linear programs. We simply need
to relax the requirement on the value for  that is returned. It is easily shown that using
an -value-preserving transformation at each step leads to convergence to a policy that is
β
within 1−β
of optimal for all states.
For controller reductions, relaxing the tolerance may lead to smaller controllers because
some value can be sacrificed. For bounded backups, it may help in escaping from local
optima. Though relaxing the tolerance for a bounded backup could lead to a decrease in
value for some states, a small “downward” step could lead to higher value overall in the
long run. We are currently working on testing these hypotheses empirically.
General-Sum Games In a general-sum game, there is a set of agents, each with its own
set of strategies, and a strategy profile is defined to be a tuple of strategies for all agents.
Each agent assigns a payoff to each strategy profile. The agents may be noncooperative, so
the same strategy profile may be assigned different values for each agent.
The DEC-POMDP model can be extended to a general-sum game by allowing each
agent to have its own reward function. In this case, the strategies are the local policies, and
a strategy profile is a joint policy. This model is often called a partially observable stochastic
game (POSG). Hansen et al. (2004) presented a dynamic programming algorithm for finitehorizon POSGs. The algorithm was shown to perform iterated elimination of dominated
strategies in the game. Roughly speaking, it eliminates strategies that are not useful for an
agent, regardless of the strategies of the other agents.
Work remains to be done on extending the notion of a value-preserving transformation
to the noncooperative case. One possibility is to redefine value-preserving transformations
so that value is preserved for all agents. This is closely related to the idea of Pareto
optimality. In a general-sum game, a strategy profile is said to be Pareto optimal if there
does not exist another strategy profile that yields higher payoff for all agents. It seems that
policy iteration using the revised definition of value-preserving transformation would tend
to move the controller in the direction of the Pareto optimal set. Another possibility is
126

Policy Iteration for DEC-POMDPs

to define value-preserving transformations with respect to specific agents. As each agent
transforms its own controller, the joint controller should move towards a Nash equilibrium.
Handling Large Numbers of Agents The general DEC-POMDP representation presented in this paper grows exponentially with the number of agents, as seen in the growth
of the set of joint actions and observations as well as the transition, reward and observation
functions. Thus this representation is not feasible for large numbers of agents. However,
a compact representation is possible if each agent interacts directly with just a few other
agents. We can have a separate state space for each agent, factored transition probabilities,
and a reward function that is the sum of local reward functions for clusters of agents. In
this case, the problem size is exponential only in the maximum number of agents interacting
directly. This idea is closely related to recent work on graphical games (La Mura, 2000;
Koller & Milch, 2003).
Once we have a compact representation, the next question to answer is whether we
can adapt policy iteration to work efficiently with the representation. This indeed seems
possible. With the value-preserving transformations we presented, the nodes of the other
agents are considered part of the hidden state of the agent under consideration. These
techniques modify the controller of the agent to get value improvement for all possible
hidden states. When an agent’s state transitions and rewards do not depend on some other
agent, it should not need to consider that agent’s nodes as part of its hidden state. A
specific compact representation along with extensions of different algorithms was proposed
by Nair et al. (2005).

Acknowledgments
We thank Martin Allen, Marek Petrik and Siddharth Srivastava for helpful discussions of
this work. Marek and Siddharth, in particular, helped formalize and prove Theorem 1. The
anonymous reviewers provided valuable feedback and suggestions. Support for this work
was provided in part by the National Science Foundation under grants IIS-0535061 and
IIS-0812149, by NASA under cooperative agreement NCC-2-1311, and by the Air Force
Office of Scientific Research under grants F49620-03-1-0090 and FA9550-08-1-0181.

Appendix A. Proof of Theorem 1
A correlation device produces a sequence of values that all the agents can observe. Let X
be the set of all possible infinite sequences that can be generated by a correlation device.
Let Vx (~q0 , s0 ) be the value of the correlated joint controller with respect to some correlation
sequence x ∈ X, initial nodes ~q0 of the agent controllers, and initial state s0 of the problem.
We will refer to Vx (~q0 , s0 ) simply as Vx – the value of some sequence x, given the controllers
for the agents. We define a regular sequence as a sequence that can be generated by a
regular expression. Before we prove Theorem 1, we establish the following property.
Lemma 2 The value of any sequence, whether regular or non-regular, can be approximated
within any  by some other sequence.
Proof: The property holds thanks to the discount factor used in infinite-horizon DECPOMDPs. Given a sequence x with value Vx , we can determine another sequence x0 such
127

Bernstein, Amato, Hansen, & Zilberstein

that |Vx0 − Vx | < . The sequence x0 is constructed by choosing the first k elements of x,
and then choosing an arbitrary regular or non-regular sequence for the remaining elements.
kR
max
As long as k is chosen such that  ≥ β(1−β)
, then |Vx0 − Vx | < . 2
Theorem 1 Given an initial state and a correlated joint controller, there always exists
some finite-size joint controller without a correlation device that produces at least the same
value for the initial state.
Proof: Let E represent the expected value of the joint controller with the correlation
device. Let V = {Vx | x ∈ X} be the set of values produced by all the possible correlation
device sequences. Let inf and sup represent the infimum and supremum of V respectively.
We break the proof into two cases, depending on the relation of the expectation versus
the supremum. We show in each case that a regular sequence can be found that produces
at least the same value as E. Once such a regular sequence is found, then that sequence can
be generated by a finite-state controller that can be embedded within each agent. Thus, a
finite number of nodes can be added to the agents’ controllers to provide equal or greater
value, without using a correlation device.
Case (1) inf ≤ E < sup
Based on Lemma 2, there is some regular sequence x that can approximate the supremum
within . If we choose  = sup −E, then Vx ≥ sup − = E.
Case (2) E = sup
If there is a regular sequence, x, for which Vx = E, we can choose that sequence. If no
such regular sequence exists, we will show that E 6= sup. We give a somewhat informal
argument, but this can be more formally proven using cylinder sets as discussed by Parker
(2002). We begin by first choosing some regular sequence. We can construct a neighborhood around this sequence (as described in Lemma 2) by choosing a fixed length prefix
of
A prefixP
of length k has a well-defined probability that is defined as
P the sequence.
P
0)
1 |q 0 ) . . .
k−1 |q k−2 ) where P (q 0 ) is the probability distribution
P
(q
P
(q
c
c c
c
c
qc0
qc1
qck−1 P (qc
of initial node of the correlation device and P (qci |qci−1 ) represents the probability of transitioning to correlation device node qci from node qci−1 . The set of sequences that possess this
prefix has probability equal to that of the prefix. Because we assumed there exists some
regular sequence which has value less than the supremum, we can always choose a prefix
and length such that the values of the sequences in the set are less than the supremum.
Because the probability of this set is nonzero and the value of these sequences is less than
the supremum, then E 6= sup, which is a contradiction.
Therefore, some regular sequence can be found that provides at least the same value as
the expected value of the correlated joint controller. This allows some uncorrelated joint
controller to produce at least the same value as a given correlated one. 2

Appendix B. Proof of Lemma 1
For ease of exposition, we prove the lemma under the assumption that there is no correlation
device. Including a correlation device is straightforward but unnecessarily tedious.
128

Policy Iteration for DEC-POMDPs

Lemma 1 Let C and D be correlated joint controllers, and let Ĉ and D̂ be the results of
performing exhaustive backups on C and D, respectively. Then Ĉ ≤ D̂ if C ≤ D.
Proof: Suppose we are given controllers C and D, where C ≤ D. Call the sets of joint
~ and R,
~ respectively. It follows that there exists a function
nodes for these controllers Q
~
fi : Qi → ∆Ri for each agent i such that for all s ∈ S and ~q ∈ Q
V (s, ~q) ≤

X

P (~r|~q)V (s, ~r).

~
r

We now define functions fˆi to map between the two controllers Ĉ and D̂. For the old
nodes, we define fˆi to produce the same output as fi . It remains to specify the results of fˆi
applied to the nodes added by the exhaustive backup. New nodes of Ĉ will be mapped to
distributions involving only new nodes of D̂.
To describe the mapping formally, we need to introduce some new notation. Recall that
the new nodes are all deterministic. For each new node ~r in controller D̂, the node’s action
is denoted ~a(~r), and its transition rule is denoted ~r 0 (~r, ~o). Now, the mappings fˆi are defined
such that
P (~r|~q) = P (~a(~r)|~q)

YX

P (~q 0 |~q, ~a(~r), ~o)P (~r 0 (~r, ~o)|~q 0 )

q~ 0

~
o

for all ~q in controller Ĉ and ~r in controller D̂.
We must now show that the mapping fˆ satisfies the inequality given in the definition
of a value-preserving transformation. For the nodes that were not added by the exhaustive
backup, this is straightforward. For the new nodes ~q of the controller Ĉ, we have for all
s ∈ S,

V (s, ~q) =

X

P (~a|~q) R(s, ~a) +


X

P (s0 , ~o|s, ~a)P (~q 0 |~q, ~a, ~o)V (s0 , ~q 0 )

~
o,s0 ,~
q0

~a




≤

X

P (~a|~q) R(s, ~a) +

X

P (s0 , ~o|s, ~a)P (~q 0 |~q, ~a, ~o)

~
o,s0 ,~
q0

~a

X

P (~r 0 |~q 0 )V (s0 , ~r 0 )

~
r0


=

X

P (~a|~q) R(s, ~a) +


X

P (s0 , ~o|s, ~a)P (~q 0 |~q, ~a, ~o)P (~r 0 |~q 0 )V (s0 , ~r 0 )

~
o,s0 ,~
q 0 ,~
r0

~a


=

X

=

X

P (~r|~q) R(s, ~a(~r)) +


X

P (s0 , ~o|s, ~a(~r))V (s0 , ~r 0 (~r, ~o))

~
o,s0

~
r

P (~r|~q)V (s, ~r).

~
r

2
129

Bernstein, Amato, Hansen, & Zilberstein

References
Amato, C., Bernstein, D. S., & Zilberstein, S. (2007). Optimizing memory-bounded controllers for decentralized POMDPs. In Proceedings of the Twenty-Third Conference
on Uncertainty in Artificial Intelligence.
Astrom, K. J. (1965). Optimal control of Markov decision processes with incomplete state
estimation. Journal of Mathematical Analysis and Applications, 10, 174–205.
Aumann, R. J. (1974). Subjectivity and correlation in randomized strategies. Journal of
Mathematical Economics, 1, 67–96.
Bernstein, D. S., Givan, R., Immerman, N., & Zilberstein, S. (2002). The complexity of decentralized control of Markov decision processes. Mathematics of Operations Research,
27 (4), 819–840.
Bernstein, D. S., Hansen, E. A., & Zilberstein, S. (2005). Bounded policy iteration for decentralized POMDPs. In Proceedings of the Nineteenth International Joint Conference
on Artificial Intelligence, pp. 1287–1292.
Bonet, B., & Geffner, H. (2000). Planning with incomplete information as heuristic search
in belief space. In Proceedings of the Fifth International Conference on AI Planning
and Scheduling, pp. 52–61.
Cassandra, A., Littman, M. L., & Zhang, N. L. (1997). Incremental pruning: A simple, fast,
exact method for partially observable Markov decision processes. In Proceedings of
the Thirteenth Annual Conference on Uncertainty in Artificial Intelligence, pp. 54–61.
Cheng, H.-T. (1988). Algorithms for Partially Observable Markov Decision Processes. Ph.D.
thesis, University of British Columbia.
Emery-Montemerlo, R., Gordon, G., Schnieder, J., & Thrun, S. (2004). Approximate solutions for partially observable stochastic games with common payoffs. In Proceedings
of the Third International Joint Conference on Autonomous Agents and Multi Agent
Systems, pp. 136–143.
Feng, Z., & Zilberstein, S. (2004). Region-based incremental pruning for POMDPs. In
Proceedings of the Twentieth Conference on Uncertainty in Artificial Intelligence, pp.
146–153.
Feng, Z., & Zilberstein, S. (2005). Efficient maximization in solving POMDPs. In Proceedings of the Twentieth National Conference on Artificial Intelligence, pp. 975–980.
Hansen, E. (1998a). Solving POMDPs by searching in policy space. In Proceedings of the
Fourteenth Annual Conference on Uncertainty in Artificial Intelligence, pp. 211–219.
Hansen, E. A. (1998b). Finite-Memory Control of Partially Observable Systems. Ph.D.
thesis, University of Massachusetts Amherst, Amherst, Massachusetts.
Hansen, E. A., Bernstein, D. S., & Zilberstein, S. (2004). Dynamic programming for partially
observable stochastic games. In Proceedings of the Nineteenth National Conference
on Artificial Intelligence, pp. 709–715.
Ji, S., Parr, R., Li, H., Liao, X., & Carin, L. (2007). Point-based policy iteration. In
Proceedings of the Twenty-Second National Conference on Artificial Intelligence, pp.
1243–1249.
130

Policy Iteration for DEC-POMDPs

Kaelbling, L. P., Littman, M. L., & Cassandra, A. R. (1998). Planning and acting in
partially observable stochastic domains. Artificial Intelligence, 101 (1-2), 99–134.
Koller, D., & Milch, B. (2003). Multi-agent influence diagrams for representing and solving
games. Games and Economic Behavior, 45 (1), 181–221.
La Mura, P. (2000). Game networks. In Proceedings of the Sixteenth Conference on Uncertainty in Artificial Intelligence, pp. 335–342.
Lark III, J. W. (1990). Applications of Best-First Heuristic Search to Finite-Horizon Partially Observed Markov Decision Processes. Ph.D. thesis, University of Virginia.
Littman, M. L., Cassandra, A. R., & Kaelbling, L. P. (1995). Learning policies for partially
observable environments: Scaling up. In Proceedings of the Twelfth International Conference on Machine Learning, pp. 362–370.
Nair, R., Pynadath, D., Yokoo, M., Tambe, M., & Marsella, S. (2003). Taming decentralized
POMDPs: Towards efficient policy computation for multiagent settings. In Proceedings
of the Eighteenth International Joint Conference on Artificial Intelligence, pp. 705–
711.
Nair, R., Varakantham, P., Tambe, M., & Yokoo, M. (2005). Networked distributed
POMDPs: A synthesis of distributed constraint optimization and POMDPs. In Proceedings of the Twentieth National Conference on Artificial Intelligence, pp. 133–139.
Parker, D. A. (2002). Implementation of Symbolic Model Checking for Probabilistic Systems.
Ph.D. thesis, University of Birmingham, Birmingham, England.
Peshkin, L., Kim, K.-E., Meuleau, N., & Kaelbling, L. P. (2000). Learning to cooperate via
policy search. In Proceedings of the Sixteenth International Conference on Uncertainty
in Artificial Intelligence, pp. 489–496.
Pineau, J., Gordon, G., & Thrun, S. (2003). Point-based value iteration: An anytime algorithm for POMDPs. In Proceedings of the Eighteenth International Joint Conference
on Artificial Intelligence, pp. 1025–1031.
Platzman, L. K. (1980). A feasible computational approach to infinite-horizon partiallyobserved Markov decision processes. Tech. rep., Georgia Institute of Technology.
Reprinted in Working Notes of the 1998 AAAI Fall Symposium on Planning Using
Partially Observable Markov Decision Processes.
Poupart, P., & Boutilier, C. (2003). Bounded finite state controllers. In Proceedings of
Advances in Neural Information Processing Systems 16.
Seuken, S., & Zilberstein, S. (2007). Improved memory-bounded dynamic programming for
decentralized POMDPs. In Proceedings of the Twenty-Third Conference on Uncertainty in Artificial Intelligence.
Simmons, R., & Koenig, S. (1995). Probabilistic navigation in partially observable environments. In Proceedings of the Fourteenth International Joint Conference on Artificial
Intelligence, pp. 1080–1087.
Singh, S. (1994). Learning to Solve Markovian Decision Processes. Ph.D. thesis, University
of Massachusetts, Amherst, Massachusetts.
131

Bernstein, Amato, Hansen, & Zilberstein

Singh, S. P., Jaakkola, T., & Jordan, M. I. (1994). Learning without state-estimation in
partially observable markovian decision processes. In Proceedings of the Eleventh
International Conference on Machine Learning, pp. 284–292.
Smallwood, R. D., & Sondik, E. J. (1973). The optimal control of partially observable
Markov processes over a finite horizon. Operations Research, 21 (5), 1071–1088.
Smith, T., & Simmons, R. (2005). Point-based POMDP algorithms: Improved analysis and
implementation. In Proceedings of the Twenty-First Conference on Uncertainty in
Artificial Intelligence, pp. 542–547.
Smith, T., Thompson, D. R., & Wettergreen, D. S. (2007). Generating exponentially smaller
POMDP models using conditionally irrelevant variable abstraction. In Proceedings of
the Seventeenth International Conference on Applied Planning and Scheduling.
Sondik, E. J. (1978). The optimal control of partially observable Markov processes over the
infinite horizon: Discounted costs. Operations Research, 26, 282–304.
Szer, D., & Charpillet, F. (2005). An optimal best-first search algorithm for solving infinite
horizon DEC-POMDPs. In Proceedings of the Sixteenth European Conference on
Machine Learning, pp. 389–399.
Szer, D., & Charpillet, F. (2006). Point-based dynamic programming for DEC-POMDPs.
In Proceedings of the Twenty-First National Conference on Artificial Intelligence, pp.
1233–1238.
Szer, D., Charpillet, F., & Zilberstein, S. (2005). MAA*: A heuristic search algorithm for
solving decentralized POMDPs. In Proceedings of the Twenty-First Conference on
Uncertainty in Artificial Intelligence, pp. 576–590.
Witsenhausen, H. S. (1971). Separation of estimation and control for discrete time systems.
Proceedings of the IEEE, 59 (11), 1557–1566.
Zhang, N. L., & Lee, S. S. (1998). Planning with partially observable Markov decision
processes: Advances in exact solution methods. In Proceedings of the Fourteenth
Conference on Uncertainty in Artificial Intelligence, pp. 523–530.
Zhang, N. L., & Zhang, W. (2001). Speeding up the convergence of value iteration in partially observable Markov decision processes. Journal of Artificial Intelligence Research,
14, 29–51.

132

Journal of Artificial Intelligence Research 34 (2009) 27–59

Submitted 12/07; published 01/09

A Heuristic Search Approach to Planning
with Continuous Resources in Stochastic Domains
Nicolas Meuleau

nicolas.f.meuleau@nasa.gov

NASA Ames Research Center
Mail Stop 269-3
Moffet Field, CA 94035-1000, USA

Emmanuel Benazera

ebenazer@laas.fr

LAAS-CNRS, Université de Toulouse
7, av. du Colonel Roche
31077 Toulouse Cedex 4, France

Ronen I. Brafman

brafman@cs.bgu.ac.il

Department of Computer Science
Ben-Gurion University
Beer-Sheva 84105, Israel

Eric A. Hansen

hansen@cse.msstate.edu

Department of Computer Science and Engineering
Mississippi State University
Mississippi State, MS 39762, USA

Mausam

mausam@cs.washington.edu

Department of Computer Science and Engineering
University of Washington
Seattle, WA 981952350, USA

Abstract
We consider the problem of optimal planning in stochastic domains with resource constraints,
where the resources are continuous and the choice of action at each step depends on resource availability. We introduce the HAO* algorithm, a generalization of the AO* algorithm that performs
search in a hybrid state space that is modeled using both discrete and continuous state variables, where the continuous variables represent monotonic resources. Like other heuristic search
algorithms, HAO* leverages knowledge of the start state and an admissible heuristic to focus
computational effort on those parts of the state space that could be reached from the start state
by following an optimal policy. We show that this approach is especially effective when resource
constraints limit how much of the state space is reachable. Experimental results demonstrate
its effectiveness in the domain that motivates our research: automated planning for planetary
exploration rovers.

1. Introduction
Many NASA planetary exploration missions rely on rovers – mobile robots that carry a suite of
scientific instruments for use in characterizing planetary surfaces and transmitting information back
to Earth. Because of difficulties in communicating with devices on distant planets, direct human
control of rovers by tele-operation is infeasible, and rovers must be able to act autonomously for
substantial periods of time. For example, the Mars Exploration Rovers (MER), aka, Spirit and
Opportunity, are designed to communicate with the ground only twice per Martian day.
Autonomous control of planetary exploration rovers presents many challenges for research in
automated planning. Progress has been made in meeting some of these challenges. For example, the
planning software developed for the Mars Sojourner and MER rovers has contributed significantly

c
2009
AI Access Foundation. All rights reserved.

Meuleau, Benazera, Brafman, Hansen & Mausam

to the success of these missions (Bresina, Jonsson, Morris, & Rajan, 2005). But many important
challenges must still be addressed to achieve the more ambitious goals of future missions (Bresina,
Dearden, Meuleau, Ramakrishnan, Smith, & Washington, 2002).
Among these challenges is the problem of plan execution in uncertain environments. On planetary
surfaces such as Mars, there is uncertainty about the terrain, meteorological conditions, and the state
of the rover itself (position, battery charge, solar panels, component wear, etc.) In turn, this leads
to uncertainty about the outcome of the rover’s actions. Much of this uncertainty is about resource
consumption. For example, factors such as slope and terrain affect speed of movement and rate of
power consumption, making it difficult to predict with certainty how long it will take for a rover
to travel between two points, or how much power it will consume in doing so. Because of limits
on critical resources such as time and battery power, rover plans are currently very conservative
and based on worst-case estimates of time and resource usage. In addition, instructions sent to
planetary rovers are in the form of a sequential plan for attaining a single goal (e.g., photographing
an interesting rock). If an action has an unintended outcome that causes a plan to fail, the rover
stops and waits for further instructions; it makes no attempt to recover or achieve an alternative
goal. This can result in under-utilized resources and missed science opportunities.
Over the past decade, there has been a great deal of research on how to generate conditional
plans in domains with uncertain action outcomes. Much of this work is formalized in the framework
of Markov decision processes (Puterman, 1994; Boutilier, Dean, & Hanks, 1999). However, as
Bresina et al. (2002) point out, important aspects of the rover planning problem are not adequately
handled by traditional planning algorithms, including algorithms for Markov decision processes. In
particular, most traditional planners assume a discrete state space and a small discrete number of
action outcomes. But in automated planning for planetary exploration rovers, critical resources such
as time and battery power are continuous, and most of the uncertainty in the domain results from
the effect of actions on these variables. This requires a conditional planner that can branch not
only on discrete action outcomes, but on the availability of continuous resources, and such a planner
must be able to reason about continuous as well as discrete state variables.
Closely related to the challenges of uncertain plan execution and continuous resources is the
challenge of over-subscription planning. The rovers of future missions will have much improved
capabilities. Whereas the current MER rovers require an average of three days to visit a single rock,
progress in areas such as automatic instrument placement will allow rovers to visit multiple rocks
and perform a large number of scientific observations in a single communication cycle (Pedersen,
Smith, Deans, Sargent, Kunz, Lees, & Rajagopalan, 2005). Moreover, communication cycles will
lengthen substantially in more distant missions to the moons of Jupiter and Saturn, requiring longer
periods of autonomous behavior. As a result, space scientists of future missions are expected to
specify a large number of science goals at once, and often this will present what is known as an oversubscription planning problem. This refers to a problem in which it is infeasible to achieve all goals,
and the objective is to achieve the best subset of goals within resource constraints (Smith, 2004). In
the case of the rover, there will be multiple locations the rover could reach, and many experiments
the rover could conduct, most combinations of which are infeasible due to resource constraints. The
planner must select a feasible subset of these that maximizes expected science return. When action
outcomes (including resource consumption) are stochastic, a plan that maximizes expected science
return will be a conditional plan that prescribes different courses of action based on the results of
previous actions, including resource availability.
In this paper, we present an implemented planning algorithm that handles all of these problems
together: uncertain action outcomes, limited continuous resources, and over-subscription planning.
We formalize the rover planning problem as a hybrid-state Markov decision process, that is, a Markov
decision process (MDP) with both discrete and continuous state variables, and we use the continuous
variables to represent resources. The planning algorithm we introduce is a heuristic search algorithm
called HAO*, for Hybrid-state AO*. It is a generalization of the classic AO* heuristic search algorithm (Nilsson, 1980; Pearl, 1984). Whereas AO* searches in discrete state spaces, HAO* solves

28

HAO*

planning problems in hybrid domains with both discrete and continuous state variables. To handle
hybrid domains, HAO* builds on earlier work on dynamic programming algorithms for continuous
and hybrid-state MDPs, in particular, the work of Feng et al. (2004).
Generalizing AND/OR graph search for hybrid state spaces poses a complex challenge, and we
only consider a special case of the problem. In particular, continuous variables are used to represent
monotonic resources. The search is for the best conditional plan that allows branching not only on
the values of the discrete variables, but on the availability of these resources, and does not violate a
resource constraint.
It is well-known that heuristic search can be more efficient than dynamic programming because it
uses reachability analysis guided by a heuristic to focus computation on the relevant parts of the state
space. We show that for problems with resource constraints, including over-subscription planning
problems, heuristic search is especially effective because resource constraints can significantly limit
reachability. Unlike dynamic programming, a systematic forward search algorithm such as AO* keeps
track of the trajectory from the start state to each reachable state, and thus it can check whether the
trajectory is feasible or violates a resource constraint. By pruning infeasible trajectories, a heuristic
search algorithm can dramatically reduce the number of states that must be considered to find an
optimal policy. This is particularly important in our domain where the discrete state space is huge
(exponential in the number of goals), and yet the portion reachable from any initial state is relatively
small, due to resource constraints.

2. Problem Formulation and Background
We start with a formal definition of the planning problem we are tackling. It is a special case of
a hybrid-state Markov decision process, and so we first define this model. Then we discuss how
to include resource constraints and formalize over-subscription planning in this model. Finally we
review a class of dynamic programming algorithms for solving hybrid-state MDPs, since some of
these algorithmic techniques will be incorporated in the heuristic search algorithm we develop in
Section 3.
2.1 Hybrid-State Markov Decision Process
A hybrid-state Markov decision process, or hybrid-state MDP, is a factored Markov decision process
that has both discrete and continuous state variables. We define it as a tuple (N, X, A, P, R), where
N is a discrete state variable, X = {X1 , X2 , ..., Xd } is a set of continuous state variables, A is a set
of actions, P is a stochastic state transition model, and R is a reward function. We describe these
elements in more detail below. A hybrid-state MDP is sometimes referred to as simply a hybrid
MDP. The term “hybrid” does not refer to the dynamics of the model, which are discrete. Another
term for a hybrid-state MDP, which originates in the Markov chain literature, is a general-state
MDP.
Although a hybrid-state MDP can have multiple discrete variables, this plays no role in the algorithms described in this paper, and so, for notational convenience, we model the discrete component
of the state space as a single variable N . Our focus is on the continuous component. We assume
N the
domain of each continuous variable Xi ∈ X is a closed interval of the real line, and so X = i Xi
is the hypercube over which the continuous variables are defined. The state set S of a hybrid-state
MDP is the set of all possible assignments of values to the state variables. In particular, a hybrid
state s ∈ S is a pair (n, x) where n ∈ N is the value of the discrete variable, and x = (xi ) is a vector
of values of the continuous variables.
State transitions occur as a result of actions, and the process evolves according to Markovian
state transition probabilities Pr(s0 | s, a), where s = (n, x) denotes the state before action a and
s0 = (n0 , x0 ) denotes the state after action a, also called the arrival state. These probabilities can be
decomposed into:

29

Meuleau, Benazera, Brafman, Hansen & Mausam

• the discrete marginals Pr(n0 |n, x, a). For all (n, x, a),

Pr(n0 |n, x, a) = 1;
R
• the continuous conditionals Pr(x0 |n, x, a, n0 ). For all (n, x, a, n0 ), x0 ∈X Pr(x0 |n, x, a, n0 )dx0 =
1.
P

n0 ∈N

We assume the reward associated with a transition is a function of the arrival state only, and let
Rn (x) denote the reward associated with a transition to state (n, x). More complex dependencies
are possible, but this is sufficient for the goal-based domain models we consider in this paper.
2.2 Resource Constraints and Over-Subscription Planning
To model the rover planning problem, we consider a special type of MDP in which the objective
is to optimize expected cumulative reward subject to resource constraints. We make the following
assumptions:
• there is an initial allocation of one or more non-replenishable resources,
• each action has some minimum positive consumption of at least one resource, and
• once resources are exhausted, no further action can be taken.
One way to model an MDP with resource constraints is to formulate it as a constrained MDP,
a model that has been widely studied in the operations research community (Altman, 1999). In
this model, each action a incurs a transition-dependent resource cost, Cai (s, s0 ), for each resource
i. Given an initial allocation of resources and an initial state, linear programming is used to find
the best feasible policy, which may be a randomized policy. Although a constrained MDP models
resource consumption, it does not include resources in the state space. As a result, a policy cannot
be conditioned upon resource availability. This is not a problem if resource consumption is either
deterministic or unobservable. But it is not a good fit for the rover domain, in which resource
consumption is stochastic and observable, and the rover should take different actions depending on
current resource availability.
We adopt a different approach to modeling resource constraints in which resources are included
in the state description. Although this increases the size of the state space, it allows decisions to be
made based on resource availability, and it allows a stochastic model of resource consumption. Since
resources in the rover domain are continuous, we use the continuous variables of a hybrid-state MDP
to represent resources. Note that the duration of actions is one of the biggest sources of uncertainty
in our rover problems, and we model time as one of the continuous resources. Resource constraints
are represented in the form of executability constraints on actions, where An (x) denotes the set of
actions executable in state (n, x). An action cannot be executed in a state that does not satisfy its
minimum resource requirements.
Having discussed how to incorporate resource consumption and resource constraints in a hybridstate MDP, we next discuss how to formalize over-subscription planning. In our rover planning
problem, scientists provide the planner with a set of “goals” they would like the rover to achieve,
where each goal corresponds to a scientific task such as taking a picture of a rock or performing an
analysis of a soil sample. The scientists also specify a utility or reward for each goal. Usually only
a subset of these goals is feasible under resource constraints, and the problem is to find a feasible
plan that maximizes expected utility. Over-subscription planning for planetary exploration rovers
has been considered by Smith (2004) and van den Briel et al. (2004) for deterministic domains.
We consider over-subscription planning in stochastic domains, especially domains with stochastic
resource consumption. This requires construction of conditional plans in which the selection of goals
to achieve can change depending on resource availability.
In over-subscription planning, the utility associated with each goal can be achieved only once; no
additional utility is achieved for repeating the task. Therefore, the discrete state must include a set
of Boolean variables to keep track of the set of goals achieved so far by the rover, with one Boolean
30

HAO*

variable for each goal. Keeping track of already-achieved goals ensures a Markovian reward structure,
since achievement of a goal is rewarded only if it was not achieved in the past. However, it also
significantly increases the size of the discrete state space. Maintaining history information to ensure a
Markovian reward structure is a simple example of planning with non-Markovian rewards (Thiebaux,
Gretton, Slaney, Price, & Kabanza, 2006).
2.3 Optimality Equation
The rover planning problem we consider is a special case of a finite-horizon hybrid-state MDP in
which termination occurs after an indefinite number of steps. The Bellman optimality equation for
this problem takes the following form:
Vn (x)

=

Vn (x)

=

0 when (n, x) is a terminal state; otherwise,
"

Z
X
max
Pr(n0 | n, x, a)
Pr(x0 | n, x, a, n0 ) (Rn0 (x0 ) + Vn0 (x0 )) dx0 .

a∈An (x)

n0 ∈N

(1)

x0

We define a terminal state as a state in which no actions are eligible to execute, that is, An (x) = ∅.
We use terminal states to model various conditions for plan termination. This includes the situation
in which all goals have been achieved; the situation in which resources have been exhausted; and the
situation in which an action results in some error condition that requires executing a safe sequence
by the rover and terminating plan execution. In addition to terminal states, we assume an explicit
initial state denoted (n0 , x0 ).
Assuming that resources are limited and non-replenishable, and that every action consumes
some resource (and the amount consumed is greater than or equal to some positive quantity c), plan
execution will terminate after a finite number of steps. The maximum number of steps is bounded by
the initial resource allocation divided by c, the minimal resource consumption per step. The actual
number of steps is usually much less and indefinite, because resource consumption is stochastic and
because the choice of action influences resource consumption. Because the number of steps it takes
for a plan to terminate is bounded but indefinite, we call this a bounded-horizon MDP in contrast
to a finite-horizon MDP. However, we note that any bounded-horizon MDP can be converted to a
finite-horizon MDP by specifying a horizon that is equal to the maximum number of plan steps, and
introducing a no-op action that is taken in any terminal state.
Note that there is usually a difference between the number of plan steps and the time a plan takes
to execute. Since we model time as one of the continuous resources, the time it takes to execute a
plan step is both state and action dependent, and stochastic.
Given a hybrid-state MDP with a set of terminal states and an initial state (n0 , x0 ), the objective
is to find a policy, π : (N × X) → A, that maximizes expected cumulative reward; specifically, an
optimal policy has a value function that satisfies the optimality equation given by Equation (1). In
our rover domain, cumulative reward is equal to the sum of rewards for the goals achieved before
reaching a terminal state and there is no direct incentive to save resources; an optimal solution saves
resources only if this allows achieving more goals. However, our framework is general enough to
allow reasoning about both the cost and the availability of resources. For example, an incentive for
conserving resources could be modeled by specifying a reward that is proportional to the amount of
resources left unused upon entering the terminal state. Note that our framework allows reasoning
about both the cost and availability of resources without needing to formulate this as a problem of
multi-objective optimization, and we stay in a standard decision-theoretic framework.
2.4 Dynamic Programming for Continuous-State and Hybrid-State MDPs
Because the planning problem we consider is a finite-horizon hybrid-state MDP, it can be solved
by any algorithm for solving finite-horizon hybrid-state MDPs. Most algorithms for solving hybridstate (and continuous-state) MDPs rely on some form of approximation. A widely-used approach is
31

Meuleau, Benazera, Brafman, Hansen & Mausam

Figure 1: Value function in the initial state of a simple rover problem: optimal expected return as
a function of two continuous variables (time and energy remaining).

to discretize the continuous state space into a finite number of grid points and solve the resulting
finite-state MDP using dynamic programming and interpolation (Rust, 1997; Munos & Moore,
2002). Another approach is parametric function approximation; a function associated with the
dynamic programming problem – such as the value function or policy function – is approximated
by a smooth function of k unknown parameters. In general, parametric function approximation is
faster than grid-based approximation, but has the drawback that it may fail to converge, or may
converge to an incorrect solution. Parametric function approximation is used by other algorithms for
solving continuous-state MDPs besides dynamic programming. Reinforcement learning algorithms
use artificial neural networks as function approximators (Bertsekas & Tsitsiklis, 1996). An approach
to solving MDPs called approximate linear programming has been extended to allow continuous as
well as discrete state variables (Kveton, Hauskrecht, & Guestrin, 2006).
We review another approach to solving hybrid-state (or continuous-state) MDPs that assumes
the problem has special structure that can be exploited by the dynamic
programming algorithm.
R
The structure assumed by this approach ensures that the convolution x0 Pr(x0 | n, x, a, n0 )(Rn0 (x0 )+
Vn0 (x0 ))dx0 in Equation (1) can be computed exactly in finite time, and the value function computed
by dynamic programming is piecewise-constant or piecewise-linear. The initial idea for this approach
is due to the work of Boyan and Littman (2000), who describe a class of MDPs called time-dependent
MDPs, in which transitions take place along a single, irreversible continuous dimension. They
describe a dynamic programming algorithm for computing an exact piecewise-linear value function
when the transition probabilities are discrete and rewards are piecewise linear. Feng et al. (2004)
extend this approach to continuous state spaces of more than one dimension, and consider MDPs with
discrete transition probabilities and two types of reward models: piecewise constant and piecewise
linear. Li and Littman (2005) further extend the approach to allow transition probabilities that are
piecewise-constant, instead of discrete, although this extension requires some approximation in the
dynamic programming algorithm.
The problem structure exploited by these algorithms is characteristic of the Mars rover domain
and other over-subscription planning problems. Figure 1 shows the optimal value functions from
the initial state of a typical Mars rover problem as a function of two continuous variables: the
time and energy remaining (Bresina et al., 2002). The value functions feature a set of humps and
plateaus, each of them representing a region of the state space where similar goals are pursued by
the optimal policy. The sharpness of a hump or plateau reflects uncertainty about achieving the
goal(s). Constraints that impose minimal resource levels before attempting some actions introduce

32

HAO*

sharp cuts in the regions. Plateau regions where the expected reward is nearly constant represent
regions of the state space where the optimal policy is the same, and the probability distribution over
future histories induced by this optimal policy is nearly constant.
The structure in such a value function can be exploited by partitioning the continuous state
space into a finite number of hyper-rectangular regions. (A region is a hyper-rectangle if it is the
Cartesian product of intervals at each dimension.) In each hyper-rectangle, the value function is
either constant (for a piecewise-constant function) or linear (for a piecewise-linear function). The
resolution of the hyper-rectangular partitioning is adjusted to fit the value function. Large hyperrectangles are used to represent large plateaus. Small hyper-rectangles are used to represent regions
of the state space where a finer discretization of the value function is useful, such as the edges of
plateaus and the curved hump where there is more time and energy available. A natural choice of
data structures for rectangular partitioning of a continuous space is kd-trees (Friedman, Bentley,
& Finkel, 1977), although other choices are possible. Figures 6 and 10 in Section 4.1 show value
functions for the initial state of a simple rover planning problem, created by a piecewise-constant
partitioning of the continuous state space.
The continuous-state domains of the transition and reward functions are similarly partitioned into
hyper-rectangles. The reward function of each action has the same piecewise-constant (or piecewiselinear) representation as the value function. The transition function partitions the state space into
regions for which the set of outcomes of an action and the probability distribution over the set of
outcomes are identical. Following Boyan and Littman (2000), both relative and absolute transitions
are supported. A relative outcome can be viewed as shifting a region by a constant δ. That is, for
any two states x and y in the same region, the transition probabilitiesP r(x0 |x, a) and P r(y 0 |y, a)
are defined in term of the probability of δ, such that δ = (x0 − x) = (y 0 − y). An absolute outcome
maps all states in a region to a single state. That is, for any two states x and y in the same region,
P r(x0 |x, a) = P r(x0 |y, a). We can view a relative outcome as a pair (δ, p), where p is the probability
of that outcome, and we can view an absolute outcome as a pair (x0 , p). This assumes there is
only a finite number of non-zero probabilities, i.e., the probability distribution is discretized, which
means that for any state and action, a finite set of states can be reached with non-zero probability.
This representation guarantees that a dynamic programming update of a piecewise-constant value
function results in another piecewise-constant value function. Feng et al. (2004) show that for such
transition functions and for any finite horizon, there exists a partition of the continuous space into
hyper-rectangles over which the optimal value function is piecewise constant or linear.
The restriction to discrete transition functions is a strong one, and often means the transition
function must be approximated. For example, rover power consumption is normally distributed,
and thus must be discretized. (Since the amount of power available must be non-negative, our
implementation truncates any negative part of the normal distribution and renormalizes.) Any continuous transition function can be approximated by an appropriately fine discretization, and Feng et
al. (2004) argue that this provides an attractive alternative to function approximation approaches in
that it approximates the model but then solves the approximate model exactly, rather than finding
an approximate value function for the original model. (For this reason, we will sometimes refer
to finding optimal policies and value functions, even when the model has been approximated.) To
avoid discretizing the transition function, Li and Littman (2005) describe an algorithm that allows
piecewise-constant transition functions, in exchange for some approximation in the dynamic programming algorithm. Marecki et al.(2007) describe a different approach to this class of problems in
which probability distributions over resource consumptions are represented with phase-type distributions and a dynamic programming algorithm exploits this representation. Although we use the
work of Feng et al. (2004) in our implementation, the heuristic search algorithm we develop in the
next section could use any of these or some other approach to representing and computing value
functions and policies for a hybrid-state MDP.

33

Meuleau, Benazera, Brafman, Hansen & Mausam

3. Heuristic Search in a Hybrid State Space
In this section, we present the primary contribution of this paper: an approach to solving a special
class of hybrid-state MDPs using a novel generalization of the heuristic search algorithm AO*. In
particular, we describe a generalization of this algorithm for solving hybrid-state MDPs in which
the continuous variables represent monotonic and constrained resources and the acyclic plan found
by the search algorithm allows branching on the availability of these resources.
The motivation for using heuristic search is the potentially huge size of the state space, which
makes dynamic programming infeasible. One reason for this size is the existence of continuous
variables. But even if we only consider the discrete component of the state space, the size of the
state space is exponential in the number of discrete variables. As is well-known, AO* can be very
effective in solving planning problems that have a large state space because it only considers states
that are reachable from an initial state, and it uses an informative heuristic function to focus on
states that are reachable in the course of executing a good plan. As a result, AO* can often find an
optimal plan by exploring a small fraction of the entire state space.
We begin this section with a review of the standard AO* algorithm. Then we consider how
to generalize AO* to search in a hybrid state space and discuss the properties of the generalized
algorithm, as well as its most efficient implementations.
3.1 AO*
Recall that AO* is an algorithm for AND/OR graph search problems (Nilsson, 1980; Pearl, 1984).
Such graphs arise in problems where there are choices (the OR components), and each choice can
have multiple consequences (the AND component), as is the case in planning under uncertainty.
Hansen and Zilberstein (2001) show how AND/OR graph search techniques can be used in solving
MDPs.
Following Nilsson (1980) and Hansen and Zilberstein (2001), we define an AND/OR graph as
a hypergraph. Instead of arcs that connect pairs of nodes as in an ordinary graph, a hypergraph
has hyperarcs, or k-connectors, that connect a node to a set of k successor nodes. When an MDP is
represented by a hypergraph, each node corresponds to a state; the root node corresponds to the start
state, and the leaf nodes correspond to terminal states. Thus we often use the word state to refer to
the corresponding node in the hypergraph representing an MDP. A k-connector corresponds to an
action that transforms a state into one of k possible successor states, with a probability attached to
each successor such that the probabilities sum to one. In this paper, we assume the AND/OR graph
is acyclic, which is consistent with our assumption that the underlying MDP has a bounded-horizon.
In AND/OR graph search, a solution takes the form of an acyclic subgraph called a solution
graph, which is defined as follows:
• the start node belongs to a solution graph;
• for every non-terminal node in a solution graph, exactly one outgoing k-connector (corresponding to an action) is part of the solution graph and each of its successor nodes also belongs to
the solution graph;
• every directed path in the solution graph terminates at a terminal node.
A solution graph that maximizes expected cumulative reward is found by solving the following
system of equations,

0 if s is a terminal
state; otherwise,
P

V ∗ (s) =
(2)
0
0
∗ 0
maxa∈A(s)
P
0
s ∈S r(s |s, a) (R(s ) + V (s )) ,
where V ∗ (s) denotes the expected value of an optimal solution for state s, and V ∗ is called the
optimal evaluation function (or value function in MDP terminology). Note that this is identical to
34

HAO*

the optimality equation for hybrid-state MDPs defined in Equation (1), if the latter is restricted to
a discrete state space. In keeping with the convention in the literature on MDPs, we treat this as a
value-maximization problem even though AO* is usually formalized as solving a cost-minimization
problem.
For state-space search problems that are formalized as AND/OR graphs, an optimal solution
graph can be found using the heuristic search algorithm AO* (Nilsson, 1980; Pearl, 1984). Like other
heuristic search algorithms, the advantage of AO* over dynamic programming is that it can find an
optimal solution for a particular starting state without evaluating all problem states. Therefore, a
graph is not usually supplied explicitly to the search algorithm. An implicit graph, G, is specified
implicitly by a start node or start state s and a successor function that generates the successors
states for any state-action pair. The search algorithm constructs an explicit graph, G0 , that initially
consists only of the start state. A tip or leaf state of the explicit graph is said to be terminal if
it is a goal state (or some other state in which no action can be taken); otherwise, it is said to be
nonterminal. A nonterminal tip state can be expanded by adding to the explicit graph its outgoing
k-connectors (one for each action) and any successor states not already in the explicit graph.
AO* solves a state-space search problem by gradually building a solution graph, beginning from
the start state. A partial solution graph is defined similarly to a solution graph, with the difference
that tip states of a partial solution graph may be nonterminal states of the implicit AND/OR graph.
A partial solution graph is defined as follows:
• the start state belongs to a partial solution graph;
• for every non-tip state in a partial solution graph, exactly one outgoing k-connector (corresponding to an action) is part of the partial solution graph and each of its successor states also
belongs to the partial solution graph;
• every directed path in a partial solution graph terminates at a tip state of the explicit graph.
The value of a partial solution graph is defined similarly to the value of a solution graph. The
difference is that if a tip state of a partial solution graph is nonterminal, it does not have a value
that can be propagated backwards. Instead, we assume there is an admissible heuristic estimate
H(s) of the maximal-value solution graph for state s. A heuristic evaluation function H is said to
be admissible if H(s) ≥ V ∗ (s) for every state s. We can recursively calculate an admissible heuristic
estimate V (s) of the optimal value of any state s in the explicit graph as follows:

 0 if s is a terminal state,
V (s) =
a nonterminal tip state,

 H(s) if s isP
0
0
0
maxa∈A(s)
s0 ∈S P r(s |s, a) (R(s ) + V (s )) otherwise.

(3)

The best partial solution graph can be determined at any time by propagating heuristic estimates
from the tip states of the explicit graph to the start state. If we mark the action that maximizes
the value of each state, the best partial solution graph can be determined by starting at the root of
the graph and selecting the best (i.e., marked) action for each reachable state.
Table 1 outlines the AO* algorithm for finding an optimal solution graph in an acyclic AND/OR
graph. It interleaves forward expansion of the best partial solution with a value update step that
updates estimated state values and the best partial solution. In the simplest version of AO*, the
values of the expanded state and all of its ancestor states in the explicit graph are updated. But in
fact, the only ancestor states that need to be re-evaluated are those from which the expanded state
can be reached by taking marked actions (i.e., by choosing the best action for each state). Thus,
the parenthetical remark in step 2(b)i of Table 1 indicates that a parent s0 of state s is not added
to Z unless both the estimated value of state s has changed and state s can be reached from state
s0 by choosing the best action for state s0 . AO* terminates when the policy expansion step does not

35

Meuleau, Benazera, Brafman, Hansen & Mausam

1. The explicit graph G0 initially consists of the start state s0 .
2. While the best solution graph has some nonterminal tip state:
(a) Expand best partial solution: Expand some nonterminal tip state s of the best partial
solution graph and add any new successor states to G0 . For each new state s0 added to
G0 by expanding s, if s0 is a terminal state then V (s0 ) := 0; else V (s0 ) := H(s0 ).
(b) Update state values and mark best actions:
i. Create a set Z that contains the expanded state and all of its ancestors in the explicit
graph along marked action arcs. (I.e., only include ancestor states from which the
expanded state can be reached by following the current best solution.)
ii. Repeat the following steps until Z is empty.
A. Remove from Z a state s such that no descendant of s in G0 occurs in Z.
P
B. Set V (s) := maxa∈A(s) s0 P r(s0 |s, a) (R(s0 ) + V (s0 )) and mark the best action
for s. (When determining the best action resolve ties arbitrarily, but give preference to the currently marked action.)
(c) Identify the best solution graph and all nonterminal states on its fringe
3. Return an optimal solution graph.
Table 1: AO* algorithm.
find any nonterminal states on the fringe of the best solution graph. At this point, the best solution
graph is an optimal solution.
Following the literature on AND/OR graph search, we have so far referred to the solution found
by AO* as a solution graph. But in the following, when AO* is used to solve an MDP, we sometimes
follow the literature on MDPs in referring to a solution as a policy. We also sometimes refer to it as
a policy graph, to indicate that a policy is represented in the form of a graph.
3.2 Hybrid-State AO*
We now consider how to generalize AO* to solve a bounded-horizon hybrid-state MDP. The challenge
we face in applying AO* to this problem is the challenge of performing state-space search in a hybrid
state space.
The solution we adopt is to search in an aggregate state space that is represented by an AND/OR
graph in which there is a node for each distinct value of the discrete component of the state. In other
words, each node of the AND/OR graph represents a region of the continuous state space in which
the discrete value is the same. Given this partition of the continuous state space, we use AND/OR
graph search techniques to solve the MDP for those parts of the state space that are reachable from
the start state under the best policy.
However, AND/OR graph search techniques must be modified in important ways to allow search
in a hybrid state space that is represented in this way. In particular, there is no longer a correspondence between the nodes of the AND/OR graph and individual states. Each node now corresponds
to a continuous region of the state space, and different actions may be optimal for different hybrid states associated with the same search node. In the case of rover planning, for example, the
best action is likely to depend on how much energy or time is remaining, and energy and time are
continuous state variables.
To address this problem and still find an optimal solution, we attach to each search node a set of
functions (of the continuous variables) that make it possible to associate different values, heuristics,
and actions with different hybrid states that map to the same search node. As before, the explicit

36

HAO*

search graph consists of all nodes and edges of the AND/OR graph that have been generated so far,
and describes all the states that have been considered so far by the search algorithm. The difference
is that we use a more complex state representation in which a set of continuous functions allows
representation and reasoning about the continuous part of the state space associated with a search
node.
We begin by describing this more complex node data structure, and then we describe the HAO*
algorithm.
3.2.1 Data Structures
Each node n of the explicit AND/OR graph G0 consists of the following:
• The value of the discrete state variable.
• Pointers to its parents and children in the explicit graph and the policy graph.
• Openn (·) → {0, 1}: the “Open list”. For each x ∈ X, Openn (x) indicates whether (n, x) is on
the frontier of the explicit graph, i.e., generated but not yet expanded.
• Closedn (·) → {0, 1}: the “Closed list”. For each x ∈ X, Closedn (x) indicates whether (n, x)
is in the interior of the explicit graph, i.e., already expanded.
Note that, for all (n, x), Openn (x) ∩ Closedn (x) = ∅. (A state cannot be both open and
closed.) There can be parts of the continuous state space associated with a node that are
neither open nor closed. Until the explicit graph contains a trajectory from the start state
to a particular hybrid state, that hybrid state is not considered generated, even if the search
node to which it corresponds has been generated; such states are neither open nor closed. In
addition, only non-terminal states can be open or closed. Note that we do not refer to open
or closed nodes; instead, we refer to the hybrid states associated with nodes as being open or
closed.
• Hn (·): the heuristic function. For each x ∈ X, Hn (x) is a heuristic estimate of the optimal
expected cumulative reward from state (n, x).
• Vn (·): the value function. For any open state (n, x), Vn (x) = Hn (x). For any closed state
(n, x), Vn (x) is obtained by backing up the values of its successor states, as in Equation (4).
• πn (·) → A: the policy. Note that it is defined for closed states only.
• Reachablen (·) → {0, 1}: For each x ∈ X, Reachablen (x) indicates whether (n, x) is reachable
by executing the current best policy beginning from the start state (n0 , x0 ).
We assume that these various continuous functions, which represent information about the hybrid states associated with a search node, partition the state space associated with a node into a
discrete number of regions, and associate a distinct value or action with each region. Given such
a partitioning, the HAO* algorithm expands and evaluates these regions of the hybrid state space,
instead of individual hybrid states. The finiteness of the partition is important in order to ensure
that the search frontier can be extended by a finite number of expansions, and to ensure that HAO*
can terminate after a finite number of steps. In our implementation of HAO*, described in Section 4, we use the piecewise-constant partitioning of a continuous state space proposed by Feng et
al. (2004). However, any method of discrete partitioning could be used, provided that the condition
above holds; for example, Li and Littman (2005) describe an alternative method of partitioning.
Note that two forms of state-space partitioning are used in our algorithm. First, the hybrid state
space is partitioned into a finite number of regions, one for each discrete state, where each of these

37

Meuleau, Benazera, Brafman, Hansen & Mausam

regions corresponds to a node of the AND/OR graph. Second, the continuous state space associated with a particular node is further partitioned into smaller regions based on a piecewise-constant
representation of a continuous function, such as the one used by Feng et al. (2004).
In addition to this more complex representation of the nodes of an AND/OR graph, our algorithm
requires a more complex definition of the the best (partial) solution. In standard AO*, the oneto-one correspondence between nodes and individual states means that a solution or policy can
be represented entirely by a graph, called the (partial) solution graph, in which a single action is
associated with each node. In the HAO* algorithm, a continuum of states is associated with each
node, and different actions may be optimal for different regions of the state space associated with a
particular node. For the HAO* algorithm, a (partial) solution graph is a sub-graph of the explicit
graph that is defined as follows:
• the start node belongs to a solution graph;
• for every non-tip node in a solution graph, one or more outgoing k-connectors are part of the
solution graph, one for each action that is optimal for some hybrid state associated with the
node, and each of their successor nodes also belongs to the solution graph;
• every directed path in the solution graph terminates at a tip node of the explicit graph.
The key difference in this definition is that there may be more than one optimal action associated
with a node, since different actions may be optimal for different hybrid states associated with the
node. A policy is represented not only by a solution graph, but by the continuous functions πn (.)
and Reachablen (.). In particular, a (partial) policy π specifies an action for each reachable region of
the continuous state space. The best (partial) policy is the one that satisfies the following optimality
equation:
Vn (x)

=

Vn (x)

= Hn (x) when (n, x) is a nonterminal open state,
"

Z
X
=
max
Pr(n0 | n, x, a)
Pr(x0 | n, x, a, n0 ) (Rn0 (x0 ) + Vn0 (x0 )) dx0 .

Vn (x)

0 when (n, x) is a terminal state,

a∈An (x)

n0 ∈N

(4)

x0

Note that this optimality equation is only satisfied for regions of the state space that are reachable
from the start state, (n0 , x0 ) by following an optimal policy.
3.2.2 Algorithm
Table 2 gives a high-level summary of the HAO* algorithm. In outline, it is the same as the AO*
algorithm, and consists of iteration of the same three steps; solution (or policy) expansion, use of
dynamic programming to update the current value function and policy, and analysis of reachability
to identify the frontier of the solution that is eligible for expansion. In detail, it is modified in several
important ways to allow search of a hybrid state space. In the following, we discuss the modifications
to each of these three steps.
Policy expansion All nodes of the current solution graph are identified and one or more open
regions associated with these nodes are selected for expansion. That is, one or more regions of the
hybrid state space in the intersection of Open and Reachable is chosen for expansion. All actions
applicable to the states in these open regions are simulated, and the results of these actions are added
to the explicit graph. In some cases, this means adding a new node to the AND/OR graph. In other
cases, it simply involves marking one or more regions of the continuous state space associated with
an existing node as open. More specifically, when an action leads to a new node, this node is added to
the explicit graph, and all states corresponding to this node that are reachable from the expanded
region(s) after the action under consideration are marked as open. When an action leads to an
38

HAO*

1. The explicit graph G0 initially consists of the start node and corresponding start state (n0 , x0 ),
marked as open and reachable.
2. While Reachablen (x) ∩ Openn (x) is non-empty for some (n, x):
(a) Expand best partial solution: Expand one or more region(s) of open states on the frontier
of the explicit state space that is reachable by following the best partial policy. Add new
successor states to G0 . In some cases, this requires adding a new node to the AND/OR
graph. In other cases, it simply involves marking one or more regions of the continuous
state space associated with an existing node as open. States in the expanded region(s)
are marked as closed.
(b) Update state values and mark best actions:
i. Create a set Z that contains the node(s) associated with the just expanded regions
of states and all ancestor nodes in the explicit graph along marked action arcs.
ii. Decompose the part of the explicit AND/OR graph that consists of nodes in Z into
strongly connected components.
iii. Repeat the following steps until Z is empty.
A. Remove from Z a set of nodes such that (1) they all belong to the same connected
component, and (2) no descendant of these nodes occurs in Z.
B. For every node n in this connected component and for all states (n, x) in any
expanded region of node n, set
Vn (x) :=
"
max
a∈An (x)

X

Pr(n0 | n, x, a)

Z


Pr(x0 | n, x, a, n0 ) (Rn0 (x0 ) + Vn0 (x0 )) dx0 ,

x0

n0 ∈N

and mark the best action. (When determining the best action resolve ties arbitrarily, but give preference to the currently marked action.) Repeat until there
is no longer a change of value for any of these nodes.
(c) Identify the best solution graph and all nonterminal states on its frontier. This step
updates Reachablen (x).
3. Return an optimal policy.
Table 2: HAO* algorithm.
existing node, any region(s) of Markov states in this node that is both reachable from the expanded
region(s) and not marked as closed, is marked open. Expanded regions of the state space are marked
as closed. Thus, different regions associated with the same node can be opened and expanded at
different times. This process is illustrated in Figure 2. In this figure, nodes corresponding to a
distinct value for the discrete state are represented as rectangles, and circular connectors represent
actions. For each node, we see how many distinct continuous regions exist. For each such region we
see whether it is closed (“C”) or open (“O”), and whether it is reachable from the initial state (“R”)
when executing the current best policy (“OPT”). For instance, in Figure 2(a), node At(Start) has
a single region marked closed and reachable, and node Lost has two regions: the smallest, open and
reachable, and the largest, closed and unreachable.
Dynamic programming As in standard AO*, the value of any newly-expanded node n must
be updated by computing a Bellman backup based on the value functions of the children of n

39

Meuleau, Benazera, Brafman, Hansen & Mausam

At(Start)

At(Loc1)
O

At(Start)
C

C

R

R

Navigate
(Start, Loc1)

At(Loc1)

OPT

C

R

Navigate
(Start, Loc1)

OPT

R

Navigate
(Loc1, Loc2)

Lost
O

C

Lost
O

R

O

C

C

R

At(Loc2)

Panoramic
Camera

O

(a) Before expansion

Panoramic
Camera

(b) After expansion

Figure 2: Expanding a region of the state space. (a) Before expansion: The nodes At(Start),
At(Loc1) and Lost have been previously created. The unique region in At(Loc1) is the
next region to be expanded. (b) After expansion: The action Navigate(Loc1, Loc2) that
can be applied in the expanded region has been added to the graph. This action can lead
either to the preexisting node Lost, or to the new node At(Loc2). The expanded region (in
At(Loc1)), as well as the continuous regions reachable from there (in Lost and At(Loc2)),
are highlighted in a dotted framed. Following expansion, the expanded region is closed.
Discrete state At(Loc2) has been added to the graph and all its reachable regions are
open. Additionally, new open regions have been added to node Lost.

in the explicit graph. For each expanded region of the state space associated with node n, each
action is evaluated, the best action is selected, and the corresponding continuous value function
is associated with the region. The continuous-state value function is computed by evaluating the
continuous integral in Equation (4). We can use any method for computing this integral. In our
implementation, we use the dynamic programming algorithm of Feng et al. (2004). As reviewed
in Section 2.4, they show that the continuous integral over x0 can be computed exactly, as long as
the transition and reward functions satisfy certain conditions. Note that, with some hybrid-state
dynamic programming techniques such as Feng et al. (2004), dynamic programming backups may
increase the number of pieces of the value function attached to the updated regions (Figure 3(a)).
Once the expanded regions of the continuous state space associated with a node n are reevaluated, the new values must be propagated backward in the explicit graph. The backward
propagation stops at nodes where the value function is not modified, or at the root node. The
standard AO* algorithm, summarized in Figure 1, assumes that the AND/OR graph in which it
searches is acyclic. There are extensions of AO* for searching in AND/OR graphs that contain
cycles. One line of research is concerned with how to find acyclic solutions in AND/OR graphs
that contain cycles (Jimenez & Torras, 2000). Another generalization of AO*, called LAO*, allows
solutions to contain cycles or “loops” in order to specify policies for infinite-horizon MDPs (Hansen
& Zilberstein, 2001).

40

HAO*

At(Start)

At(Loc1)
C C C

At(Start)
C

C

R

R

Navigate
(Start, Loc1)

At(Loc1)

OPT

C C C

R R R

Navigate
(Loc1, Loc2)

Lost
O

O

C

OPT

C

R

At(Loc2)
O

OPT

R R R

Navigate
(Loc1, Loc2)

OPT

Navigate
(Start, Loc1)

At(Loc2)

Panoramic
Camera

O
R

(a) Dynamic programming

Lost
O

O

C

R

R

R

C

Panoramic
Camera

(b) Reachability analysis

Figure 3: Dynamic programming and reachability analysis (Figure 2 continued). (a) Dynamic programming: The optimal policy has been reevaluated and Navigate(Loc1, Loc2) appears
optimal in some continuous states of At(Loc2). Node At(Loc1) is represented with a finer
partition of the continuous state space to illustrate the fact that the backup increased the
number of pieces of the value function associated with the expanded region. (b) Reachability analysis: The newly created region of At(Loc2) becomes reachable, as well as the
regions of Lost that can be reached through Navigate(Loc1, Loc2).

Given our assumption that every action has positive resource consumption, there can be no
loops in the state space of our problem because the resources available decrease at each step. But
surprisingly, there can be loops in the AND/OR graph. This is possible because the AND/OR
graph represents a projection of the state space onto a smaller space that consists of only the
discrete component of the state. For example, it is possible for the rover to return to the same
site it has visited before. The rover is not actually in the same state, since it has fewer resources
available. But the AND/OR graph represents a projection of the state space that does not include
the continuous aspects of the state, such as resources, and this means the rover can visit a state that
projects to the same node of the AND/OR graph as a state it visited earlier, as shown in Figure 4.
As a result, there can be loops in the AND/OR graph, and even loops in the part of the AND/OR
graph that corresponds to a solution. But in a sense, these are “phantom loops” that can only
appear in the projected state space, and not in the real state space.
Nevertheless we must modify the dynamic programming (DP) algorithm to deal with these loops.
Because there are no loops in the real state space, we know that the exact value function can be
updated by a finite number of backups performed in the correct order, with one backup performed
for any state that can be visited along a path from the start state to the expanded node(s). But
because multiple states can map to the same AND/OR graph node, the continuous region of the
state space associated with a particular node may need to be evaluated more than once. To identify
the AND/OR graph nodes that need to be evaluated more than once, we use the following two-step
algorithm.

41

Meuleau, Benazera, Brafman, Hansen & Mausam

At(Start)

At(Location1)
energy = 80

At(Location1)
energy = 50

At(Location1)

At(Start)
energy = 100
At(Location2)
energy = 65

At(Location2)
energy = 35

At(Location2)

Figure 4: Phantom loops in HAO*: solid boxes represent Markov states. Dashed boxes represent
search nodes, that is, the projection of Markov states on the discrete components. Arrows
represent possible state transition. Bold arrows show an instance of phantom loop in the
search space.

First, we consider the part of the AND/OR graph that consists of ancestor nodes of the just
expanded node(s). This is the set Z of nodes identified at the beginning of the DP step. We
decompose this part of the graph into strongly connected components. The graph of strongly
connected components is acyclic and can be used to prescribe the order of backups in almost the
same way as in the standard AO* algorithm. In particular, the nodes in a particular component are
not backed up until all nodes in its descendant components have been backed up. Note that in the
case of an acyclic graph, every strongly connected component has a single node. It is only possible
for a connected component to have more than one node if there are loops in the AND/OR graph.
If there are loops in the AND/OR graph, the primary change in the DP step of the algorithm
occurs when it is time to perform backups on the nodes in a connected component with more than one
node. In this case, all nodes in the connected component are evaluated. Then, they are repeatedly
re-evaluated until the value functions of these nodes converge, that is, until there is no change in
the values of any of the nodes. Because there are no loops in the real state space, convergence is
guaranteed to occur after a finite number of steps. Typically, it occurs after a very small number
of steps. An advantage of decomposing the AND/OR graph into connected components is that it
identifies loops and localizes their effect to a small number of nodes. In experiments in our test
domain, most nodes of the graph need to be evaluated just once during the DP step, and only a
small number of nodes (and often none) need to be evaluated more than once.
Note that decomposition of the nodes in Z into connected components is a method for improving
the efficiency of the dynamic programming step, and is not required for its correctness. The alternative of repeatedly updating all nodes in Z until all their values converge is also correct, although
it is likely to result in many useless updates of already converged nodes.
Analysis of reachability Change in the value function can lead to change in the optimal policy,
and, thus, to change in which states are visited by the best policy. This, in turn, can affect which
open regions of the state space are eligible to be expanded. In this final step, HAO* identifies the
best (partial) policy and recomputes Reachablen for all nodes and states in the explicit graph, as
follows (see Figure 3(b)). For each node n in the best (partial) solution graph, consider each of its
parents n0 in the solution graph, and all the actions a that can lead from one of the parents to n.
Then Reachablen (x) is the support of Pn (x), where
X Z
Pn (x) =
Reachablen0 (x0 ) Pr(n | n0 , x0 , a) Pr(x | n0 , x0 , a, n)dx0 ,
(5)
(n0 ,a)∈Ωn

X

42

HAO*

that is, Reachablen (x) = {x ∈ X : Pn (x) > 0}. In Equation (5), Ωn is the set of pairs (n0 , a) where
a is the best action in n0 for some reachable resource level:
Ωn = {(n0 , a) ∈ N × A : ∃x ∈ X, Pn0 (x) > 0, πn0 (x) = a, Pr(n | n0 , x, a) > 0} .
It is clear that we can restrict our attention to state-action pairs in Ωn , only.
By performing this reachability analysis, HAO* identifies the frontier of the state space that is
eligible for expansion. HAO* terminates when this frontier is empty, that is, when it does not find
any hybrid states in the intersection of Reachable and Open.
3.3 Convergence and Error Bounds
We next consider some of the theoretical properties of HAO*. First, under reasonable assumptions,
we prove that HAO* converges to an optimal policy after a finite number of steps. Then we discuss
how to use HAO* to find sub-optimal policies with error bounds.
The proof of convergence after a finite number of steps depends, among other things, on the
assumption that a hybrid-state MDP has a finite branching factor. In our implementation, this
means that for any region of the state space that can be represented by a hyper-rectangle, the set
of successor regions after an action can be represented by a finite set of hyper-rectangles. From
this assumption and the assumption that the number of actions is finite, it follows that for every
assignment n to the discrete variables, the set
{x|(n, x)is reachable from the initial state using some fixed sequence of actions}
is the union of a finite number of open or closed hyper-rectangles. This assumption can be viewed
as a generalization of the assumption of a finite branching factor in a discrete AND/OR graph upon
which the finite convergence proof of AO* depends.
Theorem 1 If the heuristic functions Hn are admissible (optimistic), all actions have positive resource consumptions, both continuous backups and action application are computable exactly in finite
time, and the branching factor is finite, then:
1. At each step of HAO*, Vn (x) is an upper-bound on the optimal expected return in (n, x), for
all (n, x) expanded by HAO*;
2. HAO* terminates after a finite number of steps;
3. After termination, Vn (x) is equal to the optimal expected return in (n, x), for all (n, x) reachable
under an optimal policy, i.e., Reachablen (x) > 0.
Proof: (1) The proof is by induction. Every state (n, x) is assigned an initial heuristic estimate,
and Vn (x) = Hn (x) ≥ Vn∗ (x) by the admissibility of the heuristic evaluation function. We make the
inductive hypothesis that at some point in the algorithm, Vn (x) ≥ Vn∗ (x) for every state (n, x). If a
backup is performed for any state (n, x),
"

Z
X
Vn (x) =
max
Pr(n0 | n, x, a)
Pr(x0 | n, x, a, n0 ) (Rn0 (x0 ) + Vn0 (x0 )) dx0
a∈An (x)

x0

n0 ∈N

"
≥

max
a∈An (x)

X
n0 ∈N

0

Z

Pr(n | n, x, a)

0

0

0

Pr(x | n, x, a, n ) (Rn0 (x ) +
x0

= Vn∗ (x) ,
where the last equality restates the Bellman optimality equation.

43

Vn∗0 (x0 )) dx0



Meuleau, Benazera, Brafman, Hansen & Mausam

(2) Because each action has positive, bounded from below, resource consumption, and resources
are finite and non-replenishable, the complete implicit AND/OR graph must be finite. For the same
reason, this graph can be turned into a finite graph without loops: Along any directed loop in
this graph, the amount of maximal available resources must decrease by some  which is a positive
lower-bound on the amount of resources consumed by an action. Each node in this graph may be
expanded a number of times that is bounded by the number of its ancestor. (Each time a new
ancestor is discovered, it may lead to an update in the set of reachable regions for this node.)
Moreover, finite branching factor implies that the number of regions considered within each node
is bounded (because there are finite ways of reaching this node, each of which contributes a finite
number of hyper-rectangles). Thus, overall, the number of regions considered is finite, and the
processing required for each region expansion is finite (because action application and backups are
computed in finite time). This leads to the desired conclusion.
(3) The search algorithm terminates when the policy for the start state (n0 , x0 ) is complete,
that is, when it does not lead to any unexpanded states. For every state (n, x) that is reachable
by following this policy, it is contradictory to suppose Vn (x) > Vn∗ (x) since that implies a complete
policy that is better than optimal. By the Bellman optimality equation of Equation (1), we know
that Vn (x) ≥ Vn∗ (x) for every state in this complete policy. Therefore, Vn (x) = Vn∗ (x). 
HAO* not only converges to an optimal solution, stopping the algorithm early allows a flexible
trade-off between solution quality and computation time. If we assume that, in each state, there
is a done action that terminates execution with zero reward (in a rover problem, we would then
start a safe sequence), then we can evaluate the current policy at each step of the algorithm by
assuming that execution ends each time we reach a leaf of the policy graph. Under this assumption,
the error of the current policy at each step of the algorithm can be bounded. We show this by
using a decomposition of the value function described by Chakrabarti et al.(1988) and Hansen and
Zilberstein (2001). We note that at any point in the algorithm, the value function can be decomposed
into two parts, gn (x) and hn (x), such that
gn (x)

=

gn (x)

=

0 when (n, x) is an open state, on the fringe of the greedy policy; otherwise,
Z
X
0
∗
Pr(n | n, x, a )
Pr(x0 | n, x, a∗ , n0 ) (Rn (x) + gn0 (x0 )) dx0 ,

(6)

x0

n0 ∈N

and
hn (x)

= Hn (x) when (n, x) is an open state, on the fringe of the greedy policy; otherwise,
Z
X
hn (x) =
Pr(n0 | n, x, a∗ )
Pr(x0 | n, x, a∗ , n0 ) hn0 (x0 )dx0 ,
(7)
n0 ∈N

x0

where a∗ is the action that maximizes the right-hand side of Equation (4). Note that Vn (x) =
gn (x) + hn (x). We use this decomposition of the value function to bound the error of the best policy
found so far, as follows.
Theorem 2 At each step of the HAO* algorithm, the error of the current best policy is bounded by
hn0 (x0 ).
Proof: For any state (n, x) in the explicit search space, a lower bound on its optimal value is given
by gn (x), which is the value that can be achieved by the current policy when the done action is
executed at all fringe states, and an upper bound is given by Vn (x) = gn (x) + hn (x), as established
in Theorem 1. It follows that hn0 (x0 ) bounds the difference between the optimal value and the
current admissible value of any state (n, x), including the initial state (n0 , x) ).
Note that the error bound for the initial state is hn0 (x0 ) = Hn0 (x0 ) at the start of the algorithm;
it decreases with the progress of the algorithm; and hn0 (x0 ) = 0 when HAO* converges to an optimal
solution.
44

HAO*

3.4 Heuristic Function
The heuristic function Hn focuses the search on reachable states that are most likely to be useful.
The more informative the heuristic, the more scalable the search algorithm. In our implementation
of HAO* for the rover planning problem, which is described in detail in the next section, we used
the simple admissible heuristic function which assigns to each node the sum of all rewards associated
with goals that have not been achieved so far. Note that this heuristic function only depends on the
discrete component of the state, and not on the continuous variables; that is, the function Hn (x)
is constant over all values of x. It is obvious that this heuristic is admissible, since it represents
the maximum additional reward that could be achieved by continuing plan execution. Although it
is not obvious that a heuristic this simple could be useful, the experimental results we present in
Section 4 show that it is. We considered an additional, more informed heuristic function that solved
a relaxed, suitably discretized, version of the planning problem. However, taking into account the
time required to compute this heuristic estimate, the simpler heuristic performed better.
3.5 Expansion Policy
HAO* works correctly and converges to an optimal solution no matter which continuous region(s)
of which node(s) are expanded in each iteration (step 2.a). But the quality of the solution may
improve more quickly by using some “heuristics” to choose which region(s) on the fringe to expand
next.
One simple strategy is to select a node and expand all continuous regions of this node that
are open and reachable. In a preliminary implementation, we expanded (the open regions of) the
node that is most likely to be reached using the current policy. Changes in the value of these
states will have the greatest effect on the value of earlier nodes. Implementing this strategy requires
performing the additional work involved in maintaining the probability associated with each state.
If such probabilities are available, one could also focus on expanding the most promising node, that
is, the node where the integral of Hn (x) times the probability over all values of x is the highest, as
described by Mausam, Benazera, Brafman, Meuleau, and Hansen (2005).
Hansen and Zilberstein (2001) observed that, in the case of LAO*, the algorithm is more efficient
if we expand several nodes in the fringe before performing dynamic programming in the explicit
graph. This is because the cost of performing the update of a node largely dominates the cost of
expanding a node. If we expand only one node of the fringe at each iteration, we might have to
perform more DP backups than if we expand several nodes with common ancestors before proceeding
to DP. In the limit, we might want to expand all nodes of the fringe at each algorithm iteration.
Indeed, this variant of LAO* proved the most efficient (Hansen & Zilberstein, 2001).
In the case of LAO*, updates are expensive because of the loops in the implicit graph. In HAO*,
the update of a region induces a call to the hybrid dynamic programming module for each open
region of the node. Therefore, the same technique is likely to produce the same benefit.
Pursuing this idea, we allowed our algorithm to expand all nodes in the fringe and all their
descendants up to a fixed depth at each iteration. We defined a parameter, called the expansion
horizon and denoted k, to represent, loosely speaking, the number of times the whole fringe is
expanded at each iteration. When k = 1, HAO* expands all open and reachable regions of all
nodes in the fringe before recomputing the optimal policy. When k = 2, it expands all regions in
the fringe and all their children before updating the policy. At k = 3 it also consider the grandchildren of regions in the fringe, and so on. When k tends to infinity, the algorithm essentially
performs an exhaustive search: it first expands the graph of all reachable nodes, then performs one
pass of (hybrid) dynamic programming in this graph to determine the optimal policy. By balancing
node expansion and update, the expansion horizon allows tuning the algorithm behavior from an
exhaustive search to a more traditional heuristic search. Our experiments showed that a value of k
between 5 and 10 is optimal to solve our hardest benchmark problems (see section 4).

45

Meuleau, Benazera, Brafman, Hansen & Mausam

Start

ObsPt3

Unsafe

C4
Obs
Pt4

Featureless
C6

W2
W3

W1

Obs
Pt5

ObsPt2

Audience

Demo

label

: Waypoint
Name

: Rock
: IP + CHAMP

ObsPt1
Far

: Science Cam.

Figure 5: The K9 rover (top left) was developed at the Jet Propulsion Laboratory and NASA Ames
Research Center as a prototype for the MER rovers. It is used to test advanced rover
software, including automated planners of the rover’s activities. Right: topological map
of the 2004 IS demo problem. Arrows labeled “IP + CHAMP” represent the opportunity
to deploy the arm against a rock (instrument placement) and take a picture of it with
the CHAMP Camera. Arrows labeled “Science Cam” represent the opportunity to take a
remote picture of a rock with the Science Camera.

3.6 Updating Multiple Regions
The expansion policies described above are based on expanding all open regions of one or several
nodes simultaneously. They allow leveraging hybrid-state dynamic programming techniques such as
those of Feng et al. (2004) and Li and Littman (2005). These techniques may compute in a single
iteration piecewise constant and linear value functions that cover a large range of continuous states,
possibly the whole space of possible values. In particular, they can back up in one iteration all
continuous states included between given bounds.
Therefore, when several open regions of the same node are expanded at the same iteration of
HAO*, we can update all of them simultaneously by backing-up a subset of continuous states that
includes all these regions. For instance, one may record lower bounds and upper bounds on each
continuous variable over the expanded regions, and then compute a value function that covers the
hyper-rectangle between these bounds.
This modification of the algorithm does not impact convergence. As long as the value of all
expanded regions is computed, the convergence proof holds. However, execution time may be adversely affected if the expanded regions are a proper subset of the region of continuous states that is

46

HAO*

(a) Value function Vn (.) for the initial node. The
first plateau corresponds to analyzing R1, the second plateau to analyzing R2, and the third plateau
to analyzing both R1 and R2.

(b) The policy πn (.) for the starting
node shows the partitions of the resource space where different actions
are optimal. Dark: no action; Grey:
navigation to R2; Light: analysis of
R1.

Figure 6: (a) Optimal value function for the initial state of the simple rover problem over all possible
values for the continuous resources (time and energy remaining). The value function is
partitioned into 3476 pieces. (b) Optimal policy for the same set of states.

backed-up. In that case, the values of states that are not open or not reachable is uselessly computed,
which deviates from a pure heuristic search algorithm.
However, this modification may also be beneficial because it avoids some redundant computation.
Hybrid-state dynamic programming techniques manipulate pieces of value functions. Thus, if several
expanded regions are included in the same piece of the value function, their value is computed only
once. In practice, this benefit may outweigh the cost of evaluating useless regions. Moreover, cost
is further reduced by storing the value functions associated with each node of the graph, so that
computed values of irrelevant regions are saved in case these regions become eligible for expansion
(i.e., open and reachable) later. Thus, this variant of HAO* fully exploits hybrid-state dynamic
programming techniques.

4. Experimental Evaluation
In this section, we describe the performance of HAO* in solving planning problems for a simulated
planetary exploration rover with two monotonic and continuous-valued resources: time and battery
power. Section 4.1 uses a simple “toy” example of this problem to illustrate the basic steps of
the HAO* algorithm. Section 4.2 tests the performance of the algorithm using a realistic, real-size
NASA simulation of a rover and analyzes the results of the experiments. The simulation uses a
model of the K9 rover (see Figure 5) developed for the Intelligent Systems (IS) demo at NASA
Ames Research Center in October 2004 (Pedersen et al., 2005). This is a complex real-size model of
the K9 rover that uses command names understandable by the rover’s execution language, so that
the plans produced by our algorithm can be directly executed by the rover. For the experiments
reported in Section 4.2, we did not simplify this NASA simulation model in any way.

47

Meuleau, Benazera, Brafman, Hansen & Mausam

Figure 7: First iteration of HAO* on the toy problem. The explicit graph is marked by dim edges
and the solution graph is marked by thick edges. Tip nodes 4, 5, 6 and 7 are shown with
constant heuristic functions and expanded nodes 1, 2 and 3 are shown with backed up
value functions.

In the planning problem we consider, an autonomous rover must navigate in a planar graph
representing its surroundings and the authorized navigation paths, and schedule observations to
be performed on different rocks situated at different locations. Only a subset of its observational
goals can be achieved in a single run due to limited resources. Therefore, this is an oversubscribed
planning problem. It is also a problem of planning under uncertainty since each action has uncertain
positive resource consumptions and a probability of failing.
A significant amount of uncertainty in the domain comes from the tracking mechanism used by
the rover. Tracking is the process by which the rover recognizes a rock based on certain features in
its camera image that are associated with the rock. During mission operations, a problem instance
containing a fixed set of locations, paths, and rocks is built from the last panoramic camera image
sent by the rover. Each “logical rock” in this problem instance corresponds to a real rock, and
the rover must associate the two on the basis of features that can be detected by its instruments,
including its camera. As the rover moves and its camera image changes, the rover must keep track
of how those features of the image evolve. This process is uncertain and subject to faults that result
in losing track of a rock. In practice, tracking is modeled in the following way:
• In order to perform a measurement on a rock, the rover must be tracking this rock.
• To navigate along a path, it must be tracking one of the rocks that enables following this path.
The set of rocks that enable each path is part of the problem definition given to the planner.
• The decision to start tracking a rock must be made before the rover begins to move. Once
the rover starts moving, it may keep track of a rock already being tracked or voluntarily stop
tracking it, but it cannot acquire a new rock that was not tracked initially.

48

HAO*

Figure 8: Second iteration of HAO* on the toy problem.
• The rover may randomly lose track of some rocks while navigating along a path. The probability of losing track of a rock depends on the rock and the path followed, it is part of the
problem definition given to the planner.
• There is no way to reacquire a rock whose track has been lost, intentionally or by accident.
• The number of rocks tracked strongly influences the duration and resource consumption of
navigate actions. The higher the number of rocks tracked, the more costly it is to navigate
along a path. This is because the rover has to stop regularly to check and record the aspect
of each rock being tracked. This creates an incentive to limit the number of rocks tracked by
the rover given the set of goals it has chosen and the path it intends to follow.
So, the rover initially selects a set of rocks to track and tries to keep this set as small as possible
given its goals. Once it starts moving, it may lose track of some rocks, and this may cause it to
reconsider the set of goals it will pursue and the route to get to the corresponding rocks. It can
also purposely stop tracking a rock when this is no longer necessary given the goals that are left to
achieve.
Our implementation of HAO* uses the dynamic programming algorithm developed by Feng et
al. (2004) and summarized in Section 2.4 in order to perform backups in a hybrid state space, and
partitions the continuous state-space associated with a node into piecewise-constant regions. It uses
multiple-region updates as described in Section 3.6: an upper bound on the each resource over
all expanded regions is computed, and all states included between these bounds and the minimal
possible resource levels are updated.
In our experiments, we use the variant of the HAO* algorithm described in Section 3.5, where a
parameter k sets the number of times the whole fringe is expanded at each iteration of HAO*; this
allows the behavior of the algorithm to be tuned from an exhaustive search to a heuristic search. We
used an expansion horizon of k = 2 for the simple example in Section 4.1 and a default expansion
horizon of k = 7 for the larger examples in Section 4.2. Section 4.2.3 describes experiments with
different expansion horizons.

49

Meuleau, Benazera, Brafman, Hansen & Mausam

Figure 9: Third iteration of HAO* on the toy problem.
Our implementation of HAO* uses the simple heuristic described in Section 3.4, augmented with
a small amount of domain knowledge. The value Hn (x) of a state (n, x) is essentially equal to the
sum of the utilities of all goals not yet achieved in n. However, if the rover has already moved and a
certain rock is not being tracked in state n, then all goals requiring this rock to be tracked are not
included in the sum. This reflects the fact that, once the rover has moved, it cannot start tracking a
rock any more, and thus all goals that require this rock to be tracked are unreachable. The resulting
heuristic is admissible (i.e., it never underestimates the value of a state), and it is straightforward to
compute. Note that it does not depend on the current resource levels, so that the functions Hn (x)
are constant over all values of x.
4.1 Example
We begin with a very simple example of the rover planning problem in order to illustrate the steps
of the algorithm. We solve this example using the same implementation of HAO* that we use to
solve the more realistic examples considered in Section 4.2.
In this example, the targets are two rocks, R1 and R2, positioned at locations L1 and L2,
respectively. The rover’s initial location is L1, and there is a direct path between L1 and L2.
Analyzing rock R1 yields a reward of 10 and analyzing rock R2 yields a reward of 20. The rover’s
action set is simplified. Notably, it features a single action Pic(Rx) to represents all the steps of
analyzing rock Rx, and the “stop tracking” actions have been removed.
Figure 6 shows the optimal value function and the optimal policy found by HAO* for the starting
discrete state, and resources ranging over the whole space of possible values. Figures 7, 8 and 9
show the step-by-step process by which HAO* solves this problem. Using an expansion horizon of
k = 2, HAO* solves this problem in three iterations, as follows:
• Iteration 1: As shown in Figure 7, HAO* expands nodes 1, 2 and 3 and computes a heuristic
function for the new tip nodes 4, 5, 6 and 7. The backup step yields value function estimates
for nodes 1, 2 and 3. HAO* then identifies the best solution graph and a new fringe node 6.

50

HAO*

(a) 1012 pieces.

(b) 3465pieces.

(c) 6122pieces.

Figure 10: Optimal value functions for the initial state of the simple rover problem with increasing initial resource levels (from left to right). The optimal return appears as a three
dimensional function carved into the reachable space of the heuristic function.
problem
name
Rover1
Rover2
Rover3
Rover4

rover
locations
7
7
9
11

paths

goals

fluents

actions

10
11
16
20

3
5
6
6

30
41
49
51

43
56
73
81

discrete
states
(approx.)
1.1 109
2.2 1012
5.6 1014
2.3 1015

reachable
discrete
states
613
5255
20393
22866

explicit
graph

optimal
policy

longest
branch

234
1068
2430
4321

50
48
43
44

35
35
43
43

Table 3: Size of benchmark rover problems.
• Iteration 2: As shown in Figure 8, HAO* expands nodes 6, 8, 9 and 10, starting with
previous fringe node 6, and computes heuristic functions for the new tip nodes 11, 12 and 13.
The heuristic value for node 12 is zero because, in this state, the rover has lost track of R2
and has already analyzed R1. The backup step improves the accuracy of the value function in
several nodes. Node 11 is the only new fringe node since 12 is a terminal node.
• Iteration 3: As shown in Figure 9, HAO* expands node 11 and node 14. The search ends
after this iteration because there is no more open node in the optimal solution graph.
For comparison, Figure 10 shows how the value function found by HAO* varies with different initial
resource levels. In these figures, unreachable states are assigned a large constant heuristic value, so
that the value function for reachable states appears as carved in the plateau of the heuristic.
4.2 Performance
Now, we describe HAO*’s performance in solving four much larger rover planning problems using the
NASA simulation model. The characteristics of these problems are displayed in Tables 3. Columns
two to six show the size of the problems in terms of rover locations, paths, and goals. They also show
the total number of fluents (Boolean state variables) and actions in each problem. Columns seven
to ten report on the size of the discrete state space. The total number of discrete states is two raised
to the power of the number of fluents. Although this is a huge state space, only a limited number
of states can be reached from the start state, depending on the initial resource levels. The eighth
column in Table 3 shows the number of reachable discrete states if the initial time and energy levels
are set to their maximum value. (The maximum initial resource levels are based on the scenario of
the 2004 IS demo and represent several hours of rover activity.) It shows that simple reachability
51

Meuleau, Benazera, Brafman, Hansen & Mausam

700

500
400
300
200
100
0

reachable
created
expanded
in optimal policy

600
Number of discrete states

600
Number of discrete states

700

reachable
created
expanded
in optimal policy

500
400
300
200
100

0

100000

200000
300000
Initial energy

400000

0

500000

0

2000

4000
6000
Initial time

8000

10000

8000

10000

8000

10000

8000

10000

(a) Rover1
6000

reachable
created
expanded
in optimal policy

5000

Number of discrete states

Number of discrete states

6000

4000
3000
2000
1000
0

0

100000

200000
300000
Initial energy

400000

4000
3000
2000
1000
0

500000

reachable
created
expanded
in optimal policy

5000

0

2000

4000
6000
Initial time

(b) Rover2
25000

reachable
created
expanded
in optimal policy

20000

Number of discrete states

Number of discrete states

25000

15000
10000
5000
0

0

100000

200000 300000
Initial energy

400000

20000
15000
10000
5000
0

500000

reachable
created
expanded
in optimal policy

0

2000

4000
6000
Initial time

(c) Rover3
25000

reachable
created
expanded
in optimal policy

20000

Number of discrete states

Number of discrete states

25000

15000
10000
5000
0

0

100000

200000 300000
Initial energy

400000

20000
15000
10000
5000
0

500000

reachable
created
expanded
in optimal policy

0

2000

4000
6000
Initial time

(d) Rover4
Figure 11: Number of nodes created and expanded by HAO* vs. number of reachable discrete states.
The graphs in the left column are obtained by fixing the initial time to its maximum value
and varying the initial energy. The graphs in the right column are obtained by fixing the
initial energy to its maximum value and varying the initial time. Results obtained with
k = 7.
52

HAO*

analysis based on resource availability makes a huge difference. This is partly due to the fact that
our planning domain, which is very close to the K9 execution language, does not allow many fluents
to be true simultaneously. Columns nine and ten show the number of discrete states in the explicit
graph and in the optimal policy. More precisely, the former is the number of nodes created by HAO*,
that is, a subset of the reachable discrete states. The number of reachable discrete states, and thus
the size of the graph to explore, may seem small compared to other discrete combinatorial problems
solved by AI techniques. But each iteration, a continuous approximation of the two-dimensional
backup is necessary to evaluate the hybrid state space associated with the graph. Finally, the last
column of Table 3 shows the length of the longest branch in the optimal policy when the initial
resource levels are set to their maximum value.
The largest of the four instances (that is, Rover4) is exactly the problem of the October 2004
IS demo. This is considered a very large rover problem. For example, it is much larger than the
problems faced by the MER rovers that never visit more than one rock in a single planning cycle.
4.2.1 Efficiency of Pruning
In a first set of simulations, we try to evaluate the efficiency of heuristic pruning in HAO*, that is,
the portion of the discrete search space that is spared from exploration through the use of admissible
heuristics. For this purpose, we compare the number of discrete states that are reachable for a given
resource level with the number of nodes created and expanded by HAO*. We also consider the
number of nodes in the optimal policy found by the algorithm.
Results for the four benchmark problems are presented in Figure 11. These curves are obtained
by fixing one resource to its maximum possible value and varying the other from 0 to its maximum.
Therefore, they represent problems where mostly one resource is constraining. These result show,
notably, that a single resource is enough to constrain the reachability of the state space significantly.
Not surprisingly, problems become larger as the initial resources increase, because more discrete
states become reachable. Despite the simplicity of the heuristic used, HAO* is able to by-pass
a significant part of the search space. Moreover, the bigger the problem, the more leverage the
algorithm can take from the simple heuristic.
These results are quite encouraging, but the number of nodes created and expanded does not
always reflect search time. Therefore, we examine the time it takes for HAO* to produce solutions.
4.2.2 Search Time
Figure 12 shows HAO* search time for the same set of experiments. These curves do not exhibit the
same monotonicity and, instead, appear to show a significant amount of noise. It is surprising that
search time does not always increase with an increase in the initial levels of resource, although the
search space is bigger. This shows that search complexity does not depend on the size of the search
space alone. Other factors must explain complexity peaks as observed in Figure 12.
Because the number of nodes created and expanded by the algorithm does not contain such noise,
the reason for the peaks of computation time must be the time spent in dynamic programming
backups. Moreover, search time appears closely related to the complexity of the optimal policy.
Figure 13 shows the number of nodes and branches in the policy found by the algorithm, as well as
the number of goals pursued by this policy. It shows that: (i) in some cases, increasing the initial
resource level eliminates the need for branching and reduces the size of the optimal solution; (ii) the
size of the optimal policy and, secondarily, its number of branches, explains most of the peaks in the
search time curves. Therefore, the question is: why does a large solution graph induce a long time
spent in backups? There are two possible answers to this question: because the backups take longer
and/or because more backups are performed. The first explanation is pretty intuitive. When the
policy graph contains many branches leading to different combinations of goals, the value functions
contain many humps and plateaus, and therefore many pieces, which impacts the complexity of
dynamic programming backups. However, we do not have at this time any empirical evidence to
53

18

18

16

16

14

14

12

12

Search time (s)

Search time (s)

Meuleau, Benazera, Brafman, Hansen & Mausam

10
8
6

10
8
6

4

4

2

2

0

0

100000

200000
300000
Initial energy

400000

0

500000

0

2000

4000
6000
Initial time

8000

10000

4000
6000
Initial time

8000

10000

180

160

160

140

140

120

120

Search time (s)

Search time (s)

(a) Rover1
180

100
80
60

100
80
60

40

40

20

20

0

0

100000

200000
300000
Initial energy

400000

0

500000

0

2000

25000

20000

20000
Search time (s)

Search time (s)

(b) Rover2
25000

15000
10000
5000
0

15000
10000
5000

0

100000

200000 300000
Initial energy

400000

0

500000

0

2000

4000
6000
Initial time

8000

10000

0

2000

4000
6000
Initial time

8000

10000

20000

20000

15000

15000
Search time (s)

Search time (s)

(c) Rover3

10000

5000

0

10000

5000

0

100000

200000 300000
Initial energy

400000

0

500000

(d) Rover4
Figure 12: HAO* search time. The graphs in the left column are obtained by fixing the initial time
to its maximum value, and the graphs in the right column are obtained by fixing the
initial energy to its maximum. Results obtained with k = 7.

54

HAO*

confirm this hypothesis. Conversely, we observe that the peak of Figure 12 comes with an increase
of the number of backups. More work is required to explain this.
4.2.3 Expansion Horizon
The results of Section 4.2.1 show that HAO* can leverage even a simple admissible heuristic to prune
a large portion of the search space. But it does not necessarily follow that HAO* can outperform an
“exhaustive search” algorithm that creates a graph of all reachable states, and then executes one pass
of dynamic programming in this graph to find the optimal policy. Although HAO* expands a smaller
graph than such an exhaustive search, it must evaluate the graph more often. In Section 3.5, we
introduced a parameter k for expansion horizon in order to allow adjustment of a trade-off between
the time spent expanding nodes and the time spent evaluating nodes. We now study the influence
of this parameter on the algorithm.
Figure 14 shows the number of nodes created and expanded by HAO* as a function of the
expansion horizon for the four benchmark problem instances. Not surprisingly, the algorithm creates
and expands more nodes as the expansion horizon increases. Essentially, it behaves more like an
exhaustive search as k is increased. For the two smallest problem instances, and for large enough
values of k, the number of visited states levels off when the total number of reachable states is
reached. For the two largest problem instances, we had to interrupt the experiments once k reached
25 because search time became too long.
Figure 15 shows the effect of the expansion horizon on the search time of HAO*. For the smallest
problem instance (Rover1), HAO* does not have a clear advantage over an exhaustive search (with
k > 20), even though it explores fewer nodes. But for the three larger problem instances, HAO*
has a clear advantage. For the Rover2 problem instance, the search time of HAO* levels off after
k = 25, indicating the limit of reachable states has been reached. However, the duration of such
an exhaustive search is several times longer than for HAO* with smaller settings of k. The benefits
of HAO* are clearer for the two largest problem instances. As k is increased, the algorithm is
quickly overwhelmed by the combinatorial explosion in the size of the search space, and simulations
eventually need to be interrupted because search time becomes too long. For these same problem
instances and smaller settings of k, HAO* is able to efficiently find optimal solutions.
Overall, our results show that there is a clear benefit to using admissible heuristics to prune the
search space, although the expansion horizon must be adjusted appropriately in order for HAO* to
achieve a favorable trade-off between node-expansion time and node-evaluation time.

5. Conclusion
We introduced a heuristic search approach to finding optimal conditional plans in domains characterized by continuous state variables that represent limited, consumable resources. The HAO*
algorithm is a variant of the AO* algorithm that, to the best of our knowledge, is the first algorithm to deal with all of the following: limited continuous resources, uncertain action outcomes, and
over-subscription planning. We tested HAO* in a realistic NASA simulation of a planetary rover,
a complex domain of practical importance, and our results demonstrate its effectiveness in solving
problems that are too large to be solved by the straightforward application of dynamic programming. It is effective because heuristic search can exploit resource constraints, as well as an admissible
heuristic, in order to limit the reachable state space.
In our implementation, the HAO* algorithm is integrated with the dynamic programming algorithm of Feng et al. (2004). However HAO* can be integrated with other dynamic programming
algorithms for solving hybrid-state MDPs. The Feng et al. algorithm finds optimal policies under
the limiting assumptions that transition probabilities are discrete, and rewards are either piecewiseconstant or piecewise-linear. More recently-developed dynamic programming algorithms for hybridstate MDPs make less restrictive assumptions, and also have the potential to improve computational

55

Meuleau, Benazera, Brafman, Hansen & Mausam

30

3

20

2

10

1

0

0

100000

200000 300000
Initial energy

400000

40

0
500000

5

Nodes
Branches
Goals

4

30

3

20

2

10

1

0

0

2000

4000
6000
Initial time

8000

Number of branches and goals

4

50

Number of nodes

40
Number of nodes

5

Nodes
Branches
Goals

Number of branches and goals

50

0
10000

(a) Rover1

45

3

30

2

15

1

0

0

100000

200000 300000
Initial energy

400000

60

0
500000

5

Nodes
Branches
Goals

4

45

3

30

2

15

1

0

0

2000

4000
6000
Initial time

8000

Number of branches and goals

4

75

Number of nodes

Nodes
Branches
Goals

60
Number of nodes

5
Number of branches and goals

75

0
10000

(b) Rover2

45

3

30

2

15

1

0

0

100000

200000 300000
Initial energy

400000

60

0
500000

5

Nodes
Branches
Goals

4

45

3

30

2

15

1

0

0

2000

4000
6000
Initial time

8000

Number of branches and goals

4

75

Number of nodes

Nodes
Branches
Goals

60
Number of nodes

5
Number of branches and goals

75

0
10000

(c) Rover3

60

3

40

2

20

1

0

0

100000

200000 300000
Initial energy

400000

80

0
500000

5

Nodes
Branches
Goals

4

60

3

40

2

20

1

0

0

2000

4000
6000
Initial time

8000

Number of branches and goals

4

100

Number of nodes

Nodes
Branches
Goals

80
Number of nodes

5
Number of branches and goals

100

0
10000

(d) Rover4
Figure 13: Complexity of the optimal policy: number of nodes, branches, and goals in the optimal
policy in the same setting as Figure 11.

56

HAO*

700

Number of discrete states

600
Number of discrete states

6000

created
expanded

500
400
300
200
100
0

0

5

10
15
20
Expansion horizon

4000
3000
2000
1000
0

25

created
expanded

5000

0

5

10

(a) Rover1
14000

Number of discrete states

Number of discrete states

30

created
expanded

14000

10000
8000
6000
4000
2000
0

25

(b) Rover2
16000

created
expanded

12000

15
20
Expansion horizon

12000
10000
8000
6000
4000
2000

0

5

10
15
Expansion horizon

0

20

(c) Rover3

0

5

10
15
Expansion horizon

20

(d) Rover4

Figure 14: Influence of the expansion horizon on the number of nodes visited by the algorithm.
efficiency (Li & Littman, 2005; Marecki et al., 2007). Integrating HAO* with one of these algorithms
could improve performance further.
There are several other interesting directions in which this work could be extended. In developing HAO*, we made the assumptions that every action consumes some resource and resources are
non-replenishable. Without these assumptions, the same state could be revisited and an optimal
plan could have loops as well as branches. Generalizing our approach to allow plans with loops,
which seems necessary to handle replenishable resources, requires generalizing the heuristic search
algorithm LAO* to solve hybrid MDPs (Hansen & Zilberstein, 2001). Another possible extension is
to allow continuous action variables in addition to continuous state variables. Finally, our heuristic
search approach could be combined with other approaches to improving scalability, such as hierarchical decomposition (Meuleau & Brafman, 2007). This would allow it to handle the even larger state
spaces that result when the number of goals in an over-subscription planning problem is increased.
Acknowledgments
This work was funded by the NASA Intelligent Systems program, grant NRA2-38169. Eric Hansen
was supported in part by a NASA Summer Faculty Fellowship and by funding from the Mississippi
Space Grant Consortium. This work was performed while Emmanuel Benazera was working at
NASA Ames Research Center and Ronen Brafman was visiting NASA Ames Research Center, both
as consultants for the Research Institute for Advanced Computer Science. Ronen Brafman was
supported in part by the Lynn and William Frankel Center for Computer Science, the Paul Ivanier
Center for Robotics and Production Management, and ISF grant #110707. Nicolas Meuleau is a
consultant of Carnegie Mellon University at NASA Ames Research Center.

57

Meuleau, Benazera, Brafman, Hansen & Mausam

60

1800
1600
1400

40

Search time (s)

Search time (s)

50

30
20

1000
800
600
400

10
0

1200

200
0

5

10
15
20
Expansion horizon

0

25

0

5

10

(a) Rover1

30

30000
25000
Search time (s)

20000
Search time (s)

25

(b) Rover2

25000

15000
10000
5000
0

15
20
Expansion horizon

20000
15000
10000
5000

0

5

10
15
Expansion horizon

0

20

(c) Rover3

0

5

10
15
Expansion horizon

20

(d) Rover4

Figure 15: Influence of the expansion horizon on overall search time.

References
Altman, E. (1999). Constrained Markov Decision Processes. Chapman and HALL/CRC.
Bertsekas, D., & Tsitsiklis, J. (1996). Neural Dynamic Programming. Athena Scientific, Belmont,
MA.
Boutilier, C., Dean, T., & Hanks, S. (1999). Decision-theoretic planning: Structural assumptions
and computational leverage. Journal of Artificial Intelligence Research, 11, 1–94.
Boyan, J., & Littman, M. (2000). Exact solutions to time-dependent MDPs. In Advances in Neural
Information Processing Systems 13, pp. 1–7. MIT Press, Cambridge.
Bresina, J., Dearden, R., Meuleau, N., Ramakrishnan, S., Smith, D., & Washington, R. (2002).
Planning under continuous time and resource uncertainty: A challenge for AI. In Proceedings
of the Eighteenth Conference on Uncertainty in Artificial Intelligence, pp. 77–84.
Bresina, J., Jonsson, A., Morris, P., & Rajan, K. (2005). Activity planning for the mars exploration
rovers. In Proceedings of the Fifteenth International Conference on Automated Planning and
Scheduling, pp. 40–49.
Chakrabarti, P., Ghose, S., & DeSarkar, S. (1988). Admissibility of AO* when heuristics overestimate. Aritificial Intelligence, 34, 97–113.
Feng, Z., Dearden, R., Meuleau, N., & Washington, R. (2004). Dynamic programming for structured continuous Markov decision problems. In Proceedings of the Twentieth Conference on
Uncertainty in Artificial Intelligence, pp. 154–161.
58

HAO*

Friedman, J., Bentley, J., & Finkel, R. (1977). An algorithm for finding best matches in logarithmic
expected time. ACM Trans. Mathematical Software, 3(3), 209–226.
Hansen, E., & Zilberstein, S. (2001). LAO*: A heuristic search algorithm that finds solutions with
loops. Artificial Intelligence, 129, 35–62.
Jimenez, P., & Torras, C. (2000). An efficient algorithm for searching implicit AND/OR graphs with
cycles. Artificial Intelligence, 124, 1–30.
Kveton, B., Hauskrecht, M., & Guestrin, C. (2006). Solving factored MDPs with hybrid state and
action variables. Journal of Artificial Intelligence Research, 27, 153–201.
Li, L., & Littman, M. (2005). Lazy approximation for solving continuous finite-horizon MDPs. In
Proceedings of the Twentieth National Conference on Artificial Intelligence, pp. 1175–1180.
Marecki, J., Koenig, S., & Tambe, M. (2007). A fast analytical algorithm for solving markov decision
processes with real-valued resources. In Proceedings of the 20th International Joint Conference
on Artificial Intelligence (IJCAI-07, pp. 2536–2541.
Mausam, Benazera, E., Brafman, R., Meuleau, N., & Hansen, E. (2005). Planning with continuous resources in stochastic domains. In Proceedings of the Nineteenth International Joint
Conference on Artificial Intelligence, pp. 1244–1251. Professional Book Center, Denver, CO.
Meuleau, N., & Brafman, R. (2007). Hierarchical heuristic forward search in stochastic domains. In
Proceedings of the 20th International Joint Conference on Artificial Intelligence (IJCAI-07),
pp. 2542–2549.
Munos, R., & Moore, A. (2002). Variable resolution discretization in optimal control. Machine
Learning, 49 (2-3), 291–323.
Nilsson, N. (1980). Principles of Artificial Intelligence. Tioga Publishing Company, Palo Alto, CA.
Pearl, J. (1984). Heuristics: Intelligent Search Strategies for Computer Problem Solving. AddisonWesley.
Pedersen, L., Smith, D., Deans, M., Sargent, R., Kunz, C., Lees, D., & Rajagopalan, S. (2005).
Mission planning and target tracking for autonomous instrument placement. In Proceedings
of the 2005 IEEE Aerospace Conference., Big Sky, Montana.
Puterman, M. (1994). Markov Decision Processes: Discrete Stochastic Dynamic Programming.
Wiley, New York, NY.
Rust, J. (1997). Using randomization to break the curse of dimensionality. Econimetrica, 65, 487–
516.
Smith, D. (2004). Choosing objectives in over-subscription planning. In Proceedings of the Fourteenth
International Conference on Automated Planning and Scheduling, pp. 393–401.
Thiebaux, S., Gretton, C., Slaney, J., Price, D., & Kabanza, F. (2006). Decision-theoretic planning
with non-Markovian rewards. Journal of Artificial Intelligence Research, 25, 17–74.
van den Briel, M., Sanchez, R., Do, M., & Kambhampati, S. (2004). Effective approaches for partial
satisfation (over-subscription) planning. In Proceedings of the Nineteenth National Conference
on Artificial Intelligence, pp. 562–569.

59

