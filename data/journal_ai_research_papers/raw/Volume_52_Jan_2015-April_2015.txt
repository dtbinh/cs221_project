Journal of Artificial Intelligence Research 52 (2015) 601-713

Submitted 08/14; published 04/15

A Compositional Framework for Grounding Language
Inference, Generation, and Acquisition in Video
Haonan Yu
N. Siddharth
Andrei Barbu
Jeﬀrey Mark Siskind

haonan@haonanyu.com
siddharth@iffsid.com
andrei@0xab.com
qobi@purdue.edu

School of Electrical and Computer Engineering
Purdue University
465 Northwestern Avenue
West Lafayette, IN 47907-2035 USA

Abstract
We present an approach to simultaneously reasoning about a video clip and an entire
natural-language sentence. The compositional nature of language is exploited to construct
models which represent the meanings of entire sentences composed out of the meanings of
the words in those sentences mediated by a grammar that encodes the predicate-argument
relations. We demonstrate that these models faithfully represent the meanings of sentences
and are sensitive to how the roles played by participants (nouns), their characteristics (adjectives), the actions performed (verbs), the manner of such actions (adverbs), and changing
spatial relations between participants (prepositions) affect the meaning of a sentence and
how it is grounded in video. We exploit this methodology in three ways. In the first, a video
clip along with a sentence are taken as input and the participants in the event described
by the sentence are highlighted, even when the clip depicts multiple similar simultaneous
events. In the second, a video clip is taken as input without a sentence and a sentence is
generated that describes an event in that clip. In the third, a corpus of video clips is paired
with sentences which describe some of the events in those clips and the meanings of the
words in those sentences are learned. We learn these meanings without needing to specify
which attribute of the video clips each word in a given sentence refers to. The learned
meaning representations are shown to be intelligible to humans.

1. Introduction
People use their knowledge of language to make sense of the world around them, not just
to describe their observations or communicate to others. In this work, we present an
approach which is able to describe video clips in natural language while simultaneously
using that capacity to reason about the content of those clips. While earlier approaches
can detect individual features in video (Laptev, 2005; Kuehne, Jhuang, Garrote, Poggio, &
Serre, 2011), such as objects or events, we show how knowledge of language can integrate
information from these different feature detectors in order to both improve their performance
and support novel functionality. To do this, we exploit the compositional nature of language
to construct models for entire sentences from individual word models, and use such models to
determine if an entire sentence describes a video clip. We call the mechanism for determining
how well a video clip depicts a sentence, and alternatively how well a sentence describes a
c
2015
AI Access Foundation. All rights reserved.

Yu, Siddharth, Barbu, & Siskind

video clip, the sentence tracker (Yu & Siskind, 2013; Siddharth, Barbu, & Siskind, 2014),
because it simultaneously performs multi-object tracking and recognition of events described
by sentences. This ability to score video-sentence pairs also allows us to perform another
important task that humans naturally engage in: learning word meanings. We show how
the sentence tracker can perform this task using the same kind of information that is
available to children, namely, video paired with entire sentences which describe some of
the events depicted. This general-purpose inference mechanism for combining bottom-up
information from low-level video-feature detectors and top-down information from naturallanguage semantics allows us to perform three novel tasks: tracking objects which are
engaged in a specific event as described by a sentence, generating a sentence to describe a
video clip, and learning word meaning from video clips paired with entire sentences.
Fundamentally, our approach relies on solving two separate problems simultaneously:
tracking the participants of an event and recognizing the occurrence of that event. We
formulate this as the combination of two measures: a measure of how well a video clip
depicts a track collection and how well that track collection depicts an event. Note that
what we mean by ‘event’ is a complex state of affairs described by an entire sentence, not
the common definition used in the computer vision community, which refers to a single verb
label attached to a video clip. In order to solve both problems simultaneously, we show
how the similarity between tracking and event recognition facilities a common inference
algorithm. We perform single-object tracking by combining the output of an unreliable
detection source, an object detector, with an estimate of the motion present in the video,
optical flow. The tracks produced consist of strong detections and their motion agrees
with the motion present in the video. We perform single-word recognition by representing
the meaning of a word in terms of the gross motion of object tracks. Finally, we show how
single-object tracking and single-word recognition combine to perform multi-object tracking
and whole-sentence recognition by exploiting the compositionality of language to combine
word models into sentence models and by formulating both tasks in a way that is amenable
to dynamic programming.
This ability to perform both tasks simultaneously—in other words, to score a videosentence pair with how well the video clip depicts the sentence—is crucial for attaining
good performance. By integrating top-down and bottom-up information, it corrects errors
in object-detector output. This is important because object detectors are highly unreliable,
achieving at most 40%-50% average precision on the PASCAL Visual Object Classes (VOC)
challenge (Everingham, Van Gool, Williams, Winn, & Zisserman, 2010). Barbu, Siddharth,
Michaux, and Siskind (2012b) showed how the reliability of object tracking and singleword recognition (typically for a verb) can be improved by performing both simultaneously.
We build on this earlier work and extend it to track multiple objects and recognize whole
sentences. We further extend that work with a novel approach to sentence generation and
learning word meanings.
Following Yamoto, Ohya, and Ishii (1992), Siskind and Morris (1996), and Starner,
Weaver, and Pentland (1998), we represent word meanings in a fashion that can be grounded
in video as multi-state time-series classifiers, either hidden Markov models (HMMs) or
finite-state machines (FSMs), over features extracted from object tracks in such video. For
example, a model for approach might use three states to encode an event where the distance between two tracked objects is initially high, over time decreases, and finally ends
602

Grounding Language Inference, Generation, and Acquisition in Video

by being small. Those earlier approaches confined themselves to representing the meaning
of verbs, but we employ the same representation for all words in the lexicon regardless
of their part of speech. This allows us to combine word models together into sentence
models, in essence, creating large factorial models. Unlike earlier work (Kulkarni, Premraj, Dhar, Li, Choi, Berg, & Berg, 2011; Hanckmann, Schutte, & Burghouts, 2012; Barbu,
Bridge, Burchill, Coroian, Dickinson, Fidler, Michaux, Mussman, Siddharth, Salvi, Schmidt,
Shangguan, Siskind, Waggoner, Wang, Wei, Yin, & Zhang, 2012a; Krishnamoorthy, Malkarnenkar, Mooney, Saenko, & Guadarrama, 2013), we exploit linguistics, namely the concept
of linking, to construct the particular factorial model which encodes the predicate-argument
structure of a specific sentence, not all sentences which happen to share the same words.
For example the sentence, The person picked up the backpack has very different meaning
from the sentence The backpack picked up the person, despite sharing all words, and our
method encodes such distinctions.
An overview of the operation of the sentence tracker is shown in Figure 1. Information
is extracted from video using object detectors and optical flow, as discussed in Section 2.1.
Independently, a sentence is parsed and the number of participants is determined, together
with a linking function, as discussed in Sections 3. Each word in the sentence has an
associated model, as discussed in Section 2.2. The information extracted from the sentence
combines with the per-word models to form a model for an entire sentence, as discussed in
Sections 2.3 and 2.4. That model takes, as input, the data extracted from a video clip and
computes how well the clip depicts the given sentence, the video-sentence score shown in
Equation 10.
In order to more formally articulate this approach and its applications, we represent the
measure of how well a video clip depicts a sentence as a function S : (B, s, Λ) 7→ (τ , J),
where B represents the information extracted from a video clip, s represents the sentence,
Λ represents word meanings, τ is the video-sentence score, and J is a collection of tracks,
one for each participant in the event described by the sentence, corresponding to the optimal
video-sentence score. We use Sτ and SJ to refer to the two components produced by S. This
function internally makes use of the number L of event participants and θ, a linking function.
The linking function maps arguments of words in the sentence to event participants. We
make use of a linking process, a function Θ : s 7→ (L, θ), that will be described in Section 3,
to derive the number L of participants and the linking function θ. We now elaborate on
three applications of this approach that we will demonstrate: language inference, language
generation, and language acquisition.
In language inference, one can apply the sentence tracker to the same video clip B, that
depicts multiple simultaneous events taking place in the field of view, with two different sentences s1 and s2 . In other words, one can compute J1 = SJ (B, s1 , Λ) and J2 = SJ (B, s2 , Λ)
to yield two different track collections J1 and J2 corresponding to the different sets of
participants in the different events described by s1 and s2 . We demonstrate this in Section 5.3. Specifically, we show how language inference, unlike many other approaches to
event recognition, not only deals with video that depicts multiple simultaneous events, but
is also sensitive to subtle changes in sentence meaning. We present an experiment where we
construct minimal pairs of sentences, given a grammar, which differ in only a single lexical
constituent, where that varying lexical constituent can itself vary among all parts of speech
and sentential positions. For example the two sentences
603

Yu, Siddharth, Barbu, & Siskind

Section 3

Section 2.1

sentence s

video B

linking process Θ
number of
participants L

object
detections

linking function θ

optical flow

lexicon Λ
sentence tracker S
word models λ

Sections 2.3 and 2.4

Section 4

Section 2.2
track collection J

video-sentence score τ

Equation 10
Figure 1: An overview of the approach presented and a roadmap to its presentation. Section 5.3 demonstrates language inference. Section 5.4 demonstrates language generation.
Section 5.5 demonstrates language acquisition.
The person to the left of the trash can put down an object.
The person to the right of the trash can put down an object.
are minimal pairs which differ in the preposition attached to the subject noun phrase. We
construct a video corpus where both sentences in such minimal pairs occur simultaneously
in the same video clip and demonstrate how language inference is sensitive to changes in
sentential meaning by producing two distinct and semantically appropriate sets of tracks
given each of the two sentences as input. To conduct a thorough1 evaluation, we employ a
vocabulary of 17 lexical items (5 nouns, 2 adjectives, 4 verbs, 2 adverbs, 2 spatial-relation
prepositions, and 2 motion prepositions) and a video corpus of 94 clips.
1. By ‘thorough’ we mean the following:
1. We evaluate all three of the applications of our general method: inference, generation, and acquisition.
2. We show performance on our entire corpus, without cherry picking.
3. We illustrate deep semantic grounding by way of minimal pairs that vary all lexical items and all
sentential positions.
4. We demonstrate deep semantic grounding by rendering the thematic-role assignments for sentences
on associated videos, illustrating correct assignment of event participants to roles and predicate
arguments.
5. We compare our learned models with ground-truth meaning representations and precisely measure
the KL divergence of such in Table 10.

604

Grounding Language Inference, Generation, and Acquisition in Video

In language generation, we take a video clip B as input and systematically search the
space of all possible sentences s, that can be generated by a context-free grammar, and find
the sentence with maximal video-sentence score:
argmax Sτ (B, s, Λ)
s

This generates a sentence that best describes an input video clip B. We demonstrate this
in Section 5.4. Unlike previous approaches to sentence generation from video which are
largely ad hoc(Barbu et al., 2012a; Hanckmann et al., 2012; Krishnamoorthy et al., 2013),
we present an approach which is optimal, in the sense that the generated sentence is that
which will produce the highest video-sentence score. Our evaluation for language generation
uses the same video corpus, grammar, and lexicon as used for language inference.
In language acquisition, we exploit the fact that we can simultaneously reason both about
the presence and motion of participants in a video clip and about the meaning of a sentence
describing that clip to compute models for word meaning from a training set of video clips
paired with sentences. In other words, given a training set {(B1 , s1 ), . . . , (BM , sM )} of
video-sentence pairs where the word meanings Λ are unknown, we compute
argmax
Λ

M
X

Sτ (Bm , sm , Λ)

m=1

which finds the word meanings Λ that maximize the aggregate score for all video-sentence
pairs in the training set. We demonstrate this in Section 5.5. We learn word meanings
without needing to annotate which word refers to which attribute of the video and without
annotating the tracks for the objects which participate in the event described in the training
sentences. To conduct a thorough evaluation, we employ a vocabulary of 16 lexical items
(6 nouns, 4 verbs, 2 adverbs, 2 spatial-relation prepositions, and 2 motion prepositions) and
a video corpus of 94 clips out of which a total of 276 video-sentence pairs are constructed.
The central contribution of this work is the sentence tracker, a precise mathematical and
computational framework for performing simultaneous object detection, multi-object tracking, action recognition, and recognition of multiple predicates assigned to different subsets
of participants, culminating in Equation 10, as implemented as an efficient algorithm as
illustrated in Figures 11 and 12, that implements exact inference in a joint model, along
with the method for training such solely from videos paired with sentential annotation.
The current focus in the computational linguistics community has been on large-scale unrestricted text processing for a long time now. The computer vision community is currently
undergoing a similar transition towards processing large-scale unrestricted image and video
corpora. Our sentence tracker is not intended to process unrestricted text and video. Nor is
it intended to produce natural-sounding text descriptions of video. We are more concerned
with semantics, as reflected by the truth of the text descriptions and the accuracy of the
learned meaning representations. Moreover, we evaluate it on a corpus that is considerably
smaller than what is currently used in both the computational linguistics and computer
vision communities. We do this because we intend our work to address an orthogonal set
of concerns:
1. We provide a unified framework that supports inference, generation, and acquisition.
605

Yu, Siddharth, Barbu, & Siskind

2. We demonstrate that it learns correct meanings of all words, with no prior meanings
of any words, from video paired with whole sentences, with no manual guidance as to
which words correspond to which components of the video.
3. We demonstrate that it has deep understanding of sentential semantics, grounded in
video, and that such are derived by a systematic computational process from deep
word meanings grounded in video.
4. This deep understanding allows the framework to distinguish between subtle semantic
distinctions that are manifest in two sentences that differ in a single word or in word
order, i.e., it understands the mapping between objects detected in the video and the
particular semantic roles they play in the sentences.
This does not mean that it has greater or lesser limitations than current work in computational linguistics or computer vision. Different research has different limitations. The above
four points highlight some of the limitations that such current work exhibits that are absent
from the work presented here.

2. Joint Tracking and Event Recognition
We represent word meanings, and ultimately sentence meanings, as constraints over the
time-varying spatial relations between event participants: their relative and/or absolute
positions, velocities, and/or accelerations. This requires that we track the positions of
event participants over the course of a video clip. In an ideal world, we would be able to
accurately determine which object classes were present in any video frame and for those
that are, precisely determine the positions of all instances of those classes in the field of
view. Unfortunately, the current state of the art in object detection is far from this ideal.
Object detectors only achieve between 3.8% and 65% average precision on the PASCAL
VOC benchmark (Everingham et al., 2010). This means that, in practice, they suffer from
both false positives and false negatives, as illustrated in Figure 2. While we wish to produce
a single detection for each of the person and backpack, as shown in Figure 2(a), in practice,
we often get spurious detections (false positives), as happens for the person detector in
Figure 2(b), and fail to obtain the desired detection (false negatives), as happens for the
backpack detector in Figure 2(c).
2.1 Detection-Based Tracking
The general approach to resolving this problem is to overgenerate. We lower the acceptance
threshold for the detector, trading off a higher false-positive rate for a lower false-negative
rate, as in Figure 2(d). We attempt to lower the threshold sufficiently to completely eliminate false negatives, biasing it to have a preponderance of false positives. The tracking
problem then reduces to the problem of selecting detections from the frames of a video clip
to assemble coherent tracks.
Let us assume, for a moment, that we wish to track a single instance of a specified object
class known to be present in the field of view throughout a video clip. We track that object
by selecting a single detection in each frame from the pool of detections for that object
class. The sequence of the top-scoring detection in each frame might not be temporally
coherent, as shown in Figure 3(a). Likewise, the most temporally-coherent sequence of
detections might consist of low-scoring misdetections, as shown in Figure 3(b). Thus our
606

Grounding Language Inference, Generation, and Acquisition in Video

(a)

(b)

(c)

(d)

Figure 2: State-of-the-art object detectors are imperfect. While we wish a single detection
for the person and backpack, as in (a), in practice we often get spurious detections (false
positives), as in (b), or fail to obtain the desired detection (false negatives), as in (c).
Reducing the acceptance threshold biases the detector to trade off a higher false-positive
rate for a lower false-negative rate, as in (d).

approach is to balance these two extremes by incorporating both the detection score and a
temporal-coherence score into the selection criterion. This often can yield the desired track,
as shown in Figure 3(c).
We adopt an objective function that linearly combines both the sum of the detection
scores in all video frames and the sum of a temporal-coherence score applied to all pairs
of adjacent video frames. More formally, in a video clip B of T frames, with J t detections bt1 , . . . , btJ t in frame t, we seek a track j, namely a sequence j 1 , . . . , j T of detection
indices, that maximizes the sum of the detection scores f (btj t ) and the temporal-coherence
scores g(bt−1
, bt ):
j t−1 j t
max
j

T
X
t=1

f (btj t )

!

+

T
X
t=2

607

g(bt−1
, bt )
j t−1 j t

!

(1)

Yu, Siddharth, Barbu, & Siskind

(a)

(b)

(c)

Figure 3: Assembling a track from a single detection per frame selected from a pool of
overgenerated detections. Selecting the top-scoring detection in each frame of a video
clip can yield an incoherent track, as shown in (a). Selecting tracks to maximize temporal
coherence can lead to tracks incorporating solely low-scoring misdetections, as shown in (b).
Selecting tracks to maximize an appropriate combination of detection score and temporalcoherence score can lead to the desired track, as shown in (c).
The objective function in Equation 1 constitutes a measure of how well a video clip B depicts
a track j. We employ this particular objective function because it can be optimized efficiently
with dynamic programming (Bellman, 1957), namely the Viterbi (1967) algorithm. This
leads to a lattice, as shown in Figure 4. The columns of the lattice correspond to video
frames, the detections in each frame constitute the columns, and a track constitutes a path
through the lattice.
The general approach to tracking by overgenerating detections and selecting among
those to yield a track is known as detection-based tracking (Han, Sethi, Hua, & Gong,
2004; Avidan, 2004; Wu & Nevatia, 2007). Our approach to using the Viterbi algorithm for
this purpose was first explored by Wolf, Viterbi, and Dixon (1989) to track radar detections.
It relies on an analogy:
“... detections correspond to HMM states, the detection score corresponds to
the HMM output probability, the temporal-coherence score corresponds to the
HMM state-transition probability, and finding the optimal track corresponds
to finding the maximum a posteriori probability (MAP) estimate of the HMM
state sequence (where the computation of the MAP estimate is performed in log
space).”
We crucially rely on this analogy for the entire remainder of this paper.
The above can trivially be modified to denote a MAP estimate in log space with suitable
normalization by a constant factor. For our purposes, however, all that is relevant is that
it optimizes a linear combination of two score components: the sum of state-based scores
and the sum of transition-based scores. In particular, the Viterbi algorithm can be applied
to Equation 1, without any constraint on permissible values for the scores f (b) and g(b′ , b).
608

Grounding Language Inference, Generation, and Acquisition in Video

t=1

t=2

t=3

j=1

b11

b21

b31

...

bT1

j=2

b12

b22

b32

...

bT2

j=3

b13

b23

b33

...

bT3

..
.

..
.

..
.

b1J 1

b2J 2

b3J 3

j = Jt

t=T

..
.
...

bTJ T

g
f
detection temporal
score coherence
score
Figure 4: The lattice constructed by the Viterbi algorithm for detection-based tracking.
The columns correspond to video frames t = 1, . . . , T . Each column contains the overgenerated collection bt1 , . . . , btJ t of detections for that frame. The rows correspond to detection
indices j. A track j, namely a sequence j 1 , . . . , j T of detection indices, corresponds to a
path through the lattice. The Viterbi algorithm finds the path that optimizes Equation 1,
among the exponentially many potential tracks, in time O(T J 2 ), where J is the maximum
of J 1 , . . . , J T .
This detection-based tracking framework is very general. It can use any detection
source(s), any method f (b) for scoring such detections b, and any method g(b′ , b) for scoring temporal coherence between detections b′ and b in adjacent frames. In the work reported here, we use the deformable part model (DPM) detector (Felzenszwalb, Girshick,
McAllester, & Ramanan, 2010a; Felzenszwalb, Girshick, & McAllester, 2010b) as the detection source, which yields detections represented as axis-aligned rectangles and use the
scores provided by DPM as the basis of f (b). The raw DPM score ranges from −∞ to
∞. Nominally, Equation 1 and the Viterbi algorithm can support such scores. However,
these raw DPM scores, unfortunately, are incomparable across object classes. For reasons
to be discussed in Section 2.3, joint tracking of multiple objects requires that the detection
scores be comparable across their object classes. Moreover, for reasons to be discussed
in Section 4, language acquisition requires moderately accurate indication of which object
classes are present in the field of view, which could be ascertained if the detection scores
were comparable across object classes. To address the above, we normalize the detection
scores f (b) within each object class using a sigmoid
1
1 + exp(−χ(f (b) − ρ))
609

Yu, Siddharth, Barbu, & Siskind

where the parameters χ and ρ are empirically determined per object class so that detection
score correlates with the probability of a detection being a true positive. We convert this,
and other values discussed in later sections, to log space, to protect against underflow in
floating-point calculations. Choosing the parameters χ and ρ in this fashion on a per-class
basis allows the resulting detection scores to be comparable across classes. Note that while
the resulting values of f (b) are in the range (−∞, 0], we do not take these to represent log
probabilities.
We use optical flow to compute the adjacent-frame temporal-coherence score. We employ
the FlowLib optical-flow library (Werlberger, Pock, & Bischof, 2010) as it is one of the
highest-performing methods on optical-flow benchmarks (Baker, Scharstein, Lewis, Roth,
Black, & Szeliski, 2011). More specifically, to compute g(bt−1
, bt ), we compute the optical
j t−1 j t
flow for frame t − 1, compute the average flow vector v inside the axis-aligned rectangle
for detection bt−1
, forward project this detection one frame by translating that rectangle
j t−1
along v, and compute the square of the Euclidean distance between the center of that
translated rectangle and the center of the corresponding rectangle for btj t . This yields a
value that measures how well the local detection displacement matches a local estimate
of its velocity and ranges from 0 to ∞ in a fashion that is inversely related to temporal
coherence. We wish this value to be comparable to the detection score f (b) so that temporal
coherence neither overpowers nor is overpowered by detection score. Thus we normalize
temporal coherence with a sigmoid as well, using a negative χ to invert the polarity, and
convert to log space. Unlike for detection score, a single set of sigmoid parameters can
be used across all object classes, because the temporal-coherence score only depends on
detection centers. Note that again, while the resulting values of g(b′ , b) are in the range
(−∞, 0], we do not take these to represent log probabilities. Moreover, even though the
values of f (b) and g(b′ , b) are in the range (−∞, 0], and the values produced by Equation 1
also lie in that range, they do not represent log probabilities.
2.2 Event Recognition Based on Motion Proﬁle using HMMs
Given a particular track collection, one can determine whether those tracks depict a given
event by measuring time-varying properties of those tracks. Such properties could be the
relative and/or absolute object positions, velocities, and/or accelerations. The time-varying
properties can be represented abstractly as a time-series of feature vectors computed from
the tracks. In this view, event recognition can be formulated as time-series classification.
Such classification can be performed by hidden Markov models (HMMs), either by computing a likelihood or a MAP estimate. Let us limit consideration, for a moment, to events
with a single participant. In this case, we can abstractly take such an HMM to consist
of K states, a state-transition function a(k ′ , k) in log space, and an output model h(k, b)
which denotes the log probability of generating a detection b in state k. Let us refer to
the collection of K, a, and h as an event model λ. In log space, the MAP estimate for a
particular track j is
!
!
T
T
X
X
t t
t−1 t
max
h(k , bj t ) +
a(k , k )
(2)
k

t=1

t=2

k1 , . . . , kT

where k is a sequence
of states. Let Bj denote the detection sequence b1j 1 , . . . , bTjT
selected from the video clip B by the track j. Equation 2 constitutes a measure of how
610

Grounding Language Inference, Generation, and Acquisition in Video

well the detection sequence Bj selected from a video clip B by a track j depicts an event
model λ. Higher MAP estimates result from tracks that better depict the event model.
MAP estimates can be computed efficiently using the Viterbi algorithm in time O(T K 2 ).
Note the similarity between Equations 2 and 1. This is due to the aforementioned analogy.
Momentarily, we will crucially avail ourselves of the fact that both can be computed with
the Viterbi algorithm. But we first need to address several subtleties in our formulation.
We use HMMs to encode probability distributions over time-series of feature vectors
extracted from object tracks. These in turn serve to represent the meanings of verbs that
describe the motion of such participant objects. For example, the meaning of the word
bounce might be represented with an HMM, like that in Figure 5, that places high probability on a track that exhibits alternating downward and upward motion. While such
representations are tolerant of noisy input and can be learned using Baum-Welch (Baum,
Petrie, Soules, & Weiss, 1970; Baum, 1972), HMMs with many states, many features, and
non-sparsely populated state-transition functions and output models are difficult for humans to understand and create. In Sections 5.3 and 5.4, we conduct experiments with
human-generated meaning representations. While, in Section 5.5, we conduct experiments
with machine-learned meaning representations, we also compare such with human-generated
meaning representations. To facilitate perspicuity in human-generated meaning representations, we adopt a regular-expression notation, such as the following representation of the
meaning of the word bounce:
△

λbounce = (movingDown+ movingUp+ )+
In the above, movingDown(b) and movingUp(b) are predicates over detections b that are
used to construct the output model h(k, b) and the regular expression is used to determine
the number K of states, the state-transition function a(k ′ , k), and which predicate to employ
as the output model for a given state. These can be straightforwardly converted to finitestate machines (FSMs) which can, in turn, be viewed as a special case of HMMs with 0/1
state-transition functions and output models (−∞/0 in log space).
Equation 2 is formulated abstractly around a single state-transition function a(k ′ , k). We
also must include distributions over initial and final states. Traditional HMM formulations
only incorporate initial-state distributions but not final-state distributions. Such HMMs
might recognize a prefix of an event specification and not be constrained to match the
entire event specification. (Without an initial-state distribution, it might recognize any
subinterval of an event specification.) Our actual formulations include such initial- and
final-state distributions but we omit them from our presentation for the sake of expository
clarity.
Formulating the output model h(k, b) so as to depend on the detections in a single
track allows an HMM to encode time-varying constraints on that single track. This can be
used to represent the meaning of an intransitive verb that describes the motion of a single
participant. We wish, however, to also be able to represent the meanings of transitive verbs
that describe the motion of pairs of participants. We accomplish this by extending the
output model h(k, b1 , b2 ) to depend on pairs of detections, one from each track. If we have
two distinct tracks j1 = (j11 , . . . , j1T ) and j2 = (j21 , . . . , j2T ) for two distinct participants,
we can think of them as deriving from the same detection pool. This allows extending
611

Yu, Siddharth, Barbu, & Siskind

0.01
0.99

0.99

0.98

0.01

0.01

0.01

0

1.0

upward

rightward

leftward

downward

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

upward

rightward

leftward

downward

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

upward

rightward

leftward

downward

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

velocity magnitude
velocity orientation
for the first argument for the first argument

Figure 5: An HMM that represents the meaning of the word bounce as a track that exhibits
alternating downward and upward motion.
Equation 2 as
max
k

T
X
t=1

h(k t , btj t , btj t )
1

2

!

+

T
X
t=2

a(k t−1 , k t )

!

(3)

to support this.
HMMs can be susceptible to short-term noise in the input signal. If one were to have
an event model, such as that in Figure 6(a), that is intended to match a time series where
there is an interval where the velocity is zero, followed by an interval where there is upward
motion, followed by an interval where the velocity is again zero, it may unintentionally
match a time series where the interval of upward motion is but a single frame that is
spurious and the result of noisy tracking and feature extraction. The same thing might
happen with an FSM representation such as
△

rest(b1 , b2 ) = stationary(b1 ) ∧ stationary(b2 ) ∧ close(b1 , b2 )
△

action(b1 , b2 ) = stationary(b1 ) ∧ movingUp(b2 ) ∧ close(b1 , b2 )
△

λpick up = rest+ action+ rest+
that is intended to model the meaning of pick up as a period of time where the agent is
stationary and close to the patient that is subdivided into three sequential intervals where
612

Grounding Language Inference, Generation, and Acquisition in Video

0.99

0.99
0.01

1.00
0.01

0

1.0

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

0.99

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

velocity magnitude
for the first argument

(a)

0.99

0.99

0.99

0.01

0.01

0.01

1.00
0.01

0

1.0

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

velocity magnitude
for the first argument

(b)

Figure 6: (a) An HMM that is susceptible to short-term noise in the input signal. The
central state might admit a noisy impulse lasting a single frame. (b) A variant of (a) that
constrains the central interval to hold for at least 3 frames.
the patient is at first stationary, then moves up, and then is stationary again. This can
unintentionally match a time series where the patient is continually stationary except for
a single frame that is spurious and the result of noisy tracking and feature extraction. We
can address this issue by requiring the central interval to have a minimum duration. We
△

indicate such with the regular-expression operator R{n,} = R
. . R} R∗ to indicate that
| .{z

the R must be repeated at least n times. A definition such as

n

△

λpick up = rest+ action{3,} rest+

can be reduced to an FSM within our framework. Similarly, one can add a minimum stateduration requirement to an HMM, such as that in Figure 6(a), by recoding it as in Figure 6(b).
The above handles short-term false positives, namely the presence of a short-term spuriously true signal. We also need to handle short-term false negatives, namely an intended
613

Yu, Siddharth, Barbu, & Siskind

longer interval where a signal must meet a specified condition but fails to do so due to
a short-term failure to meet that condition. We use a new regular-expression operator
△

R[n,] = (R [true]){n,} to indicate that R must be repeated at least n times but can optionally have a single frame of noise between each repetition. One can extend HMMs in
a similar fashion though we have not found the need to do so because the output models
already can tolerate some noise.
Nominally, our detections btj are axis-aligned rectangles represented as image coordinates. This allows the output models h(k, b) to depend on quantities that can be computed
from such, e.g., position of the detection center, the size of the detection, and the aspect
ratio of the detection, which can indicate notions like big, small, tall, or wide. It also allows
two-track output models h(k, b1 , b2 ) to depend on quantities like the distance between detection centers or the orientation of a line between those centers, which can indicate notions
like close, far, above, or below. Without further information, it is not possible for the output
models to depend on relative or absolute velocity, which would be needed to encode notions
like fast, slow, stationary, moving, upwards, downwards, towards, or away from. One way
to achieve such would be to extend the output models to depend on detections from adjacent frames, as in h(k, b′ , b) or h(k, b′1 , b1 , b′2 , b2 ). We can accomplish such with a variant of
Equation 2 that sums over pairs of adjacent detections.
!
T
X
t t−1
t
t−1 t
max
h(k , bj t−1 , bj t ) + a(k , k )
k

t=2

This can be further generalized by extending the sums over three adjacent frames for acceleration, or even over more frames for longer-term velocity and acceleration. However,
multiple-point estimates, e.g., two-point velocity estimates or three-point acceleration estimates, suffer from noise due to inaccurate tracking. Moreover, such extensions would
not support other desired features that could be extracted from the image, such as color.
Thus we instead extend the notion of detection to include any information that might be
extracted from the image at the location of the detection, such as average hue or optical
flow inside the detection, and retain the initial formulation of output models h(k, b) and
h(k, b1 , b2 ) that depends on detections in a single frame.
2.3 The Event Tracker
The aforementioned method operates as a feed-forward pipeline. Equation 1 produces tracks
for event participants, a time series of feature vectors is extracted from such tracks, and
those time series are classified with HMMs to detect verb/event occurrences. This approach,
however, can be very brittle. Failure earlier in the pipeline necessarily leads to failure later in
the pipeline. This is particularly of concern, since the pipeline starts with object detections
and, as we mentioned before, state-of-the-art object detection is unreliable.
Barbu et al. (2012b) presented a novel approach for addressing this brittleness called
the event tracker. This approach originates from the observation that Equations 1 and 2
share the same structure due to the aforementioned analogy, and thus share an analogous
algorithmic framework for performing the optimization through analogous lattices. The
feed-forward pipeline essentially cascades these algorithms and lattices, as shown in Figure 7(a). This independently optimizes Equation 1, as a measure of how well a video clip B
614

Grounding Language Inference, Generation, and Acquisition in Video

depicts a track j, and Equation 2, as a measure of how well the detection sequence Bj
selected from a video clip B by the track j depicts an event model λ, performing the former before the latter, and constructing the latter optimization problem around the track j
produced by the former. Doing so takes Equation 2 as the sole measure of how well a video
clip B depicts an event model λ. More precisely, it performs the following optimization:
!
!
T
T
X
X
max
h(k t , bt̂t ) +
a(k t−1 , k t )
k
t=1
t=2
!
!
(4)
T
T
X
X
t−1
where ̂ = argmax
f (btj t ) +
g(bj t−1 , btj t )
j

t=1

t=2

While this does measure how well the detection sequence Bj selected from the video clip B
by the track j depicts an event model λ, it might not measure how well the video clip B
depicts the event model λ because it fails to incorporate into that measure how well the
video clip B depicts the track j. Thus, we might instead take the sum of Equations 1 and 2
as the measure of how well a video clip B depicts an event model λ. More precisely, we
could adopt the following measure which involves the same optimization as Equation 4:
!# "
"
!
!
!#
T
T
T
T
X
X
X
X
t−1
t t
t
t−1 t
t
max
h(k , b̂t ) +
f (bj t ) +
a(k , k )
g(bj t−1 , bj t )
+ max
j
k
t=1
t=2
t=1
t=2
!
!
T
T
X
X
g(bt−1
, bt )
f (btj t ) +
where ̂ = argmax
j t−1 j t
j

t=2

t=1

(5)
This still independently optimizes the track j with Equation 1 and the state sequence k
with Equation 2. We could, however, attempt to jointly optimize the track j and the state
sequence k. This could be done by lifting both the maximizations over the track j and
the state sequence k outside the summation of the measures of how well the video clip B
depicts the track j and how well the detection sequence Bj selected from the video clip B
by the track j depicts the event model λ. This leads to the following optimization problem:
!
!
!
!
T
T
T
T
X
X
X
X
max
a(k t−1 , k t )
(6)
f (btj t ) +
g(bt−1
, bt ) +
h(k t , btj t ) +
j t−1 j t
j,k

t=1

t=2

t=1

t=2

The crucial observation by Barbu et al. (2012b) is that Equation 6 has the same structure as
both Equations 1 and 2 and can be optimized using the same Viterbi algorithm by forming
a cross-product of the tracker and HMM lattices, as shown in Figure 7(b), where each node
in the resulting lattice combines a detection and an HMM state, as shown in Figure 7(c).
Since the width of the cross-product lattice is O(JK), applying the Viterbi algorithm to
this cross-product lattice finds the path that optimizes Equation 6, among the exponentially
many potential paths, in time O(T (JK)2 ).
Like before, Equation 6 can trivially be modified to denote a MAP estimate in log space
with suitable normalization. However, we do not need to do so because the constant factor
introduced by such normalization would not change the result of the joint optimization of
the track j and the state sequence k. Like before, the Viterbi algorithm can be applied to
615

Yu, Siddharth, Barbu, & Siskind

(a)

t=1

t=2

t=3

j=1

b11

b21

b31

...

bT1

j=2

b12

b22

b32

...

bT2

j=3

b13

b23

b33

...

bT3

j = Jt

..
.

..
.

..
.

b1J 1

b2J 2

b3J 3

t=1

t=2

t=3

k=1

1

1

1

...

1

k=2

2

2

2

...

2

k=3

3

3

3

...

3

..
.

..
.

..
.

K

K

K

t=T

..
.
...

bTJ T

k=K

f
g
detection temporal
score coherence
score

max
j

(b)

T
X
t=1

tracker lattice
!
!
T
X
t−1
t
t
f (bj t ) +
g(bj t−1 , bj t )

max
k

t=2

t=1

t=2

t=3

b11

b21

b31

...

bT1

j=2

b12

b22

b32

...

bT2

j=3

b13

b23

b33

...

bT3

..
.

..
.

..
.

b1J 1

b2J 2

b3J 3

T
X
t=1

...

K

verb lattice
!
!
T
X
t t
t−1 t
h(k , bj t ) +
a(k , k )
t=2

t=1

t=2

t=3

k=1

1

1

1

...

1

k=2

2

2

2

...

2

k=3

3

3

3

...

3

..
.

..
.

..
.

K

K

K

t=T

×

..
.
...

bTJ T

k=K

f
g
detection temporal
score coherence
score

t=T

..
.
...

K

h
a
output state
model transition
function

tracker lattice
!
!
T
T
X
X
t−1
t
t
max
f (bj t ) +
g(bj t−1 , bj t ) +
j,k

..
.

h
a
output state
model transition
function

j=1

j = Jt

t=T

t=1

t=2

j=1

j = Jt

T
X
t=1

verb lattice
!
!
T
X
t t
t−1 t
h(k , bj t ) +
a(k , k )
t=2

t=1

t=2

t=3

b11 , 1

b21 , 1

b31 , 1

t=T

..
.

..
.

..
.

b1J 1 , 1

b2J 2 , 1

b3J 3 , 1

...

bTJ T , 1

b11 , 2

b21 , 2

b31 , 2

...

bT1 , 2

..
.

..
.

..
.

b2J 2 , K

b3J 3 , K

...

bT1 , 1
..
.

(c)

b1J 1 , K

g, a

..
.
...

bTJ T , K

f, h

Figure 7: (a) A pipeline consisting of a cascade of a tracker lattice followed by an HMM lattice
used for verb/event recognition. In (a), finding the track j that optimizes the measure of how well
a video clip B depicts that track, Equation 1, happens independently of and prior to finding the
state sequence k that optimizes the measure of how well the detection sequence Bj selected from
a video clip B by the track j depicts the event model λ, Equation 2, the latter depending on the
track j produced by the former. Since only the portion from Equation 2 is used as the measure of
how well video clip B depicts event model λ, this corresponds to optimizing the scoring function
in Equation 4. Taking the measure of how well a video clip B depicts an event model λ as a
combination of measures of how well the video clip B depicts the track j and how well the detection
sequence Bj selected from the video clip B by the track j depicts an event model λ can be viewed as
optimizing the scoring function in Equation 5, the sum of the two measures. (b) A variant of (a) that
jointly optimizes the two measures corresponding to the optimization in Equation 6 that migrates
the optimization outside the sum. (c) A method for performing the joint optimization in (b) by
forming a cross-product lattice.
616

Grounding Language Inference, Generation, and Acquisition in Video

Equation 6 without any constraint on permissible values for the detection score f (b), the
temporal-coherence score g(b′ , b), the output model h(k, b), and the state-transition function
a(k ′ , k) However, constraining them to lie in the same range empirically allows it to serve
as a good scoring function.
The event tracker ameliorates the brittleness of the feed-forward pipeline by allowing topdown information about the event to influence tracking. Using HMMs as event recognizers is
accomplished by selecting that event model which best fits the event. This involves running
each event model independently on the data. In the context of running a particular event
model on the data, that event model could influence tracking in a top-down fashion. For
example, in the context of evaluating how well an event model for walk fits the data, the
tracker would be biased to produce tracks which move at a normal walking pace. Stationary
tracks, or those that move too quickly, would not depict the target event and would be
filtered out by Equation 6 but not by Equations 1, 4, or 5, when such tracks comprised
high-scoring detections and were temporally coherent.
Equation 6 jointly optimizes a single tracker and a single event model. As such, it can
only recognize events that have a single participant, such as those described by intransitive
verbs. Events with two participants, such as those described by transitive verbs, can be
encoded using the methods from Section 2.2, by using Equation 3 instead of Equation 2
and forming the cross product of this with two trackers instead of one.
!
!
!
!
T
T
T
T
X
X
X
X
t−1
t−1
t
t
t
t
(7)
g(bj t−1 , bj t )
f (bj t ) +
g(bj t−1 , bj t ) +
f (bj t ) +
max
2
2
1
1
j1 ,j2 ,k
2
1
t=2
t=1
t=2!
t=1
!
T
T
X
X
a(k t−1 , k t )
h(k t , btj t , btj t ) +
+
t=1

1

2

t=2

This can be further generalized from two participants to L participants.
!#
" L
!
T
T
X X
X
t−1
t
t
g(bj t−1 , bj t )
max
f (bj t ) +
l
l
J,k
l
t=2
t=1
l=1
!
!
T
T
X
X
a(k t−1 , k t )
+
h(k t , btj t , . . . , btj t ) +
t=1

L

1

(8)

t=2

In the above, J denotes a track collection j1 , . . . , jL which, in turn, comprises detection
indices jlt . Equations 7 and 8 can also be optimized with the Viterbi algorithm by forming
a cross-product lattice. Since the width of this cross-product lattice is O(J L K), applying
the Viterbi algorithm to this cross-product lattice finds the path that optimizes Equation 8,
among the exponentially many potential paths, in time O(T (J L K)2 ). Note that this is
exponential in the number L of participants. In practice, however, the arity of the semantic
predicate underlying most events is limited, such as to three in the case of ditransitive verbs.
Let BJ denote the detection-sequence collection b1j 1 , . . . , bTjT , . . . , b1j 1 , . . . , bTjT selected
1
L
1
L
from the video clip B by the track collection J. Equation 8 jointly optimizes a measure
of how well the video clip B depicts the event model λ as a combination of measures
of how well the video clip B depicts the track collection J and how well the detectionsequence collection BJ selected from the video clip B by the track collection J depicts an
617

Yu, Siddharth, Barbu, & Siskind

p2

b1 b2

b1
p1

p1

b2
p2
b1

p2

b2 p1

Figure 8: Example showing the necessity for normalization of detection scores across different object classes. (left) Image depicting two pairs of detections for the person and
backpack object classes. (right top) Distribution of raw detection scores for the two object
classes. Indicated are scores corresponding to the detections in the image where f (b1 ) = 4,
f (b2 ) = 6, f (p2 ) = 11, and f (p1 ) = 14. (right bottom) Distribution of detection scores for
the two object classes after cross-object-class normalization where f (b1 ) = 5, f (b2 ) = 12,
f (p2 ) = 9, and f (p1 ) = 14.

event model λ. Note that Equation 8 involves the summation over multiple detection-score
components f , one for each of the L participants. The fact that raw detection scores are
incomparable across object class means that the detection scores for different participants
contribute to different extents in the final score. Figure 8 shows an example where differences
in variance between detection scores for person and trash can result in a better score through
Equation 8 for a spurious set of detections. The values p1 and p2 indicate detections for
the person object class and the values b1 and b2 indicate detections for the backpack object
class. Let us assume that both pairs of detections, (p1 , b1 ) and (p2 , b2 ), match an event
model, such as carry, equally well. In that case, the raw detections scores would yield
(p1 , b1 ) as the best match because f (p1 ) + f (b1 ) > f (p2 ) + f (b2 ). It is for this reason
that we employ normalization of detection scores as discussed in Section 2.1. Doing so
results in the selection of the correct pair of detections, (p2 , b2 ), since after normalization,
f (p2 ) + f (b2 ) > f (p1 ) + f (b1 ).
Figure 9 illustrates the power of the event tracker. The objective is to track the person.
However, due to the poor performance of the state-of-the-art person detector, it produces
strong false-positive detections on the bench in the background. Even when overgenerating
detections, as shown in Figure 9(a), and selecting a track that optimizes Equation 1, as
shown in Figure 9(b), this tracks the bench in the background for a portion of the video clip,
618

Grounding Language Inference, Generation, and Acquisition in Video

(a)

(b)

(c)

Figure 9: Keyframes from a video clip that demonstrates the advantages of the event
tracker. (a) Overgenerated person detections. (b) Detections selected by detection-based
tracking in Equation 1. Note that it selects a strong false-positive detection on a bench in
the background and is not able to rule out such detections as with the exception of a single
large jump, the rest of the track happens to be temporally coherent. (c) Detections selected
by the event tracker from top-down information, in the form of a model for the transitive
verb carry, constraining such detections to fill the role of agent in the event, in the context
where a backpack, as patient, is carried by the person but not by the bench.
instead of a person. This happens because the track is largely temporally coherent within
segments, and in combination with the strong false-positive detections in the background,
overpowers the adverse effect of a single large jump, thus yielding a high score for Equation 1.
However, top-down information in the form of an event model for the transitive verb carry,
linked to two trackers, one for an agent and one for a patient, selects a track for the agent,
comprising true-positive person detections, that accurately reflects the role played by the
person in the event, as shown in Figure 9(c), where a backpack, as patient, is carried by
the person and not by the bench in the background.
2.4 The Sentence Tracker
The event tracker from the previous section, and more generally HMM-based event recognizers, can model events with varying numbers of participants (one, two, and L participants
619

Yu, Siddharth, Barbu, & Siskind

for the event trackers in Equations 6, 7, 8 and one or two participants for the HMM-based
event recognizers in Equations 2 and 3). Nominally, we can think of such events as being
described by verbs: one-participant events as intransitive verbs, two-participant events as
transitive verbs, and three-participant events as ditransitive verbs. Figures 25 through 28
in Appendix B gives examples of HMMs that represent the meanings of verbs. However,
nothing in the framework formally restricts us to doing so. The meanings of words in other
parts of speech can often also be represented as HMMs. For example, the meaning of a
noun that describes an object class can be represented as a single-state one-participant
HMM whose output model serves as a classifier for that object class. Figure 23 in Appendix B gives examples of HMMs that represent the meanings of nouns. Similarly, the
meaning of an adjective that describes object characteristics can be represented as a singlestate one-participant HMM whose output model serves to select detections that exhibit the
desired characteristics reflected by that adjective. For example, the meanings of adjectives
like big or tall could be represented with output models over the areas or aspect ratios
of participant detections. Likewise, the meaning of a preposition that describes a spatial
relation between two objects can be represented as a single-state two-participant HMM
whose output model serves to select the collection of features that encode that relation. For
example, the meaning of the preposition to the left of could be represented with an output
model over the relative x-coordinates of the detections for the participants. Figure 24 in
Appendix B gives examples of HMMs that represent the meanings of spatial-relation prepositions. More generally, any static property of either a single participant, or a collection of
participants, can be encoded as a single-state HMM.
Multiple-state HMMs can encode the dynamic properties of either a single participant
or a collection of participants. Such can reflect the meanings of adverbs and prepositions
in addition to verbs. For example, the meaning of an adverb such as quickly that describes
the changing characteristics of the motion of a single participant could be represented as a
three-state HMM describing the transition from no motion, to motion with high velocity,
back to no motion. Figure 29 in Appendix B gives examples of HMMs that represent the
meanings of adverbs. Similarly, the meaning of a preposition such as towards that describes
the changing relative motion between a pair of participants could be represented as a threestate HMM describing the transition from the agent being distant from the goal, to a period
where the distance between the agent and the goal decreases while the goal is stationary,
ending with the agent being close to the goal. Figure 30 in Appendix B gives examples of
HMMs that represent the meanings of motion prepositions.
We thus see that the distinction between different parts of speech is primarily syntactic,
not semantic, i.e., how word use is reflected by the grammar, not its potential meaning.
While there may be some coarse-grained trends, such as the canonical structure realizations
(CSRs) proposed by Grimshaw (1979, 1981) and Pinker (1984), where nouns typically describe object class, adjectives typically describe object properties, verbs typically describe
event class, adverbs typically describe event properties, and prepositions typically describe
spatial relations, this is not universally the case. Some intransitive verbs like sleep describe a more static object property, some transitive verbs like hold describe a more static
spatial relation between pairs of objects, and some nouns like wedding describe an event.
While it might seem like overkill to represent static classifiers as single-state HMMs, there
are several advantages to adopting a single uniform meaning representation in the form of
620

Grounding Language Inference, Generation, and Acquisition in Video

HMMs. First, the capacity for multiple states affords the ability to encode a resilience to
temporal noise. Thus in practice, even static properties might be more robustly encoded
with multiple states. Second, adopting a single uniform representation simplifies the overall
framework and associated algorithms.
The event tracker from the previous section could influence detection-based tracking with
top-down information from an event model. This event model could represent the meaning
of an individual word. It could constrain a single track for single-participant words like
intransitive verbs (Equation 6), a pair of tracks for two-participant words like transitive
verbs (Equation 7), or even a collection of L tracks for L-participant words (Equation 8).
Just as it was possible to take cross products of multiple trackers with a single event
model, one can further extend the framework to take cross products of multiple trackers
with multiple event models, thereby constraining the track collection to jointly satisfy a
collection of event models for the words s1 , . . . , sW in a sentence s.
!#
" L
!
T
T
X X
X
t−1
t
t
(9)
max
f (bj t ) +
g(bj t−1 , bj t )
l
l
J,K
l
t=2
l=1
" W t=1 T
!
!#
T
X X
X
t
t−1 t
+
hsw (kw
, btj t , . . . , btj t ) +
asw (kw
, kw )
w=1

L

1

t=1

t=2

In the above, K denotes a state-sequence collection k1 , . . . , kW which, in turn, comprises
t . This has L distinct trackers with distinct detection indices j t that select
state indices kw
l
the optimal detection for participant l in frame t.
We distinguish between words in the lexicon and occurrences of those in sentences. We
refer to the former as lexical entries e and the latter as words w. A given lexical entry
may appear as more than one word in a sentence. A lexicon Λ contains E event models
λ1 , . . . , λE , one event model λe for each lexical entry e. A sentence s is formulated as a
sequence s1 , . . . , sW of W lexical entries sw , one for each word w. Equation 9 has W distinct
event models λsw , one for each word w in the sentence s, each taken as the event model for
the lexical entry sw for that word w. Each event model λsw has distinct numbers Ksw of
states, state-transition functions asw , and output models hsw . Note that while the statetransition functions asw and output models hsw vary by word w, the detection score f and
the temporal-coherence score g do not vary by participant l.
t , bt , . . . , bt ) for each word w
As formulated in Equation 9, the output model hsw (kw
t
jL
j1t
depends on the detections for frame t selected by the tracks j1 , . . . , jL for all L participants.
In practice, the meaning of each individual word only applies to a subset of the participants,
as illustrated in Figure 10. Here, the sentence The person to the left of the stool carried
the traffic cone towards the trash can describes an event that has four participants: an
agent, a referent, a patient, and a goal. The nouns person, stool, traffic cone and trash
can refer to the agent, referent, patient, and goal respectively. The verb carried describes
a semantic relation only between the agent and the patient. The preposition to the left
of describes a semantic relation only between the agent and the referent. The preposition
towards describes a semantic relation only between the agent and the goal. We employ
i to indicate which participant fills argument i for the event model
a linking function θw
for word w. Let Bhs, t, w, Ji denote btj t , . . . , btj t , the collection of detections selected in
Is
θw w

1
θw

621

Yu, Siddharth, Barbu, & Siskind

frame t by the track collection J as assigned to the Isw arguments of the event model for
word w by the linking function θ. We incorporate the arity I in an event model λ, along
with the number K of states, the state-transition function a, and the output model h. This
allows reformulating Equation 9 as
!
!#
" L
T
T
X
X X
g(bt−1
, bt t )
f (btj t ) +
(10)
max
jlt−1 jl
l
J,K
t=2
t=1
l=1
"W
!
!#
T
T
X X
X
t
t−1 t
+
hsw (kw , Bhs, t, w, Ji) +
asw (kw , kw )
w=1

t=1

t=2

We refer to Equation 10 as the sentence tracker. For the remainder of this paper, Isw ≤ 2.
Equation 10 can also be optimized with the Viterbi algorithm by forming a cross-product
lattice. Since the width of this cross-product lattice is O(J L K W ), where K is the maximum of Ks1 , . . . , KsW , applying the Viterbi algorithm to this cross-product lattice finds the
path that optimizes Equation 10, among the exponentially many potential paths, in time
O(T (J L K W )2 ). Note that this is exponential both in the number L of participants and the
sentence length W . In practice, however, natural-language sentences have bounded length
and are typically short. Moreover, the quadratic time complexity is mitigated somewhat
W
Y
by the fact that K W is an approximation to
Ksw . In practice, nouns, adjectives, and
w=1

spatial-relation prepositions describe static properties of tracks and thus have word models where Ksw = 1. Even longer sentences will be comprised predominantly of such word
models and will contain relatively few verbs, adverbs, and motion prepositions.
Modeling the meaning of a sentence through a collection of words whose meanings are
modeled by HMMs defines a factorial HMM for that sentence, where the overall Markov
process for that sentence is factored into independent component processes (Brand, Oliver,
& Pentland, 1997; Zhong & Ghosh, 2001) for the individual words. In this view, K denotes
the state sequence for the combined factorial HMM and kw denotes the factor of that state
sequence for word w. Figure 11 illustrates the formation of the cross product of two tracker
lattices (Equation 1) and three word lattices (Equation 2), linked together by an appropriate
linking function θ to implement the sentence tracker (Equation 10) for the sentence The
person carried the backpack. Figure 12 illustrates the resulting cross-product lattice where
each node in the lattice consists of the combination of two detections, one for each tracker
lattice, and three HMM states, one for each word lattice. The state thus represented by
each node in this cross-product lattice can be factored into a collection of states written
inside the node separated by commas.
Equation 10 constitutes S : (B, s, Λ) 7→ (τ , J). It scores a video-sentence pair with a
measure of how well a given video clip B depicts a given sentence s, as interpreted by a given
lexicon Λ. Alternatively, that score measures how well a given sentence s, as interpreted by
a given lexicon Λ, describes a given video clip B. T and J 1 , . . . , J T are determined from B,
W is determined from s, the arities Isw , the numbers Ksw of states, the state-transition
functions asw and the output models hsw are taken from the words models λsw , and the
number L of participants and the linking function θ are computed from the sentence s by the
linking process Θ : s 7→ (L, θ) described in Section 3. The result of Equation 10 constitutes
the video-sentence score τ . The track collection that yields that score constitutes J.
622

Grounding Language Inference, Generation, and Acquisition in Video

The person to the left of the stool carried the traﬃc cone towards the trash can.

i
θw
agent

patient

referent

goal

jlt
detection 0

detection 1

detection 2

detection 3

3
0

1
2

Figure 10: An illustration of the linking function θ used by the sentence tracker. Each
word in the sentence has one or more arguments. (When words have two arguments,
the first argument is indicated by a solid line and the second by a dashed line.) Each
argument of each word is filled by a participant in the event described by the sentence. A
given participant can fill arguments for one or more words. Each participant is tracked by
a tracker which selects detections from a pool of detections produced by multiple object
i from arguments i of words w to participants is determined
detectors. The upper mapping θw
by parsing the sentence. The lower mapping jlt from participants l in frames t to detections
is determined automatically by Equation 10. This figure shows a possible (but erroneous)
interpretation of the sentence where the lower mapping, indicated by the darker lines, is:
agent 7→ detection 3, referent 7→ detection 0, patient 7→ detection 1, and goal 7→
detection 2.

623

Yu, Siddharth, Barbu, & Siskind

t=1

t=2

t=3

t=1

t=2

t=3

j1 = 1

b11

b21

b31

...

bT1

j1 = 1

b11

b21

b31

...

bT1

j1 = 2

b12

b22

b32

...

bT2

j1 = 2

b12

b22

b32

...

bT2

j1 = 3

b13

b23

b33

...

bT3

j1 = 3

b13

b23

b33

...

bT3

..
.

..
.

..
.

..
.

..
.

..
.

b1J 1

b2J 2

b3J 3

b1J 1

b2J 2

b3J 3

...

bTJ T

j1 = J t

fa

t=T

×

..
.
...

bTJ T

j1 = J t

fp

ga

t=1

t=2

t=3

1

1

1

...

1

k wp = 2

2

2

2

...

2

k wp = 3

3

3

3

...

3

..
.

..
.

..
.

Kswp

Kswp

Kswp

kwp = Kswp

patient-tracker

t=1

t=2

t=3

k wc = 1

1

1

1

...

1

k wc = 2

2

2

2

...

2

k wc = 3

3

3

3

...

3

..
.

..
.

..
.

Kswc

Kswc

Kswc

t=T

×

..
.
...

Kswp

h s wp a s wp

..
.

gp

agent-tracker

k wp = 1

t=T

kwc = Kswc

t=1

t=2

t=3

k wb = 1

1

1

1

...

1

k wb = 2

2

2

2

...

2

k wb = 3

3

3

3

...

3

..
.

..
.

..
.

Kswb

K swb

K s wb

...

K s wb

t=T

×

..
.
...

Kswc

k w b = K s wb

..
.

h s wb a s wb

hs wc a s wc

person

t=T

backpack

carried

Figure 11: Forming the cross product of two tracker lattices (Equation 1) and three word
lattices (Equation 2) to implement the sentence tracker (Equation 10) for the sentence The
person carried the backpack. The connections between the tracker lattices and the word
lattices denote the linking function θ.

t=1

t=2

t=3

b11 ,b11
1,1,1

b21 ,b21
1,1,1

b31 ,b31
1,1,1

..
.

..
.

..
.

j1 =J t ,j2 =J t
kwp =1,kwc =1,kwb =1

b1 1 ,b1 1
J
J
1,1,1

b2 2 ,b2 2
J
J
1,1,1

b3 3 ,b3 3
J
J
1,1,1

...

bT T ,bT T
J
J
1,1,1

j1 =1,j2 =1
kwp =1,kwc =1,kwb =2

b11 ,b11
1,1,2

b21 ,b21
1,1,2

b31 ,b31
1,1,2

...

T
bT
1 ,b1
1,1,2

..
.

..
.

..
.

j1 =1,j2 =1
kwp =1,kwc =1,kwb =1

j1 =J t ,j2 =J t
kwp =Kswp ,kwc =Kswc ,kwb =Ksw

b1 1 ,b1 1
J
J
Kswp ,Kswc ,Ksw

b

b

ga , gp , aswp , aswc , aswb

b2 2 ,b2 2
J
J
Kswp ,Kswc ,Ksw

b

b3 3 ,b3 3
J
J
Kswp ,Kswc ,Ksw

t=T
...

T
bT
1 ,b1
1,1,1

..
.

..
.
...
b

bT T ,bT T
J
J
Kswp ,Kswc ,Ksw

b

fa , fp , hswp , hswc , hswb

Figure 12: The actual cross-product lattice produced for the example in Figure 11. Note
that each node in the lattice consists of the combination of two detections, one for each
tracker lattice, and three HMM states, one for each word lattice.

624

Grounding Language Inference, Generation, and Acquisition in Video

3. The Linking Process
The sentence tracker requires specification of the number L of participants and the linking
i that indicates which participant fills argument i of word w for each argument
function θw
of each word in the sentence. Often, the same participant (i.e., tracker) can fill multiple
arguments of multiple words. A sentence like
The person to the right of the chair picked up the backpack
| {z } |
| {z } | {z }
| {z }
{z
}

(11)

θ11 = 1 θ21 = 1 θ22 = 2 θ31 = 2 θ41 = 1 θ42 = 3 θ51 = 3

(12)

1

2

3

4

5

has 3 participants and requires a linking function like

that assigns the argument of person and the first argument of both to the right of and
picked up to the first participant, the argument of chair and the second argument of to the
right of to the second participant, and the argument of backpack and the second argument
of picked up to the third participant. The number L of participants for a sentence s, and
the corresponding linking function θ, are produced by a linking process Θ : s 7→ (L, θ).
We use a particular linking process that is described in details in Appendix A. This process makes use of techniques from mainstream linguistics, namely X-bar theory (Jackendoff,
1977) and government relations (Chomsky, 1982; Aoun & Sportiche, 1983; Haegeman, 1992;
Chomsky, 2002). As such, it is limited to a small hand-built grammar (Figure 11a) and a
small lexicon (Figure 11b). For our purposes, this is not restrictive. The state of the art in
computer vision limits the number of distinct object classes that can be reliably detected
and the number of distinct action classes that can be reliably detected. This restricts the
number of nouns and verbs that can be supported by any method, such as ours, that attempts to ground language in computer vision methods that detect objects and actions.
This further restricts the class of utterances that can be constructed from a small set of
nouns and verbs. For this, a small hand-constructed grammar suffices. While one could
conceivably use methods that support larger grammars and vocabularies that process a
larger space of unrestricted text, it would not be possible to ground such in the current
state-of-the art computer vision techniques. We discuss this in further detail in Sections 6
and 7.
The linking process that we employ uses well-known techniques from mainstream linguistics. It is not the central contribution of our work. Rather, the central contribution
is the sentence tracker (Section 2.4). All the sentence tracker requires is any linking process Θ : s 7→ (L, θ) that maps a sentence s to the number L of participants and a linking
function θ. This need not be restricted to the particular grammar and lexicon from Figure 11. Indeed, it can employ any one of a plethora of well-known and well-understood
techniques that are common in the computational linguistics community. It need not even
be restricted to any particular grammar or lexicon. It is possible to construct a linking
process with standard mechanisms, such as the dependency relations produced by parsing
with a dependency grammar. For example, the Stanford Parser (Klein & Manning, 2003)
produces the dependencies on the right for the sentence in Equation 11, which can also be
used to determine the requisite number of participants and to construct the requisite linking
function. The output below correctly identifies three participants, person-2, chair-8, and
625

Yu, Siddharth, Barbu, & Siskind

det(person-2, The-1)
nsubj(picked-9, person-2)
det(right-5, the-4)
prep_to(person-2, right-5)
det(chair-8, the-7)
prep_of(right-5, chair-8)
root(ROOT-0, picked-9)
prt(picked-9, up-10)
det(backpack-12, the-11)
dobj(picked-9, backpack-12)

backpack-12. Note how the transitive verb picked-9 distinguishes between its two arguments,
identifying person-2 as its first argument through the nsubj dependency and backpack-12
as its second argument through the dobj dependency. Also note how the spatial relation
right-5 distinguishes between its two arguments, identifying person-2 as its first argument
through the prep to dependency and chair-8 as its second argument through the prep of
dependency.

4. Language Acquisition with the Sentence Tracker
Children learn language through exposure to rich perceptual context. They observe events
while hearing descriptions of such events. By correlating many events with corresponding
descriptions, they learn to map words, phrases, and sentences to meaning representations
that refer to the world. They come to know that the noun chair refers to an object class
which typically has a back and four legs. They also come to know that the verb approach
refers to a dynamic process in which one object moves towards another. These learned
concepts are not purely symbolic; they can be used to decide presence or absence of the
intended reference in perceptual input. Thus these concepts are perceptually grounded.
When children learn language, they are not usually given information about which
words in a sentence correspond to which concepts they see. For example, a child who hears
The dog chased a cat while seeing a dog chase a cat, with no prior knowledge about the
meaning of any word in this sentence, might entertain at least two possible correspondences
or mappings: (i) dog 7→ dog ∧ cat 7→ cat or (ii) dog 7→ cat ∧ cat 7→ dog. With the first,
the child might assume that chased means ran after while in the second the child might
assume that it means ran before. Thus a child who hears a description in the context of
an observed event will need to disambiguate among several possible interpretations of the
meanings of the words in that description. Things get worse when this process exhibits
referential uncertainty (Siskind, 1996): multiple simultaneous descriptions in the context of
multiple simultaneous events.
This situation faced by children motivates the formulation shown in Figure 13, where
video clips represent what children see and textual sentences represent what they hear. Note
that a given video clip can be paired with more than one sentence and a given sentence can be
paired with more than one video clip. Siskind (1996, 2001) showed that even with referential
uncertainty and noise, a system based on cross-situational learning (Smith, Smith, Blythe, &
Vogt, 2006; Smith, Smith, & Blythe, 2011) can robustly acquire a lexicon, mapping words
to word-level meanings from sentences paired with sentence-level meanings. However, it
did so only for symbolic representations of word- and sentence-level meanings that were not
626

Grounding Language Inference, Generation, and Acquisition in Video

The person picked up the traffic cone to the left of the stool.

The person picked up the traffic cone.

The person carried the chair.

The chair approached the backpack.

The chair approached traffic cone slowly.

The person carried the chair away from the backpack.

Figure 13: Video-sentence pairs in the language-acquisition problem. A video clip can be
paired with multiple sentences and a sentence can be paired with multiple video clips.
perceptually grounded. An ideal system would not require detailed word-level labelings to
acquire word meanings from video but rather could learn language in a largely unsupervised
fashion, just as a child does, from video paired with sentences. The algorithm presented in
this section can resolve the ambiguity inherent with such referential uncertainty to yield a
lexicon with the intended meaning for each word. While this algorithm can solve a problem
that is reminiscent to that faced by children, we make no psychological or neurophysiological
claims.
One can view the language-acquisition task as a constraint-satisfaction problem (CSP),
as depicted in Figure 14. Doing so treats words as variables, each with initially unknown
meaning. A video-sentence pair can be viewed as a constraint imposed on the words in that
sentence: the words in a sentence are mutually constrained by the requirement that the
collection of word meanings allow the sentence to describe the video clip. This constraint
will be formulated below using a variant of the sentence tracker from Section 2. Since the
same word may appear in different sentences, a sufficient number of video-sentence pairs
will form a connected network. We can do two types of inference on this network. First, one
can perform inference across different words in the same sentence. Suppose we know the
meanings of all the words in the sentence except for one. In this case, the meaning of the
unknown word can be inferred by applying the video-sentence constraint. For example, in
Figure 14, if we know the meaning of backpack and person, the meaning of picked up could
627

Yu, Siddharth, Barbu, & Siskind

chair

picked up
The person picked up the chair.
(b)

person
The chair approached the backpack.

The person picked up the backpack.
(a)
approached
backpack

Figure 14: Viewing language acquisition as a constraint-satisfaction problem (CSP) which is
solved by propagating information about word meanings around a network. Word meanings
in green are used to learn word meanings in orange which are then used to learn further
word meanings in red. This performs inference both across different words in the same
sentence, and shown in (a), and the same word in different sentences, as shown in (b).

be inferred from constraint (a), because that will be the only process that occurred between
the person and the backpack. Second, one can perform inference across the same word in
different sentences. The meaning of a given word can be shared and exploited by multiple
sentences when inferring the meanings of other words in those sentences. For example, after
learning the meaning of picked up, from constraint (b), the meaning of chair can also be
inferred. Thus, information about word meanings can propagate through the network. As a
result, word meanings are mutually constrained as they are learned. Siskind (1996) refers to
this learning mechanism as cross-situational learning. In practice, this process starts with
no information about any word meanings. But our formulation below using EM (Dempster,
Laird, & Rubin, 1977) can propagate partial information about word meanings. Thus by
starting with an initial guess at the meaning for each word and iterating this process, we
can converge to the intended lexicon.
As discussed earlier, the sentence tracker supports representing word meanings as HMMs
or as FSMS, a special case of HMMs where the state-transition functions and output mod628

Grounding Language Inference, Generation, and Acquisition in Video

els are 0/1 (−∞/0 in log space). In Section 5.2, we formulate the output models for
manually-constructed FSMs as regular expressions over Boolean features computed from
the detections using the predicates shown in Table 6. Our procedure for learning word
meanings employs HMMs where the state-transition functions and output models are not
0/1. In this case, the output models are derived from the features shown in Table 8. We
use Φ to denote the computation that produces the feature vectors from detections and N
to denote the length of such feature vectors. Word models λ are extended to incorporate N
and Φ.
We employ discrete distributions for our output models h. Further, we assume such
distributions are factorial in the features, i.e., the distributions over the features in the
feature vector are independent. To this end, we quantize each feature into bins. The
particular binning process is described in Section 5.5. This means that the output models
take the form
N
X
he (k, b1 , . . . , bIe ) =
hne (k, Φne (b1 , . . . , bIe ))
n=1

where

Φne (b1 , . . . , bIe ) ∈ {φne,1 , . . . , φne,Zen }
Zen indicates the number of bins for feature n for lexical entry e and φne,z indicates the
quantized value for bin z of feature n for lexical entry e.
Our learning procedure makes five assumptions.
1. Our training set contains M samples, each pairing a short video clip Bm with a
sentence sm that describes that clip. The procedure is not able to determine the
alignment between multiple sentences and longer video segments. Note that there is
no requirement that the clip depict only that sentence. Other objects may be present
and other events may occur. In fact, nothing precludes a training set with multiple
copies of the same clip, each paired with a different sentence describing a different
aspect of that clip. Similarly, nothing precludes a training set with multiple copies
of the same sentence, each paired with a different clip that depicts that sentence.
Moreover, our procedure potentially can handle a small amount of noise, where a clip
is paired with an incorrect sentence that does not describe the clip.
2. We already have (pre-trained) low-level object detectors capable of detecting instances
of our target event participants in individual frames of the video. We allow such detections to be unreliable; our method can handle a moderate amount of false positives
and false negatives using techniques from Section 2. We do not need to know the
mapping from these object-detection classes to nouns; our procedure determines that.
In other words, while our detectors locate and classify objects with symbolic labels like
chair, these labels are distinct from lexical entries like chair. Our procedure learns
the mapping from lexical entries to object-class labels. This mapping need not be
one-to-one and can be noisy. Learning such a mapping, however, requires that not
all object classes be present at all times, as that would not provide the constraint
required to learn such mapping—a lexical entry could correspond to any object class.
When such is not the case, we additionally need to identify which object classes are
present in the video clip. This is made possible by the fact that detection scores have
been rendered comparable, using the normalization process described in Section 2.1,
629

Yu, Siddharth, Barbu, & Siskind

and thus we can use these normalized scores as an indicator of object presence in the
video clip.
3. We know the part of speech ce associated with each lexical entry e. The particular
mapping from lexical entry to part of speech used in the experiments in Section 5.5
is given in Table 11(a).
4. The word models λ for all lexical entries of the same part of speech have the same
arity I, the same number K of states, the same feature-vector length N , and the
same computation Φ that produces the feature vectors, together with the associated
binning process for quantizing the features. These values are known and not learned.
The particular values for these parameters used in the experiments in Section 5.5 are
given in Table 8.
5. We know the linking process Θ and the grammar and lexicon portion needed to
determine the number L of participants and the linking function θ for each training
sentence. The particular linking process used in the experiments in Section 5.5 is
described in Section 3 using the grammar and lexicon portion from Table 11. We do
not know the track collection J chosen for each training sample. This is determined
automatically by the methods from Section 2.
The grammar, portions of the lexicon Λ, namely the components I, K, N , and Φ, and the
linking process Θ are prespecified and not learned. Only the state-transition functions a and
the output models hn are learned. One can imagine learning some or all of the grammar,
some or all of the nonlearned portions of the lexicon, and perhaps even the linking process Θ,
such as done by Kwiatkowski, Goldwater, Zettlemoyer, and Steedman (2012). We leave such
for future work.
4.1 The General Approach
We are given a grammar, portions of a lexicon Λ, namely the components I, K, N , and Φ,
and a linking process Θ. The lexicon contains E word models λe for lexical entries e. We are
given a training set of M samples, each a video clip Bm paired with a sentence sm . Let B
denote B1 , . . . , BM and S denote s1 , . . . , sM . We use the grammar, the nonlearned portions
of the lexicon Λ, and the linking process Θ to determine the number L of participants and
the linking function θ for each training sentence. If we had the state-transition functions ae
and the output models hne for the word models λe in the lexicon Λ, we could instantiate
the sentence tracker from Equation 10 on each training sample to compute a video-sentence
score τ for that sample. A side effect of doing this would be to compute the track collection J
that yielded that video-sentence score. Moreover, we could compute an aggregate score for
the entire training set by summing such per-sample scores. However, we don’t know the
state-transition functions ae and the output models hne . These constitute the unknown
meanings of the words in our training set which we wish to learn. We jointly learn ae
and hne for all lexical entries e by searching for those that maximize the aggregate score.
4.2 The Learning Procedure
We perform that search by Baum-Welch. While Equation 10 constitutes a score that potentially could be maximized, it is easier to adapt a scoring function that is more like a
likelihood calculation, than Equation 10, which is more like a MAP estimate, to the EM
630

Grounding Language Inference, Generation, and Acquisition in Video

framework. P
Thus we convert Equation 10 from log space to linear space and replace the
max with a
to redefine our scoring function as follows:
X
J,K

"

L
T
Y
Y

f (btj t )
l

t=1
T
Y

"l=1
W
Y

w=1

!

T
Y
t=2

, bt t )
g(bt−1
jlt−1 jl

t
hsw (kw
, Bhs, t, w, Ji)

t=1

!

!#

(13)

T
Y

t−1 t
, kw )
asw (kw

t=2

!#

where f , g, h, and a are in linear space. Recall that Equation 6 jointly maximizes the sum of
a measure of how well a video clip B depicts a track j and a measure of how well the detection
sequence Bj selected from a video clip B by the track j depicts an event model λ. Similarly,
Equation 10 jointly maximizes the sum of a measure of how well a video clip B depicts a
track collection J and a measure of how well the detection-sequence collection BJ selected
from a video clip B by the track collection J depicts a given sentence s, as interpreted by
a given lexicon Λ. One can maximize just the first component of this latter sum.
!#
!
" L
T
T
X
X X
t−1
t
t
(14)
max
g(bj t−1 , bj t )
f (bj t ) +
J

l=1

t=1

l

t=2

l

l

This is a variant of Equation 1 for a track collection. One can
P similarly convert Equation 14
from log space to linear space and replace the max with a
to yield:
X
J

"

L
T
Y
Y
l=1

t=1

f (btj t )
l

!

T
Y
t=2

, bt t )
g(bt−1
jlt−1 jl

!#

(15)

By suitable normalization with a constant factor, Equation 15 can be used to obtain the
probability of a particular track collection J relative to a distribution over all possible
track collections where the probability of a given track collection was proportional to the
summand. Let us denote this probability of a given track collection J as P (J|B).
For a given track collection J, one can similarly maximize just the measure of how well
the detection-sequence collection BJ selected from a video clip B by the track collection J
depicts a sentence s, as interpreted by a given lexicon Λ.
"W
!
!#
T
T
X X
X
t
t−1 t
max
(16)
hsw (kw , Bhs, t, w, Ji) +
asw (kw , kw )
K

w=1

t=1

t=2

This is a variant of Equation 2 for a factorial HMM for multiple words. One can
P similarly
convert Equation 16 from log space to linear space and replace the max with a
to yield:
X
K

"

W
Y

w=1

T
Y

t
, Bhs, t, w, Ji)
hsw (kw

t=1

!

T
Y
t=2

t−1 t
, kw )
asw (kw

!#

(17)

The summand in Equation 17 is the joint probability of a state sequence K and BJ depicting
a sentence s, as interpreted by a given lexicon Λ: P (K, BJ |s, Λ) = P (BJ |K, s, Λ)P (K|s, Λ).
631

Yu, Siddharth, Barbu, & Siskind

Equation 17 is the (marginal) probability of BJ depicting a sentence s, as interpreted by a
given lexicon Λ: P (BJ |s, Λ). If we divide Equation 13 by Equation 15 we obtain:
L(B; s, Λ) =

X

P (J|B)P (BJ |s, Λ)

J

This is the expected probability of BJ depicting a sentence s, as interpreted by a given
lexicon Λ, over the track collection distribution underlying P (J|B). Equations 13 and 15
can both be computed efficiently by the forward algorithm (Baum & Petrie, 1966). This
allows us to take L(B; s, Λ) as a sample score and adopt
L(B; S, Λ) =

M
Y

L(Bm ; sm , Λ)

m=1

as the training-set score. We seek the a and h in Λ that maximize L(B; S, Λ). Note that
both the sample and training-set scores are in [0, 1].
We can find a local maximum to this objective function using the same techniques as used
by Baum-Welch. The reestimation formulas can be derived with auxiliary functions that are
analogous to those used for HMMs (Bilmes, 1998). Let us first define J = J1 , . . . , JM and
K = K1 , . . . , KM to be track collections and state-sequence collections for the entire training
set. Then let us define L(B, J , K; S, Λ) as the product of the summand of Equation 13 over
the training set divided by the product of Equation 15 over the training set. Thus we have:
X
L(B; S, Λ) =
L(B, J , K; S, Λ)
J ,K

We adopt the following auxiliary function:
X
F (Λ, Λ′ ) =
L(B, J , K; S, Λ′ ) log L(B, J , K; S, Λ)
J ,K

where Λ′ is the current lexicon and Λ is a potential new lexicon. One can show that
F (Λ, Λ′ ) ≥ F (Λ′ , Λ′ ) implies L(B; S, Λ) ≥ L(B; S, Λ′ ).

X  L(B, J , K; S, Λ′ )
L(B, J , K; S, Λ)
F (Λ, Λ′ ) − F (Λ′ , Λ′ ) = L(B; S, Λ′ )
log
L(B; S, Λ′ )
L(B, J , K; S, Λ′ )
J ,K

X
L(B, J , K; S, Λ)
P (J , K|B, S, Λ′ ) log
∝
L(B, J , K; S, Λ′ )
J ,K

X
′ L(B, J , K; S, Λ)
P (J , K|B, S, Λ )
≤ log
L(B, J , K; S, Λ′ )
J ,K

= log

X L(B, J , K; S, Λ)

J ,K

= log

L(B; S, Λ′ )

L(B; S, Λ)
L(B; S, Λ′ )

632

Grounding Language Inference, Generation, and Acquisition in Video

The second step above holds because the training-set score L(B; S, Λ′ ) is nonnegative. The
third step holds due to Jensen’s (1906) inequality. Thus given the current lexicon Λ′ , if we
find a new lexicon Λ such that F (Λ, Λ′ ) ≥ F (Λ′ , Λ′ ), one can iterate this process, increasing
the training-set score to a local maximum. This can be done by maximizing F (Λ, Λ′ ) with
respect to Λ. Since L(B, J , K; S, Λ) is proportional to the product of the summands of
Equation 13 over the training set, which is the product of two terms, only the latter of
which depends on Λ, the following holds:

X L(B, J , K; S, Λ′ )

F (Λ, Λ′ ) ∝

J ,K

L(B; S, Λ′ )

X L(B, J , K; S, Λ′ )

∝

J ,K

L(B; S, Λ′ )

log L(B, J , K; S, Λ)
Wm
M X
X

m=1 w=1





Tm
X


t
, Bm hsm , t, w, Jm i)
log hsm,w (km,w
|
{z
}
t=1
h


Tm
X
t
t−1
)
, km,w
log asm,w (km,w
+
{z
}
|
t=2




a

where Tm is the number of frames in the video clip Bm for training sample m , Wm is the
number of words in the sentence sm for training sample m, sm,w is the lexical entry for
t
t in the stateword w in the sentence sm for training sample m, and km,w
is the state kw
sequence collection Km for training sample m. In the above, Bm hsm , t, w, Jm i is extended
, the collection of detections selected in frame t of the video
to denote btj t , . . . , btj t
1
θm,w

Ism,w
θm,w

clip Bm by the track collection Jm as assigned to the Ism,w arguments of the word model
i
for word w in sentence sm by the linking function θm,w
produced on sm that determines the
participant for argument i of word w for sentence sm . Thus F (Λ, Λ′ ) comprises two terms,
one of which, H, is a weighted sum of terms h and the other of which, A, is a weighted
sum of terms a. One can maximize F (Λ, Λ′ ) by maximizing H and A independently. These
lead to reestimation procedures for the output models h and state-transition functions a.
First consider A. Rewrite the term to explicitly sum over lexical entries e and pairs of
states k ′ and k.

A=

=

=

X

X
X

t−1 = k ′ , k t
′
L(B, km,w
m,w = k; S, Λ )
log ae (k ′ , k)
L(B; S, Λ′ )
t−1 = k ′ , k t
′
′
L(Bm , km,w
m,w = k; sm , Λ )L(Bm′ 6=m ; Sm′ 6=m , Λ )
log ae (k ′ , k)
L(Bm ; sm , Λ′ )L(Bm′ 6=m ; Sm′ 6=m , Λ′ )
t−1 = k ′ , k t
′
L(Bm , km,w
m,w = k; sm , Λ )
log ae (k ′ , k)
L(Bm ; sm , Λ′ )

633

(18)

Yu, Siddharth, Barbu, & Siskind

where

X

denotes

Tm
Wm X
Ke X
Ke X
M X
E X
X

and where

e=1 k′ =1 k=1 m=1 w=1 t=2
sm,w =e

t−1 = k ′ , k t
′
L(B, km,w
m,w = k; S, Λ ) =

X X

L(B, J , K; S, Λ′ )

X X

L(Bm , Jm , Km ; sm , Λ′ )

J

t−1 = k ′ , k t
′
L(Bm , km,w
m,w = k; sm , Λ ) =

Jm

L(Bm′ 6=m ; Sm′ 6=m

, Λ′ )

=

K
t−1
km,w
=k′
t
km,w =k

Km
t−1
km,w
=k′
t
km,w =k

M
Y

L(Bm′ ; sm′ , Λ)

m′ =1
m′ 6=m

The second step in Equation 18 holds because of the assumption that the training samples
are i.i.d. Taking the derivative of A with respect to each ae (k ′ , k), we get the reestimation
formula for the state-transition function:
ae (k ′ , k) := κe (k ′ )

Wm X
Tm
M X
t−1 = k ′ , k t
′
X
L(Bm , km,w
m,w = k; sm , Λ )
L(Bm ; sm , Λ′ )
m=1 w=1 t=2 |
{z
}
sm,w =e

ξ(m,w,k′ ,k,t)

The coefficient κe (k ′ ) is chosen to normalize the distribution so that it sums to one.
The reestimation formula for the output model can be derived similarly from H. We
make use of the fact that the output model is a factorial model where the factors are discrete
distributions. In linear space:

he (k, b1 , . . . , bIe ) =

Ne
Y

hne (k, Φne (b1 , . . . , bIe ))

n=1

Again, rewrite H to explicitly sum over lexical entries e, states k, features n, and bins z.

H=
=
=

X

X

X

t
L(B, km,w
= k, Φne (Bm hsm , t, w, Jm i) = φne,z ; S, Λ′ )
log hne (k, φne,z )
L(B; S, Λ′ )
t
L(Bm , km,w
= k, Φne (Bm hsm , t, w, Jm i) = φne,z ; sm , Λ′ )L(Bm′ 6=m ; Sm′ 6=m , Λ′ )
log hne (k, φne,z )
L(Bm ; sm , Λ′ )L(Bm′ 6=m ; Sm′ 6=m , Λ′ )
t
L(Bm , km,w
= k, Φne (Bm hsm , t, w, Jm i) = φne,z ; sm , Λ′ )
log hne (k, φne,z )
L(Bm ; sm , Λ′ )

634

Grounding Language Inference, Generation, and Acquisition in Video

where

X

n

denotes

Z e M Wm Tm
Ke X
Ne X
E X
X XX
X

and where

e=1 k=1 n=1 z=1 m=1 w=1 t=1
sm,w =e

t
′) =
L(B, km,w
= k, Φne (Bm hsm , t, w, JmX
i) = φne,z ; S, ΛX

L(B, J , K; S, Λ′ )

K
J
t
n
Φn
e (Bm hsm ,t,w,Jm i)=φe,z km,w =k

t
n
L(Bm , km,w
= k, Φne (Bm hsm , t, w, JX
, Λ′ ) =
m i) = φe,z ; smX
L(Bm , Jm , Km ; sm , Λ′ )
Km
Jm
n
t
Φn
e (Bm hsm ,t,w,Jm i)=φe,z km,w =k

Taking the derivative of H with respect to each hne (k, φne,z ), we get the reestimation formula
for the output model:
hne (k, φ) := ψen (k)

Tm
Wm X
M X
t
X
L(Bm , km,w
= k, Φne (Bm hsm , t, w, Jm i) = φ; sm , Λ′ )
L(Bm ; sm , Λ′ )
m=1 w=1 t=1 |
{z
}
sm,w =e

δ(m,w,n,k,φ,t)

The coefficient ψen (k) is chosen to normalize the distribution so that it sums to one.
The reestimation formulas involve occurrence counting. Since we use factorial HMMs
that involve a cross-product lattice and use a scoring function derived from Equation 13 that
incorporates both tracking (Equation 1) and word models (Equation 2), we need to count occurrences in the whole cross-product lattice. As an example of such cross-product occurrence
counting, when counting the transitions from state k ′ to k for word w from frame t−1 to t in
sample m, i.e., ξ(m, w, k ′ , k, t), we need to count all the possible paths through the adjacent
t−1
t−1
t−1
t−1
t
t , . . . , jt
t
factorial states, i.e., from jm,1
, . . . , jm,L
, km,1
, . . . , km,W
to jm,1
m,L , km,1 , . . . , km,W
t−1 = k ′ and k t
such that km,w
m,w = k. Similarly, when counting the frequency of being at
state k while observing the value φ as the feature n in frame t of sample m for the word w,
i.e., δ(m, w, n, k, φ, t), we need to count all the possible paths through the factorial state
t , . . . , jt
t
t
t
n
jm,1
m,L , km,1 , . . . , km,W such that km,w = k and Φe (Bm hsm , t, w, Jm i) = φ.
The reestimation of one word model can depend on the previous estimate for other word
models. This dependence happens because the linking function can assign the same participant to arguments of different words in a sentence and the same lexical entry can appear
in different training sentences. It is precisely this dependence that leads to cross-situational
learning: the former performs inference across different words in the same sentence and the
latter performs inference across the same word in different sentences.

5. Experiments
The sentence tracker implements a function S : (B, s, Λ) 7→ (τ , J) that takes a video clip B
as input, along with a sentence s and a lexicon Λ, and produces, as output, a video-sentence
score τ , together with a track collection J that depicts the sentence s as interpreted by the
lexicon Λ. The ability to produce both a score and a track collection allows the sentence
tracker to be used in a variety of ways, among them:
635

Yu, Siddharth, Barbu, & Siskind

language inference Using the track collection that it produces, it can take a sentence
as input and focus its attention on the event described in the sentence. This allows
processing a video clip that depicts many participants, various subsets of whom are
engaged is different events, to track those particular participants that are engaged in
a particular event as specified by a sentence.
language generation Using the score that it produces, it can generate sentential descriptions of video clips by efficiently searching through the space of possible sentences to
find one that best describes a given clip.
language acquisition Using the score that it produces, it can learn word meanings from a
training set of video clips paired with sentences that describe those clips, by searching
the space of potential word meanings to find those that collectively allows the sentences
to best describe the associated clips.
We evaluate the first use in Section 5.3, the second use in Section 5.4, and the third use in
Section 5.5.
5.1 The Corpora
To conduct our evaluation, we filmed two different corpora, each containing 94 video clips.
One corpus was used for the experiments in Sections 5.3 and 5.4 while the other was used for
the experiments in Section 5.5. Both corpora were filmed at 640×480 resolution and 30 fps.
Each contained clips that varied in length between 3 and 5 seconds. Both were filmed in
a variety of outdoor environments, the first varying between three different environments
and the second varying between four. The camera was moved between filming each clip so
that the varying background precluded unanticipated confounds.
The video clips were filmed with a variety of actors and objects. The clips in the first
corpus each contain one or two people from a collection of three actors while the clips in the
second corpus each contain a single person from a collection of four actors. The first corpus
was filmed with three objects, a backpack, a chair, and a trash can, each of which were
present in the field of view for all clips. The second corpus was filmed with five objects, a
backpack, a chair, a traffic cone, a trash can, and a stool, with either two or three present
in the field of view of any given clip. The whole dataset was counterbalanced to avoid
artifactual correlation. Each object class and combination of object classes appears in clips
with nearly equal frequency.
The four different environments for the second corpus were used to construct three different cross-validation folds. The 29 video clips filmed in one environment always contain
exactly two objects while the 23, 22, and 20 clips filmed in each of the other three environments respectively always contain exactly three objects. The test set for a given fold
comprised all of the clips filmed in one of the latter three environments. Thus the test sets
for the three folds contained 23, 22, and 20 clips respectively. The training set for a given
fold comprised all clips except for the test set for that fold. Thus the training sets for the
three folds contained 71, 72, and 74 clips respectively.
All video clips depict multiple simultaneous events. The depiction, from clip to clip,
varied in scene layout and the actor(s) performing the event. The clips in the first corpus
each depicted one or more of the 21 sentences from Table 1. The clips in the second corpus
each depicted one or more of the 187 sentences from Tables 2 and 3. These sentences
636

Grounding Language Inference, Generation, and Acquisition in Video

1 a.
b.
2 a.
b.
3 a.
b.
4 a.
b.
5 a.
b.
6 a.
b.
7 a.
b.
8 a.
b.
9 a.
b.
1 0.
1 1.
1 2.

The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The

backpack approached the trash can.
chair approached the trash can.
red object approached the trash can.
blue object approached the trash can.
person to the left of the trash can put down an object.
person to the right of the trash can put down an object.
person put down the trash can.
person put down the backpack.
person carried the red object.
person carried the blue object.
person picked up an object to the left of the trash can.
person picked up an object to the right of the trash can.
person picked up an object.
person put down an object.
person picked up an object quickly.
person picked up an object slowly.
person carried an object towards the trash can.
person carried an object away from the trash can.
backpack approached the chair.
red object approached the chair.
person put down the chair.

Table 1: A selection of sentences drawn from the grammar in Table 11(a) based on which
we collected multiple video clips for the first corpus. Note that sentence pairs 1 through 9
constitute minimal pairs, where a single constituent varies between two lexical entries in each
pair. The varying constituent ranges over all parts of speech and all sentential positions.
were constrained to conform to the grammar in Table 11(a). The 187 sentences for the
second corpus were divided into two groups, one consisting of 175 sentences that were used
exclusively for training and one consisting of 12 sentences that were used exclusively for
test. This delineation is indicated by the horizontal line in Table 3.
The corpora were carefully constructed in a number of ways. First, many video clips
depict more than one sentence. In particular, many clips depict simultaneous distinct events.
Second, each sentence describes multiple clips. Third, the first corpus was constructed with
minimal pairs: clips described by a pair of sentences which differ in exactly one lexical item.
These minimal pairs help evaluate language inference and are indicated as the ‘a’ and ‘b’
variants of sentences 1–9 in Table 1. That varying lexical item was carefully chosen to span
all parts of speech and all sentential positions: sentence 1 varies subject noun, sentence 2
varies subject adjective, sentence 3 varies subject preposition, sentence 4 varies object noun,
sentence 5 varies object adjective, sentence 6 varies object preposition, sentence 7 varies
verb, sentence 8 varies adverb, and sentence 9 varies motion preposition. Fourth, each clip
in the second corpus contains only a subset of the objects used in that corpus. Without
such asymmetry it would be difficult (but not impossible) to determine the correspondence
637

Yu, Siddharth, Barbu, & Siskind

The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The

chair approached the stool.
chair to the right of the backpack approached the stool.
chair to the left of the stool approached the stool.
person picked up the stool.
person picked up the stool to the left of the backpack.
person carried the trash can.
person carried the trash can to the left of the backpack.
person put down the trash can.
person put down the trash can quickly.
person put down the trash can to the left of the stool.
person to the left of the backpack put down the trash can.
person picked up the chair.
person picked up the chair quickly.
person picked up the chair to the left of the traffic cone.
person picked up the chair to the left of the backpack.
person put down the chair.
person put down the chair quickly.
person to the left of the traffic cone put down the chair.
person carried the traffic cone.
person to the left of the backpack carried the traffic cone.
person carried the traffic cone away from the trash can.
backpack approached the traffic cone.
backpack to the right of the chair approached the traffic cone.
backpack to the left of the traffic cone approached the traffic cone.
person put down the traffic cone.
person put down the traffic cone to the left of the stool.
person to the left of the chair put down the traffic cone.
person carried the backpack.
person to the left of the chair carried the backpack.
person carried the backpack away from the stool.
person put down the stool to the left of the trash can.
person approached the trash can.
stool approached the trash can.
person carried the stool.
person carried the stool towards the trash can.
stool approached the trash can to the left of the traffic cone.
backpack to the left of the traffic cone approached the trash can.
backpack to the right of the trash can approached the trash can.
traffic cone approached the stool to the left of the trash can.
trash can approached the chair.
trash can to the left of the chair approached the chair.
trash can approached the chair to the left of the backpack.
person approached the chair.
person picked up the trash can to the left of the stool.
person approached the traffic cone.
chair approached the traffic cone.
person to the left of the backpack approached the traffic cone.
person carried the chair towards the traffic cone.
person put down the chair to the right of the backpack.
person to the right of the traffic cone put down the chair.
person to the right of the trash can put down the traffic cone.
person to the left of the backpack put down the traffic cone.
person put down the traffic cone slowly.
person picked up the chair to the right of the backpack.
person to the right of the trash can picked up the chair.
stool approached the traffic cone to the right of the chair.
stool approached the traffic cone to the left of the person.
person picked up the traffic cone quickly.
person picked up the traffic cone to the left of the stool.
person to the left of the chair picked up the traffic cone.

The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The

person picked up the backpack.
person to the left of the chair picked up the backpack.
person put down the backpack.
person put down the backpack slowly.
person to the right of the chair put down the backpack.
person put down the backpack to the right of the trash can.
traffic cone approached the stool.
traffic cone to the left of the trash can approached the stool.
traffic cone to the right of the stool approached the stool.
backpack approached the trash can.
backpack approached the trash can to the right of the stool.
backpack to the right of the stool approached the trash can.
person carried the chair.
person to the left of the stool carried the chair.
person carried the chair to the left of the traffic cone.
person picked up the trash can.
person picked up the trash can quickly.
person picked up the trash can to the right of the stool.
person picked up the traffic cone.
person picked up the traffic cone slowly.
person to the left of the stool picked up the traffic cone.
person picked up the traffic cone to the right of the trash can.
stool approached the traffic cone.
stool to the left of the traffic cone approached the traffic cone.
stool to the right of the chair approached the traffic cone.
chair approached the trash can.
chair to the left of the traffic cone approached the trash can.
chair to the left of the trash can approached the trash can.
person put down the stool.
person to the left of the traffic cone put down the stool.
traffic cone approached the chair to the left of the stool.
traffic cone approached the chair.
person carried the traffic cone towards the chair.
person to the left of the stool carried the traffic cone.
person carried the traffic cone away from the chair.
person to the left of the stool put down the backpack.
person put down the backpack to the right of the chair.
person picked up the stool slowly.
person to the right of the trash can put down the stool.
traffic cone approached the trash can.
traffic cone to the right of the stool approached the trash can.
chair approached the stool to the left of the traffic cone.
chair to the right of the stool approached the stool.
person to the left of the stool put down the trash can.
person put down the trash can to the left of the traffic cone.
person approached the stool.
backpack approached the stool.
person carried the backpack towards the stool.
backpack approached the chair.
backpack to the right of the chair approached the chair.
backpack to the right of the traffic cone approached the chair.
person carried the stool away from the traffic cone.
person to the left of the traffic cone picked up the backpack.
stool approached the backpack.
stool approached the backpack to the right of the trash can.
stool to the left of the backpack approached the backpack.
person to the left of the chair approached the stool.
person carried the stool towards the chair.
person to the left of the chair put down the stool.
person put down the stool slowly.

Table 2: A selection of sentences (first part) drawn from the grammar in Table 11(a) that
were used to annotate the clips for the second corpus.

638

Grounding Language Inference, Generation, and Acquisition in Video

The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The

person to the right of the trash can approached the chair.
person to the right of the trash can carried the chair.
person to the right of the trash can put down the chair.
person put down the chair slowly.
person to the right of the trash can approached the stool.
person picked up the stool to the right of the trash can.
person put down the stool to the right of the trash can.
person to the left of the stool approached the chair.
person picked up the chair to the left of the stool.
person carried the chair towards the stool.
person to the left of the stool put down the chair.
person to the right of the chair approached the trash can.
person picked up the trash can to the right of the chair.
person carried the trash can away from the chair.
person put down the trash can to the right of the chair.
person picked up the stool quickly.
person put down the stool quickly.
person approached the chair to the left of the stool.
person put down the chair to the left of the stool.
trash can approached the traffic cone.
trash can to the right of the backpack approached the traffic cone.
trash can approached the traffic cone to the right of the backpack.
person to the right of the chair put down the trash can.
person carried the chair towards the backpack.
chair approached the backpack.
chair approached the backpack to the left of the stool.
person carried the trash can towards the traffic cone.

The
The
The
The
The
The

person
person
person
person
person
person

The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The
The

picked up the stool to the right of the traffic cone.
to the left of the stool picked up the trash can.
put down the stool to the left of the chair.
to the left of the trash can carried the stool.
put down the backpack quickly.
to the left of the backpack put down the chair.

person to the right of the backpack picked up the stool.
person to the right of the backpack picked up the traffic cone.
person to the left of the trash can picked up the traffic cone.
trash can approached the stool.
trash can to the left of the stool approached the stool.
trash can to the right of the chair approached the stool.
person picked up the trash can to the left of the chair.
person carried the backpack away from the chair.
person to the left of the traffic cone carried the backpack.
person carried the stool away from the chair.
person to the right of the chair picked up the backpack.
person to the left of the trash can picked up the backpack.
person picked up the backpack quickly.
traffic cone approached the backpack.
traffic cone to the left of the backpack approached the backpack.
traffic cone approached the backpack to the left of the stool.
person to the left of the traffic cone picked up the chair.
person to the left of the trash can put down the traffic cone.
person put down the traffic cone to the right of the stool.
person carried the traffic cone towards the trash can.
person carried the traffic cone away from the stool.
stool approached the chair.
stool approached the chair to the right of the traffic cone.
stool to the right of the traffic cone approached the chair.
person to the left of the traffic cone put down the backpack.
person to the right of the trash can put down the backpack.
chair to the left of the backpack approached the backpack.
chair approached the backpack to the left of the trash can.

The
The
The
The
The
The

trash can to the left of the backpack approached the chair.
person carried the trash can towards the chair.
person picked up the chair slowly.
person picked up the stool to the left of the chair.
person picked up the backpack to the right of the trash can.
person carried the trash can away from the backpack.

Table 3: A selection of sentences (second part) drawn from the grammar in Table 11(a).
The sentences above the horizontal line were used to annotate the clips for the second corpus
and those below it were used for test.
between nouns and object classes. Note, however, that since the training clips each contain
more than one object, the task of learning noun meanings is still challenging. We filmed our
own corpora as we are unaware of any existing corpora that exhibit the above properties.2
We annotated each of the 94 video clips in each corpus with human judgments. The
first corpus was annotated against each of the 21 sentences from Table 1, indicating whether
the given clip depicted the given sentence. Table 4 provides statistics on this annotation.
The resulting set of 94 × 21 = 1974 judgments and the associated statistics were used
to compare and contrast our machine-generated results against human judgments in the
analyses in Sections 5.3 and 5.4. Each clip in the second corpus was used either for training
or test, depending on the cross-validation fold, as described earlier. When it was included
in the training set, it was paired with between 1 and 5 sentences selected from the 175
2. The video clips, sentential annotation described below, and all code needed to replicate the experiments in this section are available at http://upplysingaoflun.ecn.purdue.edu/~qobi/cccp
/grounding-language-in-video.html.

639

Yu, Siddharth, Barbu, & Siskind

#Clips that depict a given sentence
#Sentences that describe a given clip

µ

σ

12.33
2.76

6.48
1.22

Table 4: Annotation statistics for the first corpus.
µ
σ
#Clips that depict a given sentence
#Sentences that describe a given clip

2.00
0.37

0.58
0.61

Table 5: Annotation statistics for the second corpus.
training sentences from Tables 2 and 3 that were deemed to describe the associated training
clip by a human judge. On average, each training clip was paired with 2.94 sentences.
Collectively, the corpus contains 276 video-sentence pairs used for training. The three
training folds contained 213, 208, and 204 video-sentence pairs respectively. When a given
clip was included in the test set, it was paired with all 12 test sentences from Table 3. Thus
the 94 − 29 = 65 potential test clips in the second corpus were annotated against each of
the 12 test sentences from Table 3, indicating whether the given clip depicted the given
sentence. Table 5 provides statistics on this annotation. The resulting set of 65 × 12 = 780
judgments and the associated statistics were used to compare and contrast our machinegenerated results against human judgments in the analyses in Section 5.5.
All of our experiments use an off-the-shelf object detector (Felzenszwalb et al., 2010a,
2010b) which outputs detections in the form of scored axis-aligned rectangles. In particular, we used the implementation described by Song, Zickler, Althoff, Girshick, Fritz, Geyer,
Felzenszwalb, and Darrell (2012). Using off-the-shelf software, we trained six object detectors, one for each of the six object classes in our corpora: person, backpack, chair, traffic
cone, trash can, and stool. To compensate for false negatives, as described in Section 2.1,
we lowered the acceptance threshold on the models produced by automatic training. The
per-part thresholds were uniformly reduced by 1.2, the model thresholds were uniformly
reduced by 2.0, and non-maxima suppression was set to 0.6 for the first corpus and 0.55
for the second. We applied the person, backpack, chair, and trash can detectors uniformly
to all frames of all video clips in the first corpus and all six detectors to all frames of all
clips in the second corpus. For the first corpus, we selected the five highest-scoring detections produced by each object detector in each frame and pooled the results yielding
twenty detections per frame. For the second corpus, we selected the two highest-scoring
detections produced by each object detector in each frame and pooled the results yielding
twelve detections per frame. While having a larger pool of detections per frame can better
compensate for false negatives in object detection and potentially yield smoother tracks,
it increases the size of the lattice and the concomitant running time but does not lead to
appreciably better performance on our corpora.
5.2 The Manually-Constructed Lexicons
The experiments in Sections 5.3 and 5.4 use manually-constructed FSMs to represent word
meanings when evaluating language inference and language generation. These hand-written
representations of word meaning clearly encode pretheoretic human intuition and make such
640

Grounding Language Inference, Generation, and Acquisition in Video

intuition perspicuous. For these experiments, we formulate the word models for the lexical
entries in Table 11(a) that appear in the sentences in Table 1. The experiments in Section 5.5
learn word models represented as HMMs. We evaluated these learned word models, in part,
by comparison with manually-constructed HMMs. These manually-constructed HMMs will
be discussed in Section 5.5.
We formulate the FSMs as regular expressions over predicates computed from detections.
The particular set of regular expressions and associated predicates that are used in the
experiments in Sections 5.3 and 5.4 are given in Table 6. The predicates are formulated
around a number of primitive functions. The function avgFlow(b) computes a vector that
represents the average optical flow inside the detection b. The function model(b) returns the
object class of b. The function x(b) returns the x-coordinate of the center of b. The function
hue(b) returns the average hue of the pixels inside b. The function angleSep determines the
angular distance between two angular arguments. The function fwdProj(b) displaces b by the
average optical flow inside b. The function 6 determines the angular component of a given
vector. The function ⊥ computes a normal unit vector for a given vector. The argument v
to noJitter denotes a specified direction represented as a 2D unit vector in that direction.
Predicates that take a single detection b as their sole argument can serve as 0/1 output
models h(k, b) (−∞/0 in log space) for single-participant word models. Predicates that
take a pair of detections b1 and b2 as their sole arguments can serve as 0/1 output models
h(k, b1 , b2 ) (−∞/0 in log space) for two-participant word models. Regular expressions are
formulated around predicates as atoms. A given regular expression must be formed solely
from output models of the same arity and denotes a word model with a 0/1 state-transition
function (−∞/0 in log space) where the output models are associated with the appropriate
states.
5.3 Experiment 1: Language Inference
Tracking is traditionally performed using cues from motion, object detection, and/or manual
initialization on an object of interest (Yilmaz, Javed, & Shah, 2006). However, in the
case of a cluttered scene involving multiple events occurring simultaneously, there can be
many moving objects, many instances of the same object class, and perhaps even multiple
simultaneously occurring instances of the same event class. Here we illustrate how one can
use a sentential description to guide the tracking of objects based on which ones participate
in the target event.
The sentence tracker can focus its attention on just those objects that participate in
an event specified by a sentential description. Such a description can differentiate between
different simultaneous events taking place between many moving objects in the scene using
descriptions constructed out of a variety of parts of speech. Using nouns to specify object
class, one could differentiate between
The person picked up the backpack and
The person picked up the chair.
Using adjectives to specify object properties, one could differentiate between
The person picked up the red object and
The person picked up the blue object.
641

Yu, Siddharth, Barbu, & Siskind

Constants
△

△

xBoundary = 300px

△

nextTo = 50px

△

∆static = 6px

△

∆slow = 30px

△

∆angle = 30◦

∆closing = 10px

△

∆jump = 30px

△

∆quick = 80px

△

∆hue = 30◦

Simple Predicates
△

△

noJitter(b, v) = kavgFlow(b) · vk ≤ ∆jump

alike(b1 , b2 ) = model(b1 ) = model(b2 )

△

△

close(b1 , b2 ) = |x(b1 ) − x(b2 )| < xBoundary

far(b1 , b2 ) = |x(b1 ) − x(b2 )| ≥ xBoundary

△

△

left(b1 , b2 ) = 0 < x(b2 ) − x(b1 ) ≤ nextTo

right(b1 , b2 ) = 0 < x(b1 ) − x(b2 ) ≤ nextTo

△

hasColor(b, hue) = angleSep(hue(b), hue) ≤ ∆hue

△

stationary(b) = kavgFlow(b)k ≤ ∆static

△

△

quick(b) = kavgFlow(b)k ≥ ∆quick

slow(b) = kavgFlow(b)k ≤ ∆slow

△

△

person(b) = model(b) = person

backpack(b) = model(b) = backpack

△

△

chair(b) = model(b) = chair

trashcan(b) = model(b) = trashcan

△

△

blue(b) = hasColor(b, 225◦ )

red(b) = hasColor(b, 0◦ )
Complex Predicates

△

stationaryClose(b1 , b2 ) = stationary(b1 ) ∧ stationary(b2 ) ∧ ¬alike(b1 , b2 ) ∧ close(b1 , b2 )
△

stationaryFar(b1 , b2 ) = stationary(b1 ) ∧ stationary(b2 ) ∧ ¬alike(b1 , b2 ) ∧ far(b1 , b2 )
△

closer(b1 , b2 ) = |x(b1 ) − x(b2 )| > |x(fwdProj(b1 )) − x(b2 )| + ∆closing
△

farther(b1 , b2 ) = |x(b1 ) − x(b2 )| < |x(fwdProj(b1 )) − x(b2 )| + ∆closing
△

moveCloser(b1 , b2 ) = noJitter(b1 , (0, 1)) ∧ noJitter(b2 , (0, 1)) ∧ closer(b1 , b2 )
△

moveFarther(b1 , b2 ) = noJitter(b1 , (0, 1)) ∧ noJitter(b2 , (0, 1)) ∧ farther(b1 , b2 )
△

inDirection(b, v) = noJitter(b, ⊥(v)) ∧ ¬stationary(b) ∧ angleSep(6 avgFlow(b), 6 v) < ∆angle
△

approaching(b1 , b2 ) = ¬alike(b1 , b2 ) ∧ stationary(b2 ) ∧ moveCloser(b1 , b2 )
△

departing(b1 , b2 ) = ¬alike(b1 , b2 ) ∧ stationary(b2 ) ∧ moveFarther(b1 , b2 )
△

carry(b1 , b2 , v) = person(b1 ) ∧ ¬alike(b1 , b2 ) ∧ inDirection(b1 , v) ∧ inDirection(b2 , v)
△

carrying(b1 , b2 ) = carry(b1 , b2 , (0, 1)) ∨ carry(b1 , b2 , (0, −1))
△

pickingUp(b1 , b2 ) = person(b1 ) ∧ ¬alike(b1 , b2 ) ∧ stationary(b1 ) ∧ inDirection(b2 , (0, 1))
△

puttingDown(b1 , b2 ) = person(b1 ) ∧ ¬alike(b1 , b2 ) ∧ stationary(b1 ) ∧ inDirection(b2 , (0, −1))
Regular Expressions
△

λperson = person+
△

λtrash can = trashcan+
△

λblue = blue+

△

λbackpack = backpack+
△

λobject = (backpack | chair | trashcan)+
△
△
λquickly = true+ quick[3,] true+
λred = red+
△

△

λto the right of = right+

λto the left of = left+

△

λchair = chair+

△

λslowly = true+ slow[3,] true+

△

λapproached = stationaryFar+ approaching[3,] stationaryClose+
△

λcarried = stationaryClose+ carrying[3,] stationaryClose+
△

λpicked up = stationaryClose+ pickingUp[3,] stationaryClose+
△

λput down = stationaryClose+ puttingDown[3,] stationaryClose+
△

λtowards = stationaryFar+ approaching[3,] stationaryClose+
△

λaway from = stationaryClose+ departing[3,] stationaryFar+

Table 6: The FSMs representing the meanings of the lexical entries in Table 11(a) that
appear in the sentences in Table 1 used for the experiments in Sections 5.3 and 5.4.

642

Grounding Language Inference, Generation, and Acquisition in Video

Using verbs to specify events, one could differentiate between
The person picked up the red object and
The person put down the red object.
Using adverbs to specify motion properties, one could differentiate between
The person quickly picked up the red object and
The person slowly picked up the red object.
Using prepositions to specify (changing) spatial relations between objects, one could differentiate between
The person to the right of the chair picked up an object and
The person to the left of the chair picked up an object.
Furthermore, such a sentential description can even differentiate which objects to track
based on the role that they play in an event: agent, patient, source, goal, or referent. For
example, the sentence The person picked up the backpack to the left of the chair differs from
The person picked up the chair to the left of the backpack in that the roles of the backpack
and the chair are exchanged. Although the same objects are involved in the described
events, their roles in the events differ, and can be distinguished by the tracker. Figure 15
demonstrates this ability: different tracks are produced for the same video that depicts
multiple simultaneous events when focused with different sentences. In this figure, as well
as Figure 16 and Figures 21 and 22 in Appendix B, the boxes around the participants are
color coded to indicate semantic role: agent in red, patient in blue, source in violet, goal in
turquoise, and referent in green. This particularly illustrates that our system understands
the image regions that correspond to the participants and the particular mapping of such to
argument positions of predicates that denote the meanings of lexical items in the sentential
description. This further illustrates deep semantic understanding.
Figure 15 evaluates this ability for each sentential position. Figure 21 in Appendix B
evaluates this ability on all 9 minimal pairs, as indicated by the ‘a’ and ‘b’ variants of
sentences 1–9 in Table 1, collectively applied to all 25 suitable video clips in the first corpus.
We discard two clips from the original set of 9 × 3 = 27 video clips due to the fact that they
involve an adjective (grey), corresponding to the chair, that cannot be reliably extracted
from the video. For 18 out of the 25, both sentences in the minimal pair yielded track
collections deemed to be correct depictions. We determine error from subjective human
judgment of whether the track collection that our system produces matches the desired
description. All of the errors encountered in this task fall into one of two categories. One
category deals with the use of a color adjective along with the generic word object in the
presence of some other entity in the video other than the intended object that incidentally
has a similar color. The sole error in this category involves the tracker selecting detections
on a person’s red shirt instead of the red backpack, for one of three instances of minimal
pair 2 in Table 1: The red object approached the chair and The blue object approached
the chair. The correct result is obtained for the other instance of this minimal pair when
associated with different video clips. The other category is largely due to the deficiencies
of the detectors, particularly that for the trash can. In at least four instances, the paucity
643

Yu, Siddharth, Barbu, & Siskind

Differentiate
on
verb
The person picked up an object.

The person put down an object.

The backpack approached the trash can.

The chair approached the trash can.

The red object approached the chair.

The blue object approached the chair.

The person to the left of the trash can put down an object.

The person to the right of the trash can put down an object.

The person put down the trash can.

The person put down the backpack.

The person carried the red object.

The person carried the blue object.

The person picked up an object to the left of the trash can.

The person picked up an object to the right of the trash can.

The person carried an object towards the trash can.

The person carried an object away from the trash can.

subject
noun

adjective
in subject
NP

preposition
in subject
NP

object
noun

adjective
in object
NP

preposition
in object
NP

preposition
in an
adjunct

Figure 15: Language inference: two different track collections for the same video clip produced under guidance of two different sentences. Each clip is processed by a minimal pair, a
sentence that varies in a single lexical item highlighted in red vs. green. The varying lexical
item itself varies among all sentential positions across the eight examples. Results for all
video clips processed by the minimal pairs in sentences 1–9 from Table 1 are included in
Figure 21 in Appendix B. In this figure, as well as in Figures 16, 21, and 22, we indicate
thematic role of the participants by the color of the bounding box: the red box denotes the
agent, the blue box denotes the patient, the violet box denotes the source, the turquoise
box denotes the goal, and the green box denotes the referent. These roles are determined
automatically using the techniques in Appendix A.

644

Grounding Language Inference, Generation, and Acquisition in Video

Contraction Threshold

Accuracy

0.95
67.02%
0.90
71.27%
0.85
64.89%
Table 7: Accuracy as a function of contraction threshold.
of detections from the trash can detector results either in poor tracks or a complete failure
to satisfy the FSMs corresponding to other word models. This is further exacerbated in
the case of adverbs. Since adverbs modify verbs, and verbs vary in the manner of their
execution, tight bounds on what would constitute quickly or slowly are difficult to obtain.
Any bounds we are able to impose are sufficiently noisy that sometimes the distinction
between an action happening quickly or slowly is lost. Two such errors occur here, namely
on two instances of minimal pair 8 in Table 1: The person picked up an object quickly and
The person picked up an object slowly. The correct result is obtained for the remaining
instance of this minimal pair when associated with a different video clip.
5.4 Experiment 2: Language Generation
We can use the ability of the sentence tracker to score a video-sentence pair to generate a
sentence that describes a given video clip by searching for the highest-scoring sentence for
that clip. However, this has a problem. Recall that f , g, h, and a are all values in log
space that range in (−∞, 0] where increasing value denotes higher score, i.e., better fit to
the model. Since the sentence-tracker scoring function (Equation 10) sums these, scores
decrease with longer word strings and greater numbers of participants that result from
longer word strings. So we don’t actually search for the highest-scoring sentence, which
would bias the process towards short sentences. Instead we seek complex sentences that
describe the clip as they are more informative.
Nominally, this search process would be intractable since the space of possible sentences
can be huge and even infinite. However, we can use beam search to get an approximate
answer. This is possible because the sentence tracker can score any word sequence, not
just complete sentences, as long one can construct a linking function θ. We can select
the top-scoring single-word sequences and then repeatedly extend the top-scoring W -word
sequences, by one word, to select the top-scoring W + 1-word sequences, subject to the
constraint that a linking function θ exists for these W + 1 words and these W + 1-word
sequences can be extended to grammatical sentences by insertion of additional words. We
terminate the search process when the contraction threshold, the ratio between the score
of a sequence and the score of the sequence expanding from it, drops below a specified
value and the sequence being expanded is a complete sentence. This contraction threshold
controls complexity of the generated sentence.
When restricted to FSMs, h and a will be 0/1 which become −∞/0 in log space. Thus
increase in the number of words can only decrease a score to −∞, meaning that a sequence
of words no-longer describes a video clip. Since we seek sentences that do, we terminate
the above beam-search process before the score goes to −∞. In this case, there is no
approximation: a beam search maintaining all W -word sequences with finite score yields
the highest-scoring sentence before the contraction threshold is met.
645

Yu, Siddharth, Barbu, & Siskind

To evaluate this approach, we searched the space of sentences generated by the grammar
in Table 11(a) to find the top-scoring sentence for each of the 94 video clips in the first corpus.
Note that the grammar generates an infinite number of sentences due to recursion in NP.
Even restricting the grammar to eliminate NP recursion yields a space of 147,123,874,800
sentences. Despite not restricting the grammar in this fashion, we are able to effectively
find good descriptions of the video clips.
We evaluated the accuracy of the sentence tracker in generating descriptions for all 94
video clips in the first corpus for multiple contraction thresholds. Accuracy was computed
as the percentage of the 94 clips for which the sentence tracker produced descriptions
that were deemed to describe the video by human judges. The resulting accuracy for
different contraction thresholds is shown in Table 7. Figure 16 shows the highest-scoring
sentence generated by this approach for several clips in the first corpus for the contraction
threshold 0.90. Figure 22 in Appendix B shows the highest-scoring sentence generated
by this approach on each of the 94 clips in the first corpus. To illustrate the effect of
the contraction threshold, we show below, the generated sentence for the corresponding
contraction thresholds for the first video clip in Figure 16.
0.95
0.90
0.85

The backpack approached the trash can.
The backpack to the left of the chair approached the trash can.
The backpack to the left of the chair approached the trash can.

An important distinction between this approach and the state of the art for generating
sentential video description is the generativity of the labeling domain. In existing work
(Kulkarni et al., 2011; Gupta, Verma, & Jawahar, 2012), the process of labeling events in
video involves searching for phrases or sentences that best match the video using a trained
set of classifiers. This process usually involves extracting correspondences between labels
and video features in a training corpus. The training corpus labels each video with a word
or phrase and the sentence-generation process on an unseen video labels that video either
with an existing label from the training corpus or a simple concatenation of such labels. In
contrast, our approach can label an unseen video with any grammatical utterance admitted
by the grammar and lexicon, from a potentially unbounded set, even ones that have never
appeared, in whole or in part, in the training set.
The sentence-tracker framework can also generate sentential video description from a
fixed set of sentential labels, simply by scoring each potential label against an unseen video
clip and selecting the top-scoring label. We evaluate this ability by labeling each of the 94
video clips in the first corpus from the fixed label set of 21 sentences shown in Table 1 and
comparing such with human judgments. We performed three analyses. First, we measured
the percentage of clips that depict their top-scoring sentence as determined by human judges.
This was determined to be 94.68%. Chance performance is 13.12%, since on average, 2.76
sentences are deemed to describe a given clip, as shown in Table 4. Second, if we relax our
selection criterion slightly, to consider the percentage of clips described by at least one of the
top-three sentences, we obtain 100% accuracy. Chance performance is 1 − (1 − 0.1312)3 ≈
34.42%. Finally, we can threshold the video-sentence score, yielding a binary machine
judgment as to whether a given sentence describes a given clip, or alternatively whether
a given clip depicts a given sentence. We can then ask how well such machine judgments
match human judgment over all 94 × 21 = 1974 video-sentence pairs in the first corpus.
646

Grounding Language Inference, Generation, and Acquisition in Video

The backpack to the left of the chair approached the trash can.

The person to the right of the backpack carried the chair.

The person to the right of the trash can approached the trash can.

The chair to the right of the person approached the trash can.

The backpack to the left of the trash can approached the trash can.
Figure 16: Sentential descriptions generated for several video clips in the first corpus subject
to the contraction threshold 0.90. The highest-scoring sentence for each clip is generated,
among all sentences that are generated by the grammar in Table 11(a), by means of a beam
search. The sentences deemed by human judges to describe the associated clips are indicated
in green, while ones that do not are indicated in red. Sentential descriptions generated for
each of the 94 video clips in the first corpus are shown in Figure 22 in Appendix B.

647

Yu, Siddharth, Barbu, & Siskind

Searching for the threshold that maximizes this accuracy yields an accuracy of 86.88%.
Chance performance is 13.12%, since 259 out of the 1974 human judgments are positive.
Thus the sentence tracker performs significantly above chance on all three analyses.
5.5 Experiment 3: Language Acquisition
The sentence tracker, when wrapped in EM, can learn a lexicon that maps words to their
meanings from a training set of video clips paired with sentences. A crucial distinction
between this approach and the prior state of the art in learning object and event recognizers
from video is that, in this approach, the training videos are paired with entire sentences, not
individual class labels. These sentential labels are generative; the set of possible labels is
infinite as they are generated by a context-free grammar that contains recursion. Thus the
vast majority of the potential labels never appear in the training set. Yet our method can
learn to describe previously unseen videos with previously unseen sentential labels that are
composed of words that likely do not occur in a single training sample but instead require
composing words that are each learned by exposure to distinct training samples.
To evaluate the use of the sentence tracker to perform language acquisition, we employ
the second corpus described in Section 5.1, in particular Tables 2 and 3, together with the
grammar and lexicon from Table 11. This language fragment contains 17 lexical entries
over 6 parts of speech (1 determiner, 6 nouns, 2 spatial-relation prepositions, 4 verbs,
2 adverbs, and 2 motion prepositions). We model and learn the meanings of all the content
words in this lexicon. Table 8 specifies the arity I, the number K of states, the feature-vector
length N , the number Z of bins fore each feature, and the feature computation Φ for the
word models of each part of speech c. While we specify a different subset of features for each
part of speech, we presume that, in principle, with enough training data, we could include
all features in all parts of speech and automatically learn which ones are noninformative
and lead to uniform distributions.
We compute continuous features, such as velocity, distance, size ratio, and x-position
from the detections and quantize the features into bins as follows:
velocity To reduce noise, we compute the velocity of a participant by averaging the optical
flow in the detection. The velocity magnitude is quantized into 5 levels. For expository clarity, we refer to these levels mnemonically as absolutely stationary, mostly
stationary, moving slowly, moving quickly, and moving very quickly. The velocity orientation is quantized into 4 directions: leftward, upward, rightward, and downward.
distance We compute the Euclidean distance between the detection centers of two participants, which is quantized into 3 levels: near, moderate distance, and far.
size ratio We compute the ratio of the detection area of the first participant to the detection area of the second participant, quantized into 2 levels: larger than and smaller
than.
x-position We compute the difference between the x-coordinates of the participants, quantized into 2 levels: to the left of and to the right of.
The binning process was determined by a preprocessing step that clustered a subset of the
training data. In addition to the above continuous features that need quantization, we also
incorporate the index of the detector that produced the detection as a discrete feature.
648

Grounding Language Inference, Generation, and Acquisition in Video

c

I K N Z

N

1

1

Φ

1

6

detector index
velocity magnitude for the first argument
velocity orientation for the first argument
velocity magnitude for the second argument
velocity orientation for the second argument
distance between the first and second arguments
size of the first argument / size of the second argument

V

2

3

6

5
4
5
4
3
2

P

2

1

1

2

difference between the x-positions of the first and second arguments

Adv 1

3

1

5

velocity magnitude

PM

3

2

5
3

velocity magnitude for first argument
distance between the first and second arguments

2

Table 8: Characteristics of the HMMs used to model word meanings for various parts of
speech c. I denotes arity, K denotes the number of states, N denotes the number of features
in the output model, Z denotes number of bins for a particular feature, and Φ denotes the
feature computation.
The detector index is mainly used for identifying a detection when learning nouns. The
particular features computed for each part of speech are given in Table 8.
Note that while we use English phrases, like to the left of, to refer to particular bins of
particular features, and we have object detectors which we train on samples of a particular
object class such as backpack, such phrases are only mnemonic of the clustering and objectdetector training process. We do not have a fixed correspondence between the lexical entries
and any particular feature value. Moreover, that correspondence need not be one-to-one: a
given lexical entry may correspond to a (time variant) constellation of feature values and
any given feature value may participate in the meaning of multiple lexical entries.
We performed three-fold cross validation using the partitioning described in Section 5.1.
It is important to stress that for each fold, the test set was disjoint from the training set, both
in video clips and in sentential labels. This crucially allowed us to evaluate the generative
nature of the sentential labels: the ability to learn to generate previously unseen labels for
previously unseen video.
For each fold, we trained a lexicon on the training set for that fold using the procedure
from Section 4. We then evaluated the trained lexicon on the test set for that fold by
performing three distinct analyses:
1. comparing F1 score on the test set with a variety of baselines
2. comparing an ROC curve on the test set with a variety of baselines
3. inspection of the learned models and comparison with hand-constructed models
The first two analyses require scoring unseen video-sentence pairs. These could be scored
with Equation 10. However, this score depend on the sentence length W , the length T of
the video clip, the number L of participants, and the collective numbers of states K and
feature-vector lengths N for the word models for words in that sentence. One can remove
649

Yu, Siddharth, Barbu, & Siskind

Fold

Baselines

Our method

Chance

Blind

Hand

1
2
3

0.06
0.07
0.04

0.10
0.12
0.08

0.73
0.65
0.50

0.56
0.50
0.31

average

0.06

0.10

0.62

0.46

Table 9: A comparison of the F1 scores on the test sets between our method and a variety
of baselines.
the dependence on the number L of participants by using L(B; s, Λ) as the score. However,
this does not remove dependence on the other factors.
To render the scores comparable across such variation, we apply a sentence-length prior
π(s) to the average per-frame score computed from the whole-video score L(B; s, Λ):
1

[L(B; s, Λ)] T π(s)
where

π(s) = exp

W
X

w=1

ω(Z) = −

Z
X
z=1



Ns w

ω(Ksw ) +

X

n=1

1
1
log = log Z
Z
Z



ω(Zsnw )

In the above, ω(Z) is the entropy of a uniform distribution over Z bins. This prior prefers
longer sentences which are more descriptive of the video.
The resulting scores are thresholded to decide hits, which together with the manual
annotation, can generate True Positive (TP), True Negative (TN), False Positive (FP), and
False Negative (FN) counts. To conduct our first analysis, for each fold, we selected the
threshold that led to the maximal F1 score on the training set, and used this threshold to
compute the F1 score on the test set. Table 9 reports the per-fold F1 scores along with the
average across folds.
For comparison, we also report F1 scores for three baselines: Chance, Blind, and
Hand. The Chance baseline randomly classifies a video-sentence pair as a hit with probability 0.5. The Blind baseline determines hits by potentially looking at the sentence but
never looking at the video. This strategy will make the same decision on video-sentence
pairs if these pairs contain the same sentence. We can find an upper bound of the F1
score that a blind method could have on each of our test sets by solving a 0/1 fractionalprogramming problem as follows. An optimal blind baseline will try to find a decision dm
for each of the M test sentences sm that maximizes the F1 score. Suppose, comparison
with ground-truth yields FPm false positives and TPm true positives on the test set when
650

Grounding Language Inference, Generation, and Acquisition in Video

dm = 1. Also suppose that setting dm = 0 yields FNm false negatives. The F1 score is then:
1

1+

M
X

dm FPm + (1 − dm )FNm

m=1
M
X

2dm TPm

m=1

|

{z
∆

}

Thus to maximize F1 we seek to minimize the term ∆. This is an instance of 0/1 fractionalprogramming problem which can be solved by binary search or Dinkelbach’s (1967) algorithm. This yields the best possible F1 score that any blind algorithm can produce. The
Hand baseline determines hits with the hand-crafted HMMs described below. These were
carefully designed to yield what we believe is near-optimal performance. As can be seen
from Table 9, our trained word models perform substantially better than the Chance and
Blind baselines and approach the performance of the Hand baseline. Because the corpus
was counterbalanced, the Chance and Blind baselines exhibit similar poor performance.
To conduct our second analysis, we varied the threshold used to decide hits to produce
ROC curves. Figure 17 shows curves for each of the folds along with an average across
folds, comparing our trained word models against the various baselines. Again, our trained
word models significantly outperform the baselines and essentially match the performance
of the hand-crafted word models.
Good F1 scores and ROC curves are necessary but not sufficient to demonstrate successful learning. It is possible that the trained word models reflect artifactual properties
of the corpus and don’t encode the natural pretheoretic intended meaning. For example, if
the dataset has spurious unintended correlations, such as whenever approach happens, the
agent is always larger than the goal, the learned word model may reflect that correlation
and this correlation may be the primary factor leading to good performance on the test set.
If such an artifactual correlation is overly strong, it could even overpower the correlations
between the relevant features and allow learning meanings that do not rely on those features and which would fail to generalize to corpora that did not exhibit the same artifactual
properties.
To evaluate whether this occurs in our experiments, we conducted a third analysis that
compared our trained word models (for fold 2) with the hand-crafted ones illustrated in Figures 23 through 30 in Appendix B. For qualitative comparison, we render the hand-crafted
and trained word models side by side for each lexical entry, graphically illustrating the
output distributions and textually illustrating the initial-state and state-transition-function
distributions. Qualitative inspection indicates that the corresponding word models are indeed quite similar except for noise in the learned word models. The crucial qualitative
observation is that to a large extent the initial-state and state-transition-function distributions place the bulk of the probability mass in the same state and the relevant output
distributions exhibit peaks at the same bins. For example, for the word person, the two
word models have a peak for the first bin which denotes the object-detector class person.
Similarly, both word models for the verb approached describe the qualitative motion profile.
Both depict an initial state in which:
651

Yu, Siddharth, Barbu, & Siskind

(a)

(b)

(c)

(d)

Figure 17: ROC curves comparing the performance of the trained models against the various
baselines for the three folds (a-c) and averaged across fold (d).

1. the agent and the goal are both stationary and
2. the agent is far from the goal
followed by an intermediate state in which:
1. the agent is moving horizontally,
2. the goal is stationary, and
3. the distance between the participants is decreasing
followed by a final state in which:
1. the agent and the goal are both stationary and
2. the agent is close to the goal.
There are two primary qualitative differences between the learned and hand-crafted distributions. The first is noise. The second is that the hand-crafted distributions for irrelevant
features are intentionally uniform while the learned distributions for these features sometimes encode the artifactual properties of the corpus to a small extent. For example, the
second state of the trained word model for picked up indicates that the first argument is
652

Grounding Language Inference, Generation, and Acquisition in Video

trained word models
person
backpack
chair
traffic cone
trash can
stool
to the left of
to the right of
approached
carried
picked up
put down
towards
away from

random word models

1

2

3

average

1

2

3

average

0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
12.63
15.89
9.40
8.73
1.71
3.21

0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
15.43
10.60
9.44
13.09
4.69
6.72

0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
12.44
11.74
10.97
10.05
3.14
2.86

0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
13.50
12.74
9.94
10.62
3.18
4.27

1.11
5.43
4.17
2.09
0.82
1.12
1.19
0.50
11.32
14.42
12.86
16.59
3.97
10.91

1.09
1.72
1.44
1.47
1.35
1.33
0.26
0.09
18.92
11.97
8.49
11.87
3.88
5.32

3.45
1.14
1.64
1.78
1.09
4.10
0.59
0.53
18.10
15.10
14.44
14.02
4.65
9.81

1.88
2.76
2.42
1.78
1.09
2.18
0.68
0.37
16.11
13.83
11.93
14.16
4.17
8.68

Table 10: An upper bound on the KL-divergence between the hand-crafted and trained
word models for each fold and averaged across folds. (left) KL-divergence between trained
word models and hand-crafted word models. (right) KL-divergence between random word
models and hand-crafted word models.

moving upward while the hand-crafted word model contains a uniform distribution for the
velocity orientation of the first argument. Similarly, the second and third states for the
trained word model for carried appear, at first glance, to be quite different from the handwritten one. However, closer inspection reveals that they encode similar information. The
second state in the hand-written word model actually corresponds to the last two states
in the trained word model, which collectively encode a mixture distribution. The mixture distribution encodes that fact that carried is bidirectional and can involve leftward
or rightward motion. The hand-written word model encodes this with a single state and
a bimodal output distribution while the trained word model encodes this with two states
each with unimodal output distributions. The lack of an additional state forces the trained
word model to merge the output distributions for the velocity features from the last state
in the hand-crafted word model into the two states that code the mixture distribution. We
expect such differences to be eliminated with a larger training set or more accurate feature
extraction.
We augmented this qualitative analysis of the similarity between the hand-crafted and
trained word models with a quantitative analysis. We computed the KL-divergence between
the output distributions of corresponding word models. This is not the true KL-divergence
between two word models, as it ignores the initial-state distributions and state-transition
functions, but provides a loose lower bound on the actual KL-divergence. Table 10 reports
these for each word in our lexicon. Across the board, the trained word models are much
closer to the hand-trained ones than the random word models.
653

Yu, Siddharth, Barbu, & Siskind

6. Related Work
The language-inference task discussed in Section 5.3 requires a mechanism to focus attention
on a particular activity in a video that depicts multiple simultaneous activities. Obtaining
such a capability by extension of other state-of-the-art methods that can identify activity
in video is not trivial. A large portion of such work, such as recently done by Kuehne et al.
(2011) and Sadanand and Corso (2012), identify either a single activity in a given video or a
rank ordering of possible activities. If such videos depicted multiple simultaneous identical
activities, then these methods would identify only a single instance of such activity. This is
partly due to the fact that matching features, say from STIP (Laptev, 2005), only provides a
score, but no means of localization. Our method, on the other hand, can do so. If there exist
two instances of an activity, say pick up, occurring simultaneously, we can specify which
one to focus attention on by means of other elements in the video, such as characteristics
of the participants (adjectives), manner of the action (adverbs), or relations between the
participants and other unrelated objects in the scene (prepositions). As discussed previously
in Section 5.4, much of the prior work on generating sentences to describe images (Jie,
Caputo, & Ferrari, 2009; Farhadi, Hejrati, Sadeghi, Young, Rashtchian, Hockenmaier, &
Forsyth, 2010; Kulkarni et al., 2011; Li & Ma, 2011; Yang, Teo, Daumé III, & Aloimonos,
2011; Gupta et al., 2012; Mitchell, Dodge, Goyal, Yamaguchi, Stratos, Han, Mensch, Berg,
Berg, & III, 2012) and video (Kojima, Tamura, & Fukunaga, 2002; Fernández Tena, Baiget,
Roca, & Gonzàlez, 2007; Barbu et al., 2012a; Hanckmann et al., 2012; Khan & Gotoh, 2012;
Krishnamoorthy et al., 2013; Wang, Guan, Qiu, Zhuo, & Feng, 2013) uses special-purpose
natural-language-generation methods. Our method, in contrast, systematically searches for
the highest-scoring sentence generated by a grammar using the same video-sentence scoring
function as used for language inference and language acquisition. The generativity of our
labeling domain allows us to label an unseen video with any sentence, from a potentially
unbounded set, including those that have never appeared, in whole or in part, in any form
of training.
There has been active research on grounded language learning in the computational
linguistics community. Some of this research employs approaches that directly map words
to perceptual features extracted from the external world. Roy (2002) paired training sentences with vectors of real-valued features extracted from synthesized images which depict
2D blocks-world scenes, to learn a specific set of features for adjectives, nouns, and adjuncts. Roy and Pentland (2002) presented a computational model which acquires word
meanings directly from multimodal sensory input. Yu and Ballard (2004) paired training
images containing multiple objects with spoken name candidates for the objects to find
the correspondence between lexical items and visual features. Marocco, Cangelosi, Fischer,
and Belpaeme (2010) grounded the meanings of action words in the link between a robot’s
action effects and the behavior observed on the manipulated objects before and after the
action. Because these approaches directly learn word meanings from associated features,
they can only robustly understand a limited set of sentential fragments and lack the capability to deal with complex syntactic structures, since the resulting word meanings are
neither generative nor compositional.
Other work within the computational linguistics community has focused on learning
symbolic representations of word meanings from corpora of sentences paired with sym654

Grounding Language Inference, Generation, and Acquisition in Video

bolic representations of sentential meaning, as illustrated in Figure 18(a). Thompson and
Mooney (2003) described a system called Wolfie that acquires a semantic lexicon of phrasemeaning pairs from a corpus of sentences paired with semantic representations. Zettlemoyer and Collins (2005) presented a method for learning sentence meanings in the form of
lambda-calculus encodings. Dominey and Boucher (2005) paired narrated sentences with
symbolic representations of their meanings, automatically extracted from video, to learn
object names, spatial-relation terms, and event names as mappings from the grammatical
structure of sentential fragments to the semantic structure of the associated meaning representation. Piantadosi, Goodman, Ellis, and Tenenbaum (2008) employed an unsupervised,
cross-situational Bayesian learning model for the acquisition of compositional semantics, to
solve the problem of referential uncertainty. Chen and Mooney (2008) and Kim and Mooney
(2010) learned the language of sportscasting by determining the alignment between game
commentaries and the meaning representations output by a rule-based simulation of the
game. This was later reduced to the task of learning a Probabilistic Context-Free Grammar (PCFG) by Börschinger, Jones, and Johnson (2011). Their subsequent work (Chen
& Mooney, 2011; Kim & Mooney, 2012, 2013) proposed techniques for learning to follow
navigation instructions from observation given weak, ambiguous supervision. Kwiatkowski,
Zettlemoyer, Goldwater, and Steedman (2010) and Kwiatkowski et al. (2012) presented an
approach that learns Montague-grammar representations of word meanings together with
a combinatory categorial grammar (CCG) from child-directed sentences paired with firstorder formulas that represent their meaning. Although these methods succeed in learning
word meanings from sentential descriptions, they do so only for symbolic representations
that might be extracted from simple or synthesized visual input; they fail to bridge the gap
between language and computer vision, i.e., they do not extract meaning representations
from complex visual scenes.
More recent work in the computational linguistics and robotics communities has attempted to learn grounded word meanings from richer perceptual input paired with multiword phrases. Krishnamurthy and Kollar (2013) introduced the Logical Semantics with
Perception (LSP) framework for grounded language acquisition that learns to map natural
language statements to their referents in a physical environment. However, they did this
only for nouns and spatial-relation prepositions on a small set of static images. Tellex,
Thaker, Joseph, and Roy (2013) learned the mapping between specific phrases and aspects
of the external world for a robotic system, but they assumed an ideal scene: perfect object classification, a 3D coordinate system, and unambiguous demonstration of the robot
correctly executing the action in the environment.
There has also been research on training object and event models from large corpora
of complex images and video in the computer vision community (Feng, Manmatha, &
Lavrenko, 2004; Yao, Yang, Lin, Lee, & Zhu, 2010; Kulkarni et al., 2011; Ordonez, Kulkarni, & Berg, 2011; Kuznetsova, Ordonez, Berg, Berg, & Choi, 2012; Sadanand & Corso,
2012; Chen & Grauman, 2013; Everts, van Gemert, & Gevers, 2013; Song, Morency, &
Davis, 2013; Tian, Sukthankar, & Shah, 2013a), as illustrated in Figure 18(b). These can
be viewed as learning meanings for nouns and verbs. However, most such work requires
training data that labels individual concepts with individual words (i.e., objects delineated
via bounding boxes in images as nouns and events that occur in short video clips as verbs).
In other words, they have to specify the correspondence between the concepts in the data
655

Yu, Siddharth, Barbu, & Siskind

training sentence
training meaning
learned representations

The person picked up the chair.
cause(person, go(chair, up))
person
picked up
chair

person
cause(x,go(y,up))
chair

(a)
nouns
training words

training
images/videos

person

verbs
chair

picked up

...

...

upward

rightward

downward

leftward

velocity orientation
for the second argument

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

velocity magnitude
for the second argument

learned
representations

(b)

Figure 18: An illustration of the dominant paradigms in prior work. (a) Most work in
the computational linguistics community learns symbolic representations of word meanings
from sentences paired with symbolic representations of sentential meanings. (b) Most work
in the computer vision community learns each word independently, from training data that
annotates which image or video portion corresponds to an object or event label, with distinct
representations for each part of speech.

and the words to be trained. There is no attempt to model phrasal or sentential meaning,
let alone acquire the object or event models from training data labeled with phrasal or
sentential annotation. As a result, the learned word meanings are neither generative nor
compositional. Descriptions of new images and video are produced by mosaicing together
previously learned sentence fragments. Moreover, unlike the methods presented here, these
approaches use distinct representations for different parts of speech; i.e., object and event
recognizers use different representations.
Our method differs from prior work in three ways. First, our input consists of realistic
video filmed in an outdoor environment. Second, we learn the entire lexicon, including
nouns, verbs, adverbs, and prepositions, simultaneously from video described with whole
656

Grounding Language Inference, Generation, and Acquisition in Video

sentences. Third, we adopt a uniform representation for the meanings of words in all
parts of speech, namely hidden Markov models (HMMs) whose states and distributions
allow multiple possible interpretations of a word or a sentence in an ambiguous perceptual
context.
The work presented here is most similar to three very recent papers (Das, Xu, Doell, &
Corso, 2013; Rohrbach, Qin, Titov, Thater, Pinkal, & Schiele, 2013; Guadarrama, Krishnamoorthy, Malkarnenkar, Venugopalan, Mooney, Darrell, & Saenko, 2013) which generate
text descriptions of video. On the surface, these papers appear to describe approaches that
handle unrestricted text and video. However, deeper analysis reveals that this is not the
case. Indeed, such analysis demonstrates that the space of text supported by these systems
is far more restrictive than what we present here. We discuss this prior work in depth below
along with such analysis.
Das et al. (2013) generate text descriptions of cooking videos garnered from YouTube.
They do so by using shallow vision features on an unseen video to index into a training
corpus of videos paired with text annotations to find similar videos and stitching together
fragments of the text associated with the indexed videos to obtain a new text annotation
of the unseen video.
1. It does not have a model of word or sentence meanings. It doesn’t know what the
words or the sentences in the annotations refer to in the video. One can’t point to
any component in the system and say this is its definition for this particular word.
This is precisely what we do in Table 6 and Figures 5, 6, and 23–30 (in Appendix B).
Moreover, one can’t analyze what portions of the meanings are correct and what are
wrong, as we do on page 651. When the system generates an incorrect annotation,
there is nothing much one can say about it other than it did so.
2. Because of (1) it can’t do what we call inference. It can’t process a video with
simultaneous actions taking place with different subsets of actors and objects in the
video with two different sentences and highlight the different sets of participants for the
different sentences. This is precisely what we demonstrate in Figure 15 and Figure 21
in Appendix B. This demonstrates deep understanding. The fact that we do so for
minimal pairs, pairs of sentences that differ in a single word, and vary that word over
all lexical entries and all sentential positions demonstrates that our semantic model
reflects deep understanding of every word.
3. The work of Das et al. (2013) lacks such. This causes their method to generate a
huge number of erroneous descriptions. Das et al. (2013, Figure 6) show five sample
sentences generated for each of five sample videos. For all sample videos, between
three and four of the generated sentences are false of the video. Most have completely
incorrect objects and actions. These are the examples picked to showcase their system.
Presumably, it performs worse on other examples. In contrast, we conduct and present
results of a thorough evaluation: Figure 21 in Appendix B presents results on all
examples, without exception.
4. Most of the nouns and adjectives generated in sentences in the work of Das et al. (2013,
Figure 6) describe objects that are far beyond the ability of state-of-the-art objectdetection systems to detect (e.g., knob, pliers pieces of metal, glass bowl, porcelain
bowl, sponge, old food, dish towel, hand held brush, vacuum, panel, health care reform,
. . .), particularly at the size they are in the field of view. Ditto for verbs denoting
657

Yu, Siddharth, Barbu, & Siskind

actions (e.g., clean, speak, sit, stand, open, renovate install, bend, cook, mix, . . .). The
system is not really grounding the meanings of these words in video. Rather it is
just indexing based on surface features. This is what we mean when we say that our
system uses linguistics. While this system may use techniques that are prevalent in the
natural-language-processing community, and one might even call them computational
linguistics, one would not call them linguistics. This is not to denigrate such a system.
It is simply incomparable to our work.
5. Das et al. (2013) do not report measured alignment between the words in the text
and the portions of the video. Thus one is unable to determine whether sentence
generation really is based on video features that convey the meanings of the words
and sentences generated or whether it is more based on accidental correlation with
features in the background that are not reflective of the true meanings.
Rohrbach et al. (2013) generate text annotations for videos with a two-step process.
They first translate a video x into an intermediate representation (SR) y and then translate
the SR y into a sentence z. The SR is five discrete random variables (activity, tool, object,
source, and target). There are 66 possible activities, 43 possible tools, 109 possible objects,
51 possible sources, and 35 possible targets. The mapping from video to SR is mediated by
a joint probability model implemented as a conditional random field (CRF) that mutually
constrains these five random variables. This CRF is trained in a supervised fashion. The
training data contains videos paired with human annotated SRs. The mapping process
from video to SR yields a quantized SR by returning the SR from the training set with the
lowest Hamming (1950) distance to the SR estimated by the CRF.
The text-generation process involves a second step which maps an SR to a sentence.
However, this process does not use any information from the video that is not already
abstracted in the SR. For purposes of comparing with our work, this process is not relevant.
The discrete quantized SR is the component of the work of Rohrbach et al. (2013) that
is most analogous to the individual words that we generate. In our case, the mapping
from words to sentences is done by a deterministic grammar and neither introduces errors
nor contains any other joint-distribution information to filter out errors. Their mapping
from SR to sentences can introduce errors but also constitutes an additional level of jointconstrained-distribution information that can filter out errors. Thus we compare our system
to only the first step of their work.
Due to Hamming-distance post processing, Rohrbach et al. (2013) can output only
one of 5,609 possible SRs out of a total of 66×43×109×51×35=552,175,470 ones that are
nominally possible. Thus it can only generate 5,609 possible sentences. In contrast, our
system can generate 235,575 possible sentences with no more than three objects for the
first corpus, 406,296 possible sentences with no more than three objects for the second
corpus, 6,614,325 possible sentences with no more than four objects for the first corpus,
and 13,633,272 possible sentences with no more than four objects for the second corpus.
Thus while on the surface, it appears that the system of Rohrbach et al. (2013) handles
unrestricted text, in reality it handles a space of sentences that is four to five orders of
magnitude smaller than we do. Thus they are solving an immensely easier problem with a
much smaller space of possible outputs. Yet, Rohrbach et al. (2013, Table 1) indicate that
they obtain the correct SR only 21.6% of the time. We obtain a true sentence more than
658

Grounding Language Inference, Generation, and Acquisition in Video

64% of the time. Moreover, our system learns solely from videos paired with sentences.
Their system requires additional human annotation of the SRs associated with each video.
Points 1–5 from our comparison with the work of Das et al. (2013) also apply to the
work of Rohrbach et al. (2013). In particular, the vast majority of the object classes are well
beyond the state-of-the-art ability to support recognition if it were not for the CRF (e.g.,
avocado, egg, cucumber, bag of chilies, cutting board, loaf of bread, lime, knife, plate, butter,
carrot, (half ) kiwi, package of beans, orange, saucer, . . .), particularly at the size they are
in the field of view. Similarly, the vast majority of the verbs are well beyond the state of
the art to support in action recognition, if it were not for the CRF (e.g., slice, crack, take
out, rinses, put away, select, split, . . .). Rohrbach et al. (2013) derive most of their success
from the highly constrained set of possible SRs and the distribution encoded in the CRF.
That means it cannot describe videos that exhibit a person taking a kiwi out of the fridge if
that never occurred in the training corpus, even though it might be a perfectly reasonable
video. Surely vastly more than 5,609 of the 552,175,470 possible SRs are plausible and
perhaps even likely. Yet even with this constraint, Rohrbach et al. (2013, Table 2) report
that when human judges evaluated the truth of the generated sentences, the average report
was 3.1 on a scale from 1 to 5, 3 being “70–80% good.” Moreover, they are limited to
the particular representation employed for SRs. They can only encode sentence meanings
that are formulated in terms of the particular five random variables (activity, tool, object,
source, and target). In contrast, our approach can formulate sentence meanings in terms of
arbitrary conjunctions of any predicates applied to any subset of event participants so long
as those predicates can be formulated as HMMs over arbitrary output distributions over
features that can be extracted from the video.
Guadarrama et al. (2013) describe a method that outputs three-word sentences to summarize video activity. Like Rohrbach et al. (2013), such are encoded as three variables: an
actor (subject), an action (verb), and an object (object). There are 45 possible subjects,
218 possible verbs, and 241 possible objects. Given a training corpus comprising video
clips paired with annotated SVO triples, the method first builds three semantic hierarchies,
represented as trees, one for each of subject, verb, and object, that indicate the similarity
relationships among the meanings of the words that occur in the training corpus. Each word
that appears in the training corpus constitutes a leaf node in one of the hierarchy trees.
The internal nodes represent sets of dominated leaf nodes, a generalized concept having less
specificity than the leaf nodes.
A visual classifier is associated with the leaf nodes for each individual subject, verb, and
object. The leaf classifier uses
1. Dense Trajectories (Wang, Kläser, Schmid, & Liu, 2011, 2013; Wang & Schmid, 2013),
encoded using a pre-trained codebook,
2. a vector of object-detector scores, each entry denoting the maximal score for each
object class, and
3. a multi-channel approach that combines the above two features and classifies them
with a non-linear SVM.
Once the classifiers are trained, probability estimates for the nodes in the hierarchy trees
are obtained for an unseen video clip. Then nodes from the three hierarchies representing
words to be generated for the unseen video clip are predicted by optimizing a cost function
that trades off specificity for accuracy. When an internal node is predicted, the represen659

Yu, Siddharth, Barbu, & Siskind

tative leaf word is selected from the set of leaves dominated by that node as the leaf that
has the highest cumulative WUP in WordNet (Miller, 1995; Fellbaum, 1998). Guadarrama
et al. (2013) also introduce a zero-shot approach to generate verbs that do not appear in
the training corpus and thus are absent from the verb hierarchy. To do that, the verb is
determined with text-mined likelihoods that fit the detected subject and object. While they
paint this as a virtue, we view it as a deficit. Essentially, it is guessing the verb. While there
are some celebrated cases where objects predict verbs and vice versa (e.g., hammer ), we
believe that this accounts for far less in actual video. When one sees a dog and a cat, there
are still a plethora of possible verbs: approach, leave, run away from, fight with, ignore,
chase, flee from,bite, lick, . . . It is easy to pick examples that showcase where this works
but that says little about how well the approach works in general.
The approach taken by Guadarrama et al. (2013) is very similar to that taken by
Rohrbach et al. (2013), in that both construct joint probability models of a collection of
random variables, five in the case of the latter but three in the case of the former. Rohrbach
et al. add quantization by Hamming distance that is absent in the work of Guadarrama
et al., and Guadarrama et al. add the zero-shot approach along with the hierarchies that
balance between accuracy and specificity that is absent in the work of Rohrbach et al.. Without the above zero-shot extension, Guadarrama et al. output one of 45×218×241=2,364,210
possible sentences. This number is roughly equivalent to the number of sentences that our
method can produce.
The work of Guadarrama et al. exhibits the same shortcomings as in the work of
Rohrbach et al. and Das et al. (2013). Points 1–5 from our comparison with the work of
Das et al. also apply to the work of Guadarrama et al.. As is the case with the work of
Rohrbach et al., the vast majority of the object classes are well beyond the state-of-theart ability to support recognition (e.g., chef, cook, microphone, flute, flour, music, pasta,
spaghetti, . . .), particularly at the size they are in the field of view. Similarly, the vast
majority of the verbs are well beyond the state of the art to support in action recognition
(e.g., slice, cut, chop, prepare, make, . . .). It is almost certain that the visual-feature space
would not separate verbs such as chop and cut, and nouns such as pasta and spaghetti.
These words are also so similar in their semantic meanings that it is even quite difficult for
humans to distinguish in short video clips. Thus while the number of words that can appear
in the generated sentences is increased by considering similar lexical items, the difficult of
the generation task does not increase as much as expected if the evaluation is lax (e.g.,
considering chop to be correct even though slice actually happens in the video).
On the other hand, because of the specificity-accuracy tradeoff, the generated sentences
sometimes are uninformative, e.g., An animal plays something and An animal does something with the instrument (Guadarrama et al., 2013, Table 4). Also the zero-shot approach
seems to override the actual activity recognition quite easily, as can be seen in the fourth
row (Guadarrama et al., 2013, Table 4): A car rides the vehicle. Finally, Guadarrama et al.
do not evaluate the truth of the sentences generated. Instead, they only calculate the WUP
similarity between generated and annotated subjects, verbs, and objects, independently.
By our estimates, seven out of the eleven generated sentences in are false of the corresponding video clip. These are the examples picked to showcase their system. Presumably, it
performs worse on other examples. It is unclear what the actual truth accuracy of the
generated sentences is over the entire corpus.
660

Grounding Language Inference, Generation, and Acquisition in Video

There is also something deeply unsettling about the general approach taken by both
Rohrbach et al. and Guadarrama et al. of using a joint probability model derived by text
mining to influence activity recognition. Suppose that a corpus of text had much higher
frequency of occurrence of dog chases cat than dog is-bigger-than cat or dog eats-with cat.
That says nothing about the actual prior truth probability of the underlying propositions,
let alone the actual posterior truth probability conditioned on a particular video. In some
sense, Rohrbach et al. and Guadarrama et al. are actually not grounding language in
video but rather generating natural-language utterances using information obtained from
ungrounded language.

7. Discussion
The computational linguistics community has become accustomed to employing large lexicons and grammars trained on large text corpora to process unrestricted text. Similarly,
the computer vision community has become accustomed to employing methods that can be
trained on large image and video corpora to process unrestricted images and video. One
may wonder what it would take to extend the methods explored here so that they too
can apply to large-scale unrestricted text and video corpora. One might assume that it
is simply a matter of employing better state-of-the-art methods from both computational
linguistics and computer vision. This, however, is not the case. While we do not use
state-of-the-art methods from computational linguistics, our computer vision methods are
state of the art. We use the deformable part model (DPM) object detector (Felzenszwalb
et al., 2010a, 2010b) and an action detector that exhibits state-of-the-art performance. Our
approach is limited by computer vision, not computational linguistics. The state of the
art in object detection is reflected by the ongoing Pascal Visual Object Category (VOC)
Challenge (Everingham et al., 2010). It currently has 20 classes and current state-of-the-art
performance is about 40-50% on the best classes, and far worse for other classes. The state
of the art in action recognition is reflected by the standard corpora used in that community, e.g., Weizmann (9 classes; Blank, Gorelick, Shechtman, Irani, & Basri, 2005), KTH
(6 classes; Schuldt, Laptev, & Caputo, 2004a), UCF Sports (10 classes; Rodriguez, Ahmed,
& Shah, 2008), UCF YouTube (11 classes; Liu, Luo, & Shah, 2009), and Olympic Sports (16
classes; Niebles, Chen, & Fei-Fei, 2010). The best reported performance on these corpora
(Weizmann 100%: Tian, Sukthankar, & Shah, 2013b; KTH 95.49%: Yuan, Li, Hu, Ling, &
Maybank, 2013; UCF Sports 95%: Sadanand & Corso, 2012; UCF YouTube 89.4%: Zhu,
Wang, Yang, Zhang, & Tu, 2013; and Olympic Sports 85%: Gaidon, Harchaoui, & Schmid,
2014) might lead one to the mistaken conclusion that action classification is solved for small
numbers of classes. However, Barbu, Barrett, Chen, Siddharth, Xiong, Corso, Fellbaum,
Hanson, Hanson, Hélie, Malaia, Pearlmutter, Siskind, Talavage, and Wilbur (2014) illustrate that this is false, a 6-class corpus for which state-of-the-art methods get no more than
52.34%. Moreover, the largest corpora actively used for action recognition contain about 50
classes (UCF50, Reddy & Shah, 2013 and HMDB51, Kuehne et al., 2011). The best reported
performance on UCF50 is 91.2% and on HMDB51 is 57.2%, (Wang & Schmid, 2013). Thus
an approach, such as ours, which grounds the meaning of each individual word in stateof-the-art computer vision object detectors, trackers, and action recognizers is inherently
limited to a very small number of concepts. The space of natural-language utterances that
661

Yu, Siddharth, Barbu, & Siskind

one can erect around such is thus limited and can effectively be captured by a small fixed
unambiguous context-free grammar. Thus employing state-of-the-art methods from computational linguistics would not improve the generality of our approach given the limited
state of the art in computer vision.
In this paper we, thus, do not employ such state-of-the-art methods from computational
linguistics. We employ a small fixed lexicon and grammar. We make no claim that this
lexicon and grammar is general. The particular lexicon and grammar is not the focus of
this work. They serve to illustrate our framework and the capability of that framework for
supporting the concerns outlined at the end of Section 1. One can change the lexicon or
grammar and still use our framework. Indeed, we have done so and report some of this.
Table 11(a) reports two slightly different grammars. The experiments employ two different video corpora with two different sets of sentential annotations that use these different
grammars as reported in Tables 1–3. These video corpora use different sets of objects and
associated object-detector models. Barbu, Siddharth, and Siskind (2014) employ yet another corpus, with a different set of objects and object-detector models, a different lexicon, a
different grammar, and a different set of word-meaning representations. This demonstrates
that our framework can be adapted to a variety of such. But beyond this, Barbu et al.
(2014) demonstrate yet another whole different application of the same framework, namely
video retrieval. And they do so on a corpus of ten full-length Hollywood movies. This
corpus is far from “toy.” Our framework can support such large-scale real-world video “in
the wild.” Yet the concept vocabulary is still small so the natural-language fragment is still
restricted. While one could employ state-of-the-art methods from computational linguistics,
the supported concept set and thus the supported language fragment would still be small.
Thus one would not be using these state-of-the-art methods to the potential that they were
designed for.
There are two general approaches towards action recognition in computer vision. One
employs methods to detect and track people and objects that participate in the action,
classifying action by properties derived from the detected objects and tracks. The other
extracts and classifies features from video without detecting and tracking people and objects. The latter methods generally employ a bag of spatio-temporal visual-words approach
(BOW). They generally extract feature vectors, such as spatio-temporal interest points
(STIP; Schuldt, Laptev, & Caputo, 2004b), at a subset of space-time points, build a codebook by pooling such, vector quantize such feature vectors on this codebook, compute a
histogram of codebook-entry occurrences on the pooled frames of a video, and classify these
histograms with temporally invariant models. Early approaches to action recognition generally employed the former method (e.g., Siskind & Morris, 1996; Mann, Jepson, & Siskind,
1996, 1997; Siskind, 1999, 2000, 2001; Fern, Givan, & Siskind, 2002a; Fern, Siskind, & Givan, 2002c; Fern, Givan, & Siskind, 2002b; Siskind, 2003). This approach was eschewed in
more recent work, in favor of the latter method, because of the difficulty of detecting and
tracking people and objects reliably (e.g., Schuldt et al., 2004b; Liu et al., 2009; IkizlerCinbis & Sclaroff, 2010; Kuehne et al., 2011; Reddy & Shah, 2013). However, the BOW
approach suffers from a severe limitation: it does not localize the event participants. While
it may be able to generate verbs to describe classified actions, it cannot generate nouns
to describe the object class of event participants, adjectives to describe the properties of
event participants, spatial-relation prepositions to describe the relative position of event
662

Grounding Language Inference, Generation, and Acquisition in Video

participants, adverbs to describe event properties, or motion prepositions to describe the
path taken by event participants. This is a distinguishing, novel, and unique aspect of our
approach. Moreover, while some systems, such as the one proposed by Guadarrama et al.
(2013), employ an object detector in addition to a STIP-based event detector, they do not
link the objects as arguments to the event predicates. Any system using a similar approach
like this would
1. fail to distinguish the dog approached the person from the cat approached the person
when both a dog and a cat were present in the field of view and
2. fail to distinguish the dog approached the person from the person approached the dog.
Our approach correctly makes such distinctions. One of the design principles behind our
corpus was that multiple people appear in most, if not all, videos, and most, if not all, objects
appear in every video. Beyond this, most videos depict simultaneous different actions by
different subsets of the participants. This is what renders the minimal-pairs experiment
(Section 5.3) and the acquisition experiment (Section 5.5) far from trivial.
We make no claim that the particular features that we employ in Tables 6 and 8 are
sufficient to represent the semantics of all possible words and utterances. These serve just
to support the experimental evaluation conducted in Section 5. One could employ the same
sentence-tracker approach discussed here with a different set of features. Indeed, we have
done so (Barbu et al., 2014). Moreover, we make no claim that one can employ HMMs
that form the core of the sentence tracker to represent the semantics of all possible words
and utterances. This is not just a limitation of an HMM-based approach that requires
object detectors and trackers; BOW approaches suffer from this as well. A BOW approach
cannot represent the verb approach. And neither a BOW or HMM approach can represent
the verbs liberate, contemplate, discuss, help, finish, . . . Representing the semantics of the
entire space of verbs, let alone all of natural language, even in a non-grounded fashion, and
even more so, grounded in video, is the central unsolved problem of all of computational
linguistics, AI, and cognitive science.
On the surface, it may appear that BOW approaches can be more robust at recognizing
certain action classes like play an instrument than approaches that involve detecting and
tracking objects. However, none of the standard datasets (Weizmann, KTH, UCF Sports,
UCF YouTube, Olympic Sports, UCF50, or HMDB51) have a class playing an instrument
(in general). Only one, UCF50, has classes for playing a small number of specific instruments: drumming, playing guitar, playing piano, and playing violin. We are unaware of any
published action-recognition systems that perform well on this dataset. One of the best
performing methods on this dataset is Action Bank (Sadanand & Corso, 2012), but it does
not use BOW. The performance of this method is enlightening as to the current state of
the art. It gets only roughly 80% accuracy on these classes. Moreover the confusion matrix is enlightening: drumming is confused with biking and yoyo, playing piano is confused
with basketball, drumming, golf swing, tennis swing, soccer, and juggling, and playing violin
is confused with drumming, rope-climbing, taichi, tennis, yoyo, and rock climbing. These
confusions indicate that it lacks any deep understanding of the characteristic of the actions
in question and appears to be triggering off of spurious correlations with the particular
dataset. In particular, the dataset does not contain people sitting next to a drum set or
piano, or holding a guitar or violin without playing it. So there is no way to know whether
it is actually recognizing the playing activity or simply recognizing gross image statistics
663

Yu, Siddharth, Barbu, & Siskind

that indicate that such instruments are present in the field of view. That is before one gets
to motions such as air guitar, banging the piano keys with your elbow, or simply waving
a violin in the air that constitute activity with the instrument in question but don’t constitute playing said instrument. Beyond this, we see little ability for it to generalize from
playing a specific instrument to playing an instrument in general.
BOW-based systems often do not encode the true semantics of the actions in question.
They often trigger off of spurious correlations in the dataset. This has been acknowledged
by authors of such systems themselves.
“For instance, v spiking normally happens in a crowd of people, and diving
happens in a pool. This is common for professional sport actions which take
place in highly structured environments (Liu et al., 2009, p. 2002)”
“Basketball shooting and volleyball actions are also confused in some cases: this
is largely because most of the time, the basketball and volleyball sports use very
similar courts (Ikizler-Cinbis & Sclarof, 2010, p. 505)”
One may desire, or even expect, some form of characterization of the space of possible
words or videos that our approach can support. Unfortunately, we know of no way to provide such. We know of no way, in general, of formally characterizing the space of words,
images, or video that can be supported by any action-recognition system, or for that matter any object-recognition system or, more generally, any computer vision, computational
linguistics, or AI system.
Our current corpus lacks camera motion. But this is not a restriction of our approach.
This restriction does not appear in any of the mathematical or algorithmic formulations in
Section 2 and 4, or even in the implementation. The sentence tracker is an extension of
prior work on detection-based tracking (Barbu et al., 2012b) which was employed to perform
action recognition and sentence generation on videos that do involve camera motion (Barbu
et al., 2012a). Barbu et al. (2014) apply the sentence tracker to perform video retrieval on
a corpus of ten full-length Hollywood movies, the vast majority of which involve camera
motion.
Our framework is expressly not restricted to using only verbs to represent events. Our
current linking process and the particular grammar used to support that process is restricted
to such. But nothing turns on that. As discussed above, the sentence tracker can use any
linking process to construct any factorial utterance-level HMM out of constituent wordlevel HMMs. For expedience, we limit the set of features entertained during learning on a
part-of-speech basis. This restriction could be lifted with no change to the algorithm or its
implementation. It was introduced to allow convergence with a smaller training set. We
know of no reason why the method from Section 4 would not work without such a restriction.
It would require a larger corpus that would be unwieldy to perform experiments with.
Our method represents word meanings in all parts of speech simply as predicates over
one or more tracks and sentential meanings as conjunctions of such. Presumably, a different linking process could construct the same logical form man(x) ∧ pause(x) from both
sentences like The man made a pause as well as it could from The man paused. This is
the beauty of our approach, employing a unified representation for the meanings of all
664

Grounding Language Inference, Generation, and Acquisition in Video

words in all parts of speech, a common cost function, a common algorithm, and a common
implementation.
State-of-the-art object-recognition systems are highly unreliable. For most image datasets,
a trained object model, for say person or chair, may succeed on one image and fail on another, even if it is of the same chair or same person in the same pose wearing the same
clothing in the same background. For most video, this even happens between adjacent
frames of the same video. State-of-the-art object detection suffers from immense false positives and negatives. Moreover, not only does reliable object detection not imply reliable
action recognition, state-of-the-art action recognizers are similarly highly unreliable. Stateof-the-art recognizers for bend and wave trained on one dataset yield chance performance
on a different datasets. Even on the same dataset, action recognizers can mysteriously
both succeed and fail on very similar samples, with the same background, same actors,
same manner of performance of action, etc. The central novel contribution of this work
is the sentence tracker in Equation 10, a method for overcoming the severe limitations of
both object detectors and action detectors by formulating a joint model of object detection,
tracking (temporal coherence), and sentential semantics.
While our video corpora may appear to be simpler than those typically used for current
action-recognition work in the computer vision community (e.g., Weizmann, KTH, UCF
Sports, UCF YouTube, Olympic Sports, UCF50, or HMDB51) this apparent simplicity is
misleading. Several aspects of our video corpora are far more complex than those used in
the vast majority of related work.
1. Most videos contain many, if not all, of the objects in our repertoire. This makes
language acquisition difficult. One needs to determine which objects are being referred
to by the training sentences and ignore the extraneous ones in the field of view. This
is all done automatically without any human annotation.
2. Most videos contain at least two simultaneous actions, often performed by different
people on different objects. One needs to determine which action is being referred to
by the training sentence associated with that video, pay attention to the particular
subset of people and objects that participate in that action, and ignore the extraneous
activity that occurs in the field of view. This is all done automatically without any
human annotation.
3. Our system can process complex natural-language sentences that contain many participants, e.g., something as complex as The person to the left of the chair carried
the backpack to the right of the traffic cone towards the stool to the left of the person. It can even support multiple instances of the same noun in a sentence that refer
to distinct instances of that object class in the video (as in person above). It can
determine the semantic-role assignment, which nouns and which arguments of which
words correspond to which regions in the video frames. Such assignment is determined
automatically without any human annotation and can change with small and subtle
changes to the sentence. Moreover, we can learn solely from such complex sentential annotation, without any human annotation of which words correspond to which
regions in the video frames.
Our novel and central technical contribution is the formulation of the sentence tracker
in Equation 10 and the observation that it can be optimized using standard well-known
techniques adapted from HMMs, namely the Viterbi algorithm (1967) and Baum-Welch
665

Yu, Siddharth, Barbu, & Siskind

(1970, 1972). The key to understanding Equation 10 is that it jointly optimizes a cost function that incorporates multiple detection-based trackers, one for each event participant, and
multiple factorial event models, one for each lexical item in a sentence, judiciously linking
the detection-based trackers to the factors of the sentential model in a way consistent with
the predicate-argument structure of a sentence, to model the truth-conditional semantics of
a sentence and how it is derived from its constituent words. Formulating truth-conditional
sentential semantics in this way allows exiting algorithms like Viterbi and Baum-Welch to
ground the semantics of natural language in video and perform novel applications such as
language inference (Section 5.3), language generation (Section 5.4, and language acquisition
(Section 5.5), particularly the minimal-pair experiment in Figure 15 and acquisition from
videos labeled with whole sentences and no further human annotation.
There has been significant prior work on multi-object tracking (e.g., Berclaz, Fleuret,
Turetken, & Fua, 2011; Pirsiavash, Ramanan, & Fowlkes, 2011). A novel aspect of the event
tracker is that the particular formulation of detection-based tracking as a cost function that
can be optimized by the Viterbi algorithm allows forming a joint model with an HMM-based
event detector that can also be optimized by the Viterbi algorithm with a cross-product
lattice. This might not be possible with other trackers and other event models. Beyond
this, the sentence tracker forms a joint model of multiple trackers and a factorial HMM,
linking particular factors to particular trackers, in a way that can again, also be optimized
by the Viterbi algorithm with a cross-product lattice. This also might not be possible with
other multi-object trackers and other event models.
Our video corpora were filmed by giving actors instructions about what actions to perform. As such, they were ‘staged.’ The computational linguistics community has attempted
to use unsolicited samples of natural language for fear that solicited samples might introduce bias. One might wonder whether it is desirable, and even possible, to do so for video
corpora as well. However, it appears infeasible to gather unsolicited video corpora except
in surveillance situations. Surveillance video tends to be highly uniform and sparse: only a
few event classes occur and most occur very infrequently. This renders it ill suited to action
recognition. Almost all other situations where video is recorded, even when not recorded
explicitly for computer vision use, is solicited. Most amateur video of the form uploaded to
YouTube is similarly staged at some level as it usually records activity elicited specifically
for filming. Indeed, most prominent video corpora used in the computer vision community
to evaluate action recognition were filmed specifically for the purpose of constructing the
corpus: Weizmann, KTH, the Activities of Daily Living corpus (Messing, Pal, & Kautz,
2009), the DARPA Mind’s Eye corpus (both year 1 and year 2), and the TaCOS corpus
used by Rohrbach et al. (2013), just to name a few. While the YouCook corpus used by
Das et al. (2013) was culled from YouTube, the videos themselves appear to be staged, just
as all of the above.
Some related work on generating sentences that describe video evaluates the generated
sentences by comparison with human-elicited sentences for the same video. Such is often
done by computing BLEU scores (Rohrbach et al., 2013) or measuring the fraction of
words in common between the machine-generated and human-elicited descriptions (Khan,
Zhang, & Gotoh, 2011). While such might evaluate the degree to which machine-generated
sentences are natural sounding, it fails to evaluate the truth of the machine-generated
sentences, the central objective of our work. Indeed, machine-generated sentences with
666

Grounding Language Inference, Generation, and Acquisition in Video

high BLEU scores or high commonality with human-elicited descriptions are often false of
the video even when the human-elicited descriptions are true.
Our current linking process would fail with an ambiguous sentence parse. The linking
process might also fail to yield an unambiguous role assignment and unique linking function. Further, our current lexicon contains no lexical ambiguity and our current linking
process would not support such. Any of the myriad approaches to parsing and constructing
logical form in the presence of ambiguity could be brought to bear on this problem. But
beyond this, the current approach offers a novel possibility that no existing approach can
support. One can imagine using video to disambiguate parsing and the construction of
logical form. One could imagine evaluating the truth of various word senses, sentence fragments, attachment alternatives, and alternate logical forms against video using the sentence
tracker.
The sentence tracker is a general-purpose inference mechanism for combining information from multiple frames of a video using both language and vision. While we have
presented a particular instantiation of the sentence tracker, with particular detectors, particular temporal-coherence scores, and particular event models operating in 2D, the general
approach could be instantiated in numerous other ways. We have employed object detectors as detection sources, but any method that selects image regions could be used in the
approach presented. These need not be rectangular: one can imagine variants of the sentence tracker that employ general-purpose foreground-background segmentation instead of
object detection. They also need not be two-dimensional: one can imagine variants of the
sentence tracker that employ projection models to reconstruct temporally-coherent tracks
in 3D from 2D images that also satisfy 3D event models. We could even pool the detections
from a variety of sources and scale their scores to prefer more reliable ones when possible.
Moreover, our temporal-coherence score uses only optical flow, but it could employ an appearance model in order to alleviate situations where tracks converge to the same image
location and are swapped between the two tracked objects as they again diverge from that
location. If one were to employ a human-pose detector, one could incorporate coherence
of human-pose variation into the temporal-coherence model. One could similarly incorporate changing human pose into the event model. Doing so with the event tracker would
allow such an event model to influence and improve the recovered human pose estimated
in a top-down fashion, much in the same way that the event model can influence and improve the recovered tracks. Finally, while our event models are formulated as HMMs, more
general frameworks are possible. Even nongenerative frameworks, like maximum-entropy
Markov models, could be accommodated as long as inference could be performed using a
lattice and dynamic programming. One can even imagine forgoing the lattice and dynamic
programming to integrate more complex models of object detection, temporal coherence,
and events using message-passing inference.
The sentence tracker can also learn word meanings from video paired with sentences.
Unlike prior work, our method deals with video labeled with whole sentences, instead of
individual words. Moreover, our method successfully learns without any prior delineation of
the correspondence between words in the sentence labels to visual features in the associated
video used for object and/or event recognition. The experiments show that it can correctly
learn the meaning representations in terms of HMM parameters for our lexical entries,
from highly ambiguous training data, where each training video clip depicts more than one
667

Yu, Siddharth, Barbu, & Siskind

sentence and each sentence describes more than one clip. It does so by performing both
inter- and intra-sentential inference: determining the meaning of a word cross-situationally
from the collection of training samples in which it appears and well as by spreading the
sentential meaning across the words in that sentence in a way that is consistent across a
training set.
Our method is amenable to further extension. First, due to the nature of Markov
models, each state depends only on its immediate predecessor. As discussed in Section 2.2,
this property implies that the output model can only employ features computed on single
frames or two adjacent frames. Such features may prove inadequate for larger lexicons. For
example, our models often exhibit difficulty in differentiating between picked up and put
down, since the only difference encoded is in the second-argument velocity orientation in
the second state. Our current implementation computes this orientation using optical flow
which can be noisy. One could more reliably differentiate between these two event classes if
one could encode in the model the overall displacement of the second argument, along with
the direction of that displacement, as the event proceeds: picked up involves a significant
upward displacement while put down involves a significant downward displacement While
it is not possible to encode such a multiple-frame feature in an HMM, it is possible to do
so in more complex graphical models such as conditional random fields (CRFs). One can
imagine employing CRFs as the event model, together with object detection and temporal
coherence, in a variant of the sentence tracker.
Another possible extension is employing state-duration models in the HMMs. Without explicit state-duration models, the implicit state-duration model is exponential: the
probability of staying in a state k for t frames is a(k, k)t . While such an exponential stateduration model can encode a minimum duration for an event, to filter out short-term noise
in the signal, as discussed in Section 2.2, it cannot bias an event detector towards a typical
duration for performing an event. In our experiments, this can manifest itself in difficulty in
distinguishing between picked up and put down because they have similar initial and final
states but differ only in a short transition period. Employing explicit state-duration models,
such as hidden semi-Markov models (HSMMs; Yu, 2010) as the event models within the
sentence-tracker framework could potentially improve alleviate this difficulty.
A third possible extension is to employ discriminative training instead of maximumlikelihood training. Maximum-likelihood training makes use of only positive sentential labels
on training data. Discriminative training can also make use of negative sentential labels.
This could reduce the amount of training data required and also could yield better results as
it trains the models competitively. Doing so would require a method for obtaining negative
sentence labels. One could do so with manual annotation, just as for positive sentence
labels. However, discriminative training works well when the number of negative labels far
exceeds the number of positive ones. Thus rather than manual annotation, one can imagine
some form of sentential inference to automatically generate negative sentential labels that
could not possibly be true for a video with an associated positive sentential label. This may
allow learning larger lexicons from more complex video without excessive training data.
668

Grounding Language Inference, Generation, and Acquisition in Video

8. Conclusion
We have presented a novel framework that utilizes the compositional structure of events
and the compositional structure of language to drive a semantically meaningful and targeted
approach towards event recognition. This multimodal framework integrates low-level visual
components, such as object detectors, with high-level semantic information, in the form of
sentential descriptions in natural language. Such integration is facilitated by the shared
structure of detection-based tracking, which encodes the low-level visual features, and of
the event models, in the form of HMMs, which encode the sentential semantics.
We demonstrated the utility and expressiveness of our framework by performing three
separate tasks on our video corpora, simply by leveraging our framework in different manners. The first, language inference, showcases the ability to focus the attention of a
tracker on the event described by a sentence, demonstrating the capability to correctly
identify such subtle distinctions as between The person picked up the chair to the left of
the trash can and The person picked up the chair to the right of the trash can. The second,
language generation, showcases the ability to produce a complex sentential description
of a video clip, involving multiple parts of speech, by performing an efficient search for
the best description though the space of all possible descriptions. The third, language
acquisition, showcases the ability learn a lexicon from a corpus of video clips annotated
with sentential descriptions by searching among all possible lexicons to find one that allows
the sentences to best collectively describe their associated video clips.

Acknowledgments
This research was sponsored by the Army Research Laboratory and was accomplished under
Cooperative Agreement Number W911NF-10-2-0060. The views and conclusions contained
in this document are those of the authors and should not be interpreted as representing
the official policies, either express or implied, of the Army Research Laboratory or the U.S.
Government. The U.S. Government is authorized to reproduce and distribute reprints for
Government purposes, notwithstanding any copyright notation herein.

Appendix A. Our Linking Process
We use a linking process that is mediated by a grammar and portions of the lexicon Λ. The
lexicon portion specifies the arity I and permissible roles of individual lexical entries. The
grammar used for the experiments in Section 5 is shown in Table 11(a). The portion of
the lexicon that specifies arity and permissible roles used in those experiments is shown in
Table 11(b). With this grammar and lexicon portion, the linking process to be described
below can determine that the sentence in Equation 11 has 3 participants and can produce
the linking function in Equation 12.
The linking process Θ operates by first constructing a parse tree of the sentence s
given the grammar. We do so by means of a recursive-descent parser. The lexical-category
heads in this parse tree map to words used by the sentence tracker. Nominally, the lexical
categories, e.g., noun (N), adjective (A), verb (V), adverb (Adv), and preposition (P),
serve as heads of the corresponding phrasal categories NP, AP, VP, AdvP, and PP. The
669

Yu, Siddharth, Barbu, & Siskind

(a)

S → NP VP
NP → D [A] N [PP]
D → an | the
A → blue | red
N → person | backpack | chair |trash can | traffic cone | stool | object
PP → P NP
P → to the left of | to the right of
VP → V NP [Adv] [PPM ]
V → approached | carried | picked up | put down
Adv → quickly | slowly
PPM → PM NP
PM → towards | away from

(b)

to the left of : {agent, patient, source, goal, referent}, {referent}
to the right of : {agent, patient, source, goal, referent}, {referent}
approached : {agent}, {goal}
carried : {agent}, {patient}
picked up: {agent}, {patient}
put down: {agent}, {patient}
towards: {agent, patient}, {goal}
away from: {agent, patient}, {source}
other: {agent, patient, source, goal, referent}

Table 11: (a) The grammar used for the experiments in Section 5. Terminals and nonterminals in red are used only for the experiments in Sections 5.3 and 5.4 on the first corpus.
Terminals and nonterminals in green are used only for the experiments in Section 5.5 on
the second corpus. Terminals and nonterminals in black are used for all experiments on
all corpora. The first corpus uses 19 lexical entries over 7 parts of speech (2 determiners, 2 adjectives, 5 nouns, 2 spatial-relation prepositions, 4 verbs, 2 adverbs, and 2 motion
prepositions). The second corpus uses 17 lexical entries over 6 parts of speech (1 determiner,
6 nouns, 2 spatial-relation prepositions, 4 verbs, 2 adverbs, and 2 motion prepositions). Note
that the grammar allows for infinite recursion in the noun phrase. (b) The portion of the
lexicon that specifies arity and permissible roles for the experiments in Section 5.

structure of the parse tree encodes the linking function between different words in the
form of government relations (Chomsky, 1982; Aoun & Sportiche, 1983; Haegeman, 1992;
Chomsky, 2002). This government relation can be defined formally as in Figure 19. For
example, we determine that in Figure 20, the N person governs the P to the right of but
not the N chair, and that the P to the right of governs the N chair.
The government relation, coupled with the lexicon portion, determines the number L
of participants and the linking function θ. We construct a word w for each head. The
lexicon portion specifies the arity of each lexical entry, namely the fact that person, chair,
670

Grounding Language Inference, Generation, and Acquisition in Video

•
•
•
•

The lexical categories N, A, V, Adv, and P are heads.
Parse-tree nodes α labeled with heads are governors.
A parse-tree node α dominates a parse-tree node β iff β is a subtree of α.
From X-bar theory (Jackendoff, 1977), a parse-tree node β is the maximal projection
of a parse-tree node α iff
α is labeled with a lexical category X,
β is labeled with the corresponding phrasal category XP,
β dominates α, and
no other parse-tree node γ exists where
γ is labeled with XP,
β dominates γ, and
γ dominates α.
• A parse-tree node α m-commands a parse-tree node β iff α and β do not dominate
each other and the maximal projection of α dominates β.
• A parse-tree node α c-commands a parse-tree node β iff α and β do not dominate
each other and α’s immediate parent dominates β.
• A parse-tree node α governs a parse-tree node β iff
α is a governor,
α m-commands β, and
no other parse-tree node γ exists where
γ is a governor,
γ m-commands β,
γ c-commands β, and
γ does not c-command α.
Figure 19: The government relation underlying the linking process Θ.

and backpack are unary and to the right of and picked up are binary. The sole argument
for the word associated with each head noun is filled with a distinct participant.3 The sole
argument of the word associated with each unary non-noun head α is filled with the sole
argument of the word associated with the head noun that governs α. The first argument of
the word associated with each binary non-noun head α is also filled with the sole argument
of the word associated with the head noun that governs α. The second argument of the word
associated with each binary non-noun head α is filled with the sole argument of the word
associated with the head noun that is governed by α. In the example in Figure 20, the sole
arguments of the words associated with the nouns person, chair, and backpack are assigned
the distinct participants 1, 2, and 3 respectively. The arguments of the word associated
with the preposition to the right of are assigned to participants 1 and 2, since the N person
governs the P to the right of which in turn governs the N chair. Similarly, the arguments
of the word associated with the verb picked up are assigned to participants 1 and 3, since
the N person governs the V picked up which in turn governs the N backpack.
3. This document does not concern itself with anaphora, thus we omit discussion of how to support potential
coreference. Our implementation, in fact, does support such and mediates such by analysis of the
determiners.

671

Yu, Siddharth, Barbu, & Siskind

S
VP

NP
D

the person

picked up

NP

P
to the right of

NP

V

PP

N

D

N

D

N

the backpack

the chair
Figure 20: A parse tree for the example sentence The person to the right of the chair picked
up the backpack. The highlighted portion indicates the government relations for the P to
the right of that are used to determine its arguments. The N person governs the P to the
right of, but not the N chair, and the P to the right of governs the N chair.
We further determine a consistent assignment of roles, one of agent, patient, source,
goal, and referent, to participants. The allowed roles for each argument of each word are
specified in the lexicon portion. A specification of the arity and permissible roles used for the
experiments in Section 5 is given in Table 11(b). The specification e : {r11 , . . .}, . . . , {r1Ie , . . .}
means that the arity for lexical entry e is Ie and r1i , . . . constitute the permissible roles for
argument i. Each participant is constrained to be assigned a role in the intersection of the
sets of permissible roles for each argument of each word where that participant appears.
We further constrain the role assignment to assign each role to at most one participant. For
the example sentence in Equation 11, the role assignment is computed as follows:
role(1) ∈ {agent, patient, source, goal, referent} ∩ {agent, patient} ∩ {agent}
role(2) ∈ {agent, patient, source, goal, referent} ∩ {referent}
role(3) ∈ {agent, patient, source, goal, referent} ∩ {patient}
leading to:
role(1) = agent role(2) = referent role(3) = patient

672

Grounding Language Inference, Generation, and Acquisition in Video

Appendix B. Complete Experimental Results

The backpack approached the trash can.

The chair approached the trash can.

The person to the left of the trash can put down an object.

The person to the right of the trash can put down an object.
Figure 21: Language inference: two different track collections for the same video clip produced under guidance of two different sentences. The minimal pairs of sentences correspond
to sentences 1–9 from Table 1 with the differences between the (a) and (b) variants highlighted. The track collections deemed by human judges to depict the given sentences are
indicated in green, while ones that do not are indicated in red.

673

Yu, Siddharth, Barbu, & Siskind

The person put down the trash can.

The person put down the backpack.

The person carried the red object.

The person carried the blue object.

The person picked up an object to the left of the trash can.

The person picked up an object to the right of the trash can.
Figure 21: Language-inference examples continued.
674

Grounding Language Inference, Generation, and Acquisition in Video

The person picked up an object.

The person put down an object.

The person picked up an object quickly.

The person picked up an object slowly.

The person carried an object towards the trash can.

The person carried an object away from the trash can.
Figure 21: Language-inference examples continued.
675

Yu, Siddharth, Barbu, & Siskind

The backpack approached the trash can.

The chair approached the trash can.

The red object approached the chair.

The blue object approached the chair.

The person to the left of the trash can put down an object.

The person to the right of the trash can put down an object.
Figure 21: Language-inference examples continued.
676

Grounding Language Inference, Generation, and Acquisition in Video

The person put down the trash can.

The person put down the backpack.

The person picked up an object to the left of the trash can.

The person picked up an object to the right of the trash can.

The person picked up an object to the left of the trash can.

The person picked up an object to the right of the trash can.
Figure 21: Language-inference examples continued.
677

Yu, Siddharth, Barbu, & Siskind

The person picked up an object.

The person put down an object.

The person picked up an object quickly.

The person picked up an object slowly.

The person carried an object towards the trash can.

The person carried an object away from the trash can.
Figure 21: Language-inference examples continued.
678

Grounding Language Inference, Generation, and Acquisition in Video

The backpack approached the trash can.

The chair approached the trash can.

The red object approached the chair.

The blue object approached the chair.

The person put down the chair.

The person put down the backpack.
Figure 21: Language-inference examples continued.
679

Yu, Siddharth, Barbu, & Siskind

The person carried the red object.

The person carried the blue object.

The person picked up an object to the left of the trash can.

The person picked up an object to the right of the trash can.

The person picked up an object.

The person put down an object.
Figure 21: Language-inference examples continued.
680

Grounding Language Inference, Generation, and Acquisition in Video

The person picked up an object quickly.

The person picked up an object slowly.

The person carried an object towards the trash can.

The person carried an object away from the trash can.
Figure 21: Language-inference examples continued.

681

Yu, Siddharth, Barbu, & Siskind

The backpack to the left of the chair approached the trash can.

The person to the right of the backpack carried the chair.

The person to the right of the trash can approached the trash can.

The chair to the right of the person approached the trash can.

The backpack to the left of the trash can approached the trash can.
Figure 22: Sentential descriptions generated for each of the 94 video clips in the first
corpus subject to the contraction threshold 0.90. The highest-scoring sentence for each clip
is generated, among all sentences that are generated by the grammar in Table 11(a), by
means of a beam search. The sentences deemed by human judges to describe the associated
clips are indicated in green, while ones that do not are indicated in red.

682

Grounding Language Inference, Generation, and Acquisition in Video

The chair to the left of the trash can approached the trash can.

The backpack to the right of the trash can approached the trash can.

The backpack to the right of the trash can approached the trash can.

The person to the left of the trash can put down the chair.

The backpack to the right of the person approached the trash can.

The person to the right of the chair put down the backpack.
Figure 22: Sentential-description examples continued.
683

Yu, Siddharth, Barbu, & Siskind

The chair to the left of the trash can approached the backpack.

The trash can to the right of the person approached the chair.

The person to the right of the chair put down the trash can.

The person to the right of the chair put down the trash can.

The person to the right of the chair approached the trash can.

The trash can to the right of the chair approached the chair.
Figure 22: Sentential-description examples continued.
684

Grounding Language Inference, Generation, and Acquisition in Video

The backpack to the right of the chair approached the chair.

The person to the left of the trash can picked up the chair.

The person to the right of the chair picked up the backpack.

The person to the right of the trash can picked up the backpack.

The person to the left of the chair picked up the backpack.

The trash can to the right of the person approached the chair.
Figure 22: Sentential-description examples continued.
685

Yu, Siddharth, Barbu, & Siskind

The backpack to the left of the trash can approached the trash can.

The person to the right of the chair put down the chair.

The trash can to the right of the chair approached the person.

The person to the right of the chair picked up the trash can.

The person to the left of the trash can picked up the chair.

The backpack to the right of the chair approached the trash can.
Figure 22: Sentential-description examples continued.
686

Grounding Language Inference, Generation, and Acquisition in Video

The person to the right of the chair carried the backpack.

The chair to the left of the trash can approached the trash can.

The person to the right of the chair approached the chair.

The backpack to the right of the person approached the trash can.

The person to the left of the trash can approached the trash can.

The backpack to the right of the trash can approached the trash can.
Figure 22: Sentential-description examples continued.
687

Yu, Siddharth, Barbu, & Siskind

The backpack to the left of the chair approached the chair.

The trash can to the right of the backpack approached the chair.

The trash can to the right of the chair approached the chair.

The person to the right of the trash can put down the chair.

The person to the left of the chair put down the backpack.

The chair to the right of the trash can approached the trash can.
Figure 22: Sentential-description examples continued.
688

Grounding Language Inference, Generation, and Acquisition in Video

The trash can to the left of the person approached the backpack.

The trash can to the left of the chair approached the backpack.

The person to the left of the chair put down the backpack.

The person to the left of the chair put down the backpack.

The person to the left of the chair put down the backpack.

The chair to the right of the backpack approached the trash can.
Figure 22: Sentential-description examples continued.
689

Yu, Siddharth, Barbu, & Siskind

The trash can to the left of the chair approached the backpack.

The trash can to the left of the backpack approached the backpack.

The backpack to the left of the chair approached the trash can.

The person to the right of the trash can picked up the chair.

The person to the left of the trash can picked up the trash can.

The person to the left of the trash can picked up the backpack.
Figure 22: Sentential-description examples continued.
690

Grounding Language Inference, Generation, and Acquisition in Video

The person to the right of the chair picked up the backpack.

The person to the right of the trash can put down the backpack.

The person to the left of the chair approached the chair.

The person to the right of the chair picked up the backpack.

The person to the right of the chair picked up the backpack.

The person to the right of the trash can picked up the backpack.
Figure 22: Sentential-description examples continued.
691

Yu, Siddharth, Barbu, & Siskind

The person to the left of the backpack picked up the chair.

The trash can to the right of the chair approached the chair.

The person to the right of the trash can carried the backpack.

The chair to the left of the trash can approached the trash can.

The person to the left of the backpack approached the trash can.

The chair to the left of the backpack approached the trash can.
Figure 22: Sentential-description examples continued.
692

Grounding Language Inference, Generation, and Acquisition in Video

The trash can to the right of the person approached the chair.

The backpack to the right of the trash can approached the trash can.

The backpack to the left of the chair approached the chair.

The trash can to the right of the backpack approached the chair.

The backpack to the left of the chair approached the chair.

The person to the right of the trash can put down the chair.
Figure 22: Sentential-description examples continued.
693

Yu, Siddharth, Barbu, & Siskind

The person to the left of the chair put down the backpack.

The person to the left of the trash can put down the backpack.

The person to the right of the chair put down the backpack.

The person to the right of the chair put down the chair.

The person to the right of the trash can put down the chair.

The backpack to the right of the trash can approached the chair.
Figure 22: Sentential-description examples continued.
694

Grounding Language Inference, Generation, and Acquisition in Video

The person to the left of the backpack carried the trash can.

The backpack to the right of the chair approached the chair.

The person to the right of the chair approached the trash can.

The person to the right of the chair picked up the backpack.

The person to the right of the trash can picked up the backpack.

The person to the left of the backpack picked up the backpack.
Figure 22: Sentential-description examples continued.
695

Yu, Siddharth, Barbu, & Siskind

The trash can to the right of the chair approached the person.

The person to the right of the chair put down the backpack.

The trash can to the left of the person approached the person.

The person to the right of the chair picked up the backpack.

The person to the left of the chair put down the trash can.

The person to the left of the trash can picked up the trash can.
Figure 22: Sentential-description examples continued.
696

Grounding Language Inference, Generation, and Acquisition in Video

The person to the left of the trash can picked up the backpack.

The person to the left of the trash can picked up the trash can.

The backpack to the right of the chair approached the trash can.

The person to the right of the trash can carried the backpack.

The chair to the left of the trash can approached the trash can.
Figure 22: Sentential-description examples continued.

697

Yu, Siddharth, Barbu, & Siskind

stool
traffic cone
trash can
chair
backpack
person

stool
traffic cone
trash can
chair
backpack
person

detector index
for the first argument

stool
traffic cone
trash can
chair
backpack
person

stool
traffic cone
trash can
chair
backpack
person

detector index
for the first argument

stool
traffic cone
trash can
chair
backpack
person

stool
traffic cone
trash can
chair
backpack
person

detector index
for the first argument

stool
traffic cone
trash can
chair
backpack
person

stool
traffic cone
trash can
chair
backpack
person

detector index
for the first argument

stool
traffic cone
trash can
chair
backpack
person

stool
traffic cone
trash can
chair
backpack
person

detector index
for the first argument

stool
traffic cone
trash can
chair
backpack
person

stool
traffic cone
trash can
chair
backpack
person

detector index
for the first argument

698

1.0

0
0
0
0

1.00
1.00
1.00
1.00

1.0
1.0
1.0

stool
traffic cone

trained
hand-crafted
trained
hand-crafted

1.0

0
0
0
0

1.00
1.00
1.00
1.00

trained
hand-crafted
trained
hand-crafted

1.0
1.0
1.0

trash can
chair

1.0

0
0
0
0

1.00
1.00
1.00
1.00

trained
hand-crafted
trained
hand-crafted

1.0
1.0
1.0

backpack
person

Figure 23: Comparison between hand-crafted and trained models for nouns.

Grounding Language Inference, Generation, and Acquisition in Video

to the left of
hand-crafted

to the right of
trained

1.00

hand-crafted

1.00

1.00

0

0

1.00

0

1.0

1.0

trained

0

1.0

1.0

to the right of

to the left of

to the right of

to the left of

difference between the
x-position of the first and
second arguments

to the right of

to the left of

to the right of

to the left of

difference between the
x-position of the first and
second arguments

Figure 24: Comparison between hand-crafted and trained models for spatial-relation prepositions.

699

Yu, Siddharth, Barbu, & Siskind

approached

0.05
0.01
0.01

2

4
4
0

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

leftward

leftward

leftward

leftward

leftward

upward

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

leftward

velocity orientation
for the first argument

downward

rightward

upward

downward

rightward

upward

downward

rightward

upward

downward

rightward

upward

downward

rightward

upward

downward

rightward

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

velocity magnitude
for the first argument

upward

leftward

upward

leftward

upward

leftward

near

far

near

far

near

far

near

smaller than

larger than

smaller than

larger than

smaller than

larger than

smaller than

larger than

smaller than

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

leftward

far

larger than

far

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

upward

near

smaller than

upward

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

leftward

far

downward

rightward

downward

rightward

downward

rightward

downward

rightward

downward

rightward

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

upward
rightward
downward

near

moderate distance

moderate distance

moderate distance

moderate distance

moderate distance

moderate distance

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

leftward

ratio of the size
velocity orientation distance between the first
of the first argument to
for the second argument and second arguments the size of the second argument

larger than

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

velocity magnitude
for the second argument

700

0.0

0.4
0.5
1.0

1.00
0.95
0.91
1.00
0.99
0.99

trained
0.09
hand-crafted

Figure 25: Comparison between hand-crafted and trained models for the verb approached.

Grounding Language Inference, Generation, and Acquisition in Video

carried

4

6
0

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

leftward

leftward

leftward

leftward

leftward

upward

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

leftward

velocity orientation
for the first argument

downward

rightward

upward

downward

rightward

upward

downward

rightward

upward

downward

rightward

upward

downward

rightward

upward

downward

rightward

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

velocity magnitude
for the first argument

upward

leftward

upward

leftward

upward

leftward

near

far

near

far

near

far

near

smaller than

larger than

smaller than

larger than

smaller than

larger than

smaller than

larger than

smaller than

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

leftward

far

larger than

far

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

upward

near

smaller than

upward

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

leftward

far

downward

rightward

downward

rightward

downward

rightward

downward

rightward

downward

rightward

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

upward
rightward
downward

near

moderate distance

moderate distance

moderate distance

moderate distance

moderate distance

moderate distance

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

leftward

ratio of the size
velocity orientation distance between the first
of the first argument to
for the second argument and second arguments the size of the second argument

larger than

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

velocity magnitude
for the second argument

701

0.0

0.9
1.0

0.02
0.08
0.01
0.01

1.00
0.98
0.86
1.00
0.99
0.99

trained
0.05
hand-crafted

Figure 26: Comparison between hand-crafted and trained models for the verb carried.

Yu, Siddharth, Barbu, & Siskind

picked up

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

leftward

leftward

leftward

leftward

leftward

upward

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

leftward

velocity orientation
for the first argument

downward

rightward

upward

downward

rightward

upward

downward

rightward

upward

downward

rightward

upward

downward

rightward

upward

downward

rightward

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

velocity magnitude
for the first argument

upward

leftward

upward

leftward

upward

leftward

near

far

near

far

near

far

near

smaller than

larger than

smaller than

larger than

smaller than

larger than

smaller than

larger than

smaller than

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

leftward

far

larger than

far

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

upward

near

smaller than

upward

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

leftward

far

downward

rightward

downward

rightward

downward

rightward

downward

rightward

downward

rightward

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

upward
rightward
downward

near

moderate distance

moderate distance

moderate distance

moderate distance

moderate distance

moderate distance

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

leftward

ratio of the size
velocity orientation distance between the first
of the first argument to
for the second argument and second arguments the size of the second argument

larger than

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

velocity magnitude
for the second argument

702

7

0
1

0.04
0.04
0.01
0.01

0.96
1.00
0.99

0.0

.93
.00

1.00
trained
0.96
hand-crafted
0.99

Figure 27: Comparison between hand-crafted and trained models for the verb picked up.

Grounding Language Inference, Generation, and Acquisition in Video

put down

1.0

0
1.0

0

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

leftward

leftward

leftward

leftward

leftward

upward

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

leftward

velocity orientation
for the first argument

downward

rightward

upward

downward

rightward

upward

downward

rightward

upward

downward

rightward

upward

downward

rightward

upward

downward

rightward

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

velocity magnitude
for the first argument

upward

leftward

upward

leftward

upward

leftward

near

far

near

far

near

far

near

smaller than

larger than

smaller than

larger than

smaller than

larger than

smaller than

larger than

smaller than

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

leftward

far

larger than

far

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

upward

near

smaller than

upward

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

leftward

far

downward

rightward

downward

rightward

downward

rightward

downward

rightward

downward

rightward

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

upward
rightward
downward

near

moderate distance

moderate distance

moderate distance

moderate distance

moderate distance

moderate distance

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

leftward

ratio of the size
velocity orientation distance between the first
of the first argument to
for the second argument and second arguments the size of the second argument

larger than

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

velocity magnitude
for the second argument

703

0.06
0.01
0.01
0.01

1.00
0.94
0.97
1.00
0.99
0.99

trained
0.02
hand-crafted

Figure 28: Comparison between hand-crafted and trained models for the verb put down.

Yu, Siddharth, Barbu, & Siskind

slowly

.00
1
.00
1

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

velocity magnitude
for the first argument

704

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

0
0

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

velocity magnitude
for the first argument

1.0
1.0

0.05
0.08
0.01
0.01

1.00
trained
0.95
0.92
1.00
hand-crafted
0.99
0.99

0.04
0.02
0.01
0.01

1.00
trained
0.96
0.98
1.00
hand-crafted
0.99
0.99

quickly

Figure 29: Comparison between hand-crafted and trained models for adverbs.

Grounding Language Inference, Generation, and Acquisition in Video

towards

1.0

0
1.0

0

near

far

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

near

moderate distance

far

moderate distance

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

near

near

near

far
moderate distance

far
moderate distance

far
moderate distance

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

near

near

far

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

near

moderate distance

far

moderate distance

far

moderate distance

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

near

near

far

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

near

moderate distance

far

moderate distance

far

moderate distance

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

velocity magnitude
distance between
for the first argument the first and second arguments

705

far

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

near

1
1

0.07
0.07
0.01
0.01

moderate distance

moving very quickly
moving quickly
moving slowly
mostly stationary
absolutely stationary

velocity magnitude
distance between
for the first argument the first and second arguments

.00
.00

1.00
trained
0.93
0.93
1.00
hand-crafted
0.99
0.99

×

1.00
0.01
0.01

1.00
0.94
1.00
0.99
0.99

trained
0.06
hand-crafted

away from

Figure 30: Comparison between hand-crafted and trained models for motion prepositions.

Yu, Siddharth, Barbu, & Siskind

References
Aoun, J., & Sportiche, D. (1983). On the formal theory of government. Linguistic Review,
2 (3), 211–236.
Avidan, S. (2004). Support vector tracking. IEEE Transactions on Pattern Analysis and
Machine Intelligence, 26 (8), 1064–1072.
Baker, S., Scharstein, D., Lewis, J., Roth, S., Black, M. J., & Szeliski, R. (2011). A database
and evaluation methodology for optical flow. International Journal of Computer Vision, 92 (1), 1–31.
Barbu, A., Barrett, D. P., Chen, W., Siddharth, N., Xiong, C., Corso, J. J., Fellbaum,
C. D., Hanson, C., Hanson, S. J., Hélie, S., Malaia, E., Pearlmutter, B. A., Siskind,
J. M., Talavage, T. M., & Wilbur, R. B. (2014). Seeing is worse than believing:
Reading people’s minds better than computer-vision methods recognize actions. In
Proceedings of the European Conference on Computer Vision, pp. 612–627.
Barbu, A., Bridge, A., Burchill, Z., Coroian, D., Dickinson, S., Fidler, S., Michaux, A.,
Mussman, S., Siddharth, N., Salvi, D., Schmidt, L., Shangguan, J., Siskind, J. M.,
Waggoner, J., Wang, S., Wei, J., Yin, Y., & Zhang, Z. (2012a). Video in sentences
out. In Proceedings of the Conference on Uncertainty in Artificial Intelligence, pp.
102–112.
Barbu, A., Siddharth, N., Michaux, A., & Siskind, J. M. (2012b). Simultaneous object
detection, tracking, and event recognition. Advances in Cognitive Systems, 2, 203–
220.
Barbu, A., Siddharth, N., & Siskind, J. M. (2014). Language-driven video retrieval. In
Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
Workshop on Vision Meets Cognition.
Baum, L. E. (1972). An inequality and associated maximization technique in statistical
estimation of probabilistic functions of a Markov process. Inequalities, 3, 1–8.
Baum, L. E., & Petrie, T. (1966). Statistical inference for probabilistic functions of finite
state Markov chains. The Annals of Mathematical Statistics, 37 (6), 1554–1563.
Baum, L. E., Petrie, T., Soules, G., & Weiss, N. (1970). A maximization technique occuring
in the statistical analysis of probabilistic functions of Markov chains. The Annals of
Mathematical Statistics, 41 (1), 164–171.
Bellman, R. (1957). Dynamic Programming. Princeton University Press.
Berclaz, J., Fleuret, F., Turetken, E., & Fua, P. (2011). Multiple object tracking using
K-shortest paths optimization. IEEE Transactions on Pattern Analysis and Machine
Intelligence, 33 (9), 1806–1819.
Bilmes, J. (1998). A gentle tutorial of the EM algorithm and its application to parameter
estimation for Gaussian mixture and hidden Markov models. Tech. rep. TR-97-021,
ICSI.
Blank, M., Gorelick, L., Shechtman, E., Irani, M., & Basri, R. (2005). Actions as space-time
shapes. In Proceedings of the IEEE International Conference on Computer Vision,
pp. 1395–1402.
706

Grounding Language Inference, Generation, and Acquisition in Video

Börschinger, B., Jones, B. K., & Johnson, M. (2011). Reducing grounded learning tasks
to grammatical inference. In Proceedings of the Conference on Empirical Methods in
Natural Language Processing, pp. 1416–1425.
Brand, M., Oliver, N., & Pentland, A. (1997). Coupled hidden Markov models for complex
action recognition. In Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition, pp. 994–999.
Chen, C.-Y., & Grauman, K. (2013). Watching unlabeled videos helps learn new human
actions from very few labeled snapshots. In Proceedings of the IEEE Conference on
Computer Vision and Pattern Recognition, pp. 572–579.
Chen, D. L., & Mooney, R. J. (2008). Learning to sportscast: A test of grounded language
acquisition. In Proceedings of the International Conference on Machine Learning, pp.
128–135.
Chen, D. L., & Mooney, R. J. (2011). Learning to interpret natural language navigation
instructions from observations. In Proceedings of the Conference on Artificial Intelligence, pp. 859–865.
Chomsky, N. (1982). Some Concepts and Consequences of the Theory of Government and
Binding. MIT Press.
Chomsky, N. (2002). Syntactic Structures (Second edition). Walter de Gruyter.
Das, P., Xu, C., Doell, R. F., & Corso, J. J. (2013). A thousand frames in just a few words:
Lingual description of videos through latent topics and sparse object stitching. In
Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,
pp. 2634–2641.
Dempster, A. P., Laird, N. M., & Rubin, D. B. (1977). Maximum likelihood from incomplete
data via the EM algorithm (with discussion). Journal of the Royal Statistical Society
B, 39 (1), 1–38.
Dinkelbach, W. (1967). On nonlinear fractional programming. Management Science, 13 (7),
492–498.
Dominey, P. F., & Boucher, J.-D. (2005). Learning to talk about events from narrated video
in a construction grammar framework. Artificial Intelligence, 167 (1-2), 31–61.
Everingham, M., Van Gool, L., Williams, C. K. I., Winn, J., & Zisserman, A. (2010). The
PASCAL Visual Object Classes (VOC) challenge. International Journal of Computer
Vision, 88 (2), 303–338.
Everts, I., van Gemert, J. C., & Gevers, T. (2013). Evaluation of color stips for human
action recognition. In Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition, pp. 2850–2857.
Farhadi, A., Hejrati, M., Sadeghi, M., Young, P., Rashtchian, C., Hockenmaier, J., &
Forsyth, D. (2010). Every picture tells a story: Generating sentences from images.
In Proceedings of the European Conference on Computer Vision, pp. 15–29.
Fellbaum, C. (1998). WordNet: an electronic lexical database. MIT Press.
707

Yu, Siddharth, Barbu, & Siskind

Felzenszwalb, P. F., Girshick, R. B., McAllester, D., & Ramanan, D. (2010a). Object
detection with discriminatively trained part-based models. IEEE Transactions on
Pattern Analysis and Machine Intelligence, 32 (9), 1627–1645.
Felzenszwalb, P. F., Girshick, R. B., & McAllester, D. A. (2010b). Cascade object detection
with deformable part models. In Proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition, pp. 2241–2248.
Feng, S. L., Manmatha, R., & Lavrenko, V. (2004). Multiple Bernoulli relevance models
for image and video annotation. In Proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition, pp. 1002–1009.
Fern, A. P., Givan, R. L., & Siskind, J. M. (2002a). Specific-to-general learning for temporal
events. In Proceedings of the Conference on Artificial Intelligence, pp. 152–158.
Fern, A. P., Givan, R. L., & Siskind, J. M. (2002b). Specific-to-general learning for temporal
events with application to learning event definitions from video. Journal of Artificial
Intelligence Research, 17, 379–449.
Fern, A. P., Siskind, J. M., & Givan, R. L. (2002c). Learning temporal, relational, forcedynamic event definitions from video. In Proceedings of the Conference on Artificial
Intelligence, pp. 159–166.
Fernández Tena, C., Baiget, P., Roca, X., & Gonzàlez, J. (2007). Natural language descriptions of human behavior from video sequences. In Advances in Artificial Intelligence,
pp. 279–292.
Gaidon, A., Harchaoui, Z., & Schmid, C. (2014). Activity representation with motion
hierarchies. International Journal of Computer Vision, 107 (3), 219–238.
Grimshaw, J. (1979). Complement selection and the lexicon. Linguistic Inquiry, 10 (2),
279–326.
Grimshaw, J. (1981). Form, function, and the language acquisition device. In Baker, C. L.,
& McCarthy, J. J. (Eds.), The Logical Problem of Language Acquisition, pp. 165–182.
MIT Press.
Guadarrama, S., Krishnamoorthy, N., Malkarnenkar, G., Venugopalan, S., Mooney, R., Darrell, T., & Saenko, K. (2013). Youtube2text: Recognizing and describing arbitrary
activities using semantic hierarchies and zero-shot recognition. In Proceedings of the
IEEE International Conference on Computer Vision, pp. 2712–2719.
Gupta, A., Verma, Y., & Jawahar, C. (2012). Choosing linguistics over vision to describe
images. In Proceedings of the Conference on Artificial Intelligence, pp. 606–612.
Haegeman, L. (1992). Introduction to government and binding theory. Blackwell.
Hamming, R. W. (1950). Error detecting and error correcting codes. Bell System Technical
Journal, 29 (2), 147–160.
Han, M., Sethi, A., Hua, W., & Gong, Y. (2004). A detection-based multiple object tracking
method. In Proceedings of the IEEE International Conference on Image Processing,
pp. 3065–3068.
708

Grounding Language Inference, Generation, and Acquisition in Video

Hanckmann, P., Schutte, K., & Burghouts, G. J. (2012). Automated textual descriptions for
a wide range of video events with 48 human actions. In Proceedings of the European
Conference on Computer Vision (Workshops and Demonstrations), pp. 372–380.
Ikizler-Cinbis, N., & Sclaroff, S. (2010). Object, scene and actions: Combining multiple
features for human action recognition. In Proceedings of the European Conference on
Computer Vision, pp. 494–507.
Jackendoff, R. (1977). X-bar-syntax: A study of phrase structure. MIT Press.
Jensen, J. L. W. V. (1906). Sur les fonctions convexes et les inégalités entre les valeurs
moyennes. Acta Mathematica, 30 (1), 175–193.
Jie, L., Caputo, B., & Ferrari, V. (2009). Who’s doing what: Joint modeling of names
and verbs for simultaneous face and pose annotation. In Proceedings of the Neural
Information Processing Systems Conference, pp. 1168–1176.
Khan, M. U. G., & Gotoh, Y. (2012). Describing video contents in natural language. In
Proceedings of the Workshop on Innovative Hybrid Approaches to the Processing of
Textual Data, pp. 27–35.
Khan, M. U. G., Zhang, L., & Gotoh, Y. (2011). Human focused video description. In
Proceedings of the IEEE International Conference on Computer Vision (Workshops),
pp. 1480–1487.
Kim, J., & Mooney, R. J. (2010). Generative alignment and semantic parsing for learning from ambiguous supervision. In Proceedings of the International Conference on
Computational Linguistics, pp. 543–551.
Kim, J., & Mooney, R. J. (2012). Unsupervised PCFG induction for grounded language
learning with highly ambiguous supervision. In Proceedings of the Conference on
Empirical Methods in Natural Language Processing, pp. 433–444.
Kim, J., & Mooney, R. J. (2013). Adapting discriminative reranking to grounded language
learning. In Proceedings of the Annual Meeting of the Association for Computational
Linguistics, pp. 218–227.
Klein, D., & Manning, C. D. (2003). Accurate unlexicalized parsing. In Proceedings of the
Annual Meeting of the Association for Computational Linguistics, pp. 423–430.
Kojima, A., Tamura, T., & Fukunaga, K. (2002). Natural language description of human
activities from video images based on concept hierarchy of actions. International
Journal of Computer Vision, 50 (2), 171–184.
Krishnamoorthy, N., Malkarnenkar, G., Mooney, R. J., Saenko, K., & Guadarrama, S.
(2013). Generating natural-language video descriptions using text-mined knowledge.
In Proceedings of the NAACL HLT Workshop on Vision and Language, pp. 10–19.
Krishnamurthy, J., & Kollar, T. (2013). Jointly learning to parse and perceive: Connecting
natural language to the physical world. Transactions of the Association for Computational Linguistics, 1, 193–206.
Kuehne, H., Jhuang, H., Garrote, E., Poggio, T., & Serre, T. (2011). HMDB: A large video
database for human motion recognition. In Proceedings of the IEEE International
Conference on Computer Vision, pp. 2556–2563.
709

Yu, Siddharth, Barbu, & Siskind

Kulkarni, G., Premraj, V., Dhar, S., Li, S., Choi, Y., Berg, A. C., & Berg, T. L. (2011).
Baby talk: Understanding and generating simple image descriptions. In Proceedings
of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1601–1608.
Kuznetsova, P., Ordonez, V., Berg, A. C., Berg, T. L., & Choi, Y. (2012). Collective
generation of natural image descriptions. In Proceedings of the Annual Meeting of the
Association for Computational Linguistics, pp. 359–368.
Kwiatkowski, T., Goldwater, S., Zettlemoyer, L., & Steedman, M. (2012). A probabilistic
model of syntactic and semantic acquisition from child-directed utterances and their
meanings. In Proceedings of the Conference of the European Chapter of the Association
for Computational Linguistics, pp. 234–244.
Kwiatkowski, T., Zettlemoyer, L., Goldwater, S., & Steedman, M. (2010). Inducing probabilistic CCG grammars from logical form with higher-order unification. In Proceedings
of the Conference on Empirical Methods in Natural Language Processing, pp. 1223–
1233.
Laptev, I. (2005). On space-time interest points. International Journal of Computer Vision,
64 (2/3), 107–123.
Li, P., & Ma, J. (2011). What is happening in a still picture?. In Proceedings of the Asian
Conference on Pattern Recognition, pp. 32–36.
Liu, J., Luo, J., & Shah, M. (2009). Recognizing realistic actions from videos “in the wild”.
In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,
pp. 1996–2003.
Mann, R., Jepson, A. D., & Siskind, J. M. (1996). The computational perception of scene
dynamics. In Proceedings of the European Conference on Computer Vision, pp. 528–
539.
Mann, R., Jepson, A. D., & Siskind, J. M. (1997). The computational perception of scene
dynamics. Computer Vision and Image Understanding, 65 (2), 113–128.
Marocco, D., Cangelosi, A., Fischer, K., & Belpaeme, T. (2010). Grounding action words
in the sensorimotor interaction with the world: experiments with a simulated iCub
humanoid robot. Frontiers in Neurorobotics, 4 (7), 1–15.
Messing, R., Pal, C., & Kautz, H. (2009). Activity recognition using the velocity histories of
tracked keypoints. In Proceedings of the IEEE International Conference on Computer
Vision, pp. 104–111.
Miller, G. A. (1995). WordNet: a lexical database for English. Communications of the
ACM, 38 (11), 39–41.
Mitchell, M., Dodge, J., Goyal, A., Yamaguchi, K., Stratos, K., Han, X., Mensch, A., Berg,
A. C., Berg, T. L., & III, H. D. (2012). Midge: Generating image descriptions from
computer vision detections. In Proceedings of the Conference of the European Chapter
of the Association for Computational Linguistics, pp. 747–756.
Niebles, J. C., Chen, C.-W., & Fei-Fei, L. (2010). Modeling temporal structure of decomposable motion segments for activity classification. In Proceedings of the European
Conference on Computer Vision, pp. 392–405.
710

Grounding Language Inference, Generation, and Acquisition in Video

Ordonez, V., Kulkarni, G., & Berg, T. L. (2011). Im2text: Describing images using 1 million
captioned photographs. In Proceedings of the Neural Information Processing Systems
Conference, pp. 1143–1151.
Piantadosi, S. T., Goodman, N. D., Ellis, B. A., & Tenenbaum, J. B. (2008). A Bayesian
model of the acquisition of compositional semantics. In Proceedings of the Annual
Conference of the Cognitive Science Society, pp. 1620–1625.
Pinker, S. (1984). Language Learnability and Language Development. Harvard University
Press.
Pirsiavash, H., Ramanan, D., & Fowlkes, C. C. (2011). Globally-optimal greedy algorithms
for tracking a variable number of objects. In Proceedings of the IEEE Conference on
Computer Vision and Pattern Recognition, pp. 1201–1208.
Reddy, K. K., & Shah, M. (2013). Recognizing 50 human action categories of web videos.
Machine Vision and Applications, 24 (5), 971–981.
Rodriguez, M. D., Ahmed, J., & Shah, M. (2008). Action MACH: a spatio-temporal maximum average correlation height filter for action recognition. In Proceedings of the
IEEE Conference on Computer Vision and Pattern Recognition, pp. 1–8.
Rohrbach, M., Qin, W., Titov, I., Thater, S., Pinkal, M., & Schiele, B. (2013). Translating video content to natural language descriptions. In Proceedings of the IEEE
International Conference on Computer Vision, pp. 433–440.
Roy, D. (2002). Learning visually-grounded words and syntax for a scene description task.
Computer Speech and Language, 16 (3-4), 353–385.
Roy, D. K., & Pentland, A. P. (2002). Learning words from sights and sounds: A computational model. Cognitive Science, 26 (1), 113–146.
Sadanand, S., & Corso, J. J. (2012). Action bank: A high-level representation of activity
in video. In Proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition, pp. 1234–1241.
Schuldt, C., Laptev, I., & Caputo, B. (2004a). Recognizing human actions: a local SVM
approach. In Proceedings of the International Conference on Pattern Recognition, pp.
32–36.
Schuldt, C., Laptev, I., & Caputo, B. (2004b). Recognizing human actions: A local svm
approach. In Proceedings of the International Conference on Pattern Recognition, pp.
32–36.
Siddharth, N., Barbu, A., & Siskind, J. M. (2014). Seeing what you’re told: Sentence-guided
activity recognition in video. In Proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition, pp. 732–739.
Siskind, J. M. (1996). A computational study of cross-situational techniques for learning
word-to-meaning mappings. Cognition, 61 (1-2), 39–91.
Siskind, J. M. (2001). Grounding the lexical semantics of verbs in visual perception using
force dynamics and event logic. Journal of Artificial Intelligence Research, 15, 31–90.
Siskind, J. M., & Morris, Q. (1996). A maximum-likelihood approach to visual event classification. In Proceedings of the European Conference on Computer Vision, pp. 347–360.
711

Yu, Siddharth, Barbu, & Siskind

Siskind, J. M. (1999). Visual event perception. In Proceedings of the NEC Research Symposium, pp. 91–154.
Siskind, J. M. (2000). Visual event classification via force dynamics. In Proceedings of the
Conference on Artificial Intelligence, pp. 149–155.
Siskind, J. M. (2003). Reconstructing force-dynamic models from video sequences. Artificial
Intelligence, 151 (1-2), 91–154.
Siskind, J. M., & Morris, Q. (1996). A maximum-likelihood approach to visual event classification. In Proceedings of the European Conference on Computer Vision, pp. 347–360.
Smith, K., Smith, A. D. M., & Blythe, R. A. (2011). Cross-situational learning: An experimental study of word-learning mechanisms. Cognitive Science, 35 (3), 480–498.
Smith, K., Smith, A. D. M., Blythe, R. A., & Vogt, P. (2006). Cross-situational learning: A mathematical approach. In Proceedings of the International Workshop on the
Emergence and Evolution of Linguistic Communication, pp. 31–44.
Song, H. O., Zickler, S., Althoff, T., Girshick, R., Fritz, M., Geyer, C., Felzenszwalb, P.,
& Darrell, T. (2012). Sparselet models for efficient multiclass object detection. In
Proceedings of the European Conference on Computer Vision, pp. 802–815.
Song, Y., Morency, L.-P., & Davis, R. (2013). Action recognition by hierarchical sequence
summarization. In Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition, pp. 3562–3569.
Starner, T., Weaver, J., & Pentland, A. (1998). Real-time American Sign Language recognition using desk and wearable computer based video. IEEE Transactions on Pattern
Analysis and Machine Intelligence, 20 (12), 1371–1375.
Tellex, S., Thaker, P., Joseph, J., & Roy, N. (2013). Learning perceptually grounded word
meanings from unaligned parallel data. Machine Learning, 0, 1–17.
Thompson, C. A., & Mooney, R. J. (2003). Acquiring word-meaning mappings for natural
language interfaces. Journal of Artificial Intelligence Research, 18, 1–44.
Tian, Y., Sukthankar, R., & Shah, M. (2013a). Spatiotemporal deformable part models for
action detection. In Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition, pp. 2642–2649.
Tian, Y., Sukthankar, R., & Shah, M. (2013b). Spatiotemporal deformable part models for
action detection. In Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition, pp. 2642–2649.
Viterbi, A. J. (1967). Error bounds for convolutional codes and an asymtotically optimum
decoding algorithm. IEEE Transactions on Information Theory, 13 (2), 260–267.
Wang, H., Kläser, A., Schmid, C., & Liu, C.-L. (2011). Action recognition by dense trajectories. In Proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition, pp. 3169–3176.
Wang, H., Kläser, A., Schmid, C., & Liu, C.-L. (2013). Dense trajectories and motion
boundary descriptors for action recognition. International Journal of Computer Vision, 103 (1), 60–79.
712

Grounding Language Inference, Generation, and Acquisition in Video

Wang, H., & Schmid, C. (2013). Action recognition with improved trajectories. In Proceedings of the IEEE International Conference on Computer Vision, pp. 3551–3558.
Wang, Z., Guan, G., Qiu, Y., Zhuo, L., & Feng, D. (2013). Semantic context based refinement for news video annotation. Multimedia Tools and Applications, 67 (3), 607–627.
Werlberger, M., Pock, T., & Bischof, H. (2010). Motion estimation with non-local total
variation regularization. In Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition, pp. 2464–2471.
Wolf, J. K., Viterbi, A. M., & Dixon, G. S. (1989). Finding the best set of K paths through
a trellis with application to multitarget tracking. IEEE Transactions on Aerospace
and Electronic Systems, 25 (2), 287–296.
Wu, B., & Nevatia, R. (2007). Detection and tracking of multiple, partially occluded humans
by Bayesian combination of edgelet based part detectors. International Journal of
Computer Vision, 75 (2), 247–266.
Yamoto, J., Ohya, J., & Ishii, K. (1992). Recognizing human action in time-sequential images using hidden Markov model. In Proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition, pp. 379–385.
Yang, Y., Teo, C. L., Daumé III, H., & Aloimonos, Y. (2011). Corpus-guided sentence
generation of natural images. In Proceedings of the Conference on Empirical Methods
in Natural Language Processing, pp. 444–454.
Yao, B. Z., Yang, X., Lin, L., Lee, M. W., & Zhu, S.-C. (2010). I2T: Image parsing to text
description. Proceedings of the IEEE, 98 (8), 1485–1508.
Yilmaz, A., Javed, O., & Shah, M. (2006). Object tracking: A survey. ACM Computing
Surveys, 38 (4), 1–45.
Yu, C., & Ballard, D. H. (2004). On the integration of grounding language and learning
objects. In Proceedings of the Conference on Artificial Intelligence, pp. 488–493.
Yu, H., & Siskind, J. M. (2013). Grounded language learning from video described with
sentences. In Proceedings of the Annual Meeting of the Association for Computational
Linguistics, pp. 53–63.
Yu, S.-Z. (2010). Hidden semi-Markov models. Artificial Intelligence, 174 (2), 215–243.
Yuan, C., Li, X., Hu, W., Ling, H., & Maybank, S. (2013). 3D R transform on spatiotemporal interest points for action recognition. In Proceedings of the IEEE Conference
on Computer Vision and Pattern Recognition, pp. 724–730.
Zettlemoyer, L. S., & Collins, M. (2005). Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars. In Proceedings of the Conference on Uncertainty in Artificial Intelligence, pp. 658–666.
Zhong, S., & Ghosh, J. (2001). A new formulation of coupled hidden Markov models. Tech.
rep., Department of Electrical and Computer Engineering, The University of Texas
at Austin.
Zhu, J., Wang, B., Yang, X., Zhang, W., & Tu, Z. (2013). Action recognition with Actons.
In Proceedings of the IEEE International Conference on Computer Vision, pp. 3559–
3566.
713

Journal of Articial Intelligence Research 52 (2015) 235-286

Submitted 10/14; published 02/15

Lazy Model Expansion:
Interleaving Grounding with Search

broes.decat@gmail.com

Broes De Cat

OM Partners, Belgium

Marc.Denecker@cs.kuleuven.be

Marc Denecker

Dept. Computer Science, KULeuven, Belgium

pstuckey@unimelb.edu.au

Peter Stuckey

National ICT Australia and
Dept. of Computing and Information Systems
The University of Melbourne, Australia

Maurice Bruynooghe

Dept. Computer Science, KULeuven, Belgium

Maurice.Bruynooghe@cs.kuleuven.be

Abstract

Finding satisfying assignments for the variables involved in a set of constraints can be
cast as a (bounded) model generation problem: search for (bounded) models of a theory
in some logic. The state-of-the-art approach for bounded model generation for rich knowledge representation languages like Answer Set Programming (ASP) and FO(·) and a CSP
modeling language such as Zinc, is ground-and-solve : reduce the theory to a ground or
propositional one and apply a search algorithm to the resulting theory.
An important bottleneck is the blow-up of the size of the theory caused by the grounding
phase. Lazily grounding the theory during search is a way to overcome this bottleneck.
We present a theoretical framework and an implementation in the context of the FO(·)
knowledge representation language. Instead of grounding all parts of a theory, justications
are derived for some parts of it. Given a partial assignment for the grounded part of the
theory and valid justications for the formulas of the non-grounded part, the justications
provide a recipe to construct a complete assignment that satises the non-grounded part.
When a justication for a particular formula becomes invalid during search, a new one is
derived; if that fails, the formula is split in a part to be grounded and a part that can be
justied. Experimental results illustrate the power and generality of this approach.

1. Introduction
The world is lled with combinatorial problems.

These include important combinatorial

optimization tasks such as planning, scheduling and rostering, combinatorics problems such
as extremal graph theory, and countless puzzles and games. Solving combinatorial problems
is hard, and all the methods we know to tackle them involve some kind of search.
Various

declarative paradigms

have been developed to solve such problems.

In such

approaches, objects and attributes that are searched for are represented by symbols, and
constraints to be satised by those objects are represented as expressions over these symbols

c 2015 AI Access Foundation. All rights reserved.


De Cat, Denecker, Stuckey & Bruynooghe
in a declarative language. Solvers then search for values for these symbols that satisfy the
constraints. This idea is found in the elds of Constraint Programming (CP) (Apt, 2003),
ASP (Marek & Truszczy«ski, 1999), SAT, Mixed Integer Programming (MIP), etc. In the
terminology of logic, the declarative method amounts to expressing the desired properties of

logical theory. The data of a particular problem instance
partial interpretation (or structure). The solving process is to
apply model generation, or more specically model expansion (Mitchell & Ternovska, 2005),
a problem class by sentences in a

corresponds naturally to a

the task of nding a structure that expands the input partial structure and satises the
theory. The resulting structure is a solution to the problem. Model generation/expansion,
studied for example in the eld of Knowledge Representation (KR) (Baral, 2003), is thus
analogous to the task of solving constraint satisfaction problems, studied in CP, and that
of generating answer sets of logic programs, studied in ASP.
The similarities between these areas go deeper and extend to the level of the used techniques.

State-of-the-art approaches often follow a two-phase solving methodology.

In a

rst phase, the input theory, in the rich language at hand, is reduced into a fragment of
the language that is supported by some search algorithm. In the second phase, the search
algorithm is applied to the reduced theory to eectively search for models. For example,
model generation for the language MiniZinc (Nethercote et al., 2007) is performed by reducing to the ground language FlatZinc, for which search algorithms are available. Similarly,
the language

PC(·)

FO(·)

(Denecker & Ternovska, 2008) is reduced to its propositional fragment

(see, e.g., Wittocx, Mariën, & Denecker, 2010), and ASP is reduced to propositional

ASP (see, e.g., Gebser, Schaub, & Thiele, 2007). As the reduced theory is often in a ground
fragment of the language, we refer to the resulting reduced theory as the
the rst phase as the

grounding

grounding

and to

phase (where quantiers are instantiated with elements in

the domain). In other elds, grounding is also referred to as attening, unrolling, splitting
or propositionalization. The solving methodology itself is generally referred to as

and-solve.

ground-

Grounding becomes a bottleneck as users turn to applications with large domains and
complex constraints. Indeed, it is easy to see that the grounding size of an FO formula is
exponential in the nesting depth of quantiers and in the arity of predicates and polynomial
in the size of the universe of discourse.

There is an increasing number of applications

where the size of the grounded theory is so large that it does not t in memory.

For

example, Son, Pontelli, and Le (2014) discuss several ASP applications where the groundand-solve approach turns out to be inadequate.
In this paper, we present a novel approach to remedy this bottleneck, called

lazy model

expansion, where the grounding is generated lazily (on-the-y) during search, instead of upfront. The approach works by associating justications to the non-ground parts of the theory.
A valid justication for a non-ground formula is a recipe to expand a partial structure into
a more precise (partial) structure that satises the formula. Of course, it is crucial that the
recipe is a lot more compact than the grounding of the formula. Given a partial structure
and a valid justication for each of the non-ground formulas, a (total) structure is obtained
by extending the partial structure with the literals in the justications of the non-ground
formulas. Justications are selected in such a way that this total structure is a model for
the whole initial theory.

Consequently, model generation can be limited to the grounded

part of the theory; if a model is found for that part, it can be extended to a model of the

236

Lazy Model Expansion: Interleaving Grounding with Search
whole theory. However, a new assignment during model generation can conict with one of
the justications. In that case, an alternative justication needs to be sought. If none is
found, the associated formula can be split in two parts, one part that is grounded and one
part for which a valid justication is still available.

Example 1.1.

Consider the

Sokoban

problem, a planning problem where a robot has to

push blocks around on a 2-D grid to arrange them in a given goal conguration. A constraint
on the move action is that the target position
(at time

t ∈ T)

p∈P

of the moved block

b∈B

is currently

empty, which can be expressed as

∀(t, b, p) ∈ T × B × P : move(b, p, t) ⇒ empty(p, t).

(1)

As it is not known in advance how many time steps are needed, one ideally wants to assume
a very large or even innite number of steps. Using ground-and-solve, this blows up the size
of the grounding. Incremental grounding, iteratively extending the time domain until it is
large enough to allow for a plan, has been developed to avoid the blow-up in the context of
planning (Gebser et al., 2008). Our approach is more general and does not depend on the
presence of one domain that can be incrementally increased.
Returning to the example, instead of grounding sentence (1), we associate with it a
justication, a recipe to satisfy it.

Make

move(b, p, t)

false for all

b, p

and

t

is such a

recipe. When the search nds a model for the grounded part of the problem that is not in
conict with the recipe, the model can be extended with the literals in the recipe to obtain a
model of the whole theory. However, if the search would decide to move block

p1

b1

to position

at time t1 , a conict is created with the recipe. To resolve it, the instance of sentence (1)

that is in conict with the partial model of the search is split o and sentence (1) is replaced
by the equivalent sentences:

move(b1 , p1 , t1 ) ⇒ empty(p1 , t1 )

(2)

∀(t, b, p) ∈ T × B × P \(t1 , b1 , p1 ) : move(b, p, t) ⇒ empty(p, t)

(3)

Sentence (2) is grounded and passed to the search component which will use it to check
that

empty(p1 , t1 )

holds.

Sentence (3) is non-ground and can be satised by the recipe

 move(b, p, t) is false except for

move(b1 , p1 , t1 ).

When the search makes more moves, more

instances will be grounded, until the search nds a partial plan for the problem at hand.
Then the literals in the recipe of the remaining non-ground formula making

move(b, p, t)

false for all instances of sentence (1) that have not been grounded will complete the plan.
The main contributions of this paper are:

•

A theoretical framework for

lazy model expansion.

By aiming at minimally instantiat-

ing quantied variables, it paves the way for a solution to the long-standing problem of
handling quantiers in search problems, encountered, e.g., in the elds of ASP (Lefèvre
& Nicolas, 2009) and SAT Modulo Theories (Ge & de Moura, 2009). The framework
also generalizes existing approaches that are related to the grounding bottleneck such
as incremental domain extension (Claessen & Sörensson, 2003) and lazy clause generation (Ohrimenko, Stuckey, & Codish, 2009).

237

De Cat, Denecker, Stuckey & Bruynooghe
•

A complete algorithm for lazy model expansion for the logic

FO(ID ),

the extension of

rst-order logic (FO) with inductive denitions (a language closely related to ASP as
shown in Denecker et al., 2012). This includes ecient algorithms to derive consistent
sets of justications and to maintain them throughout changes in a partial structure
(e.g., during search).

•

IDP

An implementation extending the

knowledge-base system (De Cat et al., 2014)

and experiments that illustrate the power and generality of lazy grounding.
Lazy grounding is a new step in our ability to solve complex combinatorial problems. By
avoiding the up-front grounding step of previous approaches, lazy grounding can ground
enough of the problem to solve it. While our method is developed for the logic

FO(ID ),

as

will become clear, justications are associated with rules, and these rules are very similar
to the rules used by ASP systems. Hence, as discussed towards the end of the paper, our
framework and algorithms can be applied also in the context of ASP.
The paper is organized as follows.

In Section 2, the necessary background and nota-

tions are introduced. Formal denitions of lazy grounding with

FO(ID )

are presented in

Section 3, followed by a presentation of the relevant algorithms and heuristics in Sections 4
and 5. Experimental evaluation is provided in Section 6, followed by a discussion on related
and future work and a conclusion. A preliminary version of the paper appeared as the work
of De Cat, Denecker, and Stuckey (2012) and of De Cat (2014, ch. 7).

2. Preliminaries
In this section, we provide the necessary background on the logic
tasks model generation and model expansion for

FO(ID )

FO(ID ),

on the inference

and on the ground-and-solve

approach to model expansion.

2.1

FO(ID )

First, we dene syntax and semantics of the logic

FO(ID )

(Denecker & Ternovska, 2008),

the extension of rst-order logic (FO) with inductive denitions. We assume familiarity with
FO. Without loss of generality, we limit

FO(ID )

to the function-free fragment. Function

symbols can always be eliminated using graph predicates (Enderton, 2001).
A (function-free) vocabulary

Σ

consists of a set of predicate symbols.

Propositional

> and ⊥, denoting true and
false respectively. Predicate symbols are usually denoted by P , Q, R; atoms by a, literals
(atoms or their negation) by l; variables by x, y ; and domain elements by d. With ē we
denote an ordered set of objects e1 , . . . , en ; with P/n a predicate P of arity n.

symbols are 0-ary predicate symbols; these include the symbols

The methods for model generating developed below require that a (possibly innite)
domain

D

Σ, a domain atom is an

P d with P/n ∈ Σ and d ∈ Dn , an n-tuple of domain elements. Likewise,

is given and xed. Given a (function-free) vocabulary

atom of the form
we consider

domain literals.

Σ consists of the domain D and an n-ary relation P I ⊆ Dn
for all predicate symbols P/n ∈ Σ. Alternatively, an n-ary relation can be viewed as a
n
function D → {t, f }. The propositional symbols > and ⊥ are respectively interpreted as t
and f .
A structure

I

interpreting

238

Lazy Model Expansion: Interleaving Grounding with Search
Model generation algorithms maintain
themselves in an

inconsistent

partial

structures and may (temporarily) nd

state, for example when a conict arises. To represent such

I are introduced; they consist of the domain
n-ary predicate P in Σ, of a three- or four-valued relation P I . This is a
n
function D → {t, f , u, i}. A structure is two-valued if the range of its relations is {t, f },
partial or three-valued if the range is {t, f , u}) and four-valued in general. Thus, two-valued
states, three-valued and four-valued structures

D

and, for each

structures are also three-valued and four-valued.

When unqualied, the term

structure

stands for the most general, four-valued case.
Given a xed

D

and

Σ, an alternative way to represent I

domain

aI

=t

D

if only

a

=f

if only

S

and

a, aI = i (inconsistent) if
¬a is in S and aI = u (unknown)

such that for a domain atom

I
is in S , a

S of domain literals.
Σ-structures I with
both a and ¬a are in S ,

is as a set

Indeed, there is a one-to-one correspondence between such sets

otherwise. Hence,

we may treat four-valued structures as sets of domain literals and vice versa. A structure is

inconsistent if at least one domain atom is inconsistent.

I of a vocabulary Σ can be naturally viewed as a structure of a larger
⊃ Σ, namely by setting aI = u for any domain atom of a predicate in Σ0 \ Σ.
For a set σ of predicate symbols, we use I|σ to denote the restriction of I to the symbols
I|
I
of σ . For a set S of domain atoms, we use I|S to denote the restriction of I to S : a S = a
I|
if a ∈ S and a S = u otherwise. We call I a two-valued structure of S if I is two-valued
on domain atoms of S and unknown otherwise.
−1 of a truth value v is dened as follows: t−1 = f , f −1 = t, u−1 = u and
The inverse v
−1
i = i. The truth order >t on truth values is dened by t >t u >t f and t >t i >t f . The
precision order >p is dened by i >p t >p u and i >p f >p u. Both orders are pointwise
0
extended to arbitrary Σ-structures. We say that I ' is an expansion of I if I ≥p I , that
0
I
I
is if for each domain atom a, a
≥p a . Viewing structures as sets of domain literals, this
0
corresponds to I ⊇ I .
A structure

0
vocabulary Σ

We assume familiarity with the syntax of (function-free) FO. To facilitate the reasoning
with partially grounded formulas, we deviate from standard FO and quantify over explicitly

∃x ∈ D0 : ϕ and ∀x ∈ D0 : ϕ, with
⊆ D. We sometimes abbreviate ∃x1 ∈ D1 : . . . ∃xn ∈ Dn : ϕ as ∃x ∈ D : ϕ, and similarly
for ∀. Given a formula ϕ, ϕ[x] indicates that x are the free variables of ϕ. Substitution of a
variable x in formula ϕ by a term t is denoted by ϕ[x/t]. A ground formula (in domain D )
specied subsets of the domain

D.

This is denoted as

D0

is a formula without variables (hence without quantiers). Similar properties and notations
are used for

rules

(introduced below).

voc(T ) the set of all predicate symbols that occur in theory T . For
a structure I , voc(I) is the set of symbols interpreted by I . Unless specied otherwise,
theories and structures range over the vocabulary Σ.
The language FO(ID ) extends FO with (inductive) denitions. A theory in FO(ID )
is a (nite) set of sentences and denitions. A denition ∆ is a (nite) set of rules of the
form ∀x ∈ D : P (x1 , . . . , xn ) ← ϕ, with P a predicate symbol and ϕ an FO formula. The
atom P (x) is referred to as the head of the rule and ϕ as the body. Given a rule r , we let
head (r) and body(r) denote respectively the head and the body of r. Given a denition ∆,
a domain atom P d is dened by ∆ if there exists a rule ∀x ∈ D : P (x) ← ϕ in ∆ such



that d ∈ D . Otherwise P d is open in ∆. A domain literal ¬P d is dened by ∆ if P d
We denote by

239

De Cat, Denecker, Stuckey & Bruynooghe
∆. The sets of dened and open domain atoms of ∆ are denoted as defined (∆)
open(∆), respectively.

is dened by
and

Without loss of generality, we assume that in any denition a domain atom is dened
by at most one rule. Technically, this means that rules

P (x) ← ϕ2

∀x ∈ D1 : P (x) ← ϕ1 , ∀x ∈ D2 :

D1 ∩ D2 = ∅. Rules can always be made disjunct
∀x ∈ D1 ∩ D2 : P (x) ← ϕ1 ∨ ϕ2 , ∀x ∈ D1 \ D2 : P (x) ← ϕ1 ,

are pairwise disjunct, that is

by transforming them in

∀x ∈ D2 \ D1 : P (x) ← ϕ2 .
2.1.1 Model Semantics
The semantics of

FO(ID )

is a two-valued model semantics.

Nevertheless, we introduce

concepts of three- and four-valued semantics which are useful in dening the semantics
of denitions and in formalizing lazy grounding.

We use the standard four-valued truth

assignment function, dened by structural induction for pairs of FO domain formulas

ϕ and

I that interpret ϕ:
I
I
• P d = P I (d ),

structures

• (ψ ∧ φ)I = min<t (ψ I , φI ),
• (ψ ∨ φ)I = max<t (ψ I , φI ),
• (¬ψ)I = (ψ I )−1 ,
• (∃x ∈ D : ψ)I = max<t ({ψ[x/d]I | d ∈ D}),
• (∀x ∈ D : ψ)I = min<t ({ψ[x/d]I | d ∈ D}).
The assignment function is monotonic in the precision order: if

I ≤p I 0 ,

then

ϕI ≤p ϕI

0

.

Hence, if a formula is true in a partial structure, it is true in all two-valued expansions of
it.

Also, if

I

is two-valued (respectively three-valued, four-valued) then

ϕI

is two-valued

I

is two-valued

(respectively three-valued, four-valued).
A structure
and

ϕI = t.

I

is a

model

of /

satises

a sentence

ϕ

(notation

I |= ϕ)

if

The satisfaction relation can be dened for denitions as well. The semantics

of denitions is based on the parametrized well-founded semantics, an extension of the wellfounded semantics of logic programs informally described rst in the work of Van Gelder
(1993), and formally dened for

FO(ID )'s

denitions by Denecker (2000). This semantics

formalizes the informal semantics of rule sets as (inductive) denitions (Denecker, 1998;
A structure I is
∆ (notation I |= ∆) if I is two-valued and is the wellfounded model denoted as wf∆ ( I|open(∆) ) of ∆ in the structure I|open(∆) (Denecker
& Ternovska, 2008). In case wf∆ ( I|open(∆) ) is not two-valued, ∆ has no model expanding
I|open(∆) . A structure I satises a theory T if I is two-valued and I is a model of all
sentences and denitions in T . In the next subsection, we present a formalization of the
Denecker, Bruynooghe, & Marek, 2001; Denecker & Vennekens, 2014).
a

model

of /

satises

a denition

well-founded semantics using the notion of
According to

FO(ID )'s

justication.

methodology, (formal) denitions are used to express informal

denitions. In the work of Denecker and Vennekens (2014), it was shown that

FO(ID )

de-

nitions oer a uniform representation of the most important types of informal denitions and

240

Lazy Model Expansion: Interleaving Grounding with Search
that expressing informal denitions leads to rule sets that are

∆

is called

total

if the well-founded model of

∆

is two-valued (Denecker & Ternovska, 2008).

total.

Formally, a denition

in each two-valued structure

I

open(∆)

of

In general, totality is undecidable; however

broad, syntactically dened classes of denitions have been proven to be total (e.g., nonrecursive, positive, stratied and locally stratied denitions, see Denecker & Ternovska,
2008). Inspection of current

FO(ID )

applications shows that in practice, non-total deni-

tions occur rarely and almost always contain a modeling error. Also, in most cases totality
can be established through a simple syntactic check.

Totality can be usefully exploited

during computation. The lazy grounding techniques introduced below exploit totality and
should be applied only to total denitions. This restriction matches with

FO(ID )'s

and methodology and, in practice, this does not impose a strong limitation.

design

In case the

input theory does contain denitions that are not known to be total, all is not lost: those
denitions can be grounded completely up-front, in which case lazy grounding can be applied
safely to the remaining sentences and total denitions in the input.

Equivalence.
equivalent

Two theories

T

and

T 0,

which can be over dierent vocabularies, are

Σ-

0
can be expanded to a model of T and vice

T restricted to Σ
T 0 are strongly Σ-equivalent if the above expansions are also
unique. By extension, (strong) Σ-equivalence in a structure I is dened similarly: if each
0
model of T expanding I can be expanded to a model of T expanding I and vice versa; to
obtain strong equivalence, these expansions have to be unique. From a theory T , we often
0
derive a strongly voc(T )-equivalent theory T in a given structure I . Such transformations
0
preserve satisability and number of models and each model of T can be directly mapped
to a model of T by projection on voc(T ).
versa.

if each model of

Two theories

T

Canonical theories.

and

To simplify the presentation, the lazy grounding techniques are

presented here for theories of the form

{PT , ∆},

a single denition with function-free rules.

with

PT

a propositional symbol, and

This is without loss of generality.

∆

First, as

mentioned above, standard techniques (Enderton, 2001) allow one to make a theory functionfree. Second, multiple denitions can always be combined into one as described by Denecker
and Ternovska (2008) and Mariën, Gilis, and Denecker (2004). This is achieved by renaming
dened predicates in some of the denitions, merging all rules into one set and adding
equivalence constraints between predicates and their renamings.

{ϕ1 , . . . , ϕn , ∆}

equivalent theory

{PT , ∆ ∪ {PT ← ϕ1 ∧ · · · ∧ ϕn }}

with

PT

T =
voc(T )-

Third, the theory

resulting from the previous step can be translated to the strongly

a new propositional symbol.

This transformation results in a ground set of sentences and a denition consisting of a
set of (ground and non-ground) rules, so lazy grounding has only to cope with non-ground
rules. Furthermore, we assume that rule bodies are in negation normal form (negation only
occurs in front of atoms) and that, for each dened domain atom
rule

∀x ∈ D : P (x) ← ϕ ∈ ∆

such that

d∈D


P d ,

there is a unique

.

The methods proposed below can be extended to full

FO(ID )

with functions, and such

extended methods have been implemented in our system. However, this introduces a number
of rather irrelevant technicalities which we want to avoid here.

241

De Cat, Denecker, Stuckey & Bruynooghe
2.1.2 Justifications

D and a canonical theory T = {ϕ, ∆} as explained
D correspond one-to-one to sets of domain literals.

Denition 2.1 (Direct
justication). A direct justication for a dened domain literal P d

(respectively ¬P d ) is a consistent non-empty set S of domain literals such that, for the
S
rule ∀x ∈ D : P (x) ← ϕ of ∆ such that d ∈ D , it holds that ϕ[x/d] = t (respectively
S
ϕ[x/d] = f ).

0
Any consistent superset S of a direct justication S of P d is a direct justication
0
as well. Indeed, a body ϕ[x/d] true in S is true in the more precise S . Also, a direct
justication S is not empty by denition; if ϕ is true in every structure, then a minimal
direct justication is {>}.

We assume the presence of a domain

above. Recall, structures with domain

Example 2.2.

Consider a domain



A direct justication for

D = {d1 , . . . , dn }

and the denition

∀x ∈ D : P (x) ← Q(x) ∨ R(x)
∀x ∈ D : Q(x) ← P (x)

Q(di )

is

{P (di )}

and for

¬Q(di )

is

∆



{¬P (di )}.

Both domain literals

have many other direct justications, but those are the unique minimal ones under the

P (di ) are both {Q(di )} and {R(di )} while
¬P (di ) is {¬Q(di ), ¬R(di )}. Atoms R(di ) are open

subset relation. Minimal direct justications for
the only minimal direct justication for
and have no direct justication.

G is a pair hV, Ei of a set V of nodes and a set E of directed
(vi , vj ) of nodes. For any node v ∈ V , we denote by G(v) the
G(v) = {w | (v, w) ∈ E}.

A (directed) graph
i.e., ordered pairs
children of

v,

i.e.,

Denition 2.3 (Justication).
of domain literals of

∆

A

justication

over a denition

such that for each domain literal

l, J(l)

∆

is a graph

J

edges,
set of

over the set

is either empty or a direct

justication of l.
Thus, a justication is a graph that encodes for every dened domain literal none or one
direct justication. In the sequel we say that
denoted as a set of pairs

l → S,

with

S

J

is

dened in l

if

J(l) 6= ∅.

A justication is

a direct justication of l.

Denition 2.4 (Justication subgraph).

Let

J

be a justication over

∆.

The justication

for a literal l is the subgraph Jl of nodes and edges of J reachable from l. The justication
for a set of literals L is the subgraph JL of nodes and edges of J reachable from any l ∈ L.
A justication J over ∆ is total for l if J is dened in each literal that is reachable from
l and dened in ∆; it is total for a set of literals L if it is total for each literal in L. A
justication J is consistent with a structure I if I is consistent and none of the literals for
which
If

J
J

is dened is false in

I.

is total for l, then the leaves of

Jl

are open domain literals.

242

Lazy Model Expansion: Interleaving Grounding with Search
Denition 2.5.
li → li+1 ,

positive literals; it is

cycle

J

A path in a justication

is a sequence

then there is an edge from li to li+1 in

negative

in a justication

J

J.

l0 → l1 → . . .

A path is

positive

if it consists of only negative literals; it is

is a set of domain literals on a path in

J

such that, if

if it consists of only

mixed

otherwise. A

that starts and ends in

the same domain literal. A cycle is positive (respectively, negative) if all domain literals are
positive literals (respectively, negative literals); otherwise the cycle is mixed.
An innite path may be cyclic or not. If
Intuitively, a justication
truth of

l.

J

D

is nite, every innite path is cyclic.

containing a domain literal

l

provides an argument for the

The strength of this argument depends on the truth of the leaves and on the

innite paths and cycles in
provides the argument that

Jl .
l is

If all leaves are true and every innite path is negative,
true. If a leaf is false or unknown, or

or mixed loop, the argument for

l

Jl

Jl

contains a positive

is weak. Notice that other justications for

l

may still

argue l's truth.

Denition 2.6 (Justies).

l is well-founded in the justication
J if every innite path in Jl is negative. Otherwise l is unfounded in J .
A justication J over ∆ justies a set of literals L dened in ∆ (the set L of literals has
a justication J ) if (i) JL is total for L; (ii) each literal of L is well-founded in J ; (iii) the
set of literals in JL is consistent.

P (d)

Q(d)

We say that a dened literal

P (d)

R(d)

P (d)

Q(d)

¬P (d)

¬Q(d)

¬R(d)

Q(d)
(i)

(ii)

(iii)

Figure 1: Justications for denition

Example 2.7.

∆

P (d)

d ∈ D.

in Example 2.2 that contain the dened domain atoms

Justication (ii) justies

(iii), however, is not total for
for both

in Example 2.2, with

In Figure 1, we show a few possible justications (ordered (i)-(iv) from left

to right) over denition

Q(d) (d ∈ D).

∆

(iv)

and

P (d)

nor

P (d)
Q(d)

and

Q(d)

and (iv) justies

¬P (d)

P (d) and
¬Q(d);

and

and (i) has a positive cycle and is unfounded

Q(d).

The relationship between justications and the well-founded semantics has been investigated in dierent publications (Denecker & De Schreye, 1993, 1992; Mariën, 2009). Below
we recall the results on which this paper relies. The rst result states that if
literals in
in

L

L, then
JL .

any model

I

of

∆

in which the leaves of

JL

J

justies all

are true, satises all literals

and in

Proposition 2.8. If J is a justication over ∆ that justies a set of domain literals L then
all literals in JL are true in every model of ∆ in which the (open) leaves of JL are true.
243

De Cat, Denecker, Stuckey & Bruynooghe
For an interpretation Iopen that is two-valued for open(∆), the well-founded model
wf∆ (Iopen ) can be computed in time polynomial in the size of the domain, as shown by Chen
and Warren (1996). In general, wf∆ (Iopen ) is a three-valued structure. If wf∆ (Iopen ) is twovalued, then it is the unique model of ∆ that expands Iopen ; otherwise, ∆ has no model that
expands Iopen . The above proposition follows from the fact that if a justication J justies
L and all leaves of J are true in Iopen , then all literals of L are true in wf∆ (Iopen ).

Example 2.9

.

if

R(d)

is true in

in which

R(d)

Justication (ii) justies L = {Q(d)} and
Iopen interpreting the open predicates of ∆,
wf∆ (Iopen ). In particular, in any model of ∆

(Continued from Example 2.7)

has a unique open leaf
is

R(d).

For any structure

Iopen , then Q(d) is
true, Q(d) is true.

true in

Proposition 2.10. If I is a model of ∆, then a justication J over ∆ exists that consists
of literals true in I , is dened for all dened domain literals true in I and justies each of
them.

Corollary 2.11. In case

∆ is total, if a justication J over ∆ justies a set of domain
literals L, then every two-valued open(∆)-structure consistent with JL can be extended in a
unique way to a model of ∆ that satises all literals of L.
{PT , ∆}
justies PT .

Hence, for a canonical theory
justication

J

exists that

(recall,

∆

is total), the theory is satisable i a

2.2 Generating Models
Model generation
a model of

T.

is the inference task that takes as input a theory

T

and returns as output

Model Expansion (MX) was dened by Mitchell et al. (2006) as the inference

task that takes as input a theory
subvocabulary of

Σ,

T

over vocabulary

and returns an expansion

M

of

Σ
I

I

and a two-valued structure
that satises

T.

over a

Here, it will be the

more general inference problem as dened by Wittocx, Mariën, and Denecker (2008) that
takes as input a (potentially partial) structure
that satises

I

over

Σ,

and returns an expansion

M

of

I

T.

As already mentioned, the state-of-the-art approach to model expansion in
is (similar to ASP) grounding

T

in the context of

I

FO(ID )

and afterwards applying search to

the resulting ground theory. The latter can, e.g., be accomplished by the SAT(ID) search
algorithm (Mariën et al., 2008).
Below, we present the grounding algorithm that is the basis of the lazy MX algorithm.
We assume familiarity with the basic Conict-Driven Clause-Learning (CDCL) algorithm of
SAT solvers (Marques Silva, Lynce, & Malik, 2009).

2.2.1 Grounding
For an overview of intelligent grounding techniques in

FO(ID ),

we refer the reader to the

work of Wittocx, Denecker, and Bruynooghe (2013) and of Wittocx et al. (2010). Below we
present the basic principle.

T over vocabulary Σ, a partial structure I with
⊥, and returns a ground theory T 0 that is strongly

A grounder takes as input a theory
domain

D,

interpreting at least

>

and

244

Lazy Model Expansion: Interleaving Grounding with Search
Σ-equivalent

with

we assume that

T

T

in

I.

Theory

T0

is then called a

is a canonical theory of the form

grounding

of

T

given

I.

Recall that

{PT , ∆}.

One way to compute the grounding is using a top-down process on the theory, iteratively
applying grounding steps to direct subformulas of the rule or formula at hand. The grounding
Let ϕ[x] be a
T and let D be the domains of x. A Tseitin transformation replaces ϕ by the
1
atom Tϕ (x), with Tϕ a new |x|-ary predicate symbol called a Tseitin symbol, and extends
∆ with the rule ∀x ∈ D : Tϕ (x) ← ϕ. The new theory is strongly Σ-equivalent to the

algorithm may replace subformulas by new predicate symbols as follows.
formula in

original one (Vennekens et al., 2007).
The procedure one_step_ground, outlined in Figure 1, performs one step in the grounding process. Called with a formula or rule

ϕ

in canonical form, the algorithm replaces all

G
(rules or formulas) and a possibly non-ground part R (rules). If ϕ is a formula, then G
consists of ground formulas. Replacing ϕ by the returned ground formulas and extending ∆
with the returned rules produces a theory that is strongly voc(T )-equivalent to the original.
If ϕ is a rule from ∆, G consists of ground rules, and replacing ϕ by both sets of returned
rules results again in a theory that is strongly voc(T )-equivalent to the original.
direct subformulas with Tseitin symbols and returns a pair consisting of a ground part

Algorithm 1: The one_step_ground algorithm.
1 Function one_step_ground (formula or rule ϕ)
2
switch ϕ do 
3
case [¬]P d return h{ϕ}, ∅i;
4
case P d ← ψ
5
6
7
8
9
10
11
12
13
14
15
16

hG, ∆i

:= one_step_ground(ψ );

return h{P d ← g∈G g}, ∆i;
case ψ1 ∨ . . . W
∨ ψn
return h{ i∈[1,n] Tψi }, {Tψi ← ψi | i ∈ [1, n]}i;
case ψ1 ∧ . . . ∧ ψn
return h{Tψi | i ∈ [1, n]}, {Tψi ← ψi | i ∈ [1, n]}i;
case ∀x ∈ D : P (x) ← ψ
return h∅, {P (x)[x/d] ← ψ[x/d] | d ∈ D}i;
case ∃x ∈ D :Wψ[x]
return h{ d∈D Tψ[x/d] }, {Tψ[x/d] ← ψ[x/d] | d ∈ D}i;
case ∀x ∈ D : ψ[x]
return h{Tψ[x/d] | d ∈ D}, {Tψ[x/d] ← ψ[x/d] | d ∈ D}i;


V

Grounding a theory then boils down to applying one_step_ground on the sentence
(which copies

PT

PT

to the ground part) and on each rule of the theory and repeatedly applying

one_step_ground on the returned rules

R (all returned sentences and rules in G are ground).

We use ground to refer to the algorithm for this overall process.
1. Tseitin (1968) introduced such symbols as part of his normal form transformation.

245

De Cat, Denecker, Stuckey & Bruynooghe
Various improvements exist, such as returning

⊥

returning

>/⊥

for atoms interpreted in

I

and

from conjunctions whenever a false conjunct is encountered (analogously for

disjunctions and quantications).
Also, algorithm one_step_ground introduces a large number of Tseitin symbols. Stateof-the-art grounding algorithms use a number of optimizations to reduce the number of such
symbols. As these optimizations are not directly applicable to the techniques presented in
this paper, we start from the naive one_step_ground algorithm. In Section 5, we present
an optimized version of one_step_ground that introduces fewer Tseitin symbols and hence
results in smaller groundings.

3. Lazy Grounding and Lazy Model Expansion
lazy grounding to refer to the process of partially grounding a theory and
lazy model expansion (lazy MX) for the process that interleaves lazy grounding

We use the term
the term

with model expansion over the grounded part. In Section 3.1, we formalize a framework for
lazy model expansion of

FO(ID )

theories; in Section 3.2, we formalize the instance of this

framework that is the basis of our current implementation; in Section 3.3, we illustrate its
operation.

3.1 Lazy Model Expansion for FO(ID) Theories
Given a canonical theory

T = {PT , ∆}

and an input structure

Iin ,

models expanding

Iin

are searched for by interleaving lazy grounding with search on the already grounded part.
We rst focus on the lazy grounding.
Apart from the initial step that moves

PT

to the grounded part, the input of each step

consists of a set of rules still to be grounded, an already grounded theory and a three-valued
structure that is an expansion of the initial input structure.
Each subsequent grounding step can replace non-ground rules by ground rules and might
introduce new rules. Hence, the state of the grounding includes a set
and a set

∆d

(the

delayed denition )

∆g

of ground rules

of (possibly) non-ground rules. The denitions have

∆g ∪ ∆d (in what follows abbreviated as ∆gd ) is voc(∆)-equivalent with
the original denition ∆ and hence, ∆gd is total. The grounding procedure will guarantee
that, at all times, ∆g and ∆d are total.
Given a partial structure Iin and the rule sets ∆g and ∆d , the key idea behind lazy
model expansion is (i) to use a search algorithm to search for a model I of ∆g that is an
expansion of Iin in which PT is true; (ii) to maintain a justication J such that the literals
true in I and dened in ∆d are justied over ∆gd and that J is consistent with I ; (iii) to
interleave steps (i) and (ii) and to move parts of ∆d to ∆g when some literal dened in ∆d
the property that

that needs to be justied cannot be justied.

h∆g , ∆d , J, Ii
∆d yet to be grounded, a justication J , and
∆d is ∆, ∆g = ∅, and J is the empty graph.

Thus, to control lazy model expansion, it suces to maintain a state
consisting of the grounded rules
a three-valued structure

I.

∆g ,

Initially,

the rules

I

is

Iin ,

Lazy model expansion searches over the space of

Denition 3.1 (Acceptable state).
tence

acceptable

states.

A tuple h∆g , ∆d , J, Ii of a theory with an atomic senPT , a total denition ∆, and an input structure Iin is an acceptable state if (i) ∆gd , ∆g

246

Lazy Model Expansion: Interleaving Grounding with Search
and

∆d

∆gd is strongly voc(∆)-equivalent with ∆, (ii) no domain
∆d , (iii) J is a justication over ∆gd , (iv) I is an expansion
L of literals true in I and dened in ∆d is justied by J , and (vi) JL ,
the literals in L, is consistent with I .

are total denitions and

atom is dened in both
of

v

Iin ,

( ) the set

the justication of

Example 3.2.

∆g

and

Consider the theory

{PT , ∆},

with

∆

the denition



PT ← T1 ∨ T2 ∨ T3 .



 T ← ∀x ∈ D : Q(x).
1

T2 ← ∀x ∈ D : R(x).




T3 ← ∃x ∈ D : ¬Q(x).
Let

I

be the structure

{PT , T1 }

(hence,

T2

and

T3













are unknown), and

∆g

and

∆d

the

denitions consisting of the rst rule and the remaining rules, respectively. Furthermore, let

J be {T1 → {Q(d) | d ∈ D}}. The tuple h∆g , ∆d , J, Ii is then an acceptable
T1 is the only literal in I that is dened in ∆d and it is justied by J .

state. Indeed,

As already said, the lazy model expansion algorithm starts from the initial state

∅, ∆d = ∆, J = ∅, I = Iin ,

which is acceptable if dened literals are unknown in

each state, it either renes

I

by propagation or choice, or it backjumps.

∆g =

Iin .

In

If the resulting

state is unacceptable, a repair operation restores acceptability; these steps are described in
Section 3.2.
in

∆gd .

The algorithm tries to compute an acceptable state in which

T

By Corollary 2.11, this would entail that a model of

PT

is justied

exists; it can be computed

eciently through well-founded model computation. In intermediate states, the justication
may be non-total for

PT ,

iii),

Note that, in (
is justied over

∆d .

contain unfounded literals, or be inconsistent.

the justication must be over

∆gd .

Indeed, assume some literal

Its justication graph can have a leaf that is dened in

∆g

l

and that

depends positively or negatively on l. Then every attempt to extend this justication graph

l over ∆gd might fail, e.g., because of a forbidden
cycle. Consider, e.g., the denitions ∆g = {P ← Q} and ∆d = {Q ← P }. In that case, it
would not be correct to take P as justication for Q being true, even though it is a valid
justication within ∆d . Indeed, no model exists that justies Q in the full denition ∆gd .
to a total justication graph that justies

Proposition 3.3. Let h∆g , ∆d , J, Ii be an acceptable state.

∆gd has a well-founded model
that expands the literals that are true in I and dened in the (delayed) denition ∆d .

Proof.

L

Let

be the set of literals true in

justies the literals of
expands

L.

I

and dened in

to the open literals of

because

As the state is acceptable,

J

Hence, by Corollary 2.11, there exists a well-founded model that

L.

Example 3.4 (Continued from Example 3.2).
>

∆d .

I

is a model of

J

(i.e., to

∆g , PT

be interpreted randomly, as no

The well-founded evaluation, after assigning

{Q(d) | d ∈ D}),

derives that

T1

is true.

Moreover,

is also true in such a well-founded model. Note that

R-atoms

occur in

I

or

J.

The following theorem states when the obtained expansion is also a model of

247

T.

R

can

De Cat, Denecker, Stuckey & Bruynooghe
Theorem 3.5. Let h∆g , ∆d , J, Ii be an acceptable state of a theory T = (PT , ∆) with input
structure Iin such that PT is true in I and I|voc(∆g ) is a model of ∆g . Then there exists a
model M of T that expands I|voc(∆g ) .
Proof. I|voc(∆g )
justication

Jg

is a model of
over

∆g

only domain literals true in
combine them in one

It follows from Proposition 2.10 that there exists a

I|voc(∆g ) .

∆g

and that consists of

We now have two justications:

as follows: for each dened literal

l

of

∆gd ,

if

J

J

and

Jg .

We

l, we
Jg for

is dened in

Jc (l) = Jg (l). As Jc takes edges from either J or
each dened literal, it is a justication for ∆gd .
We verify that Jc justies PT . First, it is total in PT . Indeed, any path from PT either
consists of literals dened in ∆g , and then it is a branch of the total Jg over ∆g , or it passes
0
to a literal l dened in ∆d , which is justied by J according to condition (v) and hence
(Jc )l0 = Jl0 is total. As such, from PT we cannot reach a dened literal of ∆gd in which
Jc is undened. Second, Jc does not contain unfounded literals starting from PT . This is
because any path from PT is either a path in Jg (so well-founded as it justies ∆g ) or it has
a tail in J (well-founded by property (v)). Finally, the set of literals reachable from PT in
Jc is consistent. Also this we can see if we look at paths in Jc from PT : at rst we follow
Jg which consists of true literals in I , then we may get into a path of J which contains
literals that are consistent with I . In any case, it is impossible to reach both a literal and
set

Jc (l) = J(l);

Jc

∆g .

that justies every true dened literal of

otherwise, we set

its negation.
It follows from Proposition 2.8 that there exists a model of
and in which

PT

is true. Since

∆gd

that expands

I|voc(∆g )

∆gd is strongly equivalent with ∆, the proposition follows.

M can be achieved by well-founded evalstarting from any two-valued open(∆gd )-

Recall that eectively computing such a model
uation of

∆gd ,

with polynomial data complexity,

structure expanding

I|voc(∆g )

(Chen & Warren, 1996).

In the above theorem, it is required that
to compute a two-valued model of
justication that justies

PT .

∆g .

I

is a model of

∆g .

Actually, we do not need

It suces to search for a partial structure and a

So, we can relax this requirement at the expense of also

maintaining justications for literals true in

I

and dened in

∆g .

Corollary 3.6. Let h∆g , ∆d , J, Ii be an acceptable state of a theory T

= {PT , ∆} with input

structure Iin such that PT is true in I and J justies PT over ∆gd . Then there exists a
model M of T that expands I|S with S the set of dened literals in JPT .
∆g expanding Iin in which PT is true implies the lack of models
∆g has no model expanding Iin , then it has an unsatisable
core, i.e., a set of rules from ∆g such that no model exists that expands Iin . Hence, it is also
an unsatisable core for T = (PT , ∆). To nd an unsatisable core, one can, for example,
Failure to nd a model of

of

T

expanding

Iin .

Indeed, if

use techniques described by Torlak, Chang, and Jackson (2008).

3.2 Practical Justication Management for FO(ID) Theories
Roughly speaking, our lazy model expansion framework consists of two components.
the one hand, a standard model expansion algorithm that operates on

{PT , ∆g } and, on
∆gd and lazily

the other hand, a justication manager that maintains a justication over

248

On

Lazy Model Expansion: Interleaving Grounding with Search
grounds

∆d .

Lazy model expansion performs search over the space of acceptable states and

aims at reaching a state where Theorem 3.5 (or Corollary 3.6) is applicable. To avoid slowing
down the search during model expansion, the work done by the justication manager and
the lazy grounding must be limited. To achieve this, we have designed a system in which the
justication manager has no access to the grounded denition

∆g

and need not restore its

state when the search algorithm backtracks over the current structure
manager only has access to

I

∆g

particular, a literal dened in

I.

The justication

and maintains justications that are restricted to

∆d .

In

is not allowed in a direct justication. Our justication

manager maintains the following properties:

•

Literals in direct justications are either open in

•

All direct justications in
structure

•

J

∆gd

or dened in

∆d .

are kept consistent with each other and with the current

I.

The justication graph dened by

J

has no unfounded literals and is total.

To distinguish acceptable states that meet these additional requirements from acceptable
states as dened in Denition 3.1, we call them

Denition 3.7

(Default acceptable state)

.

default acceptable states ; we dene them as:

A state

i

h∆g , ∆d , J, Ii

is a default acceptable

state if it is an acceptable state and, in addition, ( ) literals in direct justications are either
open in

∆gd

or dened in

∆d ,

ii

and ( )

J

justies the set of all literals for which

J

is dened.

It follows that default acceptable states satisfy two extra conditions: they do not justify
literals dened in
consistent.

∆d

in terms of literals dened in

∆g ,

and dened in

∆d ,

are consistent.

J

is

that are true in

I

and the set of all literals in

For an acceptable state, it suces that the literals in

J

Since default acceptable states are acceptable states,

Theorem 3.5 and Corollary 3.6 also hold for default acceptable states.
During standard model expansion, the main state-changing operations are to make

I

more precise (by making literals true, either through choice or propagation) and to make

I

less precise (by backjumping).

and model expansion modies

I

When
into

I ',

S = h∆g , ∆d , J, Ii is a default acceptable state
0
the new state h∆g , ∆d , J, I i is not necessarily a

default acceptable state. The following propositions identify situations where acceptability
is preserved.

Proposition 3.8. Let h∆g , ∆d , J, Ii be a default acceptable state, L a set of literals unknown
in I and I 0 the consistent structure I ∪ L. If (i) literals of L either are not dened in ∆d
or have a direct justication in J and (ii) no direct justication in J contains the negation
of a literal in L, then h∆g , ∆d , J, I 0 i is a default acceptable state.
Proof.

i

As the literals true in

( ) that all literals true in
in

J

are consistent with

all literals true in

I'

I'

I,

I

∆d have a direct justication, it follows from
∆d have a direct justication. As justications
they are also consistent with I '. Hence, J justies

and dened in

and dened in

ii

then, by ( ),

and dened in

∆d .

Proposition 3.9. Let h∆g , ∆d , J, Ii be a default acceptable state. Then h∆g , ∆d , J, I 0 i with
I 0 <p I is a default acceptable state.

249

De Cat, Denecker, Stuckey & Bruynooghe
Proof.
of

I, J

J

The justication

justies all literals dened in

justies all literals dened in

∆

and true in

In a default acceptable state, literals dened in
of literals dened in
hidden loops over
both

∆g

and

∆d ,

∆d .

∆gd .

∆

and true in

I.

As

I'

is a subset

I '.

∆g

are not allowed in direct justications

This restriction is quite limiting (see next section) but is to avoid

Such loops can only be detected by maintaining a justication over

which our current implementation does not do. Several methods exist to

l dened in ∆g can be allowed in direct
∆d , provided it can be established that l's justication cannot loop over ∆gd .
One case is when the body of the rule of l has no dened literals. A step further is to analyze
the dependency graph: a literal dened in ∆g can be allowed in the direct justication of
a literal dened in ∆d provided both literals do not belong to the same strongly connected

extend the class of default acceptable states. Literals
justications of

component of the dependency graph. In that case, they cannot be part of the same cycle.

3.3 An Example
In the rest of the section, we illustrate the behavior of lazy model expansion on an articial
example, constructed in such a way that all main features are illustrated. In the next section,
the processes involved are described in more detail.
We focus on the operation of the justication manager and its interaction with the
solving process. The manager is activated in an unacceptable state, either when the solver
falsies a literal that occurs in a direct justication of

J

l dened in
for l to extend

or when a true literal

∆d is not justied by J . One option for repair is to search for a justication
J . In general this problem is as hard as the model expansion problem itself,
Corollary 2.11. Our manager only searches
extend

J,

and if it does not nd one, it grounds l's denition and moves it to

Our example uses a theory

T

as shown by

locally for a direct justication that justies l to
∆g .

which states that a symmetric graph (edge/2) exists where

R/1)
D = {d1 , . . . , dn } and
the equality predicate as the identity relation on D (below omitted in I ). Predicates edge, R
and root are not interpreted; R and root are dened. In particular, root is dened as the
singleton {d1 }, specifying the root as d1 .

at least one node other than the root node (predicate
from the root node. The input structure

P
T











PT
C1
C2
∀x ∈ D : root(x)
∀x ∈ D : R(x)

I

root/1)

is reachable (predicate

interprets the domain as

← C1 ∧ C2
← ∃x ∈ D : ¬root(x) ∧ R(x)
← ∀(x y) ∈ D2 : edge(x, y) ⇒ edge(y, x)
← x = d1
← root(x) ∨ ∃y ∈ D : edge(x, y) ∧ R(y)

(1)
(2)
(3)
(4)
(5)













The lazy MX algorithm proceeds as follows:
1. The initial default acceptable state is
and

h∆g , ∆d , J, Ii

in which

∆g , I

and

J

are empty,

∆d = ∆.

2. Propagation over

{PT , ∆g }

sets

I

to

{PT }.

This expands the structure

the conditions of Proposition 3.8 are no longer satised.

250

I,

but now

The resulting state is not

Lazy Model Expansion: Interleaving Grounding with Search
acceptable since

J.

PT

is true and dened in

∆d

while it has no direct justication in

J with a direct justication for PT .
The atom PT has a unique direct justication {C1 , C2 } but extending J with it does
not restore (default) acceptability since C1 , C2 have no direct justication in J and
PT remains unjustied. Therefore, the alternative is taken and rule (1) is moved to
∆g . Now, a default acceptable state is obtained.
One option to repair acceptability is to extend

I to {PT , C1 , C2 }. Now C1 and C2 have to be justied. Consider
C2 and rule (3). As edge is open, our manager can build the direct justication
{¬edge(d, d0 ) | (d, d0 ) ∈ D2 }, that sets all negative edge literals true, and extends J
with it (setting all positive edge literals true would be equally good). This justies C2
and avoids the grounding of the rule dening C2 .

3. Unit propagation sets
rst

4. Literal

C1

cannot be justied (with the local approach) since each of its direct jus-

tications contains unjustied dened literals.

However, as rule (2) is existentially

quantied, one can avoid grounding the whole rule by performing a Tseitin transformation to isolate one instance and then only ground that instance. For the purpose

d1 :

← (¬root(d1 ) ∧ R(d1 )) ∨ T
(2a)
← ∃x ∈ D \ {d1 } : ¬root(x) ∧ R(x) (2b)

of illustration, we make the (bad) choice of instantiating



C1
T

Rule (2a) is moved to

∆g

x

with

and a default acceptable state is reached.

5. We are in an acceptable state in which no further propagation is possible, so a choice
has to be made. As

C1

is true, the body of rule (2a) has to become true. Preferably

not selecting a Tseitin (this would trigger more grounding), the rst disjunct is selected
by model expansion and propagation extends the structure with
The literal

¬root(d1 )

denition of
dening

root

root

∆d by
{¬(d1 = d1 )} is

is dened in

unique direct justication

¬root(d1 ) and R(d1 ).

rule (4) but cannot be justied since its
false. The manager partially grounds the

and splits it up in a ground rule (4a) and a non-ground rule (4b)

for the other domain elements:



root(d1 ) ← d1 = d1 (4a)
∀x ∈ D \ {d1 } : root(x) ← x = d1 (4b)



∆g . Note that root(d1 ) is justied by {d1 = d1 } in ∆gd , hence
root(d1 ) in direct justications in ∆d . Whenever grounding has been

Rule (4a) is moved to
it is safe to use

done, the justication manager is interrupted by propagation, which can infer the truth
of additional literals, or detect an inconsistency (which will result in backjumping).
In both cases, the manager has to resume the revision of the justication afterwards,
until an acceptable state is reached.
unacceptable (due to the unjustied

Here, even though the resulting state is still

R(d1 )),

∆g
root(d1 ) and a conict.

the creation of the new rule (4a) in

interrupts the manager. Propagation using the new rule derives

I = {PT , C1 , C2 }, the subsequent propagation sets the structure
{PT , C1 , C2 , root(d1 ), T }. Still not in a default acceptable state (T is not justied),

After backtracking to

I

to

rule (2b) is further transformed to split o another instance.



T ← (¬root(d2 ) ∧ R(d2 )) ∨ T2
(2ba)
T2 ← ∃x ∈ D \ {d1 , d2 } : ¬root(x) ∧ R(x) (2bb)

251



De Cat, Denecker, Stuckey & Bruynooghe
∆g ,

Rule (2ba) is moved to

while rule (2bb) remains in

∆d .

This state is default

acceptable.

T2 , choosing the rst disjunct in rule (2ba)
R(d2 ). The literal ¬root(d2 ) is dened in ∆d , but is
justied by the direct justication {¬(d2 = d1 )}. The literal R(d2 ) cannot be justied
by a direct justication (as all edge literals are false in the current justication graph)
and rule (5) is transformed to split o the instance for d2 . Actually, this instance in

6. Again, the search avoids the new Tseitin
which propagates

¬root(d2 )

and

turn has a disjunctive body with a complex subformula, so to avoid grounding the
subformula, we break it up in two parts and introduce another Tseitin.







R(d2 ) ← root(d2 ) ∨ T3
(5aa) 


T3 ← ∃y ∈ D : edge(d2 , y) ∧ R(y)
(5ab)
 ∀x ∈ D \ {d2 } : R(x) ← root(x)





∨ ∃y ∈ D : edge(x, y) ∧ R(y)
(5b)
Rule (5aa) is moved to

∆g ,

the others remain in

∆d .

I is {PT , C1 , C2 , root(d1 ), T, ¬root(d2 ), R(d2 )}, hence propagation on rule (5aa) in ∆g extends it with T3 . There is no direct justication justifying
T3 and, hence, rule (5ab) is partially grounded by splitting o the d1 case:


T3 ← (edge(d2 , d1 ) ∧ R(d1 )) ∨ T4
(5aba)
T4 ← ∃y ∈ D \ {d1 } : edge(d2 , y) ∧ R(y) (5abb)

7. The current structure

Rule (5aba) is moved to

∆g

while rule (5abb) remains in

8. The search selects the rst disjunct of

R(d1 ).
it.

The literal

Extending

J

R(d1 )

is dened in

∆d .

T3 's rule body and propagates edge(d2 , d1 ) and
∆d , but {root(d1 )} is a direct justication for

with this direct justication yields an acceptable but not default

root(d1 ) is dened in ∆g . However, root(d1 ) is justied in ∆gd ,
J with this direct justication as discussed earlier. Now the
justication manager faces a new problem: the true literal edge(d2 , d1 ) is in conict
0
0
2
with the direct justication {¬edge(d, d ) | (d, d ) ∈ D } of C2 (rule (3)). To handle
this conict, it splits o the aected instance (x = d2 , y = d1 ) from this rule:


C2 ← (edge(d2 , d1 ) ⇒ edge(d1 , d2 )) ∧ T5
(3a)
T5 ← ∀(x y) ∈ D2 \ {(d2 , d1 )} : edge(x, y) ⇒ edge(y, x) (3b)

acceptable state, since

making it safe to extend

∆g while rule (3b) remains in ∆d . The direct justication of
{¬edge(d, d0 ) | (d, d0 ) ∈ D2 \ {(d2 , d1 )}}, the unaected part of the direct
justication of C2 . This restores acceptability.

Rule (3a) is moved to

T5

is set to

9. Propagation on rule (3a) extends

I

with

edge(d1 , d2 )

and

T5 . The literal edge(d1 , d2 ),
T5 (rule (3b)). To resolve

which is true, is in conict with the direct justication for

it, the justication manager partially grounds rule (3b) and splits o the instance

{x = d1 , y = d2 } as follows.


(3ba) 
 T5 ← (edge(d1 , d2 ) ⇒ edge(d2 , d1 )) ∧ T6
T6 ← ∀(x y) ∈ D2 \ {(d2 , d1 ), (d1 , d2 )} :


edge(x, y) ⇒ edge(y, x) (3bb)

252

Lazy Model Expansion: Interleaving Grounding with Search
∆g while rule (3bb) remains in ∆d ; T6 inherits the direct
¬edge(d1 , d2 ) removed. Propagation on rule (3ba) extends I
state is acceptable, with T6 dened in ∆d but justied.

Rule (3ba) is moved to
justication of
with

T6 .

By now,

T5

with

The resulting

∆g

consists of the rules (1), (2a), (4a), (2ba), (5aa), (5aba), (3a), and (3ba), and

∆d consists of the rules (4b), (2bb), (5b), (5abb), and (3bb). The cur{PT , C1 , C2 , root(d1 ), ¬root(d2 ), edge(d2 , d1 ), edge(d1 , d2 ), R(d1 ), R(d2 ),
T, T3 , T5 , T6 }, a model of PT ∪ ∆g .
Of these literals, ¬root(d2 ), R(d1 ) and T6 are dened in ∆d . Literal ¬root(d2 ), dened
by rule (4b) has {¬(d2 = d1 )} as direct justication. Literal R(d1 ), dened by rule (5b), has
{root(d1)} as direct justication. Literal T6 , dened by rule (3bb) has as direct justication
the set of all negative edge literals over D except edge(d1 , d2 ) and edge(d2 , d1 ). To obtain
a full model of the theory, I is extended with the literals of the above direct justications.

the residual denition
rent structure

I

is

In this case, this assigns all open literals and the model can be completed by the wellfounded model computation over

∆gd .

Actually, this can be done without grounding the

denition (Jansen, Jorissen, & Janssens, 2013).

4. Justication Management
In Section 3.2, we have instantiated our general framework, developed in Section 3.1, for a
justication manager that only has access to

∆d .

In the example of Section 3.3, the justi-

cation was constructed on demand, i.e., each time some literal needed a (dierent) direct
justication, the body of its dening rule was analyzed and a justication was extracted. If
that failed, part of the rule was grounded. This was called the
imagine a

global approach,

where more rules of

∆d

local approach.

One can also

are considered at once in an attempt to

select direct justications that minimize the grounding of the rules as a whole. Obviously,
a global approach will be more time consuming, so should not be applied every time an
adjustment of the justication is required. In this section, we describe both approaches.
Before describing the algorithms, we introduce some notations and assume some normalizations have been done. The function nnf reduces a formula to its negation normal form.

S a set and s a single element, S + s and S − s are used as shorthands for S ∪ {s} and
S\{s}. With J a justication, we denote by J[l → d] the graph identical to J except that l
is now justied by d. We assume quantiers range over a single variable and variable names
With

are not reused in a formula. Furthermore, we assume basic reductions have been applied to
formulas, e.g.,

>∧ϕ

reduces to

ϕ, ∀x ∈ ∅ : ϕ

reduces to

t,

...

4.1 The Local Approach
Algorithm 2 shows the top level of the lazy_mx model expansion algorithm, taking as input
theory

{PT , ∆}

and

Iin . Denitions ∆d and ∆g are initialized with ∆ and
I is initialized as Iin . The set of ground sentences Tg
the initial justication J is empty. An auxiliary (FIFO)

is initialized as empty.

The latter keeps track of literals for which the direct

and input structure

the empty denition, respectively, and
is initialized with the fact
queue

qch

PT

justication needs to be checked.
The main loop performs model expansion over

Tg ∪ ∆g ,

interleaved with work by the

justication manager towards establishing a default acceptable state. The model expansion

253

De Cat, Denecker, Stuckey & Bruynooghe
part consists of propagation (the call to propagate), the test on whether the current state
is inconsistent (with learning and backjumping), the test on whether a model of

Tg ∪ ∆g

has been found (returning the model and the justication) and of the choice step that

Tg ∪ ∆g

selects a literal unknown in

and assigns it a value.

Propagation returns literals

that are entailed by a ground theory over a (partial) structure, for example by applying
unit propagation and unfounded/wellfoundedness propagation (Mariën et al., 2008). The
test for a model is only performed in a default acceptable state (i.e., when the queue

qch

is empty). If the test succeeds, this ensures that the well-founded model computation can
expand the current structure

I

extended with the direct justications of all literals into

a model of the whole theory. Also the choice step only takes place in a default acceptable
state; this ensures that the search space is limited to the state space of default acceptable
states.

The justication manager is activated when a propagation or choice step assigns

a literal
valid.

If

l.
l

By calling check_literal, it is checked whether the current justication remains
is dened in

to the queue

qch

∆d

and has no justication, it needs a justication and is added

for further processing by the justication manager.

If

¬l

0
justication of another literal l , the justication becomes inconsistent with
another justication so it is also added to

qch .

occurs in the

I

and

l0

needs

The further processing is done by selecting

elements from the queue and calling the lazy_ground function.

The latter function rst

attempts to nd a (dierent) consistent direct justication for l; if that fails, it splits o the
rule instance dening

l

from

∆d

and partially grounds it, hence

∆g

is extended. The new

clauses may trigger propagation; therefore the processing of queued literals is interleaved
with propagation and, possibly, with backtracking . Note that backtracking might restore
the consistency with

I

of the direct justication

J(l)

of a literal

l

on

qch .

4.1.1 Lazy Grounding of One Rule
The function lazy_ground, Algorithm 3, checks whether the literal
tion; if not, it simply returns. Otherwise, it checks whether

l

l

needs a direct justica-

has a valid justication, i.e.,

one that satises the invariants detailed below. If so, it also returns; otherwise, it passes the
rule body that has to be used to construct a justication (the negation of the dening rule
when the literal is negative) to build_djust, a function that attempts to nd a valid direct
justication. Besides the literal and the rule body, also an initial justication, derived from
the rule body, is passed to build_djust. If the latter function is successful, the justication
is updated and lazy_ground is done; if not, the direct justication of the literal

false

l

is set to

and split_and_ground is called to ground part of the rule dening l.

Before going into more details, we rst analyze which properties we want to maintain
in the current justication
considered part of

J

J.

The direct justications of literals in the

qch queue
J are:

are not

since they might be invalid. The global invariants of

•

no literals are unfounded in

•

the set of literals in

J

(recall, negative cycles are allowed),

J

is consistent.

For each direct justication

S = J(l) of J

for some

l

not on the queue, invariants of the lazy

grounding process are:

• S

contains no literals dened in

∆g

(unless such a literal is safely justied in

discussed before),

254

∆gd ,

as

Lazy Model Expansion: Interleaving Grounding with Search

Algorithm 2: The lazy_mx lazy model expansion algorithm.
1 Function lazy_mx (atomic sentence PT , denition ∆, structure Iin )
Output: either a model of ∆g and J or false

2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19

20
21
22

Tg

:= {PT };

∆g

while true do

:=

∅; ∆d

:=

∆; J

:=

∅; I

:=

Iin ; qch

:=

L := propagate(Tg ∪ ∆g , I );
I := I ∪ L;
foreach l ∈ L do qch :=check_literal(l,qch );
if I is inconsistent then
Tg += learn_nogood(I , Tg );
if conict at root level then return false ;
I := I at state of backjump point;
else if qch is not empty then
(l, qch ) := dequeue(qch );
lazy_ground(l);
else if I is a model of Tg ∪ ∆g then
return I , J ;

else

select choice literal l;

I

:=

I + l;

qch :=check_literal(l,qch );

Function check_literal (literal l, literal queue qch )
Data: global ∆d and J Output: updated queue
if l dened in ∆d and J(l) = undef then qch := enqueue(l,qch ) ;
foreach l0 such that ¬l ∈ J(l0 ) do qch := enqueue(l0 ,qch ) ;
return qch ;

Algorithm 3: The lazy grounding of a literal.
1 Function lazy_ground (literal l)
Data: global ∆d , J and I
2
if l ∈ I and l dened in ∆d then
3
if J(l) exists and obeys the invariants then return;
4
else

5
6
7
8
9
10
11

∅;

ϕ

:= body of the rule dening l;

if l is a negative literal then

ϕ := nnf (¬ϕ)
dj := build_djust(l, ϕ, init_just(l));
if dj 6= false then J := J[l → dj]; return;

else

J

=

J[l → false];

split_and_ground(l);

255

;

De Cat, Denecker, Stuckey & Bruynooghe
•

literals in
the queue

S that
qch .

are dened in

∆d

either have a direct justication in

J

or belong to

qch

These invariants imply that a default acceptable state is reached when the

queue is

empty. Indeed, it follows from the invariants that the current justication is total in that
situation and hence all literals that have a direct justication are justied (Denition 2.6).
Due to the policy followed to queue literals, the current justication is also consistent with

I

while all literals true in

I

and dened in

∆d

have a justication, hence

h∆g , ∆d , J, Ii

is a

default acceptable state.

4.1.2 Building a Direct Justification
The purpose of build_djust, Algorithm 4, is to extend
for literal

l

∆d .

dened in

I.
formula ϕ

Here

l

J

with a suitable direct justication

is a literal for which

J(l)

is currently undened or is

i

inconsistent with

It is a recursive function which takes three parameters: ( ) the literal

l,

to be made true by the direct justication (initially the whole body of

ii

( ) the

the rule dening the literal; note that the initialization takes the negation of the rule when

iii) a description of the direct justication derived so far, initialized

the literal is negative), (

through init_just(l). For this algorithm, we assume

ϕ is such that dierent quantiers range

over dierent variables.
Before going into details, we discuss how to represent direct justications.

Basically,

we could represent a direct justication as a set of ground literals. However, this set can
be quite large and using a ground representation might hence defy the purpose of lazy

hL, Bi with L a set of
B a set of bindings xi ∈ Di with xi a variable and Di
a domain. A set of bindings B = {x1 ∈ D1 , . . . , xn ∈ Dn } represents the set of variable
substitutions SB = {{x1 /d1 , . . . , xn /dn } | di ∈ Di for each i ∈ [1, n]}. The set of ground
literals represented by hL, Bi is then {lθ | l ∈ L and θ ∈ SB }. The direct justication of a
literal P (d1 , . . . , dn ), dened by a rule ∀x ∈ D : P (x) ← ϕ, is initialized by init_just(l) as
h∅, {x1 ∈ {d1 }, . . . , xn ∈ {dn }}i. In eect, B allows to identify the relevant rule instantiation

grounding.

Instead, we represent a direct justication as a pair

possibly non-ground literals and

by providing the appropriate variable instantiation from the domains, while the set of literals
is empty.
The build_djust algorithm searches for a set of literals making
recursively calling itself on subformulas of
larger justication for

ϕ.

ϕ

ϕ

true.

It works by

and composing the results afterwards into a

When no such set of literals is found, for example because none

exists that is consistent with all other direct justications,

false

is returned.

The base case is when the formula is a literal. To make that literal true, all instances of
the literal under the set of bindings

B

must be true, hence, the set of literals

L

is extended

with the literal itself. The resulting direct justication has to satisfy all invariants, which is
checked by the call to valid: it returns

true for a call valid(l, dj) if dj
l and J[l → dj] satises

to be (part of ) a direct justication for

satises the invariants
the invariants on the

justication.
A universally quantied formula
quantied variable.

x ∈ D.

∀x ∈ D : ψ

has to be true for each instance of the

Hence, in the recursive call, the set of bindings

B

is extended with

For an existentially quantied formula, it suces that one instance is true. Hence,

a minimal approach is to try each instance separately until one succeeds; if all fail,

256

false

is

Lazy Model Expansion: Interleaving Grounding with Search

Algorithm 4: The build_djust algorithm.
1 Function build_djust (literal l, formula ϕ and justication hL, Bi)
Input: B binds all free variables of ϕ
Output: either a direct justication or false
2
switch ϕ do
3
case ϕ is a literal
4
if valid(l, hL ∪ {ϕ}, Bi) then return hL ∪ {ϕ}, Bi;
5
else return false ;
6
case ∀x ∈ D0 : ψ
7
return build_djust(l, ψ, hL, B ∪ {x ∈ D0 }i);
8
case ∃x ∈ D0 : ψ
9
if large(D0 ) then
10
return build_djust(l, ψ, hL, B ∪ {x ∈ D0 }i);
11
foreach di ∈ D0 do

12
13

hL0 , B 0 i := build_djust(l, ψ, hL, B ∪ {x ∈ {di }}i);
if hL0 , B 0 i =
6 false then return hL0 , B 0 i;

14
15
16
17
18
19

return false ;
case ϕ1 ∧ . . . ∧ ϕn
foreach i ∈ [1, n] do

20
21
22
23
24

return hL, Bi;
case ϕ1 ∨ . . . ∨ ϕn
foreach i ∈ [1, n] do

25

hL0 , B 0 i := build_djust(l, ϕi , hL, Bi);
if hL0 , B 0 i = false then return false ;
else hL, Bi := hL0 , B 0 i;

hL0 , B 0 i := build_djust(l, ϕi , hL, Bi);
if hL0 , B 0 i =
6 false then return hL0 , B 0 i;

return false ;

257

De Cat, Denecker, Stuckey & Bruynooghe
returned. Note however that we do not want to iterate over each domain element if
large, which would be similar to constructing the grounding itself. Instead, if
extend the binding with

x ∈ D.

D

D

is

is large, we

Conjunction is similar to universal quantication, except

that explicit iteration over each conjunct is needed. As soon as one conjunct fails, the whole
conjunction fails. Disjunction is similar to existential quantication with a small domain.
Note that build_djust is non-deterministic due to choices for a domain element to justify
an existentially quantied formula, or for a disjunct to justify a disjunction.

Example 4.1.

Consider the following rule over a large domain

D.

H ← ∀x ∈ D : ¬P (x) ∨ (∃y ∈ D : Q(x, y) ∧ ¬R(x, y))
Assume that

J is empty and we
h{¬P (x)}, {x ∈ D}i

have no loops to keep track of.

Applying build_djust

¬P (x) in the body is chosen. This
corresponds to the direct justication {¬P (x) | x ∈ D}. Alternatively, if the second disjunct is chosen, it returns h{Q(x, y), ¬R(x, y)}, {x ∈ D, y ∈ D}i, which represents the direct
justication {Q(x, y) | x ∈ D, y ∈ D} ∪ {¬R(x, y) | x ∈ D, y ∈ D}.
to

H

returns

if the rst disjunct

4.1.3 Partially Grounding a Rule
The last bit of the lazy model expansion algorithm handles the case where no justication
can be found and the denition of a literal

l

is to be grounded.

A straightforward way

would be to call one_step_ground on the rule dening l, and store the result in

∆g

and

∆d .

However, in many cases such an operation results in too much grounding.

Example 4.2.

of the form ∀x ∈ D : P (x) ← ϕ in a situation where no
P (d). Applying one_step_ground to r1 would instantiate
x with all elements in D, resulting in |D| rules, while in fact it suces to split r1 in two rules,
one for the instance x = d and one for the remainder. Another example applies to a rule r2
of the form H ← ∀x ∈ D : Q(x) ∨ R(x) and a direct justication J(H) = {Q(x) | x ∈ D}.
When Q(d) becomes false, the justication manager may need to ground this rule. Applying
one_step_ground to it would instantiate the universally quantied x with all elements in D .
Instead, it is better to split o the instance for x = d and to introduce a Tseitin T for the
remainder, producing H ← (Q(d) ∨ R(d)) ∧ T for ∆g and T ← ∀x ∈ D − d : Q(x) ∨ R(x)
for ∆d . The direct justication for T can be obtained incrementally by removing Q(d) from
that of H , as discussed in Section 4.1.5.
Consider a rule

r1

justication can be found for atom

The split_and_ground algorithm (Algorithm 5) has to ground part of the rule dening
a given literal
dening

∆d

l

l,

say


P d .

The rst step is to split o the rule instance for which the rule

has to be grounded (the call to split).

that denes


P d .

Let

We then replace that rule by

additionally return the rule


P d ← ϕ[x/d].

∀x ∈ D : P (x) ← ϕ be the rule in
∀x ∈ D − d : P (x) ← ϕ in ∆d and

Afterwards, we apply one_step_ground to the

latter rule and add the computed rules to either

∆g

or

∆d . 2

The result of split_and_ground is that denition
one. The limit is a ground denition
equivalent with

∆gd

in which

∆gd is more ground than the previous
∆d is empty and ∆g is strongly voc(∆)-

∆.

2. Recall, the head of a new grounded rule is always dierent from the head of already grounded rules.

258

Lazy Model Expansion: Interleaving Grounding with Search
Algorithm 5: The split_and_ground algorithm.
1 Function split_and_ground (literal l)
Input: l is dened in ∆d
Result: update to ∆g , ∆d , J , and qch
2
3

r := split(l); // split updates ∆d
(∆0g , ∆0d ) := one_step_ground(r);
∆g ∪ = ∆g '; ∆d ∪ = ∆d ';

4

Even if no justication was found, we can do better than just splitting o

l

and applying

one_step_ground, as shown in Example 4.2. First, splitting can be made signicantly more
intelligent, which is discussed in Section 4.1.5. Second, we can improve one_step_ground to
only ground part of expressions if possible, which we describe below.

Improving one_step_ground.
all subformulas/instantiations of
result consists of

|D|

l ← ϕ iterates over
∃x ∈ D : P (x), the

Applying one_step_ground to a rule

ϕ.

For example if

ϕ

is the sentence

new rules and as many new Tseitin symbols. Instead, depending on

the value of l, it is sucient to introduce only one (or some) of these subformulas, as shown
in Algorithm 6, which extends the switch statement of one_step_ground with two higherpriority cases.

If

l

is true, it is sucient to ground one disjunct/existential instantiation

and to delay the rest by Tseitin introduction. If

l

is false, we take a similar approach for

conjunction/universal quantication.

Algorithm 6: Additional cases for the one_step_ground algorithm.
1 switch r do
2
case l ← ϕ1 ∨ . . . ∨ ϕn and I(l) = t

3
4

5
6
7
8

choose

i ∈ [1, n];

return h{l ← ϕi ∨ T }, {T ←
case l ← ∃x ∈ D : ϕ and I(l) = t

W

choose

j∈{1...n}−i ϕj }i;

d ∈ D;

return h{l ← ϕ[x/d] ∨ T }, {T
analogous cases for

∧

and

∀

in

← ∃x ∈ D − d : ϕ}i;
combination with I(l) = f .

4.1.4 Algorithmic Properties
Correctness and termination of the presented algorithms is discussed in the following theorem.

Theorem 4.3 (Correctness and termination). If lazy_mx returns an interpretation I , then

expanding I with the literals in the direct justications of J , applying the well-founded evaluation over ∆gd and restricting it to voc(T ) results in a model of T . If the algorithm returns
false , no interpretation exists that is more precise than Iin and satises T .

259

De Cat, Denecker, Stuckey & Bruynooghe
Algorithm lazy_mx terminates if I is over a nite domain D. Otherwise, termination is
possible but not guaranteed.3
Proof.

If lazy_mx returns an interpretation

I, I

is a model of

∆g

and

qch

is empty. Given

the properties of split_and_ground, after applying lazy_ground for a literal l, either
valid justication or is dened in
state and, by Theorem 3.5,
returns

false ,

I

∆g .

∆gd

qch

has a

is empty, we are in a default acceptable

can be expanded into a model of the whole theory. If lazy_mx

it has been proven that

be no models of

Hence if

l

and hence

T

∆g

has no models in

Iin .

In that case, there can also

Iin .

also has no models expanding

Without calls to lazy_ground, the search algorithm terminates for any nite
tion lazy_ground itself produces an ever-increasing ground theory
as limit. Hence, lazy_mx always terminates if

D

D

is nite. If

∆g

∆g ; the func-

with the full grounding

is innite, the limit of

∆g

is

an innite grounding, so termination cannot be guaranteed.

4.1.5 Symbolic Justifications, Incremental Querying and Splitting
The algorithms presented above are sound and complete.

However, they can be further

improved by taking the formulas from which justications are derived into account.

Symbolic justications and incremental querying.
for (subformulas of ) a formula

Example 4.4.

ϕ,

When multiple justications exist

grounding can be further delayed.

Consider the formula

∀x ∈ D : P (x) ∨ Q(x),

where both

h{P (x)}, {x ∈ D}i

h{Q(x)}, {x ∈ D}i are justications. From that, we could derive the justication: for
d ∈ D, make either P (d) or Q(d) true. Hence, more grounding is necessary only when
both P (d) and Q(d) become false for the same d.

and

each

We can do this automatically by changing build_djust as follows:

•

The algorithm is allowed to select multiple disjunctions / existential quantications
even if a valid justication was already found for one (Lines 13 and 24).

•

build_djust no longer returns a justication, but a symbolic

justication formula

that

entails the original formula. The formula is built during build_djust and reects the
subformulas/instantiations that have been selected.

From

ψ,

the justication itself

ψ . For
{P (x) | x ∈
∀x ∈ D : P (x) ∨ Q(x).

can be derived directly as the set of non-false literals in the (full) grounding of
example, for a formula

D},
•

∀x ∈ D : P (x) ∨ Q(x),

instead of the justication

build_djust might now return the justication formula

The validity check (valid) is extended to return false if the justication formula is false.

By allowing more complex formulas (instead of a conjunction of universally quantied literals), the validity check whether a formula has become false after incremental changes
to

I

is now more expensive. This is in fact an

incremental query

problem. In the exper-

iments, we limit the depth of the allowed formulas and use a straightforward (expensive)
algorithm that evaluates the whole formula whenever an assignment can falsify it.
3. It is possible to change the integration of

lazy_ground in lazy_mx to guarantee termination if a nite

model exists, see Section 5.1.

260

Lazy Model Expansion: Interleaving Grounding with Search
Body splitting.

As described in Algorithm 3 of Section 4.1.3, split simply splits o the

rule instance that denes l, then one_step_ground grounds this rule instance step by step,
in accordance with the structure of the formula. However, when the grounding is triggered
by a conict with the current justication, one_step_ground is blind for the origin of the
conict.

By using the conicting literals, one could focus on grounding the part of the

formula that contributes to the conict. One can do so by restructuring the rule in a part
to be grounded, that contains the conict, and a part not to be grounded, for which the
old justication can be adjusted to still apply.

The latter part can then be split o by

introducing new Tseitins and the transformation is called body splitting. This approach can
be inserted in Algorithm 3 after the call to split. For this, the original justication (call it

jold )

is passed as an extra argument to split_and_ground.

Example 4.5.

h ← ∀x ∈ D : P (x); let h{P (x)}, {x ∈ D}i be the justication for h true in I . When P (d) becomes false, it is easy to see that we can split o the
violating instantiation by rewriting the original rule into h ← P (d) ∧ T and adding the
rule T ← ∀x ∈ D − d : P (x). Crucially, a justication for the second part can be derived
from the original justication, namely h{P (x)}, {x ∈ D − d}i. The second part can hence
be added to ∆d and its justication to J while the rst part is added to ∆g .
Consider the rule

r and its direct justication jold can be done in an ecient way.
v is a true domain literal in the partial structure and that the direct justication
of rule r contains its negation ¬v . The implementation is such that the binding(s) for
which the justication instantiates to ¬v can be extracted from the representation of the
direct justication of the rule. For simplicity, assume {x = d1 , . . . , dn } is the single such
instance. A recursive algorithm visits the formula ϕ in the body of r depth-rst. Whenever
a quantication ∀x ∈ D : ϕ is encountered with x equal to xj ∈ x, it is replaced by
(∀x ∈ D − dj : ϕ) ∧ ϕ[x = dj ]. Then a Tseitin transformation is applied to the left-hand
This revision of a rule

Assume that

conjunct and the algorithm recurses on the right-hand conjunct with what remains of the
binding. The new rule dening the new Tseitin has jold −v as a direct justication. Similarly,
an existential quantication is replaced by a disjunction.

The result is a set of new rules

for which no new justication has to be sought and a smaller rule

r0

which is passed to

one_step_ground. Correctness follows from the fact the jold − v is a valid justication, none
of the new rules contains

Example 4.6.

v,

and from the correctness of the Tseitin transformation.

In Example 4.1, justications were sought for

H

in the rule

H ← ∀x ∈ D : ¬P (x) ∨ (∃y ∈ D : Q(x, y) ∧ ¬R(x, y)).
J = {Q(x, y) | x ∈ D, y ∈ D} ∪ {¬R(x, y) | x ∈
I , and l = Q(d1 , d2 ) becomes false, J is no longer
consistent with I and cannot be repaired. J − l, however, is still consistent with I , but is
not a justication of the whole body. On the other hand, J − l is a justication for the
subformula ¬P (x) ∨ ∃y ∈ D : Q(x, y) ∧ ¬R(x, y) for each instantiation of x dierent from
d1 . Consequently, we can split the quantication ∀x ∈ D : into x ∈ D − d1 and x = d1

Assume we selected the justication

D, y ∈ D}.

When

P (d1 )

is true in

and apply a Tseitin transformation to the former. Afterwards, we recursively visit the latter
formula and apply a similar reasoning to the existential quantication. The operations on

261

De Cat, Denecker, Stuckey & Bruynooghe
∧ (split 1)
∀x ∈ D − d1

.

∨

∨

¬P (x)

∃y ∈ D
∧

Q(x, y)

∨ (split 2)

¬P (d1 )

∃y 0 ∈ D − d2

.

∧

∧

¬R(x, y)
Q(d1 , y 0 )

¬R(d1 , y 0 ) Q(d1 , d2 ) ¬R(d1 , d2 )

∀x ∈ D : ¬P (x) ∨ ∃y ∈ D : Q(x, y) ∧ ¬R(x, y) is split for a violating
Q(d1 , d2 ). The original justication without Q(d1 , d2 ) is a justication of

Figure 2: The rule body
literal

the left-hand side of all splits, with the justication formula shown in blue. The
remaining non-justied formula is shown in red.

the formula are illustrated in Figure 2. The result consists of the following rules, where the
rule for

H

is now even ground.




 H ← T1 ∧ (¬P (d1 ) ∨ (T2 ∨ (Q(d1 , d2 ) ∧ ¬R(d1 , d2 )))).






T1 ← ∀x ∈ D − d1 : ¬P (x) ∨ ∃y ∈ D : Q(x, y) ∧ ¬R(x, y).




 T ← ∃y ∈ D − d : Q(d , y) ∧ ¬R(d , y).

2
2
1
1
To further optimize the traversal of the formula
the path taken through the parse tree of

Example 4.7.

ϕ

ϕ,

build_djust can be extended to store

and the direct justications of the subformulas.

C1 ← ∀(x y) ∈ D2 : ¬edge(x, y) ∨ edge(y, x) has to be
justied, J is empty and I does not interpret edge. The build_djust algorithm recursively
visits the body of the rule until ¬edge(x, y) is returned as it is a valid literal to use. Going
up one level, we store that for ¬edge(x, y) ∨ edge(y, x), we selected {¬edge(x, y)}. Assuming
no more disjuncts are selected, ¬edge(x, y) is returned again. Going back up through both
quantications, we store that, for both quantications, we selected D as the set of relevant
2
domain elements, and build_djust returns the justication formula ∀(x y) ∈ D : ¬edge(x, y).
Assume the rule

If build_djust is given access to
direct justication.

jold ,

similar optimizations are possible for repairing a

Consider again Example 4.6, but assume

P (d1 )

is unknown in

I.

In

this case, the left branch of Figure 2 can also be transformed in a rule with a still valid,

¬P (d1 ) as direct
justication for the rule H ← T1 ∧ (¬P (d1 ) ∨ (∃y ∈ (D − d1 ) : Q(d1 , y) ∧ ¬R(d1 , y))), where
T1 is as in Example 4.6.

direct justication. For the right branch, a repair is to select the disjunct

4.2 The Global Approach
Finding justications using the greedy local approach can easily lead to more grounding than
necessary. Consider for example the sentences

262

∀x ∈ D : P (x)

and

∀x ∈ D : P (x) ⇒ Q(x).

Lazy Model Expansion: Interleaving Grounding with Search
Applying the local approach to the second sentence rst (with an empty
the construction which makes atoms over

P

J ),

might result in

false. Then applying the local approach to the

rst sentence nds no valid justication for it; so it has to be fully grounded. The global
approach takes a set of rules as input and tries to select direct justications for them such
that the

expected

grounding size of the whole set is minimal.

We cast the task, called the

optimal justication problem, as a problem on a graph as
rule nodes R and justication nodes J .

follows. The graph consists of two types of nodes,

A justication node is a symbolic set of literals representing a possible justication (for the

I ). A rule node is a pair
t (t, f , u); A pair hr, ti for a rule r with head l
expresses that there exists a direct justication for l; the pair hr, f i that there exists a direct
justication for ¬l and the pair hr, ui that r has no justication.

literals dened by a rule in

hr, ti

r

of a rule

in

∆d

∆d ,

given the current partial structure

and a truth value

There are three types of edges:

• Valid edges

between a rule node

(the negation of ) the head of

• Conict edges

hr, ti (hr, f i) and a justication node j

where

j

justies

r.

i

ii

between ( ) rule nodes of the same rule with dierent truth value, ( )

iii) a rule node hr, ti (hr, f i) where
¬l (l), and (iv) a rule node hr, ui,

justication nodes that contain opposite literals, (

r

denes

where
(or

r

¬l)

l,

and a justication node that contains

denes

l,

and a justication node that contains

or

¬l

(a conict because

l

hr, ti (hr, f i)

j

needs a justication).

• Depends-on edges

between a justication node

contains negative (positive) literals dened by
The aim is then to select subsets

•

l

Rsel ⊆ R

and

j and
r.

Jsel ⊆ J

a rule node

where

such that

Each selected rule node is connected with a valid edge to at least one selected justication node.

•

No conict edges exist between pairs of selected nodes.

•

Neither positive nor mixed cycles exist in the subgraph consisting of the valid and
depends-on edges between the selected nodes.

From a selection

{Rsel , Jsel }

extracted as follows.
rule

r

such that

satisfying these constraints, an initial justication

A literal

hr, ti (hr, f i)

l (¬l)

can be

is a selected rule. Its direct justication is the union of the

justications of the justication nodes in
edge.

J

is given a direct justication if it is dened by a

Jsel

connected with

hr, ti (hr, f i)

through a valid

Moreover, all literals dened by rules for which no rule node was selected can be

added to the initial

qch

queue, to be handled by the local approach, as a complete solution

must have a justication for them. When

hr, ui

is selected, it means that the grounding of

instances of the rule is delayed until the literals it denes become assigned.
This type of problem is somewhat related to the NP-hard

hitting set

(or

set cover )

problem (Karp, 1972): given a set of top and bottom nodes and edges between them,
the task is to nd a minimal set of bottom nodes such that each top node has an edge to at
least one selected bottom node.

263

De Cat, Denecker, Stuckey & Bruynooghe
h∆g , ∆d , J, Ii, the input for the optimal justication
∆d , a node is constructed for each of the
the truth value is known in I ) and also their conict

Given a default acceptable state

problem is generated as follows. For any rule in
three truth values (only one when
edges are added.

Valid edges and justication nodes are obtained using a (straightforward)

adaptation of build_djust that returns a set of possible justications that make the head of
a rule true (false). E.g., for a rule

P (x)

∀x ∈ D : P (x) ← ϕ, build_djust is called with the literal
{x ∈ D}. Conict and depends-on edges are derived

and the binding is initialized at

by checking dependencies between justications and between rules and justications.

To

keep this ecient, it is done on the symbolic level.

Example 4.8.

PT , C1

and

C2

← ∃x ∈ D : ¬root(x) ∧ R(x)
← ∀(x y) ∈ D2 : edge(x, y) ⇒ edge(y, x)
← x = d1
← root(x) ∨ ∃y ∈ D : edge(x, y) ∧ R(y)

(2)
(3)
(4)
(5)






Consider the theory of our running example, after

propagated to be true. Denition






C1
C2
∀x
∈
D
:
root(x)



∀x ∈ D : R(x)

∆d

have been

is then





The associated optimal construction set input is shown in Figure 3. Note that in rule

C1 and C2 are true in I ,
root(x) nor ¬root(x) can be

nodes, we use the dened head literals to identify the rule. Literal
hence there is only one rule node for rules (2) and (3). Neither
justied for all

x ∈ D,

hence there is only a

hroot, ui

tuple.

There are four solutions that are subset-maximal with respect to rule nodes, namely the
following rule node selections:

{hR, ui , hroot, ui , hC2 , ti}

(a)

{hR, f i , hC2 , ti}

(b)

{hR, ti , hC2 , ti}

(c)

{hC1 , ti , hC2 , ti}

(d)

For each of these, multiple justication selections are possible (also shown in Figure 3).
For

C1 ,

we have to select justication

(iv),

but for

C2

we can choose from

(v)

or

(vi)

(but

not both).
The objective is then not to maximize the number of selected rule nodes, but to minimize
the expected grounding size.

To obtain an estimate of the expected grounding size, the

following conditions were taken into account:

•

It should depend on the size of the grounding of the rule.

•

Assigning multiple justications to a rule should result in a lower estimate as the rule
will only be grounded when all are false.

•

Variables occurring in multiple justications result in less matching instantiations.

•

In most practical applications, the number of false atoms far exceeds the number of
true ones in any model. Hence, positive literals in a justication should have a higher
cost than negative ones.

264

Lazy Model Expansion: Interleaving Grounding with Search
hR, f i

h{¬root(x), ¬edge(x, y)}, {x ∈ D, y ∈ D}i

hR, ui

h{¬root(x), ¬R(x)}, {x ∈ D}i

hR, ti

h{root(x)}, {x ∈ D}i

hC1 , ti

h{¬root(x), R(x)}, {x ∈ D}i

hC2 , ti

h{edge(x, y)}, {x ∈ D, y ∈ D}i

hroot, ui

h{¬edge(x, y)}, {x ∈ D, y ∈ D}i

(i)

(ii))

(iii)
(iv)
(v)
(vi)

Figure 3: The graph that is part of the input to the optimal justication problem of Example 4.8.

Rule nodes are shown on the left, justication nodes on the right;

valid edges are shown in green, conict edges in red and depends-on edges in blue.
For readability, conicts between justications and unknown rule nodes are not
shown.

We approximate the expected grounding size with the function
input a rule

r

(with head

h),

J.

which takes as

n

the selected type of justication (rule not selected ( ), no

justication (u), a justication for
cations

expsize

h (t)

or a justication for

¬h (f ))

and the set of justi-

The function returns the expected grounding size of the rule (size(r), dened

below) weighted depending on the type of justication. The weights are derived from two
estimates:

pval

ptr

is the probability an atom will become assigned and

is the probability of

n

an assigned atom to be true. Hence, as dened formally below, for non-delayed rules ( ),

u

the full size is used; a rule without justication ( ) is weighted by

t

( ) is weighted by

ptr ,

product over the justications
namely

pt

literals in

f

a false one ( ) by

j

in

J.

1 − ptr ;

a true justication

the latter two weights are multiplied by a

Each factor of this product is a sum of two terms,

times the number of negative literals in

j.

pval ;

j

and

1 − ptr

times the number of positive

The eect is that the expected size decreases as the number of justications

increases and that the expected size increases as a justication has more literals.

expsize (r, n, ∅) = size(r)
expsize (r, u, ∅) = size(r) × pval
expsize (r, f , J) = size(r) × pval × (1 − ptr ) ×

Y

((1 − ptr ) × |pos.

lits.

∈ j|

j∈J

+ ptr × |neg. lits. ∈ j|)
Y
expsize (r, t, J) = size(r) × pval × ptr ×
((1 − ptr ) × |pos. lits. ∈ j|
j∈J

+ ptr × |neg.
For the probabilities, we assumed

pval

lots of literals will not get a value, and

lits.

∈ j|)

to be small (currently 0.1) to reect the hope that

ptr

is less than half, to reect that atoms are more

265

De Cat, Denecker, Stuckey & Bruynooghe
often assigned false than true. The function

size

is dened below. The function returns the

number of atoms in the grounding of a rule or formula, except for existential quantication
and disjunction. For these, we take into account that they can be grounded only partially
using Tseitin transformation, by taking the logarithm of the total grounding size.

size(L) = 1
size(L ← ϕ) = size(ϕ) + 1
size(∀x ∈ D : ϕ) = D × size(ϕ)
X
size(ϕi )
size(φ1 ∧ . . . ∧ ϕn ) =
i∈[1,n]

size(∃x ∈ D : ϕ) = log(D) × size(ϕ)
P

i∈[1,n] size(ϕi )

size(φ1 ∨ . . . ∨ ϕn ) = log(n) ×

n

Solutions to the optimal justication problem should minimize the term

X

expsize (r, t(r), J(r))

r∈∆d
with

t(r)

the type (t,

f,

or

u)

and

J(r)

the justication of the literal dened by

r.

Example 4.9 (Continued from Example 4.8). The size of rule C1 is 1+log(D)×2, that of C2

1+D2 ×log(2), that of root is D×(1+1), and that of R is D×(1+log(2)×(1+log(D)×2)/2.
Consider assigning justication (iv) to C1 : this results in an expected cost for that rule of
(1 + log(D) × 2) × 0.3 × 1 (as the construction relies on making R true). Additionally, it
would force the grounding of the rule dening R, increasing the cost with the size of the
rule for R. The optimal solution for the problem in Figure 3 is then rule node selection (a)
2
with justication (vi) for C2 . Its cost is the sum of (1 + D × log(2) × 0.3 (for justication
(vi)) and 1 + log(D) × 2 (the expected size of the rule for C1 ). Now, only the rule for C1
is

has to be passed to the local approach.
To solve the optimal justication problem,

IDP's

optimization inference itself is applied

to a (meta-level) declarative specication of the task.

4

For larger theories

T,

the problem

turns out to be quite hard, so two approximations were considered to reduce the search
space.

First, the number of selected justications for any rule was limited to 2.

as the values of

size(r)

can grow quite large, the approximation

standard approach). Rounding to integer values was applied as

dlog(size(r))e

IDP's

Second,

is used (a

support for oating

point number is still preliminary. The resulting specication could be solved to optimality
within seconds for all tested theories. During lazy model expansion, the global approach is
applied in the initial phase when all Tseitin literals representing sentences in the original
theory have been propagated true.

5. Heuristics and Inference Tasks
This section discusses how to tune the lazy grounding and the search heuristics of the
underlying SAT solver to obtain an eective implementation of lazy model expansion. We
4. The specication is part of

IDP

's public distribution.

266

Lazy Model Expansion: Interleaving Grounding with Search
also describe a few other inferences tasks beyond model expansion that are useful in the
context of lazy grounding. A few less important issues are discussed in Appendix A.

5.1 Heuristics
Heuristics play an important role in the lazy grounding algorithms, as they serve to nd
the right balance between how much to ground and how long to search. We rst discuss
how our heuristics were chosen. Afterwards, we discuss an alternative approach to minimize
grounding.

5.1.1 The Balance between Grounding and Search
The algorithms leave room for a number of heuristic choices that can have an important
eect on the performance.

We now briey discuss these choices.

As a guideline for our

decisions, the following principles are used:

•

Avoid leaving the search process without enough information to make an informed
decision; for example, avoid losing too much (unit) propagation or introducing too
many Tseitin symbols.

•

Prevent creating a grounding that is too large; this may for example happen as the
result of a very long propagate-ground sequence.

Recall, the goal is not to create a minimal grounding, but to solve model expansion problems
while avoiding a too large grounding.
Below, we introduce a number of parameters that aect these heuristics.

The exact

values used in the experimental evaluation for the parameters introduced below are specied
in Appendix A.
In split_and_ground, when handling a disjunction or existential quantication, there is
a choice on how many disjuncts to expand. If we expand one instantiation at a time for a
rule

h ← ∃x ∈ D : P (x),

as done in Algorithm 6 (lines 3 and 6), iterative application results

in a ground theory

h ← P (d1 ) ∨ T1
T1 ← P (d2 ) ∨ T2
T2 ← P (d3 ) ∨ T3
.
.
.

Tn ← ∃x ∈ D \ {d1 , d2 , . . . , dn } : P (x).
A SAT-solver such as MiniSAT, which is used in the
the

P (di )

IDP

system, initially assigns

atoms; such a choice triggers an iteration of propagation and grounding.

f

to

The

resulting thrashing behavior can be reduced somewhat, and the grounding is more compact
when the grounding introduces

n

disjuncts at a time:

h ← P (d1 ) ∨ . . . ∨ P (dn ) ∨ T
T ← ∃x ∈ D \ {d1 , d2 , . . . , dn } : P (x).

267

De Cat, Denecker, Stuckey & Bruynooghe
To further remedy this, two search-related heuristics are changed. First, the initial truth
value is randomized, but favoring false (as in most models, many more atoms are false than
true). Second, search algorithms typically

restart

after an (ever-increasing) threshold on the

number of conicts, sometimes caching the truth value assigned to atoms (

polarity caching ).

This allows the solver to take learned information into account in the search heuristic while
staying approximately in the same part of the search space.

In case of lazy grounding,

we might want to jump to another part of the search space when we come across long
propagate-ground sequences. To this end, we introduce the concept of

randomized restarts,

which take place after an (ever-increasing) threshold on the number of times

∆g

is extended

and randomly ipping some of the cached truth values.
In addition, build_djust always returns

false

if it is estimated that the formula has a

small grounding. Indeed, grounding such formulas can help the search. Whether a formula
is considered small is determined in terms of its (estimated) grounding size.
strategy is used in split_and_ground:

The same

whenever the formula to which one_step_ground

would be applied is small, ground is applied instead, to completely ground the formula.

5.1.2 Late Grounding
Grounding is applied during the search process as soon as unit propagation has taken place.
The result is a focus on the current location in the search space, but with the danger of
grounding too much if there is no solution in that part of the space. Alternatively, we could
apply the opposite strategy, namely to ground as late as possible: only apply additional
grounding when the search algorithm terminates without ever having found a model in an
acceptable default state. Such a strategy is well-known from the elds of incremental proving
and planning, where the domain (number of time steps) is only increased after search over
the previous, smaller bound has nished. This guarantees a minimal grounding. A prototype
of this strategy has been implemented in

IDP

with good results on planning problems.

5.2 Related Inference Tasks
The bulk of the paper focuses on model expansion (MX) for
solutions are structures that are two-valued on

voc(T ).

FO(ID )

theories

T,

for which

Often, one is only interested in a

small subset of the symbols in voc(T ). This is for example the case for model generation for
∃SO(ID), the language which extends FO(ID) with existential quantication over relations.
An ∃SO(ID ) problem ∃P1 , . . . , Pn : T with an initial structure I , relation symbols P1 , . . . ,
Pn , and T an FO(ID) theory, can be solved by model generation for the FO(ID) theory
T with initial structure I and by dropping the interpretation of the symbols P1 , . . . , Pn in
the models. Another example is query evaluation for FO(ID ): given a theory T , an initial
structure I and a formula ϕ with free variables x (all in FO(ID )), the purpose of evaluating
the query hT , I, ϕi is to nd assignments of domain elements d to x such that a model of
T exists that expands I and in which ϕ[x/d] is true. To solve it by model expansion in
FO(ID ), a new predicate symbol T is introduced and answers to the query are tuples of

domain elements d such that T d is true in a model of the theory T extended with the
sentence ∃x ∈ D : T (x) and the denition {∀x ∈ D : T (x) ← ϕ}.
In both cases, approaches using (standard) model expansion compute a total interpretation and afterwards drop all unnecessary information, which is quite inecient. Lazy model

268

Lazy Model Expansion: Interleaving Grounding with Search
expansion can save a lot of work by only partially grounding the theory. However, once a
model is found for the grounded part, the justications and the remaining denitions are
used to expand the structure to a model of the full theory.

Although this expansion is

obtained in polynomial time, it is still inecient when afterwards a large part of the model
is dropped.
To remedy this, we dene a variant of the model expansion task, denoted

T,

restricted

MX.

I and an additional list of symbols O,
5
called output symbols. Solutions are then structures M which are two-valued on all symbols
in O and for which an expansion exists that extends I and is a model of T . Adapting lazy
Restricted MX takes as input a theory

a structure

grounding to solve restricted MX can be done through an analysis of which justications
need not be added (completely) to the structure, splitting

∆gd

into multiple denitions and

only evaluating those dening output symbols or symbols on which those depend (using a
stratication argument).
The above-mentioned inference tasks can be cast trivially to restricted MX problems and
lazy restricted MX then greatly improves the eciency with respect to ground-and-solve, as
shown in the experimental section.
The extension of

FO(ID )

with

procedurally interpreted

symbols (De Cat et al., 2014)

provides another class of interesting problems. Such predicate symbols have a xed interpretation, but to know whether a tuple belongs to the predicate, a procedural function has
to be executed. Such an approach provides a clean way to combine declarative and procedural specications. Consider for example a symbol

isP rime(N)

that is interpreted by a

procedure which executes an ecient prime-verication algorithm and returns true i the
given argument is prime. We are generally not interested in the complete interpretation of

isP rime, so it can be cast as a restricted MX problem with isP rime not in O.

Solving such

a problem using lazy grounding then has the benet of only executing the associated function

during

search for relevant atoms

isP rime(d).

Also for this task, we show an experimental

evaluation in the next section.

6. Experiments
The

IDP

system has a state-of-the-art model expansion engine, as can be observed from

previous Answer-Set Programming competitions (Denecker et al., 2009; Calimeri et al., 2014;
Alviano et al., 2013). The lazy model expansion algorithms presented in this paper were
implemented in the

IDP

system, by extending the existing algorithms (De Cat, Bogaerts,

Devriendt, & Denecker, 2013).
The current implementation is incomplete in the sense that the cycle check for justications has not been implemented yet. This only aects inductive denitions as non-inductive
ones can be replaced by the FO formulas of their completion.

As a workaround for the

lack of a cycle check, build_djust, the function that constructs a direct justication, returns
false for rules dening inductive predicates. As a consequence, an instance of such a rule
is immediately grounded, although lazily, when a domain atom dened by the rule is assigned a value. Another consequence is that inductively dened predicates cannot be used
in justications of other rules. This aects three benchmarks of the ASP competition (de5. Within the ASP community, they are sometimes referred to as show predicates.

269

De Cat, Denecker, Stuckey & Bruynooghe
scribed below in Section 6.2), namely

Reachability, Sokoban

and

Labyrinth.

For these,

the grounding might be delayed even more in a complete implementation.
The section is organized as follows. In Section 6.1, we evaluate the overhead of completely
grounding a theory using the presented approach. In Section 6.2, we evaluate the eect of
lazy grounding on a number of benchmarks of the ASP competition.

In Section 6.3, a

number of additional properties of the presented algorithms are demonstrated.
We tested three dierent setups:
(referred to as

g&s), IDP

IDP

with the standard ground-and-solve approach

with lazy model expansion (lazy) and the award-winning ASP

system Gringo-Clasp (ASP). We used

IDP

version 3.2.1-lazy, Gringo 3.0.5 and Clasp 2.1.2-st.

The parameters of the lazy grounding algorithms are discussed in Section 5.1, the values
used in the experiments are documented in Appendix A. The experiments for Sections 6.1
and 6.3 were run on a 64-bit Ubuntu 13.10 system with a quad-core 2.53 GHz processor
and 8 GB of RAM. Experiments for Section 6.2 were run on a 64-bit Ubuntu 12.10 system
with a 24-core 2.40-Ghz processor and 128 GB of RAM. A timeout of 1000 seconds and a
memory limit of 3 GB was used; out-of-time is indicated by

T,

out-of-memory by

M.6

6.1 Eect on Grounding Time
Lazy grounding may reduce grounding size and time but also causes overhead. For instance,
we expect the (naive) incremental querying of justications to be costly as discussed previously. The aim of this section is to quantify the overhead caused by lazy grounding. In the
experiments below we compare the grounding time of the standard IDP system with that
of a

naive

instance of the lazy grounding algorithm that is forced to generate the complete

grounding before starting the search. This instance was obtained from the standard algorithm using some small changes: the shortcut to ground small formulas at once is turned
o, disjuncts and instances of existentially quantied formulas are grounded one by one, a
dened literal is enqueued for lazy grounding as soon as it appears in

∆g .

For comparison,

we also measure the cost of the standard lazy grounding algorithm that computes partial
groundings.
We devised six benchmarks to test various aspects of the novel algorithm. Each benchmark is a simple theory with at most two sentences that is simple to solve. The benchmarks
are designed to measure the cost of dierent aspects of lazy grounding: delaying and resuming grounding, the querying needed to resume grounding, the splitting of formulas, etc.
Specically, the tested aspects are the following:
1. Overhead of delaying and resuming grounding in case of an existential quantier with
a large domain.

The sentence is

n disjuncts; naive lazy
n − 2 Tseitin symbols.

clause with
introduces

∃x : P (x).

Standard grounding creates a single

grounding grounds the formula piece by piece and

2. Overhead in case of an inductive denition, here

{∀x : P (x) ← P (x) ∨ Q(x)}.

standard grounding and naive lazy grounding construct a ground rule for each

Both

P (d)

atom.
6. Benchmarks, experimental data and complete results are available at

krr/experiments/lazygrounding/jair.

270

http://dtai.cs.kuleuven.be/

Lazy Model Expansion: Interleaving Grounding with Search
3. Overhead in case of a universal quantication.
standard grounding creates

n

The sentence is

∀x : P (x).

While

atomic formulas, naive lazy grounding splits o one

instance at a time and introduces

n−2

Tseitin symbols.

4. Lifted Unit Propagation (LUP) (Wittocx et al., 2010, 2013) is an important preprocessing step to reduce the grounding size. Concretely, applying LUP to the rules

∀x : ¬R(x)
∀x : R(x) ⇒ ∀y : P (x, y)
derives that the second formula follows from the rst and hence does not need to be
grounded at all. This theory is used to check whether LUP remains equally important
in a system with lazy grounding.

∀x :
R(x) ⇒ ∀y : P (x, y). Standard grounding creates a formula for each instance d of
x with a Tseitin for the grounding of ∀y : P (d, y). Naive lazy grounding creates an
extra Tseitin for each instance d of x and an extra set of Tseitins for the piece by piece
grounding of the subformula ∀y : P (d, y).

5. Overhead in case of nested universal quantication. The sentence is of the form

6. Overhead of the incremental querying in case a symbolic justication has to be validated. The sentence is

∀x : R(x) ∨ S(x),

with an identical justication formula. The

formula is validated by checking the falsity of the query
query is re-evaluated each time an

R-atom

or

S -atom

∃x : ¬R(x) ∧ ¬S(x).

This

is falsied.

6.1.1 Results
Experiments were done for predicates

P

and

Q

with arity 3 and

R

and

S

with arity 2, and

domains of size 10, 20, 30, 40 and 50. None of the predicates symbols were interpreted in
the structure.
In all experiments, the overhead for the time required to solve the initial optimization
problem (for the global approach) was always around 0.02 seconds, so in itself negligible.
The results for the rst three experiments are not shown as the dierences between standard
grounding and naive lazy grounding are negligible.

While expected for experiment 2, for

experiments 1 and 3, it shows that our actual implementation eliminates the overhead for
Tseitins when quantiers are not nested. In each of these three experiments, standard lazy
grounding is able to justify the formulas without grounding them and hence fast and almost
insensitive to the domain size. As shown in Figure 4, there is no dierence between standard
grounding and naive lazy grounding for experiment 4. In both cases, the use of LUP has a
big impact on the size of the grounding and hence on the time. While experiment 1 and 3
showed that a top level quantier does not create overhead for lazy grounding, experiment 5
shows that this does not hold anymore for nested quantiers and that naive lazy grounding
has substantial overhead when compared with standard grounding. Note that this overhead
is worst case.

When Tseitins can be justied, their denitions are not grounded, which

explains why normal lazy grounding is faster than standard grounding and insensitive to
the domain size.

Experiment 6 shows that a more complex justication formula causes

signicant overhead for naive lazy grounding. Also here, the overhead is worst case and not

271

De Cat, Denecker, Stuckey & Bruynooghe

4. Grounding with bounds

5. Nested universal quantification

16

6. Complex justification, shared variables
4.5

14

ground without LUP
ground with LUP
naive lazy ground without LUP
naive lazy ground with LUP
lazy ground with LUP

14
12

ground
naive lazy-ground
lazy-ground

12

ground
naive lazy-ground
lazy-ground

4.0
3.5

10
3.0

8

Seconds

Seconds

Seconds

10
8

6

2.5
2.0

6
1.5
4

4

1.0

2

2

0

0
0

10

20

30

40

50

0.5
0.0
0

10

Domain size

20

30

Domain size

40

50

0

10

20

30

40

50

Domain size

Figure 4: Time overhead of naive lazy grounding over ground-and-solve when completely
grounding the input theory, for benchmarks 4, 5 and 6. The time includes grounding, solving and the time needed to nd justications. The time required by the
standard lazy grounding algorithm is also shown for comparison.

visible in normal lazy grounding. Still, it is an important part of future research to reduce
the overhead of the incremental querying of complex justication formulas.

6.2 ASP Competition Benchmarks
Second, we selected benchmarks from previous ASP competitions to evaluate the lazy
grounding algorithm in a more realistic setting. Many benchmarks solutions of that competition are carefully ne tuned for speed and minimal grounding. Lazy grounding is usually
unable to substantially reduce the grounding of such theories and, due to its overhead, is
then slower than standard ground and solve. For this reason, we have sometimes selected
modelings of the benchmarks that are more natural but less optimized in time and grounding size. We justify this on the ground that the aim of our work is to improve inference for
declarative

modeling

(De Cat et al., 2014), where the emphasis is not on developing intricate

encodings, but on modeling a problem close to its natural language specication.
We selected the following problems (see the competition websites for complete descriptions). They consist of problems that are known to be hard, in order to evaluate the eect
of lazy model expansion on search, and problems that typically result in a large grounding.

• Reachability:

Given a directed graph, determine whether a path exists between two

given nodes.

• Labyrinth:

A planning problem where an agent traverses a graph by moving between

connected nodes to reach a given goal node. In addition, the graph can be manipulated
to change its connectedness.

• Packing:

Given a rectangle and a number of squares, t all squares into the grid

without overlaps.

• Disjunctive Scheduling:

Schedule a number of actions with a given earliest start

and latest end time with additional constraints on precedence and disjointness.

272

Lazy Model Expansion: Interleaving Grounding with Search
# inst.

# solved

g&s

benchmark

Sokoban
Disj. Sched.
Packing
Labyrinth
Reachability
Stable Marr.
Graph Col.

50

44

21

5

lazy
25

50

44

21
44

261

83

72

16

2

106

21

60

16
94

34

12

avg. time (sec.)

ASP

50

g&s

lazy

ASP

102

59

5

130

207

6

173

121

20
5

196

245

181
40

141
4

110

12

5

643

402

18

211

21

437
44
85

Table 1: The number of solved instances for the ASP benchmarks and the average time taken
on the solved instances. Dierent solvers solve quite dierent sets of instances.

• Sokoban:

A planning problem where a robot has to push a number of blocks to goal

positions, constrained by a 2-D maze.

• Graph Colouring:

Given a graph, assign colour to nodes (from a given set of colours),

such that no connected nodes have the same colour.

• Stable Marriage:

Given a set of men and women and a set of preferences, nd a

stable assignment: no swap results in a better match.
For each of these, we used all instances from the 2011 and 2013 competitions, except for
the 2013

Reachability

instances, because of the huge data les which none of the systems

Stable Marriage, Graph Colouring and Reachability, we
Packing and Disjunctive
IDP
Scheduling, we constructed a natural FO(·) encoding and made a faithful translation to
ASP. For the more complex benchmarks of Labyrinth and Sokoban, we used the original
FO(·)IDP and Gringo-Clasp's ASP specications submitted to the 2011 competition. For the

is designed to handle.

For

based our encodings on the available ASP-Core-2 encodings. For

lazy model expansion, we replaced cardinality expressions by their FO encoding as for the
former no justications are derived yet; this also increases the size of the full grounding.

6.2.1 Results
The number of solved instances and average time are shown in Table 1; the average grounding
size for the

IDP

7

setup is shown in Table 2.

For time and grounding size, unsolved instances

Reachability (9 times for g&s,
ASP), Disjunctive Scheduling (6 times for ASP) Labyrinth (160 times for g&s,
once for ASP), Packing (4 times for g&s, 4 times for lazy, 30 times for ASP) and Stable
Marriage (66 times for ASP); all other unsolved instances were caused by a time-out.8
were not taken into account. Memory overows happened in
9 times for

7. Grounding consists of variable instantiation interleaved with formula simplication (e.g., dropping false
disjuncts, true conjuncts, replacing disjunctions with true disjuncts by true and conjunctions with false
conjunctions by false, etc). These simplication steps may seriously reduce the grounding size.
8.

IDP

has automatic symmetry breaking, the cause of the dierence between

Colouring.

273

g&s

and

ASP

for

Graph

De Cat, Denecker, Stuckey & Bruynooghe
ground size (# atoms)
benchmark

Sokoban
Disj. Sched.
Packing
Labyrinth
Reachability
Stable Marr.
Graph Col.

g&s
2.65 × 104
5.17 × 106
3.86 × 107
1.68 × 106
2.87 × 107
2.11 × 107
1.15 × 104

lazy
2.90 × 105
2.72 × 106
1.69 × 107
1.38 × 106
1.61 × 104
1.20 × 107
1.58 × 104

ground time

ASP
4.63 × 104
8.04 × 105
4.53 × 106
3.55 × 105
1.35 × 106
3.36 × 106
2.80 × 104

Table 2: The average grounding size for the number of
marks, for all setups. For the
taken. For

g&s

and

ASP,

lazy

solved

g&s(sec.)

ASP

2.0
129.7
165.6
101.0
109.7
642.7

0.1

(sec.)

0.3
0.7
4.7
2.3
14.5
3.2
0.1

instances of the ASP bench-

setup, the size of the nal ground theory was

the average grounding time is also shown.

The results show that lazy model expansion solved more instances than the other setups
in four out of seven cases. In those cases, the problems also got solved signicantly below
the time threshold.

In ve out of seven cases, the (nal) grounding size was smaller for

lazy model expansion, orders of magnitude in one case. For

Colouring,

Sokoban, Labyrinth and Graph

lazy model expansion was outperformed by ground-and-solve, indicating that

Sokoban,
lazy grounding size was even higher than for g&s (possible due to the FO encoding
of cardinalities), indicating that a large part of the search space was explored. For Stable
Marriage, the relatively small dierence in grounding size between g&s and lazy leads us
the loss of information outweighed the gain of grounding less up-front. E.g., for
the nal

to believe that the dierent search heuristic was the main factor, not lazy grounding itself.
We also experimented with the

Airport Pickup ASP-2011 benchmark, a fairly standard

scheduling problem (transporting passengers by taxis taking into account fuel consumption)
except that no upper bound on time is provided.

9

Hence any ground-and-solve approach

would need to construct an innite grounding. Applying straightforward lazy model expansion also resulted in a grounding that was too large. However, with the prototype that uses
the late grounding heuristic described in Section 5.1,

IDP

solved one out of ten instances.

For the others, grounding was not the problem, but the search took too long at each of the
time intervals

1..n

considered to get up to a sucient

n

to solve the problem (even with the

standard search heuristic).
The presented results show that, although often benecial, lazy model expansion can be
a considerable overhead for some hard search problems. On the other hand, while inspecting
the outcome of the experiments, we observed that the class of specications and instances
solved by lazy grounding and traditional grounding only partially overlap. This suggests that
it might be a good idea to integrate both approaches into a

portfolio

system. Such a system

can either select heuristically whether to use ground-and-solve or lazy model expansion
(based on the input) or running both in parallel, aborting either one if it uses too much
memory. However, on all the problems considered, lazy model expansion could start search
9. It is possible to derive nite worst-case thresholds for the Airport Pickup problem. This is, however, not
part of the original specication.

274

Lazy Model Expansion: Interleaving Grounding with Search
much earlier than ground-and-solve, even though it got lost more often during search. This
leads us to believe that to realize the full potential of lazy grounding, more work is necessary
on developing suitable heuristics (possibly user-specied ones).

6.3 Specic Experiments
In addition to the ASP competition benchmarks, some experiments were conducted using
crafted benchmarks to illustrate specic properties of the lazy grounding algorithm.
The rst part of Table 3 shows the results of scalability experiments. For each of the
benchmarks

Packing, Sokoban

and

Disjunctive Scheduling,

we selected a simple prob-

lem instance and gradually extended its domain size by orders of magnitude: the size of the
grid (Packing) or the number of time points (Sokoban,

Disjunctive Scheduling).

The

results show that for each of the instances, lazy model expansion scales much better than
the ground-and-solve strategies of
satisable instances. However, for
signicantly.

IDP

and Gringo-Clasp and for satisable as well as un-

Disjunctive Scheduling the solving time still increases

The reason is that the lazy heuristics are still naive and make uninformed

choices too often.
As we mentioned in the previous section, ASP competition problems typically have small
groundings since running benchmarks which are too large for any system to handle does not
provide a useful comparison of the systems. Hence, we also evaluated lazy model expansion
on a number of crafted benchmarks where grounding is non-trivial.
work to look for more practical applications of this type.

It is part of future

We constructed the following

benchmarks:

• Dynamic reachability,
•

Lazy evaluation of

the example described in Section 3.3.

procedurally interpreted

the prime numbers.

symbols, using a simple theory over

As described in Section 5.2, a predicate symbol

isP rime/1

is

interpreted by a procedure that returns true if the argument is prime.

function

•

A predicate encoding of a

•

An experiment that simulates model generation for a theory with an unknown domain.

with a huge domain.

used/1; quantied formulas
∃x : (used(x) ∧ ϕ); model
6
domain of size 10 .

The unknown domain is expressed by a new predicate

∀x : ϕ

are translated to

∀x : (used(x) ⇒ ϕ)

and

∃x : ϕ

generation is simulated by model expansion with a

to

For each one, a faithful ASP encoding was constructed. The second part of Table 3 shows
the results for these benchmarks. They show a signicant improvement of lazy model expansion over ground-and-solve on all examples: in each case, both
memory overow during grounding, while
for

Disjunctive Scheduling,

lazy

g&s

and

ASP

went into

found solutions within seconds. However,

it is also evident that the lazy approach would benet from

improved heuristics: increasing the domain size signicantly increases the solving time, while
the instances are not intrinsically harder.

6.3.1 Closer to Inherent Complexity?
During the modeling phase of an application, dierent encodings are typically tested out,
in an attempt to improve performance or to locate bugs. While modeling our experimental

275

De Cat, Denecker, Stuckey & Bruynooghe
benchmark

packing-10
packing-25
packing-50
sokoban-103
sokoban-104
sokoban-105
disj-sched-sat-103
disj-sched-sat-104
disj-sched-sat-105
disj-sched-unsat-103
disj-sched-unsat-104
disj-sched-unsat-105
dynamic reachability
procedural
function
modelgeneration

lazy

g&s

ASP

0.2

2.0

0.1

0.3

2.0

0.1

1.1

10.03

5.8

0.31

0.3

0.1

0.5

20.0

1.1

2.6

T

68.0

0.39

0.49

0.07
17.44

13.04

16.05

164.18

M

M

0.24

0 49

0.09

4.11

16.04

19.85

M
M
M
M
M

M
M
M
M
M

164.2
0.18
1.24
0.79
0.19

Table 3: The solving time for additional crafted benchmarks, one instance each.

benchmarks, we noticed that simplifying a theory by dropping constraints often resulted
in a dramatic reduction in the time lazy model expansion took to nd a model. Standard
model expansion, on the other hand, was much less aected by such simplications.

In

our opinion, this observation, while hardly denitive evidence, is another indication that
the presented algorithms are able to derive justications for parts of a theory that can be
satised cheaply. In that way, the approach is able to distinguish better between problems
which are inherently dicult and problems which would just have a large grounding.

7. Related Work
Lazy model expansion oers a solution for the blow-up of the grounding that often occurs
in the ground-and-solve model expansion methodology for

FO(ID )

theories.

Answer Set

Programming (ASP) and SAT Modulo Theories (SMT) techniques also process theories that
can have a large grounding; the constraint store of Constraint Programming (CP) and Mixed
Integer Programming and the clauses of SAT can be considered the equivalent of a grounded
theory (they are often derived from quantied descriptions such as  ci

j

< cj

for all i and

for which . . . ) and can also become very large. Lefèvre and Nicolas (2009) and Ge and

de Moura (2009) have reported a blow-up problem in these paradigms and a multitude of
techniques has been developed to address it. We distinguish four approaches.
First, concerning grounding up-front, research has been done towards

of the grounding

i static analysis
ii

itself through ( )

reducing the size

of the input to derive bounds on variable

instantiations (Wittocx et al., 2010, 2013), ( ) techniques to

compile

specic types of sen-

tences into more compact ground sentences (Tamura et al., 2009; Metodi & Codish, 2012),

iii) detect parts that can be evaluated polynomially (Leone et al., 2006; Gebser et al., 2011;
iv) detect parts that are not relevant to the task at hand (e.g., in

(

Jansen et al., 2013) and (

276

Lazy Model Expansion: Interleaving Grounding with Search
the context of query problems) as shown in the work of Leone et al. (2006). Naturally, each
of these approaches can be used in conjunction with lazy grounding to further reduce the
size of the grounding. In

IDP,

i

e.g., lazy grounding is already combined with ( ) and (

Second, the size of the grounding can be reduced by

enriching

the language.

iii).

For ex-

ample, ASP solvers typically support ground aggregates (interpreted second-order functions
such as cardinality or sum that take sets as arguments), and CP and SMT solvers support
(uninterpreted) functions. More recently, the Constraint-ASP paradigm was developed (Ostrowski & Schaub, 2012), that integrates ASP and CP by extending the ASP language with

constraint

atoms. These are interpreted as constraints in a CSP problem and can thus be

handled using CP techniques. Various CASP solvers are already available, such as Clingcon (Ostrowski and Schaub), Ezcsp (Balduccini, 2011), Mingo (Liu, Janhunen, & Niemelä,
2012) and Inca (Drescher & Walsh, 2012). This technique is also integrated into
Cat et al., 2013).

Inca and

IDP

IDP

(De

in fact implement Lazy Clause Generation (Ohrimenko

et al., 2009), an optimized form of lazy grounding for specic types of constraints.
language HEX-ASP (Eiter et al., 2005) also extends ASP, this time with

external

The

atoms

that represent (higher-order) external function calls.
Third,

incremental approaches

are well-known from model generation, theorem proving

and planning. For these tasks, the domain is typically not xed in advance, but part of the
structure being sought, such as the number of time steps in a planning problem (recall the
Sokoban example from the introduction). Such an approach typically works by grounding
the problem for an initial guess of (the number of elements in) the domain.

Afterwards,

search is applied; if no model was found, the domain is extended and more grounding is
done. This is iterated until a model is found or a bound on the maximum domain size is
hit (if one is known).

This technique is applied, e.g., in the prover Paradox (Claessen &

Sörensson, 2003) and the ASP solver IClingo (Gebser et al., 2008).
Fourth, and closest to lazy grounding itself, is a large body of research devoted to
delaying the grounding of specic types of expressions until necessary (for example until they
result in propagation). Propagation techniques on the rst-order level that delay grounding
until propagation ensues have been researched within ASP (Lefèvre & Nicolas, 2009; Dal
Palù et al., 2009; Dao-Tran et al., 2012) and within CP (Ohrimenko et al., 2009).

Such

techniques can be used in conjunction with lazy grounding as they derive more intelligent
justications for specic types of constraints than presented here. For example, Dao-Tran et
al. also presented an ecient algorithm for bottom-up propagation in a denition. Within
SMT, various theory propagators work by lazily transforming their theory into SAT, such
as for the theory of Bit Vectors by Bruttomesso et al. (2007).

Ge and de Moura (2009)

investigated quantier handling by combining heuristic instantiation methods with research
into decidable fragments of FO theories, as these can be eciently checked for models.
Within ASP, work has been done on goal-directed reasoning. Both Bonatti, Pontelli, and
Son (2008) and Marple, Bansal, Min, and Gupta (2012) demonstrate approaches, in the
style of SLD resolution, that apply top-down instantiation to answer queries over innite
domains. Saptawijaya and Pereira (2013) extend an abduction framework to lazily generate
part of the relevant sentences. In search algorithms, justications (or

watches )

are used to

derive when a constraint will not result in propagation or is already satised, and hence need
not be checked in the propagation phase. Nightingale et al. (2013) show how maintaining
(short) justications can signicantly reduce the cost of the propagation phase.

277

De Cat, Denecker, Stuckey & Bruynooghe
In fact, a well-known technique already exists that combines search with lazy instantiation of quantiers, namely

skolemization,

where existentially quantied variables are re-

placed by newly introduced function symbols.

Universal quantications are handled by

instantiating them for those introduced function symbols.

Reasoning on consistency can,

e.g., be achieved by congruence closure algorithms, capable of deriving consistency without eectively assigning an interpretation to the function symbols.

These techniques are

used in Tableau theorem proving (Hähnle, 2001) and SMT solvers (Detlefs, Nelson, & Saxe,
2005).

Formula (Jackson, Bjorner, & Schulte, 2013) interleaves creating a ground pro-

gram and giving it to an SMT solver, iterating when symbolic guesses proved to be wrong.
Skolemization-based techniques typically work well in case only a small number of constants
needs to be introduced, but have diculty in case the relevant domain is large. One can also
see that lazy grounding (with support for function symbols) could incorporate skolemization by adapting the rules for grounding existential and universal quantication. We expect
skolemization to be complementary to lazy grounding, but an in-depth investigation is part
of future work.
In the eld of probabilistic inference, several related techniques have been developed that
also rely on lazy instantiation. First, the Problog system uses a form of static dependency
analysis to ground a (probabilistic) program in the context of a given query, by constructing
all possible ways to derive the query in a top-down fashion (Kimmig et al., 2011). Second,
so-called

lazy inference,

applied e.g. in

LazySAT

fact that, for the considered inference, a (xed)

(Singla & Domingos, 2006), exploits the

default

assumption exists under which

an expression certainly does not contribute to the probabilities.

Hence, expressions for

which the assumption certainly holds do not have to be considered during search. Third,

cutting plane inference

(Riedel, 2009) applies lazy inference in an interleaved setting, only

constructing the part of the program for which the assumptions are not satised.

8. Future Work
Several aspects of the presented work need further investigation. One aspect is extending
support to lazily ground more complex expressions, including aggregate expressions and

P
( x∈D and P (x) f (x)) > 3, which
atom P (d) is true, with d ∈ D , P a

(nested) function terms. Consider for example the sentence
expresses that the sum of terms
predicate and

f

f (d)

for which the

a function, should be larger than 3. One can observe that it is not necessary

to ground the whole sentence up-front.
(hence positive), the set

For example, if

{P (d1 ), f (d1 ) > 3}

f

maps to the natural numbers

is a minimal justication.

Even if no easy

justication can be found, we can suce by grounding only part of the sentence and delay

P

P (d1 ) f (d1 )) > 3 ∨ T ,
P
P
with T a Tseitin symbol dened as (
P (d1 ) f (d1 )) + ( x∈D\d1 and P (x) f (x)) > 3. Indeed,
in any model of the sentence in which T is false, the original inequality is satised.

the remainder.

For example, we can create the ground sentence

(

A second aspect is whether there are advantages to grounding earlier, for example to
guarantee no propagation is lost, or grounding later, possibly reducing the size of the grounding even more. For example, consider the sentences

P ⇒φ

and

¬P ⇒ ψ ,

with

φ

and

ψ

both large formulas for which no justication was found. Instead of grounding at least one
of the sentences, we might add

P

to the list of atoms the search algorithm has to assign and

278

Lazy Model Expansion: Interleaving Grounding with Search
only ground either of the sentences when

P

has been assigned a value (it might even be that

unsatisability is detected before grounding either one).
Given that lazy grounding is useful, what about lazy

forgetting

the grounded theory? As

the ground theory is extended when making the structure more precise, the ground theory
could be reduced again during backtracking.

By storing the justication violations that

caused grounding, we can derive which grounding can be forgotten again if the violation is
no longer problematic (e.g., after backtracking). For this, an algorithm needs to be developed
which tracks grounding/splitting dependencies between rules given their justications. This
closely resembles techniques used in tableau theorem proving and SMT, where the theory
at hand can be compacted when moving to a dierent part of the search space.
The approach described for lazy grounding can also be applied to answer set generation
in the eld of ASP. In ASP, a logic program under stable semantics can be seen as one rule
set, a single denition. However, such ASP programs do not satisfy a major condition to
apply lazy grounding. Indeed such programs are typically non-total, due to the presence of
constraints and rules of the form

p ← not np, np ← not p

or other

choice rules

which result

in multiple stable models. However, as described by Denecker et al. (2012), most practical
ASP programs can be partitioned in a set of choice rules, a set of

total

denitions and a set

of constraints (the so-called Generate-Dene-Test partition). Any ASP program that can
be GDT-partitioned, can be translated straightforwardly into an equivalent

FO(ID )

theory

that only contains total denitions. This suggests a way to apply lazy grounding to such
ASP programs.

9. Conclusion
Solvers used in the domains of SAT, SMT and ASP are often confronted with problems
that are too large to ground. Lazy model expansion, the technique described in this paper,
interleaves grounding and search in order to avoid the grounding bottleneck. The technique
builds upon the concept of a justication, a deterministic recipe to extend an interpretation
such that it satises certain constraints. A theoretical framework has been developed for lazy
model expansion for the language

FO(ID ) and algorithms have been presented to derive and

maintain such justications and to interleave grounding with state-of-the-art CDCL search
algorithms.

The framework aims at bounded model expansion, in which all domains are

nite, but is also an initial step towards handling innite domains eciently. Experimental
evaluation has been provided, using an implementation in the

IDP

system, in which lazy

model expansion was compared with a state-of-the-art ground-and-solve approach.

The

experiments showed considerable improvement over ground-and-solve in existing benchmarks
as well as in new applications. The main disadvantage is the less-informed search algorithm,
caused by the delay in propagation and the introduction of additional symbols. A possible
solution is to develop new heuristics or portfolio approaches that combine the strengths of
both methods. Finally, we have indicated a way how the proposed methods can be applied
beyond

FO(ID ),

to ASP solvers in general.

279

De Cat, Denecker, Stuckey & Bruynooghe
Acknowledgements
During this research, Broes De Cat was funded by the Agency for Innovation by Science
and Technology in Flanders (IWT). This research was also supported by FWO-Vlaanderen
and by the project GOA 13/010, Research Fund KULeuven.

NICTA is funded by the

Australian Government through the Department of Communications and the Australian
Research Council through the ICT Centre of Excellence Program.

Appendix A. More Details about the Algorithms
In this appendix, we mention parameter values as well as some optimizations that further
reduce the grounding overhead and/or improve the search. For each optimization, we indicate what is currently implemented (and part of the experimental results) and what is part
of future work.

A.1 Parameter Values
In 5.1, a number of parameters were introduced to control the behavior of lazy model
expansion.

Here, we provide details on the values used in the experimental evaluation.

These values were set manually, based on experience and a limited number of observations
(e.g., the extension threshold works similar to the conict threshold of the SAT solver). It
is part of future work to study the impact of dierent values.

•

For an existential quantication, 10 instantiations are grounded at a time; for a disjunction, 3 disjuncts are grounded at a time. This turned out to give the best balance
between introducing too many Tseitin atoms and grounding too much.

•

The initial truth value is

•

The initial threshold for randomized restarts is 100 extensions of the ground theory.

t

with probability

0.2

and

f

otherwise.

It is doubled after each restart.

•

A formula is considered small if its estimated grounding size is below

104

atoms.

A.2 Extension to FO(·)IDP
So far, we have described a lazy model expansion algorithm for function-free
However,

FO(·)IDP ,

the knowledge-base language of the

IDP

FO(ID ).

system, supports a much richer

input language. Besides types which we use to initialize the domains it also supports
(partial) functions, aggregates and arithmetic.

Our current implementation ignores the

latter extensions through a straightforward adaptation of build_djust (Algorithm 4): the
case for literals is extended to return

FO(ID )

false

when the literal is not part of the function-free

language. For example, given a rule

a justication but

Q(f (x))

h ← ∀x : P (x) ∨ Q(f (x)), P (x) can be used in

cannot. For functions, there is also the option to replace them

by graph predicates during the preprocessing step. As for the experiments of Section 6.2,
functions, if any, are given in the input structure and hence play no role.
It is part of future work to extend lazy grounding for these extensions, especially for
functions. Techniques developed in SMT and in Constraint Programming to handle (ground)

280

Lazy Model Expansion: Interleaving Grounding with Search
atoms containing function symbols are useful to reduce the size of the grounding and improve
search. In previous work, these techniques have been integrated in the

IDP

system (De Cat

et al., 2013) and it is certainly worthwhile to fully integrate them with lazy grounding.

A.3 Cheap Propagation Checks.
In lazy_mx, it is checked for each assigned literal whether it is dened in

∆d

and whether

it violates any justications. To implement this cheaply, our implementation maintains a
mapping for literals in

∆g .

It states whether the literal is dened in

∆d

and also lists the

justications in which its negation occurs. This mapping is extended whenever a new literal
is added to

∆g

and maintained whenever justications change.

The performance of the

search loop is unaected as long as literals are assigned for which the mapping is empty.

A.4 Stopping Early
In Algorithm 2, we took the standard stopping criterion used in most search algorithms
(Line 14): to stop in a conict-free state where

I

is two-valued on all symbols of

principle, we may stop earlier, with a partial structure

PT .

Indeed, Corollary 3.6 tells us that such an

I

I

Tg ∪ ∆g .

In

that admits a total justication for

can be expanded to a model. This has a

A dened
∆d that is irrelevant (in eect, does not appear in the justication) will trigger grounding
of A's denition, which in turn might introduce new literals dened in ∆d , causing a cascade

considerable impact on grounding size. Indeed, assigning a truth value to an atom
in

of unnecessary groundings and assignments.
justication of

∆g ,

Our solver algorithm does not maintain a

so it cannot know exactly when a justication exists.

Instead, the

implemented algorithm only chooses literals that are watched by some formula/rule.

It

stops with a partial structure in which unwatched literals may not be assigned. It can be
shown that this suces to guarantee that

I

admits a justication. Hence it is safe to stop

search.

A.5 Approximate Justications
In some cases, build_djust cannot nd a valid justication for a large formula because a few

I.
false if at least one atom of P
literals are already false in

For example for a formula

∀x ∈ D : P (x),

build_djust returns

is false. Instead, we have adapted build_djust with a heuristic

check on the number of expected violations. If it is small enough, the justication is still
returned. Naturally, we are then required to check whether there are any real violations, by
querying the justication formula over

I,

and apply lazy_ground to them.

References
Alviano, M., Calimeri, F., Charwat, G., Dao-Tran, M., Dodaro, C., Ianni, G., Krennwallner,
T., Kronegger, M., Oetsch, J., Pfandler, A., Pührer, J., Redl, C., Ricca, F., Schneider,
P., Schwengerer, M., Spendier, L. K., Wallner, J. P., & Xiao, G. (2013). The fourth
Answer Set Programming competition: Preliminary report.
T. C. (Eds.),
Apt, K. R. (2003).

In Cabalar, P., & Son,

LPNMR, Vol. 8148 of LNCS, pp. 4253. Springer.
Principles of Constraint Programming. Cambridge University Press.
281

De Cat, Denecker, Stuckey & Bruynooghe
Balduccini, M. (2011).

Industrial-size scheduling with ASP+CP.

In Delgrande, J. P., &

LPNMR, Vol. 6645 of LNCS, pp. 284296. Springer.
Knowledge Representation, Reasoning, and Declarative Problem Solving.

Faber, W. (Eds.),
Baral, C. (2003).

Cambridge University Press, New York, NY, USA.
Bonatti, P. A., Pontelli, E., & Son, T. C. (2008).

Credulous resolution for answer set

programming. In Fox, D., & Gomes, C. P. (Eds.),

AAAI, pp. 418423. AAAI Press.

Bruttomesso, R., Cimatti, A., Franzén, A., Griggio, A., Hanna, Z., Nadel, A., Palti, A.,
& Sebastiani, R. (2007).
verication problems.

A lazy and layered SMT(BV) solver for hard industrial

In Damm, W., & Hermanns, H. (Eds.),

LNCS, pp. 547560. Springer.

CAV,

Vol. 4590 of

Calimeri, F., Ianni, G., & Ricca, F. (2014). The third open answer set programming competition.

TPLP, 14 (1), 117135.

Chen, W., & Warren, D. S. (1996). Tabled evaluation with delaying for general logic programs.

J. ACM, 43 (1), 2074.

Claessen, K., & Sörensson, N. (2003).

New techniques that improve MACE-style model

Proceedings of the CADE-19 Workshop: Model Computation - Principles,
Algorithms, Applications.
nding. In

Dal Palù, A., Dovier, A., Pontelli, E., & Rossi, G. (2009). Answer set programming with
constraints using lazy grounding. In Hill, P. M., & Warren, D. S. (Eds.),
5649 of

LNCS, pp. 115129. Springer.

Dao-Tran, M., Eiter, T., Fink, M., Weidinger, G., & Weinzierl, A. (2012).

ICLP,

Vol.

Omiga : An

open minded grounding on-the-y answer set solver. In del Cerro, L. F., Herzig, A.,

JELIA, Vol. 7519 of LNCS, pp. 480483. Springer.
Cat, B. (2014). Separating Knowledge from Computation: An FO(.) Knowledge Base
System and its Model Expansion Inference. Ph.D. thesis, KU Leuven, Leuven, Belgium.
& Mengin, J. (Eds.),

De

De Cat, B., Bogaerts, B., Bruynooghe, M., & Denecker, M. (2014).
modelling language: The IDP system.

CoRR, abs/1401.6312.

Predicate logic as a

De Cat, B., Bogaerts, B., Devriendt, J., & Denecker, M. (2013). Model expansion in the
presence of function symbols using constraint programming. In

ICTAI, pp. 10681075.

IEEE.
De Cat, B., Denecker, M., & Stuckey, P. J. (2012). Lazy model expansion by incremental
grounding. In Dovier, A., & Costa, V. S. (Eds.),

ICLP (Technical Communications),

LIPIcs, pp. 201211. Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik.
Delgrande, J. P., & Faber, W. (Eds.). (2011). Logic Programming and Nonmonotonic Reasoning - 11th International Conference, LPNMR 2011, Vancouver, Canada, May 16-19,
2011. Proceedings, Vol. 6645 of LNCS. Springer.
Vol. 17 of

Denecker, M. (1998). The well-founded semantics is the principle of inductive denition. In
Dix, J., del Cerro, L. F., & Furbach, U. (Eds.),
Springer.

282

JELIA, Vol. 1489 of LNCS, pp. 116.

Lazy Model Expansion: Interleaving Grounding with Search
Denecker, M. (2000). Extending classical logic with inductive denitions. In Lloyd, J. W.,
Dahl, V., Furbach, U., Kerber, M., Lau, K.-K., Palamidessi, C., Pereira, L. M., Sagiv,
Y., & Stuckey, P. J. (Eds.),

CL, Vol. 1861 of LNCS, pp. 703717. Springer.

Denecker, M., Bruynooghe, M., & Marek, V. W. (2001). Logic programming revisited: Logic
programs as inductive denitions.

ACM Trans. Comput. Log., 2 (4), 623654.

Denecker, M., & De Schreye, D. (1992). Justication semantics: A unifying framework for
the semantics of logic programs.

Tech. rep. 157, Department of Computer Science,

K.U.Leuven.
Denecker, M., & De Schreye, D. (1993). Justication semantics: A unifying framework for
the semantics of logic programs. In Pereira, L. M., & Nerode, A. (Eds.),

LPNMR, pp.

365379. MIT Press.
Denecker, M., Lierler, Y., Truszczynski, M., & Vennekens, J. (2012).
mal semantics for answer set programming.

ICLP (Technical Communications),

Vol. 17 of

A Tarskian infor-

In Dovier, A., & Costa, V. S. (Eds.),

LIPIcs,

pp. 277289. Schloss Dagstuhl

- Leibniz-Zentrum fuer Informatik.
Denecker, M., & Ternovska, E. (2008). A logic of nonmonotone inductive denitions.

Trans. Comput. Log., 9 (2), 14:114:52.

ACM

Denecker, M., & Vennekens, J. (2014). The well-founded semantics is the principle of inductive denition, revisited. In Baral, C., De Giacomo, G., & Eiter, T. (Eds.),

KR,

pp.

2231. AAAI Press.
Denecker, M., Vennekens, J., Bond, S., Gebser, M., & Truszczy«ski, M. (2009). The second
answer set programming competition.

In Erdem, E., Lin, F., & Schaub, T. (Eds.),

LPNMR, Vol. 5753 of LNCS, pp. 637654. Springer.
Detlefs, D., Nelson, G., & Saxe, J. B. (2005).
checking.

J. ACM, 52 (3), 365473.

Simplify: A theorem prover for program

Technical Communications of the 28th International Conference on Logic Programming, ICLP 2012, September 4-8, 2012, Budapest,
Hungary. Proceedings, Vol. 17 of LIPIcs. Schloss Dagstuhl - Leibniz-Zentrum fuer In-

Dovier, A., & Costa, V. S. (Eds.). (2012).

formatik.
Drescher, C., & Walsh, T. (2012). Answer set solving with lazy nogood generation. In Dovier,
A., & Costa, V. S. (Eds.),

ICLP (Technical Communications),

Vol. 17 of

LIPIcs,

pp.

188200. Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik.
Eiter, T., Ianni, G., Schindlauer, R., & Tompits, H. (2005). A uniform integration of higherorder reasoning and external evaluations in answer-set programming.

In Kaelbling,

IJCAI, pp. 9096. Professional Book Center.
A Mathematical Introduction To Logic (Second edition).

L. P., & Saotti, A. (Eds.),
Enderton, H. B. (2001).

Academic

Press.

Logic Programming and Nonmonotonic Reasoning, 10th International Conference, LPNMR 2009, Potsdam, Germany, September
14-18, 2009. Proceedings, Vol. 5753 of LNCS. Springer.

Erdem, E., Lin, F., & Schaub, T. (Eds.). (2009).

283

De Cat, Denecker, Stuckey & Bruynooghe
Ge, Y., & de Moura, L. M. (2009). Complete instantiation for quantied formulas in satisabiliby modulo theories. In Bouajjani, A., & Maler, O. (Eds.),

LNCS, pp. 306320. Springer.

CAV,

Vol. 5643 of

Gebser, M., Kaminski, R., Kaufmann, B., Ostrowski, M., Schaub, T., & Thiele, S. (2008).
Engineering an incremental ASP solver.
(Eds.),

In García de la Banda, M., & Pontelli, E.

ICLP, Vol. 5366 of LNCS, pp. 190205. Springer.

Gebser, M., Kaminski, R., König, A., & Schaub, T. (2011). Advances in Gringo series 3.
In Delgrande, J. P., & Faber, W. (Eds.),

LPNMR,

Vol. 6645 of

LNCS,

pp. 345351.

Springer.
Gebser, M., Schaub, T., & Thiele, S. (2007).

GrinGo : A new grounder for Answer Set

Programming. In Baral, C., Brewka, G., & Schlipf, J. S. (Eds.),

LNCS, pp. 266271. Springer.

Hähnle, R. (2001).
(Eds.),

Tableaux and related methods.

LPNMR, Vol. 4483 of

In Robinson, J. A., & Voronkov, A.

Handbook of Automated Reasoning, pp. 100178. Elsevier and MIT Press.

Jackson, E. K., Bjorner, N., & Schulte, W. (2013).

Open-world logic programs: A new

foundation for formal specications. Tech. rep. MSR-TR-2013-55, Microsoft Research.
Jansen, J., Jorissen, A., & Janssens, G. (2013). Compiling input∗

3
into tabled Prolog rules for IDP .

FO(·) inductive denitions

TPLP, 13 (4-5), 691704.

Karp, R. (1972). Reducibility among combinatorial problems. In Miller, R., & Thatcher, J.
(Eds.),

Complexity of Computer Computations, pp. 85103. Plenum Press.

Kimmig, A., Demoen, B., De Raedt, L., Santos Costa, V., & Rocha, R. (2011).
implementation of the probabilistic logic programming language ProbLog.

11 (2-3), 235262.

Lefèvre, C., & Nicolas, P. (2009).

On the

TPLP,

The rst version of a new ASP solver: ASPeRiX.

Erdem, E., Lin, F., & Schaub, T. (Eds.),

LPNMR,

Vol. 5753 of

LNCS,

In

pp. 522527.

Springer.
Leone, N., Pfeifer, G., Faber, W., Eiter, T., Gottlob, G., Perri, S., & Scarcello, F. (2006).
The DLV system for knowledge representation and reasoning.

Log., 7 (3), 499562.

ACM Trans. Comput.

Liu, G., Janhunen, T., & Niemelä, I. (2012). Answer Set Programming via Mixed Integer
Programming.

In Brewka, G., Eiter, T., & McIlraith, S. A. (Eds.),

KR,

pp. 3242.

AAAI Press.
Marek, V. W., & Truszczy«ski, M. (1999).
gramming paradigm.
D. S. (Eds.),

Stable models and an alternative logic pro-

In Apt, K. R., Marek, V. W., Truszczy«ski, M., & Warren,

The Logic Programming Paradigm: A 25-Year Perspective,

pp. 375398.

Springer-Verlag.
Mariën, M. (2009).

Model Generation for ID-Logic.

Ph.D. thesis, Department of Computer

Science, KU Leuven, Belgium.
Mariën, M., Gilis, D., & Denecker, M. (2004). On the relation between ID-Logic and answer
set programming. In Alferes, J. J., & Leite, J. A. (Eds.),
pp. 108120. Springer.

284

JELIA,

Vol. 3229 of

LNCS,

Lazy Model Expansion: Interleaving Grounding with Search
Mariën, M., Wittocx, J., Denecker, M., & Bruynooghe, M. (2008). SAT(ID): Satisability of
propositional logic extended with inductive denitions. In Kleine Büning, H., & Zhao,
X. (Eds.),

SAT, Vol. 4996 of LNCS, pp. 211224. Springer.

Marple, K., Bansal, A., Min, R., & Gupta, G. (2012). Goal-directed execution of answer
set programs. In Schreye, D. D., Janssens, G., & King, A. (Eds.),

PPDP,

pp. 3544.

ACM.
Marques Silva, J. P., Lynce, I., & Malik, S. (2009).

Conict-driven clause learning SAT

Handbook of
Satisability, Vol. 185 of Frontiers in Articial Intelligence and Applications, pp. 131
solvers.

In Biere, A., Heule, M., van Maaren, H., & Walsh, T. (Eds.),

153. IOS Press.
Metodi, A., & Codish, M. (2012). Compiling nite domain constraints to SAT with BEE.

TPLP, 12 (4-5), 465483.

Mitchell, D. G., & Ternovska, E. (2005).

A framework for representing and solving NP

search problems. In Veloso, M. M., & Kambhampati, S. (Eds.),

AAAI,

pp. 430435.

AAAI Press / The MIT Press.
Mitchell, D. G., Ternovska, E., Hach, F., & Mohebali, R. (2006).

Model expansion as a

framework for modelling and solving search problems. Tech. rep. TR 2006-24, Simon
Fraser University, Canada.
Nethercote, N., Stuckey, P., Becket, R., Brand, S., Duck, G., & Tack, G. (2007). Minizinc:
Towards a standard CP modelling language. In Bessiere, C. (Ed.),
of

LNCS, pp. 529543. Springer.

CP'07,

Vol. 4741

Nightingale, P., Gent, I. P., Jeerson, C., & Miguel, I. (2013). Short and long supports for
constraint propagation.

J. Artif. Intell. Res. (JAIR), 46, 145.

Ohrimenko, O., Stuckey, P. J., & Codish, M. (2009). Propagation via lazy clause generation.

Constraints, 14 (3), 357391.

Ostrowski, M., & Schaub, T. (2012).

12 (4-5), 485503.

ASP modulo CSP: The clingcon system.

Riedel, S. (2009). Cutting plane MAP inference for Markov logic. In

on Statistical Relational Learning (SRL-2009).

Saptawijaya, A., & Pereira, L. M. (2013).

TPLP,

International Workshop

Towards practical tabled abduction in logic

programs. In Correia, L., Reis, L. P., & Cascalho, J. (Eds.),

EPIA, Vol. 8154 of LNCS,

pp. 223234. Springer.
Singla, P., & Domingos, P. (2006). Memory-ecient inference in relational domains. In Gil,
Y., & Mooney, R. J. (Eds.),

AAAI, pp. 488493. AAAI Press.

Son, T. C., Pontelli, E., & Le, T. (2014).

Two applications of the ASP-Prolog system:

Decomposable programs and multi-context systems. In Flatt, M., & Guo, H.-F. (Eds.),

PADL, Vol. 8324 of Lecture Notes in Computer Science, pp. 87103. Springer.

Tamura, N., Taga, A., Kitagawa, S., & Banbara, M. (2009). Compiling nite linear CSP
into SAT.

Constraints, 14 (2), 254272.

285

De Cat, Denecker, Stuckey & Bruynooghe
Torlak, E., Chang, F. S.-H., & Jackson, D. (2008). Finding minimal unsatisable cores of
declarative specications. In Cuéllar, J., Maibaum, T. S. E., & Sere, K. (Eds.),
Vol. 5014 of

LNCS, pp. 326341. Springer.

FM,

Tseitin, G. S. (1968). On the complexity of derivation in propositional calculus. In Slisenko,
A. O. (Ed.),

Studies in Constructive Mathematics and Mathematical Logic II, pp. 115

125. Consultants Bureau, N.Y.
Van Gelder, A. (1993). The alternating xpoint of logic programs with negation.

Syst. Sci., 47 (1), 185221.

J. Comput.

Vennekens, J., Mariën, M., Wittocx, J., & Denecker, M. (2007). Predicate introduction for
logics with a xpoint semantics. Part I: Logic programming.

79 (1-2), 187208.

Fundamenta Informaticae,

Wittocx, J., Denecker, M., & Bruynooghe, M. (2013). Constraint propagation for rst-order
logic and inductive denitions.

ACM Trans. Comput. Logic, 14 (3), 17:117:45.

Wittocx, J., Mariën, M., & Denecker, M. (2008). The

idp system: A model expansion system

for an extension of classical logic. In Denecker, M. (Ed.),

LaSh, pp. 153165. ACCO.

Wittocx, J., Mariën, M., & Denecker, M. (2010). Grounding FO and FO(ID) with bounds.

J. Artif. Intell. Res. (JAIR), 38, 223269.

286

Journal of Artificial Intelligence Research 52 (2015) 477-505

Submitted 10/14; published 04/15

A Case-Based Reasoning Framework to Choose Trust Models for
Different E-Marketplace Environments
Athirai A. Irissappane
Jie Zhang

ATHIRAI 001@ E . NTU . EDU . SG
ZHANGJ @ NTU . EDU . SG

School of Computer Engineering
Nanyang Technological University, Singapore

Abstract
The performance of trust models highly depend on the characteristics of the environments
where they are applied. Thus, it becomes challenging to choose a suitable trust model for a given
e-marketplace environment, especially when ground truth about the agent (buyer and seller) behavior is unknown (called unknown environment). We propose a case-based reasoning framework to
choose suitable trust models for unknown environments, based on the intuition that if a trust model
performs well in one environment, it will do so in another similar environment. Firstly, we build a
case base with a number of simulated environments (with known ground truth) along with the trust
models most suitable for each of them. Given an unknown environment, case-based retrieval algorithms retrieve the most similar case(s), and the trust model of the most similar case(s) is chosen as
the most suitable model for the unknown environment. Evaluation results confirm the effectiveness
of our framework in choosing suitable trust models for different e-marketplace environments.

1. Introduction
In multiagent e-marketplaces, self-interested selling agents may act maliciously by not delivering
products with the same quality as promised. It is thus important for buying agents to reason about the
trustworthiness (quality) of sellers in providing good quality products and determine which sellers
to do business with. However, in such open and large environments, buyers often encounter sellers
with which they have no previous experience. In this case, buyers often obtain advice (i.e., ratings)
about the sellers from other buyers (called advisors). However, some advisors may be dishonest and
provide unfair ratings, to promote or demote some sellers (Irissappane, Oliehoek, & Zhang, 2014).
Many trust models (Sabater & Sierra, 2005) have been proposed to assess seller trustworthiness, some of which, such as BLADE (Regan, Poupart, & Cohen, 2006), also address the unfair
rating problem. However, the performance (accuracy in predicting seller trustworthiness) of trust
models is often highly affected by the characteristics of the environments where they are applied.
Specifically, Fullam and Barber (2007) found out that the performance of trust models is influenced by environmental settings such as frequency of transactions, honesty of sellers and accuracy
of advisors’ ratings. A detailed comparison between BRS (Whitby, Jøsang, & Indulska, 2004),
TRAVOS (Teacy, Patel, Jennings, & Luck, 2006) and Personalized (Zhang & Cohen, 2008) (see
Sec. 2 for details) has been conducted by Zhang (2009) in a simulated dynamic e-marketplace environment. The results show that 1) BRS performs the best when buyers do not have much experience
with sellers in the environment and the majority of advisors provide fair ratings about sellers; 2)
TRAVOS has the advantage in the scenario where buyers have sufficient experience but advisors

c
2015
AI Access Foundation. All rights reserved.

I RISSAPPANE & Z HANG

only lie about some specific sellers and 3) Personalized fares well when the majority of advisors are
dishonest and sellers widely change their behavior over time.
In addition, almost all trust models rely on certain tuning parameters which may significantly
affect their performance. For example, to identify a dishonest advisor, BRS uses the quantile parameter (q) to determine whether the trustworthiness of a seller falls between q quantile and 1 − q
quantile of the distribution formed by the advisor’s ratings to the seller. TRAVOS has the bin parameter to divide [0, 1] into bin number of equal intervals, and Personalized uses the parameter of the
minimum number of ratings required by buyers to have accurate modeling of seller trustworthiness.
Further, most trust models have only been evaluated in simulated e-marketplace environments,
where ground truth i.e., the actual truth about agents’ malicious behavior is known upfront, such as
whether sellers deliver products with lower quality than what they promised and whether advisors
provide unfair ratings. In simulated environments, the performance of trust models with specific
parameter values can be evaluated, and the best models can then be easily chosen. However, for real
e-marketplaces, it is difficult to obtain ground truth because it is expensive or time consuming to
manually inspect every transaction. Even if we manage to find ground truth for a few real environments, we cannot guarantee that the best models in these environments will be the most suitable for
all other environments. In addition, environments may keep changing, and a suitable model for an
environment in one period may not be so in another period. Thus, choosing suitable trust models for
real environments (where ground truth about agents’ behavior is unknown, hence called unknown
environments) is challenging and not well addressed, but important for practical applications.
In this paper, we propose a novel Case-Based Reasoning (CBR) framework to choose suitable
trust models for unknown e-marketplace environments. CBR is a well-known artificial intelligence
technique, which can be applied to complicated and unstructured problems relatively easily (Sormo,
Cassens, & Aamodt, 2005). The fundamental concept in CBR is that similar problems will have
similar solutions, with the advantage of learning continuously by just adding new cases to the case
base. For the problem of choosing trust models, a similar intuition is that if a trust model performs
well in one environment, it will do so in another similar environment. Thus, CBR becomes a
suitable technique to address the problem by finding the trust models that are suitable for similar emarketplace environments (i.e., similar problems). Specifically, in the proposed framework, we first
find out the best trust models with their best parameter settings in a set of simulated environments,
representing the case base. For a given unknown real environment, we find the most similar case(s)
from the case base using case-based retrieval methods (Watson & Marir, 1994) such as k-nearest
neighbors, K-dimension (K-d) trees, decision trees, etc. The trust model of the most similar case(s)
is then chosen to be the most suitable trust model for the unknown environment.
The presented work is an extension to our previous work (Irissappane, Jiang, & Zhang, 2013),
which describes a simple framework to choose trust models using similarity based computation. In
this paper, we make a number of additional contributions: 1) we formalize the framework to choose
trust models using a case-based reasoning paradigm. Doing so, we have explored CBR techniques
i.e., case representation and retrieval methodologies, to choose suitable trust models in an efficient
manner; 2) we introduce additional case indexing and retrieval schemes, K-d trees and decision trees
apart from k-nearest neighbors; 3) we introduce feature weights (in addition to feature selection),
to improve the accuracy in determining the nearest neighbors in k-nearest neighbors and K-d tree
retrieval techniques. While the above are contributions from the research perspective, we have also
conducted more extensive and detailed experimentation to further demonstrate the effectiveness of
the framework. Experimental results show that with a very high probability, our framework can
478

A F RAMEWORK TO C HOOSE T RUST M ODELS FOR D IFFERENT E-M ARKETPLACES

choose the most suitable trust models to evaluate seller trustworthiness for different unknown environments. Evaluations also indicate that seller trustworthiness evaluated using trust models chosen
by our framework in a set of different e-market environments is more accurate than applying any
specific trust model with its best parameter values in those environments. Specifically, the additional
experiments: 1) justify the impact of using suitable trust models in e-marketplaces by demonstrating
that suitable trust models produce more accurate estimate of seller trustworthiness and help buyers
to make informed decisions, thereby resulting in greater utility for buyers than when using other
(unsuitable) trust models; 2) consider an extended data set by increasing the number of cases in the
case base from 972 to 2268 and show that the performance of the framework has improved using
a larger case base; 3) compare the accuracy of k-nearest neighbors, K-d trees and decision trees in
choosing suitable trust models and show that k-nearest neighbors and K-d trees outperform decision
trees, while performing equally well; 4) compare the time complexity of the retrieval techniques,
showing that decision trees require slightly lesser retrieval time than K-d trees, which in turn require
lesser time than k-nearest neighbors; 5) show that adding weights to the features while determining the nearest neighbors in k-nearest neighbors and K-d trees improves the accuracy in choosing
suitable trust models by a slight margin; 6) demonstrate that if the buyer chooses to aggregate the
outcomes of all the trust models to determine seller trustworthiness instead of using a single most
suitable trust model, it results in a high margin of error; 7) analyze the time complexity involved in
extending the framework by adding new features to represent the environments in the case base and
adding new defense models, both of which will improve the accuracy of the framework.
The rest of the paper is organized as follows. In Sec. 2, we provide an overview of the related
research on choosing trust models. We clearly point out the shortcomings of the existing approaches,
and explain how we cope with those shortcomings in our work. Sec. 3 describes the background on
case-based reasoning. The detailed description of the framework is presented in Sec. 4. Here, we
also describe how the framework can be extended to accommodate more trust models and different
e-marketplace environments. In Sec. 5, we present the experimental results using seven trust models
to demonstrate the accuracy of the framework (using k-nearest neighbors, K-d tree and decision tree
retrieval) in correctly selecting the most suitable trust models for unknown environments. Finally,
Sec. 6 concludes the current work and proposes future work.

2. Related Work
Here, we provide an overview of the existing trust models and frameworks to choose trust models.
2.1 Trust Models
Many trust models have been proposed in the literature. The Beta Reputation System (BRS) (Jøsang
& Ismail, 2002) models seller trustworthiness as the expected value of the beta probability distribution of the (binary) ratings given by the advisors to the seller. To handle unfair ratings provided
by advisors, Whitby et al. (2004) extend BRS to filter out those ratings that are not in the majority
amongst other ones by using the Iterated Filtering approach. Specifically, if the cumulated trustworthiness score of a seller falls in the rejection area (q quantile or 1 − q quantile) of the beta
distribution of an advisor’s ratings to that seller, the advisor will be considered dishonest and filtered out. However, the Iterated Filtering approach is only effective when a significant majority of
the ratings are fair, thereby leading to lower performance when the number of dishonest advisors is
large. Teacy et al. (2006) propose TRAVOS to evaluate advisor trustworthiness, using it to discount
479

I RISSAPPANE & Z HANG

their ratings before being aggregated to evaluate seller quality. TRAVOS divides the interval of
[0, 1] into bin number of equal bins to determine the previous advice provided by the advisor that
are similar to its current advice. Two pieces of advice are similar if they are within the same bin.
The trustworthiness of the advisor is then calculated as the expected value of the beta probability
density function representing the amount of the successful and unsuccessful interactions between
the buyer and the seller based on the previous advice. However, this model assumes that sellers
behave consistently towards all the buyers in the e-marketplace, which might not be true in many
cases. Yu and Singh (2003) use belief theory to represent trustworthiness scores. To determine
seller quality, they rely on a referral network to find advisors, and thereby combine the beliefs of
the advisors regarding the seller. The referral process begins with the buyer initially contacting a
pre-defined number of neighbors/advisors, who may give an opinion about the seller or refer other
advisors and continues until termination is reached. The referral process terminates in success when
an opinion is received from an advisor and in failure when the depth limit of the referral network
is reached or when it arrives at an advisor who neither gives an opinion nor a referral. Weights are
also assigned to each advisor, in order to identify the deceptive ones.
The BLADE approach (Regan et al., 2006) applies Bayesian learning to reinterpret advisors’
ratings instead of filtering the unfair ones. By establishing a correlation between seller properties
and advisors’ ratings, the buyer can infer advisors’ subjective evaluation functions to derive certain
properties of the seller. Though the reinterpretation helps to cope with advisors’ subjectivity and
deception simultaneously, a significant amount of evidence (ratings) is required to accurately determine the behavior of the advisors. Thereby, BLADE cannot perform effectively in sparse scenarios,
where buyers do not have sufficient ratings to the sellers. In the personalized approach (Zhang &
Cohen, 2008), the trustworthiness of a seller takes into account both the buyer’s personal experience with the seller and the public knowledge about the seller. When the buyer has enough private
information about (personal experience with) the seller (determined by the minimum number of
transactions with the seller using the acceptable level of error  and a confidence level γ), the buyer
uses private knowledge alone, otherwise it uses an aggregation of both the private and public knowledge to compute the trustworthiness of the seller. A similar approach is used to compute advisor
trustworthiness. Prob-Cog (Noorian, Marsh, & Fleming, 2011) is a two-layered cognitive approach
to filter the ratings provided by advisors, based on the similarity between the ratings of the buyer
and those of the advisor and the advisors’ behavioral characteristics. In the first layer, advisors are
filtered out if the average difference between the advisors’ opinions and the buyer’s personal ratings
exceeds a threshold value µ. In the second layer, the approach recognizes the behavioral characteristics of the advisors who have passed the first layer and subjectively evaluates their degree of
trustworthiness. The approach has the advantage that it proposed the idea to differentiate advisors’
behavior patterns. However, Prob-Cog assumes advisors’ behavior to be consistent across all sellers,
thereby making it inefficient when they dynamically change behavior by behaving honestly towards
some sellers while being dishonest to others. The iCLUB approach (Liu et al., 2011) adopts a clustering technique DBSCAN, to filter out dishonest advisors based on local and global information.
DBSCAN works by grouping points which are density-reachable i.e., not farther away than a given
distance θ from each other. It also requires a pre-defined minimum number of points minP ts to
form a dense region i.e., a cluster to be specified. In iCLUB, the DBSCAN clusters are formed using
the ratings given by the buyer and advisors to the sellers. For a target seller, if advisors’ ratings are
not in the cluster containing the active buyer’s ratings, the advisors are considered to be dishonest.

480

A F RAMEWORK TO C HOOSE T RUST M ODELS FOR D IFFERENT E-M ARKETPLACES

When the buyer has no sufficient direct experience with the target seller (number of transactions is
less than threshold τ ), the same process is applied on the non-target sellers.
As we can see, the performance of each trust model mentioned above varies depending on the
environmental settings (especially buyer and seller behavior), where they are applied. Each trust
model may not be the most suitable model for all the environments. Thus, for a given unknown
environment, it is necessary to choose from among a pool of trust models, in order to accurately
assess seller trustworthiness and choose a good quality seller for a transaction.
2.2 Existing Frameworks to Choose Trust Models
Only a few approaches have been proposed to choose trust models. For example, Hang, Wang and
Singh (2009) make use of explicitly indicated trust relationships by users in real-world systems
(e.g., FilmTrust) to evaluate trust models. For a weighted graph with vertices denoting agents and
edges representing the direct relationship of trust from the agent at the source vertex to the agent at
the target vertex, the weight (extent of trust between the agents at the vertices) of a particular edge
can be determined from other relevant edges. For evaluation, an edge is temporarily removed and
the weight on the edge is estimated. The accuracy in predicting the weight on the edge determines
the effectiveness of the trust model. The major drawback with this method is that users may lie
about their trust relationships, which in turn may affect the evaluation process. Some works (Wang,
Hang, & Singh, 2011; Irissappane & Zhang, 2014) use data from real-world e-markets (e.g., eBay
and Amazon) to evaluate the performance of trust models by their accuracy in predicting ratings of
given transactions (i.e., for each seller, the ratings of the previous i transactions are used to predict
the (i + 1)th rating to the seller). However, the ground truth about whether the ratings of those
transactions are unfair may be unknown. One may argue that we can rely on buyers themselves to
choose trust models because they know their true experience with sellers. But, it will be costly for
buyers to evaluate each trust model with various parameters in the given environment.
Closely related to our work is the Personalized Trust Framework (PTF) (Huynh, 2009) that selects an appropriate trust model for a particular environment based on users’ choice. Here, users
can specify how to select a trust model based on the information about whose trustworthiness is
to be evaluated and the configuration of trust models. In the framework, 1) a subject whose trustworthiness is to be evaluated is first sent to the trust manager. The trust manager stores many trust
profiles which contain rules suggested by the end users, regarding which trust model to use for
which subject; 2) the trust manager matches the subject’s information with the trust profiles to find
a suitable trust model and initializes the trust engine for the selected model; 3) the selected trust
model then derives the trust value of the subject. PTF relies entirely on human intervention (users
specify rules to select trust models). Though it is possible to identify certain rules to determine the
most suitable trust model for some environments (e.g., BRS performs well when majority advisors
are honest, BLADE performs well when advisors have subjective differences, etc.), it is impossible
to know which models will perform the best in complex real world environments as they may have
a variety of buyer and seller behavior. Also, the ground truth about the honesty and subjectivity of
buyers and sellers is extremely challenging to determine, resulting in rules that will only be partial
and thus insufficient to accurately choose suitable trust models when using PTF. On the other hand,
in our case-based reasoning framework, we compare the properties of the unknown environment
with existing cases in the case-base using an automated approach and choose suitable trust models,
which are shown to be highly accurate through our experiments in Sec. 5.

481

I RISSAPPANE & Z HANG

3. Background
Case-Based Reasoning (CBR) is the process of solving new problems based on the solutions of
similar past problems. Conceptually, CBR is commonly described by the CBR-cycle (Aamodt &
Plaza, 1994). The CBR-cycle comprises of four activities: retrieve, reuse, revise and retain.
In the retrieve phase, one or more cases, similar to the new problem are selected from the case
base. Many case-based retrieval algorithms exist in literature (Watson & Marir, 1994). Nearest
neighbor techniques (Duda & Hart, 1973) are perhaps the most widely used retrieval techniques
in CBR. Distance measures such as Euclidean distance can be employed to identify the nearest
neighbors (cases). Despite its simplicity, nearest neighbor retrieval has been successful in a large
number of classification problems (Hastie, Tibshirani, & Friedman, 2009). However, when the case
base grows, the efficiency of retrieval decreases, as an increasing number of cases must be taken into
account to find the most similar case. K-d trees (Wess, Althoff, & Derwand, 1994), which organize
the case base into a binary tree structure have been shown to reduce the complexity in the retrieval of
the nearest neighbors. Alternatively, inductive retrieval algorithms (Soltani, 2013; Watson, 1999),
determining which features do the best job in discriminating cases and generate a decision tree type
structure to organize the cases in memory, can also be used to improve retrieval efficiency.
When one or more similar cases have been retrieved, the solution (or other problem solving
information) contained in these cases is reused to solve the current problem. Reusing a retrieved
solution can be quite simple, if the solution is returned unchanged as the proposed solution for the
new problem. This is specifically the case for classification tasks with a limited number of solutions
(classes) and a large number of cases. In such scenarios, every potential solution is contained in the
case base and hence adaptation is usually not required. On the other hand, for synthetic tasks (such
as configuration or planning) solution adaptation for the new problem is necessary.
In the revise phase, the solution determined so far is verified in the real world and possibly
corrected or improved, e.g., by a domain expert. Finally, the retain phase takes the feedback from
the revise phase and updates the knowledge, particularly the case base and the new problem solving
experience becomes available for reuse in future problem solving episodes.
The major challenge in CBR resides in the retrieval of existing cases that are sufficiently similar
to the new problem. Since e-marketplace environments with ground truth (existing cases) may not
exist (or may be difficult to obtain), in our framework, we have to create them by simulations. In
addition, in our framework, the features (characteristics of the e-marketplace environments) used
to represent the cases in the case base are not known beforehand. We thus have to come up with
an exhaustive list of potential features (to describe the e-marketplace) and carefully select the most
relevant ones, in order to efficiently choose suitable trust models.

4. The Proposed Case-Based Reasoning Framework
Fig. 1 illustrates the detailed design of the framework. The most important component of the framework is the case base. To build the case base, we first simulate a large set of e-marketplace environments with known ground truth about the honesty of agents’ behavior. Given a set of available
trust models with specific values of their parameters (referred to as candidate trust models), we
evaluate their performance in each simulated environment, where the best model is identified and
forms a best environment-model pair (representing a case in the case base). In this process, we also
choose the most relevant features to represent the cases, for efficient retrieval. Given an unknown

482

A F RAMEWORK TO C HOOSE T RUST M ODELS FOR D IFFERENT E-M ARKETPLACES

real environment, the framework then extracts the set of carefully selected (most relevant) features
and determines the most similar case(s) from the case base using case-based retrieval techniques.
The trust model of the most similar case(s) is then reused as the solution for the unknown real environment. The given unknown environment along with the most suitable trust model is then retained
in the framework for reuse in the future problem solving episodes. The major components of the
framework and the detailed procedures are described in the following subsections.
Building the Case Base

Simulated
Environments

Case Retrieval

Candidate
Trust Models

Most Similar Case(s)

Feature Values of
Unknown Environment

Case Base

Feature Extraction and
Selection

Evaluate Candidate
Trust Models

(Environment, Model)
Unknown
Environment

Case Reuse
Most Relevant
Features

Most Suitable
Trust Model

Verify
Accuracy

Case Retain

Figure 1: Design of the case-based reasoning framework

4.1 The Case Base
CBR is heavily dependant on the structure and content of the case base. In our framework, a case
in the case base is described by an e-marketplace environment (represented by a set of carefully
selected features) along with the trust model which performs the best in the environment. Unlike
other domains, real e-marketplace environments with ground truth about the honesty of sellers and
buyers are rare and may not exist, hence it becomes challenging to build the case base. We will
mainly rely on simulations to create the existing cases in the case base.
4.1.1 E-M ARKETPLACE E NVIRONMENTS
An e-marketplace environment (E) consists of a set of sellers, a set of buyers, transactions (each of
which is between a seller and a buyer with a certain monetary value) and ratings (each of which is
given by a buyer to a seller at a specific time indicating whether the buyer is satisfied or not with the
transaction). So, E is a tuple,
E = hS, B, {Ts,b |s = 1...Ns , b = 1...Nb } , {Rs,b |s = 1...Ns , b = 1...Nb }i

(1)

where S represents the set of all sellers, B represents the set of all buyers, Ns and Nb are the
numbers of sellers and buyers in E, respectively. Rs,b denotes the set of ratings from buyer b to
seller s for the transactions Ts,b . Each rating rs,b ∈ Rs,b for the transaction ts,b ∈ Ts,b is a tuple,
rs,b = hid, s, b, hs , hb , t, vali
483

(2)

I RISSAPPANE & Z HANG

where id, s, b denote the rating index, index of the seller and that of the buyer, respectively.
hs (∈ [0, 1]) and hb (∈ {honest, dishonest}) denote the ground truth i.e., the actual seller trustworthiness and honesty of the buyer for this transaction, respectively. A dishonest seller (with low
trustworthiness) may advertise its products having high quality but actually deliver low quality ones
or not deliver at all. Also, a dishonest buyer may lie about its satisfaction level of a transaction by
providing an unfair rating. The hs and hb attributes help to distinguish such dishonest behaviors
from the honest ones. The time (integer value denoting the day of simulation) when the rating is
given is denoted by t. val denotes the actual value of the rating, which can be binary (e.g., 0 or 1),
multi-nominal (e.g., 1 - 5) or real (e.g., in the range [0, 1]).
There are two types of environments in our framework: 1) known environments (Eknown ), where
the ground truth about seller and buyer honesty is known. The known environments along with their
most suitable trust models help in building the case base for our framework; 2) unknown environments (Etest ) are those where ground truth is not known. They represent the test environments for
which the most suitable trust models need to be determined.
To build the case base, we will simulate a large number of Eknown environments, to cover as
many scenarios as possible and closely depict real-world environments. For example, we may simulate an environment with many sellers but fewer buyers (to represent a high provision e-marketplace)
or with many buyers but fewer sellers (to illustrate a competitive e-marketplace). We may simulate a
very sparse environment with few ratings provided by buyers, and a very dense environment where
each seller is flooded with a large number of ratings. We may also simulate different scenarios
where buyers are active or inactive in providing ratings. In these environments, we may also simulate sellers with different levels of honesty, and buyers launching different types of unfair rating
attacks (Hoffman et al., 2009), including for example, unfair ratings to only reputable or disreputable sellers, a lot or few unfair ratings, unfair ratings given in a short or long time period, etc.
4.1.2 C ANDIDATE T RUST M ODELS
As exemplified in Sec. 2, many trust models have been proposed to evaluate seller trustworthiness in
e-marketplaces. New trust models will also likely be proposed in the future. All these trust models
can be considered as candidate trust models in our framework. In addition, most of them have some
parameters to tune, which may result in different performance. Thus, a candidate trust model (T M )
is defined as a trust model with a specific value for each of its parameters. For a parameter varying
in a range, we divide its range into a number of equal intervals and randomly choose a value in each
interval. Ideally, the larger number of intervals is better.
4.1.3 F EATURE E XTRACTION AND S ELECTION
To formally represent an environment in the case base, each environment can be described by a
set of features, representing the characteristics of the environment (e.g., ratio of number of buyers
versus sellers, variance of ratings per seller or per buyer, average number of transactions per time
period, percentage of rated sellers, etc.). An exhaustive list of potential features is extracted from
which the most relevant features can be identified and used to represent the environment, in order to
reduce the computational cost and increase the efficiency of the framework. If F = {f1 , ..., fn } is
the set of all features and P (F̂ ) be the performance of the framework while using a subset F̂ ⊂ F
of features. The most relevant subset of features F̂ ∗ is chosen such that the framework achieves the
best performance, formalized by Eqn. 3.

484

A F RAMEWORK TO C HOOSE T RUST M ODELS FOR D IFFERENT E-M ARKETPLACES

F̂ ∗ = arg max P (F̂ )

(3)

F̂ ⊂F

Before constructing the case base, we simulate another set of e-marketplace environments and
evaluate the performance of our framework in these environments using all the possible features.
The features whose values significantly correlate to the performance of the framework are determined using five widely used correlation and regression analysis techniques, namely Pearson correlation, Kendall rank correlation, Spearman rank correlation, linear regression (backward) and linear
regression (stepwise). The results of the correlation are also analyzed by the Paired-Samples T-test
to check for statistical significance. Each correlation and regression analysis technique results in
a subset of significantly relevant features recognized by that technique (F̂ ⊂ F ). The most influential set of features (F̂ ∗ ) is then determined1 from the five subsets of features (each recognized
by the above five techniques, respectively) using Eqn. 3, the details of which will be presented in
Sec. 5.1.3. Thus, only the features in F̂ ∗ will be used to represent the environments in the case base.
4.1.4 B EST E NVIRONMENT-M ODEL PAIRS
Given a set of known environments and a set of candidate trust models, we find out in each environment (Eknown ), which candidate model (T M ) shows the best performance. Specifically, the
performance P (Eknown , T M ) is measured in terms of a performance metric, such as the Mean
Absolute Error (MAE) in determining seller trustworthiness, given by Eqn. 4, where Tstrue and
Tspredicted represent the actual and predicted trustworthiness of seller s, respectively. The lower the
MAE, the better is the performance of the trust model. The above evaluations result in a set of best
environment-model pairs (Eknown , T M ∗ ), which form the case base. If several models perform
equally best in an environment, we keep them all in the case base.
MAE =

1 X true
|Ts
− Tspredicted |
Ns

(4)

s∈S

4.2 Case Retrieval
Given an unknown environment Etest , case-based retrieval algorithms will retrieve the most similar
case(s), (Eknown , T M ) pair(s), whose simulated environment Eknown is the most similar to Etest .
Every retrieval algorithm is a combination of a procedure for searching the case base to find the
most similar case and a similarity assessment procedure, which determines the similarity between
the given unknown environment Etest and a known environment Eknown in the case base.
Firstly, we will consider the structural manner in which cases are represented in the case base,
which plays a major role in the efficient retrieval of cases. The choice of such case representation
chiefly depends on the type of problems the CBR system is intended to solve, varying from relatively
simple feature-value vectors, to complex data-structures. In the framework, we propose to represent
the case base using two structural representations (Watson & Marir, 1994): 1) flat representation; 2)
hierarchical representation, and analyze the performance of the framework in both scenarios.
1. This feature selection process will be used to determine the most influential features only while using k-nearest
neighbors, K-d tree retrieval and not decision trees as it employs its own embedded feature selection methodology.

485

I RISSAPPANE & Z HANG

4.2.1 F LAT R EPRESENTATION
The simplest format to represent the cases in the case base is to have simple feature-value vectors
for the environments (Eqn. 5), obtained from the most influential features (more suitable for cases
with numeric feature values). In this flat memory model, all cases are organized at the same level
and no relationships between features or between cases are shown.
E =< fi | ∀fi ∈ F̂ ∗ >

(5)

Classical nearest neighbor (Duda & Hart, 1973) retrieval is a method of choice for the retrieval of
the cases with flat representation, as shown in Fig. 2. Given an unknown environment Etest , it is
compared with the cases in the case base and similar cases are found according to the similarity in
the features between Etest and Eknown environments, measured in terms of Euclidean distance,
sX
dist(Etest , Eknown ) =
(Etest (fi ) − Eknown (fi ))2
(6)
fi ∈F̂ ∗
∗

T M = arg max N (T M )

(7)

T M ∈TM

Additionally, we can also assign weights to the different features while calculating the distance in
Eqn. 6. In k-nearest neighbors, k cases, which are closest to Etest based on similarity, are retrieved
and the most similar case(s) are chosen by a majority vote, such that the suitable trust model of the
most similar case(s) occurs the maximum number of times among the k closest cases, as shown in
Eqn. 7, where N (T M ) represents the number of times the trust model T M appears in the k closest
cases, TM represents the set of all candidate trust models in the framework and T M ∗ represents the
trust model of the most similar case(s), which is the most suitable trust model for Etest .
The retrieval time in this memory organization is very high (O(|C|), where |C| is the number
of cases in the case base), since for each retrieval, all the cases in the case base must be compared
to the target case Etest , making it unsuitable for large case bases. However, this approach has been
verified to provide maximum accuracy and easy retention.
Case Retrieval
Case
Representation
Flat Storage

Feature Values of
Unknown Environment

Case Base
(Environment, Model)
Unknown
Environment

k-Nearest
Neighbors

Majority Vote
Case Reuse
Most Suitable
Trust Model

Figure 2: k-Nearest Neighbors retrieval

486

A F RAMEWORK TO C HOOSE T RUST M ODELS FOR D IFFERENT E-M ARKETPLACES

4.2.2 H IERARCHICAL R EPRESENTATION
For more efficient and rapid retrieval, a more structured representation of the cases is necessary,
because only a small subset of cases need to be considered during retrieval from a large case base.
Following a hierarchical representation helps to organize cases which share similar features under a
more generalized structure. We demonstrate the use of two hierarchical tree structures which differ
in their method of indexing (assigning indices to cases) but greatly improve the retrieval efficiency.
Case Retrieval

K-d Trees
Case
Representation

f1=m1
f2=m2
>

≤

(Environment, Model)

f2=m3

Bucket
(Eknown, TM)

>

f3=m4

….

Case Base

Feature Values of
Unknown Environment

>

≤

f3=m5

>

≤
Bucket
(Eknown, TM)

Bucket
(Eknown, TM)

Unknown
Environment

k-Nearest
Neighbors

Majority Vote
Case Reuse
Most Suitable
Trust Model

Figure 3: K-d Tree retrieval
Traditionally, K-dimensional (K-d) tree representation has been demonstrated to be very useful
to reduce the retrieval time of the similar cases using nearest neighbors (Wess et al., 1994). K-d
tree, where K represents the number of feature dimensions representing a case (i.e., K = |F̂ ∗ |), is
a multi-dimensional binary search tree that splits the case base into groups of cases in such a way
that each group contains cases that are similar to each other. Specifically, each node in the K-d
tree splits all its children along a specific feature, using a hyperplane that is perpendicular to the
corresponding axis. At the root (which contains the entire case base), all children are split based
on the first feature (f1 ∈ F̂ ∗ ), i.e., cases with f1 less than (or equal to) the root will be in the left
sub-tree and those greater than the root will be in the right sub-tree, as shown in Fig. 3. Each level
down the tree divides the cases on the next feature fi ∈ F̂ ∗ , returning to the first dimension f1 once
all other features have been exhausted. The leaves of the tree which contain a specific number of
cases are called buckets. For partitioning, the median point of the feature (f1 = m1 as shown in
Fig. 3) is selected for the root node and all cases with a smaller value (than m1 for f1 ) are placed to
the left and larger to the right. A similar procedure is followed for the left and right sub-trees until
the last trees to be partitioned are composed of few cases (not more than bucketsize).
For retrieval, a recursive search procedure is adopted. A queue containing k most similar cases
is maintained throughout the search. If the search examines a leaf node, the similarity of each case
in the bucket with the given unknown environment Etest , is computed using Eqn. 6 as in k-nearest
487

I RISSAPPANE & Z HANG

neighbors and the queue is updated. In case of a non-leaf node, the search is recursively called on
the child node, where Etest belongs (by comparing the features of Etest with the partitioning value
at each node). When this recursion terminates (at the non-leaf node), it is tested whether the other
child of the node needs to be examined (if the geometric boundaries delimiting the cases under the
node overlap the ball centered at Etest with radius equal to the similarity of the k th nearest neighbor
encountered so far, then the other child needs to be examined, and can be ignored otherwise). The
procedure (unwinding the recursive search) is repeated until the root is reached. After determining
the k most similar cases (present in the queue), the most suitable trust model is determined using
Eqn. 7. The average retrieval time for determining the k most similar cases in K-d trees is found to
be O(k × log|C|), where |C| is the size of the case base.
Another hierarchical organization frequently used in CBR is Decision trees. Decision trees are
induction-based models (Soltani, 2013) which learn general domain-specific knowledge from a set
of training data and represent the knowledge in the form of trees. Decision trees (when compared
to the other classes of learning methods), are quite fast, can be directly applied to the training
data without much pre-processing and produce relatively interpretable models (Hastie et al., 2009).
Unlike k-nearest neighbors and K-d trees, which use similarity based retrieval techniques, decision
trees learn rules in order to determine the most suitable trust model. They also have an implicit
feature selection process. Each node in the decision tree specifies a test of some feature attribute
(e.g., f1 in Fig. 4), and each branch descending from that node corresponds to possible values
(e.g., f1 ≤ v1 in Fig. 4 ) for this feature attribute. In making these trees, how much a feature
can discriminate the cases is calculated (e.g., with information gain of cases) and the feature with
highest discriminative power is located at the top of the tree. The calculation is again performed for
the remaining features, thereby building the tree in a top-down fashion. The solution i.e., the most
suitable trust model is located at the leaves of the tree. Algorithms developed for decision trees
Case Retrieval

Decision Trees

Case
Representation

f1

f2

Case Base
≤v2

(Environment, Model)

Feature Values of
Unknown Environment

>v1

≤v1

f3

>v2; ≤v3

>v3

>v4

≤v4

f4

f5
….

TM

Unknown
Environment

TM

Case Reuse
Most Suitable
Trust Model

Figure 4: Decision Tree retrieval
are mostly the variations of a top-down, greedy search algorithm exemplified by ID3 (Quinlan,
1986) and its successor C4.5 (Quinlan, 1993). The algorithms construct the decision tree using the
divide and conquer strategy i.e., they build the decision tree by recursively dividing the case base
into subsets according to a splitting criterion called the information gain ratio. The intuition is to
488

A F RAMEWORK TO C HOOSE T RUST M ODELS FOR D IFFERENT E-M ARKETPLACES

partition the case base in such a way that the information needed to classify a new case is reduced
as much as possible. Eqn. 8 represents the information gain (discriminative power) for a feature
fi ∈ F , regarding a set of cases C in the case base, where V (fi ) is the set of all possible values for
feature fi and Cv ∈ C is a set of cases with feature fi taking the value v. p(T M ) is the proportion
of cases in the case base for which trust model T M is the most suitable. Since decision trees have
such a built-in feature selection methodology, with the most influential features selected and used
in building the decision tree, we do not employ the feature selection process described in Sec. 4.1.3
before the case retrieval using decision trees, as it might affect the retrieval accuracy otherwise. For
retrieval, features of the unknown environment (Etest ) are compared with nodes in the tree, until it
gets to one of the leaves that contains the most suitable trust model (T M as shown in Fig. 4).
Inf ormationGain(fi , C) = Entropy(C) −

X
v∈V (fi )

where, Entropy(C) =

X

|Cv |
Entropy(Cv )
|C|

−p(T M ) log2 p(T M )

(8)
(9)

T M ∈TM

4.3 Case Reuse
After retrieving the most similar case(s) (using retrieval methods as discussed in the previous subsection) to the target case (Etest ), the framework needs to reason according to the retrieved cases
to find a reasonable and accurate solution (most suitable trust model) for Etest . The reuse of the
solution can be done in two ways (Soltani, 2013): 1) reusing the solution of the retrieved case
as the solution for the target case without any adaptation (applicable to classification problems);
2) adapting the retrieved solution to the target case, which is necessary for problem-solving tasks
such as design, configuration, and planning. Since we deal with a classification problem, by identifying to which class (candidate trust model in our case) a given unknown environment belongs,
we do not perform any adaption and simply reuse the solution of the retrieved case(s)2 . Thereby,
our framework will choose the trust model of the retrieved case(s) as the most suitable model for
Etest (using k-nearest neighbors and K-d trees, while for decision tree retrieval the framework will
directly choose the trust model suggested by the decision tree as no similar case(s) will be retrieved).
4.4 Case Retain
Case-based reasoning favors learning from experience. After choosing to reuse a solution from the
retrieved case(s) for Etest , it may be found that the solution is, in fact, incorrect, thus providing an
opportunity to learn from failure. Our framework offers a simple procedure, where the case solution
is evaluated and if the solution is incorrect, it is revised and the best solution for Etest is found.
Then the new case along with the best trust model (Etest , T M ∗ ) is retained in the case base (Fig. 1).
The proposed case-based reasoning framework is generic and can be further extended or concretized
in the following aspects: 1) whenever a new trust model is proposed, it can be added into the framework. Our framework is capable of taking advantage of the trust model to improve the performance
in evaluating seller trustworthiness; 2) whenever a new insightful feature is identified, it can be
added into the framework to participate in the feature selection process and in fact may further
improve the performance of the framework; 3) more promising feature selection methods such as
2. For more than one most similar cases, with different solutions, we randomly choose one of the solutions.

489

I RISSAPPANE & Z HANG

incremental hill-climbers (Wettschereck & Aha, 1995), a wrapper model to measure the importance
of features, can be adopted to enhance the performance of the framework and 4) more sophisticated
memory representations can be used for a more efficient and fast retrieval of the cases.

5. Experimentation
We instantiate our framework and conduct a series of experiments to demonstrate its effectiveness in
choosing suitable trust models. Firstly, we build the case base by generating a number of simulated
environments and finding the most suitable trust models for them. In this process, we also determine
the most influential features to represent the simulated environments in the case base. We then
generate unknown (both simulated and real) environments for testing and verify the performance of
the framework in choosing the best trust models for these unknown environments. We also compare
the performance of k-nearest neighbors (k-NN), K-d tree (K-dT) and decision tree (DT) retrieval
techniques, in finding the most suitable trust model for the given unknown environments.
5.1 The Case Base
The case base is built using a large set of simulated environments along with the most suitable
candidate trust models for the environments, as described below.
5.1.1 S IMULATED E NVIRONMENTS
In the framework, 2268 e-marketplace environments (Eknown ) are simulated, consisting of different numbers of sellers (chosen from {10, 25, 50}) with different levels of trustworthiness Tstrue ,
uniformly distributed over [0, 1]. Sellers provide good quality products with a probability Tstrue
when interacting with each of the buyers. Honest buyers always provide correct opinions (similar
to the actual seller trustworthiness Tstrue ) about the sellers, while dishonest buyers3 provide unfair ratings4 i.e., incorrect opinions which are complimentary to the actual seller trustworthiness
(1 − Tstrue ). We simulate different distributions of fair ratings given by honest buyers: 1) sparse,
where a honest buyer rates a seller at most once; 2) intensive, where a honest buyer rates a seller
more than once; 3) mixed, which is combination of sparse and intensive scenarios. We also simulate
different unfair rating attack scenarios for dishonest buyers by adjusting 4 parameters: 1) individual
attack frequency denoting the average number of unfair ratings provided by each dishonest buyer
which exhibit sparse, intensive or mixed behavior; 2) attack period referring to the period when
unfair ratings are given, where 7 and 100 denote that dishonest buyers provide unfair ratings over
one week (a concentrated attack) and 100 days (a distributed attack), respectively. While dishonest
buyers provide unfair ratings during the attack period, they behave honestly by providing fair ratings
outside the attack period. This helps to simulate dynamic environments where buyers change their
behaviors; (3) attack target taking a value of 0 or 1, indicating that attack targets are sellers with low
trustworthiness (Tstrue ≤ 0.5) or high trustworthiness (Tstrue > 0.5), respectively; 4) overall attack
rate denoting the ratio of number of unfair ratings to fair ratings, chosen from {0.25, 1, 4}. Through
the parameters of individual attack frequency and overall attack rate, the numbers of dishonest and
honest buyers are determined. The marketplaces operate for 100 days. The total number of ratings is chosen from {50, 75, 100, 150, 175, 200, 250}. We also limit the total number of ratings to
3. Buyers providing incorrect opinions due to subjective differences or ignorance are also considered dishonest.
4. Ratings in simulated environments are of the real type for being easily mapped to other types (binary, multi-nominal).

490

A F RAMEWORK TO C HOOSE T RUST M ODELS FOR D IFFERENT E-M ARKETPLACES

{50}, {50, 100}, {50, 100, 200} and {50, 100, 175, 250} to simulate 324, 648, 972 and 1296 environments, respectively, in order to examine the influence of the number of simulated environments
(size of the case base) on the performance of our framework.
5.1.2 C ANDIDATE T RUST M ODELS
The framework includes 7 representative trust models: BRS (Whitby et al., 2004), iCLUB (Liu
et al., 2011), TRAVOS (Teacy et al., 2006), Personalized (Zhang & Cohen, 2008), Referral Networks (Yu & Singh, 2003), BLADE (Regan et al., 2006) and Prob-Cog (Noorian et al., 2011). The
following parameters (as described in Sec. 2) are considered to design the candidate trust models:
1) for BRS, the quantile parameter q ∈ {0.05, 0.1, 0.3, 0.5}, which is used to filter dishonest buyers is considered; 2) for TRAVOS, the number of bins to determine the acceptable error level in
buyers’ ratings bin ∈ {2, 3, 5, 8, 10} is considered; 3) for Referral Networks, number of neighbors
∈ {2, 4, 6} and depth limit of referral networks ∈ {4, 6, 8} are considered; 4) for Personalized, error
level  ∈ {0.3, 0.5, 0.7} and confidence level γ ∈ {0.3, 0.5, 0.7} are considered; 5) for Prob-Cog,
we consider the threshold to filter out dishonest buyers µ ∈ {0.1, 0.2, . . . , 0.9}; 6) for iCLUB, we
consider the minimum number of ratings required to form a DBSCAN cluster minP ts ∈ [1, 6],
maximum neighbor distance θ ∈ [0.3, 0.7] and threshold to choose the local or global component
τ ∈ [3, 6]. In the end, we obtain 45 candidate trust models (TM) in total.
Features
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18

Pearson Kendall Spearman Backward Stepwise All
(C1)
(C2)
(C3)
(C4)
(C5) (C6)
Variance of the Percentage of Ratings for each Seller
∗
∗
Avg. Number of Ratings Provided by each Buyer for each Seller
∗
∗
∗
∗
∗
∗
Ratio of Number of Buyers versus Number of Sellers
∗
∗
∗
∗
Skewness of Rating Period
∗
∗
∗
∗
Variance of Percentage of Ratings Provided by each Buyer
∗
∗
∗
∗
∗
∗
Skewness of Number of Ratings Provided by each Buyer
∗
∗
∗
Percentage of Satisfactory Sellers
∗
∗
∗
∗
∗
∗
Number of Buyers
∗
∗
∗
∗
∗
Avg. Number of Ratings for each Seller
∗
∗
∗
∗
∗
∗
Variance of Number of Ratings provided by each Buyer
∗
∗
∗
Total Number of Ratings
∗
∗
∗
∗
∗
∗
Variance of Number of Ratings for each Seller
∗
∗
∗
∗
∗
∗
Skewness of Number of Ratings for each Seller
∗
∗
∗
∗
∗
Avg. Number of Transactions in each Day
∗
∗
∗
Total Percentage of Sellers Rated by Buyers
∗
∗
∗
∗
∗
∗
Time Period the Marketplace Operates
∗
∗
∗
∗
Maximum Percentage of Ratings for Sellers
∗
∗
∗
∗
∗
Total Percentage of Buyers who are Active in the Marketplace
∗
∗
∗
∗

Table 1: Selection of the most relevant features
5.1.3 F EATURE S ELECTION
We consider a set of 18 potential features (F ) to analyze the characteristics of the simulated environments, as listed in Table 1. We use some general statistical metrics to describe the features.
For example, variance refers to the spread of values, skewness describes the asymmetry from the
normal distribution, etc. A satisfactory seller refers to the one who receives more positive ratings
than negative ones from buyers. An active buyer refers to the buyer, who provides at least one rating
to any seller. The feature values for the simulated environments are extracted using the parameters
to generate the simulated environments, as described in Sec. 5.1.1. Since the features (in Table 1)
491

I RISSAPPANE & Z HANG

do not depend on the ground truth (buyer and seller honesty), it is also easier to extract such feature
values for unknown environments (with no ground truth).
To select the most relevant features (for efficient retrieval using k-NN and K-dT), we adopt
the five correlation and regression analysis techniques mentioned in Sec. 4.1.3. The results of the
analysis of the 18 features on how they are correlated to the performance (MAE) of the framework
is shown in Table 1. Here, ’*’ denotes that the feature has a significant correlation (after PairedSamples T-test) to the performance of the framework. In Table 1, columns C1, C2, C3, C4 and C5
represent the combination of the features flagged with ‘*’. C6 represents a combination of all the
features. To verify the effectiveness of the 6 feature combinations, we randomly generate a large
number of unknown environments and compare the results. We obtain an average MAE (using kNN retrieval5 ) of 0.44, 0.36, 0.36, 0.25, 0.33, 0.32 for the combinations C1, C2, C3, C4, C5 and C6,
respectively. C4 has the lowest MAE and is chosen as the set of most influential features (F̂ ∗ ), by
Eqn. 3. The features in C4 will be used for comparing the unknown and simulated environments in
the rest of the experiments (using k-NN and K-dT retrieval to obtain the similar case(s) for Etest ).
5.1.4 B EST E NVIRONMENT-M ODEL PAIRS
For each simulated environment, we find out the best candidate trust model based on the performance metric MAE. MAE is a suitable metric to assess the performance of the trust models because
accurately determining the trustworthiness of sellers helps buyers to choose good transaction partners, thereby increasing their utility in the long run (as demonstrated by the experiments in Sec. 5.4).
We first calculate the MAE of all candidate trust models in predicting seller trustworthiness for the
simulated environments and select the one with the lowest MAE value. Here, we also compute the
difference in MAE (for each seller in the e-marketplace environment) between pairs of trust models to assess if the MAE values of the most suitable trust model is significantly better than all the
others (using Paired-Samples T-test). In the end, we obtain 3664 best environment-model pairs6
(Eknown , T M ∗ ), which form the case base for the framework.
Fig. 5(a) illustrates the number of simulated environments in the case base where each candidate
trust model achieves the best performance, which are 733, 306, 448, 979, 190, 253 and 755 for
BRS, iCLUB, TRAVOS, Personalized, Referral, BLADE and Prob-Cog, respectively. The numbers
indicate that the case base contains sufficient number of cases for each trust model. A sample case
i.e., (Eknown , T M ∗ ) is shown in Eqn. 10. Here Eknown is described by the 18 features (we show
all the features considered before the feature selection process for clarity) in the order as mentioned
in Table 1 and T M ∗ is the BLADE model for this environment.
(Eknown , T M ∗ ) =(< 0.30, 0.09, 18.2, 0.04, 0.4, 1.5, 0.6, 182, 19, 0.36, 200, 0.18,
1.3, 2, 1, 100, 0.62, 0.2 >, BLADE)

(10)

5.2 Case Retrieval Algorithms
We use k-NN, K-dT and DT retrieval techniques in identifying suitable trust models for unknown
environments and compare their performance.
To determine the number of nearest neighbors in k-NN and K-dT, we randomly generate 972
unknown environments (using different values for the parameters to generate the simulated envi5. K-d tree retrieval obtains similar MAE values.
6. A simulated environment can have more than one most suitable trust model (which do not significantly outperform
each other) with the lowest MAE.

492

A F RAMEWORK TO C HOOSE T RUST M ODELS FOR D IFFERENT E-M ARKETPLACES

·102

0.4
755

733

6
488
4

0.3
MAE

No. of Use Times

8

K-dT

k-NN

979

10

306

0.2
0.1

253
190

2

0
0

BR
S

P
BL
T
iC
Re
Pe
LU R A
r
fer
AD robVO son
r
Co
B
a
E
al
g
S
ize l
d

1

2

3

4

5

6

7

8

9

10

k

(a)

(b)

Figure 5: (a) No. of times each trust model is selected as the most suitable model for simulated
environments; (b) Influence of k on the MAE in determining seller trustworthiness using
k-NN and K-dT
ronments) and evaluate the performance of k-NN and k-dT in choosing suitable trust models, for
different values of k. Table 2 presents the influence of k on the accuracy of choosing the most
suitable trust models (with the most suitable parameters) for the 972 randomly generated unknown
environments, using k-NN and k-dT retrieval techniques. Correct Model indicates that the trust
model chosen is the same as the best model identified by evaluating all candidate trust models in
the given unknown environment. Correct Model and Paras indicates that the correct trust model is
chosen with the appropriate tuning parameters. Also,  = 0.05 is a tolerance value, indicating that
the difference between the MAE of the chosen trust model and that of the truly most suitable model
is within . We find that the accuracy in choosing the correct trust models (with parameters) is the
highest when k = 3 and acceptable when k = 1, 2 for both k-NN and K-dT. For k values greater
than 3, the performance decreases, signifying that the boundaries between the classes (candidate
trust models) become less distinct. Fig. 5(b) shows the MAE in determining seller trustworthiness
(corresponding to the accuracy in Table 2), when the value of k is increased from 1 to 10. k-NN
and K-dT obtain similar MAE values in determining seller trustworthiness for different values of k.
Again, we find that when k ∈ {2, 3}, the lowest MAE (0.24) is achieved. Hence, we will use k = 3
for all the experiments (using k-NN and K-dT) in this paper.
k-NN
Correct Model
Correct Model with 
Correct Model and Paras
Correct Model and Paras with 
K-dT
Correct Model
Correct Model with 
Correct Model and Paras
Correct Model and Paras with 

k=1
94.0%
97.0%
92.0%
96.0%
k=1
94.0%
96.0%
91.0%
95.0%

k=2
96.0%
97.0%
94.0%
97.0%
k=2
95.0%
97.0%
94.0%
96.0%

k=3
97.0%
99.0%
97.0%
98.0%
k=3
97.0%
98.0%
97.0%
98.0%

k=4
89.0%
91.0%
85.0%
87.0%
k=4
89.0%
92.0%
86.0%
87.0%

k=5
82.0%
84.0%
77.0%
79.0%
k=5
83.0%
84.0%
78.0%
79.0%

k=6
76.0%
78.0%
71.0%
73.0%
k=6
76.0%
78.0%
71.0%
73.0%

k=7
75.0%
77.0%
69.0%
71.0%
k=7
75.0%
76.0%
69.0%
71.0%

Table 2: Influence of k on the accuracy of the framework

493

k=8
73.0%
75.0%
67.0%
69.0%
k=8
74.0%
75.0%
68.0%
69.0%

k=9
71.0%
73.0%
65.0%
67.0%
k=9
72.0%
73.0%
65.0%
67.0%

k=10
71.0%
73.0%
65.0%
67.0%
k=10
71.0%
73.0%
65.0%
66.0%

I RISSAPPANE & Z HANG

For K-dT retrieval, we use the weka implementation (median based partitioning with a maximum of 20 instances in a leaf node). The K-d tree is built using the 3664 best environment-model
pairs (described in Sec. 5.1.4). For the DT retrieval, we use the C4.5 algorithm (J48 weka implementation with pruning confidence 0.25 and minimum number of instances as 2, which are the
default values). The decision tree is also built using the 3664 best environment-model pairs, which
will then be used to find the most suitable model for the unknown environments.
5.3 Unknown Environments for Testing
The framework is evaluated using 6 categories of unknown environments Etest (where ground truth
about seller and buyer honesty is in fact known) in both normal and extreme scenarios.
Specifically, Unknown Random Environments are generated using parameter values different
from simulated environments such as: 1) number of sellers ∈ {33, 66, 99}; 2) total number of
ratings ∈ {333, 666, 999}; 3) ratio of number of unfair ratings versus fair ratings ∈ {0.1, 1, 10}; 4)
time period of attacks ∈ {50, 100}, from which 100 environments are randomly chosen for testing.
Unknown Real Environments are generated using Real data obtained from IM DB.com, where
users rate movies directed by different directors. We remove outlying ratings and select only directors whose movies are very highly rated, resulting in 40 different directors, with 1142 movies
rated by 188 users. We then simulate 3 types of unfair rating attacks, namely RepBad, RepSelf and
RepTrap (Yang, Feng, Sun, & Dai, 2008), and their combination to bad-mouth targeted directors
(sellers in our case). Finally, we generate 48 real environments with simulated attacks.
Large Environments are those where number of sellers is larger than 50, number of ratings is
larger than 100 and number of buyers is larger than 80. We generate 160 such large environments.
Extremely Sparse Environments are those where buyers do not provide sufficient ratings. Specifically, each buyer gives an average of 0.1 ratings to sellers. We generate 36 such environments where
the number of sellers is 10, total number of ratings is 100, and overall attack rate ∈ {0.25, 1, 4}.
Environments with Dynamic Seller and Buyer Behavior are environments where sellers/buyers
change their behavior dynamically. Sellers change their behavior by providing complimentary quality products (than previously presented) after a random period of operation in the e-marketplace.
(Dishonest) buyers change their behavior by providing unfair ratings only during specific periods
and behaving honestly, otherwise. 35 environments (number of sellers is 10 and total number of
ratings is 50) with such dynamic behaviors are generated.
Environments with Many Attacks are those with intensive attacking scenarios, where attack rate
is larger than 10. We specifically use real data from IM DB.com and simulate RepBad, RepSelf,
RepTrap attacks and their combination to generate 24 such environments.
5.4 Experimental Results
Here, we present the results on unknown random and real environments as well as results on extreme
scenarios. We also analyze the possible extensions to the framework such as adding weights to the
features while determining the nearest neighbors in k-NN and K-dT retrieval, etc.
5.4.1 P ERFORMANCE C OMPARISON IN U NKNOWN R ANDOM AND R EAL E NVIRONMENTS
Table 3 presents the accuracy of our framework in choosing the most suitable trust models (with the
most suitable parameters) in unknown random and real environments (using k-NN, K-dT and DT
retrieval techniques). As mentioned in Sec. 5.2, a correct selection indicates that the trust model
494

A F RAMEWORK TO C HOOSE T RUST M ODELS FOR D IFFERENT E-M ARKETPLACES

chosen is the same as the best model identified by evaluating all candidate trust models in a given
unknown environment and  is the tolerance value, indicating that the difference between the MAE
of the chosen trust model and that of the truly most suitable model is within .
Unknown Random Environments
k-Nearest Neighbors (k-NN)
324 SE
648 SE
972 SE
Correct Model
81.0%
84.0%
92.0%
Correct Model with 
87.0%
89.0%
95.0%
Correct Models and Paras
72.0%
76.0%
82.0%
Correct Model and Paras with  85.0%
86.0%
94.0%
K-d Trees (K-dT)
324 SE
648 SE
972 SE
Correct Model
80.0%
84.0%
92.5%
Correct Model with 
87.0%
90.0%
95.0%
Correct Models and Paras
71.0%
76.0%
82.5%
Correct Model and Paras with  85.0%
87.0%
94.2%
Decision Trees (DT)
324 SE
648 SE
972 SE
Correct Model
52.0%
54.0%
63.0%
Correct Model with 
64.0%
67.0%
72.0%
Correct Model and Paras
31.0%
33.0%
35.0%
Correct Model and Paras with  49.0%
53.0%
58.0%
Unknown Real Environments
k-Nearest Neighbors (k-NN)
324 SE
648 SE
972 SE
Correct Model
81.3%
83.3%
83.3%
Correct Model with 
89.6%
95.8%
95.8%
Correct Model and Paras
72.9%
75.0%
77.1%
Correct Model and Paras with  89.6%
95.8%
95.8%
K-d Trees (K-dT)
324 SE
648 SE
972 SE
Correct Model
80.1%
82.3%
83.3%
Correct Model with 
89.0%
95.1%
96.2%
Correct Model and Paras
71.0%
74.0%
78.1%
Correct Model and Paras with  88.0%
95.0%
95.2%
Decision Trees (DT)
324 SE
648 SE
972 SE
Correct Model
08.3%
08.3%
14.6%
Correct Model with 
55.1%
58.3%
68.8%
Correct Model and Paras
00.0%
00.0%
00.0%
Correct Model and Paras with  54.3%
59.2%
68.8%

1296 SE
96.0%
98.0%
96.0%
97.0%
1296 SE
95.0%
98.0%
95.0%
97.0%
1296 SE
72.0%
78.0%
40.0%
63.0%

2268 SE
97.0%
98.0%
97.0%
98.0%
2268 SE
97.0%
98.0%
97.0%
98.0%
2268 SE
80.0%
85.0%
46.0%
67.0%

1296 SE
86.3%
97.3%
79.3%
96.3%
1296 SE
86.7%
97.0%
79.0%
96.0%
1296 SE
40.3%
80.3%
02.0%
80.3%

2268 SE
87.5%
97.3%
81.3%
97.2%
2268 SE
87.0%
97.0%
82.0%
97.5%
2268 SE
45.0 %
83.3%
02.1%
83.3%

Table 3: Accuracy of choosing most suitable trust models (with parameters) for unknown random
and real environments
From Table 3 (under unknown random environments), we can see that the accuracy of our framework increases as the number of simulated environments (SE) in the case base increases (the trend
is the same for k-NN, K-dT and DT), and is the best when there are 2268 simulated environments
(SE) in the case base. This is because with a larger number of cases in the case base, it is easier to
find a closely similar environment to the given unknown environment.
We also find that k-NN and K-dT show similar performance, while outperforming the DT retrieval technique. K-dT is mainly used to improve the retrieval time in k-NN through appropriate
organization of cases in the form of trees. However, for retrieval, K-dT uses the same similarity
measure and the same number of nearest neighbors as k-NN. This is the reason for the similar
performance of k-NN and K-dT. On the other hand, DT retrieval shows a lower performance as
it requires more training instances (cases in the case base) to learn the entire problem space (and
build a complete decision tree) and is known to show a surge in performance when dealing with
continuous feature values (Quinlan, 1996) (in our framework the feature values are continuous).
With smaller number of cases (say 324 SE), DT obtains only an accuracy of 52.0% in choosing the
495

I RISSAPPANE & Z HANG

k-NN

0.4

K-dT

DT

K-dT

DT

0.3
MAE

MAE

0.3

0.2

0.1

0

k-NN

0.4

0.2

0.1

324

648

972

1296

0

2268

|Simulated Environments|

324

648

972

1296

2268

|Simulated Environments|

(a)

(b)

Figure 6: Influence of the number of simulated environments on the performance of k-NN, K-dT
and DT retrieval techniques: (a) random environments; (b) real environments
best trust model for the unknown random environments. Even with 2268 SE the accuracy is only
80.0%, which is less than the accuracy for k-NN with 324 SE. k-NN and K-dT obtain an accuracy
of 97.0% in selecting the most suitable models and a 98.0% accuracy with a tolerance  = 0.05,
for 2268 simulated environments. Thus, it shows that our framework, using the k-NN, K-dT retrieval techniques can choose candidate models whose performance is very close to the ideal case.
Even with only 324 simulated environments, the performance of k-NN and K-dT is still acceptable,
selecting the most suitable models with an accuracy of 81.0% and 80.0%, respectively.
Fig. 6 shows the influence of the number of simulated environments (size of the case base) on the
MAE obtained, while determining seller trustworthiness using the candidate trust model suggested
by the k-NN, K-dT and DT retrieval techniques. The more accurate selection of the best trust model
results in a lower MAE value in determining seller trustworthiness. Fig. 6(a) shows that k-NN and
K-dT obtain a lower MAE than DT in all cases. When the number of simulated environments is
2268, k-NN and K-dT, both obtain an MAE of 0.25, while DT obtains an MAE of 0.31. However,
when the number of simulated environments is increased, we find that the rate at which the MAE
of DT decreases is greater than k-NN and K-dT, because with more training instances, DT can
produce more accurate results. Eventually, when the number of simulated environments is further
increased (greater than 2268), DT may show the same (even better) performance as k-NN and K-dT.
However, we do not further increase the number of simulated environments in our experiments due
to the complexity involved in building the case base, by evaluating all the 45 candidate trust models
in each simulated environment and selecting the most suitable model for each of them.
Table 3 (under unknown real environments) again shows that k-NN and K-dT perform equally
well (with accuracy of 87.5% and 87.0% in selecting the most suitable models with 2268 simulated environments, respectively), outperforming DT retrieval (with accuracy of 45.0%) in real
environments. We also notice that the accuracy of all the techniques is lower than that in the random environments. This is because, characteristics of real environments may vary extensively from
those of the simulated environments in the case base, making it difficult for the retrieval algorithms
to identify similar cases whose simulated environment is similar to the real one. Nevertheless, the
performance of k-NN and K-dT in unknown real environments is also sufficient (greater than 86%).
Fig. 6(b) again shows that k-NN, K-dT perform better than decision trees. However, we can see

496

0.7

0.7

0.6

0.6

0.5

0.5

0.4

0.4

MAE

MAE

A F RAMEWORK TO C HOOSE T RUST M ODELS FOR D IFFERENT E-M ARKETPLACES

0.3

0.3

0.2

0.2

0.1

0.1

0

0

BR iC TR Pe Re BL Pr AV D K kS LU AV rso fer AD ob- G T -dT NN
B O na ra E Co
g
S liz l
ed

BR iC TR Pe Re BL Pr AV D K kS LU AV rso fer AD ob- G T -dT NN
B O na ra E Co
g
S liz l
ed

(a)
30

28
22

No. of Use Times

No. of Use Times

30

(b)

19

20

14
11
10

22
20
13
10
5

4
0

BR
S

4

3

2
0

P
BL
T
iC
Re
Pe
LU R A
r
fer
AD robVO son
r
Co
B
a
E
al
g
S
ize l
d

(c)

BR
S

1
0
P
BL
T
iC
Re
Pe
LU R A
rs
fer
AD robo
VO
ra
Co
B
na
E
l
liz
g
S
ed

(d)

Figure 7: MAE of our framework and other trust models for: (a) random environments; (b) real
environments; No. of times each trust model is selected as the most suitable for: (c)
random environments; (d) real environments
that the MAE values in Fig. 6(b) are smaller than those in Fig. 6(a), though the accuracy for real
environments (Table 3) is lower than unknown random environments. This is because, we assume
that the sellers (in real environments) are either of high or low quality (while in unknown random
environments seller quality is uniformly distributed in [0, 1]), thus easily identifiable by the candidate trust models. We also find that the average MAE in determining seller trustworthiness using the
truly most suitable trust models for the unknown real environments is 0.01, while for the unknown
random environments it is 0.22, a comparatively larger value. Thereby, for unknown real environments, the framework chooses a trust model whose MAE is similar to that of the truly most suitable
trust model to obtain better accuracy, which in this case has a lower value than the MAE for the
unknown random environments. The greater rate at which MAE decreases for DT is very evident
in Fig. 6(b), since in real environments we assume seller trustworthiness to be binary, thereby, even
a small variation in the choice of trust models can impact the MAE values to a great extent.
Fig. 7(a-b) show the MAE of our framework in comparison with the other trust models in unknown random and unknown real environments. For the other trust models in the unknown environ-

497

4

4

3

3
Utility

Utility

I RISSAPPANE & Z HANG

2

1

0

2

1

0

BR iC TR Pe Re BL Pr AV D K kS LU AV rso fer AD ob- G T -dT NN
B O na ra E Co
g
S liz l
ed

(a)

BR iC TR Pe Re BL Pr AV D K kS LU AV rso fer AD ob- G T -dT NN
B O na ra E Co
g
S liz l
ed

(b)

Figure 8: Average utility of buyers: (a) random environments; (b) real environments
ment, we use their best parameter values. We show the performance of k-NN, K-dT and DT using
2268 simulated environments, to obtain the best performance. To demonstrate the scenario when
buyers may choose to aggregate the outcomes of all trust models (instead of using a single most
suitable trust model), while determining seller trustworthiness, we also show the MAE obtained by
adopting such a heuristic denoted by AVG in Fig. 7(a-b). From Fig. 7(a), we find that k-NN and
K-dT obtain the lowest MAE of 0.25, showing that they are able to choose better trust models to
evaluate seller trustworthiness than always applying a single model. DT obtains an MAE of 0.31,
a higher value than Personalized with MAE 0.30. AVG obtains a higher MAE of 0.44, showing
that using the aggregated outcome of all trust models may not result in accurate values for seller
trustworthiness. For the unknown real environments (Fig. 7(b)), again k-NN and K-dT obtain the
lowest MAE (0.022 and 0.025, respectively) when compared to other trust models.
Fig. 7(c-d) shows the numbers of unknown random environments and unknown real environments, respectively for which each trust model is chosen as the most suitable one, using the k-NN
retrieval technique (K-dT retrieval also obtains similar values). The numbers are 28, 4, 19, 14, 2, 22
and 11 for BRS, iCLUB, TRAVOS, Personalized, Referral, BLADE and Prob-Cog, respectively for
the 100 unknown random environments, and 3, 5, 13, 22, 1, 0 and 4 for these models in the 48 unknown real environments. The numbers signify that our framework is able to choose different trust
models from a candidate set for various unknown environments. The difference in the use times of
the trust models between random and real environments also indicate that the trust models perform
differently in different kinds of environments.
Fig. 8(a-b) show the average utility of all the buyers in the e-marketplace corresponding to
the MAE of the trust models in Fig. 7(a-b). Specifically, a buyer gains a reward of +5 when he
chooses a high quality seller (by evaluating the trustworthiness of all the sellers in the market using
the prescribed trust model), with Tstrue > 0.5 and a penalty of −5, on choosing a low quality seller
with Tstrue ≤ 0.5, for a transaction. Fig. 8(a) shows that k-NN and K-dT obtain the highest utility of
2.20 and 2.19, respectively. The trend also shows that trust models with a higher MAE (in Fig. 7(a))
have a lower utility than those with a lower MAE, because when the buyers are able to accurately
predict seller trustworthiness, they can correctly choose good quality sellers as transaction partners.
Fig. 8(b) also shows that k-NN and K-dT obtain the highest utility of 3.53 and 3.50, respectively.
The experiments in Fig. 8(a-b) also justify that MAE is a suitable metric to assess the performance
498

A F RAMEWORK TO C HOOSE T RUST M ODELS FOR D IFFERENT E-M ARKETPLACES

k-NN

5

DT

K-dT

4

4

3

3

Seconds

Seconds

5

2

1

0

DT

K-dT

k-NN

2

1

324

648

972

1296

0

2268

|Simulated Environments|

324

648

972

1296

2268

|Simulated Environments|

(a)

(b)

Figure 9: Time to choose the best trust models: (a) random environments; (b) real environments
of a trust model in a given environment, as it (indirectly) monitors the decisions of the buyers, by
having a large impact on the utility/value addition gained from their transactions with the sellers.
Fig. 9(a-b) show the time taken by the framework to choose the best trust models for the unknown random and real environments, using k-NN, K-dT and DT retrieval techniques. Though
K-dT obtains a similar accuracy as k-NN (Table 3 and Fig. 7), it greatly improves the time taken to
find the most suitable trust model, as shown in Fig. 9(a-b). Specifically, Fig. 9(a) shows that the time
taken to find the suitable trust models for the 100 unknown random environments by k-NN, K-dT
and DT is 4.18s, 1.40s and 1.10s, using 2268 simulated environments in the case base, respectively.
We find that both K-dT and DT approaches are faster than k-NN, which compares the features of
the unknown environment with all the cases in the case base (Soltani, 2013). K-dT and DT use a
tree structure to represent the cases in the case base (as described in Sec. 4.2.2) and retrieve the most
suitable trust model by traversing the tree. However, decision tree retrieval is slightly faster than
K-dT. This is because in K-dT, the dimensionality (number of features) of the cases and the number of similar cases (k nearest neighbors) that are needed to be retrieved, affect the retrieval time
(requiring more number of leaves to be visited through backtracking). Literature (Ahmed, 2004;
Vempala, 2012) also shows that with high-dimensional data (greater than 20), most of the leaves in
the K-d tree are visited and the efficiency is no better than exhaustive k-NN search, which can be a
concern when the feature space in the framework is further increased. From Fig. 9(b), we can again
see that for unknown real environments K-dT and DT require lesser retrieval time than k-NN. The
time taken by k-NN, K-dT and DT is 3.15s, 0.83s and 0.35s, using 2268 simulated environments in
the case base, respectively. However, the values are lower than those in Fig. 9(a), since we consider
the time taken to choose the best trust models for all the 100 unknown random environments, while
the number of real environments considered is only 48. Though the time taken by K-dT is slightly
greater than DT, it is still comparable and shows a much better performance in terms of retrieval
accuracy (Table 3 and Fig. 7).
5.4.2 P ERFORMANCE C OMPARISON IN E XTREME S CENARIOS
Fig. 10 shows the MAE of trust models in the 4 extreme scenarios (i.e., large environments, extremely sparse environments, environments with dynamic seller and buyer behavior and environments with many attacks). Table 4 presents the probability of choosing the trust models in each

499

0.7

0.7

0.6

0.6

0.5

0.5

0.4

0.4

MAE

MAE

I RISSAPPANE & Z HANG

0.3

0.3

0.2

0.2

0.1

0.1

0

0

BR iC TR Pe Re BL Pr AV D K kS LU AV rso fer AD ob- G T -dT NN
B O na ra E Co
g
S liz l
ed

(b)

0.7

0.7

0.6

0.6

0.5

0.5

0.4

0.4

MAE

MAE

(a)

0.3

0.3

0.2

0.2

0.1

0.1

0

BR iC TR Pe Re BL Pr AV D K kS LU AV rso fer AD ob- G T -dT NN
B O na ra E Co
g
S liz l
ed

0

BR iC TR Pe Re BL Pr AV D K kS LU AV rso fer AD ob- G T -dT NN
B O na ra E Co
g
S liz l
ed

(c)

BR iC TR Pe Re BL Pr AV D K kS LU AV rso fer AD ob- G T -dT NN
B O na ra E Co
g
S liz l
ed

(d)

Figure 10: MAE of our framework and other trust models in extreme scenarios: (a) large environments; (b) extremely sparse environments; (c) environments with dynamic seller and
buyer behavior and (d) environments with many attacks
of these 4 extreme cases using the k-NN retrieval technique (K-dT obtains almost the same probabilities as k-NN). Results show that k-NN and K-dT outperform DT, AVG and all the other trust
models, while performing equally well in these environments.
More specifically, Fig. 10(a) shows that k-NN and K-dT obtain the lowest MAE of 0.24 in large
environments. We also find that iCLUB, TRAVOS and Personalized obtain smaller MAE than other
trust models in these large environments. The reason is that these three trust models are able to
distinguish dishonest and honest advisors when they get sufficient rating sources. From Table 4
under large environments, we can see that k-NN selects iCLUB, TRAVOS and Personalized with
the highest probabilities, 26.9%, 23.8% and 38.2%, respectively. Fig. 10(a) also shows that DT and
AVG obtain a larger MAE value (0.27 and 0.28, respectively) than k-NN and K-dT.
From Fig. 10(b), in sparse environments, again k-NN and K-dT obtain the lowest MAE of 0.24
and 0.23 and DT obtains a MAE value of 0.35. BRS and Prob-Cog perform better than other trust
models, because BRS adopts the ‘majority-rule’ to consider the opinions from other advisors, and

500

A F RAMEWORK TO C HOOSE T RUST M ODELS FOR D IFFERENT E-M ARKETPLACES

Trust Models
BRS
iCLUB
TRAVOS
Personalized
Referral
BLADE
Prob-Cog

Large
0.6%
26.9%
23.8%
38.2%
0.6%
9.3%
0.6%

Sparse
25.7%
13.9%
2.1%
2.8%
2.8%
0.0%
52.7%

Dynamic
7.4%
7.2%
4.6%
27.8%
18.5%
31.5%
3.0%

Many Attacks
6.9%
10.3%
13.8%
58.7%
0.0%
0.0%
10.3%

Table 4: Probability of choosing trust models in the four extreme e-market scenarios
Prob-Cog extends the incompetence tolerance threshold to incorporate a larger number of advisors’
ratings. Both models obtain a comparatively low MAE as they are less restrictive in accepting
opinions from advisors than other trust models. In Table 4, under sparse environments, k-NN selects
BRS and Prob-Cog with the highest probabilities, 25.7% and 52.7%, respectively.
Fig. 10(c) shows that k-NN and K-dT obtain the lowest MAE and Personalized and BLADE
outperform other trust models in the environments where sellers change their behavior dynamically.
To explain, Personalized considers advisors’ latest ratings within a certain time window, which alleviates the influence of sellers’ dynamic behavior. BLADE re-interprets advisors’ ratings based on
learning, thereby takes into account the changing behavior of buyers and sellers. In Table 4, k-NN
selects Personalized and BLADE with the highest probabilities, 27.8% and 31.5%, respectively.
Fig. 10(c) also signifies that our framework is able to deal with scenarios where buyers and sellers
change their behavior, because the case base already contains environments representing such dynamic behavior (as described in Sec. 5.1.1), along with their most suitable trust models. Fig. 10(d)
shows that k-NN an K-dT outperform other trust models with the lowest MAE of 0.02 and Personalized and TRAVOS perform well in the environments with many attacks. DT obtains an MAE of
0.03, a comparable but greater value than k-NN and K-dT. The characteristics of attacks play a major role in judging the performance of the trust models. In these extreme environments, the attackers
(dishonest advisors) first give honest ratings to non-target sellers to promote themselves, and then
provide unfair ratings to bad-mouth target sellers. The performance of Personalized and TRAVOS
is better because they both model advisor trustworthiness more accurately by comparing buyers’
own opinions and advisors’ ratings on commonly rated sellers. Also, in the environments, we only
select buyers with sufficient personal experience (ratings) which Personalized and TRAVOS take
advantage of. In Table 4, k-NN selects Personalized and TRAVOS with probabilities 58.7% and
13.8% for the environments with many attacks, respectively.
In summary, from Fig. 10 and Table 4, the results indicate that our framework (using k-NN and
K-dT retrieval technique) is able to select suitable trust models for extreme scenarios and obtain
more accurate seller trustworthiness than AVG and any other individual trust model. Also, we find
that the performance of k-NN and K-dT retrieval is better than DT retrieval in all the cases. Decision
trees are induction models which learn rules (based on features) to determine suitable trust models.
This comes close to the method that PTF (described in Sec. 2) works, the only difference being that
in decision trees the rules are learned and organized in the form of trees, while in PTF the rules
need to be manually specified by the user in a pre-defined format (Huynh, 2009). However, we can
see that with the available number of simulated environments (2268) in the case base, decision trees
cannot learn the complete domain knowledge to construct trees which help to accurately determine
suitable trust models. We can thereby infer that using a rule based system such as PTF will also
result in such moderate performance as decision trees (with the given size of the case base).

501

I RISSAPPANE & Z HANG

5.4.3 A NALYSIS ON THE P OSSIBLE I MPROVEMENTS TO THE F RAMEWORK
It has been demonstrated in literature that feature weighting (assigning weights to individual features) after feature selection (selecting a subset of relevant features and ignoring others), can improve the performance of k-NN (Tahir, Bouridane, & Kurugollu, 2007). Thus, to further improve
the performance of the framework (using k-NN and thereby, K-dT retrieval), we can assign weights
to each (most influential) feature. We conduct experiments using the linear adaptive filters-least
mean squares (Mitchell, 1997), with learning rate 0.2, to determine the weights for the features,
using 972 randomly generated environments. The weights for the 13 most influential features (in
the same order as C4 in Table 1), determined using k-NN are, 0.16, 0.02, 0.01, 0.02, 0.03, 0.2, 0.09,
0.05, 0.04, 0.1, 0.17, 0.01 and 0.1, respectively. We use the same weights for K-dT and analyze its
performance. Table 5 shows the performance of k-NN and K-dT, using the above feature weights
while calculating the similarity between the environments in order to determine the most suitable
trust model. k-NN obtains an improvement of 1.0% and 1.5% in terms of accuracy in selecting the
suitable trust model for unknown random and real environments (when compared to the values in
Table 3, where k-NN and K-dT assign equal weights to all the 13 influential features), respectively.
For extreme scenarios, k-NN obtains an improvement of (at most) 2.0%. K-dT obtains a similar
accuracy improvement of 0.5% and 2.0% for unknown random and real environments, while for the
extreme scenarios, it obtains an improvement of (at most) 2.0%.
k-NN + feature weights
Correct Model
Correct Model with 
Correct Models and Paras
Correct Model and Paras with 
MAE
Accuracy Improvement
K-dT + feature weights
Correct Model
Correct Model with 
Correct Models and Paras
Correct Model and Paras with 
MAE
Accuracy Improvement

Random
98.0%
98.5%
97.0%
98.0%
0.23
1.0%
Random
97.5%
98.5%
97.0%
98.0%
0.23
0.5%

Real
89.0%
98.0%
82.0%
97.2%
0.02
1.5%
Real
89.0%
97.0%
82.0%
97.2%
0.02
2.0%

Large
93.0%
95.0%
95.0%
96.1%
0.22
1.0%
Large
94.0%
95.0%
95.0%
96.1%
0.21
1.0%

Sparse
90.0%
98.0%
96.0%
97.0%
0.22
1.0%
Sparse
90.2%
97.0%
96.0%
97.0%
0.22
2.0%

Dynamic
97.0%
97.0%
97.0%
98.0%
0.30
2.0%
Dynamic
97.1%
97.0%
98.0%
98.0%
0.30
2.0%

Attacks
86.0%
92.0%
80.1%
95.4%
0.02
0.0%
Attacks
85.0%
92.0%
80.0%
96.0%
0.02
0.0%

Table 5: Influence of using feature weights in k-NN and K-dT
Also, as mentioned in Sec. 4, the framework can be extended by adding new features and trust
models. Specifically, to add a new feature we need to: 1) generate a new set of Eknown environments,
including the new feature; 2) select the most influential features F̂ ∗ (using the 5 correlation and
regression techniques as mentioned in Table 1), from the new extended feature set, by testing them in
randomly generated Etest environments, and 3) build the new case base. Thus, the time complexity
for adding a new feature is O((|Eknown |+|Etest |)∗|TM|+5∗tmodel ), which includes the time taken
to find the actual performance of all the defense models TM in the known Eknown and test Etest
environments (represented by (|Eknown | + |Etest |) ∗ |TM|) and the time taken by tmodel (model ∈
{k-NN, K-dT}) to find the most suitable trust models using the 5 different feature combinations
(represented by 5 ∗ tmodel ). When |Eknown | = 2268, |Etest | = 972, |TM| = 45, k = 3 and
model = K-dT, the total time taken to build the new case base on adding a new feature is nearly
3 hours. Adding a new trust model simply takes 3.6 mins (O(|Eknown |)), as it only requires to
run the new trust model on the 2268 environments to build the new case base. Though the above
502

A F RAMEWORK TO C HOOSE T RUST M ODELS FOR D IFFERENT E-M ARKETPLACES

calculations show that a considerable computation time is involved, adding a new feature or a trust
model will lead to an improvement in the performance of the framework. Specifically, adding a
new feature can help to more accurately select suitable trust models and adding a new trust model
may result in a lower MAE for certain environments, leading to better decision making and thereby
improving the utility for the buyers in the environment as shown in Fig. 8. Also, all the above
computation need to be done off-line and the online effort is much lower as can be seen in Fig. 9.

6. Conclusion and Future Work
In this paper, we propose a case-based reasoning framework to choose suitable trust models for
the environments where ground truth about agents’ behavior is unknown. In the framework, the
case base is built by generating a number of simulated environments and determining the most
suitable trust models for the environments. The framework also offers to choose between different
techniques (k-nearest neighbors, K-d trees and decision trees) for case retrieval. Given an unknown
environment, the most similar case(s) are retrieved using the retrieval techniques. Then, the trust
model corresponding to the most similar case(s) is chosen as the most suitable one for the unknown
environment. Experimental results confirm that our framework can accurately select suitable trust
models for various unknown environments (both simulated and real e-marketplaces). We also find
that k-nearest neighbors and K-d tree retrieval techniques can more accurately choose suitable trust
models by determining the most similar case(s) from the case base than decision trees, especially
when the number of simulated environments (cases in the case base) is much smaller. It is also
demonstrated that K-d trees significantly improve the time complexity in choosing suitable trust
models over k-nearest neighbors. Experiments also verify that using our framework to choose
suitable trust models for unknown environments (using k-nearest neighbors and K-d tree retrieval)
is better than always applying any single trust model (or the aggregate of all trust models), in terms
of the accuracy in evaluating seller trustworthiness.
Currently, the framework achieves the best performance when the number of simulated environments in the case base is as large as 2268 environments; the performance will further increase
by adding more simulated environments. While adding more simulated environments is a feasible
option to further improve the performance of the framework, it requires tremendous off-line computation to determine suitable trust models for the simulated environments and build the case base.
In the future, we will investigate methods to generate simulated environments that are more representative of real world e-marketplaces, such that the performance of the framework is much higher
even when the case base contains smaller number of simulated environments. We will also analyze
more effective feature selection techniques to accurately select trust models in this regard.
Another important direction of future work is to consider the scenario when the features of
the unknown environment deviate from the most similar simulated environment determined by the
framework, during its execution time. One possible solution is to use the proposed framework to
choose the most suitable trust model over regular intervals of time when the unknown environment
operates. We will conduct detailed experiments to analyze the performance of the framework in such
scenarios. We will also continue to evaluate our framework by incorporating more sophisticated
trust models and involving more real data sets.

503

I RISSAPPANE & Z HANG

References
Aamodt, A., & Plaza, E. (1994). Case-based reasoning: Foundational issues, methodological variations, and system approaches. AI communications, 7(1), 39–59.
Ahmed, Y. S. (2004). Multiple Random Projection For Fast, Approximate Nearest Neighbor Search
in High Dimensions. Ph.D. thesis, University of Toronto.
Duda, R. O., & Hart, P. E. (1973). Pattern classification and scene analysis, Vol. 3. Wiley.
Fullam, K. K., & Barber, K. S. (2007). Dynamically learning sources of trust information: Experience vs. reputation. In Proceedings of the International Joint Conference on Autonomous
Agents and Multiagent Systems (AAMAS).
Hang, C. W., Wang, Y., & Singh, M. P. (2009). Operators for propagating trust and their evaluation
in social networks. In Proceedings of the International Joint Conference on Autonomous
Agents and Multiagent Systems (AAMAS).
Hastie, T., Tibshirani, R., & Friedman, J. (2009). The elements of statistical learning, Vol. 2.
Springer.
Hoffman, K., Zage, D., & Nita-Rotaru, C. (2009). A survey of attack and defense techniques for
reputation systems. ACM Computing Surveys (CSUR), 42(1), 1.
Huynh, T. (2009). A personalized framework for trust assessment. In Proceedings of the ACM
Symposium on Applied Computing (SAC).
Irissappane, A. A., Jiang, S., & Zhang, J. (2013). A framework to choose trust models for different
e-marketplace environments. In Proceedings of the 23rd International Joint Conference on
Artificial Intelligence (IJCAI).
Irissappane, A. A., Oliehoek, F. A., & Zhang, J. (2014). A POMDP based approach to optimally
select sellers in electronic marketplaces. In Proceedings of the 13th International Conference
on Autonomous Agents and Multiagent Systems (AAMAS).
Irissappane, A. A., & Zhang, J. (2014). A testbed to evaluate the robustness of reputation systems in
e-marketplaces. In Proceedings of the 13th International Conference on Autonomous Agents
and Multiagent Systems (AAMAS).
Jøsang, A., & Ismail, R. (2002). The Beta reputation system. In Proceedings of the 15th Bled
Electronic Commerce Conference.
Liu, S., Zhang, J., Miao, C., Theng, Y., & Kot, A. (2011). iCLUB: An integrated clustering-based
approach to improve the robustness of reputation systems. In Proceedings of the International
Conference on Autonomous Agents and Multiagent Systems (AAMAS).
Mitchell, T. M. (1997). Machine learning. McGraw-Hill.
Noorian, Z., Marsh, S., & Fleming, M. (2011). Multi-layer cognitive filtering by behavioral modeling. In Proceedings of the International Conference on Autonomous Agents and Multiagent
Systems (AAMAS).
Quinlan, J. R. (1986). Induction of decision trees. Machine learning, 1(1), 81–106.
Quinlan, J. R. (1996). Improved use of continuous attributes in C4.5. Journal of Artificial Intelligence Research (JAIR), 4(1), 77–90.

504

A F RAMEWORK TO C HOOSE T RUST M ODELS FOR D IFFERENT E-M ARKETPLACES

Quinlan, J. R. (1993). C4. 5: Programs for machine learning, Vol. 1. Morgan kaufmann.
Regan, K., Poupart, P., & Cohen, R. (2006). Bayesian reputation modeling in e-marketplaces sensitive to subjectivity, deception and change. In Proceedings of the National Conference on
Artificial Intelligence (AAAI).
Sabater, J., & Sierra, C. (2005). Review on computational trust and reputation models. Artificial
Intelligence Review, 24(1), 33–60.
Soltani, S. (2013). Case-based reasoning for diagnosis and solution planning. Technical Report,
Queen’s University.
Sormo, F., Cassens, J., & Aamodt, A. (2005). Explanation in case-based reasoning–perspectives
and goals. Artificial Intelligence Review, 24(2), 109–143.
Tahir, M. A., Bouridane, A., & Kurugollu, F. (2007). Simultaneous feature selection and feature
weighting using hybrid tabu search/k-nearest neighbor classifier. Pattern Recognition Letters,
28(4), 438–446.
Teacy, W., Patel, J., Jennings, N., & Luck, M. (2006). TRAVOS: Trust and reputation in the context
of inaccurate information sources. Autonomous Agents and Multiagent Systems, 12, 183–198.
Vempala, S. S. (2012). Randomly-oriented k-d trees adapt to intrinsic dimension. In Proceedings of
the 32nd International Conference on Foundations of Software Technology and Theoretical
Computer Science (FSTTCS).
Wang, Y., Hang, C.-W., & Singh, M. P. (2011). A probabilistic approach for maintaining trust based
on evidence. Journal of Artificial Intelligence Research, 40(1), 221–267.
Watson, I. (1999). Case-based reasoning is a methodology not a technology. Knowledge-based
systems, 12(5), 303–308.
Watson, I., & Marir, F. (1994). Case-based reasoning: A review. Knowledge Engineering Review,
9(4), 327–354.
Wess, S., Althoff, K.-D., & Derwand, G. (1994). Using k-d trees to improve the retrieval step in
case-based reasoning. Springer.
Wettschereck, D., & Aha, D. W. (1995). Weighting features. Case-based Reasoning Research and
Development, 347–358.
Whitby, A., Jøsang, A., & Indulska, J. (2004). Filtering out unfair ratings in bayesian reputation
systems. In Proceedings of the AAMAS Workshop on Trust in Agent Societies (TRUST).
Yang, Y., Feng, Q., Sun, Y. L., & Dai, Y. (2008). RepTrap: A novel attack on feedback-based
reputation systems. In Proceedings of the International Conference on Security and Privacy
in Communication Networks (SecureComm).
Yu, B., & Singh, M. (2003). Detecting deception in reputation management. In Proceedings of the
International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS).
Zhang, J., & Cohen, R. (2008). Evaluating the trustworthiness of advice about seller agents in emarketplaces: A personalized approach. Electronic Commerce Research and Applications,
7(3), 330–340.
Zhang, J. (2009). Promoting honesty in e-marketplaces: Combining trust modeling and incentive
mechanism design. Ph.D. thesis, University of Waterloo.

505

Journal of Artificial Intelligence Research 52 (2015) 445-475

Submitted 09/14; published 03/15

Modeling the Lifespan of Discourse Entities
with Application to Coreference Resolution
Marie-Catherine de Marneffe

MCDM @ LING . OHIO - STATE . EDU

Linguistics Department
The Ohio State University
Columbus, OH 43210 USA

Marta Recasens

RECASENS @ GOOGLE . COM

Google Inc.
Mountain View, CA 94043 USA

Christopher Potts

CGPOTTS @ STANFORD . EDU

Linguistics Department
Stanford University
Stanford, CA 94035 USA

Abstract
A discourse typically involves numerous entities, but few are mentioned more than once. Distinguishing those that die out after just one mention (singleton) from those that lead longer lives
(coreferent) would dramatically simplify the hypothesis space for coreference resolution models,
leading to increased performance. To realize these gains, we build a classifier for predicting the
singleton/coreferent distinction. The model’s feature representations synthesize linguistic insights
about the factors affecting discourse entity lifespans (especially negation, modality, and attitude
predication) with existing results about the benefits of “surface” (part-of-speech and n-gram-based)
features for coreference resolution. The model is effective in its own right, and the feature representations help to identify the anchor phrases in bridging anaphora as well. Furthermore, incorporating
the model into two very different state-of-the-art coreference resolution systems, one rule-based and
the other learning-based, yields significant performance improvements.

1. Introduction
Karttunen imagined a text interpreting system designed to keep track of “all the individuals, that is,
events, objects, etc., mentioned in the text and, for each individual, record whatever is said about it”
(Karttunen, 1976, p. 364). He used the term discourse referent to describe these abstract individuals.
Some discourse referents are easily mapped to specific entities in the world, as with most proper
names. Others are indeterminate in the sense that they are compatible with many different real-world
entities, as with indefinites like a train. In either case, discourse referents can enter into anaphoric
relations in discourse; even if we do not know exactly what real-world object a train picks out in
We heard a train in the distance . . . , we can nonetheless refer to it with subsequent pronouns and
ascribe properties to it (. . . It had a loud horn).
Not all discourse referents enjoy repeat appearances in the discourse. Some lead long lives
and appear in a wide variety of discourse contexts, whereas others never escape their birthplaces,
dying out after just one mention. The central question of this paper is what factors influence the
lifespan of a discourse referent. We focus on noun phrases, which are the most direct identifiers
of discourse referents in English. More specifically, we seek to predict whether a given discourse
c
2015
AI Access Foundation. All rights reserved.

DE

M ARNEFFE , R ECASENS & P OTTS

referent will be coreferent (mentioned multiple times in a given discourse) or singleton (mentioned
just once). The ability to make this distinction based on properties of the noun phrases used to
identify these referents (henceforth, mentions) would benefit coreference resolution models, by simplifying the hypothesis space they consider when predicting anaphoric links, and it could improve
performance on other tasks that require accurately tracking discourse entities, including textual entailment (Delmonte, Bristot, Piccolino Boniforti, & Tonelli, 2007; Giampiccolo, Magnini, Dagan,
& Dolan, 2007) and discourse coherence (Hobbs, 1979; Grosz, Joshi, & Weinstein, 1995; Kehler,
2002; Barzilay & Lapata, 2008; Prasad, Dinesh, Lee, Miltsakaki, Robaldo, Joshi, & Webber, 2008).
The existing literature provides numerous generalizations relevant to the singleton/coreferent
distinction. It is known, for example, that the internal syntax and morphology of the phrase used
to establish the discourse referent provide important clues as to the lifespan of that referent (Prince,
1981a, 1981b; Wang, McCready, & Asher, 2006). Information structuring is also important; certain
grammatical and discourse roles correlate with long lifespans (Chafe, 1976; Hobbs, 1979; Walker,
Joshi, & Prince, 1997; Beaver, 2004). Features based on these insights have long been integrated
into coreference resolution systems. Our contribution is to explore the interaction of all of these
features with semantic operators like negation, modals, and attitude predicates (know, be certain,
wonder). Such interactions were Karttunen’s primary focus (Karttunen, 1973, 1976), and they have
long dominated work on dynamic approaches to linguistic meaning (Kamp, 1981; Heim, 1982,
1992; Roberts, 1990; Groenendijk & Stokhof, 1991; Bittner, 2001). Here, we highlight the importance of such interactions for predicting the lifespans of discourse referents in actual text.
Our approach also capitalizes on the results of Durrett and Klein (2013) and Hall, Durrett, and
Klein (2014) concerning the power of “surface” features for natural language processing (NLP)
tasks. Those authors show that large sets of easily extracted part-of-speech (POS) and n-grambased features can achieve results that are at least as good as those achieved with hand-engineered
linguistic features. We therefore investigate the contribution of surface features for predicting the
lifespan of discourse entities. We find that surface features alone have substantial predictive value
for this task, but that adding more specialized linguistic features leads to reliable performance gains.
This suggests that some of the linguistic constraints relevant for lifespan prediction go beyond what
can be approximated with surface-level information given available data.
The first step in our analysis is to bring the insights from linguistic theories together into a
single logistic regression model — the lifespan model — and assess their predictive power on real
data. We show that the linguistic features generally behave as the existing literature leads us to
expect, and that the model itself is effective at predicting whether a given mention is singleton or
coreferent. The second step is to bring in surface features to obtain a more predictive model. We then
provide an initial assessment of the engineering value of making the singleton/coreferent distinction
by incorporating our lifespan model into two very different, state-of-the-art coreference resolution
systems: the rule-based Stanford coreference system (Lee, Peirsman, Chang, Chambers, Surdeanu,
& Jurafsky, 2011) and the learning-based Berkeley coreference system (Durrett & Klein, 2013). For
both, adding our features results in a significant improvement in precision on the CoNLL-2011 and
CoNLL-2012 Shared Task data, across all the standardly used coreference resolution measures, and
we see reliable boosts in recall as well.
This article subsumes and extends the work of Recasens, de Marneffe, and Potts (2013). The
specific differences are as follows. First, freed of NAACL’s tight space constraints, we provide a
much more in-depth linguistic analysis of the various features in our lifespan model, and include
more details throughout. Second, we examine the contribution of surface features to the lifespan
446

M ODELING THE L IFESPAN OF D ISCOURSE E NTITIES

model. Third, we assess the value of the lifespan model for predicting which phrases will act as
anchors in bridging anaphora. Fourth, to give a fuller evaluation of the coreference applications
of our model, we incorporate our best lifespan model into a learning-based system (the Berkeley
coreference system), complementing our previous results on the rule-based Stanford coreference
system. Fifth, we use the most recent version of the CoNLL scorer (v8.0), which includes results
according to BLANC and fixes a bug that incorrectly boosted B3 and CEAF scores by a few points.
Sixth, we benefit from Kummerfeld and Klein’s (2013) error analysis tool to gain deeper insights
into the errors that our lifespan model helps with.

2. Linguistic Insights
This section briefly summarizes previous research on anaphora resolution, discourse structure, and
discourse coherence in the linguistic literature. Our goal is to obtain a clear picture of how the
lifespan of a discourse referent is shaped by features of its mentions — not only their local morphosyntactic features but also features of the syntactic and semantic environments in which they
occur. The insights we gather in this section inform the design of the feature extraction functions
in our lifespan model (Section 5) and in turn shape our contributions to the Stanford and Berkeley
coreference systems (Section 8).
Karttunen (1976) was primarily concerned with the ways in which the semantic scope of an
indefinite influences the lifespan of its associated discourse referent. In the three-sentence discourse
(1), the indefinite an exam question in sentence 1 has text-level scope. As a result, its associated
discourse referent is free to lead a long life, linking with a mention that is also at the text-level
(sentence 2) and one that is embedded below negation (sentence 3).
(1)

Kim read over an exam question. It was hard. He didn’t understand it.

In contrast, as Karttunen observed, if an indefinite is interpreted in the scope of negation, then
it is typically available for anaphoric reference inside that negative environment, as in (2), but not
outside of it, as in (3). (We use # to mark discourses that are incoherent on the intended construal.)
(2)

Kim didn’t understand an exam question even after reading it twice.

(3)

Kim didn’t understand an exam question. # It was too hard.

Of course, (3) has a coherent construal on which an exam question is interpreted as taking widescope with respect to negation (‘there is a question Kim didn’t understand’). Such inverse scope
readings are often disfavored, but they become more salient when modifiers like certain and particular are included (Fodor & Sag, 1982; Schwarzschild, 2002), or where the mention contains
a positive polarity item, that is, an item like some or tons of that resists scoping under negation
semantically (Baker, 1970; Israel, 1996, 2001):
(4)

Kim didn’t understand a particular exam question. She pondered it for hours to no avail.

(5)

Kim didn’t understand some exam question. She pondered it for hours to no avail.

Conversely, using a negative polarity item (NPI) like any inside the indefinite mention essentially ensures a narrow-scope reading (Ladusaw, 1996; Israel, 2004), which leads to an impossibleto-resolve anaphoric link for simple variants of (3):
(6)

Kim didn’t understand any exam question. # It was too hard.
447

DE

M ARNEFFE , R ECASENS & P OTTS

The pattern Karttunen saw in all this is that semantic scope and anaphoric potential are intimately related: a given mention can participate in anaphoric relationships within its scope, but not
outside of it. Broadly speaking, this is familiar from quantificational binding in logical languages
(Cresswell, 2002) and variable scope in the control structures of programming languages (Muskens,
van Benthem, & Visser, 1997). Thus, an indefinite with text-level scope has free reign, whereas one
inside the scope of an operator like negation is restricted to links that do not span the outer boundaries of that scopal environment. These are semantic generalizations that might not be directly
reflected in the surface syntax, but interpretive preferences and internal morphosyntactic features of
the mention can help to disambiguate the intended logical form.
Karttunen (1976) immediately generalized his observations about negation and discourse reference to modal auxiliaries and non-factive attitude predicates like want and claim. The following are
based on his original examples:
(7)

Bill can make a kite. # It has a long string.

(8)

John wants to catch a fish. # Do you see it from here?

(9)

Sandy claims that Jesse bought a bicycle. # It has a green frame.

As with negation, the pattern makes intuitive sense. Bill’s abilities regarding kite construction do
not involve any specific kite, and hence the first sentence of (7) does not automatically establish the
right sort of discourse referent. Similarly, wanting to catch a fish does not guarantee the salience (or
even existence) of a fish, and Sandy might be so unreliable as a source that a bicycle has no status
outside of the semantic scope of claim.
All of (7)–(9) cohere if the indefinite is interpreted outside of the scope of the relevant semantic
operator. The relative preferences for surface and inverse scope are harder to characterize than they
were with negation, because they are influenced in complex ways by the semantics and pragmatics
of the attitude predicate, the reliability of the source of the information, and the nature of the conversational issues and goals. For example, if the speaker of (9) regards Sandy as a reliable source
regarding Jesse’s bike buying, then a bicycle will likely attain text-level scope as a by-product of
‘Jesse bought a bicycle’ becoming a text-level commitment. Karttunen (1973) discusses these patterns, observing that, in many contexts, pragmatic pressures encourage embedded content to become
elevated to the text level in this way. De Marneffe, Manning, and Potts (2012) study newspaper data
in which this is an extremely common pattern because the attitude verbs tend to function as evidential markers for the source of the embedded content (Rooryck, 2001; Simons, 2007). We will
see later that attitude predicates seem to encourage long lifespans in the OntoNotes data too (the
majority of which is news-like), arguably as a result of just these pragmatic factors.
We have so far restricted attention to anaphoric links in which an indefinite establishes a new
discourse referent and a pronoun refers to it. Our observations carry over directly to links from indefinites to definite noun phrases, which linguistic theories treat roughly as pronouns with additional
descriptive content (for discussion, see the work of Elbourne, 2008). Other mention-patterns tend to
be quite different, though. Where discourse referents are established by definites or named entities,
the interactions with negation and other operators are simpler because definites and named entities
do not interact scopally with these operators (but see the work of Aloni, 2000, for related issues
involving presupposition and intensionality). Thus, such anaphoric connections are unconstrained
by the factors we have been discussing. Conversely, truly quantified phrases like no student and every linguist are severely limited, not only by their interaction with other operators but also by their
448

M ODELING THE L IFESPAN OF D ISCOURSE E NTITIES

own deficiencies when it comes to establishing discourse referents. There are cases in which these
expressions establish new discourse referents, but they seem to be infrequent and unusual (Wang
et al., 2006).
Cross-cutting the above considerations are factors that have long been central to studies of coreference and anaphora within computational linguistics and NLP. For instance, animate nouns are
generally the most likely to lead long discourse lives, whereas mentions that refer to abstract objects like quantities, percentages, and other measures tend to be singleton. We assume that these
statistical patterns derive, not from narrow linguistic constraints, but rather from general cognitive
biases concerning how people conceptualize and discuss different kinds of objects. However, there
is evidence that these biases can make their way into the grammars of specific languages in the
form of morpho-semantic phenomena like obviation (Aissen, 1997) and differential object marking
(Aissen, 2003).
The syntactic environment in which the phrases occur will also modulate their anaphoric potential and hence their lifespans. For example, Prince (1981b) reports that semantically indefinite
phrases using this, as in There was this guy in the back row, are highly likely to be referred to in
a subsequent clause. Similarly, Chafe (1976) shows that information structuring choices are also
predictive of whether a given noun phrase will serve as the antecedent for later referential devices.
There are also close correlations between being in a syntactic topic position and leading a long discourse life (Grosz et al., 1995; Beaver, 2004); for a focused evaluation of these ideas for handling
coreference, see the work of Beaver (2007).
We seek to incorporate all of the above observations into our lifespan model. There are additional patterns from the literature that we do not pursue, because they are too infrequent in our
data. For example, Karttunen (1976) also identified a natural class of counterexamples to his basic scope generalizations: certain sequences of intensional predicates support exceptional anaphoric
links, a phenomenon that was later studied systematically under the heading of modal subordination
(Roberts, 1990, 1996):
(10)

Frank wants to marry a rich linguist. # She is kind.

(11)

Frank wants to marry a rich linguist. She should be kind.

In addition, mentions inside parenthetical clauses are less likely to introduce long-term discourse
referents, due to the likelihood that the parenthetical clause itself conveys only secondary content as
compared with the main clause that hosts it (Potts, 2005). Thus, while anaphoric links into and out
of parentheticals are possible (AnderBois, Brasoveanu, & Henderson, 2010; Potts, 2012), they seem
to arise relatively rarely, a valuable piece of practical advice for appositive-rich texts like scientific
papers but unfortunately not one we could put into action here.
Karttunen’s observations helped set the agenda for dynamic approaches to semantics for the next
few decades (Kamp, 1981; Heim, 1982; Groenendijk & Stokhof, 1991). That literature refined and
extended his observations in numerous ways. Taken together, the findings suggest that intensional
operators and negation interact in complex ways with discourse anaphora. By default, we expect
phrases introduced in the scope of such operators to lead short lifespans, but it is possible for them
to take wide-scope with respect to those operators, which broadens the range of anaphoric links they
can establish. Such readings are favored or disfavored by the pragmatics of the situation as well as
the lexical and syntactic nature of the phrases involved. In what follows, we seek to model these
interactions and use them to inform a lifespan model.
449

DE

M ARNEFFE , R ECASENS & P OTTS

3. Previous Engineering Efforts and Quantitative Evaluations
The above insights have inspired NLP researchers to try to predict the roles that different mentions
will play in coreference chains. Previous work in this area can be subdivided into detecting four
different targets: non-referential mentions, non-anaphoric mentions, discourse-new mentions, and
non-antecedent mentions. The terminology has not always been used in a consistent way in linguistics or NLP, but we believe that the results can ultimately be brought together. Here, we aim to
clarify the terminology and find common insights behind the various features that have been used.
We are the first to single out the singleton/coreferent detection task as such, but our work finds
important antecedents in the existing literature.
3.1 Non-referential Mentions
Some noun phrases do not refer to a discourse referent but rather just fill a syntactic position. In
English, the canonical example of a non-referential NP is the expletive pronoun it, as in It is obvious
that we will succeed. Some lexical NPs do not introduce a discourse referent either, such as a
linguist in Pat is a linguist: while the mention Pat does introduce a discourse referent, a linguist
simply predicates something of her. Detecting such non-referential uses plays a role in coreference
resolution: since these NPs do not pick out discourse referents (new or existing), they cannot enter
into any anaphoric relations of the kind under consideration here.
Early work in non-referentiality detection focuses on the pronoun it, aiming to distinguish referential uses from non-referential ones. Paice and Husk (1987) develop a rule-based system, Evans
(2001) uses a supervised approach, and Müller (2006) focuses on the use of it in spoken dialog.
These studies mainly employ lexico-syntactic features of the immediate surrounding context of the
pronoun. Similarly, Bergsma, Lin, and Goebel (2008) explore a system that uses Web-count features derived from the Google n-grams data (Brants & Franz, 2006) to capture the most frequent
subjects that can replace the pronoun it: for referential cases (e.g., it is able to), other words than it
will be frequent in the n-grams, such as he is able to or China is able to, whereas for non-referential
cases, the pronoun it will likely be the most frequent subject (e.g., it is important to).
More recently, Bergsma and Yarowsky (2011) develop the NADA system, which improves on
Bergsma et al. (2008) by incorporating lexical features. The lexical features indicate the presence
or absence of some strings at specific positions around the pronoun: three-grams to five-grams
spanning the pronoun; two tokens before the pronoun to five tokens after the pronoun with their
positions; any token within twenty tokens to the right of the pronoun; and any token within ten
tokens to the left of the pronoun that is a named entity or belongs to the following list: that, this,
and, said, says, it, It, its, itself. Using both types of features, lexical and Web-count, they achieve
85% accuracy on different datasets.
Byron and Gegg-Harrison (2004) apply some of the linguistic insights highlighted by Karttunen
(Section 2) to the special case of pronoun resolution, seeking to discard non-referential indefinite
NPs from the set of potential antecedents for pronouns. They use a hard filter for non-referential
mentions, looking at the presence of indefinites, negation, apposition (hand-labeled), modals, adjectival phrases or predication adjuncts (tagged ‘-CLR’ in the Penn Treebank), predicates of copular
verbs (tagged ‘-PRD’), and noun phrases that express a value. They found that removing nonreferential mentions gave a small boost in performance for pronoun resolution.
450

M ODELING THE L IFESPAN OF D ISCOURSE E NTITIES

3.2 Non-anaphoric Mentions
Non-anaphoric NPs are those whose interpretation does not depend on a previous mention in the
text. For example, the phrase the new Scorsese movie that stars De Niro in (12) (while manifesting
many kinds of context dependence) does not depend on any other overt phrases in order to capture all
of its descriptive content. In contrast, the movie in (13) crucially links back to the previous sentence
for its descriptive content; it superficially involves just the predicate ‘movie’, but it is construed as
having the additional property ‘seen by the speaker the previous night’.
(12)

Last night, I watched the new Scorsese movie that stars De Niro.

(13)

Last night, I watched a movie and read a paper. The movie was directed by Scorsese.

There is no direct correspondence between anaphora and coreferentiality. Coreferent mentions
can be non-anaphoric (as in a text containing multiple tokens of the phrase The White House), and
anaphoric mentions can be coreferent or non-coreferent (van Deemter & Kibble, 2000). Cases of
bridging anaphora (Clark, 1975) like (14) involve non-coreferent anaphora. Here, the ceiling is
interpreted as the ceiling of the room mentioned in the previous sentence, and thus it is anaphoric to
the room without being coreferent with it or any other phrase in the discourse.
(14)

I looked into the room. The ceiling was very high.

We return to such cases in Section 6, where we use our lifespan model to characterize the sense in
which bridging anchors like the room lead longer lifespans than a count of their strictly coreferent
mentions would suggest.
Poesio, Uryupina, Vieira, Alexandrov-Kabadjov, and Goulart (2004) and Poesio, AlexandrovKabadjov, Vieira, Goulart, and Uryupina (2005) summarize previous approaches to non-anaphoricity
detection, which they refer to as discourse-new detectors. Vieira and Poesio (2000) focus on definite NPs and use syntactic heuristics based on pre- and post-modification to distinguish between
anaphoric and non-anaphoric NPs. Modification is a good indicator of anaphoricity; heavily modified phrases like the new Scorsese movie that stars De Niro tend to be non-anaphoric, whereas short
phrases with general descriptive content like the movie tend to be anaphoric. Bean and Riloff (1999)
also focus on definite NPs: in addition to syntactic heuristics based on pre- and post-modification,
they use techniques mining lists of likely non-anaphoric NPs (such as the presence of NPs in the first
sentence of a document). Compared to Vieira and Poesio (2000), they obtain substantially higher
recall (with recall and precision figures around 80%).
In their non-anaphoricity detector, Poesio et al. (2005) use a head feature (distance between
NPs with identical heads), syntactic features (e.g., occurring inside an appositive or copular clause,
being post-modified), capitalization of the mention, presence of the mention in the first sentence of
a Web page, position of the mention in the text, and the probability of the mention being definite as
computed from the Web using the technique of Uryupina (2003). They find that the most important
features are the head feature and the definiteness probabilities.
3.3 Discourse-New Mentions
Discourse-new mentions are those that introduce a new entity into the discourse (Prince, 1981b;
Fraurud, 1990). The entity might be singleton or involve a chain of coreferring mentions in which
the first phrase is the discourse-new one and the rest are considered discourse-old. Cast as an
451

DE

M ARNEFFE , R ECASENS & P OTTS

information status task, the goal of discourse-new mention detection is to find discourse referents
which were not previously available to the hearer/reader; e.g., see the work of Nissim (2006).
Ng and Cardie (2002) develop a discourse-new classifier that targets every kind of NP using a
variety of feature types: lexical (string and head matching, conjunction), morpho-syntactic (definiteness, quantification, number), grammatical (appositional or copular context, modifier structure,
proper-noun embedding), and shallow semantic (e.g., WordNet features). They incorporate the
classifier into their coreference resolution system, pre-filtering NPs that are tagged as discoursenew. However, this pre-filtering ultimately hurts coreference resolution system performance: even
though precision increases, recall drops considerably. In Section 8.2.3, we report similar results
for our model instantiated with discourse-new pre-filtering, but we find that the recall drop can be
avoided if filtering is applied only when the mention under analysis is tagged as discourse-new and
the antecedent candidate is tagged as singleton.
Ng and Cardie’s (2002) work is cast as non-anaphoricity detection, but their model is perhaps
better described as trying to distinguish coreferent mentions from those that are singleton or initiate
coreference chains. More specifically, they write, “a positive instance is created for each NP that is
involved in a coreference chain but is not the head of the chain” (Ng & Cardie, 2002, p. 3), which
picks out non-initial members of coreference chains. Conversely, “a negative instance is created for
each of the remaining NPs” (Ng & Cardie, 2002, p. 3), i.e., those without any antecedents.
Uryupina (2009) proposes a discourse-new mention detector for any kind of NP. The classifier
relies on features falling into three categories she defines: ‘lexical’ (number of words in the mention), ‘syntactic’ (POS, number, person, determiner, pre- and post-modification), ‘semantic’ (gender, semantic class), and ‘salience’ (grammatical role, position in the sentence and in the paragraph).
In addition, she includes some of Karttunen’s features as implemented by Byron and Gegg-Harrison
(2004). Her classifier also checks for mentions with identical heads, and distance between these.
Only the syntactic and head features deliver improvements to a majority baseline (which marks
each NP as discourse-new), performing almost as well as all the features together. Uryupina notes,
however, that most of the features, and especially those based in Karttunen’s ideas, have not been
designed for discourse-new mention detection.
Both Ng and Cardie (2002) and Uryupina (2009) integrated their discourse-new detector into a
coreference resolution system in a pipeline manner. For a joint approach to discourse-new detection
and coreference resolution, see the work of Denis and Baldridge (2007).
3.4 Non-antecedent Mentions
As Uryupina (2009) observes, for coreference resolution, what matters is the fact that some NPs are
unavailable as antecedents. She therefore builds a classifier that marks NPs as likely antecedents
or not. Her system is based on the same features as her discourse-new detector described above
(Section 3.3). For non-antecedenthood detection, only the syntactic and semantic features lead
to a significant precision improvement over a majority baseline (which marks each NP as nonantecedent), with the syntactic features alone performing as well as all the features together.
3.5 Our Approach: Singletons
Our model cross-cuts these four categories. Unlike previous models of non-referentality, ours is
not restricted to pronouns or to indefinite NPs, but tries to identify any kind of non-referential NP
as well as any referential NP whose referent is mentioned only once (i.e., singleton). Thus, all
452

M ODELING THE L IFESPAN OF D ISCOURSE E NTITIES

Dataset

Docs

Tokens

Training
Development
Test

2,802
343
348

1.3M
160K
170K

M ENTIONS
Coreferent Singletons
152,974
18,855
19,407

181,274
23,140
23,657

Table 1: CoNLL-2012 Shared Task data statistics. We added singletons (noun phrases not annotated as coreferent), which account for 55% of the referents in the development set.

non-referential NPs fall into our singleton class. On the other hand, there is no strict correspondence between our singleton/coreferent distinction and the non-anaphoric/anaphoric distinction,
since anaphoricity is based on whether the mention relies on a previous one for its interpretation,
whereas the singleton/coreferent divide is based on how long the lifespan of an entity is. Similarly,
discourse-new mentions can either be coreferent or singleton in our classification, depending on
whether the entity is mentioned again or not.
In terms of feature representations, we have tried to stay as close as possible to Karttunen’s
original insights: we extract the features from full syntactic parses, seeking to remain faithful to the
underlying semantic relationships involved, and we include feature interaction terms to capture the
complex set of dependencies reviewed above in Section 2. This approach allows us to both evaluate
those linguistic ideas quantitatively and to assess their practical contributions to full coreference
systems.

4. Data
The data used throughout this paper come from the CoNLL-2012 Shared Task data (Pradhan, Moschitti, Xue, Uryupina, & Zhang, 2012), which included the 1.6M English words from OntoNotes
v5.0 (Pradhan & Xue, 2009) with several common layers of annotation (coreference, parse trees,
named-entity tags, etc.). The OntoNotes corpus contains documents from seven different domains:
broadcast conversation (20%), broadcast news (13%), magazine (7%), newswire (21%), telephone
conversation (13%), weblogs and newsgroups (15%), and pivot text (11%). Most of these genres
are news-like, with the exception of the pivot texts (which come from the New Testament) and the
telephone conversations. We used the training, development, and test splits as defined in the shared
task (Table 1). Since the coreference annotations of OntoNotes do not contain any singleton mentions, we automatically marked as singleton all the noun phrases not annotated as coreferent. We
excluded verbal mentions.
Because we mark as singleton all the noun phrases not annotated as coreferent, our definition of
singletons includes non-referential noun phrases such as it in It is raining, and president in He served
as president for two terms (Section 3.1). This makes practical sense: the starting point of most
coreference resolution systems is to take all noun phrases as possible candidates for coreference
and subsequently find the clusters that are coreferent with one another. The more phrases we can
accurately identify as singleton, the more phrases we can exclude from this clustering step, which
should translate directly into performance gains.
453

DE

M ARNEFFE , R ECASENS & P OTTS

Referents

23140

2369
Singleton

2

797

415

236

436

140

61

92

3

4

5

6-10

11-15

16-20

>20

Mentions

Figure 1: Distribution of referent lifespans in the 2012 OntoNotes development set.

5. Predicting Lifespans with Linguistic Features
We now describe our model for predicting the lifespan of discourse referents using the linguistic
factors proposed in Section 2. The model makes a binary distinction between discourse referents
that are not part of a coreference chain (singleton) and those that are part of one (coreferent). The
distribution of lifespans in our data is shown in Figure 1.
This plot gives the number of entities associated with a single mention, the number associated
with two mentions, and so forth. The fact that singletons so dominate the data suggests that the binary singleton/coreferent division is a natural one. The propensity toward singletons also highlights
the relevance of detecting singletons for a coreference system. Following Bergsma and Yarowsky
(2011), we use a logistic regression model, which has been shown to perform well on a range of
NLP tasks. We fit the logistic regression model in R (R Development Core Team, 2013) on the training data, coding singletons as ‘0’ and coreferent mentions as ‘1’. Thus, throughout the following
tables of coefficient estimates, positive values favor coreferent mentions and negative values favor
singletons. We turn now to describing and motivating the features of this model.
5.1 Morphosyntax of the Mention
Table 2 summarizes the features from our model that concern the internal morphology and syntactic
structure of the mention, giving their coefficient estimates. In all the tables, if not indicated otherwise, the coefficient estimates are significant at p < 0.001. We use ∗ to indicate significance at
p < 0.05, and † to indicate estimates with p ≥ 0.05. The morphosyntactic features include type
(‘pronoun’, ‘proper noun’, ‘common noun’), animacy, named-entity tag, person, number, quantification (‘definite’, ‘indefinite’, ‘quantified’), and number of modifiers of the mention. Many are
common in coreference systems (Recasens & Hovy, 2009), but our model highlights their influence
on lifespans. Where available, we used gold annotations to derive our features, since our primary
goal is to shed light on the relevance of the features claimed to influence lifespans.
454

M ODELING THE L IFESPAN OF D ISCOURSE E NTITIES

The morphosyntactic features were operationalized using static lists and lexicons as well as the
Stanford dependencies as output by the Stanford parser (version 2.0.3; de Marneffe, MacCartney, &
Manning, 2006) on the gold constituent trees. The features are extracted in the following way:
Type The type feature captures whether the mention is a pronoun, proper noun, or common noun.
The value is determined by the gold POS tag of the mention and its named-entity tag.
Animacy We set animacy values (‘animate’, ‘inanimate’, ‘unknown’) using a static list for pronouns, named-entity tags (e.g., PERSON is animate whereas LOCATION is not), and a dictionary
bootstrapped from the Web (Ji & Lin, 2009).
Person Person values (‘1’, ‘2’, ‘3’) are assigned only to pronouns (identified by POS tag), using
a static list. Mentions that are not pronouns get a value of ‘0’.
Number The number value (‘singular’, ‘plural’, ‘unknown’) is based on a static list for pronouns,
POS tags, Bergsma and Lin’s (2006) static dictionary, and named-entity tags. (Mentions marked
as a named entity are considered singular with the exception of organizations, which can be both
singular and plural and get the value ‘unknown’.)
Quantification As we discussed in Section 2, indefinites and definites can be given a referential
semantics that pairs naturally with discourse anaphora, whereas the anaphoric possibilities of truly
quantified terms are restricted. To operationalize quantification and decide whether a mention is
definite, indefinite, or quantified, we use the dependencies to find possible determiners, possessors,
and numerical quantifiers of a mention. A mention is ‘definite’ if it is a named entity, if it has a
possessor (e.g., car in John’s car is definite), or if its determiner is definite (the), demonstrative,
or possessive. A mention is ‘quantified’ if it has a numerical quantifier (e.g., two cars) or if its
determiner is all, both, neither or either. All other mentions are ‘indefinite’.
Number of modifiers We added a feature counting how many modifiers the mention has, seeking to capture a correlation with specificity and referentiality. As modifiers, we counted adjectival,
participial, infinitival, and prepositional modifiers as well as relative clause modifiers, noun compounds, and possessives. (Thus, there are four modifiers in the phrase a modern multifunctional
business center costing 60 million yuan.)
Named entities Our model also includes named-entity features for all of the 18 OntoNotes entitytypes, with ‘NER = O’ true of non-named-entities. We used the gold entity-type annotation.
Table 2 summarizes the coefficient estimates we obtain for these features. In broad terms, the
picture is as one would expect from the taxonomy of given and new defined by Prince (1981b) and
assumed throughout dynamic semantics (Kamp, 1981; Heim, 1982): pronouns depend on anaphoric
connections to previous mentions for disambiguation and thus are likely to be coreferent. This is
corroborated by the positive coefficient estimate for ‘Type = pronoun’.
Few quantified phrases participate in discourse anaphora (Partee, 1987; Wang et al., 2006),
accounting for the association between quantifiers and singletons (as measured by the negative
coefficient estimate for ‘Quantifier = quantified’).
The negative coefficient for indefinites is initially surprising. As seen in Section 2, theories
stretching back to Karttunen (1976) say that indefinites excel at establishing new discourse entities
and so should be frequent participants in coreference chains, but here the association with such
455

DE

M ARNEFFE , R ECASENS & P OTTS

Feature

Coefficient

Feature

Coefficient

Type = pronoun
Type = proper noun
Animacy = inanimate
Animacy = unknown
Person = 1
Person = 2
Person = 3
Number = singular
Number = unknown
Quantifier = indefinite
Quantifier = quantified
Number of modifiers
NER = DATE
NER = EVENT
NER = FACILITY

1.17
1.89
−1.36
−0.39
1.04
0.13
1.62
0.61
0.17
−1.43
−1.25
−0.39
1.83
2.89
2.94

= GPE
NER = LANGUAGE
NER = LAW
NER = LOCATION
NER = MONEY
NER = NORP
NER = O
NER = ORDINAL
NER = ORGANIZATION
NER = PERCENT
NER = PERSON
NER = PRODUCT
NER = QUANTITY
NER = TIME
NER = WORK OF ART

3.46
2.56
2.85
2.83
0.05
0.82
4.17
−0.90
3.39
0.88
2.28
2.64
−0.02
1.53
2.42

NER

†

†

Table 2: Internal morphosyntactic features of the lifespan model. † indicates a non-significant coefficient (p ≥ 0.05); no sign indicates a significant coefficient (p < 0.001).

chains is negative. We return to this in Section 5.3, where we argue that interactions with semantic
operators explain this fact.
The behavior of the named-entity (NER) features is closely aligned with previous models and
our theoretical discussion above. As a rule, named entities behave like ‘Type = proper noun’ in associating with coreferent mentions. The exceptions are MONEY, ORDINAL, NORP (for nationalities
and religions), PERCENT, and QUANTITY, which seem intuitively unlikely to participate in coreference chains. The person, number, and animacy features together suggest that singular animates are
excellent coreferent noun phrases.
The one real surprise for us here concerns the feature ‘Number of modifiers’. Inspired by observations of Fodor and Sag (1982) and Schwarzschild (2002), we expected this feature to positively
correlate with being coreferent. Our reasoning was that increased modification would likely result
in increased specificity, thereby making the associated discourse referent more identifiable and more
distinctive. The opposite seems to hold in our data. However, we hesitate to conclude from this that
the original hypothesis is mistaken. Rather, we suspect that our model is just insufficiently sensitive
to interactions between modifier counts and the lexical semantics of the modifiers themselves.
5.2 Grammatical Role of the Mention
Synthesizing much work in Centering Theory and information structuring, we hypothesized that
coreferent mentions are likely to appear as core verbal arguments and favor sentence-initial (topictracking) positions (Ward & Birner, 2004). To capture these insights, we used the grammatical
relation of the mention given by the Stanford dependencies on gold constituents, and the sentence
position of the mention.
456

M ODELING THE L IFESPAN OF D ISCOURSE E NTITIES

Feature

Coefficient

Feature

Coefficient

Sentence Position = end
Sentence Position = first
Sentence Position = last
Sentence Position = middle
In coordination

−0.22
0.03
−0.31
−0.11
−0.48

Relation = noun argument
Relation = other
Relation = root
Relation = subject
Relation = verb argument

0.56
−0.67
−0.61
0.65
0.32

†

Table 3: Grammatical role features of the lifespan model. † indicates a non-significant coefficient
(p ≥ 0.05); no sign indicates a significant coefficient (p < 0.001).

Sentence position Sentence position was determined based on the raw string: ‘first’ indicates that
the mention is the first word of the sentence, ‘end’ the last word, and ‘begin’, ‘middle’, and ‘last’
indicate whether the mention is situated in the first, second, or last third of the sentence, respectively.
Relation To distinguish among grammatical relations, we check whether the mention is a ‘subject’, ‘adjunct’ (which includes prepositional objects, adverbial modifiers, and temporal modifiers),
‘verb argument’ (which includes direct and indirect objects, clausal complements, adjectival complements and attributes), or ‘noun argument’ (which includes relative clauses, appositions, possessives, noun compounds, and adjectival modifiers).
In coordination We also indicated whether or not the mention is a conjunct to see whether being
inside a coordinate phrase affects coreference in ways that go beyond the grammatical role of the
containing phrase.
The coefficient estimates in Table 3 support our general hypotheses: arguments make good discourse
referents, subjects best of all, whereas sentence-final positions disfavor coreference. In addition, we
note that the model identifies a negative correlation between coordination and coreference.
5.3 Semantic Environment of the Mention
Table 4 highlights the complex interactions between discourse anaphora and semantic operators introduced in Section 2. These interactions have been a focus of logical semantics since Karttunen
(1976), whose guiding observation is semantic: an indefinite interpreted inside the scope of a negation, modal, or attitude predicate is generally unavailable for anaphoric reference outside of the
scope of that operator. Heim (1992) also relates the anaphoric properties of NPs to scope-taking
and the entailments of attitude predications.
We do not have direct access to semantic scope, but we expect syntactic scope to correlate
strongly with semantic scope. We therefore used dependency representations to define features
capturing syntactic scope for negation, modal auxiliaries, and a broad range of attitude predicates
(181 verbs and 374 nouns from Saurı́, 2008). Technically, for a given mention, we produce a
‘negation’, ‘modal’ or ‘under attitude verb’ feature according to the presence of pre-defined negation
or modality markers (such as not, can, may) or attitude predicates (e.g., accuse, allege, doubt, say)
in the dependency path. For example, the NP relief will be given a ‘negation’ feature in while the
financial storm shows no sign of relief today, since it is under the scope of no sign. Similarly, the
mention scientific and technological companies is in the scope of the modal auxiliary would and the
457

DE

M ARNEFFE , R ECASENS & P OTTS

Feature

Coefficient

Presence of negation
Presence of modality
Under an attitude verb
AttitudeVerb * (Type = pronoun)
AttitudeVerb * (Type = proper noun)
AttitudeVerb * (Quantifier = indefinite)
AttitudeVerb * (Quantifier = quantified)
Modal * (Type = pronoun)
Modal * (Type = proper noun)
Modal * (Quantifier = indefinite)
Modal * (Quantifier = quantified)
Negation * (Type = pronoun)
Negation * (Type = proper noun)
Negation * (Quantifier = indefinite)
Negation * (Quantifier = quantified)
Negation * (Number of modifiers)

−0.18
−0.22
0.10
0.41
0.10
−0.19
0.10
0.13
0.35
−0.00
0.17
1.07
0.30
−0.36
−0.39
0.11

†
∗
†
†

†

Table 4: Semantic environment features and interactions in the lifespan model. † indicates a nonsignificant coefficient (p ≥ 0.05); no sign indicates a significant coefficient (p < 0.001); ∗
indicates significance at p < 0.05.

attitude verb said in firms from Taiwan said that they would establish scientific and technological
companies in the zone, and so it receives ‘modal’ and ‘under attitude verb’ features.
Table 4 summarizes our model’s semantic environment features and their interactions. The interaction terms added to the model follow the previous linguistic literature: we expect that the scope
of the semantic operators (negation, modality and attitude predicate) will interact with the internal syntax of the mention, specifically with its type and its definiteness/quantification. The results
are beautifully aligned with our guiding linguistic hypotheses. First, negation and modality both
negatively correlate with coreference, as expected given the constraints they impose on lifespans.
Interacting these semantic features with those for the internal syntax of mentions also yields the
expected results: since proper names and pronouns are not scope-taking, they are largely unaffected
by the environment features, whereas indefinites, which are affected by scope, emerge as even more
restricted, just as Karttunen and others would predict.
The coefficient values for attitude predicates and their interactions seem anomalous in light of
the semantics of these items. In Section 2, we noted that non-factive attitude predicates like say
cannot offer semantic guarantees that mentions in their scope will survive outside that scope. This
might lead one to think that they will be biased against long-lived mentions, when in fact we see the
opposite. However, we also observed that pragmatic factors often facilitate exceptional anaphoric
dependencies in attitude predications. Karttunen (1973) referred to this as the ‘leakiness’ of these
predicates — information introduced in their scope seems often to percolate up to the text level in
a wide range of contexts (Rooryck, 2001; Simons, 2007; Harris & Potts, 2009). Since the lifespan
458

M ODELING THE L IFESPAN OF D ISCOURSE E NTITIES

# F EATURES
L INGUISTIC
S URFACE
C OMBINED
C ONFIDENT

123
73,393
73,516
73,516

S INGLETON
Recall Precision F1
80.2
80.2
81.1
56.0

77.5
79.9
80.8
89.8

78.8
80.0
80.9
69.0

C OREFERENT
Recall Precision F1
71.4
75.3
76.4
48.2

74.6
75.6
76.6
90.7

73.0
75.4
76.5
62.9

ACCURACY
76.3
78.0
79.0
52.5

Table 5: Recall, precision, F1 and accuracy for the three different sets of features on the OntoNotes
development set. C ONFIDENT is the C OMBINED model in which singleton is predicted if
Pr < 0.2 and coreferent if Pr > 0.8.

model is trained on real usage data, it is not surprising that it reflects these pragmatic factors rather
than just the lexical semantics (de Marneffe et al., 2012).
As noted earlier, features in Table 4 are not standardly used in coreference systems. Uryupina
(2009) notes that the Karttunen features she implemented (see Section 3) do not significantly improve the performance of her discourse-new mention and non-antecedent detectors. Contrary to
Uryupina, adding the features in Table 4 to a model which only incorporates the features described
in Table 2 and Table 3 results in a significantly better model (likelihood ratio test, p < 0.001). The
accuracy on the CoNLL-2012 development set also improves when adding the Karttunen features
(McNemar’s test, p < 0.001).
5.4 Results
As highlighted above, the lifespan model we built from the OntoNotes data confirms the claims by
Karttunen and others concerning how semantic operators interact with specific kinds of mention.
This is novel quantitative evidence for such theories. The model also successfully learns to tease
singleton and coreferent mentions apart, suggesting that it has practical value for NLP applications.
The first row of Table 5 summarizes the linguistic model performance on the development set of
the OntoNotes data described in Section 4, giving precision, recall, and F1 measures for singleton
and coreferent mentions. The accuracy of the model is 76.3%. A majority baseline, predicting all
mentions as singletons, leads to an accuracy of 55.1%.

6. Extension to Bridging
The lifespan model suggests a new perspective on bridging anaphora, which we discussed briefly
in Section 3.2 using example (14), repeated here:
(15)

I looked into the room. The ceiling was very high.

The anchor phrase the room is superficially singleton in this discourse, but its intuitive lifespan
is longer: it makes salient a discourse referent for the ceiling of the room, which the ceiling in
the second sentence then refers to. The bridging relationship keeps the room alive as a discourse
referent, extending its lifespan, though not in a way that can be read directly off of the text. Together
with the basic tenets of the lifespan model, these observations suggest a testable hypothesis about
459

DE

M ARNEFFE , R ECASENS & P OTTS

bridging: even when bridging anchors are superficially singleton (henceforth, singleton anchors),1
our lifespan model should tend to classify them as coreferent, since the model is not designed to
detect later mentions per se, but rather to capture more abstract information about the roles that
entities play in discourse.
OntoNotes does not contain annotations for bridging anaphora, so evaluating this hypothesis is
not straightforward. However, Hou, Markert, and Strube (2013) annotated 50 of the WSJ texts in
OntoNotes for bridging information, yielding annotations for 663 bridging anchors. Of these, 145
are singleton anchors in the sense that we identify them (Section 4) and thus can be used to assess
our model’s ability to detect the abstract sense in which bridging anchors are long-lived.
Ideally, we would simply run our trained lifespan model on these examples. This proves ineffective, though, because (outside of Hou et al.’s data) the OntoNotes annotations treat singleton
anchors as singleton, meaning that our trained lifespan model is optimized on data that obscure the
distinction of interest. Nonetheless, we expect the feature representations that form the backbone of
the lifespan model to be able to distinguish true singletons from singleton anchors if given the right
kind of training data. The small number of relevant bridging annotations poses some obstacles to
pursuing this idea, but we sought to navigate around them as follows: using the annotated corpus
of Hou et al., we extract all 145 of the singleton anchors and then sample an additional 145 true
singletons from those documents (from a total of 5,804 such cases). This yields a data set that we
can be confident makes the relevant distinction. We then randomly divide this data set into 80%
training data and 20% testing data, and conduct a standard classifier evaluation. We use a logistic
regression classifier, employing recursive feature elimination with cross-validation (Guyon, Weston,
& Barnhill, 2002), as implemented by Pedregosa et al. (2011), to try to find a compact model that
is effective for the small data set. The model used an `2 regularizer with a penalty of 0.5, though
`1 regularization and changes to the penalty delivered essentially the same results, both with and
without the recursive feature elimination step.
Because these train and test sets are small, performance varies greatly depending on the nature
of the true singleton sample, so we repeat this experiment 1,000 times and average the results. With
this procedure, our lifespan feature representations achieve a mean F1 of 65% (standard error 0.002;
mean precision 62%, mean recall 0.69%), indicating our lifespan-based features are sensitive to the
distinction between singleton anchors and true singletons. This finding further bolsters the design
of the lifespan feature representations and also shows that “lifespan” is deeper and more abstract
than merely counting referents. Given the right kind of annotations, we believe our model could be
extended to provide an even fuller treatment of bridging, which is governed partly by its own mix
of linguistic and contextual factors (Hawkins, 1978; Prince, 1981b; Schwarz, 2009).

7. Predicting Lifespans with Surface Features
Durrett and Klein (2013) and Hall et al. (2014) showed that, on the tasks of coreference resolution
and parsing, a large quantity of surface-level information can not only implicitly model some linguistic features, but also capture other patterns in the data that are not easily identified manually.
Given the large amount of annotated data available in the OntoNotes corpus, we might expect a
sufficient amount of surface-level data to capture some of the linguistic insights hand-engineered in
1. Some bridging anchors also have literal coreferent mentions, as in I looked into the room. It was empty, and the
ceiling was very high., where the room is coreferent with it in addition to providing discourse support for the ceiling.
We set aside such cases in our bridging experiments.

460

M ODELING THE L IFESPAN OF D ISCOURSE E NTITIES

the lifespan model defined above. We therefore tested how a model using POS tags and n-grams
fares on the lifespan task.
We used the following features in this surface model: the lemmas of all the words in the mention,
the POS tags of all the words in the mention, the POS tag of the head of the mention, and the lemma
and POS tags of the two words preceding and following the mention (with dummy BEGIN and END
words to mark the beginning and end of sentences). As suggested by Durrett and Klein (2013), such
features might capture information encoded in the NER tag, number, person, and sentence position.
The surface model’s performance is reported in the second row of Table 5. For all models in
Table 5, the `2 regularization penalty was chosen via five-fold cross-validation on the training data.
For the linguistic model, using the tuned `2 regularization penalty rather than the default one makes
almost no difference, but it substantially improves performance for the models with more features.
We additionally experimented with different algorithms for feature selection, but found that the
results were invariably best, for all our models, when we retained their full sets of features. The last
row of the table gives the performance of a model in which we combine both the linguistic and the
surface features to evaluate whether the surface features alone cover all the information captured by
the linguistic features, or whether the linguistic features have additional predictive value.
The surface model performs better than the linguistic-only model, especially for the coreferent
category. However, the small number of linguistically-motivated features yields results in the same
range as those obtained with the large number of features in the surface model, which might be
of importance for tasks where only a small amount of annotated data is available, such as in the
bridging experiment in Section 6. (The obvious trade-off here is that the surface features are easier
to specify and implement.) As shown in the C OMBINED row of Table 5, combined with the surface
feature set, the linguistically-motivated features give a statistically significant boost in performance.
This suggests that the surface features miss certain long-distance interactions between discourse
anaphora and semantic operators — interactions that the linguistic features explicitly encode.
Our best model for predicting lifespan is the combined one. Instead of using the standard 0.5
threshold as decision boundary, we can also make use of the full distribution returned by the logistic regression model and rely only on confident decisions. The resulting C ONFIDENT model is a
C OMBINED one that predicts singleton if Pr < 0.2 and coreferent if Pr > 0.8. The threshold values
reported here are the best trade-off we found between a precision score close to 0.90 without losing
too much in recall. As expected, by using such a highly confident model, we increase precision,
though at a cost to recall. Which kind of model is preferred will depend on the application; as noted
by Ng (2004) and Uryupina (2009), when incorporating the lifespan model in downstream NLP
applications, we often want highly accurate predictions, which favors a model like C ONFIDENT.

8. Application to Coreference Resolution
To further assess the value of the lifespan model for NLP applications, we now incorporate the best
feature combination into two state-of-the art coreference resolution systems: the Stanford system
(Lee et al., 2011) and the Berkeley system (Durrett & Klein, 2013). In both cases, the original
model serves as our baseline, and we focus on the extent to which the lifespan model contributes
to improvements to that baseline. This allows us to quantify the power and effectiveness of the
lifespan model in two very different systems — a rule-based one (Stanford) and a learning-based
one (Berkeley).
461

DE

M ARNEFFE , R ECASENS & P OTTS

8.1 Evaluation Measures
To evaluate the incorporation of the lifespan model into the coreference systems, we use the English
development and test sets from the CoNLL-2011 and CoNLL-2012 Shared Tasks. Although the
CoNLL shared tasks evaluated systems on only multi-mention (i.e., non-singleton) entities, we can
still expect the lifespan model to help: by stopping singletons from being linked to multi-mention
entities, we expect to see an increase in precision. Our evaluation uses the measures given by the
CoNLL scorer:
• MUC (Vilain, Burger, Aberdeen, Connolly, & Hirschman, 1995): Link-based metric that
measures how many links the gold and system partitions have in common.
• B3 (Bagga & Baldwin, 1998): Mention-based metric that measures the proportion of mention
overlap between gold and predicted entities.
• CEAF-φ3 (Luo, 2005): Mention-based metric that, unlike B3 , enforces a one-to-one alignment between gold and predicted entities.
• CEAF-φ4 (Luo, 2005): The entity-based version of the above metric.
• CoNLL (Denis & Baldridge, 2009; Pradhan, Ramshaw, Marcus, Palmer, Weischedel, & Xue,
2011): Average of MUC, B3 and CEAF-φ4 .
• BLANC (Recasens & Hovy, 2011): Link-based metric that takes the mean of coreference
and non-coreference links, thereby rewarding (but not over-rewarding) singletons.
We use the new CoNLL coreference scorer (Pradhan, Luo, Recasens, Hovy, Ng, & Strube, 2014,
version 8.0), which fixes a bug in previous versions concerning the way gold and predicted mentions
are aligned when evaluating on automatically predicted mentions. The new scorer does not modify
either the gold or system output, but implements the measures as originally proposed, and extends
BLANC to successfully handle predicted mentions, following Luo, Pradhan, Recasens, and Hovy
(2014).
8.2 Incorporating the Lifespan Model into the Stanford Coreference System
The Stanford system was the highest-scoring system in the CoNLL-2011 Shared Task (Pradhan
et al., 2011), and was also part of the highest-scoring system (Fernandes, dos Santos, & Milidiú,
2012) in the CoNLL-2012 Shared Task (Pradhan et al., 2012). It is a rule-based system that includes
a total of ten rules (or “sieves”) for entity coreference, such as exact string match and pronominal
resolution. The sieves are applied from highest to lowest precision, each rule adding coreference
links. In each coreference resolution sieve, the document’s mentions are traversed left to right. To
prune the search space, if a mention has already been linked to another one by a previous sieve,
only the mention that is first in textual order is considered by the subsequent sieves. Furthermore,
mentions that are headed by an indefinite pronoun (e.g., some, other) or start with an indefinite
determiner (a, an) are discarded if there is no antecedent that has the exact same string. Each
mention is compared to the previous mentions in the text until a coreferent antecedent is found
(according to the current sieve) or the beginning of the text is reached. Candidates are sorted using
a left-to-right breadth-first traversal of the parse tree, which favors subjects and syntactic salience
in general.
The lifespan model can improve coreference resolution in two different ways: (i) mentions classified as singletons should not be considered as either antecedents or coreferent, and (ii) mentions
462

M ODELING THE L IFESPAN OF D ISCOURSE E NTITIES

classified as coreferent should be linked with other mention(s). By successfully predicting singletons (i), we can enhance the system’s precision; by successfully predicting coreferent mentions (ii),
we can improve the system’s recall. Here we focus on (i) and use the lifespan model for detecting
singletons. This decision is motivated by two factors. First, given the large number of singletons
(Figure 1), we are more likely to see a gain in performance from discarding singletons. Second, the
multi-sieve nature of the Stanford coreference system does not make it straightforward to decide
which antecedent a mention should be linked to even if we know that it is coreferent.
To integrate the singleton model into the Stanford coreference system, we depart from previous
work by not letting a sieve consider whether a pair of mentions is coreferent if both mentions are
classified as singletons by our C ONFIDENT model and the mentions are not a named entity. In doing
this, we discard 29% of the NPs under consideration. Experiments on the development set yielded
higher performance when not taking into account named entities. Performance was higher with the
C ONFIDENT model than with the S TANDARD model.
We therefore use the lifespan model to help coreference resolution as a pre-filtering step to
coreference resolution, discarding mentions tagged as singletons by the lifespan model. Previous
work on incorporating a non-referentiality or discourse-new detection module as a pre-processing
step for coreference resolution has shown mixed results, as we discussed in Section 3. The general
arguments for pipeline vs. joint approaches apply here: pipeline approaches prevent recovering from
errors earlier in the pipeline, but joint approaches tend to increase model complexity and associated
optimization challenges, and they do not easily allow separating different modules, which makes
feature design and error analysis more difficult as well. In any case, in the context of the Stanford
system’s sieve-architecture, it is more natural to add the lifespan model as a pre-filtering step.
8.2.1 R ESULTS
Table 6 summarizes the performance of the Stanford system on the CoNLL-2011 and CoNLL-2012
development and test sets. To evaluate the incorporation of the lifespan model in a realistic setting,
we use the automatic parses, and the POS and NER tags provided in the CoNLL documents. All the
scores are on automatically predicted mentions. The baseline is the Stanford coreference system,
and ‘w/ Lifespan’ is that system extended with our lifespan model to discard singletons, as explained
above. Stars indicate a statistically significant difference (Wilcoxon signed-rank test, p < 0.05)
according to jackknifing (10 partitions of the development set or the test set, balanced over the
different domains2 of the corpus). As expected, the lifespan model significantly increases precision
(up to +4.0 points) but decreases recall (by −0.7 points). Overall, however, the gain in precision is
higher than the loss in recall, and we obtain a significant improvement of 0.4–1.5 points in the F1
score of all evaluation measures.
8.2.2 E RROR A NALYSIS
Kummerfeld and Klein (2013) provide a useful tool for automatically analyzing and categorizing
errors made by coreference resolution systems. The tool identifies seven intuitive error types: span
error, conflated entities (entity mentions that do not corefer are clustered together), extra entity
(entities that are not in the gold data are added), extra mention (the system incorrectly introduces
2. As mentioned in Section 4, the OntoNotes corpus contains documents from seven different domains and coreference
performance has been shown to vary highly depending on the domain (Pradhan et al., 2012).

463

DE

CoNLL
F1

Stanford
2011 DEV SET
Baseline
w/ Lifespan
Discourse-new

R

M ARNEFFE , R ECASENS & P OTTS

MUC
P

F1

R

B3
P

F1

R

CEAF-φ4
P
F1

51.49
52.23*
51.52

58.00* 55.97 56.97
57.57 57.72* 57.65*
56.30 58.98* 57.61*

48.01* 49.81 48.89
47.45 51.62* 49.45*
45.51 52.33* 48.68

54.27* 44.03 48.62
53.46 46.27* 49.60*
48.63 47.93* 48.28

2011 TEST SET
Baseline
50.55
w/ Lifespan
51.58*
Discourse-new 51.26*

60.09* 56.09 58.02
59.75 58.32* 59.03*
58.92 59.71* 59.31*

47.57* 47.91 47.74
47.06 50.18* 48.57*
45.72 51.06* 48.25*

52.28* 40.90 45.89
51.42 43.50* 47.13*
47.41 45.1* 46.22

2012 DEV SET
Baseline
w/ Lifespan
Discourse-new

55.26
55.77*
53.63

61.36* 65.26 63.25
60.99 66.70* 63.72*
60.71 63.27 61.96

48.35* 57.05 52.34
47.87 58.57* 52.68*
47.25 54.42 50.58

53.86* 47.01 50.20
53.10 48.91* 50.92*
49.35 47.41* 48.36

2012 TEST SET
Baseline
53.31
w/ Lifespan
54.58*
Discourse-new 53.01

62.05* 61.35 61.70
61.31 65.61* 63.39*
61.22 62.73* 61.97

48.00* 52.66 50.22
46.91 57.05* 51.49*
46.72 53.62* 49.93

52.29* 44.36 48.00
51.03 46.87* 48.86*
48.38 45.92* 47.12

(a)

Stanford

R

CEAF-φ3
P
F1

R

BLANC
P
F1

2011 DEV SET
Baseline
w/ Lifespan
Discourse-new

57.11* 52.50 54.71
56.55 54.43* 55.47*
54.02 55.67* 54.83

45.04* 46.84 45.14
44.37 48.65* 45.85*
42.59 49.57* 45.60

2011 TEST SET
Baseline
w/ Lifespan
Discourse-new

55.57* 49.56 52.39
55.04 51.80* 53.37*
53.2
53.08* 53.14*

46.46* 47.51 46.12
45.98 49.53* 47.06*
44.87 50.82* 47.33*

2012 DEV SET
Baseline
w/ Lifespan
Discourse-new

56.59* 57.22 56.90
56.11 58.75* 57.40*
55.00 56.18 55.58

48.78* 56.47 51.94
48.23 57.94* 52.36*
48.11 54.12 50.73

2012 TEST SET
Baseline
w/ Lifespan
Discourse-new

56.12* 53.46 54.76
54.98 56.69* 55.82*
54.43 54.78* 54.60

49.08* 54.48 50.88
47.69 59.15* 52.28*
47.95 55.81* 51.14*

(b)

Table 6: Performance of the Stanford system on the CoNLL-2011 and CoNLL-2012 development
and test sets. Scores (v8.0 of the CoNLL scorer) are on automatically predicted mentions,
using the CoNLL automatic annotations. Stars on the ‘w/ Lifespan’ and ‘Discourse-new’
rows indicate a significant difference from the baseline (Wilcoxon signed-rank test, p <
0.05).
464

M ODELING THE L IFESPAN OF D ISCOURSE E NTITIES

Error

they1

Gold
scientists1
they1
his family2
they2

Extra entity

various major Hong Kong media
no media

–
–

Extra mention

a book
the book
it

–
the book
it

Conflated entities

System
scientists1
they1

(a) Errors affecting precision.

Error

System
scientists1
they1
his family2
they1

Gold
scientists1
they1
his family2
they2

Missing entity

–
–

a network
it

Missing mention

two mothers
their
–

two mothers
their
two mothers who lost very loved ones

Divided entity

(b) Errors affecting recall.

Table 7: Illustration of the error types provided by Kummerfeld and Klein’s (2013) system: errors
made by the Stanford coreference system on the CoNLL-2012 development set.

a mention as coreferent in a cluster),3 divided entity (an entity is split into two or more different
clusters),4 missing entity (the system fails to detect an entity), and missing mention (an entity is
missing one of its mentions). Table 7 illustrates the error types we are interested in,5 showing errors
made by the Stanford system, separated into those affecting precision and those affecting recall.
We ran Kummerfeld and Klein’s (2013) system on the Stanford output to quantify the improvement obtained by incorporating the lifespan model into the coreference system for the CoNLL-2012
development set. Figure 2 shows the difference in errors between the original Stanford coreference
system and the system in which the lifespan model is integrated. The lifespan model generally
reduces errors affecting precision, most notably by getting rid of some spurious entities (“Extra
entity”). The top three errors in Table 7 — all precision-related — are fixed by integrating the lifespan model into the Stanford system. On the other hand, the bottom two errors — recall-related —
3. The distinction between the two categories conflated entities and extra mention makes sense in a corpus like
OntoNotes where singletons are not annotated: the former occurs when the system clusters one or more mentions
from a multi-mention entity into an incorrect entity, whereas the latter occurs when the system incorrectly clusters
with others a mention that is truly part of a singleton entity (and so not annotated in the gold).
4. A conflated-entities error and a divided-entity error often co-occur.
5. The “span error” category is not relevant in the comparison here: both systems (with and without lifespan) work on
the same predicted mentions.

465

DE

M ARNEFFE , R ECASENS & P OTTS

Stanford alone

Conflated entities

Extra entity

Extra mention

with lifespan

897

Stanford alone

728

with lifespan

Stanford alone

535

with lifespan

523

Stanford alone

Divided entities

Missing entity

Missing mention

1635
1607

with lifespan

2038
2021

830

Stanford alone

877

with lifespan

Stanford alone

1154

with lifespan

1158

Figure 2: Number of errors for the Stanford coreference system (with and without the lifespan
model) on the CoNLL-2012 development set.

are introduced by the lifespan model. However, the cumulative gain in error reduction across error
categories results in a significant improvement in overall coreference performance.
8.2.3 U SING THE L IFESPAN M ODEL AS A D ISCOURSE -N EW M ENTION C LASSIFIER
As we discussed in Section 3.3, previous work (Ng & Cardie, 2002; Uryupina, 2009) reports a
loss in coreference resolution performance when pre-filtering discourse-new mentions, i.e., singleton mentions as well as mentions that start a coreference chain. To mimic such pre-filtering, we
incorporate the lifespan model into the Stanford system in the following way: only mentions that
our model does not classify as singletons are considered by every sieve and hypothesized to corefer
with some other previous mention, while discourse-new mentions are removed from consideration.
When we do so, we also see a performance loss, as shown in the ‘Discourse-new’ rows of Table 6. There are no clear significant gains across the measures, compared to the performance of the
standard Stanford system (‘Baseline’ rows). The improvements we do see in Table 6 result from
pre-filtering pairs of mentions both of which our lifespan model classifies as singletons. This stricter
constraint seems to balance out the loss of pre-filtering too many mentions at this early stage.
8.3 Incorporating the Lifespan Model into the Berkeley Coreference System
The Berkeley coreference system (Durrett & Klein, 2013; Durrett, Hall, & Klein, 2013) is currently
the highest scoring coreference system that is publicly available. It uses a mention-synchronous
framework: for each mention, the system either chooses one antecedent or decides that the mention
starts a new cluster (perhaps leading to a singleton cluster). It is a log-linear model in which features
are extracted over mentions to decide whether or not the mentions are anaphoric, and features are
extracted over pairs of mentions to decide whether or not the pairs corefer. The baseline we compare
466

M ODELING THE L IFESPAN OF D ISCOURSE E NTITIES

against takes the best feature set, the ‘FINAL’ one, as reported by Durrett and Klein (2013), which
combines a large number of lexicalized surface features as well as semantic features.
To incorporate the lifespan model into the Berkeley system, we use the probabilities of the
mentions given by the lifespan model. For each pair of mentions, we add lifespan features by
adding the lifespan probability for each mention. We also add a singleton feature if both mentions
have a lifespan probability below 0.2, and a coreferent feature if both mentions have a lifespan
probability above 0.8. Unlike the Stanford architecture, where exploiting the coreferent predictions
is not straightforward (Section 8.2), the learning-based setup of the Berkeley system allows us to
make use of the lifespan probabilities without focusing only on singleton-class prediction.
Instead of incorporating the lifespan probabilities from the lifespan model, we also tried adding
to the Berkeley system all features from the lifespan model not already present in the Berkeley
system (i.e., all the features in Table 3 and Table 4). However, while it did lead to significant
improvements for the CoNLL 2012 development data, it did not for the CoNLL 2012 test data.
Moreover, overall results were less good than when incorporating the probabilities in the manner
described above.
8.3.1 R ESULTS
Table 8 shows the results of the Berkeley system on the CoNLL 2011 and 2012 development and
test sets. As with the Stanford system, all the scores are on automatically predicted mentions. We
use the automatic POS tags, parse trees, and NER annotations provided in the CoNLL data both
for training and testing. We restrict training to the training data only.6 The baseline is the ‘FINAL’
Berkeley coreference system, and ‘w/ Lifespan’ is the same system extended with the lifespan,
singleton and coreferent features, as explained above. Significance is computed in the same way as
for the Stanford system (we created 10 partitions of the development set or the test set, balanced
over the different domains of the corpus).
In the learning-based context of the Berkeley system, the lifespan model increases precision as
well as recall, leading to a final improvement in the CoNLL score of 1.0 to 2.0 points. Since we
use the lifespan model for predicting both singleton and coreferent mentions, we manage to improve both precision and recall. This provides additional empirical support for splitting coreference
resolution into an entity-lifespan task that predicts which mentions refer to the long-lived entities
in a discourse and a coreference task that focuses on establishing coreference links between these
mentions.
8.3.2 E RROR A NALYSIS
Parallel to our analysis of the Stanford coreference system output, we ran Kummerfeld and Klein’s
(2013) system on the Berkeley output. Figure 3 shows the difference in errors between the original Berkeley coreference system (‘FINAL’ feature set) and that system enhanced with the lifespan
model. The enhanced system commits fewer errors affecting precision (upper part of Figure 3),
6. We also tried training on the gold POS tags, parse trees, and NER annotations provided in the CoNLL data, but
using the automatic annotations at test time. This does not make any difference for the original Berkeley system.
When incorporating the linguistic features (either the lifespan probabilities or all features from the lifespan model
not already in the Berkeley system), such a setting does lead to significant improvements over the baseline. However,
improvements do not hold consistently across the development and test sets: when compared to results obtained with
training on automatic annotations, training on gold improves the performance of the linguistically informed systems
only for the test set.

467

DE

Berkeley

CoNLL
F1

R

M ARNEFFE , R ECASENS & P OTTS

MUC
P

F1

R

B3
P

F1

R

CEAF-φ4
P
F1

2011 DEV SET
Baseline
59.72
w/ Lifespan 61.03*

62.67 70.22 66.23
64.78* 72.24* 68.30*

52.19 62.54 56.90
54.65* 63.28* 58.65*

53.77* 58.43 56.00
52.89 59.83* 56.15

2011 TEST SET
Baseline
59.06
w/ Lifespan 59.65*

64.14 71.68 67.70
64.96* 73.29* 68.87*

50.81 61.31 55.56
51.78* 62.38* 56.59*

51.66* 56.34 53.90
49.89 57.62* 53.48

2012 DEV SET
Baseline
61.49
w/ Lifespan 63.42*

69.06 71.32 70.17
70.76* 74.30* 72.49*

57.10 60.55 58.78
59.35* 62.79* 61.02*

55.20* 55.80 55.50
54.74 58.94* 56.76*

2012 TEST SET
Baseline
61.06
w/ Lifespan 62.15*

69.17 71.96 70.54
70.42* 74.07* 72.20*

55.77 60.50 58.04
56.87* 62.21* 59.42*

53.82* 55.37 54.58
52.64 57.20* 54.83

(a)

Berkeley

R

CEAF-φ3
P
F1

R

BLANC
P
F1

2011 DEV SET
Baseline
w/ Lifespan

58.82 65.37 61.92
59.29* 66.36* 62.63*

50.38 59.93 54.73
52.83* 62.92* 57.37*

2011 TEST SET
Baseline
w/ Lifespan

56.71
56.37

63.01 59.70
63.96* 59.93

49.11 59.67 53.88
50.66* 61.87* 55.68*

2012 DEV SET
Baseline
w/ Lifespan

62.29
62.65

64.01 63.14
66.18* 64.37*

60.32 60.79 60.53
62.19* 63.80* 62.86*

2012 TEST SET
Baseline
w/ Lifespan

60.83 63.12 61.95
61.05* 64.68* 62.81*

57.70 61.79 59.68
58.92* 63.93* 61.32*

(b)

Table 8: Performance of the Berkeley system on the CoNLL 2011 and CoNLL 2012 development
and test sets. Scores (v8.0 of the CoNLL scorer) are on automatically predicted mentions,
using the CoNLL automatic annotations. Stars indicate a significant difference (Wilcoxon
signed-rank test, p < 0.05).

but not significantly for each category. However, the cumulative gains do result in a significant
improvement in overall precision. Globally, the lifespan model fixes more errors than it brings in.
468

M ODELING THE L IFESPAN OF D ISCOURSE E NTITIES

Berkeley alone

Conflated entities

Extra entity

Extra mention

with lifespan

Berkeley alone
with lifespan

579
533

594

Berkeley alone
with lifespan

508

Berkeley alone

Divided entities

Missing entity

Missing mention

1448
1412

with lifespan

Berkeley alone

818

with lifespan

820

Berkeley alone
with lifespan

1669
1572

829
941

Figure 3: Number of errors for the Berkeley coreference system (with and without the lifespan
model) on the CoNLL 2012 development set.

9. Conclusion
What factors determine the fate of a given discourse referent? Is it nature (its internal morphosyntax) or nurture (the broader syntactic and semantic environments of its mentions)? Our lifespan
model (Section 5) suggests that nature, nurture, and their interactions are all important. The model
validates existing linguistic generalizations about discourse anaphora (Section 2), and provides new
insights into previous engineering efforts in a similar direction (Section 3). We also show that
linguistically-motivated features bring improvement on top of surface features (Section 7), demonstrating that automatic language processing should not rely only on machine learning and big data.
The lifespan model performs well in its own right, achieving 79% accuracy in predicting whether
a given mention is singleton or coreferent. This alone could have ramifications for tracking topics,
identifying protagonists, and discourse coherence. In this paper, we demonstrated the benefits of
the lifespan model for coreference resolution. We incorporated the lifespan model into two very
different coreference resolution systems and showed that it yields improvements of practical and
statistical significance in both cases (Section 8).
Stepping back, we hope to have provided a compelling illustration of how efforts in theoretical
linguistics and NLP can complement each other, both for developing models and for assessing them
in scientific and engineering contexts.

Acknowledgments
We thank Jefferson Barlew, Greg Durrett, Micha Elsner, Gregory Kierstead, Craige Roberts, Michael
White, the Stanford NLP Group, and our anonymous reviewers for their helpful suggestions on earlier drafts of this paper. This research was supported in part by ONR grant No. N00014-10-1-0109
and ARO grant No. W911NF-07-1-0216.
469

DE

M ARNEFFE , R ECASENS & P OTTS

References
Aissen, J. (1997). On the syntax of obviation. Language, 73(4), 705–750.
Aissen, J. (2003). Differential object marking: Iconicity vs. economy. Natural Language and
Linguistic Theory, 21(3), 435–483.
Aloni, M. (2000). Quantification under Conceptual Covers. Ph.D. thesis, University of Amsterdam.
AnderBois, S., Brasoveanu, A., & Henderson, R. (2010). Crossing the appositive/at-issue meaning
boundary. In Li, N., & Lutz, D. (Eds.), Proceedings of Semantics and Linguistic Theory 20,
pp. 328–346. CLC Publications.
Bagga, A., & Baldwin, B. (1998). Algorithms for scoring coreference chains. In Proceedings of the
LREC 1998 Workshop on Linguistic Coreference, pp. 563–566.
Baker, C. L. (1970). Double negatives. Linguistic Inquiry, 1(2), 169–186.
Barzilay, R., & Lapata, M. (2008). Modeling local coherence: An entity-based approach. Computational Linguistics, 34(1), 1–34.
Bean, D. L., & Riloff, E. (1999). Corpus-based identification of non-anaphoric noun phrases. In
Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics,
pp. 373–380. ACL.
Beaver, D. (2004). The optimization of discourse anaphora. Linguistics and Philosophy, 27(1),
3–56.
Beaver, D. I. (2007). Corpus pragmatics: Something old, something new. Paper presented at the
annual meeting of the Texas Linguistic Society.
Bergsma, S., & Lin, D. (2006). Bootstrapping path-based pronoun resolution. In Proceedings of the
21st International Conference on Computational Linguistics and 44th Annual Meeting of the
Association for Computational Linguistics, pp. 33–40. ACL.
Bergsma, S., Lin, D., & Goebel, R. (2008). Distributional identification of non-referential pronouns.
In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics:
Human Language Technologies, pp. 10–18. ACL.
Bergsma, S., & Yarowsky, D. (2011). NADA: A robust system for non-referential pronoun detection. In Hendrickx, I., Lalitha Devi, S., Branco, A., & Mitkov, R. (Eds.), Anaphora Processing
and Applications, Vol. 7099 of Lecture Notes in Computer Science, pp. 12–23. Springer.
Bittner, M. (2001). Surface composition as bridging. Journal of Semantics, 18(2), 127–177.
Brants, T., & Franz, A. (2006). The Google Web 1T 5gram corpus version 1.1. LDC2006T13.
Byron, D. K., & Gegg-Harrison, W. (2004). Eliminating non-referring noun phrases from coreference resolution. In Proceedings of the Discourse Anaphora and Reference Resolution Conference, pp. 21–26.
Chafe, W. L. (1976). Givenness, contrastiveness, definiteness, subjects, topics, and point of view.
In Li, C. N. (Ed.), Subject and Topic, pp. 25–55. Academic Press.
Clark, H. H. (1975). Bridging. In Schank, R. C., & Nash-Webber, B. L. (Eds.), Theoretical Issues
in Natural Language Processing, pp. 169–174. ACM.
470

M ODELING THE L IFESPAN OF D ISCOURSE E NTITIES

Cresswell, M. J. (2002). Static semantics for dynamic discourse. Linguistics and Philosophy, 25(5–
6), 545–571.
de Marneffe, M.-C., MacCartney, B., & Manning, C. D. (2006). Generating typed dependency
parses from phrase structure parses. In Proceedings of the Fifth International Conference on
Language Resources and Evaluation, pp. 449–454. ACL.
de Marneffe, M.-C., Manning, C. D., & Potts, C. (2012). Did it happen? The pragmatic complexity
of veridicality assessment. Computational Linguistics, 38(2), 301–333.
Delmonte, R., Bristot, A., Piccolino Boniforti, M. A., & Tonelli, S. (2007). Entailment and anaphora
resolution in RTE3. In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and
Paraphrasing, pp. 48–53.
Denis, P., & Baldridge, J. (2007). Joint determination of anaphoricity and coreference resolution
using integer programming. In Human Language Technologies 2007: The Conference of the
North American Chapter of the Association for Computational Linguistics; Proceedings of
the Main Conference, pp. 236–243. ACL.
Denis, P., & Baldridge, J. (2009). Global joint models for coreference resolution and named entity
classification. Procesamiento del Lenguaje Natural, 42, 87–96.
Durrett, G., Hall, D., & Klein, D. (2013). Decentralized entity-level modeling for coreference
resolution. In Proceedings of the 51st Annual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers), pp. 114–124. ACL.
Durrett, G., & Klein, D. (2013). Easy victories and uphill battles in coreference resolution. In
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,
pp. 1971–1982. ACL.
Elbourne, P. (2008). Demonstratives as individual concepts. Linguistics and Philosophy, 31(4),
409–466.
Evans, R. (2001). Applying machine learning toward an automatic classification of “it”. Literary
and Linguistic Computing, 16(1), 45–57.
Fernandes, E., dos Santos, C., & Milidiú, R. (2012). Latent structure perceptron with feature induction for unrestricted coreference resolution. In Joint Conference on EMNLP and CoNLL
- Shared Task, pp. 41–48. ACL.
Fodor, J. D., & Sag, I. A. (1982). Referential and quantificational indefinites. Linguistics and
Philosophy, 5(3), 355–398.
Fraurud, K. (1990). Definiteness and the processing of noun phrases in natural discourse. Journal
of Semantics, 7(4), 395–433.
Giampiccolo, D., Magnini, B., Dagan, I., & Dolan, B. (2007). The third PASCAL recognizing
textual entailment challenge. In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing, pp. 1–9.
Groenendijk, J., & Stokhof, M. (1991). Dynamic predicate logic. Linguistics and Philosophy, 14(1),
39–100.
Grosz, B. J., Joshi, A. K., & Weinstein, S. (1995). Centering: A framework for modeling the local
coherence of discourse. Computational Linguistics, 21(2), 203–225.
471

DE

M ARNEFFE , R ECASENS & P OTTS

Guyon, I., Weston, J., & Barnhill, S. (2002). Gene selection for cancer classification using support
vector machines. Machine Learning, 46(1–3), 389–422.
Hall, D., Durrett, G., & Klein, D. (2014). Less grammar, more features. In Proceedings of the 52nd
Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),
pp. 228–237. ACL.
Harris, J. A., & Potts, C. (2009). Perspective-shifting with appositives and expressives. Linguistics
and Philosophy, 32(6), 523–552.
Hawkins, J. A. (1978). Definiteness and Indefiniteness. Croom Helm.
Heim, I. (1982). The Semantics of Definite and Indefinite Noun Phrases. Ph.D. thesis, UMass
Amherst.
Heim, I. (1992). Presupposition projection and the semantics of attitude verbs. Journal of Semantics,
9(2), 183–221.
Hobbs, J. R. (1979). Coherence and coreference. Cognitive Science, 3(1), 67–90.
Hou, Y., Markert, K., & Strube, M. (2013). Global inference for bridging anaphora resolution. In
Proceedings of the 2013 Conference of the North American Chapter of the Association for
Computational Linguistics: Human Language Technologies, pp. 907–917. ACL.
Israel, M. (1996). Polarity sensitivity as lexical semantics. Linguistics and Philosophy, 19(6),
619–666.
Israel, M. (2001). Minimizers, maximizers, and the rhetoric of scalar reasoning. Journal of Semantics, 18(4), 297–331.
Israel, M. (2004). The pragmatics of polarity. In Horn, L., & Ward, G. (Eds.), The Handbook of
Pragmatics, pp. 701–723. Blackwell.
Ji, H., & Lin, D. (2009). Gender and animacy knowledge discovery from web-scale n-grams for
unsupervised person mention detection. In Proceedings of the 23rd Pacific Asia Conference
on Language, Information and Computation, pp. 220–229.
Kamp, H. (1981). A theory of truth and discourse representation. In Groenendijk, J., Janssen,
T. M. V., & Stockhof, M. (Eds.), Formal Methods in the Study of Language, pp. 277–322.
Mathematical Centre.
Karttunen, L. (1973). Presuppositions and compound sentences. Linguistic Inquiry, 4(2), 169–193.
Karttunen, L. (1976). Discourse referents. In McCawley, J. D. (Ed.), Syntax and Semantics, Vol. 7:
Notes from the Linguistic Underground, pp. 363–385. Academic Press.
Kehler, A. (2002). Coherence, Reference, and the Theory of Grammar. CSLI.
Kummerfeld, J. K., & Klein, D. (2013). Error-driven analysis of challenges in coreference resolution. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language
Processing, pp. 265–277. ACL.
Ladusaw, W. A. (1996). Negation and polarity items. In Lappin, S. (Ed.), The Handbook of Contemporary Semantic Theory, pp. 321–341. Blackwell.
472

M ODELING THE L IFESPAN OF D ISCOURSE E NTITIES

Lee, H., Peirsman, Y., Chang, A., Chambers, N., Surdeanu, M., & Jurafsky, D. (2011). Stanford’s
multi-pass sieve coreference resolution system at the CoNLL-2011 shared task. In Proceedings of the 15th Conference on Computational Natural Language Learning: Shared Task, pp.
28–34. ACL.
Luo, X. (2005). On coreference resolution performance metrics. In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language
Processing, pp. 25–32. ACL.
Luo, X., Pradhan, S., Recasens, M., & Hovy, E. (2014). An extension of BLANC to system mentions. In Proceedings of the 52nd Annual Meeting of the Association for Computational
Linguistics, pp. 24–29. ACL.
Müller, C. (2006). Automatic detection of nonreferential it in spoken multi-party dialog. In Proceedings of the European Chapter of the Association for Computational Linguistics, pp. 49–56.
ACL.
Muskens, R., van Benthem, J., & Visser (1997). Dynamics. In van Benthem, J., & ter Meulen, A.
(Eds.), Handbook of Logic and Language, pp. 587–648. Elsevier.
Ng, V. (2004). Learning noun phrase anaphoricity to improve coreference resolution: Issues in
representation and optimization. In Proceedings of the 42nd Annual Meeting on Association
for Computational Linguistics, pp. 152–159. ACL.
Ng, V., & Cardie, C. (2002). Identifying anaphoric and non-anaphoric noun phrases to improve
coreference resolution. In Proceedings of the 19th International Conference on Computational Linguistics, pp. 1–7. ACL.
Nissim, M. (2006). Learning information status of discourse entities. In Proceedings of the 2006
Conference on Empirical Methods in Natural Language Processing, pp. 94–102.
Paice, C. D., & Husk, G. D. (1987). Towards the automatic recognition of anaphoric features in
English text: the impersonal pronoun “it”. Computer Speech & Language, 2(2), 109–132.
Partee, B. H. (1987). Noun phrase interpretation and type-shifting principles. In Groenendijk,
J., de Jong, D., & Stokhof, M. (Eds.), Studies in Discourse Representation Theory and the
Theory of Generalized Quantifiers, pp. 115–143. Foris Publications.
Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M.,
Perrot, M., & Duchesnay, É. (2011). Scikit-learn: Machine learning in Python. Journal of
Machine Learning Research, 12, 2825–2830.
Poesio, M., Alexandrov-Kabadjov, M., Vieira, R., Goulart, R., & Uryupina, O. (2005). Does
discourse-new detection help definite description resolution?. In Proceedings of the 6th International Workshop on Computational Semantics, pp. 236–246.
Poesio, M., Uryupina, O., Vieira, R., Alexandrov-Kabadjov, M., & Goulart, R. (2004). Discoursenew detectors for definite description resolution: A survey and a preliminary proposal. In
Harabagiu, S., & Farwell, D. (Eds.), ACL 2004: Workshop on Reference Resolution and its
Applications, pp. 47–54. ACL.
Potts, C. (2005). The Logic of Conventional Implicatures. Oxford University Press.
473

DE

M ARNEFFE , R ECASENS & P OTTS

Potts, C. (2012). Conventional implicature and expressive content. In Maienborn, C., von Heusinger,
K., & Portner, P. (Eds.), Semantics: An International Handbook of Natural Language Meaning, Vol. 3, pp. 2516–2536. Mouton de Gruyter.
Pradhan, S., Luo, X., Recasens, M., Hovy, E., Ng, V., & Strube, M. (2014). Scoring coreference partitions of predicted mentions: A reference implementation. In Proceedings of the
52nd Annual Meeting of the Association for Computational Linguistics, pp. 30–35. ACL.
https://github.com/conll/reference-coreference-scorers.
Pradhan, S., Moschitti, A., Xue, N., Uryupina, O., & Zhang, Y. (2012). Conll-2012 shared task:
Modeling multilingual unrestricted coreference in ontonotes. In Joint Conference on EMNLP
and CoNLL - Shared Task, pp. 1–40. ACL.
Pradhan, S., Ramshaw, L., Marcus, M., Palmer, M., Weischedel, R., & Xue, N. (2011). CoNLL2011 shared task: Modeling unrestricted coreference in OntoNotes. In Proceedings of the
Fifteenth Conference on Computational Natural Language Learning: Shared Task, pp. 1–27.
ACL.
Pradhan, S. S., & Xue, N. (2009). Ontonotes: The 90% solution. In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, Companion Volume: Tutorial Abstracts, pp. 11–12.
ACL.
Prasad, R., Dinesh, N., Lee, A., Miltsakaki, E., Robaldo, L., Joshi, A., & Webber, B. (2008). The
Penn Discourse Treebank 2.0. In Proceedings of the Sixth International Language Resources
and Evaluation, pp. 2961–2968. European Language Resources Association.
Prince, E. (1981a). On the inferencing of indefinite ‘this’ NPs. In Webber, B. L., Sag, I., & Joshi,
A. (Eds.), Elements of Discourse Understanding, pp. 231–250. Cambridge University Press.
Prince, E. F. (1981b). Toward a taxonomy of given–new information. In Cole, P. (Ed.), Radical
Pragmatics, pp. 223–255. Academic Press.
R Development Core Team (2013). R: A Language and Environment for Statistical Computing. R
Foundation for Statistical Computing.
Recasens, M., de Marneffe, M.-C., & Potts, C. (2013). The life and death of discourse entities:
Identifying singleton mentions. In Human Language Technologies: The 2013 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pp.
627–633. ACL.
Recasens, M., & Hovy, E. (2009). A deeper look into features for coreference resolution. In
Lalitha Devi, S., Branco, A., & Mitkov, R. (Eds.), Anaphora Processing and Applications,
Vol. 5847 of Lecture Notes in Computer Science, pp. 29–42. Springer.
Recasens, M., & Hovy, E. (2011). BLANC: Implementing the Rand index for coreference evaluation. Natural Language Engineering, 17(4), 485–510.
Roberts, C. (1990). Modal Subordination, Anaphora, and Distributivity. Garland.
Roberts, C. (1996). Anaphora in intensional contexts. In Lappin, S. (Ed.), The Handbook of Contemporary Semantic Theory, pp. 215–246. Blackwell.
Rooryck, J. (2001). Evidentiality, Part II. Glot International, 5(5), 161–168.
474

M ODELING THE L IFESPAN OF D ISCOURSE E NTITIES

Saurı́, R. (2008). A Factuality Profiler for Eventualities in Text. Ph.D. thesis, Brandeis University.
Schwarz, F. (2009). Two Types of Definites in Natural Language. Ph.D. thesis, UMass Amherst.
Schwarzschild, R. (2002). Singleton indefinites. Journal of Semantics, 19(3), 289–314.
Simons, M. (2007). Observations on embedding verbs, evidentiality, and presupposition. Lingua,
117(6), 1034–1056.
Uryupina, O. (2003). High-precision identification of discourse new and unique noun phrases.
In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics
Student Research Workshop, pp. 80–86. ACL.
Uryupina, O. (2009). Detecting anaphoricity and antecedenthood for coreference resolution. Procesamiento del lenguaje natural, 42, 113–120.
van Deemter, K., & Kibble, R. (2000). On coreferring: Coreference in MUC and related annotation
schemes. Computational linguistics, 26(4), 629–637.
Vieira, R., & Poesio, M. (2000). An empirically based system for processing definite descriptions.
Computational Linguistics, 26(4), 539–593.
Vilain, M., Burger, J., Aberdeen, J., Connolly, D., & Hirschman, L. (1995). A model-theoretic
coreference scoring scheme. In Proceedings of the 6th Message Understanding Conference,
pp. 45–52. Morgan Kaufman.
Walker, M. A., Joshi, A. K., & Prince, E. F. (Eds.). (1997). Centering in Discourse. Oxford University Press.
Wang, L., McCready, E., & Asher, N. (2006). Information dependency in quantificational subordination. In von Heusinger, K., & Turner, K. (Eds.), Where Semantics Meets Pragmatics, pp.
267–304. Elsevier.
Ward, G., & Birner, B. (2004). Information structure and non-canonical syntax. In Horn, L. R., &
Ward, G. (Eds.), The Handbook of Pragmatics, pp. 153–174. Blackwell Publishing Ltd.

475

Journal of Artificial Intelligence Research 52 (2015) 331-360

Submitted 01/15; published 02/15

Scheduling Conservation Designs for Maximum Flexibility
via Network Cascade Optimization
Shan Xue
Alan Fern

xue@eecs.oregonstate.edu
afern@eecs.oregonstate.edu

School of EECS, Oregon State University
Corvallis, OR 97331 USA

Daniel Sheldon

sheldon@cs.umass.edu

School of Computer Science, University of Massachusetts
Amherst, MA 01003, USA

Abstract
One approach to conserving endangered species is to purchase and protect a set of land
parcels in a way that maximizes the expected future population spread. Unfortunately,
an ideal set of parcels may have a cost that is beyond the immediate budget constraints
and must thus be purchased incrementally. This raises the challenge of deciding how to
schedule the parcel purchases in a way that maximizes the flexibility of budget usage while
keeping population spread loss in control. In this paper, we introduce a formulation of this
scheduling problem that does not rely on knowing the future budgets of an organization. In
particular, we consider scheduling purchases in a way that achieves a population spread no
less than desired but delays purchases as long as possible. Such schedules offer conservation
planners maximum flexibility and use available budgets in the most efficient way. We
develop the problem formally as a stochastic optimization problem over a network cascade
model describing a commonly used model of population spread. Our solution approach is
based on reducing the stochastic problem to a novel variant of the directed Steiner tree
problem, which we call the set-weighted directed Steiner graph problem. We show that this
problem is computationally hard, motivating the development of a primal-dual algorithm
for the problem that computes both a feasible solution and a bound on the quality of an
optimal solution. We evaluate the approach on both real and synthetic conservation data
with a standard population spread model. The algorithm is shown to produce near optimal
results and is much more scalable than more generic off-the-shelf optimizers. Finally, we
evaluate a variant of the algorithm to explore the trade-offs between budget savings and
population growth.

1. Introduction
Reserve site selection is a key problem in conservation planning in which planners select land
regions to be designated as nature reserves, either to achieve general conservation goals such
as preserving biodiversity, or to achieve specific goals such as supporting the recovery of an
endangered species. In general, the problem is extremely complex as it involves reasoning
about the interplay between uncertain population spread, uncertain future budgets, and
other problem specific factors. In particular, properly assessing population spread involves
reasoning about spatial aspects of landscapes such as their sizes, shapes, and connectivity.
Further, the decision space is huge, consisting of all possible land investment combinations
over time.
c
2015
AI Access Foundation. All rights reserved.

Xue, Fern, & Sheldon

Given the above factors, it would be highly desirable for conservation practitioners to
enhance their decision making via automated, or semi-automated, planning and scheduling
algorithms. Unfortunately, this problem is beyond the scope of existing off-the-shelf stochastic planners and schedulers. This is largely due to the combination of enormous state and
action spaces, the highly uncertain, exogenous dynamics, and the need for spatio-temporal
reasoning. The main contribution of this paper is to make progress toward handling these
complexities by studying a useful subproblem of conservation planning that can be used by
practitioners on realistic scenarios. The general schema used to develop our algorithm is
more widely applicable (see Section 7) and one that has not received significant attention
in the AI community. Thus, we hope that this work will also inspire new specialized and
general-purpose approaches for complex stochastic planning/scheduling problems.
Recently, Sheldon et al. (2010) studied a restricted, but still challenging, version of
the conservation planning problem, which we will refer to as upfront conservation design
optimization. In this problem, the planner is given an upfront budget and a stochastic
metapopulation model (Hanski & Ovaskainen, 2000) that describes how the species under
consideration will spread throughout a landscape of available habitat. In addition the
system is given information about the costs of potential land parcels that are available for
purchase and conservation. The objective is to select a set of land parcels to immediately
purchase and conserve, subject to the budget constraint, that will maximize the spread of
the population within a specified time horizon.
A key simplification present in this problem is that all land parcels are assumed to be
purchased upfront with the currently available budget. An advantage of this simplification
is that it allows for a reasonably efficient and near optimal solution approach (Sheldon
et al., 2010). However, the upfront simplification limits the utility of the approach in a
number of ways. First, conservation budgets generally arrive in increments over time, so it
is unrealistic to purchase a large set of parcels in advance and restricting to a small set of
parcels using the current budget may be very suboptimal in the long run. Moreover, it is
often unnecessary to purchase parcels that are spatially remote from the current population
until the species has spread enough to make them relevant to further population growth.
Second, this upfront simplification requires planners to commit in advance to conservation
strategies that may take many years to play out, which ignores the potential advantage of
observing and responding to the stochastic outcomes of the population spreading process as
it unfolds. For example, as the population spread is observed, it may be beneficial to divert
money from failed subpopulations to purchase more parcels near thriving populations.
In contrast to upfront planning, an ideal approach would be fully adaptive planning,
where, at regular decision epochs, the planner would make purchase decisions based on the
most recent population and budgetary information. Unfortunately, no currently-available
adaptive planning tools can scale to realistic conservation scenarios. This is due to the
combination of an enormous state space (possible population and purchase configurations),
enormous action space (possible subsets of land parcels to purchase), long horizons (tens to
hundreds of years), and high degree of stochasticity in the population spread model.
Given the challenge of arriving at a fully adaptive solution, a main contribution of
this paper is to introduce a problem that strikes an important middle-ground between
the upfront and fully adaptive approaches. In particular, we consider conservation design
scheduling for exploring the trade-off between future population and cost, where we are
332

Scheduling Conservation Designs for Maximum Flexibility

given an initial conservation design (i.e. a set of parcels to purchase) and are asked to
schedule the purchase time of each parcel in a way that (1) achieves a population spread
over the time horizon within an arbitrary tolerance of population loss, and (2) maximizes
purchase flexibility by delaying the specified purchase time (i.e. purchase deadline) for each
parcel as long as possible.
This problem formulation simplifies over the fully adaptive problem in a number of ways.
First, the set of parcels to be purchased is provided as input, which removes this degree
of freedom from the planning problem. Second, and more significantly, in order to select
an action for the current time step, the general case of fully adaptive planning requires
computing a policy that dictates what to do at each possible future contingency, or at least
the reasonably likely ones. In contrast, the space of possible schedules, our focus here, is
much smaller than the space of policies or even partial policies. This allows for a compact
encoding of the scheduling problem, which does not appear possible for the problem of
computing full, or even, partial policies. This distinction between the fully adaptive and
scheduling setting is akin to the distinction between closed-loop and open-loop planning,
where generally computing closed-loop plans is considered to be more difficult than openloop plans for large stochastic problems.
A solution to the above scheduling problem yields a useful tool to conservation planners,
who can first develop conservation designs that capture their own complex decision-making
objectives, perhaps with optimization software, and then schedule the purchases to obtain
the most efficient and cost-effective implementation of that design. The conservation planner
then has the flexibility to purchase the parcels at any time before the schedule-specified
deadlines, knowing that the population spread will not be hurt too much by such purchase
delays.
In addition, our scheduling problem can potentially be used as a component of an
adaptive planner. A common and successful approach for many adaptive planning problems
is replanning, where at each decision epoch a non-adaptive plan is computed from the current
state and its first actions are executed. Our work enables a replanning approach that at
each decision epoch first computes an upfront design using existing work (e.g. Sheldon
et al., 2010), and then computes a schedule and purchases only the parcels scheduled to
be purchased immediately. This purchase strategy would spend the minimum amount of
budget at each step while guaranteeing a limited loss in population spread.
In addition to introducing and formalizing the problem of conservation design scheduling, the second contribution of this paper is to develop a principled algorithm for solving
it. The key idea is to apply the Sample Average Approximation (SAA) approach (Shapiro,
2003) in order to arrive at a novel deterministic optimization problem, for which we develop a principled solution with a motivation from its special case. In particular, when
the approximated loss tolerance ratio is 0, our deterministic optimization problem is one of
network cascade optimization, which we show is equivalent to a novel variant of the directed
Steiner tree problem. In the traditional Steiner tree problem, graph edges are associated
with costs, and the objective is to compute a Steiner tree with minimum cumulative edge
cost. In our variant, the set-weighted directed Steiner graph problem, costs are associated with sets of edges (possibly non-disjoint) rather than individual edges. We show that
this problem is computationally hard even under restrictions where the traditional problem
admits an efficient solution. We then present an efficient primal-dual algorithm, which is
333

Xue, Fern, & Sheldon

guaranteed to compute both a feasible solution and a bound on the quality of the optimal
solution. Then an early-stopping version of the algorithm provides a natural approach to
explore the trade-off between future population and budget flexibility.
Our experiments on both real and synthetic data from a Red-cockaded Woodpecker
conservation problem show that our primal-dual algorithm produces near optimal results
and is much more scalable than standard optimization tools (CPLEX). We also show that
the trade-off between population and budget allows for a flexibility of purchasing land
parcels.
In what follows, Section 2 first presents related work, followed by our problem formulation in Section 3. Section 4 then shows how to reduce our subproblem to the set-weighted
directed Steiner graph problem. Section 5 derives the corresponding primal-dual algorithm
and a natural extension for the trade-off problem. Experiments are presented in Section 6.
Finally we conclude and discuss future work.

2. Related Work
Previously, many different algorithms have been proposed to select reserve sites by formulating a numerical measure of reserve quality (together with the possible addition of
constraints the reserve must satisfy) and then solving for the optimal set of sites under the
proposed model (e.g. see the review article, Williams, Revelle, & Levin, 2005). Although
the earliest reserve site selection algorithms largely ignored spatial considerations, many
newer models incorporate spatial objectives or constraints directly into the optimization
problems. Williams, Revelle, and Levin argue that a primary reason for the importance of
spatial attributes is the fact that they capture properties of the landscape that are favorable
for the underlying population dynamics, and that an important, but computationally difficult, research direction is to directly optimize with respect to a model for the population
dynamics instead of using spatial attributes as a proxy. This is the direction that we are
following in this paper by addressing the problem of spatial conservation planning with
respect to a specific and widely adopted model of population dynamics.
A recent approach that explicitly reasons about a population dynamics model is the
work of Sheldon et al. (2010) on the upfront conservation design problem, as described
in Section 1. In order to cope with the stochasticity of the model, the popular Sample
Average Approximation (SAA) approach was employed to transform the stochastic problem
into a deterministic combinatorial optimization problem. This problem was then encoded
as a Mixed Integer Program (MIP) and solved using state-of-the-art solvers. While that
approach was able to solve reasonably large problems via various speedup techniques, the
scalability is still limited to a relatively small number of “sample scenarios” used by SAA,
which controls the accuracy of the approach. Kumar et al. (2012) have addressed this
aspect of the approach. Lagrangian relaxation was used to decompose the SAA problem
into independent subproblems that could each be solved in a practical time frame, possibly
in parallel, by standard optimizers. This was shown to significantly reduce the runtime
dependence on the number of SAA samples used.
Unfortunately, directly extending the above approach to compute multi-stage adaptive
solutions, where the budget arrives in increments over time, does not seem practical. One
attempt at this for two-stage problems was considered by Ahmadizadeh et al. (2010). They
334

Scheduling Conservation Designs for Maximum Flexibility

explore re-planning using a two-stage non-adaptive problem formulation, and find that it
can indeed offer advantages over upfront planning. In their setting, the budget split and
decision epochs are manually fixed. Unlike that work, our work explicitly separates the
decision of which parcels to buy from the decision of when to buy them (the focus of this
work), so that we may develop efficient special-purpose algorithms for the latter problem
that scale much more easily to bigger problems and more stages.
There are several existing approaches that might be considered for a fully adaptive
solution to the conservation problem. For example, the fully adaptive problem can be
encoded as a Markov Decision Process (MDP), but the resulting state and action spaces
would be far too big for state-of-the-art solvers. For instance, recent advances in solving
large spatio-temporal MDPs (Crowley & Poole, 2011) require significant restrictions to
the solution space, which are not acceptable in our application. As an existing approach
for stochastic planning that has been successfully applied by Bent et al. (2004), Chang
et al. (2000), Chong et al. (2000) and Yoon et al. (2008), Hindsight Optimization
samples the future outcomes and optimistically estimates the state value based on the
determined futures. However, when the action space is huge, this approach would have
computational problems as current algorithms require enumeration of all the candidate
actions when approximating the state value. Another approach would be to formulate the
adaptive planning problem as a multi-stage stochastic integer program. However, the size of
such a problem formulation scales exponentially with the number of stages, and the running
time is already very costly for a single stage (Sheldon et al., 2010), or for a two-stage problem
in a simpler setting that is not fully adaptive (Ahmadizadeh et al., 2010).
Recently, Golovin et al. (2011) proved that a simple greedy planning strategy provides
near-optimal solutions in an adaptive conservation setting that at first appears similar
to ours. However, in order to provide approximation guarantees, the authors restrict the
population dynamics so that no spread occurs between distinct land parcels. While this may
be a reasonable assumption for slow-moving species such as certain insects, which were the
focus of that work, it ignores critical aspects of the population dynamics of highly-mobile
animals such as birds, including the Red-cockaded Woodpecker on which our experiments
are based.

3. Problem Formulation
In this section, we first introduce the basic terminology of conservation design planning and
define our main stochastic optimization problem. Next, we describe how the Sample Average
Approximation (SAA) is used to transform this problem into a deterministic optimization
problem, which is the focus of the remainder of the paper.
3.1 Basic Concepts
We largely follow the formulation of Sheldon et al. (2010). Our conservation problems
will involve a (large) land region of interest that is divided into land parcels that are the
smallest land units available for purchase. Each parcel contains some number of distinct
habitat patches, which are the atomic units in the population dynamics model and can
either be occupied or unoccupied by the species of interest. For example, in the Redcockaded Woodpecker problem considered in our experiments, habitat patches correspond
335

Xue, Fern, & Sheldon

to particular trees that have been prepared by humans (or existing birds) to facilitate
nesting. Each parcel p has a cost c(p), which denotes the cost of purchasing the land and
restoring or conserving all of its habitat patches so that they are suitable for the species to
occupy.
A conservation design is a set of parcels that are intended to be purchased and conserved.
Given a conservation design D, a purchase schedule π for D is a mapping from parcels in D
to purchase times in {0, 1, . . . , H, ∞}, where H is the time horizon of interest and purchasing
a parcel at time t = ∞ means this parcel is not going to be purchased. Thus the scheduler
may choose not to purchase some parcels even though they are part of the design so as to
realize the best tradeoff between budget flexibility and population spread. Although the
species population dynamics have a yearly time step in our model (described below), the
allowed purchase times (i.e. decision epochs) may be less frequent depending on the specific
problem. An upfront schedule is one that assigns all parcels to purchase time t = 0.
It is worth noting that the purchase times specified by a schedule are best viewed as
purchase deadlines. That is, we interpret the schedule as constraining the purchases to occur
before or at the specified times. This view is justified by the fact that in the setup below,
purchasing a parcel at an earlier time than specified will never result in worse population
spread.

3.1.1 Population Dynamics Model
We use the same stochastic dynamics model as Sheldon et al. (2010), which is an instance of
a popular metapopulation model from the ecology literature (Hanski & Ovaskainen, 2000).
A patch a has two possible states at each time step, either unoccupied or occupied, and
only conserved patches may be occupied. The population dynamics consists of two types
of stochastic events. Colonization events occur when a population from patch a colonizes
an unoccupied patch b, which happens with probability pab . Extinction events occur when
a patch a that is occupied at time t becomes unoccupied at time t + 1, which happens with
probability 1 − paa . All events are independent. The details of the probabilities used in our
experiments are given in Section 6.
The single-step colonization probability pab in our experiments typically decays with
the distance between patches a and b, which encodes spatio-temporal dynamics in which
populations slowly spread from a source population when new habitat is made available.
Thus, in long-term planning for population spread, it is often unnecessary to purchase
parcels that are distant from a source population at time t = 0, since the probability of the
population spreading to such distant patches in the near future is negligible. By delaying
such purchases until they become relevant to the design (i.e. the population has spread
nearby), a conservation organization can use limited funds much more flexibly. However,
it is non-trivial to decide how much to delay purchases so as not to harm the spread, since
this decision depends very much on the spatio-temporal details of the population spread
model. It is this decision that the optimization problem defined below is designed to make.
336

Scheduling Conservation Designs for Maximum Flexibility

3.2 Stochastic Optimization Problem
Our problem statement will rely on two important concepts: 1) the reward of a schedule,
and 2) the flexibility of a schedule. We first define these two concepts and then formulate
the optimization problem in terms of them.
The reward of schedule π, denoted by R(π), is a random variable that encodes the
amount of population spread at time H, which is simply a count of the number of occupied
patches at time H. It is easy to show in our model that the upfront schedule always
achieves at least as much reward as any other schedule and thus maximizes the expected
reward. Thus, we define the maximum expected reward as R∗ = E[R(πupfront )]. Our
optimization goal is to find a schedule π that almost achieves this optimal expected reward,
—i.e. E[R(π)] ≥ (1 − ε)R∗ where ε is a positive real number and indicates the percentage
tolerance of reward loss —but has maximum “purchase flexibility”. We know that the
upfront schedule achieves (1 − ε)R∗ , however, it requires commitment to all expenditures
at the first time step and is thus the least flexible. Indeed, we now formalize the notion of
flexibility in terms of expenditures over time.
Given any schedule π we can define its corresponding cost curve Cπ to be a function
from purchase times to accumulated cost, so that Cπ (t) is equal to the total cost of parcels
purchased under π from time 0 up to and including time t. This curve is non-decreasing
and provides a view of a schedule’s spending profile over the time horizon. In particular,
if the profile of cost curve Cπ1 is never above that of Cπ2 , i.e. the total expenditures of π1
never exceed those of π2 , then we can say that π1 offers more flexibility in terms of budget
management compared to π2 and should be preferred if all else is equal.
Now we define a surrogate cost function over schedules as
costf (π) =

X

c(p) · f (π(p))

p

which is parameterized by a function f from times in {0, . . . , H, ∞} to real numbers. We
require f (∞) = 0 for any f so that any parcel that is not purchased within the time horizon
would not contribute to the surrogate cost. We can see that this surrogate cost function is
simply a weighted sum of the parcel costs, where the weight is determined by f based on
the parcel’s purchase time. Although our algorithm can work with any real-valued function,
we assume henceforth that f is strictly decreasing. There are two reasons for this. First,
discounting future costs makes sense due to economic factors such as inflation. Second,
intuitively, since f decreases with purchase times, minimizing with respect to costf would
favor schedules that delay purchasing. In particular, if policy π1 has a cost profile that is
never greater than that of π2 , then π1 will be assigned a lower surrogate cost when f is
strictly decreasing.
If all parcels have positive costs, then the upfront schedule is the unique element that
maximizes the surrogate cost, and the schedule that defers all purchases until time H gives
the unique minimum as f is a strictly decreasing function. However, if we restrict to
schedules that achieve at least reward (1 − ε)R∗ , the latter schedule will be excluded and
there may no longer be a unique minimum.
337

Xue, Fern, & Sheldon

We can now specify the problem of conservation design scheduling, which is to find a
schedule π ∗ from the set of all possible schedules such that:
π ∗ ∈ arg min costf (π) s.t. E[R(π)] ≥ (1 − ε)R∗
π

(1)

That is, out of all schedules that achieve reward (1 − ε)R∗ we want to return one that is
minimal in terms of its surrogate cost (i.e. it has maximal flexibility). Thus, ε controls
the trade-off between flexibility and reward. In particular, using larger ε increases the
set of feasible schedules and allows the potential for returning a more flexible schedule by
sacrificing some reward.
Note that by varying the choice of f it may be possible to generate different solutions to
Equation 1, each of which is minimal in the sense that no other feasible policy has a strictly
lower cost curve. In our experiments, we use a simple discounted f given by f (t) = β t for
a discount factor β ∈ (0, 1).
In practice, it is likely that a conservation manager will not have a particular value of ε
in mind at design time. Rather, ε is best viewed as a parameter that will be varied in order
to observe the different flexibility-reward trade-offs that are possible. The final selection of
a schedule would then be based on an assessment of those possibilities.
Finally, it is worth noting that for ε = 0 (no reward approximation), the upfront solution
will be the only feasible solution under typical population spread models. Thus, using
ε > 0 is necessary for achieving any additional flexibility. This is because requiring a
policy to achieve expected reward exactly R∗ (i.e., ε = 0) requires it to make purchases to
accommodate very unlikely outcomes of the population spread model that contribute a tiny,
but positive, amount to the expected reward. For example, consider an outcome where the
population jumps from its initial location to a very distant location in the first year, and
then undergoes no further spread. This has vanishingly small, but positive, probability. The
upfront schedule will support this population spread, since the distant location is purchased
at the first step. Thus, any schedule that does not purchase the distant parcel in the first
step will suffer a tiny loss in reward compared to the upfront schedule, so it does not
achieve ε = 0. However, such a purchase will tend to be useless for the vast majority of the
probability mass.
3.3 Deterministic Optimization Problem
The above optimization problem is stochastic in the sense that its constraint is defined in
terms of an expectation over a complicated population spread distribution. This greatly
complicates the direct solution of this problem. As in prior work on stochastic optimization
of upfront schedules (Sheldon et al., 2010), we address this complication by converting the
stochastic problem into an approximately equivalent deterministic optimization problem.
This is done via the very common Sample Average Approximation (SAA) approach (see
Shapiro, 2003 for a survey of some results). The key idea is to approximate a stochastic
optimization problem using a collection of samples from the probability distribution, which
are used to approximate expectations or probabilities via averages over samples.
In our problem formulation, each sample corresponds to a so-called cascade scenario,
which is a particular realization of the population spread process over the time horizon.
The main idea behind our application of SAA is to generate a set of such cascade scenarios
338

Scheduling Conservation Designs for Maximum Flexibility

from the probabilistic population spread model, and to approximate the expected reward of
schedules as the average reward over the scenarios. The scenarios are combined into a single
scenario graph, which is illustrated in Figure 1 and explained in detail in the remainder of
this section.
More concretely, a cascade scenario is a layered graph, where layers correspond to time
steps, with a vertex va,t for each patch a and each time step t. For each pair of patches
(a, b) and time step t, a coin is flipped with probability pab to determine if the directed
edge (va,t , vb,t+1 ) is present or not. If this edge is present and patch a is occupied at time
t (through previous colonizations or non-extinctions), then patch b will be colonized and
become occupied at time t + 1, as long as it is conserved. That is, the presence of edge
(va,t , vb,t+1 ) is interpreted as meaning that if a is occupied at time t and b is conserved at
or before time t + 1, then b will be occupied at time t + 1 in the particular scenario. In this
way, a cascade scenario graph encodes occupancy as reachability. In particular, assuming
(for now) that all patches are conserved, then patch b is occupied at time t exactly when
vb,t is reachable from a vertex va,0 corresponding to an initially occupied patch a.
To approximate the probabilistic spread model, we sample a set of N i.i.d. cascade
n }. These scenarios
scenarios {C1 , . . . , CN }, where we will denote the vertices in Cn by {va,t
are combined into a single scenario graph, which has an additional root vertex r with
n ) to each vertex representing an initially occupied patch a. Figure 1
directed edges (r, va,0
shows an example scenario graph that has three scenarios over a range of five time steps
involving three patches a, b, and c, and two parcels, one containing a and b and the other
containing just c. In this example, a is the only initially occupied patch and hence is
connected at time step zero to the root node r across all three scenarios. Assuming that all
parcels are conserved (i.e. purchased upfront), if a vertex is connected to the root node r,
then the corresponding patch is considered to be occupied at the corresponding time in the
particular scenario. This is because we defined r so that it can only be connected to other
vertices through initially occupied patches.
Scenario graphs will be used in our work to estimate the reward of schedules as follows.
n and all of its incoming
Given a scenario graph, a schedule π is said to purchase node va,t
edges if patch a is purchased no later than time t, that is, π(p) ≤ t where a belongs to
parcel p. Thus, purchasing a parcel p at time t can be viewed as purchasing all vertices in
the scenario graph, along with their incoming edges that involve patches in p that occur at
layer t or later. This reflects the fact that once a patch is purchased and conserved, it is
considered to be conserved and hence eligible for occupancy for the remainder of the time
horizon. In Figure 1, an example schedule is shown that purchases parcel p1 (containing a
and b) at time 0, and parcel p2 (containing c) at time 3. The vertices that are purchased
by this schedule are shown in the shaded region and their (purchased) incoming edges are
shown in bold.
We can now define under what conditions a vertex in a scenario graph is considered
n becomes occupied under π if there is a path
to be occupied given a schedule. Vertex va,t
n . We define the variable X n (a, t) to be equal to 1
through purchased edges from r to va,t
π
n
if va,t is occupied under π and 0 otherwise. In Figure 1, we have shaded in red the set of
vertices that are occupied under the example policy. As an example, note that in scenario 3,
3 is not occupied since there is no path from r to it through purchased edges.
the vertex vc,3
This is despite the fact that there is a path in the graph from r, since that path involves
339

Xue, Fern, & Sheldon

Figure 1: Example scenario graph (N = 3) for problem with parcels p1 = {a, b}, p2 = {c}.
The schedule (π(p1 ) = 0, π(p2 ) = 3) is also illustrated, using shaded boxes to
indicate purchased nodes and heavy line weights to indicate purchased edges.
Vertices representing occupied patches under this schedule are colored red.

some unpurchased edges. Note that the upfront schedule would purchase this node, since
all vertices and edges would be considered to be purchased under that schedule.
The average reward of a schedule π relative to a scenario graph built from scenarios
{C1 , . . . , CN } is denoted as follows.
R̂(π) =

N
1 XX n
Xπ (a, H)
N
a
n=1

This is just the average across scenarios of the number of occupied patches at time H.
In Figure 1 the average reward for the example schedule would be 2. A key property of
scenario graphs is that as N → ∞ we have that R̂(π) converges to E[R(π)] for any fixed
π. This implies that the set of schedules {π : R̂(π) ≥ (1 − ε)R̂(πupfront )} converges to
the set {π : R(π) ≥ (1 − ε)R∗ } as N grows, which is the set of policies that we wish
to optimize flexibility over. Further, for any policy π, one can use standard probability
concentration bounds (e.g. Chernoff bounds) to show that the event |R(π) − R̂(π)| ≥  has
a probability mass that decreases exponentially fast as N grows. This suggests that only a
relatively small number of scenarios are required to reliably obtain a tight approximation
to the true expected reward of a policy. In practice, however, it is important to empirically
validate that the approximation errors are reasonable for the number of scenarios used in
the approximation.
340

Scheduling Conservation Designs for Maximum Flexibility

The above motivates a deterministic SAA formulation of our original stochastic optimization problem (1) where flexibility is optimized subject to a constraint based on the
empirical reward R̂. That is, our deterministic problem is to solve:
π ∗ ∈ arg min costf (π) s.t. R̂(π) ≥ (1 − ε̂)R̂∗
π

(2)

where R̂∗ = R̂(πupfront ).
3.4 Overview of Solution Approach
Recall that for the stochastic optimization problem (1) setting ε = 0 resulted in an optimization problem that would typically have only the upfront schedule as a feasible solution.
Rather, here, for the approximate SAA formulation, there will typically be non-upfront
solutions that are feasible, even when using ε̂ = 0. This is because even for large (but practical) values of N , the set of scenarios used for the approximation will not tend to include
highly unlikely scenarios, which need to be accounted for in the stochastic solution when
using ε = 0. This observation motivates our solution approach for (2). In particular, in
Section 4, we first consider the problem when ε̂ = 0, which turns out to be a new variant
of the classic Steiner tree problem. We then derive an incremental primal-dual algorithm
for the problem (Section 5) that can be used to approximately solve the ε̂ = 0 case or the
ε̂ > 0 case through early stopping. Our experiments will show that this approach is able to
provide significant flexibility with little loss in reward, with the flexibility-reward trade-off
being controlled by ε̂ > 0.

4. Set-Weighted Directed Steiner Graph Formulation
As motivated above, here we focus on optimization problem (2) for the case when ε̂ = 0.
That is, we must optimize flexibility subject to the constraint that we obtain the optimal
empirical reward as measured by R̂. In this section, we show how to formulate this problem
as a novel variant of the Steiner tree problem.
4.1 Set-Weighted Directed Steiner Graph
From (2), we arrive at our final optimization problem for ε̂ = 0:
π ∗ ∈ arg min costf (π) s.t. R̂(π) = R̂∗ .
π

(3)

We can view this problem as a type of Steiner tree problem on the scenario graph. In
particular, we say that any vertex at time t = H is a terminal vertex if it is reachable from
the root r, which is the set of nodes with Xπnupfront (a, H) = 1 and hence contribute to the
upfront reward R̂∗ . The only way for π to satisfy the constraint R̂(π) = R̂∗ is to purchase
a set of edges in the scenario graph that connect all of those target nodes to r. Thus, the
constraint in Equation 3 corresponds to purchasing edges such that r has a path to each
terminal, as in the Steiner tree problem.
As an example, consider again the scenario graph in Figure 1. The terminal nodes in
1 and v 3 , which are the only two
this example are all nodes at layer t = 4 except for vb,4
b,4
nodes that are not connected to r by a directed path. A schedule that satisfies the constraint
341

Xue, Fern, & Sheldon

R̂(π) = R̂∗ must purchase edges such that all of these terminals are reachable from r. Note
that for the example schedule of Figure 1, the set of purchased edges does not satisfy this
3 .
constraint since there is no path of purchased edges to the terminal vertex vc,4
While our problem is very similar to the traditional Steiner tree problem, there is a
significant difference. In the traditional problem, each edge is associated with a distinct
weight and can be purchased individually, with the goal of connecting all terminals using a
set of edges of minimum total weight (which always forms a tree). Rather, our situation is
more complicated because we purchase parcels, which correspond to subsets of edges in the
scenario graph. In particular, purchasing a parcel p at time t, which incurs cost c(p)f (t) in
Equation (3), corresponds to purchasing an edge set Ep,t with cost c(p)f (t) that contains
n ) that come from any vertex u and arrive at any vertex v n with a ∈ p,
all the edges (u, va,t
0
a,t0
t0 ≥ t and n ∈ {1, . . . , N }. Note that under this cost model, the total cost of edge sets
purchased by a schedule π exactly equals our surrogate objective costf (π).
From the above we see that our problem is an instance of a problem that we will call
the Set-weighted Directed Steiner Graph (SW-DSG) problem, a novel variant of the Steiner
tree problem, the goal of which is to select a set of vertices with minimal total cost in order
to connect all the terminal vertices to the root. For the remainder of the paper we will
discuss this problem in its general form to simplify notation. The input for SW-DSG is a
directed graph G = (V, E) with a single root vertex r, a set of terminal vertices T ⊆ V,
a set of M edge sets E = {E1 , . . . , EM } where each Es ⊆ E, and a non-negative cost
cs for each Es . In particular, our conservation problem has edge sets E = {Ep,t } with
n ) : (u, v n ) ∈ E, a ∈ p, t0 ≥ t, n ∈ {1, . . . , N }} and cost c
Ep,t = {(u, va,t
0
p,t = c(p)f (t). A
a,t0
subset of E forms a Steiner graph if the union of the edges connect r to all vertices in T .
The desired output is a minimum cost subset of E that forms a Steiner graph. Note that
the optimal Steiner graph need not be a tree in SW-DSG, unlike in the traditional Steiner
tree problem.
It is clear that SW-DSG is more general than the original deterministic optimization
problem since the latter has a specific edge set structure. For instance, Ep,t1 ⊆ Ep,t2
if t1 > t2 . However, this structure does not make it an easier problem than SW-DSG.
In the following sections, we prove that both problems are NP-complete and our primaldual algorithm is the same for either setting. The special structure does not lead to any
algorithmic advantages in deriving a primal-dual algorithm. Therefore, we mainly discuss
the problem in the form of SW-DSG to simplify notation.
While the SW-DSG problem was motivated by our particular conservation application,
it is relevant to other problems that have Steiner style objectives, but where the “edge
resources” are best considered as groups. For example, Steiner trees are often used for the
design of communication networks where edges correspond to existing or potentially new
communication links. For situations where those links must be purchased as coherent sets
(e.g. the communication infrastructure of different companies/organizations), our SW-DSG
problem would be the appropriate formulation.
4.2 Computational Complexity
To our knowledge, the SW-DSG generalization of the Steiner tree problem has not been
previously studied and hence we now consider its computational complexity.
342

Scheduling Conservation Designs for Maximum Flexibility

The SW-DSG problem is a generalization of the traditional directed Steiner tree (DST)
problem, which is known to be NP-complete (Hwang, Richards, & Winter, 1992). Further,
under standard complexity assumptions, DST is hard to approximate by a factor better
than log(|T |) (Charikar, Chekuri, Cheung, Dai, Guha, & Li, 1998). Note that these results
hold even for acyclic directed graphs. There are a number of effective heuristic algorithms
for DST (Drummond & Santos, 2009), with many of the most successful relying on shortest path computations as a subroutine. While shortest paths can be computed in edge
weighted graphs efficiently, this turns out to not be the case for our set-weighted problem.
In particular, note that the shortest path problem is a special case of DST (or SW-DSG)
where there is a single terminal vertex. This problem turns out to be NP-Hard for SWDSG, even when restricted to acyclic graphs and the special edge set structure shown in
our original deterministic optimization problem, which is the case for the scenario graphs
from our conservation problem.
Theorem 1. The SW-DSG problem is NP-hard even when restricted to acyclic graphs with
a single terminal vertex and the edge set structure in scenario graph.
Proof. We prove the hardness by reducing the weighted set cover problem to the subclass of
SW-DSG problems restricted to a scenario graph with one scenario and exactly one terminal.
Note that here we consider the decision version of the SW-DSG problem, which asks if there
is a feasible Steiner graph whose cost is less than a specified threshold C ∗ . An instance of
the weighted set cover problem specifies a ground set of elements S = {e1 , . . . , en }, a set
S = {S1 , . . . , Sm } of m subsets Sj ⊆ S, a cost Cj for each subset, and a cost bound C ∗ .
0
∗
The problem
S asks whether there is a collection S ⊆ S with total cost no more than C
such that Sj ∈S 0 = S.
Given a set cover instance, we first describe how to construct a scenario graph as illustrated in Figure 2 and later describe the corresponding SW-DSG instance. The graph
contains 2n layers, which alternate between set layers and element layers starting with a
set layer (n layers of each, hence 2n layers). Each layer has m vertices labeled S1 , . . . , Sm
to represent the sets in S and n vertices labeled e1 , . . . , en to represent the elements in S.
In addition we include a root vertex r. Each vertex can also be seen as a parcel with a
single patch. The edges in the graph only go from one layer to the immediate next layer
as follows. The root vertex has an edge going to each Sj in the first set layer. For the ith
element layer (i.e. layer 2i in the graph), we include an edge from a vertex with label Sj in
the previous layer to a vertex with label ei in the current layer whenever ei ∈ Sj . Finally,
vertex ei at the ith element layer has an edge from it to each Sj in the next layer.
The corresponding SW-DSG (conservation problem) instance on this graph is specified
as follows. The root node is r and the single terminal vertex is en at the final element layer.
The edge sets are specified as follows, which is the same as the setting in a scenario graph.
There are edge sets Ej,t for each Sj at time t. In particular, Ej,t contains every incoming
edge that is from any vertex and to any vertex labeled as Sj at layers t0 ≥ t. We let the
strictly decreasing f (t) be sufficiently close to 1 for all t’s. The cost of each Ej,t is equal to
Cj × f (t) where Cj is the cost of Sj in the original set cover problem. In other words, the
cost of Ej,t is almost Cj . Similarly, there are edge sets Ei,t for each ei at time t. We set
their costs as 0. The cost threshold for the SW-DSG problem is equal to the threshold C ∗
of the set cover problem.
343

Xue, Fern, & Sheldon

To see that this reduction is correct, consider the case where the resulting SW-DSG
instance has a feasible solution. The solution provides a path from r to en through purchased
edge sets that have total cost at most C ∗ .
Since the edge set Ei,t for each ei has zero cost, the edge set cost is the result of
purchasing edge sets Ej,t . By the construction the path must go through a sequence of
alternating element nodes and set nodes. In particular, the path must traverse each element
node ei for i = 1, . . . , n. The only way for this to happen is to purchase for each of those
ei at least one edge leading to ei from one of the immediately preceding Sj at layer t ≤ 2i,
which is only possible when ei ∈ Sj . This can only happen by purchasing the corresponding
edge set Ej,t , corresponding to Sj , which has a cost of (almost) Cj . From this we see that
the collection of Sj corresponding to purchased edge sets must cover all of the elements and
that their total cost is no more than C ∗ . Thus, the collection of sets is a solution to the set
cover problem.
Conversely consider an instance of the set cover problem with a feasible solution. It is
easy to verify that a feasible solution to the corresponding SW-DSG problem is to purchase
edge sets Ej,1 corresponding to any Sj in the set cover solution. Combining the above we
see that there is a feasible solution to the SW-DSG instance if and only if there is a feasible
solution to the set cover instance.

Figure 2: Description of the reduction from set cover to SW-DSG with a single terminal
vertex and a scenario graph.

The above result proves that the shortest (or least cost) path problem is also NP-hard
for SW-DSG, i.e. the problem of finding a least cost path when edges are purchased as
sets. Thus, it is difficult to extend prior shortest-path-based heuristics for the Steiner tree
problem to our problem. Given that SW-DSG is in NP, it is NP-complete. This motivates
our derivation of an efficient heuristic solution approach in the next section, which computes
both a feasible solution along with a bound on the cost of the optimal solution. Importantly
this bound provides a sense of how good the computed solution is compared to the optimal.
344

Scheduling Conservation Designs for Maximum Flexibility

5. Primal-Dual Algorithm
A potential solution approach to the SW-DSG problem is to encode it as a Mixed Integer
Program (MIP), which is straightforward, and then to use an off-the-shelf MIP optimizer.
While this approach produced non-trivial results for the upfront conservation problem (Sheldon et al., 2010), as our experiments will demonstrate, it does not scale well for our problem.
A related approach could be to consider a rounding procedure for the MIP’s LP-relaxation.
While solving the LP-relaxation is easier than solving the MIP, our experiments show that
the scalability of LP solvers is also poor for the problem sizes of interest to us. Instead,
we exploit the MIP encoding in another way, by following the primal-dual schema (Vazirani, 2001) to derive a scalable algorithm that performs near optimally in our experiments.
Our work can be considered as a non-trivial generalization of previous work (Wong, 1984),
where the primal-dual schema was applied to DST. Moreover, an early-stopping version of
our primal-dual algorithm provides a way to trade-off the schedule flexibility and reward
(ε̂ > 0). Note that the primal-dual algorithms for SW-DSG and our original deterministic
conservation problem only differ in the notations. In other words, the edge set structure in
conservation problem does not offer further improvements for the algorithm. Thus in the
following, we only present the approach for SW-DSG.
5.1 Primal-Dual Algorithm for SW-DSG
To apply the primal-dual schema, we start by giving a primal MIP for the SW-DSG problem
along with the dual of its LP-relaxation in Figure 3. The primal MIP includes a binary
variable y(Es ) for each edge set in E, which indicates whether Es was purchased (y(Es ) = 1)
or not (y(Es ) = 0). The objective of the primal is then simply the sum of these variables
weighted by the costs of the corresponding edge sets. The Steiner graph constraint, requiring
that all terminals be connected to the root node by purchased edges, is encoded using a
standard network-flow encoding (lines 2–4) involving flow variables xki,j . The flow variable
xki,j encodes the flow on edge (i, j) destined for terminal k. The flow balance constraints
(2) guarantee that one unit of flow is carried on a path from the root node r to terminal k.
The LP-relaxation of the primal simply replaces the integer constraints on the y(Es )
variables with a positivity constraint. The dual of this relaxed problem (lines 6–9) includes
k corresponding to the primal flow constraints. Note that the
dual variables uki and wi,j
constraint that one unit of flow leaves the root is implied by the other flow constraints. By
omitting this constraint, one could simplify the dual by eliminating the ukr variables (or,
equivalently, set ukr = 0 for all k ∈ T ).
Given the primal and dual formulations of our problem, we can now apply the primaldual schema for designing optimization algorithms. In particular, our primal-dual algorithm
is iterative where each iteration increases the value of the dual objective and purchases
a single edge set Es , which corresponds to setting the primal variable y(Es ) = 1. The
iteration stops when the purchased edges form a Steiner graph (i.e. the primal becomes
feasible). The value of the dual objective at the end of the iteration serves as a lower bound
on the optimal primal objective, which provides a worst-case indication of how far from
optimal the returned solution is. At a high level, this algorithm is a simple greedy heuristic
that continuously purchases the most beneficial edge set in order to build paths for an
345

Xue, Fern, & Sheldon

(Primal) min

M
X

y(Es ) × cs ,

subject to:

(1)

s=1

X
(i,h)∈E

xki,h −

X

xkj,i

(j,i)∈E

xki,j



if i = r
1,
= −1, if i = k , k ∈ T, i ∈ V


0,
if i =
6 r, k
X
y(Es ), k ∈ T, (i, j) ∈ E
≤

(2)

(3)

s:(i,j)∈Es

xki,j ≥ 0, (i, j) ∈ E, k ∈ T
y(Es ) ∈ {0, 1}

(Dual) max

X

(ukk − ukr ),

(4)
(5)

subject to:

(6)

k∈T

X

k
wi,j
≤ cs , s ∈ {1, . . . , M }

(7)

k
ukj − uki − wi,j
≤ 0, k ∈ T, (i, j) ∈ E

(8)

k,(i,j)∈Es

k
wi,j

≥0

(9)

Figure 3: MIP for the SW-DSG problem and the corresponding dual LP of the MIP’s LPrelaxation. The SW-DSG problem is defined by a graph G = (V, E), a root vertex
r, a set of terminal vertices T , and a set of edges sets E = {Es : s = 1, . . . , M },
where each Es ⊆ E.

unconnected terminal. The primal-dual schema provides a principled way of incrementally
computing this heuristic and at the same time computing a lower bound.
Algorithm 1 gives pseudo-code for the algorithm. The main data structure is an auxiliary
graph G0 = (V, A) with the same vertices as the input graph G. The auxiliary graph edge
set A is initially empty and then each iteration adds the newly purchased edges Es ∈ E.
The algorithm terminates when the edges in A form a Steiner graph. The edge sets used
to construct this graph are then returned as the solution, following a pruning step that
removes obviously redundant edge sets, which the algorithm can sometimes include during
the iteration process.
In order to describe the algorithm in detail, we first introduce some terminology. Given
a current auxiliary graph A, we let C(k) denote the set of all vertices that have directed
paths to terminal node k via only edges in A. Note that we consider k to be included in
C(k). Also, we define the cut set of a terminal node k, denoted by Cut(k), to be the set of
all edges (i, j) such that j ∈ C(k) and i 6∈ C(k). Intuitively, if k is not already reachable
from the root, we know that at least one edge in Cut(k) must be added to A in order to
arrive at a Steiner graph.
346

Scheduling Conservation Designs for Maximum Flexibility

Algorithm 1 Primal-Dual Algorithm for SW-DSG.
1: {Inputs: Graph G = (V, E), edge sets E = {E1 , . . . , EM }, costs {c1 , · · · , cM }, terminals
T ⊆ V}
2: Initialize:
k = 0, for each (i, j) ∈ E, k ∈ T
uki = 0, for each k ∈ T, i ∈ V; wi,j
0
G = (V, A) with A = ∅
lowerBound = 0, solution = ∅
3: while G0 is not a Steiner graph do
4:
Let k be random vertex in T not connected to r in G0
5:
S = {s | Es ∩ Cut(k) 6= ∅, s 6∈ solution}
6:
s∗ = arg mins∈S ∆(s,
 k)P

k0
where ∆(s, k) = cs − k0 ∈T,(m,n)∈Es wm,n
/|Es ∩ Cut(k)|
7:
8:
9:
10:
11:
12:
13:

ukj = ukj + ∆(s∗ , k), for each j ∈ C(k)
k = w k + ∆(s∗ , k), for each (i, j) ∈ Cut(k)
wi,j
i,j
A = A ∪ Es∗
lowerBound = lowerBound + ∆(s∗ , k)
solution = solution ∪ {s∗ }
end while
Pruning: solution = solution − {s | ∃s0 ∈ solution, Es ⊂ Es0 }

The algorithm first initializes all dual variables to zeros and the auxiliary graph A to
include all vertices and no edges. Each iteration then proceeds by first randomly selecting
a terminal vertex k that is not connected to r in the auxiliary graph. At an intuitive level,
the algorithm will then select an edge set Es that contains a cutset edge of k according to
a heuristic ∆(s, k) that is derived by applying the primal-dual schema. More concretely,
the aim of each iteration is to raise the dual objective value by increasing the value of ukk
while maintaining feasibility. Increasing ukk by itself will violate constraints of type (8) in
the dual and lines 5 through 8 of the algorithm maintain feasibility by selecting an edge set
Es∗ among those that intersects the cut set of k and then raising all variables corresponding
to vertices in C(k) and edges in Cut(k) by a value ∆(s∗ , k) (including ukk ). This is done in
a way that causes the dual constraint of type (7) corresponding to edge set Es∗ to become
tight. Since this constraint corresponds to primal variable y(Es∗ ), the algorithm effectively
sets y(Es∗ ) = 1, indicating a purchase, by adding the edges in Es∗ to A. The dual objective
value at termination is the sum across iterations of ∆(s∗ , k) and is returned as the lower
bound.
The key property of our algorithm is that each iteration increases the dual objective,
while also maintaining feasibility of the dual. This guarantees that at each iteration the
dual objective value corresponds to a true lower bound on the optimal value of the primal.
Theorem 2. Each iteration of the primal-dual algorithm produces a feasible dual solution
with increased objective.
Proof. As the base case, the initialization assigns all dual variables to be zeros, which is a
l },
feasible solution. Now suppose that iteration q − 1 starts with a feasible solution {uli , wi,j
which satisfies the dual constraints of type (7) and (8). Now if the algorithm terminates,
347

Xue, Fern, & Sheldon

we get a feasible solution. Otherwise let k be the terminal vertex selected. For all variables
l } with l 6= k the values are not changed, so (8) is satisfied. For the remaining
{uli , wi,j
variables with l = k, there are three cases. Case 1: For j 6∈ C(k), the variables ukj and
k are unchanged, so they cannot contribute to a violation of (7) or (8). Case 2: For any
wi,j
edge (i, j) with both j, i ∈ C(k), we increase both ukj and uki by ∆(s∗ , k) and continue to
satisfy the corresponding constraint of (8). Case 3: For any cut set edge (i, j) ∈ Cut(k), we
k by ∆(s∗ , k) so that (8) remains satisfied. Since the w k for edges in the
increase ukj and wi,j
i,j
cut set are increased, we must ensure that constraints of type (7) do not become violated.
The choice of ∆(s∗ , k) made by the algorithm can be verified to never violate any of those
constraints and makes at least one of them tight.
After the main portion of the algorithm terminates, a pruning step is conducted to
remove any edge set that is a subset of some other edge set in the solution, which decreases
the total cost while maintaining feasibility. In particular, in the context of our conservation
scheduling problem, the pruning step ensures that each parcel is purchased no more than
once in the final solution. There are other more aggressive and computationally expensive
pruning techniques that could also be used. For example, one could consider removing each
one of the selected edge sets from the final solution and then test for feasibility. If the
solution is still feasible, then the edge set can be eliminated. We did not find this more
aggressive style of pruning to be necessary in our experiments.
5.1.1 Implementation and Running Time
k dual variables.
Note that our pseudo-code stores and updates values for the ukj and wi,j
Then a naive implementation of the above algorithm would result in O(|E||T |) runtime for
initialization as well as the computation per iteration, where |E| is the number of edges
in the graph and |T | is the number of terminals. This could be too much for SW-DSG
problems with a large network such as the one in our conservation application. However,
the algorithm is described in this way only for presentation purposes. It turns out that for
the purposes of running the algorithm, it can be implemented significantly more efficiently.
k values for
In particular, we only need to store and update the sum of corresponding wi,j
each edge set (i.e. the sum term that appears inside of the definition of ∆(s, k) on line
6), and maintain the current objective value (stored as lowerBound in the pseudo-code),
which is updated on line 10. Therefore, before the iterations only those M + 1 variables
need to be initialized, where M is the number of edge sets and is much smaller than the
size of the network. In our implementation the dominant computation per iteration is the
computation of the cut set for the selected terminal k. We find the cut set by a backward
traversal from terminal k toward the root. The time for this computation is acceptable
when terminals are only connected to relatively small parts of the overall graph. This is
the case in our conservation problem, where terminals are only connected to nodes in the
same cascade and among those only ones that are spatially close enough to be reached. In
other applications where terminals are possibly connected to a large portion of the graph,
it may be preferable to incrementally maintain a cut set for every terminal at each iteration
to reduce the computation. Then the memory needed is O(C|T |) where C is the maximum
size of a cut set and presumably C  |E|. After getting the cut set, the algorithm takes
O(M C) time to identify the best edge set and update the solution.

348

Scheduling Conservation Designs for Maximum Flexibility

5.2 Early-Stopping for Fractional Connection
In our primal-dual algorithm, the computation continues until all of the terminals in the
scenario graph are connected by paths from the root. In the context of our conservation
problem this corresponds to having no reward approximation loss (ε̂ = 0). Here we modify
the above primal-dual algorithm to allow for reward approximation loss where ε̂ > 0. This
case corresponds to only modifying the SW-DSG feasibility constraint to only require a
fraction 1 − ε̂ of the terminals to be connected, leading to a natural way of exploring the
trade-off between reward and flexibility.
Given the incremental, greedy nature of our primal-dual algorithm, which adds one
edge set each iteration, a natural choice for this fractional connection problem is to stop
the algorithm whenever at least a fraction 1 − ε̂ of the terminals are connected. While this
basic early-stopping approach will lead to some improvement in the cost of the returned
solution, compared to ε̂ = 0, the savings are often quite minimal. This is due to the fact
that the primal-dual algorithm grows paths from the terminal nodes to the root and is
unaware of the early-stopping condition. As a result, some of the paths that were being
grown are never actually connected to the root at the point that the algorithm is stopped.
These unconnected paths can be considered to be a waste of resources with respect to
meeting the fractional connection constraint. Thus, to make this early-stopping algorithm
viable, it is necessary to perform pruning on the early-stopping result. Our algorithm for
fractional coverage then has two stages: 1) Generation, where early-stopping is used to
generate an initial solution that meets the fractional connection constraint, and 2) Pruning,
where the solution produced in stage 1 is pruned while maintaining the fractional connection
constraint.
For the pruning stage we use a simple but effective greedy strategy. The idea is to
iterate through the purchased parcels in the schedule returned by the early-stopping stage
and to delay the purchase of each parcel as long as possible while ensuring that the number
of connected terminal nodes is almost always within the required fractional connection
tolerance.
We have found that for our conservation application, where the SW-DSG problem corresponds to a set of cascades, it is beneficial to prune using an independently generated and
larger set of scenarios than those used to create the initial solution. This is analogous to using validation data to tune algorithm parameters in Machine Learning prediction problems,
and it is beneficial for the same reasons. We found that pruning based on the original set of
scenarios was often overly aggressive and hurt empirical performance due to over-fitting of
the SAA scenarios. Since we can easily generate independent scenarios to estimate the true
expected reward of the pruned policies, it is better to prune based on that criterion instead.
Also, since the computational complexity of evaluating the reward of pruned policies is low
compared with the SAA optimization, we can afford to use a larger set of scenarios. In
particular, in our experiments we formed the initial schedules based on a set of 10 cascade
scenarios and conducted the pruning step with respect to 40 cascade scenarios.
This approach for pruning can also be viewed as directly enforcing a threshold on the
(independently estimated) expected reward from the original stochastic problem (Equation
1) instead of enforcing a threshold on the objective value of the SAA problem (Equation
2). Since we can’t calculate the correct threshold value (the RHS of Equation 1) without
349

Xue, Fern, & Sheldon

knowing the true optimum R∗ of the stochastic problem, we use the SAA optimum R̂∗
in its place. The SAA optimum is a stochastic upper bound to R∗ , so this is generally a
conservative approach for enforcing Equation 1.

6. Experiments
In this section, we first evaluate our primal-dual algorithm by applying it to a real, full-scale
conservation problem. Next, to verify the robustness of our approach to other problems, we
present results using synthetic conservation data from a problem generator used in several
recent studies. We focus the first two parts of the experimentation on the case of ε̂ = 0,
which we will see provides substantial gains in flexibility. In order to explore the trade-off
between flexibility and reward (population spread), at the end of this section, we evaluate
the early-stopping approach for ε̂ > 0.
6.1 Evaluation of Primal-Dual Algorithm on Real Conservation Map
The real map we use is the same dataset as in prior work by Sheldon et al. (2010) on
computing upfront conservation designs. The data is derived from a conservation problem
involving the Red-cockaded Woodpecker (RCW) in a large land region of the southeastern
United States that was of interest to The Conservation Fund. The region was divided into
443 non-overlapping parcels (each with an area of at least 125 acres) and 2500 patches
serving as potential habitat sites. Parcel costs were based on land prices and some land
parcels were already conserved and thus had cost zero. We use the same population spread
model as Sheldon et al. (2010), which was based on individual-based models of the RCW.
Since our approach requires a conservation design as input, we use the design computed
by Sheldon et al. (2010) using a total budget constraint of $320M. The map of the area is
shown in the left cell of Figure 7, with parcels making up the design shaded green and free
parcels (with cost 0) shaded grey; red ‘+’ marks indicate initially occupied patches. Our
method also requires specifying a strictly decreasing function for defining the surrogate cost
function, for which we use f (t) = β t with β = 0.96. We found that the results are not very
sensitive to the value of β.
6.1.1 Comparing to Optimal Solutions
Here we compare the solutions of our primal-dual algorithm to optimal solutions found using
the CPLEX solver applied to a MIP encoding of the SW-DSG problem. The MIP encodings
become very large as the horizon and number of scenarios increase. In particular, there are
443 · H + 2500 · H · N variables and the number of constraints grows with the number of
edges, in the cascade network, which becomes impractical as N and H grow. Since the
optimal solver can’t scale to large versions of the problem, we consider problems involving
cascade networks with just 2 scenarios and horizons ranging from just 15 to 40 years. We
also use CPLEX to compute solutions to the LP-relaxation of the MIP. The objective value
returned for the LP provides an alternative approach to computing a lower bound on the
optimal solution and thus is interesting to compare to our lower bound in terms of tightness
and runtime. Since our primal-dual algorithm is stochastic due to the random selection of
350

Scheduling Conservation Designs for Maximum Flexibility

H
H
H
H
H
H

=
=
=
=
=
=

15
20
25
30
35
40

Cost
MIP
126.8
123.6
117.6
130.4

(M$)
PD
126.22
125.7
121.4
134.0
131.3
127.5

Lower
LP
122.2
117.7
104.7
117.3
109.9

Bound
PD
84.9
71.9
61.5
56.9
64.1
59.7

Run
MIP
5.5
8.2
28
5126

Time
LP
6.13
7.6
10
15
18

(s)
PD
0.9
2.5
9.0
11
25
45

Table 1: Comparison of Primal-Dual (PD) with MIP and LP.

terminal nodes, we report averages over 20 runs, noting that the standard deviations are
negligible.
The first two data columns of Table 6.1.1 show the (surrogate) cost of the solutions
found by CPLEX solving MIP and our algorithm (PD) for increasing horizons, where larger
horizons correspond to larger problems. When a method fails to return a solution due to
memory constraints no value is shown in the table. We see that for horizons where MIP is
able to yield solutions by CPLEX, our algorithm produces solutions that have very similar
costs (here lower cost is better). We also see that the MIP solver runs out of memory and
is unable to return solutions for the 2 largest problem instances, which are already scaled
down versions of the problem (small number of cascades and horizon).
The next two columns of Table 6.1.1 provide results for the lower bound computed by
CPLEX solving the LP and by the PD algorithm. We see that the lower bound produced
by the LP is significantly tighter than the bound produced by our algorithm. However, the
LP cannot be solved by CPLEX for the largest problem, while our approach still yields a
lower bound. Overall, though our lower bound is not as good as the LP (when it can be
computed), it is generally within a factor of two of the optimal solution, which provides a
non-trivial assurance about the quality of the returned solution for very large problems.
The final three columns of Table 6.1.1 present the time used by the approaches for each
problem, where blank cells indicate that the method ran out of memory. Our algorithm is
significantly faster than the MIP approach, which fails for the two largest problems, and
is comparable with the LP approach, which only provides a lower bound and fails for the
largest problem. This later result indicates that a solution based on LP-rounding would
face difficulty, since even solving the LP for these large problems (40 time steps with 2500
patches each) is computationally demanding. An advantage of the primal-dual algorithm
is that it avoids encoding the LP and rather works directly with a graph.

2. Here the PD cost is less than the “optimal” MIP cost returned by CPLEX. After investigating, we found
that CPLEX correctly evaluates the solution it returns, but thinks that the solution is optimal when it
is not. It appears that this issue is due to the small error tolerance allowed by the CPLEX solver.
3. Here MIP takes less time than LP. We think this is possibly because CPLEX uses different algorithms
for LP and MIP. Especially, MIP is solved by branch-and-bound algorithm which uses modern features
like cutting planes and heuristics, making CPLEX a powerful MIP solver.

351

Xue, Fern, & Sheldon

6.1.2 Number of Cascades in the Scenario Graph
According to SAA, the optimal solution over a finite set of cascade scenarios will converge
to true optimum with more scenarios. Previously only two cascades are used due to the
poor scalability of CPLEX. Now we study the number of cascade scenarios we should use
to ensure a good solution. Recall that as N increases, the original stochastic problem is
approximated more accurately. Yet a larger N corresponds to more computation. More
importantly, here with  = 0, a larger N leaves the schedule less space for flexibility. In the
extreme case of N → ∞, the only possible schedule is the upfront schedule that has minimal
flexibility. To find a good value of N in practice, we study the primal-dual solutions with
different number of cascade scenarios by validating the reward R(π) that the each primaldual schedule can achieve. Given that the population spread is stochastic, we compute the
reward R̂(π) by running 20 simulations of the stochastic population spread model. Each
simulation provides a reward value (number of occupied patches at the horizon) and we
average the results. We do this for the schedules produced by our primal-dual algorithm
and for the upfront schedule. Recall that the intention is to nearly match the reward of
the upfront schedule. Figure 4 presents the results when the time horizon is H = 20. We
observe that the primal-dual schedule achieves more and more reward when N increases,
and the reward is converging towards the expected reward of the upfront schedule. We also
see that 10 cascades is quite close to get the best performance and the rate of improvement
is slowing down. Thus, the remainder of our experiments use 10 cascades for the SAA.

Figure 4: Rewards of PD solutions w.r.t the number of cascade scenarios.

6.1.3 Quality of Conservation Schedules
We now evaluate our algorithm on problems of more realistic sizes. Here, we consider
problems based on 10 cascades and horizons ranging from 20 to 100 years, which are well
beyond the range approachable for the MIP and LP. The solution times for our algorithm
ranged from 15 seconds for H = 20 to 29 minutes for H = 100.
First, we evaluate the average accumulated reward of the schedule returned by our
method for each horizon in Figure 5. The average reward of the upfront schedule ranged
from 332 for H = 20 to 615 at H = 100 and for all time horizons the primal-dual solution
attained average reward at least 95.3% of optimal, with negligible error bars about the
352

Scheduling Conservation Designs for Maximum Flexibility

averages. The small gap indicates that for 10 scenarios the SAA approximation is quite
good—the gap could be further reduced by increasing the number of scenarios.

Figure 5: Rewards of PD schedules w.r.t.
time horizon H.

Figure 6: Cost curves of PD schedules for
horizons 20 to 100.

Of course, we must also consider the cost curves corresponding to the schedules, since
that is what affords the flexibility criterion of our problem. Figure 6 presents the cost
curves for our schedules. Note that as defined in Section 3.2, a cost curve shows the (nondiscounted) accumulated cost of a schedule over time. Then the cost curve for a schedule
produced for horizon H will only increase until time H and then remain flat, reflecting that
no purchases are made after that time. We see that for all horizons the cost curves show
a fairly gradual increase in cost expenditures over time, indicating that the schedules are
indeed providing a significant amount of flexibility regarding purchase times, particularly
when compared to the upfront schedule, the cost curve of which is the flat black line in
Figure 6 since all the parcels are purchased at time 0. In experiments not shown, we found
that the cost curves vary by a small amount for different values of β, but the same general
trend is present. Interestingly, in all curves there is a sudden jump in cost at around 20
years. To understand this in Figure 7 we show both the parcel purchases made by our
schedule and the population spread on the map over the 100 year horizon. We see that at
t = 20 the sharp increase in cost is due to the purchase of some relatively expensive and
vast parcels in the southern part of the design. Looking at the population spread dynamics,
it is apparent that those parcels are a critical gateway for ensuring reliable spread to the
southwestern part of the design in later years. Delaying the purchase any longer significantly
increases the probability that such spread does not occur, which our approach discovers.
Another interesting observation can be seen by comparing the expected population
spread under the PD computed schedule and the expected population spread of the upfront
schedule (Figure 7). The most striking difference between the spreads is seen at time steps
t = 20, 60, 80 in the northeastern part of the map. For the upfront schedule the entire
northeastern part is occupied in large part, while for the PD schedule there is a “hole” in
the northeastern part near where the initial bird populations are located. Note, however,
that this hole is finally occupied by the horizon of the problem (t = 100). At that time, the
spread in the upfront and PD schedules are visually very similar, which agrees with the fact
that their measured rewards were also similar. The reason for the difference in population
spread is that the PD schedule delays the purchase of some of the northeastern parts of
353

Xue, Fern, & Sheldon

t = 20

t = 60

t = 80

t = 100

Figure 7: (Left) Original conservation design used for scheduling shown as green shaded
parcels. Free (zero-cost) parcels are also shaded in dark grey and red ‘+’ indicates
initially occupied patches. (Right) The top row shows the parcels purchased
(shaded green) by our PD schedule over a horizon of 100 years. The middle
row shows the population spread over the same horizon for the schedule, where
lighter red shading of a patch indicates a smaller probability of being occupied
(as measured by 20 simulations). The bottom row shows the population spread
of the upfront schedule over a horizon of 100 years.

the map near the initial bird population until about 20 years before the time horizon ends.
From the population spread process of both schedules, we found that these parcels are very
closely connected and hence can become occupied in a fairly short time if a bird population
is nearby. This is apparent for the upfront schedule, where those areas are already occupied
by t = 20. Thus, the purchase of such parcels can be delayed as long as there is enough time
left for the population to spread over these landscapes. Therefore, the purchasing can be
delayed not only for parcels far away from current population, but also for parcels that can
be covered quickly and reliably. Note that such flexibility is mainly due to our definition of
the reward function, which only takes the population at time H into account. If we count
the population at every time step, presumably a good schedule would purchase the “hole”
area very soon for more population.
6.2 Evaluation of Primal-Dual on Synthetic Maps
To evaluate the primal-dual algorithm more thoroughly, we randomly selected 10 synthetic
maps generated and used in prior work (Ahmadizadeh et al., 2010). All the maps consist of
the same region of 146 non-overlapping parcels and 411 patches, with different configurations
of parcel costs and the initial population. For each map, we considered problems involving
354

Scheduling Conservation Designs for Maximum Flexibility

different conservation designs, where each design corresponded to the upfront solution when
the budget is limited to a factor b of the total parcel cost of the map, where b ranged from 0.1
to 0.5. In this section, we present a very similar analysis as in Section 6.1 and show consistent
results, indicating that our primal-dual algorithm is stable across different problems.
6.2.1 Comparing to Optimal Solutions
We first compare the upper and lower bounds returned by our primal-dual algorithm to the
optimal objective values of MIP and LP as computed using CPLEX. Since CPLEX still has
scalability issues when solving the larger synthetic problems, we restrict the comparison to
problems with 2 and 4 scenarios and a horizon of 20 years.
Results on all of the 10 maps are very similar. As an example, Figure 8 shows the
surrogate cost (PD-UB) and dual objective value (PD-LB) of the primal-dual solution on
map 768, together with the optimal surrogate cost (CPLEX-MIP) and the lower bound
computed for the LP by CPLEX. We see that compared to optimal, our algorithm can still
produce solutions with similar costs, especially when the problem is easy (b is smaller).
Also, we again see that the lower bound computed by CPLEX is better than the PD lower
bound. However, the PD lower bound is still within a factor of 2.

Figure 8: Cost and objective value of problems on map 768. The horizontal axis varies
the amount of budget used to compute the upfront solution that is used as the
conservation design given to the scheduling algorithms.

6.2.2 Quality of Conservation Schedules
We now consider larger problems based on 10 cascade scenarios and horizon H = 40, for
which the MIP and LP are not practically solvable.
We first compare the average accumulated reward of the schedule returned by our primaldual algorithm and the upfront schedule. Figure 9 shows results for one of our maps,
indicating that the rewards achieved by our primal-dual schedules are always very close to
those of the upfront schedules, as desired. The results for other maps are very similar.
We also study the cost curves of the schedules in order to illustrate their flexibility
compared to upfront schedules. Figure 10 presents the average cost curves for our schedules
across all the 10 maps. It is noted that when the budget is very limited, the purchase is not
delayed very much. For example, when b = 0.1, most parcels are purchased before t = 15,
long ahead of the time horizon. On further analysis this can be explained by the fact that
355

Xue, Fern, & Sheldon

Figure 9: Rewards of primal-dual schedule and upfront schedule on
map 1027.

Figure 10: Average cost curves of PD
schedules on 10 maps.

for many of the maps and such small budgets, the sets of affordable parcels are fairly spread
out and loosely connected. This means that the population requires more time in order to
reliably spread across such sets. Thus, the parcels must be purchased quite early in the
horizon to support that spread. Rather for larger budgets, the sets of parcels that must
be purchased are spread out but also more tightly coupled, which allows for easier, more
reliable population spread. Thus, it is possible to delay purchases to a much larger extent
as seen by the cost curves for the larger budgets. This shows that our algorithm is able
to afford considerable flexibility when the initial conservation design supports reasonably
reliable population spread.
6.3 Early-Stopping for Trading Off Flexibility and Reward
We now consider the early-stopping variant of our primal-dual algorithm, referred to as
PD-ES, for producing schedules that trade off flexibility for reward using ε̂ > 0. The
dataset we use here is the real conservation map. Figure 11 illustrates the cost curves of
the early-stopping schedules with ε̂ = 0.0, 0.05, 0.10, 0.15, 0.20 and H = 20, 40, 60, 80, which
demonstrates the possible budget saving over time if a corresponding fraction of reward loss
is allowed. Figure 12 shows the average simulated rewards of these schedules.
First we notice that the average reward achieved by the early-stopping schedules is
almost always within the specified error tolerance, which shows that the pruning step is
generalizing effectively. We also see that the cost curves of the early-stopping schedules
show significant improvement for even small values of ε̂ compared to no early-stopping
(ε̂ = 0). For example, when H = 60 and ε̂ = 0.20, there is almost no cost during the first
several years, and for several decades the cost is approximately half of the cost required for
ε̂ = 0. These results show that our approach is able to provide a set of schedules that spans
a spectrum of trade-offs, which can then be considered by conservation managers.

7. Summary and Future Work
In this work, we addressed the problem of scheduling purchases of parcels in a conservation
design. We formulated the problem as a network cascade optimization problem which was
356

Scheduling Conservation Designs for Maximum Flexibility

H = 20

H = 40

H = 60

H = 80

Figure 11: Cost curves of PD-ES schedules with pruning. The red line (ε̂ = 0) shows the
cost curve of non-early-stopping PD schedule.
reduced to a novel variant of the classic directed Steiner tree problem. We showed that
this problem is computationally hard and then developed a primal-dual algorithm for the
problem. Our experiments showed that this algorithm produces close to optimal results
and is much more scalable than a state-of-the-art MIP solver. We also showed that an
early-stopping variant of the algorithm is able to explore the possible trade-offs between
flexibility and reward, which is an important consideration in practice.
The scheduling problem considered in this work poses considerable challenges to generic
off-the-shelf schedulers and planners. The complicating factors include: 1) highly-stochastic,
exogenous dynamics that arise from the population spread model, 2) the need to reason
about spatio-temporal processes, 3) the long horizons that must be considered, and 4) the
combinatorial space of potential investment options at each point in time. The general
solution schema we pursued in this work is likely to be applicable to other problems that
pose similar challenges to existing techniques. In particular, this general schema suggests
approximating the problem via the SAA and then studying the resulting deterministic
optimization problem. Often the resulting deterministic problem will correspond to an
existing well-studied problems, for which state-of-the-art approximation algorithms can
be used. In other cases, such as in this work, the resulting problem will be related to
an existing well-studied problem and a solution can be designed by extending existing
solution frameworks. We expect that this generic SAA schema will be particularly useful
357

Xue, Fern, & Sheldon

H = 20

H = 40

H = 60

H = 80

Figure 12: Rewards of primal-dual schedules with early-stopping. The number below each
data point indicates the percentage of PD-ES reward over PD reward.

for problems involving stochastic spread of populations or information across networks,
since the deterministic problems will typical map to graph-theoretic problems, for which
there is a vast literature.
In future work, we plan to consider several improvements to the primal-dual algorithm.
Currently, at each iteration, the algorithm randomly picks an unconnected terminal to
grow a path from. It is likely that more intelligent selection mechanisms can improve the
overall results. We are also interested in developing a primal-dual algorithm that directly
incorporates the error tolerance constraint of our early-stopping approach. This would
provide a more direct method for trading off reward for improved flexibility. Furthermore,
we intend to pursue fully adaptive approaches to this and other conservation problems.
One idea is to incorporate our scheduling approach into a replanning algorithm that selects
purchases for the current decision epoch based on the most up-to-date information. In
particular, at each decision epoch a schedule would be formed and those parcels scheduled to
be purchased immediately (those with no flexibility) would be purchased or a subset of those
in cases where the immediate budget would be exceeded. Considering more sophisticated
approaches that take into account the immediate budget would be a natural and useful
extension. It would also be interesting to consider the conservation problem with other
variants of the reward function. For some species, rather than caring only the population
358

Scheduling Conservation Designs for Maximum Flexibility

in the end, the ecological goal may value the spread during the whole period the same or
even more. Presumably such models would have different properties and complexities from
the one we study in this paper.

Acknowledgements
Parts of the material in this paper appeared in an earlier work by Xue, Fern, and Sheldon
(2012). This work was supported by NSF under grant IIS-0964705.

References
Ahmadizadeh, K., Dilkina, C., Gomes, C. P., & Sabharwal, A. (2010). An empirical study
of optimization for maximizing diffusion in network. In 16th International Conference
on Principles and Practice of Constraint Programming.
Bent, R., & Van Hentenryck, P. (2004). Regret only! Online stochastic optimization under
time constraints. In Nineteenth AAAI Conference on Artificial Intelligence.
Chang, H. S., Givan, R. L., & Chong, E. K. (2000). On-line scheduling via sampling. In
Artificial Intelligence Planning and Scheduling.
Charikar, M., Chekuri, C., Cheung, T., Dai, A., Guha, S., & Li, M. (1998). Approximation algorithm for directed Steiner tree problems. In The Ninth Annual ACM-SIAM
Symposium on Discrete Algorithms.
Chong, E. K., Givan, R. L., & Chang, H. S. (2000). A framework for simulation-based
network control via hindsight optimization. In IEEE CDC conference.
Crowley, M., & Poole, D. (2011). Policy gradient planning for environmental decision making
with existing simulators. In Twenty-fifth AAAI Conference on Artificial Intelligence.
Drummond, L. M., & Santos, M. (2009). A distributed dual ascent algorithm for Steiner
problems in multicast routing. Networks, 53, 170–183.
Golovin, D., Krause, A., Gardner, B., Converse, S. J., & Morey, S. (2011). Dynamic resource
allocation in conservation planning. In Twenty-fifth AAAI Conference on Artificial
Intelligence.
Hanski, I., & Ovaskainen, O. (2000). The metapopulation capacity of a fragmented landscape. Nature, 404 (6779), 755–758.
Hwang, F. K., Richards, D. S., & Winter, P. (1992). The Steiner Tree Problem. Springer.
Kumar, A., Wu, X., & Zilberstein, S. (2012). Lagrangian relaxation techniques for scalable spatial conservation planning. In Twenty-sixth AAAI Conference on Artificial
Intelligence.
Shapiro, A. (2003). Monte Carlo sampling methods. In Stochastic Programming, Handbooks
in Operations Research and Management Science, Vol. 10, pp. 353–426.
Sheldon, D., Dilkina, B., Elmachtoub, A., Finseth, R., Sabharwal, A., Conrad, J., Gomes,
C., Shmoys, D., Allen, W., Amundsen, O., & Vaughan, B. (2010). Maximizing the
359

Xue, Fern, & Sheldon

spread of cascades using network design. In Uncertainty in Artificial Intelligence
(UAI).
Vazirani, V. V. (2001). Approximation Algorithms. Springer, Berlin.
Williams, J., ReVelle, C., & Levin, S. (2005). Spatial attributes and reserve design models:
a review. Environmental Modeling and Assessment, 10 (3), 163–181.
Wong, R. T. (1984). A dual ascent approach for Steiner tree problems on a directed graph.
Mathematical Programming, 28, 271–287.
Xue, S., Fern, A., & Sheldon, D. (2012). Scheduling conservation designs via network
cascade optimization. In Twenty-sixty AAAI Conference on Artificial Intelligence.
Yoon, S., Fern, A., Givan, R. L., & Kambhampati, S. (2008). Probabilistic planning via
determinization in hindsight. In Twenty-third AAAI Conference on Artificial Intelligence.

360

Journal of Artificial Intelligence Research 52 (2015) 543-600

Submitted 09/14; published 04/15

Distributed Evaluation of Nonmonotonic Multi-context Systems
Minh Dao-Tran
Thomas Eiter
Michael Fink
Thomas Krennwallner

DAO @ KR . TUWIEN . AC . AT
EITER @ KR . TUWIEN . AC . AT
FINK @ KR . TUWIEN . AC . AT
TKREN @ KR . TUWIEN . AC . AT

Institute für Informationssysteme, TU Wien
Favoritenstrasse 9-11, A-1040 Vienna, Austria

Abstract
Multi-context Systems (MCSs) are a formalism for systems consisting of knowledge bases
(possibly heterogeneous and non-monotonic) that are interlinked via bridge rules, where the global
system semantics emerges from the local semantics of the knowledge bases (also called “contexts”)
in an equilibrium. While MCSs and related formalisms are inherently targeted for distributed settings, no truly distributed algorithms for their evaluation were available. We address this shortcoming and present a suite of such algorithms which includes a basic algorithm DMCS, an advanced version DMCSOPT that exploits topology-based optimizations, and a streaming algorithm
DMCS-STREAMING that computes equilibria in packages of bounded size. The algorithms behave quite differently in several respects, as experienced in thorough experimental evaluation of a
system prototype. From the experimental results, we derive a guideline for choosing the appropriate
algorithm and running mode in particular situations, determined by the parameter settings.

1. Introduction
In the last decade, there has been an increasing interest in systems that comprise information from
multiple knowledge bases. This includes a wide range of application fields such as data integration, multi-agent systems, argumentation and many others. To picture a more concrete real-world
application, we may consider METIS (Velikova et al., 2014), an industrial prototype system for facilitating timely human decision making in maritime control. In this application, human operators
need support to determine whether a ship entering a port might hide its identity for illegal activities or might be a high risk for environmental hazard. To access such risks, METIS relies on a
number of heterogeneous external information sources such as the commercial ship database IHS
Fairplay,1 ship tracking websites,2 and news items for history of pollution events the ship may have
been involved in.
The rise of the Word Wide Web and distributed systems has propelled this development, and
to date several AI-based formalisms are available to host multiple, possibly distributed knowledge
bases in a compound system. Well-known such formalisms are distributed SAT solving (Hirayama
& Yokoo, 2005), distributed constraint satisfaction (Faltings & Yokoo, 2005; Yokoo & Hirayama,
2000), distributed ontologies in different flavors (Homola, 2010), MWeb (Analyti, Antoniou, &
Damásio, 2011), and different approaches to multi-context systems (Giunchiglia & Serafini, 1994;
Ghidini & Giunchiglia, 2001; Brewka, Roelofsen, & Serafini, 2007; Brewka & Eiter, 2007; Bikakis
1. www.ihs.com/products/maritime-information/
2. marinetraffic.com, myship.com
c
2015
AI Access Foundation. All rights reserved.

DAO -T RAN , E ITER , F INK , & K RENNWALLNER

Figure 1: Pinpointing Joker
& Antoniou, 2010) rooted in McCarthy’s (1993) work; among them, we focus here on Heterogeneous Nonmonotonic Multi-context Systems (MCSs) (Brewka & Eiter, 2007).
As a generalization of previous proposals, MCSs are a powerful formalism to specify systems
of knowledge bases that may have different formats and reasoning powers, ranging from simple
query answering over a relational database to reasoning over description logic knowledge bases (see
Baader et al., 2003), as well as to nonmonotonic formalisms such as default logic (Reiter, 1980) or
answer set programs (Gelfond & Lifschitz, 1991). To allow for heterogeneous knowledge bases and
to deal with the impedance mismatch between them, MCSs abstract knowledge bases to plain mathematical structures; on top, special bridge rules interlink the knowledge bases, where a bridge rule
adds a formula to a knowledge base, depending on certain beliefs at other knowledge bases. Hence
the semantics of a knowledge base with associated bridge rules, which forms a context, depends on
the other contexts, possibly in a cyclic manner. Based on this, MCSs have an equilibrium semantics
in terms of global states in which every context adopts an abstract “local model,” called belief set,
that is conformant with the local models adopted by the other contexts and in addition obeys the
bridge rules. The following simple example, which is a paraphrase of Ghidini and Giunchiglia’s
(2001) Magic Box, illustrates the power of this idea,
Example 1 Suppose that in a computer game, players Batman and Robin chased player Joker to
a partially occluded area, as shown in Figure 1; Robin is wounded and cannot read his distance to
objects. Neither Batman nor Robin can tell Joker’s exact position on the 3×3 box: Batman can only
assure that he is not in columns 2 and 3, while Robin can only tell that he is on row 1. However, if
they exchange their partial knowledge, they can pinpoint Joker to row 1 and column 1.
We can model Batman and Robin as contexts whose local knowledge bases include their information about Joker’s position, which is exchanged using bridge rules, such as “at row (X) ← (2 :
at row (X)).” for Batman, which informally “imports” Robin’s knowledge (context 2) about row
positions; a full encoding is given in Example 2. The equilibrium of the emerging MCS discloses
then Joker’s position to both Batman and Robin.
544

D ISTRIBUTED E VALUATION OF N ONMONOTONIC M ULTI - CONTEXT S YSTEMS

Although MCSs and related formalisms inherently target distributed systems, no truly distributed algorithms for computing equilibria of MCSs were available. Brewka and Eiter (2007)
encoded equilibria into HEX-programs (Eiter, Ianni, Schindlauer, & Tompits, 2005), which can be
evaluated using the dlvhex solver. However, while this approach elegantly offers full heterogeneity, it is fully centralized and needs technical assumptions. Roelofsen, Serafini, and Cimatti (2004)
had proposed earlier an algorithm to check satisfiability of homogeneous, monotonic MCS with a
centralized control that accesses contexts in parallel (hence is not truly distributed). Bikakis and
Antoniou (2010) instead gave a distributed algorithm for their defeasible multi-context systems;
however, the latter have homogeneous (possibly nonmonotonic) contexts with a particular type of
semantics, and the algorithm serves query answering but not model building.
The lack of distributed algorithms for evaluating MCSs based on local context handlers is due
to several obstacles:
• The abstract view of local semantics as belief sets limits for an algorithm at the global level
interference with the knowledge bases and the evaluation process at each context.
• Towards real life applications, certain levels of information hiding and security are required
(e.g. for information exchange between knowledge bases of companies) such that only selected
information is transferred between contexts via well-defined interfaces. This prevents a context
from getting more insight about its neighbors for optimization, for instance to learn conflicts (i.e.,
joint beliefs leading to contradiction) across contexts.
• The MCS system topology, i.e., the structure of context linkage, might be unknown at a context;
this disables decomposing the system for more efficient, modular evaluation.
• The bridge rules might fuel a cyclic information flow through a group of contexts. Even if each
context is easy to evaluate (e.g., all knowledge bases are acyclic logic programs), such global cycles
require nontrivial care.
In this article, we address these obstacles and present results towards efficient distributed evaluation of MCSs. Our main contributions are a suite of generic algorithms DMCS, DMCSOPT, and
DMCS-STREAMING which work truly distributed, and their implementation in a system prototype.
In more detail, the contributions are as follows.
1.1 Algorithms and Optimization Techniques
(1) Our first, basic algorithm DMCS aims at a fully distributed setting and we deal with the obstacles
above in a generic way: contexts just exchange belief sets and the call history (i.e., the access path
traversing bridge rules), but no further information. At the global level, belief states are formed
as tuples of belief sets; each context with bridge rules must respect the belief sets of its neighbors
when computing its own belief sets using a local solver for its knowledge base. Cycles are detected
from the call history, if a context gets a request and finds itself in the call history; to break a cycle,
a guessing technique is used with checks on the return path.
(2) By localizing a context’s knowledge about the system and information exchange, DMCS
can fairly easily adapt to context changes (additions or deletions), but at the same time faces some
scalability issues. To enhance the performance in an optimized version DMCSOPT, we disclose
meta-level information to contexts, viz. (i) the topology of context dependencies, which is exploited
for decomposing the MCS into sub-MCSs (blocks) that are linked in a block-tree, and (ii) the interface between contexts, for optimizing the data transfer between blocks. Here (i) breaks cycles in
545

DAO -T RAN , E ITER , F INK , & K RENNWALLNER

advance and (ii) significantly reduces duplicate local evaluation; each yields a remarkable performance gain.
(3) Still as DMCS and DMCSOPT compute all equilibria of an MCS, they can not escape from
scalability and memory issues, as multiple local belief sets can lead to combinatorial explosion at the
global level. We thus consider computing equilibria in a streaming mode; to this end, contexts pass
their belief sets not in one shot to their parents but gradually in small packages. Memory blowup
can be thus avoided and moreover contexts can continue earlier than when they wait for all answers
from all neighbors. This approach seems more user-friendly as equilibria gradually appear rather
than all at once, possibly after long time; and one may quit the computation after seeing sufficiently
many results (i.e., equilibria).
1.2 Implementation and Experiments
We have implemented the algorithms in a system prototype. To assess the effects of the optimization techniques, we have set up a benchmarking system and conducted comprehensive experiments
with MCSs of various topologies and interlinking. The results confirm our expectation of the optimization techniques in general; in a nutshell, (i) the decomposition technique clearly improves the
performance in the non-streaming mode; (ii) streaming is worthwhile as it may still find answers
while non-streaming times out; (iii) for streaming, choosing the package size is very important;
(iv) the system topology is important as some optimization techniques show drastic improvements
for specific topologies; (v) sometimes, the techniques yield no gain but incur overhead.
The results of this work provide not only truly distributed algorithms for evaluating MCSs, but
through this also for distributed versions of non-monotonic knowledge base formalisms as such
(e.g., for distributed answer set programs), and the underlying principles and techniques might be
exploited in related contexts. Furthermore, they may provide a basis for the evaluation of extensions and generalizations of MCSs, such as non-ground MCSs (Fink, Ghionna, & Weinzierl, 2011),
managed MCSs (Brewka, Eiter, Fink, & Weinzierl, 2011), supported MCS (Tasharrofi & Ternovska,
2014), or reactive MCSs (Goncalves, Knorr, & Leite, 2014; Brewka, Ellmauthaler, & Pührer, 2014).
1.3 Organization
The remainder of this article is organized as follows. The next section provides preliminaries on
Multi-context Systems. Section 3 introduces the basic distributed algorithm DMCS, while Section 4 develops the optimized algorithm DMCSOPT; Section 5 presents then the streaming algorithm DMCS-STREAMING. Experimental results of the prototype implementation are reported in
Section 6. In Section 7, we consider related works, and in Section 8 we summarize and address
further and open issues. To increase readability, proofs have been moved to the Appendix.

2. Preliminaries
This sections briefly introduces the preliminaries needed for the rest of the article.
2.1 Multi-context Systems
First, we present the formalization of Heterogeneous Nonmonotonic Multi-context Systems (MCSs)
proposed by Brewka and Eiter (2007) and further described by Brewka, Eiter, and Fink (2011),
546

D ISTRIBUTED E VALUATION OF N ONMONOTONIC M ULTI - CONTEXT S YSTEMS

which serves as the base of this work. The idea behind MCSs is to allow different logics to be used
in different contexts, and to model information flow among contexts via bridge rules. The notion of
logic is defined as follows.
Definition 1 (cf. Brewka & Eiter, 2007) A logic L = (KBL , BSL , ACCL ) is composed of the
following components:
1. KBL is the set of well-formed knowledge bases of L, each of which consists of a set of
elements called formulas;
2. BSL is the set of possible belief sets, where each S ∈ BSL is a set of elements called beliefs;
and
3. ACCL : KBL → 2BSL is a function describing the “semantics” of the logic, by assigning
to each element of KBL a set of acceptable sets of beliefs.
This notion of logic is very generic, and it abstracts the formation of an agent’s beliefs to a bare
minimum. Structure of formulas (both in the knowledge base and the belief sets) is dismissed, and
they are viewed as “naked elements.” Likewise no particular inference mechanism is associated
with a knowledge base, nor are any logical properties imposed on belief sets; the term “belief”
reflects that statements held by the agent might be on an epistemic basis, without going into further
detail. The assignment of acceptable beliefs sets to a knowledge base, each of which is intuitively a
set of beliefs that an agent is willing to adopt given the knowledge base, captures that in some logics
(e.g., in nonmonotonic logics) multiple or even no acceptable belief sets are possible.
This abstract model allows us to capture a range of different logics for knowledge representation
and reasoning, including classical logic, modal logics, epistemic logics, spatial logics, description
logics etc, but also nonmonotonic logics such as default logic (Reiter, 1980) or answer set programs
(Gelfond & Lifschitz, 1991), in different varieties and settings. A comparison to other formalisms
is given by Brewka et al. (2011). For example, classical (propositional or predicate logic) may be
modeled as follows:
• KB: the set of (well-formed) sentences over a signature Σ,
• BS: the set of deductively closed sets S of Σ-sentences, (i.e., Cn(S) = S, where Cn(·)
denotes deductive closure),
• ACC(kb): the singleton containing the deductive closure of kb, i.e., ACC(kb) = {Cn(kb)}.
For an example of nonmonotonic logics, (disjunctive) logic programs under answer set semantics (Gelfond & Lifschitz, 1991) can be modeled by
• KB: the set of logic programs over a signature Σ,
• BS: the set of consistent sets of literals over Σ,
• ACC(kb): the set AS (kb) of answer sets of kb according to Gelfond and Lifschitz (1991).3
We refer to this setting, which will be used repeatedly in the sequel, as Answer Set Programming
(ASP). Note that the answer sets of a knowledge base kb amount to particular 3-valued models of kb;
intuitively, if a positive literal p is in an answer set S, then p is known to be true, and if a negative
3. As common, we exclude inconsistent answer sets admitted by Gelfond and Lifschitz (1991).

547

DAO -T RAN , E ITER , F INK , & K RENNWALLNER

literal ¬p is in S, then p is known to be false, where “known” means that the literal is present as a
fact or derivable from rules; if neither p nor ¬p is in S, then the truth value of p is unknown. The
above MCS modeling is a possible worlds (scenarios) view via answer sets, which can be generated
by an answer set solver. However, ASP and its implementations also capture inference (truth of a
query in some respectively all answer sets) and further forms of belief set formation.
Bridge rules. Based on logics, bridge rules are introduced to provide a uniform way of interlinking
heterogeneous information sources as follows.
Definition 2 (cf. Brewka & Eiter, 2007) Let L = {L1 , . . . , Ln } be a (multi-)set of logics. An Lk bridge rule over L, 1 ≤ k ≤ n, is of the form
s ← (c1 : p1 ), . . . , (cj : pj ), not (cj+1 : pj+1 ), . . . , not (cm : pm )

(1)

where (i) for each 1 ≤ i ≤ m, ci ∈ {1, . . . , n} and pi is an element of some belief set of Lci , and
(ii) for each kb ∈ KBk , it holds that kb ∪ {s} ∈ KBk .
Informally, bridge rules refer in their bodies to other contexts (identified by ci ) and can thus add
information to a context’s knowledge base depending on what is believed or disbelieved in other
contexts. In contrast to Giunchiglia’s (1992) multi-context systems, there is no single, global set of
bridge rules; each context knows only its own bridge rules.
Now that the means for connecting contexts is available, MCSs can be formally defined.
Definition 3 (Brewka & Eiter, 2007) A multi-context system (MCS) M = (C1 , . . . , Cn ) consists
of a collection of contexts Ci = (Li , kb i , br i ) where Li = (KBi , BSi , ACCi ) is a logic, kb i ∈
KBi is a knowledge base, and br i is a set of Li -bridge rules over {L1 , . . . , Ln }.
Example 2 (cont’d) The scenario from Example 1 can be formalized by an MCS M = (C1 , C2 ),
where in both contexts L1 , L2 are instances of Answer Set Programming, and:


at col (X) ← see col (X).
• kb 1 = F ∪ F1 ∪
∪ R,
¬at col (X) ← ¬see col (X).


at row (X) ← (2 : at row (X)).
• br 1 =
¬at row (X) ∨ covered row (X) ← not (2 : see row (X)), (1 : row (X)).


at row (X) ← see row (X).
• kb 2 = F ∪ F2 ∪
∪ R,
¬at row (X) ← ¬see row (X).


at col (X) ← (1 : at col (X)).
• br 2 =
,
¬at col (X) ∨ covered col (X) ← not (1 : see col (X)), (2 : col (X)).
where
• F = {row (1). row (2). row (3). col (1). col (2). col (3).},
• F1 = {¬see col (2). ¬see col (3).},
• F2 = {see row (1).}, and
548

D ISTRIBUTED E VALUATION OF N ONMONOTONIC M ULTI - CONTEXT S YSTEMS


• R=





joker in ← at row (X).
joker in ← at col (X).

at row (X) ← joker
¬at row (X) ← joker
at col (X) ← joker



¬at col (X) ← joker


∪

in, row (X), not ¬at row (X).
in, row (X), at row (Y ), X 6= Y.
in, col (X), not ¬at col (X).
in, col (X), at col (Y ), X 6= Y.





.




Here, X and Y are variables used in schematic rules, and they range over rows resp. columns (i.e.,
1,2,3). Intuitively, C1 formalizes Batman’s knowledge about the scene and C2 that of Robin. In the
knowledge bases kb 1 and kb 2 , the facts F represent the box of size 3 × 3, while F1 and F2 state
what Batman and Robin see, viz. that Joker is not in columns 2 and 3 respectively that he is on
row 1. The next two rules simply map sensed locations to respective facts. Informally, the rules in
R make a guess on the row and the column where Joker is, if he is concluded to be in the box (first
two rules); this may lead to multiple belief sets. Importantly, Batman adjusts his knowledge base
depending on beliefs communicated by Robin (bridge rules br 1 ) and vice versa (bridge rules br 2 ).
For convenience, we introduce the following notation and conventions. For an MCS M =
(C1 , . . S
. , Cn ), we denote by Bi the set S
of all beliefs that can occur in belief sets of context Ci , i.e.,
Bi = S∈BSi S, and we let BM = ni=1 Bi (simply B, if M is understood). Without loss of
generality, we assume that for distinct contexts Ci and Cj , Bi ∩ Bj = ∅, and that for any bridge
atom of the form (i : bi ) appearing in any bridge rule in M , it holds that bi ∈ Bi .
2.2 Semantics of Multi-context Systems
The semantics of an MCS is defined in terms of special belief states, which are sequences S =
(S1 , . . . , Sn ) such that each Si is an element of BSi . Intuitively, Si should be a belief set of the
knowledge base kb i ; however, also the bridge rules must be respected. To this end, kb i is augmented
with the conclusions of its bridge rules that are applicable. More precisely, a bridge rule r of form (1)
is applicable in S, if pi ∈ Sci , for 1 ≤ i ≤ j, and pk ∈
/ Sck , for j + 1 ≤ k ≤ m. We denote by
head (r) the head of r, and by app(R, S) the set of bridge rules r ∈ R that are applicable in S.
Then,
Definition 4 (Brewka & Eiter, 2007) A belief state S = (S1 , . . . , Sn ) of an MCS M = (C1 , . . . ,
Cn ) is an equilibrium, if Si ∈ ACCi (kb i ∪ {head (r) | r ∈ app(br i , S)}), for all 1 ≤ i ≤ n.
An equilibrium thus is a belief state which contains for each context an acceptable belief set,
given the belief sets of the other contexts.
Example 3 (cont’d) The MCS M in Example 2 has the single equilibrium S = (S1 , S2 ) where
S1 = F ∪ F1 ∪ F3 and S2 = F ∪ F2 ∪ F3 where F3 = {joker in, at row (1), ¬at row (2),
¬at row (3), at col (1), ¬at col (2), ¬at col (3)}. This equilibrium indeed reflects the intuition in
the scenario in Example 1, where Batman and Robin together can infer the location of Joker, while
any single one of them cannot accomplish this task without communication.
Example 4 Let M = (C1 , C2 , C3 , C4 ) be an MCS such that all Li are ASP logics, with signatures
Σ1 = {a}, Σ2 = {b}, Σ3 = {c, d, e}, and Σ4 = {f, g}. Suppose
• kb 1 = ∅, br 1 = {a ← (2 : b), (3 : c)};
549

DAO -T RAN , E ITER , F INK , & K RENNWALLNER

• kb 2 = ∅, br 2 = {b ← (4 : g)};
• kb 3 = {c ← d; d ← c}, br 3 = {c ∨ e ← not (4 : f )};
• kb 4 = {f ∨ g ←}, br 4 = ∅.
One can check that S = ({a}, {b}, {c, d}, {g}) is an equilibrium of M .
The computation of equilibria for a given MCS has been realized by a declarative implementation using HEX-programs (Eiter et al., 2005) which can be evaluated using the dlvhex system.4
The idea is to translate an MCS into a HEX-program with (i) disjunctive facts for guessing the
truth values of beliefs, (ii) HEX-rules for capturing bridge rules, and (iii) constraints with external
atoms for capturing the acceptability functions. For further details on a concrete implementation
of this approach, we refer the reader to the MCS-IE system (Bögl, Eiter, Fink, & Schüller, 2010).
In this article, we pursue a more sophisticated approach, i.e., we design and implement distributed
algorithms, to compute equilibria of MCSs. During evaluation, there is no centralized component
that controls the communication between contexts. Each context independently runs an instance of
the algorithm and communicates with each other to exchange beliefs as well as to detect and break
cycles. These novel contributions are described in the next sections.

3. Basic Algorithm (DMCS)
This section introduces a very first, basic, truly distributed algorithm for evaluating equilibria of
an MCS. The algorithm takes a general setting as input, that is, each context has only minimal
knowledge about the whole system; or in other words, it just knows the interface with direct neighbors (parents and child contexts) but not the topological information or any further metadata of the
system. Under this setting, we concentrate on distributeness. Section 4 shifts the focus towards
optimization techniques when more metadata is provided.
Taking a local stance, we consider a context Ck and compute those parts of (potential) equilibria
of the system which contain coherent information from all contexts that are “reachable” from Ck .
3.1 Basic Notions
We start with some basic concepts. The import closure formally captures reachability.
Definition 5 (Import Closure) Let M = (C1 , . . . , Cn ) be an MCS. The import neighborhood of
context Ck , k ∈ {1, . . . , n}, is the set
In(k) = {ci | (ci : pi ) ∈ B(r), r ∈ br k }.
Furthermore, the import closure IC (k) of Ck is the smallest set S such that (i) k ∈ S and (ii) for
all i ∈ S, In(i) ⊆ S.
Equivalently, we can define the import closure constructively by IC (k) = {k} ∪
S
where IC 0 (k) = In(k), and IC j+1 (k) = i∈IC j (k) In(i).

S

j≥0 IC

j

(k),

Example 5 Consider M in Example 4. Then In(1) = {2, 3}, In(2) = In(3) = {4}, and In(4) =
∅; the import closure of C1 is IC (1) = {1, 2, 3, 4} (see Figure 2).
4. www.kr.tuwien.ac.at/research/systems/dlvhex/

550

D ISTRIBUTED E VALUATION OF N ONMONOTONIC M ULTI - CONTEXT S YSTEMS

C1

C1

IC (1)

In(1)
C2

C2

C3

C3

C4

C4
(a) Import neighborhood of C1

(b) Import closure of C1

Figure 2: Import neighborhood and Import closure
S=

S1

...



...



...

Sj

...

Sn

T =



...



...

Ti

...

Tj

...

Tn

S ./ T =

S1

...



...

Ti

...

Sj (= Tj )

...

Figure 3: Joining partial belief states
Based on the import closure we define partial equilibria.
Definition
6 (Partial Belief States and Equilibria) Let M = (C1 , . . . , Cn ) be an MCS, and let
Sn
∈
/ i=1 BSi . Then a sequence S = (S1 , . . . , Sn ) such that Si ∈ BSi ∪ {}, for all 1 ≤ i ≤ n, is
a partial belief state (PBS) of M , and S is a partial equilibrium (PE) of M w.r.t. Ck , k ∈ {1, . . . , n},
if i ∈ IC (k) implies Si ∈ ACCi (kb i ∪ {head (r) | r ∈ app(br i , S)}), and i 6∈ IC (k) implies
Si = , for all 1 ≤ i ≤ n.
Note that IC (k) essentially defines a subsystem M 0 of M that is connected by bridge rules. We use
PEs of M instead of equilibria of M 0 to keep the original MCS M intact.
For combining partial belief states S = (S1 , . . . , Sn ) and T = (T1 , . . . , Tn ), we define their
join S ./ T as the partial belief state (U1 , . . . , Un ) such that

Si , if Ti =  or Si = Ti ,
Ui =
, for all 1 ≤ i ≤ n
Ti , if Ti 6=  and Si = ,
(see Figure 3). Note that S ./ T is void, if some couples Si , Ti are from BSi but different. Naturally,
the join of two sets S and T of partial belief states is then S ./ T = {S ./ T | S ∈ S, T ∈ T }.
Example 6 Consider two sets of partial belief states:
S = { (, {b}, , {¬f, g}) , (, {¬b}, , {f, ¬g}) } and
T = {(, , {¬c, ¬d, e}, {¬f, g}), (, , {c, d, ¬e}, {¬f, g}), (, , {¬c, ¬d, ¬e}, {f, ¬g})} .
551

DAO -T RAN , E ITER , F INK , & K RENNWALLNER

Their join is given by

S ./ T =

(, {b}, {¬c, ¬d, e}, {¬f, g}), (, {b}, {c, d, ¬e}, {¬f, g}),
(, {¬b}, {¬c, ¬d, ¬e}, {f, ¬g})


.

3.2 The Basic Algorithm
Given an MCS M and a starting context Ck , we aim at finding all PEs of M w.r.t. Ck in a distributed
way. To this end, we design an algorithm DMCS whose instances run independently at a node for
each context and communicate with each other for exchanging sets of partial belief states. This
provides a method for distributed model building, and the DMCS algorithm can be applied to any
MCS provided that appropriate solvers for the respective context logics are available. As a main
feature of DMCS, it can also compute projected partial equilibria, i.e., PEs projected to a relevant
part of the beliefs showing up in Ck ’s import closure. This can be exploited for specific tasks
like, e.g., local query answering or consistency checking. When computing projected PEs, the
information communicated between contexts is minimized, keeping communication cost low.
In the sequel, we present a basic version of the algorithm, abstracting from low-level implementation issues; the overall MCS structure is assumed to be unknown at context nodes. The idea is as
follows: starting from context Ck , we visit its import closure by expanding the import neighborhood
at each context Ci like in a depth-first search (DFS), until a leaf context is reached or a cycle is detected, by finding the current context in the set hist of already visited contexts. A leaf context simply
computes its local belief sets, transforms them into partial belief states, and returns this result to its
parent (invoking context, Figure 4a). In case of a cycle (Figure 4c), the context Ci which detects the
cycle must also break it, by (i) guessing belief sets for its “export” interface, (ii) transforming the
guesses into partial belief states, and (iii) returning them to the invoking context.
An intermediate context Ci produces partial belief states that will be joined, i.e., consistently
combined, with partial belief states of its neighbors; to enable this, Ci returns its local belief sets,
joined with the results of its own neighbors (Figure 4b).
For computing projected PEs, the algorithm offers a parameter V called the relevant interface
which must fulfill some conditions w.r.t. import closure that we next discuss.
Notation. Given a (partial) belief state S and set V ⊆ B of beliefs, we denote by S|V the restriction
of S to V, i.e., the (partial) belief state S 0 = (S1 |V , . . . , Sn |V ), where Si |V = Si ∩ V if Si 6= , and
|V = ; for a set S of (partial) belief states, we let S|V = {S|V | S ∈ S}. Next,
Definition 7 (Recursive Import Interface) For an MCS M = (C1 , . . . , Cn ) and k ∈ {1, . . . , n},
we call V(k) = {pi | (ci : pi ) ∈ B(r), r ∈ brk } the import interface of context Ck and V ∗(k) =
S
i∈IC (k) V(i) the recursive import interface of context Ck .
For a correct relevant interface V, we have two extremal cases: (1) V = V ∗(k) and (2) V = VB = B.
In (1), DMCS basically checks for consistency on the import closure of Ck by computing PEs
projected to interface beliefs. In (2), it computes PEs w.r.t. Ck . In between, by providing a fixed
interface V, problem-specific knowledge (such as query variables) and/or infrastructure information
can be exploited to keep computations focused on relevant projections of partial belief states.
The projections of partial belief states are cached in every context such that recomputation and
recombination of belief states with local belief sets are kept at a minimum.
We assume that each context Ck has a background process (or daemon in Unix terminology)
that waits for incoming requests of the form (V, hist), upon which it starts the computation outlined
552

D ISTRIBUTED E VALUATION OF N ONMONOTONIC M ULTI - CONTEXT S YSTEMS

Si =

S

S∈S` ./Sj

lsolve(S)

(V, hist)

})
{i
∪

(V, hist)

Sj

S

`

Ci

C`

(V

,h

is
t

S

Cj

C`
lsolve((, . . . , )) = S
(a) Leaf context

(b) Intermediate context

V
Ci

hi

st

=

{.
.

.,

i,

Cj

..

.}

C`
Ct
(c) Cycle breaking

Figure 4: Basic distributed algorithm - casewise
in Algorithm 1. This process also serves the purpose of keeping the cache c(k) persistent. We
write Ci .DMCS(V, hist) to specify that we send (V, hist) to the process at context Ci and wait for
its return message.
Algorithm 1 uses the following primitives:
• function lsolve(S) (Algorithm 2): augments the knowledge base kb of the current context
with the heads of bridge rules in br that are applicable w.r.t. partial belief state S, computes
local belief sets using function ACC, combines each local belief set with S, and returns the
resulting set of partial belief states; and
• function guess(V, Ck ): guesses all possible truth assignments for the relevant interface w.r.t.
Ck , i.e., for Bk ∩ V.5
DMCS proceeds in the following way:

(a) check the cache for an appropriate partial belief state;
5. In order to relate beliefs in Bk , V can either be a vector of sets, or variables in V are prefixed with context ids; for
simplicity, we kept V as a set without further assumptions.

553

DAO -T RAN , E ITER , F INK , & K RENNWALLNER

Algorithm 1: DMCS(V, hist) at Ck = (Lk , kb k , br k )
Input: V: relevant interface, hist: visited contexts
Data: c(k): static cache
Output: set of accumulated partial belief states
(a)

if c(k) is not empty then return c(k)
S := ∅

(b)
(c)

(d)

if k ∈ hist then
S := guess(V, Ck )
else
T := {(, . . . , )} and hist := hist ∪ {k}
foreach i ∈ In(k) do
if for some T ∈ T , Ti =  then
T := T ./ Ci .DMCS(V, hist)

(e)

foreach T ∈ T do S := S ∪ lsolve(T )

(f)

c(k) := S|V

// cyclic: guess local beliefs w.r.t. V
// acyclic: collect neighbor beliefs and add local ones

return S|V
Algorithm 2: lsolve(S) at Ck = (Lk , kb k , br k )
Input: S: partial belief state S = (S1 , . . . , Sn )
Output: set of locally acceptable partial belief states
T := ACCk (kb k ∪ {head (r) | r ∈ app(brk , S)})
return {(S1 , , . . . , Sk−1 , Tk , Sk+1 , . . . , Sn ) | Tk ∈ T}

(b) check for a cycle;
(c) if a cycle is detected, then guess partial belief states of the relevant interface of the context
running DMCS;
(d) if no cycle is detected, but import from neighbor contexts is needed, then request partial belief
states from all neighbors and join them;
(e) compute local belief states given the partial belief states collected from neighbors;
(f) cache the current (projected) partial belief state.
The next examples illustrate evaluation runs of DMCS for finding all partial equilibria with
different MCS. We start with an acyclic run.
Example 7 Reconsider M from Example 4. Suppose the user invokes C1 .DMCS(V, ∅), where
V = {a, b, c, f, g}, to trigger the evaluation process. Next, C1 forwards in (d) requests to C2
and C3 , which both call C4 . When called for the first time, C4 calculates in (e) its own belief sets
and assembles the set of partial belief states
S4 = {(, , , {f, ¬g}), (, , , {¬f, g})} .
554

D ISTRIBUTED E VALUATION OF N ONMONOTONIC M ULTI - CONTEXT S YSTEMS

V

c(1) : S1
C1
S10 |V

S 2 |V

c(3) : S3

c(2) : S2
C2

C3
S 3 |V

Figure 5: A cyclic topology
After caching S4 |V in (f), C4 returns S4 |V = S4 to one of the contexts C2 , C3 whose request arrived
first. On second call, C4 simply returns S4 |V to the other context from the cache.
C2 and C3 next call lsolve (in (e)) two times each, which results in S2 = S resp. S3 = T with
S, T from Example 6.
S = { (, {b}, , {¬f, g}) , (, {¬b}, , {f, ¬g}) } and
T = {(, , {¬c, ¬d, e}, {¬f, g}), (, , {c, d, ¬e}, {¬f, g}), (, , {¬c, ¬d, ¬e}, {f, ¬g})} .
Thus,
S2 |V

= { (, {b}, , {¬f, g}) , (, {¬b}, , {f, ¬g}) } and

S3 |V

= {(, , {¬c}, {¬f, g}), (, , {c}, {¬f, g}), (, , {¬c}, {f, ¬g})} .

C1 , after computing in (d)
S2 |V ./ S3 |V = {(, {b}, {¬c}, {¬f, g}), (, {b}, {c}, {¬f, g}), (, {¬b}, {¬c}, {f, ¬g})}
calls lsolve in (e) thrice to compute the final result:
S1 |V = {({a}, {b}, {c}, {¬f, g}), ({¬a}, {b}, {¬c}, {¬f, g}), ({¬a}, {¬b}, {¬c}, {f, ¬g})} .
The next example illustrates the run of DMCS on a cyclic topology.
Example 8 Let M = (C1 , C2 , C3 ) be an MCS such that each Li is an ASP logic, and
• kb 1 = ∅, br 1 = {a ← not (2 : b)};
• kb 2 = ∅, br 2 = {b ← (3 : c)}; and
• kb 3 = ∅, br 3 = {c ∨ d ← not (1 : a)}.
Figure 5 shows the cyclic topology of M . Suppose that the user sends a request to C1 by calling C1 .DMCS(V, ∅) with V = {a, b, c}. In step (d) of Algorithm 1, C1 calls C2 .DMCS(V, {1}),
then context C2 issues a call C3 .DMCS(V, {1, 2}), thus C3 invokes C1 .DMCS(V, {1, 2, 3}). At
this point, the instance of DMCS at C1 detects a cycle in (b) and guesses the partial belief states
S10 = {({a}, , ), ({¬a}, , )}
555

DAO -T RAN , E ITER , F INK , & K RENNWALLNER

for Σ1 ∩ V. Then, following the dotted lines in Figure 5, the set S10 |V = S10 is the return value for
the request from C3 , which joins it with an initial empty belief state (, , ), gives us T and then
calls lsolve(T ) for each T ∈ T in (e), resulting in
S3 = {({¬a}, , {c, ¬d}), ({¬a}, , {¬c, d}), ({a}, , {¬c, ¬d})} .
The next step of C3 is to return S3 |V back to C2 , which will proceed as C3 before. The result is
the set of belief states
S2 = {({¬a}, {b}, {c}), ({¬a}, {¬b}, {c}), ({a}, {¬b}, {¬c})} ,
which will be sent back to C1 as S2 |V . Notice that belief state ({¬a}, {¬b}, {c}) is inconsistent in
C1 , but will be eventually eliminated once C1 evaluates S2 |V with lsolve.
Next, C1 will join S2 |V with (, , ), which yields S2 |V , and then use this result to call lsolve.
The union gives us
S1 = {({¬a}, {b}, {c}), ({a}, {¬b}, {¬c})} ,
which is also sent back to the user as final result.
Given an MCS M = (C1 , . . . , Cn ) and a context Ck , using the recursive import interface of Ck ,
i.e., V ∗(k), as the relevant interface is a safe (lower) bound for the correctness of Algorithm 1. In
what follows, let M , Ck , and V ∗(k) as above.
Theorem 1 (Correctness of DMCS with partial equilibrium) For every V ⊇ V ∗(k), it holds that
S 0 ∈ Ck .DMCS(V, ∅) iff M has some partial equilibrium S w.r.t. Ck such that S 0 = S|V .
We can compute partial equilibria at Ck if we use VB . This holds because using VB preserves
all belief sets returned from step (e), as the projection at step (f) takes no effect.
Corollary 2 S is a partial equilibrium of M w.r.t. Ck iff S ∈ Ck .DMCS(VB , ∅).
Under the assumption that M has a single root context C1 , i.e., such that i ∈ IC (1) for all
2 ≤ i ≤ n, DMCS computes equilibria.
Corollary 3 If an MCS M has a single root context C1 , then S is an equilibrium of M iff S ∈
C1 .DMCS(VB , ∅).
An analysis of the algorithm yields the following upper bound on the computational complexity
and communication activity.
Proposition 4 Let M = (C1 , . . . , Cn ) be an MCS. In each run of DMCS at a context Ck with an
interface V, it holds that
(1) the total number of calls to lsolve is exponentially bound by n × |V|, i.e., O(2n×|V| ).
(2) the number of messages exchanged between contexts Ci , where i ∈ IC (k), is bounded by
2 · |E(k)|, where E(k) = {(i, cj ) | i ∈ IC (k), r ∈ bri , (cj : pj ) ∈ B(r)}.
556

D ISTRIBUTED E VALUATION OF N ONMONOTONIC M ULTI - CONTEXT S YSTEMS

3.3 Discussion
Algorithm DMCS naturally proceeds “forward” in the import direction of context Ck . Thus, starting
from there, it computes partial equilibria which cover Ck and contexts in its import closure. All
other contexts will be ignored; in fact, they are unknown to all contexts in the closure. While partial
equilibria may exist for Ck and its import closure, the whole MCS could have no equilibrium,
because, e.g., (P1) contexts that access beliefs from Ck or its closure get inconsistent, or (P2) an
isolated context or subsystem is inconsistent.
Enhancements of DMCS may deal with such situations: As for (P1), the context neighborhood
may include both importing and supporting contexts. Intuitively, if Ci imports from Cj , then Ci
must register to Cj . By carefully adapting DMCS, we can then solve (P1). However, (P2) remains;
this needs knowledge about the global system topology.
A suitable assumption is that a manager M exists which every context Ci in the system can
reach and ask whether some isolated inconsistent context or subsystem exists; if M confirms this,
Ci ’s DMCS instance simply returns ∅, eliminating all partial equilibria.
To improve decentralization and information hiding, we can weaken the manager assumption by
introducing routers. Instead of asking M, a context Ci queries an assigned router R, which collects
topology information needed by Ci or looks up a cache. The information exchange between Ci and
R is flexible, depending on the system setting, and could contain contexts that import information
from Ci , or isolated and inconsistent contexts.
A further advantage of topological information is that Ci can recognize cyclic and acyclic
branches upfront; the invocation order of the neighborhood can then be optimized, by starting with
all acyclic branches before entering cyclic subsystems. The caching mechanism can be adapted
for acyclic branches, as intermediate results are complete and the cache is meaningful even across
different evaluation sessions.
In our setting, we are safe assuming that V ∗(k) ⊆ V. But this is not needed if M resp. Ck ’s
import closure has no join-contexts, i.e., contexts having at least two parents. If we have access
to path information in M at each context, we could calculate V on the fly and adjust it during
MCS traversal. In particular, for a tree- or ring-shaped M , we can restrict V to the locally shared
interface between Ck and its import neighbors, i.e., restricting V to the bridge atoms of br k . In
presence of join-contexts, V must be made “big enough,” e.g. using path information. Furthermore,
join-contexts may be eliminated by virtually splitting them, if orthogonal parts of the contexts are
accessed. This way, scalability to many contexts can be achieved.
Next, we present optimization techniques using topological information of the system.

4. Topology-Based Optimization Algorithm (DMCSOPT)
As a basic version, Algorithm DMCS uses no further metadata apart from the minimal information
that each context must know: its interface with every neighboring context. There are scalability
issues which can be tracked down to the following problems:
(1) contexts are unaware of context dependencies in the system beyond their neighbors, and thus
treat all neighbors equally. Specifically, cyclic dependencies remain undetected until a context,
seeing the invocation chain, requests models from a context in the chain. Furthermore, a context
Ci does not know whether a neighbor Cj already requested models from another neighbor Cj 0
which then would be passed to Ci ; hence, Ci makes possibly a superfluous request to Cj 0 .
557

DAO -T RAN , E ITER , F INK , & K RENNWALLNER

(2) a context Ci returns its local models combined with the results from all its neighbors. In case of
multiple models, the result size can become huge as the system size and number of neighbors
increases. In fact, this is one of the main performance obstacles.
In this section we address optimizations to increase the scalability of distributed MCS evaluation. Resorting to methods from graph theory, we aim at decomposing, pruning, and improved
cycle breaking for dependencies in MCSs. Focusing on (1), we describe a decomposition method
using biconnected components of inter-context dependencies. Based on it we can break cycles and
prune acyclic parts ahead and create an acyclic query plan. To address (2), we foster a partial view
of the system, which is often sufficient for a satisfactory answer, as a compromise between partial
information and performance. We thus define a set of variables for each import dependency in the
system to project the models in each context to a bare minimum such that they remain meaningful.
In this manner, we can omit needless information and circumvent excessive model combinations.
We proceed as follows. After introducing a running example and a superficial explanation of
optimization on it, we present the details of the techniques in Section 4.2. Section 4.3 introduces
the notion of query plans, which is used in Section 4.4 to describe the algorithm DMCSOPT that
intertwines decomposition and pruning with variable projection for performance gains in MCS evaluation.
4.1 Running Scenario
We first present a scenario in Example 9 as a running example for this section.
Example 9 (Scientists Group) A group of four scientists, Alice, Bob, Charlie, and Demi meets
after a conference closing to arrange travel back home. The options are going by train or by car
(which is slower); if they use the train, they should bring along some food. Alice as the group
leader finally decides, based on the information she gets from Bob and Charlie.6
Alice prefers to go by car, but she would not object if Bob and Charlie want to go by train.
Charlie has a daughter, Fiona; he does not mind either option, but if Fiona is sick he wants the
fastest transport to get home. Demi just got married, and her husband, Eddie, wants her to be back
soon, and even sooner if she would come soon; Demi tries to yield to her husband’s plea.
Charlie is in charge of buying provisions if they go by train. He might choose either salad or
peanuts; notably, Alice is allergic to nuts. The options for beverages are coke and juice. Bob is
modest; he agrees to any choice of Charlie and Demi for transport but he dislikes coke. Charlie
and Demi do not want to bother the others with their personal matters and just communicate their
preferences, which is sufficient for reaching an agreement.

Example 10 The scenario in Example 9 can be encoded as an MCS M = (C1 , . . . , C6 ), where
Alice = 1, Bob = 2, etc in lexicographical order and all Li are ASP logics. The knowledge bases kbi
and bridge rules bri are as follows:




car 1 ← not train 1 .
train 1 ← (2 : train 2 ), (3 : train 3 ).
C1 : kb 1 =
and br 1 =
;
⊥ ← nuts 1 .
nuts 1 ← (3 : peanuts 3 ).
6. Similar scenarios have already been investigated in the realm of multi-agent systems (on social answer set programming see, e.g., Buccafurri & Caminiti, 2008). We do not aim at introducing a new semantics for such scenarios; our
example serves as a plain MCS showcase for the algorithms.

558

D ISTRIBUTED E VALUATION OF N ONMONOTONIC M ULTI - CONTEXT S YSTEMS

B1

1
2

1
2

3
4

3
4
5

4

B2

6

3

4

B3
3
6

5
(b) Diamond-ring block tree

(a) Diamond-ring

Figure 6: Topologies and decomposition of the scientist group example

C2 : kb 2

C3 : kb 3

C4 : kb 4
C5 : kb 5
C6 : kb 6



 car 2 ← (3 : car 3 ), (4 : car 4 ). 
= {⊥ ← not car 2 , not train 2 .} and br 2 = train 2 ← (3 : train 3 ), (4 : train 4 ), ;


not (3 : coke 3 ).


car 3 ∨ train 3 . ←








train 3 ← urgent 3 .
urgent 3 ← (6 : sick 6 ).
=
;
and br 3 =
salad 3 ∨ peanuts 3 ← train 3 . 
train 3 ← (4 : train 4 )





coke 3 ∨ juice 3 ← train 3

	

	
= car 4 ∨ train 4 ← and br 4 = train 4 ← (5 : sooner 5 ) ;

	

	
= sooner 5 ← soon 5 and br 5 = soon 5 ← (4 : train 4 ) ;

	
= sick 6 ∨ fit 6 ← and br 6 = ∅.

The context dependencies of M are shown in Fig. 6a. M has three equilibria, namely:
• ({train 1 }, {train 2 }, {train 3 , urgent 3 , juice 3 , salad 3 }, {train 4 },
{soon 5 , sooner 5 }, {sick 6 });
• ({train 1 }, {train 2 }, {train 3 , juice 3 , salad 3 }, {train 4 }, {soon 5 , sooner 5 }, {fit 6 }); and
• ({car 1 }, {car 2 }, {car 3 }, {car 4 }, ∅, {fit 6 }).
Example 11 Consider an MCS M = (C1 , . . . , C7 ) with context dependencies as drawn in Figure 7a. When the user queries C1 and just cares about the local belief sets in C1 , then in the
evaluation process, C4 can discard all local belief sets of C5 and C6 when answering to a call from
C2 or C3 . However, when C1 calls C2 (or C3 ), the invoked context must carry local belief sets of
C4 in its answers to C1 . The reason is that belief sets of C4 can cause inconsistent joins at C1 for
partial belief states returned from C2 and C3 , while those of C5 to C7 contribute only directly to
computing local belief sets at C4 . Note that belief sets of C4 to C7 play no role in determining the
applicability of bridge rules in C1 .
559

DAO -T RAN , E ITER , F INK , & K RENNWALLNER

query

query
C1
C2

C1
C3

C2

C4

C4

,S

C7
(a) Original Topology

C3

C7

(, , S3 )
(b) Triangle

C6

)

C2

C5

3

(

,S

2,

,

C6

S3

)

C1

(

C5

C3

(c) Transitive Reduction

Figure 7: Topology of Example 11 (two stacked zig-zag diamonds)
Now, take a sub-system including C1 , C2 , and C3 , assuming that C1 has bridge rules with atoms
(2 : p2 ) and (3 : p3 ) in the body, and C2 with atoms (3 : p3 ). That is, C1 depends on both C2 and
C3 , while C2 depends on C3 (see Fig. 7b). A straightforward approach to evaluate this MCS asks
at C1 for the belief sets of C2 and C3 . But as C2 also depends on C3 , we would need another query
from C2 to C3 to evaluate C2 w.r.t. the belief sets of C3 . This shows evident redundancy, as C3 will
need to compute its belief sets twice. Simple caching strategies could mellow out the second belief
state building at C3 ; nonetheless, when C1 asks C3 , the context will transmit its belief states back,
thus consuming network resources.
Moreover, when C2 asks for the PEs of C3 , it will receive a set of PEs that covers the belief sets
of C3 and in addition of all contexts in C3 ’s import closure. This is excessive from C1 ’s view, as it
only needs to know about (2 : p2 ) and (3 : p3 ). However, C1 needs the belief states of both C2 and
C3 in reply of C2 : if C2 only reports its own belief sets (which are consistent w.r.t. C3 ), C1 can’t
align the belief sets received from C2 with those received from C3 . Realizing that C2 also reports
the belief sets of C3 , no call to C3 must be made.
4.2 Decomposition of Nonmonotonic MCS
Based on the observations above, we present an optimization strategy that pursues two orthogonal
goals: (i) to prune dependencies in an MCS and cut superfluous transmissions, belief state building,
and joining of belief states; and (ii) to minimize content in transmissions. We start with defining the
topology of an MCS.
Definition 8 (Topology) The topology of an MCS M = (C1 , . . . , Cn ) is the directed graph GM =
(V, E), where V = {C1 , . . . , Cn } resp. V = {1, . . . , n} and (i, j) ∈ E iff some rule in br i has an
atom (j:p) in the body.
The first optimization technique is made up of three graph operations. We get a coarse view of the
topology by splitting it into biconnected components, which form a tree representation of the MCS.
Then, edge removal techniques yield acyclic structures.
560

D ISTRIBUTED E VALUATION OF N ONMONOTONIC M ULTI - CONTEXT S YSTEMS

In the sequel, we will use standard terminology from graph theory (see Bondy & Murty, 2008);
graphs are directed by default. We may view undirected graphs as directed graphs that have both
edges (u, v), (v, u) for an undirected edge {u, v}.
For any graph G and edges S ⊆ E(G), we denote by G\S the maximal subgraph of G having
no edges from S. Suppose that V 0 ⊆ V (G) is nonempty. Then the subgraph G0 = (V 0 , E 0 ) of G
with vertex set V 0 and edge set E = {(u, v) ∈ E(G) | u, v ∈ V (G)} is the subgraph induced by
V 0 , denoted by G[V 0 ]. The induced subgraph G[V \ V 0 ] is denoted by G\V 0 ; it results from G by
deleting the vertices in V 0 together with their incident edges. If V 0 = {v}, we write G\v for G\{v}.
Two vertices u and v of G are said to be connected, if there is a (directed) path from u to v
in G, i.e., a sequence of vertices u = v1 , v2 , . . . , vn = v, such that (vi , vi+1 ) ∈ E(G), for each i =
1, . . . , n−1; the path is trivial if n = 1. For an undirected graph G, connectedness is an equivalence
relation on V (G). Thus there is a partition of V (G) into nonempty subsets V1 , V2 , . . . , Vw such
that two vertices u and v of G are connected iff both of them belong to the same set Vi . The
subgraphs G[V1 ], G[V2 ], . . . , G[Vw ] are called the components of G. If w = 1 (i.e., G has exactly
one component), then G is connected; otherwise, G is disconnected.
A directed graph G is strongly connected, if for each vertices u, v ∈ V (G) a path from u to v
and vice versa exists. The strongly connected components of G are the subgraphs G[V1 ], . . . , G[Vm ]
in the unique partition of the graph G into pairwise disjoint induced subgraphs (i.e., Vi ∩ Vj = ∅)
that are strongly connected.
Furthermore, a directed graph G is weakly connected, if turning all edges into undirected edges
yields a connected graph. A vertex c of a weakly connected graph G is a cut vertex, if G\c is
disconnected. A biconnected graph is a weakly connected graph without cut vertices.
A block in a graph G is a maximal
biconnected
subgraph of G. Given a set of blocks B, the
S
S
union of blocks in B is defined as B = B∈B B, where the union of two graphs G1 = (V1 , E1 )
and G2 = (V2 , E2 ) is defined as G1 ∪ G2 = (V1 ∪ V2 , E1 ∪ E2 ).
Let T (G) = (B ∪ C, E) denote the undirected bipartite graph, called block tree of graph G,
where
(i) B is the set of blocks of G,
(ii) C is the set of cut vertices of G,
(iii) and (B, c) ∈ E with B ∈ B and c ∈ C iff c ∈ V (B).
Note that T (G) is a forest for any graph G and a rooted tree if G is weakly connected.
Example 12 Consider the graph in Figure 7a. One can check that 4 is the only cut vertex and there
are two blocks, viz. the subgraphs induced by {1, 2, 3, 4} and {4, 5, 6, 7}.
The next example shows the block tree of our scenario in Example 9.
Example 13 The topology GM of M in Example 10 is shown in Figure 6a. It has two cut vertices,
namely 3 and 4; thus the block tree T (GM ) (Figure 6b) contains the blocks B1 , B2 , and B3 , which
are subgraphs of GM induced by {1, 2, 3, 4}, {4, 5}, and {3, 6}, respectively.
A topological sort of a directed graph is a linear ordering of its vertices such that for every
directed edge (u, v) from vertex u to vertex v, u comes before v in the ordering.
561

DAO -T RAN , E ITER , F INK , & K RENNWALLNER

Pruning. In acyclic topologies, like the triangle presented in Figure 7b, we can exploit a minimal
graph representation to avoid unnecessary calls between contexts, namely, the transitive reduction
of the graph GM . Recall from Aho, Garey, and Ullman (1972) that a graph G− is a transitive
reduction of the directed graph G whenever the following two conditions are satisfied:
(i) there is a directed path from vertex u to vertex v in G− iff there is a directed path from u to v
in G, and
(ii) there is no graph with fewer edges than G− satisfying condition (i).
Note that G− is unique if G is acyclic. For instance, the graph in Figure 7c is the unique transitive
reduction of the one in Figure 7a.
Ear decomposition Another essential part of our optimization strategy is to break cycles by removing edges. To this end, we use ear decompositions of cyclic graphs. A block may have multiple
cycles that are not necessarily strongly connected; thus we first decompose blocks into their strongly
connected components. Using Tarjan’s algorithm (Tarjan, 1972) for this task, one gets as a byproduct a topological sort on the directed acyclic graph formed by the strongly connected components.
This yield a sequence of nodes r1 , . . . , rs that are used as entry points to each component. The next
step is to break cycles.
An ear decomposition of a strongly connected graph G rooted at a node r is a sequence P =
hP0 , . . . , Pm i of subgraphs of G such that
(i) G = P0 ∪ · · · ∪ Pm ,
(ii) P0 is a simple cycle (i.e., has no repeated edges or vertices) with r ∈ V (P0 ), and
(iii) each Pi (i > 0) is a non-trivial path (without cycles) whose endpoint ti is in P0 ∪ · · · ∪ Pi−1 ,
but the other nodes are not.
Let cb(G, P ) be the set of edges containing (`0 , r) of P0 and the last edge (`i , ti ) of each Pi , i > 0.
Here, `0 is the vertex belonging to the edge to the root node r in the simple cycle P0 .
Example 14 Take, as an example, a strongly connected graph G in Figure 8a. An ear decomposition of G rooted at node 1 is P = hP0 , P1 , P2 , P3 i where
VP0 = {1, 2, 3}, EP0 = {(1, 2), (2, 3), (3, 1)},

VP1 = {2, 4, 3}, EP1 = {(2, 4), (4, 3)},

VP2 = {2, 5, 3}, EP2 = {(2, 5), (5, 3)},

VP3 = {1, 4}, EP4 = {(1, 4)}.

The last edges of Pi are dashed. They form the set cb(G, P ) = {(3, 1), (4, 3), (5, 3), (1, 4)}.
Removing these edges results in an acyclic topology as in Figure 8b.
Intuitively, ear decomposition is used to remove cycles from the original system M . On the
resulting acyclic topology, algorithms for evaluating MCSs can be designed more conveniently.
The trade off is that for any edge (`, t) removed from M , context C` , despite being now a leaf
context, has to guess values for variables from Ct . The following example shows the application of
the optimization techniques above to our running scenario.
Example 15 (cont’d) Block B1 of T (GM ) is acyclic, and the transitive reduction gives B1− with
edges {(1, 2), (2, 3), (3, 4)}. B2 is cyclic, and hB2 i is the only ear decomposition rooted at 4;
removing cb(B2 , hB2 i) = {(5, 4)}, we obtain B20 with edges {(4, 5)}. B3 is acyclic and already
reduced. Fig. 6b shows the final result (dotted edges are removed).
562

D ISTRIBUTED E VALUATION OF N ONMONOTONIC M ULTI - CONTEXT S YSTEMS

1

2

1

3

2

3

4

4

5

5

(a) A strongly connected component

(b) Acyclic topology

Figure 8: Ear decomposition example
The graph-theoretic concepts introduced here, in particular the transitive reduction of acyclic blocks
and the ear decomposition of cyclic blocks, are used to implement the first optimization of MCS
evaluation outlined above. Intuitively, in each block, we apply ear decomposition to get rid of cycles (with the trade-off of guessing), and then use transitive reduction to minimize communication.
Given the transitive reduction B − of an acyclic block B ∈ B, and a total order on V (B − ) , one
can evaluate the respective contexts in the reverse order of this total order for computing PEs at
some context Ck : the first context simply computes its local belief sets which—represented as a
set of partial belief states S0 —constitutes an initial set of partial belief states T0 . In each iteration
step i ≥ 1, Ti is computed by joining Ti−1 with the local belief sets Si of the considered context Ci .
Given the final Tk , we have that Tk |V ∗(k) is the set of PEs at Ck (restricted to contexts in V (B − )).
Refined recursive import. Next, we define the second part of our optimization strategy which
handles minimization of information needed for transmission between two neighboring contexts
Ci and Cj . For this purpose, we refine the notion of recursive import interface (Definition 7) in a
context w.r.t. a particular neighbor and a given (sub-)graph.
Definition 9 Given an MCS M = (C1 , . . . , Cn ) and a subgraph G of GM , for S
an edge (i, j) ∈
∗
∗
E(G), the recursive import interface of Ci to Cj w.r.t. G is V (i, j)G = V (i) ∩ `∈G|j B` where
G|j contains all nodes in G reachable from j.7
Example 16 (cont’d) For the MCS in Example 10, we have V ∗ (1) = {train 2 , train 3 , peanuts 3 ,
car 3 , coke 3 , car 4 , train 4 , sooner 5 , sick 6 }. When we focus on block B1 , the refined recursive
import interface V ∗ (1, 2)B − can be obtained by removing bridge atoms from contexts in the other
1
blocks B2 and B3 , yielding {train 2 , train 3 , peanuts 3 , car 3 , coke 3 , car 4 , train 4 }.
Algorithms. Algorithms 3 and 4 combine the optimization techniques outlined above. Intuitively,
OptimizeTree takes as input a block tree T with ‘parent cut vertex’ cp and ‘root cut vertex’ cr . It traverses T in DFS manner and calls OptimizeBlock on every block. The call results are collected in a
7. Note that V ∗ (k) is defined in Definition 7.

563

DAO -T RAN , E ITER , F INK , & K RENNWALLNER

Algorithm 3: OptimizeTree(T = (B ∪ C, E), cp , cr )
Input: T : block tree, cp : identifiesSlevel in T , cr : identifies
level above cp
S
Output: F : removed edges from B, v: labels for ( B)\F
B 0 := ∅, F := ∅, v := ∅
if cp = cr then
B 0 := {B ∈ B | cr ∈ V (B)}
else
B 0 := {B ∈ B | (B, cp ) ∈ E}

(a)

(b)

// initialize siblings B0 and return values

foreach sibling block B ∈ B 0 do
// sibling blocks B of parent cp
E := OptimizeBlock(B, cp )
// prune block
0
C := {c ∈ C | (B, c) ∈ E ∧ c 6= cp }
// children cut vertices of B
B 0 := B\E, F := F ∪ E
foreach edge (i, j) of B 0 doS
// setup interface of pruned B
S
v(i, j) := V ∗(i, j)B 0 ∪ c∈C 0 V ∗(cp )|Bc ∪ (`,t)∈E V ∗(cp )|Bt
foreach child cut vertex c ∈ C 0 do
// accumulate children
(F 0 , v 0 ) := OptimizeTree(T \B, c, cp )
F := F ∪ F 0 , v := v ∪ v 0
return (F, v)

set F of removed edges; after all blocks have been processed, the final result of OptimizeTree is the
pair (F, v) where v is a labeling for the remaining edges. OptimizeBlock takes a graph G and calls
CycleBreaker for cyclic G, which decomposes G into its strongly connected components, creates
an ear decomposition P for each component Gc , and breaks cycles by removing edges cb(Gc , P ).
For the resulting acyclic subgraph of G, OptimizeBlock computes the transitive reduction G− and
returns all edges that have been removed from G. OptimizeTree continues by computing the labeling v for the remaining edges, building on the recursive import interface, but keeping relevant
interface beliefs of child cut vertices and removed edges. Example 20 (Appendix B) illustrates
Algorithms 3 and 4 with a detailed run on the MCS in Example 10.
Formally, the following property holds.
Proposition 5 Given an MCS M and a context Ck such that k is a cut vertex in the topology GM ,
OptimizeTree(T (GM ), k, k) returns a pair (F, v) such that
(i) the subgraph G of GM \F induced by IC (k) is acyclic, and
(ii) in any block B of G and for all (i, j) ∈ E(B), it holds that v(i, j) ⊇ V ∗(i, j)B .
Regarding the computational cost of computation, we obtain:
Proposition 6 Given an MCS M and a context Ck such that k is a cut vertex in the topology GM ,
OptimizeTree(T (GM ), k, k) runs in polynomial (quadratic) time in the size of T (GM ) resp. GM .

564

D ISTRIBUTED E VALUATION OF N ONMONOTONIC M ULTI - CONTEXT S YSTEMS

Algorithm 4: OptimizeBlock(G : graph, r : context id)

(c)
(d)

F := ∅
if G is cyclic then
F := CycleBreaker(G, r)

// ear decomposition of strongly connected components

Let G− be the transitive reduction of G\F
return E(G) \ E(G− )

// removed edges from G

4.3 Query Plan
Given the topology of an MCS, we need to represent a stripped version of it that contains both
the minimal dependencies between contexts and interface beliefs that need to be transferred between contexts. This representation will be a query plan that can be used for execution processing.
Syntactically, query plans have the following form.
Definition 10 (Query Plan) A query plan of an MCS M w.r.t. context Ck is any labeled subgraph
Π of GM induced by IC (k) with E(Π) ⊆ E(GM ), and edge labels v : E(G) → 2Σ .
For any MCS M and context Ck of M , not every query plan is suitable for evaluating M; however,
the following query plan is in fact effective.
Definition 11 (Effective Query Plan) Given an MCS M and a context Ck , the effective query plan
of M with respect to Ck is Πk = (V (G), E(G)\F, v) where G is the subgraph of GM induced by
IC (k) and (F, v) = OptimizeTree(T (GM ), k, k).
We next use Πk for MCS evaluation, and tacitly assume that query plans are effective.
4.4 Evaluation with Query Plans
We now present the algorithm DMCSOPT, which is based on DMCS but exploits the optimization
techniques from above. The idea of DMCSOPT is as follows: we start with context Ck and traverse
a given query plan Πk by expanding the outgoing edges of Πk at each context, like in a DFS, until
a leaf context Ci is reached. The context simply computes its local belief sets, transforms all belief
sets into partial belief states, and returns the result to its parent. If Ci has (j : p) in bridge rules
bodies but context Cj is not in the query plan (this means we broke a cycle by removing the last
edge to Cj ), all possible truth assignments to the import interface to Cj are considered.
The result of any context Ci is a set of partial belief states, which amounts to the join, i.e., the
consistent combination, of its local belief sets with the results of its neighbors; the final result is
obtained from Ck . To keep recomputation and recombination of belief states with local belief sets
at a minimum, partial belief states are cached in every context.
Algorithm 5 shows our distributed algorithm, DMCSOPT, with its instance at context Ck . On
input of the id c of a predecessor context (which the process awaits), it proceeds based on an
(acyclic) query plan Πr w.r.t. context Cr , i.e., the starting context of the system. The algorithm
maintains in cache(k) a cache at Ck (which is kept persistent).
• Ci .DMCSOPT(c): send id c to DMCSOPT at context Ci and wait for its result.
• guess(V): guess all possible truth assignments for the interface beliefs V.
565

DAO -T RAN , E ITER , F INK , & K RENNWALLNER

Algorithm 5: DMCSOPT(c : context id of predecessor) at Ck = (Lk , kb k , br k )
Data: Πr : query plan w.r.t. starting context Cr and label v, cache(k): cache
Output: set of accumulated partial belief states
(a)

(b)
(c)

(d)

(e)

if cache(k) is not empty then
S := cache(k)
else
T := {(, . . . , )}
foreach (k, i) ∈ E(Πr ) do T := T ./ Ci .DMCSOPT(k)

// neighbor belief sets

if there is i ∈ In(k) s.t. (k, i) ∈
/ E(Πr ) and Ti =  for T ∈ T then
T := guess(v(c, k)) ./ T
// guess for removed dependencies in Πr
S := ∅
foreach T ∈ T do S := S ∪ lsolve(T )
// get local beliefs w.r.t. T
cache(k) := S
if (c, k) ∈ E(Πr ) (i.e., Ck is non-root) then
return S|v(c,k)
else
return S

• lsolve(S) (Algorithm 2): given a partial belief state S, augment kbk with all heads from
bridge rules brk applicable w.r.t. S (=: kb0k ), compute local belief sets by ACC(kb0k ), and
merge them with S; return the resulting set of partial belief states.
The steps of Algorithm 5 are explained as follows:
(a)+(b) check the cache, and if it is empty get neighbor contexts from the query plan, request
partial belief states from all neighbors and join them;
(c) if there are (i : p) in the bridge rules brk such that (k, i) ∈
/ E(Πr ), and no neighbor delivered
the belief sets for Ci in step (b) (i.e., Ti = ), we have to call guess on the interface v(c, k)
and join the result with T (intuitively, this happens when edges have been removed from
cycles);
(d) compute local belief states given the partial belief states collected from neighbors; and
(e) return the locally computed belief states and project them to the variables in v(c, k) for nonroot contexts; this is the point where we mask out parts of the belief states that are not needed
in contexts lying in a different block of T (GM ).
Theorem 7 shows that DMCSOPT is sound and complete.
Theorem 7 Let Ck be a context of an MCS M , let Πk be the query plan as in Definition 11 and let
b = {p ∈ v(k, j) | (k, j) ∈ E(Πk )}. Then,
V
(i) for each S 0 ∈ Ck .DMCSOPT(k), there exists a partial equilibrium S of M w.r.t. Ck such
that S 0 = S|Vb ; and
(ii) for each partial equilibrium S of M w.r.t. Ck , there exists an S 0 ∈ Ck .DMCSOPT(k) such
that S 0 = S|Vb .
566

D ISTRIBUTED E VALUATION OF N ONMONOTONIC M ULTI - CONTEXT S YSTEMS

5. Streaming Equilibria (DMCS-STREAMING)
Algorithm DMCSOPT shows substantial improvements over DMCS; however, when the sizes of
the local knowledge bases and the context interfaces increase, it also suffers from bottlenecks.
This stems from the way in which models are exchanged between contexts. Suppose context C1
accesses several neighbors C2 , . . . , Cm under an acyclic information flow, and that each Ci , i ≥ n,
has ni PEs. Before Ci computes in DMCS resp. DMCSOPT any local models, it must join all PEs
from its neighbors; this may lead to n2 × n3 × · · · × nm many PEs, and each of them is an input
to the local solver. This may not only take considerable time but also exhaust memory, even before
local model computation starts.
Note however that if instead each neighbor would transfer just a portion of its PEs, then the
computation at C1 can avoid such a memory blowup. Moreover, this strategy also helps to reduce
inactive running time at C1 while waiting for all neighbors to return all PEs, as C1 can already start
local computing while the neighbors are producing more models.
In general, it is indispensable to trade more computation time, due to recomputations, for less
memory if eventually all partial equilibria at C1 shall be computed. This is the idea underlying a
streaming evaluation method for distributed MCS. It is particularly useful when a user is interested
in obtaining just some instead of all answers from the system, but also for other realistic scenarios
where the current evaluation algorithm does not manage to output under resource constraints in
practice any equilibrium at all.
In this section, we turn this idea into a concrete streaming algorithm DMCS-STREAMING for
computing partial equilibria. Its main features are briefly summarized as follows:
• the algorithm is fully distributed, i.e., instances of its components run at every context and
communicate, thus cooperating at the level of peers;
• when invoked at a context Ci , the algorithm streams (i.e. computes) k ≥ 1 partial equilibria
at Ci at a time; in particular, setting k = 1 allows for consistency checking of the MCS
(sub-)system.
• issuing follow-up invocations one may compute the next k partial equilibria at context C1
until no further equilibria exist; i.e., this evaluation scheme is complete.
• local buffers can be used for storing and exchanging local models (partial belief states) at
contexts, avoiding the space explosion problem.
As this section mainly studies the streaming aspect of the algorithm, we simplify the presentation and omit the interface between contexts. The principles presented here can be applied for
both DMCS and DMCSOPT by adapting the interface and pruning the topology at preprocessing
time. Furthermore, we assume to work with acyclic MCSs. Treatment of cyclic cases can be easily
achieved by adding guessing code to the solving component as in DMCS and DMCSOPT.
To the best of our knowledge, a similar streaming algorithm has neither been developed for
the particular case of computing equilibria of a MCS, nor more generally for computing models of
distributed knowledge bases. Thus, the results obtained here are not only of interest in the setting
of heterogeneous MCS, but they are also relevant in general for model computation and reasoning
over distributed (potentially homogeneous) knowledge bases like e.g. distributed SAT instances.
567

DAO -T RAN , E ITER , F INK , & K RENNWALLNER

request (k1 , k2 )

≤ k belief states

Handler

Ci

Cj1

Solver

Joiner

..
.

Output

Cjm

Figure 9: DMCS-STREAMING architecture
Algorithm 6: Handler(k1 , k2 : package range) at Ci
Output.k1 := k1 , Output.k2 := k2 ,
Solver.k2 := k2 , Joiner.k := k2 − k1 + 1
call Solver

5.1 Basic Streaming Procedure
The basic idea is as follows: each pair of neighboring contexts can communicate in multiple rounds,
and each request has the effect to receive at most k PEs. Each communication window of k PEs
ranges from the k1 -th PE to the k2 -th (= k1 + k − 1) PE. A parent context Ci requests from a child
context Cj a pair (k1 , k2 ) and will receive some time later a package of at most k PEs; receiving 
indicates that Cj has fewer than k1 models. A parallelized version is discussed in Section 5.2.
Important subroutines of the new algorithm DMCS-STREAMING take care of receiving the
requests from parents, receiving and joining answers from neighbors, local solving and returning
results to parents. They are reflected in four components: Handler, Solver, Output, and Joiner
(only active in non-leaf contexts); see Figure 9 for an architectural overview.
All components except Handler (shown in Algorithm 6) communicate using message queues:
Joiner has j queues to store partial equilibria from j neighbors, Solver has one queue to hold joined
PEs from Joiner, and Output has a queue to carry results from Solver. To bound space usage, each
queue has a limit on the number of entries. When a queue is full (resp., empty), the enqueuing writer
(resp., dequeuing reader) is automatically blocked. Furthermore, getting an element also removes
it from the queue, which makes room for other PEs in the queue later. This property frees us from
synchronization technicalities.
Algorithms 7 and 8 show how Solver and Joiner work. They use the following primitives:
• lsolve(S): works as lsolve in DMCS and DMCSOPT, but in addition may return only one
answer at a time and may be able to tell whether there are models left. Moreover, we require that
the results from lsolve are returned in a fixed order, regardless of when it is called. This property is
the key to guarantee the correctness of our algorithm.
• get first(`1 , `2 , k): send to each neighbor from c`1 to c`2 a request for the first k partial equilibria, i.e., k1 = 1 and k2 = k; if they all return some models, store them in the respective queues
and return true; otherwise, return false (some neighbor is inconsistent).
568

D ISTRIBUTED E VALUATION OF N ONMONOTONIC M ULTI - CONTEXT S YSTEMS

Algorithm 7: Solver() at Ci
Data: Input queue: q, maximal number of models: k2

(a)
(b)

count := 0
while count < k2 do
if Ci is a leaf then S := ∅
else call Joiner and pop S from q
if S =  then count := k2

(c)

while count < k2 do
pick the next model S ? from lsolve(S)
if S ? 6=  then
push S ? to Output.q
count := count + 1
else break
refresh() and push  to Output.q

• get next(`, k): request the next k equilibria from neighbor Cc` ; if Cc` sends back some models, store them in the queue q` and return true; otherwise, return false as the neighbor already
exhaustively returned its PEs from the previous request. Note that this subroutine needs to keep
track of which range has been already asked for to what neighbor, by maintaining a set of counters.
A counter w.r.t. a neighbor Cc` is initialized to 0 and increased each time get next(`, k) is called.
When its value is t, the request to Cc` asks for the t’th package of k models, i.e., models in the range
given by k1 = (t − 1) × k + 1 and k2 = t × k. When get first(`1 , `2 , k) is called, all counters in
range [`1 , `2 ] are reset to 0.
• refresh(): reset all counters and flags of Joiner to their starting states, e.g., first join to true,
all counters to 0.
The process at each context Ci is triggered when a message from a parent, which contains the
range (k1 , k2 ) arrives at Handler. The latter notifies Solver to compute up to k2 models and Output
to collect those in the range (k1 , k2 ) and return them to the parent. Furthermore, it sets the package
size at Joiner to k = k2 − k1 + 1 in case Ci needs to query further neighbors (cf. Algorithm 6).
When Solver receives a notification from Handler, it first prepares the input for the local solver.
If Ci is a leaf context, the input S gets the empty set assigned in Step (a); otherwise, Solver triggers
Joiner (Step (b)) for input from neighbors. Fed with input from them, lsolve is used in Step (c) to
compute at most k2 results and send them to the output queue.
The Joiner, which is only activated for intermediate contexts as discussed, gathers partial equilibria from the neighbors in a fixed ordering and stores the joined, consistent input to a local buffer.
It communicates just one input at a time to Solver upon request. The fixed joining order is guaranteed by always asking the first package of k models from all neighbors at the beginning in Step (d).
In subsequent rounds, we begin with finding the first neighbor Cc` that can return further models
(Step (e)), and reset the query to ask for first packs of k models from neighbors from Cc1 to Cc`−1 .
When all neighbors run out of models in Step (f), the joining process ends and sends  to Solver.
Note that while the above procedure guarantees that no models are missed, it can lead to consider the same combinations (inputs to Solver) multiple times. Using a cache helps to mitigate
569

DAO -T RAN , E ITER , F INK , & K RENNWALLNER

Algorithm 8: Joiner() at Ci
Data: Queue q1 , . . . , queue qj for In(i) = {c1 , . . . , cj }, buffer for partial equilibria: buf ,
flag first join
while true do
if buf is not empty then
pop S from buf , push S to Solver.q
return

(d)

(e)

(f)

if first join then
if get first(1, j, k) = false then
push  to Solver.q
return
else first join := false
else
` := 1
while get next(`, k) = false and ` ≤ j do ` := ` + 1
if 1 < ` ≤ j then
get first(1, ` − 1, k)
else if ` > j then
push  to Solver.q
return
for S1 ∈ q1 , . . . , Sj ∈ qj do add S1 ./ · · · ./ Sj to buf
C1

C2

C4

C3

C5

C6

C7

Figure 10: Binary tree MCS

recomputation, but as unlimited buffering again quickly exceeds memory limits, recomputation is
an inevitable part of trading computation time for less memory.
The Output component simply reads from its queue until it receives  or reaches k2 models
(cf. Algorithm 9). Upon reading, it throws away the first k1 − 1 models and only keeps the ones
from k1 onwards. Eventually, if fewer than k1 models have been returned by Solver, then Output
will return  to the parent.
Example 17 Let M = (C1 , . . . , Cn ) be an MCS such that for a given integer m > 0, we have n =
2m+1 − 1 contexts, and let ` > 0 be an integer. Let all contexts in M have ASP logics. For i < 2m ,
570

D ISTRIBUTED E VALUATION OF N ONMONOTONIC M ULTI - CONTEXT S YSTEMS

Algorithm 9: Output() at Ci
Data: Input queue: q, starting model: k1 , end model: k2
buf := ∅ and count := 0
while count < k1 do
pick an S from Output.q
if S =  then count := k2 + 1
else count := count + 1
while count < k2 + 1 do
wait for an S from Output.q
if S =  then count := k2 + 1
else
count := count + 1
add S to buf
if buf is empty then
send  to parent
else
send content of buf to parent

the context Ci = (Li , kbi , bri ) has
(
kbi =

{aji

∨

¬aji

← ti | 1 ≤ j ≤ `} and bri =

)


ti ← (2i : aj2i ),
1≤j≤` ,
ti ← (2i + 1 : aj2i+1 ) 

(2)

and for i ≥ 2m , we let Ci have
kbi = {aji ∨ ¬aji | 1 ≤ j ≤ `} and bri = ∅ .

(3)

Intuitively, M is a binary tree-shaped MCS with depth m and `+1 is the size of the alphabet in each
context. Figure 10 shows such an MCS with n = 7 contexts and depth m = 2; the internal contexts
have knowledge bases and bridge rules as in (2), while the leaf contexts are as in (3). The directed
edges show the dependencies of the bridge rules. Such a system M has equilibria S = (S1 , . . . , Sn )
with Si = {aki , ti }, for 1 ≤ k ≤ `.
To compute one PE of M using DMCS or DMCSOPT, one needs to transfer packages of 2`
PEs from each context to its parent (as each context Ci computes all subsets of {a1i , . . . , a`i }). Each
intermediate context receives 2` results from each of its children, whose join leads to 22` inputs for
lsolve; it invokes lsolve that often and only then returns its 2` models to the parent, which has to
wait for this.
On the other hand, DMCS-STREAMING only needs to transfer a single PE between each pair
of connected contexts, which is a significant saving. Indeed, consider e.g. m = 1, ` = 5, i.e.,
M = (C1 , C2 , C3 ). Querying C1 with package size k = 1 first causes the query to be forwarded to
C2 as a pair k1 = k2 = 1. As C2 is a leaf context, it invokes the local solver and eventually gets five
different models. However, it just returns one PE to C1 , say (, {a12 }, ). Note that t2 is projected
off as it is not among the atoms of C2 accessed by C1 . The same happens at C3 , which we assume
571

DAO -T RAN , E ITER , F INK , & K RENNWALLNER

to return (, , {a23 }) to C1 . At the root context C1 , the two PEs from its neighbors are consistently
combined into (, {a12 }, {a23 }). Feeding this to the local solver, C1 obtains five models, and returns
one of them, say S = ({a11 , t1 }, {a12 }, {a23 }).
The following proposition shows the correctness of our algorithm.
Proposition 8 Let M = (C1 , . . . , Cn ) be an MCS, i ∈ {1, . . . , n} and let k ≥ 1 be an integer. On
input (1, k) to Ci .Handler, Ci .Output returns up to k different partial equilibria with respect to Ci ,
and in fact k if at least k such partial equilibria exist.
5.2 Parallelized Streaming
As one might expect, the strategy of ignoring up to k1 models and then collecting the next k is
not likely to be the most effective. The reason is that each context uses only one Solver, which in
general has to serve more than one parent, i.e., requests for different ranges of models of size k.
When a new parent context requests models, we have to refresh the state of Solver and Joiner and
redo from scratch. This is unavoidable, unless a context satisfies the specific property that only one
parent can call it.
A way to address this problem is parallelization. The idea is to serve each parent with a suite
of Handler, Joiner, Solver and Output. The basic interaction between units is still as shown in
Figure 9, with the notable difference that each component now runs in an individual thread. The
significant change is that Solver does not control Joiner but waits at its queue to get new input
for the local solving process. The Joiner independently queries the neighbors, combines PEs from
neighbors, and puts the results into the Solver queue.
The effect is that we do not waste recomputation time for unused models. However, parallelization has its limits in practice. While DMCSOPT may run out of memory, unlimited parallel
instances of the streaming algorithm can exceed the number of threads/processes that the operating
system can support; this happens if contexts can reach others on many alternative paths, like in the
stacked diamond topology: the number of threads is exponential in the number of connected contexts, which prohibits scaling to large system sizes. However, in real-world applications the number
of paths might still be ok.
A compromise between the two extremes is a bounded parallel algorithm. The idea is to create
a fixed-size pool of multiple threads and components to share among the contexts; when incoming requests cannot be served with the resources available, the algorithm continues with the basic
streaming procedure. A realization remains for future work.

6. Experimental Evaluation
We have implemented the algorithms above using C ++ in a system prototype called DMCS, which
is available online.8 For space reasons, we omit a detailed presentation and refer for it to the work
of Bairakdar, Dao-Tran, Eiter, Fink, and Krennwallner (2010b), Dao-Tran (2014, ch. 7). Briefly,
the main components of the global architecture are (i) a command-line frontend dmcs for the user
to access the system; (ii) demons daemon which represent nodes that contain (a set of) contexts;
and (iii) a manager dmcsm containing meta-information about the MCS (topology, interfaces) with
8. http://www.kr.tuwien.ac.at/research/systems/dmcs,
https://github.com/DistributedMCS/dmcs/

572

D ISTRIBUTED E VALUATION OF N ONMONOTONIC M ULTI - CONTEXT S YSTEMS

C1

C2

C1

C3

C2

C3
C2

C1

C4

C2

C5

C3

C4

C6

C5

C3
C1

C6
C4

C4

C5

C6

C7

(a) Binary Tree (T)

C7

C7

(b) Diamond (D)

(c) Zig-Zag (Z)

C4

(d) Ring (R)

Figure 11: Topologies for testing DMCS algorithms
a helper dmcsgen for generating configurations with optimized components. Contexts are implemented as groups of threads that communicate with each other through concurrent message queues.
The system has two main command-line tools, viz. for running the algorihms and for test case generation, respectively. It allows to switch between different algorithms and modes by simply changing
the command-line arguments.
We now turn to an experimental evaluation of DMCS under various aspects. Next we describe
how the benchmarks were set up, and then we go into runs and results interpretation.
6.1 Benchmark Setup
The idea is to analyze strong and weak points of each algorithm with respect to different parameters,
namely system topology, system size, local theory (i.e., knowledge base) size, and interface size.
Specifically, we considered MCSs with topologies as in Figure 11, including:
Binary Tree (T): Binary trees grow balanced, i.e., every level except the last one is complete.
With this topology, no edge needs to be removed to form the optimal topology; as every
intermediate node is a cut-vertex, the import interface in the query plan is drastically reduced,
leading to an extreme performance improvement.
(Stack of) Diamond(s) (D): a diamond consists of four nodes connecting as C1 to C4 in Figure 11b. A stack of diamonds combines multiple diamonds in a row, i.e., stacking m diamonds
in a tower of 3m + 1 contexts. Similar to Binary Tree, no edge is removed in constructing
the query plan. W.r.t. this topology, every context connecting two diamonds is a cut-vertex.
As such, the import interface in the query plan is refined after every diamond; this avoids
significantly repetition of partial PEs in evaluation.
(Stack of) Zig-Zag Diamond(s) (Z): a zig-zag diamond is a diamond with a connection between
the two middle contexts, as depicted by contexts C2 to C4 in Figure 11c. A stack of zigzag diamonds is built as above. This topology is interesting as after removing two edges per
block, the query plan turns into a linear topology.
Ring (R): ring (Figure 11d). The query plan removes the connection from context Cn to C1 and
then carries the interface between them all the way back to C1 . This topology requires guess573

DAO -T RAN , E ITER , F INK , & K RENNWALLNER

a1

a2

a3

a4

a5

a6

a7

a8

Figure 12: Local theory structure
ing and checking in any DMCS algorithm; thus it is quite unpredictable which algorithm
performs better in general.
The other quantitative parameters are represented as tuple P = (n, s, b, r), where
• n is the system size (number of contexts),
• s is the local theory size (number of ground atoms in a local theory),
• b is the number of local atoms that can be used as bridge atoms in other contexts, in other
words, the number of interface atoms, and
• r is the maximal number of bridge rules. The generator generates a bridge rule while iterating
from 1 to r with 50% chance; hence on average r/2 bridge rules are generated. We allow
bridge bodies of size 1 or 2.
A test configuration is formulated as X/(n, s, b, r) where X ∈ {T, D, Z, R} represents the topology and n, s, b, r are integers representing the quantitative (i.e., size-related) parameters. As we
would like to run several instances over one configuration, the final formulation of a test instance is
Xi /(n, s, b, r), where i is the index of the test instance.
Inside each context, the local theories are structured as follows. Context Ci has s ground atoms
indicated by ai,1 , . . . , ai,s . Rules are of the form ai,j ← not ai,k where k = j + 1, if j is odd;
otherwise, we randomly choose k to be j − 1 or j + 1 with a probability of 50% for each possibility.
In case if k > s then the rule does not exist. An example of a context with local theory size is 8 can
be illustrated with the dependency graph as in Figure 12. Here, the bold arrows stand for the fixed
rules while dashed arrows stands for the rules decided by randomization. The corresponding local
theory of this figure is:


a1 ← not a2
a2 ← not a1

a3 ← not a4
a4 ← not a3

a4 ← not a5
a5 ← not a6

a6 ← not a7
a7 ← not a8


.

With this setting, a local context has 2m answer sets, where m ∈ [0, s/2].
Furthermore, one can obtain deterministic contexts (having just one answer set) by disallowing
cycles in the structure of local theories.
6.2 Experiments
We conducted the experiments on a host system using 4-core Intel(R) Xeon(R) CPU 3.0GHz processor with 16GB RAM, running Ubuntu Linux 12.04.1. Furthermore, we used DLV [build BEN/Sep
28 2011 gcc 4.3.3] as a back-end ASP solver.
We ran a comprehensive set of benchmarks under the setup described in Section 6.1. As the
parameter space P = (n, s, b, r) is huge, we singled out in an initial probing phase the following
values for the experiments:
574

D ISTRIBUTED E VALUATION OF N ONMONOTONIC M ULTI - CONTEXT S YSTEMS

1000

DMCS
DMCSOPT

100

10

1

0.1

0.01
-5

T7,10,5,5
0

5

D7,10,5,5
10

Z7,10,5,5
15

R7,10,5,5
20

T10,10,5,5
25

D10,10,5,5
30

35

Z10,10,5,5
40

R10,10,5,5
45

50

Figure 13: DMCS vs. DMCSOPT in non-streaming mode
• for the system size n, depending on the topology:
T:
D:

n ∈ {7, 10, 15, 31, 70, 100}
n ∈ {4, 7, 10, 13, 25, 31}

Z:
R:

n ∈ {4, 7, 10, 13, 25, 31, 70}
n ∈ {4, 7, 10, 13, 70}

• s, b, r are fixed to either 10, 5, 5 or 20, 10, 10, respectively.
A combination of topology X and parameters P = (n, s, b, r) is denoted by X(n, s, b, r) or X n,s,b,r
(used in figures). Each parameter setting has been tested on five instances. For each instance,
we measured the total running time and the total number of returned partial equilibria on DMCS,
DMCSOPT in non-streaming and streaming mode. For the latter mode, DMCS-STREAMING, we
asked for k answers, where k ∈ {1, 10, 100}. This parameter also influences the size of packages
transferred between contexts (at most k partial equilibria are transferred in one message). As in
streaming mode, asking for more than one PE may require multiple rounds to get all answers, it is
of interest to see how fast the first answers arrive compared to having all answers. We thus compared
the running time of these tasks for k = 10 and k = 100.
6.3 Observations and Interpretations
Figures 13-17 summarize the results of our experiments. Run times are in seconds and timeout
is 600 seconds. From these data, several interesting properties can be observed. We organize
our analysis along the following aspects: (1) comparing DMCS and DMCSOPT, (2) comparing
streaming and non-streaming mode, (3) effect of the package size, (4) role of the topologies, and
(5) the behavior of the algorithms on deterministic contexts.
6.3.1 DMCS VS . DMCSOPT
Figure 13 shows the running time of DMCS and DMCSOPT for computing all partial equilibria, i.e.,
in non-streaming mode, of five instances of the respective parameter settings. Clearly DMCSOPT
outperforms DMCS. This can be explained by the fact that when computing all answers, DMCS
always produces more partial equilibria than DMCSOPT, as one PE returned by DMCSOPT can
575

DAO -T RAN , E ITER , F INK , & K RENNWALLNER

100

100
DMCS-1st
DMCSOPT-1st
DMCS-10
DMCSOPT-10

DMCS-1st
DMCSOPT-1st
DMCS-100
DMCSOPT-100

10

10

1

1

0.1

T1

T2

T3

T4

T5

D1

(a) T (25, 10, 5, 5)

D2

D3

D4

D5

(b) D(10, 10, 5, 5)

1000

100
DMCS-1st
DMCSOPT-1st
DMCS-10
DMCSOPT-10

DMCS-1st
DMCSOPT-1st
DMCS-10
DMCSOPT-10

100

10

10

1

1

0.1

0.1

Z1

Z2

Z3

Z4

Z5

R1

(c) Z(10, 10, 5, 5)

R2

R3

R4

R5

(d) R(4, 10, 5, 5)

Figure 14: DMCS vs. DMCSOPT in streaming mode
be obtained from projecting many partial equilibria returned by DMCS on the imported interface.
Furthermore, all intermediate results are transferred in one message, which makes no difference
in terms of the number of communications between the algorithms. As such, DMCS must spend
more time on processing possibly exponentially more input; hence, unsurprisingly, it is consistently
slower than DMCSOPT.
However, the observation in streaming mode is different. Figure 14 shows the running time of
DMCS and DMCSOPT in streaming mode to compute the first 100 respectively 10 unique partial
equilibria for T (25, 10, 5, 5) respectively D(10, 10, 5, 5), Z(10, 10, 5, 5) and R(4, 10, 5, 5). On a
first view, as DMCSOPT is consistently slower than DMCS, one might question the correctness of
the results. However, they are not a surprise: again a PE returned by DMCSOPT should correspond to several PEs returned by DMCS. Hence, the batch of the first k unique answers in DMCS
corresponds to only a smaller number of (few) unique answers in DMCSOPT.
Therefore, comparing DMCS and DMCSOPT in streaming mode by measuring the runtime to
compute the first k answers is not fair. We thus took the time when both algorithms finished the first
round of answers (denoted by DMCS-1st and DMCSOPT-1st in Figure 14). With this setting, we
observed the following:
• on the majority of cases DMCSOPT finishes the first round faster than DMCS, however in
about 40% of the instances, it is the other way around; this shows the effect of using the query plan;
576

D ISTRIBUTED E VALUATION OF N ONMONOTONIC M ULTI - CONTEXT S YSTEMS

• however, in some cases DMCS wins. This can be explained as follows. First of all, in streaming
mode, we transfer only packages of k partial equilibria at a time; therefore, the effect of reducing the
amount of total work to be done does not always apply as in the non-streaming mode. Furthermore,
at every context, we compute k PEs and project them to the output interface before returning the
results. According to this strategy, when a context Ci returns k1 partial equilibria in non-streaming
mode and k2 partial equilibria in streaming to another context Cj , it might happen that k2 is much
smaller than k1 and hence does not provide enough input for Cj to compute k PEs. Therefore, Cj
will issue more requests to Ci asking for further packages of k PEs, e.g., [k + 1, 2k], [2k + 1, 3k],
etc; and this costs DMCSOPT more time to even compute the first batch of PEs at the root context.
Another approach is to compute always k unique partial equilibria before returning to a parent
context. However, this strategy risks to compute even all local models before k unique partial
equilibria can be found.
Overall, there is not much difference in running time when DMCSOPT is slower than DMCS, except
for instance R3 (Figure 14d). This however comes from a different reason: the cyclic topology with
guess-and-check effects, which play a much more important role than choosing between DMCS and
DMCSOPT (see Section 6.3.4).
6.3.2 S TREAMING VS . N ON - STREAMING DMCS
We now compare streaming and non-streaming for the same algorithm (DMCS resp. DMCSOPT).
Figure 15 shows the results for DMCS in (15a), and the results for DMCSOPT to compute
the first 10 resp. 100 PEs with small systems/local knowledge bases in (15b) and with large systems/local theories in (15c). Excluding Ring (which behaves abnormally due to guess-and-check)
one can see that:
• For DMCS, the streaming mode is definitely worth pursuing since DMCS in non-streaming
mode times out in many cases (see also Figure 13), while in streaming mode we still could find
some answers after a reasonable time.
• For DMCSOPT, the situation is a bit different, as streaming loses against non-streaming on
small instances. This is due to the recomputation that the streaming mode pays for transferring just
chunks of partial equilibria between contexts; furthermore, there are duplications between answers.
When one moves to larger systems and local knowledge bases, the streaming mode starts gaining
back. However, it does not always win, as recomputation still significantly takes time in some cases.
Summing up, when the system is small enough, one should try the non-streaming mode as it
avoids recomputation and duplication of PEs between different rounds of computation. But for large
systems, streaming can rescue us from timing out. Even if we have to pay for recomputation, it still
helps in cases when some but not all results are needed, e.g. in brave query answering (membership
of the query in some PE).
6.3.3 E FFECTS OF THE PACKAGE S IZE IN S TREAMING M ODE
The considerations above raise the question of the optimal number of PEs that should be transferred
in return messages between contexts. We will analyze the experimental results on the streaming
mode with package sizes 1, 10, and 100 to give some hints on this.
Figure 16 shows the average time to compute 1 PE of DMCSOPT in streaming mode with
respect to three package sizes. One can see that transferring just a single PE to get the first answer
577

DAO -T RAN , E ITER , F INK , & K RENNWALLNER

1000

Non-Streaming
Streaming-10
Streaming-100

100

10

1

0.1

0.01
-5

T10,10,5,5

0

5

D10,10,5,5
10

15

Z10,10,5,5

20

R4,10,5,5
25

30

(a) DMCS
1000

Non-Streaming
Streaming-10
Streaming-100

100

10

1

0.1

0.01
-5

T10,10,5,5

0

5

D10,10,5,5
10

15

Z10,10,5,5

20

R4,10,5,5
25

30

(b) DMCSOPT with small systems and local theories
1000

Non-Streaming
Streaming-10
Streaming-100

100

10

1

0.1

0.01
-5

0

T31,20,10,10

5

D10,20,10,10
10

15

Z10,20,10,10

20

R4,20,10,10
25

30

(c) DMCSOPT with large systems and local theories

Figure 15: Non-streaming vs. streaming under DMCS and DMCSOPT
is acceptable in most cases, in particular if no guessing is needed. Moving from size 1 to a small
package size like 10 here is sometimes better, as one can save communication time (sending once
a package of 10 partial equilibria vs. sending ten times a package with a single PE). This setting
(small package sizes like 10) will be more effective when communication is a big factor, which
578

D ISTRIBUTED E VALUATION OF N ONMONOTONIC M ULTI - CONTEXT S YSTEMS

1000

Streaming-1
Streaming-10
Streaming-100

100
10
1
0.1
0.01
0.001
-5

0

T100,20,10,10

5

D25,20,10,10

10

Z70,20,10,10
15

R4,20,10,10
20

25

Figure 16: Average time of DMCSOPT to find one partial equilibrium in streaming mode, varying
package size
happens in real applications where contexts are located at physically distributed nodes. In such
cases, computing 10 partial equilibria should be faster than computing 1 PE in 10 consecutive times.
Furthermore, having package of size 1 is not safe in cases where guessing is applied, e.g., in
R3 (4, 20, 10, 10). For these cases, a large enough package size might help to cover the correct
guess; but in general, there is no guarantee for such a coverage. To thoroughly solve this problem,
one needs to apply conflict learning on the whole MCS evaluation.
Also, it is interesting to see that with package size 100, DMCSOPT usually times out. The
reason is that there are many duplications and once DMCSOPT is stuck with a local search branch
that promises fewer than 100 partial equilibria, the algorithm will lose time here without finding
new unique answers and will eventually time out.
To find a good package size p with a specific setting (topology, system size, local theory size),
one may run the system on a training set and apply binary search on p.
6.3.4 E FFECT OF T OPOLOGY
A quick glance over all plots in Figures 13–16 reveals the pattern that the algorithms, especially
the optimizations, perform better on tree than on zigzag and diamond, depending on DMCS or
DMCSOPT, and worst on ring.
The system topology plays an important role here. The aspects that affect the performance of
the algorithms are (i) number of connections, (ii) the structure of block trees and cut vertices, and
(iii) acyclicity vs. cyclicity.
Regarding (i), the topology introduces the number of connections based on the system size. Tree
has fewer connections than Diamond and Zigzag, which reduces not only communication but also
local solving time as fewer requests are made; and the performance of DMCS on these topologies
proves this observation. If one follows this argument, then Ring must offer the best performance.
However, this is actually not the case due to aspect (iii) that we will shortly analyze below.
Concerning (ii), tree can be ultimately optimized as every intermediate node is a cut vertex.
Hence, when applying the query plan for DMCSOPT, we can strip off all beliefs in PEs sent from
child contexts to a parent context. In other words, only local beliefs at a context Ci are needed
to be transferred back to its parents. This drastically decreases the amount of information to be
579

DAO -T RAN , E ITER , F INK , & K RENNWALLNER

1000
DMCS-100
DMCSOPT-100

100

10

1
-2

0

R4,10,5,5
2

4

6

R7,10,5,5
8

10

12

R4,20,10,10
14

16

18

Figure 17: DMCS vs. DMCSOPT in streaming mode with package size 100 on ring
communicated, and more importantly, the number of calls to lsolve. Due to this special property,
DMCSOPT performs extremely well on the tree topology, and scales to hundreds of contexts.
Comparing Diamond and Zigzag, they have the same number of cut vertices. However, Zigzag
is converted to a linear topology with an optimal query plan (cf. Figure 11c), and therefore can be
processed much faster than Diamond. In Figure 16, DMCSOPT scales on Zigzag to 70 contexts with
an average time to compute one answer that still better than the one on diamond with 25 contexts.
Regarding (iii), Ring is a cyclic topology while the other topologies are acyclic. Hence each
of the algorithms must do some guess-and-check at some context in the topology. Making the
right guess is most important, even more important than reducing communication and calls to local
solvers. The result of running DMCS and DMCSOPT on this topology (Figure 17) does not follow
any pattern; it absolutely depends on a specific instance whether the above sequential guessing
luckily arrives at the result. Therefore, we frequently see that DMCS outperforms DMCSOPT in
streaming mode, as in such cases, guessing at the root context (after detecting the cycle) is more
effective than guessing at the parent of the root context according to the optimal query plan.
Based on these observations, one can come up with a best strategy to evaluate different types of
topologies. When dealing with MCSs of arbitrary topologies, it looks natural to decompose them
into parts of familiar topologies for which efficient strategies are known, and to combine then these
strategies to an overall evaluation method. Studying this is beyond the scope of this work and an
interesting issue for future research.
6.3.5 B EHAVIOR ON D ETERMINISTIC C ONTEXTS
Above we considered our algorithms on MCSs consisting of possibly non-deterministic contexts,
i.e., they can have more than one acceptable belief set per knowledge base. It is intriguing to see how
the algorithms behave if all contexts always have exactly one accepted belief set per knowledge base;
this might be because the underlying logic is genuinely “deterministic” and the accepted belief set
clear (e.g., closure in classical logic) or among multiple candidates a particular belief set is chosen
(in implementations typically the first or a “best” solution computed, e.g. in SAT solving or in ASP).
We observed that:
• for non-cyclic topologies, there is no performance difference between DMCS and DMCSOPT,
because the smaller interface used in DMCSOPT does not reduce the number of intermediate PEs
transferred between contexts, as there is only one partial equilibrium computed at every context.
580

D ISTRIBUTED E VALUATION OF N ONMONOTONIC M ULTI - CONTEXT S YSTEMS

1000

DMCS
DMCSOPT
MCS-IE

100

10

1

0.1

0.01
-5

T7,10,5,5
0

5

D7,10,5,5
10

Z7,10,5,5
15

R7,10,5,5
20

T10,10,5,5
25

D10,10,5,5
30

35

Z10,10,5,5
40

R10,10,5,5
45

50

Figure 18: DMCS vs. DMCSOPT in streaming mode with package size 100 on ring
• for cyclic topology (Ring), guessing plays the main role. Hence it depends on the individual
instance whether DMCS or DMCSOPT wins, like in the case of non-deterministic contexts (cf.
Section 6.3.4).
• non-streaming mode is much faster than streaming (on both DMCS and DMCSOPT); this is
reasonable as any request for further partial equilibria is redundant.
6.3.6 C OMPARISON WITH MCS-IE AND P2P-DR
Systems close to DMCS are MCS-IE (Bögl et al., 2010)9 and P2P-DR (Bikakis, Antoniou, & Hassapis, 2011). The former is a plugin of the dlvhex system and was originally developed to compute
explanations for inconsistency in Multi-context Systems, but also includes a mode for computing
equilibria of an MCS. However, MCS-IE was implemented with a centralized approach. Figure 18
presents the run time of DMCS, DMCSOPT in comparison with MCS-IE in computing all partial equilibria of the respective configurations. It shows that MCS-IE outperforms DMCS since it
inherits a powerful decomposition technique from dlvhex; however, the decomposition based on
topological information of DMCSOPT turns out to be more efficient, as it also localizes the interface beliefs to communicate between blocks of contexts, which is specific for MCS and is not
exploited by the general decomposition technique in dlvhex.
P2P-DR supports distributed query answering for multi-context systems based on defeasible
logic; for more details, see Section 7. We present here a comparison between DMCS and P2P-DR.
We converted our benchmark to P2P-DR’s style by converting the local knowledge bases and
bridge rules to defeasible local and meta rules, and added a fixed trust order between contexts. We
then queried the root context with an atom appearing in one of the answers of DMCS-STREAMING
with package size 10. It turned out that P2P-DR always found the answers in around 0.25 seconds,
regardless of the tested instance. This behavior can be explained as follows. To find answers for a
query atom, the algorithm of P2P-DR first evaluates the local theory. If it can determine the truth
value of the query, it terminates; otherwise the algorithm consults neighbors to get further evidence
for the reasoning. As our local knowledge base structure, when converted to P2P-DR’s defeasible
theories, allows for a local decision, the system works only on the local theory of the root context
9. http://www.kr.tuwien.ac.at/research/systems/mcsie/tut/

581

DAO -T RAN , E ITER , F INK , & K RENNWALLNER

for every test case, thus results in almost constant execution time. Even when asking neighbours is
necessary, P2P-DR in general may be much faster than DMCS, as the query answering process is
inherently deterministic and in a low-complexity logic; in turn, the formalism is less expressive. A
detailed study of this issue remains for future work.
6.3.7 S UMMARY
Summing up, the analysis of the experimental results shows that there is no clear winner among the
algorithms (DMCS vs. DMCSOPT) under different running modes (streaming vs. non-streaming,
with different package size) on different topologies. We can distill from it a guideline to choose the
setup that fits specific instances in practice, including some issues open for further investigation,
which can be briefly stated as follows:
• choose DMCSOPT over DMCS in non-streaming mode, except for cyclic topologies;
• in streaming mode, choose an appropriate package size carefully (e.g., doing a binary search
on some training instances;
• decompose random topologies into parts whose topologies have effective strategies to evaluate,
and study how to combine the strategies for the over all systems.

7. Related Work
In this section, we resume the discussion of related work. Starting with multi-context systems, we
provide more details on the work by Roelofsen et al. (2004), Bikakis et al. (2011) and consider other
work. We then move to related formalisms in SAT, CSP and ASP.
Roelofsen et al. (2004) described evaluation of monotone MCS with classical theories using
SAT solvers for the contexts in parallel. They used a (co-inductive) fixpoint strategy to check MCS
satisfiability, where a centralized process iteratively combines results of the SAT solvers. Apart
from being not truly distributed, an extension to nonmonotonic MCS is non-obvious; furthermore,
no caching technique was used.
Serafini, Borgida, and Tamilin (2005) and Serafini and Tamilin (2005) developed distributed
tableaux algorithms for reasoning in distributed ontologies, which can be regarded as multi-context
systems with special bridge rules. The algorithms serve to decide whether such a system is consistent, provided no cyclic context dependencies exist (in technical terms, the distributed TBox is
acyclic); the DRAGO system (Serafini & Tamilin, 2005) implements this approach for OWL ontologies. Compared to ours, this work is tailored for a specific class of multi-context systems resp.
knowledge bases, without nonmonotonic negation and cyclic dependencies (which are challenging); furthermore, it targets query answering rather than model building, which in a sense is a dual
problem.
More related to our work as regards distributed evaluation is the the system P2P-DR of Bikakis
et al. (2011). They developed a distributed algorithm for query evaluation in a multi-context system
framework that is specifically based on (propositional) defeasible logic. In this framework, contexts are built using defeasible rules and can exchange literals via bridge rules, and a trust order
between contexts is be supplied. Each knowledge base at a context has, in our terminology, a single
accepted belief set which contains the literals concluded; the global system semantics is given in
terms of a (unique) three-valued assignment to all literals, which can be determined using the algorithm: whether literal l is provably (not) a logical conclusion of the system, or whether this remains
582

D ISTRIBUTED E VALUATION OF N ONMONOTONIC M ULTI - CONTEXT S YSTEMS

open. Apart from being tailored to a particular logic and preference mechanisms for evaluating interlinked contexts, applying this algorithm to model building is not straightforward; in particular, as
it produces unique belief sets, dealing with nondeterminism and multiple equilibria is not possible.
Our work on computing equilibria for distributed multi-context systems is clearly related to
work on solving constraint satisfaction problems (CSP) and SAT solving in a distributed setting;
Yokoo and Hirayama (2000) survey some algorithms for distributed CSP solving, which are usually developed for a setting where each node (agent) holds exactly one variable, the constraints
are binary, communication is done via messages, and every node holds constraints in which it is
involved. This is also adopted by later works (Gao, Sun, & Zhang, 2007) but can be generalized
(Yokoo & Hirayama, 2000). In relation to the topology-based optimization techniques in Section 4,
biconnected components are used by Baget and Tognetti (2001) to decompose CSP problems. The
decomposition is used to localize the computation of a single solution in the components of undirected constraint graphs. Along the same lines, our approach is based on directed dependencies,
which allows us to use a query plan for MCS evaluation.
The predominant solution methods in CSP are backtracking algorithms. Bessiere, Bouyakhf,
Mechqrane, and Wahbi (2011) took them a step further with backtracking on a dynamic total ordering between agents guided by nogoods. Our approach, however, allows for cyclic dependency
between contexts. Hirayama and Yokoo (2005) presented a suite of algorithms for solving distributed SAT (DisSAT), based on a random assignment and improvement flips to reduce conflicts.
However, these algorithms are geared towards finding a single model, and an extension to streaming
multiple (or all) models is not straightforward; for other works on distributed CSP and SAT, this is
similar.
Finally, (distributed) SAT and CSP solving concerns monotonic systems (removal of clauses
resp. constraints preserves satisfiability), while MCSs evaluation concerns nonmonotonic systems,
even if all contexts were monotonic (e.g., clause sets); this makes efficient evaluation more difficult,
as important structural properties of the search space cannot be exploited.
Adjiman, Chatalic, Goasdoué, Rousset, and Simon (2006) present a framework of peer-to-peer
inference systems, where local theories of propositional clause sets share atoms and a special algorithm for consequence finding is available. As we pursue the dual problem of model building,
applying it for our needs is not straightforward; furthermore, we are dealing with non-monotonic
systems, while the peer-to-peer systems by Adjiman et al. are monotonic.
Moving to ASP, Pontelli, Son, and Nguyen’s (2011) ASP-PROLOG shares with MCS the idea
of integrating several knowledge bases, called modules, possibly under different semantics. However, they restricted module semantics to ASP and Prolog (that is, the least Herbrand model), and
ASP-PROLOG pursues query answering instead of model building.
As for streaming, an answer set streaming algorithm for HEX-programs (which generalize ASP
with external information access) was given by Eiter, Fink, Ianni, Krennwallner, and Schüller
(2011). Despite some similarities to Algorithm DMCS-STREAMING, it is rather different: monolithic programs are syntactically decomposed into modules and answer sets computed in a modular
fashion; it is not fully distributed and combines partial models from lower components to input for
upper components straightforwardly; moreover, it may use exponential space in components.
583

DAO -T RAN , E ITER , F INK , & K RENNWALLNER

8. Conclusion
We have considered distributed evaluation of Multi-context Systems (MCSs) that were introduced
by Brewka and Eiter (2007) as a general formalism to interlink possibly nonmonotonic and heterogeneous knowledge bases. We have presented a suite of generic algorithms to compute the equilibria, i.e., the semantics of an MCS in a fully distributed manner, using local solvers for the knowledge
bases at the contexts. It contains a basic algorithm DMCS, an advanced version DMCSOPT that
uses topology-based optimizations, and a streaming variant DMCS-STREAMING for computing
partial equilibria gradually. We believe that the underlying principles and techniques might be
exploited in related contexts, and in particular for distributed evaluation of other non-monotonic
knowledge base formalisms.
The algorithms have been implemented in a prototype system that is available as open source.8
On top of this implementation, we have conducted comprehensive experiments to compare the performance of the algorithms and we gave an insight analysis on the results. It points out advantages,
disadvantages as well as the time/memory trade off between the algorithms in different situations
depending on parameters such as system topology, local interface and theory size, and number of
equilibria desired by the user. Based on this, the user can choose the setting (algorithm and mode)
that fits her need best for finding (partial) equilibria of an MCS. A more extensive treatment is given
by Dao-Tran (2014).
Further work and open issues. Several issues remain for further investigation. One is further improvement of the algorithms. Here, the experimental results on the Ring topology strongly suggest
to incorporate conflict learning, which proved to be valuable in ASP and SAT solving, to DMCS
and DMCSOPT; we expect that cyclic topologies will benefit from a better guided guessing process. Another issue concerns further semantics and variants of MCSs. As for the former, grounded
equilibria are considered by Dao-Tran (2014), which are akin to answer sets of logic programs and
applicable to MCSs that satisfy certain algebraic conditions; they can be characterized like answer
sets using an (adapted) loop formula approach (Lee & Lifschitz, 2003). Dealing with supported
equilibria (Tasharrofi & Ternovska, 2014), however, is open.
Regarding MCS variants, managed MCSs (Brewka et al., 2011) generalize bridge rules to derive
operations (commands) for a management function that is applied on the knowledge bases; it seems
possible to generalize our algorithms to this setting, but an efficient realization is not straightforward. Another generalization of MCS concerns dynamic data: in areas like sensor networks, social
networks, or smart city applications, data may change or even continuously arrive at nodes, which
motivates reactive and stream processing for MCSs (Goncalves et al., 2014; Brewka et al., 2014).
Last but not least, allowing contexts to evolve via interation with users or with changes in the environment is a valuable extention. Extending our algorithms to these settings is interesting but
challenging.
Finally, extending this work to query answering over MCSs, where the user poses a query at a
context and receives results derived from (partial) equilibria is another natural issue. As there is no
need for building whole equilibria, better performance may be achieved.

Acknowledgments
This research has been supported by the Austrian Science Fund (FWF) projects P20841 and
P26471.
584

D ISTRIBUTED E VALUATION OF N ONMONOTONIC M ULTI - CONTEXT S YSTEMS

C1000

C1

C2

C2000

C3

C1

C3000

Figure 19: Introducing guess context(s)
We thank to the reviewers for pointing out corrections and their constructive suggestions which
helped to improve the presentation of this work, and we thank Antonis Bikakis for providing us with
the P2P-DR system for the experimental comparison.

Appendix A. Proofs
Proof of Theorem 1
To prove this theorem, we first prove the following Lemmas 9 and 10. The latter aims at simplifying
the proof for the cyclic case, based on the notion of converting cyclic MCSs to acyclic ones.
Lemma 9 For any context Ck and partial belief state S of an MCS M = (C1 , . . . , Cn ),
app(brk , S) = app(brk , S|V ) for all VB ⊇ V ⊇ V ∗(k).
Proof For any r ∈ app(brk , S), we have that for all (ci : pi ) ∈ B + (r) : pi ∈ Sci and for all
(cj : pj ) ∈ B − (r) : pj ∈
/ Scj . We need to show that pi ∈ Sci |Vci ∧ pj ∈
/ Scj |Vcj . Indeed:
We have V ⊆ VB ⇒ Vcj ⊆ VBj ⇒ Scj |Vcj ⊆ Scj . Therefore, pj ∈
/ Scj ⇒ pj ∈
/ Scj |Vcj .
Now, assume that pi ∈
/ Sci |Vci . From the fact that pi ∈ Sci , it follows that pi ∈
/ Vci , hence
∗
pi ∈
/ V (k). But this is in contradiction with the fact that pi occurs in some bridge rule body.
Therefore, r ∈ app(brk , S|V ).

The next Lemma 10 is based on the following notions that convert cyclic MCSs to acyclic
ones and show that they have corresponding equilibria. The intuition (illustrated in Figure 19 and
Examples 18, 19) is to introduce an additional context Ck to take care of guessing for every cycle
breaker Ck . Then, the bridge rules of Ck and its parents are modified to point to Ck . We now
formally realize this idea starting with a function ren that renames part of the bridge rules.
Definition 12 Let Ck be a context in an MCS M , and let V be an interface for running DMCS. The
renaming function ren is defined as follows:

• For an atom a: ren(a, k, V) =

ag
a

if a ∈ Bk ∩ V
otherwise


• For a context index c: ren(c, k, V) =

c
c

if c ∈ {1, . . . , n}
otherwise

• For a bridge atom (ci : pi ): ren((ci : pi ), k, V) = (ren(ci , k, V) : ren(pi , k, V))

585

DAO -T RAN , E ITER , F INK , & K RENNWALLNER

• For a bridge body B = {(c1 : p1 ) . . . (cj : pj )}:
ren(B, k, V) = {ren((ci : pi ), k, V) | (ci : pi ) ∈ B}
• For a bridge rule r = head (r) ← B(r):
ren(r, k, V) = head (r) ← ren(B(r), k, V)
• For a set of bridge rules br : ren(br , k, V) = {ren(r, k, V) | r ∈ br }
• For a context Ci = (Li , kb i , br i ) in M : ren(Ci , k, V) = (Li , kb i , ren(bri , k, V)).
Example 18 Let us slightly modify the MCS M = (C1 , C2 , C3 ) from Example 8 as follows:
• kb 1 = {e ∨ ¬e}, br 1 = {a ← (1 : e), not (2 : b)};
• kb 2 = ∅, br 2 = {b ← (3 : c)}; and
• kb 3 = ∅, br 3 = {c ∨ d ← not (1 : a)}.
Applying function ren to contexts C1 and C3 results in the following bridge rules wrt. an interface V = {a, b, c, e}:
• ren(br 1 , 1, V) = {a ← (1 : eg ), not (2 : b)},
• ren(br 3 , 1, V) = {c ∨ d ← not (1 : ag )}.
For two contexts Ci and Cj , the former is called a parent of the latter with respect to an interface
V, denoted by parent(Ci , Cj , V) iff there exists a bridge rule r ∈ br i such that there exists (c : p) ∈
B(r) and p ∈ Bj ∩ V.
A set of contexts {Cc1 , Cc2 , . . . , Cc` } of an MCS M is called a cycle w.r.t. an interface V iff
^
parent(Cc` , C1 , V) ∧
parent(Cci , Cci+1 , V)
1≤i≤`−1

holds. One can pick an arbitrary context in this set to be its cycle-breaker. Given an MCS M , there
are several ways to choose a (finite) set of its contexts to be cycle-breakers. In Algorithm DMCS,
Step (d) practically establishes the cycle-breakers based on the order that elements in In(k) are
iterated. For the next definition, we are interested in this particular set of cycle-breakers.
Definition 13 Given an MCS M = (C1 , . . . , Cn ), let CB rM = {Cc1 , . . . , Ccj } be the set of cyclebreakers for M based on the application of DMCS on M starting from context Cr . The conversion
of M to an equal acyclic M ? based on CB rM and an interface V is done as follows:

ren(Ci , i, V) if Ci ∈ CB rM
0
0
Let Ci = (Li , kb i , br i ) =
Ci
otherwise
Let Ci00 = (Li , kb i , br 00i ) = ◦Ck ∈CBM ren(Ci0 , k, V)10
 00
br i ∪ {a ← (i : ag ) | a ∈ Bi ∩ V}
000
Let Ci000 = (Li , kb i , br 000
)
where
br
=
i
i
br 00i

if Ci ∈ CB rM
otherwise

For each Cj ∈ CB rM , introduce Cj = (Lj , kb j , br j ) where br j = ∅ and kb j = {ag ∨ ¬ag | a ∈
Bj ∩ V}. Then M ? = (C1000 , . . . , Cn000 , Cc1 , . . . , Ccj ).
10. The order of composing function ren with different parameters k does not matter here.

586

D ISTRIBUTED E VALUATION OF N ONMONOTONIC M ULTI - CONTEXT S YSTEMS

Example 19 (cont’d) Let M be the MCS from Example 18 and CB rM = {C1 }. Then, the conversion in Definition 13 gives M ? = (C1000 , C2000 , C3000 , C1 ), where:
g
• kb 1 = {e ∨ ¬e}, br 000
1 = {a ← (1 : e ), not (2 : b).

a ← (1 : ag ).

e ← (1 : eg ).};

• kb 2 = ∅, br 000
2 = {b ← (3 : c)};
g
• kb 3 = ∅, br 000
3 = {c ∨ d ← not (1 : a )}; and

• kb 1 = {eg ∨ ¬eg .

ag ∨ ¬ag .}, br 1 = ∅.

Lemma 10 Let M be an MCS and M ? be its conversion to an acyclic MCS as in Definition 13.
Then the equilibria of M and M ? are in 1-1 correspondence.
Proof (Sketch) Let (R1 ) and (R2 ) be the runs of DMCS on M and M ? , respectively. Due to the
selection of CB rM to construct M ? , both (R1 ) and (R2 ) have the same order visiting the contexts,
except that when (R1 ) revisits a cycle-breaker Ck ∈ CB rM , its counterpart (R2 ) visits Ck . At these
corresponding locations:
• (R1 ) calls guess(V, Ck ) at Step (c), and
• (R2 ) calls lsolve({, . . . , }) at Step (e) since Ck is a leaf context.
The construction of the local knowledge base of Ck gives us exactly the guess on Ck . Furthermore,
these guesses are passed on to the parent contexts of Ck and then later on unified by the additional
bridge rules a ← (k : ag ) introduced in br 000
k . Therefore, the belief combinations (Step (d)) done at
Ck are executed on the same input on both runs (R1 ) and (R2 ). The correspondence of equilibria
hence follows.

Proof (Theorem 1) Thanks to Lemma 10, we now need to prove Theorem 1 only for the acyclic
case and automatically get the result for the cyclic case.
(⇒) We start by showing soundness of DMCS. Let S 0 ∈ Ck .DMCS(V, ∅) such that V ⊇ V ∗(k). We
show now that there is a partial equilibrium S of an acyclic M w.r.t. Ck such that S 0 = S|V . We
proceed by structural induction on the topology of M .
Base case: Ck is a leaf with In(k) = ∅ and brk = ∅ and k ∈
/ hist. This means that (d) is not
executed, hence, in (e), lsolve runs exactly once on (, . . . , ), and we get as result the set of all belief
states S = lsolve((, . . . , )) = {(, . . . , , Tk , , . . . , ) | Tk ∈ ACCk (kbk )}. We now show that
S 0 ∈ S|V . Towards a contradiction, assume that there is no partial equilibrium S = (S1 , . . . , Sn ) of
M w.r.t. Ck such that S 0 = S|V . From In(k) = ∅, we get that IC (k) = {k}, thus the partial belief
state (, . . . , , Tk , , . . . , ) ∈ S (where Tk ∈ ACCk (kbk )) is a partial equilibrium of M w.r.t. Ck .
Contradiction.
Induction step: assume context Ck has import neighborhood In(k) = {i1 , . . . , im } and
S i1 = Ci1 .DMCS(V, hist ∪ {k}),
..
.
S im = Cim .DMCS(V, hist ∪ {k}).
587

DAO -T RAN , E ITER , F INK , & K RENNWALLNER

Then by the induction hypothesis, for every S 0ij ∈ S ij , there exists a partial equilibrium S ij of M
w.r.t. Cij such that S ij |V = S 0ij .
Let S = Ck .DMCS(V, hist). We need to show that for every S 0 ∈ S, there is a partial equilibrium of M w.r.t. Ck such that S 0 = S|V . Indeed, since In(k) 6= ∅, Step (d) is executed; let
T = S i1 ./ · · · ./ S im
be the result of combining partial belief states from
Scalling DMCS at Ci1 , . . . , Cim . Furthermore,
?
?
by Step (e), we have that S = S |V where S = {lsolve(S) | S ∈ T }. Eventually, S 0 ∈ S|V .
Since every DMCS at Ci1 , . . . , Cim returns its partial equilibria w.r.t. Cij projected to V, we have
that every T ∈ T is a partial equilibrium w.r.t. Cij projected to V. M is acyclic and we have visited
all contexts from In(k), thus by Lemma 9 we get that for every T ∈ T , app(brk , T ) gives us all
applicable bridge rules r regardless of Tj =  in T , for j ∈
/ In(k). Hence, for all T ∈ T , lsolve(T )
returns only partial belief states, where each component is projected to V except the kth component.
As every T ∈ T preserves applicability of the rules by Lemma 9, we get that for every S 0 ∈ S|V ,
there exists a partial equilibrium S of M w.r.t. Ck such that S 0 = S|V .
(⇐) We give now a proof for completeness of DMCS by structural induction on the topology of an
acyclic M . Let S = (S1 , . . . , Sn ) be a partial equilibrium of M w.r.t. Ck and let S 0 = S|V . We
show now that S 0 ∈ Ck .DMCS(V, ∅).
Base case: Ck is a leaf context. Then, when executing Ck .DMCS(V, ∅), Step (d) is ignored and
Step (e) is called with input (, . . . , ), and lsolve((, . . . , )) gives us all belief sets S of Ck . As S
is an equilibrium of M w.r.t. Ck , S ∈ S; hence, S 0 = S|V will be returned from Ck .DMCS(V, ∅).
Induction case: suppose that the import neighborhood of context Ck is In(k) = {i1 , . . . , im }. Let
the restriction of S to every context Cij ∈ In(k) be denoted by S ij , where:

S` if ` ∈ IC (ij )
0
0
0
ij
S = (S1 , . . . , Sn ) where S` =

otherwise
Informally speaking, this restriction keeps only belief sets of the contexts reachable from Cij and
sets those of non-reachable contexts to . By the induction hypothesis, S ij |V is computed by
Cij .DMCS(V, ∅) for all ij ∈ In(k). We will show that S|V is computed by Ck .DMCS(V, ∅).
Indeed, because we are considering an acyclic M , it holds that S ij |V is also returned from a call
Cij .DMCS(V, {k}), as k plays no role in further calls from Cij to its neighbors. This means that
after step (d), T contains a T = Si1 ./ . . . ./ Sim where Sij appears at position ij in S.
Since S is a partial equilibrium of M w.r.t. Ck , we have that Sk ∈ ACCk (kbk ∪ {head (r) |
r ∈ app(brk , S)}). Furthermore, by choosing V ⊇ V ∗(k), Lemma 9 tells us that the applicability of
bridge rules is preserved under the projection of belief sets to V. This gives us that Sk ∈ lsolve(T )
in step (e), and hence S 0 = S|V is returned from Ck .DMCS(V, ∅).

Proof of Proposition 4
(1) For a context Ck , let the number of calls to its local solver be denoted by c(k). This number is
calculated during the computation of T in Step (d), and it is bounded by the maximal number of
combined partial belief sets from its neighbors. Formally speaking:
c(k) ≤ Πi∈In(k) 2|V∩Bi | ≤ 2|In(k)|×|V| ≤ 2n×|V| .
588

D ISTRIBUTED E VALUATION OF N ONMONOTONIC M ULTI - CONTEXT S YSTEMS

Hence for the whole MCS, the upper bound of calls to lsolve in a run of DMCS is
c = Σ1≤k≤n c(k) ≤ n × 2n×|V|
(2) For a context Ck of an MCS M = (C1 , . . . , Cn ), the set E(k) contains all dependencies from
contexts Ci for i ∈ IC (k). We visit all (i, j) ∈ E(k) exactly twice during DFS-traversal of M : once
when calling Cj .DMCS(V, hist) at Ci , and once when retrieving S|V from Cj in Ci . Furthermore,
the caching technique in Step (a) prevents recomputation on already visited nodes, thus prevents
recommunication in the subtree of any visited node. The claim hence follows.

Proof of Proposition 5
Item (i) is trivial to see since CycleBreaker is applied in Algorithm 4. To prove item (ii), let us look
at two cases in which an edge (`, t) is removed from the original topology at Step (a) of Algorithm 3:
• (`, t) is removed by CycleBreaker: this causes that certain nodes in the graph cannot reach t
via `. However, the interface that Ct provides is already attached to v(i, j) via V ∗ (cp )|Bt .
• (`, t) is removed by transitive reduction: this does not change the reachability of t from other
nodes; therefore, the interface that Ct provides is already included in V ∗ (i, j)B 0 .


This argument gives us property (ii).
Proof of Proposition 6
First, we estimate the complexity to compute v(i, j) in loop (a).
[
[
v(i, j) := V ∗(i, j)B 0 ∪
V ∗(cp )|Bc ∪
V ∗(cp )|Bt
c∈C 0

(`,t)∈E

On the one hand, the refined recursive import V ∗(i, j)0B is defined as (Definition 9):
V ∗(i, j)0B = {V ∗ (i) ∩

[

B` }

`∈B 0 |j

where B 0 |j contains all nodes reachable from j.
On the other hand, since all sets of possible beliefs in different contexts are disjoint, we have
that
[
c∈C 0

V ∗(cp )|Bc ∪

[

V ∗(cp )|Bt = V ∗(cp )|Sc∈C0 Bc ∪S(`,t)∈E Bt

(`,t)∈E

S
Since the recursive import interface for a node k is defined as V ∗(k) = i∈IC (k) V(i), the
expression to compute v(i, j) is in the end a combination of set intersection, union, and projection.
With an implementation of sets using hash set, that is, look up takes O(1), these operators can be
implemented in linear time. Therefore, v(i, j) can be computed in linear time in the total number of
beliefs of contexts in the system.
Given GM , the block tree graph T (GM ) can be constructed in linear time (Vats & Moura,
2010). Ear-decomposition (Step (c)) can also be done in linear time (Valdes, Tarjan, & Lawler,
589

DAO -T RAN , E ITER , F INK , & K RENNWALLNER

1982). Transitive reduction (Step (d)) can be computed in quadratic time with respect to the number
of edges in the block.
OptimizeTree(T (GM ), k, k) iterates through all blocks. Assume that we have m blocks B1 . . . ,
Bm , and each Bi contains ni edges, where n = Σm
i=1 ni is the total number of edges in the original
graph. Let ti be the time to process block Bi . Then the bound of the total processing time can be
assessed as follows:
m
m
m
X
X
X
2
t=
ti ≤
ni ≤ (
ni )2 = n2 .
i=1

i=1

i=1

Therefore, if we ignore loop (a), OptimizeTree can be done in quadratic time in the size of the
original input, i.e., the size of GM .

Proof of Theorem 7
To prove this, we need Proposition 11 to claim that partial equilibria returned from DMCS and
DMCSOPT are in correspondence. But first, we need the following supportive notion.

Definition 14 Let Ck be a context of an MCS M , and let Πk be the query plan as in Definition 11.
For each block B of Πk , the block interface of B, whose root vertex is cB , is
VB = {p ∈ v(i, j) | (i, j) ∈ E(B)} ∪ BcB .
Let Ci be a context in B. The self-recursive import interface of Ci in B is
[
V ∗ (i)B = Bi ∪
V ∗ (i, `)B .
(i,`)∈E(Πk )

Proposition 11 Let Ck be a context of an MCS M
S , let Πk be the query plan as in Definition 11 in
which Ck belongs to block B of Πk and let V = B∈Πk VB . Then,
(i) for each S 0 ∈ DMCSOPT(k) called from Cc where (c, k) ∈ E(Πk ) or c = k, there exists
a partial equilibrium S ∈ Ck .DMCS(V, ∅) such that S 0 = S|V ∗ (c,k)B if (c, k) ∈ E(Πk ) or
S 0 = S|V ∗ (k)B if c = k;
(ii) for each S ∈ Ck .DMCS(V, ∅), there exists some S ∈ DMCSOPT(k) called from Cc such that
S 0 = S|V ∗ (c,k)B if (c, k) ∈ E(Πk ) or S 0 = S|V ∗ (k)B if c = k.
A detailed proof for Proposition 11 is given in the next section, we now give a proof for Theorem 7.
Proof (Theorem 7) (i) Let S 0 ∈ Ck .DMCSOPT(k) be a result from DMCSOPT. By Proposi00
0
00
tion 11 (i) for
Sc = k, there exists an∗ S ∈ Ck .DMCS(V, ∅) such that S = S |V ∗ (k)B , where we
choose V = B∈Πk VB . Note that V (k) ⊆ V as V collects all bridge atoms from all blocks, which
might contain blocks not reachable from k. By Theorem 1, there exists a partial equilibrium S of
M such that S 00 = S|V . Thus, we have that
S 0 = (S|V )|V ∗ (k)B
= S|V ∗ (k)B
because V ∗ (k)B ⊆ V
b ⊆ V ∗ (k)B
= S|Vb
because V
(ii) Let S be a partial equilibrium of MS. By Theorem 1, there exists S 00 ∈ Ck .DMCS(V, ∅) such
that S 00 = S|V where we choose V = B∈Πk VB . As above, V ∗ (k) ⊆ V. By Proposition 11 (ii)
for c = k, there exists S 0 ∈ Ck .DMCSOPT(k) such that S 0 = S 00 |V ∗ (k)B . As above, we have that
S 0 = S|Vb .

590

D ISTRIBUTED E VALUATION OF N ONMONOTONIC M ULTI - CONTEXT S YSTEMS

Proof of Proposition 11
To support the proof of Proposition 11, we need the following lemmas.
Lemma 12 Assume context Ck has import neighborhood In(k) = {i1 , . . . , im }, no (k, ij ) is removed from the original topology by OptimizeBlock(B, cB ), and
S 0i1

= DMCSOPT(k) at Ci1
..
.

S i1

= Ci1 .DMCS(VB , ∅)
..
.

S 0im

= DMCSOPT(k) at Cim

S im

= Cim .DMCS(VB , ∅)

such that for every partial equilibrium S 0 ∈ S 0ij , there exists S ∈ S ij such that S 0 = S|V ∗ (k,ij )B .
Let T 0 = S 0i1 ./ . . . ./ S 0im and T = S i1 ./ . . . ./ SSim . Then, for each T 0 ∈ T 0 , there exists
2
V ∗ (k, ij )B .
T ∈ T such that T 0 = T |Vinput (1,m) with Vinput (`1 , `2 ) = `j=`
1
Proof We prove by induction on the number of neighbors in In(k).
Base case: In(k) = {i}, the claim trivially holds.
Induction case: In(k) = {i1 , . . . , i` }, U 0 = S 0i1 ./ . . . ./ S 0i`−1 , U = S i1 ./ . . . ./ S i`−1 , and
for each U 0 ∈ U 0 , there exists U ∈ U such that U 0 = U |Vinput(1,`−1) . We need to show that for each
T 0 ∈ U 0 ./ S 0i` , there exists a T ∈ U ./ S i` such that T 0 = T |Vinput (1,`) .
Assume that the opposite holds, i.e., there exists T = U 0 ./ S 0 where U 0 ∈ U 0 and S 0 ∈ S 0i` ,
and for all U ∈ U, S ∈ S i` such that U 0 = U |Vinput (1,`−1) and S 0 = S|V ∗ (k,i` )B , we have that
U ./ S is void.
This means there exists a context Ct reachable from Ck by two different ways, one via i` and
the other via one of i1 , . . . , i`−1 such that Ut 6= , St 6= , Ut 6= St , and either
(i) Ut0 =  or St0 = , or
(ii) Ut0 = St0 6= 
Case (i) cannot happen because Ct is reachable from Ck , hence Vinput (1, ` − 1) ∩ Bt 6= ∅ and
V ∗ (k, i` ) ∩ Bt 6= ∅.
Concerning case (ii), we have that Ut |Vinput (1,`−1) = St |V ∗ (k,i` ) 6= , hence there exists a ∈
Ut \ Ut |Vinput (1,`−1) and a ∈
/ St |V ∗ (k,i` ) . This means that Vinput (1, ` − 1) ∩ Bt 6= V ∗ (k, i` ) ∩ Bt .
∗
∗
S However, from Definition 9 of recursive import interface, we have that V (k, ix )B ∗= V (k) ∩
`∈B|k B` , where B|ix contains all nodes in B reachable from ix . It follows that V (k, i` ) and
∗
V (k, ij ) for any 1 ≤ j ≤ ` − 1 that reaches t, share the same projection to Bt , hence Vinput (1, ` −
1) ∩ Bt = V ∗ (k, i` ) ∩ Bt .
We reach a contradiction, and therefore Lemma 12 is proved.


Lemma 13 The join operator ./ has the following properties, given arbitrary belief states S, T , U
with the same size: (i) S ./ S = S (ii) S ./ T = T ./ S (iii) S ./ (T ./ U ) = (S ./ T ) ./ U .
These properties also hold for sets of belief states.
Proof The first two properties are trivial to prove. We will prove associativity.
Let R = S ./ (T ./ U ) and W = (S ./ T ) ./ U . Consider doing the joins from left to right.
At each position i (1 ≤ i ≤ n), Ri and Wi are determined by locally comparing Si , Ti and Ui . If we
591

DAO -T RAN , E ITER , F INK , & K RENNWALLNER

Si = 
Y
Y
Y

Ti = 
Y
Y
N

Ui = 
Y
N
Y

Y

N

N

N

Y

Y

N

Y

N

N

N

Y

N

N

N

Si = Ti
Y
Y
N
N
N
N
N
N
Y
N
Y
Y
N
N

Ti = Ui
Y
N
N
Y
N
Y
N
N
N
N
Y
N
Y
N

Ui = Si
Y
N
Y
N
N
N
Y
N
N
N
Y
N
N
N

Ri

Ui
Ti
Ti
void
Si
Si
void
Si
void
Si
void
void
void

Wi

Ui
Ti
Ti
void
Si
Si
void
Si
void
Si
void
void
void

Table 1: Possible cases when joining at position i

reach inconsistency, the process terminates and void is returned; otherwise, we conclude the value
for Ri , Wi and continue to the next position. The final join is returned if position n is processed
without any inconsistency.
All possible combination of Si , Ti , and Wi are shown in Table 1. One can see that we always
have the same outcome for Ri and Wi . Therefore, we have in the end either R = W or both are
void . This concludes that the join operator ./ is commutative.

Lemma 14 Let Ci and Cj be two contexts in M such that they are in the same block after executing
OptimizeTree and there is a directed path from Ci to Cj . Suppose that S i = DMCSOPT(k) at Ci
and S j = DMCSOPT(k) at Cj . Then S i = S i ./ S j .

Proof The use of cache in DMCSOPT does not change the result and can be disregarded, i.e., we
can assume without loss of generality that cache(k) = ∅ in DMCSOPT. Indeed, cache(k) is filled
with the result of the computation when it is empty (i.e., when Ck is accessed the first time), and
is after that never changed and DMCSOPT just returns cache(k), i.e., the value of the computation
with empty cache(k).
Under the above assumption, Lemma 14 can be proven by taking any path Ci = Cp1 , . . . , Cph =
Cj that connects Ci to Cj , and arguing that for each index ` ∈ {1, . . . , h}, it holds that S p` = S p` ./
S j (?). Indeed, we can show this by an induction on the path.
Base case: ` = h, statement (?) holds as we have S ph ./ S j = S j ./ S j = S j by identity
(Lemma (13), (i)).
Induction case: consider ` < h, and suppose we already established by the induction hypothesis
that S p`+1 = S p`+1 ./ S j .
592

D ISTRIBUTED E VALUATION OF N ONMONOTONIC M ULTI - CONTEXT S YSTEMS

Now by definition of S p` and DMCSOPT, it holds that S p` = lsolve(T )11 and T is, by the
statements (b) and (c), of the form T = S p`+1 ./ T 0 ; this holds because there is an edge (p` , p`+1 )
in E, and because ./ is commutative and associative (Lemma (13), (ii) and (iii)). By the induction
hypothesis, we get
T = S p`+1 ./ T 0 = (S p`+1 ./ S j ) ./ T 0 = S j ./ (S p`+1 ./ T 0 ),
that is, T is of the form S j ./ T 00 .
Next, lsolve(T ) does not change the value of any component of any interpretation I in T that is
defined in S j ; that is, lsolve(T ) ./ S j = lsolve(T ). This means S p` = lsolve(T ) = lsolve(T ) ./
S j = S p` ./ S j , which proves statement (?) holds for `.
Eventually, we get for ` = 1 that S i = S p1 = S p1 ./ S j = S i ./ S j .

Based on Lemma 14, we have the following result.
Lemma 15 Assume the import neighborhood of context Ck is In(k) = {i1 , . . . , im }, and that
S ij = DMCSOPT(k) at Cij , 1 ≤ j ≤ m. Furthermore, suppose that edge (k, ij ) was removed by
the optimization process (1 ≤ j ≤ m), and that Ci` is a neighbor of Ck such that there exists a path
from k to ij through i` in the optimized topology. Then S i` = S i` ./ S ij ; in other words, the input
to DMCSOPT at Ck is not affected by the removal of (k, ij ).
Proof Since Cij and Ci` are direct children of Ck , it follows that they belong to the same block.
Therefore, by Lemma 14 we have that S i` = S i` ./ S ij .

Proof (Proposition 11) We proceed by structural induction on the block tree of an MCS M . First,
we consider the case where the topology of M is a single block B. In this case, the interface passed
to DMCS is V = VB .
Base case: Ck is a leaf. Then we now compare a call DMCSOPT(k) at Ck and Ck .DMCS(V, ∅),
where V = V ∗ (k)B = Bk . Algorithm 1 returns local belief sets of Ck projected to V and Algorithm 5 returns plain local belief sets, the claim follows as V = V ∗ (k)B = Bk .
Induction case: Assume the import neighborhood of context Ck is In(k) = {i1 , . . . , im }, and
S 0i1

= DMCSOPT(k) at Ci1
..
.

S i1

= Ci1 .DMCS(VB , ∅)
..
.

S 0im

= DMCSOPT(k) at Cim

S im

= Cim .DMCS(VB , ∅)

such that for every partial equilibrium S 0 ∈ S 0ij , there exists S ∈ S ij such that S 0 = S|V ∗ (k,ij )B .
There are two cases. First, no edge (k, ij ) is removed by the optimization procedure. Then, by
Lemma 12, we have the correspondence between the input to DMCSOPT and DMCS at Ck .
On the other hand, assume that an edge (k, ij ) was removed by the optimization process. The
removal can be from either transitive reduction or ear decomposition. In the former case, Lemma 15
shows that the input to Ck is not affected by the removal of this edge. For the latter case, the removal
can be one of three possibilities as illustrated in Figure 20, assuming that context C1 gets called:
(i) (6, 1), the last edge of the simple cycle P0 = {1, 2, 3, 4, 5, 6}
11. With abuse of notation, we write lsolve(T ) for

S

T ∈T

lsolve(T )

593

DAO -T RAN , E ITER , F INK , & K RENNWALLNER

1

12
11

10

9

2

6

3

5
4

8

7

Figure 20: Possible cycle breakings
(ii) (9, 6), the last edge of path P1 = {5, 7, 8, 9, 6}
(iii) (12, 2), the last edge of path P2 = {3, 10, 11, 12}
Cases (i) and (iii) differ from case (ii) in the sense that a cycle will be recognized by DMCS
while for case (ii), no cycle is detected along the corresponding path.
Now, consider when (k, ij ) is removed in situations similar to cases (i) and (iii), DMCSOPT
will issue a guess at Step (c) of Algorithm 5 on v(k, ij ), which includes V ∗ (cB )|Bij = VB ∩ Bij .
On the other hand, DMCS will recognize the cycle at Cij and issue a guess on VB ∩ Bij at Step (c)
of Algorithm 1. Therefore, the guess is fed equally to Ck .
When (k, ij ) is removed in situations similar to case (ii), all guesses of Ck on the interface from
Cij will be eventually filtered when being combined with the local belief states computed by Cij ,
at the starting node of the path containing (k, ij ) as the last edge (in the ear decomposition). In
Figure 20, this is node 5.
In all cases, we have that whenever there is an input T 0 into lsolve in DMCSOPT(k) called by
Cc , there is an input T to lsolve in Ck .DMCS(VB , ∅). Therefore, the claim on the output holds.
Now that Proposition 11 holds for a single leaf block, one can see that the upper blocks only
need to import the interface
S beliefs from the cut vertices (also the root contexts of the lower blocks).
Under the setting of V = B∈Πk VB , results from DMCSOPT and DMCS projected to the interface
of the cut vertices are identical. Therefore, the upper blocks receive the same input regarding the
interfaces of the cut vertices in running both algorithms. And therefore the final results projected to
V ∗ (k)B are in the end the same.


Proof of Proposition 8
Note that the components Handler and Output simply take care of the communication part of
DMCS-STREAMING. Output makes sure that the models sent back to the invokers are in correspondence with the request that Handler got. The other routines Joiner and Solver are the main
components that play the role of Step (b) and (d) in Algorithm 5, respectively.
594

D ISTRIBUTED E VALUATION OF N ONMONOTONIC M ULTI - CONTEXT S YSTEMS

T1,1
···
T1,1
T1,1
···
T1,1

./

T2,1

./

···

./

./

T2,1

./

···

./

./

T2,1

./

···

./

./

T2,1

./

···

./

···
T1,1
···
T1,1
···
T1,1

./

T2,1

./

···

./

./

T2,1

./

···

./

./

T2,p2

./

···

./

Tm,1

∪

./

Tm,pm

∪

./

Tm,1

∪

./

Tm,pm

∪

Tm−1,pm−1
···
Tm−1,pm−1
···

./

Tm,1

∪

./

Tm,pm

∪

Tm−1,1

./

Tm,1

∪

./

Tm,pm

∪

./

Tm,1

∪

···
./

T2,p2

./

···

./

···
T1,p1

Tm−1,2
···
Tm−1,2

./

···

···
T1,1

Tm−1,1
···
Tm−1,1

Tm−1,pm−1
···

./

T2,1

./

···

./

···

Tm−1,p1
···

T1,p1

./

T2,p2

./

···

./

Tm−1,pm−1

./

Tm,pm

T1,1
···
T1,1
···
T1,1
···
T1,1
···
T1,p1

./

T2,1

./

···

./

Tm−1,1
···

./

F (m, m)

∪

./

T2,1

./

···

./

./

F (m, m)

∪

./

T2,p2

./

···

./

./

F (m, m)

∪

./

T2,p2

./

···

./

./

F (m, m)

∪

./

T2,p2

./

···

./

Tm−1,pm−1
···
Tm−1,1
···
Tm−1,pm−1
···
Tm−1,pm−1

./

F (m, m)

T1,1
···
T1,1
···
T1,p1

./

T2,1

./

···

./

∪

./

T2,p2

./

···

./

./

T2,p2

./

···

./

F (m − 1, m)
···
F (m − 1, m)
···
F (m − 1, m)

=

[T1,1 ./ F (2, m)]

∪

···

∪

[T1,p1 ./ F (2, m)]

=

F (1, m).

=

=

∪

Table 2: Accumulation of Joiner

To prove the correctness of DMCS-STREAMING, we just need to show that the input to lsolve
is complete in the sense that if Step (e) of Algorithm 8 is exhaustively executed, the full join of
partial equilibria from the neighboring contexts is delivered.
595

DAO -T RAN , E ITER , F INK , & K RENNWALLNER

Formally, assume that the current context’s import neighborhood is {1, 2, . . . , m}. Assume that
for neighbor Ci where 1 ≤ i ≤ m, the full partial equilibria are Ti and the returned packages of size
k are denoted by Ti,1 , . . . , Ti,pi , that is, Ti = Ti,1 ∪ . . . ∪ Ti,pi . For the correctness of the algorithm,
we assume that Ti,1 , . . . , Ti,pi is a fixed partition of Ti . This is possible when, for example, lsolve
always returns answers in a fixed order. We need to show that the accumulation of the join by
Algorithm 8 is actually T1 ./ . . . ./ Tm .
Indeed, each possible join T1,i1 ./ T2,i2 ./ . . . ./ Tm,im is considered by Joiner, which performs
a lexicographical traversal of all suitable combinations. Formally speaking, let F (p, q), where q <
q, denote the join result of neighbors from p to q, that is, F (p, q) = Tp ./ Tp+1 ./
S .1 . . ./ Tq .
According to the lexicographical order, we have that the accumulation of Joiner is pj=1
[T1,j ./
F (2, m)] = F (1, m) as demonstrated in Table 2.
This shows that the input to lsolve is complete. Hence, DMCS-STREAMING is correct.


Appendix B. Detailed Run of OptimizeTree
Example 20 We illustrate now the call OptimizeTree(T = (B ∪ C, E), cp , cr ) for the block set B =
{B1 , B2 , B3 }, B1 = {1, 2, 3, 4}, B2 = {4, 5}, B3 = {3, 6}, C = {1, 3, 4}, E = {(B1 , 1), (B2 , 4),
(B3 , 3)}, and cp = cr = 1.
From the local knowledge bases presented in Example 10, we have:
B1 = {car 1 , train 1 , nuts 1 }
B2 = {car 2 , train 2 }
B3 = {car 3 , train 3 , salad 3 , peanuts 3 , coke 3 , juice 3 , urgent 3 }

B4 = {car 4 , train 4 }
B5 = {soon5 , sooner 5 }
B6 = {fit 6 , sick 6 }

Since cp = cr , we start with B 0 = {B1 }. We have F = v = ∅.
Now we call OptimizeBlock(B1 , 1). Since B1 is acyclic, only the transitive reduction is applied.
We get B1− = ({1, 2, 3, 4}, {(1, 2), (2, 3), (3, 4)}). The subroutine returns E = {(1, 3), (2, 4)}.
The child cut vertices of B1 are C 0 = {3, 4}; we update F to {(1, 3), (2, 4)}.
Next, we update the label of all edges (i, j) in B1− . But before this, let us enumerate the recursive
import interfaces, starting from the import interface, for every node from 1 to 6:
V(1) = {train 2 , train 3 , peanuts 3 }
V(2) = {car 3 , coke 3 , train 3 , car 4 , train 4 }
V ∗ (1)
V ∗ (2)
V ∗ (3)
V ∗ (4)
V ∗ (5)
V ∗ (6)

V(3) = {train 4 , sick 6 }
V(5) = {train 4 }

V(4) = {sooner 5 }
V(6) = ∅

{train 2 , train 3 , peanuts 3 , car 3 , coke 3 , car 4 , train 4 , sooner 5 , sick 6 }
{train 3 , car 3 , coke 3 , train 4 , car 4 , sooner 5 , sick 6 }
{train 4 , sooner 5 , sick 6 }
{train 4 , sooner 5 }
{train 4 , sooner 5 }
∅
S
Now, let us compute V ∗ (1, 2)B1 = V ∗ (1) ∩ `∈B1 |2 B` . We have that B1 |2 = {3, 4}, thus
=
=
=
=
=
=

V ∗ (1, 2)B1 = V ∗ (1) ∩ (B3 ∪ B4 ) = {train 2 , train 3 , peanuts 3 , car 3 , coke 3 , car 4 , train 4 }
Similarly, with B1 |3 = B1 |4 = {4}, we have:
V ∗ (2, 3) = V ∗ (2) ∩ B3 = {car 4 , train 4 }
V ∗ (3, 4) = V ∗ (3) ∩ B4 = {train 4 }
596

D ISTRIBUTED E VALUATION OF N ONMONOTONIC M ULTI - CONTEXT S YSTEMS

The removed edges and updated labels to be stored respectively in F and v for block B1 can be
summarized as:
F = {(1, 3), (2, 4)}
v(1, 2) =

V ∗ (1, 2)

∪

V ∗ (1)|B3

∪

V ∗ (1)|B4

v(2, 3) = V ∗ (2, 3) ∪ V ∗ (1)|B3 ∪ V ∗ (1)|B4
v(3, 4) = V ∗ (3, 4) ∪ V ∗ (1)|B3 ∪ V ∗ (1)|B4




train 2 , train 3 , peanuts 3 ,
=
car 3 , coke 3 , car 4 , train 4
= {train 3 , peanuts 3 , car 3 , coke 3 , car 4 , train 4 }
= {train 3 , peanuts 3 , car 3 , coke 3 , car 4 , train 4 }

Next, we call OptimizeTree(T \ B1 , 3, 1) and OptimizeTree(T \ B1 , 4, 1), which eventually process
blocks B2 and B3 in the same manner as above. The two calls respectively return:
F 0 = {(5, 4)}
v 0 (4, 5) = {sooner 5 }

F 00 = ∅
v 00 (3, 6) = {train 4 , sick 6 }

Combining all results together, OptimizeTree(T, 1, 1) returns as the set of removed edges
F = {(1, 2), (3, 4), (5, 4)}
and as updated labels v for the remaining edges in the blocks
v(1, 2)
v(2, 3)
v(3, 4)
v(4, 5)
v(3, 6)

=
=
=
=
=

{train 2 , train 3 , peanuts 3 , car 3 , coke 3 , car 4 , train 4 }
{train 3 , peanuts 3 , car 3 , coke 3 , car 4 , train 4 }
{train 3 , peanuts 3 , car 3 , coke 3 , car 4 , train 4 }
{sooner 5 }
{train 4 , sick 6 }

References
Adjiman, P., Chatalic, P., Goasdoué, F., Rousset, M.-C., & Simon, L. (2006). Distributed reasoning
in a peer-to-peer setting: Application to the semantic web. J. Artif. Intell. Res., 25, 269–314.
Aho, A. V., Garey, M. R., & Ullman, J. D. (1972). The Transitive Reduction of a Directed Graph.
SIAM J. Comput., 1(2), 131–137.
Analyti, A., Antoniou, G., & Damásio, C. V. (2011). MWeb: A principled framework for modular
web rule bases and its semantics. ACM Trans. Comput. Log., 12(2), 17.
Baader, F., Calvanese, D., McGuinness, D., Nardi, D., & Patel-Schneider, P. F. (Eds.). (2003). The
Description Logic Handbook. Cambridge University Press.
Baget, J.-F., & Tognetti, Y. S. (2001). Backtracking through biconnected components of a constraint
graph. In Nebel, B. (Ed.), Proceedings of the Seventeenth International Joint Conference on
Artificial Intelligence, IJCAI 2001, Seattle, Washington, USA, August 4-10, 2001, pp. 291–
296. Morgan Kaufmann.
Bairakdar, S. E.-D., Dao-Tran, M., Eiter, T., Fink, M., & Krennwallner, T. (2010a). Decomposition
of distributed nonmonotonic multi-context systems. In Janhunen, T., & Niemelä, I. (Eds.),
Logics in Artificial Intelligence - 12th European Conference, JELIA 2010, Helsinki, Finland,
September 13-15, 2010. Proceedings, Vol. 6341 of Lecture Notes in Computer Science, pp.
24–37. Springer.
597

DAO -T RAN , E ITER , F INK , & K RENNWALLNER

Bairakdar, S. E.-D., Dao-Tran, M., Eiter, T., Fink, M., & Krennwallner, T. (2010b). The DMCS
solver for distributed nonmonotonic multi-context systems. In Janhunen, T., & Niemelä, I.
(Eds.), Logics in Artificial Intelligence - 12th European Conference, JELIA 2010, Helsinki,
Finland, September 13-15, 2010. Proceedings, Vol. 6341 of Lecture Notes in Computer Science, pp. 352–355. Springer.
Bessiere, C., Bouyakhf, E., Mechqrane, Y., & Wahbi, M. (2011). Agile asynchronous backtracking
for distributed constraint satisfaction problems. In IEEE 23rd International Conference on
Tools with Artificial Intelligence, ICTAI 2011, Boca Raton, FL, USA, November 7-9, 2011,
pp. 777–784.
Bikakis, A., & Antoniou, G. (2010). Defeasible contextual reasoning with arguments in ambient
intelligence. IEEE Transactions on Knowledge and Data Engineering, 22(11), 1492–1506.
Bikakis, A., Antoniou, G., & Hassapis, P. (2011). Strategies for contextual reasoning with conflicts
in ambient intelligence. Knowl. Inf. Syst., 27(1), 45–84.
Bögl, M., Eiter, T., Fink, M., & Schüller, P. (2010). The MCS-IE system for explaining inconsistency
in multi-context systems. In Logics in Artificial Intelligence - 12th European Conference,
JELIA 2010, Helsinki, Finland, September 13-15, 2010. Proceedings, Vol. 6341 of Lecture
Notes in Computer Science, pp. 356–359. Springer.
Bondy, A., & Murty, U. S. R. (2008). Graph Theory, Vol. 244 of Graduate Texts in Mathematics.
Springer.
Brewka, G., Eiter, T., Fink, M., & Weinzierl, A. (2011). Managed multi-context systems. In Walsh,
T. (Ed.), Proceedings of the 22nd International Joint Conference on Artificial Intelligence
(IJCAI-11), pp. 786–791. AAAI Press/IJCAI.
Brewka, G., Ellmauthaler, S., & Pührer, J. (2014). Multi-context systems for reactive reasoning in
dynamic environments. In Ellmauthaler, S., & Pührer, J. (Eds.), Proceedings of the International Workshop on Reactive Concepts in Knowledge Representation (ReactKnow) 2014, pp.
23–30. Tech.Rep. 1, Computer Science Institute, Univ. Leipzig, ISSN 1430-3701.
Brewka, G., & Eiter, T. (2007). Equilibria in heterogeneous nonmonotonic multi-context systems.
In Proceedings of the Twenty-Second AAAI Conference on Artificial Intelligence, July 22-26,
2007, Vancouver, British Columbia, Canada, pp. 385–390. AAAI Press.
Brewka, G., Eiter, T., & Fink, M. (2011). Nonmonotonic Multi-Context Systems: A Flexible Approach for Integrating Heterogeneous Knowledge Sources. In Balduccini, M., & Son, T. C.
(Eds.), Logic Programming, Knowledge Representation, and Nonmonotonic Reasoning - Essays Dedicated to Michael Gelfond on the Occasion of His 65th Birthday, Vol. 6565 of Lecture Notes in Computer Science, pp. 233–258. Springer.
Brewka, G., Roelofsen, F., & Serafini, L. (2007). Contextual default reasoning. In Veloso, M. M.
(Ed.), IJCAI 2007, Proceedings of the 20th International Joint Conference on Artificial Intelligence, Hyderabad, India, January 6-12, 2007, pp. 268–273.
Buccafurri, F., & Caminiti, G. (2008). Logic programming with social features. Theory and Practice
of Logic Programming, 8(5-6), 643–690.
Dao-Tran, M. (2014). Distributed Nonmonotonic Multi-Context Systems: Algorithms and Efficient
Evaluation. Ph.D. thesis, Faculty of Informatics, Vienna University of Technology, Austria.
598

D ISTRIBUTED E VALUATION OF N ONMONOTONIC M ULTI - CONTEXT S YSTEMS

Dao-Tran, M., Eiter, T., Fink, M., & Krennwallner, T. (2010). Distributed nonmonotonic multicontext systems. In Lin, F., Sattler, U., & Truszczynski, M. (Eds.), Principles of Knowledge Representation and Reasoning: Proceedings of the Twelfth International Conference,
KR 2010, Toronto, Ontario, Canada, May 9-13, 2010. AAAI Press.
Dao-Tran, M., Eiter, T., Fink, M., & Krennwallner, T. (2011). Model streaming for distributed multicontext systems. In Mileo, A., & Fink, M. (Eds.), 2nd International Workshop on Logicbased Interpretation of Context: Modeling and Applications, Vol. 738 of CEUR Workshop
Proceedings, pp. 11–22.
Eiter, T., Fink, M., Ianni, G., Krennwallner, T., & Schüller, P. (2011). Pushing efficient evaluation of
hex programs by modular decomposition. In Delgrande, J. P., & Faber, W. (Eds.), 11th International Conference on Logic Programming and Nonmonotonic Reasoning (LPNMR 2011),
Vancouver, BC, Canada, May 16-19, 2011, Vol. 6645 of Lecture Notes in Computer Science,
pp. 93–106. Springer.
Eiter, T., Ianni, G., Schindlauer, R., & Tompits, H. (2005). A uniform integration of higher-order
reasoning and external evaluations in answer-set programming. In IJCAI, pp. 90–96.
Faltings, B., & Yokoo, M. (2005). Introduction: Special issue on distributed constraint satisfaction.
Artif. Intell., 161(1-2), 1–5.
Fink, M., Ghionna, L., & Weinzierl, A. (2011). Relational information exchange and aggregation
in multi-context systems. In Delgrande, J. P., & Faber, W. (Eds.), 11th International Conference on Logic Programming and Nonmonotonic Reasoning (LPNMR 2011), Vancouver, BC,
Canada, 16-19 May, 2011, Vol. 6645 of Lecture Notes in Computer Science, pp. 120–133.
Springer.
Gao, J., Sun, J., & Zhang, Y. (2007). An improved concurrent search algorithm for distributed CSPs.
In Australian Conference on Artificial Intelligence, pp. 181–190.
Gelfond, M., & Lifschitz, V. (1991). Classical negation in logic programs and disjunctive databases.
New Generation Comput., 9(3/4), 365–386.
Ghidini, C., & Giunchiglia, F. (2001).
Local models semantics, or contextual reasoning=locality+compatibility. Artif. Intell., 127(2), 221–259.
Giunchiglia, F. (1992). Contextual Reasoning. Epistemologia, Special Issue on I Linguaggi e le
Macchine, 345, 345–364.
Giunchiglia, F., & Serafini, L. (1994). Multilanguage hierarchical logics or: How we can do without
modal logics. Artif. Intell., 65(1), 29–70.
Goncalves, R., Knorr, M., & Leite, J. (2014). Evolving multi-context systems. In Schaub, T.,
Friedrich, G., & O’Sullivan, B. (Eds.), Proceedings of the 21st Eureopean Conference on
Artificial Intelligence, ECAI’2014, Prague, Czech Republic, August 18-23, 2014. IOS Press.
Hirayama, K., & Yokoo, M. (2005). The distributed breakout algorithms. Artif. Intell., 161(1–2),
89–115.
Homola, M. (2010). Semantic Investigations in Distributed Ontologies. Ph.D. thesis, Comenius
University, Bratislava, Slovakia.
599

DAO -T RAN , E ITER , F INK , & K RENNWALLNER

Lee, J., & Lifschitz, V. (2003). Loop formulas for disjunctive logic programs. In Palamidessi, C.
(Ed.), Logic Programming, 19th International Conference, ICLP 2003, Mumbai, India, December 9-13, 2003, Proceedings, Lecture Notes in Computer Science, pp. 451–465. Springer.
McCarthy, J. (1993). Notes on formalizing context. In Bajcsy, R. (Ed.), Proceedings of the 13th
International Joint Conference on Artificial Intelligence. Chambéry, France, August 28 September 3, 1993, pp. 555–562. Morgan Kaufmann.
Pontelli, E., Son, T., & Nguyen, N.-H. (2011). Combining answer set programming and prolog: The
ASP-PROLOG system. In Balduccini, M., & Son, T. (Eds.), Logic Programming, Knowledge
Representation, and Nonmonotonic Reasoning, Vol. 6565, pp. 452–472. Springer Berlin Heidelberg.
Reiter, R. (1980). A logic for default reasoning. Artificial Intelligence, 13, 81–132.
Roelofsen, F., Serafini, L., & Cimatti, A. (2004). Many hands make light work: Localized satisfiability for multi-context systems. In de Mántaras, R. L., & Saitta, L. (Eds.), Proceedings of
the 16th Eureopean Conference on Artificial Intelligence, ECAI’2004, including Prestigious
Applicants of Intelligent Systems, PAIS 2004, Valencia, Spain, August 22-27, 2004, pp. 58–62.
IOS Press.
Serafini, L., Borgida, A., & Tamilin, A. (2005). Aspects of distributed and modular ontology reasoning. In Nineteenth International Joint Conference on Artificial Intelligence (IJCAI 2005),
pp. 570–575. AAAI Press.
Serafini, L., & Tamilin, A. (2005). Drago: Distributed reasoning architecture for the semantic web.
In Gómez-Pérez, A., & Euzenat, J. (Eds.), The Semantic Web: Research and Applications,
Second European Semantic Web Conference, ESWC 2005, Heraklion, Crete, Greece, May 29
- June 1, 2005, Proceedings, Lecture Notes in Computer Science, pp. 361–376. Springer.
Tarjan, R. E. (1972). Depth-First Search and Linear Graph Algorithms. SIAM J. Comput., 1(2),
146–160.
Tasharrofi, S., & Ternovska, E. (2014). Generalized multi-context systems.. In Baral, C., Giacomo,
G. D., & Eiter, T. (Eds.), Principles of Knowledge Representation and Reasoning: Proceedings of the Fourteenth International Conference, KR 2014, Vienna, Austria, July 20-24, 2014.
AAAI Press.
Valdes, J., Tarjan, R. E., & Lawler, E. L. (1982). The recognition of series parallel digraphs. SIAM
J. Comput., 11(2), 298–313.
Vats, D., & Moura, J. M. F. (2010). Graphical models as block-tree graphs. CoRR, abs/1007.0563.
Velikova, M., Novák, P., Huijbrechts, B., Laarhuis, J., Hoeksma, J., & Michels, S. (2014). An
Integrated Reconfigurable System for Maritime Situational Awareness. In ECAI 2014 - 21st
European Conference on Artificial Intelligence, 18-22 August 2014, Prague, Czech Republic
- Including Prestigious Applications of Intelligent Systems (PAIS 2014), pp. 1197–1202.
Yokoo, M., & Hirayama, K. (2000). Algorithms for distributed constraint satisfaction: A review.
Autonomous Agents and Multi-Agent Systems, 3(2), 185–207.

600

Journal of Artificial Intelligence Research 52 (2015) 1-95

Submitted 07/14; published 01/15

Coherent Predictive Inference under Exchangeability
with Imprecise Probabilities
Gert de Cooman
Jasper De Bock

gert.decooman@UGent.be
jasper.debock@UGent.be

Ghent University, SYSTeMS Research Group
Technologiepark–Zwijnaarde 914
9052 Zwijnaarde, Belgium

Márcio Alves Diniz

marcio.alves.diniz@gmail.com

Federal University of São Carlos, Department of Statistics
Rod. Washington Luis, km 235
São Carlos, Brazil

Abstract
Coherent reasoning under uncertainty can be represented in a very general manner by
coherent sets of desirable gambles. In a context that does not allow for indecision, this leads
to an approach that is mathematically equivalent to working with coherent conditional
probabilities. If we do allow for indecision, this leads to a more general foundation for coherent
(imprecise-)probabilistic inference. In this framework, and for a given finite category set,
coherent predictive inference under exchangeability can be represented using Bernstein
coherent cones of multivariate polynomials on the simplex generated by this category set.
This is a powerful generalisation of de Finetti’s Representation Theorem allowing for both
imprecision and indecision.
We define an inference system as a map that associates a Bernstein coherent cone of
polynomials with every finite category set. Many inference principles encountered in the
literature can then be interpreted, and represented mathematically, as restrictions on such
maps. We discuss, as particular examples, two important inference principles: representation
insensitivity—a strengthened version of Walley’s representation invariance—and specificity.
We show that there is an infinity of inference systems that satisfy these two principles,
amongst which we discuss in particular the skeptically cautious inference system, the inference
systems corresponding to (a modified version of) Walley and Bernard’s Imprecise Dirichlet
Multinomial Models (IDMM), the skeptical IDMM inference systems, and the Haldane
inference system. We also prove that the latter produces the same posterior inferences as
would be obtained using Haldane’s improper prior, implying that there is an infinity of
proper priors that produce the same coherent posterior inferences as Haldane’s improper one.
Finally, we impose an additional inference principle that allows us to characterise uniquely
the immediate predictions for the IDMM inference systems.

1. Introduction
This paper deals with predictive inference for categorical variables. We are therefore concerned
with a (possibly infinite) sequence of variables Xn that assume values in some finite set of
categories A. After having observed a number ň of them, and having found that, say X1 = x1 ,
X2 = x2 , . . . , Xň = xň , we consider some subject’s belief model for the next n̂ variables
Xň+1 , . . . Xň+n̂ . In the probabilistic tradition—and we want to build on this tradition in the
©2015 AI Access Foundation. All rights reserved.

De Cooman, De Bock, & Diniz

context of this paper—this belief can be modelled by a conditional predictive probability
mass function pn̂ (·|x1 , . . . , xň ) on the set An̂ of their possible values. These probability mass
functions can be used for prediction or estimation, for statistical inferences, and in decision
making involving the uncertain values of these variables. In this sense, predictive inference lies
at the heart of statistics, and more generally, of learning under uncertainty. For this reason,
it is also of crucial importance for dealing with uncertainty in Artificial Intelligence, where
for instance, intelligent systems have to learn about multinomial probabilities, or Markov
transition probabilities, rates of occurrence for phenomena, local probabilities in Bayesian or
credal networks and so on. We refer to the synthesis by Geisser (1993) and the collection of
essays by Zabell (2005) for good introductions to predictive inference and the underlying
issues that the present paper will also be concerned with.
What connects these predictive probability mass functions for various values of ň, n̂ and
(x1 , . . . , xň ) are the requirements of time consistency and coherence. The former requires
that when n1 ≤ n2 , then pn1 (·|x1 , . . . , xň ) can be obtained from pn2 (·|x1 , . . . , xň ) through the
usual marginalisation procedure; while the latter essentially demands that these conditional
probability mass functions should be connected with time-consistent unconditional probability
mass functions through Bayes’s Rule.
A common assumption about the variables Xn is that they are exchangeable, meaning
roughly that the subject believes that the order in which they are observed, or present
themselves, has no influence on the decisions and inferences he will make regarding these
variables. This assumption, and the analysis of its consequences, goes back to de Finetti
(1937) (see also Cifarelli & Regazzini, 1996). His famous Representation Theorem states,
in essence, that the time-consistent and coherent conditional and unconditional predictive
probability mass functions associated with a countably infinite exchangeable sequence of
variables in A are completely characterised by1 —and completely characterise—a unique
probability measure on the Borel sets of the simplex of all probability mass functions on A,
called their representation.2
This leads us to the central problem of predictive inference: since there is an infinity of
such probability measures on the simplex, which one does a subject choose in a particular
context, and how can a given choice be motivated and justified? The subjectivists of de
Finetti’s persuasion might answer that this question needs no answer: a subject’s personal
predictive probabilities are entirely his, and time consistency and coherence are the only
requirements he should heed. Earlier scholars, like Laplace and Bayes, whom we would now
also call subjectivists, invoked the Principle of Indifference to justify using a specific class of
predictive mass functions. Proponents of the logicist approach to predictive inference would
try enunciating general inference principles in order to narrow down, and hopefully eliminate
entirely, the possible choices for the representing probability measures on the simplex. The
logicians W. E. Johnson (1924) and, in a much more systematic fashion, Rudolf Carnap (1952)
1. . . . unless the observed sequence has probability zero.
2. Actually, in order to clarify the connection with what we shall do later on, the essence of de Finetti’s
argument is that the representation is a coherent prevision on the set of all multinomial polynomials—or
equivalently, of all continuous real functions—on this simplex (De Cooman, Quaeghebeur, & Miranda,
2009b). As a (finitely additive) coherent prevision, it can be extended uniquely only so far as to the set
of all lower semicontinuous functions, but it does determine a unique (countably additive) probability
measure on the Borel sets of that simplex, through the F. Riesz Representation Theorem (De Cooman &
Miranda, 2008a; Troffaes & De Cooman, 2014).

2

Coherent Predictive Inference under Exchangeability

tried to develop an axiom system for predictive inference based on such reasonable inference
principles. Carnap’s first group of axioms is related to what we have called coherence, but
as we suggested, these by themselves are too weak to single out a particular predictive
model. His second group consisted of invariance axioms, including exchangeability. He also
included an axiom of instantial relevance, translating the intuitive principle that predictive
inferences should actually learn from experience. His last axiom, predictive irrelevance, was
also proposed earlier by Johnson and called the sufficientness postulate by Good (1965).
Armed with these axioms, Carnap was able to derive a continuum of probabilistic inference
rules, closely related to the Dirichlet multinomial model and to the Imprecise Dirichlet
Multinomial Model (IDMM) proposed by Walley (1996) and Walley and Bernard (1999),
which we discuss in Appendices C and D, respectively.
Our point of view holds the middle ground between the subjectivist and logicist positions:
it should be possible for a subject to make assessments for certain predictive probabilities,
and to combine these with certain inference principles he finds reasonable, or which suit his
purpose for the problem at hand. Indeed, the inference systems we introduce and discuss
in Section 6, and the notion of conservative coherent inference—or natural extension—we
associate with them, provide an elegant framework and tools for making conservative coherent
predictive inferences that combine (local) subjective probability assessments with (general)
inference principles. And our work in Section 15 on characterising the immediate predictions
for the IDMM constitutes an exercise in—or an example for—precisely that.
This idea of conservative probabilistic inference brings us to what we believe is the
main contribution of this paper. It is a central idea in de Finetti’s (1975) approach to
probability—but also of course implicit in the Markov and Chebyshev inequalities—that
when a subject makes probability assessments, we can consider them as bounds on so-called
precise probability models. Calculating such most conservative but tightest bounds is indeed
what de Finetti’s (1975) Fundamental Theorem of Prevision (see also Lad, 1996) is about.
The theory of imprecise probabilities, brought to a synthesis by Williams (1976) and Walley
(1991, 2000), but going back to Boole (1952) and Keynes (1921), with crucial contributions
by quite a number of statisticians and philosophers (Smith, 1961; Levi, 1980; Seidenfeld,
Schervish, & Kadane, 1999), looks at conservative probabilistic inference precisely in this
way: how can we calculate as efficiently as possible the consequences—in the sense of most
conservative tightest bounds—of making certain probability assessments. These may be local
assessments, such as inequalities imposed on the probabilities or previsions of certain events
or variables, or structural assessments, such as independence, or exchangeability.
One advantage of imprecise probability models is that they allow for imprecision, or in
other words, the use of partial probability assessments using bounding inequalities rather
than equalities. Another, related, advantage is that they allow for indecision to be modelled
explicitly: loosely stated, if the imposed bounds on probabilities allow for more than one
probability model as a solution, it may very well be that of two actions, the first has the
higher expected utility for one compatible probability model, and the smaller for another
compatible probability model, meaning that neither action is robustly preferred over the other.
So with this current stated model for his beliefs, a subject is then undecided between these
actions. In Section 2, we give a concise overview of the relevant ideas, models and techniques
in the field of imprecise probabilities. A much more extensive and detailed recent overview of
this area of research was published by Augustin, Coolen, De Cooman, and Troffaes (2014).
3

De Cooman, De Bock, & Diniz

The present paper, then, can be described as an application of ideas in imprecise probabilities to predictive inference. Its aim is to study—and develop a general framework for
dealing with—conservative coherent predictive inference using imprecise probability models.
Using such models will also allow us to represent a subject’s indecision, which we believe is a
natural state to be in when knowing, or having learned little, about the problem at hand.
It seems important that theories of learning under uncertainty in general, and predictive
inference in particular, at least allow us (i) to start out with conservative, very imprecise and
indecisive models when little has been learned, and (ii) to become more precise and decisive
as more observations come in. We shall see that the abstract notion of an inference system
that we introduce further on, allows for—but does not necessarily force—such behaviour,
and we shall give a number of examples of concrete inference systems that display it.
Our work here builds on, but manages to reach much further than, an earlier paper by
one of the authors (De Cooman, Miranda, & Quaeghebeur, 2009a). One reason why it does
so, is that this earlier work deals only with immediate prediction models, and as we shall
see further on, predictive inference using imprecise probabilities is not completely determined
by immediate prediction, contrary to what we can expect when using precise probabilities.
But the main reason is that we are now in a position to use a very powerful mathematical
language to represent imprecise-probabilistic inferences: Walley’s (2000) coherent sets of
desirable gambles. Earlier imprecise probability models (Boole, 1952, 1961; Koopman, 1940)
centred on lower and upper probability bounds for events—or propositions. Later on (Walley,
1991, Section 2.7), it became apparent that this language of events and lower and upper
probabilities is lacking in power of expression: a much more expressive theory uses random
variables and their lower previsions or expectations. This successful theory of coherent lower
previsions is by now quite well developed (Walley, 1991; Augustin et al., 2014; Troffaes &
De Cooman, 2014). But it faces a number of problems, such as its mathematical as well as
conceptual complexity, especially when dealing with conditioning and independence, and
the fact that, as is the case with many other approaches to probability, and as we shall see
further on in Section 2.5, it has issues with conditioning on sets of (lower) probability zero.
A very attractive solution to these problems was offered by Walley (2000), in the form of
coherent sets of desirable gambles, inspired by earlier ideas (Smith, 1961; Williams, 1975b;
Seidenfeld, Schervish, & Kadane, 1995). Here, the primitive notions are not probabilities of
events, nor expectations of random variables. The focus is rather on whether a gamble, or
a risky transaction, is desirable to a subject—strictly preferred to the zero transaction, or
status quo. And a basic belief model is now not a probability measure or lower prevision,
but a set of desirable gambles. Of course, stating that a gamble is desirable also leads to a
particular lower prevision assessment: it provides a lower bound of zero on the prevision of
the gamble. We explain why we prefer to use sets of desirable gambles as basic uncertainty
models in Section 2.
In summary, then, our aim in this paper is to use sets of desirable gambles to extend the
existing probabilistic theory of predictive inference. Let us explain in some detail how we
intend to go about doing this. The basic building blocks are introduced in Sections 2–7. As
already indicated above, we give an overview of relevant notions and results concerning our
imprecise probability model of choice—coherent sets of desirable gambles—in Section 2. In
particular, we explain how to use them for conservative inference as well as conditioning;
4

Coherent Predictive Inference under Exchangeability

how to derive more commonly used models, such as lower previsions and lower probabilities,
from them; and how they relate to precise probability models.
In Section 3, we explain how we can describe a subject’s beliefs about a sequence of
variables in terms of predictive sets of desirable gambles, and the derived notion of predictive
lower previsions. These imprecise probability models generalise the above-mentioned predictive
probability mass functions pn̂ (·|x1 , . . . , xň ), and they constitute the basic tools we shall be
working with. We also explain what are the proper formulations for the above-mentioned
time consistency and coherence requirements in this more general context.
In Section 4, we discuss a number of inference principles that we believe could be reasonably
imposed on predictive inferences, and we show how to represent them mathematically in
terms of predictive sets of desirable gambles and lower previsions. Pooling invariance—or
what Walley (1996) has called the Representation Invariance Principle (RIP)—and renaming
invariance seem reasonable requirements for any type of predictive inference, and category
permutation invariance seems a natural thing to require when starting from a state of
complete ignorance. Taken together, they constitute what we call representation insensitivity.
It means that predictive inferences remain essentially unchanged when we transform the
set of categories, or in other words that they are essentially insensitive to the choice of
representation—the category set. Another inference principle we look at imposes the so-called
specificity property: when predictive inference is specific, then for a certain type of question
involving a restricted number of categories, a more general model can be replaced by a more
specific model that deals only with the categories of interest, and will produce the same
relevant inferences (Bernard, 1997).
The next important step is taken in Section 5, where we recall from the literature (De
Cooman et al., 2009b; De Cooman & Quaeghebeur, 2012) how to deal with exchangeability
when our predictive inference models are imprecise. We recall that de Finetti’s Representation
Theorem can be significantly generalised. In this case, the time-consistent and coherent
predictive sets of desirable gambles are completely characterised by a set of (multivariate)
polynomials on the simplex of all probability mass functions on the category set.3 This
set of polynomials must satisfy a number of properties, which taken together define the
notion of Bernstein coherence. Without becoming too technical at this point, the conclusion
of this section is that, in our more general context, the precise-probabilistic notion of a
representing probability measure on the simplex of all probability mass functions is replaced
by a Bernstein coherent set of polynomials on this simplex. This set of polynomials serves
completely the same purpose as the representing probability measure: it completely determines,
and conveniently and densely summarises, all predictive inferences. This is the reason why
the rest of the developments in the paper are expressed in terms of such Bernstein coherent
sets of polynomials.
We introduce coherent inference systems in Section 6 as maps that associate with any
finite set of categories a Bernstein coherent set of polynomials on the simplex of probability
mass functions on that set. So a coherent inference system is a way of fixing completely all
coherent predictive inferences for all possible category sets. Our reasons for introducing such
coherent inference systems are twofold. First of all, the inference principles in Section 4 impose
connections between predictive inferences for different category sets, so we can represent such
3. In contradistinction with de Finetti’s version, our version has no problems with conditioning on observed
sequences of (lower) probability zero.

5

De Cooman, De Bock, & Diniz

inference principles mathematically as restrictions on coherent inference systems, which is the
main topic of Section 7. Secondly, it allows us to extend the method of natural extension—or
conservative inference—introduced in Section 2.2, to also take into account principles for
predictive inference, or more generally, predictive inference for multiple category sets at once.
This leads to a method of combining (local) predictive probability assessments with (global)
inference principles to produce the most conservative predictive inferences compatible with
them.
As a first illustration of the power of our methodology, we look at immediate prediction
in Section 8: what implications do representation insensitivity and specificity have for
predictive inference about the single next observation? We show that our approach allows us
to streamline, simplify and significantly extend previous attempts in this direction by De
Cooman et al. (2009a).
The material in Sections 9–14 shows, by producing explicit examples, that there are
quite a few different types—even uncountable infinities—of coherent inference systems that
are representation insensitive and/or specific. We discuss the vacuous and nearly vacuous
inference systems in Sections 9 and 10, the skeptically cautious inference system in Section 11,
the family of IDMM inference systems in Section 12, the family of skeptical IDMM inference
systems in Section 13, and the Haldane inference system in Section 14. Most of these inference
systems, apart from the IDMM, appear here for the first time. Also, we believe that we are
the first to publish a detailed and explicit—as well as still elegant—proof that the IDMM
inference systems are indeed representation insensitive and specific. It should already be
mentioned here, however, that our IDMM inference systems are based on a modified, and
arguably better behaved, version of the models originally introduced by Walley and Bernard
(see Walley, 1996; Walley & Bernard, 1999; Bernard, 2005); we refer to Appendix D for more
explanation, with a proof that the original IDMM is not specific and that, contrary to what
is often claimed, it does not satisfy the so-called nestedness property.
Our results disprove the conjecture (Bernard, 2007; De Cooman et al., 2009a) that the
IDMM inference systems—our version or the original one—are the only ones, or even the
most conservative ones, that satisfy both representation insensitivity and specificity. But we
do show in Section 15 that the IDMM family of immediate predictions—which are the same
for our version and for the original one—are in a definite sense the most conservative ones
that are representation insensitive and specific, and satisfy another requirement, which we
have called ‘having concave surprise’.
In the conclusion (Section 16) we point to a number of surprising consequences of our
results, and discuss avenues for further research.
In order to make this paper as self-contained as possible, we have included a number of
appendices with additional discussion. To help the reader find his way through the many
notions and notations we need in this paper, Appendix A provides of list of the most common
ones, with a short hint at their meaning, and where they are introduced. Appendix B provides
useful and necessary background on the theory of multivariate polynomials on simplices, and
the important part that Bernstein basis polynomials have there. Our discussion of IDMM
inference systems relies quite heavily on Dirichlet densities on simplices, and the expectation
operators associated with them. We discuss their most important and relevant properties in
Appendix C. Appendix D contains a discussion of the original IDM and IDMM models, as
proposed by Walley and Bernard (see Walley, 1991, 1996; Walley & Bernard, 1999; Bernard,
6

Coherent Predictive Inference under Exchangeability

2005), where we show that some of the claims they make about this model need to be
more carefully formulated. As we stated above, this is our main reason for introducing, in
Section 12, our own modified version of the IDMM models, which does not suffer from such
shortcomings, and produces the same immediate prediction models as the original version.
Finally, in an effort to make this lengthy paper as readable as possible, we have moved all
proofs, and some additional technical discussion, to Appendix E.

2. Imprecise Probability Models
In this section, we give a concise overview of imprecise probability models for representing,
and making inferences and decisions under, uncertainty. As suggested in the Introduction,
we shall focus on sets of desirable gambles as our uncertainty models of choice.
Let us briefly summarise in the next section why, in the present paper, we work with such
sets as our basic uncertainty models for doing conservative probabilistic inference. The reader
who wants to dispense with motivation can proceed to Section 2.2, where we introduce the
mathematics behind these models. In later sections, we shall of course also briefly mention
derived results in terms of the more familiar language of (lower) previsions and probabilities.
2.1 Why Sets of Desirable Gambles?
First of all, a number of examples in the literature (Moral, 2005; Couso & Moral, 2011; De
Cooman & Quaeghebeur, 2012; De Cooman & Miranda, 2012) have shown that working
with and making inferences using such models is more general and more expressive. It is
also simpler and more elegant from a mathematical point of view, and it has a very intuitive
geometrical interpretation (Quaeghebeur, 2014). We shall see in Sections 2.4 and 3 that
marginalisation and conditioning are especially straightforward, and that there are no issues
with conditioning on sets of (lower) probability zero.
Also, it should become apparent from the discussion in Section 2.2, and has been explained
in some detail by Moral and Wilson (1995) and De Cooman and Miranda (2012), that the
similarity between accepting a gamble on the one hand and accepting a proposition to be true
on the other, gives a very ‘logical’ flavour to conservative probabilistic inference. Indeed, there
is a strong analogy between the two, which connects conservative probabilistic inference—also
called natural extension in the field—with logical deduction: where in classical propositional
logic we are looking for the smallest deductively closed set that contains a number of given
propositions, in an imprecise probabilities context we are looking for the smallest coherent set
of desirable gambles that contains a number of given gambles. In the context of this analogy,
precise probability models are closely related to complete, or maximal, deductively closed
sets—perfect information states. This is a clear indication that precise probability models by
themselves are not well suited for dealing with conservative inference, and that we need the
broader context of imprecise probability models as a natural language and setting in which
to do this. So in summary, working with sets of desirable gambles encompasses and subsumes
as special cases both classical (or ‘precise’) probabilistic inference and inference in classical
propositional logic; see the detailed discussion by De Cooman and Miranda (2012).
Finally, as we briefly explain in Section 5, De Cooman and Quaeghebeur (2012) have
shown that working with sets of coherent desirable gambles is especially illuminating in the
context of modelling exchangeability assessments: it exposes the simple geometrical meaning
7

De Cooman, De Bock, & Diniz

of the notion of exchangeability, and leads to a simple and particularly elegant proof of a
significant generalisation of de Finetti’s (1937) Representation Theorem for exchangeable
random variables.
In summary, we work with sets of desirable gambles because they are the most powerful,
expressive and general models at hand, because they are very intuitive to work with—though
unfortunately less familiar to most people not closely involved in the field—, and, very
importantly, because they avoid problems with conditioning on sets of (lower) probability
zero. For more details, we refer to the work of Walley (2000), Moral (2005), Couso and Moral
(2011), De Cooman and Quaeghebeur (2012), and Quaeghebeur (2014).
2.2 Coherent Sets of Desirable Gambles and Natural Extension
We consider a variable X that assumes values in some finite4 possibility space A. We model
a subject’s beliefs about the value of X by looking at which gambles on this variable the
subject finds desirable, meaning that he strictly prefers5 them to the zero gamble—the status
quo. This is a very general approach, that extends the usual rationalist and subjectivist
approach to probabilistic modelling to allow for indecision and imprecision.
A gamble is a real-valued function f on A. It is interpreted as an uncertain reward f (X)
that depends on the value of X, and is expressed in units of some predetermined linear utility.
It represents the reward the subject gets in a transaction where first the actual value x of
X is determined, and then the subject receives the amount of utility f (x)—which may be
negative, meaning he has to pay it. Throughout the paper, we use the device of writing f (X)
when we want to make clear what variable X the gamble f depends on.
Events are subsets of the possibility space A. With any event B ⊆ A we can associate a
special gamble IB , called its indicator, which assumes the value 1 on B and 0 elsewhere.
We denote the set of all gambles on A by L(A). It is a linear space under point-wise
addition of gambles, and point-wise multiplication of gambles with real numbers. For any
subset A of L(A), posi(A) is the set of all positive linear combinations of gambles in A:
posi(A) :=

{︂∑︁
n

}︂
λk fk : fk ∈ A, λk ∈ R>0 , n ∈ N .

(1)

k=1

Here, N is the set of natural numbers (without zero), and R>0 is the set of all positive real
numbers. A convex cone of gambles is a subset A of L(A) that is closed under positive linear
combinations, meaning that posi(A) = A.
For any two gambles f and g on A, we write ‘f ≥ g’ if (∀x ∈ A)f (x) ≥ g(x), and ‘f > g’
if f ≥ g and f 6= g. A gamble f > 0 is called positive. A gamble g ≤ 0 is called non-positive.
4. For the sake of simplicity, we restrict this discussion to finite possibility spaces, because this is all we
really need for the purposes of this paper. In a very limited number of remarks further on, we shall have
occasion to mention related notions for infinite possibility spaces, but we will give ample references there
to guide the interested reader to the relevant literature.
5. We want to point out that the notion of strict preference—or preference without indifference—commonly
used in preference modelling, should not be confused with Walley’s (1991, Section 3.7.7) notion of strict
desirability, which is only one of the many ways to construct from a lower prevision a set of gambles that
are strictly preferred to the zero gamble; see also the discussion near the end of Section 2.5. For more
details, we refer to a recent paper by Quaeghebeur, De Cooman, and Hermans (2014).

8

Coherent Predictive Inference under Exchangeability

L>0 (A) denotes the convex cone of all positive gambles, and L≤0 (A) the convex cone of all
non-positive gambles.
We collect the gambles that a subject finds desirable—strictly prefers6 to the zero gamble—
into his set of desirable gambles, and we shall take such sets as our basic uncertainty models.
Of course, they have to satisfy certain rationality criteria:
Definition 1 (Coherence). A set of desirable gambles D ⊆ L(A) is called coherent if it
satisfies the following requirements:
D1. 0 ∈
/ D;
D2. L>0 (A) ⊆ D;
D3. D = posi(D).
D(A) denotes the set of all coherent sets of desirable gambles on A.
Requirement D3 turns D into a convex cone. Due to D2, it includes L>0 (A); by D1–D3, it
avoids non-positivity:
D4. if f ≤ 0 then f ∈
/ posi(D), or equivalently L≤0 (A) ∩ posi(D) = ∅.
L>0 (A) is the smallest coherent subset of L(A). This so-called vacuous model therefore
reflects minimal commitments on the part of the subject: if he knows absolutely nothing
about the likelihood of the different outcomes, he will only strictly prefer to zero those
gambles that never decrease his wealth and have some possibility of increasing it.
When D1 ⊆ D2 , a subject with a set of desirable gambles D1 is more conservative, or less
committal, than a subject with a set of desirable gambles D2 , simply because the latter strictly
prefers to zero all the gambles that the former does, and possibly more. The inclusion relation
imposes a natural partial ordering on sets of desirable gambles, with a simple interpretation
of ‘is at least as conservative as’.
⋂︀ For any non-empty family of coherent sets of desirable gambles Di , i ∈ I, its intersection
i∈I Di is still coherent. This simple result underlies the notion of (conservative) coherent
inference. If a subject gives us an assessment—a set A ⊆ L(A) of gambles on A that he
finds desirable—then it tells us exactly when this assessment can be extended to a coherent
set of desirable gambles, and how to construct the smallest—and therefore least committal
or most conservative—such set:
Theorem 2 (Natural Extension, De Cooman & Quaeghebeur, 2012). Let A ⊆ L(A), and
define its natural extension by:7
⋂︁
EA :=
{D ∈ D(A) : A ⊆ D} .
Then the following statements are equivalent:
(i) A avoids non-positivity: L≤0 (A) ∩ posi(A) = ∅;
(ii) A is included in some coherent set of desirable gambles;
6. See footnote 5.
⋂︀
7. As usual, in this expression, we let ∅ = L(A).

9

De Cooman, De Bock, & Diniz

(iii) EA 6= L(A);
(iv) the set of desirable gambles EA is coherent;
(v) EA is the smallest coherent set of desirable gambles that includes A.
When any (and hence all) of these equivalent statements holds, EA = posi(L>0 (A) ∪ A).
Moreover, A is coherent if and only if A 6= L(A) and EA = A.
2.3 Maximal Coherent Sets of Desirable Gambles
An element D of D(A) is called maximal if it is not strictly included in any other element of
D(A), or in other words, if adding any gamble f to D makes sure we can no longer extend
the set D ∪ {f } to a set that is still coherent:
(∀D0 ∈ D(A))(D ⊆ D0 ⇒ D = D0 ).
M(A) denotes the set of all maximal elements of D(A). A coherent set of desirable gambles
D is maximal if and only if for all non-zero gambles f on A, f ∈
/ D ⇒ −f ∈ D (see Couso &
Moral, 2011 for the case of finite A, and De Cooman & Quaeghebeur, 2012 for the infinite
case). Coherence and natural extension can be described completely in terms of maximal
elements:
Theorem 3 (Couso & Moral, 2011; De Cooman & Quaeghebeur, 2012). A set A avoids
non-positivity
if and only if there is some maximal D ∈ M(A) such that A ⊆ D. Moreover,
⋂︀
EA = {D ∈ M(A) : A ⊆ D}.
2.4 Conditioning with Sets of Desirable Gambles
Let us suppose that our subject has a coherent set D of desirable gambles on A, expressing his
beliefs about the value that a variable X assumes in A. We can then ask what his so-called
updated set DcB of desirable gambles on B would be, were he to receive the additional
information—and nothing more—that X actually belongs to some subset B of A. The
updating, or conditioning, rule for sets of desirable gambles states that:
g ∈ DcB ⇔ gIB ∈ D for all gambles g on B.

(2)

It states that the gamble g is desirable to a subject were he to observe that X ∈ B if
and only if the called-off gamble gIB is desirable to him. This called-off gamble gIB is the
gamble on the variable X that gives a zero reward—is called off—unless X ∈ B, and in
that case reduces to the gamble g on the new possibility space B. The updated set DcB
is a set of desirable gambles on B that is still coherent, provided that D is (De Cooman
& Quaeghebeur, 2012). See the discussions by Moral (2005), Couso and Moral (2011), De
Cooman and Quaeghebeur (2012), De Cooman and Miranda (2012) and Quaeghebeur (2014)
for more detailed information on updating sets of desirable gambles.
2.5 Coherent Lower Previsions
We now use coherent sets of desirable gambles to introduce derived concepts, such as coherent
lower previsions, and probabilities.
10

Coherent Predictive Inference under Exchangeability

Given a coherent set of desirable gambles D, the functional P defined on L(A) by
P (f ) := sup {µ ∈ R : f − µ ∈ D} for all f ∈ L(A),

(3)

is a coherent lower prevision (Walley, 1991, Thm. 3.8.1). This means that it is a lower
envelope of the expectations associated with some set of probability mass functions,8 or,
equivalently, that it satisfies the following coherence properties (Walley, 1991, 2000; De
Cooman & Quaeghebeur, 2012; Miranda & De Cooman, 2014; Troffaes & De Cooman, 2014):
P1. P (f ) ≥ min f for all gambles f on A;
P2. P (f + g) ≥ P (f ) + P (g) for all gambles f, g on A;
P3. P (λf ) = λP (f ) for all gambles f on A and all real λ ≥ 0.
Here we used the notation min f := min {f (x) : x ∈ A}; max f is defined similarly. The
conjugate upper prevision P is defined by P (f ) := inf {µ ∈ R : µ − f ∈ D} = −P (−f ). The
following properties are implied by P1–P3:
P4. max f ≥ P (f ) ≥ P (f ) ≥ min f for all gambles f on A;
P5. P (f + µ) = P (f ) + µ and P (f + µ) = P (f ) + µ for all gambles f on A and all µ ∈ R.
For any gamble f , P (f ) is called the lower prevision of f , and it follows from Equation (3)
that it can be interpreted as the subject’s supremum desirable price for buying the gamble f .
For any event B, P (IB ) is also denoted by P (B), and called the lower probability of B; it
can be interpreted as the subject’s supremum desirable rate for betting on B. Similarly for
upper previsions and upper probabilities.
The lower prevision associated with the vacuous set of desirable gambles L>0 (A) is given
by P (f ) = min f . It is called the vacuous lower prevision, and it is the point-wise smallest,
or most conservative, of all coherent lower previsions.
The coherent conditional model DcB, with B a non-empty subset of A, induces a conditional lower prevision P (·|B) on L(B), by invoking Equation (3):
P (g|B) := sup {µ ∈ R : g − µ ∈ DcB} = sup {µ ∈ R : [g − µ]IB ∈ D}
for all gambles g on B. (4)
It is not difficult to show (Walley, 1991) that P and P (·|B) are related through the following
coherence condition:
P ([g − P (g|B)]IB ) = 0 for all g ∈ L(B),
(GBR)
called the Generalised Bayes Rule. This rule allows us to infer P (·|B) uniquely from P ,
provided that P (B) > 0. Otherwise, there is usually an infinity of coherent lower previsions
P (·|B) that are coherent with P in the sense that they satisfy (GBR), or equivalently, that
there is some coherent set of desirable gambles D that leads to both P and P (·|B). Two
8. This statement is valid because we are working with finite A. For infinite A, similar results can be shown
to hold (Walley, 1991; De Cooman & Quaeghebeur, 2012; Miranda & De Cooman, 2014; Troffaes &
De Cooman, 2014), and then the expectations involved are coherent previsions—expectation operators
associated with finitely additive probability measures. See also the discussion in Section 2.6.

11

De Cooman, De Bock, & Diniz

particular conditioning rules, namely natural and regular extension (Walley, 1991; Miranda
& De Cooman, 2014), always produce conditional lower previsions that satisfy GBR, and
are therefore coherent with P . When P (B) > 0—but not necessarily when P (B) = 0!—they
always produce the point-wise smallest and largest coherent conditional lower previsions,
respectively (Miranda, 2009; Miranda & De Cooman, 2014).9
Many different coherent sets of desirable gambles lead to the same coherent lower prevision
P , and they typically differ only in their boundaries. In this sense, coherent sets of desirable
gambles are more informative than coherent lower previsions: a gamble with positive lower
prevision is always desirable and one with a negative lower prevision never, but a gamble
with zero lower prevision lies on the border of the set of desirable gambles, and the lower
prevision does not generally provide information about the desirability of such gambles. If
such border behaviour is important—and it is when dealing with conditioning on events with
zero (lower) probability (Walley, 2000; Moral, 2005; Couso & Moral, 2011; Quaeghebeur,
2014)—it is useful to work with sets of desirable gambles rather than lower previsions, because
as Equations (2) and (4) tell us, they allow us to derive unique conditional models from
unconditional ones: with a coherent set of desirable gambles D there corresponds a unique
conditional set of desirable gambles DcB and a unique conditional lower prevision P (·|B), for
any non-empty event B. The smallest set of desirable gambles that induces a given coherent
lower prevision, is called the associated set of strictly desirable gambles (Walley, 1991) and is
given by {f ∈ L(A) : f > 0 or P (f ) > 0}. See the papers by Walley (2000) and Quaeghebeur
(2014) for additional discussion about why sets of desirable gambles are more informative
than coherent lower previsions.
2.6 Linear Previsions and Credal Sets
When the coherent lower and the upper prevision coincide on all gambles, then the real
functional P defined on L(A) by P (f ) := P (f ) = P (f ) for all f ∈ L(A) is a coherent prevision.
Since we assumed that A is finite,10 this means that it corresponds
to the expectation
∑︀
operator associated with a probability mass function p: P (f ) = x∈A f (x)p(x) =: Ep (f ) for
all f ∈ L(A), where p(x) := P (I{x} ) for all x ∈ A. This happens in particular if the lower
and upper previsions are induced by a maximal coherent set of desirable gambles. Indeed, up
to boundary behaviour, the so-called precise probability models P correspond to maximal
coherent sets of desirable gambles; see the discussions by Williams (1975a), Miranda and
Zaffalon (2011, Proposition 6) and Couso and Moral (2011, Section 5) for more information.
For coherent previsions P , the Generalised Bayes Rule (GBR) reduces to Bayes’s Rule:
P (gIB ) = P (B)P (g|B) for all g ∈ L(B),

(BR)

indicating that this central probabilistic updating rule is a special case of Equation (2).
9. The conditional lower previsions in Section 12 on the IDMM are produced by regular extension. The
models in Sections 11, 13 and 14 have the same lower previsions amongst them, but in nearly all cases have
very different conditional lower previsions, even though in these cases the natural and regular extensions
coincide—they are vacuous there.
10. As already hinted at in footnote 8, similar things can still be said for infinite A, but this would unduly
complicate the discussion. For more details, see the work by Walley (1991), Troffaes and De Cooman
(2014) and Miranda and De Cooman (2014).

12

Coherent Predictive Inference under Exchangeability

Because we assumed that A is finite, we can define the so-called credal set M(P ) associated
with a coherent lower prevision P as:
M(P ) := {p ∈ ΣA : (∀f ∈ L(A))Ep (f ) ≥ P (f )} ,
which is a closed and convex subset of the so-called simplex ΣA of all probability mass
functions on A.11 Then P is the lower envelope of M(P ): P (f ) = min {Ep (f ) : p ∈ M(P )}
for all f ∈ L(A) (Walley, 1991; Miranda & De Cooman, 2014; Troffaes & De Cooman,
2014). In this sense, such convex closed sets of precise probability models can also be seen
as imprecise probability models, and they are mathematically equivalent to coherent lower
previsions. They are therefore also less general and powerful than coherent sets of desirable
gambles, and also suffer from problems with conditioning on events with (lower) probability
zero.12

3. Predictive Inference
Predictive inference, in the specific sense we are focussing on here, considers a number of
variables X1 , . . . , Xn assuming values in the same category set A—we define a category set
as any non-empty finite set.13 In what follows, we shall have occasion to use many different
category sets, and we shall use italic capitals such as A, B, C, D, . . . to refer to them.
We start our discussion of predictive inference models in the most general and representationally powerful language: coherent sets of desirable gambles, as introduced in the previous
section. Further on, we shall also pay some attention to more specific derived models, such
as predictive lower previsions, and predictive lower probabilities.
Predictive inference assumes generally that a number ň of observations have been made,
ˇ = (x1 , . . . , xň ) of the first ň variables X1 , . . . , Xň . Based on this
so we know the values 𝑥
n̂ c𝑥
ˇ for the values
ˇ a subject then has a posterior predictive model DA
observation sample 𝑥,
n̂
n̂
ˇ is a coherent set of
that the next n̂ variables Xň+1 , . . . , Xň+n̂ assume in A . This DA c𝑥
desirable gambles f (Xň+1 , . . . , Xň+n̂ ) on An̂ . Here we assume that n̂ ∈ N. On the other
hand, we want to allow that ň ∈ N0 := N ∪ {0}, which is the set of all natural numbers with
zero: we also want to be able to deal with the case where no previous observations have been
n̂ a prior predictive model.14 Of course,
made. In that case, we call the corresponding model DA
technically speaking, ň + n̂ ≤ n.
As we said, the subject may also have a prior, unconditional model, for when no obn of
servations have yet been made. In its most general form, this will be a coherent set DA
11. See Section 5.2 for an explicit definition of ΣA .
12. Using sets of full conditional measures (Dubins, 1975; Cozman, 2013), rather than sets of probability
mass functions, leads to an imprecise probability model that is related to sets of desirable gambles (Couso
& Moral, 2011), and has no problems with conditioning on sets of lower probability zero either, but we
feel it is less elegant and mathematically more complicated.
13. For formal reasons, we include the trivial case of category sets with a single element, in which case we are
certain about the value that the variables assume.
14. So the terms ‘posterior’ and ‘prior’ in association with predictive models indicate whether or not previous
observations have been made. But, in order to avoid the well-known issues with temporal coherence
(Zaffalon & Miranda, 2013), we are assuming here that the prior and posterior models are based on a
subject’s beliefs before any observations have been made, so the posterior models refer to hypothetical
future situations.

13

De Cooman, De Bock, & Diniz

n̂
desirable gambles f (X1 , . . . , Xn ) on An , for some n ∈ N. He may also have coherent sets DA
n̂
of desirable gambles f (X1 , . . . , Xn̂ ) on A , where n̂ can be any natural number such that
n̂ and D n must then be related to each other through the following
n̂ ≤ n; and the sets DA
A
marginalisation, or time consistency, requirement:15
n̂
n
f (X1 , . . . , Xn̂ ) ∈ DA
⇔ f (X1 , . . . , Xn̂ ) ∈ DA
for all gambles f on An̂ .

(5)

In this expression, and throughout this paper, we identify a gamble f on An̂ with its cylindrical
extension f 0 on An , defined by f 0 (x1 , . . . , xn̂ , . . . , xn ) := f (x1 , . . . , xn̂ ) for all (x1 , . . . , xn ) ∈ An .
If we introduce the marginalisation operator margn̂ (·) := · ∩ L(An̂ ), then the time consistency
n̂ = marg (D n ) = D n ∩ L(An̂ ).
condition can also be rewritten simply as DA
n̂
A
A
n and posterior (conditional) ones D n̂ c𝑥
Prior (unconditional) predictive models DA
A ˇ must
also be related through the following updating requirement:
n̂
n
ˇ ⇔ f (Xň+1 , . . . , Xň+n̂ )I{𝑥}
f (Xň+1 , . . . , Xň+n̂ ) ∈ DA
c𝑥
ˇ (X1 , . . . , Xň ) ∈ DA

for all gambles f on An̂ , (6)
which is a special case of Equation (2): the gamble f (Xň+1 , . . . , Xň+n̂ ) is desirable after observˇ if and only if the gamble f (Xň+1 , . . . , Xň+n̂ )I{𝑥}
ing the sample 𝑥
ˇ (X1 , . . . , Xň ) is desirable
before any observations are made. This called-off gamble f (Xň+1 , . . . , Xň+n̂ )I{𝑥}
ˇ (X1 , . . . , Xň )
ˇ
is the gamble that gives zero reward—is called off—unless the first ň observations are 𝑥,
and in that case reduces to the gamble f (Xň+1 , . . . , Xň+n̂ ) on the remaining variables
Xň+1 , . . . , Xň+n̂ . The updating requirement is a generalisation of Bayes’s Rule for updating,
and in fact reduces to it when the sets of desirable gambles lead to (precise) probability
mass functions, as described in Section 2.6 and proved in detail by Walley (2000) and also
by De Cooman and Miranda (2012). But contrary to Bayes’s Rule for probability mass
functions, the updating rule (6) for coherent sets of desirable gambles clearly does not suffer
from problems when the conditioning event has (lower) probability zero: it allows us to infer
a unique conditional model from an unconditional one, regardless of the (lower or upper)
probability of the conditioning event. We refer to the work of De Cooman and Miranda
(2012) for detailed discussions of marginalisation and updating of sets of desirable gambles in
a many-variable context.
As explained in Section 2.5, we can use the relationship (3) to derive prior (unconditional)
n through:
predictive lower previsions P n̂A (·) on L(An̂ ) from the prior set DA
n
P n̂A (f ) := sup {µ ∈ R : f − µ ∈ DA
} for all gambles f on An̂ and all 1 ≤ n̂ ≤ n,

ˇ on L(An̂ ) from the posterior
and posterior (conditional) predictive lower previsions P n̂A (·|𝑥)
n̂
ˇ through:
sets DA c𝑥
{︁
}︁
n̂
ˇ := sup µ ∈ R : f − µ ∈ DA
ˇ for all gambles f on An̂ .
P n̂A (f |𝑥)
c𝑥
15. See also the related discussion of this notion by De Cooman and Miranda (2008b) and De Cooman and
Quaeghebeur (2012); it should not be confused with the temporal consistency discussed by Goldstein
(1983, 1985) and Zaffalon and Miranda (2013).

14

Coherent Predictive Inference under Exchangeability

Further on, we shall also want to condition predictive lower previsions on the additional
information that (Xň+1 , . . . , Xň+n̂ ) ∈ B n̂ , for some proper subset B of A. Using the ideas in
Sections 2.4 and 2.5, this leads for instance to the following lower prevision:
{︁
}︁
n̂
ˇ B n̂ ) := sup µ ∈ R : [g − µ]IB n̂ ∈ DA
ˇ for all gambles g on B n̂ ,
P n̂A (g|𝑥,
c𝑥
(7)
ˇ conditioned on the event B n̂ .
which is the lower prevision P n̂A (·|𝑥)

4. Principles for Predictive Inference
So far, we have introduced coherence, marginalisation and updating as basic rationality
requirements that prior and posterior predictive inference models must satisfy. But it could
be envisaged that other requirements—other inference principles—can be imposed on our
inference models. Because we want to show further on how to deal with such additional
requirements in a theory for conservative predictive inference, we now discuss, by way of
examples, a number of additional conditions, which have been suggested by a number of
authors as reasonable properties of—or requirements for—predictive inference models. We
want to stress here that by considering these requirements as examples, we do not want to
defend using them in all circumstances, or mean to suggest that they are always reasonable or
useful. They are what they are: inference principles that we might want to impose, and whose
implications for conservative predictive inference we might therefore want to investigate.
4.1 Pooling Invariance
We first consider Walley’s (1996) notion of representation invariance, which we prefer to call
pooling invariance. Consider any set of categories A, and a partition B of A with non-empty
partition classes. We can of course consider the partition B as a set of categories as well.
Therefore, in order to streamline the discussion and notation, we shall henceforth denote it
by B—as stated before, we want to use italic capitals for category sets. Each of its elements—
some subset C of A—corresponds to a single new category, which consists of the original
categories x ∈ C being pooled—considered as one. Denote by ρ(x) the unique element of the
partition B that an original category x ∈ A belongs to. This leads us to consider a surjective
(onto) map ρ from A to B.
We say that a gamble g on An does not differentiate between pooled categories when:
g(𝑥) = g(𝑦) for all 𝑥, 𝑦 ∈ An such that (∀k ∈ {1, . . . , n})ρ(xk ) = ρ(yk ),
which means that there is some gamble f on B n such that:
(∀𝑥 ∈ An )g(𝑥) = f (ρ(x1 ), . . . , ρ(xn )).
The idea underlying this formula—or requirement—is that with a sample 𝑥 = (x1 , . . . , xn ) ∈
An , there corresponds a sample ρ𝑥 := (ρ(x1 ), . . . , ρ(xn )) ∈ B n of pooled categories. Pooling
invariance requires that for gambles g = f ◦ ρ that do not differentiate between pooled
categories, it should make no difference whether we make predictive inferences using the set
of original categories A, or using the set of pooled categories B. More formally, in terms of
predictive lower previsions:

15

De Cooman, De Bock, & Diniz

ˇ = P n̂B (f |ρ𝑥)
ˇ
P n̂A (f ◦ ρ) = P n̂B (f ) and P n̂A (f ◦ ρ|𝑥)
ˇ ∈ Aň ,
for all ň, n̂ ∈ N considered, all gambles f on B n̂ and all 𝑥
or alternatively, and more generally, in terms of predictive sets of desirable gambles:
n̂
n̂
n̂
n̂
ˇ ⇔ f ∈ DB
ˇ
f ◦ ρ ∈ DA
⇔ f ∈ DB
and f ◦ ρ ∈ DA
c𝑥
cρ𝑥

ˇ ∈ Aň .
for all ň, n̂ ∈ N considered, all gambles f on B n̂ and all 𝑥
Pooling invariance seems a reasonable principle to uphold in cases where the category
set is not known in full detail. In that case it is useful to start from a limited set of broadly
defined categories, and allow the creation of new ones, by pooling or splitting old categories
as the observations proceed. In this context, recall Walley’s (1996) example: if we have a
closed bag containing coloured marbles, what is the probability of drawing a red marble
from it? With no further information, our subject has no idea about the colours of the
marbles in the bag, making it difficult to construct a suitable detailed category set for
such an experiment. After a few draws from the bag, if the predictive inference model used
respects pooling invariance, the inferences that are made about red marbles when he uses
the category set {red, yellow, blue, other} should be the same as those using the category
set {red, non-red}, where all the colours different from red are pooled together into a single
category. It appears that pooling invariance is a typically useful principle, for instance, in
sampling species problems, when one wants to assess the prevalence of a given species in
certain area.
There is a special case of pooling invariance, called embedding invariance,16 which concentrates on the case without prior observations. In terms of lower previsions:
P n̂A (f ◦ ρ) = P n̂B (f ) for all n̂ ∈ N considered, and all gambles f on B n̂ ,
or alternatively, and more generally, in terms of sets of desirable gambles:
n̂
n̂
f ◦ ρ ∈ DA
⇔ f ∈ DB
for all n̂ ∈ N considered, and all gambles f on B n̂ .

4.2 Renaming Invariance
Besides pooling invariance, we may also require renaming invariance: as long as no confusion
can arise, it should not matter for a subject’s predictive inferences what names, or labels, he
gives to the different categories.
This may seem too trivial to even mention, and as far as we know, it is always implicitly
taken for granted in predictive inference. But it will be well to devote some attention to it
here, in order to distinguish it from the category permutation invariance to be discussed
shortly, with which it is easily confused if we do not pay proper attention. If we have a
renaming bijection (a one-to-one and onto map) λ between a set of original categories A
and a set of renamed categories C, where we clearly distinguish between the elements of
A and those of C, then with a sample 𝑥 = (x1 , . . . , xn ) ∈ An of original categories, there
corresponds a sample of renamed categories λ𝑥 := (λ(x1 ), . . . , λ(xn )). And with a gamble
16. Walley calls the underlying requirement that the (lower) probability of an event A should not depend on
the possibility space into which A is embedded, the Embedding Principle (Walley, 1991, Section 5.5.1).

16

Coherent Predictive Inference under Exchangeability

f on the set C n of renamed samples, there corresponds a gamble f ◦ λ on the set An of
original samples. Clearly, we can then require that it should make no difference whether we
make predictive inferences using the set of original categories A, or using the set of renamed
categories C. More formally, in terms of predictive lower previsions:
ˇ = P n̂C (f |λ𝑥)
ˇ
P n̂A (f ◦ λ) = P n̂C (f ) and P n̂A (f ◦ λ|𝑥)
ˇ ∈ Aň ,
for all ň, n̂ ∈ N considered, all gambles f on C n̂ and all 𝑥
or alternatively, and more generally, in terms of predictive sets of desirable gambles:
n̂
n̂
n̂
n̂
ˇ ⇔ f ∈ DC
ˇ
f ◦ λ ∈ DA
⇔ f ∈ DC
and f ◦ λ ∈ DA
c𝑥
cλ𝑥

ˇ ∈ Aň .
for all ň, n̂ ∈ N considered, all gambles f on C n̂ and all 𝑥
4.3 Category Permutation Invariance
We shall be especially interested in predictive inference where a subject starts from a state of
prior ignorance. In such a state, he has no reason to distinguish between the different elements
of any set of categories A he has chosen. To formalise this idea, consider a permutation
$ of the elements of A.17 With a sample 𝑥 in An , there corresponds a permuted sample
$𝑥 := ($(x1 ), . . . , $(xn )). And with any gamble f on An , there corresponds a permuted
gamble f ◦ $ on An . If a subject has no reason to distinguish between categories z and their
images $(z), it make sense to require the following category permutation invariance:18
ˇ = P n̂A (f |$𝑥)
ˇ
P n̂A (f ◦ $) = P n̂A (f ) and P n̂A (f ◦ $|𝑥)
ˇ ∈ Aň ,
for all ň, n̂ ∈ N considered, all gambles f on An̂ and all 𝑥
or alternatively, and more generally, in terms of predictive sets of desirable gambles:
n̂
n̂
n̂
n̂
ˇ ⇔ f ∈ DA
ˇ
f ◦ $ ∈ DA
⇔ f ∈ DA
and f ◦ $ ∈ DA
c𝑥
c$𝑥

ˇ ∈ Aň .
for all ň, n̂ ∈ N considered, all gambles f on An̂ and all 𝑥
Formally, this requirement closely resembles renaming invariance, but whereas the latter is
a trivial requirement, category permutation invariance is a symmetry requirement between
categories that can only be justified when our subject has no reason to distinguish between
them, which may for instance be justified when he starts out from a state of prior ignorance.
To draw attention to the difference between the two in a somewhat loose manner: category
permutation invariance allows for confusion between new and old categories, something which
renaming invariance carefully avoids.
To see why such a principle could be reasonable, recall Walley’s (1996) bag of marbles
example, introduced above when discussing pooling invariance. Since, before having drawn any
17. This permutation $ of the elements of A, or in other words of the categories, should be contrasted with
permutations π of the order of the observations, i.e. of the time set {1, . . . , n}, considered in our discussion
of exchangeability, further on in Section 5.
18. This requirement is related to the notion of (weak) permutation invariance that De Cooman and Miranda
(2007) have studied in much detail in a paper dealing with symmetry in uncertainty modelling. It goes
back to Walley’s (1991, Section 5.5.1) Symmetry Principle.

17

De Cooman, De Bock, & Diniz

marbles from the bag, our subject has no idea how the marbles are coloured, he is in a state
of complete prior ignorance. Therefore, if he starts out with the sample space {red, non-red},
and observes the outcomes of a few draws, say twice non-red, he can consider the probability
of obtaining a red marble on the next draw. But due to the symmetry originating in complete
ignorance, if he were to permute the categories, calling the red marbles ‘non-red’ and the
non-red ones ‘red’, the situation he is now looking at is completely the same as before, and
therefore his probability of obtaining a non-red marble on the next draw after observing
twice red, must be the same as that for observing a red one, after observing non-red twice.
This principle is reminiscent of the Axiom A8 proposed by Carnap (1952) for his system of
inductive logic. Of course, this is not a reasonable principle when our subject has some prior
knowledge about the problem that would, for instance, allow him to impose an ordering on
the categories.
4.4 Representation Insensitivity
We shall call representation insensitivity the combination of pooling, renaming and category
permutation invariance. It means that predictive inferences remain essentially unchanged
when we transform the set of categories, or in other words that they are insensitive to
the choice of representation—the category set. It is not difficult to see that representation
insensitivity can be formally characterised as follows. Consider two category sets A and
D such that there is a so-called relabelling map ρ : A → D that is onto, i.e. such that
D = ρ(A) := {ρ(x) : x ∈ A}. Then with a sample 𝑥 in An , there corresponds a transformed
sample ρ𝑥 := (ρ(x1 ), . . . , ρ(xn )) in Dn . And with any gamble f on Dn there corresponds a
gamble f ◦ ρ on An .
4.4.1 Representation Insensitivity
For all category sets A and D such that there is an onto map ρ : A → D, all ň, n̂ ∈ N
ˇ ∈ Aň and all gambles f on Dn̂ :
considered, all 𝑥
ˇ = P n̂D (f |ρ𝑥),
ˇ
P n̂A (f ◦ ρ) = P n̂D (f ) and P n̂A (f ◦ ρ|𝑥)

(RI1)

or alternatively, and more generally, in terms of predictive sets of desirable gambles:
n̂
n̂
n̂
n̂
ˇ ⇔ f ∈ DD
ˇ
f ◦ ρ ∈ DA
⇔ f ∈ DD
and f ◦ ρ ∈ DA
c𝑥
cρ𝑥.

(RI2)

There is also the weaker combination of pooling, renaming and category permutation
invariance for models with no prior observations.
4.4.2 Prior Representation Insensitivity
For all category sets A and D such that there is an onto map ρ : A → D, all n̂ ∈ N considered
and all gambles f on Dn̂ :
P n̂A (f ◦ ρ) = P n̂D (f ),
(EI1)
or alternatively, and more generally, in terms of sets of desirable gambles:
n̂
n̂
f ◦ ρ ∈ DA
⇔ f ∈ DD
.

18

(EI2)

Coherent Predictive Inference under Exchangeability

4.5 Specificity
We now turn to another, rather peculiar but in our view intuitively appealing, potential property of predictive inferences. Assume that in addition to observing a sample of observations
ˇ of ň observations in a category set A, our subject comes to know or determine in some
𝑥
way that the n̂ following observations will belong to a proper subset B of A, and nothing
else—we might suppose for instance that an observation of (Xň+1 , . . . , Xň+n̂ ) has been made,
but that it is imperfect, and only allows him to conclude that (Xň+1 , . . . , Xň+n̂ ) ∈ B n̂ .
We can then impose the following requirement, which uses models conditioned on the
event B n̂ . Such conditional models have been introduced through Equations (2) and (4); see
also the discussion leading to Equation (7), near the end of Section 3.
4.5.1 Specificity
ˇ ∈ Aň and all
For all category sets A and B such that B ⊆ A, all ň, n̂ ∈ N considered, all 𝑥
gambles f on B n̂ :
ˇ B n̂ ) = P n̂B (f |𝑥↓
ˇ B ),
P n̂A (f |B n̂ ) = P n̂B (f ) and P n̂A (f |𝑥,

(SP1)

or alternatively, and more generally, in terms of predictive sets of desirable gambles:
n̂
n̂
n̂
n̂
ˇ ⇔ f ∈ DB
ˇ B,
f IB n̂ ∈ DA
⇔ f ∈ DB
and f IB n̂ ∈ DA
c𝑥
c𝑥↓

(SP2)

ˇ B is the tuple of observations obtained by eliminating from the tuple 𝑥
ˇ all observawhere 𝑥↓
ˇ B is the empty tuple, so when no observations in
tions not in B. In these expressions, when 𝑥↓
ˇ are in B, the ‘posterior’ predictive model is simply taken to reduce to the ‘prior’ predictive
𝑥
model.
Specificity means that the predictive inferences that a subject makes are the same as the
ones he would get by focussing on the category set B, and at the same time discarding all the
previous observations producing values outside B, in effect only retaining the observations
that were inside B! It is as if knowing that the future observations belong to B allows our
subject to ignore all the previous observations that happened to lie outside B. The term
specificity in this context seems to have been proposed by Bernard (1997, 2005), based on
work by Rouanet and Lecoutre (1983). In a so-called specific inference approach, for questions,
inferences and decisions involving only a restricted number of categories, a more general
model can be replaced by a more specific model that deals only with the categories of interest,
and if specificity is respected, the general and the specific models will produce the same
inferences. Specificity seems to be a relevant principle when analysing categorical data that
can be described by tree structures, as in the case of, for instance, patients that are classified
according to symptoms (Bernard, 1997).
To give a very simple example involving, once again, Walley’s bag of marbles, our subject
may have observed, after some drawings, green, red, blue and white marbles. He is asked for
his probability of drawing a red marble next, but some other observer has already seen what
it is, and informs us that it is either green or red—perhaps due to bad lighting conditions or
because she’s colour blind. If the subject uses a specific inference model, he can disregard
the previous observations involving other colours than green and red.
19

De Cooman, De Bock, & Diniz

4.6 Prior Near-Ignorance
We use the notion of near-ignorance as defined by Walley (1991, p. 521) to give the following
definition of prior near-ignorance in our context of predictive inference; see also the related
discussions by Walley (1991, Section 5.3.2), Walley (1997, Section 3) and Walley and Bernard
(1999, Section 2.3). We also refer to the paper by Piatti, Zaffalon, Trojani, and Hutter (2009)
for an interesting discussion of why prior near-ignorance may produce undesirable results in
certain contexts.
4.6.1 Prior Near-Ignorance
The prior model for any single variable Xk assuming values in some arbitrary category set A
is vacuous, so for any category set A, any n̂ ∈ N considered, any 1 ≤ k ≤ n̂ and all gambles
f on A:
P n̂A (extn̂k (f )) = min f,
or alternatively, and more generally, in terms of sets of desirable gambles:
n̂
extn̂k (f ) ∈ DA
⇒ f > 0,

where extn̂k (f ) denotes the cylindrical extension of f to a gamble on An̂ . It is defined by
extn̂k (f )(x1 , . . . , xn̂ ) := f (xk ) for all (x1 , . . . , xn̂ ) ∈ An̂ . A perhaps more intuitive, if less
formally correct, notation for this gamble is f (Xk ).
Theorem 4. Prior representation insensitivity implies prior near-ignorance.
This simple result implies that no model all of whose predictive previsions are precise can
be prior representation insensitive, let alone representation insensitive, as its prior model
for immediate predictions should then be vacuous. We shall see in Section 14 that it is
nevertheless possible for representation insensitive coherent inferences to deploy precise
posterior predictive previsions.

5. Adding Exchangeability to the Picture
We are now, for the remainder of this paper, going to add two additional assumptions.
The first assumption is that there is, in principle, no upper bound on the number of
variables that we can take into account. In other words, when we are considering n variables
X1 , . . . , Xn , we can always envisage looking at one more variable Xn+1 . This effectively
means that we are dealing with a countably infinite sequence of variables X1 , . . . , Xn , . . .
that assume values in the same category set A.
n of coherent
For our predictive inference models, this means that there is a sequence DA
sets of desirable gambles on An , n ∈ N. This sequence should of course be time-consistent in
the sense of Requirement (5), meaning that
n1
n2
n2
(∀n1 , n2 ∈ N)(n1 ≤ n2 ⇒ DA
= margn1 (DA
) = DA
∩ L(An1 )).

The second assumption is that this sequence of variables is exchangeable, which means,
roughly speaking, that the subject believes that the order in which these variables are observed,
20

Coherent Predictive Inference under Exchangeability

or present themselves, has no influence on the decisions and inferences he will make regarding
them.19
In this section, we explain succinctly how to deal with these assumptions technically, and
what their consequences are for the predictive models we are interested in. For a detailed
discussion and derivation of the results presented here, we refer to the papers by De Cooman
et al. (2009b) and De Cooman and Quaeghebeur (2012).
We begin with some useful notation, which will be employed numerous times in what
follows. Consider any element 𝛼 ∈ RA . We consider 𝛼 as an A-tuple, with as many (real)
components
∑︀ αx ∈ R as there are categories x in A. For any subset B ⊆ A, we then denote by
αB := x∈B αx the sum of its components over B.
5.1 Permutations, Count Vectors and the Hypergeometric Distribution
Consider an arbitrary n ∈ N. We denote by 𝑥 = (x1 , . . . , xn ) a generic, arbitrary element of An .
P n is the set of all permutations π of the index set {1, . . . , n}. With any such permutation π,
we can associate a permutation of An , also denoted by π, and defined by (π𝑥)k := xπ(k) , or
in other words, π(x1 , . . . , xn ) := (xπ(1) , . . . , xπ(n) ). Similarly, we lift π to a permutation π t of
L(An ) by letting π t f := f ◦ π, so (π t f )(𝑥) := f (π𝑥).
The permutation invariant atoms [𝑥] := {π𝑥 : π ∈ P n }, 𝑥 ∈ An are the smallest permutation invariant subsets of An . We introduce the counting map 𝑇 : An → NAn : 𝑥 7→ 𝑇 (𝑥),
where the count vector 𝑇 (𝑥) is the A-tuple with components
Tz (𝑥) := |{k ∈ {1, . . . , n} : xk = z}| for all z ∈ A,
and the set of possible count vectors for n observations in A is given by
{︀
}︀
NAn := 𝑚 ∈ NA
0 : mA = n .

(8)

(9)

So Tz (𝑥) is the number of times the category z appears in the sample 𝑥. If 𝑚 = 𝑇 (𝑥), then
[𝑥] = {𝑦 ∈ An : 𝑇 (𝑦) = 𝑚}, so the atom [𝑥] is completely determined by the single count
vector 𝑚 of all its elements, and is therefore also denoted by [𝑚].
We also consider the linear expectation operator HynA (·|𝑚) associated with the uniform
distribution on the invariant atom [𝑚]:
HynA (f |𝑚) :=

∑︁
1
f (𝑥) for all gambles f on An ,
|[𝑚]|

(10)

𝑥∈[𝑚]

where the number of elements ν(𝑚) := |[𝑚]| in the invariant atom [𝑚] is given by the
multinomial coefficient:
(︂
)︂ (︂ )︂
mA
n
n!
:= ∏︀
ν(𝑚) =
=
.
(11)
𝑚
𝑚
z∈A mz !
This expectation operator in Equation (10) characterises—or is the one associated with—
a (multivariate) hyper-geometric distribution (Johnson, Kotz, & Balakrishnan, 1997, Section 39.2), associated with random sampling without replacement from an urn with n balls
19. Exchangeability was also assumed by Carnap—his Axiom A7—and Johnson (1924), who named it the
“permutation postulate”.

21

De Cooman, De Bock, & Diniz

of types z ∈ A, whose composition is characterised by the count vector 𝑚. This is borne out
0
by the fact that, for any 𝑦 ∈ An , with 0 ≤ n0 ≤ n and 𝑚0 = 𝑇 (𝑦),
{︃
ν(𝑚 − 𝑚0 )/ν(𝑚) if 𝑚0 ≤ 𝑚
HynA (I{𝑦} |𝑚) =
0
otherwise
is the probability of randomly selecting, without replacement, a sequence of n0 balls of types
𝑦 from an urn with n balls whose composition is determined by the count vector 𝑚. See
also the running example below for a more concrete illustration.
This hyper-geometric expectation operator can also be seen as a linear transformation
HynA between the linear space L(An ) and the generally much lower-dimensional linear space
L(NAn ), turning a gamble f on An into a so-called count gamble HynA (f ) := HynA (f |·) on
count vectors.
Running Example. In order to make our argumentation, and the notions we introduce and
discuss, more tangible and concrete, we shall use a very simple running example, to which
we shall come back repeatedly in a number of sections. The notations and assumptions made
here will be maintained throughout the series.
Consider a (potentially infinite) sequence of coin flips, whose successive outcomes we
denote by the variables X1 , X2 , . . . Xn , . . . assuming values in the category set {H , T }. To
make this somewhat more interesting than the usual run-of-the-mill example, assume that at
each step—for each coin flip—Nathalie selects a coin from a bag of three coins, and hands it
to Arthur, who then proceeds to flip it. The coin is then put back into the bag for the next
step. The subject whose beliefs we are modelling, may or may not know something about
the nature of the coins, or about how Nathalie is choosing the coins for the subsequent flips:
she might choose them completely at random, or she might have a specific deterministic
mechanism for selecting them, or . . .
ˇ = (H , T , H , H ) of the first ň = 4 observed coin flips. The count
Consider the sequence 𝑥
ˇ that corresponds to this sequence is given by its components
vector 𝑇 (𝑥)
TH ((H , T , H , H )) = 3 and TT ((H , T , H , H )) = 1,
ˇ = (3, 1), letting the first component always refer to H , from now
and we will denote it by 𝑚
on. The corresponding permutation invariant atom is
[(H , T , H , H )] = [(3, 1)] = {(T , H , H , H ), (H , T , H , H ), (H , H , T , H ), (H , H , H , T )}
4!
3!1!

4
= 4 elements. The set of possible count vectors is given by N{H
,T } =
̂︂ := {(H , T ), (T , H )} × {H , T }2 of
{(0, 4), (1, 3), (2, 2), (3, 1), (4, 0)}. Consider the event HT
two different outcomes for the first two observations, then

and it has ν((3, 1)) =

1
1
Hy4{H ,T } (IHT
̂︂ |(3, 1)) = (1 + 1 + 0 + 0) =
4
2
is the probability of observing two different outcomes in two random draws without replacement from an urn containing three balls marked H and one ball marked T , and whose
composition is therefore determined by the count vector (3, 1).
♦
22

Coherent Predictive Inference under Exchangeability

5.2 The Multinomial Distribution
Next, we consider the simplex ΣA of all probability mass functions 𝜃 on A:
∑︁
{︀
}︀
ΣA := 𝜃 ∈ RA : 𝜃 ≥ 0 and θA = 1 , where, as before: θA :=
θx .

(12)

x∈A

With a probability mass function 𝜃 ∈ ΣA on A, there corresponds the following multinomial
expectation operator MnnA (·|𝜃):20
MnnA (f |𝜃) :=

∑︁
𝑥∈An

f (𝑥)

∏︁

θzTz (𝑥) for all gambles f on An ,

(13)

z∈A

which characterises the multinomial distribution, associated with n independent trials of an
experiment with possible outcomes in A and probability mass function 𝜃. Observe that
)︂
∑︁
∏︁
∑︁ (︂ 1
f (𝑥)) ν(𝑚)
θzmz
MnnA (f |𝜃) =
ν(𝑚)
n
z∈A
𝑚∈NA
𝑥∈[𝑚]
∑︁
∏︁
n
mz
=
HyA (f |𝑚)ν(𝑚)
θz = CoMnnA (HynA (f )|𝜃),
n
𝑚∈NA

z∈A

where we used the so-called count multinomial expectation operator:21
∑︁
∏︁
CoMnnA (g|𝜃) :=
g(𝑚)ν(𝑚)
θzmz for all gambles g on NAn .
n
𝑚∈NA

(14)

z∈A

Running Example. Consider n = 4 independent trials of an experiment with possible outcomes
in the category set {H , T } and probability mass function 𝜃 = (θH , θT ). Then
3
2 2
3
2
Mn4{H ,T } (IHT
̂︂ |(θH , θT )) = 2θH θT + 4θH θT + 2θH θT = 2θH θT (θH + θT ) = 2θH θT ,

̂︂ . Observe, by the way, that Mnn
gives the probability of the event HT
̂︂ |(θH , θT )) =
{H ,T } (IHT
2θH θT for all n ≥ 2.
With the gamble fHT
̂︂ := IHT
̂︂ on observation sequences (X1 , . . . , X4 ), there corresponds
4
a count gamble gHT
̂︂ := Hy{H ,T } (fHT
̂︂ |·) given by:
gHT
̂︂ (0, 4) = 0 and gHT
̂︂ (1, 3) =

1
2
1
and gHT
and gHT
and gHT
̂︂ (2, 2) =
̂︂ (3, 1) =
̂︂ (4, 0) = 0,
2
3
2

and

1
2 2 2
1 3
3
CoMn4{H ,T } (g|(θH , θT )) = 4θH θT
+ 6θH
θT + 4θH
θT = 2θH θT
2
3
2
leads to the same polynomial as before, as it should.

♦

20. To avoid confusion, we make a (perhaps non-standard) distinction between the multinomial expectation,
which is associated with sequences of observations, and the count multinomial expectation, associated
with their count vectors.
21. See footnote 20.

23

De Cooman, De Bock, & Diniz

5.3 Multivariate Polynomials
⋃︀
Let us introduce the notation NA := m∈N NAm for the set of all possible count vectors
corresponding to samples of at least one observation. In Equation (9), we can also let n = 0,
which turns NA0 into the singleton
containing only the null count vector 0, all of whose
⋃︀
components are zero. Then m∈N0 NAm = NA ∪ {0} is the set of all possible count vectors.
For any such count vector 𝑚 ∈ NA ∪ {0}, we consider the (multivariate) Bernstein basis
polynomial BA,𝑚 of degree mA on ΣA , defined by:
(︂
)︂
∏︁
mA ∏︁ mz
mz
BA,𝑚 (𝜃) := ν(𝑚)
θz =
θz for all 𝜃 ∈ ΣA .
(15)
𝑚
z∈A

z∈A

In particular, of course, BA,0 = 1.
Any linear combination p of Bernstein basis polynomials of degree n ≥ 0 is a (multivariate)
polynomial on ΣA , whose degree deg(p) is at most n.22 We denote the linear space of all these
polynomials of degree up to n by V n (A). Of course, polynomials of degree zero are simply real
constants. We have gathered relevant and useful information about multivariate polynomials
in Appendix B. It follows from the discussion there that, for any n ≥ 0, we can introduce a
linear isomorphism CoMnnA between the linear spaces L(NAn ) and V n (A):
∑︀ with any gamble g
on NAn , there corresponds a polynomial CoMnnA (g) := CoMnnA (g|·) = 𝑚∈N n g(𝑚)BA,𝑚 in
A
V n (A), and conversely, for any polynomial p ∈ V n (A) there is a unique gamble bnp on NAn
such that p = CoMnnA (bnp ).23 Observe that in particular, for any n ≥ 0 and 𝑚 ∈ NAn :
CoMnnA ({𝑚}|𝜃) = BA,𝑚 (𝜃) for all 𝜃 ∈ ΣA .
(16)
⋃︀
We denote by V (A) := n∈N0 V n (A) the linear space of all (multivariate) polynomials on ΣA ,
of arbitrary degree.
A set HA ⊆ V (A) of polynomials on ΣA is called Bernstein coherent if it satisfies the
following properties:
B1. 0 ∈
/ HA ;
B2. V + (A) ⊆ HA ;
B3. posi(HA ) = HA .
Here, V + (A) is the set of Bernstein positive polynomials on ΣA : those polynomials p for which
there is some n ≥ deg(p) such that bnp > 0. It follows from Proposition 28 in Appendix B
that V + (A) is a subset of the set V ++ (A) of all polynomials p such that p(𝜃) > 0 for all 𝜃
in the interior int(ΣA ) := {𝜃 ∈ ΣA : (∀x ∈ A)θx > 0} of ΣA . As a consequence of B1–B3, we
find for the set V0− (A) := −V + (A) of Bernstein negative polynomials that:
B4. V0− (A) ∩ HA = ∅.
22. The degree may be smaller than n because the sum of all Bernstein basis polynomials of fixed degree is
one. Strictly speaking, these polynomials p are restrictions to ΣA of multivariate polynomials q on RA ,
called representations of p. For any p, there are multiple representations, with possibly different degrees.
The smallest such degree is then called the degree deg(p) of p.
23. Strictly speaking, Equation (14) only defines the count multinomial expectation operator CoMnn
A for
n > 0, but it is clear that the definition extends trivially to the case n = 0.

24

Coherent Predictive Inference under Exchangeability

Finally, every Bernstein coherent set HA of polynomials on ΣA induces a lower prevision
H A on V (A) defined by:
H A (p) := sup {µ ∈ R : p − µ ∈ HA } for all p ∈ V (A).

(17)

This lower prevision is coherent, in the mathematical sense that it satisfies the coherence
requirements P1–P3.24
5.4 Exchangeability and the Representation Theorem
We are now ready to deal with exchangeability. We shall give a definition for coherent sets of
desirable gambles that generalises de Finetti’s (1937, 1975) definition, and which allows for a
significant generalisation of his Representation Theorem.
First of all, fix n ∈ N. Then the subject considers the variables X1 , . . . , Xn to be
exchangeable when he does not distinguish between any gamble f on An and its permuted
version π t f , or in other words, if the gamble f − π t f is equivalent to the zero gamble for—or
indifferent to—him. This means that he has a so-called set of indifferent gambles:
{︀
}︀
n
:= f − π t f : f ∈ L(An ) and π ∈ P n .
IA
n , then this set must be compatible
If the subject also has a coherent set of desirable gambles DA
n , in the sense that it must satisfy the rationality
with the set of indifferent gambles IA
n
n
n
requirement DA + IA = DA ; see the detailed explanations and justifications by De Cooman
and Quaeghebeur (2012) and Quaeghebeur et al. (2014) of this so-called desiring sweetened
n , are
deals requirement. We then say that the sequence X1 , . . . , Xn , and the model DA
exchangeable.
Next, the countably infinite sequence of variables X1 , . . . , Xn . . . is called exchangeable if
n, n ∈ N
all the finite subsequences X1 , . . . , Xn are, for n ∈ N. This means that all models DA
are exchangeable. They should of course also be time-consistent.
We can now formulate a powerful generalisation of de Finetti’s (1937, 1975) Representation
Theorem, which is a straightforward compilation of various results proved by De Cooman
and Quaeghebeur (2012):

Theorem 5 (Representation Theorem, De Cooman & Quaeghebeur, 2012). The sequence
n of desirable gambles on An , n ∈ N is coherent, time-consistent and exchangeable
of sets DA
if and only if there is a Bernstein coherent set HA of polynomials on ΣA such that for all
ˇ ∈ NA and all 𝑥
ˇ ∈ [𝑚]:
ˇ
n̂ ∈ N, all gambles f on An̂ , all 𝑚
n̂
n̂
ˇ ⇔ Mnn̂A (f )BA,𝑚
f ∈ DA
⇔ Mnn̂A (f ) ∈ HA and f ∈ DA
c𝑥
ˇ ∈ HA .

In that case this representation HA is unique and given by HA :=

⋃︀

(18)

n
n
n∈N MnA (DA ).

It follows from Condition (18) that HA completely determines all predictive inferences about
n̂ and all
the sequence of variables X1 , . . . , Xn , . . . , as it fixes all prior predictive models DA
24. Actually, a suitably adapted version, where the underlying possibility space need no longer be finite
(Walley, 1991; Troffaes & De Cooman, 2014), and where the domain is restricted to the polynomials on
ΣA (De Cooman & Quaeghebeur, 2012).

25

De Cooman, De Bock, & Diniz

n̂ c𝑥.
ˇ 25 This tells us that the representation HA is a set of
posterior predictive models DA
polynomials that plays the same role as a probability measure, or density, or distribution
function, on ΣA in the precise-probabilistic case.
Indeed, the corresponding coherent lower prevision H A on V (A) is given by Equation (17),
and it can be shown to determine a convex closed (compact) set

M(H A ) := {HA : (∀p ∈ V (A))HA (p) ≥ H A (p)}
of coherent previsions HA on V (A) (Walley, 1991; De Cooman et al., 2009b; De Cooman &
Quaeghebeur, 2012; Troffaes & De Cooman, 2014). As we pointed out in footnote 2—and
will come back to further on in footnote 36—each such coherent prevision HA uniquely
determines a σ-additive probability measure on the Borel sets of ΣA , and therefore the set of
polynomials HA , via M(H A ), uniquely determines a set of such probability measures. But, as
we have argued before, HA is more informative than H A and M(H A ), and has no problems
with conditioning on sets of lower probability zero: a Bernstein coherent set of polynomials
HA determines a unique lower prevision H A , and therefore through M(H A ) a unique set of
probability measures—and densities if they are absolutely continuous—on the simplex ΣA ,
but the converse is not necessarily—and usually not—the case. A set of probability densities
can be used to define a coherent set of polynomials—we provide an example of how to do
this in Section 12—but there will generally be more than one coherent set of polynomials
that leads to this same set of densities, and the updating behaviour for these different sets of
polynomials can be different on conditioning events of lower probability zero.
n̂ c𝑥
ˇ only depend on
Condition (18) also tells us that the posterior predictive models DA
ˇ through the count vector 𝑚
ˇ = 𝑇 (𝑥):
ˇ count vectors are sufficient
the observed sequence 𝑥
statistics under exchangeability. For this reason, we shall from now on denote these posterior
n̂ c𝑚
n̂ c𝑥.
ˇ as well as by DA
ˇ Also, every now and then, we shall use
predictive models by DA
n̂
n̂
DA c0 as an alternative notation for DA .
An immediate but interesting consequence of Theorem 5 is that updating on observations
preserves exchangeability: after observing the values of the first ň variables, with count
ˇ the remaining sequence of variables Xň+1 , Xň+2 , . . . is still exchangeable, and
vector 𝑚,
Condition (18) tells us that its representation is given by the Bernstein coherent set of
ˇ defined by:
polynomials HA c𝑚
ˇ := {p ∈ V (A) : BA,𝑚
HA c𝑚
ˇ p ∈ HA } .

(19)

If we compare this with Expressions (2) and (6), this tells us that, essentially, Bernstein
basis polynomials serve as likelihood functions for updating sets of polynomials. We use
ˇ to refer to the coherent lower prevision on V (A) derived from HA c𝑚
ˇ by means of
H A (·|𝑚)
ˇ = 0, we find that HA c0 = HA and H A (·|0) = H A .
Equation (17). For the special case 𝑚
ˇ are related through the following version of the Generalised
Observe that H A and H A (·|𝑚)
Bayes Rule:
ˇ
H A ([p − H A (p|𝑚)]B
(20)
ˇ ) = 0 for all p ∈ V (A).
A,𝑚
ˇ is completely determined by HA . One can consider HA as a prior model on
Clearly, HA c𝑚
ˇ plays the role of the posterior that is derived from it.
the parameter space ΣA , and HA c𝑚
25. This should be contrasted with the usual precise-probabilistic version, where the posterior predictive
models are only uniquely determined if the observed sequences has non-zero probability; see also footnote 3.

26

Coherent Predictive Inference under Exchangeability

We see from Condition (18) and Equation (19) that—similarly to what happens in a preciseprobabilistic setting—the multinomial distribution serves as a direct link between on the one
n̂ and, on the other hand,
hand, the ‘prior’ HA and its prior predictive inference models DA
n̂ c𝑚.
ˇ and its posterior predictive inference models DA
ˇ Recalling our
the ‘posterior’ HA c𝑚
ˇ
ˇ ∈ NA ∪ {0}:
convention for 𝑚 = 0, we can summarise this as follows: for all n̂ ∈ N and all 𝑚
{︁
}︁
n̂
ˇ = f ∈ L(An̂ ) : Mnn̂A (f ) ∈ HA c𝑚
ˇ
DA
c𝑚
(21)
and, as an immediate consequence:
{︁
}︁
ˇ = sup µ ∈ R : Mnn̂A (f ) − µ ∈ HA c𝑚
ˇ for all f ∈ L(An̂ )
P n̂A (f |𝑚)

(22)

or, equivalently:
ˇ = H A (Mnn̂A (f )|𝑚)
ˇ for all f ∈ L(An̂ ).
P n̂A (f |𝑚)

(23)

From a practical point of view, Equation (23) will often be easier to work with than Equaˇ will often admit a simpler expression
tion (22), because as we shall see further on, H A (·|𝑚)
ˇ compare Equations (45), (54), (61) and (69) with Equations (49), (55), (65)
than HA c𝑚;
ˇ is not always uniquely determined by H A : the relaand (73), respectively. But, H A (·|𝑚)
ˇ uniquely from H A if the prior lower probability
tion (20) only allows us to determine H A (·|𝑚)
ˇ
H A (BA,𝑚
)
of
observing
is
non-zero.
Therefore,
the sets of polynomials HA are the more
𝑚
ˇ
ˇ uniquely. As a quite dramatic
fundamental models, as they allow us to determine the HA c𝑚
illustration of this, we shall further on in Sections 11, 13 and 14 come across a number of
quite different inference systems—with different HA —that give rise to the same prior H A
ˇ
but different posterior H A (·|𝑚)!
Running Example. We now assume that our subject assesses the sequence of coin flips to be
exchangeable, and that he finds desirable any gamble of the type α − I{H } (Xn ), for some fixed
α ∈ (0, 1]; so his upper probability for observing heads on any coin flip is at most α. Since
we infer from Equation (13) that for any N ≥ n, MnN
{H ,T } (I{H } (Xn )|𝜃) = θH , we infer from
Theorem 5 that this assessment corresponds to the following coherent set of polynomials:
{︀
}︀
Hα := λ1 p+ + λ2 (α − θH ) : p+ ∈ V + ({H , T }), λ1 , λ2 ∈ R≥0 and max{λ1 , λ2 } > 0 ,
which is the smallest Bernstein coherent set of polynomials that contains the polynomial
α − θH ; for more explanation, see also the discussions by De Cooman et al. (2009b) and
De Cooman and Quaeghebeur (2012). It then follows—after some manipulations—from
Equation (17) and Proposition 28 that the corresponding lower prevision on V ({H , T }) is
completely determined by the following optimisation:
H α (p) = sup

min [p(𝜃) + λ(θH − α)]

λ≥0 𝜃∈Σ{H ,T }

̂︂ is given by
Hence, the lower probability of the event HT
H α (2θH θT ) = sup min [2x(1 − x) + λ(x − α)] = 0,
λ≥0 x∈[0,1]

and its upper probability by
H α (2θH θT ) = −H α (−2θH θT ) = inf max [2x(1 − x) − λ(x − α)]
λ≥0 x∈[0,1]

27

De Cooman, De Bock, & Diniz

=

{︃
2α(1 − α)
1
2

if α ≤ 12
otherwise.

̂︂
This tells us that exchangeability alone already guarantees that the upper probability of HT
1
is at most 2 . If all three coins in the bag are assumed to be biased towards heads, so α < 12 ,
this upper probability drops below 12 .
♦
To finish this section on representation, we want to stress that the polynomials on ΣA
should not be given a behavioural interpretation as gambles that may or may not be desirable:
they are merely mathematical and representational tools that help us characterise which
gambles on observation sequences are desirable.26 Similarly, the set of polynomials HA and
the lower prevision H A are merely mathematical tools that allow for a more convenient
representation of predictive models on observation sequences.
Running Example. To illustrate why the polynomial representation is so much more convenient
and efficient, recall that if we want to make inferences about a sequence of coin flips of
length n, we need to work with sets of desirable gambles on {H , T }n , or in other words,
with cones in a 2n -dimensional space. If we work with their polynomial representations,
we are led to consider cones of polynomials of degree up to n, which constitute a linear
space that is spanned by the n + 1 Bernstein basis polynomials of degree n, and is therefore
only n + 1-dimensional. Working with these polynomial representations therefore leads to a
dramatic—exponential—reduction in complexity.
♦

6. Reasoning about Inference Systems
We have seen in the previous section that, once we fix a category set A, predictive inferences
about exchangeable sequences assuming values in A are completely determined by a Bernstein
coherent set HA of polynomials on ΣA . So if we had some way of associating a Bernstein
coherent set HA with every possible set of categories A, this would completely fix all predictive
inferences. This leads us to the following definition.
Definition 6 (Inference Systems). We denote by F the collection of all category sets, i.e. finite
non-empty sets. An inference system is a map Φ that maps any category set A ∈ F to some
set of polynomials Φ(A) = HA on ΣA . An inference system Φ is called coherent if for all
category sets A ∈ F, Φ(A) is a Bernstein coherent set of polynomials on ΣA .
So, a coherent inference system is a way to systematically associate coherent predictive
inferences with any category set. Since the inference principles in Section 4 impose connections
between predictive inferences for different category sets, we now see that we can interpret
these inference principles—or rather, represent them mathematically—as properties of, or
restrictions on, coherent inference systems. This is what we shall do in Section 7, and
it provides one important motivation for our introducing such systems. Another, equally
26. It makes no operational, behavioural sense to consider the notion of ‘accepting a polynomial’, or finding it
‘desirable’. This is very much like the classical case, where for de Finetti (1975) the probability distributions
on the simplex ΣA are only to be used as as mathematical representations, but have no direct behavioural
meaning—although some Bayesians less careful about foundations than de Finetti might not care to make
this distinction.

28

Coherent Predictive Inference under Exchangeability

important reason for doing so, is that it allows us to extend the method of natural extension—
or conservative inference—introduced in Section 2.2, to also take into account inference
principles for predictive inference, or more generally, predictive inference for multiple category
sets at once.
To see how this comes about, let us show how we can do conservative reasoning with
inference systems. For any two inference systems Φ1 and Φ2 , we say that Φ1 is less committal —
or more conservative—than Φ2 , and we write Φ1 v Φ2 if
(∀A ∈ F)Φ1 (A) ⊆ Φ2 (A).
This simply means that the predictive inferences for each category set A are less committal
for the first than for the second inference system. If we denote by S the set of all inference
systems, then clearly this set is partially ordered by v. Actually, it is a complete lattice,
where the infimum and supremum of any non-empty family Φi , i ∈ I are given by:
(︁

)︁
(︁
)︁
⋂︁
⋃︁
inf Φi (A) =
Φi (A) and sup Φi (A) =
Φi (A) for all category sets A.
i∈I

i∈I

i∈I

i∈I

We denote by C the set of all coherent inference systems:
C := {Φ ∈ S : (∀A ∈ F)Φ(A) is Bernstein coherent} .

(24)

Then it is clear that C is a complete meet-semilattice, meaning that it is closed under arbitrary
non-empty infima:27
(∀i ∈ I)Φi ∈ C ⇒ inf Φi ∈ C.
(25)
i∈I

The bottom of this structure—the most conservative coherent inference system—is called
the vacuous inference system ΦV , and it is the coherent inference system given by:
ΦV (A) = V + (A) for all category sets A.
We shall come back in some detail to this vacuous inference system in Section 9.
The property (25) allows us to do conservative reasoning with coherent inference systems.
Suppose, for instance, that for some collection of category sets F ⊆ F, we have assessments
A in the form of a set of polynomials AA ⊆ V (A), A ∈ F. Then, if it exists, the most
conservative coherent inference system ΦA that is compatible with these assessments is given
by:
ΦA = inf {Φ ∈ C : (∀A ∈ F)AA ⊆ Φ(A)} .
And, of course, it will exist if and only the set of polynomials AA is included in some
Bernstein coherent set of polynomials HA on A, for all A ∈ F. In that case, it is not difficult
to see, given the discussion in Section 5.3, that ΦA (A) = posi(V + (A) ∪ AA ) for A ∈ F and
ΦA (A) = V + (A) for A ∈ F \ F.
27. It is not necessarily closed under suprema, however, as the union of Bernstein coherent sets of polynomials
need not be Bernstein coherent.

29

De Cooman, De Bock, & Diniz

7. Representation Insensitivity and Specificity under Exchangeability
Let us now investigate what form the inference principles of representation insensitivity (RI2)
and specificity (SP2) take for predictive inference under exchangeability, when such inference
can be completely characterised by Bernstein coherent sets of polynomials. This will allow us
to reformulate these principles as constraints on—or properties of—inference systems.
7.1 Representation Insensitivity
We recall the notations and assumptions in Section 4.4. With the surjective (onto) map
ρ : A → D we associate the surjective map Rρ : RA → RD by letting:
Rρ (𝛼)z :=

∑︁

αx

for all 𝛼 ∈ RA and all z ∈ D.

(26)

x∈A : ρ(x)=z

This map allows us to give the following elegant characterisation of representation insensitivity.
Theorem 7. A coherent inference system Φ is representation insensitive if and only if for
all category sets A and D such that there is an onto map ρ : A → D, for all p ∈ V (D) and
all 𝑚 ∈ NA ∪ {0}:
(p ◦ Rρ )BA,𝑚 ∈ Φ(A) ⇔ pBD,Rρ (𝑚) ∈ Φ(D).
(RI3)
Running Example. Assume now that the coins in the bag are actually rather thick, implying
that there is a non-negligible chance that they do not fall on one of their flat sides, but
remain upright. If we denote this new ‘up’ state by U , then we have a new category set
A := {H , T , U }. If we also consider a new ‘flat’ state F , meaning either heads or tails, then
we can also consider, instead of A, the category set D := {F , U } that does not distinguish
between heads and tails. The relabelling map ρ with ρ(H ) := ρ(T ) := F and ρ(U ) := U
identifies the proper relations between the categories in A and D.
Suppose now that we want to say something about the lower probability of the event
̂︂ of observing U on one flip and H or T on the other, immediately after observing the
UF
sequence (H , U , H , T ) with count vector 𝑚 = (2, 1, 1)—the last count in three from now on
refers to the number of U s in the observation sequence. In the A-domain, the gamble IUF
̂︂
n̂
28
can be expressed by the polynomial q = Mn{H ,T ,U } (IUF
̂︂ ), n̂ ≥ 2 given by:
q(𝜃) = 2(θH + θT )θU for all 𝜃 ∈ Σ{H ,T ,U } .
2 θ θ belong
So we want to find out whether polynomials of the type [2(θH + θT )θU − µ]12θH
T U
to Φ({H , T , U }); see Equation (18).
On the other hand, as we have seen previously, in the D-domain, the gamble IUF
̂︂ can
be expressed by the polynomial p given by p(𝜗) = 2ϑF ϑU for all 𝜗 ∈ Σ{F ,U } . Observe that
q = p ◦ Rρ . The count vector 𝑚 = (2, 1, 1) in the A-domain corresponds to a count vector
Rρ (𝑚) = (3, 1) in the D-domain, where the first component refers to the number of F s and
the second to the number of U s. So here, we need to check whether polynomials of the type
[2ϑF ϑU − µ]4ϑ3F ϑU belong to Φ({F , U }).

28. As before in similar contexts, it is easy to check that this polynomial remains the same for all n̂ ≥ 2.

30

Coherent Predictive Inference under Exchangeability

The nice thing about representation insensitivity is that it makes checking whether
2 θ θ
polynomials of the type [2(θH + θT )θU − µ]12θH
T U belong to Φ({H , T , U }) in the Adomain equivalent to checking whether polynomials of the type [2ϑF ϑU − µ]4ϑ3F ϑU belong
to Φ({F , U }) in the D-domain.
♦
Very interestingly, representation insensitivity is preserved under taking arbitrary nonempty infima of coherent inference systems, which allows us to look for the most conservative
representation insensitive coherent inference system that is compatible with an assessment A
on F, in a way that is a straightforward extension of the discussion near the end of Section 6.
Theorem 8. Consider any non-empty family Φi , i ∈ I of representation insensitive coherent
inference systems. Then their infimum inf i∈I Φi is a representation insensitive coherent
inference system as well.
7.2 Specificity
Next, we turn to specificity, and recall the notations and assumptions in Section 4.5. Let us
define the surjective restriction map rB : RA → RB by:
rB (𝛼)z := αz for all 𝛼 ∈ RA and all z ∈ B,

(27)

so in particular, rB (𝑚) is the count vector on B obtained by restricting to B the (indices of
the) components of the count vector 𝑚 on A. We also define the one-to-one injection map
iA : RB → RA by:
{︃
αx if x ∈ B
iA (𝛼)x :=
for all 𝛼 ∈ RB and all x ∈ A.
(28)
0
otherwise
This map can be used to define the following one-to-one maps IrB,A : V (B) → V (A), for any
r ∈ N0 , as follows:
∑︁
IrB,A (p) :=
bdeg(p)+r
(𝑛)BA,iA (𝑛) for all polynomials p in V (B).
(29)
p
deg(p)+r

𝑛∈NB

They derive their meaning from the following observation. A polynomial p on ΣB can be
equivalently represented in any Bernstein basis on ΣB of degree deg(p) + r. But when we
interpret these different representations as polynomials on ΣA , they are no longer equivalent,
and lead to different polynomials IrB,A (p), r ∈ N0 . The following propositions clarify what
exactly the effect of the operator IrB,A is.
Proposition 9. For any polynomial p on ΣB and any r ∈ N0 : IrB,A (p) ◦ iA = p.
We introduce the following notation, for any 𝜃 ∈ ΣA such that θB > 0: 𝜃|+
B := rB (𝜃)/θB .
Observe that 𝜃|+
∈
Σ
whenever
θ
>
0.
B
B
B
Proposition 10. Consider any polynomial p on ΣB , any r ∈ N0 and any 𝜃 ∈ ΣA . When
deg(p) + r = 0 then p = c ∈ R, and IrB,A (p|𝜃) = c. Otherwise, when deg(p) + r > 0:
{︃
deg(p)+r
θB
p(𝜃|+
if θB > 0
B)
IrB,A (p|𝜃) =
0
otherwise.
31

De Cooman, De Bock, & Diniz

The maps IrB,A allow us to give the following elegant characterisation of specificity:
Theorem 11. A coherent inference system Φ is specific if and only if for all category sets A
and B such that B ⊆ A, for all p ∈ V (B), all 𝑚 ∈ NA ∪ {0} and all r ∈ N0 :
IrB,A (p)BA,𝑚 ∈ Φ(A) ⇔ pBB,rB (𝑚) ∈ Φ(B).

(SP3)

Running Example. Suppose, as before, that we have made the observation (H , U , H , T ),
with count vector 𝑚 = (2, 1, 1). We are interested in the posterior lower probability of the
̂︂ , where somebody has told us that neither of the two subsequent coin flips—after
event HT
the first four—resulted in U . In a specific inference system, we are allowed to consider this
predictive inference problem in the reduced category space B = {H , T }, rather than in the
category space A = {H , T , U }. But then, in the B-space, we have to use the reduced count
vector rB (𝑚) = (2, 1), obtained by leaving out the number of observed U s. The polynomials
we are lead to consider here, are therefore of the type [2ϑH ϑT − µ]3ϑ2H ϑT , for which we want
to know whether they belong to Φ({F , U }).
In the A-space, the polynomial p(𝜗) = 2ϑH ϑT − µ, whose degree is deg(p) = 2, is
transformed into the polynomials
]︂
[︂
θT
θH
r
IB,A (p|𝜃) = 2
− µ (θH + θT )2+r = [2θH θT − µ(θH + θT )2 ](θH + θT )r
θH + θT θH + θ T
for r ∈ N0 . It follows from the argumentation in the proof of Theorem 11 that the original
problem requires us to check whether polynomials of the type
2
[2θH θT − µ(θH + θT )2 ](θH + θT )r 12θH
θT θU

are in Φ({H , T , U }). Specificity allows us to look at the problem in the B-space, which is
easier.
♦
Observe the close formal similarity between the conditions (RI3) and (SP3). It should
therefore not surprise us that specificity, too, is preserved under taking arbitrary non-empty
infima of inference systems.
Theorem 12. Consider any non-empty family Φi , i ∈ I of specific coherent inference systems.
Then their infimum inf i∈I Φi is a specific coherent inference system as well.
Let us denote by Crs the set of all coherent inference systems that are both representation
insensitive and specific. It follows from Theorems 8 and 12 that Crs , like C, is closed under
arbitrary non-empty infima, so we can perform conservative reasoning, in very much the
same way as we discussed near the end of Section 6.

8. Immediate Prediction
If we have an inference system Φ, we can look at the special case of immediate prediction,
where for a given category set A, after observing a sample of ň ≥ 0 variables with count vector
ˇ ∈ NAň , we want to express beliefs about the value that the next observation Xň+1 will
𝑚
assume in A. So this is the specific case of predictive inference with n̂ = 1, and Condition (18)
ˇ ∈ NAň :
can now be simplified somewhat, as for all gambles f on A and all 𝑚
1
1
ˇ ⇔ BA,𝑚
f ∈ DA
⇔ SA (f ) ∈ Φ(A) and f ∈ DA
c𝑚
ˇ SA (f ) ∈ Φ(A),

32

Coherent Predictive Inference under Exchangeability

where we let the
∑︀so-called sampling expectation SA (f ) be the linear polynomial on ΣA given
by SA (f |𝜃) := x∈A f (x)θx for all 𝜃 ∈ ΣA .
The reason for this is that NA1 = {𝑒x : x ∈ A} where 𝑒x is the count vector corresponding
to a single observation of category x, or in other words, exz = δxz for all z ∈ A [Kronecker
delta]. Hence, for all x ∈ A and any 𝜃 ∈ ΣA :
(︂ )︂ ∑︁
(︂ )︂ ∏︁
1
1
x
x
f
(z)
=
f
(x)
and
B
(𝜃)
=
θzez = θx ,
Hy1A (f |𝑒x ) =
A,𝑒
x
𝑒x
𝑒
x
z∈A

z∈[𝑒 ]

leading to:
Mn1A (f |𝜃) =

∑︁

Hy1A (f |𝑒x )BA,𝑒x (𝜃) =

1
𝑒x ∈NA

∑︁

f (x)θx = SA (f |𝜃).

(30)

x∈A

It is a matter of straightforward verification that, due to the Bernstein coherence of HA , the
1 c𝑚
ˇ is a coherent set of desirable gambles on A, for
so-called immediate prediction model DA
ˇ ∈ NA ∪ {0}. It induces the following predictive lower previsions:
every count vector 𝑚
{︀
}︀
1
ˇ = sup α ∈ R : f − α ∈ DA
ˇ
P 1A (f |𝑚)
c𝑚
= sup {α ∈ R : [SA (f ) − α]BA,𝑚
ˇ ∈ Φ(A)} .

(31)

Immediate prediction in the context of exchangeable imprecise probability models has
been studied in some detail by De Cooman et al. (2009a). Lower previsions, rather than
sets of desirable gambles, were the model of choice in that paper, and because of that, the
authors encountered problems with conditioning on sets of (lower) probability zero. In fact,
it is these problems that provided the motivation for dealing with the much more general
problem of (not necessarily immediate) predictive inference using sets of desirable gambles
in the present paper. In this section, we want to illustrate how many of the results proved
there can be made stronger (and with easier proofs, as is borne out in Appendix E.3) in the
present context.
The requirement (RI2) for representation insensitivity reduces to the following simpler
requirement on immediate prediction models: for all category sets A and D such that there
is an onto map ρ : A → D, for all gambles f on D and all 𝑚 ∈ NA ∪ {0}:
1
1
f ◦ ρ ∈ DA
c𝑚 ⇔ f ∈ DD
cRρ (𝑚).

(RI4)

Similarly, the requirement (SP2) for specificity reduces to the following simpler requirement
on immediate prediction models: for all category sets A and B such that B ⊆ A, for all
gambles f on B and all 𝑚 ∈ NA ∪ {0}:
1
1
f IB ∈ DA
c𝑚 ⇔ f ∈ DB
crB (𝑚).

(SP4)

Let us now show that there is a simple characterisation of the immediate prediction
models that satisfy representation insensitivity. To get there, observe that we can consider
any gamble g on a category set A as a (surjective) pooling map from A to the finite subset
g(A) of R—also a category set. The corresponding Rg : RA → Rg(A) is given by:
∑︁
Rg (𝛼)r =
αx for all r ∈ g(A).
x∈A : g(x)=r

33

De Cooman, De Bock, & Diniz

This simple idea allows for an intriguing reformulation of the representation insensitivity
requirement on immediate prediction models:
Proposition 13. The immediate prediction models associated with a coherent inference
system are representation insensitive if and only if for all category sets A, all gambles g on
A and all count vectors 𝑚 ∈ NA ∪ {0}:
1
1
g ∈ DA
c𝑚 ⇔ idg(A) ∈ Dg(A)
cRg (𝑚).

(RI5)

Here, for any non-empty set B, we denote by idB the identity map on B, defined by idB (z) := z
for all z ∈ B.
Proposition 13 tells us that whether a gamble is desirable depends only on the values it
assumes—and not on where they are assumed—and on the number of times each of these
values has been observed in the past—or rather would have been if we had been observing
the g(Xk ) rather than the Xk .
Let us now focus on what happens for events. Consider any event B ⊆ A that is nontrivial —meaning that B is neither empty nor equal to A. Then for any real µ the gamble
IB − µ assumes two values, 1 − µ and −µ, so we see after applying Proposition 13 that for
all 𝑚 ∈ NA ∪ {0}:
1
1
IB − µ ∈ DA
c𝑚 ⇔ id{1−µ,−µ} ∈ D{1−µ,−µ}
c(mB , mA\B ),

and therefore
{︀
}︀
1
P 1A (B|𝑚) = sup µ ∈ R : IB − µ ∈ DA
c𝑚
{︁
}︁
1
= sup µ ∈ R : id{1−µ,−µ} ∈ D{1−µ,−µ}
c(mB , mA\B ) =: ϕ(mA , mB ),

(32)
(33)

meaning that, by representation insensitivity, the predictive lower probability for a non-trivial
event B depends only on the number of times mB that it has been observed in the past
experiments, and the total number of observations mA . The same thing holds for its predictive
upper probability 1 − ϕ(mA , mA − mB ). For precise predictive probabilities, a similar property
is known as Johnson’s sufficientness postulate (Johnson, 1924; Zabell, 1982).
So for any representation insensitive{︀coherent inference system,
we see that we can define a
}︀
2
so-called lower probability function ϕ : (n, k) ∈ N0 : k ≤ n → [0, 1] through Equation (33),
which completely characterises the ‘one-step-ahead’ predictive lower and upper probabilities29
for all non-trivial events and all count vectors. We shall now use the representation insensitivity
and specificity requirements to try and say more about this lower probability function. The
following theorem strengthens, simplifies, and extends similar results by De Cooman et al.
(2009a).
Theorem 14. Consider a representation insensitive coherent inference system Φ. Then the
associated lower probability function ϕ has the following properties:
L1. ϕ is bounded: 0 ≤ ϕ(n, k) ≤ 1 for all n, k ∈ N0 such that k ≤ n.
L2. ϕ is super-additive in its second argument: ϕ(n, k + `) ≥ ϕ(n, k) + ϕ(n, `) for all
n, k, ` ∈ N0 such that k + ` ≤ n.
29. . . . but not necessarily the predictive lower and upper previsions . . .

34

Coherent Predictive Inference under Exchangeability

L3. ϕ(n, 0) = 0 for all n ∈ N0 .
L4. ϕ(n, k) ≥ kϕ(n, 1) and nϕ(n, 1) ≤ 1 for all n, k ∈ N0 such that 1 ≤ k ≤ n.
L5. ϕ is non-decreasing in its second argument: ϕ(n, k) ≤ ϕ(n, `) for all n, k, ` ∈ N0 such
that k ≤ ` ≤ n.
L6. ϕ(n, k) ≥ ϕ(n + 1, k) + ϕ(n, k)[ϕ(n + 1, k + 1) − ϕ(n + 1, k)] for all n, k ∈ N0 such that
k ≤ n.
L7. ϕ is non-increasing in its first argument: ϕ(n + 1, k) ≤ ϕ(n, k) for all n, k ∈ N0 such
that k ≤ n.
L8. Suppose that ϕ(n, 1) > 0 for all n ∈ N, and let sn :=
1
. Then sn ≥ 0 and sn+1 ≥ sn .
ϕ(n, 1) = n+s
n

1
ϕ(n,1)

− n, or equivalently,

If Φ is moreover specific, then ϕ has the following properties:
nα
L9. Consider any real α ∈ (0, 1) and suppose that ϕ(1, 1) ≥ α, then ϕ(n, n) ≥ 1−α+nα
for
1
all n ∈ N0 . As a consequence, consider any s > 0 and suppose that ϕ(1, 1) ≥ 1+s , then
n
ϕ(n, n) ≥ n+s
for all n ∈ N0 .

We know from Theorem 4 that representation insensitive coherent inference systems are
near-ignorant, meaning that they are vacuous and therefore completely indecisive about any
single observation when no prior observations have been made. This is also borne out by
Theorem 14.L3. Let us define the imprecision function by
ι(n, k) := 1 − ϕ(n, n − k) − ϕ(n, k) for all n, k ∈ N0 such that k ≤ n.

(34)

1

It is clear that P A (B|𝑚) − P 1A (B|𝑚) = ι(mA , mB ) is the width of the probability interval
for an event B that has been observed before mB out of mA times. For a representation
insensitive coherent inference system whose imprecision function ι(n, k) satisfies the following
property:
}︃
ι(n + 1, k) ≤ ι(n, k)
for all 0 ≤ k ≤ n,
(35)
ι(n + 1, k + 1) ≤ ι(n, k)
the imprecision does not increase as the total number of observations increases. This suggests
that such representation insensitive coherent inference systems will display some of the
desirable behaviour mentioned in the Introduction: they are conservative when little has been
learned, and they never become less precise as more observations come in. In the following
sections, we intend—amongst other things—to take a closer look at whether this behaviour
is present in a number of such systems.
Immediate prediction is very important for predictive inference with precise probabilities,
as the Law of Total Probability guarantees that it is completely determined by its immediate
predictions. Perhaps surprisingly, this is not the case for predictive inference with imprecise
probabilities: Appendix D provides a counterexample. This also points to some of the
limitations in scope of the earlier work by De Cooman et al. (2009a). For this reason, we now
leave immediate prediction models for what they are, and in the rest of this paper concentrate
on the more general notion of an inference system.
35

De Cooman, De Bock, & Diniz

9. The Vacuous Inference System
In this and the following sections, we provide explicit and interesting examples of representation insensitive, and of specific coherent inference systems. We begin with the simplest
one: the vacuous inference system ΦV , which we introduced in Section 6 as the smallest,
or most conservative, coherent inference system. It associates with any category set A the
smallest Bernstein coherent set ΦV (A) = HV,A := V + (A) containing all the Bernstein positive
polynomials—the ones that are guaranteed to be there anyway, by Bernstein coherence alone.
We deduce from Proposition 30 in Appendix B that:
ˇ = HV,A = V + (A) for all 𝑚
ˇ ∈ NA ∪ {0},
HV,A c𝑚
and from Proposition 28 in Appendix B that:
{︀
}︀
ˇ = H V,A (p) = sup α ∈ R : p − α ∈ V + (A)
H V,A (p|𝑚)
= min p = min p(𝜃) for all p ∈ V (A).
𝜃∈ΣA

The predictive models for this inference system are now straightforward to find, as they
ˇ ∈ NA ∪ {0}, we
follow directly from Equations (21) and (23). For any n̂ ∈ N and any 𝑚
deduce that:
{︁
}︁
n̂
n̂
ˇ = f ∈ L(An̂ ) : Mnn̂A (f ) ∈ V + (A) ,
DV,A
= DV,A
c𝑚
(36)
and
ˇ = min Mnn̂A (f |𝜃) for all f ∈ L(An̂ ).
P n̂V,A (f ) = P n̂V,A (f |𝑚)
𝜃∈ΣA

(37)

In particular:
1
1
ˇ = L>0 (A),
DV,A
= DV,A
c𝑚

P 1V,A (f )

=

ˇ
P 1V,A (f |𝑚)

(38)

= min f for all f ∈ L(A),

(39)

and
ϕV (n, k) = 0 for all n, k ∈ N0 such that k ≤ n.

(40)

These are the most conservative exchangeable predictive models there are, and they arise from
making no other assessments than exchangeability alone. As we gather from Equations (36)–
(40), they are not very interesting, because they involve no non-trivial commitments, and
they do not allow for learning from observations. This is also borne out by the corresponding
imprecision function, which is given by:
ιV (n, k) = 1 for all n, k ∈ N0 such that k ≤ n.
Running Example. We have seen before that Mnn̂{H ,T } (IHT
̂︂ |𝜃) = 2θH θT for all n̂ ≥ 2, and
therefore
n̂
P n̂V,{H ,T } (IHT
̂︂ ) = P V,{H ,T } (IHT
̂︂ |(3, 1)) =

min

Mnn̂{H ,T } (IHT
̂︂ |𝜃) =

max

Mnn̂{H ,T } (IHT
̂︂ |𝜃) =

𝜃∈Σ{H ,T }

min

𝜃∈Σ{H ,T }

2θH θT = 0

and
n̂

n̂

P V,{H ,T } (IHT
̂︂ ) = P V,{H ,T } (IHT
̂︂ |(3, 1)) =

𝜃∈Σ{H ,T }

36

1
2θH θT = .
𝜃∈Σ{H ,T }
2
max

Coherent Predictive Inference under Exchangeability

This shows that the vacuous inference model does not produce completely vacuous inferences:
it allows us to find out the consequences of making no other assessments than exchangeability.
But it does not allow us to change our lower and upper probabilities and previsions when
new observations come in.
♦
Even though it makes no non-trivial inferences, the vacuous inference system satisfies
representation insensitivity, but it is not specific.
Theorem 15. The vacuous inference system ΦV is coherent and representation insensitive.
Let us show by means of a counterexample that ΦV is not specific,
Running Example. Let us go back to inferences about the category space A = {H , T , U } and
the reduced category space B = {H , T }. Consider the polynomial p(𝜗) = ϑ2H − ϑH ϑT + ϑ2T
on Σ{H ,T } . This polynomial is Bernstein positive—so p ∈ V + ({H , T })—because
p(𝜗) = (ϑ2H − ϑH ϑT + ϑ2T )(ϑH + ϑT ) = ϑ3H + ϑ3T
has an expansion in the Bernstein basis of degree 3 that is positive. But let us now consider
the corresponding polynomial on Σ{H ,T ,U } :
2
2
q(𝜃) := I0B,A (p|𝜃) = θH
− θH θT + θT
.

(41)

This polynomial is not Bernstein positive: it is easy to see that for every n ∈ N0 ,
2
2
q(𝜃) = (θH
− θH θT + θT
)(θH + θT + θU )n
n . So q = I0 (p) ∈
will always have a term −θH θT θU
/ V + ({H , T , U }), and we infer from
B,A
Theorem 11 that ΦV cannot be specific.
♦

In the following sections, we shall prove that there are an infinity of more committal,
specific and representation insensitive coherent inference systems. We begin by introducing
a slightly modified version of the vacuous inference system that is coherent, representation
insensitive and specific.

10. The Nearly Vacuous Inference System
Let us introduce the nearly vacuous inference system ΦNV —the reason for its name will
become clear presently—by:
ΦNV (A) := HNV,A := V ++ (A) := {p ∈ V (A) : (∀𝜃 ∈ int(ΣA ))p(𝜃) > 0}
for all category sets A.
Since V ++ (A) consists of all the polynomials that are positive on int(ΣA ), we deduce from
ˇ ∈ NA ∪ {0}: HNV,A c𝑚
ˇ = HNV,A = V ++ (A)
Proposition 28 in Appendix B that, for any 𝑚
and that:
ˇ = H NV,A (p) =
H NV,A (p|𝑚)

p(𝜃) = min p(𝜃) for all p ∈ V (A).

inf
𝜃∈int(ΣA )

37

𝜃∈ΣA

De Cooman, De Bock, & Diniz

Since we know from Proposition 28 in Appendix B, and the counterexample following it, that
generally speaking V + (A) ⊂ V ++ (A), we see that this inference system is less conservative
than the vacuous one. As was the case for the vacuous inference system, the predictive models
for this nearly vacuous inference system are straightforward to find, as they follow directly
ˇ ∈ NA ∪ {0}, we deduce that:
from Equations (21) and (23). For any n̂ ∈ N and any 𝑚
{︁
}︁
n̂
n̂
ˇ = f ∈ L(An̂ ) : Mnn̂A (f ) ∈ V ++ (A) ,
DNV,A
= DNV,A
c𝑚
and
ˇ = min Mnn̂A (f |𝜃) for all f ∈ L(An̂ ).
P n̂NV,A (f ) = P n̂NV,A (f |𝑚)
𝜃∈ΣA

In particular:
1
1
ˇ = L>0 (A),
DNV,A
= DNV,A
c𝑚

ˇ = min f for all f ∈ L(A).
P 1NV,A (f ) = P 1NV,A (f |𝑚)
We see that the immediate prediction models, and the predictive lower previsions, for this
inference system are exactly the same as the ones for the vacuous inference systems.30 They
too do not allow for learning from observations.
Interestingly, and in contrast with the vacuous inference system, the nearly vacuous
inference system is specific, which already tells us that Crs 6= ∅.
Theorem 16. The nearly vacuous inference system ΦNV is coherent, representation insensitive and specific: ΦNV ∈ Crs .

11. The Skeptically Cautious Inference System
We now construct a rather simple inference system that is quite intuitive and slightly more
informative than the vacuous and nearly vacuous ones. Suppose that our subject uses the
following system for making inferences based on a sequence of ň > 0 observations with count
ˇ in a category set A. He is ‘skeptical’ in that he believes that in the future, he will
vector 𝑚,
only observe categories that he has seen previously, so only categories in the set:
ˇ := {x ∈ A : m̌x > 0} .
A[𝑚]

(42)

But he is also ‘cautious’, because his beliefs about which of these already observed categories
will be observed in the future, are ‘nearly’ vacuous. To explain this, assume first that in
particular, for n̂ future observations, he has vacuous beliefs about which count vector he will
observe in the set
{︁
}︁
n̂
n̂
ˆ
ˇ
𝑚 ∈ NA : (∀y ∈ A \ A[𝑚])m̂y = 0 = NA[
ˇ
𝑚]
ˆ that he holds possible after observing the count vector 𝑚,
ˇ
of those future count vectors 𝑚
ˇ 31 By Lemma 47 in Appendix B,
namely those count vectors with no observation outside A[𝑚].
30. This is a first example that shows that the immediate prediction models do not completely determine the
inference system. We shall come across another example in Appendix D.
31. The last equality in the equation above is actually a device that allows us to identify the count vectors on
ˇ are zero, with count vectors on A[𝑚].
ˇ We shall be using it repeatedly,
A whose components outside A[𝑚]
without explicit further mention, in the rest of this paper.

38

Coherent Predictive Inference under Exchangeability

this would lead us to associate the following set of polynomials with any count vector 𝑚 ∈ NA :
{︁
}︁
+
n
V[𝑚]
(A) := p ∈ V (A) : (∃n ≥ deg(p)) bnp |NA[𝑚]
>0
{︁
}︁
+
= p ∈ V (A) : p|ΣA[𝑚] ∈ V (A[𝑚]) .
But, because we already know that the vacuous models V + (A) do not lead to specific systems,
whereas the nearly vacuous models V ++ (A) do, we will modify this slightly, and rather
associate the following set of polynomials with any count vector 𝑚 ∈ NA :
{︁
}︁
++
V[𝑚]
(A) := p ∈ V (A) : p|ΣA[𝑚] ∈ V ++ (A[𝑚]) .
++
The polynomials in V[𝑚]
(A) are ‘desirable in representation’32 after observing a sample with
count vector 𝑚, so we infer from Equation (19) that the subject considers as ‘desirable in
representation’ all polynomials in:
{︁
}︁
++
++
V[𝑚]
(A)BA,𝑚 = pBA,𝑚 : p ∈ V[𝑚]
(A) .

We are thus led to consider the following assessment:
⋃︁
++
ASC,A :=
V[𝑚]
(A)BA,𝑚 ,
𝑚∈NA

and the set of all its positive linear combinations:
HSC,A

:= posi (ASC,A ) =

{︂∑︁
`

pk BA,𝑚k : ` ∈ N, nk ∈ N, 𝑚k ∈

NAnk , pk

}︂

∈

++
V[𝑚
(A)
k]

. (43)

k=1

The following proposition guarantees that the sets HSC,A are the appropriate most conservative
models that summarise the exchangeable inferences for our skeptically cautious subject.
Proposition 17. HSC,A is the smallest Bernstein coherent set of polynomials on ΣA that
includes ASC,A .
This also shows that the inference system ΦSC , defined by ΦSC (A) := HSC,A for all category
sets A, is coherent. We shall call it the skeptically cautious inference system.
We now want to find out how updating works in this system. To this end, we introduce a
slight generalisation of the set defined in Equation (43). Consider any 𝑚 ∈ NA ∪ {0}, and let
HSC,A,𝑚 :=

{︂∑︁
`

pk BA,𝑚k : ` ∈ N, nk ∈ N0 , mA + nk > 0, 𝑚k ∈

NAnk , pk

}︂

∈

++
V[𝑚+𝑚
(A)
k]

,

k=1

(44)
so we see that, in particular, HSC,A = HSC,A,𝑚 for 𝑚 = 0.
The sets HSC,A,𝑚 have the following interesting characterisation:
32. As stated before, polynomials have no direct behavioural but only an indirect representational meaning,
as conveniently condensed representations for desirable gambles on observation sequences. Hence our
caution here in using the term ‘desirable in representation’.

39

De Cooman, De Bock, & Diniz

Proposition 18. For all 𝑚 ∈ NA ∪ {0}:
{︀
}︀
HSC,A,𝑚 = p ∈ V (A) \ {0} : (∀K ∈ min SA,𝑚 (p))p|ΣK ∈ V ++ (K) ,

(45)

where
{︀
}︀
SA,𝑚 (p) := ∅ =
6 K ⊆ A : A[𝑚] ⊆ K and p|ΣK 6= 0 .

(46)

By min SA,𝑚 (p) we mean the set of all minimal, or non-dominating, elements of SA,𝑚 (p),
so min SA,𝑚 (p) := {C ∈ SA,𝑚 (p) : (∀K ∈ SA,𝑚 (p))(K ⊆ C ⇒ K = {︀C)}. We formally extend
}︀
Equation (42) to include the case 𝑚 = 0, so A[0] = ∅ and SA,0 (p) = ∅ =
6 K ⊆ A : p|ΣK 6= 0 .
Proposition 19. For all 𝑚 ∈ NA ∪ {0}: HSC,A c𝑚 = HSC,A,𝑚 .
By combining this result with Equation (21), we can derive—admittedly rather involved—
expressions for the predictive sets of desirable gambles for the skeptically cautious inference
ˇ ∈ NA ∪ {0}:
system. For all n̂ ∈ N and 𝑚
{︁
}︁
n̂
ˇ = f ∈ L(An̂ ) : Mnn̂A (f ) ∈ HSC,A,𝑚
c𝑚
(47)
DSC,A
ˇ .
ˇ ∈ NA :
For immediate prediction, these expressions simplify significantly. For any 𝑚
{︀
}︀
1
1
ˇ = f ∈ L(A) : f |A[𝑚]
DSC,A
= L>0 (A) and DSC,A
c𝑚
ˇ > 0 ∪ L>0 (A).

(48)

ˇ ∈ NA :
The lower previsions that are derived from HSC,A,𝑚
ˇ are more tractable. For any 𝑚
ˇ =
H SC,A (p) = min p(𝜃x◦ ) and H SC,A (p|𝑚)
x∈A

min p(𝜃) for all p ∈ V (A),

𝜃∈ΣA[𝑚]
ˇ

(49)

where, for any x ∈ A, 𝜃x◦ is the degenerate probability mass function on A that assigns all
probability mass to x.
The predictive lower previsions for the skeptically cautious inference system are now
ˇ ∈ NA :
easily obtained by combining Equations (49) and (23). For any n̂ ∈ N and any 𝑚
ˇ =
P n̂SC,A (f |𝑚)

min Mnn̂A (f |𝜃) for all f ∈ L(An )

𝜃∈ΣA[𝑚]
ˇ

(50)

and
P n̂SC,A (f ) = min f (x, x, . . . , x) for all f ∈ L(An ).

(51)

ˇ = min f (x) for all f ∈ L(A).
P 1SC,A (f ) = min f and P 1SC,A (f |𝑚)

(52)

x∈A

In particular:
ˇ
x∈A[𝑚]

The lower probability function is given by:
{︃
1 if k = n > 0
ϕSC (n, k) =
0 otherwise

for all n, k ∈ N0 such that k ≤ n,

and the corresponding imprecision function by:
{︃
1 if n = 0 or 0 < k < n
ιSC (n, k) =
0 otherwise
40

for all n, k ∈ N0 such that k ≤ n.

Coherent Predictive Inference under Exchangeability

Running Example. As before, Mnn̂{H ,T } (IHT
̂︂ |𝜃) = 2θH θT for all n̂ ≥ 2. If we also take into
account that {H , T }[(3, 1)] = {H , T }, we get:
n̂
P n̂SC,{H ,T } (IHT
̂︂ ) = P SC,{H ,T } (IHT
̂︂ |(3, 1)) =

min

Mnn̂{H ,T } (IHT
̂︂ |𝜃) =

𝜃∈Σ{H ,T }

max

Mnn̂{H ,T } (IHT
̂︂ |𝜃) =

𝜃∈Σ{H ,T }

𝜃∈Σ{H ,T }

min

2θH θT = 0

max

1
2θH θT = .
2

and
n̂

n̂

P SC,{H ,T } (IHT
̂︂ ) = P SC,{H ,T } (IHT
̂︂ |(3, 1)) =

𝜃∈Σ{H ,T }

Because all categories are observed for the count vector (3, 1)—meaning that {H , T }[(3, 1)] =
{H , T }—we find the same inferences as for the vacuous inference system.
♦
Interestingly, the coherent inference system ΦSC also satisfies both representation insensitivity and specificity.
Theorem 20. The skeptically cautious inference system ΦSC is coherent, representation
insensitive and specific: ΦSC ∈ Crs .

12. The IDMM Inference Systems
Imprecise Dirichlet Models—or IDMs, for short—are a family of parametric inference models
introduced by Walley (1996) as conveniently chosen sets of Dirichlet densities diA (·|𝛼) with
constant prior weight s:
{︀
}︀
{diA (·|𝛼) : 𝛼 ∈ KsA } , with KsA := 𝛼 ∈ RA
(53)
>0 : αA = s = {s𝑡 : 𝑡 ∈ int(ΣA )} ,
for any value of the (so-called) hyperparameter s ∈ R>0 and any category set A. The Dirichlet
densities diA (·|𝛼) are defined on int(ΣA ); see Appendix C for an explicit definition and
extensive discussion.
These IDMs generalise the Imprecise Beta models introduced earlier by Walley (1991). In
a later paper, Walley and Bernard (1999) focussed on a closely related family of predictive
inference models, which they called the Imprecise Dirichlet Multinomial Models—or IDMMs,
for short.33 We refer to these papers, and to a more recent overview paper by Bernard
(2005) for extensive motivating discussion of the IDM(M)s, their inferences and properties.
For precise Dirichlet models and their expectations, and the related Dirichlet multinomial
models, we have gathered in Appendix C the most important facts, properties and results,
necessary for a proper understanding of our present discussion of the IDM(M)s in the context
of inference systems.
One of the reasons Walley (1996) had for suggesting the IDM as a reasonable model is
precisely that it satisfies the pooling34 invariance properties we discussed in Section 4.1. This
is also discussed with more emphasis by Walley and Bernard (1999) and Bernard (2005), but
we know of no detailed and explicit formulations of these properties in the literature, and
the proofs we have seen are fairly sketchy. Bernard (1997, 2005) also suggests that the IDM
33. In the later paper, Walley and Bernard (1999) clearly distinguish in name between the parametric IDMs
and the predictive IDMMs, while in the earlier paper by Walley (1996), both types of models are referred
to as IDMs.
34. Walley uses the term ‘representation invariance’ rather than ‘pooling invariance’.

41

De Cooman, De Bock, & Diniz

and the underlying precise Dirichlet models satisfy a so-called ‘specificity’ property, which
we have tried to translate to the present context of predictive inference in Section 4.5.
In the present section, we use the ideas behind Walley and Bernard’s IDM(M)s to construct
an interesting family of coherent inference systems, and we give a detailed and formal proof
in Appendix E of the fact that these inference systems are indeed representation insensitive
and specific. Interestingly, we shall need a slightly modified version of Walley’s IDM(M)
to make things work. The reason for this is that Walley’s original version, as described by
Expression (53), has a number of less desirable properties, that seem to have been either
unknown to, or ignored by, Walley and Bernard. We describe these shortcomings in some
detail in Appendix D. For our present purposes, it suffices to mention that, contrary to what
is often claimed, and in contradistinction with our new version, inferences using the original
version of the IDM(M) do not necessarily become more conservative (or less committal) as
the hyperparameter s increases.
In our version, rather than using the hyperparameter sets KsA , we consider the sets
{︀
}︀
∆sA := 𝛼 ∈ RA
>0 : αA < s for all s ∈ R>0 .
Observe that
{︀
}︀
∆sA = s0 𝑡 : s0 ∈ R>0 , s0 < s and 𝑡 ∈ int(ΣA ) =

⋃︁

0

KsA .

0<s0 <s

For any s ∈ R>0 , and any category set A, we now consider the following set of polynomials
p, with positive Dirichlet expectation DiA (p|𝛼) for all hyperparameters 𝛼 ∈ ∆sA :
s
:= {p ∈ V (A) : (∀𝛼 ∈ ∆sA ) DiA (p|𝛼) > 0} .
HIDM,A

We shall see further on in Theorem 21 that this set is Bernstein coherent. We call the inference
system ΦsIDM , defined by:
s
ΦsIDM (A) := HIDM,A
for all category sets A,

the IDMM inference system with hyperparameter s > 0. The corresponding updated models
ˇ ∈ NA ∪ {0}, given by:
are, for any 𝑚
s
ˇ = {p ∈ V (A) : (∀𝛼 ∈ ∆sA ) DiA (p|𝑚
ˇ + 𝛼) > 0}
HIDM,A
c𝑚

(54)

ˇ = inf s DiA (p|𝑚
ˇ + 𝛼) for all p ∈ V (A).
H sIDM,A (p|𝑚)

(55)

and
𝛼∈∆A

Using these expressions, the predictive models for the IDMM inference system are straightforward to find; it suffices to apply Equations (21) and (23). For any n̂ ∈ N and any
ˇ ∈ NA ∪ {0}:
𝑚
{︁
}︁
s,n̂
ˇ = f ∈ L(An̂ ) : (∀𝛼 ∈ ∆sA ) DiA (Mnn̂A (f )|𝑚
ˇ + 𝛼) > 0 ,
DIDM,A
c𝑚
(56)
and
ˇ = inf s DiA (Mnn̂A (f )|𝑚
ˇ + 𝛼) for all f ∈ L(An̂ ),
P s,n̂
IDM,A (f |𝑚)
𝛼∈∆A

42

(57)

Coherent Predictive Inference under Exchangeability

where, using the notations introduced in Appendix C:
ˇ + 𝛼) = DiMnnA (Hyn̂A (f )|𝑚
ˇ + 𝛼)
DiA (Mnn̂A (f )|𝑚
(︂ )︂ ∏︁
∑︁
n̂
1
n̂
ˆ
=
HyA (f |𝑚)
(m̌x + αx )(m̂x ) .
(n̂) 𝑚
ˆ
(m̌A + αA )
n̂
x∈A
ˆ
𝑚∈N

(58)

A

In general, these expressions seem forbidding, but the immediate prediction models are
ˇ ∈ NA ∪ {0}:
manageable enough. For any 𝑚
{︂
}︂
1 ∑︁
s,1
ˇ = f ∈ L(A) : f > −
(59)
DIDM,A c𝑚
f (x)m̌x ,
s
x∈A
∑︁
1
s
ˇ
P s,1
(f
|
𝑚)
=
f (x)m̌x +
min f for all f ∈ L(A),
(60)
IDM,A
m̌A + s
m̌A + s
x∈A

and

k
for all n, k ∈ N0 such that k ≤ n.
n+s
The corresponding imprecision function is given by:
ϕsIDM (n, k) =

ιsIDM (n, k) =

s
for all n, k ∈ N0 such that k ≤ n,
n+s

and it is decreasing in its first and constant in its second argument, which implies that it
satisfies Condition (35). This suggests that IDMM inference systems are conservative when
little has been learned, and become more precise as more observations come in.
Running Example. As before, with Mnn̂{H ,T } (IHT
̂︂ |𝜃) = 2θH θT for all n̂ ≥ 2, we find that,
using the results in Appendix C:
⃒ )︀
(︀
⃒
Di{H ,T } Mnn̂{H ,T } (IHT
̂︂ |𝜃) 𝛼 =

2αH αT
.
(αH + αT )(αH + αT + 1)

It is then not very difficult to verify using Equation (57) that for any 0 < s:
s,n̂

P s,n̂
̂︂ ) = 0 and P IDM,{H ,T } (IHT
̂︂ ) =
IDM,{H ,T } (IHT

1 s
.
21+s

After observing the count vector (3, 1), we find after some manipulations that:
2(3 + σ)
2(3 + s)
=
,
0<σ<s (4 + σ)(5 + σ)
(4 + s)(5 + s)

P s,n̂
̂︂ |(3, 1)) = inf
IDM,{H ,T } (IHT
and similarly:

⎧
⎪
⎪
⎨6

1+s
(4 + s)(5 + s)
s,n̂
P IDM,{H ,T } (IHT
̂︂ |(3, 1)) =
⎪
1
4+s
⎪
⎩
25+s

if s ≤ 2
if s ≥ 2.

Observe that for infinitely large s, we recover the inferences for the vacuous system.
43

♦

De Cooman, De Bock, & Diniz

Interestingly, the immediate prediction models for our version of the IDMM inference
system coincide with those of Walley’s original version. Hence, in the many practical applications that are concerned with immediate prediction only, both approaches yield identical
results.
The IDMM inference systems constitute an uncountably infinite family of coherent
inference systems, each of which satisfies the representation insensitivity and specificity
requirements.
Theorem 21. For any s ∈ R>0 , the IDMM inference system ΦsIDM is coherent, representation
insensitive and specific: ΦsIDM ∈ Crs .
s
Since Crs is closed under non-empty infima, the infimum Φ∞
IDM of all ΦIDM , s > 0 is
still coherent, representation insensitive and specific, and more conservative than any of the
IDMM inference systems. It is given by:
{︀
}︀
+++
Φ∞
(A) := p ∈ V (A) : (∀𝛼 ∈ RA
IDM (A) = V
>0 ) DiA (p|𝛼) > 0 ,

and although this set generally strictly includes the sets V + (A) and V ++ (A), the associated
immediate prediction models and predictive lower previsions can be shown to coincide with
the ones for the vacuous and nearly vacuous inference systems.

13. The Skeptical IDMM Inference Systems
We now combine the ideas in the previous two sections: we suppose that our subject uses
the following system for making inferences based on a sequence of ň > 0 observations with
ˇ in a category set A. As before in Section 11, he is skeptical in that he
count vector 𝑚,
believes that in the future, he will only observe categories that he has seen previously, so only
ˇ But rather than being cautious in having completely vacuous
categories in the set A[𝑚].
beliefs about which of these already observed categories will be observed in the future, he
uses an IDMM-like inference for them, as described in Section 12.
It turns out this can be done quite simply by replacing, in the characterisation (45) of
the sets HSC,A,𝑚 of the skeptically cautious inference system, the nearly vacuous models
s
V ++ (K) by the appropriate IDMM models HIDM,K
crK (𝑚). So we define, for any category
set A, any 𝑚 ∈ NA ∪ {0} and any s ∈ R>0 , the following set of polynomials:
{︀
}︀
s
s
:= p ∈ V (A) \ {0} : (∀K ∈ min SA,𝑚 (p))p|ΣK ∈ HIDM,K
HSI,A,𝑚
crK (𝑚) ,
(61)
where we recall that if K ∈ min SA,𝑚 (p), then A[𝑚] ⊆ K and therefore K[rK (𝑚)] =
A[𝑚] ∩ K = A[𝑚], so 𝑚 and rK (𝑚) are essentially the same count vectors. We also let
s
s
:= HSI,A,𝑚
HSI,A
for 𝑚 = 0, or in other words:
}︀
{︀
s
s
:= p ∈ V (A) \ {0} : (∀K ∈ min SA,0 (p))p|ΣK ∈ HIDM,K
HSI,A
,
{︀
}︀
where, again, SA,0 (p) = ∅ =
6 K ⊆ A : p|ΣK 6= 0 . In the remainder of this section, we show
s
that the sets of polynomials HSI,A
indeed lead to the definition of a reasonable and potentially
useful type of inference system. We begin with coherence.
s
Proposition 22. HSI,A
is a Bernstein coherent set of polynomials on ΣA .

44

Coherent Predictive Inference under Exchangeability

s
This shows that the inference system ΦsSI , given by ΦsSI (A) := HSI,A
for all category sets A,
s
is coherent. We call ΦSI the skeptical IDMM inference system with hyperparameter s.
We now want to find out how updating works in this inference system. The following
proposition should not really come as a surprise.
s
s
Proposition 23. For any 𝑚 ∈ NA ∪ {0}: HSI,A
c𝑚 = HSI,A,𝑚
.

By combining this with Equation (21), we obtain the following—again, rather involved—
predictive sets of desirable gambles for the skeptical IDMM inference systems. For any n̂ ∈ N
ˇ ∈ NA ∪ {0}:
and any 𝑚
{︁
}︁
s,n̂
s
ˇ = f ∈ L(An̂ ) : Mnn̂A (f ) ∈ HSI,A,
DSI,A
c𝑚
(62)
ˇ .
𝑚
s
ˇ are rather abstract, this is not the case for the
Although the expressions for HSI,A
c𝑚
ˇ ∈ NA :
corresponding lower previsions. For any 𝑚

H sSI,A (p) = min p(𝜃x◦ ) for all p ∈ V (A)
x∈A

(63)

and
ˇ =
H sSI,A (p|𝑚)

inf

𝛼∈∆sA[𝑚]
ˇ

ˇ + 𝛼)
DiA[𝑚]
|rA[𝑚]
ˇ (p|ΣA[𝑚]
ˇ (𝑚)
ˇ

ˇ for all p ∈ V (A).
= H sIDM,A[𝑚]
|rA[𝑚]
ˇ (𝑚))
ˇ (p|ΣA[𝑚]
ˇ

(64)
(65)

Combining this with Equation (23), we immediately obtain the following predictive lower
ˇ ∈ NA :
previsions for the skeptical IDMM inference systems. For any n̂ ∈ N and any 𝑚
n̂
P s,n̂
SI,A (f ) = min f (x, x, . . . , x) for all f ∈ L(A )
x∈A

and
ˇ =
P s,n̂
SI,A (f |𝑚)

inf

𝛼∈∆sA[𝑚]
ˇ

n̂
ˇ + 𝛼)
DiA[𝑚]
ˇ (MnA[𝑚]
ˇ (𝑚)
ˇ (f |A[𝑚]
ˇ n̂ )|rA[𝑚]

ˇ for all f ∈ L(An̂ ).
= P s,n̂
ˇ (𝑚))
ˇ n̂ |rA[𝑚]
ˇ (f |A[𝑚]
IDM,A[𝑚]

(66)

The immediate prediction models of the skeptical IDMM inference systems are surprisingly
more manageable:
s,1
DSI,A
= L>0 (A) and P s,1
SI,A (f ) = min f for all f ∈ L(A)

ˇ ∈ NA :
and, for any 𝑚
{︂
}︂
1 ∑︁
s,1
ˇ = f ∈ L(A) : f |A[𝑚]
DSI,A c𝑚
f (x)m̌x ∪ L>0 (A)
ˇ >−
s

(67)

ˇ
x∈A[𝑚]

∑︁
1
s
s,1
ˇ =
(f |𝑚)
f (x)m̌x +
min f (x) for all f ∈ L(A).
P SI,A
m̌A + s
m̌A + s x∈A[𝑚]
ˇ
ˇ
x∈A[𝑚]

45

(68)

De Cooman, De Bock, & Diniz

The lower probability function is given by:
{︃
k
if k < n or n = 0
s
ϕSI (n, k) = n+s
1
if k = n > 0
and the corresponding imprecision function by:
{︃
s
if n = 0 or 0 < k < n
s
ιSI (n, k) = n+s
0
otherwise

for all n, k ∈ N0 such that k ≤ n,

for all n, k ∈ N0 such that k ≤ n.

When we consider the case n > 0, we see that ιsSI (n, n) = 0 but ιsSI (n + 1, n) =
this imprecision function does not satisfy Condition (35).

s
n+1+s

> 0, so

Running Example. Because {H , T }[(3, 1)] = {H , T }, we infer from Equation (66) that the
̂︂ are the same as for the IDMM inference systems.
inferences about the event HT
♦
All the coherent inference systems ΦsSI also satisfy both representation insensitivity and
specificity.
Theorem 24. For each s ∈ R>0 , the corresponding skeptical IDMM inference system is
coherent, representation insensitive, and specific: ΦsSI ∈ Crs .
s
Since Crs is closed under non-empty infima, the infimum Φ∞
SI of all ΦSI , s > 0 is still
coherent, representation insensitive and specific, and more conservative than any of the
skeptical IDMM inference systems. It can be shown that the associated immediate prediction
models and predictive lower previsions coincide with the ones for the skeptically cautious
inference system.

14. The Haldane Inference System
We already know from our discussion of near-ignorance following Theorem 4 that no representation insensitive coherent inference system can be fully precise, as its immediate prediction
models before observations have been made, must be completely vacuous. But we can ask
ourselves whether there are representation insensitive (and specific) inference systems whose
posterior predictive lower previsions become precise (linear) previsions. This is the problem we
address in this section. We shall first construct such an inference system, and then show that
this system is, in some definite sense, unique in having linear posterior predictive previsions.
We use the family of all IDMM inference systems ΦsIDM , s ∈ R>0 , to define an inference
system ΦH that is more committal than any of them:
⋃︁
⋃︁
s
HIDM,A
=
ΦsIDM (A) for all category sets A.
ΦH (A) = HH,A :=
s∈R>0

s∈R>0

We call this ΦH the Haldane inference system, for reasons that will become clear further on
in this section.
Theorem 25. The Haldane inference system ΦH is coherent, representation insensitive and
specific: ΦH ∈ Crs .
46

Coherent Predictive Inference under Exchangeability

Due to its representation insensitivity, the Haldane system satisfies prior near-ignorance.
This implies that before making any observation, its immediate prediction model is vacuous,
and as far away from a precise probability model as possible. But we are about to show
that, after making even a single observation, its inferences become precise-probabilistic: they
coincide with the inferences generated by the Haldane (improper) prior.
To get there, we first take a look at the models involving sets of desirable gambles. For
ˇ ∈ NA ∪ {0}:
any 𝑚
⋃︁
s
ˇ = {p ∈ V (A) : (∃s ∈ R>0 )(∀𝛼 ∈ ∆sA ) DiA (p|𝑚
ˇ + 𝛼) > 0} =
ˇ
HH,A c𝑚
HIDM,A
c𝑚.
s∈R>0
(69)
The corresponding predictive models are easily derived by applying Equation (21). For any
ˇ ∈ NA ∪ {0}:
n̂ ∈ N and any 𝑚
{︁
}︁
n̂
ˇ = f ∈ L(An̂ ) : (∃s ∈ R>0 )(∀𝛼 ∈ ∆sA ) DiA (Mnn̂A (f )|𝑚
ˇ + 𝛼) > 0
DH,A
c𝑚
⋃︁
s,n̂
ˇ
=
DIDM,A
c𝑚.
(70)
s∈R>0

The immediate prediction models are obtained by combining Equations (70) and (59). For
ˇ ∈ NA :
any 𝑚
{︂
}︂
∑︁
1
1
ˇ = f ∈ L(A) :
DH,A = L>0 (A) and DH,A c𝑚
f (x)m̌x > 0 ∪ L>0 (A).
x∈A

It turns out that the expressions for the corresponding lower previsions are much more
ˇ ∈ NA ∪ {0}:
manageable. First of all, we find for any 𝑚
ˇ + 𝛼) = lim H sIDM,A (p|𝑚)
ˇ for all p ∈ V (A).
inf DiA (p|𝑚

ˇ = lim
H H,A (p|𝑚)

s→+0 𝛼∈∆sA

s→+0

(71)

ˇ = 0, this simplifies to:
In particular, for 𝑚
H H,A (p) = min p(𝜃x◦ ) for all p ∈ V (A),
x∈A

(72)

ˇ ∈ NA , we find linear previsions:35
whereas for any 𝑚
ˇ = H H,A (p|𝑚)
ˇ = HH,A (p|𝑚)
ˇ = DiA (p|𝑚)
ˇ for all p ∈ V (A).
H H,A (p|𝑚)

(73)

The corresponding predictive models are easily derived by applying Equation (23). For any
ˇ ∈ NA ∪ {0}:
n̂ ∈ N and any 𝑚
ˇ = lim
P n̂H,A (f |𝑚)

ˇ + 𝛼) = lim P s,n̂
ˇ for all f ∈ L(An̂ ).
inf DiA (Mnn̂A (f )|𝑚
IDM,A (f |𝑚)

s→+0 𝛼∈∆sA

s→+0

(74)
ˇ = 0:
In particular, for 𝑚
P n̂H,A (f ) = min f (x, x, . . . , x) for all f ∈ L(An̂ ),
x∈A

35. The Dirichlet expectations DiA (·|𝛼) are strictly speaking defined for 𝛼 ∈ RA
>0 , but as we argue in
Appendix C, they can be continuously extended to 𝛼 with some components zero, and the others strictly
positive.

47

De Cooman, De Bock, & Diniz

ˇ ∈ NA :
and for any 𝑚
ˇ
P n̂H,A (f |𝑚)

=

n̂
ˇ
P H,A (f |𝑚)

=

n̂
ˇ
PH,A
(f |𝑚)

=

∑︁
n̂
𝑛∈NA

(︂ )︂ ∏︀
(nx )
n̂
x∈A m̌x
.
(n̂)
𝑛
m̌

Hyn̂A (f |𝑛)

(75)

A

ˇ ∈ NA :
For the immediate prediction models, we find that for any 𝑚
∑︁
m̌x
1
ˇ =
P 1H,A (f ) = min f and PH,A
(f |𝑚)
f (x)
for all f ∈ L(A),
m̌A
x∈A

and the lower probability function is given by:
{︃
k
if n > 0
ϕH (n, k) = n
for all n, k ∈ N0 such that k ≤ n.
0
if n = 0
The corresponding imprecision function is given by:
{︃
1 if n = 0
ιH (n, k) =
for all n, k ∈ N0 such that k ≤ n,
0 if n > 0
and it satisfies Condition (35), which suggests that also the Haldane inference system displays—
albeit in an extreme and not very interesting manner—the desirable behaviour mentioned in
the Introduction: it is conservative when little has been learned, and it never become less
precise as more observations come in.
Running Example. We can use Equation (74) and the results previously obtained for the
IDMM inference systems to find that
n̂

n̂
P n̂H,{H ,T } (IHT
̂︂ ) = 0 and PH,{H ,T } (IHT
̂︂ |(3, 1)) =
̂︂ ) = P H,{H ,T } (IHT

3
.
10

We want to point out that the first equalities do not contradict the prior near-ignorance of
the Haldane inference system, as that only pertains to immediate predictions: predictions
about single future observations.
♦
The precise posterior predictive previsions in Equation (75) are exactly the ones that
would be found were we to formally apply Bayes’s rule with a multinomial likelihood and
Haldane’s improper prior (Haldane,∏︀
1945; Jeffreys, 1998; Jaynes, 2003), whose ‘density’ is a
function on int(ΣA ) proportional to x∈A θx−1 . This, of course, is why we use Haldane’s name
for the inference system that produces them. Our argumentation shows that there is nothing
wrong with these posterior predictive previsions, as they are based on coherent inferences. In
fact, our analysis shows that there is an infinity of precise and proper priors on the simplex
ΣA that, together with the multinomial likelihood, are coherent with these posterior predictive
previsions: every coherent prevision on V (A) that dominates the coherent lower prevision
H H,A on V (A).36 For binomial parametric inferences under the Haldane prior, Walley (1991,
Section 7.4.8) comes to a related conclusion in a completely different manner.
36. It is an immediate consequence of the F. Riesz Representation Theorem that each such coherent prevision
is the restriction to polynomials of the expectation operator of some unique σ-additive probability measure
on the Borel sets of ΣA ; see for instance the discussion by De Cooman and Miranda (2008a) and also
footnote 2.

48

Coherent Predictive Inference under Exchangeability

There is a simple argument to show that these Haldane posterior predictive previsions
are the only precise ones that are compatible with representation insensitivity. Indeed, it
can be shown that for any representation insensitive coherent inference system with precise
posterior predictive previsions, the lower probability function must satisfy ϕ(n, k) = k/n for
n > 0 and 0 ≤ k ≤ n,37 and then it is straightforward to prove, using Bayes’s Theorem to go
from immediate prediction to more general predictive inference, that the posterior predictive
previsions must be Haldane’s.

15. Characterisation of the IDMM Immediate Predictions
The lower probability function ϕ(n, k) for a representation insensitive coherent inference
system gives the lower probability of observing a non-trivial event that has been observed k
times before in n trials.
Now suppose that a subject specifies a single lower probability, namely the value of
ϕ(1, 1) ∈ [0, 1]: the probability of observing something (again) that has been observed (once)
in a single trial. Then we can ask ourselves what the most conservative consequences of such
an assessment are, if we take representation insensitivity and specificity for granted. In other
words, what is the most conservative representation insensitive and specific coherent inference
system that has (at least) this given value ϕ(1, 1) for its lower probability function? This
question makes sense because the representation insensitive and specific coherent inference
systems constitute a complete meet-semilattice by Statement (25) and Theorems 8 and 12.38
Clearly, if ϕ(1, 1) = 0, this is the smallest representation insensitive and specific coherent
inference system, which as we know from the discussion in Sections 9 and 10, must have the
same immediate prediction models and predictive lower previsions as the (nearly) vacuous
inference system. We consider the case that 0 < ϕ(1, 1) < 1,39 or in other words, to use a
parametrisation that will turn out to be more convenient for our purposes, that:
ϕ(1, 1) =

1
1
for some positive real number s :=
− 1.
1+s
ϕ(1, 1)

(76)

Let us denote this most conservative inference system by Φs , and its lower probability
1
function by ϕs , then by assumption ϕs (1, 1) ≥ 1+s
. It now follows from Theorem 14.L9 that
n
s
ϕ (n, n) ≥ n+s for all n ∈ N0 . But since for the IDMM inference system ΦsIDM , Equation (60)
n
tells us that ϕsIDM (n, n) = n+s
, and since by assumption ϕsIDM (n, n) ≥ ϕs (n, n), we conclude
that:
n
ϕs (n, n) = ϕsIDM (n, n) =
for all n ∈ N0 .
(77)
n+s
It has been surmised (Bernard, 2007; De Cooman et al., 2009a) that the IDMM inference
system with hyperparameter s could be the smallest, most conservative, representation
1
insensitive and specific coherent inference system with a given value ϕ(1, 1) = 1+s
. In
fact, trying to prove this was what made us start research on the present paper. But
this conjecture turns out to be false: apart from the lower bound (77) on the ϕ(n, n),
37. It suffices to exploit the additivity of precise probabilities and the symmetry implied by representation
insensitivity; for an explicit proof, see the paper by De Cooman et al. (2009a, Thm. 7).
38. See the discussion near the end of Section 7.
39. We surmise, but do not prove here, that the most conservative representation insensitive and specific
coherent inference system corresponding to ϕ(1, 1) = 1 might be the skeptically cautious one.

49

De Cooman, De Bock, & Diniz

representation insensitivity and specificity impose no lower bounds on the ϕ(n, k) for k < n.
To see this, consider the inference system ΦsMC := inf{ΦSC , ΦsIDM }, which by Statement (25)
and Theorems 8, 12, 20 and 21 is coherent, representation insensitive and specific: ΦsMC ∈ Crs .
Its lower probability function ϕsMC satisfies:
{︃
n
n
min{1, n+s
} = n+s
if k = n > 0
ϕsMC (n, k) = min{ϕSC (n, k), ϕsIDM (n, k)} =
k
min{0, n+s } = 0
otherwise,
substantiating the claim we made above. See also Figure 1, where we have depicted lower (and
upper) probability functions for the Haldane system ΦH , the IDMM system ΦsIDM , ΦsMC and
n
s
the inference system inf{Φ4s
SI , ΦIDM }. The latter three all share the same value n+s for ϕ(n, n),
n ≥ 0. We conjecture that ΦsMC could be the smallest, most conservative, representation
1
insensitive and specific coherent inference system with a given value ϕ(1, 1) = 1+s
, but offer
no proof for this.
ϕ(n, k)
1
n
n+s

s
n+s

0
0

1

2

...

n−1

n

k

Figure 1: Lower and upper probability functions: ϕH for the Haldane system (dark grey,
s
4), ϕsIDM for the IDMM system with hyperparameter s (blue, ?), min{ϕ4s
SI , ϕIDM }
(orange, ) and ϕsMC = min{ϕSC , ϕsIDM } (red, ◦). This specific plot was made for
n = 10 and s = 2.
This means that if we want to characterise the IDMM inference systems in any way as
the most conservative ones, we need to add, besides coherence, representation insensitivity
and specificity, another requirement that is preserved under taking infima. One possible
candidate for this, which we shall prove does the job and is inspired by Figure 1, is the
following requirement.
Let us define the subject’s surprise of an event as his supremum rate for betting on the
opposite event, or in other words, his lower probability for the opposite event. This surprise
is high—close to one—when the subject believes strongly that the event will not occur, and
low—close to zero—when the subject has no strong beliefs that it will not occur.
50

Coherent Predictive Inference under Exchangeability

This allows us to associate a so-called surprise function ς(n, k) := ϕ(n, n − k) with a
lower probability function, where ς(n, k) is the subject’s surprise when observing a non-trivial
event that has been observed k out of n times before.
It follows from Theorem 14.L5 that for any representation insensitive system, the surprise
function is non-increasing in its second argument:
∆ς(n, k) := ς(n, k + 1) − ς(n, k) = ϕ(n, n − k − 1) − ϕ(n, n − k) ≤ 0 for 0 ≤ k ≤ n − 1.
This is a fairly intuitive property: the more often an event has been observed before, the
smaller the surprise is at seeing it again.
We shall say that a representation insensitive system has concave surprise if
∆2 ς(n, k) := ∆ς(n, k + 1) − ∆ς(n, k) ≤ 0 for 0 ≤ k ≤ n − 2,
where, of course, ∆2 ς(n, k) = ϕ(n, n − k − 2) − 2ϕ(n, n − k − 1) + ϕ(n, n − k). It is not
difficult to see that having concave surprise is preserved under taking non-empty infima
of inference systems, so it makes sense to go looking for the smallest (most conservative)
coherent representation insensitive and specific coherent inference system that has concave
surprise, and satisfies some additional local assessments, such as (76).
Looking at Figure 1 makes us suspect that the IDMM inference system ΦsIDM might be
this system, but again, we offer no proof for this conjecture. We can however provide a proof
for the following, related but (probably) weaker, statement, which focusses on immediate
prediction only:
Theorem 26. The immediate prediction models P 1A (·|𝑚), 𝑚 ∈ NA ∪ {0} for the smallest
(most conservative) coherent representation insensitive and specific coherent inference system
Φ that has concave surprise and satisfies (76), coincide with the ones for the IDMM inference
system ΦsIDM with hyperparameter s.

16. Conclusion
We believe this is the first paper that tries to deal in a systematic fashion with principles for
predictive inference under exchangeability using imprecise probability models. Two salient
features of our approach are (i) that we consistently use coherent sets of desirable gambles as
our uncertainty models of choice; and (ii) that our notion of an inference system allows us to
derive a conservative predictive inference method combining both local predictive probability
assessments and general inference principles.
The first feature is what allows us, in contradistinction with most other approaches in
probability theory, to avoid problems with determining unique conditional models from
unconditional ones when conditioning on events with (lower) probability zero. A set of
n̂ c𝑚
ˇ and
polynomials HA completely determines all prior and posterior predictive models DA
n̂
ň
ˇ even when the (lower) prior probability P A ([𝑚])
ˇ = H A (BA,𝑚
P A (·|𝑚),
ˇ ) of observing the
ˇ is zero. An approach using only lower previsions and probabilities would make
count vector 𝑚
this much more complicated and involved, if not impossible. Interestingly, we can provide
a perfect illustration of this fact using the results in Sections 11, 13 and 14.40 The three
40. Something similarly ‘dramatic’ happens in Sections 9 and 10: the inference systems there have the same
immediate prediction models and the same (predictive) lower previsions, but one is specific and the other
is not.

51

De Cooman, De Bock, & Diniz

inference systems that are described there—the skeptically cautious, the skeptical IDMM and
the Haldane systems—have, for any given category set A, three different sets of polynomials
HA . Nevertheless, as we can gather from Equations (49), (63) and (72), they have the same
lower prevision H A and therefore the same prior predictive models P n̂A . And any count vector
ˇ ∈ NA has the same prior lower probability:
𝑚
◦
ˇ = H A (BA,𝑚
P ňA ([𝑚])
ˇ ) = min BA,𝑚
ˇ (𝜃x ) = 0.
x∈A

ˇ and the
This zero lower probability makes sure that the posterior lower previsions H A (·|𝑚)
ˇ are not uniquely determined by the prior lower prevision
posterior predictive models P n̂A (·|𝑚)
H A : we infer from Equations (49), (65) and (73) that they are indeed very different for these
three types of inference systems. We fail to see how we could have come up with—let alone
proved the necessary results for—these three systems relying only on lower prevision or credal
set theory.
We can—and must—take this line of argumentation even further. By Theorem 4, any
inference system that satisfies (prior) representation insensitivity has near-vacuous prior
predictive models, and therefore, by time consistency and coherence [monotonicity], we see
ň
ˇ = 0 for any
that its prior predictive lower previsions must satisfy H A (BA,𝑚
ˇ ) = P A ([𝑚])
ˇ ∈ NA as well. This simply means that it is impossible in a (prior) representation insensitive
𝑚
coherent inference system for the lower prevision H A to uniquely determine the conditional
ˇ And therefore any systematic way of dealing with such inference
lower previsions H A (·|𝑚).
systems must be able to resolve—or deal with—this non-unicity in some way. We believe
our approach involving coherent sets of desirable gambles is one of the mathematically more
elegant ways of doing this.
The second feature has allowed us, as an example, to characterise the IDMM immediate
predictions as the most conservative ones satisfying a number of inference principles. The
approach we follow can—at least in principle—also be used for other types of inference
systems and other inference principles. The key requirement for an inference principle to
make it amenable to our approach is that, when formulated as a property of an inference
system, it should be preserved under taking arbitrary non-empty infima. The three inference
principles that we have been considering above—representation insensitivity, specificity and
having concave surprise—have this property, but there is nothing that prevents our analysis
and approach from being extended to any other inference principle that has it too. The only
complications we see, at this point, are of a technical mathematical nature. The reader will no
doubt have noticed that our proofs for the results in the later sections are quite involved and
technical, and rely quite heavily on properties of polynomials on a simplex. We feel that in
the present paper we have made some headway into this mathematical territory, for instance
with our new discussion about the Bernstein positivity of polynomials near Proposition 28
in Appendix B. In the Conclusions of a paper by De Cooman and Quaeghebeur (2012), a
characterisation of Bernstein positivity was mentioned as an open problem with interesting
practical applications in doing inference—natural extension—under exchangeability. But
much remains open for further exploration, and a more determined study of the mathematical
structure and properties of such polynomials would certainly help in alleviating the technical
difficulties of working with inference principles in inference systems.
While this paper has only just opened up what we feel to be an interesting line of
research into the foundations of predictive inference, it nevertheless has provided answers to
52

Coherent Predictive Inference under Exchangeability

a number of—if not all—open problems formulated in the Conclusions of an earlier paper by
De Cooman et al. (2009a), who tried to deal with representation insensitivity in immediate
prediction. As a first example: it was asked there whether there are representation insensitive
coherent inference systems whose lower probability functions are not additive in the second
argument? It suffices to look at Figure 1 to see that the answer is, clearly, yes. Another
question was: are there representation insensitive coherent inference systems that are not
mixing predictive systems?41 It follows from Equation (68) that the answer is yes: each of
the skeptical IDMM inference systems provides an example. Finally, we can use the infimum
ΦsMC of the skeptically cautious inference system ΦSC and an IDMM inference system ΦsIDM ,
mentioned briefly in Section 15, to answer two more questions. Are there representation
insensitive coherent inference systems for which the inequality in Theorem 14.L6 is strict?
And are there representation insensitive coherent inference systems whose behaviour on
gambles is not completely determined by their lower probability function? The inference
system ΦsMC provides a positive answer to both questions.
Most of the inference systems mentioned above, apart from the IDMM and the Haldane
systems, appear here for the first time. Some of them may appear contrived and perhaps
even artificial, but we have found them to be most useful in constructing (counter)examples,
shaping intuition, and building new models, as Figure 1 and the argumentation above clearly
indicate. We might also wonder whether there are other representation insensitive and/or
specific coherent inference systems, which cannot be produced as appropriately chosen infima
of the examples we have introduced here. We suggest, as candidates for further consideration,
the inference systems that can be derived using Walley’s (1997) bounded derivative model,
and inference systems that can be constructed using sets of infinitely divisible distributions,
as recently proposed by Mangili and Benavoli (2013). The framework provided here, as well as
the simple characterisation results of Theorems 7 and 11, should be quite useful in addressing
this and similar problems.
To end, we want to draw attention once again to a simple and direct, but quite appealing,
consequence of our argumentation in Section 14: there is an infinity of precise and proper
priors that, together with the multinomial likelihood, are coherent with the Haldane posterior
predictive previsions. So, there is no need for improper priors to ‘justify’ these posteriors, as
there are proper priors that will do the job perfectly well. This (precise-)probabilistic conclusion
follows easily when looking at the problem using the more general and powerful language
of imprecise probabilities. Moreover, we have seen that properties such as representation
insensitivity cannot be satisfied by precise probabilistic models. Finally, the entire framework
of conservative predictive inference using inference principles would be impossible to develop
within the more limitative context of precise probabilities. This shows that there are distinct
advantages to using imprecise probability models for dealing with predictive inference.

Acknowledgements
Gert de Cooman’s research was partially funded through project number 3G012512 of the
Research Foundation Flanders (FWO). Jasper De Bock is a PhD Fellow of the Research
41. Loosely speaking: that cannot be written as a (specific kind of) convex mixture of the Haldane inference
system and an IDMM inference system; see the paper by De Cooman et al. (2009a, Section 5) for more
information.

53

De Cooman, De Bock, & Diniz

Foundation Flanders and wishes to acknowledge its financial support. Marcio Diniz was
supported by FAPESP (São Paulo Research Foundation), under the project 2012/14764-0
and wishes to thank the SYSTeMS Research Group at Ghent University for its hospitality and
support during his sabbatical visit there. The authors would like to thank three anonymous
reviewers for their many insightful comments and suggestions aimed at making this paper
easier to read and cleaning up misunderstandings. A special thank you also to the great
Arthur Van Camp for his enthusiasm in everything and, in particular, in helping us check
little examples.

Appendix A. Notation
In this appendix, we provide a list of the most commonly used and most important notation,
and where it is defined or first introduced.
notation

meaning

introduced where

A, B, C, D
IB
X, Xn
ň
n̂
posi(A)
L(A)
L>0 (A)
L≤0 (A)
ˇ
𝑥
ˇ
𝑚
n̂
DA

category sets, events
indicator of an event B
variable, variable at time n
number of already observed variables
number of to be observed variables
cone generated by A
set of all gambles on A
set of all positive gambles on A
set of all non-positive gambles on A
observed sample
observed count vector
prior predictive set of desirable gambles
for category set A and n̂ future observations
posterior predictive set of desirable gambles
prior predictive lower prevision
posterior predictive lower prevision
pooling map or relabelling map
renaming bijection
category permutation
sample with observations outside B eliminated
counting map
set of count vectors for n observations
set of all count vectors, with zero
hypergeometric expectation operator
multinomial coefficient with count vector 𝑚
multinomial expectation operator
simplex of all probability mass functions on A
sum of components θx of 𝜃 over x ∈ B
Bernstein basis polynomial
set of polynomials of degree up to n on ΣA

Section 1
Section 2.2
Section 1
Section 1
Section 1
Equation (1)
Section 2.2
Section 2.2
Section 2.2
Section 3
Section 5.4
Section 3

n̂ c𝑥,
n̂ c𝑚
ˇ DA
ˇ
DA
n̂
P A (·)
ˇ P n̂A (·|𝑚)
ˇ
P n̂A (·|𝑥),
ρ
λ
$
ˇ B
𝑥↓
𝑇
NAn
NA , NA ∪ {0}
HynA (·|𝑚)
ν(𝑚)
MnnA (·|𝜃)
ΣA
θB
BA,𝑚
V n (A)

54

Section 3
Section 3
Section 3
Sections 4.1&4.4
Section 4.2
Sections 4.3
Section 4.5
Equation (8)
Equation (9)
Section 5.3
Equation (10)
Equation (11)
Equation (13)
Equation (12)
Equation (12)
Equation (15)
Section 5.3

Coherent Predictive Inference under Exchangeability

V (A)
V + (A)
V ++ (A)
HA
ˇ
HA c𝑚
HA
ˇ
H A (·|𝑚)
F
Φ
C
Crs
Rρ
rB
iA
IrB,A
SA
ϕ
ι
ς
subscript
subscript
subscript
subscript
subscript
subscript
subscript
ˇ
A[𝑚]
++
V[𝑚]
(A)

V
NV
SC
IDM
SI
H
OI

diA (·|𝛼)
DiA (·|𝛼)
DiMnnA (·|𝛼)
bnp

set of all polynomials on ΣA
set of Bernstein positive polynomials on ΣA
set of polynomials on ΣA
that are positive on int(ΣA )
representing set of polynomials
updated representing set of polynomials
lower prevision induced by HA
ˇ
lower prevision induced by HA c𝑚
set of all category sets
inference system
set of all coherent inference systems
set of coherent inference systems that are
representation insensitive and specific
extended relabelling map
restriction map
injection map
extended injection map
sampling expectation
lower probability function
imprecision function
surprise function
related to vacuous inference system
related to nearly vacuous inference system
related to skeptically cautious inference system
related to IDMM inference systems
related to skeptical IDMM inference systems
related to Haldane inference system
related to original IDMM inference systems
categories in A already observed
set of polynomials on ΣA
that are positive on int(ΣA[𝑚] )
Dirichlet density
Dirichlet expectation operator
Dirichlet multinomial expectation operator
expansion of polynomial p
in Bernstein basis of degree n

Section 5.3
Section 5.3
Section 10
Theorem 5
Equation (19)
Equation (17)
Equation (20)
Definition 6
Definition 6
Equation (24)
Theorem 12
Equation (26)
Equation (27)
Equation (28)
Equation (29)
Section 8
Equation (33)
Equation (34)
Section 15
Section 9
Section 10
Section 11
Section 12
Section 13
Section 14
Appendix D
Equation (42)
Section 11
Appendix
Appendix
Appendix
Appendix

C
C
C
B

Appendix B. Multivariate Bernstein Basis Polynomials
With any n ≥ 0 and 𝑚 ∈ NAn there corresponds
Bernstein basis polynomial
∏︀ a (multivariate)
m
x
:=
of degree n on ΣA , given by BA,𝑚 (𝜃)
ν(𝑚) x∈A θx , 𝜃 ∈ ΣA . These polynomials have a
number of very interesting properties (see for instance Prautzsch, Boehm, & Paluszny, 2002,
Chapters 10 and 11), which we list here:
BB1. The set {BA,𝑚 : ∑︀
𝑚 ∈ NAn } of all Bernstein basis polynomials of fixed degree n is linearly
independent: if 𝑚∈N n λ𝑚 BA,𝑚 = 0, then λ𝑚 = 0 for all 𝑚 in NAn .
A

55

De Cooman, De Bock, & Diniz

∈ NAn } of all Bernstein basis polynomials of fixed degree n forms a
BB2. The set {BA,𝑚 : 𝑚∑︀
partition of unity: 𝑚∈N n BA,𝑚 = 1.
A

BB3. All Bernstein basis polynomials are non-negative, and strictly positive on the interior
int(ΣA ) of ΣA .
BB4. The set {BA,𝑚 : 𝑚 ∈ NAn } of all Bernstein basis polynomials of fixed degree n forms a
basis for the linear space of all polynomials whose degree is at most n.
Property BB4 follows from BB1 and BB2.42 It follows from BB4 that:
BB5. Any polynomial p has a unique expansion in terms of the Bernstein basis polynomials—
also called Bernstein expansion—of fixed degree n ≥ deg(p),
or in other words, there is a unique count gamble bnp on NAn such that:
∑︁
p(𝜃) =
bnp (𝑚)BA,𝑚 (𝜃) for all 𝜃 ∈ ΣA .

(78)

n
𝑚∈NA

This tells us [also use BB2 and BB3] that each p(𝜃) is a convex combination of the Bernstein
coefficients bnp (𝑚), 𝑚 ∈ NAn whence:
min bnp ≤ min p ≤ p(𝜃) ≤ max p ≤ max bnp for all 𝜃 ∈ ΣA .

(79)

The following proposition adds more detail to this picture.
Proposition 27. For any polynomial p on ΣA :
lim [min bnp , max bnp ] = [min p, max p] = p(ΣA ).

n→+∞
n≥deg(p)

Proof of Proposition 27. Since bnp converges uniformly to the polynomial p as n → +∞
(Trump & Prautzsch, 1996), in the sense that
⃒ (︁ 𝜇 )︁
⃒
⃒
⃒
lim maxn ⃒p
− bnp (𝜇)⃒ = 0,
n→+∞ 𝜇∈NA
n
n≥deg(p)

we find that
lim

n→+∞
n≥deg(p)

min bnp − min p =

lim

[︀
]︀
minn bnp (𝜇) − min p

n→+∞ 𝜇∈NA
n≥deg(p)

[︁
(︁ 𝜇 )︁]︁
minn bnp (𝜇) − p
n→+∞ 𝜇∈NA
n
n≥deg(p)
⃒ (︁ 𝜇 )︁
⃒
⃒
⃒
≥ − lim maxn ⃒p
− bnp (𝜇)⃒ = 0,
n→+∞ 𝜇∈NA
n

≥

lim

n≥deg(p)

and therefore limn→+∞,n≥deg(p) min bnp ≥ min p. Furthermore, by Statement (79), we see that
limn→+∞,n≥deg(p) min bnp ≤ min p. Hence indeed limn→+∞,n≥deg(p) min bnp = min p. The proof
for the other equality is completely analogous.
42. To see how: clearly all polynomials are by definition linear combinations of Bernstein basis polynomials,
of possibly different degrees. For each of the terms, use BB2 to raise the degree to a common higher
degree n—multiply it by an appropriate version of 1. This shows that the Bernstein basis polynomials of
fixed degree n are generating for all polynomials of lower degrees. They are also independent by BB1.

56

Coherent Predictive Inference under Exchangeability

Using the above results, we can prove a number of useful relations between the Bernstein
positivity of a polynomial and its positivity on (the interior of) the simplex. They are related
to a property first proved by Hausdorff in the univariate case (Hausdorff, 1923, p. 124).
Proposition 28. Let p be any polynomial on ΣA . Consider the following statements:
(i) (∀𝜃 ∈ ΣA )p(𝜃) > 0;
(ii) p ∈ V + (A), meaning that there is some n ≥ deg(p) such that bnp > 0;
(iii) p ∈ V ++ (A), meaning that (∀𝜃 ∈ int(ΣA ))p(𝜃) > 0;
(iv) (∀𝜃 ∈ ΣA )p(𝜃) ≥ 0.
Then (i)⇒(ii)⇒(iii)⇒(iv).
Proof of Proposition 28. The first implication is a direct consequence of Proposition 27: we
infer from (i) and the continuity of p that min p > 0 and therefore, by Proposition 27, that
limn→+∞,n≥deg(p) min bnp = min p > 0, which implies (ii).
To prove that (ii)⇒(iii), assume that there is some n ≥ deg(p) such that bnp > 0, and
consider any 𝜃 ∈ int(ΣA ). Then since BA,𝑚 (𝜃) > 0 for all 𝑚 ∈ NAn [BB3], and since by
assumption bnp ≥ 0 and bnp (𝜇) > 0 for some 𝜇 ∈ NAn , we see that
p(𝜃) =

∑︁

bnp (𝑚)BA,𝑚 (𝜃) ≥ bnp (𝜇)BA,𝜇 (𝜃) > 0.

n
𝑚∈NA

The third implication is an immediate consequence of the continuity of p.
The following counterexample shows that not necessarily V + (A) = V ++ (A).
Running Example. We go back to the polynomial q on Σ{H ,T ,U } defined in Equation (41):
2
2
q(𝜃) = θH
− θH θT + θT
= (θH − θT )2 + θH θT for all 𝜃 ∈ Σ{H ,T ,U } .

We have already argued that this polynomial is not Bernstein positive. Nevertheless, it is
obviously positive on the interior of Σ{H ,T ,U } .
♦
It is also quite easy to trace the effect on the Bernstein expansion of multiplying with a
Bernstein basis polynomial:
Proposition 29. For all polynomials p on ΣA , all natural n ≥ deg(p), all 𝑚 ∈ NA ∪ {0}
and all 𝑛 ∈ NAn+mA :
⎧
ν(𝑛)
⎨bn (𝑛 − 𝑚)
if 𝑛 ≥ 𝑚
p
n+mA
ν(𝑛
−
𝑚)ν(𝑚)
bpBA,𝑚 (𝑛) =
⎩
0
otherwise.
Proof of Proposition 29. Observe that:
(︂ ∑︁
)︂
∑︁
n
pBA,𝑚 =
bp (𝜇)BA,𝜇 BA,𝑚 =
bnp (𝜇)BA,𝜇 BA,𝑚
n
𝜇∈NA

n
𝜇∈NA

57

De Cooman, De Bock, & Diniz

=

∑︁

bnp (𝜇)

n
𝜇∈NA

ν(𝜇 + 𝑚)
BA,𝜇+𝑚 ,
ν(𝜇)ν(𝑚)

and use the uniqueness of the (Bernstein) basis expansion.
This allows us to prove the following simple but interesting result about Bernstein positivity:
Proposition 30. Consider any 𝑚 ∈ NA ∪ {0} and any polynomial p on ΣA . Then:
pBA,𝑚 ∈ V + (A) ⇔ p ∈ V + (A).
Proof of Proposition 30. First, assume that pBA,𝑚 ∈ V + (A), so there is some natural n ≥
n
A
deg(p) such that bn+m
pBA,𝑚 > 0. Then it follows from Proposition 29 that also bp > 0, and
therefore p ∈ V + (A).
Assume, conversely, that p ∈ V + (A), so there is some n ≥ deg(p) such that bnp > 0. Then
+
A
it follows from Proposition 29 that also bn+m
pBA,𝑚 > 0, and therefore pBA,𝑚 ∈ V (A).

Appendix C. The Dirichlet Distribution
The density diA (·|𝛼) of the Dirichlet distribution with hyperparameter 𝛼 ∈ RA
>0 is given by:
diA (𝜃|𝛼) := ∏︀

∏︁
Γ(αA )
θxαx −1 for all 𝜃 ∈ int(ΣA ),
Γ(α
)
x
x∈A
x∈A

and for any polynomial p on ΣA we define the corresponding expectation as:43
∫︁
∏︁
Γ(αA )
p(𝜃) ∏︀
DiA (p|𝛼) :=
θxαx −1 d𝜃.
Γ(α
)
x
ΣA
x∈A
x∈A

In particular,
∫︁

(︂

)︂ ∏︁

∏︁
Γ(αA )
θxαx −1 d𝜃
Γ(αx )
ΣA
x∈A
x∈A
x∈A
(︂ )︂
(︂ )︂ ∏︁
∏︁
n
Γ(αA )
Γ(mx + αx )
1
n
=
αx (mx ) ,
=
𝑚 Γ(n + αA )
Γ(αx )
αA (n) 𝑚

DiA (BA,𝑚 |𝛼) =

n
𝑚

θxmx ∏︀

(80)

x∈A

x∈A

using the ascending factorial α(r) := Γ(α+r)
Γ(α) = α(α + 1) . . . (α + r − 1), with α ∈ R and
r ∈ N0 .
The Dirichlet distribution can be used as a prior in combination with a multinomial
likelihood, leading to the so-called Dirichlet multinomial distribution, which can be described
as follows. The probability of observing (a sample with n ≥ 0 observations with) count vector
𝑚 ∈ NA ∪ {0} in a multinomial process with Dirichlet prior density diA (·|𝛼) is given by:
∫︁
n
DiMnA ({𝑚}|𝛼) :=
CoMnnA ({𝑚}|𝜃) diA (𝜃|𝛼) d𝜃
ΣA

43. The integrals in this section can be interpreted as multiple Riemann integrals.

58

Coherent Predictive Inference under Exchangeability

∫︁
BA,𝑚 (𝜃) diA (𝜃|𝛼) d𝜃 = DiA (BA,𝑚 |𝛼),

=
ΣA

where the second equality follows from Equation (16). Therefore, more generally, if we take
the expansion of the polynomial p in Bernstein basis polynomials of degree n ≥ deg(p):
DiA (p|𝛼) =

∑︁

bnp (𝑚) DiA (BA,𝑚 |𝛼) =

n
𝑚∈NA

= DiMnnA

∑︁

bnp (𝑚) DiMnnA (I{𝑚} |𝛼)

n
𝑚∈NA

(︂ ∑︁
n
𝑚∈NA

⃒ )︂
⃒
n
bp (𝑚)I{𝑚} ⃒𝛼 = DiMnnA (bnp |𝛼),

which is the Dirichlet multinomial expectation of the count gamble bnp . This is the general
and useful relationship between the Dirichlet expectation of a polynomial p, and the Dirichlet
multinomial expectation of its Bernstein expansion bnp . Although these expectations are
strictly speaking only defined for 𝛼 ∈ RA
>0 , we can extend their definition continuously to
elements 𝛼 of RA
\
{0}
by
taking
appropriate
limits, as Equation (80) indicates.
≥
C.1 Special Properties of the Dirichlet Distribution
We now recall a few interesting properties of the Dirichlet distribution. We begin with the
updating property:
Proposition 31 (Updating). For any category set A, any polynomial p ∈ V (A), any count
vector 𝑚 ∈ NA ∪ {0} and any 𝛼 ∈ RA
>0 :
DiA (pBA,𝑚 |𝛼) = DiA (BA,𝑚 |𝛼) DiA (p|𝑚 + 𝛼).
Proof of Proposition 31.
∫︁
DiA (pBA,𝑚 |𝛼) =
p(𝜃)BA,𝑚 (𝜃) diA (𝜃|𝛼) d𝜃
ΣA
(︂
)︂
∫︁
∏︁
mA ∏︁ mx Γ(αA )
θxαx −1 d𝜃
=
p(𝜃)
θx ∏︀
Γ(α
)
𝑚
x
ΣA
x∈A
x∈A
x∈A
(︂
)︂
∫︁
∏︁
Γ(mx + αx )
mA
Γ(αA )
=
p(𝜃) diA (𝜃|𝑚 + 𝛼) d𝜃
𝑚 Γ(mA + αA )
Γ(αx )
ΣA
x∈A

= DiA (BA,𝑚 |𝛼) DiA (p|𝑚 + 𝛼),
where the last equality follows from Equation (80).
Next, we turn to the so-called renaming property:
Proposition 32 (Renaming). For any category sets A and C such that there is some bijective
(one-to-one and onto) map λ : A → C, any polynomial p ∈ V (C) and any 𝛼 ∈ RA
>0 :
DiA (p ◦ Rλ |𝛼) = DiC (p|Rλ (𝛼)).
59

De Cooman, De Bock, & Diniz

Proof of Proposition 32. Due to the linear nature of the Dirichlet expectation, it clearly
suffices to prove the property for the Bernstein basis polynomials p = BC,𝑚 , where 𝑚 ∈
NC ∪ {0}. Observe that Rλ is a bijection too. Then, using Equation (80), if we let 𝛽 := Rλ (𝛼)
and 𝑛 := Rλ−1 (𝑚), so βz = αλ−1 (z) and mz = nλ−1 (z) for all z ∈ C, and αA = βC and
nA = mC , we get:
(︂
)︂
∏︁ Γ(mz + βz )
mC
Γ(βC )
DiC (BC,𝑚 |Rλ (𝛼)) = DiC (BC,𝑚 |𝛽) =
𝑚 Γ(mC + βC )
Γ(βz )
z∈C
(︂ )︂
∏︁ Γ(nλ−1 (z) + αλ−1 (z) )
Γ(αA )
nA
=
𝑛 Γ(nA + αA )
Γ(αλ−1 (z) )
z∈C
(︂ )︂
∏︁ Γ(nx + αx )
Γ(αA )
nA
=
= DiA (BA,𝑛 |𝛼),
𝑛 Γ(nA + αA )
Γ(αx )
x∈A

and if we take into account that for all 𝜃 ∈ int(ΣA ):
(BC,𝑚 ◦ Rλ )(𝜃) = BC,𝑚 (Rλ (𝜃))
(︂
)︂
(︂
)︂
(︂
)︂
mC ∏︁ mz
mC ∏︁
mC ∏︁ nλ−1 (z)
mz
=
θλ−1 (z)
θλ−1 (z) =
Rλ (θ)z =
𝑚
𝑚
𝑚
z∈C
z∈C
z∈C
(︂ )︂ ∏︁
nA
θxnx = BA,𝑛 (𝜃),
=
𝑛
x∈A

we see that indeed DiC (BC,𝑚 |Rλ (𝛼)) = DiA (BC,𝑚 ◦ Rλ |𝛼).
The so-called pooling property generalises the renaming property:
Proposition 33 (Pooling). For any category sets A and D such that there is some onto
map ρ : A → D, any polynomial p ∈ V (D) and any 𝛼 ∈ RA
>0 :
DiA (p ◦ Rρ |𝛼) = DiD (p|Rρ (𝛼)).
Proof of Proposition 33. Due to the linear nature of the Dirichlet expectation, it again suffices
to prove the property for the Bernstein basis polynomials p = BD,𝑚 , where 𝑚 ∈ ND ∪ {0}.
Also, if we take into account the renaming property of Proposition 32, it is enough to consider
the following special case, where we have some non-empty set Do and different categories b,
c and d not belonging to it, let A := Do ∪ {b, c} and D := Do ∪ {d}, and define ρ by letting
ρ(x) := x if x ∈ Do and ρ(b) = ρ(c) := d.
Then on the one hand, taking into account Equation (80), letting 𝛽 := Rρ (𝛼) :
(︂
)︂
∏︁ Γ(mz + βz )
mD
Γ(βD )
DiD (BD,𝑚 |Rρ (𝛼)) = DiD (BD,𝑚 |𝛽) =
𝑚 Γ(mD + βD )
Γ(βz )
z∈D
(︂
)︂
mD
Γ(βD )
Γ(md + βd ) ∏︁ Γ(mz + βz )
=
.
(81)
𝑚 Γ(mD + βD ) Γ(βd )
Γ(βz )
z∈Do

On the other hand,

60

Coherent Predictive Inference under Exchangeability

DiA (BD,𝑚 ◦ Rρ |𝛼)
(︂ ∏︁
)︂
)︂
∫︁ (︂
mD
md
mz
(θb + θc )
θz
diA (𝜃|𝛼) d𝜃
=
𝑚
ΣA
z∈Do
)︂
(︂
∫︁
∏︁
Γ(αA )
mD
∏︀
=
(θb + θc )md θbαb −1 θcαc −1
θzmz +αz −1 d𝜃
𝑚
x∈A Γ(αx ) ΣA
z∈Do
(︂
)︂
)︂
(︂
∫︁
m
d
∑︁ md
∏︁
Γ(αA )
mD
∏︀
θbk+αb −1 θcmd −k+αc −1
θzmz +αz −1 d𝜃
=
k
Γ(α
)
𝑚
x
ΣA
x∈A
z∈Do
k=0
∏︀
)︂
(︂
)︂
(︂
m
d
∑︁
Γ(αA )
md Γ(k + αb )Γ(md − k + αc ) z∈Do Γ(mz + αz )
mD
∏︀
=
.
𝑚
k
Γ(mD + αA )
x∈A Γ(αx )
k=0

So, if we compare both results and recall that βD = αA , αz = βz for z ∈ Do and βd = αb + αc ,
we see that we must prove that:
)︂
md (︂
∑︁
1
md
Γ(md + αb + αc )
=
Γ(k + αb )Γ(md − k + αc )
Γ(αb + αc )
Γ(αb )Γ(αc )
k
k=0

or equivalently, using ascending factorials:
(αb + αc )(md ) =

)︂
md (︂
∑︁
md
αb (k) αc (md −k) .
k

(82)

k=0

So we see that proving the pooling property is essentially equivalent to proving Equation (82),
which is the ‘binomial theorem for ascending factorials’. This is a well-known result, and it
follows from the fact that ascending factorials are Sheffer sequences of binomial type (Sheffer,
1939). For completeness, we give a proof for it here, which is now very easy, because we have
just shown that it will hold if we can prove the pooling property in the particular case that
Do = {a}, where a is a category different from b, c and d. So A = {a, b, c} and D = {a, d},
and in this case we can rewrite Equation (81) as:
DiD (BD,𝑚 |Rρ (𝛼))
(︂
)︂
ma + md
Γ(αa + αb + αc )
Γ(md + αb + αc ) Γ(ma + αa )
=
ma
Γ(ma + md + αa + αb + αc ) Γ(αb + αc )
Γ(αa )
whereas
DiA (BD,𝑚 ◦ Rρ |𝛼) =
where we let
∫︁ 1 (︂ ∫︁
I :=
0
∫︁ 1

(1 −

0

(1 −

=

1−θa

θa )md θbαb −1 (1

θa )md θama +αa −1

(︂ ∫︁

(︂
)︂
ma + md Γ(αa + αb + αc )
I
ma
Γ(αa )Γ(αb )Γ(αc )

− θa −

1−θa

θb )αc −1 θama +αa −1 dθb

θbαb −1 (1

− θa − θb )

αc −1

)︂
dθa

)︂

dθb dθa
(︂ ∫︁ 1
)︂
∫︁ 1
md +αb +αc −1 ma +αa −1
αb −1
αc −1
=
(1 − θa )
θa
t
(1 − t)
dt dθa
0

0

0

0

61

De Cooman, De Bock, & Diniz

= B(ma + αa , md + αb + αc )B(αb , αc ) =

Γ(ma + αa )Γ(md + αb + αc ) Γ(αb )Γ(αc )
,
Γ(ma + md + αa + αb + αc ) Γ(αb + αc )

using the well-known evaluation of the Beta function in terms of Gamma functions.
Finally, we look at properties related to restriction.
Proposition 34 (Restriction). For any category sets A and B such that B ⊆ A, any
polynomial p ∈ V (B), any 𝛼 ∈ RA
>0 and any r ∈ N0 :
DiA (IrB,A (p)|𝛼) =

Γ(deg(p) + r + αB )
Γ(αA )
DiB (p|rB (𝛼)).
Γ(deg(p) + r + αA )
Γ(αB )

Proof of Proposition 34. Let n := deg(p) + r, then due to the linearity of the Dirichlet
expectation operator, and Equations (29) and (80):
∑︁
DiA (IrB,A (p)|𝛼) =
bnp (𝑛) DiA (BA,iA (𝑛) |𝛼)
n
𝑛∈NB

∏︀
∏︀
(︂ )︂
n
Γ(αA )
x∈B Γ(nx + αx )
x∈A\B Γ(αx )
∏︀
∏︀
=
𝑛 Γ(n + αA )
n
x∈A\B Γ(αx )
x∈B Γ(αx )
𝑛∈NB
(︂ )︂
∑︁
n
Γ(αA ) ∏︁ Γ(nx + αx )
=
bnp (𝑛)
𝑛 Γ(n + αA )
Γ(αx )
n
∑︁

bnp (𝑛)

𝑛∈NB

=

∑︁
n
𝑛∈NB

=

x∈B

bnp (𝑛)

Γ(αA ) Γ(n + αB )
DiB (BB,𝑛 |rB (𝛼))
Γ(n + αA ) Γ(αB )

Γ(αA ) Γ(n + αB )
DiB (p|rB (𝛼)),
Γ(n + αA ) Γ(αB )

concluding the proof.

Appendix D. The Original IDMM Inference System by Walley and
Bernard
The IDMM inference system ΦsIDM , as we introduced it in Section 12, differs from the one
originally proposed by Walley and Bernard (1999).44 In this appendix, we discuss the original
IDMM inference system, which we denote by ΦsOI , explain how it is related to ours, and
illustrate some of the advantages our version has over the one by Walley and Bernard.
D.1 Defining the Original IDMM Inference System
For any s ∈ R>0 , and any category set A, consider the following set of polynomials:
s
:= {p ∈ V (A) : (∀𝛼 ∈ KsA ) DiA (p|𝛼) > 0}
HOI,A

= {p ∈ V (A) : (∀𝑡 ∈ int(ΣA )) DiA (p|s𝑡) > 0} .
44. Strictly speaking, Walley and Bernard did not propose an inference system in our sense, but rather a
collection of prior and posterior predictive lower previsions for each category set A. The inference system
we call ‘the original IDMM inference system’ is one that produces these predictive lower previsions.

62

Coherent Predictive Inference under Exchangeability

For reasons that should become clear shortly, we call the inference system ΦsOI defined by
s
ΦsOI (A) := HOI,A
for all category sets A,

the original IDMM inference system with hyperparameter s > 0. Updating is done in much
ˇ ∈ NA ∪ {0}:
the same way as for the inference system ΦsIDM in Section 12. For any 𝑚
s
ˇ = {p ∈ V (A) : (∀𝑡 ∈ int(ΣA )) DiA (p|𝑚
ˇ + s𝑡) > 0} ,
HOI,A
c𝑚

and this should be compared with Equation (54). We leave it as an exercise to the reader to
check that ΦsOI is coherent and representation insensitive.45 However, as illustrated by the
counterexample in Section D.3, ΦsOI is not specific.
The predictive models of ΦsOI are easily derived by mimicking the approach used in
Section 12 to derive the predictive models of ΦsIDM ; see Equations (56) and (57). For any
ˇ ∈ NAň :
ň ∈ N0 , n̂ ∈ N and any 𝑚
{︁
}︁
s,n̂
ˇ = f ∈ L(An̂ ) : (∀𝑡 ∈ int(ΣA )) DiA (Mnn̂A (f )|𝑚
ˇ + s𝑡) > 0 ,
DOI,A
c𝑚

(83)

ˇ =
P s,n̂
OI,A (f |𝑚)

(84)

and
inf
𝑡∈int(ΣA )

ˇ + s𝑡) for all gambles f on An̂ .
DiA (Mnn̂A (f )|𝑚

The latter expression motivates why we refer to ΦsOI as the original IDMM inference system:
its predictive lower previsions coincide with those proposed by Walley and Bernard (1999).
Using Equation (83) for n̂ = 1, and mimicking the argument in the proof of Equation (59) in
Appendix E.7, we see that
s,1
ˇ =
DOI,A
c𝑚

{︂
f ∈ L(A) : f > −

}︂
1 ∑︁
s,1
ˇ for all 𝑚
ˇ ∈ NA ∪ {0}.
f (x)m̌x = DIDM,A
c𝑚
s
x∈A

This tells us that the IDMM and the original IDMM have the same immediate prediction
models. The corresponding immediate predictive lower previsions for the original IDMM are
well-known and are of course identical to the ones produced by our version of the IDMM
inference system, as given by Equation (60). However, as the examples in the next section
illustrate, this equality does not extend beyond immediate prediction: the IDMM and the
original IDMM are different coherent inference systems, which leads us to the general and
important conclusion that coherent inference systems are not completely determined by their
immediate prediction models.
Nevertheless, both approaches are closely related; by comparing Equations (84) and (57),
ˇ ∈ NAň
we see that for any ň ∈ N0 , n̂ ∈ N and any 𝑚
0

,n̂
ˇ = inf0 P sOI,A
ˇ for all gambles f on An̂ .
P s,n̂
(f |𝑚)
IDM,A (f |𝑚)
0<s <s

45. The proof is very similar to the one for ΦsIDM [see Theorem 21].

63

(85)

De Cooman, De Bock, & Diniz

D.2 The Original IDMM Inference System Is Not Monotone in s
The hyperparameter s of the original IDMM inference system is usually interpreted as
a degree of caution. Higher values of s are often claimed to produce inferences that are
more cautious and less informative. The following quote from Walley and Bernard (1999,
Section 2.4) makes this explicit:
“If B is any event concerning future observations, the IDMM(s) produces intervals
of posterior probabilities [P (B|𝑥), P (B|𝑥)] which are nested and become wider as
s increases. This means that the inferences produced by two IDMMs with different
values of s are always consistent with each other, and the effect of increasing s is
simply to make inferences more cautious and less informative.”
Similar statements can be found in related papers by Walley (1996, Section 2.5) and Bernard
(2005, Section 4.6). Although this is indeed true for many inferences, including many important
ones—for example, the immediate predictions—, it does not hold for “any event concerning
future observations”, as illustrated by the following example, where the lower probability of
an event concerning two future observations is shown to initially increase with s.
Example 1. Consider a situation where the possibility space A consists of two elements
only, say heads (H) and tails (T ), each of which has been observed once, so ň = 2 and
ˇ = (m̌H , m̌T ) = (1, 1). We are interested in the predictive lower probability that during the
𝑚
next two trials, heads and tails will each be observed once: so n̂ = 2 and we are looking for the
ˆ = {(H, T ), (T, H)}, with 𝑚
ˆ = (m̂H , m̂T ) = (1, 1).
predictive lower probability of the event [𝑚]
For the original IDMM inference system, the following formula provides a closed-form
expression:
ˇ =
P s,n̂
ˆ |𝑚)
OI,A (I[𝑚]

ˇ + s𝑡) = inf DiA (BA,𝑚
ˇ + s𝑡)
DiA (Mnn̂A (I[𝑚]
ˆ |𝑚
ˆ )|𝑚
𝑡∈int(ΣA )
(︂ )︂ ∏︁
1
n̂
(m̌x + stx )(m̂x )
= inf
(n̂)
ˆ
𝑚
𝑡∈int(ΣA ) (ň + s)
x∈A
inf

𝑡∈int(ΣA )

= inf

0<t<1

2(1 + st)(1 + s(1 − t))
2(1 + s)
=
.
(2 + s)(3 + s)
(2 + s)(3 + s)

ˇ initially increases with s; see also Figure 2.
We conclude that P s,n̂
ˆ |𝑚)
OI,A (I[𝑚]

(86)
♦

For our version of the IDMM inference system, the statement made in the aforementioned
quote does hold for “any event concerning future observations”. This follows trivially from
Equation (85). We illustrate this in our next example.
Example 2. Consider again the problem in Example 1. This time, we solve it using our version
of the IDMM. The result is also depicted in Figure 2, as a function of the hyperparameter s.
s,n̂
ˇ P IDM,A
ˇ is a non-increasing function of s. Indeed,
In contrast with P s,n̂
(I[𝑚]
ˆ |𝑚),
ˆ |𝑚)
OI,A (I[𝑚]
⎧
0 ,n̂
1
⎪
ˇ =
(I[𝑚]
if 0 < s < 1
P sOI,A
⎪
ˆ |𝑚)
⎨slim
0 →0
3
s,n̂
ˇ =
P IDM,A (I[𝑚]
ˆ |𝑚)
⎪
2(1 + s)
⎪
⎩P s,n̂
ˇ =
if s ≥ 1
ˆ |𝑚)
OI,A (I[𝑚]
(2 + s)(3 + s)
is the closed-form expression we find by combining Equations (85) and (86).
64

♦

Coherent Predictive Inference under Exchangeability

0.36

ˇ
P s,n̂
ˆ |𝑚)
OI,A (I[𝑚]

0.34
0.32

ˇ
P s,n̂
ˆ |𝑚)
IDM,A (I[𝑚]

0.3
0.28
s
0

0.5

1

1.5

2

Figure 2: Lower probability of observing two different outcomes during the next two experiments, given that the possibility space consists of two categories, each of which
has already been observed once: solutions according to ΦsOI (solid line) and ΦsIDM
(dashed and solid line); see Examples 1 and 2 for more information.

Clearly, the inferences for ΦsOI and ΦsIDM can differ: it suffices to compare the results in
Examples 1 and 2; see Figure 2 as well. Therefore, it seems clear that Walley’s (1996, p. 51)
statement that “[. . . ] s can be allowed to vary between 0 and s, and this produces exactly
the same inferences as the IDM with s = s.” or equivalently, that ΦsOI and ΦsIDM produce the
same inferences, should be taken to apply to immediate prediction only.
D.3 The Original IDMM Inference System Is Not Specific
As announced in Theorem 21, our version of the IDMM inference system is specific. We now
show that, at least for some values of the hyperparameter s, this is not true for the original
version.
ˇ ∈ NBň . Then for all A ⊇ B and all f ∈ L(B n̂ ):
Consider any ň ∈ N0 , n̂ ∈ N and any 𝑚
s,n̂
ˇ ⇔ (∀𝑡 ∈ int(ΣA )) DiA (Mnn̂A (f IB n̂ )|iA (𝑚)
ˇ + s𝑡) > 0
f IB n̂ ∈ DOI,A
ciA (𝑚)

ˇ + srB (𝑡)) > 0,
⇔ (∀𝑡 ∈ int(ΣA )) DiB (Mnn̂B (f )|𝑚
where the last equivalence is a consequence of Propositions 41 and 34 and the fact that
ˇ = 𝑚.
ˇ If in particular B ⊂ A, it is not hard to see that ∆sB = {srB (𝑡) : 𝑡 ∈ int(ΣA )},
rB (iA (𝑚))
which implies that:
s,n̂
s,n̂
ˇ ⇔ (∀𝛼 ∈ ∆sB ) DiB (Mnn̂B (f )|𝑚
ˇ + 𝛼) > 0 ⇔ f ∈ DIDM,B
ˇ
f IB n̂ ∈ DOI,A
ciA (𝑚)
c𝑚,

and therefore also:
ˇ
ˇ B n̂ ) = inf s DiB (Mnn̂B (f )|𝑚
ˇ + 𝛼) = P s,n̂
P s,n̂
OI,A (f |iA (𝑚),
IDM,B (f |𝑚).
𝛼∈∆B

65

De Cooman, De Bock, & Diniz

On the other hand, due to Equation (SP1), if ΦsOI were specific, we would have that:
ˇ B n̂ ) = P s,n̂
ˇ
ˇ
= P s,n̂
P s,n̂
OI,A (f |iA (𝑚),
OI,B (f |rB (iA (𝑚)))
OI,B (f |𝑚).
ˇ and P s,n̂
ˇ to
Hence, in order for ΦsOI to be specific, it is necessary for P s,n̂
OI,B (·|𝑚)
IDM,B (·|𝑚)
coincide. As illustrated by the examples in the previous section, this is not necessarily the
case. Therefore, ΦsOI is not always specific. In the counterexample we have provided, the
difference occurs for s < 1 only, whereas in practice, s is usually chosen to be either 1 or
2 (Walley & Bernard, 1999, Section 2.4). It would be interesting to see whether similar
counterexamples can be constructed for s ≥ 1.
That the original IDMM inference systems are not specific, apparently contradicts Theorem 11 by De Cooman et al. (2009a), which seems to state that they are. But in fact, what
that theorem states is that the original IDMM immediate prediction models satisfy a weaker
specificity condition, tailored to immediate prediction only. Since the immediate prediction
models for the original IDMM and the IDMM coincide, there is no contradiction.

Appendix E. Proofs and Additional Results That Are More Technical
E.1 Proofs of Results in Section 4
Proof of Theorem 4. For the sake of notational simplicity, we use the intuitive notation f (Xk )
for extn̂k (f ). We give the proof for the most general definition, in terms of sets of desirable
gambles. The proof for lower previsions then follows immediately.
Consider any category set A, any n̂ ∈ N, any 1 ≤ k ≤ n̂ and any gamble f on A such
n̂ —we may assume without loss of generality that A is not a singleton. This
that f (Xk ) ∈ DA
already implies that f 6≤ 0, by coherence [D4]. Hence in particular f 6= 0 and max f > 0.
Assume ex absurdo that f 6> 0, then there must be some a ∈ A for which f (a) < 0. Define
the gamble g on A by letting g(a) := f (a) and g(x) := max f > 0 for all x ∈ A \ {a}. Then
g ≥ f and therefore g(Xk ) ≥ f (Xk ), which implies, by coherence [use D2 and D3], that also
n̂ . If we now let λ := max f − f (a) > 0 and δ := −f (a)/λ > 0, and define the
g(Xk ) ∈ DA
n̂ , because λ > 0.
gamble h := g/λ = −δ + IA\{a} , then also, by coherence [D3], h(Xk ) ∈ DA
Now consider any natural number N ≥ 2, then it follows from repeatedly applying pooling
n̂
and renaming invariance in an appropriate manner that −δ + I{a1 } (Zk ) ∈ D{a
, where
1 ,...,aN }
Zk is any variable that assumes the value a1 when Xk 6= a and that assumes some value in
{a2 , . . . , aN } when Xk = a. By repeatedly applying category permutation invariance, we find
n̂
that −δ + I{a` } (Zk ) ∈ D{a
for all ` ∈ {1, . . . , N }. Coherence [D3] then tells us that
1 ,...,aN }
∑︀N
n̂
−N δ + 1 = `=1 [−δ + I{a` } (Zk )] ∈ D{a
. This leads to a contradiction with coherence
1 ,...,aN }
[D4] if we choose N large enough.
E.2 Proofs of Results in Section 7
Proposition 35. For all n ∈ N and 𝑥 ∈ An : 𝑇 (ρ𝑥) = Rρ (𝑇 (𝑥)).
Proof of Proposition 35. Consider any z ∈ D, then
Tz (ρ𝑥) = |{k ∈ {1, . . . , n} : ρ(xk ) = z}| =

∑︁
y∈A : ρ(y)=z

66

|{k ∈ {1, . . . , n} : xk = y}|

Coherent Predictive Inference under Exchangeability

∑︁

=

Ty (𝑥) = Rρ (𝑇 (𝑥))z ,

y∈A : ρ(y)=z

concluding the proof.
Lemma 36. For all n ∈ N, all 𝑚 ∈ NAn and all 𝑦 ∈ Dn :
∑︁
1
1
I{ρ𝑥} (𝑦) =
I
(𝑦).
ν(𝑚)
ν(Rρ (𝑚)) [Rρ (𝑚)]
𝑥∈[𝑚]

∑︀
Proof of Lemma 36. Consider the map M𝑚 : Dn → R defined by M𝑚 := 𝑥∈[𝑚] I{ρ𝑥} . Then
for any permutation π of the index set {1, . . . , n} and any 𝑦 ∈ Dn , we see that
∑︁
∑︁
M𝑚 (π𝑦) =
I{ρ𝑥} (π𝑦) =
I{ρ(π−1 𝑥)} (𝑦)
𝑥∈[𝑚]

𝑥∈[𝑚]

∑︁

=

∑︁

I{ρ𝑥} (𝑦) =

π𝑥∈[𝑚]

I{ρ𝑥} (𝑦) = M𝑚 (𝑦),

𝑥∈[𝑚]

which tells us that M𝑚 is permutation invariant and therefore∑︀constant on the atoms
[𝑛], 𝑛 ∈ NDn . This means that, with obvious notations, M𝑚 = 𝑛∈N n M𝑚 (𝑛)I[𝑛] . Now
D
M𝑚 (𝑦) > 0 implies that there is some 𝑥 ∈ [𝑚] such that 𝑦 = ρ𝑥, and therefore, by
Proposition 35, 𝑇 (𝑦) = 𝑇 (ρ𝑥) = Rρ (𝑇 (𝑥)) = Rρ (𝑚) and therefore 𝑦 ∈ [Rρ (𝑚)]. This tells
us that M𝑚 (𝑛) = 0 unless 𝑛 = Rρ (𝑚) and therefore M𝑚 = M𝑚 (Rρ (𝑚))I[Rρ (𝑚)] . Now if
we plug f := 1 into Equation (87), we see that
∑︁
∑︁
ν(𝑚) =
M𝑚 (𝑦) =
M𝑚 (Rρ (𝑚))I[Rρ (𝑚)] (𝑦) = M𝑚 (Rρ (𝑚))ν(Rρ (𝑚)).
𝑦∈Dn

𝑦∈Dn

Lemma 37. For all n ∈ N and all 𝑛 ∈ NDn :
∑︁

BD,𝑛 ◦ Rρ =

BA,𝑚

n : R (𝑚)=𝑛
𝑚∈NA
ρ

Proof of Lemma 37. For any 𝜃 in ΣA , we have that
(︂ )︂ ∏︁ (︂ ∑︁
)︂nz
n
(BD,𝑛 ◦ Rρ )(𝜃) =
θx
𝑛
z∈D x∈ρ−1 ({z})
(︂ )︂ ∏︁
(︂ )︂
∑︁
n
nz
=
z
𝑛
𝑚
nz
z
z∈D 𝑚 ∈N

(︂ )︂
n
=
𝑛
=

ρ−1 ({z})

(︂ ∏︁

∑︁
n : R (𝑚)=𝑛
𝑚∈NA
ρ

∑︁
n:
𝑚∈NA

Rρ (𝑚)=𝑛

(︂

n
𝑚

67

x∈A

z

θxmx

x∈ρ−1 ({z})

θxmx

)︂ ∏︁ (︂

x∈A

)︂ ∏︁

concluding the proof.

∏︁

θxmx =

z∈D

)︂

nz

𝑚|ρ−1 ({z})
∑︁

n:
𝑚∈NA

Rρ (𝑚)=𝑛

BA,𝑚 (𝜃),

De Cooman, De Bock, & Diniz

This lemma allows us to prove two related propositions.
Proposition 38. For all n ∈ N and all gambles f on Dn : MnnA (f ◦ ρ) = MnnD (f ) ◦ Rρ .
Proof of Proposition 38. First of all, we have for any count vector 𝑚 in NAn that
HynA (f ◦ ρ|𝑚) =

∑︁
∑︁ ∑︁
1
1
f (ρ𝑥) =
I{ρ𝑥} (𝑦)f (𝑦)
ν(𝑚)
ν(𝑚)
n
𝑥∈[𝑚] 𝑦∈D

𝑥∈[𝑚]

∑︁

=

f (𝑦)

𝑦∈Dn

I{ρ𝑥} (𝑦)

(87)

𝑥∈[𝑚]

1
I
(𝑦)
f (𝑦)
ν(Rρ (𝑚)) [Rρ (𝑚)]
n

∑︁

=

𝑦∈D

=

1
ν(𝑚)

∑︁

1
ν(Rρ (𝑚))

∑︁

f (𝑦) = HynD (f |Rρ (𝑚)),

𝑦∈[Rρ (𝑚)]

where the fourth equality follows from Lemma 36. Therefore indeed:
∑︁
∑︁
MnnA (f ◦ ρ) =
HynA (f ◦ ρ|𝑚)BA,𝑚 =
HynD (f |Rρ (𝑚))BA,𝑚
n
𝑚∈NA

=

∑︁

n
𝑚∈NA

HynD (f |𝑛)

n
𝑛∈ND

=

∑︁

∑︁

BA,𝑚

n : R (𝑚)=𝑛
𝑚∈NA
ρ

HynD (f |𝑛)(BD,𝑛 ◦ Rρ ) = MnnD (f ) ◦ Rρ ,

n
𝑛∈ND

where the fourth equality now follows from Lemma 37.
Proposition 39. For all polynomials p on ΣD and all n ∈ N0 such that n ≥ deg(p):
bnp◦Rρ = bnp ◦ Rρ .
Proof of Proposition 39. We find after expanding p in the appropriate Bernstein basis:
(︂ ∑︁
)︂
∑︁
n
p ◦ Rρ =
bp (𝑛)BD,𝑛 ◦ Rρ =
bnp (𝑛)(BD,𝑛 ◦ Rρ )
n
𝑛∈ND

=

∑︁

bnp (𝑛)

n
𝑛∈ND

=

∑︁

n
𝑛∈ND

∑︁

BA,𝑚 =

∑︁

∑︁

bnp (Rρ (𝑚))BA,𝑚

n
n : R (𝑚)=𝑛
𝑛∈ND
𝑚∈NA
ρ

n : R (𝑚)=𝑛
𝑚∈NA
ρ

(bnp ◦ Rρ )(𝑚)BA,𝑚 ,

n
𝑚∈NA

where the third equality follows from Lemma 37. The desired result now follows from the
uniqueness of an expansion in a (Bernstein) basis.
Proof of Theorem 7. Fix any category sets A and D such that there is an onto map ρ : A → D,
ˇ ∈ Aň and any gamble f on Dn̂ . We use the notation HA := Φ(A) and
any ň, n̂ ∈ N, any 𝑥
68

Coherent Predictive Inference under Exchangeability

HD := Φ(D), and we transform Condition (RI2) using the equivalence in Condition (18). On
ˇ := 𝑇 (𝑥):
ˇ
the one hand, letting 𝑚
n̂
f ◦ ρ ∈ DA
⇔ Mnn̂A (f ◦ ρ) ∈ HA ⇔ Mnn̂D (f ) ◦ Rρ ∈ HA
n̂
n̂
n̂
ˇ ⇔ BA,𝑚
f ◦ ρ ∈ DA
c𝑥
ˇ MnA (f ◦ ρ) ∈ HA ⇔ BA,𝑚
ˇ (MnD (f ) ◦ Rρ ) ∈ HA ,

where the second equivalences follow from Proposition 38. On the other hand, recalling that
ˇ = Rρ (𝑇 (𝑥))
ˇ = Rρ (𝑚)
ˇ by Proposition 35:
𝑇 (ρ𝑥)
n̂
f ∈ DD
⇔ Mnn̂D (f ) ∈ HD
n̂
n̂
ˇ ⇔ BD,Rρ (𝑚)
f ∈ DD
cρ𝑥
ˇ MnD (f ) ∈ HD .

This tells us that the equivalences in Condition (RI2) can be rewritten as:
Mnn̂D (f ) ◦ Rρ ∈ HA ⇔ Mnn̂D (f ) ∈ HD
n̂
n̂
BA,𝑚
ˇ (MnD (f ) ◦ Rρ ) ∈ HA ⇔ BD,Rρ (𝑚)
ˇ MnD (f ) ∈ HD .

The proof is complete if we observe (and recall from the discussion in Section 5.3 and
Appendix B) that by varying n̂ ∈ N and f ∈ L(Dn̂ ), we can let p := Mnn̂D (f ) range over all
ˇ ∈ Aň , we can let 𝑚
ˇ := 𝑇 (𝑥)
ˇ range
polynomials on ΣD , and that by varying ň ∈ N and 𝑥
over all count vectors in NA .
Proof of Theorem 8. Let, for ease of notation Φ := inf i∈I Φi , then Φ is coherent using Equation (25). Consider any category sets A and D such that there is an onto map ρ : A → D,
any p ∈ V (D) and any 𝑚 ∈ NA ∪ {0}. Then, using the representation insensitivity of the
coherent Φi and Theorem 7:
(p ◦ Rρ )BA,𝑚 ∈ Φ(A) ⇔ (∀i ∈ I)(p ◦ Rρ )BA,𝑚 ∈ Φi (A)
⇔ (∀i ∈ I)pBD,Rρ (𝑚) ∈ Φi (D) ⇔ pBD,Rρ (𝑚) ∈ Φ(D),
and this concludes the proof.
Proposition 40. For all 𝑥 ∈ An , 𝑇 (𝑥↓B ) = rB (𝑇 (𝑥)).
Proof of Proposition 40. Immediate, since 𝑥↓B is a sample whose components all belong to
B, and for each category in B, the number of times it occurs in 𝑥↓B is exactly the same as
the number of times it occurs in 𝑥.
Proof of Proposition 9. Consider any 𝜗 ∈ ΣB , and let, for simplicity of notation 𝜃 = iA (𝜗).
Then since for any 𝑛 ∈ NBn , with n := deg(p) + r
(︂
)︂ ∏︁
(︂ )︂ ∏︁
n
n
iA (𝑛)x
BA,iA (𝑛) (𝜃) =
θx
=
ϑnx x = BB,𝑛 (𝜗),
iA (𝑛)
𝑛
x∈A

x∈B

we see that indeed:
IrB,A (p|𝜃) =

∑︁

bnp (𝑛)BA,iA (𝑛) (𝜃) =

n
𝑛∈NB

∑︁
n
𝑛∈NB

69

bnp (𝑛)BB,𝑛 (𝜗) = p(𝜗).

De Cooman, De Bock, & Diniz

Proof of Proposition 10. When deg(p) + r = 0, then r = 0 and p = c ∈ R, and trivially
IrB,A (p|𝜃) = I0B,A (c)(𝜃) = c. So let us assume that deg(p) + r > 0. First of all, observe that
deg(p)+r

for all 𝑛 ∈ NB

and all 𝜃 ∈ ΣA :
(︂
)︂
(︂
)︂
deg(p) + r ∏︁ iA (𝑛)x
deg(p) + r ∏︁ nx
BA,iA (𝑛) (𝜃) =
θx
=
θx
iA (𝑛)
𝑛
x∈A
x∈B
{︃
deg(p)+r
θB
BB,𝑛 (𝜃|+
if θB > 0
B)
=
0
otherwise.

(88)

It therefore already follows from Condition (29) that IrB,A (p|𝜃) = 0 if θB = 0. Let us therefore
assume that θB > 0. Then Condition (29) and Equation (88) tell us that:
∑︁
IrB,A (p|𝜃) =
bdeg(p)+r
(𝑛)BA,iA (𝑛) (𝜃)
p
deg(p)+r

𝑛∈NB

deg(p)+r

∑︁

=

bdeg(p)+r
(𝑛)θB
p

BB,𝑛 (𝜃|+
B)

deg(p)+r

𝑛∈NB

deg(p)+r

deg(p)+r

∑︁

= θB

bdeg(p)+r
(𝑛)BB,𝑛 (𝜃|+
p
B ) = θB

p(𝜃|+
B ),

deg(p)+r

𝑛∈NB

which concludes the proof.
Proposition 41. For all n ∈ N and all gambles f on B n :
MnnA (f IB n ) = IrB,A (MnnB (f )), where r := n − deg(MnnB (f )).
Proof of Proposition 41. First of all, we have for any count vector 𝑚 in NAn that—with some
slight abuse of notation:
HynA (f IB n |𝑚) =

∑︁
1
1
(f IB n )(𝑥) =
ν(𝑚)
ν(𝑚)
𝑥∈[𝑚]

∑︁

f (𝑥)

𝑥∈[𝑚]∩B n

is zero unless 𝑚 = iA (𝑛) for some 𝑛 ∈ NBn . In that case, since then obviously ν(𝑚) = ν(𝑛),
and 𝑥 ∈ [iA (𝑛)] ∩ B n ⇔ 𝑥 ∈ [𝑛]—again with some slight abuse of notation:
HynA (f IB n |iA (𝑛)) =

1 ∑︁
f (𝑥) = HynB (f |𝑛).
ν(𝑛)
𝑥∈[𝑛]

Therefore, if we recall Condition (29):
∑︁
∑︁
HynB (f |𝑛)BA,iA (𝑛)
MnnA (f IB n ) =
HynA (f IB n |iA (𝑛))BA,iA (𝑛) =
n
𝑛∈NB

n
𝑛∈NB

= IrB,A (MnnB (f )),
where r := n − deg(MnnB (f )).
70

Coherent Predictive Inference under Exchangeability

Proof of Theorem 11. Fix any category sets A and B such that B ⊆ A, any ň, n̂ ∈ N, any
ˇ ∈ Aň and any gamble f on B n̂ . We use the notation HA := Φ(A) and HB := Φ(B), and
𝑥
we transform Condition (SP2) using the equivalence in Condition (18). On the one hand,
ˇ := 𝑇 (𝑥)
ˇ and r := n̂ − deg(Mnn̂B (f )):
letting 𝑚
n̂
f IB n̂ ∈ DA
⇔ Mnn̂A (f IB n̂ ) ∈ HA ⇔ IrB,A (Mnn̂B (f )) ∈ HA
n̂
n̂
r
n̂
ˇ ⇔ BA,𝑚
f IB n̂ ∈ DA
c𝑥
ˇ MnA (f IB n̂ ) ∈ HA ⇔ BA,𝑚
ˇ IB,A (MnB (f )) ∈ HA ,

where the second equivalences follow from Proposition 41. On the other hand, recalling that
ˇ B ) = rB (𝑇 (𝑥))
ˇ = rB (𝑚)
ˇ by Proposition 40:
𝑇 (𝑥↓
n̂
f ∈ DB
⇔ Mnn̂B (f ) ∈ HB
n̂
n̂
ˇ B ⇔ BB,rB (𝑚)
f ∈ DB
c𝑥↓
ˇ MnB (f ) ∈ HB .

This tells us that the equivalences in Condition (SP2) can be rewritten as:
IrB,A (Mnn̂B (f )) ∈ HA ⇔ Mnn̂B (f ) ∈ HB
r
n̂
n̂
BA,𝑚
ˇ IB,A (MnB (f )) ∈ HA ⇔ BB,rB (𝑚)
ˇ MnB (f ) ∈ HB .

The proof is complete if we recall from the discussion in Section 5.3 and Appendix B that
by varying n̂ ∈ N and f ∈ L(B n̂ ), we can let p := Mnn̂B (f ) = CoMnn̂B (Hyn̂B (f )) range over
all polynomials on ΣB and r = n̂ − deg(Mnn̂B (f )) range over all elements of N0 , and that by
ˇ ∈ Aň , we can let 𝑚
ˇ := 𝑇 (𝑥)
ˇ range over all count vectors in NA .
varying ň ∈ N and 𝑥
Proof of Theorem 12. Let, for ease of notation Φ := inf i∈I Φi , then Φ is coherent using
Equation (25). Consider any category sets A and B such that B ⊆ A, any p ∈ V (B), any
𝑚 ∈ NA ∪ {0} and any r ∈ N0 . Then, using the specificity of the Φi :
IrB,A (p)BA,𝑚 ∈ Φ(A) ⇔ (∀i ∈ I)IrB,A (p)BA,𝑚 ∈ Φi (A)
⇔ (∀i ∈ I)pBB,rB (𝑚) ∈ Φi (B) ⇔ pBB,rB (𝑚) ∈ Φ(B),
which concludes the proof.
E.3 Proofs of Results in Section 8
Proof of Proposition 13. For sufficiency, fix a category set A, a gamble g on A, and a count
vector 𝑚 ∈ NA ∪ {0}. Condition (RI4) with D := g(A), ρ := g, f := idD yields Condition (RI5).
For necessity, fix category sets A and D such that there is an onto map ρ : A → D, a
gamble f on D, and a count vector 𝑚 ∈ NA ∪ {0}. Observe that (f ◦ ρ)(A) = f (D) and that
for all r ∈ f (D)
∑︁
∑︁
∑︁
Rf ◦ρ (𝑚)r =
mx =
mx
x∈A : (f ◦ρ)(x)=r

z∈D : f (z)=r x∈A : ρ(x)=z

∑︁

=

z∈D : f (z)=r

71

Rρ (𝑚)z = Rf (Rρ (𝑚))r ,

De Cooman, De Bock, & Diniz

so Rf ◦ρ = Rf ◦ Rρ . We now infer by invoking Condition (RI5) twice that:
1
1
f ◦ ρ ∈ DA
c𝑚 ⇔ id(f ◦ρ)(A) ∈ D(f
◦ρ)(A) cRf ◦ρ (𝑚)
1
⇔ idf (D) ∈ Df1 (D) cRf (Rρ (𝑚)) ⇔ f ∈ DD
cRρ (𝑚),

concluding the proof.
Proof of Theorem 14. The arguments in this proof rely heavily on the following expression
for the lower probability function:
{︁
}︁
1
ϕ(n, k) = sup α ∈ R : I{a} − α ∈ D{a,b}
c(k, n − k)
}︁
{︁
= sup α ∈ R : θak θbn−k [θa − α] ∈ Φ({a, b})
(89)
and other related expressions that are equivalent to it by representation insensitivity and
Bernstein coherence [B3]. Both expressions follow from Equations (32) and (33), Bernstein
coherence [B3] and representation insensitivity in its form (RI4).
L1. Immediate from Bernstein coherence and the fact that ϕ(n, k) is a lower probability:
use Equation (89), B2 and B4.
L2. Fix any non-negative integers n, k and ` such that k + ` ≤ n. Consider any real
α < ϕ(n, k) and β < ϕ(n, `), then it follows from applying Equation (89) and Condition (RI4)
that both θxk θy` θzn−k−` [θx − α] ∈ Φ({x, y, z}) and θxk θy` θzn−k−` [θy − β] ∈ Φ({x, y, z}), whence,
by Bernstein coherence [B3], θxk θy` θzn−k−` [(θx + θy ) − (α + β)] ∈ Φ({x, y, z}). Applying
Equation (89) and Condition (RI4) again tells us that θuk+` θzn−k−` [θu − (α + β)] ∈ Φ({u, z}),
whence α + β ≤ ϕ(n, k + `).
L3, L4 and L5 are immediate consequences of L1 and L2.
L6. Consider the category set A := {a, b} and the count vector 𝑚 with ma := k and
mb := n − k. Define the gamble g on A by g(a) := ϕ(n + 1, k + 1) and g(b) := ϕ(n + 1, k).
Then g(a) ≥ g(b) by L5, and therefore the coherence [P5 and P3] of the predictive lower
prevision P 1A (·|𝑚) tells us that P 1A (g|𝑚) = g(b) + [g(a) − g(b)]P 1A ({a}|𝑚) = ϕ(n + 1, k) +
ϕ(n, k)[ϕ(n + 1, k + 1) − ϕ(n + 1, k)] [see also Equation (33)]. So it clearly suffices to prove
that P 1A (g|𝑚) ≤ ϕ(n, k) = P 1A ({a}|𝑚). Consider any α < P 1A (g|𝑚), then it follows using
Equation (31) that:
θak θbn−k [g(a)θa + g(b)θb − α] ∈ Φ(A).
(90)
Also, for any  > 0, both θak+1 θbn−k [θa − g(a) + ] ∈ Φ(A) and θak θbn+1−k [θa − g(b) + ] ∈ Φ(A),
and therefore, by coherence [B3], and recalling that θa + θb = 1,
Φ(A) 3 θak+1 θbn−k [θa − g(a) + ] + θak θbn+1−k [θa − g(b) + ]
= θak θbn−k [θa − g(a)θa − g(b)θb + ]. (91)
Combining Statements (90) and (91) using coherence [B3], this leads to θak θbn−k [θa − α + ] ∈
Φ(A), whence ϕ(n, k) ≥ α − , and this completes the proof.
L7. Use L1 and L5 to find that ϕ(n, k)[ϕ(n + 1, k + 1) − ϕ(n + 1, k)] ≥ 0, and then use L6.
L8. That sn ≥ 0 follows from L4, so we only need to prove that sn+1 ≥ sn , or equivalently,
that ϕ(n, 1) ≥ ϕ(n + 1, 1)[1 + ϕ(n, 1)]. Indeed:
ϕ(n, 1) ≥ ϕ(n + 1, 1) + ϕ(n, 1)[ϕ(n + 1, 2) − ϕ(n + 1, 1)]
72

Coherent Predictive Inference under Exchangeability

≥ ϕ(n + 1, 1) + ϕ(n, 1)[2ϕ(n + 1, 1) − ϕ(n + 1, 1)]
= ϕ(n + 1, 1) + ϕ(n, 1)ϕ(n + 1, 1),
where the first inequality follows from L6 with k = 1, and the second from L4 and L1.
L9. The inequalities hold trivially for n = 0, due to L1. So consider any n ∈ N, and
category sets A := {x, y} and B := {x1 , x2 , . . . , xn , y}. Let 0 <  < α and β := α −  > 0.
Since ϕ(1, 1) > β, we see that θx [θx − β] ∈ Φ(A), or equivalently, θx [θx (1 − β) − βθy ] ∈ Φ(A),
since θx + θy = 1. Representation insensitivity [use Equation (89) and Condition (RI4)] then
tells us that ϑxk [ϑxk (1 − ∏︀
β) − βϑy ] ∈ Φ({xk , y}), and specificity [use Theorem 11] allows us
to infer from this that ( nk=1 ϑxk∏︀
)[ϑxk (1 − β)
∑︀n− βϑy ] ∈ Φ(B), for all k ∈ {1, . . . , n}. Now
n
infer from coherence [B3] that ( k=1 ϑxk )[ k=1 ϑxk (1 − β) − nβϑy ] ∈ Φ(B), and apply
representation insensitivity to get to θxn [θx (1 − β) − nβθy ] ∈ Φ(A). Since θy = 1 − θx , this
nβ
is equivalent to θxn [θx (1 − β + nβ) − nβ] ∈ Φ(A). This shows that φ(n, n) ≥ 1−β+nβ
, using
Equation (89). The rest of the proof is now immediate.
E.4 Proofs of Results in Section 9
Proof of Theorem 15. That ΦV is coherent is obvious, because for each category set A ∈ F,
ΦV (A) = V + (A) is a Bernstein coherent set of polynomials on ΣA .
To prove representation insensitivity, we use Theorem 7. Consider any category sets A
and D such that there is an onto map ρ : A → D, any p ∈ V (D) and any 𝑚 ∈ NA ∪ {0}.
Then indeed
(p ◦ Rρ )BA,𝑚 ∈ V + (A) ⇔ p ◦ Rρ ∈ V + (A) ⇔ p ∈ V + (D) ⇔ pBD,Rρ (𝑚) ∈ V + (D),
where the first and last equivalences follow from Proposition 30, and the second one from
Lemma 48 with K = A.
E.5 Proofs of Results in Section 10
Proof of Theorem 16. That ΦV is coherent is obvious, because for each category set A ∈ F,
ΦV (A) = V ++ (A) is obviously a convex cone that includes V + (A) [Proposition 28] and does
not contain the zero polynomial: V ++ (A) is therefore a Bernstein coherent set of polynomials
on ΣA .
To prove representation insensitivity, we use Theorem 7. Consider any category sets A
and D such that there is an onto map ρ : A → D, any p ∈ V (D) and any 𝑚 ∈ NA ∪ {0}.
Then indeed
(p ◦ Rρ )BA,𝑚 ∈ V ++ (A) ⇔ (∀𝜃 ∈ int(ΣA ))p(Rρ (𝜃))BA,𝑚 (𝜃) > 0
⇔ (∀𝜃 ∈ int(ΣA ))p(Rρ (𝜃)) > 0
⇔ (∀𝜗 ∈ int(ΣD ))p(𝜗) > 0
⇔ (∀𝜗 ∈ int(ΣD ))p(𝜗)BD,Rρ (𝑚) (𝜗) > 0 ⇔ pBD,Rρ (𝑚) ∈ V ++ (D),
where the second and fourth equivalences follow from the Bernstein positivity of the Bernstein
basis polynomials and Proposition 28, and the third one from Lemma 48 with K = A.
73

De Cooman, De Bock, & Diniz

To prove specificity, we use Theorem 11. Consider any category sets A and B such that
B ⊆ A, any p ∈ V (B), any 𝑚 ∈ NA ∪ {0} and any r ∈ N0 . Then indeed:
IrB,A (p)BA,𝑚 ∈ V ++ (A) ⇔ (∀𝜃 ∈ int(ΣA ))IrB,A (p|𝜃)BA,𝑚 (𝜃) > 0
⇔ (∀𝜃 ∈ int(ΣA ))IrB,A (p|𝜃) > 0
⇔ (∀𝜗 ∈ int(ΣB ))p(𝜗) > 0
⇔ (∀𝜗 ∈ int(ΣB ))p(𝜗)BB,rB (𝑚) (𝜗) > 0 ⇔ pBB,rB (𝑚) ∈ V ++ (B),
where the second and fourth equivalences follow from the Bernstein positivity of the Bernstein
basis polynomials and Proposition 28, and the third one from Lemma 52 with K = A.
E.6 Proofs of Results in Section 11
Below, we use the convenient device of identifying, for any proper subset B of A, an element
𝜗 of ΣB with the unique corresponding element 𝜃 = iA (𝜗) of ΣA whose components outside
B are zero:
(∀x ∈ B)θx = ϑx and (∀x ∈ A \ B)θx = 0.
Also observe that, using this convention, we can identify int(ΣA[𝑚] ) with a subset of ΣA , and
then characterise it as follows:
for any 𝜃 ∈ ΣA : 𝜃 ∈ int(ΣA[𝑚] ) ⇔ (∀x ∈ A)(θx > 0 ⇔ mx > 0).
Proof of Proposition 17. It clearly suffices to prove that V + (A) ⊆ HSC,A and 0 ∈
/ HSC,A .
The first statement is easy to prove because ASC,A trivially includes all non-constant
Bernstein basis polynomials, by Proposition 28. Since V + (A) consists of finite, strictly positive
linear combinations of these non-constant Bernstein basis polynomials, we immediately have
that V + (A) ⊆ HSC,A .
To prove the second statement, suppose ex absurdo that 0 ∈ HSC,A . This implies that
++
there are finitely many nk > 0, count vectors 𝑚k in NAnk and pk ∈ V[𝑚
(A) such that
k]
∑︀
0 = k pk BA,𝑚k . It is always possible to find (at least) one such count vector, 𝑚1 say,
for which A[𝑚k ] 6⊂ A[𝑚1 ] for all k. In other words, we have either A[𝑚k ] = A[𝑚1 ] or
A[𝑚k ] \ A[𝑚1 ] 6= ∅. Now consider any 𝜃 ∈ int(ΣA[𝑚1 ] ). If A[𝑚k ] \ A[𝑚1 ] 6= ∅, then
++
BA,𝑚k (𝜃) = 0. If A[𝑚k ] = A[𝑚1 ], then BA,𝑚k (𝜃) > 0, and moreover, since pk ∈ V[𝑚
(A),
k]
∑︀
pk (𝜃) > 0. Hence 0 = k pk (𝜃)BA,𝑚k (𝜃) > 0, a contradiction.
Lemma 42. Consider any 𝑚 ∈ NA ∪ {0} and p ∈ HSC,A,𝑚 , so there are ` ∈ N, nk ∈ N0
∑︀
++
such that mA + nk > 0, 𝑚k ∈ NAnk and pk ∈ V[𝑚+𝑚
(A) such that p = `k=1 pk BA,𝑚k .
k]
Then
SA,𝑚 (p) = {K ⊆ A : A[𝑚 + 𝑚k ] ⊆ K for some k ∈ {1, . . . , `}}
and therefore
min SA,𝑚 (p) = min {A[𝑚 + 𝑚k ] : k ∈ {1, . . . , `}} .
Proof of Lemma 42. The second statement is trivial, given the first. So we restrict our
attention to proving the first statement.
Assume first that A[𝑚 + 𝑚r ] ⊆ K ⊆ A for some r ∈ {1, . . . , `}. Then clearly K 6= ∅,
since mA + nr > 0. We may assume without loss of generality that A[𝑚 + 𝑚r ] is a minimal
74

Coherent Predictive Inference under Exchangeability

element of the set {A[𝑚 + 𝑚k ] : k ∈ {1, . . . , `}}. Consider any 𝜃 ∈ int(ΣA[𝑚+𝑚r ] ), whence
also 𝜃 ∈ ΣK . Now for all k ∈ {1, . . . , `} such that A[𝑚 + 𝑚k ] = A[𝑚 + 𝑚r ]—and there
++
clearly is at least one such k—we see that both pk (𝜃) > 0 since pk ∈ V[𝑚+𝑚
(A), and
k]
BA,𝑚k (𝜃) > 0, whence (pk BA,𝑚k )(𝜃) > 0. For all other k we must have that A[𝑚 + 𝑚k ] \
A[𝑚 + 𝑚r ] 6= ∅, and therefore (pk BA,𝑚k )(𝜃) = 0 since BA,𝑚k (𝜃) = 0. This guarantees that
∑︀
p(𝜃) = `k=1 (pk BA,𝑚k )(𝜃) > 0, whence indeed K ∈ SA,𝑚 (p), since we already know that
𝜃 ∈ ΣK , A[𝑚] ⊆ A[𝑚 + 𝑚r ] ⊆ K and K 6= ∅.
Assume, conversely, that K ∈ SA,𝑚 (p), which implies that ∅ 6= K ⊆ A and A[𝑚] ⊆ K,
and that there is some 𝜗 ∈ ΣK such that p(𝜗) 6= 0. Observe that A[𝑚 + 𝑚k ] = A[𝑚]∪A[𝑚k ],
and assume ex absurdo that A[𝑚 + 𝑚k ] * K and therefore A[𝑚k ] * K for all k ∈ {1, . . . , `}.
Fix any k ∈ {1, . . . , `}, then there is some x ∈ A[𝑚
/ K, and therefore ϑx = 0,
∑︀ k ] such that x ∈
whence BA,𝑚k (𝜗) = 0. This shows that p(𝜗) = `k=1 (pk BA,𝑚k )(𝜗) = 0, a contradiction.
Lemma 43. Consider any 𝑚 ∈ NA ∪{0}, any p ∈ V (A) and any n ∈ N such that n ≥ deg(p).
Then for all 𝜇 ∈ NAn :
bnp (𝜇) 6= 0 ⇒ (∃K ∈ min SA,𝑚 (p))K \ A[𝑚] ⊆ A[𝜇].
Proof of Lemma 43. Fix any 𝜇 in NAn . We prove the contraposition, so suppose that for
all K in min SA,𝑚 (p), we have that K \ A[𝑚] * A[𝜇] and therefore K * A[𝑚 + 𝜇], since
A[𝑚 + 𝜇] = A[𝑚] ∪ A[𝜇]. Hence, A[𝑚 + 𝜇] ∈
/ SA,𝑚 (p). Since moreover ∅ 6= A[𝑚 + 𝜇] and
A[𝑚] ⊆ A[𝑚 + 𝜇], we infer from Equation (46) that p|ΣB = 0, where we let, for ease of
notation, B := A[𝑚 + 𝜇]. We can rewrite this as [see also Lemma 47]:
0 = p|ΣB =

∑︁
n
𝜂∈NA

bnp (𝜂)BA,𝜂 |ΣB =

∑︁
n
𝜂∈NB

bnp (𝜂)BA,𝜂 |ΣB =

∑︁

bnp (𝜂)BB,𝜂 .

n
𝜂∈NB

Due to the uniqueness of the Bernstein expansion, this is only possible if bnp (𝜂) = 0 for all
n
n
𝜂 ∈ NA[𝑚+𝜇]
. This concludes the proof since, clearly, 𝜇 ∈ NA[𝑚+𝜇]
.
∑︀
Proof of Proposition 18. First, assume that p ∈ HSC,A,𝑚 , implying that p = `k=1 pk BA,𝑚k
++
for some ` ∈ N, nk ∈ N0 such that mA + nk > 0, 𝑚k ∈ NAnk and pk ∈ V[𝑚+𝑚
(A). It already
k]
follows from Lemma 42 that p =
6 0 and that min SA,𝑚 (p) = min {A[𝑚 + 𝑚k ] : k ∈ {1, . . . , `}}.
Consider now any K ∈ min {A[𝑚 + 𝑚k ] : k ∈ {1, . . . , `}} and any 𝜃 ∈ int(ΣK ). Then for all
k, we have that either A[𝑚 + 𝑚k ] = K or A[𝑚 + 𝑚k ] \ K 6= ∅. If A[𝑚 + 𝑚k ] = K—which
happens for at least one k, due to our choice of K—then pk (𝜃) > 0 and BA,𝑚k (𝜃) > 0. If
A[𝑚 + 𝑚k ] \ K 6= ∅, then since A[𝑚] ⊆ K, A[𝑚k ] \ K =
6 ∅, implying that BA,𝑚k (𝜃) = 0.
Hence, p(𝜃) > 0. Since this holds for all 𝜃 ∈ int(ΣK ), we find that p|ΣK ∈ V ++ (K).
Assume, conversely, that p ∈ V (A)\{0} and ∑︀
that p|ΣK ∈ V ++ (K) for
∑︀ all K n∈ min SA,𝑚 (p).
n
Fix any n ∈ N such that n ≥ deg(p), then p = 𝜇∈N n bp (𝜇)BA,𝜇 = 𝜇∈M bp (𝜇)BA,𝜇 , with
A
{︀
}︀
M := 𝜇 ∈ NAn : bnp (𝜇) 6= 0 . Since p 6= 0, we infer from Equation (46) that min SA,𝑚 (p) 6= ∅
[observe that A ∈ SA,𝑚 (p)]. We know from Lemma 43 that for any 𝜇 ∈ M , there is at least
one K ∈ min SA,𝑚 (p) such that K \ A[𝑚] ⊆ A[𝜇]. Let us just pick any of these K, and call
it K𝜇 . Now let, for any K ∈ min SA,𝑚 (p), MK := {𝜇 ∈ M : K𝜇 = K}, then we have found
a way to divide M into disjoint subsets MK , one for every K ∈ min SA,𝑚 (p) and some of
75

De Cooman, De Bock, & Diniz

⋃︀
which may be empty, such that K \ A[𝑚] ⊆ A[𝜇] for all 𝜇 ∈ MK , M = K∈min SA,𝑚 (p) MK
∑︀
∑︀
and therefore p = K∈min SA,𝑚 (p) 𝜇∈MK bnp (𝜇)BA,𝜇 .
Now fix any K ∈ min SA,𝑚 (p), then we construct a count vector 𝑚K by letting (mK )x := 1
if x ∈ K \ A[𝑚] and (mK )x := 0 otherwise. Notice that 𝑚K ∈ NAnK , with nK the number of
elements |K \ A[𝑚]| in the set K \ A[𝑚], and therefore nK ≤ n. Consider any 𝜇 ∈ MK , then
since (mK )x = 1 implies that x ∈ A[𝜇] and therefore µx ≥ 1, we see that for all 𝜃 ∈ ΣA :
BA,𝜇 (𝜃) = ν(𝜇)

∏︁

θxµx = ν(𝜇)

x∈A[𝜇]

∏︁

θxµx −(mK )x

x∈A[𝜇]

∏︁

θx(mK )x

x∈A[𝜇]

= λ(K, 𝜇)BA,𝜇−𝑚K (𝜃)BA,𝑚K (𝜃),
∑︀
n
−1 ν(𝑚 )−1 . Hence, we can rewrite
where λ(K, 𝜇) := ν(𝜇)ν(𝜇 −
𝑚
)
K
K
𝜇∈MK bp (𝜇)BA,𝜇
∑︀
:= 𝜇∈MK λ(K, 𝜇)bnp (𝜇)BA,𝜇−𝑚K . In this way, we find that p =
as
∑︀ pK BA,𝑚K , where pK
K∈min SA,𝑚 (p) BA,𝑚K pK .
Hence, if we fix any K ∈ min SA,𝑚 (p) 6= ∅, then we are left to prove that mA + nK > 0
++
and pK ∈ V[𝑚+𝑚
(A). Assume first, ex absurdo, that mA + nK = 0. Then in particular
K]
++
K = ∅, which contradicts K ∈ SA,𝑚 (p). So it remains to prove that pK ∈ V[𝑚+𝑚
(A).
K]
Consider any 𝜃 ∈ int(ΣA[𝑚+𝑚K ] ). Then we can derive from K ∈ min SA,𝑚 (p) ⊆ SA,𝑚 (p)
that A[𝑚] ⊆ K. Since A[𝑚K ] = K \A[𝑚], this implies that A[𝑚 + 𝑚K ] = A[𝑚]∪A[𝑚K ] =
A[𝑚] ∪ (K \ A[𝑚]) = K, and therefore also 𝜃 ∈ int(ΣK ). For all K 0 ∈ min SA,𝑚 (p) \ {K},
K0 \ K =
6 ∅ and therefore BA,𝑚K 0 (𝜃) = 0. Hence, p(𝜃) = BA,𝑚K (𝜃)pK (𝜃). We know that
p(𝜃) > 0 because p|ΣK ∈ V ++ (K) and that BA,𝑚K (𝜃) > 0 because A[𝑚K ] = K \ A[𝑚] ⊆ K.
We conclude that indeed pK (𝜃) > 0.
Lemma 44. For all 𝑚 ∈ NA ∪ {0} and p ∈ V (A):
SA,𝑚 (p) = SA,0 (pBA,𝑚 ) and therefore min SA,𝑚 (p) = min SA,0 (pBA,𝑚 ).
Proof of Lemma 44. First, assume that K ∈ SA,𝑚 (p). Then ∅ 6= K ⊆ A, A[𝑚] ⊆ K and
p|ΣK 6= 0. From this last inequality and the continuity of polynomials, we infer that there is
some 𝜃 ∈ int(ΣK ) such that p(𝜃) 6= 0. Since A[𝑚] ⊆ K, we find that p(𝜃)BA,𝑚 (𝜃) 6= 0 and
therefore (pBA,𝑚 )|ΣK 6= 0.
Assume, conversely, that K ∈ SA,0 (pBA,𝑚 ). Then ∅ =
6 K ⊆ A and (pBA,𝑚 )|ΣK 6= 0. This
last inequality implies that there is some 𝜃 ∈ ΣK such that (pBA,𝑚 )(𝜃) 6= 0 and therefore
both BA,𝑚 (𝜃) 6= 0 and p(𝜃) 6= 0. From BA,𝑚 (𝜃) 6= 0, we derive that A[𝑚] ⊆ K and from
p(𝜃) 6= 0, we derive that p|ΣK 6= 0.
Proof of Proposition 19. By the way HSC,A and HSC,A,𝑚 are constructed [see the defining
expressions (43) and (44)], it clearly suffices to prove that HSC,A c𝑚 ⊆ HSC,A,𝑚 . Consider
therefore any p ∈ V (A) such that pBA,𝑚 ∈ HSC,A , which by Proposition 18, implies that
pBA,𝑚 6= 0 and that (pBA,𝑚 )|ΣK ∈ V ++ (K) for all K ∈ min SA,0 (pBA,𝑚 ). We now set out
to prove that p ∈ HSC,A,𝑚 . Applying Proposition 18 again, and since, clearly, p 6= 0, we
see that it suffices to show that p|ΣK ∈ V ++ (K) for all K ∈ min SA,𝑚 (p). So consider any
K ∈ min SA,𝑚 (p). Then, by Lemma 44, K ∈ min SA,0 (pBA,𝑚 ), so we have already argued
above that (pBA,𝑚 )|ΣK ∈ V ++ (K). Hence indeed also p|ΣK ∈ V ++ (K).
76

Coherent Predictive Inference under Exchangeability

ˇ ∈
Proof of Equation (48). Combining Equations (47) and (30), we see that, for any 𝑚
NA ∪ {0}:
1
ˇ = {f ∈ L(A) : SA (f ) ∈ HSC,A,𝑚
DSC,A
c𝑚
(92)
ˇ }.
Also, for any f ∈ L(A) and any ∅ =
6 K ⊆ A:
SA (f ) = 0 ⇔ f = 0, SA (f )|ΣK ∈ V ++ (K) ⇔ f |K > 0 and SA (f )|ΣK = 0 ⇔ f |K = 0. (93)
ˇ = 0. For any f ∈ L(A):
We start with the case 𝑚
min SA,0 (SA (f )) = {{x} : x ∈ A and f (x) 6= 0} ,
1
because of Statement (93). Hence, by Proposition 18 and Equations (92) and (93): DSC,A
=
L>0 (A).
ˇ ∈ NA . For all f ∈ L(A):
Next, we consider any 𝑚

{︃
ˇ
{A[𝑚]}
if f |A[𝑚]
6 0
ˇ =
min SA,𝑚
ˇ (SA (f )) =
ˇ ∪ {x} : x ∈ A \ A[𝑚]
ˇ and f (x) 6= 0} if f |A[𝑚]
{A[𝑚]
ˇ =0

(94)

because of Equation (93). Now recall Proposition 18 and Equations (92) and (93) and
1
ˇ if and
consider two cases: f |A[𝑚]
ˇ 6= 0 and f |A[𝑚]
ˇ = 0. If f |A[𝑚]
ˇ 6= 0, then f ∈ DSC,A c𝑚
only {︀if f 6= 0 [which is redundant]
and f |A[𝑚]
ˇ > 0 or, equivalently [since f |A[𝑚]
ˇ 6= 0], if
}︀
1
ˇ if and only if
f ∈ h ∈ L(A) : h|A[𝑚]
ˇ > 0 ∪ L>0 (A). If f |A[𝑚]
ˇ = 0, then f ∈ DSC,A c𝑚
ˇ or, equivalently [since f |A[𝑚]
f 6={︀0 and f (x) ≥ 0 for }︀
all x ∈ A \ A[𝑚]
ˇ = 0], again if
f ∈ h ∈ L(A) : h|A[𝑚]
ˇ > 0 ∪ L>0 (A).
Proof of Equation (49). We start with the first part of Equation (49). Due to Equation (17)
and Proposition 19, it suffices to prove that, for any p ∈ V (A), minx∈A p(𝜃x◦ ) > 0 ⇒ p ∈
HSC,A,0 and minx∈A p(𝜃x◦ ) < 0 ⇒ p ∈
/ HSC,A,0 .
◦
First, assume that minx∈A p(𝜃x ) < 0. Then there is some y ∈ A for which p(𝜃y◦ ) < 0.
Hence, since p|Σ{y} = p(𝜃y◦ ) < 0, we find that {y} ∈ min SA,0 (p) and therefore also that
p∈
/ HSC,A,0 , by Proposition 18.
Next, assume that minx∈A p(𝜃x◦ ) > 0. Then p|Σ{x} = p(𝜃x◦ ) > 0 for all x ∈ A, implying
that min SA,0 (p) = {{x} : x ∈ A} and therefore also, since p 6= 0, that p ∈ HSC,A,0 , by
Proposition 18.
We now turn to the second part of Equation (49). Due to Equation (17) and Proposition 19,
ˇ ∈ NA and any p ∈ V (A), min𝜃∈ΣA[𝑚]
it suffices to prove that, for any 𝑚
p(𝜃) > 0 ⇒ p ∈
ˇ
HSC,A,𝑚
p(𝜃) < 0 ⇒ p ∈
/ HSC,A,𝑚
ˇ and min𝜃∈ΣA[𝑚]
ˇ.
ˇ
First, assume that min𝜃∈ΣA[𝑚]
p(𝜃)
<
0.
Then
there is some 𝜃 ∈ int(ΣA[𝑚]
ˇ ) for which
ˇ
++
ˇ
ˇ ∈
p(𝜃) < 0, implying that p|ΣA[𝑚]
6= 0 and p|ΣA[𝑚]
∈
/ V (A[𝑚]).
Hence, we find that A[𝑚]
ˇ
ˇ
min SA,𝑚
/ HSC,A,𝑚
ˇ (p) and therefore also that p ∈
ˇ , by Proposition 18.
ˇ
Next, assume that min𝜃∈ΣA[𝑚]
p(𝜃)
>
0.
Then
p|ΣA[𝑚]
=
6 0 and p|ΣA[𝑚]
∈ V ++ (A[𝑚]).
ˇ
ˇ
ˇ
ˇ and therefore also, since p 6= 0, that p ∈ HSC,A,𝑚
Hence, we find that min SA,𝑚
ˇ (p) = {A[𝑚]}
ˇ,
by Proposition 18.
77

De Cooman, De Bock, & Diniz

Proof of Equation (52). The first part of Equation (52) is a trivial consequence of Equaˇ ∈ NA and any f ∈ L(A). Then, combining
tion (51). For the second part, consider any 𝑚
Equations (50) and (30):
∑︁
∑︁
ˇ = min
f (x)θx = min f (x).
P 1SC,A (f |𝑚)
f (x)θx = min
𝜃∈ΣA[𝑚]
ˇ

x∈A

𝜃∈ΣA[𝑚]
ˇ

ˇ
x∈A[𝑚]

ˇ
x∈A[𝑚]

Lemma 45. Consider any category sets A and D such that there is an onto map ρ : A → D,
any p ∈ V (D) and any ∅ =
6 K ⊆ A. Then (p ◦ Rρ )|ΣK 6= 0 ⇔ p|Σρ(K) 6= 0.
Proof of Lemma 45. First, assume that p|Σρ(K) 6= 0, so there is some 𝜗 ∈ Σρ(K) such that
p(𝜗) 6= 0. Now choose any 𝜃 ∈ ΣK such that Rρ (𝜃) = 𝜗. Then, clearly, (p ◦ Rρ )(𝜃) =
p(Rρ (𝜃)) = p(𝜗) 6= 0 and therefore (p ◦ Rρ )|ΣK 6= 0.
Assume, conversely, that (p◦Rρ )|ΣK 6= 0, so there is some 𝜃 ∈ ΣK such that (p◦Rρ )(𝜃) 6= 0.
If we let 𝜗 := Rρ (𝜃), then 𝜗 ∈ Σρ(K) and p(𝜗) = p(Rρ (𝜃)) = (p ◦ Rρ )(𝜃) 6= 0. Hence,
p|Σρ(K) 6= 0.
Lemma 46. Consider any category sets A and D such that there is an onto map ρ : A → D,
any p ∈ V (D), and any 𝑚 ∈ NA ∪ {0}. Then
{︀
}︀
SA,𝑚 (p ◦ Rρ ) = K ⊆ A : A[𝑚] ⊆ K and ρ(K) ∈ SD,Rρ (𝑚) (p) ,
and therefore
ρ(SA,𝑚 (p ◦ Rρ )) = SD,Rρ (𝑚) (p) and ρ(min SA,𝑚 (p ◦ Rρ )) = min SD,Rρ (𝑚) (p).
Proof of Lemma 46. We start by proving the first statement. First, assume that K ∈ SA,𝑚 (p◦
Rρ ), implying that ∅ =
6 K ⊆ A, A[𝑚] ⊆ K and (p ◦ Rρ )|ΣK 6= 0. Then ∅ 6= ρ(K) ⊆ D,
D[Rρ (𝑚)] = ρ(A[𝑚]) ⊆ ρ(K) and, by Lemma 45, p|Σρ(K) 6= 0. Hence, ρ(K) ∈ SD,Rρ (𝑚) (p).
Conversely, assume that K ⊆ A, A[𝑚] ⊆ K and ρ(K) ∈ SD,Rρ (𝑚) (p). Then ∅ =
6 ρ(K), which
implies that ∅ =
6 K, and also p|Σρ(K) 6= 0, which, by Lemma 45, implies that (p ◦ Rρ )|ΣK 6= 0.
Hence, K ∈ SA,𝑚 (p ◦ Rρ ).
The first statement implies that ρ(SA,𝑚 (p ◦ Rρ )) ⊆ SD,Rρ (𝑚) (p) and therefore, in order
to prove the second statement, it suffices to show that SD,Rρ (𝑚) (p) ⊆ ρ(SA,𝑚 (p ◦ Rρ )) or,
equivalently, that for every L ∈ SD,Rρ (𝑚) (p), there is some K ∈ SA,𝑚 (p ◦ Rρ ) such that
ρ(K) = L. So choose any L ∈ SD,Rρ (𝑚) (p) and let K := {x ∈ A : ρ(x) ∈ L} = ρ−1 (L). Then
ρ(K) = L because ρ is onto, and since ρ(A[𝑚]) = D[Rρ (𝑚)] ⊆ L, it follows that A[𝑚] ⊆ K.
Hence, by the first statement, K ∈ SA,𝑚 (p ◦ Rρ ).
To prove the third statement, first assume that K ∈ min SA,𝑚 (p ◦ Rρ ), implying that
K ∈ SA,𝑚 (p ◦ Rρ ) and that, for all K 0 ∈ SA,𝑚 (p ◦ Rρ ), K 0 6⊂ K. By the second statement,
ρ(K) ∈ SD,Rρ (𝑚) (p). To prove that ρ(K) ∈ min SD,Rρ (𝑚) (p), assume ex absurdo that there
is some L ∈ SD,Rρ (𝑚) (p) such that L ⊂ ρ(K). Let K 0 := {x ∈ K : ρ(x) ∈ L} = K ∩ ρ−1 (L).
Then K 0 ⊂ K and ρ(K 0 ) = L, and therefore, by Lemma 45, (p ◦ Rρ )|ΣK 0 6= 0, because
K 0 6= ∅ and p|ΣL =
6 0. Since L ∈ SD,Rρ (𝑚) (p), we see that ρ(A[𝑚]) = D[Rρ (𝑚)] ⊆ L and
therefore A[𝑚] ⊆ ρ−1 (L). Since K ∈ SA,𝑚 (p ◦ Rρ ), we also know that A[𝑚] ⊆ K, and
therefore A[𝑚] ⊆ K ∩ ρ−1 (L) = K 0 . This tells us that K 0 ∈ SA,𝑚 (p ◦ Rρ ), a contradiction.
Assume, conversely, that L ∈ min SD,Rρ (𝑚) (p), implying that L ∈ SD,Rρ (𝑚) (p). Then, by
78

Coherent Predictive Inference under Exchangeability

the second statement, there is some K 0 ∈ SA,𝑚 (p ◦ Rρ ) such that ρ(K 0 ) = L. Hence, there
is some K ∈ min SA,𝑚 (p ◦ Rρ ) such that K ⊆ K 0 and therefore ρ(K) ⊆ ρ(K 0 ) = L. Since
L ∈ min SD,Rρ (𝑚) (p) and since, due to the second statement, ρ(K) ∈ SD,Rρ (𝑚) (p), we also
have that ρ(K) 6⊂ L and therefore ρ(K) = L.
Lemma 47. Let ∅ =
6 K ⊆ A and let p be any polynomial on ΣA . Then for any n ≥ deg(p):
bnp|Σ = bnp |NKn .
K

Proof of Lemma 47. It follows from
∑︁
p(θ) =
bnp (𝑚)BA,𝑚 (θ) for all θ ∈ ΣA
n
𝑚∈NA

that for all ϑ ∈ ΣK :
p|ΣK (ϑ) =

∑︁
n
𝑚∈NA

=

∑︁

∑︁

bnp (𝑚)BA,𝑚 (iA (ϑ)) =

bnp (𝑚)BA,𝑚 (iA (ϑ))

n : A[𝑚]⊆K
𝑚∈NA

bnp |NKn (𝑛)BK,𝑛 (ϑ),

n
𝑛∈NK

and this completes the proof.
Lemma 48. Consider any category sets A and D such that there is an onto map ρ : A → D,
any p ∈ V (D) and any ∅ =
6 K ⊆ A. Then:
(i) (p ◦ Rρ )|ΣK ∈ V + (K) ⇔ p|Σρ(K) ∈ V + (ρ(K));
(ii) (p ◦ Rρ )|ΣK ∈ V ++ (K) ⇔ p|Σρ(K) ∈ V ++ (ρ(K)).
Proof of Lemma 48. The first statement follows from the fact that, for all n ≥ deg(p):
bn(p◦Rρ )|Σ

K

n
> 0 ⇔ bn(p◦Rρ ) |NKn > 0 ⇔ (bnp ◦ Rρ )|NKn > 0 ⇔ bnp |Nρ(K)
> 0 ⇔ bnp|Σ

> 0,
ρ(K)

where the first and last equivalence are due to Lemma 47, the second equivalence follows
n) = Nn
from Proposition 39, and the third equivalence holds because Rρ (NK
ρ(K) .
We now turn to the second statement, where we have to prove that the following statements
are equivalent:
(a) (∀𝜃 ∈ int(ΣK ))p(Rρ (𝜃)) > 0;
(b) (∀𝜗 ∈ int(Σρ(K) ))p(𝜗) > 0.
First assume that (a) holds, and consider any 𝜗 ∈ int(Σρ(K) ). We have to prove that p(𝜗) > 0.
−1
We construct a 𝜃 ∈ ΣK as follows.
∑︀ Consider any z ∈ ρ(K). For all x ∈ ρ ({z}) ∩ K, choose
the θx > 0 in such a way that x∈K : ρ(x)=z θx = ϑz . In this way, we have found a 𝜃 ∈ ΣK
satisfying Rρ (𝜃) = 𝜗, and such that moreover θx > 0 for all x ∈ K, whence 𝜃 ∈ int(ΣK ). We
now infer from (a) that indeed p(𝜗) = p(Rρ (𝜃)) > 0.
Assume, conversely, that (b) holds, and consider any 𝜃 ∈ int(ΣK ). Then, for any z ∈ D,
Rρ (𝜃)z > 0 if z ∈ ρ(K) and Rρ (𝜃)z = 0 otherwise. This means that Rρ (𝜃) ∈ int(Σρ(K) ) and
we infer from (b) that indeed p(Rρ (𝜃)) > 0.
79

De Cooman, De Bock, & Diniz

Proposition 49. ΦSC is representation insensitive.
Proof of Proposition 49. We use the characterisation of representation insensitivity in Theorem 7. Consider any category sets A and D such that there is an onto map ρ : A → D,
any p ∈ V (D) and any 𝑚 ∈ NA ∪ {0}. Then, by Proposition 19, we need to prove that
p ◦ Rρ ∈ HSC,A,𝑚 ⇔ p ∈ HSC,D,Rρ (𝑚) .
First, assume that p ∈ HSC,D,Rρ (𝑚) , which, by Proposition 18, implies that p 6= 0 and
that p|ΣL ∈ V ++ (L) for all L ∈ min SD,Rρ (𝑚) (p). Applying Lemma 45 with K = A, we infer
from p =
6 0 that p ◦ Rρ 6= 0. Consider now any K ∈ min SA,𝑚 (p ◦ Rρ ). Then, by Lemma 46,
ρ(K) ∈ min SD,Rρ (𝑚) (p), implying that, due to the assumption, p|Σρ(K) ∈ V ++ (ρ(K)). Since
K 6= ∅, we can apply Lemma 48 to find that (p ◦ Rρ )|ΣK ∈ V ++ (K). Hence, by Proposition 18,
p ◦ Rρ ∈ HSC,A,𝑚 .
Assume, conversely, that p◦Rρ ∈ HSC,A,𝑚 , which, by Proposition 18, implies that p◦Rρ 6= 0
and that (p ◦ Rρ )|ΣK ∈ V ++ (K) for all K ∈ min SA,𝑚 (p ◦ Rρ ). Applying Lemma 45, with
K = A, we infer from p ◦ Rρ 6= 0 that p 6= 0. Now, consider any L ∈ min SD,Rρ (𝑚) (p), then
by Lemma 46, there is some K ∈ min SA,𝑚 (p ◦ Rρ ) such that ρ(K) = L. Since K =
6 ∅ and,
by assumption, (p ◦ Rρ )|ΣK ∈ V ++ (K), we infer from Lemma 48 that p|ΣL ∈ V ++ (L). Hence,
by Proposition 18, p ∈ HSC,D,Rρ (𝑚) .
Lemma 50. Consider any category sets A and B such that B ⊆ A, any p ∈ V (B), any
K ⊆ A such that K ∩ B 6= ∅ and any r ∈ N0 . Then IrB,A (p)|ΣK 6= 0 ⇔ p|ΣK∩B 6= 0.
Proof of Lemma 50. We may assume without loss of generality that r + deg(p) > 0, as the
proof is trivial otherwise.
First, assume that p|ΣK∩B =
6 0, which means that there is some 𝜗 ∈ ΣK∩B such that
p(𝜗) 6= 0. Then 𝜃 := iA (𝜗) ∈ ΣK , and we infer from Proposition 9 that IrB,A (p|𝜃) = p(𝜗) 6= 0
and therefore IrB,A (p)|ΣK 6= 0.
Assume, conversely, that IrB,A (p)|ΣK 6= 0, which means, due to the continuity of polynomials, that there is some 𝜃 ∈ int(ΣK ) such that IrB,A (p|𝜃) 6= 0. We now infer from K ∩ B 6= ∅
+
that θB > 0, so Proposition 10 guarantees that p(𝜃|+
B ) 6= 0. Since 𝜃|B ∈ ΣK∩B , we find that
p|ΣK∩B 6= 0.
Lemma 51. Consider any category sets A and B such that B ⊆ A, any p ∈ V (B) any
r ∈ N0 such that r + deg(p) > 0, and any 𝑚 ∈ NA ∪ {0}. Then
{︀
}︀
SA,𝑚 (IrB,A (p)) = K ⊆ A : A[𝑚] ⊆ K and K ∩ B ∈ SB,rB (𝑚) (p) ,
and therefore
{︀
}︀
SB,rB (𝑚) (p) = K ∩ B : K ∈ SA,𝑚 (IrB,A (p))
and
{︀
}︀
min SB,rB (𝑚) (p) = K ∩ B : K ∈ min SA,𝑚 (IrB,A (p)) .
Proof of Lemma 51. We begin with the first statement. First, assume that K ∈ SA,𝑚 (IrB,A (p))
and therefore that ∅ 6= K ⊆ A, A[𝑚] ⊆ K and IrB,A (p)|ΣK =
6 0. Then K ⊆ A implies that
K∩B ⊆ B, A[𝑚] ⊆ K implies that B[rB (𝑚)] = A[𝑚]∩B ⊆ K∩B. Moreover, IrB,A (p)|ΣK =
6 0
together with Proposition 10 and r + deg(p) > 0 implies that K ∩ B 6= ∅, which in turn, by
Lemma 50, implies that p|ΣK∩B 6= 0. Hence, K ∩ B ∈ SB,rB (𝑚) (p). Conversely, assume that
80

Coherent Predictive Inference under Exchangeability

K ⊆ A, A[𝑚] ⊆ K and K ∩ B ∈ SB,rB (𝑚) (p). Then K ∩ B 6= ∅, implying that K 6= ∅, and
p|ΣK∩B 6= 0, which, by Lemma 50, implies that IrB,A (p)|ΣK 6= 0. Hence, K ∈ SA,𝑚 (IrB,A (p)).
In order to prove the second statement, it clearly suffices to show that SB,rB (𝑚) (p) ⊆
{K ∩ B : K ∈ SA,𝑚 (IrB,A (p))}, since the converse inclusion follows directly from the first
statement. So consider any L ∈ SB,rB (𝑚) (p) and let K := L ∪ A[𝑚]. Then K ⊆ A, A[𝑚] ⊆ K
and K ∩ B = L ∪ (A[𝑚] ∩ B) = L ∪ B[rB (𝑚)] = L. Hence, by the first statement, indeed
K ∈ SA,𝑚 (IrB,A (p)).
To prove the third statement, first assume that K ∈ min SA,𝑚 (IrB,A (p)), implying that
in particular K ∈ SA,𝑚 (IrB,A (p)). Then, by the second statement, K ∩ B ∈ SB,rB (𝑚) (p). To
prove that K ∩ B ∈ min SB,rB (𝑚) (p), consider any L ∈ SB,rB (𝑚) (p) such that L ⊆ K ∩ B, and
let K 0 := L ∪ A[𝑚]. Then, by an argument identical to the one used in the proof of the second
statement, K 0 ∩ B = L and K 0 ∈ SA,𝑚 (IrB,A (p)). However, since K 0 ∩ B = L ⊆ K ∩ B and
K 0 \ B = A[𝑚] \ B ⊆ K \ B, we find that K 0 = (K 0 ∩ B) ∪ (K 0 \ B) ⊆ (K ∩ B) ∪ (K \ B) = K,
and therefore K 0 = K, by assumption. Hence indeed L = K 0 ∩ B = K ∩ B. Assume,
conversely, that L ∈ min SB,rB (𝑚) (p), implying that L ∈ SB,rB (𝑚) (p). Then, by the second
statement, there is some K 0 ∈ SA,𝑚 (IrB,A (p)) such that K 0 ∩ B = L, so there is some
K ∈ min SA,𝑚 (IrB,A (p)) such that K ⊆ K 0 and therefore K ∩ B ⊆ K 0 ∩ B = L. Since
L ∈ min SB,rB (𝑚) (p) and, by the second statement, K ∩ B ∈ SB,rB (𝑚) (p), we also have that
K ∩ B = L.
Lemma 52. Consider any category sets A and B such that B ⊆ A, any p ∈ V (B), any K ⊆ A
such that K ∩ B 6= ∅ and any r ∈ N0 . Then IrB,A (p)|ΣK ∈ V ++ (K) ⇔ p|ΣK∩B ∈ V ++ (K ∩ B).
Proof of Lemma 52. We may assume without loss of generality that r + deg(p) > 0, as the
proof is trivial otherwise. Using Proposition 10, and considering that, since K ∩ B =
6 ∅, θB > 0
for any 𝜃 ∈ int(ΣK ), it then suffices to prove that the following statements are equivalent:
(a) (∀𝜃 ∈ int(ΣK ))p(𝜃|+
B ) > 0;
(b) (∀𝜗 ∈ int(ΣK∩B ))p(𝜗) > 0.
First assume that (a) holds, and consider any 𝜗 ∈ int(ΣK∩B ). We have to prove that p(𝜗) > 0.
We construct
a 𝜃 ∈ ΣK as follows. For any x ∈ K \ B, choose θx > 0 in such a way that
∑︀
κ := x∈K\B θx < 1, which is always possible. And for any x ∈ K ∩B, let θx := (1−κ)ϑx > 0.
Then it follows from this construction that θB = 1 − κ > 0, 𝜃|+
B = 𝜗 and 𝜃 ∈ int(ΣK ), so we
infer from (a) that indeed p(𝜗) = p(𝜃|+
)
>
0.
B
Assume, conversely, that (b) holds, and consider any 𝜃 ∈ int(ΣK ). Then θB > 0 because
+
K ∩B =
6 0 and therefore, for all z ∈ B, (𝜃|+
B )z > 0 ⇔ z ∈ K ∩ B. Hence 𝜃|B ∈ int(ΣK∩B ),
+
so we infer from (b) that p(𝜃|B ) > 0.
Proposition 53. ΦSC is specific.
Proof of Proposition 53. We use the characterisation of specificity in Theorem 11. Consider
any category sets A and B such that B ⊆ A, any p ∈ V (B), any 𝑚 ∈ NA ∪{0}, and any r ∈ N0 .
Then, by Proposition 19, we need to prove that IrB,A (p) ∈ HSC,A,𝑚 ⇔ p ∈ HSC,B,rB (𝑚) .
First, assume that p ∈ HSC,B,rB (𝑚) , which, by Proposition 18, implies that p 6= 0 and
that p|ΣL ∈ V ++ (L) for all L ∈ min SB,rB (𝑚) (p). Applying Lemma 50 with K = A, we infer
from p 6= 0 that IrB,A (p) 6= 0. Consider any K ∈ min SA,𝑚 (IrB,A (p)), then by Lemma 51,
81

De Cooman, De Bock, & Diniz

K ∩ B ∈ min SB,rB (𝑚) (p), implying that, due to the assumption, p|ΣK∩B ∈ V ++ (K ∩ B).
Since K ∩ B 6= 0, we can apply Lemma 52 to find that IrB,A (p)|ΣK ∈ V ++ (K). Hence, again
by Proposition 18, IrB,A (p) ∈ HSC,A,𝑚 .
Assume, conversely, that IrB,A (p) ∈ HSC,A,𝑚 , which, by Proposition 18, implies that
r
IB,A (p) 6= 0 and that IrB,A (p)|ΣK ∈ V ++ (K) for all K ∈ min SA,𝑚 (IrB,A (p)). From Lemma 50
with K = A, and from IrB,A (p) 6= 0, we infer that p 6= 0. Consider any L ∈ min SB,rB (𝑚) (p),
then, by Lemma 51, there is some K ∈ min SA,𝑚 (IrB,A (p)) such that K∩B = L. Since therefore
K ∩ B 6= 0 and since, by assumption, IrB,A (p)|ΣK ∈ V ++ (K), we infer from Lemma 52 that
p|ΣL ∈ V ++ (L). Hence, by Proposition 18, p ∈ HSC,B,rB (𝑚) .
Proof of Theorem 20. This is an immediate consequence of Propositions 17 [coherence], 49
[representation insensitivity] and 53 [specificity].
E.7 Proofs of Results in Section 12
ˇ ∈ NA ∪ {0} and any p ∈ V (A). Then
Proof of Equation (54). Consider any 𝑚
s
s
ˇ ⇔ BA,𝑚 p ∈ HIDM,A
p ∈ HIDM,A
c𝑚
⇔ (∀𝛼 ∈ ∆sA ) DiA (BA,𝑚 p|𝛼) > 0

ˇ + 𝛼) > 0
⇔ (∀𝛼 ∈ ∆sA ) DiA (BA,𝑚 |𝛼) DiA (p|𝑚
ˇ + 𝛼) > 0,
⇔ (∀𝛼 ∈ ∆sA ) DiA (p|𝑚
where the third equivalence follows from the Updating Property of the Dirichlet expectation
[Proposition 31].
ˇ ∈ NA ∪ {0}. Then, combining Equations (56)
Proof of Equation (59). Consider any 𝑚
and (58) for n̂ = 1:
{︁
}︁
∑︁
m̌x + αx
s,1
ˇ = f ∈ L(A) : (∀𝛼 ∈ ∆sA )
DIDM,A
c𝑚
f (x)
>0 .
m̌A + αA
x∈A

Now consider any f ∈ L(A). Then for all 𝛼 ∈ ∆sA :
∑︁
x∈A

f (x)

∑︁
∑︁
m̌x + αx
αx
1 ∑︁
>0⇔
f (x)(m̌x + αx ) > 0 ⇔
>−
f (x)
f (x)m̌x .
m̌A + αA
s
s
x∈A

x∈A

Combining the equations above, and letting c := − 1s
find that:

x∈A

∑︀

x∈A f (x)m̌x

s,1
ˇ ⇔ (∀s0 ∈ (0, s))(∀𝑡 ∈ int(ΣA ))
f ∈ DIDM,A
c𝑚

for ease of notation, we

s0 ∑︁
f (x)tx > c.
s

(95)

x∈A

If f  c, then there is some y ∈ A for which f (y) < c and therefore, by Statement (95),
s,1
ˇ [choose s0 and ty close enough to s and 1, respectively]. If f = c, then due to
f∈
/ DIDM,A
c𝑚
s,1
ˇ Finally, let us
the definition of c, f = c = 0. Hence, again by Statement (95), f ∈
/ DIDM,A
c𝑚.
see what happens ∑︀
if f > c. Then clearly c ≤ 0. Consider any s0 ∈ (0, ∑︀
s) and any 𝑡 ∈ int(ΣA ).
0
0
Then since f > c, x∈A f (x)tx > c and therefore also, since c ≤ 0, ss x∈A f (x)tx > ss c ≥ c.
s,1
ˇ by Statement (95).
Hence f ∈ DIDM,A
c𝑚
82

Coherent Predictive Inference under Exchangeability

ˇ ∈ NA ∪ {0} and any f ∈ L(A). Then by combining
Proof of Equation (60). Consider any 𝑚
Equations (57) and (58):
∑︁
m̌x + αx
m̌x + s0 tx
= inf
inf
f (x)
𝛼∈∆A
m̌A + αA s0 ∈(0,s) 𝑡∈int(ΣA )
m̌A + s0
x∈A
x∈A
(︂
)︂
∑︁
∑︁
1
s0
= inf
f (x)m̌x +
inf
f (x)tx
m̌A + s0 𝑡∈int(ΣA )
s0 ∈(0,s) m̌A + s0
x∈A
x∈A
(︂
)︂
∑︁
1
s0
= inf
f (x)m̌x +
min f
m̌A + s0
s0 ∈(0,s) m̌A + s0
x∈A
∑︁
s
1
f (x)m̌x +
min f,
=
m̌A + s
m̌A + s

ˇ = inf s
P s,1
IDM,A (f |𝑚)

∑︁

f (x)

x∈A

where the last equality follows from min f ≤

m̌x
x∈A f (x) m̌A , a

∑︀

property of convex combinations.

Proof of Theorem 21. For coherence, if we fix any category set A, then we must prove that
s
HIDM,A
satisfies the requirements B1–B3 of Bernstein coherence. This is trivial from the
s
definition of HIDM,A
, the linearity of the Dirichlet expectation operator, and the fact that
the Dirichlet expectation of any Bernstein basis polynomial is positive.
Next, we turn to representation insensitivity, and use its characterisation in Theorem 7.
Consider any category sets A and D such that there is an onto map ρ : A → D, any p ∈ V (D)
and any 𝑚 ∈ NA ∪ {0}. Then, using the Pooling Property [Proposition 33] of the Dirichlet
expectation and Equation (54), we find that indeed:
s
(p ◦ Rρ )BA,𝑚 ∈ HIDM,A
⇔ (∀𝛼 ∈ ∆sA ) DiA (p ◦ Rρ |𝑚 + 𝛼) > 0

⇔ (∀𝛼 ∈ ∆sA ) DiD (p|Rρ (𝑚 + 𝛼)) > 0
s
⇔ (∀𝛽 ∈ ∆sD ) DiD (p|Rρ (𝑚) + 𝛽) > 0 ⇔ pBD,Rρ (𝑚) ∈ HIDM,D
,

where the third equivalence follows from the equality ∆sD = Rρ (∆sA ).
Finally, we turn to specificity, and use its characterisation in Theorem 11. Consider
any category sets A and B such that B ⊆ A, any p ∈ V (B), any 𝑚 ∈ NA ∪ {0} and any
r ∈ N0 . Then, using the Restriction Property [Proposition 34] of the Dirichlet expectation
and Equation (54), we find that indeed:
s
IrB,A (p)BA,𝑚 ∈ HIDM,A
⇔ (∀𝛼 ∈ ∆sA ) DiA (IrB,A (p)|𝑚 + 𝛼) > 0

⇔ (∀𝛼 ∈ ∆sA ) DiB (p|rB (𝑚 + 𝛼)) > 0
s
⇔ (∀𝛽 ∈ ∆sB ) DiB (p|rB (𝑚) + 𝛽) > 0 ⇔ pBB,rB (𝑚) ∈ HIDM,B
,

where the third equivalence follows from ∆sB = rB (∆sA ).
E.8 Proofs of Results in Section 13
s
Lemma 54. For any p1 , p2 ∈ HSI,A
: SA,0 (p1 + p2 ) = SA,0 (p1 ) ∪ SA,0 (p2 ).

83

De Cooman, De Bock, & Diniz

Proof of Lemma 54. First, consider any K ∈ SA,0 (p1 + p2 ), meaning that ∅ 6= K ⊆ A and
(p1 + p2 )|ΣK 6= 0. Assume, ex absurdo, that K ∈
/ SA,0 (p1 ) and K ∈
/ SA,0 (p2 ). Then p1 |ΣK = 0
and p2 |ΣK = 0 and therefore (p1 + p2 )|ΣK = 0, which is a contradiction. Hence indeed
K ∈ SA,0 (p1 ) ∪ SA,0 (p2 ).
Next, consider any K ∈ SA,0 (p1 ) ∪ SA,0 (p2 ), implying that ∅ =
6 K ⊆ A. Then there is
at least one K 0 ∈ min(SA,0 (p1 ) ∪ SA,0 (p2 )) such that K 0 ⊆ K, and we can assume without
loss of generality that K 0 ∈ SA,0 (p1 ). Since K 0 ∈ min(SA,0 (p1 ) ∪ SA,0 (p2 )), we have that
L 6⊂ K 0 for all L ∈ SA,0 (p1 ) ∪ SA,0 (p2 ), and therefore K 0 ∈ min SA,0 (p1 ). This already tells us
s
0
that p1 |ΣK 0 ∈ HIDM,K
0 . There are now two possibilities. The first one is that K ∈ SA,0 (p2 ),
s
and then, in very much the same way as as above, we find that p2 |ΣK 0 ∈ HIDM,K 0 . Hence,
s
s
due to the Bernstein coherence [B3] of HIDM,K
0 , (p1 + p2 )|Σ 0 = p1 |Σ 0 + p2 |Σ 0 ∈ HIDM,K 0 .
K
K
K
0
0
The second possibility is that K ∈
/ SA,0 (p2 ), and then p2 |ΣK 0 = 0 since K 6= ∅, so we find,
s
here too, that (p1 + p2 )|ΣK 0 = p1 |ΣK 0 + p2 |ΣK 0 = p1 |ΣK 0 ∈ HIDM,K
0 . In both cases, therefore,
s
s
(p1 + p2 )|ΣK 0 ∈ HIDM,K 0 , and the Bernstein coherence [B1] of HIDM,K
0 allows us to conclude
6 0. Since K 0 ⊆ K, we find that also (p1 + p2 )|ΣK 6= 0 and therefore that
that (p1 + p2 )|ΣK 0 =
K ∈ SA,0 (p1 + p2 ).
s
s
Proof of Proposition 22. Since 0 ∈
/ HSI,A
, we are left to prove that V + (A) ⊆ HSI,A
and that,
s
s
s
for all λ > 0 and p, p1 , p2 ∈ HSI,A , λp ∈ HSI,A and p1 + p2 ∈ HSI,A .
s
First, consider any λ > 0 and p ∈ HSI,A
. Then, clearly, SA,0 (λp) = SA,0 (p) and therefore
min SA,0 (λp) = min SA,0 (p). Then for any K ∈ min SA,0 (λp), we have that K ∈ min SA,0 (p),
s
s
which, since p ∈ HSI,A
, implies that p|ΣK ∈ HIDM,K
and therefore, due to the Bernstein
s
s
coherence of HIDM,K , that (λp)|ΣK = λ(p|ΣK ) ∈ HIDM,K
. Furthermore, since p 6= 0 also
s
λp 6= 0, and therefore λp ∈ HSI,A .
s
Next, consider any p1 , p2 ∈ HSI,A
. Then p1 6= 0 and p2 6= 0, implying that SA,0 (p1 ) 6= ∅
and SA,0 (p2 ) 6= ∅, and therefore SA,0 (p1 ) ∪ SA,0 (p2 ) 6= ∅. Applying Lemma 54, we find
that SA,0 (p1 + p2 ) 6= ∅, so there is some K such that ∅ 6= K ⊆ A, (p1 + p2 )|ΣK =
6 0 and
therefore p1 + p2 6= 0. Then for any K 0 ∈ min SA,0 (p1 + p2 ), or equivalently, due to Lemma 54,
K 0 ∈ min(SA,0 (p1 ) ∪ SA,0 (p2 )). Then, by applying the same reasoning as in the second part
s
s
of the proof of Lemma 54, we find that (p1 + p2 )|ΣK 0 ∈ HIDM,K
0 . Hence, p1 + p2 ∈ HSI,A .
s
Since we have already shown that HSI,A is closed under taking positive linear combinations,
and since V + (A) consists of positive linear combinations of Bernstein basis polynomials, we
s
only need to show that HSI,A
contains all Bernstein basis polynomials in order to prove that
+
s
V (A) ⊆ HSI,A . So consider any 𝑚 ∈ NA ∪ {0}. Then, for any K such that ∅ 6= K ⊆ A, we
have that BA,𝑚 |ΣK = BK,rK (𝑚) if A[𝑚] ⊆ K, and BA,𝑚 |ΣK = 0 otherwise. This implies that
s
SA,0 (BA,𝑚 ) = {∅ =
6 K ⊆ A : A[𝑚] ⊆ K} and that, due to the Bernstein coherence of HIDM,K
,
s
s
BA,𝑚 |ΣK = BK,rK (𝑚) ∈ HIDM,K for all K ∈ SA,0 (BA,𝑚 ). Hence, BA,𝑚 |ΣK ∈ HIDM,K for all
s
K ∈ min SA,0 (BA,𝑚 ). Since also BA,𝑚 6= 0, we find that indeed BA,𝑚 ∈ HSI,A
.
s
s
Proof of Proposition 23. We first prove that HSI,A
c𝑚 ⊆ HSI,A,𝑚
. Consider any p ∈ V (A)
s
s
such that pBA,𝑚 ∈ HSI,A , meaning that pBA,𝑚 6= 0 and that (pBA,𝑚 )|ΣK ∈ HIDM,K
for all
s
K ∈ min SA,0 (pBA,𝑚 ). We set out to prove that p ∈ HSI,A,𝑚 . Since, clearly, p 6= 0, it suffices to
s
show that p|ΣK ∈ HIDM,K
crK (𝑚) for all K ∈ min SA,𝑚 (p). So consider any K ∈ min SA,𝑚 (p),
implying that A[𝑚] ⊆ K and therefore also that K[rK (𝑚)] = A[𝑚]. We also infer from
s
Lemma 44 that K ∈ min SA,0 (pBA,𝑚 ), which tells us that (pBA,𝑚 )|ΣK ∈ HIDM,K
. Since
s
(pBA,𝑚 )|ΣK = p|ΣK BA,𝑚 |ΣK = p|ΣK BK,rK (𝑚) , we find that p|ΣK ∈ HIDM,K crK (𝑚).

84

Coherent Predictive Inference under Exchangeability

s
s
s
Next, we prove that HSI,A,𝑚
⊆ HSI,A
c𝑚. Consider any p ∈ HSI,A,𝑚
, meaning that
s
p 6= 0 and p|ΣK ∈ HIDM,K crK (𝑚) for all K ∈ min SA,𝑚 (p). We set out to prove that
s
s
pBA,𝑚 ∈ HSI,A
or, equivalently, that pBA,𝑚 =
for all
6 0 and that (pBA,𝑚 )|ΣK ∈ HIDM,K
K ∈ min SA,0 (pBA,𝑚 ). Since p 6= 0, the continuity of polynomials guarantees that there is
some 𝜃 ∈ int(ΣA ) such that p(𝜃) 6= 0 and therefore also (pBA,𝑚 )(𝜃) 6= 0. So we know already
that pBA,𝑚 6= 0. Consider any K ∈ min SA,0 (pBA,𝑚 ). Then, by Lemma 44, K ∈ min SA,𝑚 (p),
s
s
implying that A[𝑚] ⊆ K and p|ΣK ∈ HIDM,K
crK (𝑚) and therefore p|ΣK BK,rK (𝑚) ∈ HIDM,K
.
s
Since moreover p|ΣK BK,rK (𝑚) = (pBA,𝑚 )|ΣK , we find that indeed (pBA,𝑚 )|ΣK ∈ HIDM,K .

Proof of Equation (63). Due to Equation (17), it suffices to prove that, for any p ∈ V (A),
s
s
minx∈A p(𝜃x◦ ) > 0 ⇒ p ∈ HSI,A
and minx∈A p(𝜃x◦ ) < 0 ⇒ p ∈
/ HSI,A
.
◦
First, assume that minx∈A p(𝜃x ) < 0. Then there is some y ∈ A for which p(𝜃y◦ ) < 0.
Hence, since p|Σ{y} = p(𝜃y◦ ) < 0, we find that {y} ∈ min SA,0 (p) and therefore also, due to
s
s
the Bernstein coherence of HIDM,{y}
[see Theorem 21], that p|Σ{y} ∈
/ HIDM,{y}
, from which
s
we infer that p ∈
/ HSI,A .
Next, assume that minx∈A p(𝜃x◦ ) > 0. Then p|Σ{x} = p(𝜃x◦ ) > 0 for all x ∈ A, implying
s
that min SA,0 (p) = {{x} : x ∈ A} and that, for all x ∈ A, p|Σ{x} ∈ HIDM,{x}
, again because
s
s
of the Bernstein coherence of HIDM,{x} . Hence, since p 6= 0, we find that p ∈ HSI,A
.
Proof of Equations (64) and (65). Equation (65) follows directly from Equation (55). We
prove Equation (64). Due to Equation (17) and Proposition 23, it suffices to prove that, for
ˇ ∈ NA and any p ∈ V (A):
any 𝑚
s
s
ˇ > 0 ⇒ p ∈ HSI,A,
ˇ <0⇒p∈
c(p, 𝑚)
/ HSI,A,
ˇ and c(p, 𝑚)
ˇ,
𝑚
𝑚

where, for ease of notation, we let
ˇ :=
c(p, 𝑚)

inf

𝛼∈∆sA[𝑚]
ˇ

ˇ + 𝛼).
DiA[𝑚]
|rA[𝑚]
ˇ (p|ΣA[𝑚]
ˇ (𝑚)
ˇ

ˇ < 0, implying that DiA[𝑚]
ˇ + 𝛼) < 0 for
First, assume that c(p, 𝑚)
|rA[𝑚]
ˇ (p|ΣA[𝑚]
ˇ (𝑚)
ˇ
s
some 𝛼 ∈ ∆A[𝑚]
6= 0 and, by Equation (54), that p|ΣA[𝑚]
∈
/
ˇ and therefore also that p|ΣA[𝑚]
ˇ
ˇ
s
ˇ
ˇ
HIDM,A[𝑚]
ˇ (p) and therefore also that
ˇ (𝑚). Hence, we find that A[𝑚] ∈ min SA,𝑚
ˇ crA[𝑚]
s
p∈
/ HSI,A,
.
ˇ
𝑚
ˇ > 0, implying that p|ΣA[𝑚]
Next, assume that c(p, 𝑚)
6= 0 and, by Equation (54), that
ˇ
s
ˇ
ˇ and therefore
p|ΣA[𝑚]
∈
H
cr
(
𝑚).
Hence,
we
find
that
min
S
ˇ (p) = {A[𝑚]}
A,𝑚
ˇ
A[𝑚]
ˇ
IDM,A[𝑚]
ˇ
s
also that p ∈ HSI,A,𝑚
ˇ.
ˇ ∈ NA :
Proof of Equation (67). By combining Equations (62) and (30), we see that, for any 𝑚
{︀
}︀
s,1
s
ˇ = f ∈ L(A) : SA (f ) ∈ HSI,A,
DSI,A
c𝑚
(96)
ˇ .
𝑚
Consider now any f ∈ L(A) and distinguish between two cases: f |A[𝑚]
ˇ 6= 0 and f |A[𝑚]
ˇ = 0.
If f |A[𝑚]
ˇ 6= 0 [and therefore also f 6= 0], then
s,1
s
ˇ ⇔ SA (f )|ΣA[𝑚]
f ∈ DSI,A
c𝑚
∈ HIDM,A[
ˇ (𝑚)
ˇ crA[𝑚]
𝑚]
ˇ
s
⇔ SA[𝑚]
ˇ (f |A[𝑚]
ˇ ) ∈ HIDM,A[𝑚]
ˇ (𝑚)
ˇ crA[𝑚]

85

De Cooman, De Bock, & Diniz

s,1
⇔ f |A[𝑚]
ˇ ∈ DIDM,A[𝑚]
ˇ (𝑚)
ˇ crA[𝑚]
∑︁
1
1 ∑︁
⇔ f |A[𝑚]
>
−
f
(x)
m̌
⇔
f
>
−
f (x)m̌x or f > 0,
x
ˇ
ˇ
|A[𝑚]
s
s
ˇ
x∈A[𝑚]

ˇ
x∈A[𝑚]

where the first equivalence is due to Statement (93) and Equations (94), (61) and (96). The
second equivalence follows from the definition of SA and SA[𝑚]
ˇ and the third one is due to
Equations (21) and (30). The fourth equivalence is a consequence of Equation (67) and the
final equivalence holds because f > 0 is redundant, given that f |A[𝑚]
ˇ 6= 0.
If f |A[𝑚]
ˇ = 0, then [again, using Statement (93) and Equations (94), (61) and (96)]
s,1
ˇ if and only if f 6= 0 and if for all x ∈ A \ A[𝑚]:
ˇ
f ∈ DSI,A
c𝑚
s
f (x) = 0 or SA (f )|ΣA[𝑚]∪{x}
∈ HIDM,A[
crA[𝑚]∪{x}
(𝑚).
ˇ
ˇ
𝑚]∪{x}
ˇ
s
Since f |A[𝑚]
crA[𝑚]∪{x}
(𝑚) is Bernstein coherent [Theorem 21], the
ˇ = 0 and HIDM,A[𝑚]∪{x}
ˇ
ˇ
latter statement is equivalent to f (x) > 0. Hence, we find that:
s,1
ˇ ⇔ f 6= 0 and (∀x ∈ A \ A[𝑚])f
ˇ
f ∈ DSI,A
c𝑚
(x) ≥ 0

⇔f >0
⇔ f |A[𝑚]
ˇ >−

1 ∑︁
f (x)m̌x or f > 0,
s
ˇ
x∈A[𝑚]

where the second and third equivalences are consequences of f |A[𝑚]
ˇ = 0.
Lemma 55. Consider any category sets A and D such that there is an onto map ρ : A → D,
any p ∈ V (D), any 𝑚 ∈ NA ∪ {0}, and any ∅ 6= K ⊆ A such that A[𝑚] ⊆ K. Then
s
s
(p ◦ Rρ )|ΣK ∈ HIDM,K
crK (𝑚) ⇔ p|Σρ(K) ∈ HIDM,ρ(K)
crρ(K) (Rρ (𝑚)).
Proof of Lemma 55. Let A∗ := K, D∗ := ρ(K), ρ∗ := ρ|K and p∗ := p|Σρ(K) . Then ρ∗ is
an onto map from A∗ to D∗ , p∗ ∈ V (D∗ ) and p∗ ◦ Rρ∗ = p|Σρ(K) ◦ Rρ|K = (p ◦ Rρ )|ΣK .
mA
Since A[𝑚] ⊆ K, we can identify 𝑚 with an element 𝑚∗ := rK (𝑚) of NK
and therefore
the result follows from the representation insensitivity of the IDMM inference system with
hyperparameter s, because then also Rρ∗ (𝑚∗ ) = Rρ|K (rK (𝑚)) = rρ(K) (Rρ (𝑚)):
s
∗
∗
s
∗
p∗ ◦ Rρ∗ ∈ HIDM,A
∗ c𝑚 ⇔ p ∈ HIDM,D ∗ cRρ∗ (𝑚 ).

Proposition 56. ΦsSI is representation insensitive.
Proof of Proposition 56. We use the characterisation of representation insensitivity in Theorem 7. Consider any category sets A and D such that there is an onto map ρ : A → D,
any p ∈ V (D) and any 𝑚 ∈ NA ∪ {0}. Then, by Proposition 23, we need to prove that
s
s
p ◦ Rρ ∈ HSI,A,𝑚
⇔ p ∈ HSI,D,R
.
ρ (𝑚)
s
s
First, assume that p ∈ HSI,D,Rρ (𝑚) , meaning that p 6= 0 and p|ΣL ∈ HIDM,L
crL (Rρ (𝑚))
for all L ∈ min SD,Rρ (𝑚) (p). Applying Lemma 45 with K = A, we infer from p 6= 0 that
p ◦ Rρ 6= 0. Consider any K ∈ min SA,𝑚 (p ◦ Rρ ), so ∅ 6= K ⊆ A and A[𝑚] ⊆ K. Then,
by Lemma 46, ρ(K) ∈ min SD,Rρ (𝑚) (p), implying that, due to the assumption, p|Σρ(K) ∈
86

Coherent Predictive Inference under Exchangeability

s
s
HIDM,ρ(K)
crρ(K) (Rρ (𝑚)). Applying Lemma 55, we find that (p ◦ Rρ )|ΣK ∈ HIDM,K
crK (𝑚).
s
Hence, p ◦ Rρ ∈ HSI,A,𝑚 .
s
Assume, conversely, that p ◦ Rρ ∈ HSI,A,𝑚
, meaning that p ◦ Rρ 6= 0 and that (p ◦ Rρ )|ΣK ∈
s
HIDM,K crK (𝑚) for all K ∈ min SA,𝑚 (p ◦ Rρ ). Applying Lemma 45 with K = A, we infer
from p ◦ Rρ 6= 0 that p 6= 0. Consider any L ∈ min SD,Rρ (𝑚) (p). By Lemma 46, there
is some K ∈ min SA,𝑚 (p ◦ Rρ ) such that ρ(K) = L. Since ∅ 6= K ⊆ A, A[𝑚] ⊆ K
s
and, by the assumption, (p ◦ Rρ )|ΣK ∈ HIDM,K
crK (𝑚), we infer from Lemma 55 that
s
s
p|ΣL ∈ HIDM,L crL (Rρ (𝑚)). Hence, p ∈ HSI,D,Rρ (𝑚) .

Lemma 57. Consider any category sets A and B such that B ⊆ A, any p ∈ V (B), any
𝑚 ∈ NA ∪ {0}, any r ∈ N0 and any K ⊆ A such that K ∩ B 6= ∅ and A[𝑚] ⊆ K. Then
s
s
IrB,A (p)|ΣK ∈ HIDM,K
crK (𝑚) ⇔ p|ΣK∩B ∈ HIDM,K∩B
crK∩B (𝑚).
Proof of Lemma 57. Let A∗ := K, B ∗ := K ∩ B, p∗ := p|ΣK∩B and r∗ = deg(p) − deg(p∗ ) + r.
Then B ∗ ⊆ A∗ , p∗ ∈ V (B ∗ ), r∗ ≥ r ≥ 0, r∗ + deg(p∗ ) = r + deg(p), and
∑︁
∑︁
bdeg(p)+r
(𝑛)BA,iA (𝑛)|ΣK =
bdeg(p)+r
(𝑛)BA,iA (𝑛)|ΣK
IrB,A (p)|ΣK =
p
p
deg(p)+r

deg(p)+r

𝑛∈NB

=

∑︁

𝑛∈NB
B[𝑛]⊆K
∗

bdeg(p)+r
(𝑛)BK,iK (𝑛) = IrB ∗ ,A∗ (p∗ ),
p|Σ
K∩B

deg(p)+r

𝑛∈NK∩B

where the third equality follows from the unicity of the Bernstein expansion of a polynomial.
Since A[𝑚] ⊆ K, we can identify 𝑚 with an element 𝑚∗ := rK (𝑚) of NK ∪{0} and therefore
the result follows from the specificity of the IDMM inference system with hyperparameter s,
because then also rB ∗ (𝑚∗ ) = rK∩B (𝑚):
∗

s
∗
∗
s
∗
IrB ∗ ,A∗ (p∗ ) ∈ HIDM,A
∗ c𝑚 ⇔ p ∈ HIDM,B ∗ crB ∗ (𝑚 ).

Proposition 58. ΦsSI is specific.
Proof of Proposition 58. We use the characterisation of specificity in Theorem 11. Consider
any category sets A and B such that B ⊆ A, any p ∈ V (B), any 𝑚 ∈ NA ∪ {0} and any
s
s
r ∈ N0 . Then, by Proposition 23, we need to prove that IrB,A (p) ∈ HSI,A,𝑚
⇔ p ∈ HSI,B,r
.
B (𝑚)
It is clear from Propositions 10 and 22 that we can assume without loss of generality that
r + deg(p) > 0.
s
s
First, assume that p ∈ HSI,B,r
, implying that p =
6 0 and that p|ΣL ∈ HIDM,L
crB∩L (𝑚)
B (𝑚)
for all L ∈ min SB,rB (𝑚) (p). Applying Lemma 50 with K = A, we infer from p 6= 0 that
IrB,A (p) 6= 0. Consider any K ∈ min SA,𝑚 (IrB,A (p)). Then we infer from Lemma 51 that K ∩
s
crK∩B (𝑚).
B ∈ min SB,rB (𝑚) (p), implying that, due to our assumption, p|ΣK∩B ∈ HIDM,K∩B
r
s
Since K ∩ B 6= 0 and A[𝑚] ⊆ K, IB,A (p)|ΣK ∈ HIDM,K crK (𝑚) because of Lemma 57. Hence,
s
IrB,A (p) ∈ HSI,A,𝑚
.
s
Assume, conversely, that IrB,A (p) ∈ HSI,A,𝑚
, which implies that IrB,A (p) 6= 0 and that
r
s
IB,A (p)|ΣK ∈ HIDM,K crK (𝑚) for all K ∈ min SA,𝑚 (IrB,A (p)). Applying Lemma 50 with
K = A, we infer from IrB,A (p) 6= 0 that p 6= 0. Consider any L ∈ min SB,rB (𝑚) (p). By
Lemma 51, there is some K ∈ min SA,𝑚 (IrB,A (p)) such that K ∩ B = L. Since K ∩ B 6= 0,
87

De Cooman, De Bock, & Diniz

s
A[𝑚] ⊆ K and, by assumption, IrB,A (p)|ΣK ∈ HIDM,K
crK (𝑚), we infer from Lemma 57
s
s
that p|ΣK∩B ∈ HIDM,K∩B crK∩B (𝑚), or in other words, p|ΣL ∈ HIDM,L
crB∩L (𝑚). Hence,
s
p ∈ HSI,B,rB (𝑚) .

Proof of Theorem 24. This is an immediate consequence of Propositions 22 [coherence], 56
[representation insensitivity] and 58 [specificity].
E.9 Proofs of Results in Section 14
Proof of Theorem 25. We begin with coherence. Consider any category set A, then we have
s
to prove that HH,A is Bernstein coherent. For B1, recall that 0 ∈
/ HIDM,A
for all s > 0, and
+
s
therefore also 0 ∈
/ HH,A . Similarly, for B2, recall that V (A) ⊆ HIDM,A for all s > 0, and
+
therefore also V (A) ⊆ HH,A . For B3, consider n ∈ N and λk ∈ R>0 and pk ∈ HH,A for
s
all k ∈ {1, . . . ,∑︀
n}. Then there is some s > 0 such that pk ∈ HIDM,A
for all k ∈ {1, . . . , n},
n
s
and
∑︀n therefore k=1 λk pk ∈ HIDM,A , by Bernstein coherence [Theorem 21]. Hence indeed
k=1 λk pk ∈ HH,A .
Next, we turn to representation insensitivity, and use its characterisation in Theorem 7.
Consider any category sets A and D such that there is an onto map ρ : A → D, any p ∈ V (D)
and any 𝑚 ∈ NA ∪ {0}. Then we find that indeed:
s
(p ◦ Rρ )BA,𝑚 ∈ HH,A ⇔ (∃s ∈ R>0 )(p ◦ Rρ )BA,𝑚 ∈ HIDM,A
s
⇔ (∃s ∈ R>0 )pBD,Rρ (𝑚) ∈ HIDM,D
⇔ pBD,Rρ (𝑚) ∈ HH,D ,

where the second equivalence follows from the representation insensitivity of the IDMM
inference systems [Theorem 21].
Finally, we turn to specificity, and use its characterisation in Theorem 11. Consider any
category sets A and B such that B ⊆ A, any p ∈ V (B), any 𝑚 ∈ NA ∪ {0} and any r ∈ N0 .
Then we find that indeed:
s
IrB,A (p)BA,𝑚 ∈ HH,A ⇔ (∃s ∈ R>0 )IrB,A (p)BA,𝑚 ∈ HIDM,A
s
⇔ (∃s ∈ R>0 )pBB,rB (𝑚) ∈ HIDM,B
⇔ pBB,rB (𝑚) ∈ HH,B ,

where the second equivalence follows from the specificity of IDMM inference systems [Theorem 21].
ˇ ∈ NA ∪ {0} and any p ∈ V (A):
Proof of Equation (69). For any 𝑚
s
ˇ ⇔ pBA,𝑚
p ∈ HH,A c𝑚
ˇ ∈ HH,A ⇔ (∃s ∈ R>0 )pBA,𝑚
ˇ ∈ HIDM,A
s
ˇ
⇔ (∃s ∈ R>0 )p ∈ HIDM,A
c𝑚.

Combined with Equation (54), this yields the desired result.
ˇ ∈ NA ∪ {0} and any p ∈ V (A):
Proof of Equation (71). For any 𝑚
ˇ = sup {µ ∈ R : p − µ ∈ HH,A c𝑚}
ˇ
H H,A (p|𝑚)
{︀
}︀
s
ˇ
= sup sup µ ∈ R : p − µ ∈ HIDM,A
c𝑚
s∈R>0

88

Coherent Predictive Inference under Exchangeability

ˇ + 𝛼) = lim
inf s DiA (p|𝑚

= sup

ˇ + 𝛼),
inf DiA (p|𝑚

s→+0 𝛼∈∆sA

s∈R>0 𝛼∈∆A

where the second equality is due to Equation (69), and the third one due to Equation (54).
Proof of Equation (72). Consider any p ∈ V (A) and apply Equation (71):
H H,A (p) = lim

inf DiA (p|𝛼) = lim

s→+0 𝛼∈∆sA

inf DiA (p|s0 𝑡)

inf

s→+0 𝑡∈int(ΣA ) s0 ∈(0,s)

(97)

Now fix any n ≥ max{deg(p), 1} and any 𝑡 ∈ int(ΣA ). Using Equation (80), we find that for
all 𝑚 ∈ NAn :
(︂

1

0

DiA (BA,𝑚 |s 𝑡) =

s0 (n)

)︂
(︂ )︂ ∏︁
n ∏︁ 0 (mx )
n
1
(m )
(s tx )
= (n)
(s0 tx ) x ,
0
𝑚
𝑚
s
x∈A
x∈A[𝑚]

where for all x ∈ A[𝑚]:
(mx )

(s0 tx )

= (s0 tx )(s0 tx + 1) . . . (s0 tx + mx − 1) = s0 tx (mx − 1)![1 + O(s0 )]

and similarly:
1
s0 (n)

=

s0 (n

1
[1 + O(s0 )].
− 1)!

Hence, we find that
(︃ ∏︀
0

DiA (BA,𝑚 |s 𝑡) =

x∈A[𝑚] tx (mx

− 1)!

)︃

(n − 1)!

s0|A[𝑚]|−1 [1 + O(s0 )].

We now consider two cases: |A[𝑚]| > 1 and |A[𝑚]| = 1 [since n ≥ 1, these cases are
exhaustive]. If |A[𝑚]| > 1, then DiA (BA,𝑚 |s0 𝑡) = O(s0 ). If |A[𝑚]| = 1 or, equivalently, if
there is some x ∈ A such that 𝑚 = n𝑒x , then DiA (BA,n𝑒x |s0 𝑡) = tx [1 + O(s0 )]. If we combine
this with Equation (78), we find that
DiA (p|s0 𝑡) =

∑︁

bnp (𝑚) DiA (BA,𝑚 |s0 𝑡) =

n
𝑚∈NA

∑︁

bnp (n𝑒x )tx + O(s0 ).

x∈A

Furthermore, again due to Equation (78):
bnp (n𝑒x ) =

∑︁

bnp (𝑚)BA,𝑚 (𝜃x◦ ) = p(𝜃x◦ ) for all x ∈ A.

n
𝑚∈NA

Hence, we conclude that
DiA (p|s0 𝑡) =

∑︁

p(𝜃x◦ )tx + O(s0 ),

x∈A

which, combined with Equation (97), leads to the desired result.
89

De Cooman, De Bock, & Diniz

ˇ ∈ NA and any p ∈ V (A) and use Equation (71):
Proof of Equation (73). Consider any 𝑚
ˇ = lim
H H,A (p|𝑚)

ˇ = lim sup DiA (p|𝑚
ˇ + 𝛼). (98)
ˇ + 𝛼) and H H,A (p|𝑚)
inf DiA (p|𝑚

s→+0 𝛼∈∆sA

s→+0 𝛼∈∆s

A

ˇ is Bernstein coherent [Theorem 25], it follows that H H,A (·|𝑚)
ˇ is a coherent
Since HH,A c𝑚
ˇ is super-additive, and that its conjugate upper
lower prevision. This implies that H H,A (·|𝑚)
ˇ is sub-additive. Hence, it suffices to prove the equalities in Equation (73)
prevision H H,A (·|𝑚)
for any Bernstein basis polynomial p = BA,𝑛 , where 𝑛 ∈ NA ∪ {0}. Now for any 𝛼 ∈ ∆sA we
gather from Equation (80) in Appendix B that:
(︂ )︂ ∏︁
n
ˇ + 𝛼) =
(m̌x + αx )(nx ) .
DiA (BA,𝑛 |𝑚
(n) 𝑛
(m̌A + αA )
x∈A
1

Observe that:
x)
(m̌x + αx )(nx ) = (m̌x + αx )(m̌x + αx + 1) . . . (m̌x + αx + nx − 1) = m̌(n
[1 + O(αx )],
x

and similarly, since m̌A > 0:
1
(m̌A + αA )

(n)

1

=

(n)

m̌A

[1 + O(αA )]

Therefore:
(︂ )︂ ∏︀
(nx )
∏︁
n
x∈A m̌x
ˇ + 𝛼) =
DiA (BA,𝑛 |𝑚
[1
+
O(α
)]
[1 + O(αx )],
A
(n)
𝑛
m̌
x∈A

A

which, using Equation (98), leads to:46
(︂ )︂ ∏︀
(nx )
n
x∈A m̌x
ˇ = H H,A (BA,𝑛 |𝑚)
ˇ =
ˇ
H H,A (BA,𝑛 |𝑚)
= DiA (BA,𝑛 |𝑚).
(n)
𝑛
m̌
A

E.10 Proofs of Results in Section 15
Proof of Theorem 26. We have already argued above that there is a smallest such inference
system Φ, and we shall denote its lower probability function by ϕ. First, assume that n ≥ 2.
If we denote ∆ϕ(n, k) := ϕ(n, k + 1) − ϕ(n, k), then it follows from the assumptions that
∆ϕ(n, k + 1) ≤ ∆ϕ(n, k) for 0 ≤ k ≤ n − 2.

(99)

We are first going to prove by induction that this implies that
ϕ(n, k) ≥

k
ϕ(n, n) for 0 ≤ k ≤ n.
n

46. See footnote 35.

90

(100)

Coherent Predictive Inference under Exchangeability

Observe that this inequality holds trivially for k = 0 [Theorem 14.L1]. So assume that the
inequality holds for k = `, where ` ∈ {0, . . . , n − 1}. Then we must show that it also holds
for k = ` + 1. Assume, ex absurdo, that it does not, and therefore
ϕ(n, ` + 1) <

`+1
1
ϕ(n, n) ≤ ϕ(n, `) + ϕ(n, n),
n
n

(101)

where the second inequality follows from the induction hypothesis. Now we also have that
ϕ(n, n) = ϕ(n, ` + 1) +

n−1
∑︁

∆ϕ(n, m) ≤ ϕ(n, ` + 1) + (n − ` − 1)∆ϕ(n, `)

m=`+1

<

`+1
n−`−1
ϕ(n, n) +
ϕ(n, n) = ϕ(n, n),
n
n

where the first inequality follows from Equation (99), and the second from the first and
second inequalities in Equation (101). This is a contradiction, which completes our proof by
induction of (100).
We infer from (100), Theorem 14.L9 and assumption (76) that
ϕ(n, k) ≥

k n
k
=
for 0 ≤ k ≤ n.
nn+s
n+s

(102)

Also observe that this inequality holds trivially for n ∈ {0, 1}. We then get for the predictive
lower prevision P 1A (h|𝑚) of any gamble h on A:
∑︁
[h(x) − min h]P 1A (I{x} |𝑚)
P 1A (h|𝑚) = min h + P 1A (h − min h|𝑚) ≥ min h +
x∈A

= min h +

∑︁

[h(x) − min h]ϕ(n, mx )

x∈A

≥ min h +

∑︁
x∈A

[h(x) − min h]

mx
= P s,1
IDM,A (h|𝑚),
n+s

where the first equality and the first inequality follow from the coherence [P5, P2 and P3]
of P 1A (·|𝑚), the second equality from representation insensitivity [Equation (33)], and the
second inequality from Equation (102). For the converse inequality, observe that the IDMM
inference system ΦsIDM is coherent, representation insensitive, and specific by Theorem 21,
clearly has concave surprise, satisfies assumption (76), and therefore dominates the smallest
such inference system.

References
Augustin, T., Coolen, F. P. A., De Cooman, G., & Troffaes, M. C. M. (Eds.). (2014).
Introduction to Imprecise Probabilities. John Wiley & Sons.
Bernard, J.-M. (1997). Bayesian analysis of tree-structured categorized data. Revue Internationale de Systémique, 11, 11–29.
Bernard, J.-M. (2005). An introduction to the imprecise Dirichlet model for multinomial
data. International Journal of Approximate Reasoning, 39, 123–150.
91

De Cooman, De Bock, & Diniz

Bernard, J.-M. (2007). In personal conversation..
Boole, G. (1847, reprinted in 1961). The Laws of Thought. Dover Publications, New York.
Boole, G. (2004, reprint of the work originally published by Watts & Co., London, in 1952).
Studies in Logic and Probability. Dover Publications, Mineola, NY.
Carnap, R. (1952). The continuum of inductive methods. The University of Chicago Press.
Cifarelli, D. M., & Regazzini, E. (1996). De Finetti’s contributions to probability and statistics.
Statistical Science, 11, 253–282.
Couso, I., & Moral, S. (2011). Sets of desirable gambles: conditioning, representation, and
precise probabilities. International Journal of Approximate Reasoning, 52 (7), 1034–
1055.
Cozman, F. G. (2013). Independence for full conditional probabilities: Structure, factorization, non-uniqueness, and bayesian networks. International Journal Of Approximate
Reasoning, 54 (9), 1261–1278.
De Cooman, G., & Miranda, E. (2007). Symmetry of models versus models of symmetry. In
Harper, W. L., & Wheeler, G. R. (Eds.), Probability and Inference: Essays in Honor of
Henry E. Kyburg, Jr., pp. 67–149. King’s College Publications.
De Cooman, G., & Miranda, E. (2008a). The F. Riesz Representation Theorem and finite
additivity. In Dubois, D., Lubiano, M. A., Prade, H., Gil, M. A., Grzegorzewski,
P., & Hryniewicz, O. (Eds.), Soft Methods for Handling Variability and Imprecision
(Proceedings of SMPS 2008), pp. 243–252. Springer.
De Cooman, G., & Miranda, E. (2008b). Weak and strong laws of large numbers for coherent
lower previsions. Journal of Statistical Planning and Inference, 138 (8), 2409–2432.
De Cooman, G., & Miranda, E. (2012). Irrelevant and independent natural extension for
sets of desirable gambles.. Journal of Artificial Intelligence Research, 45, 601–640.
De Cooman, G., Miranda, E., & Quaeghebeur, E. (2009a). Representation insensitivity in
immediate prediction under exchangeability. International Journal of Approximate
Reasoning, 50 (2), 204–216.
De Cooman, G., & Quaeghebeur, E. (2012). Exchangeability and sets of desirable gambles.
International Journal of Approximate Reasoning, 53 (3), 363–395. Special issue in
honour of Henry E. Kyburg, Jr.
De Cooman, G., Quaeghebeur, E., & Miranda, E. (2009b). Exchangeable lower previsions.
Bernoulli, 15 (3), 721–735.
de Finetti, B. (1937). La prévision: ses lois logiques, ses sources subjectives. Annales de
l’Institut Henri Poincaré, 7, 1–68. English translation by Kyburg Jr. and Smokler
(1964).
de Finetti, B. (1970). Teoria delle Probabilità. Einaudi, Turin.
de Finetti, B. (1974–1975). Theory of Probability: A Critical Introductory Treatment. John
Wiley & Sons, Chichester. English translation de Finetti’s (1970) book, two volumes.
Dubins, L. E. (1975). Finitely additive conditional probabilities, conglomerability and
disintegrations. The Annals of Probability, 3, 88–99.
92

Coherent Predictive Inference under Exchangeability

Geisser, S. (1993). Predictive Inference: An Introduction. Chapman & Hall.
Goldstein, M. (1983). The prevision of a prevision. Journal of the American Statistical
Society, 87, 817–819.
Goldstein, M. (1985). Temporal coherence. In Bernardo, J. M., DeGroot, M. H., Lindley,
D. V., & Smith, A. F. M. (Eds.), Bayesian Statistics, Vol. 2, pp. 231–248. North-Holland,
Amsterdam. With discussion.
Good, I. J. (1965). The Estimation of Probabilities: An Essay on Modern Bayesian Methods.
The MIT Press.
Haldane, J. B. S. (1945). On a method of estimating frequencies. Biometrika, 33, 222–225.
Hausdorff, F. (1923). Momentprobleme für ein endliches Intervall. Mathematische Zeitschrift,
13, 220–248.
Jaynes, E. T. (2003). Probability Theory: The Logic of Science. Cambridge University Press.
Jeffreys, H. (1998). Theory of Probability. Oxford Classics series. Oxford University Press.
Reprint of the third edition (1961), with corrections.
Johnson, N. L., Kotz, S., & Balakrishnan, N. (1997). Discrete Multivariate Distributions.
Wiley Series in Probability and Statistics. John Wiley and Sons, New York.
Johnson, W. E. (1924). Logic, Part III. The Logical Foundations of Science. Cambridge
University Press. Reprinted by Dover Publications in 1964.
Keynes, J. M. (1921). A Treatise on Probability. Macmillan, London.
Koopman, B. O. (1940). The Axioms and Algebra of Intuitive Probability. The Annals of
Mathematics, Second Series, 41 (2), 269–292.
Kyburg Jr., H. E., & Smokler, H. E. (Eds.). (1964). Studies in Subjective Probability. Wiley,
New York. Second edition (with new material) 1980.
Lad, F. (1996). Operational Subjective Statistical Methods: A Mathematical, Philosophical
and Historical Introduction. John Wiley & Sons.
Levi, I. (1980). The Enterprise of Knowledge. MIT Press, London.
Mangili, F., & Benavoli, A. (2013). New prior near-ignorance models on the simplex.
In Cozman, F., Denœux, T., Destercke, S., & Seidenfeld, T. (Eds.), ISIPTA ’13 –
Proceedings of the Eighth International Symposium on Imprecise Probability: Theories
and Applications, pp. 213–222. SIPTA.
Miranda, E. (2009). Updating coherent lower previsions on finite spaces. Fuzzy Sets and
Systems, 160 (9), 1286–1307.
Miranda, E., & De Cooman, G. (2014). Introduction to Imprecise Probabilities, chap. Lower
previsions. John Wiley & Sons.
Miranda, E., & Zaffalon, M. (2011). Notes on desirability and conditional lower previsions.
Annals Of Mathematics And Artificial Intelligence, 60 (3-4), 251–309.
Moral, S. (2005). Epistemic irrelevance on sets of desirable gambles. Annals of Mathematics
and Artificial Intelligence, 45, 197–214.
93

De Cooman, De Bock, & Diniz

Moral, S., & Wilson, N. (1995). Revision rules for convex sets of probabilities. In Coletti,
G., Dubois, D., & Scozzafava, R. (Eds.), Mathematical Models for Handling Partial
Knowledge in Artificial Intelligence, pp. 113–128. Plenum Press, New York.
Piatti, A., Zaffalon, M., Trojani, F., & Hutter, M. (2009). Limits of learning about a categorical
latent variable under prior near-ignorance. International Journal Of Approximate
Reasoning, 50 (4), 597–611.
Prautzsch, H., Boehm, W., & Paluszny, M. (2002). Bézier and B-Spline Techniques. Springer,
Berlin.
Quaeghebeur, E. (2014). Introduction to Imprecise Probabilities, chap. Desirability. John
Wiley & Sons.
Quaeghebeur, E., De Cooman, G., & Hermans, F. (2014). Accept & reject statement-based
uncertainty models. International Journal of Approximate Reasoning. Accepted for
publication.
Rouanet, H., & Lecoutre, B. (1983). Specific inference in ANOVA: From significance tests
to Bayesian procedures. British Journal of Mathematical and Statistical Psychology,
36 (2), 252–268.
Seidenfeld, T., Schervish, M. J., & Kadane, J. B. (1995). A representation of partially ordered
preferences. The Annals of Statistics, 23, 2168–2217. Reprinted in the collection by
Seidenfeld et al. (1999, pp. 69–129).
Seidenfeld, T., Schervish, M. J., & Kadane, J. B. (1999). Rethinking the Foundations of
Statistics. Cambridge University Press, Cambridge.
Sheffer, I. M. (1939). Some properties of polynomial sets of type zero. Duke Mathematical
Journal, 5, 590–622.
Smith, C. A. B. (1961). Consistency in statistical inference and decision. Journal of the
Royal Statistical Society, Series A, 23, 1–37.
Troffaes, M. C. M., & De Cooman, G. (2014). Lower Previsions. Wiley.
Trump, W., & Prautzsch, H. (1996). Arbitrary degree elevation of Bézier representations.
Computer Aided Geometric Design, 13, 387–398.
Walley, P. (1991). Statistical Reasoning with Imprecise Probabilities. Chapman and Hall,
London.
Walley, P. (1996). Inferences from multinomial data: learning about a bag of marbles. Journal
of the Royal Statistical Society, Series B, 58, 3–57. With discussion.
Walley, P. (1997). A bounded derivative model for prior ignorance about a real-valued
parameter. Scandinavian Journal of Statistics, 24 (4), 463–483.
Walley, P. (2000). Towards a unified theory of imprecise probability. International Journal
of Approximate Reasoning, 24, 125–148.
Walley, P., & Bernard, J.-M. (1999). Imprecise probabilistic prediction for categorical data.
Tech. rep. CAF-9901, Laboratoire Cognition et Activitées Finalisées, Université de
Paris 8.
94

Coherent Predictive Inference under Exchangeability

Williams, P. M. (1975a). Coherence, strict coherence and zero probabilities. In Proceedings
of the Fifth International Congress on Logic, Methodology and Philosophy of Science,
Vol. VI, pp. 29–33. Dordrecht. Proceedings of a 1974 conference held in Warsaw.
Williams, P. M. (1975b). Notes on conditional previsions. Tech. rep., School of Mathematical
and Physical Science, University of Sussex, UK. See also the revised journal version by
Williams (2007).
Williams, P. M. (1976). Indeterminate probabilities. In Przelecki, M., Szaniawski, K., &
Wojcicki, R. (Eds.), Formal Methods in the Methodology of Empirical Sciences, pp.
229–246. Reidel, Dordrecht. Proceedings of a 1974 conference held in Warsaw.
Williams, P. M. (2007). Notes on conditional previsions. International Journal of Approximate
Reasoning, 44, 366–383.
Zabell, S. L. (1982). W. E. Johnson’s “sufficientness” postulate. The Annals of Statistics, 10,
1090–1099. Reprinted in the collection by Zabell (2005).
Zabell, S. L. (2005). Symmetry and Its Discontents: Essays on the History of Inductive Probability. Cambridge Studies in Probability, Induction, and Decision Theory. Cambridge
University Press, Cambridge, UK.
Zaffalon, M., & Miranda, E. (2013). Probability and time. Artificial Intelligence, 198, 1–51.

95

Journal of Artificial Intelligence Research 52 (2015) 399–443

Submitted 08/14; published 03/15

Computing Convex Coverage Sets
for Faster Multi-objective Coordination
Diederik M. Roijers
Shimon Whiteson
Frans A. Oliehoek

d.m.roijers@uva.nl
s.a.whiteson@uva.nl
f.a.oliehoek@uva.nl

Informatics Institute
University of Amsterdam
Amsterdam, The Netherlands

Abstract
In this article, we propose new algorithms for multi-objective coordination graphs (MOCoGs). Key to the efficiency of these algorithms is that they compute a convex coverage
set (CCS) instead of a Pareto coverage set (PCS). Not only is a CCS a sufficient solution
set for a large class of problems, it also has important characteristics that facilitate more
efficient solutions. We propose two main algorithms for computing a CCS in MO-CoGs.
Convex multi-objective variable elimination (CMOVE) computes a CCS by performing a
series of agent eliminations, which can be seen as solving a series of local multi-objective
subproblems. Variable elimination linear support (VELS) iteratively identifies the single
weight vector w that can lead to the maximal possible improvement on a partial CCS
and calls variable elimination to solve a scalarized instance of the problem for w. VELS
is faster than CMOVE for small and medium numbers of objectives and can compute
an ε-approximate CCS in a fraction of the runtime. In addition, we propose variants of
these methods that employ AND/OR tree search instead of variable elimination to achieve
memory efficiency. We analyze the runtime and space complexities of these methods, prove
their correctness, and compare them empirically against a naive baseline and an existing
PCS method, both in terms of memory-usage and runtime. Our results show that, by
focusing on the CCS, these methods achieve much better scalability in the number of
agents than the current state of the art.

1. Introduction
In many real-world problem domains, such as maintenance planning (Scharpff, Spaan,
Volker, & De Weerdt, 2013) and traffic light control (Pham et al., 2013), multiple agents
need to coordinate their actions in order to maximize a common utility. Key to coordinating
efficiently in these domains is exploiting loose couplings between agents (Guestrin, Koller,
& Parr, 2002; Kok & Vlassis, 2004): each agent’s actions directly affect only a subset of the
other agents.
Multi-agent coordination is complicated by the fact that, in many domains, agents need
to balance multiple objectives (Roijers, Vamplew, Whiteson, & Dazeley, 2013a). For example, agents might have to maximize the performance of a computer network while minimizing
power consumption (Tesauro, Das, Chan, Kephart, Lefurgy, Levine, & Rawson, 2007), or
maximize the cost efficiency of maintenance tasks on a road network while minimizing traffic
delays (Roijers, Scharpff, Spaan, Oliehoek, de Weerdt, & Whiteson, 2014).
c
2015
AI Access Foundation. All rights reserved.

Roijers, Whiteson, & Oliehoek

Figure 1: Mining company example.
However, the presence of multiple objectives does not per se necessitate the use of
specialized multi-objective solution methods. If the problem can be scalarized, i.e., the
utility function can be converted to a scalar utility function, the problem may be solvable
with existing single-objective methods. Such a conversion involves two steps (Roijers et al.,
2013a). The first step is to specify a scalarization function.
Definition 1. A scalarization function f , is a function that maps a multi-objective utility
of a solution a of a decision problem, u(a), to a scalar utility uw (a):
uw (a) = f (u(a), w),
where w is a weight vector that parameterizes f .
The second step is to define a single-objective version of the decision problem such that the
utility of each solution a equals the scalarized utility of the original problem uw (a).
Unfortunately, scalarizing the problem before solving it is not always possible because
w may not be known in advance. For example, consider a company that mines different
resources. In Figure 1, we depict the problem this company faces: in the morning one van
per village needs to transport workers from that village to a nearby mine, where various
resources will be mined. Different mines yield different quantities of resource per worker.
The market prices per resource vary through a stochastic process and every price change
can alter the optimal assignment of vans. The expected price variation increases with
the passage of time. To maximize performance, it is thus critical to act based on the latest
possible price information. Since computing the optimal van assignment takes time, redoing
this computation for every price change is highly undesirable.
In such settings, we need a multi-objective method that computes, in advance, an optimal solution for all possible prices, w. We call such a set a coverage set (CS). In many
cases, w is revealed before a solution must be executed, in which case that solution can
be automatically selected from the CS given w. In other cases, w is never made explicit
but instead a human is involved in the decision making and selects one solution from the
CS, perhaps on the basis of constraints or preferences that were too difficult to formalize in
the objectives themselves (Roijers et al., 2013a). In both cases, because the CS is typically
much smaller than the complete set of solutions, selecting the optimal joint action from the
CS is typically much easier than selecting it directly from the complete set of solutions.
400

Computing CCSs for Faster Multi-objective Coordination

In this article, we consider how multi-objective methods can be made efficient for problems that require the coordination of multiple, loosely coupled agents. In particular, we address multi-objective coordination graphs (MO-CoGs): one-shot multi-agent decision problems in which loose couplings are expressed using a graphical model. MO-CoGs form an
important class of decision problems. Not only can they be used to model a variety of realworld problems (Delle Fave, Stranders, Rogers, & Jennings, 2011; Marinescu, 2011; Rollón,
2008), but many sequential decision problems can be modeled as a series of MO-CoGs, as is
common in single-objective problems (Guestrin et al., 2002; Kok & Vlassis, 2004; Oliehoek,
Spaan, Dibangoye, & Amato, 2010).
Key to the efficiency of the MO-CoG methods we propose is that they compute a convex
coverage set (CCS) instead of a Pareto coverage set (PCS). The CCS is a subset of the
PCS that is a sufficient solution for any multi-objective problem with a linear scalarization
function. For example, in the mining company example of Figure 1, f is linear, since the
total revenue is simply the sum of the quantity of each resource mined times its price per
unit. However, even if f is nonlinear, if stochastic solutions are allowed, then a CCS is
again sufficient.1
The CCS has not previously been considered as a solution concept for MO-CoGs because
computing a CCS requires running linear programs, whilst computing a PCS requires only
pairwise comparisons of solutions. However, a key insight of this article2 is that, in loosely
coupled systems, CCSs are easier to compute than PCSs, for two reasons. First, the CCS is
a (typically much smaller) subset of the PCS. In loosely coupled settings, efficient methods
work by solving a series of local subproblems; focusing on the CCS can greatly reduce the size
of these subproblems. Second, focusing on the CCS makes solving a MO-CoG equivalent to
finding an optimal piecewise-linear and convex (PWLC) scalarized value function, for which
efficient techniques can be adapted. For these reasons, we argue that the CCS is often the
concept of choice for MO-CoGs.
We propose two approaches that exploit these insights to solve MO-CoGs more efficiently
than existing methods (Delle Fave et al., 2011; Dubus, Gonzales, & Perny, 2009; Marinescu,
Razak, & Wilson, 2012; Rollón & Larrosa, 2006). The first approach deals with the multiple
objectives on the level of individual agents, while the second deals with them on a global
level.
The first approach extends an algorithm by Rollón and Larrosa (2006) which we refer
to as Pareto multi-objective variable elimination (PMOVE) 3 , that computes local Pareto
sets at each agent elimination, to compute a CCS instead. We call the resulting algorithm
convex multi-objective variable elimination (CMOVE).
The second approach is a new abstract algorithm that we call optimistic linear support
(OLS) and is much faster for small and medium numbers of objectives. Furthermore, OLS
1. To be precise, in the case of stochastic strategies a CCS of deterministic strategies is always sufficient
(Vamplew, Dazeley, Barker, & Kelarev, 2009); in the case of deterministic strategies, linearity of the
scalarization function makes the CCS sufficient (Roijers et al., 2013a).
2. This article synthesizes and extends research already reported in two conference papers. Specifically,
the CMOVE algorithm (Section 4) was previously published at ADT (Roijers, Whiteson, & Oliehoek,
2013b) and the VELS algorithm (Section 5) at AAMAS (Roijers, Whiteson, & Oliehoek, 2014). The
memory-efficient methods for computing CCSs (Section 6) are a novel contribution of this article.
3. In the original article, this algorithm is called multi-objective bucket elimination (MOBE). However, we
use PMOVE to be consistent with the names of the other algorithms mentioned in this article.

401

Roijers, Whiteson, & Oliehoek

can be used to produce a bounded approximation of the CCS, an ε-CCS, if there is not
enough time to compute a full CCS. OLS is a generic method that employs single-objective
solvers as a subroutine. In this article, we consider two implementations of this subroutine.
Using variable elimination (VE) as a subroutine yields variable elimination linear support
(VELS), which is particularly fast for small and moderate numbers of objectives and is more
memory-efficient than CMOVE. However, when memory is highly limited, this reduction
in memory usage may not be enough. In such cases, using AND/OR search (Mateescu &
Dechter, 2005) instead of VE yields AND/OR tree search linear support (TSLS), which is
slower than VELS but much more memory efficient.
We prove the correctness of both CMOVE and OLS. We analyze the runtime and space
complexities of both methods and show that our methods have better guarantees than
PCS methods. We show CMOVE and OLS are complementary, i.e., various trade-offs exist
between them and their variants.
Furthermore, we demonstrate empirically, on both randomized and more realistic problems, that CMOVE and VELS scale much better than previous algorithms. We also empirically confirm the trade-offs between CMOVE and OLS. We show that OLS, when used as
a bounded approximation algorithm, can save additional orders of magnitude of runtime,
even for small ε. Finally, we show that, even when memory is highly limited, TSLS can
still solve large problems.
The rest of this article is structured as follows. First, we provide a formal definition
of our model, as well as an overview of existing solution methods in Section 2. After
presenting a naive approach in Section 3, in Sections 4, 5 and 6, we analyze the runtime
and space complexities of each algorithm, and compare them empirically, against each other
and existing algorithms, at the end of each section. Finally, we conclude in Section 7 with
an overview of our contributions and findings, and suggestions for future research.

2. Background
In this section, we formalize the multi-objective coordination graph (MO-CoG). Before doing
so however, we describe the single-objective version of this problem, the coordination graph
(CoG), of which the MO-CoG is an extension, and the variable elimination (VE) algorithm
for solving CoGs. The methods we present in Section 4 and 5 build on VE in different ways.
2.1 (Single-Objective) Coordination Graphs
A coordination graph (CoG) (Guestrin et al., 2002; Kok & Vlassis, 2004) is a tuple hD, A, Ui,
where
• D = {1, ..., n} is the set of n agents,
• A = Ai × ... × An is the joint action space: the Cartesian product of the finite action
spaces of all agents. A joint action is thus a tuple containing an action for each agent
a = ha1 , ..., an i, and

	
• U = u1 , ..., uρ is the set of ρ scalar local payoff functions, each of which has limited
scope, i.e., it depends on onlyPa subset of the agents. The total team payoff is the sum
of the local payoffs: u(a) = ρe=1 ue (ae ).
402

Computing CCSs for Faster Multi-objective Coordination

Figure 2: (a) A CoG with 3 agents and 2 local payoff functions (b) after eliminating agent 3 by
adding u3 (c) after eliminating agent 2 by adding u4 .

ȧ1
ā1

ȧ2
3.25
1.25

ā2
0
3.75

ȧ2
ā2

ȧ3
2.5
0

ā3
1.5
1

Table 1: The payoff matrices for u1 (a1 , a2 ) (left) and u2 (a2 , a3 ) (right). There are two possible
actions per agent, denoted by a dot (ȧ1 ) and a bar (ā1 ).

All agents share the payoff function u(a). We abuse the notation e to both index a local
payoff function ue and to denote the subset of agents in its scope; ae is thus a local joint
action, i.e., a joint action of this subset of agents.
The decomposition of u(a) into local payoff functions can be represented as a factor
graph (Bishop, 2006), a bipartite graph containing two types of vertices: agents (variables)
and local payoff functions (factors), with edges connecting local payoff functions to the
agents in their scope.
Figure 2a shows the factor graph of an example CoG in which the team payoff function
decomposes into two local payoff functions, each with two agents in scope:
u(a) =

ρ
X

ue (ae ) = u1 (a1 , a2 ) + u2 (a2 , a3 ).

e=1

The local payoff functions are defined in Table 1. The factor graph illustrates the loose
couplings that result from the decomposition into local payoff functions. In particular, each
agent’s choice of action directly depends only on those of its immediate neighbors, e.g., once
agent 1 knows agent 2’s action, it can choose its own action without considering agent 3.
2.2 Variable Elimination
We now discuss the variable elimination (VE) algorithm, on which several multi-objective
extensions (Rollón & Larrosa, 2006; Rollón, 2008) build, including our own CMOVE algorithm (Section 4). We also use VE as a subroutine in the OLS algorithm (Section 5).
VE exploits the loose couplings expressed by the local payoff functions to efficiently
compute the optimal joint action, i.e., the joint action maximizing u(a). First, in the forward
403

Roijers, Whiteson, & Oliehoek

pass, VE eliminates each of the agents in turn by computing the value of that agent’s best
response to every possible joint action of its neighbors. These values are used to construct a
new local payoff function that encodes the value of the best response and replaces the agent
and the payoff functions in which it participated. In the original algorithm, once all agents
are eliminated, a backward pass assembles the optimal joint action using the constructed
payoff functions. Here, we present a slight variant in which each payoff is ‘tagged’ with the
action that generates it, obviating the need for a backwards pass. While the two algorithms
are equivalent, this variant is more amenable to the multi-objective extension we present in
Section 4.
VE eliminates agents from the graph in a predetermined order. Algorithm 1 shows
pseudocode for the elimination of a single agent i. First, VE determines the set of local
payoff functions connected to i, Ui , and the neighboring agents of i, ni (lines 1-2).
Definition 2. The set of neighboring local payoff functions Ui of i is the set of all local
payoff functions that have agent i in scope.
Definition 3. The set of neighboring agents of i, ni , is the set of all agents that are in
scope of one or more of the local payoff functions in Ui .
Then, it constructs a new payoff function by computing the value of agent i’s best
response to each possible joint action ani of the agents in ni (lines 3-12). To do so, it
loops over all these joint actions Ani (line 4). For each ani , it loops over all the actions Ai
available to agent i (line 6). For each ai ∈ Ai , it computes the local payoff when agent i
responds to ani with ai (line 7). VE tags the total payoff with ai , the action that generates
it (line 8) in order to be able to retrieve the optimal joint action later. If there are already
tags present, VE appends ai to them; in this way, the entire joint action is incrementally
constructed. VE maintains the value of the best response by taking the maximum of these
payoffs (line 11). Finally, it eliminates the agent and all payoff functions in Ui and replaces
them with the newly constructed local payoff function (line 13).
Algorithm 1: elimVE(U, i)
1
2
3
4
5
6
7

Input: A CoG U, and an agent i
Ui ← set of local payoff functions involving i
ni ← set of neighboring agents of i
unew ← a new factor taking joint actions of ni , ani , as input
foreach ani ∈ Ani do
S←∅
foreach aX
i ∈ Ai do
v←
uj (ani , ai )
uj ∈Ui

8
9
10
11
12
13

tag v with ai
S ← S ∪ {v}
end
unew (ani ) ← max(S)
end
return (U \ Ui ) ∪ {unew }

404

Computing CCSs for Faster Multi-objective Coordination

Consider the example in Figure 2a and Table 1. The optimal payoff maximizes the sum
of the two payoff functions:
max u(a) = max u1 (a1 , a2 ) + u2 (a2 , a3 ).
a

a1 ,a2 ,a3

If VE eliminates agent 3 first, then it pushes the maximization over a3 inward such that
goes only over the local payoff functions involving agent 3, in this case just u2 :


1
2
max u(a) = max u (a1 , a2 ) + max u (a2 , a3 ) .
a

a1 ,a2

a3

VE solves the inner maximization and replaces it with a new local payoff function u3 that
depends only on agent 3’s neighbors, thereby eliminating agent 1:

max u(a) = max u1 (a1 , a2 ) + u3 (a2 ) ,
a

a1 ,a2

which leads to the new factor graph depicted in Figure 2b. The values of u3 (a2 ) are u3 (ȧ2 ) =
2.5, using ȧ3 , and u3 (ā2 ) = 1 using ā3 , as these are the optimal payoffs for the actions of
agent 2, given the payoffs shown in Table 1. Because we ultimately want the optimal joint
action, not just the optimal payoff, VE tags each payoff of u3 with the action of agent 3
that generates it, i.e., we can think of u3 (a2 ) as a (value, tag) pair. We denote such a pair
with parentheses and a subscript: u3 (ȧ2 ) = (2.5)ȧ3 , and u3 (ā2 ) = (1)ā3 .
VE next eliminates agent 2, yielding the factor graph shown in Figure 2c:


1
3
max u(a) = max max u (a1 , a2 ) + u (a2 ) = max u4 (a1 ).
a

a1

a2

a1

VE appends the new tags for agent 2 to the existing tags for agent 3, yielding the following
tagged payoff values: u4 (ȧ1 ) = maxa2 u1 (ȧ1 , a2 ) + u3 (a2 ) =(3.25)ȧ2 + (2.5)ȧ2 ȧ3 = (5.75)ȧ2 ȧ3
and u4 (ā1 ) = (3.75)ā2 + (1)ā2 ā3 = (4.75)ā2 ā3 . Finally, maximizing over a1 yields the optimal
payoff of (5.75)ȧ1 ȧ2 ȧ3 , with the optimal action contained in the tags.
The runtime complexity of VE is exponential, not in the number of agents, but only in
the induced width, which is often much less than the number of agents.
Theorem 1. The computational complexity of VE is O(n|Amax |w ) where |Amax | is the
maximal number of actions for a single agent and w is the induced width, i.e., the maximal
number of neighboring agents of an agent plus one (the agent itself ), at the moment when
it is eliminated (Guestrin et al., 2002).
Theorem 2. The space complexity of VE is O( n |Amax |w ).
This space complexity arises because, for every agent elimination, a new local payoff
function is created with O(|Amax |w ) fields (possible input actions). Since it is impossible
to tell a priori how many of these new local payoff functions exist at any given time during
the execution of VE, this need to be multiplied by the total number of new local payoff
functions created during a VE execution, which is n.
While VE is designed to minimize runtime4 other methods focus on memory efficiency
instead (Mateescu & Dechter, 2005). We discuss memory efficiency further in Section 6.1.
4. In fact, VE is proven to have the best runtime guarantees within a large class of algorithms (Rosenthal,
1977).

405

Roijers, Whiteson, & Oliehoek

ȧ1
ā1

ȧ2
(4,1)
(1,2)

ā2
(0,0)
(3,6)

ȧ2
ā2

ȧ3
(3,1)
(0,0)

ā3
(1,3)
(1,1)

Table 2: The two-dimensional payoff matrices for u1 (a1 , a2 ) (left) and u2 (a2 , a3 ) (right).
2.3 Multi-objective Coordination Graphs
A multi-objective coordination

	graph (MO-CoG) is a tuple hD, A, Ui in which D and A are
as before but, U = u1 , ..., uρ is now a set of ρ, d-dimensional local P
payoff functions. The
total team payoff is the sum of local vector-valued payoffs: u(a) = ρe=1 ue (ae ). We use
ui to indicate the value of the i-th objective. We denote the set of all possible joint action
values as V. Table 2 shows a two-dimensional MO-CoG with the same structure as the
single-objective example in Section 2.1, but with multi-objective payoffs.
The solution to a MO-CoG is a coverage set (CS) of joint actions a and associated values
u(a) that contains at least one optimal joint action for each possible parameter vector w
of the scalarization function f (Definition 1). A CS is a subset of the undominated set:
Definition 4. The undominated set (U) of a MO-CoG, is the set of all joint actions and
associated payoff values that are optimal for some w of the scalarization function f .

	
U (V) = u(a) : u(a)∈ V ∧ ∃w∀a0 uw (a) ≥ uw (a0 ) .
Because we care about having at least one optimal joint action for every w, rather than all
optimal joint actions, a lossless subset of U suffices:
Definition 5. A coverage set (CS), CS(V), is a subset of U , such that for each possible w,
there is at least one optimal solution in the CS, i.e.,
∀w∃a


u(a) ∈ CS(V) ∧ ∀a0 uw (a) ≥ uw (a0 ) .

Note that the CS is not necessarily unique. Typically we seek the smallest possible CS. For
convenience, we assume that payoff vectors in the CS contain both the values and associated
joint actions, as suggested by the tagging scheme described in Section 2.2.
Which payoff vectors from V should be in the CS depends on what we know about the
scalarization function f . A minimal assumption is that f is monotonically increasing, i.e.,
if the value for one objective ui , increases while all uj6=i stay constant, the scalarized value
u(a) cannot decrease. This assumption ensures that objectives are desirable, i.e., all else
being equal, having more of them is always better.
Definition 6. The Pareto front is the undominated set for arbitrary strictly monotonically
increasing scalarization functions f .

	
P F (V) = u(a) : u(a)∈ V ∧ ¬∃a0 u(a0 ) P u(a) ,
where P indicates Pareto dominance (P-dominance): greater or equal in all objectives and
strictly greater in at least one objective.
406

Computing CCSs for Faster Multi-objective Coordination

In order to have all optimal scalarized values, it is not necessary to compute the entire
PF. E.g., if two joint actions have equal payoffs we need to retain only one of those.
Definition 7. A Pareto coverage set (PCS), P CS(V) ⊆ P F (V), is a coverage set for
arbitrary strictly monotonically increasing scalarization functions f , i.e.,

∀a0 ∃a u(a) ∈ P CS(V) ∧ (u(a) P u(a0 ) ∨ u(a) = u(a0 )) .
Computing P-dominance requires only pairwise comparison of payoff vectors (Feng &
Zilberstein, 2004).5
A highly prevalent scenario is that, in addition to f being monotonically increasing,
we also know that it is linear, that is, the parameter vectors w are weights by which the
values of the individual objectives are multiplied, f = w · u(a). In the mining example from
Figure 1, resources are traded on an open market and all resources have a positive unit
price. In this case, the scalarization is a linear combination of the amount of each resource
mined, where the weights correspond to the price per unit of each resource. Many more
examples of linear scalarization functions exist in the literature, e.g., (Lizotte, Bowling, &
Murphy, 2010). Because we assume the linear scalarization is monotonically increasing, we
can represent it without loss of generality as a convex combination of the objectives: i.e.,
the weights are positive and sum to 1. In this case, only a convex coverage set (CCS) is
needed, which is a subset of the convex hull (CH) 6 :
Definition 8. The convex hull (CH) is the undominated set for linear non-decreasing
scalarizations f (u(a), w) = w · u(a):

	
CH(V) = u(a) : u(a)∈ V ∧ ∃w∀a0 w · u(a) ≥ w · u(a0 ) .
That is, the CH contains all solutions that attain the optimal value for at least one weight.
Vectors not in the CH are C-dominated. In contrast to P-domination, C-domination cannot
be tested for with pairwise comparisons because it can take two or more payoff vectors to
C-dominate a payoff vector. Note that the CH contains more solutions than needed to guarantee an optimal scalarized value value: it can contain multiple solutions that are optimal
for one specific weight. A lossless subset of the CH with respect to linear scalarizations is
called a convex coverage set (CCS), i.e., a CCS retains at least one u(a) that maximizes
the scalarized payoff, w · u(a), for every w:
Definition 9. A convex coverage set (CCS), CCS(V) ⊆ CH(V), is a CS for linear nondecreasing scalarizations, i.e.,

∀w∃a u(a) ∈ CCS(V) ∧ ∀a0 w · u(a) ≥ w · u(a0 ) .
Since linear non-decreasing functions are a specific type of monotonically increasing function, there is always a CCS that is a subset of the smallest possible PCS.
As previously mentioned, CSs like the PCS and CCS, may not be unique. For example,
if there are two joint actions with equal payoff vectors, we need at most one of them to
make a PCS or CCS.
5. P-dominance is often called pairwise dominance in the POMDP literature.
6. Note that the term convex hull is overloaded. In graphics, the convex hull is a superset of what we mean
by the convex hull in this article.

407

Roijers, Whiteson, & Oliehoek

Figure 3: The CCS (filled circles at left, and solid black lines at right) versus the PCS (filled circles
and squares at left, and both dashed and solid black lines at right) for twelve random
2-dimensional payoff vectors.

In practice, the PCS and the CCS are often equal to the PF and CH. However, the
algorithms proposed in this article are guaranteed to produce a PCS or a CCS, and not
necessarily the entire PF or the CH. Because PCSs and the CCSs are sufficient solutions in
terms of scalarized value, we say that these algorithms solve the MO-CoGs.
In Figure 3 (left) the values of joint actions, u(a), are represented as points in valuespace, for a two-objective MO-CoG. The joint action value A is in both the CCS and the
PCS. B, however, is in the PCS, but not the CCS, because there is no weight for which a
linear scalarization of B’s value would be optimal, as shown in Figure 3 (right), where the
scalarized value of the strategies are plotted as a function of the weight on the first objective
(w2 = 1 − w1 ). C is in neither the CCS nor the PCS: it is Pareto-dominated by A.
Many multi-objective methods, e.g., (Delle Fave et al., 2011; Dubus et al., 2009; Marinescu et al., 2012; Rollón, 2008) simply assume that the PCS is the appropriate solution
concept. However, we argue that the choice of CS depends on what one can assume about
how utility is defined with respect to the multiple objectives, i.e., which scalarization function is used to scalarize the vector-valued payoffs. We argue that in many situations the
scalarization function is linear, and that in such cases one should use the CCS.
In addition to the shape of f , the choice of solution concept depends on whether only
deterministic joint actions are considered or whether stochastic strategies are also permitted. A stochastic strategy π assigns a probabilityPto each joint action A → [0, 1]. The
probabilities for all joint actions together sum to 1, a∈A π(a) = 1. The value of a stochastic strategy is a linear
P combination of the value vectors of the joint actions of which it is
π
a mixture: u =
a∈A π(a)u(a). Therefore, the optimal values, for any monotonically
increasing f , lie on the convex upper surface spanned by the strategies in the CCS, as
indicated by the lines in Figure 3 (left). Therefore, all optimal values for monotonically
increasing f , including nonlinear ones, can be constructed by taking mixture policies from
the CCS (Vamplew et al., 2009).
This article considers methods for computing CCSs, which, as we show in Sections 4
and 5, can be computed more efficiently than PCSs. Furthermore, CCSs are typically much
408

Computing CCSs for Faster Multi-objective Coordination

smaller. This is particularly important when the final selection of the joint is done by (a
group of) humans, who have to compare all possible alternatives in the solution set.
The methods presented in this article are based on variable elimination (VE) (Sections
4 and 5) and AND/OR tree search (TS) (Section 6). These algorithms are exact solution
methods for CoGs.
The CMOVE algorithm we propose in Section 5 is based on VE. It differs from another
multi-objective algorithm based on VE, which we refer to as PMOVE (Rollón & Larrosa,
2006), in that it produces a CCS rather than a PCS. An alternative to VE are messagepassing algorithms, like max-plus (Pearl, 1988; Kok & Vlassis, 2006a). However, these are
guaranteed to be exact only for tree-structured CoGs. Multi-objective methods that build
on max-plus such as that of Delle Fave et al. (2011), have this same limitation, unless
they preprocess the CoG to form a clique-tree or GAI network (Dubus et al., 2009). On
tree structured graphs, both message-passing algorithms and VE produce optimal solutions
with similar runtime guarantees. Note that, like PMOVE, existing multi-objective methods
based on message passing produce a PCS rather than a CCS.
In Section 5, we take a different approach to multi-objective coordination based on an
outer loop approach. As we explain, this approach is applicable only for computing a CCS,
not a PCS, but has considerable advantages in terms of runtime and memory usage.

3. Non-graphical Approach
A naive way to compute a CCS is to ignore the graphical structure, calculate the set of all
possible payoffs for all joint actions V, and prune away the C-dominated joint actions. We
first translate the problem to a set of value set factors (VSFs), F. Each VSF f is a function
mapping local joint actions to sets of payoff vectors. The initial VSFs are constructed from
the local payoff functions such that
f e (ae ) = {ue (ae )},
i.e., each VSF maps a local joint action to the singleton set containing only that action’s
local payoff. We can now define V in terms of F using the cross-sum operator over all VSFs
in F for each joint action a:
[M
V(F) =
f e (ae ),
a f e ∈F

where the cross-sum of two sets A and B contains all possible vectors that can be made by
summing one payoff vector from each set:
A ⊕ B = {a + b : a ∈ A ∧ b ∈ B} .
The CCS can now be calculated by applying a pruning operator CPrune (described below)
that removes all C-dominated vectors from a set of value vectors, to V:
[M
CCS(V(F)) = CPrune(V(F)) = CPrune(
f e (ae )).
(1)
a f e ∈F

The non-graphical CCS algorithm simply computes the righthand side of Equation 1, i.e.,
it computes V(F) explicitly by looping over all actions, and for each action looping over all
local VSFs, and then pruning that set down to a CCS.
409

Roijers, Whiteson, & Oliehoek

A CCS contains at least one payoff vector that maximizes the scalarized value for every
w:
∀w



a = arg max w · u(a)



=⇒ ∃a0

u(a0 ) ∈ CCS(V(F)) ∧ w · u(a) = w · u(a0 ). (2)

a∈A

That is, for every w there is an solution a0 that is part of the CCS and that achieves the
same value as a maximizing solution a. Moreover the value of such solutions is given by the
dot product. Thus, finding the CCS is analogous to the problem faced in partially observable
Markov decision processes (POMDPs) (Feng & Zilberstein, 2004), where optimal α-vectors
(corresponding to the value vectors u(a)) for all beliefs (corresponding to the weight vectors
w) must be found. Therefore, we can employ pruning operators from POMDP literature.
Algorithm 2 describes our implementation of CPrune, which is based on that of Feng and
Zilberstein (2004) with one modification. In order to improve runtime guarantees, CPrune
first pre-prunes the candidate solutions U to a PCS using the PPrune (Algorithm 3) at line
1. PPrune computes a PCS in O(d|U||P CS|) by running pairwise comparisons. Next, a
partial CCS, U ∗, is constructed as follows: a random vector u from U is selected at line 4.
For u the algorithm tries to find a weight vector w for which u is better than the vectors
in U ∗ (line 5), by solving the linear program in Algorithm 4. If there is such a w, CPrune
finds the best vector v for w in U and moves it to U ∗ (line 11–13). If there is no weight for
which u is better it is C-dominated and thus removed u from U (line 8).
Algorithm 2: CPrune(U)
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16

Input: A set of payoff vectors U
U ← PPrune(U)
U∗ ← ∅
while notEmpty(U) do
select random u from U
w ← findWeight(u, U ∗ )
if w=null then
//did not find a weight where u is optimal
remove u from U
end
else
v ← arg maxu∈U w · u
U ← U \ {v}
U ∗ ← U ∗ ∪ {v}
end
end
return U ∗

The runtime of CPrune as defined by Algorithm 2 is
O(d|U||P CS| + |P CS|P (d|CCS|)),

(3)

where P (d|CCS|) is a polynomial in the size of the CCS and the number of objectives d,
which is the runtime of the linear program that tests for C-domination (Algorithm 4).
410

Computing CCSs for Faster Multi-objective Coordination

Algorithm 3: PPrune(U)
1
2
3
4
5
6
7
8
9
10
11
12

Input: A set of payoff vectors U
U∗ ← ∅
while U 6= ∅ do
u ← the first element of U
foreach v ∈ U do
if v P u then
u ← v // Continue with v instead of u
end
end
Remove u, and all vectors P-dominated by u, from U
Add u to U ∗
end
return U ∗

Algorithm 4: findWeight(u, U)
max x
x,w

subject to w · (u − u0 ) − x ≥ 0, ∀u0 ∈ U
d
X

wi = 1

i=1

if x > 0 return w else return null

The key downside of the non-graphical approach is that it requires explicitly enumerating
all possible joint actions and calculating the payoffs associated with each one. Consequently,
it is intractable for all but small numbers of agents, as the number of joint actions grows
exponentially in the number of agents.
Theorem 3. The time complexity of computing a CCS of a MO-CoG containing ρ local
payoff functions, following the non-graphical approach (Equation 1) is:
O(dρ|Amax |n + d|Amax |n |P CS| + |P CS|P (d|CCS|)
Proof. First, V is computed by looping over all ρ VSFs for each joint action a, summing
vectors of length d. If the maximum size of the action space of an agent is Amax there are
O(|Amax |n ) joint actions. V contains one payoff vector for each joint action. V is the input
of CPrune.
In the next two sections, we present two approaches to compute CCSs more efficiently.
The first approach pushed the CPrune operator in Equation 1 into the cross-sum and
union, just as the max-operator is pushed into the summation in VE. We call this the
inner loop approach, as it uses pruning operators during agent eliminations, which is the
inner loop of the VE algorithm. The second approach is inspired by linear support (Cheng,
411

Roijers, Whiteson, & Oliehoek

1988), a POMDP pruning operator that only requires finding the optimal solution for certain w. Instead of performing maximization over the entire set V, as in the original linear
support algorithm, we show that we can use VE on a finite number of scalarized instances
of the MO-CoG, avoiding explicit calculation of V. We call this approach the outer loop
approach, as this it creates an outer loop around a single objective method (like VE), which
it calls as a subroutine.

4. Convex Variable Elimination for MO-CoGs
In this section we show how to exploit loose couplings and calculate a CCS using an inner loop approach, i.e., by pushing the pruning operators into the cross-sum and union
operators of Equation 1. The result is CMOVE, an extension to Rollón and Larrosa’s
Pareto-based extension of VE, which we refer to as PMOVE (Rollón & Larrosa, 2006).
By analyzing CMOVE’s complexity in terms of local convex coverage sets, we show that
this approach yields much better runtime complexity guarantees than the non-graphical
approach to computing CCSs that was presented in Section 3.
4.1 Exploiting Loose Couplings in the Inner Loop
In the non-graphical approach, computing a CCS is more expensive than computing a PCS,
as we have shown in Section 3. We now show that, in MO-CoGs, we can compute a CCS
much more efficiently by exploiting the MO-CoG’s graphical structure. In particular, like in
VE, we can solve the MO-CoG as a series of local subproblems, by eliminating agents and
manipulating the set of VSFs F which describe the MO-CoG. The key idea is to compute
local CCSs (LCCSs) when eliminating an agent instead of a single best response (as in VE).
When computing an LCCS, the algorithm prunes away as many vectors as possible. This
minimizes the number of payoff vectors that are calculated at the global level, which can
greatly reduce computation time. Here we describe the elim operator for eliminating agents
used by CMOVE in Section 4.2.
We first need to update our definition of neighboring local payoff functions (Definition
2), to neighboring VSFs.
Definition 10. The set of neighboring VSFs Fi of i is the set of all local payoff functions
that have agent i in scope.
The neighboring agents ni of an agent i are now the agents in the scope of a VSF in
Fi , except for i itself, corresponding to Definition 3. For each possible local joint action of
ni , we now compute an LCCS that contains the payoffs of the C-undominated responses of
agent i, as the best response values of i. In other words, it is the CCS of the subproblem that
arises when considering only Fi and fixing a specific local joint action ani . To compute the
LCCS, we must consider all payoff vectors of the subproblem, Vi , and prune the dominated
ones.
Definition 11. If we fix all actions
in ani , but not ai , the set of all payoff vectors for
S L
this subproblem is: Vi (Fi , ani ) = ai f e ∈Fi f e (ae ), where ae is formed from ai and the
appropriate part of ani .
Using Definition 11, we can now define the LCCS as the CCS of Vi .
412

Computing CCSs for Faster Multi-objective Coordination

Definition 12. A local CCS, an LCCS, is the C-undominated subset of Vi (Fi , ani ):
LCCSi (Fi , ani ) = CCS(Vi (Fi , ani )).

Using these LCCSs, we can create a new VSF, f new , conditioned on the actions of the
agents in ni :
∀ani f new (ani ) = LCCS i (Fi , ani ).
The elim operator replaces the VSFs in Fi in F by this new factor:
elim(F, i) = (F \ Fi ) ∪ {f new (ani )}.
Theorem 4. elim preserves the CCS: ∀i ∀F CCS(V(F)) = CCS(V(elim(F, i))).
Proof. We show this by using the implication of Equation 2, i.e., for all joint actions a for
which there is a w at which the scalarized value of a is maximal, a vector-valued payoff
u(a0 ) for which w · u(a0 ) = w · u(a0 ) is in the CCS. We show that the maximal scalarized
payoff cannot be lost as a result of elim.
The
function distributes over the local payoff functions: w · u(a) =
P linear scalarization
P
w · e ue (ae ) = e w · ue (ae ). Thus, when eliminating agent i, we divide the set of VSFs
into non-neighbors (nn), in which agent i does not participate, and neighbors (ni ) such
that:
X
X
w · u(a) =
w · ue (ae ) +
w · ue (ae ).
e∈nn

e∈ni

Now, following Equation 2, the CCS contains maxa∈A w · u(a) for all w. elim pushes this
maximization in:
max w · u(a) = max
a∈A

a−i ∈A−i

X

w · ue (ae ) + max

ai ∈Ai

e∈nn

X

w · ue (ae ).

e∈ni

elim
the agent-i factors by a term f new (ani ) that satisfies w · f new (ani ) = maxai
P replaces
e
e∈ni w · u (ae ) per definition, thus preserving the maximum scalarized value for all w and
thereby preserving the CCS.
Instead of an LCCS, we could compute a local PCS (LPCS), that is, using a PCS
computation on Vi instead of a CCS computation. Note that, since LCCS ⊆ LPCS ⊆ Vi ,
elim not only reduces the problem size with respect to Vi , it can do so more than would
be possible if we only considered P-dominance. Therefore, focusing on the CCS can greatly
reduce the sizes of local subproblems. Since the solution of a local subproblem is the input
for the next agent elimination, the size of subsequent local subproblems is also reduced,
which can lead to considerable speed-ups.
413

Roijers, Whiteson, & Oliehoek

4.2 Convex Multi-objective Variable Elimination
We now present the convex multi-objective variable elimination (CMOVE) algorithm, which
implements elim using CPrune. Like VE, CMOVE iteratively eliminates agents until none
are left. However, our implementation of elim computes a CCS and outputs the correct
joint actions for each payoff vector in this CCS, rather than a single joint action. CMOVE
is an extension to Rollón and Larrosa’s Pareto-based extension of VE, which we refer to as
PMOVE (Rollón & Larrosa, 2006).
The most important difference between CMOVE and PMOVE is that CMOVE computes a CCS, which typically leads to much smaller subproblems and thus much better
computational efficiency. In addition, we identify three places where pruning can take
place, yielding a more flexible algorithm with different trade-offs. Finally, we use the tagging scheme instead of the backwards pass, as in Section 2.2.
Algorithm 5 presents an abstract version of CMOVE that leaves the pruning operators
unspecified. As in Section 3, CMOVE first translates the problem into a set of vector-set
factors (VSFs), F on line 1. Next, CMOVE iteratively eliminates agents using elim (line
2–5). The elimination order can be determined using techniques devised for single-objective
VE (Koller & Friedman, 2009).
Algorithm 5: CMOVE(U, prune1, prune2, prune3, q)

1
2
3
4
5
6
7
8

Input: A set of local payoff functions U and an elimination order q (a queue containing all
agents)
F ← create one VSF for every local payoff function in U
while ani ∈ Ani do
i ← q.dequeue()
F ← elim(F, i, prune1, prune2)
end
f ← retrieve final factor from F
S ← f (a∅ )
return prune3(S)

Algorithm 6 shows our implementation of elim, parameterized with two pruning operators, prune1 and prune2, corresponding to two different pruning locations inside the
operator that computes LCCSi : ComputeLCCSi (Fi , ani , prune1, prune2).
Algorithm 6: elim(F, i, prune1, prune2)
1
2
3
4
5
6
7
8

Input: A set of VSFs F, and an agent i
ni ← the set of neighboring agents of i
Fi ← the subset of VSF that have i in scope
f new (ani ) ← a new VSF
foreach ani ∈ Ani do
f new (ani ) ← ComputeLCCS i (Fi , ani , prune1, prune2)
end
F ← F \ Fi ∪ {f new }
return F

414

Computing CCSs for Faster Multi-objective Coordination

ComputeLCCSi is implemented as follows: first we define a new cross-sum-and-prune
ˆ = prune1(A ⊕ B). LCCSi applies this operator sequentially:
operator A⊕B
[M
ˆ
f e (ae )).
(4)
ComputeLCCSi (Fi , ani , prune1, prune2) = prune2(
e
ai

f ∈Fi

ˆ operator, leading to incremental
prune1 is applied to each cross-sum of two sets, via the ⊕
pruning (Cassandra, Littman, & Zhang, 1997). prune2 is applied at a coarser level, after
the union. CMOVE applies elim iteratively until no agents remain, resulting in a CCS.
Note that, when there are no agents left, f new on line 3 has no agents to condition on. In
this case, we consider the “actions of the neighbors” to be a single empty action: a∅ .
Pruning can also be applied at the very end, after all agents have been eliminated,
which we call prune3. In increasing level of coarseness, we thus have three pruning operators: incremental pruning (prune1), pruning after the union over actions of the eliminated
agent (prune2), and pruning after all agents have been eliminated (prune3), as reflected in
Algorithm 5. After all agents have been eliminated, the final factor is taken from the set
of factors (line 6), and the single set, S contained in that factor is retrieved (line 7). Note
that we use the empty action a∅ to denote the field in the final factor, as it has no agents
in scope. Finally prune3 is called on S.
Consider the example in Figure 2a, using the payoffs defined by Table 2, and apply
CMOVE. First, CMOVE creates the VSFs f 1 and f 2 from u1 and u2 . To eliminate agent 3,
it creates a new VSF f 3 (a2 ) by computing the LCCSs for every a2 and tagging each element
of each set with the action of agent 3 that generates it. For ȧ2 , CMOVE first generates
the set {(3, 1)ȧ3 , (1, 3)ā3 }. Since both of these vectors are optimal for some w, neither is
removed by pruning and thus f 3 (ȧ2 ) = {(3, 1)ȧ3 , (1, 3)ā3 }. For ā2 , CMOVE first generates
{(0, 0)ȧ3 , (1, 1)ā3 }. CPrune determines that (0, 0)ȧ3 is dominated and consequently removes
it, yielding f 3 (ā2 ) = {(1, 1)ā3 }. CMOVE then adds f 3 to the graph and removes f 2 and
agent 3, yielding the factor graph shown in Figure 2b.
CMOVE then eliminates agent 2 by combining f 1 and f 3 to create f 4 . For f 4 (ȧ1 ),
CMOVE must calculate the LCCS of:
(f 1 (ȧ1 , ȧ2 ) ⊕ f 3 (ȧ2 )) ∪ (f 1 (ȧ1 , ā2 ) ⊕ f 3 (ā2 )).
The first cross sum yields {(7, 2)ȧ2 ȧ3 , (5, 4)ȧ2 ā3 } and the second yields {(1, 1)ā2 ā3 }. Pruning
their union yields f 4 (ȧ1 ) = {(7, 2)ȧ2 ȧ3 , (5, 4)ȧ2 ā3 }. Similarly, for ā1 taking the union yields
{(4, 3)ȧ2 ȧ3 , (2, 5)ȧ2 ā3 , (4, 7)ā2 ā3 }, of which the LCCS is f 4 (ā1 ) = {(4, 7)ā2 ā3 }. Adding f 4
results in the graph in Figure 2c.
Finally, CMOVE eliminates agent 1. Since there are no neighboring agents left, Ai
contains only the empty action. CMOVE takes the union of f 4 (ȧ1 ) and f 4 (ā1 ). Since
(7, 2){ȧ1 ȧ2 ȧ3 } and (4, 7){ā1 ā2 ā3 } dominate (5, 4){ȧ1 ȧ2 ā3 } , the latter is pruned, leaving CCS =
{(7, 2){ȧ1 ȧ2 ȧ3 } , (4, 7){ā1 ā2 ā3 } }.
4.3 CMOVE Variants
There are several ways to implement the pruning operators that lead to correct instantiations of CMOVE. Both PPrune (Algorithm 2) and CPrune (Algorithm 1) can be used, as
long as either prune2 or prune3 is CPrune. Note that if prune2 computes the CCS, prune3
is not necessary.
415

Roijers, Whiteson, & Oliehoek

In this article, we consider Basic CMOVE, which does not use prune1 and prune3 and
only prunes at prune2 using CPrune, as well as Incremental CMOVE, which uses CPrune at
both prune1 and prune2. The latter invests more effort in intermediate pruning, which can
result in smaller cross-sums, and a resulting speedup. However, when only a few vectors
can be pruned in these intermediate steps, this additional speedup may not occur, and
the algorithm creates unnecessary overhead.7 We empirically investigate these variants in
Section 4.5
One could also consider using pruning operators that contain prior knowledge about
the range of possible weight vectors. If such information is available, it could be easily
incorporated by changing the pruning operators accordingly, leading to even smaller LCCSs,
and thus a faster algorithm. In this article however, we focus on the case in which such
prior knowledge is not available.
4.4 Analysis
We now analyze the correctness and complexity of CMOVE.
Theorem 5. MOVE correctly computes a CCS.
Proof. The proof works by induction on the number of agents. The base case is the original
MO-CoG, where each f e (ae ) from F is a singleton set. Then, since elim preserves the CCS
(see Theorem 1), no necessary vectors are lost. When the last agent is eliminated, only
one factor remains; since it is not conditioned on any agent actions and is the result of an
LCCS computation, it must contain one set: the CCS.
Theorem 6. The computational complexity of CMOVE is
O( n |Amax |wa (wf R1 + R2 ) + R3 ),

(5)

where wa is the induced agent width, i.e., the maximum number of neighboring agents (connected via factors) of an agent when eliminated, wf is the induced factor width, i.e., the
maximum number of neighboring factors of an agent when eliminated, and R1 , R2 and R3
are the cost of applying the prune1, prune2 and prune3 operators.
Proof. CMOVE eliminates n agents and for each one computes an LCCS for each joint
action of the eliminated agent’s neighbors, in a field in a new VSF. CMOVE computes
O(|Amax |wa ) fields per iteration, calling prune1 (Equation 4) for each adjacent factor, and
prune2 once after taking the union over actions of the eliminated agent. prune3 is called
exactly once, after eliminating all agents (line 8 of Algorithm 5).
Unlike the non-graphical approach, CMOVE is exponential only in wa , not the number
of agents. In this respect, our results are similar to those for PMOVE (Rollón, 2008).
However, those earlier complexity results do not make the effect of pruning explicit. Instead,
the complexity bound makes use of additional problem constraints, which limit the total
number of possible different value vectors. Specifically, in the analysis of PMOVE, the
payoff vectors are integer-valued, with a maximum value for all objectives. In practice,
7. We can also compute a PCS first, using prune1 and prune2, and then compute the CCS with prune3.
However, this is useful only for small problems for which a PCS is cheaper to compute than a CCS.

416

Computing CCSs for Faster Multi-objective Coordination

such bounds can be very loose or even impossible to define (e.g., when the payoff values
are real-valued in one or more objectives). Therefore, we instead give a description of
the computational complexity that makes explicit the dependence on the effectiveness of
pruning. Even though such complexity bounds are not better in the worst case (i.e., when
no pruning is possible), they allow greater insight into the runtimes of the algorithms we
evaluate, as is apparent in our analysis of the experimental results in Section 4.5.
Theorem 6 demonstrates that the complexity of CMOVE depends heavily on the runtime
of its pruning operators, which in turn depends on the sizes of the input sets. The input
set of prune2 is the union of what is returned by a series of applications of prune1, while
prune3 uses the output of the last application of prune2. We therefore need to balance
the effort of the lower-level pruning with that of the higher-level pruning, which occurs less
often but is dependent on the output of the lower level. The bigger the LCCSs, the more
can be gained from lower-level pruning.
Theorem 7. The space complexity of CMOVE is
O( d n |Amax |wa |LCCSmax | + d ρ |Amax ||emax | ),
where |LCCSmax | is maximum size of a local CCS, ρ is the original number of VSFs, and
|emax | is the maximum scope size of the original VSFs.
Proof. CMOVE computes a local CCS for each new VSF for each joint action of the eliminated agent’s neighbors. There are maximally wa neighbors. There are maximally n new
factors. Each payoff vector stores d real numbers.
There are ρ VSFs created during the initialization of CMOVE. All of these VSFs have
exactly one payoff vector containing d real numbers, per joint action of the agents in scope.
There are maximally |Amax ||emax | such joint actions.
For PMOVE, the space complexity is the same but with |P CCSmax | instead of |LCCSmax |.
Because the LCCS is a subset of the corresponding LPCS, CMOVE is thus strictly more
memory efficient than PMOVE.
Note that Theorem 7 is a rather loose upper bound on the space complexity, as not all
VSFs, original or new, exist at the same time. However, it is not possible to to predict
a priori how many of these VSFs exist at the same time, resulting in a space complexity
bound on the basis of all VSFs that exist at some point during the execution of CMOVE.
4.5 Empirical Evaluation
To test the efficiency of CMOVE, we now compare its runtimes to those of PMOVE8 and
the non-graphical approach for problems with varying numbers of agents and objectives.
We also analyze how these runtimes correspond to the sizes of the PCS and CCS.
We use two types of experiments. The first experiments are done with random MOCoGs in which we can directly control all variables. In the second experiment, we use
Mining Day, a more realistic benchmark, that is more structured than random MO-CoGs
but still randomized.
8. We compare to PMOVE using only prune2 = PPrune, rather than prune1 = prune2 = PPrune, as was
proposed in the original article (Rollón & Larrosa, 2006) because we found the former option slightly
but consistently faster.

417

Roijers, Whiteson, & Oliehoek

(a)

(b)

(c)

Figure 4: (a) Runtimes (ms) in log-scale for the nongraphical method, PMOVE and CMOVE with
standard deviation of mean (error bars), (b) the corresponding number of vectors in the
PCS and CCS, and (c) the corresponding spread of the induced width.

4.5.1 Random Graphs
To generate random MO-CoGs, we employ a procedure that takes as input: n, the number
of agents; d, the number of payoff dimensions; ρ the number of local payoff functions; and
|Ai |, the action space size of the agents, which is the same for all agents. The procedure
then starts with a fully connected graph with local payoff functions connecting to two agents
each. Then, local payoff functions are randomly removed, while ensuring that the graph
remains connected, until only ρ local payoff functions remain. The values for the different
objectives in each local payoff function are real numbers that are drawn independently and
uniformly from the interval [0, 10]. We compare algorithms on the same set of randomly
generated MO-CoGs for each separate value of n, d, ρ, and |Ai |.
To compare basic CMOVE, incremental CMOVE, PMOVE, and the non-graphical
method, we test them on random MO-CoGs with the number of agents ranging between
10 and 85, the average number of factors per agent held at ρ = 1.5n, and the number of
objectives d = 2. This experiment was run on a 2.4 GHz Intel Core i5 computer, with 4 GB
memory. Figure 4 shows the results, averaged over 20 MO-CoGs for each number of agents.
The runtime (Figure 4a) of the non-graphical method quickly explodes. Both CMOVE
variants are slower than PMOVE for small numbers of agents, but the runtime grows much
more slowly than that of PMOVE. At 70 agents, both CMOVE variants are faster than
PMOVE on average. For 75 agents, one of the MO-CoGs generated caused PMOVE to
time out at 5000s, while basic CMOVE had a maximum runtime of 132s, and incremental
CMOVE 136s. This can be explained by the differences in the size of the solutions, i.e.,
the PCS and the CCS (Figure 4b). The PCS grows much more quickly with the number of
agents than the CCS does. For two-objective problems, incremental CMOVE seems to be
consistently slower than basic CMOVE.
While CMOVE’s runtime grows much more slowly than that of the nongraphical method,
it is still exponential in the number of agents, a counterintuitive result since the worst-case
complexity is linear in the number of agents. This can be explained by the induced width
of the MO-CoGs, in which the runtime of CMOVE is exponential. In Figure 4c, we see that
the induced width increases linearly with the number of agents for random graphs.
418

Computing CCSs for Faster Multi-objective Coordination

Figure 5: Runtimes (ms) for the non-graphical method, PMOVE and CMOVE in log-scale with the
standard deviation of mean (error bars) (left) and the corresponding number of vectors
in the PCS and CCS (right), for increasing numbers of agents and 5 objectives.

We therefore conclude that, in two-objective MO-CoGs, the non-graphical method is
intractable, even for small numbers of agents, and that the runtime of CMOVE increases
much less with the number of agents than PMOVE does.
To test how the runtime behavior changes with a higher number of objectives, we run
the same experiment with the average number of factors per agent held at ρ = 1.5n and
increasing numbers of agents again, but now for d = 5. This and all remaining experiments
described in this section were executed on a Xeon L5520 2.26 GHz computer with 24 GB
memory. Figure 5 (left) shows the results of this experiment, averaged over 85 MO-CoGs
for each number of agents. Note that we do not plot the induced widths, as this does not
change with the number of objectives. These results demonstrate that, as the number of
agents grows, using CMOVE becomes key to containing the computational cost of solving
the MO-CoG. CMOVE outperforms the nongraphical method from 12 agents onwards. At
25 agents, basic CMOVE is 38 times faster. CMOVE also does significantly better than
PMOVE. Though it is one order of magnitude slower with 10 agents (238ms (basic) and
416ms (incremental) versus 33ms on average), its runtime grows much more slowly than
that of PMOVE. At 20 agents, both CMOVE variants are faster than PMOVE and at
28 agents, Basic CMOVE is almost one order of magnitude faster (228s versus 1, 650s on
average), and the difference increases with every agent.
As before, the runtime of CMOVE is exponential in the induced width, which increases
with the number of agents, from 3.1 at n = 10 to 6.0 at n = 30 on average, as a result of
the random MO-CoG generation procedure. However, CMOVE’s runtime is polynomial in
the size of the CCS, and this size grows exponentially, as shown in Figure 5 (right). The
fact that CMOVE is much faster than PMOVE can be explained by the sizes of the PCS
and CCS, as the former grows much faster than the latter. At 10 agents, the average PCS
size is 230 and the average CCS size is 65. At 30 agents, the average PCS size has risen to
51, 745 while the average CCS size is only 1, 575.
Figure 6 (left) compares the scalability of the algorithms in the number of objectives,
on random MO-CoGs with n = 20 and ρ = 30, averaged over 100 MO-CoGs. CMOVE
always outperforms the nongraphical method. Interestingly, the nongraphical method is
419

Roijers, Whiteson, & Oliehoek

Figure 6: Runtimes (ms) for the non-graphical method, PMOVE and CMOVE in logscale with the
standard deviation of mean (error bars) (left) and the corresponding number of vectors
in the PCS and CCS (right), for increasing numbers of objectives.

several orders of magnitude slower at d = 2, grows slowly until d = 5, and then starts to
grow with about the same exponent as PMOVE. This can be explained by the fact that the
time it takes to enumerate of all joint actions and payoffs remains approximately constant,
while the time it takes to prune increases exponentially with the number of objectives.
When d = 2, CMOVE is an order of magnitude slower than PMOVE (163ms (basic) and
377 (incremental) versus 30ms). However, when d = 5, both CMOVE variants are already
faster than PMOVE and at 8 dimensions they are respectively 3.2 and 2.4 times faster.
This happens because the CCS grows much more slowly than the PCS, as shown in Figure
6 (right). The difference between incremental and basic CMOVE decreases as the number
of dimensions increases, from a factor 2.3 at d = 2 to 1.3 at d = 8. This trend indicates
that pruning after every cross-sum, i.e., at prune1, becomes (relatively) better for higher
numbers of objectives. Although we were unable to solve problem instances with many more
objectives within reasonable time, we expect this trend to continue and that incremental
CMOVE would be faster than basic CMOVE for problems with very many objectives.
Overall, we conclude that, for random graphs, CMOVE is key to solving MO-CoGs
within reasonable time, especially when the problem size increases in either the number of
agents, the number of objectives, or both.
4.5.2 Mining Day
In Mining Day, a mining company mines gold and silver (objectives) from a set of mines
(local payoff functions) located in the mountains (see Figure 1). The mine workers live in
villages at the foot of the mountains. The company has one van in each village (agents)
for transporting workers and must determine every morning to which mine each van should
go (actions). However, vans can only travel to nearby mines (graph connectivity). Workers
are more efficient if there are more workers at the mine: there is a 3% efficiency bonus per
worker such that the amount of each resource mined per worker is x · 1.03w , where x is
the base rate per worker and w is the number of workers at the mine. The base rate of
gold and silver are properties of a mine. Since the company aims to maximize revenue, the
best strategy depends on the fluctuating prices of gold and silver. To maximize revenue,
420

Computing CCSs for Faster Multi-objective Coordination

Figure 7: Runtimes (ms) for basic and incremental CMOVE, and PMOVE, in log-scale with the
standard deviation of mean (error bars) (left) and the corresponding number of vectors
in the PCS and CCS (right), for increasing numbers of agents.

the mining company wants to use the latest possible price information, and not lose time
recomputing the optimal strategy with every price change. Therefore, we must calculate a
CCS.
To generate a Mining Day instance with v villages (agents), we randomly assign 2-5
workers to each village and connect it to 2-4 mines. Each village is only connected to mines
with a greater or equal index, i.e., if village i is connected to m mines, it is connected to
mines i to i + m − 1. The last village is connected to 4 mines and thus the number of mines
is v + 3. The base rates per worker for each resource at each mine are drawn uniformly and
independently from the interval [0, 10].
In order to compare the runtimes of basic and incremental CMOVE against PMOVE
on a more realistic benchmark, we generate Mining Day instances with varying numbers
of agents. Note that we do not include the non-graphical method, as its runtime mainly
depends on the number of agents, and is thus not considerably faster for this problem
than for random graphs. The runtime results are shown in Figure 7 (left). Both CMOVE
and PMOVE are able to tackle problems with over 100 agents. However, the runtime of
PMOVE grows much more quickly than that of CMOVE. In this two-objective setting,
basic CMOVE is better than incremental CMOVE. Basic CMOVE and PMOVE both have
runtimes of around 2.8s at 60 agents, but at 100 agents, basic CMOVE runs in about 5.9s
and PMOVE in 21s. Even though incremental CMOVE is worse than basic CMOVE, its
runtime still grows much more slowly than that of PMOVE, and it beats PMOVE when
there are many agents.
The difference between PMOVE and CMOVE results from the relationship between the
number of agents and the sizes of the CCS, which grows linearly, and the PCS, which grows
polynomially, as shown in Figure 7 (right). The induced width remains around 4 regardless
of the number of agents. These results demonstrate that, as the CCS grows more slowly
than the PCS with the number of agents, CMOVE can solve MO-CoGs more efficiently
than PMOVE as the number of agents increases.
421

Roijers, Whiteson, & Oliehoek

5. Linear Support for MO-CoGs
In this section, we present variable elimination linear support (VELS). VELS is a new
method for computing the CCS in MO-CoGs that has several advantages over CMOVE:
for moderate numbers of objectives, its runtime complexity is better; it is an anytime
algorithm, i.e., over time, VELS produces intermediate results which become better and
better approximations of the CCS and therefore, when provided with a maximum scalarized
error ε, VELS can compute an ε-optimal CCS.
Rather than dealing with the multiple objectives in the inner loop (like CMOVE), VELS
deals with them in the outer loop and employs VE as a subroutine. VELS thus builds the
CCS incrementally. With each iteration of its outer loop, VELS adds at most one new
vector to a partial CCS. To find this vector, VELS selects a single w (the one that offers
the maximal possible improvement), and passes that w to the inner loop. In the inner loop,
VELS uses VE (Section 2.2) to solve the single-objective coordination graph (CoG) that
results from scalarizing the MO-CoG using the w selected by the outer loop. The joint
action that is optimal for this CoG and its multi-objective payoff are then added to the
partial CCS.
The departure point for creating VELS is Cheng’s linear support (Cheng, 1988). Cheng’s
linear support was originally designed as a pruning algorithm for POMDPs. Unfortunately,
this algorithm is rarely used for POMDPs in practice, as its runtime is exponential in the
number of states. However, the number of states in a POMDP corresponds to the number
of objectives in a MO-CoG, and while realistic POMDPs typically have many states, many
MO-CoGs have only a handful of objectives. Therefore, for MO-CoGs, the scalability in the
number of agents is more important, making Cheng’s linear support an attractive starting
point for developing an efficient MO-CoG solution method.
Building on Cheng’s linear support, in Section 5.1 we create an abstract algorithm that
we call optimistic linear support (OLS), which builds up the CCS incrementally. Because
OLS takes an arbitrary single-objective problem solver as input, it can be seen as a generic
multi-objective method. We show that OLS chooses a w at each iteration such that, after
a finite number of iterations, no further improvements to the partial CCS can be made
and OLS can terminate. Furthermore, we bound the maximum scalarized error of the
intermediate results, so that they can be used as bounded approximations of the CCS.
Then, in Section 5.2, we instantiate OLS by using VE as its single-objective problem solver,
yielding VELS, an effective MO-CoG algorithm.
5.1 Optimistic Linear Support
OLS constructs the CCS incrementally, by adding vectors to an initially empty partial CCS :
Definition 13. A partial CCS, S, is a subset of the CCS, which is in turn a subset of V:
S ⊆ CCS ⊆ V.
We define the scalarized value function over S, corresponding to the convex upper surface
(shown in bold) in Figure 8b-d:
Definition 14. A scalarized value function over a partial CCS, S, is a function that takes
a weight vector w as input, and returns the maximal attainable scalarized value with any
422

Computing CCSs for Faster Multi-objective Coordination

(a)

(b)

(c)

(d)

Figure 8: (a) All possible payoff vectors for a 2-objective MO-CoG. (b) OLS finds two payoff
vectors at the extrema (red vertical lines), a new corner weight wc = (0.5, 0.5) is
found, with maximal possible improvement ∆. CCS is shown as the dotted line.
(c) OLS finds a new vector at (0.5, 0.5), and adds two new corner weights to Q.
(d) OLS calls SolveCoG for both corner weights (in two iterations), and finds no
new vectors, ensuring S = CCS = CCS.
payoff vector in S:
u∗S (w) = max w · u(a).
u(a)∈S

Similarly, we define the set of maximizing joint actions:
Definition 15. The optimal joint action set function with respect to S is a function that
gives the joint actions that maximize the scalarized value:
AS (w) = arg max w · u(a).
u(a)∈S

Note that AS (w) is a set because for some w there can be multiple joint actions that provide
the same scalarized value.
Using these definitions, we can describe optimistic linear support (OLS). OLS adds
vectors to a partial CCS, S, finding new vectors for so-called corner weights. These corner
weights are the weights where u∗S (w) (Definition 14) changes slope in all directions. These
must thus be weights where AS (w) (Definition 15) consists of multiple payoff vectors. Every
corner weight is prioritized by the maximal possible improvement of finding a new payoff
vector at that corner weight. When the maximal possible improvement is 0, OLS knows
that the partial CCS is complete. An example of this process is given in Figure 8, where
the (corner) weights where the algorithm has searched for new payoff vectors are indicated
by red vertical lines.
OLS is shown in Algorithm 7. To find the optimal payoff for a corner weight, OLS
assumes access to a function called SolveCoG that computes the best payoff vector for a
given w. For now, we leave the implementation of SolveCoG abstract. In Section 5.2, we
discuss how to implement SolveCoG. OLS also takes as input m, the MO-CoG to be solved,
and ε, the maximal tolerable error in the result.
We first describe how OLS is initialized (Section 5.1.1). Then, we define corner weights
formally and describe how OLS identifies them (Section 5.1.2). Finally, we describe how
423

Roijers, Whiteson, & Oliehoek

Algorithm 7: OLS(m, SolveCoG, ε)
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24

Input:
A CoGGCCS,
and an agent i to eliminate.
S
← ∅//partial
W ← ∅ //set of checked weights
Q ← an empty priority queue
foreach extremum of the weight simplex we do
Q.add(we , ∞) // add extrema with infinite priority
end
while ¬Q.isEmpty() ∧ ¬timeOut do
w ← Q.pop()
u ← SolveCoG(m, w)
if u 6∈ S then
Wdel ← remove the corner weights made obsolete by u from Q, and store them
Wdel ← {w} ∪ Wdel //corner weights which are removed because of adding u
Wu ← newCornerWeights(u, Wdel , S)
S ← S ∪ {u}
foreach w ∈ Wu do
∆r (w) ← calculate improvement using maxValueLP(w, S, W)
if ∆r (w) > ε then
Q.add(w, ∆r (w))
end
end
end
W ← W ∪ {w}
end
return S and the highest ∆r (w) left in Q

OLS prioritizes corner weights and how this can also be used to bound the error when
stopping OLS before it is done finding a full CCS (Section 5.1.3).
5.1.1 Initialization
OLS starts by initializing the partial CCS, S, which will contain the payoff vectors in the
CCS discovered so far (line 1 of Algorithm 7), as well as the set of visited weights W (line
2). Then, it adds the extrema of the weight simplex, i.e., those points where all of the
weight is on one objective, to a priority queue Q, with infinite priority (line 5).
These extrema are popped off the priority queue when OLS enters the main loop (line
7), in which the w with the highest priority is selected (line 8). SolveCoG is then called
with w (line 9) to find u, the best payoff vector for that w.
For example, Figure 8b shows S after two payoff vectors of a 2-dimensional MOCoG have been found by applying SolveCoG to the extrema of the weight simplex: S =
{(1, 8), (7, 2)}. Each of these vectors must be part of the CCS because it is optimal for
at least one w: the one for which SolveCoG returned it as a solution (the extrema of the
weight simplex). The set of weights W that OLS has tested so far are marked with vertical
red line segments.
424

Computing CCSs for Faster Multi-objective Coordination

5.1.2 Corner Weights
After having evaluated the extrema, S consists of d (the number of objectives) payoff vectors
and associated joint actions. However, for many weights on the simplex, it does not yet
contain the optimal payoff vector. Therefore, after identifying a new vector u to add to S
(line 9), OLS must determine what new weights to add to Q. Like Cheng’s linear support,
OLS does so by identifying the corner weights: the weights at the corners of the convex
upper surface, i.e., the points where the PWLC surface u∗S (w) changes slope. To define
the corner weights precisely, we must first define P , the polyhedral subspace of the weight
simplex that is above u∗S (w) (Bertsimas & Tsitsiklis, 1997). The corner weights are the
vertices of P, which can be defined by a set of linear inequalities:
Definition 16. If S is the set of known payoff vectors, we define a polyhedron
X
P = {x ∈ <d+1 : S + x ≥ ~0, ∀i, wi > 0,
wi = 1},
i

where S + is a matrix with the elements of S as row vectors, augmented by a column vector
of −1’s. The setPof linear inequalities S + x ≥ ~0, is supplemented by the simplex constraints:
∀i wi > 0 and i wi = 1. The vector x = (w1 , ..., wd , u) consists of a weight vector and
a scalarized value at those weights. The corner weights are the weights contained in the
vertices of P , which are also of the form (w1 , ..., wd , u).
Note that, due to the simplex constraints, P is only d-dimensional. Furthermore, the
extrema of the weight simplex are special cases of corner weights.
After identifying u, OLS identifies which corner weights change in the polyhedron P by
adding u to S. Fortunately, this does not require recomputation of all the corner weights,
but can be done incrementally: first, the corner weights in Q for which u yields a better
value than currently known are deleted from the queue (line 11) and then the function
newCornerWeights(u, Wdel , S) at line 13 calculates the new corner weights that involve u
by solving a system of linear equations to see where u intersects with the boundaries and
the relevant subset of the present vectors in S.
newCornerWeights(u, Wdel , S) (line 13) first calculates the set of all relevant payoff
vectors, Arel , by taking the union of all the maximizing vectors of the weights in Wdel 9 :
Arel =

[

AS (w).

w∈Wdel

If any AS (w) contains fewer than d payoff vectors, then a boundary of the weight simplex
is involved. These boundaries are also stored. All possible subsets of size d − 1 (of vectors
and boundaries) are taken. For each subset the weight where these d − 1 payoff vectors
(and/or boundaries) intersect with each other and u is computed by solving a system of
linear equations. The intersection weights for all subsets together form the set of candidate
corner weights: Wcan . newCornerWeights(u, Wdel , S) returns the subset of Wcan which are
inside of the weight simplex and for which u has a higher scalarized value than any payoff
9. In fact, in our implementation, we optimize this step by caching AS (w) for all w in Q.

425

Roijers, Whiteson, & Oliehoek

vector already in S. Figure 8b shows one new corner weight labelled wc = (0.5, 0.5). In
practice, |Arel | is very small, so only a few systems of linear equations need to be solved.10
After calculating the new corner weights Wu at line 13, u is added to S at line 14.
Cheng showed that finding the best payoff vector for each corner weight and adding it to
the partial CCS, i.e., S ← S ∪ {SolveCoG(w)}, guarantees the best improvement to S:
Theorem 8. (Cheng 1988) The maximum value of:
max

min w · u − w · v,

w,u∈CCS v∈S

i.e., the maximal improvement to S by adding a vector to it, is at one of the corner weights
(Cheng, 1988).
Theorem 8 guarantees the correctness of OLS: after all corner weights are checked, there
are no new payoff vectors; thus the maximal improvement must be 0 and OLS has found
the full CCS.
5.1.3 Prioritization
Cheng’s linear support assumes that all corner weights can be checked inexpensively, which
is a reasonable assumption in a POMDP setting. However, since SolveCoG is an expensive
operation, testing all corner weights may not be feasible in MO-CoGs. Therefore, unlike
Cheng’s linear support, OLS pops only one w off Q to be tested per iteration. Making
OLS efficient thus critically depends on giving each w a suitable priority when adding it
to Q. To this end, OLS prioritizes each corner weight w according to its maximal possible
improvement, an upper bound on the improvement in u∗S (w). This upper bound is computed
with respect to CCS, the optimistic hypothetical CCS, i.e., the best-case scenario for the
final CCS given that S is the current partial CCS and W is the set of weights already
tested with SolveCoG. The key advantage of OLS over Cheng’s linear support is that these
priorities can be computed without calling SolveCoG, obviating the need to run SolveCoG
on all corner weights.
Definition 17. An optimistic hypothetical CCS, CCS is a set of payoff vectors that yields
the highest possible scalarized value for all possible w consistent with finding the vectors S
at the weights in W.
Figure 8b denotes the CCS = {(1, 8), (7, 2), (7, 8)} with a dotted line. Note that CCS is a
superset of S and the value of u∗CCS (w) is the same as u∗S (w) at all the weights in W. For
∗
a given w, maxValueLP finds the the scalarized value of uCCS
(w) by solving:
max w · v
subject to W v ≤ u∗S,W ,
10. However, in theory it is possible to construct a partial CCS, S that has a corner weight for which all
payoff vectors in S are in Adel .

426

Computing CCSs for Faster Multi-objective Coordination

where u∗S,W is a vector containing u∗S (w0 ) for all w0 ∈ W. Note that we abuse the notation
W, which in this case is a matrix whose rows consist of all the weight vectors in the set
W.11
Using CCS, we can define the maximal possible improvement:
∆(w) = u∗CCS (w) − u∗S (w).
Figure 8b shows ∆(wc ) with a dashed line. We use the maximal relative possible improvement, ∆r (w) = ∆(w)/u∗CCS (w), as the priority of each new corner weight w ∈ Wu . In

Figure 8b, ∆r (wc )= (0.5,0.5)·((7,8)−(1,8))
= 0.4. When a corner weight w is identified (line 13),
7.5
it is added to Q with priority ∆r (w) as long as ∆r (w) > ε (lines 16-18).
After wc in Figure 8b is added to Q, it is popped off again (as it is the only element
of Q). SolveCoG(wc ) generates a new vector (5, 6), yielding S = {(1, 8), (7, 2), (5, 6)}, as
illustrated in Figure 8c. The new corner weights (0.667, 0.333) and (0.333, 0.667) are the
points at which (5, 6) intersects with (7, 2) and (1, 8). Testing these weights, as illustrated in
Figure 8d, does not result in new payoff vectors, causing OLS to terminate. The maximal
improvement at these corner weights is 0 and thus, due to Theorem 8, S = CCS upon
termination. OLS called solveCoG for only 5 weights resulting exactly in the 3 payoff
vectors of the CCS. The other 7 payoff vectors in V (displayed as grey and dashed black
lines in Figure 8a) were never generated.
5.2 Variable Elimination Linear Support
Any exact CoG algorithm can be used to implement SolveCoG. A naive approach is to
explicitly compute the values of all joint actions V and select the joint action that maximizes
this value:
SolveCoG(m, w) = arg max w · u(a).
u(a)∈V

This implementation of SolveCoG in combination with OLS yields an algorithm that we
refer to as non-graphical linear support (NGLS), because it ignores the graphical structure,
flattening the CoG into a standard multi-objective cooperative normal form game. The
main downside is that the computational complexity of SolveCoG is linear in |V| (which
is equal to |A|), which is exponential in the number of agents, making it feasible only for
MO-CoGs with very few agents.
By contrast, if we use VE (Section 2.2) to implement SolveCoG, we can do better. We
call the resulting algorithm variable elimination linear support (VELS). Having dealt with
the multiple objectives in the outer loop of OLS, VELS relies on VE to exploit the graphical
structure in the inner loop, yielding a much more efficient method than NGLS.
5.3 Analysis
We now analyze the computational complexity of VELS.
11. Our implementation of OLS reduces the size of the LP by using only the subset of weights in W for
which the joint actions involved in w, AS (w), have been found to be optimal. This can lead to a slight
∗
overestimation of uCCS
(w).

427

Roijers, Whiteson, & Oliehoek

Theorem 9. The runtime of VELS with ε = 0 is
O((|CCS| + |WCCS |)(n|Amax |w + Cnw + Cheur )),
where w is the induced width when running VE, |CCS| is the size of the CCS, |WCCS | is
the number of corner weights of u∗CCS (w), Cnw the time it costs to run newCornerWeights,
and Cheur the cost of the computation of the value of the optimistic CCS using maxValueLP.
Proof. Since n|Amax |w is the runtime of VE (Theorem 1), the runtime of VELS is this
quantity (plus the overhead per corner weight Cnw + Cheur ) multiplied by the number of
calls to VE. To count these calls, we consider two cases: calls to VE that result in adding
a new vector to S and those that do not result in a new vector but instead confirm the
optimality of the scalarized value at that weight. The former is the size of the final CCS,
|CCS|, while the latter is the number of corner weights for the final CCS, |WCCS |.
The overhead of OLS itself, i.e., computing new corner weights, Cnw , and calculating
the maximal relative improvement, Cheur , is very small compared to the SolveCoG calls.
In practice, newCornerWeights(u, Wdel , S) computes the solutions to only a small set of
linear equations (of d equations each). maxValueLP(w, S, W) computes the solutions to
linear programs, which is polynomial in the size of its inputs.12
For d = 2, the number of corner weights is smaller than |CCS| and the runtime of
VELS is thus O(n|Amax |w |CCS|). For d = 3, the number of corner weights is twice |CCS|
(minus a constant) because, when SolveCoG finds a new payoff vector, one corner weight is
removed and three new corner weights are added. For d > 3, a loose bound on |WCCS | is

the total number of possible combinations of d payoff vectors or boundaries: O( |CCS|+d
).
d
However, we can obtain a tighter bound by observing that counting the number of corner
weights given a CCS is equivalent to vertex enumeration, which is the dual problem of
facet enumeration, i.e., counting the number of vertices given the corner weights (Kaibel &
Pfetsch, 2003).
Theorem 10. For arbitrary d, |WCCS | is bounded by O(
(Avis & Devroye, 2000).

|CCS|−b d+1
c
2
|CCS|−d

+

|CCS|−b d+2
c
2
)
|CCS|−d

Proof. This result follows directly from McMullen’s upper bound theorem for facet enumeration (Henk, Richter-Gebert, & Ziegler, 1997; McMullen, 1970).
The same reasoning used to prove Theorems 9 can also be used to establish the following:
Corollary 1. The runtime of VELS with ε ≥ 0 is
O((|ε-CCS| + |Wε–CCS |)(n|Amax |w + Cnw + Cheur ), where |ε-CCS| is the size of the ε-CCS,
and |Wε–CCS | is the number of corner weights of u∗ε–CCS (w).
In practice, VELS will often not test all the corner weights of the polyhedron spanned
by the ε-CCS, but this cannot be guaranteed in general. In Section 5.4, we show empirically
that |ε-CCS| decreases rapidly as ε increases.
12. When the reduction in Footnote 11 is used, only a very small subset of W is used, making it even smaller.

428

Computing CCSs for Faster Multi-objective Coordination

Figure 9: (left) The runtimes of PMOVE, CMOVE and VELS with different values of ε,
for varying numbers of agents, n, and ρ = 1.5n factors, 2 actions per agent, and
2 objectives and (right) the corresponding sizes of the ε-CCSs.
Theorem 11. The space complexity of VELS is O(d|ε-CCS|+d|Wε–CCS |+n|Amax |w ) with
ε ≥ 0.
Proof. OLS needs to store every corner weight (a vector of length d) in the queue, which
is at most |Wε–CCS |. OLS also needs to store every vector in S (also vectors of length d).
Furthermore, when SolveCoG is called, the memory usage of VE is added to the memory
usage of the outer loop of OLS. The memory usage of VE is n|Amax |w (Theorem 2).
Because OLS adds few memory requirements to that of VE, VELS is almost as memory
efficient as VE and thus considerably more memory efficient than CMOVE (Theorem 7).
5.4 Empirical Evaluation
We now empirically evaluate VELS, in comparison to CMOVE and PMOVE. We no longer
compare against the non-graphical method as this is clearly dominated by CMOVE and
PMOVE. Where we refer to CMOVE in this section, we mean basic CMOVE, as this was
fastest for the tested scenarios. Like before, we use both random graphs and the Mining Day
benchmark. All experiments in this section were run on a 2.4 GHx Intel Core i5 computer,
with 4 GB memory.
5.4.1 Random Graphs
To test VELS on randomly generated MO-CoGs, we use the same MO-CoG generation
procedure as in Section 4. To determine how the scalability of exact and approximate
VELS compares to that of PMOVE and CMOVE, we tested them on random MO-CoGs
with increasing numbers of agents. The average number of factors per agent was held at
ρ = 1.5n and the number of objectives at d = 2. Figure 9 shows the results, which are
averaged over 30 MO-CoGs for each number of agents. Note that the runtimes on the left,
on the y-axis, are in log-scale but the set sizes on the right are not.
These results demonstrate that VELS is more efficient than CMOVE for two-objective
random MO-CoGs. The runtime of exact VELS (ε = 0) is on average 16 times less than
429

Roijers, Whiteson, & Oliehoek

that of CMOVE. CMOVE solves random MO-CoGs with 85 agents in 74s on average, whilst
exact VELS can handle 110 agents in 71s.
While this is already a large gain, we can achieve an even lower growth rate by permitting
a small ε. For 110 agents, permitting a 0.001 error margin yields a gain of more than an
order of magnitude, reducing the runtime to 5.7s. Permitting a 0.01 error reduces the
runtime to only 1.3s. We can thus reduce the runtime of VELS by a factor of 57, while
retaining 99% accuracy. Compared to CMOVE at 85 agents, VELS with ε = 0.01 is 109
times faster.
These speedups can be explained by the slower growth of the ε-CCS (Figure 9 (right)).
For small numbers of agents, the size of the ε-CCS grows only slightly more slowly than
the size of the full CCS. However, from a certain number of agents onwards, the size of the
ε-CCS grows only marginally while the size of the full CCS keeps on growing. For ε = 0.01,
the ε-CCS grew from 2.95 payoff vectors to 5.45 payoff vectors between 5 and 20 agents,
and then only marginally to 5.50 at 110 agents. By contrast, the full CCS grew from 3.00
to 9.90 vectors between 5 and 20 agents, but then keeps on growing to 44.50 at 110 agents.
A similar picture holds for the 0.001-CCS, which grows rapidly from 3.00 vectors at 5 to
14.75 vectors at 50 agents, then grows slowly to 16.00 at 90 agents, and then stabilizes, to
reach 16.30 vectors at 120 agents. Between 90 and 120 agents, the full CCS grows from
35.07 vectors to 45.40 vectors, making it almost 3 times as large as the 0.001-CCS and 9
times larger than the 0.01-CCS .
To test the scalability of VELS with respect to the number of objectives, we tested it
on random MO-CoGs with a constant number of agents and factors n = 25 and ρ = 1.5n,
but increased the number of objectives, for ε = 0 and ε = 0.1. We compare this to the
scalability of CMOVE. We kept the number of agents (n = 25) and the number of local
payoff functions (ρ = 37) small in order to test the limits of scalability in the number of
objectives. The number of actions per agent was 2. Figure 10 (left) plots the number of
objectives against the runtime (in log scale). Because the CCS grows exponentially with
the number of objectives (Figure 10 (right)), the runtime of CMOVE is also exponential in
the number of objectives. VELS however is linear in the number of corner weights, which is
exponential in the size of the CCS, making VELS doubly exponential. Exact VELS (ε = 0)
is faster than CMOVE for d = 2 and d = 3, and for d = 4 approximate VELS with ε = 0.1
is more than 20 times faster. However for d = 5 even approximate VELS with ε = 0.1 is
slower than CMOVE.
Unlike when the number of agents grows, the size of the ε-CCS (Figure 10 (right)) does
not stabilize when the number of objectives grows, as can be seen in the following table:
|ε–CCS|
d=2
d=3
d=4

ε=0
10.6
68.8
295.1

ε = 0.001
7.3
64.6
286.1

ε = 0.01
5.6
41.0
242.6

ε = 0.1
3.0
34.8
221.7

We therefore conclude that VELS can compute a CCS faster than CMOVE for 3 objectives
or less, but that CMOVE scales better in the number of objectives. VELS however, scales
better in the number of agents.
430

Computing CCSs for Faster Multi-objective Coordination

Figure 10: (left) the runtimes of CMOVE and VELS (ε = 0 and ε = 0.1), for varying numbers of objectives (right) the size of the ε-CCS for varying numbers of objectives.

Figure 11: (left) plot of the runtimes of CMOVE and VELS with different values of ε, for
varying n (up to 500). (right) loglogplot of the runtime of VELS on 250, 500,
and 1000 agent mining day instances, for varying values of ε.
5.4.2 Mining Day
We now compare CMOVE and VELS on the Mining Day benchmark using the same generation procedure as in Section 4.5.2. We generated 30 Mining Day instances for increasing n
and averaged the runtimes (Figure 11 (left)). At 160 agents, CMOVE has reached a runtime
of 22s. Exact VELS (ε = 0) can compute the complete CCS for a MO-CoG with 420 agents
in the same time. This indicates that VELS greatly outperforms CMOVE on this structured
2-objective MO-CoG. Moreover, when we allow only 0.1% error (ε = 0.001), it takes only
1.1s to compute an ε-CCS for 420 agents, a speedup of over an order of magnitude.
To measure the additional speedups obtainable by further increasing ε, and to test VELS
on very large problems, we generated Mining Day instances with n ∈ {250, 500, 1000}. We
averaged over 25 instances per value of ε. On these instances, exact VELS runs in 4.2s
for n = 250, 30s for n = 500 and 218s for n = 1000 on average. As expected, increasing
ε leads to greater speedups (Figure 11 (right)). However, when ε is close to 0, i.e., the
431

Roijers, Whiteson, & Oliehoek

ε-CCS is close to the full CCS, the speedup is small. After ε has increased beyond a certain
value (dependent on n), the decline becomes steady, shown as a line in the log-log plot. If
ε increases by a factor 10, the runtime decreases by about a factor 1.6.
Thus, these results show that VELS can compute an exact CCS for unprecedented
numbers of agents (1000) in well-structured problems. In addition, they show that small
values of ε enable large speedups, and that increasing ε leads to even bigger improvements
in scalability.

6. Memory-Efficient Methods
Both CMOVE and VELS are designed to minimize the runtime required to compute a CCS.
However, in some cases, the bottleneck may be memory instead. Memory-efficient methods
for CoGs and related problems have recently received considerable attention (Dechter &
Mateescu, 2007; Marinescu, 2008, 2009; Mateescu & Dechter, 2005). In this section, we
show that, because it is an outer loop method, VELS is naturally memory efficient and
can therefore solve much larger MO-CoGs than an inner loop method like CMOVE when
memory is restricted. In addition, we show how both CMOVE and VELS can be modified
to produce even more memory-efficient variants.
6.1 And/Or Tree Search
We begin with some background on AND/OR tree search (Dechter & Mateescu, 2007;
Marinescu, 2008; Mateescu & Dechter, 2005; Yeoh, Felner, & Koenig, 2010), a class of
algorithms for solving single-objective CoGs that can be tuned to provide better space
complexity guarantees than VE. However, the improvement in space complexity comes at
a price, i.e., the runtime complexity is worse (Mateescu & Dechter, 2005). The background
we provide is brief; for a broader overview of AND/OR tree search for CoGs and related
models please see the work of Dechter (2013) and Marinescu (2008), and for multi-objective
versions the work of Marinescu (2009, 2011).
AND/OR tree search algorithms work by converting the graph to a pseudo tree (PT)
such that each agent need only know which actions its ancestors and descendants in the PT
take in order to select its own action. For example, if an agent i (a node) in the PT has two
subtrees (T1 and T2 ) under it, all the agents in T1 are conditionally independent of all the
agents in T2 given i and the ancestors of i. Figure 12a shows the PT for the coordination
graph in Figure 2a.
Next, AND/OR tree search algorithms perform a tree search that results in an AND/OR
search tree (AOST). Each agent i in an AOST is an OR-node. Its children are AND-nodes,
each corresponding to one of agent i’s actions. In turn, the children of these AND-nodes are
OR-nodes corresponding to agent i’s children in the PT. Because each action (AND-nodes)
of agent i has the same agents under it as OR-nodes, the agents and actions can appear in
the tree multiple times. Figure 12b shows an AOST for the graph of Figure 2a.
A specific joint action can be constructed by traversing the tree, starting at the root and
selecting one alternative from the childen of each OR-node, i.e., one action for each agent,
and continuing down all children of each AND-node. For example, in Figure 12b, the joint
action < ā1 , ȧ2 , ȧ3 > is indicated in grey. To retrieve the value of a joint action, we must
first define the value of AND-nodes.
432

Computing CCSs for Faster Multi-objective Coordination

Figure 12: (a) a pseudo tree, (b) a corresponding AND/OR search tree.
Definition 18. The value of an AND-node vai , representing an action ai of an agent i is
the sum of the local payoff functions that have i in scope; ai , together with its AND-node
ancestors’ actions, specifies an action for each agent in scope of these local payoff functions.
For example, in Figure 12b, the total payoff of the CoG is u(a1 , a2 , a3 ) = u1 (a1 , a2 ) +
u2 (a2 , a3 ). The value of the grey AND-node ȧ3 is u2 (ȧ2 , ȧ3 ), as u3 is the only payoff function
that has agent 3 in scope and, together with its ancestral AND-nodes, the grey ȧ2 -node, ȧ3
completes a joint local action for u2 .
To retrieve the optimal action, we must define the value of a subtree in the AOST:
Definition 19. The value of a subtree v(Ti ) rooted by an OR-node i in an AOST is the
maximum of the value of the subtrees rooted by the (AND-node) children of i. The value of
a subtree v(Tai ) rooted by an AND-node ai in an AOST is the value of ai itself (Definition
18) plus the sum of the value of the subtrees rooted by the (OR-node) children of ai .
The most memory-efficient way to retrieve the optimal joint action using an AOST
is Euler-touring it, i.e., performing a depth-first search and computing the values of the
subtrees. By generating nodes on the fly and deleting them after they are evaluated, memory
usage is minimized. We refer to this algorithm simply as AND/OR tree search (TS). As
in earlier sections, our implementation employs a tagging scheme, tagging the value of a
subtree with the actions that maximize it.
While TS is a single-objective method, it has been extended to compute the PCS,
yielding an algorithm we call Pareto TS (PTS) (Marinescu, 2009). To define PTS, we must
update Definition 19 to be a set of Pareto-optimal payoffs. We refer to such a subtree value
set as an intermediate PCS (IPCS).
Definition 20. The intermediate PCS of a subtree, IP CS(Ti ) rooted by an OR-node i is
the PCS of the union of the intermediate PCSs of the children, ch(i), of i:
IP CS(Ti ) = PPrune(

[

aj ∈ch(i)

433

IP CS(Taj )).

Roijers, Whiteson, & Oliehoek

The intermediate PCS of a subtree, IP CS(Tai ) rooted by an AND-node ai is the PCS of the
value of ai itself (Definition 18) plus the cross-sum of the intermediate PCSs of the subtrees
rooted by the (OR-node) children of ai :


M
IP CS(Tj ) ⊕ {vai }).
IP CS(Tai ) = PPrune(
j∈ch(ai )

Thus, PTS replaces the max operator in TS by a pruning operator, just as PMOVE replaces
the max operator in VE by a pruning operator.
6.2 Memory-Efficient CCS Algorithms
We now propose two memory-efficient algorithms for computing a CCS. Both are straightforward variants of CMOVE and VELS.
The first algorithm, which we call Convex TS (CTS), simply replaces PPrune by CPrune
in Definition 20. Thus, CTS is like PTS but with a different pruning operator. It can
also be seen as CMOVE but with VE replaced with TS. The advantage of CTS over PTS
is analogous to that of CMOVE over PMOVE: it is highly beneficial to compute local
CCSs instead of local PCSs because the intermediate coverage sets are input to the next
subproblem in a sequential search scheme, regardless of whether that scheme is VE or TS.
While CTS is more memory efficient than CMOVE, it still requires computing intermediate
coverage sets that take up space. While these are typically only about as large as the CCS,
their size is bounded only by the total number of joint actions.
The second algorithm addresses this problem by employing OLS with TS as the singleobjective solver subroutine, SolveCoG, yielding tree search linear support (TSLS). Thus,
TSLS is like VELS but with VE replaced by TS. Because TSLS is an outer-loop method, it
runs TS in sequence, requiring only the memory used by TS itself and the overhead of the
outer loop, which consists only of the partial CCS (Definition 13) and the priority queue.
Consequently, TSLS is even more memory efficient than CTS.
6.3 Analysis
TS has much better space complexity than VE, i.e., only linear in the number of agents n:
Theorem 12. The time complexity of TS is O(n|Amax |m ), where n is the number of agents,
|Amax | is the maximal number of actions of a single agent and m is the depth of the pseudo
tree, and uses linear space, O(n).
Proof. The number of nodes in an AOST is bounded by O(n|Amax |m ). The tree creates
maximally |Amax | children at each OR-node. If every AND-node had exactly one child, the
number of nodes would be bounded by O(|Amax |m ), as the PT is m deep. However, if there
is branching in the PT, an AND-node can have multiple children. Each branch increases
the size of the AOST by at most O(|Amax |m ) nodes. Because there are exactly n agents in
the PT, this can happen at most n times. At each node in the AOST, TS performs either
a summation of scalars, or a maximization over scalars. Because TS performs depth-first
search, at most O(n) nodes need to exist at any point during execution.
434

Computing CCSs for Faster Multi-objective Coordination

TS’s memory usage is usually lower than that required to store the original (singleobjective) problem in memory: O(ρ|Amax |emax ), where ρ is the number of local payoff
functions in the problem, |Amax | is the maximal size of the action space of a single agent,
and emax is the maximal size of the scope of a single local payoff function.
The PT-depth m is a different constant than the induced width w, and is typically
larger. However, m can be bounded in w.
Theorem 13. Given a MO-CoG with induced width w, there there exists a pseudo tree for
which the depth m ≤ w log n (Dechter & Mateescu, 2007).
Thus, combining Theorems 12 and 13 shows that, when there are few agents, TS can
be much more memory efficient than VE with a relatively small runtime penalty.
Using the time and space complexity results for TS, we can establish the following
corollaries about the time and space complexity of CTS and TSLS.
Corollary 2. The time complexity of CTS is O(n|Amax |m R), where R is the runtime of
CPrune.
Proof. O(n|Amax |m ) bounds the number of nodes in the AOST. For each node in the AOST
CPrune is called.
The runtime of CPrune in terms of the size of its input is given in Equation 3. Note
that the size of the input of CPrune depends on the size of the intermediate CCSs of
the children of a node. In the case of an AND-node, this input size is O(|ICCSmax |c ),
where c is the maximum number of children of an AND-node.13 For OR-nodes this is
O(|Amax ||ICCSmax |).
Corollary 3. The space complexity of CTS is O(n|ICCSmax |), where |ICCSmax | is the
maximum size of an intermediate CCS during the execution of CTS.
Proof. Like in TS, only O(n) nodes of the AOST need to exist during any point during
execution, and each node contains an intermediate CCS.
CTS is thus much more memory efficient than CMOVE, which has a space complexity
that is exponential in the induced width (Theorem 7).
Corollary 4. The time complexity of TSLS is O((|ε-CCS|+|Wε -CCS |) (n |Amax |m +Cnw +
Cheur )), where m ≤ w log n and ε ≥ 0.
Proof. The proof is the same as that of Theorem 9 but with the time complexity of VE
replaced by that of TS.
In terms of memory usage, the outer loop approach (OLS) has a large advantage over
the inner loop approach, because the overhead of the outer loop consists only of the partial
CCS (Definition 13) and the priority queue. VELS (Theorem 11) thus has much better
space complexity than CMOVE (Theorem 7). TSLS has the same advantage over CTS as
VELS over CMOVE. Therefore, TSLS has very low memory usage, since it requires only
the memory used by TS itself plus the overhead of the outer loop.
13. Note that c is in turn upper bounded by n but this is a very loose bound.

435

Roijers, Whiteson, & Oliehoek

Corollary 5. The space complexity of TSLS is O(d|ε-CCS| + d|Wε -CCS | + n)), where
m ≤ w log n and ε ≥ 0.
Proof. The proof is the same as that of Theorem 11 but with the space complexity of VE
replaced by that of TS.
As mentioned in Section 6.1, TS is the most memory-efficient member of the class of
AND/OR tree search algorithms. Other members of this class offer different trade-offs
between time and space complexity. It is possible to create inner loop algorithms and
corresponding outer loop algorithms on the basis of these other algorithms. The time
and space complexity analyses of these algorithms can be performed in a similar manner to
Corollaries 2–5. The advantages of the outer loop methods compared to their corresponding
inner loop methods will however remain the same as for TSLS and CTS. Therefore, in this
article we focus on comparing the most memory-efficient inner loop method against the
most memory-efficient outer loop method.
6.4 Empirical Evaluation
In this section, we compare CTS and TSLS to CMOVE and VELS. As before, we use both
random graphs and the Mining Day benchmark. To obtain the PTs for CTS and TSLS,
we use the same heuristic as CMOVE and VELS to generate an elimination order and
then transform it into a PT for which m ≤ w log n holds (whose existence is guaranteed by
Theorem 13), using the procedure suggested by Bayardo and Miranker (1995).
6.4.1 Random Graphs
First, we test our algorithms on random graphs, employing the same generation procedure
as in Section 4.5.1. Because connections between agents in these graphs are generated
randomly, the induced width varies between different problems. On average, the induced
width increases with the number of local payoff functions, even when the ratio between
local payoff factors and the number of agents remains constant.
In order to test the sizes of problems that the different MO-CoG solution methods can
handle within limited memory, we generate random graphs with two objectives, a varying
number of agents n, and with ρ = 1.5n local payoff functions, as in previous sections. We
limited the maximal available memory to 1kB and imposed a timeout of 1800s.
Figure 13a shows that VELS can scale to more agents within the given memory constraints than the other non-memory efficient methods. In particular, PMOVE and CMOVE
can handle only 30 and 40 agents, respectively, because, for a given induced width w, they
must store O(|Amax |w ) local CSs. At 30 agents, the induced width (Figure 13c) is at most
6, while at 40 agents the induced width is at most 8. VELS can handle 65 agents, with an
induced width of at most 11, because most of its memory demands come from running VE
in the inner loop, while the outer loop adds little overhead. VE need only store one payoff
in each new local payoff function that results from an agent elimination, whereas PMOVE
and CMOVE must store local coverage sets. Thus, using an outer loop approach (VELS)
instead of the inner loop approach (CMOVE) already yields a significant improvement in
the problem sizes that can be tackled with limited memory.
436

Computing CCSs for Faster Multi-objective Coordination

(a)

(b)

(c)

Figure 13: (a) Runtimes in ms of TSLS, VELS, CTS, CMOVE and PMOVE on random 2objective MO-CoGs with varying numbers of agents n and ρ = 1.5n local payoff
factors. (b) Runtimes of approximate TSLS for varying amounts of allowed error
ε, compared to (Exact) VELS, for the same problem parameters as in (a). (c)
The corresponding induced widths of the MO-CoGs in (b).

However, scaling beyond 65 agents requires a memory-efficient approach. Figure 13a
also shows that, while CTS and TSLS require more runtime, they can handle more agents
within the memory constraints. In fact, we were unable to generate a MO-CoG with enough
agents to cause these methods to run out of memory. TSLS is faster than CTS, in this case
4.2 times faster, for the same reasons that VELS is faster than CMOVE.
However, speed is not the only advantage of the outer loop approach. When we allow
a bit of error in scalarized value, ε, we can trade accuracy for runtime (Figure 13b). At 65
agents, exact TSLS (ε = 0), had an average runtime of 106s, which is 51 times slower than
VELS. However, for ε = 0.0001, the runtime was only 70s (33 times slower). For ε = 0.01 it
is 11s (5.4 times slower), and for ε = 0.1 it is only 6s (2.9 times slower). Furthermore, the
relative increase in runtime as the number of agents increases is less for higher ε. Thus, an
approximate version of TSLS is a highly attractive method for cases in which both memory
and runtime are limited.
6.4.2 Mining Field
We compare the performance of CMOVE and VELS against TSLS on a variation of Mining
Day that we call Mining Field. We no longer consider CLS because it has consistently higher
runtime than TSLS and worse space complexity. We use Mining Field in order to ensure
an interesting problem for the memory-restricted setting. In Mining Day (see Section 4),
the induced width depends only on the parameter specifying the connectivity of the villages
and does not increase with the number of agents and factors. Therefore, whether or not
VELS is memory-efficient enough to handle a particular instance depends primarily on this
parameter and not on the number of agents.
In Mining Field, the villages are not situated along a mountain ridge but are placed on
an s × s grid. The number of agents is thus n = s2 . We use random placement of mines,
while ensuring that the graph is connected. Because the induced width of a connected grid
is s and we generate grid-like graphs, larger instances have a higher induced width. The
437

Roijers, Whiteson, & Oliehoek

village

(a)

mine

(b)

(c)

Figure 14: (a) An example of a 4 by 4 Mining Field instance. The additional mines m are
marked with a ‘+’. (b) Runtimes in ms of TSLS (for varying amounts of allowed
error ε), VELS (ε = 0), and CMOVE on 2-objective Mining Field instances with
varying numbers of additional mines m ∈ [2..14] and a grid size of s = 7. (c)
The corresponding induced widths of the Mining Field instances.

induced width thus no longer depends only on the connectivity parameter but also increases
with the number of agents and factors in the graph.
An example Mining Field instance is provided in Figure 14a. We choose the distance
between adjacent villages on the grid to be unit length. On this map, we then place the
mines (local payoff functions). We connect all agents using an arbitrary tree using 2-agent
local payoff functions (mines). In the figures, the mines that span this tree are unmarked
and connected to the mines with black edges. We require s2 − 1 factors to build the tree.
Then we add m additional mines, by (independently) placing them on a random point on
the map inside the grid. When a mine is placed, we connect it to the villages that are within
a r = √12 + η radius of that mine on the map. We chose η = 0.2. Therefore, the maximum
connectivity of a factor (mine) created in this fashion is 4. In the figure, these mines are
marked with a ‘+’. The rewards per mine per worker, as well as the number of workers per
village, are generated in the same way as in Mining Day.
To compare the runtimes and memory requirements of CMOVE, VELS, and TSLS on
Mining Field, we tested them on a 7 × 7 instance (49 agents), with 1MB available memory.
For TSLS, we use three different values of ε: 0 (exact), 0.01 and 0.1. We use a time limit of
1.8 × 106 s (30 minutes). We increase the number of additional mines m from 2 (50 factors
in total) onwards, by steps of 2.
Using this setup, it was not possible to solve any of the problem instances using PMOVE,
which ran out of memory for all problems. In fact, PMOVE succeeded only a tree-shaped
problem. i.e., one without any additional factors. Figures 14b and 14c) show the results for
the remaining methods. CMOVE runs out of memory at 6 additional factors (54 factors in
total). By contrast, VELS runs out of memory only at 16 additional factors, at an induced
width of 6.
Compared to the random-graph results in Section 6.4.1, the induced widths of the
problems that CMOVE and VELS can handle are lower in Mining Field. We suspect that
438

Computing CCSs for Faster Multi-objective Coordination

this is because, on a grid-shaped problem, the number of factors with the highest induced
width that need to exist in parallel during the execution of the algorithms is higher.
TSLS does not run out of memory on any of the tested instances. In face, we were
unable to generate instances for which TSLS does run out of memory. However, it does
run out of time. For ε = 0, TSLS first exceeds the time limit at m = 10 additional mines.
For ε = 0.01, this happens at m = 14. For ε = 0.1, TSLS ran out of time at m = 16.
The differences in runtime between TSLS and VELS are larger than for random graphs
and therefore it is more difficult to compensate for the slower runtime of TSLS by choosing
a higher ε. How much slower TSLS is compared to VELS thus seems to depend on the
structure of the MO-CoG.
These Mining Field results confirm the conclusion of the random-graph experiments that
using an outer loop approach (VELS) instead of the inner loop approach (CMOVE) yields
a significant improvement in the problem sizes that can be tackled with limited memory.
Futhermore, TSLS can be used to solve problem sizes beyond those that VELS can handle
within limited memory. An approximate version of TSLS is an appealing choice for cases
in which both memory and runtime are limited.

7. Conclusions and Future Work
In this article, we proposed new algorithms that exploit loose couplings to compute a CCS
for multi-objective coordination graphs. We showed that exploiting these loose couplings
is key to solving MO-CoGs with many agents. In particular, we showed, both theoretically
and empirically, that computing a CCS has considerable advantages over computing a PCS
in terms of both runtime and memory usage. Our experiments have consistently shown
that the runtime of PCS methods grows a lot faster than that of our CCS methods.
CMOVE deals with multiple objectives in the inner loop, i.e., it computes local CCSs
while looping over the agents. By contrast, VELS deals with multiple objectives in the
outer loop, i.e., it identifies weights where the maximal improvement upon a partial CCS
can be made and solves scalarized (single-objective) problems using these weights, yielding
an anytime approach. In addition, CTS and TSLS are memory-efficient variants of these
methods. We proved the correctness of these algorithms and analyzed their complexity.
CMOVE and VELS are complementary methods. CMOVE scales better in the number
of objectives, while VELS scales better in the number of agents and can compute an εCCS, leading to large additional speedups. Furthermore, VELS is more memory-efficient
than CMOVE. In fact, VELS uses little more memory than single-objective VE.
However, if memory is very restricted and VELS cannot be applied, TSLS provides a
memory-efficient alternative. While TSLS is considerably slower than VELS, some of this
loss can be compensated by allowing some error (ε).
There are numerous possibilities for future work. As mentioned in Section 5, OLS is a
generic method that can also be applied to other multi-objective problems. In fact, (together
with other authors) we already applied OLS to large multi-objective MDPs and showed that
OLS can be extended to permit non-exact single-objective solvers (Roijers et al., 2014). In
future work, we intend to investigate ε-approximate methods for MO-CoGs, by using ζapproximate single-objective solvers for CoGs, using, e.g., LP-relaxation methods (Sontag,
Globerson, & Jaakkola, 2011). We will attempt to find the optimal balance between the
439

Roijers, Whiteson, & Oliehoek

levels of approximation in the inner and outer loop, with respect to runtime guarantees and
empirical runtimes.
Many methods exist for single-objective coordination graphs in which a single parameter
controls the trade-off between memory usage and runtime (Furcy & Koenig, 2005; Rollón,
2008). For some of these algorithms, a corresponding multi-objective inner-loop version
that computes a PCS (Marinescu, 2009, 2011) has been devised. It would be interesting
to create inner and outer loop methods based on these methods that compute a CCS
instead and compare performance. In particular, we have shown that OLS requires very
little extra memory usage compared to single-objective solvers. It would be interesting to
investigate how much extra memory could be used by a single-objective solver inside OLS,
in comparison to the corresponding inner-loop method.
In addition to further work on MO-CoGs, we also aim to extend our work to sequential
settings. In particular, we will look at developing an efficient planning method for multiagent multi-objective MDPs by better exploiting loosely couplings. First, we will try to
develop an ε-approximate planning version of sparse-cooperative Q-learning (Kok & Vlassis,
2006b). However, this may not be possible in general because the effects of an agent on
other agents via the state is impossible to bound in general. Therefore, we hope to identify a
broadly applicable subclass of multi-agent MOMDPs for which an ε-approximate planning
method yields a substantial speed-up compared to exact planning methods.

Acknowledgements
We thank Rina Dechter for introducing us to memory-efficient methods for CoGs and
MO-CoGs, and Radu Marinescu for his tips on memory-efficient methods and their implementation. Also, we would like to thank Maarten Inja, as well as the anonymous reviewers, for their valuable feedback. This research is supported by the NWO DTC-NCAP
(#612.001.109) and NWO CATCH (#640.005.003) projects and NWO Innovational Research Incentives Scheme Veni (#639.021.336). Frans Oliehoek is affiliated with both the
University of Amsterdam and the University of Liverpool.

References
Avis, D., & Devroye, L. (2000). Estimating the number of vertices of a polyhedron. Information processing letters, 73 (3), 137–143.
Bayardo, R. J. J., & Miranker, D. P. (1995). On the space-time trade-off in solving constraint
satisfaction problems. In IJCAI 1995: Proceedings of the Fourteenth International
Joint Conference on Artificial Intelligence.
Bertsimas, D., & Tsitsiklis, J. (1997). Introduction to Linear Optimization. Athena Scientific.
Bishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.
Cassandra, A., Littman, M., & Zhang, N. (1997). Incremental pruning: A simple, fast, exact
method for partially observable markov decision processes. In UAI 1997: Proceedings
of the Thirteenth Conference on Uncertainty in Artificial Intelligence, pp. 54–61.
440

Computing CCSs for Faster Multi-objective Coordination

Cheng, H.-T. (1988). Algorithms for partially observable Markov decision processes. Ph.D.
thesis, University of British Columbia, Vancouver.
Dechter, R. (2013). Reasoning with Probabilistic and Deterministic Graphical Models: Exact Algorithms, Vol. 7 of Synthesis Lectures on Artificial Intelligence and Machine
Learning. Morgan & Claypool Publishers.
Dechter, R., & Mateescu, R. (2007). And/or search spaces for graphical models. Artificial
intelligence, 171 (2), 73–106.
Delle Fave, F., Stranders, R., Rogers, A., & Jennings, N. (2011). Bounded decentralised
coordination over multiple objectives. In Proceedings of the Tenth International Joint
Conference on Autonomous Agents and Multiagent Systems, pp. 371–378.
Dubus, J., Gonzales, C., & Perny, P. (2009). Choquet optimization using gai networks
for multiagent/multicriteria decision-making. In ADT 2009: Proceedings of the First
International Conference on Algorithmic Decision Theory, pp. 377–389.
Feng, Z., & Zilberstein, S. (2004). Region-based incremental pruning for POMDPs. In UAI
2004: Proceedings of the Twentieth Conference on Uncertainty in Artificial Intelligence, pp. 146–153.
Furcy, D., & Koenig, S. (2005). Limited discrepancy beam search. In IJCAI 2005: Proceedings of the Nineteenth International Joint Conference on Artificial Intelligence, pp.
125–131.
Guestrin, C., Koller, D., & Parr, R. (2002). Multiagent planning with factored MDPs. In
Advances in Neural Information Processing Systems 15 (NIPS’02).
Henk, M., Richter-Gebert, J., & Ziegler, G. M. (1997). Basic properties of convex polytopes.
In Handbook of Discrete and Computational Geometry, Ch.13, pp. 243–270. CRC
Press, Boca.
Kaibel, V., & Pfetsch, M. E. (2003). Some algorithmic problems in polytope theory. In
Algebra, Geometry and Software Systems, pp. 23–47. Springer.
Kok, J. R., & Vlassis, N. (2004). Sparse cooperative Q-learning. In Proceedings of the
twenty-first international conference on Machine learning, ICML ’04, New York, NY,
USA. ACM.
Kok, J. R., & Vlassis, N. (2006a). Using the max-plus algorithm for multiagent decision
making in coordination graphs. In RoboCup 2005: Robot Soccer World Cup IX, pp.
1–12.
Kok, J., & Vlassis, N. (2006b). Collaborative multiagent reinforcement learning by payoff
propagation. Journal of Machine Learning Research, 7, 1789–1828.
Koller, D., & Friedman, N. (2009). Probabilistic Graphical Models: Principles and Techniques. MIT Press.
Lizotte, D., Bowling, M., & Murphy, S. (2010). Efficient reinforcement learning with multiple
reward functions for randomized clinical trial analysis. In Proceedings of the 27th
International Conference on Machine Learning (ICML-10), pp. 695–702.
441

Roijers, Whiteson, & Oliehoek

Marinescu, R., Razak, A., & Wilson, N. (2012). Multi-objective influence diagrams. In
UAI 2012: Proceedings of the Twenty-Eighth Conference on Uncertainty in Artificial
Intelligence.
Marinescu, R. (2008). AND/OR Search Strategies for Combinatorial Optimization in Graphical Models. Ph.D. thesis, University of California, Irvine.
Marinescu, R. (2009). Exploiting problem decomposition in multi-objective constraint optimization. In Principles and Practice of Constraint Programming-CP 2009, pp. 592–
607. Springer.
Marinescu, R. (2011). Efficient approximation algorithms for multi-objective constraint
optimization. In ADT 2011: Proceedings of the Second International Conference on
Algorithmic Decision Theory, pp. 150–164. Springer.
Mateescu, R., & Dechter, R. (2005). The relationship between AND/OR search and variable
elimination. In UAI 2005: Proceedings of the Twenty-First Conference on Uncertainty
in Artificial Intelligence, pp. 380–387.
McMullen, P. (1970). The maximum numbers of faces of a convex polytope. Mathematika,
17 (2), 179–184.
Oliehoek, F. A., Spaan, M. T. J., Dibangoye, J. S., & Amato, C. (2010). Heuristic search
for identical payoff bayesian games. In AAMAS 2010: Proceedings of the Ninth International Joint Conference on Autonomous Agents and Multiagent Systems, pp.
1115–1122.
Pearl, J. (1988). Probabilistic reasoning in intelligent systems: networks of plausible inference. Morgan Kaufmann.
Pham, T. T., Brys, T., Taylor, M. E., Brys, T., Drugan, M. M., Bosman, P. A., Cock,
M.-D., Lazar, C., Demarchi, L., Steenhoff, D., et al. (2013). Learning coordinated
traffic light control. In Proceedings of the Adaptive and Learning Agents workshop (at
AAMAS-13), Vol. 10, pp. 1196–1201.
Roijers, D. M., Scharpff, J., Spaan, M. T. J., Oliehoek, F. A., de Weerdt, M., & Whiteson,
S. (2014). Bounded approximations for linear multi-objective planning under uncertainty. In ICAPS 2014: Proceedings of the Twenty-Fourth International Conference
on Automated Planning and Scheduling, pp. 262–270.
Roijers, D. M., Vamplew, P., Whiteson, S., & Dazeley, R. (2013a). A survey of multiobjective sequential decision-making. Journal of Artificial Intelligence Research, 47,
67–113.
Roijers, D. M., Whiteson, S., & Oliehoek, F. (2013b). Computing convex coverage sets for
multi-objective coordination graphs. In ADT 2013: Proceedings of the Third International Conference on Algorithmic Decision Theory, pp. 309–323.
Roijers, D. M., Whiteson, S., & Oliehoek, F. A. (2014). Linear support for multi-objective
coordination graphs. In AAMAS 2014: Proceedings of the Thirteenth International
Joint Conference on Autonomous Agents and Multi-Agent Systems, pp. 1297–1304.
Rollón, E. (2008). Multi-Objective Optimization for Graphical Models. Ph.D. thesis, Universitat Politècnica de Catalunya, Barcelona.
442

Computing CCSs for Faster Multi-objective Coordination

Rollón, E., & Larrosa, J. (2006). Bucket elimination for multiobjective optimization problems. Journal of Heuristics, 12, 307–328.
Rosenthal, A. (1977). Nonserial dynamic programming is optimal. In Proceedings of the
Ninth Annual ACM Symposium on Theory of Computing, pp. 98–105. ACM.
Scharpff, J., Spaan, M. T. J., Volker, L., & De Weerdt, M. (2013). Planning under uncertainty for coordinating infrastructural maintenance. In Proceedings of the 8th annual
workshop on Multiagent Sequencial Decision Making Under Certainty.
Sontag, D., Globerson, A., & Jaakkola, T. (2011). Introduction to dual decomposition for
inference. Optimization for Machine Learning, 1, 219–254.
Tesauro, G., Das, R., Chan, H., Kephart, J. O., Lefurgy, C., Levine, D. W., & Rawson, F.
(2007). Managing power consumption and performance of computing systems using
reinforcement learning. In Advances in Neural Information Processing Systems 20
(NIPS’07).
Vamplew, P., Dazeley, R., Barker, E., & Kelarev, A. (2009). Constructing stochastic mixture policies for episodic multiobjective reinforcement learning tasks. In Advances in
Artificial Intelligence, pp. 340–349.
Yeoh, W., Felner, A., & Koenig, S. (2010). BnB-ADOPT: An asynchronous branch-andbound DCOP algorithm. Journal of Artificial Intelligence Research, 38, 85–133.

443

Journal of Artificial Intelligence Research 52 (2015) 179-201

Submitted 5/14; published 1/15

Agnostic Pointwise-Competitive Selective Classification
Yair Wiener
Ran El-Yaniv

wyair@tx.technion.ac.il
rani@cs.technion.ac.il

Computer Science Department
Technion – Israel Institute of Technology
Haifa 32000, Israel

Abstract
A pointwise competitive classifier from class F is required to classify identically to the
best classifier in hindsight from F. For noisy, agnostic settings we present a strategy for
learning pointwise-competitive classifiers from a finite training sample provided that the
classifier can abstain from prediction at a certain region of its choice. For some interesting hypothesis classes and families of distributions,
the measure of this

 rejected region is
β /2
shown to be diminishing at rate β1 · O (polylog(m) · log(1/δ)/m) 2
, with high probability, where m is the sample size, δ is the standard confidence parameter, and β1 , β2 are
smoothness parameters of a Bernstein type condition of the associated excess loss class
(related to F and the 0/1 loss). Exact implementation of the proposed learning strategy
is dependent on an ERM oracle that is hard to compute in the agnostic case. We thus
consider a heuristic approximation procedure that is based on SVMs, and show empirically
that this algorithm consistently outperforms a traditional rejection mechanism based on
distance from decision boundary.

1. Introduction
Given a labeled training set and a class of models F, is it possible to select from F, based
on a finite training sample, a model whose predictions are always identical to best model
in hindsight? While classical results from statistical learning theory surely preclude such a
possibility within the standard model, when changing the rules of the game it is possible.
Indeed, consider a game where our classifier is allowed to abstain from prediction without
penalty in some region of its choice (a.k.a classification with a reject option). For this game,
and assuming a noise free “realizable” setting, it was shown by El-Yaniv and Wiener (2010)
that one can train a “perfect classifier” that never errs whenever it is willing to predict.
While always abstaining will render such perfect classification vacuous, it was shown that
for a quite broad set of problems (each specified by an underlying distribution family and
a hypothesis class), perfect realizable classification is achievable with a rejection rate that
diminishes quickly to zero with the training sample size.
In general, perfect classification cannot be achieved in a noisy setting. In this paper, our
objective is to achieve pointwise competitiveness, a property ensuring that the prediction at
every non-rejected test point is identical to the prediction of the best predictor in hindsight
from the same class. Here we consider pointwise-competitive selective classification and
generalize the results of El-Yaniv and Wiener (2010) to the agnostic case. In particular,
we show that pointwise-competitive classification is achievable with high probability by a
learning strategy called low error selective strategy (LESS). Given a training sample Sm

c
2015
AI Access Foundation. All rights reserved.

Wiener & El-Yaniv

and a hypothesis class F, LESS outputs a pointwise-competitive selective classifier (f, g),
where f (x) is a standard classifier, and g(x) is a selection function that qualifies some of
the predictions as “don’t knows” (see definitions in Section 2). The classifier f is simply
taken to be the empirical risk minimizer (ERM) classifier, fˆ. Pointwise competitiveness is
achieved through g as follows. Using standard concentration inequalities, we show that the
true risk minimizer, f ∗ , achieves empirical error that is close that of fˆ. Thus, with high
probability f ∗ belongs to the class of low empirical error hypotheses. Now all that is left
to do is set g(x) such that it allows the prediction of the label of x, as fˆ(x), if and only
if all the hypotheses in this low error class unanimously agree on the label of x. In the
simpler, realizable setting (El-Yaniv & Wiener, 2010), this low error class simply reduces
to the version space.
The bulk of our analysis (in Sections 3, 4 and 5) concerns coverage bounds for LESS,
namely, showing that the measure of the region where the classifier (f, g) refuses to classify,
diminishes quickly, with high probability, as the training sample size grows (see Section 2
for a formal definition). We provide several general and distribution-dependent coverage
bounds. In particular, we show (in Corollaries 12 and 14, respectively) high probability
bounds for the coverage Φ(f, g) of the classifier (f, g, ) of the form,


Φ(f, g) ≥ 1 − β1 · O (polylog(m) · log(1/δ)/m)β2 /2 ,

for linear models under (unknown) distribution P (X, Y ), where X are feature space points
and Y are labels, whose marginal P (X) is any finite mixture of Gaussians, and for axis
aligned rectangles under P (X, Y ) whose marginal P (X) is a product distribution, where
β1 , β2 are Bernstein class smoothness parameters depending on the hypothesis class and the
underlying distribution (and the loss function, 0/1 in our case).
At the outset, efficient implementation of LESS seems to be out of reach as we are
required to track the supremum of the empirical error over a possibly infinite hypothesis
subset, which in general might be intractable. To overcome this computational difficulty, we
propose a reduction of this problem to a problem of calculating (two) constrained ERMs.
For any given test point x, we calculate the ERM over the training sample Sm with a
constraint on the label of x (one positive label constraint and one negative). We show
that thresholding the difference in empirical error between these two constrained ERMs is
equivalent to tracking the supremum over the entire (infinite) hypothesis subset. Based
on this reduction we introduce in Section 6 a “disbelief principle” that motivates a heuristic implementation of LESS, which relies on constrained SVMs, and mimics the optimal
behavior.
In Section 7 we present some numerical examples over medical classification problems
and examine the empirical performance of the new algorithm and compare its performance
with that of the widely used selective classification method for rejection, based on distance
from decision boundary.

2. Pointwise-Competitive Selective Classification: Preliminary
Definitions
Let X be some feature space, for example, d-dimensional vectors in Rd , and Y be some
output space. In standard classification, the goal is to learn a classifier f : X → Y, using
172

Agnostic Pointwise-Competitive Selective Classification

a finite training sample of m labeled examples, Sm = {(xi , yi )}m
i=1 , assumed to be sampled
i.i.d. from some unknown underlying distribution P (X, Y ) over X × Y. The classifier is to
be selected from some hypothesis class F. Let ℓ : Y × Y → [0, 1] be a bounded loss function.
In selective classification (El-Yaniv & Wiener, 2010), the learning algorithm receives Sm
and is required to output a selective classifier, defined to be a pair (f, g), where f ∈ F is a
classifier, and g : X → {0, 1} is a selection function, serving as qualifier for f as follows. For
any x ∈ X , (f, g)(x) = f (x) iff g(x) = 1. Otherwise, the classifier outputs “I don’t know.”
The general performance of a selective predictor is characterized in terms of two quantities: coverage and risk. The coverage of (f, g) is Φ(f, g) , EP [g(x)] . The true risk of (f, g),
with respect to some loss function ℓ, is the average loss of f restricted to its region of activity
as qualified by g, and normalized by its coverage, R(f, g) , EP [ℓ(f (x), y) · g(x)] /Φ(f, g). It
is easy to verify that if g ≡ 1 (and therefore Φ(f, g) = 1), then R(f, g) reduces
to the famil1 Pm
iar risk functional R(f ) , EP [ℓ(f (x), y)]. For a classifier f , let R̂(f ) , m i=1 ℓ(f (xi ), yi ),
the standard empirical error of f over the sample Sm . Let fˆ = argminf ∈F R̂(f ) be the
empirical risk minimizer (ERM), and let f ∗ = argminf ∈F R(f ) be the true risk minimizer
with respect to unknown distribution P (X, Y ).1 Clearly, the true risk minimizer f ∗ is unknown. A selective classifier (f, g) is called pointwise-competitive if for any x ∈ X , for which
g(x) > 0, f (x) = f ∗ (x).

3. Low Error Selective Strategy (LESS)
For any hypothesis class F, hypothesis f ∈ F, distribution P , sample Sm , and real number
r > 0, define the true and empirical low-error sets,

	
V(f, r) , f ′ ∈ F : R(f ′ ) ≤ R(f ) + r
(1)
and

n
o
V̂(f, r) , f ′ ∈ F : R̂(f ′ ) ≤ R̂(f ) + r .

(2)

Throughout the paper we denote by σ(m, δ, d) the slack of a standard uniform deviation
bound, given in terms of the training sample size, m, the confidence parameter, δ, and the
VC-dimension, d, of the class F,
s

+ ln 2δ
2d ln 2me
d
σ(m, δ, d) , 2
.
(3)
m
The following theorem is a slight extension of the statement made by Bousquet, Boucheron,
and Lugosi (2004, p. 184).
Theorem 1 (Bousquet et al., 2004). Let ℓ be the 0/1 loss function and F, a hypothesis
class whose VC-dimension is d. For any 0 < δ < 1, with probability of at least 1 − δ over
the choice of Sm from P m , any hypothesis f ∈ F satisfies
R(f ) ≤ R̂(f ) + σ(m, δ, d).
Similarly, R̂(f ) ≤ R(f ) + σ(m, δ, d) under the same conditions.
1

More formally, f ∗ is a classifier such that R(f ∗ ) = inf f ∈F R(f ) and inf f ∈F P ((x, y) : f (x) 6= f ∗ (x)) = 0.
The existence of such a (measurable) f ∗ is guaranteed under sufficient considerations (see Hanneke, 2012,
pp. 1511-2).

173

Wiener & El-Yaniv

Remark 2. The use of Theorem 1 and, in particular, VC bounds for classification problems
(0/1 loss) is not mandatory for developing the theory presented in this paper. Similar
theories can be developed using other types of bounds (e.g., Rademacher or compression
bounds) for other learning problems.
Let G ⊆ F. The disagreement set (Hanneke, 2007a; El-Yaniv & Wiener, 2010) w.r.t. G
is defined as
DIS(G) , {x ∈ X : ∃f1 , f2 ∈ G s.t. f1 (x) 6= f2 (x)} .
(4)
Let us now motivate the low-error selective strategy (LESS) whose pseudo-code appears
in Strategy 1. The strategy is define whenever the empirical risk minimizer (ERM) exists,
for example, in the case of the 0/1 loss. Using a standard uniform deviation bound, such as
the one in Theorem 1, one can show that the training error of the true risk minimizer, f ∗ ,
cannot be “too far” from the training error of the empirical risk minimizer, fˆ. Therefore,

we can guarantee, with high probability, that the empirical low error class V̂ fˆ, r (applied
with appropriately chosen r) includes the true risk minimizer f ∗ . The selection function
g is now constructed to accept a subset of the domain X , on which all hypotheses in the
empirical low-error set unanimously agree. Strategy 1 formulates this idea. We call it a
‘strategy’ rather then an ‘algorithm’ because it lacks implementation details. Indeed, it is
not clear at the outset if this strategy can be implemented.
Strategy 1 Agnostic low-error selective strategy (LESS)
Input: Sm , m, δ, d
Output: a pointwise-competitive selective classifier (h, g) w.p. 1 − δ
ˆ
1: Set fˆ = ERM
 (F, Sm ), i.e., f is any empirical risk minimizer from F w.r.t. Sm
2: Set G = V̂ fˆ, 2σ(m, δ/4, d) (see Eq. (2) and (3))
3: Construct g such that g(x) = 1 ⇐⇒ x ∈ {X \ DIS (G)}
4: f = fˆ
We now begin the analysis of LESS. The following lemma establishes its pointwise competitiveness. In Section 4 we develop general coverage bounds in terms of an undetermined
disagreement coefficient. Then, in Section 5 we present distribution-dependent bounds that
do not rely on the disagreement coefficient.
Lemma 3 (pointwise competitiveness). Let ℓ be the 0/1 loss function and F, a hypothesis
class whose VC-dimension is d. Let δ > 0 be given and let (f, g) be the selective classifier
chosen by LESS. Then, with probability of at least 1 − δ/2, (f, g) is a pointwise competitive
selective classifier.
Proof. By Theorem 1, with probability of at least 1 − δ/4,
R̂(f ∗ ) ≤ R(f ∗ ) + σ (m, δ/4, d) .
Clearly, since f ∗ minimizes the true error, R(f ∗ ) ≤ R(fˆ). Applying again Theorem 1, we
know that with probability of at least 1 − δ/4,
R(fˆ) ≤ R̂(fˆ) + σ (m, δ/4, d) .
174

Agnostic Pointwise-Competitive Selective Classification

Using the union bound, it follows that with probability of at least 1 − δ/2,
R̂(f ∗ ) ≤ R̂(fˆ) + 2σ (m, δ/4, d) .
Hence, with probability of at least 1 − δ/2,


f ∗ ∈ V̂ fˆ, 2σ (m, δ/4, d) , G.

By definition, LESS constructs the selection function g(x) such that it equals one iff x ∈
X \DIS (G) . Thus, for any x ∈ X , for which g(x) = 1, all the hypotheses in G agree, and in
particular f ∗ and fˆ agree. Therefore (f, g) is pointwise-competitive with high probability.

4. General Coverage Bounds for LESS in Terms of the Disagreement
Coefficient
We require the following definitions to facilitate the coverage analysis. For any f ∈ F and
r > 0, define the set B(f, r) of all hypotheses that reside in a ball of radius r around f ,


 ′
	
′
B(f, r) , f ∈ F : Pr f (X) 6= f (X) ≤ r .
X∼P

For any G ⊆ F, and distribution P , we denote by ∆G the volume of the disagreement set
of G (see (4)), ∆G , Pr {DIS(G)}. Let r0 ≥ 0. The disagreement coefficient (Hanneke,
2009) of the hypothesis class F with respect to the target distribution P is
θ(r0 ) , θf ∗ (r0 ) = sup

r>r0

∆B(f ∗ , r)
.
r

(5)

The disagreement coefficient will be utilized later on in our analysis. See also a discussion
on its characteristics after Corollary 7. The associated excess loss class of the class F and
the loss function ℓ (Massart, 2000; Mendelson, 2002; Bartlett, Mendelson, & Philips, 2004)
is defined as
XL(F, ℓ)(x, y) , {ℓ(f (x), y) − ℓ(f ∗ (x), y) : f ∈ F} .
Whenever F and ℓ are fixed we abbreviate XL = XL(F, ℓ)(x, y). XL is said to be a
(β1 , β2 )-Bernstein class with respect to P (where 0 < β2 ≤ 1 and β1 ≥ 1), if every h ∈ XL
satisfies
Eh2 ≤ β1 (Eh)β2 .
(6)
Bernstein classes arise in many natural situations (see, e.g., Koltchinskii, 2006; Bartlett &
Mendelson, 2006; Bartlett & Wegkamp, 2008). For example, if the conditional probability
P (Y |X) is bounded away from 1/2, or it satisfies Tsybakov’s noise conditions2 , then the
excess loss function is a Bernstein class (Bartlett & Mendelson, 2006; Tsybakov, 2004).3
2

If the data was generated from any unknown deterministic hypothesis with limited noise then P (Y |X) is
bounded away from 1/2.

3

Specifically, for the 0/1 loss, Assumption A in Proposition 1 in the work of Tsybakov (2004), is equivalent
α
to the Bernstein class condition of Equation (6) above with β2 = 1+α
, where α is the Tsybakov noise
parameter.

175

Wiener & El-Yaniv

In the following sequence of lemmas and theorems we assume a binary hypothesis class F
with VC-dimension d, an underlying distribution P over X ×{±1}, and that ℓ is the 0/1 loss
function. Also, XL denotes the associated excess loss class. Our results can be extended to
loss functions other than 0/1 by similar techniques to those used by Beygelzimer, Dasgupta,
and Langford (2009).
In Figure 1 we schematically depict the hypothesis class F (the gray area), the target
hypothesis (filled black circle outside F), and the best hypothesis in the class f ∗ . The
distance of two points in the diagram relates to the distance between two hypothesis under
the marginal distribution P (X). Our first observation is that if the excess loss class is
(β1 , β2 )-Bernstein class, then the set of low true error (depicted in Figure 1 (a)) resides
within a larger ball centered around f ∗ (see Figure 1 (b)).

Figure 1: The set of low true error (a) resides within a ball around f ∗ (b).
Lemma 4. If XL is a (β1 , β2 )-Bernstein class with respect to P , then for any r > 0


V(f ∗ , r) ⊆ B f ∗ , β1 rβ2 .

Proof. If f ∈ V(f ∗ , r) then, by definition, E {I(f (X) 6= Y )} ≤ E {I(f ∗ (X) 6= Y )} + r. By
linearity of expectation we have,
E {I(f (X) 6= Y ) − I(f ∗ (X) 6= Y )} ≤ r.
Since XL is (β1 , β2 )-Bernstein,
E {I(f (X) 6= f ∗ (X))} = E {|I(f (X) 6= Y ) − I(f ∗ (X) 6= Y )|}
n
o
= E (ℓ(f (X), Y ) − ℓ(f ∗ (X), Y ))2 , Eh2 ≤ β1 (Eh)β2
, β1 (E {I(f (X) 6= Y ) − I(f ∗ (X) 6= Y )})β2 .


By (7), E {I(f (X) 6= f ∗ (X))} ≤ β1 rβ2 . Therefore, by definition, f ∈ B f ∗ , β1 rβ2 .
176

(7)

Agnostic Pointwise-Competitive Selective Classification

So far we have seen that the set of low true error resides within a ball around f ∗ . Now
we would like to prove that with high probability the set of low empirical error (depicted
in Figure 2 (a)) resides within the set of low true error (see Figure 2 (b)). We emphasize
that the distance between hypotheses in Figure 2 (a) is based on the empirical error, while
the distance in Figure 2 (b) is based on the true error.

Figure 2: The set of low empirical error (a) resides within the set of low true error (b).
Lemma 5. For any r > 0, and 0 < δ < 1, with probability of at least 1 − δ,
V̂(fˆ, r) ⊆ V (f ∗ , 2σ (m, δ/2, d) + r) .
Proof. If f ∈ V̂(fˆ, r), then, by definition, R̂(f ) ≤ R̂(fˆ) + r. Since fˆ minimizes the empirical
error, we know that R̂(fˆ) ≤ R̂(f ∗ ). Using Theorem 1 twice, and applying the union bound,
we see that with probability of at least 1 − δ,
R(f ) ≤ R̂(f ) + σ(m, δ/2, d)

∧

R̂(f ∗ ) ≤ R(f ∗ ) + σ(m, δ/2, d).

Therefore,
R(f ) ≤ R(f ∗ ) + 2σ (m, δ/2, d) + r,
and
f ∈ V (f ∗ , 2σ (m, δ/2, d) + r) .

We have shown that, with high probability, the set of low empirical error is a subset of
a certain ball around f ∗ . Therefore, the probability that at least two hypotheses in the set
of low empirical error will disagree with each other is bounded by the probability that at
least two hypotheses in that ball around f ∗ will disagree with each other. Fortunately, the
latter is bounded by the disagreement coefficient as established in the following lemma.

177

Wiener & El-Yaniv

Lemma 6. For any r > 0 and 0 < δ < 1, with probability of at least 1 − δ,
∆V̂(fˆ, r) ≤ β1 · (2σ (m, δ/2, d) + r)β2 · θ(r0 ),
where θ(r0 ) is the disagreement coefficient of F with respect to P , applied with r0 =
(2σ(m, δ/2, d))β2 (see (5)).
Proof. Applying Lemmas 5 and 4 we get that with probability of at least 1 − δ,


V̂(fˆ, r) ⊆ B f ∗ , β1 (2σ (m, δ/2, d) + r)β2 .

Therefore,



∆V̂(fˆ, r) ≤ ∆B f ∗ , β1 (2σ (m, δ/2, d) + r)β2 .

By the definition of the disagreement coefficient (5), for any r′ > r0 , ∆B(f ∗ , r′ ) ≤ θ(r0 )r′ .
Recalling that β1 ≥ 1 and thus observing that r′ = β1 (2σ (m, δ/2, d) + r)β2 > (2σ (m, δ/2, d))β2 =
r0 , the proof is complete.
We are now in a position to state our first coverage bound for the selective classifier
constructed by LESS. This bound is given in terms of the disagreement coefficient.
Corollary 7. Let F be a hypothesis class as in Theorem 1, and assume that XL is a
(β1 , β2 )-Bernstein class w.r.t. P . Let (f, g) be the selective classifier constructed by LESS.
Then, with probability of at least 1 − δ, (f, g) is a pointwise competitive selective classifier
and
Φ(f, g) ≥ 1 − β1 · (4σ (m, δ/4, d))β2 · θ(r0 ),

where θ(r0 ) is the disagreement coefficient of F with respect to P , and r0 = (2σ(m, δ/4, d))β2 .

Proof. 
By Lemma 3, with
 probability of at least 1−δ/2, (f, g) is pointwise-competitive. Set
ˆ
G , V̂ f , 2σ (m, δ/4, d) . By construction, f = fˆ, and the selection function g(x) equals
one iff x ∈ X \ DIS (G). Thus, by the definition of coverage, Φ(f, g) = E{g(X)} = 1 − ∆G.
Therefore, applications of Lemma 6 and the union bound imply that with probability of at
least 1 − δ, (f, g) is pointwise-competitive and its coverage satisfies,
Φ(f, g) = E{g(X)} = 1 − ∆G ≥ 1 − β1 · (4σ (m, δ/4, d))β2 · θ(r0 ),

Noting that θ(r) is monotone non-increasing with r, we know that the coverage bound
of Corollary 7 clearly applies with θ(0). The quantity θ(0) has been discussed in numerous papers and has been shown to be finite in various settings including thresholds in R
under any distribution (θ(0) = 2) (Hanneke, 2009), linear
√ separators through the origin
in Rd under uniform distribution on the sphere (θ(0) ≤ d) (Hanneke, 2009), and linear
separators in Rd under smooth data distribution bounded away from zero (θ(0) ≤ c(f ∗ )d,
where c(f ∗ ) is an unknown constant that depends on the target hypothesis) (Friedman,
2009). For these cases, an application of Corollary 7 is sufficient to guarantee pointwisecompetitiveness with bounded coverage that converges to one. Unfortunately for many
hypothesis classes and distributions the disagreement coefficient θ(0) is infinite (Hanneke,
2009). Fortunately, if the disagreement coefficient θ(r) grows slowly with respect to 1/r (as
shown in Wang, 2011, under sufficient smoothness conditions), Corollary 7 is sufficient to
guarantee bounded coverage.

178

Agnostic Pointwise-Competitive Selective Classification

5. More Distribution-Dependent Coverage Bounds for LESS
In this section we establish distribution-dependent coverage bounds for LESS. The starting
point of these bounds is the following corollary.
Corollary 8. Let F be a hypothesis class as in Theorem 1, and assume that F has disagreement coefficient
θ(r0 ) = O (polylog (1/r0 ))
(8)
w.r.t. distribution P , and that XL is a (β1 , β2 )-Bernstein class w.r.t. the same distribution.
Let (f, g) be the selective classifier chosen by LESS. Then, with probability of at least 1 − δ,
(f, g) is pointwise competitive and its coverage satisfies,
!


polylog(m)
1 β2 /2
Φ(f, g) ≥ 1 − β1 · O
· log
.
m
δ
Proof. Plugging in (8) in the coverage bound of Corollary 7 immediately yields the result.

Corollary 8 states fast coverage bounds for LESS in cases where the disagreement coefficient grows slowly with respect to 1/r0 .4 Recent results on disagreement-based active
learning and selective prediction (Wiener et al., 2014; Wiener, 2013) established tight relations between the disagreement coefficient and an empirical quantity called the version space
compression set size. This quantity has been analyzed by El-Yaniv and Wiener (2010) in
the context of realizable selective classification, and there are known distribution-dependent
bounds for it. Our plan for the rest of this section is to introduce the version space compression set size, discuss its relation to the disagreement coefficient, and then show how to
apply those results in the agnostic setting.
While we are interested in solving the agnostic case, we will now consider for a moment
the realizable setting and utilize known results that will be used in our analysis. Specifically,
we now assume that ∃f ∗ ∈ F with P(Y = f ∗ (x)|X = x) = 1 for all x ∈ X , where
(X, Y ) ∼ P . Given a training sample Sm , let VSF ,S be the induced version space, i.e., the
set of all hypotheses consistent with the given sample Sm . The version space compression
set size, denoted n̂(Sm ) = n̂(F, Sm ), is defined to be the size of the smallest subset of
Sm inducing the same version space (Hanneke, 2007b; El-Yaniv & Wiener, 2010). Being a
function of Sm , clearly n̂(Sm ) is a random variable, and for any specific realization Sm its
value is unique.
For any m and δ ∈ (0, 1], define the version space compression set size minimal bound as
Bn̂ (m, δ) , min {b ∈ N : P(n̂(Sm ) ≤ b) ≥ 1 − δ} .

(9)

We rely on the following lemma (Wiener et al., 2014). For the sake of self-containment we
provide its proof in the appendix.
4

When the disagreement coefficient does not grow ploy-logarithmically with 1/r0 but is still o(1/r0 ), it is
still possible to prove a lower bound on the coverage. Specifically, if θ(r0 ) = O ((1/r0 )α ) with α < 1, one
√
can show that Φ(f, g) ≥ 1 − O(1/( m)β2 (1−α) ).

179

Wiener & El-Yaniv

Lemma 9 (Wiener et al., 2014). In the realizablecase, if Bn̂ (m,
δ) = O (polylog(m) log (1/δ)),

1
1
or Bn̂ m, 20 = O (polylog(m)), then θ(r0 ) = O polylog r0 .

Obviously, the statement of Lemma 9 only holds (and is well defined) within a realizable
setting (the version space compression set size is only defined for this setting). We now turn
back to the agnostic setting and consider an arbitrary underlying distribution P over X ×Y.
Recall that in the agnostic setting, we let f ∗ : X → Y denote a (measurable) classifier
such that R(f ∗ ) = inf f ∈F R(f ) and inf f ∈F P ((x, y) : f (x) 6= f ∗ (x)) = 0, which is guaranteed
to exist under sufficient assumptions (see Hanneke, 2012, Section 6.1); We call f ∗ an infimal
(best) hypothesis (of F, w.r.t. P ). Clearly there can be several different infimal hypotheses.
We note, however, that if XL is a (β1 , β2 )-Bernstein class with respect to P (as we assume
in this paper), then Lemma 4 ensures that all infimal hypotheses are identical up to measure
zero.
The definitions of version space and version space compression set size can be naturally
generalized to the agnostic setting with respect to an infimal hypothesis (Wiener et al.,
2014) as follows. Let f ∗ be an infimal hypothesis of F w.r.t. P . The agnostic version space
of Sm is
VSF ,Sm ,f ∗ , {f ∈ F : ∀(x, y) ∈ Sm , f (x) = f ∗ (x)}.

The agnostic version space compression set size, denoted n̂(Sm ) = n̂(F, Sm , f ∗ ), is defined
to be the size of the smallest subset of Sm inducing the agnostic version space VSF ,Sm ,f ∗ .
Finally, extend also the definition of the version space compression set minimal bound to
the agnostic setting as follows.
Bn̂ (m, δ, f ∗ ) , min{b ∈ N : P(n̂(F, Sm , f ∗ ) ≤ b) ≥ 1 − δ}.

The key observation that allows for surprisingly easy utilization of Lemma 9 in the
agnostic setting is that the disagreement coefficient depends only on the hypothesis class
F and the marginal distribution P (X). Using an infimal hypothesis f ∗ we can therefore
take any agnostic learning problem and consider its realizable “projection,” whereby points
are labeled by f ∗ and it has the same marginal distribution P (X). These two problems
will have (essentially) the same disagreement coefficients. This idea was initially observed
by Hanneke (2013) and Wiener (2013). Here we formulate it as a slight variation of the
formulation in the work of Wiener, Hanneke, and El-Yaniv (2014).
We define the disagreement in the agnostic setting as in (5) with respect to an infimal hypothesis f ∗ . For any agnostic learning problem (F, P ) we define its realizable
projection (F ′ , P ′ ) as follows. Let F ′ , F ∪ {f ∗ } where f ∗ is an infimal hypothesis of
the agnostic problem. Define P ′ to be a distribution with marginal P ′ (X) = P (X), and
P(Y = f ∗ (x)|X = x) = 1 for all x ∈ X . It is easy to verify that (F ′ , P ′ ) is a realizable
learning problem, i.e., ∃f ∗ ∈ F ′ with PP ′ (X,Y ) (Y = f ∗ (x)|X = x) = 1 for all x ∈ X .
Lemma 10 (Realizable projection). Given any agnostic learning problem, (F, P ), let
(F ′ , P ′ ) be its realizable projection. Let θ(r0 ) and θ′ (r0 ) be the associated disagreement coefficients of the agnostic and realizable projection problems, respectively. Then, θ(r0 ) ≤ θ′ (r0 ).

Proof. First note that θ and θ′ depend, respectively, on P and P ′ only via f ∗ and the
marginal distributions P (X) = P ′ (X). Since F ⊆ F ∪ {f ∗ } = F ′ , we readily get that
θ(r0 ) ≤ θ′ (r0 ).
180

Agnostic Pointwise-Competitive Selective Classification

Let us summarize the above derivation. Given an agnostic problem (F, P ), consider
its realizable projection (F ′ , P ′ ). If Bn̂ (m, δ) = O (polylog(m) log (1/δ)) (or Bn̂ (m, 1/20) =
O (polylog(m))) for the realizable problem, then by Lemma 9, θ(r0 ) = O (polylog (1/r0 )),
which, by Lemma 10, also holds in the original agnostic problem. Therefore, Corollary 7
applies and we obtain a fast coverage bound for LESS w.r.t. (F, P ).
New agnostic coverage bounds for LESS are obtained using the following known bounds
for the (realizable) version space compression set size. The first one, by El-Yaniv and Wiener
(2010), applies to the problem of learning linear separators under a mixture of Gaussian
distributions. The following theorem is a direct application of Lemma 32 in the work of
El-Yaniv and Wiener (2010).
Theorem 11 (El-Yaniv & Wiener, 2010). For any d, n ∈ N, let X ⊆ Rd , F be the space of
linear separators on Rd , and P be any distribution with marginal over Rd that is a mixture
of n multivariate normal distributions. Then, there is a constant cd,n > 0 (depending on
d, n, but otherwise independent of P ) such that ∀m ≥ 2,
Bn̂ (m, 1/20) ≤ cd,n (log(m))d−1 .
Applying Theorem 11, together with Lemma 10, Lemma 9 and Corollary 8, immediately
yields the following result.
Corollary 12. Assume the conditions of Theorem 11. Assume also that XL is a (β1 , β2 )Bernstein class w.r.t. P (X, Y ). Let (f, g) be the selective classifier constructed by LESS.
Then, with probability of at least 1 − δ, (f, g) is a pointwise competitive selective classifier
and


Φ(f, g) ≥ 1 − β1 · O (polylog(m) · log(1/δ)/m)β2 /2 .
The second version space compression set size bound concerns realizable learning of
axis-aligned rectangles under product densities over Rn . Such bounds have been previously
proposed by Wiener, Hanneke, and El-Yaniv (2014) and El-Yaniv and Wiener (2010, 2012).
We now state (without proof) a recent bound (Wiener, Hanneke, & El-Yaniv, 2014) giving
version space compression set size bound for this learning problem (whose positive class is
bounded away from zero).

Theorem 13 (Wiener et al., 2014). For d, m ∈ N and λ, δ ∈ (0, 1), let X ⊆ Rd . For any P
with marginal distribution over Rd that is a product of densities over Rd with marginals
having continuous CDFs, and for F the space of axis-aligned rectangles f on Rd with
P ((x, y) : f (x) = 1) ≥ λ,
 
8d
8d
Bn̂ (m, δ) ≤
ln
.
λ
δ
Here again, an application of Theorem 13, together with Lemma 10, Lemma 9 and Corollary 8 yields the following corollary.
Corollary 14. For d, m ∈ N and λ, δ ∈ (0, 1), let X ⊆ Rd . Let P (X, Y ) be an underlying
distribution with marginal P (X) that is a product of densities over Rd with marginals having
continuous CDFs. Let F the space of axis-aligned rectangles f on Rd with P ((x, y) : f (x) =
1) ≥ λ, Assume that XL is a (β1 , β2 )-Bernstein class w.r.t. P (X, Y ). Let (f, g) be the
181

Wiener & El-Yaniv

selective classifier constructed by LESS. Then, with probability of at least 1 − δ, (f, g) is a
pointwise competitive selective classifier and


Φ(f, g) ≥ 1 − β1 · O (polylog(m) · log(1/δ)/m)β2 /2 .

6. ERM Oracles and the Disbelief principle
At the outset, efficient construction of the selection function g prescribed by LESS seems
to be out of reach as we are required to verify, for each point x in question, whether all
hypotheses in the low error class agree on its label. Moreover, g should be computed for the
entire domain. Luckily, it is possible to compute g in a “lazy” manner and we now show
how to compute g(x) by calculating (two) constrained ERMs. For any given test point x,
we calculate the ERM over the training sample Sm with a constraint on the label of x (one
positive label constraint and one negative). We show that thresholding the difference in
empirical error between these two constrained ERMs is equivalent to tracking the supremum
over the entire (infinite) hypothesis subset. The following lemma establishes this reduction.
Lemma 15. Let (f, g) be a selective classifier chosen by LESS after observing the training
sample Sm . Let fˆ be an empirical risk minimizer over Sm . Let x be any point in X and
define
o

n
f˜x , argmin R̂(f ) | f (x) = −sign fˆ(x) ,
f ∈F

i.e., an empirical risk minimizer forced to label x the opposite from fˆ(x). Then
g(x) = 0

⇐⇒

R̂(f˜x ) − R̂(fˆ) ≤ 2σ (m, δ/4, d) .

Proof. First note that according to the definition of V̂ (see Eq (2)),


R̂(f˜x ) − R̂(fˆ) ≤ 2σ (m, δ/4, d) ⇐⇒ f˜x ∈ V̂ fˆ, 2σ (m, δ/4, d) .

(10)

(11)

To prove the first direction (⇐=) of (10), assume that the RHS of (10) holds. By (11), we
get that both fˆ, f˜x ∈ V̂. However, by construction, fˆ(x) = −f˜x (x), so x ∈ DIS(V̂) and
g(x) = 0.
To prove the other direction (=⇒), assume that R̂(f˜x ) − R̂(fˆ) > 2σ (m, δ/4, d). Under
this assumption, we will prove that for any f ′ ∈ V̂, f ′ (x) = fˆ(x), and therefore, x ∈
X \ DIS(V̂), entailing that g(x) = 1. Indeed, assume by contradiction that there exists
f ′ ∈ V̂ such that f ′ (x) = f˜x (x) 6= fˆ(x). By construction, it holds that
R̂(f ′ ) ≥ R̂(f˜x ) > R̂(fˆ) + 2σ (m, δ/4, d) ,
so f ′ 6∈ V̂. Contradiction.
Lemma 15 tells us that in order to decide if point x should be rejected we need to measure
the empirical error R̂(f˜x ) of a special empirical risk minimizer, f˜x , which is constrained to
label x the opposite from ĥ(x). If this error is sufficiently close to R̂(ĥ), our classifier cannot
be too sure about the label of x and we must reject it. Thus, provided we can compute
these ERMs, we can decide whether to predict or reject any individual test point x ∈ X ,
182

Agnostic Pointwise-Competitive Selective Classification

without actually constructing g for the entire domain X . Figure 3 illustrates this principle
for a 2-dimensional example. The hypothesis class is the class of linear classifiers in R2
and the source distribution is two normal distributions. Negative samples are represented
by blue circles and positive samples by red squares. As usual, fˆ denotes the empirical

Figure 3: Constrained ERM.
risk minimizer. Let us assume that we want to classify point x1 . This point is classified
positive by fˆ. Therefore, we force this point to be negative and calculate the restricted
ERM (depicted by doted line marked f˜x1 ). The difference between the empirical risk of fˆ
and f˜x1 is not large enough, so point x1 will be rejected. However, if we want to classify
point x2 , the difference between the empirical risk of fˆ and f˜x2 is quite large and the point
will be classified as positive.
Equation (11) motivates the following definition of a “disbelief index” DF (x, Sm ) for
each individual point in X . Specifically, for any x ∈ X , define its disbelief index w.r.t. Sm
and F,
D(x) , DF (x, Sm ) , R̂(f˜x ) − R̂(fˆ).
Observe that D(x) is large whenever our model is sensitive to the label of x in the sense
that when we are forced to bend our best model to fit the opposite label of x, our model
substantially deteriorates, giving rise to a large disbelief index. This large D(x) can be
interpreted as our disbelief in the possibility that x can be labeled so differently. In this
case we should definitely predict the label of x using our unforced model. Conversely, if
D(x) is small, our model is indifferent to the label of x and in this sense, is not committed
to its label. In this case we should abstain from prediction at x. Notice that LESS is a
specific application of thresholded disbelief index.
We note that a similar technique of using an ERM oracle that can enforce an arbitrary
number of example-based constraints was used by Dasgupta, Hsu, and Monteleoni (2007a)
and Beygelzimer, Hsu, Langford, and Zhang (2010), in the context of active learning. As
in our disbelief index, the difference between the empirical risk (or importance weighted
empirical risk, see Beygelzimer et al., 2010) of two ERM oracles (with different constraints)
is used to estimate prediction confidence.

183

Wiener & El-Yaniv

0.1

0.16
0.14

0.09
test error

test error

0.12
0.1
0.08

0.08
0.07

0.06
0.04

0.06

0.02
0

0.2

0.4

0.6

0.8

0.05
0.1

1

c

0.2

0.3

0.4

0.5

0.6

c

Figure 4: RC curve of our technique (depicted in red) compared to rejection based on
distance from decision boundary (depicted in dashed green line). The RC curve
in right figure zooms into the lower coverage regions of the left curve.

In practical applications of selective prediction it is desirable to allow for some control
over the trade-off between risk and coverage; in other words, it is desirable to be able to
develop the entire risk-coverage (RC) curve for the classifier at hand (see, e.g., El-Yaniv &
Wiener, 2010) and let the user choose the cutoff point along this curve in accordance with
other practical considerations and constraints. The disbelief index facilitates an exploration
of the risk-coverage trade-off curve for our classifier as follows. Given a pool of test points we
can rank these test points according to their disbelief index, and points with low index should
be rejected first. Thus, this ranking provides the means for constructing a risk-coverage
trade-off curve. Ignoring for the moment implementation details (which are discussed in
Section 7), a typical RC curve generated by LESS is depicted in Figure 4 (red curve)5 . The
dashed green RC curve was computed using the traditional distance-based techniques for
rejection (see discussion of this common technique in Section 8) The right graph is a zoom
in section of the entire RC curve (depicted on the left graph). The dashed horizontal line is
the test error of f ∗ on the entire domain and the dotted line is the Bayes error. While for
high coverage values the two techniques are statistically indistinguishable, for any coverage
less than 60% we get a significant advantage for LESS. It is clear that in this case not only
the estimation error was reduced, but also the test error goes significantly below the optimal
test error of f ∗ for low coverage values.
Interestingly, the disbelief index generates rejection regions that are fundamentally different than those obtained by the traditional distance-based techniques for rejection (see
Section 8). To illustrate this point (and still ignoring implementation details), consider
Figure 5 where we depict the rejection regions for a training sample of 150 points sampled
from a mixture of two identical normal distributions (centered at different locations). The
height map in this figure, which correspond to disbelief index magnitude (a), and distance
from decision boundary (b), reflect the “confidence regions” of each technique according to
its own confidence measure.
5

The learning problem is the same synthetic problem used for generating Figure 6.

184

Agnostic Pointwise-Competitive Selective Classification

(a)

(b)

Figure 5: Linear classifier. Confidence height map using (a) disbelief index; (b) distance
from decision boundary.

Figure 6: SVM with polynomial kernel. Confidence height map using (a) disbelief index;
(b) distance from decision boundary.

To intuitively explain the height map of Figure 5(a), recall that the disbelief index is
the difference between the empirical error of the ERM and the restricted ERM. If a test
point resides in a high density region, we expect that forcing the wrong label for that point
will result in a large increase of the training error. As a result, the denser the area is, the
larger the disbelief index, and therefore, the higher the classification confidence.
The second synthetic 2D source distribution we consider is even more striking. Here X
is distributed uniformly over [0, 3π] × [−2, 2] and the labels are sampled according to the
following conditional distribution

0.95, x2 ≥ sin(x1 );
P (Y = 1|X = (x1 , x2 )) ,
0.05, else.
The thick red line depicts the decision boundary of the Bayes classifier. The hight maps
in Figure 6 depict the rejection regions obtained by (our approximation of) LESS and by

185

Wiener & El-Yaniv

the traditional (distance from decision boundary) technique for a training sample of 50
points sampled from this distribution (averaged over 100 iterations). Here the hypothesis
class used for training was SVM with a polynomial kernel of degree 5. The qualitative
difference between these two techniques, and in particular, the nice fit of the disbelief
principle technique compared to SVM is quite surprising.

Figure 7: RC curves for SVM with linear kernel. Our method in solid red, and rejection
based on distance from decision boundary in dashed green. Horizontal axis (c)
represents coverage.

7. Heuristic Procedure Using SVM and its Empirical Performance
The computation of a (constrained) ERM oracle can be efficiently achieved in the case of
realizable learning with linear models (see, e.g., El-Yaniv & Wiener, 2010) and in the case
of linear regression (Wiener & El Yaniv, 2012). However, in a noisy setting the computation
of the linear ERM oracle can be reduced to a variant of the MAX FLS and C MAX FLS
problems (with strict and non-strict inequalities) (Amaldi & Kann, 1995). Unfortunately,

186

Agnostic Pointwise-Competitive Selective Classification

MAX FLS is APX-complete (within a factor 2). C MAX FLS is MAX IND SET-hard, and
cannot be approximated efficiently at all. Moreover, there are extensions of these results
to other classes, including axis-aligned hyper-rectangles, showing that approximating ERM
for these classes is NP-hard (Ben-David et al., 2003).
While at present it is not known if these hardness results (and other related lower
bounds) hold for half spaces under nice distributions such as Gaussian (mixtures), we note
that Tauman Kalai et al. (2008) studied the problem of agnostically learning halfspaces
under distributional assumptions. In particular, they showed that if the data distribution is
uniform over the d-dimensional unit sphere (or hyper-cube, and other related distributions),
4
then it is possible to agnostically learn ǫ-accurate halfspaces in time poly(d1/ǫ ). However,
it is known that these particular distributions do not elicit effective pointwise competitive
learning. On the contrary, the uniform distribution over the unit sphere is among the
worst possible distributions for pointwise-competitive classification (and disagreement-based
active learning) unless one utilizes homogeneous halfspaces (see discussion in, e.g., El-Yaniv
& Wiener, 2010).

Figure 8: SVM with linear kernel. The maximum coverage for a distance-based rejection
technique that allows the same error rate as our method with a specific coverage.

187

Wiener & El-Yaniv

Having discussed these computational hurdles, we should recall that much of applied
machine learning research and many of its applications are doing quite well with heuristic
approximations (rather than formal ones). When practical performance is the objective,
clever heuristics and tricks can sometimes make the difference. At this point in the paper
we therefore switch from theory to practice, aiming at implementing a rejection method
inspired by the disbelief principle and see how well they work on real world problems.
We “approximate” the ERM as follows. Using support vector machines (SVMs) we use
a high C value (105 in our experiments) to penalize more on training errors than on small
margin (see definitions of the SVM parameters in, e.g. Chang & Lin, 2011). In this way the
solution to the optimization problem tend to get closer to the ERM. In order to estimate
R̂(f˜x ) we have to restrict the SVM optimizer to only consider hypotheses that classify the
point x in a specific way. To accomplish this we use a weighted SVM for unbalanced data.
We add the point x as another training point with weight 10 times larger than the weight
of all training points combined. Thus, the penalty for misclassification of x is very large
and the optimizer finds a solution that doesn’t violate the constraint.
Another problem we face is that the disbelief index is a noisy statistic that highly
depends on the sample Sm . To overcome this noise we use robust statistics. First we
1 , S 2 , . . . S k ) using bootstrap sampling
generate an odd number k of different samples (Sm
m
m
(we used k = 11). For each sample we calculate the disbelief index for all test points and for
each point take the median of these measurements as the final index. We also note that for
any finite training sample the disbelief index is a discrete variable. It is often the case that
several test points share the same disbelief index. In those cases we can use any confidence
measure as a tie breaker. In our experiments we use distance from decision boundary to
break ties. Focusing on SVMs with a linear kernel we compared the RC (Risk-Coverage)
curves achieved by the proposed method with those achieved by SVM with rejection based
on distance from decision boundary. This latter approach is very common in practical
applications of selective classification. For implementation we used LIBSVM (Chang &
Lin, 2011).
We tested our algorithm on standard medical diagnosis problems from the UCI repository, including all datasets used by Grandvalet, Rakotomamonjy, Keshet, and Canu (2008).
We transformed nominal features to numerical ones in a standard way using binary indicator attributes. We also normalized each attribute independently so that its dynamic
range is [0, 1]. No other preprocessing was employed. In each iteration we choose uniformly
at random non-overlapping training set (100 samples) and test set (200 samples) for each
dataset.6 The SVM was trained on the entire training set, and test samples were sorted
according to confidence (either using distance from decision boundary or disbelief index).
Figure 7 depicts the RC curves of our technique (red solid line) and rejection based on
distance from decision boundary (green dashed line) for linear kernel on all 6 datasets. All
results are averaged over 500 iterations (error bars show standard error). With the exception
of the Hepatitis dataset, in which both methods were statistically indistinguishable, in
all other datasets the proposed method exhibits significant advantage over the traditional
approach. We would like to highlight the performance of the proposed method on the
Pima dataset. While the traditional approach cannot achieve error less than 8% for any
6

Due to the size of the Hepatitis dataset the test set was limited to 29 samples.

188

Agnostic Pointwise-Competitive Selective Classification

Figure 9: RC curves for SVM with RBF kernel. Our method in solid red and rejection
based on distance from decision boundary in dashed green.

rejection rate, in our approach the test error decreases monotonically to zero with rejection
rate. Furthermore, a clear advantage for our method over a large range of rejection rates is
evident in the Haberman dataset.7 .
For the sake of fairness, we note that the running time of our algorithm (as presented
here) is substantially longer than the traditional technique. The performance of our algorithm can be substantially improved when many unlabeled samples are available. In this
case the rejection function can be evaluated on the unlabeled samples to generate a new
“labeled” sample. Then a new rejection classifier can be trained on this sample.
Figure 8 depicts the maximum coverage for a distance-based rejection technique that
allows the same error rate as our method with a specific coverage. For example, let us
assume that our method can have an error rate of 10% with coverage of 60% and the
7

The Haberman dataset contains survival data of patients who had undergone surgery for breast cancer.
With estimated 207,090 new cases of breast cancer in the united states during 2010 (Society, 2010) an
improvement of 1% affects the lives of more than 2000 women.

189

Wiener & El-Yaniv

Figure 10: SVM with RBF kernel. The maximum coverage for a distance-based rejection
technique that allows the same error rate as our method with a specific coverage.

distance-based rejection technique achieves the same error with maximum coverage of 40%.
Then the point (0.6, 0.4) will be on the red line. Thus, if the red line is bellow the diagonal
then our technique has an advantage over distance-based rejection and visa versa. As an
example, consider the Haberman dataset, and observe that regardless of the rejection rate,
distance-based technique cannot achieve the same error as our technique with coverage
lower than 80%.
Figures 9 and 10 depict the results obtained with RBF kernel. In this case a statistically
significant advantage for our technique was observed for all datasets.

8. Related Work
Pointwise-competitive classification is a unique and extreme instance of classification with
an abstention option, an idea which emerged from the pattern recognition community, was
first proposed and studied 50 years ago by Chow (1957, 1970), and generated lots of interest

190

Agnostic Pointwise-Competitive Selective Classification

(Fumera et al., 2001; Tortorella, 2001; Santos-Pereira & Pires, 2005; Fumera & Roli, 2002;
Pietraszek, 2005; Bounsiar et al., 2006; Landgrebe et al., 2006; Herbei & Wegkamp, 2006;
Hellman, 1970; El-Yaniv & Pidan, 2011; Bartlett & Wegkamp, 2008; Wegkap, 2007; Freund
et al., 2004). Taking a broader perspective, pointwise-competitive selective prediction (and
in particular, classification) is a particular instance of the broader concept of confidencerated learning, whereby the learner must formally quantify confidence in its prediction.
Achieving effective confidence-rated prediction (including abstention) is a longstanding and
challenging goal in a number of disciplines and research communities. Let us first discuss
some of the most prominent approaches to confidence-rated prediction and note how they
related to the present work.
In the ‘knows-what-it-knows’ (KWIK) framework studied in reinforcement-learning (Li,
Littman, & Walsh, 2008; Strehl & Littman, 2007; Li & Littman, 2010) a similar notion
to pointwise competitiveness is studied, and coverage rates are analyzed (Li et al., 2008;
Li, 2009). However, KWIK was limited to the realizable model and is concerned with an
adversarial setting where both the target hypothesis and the training data are selected by
an adversary. While all positive results for the KWIK adversarial setting apply to the
statistical pointwise-competitive prediction setting (where training examples are sampled
i.i.d.), this adversarial setting precludes non trivial coverage for all the interesting hypothesis
classes currently addressed by pointwise-competitive prediction. This deficiency comes as no
surprise because the KWIK adversarial setting is much more challenging than the statistical
pointwise-competitive prediction assumptions.
The conformal prediction framework (Vovk, Gammerman, & Shafer, 2005) provides
hedged predictions by allowing the possibility of multi-labeled predictions and guarantees
a user-desired confidence rate in an asymptotic sense. Conformal prediction is mainly concerned with an online probabilistic setting. Rather than predicting a single label for each
sample point, a conformal predictor can assign multiple labels. Any user-defined confidence level ǫ for the error rate can be asymptotically guaranteed. When interpreting these
multi-labeled predictions as rejection, we can compare it to pointwise-competitive prediction. In this sense, conformal prediction can construct online predictors with a reject option
that have asymptotic performance guarantees. A few important differences between conformal predictions and pointwise-competitive prediction can be pointed out. While both
approaches provide “hedged” predictions, they use different notions of hedging. Whereas
in pointwise-competitive prediction the goal is to guarantee that with high probability over
the training sample our predictor agrees with the best predictor in the same class over all
points in the accepted domain, the goal in conformal predictions is to provide guarantees
for the average error rate, where the average is taken over all possible samples and test
points.8 In this sense, conformal prediction cannot achieve pointwise competitiveness. In
addition, conformal prediction also utilizes a different notion of error than the one used in
the pointwise-competitive model. While pointwise-competitive prediction is focused on performance guarantees for the error rate only on the covered (accepted) examples, conformal
prediction provides a guarantee for all examples (including those that have multiple predictions or none at all). By increasing the multi-labeled prediction rate (uncertain prediction),
8

As noted by Vovk et al.: “It is impossible to achieve the conditional probability of error equal to ǫ given the
observed examples, but it is the unconditional probability of error that equals ǫ. Therefore, it implicitly
involves averaging over different data sequences...” (Vovk et al., 2005, p. 295).

191

Wiener & El-Yaniv

the error rate can be decreased to any arbitrarily small value. This is not the case with the
pointwise-competitive prediction error notion on the covered examples, which is bounded
below by the Bayes error on the covered region. Finally, conformal prediction mentions
a notion of efficiency, which is similar to coverage but, to the best of our knowledge, no
finite sample results have been established. Another interesting scheme in the vicinity of
confidence-rated learning is the the guaranteed error machine (GEM) (Campi, 2010). In
the GEM model the reject option is considered as a correct answer, which means that risk
can be reduced arbitrarily (as in conformal prediction).
Pointwise-competitive classification is a special case of pointwise-competitive prediction
(El-Yaniv & Wiener, 2010, 2011; Wiener & El Yaniv, 2012; El-Yaniv & Wiener, 2012;
Wiener, 2013; Wiener et al., 2014). Pointwise-competitive selective classification was first
addressed by El-Yaniv and Wiener (2010) where the realizable case was studied (in that
paper pointwise-competitiveness was termed “perfect classification”). The present article
extends pointwise-competitive classification to noisy problems
There are also a number of theoretical studies of (general) selective classification (not
pointwise-competitive). Freund et al. (2004) studied a simple ensemble method for binary
classification. Given a hypothesis class F, the method outputs a weighted average of all
the hypotheses in F, where the weight of each hypothesis exponentially depends on its
individual training error. Their algorithm abstains from prediction whenever the weighted
average of all individual predictions is close to zero. They were able to bound the probability
of misclassification by 2R(f ∗ ) + ǫ(m) and, under some conditions, they proved a bound of
5R(f ∗ ) + ǫ(F, m) on the rejection rate. The LESS strategy can be viewed as an extreme
variation of the Freund et al. method. We include in our “ensemble” only hypotheses with
sufficiently low empirical error and we abstain if the weighted average of all predictions is
not definitive ( 6= ±1). Our risk and coverage bounds are asymptotically tighter.
Excess risk bounds were developed by Herbei and Wegkamp (2006) for a model where
each rejection incurs a cost in [0, 1/2]. Their bound applies to any empirical risk minimizer
over a hypothesis class of ternary hypotheses (whose output is in {±1, reject}). See also
various extensions by Wegkap (2007) and Bartlett and Wegkamp (2008).
A rejection mechanism for SVMs based on distance from decision boundary is perhaps
the most widely known and used rejection technique. It is routinely used in medical applications (Mukherjee et al., 1998; Guyon et al., 2002; Mukherjee, 2003). Few papers proposed
alternative techniques for rejection in the case of SVMs. Those include taking the reject
area into account during optimization (Fumera & Roli, 2002), training two SVM classifiers
with asymmetric cost (Sousa, Mora, & Cardoso, 2009), and using a hinge loss (Bartlett &
Wegkamp, 2008). Grandvalet et al. (2008) proposed an efficient implementation of SVM
with a reject option using a double hinge loss. They empirically compared their results
with two other selective classifiers: the one proposed by Bartlett and Wegkamp (2008) and
the traditional rejection based on distance from decision boundary. In their experiments
there was no statistically significant advantage to either method compared to the traditional
approach for high rejection rates.
Pointwise selective classification is strongly tied to disagreement-based active learning.
For the realizable case, El-Yaniv and Wiener (2012) presented a reduction of stream-based
active learning with the CAL algorithm of Cohn et al. (1994) to pointwise-competitive
classification. This reduction roughly states that if the rejection rate (the reciprocal of

192

Agnostic Pointwise-Competitive Selective Classification

coverage) of LESS is O(polylog(m/δ)/m) then the problem (F, P ) is actively learnable
by CAL with exponential speedup. A consequence of this reduction resulted in the first
exponential speedup bounds for CAL with general linear models under any finite mixture
of Gaussians. The other direction, showing that exponential speedup for CAL implies the
above rejection rate for LESS (in the realizable setting) was recently established by Wiener
(2013) and by Wiener, Hanneke, and El-Yaniv (2014) (using two different techniques).
The version space compression set size, which is extensively utilized in the present
work, has been introduced implicitly by Hanneke (2007b) as a special case of the extended
teaching dimension, and in that context, the version space compression set is called the
minimal specifying set. It was introduced explicitly by El-Yaniv and Wiener (2010) in the
context of selective classification, and was proved by El-Yaniv and Wiener (2012) to be a
special case of the extended teaching dimension of Hanneke (2007b). Relations between
the disagreement coefficient and the version space compression set size were first discussed
El-Yaniv and Wiener (2012). Sharp ties between these two quantities, such as those stated
in Lemma 9, and others were very recently developed by Wiener, Hanneke, and El-Yaniv
(2014).

9. Concluding Remarks
We find the existence of pointwise-competitive classification quite fascinating. The striking
feature of such a classifier is that, by definition, a pointwise-competitive predictor is free
of estimation error and cannot overfit. This means that our hypothesis class can be as
expressive as we like and still we will be protected from overfitting. However, without
effective coverage bounds our pointwise-competitive classifier may refuse to predict at all
times.
The current paper, and recent studies on both selective prediction (El-Yaniv & Wiener,
2015) and active learning (Wiener, Hanneke, & El-Yaniv, 2014), place the version space
compression set size at the center of stage, as a leading quantity that can drive results and
intuition in both domains. At present, this is the only known technique able to prove fast
coverage for pointwise-competitive classification and exponential label complexity speedup
for disagreement-based active learning for both general linear models under a fixed mixture
of Gaussians and axis aligned rectangles under product distributions.. Is it possible to
extend these results beyond linear classifiers and axis aligned rectangles under interesting
distribution families? For example, it is plausible that existing results for axis-aligned
rectangles can be extended to decision trees.
The formal relationship between active learning and pointwise-competitive classification
(El-Yaniv & Wiener, 2012; Wiener, 2013; Wiener et al., 2014) created a powerful synergy
that allows for migrating results between these two models. Currently, this formal connection is manifested via two links. The first, within a realizable setting, is the equivalence
of LESS-based classification with fast coverage to CAL-based active learning with exponential speedup. The second link consists of bounds that relate the underlying complexity
measures: the disagreement coefficient in active learning, and version space compression
set size in pointwise-competitive classification. A number of other non-established relations that can significantly substantiate the interaction between the two problems could be
considered. For example, is it possible to prove a direct equivalence between LESS-based

193

Wiener & El-Yaniv

pointwise-competitive agnostic classification with fast coverage rates and LESS-based active
learning with exponential speedup? We expect that a resolution of this question will have
various interesting implications. For example, such a relationship could potentially facilitate
the migration of very interesting algorithms and techniques devised for active learning to
the pointwise-competitive framework. An immediate candidate is the algorithm of Beygelzimer et al. (2010), which builds on ideas of Dasgupta et al. (2007b) and Beygelzimer et al.
(2009). Resembling the implementation proposed for LESS via calls to (a constrained) ERM
oracle, this algorithm works without tracking the version space for both the final choice of
the hypothesis as well as the querying component. Instead, for querying, it relies on an
ERM oracle that enforces at most one example-based constrain. Thus, the importanceweighting technique on which it is based resembles the disbelief principle we outline here.
In this regard, it will be very interesting to also consider and migrate ideas from active
learning algorithms emerging from the online learning branch (Orabona & Cesa-Bianchi,
2011; Cesa-Bianchi et al., 2009; Dekel et al., 2010) while using, as required, online to batch
conversion techniques (Zhang, 2005; Kakade & Tewari, 2009; Cesa-Bianchi & Gentile, 2008;
Dekel, 2008).
The LESS strategy requires a unanimous vote among all hypotheses in a low empirical
error subset of the hypothesis class. When considering, e.g., linear models, this subset of
hypotheses is uncountable, and in any case (even if it is finite) its size can be huge. Clearly,
LESS is an extremely radical and defensive strategy. An immediate question that arises
is whether the LESS unanimity requirement can be relaxed to a majority vote. Can we
achieve pointwise competitiveness with only a (strong) majority vote instead of unanimity?
Besides the greater flexibility of a general voting scheme, which may lead to different types
of interesting learning algorithms, such a relaxation can potentially ease the computational
complexity of implementing LESS (which, as discussed above, is a bottleneck in agnostic
classification). For example, with a relaxed voting scheme we might utilize hypothesis
sampling, for which a classical example in a related context is the celebrated query-bycommittee (QBC) strategy (Seung et al., 1992; Freund et al., 1997; Fine et al., 2002; GiladBachrach, 2007; Gilad-Bachrach et al., 2005). However, if strict pointwise competitiveness
is advocated, it is easy to see any strong majority vote is not sufficient. Indeed, consider an
f ∗ that differs from all other hypotheses in F on a single point in X . Unless the probability
of this point is very large (not the typical case), with high probability this point is not part
of the training set Sm , and therefore, any majority vote (even very strong) will label it the
opposite of f ∗ . Hence, in the worst case, even a strong majority is not sufficient for pointwise
competitiveness. As a natural compromise for the pointwise competitiveness objective, one
can revert to standard excess-risk bounds (Bartlett et al., 2006) whereby we compare the
overall average performance of our predictor, R(f ), to that of the optimal predictor, R(f ∗ )
(not pointwise). In this regard, the work of Freund, Mansour, and Schapire (2004) discussed
in Section 8, is such a result with its excess-risk bound R(f, g) ≤ 2R(f ∗ 
) + O 1/(m1/2−θ)
√
(θ is a hyper-parameter) and coverage bound Φ(f, g) ≥ 1 − 5R(f ∗ ) − O ln |F|/ m1/2−θ .
Considering excess-risk bounds against f ∗ , is it possible to beat the above risk and coverage
bounds using a relaxed voting scheme for rejection? What would be the optimal bounds
in a fully agnostic setting? Can better bounds be devised for specific distributions like
Gaussian mixtures? We note that the Freund et al. strategy is also interesting because

194

Agnostic Pointwise-Competitive Selective Classification

the final aggregated predictor is in general outside of F and can, in principle, significantly
outperform f ∗ ∈ F (the above bound does not elicit such a behavior). This emphasizes the
potential usefulness of ensembles, applied not only in the rejection scheme, but also in the
final predictor. Recall that in the LESS strategy the final predictor always belongs to F.
Thus, when considering ensembles and allowing excess-risk bounds, there can be even more
ambitious goals, such as strictly beating f ∗ on average.

Acknowledgments
We thank the anonymous referees for their good comments, and are grateful to Steve Hanneke for helpful and insightful discussions. Also, we warmly thank the Intel Collaborative
Research Institute for Computational Intelligence (ICRI-CI), and Israel Science Foundation
(ISF) for their generous support.

Appendix A. Some Proofs
The proof of Lemma 9 below relies on the following Lemma 16 (Wiener et al., 2014), whose
proof is also provided here for the sake of self-containment.

Lemma 16 (Wiener et al., 2014). In the realizable case, for any r0 ∈ (0, 1),


 
1
1
,
, 512 .
θ(r0 ) ≤ max max 16Bn̂
r 20
r∈(r0 ,1)


Proof. We will prove that, for any r ∈ (0, 1),

 


∆B(f ∗ , r)
1
1
≤ max 16Bn̂
,
, 512 .
r
r 20

(12)

The result then follows by taking the supremum of both sides over r ∈ (r0 , 1).
Fix r ∈ (0, 1), let m = ⌈1/r⌉, and for i ∈ {1, . . . , m}, define Sm\i = Sm \ {(xi , yi )}. Also
define Dm\i = DIS(VSF ,Sm\i ∩ B(f ∗ , r)) and ∆m\i = P(xi ∈ Dm\i |Sm\i ) = P (Dm\i × Y).
If ∆B(f ∗ , r)m ≤ 512, (12) clearly holds. Otherwise, suppose ∆B(f ∗ , r)m > 512. If xi ∈
DIS(VSF ,Sm\i ), then we must have (xi , yi ) ∈ CˆSm . So

n̂(Sm ) ≥

m
X
i=1

1

DIS(VSF ,Sm\i ) (xi ).

195

Wiener & El-Yaniv

Therefore,
P {n̂(Sm ) ≤ (1/16)∆B(f ∗ , r)m}
)
(m
X
∗
≤P
DIS(VSF ,S
) (xi ) ≤ (1/16)∆B(f , r)m
1

≤P
=P

m\i

i=1
(m
X

Dm\i (xi )

1

i=1
(m
X

≤ (1/16)∆B(f , r)m

DIS(B(f ∗ ,r)) (xi )

1

i=1

=P

(

m
X

−

DIS(B(f ∗ ,r)) (xi )

−

1

1

+P

1

i=1
m
X

≤P

−

DIS(B(f ∗ ,r)) (xi )
i=1
m
X

i=1
(m
X

i=1
(m
X
1

1

)

∗

1

1

Dm\i (xi )

Dm\i (xi )

≥

m
X

+P

DIS(B(f ∗ ,r)) (xi )

i=1

m
X

1
∆B(f ∗ , r)m,
DIS(B(f ∗ ,r)) (xi ) −
16
1

Dm\i (xi )

m
X

1

1

i=1

− (1/16)∆B(f , r)m

)
7
∗
DIS(B(f ∗ ,r)) (xi ) < ∆B(f , r)m
8

≥

1
∆B(f ∗ , r)m,
DIS(B(f ∗ ,r)) (xi ) −
16

DIS(B(f ∗ ,r)) (xi )

)

≥

m
X
i=1

)

1

)
7
∗
DIS(B(f ∗ ,r)) (xi ) ≥ ∆B(f , r)m
8

< (7/8)∆B(f ∗ , r)m

i=1

(

1

∗

DIS(B(f ∗ ,r)) (xi )

i=1

−

1

Dm\i (xi )

∗

)

≥ (13/16)∆B(f , r)m

.

Since we are considering the case ∆B(f ∗ , r)m > 512, a Chernoff bound implies
!
m
X
∗
≤ exp {−∆B(f ∗ , r)m/128} < e−4 .
P
DIS(B(f ∗ ,r)) (xi ) < (7/8)∆B(f , r)m
1

i=1

Furthermore, Markov’s inequality implies
P

m
X

1

DIS(B(f ∗ ,r)) (xi )

i=1

−

1

Dm\i (xi )

!

≥ (13/16)∆B(f ∗ , r)m
≤

m∆B(f ∗ , r) − E

hP
m

i=1

1

Dm\i (xi )

(13/16)m∆B(f ∗ , r)

Since the xi values are exchangeable,
#
"m
m
m

h h
ii X
X
X





E E Dm\i (xi )Sm\i =
E ∆m\i = mE ∆m\m .
E
Dm\i (xi ) =
1

i=1

1

i=1

i=1

196

i

.

Agnostic Pointwise-Competitive Selective Classification

it can be shown (Hanneke, 2012) that this is at least
m(1 − r)m−1 ∆B(f ∗ , r).
In particular, when ∆B(f ∗ , r)m > 512, we must have r < 1/511 < 1/2, which implies
(1 − r)⌈1/r⌉−1 ≥ 1/4, so that we have
#
"m
X
∗
E
Dm\i (xi ) ≥ (1/4)m∆B(f , r).
1

i=1

Altogether, we have established that
P (n̂(Sm ) ≤ (1/16)∆B(f ∗ , r)m) <

m∆B(f ∗ , r) − (1/4)m∆B(f ∗ , r)
+ e−4
(13/16)m∆B(f ∗ , r)
12
=
+ e−4 < 19/20.
13


1
Thus, since n̂(Sm ) ≤ Bn̂ m, 20
with probability at least 19/20, we must have that


∆B(f ∗ , r)
1
.
Bn̂ m,
> (1/16)∆B(f ∗ , r)m ≥ (1/16)
20
r

Proof of Lemma 9. Assuming that Bn̂ (m, δ) = O polylog(m) log 1δ holds, there exists
a constant δ1 ∈ (0, 1/20) for
Because Bn̂ (m, δ) is non which Bn̂ (m, δ1 ) = O (polylog(m)).

1
1
≤ Bn̂ (m, δ1 ), and thus Bn̂ m, 20
= O (polylog(m)). Therefore,
increasing with δ, Bn̂ m, 20




 

1
1
max Bn̂ m,
= O max polylog(m) = O polylog
,
20
r0
m≤1/r0
m≤1/r0
and using Lemma 16 we have,




1
θ(r0 ) ≤ max
max 16Bn̂ m,
, 512
20
m≤⌈1/r0 ⌉



 

1
1
.
= O polylog
≤ 528 + 16 max Bn̂ m,
20
r0
m≤1/r0

References
Amaldi, E., & Kann, V. (1995). The complexity and approximability of finding maximum
feasible subsystems of linear relations. Theoretical computer science, 147 (1), 181–210.
Bartlett, P. L., Jordan, M. I., & McAuliffe, J. D. (2006). Convexity, classification, and risk
bounds. Journal of the American Statistical Association, 101 (473), 138–156.
Bartlett, P., & Mendelson, S. (2006). Discussion of ”2004 IMS medallion lecture: Local
rademacher complexities and oracle inequalities in risk minimization” by V. koltchinskii. Annals of Statistics, 34, 2657–2663.

197

Wiener & El-Yaniv

Bartlett, P., Mendelson, S., & Philips, P. (2004). Local complexities for empirical risk
minimization. In COLT: Proceedings of the Workshop on Computational Learning
Theory, Morgan Kaufmann Publishers.
Bartlett, P., & Wegkamp, M. (2008). Classification with a reject option using a hinge loss.
Journal of Machine Learning Research, 9, 1823–1840.
Ben-David, S., Eiron, N., & Long, P. (2003). On the difficulty of approximately maximizing
agreements. Journal of Computer and System Sciences, 66 (3), 496–514.
Beygelzimer, A., Dasgupta, S., & Langford, J. (2009). Importance weighted active learning.
In Proceedings of the 26th Annual International Conference on Machine Learning, pp.
49–56. ACM.
Beygelzimer, A., Hsu, D., Langford, J., & Zhang, T. (2010). Agnostic active learning without
constraints. Advances in Neural Information Processing Systems 23.
Beygelzimer, A., Dasgupta, S., & Langford, J. (2009). Importance weighted active learning.
In Proceedings of the 26th annual international conference on machine learning, pp.
49–56. ACM.
Beygelzimer, A., Hsu, D., Langford, J., & Zhang, T. (2010). Agnostic active learning without
constraints. arXiv preprint arXiv:1006.2588.
Bounsiar, A., Grall, E., & Beauseroy, P. (2006). A kernel based rejection method for supervised classification. International Journal of Computational Intelligence, 3, 312–321.
Bousquet, O., Boucheron, S., & Lugosi, G. (2004). Introduction to statistical learning
theory. In Advanced Lectures on Machine Learning, Vol. 3176 of Lecture Notes in
Computer Science, pp. 169–207. Springer.
Campi, M. (2010). Classification with guaranteed probability of error. Mach. Learn., 80 (1),
63–84.
Cesa-Bianchi, N., & Gentile, C. (2008). Improved risk tail bounds for on-line algorithms.
Information Theory, IEEE Transactions on, 54 (1), 386–390.
Cesa-Bianchi, N., Gentile, C., & Orabona, F. (2009). Robust bounds for classification via
selective sampling. In Proceedings of the 26th Annual International Conference on
Machine Learning, pp. 121–128. ACM.
Chang, C., & Lin, C. (2011). LIBSVM: A library for support vector machines. ACM
Transactions on Intelligent Systems and Technology, 2, 27:1–27:27. Software available
at ”http://www.csie.ntu.edu.tw/ cjlin/libsvm”.
Chow, C. (1957). An optimum character recognition system using decision function. IEEE
Trans. Computer, 6 (4), 247–254.
Chow, C. (1970). On optimum recognition error and reject trade-off. IEEE Trans. on
Information Theory, 16, 41–36.
Cohn, D., Atlas, L., & Ladner, R. (1994). Improving generalization with active learning.
Machine Learning, 15 (2), 201–221.
Dasgupta, S., Hsu, D., & Monteleoni, C. (2007a). A general agnostic active learning algorithm. In NIPS.

198

Agnostic Pointwise-Competitive Selective Classification

Dasgupta, S., Monteleoni, C., & Hsu, D. J. (2007b). A general agnostic active learning
algorithm. In Advances in neural information processing systems, pp. 353–360.
Dekel, O. (2008). From online to batch learning with cutoff-averaging.. NIPS.
Dekel, O., Gentile, C., & Sridharan, K. (2010). Robust selective sampling from single and
multiple teachers.. In COLT, pp. 346–358.
El-Yaniv, R., & Pidan, D. (2011). Selective prediction of financial trends with hidden
markov models. In NIPS, pp. 855–863.
El-Yaniv, R., & Wiener, Y. (2010). On the foundations of noise-free selective classification.
Journal of Machine Learning Research, 11, 1605–1641.
El-Yaniv, R., & Wiener, Y. (2011). Agnostic selective classification. In Neural Information
Processing Systems (NIPS).
El-Yaniv, R., & Wiener, Y. (2012). Active learning via perfect selective classification.
Journal of Machine Learning Research, 13, 255–279.
El-Yaniv, R., & Wiener, Y. (2015). On the version space compression set size and its
applications. In Vovk, V., Papadopoulos, H., & Gammerman, A. (Eds.), Measures of
Complexity: Festschrift for Alexey Chervonenkis. Springer, Berlin.
Fine, S., Gilad-Bachrach, R., & Shamir, E. (2002). Query by committee, linear separation
and random walks. Theoretical Computer Science, 284 (1), 25–51.
Freund, Y., Mansour, Y., & Schapire, R. (2004). Generalization bounds for averaged classifiers. Annals of Statistics, 32 (4), 1698–1722.
Freund, Y., Seung, H., Shamir, E., & Tishby, N. (1997). Selective sampling using the query
by committee algorithm. Machine Learning, 28, 133–168.
Friedman, E. (2009). Active learning for smooth problems. In Proceedings of the 22nd
Annual Conference on Learning Theory.
Fumera, G., & Roli, F. (2002). Support vector machines with embedded reject option. In
Pattern Recognition with Support Vector Machines: First International Workshop, pp.
811–919.
Fumera, G., Roli, F., & Giacinto, G. (2001). Multiple reject thresholds for improving
classification reliability. Lecture Notes in Computer Science, 1876.
Gilad-Bachrach, R. (2007). To PAC and Beyond. Ph.D. thesis, the Hebrew University of
Jerusalem.
Gilad-Bachrach, R., Navot, A., & Tishby, N. (2005). Query by committee made real. In
NIPS.
Grandvalet, Y., Rakotomamonjy, A., Keshet, J., & Canu, S. (2008). Support vector machines with a reject option. In NIPS, pp. 537–544. MIT Press.
Guyon, I., Weston, J., Barnhill, S., & Vapnik, V. (2002). Gene selection for cancer classification using support vector machines.. Machine Learning, 389–422.
Hanneke, S. (2007a). A bound on the label complexity of agnostic active learning. In ICML,
pp. 353–360.

199

Wiener & El-Yaniv

Hanneke, S. (2007b). Teaching dimension and the complexity of active learning. In Proceedings of the 20th Annual Conference on Learning Theory (COLT), Vol. 4539 of Lecture
Notes in Artificial Intelligence, pp. 66–81.
Hanneke, S. (2009). Theoretical Foundations of Active Learning. Ph.D. thesis, Carnegie
Mellon University.
Hanneke, S. (2013). A statistical theory of active learning. Unpublished.
Hanneke, S. (2012). Activized learning: Transforming passive to active with improved label
complexity. The Journal of Machine Learning Research, 98888, 1469–1587.
Hellman, M. (1970). The nearest neighbor classification rule with a reject option. IEEE
Trans. on Systems Sc. and Cyb., 6, 179–185.
Herbei, R., & Wegkamp, M. (2006). Classification with reject option. The Canadian Journal
of Statistics, 34 (4), 709–721.
Kakade, S., & Tewari, A. (2009). On the generalization ability of online strongly convex
programming algorithms. In Advances in Neural Information Processing Systems
(NIPS), pp. 801–808.
Koltchinskii, V. (2006). 2004 IMS medallion lecture: Local rademacher complexities and
oracle inequalities in risk minimization. Annals of Statistics, 34, 2593–2656.
Landgrebe, T., Tax, D., Paclı́k, P., & Duin, R. (2006). The interaction between classification
and reject performance for distance-based reject-option classifiers. Pattern Recognition
Letters, 27 (8), 908–917.
Li, L., & Littman, M. L. (2010). Reducing reinforcement learning to kwik online regression.
Annals of Mathematics and Artificial Intelligence, 217–237.
Li, L., Littman, M., & Walsh, T. (2008). Knows what it knows: a framework for self-aware
learning. In Proceedings of the 25th international conference on Machine learning, pp.
568–575. ACM.
Li, L. (2009). A unifying framework for computational reinforcement learning theory. Ph.D.
thesis, Rutgers, The State University of New Jersey.
Massart, P. (2000). Some applications of concentration inequalities to statistics. In Annales
de la Faculté des Sciences de Toulouse, Vol. 9, pp. 245–303. Université Paul Sabatier.
Mendelson, S. (2002). Improving the sample complexity using global data. Information
Theory, IEEE Transactions on, 48 (7), 1977–1991.
Mukherjee, S. (2003). Chapter 9. classifying microarray data using support vector machines.
In of scientists from the University of Pennsylvania School of Medicine and the School
of Engineering and Applied Science. Kluwer Academic Publishers.
Mukherjee, S., Tamayo, P., Slonim, D., Verri, A., Golub, T., Mesirov, J. P., & Poggio, T.
(1998). Support vector machine classification of microarray data. Tech. rep., AI Memo
1677, Massachusetts Institute of Technology.
Orabona, F., & Cesa-Bianchi, N. (2011). Better algorithms for selective sampling. In
Proceedings of the 28th International Conference on Machine Learning (ICML-11),
pp. 433–440.

200

Agnostic Pointwise-Competitive Selective Classification

Pietraszek, T. (2005). Optimizing abstaining classifiers using ROC analysis. In Proceedings of the Twenty-Second International Conference on Machine Learning(ICML), pp.
665–672.
Santos-Pereira, C., & Pires, A. (2005). On optimal reject rules and ROC curves. Pattern
Recognition Letters, 26 (7), 943–952.
Seung, H., Opper, M., & Sompolinsky, H. (1992). Query by committee. In Proceedings of
the Fifth Annual Workshop on Computational Learning theory (COLT), pp. 287–294.
Society, A. C. (2010). Cancer facts & figures 2010..
Sousa, R., Mora, B., & Cardoso, J. (2009). An ordinal data method for the classification
with reject option. In ICMLA, pp. 746–750. IEEE Computer Society.
Strehl, A. L., & Littman, M. L. (2007). Online linear regression and its application to
model-based reinforcement learning. In Advances in Neural Information Processing
Systems, pp. 1417–1424.
Tauman Kalai, A., Klivans, A., Mansour, Y., & Servedio, R. (2008). Agnostically learning
halfspaces. SIAM J. Comput., 37 (6), 1777–1805.
Tortorella, F. (2001). An optimal reject rule for binary classifiers. Lecture Notes in Computer
Science, 1876, 611–620.
Tsybakov, A. (2004). Optimal aggregation of classifiers in statistical learning. Annals of
Mathematical Statistics, 32, 135–166.
Vovk, V., Gammerman, A., & Shafer, G. (2005). Algorithmic Learning in a Random World.
Springer, New York.
Wang, L. (2011). Smoothness, disagreement coefficient, and the label complexity of agnostic
active learning. JMLR, 2269–2292.
Wegkap, M. (2007). Lasso type classifiers with a reject option. Electronic Journal of
Statistics, 1, 155–168.
Wiener, Y. (2013). Theoretical Foundations of Selective Prediction. Ph.D. thesis, Technion
— Israel Institute of Technology.
Wiener, Y., & El Yaniv, R. (2012). Pointwise tracking the optimal regression function. In
Advances in Neural Information Processing Systems 25, pp. 2051–2059.
Wiener, Y., Hanneke, S., & El-Yaniv, R. (2014). A compression technique for analyzing
disagreement-based active learning. arXiv preprint arXiv:1404.1504.
Zhang, T. (2005). Data dependent concentration bounds for sequential prediction algorithms. In Learning Theory, pp. 173–187. Springer.

201

Journal of Artificial Intelligence Research 52 (2015) 287-329

Submitted 10/14; published 02/15

Revision by History
Paolo Liberatore

liberato@dis.uniroma1.it

Sapienza University of Rome, DIAG
Via Ariosto 25, 00185 Rome, Italy

Abstract
This article proposes a solution to the problem of obtaining plausibility information,
which is necessary to perform belief revision: given a sequence of revisions, together with
their results, derive a possible initial order that has generated them; this is different from
the usual assumption of starting from an all-equal initial order and modifying it by a sequence of revisions. Four semantics for iterated revision are considered: natural, restrained,
lexicographic and reinforcement. For each, a necessary and sufficient condition to the existence of an order generating a given history of revisions and results is proved. Complexity
is proved coNP complete in all cases but one (reinforcement revision with unbounded sequence length).

1. Introduction
Many belief revision operators are based on some sort of plausibility order (Spohn, 1988;
Boutilier, 1996; Nayak, 1994; Williams, 1994; Areces & Becher, 2001; Zhang, 2004; Benferhat, Kaci, Le Berre, & Williams, 2004; Hild & Spohn, 2008; Fermé & Hansson, 2011).
Whenever revising can be done in two or more different ways, the result is the disjunction of
either all of them (Alchourròn & Makinson, 1982; Fagin, Ullman, & Vardi, 1983; Winslett,
1988) or the most plausible ones only according to the order (Gärdenfors, 1988; Katsuno
& Mendelzon, 1991; Peppas, 2008; Nebel, 1992; Fermé & Hansson, 2011). Fewer disjuncts
imply more formulae; therefore, the more discriminating the order, the more informative
the result. A fine-grained order is central to the usefulness of the revised knowledge base.
Iterated revision provides itself a way for obtaining a plausibility order. Even starting
from an all-equal plausibility order (the least discriminating one), each revision changes it by
making some possibilities more plausible than others (Spohn, 1988; Boutilier, 1996; Nayak,
1994; Williams, 1994; Booth & Meyer, 2006; Jin & Thielscher, 2007). A sequence of revisions
produces an order that, depending on the revising formulae, is more or less informative. In
some cases, this is a solution to the problem of obtaining a plausibility order: by a sequence
of previous revisions (Konieczny & Pino Pérez, 2000; Baltag, Gierasimczuk, & Smets, 2011).
However, even a long history of revisions may not produce a fine discrimination. In a limit
case, after revising by a, ¬a, a, ¬a, etc., the final order only discriminates models of a from
models of ¬a.
Is there any other way to obtain an initial plausibility order? One possibility is to derive
it from knowledge of the previous results (this can also be done for merging, Liberatore,
2014b, 2014a). In other words, not only the previous revising formulae are given, but also
the results they produced. If K0 is the initial knowledge base and P1 the first revising
formula, the result is another knowledge base K1 , which can be further revised by P2 . In
this article, all Ki ’s and Pi ’s are assumed known up to a certain point:
c
°2015
AI Access Foundation. All rights reserved.

Liberatore

P

P

P

P

1
2
3
n
K0 −→
K1 −→
K2 −→
K3 . . . Kn−1 −→
Kn

Such a sequence of consistent formulae [K0 , P1 , K1 , . . . , Pn , Kn ] is called a revision sequence. It gives information about the initial plausibility order over models, like the following example shows.
Example 1 Let [K0 , P1 , K1 ] be the revision sequence where:
K0 = a
P1 = ¬a
K1 = ¬a ∧ b ∧ c
This specific K1 = ¬a ∧ b ∧ c is not the only possible result of revising K0 = a by
P1 = ¬a. While for example ¬a ∧ ¬b ∧ c was also possible, ¬a ∧ b ∧ c is the actual revision
result. This means that the model {¬a, b, c} was considered more plausible than {¬a, ¬b, c},
another model of P1 . This information can be useful in subsequent revisions.
A revision sequence may be seen as a form of training: the first n revisions are manually performed by human operators, the following others are done automatically using the initial plausibility order obtained from the training. Technically, from the revision sequence [K0 , P1 , K1 , . . . , Pn , Kn ] containing the revising formulae and their resulting
knowledge bases up to Kn , one derives an initial plausibility order, which is revised by
P1 , . . . , Pn , Pn+1 , Pn+2 , . . . to obtain Kn+1 , Kn+2 , . . . A similar mechanism has been studied
by Nittka and Booth (2008); a comparison with their approach is in the conclusions.
Example 2 As a part of a research project, PhD student Polyxena is tasked with automating the incorporation of new data in a database, a process so far manually performed by the
database maintainers, a specialized group of people. She soon realizes that the information
to be incorporated may be disjunctive, so that revisions may be done in multiple ways. Introducing data in the form “either ¬a or ¬b” when both a and b are in the database requires
erasing either a, b or both. Studying the relevant literature on the topic, she finds out that
such choices require plausibility information. Since the previous revisions were performed by
the database maintainers, they possess this information. She therefore asks them about the
rank of the models, getting answers ranging from “what do you mean?” to “I rank Brazilian
redhead models at the top, but Swiss models are not bad”. After spending half an hour trying
to explain to them the concepts of plausibility, consistency, propositional models (and how
they differ from “fashion models”) and ranking, she gives up.
When she is about to leave the room, one of the maintainers suggests to her to have
a look at the logs, since these files record everything that happened to the database. She
does, and indeed all previous revisions are stored in the logs: both the new information
and how the database maintainers incorporated it. The problem now shifts from eliciting
a rank from the database maintainers, which proved difficult, to determining it from the
previous history of revisions. She finds out that the sequence of revisions and results is
natural-compatible (Definition 4) but not compatible with the other revisions. This means
288

Revision by History

that not only an initial plausibility order can be calculated using Lemma 2, but also that the
people who performed the previous revisions had (unknowingly) adopted a policy of minimal
plausibility change.
Apart from the remarks of the operators, admittedly surreal for comedic purposes, the
example shows a not-so-uncommon scenario: a process performed by hand is to be automated, and eliciting information from the people who have performed it so far is difficult.
First, this information may have never been expressed in an explicit form; second, it may
be hard to formalize for people lacking a background in formal logic.
In the case of belief revision, the information needed to perform the subsequent revisions
is the initial order of the models. However, eliciting an order is not as easy as it may seem, as
shown by research on the similar concept of preference (Sandholm & Conen, 2010; Carson &
Louviere, 2011), not to mention the experimental results in cognitive psychology (Tversky
& Kahneman, 1983): after being given some background information, the majority of the
participants in a test reckoned “Linda is a bank teller and is active in the feminist movement”
to be more likely than “Linda is a bank teller”, while probability theory forbids a ∧ b to be
more likely than a.
Furthermore, providing plausibility information is an additional work for the people who
have manually performed the process so far. Instead, as Example 1 shows, some information
may be derived from the previous history of revisions.
Another example is in data synchronization: the SyncML protocol (OMA, 2002) allows
synchronizing data (phonebook, calendar notes, etc.) between a mobile phone and a computer, but conflicts may arise; an implementation may then ask the user what to do, or
take a decision (like “phone always wins”) which may however be later manually reversed
by the user. Either way, the result tells how the conflict should have been solved. Again,
both the revising formula and the resulting knowledge base are given, and can be used to
derive information about the unknown plausibility order.
As Example 1 shows,
from the knowledge of a revision sequence
[K0 , P1 , K1 , P2 , K2 , . . . , Pn , Kn ] some information about the initial plausibility of models
can be derived. Such an information depends on the revision semantics, and some sequences
are not generated at all by some semantics.
Example 3 Let [K0 , P1 , K1 , P2 , K2 , P3 , K3 ] be the revision sequence defined as follows.
K0 = a
P1 = b
K1 = a ∧ b
P2 = c
K2 = a ∧ b ∧ c
P3 = ¬a
K3 = ¬a
It will be shown that there exists an initial order of the models that generates this sequence
using the natural revision semantics. By contrast, no order generates it with the restrained
and lexicographic semantics.
289

Liberatore

The technical results provided by this article are: first, equivalent formulations for the
problem of establishing the existence of an order generating a revision sequence using the
natural, lexicographical, restrained and reinforcement revision; second, how an initial order
can be built if one exists; third, a complexity characterization.
Since the number of models is exponential in the number of variables, “there exists an
order over models such that . . . ” is a quantification over a data structure that may be
exponential in size. As a result, brute-force search takes double exponential time. The
equivalent formulations avoid this high computational cost by recasting the problem in
terms of polynomial-size data structures.
The problem of establishing the existence of an initial order generating a given sequence
is coNP-complete in all cases but one (reinforcement revision with unbounded sequence
length), therefore showing that the problem can be expressed as the validity of a ∀QBF.
This proves that the problem can be recast in a form that does not contain the existential
quantification over the initial order.

2. Preliminaries
Belief revision as considered in this article is on propositional formulae built on a finite
alphabet of variables. A truth evaluation over such an alphabet is called a model: a function
from the variables to either true or false. Following a common terminology of propositional
logic, if a model satisfies a formula then it is a model of the formula, and the formula
has that model. The set of models of a formula F is denoted Mod(F ). A QBF is a
propositional formula where the variables are quantified, either universally (like in ∀a.¬a ∧
¬b), existentially (like in ∃a∃b.a ∨ b) or both (like in ∃a∀b.a → b). When all variables are
universally quantified the formula is a ∀QBF .
A revision sequence represents the evolution of beliefs over time, including both the
revising formulae and their results.
Definition 1 A revision sequence is an odd sequence of consistent propositional formulae
[K0 , P1 , K1 , . . . , Pn , Kn ] over a finite set of variables.
The semantics for belief revision considered in this article work on an ordering of the
models, representing their relative plausibility, which is modified when new information
arrives. Such orderings can be defined as follows.
Definition 2 A total preorder C is a partition of the models into a finite sequence of classes
[C(0), C(1), C(2), . . . , C(m)] with C(0) 6= ∅.
Intuitively, such a partition represents a way to compare models: I and J compare the
same if they are in the same class, I compares greater than J if it is in a class of higher
index. The use of partitions instead of the usual notation I ≤ J simplifies definitions and
proofs. Since classes can be empty (except the first), several partitions may represent the
same way of comparing models. This is not a problem as total preorders are never checked
for equality in this article.
A total preorder can be depicted as a shelf, as in Figure 1. The bottom drawer C(0)
contains the most plausible models. These represent the situations currently believed possible: C(0) = Mod(K0 ). Revising C by P1 changes it into a new preorder CP1 that takes into
290

Revision by History

account the new information. The class CP1 (0) contains the models that are now considered
the most plausible; therefore, CP1 (0) = Mod(K1 ).

C(7)
C(6)
C(5)
C(4)
C(3)
C(2)
C(1)
C(0)

Figure 1: The graphical representation of a total preorder C
Such a partition formalizes the plausibility of models: models of C(i) are more plausible
than models of C(i + 1). The lower the class, the more plausible the model; for this reason,
a total preorder is often seen as representing implausibility rather than plausibility. It is
inverse of an ordinal conditional function (Spohn, 1988): κ(I) = n if and only if I ∈ C(n).
The study of two of the semantics considered in this article involves the prefixes and
the maxsets of a sequence. Sequences are denoted using brackets [. . .]. Given a sequence of
formulae [P1 , . . . , Pn ], its h-prefix is the sequence containing only its first h − 1 formulae in
the sequence. The maxset of a sequence extends the concept of maximal consistent subsets
from sets to sequences.

maxset([P1 , . . . , Pn ]) = maxset(²; [P1 , . . . , Pn ])


 maxset([Q1 , . . . , Qi , P1 ]; [P2 , . . . , Pn ])


if Q1 ∧ · · · ∧ Qi ∧ P1 is consistent
maxset([Q1 , . . . , Qi ]; [P1 , P2 , . . . , Pn ]) =

maxset([Q1 , . . . , Qi , true], [P2 , . . . , Pn ])



otherwise
maxset([Q1 , . . . , Qn ]; ²) = [Q1 , . . . , Qn ]
A sequence of formulae used in a context where a propositional formula is expected
implicitly represents the conjunctions of its formulae. For example, a ∨ [b, ¬c, c ∨ d] means
a ∨ (b ∧ ¬c ∧ (c ∨ d)). According to this notation, Q1 ∧ · · · ∧ Qi ∧ P1 is inconsistent if and only
if [Q1 , . . . , Qi ] |= ¬P1 . As a result, [Q1 , . . . , Qi , true] can be replaced by [Q1 , . . . , Qi , ¬P1 ] in
the definition of a maxset.
By definition of prefixes and maxsets, they commute: the h-prefix of the maxset of a
sequence is the same as the maxset of the h-prefix of the same sequence. As a result, if P is
the h-th element of the sequence S then P ∈ maxset(S) if and only if P ∧maxset(prefixh (S))
is consistent.
The maxset is often written maxset(P1 , . . . , Pn ) as a shorthand of maxset([P1 , . . . , Pn ]).
A number of properties of maxsets are now shown. All proofs are in the appendix.
291

Liberatore

Lemma 1 If F is consistent and F |= maxset(P1 , . . . , Pn ), then maxset(P1 , . . . , Pn ) ≡
{Pi | 1 ≤ i ≤ n and F |= Pi }.
Lemma 2 If F is consistent and F |= maxset(P1 , . . . , Pn ), every consistent subset of
{P1 , . . . , Pn } that contains all formulae entailed by F is equivalent to maxset(P1 , . . . , Pn ).
In this article, a sequence of formulae where some of them are replaced by true is called
a subsequence. This is similar to the usual definition, with the difference that formulae
maintain their position in the sequence.
Lemma 3 If F is consistent then F 6|= maxset(P1 , . . . , Pn ) if and only if there exists a
subsequence R of [P1 , . . . , Pn ] such that:
1. R is consistent;
2. if F |= Pi then Pi ∈ R;
3. for some i, Pi 6∈ R and Pi ∧ prefixi (R) is consistent.
The conditions in the lemma are all of existential type: there exists R, there exists
a model for R, either F 6|= Pi or Pi ∈ R and Pi ∧ prefixi (R) is consistent. This proves
that checking F 6|= maxset(P1 , . . . , Pn ) can be expressed as the validity of a ∃QBF, and is
therefore in NP.
Corollary 1 If F is consistent, checking F 6|= maxset(P1 , . . . , Pn ) is in NP.
The lemma avoids constructing the maxset one formula at time by replacing the test
of satisfiability of Pi ∧ prefixi (maxset(P1 , . . . , Pn )) with F |= Pi , which is the same if F is
consistent and entails the maxset. This way, the sequence of satisfiability checks required
to build the maxset are parallelized, that is, turned into a number of validity checks that
can be performed in parallel.
In order to check F ≡ maxset(P1 , . . . , Pn ), one first checks whether F |=
maxset(P1 , . . . , Pn ), and then maxset(P1 , . . . , Pn ) |= F . Assuming that the first condition
is true, the second can be shown in coNP.
Theorem 1 If F is consistent, checking F ≡ maxset(P1 , . . . , Pn ) is in coNP.
In this article, only revisions satisfying the AGM postulate 4 are considered: K ∗ P ≡
K ∧ P if K ∧ P is consistent. Also, all formulae Pi and Ki in the sequences are assumed
consistent. When checking a sequence for being generated by some total preorder, Ki−1 ∧Pi
is consistent if and only if Ki ≡ Ki−1 ∧Pi . In particular, if the sequence is generated by some
total preorder and Ki−1 ∧Pi is consistent then by the AGM postulate Ki−1 ∧Pi is equivalent
to Ki ; conversely, if Ki ≡ Ki−1 ∧ Pi is consistent then the consistency of Ki implies that of
Ki−1 ∧ Pi . This property is important because it allows replacing a satisfiability test with
an unsatisfiability test.
292

Revision by History

⇒

P

P

-

Figure 2: Natural revision

3. Natural Revision
Natural revision (Boutilier, 1996) modifies a total preorder of plausibility of models C in
light of a new piece of information P into a new total preorder CP that is as close as possible
to the original one. In the new preorder P has to be true in all most plausible models, these
of CP (0). A minimal change of C ensuring this is setting CP (0) to be the minimal models
of P according to C, leaving the rest of the preorder unaltered.
Definition 3 The natural revision of the total preorder C by formula P is defined as the
total preorder CP that follows, where i is the minimal index such that C(i) ∩ Mod(P ) 6= ∅:
(

CP (j) =

C(i) ∩ Mod(P ) if j = 0
C(j − 1)\CP (0) otherwise

For example, CP (0) = C(i) ∩ Mod(P ), while CP (1) = C(1 − 1)\CP (0) = C(0)\CP (0).
Graphically, the change that P produces to the preorder in natural revision can be depicted
as “cutting out” the lowest models of P and placing them below the others, as shown in
Figure 2.
If CP1 ,...,Pi is the result of revising C by P1 , then P2 , etc. using natural revision, then
Mod(Ki ) = CP1 ,...,Pi (0) in the revision sequence [K0 , P1 , K1 , . . . , Pn , Kn ].
Example 4 Let C = [C(0), C(1)] be the total preorder such that:

C(0) = Mod(a)
C(1) = Mod(¬a)
Revising it by P1 = b, P2 = c and P3 = ¬a using natural revision generates the revision
sequence in Example 3. Indeed, revising C by P1 = b makes the minimal models of P1 to
form the new class zero. Since C(0) ∩ Mod(P ) 6= ∅, the index i in the definition of natural
revision is zero. The resulting preorder is therefore:
293

Liberatore

CP1 (0) = C(0) ∩ Mod(P1 ) = Mod(a ∧ b)
CP1 (1) = C(0)\CP1 (0) = Mod(a ∧ ¬b)
CP1 (2) = C(1)\CP1 (0) = Mod(¬a)
Since Mod(K1 ) = CP1 (0), it follows that K1 ≡ a ∧ b. A similar change happens when
revising by P2 = c, since CP (0) ∩ Mod(P2 ) 6= ∅, which implies i = 0.
CP1 P2 (0) = Mod(a ∧ b ∧ c)
CP1 P2 (1) = Mod(a ∧ b ∧ ¬c)
CP1 P2 (2) = Mod(a ∧ ¬b)
CP1 P2 (3) = Mod(¬a)
Again, Mod(K2 ) = CP1 P2 (0), which implies K2 ≡ a ∧ b ∧ c. The minimal models of
P3 = ¬a are the entire class CP1 P2 (3). Therefore, i = 3 and the preorder becomes:
CP1 P2 P3 (0) = Mod(¬a)
CP1 P2 P3 (1) = Mod(a ∧ b ∧ c)
CP1 P2 P3 (2) = Mod(a ∧ b ∧ ¬c)
CP1 P2 P3 (3) = Mod(a ∧ ¬b)
This proves that K3 ≡ ¬a. The revision sequence coincides with that of Example 3.
Looking at this example in the other direction, it shows that the revision sequence [a, b, a ∧
b, c, a ∧ b ∧ c, ¬a, ¬a] is generated by natural revision from some preorder. It will be proved
that this is not the case for restrained and lexicographic revisions.
The aim of this article is to establish whether a sequence is generated by some preorder,
and finding it. Unfortunately, a direct search in the space of total preorders is unfeasible:
the number of models is exponential in the number of the variables, and the number of
total preorders is therefore a double exponential. Fortunately, for natural revision this
difficulty can be overcome thanks to a necessary and sufficient condition for a sequence to
be generated by some total preorder. A number of lemmas are needed to prove it. The first
shows that the revising by a formula does not alter the relative order of models that are
not in the resulting knowledge base.
Lemma 4 If CP (0) ∩ Mod(F ) = ∅ then CP compares the models of F as C does, where CP
is the natural revision of the total preorder C with formula P .
This result can be iterated over a number of revising formulae: if the resulting knowledge
bases Ki are all inconsistent with a formula F , the relative order of models of F is not
changed. The result of a final revision by F can therefore be calculated from the original
ordering, in this case. The following lemma is formulated over a fragment of a revision
sequence because this is how it is later applied.
294

Revision by History

Lemma 5 Let [Kj , Pj+1 , . . . , Pi , Ki ] be a revision sequence generated by natural revision
from a total preorder C. If Kj ∧ Pi is consistent while none of Kj+1 ∧ Pi , . . . , Ki−1 ∧ Pi is,
then CPj+1 ,...,Pi (0) = Mod(Kj ∧ Pi ).
This lemma is similar to a result by Boutilier (1996, Thm. 17), but lifts the assumption
that all conjunctions Kj ∧ Pj+1 , . . . , Ki−2 ∧ Pi−1 are consistent. It shows that if Pi is
consistent with a previous Kj , then natural revision by Pi produces a result that can be
determined from Kj only, independent of the initial preorder. The following lemma covers
the other case, where Pi is inconsistent with all previous Kj .
Lemma 6 If the revision sequence [K0 , P1 , K1 , . . . , Pi , Ki ] is generated by natural revision
from the total preorder C and Pi is inconsistent with each of K0 , . . . , Ki−1 , then the models
of Ki are the minimal models of Pi according to C.
The last two lemmas prove that, for natural revision, Ki is equivalent to Kj ∧ Pi for
the maximal j for which this conjunction is consistent if one exists, otherwise is determined
from the initial preorder. The first is a necessary condition for the existence of a total
preorder generating the sequence.
Definition 4 A revision sequence [K0 , P1 , . . . , Pn , Kn ] is natural-compatible if, for every
i ∈ {1, . . . , n}, it holds:
1. Ki |= Pi ;
2. if j is the maximal index such that j < i and Kj ∧ Pi is consistent (if any), then
Ki ≡ Kj ∧ Pi .
If a sequence is natural-compatible then it is generated by natural revision from some
initial total preorder.
Theorem 2 If [K0 , P1 , K1 , . . . , Pn , Kn ] is natural-compatible then it is generated by natural
revision from the initial preorder C = [C(0), . . . , C(n + 1)].


 Mod(Ki )

if i ≤ n and ∀l < i . Kl ∧ Pi |= ⊥
∅
otherwise, if i ≤ n
C(i) =

 S{Mod(K ) | ∃l < j . K ∧ P 6|= ⊥} if i = n + 1
j
j
l
Natural-compatibility is not only a sufficient condition for a sequence being generated
by natural revision from some initial preorder. The following theorem proves that it is also
necessary. Therefore, it characterizes exactly the revision sequences that natural revision
generates.
Theorem 3 A revision sequence [K0 , P1 , K1 , . . . , Pn , Kn ] is generated by natural revision
from some initial total preorder if and only if it is natural-compatible.
The following example illustrates natural compatibility and its application to natural
revision.
295

Liberatore

Example 5 The revision sequence in the previous example is natural-compatible. The first
condition of natural compatibility is satisfied: K1 = a ∧ b implies P1 = b; K2 = a ∧ b ∧ c
implies P2 = c; and K3 = ¬a implies P3 = ¬a.
The last preceding formula Kj consistent with P1 = b is K0 = a, and indeed K1 =
K0 ∧ P1 = a ∧ b. The last preceding formula Kj consistent with P2 = c is K1 = a ∧ b, and
indeed K2 = K1 ∧ P2 = a ∧ b ∧ c. Finally, P3 = ¬a is consistent with none of K0 , K1 , K2 .
Therefore, the second condition of natural compatibility places no constraint on it.
Theorem 2 not only proves that the revision sequence is generated by natural revision
from some preorder, but it also provides one: C(0) = Mod(a), C(1) = Mod(¬a). This was
indeed the preorder used in the previous example to generate the sequence.
Natural compatibility can be rewritten as a number of satisfiability and unsatisfiability
tests. In particular, that j is the maximal index having the property can be written as:
Kj ∧ Pi is consistent and Kh ∧ Pi is not, for j < h < i. This way, no satisfiability check is
dependent on another, so the problem can be solved with two parallel calls to an NP oracle,
one positive and one negative. The assumption that formulae in revision sequences are all
consistent allows rewriting the first.
Lemma 7 Checking the existence of a total preorder C generating a revision sequence
[K0 , P1 , K1 , . . . , Pn , Kn ] using natural revision is in coNP.
The problem is also hard for coNP. Therefore, it is coNP complete.
Theorem 4 The problem of establishing the existence of a preorder generating a revision
sequence using natural revision is coNP complete.

4. Restrained Revision
Restrained revision (Booth & Meyer, 2006) has in common to natural revision that when
revising a total preorder C by a formula P , the minimal models of P becomes the new class
zero. In addition, every other class is split in two according to satisfaction of P : the models
of P go in the lower class, the others in the higher.
Equivalently, every class i is refined (Papini, 2001) into classes 2i and 2i + 1, where the
first class contains the models of class i satisfying P and the second the models of class i
not satisfying P ; then, natural revision is applied.
Definition 5 The restrained revision of the total preorder C by formula P is defined as the
total preorder CP that follows, where i is the minimal index such that C(i) ∩ Mod(P ) 6= ∅
and / denotes quotient (integer division, truncated):


 C(i) ∩ Mod(P )

CP (j) =

if j = 0
(C((j − 1)/2)\CP (0)) ∩ Mod(P ) if j > 0 odd

 (C((j − 1)/2)\C (0))\Mod(P )
otherwise
P

For example,
CP (0) = C(i) ∩ Mod(P ),
CP (1) = (C((1 − 1)/2)\CP (0)) ∩
Mod(P ) = (C(0)\CP (0)) ∩ Mod(P ) and CP (2) = (C((2 − 1)/2)\CP (0))\Mod(P ) =
(C(0)\CP (0))\Mod(P ) since (2 − 1)/2 = 1/2 = 0 using integer division.
296

Revision by History

-

P

⇒

-

-

Figure 3: Restrained revision
A graphical example of the application of restrained revision to a total preorder is in
Figure 3.
The revision sequence in Example 3 is not generated by any preorder using restrained
revision. This will be proved using a necessary and sufficient condition to the existence of a
preorder generating the sequence. For now, just to illustrate how restrained revision works,
the preorder shown for natural revision is used.
Example 6 Let C be the following total preorder:
C(0) = Mod(a)
C(1) = Mod(¬a)
Restrained revision by P1 = b, P2 = c and P3 = ¬a generates a revision sequence
different than that in Example 3. Since K0 = Mod(C(0)), it follows K0 ≡ a. Revising C
by P1 = b makes the minimal models of P1 to be the new class zero and splits every other
class by b/¬b. The resulting total preorder after removing the empty classes is therefore:
CP1 (0) = Mod(a ∧ b)
CP1 (1) = Mod(a ∧ ¬b)
CP1 (2) = Mod(¬a ∧ b)
CP1 (3) = Mod(¬a ∧ ¬b)
Since Mod(K1 ) = CP1 (0), it follows that K1 ≡ a ∧ b. A similar change happens when
revising by P2 = c:
297

Liberatore

CP1 P2 (0) = Mod(a ∧ b ∧ c)
CP1 P2 (1) = Mod(a ∧ b ∧ ¬c)
CP1 P2 (2) = Mod(a ∧ ¬b ∧ c)
CP1 P2 (3) = Mod(a ∧ ¬b ∧ ¬c)
CP1 P2 (4) = Mod(¬a ∧ b ∧ c)
CP1 P2 (5) = Mod(¬a ∧ b ∧ ¬c)
CP1 P2 (6) = Mod(¬a ∧ ¬b ∧ c)
CP1 P2 (7) = Mod(¬a ∧ ¬b ∧ ¬c)
Again, Mod(K2 ) = CP1 P2 (0), which implies K2 ≡ a ∧ b ∧ c. The minimal models of
P3 = ¬a are the whole class CP1 P2 (4). The preorder therefore becomes:
CP1 P2 P3 (0) = Mod(¬a ∧ b ∧ c)
CP1 P2 P3 (1) = Mod(a ∧ b ∧ c)
CP1 P2 P3 (2) = Mod(a ∧ b ∧ ¬c)
CP1 P2 P3 (3) = Mod(a ∧ ¬b ∧ c)
CP1 P2 P3 (4) = Mod(a ∧ ¬b ∧ ¬c)
CP1 P2 P3 (5) = Mod(¬a ∧ b ∧ ¬c)
CP1 P2 P3 (6) = Mod(¬a ∧ ¬b ∧ c)
CP1 P2 P3 (7) = Mod(¬a ∧ ¬b ∧ ¬c)
As a result, K3 ≡ ¬a ∧ b ∧ c. This revision sequence coincides with that of Example 3
up to P3 but K3 is different, as K3 = ¬a in the previous example. It will be shown that no
preorder generates that sequence using restrained revision.
The following property is similar to Lemma 5 of natural revision, with the difference
that a maxset is introduces to account for the class split.
Lemma 8 Let [Kj , Pj+1 , . . . , Pi , Ki ] be a revision sequence generated by restrained revision
from the initial total preorder C. If Kj ∧ Pi is consistent while none of Kj+1 ∧ Pi , . . . ,
Ki−1 ∧ Pi is, then CPj+1 ,...,Pi (0) = Mod(maxset(Kj ∧ Pi , Pj+1 , . . . , Pi−1 )).
This result is the first half of a necessary and sufficient condition for a sequence being
generated by restrained revision from some preorder, which involves the following definition.
Definition 6 A revision sequence [K0 , P1 , K1 . . . , Pn , Kn ] is restrained-compatible if, for
every i ∈ {1, . . . , n}, it holds:
1. Ki |= Pi ;
2. Ki ≡ maxset(Kj ∧ Pi , Pj+1 , . . . , Pi−i ) if j is the maximal index such that j < i and
Kj ∧ Pi is consistent, if any;
298

Revision by History

3. either Ki |= Pl or Ki |= ¬Pl for every l < i if no such j exists.
As a side remark, the condition that either Ki |= Pl or Ki |= ¬Pl in the third point of
the definition refers to all indexes l < i, including the ones for which Kl is consistent with
a previous Kj .
If a revision sequence is restrained-compatible it is generated by restrained revision from
some initial preorder. The following lemma specifies which one that is.
Lemma 9 If [K0 , P1 , K1 , . . . , Pn , Kn ] is restrained-compatible then it is generated by restrained revision from the total preorder C = [C(0), . . . , C(n + 1)], where:


 Mod(Ki )

C(i) =

if i ≤ n and ∀l < i . Pi ∧ Kl |= ⊥
otherwise, if i ≤ n

 S{Mod(K ) | ∃l < j P ∧ K 6|= ⊥} if i = n + 1
j
j
l
∅

The results proved so far can be collected into an equivalent formulation of the existence
of a preorder generating a sequence.
Theorem 5 A revision sequence [K0 , P1 , K1 , . . . , Pn , Kn ] is generated by restrained revision
from some initial total preorder if and only if it is restrained-compatible.
The sequence in Example 3 can be shown not to be restrained-compatible. Therefore,
not only it is not generated by restrained revision from the preorder that worked for natural
revision, it is not generated from any other.
Example 7 The revision sequence [K0 , P1 , K1 , P2 , K2 , P3 , K3 ] with K0 = a, P1 = b, K1 =
a ∧ b, P2 = c, K2 = a ∧ b ∧ c, P3 = ¬a, K3 = ¬a is not restrained-compatible (this is
the sequence of Example 3). Indeed, P3 = ¬a is inconsistent with each of K0 , K1 and K2 ,
yet K3 = ¬a entails neither P1 = b nor ¬P1 = ¬b, thereby violating the third condition of
restrained compatibility.
The definition of restrained compatibility involves consistency and entailment checks.
The following lemma rewrites it in a form that can be shown to use only inconsistencies.
Lemma 10 A revision sequence [K0 , P1 , K1 . . . , Pn , Kn ] is restrained-compatible if and only
if, for every index i:
1. Ki |= Pi ;
2. for every 0 ≤ j < i, either Kj ∧ Pi is inconsistent or Ki |= Kl ∧ Pi for some j < l < i
or Ki ≡ maxset(Kj ∧ Pi , Pj+1 , . . . , Pi−1 );
3. for every 0 ≤ j < i, Ki |= Pj , Ki |= ¬Pj , or Ki |= Kl ∧ Pi for some 0 ≤ l < i.
Since checking equivalence of a consistent formula and a maxset is a problem in coNP
by Theorem 1, it can be expressed as a universally quantified formula. As a result, all
quantifiers in the conditions of the lemma are universal, and the whole problem is in coNP.
Hardness for the same class is easy to prove.
Theorem 6 Establishing the existence of a total preorder generating a restrained revision
sequence is coNP-complete.
299

Liberatore

5. Intermezzo: Multiple Preorders
The same revision sequence may be generated by more than one total preorder. Examples
exist even with two variables only, such as the sequence [K0 , P1 , K1 , P2 , K2 ] with K0 = a∧b,
P1 = a ∧ ¬b, K1 = a ∧ ¬b, P2 = ¬a ∧ b and K2 = ¬a ∧ b.
a∧¬b

¬a∧b

a ∧ b −→ a ∧ ¬b −→ ¬a ∧ b
According to Lemma 9, the sequence is generated by restrained revision from the initial
preorder C = [C(0), C(1), C(2), C(3)].
C(0) = Mod(a ∧ b)
C(1) = Mod(a ∧ ¬b)
C(2) = Mod(¬a ∧ b)
C(3) = Mod(¬a ∧ ¬b)
However, this is not the only preorder generating the sequence. Classes C(1) and C(2)
can be swapped, still leading to the same result.
C(0) = Mod(a ∧ b)
C(1) = Mod(¬a ∧ b)
C(2) = Mod(a ∧ ¬b)
C(4) = Mod(¬a ∧ ¬b)
Intuitively, revising by a single-model formula has always a single possible outcome:
the formula itself. As a result, even if Mod(K1 ) is now contained in a class greater than
Mod(K2 ), still the minimal models of P1 are Mod(K1 ).
In a way, this is expected: when revision can only be performed in a single possible
way, the initial preorder is irrelevant. This intuition holds for all considered revisions, and
is confirmed by further simplifying the preorder: indeed, apart from C(0), the other classes
can be shuffled in every possible way, or even merged:
C(0) = Mod(a ∧ b)
C(1) = Mod(¬a ∧ b) ∪ Mod(a ∧ ¬b) ∪ Mod(¬a ∧ ¬b)
This kind of preorder works whenever each Pi has a single model, but not in general.
Even restricting to the Pi ’s such that Pi ∧ Kj |= ⊥ for all j < i, if l < i then Pi ∧ Kl is
guaranteed to be inconsistent, but Pl ∧ Ki is not. In other words, Mod(Ki ) cannot always
be swapped or merged with Mod(Kl ).
When more than one preorder is possible, a sensible principle is to choose the least discriminating one. Such a preorder would compare I different from J only if strictly necessary
to obtain the revision sequence. In other words, it does not carry plausibility information
that does not follow from the revision sequence. Such a minimization is similar in spirit
300

Revision by History

to the way rational closure in conditional logic is the most rationally rooted consequence
relation (Lehmann & Magidor, 1992; Booth & Nittka, 2008). The last preorder shown
obeys this principle, but the question of whether a least discriminating preorder exists for
all revision sequences and all considered revision semantics is an open problem.
A different possible solution is to proceed by refutation:
if a sequence
[K0 , P1 , K2 , . . . , Pn , Kn ] is generated by a revision from some preorder but
[K0 , P1 , K2 , . . . , Pn , Kn , Pn+1 , Kn+1 ] is not, then ¬Kn+1 might be considered true
after revising by Pn+1 .
As correctly pointed out by one of the reviewers, a revision sequence may even be
generated by different revisions from different initial preorder, adding a second dimension
to the problem: not only the preorder, but also the semantics of revision has to be chosen.
The sequence shown in this example is one of this kind: it is generated by all four revision
semantics considered in this article from every initial preorder C with C(0) = Mod(a ∧ b).

6. Lexicographic Revision
In a seminal work on iterated revision, Spohn (1988) defined a tentative semantics based
on the principle that newer formulae are more plausible than older ones at all levels of
plausibility: even the most unlikely models of P are to be preferred over the most likely
of ¬P . In spite of some apparent drawbacks pointed out by its author, this semantics was
later recognized as a principled way to perform iterated revision (Nayak, 1994; Darwiche &
Pearl, 1997; Booth & Meyer, 2006; Jin & Thielscher, 2007; Konieczny & Pino Pérez, 2000).
Like the other revisions used in this article, lexicographic revision works on a total
preorder of plausibility of models C. In particular, revision by P changes it by moving all
models of P to classes of index lower than the others.
Definition 7 The lexicographic revision of a total preorder C by a formula P is defined
as the following total preorder, where i and j are respectively the indexes of the lowest and
highest classes containing models of P :
(

CP (k) =

C(k + i) ∩ Mod(P )
if k ≤ j − i
C(k − j + i − 1)\Mod(P ) otherwise

The new class zero is CP (0) = C(0 + i) ∩ Mod(P ); as expected, it comprises the minimal
models of P , since C(i) is the lowest class containing models of P . The class CP (j − i) =
C(j − i + i) ∩ Mod(P ) = C(j) ∩ Mod(P ) contains the highest-class models of P , since by
assumption these are in C(j). The models of C(0) that satisfy ¬P , if any, are moved to
class CP (j − i + 1) = C(j − i + 1 − j + i − 1)\Mod(P ) = C(0)\Mod(P ). The index is
j − i + 1 because the lower classes CP (0), . . . , CP (j − i) contain the models of P coming
from C(i), . . . , C(j).
Figure 4 shows how a total preorder C is changed by a formula P using lexicographic
revision.
Graphically, lexicographic revision “cuts out” the models of P from their classes and
wedges them under the shelf. This way, every model of P belongs to a lower class than all
models of ¬P . At the same time, the relative position of two models of P is not changed,
and the same holds for every two models of ¬P .
301

Liberatore

P

⇒
-

P

Figure 4: Lexicographic revision
Example 8 It will be shown that the sequence in Example 3 is not generated by lexicographic
revision from any total preorder. Meanwhile, to illustrate the definition of lexicographic
revision the preorder used in the example for natural revision is revised by P1 = b, P2 = c
and P3 = ¬a.
C(0) = Mod(a)
C(1) = Mod(¬a)
Revising C by P1 = b using lexicographic revision removes all models of P1 from their
classes and creates new classes for them at the bottom:
CP1 (0) = Mod(a ∧ b)
CP1 (1) = Mod(¬a ∧ b)
CP1 (2) = Mod(a ∧ ¬b)
CP1 (3) = Mod(¬a ∧ ¬b)
As a result, K1 = a ∧ b. Revising by P2 = c has a similar effect:
CP1 P2 (0) = Mod(a ∧ b ∧ c)
CP1 P2 (1) = Mod(¬a ∧ b ∧ c)
CP1 P2 (2) = Mod(a ∧ ¬b ∧ c)
CP1 P2 (3) = Mod(¬a ∧ ¬b ∧ c)
CP1 P2 (4) = Mod(a ∧ b ∧ ¬c)
302

Revision by History

CP1 P2 (5) = Mod(¬a ∧ b ∧ ¬c)
CP1 P2 (6) = Mod(a ∧ ¬b ∧ ¬c)
CP1 P2 (7) = Mod(¬a ∧ ¬b ∧ ¬c)

This preorder produces K2 = a ∧ b ∧ c. Finally, revising by P3 = ¬a and removing the
empty classes makes the classes 1, 3, 5, 7 to become the new classes 0, 1, 2, 3.
CP1 P2 P3 (0) = Mod(¬a ∧ b ∧ c)
CP1 P2 P3 (1) = Mod(¬a ∧ ¬b ∧ c)
CP1 P2 P3 (2) = Mod(¬a ∧ b ∧ ¬c)
CP1 P2 P3 (3) = Mod(¬a ∧ ¬b ∧ ¬c)
CP1 P2 P3 (4) = Mod(a ∧ b ∧ c)
CP1 P2 P3 (5) = Mod(a ∧ ¬b ∧ c)
CP1 P2 P3 (6) = Mod(a ∧ b ∧ ¬c)
CP1 P2 P3 (7) = Mod(a ∧ ¬b ∧ ¬c)

Since K3 = ¬a ∧ b ∧ c is not equivalent to ¬a, the revision sequence in Example 3 is
not generated by lexicographic revision from the initial preorder C. It will be shown that no
preorder at all generates that sequence using lexicographic revision.
For every preorder C and consistent formula P , the revised preorder CP using lexicographic revision has three properties:
1. CP (0) is the set of minimal models of P in the preorder C;
2. there exists an index h such

S

i=0,...,h CP (i)

= Mod(P );

3. if two models both satisfy P or both falsify it, CP compares them as C does.
Lexicographic revision can be recast in terms of the maxsets of the reversed sequence.
Booth and Nittka (2008) proved the following property; more precisely, what they proved
implies the following property because an arbitrary preorder [C(0), . . . , C(n)] is obtained
by revising the ordering with all models in class zero with a sequence of formulae having
C(n), . . . , C(0) as their sets of models.
Property 1 If [K0 , P1 , . . . , Kn , Pn ] is a revision sequence generated by lexicographic revision from the total preorder C, then Mod(Ki ) is the set of minimal models of
maxset(Pi , . . . , P1 ) according to C.
This property has the following consequences:
1. all models of Ki are in the same class of C;
303

Liberatore

2. all other models of maxset(Pi , . . . , P1 ) are in greater classes.
Two further properties follow. First, if Ki ∧Kj is consistent then all models in Mod(Ki )∪
Mod(Kj ) are in the same class of C. Indeed, since Ki ∧ Kj is consistent, it has a model
I; since all models of Ki are in the same class of I, and the same for Kj , all models of
these two formulae are in the same class. Second, if Kj has some models in common with
¬Ki ∧ maxset(Pi , . . . , P1 ), then all its models are in the same class of C, greater than that
of the models of Ki .
This allows shifting from a total preorder among models to a total preorder among
formulae Ki . Since this is a preorder over the formulae Ki , which are the results of the
revision process, it is called a result preorder.
Definition 8 A result preorder for the revision sequence [K0 , P1 , . . . , Pn , Kn ] is a total
preorder among its formulae Ki such that:
1. if Ki ∧ Kj is consistent then Ki and Kj are in the same class;
2. if ¬Ki ∧ Kj ∧ maxset(Pi , . . . , P1 ) is consistent then Ki is in a lower class than Kj .
The advantage of result preorders is that they can be built from the revision sequence,
as it will be shown. Before, it is proved that the existence of a result preorder is the
same as the existence of an initial total preorder over models generating the sequence by
lexicographic revision. Since two preorders are involved (one among models, one among
formulae), a distinction is made between “preorder among models C” and “preorder among
formulae R”; result preorders are of the second kind.
Lemma 11 If a revision sequence [K0 , P1 , K1 , . . . , Pn , Kn ] is generated by lexicographic
revision from the total preorder among models C then it has the result preorder R defined
by:
R(i) = {Ki | Mod(Ki ) ⊆ C(i)}
The converse also holds: from a result preorder for a revision sequence one can derive a
preorder among models that generates the sequence using lexicographic revision.
Lemma 12 If R is a result preorder for a revision sequence [K0 , P1 , K1 , . . . , Pn , Kn ] such
that Ki |= maxset(Pi , . . . , P1 ) for every i, then lexicographic revision from the following
total preorder C among models generates the revision sequence, where z is the index of the
greatest class of R:
( S

C(h) =

{Mod(Ki ) | Ki ∈ R(h)} if h ≤ z
{I | I 6∈ K1 ∪ · · · ∪ Kn }
if h = z + 1

The two lemmas together imply the following corollary.
Corollary 2 A revision sequence [K0 , P1 , . . . , Pn , Kn ] is generated by lexicographic revision
from some initial preorder among models if and only if a result preorder for the sequence
exists and Ki |= maxset(Pi , . . . , P1 ) for every i.
304

Revision by History

The condition of existence of a result preorder is already simpler than that of existence
of an initial total preorder over models, since the number of formulae Ki is linear in the size
of the revision sequence while the number of models may be exponential. The existence of
a result preorder can be further recast in terms of a condition over the revision sequence.
Definition 9 A revision sequence [K0 , P1 , . . . , Kn , Pn ] is lexicographic compatible if Ki |=
maxset(Pi , . . . , P1 ) for every i and the relations ' and < defined as follows do not form
cycles containing some < links:
• Ki ' Kj if and only if Ki ∧ Kj is consistent;
• Ki < Kj if and only if ¬Ki ∧ Kj ∧ maxset(Pi , . . . , P1 ) is consistent.
The rationale of the definition is that Ki ' Kj is the same as Ki and Kj being in the
same class of R, and Ki < Kj is the same as Ki being in a lower class. This intuition is
confirmed by the following lemma.
Lemma 13 A revision sequence is generated by lexicographic revision from some total preorder if and only if it is lexicographic compatible.
This result can be applied to the running example.
Example 9 The revision sequence presented in Example 3 is not lexicographic compatible.
Indeed, maxset(P3 , P2 , P1 ) = maxset(¬a, c, b) = ¬a ∧ c ∧ b, which is not entailed by K3 =
¬a. As a result, the revision sequence is not generated by lexicographic revision from any
preorder.
Given a revision sequence, one can determine the consistency of Ki ∧ Kj and ¬Ki ∧ Kj ∧
maxset(Pi , . . . , P1 ) for every pair of formulae Ki and Kj . The problem of non-existence of
a preorder generating the sequence is then turned into that of existence of cycles, which is
computationally easy (polynomial in the size of the revision sequence). The hard part is
checking consistency. Since the problem is polynomial if an NP oracle is available (which
turns all consistency checks into constant-time operations), the problem is in ∆p2 . However,
it can be proved to be even computationally easier than that.
Lemma 14 A revision sequence [K0 , P1 , K1 . . . , Pn , Kn ] is not lexicographic compatible if
and only if either Ki 6|= maxset(Pi , . . . , P1 ) for some i or consistent sets R1 , . . . , Rn exist
such that:
1. {Pj | 1 ≤ j ≤ i and Ki |= Pj } ⊆ Ri for every i; and
2. there exists a cycle Ki1 , . . . , Kim = Ki1 such that either Kij ∧Kij+1 or ¬Kij ∧Kij+1 ∧Ri
is consistent for all ij ∈ {i1 , . . . , im−1 }, and the second is consistent for at least one
such index.
The advantage of this reformulation of lexicographic incompatibility is that all entailment tests it contains can be reformulated in terms of consistency. This means that incompatibility is in NP. Therefore, compatibility is in coNP. It can also be shown hard for the
same class.
Theorem 7 The problem of checking the existence of a total preorder generating a revision
sequence using lexicographic revision is coNP-complete.
305

Liberatore

P

⇒
P

Figure 5: Reinforcement revision

7. Reinforcement Revision
Reinforcement revision (Jin & Thielscher, 2007) takes as input not only a total preorder
to revise C and a revising formula P , but also a parameter m that encodes the degree of
belief in P (more precisely, m is the degree of disbelief in ¬P ). For the sake of simplicity,
the restriction to the the case m = 1 is analyzed.
Definition 10 The reinforcement revision of the total preorder C by formula P and parameter m = 1 is the following total preorder CP , where i is the minimal index such that
C(i) ∩ Mod(P ) 6= ∅.
(

CP (j) =

C(i) ∩ Mod(P )
if j = 0
C(j − 1)\Mod(P ) ∪ C(j + i) ∩ Mod(P ) if j > 0

The general definition has j − m instead of j − 1; in this article, m is always 1. The two
cases can be merged into the single one CP (j) = C(j − 1)\Mod(P ) ∪ C(j + i) ∩ Mod(P ) for
all j ≥ 0 by assuming that C(−1) = ∅. For example, CP (0) = C(−1)\Mod(P ) ∪ C(i) ∩
Mod(P ) = C(i) ∩ Mod(P ), while CP (1) = C(0)\Mod(P ) ∪ C(i + 1) ∩ Mod(P ).
A graphical example of a revision is in Figure 5.
The behavior of this revision is shown on the preorder and formulae of Example 3.
Example 10 Revising the preorder C = [C(0), C(1)] where C(0) = Mod(a) and C(1) =
Mod(¬a) by P1 = b using reinforcement revision has the effect of increasing the class of
every model of ¬P1 by one; the models of P1 do not decrease of class since some of them
are already in class zero, which means that i = 0 in the definition of CP .
CP1 (0) = Mod(a ∧ b)
CP1 (1) = Mod((a ∧ ¬b) ∨ (¬a ∧ b))
CP1 (2) = Mod(¬a ∧ ¬b)

306

Revision by History

The same happens when revising by P2 = c: every class is the union of the original class
conjoined with c and of the previous class conjoined with ¬c:
CP1 P2 (0) = Mod(a ∧ b ∧ c)
CP1 P2 (1) = Mod((a ∧ b ∧ ¬c) ∨ (a ∧ ¬b ∧ c) ∨ (¬a ∧ b ∧ c))
CP1 P2 (2) = Mod((a ∧ ¬b ∧ ¬c) ∨ (¬a ∧ b ∧ ¬c) ∨ (¬a ∧ ¬b ∧ c))
CP1 P2 (3) = Mod(¬a ∧ ¬b ∧ ¬c)
The minimal class containing models of P3 = ¬a is CP1 P2 (1). Therefore, models of ¬a
are decreased of one class. Models of ¬P3 = a are increased of one class, as usual:
CP1 P2 P3 (0) = Mod((¬a ∧ b ∧ c))
CP1 P2 P3 (1) = Mod((a ∧ b ∧ c) ∨ (¬a ∧ ¬b ∧ c) ∨ (¬a ∧ b ∧ ¬c))
CP1 P2 P3 (2) = Mod((¬a ∧ ¬b ∧ ¬c) ∨ (a ∧ b ∧ ¬c) ∨ (a ∧ ¬b ∧ c))
CP1 P2 P3 (3) = Mod(a ∧ ¬b ∧ ¬c)
As a result, K3 = ¬a ∧ b ∧ c.
As for the other revision semantics, every Ki is assumed consistent; the case of inconsistent Ki is degenerated, as no preorder produces such a knowledge base.
Given a fixed revision sequence [K0 , P1 , K1 , . . . , Pn , Kn ] generated by reinforcement revision from the initial total preorder C, the lowest class index of the models of Pi in the
ordering CP1 ,...,Pi is denoted DC (i). Formally:
DC (i) = min{j | CP1 ,...,Pi−1 (j) ∩ Mod(Pi ) 6= ∅}
Revising by Pi shifts down all models of Pi of DC (i) classes and raises all other models
of one class. As a result, DC (1), . . . , DC (n) tell how a model is moved up or down at every
step, allowing to determine how a model is moved between step i and step j.
Definition 11 The movement of I from i to j according to DC in the revision sequence
[K0 , P1 , K1 , . . . , Pn , Kn ] is MDC (I, i, j) where:
• MDC (I, i, i) = 0;
• MDC (I, i, i + 1) = −DC (i + 1) if I |= Pi+1 and MDC (I, i, i + 1) = 1 otherwise;
• if j > i then MDC (I, i, j) =

P

l=i,...,j−1 MDC (I, l, l

+ 1);

• if j < i then MDC (I, i, j) = −MDC (I, j, i).
Since DC (i) is the minimal class of models of Pi at step i − 1 according to an initial preorder, MDC (I, i, j) is the change of classes between i and j when using the same
preorder. The initial preorder C affects the definition of MDC (I, i, j) only indirectly, via
the sequence DC = [DC (1), . . . , DC (n)]. As a result, MV (I, i, j) can be defined from an
arbitrary sequence of n numbers V = [V (1), . . . , V (n)].
307

Liberatore

Lemma 15 For every sequence of n numbers V = [V (1), . . . , V (n)], it holds MV (I, i, j) =
MV (I, i, h) + MV (I, h, j) for every three indexes i, j and h.
This lemma holds even if h is not between i and j.
Since MDC (I, i, j) has been defined so that it is the change of class of model I from step
i to step j, in the particular case where I |= Ki it is the class of I at step j, since that at
step i is zero.
Lemma 16 If a revision sequence [K0 , P1 , K1 , . . . , Pn , Kn ] is generated by reinforcement revision from the total preorder C and DC = [DC (1), . . . , DC (n)] with DC (i) =
min{j | CP1 ,...,Pi−1 (j) ∩ Mod(Pi ) 6= ∅} and I |= Ki then, for every j:
• MDC (I, i, j) = 0 if I |= Kj ;
• MDC (I, i, j) > 0 otherwise.
This lemma can be reversed, in the sense that a sequence of values having this property
allows to determine a preorder generating the sequence.
Definition 12 A sequence of nonnegative integer values V = [V (1), . . . , V (n)] is a reinforcement mover of the revision sequence [K0 , P1 , K1 , . . . , Pn , Kn ] if, for every i and j, if
I |= Ki then:
• MV (I, i, j) = 0 if I |= Kj ;
• MV (I, i, j) > 0 otherwise.
The previous lemma can therefore be recast as: if a sequence is generated by reinforcement revision from the total preorder C, then it has a reinforcement mover: DC . The
converse also holds: from a reinforcement mover one can determine a total preorder generating the revision sequence.
Lemma 17 If V = [V (1), . . . , V (n)] is a reinforcement mover for the revision sequence
[K0 , P1 , K1 , . . . , Pn , Kn ], the following initial preorder C = [C(0), . . . , C(V (1) + · · · + V (n +
1))] generates the revision sequence by reinforcement revision and DC = V .
(

C(j) =

{I | I |= Ki and MV (I, i, 0) = j} if j < V (1) + . . . + V (n) + 1
{I | ∀i . I 6|= Ki }
if j = V (1) + . . . + V (n) + 1

In contrast to the condition of compatibility for the other revision semantics, this one
does not explicitly require Ki |= Pi . It is however implied: if I 6|= Pi then MV (I, i − 1, i) = 1
by the definition of movement (Definition 11) and if I |= Ki then MV (I, i, j) ≥ 0 for every j
by definition of reinforcement mover (Definition 12). But in the particular case of j = i − 1
this is MV (I, i, j) = MV (I, i, i − 1) = −MV (I, i − 1, i) = −1, which is not greater than or
equal to zero. Therefore, no reinforcement mover exists if Ki 6|= Pi .
This lemma allows checking the existence of a preorder generating the sequence by
guessing V (1), . . . , V (n) and then checking the class of every model I that satisfies at least
a Ki . However, membership to the polynomial hierarchy follows only if all such values V (i)
are representable in polynomial space, which is only possible if their values are bounded by
some exponential in the size of the sequence.
308

Revision by History

Lemma 18 If reinforcement revision generates a revision sequence [K0 , P1 , K1 , . . . , Pn , Kn ]
from some total preorder, then it also generates the same sequence from a preorder in which
the minimal initial class of models of P1 is 0 or 1.
This lemma proves that if a sequence is generated by some preorder is also generated by
a preorder C such that DC (1) is either 0 or 1. In particular, if K0 ∧ P1 is consistent then
DC (1) = 0, otherwise DC (1) = 1. This is the base case of a recursive proof giving a bound
on the size of the other DC (i). Intuitively, this is done by lowering all models of Pi of the
same number of classes in the initial preorder; after revising by Pi they will moved together
so that their minimal ones are in class zero, resulting in the same ordering as obtained from
the original one. This lowering cannot however be so large that some of these models enter
class zero at a previous step j if they do not satisfy Kj .
Lemma 19 If reinforcement revision generates the sequence [K0 , P1 , K1 , . . . , Pn , Kn ] from
a total preorder, it is also generates the same sequence from a total preorder C such that
DC (i + 1) ≤ DC (1) + . . . + DC (i) + i + 1.
This lemma can be seen as the inductive part of a proof, where the previous one was
the base case. They lead to the following conclusion.
Lemma 20 Reinforcement revision generates the revision sequence [K0 , P1 , K1 , . . . , Pn , Kn ]
from a total preorder if and only if it generates the same sequence from a total preorder such
that each DC (i) is bounded by 2i − 1.
The values of DC (1), . . . , DC (n) are bounded by an exponential in the value of n, which
is also a lower bound on the size of the sequence [K0 , P1 , . . . , Pn , Kn ]. Therefore, each DC (i)
can be represented in space polynomial in the size of the sequence.
Theorem 8 Establishing the existence of a total preorder generating the revision sequence
[K0 , P1 , . . . , Pn , Kn ] by reinforcement revision is in Σp2 , and is in coNP if n is a constant.
For the case of constant-length sequences, hardness is easy to prove.
Theorem 9 Checking the existence of a preorder generating a reinforcement revision sequence [K0 , P1 , K1 , . . . , Pn , Kn ] is coNP-complete, if n is a constant.

8. Conclusions
Belief revision employs plausibility orders to revise a knowledge base, but how to obtain
such orders has largely been neglected. The solution proposed and studied in this article
is to assume knowledge of previous revisions, “reversing” them to obtain the initial order,
which can be then used in further revisions. This method is similar to deriving the order
from hypothetical revisions like K ∗ P |= Q, K ∗ R |= T , etc., which assumes knowledge of
what would happen if the revising formula is P , if it is R, etc. In the approach considered
in this article the results of iteratively incorporating a series of new formulae are given, like
in nested counterfactuals (Eiter & Gottlob, 1996). Booth and Nittka (2008) considered the
problem of deriving facts holding at some time points from partial information expressed
309

Liberatore

in terms of positive and negative conditions (i.e., some formulae hold and some others
do not hold at certain time points), and this is done by constructing an initial ordering.
Their study focuses on lexicographic revision only, but allows for partial knowledge of both
revisions and results, and includes the choice of an initial ordering among the possible ones.
Rather than entailment information like K ∗P ∗R |= Q, in this article the history of revisions
and resulting knowledge bases is assumed fully known. These could be the actual results of
manually performed changes, and may already be available.
The analysis has shown simple equivalent conditions to the existence of an ordering generating a given series of revisions and results for natural (Boutilier, 1996), restrained (Booth
& Meyer, 2006), lexicographic (Spohn, 1988; Nayak, 1994) and reinforcement revisions (Jin
& Thielscher, 2007). The conditions allow to construct such an initial ordering if one exists.
Using these equivalent conditions, the complexity of establishing the existence of orderings generating a sequence has been established for the considered semantics. Surprisingly,
they turned out to be relatively simple: coNP complete in all cases but one (reinforcement
revision with unbounded sequence length). This is the same as checking propositional entailment, which means that checking generability does not increase complexity over that of
the base language of propositional logic.
As shown in Section 5, the same revision sequence may be generated by more than one
ordering. This leads to the question of whether one of them may be considered the “most
natural” for the sequence. If for example I is less than J in an ordering but not in another,
the second may be seen as more cautious, and in the end more rational: the sequence can
be generated without assuming that I represents a more plausible world than J, so there
is no reason to draw such a conclusion. The question of whether a single least informative
ordering exists for every sequence, in each of the considered revision semantics, is an open
problem.
Still open is the comparison of generable sequences in the various revisions: as shown
by the running example, a sequence that is generated by natural revision is generated by
no ordering with the restrained and lexicographic revision. Is there any sequence with the
opposite property? If not, natural revision may be seen as more suited at explaining why a
revision sequence has been generated. On the other hand, it may also give less information
about the initial ordering used to generate them; this is the case if the orderings generating
the same sequence are more numerous than in the other semantics.
The four semantics for iterated belief revisions are not the only ones defined in the literature (Williams, 1994; Darwiche & Pearl, 1997; Areces & Becher, 2001; Benferhat et al.,
2004; Konieczny & Pino Pérez, 2000; Zhang, 2004); a recent survey counted at least twenty
seven revision-related operators (Rott, 2009). Natural and lexicographic semantics are regarded as extreme forms of revision satisfying the Darwiche-Pearl postulates (Darwiche &
Pearl, 1997), where minimal and maximal hearing is respectively given to the new information. Restrained and reinforcement revision can be considered to be in the middle, as they
also obey some other conditions (Booth & Meyer, 2006; Jin & Thielscher, 2007). The four
considered semantics therefore constitute a reasonable spectrum of possibilities, but others
exist.
Some require additional information (like the strength of every revision, Spohn, 1988;
Williams, 1994; Benferhat et al., 2004), others are families of revisions rather than single
ones (Darwiche & Pearl, 1997; Zhang, 2004). These, in particular, open an interesting
310

Revision by History

line of research: whether a revision sequence can be generated by some ordering and some
revision semantics satisfying a given set of conditions, like the Darwiche and Pearl (1997)
postulates. In other words, both the ordering and the semantics are the solution of the
problem, while the given is only the revision sequence.
The assumption of reliability strictly increasing with time also gives other directions to
study. Indeed, this principle has been realized as not true in general (Peppas, 2008) and
iterated revision recognized as a form of prioritized merging (Delgrande, Dubois, & Lang,
2006). In this perspective, giving preference to the last formula is just a particular case.
It is a case of interest, yet searching for the initial plausibility order is also possible in the
general case.
Yet another open problem is how to combine the approach in this article with results
about how people actually perform revision. Indeed, it has been experimentally proved
that human revision suffers from a number of biases (Tversky & Kahneman, 1983; See,
Morrison, Rothman, & Soll, 2011; Wang, Zhang, & Johnson, 2000), such as the anchoring
or order effect, the excessive preference of knowledge acquired early. These studies show
that revision performed by people is not fully rational, contrary to what belief revision
formal semantics attempt to be. Such psychological, extra-logical biases should be kept
into account when working on sequences of manually-performed revisions.
8.1 Acknowledgements
The author thanks the anonymous referees for their useful suggestions on the previous
versions of this article.

Appendix A. Proofs
The following sections contain the proofs of all lemmas and theorems in the article.
A.1 Preliminaries: Proofs
Lemma 1 If F is consistent and F |= maxset(P1 , . . . , Pn ), then maxset(P1 , . . . , Pn ) ≡
{Pi | 1 ≤ i ≤ n and F |= Pi }.
Proof. Since F |= maxset(P1 , . . . , Pn ) then F implies every Pi that is in the maxset.
The only possibility for the claim not to hold is that F also implies some Pi not in the
maxset. Since every element of maxset(P1 , . . . , Pn ) is implied by F , also every element
of prefixi (maxset(P1 , . . . , Pn )) is. Since F also entails Pi , every model of F satisfies both
prefixi (maxset(P1 , . . . , Pn )) and Pi . The consistency of Pi ∧ prefixi (maxset(P1 , . . . , Pn ))
contradicts the assumption that Pi is not in the maxset.
Lemma 2 If F is consistent and F |= maxset(P1 , . . . , Pn ), every consistent subset of
{P1 , . . . , Pn } that contains all formulae entailed by F is equivalent to maxset(P1 , . . . , Pn ).
Proof. By Lemma 1, since F is consistent and F |= maxset(P1 , . . . , Pn ) then
maxset(P1 , . . . , Pn ) ≡ {Pi | 1 ≤ i ≤ n and F |= Pi }. This proves that maxset(P1 , . . . , Pn )
contains all formulae entailed by F .
Let R be a consistent proper superset of
311

Liberatore

maxset(P1 , . . . , Pn ). Let Pi be the lowest-index formula that is in R but not in
maxset(P1 , . . . , Pn ). Since this is the lowest index, R and maxset(P1 , . . . , Pn ) have the
same formulae among {P1 , . . . , Pi−1 }. Since R is consistent, its intersection with this set
is consistent as well. Since R also contains Pi , it follows that prefixi (P1 , . . . , Pn ) ∪ {Pi } is
consistent, contradicting the assumption that Pi is not in maxset(P1 , . . . , Pn ).
Lemma 3 If F is consistent then F 6|= maxset(P1 , . . . , Pn ) if and only if there exists a
subsequence R of [P1 , . . . , Pn ] such that:
1. R is consistent;
2. if F |= Pi then Pi ∈ R;
3. for some i, Pi 6∈ R and Pi ∧ prefixi (R) is consistent.
Proof. Two cases are considered: first, F entails the maxset; second, F does not. In the
first, no such R is proved to exists; in the second, one such R is shown.
If F |= maxset(P1 , . . . , Pn ), then F implies all elements of the maxset. As a result,
the second condition can only be true if R contains all formulae in the maxset. If R also
contains some formulae not in the maxset, since a formula not in the maxset is inconsistent
with the maxset, then R is inconsistent. As a result, R can be consistent only if it coincides
with the maxset. This contradicts the third point, showing that for every R, if the first and
the second conditions are true the third is false.
If F 6|= maxset(P1 , . . . , Pn ), the three conditions are satisfied by R containing precisely
the formulae Pi entailed by F . This choice meets the first condition because F is consistent
and the second by construction. The third condition is now proved to hold as well.
Since F does not entail the maxset then F does not entail some formulae in the maxset.
Let i be the least index of a formula in maxset(P1 , . . . , Pn ) that is not entailed by F . By
construction, every formula Pj in the maxset is in R if j < i. It can be shown that the
converse also holds. To the contrary, let j < i be the lowest index of a formula in R that is
not in the maxset.
The assumptions that i and j are the least indexes on which R and the maxset differ (in
a way or the other) imply prefixj (R) = prefixj (maxset(P1 , . . . , Pn )). Since by assumption
Pj is not in the maxset, it is inconsistent with prefixj (maxset(P1 , . . . , Pn )). As a result, it is
also inconsistent with prefixj (R). Since Pj ∈ R, that implies the inconsistency of R, which
was proved consistent.
This contradiction proves that R and the maxset are not only equal up to some index
j < i, but up to i. In other words, prefixi (R) = prefixi (maxset(P1 , . . . , Pn )).
By assumption Pi is a formula in the maxset that is not in R. Being in the maxset
means that Pi ∧ prefixi (maxset(P1 , . . . , Pn )) is consistent. As it has just been proved, the
latter is equivalent to Pi ∧ prefixi (R). This concludes the proof of the third condition.
Theorem 1 If F is consistent, checking F ≡ maxset(P1 , . . . , Pn ) is in coNP.
Proof. F ≡ maxset(P1 , . . . , Pn ) holds if F |= maxset(P1 , . . . , Pn ) and maxset(P1 , . . . , Pn ) |=
F . If the first condition is true, by Lemma 1 the maxset comprises exactly the formulae
312

Revision by History

entailed by F . Therefore, the converse maxset(P1 , . . . , Pn ) 6|= F can only happen if there
exists a model I satisfying all formulae Pi entailed by F but not F itself. In other words:
F ≡ maxset(P1 , . . . , Pn )
iff F |= maxset(P1 , . . . , Pn ) and maxset(P1 , . . . , Pn ) |= F
iff F |= maxset(P1 , . . . , Pn ) and ¬(∃I . I 6|= F and ∀i(F |= Pi → I |= Pi ))
iff F |= maxset(P1 , . . . , Pn ) and ¬(∃I . I 6|= F and ∀i(F 6|= Pi or I |= Pi ))
iff F |= maxset(P1 , . . . , Pn ) and ∀I . I |= F or ∃i(F |= Pi and I 6|= Pi ))

Lemma 3 reformulates the converse of the first condition F |= maxset(P1 , . . . , Pn ) using
only existential quantifiers (the second point is equivalent to either F 6|= Pi or Pi ∈ R).
As a result, the first condition can be expressed using only universal quantifiers. The only
existential quantifier in the second condition is that over i, which can be replaced by a
disjunction. Since all quantifiers are universal, the problem is in coNP.
A.2 Natural Revision: Proofs
Lemma 4 If CP (0) ∩ Mod(F ) = ∅ then CP compares the models of F as C does, where CP
is the natural revision of the total preorder C with formula P .
Proof. Let I and J be two models of F , m and l their classes. Since these are models of F and
CP (0) ∩ Mod(F ) = ∅, they do not belong to CP (0). As a result, CP (m + 1) = C(m)\CP (0)
contains I and CP (l + 1) = C(l)\CP (0) contains J. This proves that revising C by F
increases the classes of I and J by one each. Therefore, I is greater or equal than J
according to CP if and only if it is according to C.
Lemma 5 Let [Kj , Pj+1 , . . . , Pi , Ki ] be a revision sequence generated by natural revision
from a total preorder C. If Kj ∧ Pi is consistent while none of Kj+1 ∧ Pi , . . . , Ki−1 ∧ Pi is,
then CPj+1 ,...,Pi (0) = Mod(Kj ∧ Pi ).
Proof. By Lemma 4, CPj+1 ,...,Pi−1 compares models of Pi in the same way C does. As a
result, Mod(Ki ) are the minimal models of Pi in C. Since C(0) = Mod(Kj ) and Kj ∧ Pi is
consistent, these minimal models are C(0) ∩ Mod(Pi ) = Mod(Kj ∧ Pi ).
Lemma 6 If the revision sequence [K0 , P1 , K1 , . . . , Pi , Ki ] is generated by natural revision
from the total preorder C and Pi is inconsistent with each of K0 , . . . , Ki−1 , then the models
of Ki are the minimal models of Pi according to C.
Proof. By Lemma 4, revising C by P1 , . . . , Pi−1 does not affect the order between the
models of Pi . As a result, the minimal models of Pi according to CP1 ,...,Pi−1 are the minimal
models of Pi according to C.
313

Liberatore

Theorem 2 If [K0 , P1 , K1 , . . . , Pn , Kn ] is natural-compatible then it is generated by natural
revision from the initial preorder C = [C(0), . . . , C(n + 1)].


 Mod(Ki )

C(i) =

if i ≤ n and ∀l < i . Kl ∧ Pi |= ⊥
otherwise, if i ≤ n

 S{Mod(K ) | ∃l < j . K ∧ P 6|= ⊥} if i = n + 1
j
j
l
∅

Proof. Since no formula has index lower than zero, C(0) is equal to Mod(K0 ) and is therefore
not empty. The classes of C contain all models because C(n + 1) comprises every model
not in C(0), . . . , C(n). To prove that C is a total preorder, it is to be proved that the sets
C(i) are disjoint. A model is in C(i) with i ≤ n only if it is in Mod(Ki ). Therefore, it is
also a model of Pi . Since Pi is inconsistent with each of K0 , . . . , Ki−1 , the model is not in
any of C(0), . . . , C(i − 1). The class C(n + 1) contains exactly the models that are not in
C(0) ∪ · · · ∪ C(n). This proves that C is a total preorder.
The formulae Ki are generated in different ways depending on whether Kj ∧ Pi is consistent for some j < i:
• if such an index j exists, then by the assumption of natural compatibility Ki ≡ Kj ∧Pi
for the maximal such j; by Lemma 5, this is exactly the result of revising C by
P1 , . . . , Pi .
• otherwise, Pi is inconsistent with each of K0 , . . . , Ki−1 ; by Lemma 6, Mod(Ki )
are the minimal models of Pi in the initial preorder C. Since Pi is inconsistent with K0 , . . . , Ki−1 , then: first, since C(0), . . . , C(i − 1) are subsets of
Mod(K0 ), . . . , Mod(Ki−1 ), these classes do not contain models of Pi ; second, C(i)
is not empty but equal to Mod(Ki ). As a result, the minimal models of Pi are exactly
Mod(Ki ).

Theorem 3 A revision sequence [K0 , P1 , K1 , . . . , Pn , Kn ] is generated by natural revision
from some initial total preorder if and only if it is natural-compatible.
Proof. The previous theorem shows that every natural-compatible sequence is generated
by natural revision from some total preorder. The converse is now proved: if a sequence is
not natural-compatible then it is not generated by natural revision from any preorder.
Since Mod(Ki ) = CP1 ,...,Pi−1 ,Pi (0) = CP1 ,...,Pi−1 (l) ∩ Mod(Pi ) for some l, it holds
Mod(Ki ) ⊆ Mod(Pi ), which is the same as Ki |= Pi . Therefore, if Ki 6|= Pi no preorder can
generate the revision sequence. Otherwise, natural-compatibility is violated if, for some j
and i:
1. Kj ∧ Pi is consistent;
2. formulae Kj+1 ∧ Pi , . . . , Ki−1 ∧ Pi are inconsistent;
3. Kj ∧ Pi is not equivalent to Ki .
314

Revision by History

By Lemma 5, the first two points imply that revising Cj by Pj+1 , . . . , Pi generates a
formula equivalent to Kj ∧ Pi , contradicting the third point. This proves that a revision
sequence that is not natural-compatible is not generated by natural revision from any preorder.
Lemma 7 Checking the existence of a total preorder C generating a revision sequence
[K0 , P1 , K1 , . . . , Pn , Kn ] using natural revision is in coNP.
Proof. According to Theorem 3, such a preorder C exists if and only if, for every i ∈
{1, . . . , n}, it holds that Ki |= Pi and, if j is the maximal index such that j < i and Kj ∧ Pi
is consistent (if any), then Ki ≡ Kj ∧ Pi . The first part, Ki |= Pi for all i, can be verified
by a linear number of independent unsatisfiability tests.
The second part can be rewritten as: if Kj ∧ Pi is consistent and Kh ∧ Pi is inconsistent
for every h between j and i, then Ki ≡ Kj ∧ Pi . Rewriting implication as disjunction, for
every j = 0, . . . , i − 1:
1. either K0 ∧Pi is inconsistent or Kh ∧Pi is consistent for some 0 < h < i or Ki ≡ K0 ∧Pi ;
and
2. either K1 ∧Pi is inconsistent or Kh ∧Pi is consistent for some 1 < h < i, or Ki ≡ K1 ∧Pi ;
and
3. . . . ;
4. either Ki−1 ∧ Pi is inconsistent or Ki ≡ K0 ∧ Pi .
These are the conditions for index i. They have to hold for every i ∈ {1, . . . , n}. Since
the formulae Ki are consistent, the conditions can be simplified: if Kj ∧Pi is consistent, then
either Kh ∧ Pi is consistent for j < h < i or Ki ≡ Kj ∧ Pi ; in the latter case, Ki ≡ Kh ∧ Pi
for one such index h (the last). Therefore, the condition can be recast as:
Kj ∧ Pi |= ⊥ or Ki ≡ Kj+1 ∧ Pi or . . . Ki ≡ Ki−1 ∧ Pi or Ki ≡ Kj ∧ Pi
This condition can be checked with a number of independent unsatisfiability tests, and
is therefore in coNP.
Theorem 4 The problem of establishing the existence of a preorder generating a revision
sequence using natural revision is coNP complete.
Proof. Membership is proved in the previous lemma. Hardness is proved by reduction from
the problem of checking whether a formula G is unsatisfiable. The instance is [K0 , P1 , K2 ]
with K0 = a, K1 = P1 = a → G, where a is a new variable, not in G. If G is satisfiable,
then K0 ∧ P1 is consistent; therefore, it should be equivalent to K1 . Instead, it is a ∧ G. If
G is unsatisfiable, then K1 = P1 = ¬a is inconsistent with K0 . By Theorem 3, a preorder
generating the sequence using natural revision exists.

315

Liberatore

A.3 Restrained Revision: Proofs
Lemma 8 Let [Kj , Pj+1 , . . . , Pi , Ki ] be a revision sequence generated by restrained revision
from the initial total preorder C. If Kj ∧ Pi is consistent while none of Kj+1 ∧ Pi , . . . ,
Ki−1 ∧ Pi is, then CPj+1 ,...,Pi (0) = Mod(maxset(Kj ∧ Pi , Pj+1 , . . . , Pi−1 )).
Proof. Proof is by induction on i − j. When j = i + 1 the claim CPi (0) = Mod(maxset(Kj ∧
Pi )) holds because Kj ∧ Pi is consistent by assumption.
The inductive claim is that CPj+1 ,...,Pi−2 ,Pi−1 ,Pi (0)
=
Mod(maxset(Kj ∧
Pi , Pj+1 , . . . , Pi−2 , Pi−1 )), the inductive assumption is the same without Pi−1 :
CPj+1 ,...,Pi−2 ,Pi (0) = Mod(maxset(Kj ∧ Pi , Pj+1 , . . . , Pi−2 ))
By definition, CPj+1 ,...,Pi−2 ,Pi (0) is CPj+1 ,...,Pi−2 (k) ∩ Mod(Pi ) where k is the minimal
integer making this intersection non-empty. As a result, CPj+1 ,...,Pi−2 (l) ∩ Mod(Pi ) = ∅ for
all indexes l such that 0 ≤ l < k. Revising the preorder by Pi−1 changes the classes of:
• the models of Ki−1 , which become class zero;
• the models of the same class, which are split according to whether they satisfy Pi−1 .
Since no model of Ki−1 satisfies Pi by assumption, CPj+1 ,...,Pi−2 ,Pi−1 (0) ∩ Mod(Pi ) = ∅
holds. None of the classes of CPj+1 ,...,Pi−2 of index 0 ≤ l < k intersect Mod(Pi ); therefore,
neither do the ones resulting from splitting them. As a result, the minimal-index class
intersecting Mod(Pi ) is one of the two resulting from splitting CPj+1 ,...,Pi−2 (k), which are:
CPj+1 ,...,Pi−2 (k) ∩ Mod(Pi−1 )
CPj+1 ,...,Pi−2 (k)\Mod(Pi−1 )
If the first intersects Mod(Pi ), this is Mod(Ki ); otherwise, Mod(Ki ) is the second. In
formulae:
(

Mod(Ki ) =

CPj+1 ,...,Pi−2 (k) ∩ Mod(Pi−1 ) ∩ Mod(Pi ) if not empty
(CPj+1 ,...,Pi−2 (k)\Mod(Pi−1 )) ∩ Mod(Pi ) otherwise

By the properties of set operators, this equation can be rewritten as:
(

Mod(Ki ) =

CPj+1 ,...,Pi−2 (k) ∩ Mod(Pi ) ∩ Mod(Pi−1 ) if not empty
(CPj+1 ,...,Pi−2 (k) ∩ Mod(Pi ))\Mod(Pi−1 ) otherwise

By the way k was defined, CPj+1 ,...,Pi−2 (k) ∩ Mod(Pi ) is equal to CPj+1 ,...,Pi−2 ,Pi (0). The
latter is by the inductive assumption Mod(maxset(Kj ∧ Pi , Pj+1 , . . . , Pi−2 )). Intersecting
this set with Mod(Pi−1 ) if the result is not empty, and subtracting Mod(Pi−1 ) otherwise
is the same as adding Pi−1 to the end of the sequence, by the definition of maxset of a
sequence. Since Mod(Ki ) = CPj+1 ,...,Pi−2 ,Pi−1 ,Pi (0), this proves the inductive claim that this
set is equal to Mod(maxset(Kj ∧ Pi , Pj+1 , . . . , Pi−2 , Pi−1 )).

316

Revision by History

Lemma 9 If [K0 , P1 , K1 , . . . , Pn , Kn ] is restrained-compatible then it is generated by restrained revision from the total preorder C = [C(0), . . . , C(n + 1)], where:


 Mod(Ki )

C(i) =

if i ≤ n and ∀l < i . Pi ∧ Kl |= ⊥
otherwise, if i ≤ n

 S{Mod(K ) | ∃l < j P ∧ K 6|= ⊥} if i = n + 1
j
j
l
∅

Proof. No formula has index less than zero; therefore, C(0) = Mod(K0 ), which is not empty
because all formulae in the sequences are consistent by assumption. Since C(n + 1) contains
all models not in C(0) ∪ · · · ∪ C(n), the union of the classes include all models, and no model
in C(n+1) is also in another classes. In order to prove that C is a partition, it is shown that
no model of C(i) is also in C(l) with l < i ≤ n. If I ∈ C(i) with i ≤ n then I ∈ Mod(Ki )
with Pi ∧ Kl inconsistent for all l < i. Since Ki |= Pi , also Ki ∧ Kl is inconsistent. This
proves that a model I cannot be in C(i) and also in C(l) with l < i.
The previous lemma shows that, regardless of the initial total preorder, if a revision
sequence is generated by restrained revision then Ki ≡ maxset(Kj ∧ Pi , Pj+1 , . . . , Pi−i ) if
j is the maximal index such that j < i and Kj ∧ Pi is consistent, if any. Since restrained
compatibility ensures that this condition holds, all Ki for which such a j exists are obtained
by revision regardless of C.
Remains to show that C generates Ki even if Pi ∧ Kl is inconsistent for all l < i. The
models of Pi are in C(i) = Mod(Ki ) and classes of greater index. Indeed, if a model of
Pi were in C(l) with l < k then Pi ∧ Kl would be consistent. Revising C by Pl , with
l = 1, . . . , i − 1, changes the preorder in two ways:
1. the models of Kl are moved to class zero;
2. all other classes are split according to satisfaction of Pl .
Since Pi ∧ Kl is inconsistent, no model of Pi is moved to class zero. As a result, the
relative position of the models of Pi is only modified by the second change, the splitting of
the classes. This could break the class Mod(Ki ) in two, but not in this case. Indeed, since
either Ki |= Pl or Ki |= ¬Pl , either all models of Ki satisfy Pl or all falsify Pl . In other
words, the change may alter the comparison of two models of Pi , but does not if they are
both in Mod(Ki ).
Two claims are therefore proved: that the models of Pi are in C(i) = Mod(Ki ) and
greater classes; and that after the first i − 1 revisions the minimal models of Pi are still
Mod(Ki ). This proves that the result of the i-th revision is Ki .
Theorem 5 A revision sequence [K0 , P1 , K1 , . . . , Pn , Kn ] is generated by restrained revision
from some initial total preorder if and only if it is restrained-compatible.
Proof. The previous lemma shows that every restrained-compatible revision sequence is
generated by a certain initial preorder. Remains therefore to prove the converse: if a
revision sequence is not restrained-compatible then it is generated by no initial preorder.
Lemma 8 proves that every sequence generated by restrained revision satisfies the condition that Ki ≡ maxset(Pi ∧ Kj , Pj+1 , . . . , Pi−1 ) where j is the maximal j < i such that
317

Liberatore

Pi ∧ Kj is consistent. That Ki |= Pi holds is a consequence of Mod(Ki ) being the set of minimal models satisfying Pi . Remains therefore to prove the necessity of the third condition
of restrained compatibility: if Pi is consistent with all Kj with j < k then either Ki |= Pl
or Ki |= ¬Pl for every l < i.
To the contrary, let l < i be such that Ki 6|= Pl and Ki 6|= ¬Pl . These two conditions
imply that Mod(Ki ) contains some models of Pl and some models of ¬Pl . Even if the
models of Ki are in the same class after l − 1 revisions, the l-th one separates the ones
satisfying Pl from the ones satisfying ¬Pl . These may end in two consecutive classes, or in
the new class zero and in another class, but either way the models of Ki are placed in two
separate classes. Since constrained revision never merges classes, these models are still in
separate classes after the i − 1-th revision. As a result, revising by Pi can only select a part
of Mod(Ki ) and not all of it.
Lemma 10 A revision sequence [K0 , P1 , K1 . . . , Pn , Kn ] is restrained-compatible if and only
if, for every index i:
1. Ki |= Pi ;
2. for every 0 ≤ j < i, either Kj ∧ Pi is inconsistent or Ki |= Kl ∧ Pi for some j < l < i
or Ki ≡ maxset(Kj ∧ Pi , Pj+1 , . . . , Pi−1 );
3. for every 0 ≤ j < i, Ki |= Pj , Ki |= ¬Pj , or Ki |= Kl ∧ Pi for some 0 ≤ l < i.
Proof. The three conditions of restrained compatibility can be rewritten as follows, for
every index i.
1. Ki |= Pi ;
2. for every j such that 0 ≤ j < i, either Kj ∧ Pi is inconsistent or Kl ∧ Pi is consistent
for some j < l < i or Ki ≡ maxset(Kj ∧ Pi , Pj+1 , . . . , Pi−1 );
3. for every j such that 0 ≤ j < i, either Ki |= Pj or Ki |= ¬Pj or Kl ∧ Pi is consistent
for some 0 ≤ l < i.
Both the second and the third point include “Kl ∧ Pi is consistent for some h ≤ l < i”:
in the first, h = j + 1; in the second, h = 0. In the particular conditions of the lemma,
these two conditions will be shown to be equivalent:
1. Kl ∧ Pi is satisfiable for some l such that h ≤ l < i;
2. Ki |= Kl ∧ Pi for some l such that h ≤ l < i.
It is proved that: first, if the sequence is restrained-compatible then Condition 1 implies
Condition 2; second, if the three conditions of the lemma are true then Condition 2 implies
Condition 1.
Condition 1 is that Kl ∧ Pi is consistent for some h ≤ l < i. Either l is the maximal
index with this property or some other index between h and i is. Let g be such a maximal
index. By restrained compatibility, Ki ≡ maxset(Kg ∧ Pi , Pi−1 , . . . , Pg+1 ). The maxset of a
318

Revision by History

sequence implies its first element, if consistent. Since this is the case, Ki |= Kg ∧ Pi . This
means that Condition 2 holds for index g.
Condition 2 is that Ki |= Kh ∧ Pi for some h ≤ l < i. Since Ki is consistent, Kh ∧ Pi is
consistent as well, proving Condition 1 for the same index l.
Theorem 6 Establishing the existence of a total preorder generating a restrained revision
sequence is coNP-complete.
Proof. Membership follows from the previous lemma. Its conditions can be all reformulated
as entailments (like Ki |= Pi ), inconsistencies (like that of Kj ∧ Pi ) and equivalences with
maxsets (Ki ≡ maxset(Kj ∧ Pi , Pj+1 , . . . , Pi−1 )). All these problems are in coNP, and can
therefore be rewritten as universal quantified formulae. The whole problem is a combination
of these; by renaming all variables and taking out the quantifiers, a single universally
quantified formula results. Since ∀QBF is in coNP, the problem is in coNP.
Hardness is proved by reduction from the problem of propositional unsatisfiability. Given
a formula F , the associated revision sequence is [a, b ∨ F, a ∧ b], where a and b are fresh
variables, not occurring in F . If F is unsatisfiable then b ∨ F is equivalent to b, and the
sequence [a, b, a ∧ b] is generated by the preorder C = [C(0), C(1)] with C(0) = Mod(a) and
C(1) = Mod(¬a). If F is satisfiable then a ∧ (b ∨ F ) is satisfiable but is not equivalent to
a ∧ b, which makes the sequence not generated by restrained revision from any preorder.
The sequence is therefore generated by restrained revision from some preorder if and only
if F is unsatisfiable.
A.4 Lexicographic Revision: Proofs
Lemma 11 If a revision sequence [K0 , P1 , K1 , . . . , Pn , Kn ] is generated by lexicographic
revision from the total preorder among models C then it has the result preorder R defined
by:
R(i) = {Ki | Mod(Ki ) ⊆ C(i)}
Proof. R is a total preorder because: first, R(0) is not empty because C(0) = Mod(K0 ),
which implies Mod(K0 ) ⊆ C(0) and K0 ∈ R(0); second, no formula is in two classes of
R because C is a partition. Third, every Ki is in a class of R because of Property 1:
since Mod(Ki ) is a set of minimal models of C, all its models are in the same class C(j);
therefore, Ki ∈ R(j). Remains to prove that this preorder satisfies the two conditions for
being a result preorder for the sequence.
If Ki and Kj are consistent with each other, they have a common model I. Let h be
its class. By construction, since I |= Ki then Ki ∈ R(h). The same holds for Kj , since
I |= Kj . As a result, Kj ∈ R(h).
Let Ki and Kj be such that ¬Ki ∧Kj ∧maxset(Pi , . . . , P1 ) is consistent. By assumption,
the sequence is generated by lexicographic revision from C. As a result, the models of Ki are
exactly the minimal models of maxset(Pi , . . . , P1 ) according to C. Let h be the class of such
models. By construction of R, it holds Ki ∈ R(h). All models of ¬Ki ∧ maxset(Pi , . . . , P1 )
belong to a greater class l > h. Since ¬Ki ∧ Kj ∧ maxset(Pi , . . . , P1 ) is consistent, Kj has
319

Liberatore

some models in C(l). Since all models of Kj are in the same class, it follows Mod(Kj ) ⊆ C(l),
which implies Kj ∈ R(l). Since l > h, the claim is proved.
Lemma 12 If R is a result preorder for a revision sequence [K0 , P1 , K1 , . . . , Pn , Kn ] such
that Ki |= maxset(Pi , . . . , P1 ) for every i, then lexicographic revision from the following
total preorder C among models generates the revision sequence, where z is the index of the
greatest class of R:
( S

C(h) =

{Mod(Ki ) | Ki ∈ R(h)} if h ≤ z
{I | I 6∈ K1 ∪ · · · ∪ Kn }
if h = z + 1

Proof. C is proved to be a total preorder. First, C(0) is not empty since R(0) is not empty.
Second, no model belongs to more than one class: if I is in both C(h) and C(l) then by
definition there exists Ki ∈ R(h) and Kj ∈ R(l) that are both satisfied by I; this implies
that Ki ∧ Kj is consistent; since R is a result preorder for the sequence, it follows that l = h.
Models of C(z + 1) are exactly the ones not contained in the other classes.
Remains to be proved that lexicographic revision generates the revision sequence from
C: revising C by P1 , . . . , Pi generates Ki . Since Ki |= maxset(Pi , . . . , P1 ) by assumption,
all models of Ki are also models of maxset(Pi , . . . , P1 ). Remains to be proved that they are
the minimal ones: all other models are in greater classes. Let h be the class of the models
of Ki , and I be a model of ¬Ki ∧ maxset(Pi , . . . , P1 ). If I does not satisfy any other Kj
then I ∈ R(z + 1), and z + 1 > h since z is the greatest index of the classes of R. If I
satisfies Kj then it satisfies ¬Ki ∧ Kj ∧ maxset(Pi , . . . , P1 ), which is therefore satisfiable.
Since R is a result preorder for the sequence, Kj is in a class R(l) with l > h. This implies
that I ∈ C(l). This proves that every model of maxset(Pi , . . . , P1 ) that is not in Mod(Ki )
is in a class greater than h.
Lemma 13 A revision sequence is generated by lexicographic revision from some total preorder if and only if it is lexicographic compatible.
Proof. If the revision sequence is generated by some total preorder then Ki |=
maxset(Pi , . . . , P1 ) holds for every i. Furthermore, a result preorder R for it exists by
Lemma 11. From it, define the relations ' and < as: Ki ' Kj if and only if Ki and Kj are
in the same class R(h); Ki < Kj if Ki ∈ R(h), Kj ∈ R(l) and h < l. Since R is a revision
preorder for the sequence, if Ki ∧ Kj is consistent then Ki and Kj are in the same class,
which implies Ki ' Kj . In the same way, if ¬Ki ∧ Kj ∧ maxset(Pi , . . . , P1 ) is consistent
then Ki is in a lower class than Kj , implying Ki < Kj . A cycle containing < is impossible
because Ki < Kj means that the class of Ki is lower than the class of Kj .
This does not prove lexicographic compatibility, which requires Ki ' Kj and Ki < Kj to
be respectively equivalent to the consistency of Ki ∧ Kj and ¬Ki ∧ Ki ∧ maxset(Pi , . . . , P1 ),
not merely implied by them. However, by removing from these relations all pairs Ki and
Kj not satisfying the respective condition makes these relations weaker. Therefore, no new
cycle is created.
To prove the other direction, assume that Ki |= maxset(Pi , . . . , P1 ) for every i and
that ' and < are two relations defined from the sequence as specified in the definition
320

Revision by History

of lexicographic compatibility. A result preorder for the sequence is shown. Together with
Ki |= maxset(Pi , . . . , P1 ), this implies that the revision sequence is generated by some initial
preorder by Lemma 12.
From ' and <, a relation ≤ is defined: Ki ≤ Kj if either Ki ' Kj or Ki < Kj . This
relation is not necessarily transitive, but has a number of other properties:
1. if Ki ' Kj then Ki ≤ Kj and Kj ≤ Ki ; indeed, Ki ' Kj holds only if Ki ∧ Kj is
consistent, which implies that Kj ∧ Ki is consistent; therefore, Kj ' Ki , which implies
Kj ≤ Ki ;
2. if Ki < Kj then Ki ≤ Kj and Kj 6≤ Ki ; to the converse, if Kj ≤ Ki , then either
Kj ' Ki or Kj < Ki ; in both cases, this is a cycle of ' and < containing one < link,
which contradicts the assumption that no such cycle exists;
3. ≤ is reflexive; indeed, all formulae Ki are consistent by assumption; therefore, Ki ∧ Ki
is consistent, which implies Ki ' Ki and Ki ≤ Ki ;
4. ≤ is Suzumura consistent (Suzumura, 1976): it does not form cycles Ki1 , . . . , Kim =
Ki1 such that Kij ≤ Kij+1 for all j and for some j also Kij+1 6≤ Kij ; this is proved
below.
Properties 1 and 2 mean that ' and < are the equivalence and strict part of ≤, respectively. Indeed, Ki ≤ Kj holds only if either Ki ' Kj or Ki < Kj ; the former implies
Kj ≤ Ki , the latter Kj 6≤ Ki . Property 4 is a consequence of this fact and of the assumption
of nonexistence of cycles of ' and < containing at least one link <.
Since ≤ is reflexive (Property 3) and Suzumura consistent (Property 4), by the Suzumura
extension theorem (Suzumura, 1976) a total preorder R extending ≤ exists. Extending
means that both the equivalence and strict parts of ≤ are preserved in R. Since these have
been proved to be ' and <, the total preorder R has Ki and Kj in the same class if Ki ' Kj
and Ki in a lower class if Ki < Kj .
If Ki ∧ Kj is consistent then Ki ' Kj , which implies that Ki and Kj are in the same
class of R. If ¬Ki ∧ Kj ∧ maxset(Pi , . . . , P1 ) is consistent then Ki < Kj , which implies that
the class of Ki in R is less than the class of Kj . This proves that R is a result preorder for
the revision sequence.
Lemma 14 A revision sequence [K0 , P1 , K1 . . . , Pn , Kn ] is not lexicographic compatible if
and only if either Ki 6|= maxset(Pi , . . . , P1 ) for some i or consistent sets R1 , . . . , Rn exist
such that:
1. {Pj | 1 ≤ j ≤ i and Ki |= Pj } ⊆ Ri for every i; and
2. there exists a cycle Ki1 , . . . , Kim = Ki1 such that either Kij ∧Kij+1 or ¬Kij ∧Kij+1 ∧Ri
is consistent for all ij ∈ {i1 , . . . , im−1 }, and the second is consistent for at least one
such index.
Proof.
A revision sequence is lexicographic compatible if and only if Ki |=
maxset(Pi , . . . , P1 ) for all i and there is no cycle as specified by the definition. Inverting
321

Liberatore

this condition, a sequence is not lexicographic compatible if either Ki 6|= maxset(Pi , . . . , P1 )
or a cycle exists. As a result, one can check whether Ki 6|= maxset(Pi , . . . , P1 ) for some i; if
this is true, no further check is needed: the sequence is not lexicographic compatible. The
presence of cycles is irrelevant in this case. The other case is that Ki |= maxset(Pi , . . . , P1 )
for all i, and then the sequence is not lexicographic compatible if and only if it contains
cycles.
The point is that the condition for the presence of cycles can be written under the
assumption that Ki |= maxset(Pi , . . . , P1 ), since this is the only case where this condition
matters. By Lemma 2, the only consistent subset of {P1 , . . . , Pi } containing all formulae entailed by Ki is maxset(Pi , . . . , P1 ). This means that Ri can be used in place of
maxset(Pi , . . . , P1 ), since the only Ri satisfying the first condition in the statement of the
lemma is maxset(Pi , . . . , P1 ).
Theorem 7 The problem of checking the existence of a total preorder generating a revision
sequence using lexicographic revision is coNP-complete.
Proof. Membership follows from the previous lemma: the sequence is not generated by
lexicographic revision from any preorder if and only if it is not lexicographic compatible,
which in turns can be checked by existential quantifiers only:
1. Ki 6|= maxset(Pi , . . . , P1 );
2. there exists Ri ;
3. Ri is consistent;
4. either Ki 6|= Pj or Pj ∈ Ri ;
5. there exists a cycle Ki1 , . . . , Kim = Ki1 ;
6. Kij ∧ Kij+1 is consistent;
7. ¬Kij ∧ Kij+1 ∧ Ri is consistent.
The first condition can be expressed in terms of existential quantifiers only as shown by
Lemma 3. The same holds for the other conditions as well. As a result, incompatibility is
in NP, which means that the existence of preorder generating the sequence is in coNP.
Hardness is proved by reduction from propositional unsatisfiability. A formula F is
satisfiable if and only if [K0 , P1 , K1 ] is generated by no preorder, where K0 = a, P1 = a and
K1 = a ∨ F and a is a new variable not contained in F . Indeed, if F is unsatisfiable, then
K1 = a, and the sequence is generated by the preorder C = [C(0), C(1)] with C(0) = Mod(a)
and C(1) = Mod(¬a). If F is satisfiable, then K1 has some models that do not satisfy P1 :
the ones of F . As a result, K1 6|= P1 , and the sequence is not generated by any preorder.

322

Revision by History

A.5 Reinforcement Revision: Proofs
Lemma 15 For every sequence of n numbers V = [V (1), . . . , V (n)], it holds MV (I, i, j) =
MV (I, i, h) + MV (I, h, j) for every three indexes i, j and h.
Proof. If i < j then MV (I, i, j) is the sum of MV (I, l, l+1) for i < l ≤ j. Otherwise, it is the
sum of −MV (I, l, l + 1) = MV (I, l + 1, l). Also MV (I, i, h) and MV (I, h, j) can be expressed
in the same way. If h is between i and j the result follows immediately. Otherwise, if i < j
and h > j then MV (I, i, h) includes MV (I, l, l + 1) for l > j, but then MV (I, h, j) includes
MV (I, l + 1, l) = −MV (I, l, l + 1), which subtracts the same amount from the sum. The
case h < i is similar.
Lemma 16 If a revision sequence [K0 , P1 , K1 , . . . , Pn , Kn ] is generated by reinforcement revision from the total preorder C and DC = [DC (1), . . . , DC (n)] with DC (i) =
min{j | CP1 ,...,Pi−1 (j) ∩ Mod(Pi ) 6= ∅} and I |= Ki then, for every j:
• MDC (I, i, j) = 0 if I |= Kj ;
• MDC (I, i, j) > 0 otherwise.
Proof. If a model I is in CP1 ...Pi−1 (c) then it is in CP1 ...Pi (c − DC (i)) if I |= Pi and in
CP1 ...Pi−1 (c + 1) otherwise. As a result, MDC (I, i, i + 1) is the difference between the class
of I in the preorder at step i + 1 and the preorder at step i. Since MDC (I, i, j) is the sum
of these amounts from index i to index j, it is the difference between the class of I at step
j and i. If I |= Ki then its class at step i is zero. As a result, MDC (I, i, j) is the class of I
at step j. This is zero if I |= Kj and greater otherwise.
Lemma 17 If V = [V (1), . . . , V (n)] is a reinforcement mover for the revision sequence
[K0 , P1 , K1 , . . . , Pn , Kn ], the following initial preorder C = [C(0), . . . , C(V (1) + · · · + V (n +
1))] generates the revision sequence by reinforcement revision and DC = V .
(

C(j) =

{I | I |= Ki and MV (I, i, 0) = j} if j < V (1) + . . . + V (n) + 1
{I | ∀i . I 6|= Ki }
if j = V (1) + . . . + V (n) + 1

Proof. Since K0 is consistent, it has at least a model I. Since I |= K0 and MV (I, 0, 0) = 0
by definition, it follows I ∈ C(0), proving that C(0) is not empty. Every model is in some
class because if I |= Ki then I is in C(MV (I, i, 0)), otherwise it is in C(V (1) + . . . + V (n) +
1). To prove that C is a total preorder, remains to prove that no model belongs to two
classes. If I |= Ki and I |= Kj then MV (I, j, i) = 0 because V is a reinforcement mover;
therefore, MV (I, i, 0) = 0 + MV (I, i, 0) = MV (I, j, i) + MV (I, i, 0) = MV (I, j, 0). A model
of C(V (1) + . . . + V (n) + 1) does not satisfy any Ki ; therefore, it cannot be in any other
class C(j). This proves that C is a total preorder.
The longest part of the proof is to show that reinforcement revision generates the
sequence from C. Inductively, it is assumed that DC (1) = V (1), DC (2) = V (2), . . . ,
DC (i) = V (i), where DC (l) = min{j | CP1 ,...,Pl−1 (j) ∩ Mod(Pl ) 6= ∅}. It is then proved that
323

Liberatore

all models of Ki are in CP1 ,...,Pi (0) and all other models are in classes of greater index of
the same total preorder. Furthermore, the minimal class of models of Pi+1 in that preorder
is V (i + 1), proving that DC (i + 1) = V (i + 1), which allows to iterate the proof.
The base case is with i = 0: what is to be proved is that Mod(K0 ) = C(0) and DC (1) =
V (1). By construction of C, a model I is in C(0) if MV (I, i, 0) = 0 and I |= Ki for some i;
both hold for i = 0. Vice versa, if I ∈ C(0) then I |= Ki and MV (I, i, 0) = 0 for some i. If
I 6|= K0 , the definition of reinforced mover with j = 0 implies that MV (I, i, 0) > 0, which
in turn implies I 6∈ C(0), a contradiction.
In order to prove that DC (1) = V (1), let I be a model of P1 . By construction of C, if
I |= K1 then I is in C(V (1)). If I 6|= K1 two cases are possible. In the first, I 6|= Kj for every
j. This implies that I ∈ C(V (1) + . . . + V (n) + 1), and V (1) + . . . + V (n) + 1 > V (1). In the
second case, I |= Kj for some other j. By definition of reinforcement mover, MV (I, j, 1) > 0.
The class of C containing I has index MV (I, j, 0) = MV (I, j, 1)+MV (I, 1, 0) = MV (I, j, 1)+
V (1), the last step being a consequence of I |= Pi . Since MV (I, j, 1) > 0, it follows that
this amount is greater than V (1). This proves that V (1) is the index of the minimal class
of models of P1 in C: DC (1) = V (1). This concludes the base case.
It is now assumed that DC (1) = V (1), . . . , DC (i) = V (i), and is proved that CP1 ...Pi
has the class zero equal to Mod(Ki ) and the minimal models of Pi+1 in class V (i + 1), which
proves that DC (i + 1) = V (i + 1). By induction, this proves that the sequence is generated
by reinforcement revision from the total preorder C.
Let I be a model of Ki . By construction, I ∈ C(MV (I, i, 0)). The first i revisions
increase the class of I by MDC (I, 0, i). Since DC (1), . . . , DC (i) are equal to V (1), . . . , V (i)
by the inductive assumption, this is the same as MV (I, 0, i). By definition of MV , it
holds MV (I, i, 0) = −MV (I, 0, i). As a result, MV (I, i, 0) + MDC (I, 0, i) = MV (I, i, 0) −
MV (I, i, 0) = 0: the model I is in CP1 ...Pi (0).
If I is not a model of Ki , then it may be a model of some other Kj or not. In the second
case, it is in C(V (1) + · · · + V (n) + 1). The first i steps reduce its class number by at most
DC (1) + . . . + DC (i), leading to V (1) + · · · + V (n) + 1 + DC (1) + . . . + DC (i). Since the
first i values of V and DC coincide, this is V (1) + · · · + V (n) + 1 − V (1) − · · · − V (i) =
1 + V (i + 1) + · · · + V (n), which is greater than zero.
If I is a model of some Kj then I ∈ C(MV (I, j, 0)) by the definition of C. Its class at step
i is therefore MV (I, j, 0)+MDC (I, 0, i). Since DC (1), . . . , DC (i) coincide with V (1), . . . , V (i)
by the induction hypothesis, the second term is equal to MV (I, 0, i). The sum is therefore
equal to MV (I, j, 0) + MV (I, 0, i) = MV (I, j, 0) − MV (I, i, 0) = MV (I, j, i) + MV (I, i, 0) −
MV (I, i, 0) = MV (I, j, i). By the definition of reinforced mover with i and j reversed, since
I |= Kj and I 6|= Ki then MV (I, j, i) > 0. This proves that the class of I in the order
CP1 ...Pi has index larger than zero.
The last step of the proof is to show that the models of Pi+1 are in classes of index
V (i + 1) and greater according to the ordering at step i, which is CP1 ...Pi . Let I be a model
of Pi+1 . If it does not satisfy any Kj then it is in C(V (1)+· · ·+V (n)+1). At step i its class
is at least V (1) + · · · + V (n) + 1 − DC (1) − · · · − DC (i), since DC (j) is the maximal decrease
of classes at step j. Since DC (1), . . . , DC (i) coincide with V (1), · · · , V (i) by the induction
assumption, this is equal to V (1)+· · ·+V (n)+1−V (1)−· · ·−V (i) = V (i+1)+· · ·+V (n)+1,
which is larger than V (i + 1).
324

Revision by History

If I satisfies some Kj , possibly with j = i + 1, then I ∈ C(MV (I, j, 0)) by the definition
of C. At step i, its class index is MV (I, j, 0) + MDC (I, 0, i). Since DC (1), . . . , DC (i) are
assumed equal to V (1), . . . , V (i), the second term is equal to MV (I, 0, i) and the sum to
MV (I, j, 0) + MV (I, 0, i) = MV (I, j, i). Since I |= Pi+1 , MV (I, i, i + 1) = −V (i + 1) by the
definition of MV (Definition 11 with V in place of DC ). The definition of reinforced mover
ensures that MV (I, j, i + 1) = MV (I, j, i) + MV (I, i, i + 1) = MV (I, j, i) − V (i + 1) is equal
to 0 if I |= Ki+1 and greater otherwise. Since Ki+1 has some models, the minimal value
of MV (I, j, i) − V (i + 1) is zero, proving that the minimal value of MV (I, j, i) is V (i + 1).
This proves that DC (i + 1) = V (i + 1).
Lemma 18 If reinforcement revision generates a revision sequence [K0 , P1 , K1 , . . . , Pn , Kn ]
from some total preorder, then it also generates the same sequence from a preorder in which
the minimal initial class of models of P1 is 0 or 1.
Proof. If K0 ∧ P1 is consistent then P1 has models in K0 , which is class zero.
Otherwise, let the class indexes of models of P1 be k1 < k2 < k3 < . . . Revision by P1
decreases all these numbers by k1 , making them k1 − k1 = 0, k2 − k1 , k3 − k1 , etc.
From the given initial preorder, a new one can be generated by reducing each model of
P1 of k1 − 1 classes. This new initial preorder generates the same revision sequence. The
models that do not satisfy P1 are not changed of initial class, and after revising by P1 are
still moved up one class.
The models of P1 are in classes k1 − (k1 − 1), k2 − (k1 − 1), k3 − (k1 − 1), etc. of the
new preorder. Since k1 is the minimal index of models of P1 , none of these indexes is zero.
Therefore, no model of P1 enters K0 .
The minimal class of models of P1 in the new initial preorder is 1, proving that DC (1) =
1. This implies that revising by P1 decreases the class of the models of P1 by one. As a
result, the indexes of these classes are k1 − (k1 − 1) − 1, k2 − (k1 − 1) − 1, k3 − (k1 − 1) − 1,
etc. and these coincide with k1 − k1 = 0, k2 − k1 , k3 − k1 , etc. These are the same classes
obtained revising the original preorder by P1 . The models that do not satisfy P1 are in
the same initial class and are still moved up one class. This proves that the ordering after
revising by P1 is the same as before. Therefore, from this point on the revision sequences
are identical.
Lemma 19 If reinforcement revision generates the sequence [K0 , P1 , K1 , . . . , Pn , Kn ] from
a total preorder, it is also generates the same sequence from a total preorder C such that
DC (i + 1) ≤ DC (1) + . . . + DC (i) + i + 1.
Proof. The claim is proved in two cases separately: Pi+1 has some models that satisfy some
Kj with j < i, or it does not.
Case 1: some models of Pi+1 satisfy Kj with j < i. Such models are in class zero at
step j. Therefore, they are at most in class i − j at step i. This proves that Pi+1 has some
models in class i − j, so the minimal class of its models is i − j or less: DC (i + 1) ≤ i − j,
which is less that DC (1) + . . . + DC (i) + i + 1 because i − j < i + 1.
Case 2: no model of Pi+1 is in any Kj with j < i. Let C(l) be the minimal initial class
of the models of Pi+1 . If l > DC (1) + . . . + DC (i), then all models of Pi+1 can be decreased
325

Liberatore

of l − (DC (1) + . . . + DC (i)) − 1 classes without affecting the generated sequence. Models of
class l move to class l−(l−(DC (1)+. . .+DC (i)−1)) = DC (1)+. . .+DC (i)+1. The maximal
class such a model may reach at step i is DC (1) + . . . + DC (i) + 1 + i, since each step may at
most increase the class of a model of one. Therefore, DC (i+1) ≤ DC (1)+. . .+DC (i)+i+1.
What remains to be proved is that this change does not affect the revision results.
Regarding the steps before i + 1, since the models of Pi+1 are in the initial class DC (1) +
. . . + DC (i) + 1 or greater, while the models of K1 are in the initial class DC (1), the minimal
class of models of P1 is still DC (1) and the result of revision is still K1 . Since DC (1) is the
same as before, a similar line of reasoning can be applied to the models of K2 and to DC (2),
then to K3 and so on until Ki , proving that neither K1 , . . . , Ki nor DC (1), . . . , DC (i) are
affected by the change. Since DC (1), . . . , DC (i) tell how the models are moved, at step i
the models of ¬Pi+1 are in the same classes as before the change. The models of Pi+1 are
lowered of DC (i + 1) classes. Since the change has not altered their relative initial positions,
it does not modify their relative positions at step i. The preorder at step i + 1 is therefore
the same as before.
Lemma 20 Reinforcement revision generates the revision sequence [K0 , P1 , K1 , . . . , Pn , Kn ]
from a total preorder if and only if it generates the same sequence from a total preorder such
that each DC (i) is bounded by 2i − 1.
Proof. It has been proved that if DC (1) is not 1, the preorder can be modified to make it
so.
Since DC (i + 1) is bounded by DC (1) + . . . + DC (i) + i + 1, assuming the claim for
DC (1), . . . , DC (i) leads to DC (i + 1) ≤ (21 − 1) + · · · + (2i − 1) + i + 1, which is the same
as DC (i + 1) ≤ (20 + 21 + · · · + 2i ) − 20 − 1 ∗ i + i + 1 = 21 + · · · + 2i , which is 2i+1 − 1.
Theorem 8 Establishing the existence of a total preorder generating the revision sequence
[K0 , P1 , . . . , Pn , Kn ] by reinforcement revision is in Σp2 , and is in coNP if n is a constant.
Proof. By the above lemma, a revision sequence is generated by a preorder if and only
if it is generated by a preorder for which DC (i) is between 0 and 2i − 1. As a result, the
problem can be solved by guessing a reinforcement mover V = [V (1), . . . , V (n)] for the
sequence, where each V (i) is between 0 and 2i − 1, since this implies not only the existence
of a total preorder C generating the sequence but also that DC (i) = V (i) for all indexes.
If n is a constant the guessing can be replaced by a disjunction. Checking whether V is
a reinforcement mover amount to check whether, for all I, i and j, it holds that I |= Ki
implies MV (I, i, j) = 0 if I |= Kj and MV (I, i, j) > 0 otherwise. Calculating MV (I, i, j)
can be done in polynomial time since the only checks it requires are in the form j > i and
I |= Pl . Therefore, this verification is in coNP, and the whole problem in Σp2 because of the
guessing of V .
Theorem 9 Checking the existence of a preorder generating a reinforcement revision sequence [K0 , P1 , K1 , . . . , Pn , Kn ] is coNP-complete, if n is a constant.
326

Revision by History

Proof. Membership is proved by the previous theorem. Hardness can be proved from the
problem of propositional unsatisfiability. Given a formula F , its corresponding revision
sequence is [K0 , P1 , K1 ] with K0 = a ∨ F , P1 = b and K1 = a ∧ b, where a and b are
fresh variables not occurring in F . In this sequence, K0 = a ∨ F is consistent with P1 = b.
Therefore, K1 = a ∧ b should be equivalent to their conjunction (a ∨ F ) ∧ b. If F is
unsatisfiable this is the case. Otherwise, the model of F extended by assigning a to false
and b to false is a model of K0 ∧ P1 that is not a model of K1 . This proves that the sequence
is generated by some preorder if and only if F is unsatisfiable.

References
Alchourròn, C., & Makinson, D. (1982). On the logic of theory change: Contraction functions
and their associated revision functions. Theoria, 48 (1), 14–37.
Areces, C., & Becher, V. (2001). Iterable AGM functions. In Rott, H., & Williams, M.A. (Eds.), Frontiers in Belief Revision, Applied Logic Series, pp. 261–277. Kluwer
Academic Publisher.
Baltag, A., Gierasimczuk, N., & Smets, S. (2011). Belief revision as a truth-tracking process.
In Proceedings of the Thirteenth Conference on Theoretical Aspects of Rationality and
Knowledge (TARK 2011), pp. 187–190.
Benferhat, S., Kaci, S., Le Berre, D., & Williams, M.-A. (2004). Weakening conflicting
information for iterated revision and knowledge integration. Artificial Intelligence,
153, 339–371.
Booth, R., & Meyer, T. (2006). Admissible and restrained revision. Journal of Artificial
Intelligence Research, 26, 127–151.
Booth, R., & Nittka, A. (2008). Reconstructing an agent’s epistemic state from observations
about its beliefs and non-beliefs. Journal of Logic and Computation, 18, 755–782.
Boutilier, C. (1996). Iterated revision and minimal change of conditional beliefs. Journal
of Philosophical Logic, 23, 263–305.
Carson, R., & Louviere, J. (2011). A common nomenclature for stated preference elicitation
approaches. Environmental and Resource Economics, 49 (4), 539–559.
Darwiche, A., & Pearl, J. (1997). On the logic of iterated belief revision. Artificial Intelligence Journal, 89 (1–2), 1–29.
Delgrande, J., Dubois, D., & Lang, J. (2006). Iterated revision as prioritized merging. In
Proceedings, Tenth International Conference on Principles of Knowledge Representation and Reasoning, KR-2006, pp. 210–220.
Eiter, T., & Gottlob, G. (1996). The complexity of nested counterfactuals and iterated
knowledge base revisions. Journal of Computer and System Sciences, 53 (3), 497–512.
Fagin, R., Ullman, J. D., & Vardi, M. Y. (1983). On the semantics of updates in databases.
In Proceedings of the Second ACM SIGACT SIGMOD Symposium on Principles of
Database Systems (PODS’83), pp. 352–365.
327

Liberatore

Fermé, E., & Hansson, S. (2011). AGM 25 years - Twenty-five years of research in belief
change. Journal of Philosophical Logic, 40 (2), 295–331.
Gärdenfors, P. (1988). Knowledge in Flux: Modeling the Dynamics of Epistemic States.
Bradford Books, MIT Press, Cambridge, MA.
Hild, M., & Spohn, W. (2008). The measurement of ranks and the laws of iterated contraction. Artificial Intelligence, 172 (10), 1195–1218.
Jin, Y., & Thielscher, M. (2007). Iterated belief revision, revised. Artificial Intelligence
Journal, 171 (1), 1–18.
Katsuno, H., & Mendelzon, A. O. (1991). Propositional knowledge base revision and minimal change. Artificial Intelligence, 52, 263–294.
Konieczny, S., & Pino Pérez, R. (2000). A framework for iterated revision. Journal of
Applied Non-Classical Logics, 10, 339–367.
Lehmann, D., & Magidor, M. (1992). What does a conditional knowledge base entail?
Artificial Intelligence, 55, 1–60.
Liberatore, P. (2014a). Belief revision by examples.
(CoRR), abs/1409.5340.

Computing Research Repository

Liberatore, P. (2014b). Belief revision by reliability assessment. Manuscript.
Nayak, A. (1994). Iterated belief change based on epistemic entrenchment. Erkenntnis, 41,
353–390.
Nebel, B. (1992). Syntax-Based Approaches to Belief Revision, pp. 52–88. Cambridge
University Press.
Nittka, A., & Booth, R. (2008). A method for reasoning about other agents’ beliefs from
observations. In Logic and the foundation of game and decision theory, Vol. 3 of Texts
in logic and games, pp. 153–182.
Papini, O. (2001). Iterated revision operations stemming from the history of an agent’s
observations. In Frontiers in belief revision, Vol. 22 of Applied Logic Series, pp. 279–
301. Springer.
Peppas, P. (2008). Belief revision, pp. 317–359. Elsevier.
Rott, H. (2009). Shifting priorities: Simple representations for twenty-seven iterated theory change operators. In Towards Mathematical Philosophy, Vol. 28, pp. 269–296.
Springer.
Sandholm, T., & Conen, W. (2010). Preference elicitation in combinatorial auctions. US
Patent 7,742,971.
See, K., Morrison, W., Rothman, N., & Soll, J. (2011). The detrimental effects of power
on confidence, advice taking, and accuracy. Organizational Behavior and Human
Decision Processes, 116 (2), 272–285.
Spohn, W. (1988). Ordinal conditional functions: A dynamic theory of epistemic states. In
Causation in Decision, Belief Change, and Statistics, pp. 105–134. Kluwer Academics.
Suzumura, K. (1976). Remarks on the theory of collective choice. Economica, New Series,
43, 381–390.
328

Revision by History

SyncML (2002). SyncML sync protocol, version 1.1.
Tversky, A., & Kahneman, D. (1983). Extensional versus intuitive reasoning: the conjunction fallacy in probability judgment. Psychological review, 90 (4), 293–315.
Wang, H., Zhang, J., & Johnson, T. R. (2000). Human belief revision and order effect. In
Proceedings of the 22th Annual Conference of the Cognitive Science Society.
Williams, M. (1994). Transmutations of knowledge systems. In Proceedings of the Fourth International Conference on the Principles of Knowledge Representation and Reasoning
(KR’94), pp. 619–629.
Winslett, M. (1988). Reasoning about actions using a possible models approach. In Proceedings of the Seventh National Conference on Artificial Intelligence (AAAI’88), pp.
89–93.
Zhang, D. (2004). Properties of iterated multiple belief revision. In Proceedings of the Seventh International Conference on Logic Programming and Nonmonotonic Reasoning
(LPNMR 2004), pp. 314–325.

329

Journal of Artificial Intelligence Research 52 (2015) 507-542

Submitted 11/14; published 04/15

Weighted Electoral Control
Piotr Faliszewski

faliszew@agh.edu.pl

Department of Computer Science
AGH University of Science and Technology
Krakow, Poland

Edith Hemaspaandra

eh@cs.rit.edu

Department of Computer Science
Rochester Institute of Technology
Rochester, NY 14623, USA

Lane A. Hemaspaandra

lane@cs.rochester.edu

Department of Computer Science
University of Rochester
Rochester, NY 14627, USA

Abstract
Although manipulation and bribery have been extensively studied under weighted voting, there has been almost no work done on election control under weighted voting. This
is unfortunate, since weighted voting appears in many important natural settings. In this
paper, we study the complexity of controlling the outcome of weighted elections through
adding and deleting voters. We obtain polynomial-time algorithms, NP-completeness results, and for many NP-complete cases, approximation algorithms. In particular, for scoring rules we completely characterize the complexity of weighted voter control. Our work
shows that for quite a few important cases, either polynomial-time exact algorithms or
polynomial-time approximation algorithms exist.

1. Introduction
In many real-world election systems the voters come with weights. Examples range from
stockholder elections weighted by shares, to the US Electoral College, to the often-used example of the Nassau County Board of Supervisors, to (in effect) any parliamentary system
in which the parties typically vote as blocks, to Sweden’s system of wealth-weighted voting
instituted in 1866 (and no longer used) where “the wealthiest members of the rural communities received as many as 5,000 votes” and “in 10 percent of the districts the weighted
votes of just three voters could be decisive” (Congleton, 2011). Furthermore, there are
many important voting applications within multiagent systems, e.g., in recommender systems (Ghosh, Mundhe, Hernandez, & Sen, 1999; Lu & Boutilier, 2011), planning (Ephrati
& Rosenschein, 1997), and web search (Dwork, Kumar, Naor, & Sivakumar, 2001). In these
applications, it is quite natural for the voters (i.e., agents) to be weighted (e.g., by the
amount of trust we put in them or by the power of the resources they possess).
So it is not surprising that in the study of manipulative attacks on elections, weighted
voting has been given great attention. For bribery and manipulation, two of the three most
studied types of manipulative attacks on elections, study of the case of weighted voters
has been extensively conducted. Yet for the remaining one of the three most studied types
c
2015
AI Access Foundation. All rights reserved.

Faliszewski, Hemaspaandra, & Hemaspaandra

of attacks on elections, so-called control attacks, almost no attention has been given to
the case of weighted voting; to the best of our knowledge, the only time this issue has
been previously raised is in two M.S./Ph.D. theses (Russell, 2007; Lin, 2012). This lack of
attention is troubling, since the key types of control attacks, such as adding and deleting
voters, certainly do occur in many weighted elections. As a coda to this section, we will
give some examples.
We study the complexity in weighted elections of arguably the most important types
of control—adding and deleting voters—for various election systems. We focus on scoring
rules, families of scoring rules, Condorcet-consistent rules, and weakCondorcet-consistent
rules. Control by deleting (adding) voters asks whether in a given election a given candidate
can be made to win by deleting (adding) at most a certain number of the voters (at most
a certain number of the members of the pool of potential additional voters). These control
types model issues that are found in many electoral settings, ranging from human to electronic. They are (abstractions of) issues often faced by people seeking to steer an election,
such as experts doing campaign management, and deciding for example which k people to
offer rides to the polls. Adding and deleting voters also can occur in multiagent systems.
For example, if agents are entities over the Internet, then one can attempt a denial-of-service
attack on some of them to prevent their votes from arriving on time. On the other hand,
adding voters pertains to simply encouraging some agents to vote, multiplying the existing
agents, or performing false-name attacks (for false-name attacks in related settings, see, for
example, Wagman & Conitzer, 2014; Waggoner, Xia, & Conitzer, 2012; Aziz, Bachrach,
Elkind, & Paterson, 2011).
Control was introduced (without weights) in 1992 in the seminal paper by Bartholdi,
Tovey, and Trick (1992). Control has been the subject of much attention since. That attention, and the present paper, are part of the line of work, started by Bartholdi, Tovey,
and Trick (1989, 1992) and Bartholdi and Orlin (1991), that seeks to determine for which
types of manipulative attacks on elections the attacker’s task requires just polynomial-time
computation. For a more detailed discussion of this line of work, we refer the reader to the
related work section at the end of the paper and to the surveys of Faliszewski, Hemaspaandra, Hemaspaandra, and Rothe (2009), Faliszewski, Hemaspaandra, and Hemaspaandra
(2010), and Brandt, Conitzer, and Endriss (2013).
Our main results are as follows (see Section 6 for tables summarizing our results). First,
in Section 4.1 we provide a detailed study of the complexity of voter control under scoring
protocols, for the case of fixed numbers of candidates. We show that both constructive
control by adding voters and constructive control by deleting voters are in P for t-approval
(and so this also covers plurality and t0 -veto1 ) and are NP-complete otherwise. It is interesting to compare this result to an analogous theorem regarding weighted coalitional
manipulation: There are cases where the complexities of voter control and manipulation
are the same (e.g., for plurality or for Borda) but there are also cases where voter control
is easier (t-approval for t ≥ 2, for elections with more than t candidates). Is it ever possible that weighted voter control is harder than weighted voting manipulation? We show
that weighted voter control is NP-hard for Condorcet-consistent rules with at least three
candidates (and so clearly is also NP-hard for weakCondorcet-consistent rules with at least
1. If the number of candidates is fixed, then t-veto can be expressed as (m − t)-approval, where m is the
number of candidates. If the number of candidates is unbounded, then t-veto is not t0 -approval.

508

Weighted Electoral Control

three candidates). Since weighted coalitional manipulation for the 3-candidate Llull system
is in P (Faliszewski, Hemaspaandra, & Schnoor, 2008), together with the fact that Llull is
weakCondorcet-consistent, this implies that there is a setting where weighted voter control
is harder than weighted coalitional manipulation.
In Sections 4.2 and 4.3 we focus on the complexity of weighted voter control under
t-approval and t-veto, for the case of unbounded numbers of candidates. At the start of
Section 4.2, we will explain why these are the most interesting cases. In Section 4.2 we
resolve six problems left open by Lin (2012). We establish the complexity of weighted
control by adding voters for 2-approval, 2-veto, and 3-approval, and of weighted control
by deleting voters for 2-approval, 2-veto, and 3-veto. In Section 4.3, we give polynomialtime approximation algorithms for weighted voter control under t-approval and t-veto. Our
algorithms seek to minimize the number of voters that are added or deleted.
We believe that the complexity of weighted voter control, and more generally the complexity of attacks on weighted elections, is an important and interesting research direction
that deserves much further study. In particular, our research suggests that it is worthwhile
to seek approximation algorithms for weighted elections problems and that doing so can
lead to interesting algorithms.

2. Motivation for Studying Control in Weighted Elections
In the Introduction, we noted the importance of weights in many electoral settings and
described the natural importance of—and gave pointers to the extensive line of work
studying—control attacks in many (unweighted) settings. We also stated that control attacks can naturally be expected to occur even in many weighted election settings.
In the present section, we give some examples motivating the study of weighted electoral
control.
Let us consider an academic department that has as its salient issue in a particular
term the question of what course to add to its B.S. major’s requirements. Suppose the
department is highly polarized on this issue by research area, i.e., all the faculty in a given
research area will vote as a block (either because they all agree, or because by tradition
they meet before the actual faculty meetings to, within their group, reach a group position
that they will all support). And suppose that for each group there are days/times where
the entire group would be unlikely to attend, e.g., because that time is the time of the
major yearly research conference in that area. The department chair, knowing that he or
she has the power to schedule when faculty meetings are held, and what the agenda is at
each meeting, might well model his or her task as a weighted control by deleting voters
problem, in which the voters are the groups, each group’s weight is the number of faculty
members in the groups, and the deletion limit is one.
In fact, more generally, individual voters may blur into a collection of weighted votes in
settings where the voter set partitions into groups that will express identical preferences. As
another example of this sort, at one of the authors’ schools, members of the faculty senate
are chosen by the election system known as single transferable vote. However, it is not
unheard of for departmental leaders to send out a friendly suggestion to the department’s
members regarding for whom to vote. If one assumes that the departments vote as blocks,
and one is trying to decide which candidates to add to the election, or convince not to
509

Faliszewski, Hemaspaandra, & Hemaspaandra

run in the election, in order to make a given candidate win (or not win), one in effect is
studying weighted constructive control by adding candidates, weighted constructive control
by deleting candidates, weighted destructive control by adding candidates, or weighted
destructive control by deleting candidates.
The examples just given were ones where the weightings are created by individuals
forming themselves into blocks, and that can occur even in highly political contexts. For
example, in the US House of Representatives, on issues (for example, water rights or farm
subsidies) on which a state’s delegation tends to vote as a block in the parochial interests of
its state’s constituents or companies, pressure by lobbyists on state delegations to abstain
from a given vote is in effect (give or take issues of failing to have a quorum) a control by
deleting voters attack.
However, there are also many voting cases where the weights are inherent in the standalone individual voters, and in many of these cases control attacks may well occur. For
example, consider US Corporate Elections. In these, the vote of each stockholder is weighted
by his or her number of shares. The most natural way to frame control problems in this
setting is the case of adding and deleting candidates, for example, regarding who is running
for a spot as a company officer or director. But even voter control can come into play here,
for example, through some actor sending mailings to—or phoning and speaking to—voters
to convince them to abstain from voting, or to encourage voters to vote in this election.
(The “bound on additions/deletions” model that counts number of voters, rather than their
weights, is quite reasonable in this setting, because regardless of his or her weight, a given
targeted voter can be addressed by, for example, a mailing/visit/phone-call, although in
reality one admittedly might focus more resources on the biggest stockholders.)
There are many other weighted control examples we have not presented. Let us finish
with what is an extremely high-stakes example. In the US Electoral College, which works
by majority rule among the electors, the electors from each state usually vote as a block,
since the system lets whoever has the greatest popular vote in the given state select every
elector from that state (note: two of the fifty states have different policies). Thus the issue
of, for example, whether someone such as Ralph Nader does or does not run, or does or does
not withdraw his name from consideration at some particular time, can have a sweeping
effect on the nation, in what is in effect a weighted control by adding/deleting candidates
scenario.
We have now given a number of examples, some for voter control and some for candidate
control, of settings where weighted control may occur. The examples we have given vary
in their naturalness, and for both weighted and unweighted control there certainly are
points on which the models don’t capture all the nuances of the real world. For example,
some electoral partitioning problems have geographic/contiguity constraints, groups that
are modeled as voting as blocks may in fact have defectors, and Internet denial-of-service
attacks may not have the freedom to suppress each vote independently but rather may
have to suppress all or none of the votes coming over a given line/provider (see, e.g., Chen,
Faliszewski, Niedermeier, & Talmon, 2014). Nonetheless, our belief is that the importance of
weighted elections and the importance of control attacks should not remain forever separate.
We feel that control attacks are sufficiently natural in many weighted settings—varying
from academic departments to companies’ stockholders to nations—that studying weighted
control is worth undertaking. We also feel that, although this is not the subject of the
510

Weighted Electoral Control

present paper, it will be important for experimental studies to be undertaken to see the
extent to which heuristic approaches can circumvent worst-case hardness results regarding
weighted control (see Rothe & Schend, 2013, for an assessment of this type of approach in
other settings, although see also Hemaspaandra & Williams, 2012, for a discussion of some
limitations of heuristic attacks).

3. Preliminaries
We assume that the reader is familiar with the basic notions of computational complexity
theory and the theory of algorithms. Below we provide relevant definitions and conventions
regarding elections, election rules, and control in elections. We also review some NPcomplete problems that we use in our reductions.
3.1 Elections
We take an election to be a pair E = (C, V ), where C is a set of candidates and V is a
collection of voters. Each voter has a preference order over the set C. A preference order
is a total, linear order that ranks the candidates from the most preferred one to the least
preferred one. For example, if C = {a, b, c} and some voter likes a best, then b, and then
c, then his or her preference order is a > b > c. In weighted elections, each voter v also
has a positive integer weight ω(v). A voter of weight ω(v) is treated by the election system
as ω(v) unweighted voters. Given two collections of voters, V and W , we write V + W to
denote their concatenation.
3.2 Election Rules
An election rule (or voting rule) is a function R that given an election E = (C, V ) returns
a subset R(E) ⊆ C, namely those candidates that are said to win the election.
An m-candidate scoring rule is defined through a nonincreasing vector α = (α1 , . . . , αm )
of nonnegative integers. For each voter v, each candidate c receives αpos(v,c) points, where
pos(v, c) is the position of c in v’s preference order. The candidates with the maximum
total score are the winners. Given an election E and a voting rule R that assigns scores to
the candidates, we write score E (c) to denote c’s total score in E under R. The voting rule
used will always be clear from context. Many election rules are defined through families of
scoring rules, with one scoring vector for each possible number of candidates. For example:
1. Plurality rule uses vectors of the form (1, 0, . . . , 0).
2. t-approval uses vectors (α1 , . . . , αm ), where αi = 1 for each i ∈ {1, . . . , t}, and αi = 0
for i > t. By t-veto we mean the system that for m candidates uses the (m−t)-approval
scoring vector. For m-candidate t-approval and t-veto systems we will often treat each
vote as a 0/1 m-dimensional approval vector that indicates which candidates receive
points from the vote. Naturally, such a vector contains exactly t ones for t-approval
and exactly t zeroes for t-veto.2
2. We emphasize that such a view of t-approval and t-veto is correct in settings where the set of candidates
remains fixed. If the set of candidates were to change (e.g., as in control by adding/deleting candidates),
then we would have to use the standard, preference-order-based definition.

511

Faliszewski, Hemaspaandra, & Hemaspaandra

3. Borda’s rule uses vectors of the form (m − 1, m − 2, . . . , 0), where m is the number of
candidates.
Given an election E = (C, V ), a candidate c is a Condorcet winner (weak Condorcet
winner) if for every other candidate d ∈ C −{c} it holds that more than half (at least half) of
the voters prefer c to d. Note that it is possible that there is no Condorcet winner in a given
election, and it is even possible that there is no weak Condorcet winner in a given election.
Let Condorcet denote the election system whose winner set is exactly the set of Condorcet
winners, and let weakCondorcet denote the election system whose winner set is exactly the
set of weak Condorcet winners. We say that a rule R is Condorcet-consistent if whenever
there is a Condorcet winner he or she is the sole winner elected under R. Analogously, a rule
is weakCondorcet-consistent if it elects exactly the weak Condorcet winners whenever they
exist. Every weakCondorcet-consistent system is Condorcet-consistent, but the converse
does not always hold.
There are many Condorcet-consistent rules. We will briefly touch upon the Copeland
family of rules and the Maximin rule. For a given election E = (C, V ) and two distinct
candidates c, d ∈ C, we let NE (c, d) be the number of voters that prefer c to d. Let α be a
rational number, 0 ≤ α ≤ 1. Under Copelandα the score of candidate c ∈ C is defined as:
k{d ∈ C − {c} | NE (c, d) > NE (d, c)}k + αk{d ∈ C − {c} | NE (c, d) = NE (d, c)}k,
and under Maximin the score of candidate c ∈ C is defined as mind∈C−{c} NE (c, d). The
candidates with the highest score are winners. Llull is another name for Copeland1 . Clearly,
Llull and Maximin are weakCondorcet-consistent.
3.3 Electoral Control
We focus on constructive control by adding/deleting voters in weighted elections. However,
there are also other standard types of control studied in the literature (e.g., control by
adding/deleting candidates and various forms of partitioning of candidates and voters; we
point the reader to Section 5 for a discussion of related work).
Definition 3.1. Let R be a voting rule. In both weighted constructive control by adding
voters under rule R (R-WCCAV) and weighted constructive control by deleting voters under
rule R (R-WCCDV), our input contains a set of candidates C, a collection of weighted
voters V (sometimes referred to as the registered voters) with preferences over C, a preferred
candidate p ∈ C, and a nonnegative integer k. In R-WCCAV we also have an additional
collection W of weighted voters (sometimes referred to as the unregistered voters) with
preferences over C. In these problems we ask the following questions:
1. R-WCCAV: Is there a subcollection W 0 of W , of at most k voters, such that p ∈
R(C, V +W 0 )?
2. R-WCCDV: Is there a subcollection V 0 of V , of at most k voters, such that p ∈
R(C, V −V 0 )?
Although in this paper we focus primarily on constructive control, Section 4.1 makes
some comments about the so-called destructive variants of control problems. Given a voting rule R, weighted destructive control by adding voters under rule R (R-WDCAV) and
512

Weighted Electoral Control

weighted destructive control by deleting voters under rule R (R-WDCDV) are defined analogously to their constructive variants, with the only difference being that the goal is to
ensure that the distinguished candidate p is not a winner. We mention in passing that
throughout this paper we use what is known as the nonunique-winner model (a.k.a. the
cowinner model), i.e., the goal is to make p be, or prevent p from being, an element of the
winner set. We consider the nonunique-winner model to be a cleaner and more natural
model than the so-called unique-winner model, in which p must be made or kept from being
a one-and-only winner of the election, as that model more strongly blurs tie-breaking issues
with control issues.
Note that in the above definitions the parameter k defines the number of voters that can
be added/deleted, and not the total weight of the voters that can be added/deleted. This is
a standard approach when modeling strategic behavior in weighted elections. For example,
in the study of “R-weighted-bribery” (Faliszewski, Hemaspaandra, & Hemaspaandra, 2009),
bribing each weighted voter has unit cost regardless of the voter’s weight, and in the study
of weighted manipulation in nearly single-peaked societies (Faliszewski, Hemaspaandra,
& Hemaspaandra, 2014), the “mavericity” of a society depends on the number of so-called
mavericks rather than their total weight. As to what k might be “in practice,” k is reflecting
the ability of the chair to add/delete voters, and so k in practice would reflect how many
voters the chair is viewed as having the resources to lure in or pressure out.
We will consider approximation algorithms for WCCAV and WCCDV under t-approval
and t-veto. When doing so, we will assume that input instances do not contain the integer
k. Rather, the goal is simply to find (when success is possible at all) as small as possible a
collection of voters to add/delete such that p is a winner of the resulting election. (Just as
mentioned in the previous paragraph, we again are counting the number of added/deleted
voters, not the total weight of the added/deleted voters.) For a positive integer h, an
h-approximation algorithm for WCCAV/WCCDV is an algorithm that (when success is
possible at all) always finds a solution that adds/deletes at most h times as many voters as an
optimal action does. The notion of an f (·)-approximation algorithm for WCCAV/WCCDV
is defined analogously, where the argument to f is some variable related to the problem
or instance. And the meaning of O(f (·))-approximation algorithms will be similarly clear
from context. It is natural to worry about how the above seemingly incomplete definitions
interact with the possibility that success might be impossible regardless of how many votes
one adds/deletes. However, for t-approval WCCDV and t-veto WCCDV (and indeed, for
any scoring rule), it is always possible to ensure that p is a winner, for example by deleting
all the voters (recall that we are in the nonunique-winner model). For t-approval WCCAV
and t-veto WCCAV, it is possible to ensure p’s victory through adding voters if and only if
p is a winner after we add all the unregistered voters that approve of p. These observations
make it particularly easy to discuss and study approximation algorithms for t-approval and
for t-veto, because we can always easily check whether there is some solution. For voting
rules that don’t have this easy-checking property, such an analysis might be much more
complicated. The reader may wish to compare our work with Brelsford et al.’s attempt
at framing a general election-problem approximation framework (Brelsford, Faliszewski,
Hemaspaandra, Schnoor, & Schnoor, 2008).
In this paper we do not consider candidate-control cases (such as weighted constructive control by adding candidates and weighted constructive control by deleting candidates,
513

Faliszewski, Hemaspaandra, & Hemaspaandra

WCCAC and WCCDC). The reason is that for a bounded number of candidates, when
winner determination in the given weighted election system is in P it holds that both WCCAC and WCCDC are in P by brute-force search. On the other hand, if the number of
candidates is not bounded then candidate control is already NP-hard for plurality (and
t-approval and t-veto, in both the constructive setting and the destructive setting) even
without weights (Bartholdi et al., 1992; Hemaspaandra, Hemaspaandra, & Rothe, 2007;
Elkind, Faliszewski, & Slinko, 2011; Lin, 2012). Furthermore, many results for candidate
control under Condorcet-consistent rules can be claimed in the weighted setting. For example, for the Maximin rule and for the Copeland family of rules, hardness results translate
immediately, and it is straightforward to see that the existing polynomial-time algorithms
for the unweighted cases also work for the weighted cases (Faliszewski, Hemaspaandra, &
Hemaspaandra, 2011).
3.4 Weighted Coalitional Manipulation
One of our goals is to compare the complexity of weighted voter control with the complexity
of weighted coalitional manipulation (WCM). WCM is similar to WCCAV in that we also
add voters, but it differs in that (a) we have to add exactly a given number of voters, and
(b) we can pick the preference orders of the added voters. It is quite interesting to see how
the differences in these problems’ definitions affect their complexities.
Definition 3.2. Let R be a voting rule. In R-WCM we are given a weighted election (C, V ),
a preferred candidate p ∈ C, and a sequence k1 , . . . , kn of positive integers. We ask whether
it is possible to construct a collection W = (w1 , . . . , wn ) of n voters such that for each i,
1 ≤ i ≤ n, ω(wi ) = ki , and p is a winner of the R election (C, V +W ). The voters in W
are called manipulators.
3.5 Computational Complexity
In our NP-hardness proofs we use reductions from the following NP-complete problems.
Definition 3.3. An instance of Partition consists of a sequence (k1 , . . . , kt ) of
Ppositive
integers whose sum is even. We ask whether there is a set I ⊆ {1, . . . , t} such that i∈I ki =
1 Pt
i=1 ki .
2
In the proof of Theorem 4.3 we will use the following restricted version of Partition,
where we have greater control over the numbers involved in the problem.
Definition 3.4. An instance of Partition 0 consists of a sequence (k1 , . . . , kt ) of positive
integers, whose sum is P
even, such that (a) t is an even number, and (b) for each ki , 1 ≤ i ≤ t,
1
it holds that ki ≥ t+1 tj=1 kj . We ask whether there is a set I ⊆ {1, . . . , t} of cardinality
P
t
1 Pt
i∈I ki = 2
i=1 ki .
2 such that
Showing the NP-completeness of this problem is a standard exercise. (In particular, the
NP-completeness of a variant of this problem is established as Lemma 2.3 in Faliszewski
et al., 2009; the same approach can be used to show the NP-completeness of Partition0 .)
Our remaining hardness proofs are based on reductions from a restricted version of the wellknown Exact-Cover-By-3-Sets problem. This restricted version is still NP-complete (Garey
& Johnson, 1979).
514

Weighted Electoral Control

Definition 3.5. An instance of X3C 0 consists of a set B = {b1 , . . . , b3t } and a family
S = {S1 , . . . , Sn } of 3-element subsets of B such that every element of B occurs in at least
one and in at most three sets in S. We ask whether S contains an exact cover for B, i.e.,
whether there exist t sets in S whose union is B.
Our choice to use X3C0 as the basis of some of our reductions, and the particular way
we use it, will allow us to achieve something beyond simply showing that a given weighted
control result is NP-complete. We will indeed be able to show that certain weighted control
results for important election systems remain NP-complete even when the allowed set of
weights is highly restricted, e.g., in some cases, the allowed weight set can be {1, 2} or
{1, 3}. Our cases of this sort appear within the proof of Theorem 4.13 and are highlighted
in the paragraph immediately preceding that theorem.

4. Results
We now present our results. In Section 4.1 we focus on fixed numbers of candidates in
scoring protocols, weakCondorcet-consistent rules, and Condorcet-consistent rules. Then in
Sections 4.2 and 4.3 we consider case of an unbounded number of candidates, for t-approval
and t-veto.
4.1 Bounded Numbers of Candidates
It is well-known that weighted manipulation of scoring protocols is always hard, unless the
scoring protocol is in effect plurality or triviality (Hemaspaandra & Hemaspaandra, 2007).
In contrast, weighted voter control is easy for m-candidate t-approval.
Theorem 4.1. For all m and t, WCCAV and WCCDV for m-candidate t-approval are
in P.
Proof. Let (C, V, W, p, k) be an instance of WCCAV for m-candidate t-approval. We can
assume that we add only voters who approve of p. We can also assume that we add
the heaviest voters with a particular set of approvals, i.e., if we add ` voters approving
p, c1 , . . . , ct−1 , we can assume
 that we added the ` heaviest voters approving p, c1 , . . . , ct−1 .
m−1
Since there are only t−1 —which is a constant—different sets of approvals to consider,
it suffices to try all sequences of nonnegative integers k1 , . . . , k(m−1) whose sum is at most
t−1
k, and for each such sequence to check whether adding the heaviest ki voters of the ith
approval collection makes p a winner.
For each fixed m and t, it is clear that this algorithm, although brute-force in nature,
runs in time polynomial in the input size. (The actions the algorithm uses are relatively
innocuous, in fact. For example, we use sorting to group together votes within W that have
identical sets of approvals, and to sort each of those in descending order of voter weight.
And the number of sequences of nonnegative integers k1 , . . . , k(m−1) whose sum is at most
t−1

m−1
k is easily bounded by (k + 1)( t−1 ) , and this for fixed m and t is polynomial in the input
size despite the fact that k is input in binary, because we may without loss of generality
m−1
assume that k ≤ kW k. We mention in passing that the (k + 1)( t−1 ) bound is often wildly
loose. In particular, the exact number of sequences of nonnegative integers k1 , . . . , k(m−1)
t−1

515

Faliszewski, Hemaspaandra, & Hemaspaandra

+k0 −1
(m−1
t−1 )
. So summing that from k 0 equals 0 to k 0 equals k
m−1
( t−1 )−1
gives the number of sequences we will face.)
The same approach and argument work for WCCDV. Here, we delete only voters that
do not approve of p, and again we delete the heaviest voters for each approval collection.
Again, with m and t fixed, the running time is easily seen to be polynomial.

whose sum is exactly k 0 is

One might think that the argument above works for any scoring protocol, but this is
not the case. For example, consider the 3-candidate Borda instance where V consists of one
weight-1 voter b > p > a and W consists of a weight-2 and a weight-1 voter with preference
order a > p > b. Then adding the weight-1 voter makes p a winner, but adding the weight-2
voter does not. And, in fact, we have the following result.3
Theorem 4.2. WCCAV and WCCDV for Borda are NP-complete. This result holds even
when restricted to a fixed number m ≥ 3 of candidates.
Proof. We start by considering the case of adding voters. We reduce from Partition. Given
a sequence k1 , . . . , kt of positive integers that sum to 2K, construct an election with one
registered voter of weight K voting b > p > a > · · · , and t unregistered voters with weights
k1 , . . . , kt voting a > p > b > · · · . Set the addition limit to t. With m candidates, the
(initial) score of b is K(m − 1), the score of p is K(m − 2), and the score of a is K(m − 3).
Thus, for p to become a winner, b’s score (relative to p) needs to go down by at least K,
while a’s score (relative to p) should not go up by more than K. It follows that k1 , . . . , kt
has a partition if and only if p can be made a winner.
We use the same construction for the deleting voters case. Now, all voters are registered
and the deletion limit is t. Since we can’t delete all voters and since our goal is to make p
a winner, we cannot delete the one voter voting b > p > a > · · · (since then a would be the
unique winner). The rest of the argument is identical to the case of adding voters.
Interestingly, it is possible to extend the above proof to work for all scoring protocols
other than t-approval (the main idea stays the same, but the technical details are more
involved). And so, regarding the complexity of WCCAV and WCCDV for scoring protocols
with a fixed number of candidates, the cases of Theorem 4.1 are the only P cases (assuming
P 6= NP).
Theorem 4.3. For each scoring protocol (α1 , . . . , αm ), if there exists an i, 1 < i < m, such
that α1 > αi > αm , then WCCAV and WCCDV for (α1 , . . . , αm ) are NP-complete.
Proof. Let α = (α1 , . . . , αm ) be a scoring protocol such that there is an i such that α1 > αi >
αm . Let δ be the third largest value in the set {α1 , . . . , αm }. We will show that WCCAV
and WCCDV are NP-complete for scoring protocol β = (β1 , . . . , βm ) = (α1 − δ, . . . , αm − δ).
While formally we have defined scoring protocols to contain only nonnegative values, using
β simplifies our construction and does not affect the correctness of the proof. To further
simplify notation, given some candidates x1 , . . . , x` , by F [x1 = βi1 , x2 = βi2 , . . . , x` = βi` ]
we mean a fixed preference order that ensures, under β, that each xj , 1 ≤ j ≤ `, is ranked
3. An analogue of this theorem in the model in which we are bounding the total weight of votes that can
be added/deleted was obtained by Russell (2007).

516

Weighted Electoral Control

at a position that gives βij points. (The candidates not mentioned in the F [. . .] notation are
ranked arbitrarily.) We let γ1 , γ2 , and γ3 be the three highest values in the set {β1 , . . . , βm }.
Clearly, β1 = γ1 > γ2 > γ3 = 0. (Note that γ2 might be different from β2 , and γ3 might
be different from β3 . For example, if β = (3, 3, 2, 0, 0, −1, −1), then γ1 = 3, γ2 = 2, and
γ3 = 0, but β1 = 3, β2 = 3, and β3 = 2.)
We give a reduction from Partition to β-WCCAV (the membership of β-WCCAV in NP
is clear); let (k1 , . . . , kt ) be an instance of Partition, i.e., a sequence of positive integers that
sum to 2K. We form an election E = (C, V ) where C = {p, a, b, c4 , . . . , cm } and where the
collection V contains the following three groups of voters (for the WCCAV part of the proof
below, we set T = 1; for the WCCDV part of the proof we will use the same construction
but with a larger value of T ):
1. A group of T voters, each with weight K and preference order F [b = γ1 , a = γ2 , p = 0].
2. A group of T voters, each with weight K and preference order F [p = γ1 , b = γ2 , a = 0].
3. For each ci ∈ C, there are 6 collections of 2T voters, one collection for each permutation (x, y, z) of (p, a, b); the voters in each collection have weight K and preference
order F [x = β1 , y = β2 , z = β3 , ci = βm ].
Let M be the number of points that each of a, b, and p receive from the third group
of voters (each of these candidates receives the same number of points from these voters).
For each ci ∈ C and each x ∈ {p, a, b}, x receives at least 4T Kγ1 points more than ci from
the voters in the third group (in each vote in the third group, x receives at least as many
points as ci , and there are two collections of 2T voters where x receives β1 = γ1 points and
ci receives βm ≤ 0 points). Thus it holds that our candidates have the following scores:
1. p has M + T Kγ1 points,
2. a has M + T Kγ2 points,
3. b has M + T K(γ1 + γ2 ) points, and
4. each candidate ci ∈ C has at most M − 2T Kγ1 points (each ci ∈ C receives at most
M − 4T Kγ1 points from the third group of voters and at most 2T Kγ1 points from
the first two groups of voters).
As a result, b is the unique winner. There are t unregistered voters with weights
T k1 , . . . , T kt , each with preference order F = [a = γ1 , p = γ2 , b = 0]. We set the addition limit to be t. It is clear that irrespective of which voters are added, none of the
candidates in {c4 , . . . , cm } becomes a winner.
If there is a subcollection of (k1 , . . . , kt ) that sums to K, then adding corresponding
unregistered voters to the election ensures that all three of p, a, and b are winners (each
with score M + T K(γ1 + γ2 )). On the other hand, assume that there are unregistered voters
of total weight T L, whose addition to the election ensures that p is among the winners. After
adding these voters to the election, p has M +T Kγ1 +T Lγ2 points, a has M +T Lγ1 +T Kγ2
points, and b has M + T Kγ1 + T Kγ2 points. For p to have score at least as high as b, we
must have that L ≥ K. However, for a not to have score higher than p, it must be the case
517

Faliszewski, Hemaspaandra, & Hemaspaandra

that L ≤ K (recall that γ1 > γ2 ). This means that L = K. Thus it is possible to ensure
that p is a winner of the election by adding at most t unregistered voters if and only if there
is a subcollection of (k1 , . . . , kt ) that sums to K. And, completing the proof, we note that
the reduction can be carried out in polynomial time.
Let us now move on to the case of WCCDV. We will use the same construction, but
with the following modifications:
1. Our reduction is now from Partition0 . Thus without loss of generality we can assume
1
that t is an even number and that for each i, 1 ≤ i ≤ t, it holds that ki ≥ 1+t
2K.
l
m
1
2. We set T = 2t (t + 1) γ1γ−γ
+ 1 (the reasons for this choice of T will become apparent
2
in the course of the proof; intuitively it is convenient to think of T as of a large value
that, nonetheless, is polynomially bounded with respect to t).
3. We include the unregistered voters as “the fourth group of voters.”
4. We set the deletion limit to 2t .
Including the fourth group of voters, candidates have the following scores: p has M +
T Kγ1 + 2T Kγ2 points, a has M + T Kγ2 + 2T Kγ1 points, b has M + T K(γ1 + γ2 ) points,
and each candidate ci ∈ C has at most M points.
By the same reasoning as in the WCCAV case, we see that if there is a size- 2t subcollection of k1 , . . . , kt that sums to K, then deleting the corresponding voters ensures that
p is among the winners (together with a and b); we may imagine that we first remove all
the voters from the fourth group and then add back those 2t of them, whose weights sum
to T K. We now show that if there is a way to delete up to 2t voters to ensure that p is
among the winners, then the deleted voters must come from the fourth group, must have
total weight K, and there must be exactly 2t of them. For the sake of contradiction, let us
assume that it is possible to ensure p’s victory by deleting up to 2t voters, of whom fewer
than 2t come from the fourth group. Let s be the number of deleted voters from the fourth
group (s < 2t ) and let x be a real number such that xT K is their total weight. We have
that xT K is at most (see below for explanation regarding the first inequality)


t
t−s
t
2 +1
(2T K) ≤ 2T K 1 −
.
xT K ≤ 2T K −
= TK
1+t
1+t
1+t
t
That is, we have 0 ≤ x ≤ 1+t
. To see why the first inequality holds, recall that the
1
lowest weight of a voter from the fourth group is at least 1+t
2T K (because we reduce from
0
Partition ). Thus the highest total weight of s voters from the fourth group is, at most, the
total weight of the fourth-group voters (2T K) less the weight of the lightest t − s voters
t−s
(2T K)).
from this group (which is at least 1+t
Prior to deleting any voters, a has T K(γ1 − γ2 ) points more than p. After deleting
the s voters from the fourth group, this difference decreases to T K(1 − x)(γ1 − γ2 ). If we
additionally delete up to 2t voters from the first three groups of voters, each with weight K,
then the difference between the scores of a and p decreases, at most, to the following value
(note that in each deleted vote both a and p are ranked at positions where they receive γ1 ,

518

Weighted Electoral Control

γ2 , or 0 points):
t
1
t
T K(1−x)(γ1 −γ2 )− Kγ1 ≥ T K
(γ1 −γ2 )− Kγ1 = K
2
t+1
2



t
(t + 1)γ1
T (γ1 − γ2 )
− 2
t+1
t+1


> 0.

The final inequality follows by our choice of T . The above calculation shows that if there
is a way to ensure p’s victory by deleting up to 2t voters then it requires deleting exactly
t
2 voters from the fourth group. The same reasoning as in the case of WCCAV shows that
these 2t deleted voters must correspond to a size- 2t subcollection of (k1 , . . . , kt ) that sums
to K.
As a side comment, we mention that WDCAV and WDCDV for scoring protocols (that
is, the destructive variants of WCCAV and WCCDV) have simple polynomial-time algorithms: It suffices to loop through all candidates c, c 6= p, and greedily add/delete voters
to boost the score of c relative to p as much as possible.
Theorem 4.4. For each scoring protocol α = (α1 , . . . , αm ), α-WDCAV and α-WDCDV
are in P.
Combining Theorems 4.1 and 4.3, we obtain the following corollary, which we contrast with an analogous result for WCM (Hemaspaandra & Hemaspaandra, 2007); we also
mention in passing the recent attainment of a dichotomy result for voter control under
so-called pure scoring rules, for unweighted elections and an unbounded number of candidates (Hemaspaandra, Hemaspaandra, & Schnoor, 2014).
Corollary 4.5. For each scoring protocol (α1 , . . . , αm ) the problems WCCAV and WCCDV
are NP-complete if k{α1 , . . . , αm }k ≥ 3 and are in P otherwise.
Theorem 4.6 (Hemaspaandra & Hemaspaandra, 2007). For each scoring protocol
(α1 , . . . , αm ), m ≥ 2, WCM is NP-complete if α2 > αm and is in P otherwise.
We see that for scoring protocols with a fixed number m of candidates, either WCM
is harder than WCCAV and WCCDV (for the case of t-approval with 2 ≤ t < m), or
the complexity of WCM, WCCAV, and WCCDV is the same (P-membership for plurality
and triviality, and NP-completeness for the remaining cases). One may wonder which
property of WCM is responsible for the fact that for t-approval, 2 ≤ t ≤ m, WCM is
harder than WCCAV and WCCDC. Speaking very informally, the answer is that WCM
intimately involves the instantiation of the values of the (initially unspecified) votes of the
manipulators, and in this particular setting that is, in effect, requiring them to solve a
Partition problem. On the other hand, in WCCAV and WCCDV the preference orders of
all the voters are fixed in the input, and the chair chooses only which votes to add; this, for
example, facilitated the polynomial-time algorithm in the proof of Theorem 4.1.
There are, nonetheless, voting rules for which WCM is easier than WCCAV and
WCCDV. This happens, for example, if on the one hand in WCCAV and WCCDV under the particular rule the chair has to balance out differing votes in a way that makes
these problems hard, yet on the other hand for WCM under the particular rule we can
show that if there is any successful manipulation then there is one in which all the manipulators cast identical votes. Theorem 4.7, Corollary 4.8, and their proofs present exactly
such a case.
519

Faliszewski, Hemaspaandra, & Hemaspaandra

Theorem 4.7. For every weakCondorcet-consistent election system and for every
Condorcet-consistent election system, WCCAV and WCCDV are NP-hard. This result holds
even when restricted to a fixed number m ≥ 3 of candidates.
Proof. To show that WCCAV is NP-hard, we reduce from Partition. Given a sequence
k1 , . . . , kt of positive integers that sum to 2K, construct an election with two registered
voters, one voter with weight 1 voting p > a > b > · · · and one voter with weight 2K voting
b > p > a > · · · , and t unregistered voters with weights 2k1 , . . . , 2kt voting a > p > b > · · · .
Set the addition limit to t. Suppose we add unregistered voters to the election with a total
vote weight equal to 2L.
• If L < K, then b is the Condorcet winner, and thus the unique winner of the election.
• If L > K, then a is the Condorcet winner, and thus the unique winner of the election.
• If L = K, then p is the Condorcet winner, and thus the unique winner of the election.
The WCCDV case uses the same construction. Now, all voters are registered and the
deletion limit is t. Since we can delete at most t of our t + 2 voters, and since our goal is
to make p a winner, we can’t delete the sole voter voting b > p > a, since then a would be
the Condorcet winner. The rest of the argument is similar to the adding voters case.
Recall from Section 3 that Condorcet denotes the election system whose winner set is
exactly the set of Condorcet winners, and weakCondorcet denotes the election system whose
winner set is exactly the set of weak Condorcet winners.
Corollary 4.8. For Condorcet and weakCondorcet, WCM is in P and WCCAV and
WCCDV are NP-complete. This result holds even when restricted to a fixed number m ≥ 3
of candidates.
Proof. It is immediate that WCM for Condorcet and weakCondorcet are in P. To see if we
have a “yes”-instance of WCM, it suffices to check whether letting all the manipulators rank
p (the preferred candidate) first and ranking all the remaining candidates in some arbitrary
order ensures p’s victory. NP-completeness of WCCAV and WCCDV follows directly from
Theorem 4.7.
Condorcet and weakCondorcet do not always have winners. For those who prefer their
voting systems to always have at least one winner, we note that WCM for 3-candidate Llull
is in P (Faliszewski et al., 2008).
Corollary 4.9. For 3-candidate Llull, WCM is in P and WCCAV and WCCDV are NPcomplete.
The main results of this section are also presented in Table 1 of Section 6.
520

Weighted Electoral Control

4.2 t-Approval and t-Veto with an Unbounded Number of Candidates
Let us now look at the cases of t-approval and t-veto rules, for an unbounded number of
candidates. The reason we focus on these is that these are the most interesting families of
scoring protocols whose complexity has not already been resolved in the previous section.
The reason we say that is that Theorem 4.3 shows that whenever we have at least three
distinct values in a scoring vector, we have NP-completeness. So any scoring-protocol family
that, for some number of candidates, has three distinct values in its scoring vector is NPhard for WCCAV and WCCDV. Thus the really interesting cases are indeed t-approval and
t-veto.
Our starting point here is the work of Lin (2012), which showed that for t ≥ 4, WCCAV
for t-approval and WCCDV for t-veto are NP-complete, and that for t ≥ 3, WCCDV
for t-approval and WCCAV for t-veto are NP-complete. These results hold even for the
unweighted case. It is also known that the remaining unweighted cases are in P (Bartholdi
et al., 1992; Lin, 2012) and that WCCAV and WCCDV for plurality and veto are in P (Lin,
2012). In this section, we look at and solve the remaining open cases, WCCAV for 2approval, 3-approval, and 2-veto, and WCCDV for 2-approval, 2-veto, and 3-veto. We
start by showing that 2-approval-WCCAV is in P. We point out that our proof techniques
(especially the polynomial-time algorithms for 2-approval-WCCAV and for 2-veto-WCCDV)
are quite different from those of Lin (2012).
Theorem 4.10. WCCAV for 2-approval is in P.
Proof. We claim that Algorithm 1 solves 2-approval-WCCAV in polynomial time. (In this
algorithm and the proof of correctness, whenever we speak of the r heaviest voters in voter
set X, we mean the min(r, kXk) heaviest voters in X.)
We note that we will add only voters that approve of p. Thus we delete from W all the
voters who do not approve of p.
Let us consider the repeat-until loop in Algorithm 1. If we reject in the first iteration of
this loop (in the first forall loop) then, clearly, there is no solution for the given instance.
Furthermore, we claim that if there is a solution to the input instance, then after the second
forall loop it is still possible to find it. To see this, consider some candidate c ∈ C − {p}
and some number ` ∈ {1, . . . , k − 1}. If the sum of the weights of k − ` heaviest voters in
W that do not approve of c is less than sc (that is, is less than the difference between the
score of c and the score of p in the original election), then we certainly need to add at least
k − ` + 1 voters who do not approve of c. However, since altogether we can add at most k
voters, this means that we can add at most ` − 1 voters who do approve of c. In effect, we
can safely delete from W all but ` − 1 heaviest voters who approve of c (as in the proof of
Theorem 4.1, if we decide to add some r voters approving {p, c}, we may assume that we
add the r heaviest voters approving {p, c}; thus keeping only the ` − 1 heaviest voters that
approve of {p, c} is a correct strategy).
So, if we reject in the first iteration of the repeat-until loop, then certainly there is no
solution for the input instance, and if we do not, then we start the second iteration with
an instance that has a solution if and only if the original one had. Thus, by induction, we
never reject incorrectly in the repeat-until loop. If we get through the repeat-until without
rejecting, and we have fewer than k voters left in W , then adding all of W is the best we
can do (since all voters in W approve p).
521

Faliszewski, Hemaspaandra, & Hemaspaandra

Algorithm 1: 2-approval-WCCAV
Input: (C, V, W, p, k)
forall c ∈ C − {p} do
let sc = score(C,V ) (c) − score(C,V ) (p).
Delete from W all voters that do not approve of p.
repeat
forall c ∈ C − {p} do
if the sum of the weights of the k heaviest voters in W that do not approve of c is
less than sc then reject
// It is impossible to get score(c) ≤ score(p) by adding less than or equal to k voters
from W .
forall c ∈ C − {p} and ` ∈ {1, . . . , k − 1} do
if the sum of the weights of the k − ` heaviest voters in W that do not approve of c is
less than sc then
delete from W all voters approving c except for the ` − 1 heaviest such voters.
// We need to add at least k − ` + 1 voters that do not approve of c, and so we
can add at most ` − 1 voters approving c.
until no more changes.
if kW k ≥ k then accept // We can make p a winner by adding the k heaviest voters from
W.
if kW k < k then
if adding all of W will make p a winner then accept else reject

On the other hand, if we get through the repeat-until loop, and we have at least k voters
left in W , then adding the k heaviest voters from W will make p a winner. Why? Let c be a
candidate in C −{p}. Let r be the number of voters from W that are added and that approve
of c. Since we made it through the repeat-until, we know that [the sum of the weights of
the k heaviest voters in W that do not approve of c] is at least sc (because we did not reject
in the first forall loop). We will show that after adding the voters, score(c) − score(p) ≤ 0,
which implies that p is a winner. If r = 0, score(c) − score(p) = sc - [the sum of the weights
of the k heaviest voters in W ] ≤ 0. If r > 0, then [the sum of the weights of the k − r
heaviest voters in W that do not approve of c] is at least sc (for otherwise we would have at
most r − 1 voters approving c left in W due to the if statement in the second forall loop).
And so score(c) − score(p) = sc - [the sum of the weights of the k − r heaviest voters in W
that do not approve of c] ≤ 0.
Theorem 4.11. WCCDV for 2-veto is in P.
Instead of proving this theorem directly, we show a more general relation between the
complexity of t-approval/t-veto WCCAV and WCCDV.
Theorem 4.12. For each fixed t, it holds that t-veto-WCCDV (t-approval-WCCDV)
polynomial-time many-one reduces to t-approval-WCCAV (t-veto-WCCAV).
Proof. We first give a reduction from t-veto-WCCDV to t-approval-WCCAV. The idea is
that deleting a t-veto vote v from t-veto election (C, V ) is equivalent, in terms of net effect
on the scores, to adding a t-approval vote v 0 to this election, where v 0 approves exactly of
522

Weighted Electoral Control

the t candidates that v disapproves of. The problem with this approach is that we are to
reduce t-veto-WCCDV to t-approval -WCCAV and thus we have to show how to implement
t-veto scores with t-approval votes.
Let (C, V, p, k) be an instance of t-veto-WCCDV, where V = (v1 , . . . , vn ). Let m = kCk.
Let ωmax be the highest weight of a vote in V . We set D to be a set of up to t − 1 new
candidates, such that kCk + kDk is a multiple of t. We set V0 to be a collection of kCk+kDk
t
t-approval votes, where each vote has weight ωmax and each candidate in C ∪ D is approved
(t−1)(m−t)
in exactly one of the votes. For each vote vi in V we create a set Ci = {c1i , . . . , ci
}
of candidates and we create a collection of voters Vi = (vi1 , . . . , vim−t ). Each voter vij ,
1 ≤ j ≤ m − t, has weight ω(vi ) and approves of the jth candidate approved by v and of
(j−1)(t−1)+1
j(t−1)
the t − 1 candidates ci
, . . . , ci
.
S
0
0
0
We form an election E = (C , V ), where C 0 = C∪D∪ ni=1 Ci and V 0 = V0 +V1 +· · ·+Vn .
For each candidate c, let sc be c’s t-veto score in (C, V ); we see that c’s t-approval score in
E 0 is ωmax + sc (every candidate from C receives a single approval from one weight ωmax
voter from V0 and for each voter vi in V and for each candidate c that vi approves of, there
is a unique voter in Vi that has the same weight as vi and that approves of c). Furthermore,
each candidate c ∈ C 0 −C has t-approval score at most ωmax in E 0 (each candidate in C 0 −C
is approved by exactly one voter in V 0 and each voter in V 0 has weight at most ωmax ).
We form an instance (C 0 , V 0 , W, p, k) of t-approval-WCCAV, where W = (w1 , . . . , wn ),
and for each i, 1 ≤ i ≤ n, ω(wi ) = ω(vi ), and wi approves exactly of those candidates
that vi disapproves of; adding voter wi to t-approval election (C 0 , V 0 ) has the same net
effect on the scores of the candidates in C as does deleting vi from t-veto election (C, V ).
(The role of the candidates in D is to pad the election so that it is easy to use t-approval
votes—those in V0 —to ensure that the candidates in C have at least as many points as the
other candidates, irrespective of which voters we add.) This completes the reduction.
Let us now give a reduction from t-approval-WCCDV to t-veto-WCCAV. The idea is
the same as in the previous reduction and the main difficulty of the proof is to show how to
implement t-approval scores with t-veto votes.4 In particular, the role of the candidates in
D is, again, to provide a convenient way of padding the election and implementing the scores
of the other candidates. However, this time the construction is more involved because of the
nature of t-veto: as opposed to the case of t-approval, under t-veto if we add a candidate
to the election then the total number of candidates approved per vote increases.
Let (C, V, p, k) be an instance of t-approval-WCCDV, where V = (v1 , . . . , vn ). Let
m = kCk and let ωmax be the highest weight of a vote in V . We set D to be a set of
candidates such that t ≤ kDk ≤ 2t − 1 and kCk + kDk = s · t for some integer s, s ≥ 3
(note that for our setting to not be trivial it must be the case that m > t). We set V0
to be a collection of 4n(s − 2) (t-veto) votes (over candidate set C ∪ D), each with weight
ωmax ; each candidate from C is approved in all these votes whereas each candidate from
D is disapproved in at least half of them (since t ≤ kDk ≤ 2t − 1, it is easy to construct
4. The reader may wonder why we do not simply use the previous argument by applying it to (m − t)-veto
and (m − t)-approval. The reason is that given an instance of (m − t)-veto-WCCDV (with m candidates
and n voters), our reduction would output an instance of (m − t)-approval-WCCAV with more than m
candidates. Thus it would not be correct to interpret this instance as a t-veto-WCCAV instance.

523

Faliszewski, Hemaspaandra, & Hemaspaandra

such votes5 ). For each vote vi in V , we create a collection Vi of (s − 1) votes satisfying the
following requirements: (a) each candidate approved in vi is also approved in each of the
votes in Vi , and (b) each candidate not approved in vi , is approved in exactly (s − 2) votes
in Vi . (Such votes are easy to construct: We always place the top t candidates from vi in
the top t positions of the vote; for the remaining positions, in the first vote we place the
candidates in some arbitrary, easily computable order, and in each following vote we shift
these candidates cyclically by t positions with respect to the previous vote.) Each vote in
Vi has weight ω(vi ).
We form an election E 0 = (C 0 , V 0 ), where C 0 = C ∪ D and V 0 = V0 + V1 + · · · + Vn . For
0
each candidate c, let sc be c’s
Pnt-approval score in (C, V ); we see that c’s t-veto score in E
is 4n(s − 2)ωmax + (s − 2)( i=1 ω(vi )) + sc (c is approved by every voter from V0 and by
at least s − 2 voters from each group Vi , 1 ≤ i ≤ n; additionally, for every voter vi that
approves of c, there is the (s − 1)’th voter in group Vi that approves of c). Furthermore,
each candidate from D has t-veto score at most 3n(s − 2)ωmax in E 0 (each of them gets at
most 2n(s − 2)ωmax points from the voters in V0 and at most (s − 2)ωmax points from each
Vi , 1 ≤ i ≤ n).
We form an instance (C 0 , V 0 , W, p, k) of t-veto-WCCAV, where W = (w1 , . . . , wn ), and
for each i, 1 ≤ i ≤ n, ω(wi ) = ω(vi ), and wi disapproves of exactly those candidates that vi
approves of; adding voter wi to t-veto election (C 0 , V 0 ) has the same net effect on the scores
of candidates in C as deleting voter vi from t-approval election (C, V ) has. Furthermore,
since each candidate in D has at least nωmax fewer points than each candidate in C, the
fact that adding wi increases scores of candidates in D does not affect the correctness of
our reduction.
All other remaining cases (WCCDV for 2-approval, WCCAV for 3-approval, WCCAV
for 2-veto, and WCCDV for 3-veto) are NP-complete. Interestingly, in contrast to many
other NP-complete weighted election problems, we need only a very limited set of weights
to make the reductions work. Namely, due to the choice of reducing from X3C0 and due
to the particular reductions we build, the proof of the following theorem establishes (the
details of why are given within the proof) that (a) for every pair of integers 1 ≤ a < b, it
holds that WCCDV for 2-approval and WCCAV for 2-veto are NP-complete even when the
legal set of weights is restricted to be {a, b}, and (b) WCCDV for 3-approval and WCCAV
for 3-veto are NP-complete even when the legal set of weights is restricted to be {1, 3}.
Theorem 4.13. WCCAV for 2-veto and 3-approval and WCCDV for 2-approval and 3-veto
are NP-complete.
Proof. Membership in NP is immediate, so it suffices to prove NP-hardness. We will first
give the proof for WCCDV for 2-approval. By Theorem 4.12 this also immediately gives
the result for WCCAV for 2-veto. We will reduce from X3C0 from Definition 3.5. Let
B = {b1 , ..., b3t } and let S = {S1 , ..., Sn } be a family of 3-element subsets of B such that
every element of B occurs in at least one and in at most three sets in S. We construct the
5. Here is one
{d1 , . . . , dt }
are an even
and exactly

possible construction. Let D = {d1 , . . . , d` }, where t ≤ ` ≤ 2t − 1. We form sets D0 =
and D1 = {d` , . . . , d`−t+1 }. We have that D = D0 ∪ D1 (D0 and D1 might overlap). There
number of voters in V0 ; exactly half of them disapprove of the candidates from the set D0
half disapprove of the candidates from the set D1 .

524

Weighted Electoral Control

following instance (C, V, p, k) of WCCDV for 2-approval. We set C = {p} ∪ {bj | 1 ≤ j ≤
3t} ∪ {si , s0i | 1 ≤ i ≤ n} ∪ {d0 , d1 , . . . , d3t } (d0 , d1 , . . . , d3t are dummy candidates that are
used for padding). For 1 ≤ j ≤ 3t, let `j be the number of sets in S that contain bj . By
assumption, for each j, 1 ≤ j ≤ 3t, we have that 1 ≤ `j ≤ 3. V consists of the following
voters:
weight
2
1
1
1
2
3 − `j

preference order
si > s0i > · · ·
si > bi1 > · · ·
si > bi2 > · · ·
s0i > bi3 > · · ·
p > d0 > · · ·
bj > dj > · · ·





for all 1 ≤ i ≤ n and Si = {bi1 , bi2 , bi3 }



for all 1 ≤ j ≤ 3t such that `j < 3.

Note that score(si ) = 4, score(s0i ) = 3, score(bj ) = 3, score(p) = 2, and score(dj ) ≤ 2.
We set k = n + 2t and we claim that S contains an exact cover if and only if p can become
a winner after deleting at most n + 2t voters.
(⇒): Delete the (n − t) weight-2 voters corresponding to the sets not in the cover and
delete the 3t weight-1 voters corresponding to the sets in the cover. Then the score of p
does not change, the score of each si decreases by 2, the score of each s0i decreases by at
least 1, and the score of each bj decreases by 1. So, p is a winner.
(⇐): We need to delete 3t voters to decrease the score of every bj candidate by 1. (Note
that there is no reason to delete the voters with preference orders of the form bj > dj > · · ·
(1 ≤ j ≤ 3t). It suffices to decrease the score of each bj by one and, since we also need to
decrease the scores of candidates si and s0i (1 ≤ i ≤ n), it is always better to delete voters
with preference orders of the form si > bj > · · · and s0i > bj > · · · .) After deleting these 3t
voters, there are at most t values of i, 1 ≤ i ≤ n, such that the score of si and the score of
s0i are at most 2 (for each i, obtaining the score at most 2 for candidates si and s0i takes at
least 3 unique voters of the 3t deleted ones).
If there are exactly t values of i, 1 ≤ i ≤ n, such that the score of si and the score of s0i
are at most 2, then these t values of i correspond to a cover. (Why is this so? We consider
a situation where we have already deleted the 3t voters with preference orders of the forms
si > bj > · · · and s0i > bj > · · · , where bj ∈ Si . If, after deleting these voters, for some i the
scores of both si and s0i decreased to 2, we must have deleted exactly the three voters that
correspond to members of Si . Thus, if after deleting voters corresponding to 3t members
of B we ensured that there are t values i such that the scores of si and s0i decreased to 2,
then it must be the case that these values of i correspond to a cover.) If there are less than
t values of i, 1 ≤ i ≤ n, such that the score of si and the score of s0i are at most 2, then the
remaining voters that are deleted, and there are at most n − t of them, need to decrease
the score of si and/or s0i for more than n − t values of i, 1 ≤ i ≤ n. But that is not possible,
since there is no voter that approves of both si or s0i and sj or s0j for i 6= j.
Note that this construction uses only weights 1 and 2. In fact, we can establish NPcompleteness for WCCDV for 2-approval for every set of allowed weights of size at least
two (note that if the set of weights has size one, the problem is in P, since this is in essence
the unweighted case resolved by Lin, 2012). Since the reductions of Theorem 4.12 do not
change the set of voter weights, we have the same result for WCCAV for 2-veto.
525

Faliszewski, Hemaspaandra, & Hemaspaandra

So, suppose our weight set contains w1 and w2 , w2 > w1 > 0. We modify the construction above as follows. We keep the same set of candidates and we change the voters as
follows.
#
1
1
1
1
2
1
` − `j

weight
w2
w1
w1
w1
w1
w2
w1

preference order
si > s0i > · · ·
si > bi1 > · · ·
si > bi2 > · · ·
s0i > bi3 > · · ·
p > d0 > · · ·
p > d0 > · · ·
bj > dj > · · ·





for all 1 ≤ i ≤ n and Si = {bi1 , bi2 , bi3 }



if w2 ≤ 2w1
if w2 > 2w1
for all 1 ≤ j ≤ 3t.

Here, ` is the smallest integer such that `w1 > max(2w1 , w2 ). Note that ` ≥ 3 and so
`−`j is never negative. Note that score(si ) = w2 +2w1 , score(s0i ) = w2 +w1 , score(bj ) = `w1 ,
score(p) = max(2w1 , w2 ), and score(dj ) ≤ max(2w1 , w2 ). The same argument as above
shows that S contains an exact cover if and only if p can become a winner after deleting at
most n + 2t voters.
We now turn to the proof for WCCDV for 3-veto. Our construction will use only weights
1 and 3. Since the reductions of Theorem 4.12 do not change the set of voter weights, weights
1 and 3 also suffice to get NP-completeness for WCCAV for 3-approval. Given the instance
of X3C0 described above, we construct the following instance (C, V, p, k) of WCCDV for
3-veto. We set C = {p} ∪ B ∪ {si | 1 ≤ i ≤ n} ∪ {r, d, d0 } (d and d0 are dummy candidates
that are used for padding) and V consists of the following voters:
#
1
1
1
1
3n − 3t
3n − 3
3n + 1 − `j

weight
3
1
1
1
1
1
1

preference order
· · · > p > si > r
· · · > p > si > bi1
· · · > p > si > bi2
· · · > p > si > bi3
· · · > d > d0 > r
· · · > d > d0 > si
· · · > d > d0 > bj





for all 1 ≤ i ≤ n and Si = {bi1 , bi2 , bi3 }



for all 1 ≤ i ≤ n
for all 1 ≤ j ≤ 3t.

It is more convenient to count the number of vetoes for each candidate than to count the
number of approvals. Note that vetoes(si ) = 3n+3, vetoes(bj ) = 3n+1, vetoes(r) = 6n−3t,
vetoes(p) = 6n, and vetoes(d) = vetoes(d0 ) ≥ 3n. We claim that S contains an exact cover
if and only if p can become a winner (i.e., have a lowest number of vetoes) after deleting at
most n + 2t voters.
(⇒): Delete the (n − t) weight-3 voters corresponding to the sets not in the cover and
delete the 3t weight-1 voters that veto p and that correspond to the sets in the cover. Then
vetoes(si ) = vetoes(bj ) = vetoes(r) = vetoes(p) = 3n and vetoes(d) = vetoes(d0 ) ≥ 3n. So,
p is a winner.
(⇐): We can assume that we delete only voters that veto p. Suppose we delete k1 weight1 voters and k2 weight-3 voters, k1 +k2 ≤ n+2t. After this deletion, vetoes(p) = 6n−k1 −3k2 ,
vetoes(r) = 6n − 3t − 3k2 , and vetoes(bj ) ≤ 3n + 1. In order for p to be a winner, we need
vetoes(p) ≤ vetoes(r). This implies that k1 ≥ 3t. We also need vetoes(p) − vetoes(bj ) ≤ 0.
526

Weighted Electoral Control

Since vetoes(p) − vetoes(bj ) ≥ 6n − k1 − 3k2 − (3n + 1) ≥ 6n − (n + 2t − k2 ) − 3k2 − 3n − 1 =
2n−2t−2k2 −1, it follows that k2 ≥ n−t. (To see that this is the case, note that if we require
that vetoes(p) − vetoes(bj ) ≤ 0 and we know that vetoes(p) − vetoes(bj ) ≥ 2n − 2t − 2k2 − 1,
then we must require that 2n−2t−2k2 −1 ≤ 0. This expression is equivalent to k2 ≥ n−t− 21 .
Since k2 , n, and t are integers, it must be the case that k2 ≥ n − t.) So we delete 3t weight-1
votes and n − t weight-3 votes, and after deleting these voters vetoes(p) = 3n. In order for
p to be a winner, we can delete at most one veto for each bj and at most three vetoes for
each si . This implies that the set of deleted weight-1 voters corresponds to a cover.
4.3 Approximation and Greedy Algorithms
When problems are computationally difficult, such as being NP-complete, it is natural to wonder whether good polynomial-time approximation algorithms exist. So, motivated by the NP-completeness results discussed earlier in this paper for most cases of
WCCAV/WCCDV for t-approval and t-veto, this section studies greedy and other approximation algorithms for those problems. (Recall that WCCAV is NP-complete for t-approval,
t ≥ 3, and for t-veto, t ≥ 2, and WCCDV is NP-complete for t-approval, t ≥ 2, and for
t-veto, t ≥ 3.) First, we will establish a connection to the weighted multicover problem,
and we will use it to obtain approximation results. Then we will obtain an approximation
algorithm that will work by direct action on our problem. Table 3 in Section 6 summarizes
our results on approximation algorithms for t-approval/t-veto WCCAV/WCCDV.
Before we undertake this, let us address in more detail the issue, valuably raised by a
referee, of why one might want to build approximation algorithms for control problems,
and who might use such algorithms, and whether it is unwise to obtain such algorithms if
the people using them might not be “the good guys.” As mentioned above, seeking good
polynomial-time approximation algorithms is one standard approach when exact solutions
are known to be intractable, e.g., NP-complete. Such algorithms will allow a campaign
strategist to, faced with the intractability of computing the optimal number of votes to add
or delete to achieve victory for his or her candidate, at least be able to quickly find an action
that is guaranteed to be within a particular multiplicative factor of the optimal action. One
might expect that our desire to get such approximations would hit a wall regarding the
potential impossibility of exerting control in certain instances, but as we discussed in the
Electoral Control subpart of Section 3, that worry does not hold for the particular problems
for which we will obtain approximation algorithms. Finally, as to the worry that people
(“chairs”) who employ approximation algorithms may not be “the good guys,” we have
the following somewhat multilayered reply. First, “good” and “evil” are highly contextual.
Whether a strategist’s attempts to help his or her candidate win are good or evil is very
much in the eye of the beholder. Some may decry such attempts as part of the brutal nature
of politics. Others may view such attempts, as long as no illegal actions are taken, as a
valid and indeed valuable part of the spirited, vibrant playing field of democracy. Second,
in some settings, control may be simply modeling an optimization problem, and so wellapproximating control isn’t even about candidates, but is simply about efficiency. Third,
even if one views approximating control as helping evil-doers, using that as a reason not to
learn which control problems can be approximated and how well they can be approximated
makes no more sense than sticking one’s head in the sand and hoping that cryptosystems
527

Faliszewski, Hemaspaandra, & Hemaspaandra

can’t be broken. Since evil-doers may well try to build approximation algorithms, or break
cryptosystems, the natural way of thwarting them is for the field to richly explore what
approximations and vulnerabilities exist, so that those who choose what election system
to use for a given problem can choose one that is not weak with respect to having good
approximations under whatever attacks they most fear.
4.3.1 A Weighted Multicover Approach
Let us first consider the extent to which known algorithms for the Set-Cover family of
problems apply to our setting. Specifically, we will use the following multicover problem.
Definition 4.14. An instance of Weighted Multicover (WMC) consists of a set B =
{b1 , . . . , bm }, a sequence r = (r1 , . . . , rm ) of nonnegative integers (covering requirements), a
collection S = (S1 , . . . , Sn ) of subsets of B, and a sequence ω = (ω1 , . . . , ωn ) of positive integers (weights of the sets in S). The goal is to find
P a minimum-cardinality set I ⊆ {1, . . . , n}
ωi , or to declare that no such set exists.
such that for each bj ∈ B it holds that rj ≤
i∈I∧bj ∈Si

That is, given a WMC instance we seek a smallest collection of subsets from S that
satisfies the covering requirements of the elements of B (keeping in mind that a set of
weight ω covers each of its elements ω times). WMC is an extension of Set-Cover with unit
costs. We will not define here the problem known as Covering Integer Programming (see
Kolliopoulos & Young, 2005), which for short is written as CIP. However, that problem
will be quite important to us here. The reason is that we observe that WMC is a special
case of CIP (with multiplicity constraints but) without packing constraints; footnote 6
below is in effect describing how to embed our problem in that problem. An approximation
algorithm of Kolliopoulos and Young for CIP (with multiplicity constraints but) without
packing constraints, applied to the special case of WMC, gives the following result.6
Theorem 4.15 (Kolliopoulos & Young, 2005). There is a polynomial-time algorithm that
when given an instance of WMC in which each set contains at most t elements gives an
O(log t)-approximation.
For t-approval both WCCAV and WCCDV naturally translate to equivalent WMC
instances. We consider WCCAV first. Let (C, V, W, p, k) be an instance of t-approval6. The paper of Kolliopoulos and Young (2005) does not directly speak of the WMC problem, but seeing
that their results indeed apply to WMC is an easy, if tedious, exercise. For those readers who would like
to verify that Theorem 4.15 holds, in this footnote we describe exactly where in the paper of Kolliopoulos
and Young one finds the relevant result and which parameters one should use. We warn the reader that
this footnote makes direct references to parts of that paper and so will only make sense if that paper is
simultaneously in hand. This footnote is merely a guide to understanding the particular way we draw
on that paper’s important work; providing a full-fledged survey of, or even a real discussion of, the CIP
problem is beyond the needs and scope of this paper.
Theorem 4.15 follows from the sentence—on page 496 of the work of Kolliopoulos and Young
(2005)—starting “Our second algorithm finds a solution” (which itself follows from their Theorem 8),
keeping in mind that we have none of their so-called packing constraints, and so we may take it that
what they call  is one and the matrix and vector they call B and b won’t be a factor here. Their vector
a corresponds to our rj ’s; the element in the jth row and ith column of their matrix A will for us be set
to ωi if Si contains bj and 0 otherwise; we set their cost vector c to be a vector of all 1’s; we set their
multiplicity vector d to be a vector of all 1’s; their vector x corresponds to the characteristic function of
our I; and their α will be Theorem 4.15’s bound t on the number of elements of B contained in any Si .

528

Weighted Electoral Control

WCCAV, where W = (w1 , . . . , wn ) is the collection of voters that we may add. We assume
without loss of generality that each voter in W ranks p among its top t candidates (i.e.,
approves of p).
We form an instance (B, r, S, ω) of WMC as follows. We set B = C − {p}. For each
c ∈ B, we set its covering requirement to be rc = score (C,V ) (c) 	 score (C,V ) (p), where
i	j =def max(0, i−j). For each vote w ∈ W , let Sw be the set of candidates that w does not
approve of. By our assumption regarding each voter ranking p among its top t candidates,
no Sw contains p. We set S = (Sw1 , . . . , Swn ) and we set ω = (ω(w1 ), . . . , ω(wn )). It is easy
to see that a set I ⊆ {1, . . . , n} is a solution to this instance of WMC (that is, I satisfies all
covering requirements) if and only if adding the voters {wi | i ∈ I} to the election (C, V )
ensures that p is a winner. The reason for this is the following: If we add voter wi to the
election then for each candidate c ∈ Swi , the difference between the score of c and the score
of p decreases by ω(wi ), and for each candidate c 6∈ Swi this difference does not change. The
covering requirements are set to guarantee that p’s score will match or exceed the scores of
all candidates in the election.
We stress that in the above construction we did not assume t to be a constant. Indeed,
the construction applies to t-veto just as well as to t-approval. So using Theorem 4.15 we
obtain the following result.
Theorem 4.16. There is a polynomial-time O(log m)-approximation algorithm for tapproval-WCCAV. There is a polynomial-time algorithm that when given an instance of
t-veto-WCCAV (t ∈ N) gives an O(log t)-approximation.
Proof. It suffices to use the reduction of t-approval/t-veto to WMC and apply the algorithm
from Theorem 4.15. For the case of t-approval, the reduction guarantees that each set in
the WMC instance contains at most m elements. For the case of t-veto, each of these sets
contains at most t elements.
We can obtain analogous results for the case of t-approval/t-veto and WCCDV. One can
either provide a direct reduction from these problems to WMC or notice that the reductions
given in the proof of Theorem 4.12 maintain approximation properties.
Theorem 4.17. There is a polynomial-time algorithm that when given an instance of tapproval-WCCDV (t ∈ N) gives an O(log t)-approximation. There is a polynomial-time
O(log m)-approximation algorithm for t-veto-WCCDV.
4.3.2 A Direct Approach
Using algorithms for WMC, we were able to obtain relatively strong algorithms for
WCCAV/WCCDV under t-approval and t-veto. However, with this approach we did not
find approximation algorithms for t-approval-WCCAV and t-veto-WCCDV whose approximation ratios depend only on t (and not, for example, on kCk, i.e., m, or on kV k). In the
following we will seek direct algorithms for these problems.
We now show that a very simple greedy approach yields a polynomial-time tapproximation algorithm for t-approval-WCCAV and t-veto-WCCDV. (Recall that this
means that in cases when making p win is possible, the number of voters our algorithm
adds/deletes to reach victory is never more than t times that of the optimal set of additions/deletions.)
529

Faliszewski, Hemaspaandra, & Hemaspaandra

Let GBW (greedy by weight) define the following very simple algorithm for WCCAV.
(The votes are the weighted t-approval vectors induced by the preferences of the voters.)
(Pre)discard all unregistered votes that do not approve of the preferred candidate p. Order
the (remaining) unregistered votes from heaviest to lightest, breaking ties in voter weights
in some simple, transparent way (for concreteness, let us say by lexicographic order on the
votes’ representations). GBW goes through the unregistered votes in that order, and as it
reaches each vote it adds the vote exactly if the vote disapproves of at least one candidate
whose score (i.e., total weight of approvals) is currently strictly greater than that of p. It
stops successfully when p has become a winner and unsuccessfully if before that happens
the algorithm runs out of votes to consider. The following result says that GBW is a tapproximation algorithm for t-approval-WCCAV, and also for t-veto-WCCDV, using the
obvious analogue of GBW for t-veto-WCCDV, which we will also call GBW.7
Theorem 4.18. Let t ≥ 3. The polynomial-time greedy algorithm GBW is a tapproximation algorithm for t-approval-WCCAV and t-veto-WCCDV; and there are instances in which GBW’s approximation factor on each of these problems is no better than t.
We prove Theorem 4.18’s upper and lower bound parts separately, through the following
two lemmas from which the theorem immediately follows.
Lemma 4.19. Let t ≥ 3. There are instances on which the polynomial-time greedy algorithm GBW has an approximation factor on t-approval-WCCAV no better than t. There
are instances on which the polynomial-time greedy algorithm GBW has an approximation
factor on t-veto-WCCDV no better than t.
Lemma 4.20. Let t ≥ 3. The polynomial-time greedy algorithm GBW is a t-approximation
algorithm for t-approval-WCCAV and t-veto-WCCDV.
The proof of our lower-bound claim, Lemma 4.19, consists of a somewhat detailed pair
of constructions, and is of less interest than the upper-bound part of Theorem 4.18, namely
Lemma 4.20. We thus defer to the appendix the proof of Lemma 4.19.
Proof of Lemma 4.20. Let us now prove the two claims that GBW is a t-approximation
algorithm. We will prove the result for t = 3 and WCCAV, but it will be immediately clear
that our proof straightforwardly generalizes to all greater t; and the WCCDV case follows
using Theorem 4.12.
Clearly GBW is a polynomial-time algorithm. Consider a given input instance of tapproval-WCCAV, with preferred candidate p. Without loss of generality, assume all unregistered voters approve of p. We will say a candidate “has a gap” (under the current
set of registered voters and whatever unregistered voters have already been added) if that
candidate has strictly more weight of approvals than p does. For each candidate d who has
7. For completeness and clarity, we describe what we mean by GBW for t-veto-WCCDV. Order all votes
that do not approve of p from heaviest to lightest, breaking ties in voter weights in some simple, transparent way (for concreteness, let us say by lexicographic order on the votes’ representations). GBW
goes through these votes in that order, and as it reaches each vote it removes the vote exactly if the
vote approves of at least one candidate whose score (i.e., total weight of approvals) is currently strictly
greater than that of p. It stops successfully when p has become a winner and unsuccessfully if before
that happens the algorithm runs out of such votes to consider.

530

Weighted Electoral Control

a gap, d 6= p, define id to be the minimum number of unregistered voters one has to add to
remove d’s gap; that is, if one went from heaviest to lightest among the unregistered voters,
adding in turn each that disapproved of d, id is the number of voters one would add before d
no longer had a gap. If for any candidate d it holds that no integer realizes id , then control is
impossible using the unregistered voter set. Clearly, any successful addition of voters must
add at least maxd id voters (the max throughout this proof is over all candidates initially
having a gap).
Let us henceforth assume that control is possible in the input case. We will show that
after having added at most 3 · maxd id voters GBW will have made p a winner, and so GBW
is a 3-approximation algorithm.
Before giving the detailed proof, let us very informally give a sense of the proof’s idea.
Let z be some candidate who allegedly has a gap after GBW has just added 3·maxd id voters,
and freeze the action of GBW at that point. Our proof argues that if relatively many of the
3 · maxd id voters added by GBW (i.e., at least maxd id of them) do not approve of z, then z
clearly will not have a gap at the point in time when GBW was frozen, and so the assumed
gap can’t exist in this case. Our proof further argues that if relatively few of the 3 · maxd id
voters added by GBW (i.e., at most (maxd id )−1 of them) do not approve of z (equivalently,
at least 1 + 2 · maxd id of them do approve of z), then we also arrive at a contradiction.
The latter argument is a more subtle one, involving asking which candidate’s (call it y) gap
caused the very last added vote to be added, and if needed drilling down an extra level with
a related few/many argument now focused on y, to show that GBW must at some point
have acted in a way that violates its definition, thus also yielding a contradiction. Since
the “few” and “many” cases above cover all possible cases, our proof will have achieved its
goal. We provide now the formal analysis that carries out this argument line.
So, suppose that after 3 · maxd id additions some candidate, z, still has a gap. As
discussed above we will perform a case analysis to in each case arrive at a contradiction.
Case 1 [In at least maxd id of the first 3·maxd id votes added by GBW, z is not approved].
Since for the last one of these to be added z must still have had a gap before the addition,
each earlier vote considered that disapproved z had a gap for z when it was considered
and so would have been added when reached. So, keeping in mind that iz ≤ maxd id , we
in fact must have added the iz heaviest voters disapproving of z, and so contrary to the
assumption, z no longer has a gap after these additions.
Case 2 [Case 1 does not hold]. So z is approved in at least 1 + 2 · maxd id of the added
votes. What made the final one of the added votes, call it v 0 , eligible for addition? It must
be that some candidate, say y, still had a gap just before v 0 was added.
Case 2a [y is disapproved in at least maxd id of the 2 · maxd id votes added before v 0 that
approved z]. Then, since until y’s gap was removed no unregistered voters disapproving of
y would be excluded by GBW, y’s iy heaviest voters will have been added. So contrary to
Case 2’s assumption, y does not have a gap when we get to adding vote v 0 .
Case 2b [Case 2 holds but Case 2a does not]. Then y is approved in at least 1 + maxd id
of the 2 · maxd id votes before v 0 that GBW added that approve z. So we have 1 + maxd id
votes added approving of exactly z and y. But then who made the last of those 1 + maxd id
votes, call it v 00 , eligible to be added? It must hold that some candidate w had a gap up
through v 00 . But at the moment before adding v 00 we would have added maxd id ≥ iw votes
approving exactly z and y and so disapproving w, and since w allegedly still had a gap, we
531

Faliszewski, Hemaspaandra, & Hemaspaandra

while doing so under GBW would have in fact added the iw heaviest voters disapproving
of w, and so w’s gap would have been removed before v 00 , so contrary to our assumption w
was not the gap that made v 00 eligible.
One might naturally wonder how GBW performs on t-veto-WCCAV and t-approvalWCCDV. By an argument far easier than that used in the above proof of Lemma 4.20, in
both of these cases GBW provides a t-approximation algorithm.
Theorem 4.21. GBW is a t-approximation algorithm for t-veto-WCCAV. GBW is a tapproximation algorithm for t-approval-WCCDV.
Proof. Consider t-veto-WCCAV. Let p be the preferred candidate. For each candidate d
with an initial positive “gap” relative to the preferred candidate p (i.e., a surplus over p in
total weight of approvals), let id be as defined in the proof of Lemma 4.20. (Recall that id
is the number of votes we would need to add to remove the surplus of d over p if we took
the unregistered votes, discarded all that didn’t simultaneously approve p and disapprove
d, and then
P added those one at a time from heaviest to lightest until the gap was removed.)
Clearly,
id , where the sum is taken over those candidates with an initial surplus relative
to p, is an upper bound on the number of votes added by GBW. This is true since GBW
works by adding extra votes from heaviest to lightest, restricted to those vetoing a candidate
who at that point has a positive gap relative to p; so under GBW each gap will be closed by
the largest weight votes that address it. On the other hand, in any overall optimal solution
id is a lower bound on the smallest number of votes from that solution’s added-vote set
that would suffice to remove d’s positive gap (since it takes id even if we use the heaviest
votes addressing the gap). In the overall optimal solution each added vote narrows at most
t gaps. So GBW’s solution uses at worst t times as many added votes as does the optimal
solution.
The claim for t-approval-WCCDV follows by Theorem 4.12.
This result replaces a flawed claim in the conference version of this paper (Faliszewski,
Hemaspaandra, & Hemaspaandra, 2013) that GBW and some of its cousins do not provide
O(1) approximations for these problems.8 Of course, having a t-approximation for these two
problems (namely, t-veto-WCCAV and t-approval-WCCDV) is not wildly exciting, since for
these problems the multicover-based approach from earlier in this section showed that for
some function f (t), with f (t) = O(log t), we even have f (t)-approximation algorithms for
these problems. However, if the constant of the “big oh” of that other algorithm is large,
it is possible that for sufficiently small values of t the above approach may give a better
approximation. Also, we feel that it is interesting to learn about the behavior of explicit
heuristics, especially attractive approaches such as greedy algorithms.
It is natural to ask whether similar greedy algorithms work well for other scoring rules,
e.g., for Borda’s rule. Unfortunately, for families of scoring rules other than t-approval and
t-veto the analysis, if at all possible, would likely have to be significantly different than
ours. The main reason for this is that—as discussed in the Electoral Control subpart of
8. Note that here we treat t as a constant and, so, a t-approximation algorithm provides (indeed, is) an
O(1) approximate one. The reason that is true is that, technically speaking, the WCCAV and WCCDV
problems are defined separately for each voting rule. For example, 2-approval-WCCAV is a different
problem than, say, 200-approval-WCCAV.

532

Weighted Electoral Control

Section 3—for t-approval and t-veto it is always easy to verify whether there exists some
solution (although, perhaps, one that is very far from being optimal). For other scoring
rules, e.g., for Borda, it is not at all clear whether this is possible (and we conjecture that,
indeed, it is NP-complete to do so). However, it might be an interesting research direction
to evaluate the effectiveness of such greedy algorithms empirically (we point the reader to
the work of Rothe & Schend, 2013, for a recent survey covering experimental studies of the
complexity of control in elections).

5. Related Work
The study of the complexity of (unweighted) electoral control was initiated
by Bartholdi, Tovey, and Trick (1992), who considered constructive control by
adding/deleting/partitioning candidates/voters under the plurality rule and under the Condorcet rule (that is, the rule that chooses Condorcet winner whenever there is one, and has
no winners otherwise). The various types of control model at least some of the flavor of
actions that occur in the real world, such as voter suppression and targeted get-out-the-vote
drives (see the survey of Faliszewski et al., 2010, for more examples and discussions). A
major motivation for the study of control was to obtain “complexity barrier” results, that is,
results that show that detecting opportunities for various control attacks is computationally
difficult. In particular, Bartholdi, Tovey, and Trick focused on NP-hardness as the measure
of computational difficulty.
This research direction was continued by Hemaspaandra, Hemaspaandra, and
Rothe (2007), who were the first to study destructive control attacks on elections. Since
then, many authors have studied electoral control in many varied settings and under many
different rules; we refer the reader to the survey of Faliszewski et al. (2010). Some recent
research, not covered in that survey, includes complexity-of-control results for the t-approval
family of rules (Lin, 2012), for Bucklin’s rule (and for fallback, its extension for truncated
votes; Erdélyi, Fellows, Rothe, & Schend, 2015a), for maximin (Faliszewski et al., 2011),
for range voting (Menton, 2013), and for Schultze’s rule and the ranked pairs rule (Parkes
& Xia, 2012; Menton & Singh, 2013; Hemaspaandra, Lavaee, & Menton, 2013). In the
present paper, we compare control and manipulation. The recent paper of Fitzsimmons,
Hemaspaandra, and Hemaspaandra (2013) studies settings in which both control and manipulation are occurring. Researchers have, in the quite different setting of electing members
to fill a fixed-size, multimember panel, defined variants of control that have coexisting constructive and destructive aspects (Meir, Procaccia, Rosenschein, & Zohar, 2008). There is
also work analyzing counting variants of control (Wojtas & Faliszewski, 2012), where the
goal is not only to decide if a given control attack is possible, but also to count the number
of ways in which this attack can be carried out.
The complexity-barrier research line turned out to be very successful. For most voting
rules that were considered, a significant number of control attacks are NP-hard. Indeed,
it is even possible to construct an artificial election system resistant to all types of control
attacks (Hemaspaandra, Hemaspaandra, & Rothe, 2009). However, there are also a number
of results that suggest that in practice the complexity barrier might not be as strong as one
might at first think. For example, Faliszewski, Hemaspaandra, Hemaspaandra, and Rothe
(2011) and Brandt, Brill, Hemaspaandra, and Hemaspaandra (2010) have shown that if the
533

Faliszewski, Hemaspaandra, & Hemaspaandra

votes are restricted to being single-peaked, then many control problems that are known to
be NP-complete become polynomial-time solvable. Indeed, this often holds even if elections
are just nearly single-peaked (Faliszewski et al., 2014), as many real-world elections seem
to be (see, e.g., the discussion in Gehrlein & Lepelley, 2012, ch. 2). Similarly, some initial
experimental results of Erdélyi, Fellows, Rothe, and Schend (2015b) suggest that, at least
under certain distributions and settings, some NP-hard control problems can be solved in
practice on many instances. As part of a different line of research, Xia (2012) has studied
the asymptotic behavior of the number of voters that have to be added to/deleted from a
randomly constructed election in a successful control action.
There are a number of other problems involving changing the structure of elections.
These problems include candidate cloning, where it is possible to replace a given candidate
c with a number of its clones (Elkind et al., 2011; Elkind, Faliszewski, & Slinko, 2012), or the
possible winner problem when new alternatives join, where some additional, not yet ranked
candidates can be introduced (Chevaleyre, Lang, Maudet, Monnot, & Xia, 2012; Xia, Lang,
& Monnot, 2011). This last problem is also related to the possible winner problem with
truncated ballots (Baumeister, Faliszewski, Lang, & Rothe, 2012a).
The only papers that directly raise the issue of weighted control are, to the best of
our knowledge, the theses of Russell (2007) and Lin (2012). However, we also mention the
papers of Baumeister, Roos, Rothe, Schend, and Xia (2012b), and of Perek, Faliszewski,
Pini, and Rossi (2013), where the authors, in effect, consider problems of affecting the result
of an election through picking the weights of the voters. (The paper of Perek et al. motivates
its study differently, but in effect studies a constrained variant of choosing voter weights.)
Their problems are similar to, though different from, simultaneous (multimode) addition
and deletion of voters (Faliszewski et al., 2011).
This paper has given f (·)-approximation results for weighted election control problems. Elkind and Faliszewski (2010) have given a 2-approximation algorithm for a weighted,
bribery-related case.

6. Conclusions
We have studied voter control under a number of voting rules, including scoring protocols,
families of scoring protocols, and the (weak)Condorcet-consistent rules. We have shown
that the complexity of voter control can be quite different from the complexity of weighted
coalitional manipulation: there are natural voting rules for which weighted coalitional manipulation is easy but weighted voter control is hard, and there are natural rules where the
opposite is the case. Furthermore, we have shown that for weighted voter control under
t-approval and t-veto, there are good, natural approximation algorithms. Our results for
voter control in weighted elections are summarized in Tables 1, 2, and 3.

Acknowledgements
We are very grateful to the anonymous AAMAS 2013 and JAIR referees for extremely
helpful comments and suggestions, some of which we have incorporated as examples.
We thank the editor, Jérôme Lang, for his wise guidance.
This work was sup534

Weighted Electoral Control

WCCAV

WCCDV

WCM

Plurality

P (Thm. 4.1)

P (Thm. 4.1)

P♣

t-approval, 2 ≤ t <
m
Borda

P (Thm. 4.1)

P (Thm. 4.1)

NP-comp.♦

NP-comp. (Thm. 4.2)

NP-comp. (Thm. 4.2)

NP-comp.♦

α = (α1 , . . . , αm ),
k{α1 , . . . , αm }k ≥ 3

NP-comp. (Thm. 4.3)

NP-comp. (Thm. 4.3)

NP-comp.♦

Llull (3 candidates)

NP-comp. (Cor. 4.9)

NP-comp. (Cor. 4.9)

P♥

(weak)Condorcetconsistent rules

NP-hard (Thm. 4.7)

NP-hard (Thm. 4.7)

various
complexities

Table 1: Our results for the complexity of control by adding/deleting voters in weighted
elections for any fixed number of candidates, m ≥ 3, compared to the complexity of weighted coalitional manipulation. The result marked with ♣ is due to
Conitzer et al. (2007), the results marked with ♦ are due to Hemaspaandra and
Hemaspaandra (2007), and the result marked with ♥ is due to Faliszewski et al.
(2008).

WCCAV

WCCDV

t-approval
t=2
t=3
t≥4

P (Thm. 4.10)
NP-complete (Thm. 4.13)
NP-complete♠

NP-complete (Thm. 4.13)
NP-complete♠
NP-complete♠

t-veto
t=2
t=3
t≥4

NP-complete (Thm. 4.13)
NP-complete♠
NP-complete♠

P (Thm. 4.11)
NP-complete (Thm. 4.13)
NP-complete♠

Table 2: The complexity of control by adding and deleting voters for t-approval and t-veto
with an unbounded number of candidates. The results marked with ♠ are due to
Lin (2012).

ported in part by grants AGH-11.11.230.124, NCN-DEC-2011/03/B/ST6/01393, NCNUMO-2012/06/M/ST1/00358, and NSF-CCF-{0915792,1101452,1101479}, and two Bessel
Awards from the Alexander von Humboldt Foundation.
535

Faliszewski, Hemaspaandra, & Hemaspaandra

WCCAV

WCCDV

t-approval

O(log m) (Thm. 4.16)
t (Thm. 4.18)

O(log t) (Thm. 4.17)
t (Thm. 4.21)

t-veto

O(log t) (Thm. 4.16)
t (Thm. 4.21)

O(log m) (Thm. 4.17)
t (Thm. 4.18)

Table 3: Approximation ratios of our algorithms for WCCAV and WCCDV under tapproval and t-veto.

Appendix A. Additional Details Related to Section 4.3
We present here the deferred proof of Lemma 4.19 and some other details related to Section 4.3.
Proof of Lemma 4.19. Our goal is to show that GBW sometimes really does use fully t
times the optimal number of added/deleted votes, for the cases in question. Examples are
(somewhat detailed but) not hard to construct, and the lower bound even holds for t = 2,
though in Section 4.2 we obtained an exact solution by a different approach. However, one
does have to be careful to set the “gap” pattern created by the unregistered voters to be
a realizable one. For our t-approval-WCCAV construction, this will be easy to do directly.
For our t-veto-WCCDV construction, we will establish realizability through a small tool—
which we hope may prove useful elsewhere—that lets one set up certain patterns of gaps.
We state the tool below as Tool A.1.
Fix any t ∈ {2, 3, 4, . . .}. We will now construct an instance of t-approval-WCCAV on
which GBW uses t times as many additions as the optimal strategy. Our construction
will have 2t candidates: the preferred candidate p, candidates a1 , . . . , at , and candidates
d1 , . . . , dt−1 . Now, suppose that under the votes of the registered voters, the “gaps” are as
follows. For each candidate ai , the total weight of approvals of ai exceeds the total weight
of approvals of p by exactly 2t. And for each candidate di , the total weight of approvals
of di equals the total weight of approvals of p. This can easily be realized, namely by our
registered voter set being one weight-2t voter who approves of each ai .
Our set of unregistered voters will be as follows. There will be one unregistered voter,
call it “nice,” of weight 2t, who approves of p and each of the t − 1 candidates di , and
disapproves of each of the t candidates ai . For each j, 1 ≤ j ≤ t, we will have a single
unregistered voter, call it αj , of weight 3t, who approves of p and of each ai other than aj ,
and disapproves of aj and all the di ’s.
Note that GBW will add all t voters αi . But ideal would be to add the single voter called
“nice,” since doing so suffices to make p a winner. So for each t ≥ 2 we have constructed
a setting where GBW for t-approval-WCCAV takes t times more than the optimal number
of added votes.
It also holds that for each t ≥ 2, we can similarly construct a setting where GBW for
t-veto-WCCDV takes t times more than the optimal number of deleted votes, and can prove
that setting to be realizable. In fact, we can do so by following something of the flavor of
536

Weighted Electoral Control

the above scheme, except with a slightly different vote set that adjusts it to handle the case
of deleting voters, and with more care regarding realizability. Here is the construction. Fix
any t ∈ {2, 3, 4, . . .}. Our candidate set will again be the preferred candidate p, candidates
a1 , . . . , at , and candidates d1 , . . . , dt−1 . Let us specify the voter set. We will put into our
voter set a collection of weight-1 votes such that the gaps in total approval weight relative
to d1 created by those votes are as follows. Each of d2 through dt−1 have the same total
approval weight as d1 . The total approval weight of p exceeds that of d1 by 3t2 + 3t. And
the total approval weight of each ai exceeds that of d1 by 3t2 .
As Tool A.1 below, we will observe that for 2t-candidate t-approval voting, any gap
pattern where the gaps are all multiples of t can be realized. Since in the current proof
we are using 2t-candidate t-veto, and that is the same as 2t-candidate t-approval, Tool A.1
applies here. In particular, Tool A.1 easily builds a set of weight-1 votes realizing precisely
our desired set of gaps. (The exact number of weight-1 votes used in this construction is
not important. However, from the gaps mentioned above and the vote-set size mentioned
in the tool, the precise number is easily seen to be (3t + 3 + t(3t))(2t − 1).)
We are not yet done building our voter set. We will also have in our voter set one
voter, call it “nice,” of weight 2t, who approves of exactly all t of the ai ’s. And for each j,
1 ≤ j ≤ t, we will have one voter of weight 3t who approves of exactly aj and all t − 1 of
the di ’s.
Under the entire set of votes created above—the votes from the tool combined with
“nice” and the other t votes just mentioned—it is easy to see that d1 is a candidate having
the least total approval weight, and it is tied in total approval weight with each other di .
The total approval weight of p exceeds that of d1 by 3t. And each ai exceeds d1 in total
approval weight by 5t.
However, in light of the pattern of votes and weights we have here, it is clear that GBW
(in its version for t-veto) will delete the t weight-3t voters. (Note that the votes added by
Tool A.1 are all weight-1 votes, and so are highly unattractive to GBW.) But ideal would
be to delete the single voter called “nice,” since doing so suffices to make p a winner. So for
each t ≥ 2 we have constructed a realizable setting where GBW for t-veto-WCCDV takes t
times more than the optimal number of deleted votes.
Within the above proof, we referred to and used a small tool that can build certain
patterns of vote weight gaps in certain approval elections. It would be an overreach to
claim that this is a McGarvey-like tool, since this is a different setting than, and is a far less
flexible result than, the famous theorem of McGarvey (1953). However, it in a small way is
a tool that perhaps might be useful elsewhere, and so we state and prove this modest tool.
Tool A.1. Let t ≥ 2. Let n1 , . . . , n2t−1 be any list of nonnegative integers each divisible by t.
Then there exists a collection of t-approval votes, over 2t candidates, such that under those
votes, relative to the candidate getting the fewest approvals, the list of gaps in number of
approvals between that candidate and the otherP2t − 1 candidates is precisely (n1 , . . . , n2t−1 ).
Furthermore, this can be done with (2t − 1)( ni )/t unweighted (i.e., weight 1) votes. It
alternatively can be done with (2t − 1)2 weighted votes (or even (2t − 1)k{i | ni 6= 0}k
weighted votes).
Proof. Consider an election with 2t candidates, where the votes cast are t-approval votes.
Consider the collection of 2t − 1 votes, each of weight one, in which the votes all approve
537

Faliszewski, Hemaspaandra, & Hemaspaandra

of a particular candidate (for this example, let that one be the first candidate), and the
remaining t − 1 approvals cyclically rotate around the other candidates. So the t-approval
votes, viewed as bit vectors, are these: 1 1t−1 0t , 1 0 1t−1 0t−1 , . . ., 1 0t 1t−1 , 1 1 0t 1t−2 , . . .,
1 1t−1 0t 1. Note that the first candidate is approved in all 2t − 1 of those votes, and each
other candidate is approved in exactly t − 1 of those votes. So this collection of votes sets
a gap of t in favor of the first candidate, between the total approval weight of the first
candidate and that of each other candidate And the difference in total approval weight
between each other pair of candidates is zero.
Given a gap pattern as stated in the tool, where each gap above the least-approved
candidate (call that candidate c) is a multiple of t, we can simply use the approach of the
above paragraph repeatedly, to boost each other candidate, d, one at a time to whatever
multiple of t it is supposed to exceed c by in total approval weight. (In this, d will play the
role “the first candidate” did in the previous paragraph.) If d’s surplus relative to c is kt
and we wish to use only weight-1 votes, we can do this for d with k(2t − 1) weight-1 votes.
Otherwise, we can do this for d with 2t − 1 weight-k votes. So the total number of votes
used is as given in the statement of this tool.
This appendix is not seeking to provide a comprehensive study of which gap collections
are realizable under t-approval voting, nor is it seeking to find the smallest number of voters
needed to realize realizable gap collection. That is an interesting direction for study, but
is not our goal here. However, we mention that there clearly exist some gap collections
that cannot be realized. For example, the “then there exists” claim of Tool A.1 is not even
always true if one removes the assumption of divisibility by t. An example showing this is
the following. Consider a 4-candidate setting where votes will be 2-approval votes, and we
desire a gap list relative to the least-approved candidate of (1, 1, 1), i.e., each of the other
candidates has one more approval than does the least-approved candidate. Clearly, the
total number of approvals of any set of votes achieving this is 4B + 3, where B is whatever
number of approvals the least-approved candidate happens to get under the vote set one is
trying, and so the total number of approvals is odd. However, any vote set of 2-approval
votes has an even total number of approvals. So this gap collection cannot be realized.

References
Aziz, H., Bachrach, Y., Elkind, E., & Paterson, M. (2011). False-name manipulations in
weighted voting games. Journal of Artificial Intelligence Research, 40, 57–93.
Bartholdi, III, J., & Orlin, J. (1991). Single transferable vote resists strategic voting. Social
Choice and Welfare, 8 (4), 341–354.
Bartholdi, III, J., Tovey, C., & Trick, M. (1989). The computational difficulty of manipulating an election. Social Choice and Welfare, 6 (3), 227–241.
Bartholdi, III, J., Tovey, C., & Trick, M. (1992). How hard is it to control an election?.
Mathematical and Computer Modeling, 16 (8/9), 27–40.
Baumeister, D., Faliszewski, P., Lang, J., & Rothe, J. (2012a). Campaigns for lazy voters:
Truncated ballots. In Proceedings of the 11th International Conference on Autonomous
Agents and Multiagent Systems, pp. 577–584.
538

Weighted Electoral Control

Baumeister, D., Roos, M., Rothe, J., Schend, L., & Xia, L. (2012b). The possible winner
problem with uncertain weights. In Proceedings of the 20th European Conference on
Artificial Intelligence, pp. 133–138.
Brandt, F., Brill, M., Hemaspaandra, E., & Hemaspaandra, L. (2010). Bypassing combinatorial protections: Polynomial-time algorithms for single-peaked electorates. In
Proceedings of the 24th AAAI Conference on Artificial Intelligence, pp. 715–722.
Brandt, F., Conitzer, V., & Endriss, U. (2013). Computational social choice. In Weiß, G.
(Ed.), Multiagent Systems (2nd edition). MIT Press.
Brelsford, E., Faliszewski, P., Hemaspaandra, E., Schnoor, H., & Schnoor, I. (2008). Approximability of manipulating elections. In Proceedings of the 23rd AAAI Conference
on Artificial Intelligence, pp. 44–49. AAAI Press.
Chen, J., Faliszewski, P., Niedermeier, R., & Talmon, N. (2014). Combinatorial voter control
in elections. In Proceedings of the 39th International Symposium on Mathematical
Foundations of Computer Science, Part II, pp. 153–164. Springer-Verlag Lecture Notes
in Computer Science #8635.
Chevaleyre, Y., Lang, J., Maudet, N., Monnot, J., & Xia, L. (2012). New candidates welcome! Possible winners with respect to the addition of new candidates. Mathematical
Social Sciences, 64 (1), 74–88.
Congleton, R. (2011). The Swedish transition to democracy (Chapter 14). In Perfecting
Parliament. Cambridge University Press.
Conitzer, V., Sandholm, T., & Lang, J. (2007). When are elections with few candidates
hard to manipulate?. Journal of the ACM, 54 (3), Article 14.
Dwork, C., Kumar, R., Naor, M., & Sivakumar, D. (2001). Rank aggregation methods for
the web. In Proceedings of the 10th International World Wide Web Conference, pp.
613–622. ACM Press.
Elkind, E., & Faliszewski, P. (2010). Approximation algorithms for campaign management. In Proceedings of the 6th International Workshop On Internet And Network
Economics, pp. 473–482.
Elkind, E., Faliszewski, P., & Slinko, A. (2011). Cloning in elections: Finding the possible
winners. Journal of Artificial Intelligence Research, 42, 529–573.
Elkind, E., Faliszewski, P., & Slinko, A. (2012). Clone structures in voters’ preferences. In
Proceedings of the 13th ACM Conference on Electronic Commerce, pp. 496–513.
Ephrati, E., & Rosenschein, J. (1997). A heuristic technique for multi-agent planning.
Annals of Mathematics and Artificial Intelligence, 20 (1–4), 13–67.
Erdélyi, G., Fellows, M., Rothe, J., & Schend, L. (2015a). Control complexity in Bucklin
and fallback voting: A theoretical analysis. Journal of Computer and System Sciences,
81 (4), 632–660.
Erdélyi, G., Fellows, M., Rothe, J., & Schend, L. (2015b). Control complexity in Bucklin and
fallback voting: An experimental analysis. Journal of Computer and System Sciences,
81 (4), 661–670.
539

Faliszewski, Hemaspaandra, & Hemaspaandra

Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. (2009). How hard is bribery in
elections?. Journal of Artificial Intelligence Research, 35, 485–532.
Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. (2010). Using complexity to protect
elections. Communications of the ACM, 53 (11), 74–82.
Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. (2011). Multimode attacks on
elections. Journal of Artificial Intelligence Research, 40, 305–351.
Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. (2013). Weighted electoral control. In Proceedings of the 12th International Conference on Autonomous Agents and
Multiagent Systems, pp. 367–374.
Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. (2014). The complexity of manipulative attacks in nearly single-peaked electorates. Artificial Intelligence, 207, 69–99.
Faliszewski, P., Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2009). A richer understanding of the complexity of election systems. In Ravi, S., & Shukla, S. (Eds.), Fundamental Problems in Computing: Essays in Honor of Professor Daniel J. Rosenkrantz,
pp. 375–406. Springer.
Faliszewski, P., Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2011). The shield that
never was: Societies with single-peaked preferences are more open to manipulation
and control. Information and Computation, 209 (2), 89–107.
Faliszewski, P., Hemaspaandra, E., & Schnoor, H. (2008). Copeland voting: Ties matter.
In Proceedings of the 7th International Conference on Autonomous Agents and Multiagent Systems, pp. 983–990. International Foundation for Autonomous Agents and
Multiagent Systems.
Fitzsimmons, Z., Hemaspaandra, E., & Hemaspaandra, L. (2013). Control in the presence of manipulators: Cooperative and competitive cases. In Proceedings of the 23rd
International Joint Conference on Artificial Intelligence, pp. 113–119. AAAI Press.
Garey, M., & Johnson, D. (1979). Computers and Intractability: A Guide to the Theory of
NP-Completeness. W. H. Freeman and Company.
Gehrlein, W., & Lepelley, D. (2012). Voting Paradoxes and Group Coherence: The Condorcet
Efficiency of Voting Rules. Springer.
Ghosh, S., Mundhe, M., Hernandez, K., & Sen, S. (1999). Voting for movies: The anatomy of
recommender systems. In Proceedings of the 3rd Annual Conference on Autonomous
Agents, pp. 434–435. ACM Press.
Hemaspaandra, E., & Hemaspaandra, L. (2007). Dichotomy for voting systems. Journal of
Computer and System Sciences, 73 (1), 73–83.
Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2007). Anyone but him: The complexity
of precluding an alternative. Artificial Intelligence, 171 (5–6), 255–285.
Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2009). Hybrid elections broaden
complexity-theoretic resistance to control. Mathematical Logic Quarterly, 55 (4), 397–
424.
540

Weighted Electoral Control

Hemaspaandra, E., Hemaspaandra, L., & Schnoor, H. (2014). A control dichotomy for pure
scoring rules. In Proceedings of the 28th AAAI Conference on Artificial Intelligence,
pp. 712–720. AAAI Press.
Hemaspaandra, L., Lavaee, R., & Menton, C. (2013). Schulze and ranked-pairs voting are
fixed-parameter tractable to bribe, manipulate, and control. In Proceedings of the
12th International Conference on Autonomous Agents and Multiagent Systems, pp.
1345–1346.
Hemaspaandra, L., & Williams, R. (2012). An atypical survey of typical-case heuristic
algorithms. SIGACT News, 43 (4), 71–89.
Kolliopoulos, S., & Young, N. (2005). Approximation algorithms for covering/packing integer programs. Journal of Computer and System Sciences, 71 (4), 495–505.
Lin, A. (2012). Solving Hard Problems in Election Systems. Ph.D. thesis, Rochester Institute
of Technology, Rochester, NY.
Lu, T., & Boutilier, C. (2011). Budgeted social choice: From consensus to personalized decision making. In Proceedings of the 22nd International Joint Conference on Artificial
Intelligence, pp. 280–286.
McGarvey, D. (1953). A theorem on the construction of voting paradoxes. Econometrica,
21 (4), 608–610.
Meir, R., Procaccia, A., Rosenschein, J., & Zohar, A. (2008). The complexity of strategic
behavior in multi-winner elections. Journal of Artificial Intelligence Research, 33,
149–178.
Menton, C. (2013). Normalized range voting broadly resists control. Theory of Computing
Systems, 53 (4), 507–531.
Menton, C., & Singh, P. (2013). Control complexity of Schulze voting. In Proceedings of
the 23rd International Joint Conference on Artificial Intelligence, pp. 286–292.
Parkes, D., & Xia, L. (2012). A complexity-of-strategic-behavior comparison between
Schulze’s rule and ranked pairs. In Proceedings of the 26th AAAI Conference on
Artificial Intelligence, pp. 1429–1435.
Perek, T., Faliszewski, P., Pini, M., & Rossi, F. (2013). The complexity of losing voters. In Proceedings of the 12th International Conference on Autonomous Agents and
Multiagent Systems, pp. 407–414.
Rothe, J., & Schend, L. (2013). Challenges to complexity shields that are supposed to
protect elections against manipulation and control: A survey. Annals of Mathematics
and Artificial Intelligence, 68 (1–3), 161–193.
Russell, N. (2007). Complexity of control of Borda count elections.
Rochester Institute of Technology.

Master’s thesis,

Waggoner, B., Xia, L., & Conitzer, V. (2012). Evaluating resistance to false-name manipulations in elections. In Proceedings of the 26th AAAI Conference on Artificial
Intelligence, pp. 1485–1491.
Wagman, L., & Conitzer, V. (2014). False-name-proof voting with costs over two alternatives. International Journal of Game Theory, 43 (3), 599–618.
541

Faliszewski, Hemaspaandra, & Hemaspaandra

Wojtas, K., & Faliszewski, P. (2012). Possible winners in noisy elections. In Proceedings of
the 26th AAAI Conference on Artificial Intelligence, pp. 1499–1505.
Xia, L. (2012). How many vote operations are needed to manipulate a voting system?. In
Proceedings (Workshop Notes) of the 4th International Workshop on Computational
Social Choice, pp. 443–454.
Xia, L., Lang, J., & Monnot, J. (2011). Possible winners when new alternatives join:
New results coming up!. In Proceedings of the 10th International Conference on Autonomous Agents and Multiagent Systems, pp. 829–836. International Foundation for
Autonomous Agents and Multiagent Systems.

542

Journal of Artificial Intelligence Research 52 (2015) 361-398

Submitted 7/14; published 3/15

Inferring Team Task Plans from Human Meetings:
A Generative Modeling Approach with Logic-Based Prior
Been Kim
Caleb M. Chacha
Julie A. Shah

beenkim@csail.mit.edu
c chacha@csail.mit.edu
julie a shah@csail.mit.edu

Massachusetts Institute of Technology
77 Massachusetts Ave. MA 02139, USA

Abstract
We aim to reduce the burden of programming and deploying autonomous systems to
work in concert with people in time-critical domains such as military field operations and
disaster response. Deployment plans for these operations are frequently negotiated on-thefly by teams of human planners. A human operator then translates the agreed-upon plan
into machine instructions for the robots. We present an algorithm that reduces this translation burden by inferring the final plan from a processed form of the human team’s planning
conversation. Our hybrid approach combines probabilistic generative modeling with logical
plan validation used to compute a highly structured prior over possible plans, enabling us
to overcome the challenge of performing inference over a large solution space with only a
small amount of noisy data from the team planning session. We validate the algorithm
through human subject experimentations and show that it is able to infer a human team’s
final plan with 86% accuracy on average. We also describe a robot demonstration in which
two people plan and execute a first-response collaborative task with a PR2 robot. To the
best of our knowledge, this is the first work to integrate a logical planning technique within
a generative model to perform plan inference.

1. Introduction
Robots are increasingly being introduced to work in concert with people in high-intensity
domains such as military field operations and disaster response. For example, robot deployment can allow for access to areas that would otherwise be inaccessible to people (Casper
& Murphy, 2003; Micire, 2002), to inform situation assessment (Larochelle, Kruijff, Smets,
Mioch, & Groenewegen, 2011). The human-robot interface has long been identified as a major bottleneck in utilizing these robotic systems to their full potential (Murphy, 2004). As a
result, significant research efforts have been aimed at easing the use of these systems in the
field, including careful design and validation of supervisory and control interfaces (Jones,
Rock, Burns, & Morris, 2002; Cummings, Brzezinski, & Lee, 2007; Barnes, Chen, Jentsch,
& Redden, 2011; Goodrich, Morse, Engh, Cooper, & Adams, 2009). Much of this prior
work has focused on ease of use at “execution time.” However, a significant bottleneck also
exists in planning the deployment of autonomous systems and in the programming of these
systems to coordinate task execution with a human team. Deployment plans are frequently
negotiated by human team members on-the-fly and under time pressure (Casper & Murphy,
2002, 2003). For a robot to aid in the execution of such a plan, a human operator must
transcribe and translate the result of a team planning session.
c
2015
AI Access Foundation. All rights reserved.

Kim, Chacha & Shah

In this paper, we present an algorithm that reduces this translation burden by inferring
the final plan from a processed form of the human team’s planning conversation. Inferring
the plan from noisy and incomplete observation can be formulated as a plan recognition
problem (Ryall, Marks, & Shieber, 1997; Bauer, Biundo, Dengler, Koehler, & Paul, 2011;
Mayfield, 1992; Charniak & Goldman, 1993; Carberry, 1990; Grosz & Sidner, 1990; Gal,
Reddy, Shieber, Rubin, & Grosz, 2012). The noisy and incomplete characteristics of observation stem from the fact that not all observed data (e.g., the team’s planning conversation)
will be a part of the plan that we are trying to infer, and that the entire plan may not be
observed. The focus of existing plan recognition algorithms is often to search an existing
knowledge base given noisy observation. However, deployment plans for emergency situations are seldom the same, making it infeasible to build a knowledge base. In addition,
planning conversations are often conducted under time pressure and are, therefore, often
short (i.e., contain a small amount of data). Shorter conversations result in a limited amount
of available data for inference, often making the inference problem more challenging.
Our approach combines probabilistic generative modeling with logical plan validation,
which is used to compute a highly structured prior over possible plans. This hybrid approach
enables us to overcome the challenge of performing inference over a large solution space with
only a small amount of noisy data collected from the team planning session.
In this work, we focus on inferring a final plan using text data that can be logged from
chat or transcribed speech. Processing human dialogue into more machine-understandable
forms is an important research area (Kruijff, Janıcek, & Lison, 2010; Tellex, Kollar, Dickerson, Walter, Banerjee, Teller, & Roy, 2011; Koomen, Punyakanok, Roth, & Yih, 2005;
Palmer, Gildea, & Xue, 2010; Pradhan, Ward, Hacioglu, Martin, & Jurafsky, 2004), but we
view this as a separate problem and do not focus on it in this paper.
The form of input we use preserves many of the challenging aspects of natural human
planning conversations, and can be thought of as noisy observation of the final plan. Because
the team is discussing the plan under time pressure, planning sessions often consist of a
small number of succinct communications. Our approach can infer the final agreed-upon
plan using a single planning session, despite a small amount of noisy data.
We validate the algorithm through experiments with 96 human subjects and show that
we are able to infer a human team’s final plan with 86% accuracy on average. To the best
of our knowledge, this is the first work to integrate a logical planning technique within a
generative model to perform plan inference.
In summary, this work includes the following contributions:
• We formulate the novel problem of performing inference to extract a finally agreedupon plan from a human team planning conversation.
• We propose and validate a hybrid approach to perform this inference that applies
the logic-based prior probability over the space of possible agreed-upon plans. This
approach performs efficient inference for the probabilistic generative model.
• We demonstrate the benefit of this approach using human team meeting data collected
from large-scale human subject experiments (total 96 subjects) and are able to infer
a human team’s final plan with 86% accuracy on average.
362

A Generative Modeling Approach with Logic-Based Prior

This work extends the preliminary version of this work (Kim, Chacha, & Shah, 2013) to
include the inference of complex durative task plans and to infer plans before and after new
information becomes available for the human team. In addition, we extend our probabilistic
model to be more flexible to different data sets by learning hyper-parameters. We also
improve the performance of our algorithm by designing a better proposal distribution for
inference.
The formulation of the problem is presented in Section 2, followed by the technical
approach and related work in Section 3. Our algorithm is described in Section 4. The
evaluation of the algorithm using various data sets is shown in Sections 5 and 6. Finally,
we discuss the benefits and limitations of the current approach in Section 7, and conclude
with considerations for future work in Section 8.

2. Problem Formulation
Disaster response teams are increasingly utilizing web-based planning tools to plan deployments (Di Ciaccio, Pullen, & Breimyer, 2011). Hundreds of responders access these tools
to develop their plans using audio/video conferencing, text chat and annotatable maps.
Rather than working with raw, natural language, our algorithm takes a structured form of
the human dialogue from these web-based planning tools as input. The goal of this work
is to infer a human team’s final plan from this human dialogue. In doing so, this work can
be used to design an intelligent agent for these planning tools that can actively participate
during a planning session to improve the team’s decision.
This section describes the formal definition, input and output of the problem. Formally,
this problem can be viewed as one of plan recognition, wherein the plan follows the formal
representation of the Planning Domain Description Language (PDDL). The PDDL has
been widely used in the planning research community and planning competitions (i.e., the
International Planning Competition). A plan is valid if it achieves a user-specified goal state
without violating user-specified plan constraints. Actions may be constrained to execute
in sequence or in parallel with other actions. Other plan constraints can include discrete
resource constraints (e.g. the presence of two medical teams) and temporal deadlines for
time-durative actions (e.g. a robot can only be deployed for up to 1 hour at a time due to
battery life constraints).
We assume that the team reaches agreement on a final plan. The techniques introduced
by Kim and Shah (2014) can be used to detect the strength of this agreement, and to
encourage the team to further discuss the plan to reach an agreement if necessary. Situations
where a team agrees upon a flexible plan with multiple options to be explored will be
included in future study. Also, while we assume that the team is more likely to agree on a
valid plan, we do not rule out the possibility that the final plan is invalid.
2.1 Algorithm Input
Text data from the human team conversation is collected in the form of utterances, where
each utterance is one person’s turn in the discussion, as shown in Table 1. The input to our
algorithm is a machine-understandable form of human conversation data, as illustrated in
the right-hand column of Table 1. This structured form captures the actions discussed and
the proposed ordering relations among actions for each utterance.
363

Kim, Chacha & Shah

Natural dialogue

U1

U2
U3

U4

U5

U6
U7

So I suggest using Red robot to cover “upper”
rooms (A, B, C, D) and Blue robot to cover
“lower” rooms (E, F, G, H).
Okay. so first send Red robot to B and Blue
robot to G?
Our order of inspection would be (B, C, D, A)
for Red and then (G, F, E, H) for Blue.

Oops I meant (B, D, C, A) for Red.
···
So we can have medical crew go to B when
robot is inspecting C
···
First, Red robot inspects B
Yes, and then Red robot inspects D, Red medical crew to treat B

Structured form (ordered tuple
of sets of grounded predicates)
({ST(rr,A),ST(br,E),
ST(rr,B),ST(br,F),
ST(rr,C),ST(br,G),
ST(rr,D),ST(br,H)})
({ST(rr,B),ST(br,G)})
({ST(rr,B),ST(br,G)},
{ST(rr,C),ST(br,F)},
{ST(rr,D),ST(br,E)},
{ST(rr,A), ST(br,H)})
({ST(rr,B)},{ST(rr,D)},
{ST(rr,C)},{ST(rr,A)})
({ST(m,B), ST(r,C)})

({ST(r,B)})
({ST(r,D),ST(rm,B)})

Table 1: Utterance tagging: Dialogue and structured form examples. (The structured form
uses the following shorthand - ST: send to, rr: red robot, br: blue robot, rm: red medical,
bm: blue medical, e.g. ST(br,A) : “send the blue robot to room A.”)

Although we are not working with raw, natural language, this form of data still captures many of the characteristics that make plan inference based on human conversation
challenging. Table 1 shows part of the data using the following shorthand:
ST = SendTo
rr = red robot, br = blue robot
rm = red medical, bm = blue medical
e.g. ST(br, A) = SendTo(blue robot, room A)

2.1.1 Utterance Tagging
An utterance is tagged as an ordered tuple of sets of grounded predicates. Following a
formal definition for first-order languages, a grounded predicate is an atomic formula whose
argument terms are grounded (i.e., no free variables; all variables have an assigned value).
In our case, a predicate represents an action applied to a set of objects (a crew member,
robot, room, etc.), and an utterance can be represented as ordered sets of these actions. We
only consider utterances related to plan formation; greetings and jokes, for example, are not
tagged. Each set of grounded predicates represents a collection of actions that, according to
the utterance, should happen simultaneously. The order of the sets of grounded predicates
indicates the relative order in which these collections of actions should happen. For example,
364

A Generative Modeling Approach with Logic-Based Prior

({ST(rr, B), ST(br, G)}, {ST(rm, B)}) corresponds to sending the red robot to room B
and the blue robot to room G simultaneously, followed by sending the red medical team to
room B.
As indicated in Table 1, the structured dialogue still includes high levels of noise. Each
utterance (i.e. U1-U7) discusses a partial plan, and only predicates explicitly mentioned in
the utterance are tagged (e.g. U6-U7: the “and then” in U7 implies a sequencing constraint
with the predicate discussed in U6, but the structured form of U7 does not include ST(r,B)).
Typos and misinformation are tagged without correction (e.g. U3), and any utterances
indicating a need to revise information are not placed in context (e.g. U4). Utterances that
clearly violate the ordering constraints (e.g. U1: all actions cannot happen at the same
time) are also tagged without correction. In addition, information regarding whether an
utterance was a suggestion, rejection of or agreement with a partial plan is not coded.
Note that the utterance tagging only contains information about relative ordering between the predicates appearing in that utterance, not the absolute ordering of their appearance in the final plan. For example, U2 specifies that the two grounded predicates happen
at the same time. It does not state when the two predicates happen in the final plan, or
whether other predicates will happen in parallel. This simulates how humans conversations
often unfold — at each utterance, humans only observe the relative ordering, and infer
the absolute order of predicates based on the whole conversation and an understanding of
which orderings would make a valid plan. This utterance tagging scheme is also designed
to support the future transition to automatic natural language processing. Automatic semantic role labeling (Jurafsky & Martin, 2000), for example, can be used to detect the
arguments of predicates from sentences. One of the challenges with incorporating semantic
role labeling into our system is that the dialogue from our experiments is often colloquial
and key grammatical components of sentences are often omitted. Solving this problem and
processing free-form human dialogue into more machine-understandable forms is an important research area, but we view that as a separate problem and do not focus on it in this
paper.
2.2 Algorithm Output
The output of the algorithm is an inferred final plan, sampled from the probability distribution over the final plans. The final plan has the same representation to the structured
utterance tags (ordered tuple of sets of grounded predicates). The predicates in each set
represent actions that should happen in parallel, and the ordering of sets indicates the sequence. Unlike the utterance tags, however, the sequence ordering relations in the final
plan represent the absolute order in which the actions are to be carried out. An example of
a plan is ({A1 , A2 }, {A3 }, {A4 , A5 , A6 }), where Ai represents a predicate. In this plan, A1
and A2 will happen at step 1 of the plan, A3 happens at step 2 of the plan, and so on.

3. Approach in a Nutshell and Related Work
Planning conversations performed under time pressure exhibit unique characteristics and
challenges for inferring the final plan. First, these planning conversations are succinct —
participants tend to write shortly and briefly, and to be in a hurry to make a final decision.
Second, there may be a number of different valid plans for the team’s deployment — even
365

Kim, Chacha & Shah

Figure 1: Web-based tool developed and used for data collection

366

A Generative Modeling Approach with Logic-Based Prior

with a simple scenario, people tend to generate a broad range of final plans. This represents
the typical challenges faced during real rescue missions, where each incident is unique and
participants cannot have a library of plans to choose from at each time. Third, these
conversations are noisy — often, many suggestions are made and rejected more quickly
than they would be in a more casual setting. In addition, there are not likely to be many
repeated confirmations of agreement, which might typically ease detection of the agreedupon plan.
It might seem natural to take a probabilistic approach to the plan inference problem,
as we are working with noisy data. However, the combination of a small amount of noisy
data and a large number of possible plans means that inference using typical, uninformative
priors over plans may fail to converge to the team’s final plan in a timely manner.
This problem could also be approached as a logical constraint problem of partial order
planning, if there were no noise in the utterances: If the team were to discuss only partial
plans relating to the final plan, without any errors or revisions, then a plan generator or
scheduler (Coles, Fox, Halsey, Long, & Smith, 2009) could produce the final plan using
global sequencing. Unfortunately, data collected from human conversation is sufficiently
noisy to preclude this approach.
These circumstances provided motivation for a combined approach, wherein we built
a probabilistic generative model and used a logic-based plan validator (Howey, Long, &
Fox, 2004) to compute a highly structured prior distribution over possible plans. Intuitively
speaking, this prior encodes our assumption that the final plan is likely, but not required,
to be a valid plan. This approach naturally deals with both the noise in the data and
the challenge of performing inference over plans with only a limited amount of data. We
performed sampling inference in the model using Gibbs and Metropolis-Hastings sampling
to approximate the posterior distribution over final plans, and empirical validation with
human subject experiments indicated that the algorithm achieves 86% accuracy on average.
More details of our model and inference methods are presented in Section 4.
The related work can be categorized into two categories: 1) application and 2) technique.
In terms of application, our work relates to plan recognition (Section 3.1). In terms of
technique, our approach relates to methods that combine logic and probability, though
with different focused applications (Section 3.2).
3.1 Plan Recognition
Plan recognition has been an area of interest within many domains, including interactive
software (Ryall et al., 1997; Bauer et al., 2011; Mayfield, 1992), story understanding (Charniak & Goldman, 1993) and natural language dialogue (Carberry, 1990; Grosz & Sidner,
1990).
The literature can be categorized in two ways. The first is in terms of requirements.
Some studies (Lochbaum, 1998; Kautz, 1987) require a library of plans, while others (Zhuo,
Yang, & Kambhampati, 2012; Ramırez & Geffner, 2009; Pynadath & Wellman, 2000;
Sadilek & Kautz, 2010) replace this library with relevant structural information. If a library
of plans is required, some studies (Weida & Litman, 1992; Kautz, Pelavin, Tenenberg, &
Kaufmann, 1991) assumed that this library can be collected, and that all future plans are
guaranteed to be included within the collected library. By contrast, if a library of plans is
367

Kim, Chacha & Shah

not required, it can be replaced by related structure information, such as a domain theory
or the possible set of actions performable by agents. The second categorization for the
literature is in terms of technical approach. Some studies incorporated constraint-based
approaches, while others took probabilistic or combination approaches.
First, we reviewed work that treated plan recognition as a knowledge base search problem. This method assumes that you either have or can build a knowledge base, and that
your goal is to efficiently search this knowledge base (Lochbaum, 1998; Kautz, 1987). This
approach often includes strong assumptions regarding the correctness and completeness of
the plan library, in addition to restrictions on noisy data (Weida & Litman, 1992; Kautz
et al., 1991), and is applicable in domains where the same plan reoccurs naturally. For
example, Gal et al. (2012) studied how to adaptively adjust educational content for a better
learning experience, given students’ misconceptions, using a computer-based tutoring tool.
Similarly, Brown and Burton (1978) investigated users’ underlying misconceptions using
user data collected from multiple sessions spent trying to achieve the same goal. In terms
of technical approach, the above approaches used logical methods to solve the ordering
constraints problem of searching the plan library.
We also reviewed work that replaced a knowledge base with the structural information
of the planning problem. Zhuo et al. (2012) replaced the knowledge base with action models
of the domain, and formulated the problem as one of satisfiability to recognize multi-agent
plans. A similar approach was taken by Ramırez and Geffner (2009), wherein action models
were used to replace the plan library, while Pynadath and Wellman (2000) incorporated
an extension of probabilistic context free grammars (PCFGs) to encode a set of predefined
actions to improve efficiency. More recently, Markov logic was applied to model the geometry, motion model and rules for the recognition of multi-agent plans while playing a game
of capture the flag (Sadilek & Kautz, 2010). Replacing the knowledge base with structural
information reduces the amount of prior information required. However, there are two major issues with the application of prior work to recognize plans from team conversation:
First, the above work assumed some repetition of previous plans. For example, learning the
weights in Markov logic (which represent the importance or strictness of the constraints)
requires prior data from the same mission, with the same conditions and resources. Second, using first-order logic to express plan constraints quickly becomes computationally
intractable as the complexity of a plan increases.
In contrast to logical approaches, probabilistic approaches allow for noisy observations.
Probabilistic models are used to predict a user’s next action, given noisy data (Albrecht,
Zuckerman, Nicholson, & Bud, 1997; Horvitz, Breese, Heckerman, Hovel, & Rommelse,
1998). These works use actions that are normally performed by users as training data.
However, the above approaches do not consider particular actions (e.g., actions that must
be performed by users to achieve certain goals within a software system) to be more likely.
In other words, while they can deal with noisy data, they do not incorporate structural
information that could perhaps guide the plan recognition algorithm. An additional limitation of these methods is that they assume predefined domains. By defining a domain, the
set of possible plans is limited, but the possible plans for time-critical missions is generally
not a limited set. The situation and available resources for each incident are likely to be
different. A method that can recognize a plan from noisy observations, and from an open
set of possible plans, is required.
368

A Generative Modeling Approach with Logic-Based Prior

Some probabilistic approaches incorporate structure through the format of a plan library. Pynadath and Wellman (2000) represented plan libraries as probabilistic context
free grammars (PCFGs). Then this was used to build Bayes networks that modeled the underlying generative process of plan construction. However, their parsing-based approaches
did not deal with partially-ordered plans or temporally interleaved plans. Geib et al. (2008)
and Geib and Goldman (2009) overcame this issue by working directly with the plan representation without generating an intermediate representation in the form of a belief network.
At each time step, their technique observed the previous action of the agent and generated
a pending action set. This approach, too, assumed an existing plan library and relied on
the domains with some repetition of previous plans. More recently, Nguyen, Kambhampati,
and Do (2013) introduced techniques to address incomplete knowledge of the plan library,
but for plan generation rather than plan recognition applications.
Our approach combines a probabilistic approach with logic-based prior to infer team
plans without the need for historical data, using only situational information and data from
a single planning session. The situational information includes the operators and resources
from the domain and problem specifications, which may be updated or modified from one
scenario to another. We do not require the development or addition of a plan library to infer
the plan, and demonstrate our solution is robust to incomplete knowledge of the planning
problem.
3.2 Combining Logic and Probability
The combination of a logical approach with probabilistic modeling has gained interest in
recent years. Getoor and Mihalkova (2011) introduced a language for the description of statistical models over typed relational domains, and demonstrated model learning using noisy
and uncertain real-world data. Poon and Domingos (2006) proposed statistical sampling
to improve searching efficiency for satisfiability testing. In particular, the combination of
first-order logic and probability, often referred to as Markov Logic Networks (MLN), was
studied. MLN forms the joint distribution of a probabilistic graphical model by weighting
formulas in a first-order logic (Richardson & Domingos, 2006; Singla & Domingos, 2007;
Poon & Domingos, 2009; Raedt, 2008).
Our approach shares with MLNs the philosophy of combining logical tools with probabilistic modeling. MLNs utilize first-order logic to express relationships among objects.
General first-order logic allows for the use of expressive constraints across various applications. However, within the planning domain, enumerating all constraints in first-order logic
quickly becomes intractable as the complexity of a plan increases. For example, first-order
logic does not allow the explicit expression of action preconditions and postconditions, let
alone constraints among actions. PDDL has been well-studied in the planning research
community (McDermott, Ghallab, Howe, Knoblock, Ram, Veloso, Weld, & Wilkins, 1998),
where the main focus is to develop efficient ways to express and solve planning problems.
Our approach exploits this tool to build a highly structured planning domain within the
probabilistic generative model framework.

369

Kim, Chacha & Shah

4. Algorithm
This section presents the details of our algorithm. We describe our probabilistic generative
model and indicate how this model is combined with the logic-based prior to perform efficient inference. The generative model specifies a joint probability distribution over observed
variables (e.g., human team planning conversation) and latent variables (e.g., the final plan);
our model learns the distribution of the team’s final plan, while incorporating a logic-based
prior (plan validation tool). Our key contribution is the design of this generative model
with logic-based prior. We also derive the Gibbs sampling (Andrieu, De Freitas, Doucet, &
Jordan, 2003) representation and design the scheme for applying Metropolis-Hasting sampling (Metropolis, Rosenbluth, Rosenbluth, Teller, & Teller, 1953) for performing inference
on this model.
4.1 Generative Model
We model the human team planning process, represented by their dialogue, as a probabilistic
Bayesian model. In particular, we utilize a probabilistic generative modeling approach that
has been extensively used in topic modeling (e.g., Blei, Ng, & Jordan, 2003).
We start with a plan latent variable that must be inferred through observation of utterances made during the planning session. The model generates each utterance in the
conversation by sampling a subset of the predicates in plan and computing the relative ordering in which they appear within the utterance. The mapping from the absolute ordering
in plan to the relative ordering of predicates in an utterance is described in more detail
below. Since the conversation is short and the level of noise is high, our model does not
distinguish utterances based on the order in which they appear during the conversation.
This assumption produces a simple yet powerful model, simplifies the inference steps and
enables up to 86% accuracy for the inference of the final plan. However, the model can
also be generalized to take the ordering into account with a simple extension. We include
further discussion on this assumption and the extension in Section 7.4.
The following is a step-by-step description of the generative model:
1. Variable plan: The plan variable in Figure 2 is defined as an ordered tuple of sets
of grounded predicates, and represents the final plan agreed upon by the team. It is
distributed over the space of ordered tuples of sets of grounded predicates. We assume
that the total number of grounded predicates in one domain is fixed.
The prior distribution over the plan variable is given by:
(
eα if the plan is valid
p(plan) ∝
1
if the plan is invalid.

(1)

where α is a positive number. This models our assumption that the final plan is more
likely, but is not necessarily required, to be a valid plan.
The likelihood of the plan is defined as:

370

A Generative Modeling Approach with Logic-Based Prior

θβ

kβ

β

α

kωp

plan

ωp

snt

pnt

θωp

N

s0t
T

Figure 2: Graphical model representation of the generative model. The plan latent variable
represents the final agreed-upon plan. The pnt variable represents the nth predicate of tth
utterance, while snt represents the absolute ordering of that predicate in the plan. The
s0t represents the relative ordering of sn within the utterance t. The latent variable ω p
represents the noisiness of predicates, and β represents the noisiness of the ordering.

p(s, p|plan, ωp ) ∼

YY

∼

YY

t

t

p(snt , pnt |plan, ωp )

n

p(pnt |plan, snt , ω, p)p(snt |plan)

n

Each set of predicates in plan is assigned a consecutive absolute plan step index s,
starting at s = 1 working from left to right in the ordered tuple. For example, given
plan = ({A1 , A2 }, {A3 }, {A4 , A5 , A6 }), where each Ai is a predicate, A1 and A2 occur
in parallel at plan step s = 1, and A6 occurs at plan step s = 3.
2. Variable snt : snt represents a step index (i.e., absolute ordering) of the nth predicate
in the tth utterance in the plan. A step index represents an absolute timestamp of the
predicate in the plan. In other words, snt indicates the absolute order of the predicate
pnt as it appears in plan. We use st = {s1t , s2t . . . } to represent a vector of orderings
for the tth utterance, where the vector st may not be a set of consecutive numbers.
snt is sampled as follows: For each utterance, n predicates are sampled from plan.
For example, consider n = 2, where the first sampled predicate appears in the second
set (i.e., the second timestamp) of plan and the second sampled predicate appears in
the fourth set. Under these conditions, s1t = 2 and s2t = 4. The probability of a set
being sampled is proportional to the number of predicates contained within that set.
For example, given plan = ({A1 , A2 }, {A3 }, {A4 , A5 , A6 }), the probability of selecting
the first set ({A1 , A2 }) is 62 . This models the notion that people are more likely to
371

Kim, Chacha & Shah

discuss plan steps that include many predicates, since plan steps with many actions
may require more effort to elaborate. Formally:

p(snt = i|plan) =

# predicates in set i in plan
.
total # of predicates in plan

(2)

The likelihood of st is defined as:

0

0

p(st |pt , st ) ∼ p(st |plan)p(pt , st |st , β, ωp , plan)
Y
0
∼ p(st |st , β)
p(snt |plan)p(pnt |plan, snt , ωp )
n
0

0

0

3. Variable s0t and β: The variable s0t is an array of size n, where s0t = {st1 , st2 . . . stn }.
0
The stn random variable represents the relative ordering of the nth predicate within
the tth utterance in the plan, with respect to other grounded predicates appearing in
the tth utterance.
s0t is generated from st as follows:
(
eβ
p(s0t |st ) ∝
1

if s0t = f (st )
if s0t =
6 f (st ).

(3)

where β > 0. The β random variable is a hyper-parameter that represents the noisiness
of the ordering of grounded predicates appearing throughout the entire conversation.
It takes a scalar value, and is sampled from gamma distribution:
p(β|kβ , θβ ) ∼ Gamma(kβ , θβ ),

(4)

where both kβ and θβ are set to 10.
The function f is a deterministic mapping from the absolute ordering st to the relative
ordering s0t . f takes a vector of absolute plan step indices as input, and produces a
vector of consecutive indices. For example, f maps st = (2, 4) to s0t = (1, 2) and
st = (5, 7, 2) to s0t = (2, 3, 1).
This variable models the way predicates and their orders appear during human conversation: People frequently use relative terms, such as “before” and “after,” to describe
partial sequences of a full plan, and do not often refer to absolute ordering. People
also make mistakes or otherwise incorrectly specify an ordering. Our model allows for
inconsistent relative orderings with nonzero probability; these types of mistakes are
modeled by the value of β.
4. Variable pnt and ω p : The variable pnt represents the nth predicate appearing in
the tth utterance. The absolute ordering of this grounded predicate is snt . The pnt is
sampled given snt , the plan variable and a parameter, ωp .
372

A Generative Modeling Approach with Logic-Based Prior

The ωp random variable (hyper-parameter) represents the noisiness of grounded predicates appearing throughout the entire conversation. It takes a scalar value, and is
sampled from beta distribution:
p(ωp |kωp , θωp ) ∼ beta(kωp , θωp ),

(5)

where kωp is set to 40, and θωp is set to 10.
With probability ωp , we sample the predicate pnt uniformly with replacement from the
“correct” set snt in plan as follows:
(
1
if i is in set j
n
n
p(pt = i|plan, st = j) = # pred. in set j
0
o.w.
With probability 1 − ωp , we sample the predicate pnt uniformly with replacement from
“any” set in plan (i.e., from all predicates mentioned in the dialogue). Therefore:
p(pnt = i|plan, snt = j) =

1
.
total # predicates

(6)

In other words, with higher probability ωp , we sample a value for pnt that is consistent
with snt but allows for nonzero probability that pnt is sampled from a random plan.
This allows the model to incorporate noise during the planning conversation, including
mistakes or plans that are later revised.
4.2 Plan Validation Tool
We use the Planning Domain Description Language (PDDL) 2.1 plan validation tool (Howey
et al., 2004) to evaluate the prior distribution over possible plans. In this section, we briefly
review the PDDL, and the plan validation tool that is used to form the prior in Equation
1.
4.2.1 Planning Domain Description Language
The Planning Domain Description Language (PDDL) (McDermott et al., 1998) is a standard
planning language, inspired by the Stanford Research Institute Problem Solver (STRIPS)
(Fikes & Nilsson, 1972) and Action Description Language (ADL) (Pednault, 1987), and is
now utilized in the International Planning Competition.
A PDDL model of a planning problem has two major components: a domain specification
and a problem specification. The domain description consists of a domain-name definition,
requirements on language expressivity, definition of object types, definition of constant
objects, definition of predicates (i.e. templates for logical facts), and the definition of
possible actions that are instantiated during execution. Actions have parameters that may
be instantiated with objects, preconditions, and conditional or unconditional effects. An
excerpt of the PDDL domain file used in this work, called the RESCUE domain, is shown
below. For example, the predicate isSaved encodes the logical fact of whether or not a
particular patient has been rescued, and the action SEND−ROBOT is instantiated during
execution to send a particular robot to particular location.
373

Kim, Chacha & Shah

(define (domain RESCUE)
(:requirements :typing :durative−actions :negative−preconditions)
(:types patient valve − thingsToFix location − location
med−crew mechanic robot − resource)
(:predicates
(isAt ?p − thingsToFix ?l − location)
(isSaved ?p − patient)
(isFixed ?v − valve)
(isInspected ?l − location)
(isAvail ?r − resource)
)
(:durative−action SEND−ROBOT
:parameters (?r − robot ?l − location)
:duration (= ?duration 1)
:condition (and
(at start (isAvail ?r))
(at start (not (isInspected ?l)))
)
:effect (and
(at start (not (isAvail ?r) ) )
(at end (isAvail ?r))
(at end (isInspected ?l))
)
)
...)

The problem specification consists of a problem-name definition, the definition of the
related domain-name, the definition of all the possible objects relevant to the planning
problem, the initial state of the planning environment as a conjunction of true/false facts,
and the definition of goal-states as a logical expression over true/false facts. An excerpt of
the PDDL problem specification file used in this work is shown below. The ‘init’ section
describes initial conditions — for example, patient pB is initially situated at location B,
and patient pD is at D. The ‘goal’ section indicates the desired final state — in this case all
rooms must be inspected, all patients must be rescued, and all valves fixed. The ‘metric’
section defines the metric that the planner optimizes when producing a plan.

374

A Generative Modeling Approach with Logic-Based Prior

(define (problem rescuepeople)
(:domain RESCUE)
(:objects
pB pD pG − patient
vC vF − valve
A B C D E F G H − location
redMed blueMed − med−crew
redR blueR − robot
mech1 − mechanic)
(:init
(isAt pB B)
(isAt pD D)
...
(isAvail redMed)
(isAvail blueMed)
(isAvail redR)
(isAvail blueR)
(isAvail mech1)
(not (isSaved pB))
...
(not (isInspected A))
(not (isInspected B))
...
(not (isFixed vC))
(not (isFixed vF))
)
(:goal (and
(isSaved pB)
(isSaved pD)
...
(isFixed vC)
(isFixed vF)
(isInspected A)
(isInspected B)
...
)
)
;(:metric minimize (total−time))
)

For our work, we note that domain specification could be reused from one planning
session to another if the capabilities of a team do not change. For example, once the set of
possible set of actions is defined in domain specification, it may be sufficient to merely modify
the number and names of locations, medical crews, or robots in the problem specification.
The domain and the problem specification files represent the only ‘prior knowledge’ that
our approach requires in order to infer the final agreed-upon plan. A valid plan is defined as
a totally or partially ordered sequence of grounded predicates that achieves the goal state
from the initial state, without violating any constraints. Otherwise, the plan is invalid. The
next section describes a plan validation tool that assesses the validity of a given plan, given
the domain and problem specification files.
4.2.2 Plan Validation Tool (VAL)
The plan validator is a standard tool that takes as input a planning problem described in
PDDL and a proposed solution plan. The tool incorporates three input files: 1) a domain
definition file, 2) a problem definition file and 3) a proposed solution plan file. The domain

375

Kim, Chacha & Shah

definition file contains types of parameters (e.g., resources, locations), predicate definitions
and actions (which also have parameters, conditions and effects). The problem definition
file contains information specific to the situation: For example, the number of locations
and victims, initial goal conditions and a metric to optimize. A proposed solution plan file
contains a single complete plan, described in PDDL. The output of a plan validation tool
indicates whether the proposed solution plan is valid (true) or not (false).
Metrics represent ways to compute a plan quality value. For the purpose of this study,
the metrics used included: 1) the minimization of total execution time for the radioactive
material leakage scenario, and 2) the maximization of the number of incidents responded
to in the police incident response scenario. Intuitively speaking, metrics reflect the rational
behavior of human experts. It is natural to assume that human experts would try to
minimize the total time to completion of time-critical missions (such as in the radioactive
material leakage scenario). If first responders cannot accomplish all the necessary tasks in
a scenario due to limited availability of resources, they would most likely try to maximize
the number of completed tasks (such as in the police incident response scenario).
One could imagine that these input files could be reused in subsequent missions, as
the capabilities (actions) of a team may not change dramatically. However, the number of
available resources might vary, or there might be rules implicit in a specific situation that
are not encoded in these files (e.g., to save endangered humans first before fixing a damaged
bridge). In Section 6, we demonstrate the robustness of our approach using both complete
and degraded PDDL plan specifications.
The computation of a plan’s validity is generally cheaper than that of a valid plan generation. This gives us a way to compute p(plan) (defined in Section 4.1) up to proportionality
in a computationally efficient manner. Leveraging this efficiency, we use Metropolis-Hastings
sampling, (details described in Section 4.3.1) without calculating the partition function.
4.3 Gibbs Sampling
We use Gibbs sampling to perform inference on the generative model. There are four latent
variables to sample: plan, the collection of variables snt , ωp and β. We iterate between
sampling each latent variable, given all other variables. The PDDL validator is used when
the plan variable is sampled.
4.3.1 Sampling Plan using Metropolis-Hastings
Unlike snt , where we can write down an analytic form to sample from the posterior, it is
intractable to directly resample the plan variable, as doing so would require calculating the
number of all possible plans, both valid and invalid. Therefore, we use a Metropolis-Hasting
(MH) algorithm to sample from the plan posterior distribution within the Gibbs sampling
steps.

376

A Generative Modeling Approach with Logic-Based Prior

The posterior of plan can be represented as the product of the prior and likelihood, as
follows:
p(plan|s, p) ∝ p(plan)p(s, p|plan)
= p(plan)

T Y
N
Y

p(snt , pnt |plan)

t=1 n=1

= p(plan)

T Y
N
Y

p(snt |plan)p(pnt |plan, snt )

(7)

t=1 n=1

The MH sampling algorithm is widely used to sample from a distribution when direct
sampling is difficult. This algorithm allows us to sample from posterior distribution according to the user-specified proposal distribution without having to calculate the partition
function. The typical MH algorithm defines a proposal distribution, Q(x0 |xt ), which samples a new point (i.e., x0 : a value of the plan variable in our case) given the current point
xt . The new point can be achieved by randomly selecting one of several possible moves,
as defined below. The proposed point is then accepted or rejected, with a probability of
min(1, acceptance ratio).
Unlike simple cases, where a Gaussian distribution can be used as a proposal distribution,
our distribution needs to be defined over the plan space. Recall that plan is represented as
an ordered tuple of sets of predicates. In this work, the new point (i.e., a candidate plan)
is generated by performing one of the following moves on the current plan:
• Move to next: Randomly select a predicate that is in the current plan, and move it
to the next timestamp. If it is in the last timestamp in the plan, move it to the first
timestamp.
• Move to previous: Randomly select a predicate that is in the current plan, and move
it to the previous timestamp. If it is in the first timestamp in the plan, move it to the
last timestamp.
• Add a predicate to plan: Randomly select a predicate that is not in the current plan,
and randomly choose one timestamp in the current plan. Add the predicate to the
chosen timestamp.
• Remove a predicate from plan: Randomly select and remove a predicate that is in the
current plan.
These moves are sufficient to allow for movement from one arbitrary plan to another.
The intuition behind designing this proposal distribution is described in Section 7.5.
Note that the proposal distribution, as it is, is not symmetrical — Q(x0 |xt ) 6= Q(xt |x0 ).
We need to compensate for that according to the following,
p∗ (x0 )Q(x0 |xt ) = p∗ (x)Q(xt |x0 ),

(8)

where p∗ is the target distribution. This can be done simply by counting the number of
moves possible from x0 to get to x, and from x0 to x, and weighing the acceptance ratio such
377

Kim, Chacha & Shah

that Equation 8 is true. This is often referred to as Hastings correction, which is performed
to ensure that the proposal distribution does not favor some states over others.
Next, the ratios of the proposal distribution at the current and proposed points are
calculated. When plan is valid, p(plan) is proportional to eα , and when plan is invalid,
it is proportional to 1, as described in Equation 1. Plan validity is calculated using the
plan validation tool. The remaining term, p(snt |plan)p(pnt |plan, snt ), is calculated using
Equations 2 and 6.
Then,
 ∗ the proposed
 plan is accepted with the following probability:
p (plan=x0 |s,p)
min 1, p∗ (plan=xt |s,p) , where p∗ is a function proportional to the posterior distribution.
Although we chose to incorporate MH, it is not the only usable sampling method. Any
other method that does not require calculation of the normalization constant (e.g., rejection
sampling or slice sampling) could also be used. However, for some methods, sampling from
the ordered tuple of sets of grounded predicates can be slow and complicated, as pointed
out by Neal (2003).
4.3.2 Sampling Hyper-Parameters β and ωp with Slice Sampling
We use slice sampling to sample both β and ωp . This method is simple to implement and
works well with scalar variables. Distribution choices are made based on the valid value
each can take. β can take any value, preferably with one mode, while ωp can only take a
value between [0, 1]. MH sampling may also work; however, this method could be overly
complicated for a simple scalar value. We chose the stepping out procedure, as described
by Neal et al (Neal, 2003).
4.3.3 Sampling snt
Fortunately, an analytic expression exists for the posterior of snt :
p(st |plan, pt , s0t ) ∝ p(st |plan)p(pt , s0t |plan, st )
= p(st |plan)p(pt |plan, st )p(s0t |st )
= p(s0t |st )

N
Y

p(snt |plan)p(pnt |plan, snt )

n=1

Note that this analytic expression can be expensive to evaluate if the number of possible
values of snt is large. In that case, one can marginalize snt , as the variable we truly care
about is the plan variable.

5. Experimentation
In this section, we explain the web-based collaboration tool that is used in our experiment
and two fictional rescue scenarios given to human subjects in the experiment.
5.1 Web-Based Tool Design
Disaster response teams are increasingly using web-based tools to coordinate missions and
share situational awareness. One of the tools currently used by first responders is the Next
378

A Generative Modeling Approach with Logic-Based Prior

Generation Incident Command System (NICS) (Di Ciaccio et al., 2011). This integrated
sensing and command-and-control system enables the distribution of large-scale coordination across multiple jurisdictions and agencies. It provides video and audio conferencing
capabilities, drawing tools and a chat window, and allows for the sharing of maps and resource information. Overall, the NICS enables the collection and exchange of information
critical to mission planning.
We designed a web-based collaboration tool modeled after this system, with a modification that requires the team to communicate solely via text chat. This tool was developed
using Django (Holovaty & Kaplan-Moss, 2009), a free and open-source Web application
framework written in Python. Django is designed to ease working with heavy-duty data,
and provides a Python API to enable rapid prototyping and testing. Incoming data can be
easily maintained through a user-friendly administrative interface. Although it is a simplified version of the NICS, it provides the essence of the emerging technology for large-scale
disaster coordination (Figure 1).
5.2 Scenarios
Human subjects were given one of two fictional rescue scenarios and asked to formulate a
plan by collaborating with their partners. We collected human team planning data from
the resulting conversations, and used this data to validate our algorithm. The first scenario involves a radioactive material leakage accident in a building with multiple rooms,
where all tasks (described below) were assumed to take one unit of time. We added complexity to the scenario by announcing a new piece of information halfway through the
planning conversation, requiring the team to change their plan. The second scenario also
included time-durative actions (e.g., action A can only take place if action B is taking
place). These scenarios are inspired by those described in emergency response team training manuals (FEMA, 2014), and are designed to be completed in the reasonable time for
our experiments.
5.2.1 First Scenario: Radioactive Material Leakage
This disaster scenario involves the leakage of radioactive material on a floor consisting of
eight rooms. Each room contains either a patient requiring in-person assessment or a valve
that must be repaired (Figure 4).
Goal State: All patients are assessed in-person by a medical crew. All valves are fixed
by a mechanic. All rooms are inspected by a robot.
Constraints: There are two medical crews, red and blue (discrete resource constraint),
one human mechanic (discrete resource constraint) and two robots, red and blue (discrete
resource constraint). For safety purposes, a robot must inspect the radioactivity of a room
before human crews can be sent inside (sequence constraint).
Assumption: All tasks (e.g. inspecting a room, fixing a valve) take the same amount of
time (one unit), and there are no hard temporal constraints. This assumption was made to
conduct the initial proof-of-concept experimentation described in this paper, and is relaxed
in the scenario described in Section 5.2.2.

379

Kim, Chacha & Shah

Figure 3: Radioactive material leakage scenario

Announcement: During the planning session, the team receives a situation update that
the red robot is now out of order, requiring the team to modify their previously discussed
plan to only use one robot for deployment. The announcement triggers automatically once
the team has exchanged 20 utterances. The purpose of this announcement is to increase
task complexity for the team, to have at least two competing plans and to increase the level
of noise in the conversation.
This scenario produces a large number of possible plans (more than 1012 ), many of which
are valid for achieving the goals without violating the constraints.
5.2.2 Second Scenario: Police Incidents Response
The second scenario involves a team of police officers and firefighters responding to a series
of incidents occurring in different time frames. This scenario includes more complicated
time-durative actions than the first, as well as interdependency of tasks that has to be
taken into account when planning. The current time is given as 8 p.m. Two fires have
started at this time: one at a college dorm and another at a theater building, as shown
in Figure 4. Also, three street corners, indicated as crime hot-spots (places predicted to
experience serious crimes, based on prior data), become active between 8:30 p.m. and 9 p.m.
There is also a report of a street robbery taking place at 8 p.m. No injury has occurred;
however, a police officer must speak with the victim to file an incident report.
Goal State: Respond to as many incidents as possible given the resources listed in Table
2.
Constraints:
• Putting out a fire requires one fire truck and one police car equipped with a robot.
• A police car must stay with the robot until an evacuation is over.
• Only a robot can perform an evacuation.
• Each robot can only be used once.
• Successfully responding to a fire requires both evacuating the building and putting
out the fire. Both actions can happen simultaneously.

380

A Generative Modeling Approach with Logic-Based Prior

Figure 4: Police incident response scenario

Resources

Name

Police teams
with
robots

Alpha
Bravo
Charlie

Function
Patrol hotspot
Deploy robot for evacuation
Respond to the street robbery

Fire trucks

Delta
Echo
Foxtrot

Put out fire

Duration
Evacuate one building in:
30 min with one robot
15 min with two robots
10 min with three robots
Talk to the victim in:
10 min with one police car
Put out fire in:
30 min with one fire truck
15 min with two fire trucks
10 min with three fire trucks
(same for both dorm and theater)

Table 2: Resources available in police incident response scenario

381

Kim, Chacha & Shah

• Responding to a hot-spot patrol requires one police car to be located at the site for a
specified amount of time.
• Only one police car is necessary to respond to the street robbery.
Assumption and Announcement: If no information about traffic is provided, the travel
time from place to place is assumed to be negligible. During the planning session, the team
receives the following announcement: “The traffic officer just contacted us, and said the
First and Second bridges will experience heavy traffic at 8:15 pm. It will take at least 20
minutes for any car to get across a bridge. The travel time from the theater to any hot-spot
is about 20 minutes without using the bridges.” Once this announcement is made, the team
must account for the traffic in their plan.

6. Evaluation
In this section, we evaluate the performance of our plan inference algorithm through initial
proof-of-concept human subject experimentation, and show we are able to infer a human
team’s final plan with 86% accuracy on average, where “accuracy” is defined as a composite
measure of task allocation and plan sequence accuracy measures. We also describe a robot
demonstration in which two people plan and execute a first-response collaborative task with
a PR2 robot.
6.1 Human Team Planning Data
As indicated previously, we designed a web-based collaboration tool modeled after the NICS
system (Di Ciaccio et al., 2011) used by first-response teams, but with a modification that
requires the team to communicate solely via text chat. For the radioactive material leakage
scenario, before announcement, 13 teams of two (a total of 26 participants) were recruited
through Amazon Mechanical Turk and from the greater Boston area. Recruitment was
restricted to those located in the US to increase the probability that participants were
fluent in English. For the radioactive material leakage scenario, after announcement, 21
teams of two (a total of 42 participants) were recruited through Amazon Mechanical Turk
and from the greater Boston area. For the police incident response scenario, 14 teams of
two (total 28 participants) were recruited from the greater Boston area. Participants were
not required to have prior experience or expertise in emergency or disaster planning, and
we note that there may be structural differences in the dialog of expert and novice planners.
We leave this topic for future investigation.
Each team received one of the two fictional rescue scenarios described in Section 5.2, and
was asked to collaboratively plan a rescue mission. Upon completion of the planning session,
each participant was asked to summarize the final agreed-upon plan in the structured form
described previously. An independent analyst reviewed the planning sessions to resolve
discrepancies between the two members’ descriptions when necessary. The first and second
authors, as well as two independent analysts, performed utterance tagging, with each team
planning session tagged and reviewed by two of these four analysts. On average, 36% of
predicates mentioned per data set did not end up in the final plan.

382

A Generative Modeling Approach with Logic-Based Prior

6.2 Algorithm Implementation
The algorithm was implemented in Python, and the VAL PDDL 2.1 plan validator (Howey
et al., 2004) was used. We performed 2,000 Gibbs sampling steps on the data from each
planning session. The initial plan value was set to two to five moves (from MH proposal
distribution) away from the true plan. The initial value for s variable was randomly set to
any timestamp in the initial plan value.
Within one Gibbs sampling step, we performed 30 steps of the Metropolis-Hastings
(MH) algorithm to sample the plan. Every 20 samples were selected to measure accuracy
(median), after a burn-in period of 200 samples.
Results We assessed the quality of the final plan produced by our algorithm in terms of
the accuracy of task allocation among agents (e.g. which medic travels to which room) and
the accuracy of the plan sequence.
Two metrics for task allocation accuracy were evaluated: 1) The percent of inferred plan
predicates appearing in the team’s final plan [% Inferred], and 2) the percent noise rejection
of extraneous predicates that were discussed but do not appear in the team’s final plan [%
Noise Rej].
We evaluated the accuracy of the plan sequence as follows: A pair of predicates is
correctly ordered if it is consistent with the relative ordering in the true final plan. We meaordered pairs of correct predicates
sured the percent accuracy of sequencing [% Seq] by # correctly
.
total # of pairs of correct predicates
Only correctly estimated predicates were compared, as there is no ground truth relation for
predicates not included in the true final plan. We used this relative sequencing measure
because it does not compound sequence errors, as an absolute difference measure would
(e.g. where an error in the ordering of one predicate early in the plan shifts the position of
all subsequent predicates).
Overall “composite” plan accuracy was computed as the arithmetic mean of the task
allocation and plan sequence accuracy measures. This metric summarizes the two relevant
accuracy measures so as to provide a single metric for comparison between conditions. We
evaluated our algorithm under four conditions: 1) perfect PDDL files, 2) PDDL problem file
with missing goals/constants (e.g. delete available agents), 3) PDDL domain file missing
a constraint (e.g. delete precondition), and 4) using an uninformative prior over possible
plans.
The purpose of the second condition, PDDL problem file with missing goals/constants,
was to test the robustness of our approach to incomplete problem information. This PDDL
problem specifiction was intentionally designed to omit information regarding one patient
(pG) and one robot (blueR). It also omitted the following facts about the initial state:
that pG was located at G, the blueR was available to perform inspections, and patient pG
patient was not yet rescued. The goal state omitted that pG patient was to be rescued.
This condition represented a significant degradation of the problem definition file, since the
original planning problem involved only three patients and two robots.
The purpose of the third condition, PDDL domain file with a missing constant, was to
test the robustness of our approach to missing constraints (or rules for successful execution).
It is potentially easy for a person to miss specifying a rule that is often implicitly assumed.
The third condition omitted the following constraint from the domain file: all the rooms are
to be inspected prior to sending any medical crews. This condition represented a significant

383

Kim, Chacha & Shah

degradation of the domain file, since this constraint affected any action involving one of the
medical crew teams.
Results shown in Tables 3-5 are produced by sampling plan and s variables and fixing
β = 5 and ωp = 0.8. The tables report median values for the percent of the inferred
plan predicates appearing in the final plan [% Inferred], noise rejection [% Noise Rej.], and
sequence accuracy [% Seq.]. We show that our algorithm infers final plans with greater than
86% composite accuracy on average. We also show that our approach is relatively robust to
degraded PDDL specifications (i.e., PDDL with missing goals, constants and constraints).
Further discussion of sampling hyper-parameters is found in Section 7.2.
6.3 Concept-of-Operations Robot Demonstration
We illustrate the use of our plan inference algorithm through a robot demonstration in
which two people plan and execute a first-response collaborative task with a PR2 robot.
The participants plan an impending deployment using the web-based collaborative tool we
developed. Once the planning session is complete, the dialogue is tagged manually. The
plan inferred from this data is confirmed with the human planners and provided to the
robot for execution. The registration of predicates to robot actions, and room names to
map locations, is performed offline in advance. While the first responders are on their way
to the accident scene, the PR2 autonomously navigates to each room, performing online
localization, path planning and obstacle avoidance. The robot informs the rest of the team
as it inspects each room and confirms it is safe for human team members to enter. Video
of this demo can be found here: http://tiny.cc/uxhcrw.

7. Discussion
In this section we discuss the results and trends in Tables 3-5. We then discuss how sampling hyper-parameters improves inference accuracy, and provide an interpretation of inferred hyper-parameter values and how they relate to data characteristics. We also provide
additional support for the use of PDDL by analyzing multiple Gibbs sampling runs. Our rationale behind the i.i.d assumption on utterances made in the generative model is explained,
and we show how a simple extension to our model can relax this assumption. Finally, we
provide our rationale for designing the proposal distribution for the sampling algorithm.
7.1 Results
The average accuracy of the inferred final plan improved across all three scenarios with
the use of perfect PDDL as compared to an uninformative prior over possible plans. The
sequence accuracy also consistency improved with the use PDDL, regardless of noise level
or the type of PDDL degradation. The three scenarios exhibited different levels of “noise,”
defined as the percentage of utterances that did not end up in the finally agreed upon
plan. The police incidents response scenario produced substantially higher noise (53%),
as compared to the radioactive material leaking scenario before announcement (38%) and
after announcement (17%). This is possibly because the police incidents scenario included
durative-actions, whereas the others did not. Interestingly, perfect PDDL produced more

384

A Generative Modeling Approach with Logic-Based Prior

PDDL
PDDL with missing goals
and constants
PDDL with missing constraint
No PDDL

Task Allocation
% Inferred % Noise Rej.
61
100

97

Composite
% Acc.
86

% Seq.

100

58

77

78

70
70

100
58

87
66

86
65

Table 3: Radioactive material leakage scenario plan accuracy results, before announcement
(13 teams / 26 subjects). The table reports median values for the percent of the inferred
plan predicates appearing in the final plan [% Inferred], noise rejection [% Noise Rej.], and
sequence accuracy [% Seq.]. Composite % Accuracy is calculated as the average of the
previous three measures.

PDDL
PDDL with missing goals
and constants
PDDL with missing constraint
No PDDL

Task Allocation
% Inferred % Noise Rej.
77
100

83

Composite
% Acc.
87

% Seq.

100

54

97

84

72
100

100
54

90
81

87
78

Table 4: Radioactive material leakage scenario plan accuracy results, after announcement
(21 teams / 42 subjects). The table reports median values for the percent of the inferred
plan predicates appearing in the final plan [% Inferred], noise rejection [% Noise Rej.], and
sequence accuracy [% Seq.]. Composite % Accuracy is calculated as the average of the
previous three measures.

PDDL
PDDL with missing goals
and constants
PDDL with missing constraint
No PDDL

Task Allocation
% Inferred % Noise Rej.
97
89

97

Composite
% Acc.
86

% Seq.

92

86

92

83

97
81

89
95

97
81

85
82

Table 5: Police incidents response scenario plan accuracy results (14 teams / 28 subjects).
The table reports median values for the percent of the inferred plan predicates appearing in
the final plan [% Inferred], noise rejection [% Noise Rej.], and sequence accuracy [% Seq.].
Composite % Accuracy is calculated as the average of the previous three measures.

385

Kim, Chacha & Shah

substantial improvements in sequence accuracy when noise level was higher, in the radioactive material leaking scenario before announcement, and in police incidents scenario.
Accuracy in task allocation, on the other hand, did differ depending on the noise level
and the type of PDDL degradation. The noise rejection ratio was the same or better with
PDDL or PDDL with a missing constraint, as compared to an uninformative prior, for
scenarios with less noise (e.g. the radioactive material leaking scenarios before and after
announcement). However, PDDL did not provide benefit to the noise rejection ratio for the
police incidents scenario where the noise level was more than 50%. However, in this case
PDDL did provide improvements in inferred task allocation.
7.2 Sampling Hyper-Parameters
This section discusses the results of hyper-parameter sampling. First, we show that each
data point (i.e., each team’s conversation) converges to different hyper-parameter values,
then show that those values capture the characteristics of each data point. Second, we show
how learning different sets of hyper-parameters improves different measures of accuracy,
and describe how this is consistent with our interpretation of the hyper-parameters in our
model.
PDDL
PDDL with missing goals and constants
PDDL with missing constraint
No PDDL

PDDL
PDDL with missing goals and constants
PDDL with missing constraint
No PDDL
50%

46%
42%

30%

46%

26%

42%

25%

30%
20%
13%
11%
10%

10%
0%

5%
0%

0%

0%

0%

% improved accuracy

% improved accuracy

40%

20%

17%

15%

12%

18%

17%
12%

10%
5%

5%
0%

3%
-4%

-8% -7%

0%

-5%
-10%

Radioactive before Radioactive after

-10%

Police

Radioactive before Radioactive after

Police

(a) Improvements in noise rejection when sampling (b) Improvements in sequence accuracy when samωp
pling β

Figure 5: Percent improvements in median noise rejection and median sequence accuracy
when sampling hyper-parameters versus setting ωp = 0.8 and β = 5.

7.2.1 Improvements in Sequence Accuracy versus Noise Rejection
The hyper-parameter β represents the noisiness in predicate ordering, while the hyperparameter ωp represents the noisiness in the assignment of predicates. Setting these parameters to a fixed value corresponds to an assumption about the noisiness of the data set. We
can learn these parameters through Gibbs sampling, allowing these values to be adjusted
according to different characteristics of each data set. The details of how we sample hyperparameters are explained in Section 4.3.2. We performed 2,000 Gibbs sampling steps on the

386

A Generative Modeling Approach with Logic-Based Prior

data from each planning session. The initial values of ωp and β were sampled from their
prior, where the parameters were set to the values described in Section 4.1.
We found that when we learned ωp (with β = 5), the noise rejection rate improved
compared with when we fixed ωp = 0.8. In the radioactive material leakage scenario, both
before and after the mid-scenario announcement, the noise rejection ratio was improved by
as much as 41% and 45%, respectively; in the police incident response scenario, we observed
up to a 13% improvement (Figure 5a). Note that in all cases the median noise rejection
ratio was maintained or improved with the sampling of ωp .
Similarly, when we learned β (with ωp = 0.8), sequence accuracies generally improved. In
the radioactive material leakage scenario, before and after the announcement, the sequence
accuracy improved by up to 26% and 16%, respectively; in the police incident response
scenario, we observed up to an 18% improvement (Figure 5b). Note that three cases did
see a degradation in accuracy of up to 4-8%. However in nine out of the twelve cases the
sequence accuracy was maintained or improved with the sampling of β.
Interestingly, most of the samples achieved the highest overall composite accuracy when
only plan and s were learned, and the hyper-parameters were fixed. In particular, we
observed an average 5% (± 3%) decrease in composite accuracy when sampling all four
variables together. One of the possible explanations for this finding is that, due to the
limited amount of data, Gibbs sampling may require many more iterations to converge all
the variables. This result suggests that one may choose the set of hyper-parameters to learn
based on which measure of accuracy is more important to the user.
7.2.2 Interpretation of Inferred Values of Hyper-Parameters
As described in Section 4.1, the ωp parameter models the level of noise in predicates within
the data. In other words, the ωp parameter is designed to model how many suggestions the
team makes during the conversation that are subsequently included in the final plan. If the
noise level is high, a lower-valued ωp will represent the characteristics of the conversation
well, which may allow for better performance. (However, if the noise level is too high, the
inference may still fail.)
To compare the learned value of ωp with the characteristics of the conversation, we need
a way to calculate how noisy the conversation is. The following is one way to manually
estimate the value of ωp : First, count the utterances that contain any predicates. Then,
count the utterances that contain predicates included in the final plan. The ratio between
these two numbers can be interpreted as noisiness in the predicates; the lower the number,
the more the team talked about many possible plans.
We performed this manual calculation for two teams’ trials — Team 3 and 10 — to
compare their values to the learned values. In Team 3’s trial, only 19.4% of the suggestions
made during the conversation were included in the final plan (i.e., almost 80% of suggestions
were not relevant to the final plan). On the other hand, 68% of suggestions made in Team
10’s trial were included in the final plan. Using this interpretation, Team 3’s trial is more
than twice as noisy as Team 10’s trial.
The converged value of ωp is lower in Team 3’s trial than in Team 10’s trial, reflecting
the characteristics of each data set. Figure 6b shows the converged value of ωp for each
team’s trial (sub-sampled, and for a subset of the dataset). The figure presents values of

387

Kim, Chacha & Shah

(a) Examples of β value convergences

(b) Examples of ωp value convergence

Figure 6: Inferred values of hyper-parameters (only showing subset of data set)
ωp at each iteration of the Gibbs sampling step. Note that the samples from Team 3’s trial
converge to 20%, while the samples from Team 10’s trial converge to 40%. The lower value
of ωp represents higher noise level, and matches our intuition.
However, there is no conclusive way to prove that these converged values are the true
values. In theory, the Gibbs sampling algorithm only guarantees convergences to the true

388

A Generative Modeling Approach with Logic-Based Prior

value with an infinite number of iterations. Therefore, we cannot prove that the converged
ωp variables shown in Figure 6 are the true values. In practice, a trace plot, such as that
in Figure 6, is drawn in order to demonstrate convergence to a local optimum. The fact
that the values appear to plateau after a burn-in period provides support of convergence
to a local optimum point. Investigation of this potentially local optimum point suggests
that the ωp value for each data point can be different, and that we can observe some
relationship between the ωp value and the characteristics of the data set. In addition, the
manual calculation of ‘noisiness’ is only one way of interpreting the ‘noisiness’ of the data
set. Therefore, this analysis should be considered as one possible way to gain insight into
the learned values; not a rigorous proof of the relation between the learned value of the
hyper-parameter and the characteristics of the data.
7.3 The Benefit of PDDL
This section provides additional evidence of the benefit of using PDDL by analyzing multiple
runs using the same data and sampling algorithm. As explained in Section 4.3, Gibbs
sampling is an approximate inference algorithm that can produce different results on each
run.
In this section we evaluate runs over a wide range of different settings to show that the
benefit of PDDL applies not just to a particular setting of parameters, but also to different
settings. We analyzed three cases across a range of parameters: 1) learning both plan and
s, 2) learning plan, s and ωp and 3) learning plan, s and β. In the first case, we changed the
value of α to range from 3 to 1,000, ωp from 0.3 to 0.8, and β from 1 to 100. In the second
case, in addition to α and β parameters, we varied the parameters for the prior distribution
of ωp — kωp and θωp ; both ranging from 2 to 70. In the third case, in addition to α and
ωp parameters, we varied the parameters for the prior distribution of β — kβ and θβ ; both
ranging from 0.1 to 50. Values from the all ranges were selected randomly to produce a
total of 613 runs.
Eighty-two percent of the 613 runs showed higher accuracy when PDDL was used than
when PDDL was not used. This suggests that adding the structured prior improves accuracy
over a wide range of parameter settings. Figure 7 presents the ratio of runs that saw benefit
from the use of the PDDL, for each of the three scenarios.
Interestingly, the highest accuracy was not always achieved with perfect PDDL files;
in some cases, the highest accuracy was achieved with imperfect PDDL files (e.g., PDDL
file with missing goals/constraints, as described in Section 6). This observation may be
explained by the possibility that some finally agreed-upon plans 1) are not complete and/or
2) violate constraints (mostly due to participants’ misunderstandings). For example: Prior
to the announcement during the radioactive material leakage scenario, a number of teams
had not finished building complete plans. Therefore, the final plans in these cases may have
been better inferred with incomplete PDDL files (consistent with Table 4). In the police
incident response scenario, however, a number of teams missed the constraint that the hotspot patrolling task is only considered complete if that hot-spot is fully covered from 8:30
p.m. to 9 p.m. A number of teams dispatched police cars only for a portion of that time
window, resulting in invalid plans with the perfect PDDL files (consistent with Table 5)

389

Ratio of runs using PDDL that improved composite accuracy

Kim, Chacha & Shah

1
198/230

0.9
173/216

134/167

0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

Radioactive before

Radioactive after

Police

Figure 7: Ratio of runs that show the benefit of using PDDL

The improvements achieved by adding the structure to the prior using PDDL suggest
that the structural information is beneficial to our inference problem. It would be interesting
to systematically investigate the smallest set of structural information that achieves accuracy
improvements, given a fixed computation budget, in future work.
7.4 The i.i.d Assumption on the Utterance in the Generative Model
Our generative model considers that all utterances are independent and identically distributed samples from the plan variable. In other words, we consider that all utterances
give equal evidence to a plan, regardless of the order in which they appear during the conversation. An alternative would be to have a different weight for each utterance, to take
the ordering into account. In this section, we explain the reasons for the i.i.d. assumption,
and how a simple extension to the current model can relax this assumption.
In the human subject data collected for this work, we did not observe a clear relationship
between the order of an utterance and whether the suggestion is included in the final plan.
For example, a number of teams decided to include parts of a plan that were discussed
at the beginning of the conversation within their final plan, after discussing many other
possibilities. The distribution of the utterances included in the final plan is shown in
Figure 8. In addition, when a team discusses plans under time pressure, the planning
sessions often consist of a small number of succinct communications. For example, the
average number of predicates in all utterances in a planning session is 90, whereas the
average number of predicates in a final plan is 12. A succinct conversation yields less
available data for the inference; therefore, a complicated model may fail to correctly infer
all the latent variables. A time series model, wherein the ordering is taken into account and
the weight of each utterance is a latent variable that needs to be learned from the data, is
an example of such a model.

390

A Generative Modeling Approach with Logic-Based Prior

Figure 8: The distribution of the utterances included in the final plan (normalized)

However, a simple extension of the current model can relax this assumption and incorporate the different importance of each utterance. One way to decide an utterance’s importance is to integrate human cognitive models. Human cognitive architectures (Anderson,
1983) model human cognitive operations, such as the memory model (Anderson, Bothell,
Lebiere, & Matessa, 1998). For example, we can decrease the importance of each utterance
as time proceeds in the planning session by applying varying weights to each utterance.
A simple extension to the current model can be made to incorporate the memory model.
Specifically, the variables ωp and β can be modified to be vectors that represent weight or
activation level of each utterance from the human cognition model (Anderson et al., 1998).
The vector of ωp will have the length of the utterances, ωp = {ωp,1 , ωp,2 , · · · , ωp,T }, where
each ωp,t represents the activation level of each utterance. Similarly, we can extend β to
be a vector, where each βt can represent how noisy each utterance is, weighing it accordingly. However, while these cognitive models are empirically well-verified, Whitehill (2013)
pointed out that there is no structured way to set parameters for these models. In addition,
it is unclear how the human memory model would differ depending on the characteristics
of a given task. For example, the memory model may differ significantly for short, succinct
conversations conducted under time pressure.
7.5 Engineering the Proposal Distribution in the Metropolis-Hastings
Sampling Algorithm
This section describes the impact of different proposal distributions in the MH sampling
step, and our rationale for designing the proposal distribution as described in Section 4.3.1.
There have been numerous studies conducted on selecting a family of candidate-generating
density functions (Metropolis et al., 1953; Hastings, 1970; Geweke, 1989; Gelman & Rubin,

391

Kim, Chacha & Shah

Result with proposal distribution in preliminary work
Result with proposal distribution in current work
100%

Percent composite accuracy

90%
80%
70%
60%
50%
40%
30%
20%
10%
0%

Radioactive before Radioactive after

Police

Figure 9: The impact of different proposal distributions (The highest accuracy with perfect
PDDL files)

1992). However, as pointed out by Chib and Greenberg (1995), there is no structured way
to choose the proposal distribution. It becomes more challenging when the sampled object
is not a simple scalar variable, but a more complicated object, such as the plan variable
(i.e., tuples of sets of grounded predicates) in this work. For such an object, there are larger
spaces of potential proposal distributions to choose from.
However, a good choice for proposal distribution can improve performance. Figure 9
shows the results of the two different proposal distributions used for this work. The preliminary version of this work (Kim et al., 2013) applied the following distribution:
• Select a predicate from the set of possible predicates. If it is in the current plan, move
it to either: 1) the next set of predicates or 2) the previous set, or 3) remove it from
the current plan. If it is not in the current plan, move it to one of the existing sets.
• Select two sets in the current plan and switch their orders.
One difference between the proposal distribution above and the one outlined in Section 4.3.1
is the set of allowed timestamps that a selected predicate can move to at each iteration.
The above proposed distribution allows a predicate to move to any timestamp, whereas the
one in Section 4.3.1 only allows a predicate to move to an adjacent timestamp.
The key insight into proposal distribution in this work is gained by investigating sequences of MH sampling steps and observing when a proposal distribution fails to propose
a good move. In other words, we identify what moves are necessary to move a proposed
value (i.e., proposed new plan) to the true value of the latent variable (i.e., true plan) when
they are close to each other. Often, a predicate is one timestamp off from the true timestamp (i.e., one timestamp after or before), and the proposal distribution as contained in
the preliminary work (Kim et al., 2013) often fails to suggest a better proposed point. This
392

A Generative Modeling Approach with Logic-Based Prior

motivated us to create a proposal distribution enabling more frequent moves between adjacent timestamps than between any two timestamps. As a result, we observed a substantial
improvement to accuracy in all scenarios, as shown in Figure 9.
While this particular proposal distribution cannot be applied to all cases, this insight
suggests that the following approach could be useful when designing a proposal distribution
for non-scalar valued variables: First, a distance metric is defined between the two nonscalar valued variables. In our case, this step included defining the distance between two
tuples of sets of predicates (i.e., plan variables). For example, the distance could be the
average number of missing or extraneous predicates or the number of predicates that have
incorrect timestamps. Second, starting from an initial proposed distribution, the distance
between each sample and the true value is measured. Third, we can filter sample sequences
when the distance is short, and visualize them. The shorter distance indicates moments
when sampling could have almost reached the true value, but did not. Finally, the proposed
distribution is modified to include the move that converts the samples in the third step to
the true value within one or two moves. This process allows for insight into designing the
proposal distribution. We leave further investigation of the systematic approach to future
work.

8. Conclusion and Future Work
In this work, we have formulated the novel problem of performing inference to extract
a finally agreed-upon plan from a human team’s planning conversation. We presented
an algorithm that combines a probabilistic approach with logical plan validation, used to
compute a highly structured prior over possible plans. Our approach infers team plans
without the need for historical data, using only situational information and data from a
single planning session. We do not require the development or addition of a plan library
to infer the plan, and demonstrate our solution is robust to incomplete knowledge of the
planning problem. We demonstrated the benefit of this approach using human team meeting
data collected from large-scale human subject experiments (total 96 subjects) and were able
to infer the human teams’ final plans with 86% accuracy on average.
In the future, we plan to build on this work to design an interactive agent that participates to improve human teams’ planning decisions. Specifically we envision the work
described here as a starting point for utilizing and building on human domain experts’
knowledge, and improving the quality of finally agreed-upon plan through human-machine
interaction.

9. Acknowledgement
This work is sponsored by ASD (R&E) under Air Force Contract FA8721-05-C-0002. Opinions, interpretations, conclusions and recommendations are those of the authors and are not
necessarily endorsed by the United States Government.

393

Kim, Chacha & Shah

Appendix A. The Visualization of Gibbs Sampling Convergence: Trace
Plot
It is known that there is no conclusive way to determine whether the Markov chain of the
Gibbs sampling has reached its stationary, or the desired posterior, distribution (Cowles
& Carlin, 1996). Many available diagnostic tools are designed to test for necessary but
insufficient conditions for convergence, such as work done by Gelman and Rubin (1992),
Geweke (1991), Heidelberger and Welch (1981) and Raftery and Lewis (1995), to mention
a few. In this work we utilize a much simpler yet still informative approach, which is to
visually check whether convergence has been reached using the trace plot.
A trace plot is simply a scatter plot of the statistics of successive parameter estimates
(e.g., the estimated values) with respect to the iteration steps. These statistics can be
means, variances or covariance. A trace plot is most informative when the scalar variables
are plotted. Figure 10 shows examples trace plots for the β and ωp variables.

References
Albrecht, D. W., Zuckerman, I., Nicholson, A. E., & Bud, A. (1997). Towards a Bayesian
model for keyhole plan recognition in large domains. In Proceedings of the Sixth
International Conference on User Modeling, pp. 365–376. Springer-Verlag.
Anderson, J. R. (1983). A spreading activation theory of memory. Journal of Verbal Learning
and Verbal Behavior, 22 (3), 261–295.
Anderson, J. R., Bothell, D., Lebiere, C., & Matessa, M. (1998). An integrated theory of
list memory. Journal of Memory and Language, 38 (4), 341–380.
Andrieu, C., De Freitas, N., Doucet, A., & Jordan, M. I. (2003). An introduction to mcmc
for machine learning. Machine learning, 50 (1-2), 5–43.
Barnes, M., Chen, J., Jentsch, F., & Redden, E. (2011). Designing effective soldier-robot
teams in complex environments: training, interfaces, and individual differences. EPCE,
484–493.
Bauer, M., Biundo, S., Dengler, D., Koehler, J., & Paul, G. (2011). PHI: a logic-based tool
for intelligent help systems..
Blei, D. M., Ng, A. Y., & Jordan, M. I. (2003). Latent dirichlet allocation. Journal of
Machine Learning Research, 3, 993–1022.
Brown, J. S., & Burton, R. R. (1978). Diagnostic models for procedural bugs in basic
mathematical skills. Cognitive Science, 2 (2), 155–192.
Carberry, S. (1990). Plan recognition in natural language dialogue. The MIT Press.
Casper, J., & Murphy, R. (2003). Human-robot interactions during the robot-assisted urban
search and rescue response at the World Trade Center. IEEE SMCS, 33 (3), 367–385.
Casper, J., & Murphy, R. (2002). Workflow study on human-robot interaction in USAR.
IEEE ICRA, 2, 1997–2003.
Charniak, E., & Goldman, R. P. (1993). A Bayesian model of plan recognition. Artificial
Intelligence, 64 (1), 53–79.
394

A Generative Modeling Approach with Logic-Based Prior

(a) Examples of β value convergences

(b) Examples of ωp value convergence

Figure 10: Trace Plots (only showing a subset of the data set)
Chib, S., & Greenberg, E. (1995). Understanding the Metropolis-Hastings algorithm. The
American Statistician, 49 (4), 327–335.
Coles, A., Fox, M., Halsey, K., Long, D., & Smith, A. (2009). Managing concurrency in
temporal planning using planner-scheduler interaction. Artificial Intelligence, 173 (1),
1–44.
Cowles, M. K., & Carlin, B. P. (1996). Markov chain Monte Carlo convergence diagnostics:
a comparative review. Journal of the American Statistical Association, 91 (434), 883–
904.
Cummings, M. L., Brzezinski, A. S., & Lee, J. D. (2007). Operator performance and intelligent aiding in unmanned aerial vehicle scheduling. IEEE Intelligent Systems, 22 (2),
52–59.
395

Kim, Chacha & Shah

Di Ciaccio, R., Pullen, J., & Breimyer, P. (2011). Enabling distributed command and
control with standards-based geospatial collaboration. IEEE International Conference
on HST.
FEMA (2014). Federal emergency management agency.. [Online; accessed 3-December2014].
Fikes, R. E., & Nilsson, N. J. (1972). Strips: A new approach to the application of theorem
proving to problem solving. Artificial intelligence, 2 (3), 189–208.
Gal, Y., Reddy, S., Shieber, S. M., Rubin, A., & Grosz, B. J. (2012). Plan recognition in
exploratory domains. Artificial Intelligence, 176 (1), 2270–2290.
Geib, C. W., & Goldman, R. P. (2009). A probabilistic plan recognition algorithm based
on plan tree grammars. Artificial Intelligence, 173 (11), 1101–1132.
Geib, C. W., Maraist, J., & Goldman, R. P. (2008). A new probabilistic plan recognition
algorithm based on string rewriting.. In ICAPS, pp. 91–98.
Gelman, A., & Rubin, D. B. (1992). Inference from iterative simulation using multiple
sequences. Statistical Science, 457–472.
Getoor, L., & Mihalkova, L. (2011). Learning statistical models from relational data. International Conference on Management of Data, 1195–1198.
Geweke, J. (1989). Bayesian inference in econometric models using Monte Carlo integration.
Econometrica: Journal of the Econometric Society, 1317–1339.
Geweke, J. (1991). Evaluating the accuracy of sampling-based approaches to the calculation
of posterior moments. Federal Reserve Bank of Minneapolis, Research Department.
Goodrich, M. A., Morse, B. S., Engh, C., Cooper, J. L., & Adams, J. A. (2009). Towards
using UAVs in wilderness search and rescue: Lessons from field trials. Interaction
Studies, Special Issue on Robots in the Wild: Exploring Human-Robot Interaction in
Naturalistic Environments, 10 (3), 453–478.
Grosz, B. J., & Sidner, C. L. (1990). Plans for discourse. In Cohen, P. R., Morgan,
J., & Pollack, M. E. (Eds.), Intentions in Communication, pp. 417–444. MIT Press,
Cambridge, MA.
Hastings, W. K. (1970). Monte Carlo sampling methods using Markov chains and their
applications. Biometrika, 57 (1), 97–109.
Heidelberger, P., & Welch, P. D. (1981). A spectral method for confidence interval generation
and run length control in simulations. Communications of the ACM, 24 (4), 233–245.
Holovaty, A., & Kaplan-Moss, J. (2009). The definitive guide to Django: Web development
done right. Apress.
Horvitz, E., Breese, J., Heckerman, D., Hovel, D., & Rommelse, K. (1998). The Lumiere
project: Bayesian user modeling for inferring the goals and needs of software users.
Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence,
256–265.
Howey, R., Long, D., & Fox, M. (2004). Val: Automatic plan validation, continuous effects
and mixed initiative planning using PDDL. IEEE ICTAI, 294–301.
396

A Generative Modeling Approach with Logic-Based Prior

Jones, H., Rock, S., Burns, D., & Morris, S. (2002). Autonomous robots in SWAT applications: Research, design, and operations challenges. AUVSI.
Jurafsky, D., & Martin, J. H. (2000). Speech and Language Processing: An Introduction to
Natural Language Processing, Computational Linguistics, and Speech Recognition (1st
edition). Prentice Hall PTR, Upper Saddle River, NJ, USA.
Kautz, H. A., Pelavin, R. N., Tenenberg, J. D., & Kaufmann, M. (1991). A formal theory
of plan recognition and its implementation. Reasoning about Plans, 69–125.
Kautz, H. A. (1987). A formal theory of plan recognition. Ph.D. thesis, Bell Laboratories.
Kim, B., Chacha, C. M., & Shah, J. (2013). Inferring robot task plans from human team
meetings: A generative modeling approach with logic-based prior. AAAI.
Kim, J., & Shah, J. A. (2014). Automatic prediction of consistency among team members’ understanding of group decisions in meetings. In Systems, Man and Cybernetics
(SMC), 2014 IEEE International Conference on, pp. 3702–3708. IEEE.
Koomen, P., Punyakanok, V., Roth, D., & Yih, W. (2005). Generalized inference with
multiple semantic role labeling systems. CoNLL, 181–184.
Kruijff, G., Janıcek, M., & Lison, P. (2010). Continual processing of situated dialogue in
human-robot collaborative activities. In IEEE Ro-Man.
Larochelle, B., Kruijff, G., Smets, N., Mioch, T., & Groenewegen, P. (2011). Establishing
human situation awareness using a multi-modal operator control unit in an urban
search & rescue human-robot team. IEEE Ro-Man, 229–234.
Lochbaum, K. E. (1998). A collaborative planning model of intentional structure. Computational Linguistics, 24 (4), 525–572.
Mayfield, J. (1992). Controlling inference in plan recognition. User Modeling and UserAdapted Interaction, 2 (1-2), 55–82.
McDermott, D., Ghallab, M., Howe, A., Knoblock, C., Ram, A., Veloso, M., Weld, D., &
Wilkins, D. (1998). PDDL-the planning domain definition language..
Metropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H., & Teller, E. (1953).
Equation of state calculations by fast computing machines. The Journal of Chemical
Physics, 21, 1087.
Micire, M. (2002). Analysis of robotic platforms used at the World Trade Center disaster.
Ph.D. thesis, MS thesis, Department Computer Science Engineering, Univ. South
Florida.
Murphy, R. (2004). Human-robot interaction in rescue robotics. IEEE SMCS, 34 (2), 138–
153.
Neal, R. M. (2003). Slice sampling. Annals of Statistics, 705–741.
Nguyen, T. A., Kambhampati, S., & Do, M. (2013). Synthesizing robust plans under incomplete domain models. Advances in Neural Information Processing Systems, 2472–2480.
Palmer, M., Gildea, D., & Xue, N. (2010). Semantic role labeling. Synthesis Lectures on
Human Language Technologies, 3 (1), 1–103.

397

Kim, Chacha & Shah

Pednault, E. P. D. (1987). Formulating Multi-Agent Dynamic-World Problems in the Classical Planning Framework. In Reasoning About Actions and Plans: Proceedings of the
1986 Workshop. Morgan Kaufmann Publishers.
Poon, H., & Domingos, P. (2006). Sound and efficient inference with probabilistic and
deterministic dependencies. AAAI, 21 (1), 458.
Poon, H., & Domingos, P. (2009). Unsupervised semantic parsing. EMNLP.
Pradhan, S., Ward, W., Hacioglu, K., Martin, J., & Jurafsky, D. (2004). Shallow semantic
parsing using support vector machines. NAACL-HLT, 233.
Pynadath, D. V., & Wellman, M. P. (2000). Probabilistic state-dependent grammars for
plan recognition. Proceedings of the Sixteenth conference on Uncertainty in Artificial
Intelligence, 507–514.
Raedt, L. (2008). Probabilistic logic learning. Logical and Relational Learning, 223–288.
Raftery, A. E., & Lewis, S. M. (1995). The number of iterations, convergence diagnostics
and generic metropolis algorithms. In Practical Markov Chain Monte Carlo, 115–130.
Ramırez, M., & Geffner, H. (2009). Plan recognition as planning. Proceedings of the 21st
international joint conference on Artificial Intelligence, 1778–1783.
Richardson, M., & Domingos, P. (2006). Markov logic networks. Machine learning, 62 (1),
107–136.
Ryall, K., Marks, J., & Shieber, S. (1997). An interactive constraint-based system for
drawing graphs. Proceedings of the 10th Annual ACM Symposium on User Interface
Software and Technology, 97–104.
Sadilek, A., & Kautz, H. A. (2010). Recognizing multi-agent activities from GPS data.
AAAI.
Singla, P., & Domingos, P. (2007). Markov logic in infinite domains. UAI, 368–375.
Tellex, S., Kollar, T., Dickerson, S., Walter, M., Banerjee, A., Teller, S., & Roy, N. (2011).
Understanding natural language commands for robotic navigation and mobile manipulation. AAAI.
Weida, R., & Litman, D. (1992). Terminological Reasoning with Constraint Networks and
an Application to Plan Recognition.
Whitehill, J. (2013). Understanding ACT-R - an outsider’s perspective. CoRR, 1306.0125.
Zhuo, H. H., Yang, Q., & Kambhampati, S. (2012). Action-model based multi-agent plan
recognition. Advances in Neural Information Processing Systems 25, 377–385.

398

Journal of Artificial Intelligence Research 52 (2015) 203-234

Submitted 8/14; published 1/15

On the Subexponential-Time Complexity of CSP
Ronald de Haan

DEHAAN @ KR . TUWIEN . AC . AT

Vienna University of Technology
Vienna, Austria

Iyad Kanj

IKANJ @ CS . DEPAUL . EDU

School of Computing, DePaul University
Chicago, USA

Stefan Szeider

STEFAN @ SZEIDER . NET

Vienna University of Technology
Vienna, Austria

Abstract
Not all NP-complete problems share the same practical hardness with respect to exact computation.
Whereas some NP-complete problems are amenable to efficient computational methods, others are
yet to show any such sign. It becomes a major challenge to develop a theoretical framework that is
more fine-grained than the theory of NP-completeness, and that can explain the distinction between
the exact complexities of various NP-complete problems. This distinction is highly relevant for
constraint satisfaction problems under natural restrictions, where various shades of hardness can be
observed in practice.
Acknowledging the NP-hardness of such problems, one has to look beyond polynomial time
computation. The theory of subexponential-time complexity provides such a framework, and has
been enjoying increasing popularity in complexity theory. An instance of the constraint satisfaction
problem with n variables over a domain of d values can be solved by brute-force in dn steps (omitting
a polynomial factor). In this paper we study the existence of subexponential-time algorithms, that
is, algorithms running in do(n) steps, for various natural restrictions of the constraint satisfaction
problem. We consider both the constraint satisfaction problem in which all the constraints are given
extensionally as tables, and that in which all the constraints are given intensionally in the form of
global constraints. We provide tight characterizations of the subexponential-time complexity of the
aforementioned problems with respect to several natural structural parameters, which allows us to
draw a detailed landscape of the subexponential-time complexity of the constraint satisfaction problem. Our analysis provides fundamental results indicating whether and when one can significantly
improve on the brute-force search approach for solving the constraint satisfaction problem.

1. Introduction
It has been observed in various practical contexts that some NP-hard problems are accessible to
efficient exact computational methods, whereas for others such methods are futile. It is a central
challenge for theoreticians to develop a framework, that is more fine-grained than the theory of
NP-completeness, and that can explain the distinction between the exact complexities of NP-hard
problems. Subexponential-time complexity is a framework of complexity theory that provides such
a distinction (Lokshtanov, Marx, & Saurabh, 2011). It is based on the observation that for some
NP-complete problems, one can improve the exponent in the exponential term of the upper bound
c
2015
AI Access Foundation. All rights reserved.

DE

H AAN , K ANJ , & S ZEIDER

on their running time indefinitely—such problems admit subexponential-time algorithms—whereas
for others this is apparently not possible under commonly-believed hypotheses in complexity theory.
In particular, subexponential-time algorithms were developed for many graph problems, including
I NDEPENDENT S ET and D OMINATING S ET, under natural structural restrictions; e.g., see the work
of Alber, Fernau, and Niedermeier (2004), Chen, Kanj, Perkovic, Sedgwick, and Xia (2007) and
Demaine, Fomin, Hajiaghayi, and Thilikos (2005). The benchmark problem for subexponential-time
computation is the satisfiability problem for CNF formulas, where each clause contains at most three
literals, denoted 3-CNF-S AT. The Exponential Time Hypothesis (ETH), proposed by Impagliazzo
and Paturi (2001), states that 3-CNF-S AT with n variables is not decidable in subexponential time,
i.e., not decidable in time 2o(n) (omitting polynomial factors).
The Constraint Satisfaction Problem (CSP) provides a general and uniform framework for the
representation and solution of hard combinatorial problems that arise in various areas of Artificial
Intelligence and Computer Science (Rossi, van Beek, & Walsh, 2006). For instance, in database
theory, CSP is equivalent to the evaluation problem of conjunctive queries on relational databases
(Gottlob, Leone, & Scarcello, 2002). It is well known that CSP is NP-hard, as it entails fundamental
NP-hard problems such as 3-C OLORABILITY and 3-CNF-S AT. Hence, we cannot hope for a
polynomial-time algorithm for CSP. On the other hand, CSP can obviously be solved in exponential
time: by simply trying all possible instantiations of the variables, we can solve a CSP instance
consisting of n variables that range over a domain of d values in time dn (omitting a polynomial
factor in the input size). Significant work has been concerned with improving this trivial upper bound
for various restrictions of CSP (Beigel & Eppstein, 2005; Feder & Motwani, 2002; Grandoni &
Italiano, 2006; Moser & Scheder, 2011; Schöning, 1999). For instance, Razgon (2006) showed that
binary CSP with domain size d can be solved in time (d − 1)n by a forward-checking algorithm
employing a fail-first variable ordering heuristic; although there are faster algorithms known, this
result indicates that the exponential running time for CSP can be improved by using heuristic methods
that were designed for solving real-world CSP instances in practice. All these improvements over the
trivial brute-force search give exponential running times in which the exponent is linear in n.
The aim of this paper is to investigate the theoretical limits of such improvements. More precisely,
we explore whether the exponential factor dn can be reduced to a subexponential factor do(n) or
not, considering various natural NP-hard restrictions of classical CSP in which all the constraints
are given extensionally in the form of tables, and of CSP in which the constraints are specified
intensionally using global constraints. For CSP with global constraints, we consider CSP in which
the global constraints are all either
• AllDifferent constraints (denoted CSP6= ),
• NValue constraints (denoted CSP= ),
• AtLeastNValue constraints (denoted CSP≥ ),
• AtMostNValue constraints (denoted CSP≤ ), or
• cTable constraints, i.e., constraints that are specified by tables with compressed tuples (denoted
CSPc ).
This study of CSP with global constraints is highly relevant as it is central for the modeling and
the solving of real-world problems to use various global constraints that come along with efficient
204

O N THE S UBEXPONENTIAL -T IME C OMPLEXITY OF CSP

propagation and filtering techniques (Régin, 2011; Van Hoeve & Katriel, 2006). Therefore, the
study of the existence of subexponential-time algorithms for these generic problems under various
restrictions is of prime interest.
In this paper, we obtain lower and upper bounds results, and in most cases draw a detailed
complexity landscape of CSP with extensionally represented constraints and CSP with global
constraints with respect to subexponential-time solvability. Our lower bounds are subject to the
Exponential Time Hypothesis (ETH), even though some of our results are derived under “weaker”
complexity-theoretic hypotheses (Proposition 2, Proposition 3, and Proposition 10). The structural
parameters in a CSP instance that we focus on (when relevant) are: the (instance) size, the domain
size, the number of constraints, the arity (i.e., maximum size of a constraint scope), the maximum
degree (i.e., the maximum number of occurrences of a variable), and the treewidth of the primal
or incidence graph. We highlight below some of the results that we obtain. As it turns out, for
almost all restrictions under consideration, both CSP and its generalization, CSP with the (global)
compressed table constraints (CSPc ), exhibit the same behavior with respect to their subexponentialtime solvability. So unless explicitly indicated in the results below, all results about CSP (positive
and negative) mentioned below hold as well for CSPc .
It is easy to see that CSP with bounded domain size and bounded arity has a subexponential-time
algorithm if and only if the ETH fails. Our first result provides evidence that when we drop the
bound on the domain size or the bound on the arity, the problem becomes “harder”; we refer to the
discussion preceding Proposition 2 (n below is the number of variables in the instance):
1. If B OOLEAN CSP is solvable in nonuniform subexponential time then so is (unrestricted) CNFS AT. For B OOLEAN CSPc , we show that if B OOLEAN CSPc is solvable in subexponential
time then the parameterized complexity hierarchy collapses at the second level, a consequence
that implies that CNF-S AT is solvable in subexponential time.
2. If 2-CSP (all constraints have arity 2) is solvable in subexponential time then C LIQUE is
solvable in time N o(k) (N is the number of vertices and k is the clique-size).
As it turns out, the number of tuples plays an important role in characterizing the subexponential-time
complexity of CSP. We show the following tight result:
3. CSP is solvable in subexponential time for instances in which the number of tuples is o(n),
and unless the ETH fails, is not solvable in subexponential time if the number of tuples in the
instances is Ω(n).
For B OOLEAN CSP of linear size we can even derive an equivalence to the ETH:
4. B OOLEAN CSP for instances of size Ω(n) is solvable in subexponential time if and only if the
ETH fails.
Results 3 and 4 also hold if we consider the total number of tuples in the constraint relations instead
of the input size.
5. CSP is solvable in subexponential time for instances whose primal treewidth is o(n), but is
not solvable in subexponential time for instances whose primal treewidth is Ω(n) unless the
ETH fails.
205

DE

H AAN , K ANJ , & S ZEIDER

6. CSP is solvable in polynomial time for instances whose incidence treewidth is O(1), but is
not solvable in subexponential time for instances whose incidence treewidth is ω(1) unless the
ETH fails.
For CSP6= we show the following results:
7. CSP6= is solvable in subexponential time for instances whose domain size is lower bounded by
a function that is ω(1), but is not solvable in subexponential time for any constant domain size
that is at least 3 unless the ETH fails.
We note that the aforementioned result may sound strange because it implies that the problem is
“easier” for larger domain size. This can be explained by the fact that when the domain size gets
large, the allowable upper bound on the subexponential time for solving the problem (i.e., d(n)o(n) )
gets larger as well.
8. CSP6= is solvable in subexponential time for instances whose primal treewidth is o(n), but is
not solvable in subexponential time for instances whose primal treewidth is Ω(n) unless the
ETH fails.
9. CSP6= is solvable in subexponential time for instances whose incidence treewidth is o(n), but
is not solvable in subexponential time for instances whose primal treewidth is Ω(n) unless the
ETH fails. Contrast this result with the result in (6) above.
For CSP= , CSP≥ , and CSP≤ , we show the following:
10. CSP≥ is solvable in subexponential time for instances whose number of constraints is constant
and whose domain size is lower bounded by a function that is ω(1), but is not solvable in
subexponential time if the number of constraints is linear and the domain size is constant
unless the ETH fails.
11. CSP= and CSP≤ are not solvable in subexponential time for instances whose domain size is
constant and whose number of constraints is Ω(n) unless the ETH fails.
12. CSP= , CSP≥ , and CSP≤ are solvable in subexponential time for instances whose primal
treewidth is o(n), but are not solvable in subexponential time for instances whose primal
treewidth is Ω(n) unless the ETH fails.
The table below provides a map that, for each of the structural parameters considered in the
paper, lists the results in the paper pertaining to that structural parameter. The structural parameters
that we consider for an instance of CSP, or CSP with global constraints, or both are: The size (size),
the maximum size of a constraint scope (arity), the cardinality of the domain (dom), the number of
tuples (tuples), the number of constraints (cons), the treewidth of the incidence graph (tw∗ ), the
treewidth of the primal graph (tw), and the maximum number of occurrences of a variable (deg).
206

O N THE S UBEXPONENTIAL -T IME C OMPLEXITY OF CSP

Parameter

Results

size
arity
dom
tuples
cons
tw∗
tw
deg

Theorem 3
Propositions 1, 2, 12
Theorems 1, 2, 3, 7; Propositions 1, 3, 12, 14, 17; Corollaries 1, 3
Theorem 2
Theorems 4, 6, 7; Propositions 14, 17; Corollaries 2, 3
Theorem 5; Propositions 16, 19
Theorem 5; Propositions 15, 18
Proposition 11

The results in this paper shed some light on which instances of the aforementioned variants
of CSP (with and without global constraints) may be feasible with respect to exact computation.
Moreover, some of the results derived in the paper provide strong theoretical evidence that some of
the natural restrictions of CSP may be “harder than” k-CNF-S AT—for which a subexponential-time
algorithm would lead to the failure of the ETH. Hence, our results provide a new point of view of the
relationship between CNF-S AT and CSP, an important topic of recent AI research (Jeavons & Petke,
2012; Dimopoulos & Stergiou, 2006; Benhamou, Paris, & Siegel, 2012; Bennaceur, 2004).
We close this section by mentioning some further work on the subexponential-time complexity
of CSP and problems in AI. Already the pioneering work on the ETH (Impagliazzo & Paturi, 2001;
Impagliazzo, Paturi, & Zane, 2001) considered the k-C OLORABILITY problem, which constitutes an
important special case of 2-CSP over a fixed domain of size k. There are several results on 2-CSP
with bounds on tw, the treewidth of the primal graph (see Section 3.3 for definitions). Lokshtanov
et al. (2011) showed the following lower bound, using a result about the L IST C OLORING problem
(Fellows et al., 2011a): 2-CSP cannot be solved in time f (tw)no(tw) unless the ETH fails. Marx
(2010) showed that if there is a recursively enumerable class G of graphs with unbounded treewidth
and a function f such that 2-CSP can be solved in time f (G)no(tw/ log tw) for instances whose primal
graph is in G, then the ETH fails. Jonsson, Lagerkvist, and Nordh (2013) investigated B OOLEAN
CSP over finite constraint languages and identify the “easiest” Boolean constraint language for
which CSP is still NP-hard, and show that already this problem has no subexponential-time algorithm
unless the ETH fails. Traxler (2008) studied the subexponential-time complexity of CSP where
the constraints are represented by listing the forbidden tuples; this is in contrast to the standard
representation that we use, where the allowed tuples are given, and which naturally captures database
problems (Gottlob et al., 2002; Grohe, 2006; Papadimitriou & Yannakakis, 1999). This setting
can be considered as a generalization of CNF-S AT; a single clause gives rise to a constraint with
exactly one forbidden tuple. If the arity is bounded by a constant, then it is insignificant whether the
constraints are represented by forbidden or allowed tuples, as one can translate between these two
representations in polynomial time. Finally we would like to point out some recent use of the ETH
for the complexity analysis of problems that are highly relevant for AI like Planning (Bäckström &
Jonsson, 2011), Probabilistic Inference (Kwisthout, Bodlaender, & van der Gaag, 2010), and Text
Analysis (Ge, 2013).
Parts of this paper have been published in preliminary form in the proceedings of AAAI’13 and
CP’14 (Kanj & Szeider, 2013; De Haan, Kanj, & Szeider, 2014).
207

DE

H AAN , K ANJ , & S ZEIDER

2. Preliminaries
In this section we introduce the terminologies and background material needed in the paper.
2.1 Constraint Satisfiability and CNF-Satisfiability
An instance I of the C ONSTRAINT S ATISFACTION P ROBLEM (or CSP, for short) is a triple (V, D, C),
where V is a finite set of variables, D is a finite set of domain values, and C is a finite set of constraints.
Each constraint in C is a pair (S, R), where S, the constraint scope, is a non-empty sequence of
distinct variables of V , and R, the constraint relation, is a relation over D whose arity matches
the length of S; a relation
Pis considered as a set of tuples. Therefore, the
P size of a CSP instance
I = (V, D, C) is the sum (S,R)∈C |S| · |R|; the total number of tuples is (S,R)∈C |R|. We assume,
without loss of generality, that every variable occurs in at least one constraint scope and every domain
element occurs in at least one constraint relation. Consequently, the size of an instance I is at least
as large as the number of variables in I. We write var (C) for the set of variables that occur in the
scope of constraint C.
An assignment or instantiation is a mapping from the set V of variables to the domain D. An
assignment τ satisfies a constraint C = ((x1 , . . . , xn ), R) if (τ (x1 ), . . . , τ (xn )) ∈ R, and τ satisfies
the CSP instance if it satisfies all its constraints. An instance I is consistent or satisfiable if it is
satisfied by some assignment. CSP is the problem of deciding whether a given instance of CSP is
consistent. B OOLEAN CSP denotes CSP with the Boolean domain {0, 1}. By r-CSP we denote the
restriction of CSP to instances in which the arity of each constraint is at most r.
The primal graph of a CSP instance I has as vertices the variables of I, and two variables are
joined by an edge if and only if the variables occur together in some constraint of I. The incidence
graph of a CSP instance I is a bipartite graph, one side of which consists of the variables in I and
the other side consists of the constraints in I; a variable and a constraint are joined by an edge if the
variable occurs in the constraint.
A tree decomposition of a graph G = (V, E) is a pair (T, χ) consisting of a tree T and a mapping
χ that assigns to each node t of T a subset χ(t) ⊆ V such that the following conditions are satisfied:
(i) for every edge {u, v} ∈ E there is a node t of T such that u, v ∈ χ(t); and (ii) for any three nodes
t1 , t2 , t3 of T we have χ(t2 ) ⊇ χ(t1 ) ∩ χ(t3 ) if t2 lies on a path between t1 and t3 . The width of
(T, χ) is the size of a largest set χ(t) minus 1. The treewidth of G is the smallest width over all its
tree decompositions. Bounding the treewidth is a classical method for restricting the structure of
CSP instances. The method dates back to Freuder (1982). The treewidth parameter can be applied to
CSP in terms of its primal graphs or incidence graphs giving rise to the primal treewidth (also called
induced width (Dechter, 2003)) and incidence treewidth, respectively (Samer & Szeider, 2010), of
CSP instances.
For an instance I = (V, D, C) of CSP we define the following basic parameters.
• vars: the number |V | of variables, usually denoted by n.
P
• size: the size of the CSP instance defined as (S,R)∈C |S| · |R|.
• dom: the number |D| of values; that is, the union of all the values that the variables can
assume.
• cons: the number |C| of constraints.
208

O N THE S UBEXPONENTIAL -T IME C OMPLEXITY OF CSP

• arity: the maximum size of a constraint scope.
• deg: the maximum number of occurrences of a variable.
• tw: the treewidth of the primal graph of I.
• tw∗ : the treewidth of the incidence graph of I.
A propositional formula F over a set of variable {x1 , . . . , xn } is in the conjunctive normal form
(CNF) if it is the conjunction of a set of clauses {C1 , . . . , Cm }, where each clause Ci , i = 1, . . . , m,
is the disjunction of literals (i.e., variables or negations of variables). We say that a propositional
formula F is satisfiable if there exists a truth assignment τ to the variables in F that assigns at least
one literal in each clause of F the value 1 (TRUE); we also say in this case that τ satisfies F . The
CNF-S ATISFIABILITY problem, CNF-S AT for short, is given a formula F in the CNF form, decide
whether or not F is satisfiable. The width of a clause in a CNF formula F is the number of literals
in the clause. The k-CNF-S AT problem, where k ≥ 2, is the restriction of the CNF-S AT problem
to instances in which the width of each clause is at most k. It is well known that the k-CNF-S AT
problem for k ≥ 3 is NP-complete (Garey & Johnson, 1979), whereas the 2-CNF-S AT problem is
solvable in polynomial time (Papadimitriou, 1994).
2.2 Global Constraints
It is often preferred to represent a constraint more succinctly than by listing all the tuples of the
constraint relation. Such an intensionally represented constraint is called a global constraint (Régin,
2011; Van Hoeve & Katriel, 2006). The Global Constraints Catalogue (Beldiceanu, Carlsson, &
Rampon, 2006) lists several hundred of global constraints. In this paper we focus on the following
global constraints.
• The AllDifferent global constraint is probably the best-known, most influential, and most
studied global constraint in constraint programming (Van Hoeve & Katriel, 2006). It admits
efficient matching based filtering algorithms (Régin, 1994). An AllDifferent constraint over a
set S of variables is satisfied if each variable in S is assigned a different value.
• The global constraints NValue (Pachet & Roy, 1999), AtLeastNValue (Régin, 1995), and AtMostNValue (Bessiere, Hebrard, Hnich, Kiziltan, & Walsh, 2006) are widely used in constraint
programming (Beldiceanu et al., 2006). Each such constraint C is associated with an integer
nC ∈ N; here we consider nC as a given integer, not as the value of a variable of the CSP instance. The NValue constraint C over a set SC of variables is satisfied if the number of distinct
values assigned to the variables in SC is exactly nC . The AtLeastNValue and AtMostNValue
constraints are satisfied if the number of distinct values is ≤ nC or ≥ nC , respectively. The
special case of an NValue or AtLeastNValue constraint C where nC equals the arity of C is
equivalent to an AllDifferent constraint.
• The global constraint cTable is a table constraint with compressed tuples. This global constraint
admits a potentially exponential reduction in the space compared to an extensional table
constraint and can be propagated using a variant of the GAC-schema algorithm (Katsirelos
& Walsh, 2007). cTable constraints have also been studied under the name generalized DNF
constraints (Chen & Grohe, 2010). A cTable constraint is a pair (S, U ) where S = (v1 , . . . , vr )
209

DE

H AAN , K ANJ , & S ZEIDER

is a non-empty sequence of distinct variables, and U is a set of compressed tuples, which are
sequences of the form (V1 , . . . , Vr ), where Vi ⊆ D(vi ), 1 ≤ i ≤ r. One compressed tuple
(V1 , . . . , Vr ) represents all the tuples (d1 , . . . , dr ) with di ∈ Vi . Thus, by “decompression”
one can compute from (S, U ) a (unique) equivalent table constraint (S, R) where R contains
all the tuples that are represented by the compressed tuples in U .
CSP where all constraints are AllDifferent constraints is denoted CSP6= . This variant of CSP
was studied by Fellows, Friedrich, Hermelin, Narodytska, and Rosamond (2011b) who called it
MAD-CSP (multiple all different CSP). CSP where all constraints are NValue, AtLeastNValue,
or AtMostNValue constraints, is denoted CSP= , CSP≥ , and CSP≤ , respectively. CSP where all
constraints are cTable constraints is denoted CSPc .
We note that all CSP6= , CSP= , CSP≥ , CSP≤ , CSPc , are NP-complete. In fact, CSP6= (and therefore the more general CSP≥ ) is even NP-hard for instances consisting of only two constraints (Kutz,
Elbassioni, Katriel, & Mahajan, 2008), and CSP≤ and CSP= are even NP-hard for instances consisting of a single constraint (Bessiere et al., 2007). CSPc is clearly NP-hard as it contains classical CSP
(with table constraints) as a special case. Hence all the considered problems admit the representation
of NP-hard combinatorial problems.
Consider a CSP instance that models some real-world problem and uses, among others, some of
the global constraints considered above, say the AllDifferent constraint. Then, we can combine all the
AllDifferent constraints in the instance into a new global constraint, a multi-AllDifferent constraint.
Filtering this combined constraint is polynomial time equivalent to solving one instance of CSP6= .
Such a combination of several global constraints into a new one has been considered for several
different global constraints (see, e.g., Hnich et al., 2004; Régin & Rueher, 2000).
Guarantees and limits for polynomial-time preprocessing for single NValue, AtLeastNValue, and
AtMostNValue constraints have been given by Gaspers and Szeider (2014).
The Boolean versions of the above global constraints problems, and the parameters vars, dom,
∗
cons, arity, deg, tw,
as for CSP. The size of an instance I = (V, D, C) of
P and tw , are defined
6=
CSP is defined as C∈C |SC |. For CSP= , CSP≥ , and CSP≤ , the size of an instance I = (V, D, C)
is
Pdefined as
| + log (nC )). For an instance I = (V, D, C) of CSPc , the size of I is defined as
PC∈C (|SCP
c
(S,U )∈C
(V1 ,...,Vr )∈U (|V1 | + · · · + |Vr |). Note that the definition of the instance size for CSP
encompasses that for CSP.
2.3 Subexponential Time
A proper complexity function in complexity theory stands for any nondecreasing function f that is
computable in O(n + f (n)) time and O(f (n)) space, where n is the length of the input (see Papadimitriou, 1994). The time complexity functions used in this paper are assumed to be proper complexity
function. The o(·) notation used denotes the oeff (·) notation (Flum & Grohe, 2006). More formally,
for any two proper complexity functions f, g : N → N, by writing f (n) = o(g(n)) we mean that
there exists a proper complexity function µ(n) : N → N, and n0 ∈ N, such that f (n) ≤ g(n)/µ(n)
for all n ≥ n0 . The ω(·) notation is defined similarly to the above.
It is clear that CSP and CNF-S AT are solvable in time domn |I|O(1) and 2n |I|O(1) , respectively,
where I is the input instance and n is the number of variables in I. We say that CSP (resp. CNF-S AT)
is solvable in uniform subexponential time if there exists an algorithm that solves the problem in time
domo(n) |I|O(1) (resp. 2o(n) |I|O(1) ). Using the results of Chen, Kanj, and Xia (2009) and Flum and
210

O N THE S UBEXPONENTIAL -T IME C OMPLEXITY OF CSP

Grohe (2006), the above definition is equivalent to the following: CSP (respectively, CNF-S AT) is
solvable in uniform subexponential time if there exists an algorithm that for all ε = 1/`, where ` is a
positive integer, solves the problem in time domεn |I|O(1) (resp. 2εn |I|O(1) ). CSP (resp. CNF-S AT)
is solvable in nonuniform subexponential time if for each ε = 1/`, where ` is a positive integer, there
exists an algorithm Aε that solves the problem in time domεn |I|O(n) (resp. 2εn |I|O(1) ) (that is, the
algorithm depends on ε). We note that if a problem admits a subexponential-time algorithm (uniform
or nonuniform) then this means that we can improve the exponent in the exponential-term of the
running time of the algorithm indefinitely.
Let Q and Q0 be two problems, and let µ and µ0 be two functions defined on instances of Q and
Q0 , respectively, each assigning with an instance of the corresponding problem a parameter value. In
the case of CSP and CNF-S AT, µ and µ0 will assign the number of variables in the instances of these
problems. A subexponential-time Turing reduction family (Impagliazzo, Paturi & Zane, 2001; see
also Flum & Grohe, 2006) a serf-reduction 1 for short, is an algorithm A with an oracle to Q0 such
that there are computable functions f, g : N −→ N satisfying: (1) given a pair (I, ε) where I ∈ Q
and ε = 1/` (` is a positive integer), A decides I in time f (1/ε)domεµ(I) |I|O(1) (for CNF-S AT
dom = 2); and (2) for all oracle queries of the form “I 0 ∈ Q0 ” posed by A on input (I, ε), we have
µ0 (I 0 ) ≤ g(1/ε)(µ(I) + log |I|).
The optimization class SNP consists of all search problems expressible by second-order existential
formulas whose first-order part is universal (Papadimitriou & Yannakakis, 1991). Impagliazzo, Paturi,
and Zane (2001) introduced the notion of completeness for the class SNP under serf-reductions,
and identified a class of problems which are complete for SNP under serf-reductions, such that the
subexponential-time solvability for any of these problems implies the subexponential-time solvability
of all problems in SNP. Many well-known NP-hard problems are proved to be SNP-complete under
the serf-reduction, including 3-S AT, V ERTEX C OVER, and I NDEPENDENT S ET, for which extensive
efforts have been made in the last three decades to develop subexponential-time algorithms with
no success. This fact has led to the exponential-time hypothesis, ETH, which is equivalent to the
statement that not all SNP problems are solvable in subexponential time:
Exponential-Time Hypothesis (ETH): The problem k-CNF-S AT, for any k ≥ 3, cannot be solved
in time 2o(n) , where n is the number of variables in the input formula. Therefore, there exists
c > 0 such that k-CNF-S AT cannot be solved in time 2cn .
The following result is implied, using the standard technique of renaming variables (Impagliazzo,
Paturi & Zane, 2001, Corollary 1, 2) and from the proof of the Sparsification Lemma (Impagliazzo,
Paruri & Zane, 2001; Flum & Grohe, 2006, Lemma 16.17). For the sake of completeness, we provide
a sketch of how these aforementioned results in the literature are combined to give the statement of
the lemma.
Lemma 1. k-CNF-S AT (k ≥ 3) is solvable in 2o(n) time if and only if k-CNF-S AT with a linear
number of clauses and in which the number of occurrences of each variable is at most 3 is solvable
in time 2o(n) , where n is the number of variables in the formula (note that the size of an instance of
k-CNF-S AT is polynomial in n). In particular, choosing k = 3 we get: 3-CNF-S AT in which every
variable occurs at most 3 times, denoted 3-3-S AT, is not solvable in 2o(n) time unless the ETH fails.
1. Serf-reductions were introduced by Impagliazzo, Paturi, and Zane (2001). Here we use the definition given by Flum
and Grohe (2006). There is a slight difference between the two definitions, and the latter definition is more flexible for
our purposes.

211

DE

H AAN , K ANJ , & S ZEIDER

Proof. It was shown by Impagliazzo et al. (2001, Corollary 1, 2) that, for any k ≥ 3, there is a
serf-reduction from k-CNF-S AT to k-CNF-S AT in which the number of clauses m is linear in the
number of variables n. For an instance of k-CNF-S AT in which m = O(n), the total number of
occurrences of the variables is also linear in n (because the width of each clause is at most k). Now
for each variable that appears more than ` > 3 times, using the standard technique of renaming
variables, we can replace (rename) each of the ` occurrences with a new variable, and add a cycle of
` implications (using ` new 2-CNF-S AT clauses) enforcing that all these ` new variables receive the
same value in any satisfying assignment. The resulting formula is a k-CNF-S AT formula in which
the number of occurrences of each variable is at most 3, and in which the number of new variables is
linear in the original number of variables n. This gives a serf-reduction from k-CNF-S AT (for any
k ≥ 3) to k-CNF-S AT in which the number of occurrences of each variable is at most 3 (and hence
also with a linear number of clauses).
The ETH has become a standard hypothesis in complexity theory (Lokshtanov et al., 2011).
Remark 1. In this paper, when we consider CSP (with or without global constraints) restricted
to instances in which a certain parameter is Ω(g(n)) (resp. ω(g(n)), O(g(n)), o(g(n))), for some
proper complexity function g(n) of the number of variables n in the instance, we mean CSP restricted
to all the instances in which the parameter is upper bounded by a prespecified function that is Ω(g(n))
(resp. ω(g(n)), O(g(n)), o(g(n))). For example, when we say “CSP restricted to instances whose
primal treewidth is o(n) is solvable in subexponential time” we mean the following: For any proper
complexity function g(n) = o(n), the problem consisting of the restriction of CSP to instances
whose primal treewidth is at most g(n) is solvable in subexponential time.

3. CSP and CSPc
In this section we investigate the subexponential-time complexity of CSP and CSPc with respect
to restrictions on various structural parameters. We start in Subsection 3.1 by establishing relations
among the subexponential-time complexity of CNF-S AT, CSP, and CSPc ; some of these results will
be the corner stones that the results in the subsequent (sub)sections rely upon.
3.1 Relations Among CSP, CSPc , and CNF-S AT
We start with the following simple observation:
Observation 1. For any positive integer constant r, there is a serf-reduction from r-CSP to r-CSPc
and vice versa. Moreover, each of the reductions produces an instance having the same set of
variables and the domain values as those of the original instance.
The fact that there is a serf-reduction from r-CSP to r-CSPc trivially follows from the fact that
r-CSP is a special case of r-CSPc . For the opposite direction, observe that each cTable constraint
of bounded arity can be decompressed to a table constraint, over the same set of variables, in
polynomial time by enumerating all tuples that satisfy the cTable constraint. This is a polynomial
time serf-reduction from r-CSPc to r-CSP.
Proposition 1. B OOLEAN r-CSP, where r ≥ 3, is solvable in subexponential time if and only if the
ETH fails.
212

O N THE S UBEXPONENTIAL -T IME C OMPLEXITY OF CSP

Proof. To prove the first part of the statement, we give a serf-reduction from the r-CNF-S AT to
B OOLEAN r-CSP. Given an instance F of r-CNF-S AT, it is easy to see that we can correspond with
every clause in F a constraint with arity at most r (over the same variables) containing at most 2r
tuples such that the clause is satisfied if and only if the corresponding constraint is. Clearly, this is a
polynomial-time reduction that results in an instance of B OOLEAN r-CSP with the same variable-set
as F , and hence is a serf-reduction.
To prove the converse, we give a serf-reduction from B OOLEAN r-CSP to r-CNF-S AT. Let I
be an instance of B OOLEAN r-CSP. We construct an instance F of r-CNF-S AT as follows. Let C
be a constraint in I. Since the arity of I is at most r, C contains at most r variables and 2r tuples.
We can associate with C a set of clauses in F , each of width at most r, such that C is satisfied if
and only if all the associated clauses are. This can be easily done by considering each tuple over the
variable-set of C that is not contained in C, and adding a clause to F consisting of the disjunction of
the negation of the set of literals that the tuple represents. Since each tuple represents a conjunction
of a set of at most r literals, this results in at most 2r clauses, with each being the disjunction of at
most r literals. Clearly, F is an instance of r-CNF-S AT over the same variable-set as I, and F is
computable in polynomial time. The proof follows.
The following proposition suggests that Proposition 1 may not extend to r-CSP with unbounded
domain size. Chen, Chor, Fellows, Huang, Juedes, Kanj, and Xia (2005) showed that if C LIQUE
(decide whether a given a graph on N vertices contains a complete subgraph of k vertices) is solvable
in time N o(k) then the ETH fails. The converse, however, is generally believed not to be true. The
idea behind the proof of the following proposition goes back to the paper by Papadimitriou and
Yannakakis (1999), where they used it in the context of studying the complexity of database queries.
We provide the proof for completeness.
Proposition 2. If 2-CSP is solvable in subexponential time then C LIQUE is solvable in time N o(k) .
Proof. Assume that 2-CSP is solvable in time domo(n) , and let (G, k) be an instance of C LIQUE,
where G has N vertices. Assume that the vertices in G are labeled {1, . . . , N }. We construct an
instance I of 2-CSP as follows. The variable-set of I is {x1 , . . . , xk }, and the variables range over
the domain {1, . . . , N }; that is, the variables will be used to select the vertices of G that form the
clique (if it exists). For every pair of distinct variables xi , xj , where i < j, we add a constraint Cij
containing all pairs/tuples of the form (u, v) such that uv is an edge in G and u < v.
It is not difficult to verify that G has a clique of k vertices if and only if I is consistent. Since I
has k variables and dom = N , it follows that I, and hence (G, k), can be decided in time N o(k) .
The proof follows.
By Observation 1, the statement of Proposition 1 holds true for B OOLEAN r-CSPc , and the
statement of Proposition 2 holds true for 2-CSPc .
We explore next the relation between B OOLEAN CSP with unbounded arity and CNF-S AT. We
show that if B OOLEAN CSP is solvable in nonuniform subexponential time then so is CNF-S AT. To
do so, we exhibit a nonuniform subexponential-time Turing reduction from CNF-S AT to B OOLEAN
CSP.
Intuitively, one would try to reduce an instance F of CNF-S AT to an instance I of CSP by
associating with every clause in F a constraint in I whose variables are the variables in the clause,
and whose relation consists of all tuples that satisfy the clause. There is a slight complication in
such an attempted reduction because the number of tuples in a constraint could be exponential if
213

DE

H AAN , K ANJ , & S ZEIDER

the number of variables in the corresponding clause is linear (in the total number of variables). To
overcome this subtlety, the idea is to first apply a subexponential-time (Turing) reduction, which is
originally due to Schuler (2005) and was also used and analyzed by Calabro, Impagliazzo, and Paturi
(2006), that reduces the instance F to subexponentially many (in n) instances in which the width of
each clause is at most some constant k; in our case, however, we will reduce the width to a suitable
nonconstant value. We follow this reduction with the reduction to B OOLEAN CSP described in the
proof of Proposition 1.
Theorem 1. If B OOLEAN CSP has a nonuniform subexponential-time algorithm then so does
CNF-S AT.
Proof. Suppose that B OOLEAN CSP is solvable in nonuniform subexponential time. Then for every
δ > 0, there exists an algorithm A0δ that, given an instance I of B OOLEAN CSP with n0 variables,
0
0
A0δ solves I in time 2δn |I|c , for some constant c0 > 0.
Let 0 < ε < 1 be given. We describe an algorithm Aε that solves CNF-S AT in time 2εn mO(1) .
εn
Set k = b 2(1+c
0 ) c. Let F be an instance of CNF-S AT with n variables and m clauses. The algorithm
Aε is a search-tree algorithm, and works as follows. The algorithm picks a clause C in F of width
more than k; if no such clause exists the algorithm stops. Let l1 , . . . , lk be any k literals in C. The
algorithm branches on C into two branches. The first branch, referred to as a left branch, corresponds
to one of these k literals being assigned the value 1 in the satisfying assignment sought, and in this
case C is replaced in F by the clause (l1 ∨ . . . ∨ lk ), thus reducing the number of clauses in F of
width more than k by 1. The second branch, referred to as a right branch, corresponds to assigning
all those k literals the value 0 in the satisfying assignment sought; in this case the values of the
variables corresponding to those literals have been determined, and the variables can be removed
from F and F gets updated accordingly. Therefore, in a right branch the number of variables in F is
reduced by k. The execution of the part of the algorithm described so far can be depicted by a binary
search tree whose leaves correspond to instances resulting from F at the end of the branching, and in
which each clause has width at most k. The running time of this part of the algorithm is proportional
to the number of leaves in the search tree, or equivalently, the number of root-leaf paths in the search
tree.
Before we continue the description of the algorithm Aε , we illustrate the above branching phase of
the algorithm with the following concrete example. Suppose that F is an instance of CNF-S AT over
the 6 variables {x1 , . . . , x6 } consisting of the 3 clauses C1 , C2 , C3 , where C1 = {x1 , x2 , x3 , x4 , x5 },
C2 = {x2 , x3 , x5 , x6 }, and C3 = {x1 , x3 , x4 , x5 , x6 }. Suppose that we want to reduce the formulawidth to 3 (i.e., k = 3). We pick any clause of width more than 3, say C1 , and branch on any 3
literals in C1 , say x1 , x2 , x3 . In the left branch (at least one of these 3 literals is 1) we obtain the
(CNF) formula F1 consisting of the 3 clauses {x1 , x2 , x3 }, C2 , and C3 ; in the right branch (each of
these literals is assigned 0), we obtain the formula F2 consisting of the clause {x4 , x5 } (C2 and C3
are satisfied in this case). Note that we do not branch anymore on F2 since its width is 2. Since F1
still contains clauses of width more than 3, namely C2 and C3 , we branch further on F2 by picking
a clause of width more than 3, say C3 , and branching on 3 literals in C3 , say x1 , x3 , x4 . In the left
branch, we obtain the formula F1,1 consisting of the 3 clauses {x1 , x2 , x3 }, C2 , {x1 , x3 , x4 }; in the
right branch we obtain the formula F1,2 consisting of the 2 clauses {x2 , x5 , x6 } and {x5 , x6 }. We do
not branch on F1,2 since its width is 3. Since F1,1 contains the clause C2 of width more than 3, we
branch on 3 literals in C2 , say x2 , x3 , x5 . In the left branch we obtain the formula F1,1,1 consisting
of the 3 clauses {x1 , x2 , x3 }, {x2 , x3 , x5 }, and {x1 , x3 , x4 }; we do not branch on F1,1,1 since its
214

O N THE S UBEXPONENTIAL -T IME C OMPLEXITY OF CSP

F
F1
F1,1

F2
F1,2

F1,1,1 F1,1,2

Figure 1: The search tree corresponding to the branching of the algorithm in the example.

width is 3. In the right branch we obtain the formula F1,1,2 consisting of the two clauses {x1 , x4 }
and {x6 }; we do not branch on F1,1,2 . The algorithm does not branch anymore since all the leaves in
the search tree are formulas of width at most 3. Figure 1 depicts the search tree corresponding to the
branching in the above example.
We now continue the description of the algorithm Aε . Let F 0 be an instance resulting from F at
a leaf of the search tree. We reduce F 0 to an instance IF 0 of B OOLEAN CSP as follows. For each
clause C 0 in F 0 , we correspond to it a constraint whose variable-set is the set of variables in C 0 , and
whose tuples consist of at most 2k − 1 tuples corresponding to all assignments to the variables in C 0
that satisfy C 0 . Clearly, IF 0 can be constructed in time 2k mO(1) (note that the number of clauses in
F 0 is at most m). To the instance IF 0 , we apply the algorithm A0δ with δ = ε/2. The algorithm Aε
accepts F if and only if A0δ accepts one of the instances IF 0 , for some F 0 resulting from F at a leaf
of the search tree.
To illustrate this phase of the algorithm using the example above, for each of the formulas F2 ,
F1,2 , F1,1,1 , and F1,1,2 , corresponding to the leaves of the search tree (see Figure 1), we associate
an instance of B OOLEAN CSP. For example, the instance of B OOLEAN CSP associated with F1,2
consists of two constraints. The first constraint corresponds to clause {x2 , x5 , x6 }; it has (x2 , x5 , x6 )
as its sequence of variables, and
{(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 1)} as its relation. The second constraint corresponds to clause {x5 , x6 } in F1,2 ; it has (x5 , x6 ) as its sequence of variables, and
{(0, 0), (0, 1), (1, 0)} as its relation.
The running time of Aε is upper bounded by the number of leaves in the search tree, multiplied
by a polynomial in the length of F (polynomial in m) corresponding to the (maximum) total running
time along a root-leaf path in the search tree, multiplied by the time to construct the instance IF 0
corresponding to F 0 at a leaf of the tree, and multiplied by the running time of the algorithm A0δ
applied to IF 0 . Note that the binary search tree depicting the execution of the algorithm is not a
complete binary tree. To upper bound the size of the search tree, let P be a root-leaf path in the
search tree, and let ` be the number of right branches along P . Since each right branch removes k
variables, ` ≤ n/k and the number of variables left in the instance F 0 at the leaf endpoint of P is
n − `k. Noting that the length of a path with ` right branches is at most m + ` (each left branch
reduces m by 1 and hence there can be at most m such branches on P , and there are ` right branches),
we conclude that the number of root-leaf paths, and hence the number of leaves, in the search tree is

Pdn/ke
at most `=0 m+`
.
`
215

DE

H AAN , K ANJ , & S ZEIDER

The reduction from F 0 to an instance of B OOLEAN CSP can be carried out in time 2k mO(1) , and
results in an instance IF 0 in which the number of variables is at most n0 = n − `k, the number of
constraints is at most m, and the total size is at most 2k mO(1) . Summing over all possible paths in the
search tree, the running time of Aε is 2εn mO(1) . This is a consequence of the following estimation:
dn/ke 

X
`=0


m + ` k O(1) δ(n−`k) k O(1) c0
2 m
·2
.(2 m
)
`

≤ 2

(1+c0 )k+δn

≤ 2

(1+c0 )k+δn

m

O(1)

dn/ke 

X
`=0

mO(1)




m + dn/ke
`


2m
dn/ke

0

≤ 2(1+c )k+δn mO(1) · (2m)n/k
≤ 2

(1+c0 )k+δn
εn

≤ 2 m

O(1)

m

O(1)

(1)
(2)
(3)

.

The first inequality follows after replacing ` by the larger value dn/ke in the upper part of the
binomial coefficient, and upper bounding the term 2−`δk by 1. Inequality
(1) follows
from the


2m
fact that the largest binomial coefficient in the summation is m+dn/ke
≤
(m
≥
dn/ke,
dn/ke
dn/ke
otherwise m is a constant, and the instance of CNF-S AT can be solved in polynomial time from the
beginning), and hence, the summation can be replaced by the largest binomial coefficient multiplied
by the number of terms (dn/ke+1) in the summation, which gets absorbed by the term mO(1) .
Inequality (2) follows from the trivial upper bound on the binomial coefficient (the ceiling can be
removed because polynomials in m get absorbed). Inequality (3) follows after noting that n/k is a
constant (depends on ε), and after substituting k and δ by their values/bounds.
It follows that the algorithm Aε solves CNF-S AT in time 2εn mO(1) . Therefore, if B OOLEAN
CSP has a nonuniform subexponential-time algorithm, then so does CNF-S AT. The algorithm is
nonuniform because the polynomial factor in the running time (exponent of m) depends on ε.
Theorem 1 provides strong evidence that B OOLEAN CSP is not solvable in subexponential
time. We show next that B OOLEAN CSPc is not solvable in subexponential time under a weaker
hypothesis than that assumed in Theorem 1. By SAT[3] we denote the satisfiability of normalized
propositional formulas of depth 3 (Flum & Grohe, 2006), that is, propositional formulas that are
the conjunction-of-disjunction-of-conjunction of literals. It is well known that if SAT[3] is solvable
in subexponential time then the W -hierarchy in parameterized complexity collapses at the second
level (Chen et al., 2006), that is, W [2] = FPT, which is a consequence that is deemed very unlikely
and would imply that CNF-S AT is solvable in subexponential time (Chen et al., 2006).
Proposition 3. Unless W [2] = FPT, B OOLEAN CSPc is not solvable in subexponential time.
Proof. It is easy to see that an instance of SAT[3] is polynomial-time reducible to an instance of
B OOLEAN CSPc on the same set of variables. In this reduction, every disjunction-of-conjunction of
literals in the Boolean formula is associated with a cTable constraint, where each compressed tuple
(V1 , . . . , Vr ) of this constraint represents a conjunction of literals: a positive literal xi is represented
by Vi = {1}, a negative literal ¬xi is represented by Vi = {0}, and if a variable xi does not occur in
the conjunction, it is represented by Vi = {0, 1}. Therefore, there is a serf-reduction from SAT[3] to
B OOLEAN CSPc . The statement now follows from the result by Chen et al. (2006).
216

O N THE S UBEXPONENTIAL -T IME C OMPLEXITY OF CSP

3.2 Instance Size and Number of Tuples
In this section we give characterizations of the subexponential-time complexity of CSP and CSPc
with respect to the instance size and the number of tuples. We also show that the subexponential-time
solvability of B OOLEAN CSP and B OOLEAN CSPc with linear size, or linear number of tuples, is
equivalent to the statement that the ETH fails.
Proposition 4. Unless the ETH fails, the restriction of B OOLEAN CSP to instances whose size is
Ω(n) is not solvable in subexponential time.
Proof. Let s(n) = Ω(n) ≥ cn be a proper complexity function, where c > 0 is a constant. Suppose
that the restriction of B OOLEAN CSP to instances of size at most s(n) is solvable in subexponential
time, and we will show that 3-CNF-S AT is solvable in subexponential time. By Lemma 1, it is
sufficient to show that 3-CNF-S AT with a linear number of clauses is solvable in 2o(n) time. Using
a padding argument2 , we can prove the preceding statement assuming any linear upper bound on
the number of clauses; this is true because we can pad any instance of 3-CNF-S AT with a large
number of new variables to obtain an equivalent instance in which the number of clauses satisfies the
(smaller) desired upper bound. We pick this linear upper bound to be cn/24, where c is the constant
in the upper bound on s(n).
Let F be an instance of 3-CNF-S AT with n variables and at most cn/24 clauses. We reduce F
to an instance IF of B OOLEAN CSP using the same reduction described in the proof of Theorem 1:
for each clause C of F we correspond a constraint whose variables are those in C and whose tuples
are those corresponding to the satisfying assignments to C. Since the width of C is 3 and the number
of clauses is at most cn/24, the instance IF consists of at most cn/24 constraints, each containing at
most 3 variables and 8 tuples. Therefore, the size of IF is at most cn. We now apply the hypothetical
subexponential-time algorithm to IF . Since |I| is linear in n, and since the reduction takes linear time
in n, we conclude that 3-CNF-S AT is solvable in time 2o(n) nO(1) = 2o(n) . The proof follows.
Since B OOLEAN CSP is a special case of B OOLEAN CSPc , the statement of Proposition 4 holds
true for B OOLEAN CSPc as well.
Proposition 5. The restriction of CSPc to instances with o(n) tuples is solvable in subexponential
time.
Proof. Let s(n) = o(n) be a proper complexity function, and consider the restriction of CSPc to
instances with at most s(n) tuples. We will show that this problem is solvable in time doms(n) |I|O(1) .
Let I be an instance of the problem under consideration. Consider the algorithm A that, for each
compressed tuple in a constraint in I, branches on whether or not the compressed tuple is satisfied
by the satisfying assignment sought. A branch in which more than one compressed tuple in any
constraint is selected as satisfied is rejected, and likewise for a branch in which no compressed
tuple in a constraint is selected. For each remaining branch, the algorithm checks if the branch is
consistent, which would imply that there is an assignment to the variables that aligns with the branch
and satisfies I. Checking if a branch is consistent is done as follows. Let x be a variable in I, and let
t1 , . . . , tp be the compressed tuples selected by the branch in the cTables that contain x as a variable.
2. A padding argument is a general tool that is used in complexity theory to extend a result to a larger class of problems.
For our purpose in this paper, the padding argument works by adding/padding a “dummy” part to the instance to create
an equivalent new instance in which a relation holds true between certain parameters in the new instance. We will use
the padding argument several times in this paper, and skip the details once the argument is clear.

217

DE

H AAN , K ANJ , & S ZEIDER

Let Vix , i = 1, . . . , p, be the set of values admissible for xTin the cTable from which ti was selected
by the branch. A branch is consistent with respect to x if pi=1 Vix 6= ∅, and a branch is consistent if
it is consistent with respect to every variable in I. Clearly, for a given branch by the algorithm A,
checking whether or not the branch is consistent can be done in polynomial time in |I|.
If a branch is consistent, the algorithm accepts; the algorithm rejects if no branch corresponds
to a consistent assignment. Clearly, the algorithm A is correct, and runs in time 2s(n) |I|O(1) =
doms(n) |I|O(1) (we assume that dom ≥ 2, otherwise the problem is trivial).
Noting that the number of tuples is a lower bound for the instance size, the following proposition
follows from Proposition 4 and Proposition 5:
Proposition 6. The restriction of CSP to instances in which the number of tuples is o(n) is solvable
in subexponential time, and unless the ETH fails, the restriction of CSP to instances in which the
number of tuples is Ω(n) is not solvable in subexponential time. The same holds true for CSPc .
Next, we show that the subexponential-time solvability of B OOLEAN CSP with linear size, or
with linear number of tuples, is equivalent to the statement that the ETH fails. We first need the
following proposition:
Proposition 7. If the ETH fails then the restriction of B OOLEAN CSPc to instances with linear
number of tuples is solvable in subexponential time.
Proof. We give a polynomial-time serf-reduction from B OOLEAN CSPc with linear number of tuples
to C IRCUIT S ATISFIABILITY with linear size circuits. The result will then follow from the fact that
C IRCUIT S ATISFIABILITY with linear size circuits is SNP-complete under serf-reductions (and hence
is solvable in subexponential time if and only if the ETH fails) (Impagliazzo, Paturi & Zane, 2001).
Let s(n) ≤ cn be a proper complexity function, where c > 0 is a constant. Consider the restriction
of B OOLEAN CSPc to instances in which the number of tuples is at most cn, and let I be an instance
of this problem. We construct a Boolean circuit CI as follows. The circuit CI is a depth-3 circuit
whose output gate is an AND-gate, and whose set of variables is the same as that of I. With each
cTable constraint T in I we correspond an OR-gate gT that is connected to the output gate of C. Let
T be a cTable constraint in I over the Boolean variables (v1 , . . . , vr ), and let t = (V1 , . . . , Vr ) be a
compressed tuple in T . We correspond to t an AND-gate gt in CI that is connected to the OR-gate
gT corresponding to T in CI ; the input to gt are literals in CI that are determined as follows. For
each vi , i = 1, . . . , r, if Vi = {1} then connect the variable corresponding to vi in CI to gt , and if
Vi = {0} then connect the negation of the variable corresponding to vi in CI to gt (we do nothing if
Vi = {0, 1} because there is no constraint imposed by the tuple on the Boolean value of vi ). It is
easy to see that t is satisfied if and only if the corresponding gate gt in CI evaluates to 1, and hence T
is satisfied if and only if gT evaluates to 1. It follows that I is satisfied if and only if CI is. Moreover,
the size of CI is linear in the number of tuples in I, and subsequently in the number of variables in
CI . Since the construction of CI can be done in polynomial time, the proof follows.
Clearly, the statement of the above proposition holds true for B OOLEAN CSP as well.
Proposition 4, combined with Proposition 7 after noting that the size is an upper bound on the
number of tuples, gives the following results:
Theorem 2. The restriction of B OOLEAN CSP to instances with linear number of tuples is solvable
in subexponential time if and only if the ETH fails. The same result holds for B OOLEAN CSPc .
218

O N THE S UBEXPONENTIAL -T IME C OMPLEXITY OF CSP

Theorem 3. The restriction of B OOLEAN CSP to instances with linear size is solvable in subexponential time if and only if the ETH fails. The same result holds for B OOLEAN CSPc .
3.3 Number of Constraints and Treewidth
In this section we give characterizations of the subexponential-time complexity of CSP and CSPc
with respect to the number of constraints, and the treewidth of the primal and incidence graphs. We
start withe following proposition:
Proposition 8. Unless the ETH fails, the restriction of CSP to instances in which the number of
constraints is ω(1) is not solvable in subexponential time.
Proof. Let λ(n) = ω(1) be a proper complexity function. We show that, unless the ETH fails, the
restriction of CSP to instances in which cons ≤ λ(n), denoted CSPλ is not solvable in domo(n)
time. By Proposition 1, it suffices to provide a serf-reduction from B OOLEAN 3-CSP with a linear
number of constraints to B OOLEAN CSPλ .
Let I be an instance of B OOLEAN CSP in which cons = n0 ≤ cn, where c > 0 is a constant. Let
C1 , . . . , Cn0 be the constraints in I; we partition these constraints arbitrarily into bλ(n)c many groups
C1 , . . . , Cr , where r ≤ bλ(n)c, each containing at most dn0 /λ(n)e constraints. The serf-reduction A
works as follows. A “merges” all the constraints in each group Ci , i = 1, . . . , r, into one constraint
Ci0 as follows. The variable-set of Ci0 consists of the union of the variable-sets of the constraints
in Ci . For each constraint C in Ci , iterate over all tuples in C. After selecting a tuple from each
constraint in Ci , check if all the selected tuples are consistent, and if so merge all these tuples into a
single tuple and add it to Ci0 . By merging the tuples we mean form a single tuple over the variables
in these tuples, and in which the value of each variable is its value in the selected tuples (note that
the values are consistent). Since each constraint in I has arity at most 3, and hence contains at
most 8 tuples, and since each group contains at most dn0 /λ(n)e constraints, Ci0 can be constructed
0
in time 8dn /λ(n)e n0O(1) = 2o(n) , and hence, all the constraints C10 , . . . , Cr0 can be constructed in
time 2o(n) nO(1) = 2o(n) . We now form the instance I 0 whose variable-set is that of I, and whose
constraints are C10 , . . . , Cr0 . Since r ≤ bλ(n)c, I 0 is an instance of CSPλ . Moreover, it is easy to see
that I is consistent if and only if I 0 is. Since I 0 can be constructed from I in subexponential time and
the number of variables in I 0 is at most that of I, it follows that A is a serf-reduction from B OOLEAN
3-CSP with a linear number of constraints to CSPλ .
Proposition 9. The restriction of CSPc to instances in which cons = O(1) is solvable in polynomial
time.
Proof. If the number of constraints in an instance is O(1), then in polynomial time we can enumerate
each subset of tuples such that the subset contains exactly one compressed tuple from each constraint
in the instance (because the size of such a subset is O(1)). We can then verify consistency (as
described in the proof of Proposition 5), and deduce an instantiation of the set of variables if it exists
in polynomial time.
Clearly, Proposition 8 holds true for CSPc , and Proposition 9 holds true for CSP. Therefore,
combining Proposition 8 and Proposition 9 we have:
Theorem 4. The restriction of CSP to instances with O(1) constraints is solvable in polynomial
time, and unless the ETH fails, the restriction of CSP to instances with ω(1) constraints is not
solvable in subexponential time. The same holds true for CSPc .
219

DE

H AAN , K ANJ , & S ZEIDER

When now turn our attention to treewidth. We have the following proposition:
Proposition 10. Unless CSP (in general) is solvable in subexponential time (and hence the ETH
fails), the restriction of CSP to instances whose tw is Ω(n) is not solvable in subexponential time.
Proof. Let s(n) = cn, where c > 0 is a constant, and consider the restriction of CSP to instances
whose tw is at most s(n), denoted L INEAR -tw-CSP. Note that the number of vertices in the primal
graph is n, and hence tw ≤ n. Therefore, if c ≥ 1, then the statement trivially follows. Suppose now
that c < 1, and let I be an instance of CSP with n variables. By “padding” d1/ce disjoint copies of
I we obtain an instance I 0 that is equivalent to I, whose number of variables is N 0 = d1/cen, and
whose tw is the same as that of I. Since the tw of I is at most n, it follows that the tw of I 0 is at
most cN 0 , and hence I 0 is an instance of L INEAR -tw-CSP. This gives a serf-reduction from CSP to
L INEAR -tw-CSP.
We note that the hypothesis “CSP is solvable in subexponential time” in the above theorem
implies that the “ETH fails” by Proposition 1, and implies that CNF-S AT has a nonuniform
subexponential-time algorithm by Theorem 1.
The following theorem provides a tight characterization of the subexponential-time complexity
of CSPc (and CSP) with respect to the primal and incidence treewidth.
Theorem 5. The following statements are true:
(i) The restriction of CSPc to instances in which tw = o(n) is solvable in subexponential time,
and unless the ETH fails, the restriction of CSPc to instances in which tw = Ω(n) is not
solvable in subexponential time.
(ii) The restriction of CSPc to instances in which tw∗ = O(1) is solvable in subexponential time
(even in P), and unless the ETH fails, the restriction of CSPc to instances in which tw∗ = ω(1)
is not solvable in subexponential time.
Proof. (i) Note that an upper bound on the primal treewidth implies the same upper bound on the
arity. Let I be an instance of CSPc whose tw = o(n). Since arity = o(n), each constraint contains
at most d(n)o(n) many satisfying tuples. By decompressing compressed tuples, i.e., by enumerating
all the satisfying tuples in each constraint in time O∗ (d(n)o(n) ) we can reduce the instance I to
an instance of CSP on the same set of variables, domain, and primal tree width. Now we can
compute a tree decomposition of width at most 4 · tw in time 24.38tw |I|O(1) (Amir, 2010). It is well
known (Freuder, 1990) that CSP is solvable in time O∗ (d(n)tw ) ⊆ O∗ (d(n)o(n) ), and hence I can
be decided in subexponential time. The hardness result follows from the same hardness result for
CSP in Proposition 10.
(ii) The hardness result is a direct consequence of the hardness result in Theorem 4, since cons
is an upper bound on tw∗ . Establishing the first statement requires some work. Consider an instance
I of CSPc whose incidence treewidth is a constant w.
We apply a construction of Samer and Szeider (2010) to transform I into an equivalent instance
I 0 of CSPc whose incidence treewidth is at most w + 1 and where each variable appears in the
scope of at most 3 constraints. The construction keeps all constraints of I and adds binary equality
constraints and copies of variables. The equality constraints enforce that a variable and all its copies
get assigned the same value. The construction of Samer and Szeider is stated for table constraints
220

O N THE S UBEXPONENTIAL -T IME C OMPLEXITY OF CSP

but clearly works also for cTable, since the constraints of I are not changed at all, and the newly
introduced constraints are binary.
Consider the dual graph Gd of I 0 which has as vertices the constraints of I 0 , and where two
constraints are joined by an edge if and only if they share at least one variable. Because each
variable appears in the scope of at most 3 constraints, a further result of Samer and Szeider (2010,
Lemma 2(5)) applies, which is based on a construction due to Kolaitis and Vardi (2000), and from
which it follows that the treewidth of Gd is at most 2w + 2.
Next we obtain the the CSP instance I 00 which is “dual” to the instance I 0 . This construction is
a straightforward generalization of a known construction for CSP with table constraints (see, e.g.,
Dechter, 2003, Definition 2.1). Each constraint C = (S, U ) of I 0 gives rise to a variable x[C] of I 00 ;
the domain D(x[C]) is U , a set of compressed tuples. Between any two variables x[C1 ], x[C2 ] of
I 00 corresponding to constraints C1 = (S1 , U1 ) and C2 = (S2 , U2 ), respectively, of I 0 that share at
least one variable we add a binary table constraint ((x[C1 ], x[C2 ]), R). Here, the relation R contains
all pairs (t1 , t2 ) ∈ U1 × U2 that are consistent in the sense that for all variables x that appear in
the scopes of C1 and C2 , the coordinate Vi1 of t1 corresponding to x and the coordinate Vj2 of
t2 corresponding x have a nonempty intersection. It is straightforward to see that I 0 and I 00 are
equivalent. It remains to observe that Gd is isomorphic to the primal graph of I 00 , and hence the
primal treewidth of I 00 is 2w + 2, a constant. Hence we can solve I 00 in polynomial time (Freuder,
1990).
Clearly the same results in Theorem 5 hold true for CSP since the positive results in the theorem
were shown for the more general CSPc , and the negative results were proved for CSP.
We note the difference between the subexponential-time complexity of CSPc (and CSP) with
respect to the two structural parameters tw and tw∗ : Whereas the threshold function for the
subexponential-time solvability of CSPc and CSP with respect to tw is o(n), the threshold function
with respect to tw∗ is O(1).
3.4 Degree and Arity
In this section we give characterizations of the subexponential-time complexity of CSP and CSPc
with respect to the degree and the arity.
Proposition 11. Unless the ETH fails, the restriction of CSP to instances whose deg ≥ 2 is not
solvable in subexponential time.
Proof. The statement follows from the proof of Theorem 1 after noting that, by Lemma 1, one can
use 3-3-S AT in the reduction. This will result in instances of B OOLEAN 3-CSP with degree at most
3 as well. Now for each variable x of degree 3 in an instance of B OOLEAN 3-CSP, we introduce two
new variables x0 , x00 , and add a constraint whose variables are {x, x0 , x00 }, and containing the two
tuples (0, 0, 0) and (1, 1, 1); this constraint stipulates that the values of x, x0 , x00 be the same. We
then substitute the variable x in one of the constraints it appears in with x0 , and in another constraint
that it appears in with x00 . Therefore, in the new instance, the degree of each of x, x0 , x00 becomes 2.
After repeating this step to every variable of degree 3, we obtain an instance of B OOLEAN 3-CSP in
which the degree of each variable is at most 2. Since the increase in the number of variables is linear,
the above reduction is a serf-reduction from 3-3-S AT to B OOLEAN 3-CSP with degree at most 2,
and gives the statement of the proposition.
221

DE

H AAN , K ANJ , & S ZEIDER

Proposition 12. Unless the ETH fails, the restriction of CSP to instances whose arity ≥ 2 (and
dom ≥ 3) is not solvable in subexponential time.
Proof. We will give a serf-reduction from the 3-C OLORABILITY problem to CSP with arity = 2
and dom = 3. Since the 3-C OLORABILITY problem is SNP-complete under serf-reductions (Impagliazzo, Paturi & Zane, 2001), the statement of the theorem will follow. Recall that the 3C OLORABILITY problem asks if the vertices of a given graph can be properly colored (no two
adjacent vertices are assigned the same color) with at most 3 colors.
The reduction is folklore. Given an instance of G = (V, E) of 3-C OLORABILITY, where G
has n vertices, we construct an instance I of CSP as follows. The variables of I correspond to the
vertices of G, and the domain of I corresponds to the color-set {1, 2, 3}. For every edge of the graph
we construct a constraint of arity = 2 over the two variables corresponding to the endpoint of the
edge. The constraint contains all tuples corresponding to valid colorings of the endpoints of the edge.
It is easy to see that G has a 3-coloring if and only if I is consistent. Since for the instance I we
have vars = n, which is the number of vertices in G, and since arity = 2 and dom = 3, this is a
(polynomial-time) serf-reduction from the 3-C OLORABILITY problem to CSP with arity = 2 and
dom = 3.
Clearly, Proposition 11 and Proposition 12 hold true for CSPc as well.
We note that CSPc and CSP with dom = 2 and arity = 2 are solvable in polynomial time via
simple reductions to 2-CNF-S AT.
As it turns out, both CSP and CSPc exhibit the same subexponential-time complexity behavior
with respect to the same restrictions on the structural parameters considered above. On the other
hand, the negative result proved in Proposition 3 for B OOLEAN CSPc assumes a weaker hypothesis
than the result about B OOLEAN CSP proved in Theorem 1.

4. CSP6= , CSP= , CSP≥ , and CSP≤
In this section we consider CSP6= , CSP= , CSP≥ , and CSP≤ . Since our results for CSP= , CSP≥ ,
and CSP≤ are related, and rely on the results that we establish for CSP6= , we start by presenting our
results for CSP6= .
4.1 CSP6=
Let I be an instance of CSP6= with constraints C1 , . . . , Cc for some integer c > 0, over the set of
variables {x1 , . . . , xn }. Denote by Di , i = 1, . . . , n, the domain of xi .
Proposition 13. CSP6= can be solved in time O∗ (2n ).
Proof. We reduce the instance I to an instance of the L IST C OLORING problem. Recall that in the
L IST C OLORING problem we are given a graph, each of whose vertices is associated with a list
of colors, and we are asked to decide if there exists a proper coloring of the graph such that each
vertex is assigned a color from its list. To reduce I to an instance of L IST C OLORING, we construct
the graph G whose vertices are x1 , . . . , xn (without loss of generality, we label the vertices in G
with their corresponding variables’ names in I) and such that there is an edge between two vertices
xi and xj , 1 ≤ i < j ≤ n, if and only if xi and xj appear together in some constraint in I. For
each vertex xi in G, associate with it a list of colors Li = Di . It is not difficult to see that I is a
222

O N THE S UBEXPONENTIAL -T IME C OMPLEXITY OF CSP

yes-instance of CSP6= if and only if the graph G has a proper list coloring. It is known that the L IST
C OLORING problem is solvable in time O∗ (2n ) (Björklund, Husfeldt, & Koivisto, 2009), and hence
so is CSP6= .
Corollary 1. Let d(n) = ω(1) be a proper complexity function. The restriction of CSP6= to instances
in which dom ≥ d(n) is solvable in subexponential time.
Proof. Let d(n) = ω(1) be a proper complexity function, and consider the restriction of CSP6=
to instances in which dom ≥ d(n). By Proposition 13, CSP6= is solvable in time O∗ (2n ) =
O∗ (d(n)n/ log (d(n)) ) ⊆ O∗ (domo(n) ).
We note that the above result may sound strange, especially when taken in conjunction with the
next proposition, because it implies that the problem becomes “easier” for larger domain size. This
can be explained by the fact that when the domain size gets large, the allowable upper bound on the
subexponential time for solving the problem (i.e., d(n)o(n) ) gets larger as well.
By Corollary 1, we can focus our investigation of the subexponential-time complexity of CSP6=
on instances in which dom = O(1) = d, for some integer constant d. Note that dom is an upper
bound on arity because each constraint must have arity at most dom (otherwise it cannot be satisfied).
If d ≤ 2, then each constraint can have arity at most 2, and CSP6= in this case reduces to 2-CNF-S AT,
which is in P. Therefore, we can assume in the remainder of this section that d ≥ 3.
Proposition 14. Unless the ETH fails, the restriction of CSP6= to instances in which dom = d ≥ 3
and cons = Ω(n) is not solvable in subexponential time.
Proof. It suffices to prove the result for cons = s(n), where s(n) is any specific function such that
s(n) is linear in n (Θ(n)), as the result would extend using a padding argument to any function
that is linear in n (we can add new “dummy” variables and new “dummy” constraints on those new
variables to make the relation between the constraints and the variables satisfy the desired function
s(·)).
By Lemma 1, 3-3-S AT is not solvable in subexponential time unless the ETH fails. The standard
polynomial-time reduction from 3-S AT to 3-C OLORABILITY (see Cormen et al., 2009), establishing
the NP-hardness of 3-C OLORABILITY, reduces an instance of 3-S AT on n variables and m clauses
to an instance of 3-C OLORABILITY with O(n + m) vertices and O(n + m) edges. Therefore, if
we use the same reduction but start from 3-3-S AT instead of 3-S AT, we end up with an instance of
3-C OLORABILITY in which the number of vertices is O(n) and the number of edges is O(n) as well.
Hence, we have a serf-reduction from 3-3-S AT to the restriction of 3-C OLORABILITY to instances
whose size is linear in the number of vertices, denoted L INEAR -3-C OLORABILITY. Now if we use
the standard reduction from 3-C OLORABILITY to CSP6= (in which each vertex becomes a variable,
each edge becomes a constraint of arity 2, and the domain is the set of 3 colors), but instead we
start from an instance of L INEAR -3-C OLORABILITY, we obtain an instance of CSP6= on n variables
(the same as the number of vertices in the graph), linear number of constraints, and domain size
dom = 3. Therefore, the previous reduction is a serf-reduction from L INEAR -3-C OLORABILITY
to the restriction of CSP6= to instances in which the number of constraints is linear, and dom = 3.
Composing the two serf-reductions above gives a serf reduction from 3-3-S AT to the problem under
consideration, and thus proves the proposition.
Remark 2. We note that we did not phrase the statement of Corollary 1 to consider the restriction of
CSP6= to instances in which dom = ω(1) (as we had been been doing in the paper) because such
223

DE

H AAN , K ANJ , & S ZEIDER

restriction will encompass a slice of the problem that is hard (instances whose domain size is upper
bounded by a constant), as shown in Proposition 14. So we had to explicitly consider only instances
whose domain size is lower-bounded by a function that is ω(1). Proposition 17, in the next section,
is handled similarly.
Remark 3. We do not consider the restriction of CSP6= to instances in which cons = o(n) and
dom = O(1). This is because each constraint must have arity ≤ dom, and hence, if cons = o(n)
then it would follow that the total number of variables is o(n). It follows that Proposition 14 and
Corollary 1 provide tight characterizations of the subexponential-time complexity of CSP6= with
respect to each of cons and dom.
The following proposition provides a tight characterization of the subexponential-time complexity
of CSP6= with respect to the treewidth of the primal graph:
Proposition 15. The restriction of CSP6= to instances in which tw = o(n) is solvable in subexponential time, and unless the ETH fails, the restriction of CSP6= to instances in which tw = Ω(n) is not
solvable in subexponential time.
Proof. To derive the subexponential-time result, we can assume that the domain size is d, for some
constant d ≥ 3, because in the other case we get that CSP6= is solvable in subexponential time by
Corollary 1. Let I be an instance of CSP6= such that the treewidth of its primal graph is o(n). Since
the arity of each constraint in I is at most d and the domain size is d, in polynomial time we can
reduce I to an instance of CSP on the same set of variables, and with the same domain, constraints,
and primal treewidth. By part (i) of Theorem 5, the restriction of CSP to instances whose tw = o(n)
is solvable in subexponential time, and hence I can be decided in subexponential time.
The hardness result follows from a general observation about the primal treewidth of CSP
instances. First note that the number of variables n is an upper bound on the primal treewidth; that
is, tw ≤ n. Therefore, for any upper bound s(n) = Ω(n) on tw, using a padding argument (adding
a linear number of dummy new variables and singleton constraints that do not increase the primal
treewidth) we can reduce a general instance of CSP6= to an instance in which tw ≤ s(n) at the cost
of a linear increase in the number of variables and the instance size. This provides a serf-reduction
from a general instance of CSP6= to an instance in which tw ≤ s(n) = Ω(n). The result now follows
from the same result for CSP6= on general instances (implied, e.g., from Proposition 14).
It is well known that tw ≤ arity · (tw∗ − 1) and tw∗ ≤ tw + 1 (Kolaitis & Vardi, 2000). If
arity = O(1), then tw and tw∗ are within a multiplicative constant from one another. Therefore,
from Proposition 15 we can infer the following tight result:
Proposition 16. The restriction of CSP6= to instances in which tw∗ = o(n) is solvable in subexponential time, and unless the ETH fails, the restriction of CSP6= to instances in which tw∗ = Ω(n) is
not solvable in subexponential time.
Remark 4. There are several width parameters for CSP that are even more general than tw∗ in
the sense that any instances for which tw∗ is small, the other width parameter is small as well;
but there are instances for which the other width parameter is small but tw∗ can be arbitrarily
large. Prominent examples for such width parameters are hypertree width (Gottlob et al., 2002)
and submodular width (Marx, 2013). The lower bound statement of Proposition 16 clearly carries
over to the more general width parameters. The same holds true for the lower bound statements in
Proposition 19 and Theorem 5.
224

O N THE S UBEXPONENTIAL -T IME C OMPLEXITY OF CSP

4.2 CSP= , CSP≥ , and CSP≤
We start by presenting an exact algorithm for CSP≥ ; we do so by reducing CSP≥ to CSP6= . We use
the example illustrated in Figure 2 as a running example to explain the idea behind this reduction. In
this example, the instance of CSP≥ consists of three constraints C1 , C2 , C3 , where the variables in
C1 are x1 , x2 , x3 , x4 , the variables in C2 are x4 , x5 , and the variables in C3 are x1 , x5 , x6 , x7 . The
domain of x1 is {a, b}, the domain of both x2 and x3 is {b}, the domain of x4 is {b, c}, the domain
of x5 is {a}, and the domain of both x6 and x7 is {d, e}. The number of distinct values that need to
be assigned to the variables of C1 is at least 3, to the variables of C2 is at least 2, and to the variables
of C3 is at least 3.
In a solution S (i.e., an assignment of variables to domain values) to an instance I of CSP≥ , and
for a constraint C in I, it is possible for several variables in C to be assigned the same value by the
solution S (in the running example we are forced to assign both x2 and x3 the value b). Therefore,
if we attempt a straightforward reduction from CSP≥ to CSP6= that produces the same instance I,
the solution S to I as an instance of CSP≥ may not be a solution to I as an instance of CSP6= . It
is possible that the above happens due to the fact that there are variables in I that can be removed
without affecting the satisfiability of I, because there is a solution to I in which each constraint will
still be satisfied without considering the values assigned to those variables.
The algorithm starts by trying each subset of the variables as a subset for which there exists a
solution in which each of those variables is “essential” for this solution; the algorithm then removes
all the other (nonessential) variables, updates the instance, and works toward finding a solution
under this assumption in the resulting instance. (In the running example, we remove x3 from C1 ;
see the Venn diagram on the left in Figure 2.) Even with the above assumption, it is still possible
that in a solution to the resulting instance, two variables in a constraint C are assigned the same
value. One cannot simply ignore (remove) one of these variables on the basis that removing it will
not affect the satisfiability of C, because the removed variable may contribute to the satisfiability
of a constraint other than C, in which this variable appears as well. (In the running example, we
are forced to assign both x1 and x5 the same value, which would violate constraint C3 of CSP6= .)
Therefore, the resulting instance, even though it may be a satisfiable instance of CSP≥ , it may not
be a satisfiable instance of CSP6= . However, as it will be shown in Lemma 2, it is possible in such
an instance to “reassign” each variable to a subset of the constraints that it appears in, so that after
this reassignment/repartitioning each variable contributes to the satisfiability of each constraint that
it appears in. After such a reassignment, the resulting instance of CSP≥ becomes an equivalent
instance of CSP6= . (In the running example, variable x5 is not contributing to C3 , and can be safely
reassigned to C2 ; see the Venn diagram on the right in Figure 2.) We now proceed to the formal
proofs.
Let I be an instance of CSP≥ with constraints C1 , . . . , Cc for some integer value c > 0, over the
variables x1 , . . . , xn . Let ni , i = 1, . . . , c, be the nonnegative integer associated
with constraint Ci .
S
Denote by Di , i = 1, . . . , n, the domain of variable xi , and let D = ni=1 Di . Set k = |D|. If we
consider each Ci , i = 1, . . . , c, as a set consisting of all the variables in Ci , and we draw the Venn
diagram for the Ci ’s, then this Venn diagram consists of at most s ≤ 2c many nonempty regions,
where each region Rj , j = 1, . . . , s, is defined as the intersection of all the sets containing the
variables that lie in Rj in the Venn diagram. For a solution S to the instance I, we call a variable xi
essential (to S) if discounting the value assigned to xi by S violates at least one of the constraints
(containing xi ), and hence no longer gives a solution to I. It is clear that by enumerating every
225

DE

H AAN , K ANJ , & S ZEIDER

C20

C2

x5
x4
x2
C1

x5

x4

x1 x6 x7

x2

x1 x6 x7

C10

C3

C30

Figure 2: Illustration of the example of the reduction from CSP≥ to CSP6= .
subset of the variables in I, which takes O(2n ) time, we can work under the assumption that we are
looking for a solution such that every variable is essential to S. Since we are working on an instance
of CSP≥ , adding the nonessential variables to the solution afterwards (and assigning them values
from their domains) will not hurt the solution. Therefore, without loss of generality, we will assume
that each of the variables x1 , . . . , xn is essential to the solution sought (if any exists). We start with
the following lemma.
Lemma 2 (The Repartitioning Lemma). Let I be an instance of CSP≥ . There is a solution to I
if and only if there is an instance I 0 on the same set of variables as I, and whose constraints are
C10 , . . . , Cc0 , such that:
(1) the variables in Ci0 are a subset of those in Ci , for i = 1, . . . , c;
(2) the numbers n1 , . . . , nc are the same in both I and I 0 ; and
(3) there is a solution to I 0 satisfying that for every value v, and for any two distinct variables
xi , xj that are assigned the value v in the solution for I 0 , the set of constraints that xi belongs
to in I 0 is disjoint from that that xj belongs to in I 0 .
Proof. Suppose that I has a solution S; by the discussion preceding this lemma, we can assume that
every variable is essential to S. We define the instance I 0 on the same set of variables as I as follows.
The constants n1 , . . . , nc remain the same in I 0 . We define the constraints in I 0 by a sequence of
changes performed to the constraints in I; initially the constraints of I 0 are identical to those of I.
For every value v ∈ D assigned to some variable by the solution S, let x1v , . . . , x`v be the variables
assigned the value v by S. For each xjv , j = 1, . . . , ` − 1, considered in the listed order, let Cvj be the
j
set of constraints containing xjv in I 0 , and let Cv,∪
be the union of all constraints containing any of
j+1
j
j
`
the variables xv , . . . , xv . Remove xv from each constraint in Cvj ∩ Cv,∪
.
0
We claim that the same solution to I is a solution to I that satisfies all the conditions in the
statement of the lemma. First, from the construction of the constraints in I 0 , for any value v in the
solution, the set of constraints containing each variable assigned the value v are mutually disjoint
because each variable xiv (i < `) assigned a value v is removed from each constraint that some
`
0
subsequent variable in xi+1
v , . . . , xv is contained in. Moreover, because each constraint Ci is obtained
0
from Ci only by (possibly) removing variables from Ci , we have Ci ⊆ Ci , for i = 1, . . . , c. Finally,
226

O N THE S UBEXPONENTIAL -T IME C OMPLEXITY OF CSP

when a variable xiv that is assigned a value v is removed from a constraint Cj0 , this removal will not
affect the number of different values assigned to the variables in Cj0 by S; this is because we know
for sure that there will be a subsequent variable xpv , p ∈ {i + 1, . . . , `}, that is assigned value v and
that will remain in Cj0 , namely the variable xpv with the maximum index p that appears in Cj0 .
Conversely, because each Ci0 is a subset of Ci , for i = 1, . . . , c, it is easy to see that any solution
to I 0 is also a solution to I.
Theorem 6. CSP≥ can be solved in time O∗ ((2(cons + 1) + 1)n ).
Proof. Let I be an instance of CSP≥ with constraints C1 , . . . , Cc for some integer c > 0, over the
variables x1 , . . . , xn . Let ni , i = 1, . . . , c, be the nonnegative integer associated with constraint Ci .
We first enumerate each subset of the variables {x1 , . . . , xn } as the subset of essential variables
for the solution S sought. Fix such an enumerated subset X, remove the other variables from I, and
update the instance accordingly (i.e., update the constraints); without loss of generality, we will still
refer to the resulting instance as I.
By Lemma 2, there is a solution to I if and only if there is an instance I 0 on the same set of
variables as I, and whose constraints are C10 , . . . , Cc0 , such that: (1) the variables in Ci0 form a subset
of those in Ci , for i = 1, . . . , c, (2) the numbers n1 , . . . , nc are the same in both I and I 0 , and (3)
there is a solution to I 0 satisfying that for every value v, and for any two distinct variables xi , xj that
are assigned the value v in the solution for I 0 , the set of constraints that xi belongs to in I 0 is disjoint
from that that xj belongs to in I 0 .
To find the instance I 0 , we will try every possible partitioning of the variables in X into c
constraints to determine the new constraints C10 , . . . , Cc0 in I 0 . For each such partitioning π in which
Ci0 ⊆ Ci and at least ni variables are in Ci0 , for i = 1, . . . , c, we form the instance of CSP6= on the set
of variables X and the set of constraints C10 , . . . , Cc0 , and invoke the algorithm for CSP6= described
in Proposition 13 on this instance; if the algorithm returns a solution then we return the same solution
as a solution to I. If for each enumerated subset X and each enumerated partitioning π the algorithm
for CSP6= rejects, then we reject the instance I.
It is easy to see the correctness of the above algorithm. Clearly, if there is a solution to the CSP6=
instance then there is a solution to I 0 , and hence to I. This is because each constraint contains at
least ni variables, which must receive ni distinct values in the solution to the CSP6= instance, hence
satisfying each constraint Ci and satisfying I. On the other hand, if I has a solution, then there is
an enumerated partitioning of the variables in X that will correspond to the constraints in I 0 . Now
because there is a solution to I 0 that satisfies properties (1)-(3) in Lemma 2, no two variables in the
same constraint of I 0 receive the same value v in this solution (by property (3)). Therefore, this
solution will also be a solution to the constructed instance of CSP6= . This shows the correctness of
the above algorithm.
The running time of the algorithm is the time taken to enumerate all subsets of the variables, and
for each subset X, the time to enumerate all partitions of X into c constraints, and finally for each
such partition the time taken to invoke the P
CSP6= algorithm
on the resulting instance. The number

of subsets of variables of {x1 , . . . , xn } is ni=0 ni . For each subset of cardinality i, there are at
most 2ci many ways of partitioning it into c constraints. Finally, for each instance on i variables,
the CSP6= algorithm takes O∗ (2i ) time. Putting everything together, the overall running time of the
algorithm is a polynomial factor multiplied by:
227

DE

n  
X
n
i=0

i

ci

H AAN , K ANJ , & S ZEIDER

i

·2 ·2 =

n  
X
n
i=0

i

· 2(c+1)i = (2(c+1) + 1)n .

Therefore, the running time of the algorithm is O∗ ((2(cons + 1) + 1)n ) as claimed.
Corollary 2. The restriction of CSP≥ to instances in which cons = O(1) is solvable in O∗ (2O(n) )
time.
Corollary 3. The restriction of CSP≥ to instances in which cons = o(log dom) is solvable in
subexponential time.
Proof. The result follows from Theorem 6 after noticing that if cons = o(log dom) then 2cons =
domo(1) .
Proposition 17. Let d(n) = ω(1) be a proper complexity function. The restriction of CSP≥ to
instances in which cons = O(1) and dom ≥ d(n) is solvable in subexponential time, and unless the
ETH fails, the restriction of CSP≥ to instances in which cons = Ω(n) (even when dom = O(1)) is
not solvable in subexponential time.
Proof. The positive result follows from Corollary 3. The hardness result follows from the hardness
result for CSP6= in Proposition 14 (CSP6= is a special case of CSP≥ ).
The NP-hardness reduction for CSP= with a single constraint (and linear domain size), given
by Bessiere et al. (2007), which also works for CSP≤ , is actually a serf-reduction from 3-CNF-S AT.
This implies that, unless the ETH fails, neither CSP= nor CSP≤ , restricted to instances with a single
constraint and dom = O(n), is solvable in subexponential time. We show next the same result for
the restrictions of CSP≤ and CSP= to instances with a constant domain size and a linear number of
constraints:
Theorem 7. The restrictions of CSP≤ and CSP= to instances where dom = O(1) and cons =
Ω(n) are not solvable in subexponential time, unless the ETH fails.
Proof. We give a serf-reduction from 3-3-S AT to CSP≤ ; the result will then follow by Lemma 1. The
same serf-reduction also works for the case of CSP= . Take an instance ϕ of 3-3-S AT with n variables.
We construct in polynomial time an instance of CSP≤ , with cons = O(n) and dom = O(1) that
is a yes-instance if and only if ϕ ∈ 3-3-S AT. We proceed in two steps: firstly, we modify the
well-known polynomial-time reduction from 3-S AT to V ERTEX C OVER (Garey & Johnson, 1979) to
a reduction from 3-3-S AT to CSP≤ , resulting in an instance with cons = O(n) and dom = O(n);
secondly, we transform this instance of CSP≤ to an equivalent instance of CSP≤ with cons = O(n)
and dom = O(1).
We start with the first step. Let ϕ consist of the clauses c1 , . . . , cm , where ci = l1i ∨ l2i ∨ l3i
for each 1 ≤ i ≤ m. The well-known reduction to V ERTEX C OVER produces a graph G =
(V, E), containing vertices vx , vx for each variable x occurring in ϕ, and a vertex vji for each literal
occurrence, where 1 ≤ i ≤ m and 1 ≤ j ≤ 3. The variables vx and vx are adjacent, for each
variable x, and the vertices v1i , v2i , v3i form a triangle, for each 1 ≤ i ≤ m. Moreover, there is
an edge between vji and vl , where l = lji . Then ϕ is satisfiable if and only if G has a vertex
cover consisting of n + 2m vertices. More specifically, ϕ is satisfiable if and only if G has a
228

O N THE S UBEXPONENTIAL -T IME C OMPLEXITY OF CSP

vertex cover containing exactly one vertex from vx , vx for each variable x and exactly two vertices
from v1i , v2i , v3i for each 1 ≤ i ≤ m. We now construct an instance of CSP≤ as follows. For each
edge e = {v1 , v2 } ∈ E, we introduce a variable ue with domain {v1 , v2 }. Then, for each clause ci ,
we define the set Eci to consist of all edges between v1i , v2i , v3i , between vji and vli and between vli
j
j
and vli , for each 1 ≤ j ≤ 3. Then, we add a constraint ensuring that the variables ue for all
j
nine e ∈ Eci take at most 5 different values. The assignments to the variables ue that satisfy all these
constraints exactly correspond to the vertex covers of G containing exactly one vertex from vx , vx
for each variable x and exactly two vertices from v1i , v2i , v3i for each 1 ≤ i ≤ m. These particular
vertex covers, in turn, correspond exactly to truth assignments (which set one of x, x to true, for each
variable x) satisfying ϕ. The construction of such a constraint is illustrated in Figure 3.
v1i

◦

•

◦

•

◦
• v3i

◦

v1j

v2i

◦

•

◦
◦ ◦

◦

•

v2j

◦

• v3j

◦

◦

• ◦ • • ◦ • • ◦ • • ◦ • • ◦ •
vx1 vx1 vx4 vx4 vx5 vx5 vx6 vx6 vx7 vx7
Figure 3: The CSP≤ constraints corresponding to example clauses ci = (x1 ∨ x4 ∨ x5 ) and cj =
(x5 ∨x6 ∨x7 ). Variables are denoted by ◦, and values by •. The constraints are indicated by
dashed lines. The nine variables in each constraint must be assigned to at most 5 different
values. The double lines indicate an assignment to the variables satisfying the constraint
that corresponds to the truth assignment {x1 7→ >, x4 7→ ⊥, x5 7→ >, x6 7→ >, x7 7→ ⊥}.
In the second step, we transform the instance of CSP≤ in such a way that dom = O(1). In order
to do so, we will use the following observation. Whenever two vertices v1 , v2 ∈ V have the property
that there is no constraint both containing a variable ue1 for some edge e1 incident with v1 and a
variable ue2 for some edge e2 incident with v2 , then we can safely identify the domain values v1
and v2 in the instance of CSP≤ . Consequently, we can identify all m many domain values v11 , . . . , v1m
into a single value, and similarly identify all domain values v21 , . . . , v2m and v31 , . . . , v3m . Next, to
reduce dom even more, we will identify a number of domain values vx with each other (and similarly
identify their complementary values vx with each other). Consider the primal graph of ϕ, i.e., the
graph Gpϕ containing as vertices the variables of ϕ where two vertices x, x0 are adjacent if and only
if x and x0 occur together in a clause (positively or negatively). Since each variable occurs at most 3
times in ϕ, we know that the maximum degree of Gpϕ is bounded above by 8. Then, by Brooks’
Theorem (Brooks, 1941), we know that there exists a proper coloring of Gpϕ by at most 9 colors, and
that such a coloring can be computed in linear time. Take such a proper coloring c of Gpϕ . Now, for
each color b used by the coloring c, we let Xb ⊆ Var(ϕ) be the set of variables x such that c(x) = b.
Then, since c is a proper coloring of the primal graph Gpϕ of ϕ, we know that for any color b no two
variables x, x0 ∈ Xb occur together in any clause of ϕ. Therefore, for each color 1 ≤ b ≤ 3 we
can safely identify all domain values vx for x ∈ Xb with each other in the instance of CSP≤ , and
similarly we can safely identify all domain values vx for x ∈ Xb with each other. This results in an
equivalent instance of CSP≤ with cons = O(n) and dom = O(1).
229

DE

H AAN , K ANJ , & S ZEIDER

We next consider the subexponential-time complexity of CSP= , CSP≥ , and CSP≤ with respect
of the primal treewidth. We have the following tight result:
Proposition 18. The restriction of each of CSP= , CSP≥ , and CSP≤ to instances in which tw = o(n)
is solvable in subexponential time, and unless the ETH fails, the restriction of each of CSP= , CSP≥ ,
and CSP≤ to instances in which tw = Ω(n) is not solvable in subexponential time.
Proof. The proof of this proposition for each of CSP= , CSP≥ , and CSP≤ is exactly the same as the
proof of Proposition 15.
Finally, the following hardness result for CSP= and CSP≥ with respect to tw∗ follows from
Proposition 16 since CSP6= is a special case of each of CSP= and CSP≥ :
Proposition 19. Unless the ETH fails, the restriction of CSP= (resp. CSP≥ ) to instances in which
tw∗ = Ω(n) is not solvable in subexponential time.

5. Conclusion
We have provided a first analysis of the subexponential-time complexity of CSP with extensionally
represented constraints and CSP with global constraints, for the latter focusing on instances that are
composed of the fundamental global constraints AllDifferent, AtLeastNValue, AtMostNValue, and
cTable, respectively. Our results show a detailed complexity landscape for these problems under
various natural structural restrictions. In most cases, we were able to obtain tight bounds that exactly
determine the borderline between the classes of instances that can be solved in subexponential time,
and those for which the existence of subexponential-time algorithms is unlikely. There are several
ways for extending the current work such as considering other global constraints, the combination of
different global constraints, and other structural restrictions on the primal or incidence graphs.

References
Alber, J., Fernau, H., & Niedermeier, R. (2004). Parameterized complexity: exponential speed-up for
planar graph problems. Algorithmica, 52(1), 26–56.
Amir, E. (2010). Approximation algorithms for treewidth. Algorithmica, 56(4), 448–479.
Bäckström, C., & Jonsson, P. (2011). All pspace-complete planning problems are equal but some are
more equal than others. In Borrajo, D., Likhachev, M., & López, C. L. (Eds.), Proceedings
of the Fourth Annual Symposium on Combinatorial Search, SOCS 2011, Castell de Cardona,
Barcelona, Spain, July 15.16, 2011. AAAI Press.
Beigel, R., & Eppstein, D. (2005). 3-coloring in time O(1.3289n ). J. Algorithms, 54(2), 168–204.
Beldiceanu, N., Carlsson, M., & Rampon, J.-X. (2006). Global constraint catalog. Tech.
rep. T2005:08, SICS, SE-16 429 Kista, Sweden. On-line version at http://www.emn.fr/xinfo/sdemasse/gccat/.
Benhamou, B., Paris, L., & Siegel, P. (2012). Dealing with satisfiability and n-ary CSPs in a logical
framework. Journal of Automated Reasoning, 48(3), 391–417.
Bennaceur, H. (2004). A comparison between SAT and CSP techniques. Constraints, 9(2), 123–138.
230

O N THE S UBEXPONENTIAL -T IME C OMPLEXITY OF CSP

Bessiere, C., Hebrard, E., Hnich, B., Kiziltan, Z., & Walsh, T. (2006). Filtering algorithms for the
NValue constraint. Constraints, 11(4), 271–293.
Bessiere, C., Hebrard, E., Hnich, B., & Walsh, T. (2007). The complexity of reasoning with global
constraints. Constraints, 12(2), 239–259.
Björklund, A., Husfeldt, T., & Koivisto, M. (2009). Set partitioning via inclusion-exclusion. SIAM J.
Comput., 39(2), 546–563.
Brooks, R. L. (1941). On colouring the nodes of a network. Mathematical Proceedings of the
Cambridge Philosophical Society, 37, 194–197.
Calabro, C., Impagliazzo, R., & Paturi, R. (2006). A duality between clause width and clause density
for SAT. In 21st Annual IEEE Conference on Computational Complexity (CCC 2006), 16-20
July 2006, Prague, Czech Republic, pp. 252–260. IEEE Computer Society.
Chen, H., & Grohe, M. (2010). Constraint satisfaction with succinctly specified relations. J. of
Computer and System Sciences, 76(8), 847–860.
Chen, J., Kanj, I., Perkovic, L., Sedgwick, E., & Xia, G. (2007). Genus characterizes the complexity
of certain graph problems: Some tight results. Journal of Computer and System Sciences,
73(6), 892–907.
Chen, J., Chor, B., Fellows, M., Huang, X., Juedes, D., Kanj, I. A., & Xia, G. (2005). Tight lower
bounds for certain parameterized NP-hard problems. Information and Computation, 201(2),
216–231.
Chen, J., Huang, X., Kanj, I. A., & Xia, G. (2006). Strong computational lower bounds via parameterized complexity. J. of Computer and System Sciences, 72(8), 1346–1367.
Chen, J., Kanj, I. A., & Xia, G. (2009). On parameterized exponential time complexity. Theoretical
Computer Science, 410(27-29), 2641–2648.
Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2009). Introduction to Algorithms (Third
edition). The MIT Press, Cambridge, MA.
Dechter, R. (2003). Constraint Processing. Morgan Kaufmann.
Demaine, E., Fomin, F., Hajiaghayi, M., & Thilikos, D. (2005). Subexponential parameterized
algorithms on bounded-genus graphs and H-minor-free graphs. J. ACM, 52, 866–893.
Dimopoulos, Y., & Stergiou, K. (2006). Propagation in CSP and SAT. In Benhamou, F. (Ed.),
Principles and Practice of Constraint Programming - CP 2006, 12th International Conference,
CP 2006, Nantes, France, September 25-29, 2006, Proceedings, Vol. 4204 of Lecture Notes in
Computer Science, pp. 137–151. Springer Verlag.
Feder, T., & Motwani, R. (2002). Worst-case time bounds for coloring and satisfiability problems. J.
Algorithms, 45(2), 192–201.
Fellows, M. R., Fomin, F. V., Lokshtanov, D., Rosamond, F., Saurabh, S., Szeider, S., & Thomassen, C.
(2011a). On the complexity of some colorful problems parameterized by treewidth. Information
and Computation, 209(2), 143–153.
Fellows, M. R., Friedrich, T., Hermelin, D., Narodytska, N., & Rosamond, F. A. (2011b). Constraint
satisfaction problems: Convexity makes alldifferent constraints tractable. In Walsh, T. (Ed.),
IJCAI 2011, Proceedings of the 22nd International Joint Conference on Artificial Intelligence,
Barcelona, Catalonia, Spain, July 16-22, 2011, pp. 522–527. IJCAI/AAAI.
231

DE

H AAN , K ANJ , & S ZEIDER

Flum, J., & Grohe, M. (2006). Parameterized Complexity Theory, Vol. XIV of Texts in Theoretical
Computer Science. An EATCS Series. Springer Verlag, Berlin.
Freuder, E. C. (1982). A sufficient condition for backtrack-bounded search. J. of the ACM, 29(1),
24–32.
Freuder, E. C. (1990). Complexity of k-tree structured constraint satisfaction problems. In Shrobe,
H. E., Dietterich, T. G., & Swartout, W. R. (Eds.), Proceedings of the 8th National Conference
on Artificial Intelligence. Boston, Massachusetts, July 29 - August 3, 1990, 2 Volumes, pp. 4–9.
AAAI Press / The MIT Press.
Garey, M. R., & Johnson, D. R. (1979). Computers and Intractability. W. H. Freeman and Company,
New York, San Francisco.
Gaspers, S., & Szeider, S. (2014). Guarantees and limits of preprocessing in constraint satisfaction
and reasoning. Artificial Intelligence, 216, 1–19.
Ge, R. (2013). Provable Algorithms for Machine Learning Problems. Ph.D. thesis, Princeton
University.
Gottlob, G., Leone, N., & Scarcello, F. (2002). Hypertree decompositions and tractable queries. J. of
Computer and System Sciences, 64(3), 579–627.
Grandoni, F., & Italiano, G. F. (2006). Algorithms and constraint programming. In Benhamou,
F. (Ed.), Principles and Practice of Constraint Programming - CP 2006, 12th International
Conference, CP 2006, Nantes, France, September 25-29, 2006, Proceedings, Vol. 4204 of
Lecture Notes in Computer Science, pp. 2–14. Springer Verlag.
Grohe, M. (2006). The structure of tractable constraint satisfaction problems. In Kralovic, R., &
Urzyczyn, P. (Eds.), Mathematical Foundations of Computer Science 2006, 31st International
Symposium, MFCS 2006, Stará Lesná, Slovakia, August 28-September 1, 2006, Proceedings,
Vol. 4162 of Lecture Notes in Computer Science, pp. 58–72. Springer Verlag.
de Haan, R., Kanj, I., & Szeider, S. (2014). Subexponential time complexity of CSP with global
constraints. In Proceedings of CP 2014, the 20th International Conference on Principles and
Practice of Constraint Programming, Lyon, France, September 8-12, 2014. Springer Verlag.
Hnich, B., Kiziltan, Z., & Walsh, T. (2004). Combining symmetry breaking with other constraints:
Lexicographic ordering with sums. In AI&M 1-2004, Eighth International Symposium on
Artificial Intelligence and Mathematics, January 4-6, 2004, Fort Lauderdale, Florida, USA.
van Hoeve, W.-J., & Katriel, I. (2006). Global constraints. In Rossi, F., van Beek, P., & Walsh, T.
(Eds.), Handbook of Constraint Programming, chap. 6. Elsevier.
Impagliazzo, R., & Paturi, R. (2001). On the complexity of k-SAT. J. of Computer and System
Sciences, 62(2), 367–375.
Impagliazzo, R., Paturi, R., & Zane, F. (2001). Which problems have strongly exponential complexity?. J. of Computer and System Sciences, 63(4), 512–530.
Jeavons, P., & Petke, J. (2012). Local consistency and SAT-solvers. J. Artif. Intell. Res., 43, 329–351.
Jonsson, P., Lagerkvist, V., & Nordh, G. (2013). Blowing holes in various aspects of computational
problems, with applications to constraint satisfaction. In Schulte, C. (Ed.), Principles and
Practice of Constraint Programming - 19th International Conference, CP 2013, Uppsala,
232

O N THE S UBEXPONENTIAL -T IME C OMPLEXITY OF CSP

Sweden, September 16-20, 2013. Proceedings, Vol. 8124 of Lecture Notes in Computer Science,
pp. 398–414. Springer Verlag.
Kanj, I., & Szeider, S. (2013). On the subexponential time complexity of CSP. In Proceedings of the
Twenty-Seventh AAAI Conference on Artificial Intelligence. AAAI Press.
Katsirelos, G., & Walsh, T. (2007). A compression algorithm for large arity extensional constraints.
In Bessiere, C. (Ed.), Principles and Practice of Constraint Programming - CP 2007, 13th
International Conference, CP 2007, Providence, RI, USA, September 23-27, 2007, Proceedings,
Vol. 4741 of Lecture Notes in Computer Science, pp. 379–393. Springer Verlag.
Kolaitis, P. G., & Vardi, M. Y. (2000). Conjunctive-query containment and constraint satisfaction. J.
of Computer and System Sciences, 61(2), 302–332. Special issue on the Seventeenth ACM
SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems (Seattle, WA,
1998).
Kutz, M., Elbassioni, K., Katriel, I., & Mahajan, M. (2008). Simultaneous matchings: hardness and
approximation. J. of Computer and System Sciences, 74(5), 884–897.
Kwisthout, J., Bodlaender, H. L., & van der Gaag, L. C. (2010). The necessity of bounded treewidth
for efficient inference in Bayesian networks. In Coelho, H., Studer, R., & Wooldridge, M. (Eds.),
ECAI 2010 - 19th European Conference on Artificial Intelligence, Lisbon, Portugal, August
16-20, 2010, Proceedings, Vol. 215 of Frontiers in Artificial Intelligence and Applications, pp.
237–242. IOS Press.
Lokshtanov, D., Marx, D., & Saurabh, S. (2011). Lower bounds based on the exponential time
hypothesis. Bulletin of the European Association for Theoretical Computer Science, 105,
41–72.
Marx, D. (2010). Can you beat treewidth?. Theory of Computing, 6, 85–112.
Marx, D. (2013). Tractable hypergraph properties for constraint satisfaction and conjunctive queries.
J. of the ACM, 60(6), Art. 42, 51.
Moser, R. A., & Scheder, D. (2011). A full derandomization of Schöning’s k-SAT algorithm. In
STOC’11—Proceedings of the 43rd ACM Symposium on Theory of Computing, pp. 245–251.
ACM, New York.
Pachet, F., & Roy, P. (1999). Automatic generation of music programs. In Jaffar, J. (Ed.), Principles
and Practice of Constraint Programming - CP’99, 5th International Conference, Alexandria,
Virginia, USA, October 11-14, 1999, Proceedings, Vol. 1713 of Lecture Notes in Computer
Science, pp. 331–345. Springer Verlag.
Papadimitriou, C. H. (1994). Computational Complexity. Addison-Wesley.
Papadimitriou, C. H., & Yannakakis, M. (1991). Optimization, approximation, and complexity
classes. J. of Computer and System Sciences, 43(3), 425–440.
Papadimitriou, C. H., & Yannakakis, M. (1999). On the complexity of database queries. J. of
Computer and System Sciences, 58(3), 407–427.
Razgon, I. (2006). Complexity analysis of heuristic CSP search algorithms. In Hnich, B., Carlsson,
M., Fages, F., & Rossi, F. (Eds.), Recent Advances in Constraints, Joint ERCIM/CoLogNET
International Workshop on Constraint Solving and Constraint Logic Programming, CSCLP
233

DE

H AAN , K ANJ , & S ZEIDER

2005, Uppsala, Sweden, June 20-22, 2005, Revised Selected and Invited Papers, Vol. 3978 of
Lecture Notes in Computer Science, pp. 88–99. Springer Verlag.
Régin, J.-C. (1994). A filtering algorithm for constraints of difference in CSPs. In Hayes-Roth, B.,
& Korf, R. E. (Eds.), Proceedings of the 12th National Conference on Artificial Intelligence,
Seattle, WA, USA, July 31 - August 4, 1994, Volume 1, pp. 362–367. AAAI Press / The MIT
Press.
Régin, J.-C. (1995). Développement d’outils algorithmiques pour l’Intelligence Artificielle. Ph.D.
thesis, Montpellier II. in French.
Régin, J.-C. (2011). Global constraints: A survey. In van Hentenryck, P., & Milano, M. (Eds.),
Hybrid Optimization: The Ten Years of CPAIOR, Vol. 45 of Optimization and Its Applications,
chap. 3, pp. 63–134. Springer Verlag.
Régin, J.-C., & Rueher, M. (2000). A global constraint combining a sum constraint and difference
constraints. In Dechter, R. (Ed.), Principles and Practice of Constraint Programming - CP
2000, 6th International Conference, Singapore, September 18-21, 2000, Proceedings, Vol.
1894 of Lecture Notes in Computer Science, pp. 384–395. Springer Verlag.
Rossi, F., van Beek, P., & Walsh, T. (Eds.). (2006). Handbook of Constraint Programming. Elsevier.
Samer, M., & Szeider, S. (2010). Constraint satisfaction with bounded treewidth revisited. J. of
Computer and System Sciences, 76(2), 103–114.
Schöning, U. (1999). A probabilistic algorithm for k-SAT and constraint satisfaction problems. In
40th Annual Symposium on Foundations of Computer Science (New York, 1999), pp. 410–414.
IEEE Computer Soc., Los Alamitos, CA.
Schuler, R. (2005). An algorithm for the satisfiability problem of formulas in conjunctive normal
form. J. Algorithms, 54(1), 40–44.
Traxler, P. (2008). The time complexity of constraint satisfaction. In Grohe, M., & Niedermeier, R.
(Eds.), Parameterized and Exact Computation, Third International Workshop, IWPEC 2008,
Victoria, Canada, May 14-16, 2008. Proceedings, Vol. 5018 of Lecture Notes in Computer
Science, pp. 190–201. Springer Verlag.

234

Journal of Artificial Intelligence Research 52 (2015) 97-169

Submitted 05/14; published 01/15

Deterministic Oversubscription Planning as Heuristic Search:
Abstractions and Reformulations
Carmel Domshlak
Vitaly Mirkis

dcarmel@ie.technion.ac.il
mirkis80@gmail.com

Faculty of Industrial Engineering & Management,
Technion - Israel Institute of Technology,
Haifa, Israel

Abstract
While in classical planning the objective is to achieve one of the equally attractive goal
states at as low total action cost as possible, the objective in deterministic oversubscription
planning (OSP) is to achieve an as valuable as possible subset of goals within a fixed
allowance of the total action cost. Although numerous applications in various fields share
the latter objective, no substantial algorithmic advances have been made in deterministic
OSP. Tracing the key sources of progress in classical planning, we identify a severe lack of
effective domain-independent approximations for OSP.
With our focus here on optimal planning, our goal is to bridge this gap. Two classes
of approximation techniques have been found especially useful in the context of optimal
classical planning: those based on state-space abstractions and those based on logical landmarks for goal reachability. The question we study here is whether some similar-in-spirit,
yet possibly mathematically different, approximation techniques can be developed for OSP.
In the context of abstractions, we define the notion of additive abstractions for OSP, study
the complexity of deriving effective abstractions from a rich space of hypotheses, and reveal
some substantial, empirically relevant islands of tractability. In the context of landmarks,
we show how standard goal-reachability landmarks of certain classical planning tasks can
be compiled into the OSP task of interest, resulting in an equivalent OSP task with a lower
cost allowance, and thus with a smaller search space. Our empirical evaluation confirms the
effectiveness of the proposed techniques, and opens a wide gate for further developments
in oversubscription planning.

1. Introduction
The tools of automated action planning allow autonomous systems selecting a course of
action “to get things done.” Deterministic planning is probably the most basic, and thus
the most fundamental, setting of automated action planning (Russell & Norvig, 2009). It
can be viewed as the problem of finding trajectories of interest in large-scale yet concisely
represented state-transition systems. Computational approaches to deterministic planning
vary around the way those “trajectories of interest” are defined.
The basic structure of acting in situations with underconstrained or overconstrained
resources is respectively captured by what these days is called “classical” deterministic
planning (Fikes & Nilsson, 1971), and by what Smith (2004) termed “oversubscription”
deterministic planning (OSP). In classical planning, the task is to find the most cost-effective
trajectory possible to a goal-satisfying state. In oversubscription planning, the task is to
find the most goal-effective (or valuable) state possible via a cost-satisfying trajectory. In
c
2015
AI Access Foundation. All rights reserved.

Domshlak & Mirkis

optimal classical planning and in optimal OSP, the tasks are further constrained to finding
only most cost-effective trajectories and most goal-effective states, respectively. Classical
planning and OSP can be viewed as foundational variants of deterministic planning, with
many other variants, such as net-benefit planning and cost-bounded planning, being defined
in terms of mixing and relaxing the two.1
While OSP has been extensively advocated over the years, the theory and practice of
classical planning have been studied and advanced much more intensively. The remarkable
success and continuing progress of heuristic-search solvers for classical planning is one notable example. Primary enablers of this success are the advances in domain-independent
approximations, or heuristics, of the cost needed to achieve a goal state from a given state.
It is thus possible that having a similarly rich palette of effective heuristic functions for
OSP would advance the state of the art in that problem.
Two classes of approximation techniques have been found especially useful in the context of optimal classical planning: those based on state-space abstractions (Edelkamp, 2001;
Haslum, Botea, Helmert, Bonet, & Koenig, 2007; Helmert, Haslum, Hoffmann, & Nissim,
2014; Katz & Domshlak, 2010a) and those based on logical landmarks for goal reachability (Karpas & Domshlak, 2009; Helmert & Domshlak, 2009; Domshlak, Katz, & Lefler,
2012; Bonet & Helmert, 2010; Pommerening & Helmert, 2013). Considering OSP as heuristic search, a question is then whether some similar-in-spirit, yet possibly mathematically
different, approximation techniques can be developed for heuristic-search OSP. This is precisely the question we study here.
• Starting with the most basic question of what state-space abstractions for OSP actually are, we show that the very notion of abstraction differs substantially for classical planning and OSP. Hence, first we define (additive) abstractions and abstraction
heuristics for OSP. We then investigate the computational complexity of deriving
effective abstraction heuristics in the scope of homomorphic abstraction skeletons,
paired with cost, value, and budget partitions. Along with revealing some significant
islands of tractability, this study exposes an interesting interplay between knapsackstyle problems of combinatorial optimization, continuous convex optimization, and
certain principles borrowed from explicit abstractions for classical planning.
• We introduce and study ε-landmarks, the logical properties of OSP plans that achieve
valuable states. We show that ε-landmarks correspond to regular goal-reachability
landmarks of certain classical planning tasks that can be straightforwardly derived
from the OSP tasks of interest. We then show how such ε-landmarks can be compiled
back into the OSP task of interest, resulting in an equivalent OSP task, but with a
stricter cost satisfaction constraint, and thus with a smaller effective search space.
Finally, we show how such landmark-based task enrichment can be combined in a
mutually stratifying way with the best-first branch-and-bound search used for OSP
planning, resulting in an incremental procedure that interleaves search and landmark
discovery. The entire framework is independent of the OSP planner specifics, and in
particular, of the heuristic functions it employs.
1. The connections and differences between some popular variants of deterministic planning are discussed
in Section 2.

98

On Oversubscription Planning as Heuristic Search

Our empirical evaluation on a large set of OSP tasks confirms the effectiveness of the proposed techniques. Moreover, to the best of our knowledge, our implementation constitutes
the first domain-independent solver for optimal OSP, and we hope that more advances in
this important computational problem will follow.
This work is a revision and extension of the formulations and results presented by the
authors at ICAPS-2013 and ECAI-2014 (Mirkis & Domshlak, 2013, 2014). The paper is
structured as follows. In Section 2 we formulate a general model of deterministic planning,
define several variants of deterministic planning in terms of this model, and, in particular,
show that oversubscription planning differs conceptually not only from classical planning,
but also from other popular variants of deterministic planning such as net-benefit planning
and cost-bounded planning. We also specify a simple model representation language for
OSP, as well as provide the essential background on heuristic search, and, in particular,
on OSP as heuristic search. Sections 3 and 4 are devoted, respectively, to abstractions
and abstraction approximations for OSP. Section 5 is devoted to exploiting reachability
landmarks in OSP tasks. In Section 6 we conclude and discuss some promising directions
for future work. For the sake of readability, some of the proofs are relegated to Appendix A,
and some details of the empirical results are relegated to Appendix B.

2. Background
As mentioned in the introduction, specific variants of deterministic planning differ in the
way the interest and preference over trajectories are defined. For instance, in “classical
planning” (Fikes & Nilsson, 1971), a trajectory is of interest if it connects a designated initial
state to one of the designated goal states, with the preference being towards trajectories
with lower total cost of the transitions along them. Among other, “non-classical” variants
of deterministic planning are
• oversubscription planning (Smith, 2004), the topic of interest here;
• net-benefit planning (van den Briel, Sanchez, Do, & Kambhampati, 2004; Sanchez
& Kambhampati, 2005; Baier, Bacchus, & McIlraith, 2009; Bonet & Geffner, 2008;
Benton, Do, & Kambhampati, 2009; Coles & Coles, 2011; Keyder & Geffner, 2009);
• cost-bounded (also known as resource-constrained) planning (Haslum & Geffner, 2001;
Hoffmann, Gomes, Selman, & Kautz, 2007; Gerevini, Saetti, & Serina, 2008; Thayer &
Ruml, 2011; Thayer, Stern, Felner, & Ruml, 2012; Haslum, 2013; Nakhost, Hoffmann,
& Müller, 2012); and
• planning with preferences over temporal properties of the trajectories (Baier et al.,
2009; Gerevini, Haslum, Long, Saetti, & Dimopoulos, 2009; Benton, Coles, & Coles,
2012).
Interestingly, while working on this paper, we have learned that quite a few different
variants of deterministic planning are often collectively referred to as “oversubscription
planning”. As a result, the difference between them in terms of expressiveness is not necessarily clear, and thus, the relationship between what we do here and what has already been
done in the collective sense of “oversubscription planning” is not always apparent. This is
the issue we will address first.
99

Domshlak & Mirkis

2.1 Models
Adopting and extending the notation of Geffner and Bonet (2013), we can view many
variants of deterministic planning, including classical planning, as well as many popular
non-classical variants, as special cases of a state model
M = hS, s0 , u, O, ϕ, c, Qi

(1)

with:
• a finite set of states S,
• an initial state s0 ∈ S,
• a state value function u : S 7→ R0+ ∪ {−∞},
• operators O(s) ⊆ O applicable in each state s ∈ S,
• a deterministic state transition function ϕ(s, o) such that s0 = ϕ(s, o) stands for the
state resulting from applying o ∈ O(s) in s,
• an operator cost function c : O → R0+ , and
• a quality measure Q : P 7→ R ∪ {−∞}, where P is the (infinite) set of trajectories
from s0 along operators O. A trajectory in P is a sequence of operators ho1 , . . . , on i
such that o1 ∈ O(s0 ) and, inductively, oi ∈ O(ϕ(ϕ(. . . ϕ(s0 , o1 ) . . . , oi−2 ), oi−1 )).
In this model, any trajectory π ∈ P is a solution, with preference towards solutions of
higher quality. In what
P follows, sJπK stands for the end-state of a trajectory π applied at
state s, and c(π) = o∈π c(o) is the additive cost of π. Likewise, the graphical skeleton
GM = hS, Tϕ , Oi of a model M refers to the edge-annotated, unweighted digraph induced
by M where the nodes of GM are the states S, the edge labels are the operators O, and Tϕ
contains an edge from s to s0 labeled with o iff o ∈ O(s) and s0 = ϕ(s, o).
First, consider a quality measure
Q+ (π) = u(sJπK) − c(π).

(2)

This measure assumes that state values and operator costs are comparable, and thus represents a tradeoff between the value of the end-state and the cost of the trajectory. Consider
now a fragment of the state model (1), instances of which all have the quality measure Q+ ,
and for each instance, the value function
(
ε,
s ∈ Sgoal
u(s) =
(3)
−∞, otherwise
partitions the state space into Sgoal ⊆ S, on which u takes a finite value ε ≥ 0, and the
rest of the states, on which u takes the value of −∞. Finding an optimal solution for an
instance M of this fragment corresponds to finding a shortest path from s0 to a single node
s∗ in an edge-weighted digraph G, which is obtained from GM by (i) annotating the edges
of the latter with costs c, and (ii) adding a dummy node s∗ and zero-cost edges from all
100

On Oversubscription Planning as Heuristic Search

constraint

preference

Net Benefit

Oversubscription

constraint

End-state value

Action cost
preference

Classical

Cost-bounded

Figure 1: Schematic classification of four deterministic planning models along the strictness
with which they approach the cost of operator sequences and the value of the
operator sequence end-states. White blocks are for planning models that can be
solved as single-source single-target shortest path problems.

goal nodes s ∈ Sgoal to s∗ . While specified in a non-canonical way, this fragment can be
easily verified to correspond to the model of classical planning, with Sgoal being the classical
planning goal states.
Staying with the quality measure Q+ and removing now the requirement on u to comply
with Eq. 3, we obtain a fragment that generalizes classical planning, and constitutes the
basic model of what is called net-benefit planning (Sanchez & Kambhampati, 2005). Importantly, any instance M of this fragment can be reduced to finding a shortest path from
a single node s0 to a single node s∗ in an edge-weighted digraph G, obtained from GM by
(i) annotating edges of GM with costs c, (ii) adding a dummy node s∗ andPedges from all
nodes s ∈ S to s∗ , and (ii) setting the cost of each such new edge (s, s∗ ) to s0 ∈S\{s} u(s0 ).
This reduction works because net-value maximization over the end state s is equivalent
to minimization of the net-loss of giving up on all the other possible end states. This
same basic idea underlies Keyder and Geffner’s (2009) scheme for compiling certain standard representation formalisms for net-benefit planning into a standard classical planning
formalism.2
Consider now an alternative quality measure
(
u(sJπK), c(π) ≤ b
Q (π) =
,
−∞,
otherwise
b

(4)

2. It is worth noting that the wost-case complexity equivalence between classical planning and net-benefit
planning has been shown prior to the work of Keyder and Geffner (2009) by van den Briel et al. (2004).
However, this equivalence was not prescriptive enough to suggest practically effective compilations of
compactly represented net-benefit planning tasks to classical planning tasks.

101

Domshlak & Mirkis

where b ∈ R0+ is a predefined bound on the cost of the trajectories. The fragment of the
basic model, instances of which are characterized by having the quality measure Qb and
the “ε or −∞” value functions as in Eq. 3, constitutes the model of what is called costbounded planning (Thayer & Ruml, 2011). Here as well, finding an optimal solution for a
problem instance M corresponds to finding a shortest path from s0 to s∗ in an edge-weighted
digraph G, which is derived from GM identically to the case of classical planning.3 This,
in particular, explains why it is only natural for heuristic-search methods for cost-bounded
planning to exploit heuristics developed for classical planning (Haslum, 2013).
We now arrive to a fourth fragment of the basic model. Staying with the quality measure Qb and removing the requirement on u to comply with Eq. 3, we obtain a fragment
that generalizes cost-bounded planning, and constitutes the model of oversubscription planning (Smith, 2004). As illustrated in Figure 1, the hard constraint of classical planning
translates to soft preference in OSP, and the hard constraint of OSP translates to soft preference in classical planning. However, in contrast to cost-optimal, net-benefit, and classical
planning, this fragment does not appear to be reducible to the single-source single-target
shortest path problem. In terms of the digraph G obtained from GM by annotating the
edges with costs c, finding an optimal solution to an instance of oversubscription planning
requires (i) finding shortest paths from s0 to all states s ∈ S with u(s) > 0, (ii) filtering out
from these states those that are not reachable from s0 within the cost allowance b, and (iii)
selecting from the remaining states a state that maximizes u.
This contrast between oversubscription planning and the three other popular variants of
deterministic planning discussed above has at least two important implications. First, while
a single shortest path can be searched for using best-first forward search procedures such
as A∗ , searching for shortest paths to numerous targets simultaneously requires a different,
more exhaustive, forward search framework such as branch-and-bound. Second, net-benefit
and cost-bounded planning clearly have the potential to (directly or indirectly) reuse the rich
toolbox of heuristic functions developed over the years for classical planning. In contrast,
due to the differences in the underlying computational model, the same is not necessarily
true for oversubscription planning, and examining the prospects of heuristic functions in
OSP is precisely the focus of our work here.
2.2 Notation
For k ∈ N+ , by [k] we denote the set {1, 2, . . . , k}. The indicator function of a subset A of
a set X is a function 1A : X → {0, 1} defined as 1A (x) = 1 if x ∈ A and 1A (x) = 0 if x 6∈ A.
Following Nebel (2000), when we talk about the size of a mathematically well-defined object
x, symbolically ||x||, we mean the size of a (reasonable) encoding of x. An assignment of a
variable v to value d is denoted by hv/di; we often refer to such single variable assignments
as propositions.

3. Strictly speaking, once a shortest path π from s0 to s∗ is found, it should still be checked against the
cost bound b. This test, however, is local to π, and problem solving finishes independently of the test’s
outcome.

102

On Oversubscription Planning as Heuristic Search

2.3 Model Representation
Departing from a very general model of oversubscription planning, in what follows we restrict our attention to instances of that model that are compactly representable in a language
close to the sas+ language for classical planning (Bäckström & Klein, 1991; Bäckström &
Nebel, 1995). In this language, a deterministic oversubscription planning (OSP) task
is given by a sextuple
Π = hV, s0 , u; O, c, bi,

(5)

where
(1) V = {v1 , . . . , vn } is a finite set of finite-domain state variables, with each complete
assignment to V representing a state, and S = dom(v1 ) × · · · × dom(vn ) being the state
space of the task;
(2) s0 ∈ S is a designated initial state;
(3) u is an efficiently computable state value function u : S → R0+ ;
(4) O is a finite set of operators, with each operator o ∈ O being represented by a pair
hpre(o), eff(o)i of partial assignments to V , called preconditions and effects of o, respectively;
(5) c : O → R0+ is an operator cost function;
(6) b ∈ R0+ is a cost budget allowed for the task.
Now consider the semantics of such a task description in terms of 
our basic model. An

OSP task Π = hV, s0 , u; O, c, bi can be said to induce the model MΠ = S, s0 , u, O, ϕ, c, Qb ,
with Qb being the quality measure (4) instantiated with the Π’s budget b, and the transition
function ϕ being specified as follows. For a partial assignment p to V , let V(p) ⊆ V denote
the subset of variables instantiated by p, and, for v ∈ V(p), p[v] denote the value provided
by p to the variable v. Similarly to the classical planning semantics of sas+ , operator o
is applicable in a state s iff s[v] = pre(o)[v] for all v ∈ V(pre(o)). Applying o changes the
value of each v ∈ V(eff(o)) to eff(o)[v], and the resulting state is denoted by sJoK. This
notation is only defined if o is applicable in s. Denoting an empty sequence of operators by ,
applying a sequence of operators ho1 , . . . , om i to a state s is defined inductively as sJK := s
and sJo1 , . . . , oj K := sJo1 , . . . , oj−1 KJoj K. An operator sequence π is called an s-plan if it is
applicable in state s and Qb (π) 6= −∞, that is, c(π) ≤ b.
Some
S auxiliary notation is used later on: For an OSP task Π = hV, s0 , u; O, c, bi, by
D = v∈V dom(v) we denote the union of the (uniquely labeled) state-variable domains.
For a state s and a proposition hv/di ∈ D, hv/di ∈ s is used as a shortcut notation for
s[v] = d.
An example of a simple OSP task in Figure 2 is used to illustrate this model representation. In this example, a truck is initially at location A, and it can drive (only) from location
A to location B and from location B to location C. Two packages, x and y, are initially
at location B. When a package and the truck are in the same location, the package can
be loaded onto the truck, and when a package is on the truck, it can be unloaded at the
103

Domshlak & Mirkis

x
y
A

B

C

(a)
oi
pre(oi )
eff(oi )

driveAB
i=1
{ht/Ai}
{ht/Bi}

driveBC
i=2
{ht/Bi}
{ht/Ci}

loadBx
i=3
{ht/Bi , hx/Bi}
{hx/T i}

loadBy
i=4
{ht/Bi , hy/Bi}
{hy/T i}

unloadCx
i=5
{ht/Ci , hx/T i}
{hx/Ci}

oi
pre(oi )
eff(oi )

unloadBx
i=6
{ht/Bi , hx/T i}
{hx/Bi}

unloadBy
i=7
{ht/Bi , hy/T i}
{hy/Bi}

unloadCy
i=8
{ht/Ci , hy/T i}
{hy/Ci}

loadCx
i=9
{ht/Ci , hx/Ci}
{hx/T i}

loadCy
i = 10
{ht/Ci , hy/Ci}
{hy/T i}

(b)
u=1

CBB

o2
ABB

o1

BBB

BTB
o6
o3
o7
o4
BBT

CTB

o9
o5

CCB

BTT

o2

CTT

o2
o7
o4
o3
o6
o2

o10
o8
u=1

o10
o8

CBC

CTB

o9
o5

CCB

BTT

o2

CTT

CBT

u=1

o9
o5

CTC

u=1
CCT

o9 u=2
o5
CCC

o10
o8

(c)
u=1

CBB

o2
ABB

o1

BBB

BTB
o6
o3
o7
o4
BBT

o2
o7
o4
o3
o6
o2

o10
o8
u=1

CBT

o10
o8

u=1

o9
o5

CTC

u=1
CCT

o9 u=2
o5
CCC

o10
o8

CBC

(d)

Figure 2: A simple running example of an OSP task, with (a) illustrating the story, (b) listing the operators, and (c)-(d) depicting the graphical skeleton of the induced state
model; (c) shows the region of the graphical skeleton GMΠ that is structurally
reachable from the initial state ABB, and the grayed area in (d) corresponds to
the sub-region that cannot be reached from the initial state under the budget
b = 4.

truck’s current location. Each (drive, load, and unload) operator in the task costs one unit
of cost, and the cost budget is set to four units of cost. Finally, a value of one (value unit)
is earned for each package present at location C.
This OSP task Π is described here using three state variables V = {t, x, y}, with
dom(t) = {A, B, C} and dom(x) = dom(y) = {A, B, C, T }, corresponding to the possible
locations of the truck and the two packages, respectively.

 The operator set O = {o1 , . . . , o10 }
is detailed in Figure 2(b). In the state model MΠ = S, s0 , u, O, ϕ, c, Qb induced by this
104

On Oversubscription Planning as Heuristic Search

BFBB (Π = hV, s0 , u; O, c, bi)
open := new max-heap ordered by f (n) = h(shni, b − g(n))
initialize best solution n∗ := make-root-node(s0 )
open.insert(n∗ )
closed:= ∅;
best-cost:= 0
while not open.empty()
n := open.pop-max()
if f (n) ≤ u(shn∗ i): break
if u(shni) > u(shn∗ i): update n∗ := n
if shni 6∈ closed or g(n) < best-cost(shni):
closed:= closed ∪ {shni}
best-cost(shni) := g(n)
foreach o ∈ O(shni):
n0 := make-node(shniJoK, n)
if g(n0 ) > b or f (n0 ) ≤ u(shn∗ i): continue
open.insert(n0 )
∗
return n
Figure 3: Best-first branch-and-bound (BFBB) search for OSP
task, we have S = dom(t)×dom(x)×dom(y), the initial state s0 = ABB (with the three letters in the names of the states capturing the three components of the domain cross-product),
operator cost c(oi ) = 1 for all operators oi , cost budget b = 4, and state values


1, s ∈ {?AC, ?BC, ?CA, ?CB}
u(s) = 2, s ∈ {?CC}


0, otherwise

.

The graphical skeleton GMΠ is depicted in Figures 2(c) and 2(d): Figure 2(c) shows the
region of the graphical skeleton GMΠ that is structurally reachable from the initial state
ABB, and the grayed area in Figure 2(d) corresponds to the sub-region that cannot be
reached from the initial state under the budget b = 4.
2.4 OSP as Heuristic Search
The two major ingredients of any heuristic-search planner are its search algorithm and
heuristic function. In classical planning, the heuristic is typically a function h : S → R0+ ∪
{∞}, with h(s) estimating the cost h∗ (s) of optimal s-plans. A heuristic h is admissible
if it is lower-bounding, that is, h(s) ≤ h∗ (s) for all states s. All common heuristic search
algorithms for optimal classical planning, such as A∗ , require admissible heuristics.
In contrast, a heuristic in OSP is a function h : S × R0+ → R0+ , with h(s, b) estimating
the value h∗ (s, b) of optimal s-plans under cost budget b. A heuristic h is admissible if it is
upper-bounding, that is, h(s, b) ≥ h∗ (s, b) for all states s and all cost budgets b. Here as well,
105

Domshlak & Mirkis

search algorithms for optimal OSP, such as best-first branch-and-bound (BFBB),4 require
admissible heuristics for pruning search branches without violating solution optimality.
Figure 3 depicts a pseudo-code description of BFBB for OSP; shni there denotes the state
associated with search node n, and cost-so-far g(n) is the total cost of the action sequence
associated with n. Unlike in A∗ , the order in which the nodes are selected from the OPEN
list does not affect the optimality guarantees (though it may, of course, seriously affect the
empirical efficiency of the search). In Figure 3, the ordering of OPEN corresponds to the
decreasing order of h(shni, b − g(n)). The duplicate detection and reopening mechanisms
in BFBB are similar to those in A∗ (Pearl, 1984). In addition, BFBB maintains the best
solution n∗ found so far and uses it to prune all generated nodes evaluated no higher than
u(shn∗ i). Likewise, complying with the semantics of OSP, all generated nodes n with costso-far g(n) higher than the problem’s budget b are also immediately pruned. When the
OPEN list becomes empty or the node n selected from the list promises less than the lower
bound, BFBB returns (the plan associated with) the best solution n∗ . If h is admissible,
that is, the h-based pruning of the generated nodes is sound, then the returned plan is
guaranteed to be optimal.
Let us now return to the heuristic functions. In domain-independent planning they
should be automatically derived from the description of the model in the language of choice.
A useful heuristic function must be both efficiently computable from the description of the
model, as well as relatively accurate in its estimates. Improving the accuracy of a heuristic
function without substantially worsening the time complexity of computing it translates
into faster search for plans.
In classical planning, numerous approximation techniques, such as monotonic relaxation (Bonet & Geffner, 2001, 2001; Hoffmann & Nebel, 2001), critical trees (Haslum
& Geffner, 2000), network flow (van den Briel, Benton, Kambhampati, & Vossen, 2007;
Bonet, 2013), logical landmarks for goal reachability (Richter, Helmert, & Westphal, 2008;
Karpas & Domshlak, 2009; Helmert & Domshlak, 2009; Bonet & Helmert, 2010), and
abstractions (Edelkamp, 2001; Helmert, Haslum, & Hoffmann, 2007; Katz & Domshlak,
2010a), have been translated to effective heuristic functions. Likewise, different heuristics
for classical planning can also be combined into their point-wise maximizing and/or additive
ensembles (Edelkamp, 2001; Haslum, Bonet, & Geffner, 2005; Coles, Fox, Long, & Smith,
2008; Katz & Domshlak, 2010b; Helmert & Domshlak, 2009).
In contrast, development of heuristic functions for OSP has not progressed beyond the
initial ideas of Smith (2004). In principle, the reduction of Keyder and Geffner (2009) from
net-benefit to classical planning can be used to reduce OSP to classical planning with realvalued state variables (Koehler, 1998; Helmert, 2002; Fox & Long, 2003; Hoffmann, 2003;
Gerevini, Saetti, & Serina, 2003; Gerevini et al., 2008; Edelkamp, 2003; Dvorak & Barták,
2010; Coles, Coles, Fox, & Long, 2013). So far, however, progress in heuristic-search classical
planning with numeric state variables has mostly been achieved around direct extensions
of delete relaxation heuristics via “numeric relaxed planning graphs” (Hoffmann, 2003;
Edelkamp, 2003; Gerevini et al., 2003, 2008). Unfortunately, these heuristics do not preserve
information on consumable resources such as budgeted operator cost in oversubscription
4. BFBB is also extensively used for net-benefit planning (Benton, van den Briel, & Kambhampati, 2007;
Coles & Coles, 2011; Do, Benton, van den Briel, & Kambhampati, 2007), as well as some other variants
of deterministic planning (Bonet & Geffner, 2008; Brafman & Chernyavsky, 2005).

106

On Oversubscription Planning as Heuristic Search

planning: the “negative” action effects that decrease the values of numeric variables are
ignored, possibly up to some special handling of so-called “cyclic resource transfer” (Coles
et al., 2013).
As a first step in overcoming the lack of effective heuristics for OSP, in the next section
we study abstractions for OSP, from their very definition and properties, to the prospects
of deriving admissible abstraction heuristics. In Section 5 we then study the prospects of
adapting to OSP the toolbox of logical landmarks for goal reachability. To date, abstractions
and landmarks are responsible for most state-of-the-art admissible heuristics for classical
planning, and thus are of special interest here.

3. Abstractions
The term “abstraction” is usually associated with simplifying the original model, factoring
out details less crucial in the given context. Context determines which details can be reduced, which should better preserved, and how the abstraction is created and used (Cousot
& Cousot, 1992; Clarke, Grumberg, & Peled, 1999; Helmert et al., 2014; Domshlak, Hoffmann, & Sabharwal, 2009; Katz & Domshlak, 2010b). In general terms, abstracting a model
M corresponds to associating it with a set of (typically computationally more attractive)
models M1 , . . . , Mk such that solutions to these models satisfy certain properties with respect to the solutions of M . In particular, in deterministic planning as heuristic search,
abstractions are used to derive heuristic estimates for the states of the model of interest M :
Given a state s of M and an abstraction M1 , . . . , Mk ,
(1) s is mapped to some “abstract states” s1 ∈ M1 , . . . , sk ∈ Mk ,
(2) the k models of the abstraction are solved for the respective initial states s1 , . . . , sk ,
and
(3) an aggregation of the quality of the resulting k solutions is used as the heuristic estimate
for s.
Sometimes schematically and sometimes precisely, the process of constructing abstractions as above for a state model M = hS, s0 , u, O, ϕ, c, Qi can be seen as a two-step process
of
(1) selecting an abstraction skeleton AS = {(G1 , α1 ), . . . , (Gk , αk )}, where each pair
(Gi , αi ) comprises an edge-labeled digraph Gi = hSi , Ti , Oi i, with nodes Si , edges Ti ,
and edge labels Oi , and a state mapping αi : S → Si , and
(2) extending AS to a set of abstract models M = {M1 , . . . , Mk }, such that, for i ∈ [k],
Gi is the graphical skeleton GMi of Mi .
To qualify as a valid abstraction of the model M , the resulting set of abstract models
M should satisfy certain conditions specific to the variant of the deterministic planning
under consideration. For instance, the optimal solutions of abstract models in classical
planning are required to be at most as costly as the respective solutions in the original
models, with that constraint to be satisfied by individual abstract models in case of maxaggregation (Pearl, 1984), or by the k abstract models jointly, in case of additive abstractions (Yang, Culberson, Holte, Zahavi, & Felner, 2008; Katz & Domshlak, 2010b). As we
107

Domshlak & Mirkis

now show, the concept of abstractions in general, and additive abstractions in particular, is
very different in OSP, and, for better or for worse, has many more degrees of freedom than
the respective concepts in classical planning.
3.1 Abstractions of OSP Problems
Given
an abstraction


 skeleton AS = {(G1 , α1 ), . . . , (Gk , αk )} for an OSP state model M =
S, s0 , u, O, ϕ, c, Qb , each digraph Gi = hSi , Ti , Oi i implicitly defines a set of OSP state
models consistent with it. This set is given by Ci × Ui × Bi , where Ci is the set of all
functions from operators Oi to R0+ , Ui is the set of all functions from states Si to R0+ ,
and Bi = R0+ . In these terms, each point (c, u, b) ∈ Ci × Ui × Bi induces an OSP model
consistent with Gi , and vice versa.
Connecting between these sets of models for all the digraphs in AS, let
C = C1 × · · · × Ck ,
U = U1 × · · · × Uk ,
B = B1 × · · · × Bk .
For each state s ∈ M , every point (c, u, b) ∈ C × U × B induces a set of models
n
o
(c,u,b)
(c,u,b)
M(c,u,b) = M1
, . . . , Mk
,
(c,u,b)

with Mi




= Si , αi (s0 ), u[i], Oi , ϕi , c[i], Qb[i] :

— the states Si and operators Oi correspond to the nodes and edge labels of Gi ;
— the transition function ϕi (s, o) = s0 iff Ti contains an arc from s to s0 labeled with
o ∈ Oi ;
— the initial state αi (s0 ) is determined by the initial state s0 and the state mapping αi ;
and
— the operator cost function, state value function, and cost budget are all directly determined by the choice of (c, u, b).
For some choices (c, u, b) from C × U × B, the induced sets of models M(c,u,b) can be
used for deriving admissible estimates for the state of interest s0 , while others cannot. The
respective qualification is defined below.
Definition
 1 (Additive OSP
 Abstraction)
Let M = S, s0 , u, O, ϕ, c, Qb be an OSP model and AS = {(G1 , α1 ), . . . , (G1 , αk )} be
an abstraction skeleton for M . For (c, u, b) ∈ C × U × B, M(c,u,b) is an (additive)
abstraction for M , denoted as
M(c,u,b) AAS M,
if and only if
def

h∗ (s0 , b) ≤ hM(c,u,b) (s0 , b) =

X

h∗i (αi (s0 ), b[i]),

i∈[k]

that is, when hM(c,u,b) (s0 , b) is an admissible estimate of h∗ (s0 , b).
108

On Oversubscription Planning as Heuristic Search

GM

= s1
o1 |||
||
||
/ s2
s0
o2

o3

/ s3

G1

G2

s
= 2;1
o1 zz
z
zz
zz

o1

o5
o4

/ s4

s1;0

o2

/ s1;2

(a)

o4

/ s 1;4

s2;0

o2

o3

/ s2;3
o5



/ s2;4

(b)
Figure 4: Illustration for our running example

In simple terms, a set of models forms an additive OSP abstraction if jointly the models
in it do not underestimate the value that can be obtained from the initial state, within the
5 For example, let G
given cost budget.
4a be the graphical skeleton of a state
M in Figure 


model M = {s0 , . . . , s4 }, s0 , u, {o1 , . . . , o5 }, ϕ, c, Qb , with c(oi ) = 1 for all operators oi ,
b = 2, and u(si ) = 1{4} (i). Let AS = {(G1 , α1 ), (G2 , α2 )} be an abstraction skeleton for
M , with G1 and G2 as in Figure 4b and with state mappings
(
s1;4 , i ∈ {1, 3}
α1 (si ) =
,
s1;i , otherwise
(
s2;4 , i = 2
α2 (si ) =
.
s2;i , otherwise
Consider a set of models M(c,u,b) , with constant c[1](·) = c[2](·) = 1, b[1] = b[2] = 2, and,
for j ∈ [2], u[i](si;j ) = 1{4} (j). The optimal plan s0 -plan for M is π = h(s0 , o2 , s2 ), (s2 , o4 , s4 )i,
(c,u,b)

with Qb (π) = 1, while the optimal α1 (s0 )-plan for M1
is π1 = h(s1;0 , o1 , s1;4 )i, with
(c,u,b)
b[1]
Q (π1 ) = 1, and the optimal α2 (s0 )-plan for M2
is π2 = h(s2;0 , o2 , s2;4 )i, with
Qb[2] (π2 ) = 1. Since
h∗ (s0 , b) = Qb (π) ≤ Qb[1] (π1 ) + Qb[2] (π2 ) = h∗1 (α1 (s0 ), b[1]) + h∗2 (α2 (s0 ), b[2]),
M(c,u,b) is an additive abstraction for M .
Theorem 1 For any OSP task Π = hV, s0 , u; O, c, bi, any abstraction skeleton AS =
{(G1 , α1 ), . . . , (Gk , αk )} of MΠ , and any M AAS MΠ , if the digraphs of AS are given
explicitly, then hM (s0 , b) can be computed in time polynomial in ||Π|| and ||M||.



Proof: Let M = {Mi }i∈[k] , with Mi = Si , αi (s0 ), ui , Oi , ϕi , ci , Qbi , be an additive abstraction for MΠ on the basis of AS. For i ∈ [k], let Si0 = {s ∈ Si | ci (αi (s0 ), s) ≤ bi }. Since
5. In optimal classical planning, the requirement for the abstraction to not overestimate the costs is typically
posed for all the states of the original model, not just for the initial state (Yang et al., 2008; Katz &
Domshlak, 2010b; Helmert et al., 2014). This extra requirement, however, is for pragmatic reasons of
efficiency as it allows the abstraction to be computed in preprocessing and not individually for every
state examined by the search. Heuristics for OSP, however, are functions not only of the state but also
of the available cost budget, and the latter directly applies to the initial (aka current) state only. In
sum, while defining abstractions with respect to the entire state space is not a necessity in classical
planning, in OSP it is not even clear whether defining abstractions with respect to a specific pair of a
state and a budget can deliver any practical benefits. This should not, however, be interpreted as a
formal impossibility claim, and further investigation in this direction is definitely worthwhile.

109

Domshlak & Mirkis

(−, −, −)

SSSS
kk
SS
kkkk
(−, u, −)
SSSSkk (c, −, −) SSSSkk (−, −, b)
kkkkSS
kkkkSS
(c, u, −)

(−, u, b)
(c, −, b)
SSS
SSS
kkk
kkk
(c, u, b)

Figure 5: Fragments of restricted optimization over the abstractions A ⊆ C × U × B
the digraphs of AS are given explicitly, shortest paths from αi (s0 ) to all states in Gi (and
thus, in particular, determining Si0 ) can be computed in time polynomial
in ||M|| for all
P
i ∈ [k]. In turn, since h∗i (αi (s0 ), bi ) = maxs∈Si0 ui (s), hM (s0 , b) = i∈[k] h∗i (αi (s0 ), bi ) can
be computed in time polynomial in ||M||.

The message of Theorem 1 is positive, yet it establishes only a necessary condition for
the relevance of OSP abstractions in practice. Given an OSP task Π, and having fixed an
abstraction skeleton AS with a joint performance measure space C × U × B, we should
be able to automatically separate between those (c, u, b) ∈ C × U × B that constitute
abstractions for MΠ and those that do not, and within the former set, denoted as
A ⊆ C × U × B,
home in on an abstraction that provides us with as accurate (aka as low) an estimate of
h∗ (s0 , b) as possible. Here, even the first item on the agenda is not necessarily trivial as,
in general, A seems to lack convenient combinatorial properties. For instance, generally
A does not form a combinatorial rectangle in C × U × B: Consider the OSP state model
GM and abstraction skeleton AS from our running example. Let c ∈ C be a cost function
vector with both c[1] and c[2] being constant functions with value of 1, and two performance
measures (c, u, b), (c, u0 , b0 ) ∈ C×U×B defined via budget vectors b = {b[1] = 2, b[2] = 0}
and b0 = {b0 [1] = 0, b0 [2] = 2}, and value function vectors u and u0 , with u[1], u[2], u0 [1],
and u0 [2] evaluating to zero on all states except for u[1](s1;4 ) = u0 [2](s2;4 ) = 1. It is not
0 0
hard to verify that both M(c,u,b) AAS M and M(c,u ,b ) AAS M : In M(c,u,b) , the state
(c,u,b)
s1;4 with u[1](s1;4 ) = 1 is reachable in M1
from s1;0 = α1 (s0 ) under b[1] = 2, while
0
0
(c,u0 ,b0 )
(c,u
,b
)
0
in M
, the state s2;4 with u [2](s2;4 ) = 1 is reachable in M2
from s2;0 = α2 (s0 )
0
0
under b0 [2] = 2. In contrast, both M(c,u ,b) 6AAS M and M(c,u,b ) 6AAS M : In both sets
of models, each model either comes with no budget (and the initial state in the model has
0
the value of zero), or has no states with non-zero value at all. Hence, both M(c,u ,b) and
0
M(c,u,b ) will estimate h∗ (s0 , b) as zero, while h∗ (s0 , b) = 1.
In light of the above, we approach the overall agenda of complexity analysis of abstractionbased heuristic functions in steps, under different fixations of some of the three dimensions
of A: If, for instance, we are given a vector of value functions u that is known to belong to
the projection of A on U, then we can search for a quality abstraction from the abstraction
subset A(−, u, −) ⊂ A, corresponding to the projection of A on {u}. As we show below,
even some constrained optimizations of this kind can be challenging. The lattice in Figure 5 depicts the range of options for such constrained optimization; at the extreme settings,
110

On Oversubscription Planning as Heuristic Search

o1

G1

G2

: s2;1
uu
u
u
uu

o3

/ s2;3

o1

s1;0

o2

/ s1;2

o4

/ s 1;4
j

s2;0

o3 ,o5

o2



o5

/ s2;4
j

o4

Figure 6: Homomorphic abstraction skeleton for G(Π) in Figure 4
A(−, −, −) is simply a renaming of A, and A(c, u, b) corresponds to a single abstraction
M(c,u,b) ∈ A.
3.2 Partitions and Homomorphic Abstractions
We now proceed to consider a specific family of additive abstractions, reveal some of its
interesting properties, and show that it contains substantial islands of tractability. With
Definition 1 allowing for very general abstraction skeletons, in this work we focus on homomorphic abstraction skeletons6 (Helmert et al., 2014).
Definition 
2 An abstraction skeleton
AS = {(G1 , α1 ), . . . , (Gk , αk )} for an OSP state

model M = S, s0 , u, O, ϕ, c, Qb is homomorphic if, for i ∈ [k], Oi = O, and ϕ(s, o) = s0
only if (αi (s), o, αi (s0 )) ∈ Ti .
For instance, in our running example, the abstraction skeleton in Figure 4b is not homomorphic (since, e.g., (s1 , o3 , s3 ) ∈ GM yet (α1 (s1 ), o3 , α1 (s3 )) = (s1;4 , o3 , s1;4 ) 6∈ GM1 ), while
the abstraction skeleton in Figure 6 is homomorphic. Furthermore, we focus on a fragment
of additive abstractions
Ap = A ∩ [Cp × Up × Bp ] ,
where Cp ⊆ C, Up ⊆ U, and Bp ⊆ B correspond to cost, value, and budget partitions,
respectively.



Definition 3 Given an OSP state model M = S, s0 , u, O, ϕ, c, Qb , and a homomorphic
abstraction skeleton AS = {(G1 , α1 ), . . . , (Gk , αk )} for M with a joint performance measure
C × U × B,
P
• c ∈ C is a cost partition iff, for each operator o ∈ O, i∈[k] c[i](o) ≤ c(o);
P
• u ∈ U is a value partition iff, for each state s ∈ S, i∈[k] u[i](αi (s)) ≥ u(s); and
P
• b ∈ B is a budget partition iff, i∈[k] b[i] ≤ b.
In what follows, for any node x of the lattice in Figure 5, by Ap (x) we refer to A(x)∩Ap ;
e.g., Ap (−, u, −) = A(−, u, −) ∩ Ap .
We begin our analysis of Ap by establishing an interesting “completeness” relationship
between the sets Cp and Bp , as well as an even stronger individual “completeness” of Cp and
Bp . Formulated in Theorem 2, these properties of Ap play a key role in our computational
analysis later on.
6. All the results also hold verbatim for the more general “labeled paths preserving” abstraction skeletons
studied by Katz and Domshlak (2010b) in the context of optimal classical planning. However, the
presentation is somewhat more accessible when restricted to homomorphic abstraction skeletons.

111

Domshlak & Mirkis

c

Cp

b⇤

Bp

Up

(1)

b

c⇤

Bp

Cp

Up

(2)

Figure 7: Illustration for sub-claims (1) and (2) of Theorem 2: In (1), the gray ellipse
within Bp stands for the subset of budget partitions b that pair with c in some
abstraction, that is, Ap (c, −, b) 6= ∅. However, while pairing some of these budget
partitions b with c requires then a careful selection of a value partition u (so that
M(c,u,b) will be an abstraction), there exists some budget partition b∗ for which
any choice of u will do the job.

Theorem 2 Given an OSP task Π = hV, s0 , u; O, c, bi and a homomorphic abstraction
skeleton AS = {(G1 , α1 ), . . . , (Gk , αk )} of MΠ ,
(1) for each cost partition c ∈ Cp , there exists a budget partition b∗ ∈ Bp such that
∗
M(c,u,b ) As AS for all value partitions u ∈ Up ;

(2) for each budget partition b ∈ Bp , there exists a cost partition c∗ ∈ Cp such that
∗
M(c ,u,b) As AS for all value partitions u ∈ Up .
The proof of Theorem 2 appears in Appendix A, p. 145. Figure 7 illustrates the statement of sub-claim (1) of Theorem 2, as well as, indirectly, some of its corollaries.7 The first
corollary of Theorem 2 is that the projections of Ap on Cp , Up , and Bp are the entire sets
Cp , Up , and Bp , respectively. That is, any cost partition c (and similarly, any budget partition and any value partition) can be matched with an abstraction that has that partition
as its component. Second, while not any budget partition b can be paired with a given cost
partition c in abstractions for MΠ , that is, not for all b ∈ Bp , Ap (c, −, b) 6= ∅, there are
always some budget partitions that can be paired with c. Finally, while pairing some of
these “c-compatible” budget partitions b with c requires then a careful selection of a value
partition u, there exists some “c-compatible” budget partition b∗ for which any choice of
u will result in M(c,u,b) being an abstraction of MΠ .
A priori, these properties of Ap should simplify the task of abstraction discovery and
optimization within the space of partitions Cp × Up × Bp , and later we show that this is
indeed the case. However, complexity analysis of abstraction discovery within Cp ×Up ×Bp
in most general terms is still problematic because the OSP formalism is parametric in
7. The respective illustration of sub-claim (2) of Theorem 2 is completely similar, mutatis mutandis.

112

On Oversubscription Planning as Heuristic Search

the representation of value functions. Hence, here we proceed with examining abstraction
discovery for OSP in the context of fixed value partitions u ∈ Up .

4. From Value Partitions to Complete Abstractions
Let Π be an OSP task, AS be an explicitly given homomorphic abstraction skeleton of MΠ ,
and u ∈ Up be a value partition over AS. An immediate corollary of Theorem 2 is that
Ap (−, u, −) is not empty, and thus we can try computing min(c,u,b)∈Ap (−,u,−) hM(c,u,b) (s0 ).
As of yet, however, we do not know whether this task is polynomial-time solvable for any
non-trivial class of value partitions. In fact, although Ap (−, u, −) is known, by Theorem 2,
to be non-empty, and so, too, are all of its subsets Ap (−, u, b) and Ap (c, u, −), finding even
just any abstraction (c, u, b) ∈ Ap (−, u, −) is not necessarily easy.
4.1 0-Binary Value Partitions
As a first step, we now examine abstraction discovery within a fragment of Ap in which all
value functions u[i] of the abstract models are what we call 0-binary. Later, in Section 4.2,
we show how our findings for 0-binary abstract value functions can be extended to general
value partitions.
Definition 4 A real-valued function f is called 0-binary if the codomain of f is {0, σ} for
some σ ∈ R+ . A set F of 0-binary functions is called strong if all the functions in F have
the same codomain {0, σ}.
On the one hand, 0-binary functions constitute a rather basic family of value functions.
Hence, if abstraction optimization is hard for them, it is likely to be hard for any nontrivial family of abstract value functions. On the other hand, 0-binary abstract value
functions seem to fit well abstractions of planning tasks in which value functions are linear
combinations of indicators, each representing achievement of a “goal value” for some state
variable.
In that respect, our first tractability results are for abstraction discovery in Ap (−, u, −)
where u is a strong 0-binary value partition. The first (and the simpler) result in Theorem 3
further assumes a fixed action cost partition, while the next result, in Theorem 7, is on
simultaneous selection of admissible pairs of cost and budget partitions. In Corollary 4 and
Theorem 10 we then show how the results of Theorem 3 and Theorem 7, respectively, can
be extended to pseudo-polynomial algorithms for general 0-binary value partitions.
4.1.1 Strong 0-Binary Value Partitions and the Knapsack problem
Our first tractability result is for abstraction discovery within Ap (c, u, −) where u is a strong
0-binary value partition and c is an arbitrary cost partition. The key role here is played by
the well-known
Knapsackproblem (Dantzig, 1930; Kellerer, Pferschy, & Pisinger, 2004). An


instance {wi , σi }i∈[n] , W of the Knapsack problem is given by a weight allowance W and
a set of objects [n], with each object i ∈ [n] being annotated
σi .
Pwith a weight wi and a value
0 ⊆ [n]
The objective
is
to
find
a
subset
Z
⊆
[n]
that
maximizes
σ
over
all
subsets
Z
i∈Z i
P
with
w
≤
W.
By
strict
Knapsack
we
refer
to
a
variant of Knapsack in which
0
i
i∈Z
that inequality constraint is strict. Knapsack is NP-hard (Karp, 1972; Garey & Johnson,
113

Domshlak & Mirkis

1978), but there exist pseudo-polynomial algorithms for it that run in time polynomial in the
description of the problem and in the unary representation of W (Dudzinski & Walukiewicz,
1987). The latter property makes solving Knapsack practical in many applications where the
ratio minWi wi is reasonably low. Likewise, if σi = σj for all i, j ∈ [n], then a greedy algorithm
solves the problem in linear time by iteratively expanding Z by one of the weight-wise
lightest objects in [n] \ Z, until Z cannot be expanded any further within W .
Theorem 3 (Ap (c, u, −) & strong 0-binary u)
Let Π = hV, s0 , u; O, c, bi be an OSP task, AS be an explicit homomorphic abstraction skeleton of MΠ , and u ∈ Up be a strong 0-binary value partition. Given a cost partition c ∈ Cp ,
finding an abstraction (c, u, b) ∈ Ap (c, u, −) and computing the corresponding heuristic
estimate hM(c,u,b) (s0 , b) can be done in time polynomial in ||Π|| and ||AS||.
Proof: The proof is by reduction to the polynomial fragment of the Knapsack problem
corresponding to all items having identical value. Let AS = {(G1 , α1 ), . . . , (Gk , αk )}, and,
given that u is a strong 0-binary value partition, let the codomain of all u[i] be {0, σ} for
some σ ∈ R+ .
For i ∈ [k], let wi be the cost of the cheapest path in Gi from αi (s0 ) to (one of the)
states s ∈ Si with u[i](s) = σ. Since AS is an explicit abstraction skeleton, the set {wi }i∈[k]
can be computed in time polynomial in ||AS|| using one of the standard algorithms
for the



single-source shortest paths problem. Consider now a Knapsack problem {wi , σ}i∈[k] , b ,
with weights wi being as above and value σ being identical for all objects. Let Z ⊆ [k]
be a solution to that (optimization) Knapsack problem; recall that it is computable in
polynomial time. Given that, we define budget profile b∗ ∈ B as follows:
(
wi , i ∈ Z
for i ∈ [k], b∗ [i] =
0,
otherwise.
What remains to be shown is that (c, u, b∗ ) actually induces an additive abstraction
∗
for MΠ . Assume to the contrary that M(c,u,b ) 6AAS MΠ , and let π be an optimal s0 -plan
for Π. By the construction of our Knapsack problem and of b∗ , for each i ∈ Z, there is
∗
(c,u,b∗ )
a αi (s)-plan πP
with Qb [i] (πi ) = σ. By Definition 1, our assumption implies
i for Mi
∗
that Qb (π) > i∈Z Qb [i] (πi ) = σ · |Z|. However, by Theorem 2, there exists at least one
budget partition b ∈ Bp such that M(c,u,b) AAS MΠ . Note that this budget partition
induces aP
feasible solution Z 0 = {i | wi ≤ b[i]} for our Knapsack problem, satisfying
Qb (π) ≤ i∈Z 0 Qb[i] (πi ) = σ · |Z 0 |. This, however, implies |Z| < |Z 0 |, contradicting the
∗
optimality of Z, and thus accomplishing the proof that M(c,u,b ) AAS MΠ .

The construction in the proof of Theorem 3 may appear somewhat counterintuitive:
while we are interested in minimizing the heuristic estimate of h∗ (s0 , b), the abstraction
∗
M(c,u,b ) is selected via the value-maximizing Knapsack problem. Indeed, while ultimately
we would like to obtain
min
hM(c,u,b) (s0 , b),
(6)
b : (c,u,b)∈Ap

the heuristic we manage to compute in polynomial time is actually
max
b : (c,u,b)∈Ap

hM(c,u,b) (s0 , b).
114

(7)

On Oversubscription Planning as Heuristic Search

At the same time, note that, for a fixed pair of c ∈ Cp and u ∈ Up , this estimate in Eq. 7 is
still at least as (and possibly much more) accurate as the estimate that would be obtained
by providing each of the k abstract models with the entire budget b. Later we show that
this superior accuracy is verified in our experiments, but first we proceed with examining
working with general 0-binary value partitions.
While strong 0-binary value partitions are rather restrictive, finding an element of
Ap (c, u, −) for general 0-binary u is no longer polynomial—a reduction from Knapsack
is straightforward. However, Knapsack is solvable in pseudo-polynomial time, and plugging
that Knapsack algorithm into the proof of Theorem 3 results in a search algorithm for
Ap (c, u, −) with general 0-binary u.
Corollary 4 (Ap (c, u, −) & 0-binary u)
Let Π = hV, s0 , u; O, c, bi be an OSP task, AS be an explicit homomorphic abstraction skeleton of MΠ , and u ∈ Up be a 0-binary value partition. Given a cost partition c ∈ Cp , finding
an abstraction (c, u, b) ∈ Ap (c, u, −) and computing the corresponding heuristic estimate
hM(c,u,b) (s0 , b) can be done in time polynomial in ||Π||, ||AS||, and the unary representation
of the budget b of Π.
To test and illustrate the value that additive abstractions can bring to heuristic-search
OSP, we implemented a prototype heuristic-search OSP solver8 on top of the Fast Downward
planner (Helmert, 2006). Since, unlike classical and net-benefit planning, OSP still lacks
a standard suite of benchmarks for comparative evaluation, we have cast in this role the
STRIPS classical planning tasks from the International Planning Competitions (IPC) 19982006. This “translation” to OSP was done by associating a separate unit-value with each
proposition in the conjunctive goal of the corresponding classical IPC task.
Within our prototype, we implemented the BFBB search for OSP, and provided support
for some basic pattern-database abstraction skeletons, action cost partitions, and abstraction selection in Ap (c, u, −) for strong 0-binary value partitions as in the proof of Theorem 3.
Specifically, for a task with k sub-goals:
(i) The abstraction skeleton comprised a set of k projections of the planning task onto
connected subsets of ancestors of the respective k goal variables in the causal graph.
The size of each projection was limited to 1000 abstract states, and the ancestors of
the goal variable v were added to the corresponding projection (initialized to contain
v) in a breadth-first manner, from v back along the arcs of the causal graph, until the
abstraction could not be expanded within the aforementioned size limit.
(ii) The value partition u associated the entire value of each sub-goal hv/di (only) with
the projection associated with v.
(iii) The cost partition c distributed the cost of each operator o uniformly between all the
projections that did not invalidate o, i.e., that reflected at least one state variable
affected by o.
In our evaluation, we compared BFBB node expansions with three heuristic functions,
tagged blind, basic, and hM . With all three heuristics, the h-value of a node n is set to 0
if the cost budget at n is over-consumed. If the cost budget is not over-consumed, then:
8. We are not aware of any other domain-independent planner for optimal OSP.

115

Domshlak & Mirkis

airport (25)
blocks (23)
depot (3)
driverlog (12)
freecell (5)
grid (2)
gripper (6)
logistics (10)
miconic (50)
mystery (4)
openstacks (7)
rovers (10)
satellite (9)
tpp (7)
trucks (9)
pipesw-t (12)
pipesw-nt (7)
psr-small (30)
zenotravel (10)
total

hM
23
23
3
12
5
2
6
10
50
4
7
10
9
7
9
12
7
30
10
239

25%
basic
23
23
3
12
5
2
6
10
50
4
7
10
8
7
9
12
7
30
10
238

blind
23
23
3
12
5
2
6
10
50
4
7
10
8
7
9
12
7
30
10
238

hM
20
23
3
12
5
2
6
10
50
4
7
10
7
7
9
12
7
30
10
234

50%
basic
20
23
3
12
5
2
6
10
50
4
7
7
6
7
8
12
7
30
9
228

blind
20
23
3
11
5
2
6
10
50
4
7
7
6
7
8
12
7
30
8
226

hM
19
22
3
11
5
2
6
10
50
4
7
7
6
6
6
12
7
30
9
222

75%
basic
20
18
3
9
5
2
6
10
50
4
7
6
4
6
5
11
7
30
8
211

blind
18
17
3
9
5
2
6
10
50
4
7
6
5
6
5
11
7
30
8
209

hM
19
17
3
10
5
1
6
10
50
3
7
6
5
6
5
11
7
30
8
209

100%
basic
20
17
2
7
5
1
6
10
45
3
7
5
4
5
5
10
6
30
7
195

blind
18
17
2
6
5
1
6
10
45
2
7
5
4
5
5
10
6
30
7
191

Table 1: Number of problems solved across the different budgets using the OPEN list ordered by the heuristic evaluation as in Figure 3

• Blind BFBB constitutes a trivial baseline in which h(n) is simply set to the total value
of all goals.
• In basic BFBB, h(n) is set to the total value of goals, each of which can be individually
achieved within the respective projection abstraction (see Theorem 1) given the entire
remaining budget.
• hM is an additive abstraction heuristic that is selected from Ap (c, u, −) as in the
proof of Theorem 3.
The evaluation contained all the planning tasks for which we could determine offline
the minimal cost budget needed to achieve all the goals. Each such task was approached
under four different budgets, corresponding to 25%, 50%, 75%, and 100% of the minimal
cost needed to achieve all the goals in the task, and each run was restricted to 10 minutes.
Table 1 shows the number of tasks solved within each domain for each level of cost budget.9
Figure 8 depicts the results in terms of expanded nodes across the four levels of cost budget.
(Figures 18-21 in Appendix B provide a more detailed view of the results in Figure 8 by
breaking them down into different levels of cost budget.) Despite the simplicity of the
abstraction skeletons we used, the number of nodes expanded by BFBB with hM was
typically substantially lower than the number of nodes expanded by basic BFBB, with the
difference sometimes reaching three orders of magnitude.
9. We reiterate that a task is considered solved only upon the termination of BFBB, that is, when an
optimal plan is found and proven to be optimal.

116

On Oversubscription Planning as Heuristic Search

(a)
108

unsolved

107
106
105
hM

104
103
102

unsolved

airport
blocks
depot
driverlog
freecell
grid
gripper
logistics
miconic
mystery
openstacks
pipesworld
psr-small
tpp
trucks
rovers
satellite
zenotravel

101

100 0
10 101 102 103 104 105 106 107 108
blind

(b)
108

unsolved

107
106
hM

105
104
103
unsolved

102
101

100 0
10 101 102 103 104 105 106 107 108
basic

Figure 8: Comparative view of empirical results from Table 1 in terms of expanded nodes

4.1.2 Freeing Cost Partition: Knapsack Meets Convex Optimization
Returning now to the algorithmic analysis in the context of strong 0-binary value partitions,
we now proceed with relaxing the constraint of sticking to a fixed action cost partition c.
This buys more flexibility in selecting abstractions from Ap (−, u, −), allowing us to improve
the accuracy of the heuristic estimates, while still retaining computational tractability.
117

Domshlak & Mirkis

input: Π = hV, s0 , u; O, c, bi, AS = {(G1 , α1 ), . . . , (Gk , αk )} of MΠ ,
strong 0-binary value partition u ∈ Up
output: κ(u)
for i = 1 to k do
reduce Gi to only nodes reachable from αi (s0 )
for m = k downto 1 do
if always-achievable(m) then return mσ
return 0
always-achievable(m):
m
ellipsoid-method(separation-oracle-Lm
1 ) 7→ solution x ∈ dom(X ) to L1
if x[ξ] ≤ b then return true
else return false
(a)
separation-oracle-Lm
1 (x ∈ dom(X )):
let τ be a permutation of [k] such that
x[b[τ
P(1)]] ≤ x[b[τ (2)]] ≤ · · · ≤ x[b[τ (k)]]
if x[ξ] ≤ i∈[m] x[b[τ (i)]] then return Yes
P
else return constraint ξ ≤ i∈[m] b[τ (i)]
(b)
Figure 9: A polynomial-time algorithm for computing κ(u) for a strong 0-binary value
partition u ∈ Up (Theorem 7)

Given an OSP task Π = hV, s0 , u; O, c, bi, a homomorphic abstraction skeleton AS, and
a value partition u ∈ Up over AS, let


κ(u) = min
max
(8)
hM(c,u,b) (s0 , b) .
c∈Cp

b : (c,u,b)∈Ap

Obviously, the estimate h(s0 , b) = κ(u) is at least as accurate as the estimate in Eq. 7 that
is derived with respect to a fixed cost partition c.
We now show that, for any OSP task Π, any abstraction skeleton AS = {(G1 , α1 ), . . . ,
(Gk , αk )} of MΠ , and any strong 0-binary value partition u ∈ Up over AS, κ(u) can be
computed in polynomial time. The corresponding algorithm is shown in Figure 9, with
Figure 9a depicting the macro-flow of the algorithm and Figure 9b depicting the specific
implementation of the solve sub-routine that makes the overall time complexity of the
algorithm polynomial.
The high-level flow of the algorithm in Figure 9a is as follows. Since u is a strong 0binary value partition, let the codomain of all the abstract value functions u[i] be {0, σ} for
some σ ∈ R+ . Given that, for each (c, u, b) ∈ Ap (−, u, −), it holds that hM(c,u,b) (s) = mσ
for some m ∈ {0} ∪ [k]. This is because each of the k abstract models in M(c,u,b) can
contribute to the additive estimate hM(c,u,b) (s) either σ or 0.
118

On Oversubscription Planning as Heuristic Search

The first loop of the algorithm is a preprocessing for-loop that eliminates from the
abstraction skeleton all the nodes that are structurally unreachable from the abstract initial
states α1 (s0 ), . . . , αk (s0 ).10 For ease of presentation, in what follows we assume that this
cleanup of the abstraction skeleton leaves each Gi with at least one state whose value is
σ. The second for-loop of the algorithm decreasingly iterates over all the values {kσ, (k −
1)σ, . . . , 2σ, σ} that can possibly come from the abstractions in Ap (−, u, −) as a positive
estimate of h∗ (s0 , b). Each of these candidates for κ(u) is tested in turn via the sub-routine
always-achievable. If and when this test returns positive for the first time, then we are done,
and the tested candidate mσ is identified as κ(u). Otherwise, if the test fails for all m ∈ [k],
then κ(u) = 0, in particular implying that no state with value greater than 0 can be reached
from s0 under budget b.
The test of always-achievable for κ(u) = mσ is based on a linear program (LP) Lm
1 , given
by Eq. 10. This linear program is defined over variables
#
"
[
[
(9)
{c[i](o)} ,
X = {ξ} ∪
{d(s)}s∈Gi ∪ {b[i]} ∪
o∈O

i∈[k]

constraints (10a)-(10c), and the objective of maximizing the value of the variable ξ.
Lm
1 :
max ξ
subject to


d(αi (s0 )) = 0,
∀i ∈ [k] : d(s) ≤ d(s0 ) + c[i](o), ∀(s0 , o, s) ∈ Gi
,


b[i] ≤ d(s),
∀s ∈ Gi s.t. u[i](s) = σ
(
c[i](o) ≥ 0,
∀i ∈ [k]
∀o ∈ O : P
,
i∈[k] c[i](o) ≤ c(o)
X
∀Z ⊆ [k], |Z| = m : ξ ≤
b[i].

(10a)

(10b)
(10c)

i∈Z

The roles of the different variables in Lm
1 are as follows.
• Variable c[i](o) captures the cost to be associated with label o in the digraph Gi of
AS.
• For a state s in Gi , variable d(s) captures the cost of the cheapest path in Gi from
αi (s0 ) to s, given that the edges of Gi are weighted consistently with the values of the
variables c[i](·).
• Variable b[i] captures the minimal budget needed for reaching in Gi a state with value
σ from state αi (s0 ), given that, again, the edges of Gi are weighted consistently with
the variable vector c[i].
10. This preprocessing step can be replaced by adding some extra constraints in the linear program described
below. However, that would unnecessarily complicate the presentation without adding much value.

119

Domshlak & Mirkis

• The singleton variable ξ captures the minimal total cost of reaching states with value
σ in precisely m out of k models in M(c,u,b) .
The semantics of the constraints in Lm
1 are as follows.
• The first two sets of constraints in (10a) come from a simple LP formulation of
the
P single
P source shortest paths problem with the source node αi (s0 ): Optimizing
i∈[k]
s∈Gi d(s) under a fixed weighting c of the edges leads to computing precisely
that, for all k digraphs in AS simultaneously.
• The third set of constraints in (10a) establishes the costs of the cheapest paths in {Gi }
from states αi (s0 ) to states valued σ, enforcing the semantics of variables b[1], . . . , b[k].
• Constraints (10b) are the cost partition constraints that enforce c ∈ Cp .
• Constraints (10c) enforce the aforementioned semantics of the objective variable ξ.
Two things are worth noting here. First, if all the nodes in the digraphs G1 , . . . , Gk
are structurally reachable from the “source nodes” α1 (s0 ), . . . , αk (s0 ), respectively (as it is
m
ensured by the first for-loop of the algorithm), then
S the polytope induced by L1 is bounded
and non-empty. Indeed, for any assignment to o∈O {c[i](o)} that is consistent with the
positiveness constraints in (10b), all the variables d(·) are bounded from above by the
lengths of the respective shortest paths. In turn, this bounding of d(·) bounds from above
the variables c[1], . . . , c[k] via the third set of constraints in (10a), and the constraints (10c)
then bound from above the objective ξ.
Second, while the number of variables, as well as the number of constraints in (10a)
and

k
(10b), are polynomial in ||Π|| and ||AS||, the number of constraints in (10c) is m
. Thus,
solving Lm
1 using standard methods for linear programming is infeasible. In Lemma 5 below
we show that this problem can actually be mitigated, and then, in Lemma 6 we show that
the semantics of Lm
1 match our objective of finding κ(u).
Lemma 5 The algorithm in Figure 9 terminates in time polynomial in ||Π|| and ||AS||.
Proof: The runtime complexity of the algorithm boils down to the complexity of solving
Lm
1 , and, while the number of variables in L1 (m), as well as the number of constraints in
(10a)
are polynomial in ||Π|| and ||AS||, the number of constraints in (10c) is
 and (10b),
k
m cannot be solved in polynomial time using standard methods for linear
.
Thus,
L
1
m
programming, such as the Simplex algorithm (Dantzig, 1963) or the Interior-Point methods (Nemirovsky & Yudin, 1994). However, using some other algorithms, such as the
Ellipsoid algorithm (Grotschel, Lovasz, & Schrijver, 1981) and the Random Walks family
of algorithms originating in the work of Bertsimas and Vempala (2004), an LP with an
exponential number of constraints can be solved in polynomial time, provided that we have
a polynomial time “separation oracle” for that LP. A polynomial-time separating oracle for
a convex set K ⊆ Rn is a procedure which given x ∈ Rn , either verifies that x ∈ K or
returns a hyperplane separating x from K. The procedure should run in polynomial time.
In our case, the separation problem is, given an assignment to the variables of Lm
1 , to test
whether it satisfies (10a), (10b), and (10c), and if not, produce an inequality among (10a),
(10b), and (10c) violated by that assignment.
120

On Oversubscription Planning as Heuristic Search

We now show how our separation problem for Lm
1 can be solved in polynomial time
using what is called m-sum minimization LPs (Punnen, 1992), and this is precisely what the
(parametrized with m) procedure separation-oracle-Lm
1 in Figure 9b does. As the number of
constraints in (10a) and (10b) is polynomial, their satisfaction by an assignment x ∈ dom(X )
can be tested directly by substitution. For constraints (10c), letPτ be a permutation of [k]
such that x[b[τ (1)]] ≤ x[b[τ (2)]] ≤ · · · ≤ x[b[τ (k)]]. If x[ξ] ≤ i∈[m] x[b[τ (i)]], then it is
easy to see that
Px satisfies all the constraints in (10c). Otherwise, we have our violated
inequality ξ ≤ i∈[m] b[τ (i)].

Lemma 6 The algorithm in Figure 9a computes κ(u).
The proof of Lemma 6 appears in Appendix A, p. 146. Combining the statements of
Lemmas 5 and 6, Theorem 7 summarizes our tractability result for abstraction discovery in
Ap (−, u, −) for strong 0-binary value partitions u.
Theorem 7 (Ap (−, u, −)(s) & strong 0-binary u)
Given an OSP task Π = hV, s0 , u; O, c, bi, a homomorphic explicit abstraction skeleton AS of
MΠ , and a strong 0-binary value partition u ∈ Up , κ(u) can be computed in time polynomial
in ||Π|| and ||AS||.
Unfortunately, the practical value of the result in Theorem 7 is yet to be evaluated. So
far, we have not found a reasonably efficient implementation of the Ellipsoid method for
linear inequalities, while, to the best of our knowledge, the Random Walks algorithms (Bertsimas & Vempala, 2004) have never been implemented at all. We hope that this state of
affairs will change soon, allowing these powerful algorithms to be used not only in theory,
but also in practice.
4.1.3 From Strong to General 0-Binary Value Partitions
Recall that the polynomial result of Theorem 3 for strong 0-binary value partitions easily
extends in Corollary 4 to a pseudo-polynomial algorithm for general 0-binary value partitions. It turns out that a pseudo-polynomial extension of Theorem 7 is possible as well,
though it is technically more involved. The corresponding algorithm is shown in Figure 10.
Following the format of Figure 9, Figure 10a depicts the macro-flow of the algorithm and
Figure 10b shows the specific implementation of the solve sub-routine by which the desired
time complexity can be achieved.
Similarly to the algorithm in Figure 9, a preprocessing for-loop of the algorithm first
eliminates from the abstraction skeleton all the nodes that are structurally unreachable
from the abstract initial states α1 (s0 ), . . . , αk (s0 ). Next, the algorithm performs a binary
search over an interval containing κ(u).11 Since u is a 0-binary value partition, for i ∈ [k],
by {0, σi }, σi ∈ R+ , we denote the codomain of the abstract value
P function u[i]. Given that,
for each (c, u, b) ∈ Ap (−, u, −), it holds that h(c,u,b) (s) = i∈Z σi for some Z ⊆ [k]. As
the size of this combinatorial hypothesis space is prohibitive, the while-loop in Figure 10
performs a binary search over a relaxed hypothesis space, corresponding to the continuous
11. While a binary search could have been used in the algorithm in Figure 9 as well, there it would be a
mere optimization, while here it is necessary to avoid an exponential blowup of the time complexity.

121

Domshlak & Mirkis

input: Π = hV, s0 , u; O, c, bi, AS = {(G1 , α1 ), . . . , (Gk , αk )} of MΠ ,
0-binary value partition u ∈ Up
output: κs (u)
for i = 1 to k do
reduce Gi to only nodes reachable from αi (s0 )
let 0 <  < mini∈[k] σi
α←P
0
β ← i∈[k] σi
while β − α >  do
v ← α + (β − α)/2
if always-achievable(v) then α ← v
else β ← v
if α = 0 then return 0
else return β
always-achievable(v):
ellipsoid-method(separation-oracle-Lv2 ) 7→ solution x ∈ dom(X ) to Lv2
if x[ξ] ≤ b then return true
else return false
(a)
separation-oracle-Lv2
(x ∈ dom(X )):

strict-Knapsack( {x[b[i]], σi }i∈[k] , x[ξ] ) 7→ solution Z ⊆ [k]
P
if i∈Z σi < v then return Yes
P
else return constraint ξ ≤ i∈Z b[i]
(b)
Figure 10: A pseudo-polynomial algorithm for approximating κ(u) for general 0-binary
value partitions u ∈ Up (Theorem 10)

P
interval [0, i∈[k] σi ] of R+0 . The parameter  serves as the “sufficient precision” criterion
for termination.
At an iteration corresponding to an interval [α, β], the algorithm uses its sub-routine
always-achievable to test the hypothesis κ(u) ≥ v, where v is the mid-point of [α, β]. If the
test is positive, then the next tested hypothesis is κs (u) ≥ v 0 , where v 0 is the midpoint
of [v, β]. Otherwise, the next hypothesis corresponds to the midpoint of [α, v). When the
while-loop is done, the reported estimate is set to β; while there still might be some lag
between β and κ(u), this lag can be arbitrarily reduced by reducing , and anyway, β ≥ κ(u)
ensures admissibility of the estimate. If, however, the while-loop terminates with α = 0,
then κ(u) ≤ β ≤  < mini∈[k] σi implies κ(u) = 0, and this is what we return.
The test of always-achievable for κ(u) ≥ v is based on a linear program Lv2 , which is
defined over variables X as in Eq. 9, and is obtained from Lm
1 by replacing constraints (10c)
with constraints (11c):
122

On Oversubscription Planning as Heuristic Search

Lv2 :
max ξ
subject to


d(αi (s0 )) = 0,
∀i ∈ [k] : d(s) ≤ d(s0 ) + c[i](o), ∀(s0 , o, s) ∈ Gi
,


b[i] ≤ d(s),
∀s ∈ Gi s.t. u[i](s) = σi
(
c[i](o) ≥ 0,
∀i ∈ [k]
∀o ∈ O : P
,
i∈[k] c[i](o) ≤ c(o)
X
X
∀Z ⊆ [k] s.t.
σi ≥ v : ξ ≤
b[i].
i∈Z

(11a)

(11b)
(11c)

i∈Z

While the semantics of all variables but ξ remains as in Lm
1 , ξ now captures the minimal
total cost ofPreaching some states {si }i∈[k] in the abstract models M(c,u,b) such that the
total value i∈[k] u[i](si ) ≥ v. The new constraint (11c) enforces this semantics of ξ.
Lemma 8 For any  > 0, the algorithm in Figure 10 terminates in time polynomial in
||Π||, ||AS||, log 1 , and a unary representation of the budget b of Π.
P

σi

Proof: The number of iterations of the while-loop is approximately log2 i∈[k]
, and the

run-time of each of its iterations boils down to the complexity of solving Lv2 . Here, as in
v
Lemma 5 with linear programs Lm
1 , the number of variables in L2 , as well as the number
of constraints in (11a) and (11b), are polynomial in ||Π|| and ||AS||, while the number
of constraints in (11c) is Θ(2k ). Therefore, always-achievable(v) also employs the ellipsoid
method with a sub-routine separation-oracle-Lv2 for the associated separation problem. We
now show how that separation problem for Lv2 can be solved in pseudo-polynomial time
using a standard pseudo-polynomial procedure for the strict Knapsack problem.
Given an assignment x ∈ dom(X ), its feasibility with respect to (11a) and (11b) can be
tested directly by substitution. 
For constraints (11c),
 let Z ⊆ [k] be an optimal solution
to the strict Knapsack problem {x[b[i]], σi }i∈[k] , x[ξ] , with a weight allowance x[ξ] and k
objects, with each object i ∈ [k] being associated with weight x[b[i]] and value σi .
P
• If the value i∈Z σi of Z is smaller than v, then x satisfies all the constraints in
(11c). Assume to the contrary that x violatesP
some constraint in (11c), corresponding
0
to a setPZ ⊆ [k]. By definition of (11c),
i∈Z 0 σi ≥ v, and by our assumption,
x[ξ] >
x[b[i]].
That,
however,
implies
that Z 0 is a feasible solution for our
0
i∈Z
strict Knapsack, and of value higher than that of presumably optimal Z.
P
• Otherwise, if i∈Z σi ≥ v, then Z itselfPprovides us with a constraint in (11c) that is
violated by x. This is because x[ξ] > 
i∈Z x[b[i]] holds by the
 virtue of Z being a
solution to the strict Knapsack problem {x[b[i]], σi }i∈[k] , x[ξ] .


123

Domshlak & Mirkis

Lemma 9 For any 0 <  < mini∈[k] σi , the algorithm in Figure 10a computes κ such that
κ − κ(u) ≤ .
The proof of Lemma 9 appears in Appendix A, p. 147. Combining the statements of
Lemmas 8 and 9, Theorem 10 summarizes our result for optimized abstraction discovery in
Ap (−, u, −) for general 0-binary value partitions u. Importantly, note that the algorithm in
Figure 10 depends on the unary representation of only the budget, and not of the possible
state values. In particular, it means that dependence of the complexity on the number of
alternative sub-goals in the OSP task of interest is only polynomial. Finally, Theorem 10 is
formulated in terms of the estimate precision only because the σi values of the abstract value
functions u[i] can be arbitrary real numbers. In the case of integer-valued sets of functions
u, as well as in various special cases of real-valued functions, κ(u) can be determined
precisely using a simplification of the algorithm in Figure 10. For instance, if all σ1 , . . . , σk
are integers, then setting  to any value in (0, 1) results in the while-loop terminating with
α = κ(u). These details, however, are more of a theoretical interest; for reasonably small
values of , in practice there will be no difference between estimates h(s, b) and h(s, b) + .
Theorem 10 (Ap (−, u, −)(s) & 0-binary u)
Given an OSP task Π = hV, s0 , u; O, c, bi, a homomorphic explicit abstraction skeleton AS =
{(G1 , α1 ), . . . , (Gk , αk )} of MΠ , a 0-binary value partition u ∈ Up , and  > 0, it is possible
to approximate κs (u) within an additive factor of  in time polynomial in ||Π||, ||AS||, log 1 ,
and a unary representation of the budget b of Π.
4.2 General Value Partitions
While 0-binary value partitions can be rather useful by themselves, it turns out that the
pseudo-polynomial algorithms for abstraction discovery with explicit homomorphic abstraction skeletons and 0-binary value partitions can be extended rather easily to arbitrary value
partitions, using the following observations:
(1) for any OSP task Π = hV, s0 , u; O, c, bi, any homomorphic abstraction skeleton AS =
{(G1 , α1 ), . . . , (Gk , αk )} of MΠ , and any value partition u over AS, the number of
distinct values taken by u[i] is trivially upper-bounded by the number of states in Gi ;
and
(2) the pseudo-polynomial solvability of the Knapsack problem extends to its more general
variant known as Multiple-Choice Knapsack (Dudzinski & Walukiewicz, 1987; Kellerer
et al., 2004).
The Multiple-Choice (MC) Knapsack problem hN1 , . . . , Nm ; W i is given by a weight
allowance W and m classes of objects N1 , . . . , Nm , with each object j ∈ Ni being annotated
with a weight wij and a value σij . The objective
is to find a set Z that contains at most
P
one
P object from each class and maximizes (i,j)∈Z σij over all such sets while satisfying
(i,j)∈Z wij ≤ W. By strict MC-Knapsack, we refer to a variant of MC-Knapsack in
which that inequality constraint is strict. MC-Knapsack generalizes regular Knapsack and
thus it is NP-hard. However, similarly to the regular Knapsack problem, MC-Knapsack also
admits a pseudo-polynomial, dynamic programming algorithm that runs in time polynomial
124

On Oversubscription Planning as Heuristic Search

in the description of the problem and in the unary representation of W (Dudzinski &
Walukiewicz, 1987; Kellerer et al., 2004).
Theorem 11 (Ap (c, u, −))
Let Π = hV, s0 , u; O, c, bi be an OSP task, let AS = {(G1 , α1 ), . . . , (Gk , αk )} be an explicit homomorphic abstraction skeleton of MΠ , and let u ∈ Up be an arbitrary value
partition over AS. Given a cost partition c ∈ Cp , it is possible to find an abstraction
(c, u, b) ∈ Ap (c, u, −) and compute the corresponding heuristic estimate hM(c,u,b) (s0 , b) in
time polynomial in ||Π||, ||AS||, and the unary representation of the budget b.
Proof: The proof is very similar to the proof of Theorem 3, but with the compilation being
to the MC-Knapsack problem.
For i ∈ [k], let ni be the number of distinct values taken by u[i], let {σi1 , . . . , σini } ⊂ R+
be the codomain of u[i], and, for j ∈ [ni ], let wij be the cost of the cheapest path in Gi from
αi (s0 ) to (one of the) states s ∈ Si with u[i](s) = σij . Since AS is an explicit abstraction
skeleton, for i ∈ [k], it holds that ni ≤ |Si |, and the set {wij }i∈[k],j∈[ni ] can be computed in
time polynomial in ||AS|| using one of the standard algorithms for the single-source shortest
paths problem.
Consider now an MC-Knapsack problem with a weight allowance b and k classes of
objects N1 , . . . , Nk , with |Ni | = ni and each object j ∈ Ni annotated with a weight wij and
S
a value σij . Let Z ⊆ ki=1 Ni be a solution to that (optimization) MC-Knapsack problem;
recall that it is computable in pseudo-polynomial time. Given that, we define budget profile
b∗ ∈ B as follows:
(
wij , (i, j) ∈ Z
∗
for i ∈ [k], b [i] =
0,
otherwise.
Showing that (c, u, b∗ ) actually induces an additive abstraction for MΠ is completely identical to the proof of the corresponding argument in Theorem 3, and thus omitted.

Theorem 12 (Ap (−, u, −))
Given an OSP task Π = hV, s0 , u; O, c, bi, a homomorphic explicit abstraction skeleton AS =
{(G1 , α1 ), . . . , (Gk , αk )} of MΠ , an arbitrary value partition u ∈ Up over AS, and  > 0, it
is possible to approximate κs (u) within an additive factor of  in time polynomial in ||Π||,
||AS||, log 1 , and a unary representation of the budget b of Π.
An algorithm for abstraction discovery as in Theorem 12 is depicted in Figure 11. Its
high-level flow differs from the flow of the algorithm from Figure 10 for general 0-binary
value partitions only in the initialization of parameters  and β. The major difference
between the algorithms is that here the tests of candidate values v are based on linear
programs Lv3 , which are defined as follows.
For i ∈ [k], let {σi1 , . . . , σini } ⊂ R+ be the codomain of u[i]. For v ∈ R+ , the linear
program Lv3 is defined in Eq. 13 over variables


[
[
[
{d(s)}s∈Gi ∪
X = {ξ} ∪
{b[i, j]} ∪
{c[i](o)}.
(12)
i∈[k]

j∈[ni ]

125

o∈O

Domshlak & Mirkis

input: Π = hV, s0 , u; O, c, bi, AS = {(G1 , α1 ), . . . , (Gk , αk )} of MΠ ,
0-binary value partition u ∈ Up
output: κs (u)
for i = 1 to k do
reduce Gi to only nodes reachable from αi (s0 )
let 0 <  < mini∈[k] minj∈[ni ] σij
α←P
0
β ← i∈[k] maxj∈[ni ] σij
while β − α >  do
v ← α + (β − α)/2
if always-achievable(v) then α ← v
else β ← v
if α = 0 then return 0
else return β
always-achievable(v):
ellipsoid-method(separation-oracle-Lv3 ) 7→ solution x ∈ dom(X ) to Lv3
if x[ξ] ≤ b then return true
else return false
(a)
separation-oracle-Lv3 (x ∈
 dom(X )):

strict-MC-Knapsack( {x[b[1, j]], σ1j }j∈[n1 ] , . . . , {x[b[k, j]], σkj }j∈[nk ] ; x[ξ] )
7→ solution Z ∈ [n1 ] × · · · × [nk ]
P
if i∈[k] σiZ(i) < v then return Yes
P
else return constraint ξ ≤ i∈[k] b[i, Z(i)]
(b)
Figure 11: (a) A modification of the algorithm from Figure 10 to arbitrary value partitions
u ∈ Up (Theorem 12), and (b) a pseudo-polynomial time separation oracle for
the corresponding linear programs Lv3 in Eq. 13

These variables differ from the variable set of Lv2 (see Eq. 9) by a larger set of b-variables:
Variable b[i, j] here captures the minimal budget needed for reaching in Gi a state with
value σi,j from state αi (s0 ), given that the edges of Gi are weighted consistently with the
variable vector c[i].
126

On Oversubscription Planning as Heuristic Search

Lv3 :
max ξ
subject to


d(αi (s0 )) = 0,
∀i ∈ [k] : d(s) ≤ d(s0 ) + c[i](o), ∀(s0 , o, s) ∈ Gi
,


b[i, j] ≤ d(s),
∀j ∈ [ni ]∀s ∈ Gi s.t. u[i](s) = σij
(13a)
(
c[i](o) ≥ 0,
∀i ∈ [k]
∀o ∈ O : P
,
(13b)
i∈[k] c[i](o) ≤ c(o)
∀Z ∈ [n1 ] × · · · × [nk ]
X
X
s.t.
σiZ(i) ≥ v : ξ ≤
b[i, Z(i)].
i∈[k]

(13c)

i∈[k]

Like what we had in Lemma 8 with linear programs Lv2 , while the number of variables
in Lv3 , as well as the number of constraints in (13a) and (13b), are polynomial in ||Π||
and ||AS||, the number of constraints in (13c) is Θ(dk ) where d = maxi∈[k] ni . Therefore,
always-achievable(v) also employs the ellipsoid method with a pseudo-polynomial time separation oracle, but here the latter is based on solving a strict MC-Knapsack problem (see
Figure 11b). Otherwise, solving Lv2 and solving Lv3 are similar.
Lemma 13 For any  > 0, the algorithm in Figure 11 terminates in time polynomial in
||Π||, ||AS||, log 1 , and a unary representation of the budget b of Π.
Lemma 14 Given an OSP task Π = hV, s0 , u; O, c, bi, a homomorphic explicit abstraction
skeleton AS = {(G1 , α1 ), . . . , (Gk , αk )} of MΠ , an arbitrary value partition u ∈ Up over
AS, and  > 0, the algorithm in Figure 11 computes κ such that κ − κ(u) ≤ .
The proof of Lemma 13 is similar to the proof of Lemma 8, with strict Knapsack
separation problems being replaced with strict MC-Knapsack separation problems. The
proof of Lemma 14 is also similar to the proof of Lemma 9, mutatis mutandis. Together,
Lemmas 14 and 13 establish Theorem 12.

5. Landmarks in OSP
In addition to state-space abstractions, a family of approximation techniques that have been
found extremely effective in the context of optimal classical planning is based on the notion
of logical landmarks for goal reachability (Karpas & Domshlak, 2009; Helmert & Domshlak,
2009; Domshlak et al., 2012; Bonet & Helmert, 2010; Pommerening & Helmert, 2013). In
this section we proceed with examining the prospects of such reachability landmarks in
heuristic-search OSP planning.
127

Domshlak & Mirkis

5.1 Landmarks in Classical Planning
For a state s in a classical planning task Π, a landmark is a property of operator sequences
that is satisfied by all s-plans (Hoffmann, Porteous, & Sebastia, 2004). For instance, a
“fact landmark” for a state s is an assignment to a single variable that is true at some point
in every s-plan. Most state-of-the-art admissible heuristics for classical planning use what
are called disjunctive action landmarks, each corresponding to a set of operators such
that every s-plan contains at least one operator from that set (Karpas & Domshlak, 2009;
Helmert & Domshlak, 2009; Bonet & Helmert, 2010; Pommerening & Helmert, 2013). In
what follows we consider this popular notion of landmarks, and simply refer to disjunctive
action landmarks for a state s as s-landmarks. For ease of presentation, most of our discussion will take place in the context of landmarks for the initial state of the task, and these
will simply be referred to as landmarks (for Π).
Deciding whether an operator set L ⊂ O is a landmark for classical planning task Π is
PSPACE-hard (Porteous, Sebastia, & Hoffmann, 2001). Therefore, all landmark heuristics
employ landmark discovery methods that are polynomial-time and sound, but incomplete.
In what follows we assume access to such a procedure; the actual way the landmarks are
discovered is tangential to our contribution. For
a landmark cost
P a set L of s-landmarks,
∗
0+
function lcost : L → R is admissible if
L∈L lcost(L) ≤ h (s). For a singleton set
L = {L}, lcost(L) := mino∈L c(o) is a natural admissible landmark cost function, and it
extends directly to non-singleton sets of pairwise disjoint landmarks. For more general sets
of landmarks, lcost can be devised in polynomial time via operator cost partitioning (Katz
& Domshlak, 2010b), either given L (Karpas & Domshlak, 2009), or within the actual
process of generating L (Helmert & Domshlak, 2009).
5.2 ε-Landmarks and Budget Reduction
While landmarks play an important role in (both satisficing and optimal) classical planning,
so far they have not been exploited in OSP. At first glance, this is probably no surprise,
and not only because OSP has been investigated much less than classical planning: Since
landmarks must be satisfied by all plans and because an empty operator sequence is always
a plan for any OSP task, the notion of landmark does not seem useful here. Having said
that, consider the anytime “output improvement” property of the BFBB forward search.
The empty plan is not interesting there not only because it is useless, but also because it
is “found” by BFBB right at the very beginning. In general, at all stages of the search,
anytime search algorithms like BFBB maintain the best-so-far solution π, and prune all
branches that promise value lower or equal to Qb (π). Hence, in principle, such algorithms
may benefit from information about properties that are “satisfied by all plans with value
larger than Qb (π).” Polynomial-time discovery of such “value landmarks” for arbitrary OSP
tasks is still an open problem. However, looking at what is needed and what is available,
here we show that the classical planning machinery of reachability landmarks actually can
be effectively exploited in OSP.
P In what follows, we assume that the value function of Π is additive, with u(s) =
hv/di∈s uv (d), with uv (d) ≥ 0 for all variable-value pairs hv/di. That is, the value of state
s is the sum of the (mutually independent) non-negative marginal values of the propositions
comprising s. With the value of different s-plans in an OSP task Π varying between zero
128

On Oversubscription Planning as Heuristic Search

and the value of the optimal s-plan (which may also be zero), let ε-landmark for state
s be any property that is satisfied by any s-plan π that achieves something valuable. For
instance, with the disjunctive action landmarks we use here, if L ⊆ O is an ε-landmark for
s, then every s-plan π with Qb (π) > 0 contains an operator from L. In what follows, unless
stated otherwise, we focus on ε-landmarks for (the initial state of) Π.
Definition 5 Given an OSP task Π = hV, s0 , u; O, c, bi, the ε-compilation of Π is a classical planning task Πε = hVε , s0ε , Gε ; Oε , cε i where
Vε = V ∪ {g},
with dom(g) = {0, 1},
s0ε = s0 ∪ {hg/0i},
Gε = {hg/1i},

	
Oε = O ∪ Og = O ∪ ohv/di | hv/di ∈ D, uv (d) > 0 ,
with pre(ohv/di ) = {hv/di} and eff(ohv/di ) = {hg/1i},
(
c(ω), ω = o ∈ O
cε (o) =
.
0,
ω = ohv/di ∈ Og
To put it simply, the semantics of the value hg/1i of the auxiliary variable g in Πε is
that “it has been verified that some proposition with a positive value has been achieved”.
In these terms, Πε simply extends the structure of Π with a set of zero-cost actions such
that applying any of them corresponds to verifying that a positive value can be achieved
in Π. Constructing Πε from Π is trivially polynomial time, and it allows us to discover
ε-landmarks for Π using the standard machinery for classical planning landmark discovery.
Theorem 15 For any OSP task Π, any landmark L for Πε such that L ⊆ O is an εlandmark for Π.
Proof: The proof is rather straightforward. Let P be the set of all plans π for Π with
Qb (π) > 0 and Pε the set of all plans for Πε . By the definition of P, for any plan π ∈ P,
there exists a proposition hv/di ∈ D such that uv (d) > 0 and hv/di ∈ s0 JπK. Likewise, since
s0ε
 := s0∪ {hg/0i} and Oε ⊇ O, π is applicable in

 s0ε . Hence, by definition


 of ohv/di ∈ Oε ,
π· ohv/di is applicable in s0ε and 
hg/1i ∈
s
Jπ·
o
K,
that
is,
π·
o
0ε
hv/di
hv/di ∈ Pε . In turn,

if L is a landmark for Πε , then π· ohv/di contains an operator from L, and if L ⊆ O, then
π contains an operator from L as well. This proves that all landmarks L for Πε over the
operators O of Π are ε-landmarks for Π.

With Theorem 15 in hand, we can now derive ε-landmarks for Π using any method
for classical planning landmark extraction, such as that employed by the LAMA planner (Richter et al., 2008) or the LM-Cut family of techniques (Helmert & Domshlak, 2009;
Bonet & Helmert, 2010). However, at first glance, the discriminative power of knowing
“what is needed to achieve something valuable” seems to be negligible when it comes to deriving effective heuristic estimates for OSP. The good news is that, in OSP, such information
can be effectively exploited in a slightly different way.
129

Domshlak & Mirkis

Consider a schematic example of searching for an optimal plan for an OPS task Π with
budget b, using BFBB with an admissible heuristic h. Suppose that there is only one
sequence of (all unit-cost) operators, π = ho1 , o2 , . . . , ob+1 i, applicable in the initial state
of Π, and that the only positive value state along π is its end-state. While clearly no
value higher than zero can be achieved in Π under the given budget of b, the search will
continue beyond the initial state, unless h(s0 , ·) counts the cost of all the b + 1 operators
of π. Now, suppose that h(s0 , ·) counts only the cost of {oi , . . . , ob+1 } for some i > 0, but
{o1 }, {o2 }, . . . , {oi−1 } are all discovered to be ε-landmarks for Π. Given that, suppose that
we modify Π by (a) setting the cost of operators o1 , o2 , . . . , oi−1 to zero, and (b) reducing
the budget to b − i + 1. Since all the operators o1 , o2 , . . . , oi−1 have to be applied anyway
along any value collecting plan for Π, this modification seems to preserve the semantics of
Π. At the same time, on the modified task, BFBB with the same heuristic h will prune the
initial state and thus establish without any search that the empty plan is an optimal plan
for Π. Of course, the way Π is modified in this example is as simplistic as the example itself.
Yet, this example does motivate the idea of landmark-based budget reduction for OSP, as
well as illustrates the basic idea behind the generically sound task modifications that we
discuss next.

Definition 6 Let Π = hV, s0 , u; O, c, bi be an OSP task, L = {L1 , . . . , Ln } be a set of
pairwise disjoint ε-landmarks for Π, and lcost be an admissible landmark cost function from
L. The budget reducing compilation of Π is an OSP task ΠL = hVL , s0L , uL ; OL , cL , bL i
where
n
X
bL = b −
lcost(Li )
(14)
i=1

and
VL = V ∪ {vL1 , . . . , vLn }
with dom(vLi ) = {0, 1},
s0L = s0 ∪ {hvL1 /1i , . . . , hvLn /1i},
uL = u,
OL = O ∪

n
[
i=1

OLi = O ∪

n
[

{o | o ∈ Li },

i=1

with pre(o) = pre(o) ∪ {hvLi /1i} and eff(o) = eff(o) ∪ {hvLi /0i},
(
c(o),
ω=o∈O
cL (ω) =
.
c(o) − lcost(Li ), ω = o ∈ OLi
In other words, ΠL extends the structure of Π by
• mirroring the operators of each ε-landmark Li with their “cheaper by lcost(Li )” versions,
130

On Oversubscription Planning as Heuristic Search

CBB

o2
o2

o2 o2
ABB

o1
o1

o3
BTB
o6
o3
BBB
o7
o4
BBT
o4

CTB

o4
o7
o4
BTT
o3
o3
o6
o2
CBT
o2

u=1

o5
o9
o5

u=1

CCB

o8
o10
o8
o5
CTT
o9
o5
u=1

o2
o2
o8
o10
o8

CTC

u=1
CCT

o5
u=2
o9
o5
o8
CCC
o10
o8

CBC

(a)
u=1

CBB
CTB

o2
ABB

o1

BBB

BTB
o6
o3
o7
o4
BBT

o2
o7
o4
BTT

o3
o6
o2

o9
o5

o2

CBB

o10
o8
CTT

u=1
CBT

o10
o8

u=1

CCB

o9
o5

CTC

o2 o2

o9 u=2

o5
u=1
CCT

CCC

ABB

o10
o8

CBC

o1
o1

o3
BTB
o6
o3
BBB
o7
o4
BBT
o4

o2
o2

CTB

o4
o7
o4
BTT
o3
o3
o6
o2
CBT
o2

o5
o9
o5

o2
o2
o8
o10
o8

u=1
CCB

o8
o10
o8
o5
CTT
o9
o5
u=1

u=1
CTC

u=1
CCT

o5
u=2
o9
o5
o8
CCC
o10
o8

CBC

Figure 12: Illustrations for our example of the landmark-based budget reducing compilation
ΠL : (a) The structurally reachable parts of the graphical skeleton of the model
induced by ΠL , illustrated on the projection of ΠL on the variables of the original
task Π, along with a comparison between the budget-wise reachable parts of the
graphical skeletons induced by the models of the (b) original task Π and (c) the
compiled task ΠL .

• using the “disposable” propositions hvL1 /1i , . . . , hvLn /1i to ensure that at most one
instance of these discounted operators for each Li can be applied along an operator
sequence from the initial state12 , and
• compensating for the discounted operators for Li by reducing the budget by precisely
lcost(Li ).
For example, consider the simple OSP task Π from Figure 2 (p. 104) with cost budget
b = 4, and assume we are provided with a set of four landmarks L = {L1 , . . . , L4 } where
L1 = {o1 }, L2 = {o2 }, L3 = {o3 , o4 } and L4 = {o5 , o8 }, and with admissible landmark cost
function lcost(Li ) = 1 for i ∈ [4]. Compiling (L, lcost) into Π using the budget reducing
compilation in Definition S
6 results in a task ΠL with budget bL = 0 and c(o) = 0 for all the
discounted operators o ∈ ni=1 OLi = {o1 , o2 , o3 , o4 , o5 , o8 }.
While the states of Π correspond to complete assignments to only three variables V =
{t, x, y}, ΠL already has seven variables VL = {t, x, y, vL1 , vL2 , vL3 , vL4 }. Thus, depicting
12. Note that, while the auxiliary variable g in the ε-compilation Πε of Π can effectively change its value only
from hg/0i to hg/1i, the auxiliary variables vLi in ΠL change their values (only) from hvLi /1i to hvLi /0i.
This difference reflects the “positive” semantics that is usually associated with the value 1, aka value
true, of the planning propositions: The semantics of a state s of ΠL containing the proposition hvLi /1i
is that we are still allowed to apply (one of the) discounted operators associated with the landmark Li
from s onwards.

131

Domshlak & Mirkis

compile-and-BFBB (Π = hV, s0 , u; O, c, bi)
Πε := ε-compilation of Π
L := a set of landmarks for Πε
lcost := admissible landmark cost function from L
ΠL∗ := budget reducing compilation of (L, lcost) into Π
n∗ := BFBB(ΠL∗ )
return plan for Π associated with n∗
Figure 13: BFBB search with landmark-based budget reduction
the structurally reachable parts of the graphical skeleton GMΠL is problematic. Still, to
illustrate the search space of Π, in Figure 12(a) we show the (structurally reachable parts
of the) graphical skeleton of the model induced by the projection of Π on the variables
{t, x, y} only. The arcs corresponding to discounted operators are colored, with each color
distinguishing the landmark responsible for the respective discounted operators.
Figures 12(b) and 12(c) illustrate the effect of the budget-reducing compilation by depicting the parts of the graphical skeletons GMΠ and GMΠL that are actually reachable
under the respective cost budgets b = 4 and bL = 0: While the states BTT and CTT are
reachable from the initial state of Π under the budget allowance of 4, the states corresponding to BTT and CTT are no longer reachable in ΠL , reducing the size of the search space
for BFBB. At the same time, as formulated in Theorem 16 below, this reduction of the
search space does not affect plans for Π that lead to valuable states, resulting in an effective
equivalence between Π and ΠL .
Theorem 16 Let Π = hV, s0 , u; O, c, bi be an OSP task, L be a set of pairwise disjoint
ε-landmarks for Π, lcost be an admissible landmark cost function from L, and ΠL be the
respective budget reducing compilation of Π. For every π for Π with Qb (π) > 0, there is a
plan πL for ΠL with QbL (πL ) = Qb (π), and vice versa.
The proof of Theorem 16 appears in Appendix A, p. 149. The budget reducing OSPto-OSP compilation in Definition 6 is clearly polynomial time. The compile-and-BFBB
procedure, depicted in Figure 13,
(1) generates an ε-compilation Πε of Π;
(2) uses off-the-shelf tools for classical planning to generate a set of landmarks L for Πε
and an admissible landmark cost function lcost; and
(3) compiles (L, lcost) into Π, obtaining an OSP task ΠL .
The optimal solution for ΠL (and thus for Π) is then searched for using a search algorithm
for optimal OSP such as BFBB.
Before we proceed to consider more general sets of landmarks, a few comments concerning the setup of Theorem 16 are in order. First, if the reduced budget bL turns out to
be lower than the cost of the cheapest action applicable in the initial state, then obviously
no search is needed, and the empty plan can be reported as optimal right away. Second,
132

On Oversubscription Planning as Heuristic Search

zero-cost landmarks are useless in our compilation as much as they are useless in deriving
landmark heuristics for optimal planning. Hence, lcost in what follows is assumed to be
strictly positive. Third, having both o and o applicable at a state of Πε brings no benefits
yet adds branching to the search. Hence, in our implementation, for each landmark Li ∈ L
and each operator o ∈ Li , the precondition of the regular operators o in OL is extended
with {hvLi /0i}. It is not hard to verify that this extension preserves the correctness of
ΠL in terms of Theorem 16. Finally, if the value of the initial state is not zero, that is,
the empty plan has some positive value, then ε-compilation Πε of Π will have no positive
cost landmarks at all. However, this can easily be fixed by considering as “valuable” only
propositions hv/di such that both uv (d) > 0 and hv/di 6∈ s0 . We ignore for the time being
the problem of non-zero-value initial states (and assume that Qb () = 0), but return to it
later for a more systematic discussion.
5.3 Non-Disjoint ε-Landmarks
While the budget reducing compilation ΠL above is sound for pairwise disjoint landmarks,
this is not so for more general sets of ε-landmarks. For example, consider a planning task
Π in which, for some operator o, we have c(o) = b, Qb (hoi) > 0, and Qb (π) = 0 for all other
operator sequences π 6= hoi. That is, a value greater than zero is achievable in Π, but only
via the operator o. Suppose now that our set of ε-landmarks for Π is L = {L1 , . . . , Ln },
n > 1, with lcost(Li ) > 0 for all i ∈ [n], and
Pnthat all of these ε-landmarks contain o. In this
case, while the budget in ΠL is bL = b − i=1 lcost(Li ), the cost of the cheapest replica o
of o, that is, the cost of the cheapest operator sequence achieving a non-zero value in Π, is
n

n

i=1

i=1

c(o) − max lcost(Li ) = b − max lcost(Li ) > b −

n
X

lcost(Li ) = bL .

i=1

Hence, no state with positive value will be reachable from s0L in ΠL , and thus Π and ΠL
are not “value equivalent” in the sense of Theorem 16.
This example shows why compiling non-disjoint ε-landmarks into Π independently is
not sound. In principle, it can be made sound as follows. Let Π = hV, s0 , u; O, c, bi be an
OSP task, let L = {L1 , . . . , Ln } be a set of ε-landmarks for Π, and let lcost be an admissible
landmark cost function from L. All the components in ΠL = hVL , s0L , uL ; OL , cL , bL i are
still defined as in Definition 6, except for the operator sets OL1 , . . . , OLn . The latter are
now constructed not independently of each other, but sequentially, with the content of
OLi depending on the content of all OLj , j < i. The ordering in which the sets OLi are
constructed can be arbitrary.
For each operator o ∈ O and each 1 ≤ i ≤ n, let Oo;i denote the set of all “cost
discounted” representatives of o introduced
during the construction of OL1 , . . . , OLi . For
S
1 ≤ i ≤ n, if for some operator o ∈ o0 ∈Li Oo0 ;i−1 we have cL (o) = 0, then OLi := ∅.
Otherwise, OLi contains an operator o for each operator
o ∈ Li ∪

[
o0 ∈Li

133

Oo0 ;i−1 ,

(15)

Domshlak & Mirkis

with o being defined very similarly to Definition 6 as:
pre(o) = pre(o) ∪ {hvLi /1i},
eff(o) = eff(o) ∪ {hvLi /0i},
(
c(o) − lcost(Li ),
cL (o) =
cL (o) − lcost(Li ),

o ∈ Li ,
.
S
o ∈ o0 ∈Li Oo0 ;i−1

(16)

The compilation extended this way is sound for arbitrary sets of ε-landmarks, and
on pairwise disjoint landmarks it reduces to the basic compilation used in Theorem 16.
In general, however, this extended compilation is no longer polynomial in the size of the
explicit representation of Π because
|Oo;i | = 2|{Lj |j≤i,o∈Lj }| .
For example, let L = {L1 , L2 , L3 }, L1 = {a, b}, L2 = {a, c}, L3 = {a, d}. Generation of
OL1 := {a1 , b1 } effectively follows Definition 6, but for OL2 , the base set of operators as in
Eq. 15 is already {a, c, a1 }. Thus, OL2 := {a2 , c1 , a3 }, where, for i ∈ {2, 3} and denoting a
by a0 , ai is derived according to Eq. 16 from ai−2 . Consequently, the base set of operators
for OL3 is {a, d, a1 , a2 , a3 }, resulting in OL3 = {a4 , d1 , a5 , a6 , a7 }, where, for i ∈ {4, 5, 6, 7},
ai is derived from ai−4 . In sum, ΠL ends up with 8 = 2|L| representatives of the operator a.
Since non-disjoint landmarks can bring more information, and they are typical to outputs
of standard techniques for landmark extraction in classical planning, we now present a
different, slightly more involved, compilation that is both polynomial and sound for arbitrary
sets of ε-landmarks.
Definition 7 Let Π = hV, s0 , u; O, c, bi be an OSP task, L = {L1 , . . . , Ln } be a set of
pairwise disjoint ε-landmarks for Π, and lcost be an admissible landmark cost function
from L. For each operator o, let L(o) denote the set of all landmarks in L that contain
o. Then, the generalized budget reducing compilation of Π is an OSP task ΠL∗ =
hVL∗ , s0L∗ , uL∗ ; OL∗ , cL∗ , bL∗ i where
bL∗ = b −

n
X

lcost(Li ),

i=1

VL∗ = V ∪ {vL1 , . . . , vLn }
with dom(vLi ) = {0, 1},
s0L∗ = s0 ∪ {hvL1 /1i , . . . , hvLn /1i},
uL∗ = u,
OL∗ = O ∪ {o | o ∈ ∪L∈L L} ∪ {get(L) | L ∈ L}
with
pre(o) = pre(o) ∪ {hvL /1i | L ∈ L(o)},
eff(o) = eff(o) ∪ {hvL /0i | L ∈ L(o)},

(17)

and
pre(get(L)) = {hvL /0i},
eff(get(L)) = {hvL /1i},
134

(18)

On Oversubscription Planning as Heuristic Search

and


c(o), P
cL∗ (ω) = c(o) − L∈L(o) lcost(L),


lcost(L),

ω=o∈O
.
ω=o

(19)

ω = get(L)

To illustrate this compilation, we will let L = {L1 , L2 , L3 },
L1 = {a, b},
L2 = {b, c},
L3 = {a, c},
with all operators having the cost of 2, and let
lcost(L1 ) = lcost(L2 ) = lcost(L3 ) = 1.
In ΠL∗ , we have VL∗ = V ∪ {vL1 , vL2 , vL3 } and
OL∗ = O ∪ {a, b, c, get(L1 ), get(L2 ), get(L3 )},
with, e.g.,
pre(a) = pre(a) ∪ {hvL1 /1i , hvL3 /1i},
eff(a) = eff(a) ∪ {hvL1 /0i , hvL3 /0i},
cL∗ (a) = 0,
and, for get(L1 ),
pre(get(L1 )) = {hvL /0i},
eff(get(L1 )) = {hvL /1i},
cL∗ (get(L1 )) = 1.
The intuition behind the compilation in Definition 7 is as follows. By Eq. 19, applying
a discounted operator o saves the total cost of all landmarks containing o. Therefore,
• o can be executed only at states s in which all the corresponding control propositions
{hvL /1i | L ∈ L(o)} hold, indicating that the cost of no landmark in L(o) has already
been saved before reaching s, and
• to avoid double savings around L(o), applying o in s turns off all these control propositions in sJoK.
However, considering the example above, suppose that the optimal plan π for the original
task contains an instance of operator a, followed by an instance of operator b, and no
instance of operator c. Applying a instead of a would block us from applying b instead
of b, and thus the value of the optimal plan in the compilation can be lower than Qb (π).
The rescue here comes from the get(L) actions that allow for selective “spending” of the
individual landmark costs lcost(L). In our example, while applying a in s saves the cost
of the landmarks L1 and L3 , applying get(L1 ) will then spend lcost(L1 ) and safely set the
135

Domshlak & Mirkis

control proposition hvL1 /1i. In turn, this will enable b to be applied at the next steps,
and applying b will then save the cost of L2 and “re-save” the cost of L1 . This way, the
compilation leads to equivalence between Π and ΠL∗ , formulated in Theorem 17 below and
proven in Appendix A, p. 149.
Theorem 17 Let Π = hV, s0 , u; O, c, bi be an OSP task, let L = {L1 , . . . , Ln } be a set of
ε-landmarks for Π, let lcost be an admissible landmark cost function from L, and let ΠL∗
be the (generalized) budget reducing compilation of Π. For every π for Π with Qb (π) > 0,
there is a plan πL∗ for ΠL∗ with QbL∗ (πL∗ ) = Qb (π), and vice versa.
5.4 ε-Landmarks & Incremental BFBB
As we discussed earlier, if the value of the initial state is not zero, then the empty plan
has some positive value, and thus the ε-compilation Πε of Π as in Definition 5 will have no
landmarks with positive cost. In passing we noted that this small problem can be remedied
by considering as “valuable” only facts hv/di such that both uv (d) > 0 and hv/di 6∈ s0 . We
now consider this aspect of OSP more closely, and show how the discovery of ε-landmarks
and the incremental revelation of plans by BFBB can be combined in a mutually stratifying
way.
Let Π = hV, s0 , u; O, c, bi be the OSP task of interest, and suppose we are given a set
of plans π1 , . . . , πn for Π. If so, then we are no longer interested in searching for plans
that “achieve something,” but in searching for plans that achieve something beyond what
π1 , . . . , πn already achieve. Specifically, let si = s0 Jπi K be the end-state of πi , and for any
set of propositions s ⊆ D, let goods(s) ⊆ s be the set of all propositions hv/di ∈ s such that
uv (d) > 0. If a new plan π with end-state s achieves something beyond what π1 , . . . , πn
already achieve, then, for all 1 ≤ i ≤ n,
goods(s) \ goods(si ) 6= ∅.
We now put this observation to work.
Definition 8 Given an OSP task Π = hV, s0 , u; O, c, bi and a set of reference states Sref =
{s1 , . . . , sn } of Π, the (ε, Sref )-compilation of Π is a classical planning task Π(ε,Sref ) =
hVε , s0ε , Gε ; Oε , cε i with
Vε = V ∪ {x1 , . . . , xn , search, collect},
with dom(xi ) = dom(search) = dom(collect) = {0, 1},
s0ε = s0 ∪ {hsearch/1i , hcollect/0i , hx1 /0i , . . . , hxn /0i},
Gε = {hx1 /1i , . . . , hxn /1i},
n
[
Oε = O ∪
Oi ∪ {f inish},
i=1

where
136

On Oversubscription Planning as Heuristic Search

• O = {o | o ∈ O},
pre(o) = pre(o) ∪ {hsearch/1i},
eff(o) = eff(o),
cε (o) = c(o).
•
pre(f inish) = ∅,
eff(f inish) = {hcollect/1i , hsearch/0i},
cε (f inish) = 0.
• Oi = {oi,g | si ∈ Sref , g ∈ goods(D) \ si },
pre(oi,g ) = {g, hcollect/1i},
eff(oi,g ) = {hxi /1i},
cε (oi,g ) = 0.
Note that
• the goal Gε cannot be achieved without applying the f inish operator;
• the “regular” operators o can be applied only before f inish; and
• the subgoal achieving operators oi,g can be applied only after f inish.
This way, the first part of any plan for Π(ε,Sref ) determines a plan for Π, and the second part
“verifies” that the end-state of that plan achieves a subset of value-carrying propositions
goods(D) that is included in no state from Sref .13
Theorem 18 Let Π = hV, s0 , u; O, c, bi be an OSP task, Sref = {s1 , . . . , sn } be a subset of
Π’s states, and L be a landmark for Π(ε,Sref ) such that L ⊆ O. For any plan π for Π such
that goods(s0 JπK) \ goods(si ) 6= ∅ for all si ∈ Sref , π contains an instance of at least one
operator from L0 = {o | o ∈ L}.
Proof: Assume to the contrary that there exists a plan π = ho1 , . . . , ok i for Π such that
goods(s0 JπK) \ goods(si ) 6= ∅ for all si ∈ Sref , and yet π ∩ L0 = ∅. Let {g1 , . . . , gn } be an
arbitrary set of propositions from goods(s0 JπK) \ goods(s1 ), . . . , goods(s0 JπK) \ goods(sn ),
respectively. By the construction of Π(ε,Sref ) , it is immediate that
π(ε,Sref ) = ho1 , . . . , ok , f inish, o1,g1 , . . . , on,gn i
is a plan for Π(ε,Sref ) and, by our assumption about π and L0 , it holds that π(ε,Sref ) ∩ L = ∅.
This, however, contradicts that L is a landmark for Π(ε,Sref ) .

13. This “solve & verify” technique appears to be helpful in many planning formalism compilations; see,
e.g., the work of Keyder and Geffner (2009).

137

Domshlak & Mirkis

inc-compile-and-BFBB (Π = hV, O; s0 , c, u, bi)
initialize global variables:
n∗ := s0
// best solution so far
Sref := {s0 } // current reference states
loop:
Π(ε,Sref ) = (ε, Sref )-compilation of Π
L := a set of landmarks for Π(ε,Sref )
lcost := admissible landmark cost function from L
ΠL∗ := budget reducing compilation of (L, lcost) into Π
if inc-BFBB(ΠL∗ , Sref , n∗ ) = done:
return plan for Π associated with n∗
inc-BFBB (Π, Sref , n∗ )
open := new max-heap ordered by f (n) = h(shni, b − g(n))
open.insert(make-root-node(s0 ))
closed:= ∅
best-cost:= 0
while not open.empty()
n := open.pop-max()
if f (n) ≤ u(shn∗ i): break
if u(shni) > u(shn∗ i): update n∗ := n
if goods(shni) 6⊆ goods(s0 ) for all s0 ∈ Sref :
Sref := Sref ∪ {shni}
if termination criterion: return updated
// the rest is similar to BFBB in Figure 3

if shni 6∈ closed or g(n) < best-cost(shni):
closed:= closed ∪ {shni}
best-cost(shni) := g(n)
foreach o ∈ O(shni):
n0 := make-node(shniJoK, n)
if g(n0 ) > b or f (n0 ) ≤ u(shn∗ i): continue
open.insert(n0 )
return done
Figure 14: Iterative BFBB with landmark enhancement
Theorem 18 allows us to define an iterative version of BFBB, inc-compile-and-BFBB,
depicted in Figure 14. The successive iterations of inc-compile-and-BFBB correspond to
running the regular BFBB on successively more informed (ε, Sref )-compilations of Π, with
the states discovered at iteration i making the (ε, Sref )-compilation used at iteration i + 1
more informed.
inc-compile-and-BFBB maintains as a pair of global variables: a set of reference states
Sref and the best solution so far n∗ . At each iteration of the loop, a modified version of
BFBB, inc-BFBB, is called with an (ε, Sref )-compilation of Π, created on the basis of the
138

On Oversubscription Planning as Heuristic Search

current Sref . The reference set Sref is then extended by inc-BFBB with all the non-redundant
value-carrying states discovered during the search, and n∗ is updated if the search discovers
nodes of higher value.
If and when the OPEN list becomes empty or the node n selected from the list promises
less than the lower bound, inc-BFBB returns an indicator, done, that the best solution
n∗ found so far, across the iterations of inc-compile-and-BFBB, is optimal. In that case,
inc-compile-and-BFBB leaves its loop and extracts that optimal plan from n∗ . However,
inc-BFBB may also terminate in a different way, if a certain complementary termination
criterion is satisfied. The latter criterion comes to assess whether the updates to Sref
performed in the current session of inc-BFBB warrant updating the (ε, Sref )-compilation
and restarting the search. If terminated this way, inc-BFBB returns a respective indicator,
and inc-compile-and-BFBB goes into another iteration of its loop, with the updated Sref and
n∗ . We note that, while the optimality of the algorithm holds for any such termination
condition, the latter should greatly affect the runtime efficiency of the algorithm.
Theorem 19 The inc-compile-and-BFBB search algorithm is sound and complete for optimal OSP.
Proof: First, for any complementary termination criterion employed by the inc-BFBB procedure, inc-compile-and-BFBB is guaranteed to terminate. This is because that complementary termination criterion is checked in inc-BFBB only after a proper expansion of the
global reference set Sref , and thus the number of calls to inc-BFBB by inc-compile-and-BFBB
is upper-bounded by |S|.
It terms of search, inc-BFBB is no different from the regular BFBB procedure. In turn, by
Theorem 18, the additional pruning power of the budget-reducing compilation with reference
states Sref affects only search nodes n such that u(shni) < maxs∈Sref u(s). Note also that,
each time the best solution so far n∗ is updated in inc-BFBB, it is necessarily added to Sref
(since goods(shn∗ i) of the new n∗ can be included in no goods(s) for s ∈ Sref ). Thus, optimal
solutions cannot be pruned out by inc-BFBB and the overall search by inc-compile-and-BFBB
is therefore sound.

5.5 Empirical Evaluation
To evaluate the merits of the landmark-based budget reducing compilation, we have extended our prototype OSP solver from Section 3 with the following components:
• (ε, Sref )-compilation of OSP tasks Π for arbitrary sets of reference states Sref ;
• generation of disjunctive action landmarks for (ε, Sref )-compilations using the LM-Cut
procedure (Helmert & Domshlak, 2009) of Fast Downward; and
• the incremental BFBB procedure inc-compile-and-BFBB as in Figure 14, with the
search termination criterion being satisfied (only) if the examined node n improves
over the current value lower bound, i.e., n becomes the new best-so-far node n∗ .
After some preliminary evaluation, we also added two optimality preserving enhancements to the search. Because the auxiliary variables of our compilations increase the dimensionality of the problem, and this is known to negatively affect the quality of the abstraction
139

Domshlak & Mirkis

(a) blind
108

unsolved

107
106
105
104
103
102

unsolved

compile-and-BFBB

airport
blocks
depot
driverlog
freecell
grid
gripper
logistics
miconic
mystery
openstacks
pipesworld
psr-small
tpp
trucks
rovers
satellite
zenotravel

101

100
100 101 102 103 104 105 106 107 108
BFBB

(b) hM
108

unsolved

106
105
104
103
102

unsolved

compile-and-BFBB

107

101

100
100 101 102 103 104 105 106 107 108
BFBB

Figure 15: Comparative view of empirical results in terms of expanded nodes, for BFBB
vs. compile-and-BFBB, with (a) blind and (b) abstraction hM heuristics

heuristics (Domshlak et al., 2012), we first devised the projections with respect to the original OSP problem Π, and the open list was ordered as if the search is done on the original
problem, that is, by


X
h shni↓V , b − g(n) +
lcost(L) ,
vL 6∈shni

where s↓V is the projection of the ΠL∗ ’s state s on the variables of the original OSP task Π.
This change in heuristic evaluation is sound, as Theorem 17 in particular implies that any
140

On Oversubscription Planning as Heuristic Search

admissible heuristic for Π is also an admissible heuristic for ΠL∗ , and vice versa. Second,
when a new node n is generated, we check whether
X
X
lcost(L),
lcost(L) ≥ g(n0 ) +
g(n) +
L:hvL /0i∈shn0 i

L:hvL /0i∈shni

for some previously generated node n0 that corresponds to the same state of the original
problem Π, that is, shn0 i↓V = shni↓V . If so, then n is pruned right away. Optimality
preservation of this enhancement is established in Lemma 20 and proven in Appendix A,
p. 151.
Lemma 20 Let Π be an OSP task, Π(ε,Sref ) be a (ε, Sref )-compilation of Π, L be a set of
landmarks for Π(ε,Sref ) , lcost be an admissible landmark cost function for L, and ΠL∗ be the
respective budget reducing compilation of (L, lcost) into Π. Let π1 and π2 be a pair of plans
↓V
for ΠL∗ with end-states s1 and s2 , respectively, such that s↓V
1 = s2 and
cL∗ (π1 ) +

X

lcost(L) ≥ cL∗ (π2 ) +

L:hvL /0i∈s1

X

lcost(L).

(20)

L:hvL /0i∈s2

Then, for any plan π10 that extends π1 , there exists a plan π20 that extends π2 such that
= QbL∗ (π10 ).

QbL∗ (π20 )

Our evaluation included the regular BFBB planning for Π, solving Π using landmarkbased compilation via compile-and-BFBB, and the simple setting of inc-compile-and-BFBB
described above. All three approaches were evaluated under the blind heuristic and the
additive abstraction heuristic hM described in Section 3. Figures 15-17 depict the results
of our evaluation in terms of expanded nodes. Similarly to the experiment reported in
Section 3, each task was approached under four different budgets, corresponding to 25%,
50%, 75%, and 100% of the minimal cost needed to achieve all the goals in the task,
and each run was restricted to 10 minutes. Figures 15a and 15b compare the number
of expanded nodes of BFBB and compile-and-BFBB across the four levels of cost budget,
under blind (a) and abstraction hM (b) heuristics. Figures 16a and 16b provide a similar
comparison between BFBB and inc-compile-and-BFBB. Figures 17a and 17b do the same
for compile-and-BFBB and inc-compile-and-BFBB.14 Figures 22-25 and Figures 26-29 in
Appendix B provide a more detailed view of the results in Figures 15 and 16, respectively,
by breaking them down into different levels of cost budget.
As Figure 8 shows, the results were very satisfactory. With no informative heuristic
guidance at all, the number of nodes expanded by compile-and-BFBB was typically much
lower than the number of nodes expanded by BFBB, with the difference reaching three
orders of magnitude more than once. Of the 760 task/budget pairs behind Figure 8a, 81
pairs were solved by compile-and-BFBB with no search at all (by proving that no plan can
achieve value higher than that of the initial state), while, unsurprisingly, only 4 of these
tasks were solved with no search by BFBB.
14. We do not present here a detailed comparison in terms of the running times, but the per-node CPU
time overhead due to landmark-based budget reduction was ≤ 10%. Some technical difficulties with our
implementation of inc-compile-and-BFBB led us to limit our comparison of it in each graph only to tasks
solved by both methods.

141

Domshlak & Mirkis

(a) blind
108
107
inc-compile-and-BFBB

airport
blocks
depot
driverlog
freecell
grid
gripper
logistics
miconic
mystery
openstacks
pipesworld
psr-small
tpp
trucks
rovers
satellite
zenotravel

106
105
104
103
102
101
100
100 101 102 103 104 105 106 107 108
BFBB

(b) hM
108
inc-compile-and-BFBB

107
106
105
104
103
102
101
100
100 101 102 103 104 105 106 107 108
BFBB

Figure 16: Comparative view of empirical results in terms of expanded nodes, for BFBB
vs. inc-compile-and-BFBB, with (a) blind and (b) abstraction hM heuristics

As expected, the impact of the landmark-based budget reduction is lower when the
search is equipped with a meaningful heuristic (Figure 15b). Nonetheless, even with our
abstraction heuristic in hand, the number of nodes expanded by compile-and-BFBB was
often substantially lower than the number of nodes expanded by BFBB. Here, BFBB and
compile-and-BFBB solved with no search 39 and 85 task/budget pairs, respectively. Finally, despite the rather ad hoc setting of our incremental inc-compile-and-BFBB procedure,
switching from compile-and-BFBB to inc-compile-and-BFBB was typically beneficial. Obvi142

On Oversubscription Planning as Heuristic Search

(a) blind
108
107
inc-compile-and-BFBB

airport
blocks
depot
driverlog
freecell
grid
gripper
logistics
miconic
mystery
openstacks
pipesworld
psr-small
tpp
trucks
rovers
satellite
zenotravel

106
105
104
103
102
101
100 0
10 101 102 103 104 105 106 107 108
compile-and-BFBB

(b) hM
108
inc-compile-and-BFBB

107
106
105
104
103
102
101
100 0
10 101 102 103 104 105 106 107 108
compile-and-BFBB

Figure 17: Comparative view of empirical results in terms of expanded nodes, for
compile-and-BFBB vs. inc-compile-and-BFBB, with (a) blind and (b) abstraction hM heuristics

ously, much deeper investigation and development of inc-compile-and-BFBB is still required,
especially in the context of the choice of the iteration termination criterion.

6. Summary and Future Work
Deterministic oversubscription planning captures the computational core of one of the most
important setups of automated action selection, and yet, despite the apparent importance of
143

Domshlak & Mirkis

this problem, it has not been sufficiently investigated. In this work, we progressed towards
translating the spectacular advances in classical deterministic planning to deterministic
OSP. Tracing the key sources of progress in classical planning, we identified a severe lack
of effective approximations for OSP, and worked towards bridging this gap.
Our focus was on two classes of approximation techniques that underly most state-ofthe-art optimal heuristic-search solvers for classical planning: state-space abstractions and
goal-reachability landmarks. First, we defined the notion of additive abstractions for OSP,
studied the complexity of deriving effective abstractions from a rich space of hypotheses,
and revealed some substantial, empirically relevant islands of tractability of this abstraction
discovery problem. Next, we showed how standard goal-reachability landmarks of certain
classical planning tasks can be compiled into the OSP task of interest, resulting in an
equivalent OSP task with a lower cost allowance, and thus with a sometimes dramatically
smaller search space.
All the techniques proposed here satisfy the properties required by the efficient search
algorithms for optimal OSP. However, we believe that these techniques, and especially
landmark-based budget reducing compilations, should be as beneficial in satisficing OSP
as in optimal OSP, in particular because the difference between optimal and satisficing
planning appears to be much smaller in OSP than in classical deterministic planning.
Many interesting questions remain open for future work, and the prospects for further
developments in oversubscription planning now appear quite promising. Within the specific
context of our work, the two most interesting research directions are (1) optimization of value
partitions given cost partitions, that is, optimizing abstraction discovery in Ap (c, −, −),
and (2) thoroughly investigating the interleaved landmark discovery and search for OSP
introduced in Section 5.4. In a broader context, we propose, as well, additional candidates
for future research:
• Following the work of Katz and Domshlak (2010a) on implicit abstractions for classical planning, the computational merits of implicit abstractions for OSP should be
investigated. This will inevitably give us a better understanding of the computational
tractability boundaries of deterministic OSP.
• The basic model of deterministic planning in Section 2.1 was used to provide a unifying
comparative view of the basic models of classical, cost-bounded, net-benefit, and
oversubscription planning. One practically motivated extension of this model is to lift
action costs to vectors of action costs. Such a variant of cost-bounded planning has
already been investigated (Nakhost et al., 2012), and it is only natural to examine
this extension in the context of OSP.
Unfortunately, our results on abstractions do not seem to extend directly to vectors of
costs: At the level of the planning model, adding cost measures shifts problem solving
from polynomial time shortest path(s) problems to NP-hard restricted shortest path(s)
problems (Handler & Zang, 1980). Nonetheless, like the Knapsack problem, the restricted shortest path problem can be solved in pseudo-polynomial time (Desrochers
& Soumis, 1988), and thus some extension of our results to vectors of costs might still
be achievable.
At the same time, the machinery of landmark-based budget reducing compilations
for OSP straightforwardly extends to vectors of costs and budgets. Hence, even if no
144

On Oversubscription Planning as Heuristic Search

quality heuristic for OSP with multiple cost measures is available, the blind search
can still be stratified with information coming from problem landmarks.
• While the pruning mechanism of BFBB must rely on admissible, upper-bounding
heuristic estimates, no special properties are required from a heuristic used to guide the
search choices of BFBB. Thus, developing informative yet not necessarily admissible
heuristics for OSP is clearly of interest.
Acknowledgments
This work was partially supported by the EOARD grant FA8655-12-1-2096, and the ISF
grant 1045/12.

Appendix A. Proofs
Theorem 2 Given an OSP task Π = hV, s0 , u; O, c, bi and a homomorphic abstraction
skeleton AS = {(G1 , α1 ), . . . , (Gk , αk )} of MΠ ,
(1) for each cost partition c ∈ Cp , there exists a budget partition b∗ ∈ Bp such that
∗
M(c,u,b ) As AS for all value partitions u ∈ Up ;
(2) for each budget partition b ∈ Bp , there exists a cost partition c∗ ∈ Cp such that
∗
M(c ,u,b) As AS for all value partitions u ∈ Up .
Proof: Let π = h(s0 , o1 , s1 ), (s1 , o2 , s2 ), . . . , (sn−1 , on , sn )i be an optimal s0 -plan for MΠ ,
and, for i ∈ [k], let πi = h(αi (s0 ), o1 , αi (s1 )), . . . , (αi (sn−1 ), on , αi (on ))i be the mapping of
π to Gi . Since AS is homomorphic, the paths π1 , . . . , πk are well-defined.
(1) P
Given a cost partition c ∈ Cp , let budget profile b∗ ∈ B be defined as b∗ [i] =
∗
j∈[n] c[i](oj ), for i ∈ [k]. First, note that b ∈ Bp since
X
i∈[k]

(†)

X X

b∗ [i] =

c[i](oj ) ≤

i∈[k] j∈[n]

X

(‡)

c(oj ) ≤ b,

j∈[n]

where (†) is by c being a cost partition, and (‡) is by π being an s0 -plan for MΠ .
Second, for any u ∈ U, by the construction of b∗ , πi is an αi (s0 )-plan for the abstract
(c,u,b∗ )
model Mi
. Now, let u ∈ Up , and for i ∈ [k], let πi∗ be an optimal αi (s0 )-plan for
(c,u,b∗ )
Mi
. We have
X
i∈[k]

Qb

∗ [i]

(†)

(πi∗ ) ≥

X

∗ [i]

Qb

(‡)

(πi ) ≥ Qb (π),

(21)

i∈[k]

where (†) is by optimality of πi∗ , and (‡) is by αi (sn ) being the end-state of πi and u
being a value partition. Therefore, (c, u, b∗ ) induces an additive abstraction for Π, that
∗
is, M(c,u,b ) AAS MΠ .
145

Domshlak & Mirkis

(2) Given a budget partition b, let cost profile c∗ ∈ C be defined as c∗ [i](o) = c(o) · b[i]
b ,
forPall operators o ∈ O, and all i ∈ [k]. First, we have c∗ ∈ Cp since b ∈ Bp implies
1
∗
i∈[k] b[i] ∈ [0, 1]. Second, for any u ∈ U, by the construction of c , πi is an αi (s0 )b
(c∗ ,u,b)

plan for Mi
. Following now exactly the same line of reasoning as for Eq. 21 above
∗
accomplishes the proof that M(c ,u,b) AAS MΠ for any u ∈ Up .

Lemma 6 The algorithm in Figure 9a computes κ(u).
Proof: Due to the boundness and non-emptiness of the polytope induced by Lm
1 , the termination of the algorithm is straightforward. Thus, given a strong 0-binary partition u, the
only question is whether the value with which the algorithm terminates is κ(u). First, let
us show that:
(†) For m ∈ [k], if x is a solution of Lm
1 , then x[ξ] ≤ b if and only if, for each cost partition
c ∈ Cp , there exists a budget partition b ∈ Bp such that (c, u, b) is an abstraction
for MΠ and hM(c,u,b) (s0 ) ≥ mσ.
(⇐) Assume to the contrary that, for each cost partition c ∈ Cp , there exists a budget partition b ∈ Bp with hM(c,u,b)
S (s0 ) ≥ mσ, and yet x[ξ] > b. Given the values provided by x to the cost variables o∈O {c[i](o)}, let c be the corresponding cost partition,
and δ1 , . . . , δk be the induced lengths of the shortest paths from α1 (s0 ), . . . , αk (s0 ) to σvalued states in G1 , . . . , Gk , respectively. By our assumption, let b be a budget partition
such that hM(c,u,b) (s0 ) ≥ mσ. First, by the definition of strong 0-binary value partitions,
hM(c,u,b) (s0 ) ≥ mσ implies that there exists Z ⊆ k, |Z| = m such that, for i ∈ Z, b[i] ≥ δi .
Second, constraint (10c), maximization of ξ, and the fact that the only bound on each b[i]
is by δi imply together that, for i ∈ Z, x[b[i]] = δi . Putting things together, we obtain
b∈Bp

b ≥

X

b[i] ≥

i∈Z

X

δi =

i∈Z

X

(10c)

x[b[i]] ≥ ξ,

i∈Z

contradicting our assumption.
(⇒) Assume to the contrary that, x[ξ] ≤ b, and yet there exists a cost partition c ∈ Cp
such that, for all budget partitions b ∈ Bp with (c, u, b) ∈ Ap , we have hM(c,u,b) (s0 ) < mσ.
Let the shortest path lengths δ1 , . . . , δk be defined as above, but now with respect to the
specific cost partition c from the assumption.
Likewise, let xc be a solution to Lm
1 with an
S
extra constraint on the cost variables o∈O {c[i](o)} to be assigned to c. Since the objective
in Lm
1 is to maximize the value of ξ, we have
x[ξ] ≥ xc [ξ].

(22)

Now, let
Z=

argmax

X

Z 0 ⊆[k],|Z 0 |=m i∈Z 0

146

δi .

On Oversubscription Planning as Heuristic Search

Together, constraint (10c), maximization of ξ, and the fact that the only bound on each
b[i] is by δi (via the cost variables) imply that
xc [ξ] =

X

xc [b[i]] =

i∈Z

X

δi .

(23)

i∈Z

In turn, together with x[ξ] ≤ b and Eq. 22, Eq. 23 implies that
(
xc [b[i]],
b[i] =
0,

i∈Z
otherwise

is a budget partition with (c, u, b) ∈ Ap , and hM(c,u,b) (s0 ) ≥ mσ, contradicting our assumption.
Having proved the sub-claim (†), which basically captures the semantics of Lm
1 , suppose
that the algorithm terminates within the loop, and returns mσ for some m > 0. By the
construction of the algorithm, if x is a solution of Lm
1 , then x[ξ] ≤ b. By (†), for each cost
partition c ∈ Cp , there exists (c, u, b) ∈ Ap such that h(c,u,b) (s) ≥ mσ. If m = k, then
trivially κs (u) = mσ. Otherwise, if m < k, we know that the algorithm did not terminate
at the previous iteration corresponding to m + 1. Again, (†) then implies that there exists a
cost partition c ∈ Cp for which no (c, u, b) ∈ Ap will induce h(c,u,b) (s) ≥ (m + 1)σ. Hence,
by the definition of κs (u), κs (u) < (m + 1)σ, and in turn, since u is a strong 0-binary value
partition, we have κs (u) = mσ. Finally, if the algorithm terminates after the loop and
returns 0, then precisely the same argument on the basis of (†) implies κs (u) = 0.

Lemma 9 For any 0 <  < mini∈[k] σi , the algorithm in Figure 10a computes κ such that
κ − κ(u) ≤ .
Proof: The arguments for the boundness and non-emptiness of the polytope induced by
Lv2 are precisely the same as for the polytope of Lm
1 studied in Lemma 6, and thus the
termination of the algorithm is straightforward. In what follows, we prove that the value
returned by the algorithm satisfies the claim of the lemma. Let u be the given 0-binary
partition. Similarly to the proof of Lemma 9, first we prove a sub-claim that:
(†) For v ∈ R0+ , if x is a solution of Lv2 , then x[ξ] ≤ b if and only if, for each cost partition
c ∈ Cp , there exists a budget partition b ∈ Bp such that (c, u, b) is an abstraction
for MΠ and hM(c,u,b) (s0 ) ≥ v.
The proof of (†) mirrors the proof of the respective sub-claim in Lemma 5, mutatis mutandis,
and thus it is provided here only for ease of verification.
(⇐) Assume to the contrary that, for each cost partition c ∈ Cp , there exists a budget
partition b ∈ Bp with hM(c,u,b) (s0 ) ≥ v, and yet x[ξ] > b.
S
Given the values provided by x to the cost variables o∈O {c[i](o)}, let c be the corresponding cost partition, and, for i ∈ [k], let δi be the induced length of the shortest
path from αi (s0 ) to the σi -valued states in Gi . By our assumption, let b be a budget
partition such that hM(c,u,b) (s0 ) ≥ v. First, by the
P definition of 0-binary value partitions,
hM(c,u,b) (s0 ) ≥ v implies that there exists Z ⊆ k, i∈Z σi ≥ v such that, for i ∈ Z, b[i] ≥ δi .
147

Domshlak & Mirkis

Second, constraint (11c), maximization of ξ, and the fact that the only bound on each b[i]
is by δi , imply together that, for i ∈ Z, x[b[i]] = δi . Putting things together, we obtain
b∈Bp

b ≥

X

b[i] ≥

i∈Z

X

δi =

i∈Z

X

(11c)

x[b[i]] ≥ ξ,

i∈Z

contradicting our assumption.
(⇒) Assume to the contrary that, x[ξ] ≤ b, and yet there exists a cost partition c ∈ Cp
such that, for all budget partitions b ∈ Bp with (c, u, b) ∈ Ap , we have hM(c,u,b) (s0 ) < v.
Let the shortest path lengths δ1 , . . . , δk be defined as above, but now with respect to the
specific cost partition c from the assumption.
Likewise, let xc be a solution to Lv2 with an
S
extra constraint on the cost variables o∈O {c[i](o)} to be assigned to c. Since the objective
in Lv2 is to maximize the value of ξ, we have
x[ξ] ≥ xc [ξ].

(24)

Now, let
Z = argmax

X

0
PZ ⊆[k], i∈Z 0
i∈Z 0 σi ≥v

δi .

Together, constraint (11c), maximization of ξ, and the fact that the only bound on each
b[i] is by δi (via the cost variables) imply that
xc [ξ] =

X

xc [b[i]] =

i∈Z

X

δi .

(25)

i∈Z

In turn, together with x[ξ] ≤ b and Eq. 24, Eq. 25 implies that
(
xc [b[i]], i ∈ Z
b[i] =
,
0,
otherwise
is a budget partition with (c, u, b) ∈ Ap , and hM(c,u,b) (s0 ) ≥ v, contradicting our assumption.
This finalizes the proof of the sub-claim (†). Now,Pconsider the interval end-points α
and β at the termination
of the while-loop. If β =
i∈[k] σi , then, trivially, κ(u) ≤ β.
P
Otherwise, if β < i∈[k] σi , then, by the construction of the algorithm, at some iteration of
the while loop, a test always-achievable(β) was issued, came back negative, and thus, for the
solutions xβ of Lβ2 , we have xβ [ξ] > b. Hence, by (†), κ(u) < β. Now, if α 6= 0, then, by the
construction of the algorithm, at some iteration of the while loop, a test always-achievable(α)
was issued, came back positive, and thus, for the solutions xα of Lα2 , we have xα [ξ] ≤ b.
Hence, by (†), κ(u) ≥ α. Putting these properties on α and β together with the while-loop’s
termination condition β − α ≤  implies κ − κ(u) = β − κ(u) ≤ . Finally, if α = 0, then
 < mini∈[k] σi implies β < mini∈[k] σi . In turn, since κ(u) corresponds to a sum of values of
some states in the k models of M(c,u,b) , κ(u) ≤ β concluded above implies κ = κ(u) = 0.

148

On Oversubscription Planning as Heuristic Search

Theorem 16 Let Π = hV, s0 , u; O, c, bi be an OSP task, L be a set of pairwise disjoint
ε-landmarks for Π, lcost be an admissible landmark cost function from L, and ΠL be the
respective budget reducing compilation of Π. For every π for Π with Qb (π) > 0, there is a
plan πL for ΠL with QbL (πL ) = Qb (π), and vice versa.
Proof: Let πL be a plan
Snfor ΠL , and let π be the operator sequence obtained by replacing
all operators o from i=1 OLi along πL with the respective operators o ∈ O. By the
definition S
of the action set of ΠL in Eq. 15, we have π applicable in s0 , and s0 JπK =
s0L JπL K \ ni=1 dom(vLi ). Thus, Qb (π) = QbL (πL ). Likewise, again by the definition of
the action set of ΠL in Eq. 15 and the fact that no operator in OL achieves the control
propositions {hvL1 /1i , . . . , hvLn /1i}, we have |OLi ∩ πL | ≤ 1. From that, we have

c(π) ≤ cL (πL ) +

n
X

lcost(Li ).

i=1

P
In turn, b = bL + ni=1 lcost(Li ) by Eq. 14, and cL (πL ) ≤ bL by the virtue of πL being a
plan for ΠL . Therefore, it holds that c(π) ≤ b, and thus π is a plan for Π.
In the opposite direction, let π be a plan for Π with Qb (π) > 0, and let πL be an
operator sequence obtained by replacing, for each ε-landmark L ∈ L, every first occurrence
of an operator from L with the respective “cost reduced” operator from OL . It is easy to
verify that πL is applicable in s0L , and that QbL (πL ) = Qb (π). Likewise, by the definition
of ε-landmarks, every L ∈ L will have a presence along π. From that, we have

c(πL ) = c(π) −

n
X

lcost(Li ) ≤ b −

i=1

n
X

lcost(Li ) = bL ,

i=1

where the first equality is by pairwise disjointness of {L1 , . . . , Ln }, the inequality is by π
being a plan for Π, and the second equality is by Eq. 14. Thus, πL is a plan for ΠL .


Theorem 17 Let Π = hV, s0 , u; O, c, bi be an OSP task, let L = {L1 , . . . , Ln } be a set of
ε-landmarks for Π, let lcost be an admissible landmark cost function from L, and let ΠL∗
be the (generalized) budget reducing compilation of Π. For every π for Π with Qb (π) > 0,
there is a plan πL∗ for ΠL∗ with QbL∗ (πL∗ ) = Qb (π), and vice versa.
Proof: Let πL∗ be a plan for ΠL∗ , and let π be the operator sequence obtained by (i) replacing
all operators o with the respective operators o ∈ O, and (ii) removal of all get operators. By
Eq. 17, we have π applicable in s0 , and s0 JπK = s0L∗ JπL∗ K \ {hvL1 /1i , . . . , hvLn /1i}. Thus,
Qb (π) = QbL∗ (πL∗ ). Now, for each ε-landmark L ∈ L, let ξ(L) be the number of instances
of the cost reduced counterparts o of the operators from L along πL∗ . By Eqs. 17 and 18,
for each L ∈ L, πL∗ must contain at least ξ(L) − 1 instances of operator get(L). From that,
we have
149

Domshlak & Mirkis

X

c(π) ≤ cL∗ (πL∗ ) +

X

lcost(L) −

o∈πL∗ L∈L(o)

= cL∗ (πL∗ ) +

X
X

(ξ(L) − 1)·lcost(L)

L∈L

ξ(L)·lcost(L) −

L∈L

= cL∗ (πL∗ ) +

X

X

(ξ(L) − 1)·lcost(L)

L∈L

lcost(L)

L∈L

≤ bL∗ +

X

lcost(L)

L∈L

= b,
and thus π is a plan for Π.
In the opposite direction, let π = ho1 , . . . , om i be a plan for Π with Qb (π) > 0. By
the definition of ε-landmarks, every landmark Li ∈ L will have a presence along π. Let
of (i) , f (i) ∈ [n], be the first occurrence
of an operator from Li along π, that is, f (i) =


let ρ = o(1) , . . . , o(k) , k ≤ n, be the operator sequence obtained
argminj∈[m] {oj ∈ Li }, and S
by ordering the operators i∈[n] {of (i) } consistently with π. Note that, since ε-landmarks
in L are not necessarily disjoint, we may have f (i) = f (j) for some 1 ≤ i 6= j ≤ n, and thus
k can be strictly smaller than n.
Given the above, let πL∗ be an operator sequence obtained from π based on ρ by
(1) replacing each o(i) along π with o(i) , and
(2) inserting right before each o(i) an arbitrary ordered sequence of actions
i−1
[

{get(L) | L ∈ L, {o(j) , o(i) } ⊆ L}.

(26)

j=1

Note the set union semantics of Eq. 26: even if multiple operators from {o(1) , . . . , o(i−1) }
appear in some landmark L together with o(i) , only one instance of the operator get(L) is
inserted in step (2) before o(i) .
It is not hard to verify that πL∗ is applicable in s0L∗ , and that QbL∗ (πL∗ ) = Qb (π). Now,
step (1) of expanding π to πL∗ reduces the cost of the operator sequence by
k
X

X

lcost(L) =

i=1 L∈L(o(i) )

X

µ(L)·lcost(L),

L∈L

where µ(L) is the number of all occurrences of the operators fromP
L in ρ. In turn, step (2) of
expanding π to πL∗ increases the cost of the operator sequence by L∈L (µ(L) − 1)·lcost(L).
This is because, by Eq. 26, among all µ(L) operators o(i) along πL∗ such that o(i) ∈ L, all
but the first are preceded by the dedicated instances of the operator get(L). Thus,
X
X
cL∗ (πL∗ ) = c(π) −
lcost(L) ≤ b −
lcost(L) = bL∗ ,
L∈L

L∈L

that is, πL∗ is a plan for ΠL∗ .


150

On Oversubscription Planning as Heuristic Search

Lemma 20 Let Π be an OSP task, Π(ε,Sref ) be a (ε, Sref )-compilation of Π, L be a set of
landmarks for Π(ε,Sref ) , lcost be an admissible landmark cost function for L, and ΠL∗ be the
respective budget reducing compilation of (L, lcost) into Π. Let π1 and π2 be a pair of plans
↓V
for ΠL∗ with end-states s1 and s2 , respectively, such that s↓V
1 = s2 and
cL∗ (π1 ) +

X

lcost(L) ≥ cL∗ (π2 ) +

Then, for any plan
b
L
Q ∗ (π20 ) = QbL∗ (π10 ).

lcost(L).

(20)

L:hvL /0i∈s2

L:hvL /0i∈s1

π10

X

that extends π1 , there exists a plan π20 that extends π2 such that

Proof: Under the notation in the claim, the proof is by a constructive mapping of the plan
π10 to the corresponding plan π20 .
First, we derive from π10 a plan ρ01 for Π by (i) removing the f inish operator and all
the get(·) operators, and (ii) replacing all instances of each discounted operator o with
instances of the respective original operator o. This results in a plan ρ01 := ρ1 · ρ1e for Π
P
with s0 [[ρ1 ]] = s↓V
1 and c(ρ1 ) = cL∗ (π1 ) +
L:hvL /0i∈s1 lcost(L). To see the latter, for each
∗
operator ω ∈ OL , let κ(ω) ≥ 0 denote the number of instances of ω along π1 . Given that,
we have
c(ρ1 ) = cL∗ (π1 ) −

X

κ(get(L))lcost(L) +

L∈L

X

= cL∗ (π1 ) +

lcost(L) 

L∈L

= cL∗ (π1 ) +

X

X

X

κ(o)

L∈L

o:L∈L(o)






X

lcost(L)

κ(o) − κ(get(L))

o:L∈L(o)

(27)

lcost(L) · 1s1 (hvL /0i)

L∈L

= cL∗ (π1 ) +

X

lcost(L),

L:hvL /0i∈s1

where the second and fourth equalities are just formula manipulations, the first equality is
direct from the construction of ρ1 , and the third equality is by the definition of the budget
reducing compilation, and specifically, by Eqs. 17 and 18.
Similarly to the construction of P
ρ1 from π1 , we can construct ρ2 from π2 , with and
∗
s0 [[ρ2 ]] = s↓V
and
c(ρ
)
=
c
(π
)
+
2
2
L
2
L:hvL /0i∈s2 lcost(L). Thus, by Eq. 20, c(ρ1 ) ≥ c(ρ2 ),
and also, by the setting of the lemma, s0 [[ρ1 ]] = s0 [[ρ2 ]]. Hence, ρ02 = ρ2 · ρ1e is also a plan
for Π, and Qb (ρ01 ) = Qb (ρ02 ).
As the last step, we now construct from ρ02 a plan π20 for ΠL∗ as in the claim. First, by
the properties of π2 in the claim, the plan ρ2 for Π achieves all the landmarks L6∈s2 = {L |
hvL /0i ∈ s2 }. Second, by the definition of the landmark set L, ρ1e must satisfy the rest of
the landmarks, that is, L∈s2 = {L | hvL /1i ∈ s2 }. Let us denote the operator instances along
ρ1e as ho1 , . . . , ok i, k = |ρ1e |, and let {L1 , . . . , Lk } be a partition of L∈s2 with Li ⊆ L∈s2
being the subset of all landmarks from L∈s2 for which oi is their first achiever along ρ1e .
Given that, consider an operator sequence π2e := π (k) , recursively defined via π (0) = ,
and, if Li = ∅, then π (i) = π (i−1) · hoi i, else π (i) = π (i−1) · γ · hoi i, where γ is some (arbitrary)
151

Domshlak & Mirkis

sequencing of operators
{get(L) | L ∈ Li ∧ hvL /0i ∈ s0 Jπ2 KJπ (i−1) K}.
Finally, we set π20 := π2 · π2e .
By Eqs. 17 and 18 in the definition of the budget reducing compilation,
it is easy to
P
verify that the above construction of π2e ensures cL∗ (π2e ) = c(ρ1e )− hvL /1i∈s2 lcost(L) and
QbL∗ (π2e ) = Qb (ρ02 ). In turn, by the properties of π2 , this implies that QbL∗ (π20 ) = QbL∗ (π10 )
and cL∗ (π20 ) = cL∗ (π2 ) + cL∗ (π2e ).
Finally, since
X
lcost(L)
cL∗ (π2 ) = c(ρ2 ) −
hvL /0i∈s2

and
X

cL∗ (π2e ) = c(ρ1e ) −

lcost(L),

hvL /1i∈s2

we have
cL∗ (π20 ) = c(ρ2 ) + c(ρ1e ) −

X

lcost(L).

L∈L

Thus, since c(ρ1 ) ≥ c(ρ2 ) and ρ01 = ρ1 · ρ1e is a valid plan for Π, we have
X
cL∗ (π20 ) ≤ c(ρ1 ) + c(ρ1e ) −
lcost(L)
L∈L

≤

c(ρ01 )

−

X

lcost(L)

L∈L

≤b−

X

lcost(L),

L∈L

finalizing the proof that π20 is a plan for ΠL∗ as in the claim.

152



On Oversubscription Planning as Heuristic Search

Appendix B. Detailed Evaluation Results
(a)
108

unsolved

107
106
105
hM

104
103
102

unsolved

airport
blocks
depot
driverlog
freecell
grid
gripper
logistics
miconic
mystery
openstacks
pipesworld
psr-small
tpp
trucks
rovers
satellite
zenotravel

101

100 0
10 101 102 103 104 105 106 107 108
blind

(b)
108

unsolved

107
106
hM

105
104
103
unsolved

102
101

100 0
10 101 102 103 104 105 106 107 108
basic

Figure 18: The comparison in Figure 8, p. 117, restricted to the tasks budgeted with 25%
of the minimal cost of achieving the entire set of subgoals

153

Domshlak & Mirkis

(a)
108

unsolved

107
106
105
hM

104
103
102

unsolved

airport
blocks
depot
driverlog
freecell
grid
gripper
logistics
miconic
mystery
openstacks
pipesworld
psr-small
tpp
trucks
rovers
satellite
zenotravel

101

100 0
10 101 102 103 104 105 106 107 108
blind

(b)
108

unsolved

107
106
hM

105
104
103
unsolved

102
101

100 0
10 101 102 103 104 105 106 107 108
basic

Figure 19: The comparison in Figure 8, p. 117, restricted to the tasks budgeted with 50%
of the minimal cost of achieving the entire set of subgoals

154

On Oversubscription Planning as Heuristic Search

(a)
108

unsolved

107
106
105
hM

104
103
102

unsolved

airport
blocks
depot
driverlog
freecell
grid
gripper
logistics
miconic
mystery
openstacks
pipesworld
psr-small
tpp
trucks
rovers
satellite
zenotravel

101

100 0
10 101 102 103 104 105 106 107 108
blind

(b)
108

unsolved

107
106
hM

105
104
103
unsolved

102
101

100 0
10 101 102 103 104 105 106 107 108
basic

Figure 20: The comparison in Figure 8, p. 117, restricted to the tasks budgeted with 75%
of the minimal cost of achieving the entire set of subgoals

155

Domshlak & Mirkis

(a)
108

unsolved

107
106
105
hM

104
103
102

unsolved

airport
blocks
depot
driverlog
freecell
grid
gripper
logistics
miconic
mystery
openstacks
pipesworld
psr-small
tpp
trucks
rovers
satellite
zenotravel

101

100 0
10 101 102 103 104 105 106 107 108
blind

(b)
108

unsolved

107
106
hM

105
104
103
unsolved

102
101

100 0
10 101 102 103 104 105 106 107 108
basic

Figure 21: The comparison in Figure 8, p. 117, restricted to the tasks budgeted with 100%
of the minimal cost of achieving the entire set of subgoals

156

On Oversubscription Planning as Heuristic Search

(a) blind
108

unsolved

107
compile-and-BFBB

106
105
104
103
102

unsolved

airport
blocks
depot
driverlog
freecell
grid
gripper
logistics
miconic
mystery
openstacks
pipesworld
psr-small
tpp
trucks
rovers
satellite
zenotravel

101

100
100 101 102 103 104 105 106 107 108
BFBB

(b) hM
108

unsolved

compile-and-BFBB

107
106
105
104
103
unsolved

102
101

100
100 101 102 103 104 105 106 107 108
BFBB

Figure 22: The comparison in Figure 15, p. 140, restricted to the tasks budgeted with 25%
of the minimal cost of achieving the entire set of subgoals

157

Domshlak & Mirkis

(a) blind
108

unsolved

107
compile-and-BFBB

106
105
104
103
102

unsolved

airport
blocks
depot
driverlog
freecell
grid
gripper
logistics
miconic
mystery
openstacks
pipesworld
psr-small
tpp
trucks
rovers
satellite
zenotravel

101

100
100 101 102 103 104 105 106 107 108
BFBB

(b) hM
108

unsolved

compile-and-BFBB

107
106
105
104
103
unsolved

102
101

100
100 101 102 103 104 105 106 107 108
BFBB

Figure 23: The comparison in Figure 15, p. 140, restricted to the tasks budgeted with 50%
of the minimal cost of achieving the entire set of subgoals

158

On Oversubscription Planning as Heuristic Search

(a) blind
108

unsolved

107
compile-and-BFBB

106
105
104
103
102

unsolved

airport
blocks
depot
driverlog
freecell
grid
gripper
logistics
miconic
mystery
openstacks
pipesworld
psr-small
tpp
trucks
rovers
satellite
zenotravel

101

100
100 101 102 103 104 105 106 107 108
BFBB

(b) hM
108

unsolved

compile-and-BFBB

107
106
105
104
103
unsolved

102
101

100
100 101 102 103 104 105 106 107 108
BFBB

Figure 24: The comparison in Figure 15, p. 140, restricted to the tasks budgeted with 75%
of the minimal cost of achieving the entire set of subgoals

159

Domshlak & Mirkis

(a) blind
108

unsolved

107
compile-and-BFBB

106
105
104
103
102

unsolved

airport
blocks
depot
driverlog
freecell
grid
gripper
logistics
miconic
mystery
openstacks
pipesworld
psr-small
tpp
trucks
rovers
satellite
zenotravel

101

100 0
10 101 102 103 104 105 106 107 108
BFBB

(b) hM
108

unsolved

compile-and-BFBB

107
106
105
104
103
unsolved

102
101

100 0
10 101 102 103 104 105 106 107 108
BFBB

Figure 25: The comparison in Figure 15, p. 140, restricted to the tasks budgeted with 100%
of the minimal cost of achieving the entire set of subgoals

160

On Oversubscription Planning as Heuristic Search

(a) blind
108
107
inc-compile-and-BFBB

airport
blocks
depot
driverlog
freecell
grid
gripper
logistics
miconic
mystery
openstacks
pipesworld
psr-small
tpp
trucks
rovers
satellite
zenotravel

106
105
104
103
102
101
100
100 101 102 103 104 105 106 107 108
BFBB

(b) hM
108

inc-compile-and-BFBB

107
106
105
104
103
102
101
100
100 101 102 103 104 105 106 107 108
BFBB

Figure 26: The comparison in Figure 16, p. 142, restricted to the tasks budgeted with 25%
of the minimal cost of achieving the entire set of subgoals

161

Domshlak & Mirkis

(a) blind
108
107
inc-compile-and-BFBB

airport
blocks
depot
driverlog
freecell
grid
gripper
logistics
miconic
mystery
openstacks
pipesworld
psr-small
tpp
trucks
rovers
satellite
zenotravel

106
105
104
103
102
101
100
100 101 102 103 104 105 106 107 108
BFBB

(b) hM
108

inc-compile-and-BFBB

107
106
105
104
103
102
101
100
100 101 102 103 104 105 106 107 108
BFBB

Figure 27: The comparison in Figure 16, p. 142, restricted to the tasks budgeted with 50%
of the minimal cost of achieving the entire set of subgoals

162

On Oversubscription Planning as Heuristic Search

(a) blind
108
107
inc-compile-and-BFBB

airport
blocks
depot
driverlog
freecell
grid
gripper
logistics
miconic
mystery
openstacks
pipesworld
psr-small
tpp
trucks
rovers
satellite
zenotravel

106
105
104
103
102
101
100
100 101 102 103 104 105 106 107 108
BFBB

(b) hM
108

inc-compile-and-BFBB

107
106
105
104
103
102
101
100
100 101 102 103 104 105 106 107 108
BFBB

Figure 28: The comparison in Figure 16, p. 142, restricted to the tasks budgeted with 75%
of the minimal cost of achieving the entire set of subgoals

163

Domshlak & Mirkis

(a) blind
108
107
inc-compile-and-BFBB

airport
blocks
depot
driverlog
freecell
grid
gripper
logistics
miconic
mystery
openstacks
pipesworld
psr-small
tpp
trucks
rovers
satellite
zenotravel

106
105
104
103
102
101
100 0
10 101 102 103 104 105 106 107 108
BFBB

(b) hM
108

inc-compile-and-BFBB

107
106
105
104
103
102
101
100 0
10 101 102 103 104 105 106 107 108
BFBB

Figure 29: The comparison in Figure 16, p. 142, restricted to the tasks budgeted with 100%
of the minimal cost of achieving the entire set of subgoals

164

On Oversubscription Planning as Heuristic Search

References
Bäckström, C., & Klein, I. (1991). Planning in polynomial time: The SAS-PUBS class.
Computational Intelligence, 7 (3), 181–197.
Bäckström, C., & Nebel, B. (1995). Complexity results for SAS+ planning. Computational
Intelligence, 11 (4), 625–655.
Baier, J. A., Bacchus, F., & McIlraith, S. (2009). A heuristic search approach to planning
with temporally extended preferences. Artificial Intelligence, 173 (5-6), 593–618.
Benton, J., Coles, A. J., & Coles, A. I. (2012). Temporal planning with preferences and
time-dependent continuous costs. In Proceedings of the 22nd International Conference
on Automated Planning and Scheduling (ICAPS), pp. 2–10.
Benton, J., Do, M., & Kambhampati, S. (2009). Anytime heuristic search for partial satisfaction planning. Artificial Intelligence, 173 (5-6), 562–592.
Benton, J., van den Briel, M., & Kambhampati, S. (2007). A hybrid linear programming
and relaxed plan heuristic for partial satisfaction planning problems. In Proceedings
of the Seventeenth International Conference on Automated Planning and Scheduling
(ICAPS), pp. 34–41.
Bertsimas, D., & Vempala, S. (2004). Solving convex programs by random walks. Journal
of the ACM, 51 (4), 540–556.
Bonet, B. (2013). An admissible heuristic for SAS+ planning obtained from the state
equation. In Proceedings of the 23rd International Joint Conference on Artificial
Intelligence (IJCAI), pp. 2268–2274.
Bonet, B., & Geffner, H. (2001). Planning as heuristic search. Artificial Intelligence, 129 (1–
2), 5–33.
Bonet, B., & Geffner, H. (2008). Heuristics for planning with penalties and rewards formulated in logic and computed through circuits. Artificial Intelligence, 172 (12-13),
1579–1604.
Bonet, B., & Helmert, M. (2010). Strengthening landmark heuristics via hitting sets. In
Proceedings of the 19th European Conference on Artificial Intelligence (ECAI), pp.
329–334.
Brafman, R. I., & Chernyavsky, Y. (2005). Planning with goal preferences and constraints.
In Proceedings of the International Conference on Automated Planning and Scheduling, pp. 182–191.
Clarke, E., Grumberg, O., & Peled, D. (1999). Model Checking. MIT Press.
Coles, A. I., Fox, M., Long, D., & Smith, A. J. (2008). Additive-disjunctive heuristics for
optimal planning. In Proceedings of the 18th International Conference on Automated
Planning and Scheduling (ICAPS), pp. 44–51.
Coles, A. J., Coles, A., Fox, M., & Long, D. (2013). A hybrid LP-RPG heuristic for modelling
numeric resource flows in planning. Journal of Artificial Intelligence Research, 46,
343–412.
165

Domshlak & Mirkis

Coles, A. J., & Coles, A. I. (2011). LPRPG-P: Relaxed plan heuristics for planning with
preferences. In Proceedings of the 21st International Conference on Automated Planning and Scheduling (ICAPS), pp. 37–45.
Cousot, P., & Cousot, R. (1992). Abstract interpretation frameworks. Journal of Logic and
Computation, 2 (4), 511–547.
Dantzig, G. B. (1963). Linear Programming and Extensions. Princeton University Press.
Dantzig, T. (1930). Number: The Language of Science. Macmillan.
Desrochers, M., & Soumis, F. (1988). A generalized permanent labelling algorithm for
the shortest path problem with time windows. Information Systems and Operations
Research, 26, 191–212.
Do, M. B., Benton, J., van den Briel, M., & Kambhampati, S. (2007). Planning with goal
utility dependencies. In Proceedings of the 20th International Joint Conference on
Artificial Intelligence (IJCAI), pp. 1872–1878.
Domshlak, C., Hoffmann, J., & Sabharwal, A. (2009). Friends or foes? On planning as
satisfiability and abstract CNF encodings. Journal of Artificial Intelligence Research,
36, 415–469.
Domshlak, C., Katz, M., & Lefler, S. (2012). Landmark-enhanced abstraction heuristics.
Artificial Intelligence, 189, 48–68.
Dudzinski, K., & Walukiewicz, S. (1987). Exact methods for the Knapsack problem and its
generalizations. European Journal of Operational Research, 28, 3–21.
Dvorak, F., & Barták, R. (2010). Integrating time and resources into planning. In Proceedings of the 22nd IEEE International Conference on Tools with Artificial Intelligence
(ICTAI), pp. 71–78.
Edelkamp, S. (2001). Planning with pattern databases. In Proceedings of the European
Conference on Planning (ECP), pp. 84–90.
Edelkamp, S. (2003). Taming numbers and durations in the model checking integrated
planning system. Journal of Artificial Intelligence Research, 20, 195–238.
Fikes, R. E., & Nilsson, N. (1971). STRIPS: A new approach to the application of theorem
proving to problem solving. Artificial Intelligence, 2, 189–208.
Fox, M., & Long, D. (2003). PDDL2.1: An extension to PDDL for expressing temporal
planning problems. Journal of Artificial Intelligence Research, 20, 61–124.
Garey, M. R., & Johnson, D. S. (1978). Computers and Intractability: A Guide to the Theory
of NP-Completeness. W.H. Freeman and Company, New York.
Geffner, H., & Bonet, B. (2013). A Concise Introduction to Models and Methods for Automated Planning. Synthesis Lectures on Artificial Intelligence and Machine Learning.
Morgan & Claypool.
Gerevini, A., Haslum, P., Long, D., Saetti, A., & Dimopoulos, Y. (2009). Deterministic
planning in the fifth international planning competition: PDDL3 and experimental
evaluation of the planners. Artificial Intelligence, 173 (5-6), 619–668.
166

On Oversubscription Planning as Heuristic Search

Gerevini, A., Saetti, A., & Serina, I. (2003). Planning through stochastic local search and
temporal action graphs in LPG. Journal of Artificial Intelligence Research, 20, 239–
290.
Gerevini, A., Saetti, A., & Serina, I. (2008). An approach to efficient planning with numerical
fluents and multi-criteria plan quality. Artificial Intelligence, 172 (8-9), 899–944.
Grotschel, M., Lovasz, L., & Schrijver, A. (1981). The ellipsoid method and its consequences
theorems in combinatorial optimization. Combinatorica, 1, 169–197.
Handler, G., & Zang, I. (1980). A dual algorithm for the constrained shortest path problem.
Networks, 10, 293–310.
Haslum, P. (2013). Heuristics for bounded-cost search. In Proceedings of the 23rd International Conference on Automated Planning and Scheduling (ICAPS), pp. 312–316.
Haslum, P., Bonet, B., & Geffner, H. (2005). New admissible heuristics for domainindependent planning. In Proceedings of the 20th National Conference on Artificial
Intelligence (AAAI), pp. 1163–1168.
Haslum, P., Botea, A., Helmert, M., Bonet, B., & Koenig, S. (2007). Domain-independent
construction of pattern database heuristics for cost-optimal planning. In Proceedings
of the 19th National Conference on Artificial Intelligence (AAAI), pp. 1007–1012.
Haslum, P., & Geffner, H. (2000). Admissible heuristics for optimal planning. In Proceedings of the 15th International Conference on Artificial Intelligence Planning Systems
(AIPS), pp. 140–149.
Haslum, P., & Geffner, H. (2001). Heuristic planning with time and resources. In Proceedings
of the 6th European Conference on Planning (ECP), pp. 107–112.
Helmert, M. (2002). Decidability and undecidability results for planning with numerical
state variables. In Proceedings of the Sixth International Conference on Artificial
Intelligence Planning and Scheduling (AIPS), pp. 44–53.
Helmert, M. (2006). The Fast Downward planning system. Journal of Artificial Intelligence
Research, 26, 191–246.
Helmert, M., & Domshlak, C. (2009). Landmarks, critical paths and abstractions: What’s
the difference anyway?. In Proceedings of the 19th International Conference on Automated Planning and Scheduling (ICAPS), pp. 162–169.
Helmert, M., Haslum, P., & Hoffmann, J. (2007). Flexible abstraction heuristics for optimal
sequential planning. In Proceedings of the 17th International Conference on Automated
Planning and Scheduling (ICAPS), pp. 200–207.
Helmert, M., Haslum, P., Hoffmann, J., & Nissim, R. (2014). Merge-and-shrink abstraction:
A method for generating lower bounds in factored state spaces. Journal of the ACM,
61 (3), 16:1–63.
Hoffmann, J. (2003). The Metric-FF planning system: Translating “ignoring delete lists”
to numeric state variables. Journal of Artificial Intelligence Research, 20, 291–341.
Hoffmann, J., Gomes, C. P., Selman, B., & Kautz, H. A. (2007). SAT encodings of statespace reachability problems in numeric domains. In Proceedings of the 20th International Joint Conference on Artificial Intelligence (IJCAI), pp. 1918–1923.
167

Domshlak & Mirkis

Hoffmann, J., & Nebel, B. (2001). The FF planning system: Fast plan generation through
heuristic search. Journal of Artificial Intelligence Research, 14, 253–302.
Hoffmann, J., Porteous, J., & Sebastia, L. (2004). Ordered landmarks in planning. Journal
of Artificial Intelligence Research, 22, 215–278.
Karp, R. (1972). Reducibility among combinatorial problems. In Complexity of Computer
Computations, pp. 85–103. Plenum Press, New York.
Karpas, E., & Domshlak, C. (2009). Cost-optimal planning with landmarks. In Proceedings
of the International Joint Conference on Artificial Intelligence (IJCAI-09), pp. 1728–
1733.
Katz, M., & Domshlak, C. (2010a). Implicit abstraction heuristics. Journal of Artificial
Intelligence Research, 39, 51–126.
Katz, M., & Domshlak, C. (2010b). Optimal admissible composition of abstraction heuristics. Artificial Intelligence, 174, 767–798.
Kellerer, H., Pferschy, U., & Pisinger, D. (2004). Knapsack Problems. Springer-Verlag
Berlin.
Keyder, E., & Geffner, H. (2009). Soft goals can be compiled away. Journal of Artificial
Intelligence Research, 36, 547–556.
Koehler, J. (1998). Planning under resource constraints. In Proceedings of the 13th European
Conference on Artificial Intelligence (ECAI), pp. 489–493.
Mirkis, V., & Domshlak, C. (2013). Abstractions for oversubscription planning. In Proceedings of the 23rd International Conference on Automated Planning and Scheduling
(ICAPS), pp. 153–161.
Mirkis, V., & Domshlak, C. (2014). Landmarks in oversubscription planning. In Proceedings
of the 23rd European Conference on Artificial Intelligence (ECAI), pp. 633–638.
Nakhost, H., Hoffmann, J., & Müller, M. (2012). Resource-constrained planning: A Monte
Carlo random walk approach. In Proceedings of the 22nd International Conference on
Automated Planning and Scheduling (ICAPS), pp. 181–189.
Nebel, B. (2000). On the compilability and expressive power of propositional planning
formalisms. Journal of Artificial Intelligence Research, 12, 271–315.
Nemirovsky, A., & Yudin, N. (1994). Interior-Point Polynomial Methods in Convex Programming. SIAM.
Pearl, J. (1984). Heuristics - Intelligent Search Strategies for Computer Problem Solving.
Addison-Wesley.
Pommerening, F., & Helmert, M. (2013). Incremental LM-Cut. In Proceedings of the 23rd
International Conference on Automated Planning and Scheduling (ICAPS), pp. 162–
170, Rome, Italy.
Porteous, J., Sebastia, L., & Hoffmann, J. (2001). On the extraction, ordering, and usage
of landmarks in planning. In Proceedings of the 6th European Conference on Planning
(ECP 01), pp. 37–49.
168

On Oversubscription Planning as Heuristic Search

Punnen, A. P. (1992). K-sum linear programming. The Journal of the Operational Research
Society, 43 (4), 359–363.
Richter, S., Helmert, M., & Westphal, M. (2008). Landmarks revisited. In Proceedings of
the 23rd AAAI Conference on Artificial Intelligence (AAAI-08), pp. 975–982.
Russell, S., & Norvig, P. (2009). Artificial Intelligence: A Modern Approach (3 edition).
Pearson.
Sanchez, R., & Kambhampati, S. (2005). Planning graph heuristics for selecting objectives in over-subscription planning problems. In Proceedings of the 15th International
Conference on Automated Planning and Scheduling (ICAPS), pp. 192–201.
Smith, D. (2004). Choosing objectives in over-subscription planning. In Proceedings of the
14th International Conference on Automated Planning and Scheduling (ICAPS), pp.
393–401.
Thayer, J. T., & Ruml, W. (2011). Bounded suboptimal search: A direct approach using
inadmissible estimates. In Proceedings of the 22nd International Joint Conference on
Artificial Intelligence (IJCAI), pp. 674–679.
Thayer, J. T., Stern, R. T., Felner, A., & Ruml, W. (2012). Faster bounded-cost search
using inadmissible estimates. In Proceedings of the 22nd International Conference on
Automated Planning and Scheduling (ICAPS), pp. 270–278.
van den Briel, M., Sanchez, R., Do, M. B., & Kambhampati, S. (2004). Effective approaches
for partial satisfaction (over-subscription) planning. In Proceedings of the 19th AAAI
Conference on Artificial Intelligence (AAAI), pp. 562–569.
van den Briel, M., Benton, J., Kambhampati, S., & Vossen, T. (2007). An LP-based heuristic for optimal planning. In Proceedings of the 13th International Conference on
Principles and Practice of Constraint Programming (CP), pp. 651–665.
Yang, F., Culberson, J., Holte, R., Zahavi, U., & Felner, A. (2008). A general theory
of additive state space abstractions. Journal of Artificial Intelligence Research, 32,
631–662.

169

