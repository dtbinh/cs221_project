Journal of Articial Intelligence Research 16 (2002) 167-207

Submitted 3/01; published 3/02

Learning Geometrically-Constrained Hidden Markov Models for
Robot Navigation: Bridging the Topological-Geometrical Gap
Hagit Shatkay

hagit.shatkay@celera.com

Informatics Research Group,
Celera Genomics, Rockville, MD 20850

Leslie Pack Kaelbling

Articial Intelligence Laboratory
Massachusetts Institute of Technology, Cambridge, MA 02139

lpk@ai.mit.edu

You will come to a place where the streets are not marked.
Some windows are lighted but mostly they're darked.
A place you could sprain both your elbow and chin!
Do you dare to stay out? Do you dare to go in?...
And if you go in, should you turn left or right...
or right-and-three-quarters? or, maybe, not quite?...
Simple it's not, I'm afraid you will nd,
for a mind-maker-upper to make up his mind.

Oh, the Places You'll Go, Dr. Seuss.

Abstract
Hidden Markov models (hmms) and partially observable Markov decision processes
(pomdps) provide useful tools for modeling dynamical systems. They are particularly
useful for representing the topology of environments such as road networks and oce
buildings, which are typical for robot navigation and planning. The work presented
here describes a formal framework for incorporating readily available odometric information and geometrical constraints into both the models and the algorithm that learns
them. By taking advantage of such information, learning hmms/pomdps can be made
to generate better solutions and require fewer iterations, while being robust in the face
of data reduction. Experimental results, obtained from both simulated and real robot
data, demonstrate the eectiveness of the approach.

1 Introduction

This work is concerned with robots that need to perform tasks in structured environments.
A robot moving in the environment suers from two main limitations: its noisy sensors prevent
it from condently knowing where it is, while its noisy eectors prevent it from knowing with
certainty where its actions will take it. We concentrate here on structured environments, which
can in turn be characterized by two main properties: such environments consist of vast uneventful and uninteresting areas, and are interspersed with relatively few interesting positions or
situations. Consider for instance a robot delivering a bagel in an oce building. The interesting
situations are the doors and the intersections in the building hallways, as well as the various
c 2002 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

Shatkay & Kaelbling

positions where the bagel might be with respect to the robot's arm (e.g., the robot is holding
the bagel, puts it down, etc.) Most other aspects of the environment, such as the desk positions
in the oces, are inconsequential for the bagel delivery task.
A natural way to represent the combination of such an environment and the robot's interactions
with it, is as a probabilistic automaton, in which states represent interesting situations, and
edges between states represent the actions leading from one situation to another. Probability
distributions over the transitions and over the possible observations the robot may perceive at
each situation model the robot's noisy eectors and sensors, respectively.
Such models are formally known as pomdp (partially observable Markov decision process) models, and have been proven useful for robot planning and acting under the inherent world uncertainty (Simmons & Koenig, 1995; Nourbakhsh, Powers, & Bircheld, 1995; Cassandra, Kaelbling, & Kurien, 1996).
Despite much work on using such models, the task of learning them directly and automatically
from the data has not been widely addressed. Research concerning this immediate topic to date
consists mostly of the work done by Simmons and Koenig (1996b). The assumption underlying
their work was that a human provides a rather accurate topological model of the states and
their connections, and the exact probability distributions are then learned on top of this model,
using a version of the Baum-Welch algorithm (Rabiner, 1989). Another interesting approach to
the acquisition of topological models is that of Thrun and Bucken (1996a,1996b; Thrun, 1999),
who focused on extracting deterministic topological maps from previously acquired geometricalgrid-based maps, where the latter were learned directly from the data. Further discussion of
related research on both the geometrical and the topological approaches, in their probabilistic
and deterministic versions, is given in the next section.
The work reported here is the rst successful attempt we are aware of to learn purely probabilistictopological models, directly and completely from recorded data, without using previous humanprovided or grid-based models. It is based on using weak geometric information, recorded by
the robot, to help learn the topology of the environment, and represent it as a probabilistic
model. Therefore, it directly bridges the historically perceived gap between topological and
geometrical information, and addresses the claim presented in Thrun's work (1999) that the
main shortcoming of the topological approach is its failure to utilize the inherent geometry of
the learnt environment.
Most robots are equipped with wheel encoders that enable an odometer to record the change in
the robot's position as it moves through the environment. This data is typically very noisy and
inaccurate. The oors in the environment are rarely smooth, the wheels of the robot are not
always aligned and neither are the motors, the mechanics is imperfect, resulting in slippage and
drift. All these eects accumulate, and if we were to mark the initial position of the robot, and
try to estimate its current position based on summing a long sequence of odometric recordings,
the resulting estimate will be incorrect. That is, the raw recorded odometric information is
not an eective tool, in and of itself, for determining the absolute location of the robot in the
environment.
While our approach is not aimed at determining absolute locations, the idea underlying it is that
this weak odometric information, despite its noise and inaccuracy, still provides geometrical cues
that can help to distinguish between dierent states, as well as to identify revisitation of the
same state. Hence, such information enhances the ability to learn topological models. However,
168

Learning Geometrically-Constrained HMMs

the use of geometrical information requires careful treatment of geometrical constraints and
directional data. We demonstrate how the existing models and algorithms can be extended to
take advantage of the noisy odometric data and the geometrical constraints. The geometrical
information is directly incorporated into the probabilistic topological framework, producing a
signicant improvement over the standard Baum-Welch algorithm, without the need for humanprovided model.
The rest of this paper is organized as follows: Section 2 provides a survey of previous work in
the area of learning maps for robot navigation, and briey refers to earlier work on learning
automata; Section 3 presents the formal framework for this work; Section 4 presents the main
aspects of our iterative learning algorithm, while Section 5 describes the strategies for selecting
the initial point from which the iterative process begins; Section 6 presents experimental results
obtained from both simulated and real robot data in traditionally hard-to-learn environments.
The experiments demonstrate that our algorithm indeed converges to better models with fewer
iterations than the standard Baum-Welch method, and is robust in the face of data reduction.

2 Approaches to Learning Maps and Models

The work presented here lies in the intersection between the theoretical area of learning computational models|in particular, learning automata from data sequences|and the applied area of
map acquisition for robot navigation. We concentrate here on surveying the work in the latter
area, pointing out the distinction between our approach and its predecessors. We briey review
some results from automata and computational learning theory. A more comprehensive review
of theoretical results is given by Shatkay (1999).

2.1 Modeling Environments for Robot Navigation

In the context of maps and models for robot navigation, a distinction is usually made between two
principal kinds of maps: geometric and topological. Geometric maps describe the environment
as a collection of objects or occupied positions in space, and the geometric relationships among
them. The topological framework is less concerned with the geometrical positions, and models
the world as a collection of states and their connectivity, that is, which states are reachable from
each of the other states and what actions lead from one state to the next.
We draw an additional distinction, between world-centric1 maps that provide an \objective"
description of the environment independent of the agent using the map, and robot-centric models
which capture the interaction of a particular \subjective" agent with the environment. When
learning a map, the agent needs to take into account its own noisy sensors and actuators and try
to obtain an objectively correct map that other agents could use as well. Similarly, other agents
using the map need to compensate for their own limitations in order to assess their position
according to the map. When learning a model that captures interaction, the agent acquiring the
model is the one who is also using it. Hence, the noisy sensors and actuators specic to the agent
are reected in the model. A dierent model is likely to be needed by dierent agents. Most
of the related work described below, especially within the geometrical framework, is centered
around learning objective maps of the world rather than agent-specic models. We shall point
out in this survey the work that is concerned with the latter kind of models.
Our work focuses on acquiring purely topological models, and is less concerned with learning
geometrical relationships between locations or objects, or objective maps, although geometrical
1. We thank Sebastian Thrun for the terminology.

169

Shatkay & Kaelbling

relationships do serve as an aid in our acquisition process. The concept of a state used in this
topological framework is more general than the concept of a geometrical location, since a state
can include information such as the battery level, the arm position etc. Such information, which
is of great importance for planning, is non-geometrical in nature and therefore cannot be readily
captured in a purely geometrical framework. The following sections provide a survey of work
done both within the geometrical framework and within the topological framework, as well as
combinations of the two approaches.

2.2 Geometric Maps

Geometric maps provide a description of the environment in terms of the objects placed in it
and their positions. For example, grid-based maps are an instance of the geometric approach.
In a grid-based map, the environment is modeled as a grid (an array), where each position in
the grid can be either vacant or occupied by some object (binary values placed in the array).
This approach can be further rened to reect uncertainty about the world, by having grid cells
contain occupancy probabilities rather than just binary values. A lot of work has been done on
learning such grid-based maps for robot navigation through the use of sonar readings and their
interpretation, by Moravec and Elfes and others (Moravec & Elfes, 1985; Moravec, 1988; Elfes,
1989; Asada, 1991).
An underlying assumption when learning such maps is that the robot can tell (or nd out)
where it is on the grid when it obtains a sonar reading indicating an object, and therefore can
place the object correctly on the grid. A similar localization assumption, requiring the robot
to identify its geometrical location, underlies other geometric mapping techniques by Leonard
et al. (1991), Smith et al. (1991), Thrun et al. (1998b) and Dissanayake et al. (2001), even
when an explicit grid is not part of the model. Explicit localization can be hard to satisfy.
Leonard et al. (1991) and Smith et al. (1991) address this issue through the use of geometrical
beacons to estimate the location of the robot. In what is known as the Kalman lter method, a
Gaussian probability distribution is used to model the robot's possible current location, based
on observations collected up to the current point, (without allowing the renement of previous
position estimates based on later observations). Research in this area has recently been extended
in two directions: Leonard and Feder (2000) partition the task of learning one large map into
learning multiple smaller map-sections, thus addressing the issue of computational eciency.
Dissanayake et al. (2001) conduct a theoretical study of the approach and show its convergence
properties. The latter may lead to computational eciency by identifying the cases for which a
steady-state solution can be readily obtained, accordingly bounding the number of steps required
by the algorithms to reach a useful solution in these cases.
Work by Thrun et al. (1998a) uses a similar probabilistic approach for obtaining grid-based maps.
This work is rened (Thrun et al., 1998b) to rst learn the location of signicant landmarks in
the environment and then ll in the details of the complete geometrical grid, based on laser range
scans. The latter work extends the approach of Smith et al. , by using observations obtained
both before and after a location has been visited, in order to derive a probability distribution
over possible locations. To achieve this, the authors use a forward-backward procedure similar
to the one used in the Baum-Welch algorithm (Rabiner, 1989), in order to determine possible
locations from observed data. The approach resembles ours both in the use of the forwardbackward estimation procedure, and in its probabilistic basis, aiming at obtaining a maximum
likelihood map of the environment. It still signicantly diers from ours both in its initial
assumptions and in its nal results. The data assumed to be provided to the learner includes
170

Learning Geometrically-Constrained HMMs

both the motion model and the perceptual model of the robot. These consist of transition and
observation probabilities within the grid. Both of these components are learnt by our algorithm,
although not in a grid context but in a coarser-grained, topological framework. The end result of
their algorithm is a probabilistic grid-based map, while ours is a probabilistic topological model,
as further explained in the next section.
In addition to being concerned only with locations, rather than with the richer notion of state,
a fundamental drawback of geometrical maps is their ne granularity and high accuracy. Geometrical maps, particularly grid-based ones, tend to give an accurate and detailed picture of the
environment. In cases where it is necessary for a robot to know its exact location in terms of
metric coordinates, metric maps are indeed the best choice. However, many planning tasks do
not require such ne granularity or accurate measurements, and are better facilitated through a
more abstract representation of the world. For example, if a robot needs to deliver a bagel from
oce a to oce b, all it needs to have is a map depicting the relative location of a with respect to
b, the passageways between the two oces, and perhaps a few other landmarks to help it orient
itself if it gets lost. If it has a reasonably well-operating low-level obstacle avoidance mechanism
to help it bypass ower pots and chairs that it might encounter on its way, such objects do
not need to be part of the environment map. Just as a driver traveling between cities needs to
know neither his longitude and latitude coordinates on the globe, nor the location of the specic
houses along the way, the robot does not need to know its exact location within the building
nor the exact location of various items in the environment, in order to get from one point to
another. Hence, the eort of obtaining such detailed maps is not usually justied. In addition
the maps can be very large, which makes planning|even though planning is polynomial in the
size of the map|inecient.

2.3 Topological Maps and Models

An alternative to the detailed geometric maps are the more abstract topological maps. Such
maps specify the topology of important landmarks and situations (states), and routes or transitions (arcs) between them. They are concerned less with the physical location of landmarks,
and more with topological relationships between situations. Typically, they are less complex and
support much more ecient planning than metric maps. Topological maps are built on lowerlevel abstractions that allow the robot to move along arcs (perhaps by wall- or road-following),
to recognize properties of locations, and to distinguish signicant locations as states; they are
exible in allowing a more general notion of state, possibly including information about the
non-geometrical aspects of the robot's situation.
There are two typical strategies for deriving topological maps: one is to learn the topological
map directly; the other is to rst learn a geometric map, then to derive a topological model
from it through some process of analysis.
A nice example of the second approach is provided by Thrun and Bucken (1996a, 1996b; Thrun,
1999), who use occupancy-grid techniques to build the initial map. This strategy is appropriate
when the primary cues for decomposition and abstraction of the map are geometric. However,
in many cases, the nodes of a topological map are dened in terms of other sensory data (e.g.,
labels on a door or whether or not the robot is holding a bagel). Learning a geometric map rst
also relies on the odometric abilities of a robot; if they are weak and the space is large, it is very
dicult to derive a consistent map.

171

Shatkay & Kaelbling

In contrast, our work concentrates on learning a topological model directly, assuming that abstraction of the robot's perception and action abilities has already been done. Such abstractions
were manually encoded into the lower level of our robot navigational software, as described in
Section 6. Work by Pierce and Kuipers (1997) discusses an automatic method for extracting
abstract states and features from raw perceptual information.
Kuipers and Byun (1991) provide a strategy for learning deterministic topological maps. It works
well in domains in which most of the noise in the robot's perception and action is abstracted
away, learning from single visits to nodes and traversals of arcs. A strong underlying assumption
for these strategies, when building the map, is that the current state can be reliably identied
based on local information, or based on distance traversed from the previous well-identied
state. These methods are unable to handle situations in which long sequences of actions and
observations are necessary to disambiguate the robot's state.
Mataric (1990) provides an alternative approach for learning deterministic topological maps,
represented as distributed graphs. The learning process again relies on the assumption that the
current state can be distinguished from all other states based on local information which includes
compass and sonar readings. Uncertainty is not modeled through probability distributions.
Instead, matching of current readings to already existing states is not required to be exact, and
thresholds of tolerated error are set empirically. Another dierence from the work presented
here, is that while we learn the complete probabilistic topology of the environment, in Mataric's
work the overall topology of the graph is assumed in advance to be a linear list, and additional
edges are added during the learning process. No probability distribution is associated with the
edges, and a mechanism for choosing which edge to take is determined as part of the goal seeking
process, and is not part of the model itself.
Engelson and McDermott (1992) learn \diktiometric" maps (topological maps with metric relations between nodes) from experience. The uncertainty model they use is interval-based rather
than probabilistic, and the learned representation is deterministic. Ad hoc routines handle problems resulting from failures of the uncertainty representation.
We prefer to learn a combined model of the world and the robot's interaction with the world;
this allows robust planning that takes into account likelihood of error in sensing and action. The
work most closely related to ours is by Koenig and Simmons (1996b, 1996a), who learn pomdp
models (stochastic topological models) of a robot hallway environment. They also recognize
the diculty of learning a good model without initial information; they solve the problem by
using a human-provided topological map, together with further constraints on the structure
of the model. A modied version of the Baum-Welch algorithm learns the parameters of the
model. They also developed an incremental version of Baum-Welch that can be used on-line.
Their models contain very weak metric information, representing hallways as chains of one-meter
segments and allowing the learning algorithm to select the most probable chain length. This
method is eective, but results in large models with size proportional to the hallways' length,
and strongly depends on the quality of the human-provided initial model.

2.4 Learning Automata from Data

Informally speaking, an automaton consists of a set of states and a set of transitions that lead
from one state to another. In the context of this work, the automaton states correspond to the
states of the modeled environments, and the transitions, to the state changes due to actions
performed in the environment. Each transition of the automaton is tagged by a symbol from an
172

Learning Geometrically-Constrained HMMs

input alphabet, , corresponding to the action or the input to the system that caused the state
transition. Classical automata theory (e.g., Hopcroft & Ullman, 1979) distinguishes between
deterministic and non-deterministic automata. If, for each alphabet symbol , there is a single
edge tagged by it, going out of each state, the automaton is deterministic. Otherwise, the
transition between states is not uniquely determined by the input symbol and the automaton is
non-deterministic. If we augment each transition edge of a non-deterministic automaton with a
probability of taking it given a certain input, , the resulting automaton is called probabilistic.
The basic problem of learning nite deterministic automata from given data can be roughly
described as follows: Given a set of positive and a set of negative example strings, S and T
respectively, over alphabet , and a xed number of states k, construct a minimal deterministic
nite automaton with no more than k states that accepts S and does not accept T . This problem
has been shown to be np-complete (Gold, 1978). Despite the hardness, positive results have
been shown possible under various special settings. Angluin (1987) showed that if an oracle can
answer membership queries and provide counterexamples to conjectures about the automaton,
there is a polynomial time learning algorithm from positive and negative examples. Rivest
and Schapire (1987, 1989), provide several eective methods, that under various settings, learn
deterministic automata that are correct with high probability. While the above work deals with
learning from noise-free data, Basye, Dean and Kaelbling (1995) presented several algorithms
that, with high probability, learn input-output deterministic automata, when the data observed
by the learner is corrupted by various forms of noise.
In all these cases, the learned automaton is deterministic rather than probabilistic. The basic
learning problem in the probabilistic context is to nd an automaton that assigns the same
distribution as the true one to data sequences, using training data S , that was generated by
the true automaton. Another form of a learning problem is that of nding a probabilistic
automaton  that assigns the maximum likelihood to the training data S ; that is, an automaton
that maximizes Pr(S j).
Abe and Warmuth (1992) show that nding a probabilistic automaton with 2 states, even when
a small error with respect to the true model is allowed with some probability (the probably
approximately correct, or PAC, learning model), cannot be done in polynomial time with polynomial number of examples, unless np = rp. From their work arises the broadly accepted
conjecture, which has not yet been proven, that learning hidden Markov Models is hard even
in the pac sense. There are two ways to address this hardness: one is to restrict the class of
probabilistic models learned, while the other is to learn unrestricted hidden Markov models with
good practical results but with no pac guarantees on the quality of the result.
Work by Ron et al. (1994, 1995, 1998) pursues the rst approach, learning restricted classes of
automata, namely, acyclic probabilistic nite automata, and probabilistic nite sux automata.
Both classes are useful for various applications related to natural language processing, and can
be learned in polynomial time within the pac framework.
The second approach, which is the one predominantly taken in this work, is to learn a model that
is a member of the complete unrestricted class of hidden Markov models. Only weak guarantees
exist about the goodness of the model, but the learning procedure may be directed to obtain
practically good results. This approach is based on guessing an automaton (model), and using
an iterative procedure to make the automaton t better to the training data. One algorithm
commonly used for this purpose is the Baum-Welch algorithm (Baum, Petrie, Soules, & Weiss,
1970), which is presented in detail by Rabiner (1989). The iterative updates of the model are
173

Shatkay & Kaelbling

based on gathering sucient statistics from the data given the current automaton, and the
update procedure is guaranteed to converge to a model that locally maximizes the likelihood
function Pr(datajmodel). Since the maximum is local, the model might not be close enough
to the true automaton by which the data was generated, and a challenging problem is to nd
ways to force the algorithm into converging to higher-likelihood maxima, or at least to make
it converge faster, facilitating multiple guesses of initial models, thus raising the probability
of converging to higher-likelihood maxima. Such an approach is the one taken in the work
presented here.
We assume, throughout this paper, that the number of states in the model we are learning is
known. This is not a very strong assumption since there are methods for learning the number of
states. Regularization methods for deciding on the number of states and other model parameters,
are discussed, for instance, in Vapnik's book (1995). We do not address this issue here.
The rest of the work describes our approach to learning topological models. We use noisy
odometric information that is readily available in most robots. This geometrical information is
typically not used by topological mapping methods. We demonstrate how a topological model
and the algorithm used to learn it can be extended to directly incorporate this weak odometric
information. We further show that by doing so, we can avoid the use of human-provided a priori
models and still learn stochastic environment models eciently and eectively.

3 Models and Assumptions
This section describes the formal framework for our work. It starts by introducing the classic
hidden Markov model. The model is then extended to accommodate noisy odometric information
in its most nave form, ignoring information about the robot's heading and orientation, and later
adapted to accommodate heading information.
We concentrate here on describing models and algorithms for learning hmms, rather than
pomdps. This means that the robot has no decisions to make regarding its next action at
every state; only one action can be executed at each state. In our experiments, a human operator gave the action command associated with each state to the robot when gathering the data.
Note that the action is not necessarily the same one for every state, e.g., the robot is told to
always turn right in state 1 and move forward at state 2. However, at each state only one action can be taken. The extension to complete pomdps, which we have implemented, is through
learning an hmm for each of the possible actions; it is straightforward although notationally
more cumbersome, thus we limit the discussion here to hmms.

3.1 HMMs { The Basics
A hidden Markov model consists of states, transitions, observations and probabilistic behavior,
and is formally dened as a tuple  = hS; O; A; B; i, satisfying the following conditions:

 S = fs0 ; : : : ; sN ,1 g is a nite set of N states.
 O = fo0 ; : : : ; oM ,1g is a nite set of M possible observation values.
174

Learning Geometrically-Constrained HMMs

 A is a stochastic transition matrix, with Ai;j = Pr(qt+1 = sj jqt = si), where 0  i; j  N ,1.
NX
,1
qt is the state at time t. For every state si ,

j =0

Ai;j = 1.

Ai;j holds the transition probability from state si to state sj .
 B is a stochastic observation matrix, with Bj;k = Pr(vt = ok jqt = sj ), where 0  j  N , 1;
MX
,1
0  k  M , 1. vt is the observation recorded at time t. For every state sj ,
Bj;k = 1.
Bj;k holds the probability of observing ok while being at state sj .

k=0

  is a stochastic initial distribution vector, with i = Pr(q0 = si), 0  i  N , 1.

NX
,1
i=0

i = 1.

i holds the probability of being in state si at time 0, when starting to record observations.
This model corresponds to a world whose actual state at any given time t, qt 2 S , is hidden
and not directly observable, but some observable aspects of the state, vt 2 O, are detected and
recorded when the state is visited at time t. An agent moves from one hidden state to the
next according to the probability distribution encoded in matrix A. The observed information
in each state is governed by the probability matrix B . Although our work is concerned with
discrete observations, the extension to continuous observations is straightforward and has been
well addressed in work on hidden Markov models (Liporace, 1982; Juang, 1985).
Simply stated, the problem of learning an hmm is that of \reverse engineering" a hidden Markov
model for a stochastic system from the sampled data, generated by the system. We formalize
the learning task in Section 4.1. The next section extends hmms to account for geometric
information.

3.2 Adding Odometry to Hidden Markov Models

The world is composed of a nite set of states. There is a fundamental distinction in our
framework between the term state and the term location. The state of the robot does not
directly correspond to its location. A state may include other information, such as the robot's
battery level or its orientation in that location. A robot standing in the entrance to oce 101
facing right is in a dierent state than a robot standing in the same place facing left; similarly,
a robot standing with a bagel in its arm is in a dierent state from the same robot being in the
same position without the bagel.
The dynamics of the world are described by state-transition distributions that specify the probability of making transitions from one state to the next as a result of a certain action. There
is a nite set of observations that can be perceived in each state; the relative frequency of each
observation is described by a probability distribution and depends only on the current state.
In our model, observations are multi-dimensional; an observation is a vector of values, each
chosen from a nite domain. That is, we factorize the observation associated with each state
into several components. For instance, as demonstrated in Section 6.1, we view the observation
recorded by the robot when standing in an oce environment as consisting of three components,
corresponding to the three cardinal directions: front, left and right. In this example, the observation vector is thus 3-dimensional. It is assumed that the vector's components are conditionally
independent, given the state.
175

Shatkay & Kaelbling

In addition to the above components, each state is assumed to be associated with a position in a
metric space. Whenever a state transition is made, the robot records an odometry vector, which
estimates the position of the current state relative to the previous one. For the time being we assume that the odometry vector consists of readings along the x and y coordinates of a global coordinate system, and that these readings are corrupted with independent normal noise. The latter
independence assumption is not a strict one, and can be relaxed by introducing a complete covariance matrix, although we have not done this in this work. In Section 3.3 we extend the odometry vector to include information about the heading of the robot, and drop the global coordinate
framework.
Note that the odometric relationship characterizes a transition rather than a state and, as
described below, receives a dierent treatment than the observations that are associated with
states.
There are two important assumptions underlying our treatment of odometric relations between
states: First, that there is an inherent \true" odometric relation between the position of every
two states in the world; second, that when the robot moves from one state to the next, there
is a normal, 0-mean noise around the correct expected odometric reading along each odometric
dimension. This noise reects two kinds of odometric error sources:

{ The lack of precision in the discretization of the real world into states (e.g. there is a rather

large area in which the robot can stand which can be regarded as \the doorway of the AI
lab").
{ The lack of precision of the odometric measures recorded by the robot, due to slippage,
friction, disalignment of the wheels, imprecision of the measuring instruments, etc.

To formally introduce odometric information into the hidden Markov model framework, we
dene an augmented hidden Markov model as a tuple  = hS; O; A; B; R; i, where:

 S = fs0 ; : : : ; sN ,1 g is a nite set of N states.
 O = Qli=1 Oi is a nite set of observation vectors of length l. The ith element of an

observation vector is chosen from the nite set Oi .
 A is a stochastic transition matrix, with Ai;j = Pr(qt+1 = sj jqt = si), 0  i; j  N , 1.
NX
,1
qt is the state at time t. For every state si , Ai;j = 1.
j =0

Ai;j holds the transition probability from state si to state sj .
 B is an array of l stochastic observation matrices, with Bi;j;k = Pr(Vt [i] = ok jqt = sj );
1  i  l; 0  j  N , 1; ok 2 Oi ; Vt is the observation vector at time t; Vt [i] is its ith

component.
Bi;j;k holds the probability of observing ok along the ith component of the observation
vector, while being at state sj .
 R is a relation matrix, specifying for each pair of states, si and sj , the mean and variance
of the D-dimensional2 odometric relation between them. (Ri;j [m]) is the mean of the mth

2. For the time being we consider D to be 2, corresponding to (x; y) readings.

176

Learning Geometrically-Constrained HMMs

component of the relation between si and sj and 2 (Ri;j [m]), the variance. Furthermore,
R is geometrically consistent: for each component m, the relation m (a; b) = (Ra;b [m])
must be a directed metric, satisfying the following properties for all states a, b, and c:
def

 m(a; a) = 0;
 m(a; b) = ,m(b; a) (anti-symmetry); and
 m(a; c) = m (a; b) + m(b; c) (additivity ) :
This representation of odometric relations reects the two assumptions, previously stated,
regarding the nature of the odometric information. The \true" odometric relation between
the position of every two states is represented as the mean. The noise around the correct
expected odometric relation, accounting for both the lack of precision in the real-world
discretization and the inaccuracy in measurement, is represented through the variance.

  is a stochastic initial probability vector describing the distribution of the initial state.
For simplicity it is assumed here to be of the form h0; : : : ; 0; 1; 0; : : : ; 0i, implying that there
is one designated initial state, si , in which the robot is always started.

This model extends the standard hidden Markov model described in Section 3.1 in two ways:
 It facilitates observations that are factored into components, and represented as vectors.
These components are assumed to be conditionally independent of each other given the
state. Such factorization, together with the conditional independence assumption, allows
for a simple calculation of the probability of the complete observation vector from the
probabilities of its components. It therefore results in fewer probabilistic parameters in
the learnt model than if we were to view each observation vector, consisting of a possible
combination of component-values as a single \atomic" observation.

 It introduces the odometric relation matrix R and constraints over its components. Using
R and the constraints over it, as explained in Section 4, has proven useful for learning the
other model parameters, as demonstrated in Section 6.

3.3 Handling Directional Data

We further extend the model to accommodate directional changes in addition to the positional
changes. There are two issues stemming from directional changes while moving in an environment: the need for non-traditional distributions to model directional changes, and the need
to correct for the cumulative rotational error which severely interferes with location estimation
within a global coordinate framework. A detailed discussion of these two problems and their
solution is given in an earlier paper by the authors (Shatkay & Kaelbling, 1998). For the sake
of completeness, we briey review these two issues here.
3.3.1 Circular Distributions

The robot's change in direction as it moves through the environment is expressed in terms of the
angular change with respect to its original heading. Since angular measures are inherently circular, treating them as \normally distributed", and using the standard procedures for obtaining
sucient statistics from the data is not adequate. As a trivial example, if we were to average
177

Shatkay & Kaelbling
y

1

<x 1, y1>
<x 2, y2>
<x 3, y3>
θ1

173 0
−179

0

-1

−3

θ2

θ3
1

x

-1

Figure 1: Simple average of two angles, depicted

as vectors to the unit circle. The average angle is
formed by the dashed vector.

Figure 2: Directional data represented as angles
and as vectors on the unit circle.

the two angular readings, 173 and ,179 , using simple average we obtain the angle ,3 , which
is far from the intuitive  180 , as illustrated in Figure 1.
To address the circularity issue, we use the von Mises distribution, which is a circular version of
the normal distribution, to model the change in heading between two states, as explained below.
A collection of changes in heading within a two dimensional space can be represented in terms
of either Cartesian or polar coordinates. Using a Cartesian system, n changes in headings can
be recorded as a sequence of 2-dimensional vectors, (hx1 ; y1 i; : : : hxn ; yn i), on the unit circle,
as shown in Figure 2. The same changes can also be represented as the corresponding angles
between the radii from the center of the unit circle and the X axis, (1 ; : : : ; n ), respectively.
The relationship between the two representations is:
xi = cos(i ); yi = sin(i ) ; (1  i  n) :
The vector mean of the n points, hx; yi, is calculated as:
Pn cos( )
Pn sin( )
i
i :
i
=1
i=1
x=
y
=
;
n
n

(1)

Using polar coordinates, we can express the mean vector in terms of angle, , and length, a,
where (except for the case x = y = 0):

 = arctan( xy );

a = (x2 + y 2 ) :
1
2

The angle  is the mean angle, while the length a is a measure (between 0 and 1) of how
concentrated the sample angles are around . The closer a is to 1, the more concentrated the
sample is around the mean, which corresponds to a smaller sample variance.
Intuitively, a satisfactory circular version of the normal distribution would have a mean for
which the maximum likelihood estimate is the average angle as calculated above. In a way
analogous to Gauss' derivation of the Normal distribution, von Mises developed such a circular
version (Gumbel, Greenwood, & Durand, 1953; Mardia, 1972), which is dened as follows:
Denition: A circular random variable, , 0    2, is said to have the von Mises
distribution with parameters  and , where 0    2 and  > 0, if its probability density
178

Learning Geometrically-Constrained HMMs

function is:

f;() = 2I1 () e cos(,) ;
0

where I0 () is the modied Bessel function of the rst kind and order 0:

I0 () =

1 1 1
X
2r
2 ( 2 ) :
r
!
r=0

(2)

The parameters  and  correspond to the distribution's mean and concentration respectively.
While other circular-normal distributions do exist, the von Mises has the desirable estimation
procedure alluded to earlier: Given a set of heading samples, angles 1 ; : : : n , from a von Mises
distribution, the maximum likelihood estimate  for  is:

 = arctan( xy ) ;

where y, x are as dened in Equation 1.
The maximum likelihood estimate for the concentration parameter, , is the  that satises:
n
I1 () = max[ 1 X
I0 ()
n i=1 cos(i , ); 0] ;

where I1 is the modied Bessel function of the rst kind and order 1:

I1 () =

1
X

1 ( 1 )2r+1 :
r=0 r!(r + 1)! 2

(3)

Further information about the estimation procedure is beyond the scope of this paper and can
be found elsewhere (Gumbel et al., 1953; Mardia, 1972).
To conclude, we assume that the change in heading  is von Mises-distributed, around a mean
 with concentration parameter . This assumption is reected in the model learning procedures
as explained later in Section 4.2.3. The change in heading h (a; b);  (a; b)i between each pair
of states (a; b) completes the set of parameters included in the relation matrix R which was
introduced earlier in Section 3.2.
3.3.2 Cumulative Rotational Error

We tend to think about an environment as consisting of landmarks xed in a global coordinate
system and corridors or transitions connecting these landmarks. This idea underlies the typical
maps constructed and used in everyday life. However, this view of the environment may be
problematic when robots are involved.
Conceptually, a robot has two levels at which it operates; the abstract level, in which it centers
itself through corridors, follows walls and avoids obstacles, and the physical level in which motors
turn the wheels as the robot moves. In the physical level many inaccuracies can manifest
themselves: wheels can be unaligned with each other resulting in a drift to the right or to the
left, one motor can be slightly faster than another resulting in similar drifts, an obstacle under
one of the wheels can cause the robot to rotate around itself slightly, or uneven oors may cause
179

Shatkay & Kaelbling

−ε ε

- actual position
- recorded position

Figure 3: A robot moving along the solid arrow, while correcting for drift in the direction of the dashed
arrow. The dotted arrow marks its recorded change in position.

the robot to slip in a certain direction. In addition, the measuring instrumentation for odometric
information may not be accurate in and of itself. At the abstract level, corrective actions are
constantly executed to overcome the physical drift and drag. For example, if the left wheel is
misaligned and drags the robot leftwards, a corrective action of moving to the right is constantly
taken in the higher level to keep the robot centered in the corridor.
The phenomena described above have a signicant eect on the odometry recorded by the robot,
if such data interpreted with respect to one global framework. For example, consider the robot
depicted in Figure 3. It drifts to the left , when moving from one state to the next, and
corrects for it by moving  to the right in order to maintain itself centered in the corridor.
Let us assume that states are 5 meters apart along the center of the corridor, and that the center
of the corridor is aligned with the Y axis of the global coordinate system. The robot steps back
and forth in the corridor from one state to the next. Whenever the robot reaches a state, its
odometry reading changes by hx; y; i along the hX; Y; headingi dimensions, respectively. As the
robot proceeds, the deviation with respect to the X axis becomes more and more severe. Thus,
after going through several transitions, the odometric changes recorded between every pair of
states, if taken with respect to a global coordinate system, become larger and larger. Similar
problems of inconsistent odometric changes recorded between pairs of states can arise along any
of the odometric dimensions. It is especially severe when such inconsistencies arise with respect
to the heading, since this can lead to mistakenly switching movement along the X and the Y
axes, as well as confusion between forwards and backwards movement (when the deviation in
the heading is around 90 or 180 respectively).
In early work (Shatkay & Kaelbling, 1997) we assumed perpendicularity of the corridors, which
was taken advantage of while the robot collected the data. Odometric readings were recorded
with respect to a global coordinate system, and the robot could re-align itself with the origin after
each turn. A trajectory of odometry recorded under this perpendicularity assumption by our
robot Ramona, along the x and y axes is given in Figure 4. The sequence shown was recorded
while the robot drove repeatedly around a loop of corridors. Further details about the data
gathering process are provided in Section 6. In contrast, Figure 5 shows a trajectory of another
sequence of odometric readings recorded by Ramona, driving through the same corridors, without
using the perpendicularity assumption. The data collected under the latter setting is subjected
to cumulative rotational error.
180

Learning Geometrically-Constrained HMMs
3000
1200

2500
1000

2000
800

1500

600

1000

400

200

500
200

400

600

800

1000

-2500 -2000 -1500 -1000 -500

Figure 4: Sequence gathered by Ramona, perpendicularity assumed.

500

1000

Figure 5: Sequence gathered by Ramona, no per-

pendicularity assumed.

Such data can be handled through state-relative coordinate systems (Shatkay & Kaelbling, 1998).
The latter implies that each state si has its own coordinate system, as shown in Figure 6: the
origin is anchored in si , the Y axis is aligned with the robot's heading in the state (denoted by
bold arrows in the gure), and the X axis is perpendicular to it. This is in contrast to a global
coordinate system which is anchored in the initial starting state. Within the global coordinate
system, the relations recorded may vary greatly among multiple instances of the same transition
between the same pair of states. By using the state-relative system, the recorded and learned
relationship between each pair of states, hsi ; sj i, is reliable, despite the fact that it is based on
multiple transitions recorded from si to sj .
Under state-relative coordinate systems, the geometric relation stored in Rij , (which was introduced in Section 3.2), is expressed for each pair of states, si and sj , with respect to the
coordinate system associated with state si. Accordingly, the constraints imposed over the x and
y components of the relation matrix must be specied with respect to the explicit coordinate
system used, as explained below.
Given a pair of states a and b, we denote by hx;yi (a; b) the vector h(Ra;b [x]); (Ra;b [y])i. Let
us dene Tab to be the transformation that maps an hxa ; ya i point represented with respect to
the coordinate system of state a, to the same point represented with respect to the coordinate
system of state b, hxb ; yb i.
More explicitly, let ab be the mean change in heading from state a to state b. Applying Tab to
a vector h xyaa i results in the vector h xybb i as follows:

* +

* + *

xb
x
x cos(ab ) , ya sin(ab )
= Tab a = a
yb
ya
xa sin(ab ) + ya cos(ab )

+

:

The consistency constraints within this framework must be restated as:

 hx;yi(a; a) = h0; 0i;
 hx;yi(a; b) = ,Tba[hx;yi(b; a)] (anti-symmetry);
 hx;yi(a; c) = hx;yi (a; b) + Tba[hx;yi (b; c)] (additivity).
181

Shatkay & Kaelbling
y

∆x
Sj
Si

∆θ

∆y

x

Figure 6: A robot in state Si , faces in the Y -axis direction; the relation Si ,Sj is wrt Si 's coordinate
system.

These consistency constraints are the ones that need to be enforced by our learning algorithm
which constructs the hmm. It is important to note that the transformation T itself does not
constitute a set of additional parameters that need to be learnt. Rather, it is calculated in terms
of the heading-change parameter,  , which is already an integral part of the relation matrix we
have dened in Sections 3.2 and 3.3.1.
We have introduced the basic formal model that we use for representing environments and
the robot's interaction with them. In the following section we state the learning problem and
describe the basic algorithm for learning the model from data.

4 Learning HMMs with Odometric Information

This section formalizes the learning problem for hmms, and discusses how odometric information
is incorporated into the learning algorithm. An overview of the complete algorithm is provided
in the Appendix for this paper.

4.1 The Learning Problem

The learning problem for hidden Markov models can be generally stated as follows: Given an
experience sequence E, nd a hidden Markov model that could have generated this sequence and
is \useful" or \close to the original" according to some criterion. An explicit common statistical
approach is to look for a model  that maximizes the likelihood of the data sequence E given
the model. Formally stated, it maximizes Pr(Ej). However, given the complicated landscape
of typical likelihood functions in a multi-parameter domain, obtaining a maximum likelihood
model is not feasible. All studied practical methods, and in particular the well-known BaumWelch algorithm (Rabiner (1989) and references therein) can only guarantee a local-maximum
likelihood model.
Another way of evaluating the quality of a learned model is by comparing it to the true model.
We note that stochastic models (such as hmms) induce a probability distribution over all observation sequences of a given length. The Kullback-Leibler (Kullback & Leibler, 1951) divergence
of a learned distribution from a true one is a commonly used measure for estimating how good a
182

Learning Geometrically-Constrained HMMs

learned model is. Obtaining a model that minimizes this measure is a possible learning goal. The
culprit here is that in practice, when we learn a model from data, we do not have any \ground
truth" model to compare the learned model with. Still, we can evaluate learning algorithms by
measuring how well they perform on data obtained from known models. It is reasonable to expect that an algorithm that learns well from data that is generated from a model we do have, will
perform well on data generated from an unknown model, assuming that the models indeed form
a suitable representation of the true generating process. We discuss the Kullback-Leibler (kl)
divergence in more detail in Section 6.2 in the context of evaluating our experimental results.
To summarize, the learning problem as we address it in this work is that of obtaining a model
by attempting to (locally) maximize the likelihood, while evaluating the results based on the
kl-divergence with respect to the true underlying distribution, when such a distribution is
available.

4.2 The Learning Algorithm

The learning algorithm starts from an initial model 0 and is given an experience sequence E;
it returns a revised model , which (locally) maximizes the likelihood P (Ej). The experience
sequence E is of length T ; each element, Et , for 0  t  (T , 1), is a pair hrt ; Vt i, where rt is the
observed relation vector along the x, y and  dimensions, between the states qt,1 and qt , and Vt
is the observation vector at time t.
Our algorithm extends the standard Baum-Welch algorithm to deal with the relational information and the factored observation sets. The Baum-Welch algorithm is an expectationmaximization (em) algorithm (Dempster, Laird, & Rubin, 1977); it alternates between
 the E-step of computing the state-occupation and state-transition probabilities,  and ,
at each time in the sequence given E and the current model , and
 the M-step of nding a new model, , that maximizes P (Ej; ; ),
providing monotone convergence of the likelihood function P (Ej) to a local maximum.
However, our extension introduces an additional component, namely, the relation matrix R. It
can be viewed as having two kinds of observations: state observations (as the ordinary hmm |
with the distinction that we observe integer vectors rather than integers) and transition observations (the odometry relations between states). The latter must satisfy geometrical constraints.
Hence, an extension of the standard update formulae, as described below, is required.
4.2.1 State-Occupation Probabilities

Following Rabiner (1989), we rst compute the forward () and backward ( ) matrices. t (i)
denotes the probability density value of observing E0 through Et and qt = si , given ; t (i) is
the probability density of observing Et+1 through ET ,1 given qt = si and . Formally:
t (i) = Pr(E0 ; : : : ; Et ; qt = sij) ;
t (i) = Pr(Et+1 ; : : : ; ET ,1 jqt = si ; ) :
When some of the measurements are continuous (as is the case with R), these matrices contain
probability density values rather than probabilities.
The forward procedure for calculating the  matrix is initialized with
( i
b if i = 1
0 (i) = 00 otherwise
;
183

Shatkay & Kaelbling

and continued for 0 < t  T , 1 with
t (j ) =

NX
,1
i=0

t,1 (i)Ai;j f (rt jRi;j )bjt :

(4)

The expression f (rt jRi;j ) denotes the density at point rt according to the distribution represented
by the means and variances in entry i; j of Q
the relation matrix R, while bjt is the probability of
j
observing vector vt in state sj ; that is, bt = li=0 Bi;j;vt[i] .
The backward procedure for calculating the  matrix is initialized with T ,1 (j )=1, and continued
for 0  t<T , 1 with
NX
,1
t (i) = t+1 (j )Ai;j f (rt+1 jRi;j )bjt+1 :
(5)
j =0

Given  and  , we now compute for each given time point t the state-occupation and statetransition probabilities,  and  . The state-occupation probabilities, t (i), representing the
probability of being in state si at time t given the experience sequence and the current model,
are computed as follows:
:
(6)
t (i) = Pr(qt = si jE; ) = PN,t1(i)t (i)
j =0 t (j )t (j )
Similarly, t (i; j ), the state-transition probabilities from state i to state j at time t given the
experience sequence and the current model, are computed as:
t (i; j ) = Pr(qt = si ; qt+1 = sj jE; )
t (i)Ai;j bjt+1 f (rt+1 jRi;j )t+1 (j )
:
(7)
=
NX
,1 NX
,1
i=0 j =0

t (i)Ai;j bjt+1 f (rt+1 jRi;j )t+1 (j )

These are essentially the same formulae appearing in Rabiner's tutorial (Rabiner, 1989), but
they also take into account the density of the odometric relations.
In the next phase of the algorithm, the goal is to nd a new model, , that maximizes the likelihood conditioned on the current transition and observation probabilities, Pr(Ej; ;  ). Usually,
this is simply done using maximum-likelihood estimation of the probability distributions in A
and B by computing expected transition and observation frequencies. In our model we must also
compute a new relation matrix, R, under the constraint that it remain geometrically consistent.
Through the rest of this section we use the notation v to denote a reestimated value, where v
denotes the current value.
4.2.2 Updating Transition and Observation Parameters

The A and B matrices can be straightforwardly reestimated. Ai;j is the expected number of
transitions from si to sj divided by the expected number of transitions from si , and B i;j;k is the
expected number of times ok is observed along the ith dimension when in state sj , divided by
the expected number of times of being in sj :
PT ,1 
PT ,2  (i; j )
t
t
=0
; B i;j;k = t=0PT[V,t1[i]=ok ] t (j ) :
(8)
Ai;j = PT ,2
t=0 t (i)
t=0 t (i)
The expression c denotes an indicator function with value 1 if condition c is true and 0 otherwise.
184

Learning Geometrically-Constrained HMMs
7.5
P

Q

5

P

2.5

-8

-6

-4

-2

2

4

6

8

-2.5
-5

-6

-4

-2

2

4

6
-7.5

Q

Figure 7: Examples of two sets of normally distributed points with constrained means, in 1 and in 2
dimensions.

4.2.3 Updating Relation Parameters

When reestimating the relation matrix, R, the geometrical constraints induce interdependencies
among the optimal mean estimates as well as between optimal variance estimates and mean
estimates. Parameter estimation under this form of constraints is almost untreated in mainstream statistics (Bartels, 1984) and we found no previous existing solutions to the estimation
problem addressed here. As an illustration for the issues involved in estimation under constraints
consider the following estimation problem of 2 normal means:
Example 4.1 The data consists of two sample sets of points P = fp1; p2 ; : : : ; pn g and Q =
fq1; q2 ; : : : ; qk g, independently drawn from two distinct normal distributions with means P ; Q
and variances P2 ; Q2 , respectively. We are asked to nd maximum likelihood estimates for the
two distribution parameters. Moreover, we are told that the means of the two distributions are
related, such that Q = ,P , as illustrated in Figure 7. If not for the latter constraint, the task
is simple (DeGroot, 1986), and we have:
Pn p
Pn
i ;  2 = i=1 (pi , P )2 ;
P = i=1
P
n
n

and similarly for Q and Q2 . However, the constraint P = ,Q requires nding a single mean, ,
and setting the other one to its negated value, ,. Intuitively, when choosing such a maximum
likelihood single mean, the more concentrated sample should have more eect, while the more
varied sample should be more \submissive." Thus, the overall sample deviation from the means
would be minimized and the likelihood of the data maximized. Therefore, there is a mutual
dependence between the estimation of the mean and the estimation of the variance.
Since the samples are independently drawn, their joint likelihood function is:
,(pi ,P )2

n
P
Y
f (P; QjP ; Q; P2 ; Q2 ) = e p
i=1 2P
2 2



Yk e
j =1

,(qj ,Q )2
Q

p

2 2

2Q

:

By taking the derivatives of this joint log-likelihood function, with respect to P , P and Q, and
equating them to 0, while using the constraint Q = ,P , we obtain the following set of mutual
equations for maximum likelihood estimators:
P
P
(Q2 ni=1 pi) , (P2 kj=1 qj )
P =
; Q = ,P ;
nQ2 + kP2
Pk (q +  )2
Pn (p ,  )2
i
P
i
=1
2
2
P =
; Q = j =1 j P :

n

k

185

Shatkay & Kaelbling

By substituting the expressions for P and Q into the expression for P , we obtain a cubic equation which is cumbersome, but still solvable (in this simple case). The solution provides a maximum likelihood estimate for the mean and variance under the constraint Q = ,P :
2
We now proceed to the actual update of the relation matrix under constraints. For clarity, we
initially discuss only the rst two geometrical constraints, and discuss the additivity constraint in
Section 4.3. Recall that we concentrate here on the enforcement of global constraints, appropriate
under the perpendicularity assumption, although the same idea is applied in the case of staterelative constraints.
Zero distances between states and themselves are trivially enforced, by setting all the diagonal
entries in the R matrix to 0, with a small variance.
Anti-symmetry within a global coordinate system is enforced by using the data recorded along
the transition from state sj to si as well as from state si to sj when reestimating (Ri;j ). As
demonstrated in Example 4.1, the variance has to be taken into account, leading to the following
set of mutual equations:



mi;j

=

( mi;j )2 =

PT ,2

rt[m]t (i;j ) , rt [m]t(j;i)
( m
( m
i;j )2
j;i )2

PT ,2 t(mi;j) + t(mj;i) 
t=0 (i;j )2 (j;i )2
PT ,2[ (i; j )(r [m] , m )2 ]
t=0 t
PT ,2 t(i; j ) i;j :
t=0 t
t=0

;

(9)
(10)

For the x and y dimensions, (m = x; y), this amounts to a complicated but still solvable cubic
equation. However, in the more general case, when accounting for the orientation of the robot,
and also when complete additivity is enforced, we do not obtain such closed form reestimation
formulae.
To avoid these hardships, we use a lag-behind update rule; the yet-unupdated estimate of the
variance is used for calculating a new estimate for the mean, and this new mean estimate is
used to update the variance, using Equation 10.3 Thus, the mean is updated using a variance
parameter that lags behind it in the update process, and the reestimation Equation (9) needs to
use m rather than m as follows: PT ,2 h rt [m]t (i;j) rt [m]t (j;i) i
m 2 , j;i
m )2
t=0
i :
(11)
mi;j = PT ,2(hi;jt ()i;j) t ((j;i
)
t=0

m )2 + (j;i
m )2
i;j

(

As we have shown (Shatkay, 1999), this lag-behind policy is an instance of generalized em (McLachlan & Krishnan, 1997). The latter guarantees monotone convergence to a local maximum of the
likelihood function, even when each \maximization" step increases rather than strictly maximizes the expected likelihood of the data given the current model.
Similarly, the reestimation formula for the von Mises mean () and concentration () parameters
of the heading change between states si and sj is the solution to the equations:

0 TX
1
,
BB [sin(rt [])(t (i; j )i;j , t(j; i)j;i)] CC
t
CC
= arctan B
B@ TX
,
A
[cos(rt [])(t (i; j )i;j + t (j; i)j;i )]
2

i;j

=0

2

t=0

3. A similar approach, termed one step late update, is taken by others applying em to highly non-linear optimization problems (McLachlan & Krishnan, 1997).

186

Learning Geometrically-Constrained HMMs

I1 [i;j ]
= max
I0 [i;j ]

" PT ,

#
2
(i; j ) cos(rt [] , i;j )]
t=0 [tP
; 0
T ,2  (i; j )
t=0 t

;

(12)

where I0 and I1 are the modied Bessel functions as dened by Equations 2 and 3 in Section 3.3.1.
Again, to avoid the need to solve the mutual equations, we take advantage of the lag-behind strategy, updating the mean using the current estimates of the concentration parameters, i;j ; j;i,
as follows:
PT ,2[sin(r [])( (i; j ) ,  (j; i) )] !
t
t
i;j t
j;i
i;j = arctan PTt=0
(13)
,2 [cos(r [])( (i; j ) +  (j; i) )] ;
t
t
i;j t
j;i
t=0
and then calculating the new concentration parameters based on the newly updated mean, as
the solution to Equation 12, through the use of lookup-tables.
A possible alternative to our lag-behind approach is to update the mean as though the assumption j;i = i;j holds. Under this assumption, the variance terms in Equation 9 cancel out, and
the mean update is independent of the variance once again. Then the variances are updated as
stated in Equation 10, without assuming any constraints over them. This approach was taken
in earlier stages of this work (Shatkay & Kaelbling, 1997, 1998). The lag-behind strategy is
superior, both according to our experiments, and due to its being an instance of generalized em.

4.3 Enforcing Additivity

Note that the additivity constraint directly implies the other two geometrical constraints4 . Thus,
enforcing it results in complete geometrical consistency. We present here the method for directly
enforcing additivity through the reestimation procedure along the x and y dimensions. For the
heading dimension we describe how complete geometrical consistency is achieved through the
projection of anti-symmetric estimates onto a geometrically-consistent space. As before, to
simplify the presentation, we focus on the case of global coordinate systems. The same basic
idea applies to state-relative coordinate systems, but the relationship used to recover the mean
ij from individual state coordinates is more complex.
4.3.1 Additivity in the x, y dimensions

The main observation underlying our approach is that the additivity constraint is a result of the
fact that states can be embedded in a geometrical space. That is, assuming we have N states,
s0; : : : ; sN ,1, there are points on the X , Y and  axes, x0 ; : : : ; xN ,1 , y0 ; : : : ; yN ,1 , 0 ; : : : ; N ,1,
respectively, such that each state, si , is associated with the coordinates hxi ; yi ; i i. Assuming
one global coordinate system, the mean odometric relation from state si to state sj can be
expressed as: hxj , xi ; yj , yi ; j , i i.
During the maximization phase of the em iteration, rather than try to maximize with respect
to N 2 odometric relation vectors, hXij , Yij , ij i, we reparameterize the problem. Specically,
we express each odometric relation as a function of two of the N state positions, and maximize
with respect to the unconstrained, N state positions. For instance, for the X dimension, rather
than search for N 2 maximum likelihood estimates for xij , we use the maximization step to nd
N 1-dimensional points, x0 ; : : : ; xN ,1 . We can then calculate xij = xj , xi . Moreover, since
all we are interested in is nding the best relationships between xi and xj , we can x one of
4. f(a; a)= (a; a) + (a; a)g ) ((a; a)=0) ; f((a; a)=0) ; ((a; a)= (a; b)+(b; a))g ) ((a; b) = ,(b; a)).

187

Shatkay & Kaelbling

the xi 's at 0 (e.g. x0 = 0), and nd optimal estimates for the remaining N , 1 state positions.
The variance reestimation remains as before, and the lag-behind policy is used to eliminate the
interdependency between the update of the mean and the variance parameters.
4.3.2 Additive Heading Estimation

Unfortunately, the reparameterization described above is not feasible for estimation of changes
in heading, due to the von Mises distribution assumption over the heading measures. By reparameterizing ij as j , i and trying to maximize the likelihood function with respect to the 
parameters, we obtain a set of N,1 trigonometric equations with terms of the form cos(j ) sin(i )
which do not enable simple solution.
As an alternative, it is possible to use the anti-symmetric reestimation procedure described
earlier, followed by a perpendicular projection operator, mapping the resulting headings vector
h00 ; : : : ; ij ; : : : ; N ,1;N ,1i, 0  i; j  N ,1, which does not satisfy additivity, onto a vector of
headings within an additive linear vector space. Simple orthogonal projection is not satisfactory
within our setting, since it simply looks for the additive vector closest to the non-additive one.
This procedure ignores the fact that some of the entries in the non-additive vector are based on
a lot of observations, and are therefore more reliable, while other, less reliable ones, are based on
hardly any data at all. Intuitively, we would like to keep the estimates that are well accounted
for intact, and adapt the less reliable estimates to meet the additivity constraint. More precisely,
there are heading-change estimates between states that are better accounted for than others, in
the sense that the transitions between
these states have higher expected counts than transition
P
between other states (higher t t (i; j )). We would like to project the non-additive heading
estimates vector onto a subspace of the additive vector space, in which the vectors have the same
values as the non-additive
P vector in the entries that are well-accounted for, that is, those with
the highest values of t t (i; j ). The diculty is that the latter subspace is not a linear vector
space (for instance, it does not satisfy closure under scalar multiplication), and the projection
operator over linear spaces cannot be applied directly. Still, this set of vectors does form an
ane vector space, and we can project onto it using an algebraic technique, as explained below.5
Denition
A Rn is an n-dimensional ane space if for all vectors va2A, the set of vectors:
def
A , va = fua , va jua 2 Ag is a linear space.
Hence, we can pick a vector in an ane space, va 2A, and dene the translation Ta : A ! V ,
where V is a linear space, V = A , va . This translation is trivially extended for any vector
v0 2 Rn , by dening Ta (v0 ) = v0 , va . In order to project any vector v 2 Rn onto A, we apply
the translation Ta to v and project Ta (v) onto V , which results in a vector P (Ta (v)) in V . By
applying the inverse transform Ta,1 to it, we obtain the projection of v on A, as demonstrated
in Figure 8. The linear space in the gure is the two dimensional vector space fhx; yij y = ,xg,
and the ane space is fhx; yij y = ,x + 4g. The transform Ta consists of subtracting the vector
h0; 4i. The solid arrow corresponds to the direct projection of the vector v onto the point P (v)
of the ane space. The dotted arrows represent the projection via translation of v to Ta (v), the
projection of the latter onto the linear vector space, and the inverse translation of the result,
P (Ta (v)), onto the ane space.
1

1

1

5. Many thanks to John Hughes for introducing us to this technique.

188

Learning Geometrically-Constrained HMMs

6
<x,-x+4>
4
P(v)

v

2

-2

2

-2

4
Ta (v)
P(Ta (v))

<x,-x>

-4

Figure 8: Projecting v onto the ane vector space fhx; yij y = ,x + 4g.
Although the procedure for preserving additivity over headings is not formally proven to preserve monotone convergence of the likelihood function towards a local maximum, our extensive
experiments consisting of hundreds of runs have shown that monotone convergence is preserved.

5 Choosing an Initial Model

Typically, in instances of the Baum-Welch algorithm, an initial model is picked uniformly at
random from the space of all possible models, perhaps trying multiple initial models to nd different local likelihood maxima. An alternative approach we have reported (Shatkay & Kaelbling,
1997) was based on clustering the accumulated odometric information using the simple k-means
algorithm (Duda & Hart, 1973), taking the clusters to be the states in which the observations
were recorded, to obtain state and observation counts and estimate the model parameters.
If perpendicularity is assumed when collecting the data, as shown in Figure 4, the k-means
algorithm assigns the same cluster (state) to odometric readings recorded at close locations,
leading to reasonable initial models. However, when this assumption is dropped, as illustrated
in Figure 5, the cumulative rotational error distorts the odometric location recorded within a
global coordinate system, so that the location assigned to the same state during multiple visits
varies greatly and would not be recognized as \the same" by a simple location-based clustering
algorithm. To overcome this, we developed an alternative initialization heuristics, which we call
tag-based initialization. It is based directly on the recorded relations between states, rather than
on states' absolute location. For clarity, the description here consists mostly of an illustrative
example, and concentrates on the case where global consistency constraints are enforced.
Given a sequence of observations and odometric readings E, we begin by clustering the odometric
readings into buckets. The number of buckets is at most the number of distinct state transitions
recorded in the sequence. The goal at this stage is to have each bucket contain all the odometric
readings that are close to each other along all three dimensions.
To achieve this, we start by xing a predetermined, small standard deviation value along the x,
y, and  dimensions. Denote these standard deviation values x ; y ;  respectively, (typically
x = y ). The rst odometric reading is assigned to bucket 0 and the mean of this bucket is
set to be the value of this reading. Through the rest of the process the subsequent odometric
readings are examined. If the next reading is within 1:5 standard deviations along each of the
three dimensions from the mean of some existing non-empty bucket, add it to the bucket and
189

Shatkay & Kaelbling

< 2, 94, 92 >
< -4, 102, 91 >

<1994, 0, 88 >
< 1998, -5, 90 >

< 3, -93, 86 >
< -2, -106, 91 >

< -1999, -1, 94 >
< -2003, 7, 87 >

µ1:

µ2:

µ3:

µ4:

<-1, 98, 91.5>

<1996, -2.5, 89>

<0.5, -99.5, 88.5>

<-2001, 3, 90.5>

3

4

1

2

Figure 9: The bucket assignment of the example sequence.
update the bucket mean accordingly. If not, assign it to an empty bucket and set the mean of
the bucket to be this reading.
Intuitively, by using this heuristic each of the resulting buckets is tightly concentrated about
its mean. We note that other clustering algorithms (Duda & Hart, 1973) could be used at the
bucketing stage.
Example 5.1 We would like to learn a 4-state model from a sequence of odometric readings,
hx; y; i as follows:
h2 94 92i; h1994 0 88i; h3 , 93 86i; h,1999 1 94i;
h,4 102 91i; h1998 , 5 90i; h,2 , 106 91i; h,2003 7 87i :
As a rst stage we place these readings into buckets. Suppose the standard deviation constant is
20. The placement is as shown in Figure 9. The mean value associated with each bucket is shown
as well.
2
The next stage of the algorithm is the state-tagging phase, in which each odometric reading,
rt , is assigned a pair of states, si; sj , denoting the origin state (from which the transition took
place) and the destination state (to which the transition led), respectively. In conjunction, the
mean entries, ij , of the relation matrix, R, are populated.

Example 5.1 (cont.) Returning to the sequence above, the process is demonstrated in Figure 10. We assume that the data recording starts at state 0, and that the odometric change
through self transitions is 0, with some small standard deviation (we use 20 here as well). This
is shown on part A of the gure.
Since the rst element in the sequence, h2 94 92i, is more than two standard deviations away
from the mean [0][0] and no other entry in the relation row of state 0 is populated, we pick 1
as the next state and populate the mean [0][1] to be the same as the mean of bucket 1, to which
h2 94 92i belongs. To maintain geometrical consistency the mean [1][0] is set to ,[0][1], as
shown in part B of the gure. We now have populated 2 o-diagonal entries, and the state
sequence is h0; 1i. The entry [0][1] in the matrix becomes associated with bucket 1, and this
information is recorded for helping with tagging future odometric readings belonging to the same
bucket.
The next odometric reading, h1994 0 88i, is a few standard deviations from any populated mean
in row 1 (where 1 is the current believed state). Hence, we pick a new state 2, and set the mean
[1][2] to be 2|the mean of bucket 2|to which the reading belongs (Figure 10 C). The entry
[1][2] is recorded as associated with bucket 2. To preserve anti-symmetry and additivity, [2][1]
is set to ,[1][2]. [0][2] is set to be the sum [0][1] + [1][2], and [2][0] is set to ,[0][2].
190

Learning Geometrically-Constrained HMMs
A
0
0

1

B
2

3

0

<0,0,0>

1

0
1

<0,0,0>

<0,0,0>

2

2

3

<-1,
<0,0,0> 98,
91.5>
< 1,
-98,
-91.5>

<0,0,0>

<0,0,0>

2
3

<0,0,0>

3

1

<0,0,0>

S: 0

S: 0. 1
Bucket(R[0][1]) = µ1

C
0
0
1
2

1

D
2

3

0

<-1,
<1995,
95.5,
<0,0,0> 98,
91.5> -179.5>
<1996,
< 1,
-98,
<0,0,0> -2.5,
-91.5>
89>

0
1

<-1995, <-1996,
-95.5,
2.5,
<0,0,0>
179.5> -89>

3

2
3

<0,0,0>

S: 0, 1, 2

1

2

3

<-1,
<1995, <1995.5,
95.5,
-4,
<0,0,0> 98,
91.5> -179.5> -91>
<1996, <1996.5,
< 1,
-98,
-102,
<0,0,0> -2.5,
-91.5>
89>
177.5>
<-1995, <-1996,
< 0.5,
-95.5,
2.5,
<0,0,0> -99.5,
179.5> -89>
88.5>
<-1995.5, <-1996.5, <-0.5,
99.5, <0,0,0>
4,
102,
-177.5> -88.5>
91>

S: 0,1,2,3
Bucket(R[2][3]) = µ3

Bucket(R[1][2]) = µ2

S: 0,1,2,3,0
Bucket(R[3][0]) = µ4
,..., S:0, 1, 2, 3, 0, 1, 2, 3, 0

Figure 10: Populating the odometric relation matrix and creating a state tagging sequence.
Similarly, [2][3] is updated to be the mean of bucket 3, causing the setting of [3][2], [1][3],
[0][3], [3][1], and [3][0]. Bucket 3 is associated with [2][3].
At this stage the odometric table is fully populated, as shown in part D of Figure 10. The state
sequence at this point is: h0; 1; 2; 3i. The next reading, h,1999 ,1 94i, is within one standard
deviation from [3][0] and therefore the next state is 0. Entry [3][0] is associated with bucket 4,
(the bucket to which the reading was assigned), and the state sequence becomes: h0; 1; 2; 3; 0i.
The next reading, being from bucket 1, is associated with the relation from state 0 that is tagged
by bucket 1, namely, state 1. By repeating this for the last two readings, the nal state transition
sequence becomes h0; 1; 2; 3; 0; 1; 2; 3; 0i:
2
Note that the process described in the above illustration was simplied. In the general case,
we need to take into account the rotational error in the data, use state-relative coordinate
systems, and therefore populate the entries under the transformed anti-symmetry and additivity
constraints:
 hx;yi(a; b) = ,Tba [hx;yi(b; a)] ;
 hx;yi(a; c) = hx;yi(a; b) + Tba [hx;yi(b; c)],
as dened in Section 3.3.2.
191

Shatkay & Kaelbling

It is possible that by the end of the tagging algorithm, some rows or columns of the relation
matrix are still unpopulated. This happens when there is too little data to learn from or when
the number of states provided to the algorithm is too large with respect to the actual model. In
such cases we can either \trim" the model, using the number of populated rows as the number
of states, or pick random odometric readings to populate the rest of the table, improving these
estimates later. Note that the rst approach suggests a method for learning the number of states
in the model when this is not given, starting from a gross over-estimate of the number, and truncating it to the number of populated rows in the odometric table after initialization is performed.
Once the state-transition sequence is obtained, the rest of the initialization algorithm is the same
as it is for k-means based initialization, deriving state-transition counts from the state-transition
sequence, assigning the observations to the states under the assumption that the state sequence
is correct, and obtaining state-transition and observation probabilities. The initialization phase
does not incur much computational overhead, and is equivalent time-wise to performing one
additional iteration of the em procedure.

6 Experiments and Results

The goal of the work described so far is to use odometry to improve the learning of topological
models, while using fewer iterations and less data. We tested our algorithm in a simple robotnavigation world. Our experiments consist of running the algorithm both on data obtained
from a simulated model and on data gathered by our mobile robot, Ramona. The amount of
data gathered by Ramona is used here as a proof of concept but is not sucient for statistical
analysis. For the latter, we use data obtained from the simulated model. We gathered data and
used the algorithms both with and without the perpendicularity assumption (see Section 3.3.2),
and results are provided from both settings.

6.1 Robot Domain

The robot used in our experiments, Ramona, is a modied RWI B21 robot. It has a cylindrical
synchro-drive base, 24 ultrasonic sensors and 24 infrared sensors, situated evenly around its
circumference. The infrared sensors are used mostly for short-range obstacle avoidance. The
ultrasonic sensors are longer ranged, and are used for obtaining (noisy) observations of the
environment. In the experiments described here, the robot follows a prescribed path through
the corridors in the oce environment of our department. Thus, there is no decision-making
involved, and an hmm is a sucient model, rather than a complete pomdp.
Low-level software6 provides a level of abstraction that allows the robot to move through hallways
from intersection to intersection and to turn ninety degrees to the left or right. The software
uses sonar data to distinguish doors, openings, and intersections along the path, and to stop
the robot's current action whenever such a landmark is detected. Each stop|either due to the
natural termination of an action or due to a landmark detection|is considered by the robot to
be a \state".
At each stop, ultrasonic data interpretation allows the robot to perceive, in each of the three
cardinal directions, (front, left and right), whether there is an open space, a door, a wall, or
something unknown.
Encoders on the robot's wheels allow it to estimate its pose (position and orientation) with respect to its pose at the previous intersection. After recording both the sonar-based observations
6. The low-level software was written and maintained by James Kurien.

192

Learning Geometrically-Constrained HMMs
3

5

4

6

7

8
9

2

12
13

10
11

9
8

23

42

6 7
22 20
21

43
0
19

10

5
4

1

3

2 1
41

14 15
16

18
17

24
25

38
36
37

35
34
40

11

26 27

30 31

12

0
16

15

14

29
28

39

33
32

13

Figure 11: True model of the corridors Ramona traversed. Arrows represent the prescribed path direction.

Figure 12: True model of a prescribed path
through the simulated hallway environment.

and the odometric information, the robot goes on to execute the next prescribed action. The
action command is issued manually by a human operator. Of course, both the action performance and the perception routines are subject to error. The path Ramona followed consists of
4 connected corridors in our building, which include 17 states, as shown in Figure 11.
In our simulation, we manually generated an hmm representing a prescribed path of the robot
through the complete oce environment of our department, consisting of 44 states, and the
associated transition, observation, and odometric distributions. The transition probabilities
reect an action failure rate of about 5 , 10%. That is, the probability of moving from the
current state to the correct next state in the environment, under the predetermined action is
between 0:85 and 0:95. The probability of self transition is typically between 0:05 and 0:15.
Some small probability (typically smaller than 0:02) is sometimes assigned to other transitions.
Our experience with the real robot proves that this is a reasonable transition model, since
typically the robot moves to the next state correctly, and the only error that occurs with some
signicant frequency is when it does not move at all, due to sonar interpretation indicating a
barrier when there is actually none. Once the action command is repeated the robot usually
performs the action correctly, moving to the expected next state. The observation distribution
typically assigns probabilities of 0:85 , 0:95 to the true observation that should be perceived
by the robot at each state, and probabilities of 0:05 , 0:15 to other observations that might be
perceived. For example, if a door should actually be perceived, a door is typically assigned a
probability of 0:85,0:9, a wall is assigned a probability of 0:09,0:1 and an open space is assigned
a probability of about 0:01 to be perceived. The standard deviation around odometric readings
is about 5% of the mean.
Figure 12 shows the hmm corresponding to the simulated hallway environment. Observations
and orientation are omitted from the gure for clarity. Nodes correspond to states in the
environment, while directed edges correspond to the corridors; the arrows point at the direction
in which the corridors were traversed. Further interpretation of the gures is provided in the
following section.
193

Shatkay & Kaelbling

6.2 Evaluation Method

There are a number of dierent ways of evaluating the results of a model-learning algorithm.
None are completely satisfactory, but they all give some insight into the utility of the results.
In this domain, there are transitions and observations that usually take place, and are therefore
more likely than the others. Furthermore, the relational information gives us a rough estimate
of the metric locations of the states. To get a qualitative sense of the plausibility of a learnt
model, we can extract an essential map from the learnt model, consisting of the states, the
most likely transitions and the metric measures associated with them, and ask whether this map
corresponds to the essential map underlying the true world.
Figures 11 and 12 are such essential versions of the true models, while Figures 15 and 17, shown
later, are essential versions of representative learnt ones (obtained from sequences gathered
under the perpendicularity assumption). Black dots represent the physical locations of states,
and each state is assigned a unique number. Multiple state numbers associated with a single
location typically correspond to dierent orientations of the robot at that location. The larger
black circle represents the initial state. Solid arrows represent the most likely non-self transitions
between the states. Dashed arrows represent the other transitions when their probability is 0:2
or higher. Typically, due to the predetermined path we have taken, the connectivity of the
modeled environment is low, and therefore the transitions represented by dashed arrows are
almost as likely as the most likely ones. Note that the length of the arrows, within each plot, is
signicant and represents the length of the corridors, drawn to scale.
It is important to note that the gures do not provide a complete representation of the models.
First, they lack observation and orientation information. We stress the fact that the gures
serve more as a visual aid than as a plot of the true model. We are looking for a good topological
model rather than a geometrical model. The gures provide a geometrical embedding of the
topological model. However, even when the geometry, as described by the relation matrix, is
dierent, the topology, as described by the transition and observation matrices, can still be valid.
Traditionally, in simulation experiments, the learnt model is quantitatively compared to the
actual model that generated the data. Each of the models induces a probability distribution
on strings of observations; the asymmetric Kullback-Leibler divergence (Kullback & Leibler,
1951) between the two distributions is a measure of how good the learnt model is with respect
to the true model. Given a true probability distribution P = fp1 ; :::; pn g and a learnt one
Q = fq1; :::; qn g, the kl divergence of Q with respect to P is:

D(P jjQ) =

def

n
X
i=1

pi log2 pqi :
i

We report our results in terms of a sampled version of the kl divergence, as described by Juang
and Rabiner (1985). It is based on generating sequences of sucient length (5 sequences of 1000
observations in our case) according to the distribution induced by the true model, and comparing
their log-likelihood according to the learnt model with the true model log-likelihood. The total
dierence in log-likelihood is then divided by the total number of observations, accumulated
over all the sequences, giving a number that roughly measures the dierence in log-likelihood
per observation. Formally stated, let M1 be the true model and M2 a learnt one. By generating
K sequences S1 ; : : : ; SK , each of length T , from the true model, M1 , the sampled kl-divergence,
Ds is:
K
X
[log(Pr(Si jM1 )) , log(Pr(Si jM2 ))]
i
=1
Ds(M1 jjM2 ) =
:
KT
194

Learning Geometrically-Constrained HMMs
1000
1200

500
1000

800

-1500 -1250 -1000 -750

-500

-250

600

-500
400

-1000
200

200

400

600

800

-1500

1000

Figure 13: Sequence gathered by Ramona,
perpendicularity assumed.

Figure 14: Sequence generated by our simulator, perpendicularity assumed.

We ignore the odometric information when applying the kl measure, thus allowing comparison
between purely topological models that are learnt with and without odometry.

6.3 Results within a Global Framework

We let Ramona go around the path depicted in Figure 11 and collect a sequence of about
300 observations, while assuming perpendicularity of the environment, that is, at every turning
point the angle of turn is 90 . Thus at each turn Ramona realigns its odometric readings with
its initial X and Y axes. Figure 13 plots the sequence of metric coordinates, gathered in this
way, while accumulating consecutive odometric readings, projected on hx; yi. We applied the
learning algorithm to the data 30 times. 10 of these runs were started from a k-means-based
initial model, 10 started from a tag-based initial model, and 10 started from a random initial
model. In addition we also ran the standard Baum-Welch algorithm, ignoring the odometric
information, 10 times. (Note that there is non-determinism even when using biased initial
models, since the k-means clustering starts from random seeds, and low7 random noise is added
to the data in all algorithms to avoid numerical instabilities, thus multiple runs give multiple
results). We report here the results obtained using the tag-based method, which is the most
appropriate initialization method in the general case. These results are contrasted with those
obtained when odometric information is not used at all. For a comparison of all four settings
the reader is referred to the complete report of this work (Shatkay, 1999).
Figure 15 shows the essential representations of typical learnt models starting from a tag-based
initial model. The geometry of the learnt model strongly corresponds to that of the true environment, and most of the states' positions were learnt correctly. Although the gure does
not show it, the learnt observation distributions at each state usually match well with the true
observations.
To demonstrate the eect of odometry on the quality of the learnt topological model, we contrast
the plotted models learnt using odometry with a representative topological model learnt without
7. A random number between -1cm and 1cm is added to recorded distances that are typically several meters
long.

195

Shatkay & Kaelbling
3

4

5

6

3

4

5

6

7

8

7

8

5

9

0

7

9

22

12
8
1
10
10

9
11

16

2

15
3
11
11

13
14

16

11

12

16

12
15

0

14
14

0

mona traversed.

6

4

13

Figure 15: Learnt model of the corridors Ra15

13

Figure 16: The topology of a model learnt
without the use of odometry.

the use of odometric information. Figure 16 shows the topology of a typical model learnt without
the use of odometric information. In this case, the arcs represent only topological relationships,
and their length is not meaningful. The initial state is shown as a bold circle. It is clear that
the topology learnt does not match the characteristic loop topology of the true environment.

For obtaining statistically sucient information, we generated 5 data sequences, each of length
1000, using Monte Carlo sampling from the hidden Markov model whose projection is shown in
Figure 12. One of these sequences is depicted in Figure 14. The gure demonstrates that the
noise model used in the simulation is indeed compatible with the noise pattern associated with
real robot data. We used four dierent settings of the learning algorithm:

 starting from a biased, tag-based, initial model and using odometric information;
 starting from a biased, k-means-based, initial model and using odometric information;
 starting from an initial model picked uniformly at random, while using odometric information;
 starting from a random initial model without using odometric information (standard BaumWelch).

For each sequence and each of the four algorithmic settings we ran the algorithm 10 times. To
keep the discussion focused, we concentrate here on the rst and the last of these settings and
the reader is referred to a more extensive report (Shatkay, 1999) for a complete discussion.
In all the experiments, N was set to be 44, which is the \correct" number of states; for generalization, it will be necessary to use cross-validation or regularization methods to select model
complexity. Section 5 also suggests one possible heuristic for obtaining an estimate of the number
of states.
Figure 17 shows an essential version of one learnt model, obtained from the sequence shown
in Figure 14, using tag-based initialization. We note that the learnt model is not completely
196

Learning Geometrically-Constrained HMMs
26
14

15
16 27

13
12

25
33
24
23

7

8

6

22

9
0

32 31 21

5
29 17
18
28

34

2 1
4 3

20
19 30

11
10

35 36

43 42

37
41

38
39

40

Figure 17: Learnt model of the simulated hallway environment.
accurate with respect to the true model. However, there is an obvious correspondence between
groups of states in the learnt and true models, and most of the transitions (as well as the
observations, which are not shown) were learnt correctly. The quality of the geometry of the
learnt model in this simulated large environment varies, and the geometrical results are not as
uniformly good as was the case when learning the smaller environment from real robot data.
As the environment gets large, the global relations between remote states, which are reected
in the geometrical consistency constraints, become harder to learn. Still, the topology of the
learnt model as demonstrated by our statistical experiments is good.
Table 1 lists the kl divergence between the true and learnt model, as well as the number
of runs until convergence was reached, for each of the 5 sequences for both the setting that
uses odometric information under tag-based initialization and the learning algorithm that does
not use odometric information, averaged over 10 runs per sequence. We stress that each kl
divergence measure is calculated based on new data sequences that are generated from the true
model, as described in Section 6.2. The 5 sequences from which the models were learnt do not
participate in the testing process.
The kl divergence with respect to the true model for models learnt using odometry, is about 5-6
times smaller than for models learnt without odometric data. The standard deviation around
the means is about 0.2 for kl distances for models learnt with odometry and 1.5 for the noodometry setting. To check the signicance of our results we used the simple two-sample t-test.
The models learnt using odometric information have statistically signicantly (p  0:0005) lower
average kl divergence than the others.

Seq. #
With kl
Odo Iter #
No
kl
Odo Iter #

1
0.981
16.70
6.351
124.1

2
1.290
20.90
4.863
126.0

3
1.115
22.30
5.926
113.0

4
1.241
12.70
6.261
107.4

5
1.241
27.50
4.802
122.9

Table 1: Average results of two learning settings with ve training sequences.
197

Shatkay & Kaelbling

In addition, the number of iterations required for convergence when learning using odometric
information is roughly 4-5 times smaller than that required when ignoring such information.
Again, the t-test veries the signicance of this result.
Under all three initialization settings, the models learnt are topologically somewhat inferior (and
this is with high statistical signicance), in terms of the kl divergence, to those learnt without
enforcing additivity, reported in earlier papers (Shatkay & Kaelbling, 1997, 1998). This is likely
to be a result of the very strong constraints enforced during the learning process, which prevent
the algorithm from searching better areas of the learning-space, and restrict it to reach poor local
maxima. The geometry looks superior in some cases, but it is not signicantly better. However,
there seems to be less variability in the quality of the geometrical models across multiple runs
when additivity is enforced.
While the details of an extensive comparison between the dierent initialization methods are
beyond the scope of this paper, we point out that our studies of both small and large models
show that when large models and long data sequences are involved, random initialization often
results in lower KL-divergence than the tag-based initialization. This again has to do with the
strong bias of tag-based initialization, which can lead to very peaked models compared with the
less-peaked distributions associated with the true model. Random initialization leads to atter
models. As the KL-divergence strongly penalizes models that are much more peaked than the
true ones, randomly initialized models are often closer, in terms of this measure, to the true
models than the very peaked ones learnt from other initial models. When learning small models,
where sucient training data is available, the tag-based initialization results in models that are
clearly superior to the random ones. Again, the reader is referred to the complete report of this
work (Shatkay, 1999) for a comparative study of all initialization methods under the various
settings.

6.4 Results within a Relative Framework

We applied the algorithm described in Section 4.3, extended to accommodate the state-relative
constraints (as listed in Section 3.3.2). The data used was gathered by the robot from the
same environment, and generated from the same simulated model as before (Figures 11, 12).
However, here the data is generated without assuming perpendicularity. This means that the x
and y coordinates are not realigned after each turn with the global x and y axes, but rather,
recorded \as-is." The evaluation methods stay as described above.
Figure 18 shows the projection of the odometric readings that Ramona recorded along the
x and y dimensions, while traversing this environment. For obtaining statistically sucient
information, we generated 5 data sequences, each of length 800, using Monte Carlo sampling
from the hidden Markov model whose projection is shown in Figure 12. One of these sequences
is depicted in Figure 19.
Figure 20 shows a typical model obtained by applying the algorithm enforcing the complete
geometrical consistency, to the robot data shown in Figure 18, using tag-based initialization.
We note that the rectangular geometry of the environment is preserved, although state 0 does
not participate in the loop. This is explained by observing the corresponding area of the true
environment as depicted in Figure 11, consisting of the 4 states clustered at the bottom left
corner (0, 14, 15 and 16). Due to the relatively large number of states that are close together in
that area of the true environment, it was not recognized that we ever returned particularly to
state 0 during the loop. Therefore, there was only one transition recorded from state 0 to state
198

Learning Geometrically-Constrained HMMs
3000

1500

2500

1000

2000

500

1500

-1500

-1000

-500

500

1000

-500

500

-1000

-1500

-2500 -2000 -1500 -1000 -500

500

1000

Figure 18: Sequence gathered by Ramona, no

Figure 19: Sequence generated by our simula-

perpendicularity assumed.

tor, no perpendicularity assumed.
15

14

16

1
13

12

2

11

3
4
0

5

10

6
7
9

8

Figure 20: Learnt model of the corridors Ramona traversed. Initialization is tag-based.
1 according to the expected transition counts calculated by the algorithm. When projecting the
angles to maintain additivity, (as described in Section 4.3.2), the angle from state 0 to 1 was
therefore compromised, allowing geometrical consistency to maintain the rectangular geometry
among the more regularly visited states.
For the purpose of quantitatively evaluating the learning algorithm we list in Table 2 the kl
divergence between the true and learnt model, as well as the number of iterations until convergence was reached, for each of the 5 simulation sequences with/without odometric information,
averaged over 10 runs per sequence. The table demonstrates that the kl divergence with respect to the true model for models learnt using odometric data, is about 8 times smaller than
for models learnt without it. To check the signicance of our results we again use the simple
two-sample t-test. The models learnt using odometric information have highly statistically signicantly (p  0:0005) lower average kl divergence than the others. In addition, the number of
199

Shatkay & Kaelbling

Seq. #
With kl
Odo Iter #
No
kl
Odo Iter #

1
2
3
4
5
1.46 1.18 1.20 1.02 1.22
11.8 36.8 30.7 24.6 33.3
6.91 9.93 10.03 9.54 12.43
113.3 113.1 102.0 104.2 112.5

Table 2: Average results of 2 learning settings with 5 training sequences.
iterations required for convergence when learning using odometric information is smaller than
required when ignoring such information. Again, the t-test veries the signicance (p < 0:005)
of this result.
It is important to point out that the number of iterations, although much lower, does not automatically imply that our algorithm runs in less time than the non-odometric Baum-Welch. The
major bottleneck is caused by the need to compute within the forward-backward calculations,
as described in Section 4.2.1, the values of the normal and the von-Mises densities. These require the calculation of exponent terms rather than simple multiplications, slowing down each
iteration, under the current nave implementation. However, we can solve this by augmenting
the program with look-up tables for obtaining the relevant values rather than calculating them.
In addition, we can take advantage of the symmetry in the relations table to cut down on the
amount of calculation required. It is also possible to use the fact that many odometric relations remain unchanged (particularly in the later iterations of the algorithm) from one iteration
to the next, and therefore values can be cached and shared between iterations rather than be
recalculated at each iteration.

6.5 Reducing the Amount of Data
Learning hmms obviously requires visiting states and transitioning between them multiple times,
to gather sucient data for robust statistical estimation. Intuitively, exploiting odometric data
can help reduce the number of visits needed for obtaining a reliable model.
To examine the inuence of reduction in the length of data sequences on the quality of the learnt
models, we took one of the 5 sequences and used its prexes of length 100 to 800 (the complete
sequence), in increments of 100, as training sequences. We ran the two algorithmic settings over
each of the 8 prex sequences, 10 times repeatedly. We then used the kl-divergence as described
above to evaluate each of the resulting models with respect to the true model. For each prex
length we averaged the kl-divergence over the 10 runs.
The plot in Figure 21 depicts the average kl-divergence as a function of the sequence length for
each of the two settings. It demonstrates that, in terms of the kl divergence, our algorithm,
which uses odometric information, is robust in the face of data reduction, (down to 200 data
points). In contrast, learning without the use of odometry quickly deteriorates as the amount
of data is reduced.
We note that the data sequence is twice as \wide" when odometry is used than when it is
not; that is, there is more information in each element of the sequence when odometry data is
recorded. However, the eort of recording this additional odometric information is negligible,
and is well rewarded by the fact that fewer observations and less exploration are required for
obtaining a data sequence sucient for adequate learning.
200

Learning Geometrically-Constrained HMMs
50

40

30

No Odometry

KL
20

10
Odometry Used
0

200

400
Seq. Length

600

800

Figure 21: Average kl divergence as a function of sequence length.

7 Conclusions
Odometric information, which is often readily available in the robotics domain, makes it possible
to learn hidden Markov models eciently and eectively, while using shorter training sequences.
More importantly, in contrast to the traditional perception of viewing the topological and the
geometric models as two distinct types of entities, we have shown that the odometric information
can be directly incorporated into the traditional topological hmm model, while maintaining
convergence of the reestimation algorithm to a local maximum of the likelihood function.
Our method uses the odometric information in two ways. We rst choose an initial model,
based on the odometric information. An iterative procedure, which extends the Baum-Welch
algorithm, is then used to learn the topological model of the environment while learning an
additional set of constrained geometric parameters. The additional set of constrained parameters constitutes an extension to the basic hmm/pomdp model of transitions and observations.
Even though we are primarily interested in the underlying topological model (transition and
observation probabilities), our experiments demonstrate that the use of odometric relations can
reduce the number of iterations and the amount of data required by the algorithm, and improve
the resulting model.
The initialization procedure and the enforcement of the additivity constraint over relatively
small models prove helpful both topologically and geometrically. An extensive study (Shatkay,
1999) shows that for long data sequences, generated from large models, enforcing only antisymmetry rather than additivity, leads to better topological models. This is because in these
cases, initialization is not always good, and additivity may over-constrain the learning to an
unfavorable area. Learning large models may benet from enforcing only anti-symmetry during
the rst few iterations, and complete additivity in later iterations. Alternatively, we may use our
algorithm, enforcing additivity, to learn separate models for small portions of the environment,
combining them later into one complete model. A similar idea of combining small modelfragments into a complete map of an environments was applied, in the context of geometrical
maps, in recent work by Leonard and Feder (2000).
201

Shatkay & Kaelbling

The work presented here demonstrates how domain-specic information and constraints can be
enforced as part of the statistical estimation process, resulting in better models, while requiring
shorter data sequences. We strongly believe that this idea can be applied in domains other than
robotics. In particular, the acquisition of hmms for use in molecular biology may greatly benet
from exploiting geometrical (and other) constraints on molecular structures. Similarly, temporal
constraints may be exploited in domains in which pomdps are appropriate for decision-support,
such as air-trac control and medicine.

Acknowledgments
We thank Sebastian Thrun for his insightful comments throughout this work, John Hughes and Luis Ortiz
for their helpful advice, Anthony Cassandra for his code for generating random distributions, Bill Smart
for sustaining Ramona and Jim Kurien for providing the low level code for driving her. The presentation
in this paper has beneted from the comments made by the anonymous referees to whom we are grateful.
This work was done while both authors were at the Computer Science department at Brown University,
and was supported by DARPA/Rome Labs Planning Initiative grant F30602-95-1-0020, by NSF grants
IRI-9453383 and IRI-9312395, and by the Brown University Graduate Research Fellowship.

202

Learning Geometrically-Constrained HMMs

Appendix A. An Overview of the Odometric Learning Algorithm
The algorithm takes as input an experience sequence E = hr; V i, consisting of the odometric
sequence r and the observation sequence V , as dened in the beginning of Section 4.2. The
number of states is also assumed to be given.
Learn Odometric HMM(E)
1 Initialize matrices A; B; R
(See Section 5)
2 max change 1
3 while ( max change > )
4 do Calculate Forward probabilities, 
(Equation 4)
5
Calculate Backward probabilities, 
(Equation 5)
6
Calculate state-occupation probabilities,  (Equation 6)
7
Calculate State-transition probabilities, ; (Equation 7)
8
Old A A; Old B B
9
A Reestimate (A)
(Equation 8, left)
10
B Reestimate (B )
(Equation 8, right)
11
R Reestimate (R )
(Equations 12 and 13)
x
y
x
y
12
hR ; R i Reestimate(R ; R ) (Equations 10 and 11)
13
max change MAX(Get Max Change(A; Old A );
Get Max Change(B; Old B ))
The equations referenced in Step 12 correspond to updates under the perpendicularity assumption, where a global framework is used. See (Shatkay, 1999) for update formulae within a
state-relative framework.
If additivity is enforced, step 11 is followed by a projection of the reestimated R onto an additive
ane space, as described in Section 4.3.2. In addition, step 12 is substituted by the procedure
described in Section 4.3.1. The reader is referred again to (Shatkay, 1999) for further detail.
Get Max Change is a function that takes two matrices and returns the maximal element-wise
absolute dierence between them.  is a constant set to denote the margin of error on changes
in parameters. When the change in parameters is \small enough", the model is regarded as
\unchanged".

203

Shatkay & Kaelbling

References
Abe, N., & Warmuth, M. K. (1992). On the computational complexity of approximating distributions by probabilistic automata. Machine Learning, 9 (2), 205{260.
Angluin, D. (1987). Learning regular sets from queries and counterexamples. Information and
Computation, 75, 87{106.
Asada, M. (1991). Map building for a mobile robot from sensory data. In Iyengar, S. S., &
Elfes, A. (Eds.), Autonomous Mobile Robots, pp. 312{322. IEEE Computer Society Press.
Bartels, R. (1984). Estimation in a bidirectional mixture of von Mises distributions. Biometrics,
40, 777{784.
Basye, K., Dean, T., & Kaelbling, L. P. (1995). Learning dynamics: System identication for
perceptually challenged agents. Articial Intelligence, 72 (1).
Baum, L. E., Petrie, T., Soules, G., & Weiss, N. (1970). A maximization technique occurring
in the statistical analysis of probabilistic functions of Markov chains. The Annals of
Mathematical Statistics, 41 (1), 164{171.
Cassandra, A. R., Kaelbling, L. P., & Kurien, J. A. (1996). Acting under uncertainty: Discrete
Bayesian models for mobile-robot navigation. In Proceedings of IEEE/RSJ International
Conference on Intelligent Robots and Systems.
DeGroot, M. H. (1986). Probability and Statistics (2nd edition). Addison-Wesley.
Dempster, A. P., Laird, N. M., & Rubin, D. B. (1977). Maximum likelihood from incomplete
data via the EM algorithm. Journal of the Royal Statistical Society, 39 (1), 1{38.
Dissanayake, G., Newman, P., Clark, S., Durrant-Whyte, H. F., & Csorba, M. (2001). A solution
to the simultaneous localization and map building (SLAM) problem. IEEE Transactions
on Robotics and Automation, 17 (3).
Duda, R. O., & Hart, P. E. (1973). Unsupervised Learning and Clustering, chap. 6. John Wiley
and Sons.
Elfes, A. (1989). Using occupancy grids for mobile robot perception and navigation. Computer,
Special Issue on Autonomous Intelligent Machines, 22 (6), 46{57.
Engelson, S. P., & McDermott, D. V. (1992). Error correction in mobile robot map learning.
In Proceedings of the IEEE International Conference on Robotics and Automation, pp.
2555{2560, Nice, France.
Gold, E. M. (1978). Complexity of automaton identication from given data. Information and
Control, 37, 302{320.
Gumbel, E. G., Greenwood, J. A., & Durand, D. (1953). The circular normal distribution:
Theory and tables. American Statistical Society Journal, 48, 131{152.
Hopcroft, J. E., & Ullman, J. D. (1979). Introduction to Automata Theory, Languages, and
Computation. Addison & Wesley.
204

Learning Geometrically-Constrained HMMs

Juang, B. H. (1985). Maximum likelihood estimation for mixture multivariate stochastic observations of Markov chains. AT&T Technical Journal, 64 (6).
Juang, B. H., & Rabiner, L. R. (1985). A probabilistic distance measure for hidden Markov
models. AT&T Technical Journal, 64 (2), 391{408.
Koenig, S., & Simmons, R. G. (1996a). Passive distance learning for robot navigation. In
Proceedings of the Thirteenth International Conference on Machine Learning, pp. 266{
274.
Koenig, S., & Simmons, R. G. (1996b). Unsupervised learning of probabilistic models for robot
navigation. In Proceedings of the IEEE International Conference on Robotics and Automation.
Kuipers, B., & Byun, Y.-T. (1991). A robot exploration and mapping strategy based on a semantic hierarchy of spatial representations. Journal of Robotics and Autonomous Systems,
8, 47{63.
Kullback, S., & Leibler, R. A. (1951). On information and suciency. Annals of Mathematical
Statistics, 22 (1), 79{86.
Leonard, J., Durrant-Whyte, H. F., & Cox, I. J. (1991). Dynamic map building for an autonomous mobile robot. In Iyengar, S. S., & Elfes, A. (Eds.), Autonomous Mobile Robots,
pp. 331{338. IEEE Computer Society Press.
Leonard, J. J., & Feder, H. J. S. (2000). A computationally ecient method for large-scale concurrent mapping and localization. In Hollerbach, J., & Kodischek, D. (Eds.), Proceedings
of the Ninth International Symposium on Robotics Research.
Liporace, L. A. (1982). Maximum likelihood estimation for multivariate observations of Markov
sources. IEEE Transactions on Information Theory, 28 (5).
Mardia, K. V. (1972). Statistics of Directional Data. Academic Press.
Mataric, M. J. (1990). A distributed model for mobile robot environment-learning and navigation. Master's thesis, MIT, Articial Intelligence Laboratory.
McLachlan, G. J., & Krishnan, T. (1997). The EM Algorithm and Extensions. John Wiley &
Sons.
Moravec, H. P. (1988). Sensor fusion in certainty grids for mobile robots. AI Magazine, 9 (2),
61{74.
Moravec, H. P., & Elfes, A. (1985). High resolution maps from wide angle sonar. In Proceedings
of the International Conference on Robotics and Automation, pp. 116{121.
Nourbakhsh, I., Powers, R., & Bircheld, S. (1995). Dervish: An oce-navigating robot. AI
Magazine, 16 (1), 53{60.
Pierce, D., & Kuipers, B. (1997). Map learning with uninterpreted sensors and eectors. Articial Intelligence, 92 (1-2), 169{227.
205

Shatkay & Kaelbling

Rabiner, L. R. (1989). A tutorial on hidden Markov models and selected applications in speech
recognition. Proceedings of the IEEE, 77 (2), 257{285.
Rivest, R. L., & Schapire, R. E. (1987). Diversity based inference of nite automata. In
Proceedings of the IEEE Twenty Eighth Annual Symposium on Foundations of Computer
Science, pp. 78{87, Los Angeles, California.
Rivest, R. L., & Schapire, R. E. (1989). Inference of nite automata using homing sequences. In
Proceedings of the Twenty First Annual Symposium on Theory of Computing, pp. 411{420,
Seattle, Washington.
Ron, D., Singer, Y., & Tishbi, N. (1994). Learning probabilistic automata with variable memory length. In Proceedings of the Seventh Annual Workshop on Computational Learning
Theory, pp. 35{46.
Ron, D., Singer, Y., & Tishbi, N. (1995). On the learnability and usage of acyclic probabilistic
nite automata. In Proceedings of the Eighth Annual Workshop on Computational Learning
Theory, pp. 31{40.
Ron, D., Singer, Y., & Tishby, N. (1998). On the learnability and usage of acyclic probabilistic
nite automata. Journal of Computer and Systems Science, 56 (2).
Shatkay, H. (1999). Learning Models for Robot Navigation. Ph.D. thesis, Department of Computer Science, Brown University, Providence, RI.
Shatkay, H., & Kaelbling, L. P. (1997). Learning topological maps with weak local odometric
information. In Proceedings of the Fifteenth International Joint Conference on Articial
Intelligence, Nagoya, Japan.
Shatkay, H., & Kaelbling, L. P. (1998). Heading in the right direction. In Proceedings of the
Fifteenth International Conference on Machine Learning, Madison, Wisconsin.
Simmons, R. G., & Koenig, S. (1995). Probabilistic navigation in partially observable environments. In Proceedings of the International Joint Conference on Articial Intelligence.
Smith, R., Self, M., & Cheeseman, P. (1991). A stochastic map for uncertain spatial relationships. In Iyengar, S. S., & Elfes, A. (Eds.), Autonomous Mobile Robots, pp. 323{330. IEEE
Computer Society Press.
Thrun, S. (1999). Learning metric-topological maps for indoor mobile robot navigation. AI
Journal, 1, 21{71.
Thrun, S., & Bucken, A. (1996a). Integrating grid-based and topological maps for mobile robot
navigation. In Proceedings of the Thirteenth National Conference on Articial Intelligence,
pp. 944{950.
Thrun, S., & Bucken, A. (1996b). Learning maps for indoor mobile robot navigation. Tech. rep.
CMU-CS-96-121, School of Computer Science, Carnegie Mellon University, Pittsburgh,
PA.
Thrun, S., Burgard, W., & Fox, D. (1998a). A probabilistic approach to concurrent map acquisition and localization for mobile robots. Machine Learning, 31, 29{53.
206

Learning Geometrically-Constrained HMMs

Thrun, S., Gutmann, J.-S., Fox, D., Burgard, W., & Kuipers, B. J. (1998b). Integrating topological and metric maps for mobile robot navigation: A statistical approach. In Proceedings
of the Fifteenth National Conference on Articial Intelligence, pp. 989{995.
Vapnik, V. N. (1995). The Nature of Statistical Learning Theory. Springer.

207

Journal of Articial Intelligence Research 16 (2002) 389-423

Submitted 2/02; published 6/02

The Communicative Multiagent Team Decision Problem:
Analyzing Teamwork Theories and Models

David V. Pynadath
Milind Tambe

Information Sciences Institute and Computer Science Department

pynadath@isi.edu
tambe@usc.edu

University of Southern California
4676 Admiralty Way, Marina del Rey, CA 90292 USA

Abstract

Despite the signicant progress in multiagent teamwork, existing research does not address the optimality of its prescriptions nor the complexity of the teamwork problem. Without a characterization of the optimality-complexity tradeos, it is impossible to determine
whether the assumptions and approximations made by a particular theory gain enough
eÆciency to justify the losses in overall performance. To provide a tool for use by multiagent researchers in evaluating this tradeo, we present a unied framework, the COMmunicative Multiagent Team Decision Problem (COM-MTDP). The COM-MTDP model
combines and extends existing multiagent theories, such as decentralized partially observable Markov decision processes and economic team theory. In addition to their generality
of representation, COM-MTDPs also support the analysis of both the optimality of team
performance and the computational complexity of the agents' decision problem. In analyzing complexity, we present a breakdown of the computational complexity of constructing
optimal teams under various classes of problem domains, along the dimensions of observability and communication cost. In analyzing optimality, we exploit the COM-MTDP's
ability to encode existing teamwork theories and models to encode two instantiations of
joint intentions theory taken from the literature. Furthermore, the COM-MTDP model
provides a basis for the development of novel team coordination algorithms. We derive a
domain-independent criterion for optimal communication and provide a comparative analysis of the two joint intentions instantiations with respect to this optimal policy. We have
implemented a reusable, domain-independent software package based on COM-MTDPs to
analyze teamwork coordination strategies, and we demonstrate its use by encoding and
evaluating the two joint intentions strategies within an example domain.
1. Introduction

A central challenge in the control and coordination of distributed agents is enabling them
to work together, as a team, toward a common goal. Such teamwork is critical in a vast
range of domains|for future teams of orbiting spacecraft, sensors for tracking targets, unmanned vehicles for urban battleelds, software agents for assisting organizations in rapid
crisis response, etc. Research in teamwork theory has built the foundations for successful
practical agent team implementations in such domains. On the forefront are theories based
on belief-desire-intentions (BDI) frameworks, such as joint intentions (Cohen & Levesque,
1991b, 1991a; Levesque, Cohen, & Nunes, 1990), SharedPlans (Grosz, 1996; Grosz & Kraus,
1996; Grosz & Sidner, 1990), and others (Sonenberg, Tidhar, Werner, Kinny, Ljungberg,
& Rao, 1994; Dunin-Keplicz & Verbrugge, 1996), that have provided prescriptions for coc 2002 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

Pynadath & Tambe

ordination in practical systems. These theories have inspired the construction of practical, domain-independent teamwork models and architectures (Jennings, 1995; Pynadath,
Tambe, Chauvat, & Cavedon, 1999; Rich & Sidner, 1997; Tambe, 1997; Yen, Yin, Ioerger,
Miller, Xu, & Volz, 2001), successfully applied in a range of complex domains.
Yet, two key shortcomings limit the scalability of these BDI-based theories and implementations. First, there are no techniques for the quantitative evaluation of the degree of
optimality of their coordination behavior. While optimal teamwork may be impractical in
real-world domains, such analysis would aid us in comparison of dierent theories/models
and in identifying feasible improvements. One key reason for the diÆculty in quantitative
evaluation of most existing teamwork theories is that they ignore the various uncertainties and costs in real-world environments. For instance, joint intentions theory (Cohen &
Levesque, 1991b) prescribes that team members attain mutual beliefs in key circumstances,
but it ignores the cost of attaining mutual belief (e.g., via communication). Implementations that blindly follow such prescriptions could engage in highly suboptimal coordination.
On the other hand, practical systems have addressed costs and uncertainties of real-world
environments. For instance, STEAM (Tambe, 1997; Tambe & Zhang, 1998) extends joint
intentions with decision-theoretic communication selectivity. Unfortunately, the very pragmatism of such approaches often necessarily leads to a lack of theoretical rigor, so it remains
unanswered whether STEAM's selectivity is the best an agent can do, or whether it is even
necessary at all. The second key shortcoming of existing teamwork research is the lack
of a characterization of the computational complexity of various aspects of teamwork decisions. Understanding the computational advantages of a practical coordination prescription
could potentially justify the use of that prescription as an approximation to optimality in
particular domains.
To address these shortcomings, we propose a new complementary framework, the COMmunicative Multiagent Team Decision Problem (COM-MTDP), inspired by work in economic team theory (Marschak & Radner, 1971; Yoshikawa, 1978; Ho, 1980). While our
COM-MTDP model borrows from a theory developed in another eld, we make several
contributions in applying and extending the original theory, most notably adding explicit
models of communication and system dynamics. With these extensions, the COM-MTDP
generalizes other recently developed multiagent decision frameworks, such as decentralized
POMDPs (Bernstein, Zilberstein, & Immerman, 2000).
Our denition of a team (like that in economic team theory) assumes only that team
members have a common goal and that they work selessly towards that goal (i.e., they
have no other private goals of their own). In terms of our decision-theoretic framework, we
assume that all of the team members share the same joint utility function|that is, each
team member's individual preferences are exactly the preferences of the other members and,
thus, of the team as a whole. Our denition may appear to be a \bare-bones" denition of
a team, since it does not include common concepts and assumptions from the literature on
what constitutes a team (e.g., the teammates form a joint commitment (Cohen & Levesque,
1991b), attain mutual belief upon termination of a joint goal, intend that teammates succeed in their tasks (Grosz & Kraus, 1996), etc.). From our COM-MTDP perspective, we
view these concepts as more intermediate concepts, as the means by which agents improve
their team's overall performance, rather than ends in themselves. Our hypothesis in this
investigation is that our COM-MTDP-based analysis can provide concrete justications for
390

The Communicative Multiagent Team Decision Problem

these concepts. For example, while mutual belief has no inherent value, our COM-MTDP
model can quantify the improved performance that we would expect from a team that
attains mutual belief about important aspects of its execution.
More generally, this paper demonstrates three new types of teamwork analyses made
possible by the COM-MTDP model. First, we analyze the computational complexity of
teamwork within subclasses of problem domains. For instance, some researchers have advocated teamwork without communication (Goldberg & Mataric, 1997). We use the COMMTDP model to show that, in general, the problem of constructing optimal teams without
communication is NEXP-complete, but allowing free communication reduces the problem
to be PSPACE-complete. This paper presents a breakdown of the complexity of optimal
teamwork over problem domains classied along the dimensions of observability and communication cost.
Second, the COM-MTDP model provides a powerful tool for comparing the optimality
of dierent coordination prescriptions across classes of domains. Indeed, we illustrate that
we can encode existing team coordination strategies within a COM-MTDP for evaluation.
For our analysis, we selected two joint intentions-based approaches from the literature: one
using the approach realized within GRATE* and the joint responsibility model (Jennings,
1995), and another based on STEAM (Tambe, 1997). Through this encoding, we derive the
conditions under which these team coordination strategies generate optimal team behavior,
and the complexity of the decision problems addressed by them. Furthermore, we also
derive a novel team coordination algorithm that outperforms these existing strategies in
optimality, though not in eÆciency. The end result is a well-grounded characterization of
the complexity-optimality tradeo among various means of team coordination.
Third, we can use the COM-MTDP model to empirically analyze a specic domain of
interest. We have implemented reusable, domain-independent algorithms that allow one to
evaluate the optimality of the behavior generated by dierent prescriptive policies within a
problem domain represented as a COM-MTDP. We apply these algorithms in an example
domain to empirically evaluate the aforementioned team coordination strategies, characterizing the optimality of each strategy as a function of the properties of the underlying
domain. For instance, Jennings reports experimental results (Jennings, 1995) indicating
that his joint responsibility teamwork model leads to lower waste of community eort than
competing methods of accomplishing teamwork. With our COM-MTDP model, we were
able to demonstrate the benets of Jennings' approach under many congurations of our example domain. However, in precisely characterizing the types of domains that showed such
benets, we also identied domains where these competing methods may actually perform
better. In addition, we can use our COM-MTDP model to re-create and explain previous
work that noted an instance of suboptimality in a STEAM-based, real-world implementation (Tambe, 1997). While this previous work treated that suboptimality as anomalous, our
COM-MTDP re-evaluation of the domain demonstrated that the observed suboptimality
was a symptom of STEAM's general propensity towards extraneous communication in a
signicant range of domain types. Both the algorithms and the example domain model are
available for public use in an Online Appendix 1.
Section 2 presents the COM-MTDP model's representation and places it in the context
of related multiagent models from the literature. Section 3 uses the COM-MTDP model to
dene and characterize the complexity of designing optimal agent teams. Section 4 analyzes
391

Pynadath & Tambe

the optimality of existing team coordination algorithms and derives a novel coordination
algorithm. Section 5 presents empirical results from applying our COM-MTDP algorithms
to an example domain. Section 6 summarizes our results, and Section 7 identies some
promising future directions.
2. The COM-MTDP Model

This section denes and describes the COM-MTDP model itself and its ability to represent
the important aspects of multiagent teamwork. We begin in Section 2.1 by dening the
underlying multiagent team decision problem with no explicit communication. Section 2.2
denes the complete COM-MTDP model with its extension to explicitly represent communication. Section 2.3 provides an illustration of how the COM-MTDP model represents the
execution of a team of agents. Finally, Section 2.4 describes related models of multiagent
coordination and shows how the COM-MTDP model generalizes them.
2.1 Multiagent Team Decision Problems
Given a team of seless agents, , who intend to perform some joint task, we wish to evaluate
possible policies of behavior. We represent a multiagent team decision problem (MTDP)
model as a tuple, hS; A; P; 
 ; O ; B ; Ri. We have taken the underlying components of
this model from the initial team decision model (Ho, 1980), but we have extended them to
handle dynamic decisions over time and to more easily represent multiagent domains (in
particular, agent beliefs). We assume that the model is common knowledge to all of the
team members. In other words, all of the agents believe the same model, and they believe
that they all believe the same model, etc.
2.1.1 World States:

S

 S = 1      m: a set of world states, expressed as a factored representation (a

cross product of separate features).
The state of the world here is the state of the team's environment (e.g., terrain, location of
enemy). Thus, each i represents the domain of an individual feature of that environment,
while S represents the domain of all possible combinations of values over the individual
features.
2.1.2 Domain-Level Actions:

A

fAi gi2 is a set of actions for each agent to perform to change its environment, implicitly
dening a set of combined actions, A  Qi2 Ai (corresponding to team theory's decision
variables).
Extension to Dynamic Problem: P The original team decision problem focused on
a one-shot, static problem. We extend the original concept so that each component is a
time series of random variables. The eects of domain-level actions (e.g., a ying action
changes a helicopter's position) obey a probabilistic distribution, given by a function P :
S  A  S ! [0; 1]. In other words, for each initial state s at time t, combined action a
392

The Communicative Multiagent Team Decision Problem

taken at time t, and nal state s0 at time t + 1, Pr(S t+1 = s0jS t = s; At = a) = P (s; a; s0).
The given denition of P assumes that the world dynamics obey the Markov assumption.
2.1.3 Agent Observations: 

f
igi2 is a set of observations that each agent, i, can experience of its world, implicitly
dening a combined observation, 
  Qi2 
i. 
i may include elements corresponding
to indirect evidence of the state (e.g., sensor readings) and actions of other agents (e.g.,
movement of other helicopters). In the original team-theoretic framework, the information
structure that represented the observation process of the agents was a set of deterministic
functions, Oi : S ! 
i.
Extension of Allowable Information Structures: O We extend the information
structure representation to allow for uncertain observations. We use a general stochastic
model, borrowed from the partially observable Markov decision process model (Smallwood &
Sondik, 1973), with a joint observation function: O (s; a; !) = Pr(
t = !jS t = s; At 1 =
a). This function models the sensors, representing any errors, noise, etc. In some cases,
we
Q
can separate this joint distribution into individual observation functions: O  i2 Oi ,
where Oi (s; a; !) = Pr(
ti = !jS t = s; At 1 = a). Thus, the probability distribution
specied by O forms the richer information structure used in our model. We can make
useful distinctions between dierent classes of information structures:
Collective Partial Observability This is the general case, where we make no assumptions on the observations.
Collective Observability There is a unique world state fort the combined observations of
the team: 8! 2 
, 9s 2 S such that 8s0 6= s, Pr(
 = !jS t = s0) = 0. The set
of domains that are collectively observable is a strict subset of the domains that are
collectively partially observable.
Individual Observability There is a unique world state for each individual agent's observations: 8! 2 
i, 9s 2 S such that 8s0 6= s, Pr(
ti = !jS t = s0) = 0. The set
of domains that are individually observable is a strict subset of the domains that are
collectively observable.
Non-Observability The agents receive no feedback from the world: 9! 2 
i, such that
8s 2 S and 8a 2 A , Pr(
ti = !jS t = s; At 1 = a) = 1. This assumption holds
in open-loop systems, which come under frequent consideration in classical planning (Boutilier, Dean, & Hanks, 1999).
2.1.4 Policy (Strategy) Space

iA is a domain-level policy (or strategy, in the original team theory specication) to map
an agent's belief state to an action. In the original formalism, the agent's beliefs correspond
directly to its observations (i.e., iA : 
i ! Ai).
Extension to Richer Belief State Space: B We generalize the set of possible strategies to capture the more complex mental states of the agents. Each agent, i 2 , forms a
belief state, bti 2 Bi, based on its observations seen through time t, where Bi circumscribes

393

Pynadath & Tambe

the set of possible belief states for the agent. Thus, we dene the set of possible domainlevel policies as mappings from belief states to actions, iA : Q
Bi ! Ai . We dene the set
of possible combinedt belief states over all agents to be B  i2 Bi. The corresponding
random variable, b, represents the agents' combined belief state at time t. We elaborate
on dierent types of belief states and the mapping of observations to belief states (i.e., the
state estimator function) in Section 2.2.1.
2.1.5 Reward Function:

R

A common reward function is central to the notion of teamwork in a MTDP: R : S  A !
R. This function represents the team's joint preferences over states and the cost of domainlevel actions (e.g., destroying enemy is good, returning to home base with only 10% of
original force is bad). We assume that, as seless team members, each agent shares these
preferences at the individual level as well. Therefore, each team member wants exactly
what is best for the team as a whole.
2.2 Extension for Explicit Communication: 
We make an explicit separation between domain-level actions (A) and communicative
actions. As dened in this section, communicative actions aect the receiving agents' individual belief states, but, unlike domain-level actions, they do not directly change the world
state. Although this distinction is sometimes blurry in real-world domains, we make this
explicit separation so as to isolate, as much as possible, the eects of the two types of
actions. The leverage gained from this separation provides the basis for the informative,
analytical results presented in the rest of this paper. To capture this separation, we extend
our initial MTDP model to be a communicative multiagent team decision problem (COMMTDP), that we dene as a tuple, hS; A;  ; P; 
; O; B ; Ri, with a new component,
, and an extended reward function, R.
2.2.1 Communication: 
figi2 is a set of possible messages for each agent, implicitly dening a set of combined
communications,   Qi2 i. An agent, i, may communicate message x 2 i to its
teammates, who interpret the communication by updating their belief states in response. As
a rst step in this work, we assume that all of the agents receive the messages instantaneously
and correctly (i.e., there is no lag or noise in the communication channels). This model is
common knowledge among all of the team members, so once an agent has sent a message,
it knows that its team members have received the message, and its team members know
that it knows that they have all received the message, and so on.
With communication, we divide each decision epoch into two phases: the pre-communication and post-communication phases, denoted by the subscripts  and , respectively.
In particular, the agents update their belief states at two distinct points within each decision epoch: once upon receiving observation 
ti (producing the pre-communication belief state bti ), and again upon receiving the other agents' messages (producing the postcommunication belief state bti). The distinction allows us to dierentiate between the belief
state used by the agents in selecting their communication actions and the more \up-to-date"
belief state used in selecting their domain-level actions. We also distinguish between the
394

The Communicative Multiagent Team Decision Problem

separate state-estimator functions used in each update phase:
b0i =SEi0 ()
(1)
t
t
1
t
bi =SEi (bi ; 
i )
(2)
t
t
t
bi =SEi (bi ;  )
(3)
where SEi : Bi  
i ! Bi is the pre-communication state estimator for agent i, and
SEi : Bi   ! Bi is the post-communication state estimator for agent i. The initial
state estimator, SEi0 : ; ! Bi, species the agent's prior beliefs, before any observations
are made. For each of these, we also make the obvious denitions for the corresponding
estimators for the combined belief states: SE , SE , and SE 0.
In this paper, as a rst step, we assume that the agents have perfect recall. In other
words, the agents recall all of their observations, as well as all communication of the other
agents. Thus, their belief states can representtheir entire histories as sequences of observations and received messages: Bi = 
i  , where X  denotes the set of all possible
sequences (of any length) of elements of X . The agents realize perfect recall through the
following state estimator functions:
SEi0 () = hi
(4)


 0 0 

 t 1 t 1  t
SEi ( 
i ;  ; : : : ; 
i ; 
; 
i )


 0 0 

 t 1 t 1  
 t 
=

 
i ;  ; : : :
; 
i ;  
; 
i; 
(5)
0
0
t
1
t
1
t
t
SEi ( 
i ;  ; : : : ; 
i ;  ; 
i ;  ;  )
= 


0i ; 0 ; : : : ; 

ti ; t
(6)
In other words, SEi0 initializes agent i's belief state to be an empty history, SEi appends a
new observation to agent i's belief state, and SEi appends new messages to agent i's belief
state. Under this paper's assumptions of perfect recall, all three state-estimator functions
take only constant time. However, we can potentially allow more complex functions (though
the complexity results presented hold only if the state-estimator functions take polynomial
time). For instance, although we assume perfect, synchronous, instantaneous communication here, we could potentially use the post-communication state estimator to model any
noise, temporal delays, asynchrony, cognitive burden, etc. present in the communication
channel.
We extend our denition of a policy of behavior to include a communication policy,
i : Bi ! i , analogous to Section 2.1.4's domain-level policy. We dene the joint policies,
 and A , as the combined policies across all agents in .
2.2.2 Extended Reward Function:

R

We extend the team's reward function to also represent the cost of communicative acts (e.g.,
communication channels may have associated cost): R : S  A   ! R. We assume that
the cost of communication and of domain-level actions are independent of each other, so we
can decompose the reward function into two components: a communication-level reward,
R : S   ! R, and a domain-level reward, RA : S  A ! R. The total reward is
the sum of the two component values: R(s; a; ) = RA(s; a) + R(s; ). We assume that
395

Pynadath & Tambe

communication has no inherent benet and may instead have some cost, so that for all
states, s 2 S , and messages,  2  , the reward is never positive: R(s; )  0. However,
although we assign communication no explicit value, it can have signicant implicit value
through its eect on the agents' belief states and, subsequently, on their future actions.
As with the observability function, we parameterize the communication costs associated
with message transmissions:
General Communication: We make no assumptions about communication.
Free Communication: R(s; ) = 0 for any  2 , and s 2 S . In other words,
communication actions have no eect on the agents' reward.
No communication:  = ;, i.e., no explicit communication. Alternatively, communication may be prohibitively expensive, so that 8 2  , and s 2 S , R(s;  ) = 1.
The free-communication case appears in the literature, when researchers wish to focus
on issues other than communication cost. Although, real-world domains rarely exhibit
such ideal conditions, we may be able to model some domains as having approximately free
communication to a suÆcient degree. In addition, analyzing this extreme case gives us some
understanding of the benet of communication, even if the results do not apply across all
domains. We also identify the no-communication case because such decision problems have
been of interest to researchers as well (Goldberg & Mataric, 1997). Of course, even if  = ;,
it is possible that there are domain-level actions in A that have implicit communicative
value by acting as signals that convey information to the other agents. However, we still
label such agent teams as having no communication for the purposes of the work here, since
many of our results exploit an explicit separation between domain- and communication-level
actions.
2.3 Model Illustration
We can view the evolving state as a Markov chain with separate stages for domain-level
and communication-level actions. In other words, each agent team member, i 2  begins
in some initial state, S 0, with initial belief states, b0i = SEi0 (). Each agent receives an
observation 
0i drawn according to the probability distribution O (S 0; null; 
0) (there are
no actions yet). Then, each agent updates its belief state, b0i = SEi (b0i ; 
0i ).
Next, each agent i 2  selects a message according to its communication policy, 0i =
i (b0i ), dening a combined communication, 0 . Each agent interprets the communications of all of the others by updating its belief state, b0i = SEi (b0i ; 0 ). Each
then selects an action
according
to
its
domain-level
policy,
A0i = iA(b0i ), dening a
combined action A0 . By our central assumption of teamwork, each agent receives the
same joint reward, R0 = R(S 0 ; A0 ; 0). The world then moves into a new state, S 1 ,
according to the distribution, P (S 0 ; A0 ). Again, each agent i receives an observation 
1i
drawn from 
i according to the distribution O (S 1 ; A0 ; 
1), and it updates its belief state,
b1i = SEi (b0i ; 
1i ).
The process continues, with agents choosing communication- and domain-level actions,
observing the eects, and updating their beliefs. Thus, in addition to the time series of world
states, S 0; S 1 ; : : : ; S t , the agents themselves determine a time series of communication-level
396

The Communicative Multiagent Team Decision Problem

and domain-level actions, 0 ; 1 ; : : : ; t and A1; A1 ; : : : ; At , respectively. We also have
a time series of observations for each agent i, 
0i ; 
1i ; : : : ; 
ti. Likewise, we can treat the
combined observations, 
0 ; 
1; : : : ; 
t, as a similar time series of random variables.
Finally, the agents receive a series of rewards, R0; R1 ; : : : ; Rt. We can dene the value,
V , of the policies, A and   , as the expected reward received when executing those
policies. Over a nite horizon, T , this value is equivalent to the following:
VT

(A;  ) = E

" T
X

t=0




Rt  


#

A ;  

(7)

2.4 Related Work
The COM-MTDP model subsumes many existing multiagent models, as presented in Table 1 (i.e., we can map any instance of these models into a corresponding COM-MTDP).
This generality enables us to perform novel analyses of real-world teamwork domains, as
demonstrated by Section 4's use of the COM-MTDP model for analyzing the optimality of
communication decisions.
2.4.1 Decentralized POMDPs

With its model of observability and world dynamics, our COM-MTDP model closely parallels the structure of the decentralized partially observable Markov decision process (DECPOMDP) (Bernstein et al., 2000). Following our notational conventions, a DEC-POMDP
is a tuple, hS; A ; P; 
; O ; Ri. There is no set of possible messages, , so the DECPOMDP falls into the class of domains with no communication. The DEC-POMDP observational model, O, is general enough to capture collectively partially observable domains.
2.4.2 Partially Observable Identical Payoff Stochastic Games

Stochastic games provide a rich framework for multiagent decision making when the agents
may have their own individual goals and preferences. The identical payo stochastic game
(IPSG) restricts the agents to share a single payo function, appropriate for modeling
the single, global reward function of the team context. The partially observable IPSG
(POIPSG) (Peshkin, Kim, Meuleau, & Kaelbling, 2000) is a tuple, hS; A ; P; 
; O; Ri,
very similar to the DEC-POMDP model. In other words, the observation function, O , is
general enough to support collectively partially observable domains, and there is no communication.
2.4.3 Multiagent MDPs

Another relevant model is the multiagent Markov decision process (MMDP) (Boutilier,
1996), which is a tuple, hS; A; P; Ri, in our notation. Like the DEC-POMDP, the MMDP
has no communication. In addition, the MMDP is a multiagent extension to the completely
observable MDP model, so it assumes an environment that is individually observable.

397

Pynadath & Tambe

Model

O
DEC-POMDP no communication collective partial observability
POIPSG
no communication collective partial observability
MMDP
no communication
individual observability
Xuan-Lesser general communication
collective observability
Table 1: Existing models as COM-MTDP subsets.
2.4.4 Xuan-Lesser Framework

The COM-MTDP's separation of communication from other actions is similar to previous
work on multiagent decision models (Xuan, Lesser, & Zilberstein, 2001), which supported
general communication. However, while the Xuan-Lesser model generalizes beyond individually observable environments, it supports only a subset of collectively observable environments. In particular, the Xuan-Lesser framework cannot represent agents who receive
local observations of a common world state, where the observations of dierent agents could
potentially be interdependent.
3. COM-MTDP Complexity Analysis

We can use the COM-MTDP model to prove some results about the complexity of constructing optimal agent teams (i.e., teams that coordinate to produce optimal behavior in
a problem domain). The problem facing these agents (or the designer of these agents) is
how to construct the joint policies,  and A, so as to maximize their joint reward,
as represented by the expected value, V T (A; ). In all of the results presented, we
assume that all of the values in a model instance (e.g., transition probabilities, rewards) are
rational numbers, so that we can express the particular instance as a nite-sized input.
Theorem 1 The decision problem of whether there exist policies,  and A , for a given
COM-MTDP, under general communication and collective partial observability, that yield
a total reward at least K over some nite horizon T is NEXP-complete if jj  2 (i.e.,
more than one agent).

Proof: To prove that the COM-MTDP decision problem is NEXP-hard, we reduce a DECPOMDP (Bernstein et al., 2000) to a COM-MTDP with no communication by copying
all of the other model features
from the given DEC-POMDP.
In other words, if we are



i
m
i
m
given a DEC-POMDP, S; fA gi=1; P; f
 gi=1 ; O; R , we can construct a COM-MTDP,
hS 0 ; fA0i gmi=1 ; 0; P 0 ; f
0igmi=1 ; O0; B 0; R0 i, as follows:
S0 = S
A0i = Ai
0 = ;
P 0 (s; ha1 ; : : : ; am i ; s0 ) = P (s0 js; a1 ; : : : ; am )
398

The Communicative Multiagent Team Decision Problem


0i = 
i
O0 (s; ha1 ; : : : ; am i ; h!1 ; : : : ; !m i) = O(!1 ; : : : ; !m ja1 ; : : : ; am ; s)
Bi0 = [Tj=1(
i )j
(i.e., observation sequences of length no more than the nite horizon)
R0 (s; ha1 ; : : : ; am i ;  ) = R(s; a1 ; : : : ; am )
The DEC-POMDP assumes perfect recall, so we use the state estimator functions from
Equations 5 and 6. Since there is no communication for this COM-MTDP, we have a xed
silent policy, . We can translate any domain-level policy, A, into a DEC-POMDP
joint policy, Æ, as follows:



Æi (oi1 ; : : : ; oit )  iA ( oi1 ; : : : ; oit )
(8)
The expected utility of following this joint policy, Æ, within the DEC-POMDP is identical
to that of following  and A within the constructed COM-MTDP. Thus, there exists
a policy with expected utility greater than K for the COM-MTDP if and only if there
exists one for the DEC-POMDP. The decision problem for a DEC-POMDP is known to be
NEXP-complete, so the COM-MTDP problem must be NEXP-hard.
To show that the COM-MTDP is in NEXP, our proof proceeds similarly to that of
the DEC-POMDP. In other words, we guess the joint policy,  , and write it down in
exponential time (we assume that T  jS j). We can take the COM-MTDP plus the policy
and generate (in exponential time) a corresponding MDP where the state space is the space
of all possible combined belief states of the agents. We can then use dynamic programming
to determine (in exponential time) whether  generates an expected reward of at least K .
2
In the remainder of this section, we examine the eect of communication on the complexity of constructing team policies that generate optimal behavior. We start by examining
the case under the condition of free communication, where we would expect the benet of
communication to be the greatest. To begin with, suppose that each agent is capable of
communicating its entire observation (i.e., i  
i). Before we analyze the complexity of
the team decision problem, we rst prove that the agents should exploit this capability and
communicate their true observation, as long as they incur no cost in doing so:
Theorem 2 Under free communication, consider a team of agents using a communication
policy: i (bti )  
ti . If the domain-level policy  A maximizes V T (A ;   ), then this
combined policy is dominant over any other policies. In other words, for all policies,  0A
and 0 , V T ( A ;  )  V T ( 0A ;  0 ).
Proof: Suppose we have some other communication policy, 0, that species something
other than complete communication (e.g., keeping quiet, lying). Suppose that there is some
domain-level policy, 0A , that allows the team to attain some expected reward, K , when
used in combination with 0. Then, we can construct a domain-level policy, A , such
that the team attains the same expected reward, K , when used in conjunction with the
complete-communication policy,  , as dened in the statement of Theorem 2.
Thet communication policy, 0, produces a dierent set of belief states (denoted b0 ti
and b0i) than those for  (denoted bti and bti ). In particular, we use state estimator
399

Pynadath & Tambe

functions, SEi0 and SEi0 as dened in Equations 5 and 6 to generate b0ti and b0ti .
Each belief state is a complete history of observation and communication pairs for each
agent. On the other hand, under the complete communication of , the state estimator
functions of Equations 5 and 6 reduce to:






SEi ( 
0 ; : : : ; 
t 1 ; 
ti ) = 
0 ; : : : ; 
t 1 ; 
ti
(9)

 0




SEi ( 
 ; : : : ; 
t 1 ; 
ti ; t ) = 
0 ; : : : ; 
t 1 ; t
= 

0 ; : : : ; 
t 1; 
t 
(10)
Thus, A is dened over a dierent set of belief states than 0A . In order to determine
an equivalent A, we must rst dene a recursive mapping, m, that translates the belief
states dened by  into those dened by 0 :








mi (bti ) =mi bti1 ; 
t = mi bti1 ; 
ti ; 
t
*
*
++
D
D
EE
Y t
t
= mi(bti1 ); 
ti ; 0 = mi(bti1 ); 
ti; 0j
=

*

(

mi bti1

*

); 
ti;

j 2

Y

j 2

(

( (

j0  SEj0  mj btj 1

); 
tj ))

++

(11)

Given this mapping, we then specify: iA(bti) = iA0 (mi(bti )). Executing this domainlevel policy, in conjunction with the communication policy,  , results in the identical
behavior as execution of the alternate policies, 0A and 0 . Therefore, the team following
the policies, A and  will achieve the same expected value of K , as under 0A and
0 . 2
Given this dominance of the complete-communication policy, we can prove that the
problem of constructing teams that coordinate optimally is simpler when communication is
free.
Theorem 3 The decision problem of determining whether there exist policies,  and
A , for a given COM-MTDP with free communication under collective partial observability, that yield a total reward at least K over some nite horizon T is PSPACE-complete.
Proof: To prove that the problem is PSPACE-hard, we reduce the single-agent POMDP to
a COM-MTDP. In particular, if we are given a POMDP, hS; A; P; 
; O; Ri, we can construct
a COM-MTDP, hS 0 ; A01 ; 01; P 0 ; 
01; O10 ; B10 ; R0 i, for a single-agent team (i.e.,  = f1g):
S0 = S
A01 = A
01 = ;
P 0 (s; ha1 i ; s0 ) = P (s; a1 ; s0 )

01 = 

400

The Communicative Multiagent Team Decision Problem
O10 (s; ha1 i ; h!1 i) = O(s; a1 ; !1 )

B10 =

[Tj=1(
)j
(i.e., observation sequences of length no more than the nite horizon)
RA0 (s; ha1 i) = R(s; a1 )

R0 (s;  ) =

0
This COM-MTDP satises our assumption of free communication. The POMDP assumes
perfect recall, so we use the state estimator functions from Equations 5 and 6. Just as in
the proof of Theorem 1, we can show that there exists a policy with expected utility greater
than K for this COM-MTDP if and only if there exists one for the POMDP. The decision
problem for the POMDP is known to be PSPACE-hard (Papadimitriou & Tsitsiklis, 1987),
so the COM-MTDP problem under free communication must be PSPACE-hard.
To show that the problem is in PSPACE, we take a COM-MTDP under free communication and reduce it to a single-agent POMDP. In particular, if we are given a COM-MTDP,
hS; A;  ; P; 
; O; B ; Ri, we can construct a single-agent POMDP, hS 0; A0 ; P 0 ; 
0; O0 ;
R0 i, as follows:
S0 = S
A 0 = A
P 0 (s; a; s0 ) = P (s; a; s0 )

0 = 

O0 (s; a; ! ) = O (s; a; ! )
R0 (s; a) = RA (s; a)
From Theorem 2, we need to consider only the complete-communication policy for the
COM-MTDP and this policy has a zero reward. Therefore, the decision problem for the
COM-MTDP is simply to nd a domain-level policy that produces an expected reward
exceeding K . Given full communication, the state estimator functions for the COM-MTDP
(as shown in the proof of Theorem 2) reduce to Equation 10. A policy for our POMDP
species an action for each and every history of observations: 0 : [Tj=1(
0 )j ! A0 . The
history of observations for the single-agent POMDP corresponds to the belief states of our
COM-MTDP under full communication. Therefore, we can translate a POMDP-policy, 0 ,
into an equivalent domain-level policy for the COM-MTDP:
A (h! 0 ; ! 1 ; : : : ; ! t i)  0 (h! 0 ; ! 1 ; : : : ; ! t i)
(12)
A team following A will perform the exact same domain-level actions as a single agent
following 0 . Thus, there exists a policy with expected utility greater than K for the COMMTDP if and only if there exists one for the POMDP. The decision problem for a POMDP
is known to be in PSPACE (Papadimitriou & Tsitsiklis, 1987), so the COM-MTDP problem
(under free communication) must be in PSPACE as well. 2
401

Pynadath & Tambe

Theorem 4

The decision problem of determining whether there exist policies,   and
A , for a given COM-MTDP with free communication and collective observability, that
yield a total reward at least K over some nite horizon T is P-complete.

Proof: The proof follows that of Theorem 3, but with a reduction to and from the MDP
decision problem, rather than the POMDP. The MDP decision problem is P-complete (Papadimitriou & Tsitsiklis, 1987). 2
Theorem 5 The decision problem of determining whether there exist policies,  and
A , for a given COM-MTDP with individual observability, that yield a total reward at
least K over some nite horizon T (given integers K and T ) is P-complete.

Proof: The proof follows that of Theorem 4, except that we can reduce the problem to
and from an MDP regardless of what communication policy the team uses. 2
Theorem 6 The decision problem of determining whether there exist policies,  and
A , for a given COM-MTDP with non-observability, that yield a total reward at least K
over some nite horizon T (given integers K and T ) is NP-complete.

Proof: The proof follows that of Theorem 4, except that we can reduce the problem to and
from an single-agent non-observable MDP (NOMDP) regardless of what communication
policy the team uses. In particular, because the agents are all equally ignorant of the state,
communication has no eect. The NOMDP decision problem is NP-complete (Papadimitriou & Tsitsiklis, 1987). 2
Thus, we have used the COM-MTDP framework to characterize the diÆculty of problem
domains in agent teamwork along the dimensions of communication cost and observability.
Table 2 summarizes our results, which we can use in deciding where to concentrate our
energies in attacking teamwork problems. We can use these results to draw some conclusions
about the challenges to designers of multiagent teams:
 The greatest challenges lie in those domains with either collective observability or
collective partial observability and with nonzero communication cost.
 Under collective observability and collective partial observability, teamwork without
communication is highly intractable, but, with free communication, the complexity
becomes on par with that of single-agent planning problems.
 Agent team designers have much to gain by increasing the observational capabilities of
their team (e.g., by adding new sensor agents) because of the reduction in complexity
gained by making the domain collectively observable.
 Furthermore, the results from Theorems 3 and 4 hold in any domain where the result
from Theorem 2 holds (i.e., when complete communication is the dominant policy).
Therefore, while perfectly free communication may be rare, these results show that
investment in communication in teamwork can pay o with a signicant simplication
of optimal teamwork.
402

The Communicative Multiagent Team Decision Problem

Individually Collectively
Collectively
Observable Observable Partially Observable
No Comm. P-complete NEXP-complete NEXP-complete
General Comm. P-complete NEXP-complete NEXP-complete
Free Comm. P-complete P-complete
PSPACE-complete

NonObservable
NP-Complete
NP-Complete
NP-Complete

Table 2: Time complexity of COM-MTDPs.
 On the other hand, when the world is individually observable or non-observable, com-

munication makes no dierence in performance.
 It should be noted that even under those conditions where the problem is P-complete,
the complexity of optimal teamwork is polynomial in the number of states of the
world, which may still be impractically high.
 The above complexity results pertain to nding policies that are optimal subject to
the domain properties. We will nd dierent expected rewards of the optimal policies
under dierent observability and communication properties. For instance, cutting o
all of the agents' sensors makes the domain non-observable and reduces the complexity
of generating an optimal policy from NEXP to NP, but we would expect an associated
drop in the expected reward achieved by the team.

4. Evaluating Team Coordination

Table 2 shows that providing optimal domain-level and communication policies for teams is
a diÆcult challenge. Many systems alleviate this diÆculty by having domain experts provide the domain-level plans (Tambe, 1997; Tidhar, 1993). Then, the problem for the agents
reduces to generating the appropriate team coordination,  , to ensure that they properly execute the domain-level plans, A. In this section, we demonstrate the COM-MTDP
framework's ability to analyze existing teamwork approaches in the literature. Our methodology for such analysis begins by encoding such a teamwork method as a communicationlevel policy. In other words, we translate the method into an algorithm that maps agent
beliefs (e.g., observation sequences) into communication decisions. To evaluate the performance of this policy, we then instantiate a COM-MTDP that represents the states,
transition probabilities, and reward function of a domain of interest. Our methodology
provides an evaluation of the policy in terms of the expected reward earned by the team
when following the policy in the specied domain.
We demonstrate this methodology by using our COM-MTDP framework to analyze joint
intentions theory (Cohen & Levesque, 1991b, 1991a; Levesque et al., 1990), which provides
a common basis for many existing approaches to team coordination. Section 4.1 models two
key instantiations of joint intentions taken from the literature (Jennings, 1995; Tambe, 1997)
as COM-MTDP communication policies. Section 4.2 analyzes the conditions under which
these policies generate optimal behavior and provides a third candidate policy that makes
communication decisions that are locally optimal within the context of joint intentions. In
403

Pynadath & Tambe

addition to providing the results for the particular team coordination strategies investigated,
this section also illustrates a general methodology by which one can use our COM-MTDP
framework to encode and evaluate coordination strategies proposed by existing multiagent
research.
4.1 Joint Intentions in a COM-MTDP
Joint intention theory provides a prescriptive framework for multiagent coordination in a
team setting. It does not make any claims of optimality in its teamwork, but it provides
theoretical justications for its prescriptions, grounded in the attainment of mutual belief
among the team members. We can use the COM-MTDP framework to identify the domain
properties under which attaining mutual belief generates optimal behavior and to quantify
precisely how suboptimal the performance will be otherwise.
Joint intentions theory requires that team members jointly commit to a joint persistent
goal, G. It also requires that when any team member privately believes that G is achieved
(or unachievable or irrelevant), it must then attain mutual belief throughout the team
about this achievement (or unachievability or irrelevance). To encode this prescription of
joint intentions theory within our COM-MTDP model, we rst specify the joint goal, G, as
a subset of states, G  S , where the desired goal is achieved (or unachievable or irrelevant).
Presumably, such a prescription indicates that joint intentions are not specically intended for individually observable environments. Upon achieving the goal in an individually
observable environment, each agent would simultaneously observe that S t 2 G. Because
of our assumption that the COM-MTDP model components (including O) are common
knowledge to the team, each agent would also simultaneously come to believe that its teammates have observed that S t 2 G, and that its teammates believe that it believes that all
of the team members have observed that S t 2 G, and so on. Thus, the team immediately
attains mutual belief in the achievement of the goal under individual observability without
any additional communication necessary by the team.
Instead, the joint intention framework aims at domains with some degree of unobservability. In such domains, the agents must signal the other agents, either through communication or some informative domain-level action, to attain mutual belief. However, we can
also assume that joint intention theory does not focus on domains with free communication,
where Theorem 2 shows that we can simply have the agents communicate everything, all
the time, without the need for more complex prescriptions.
The joint intention framework does not specify a precise communication policy for the
attainment of mutual belief. In this paper, we focus on communication only in the case of
goal achievement, but our methodology extends to handle unachievability and irrelevance as
well. One well-known approach (Jennings, 1995) applied joint intentions theory by having
the agents communicate the achievement of the joint goal, G, as soon as they believe G to be
true. To instantiate the behavior of Jennings' agents within a COM-MTDP, we construct a
communication policy, J, that species that an agent sends the special message, G, when
it rst believes that G holds. Following joint intentions' assumption of sincerity (Smith &
Cohen, 1996), we require that the agents never select the special G message in a belief
state unless they believe G to be true with certainty. With this requirement and with our
assumption of the team's common knowledge of the communication model, we can assume
404

The Communicative Multiagent Team Decision Problem

that all of the other agents immediately accept the special message, G, as true, and that
the agents know that all their team members accept the message as true, and so on. Thus,
the team attains mutual belief that G is true immediately upon receiving the message, G.
We can construct the communication policy, J , in constant time.
The STEAM algorithm is another instantiation of joint intentions that has had success in
several real-world domains (Tambe, 1997; Pynadath et al., 1999; Tambe, Pynadath, Chauvat, Das, & Kaminka, 2000; Pynadath & Tambe, 2002). Unlike Jennings' instantiation, the
STEAM teamwork model includes decision-theoretic communication selectivity. A domain
specication includes two parameters for each joint commitment, G:  , the probability of
miscoordinated termination of G; and Cmt , the cost of miscoordinated termination of G. In
this context, \miscoordinated termination" means that some agents immediately observe
that the team has achieved G while the rest do not. STEAM's domain specication also
includes a third parameter, Cc, to represent the cost of communication of a fact (e.g., the
achievement of G). Using these parameters, the STEAM algorithm evaluates whether the
expected cost of miscoordination outweighs the cost of communication. STEAM expresses
this criterion as the following inequality:   Cmt > Cc. We can dene a communication
policy, S based on this criterion: if the inequality holds, then an agent that has observed
the achievement of G will send the message, G; otherwise, it will not. We can construct
S in constant time.
4.2 Locally Optimal Policy
Although the STEAM policy is more selective than Jennings', it remains unanswered
whether it is optimally selective, and researchers continue to struggle with the question
of when agents should communicate (Yen et al., 2001). The few reports of suboptimal
(in particular, excessive) communication in STEAM characterized the phenomenon as an
exceptional circumstance, but it is also possible that STEAM's optimal performance is the
exception. We use the COM-MTDP model to derive an analytical characterization of optimal communication here, while Section 5 provides an empirical one by creating an algorithm
using that characterization.
Both policies, J, and S consider sending G only when an agent rst believes that
G has been achieved. Once an agent has the relevant belief, they make dierent choices, and
we consider here what the optimal decision is at this point. The domain is not individually
observable, so certain agents may be unaware of the achievement of G. When not sending
the G message, these unaware agents may unnecessarily continue performing actions in
the pursuit of achieving G. The performance of these extraneous actions could potentially
incur costs and lead to a lower utility than one would expect when sending the G message.
The decision to send G or not matters only if the team achieves G and one agent
comes to know this fact. We dene the random variable, TG, to be the earliest time at
which an agent knows this fact. We denote agent KG as the agent who knows of the
achievement at time TG . If KG = i, for some agent, i, and TG = t0 , then agent i has some
pre-communication belief state, bti0 =  , that indicates that G has been achieved. To more
precisely quantify the dierence between agent i sending the G message at time TG vs.

405

Pynadath & Tambe

never sending it, we dene the following value:
 (t0; i;  ) E
T

"T t
X0

t=0
"T t
X0

E




 = G; TG = t0 ; KG =

Rt0 +t  ti0


t=0



Rt0 +t  ti0


i; bti0 

=

#

 = null; TG = t0 ; KG = i; bti0 = 

#

(13)

We assume that, for all times other than TG, the agents follow some communication policy,
that never species G. Thus, T measures the dierence in expected reward that
hinges on agent i's specic decision to send or not send G at time t0 . Given this denition,
it is locally optimal for agent i to send the special message, G, at time t0, if and only
if T  0. We dene the communication policy, + , as the communication policy
following  for all agents at all times, except for agent i under belief state  , when
agent i sends message . With this denition, +G , is the policy under which agent i
communicates the achievement of G, and +null is the policy under which it does not.
Therefore, we can alternatively describe agent i's decision criterion as choosing +G
over +null if and only if T  0.
Unfortunately, while Equation 13 identies an exact criterion for locally optimal communication, this criterion is not yet operational. In other words, we can not directly implement
it as a communication policy for the agents. Furthermore, Equation 13 hides the underlying complexity of the computation involved, which is one of the key goals of our analysis.
Therefore, we use the COM-MTDP model to derive an operational expression of T  0.
For simplicity, we dene notational shorthand for various sequences and combinations of
values. We dene a partial sequence of random variables, X <t , to be the sequence of random variables for all times before t: X 0 , X 1 , : : : , X t 1 . We make similar denitions for the
>t , X t , etc.). The expression, (S )T , denotes the cross
other relational operators (i.e., XQ
product over states of the world, Tt=0 S , as distinguished from the time-indexed random
variable, S T , which denotes the value of the state at time T . The notation, st0 [t], species
the element in slot t within the vector st0 . We dene the function, , as shorthand within
our probability expressions. It allows us to compactly represent a particular subsequence
of world and agent belief states occurring, conditioned on the current situation, as follows:

Pr  
t; t0 ; s;   Pr(S t;t0 = s; b t;t0 =  TG = t0 ; KG = i; bti0 =  )
(14)
Informally, (ht; t0i ; s;  ) represents the event that the world and belief states from time
t through t0 correspond to the specied sequences, s and  , respectively, conditioned on
agent i being the rst to know of G's achievement at time t0 with a belief state,  . We dene
the function, , to map a pre-communication belief state into the post-communication
belief state that arises from a communication policy:
 ( ;  )  SE  ( ;   ( ))
(15)
This denition of  is a well-dened function because of the deterministic nature of the
policy, , and state-estimator function, SE  .
  ,

406

The Communicative Multiagent Team Decision Problem

Theorem 7

If we assume that, upon achievement of G, no communication other than G
is possible, then the condition T (t0 ,i, )  0 holds if and only if:
X

X

Pr((h0; t0 i ; st0 ; t0 ))

t
t
st0 2(S )t0 
0 2B 0
0

B
@



X

X





Pr (ht0 ; T i ; st0 ; t0 ) ti0 = G ; (h0; t0 i ; st0 ; t0 )



t
T t +1
st0 2(S )T t0 +1 
0 2B  0
T




X
 RA st0 [t]; A   t0 [t]; +G
t=t0



X
X
Pr (ht0 ; T i ; st0 ; t0 ) ti0 = null; (h0; t0 i ; st0 ; t0 )
t
T t +1
st0 2(S )T t0 +1 
0 2B  0
!
T




X

t
 RA st0 [t]; A   0 [t]; +null
t=t0
X X

s2G 2B

Pr ((ht0 ; t0 i ; s; )) R (s; G )

(16)

Proof: The complete proof of the following theorem appears in Online Appendix 1.
The denition of T in Equation 13 is the dierence between two expectations, where each
expectation is a sum over the possible trajectories of the agent team. Each trajectory must
includes a sequence of possible world states, since the agents' reward at each point in time
depends on the particular state of the world at that time. The agents' reward also depends
on their actions (both domain- and communication-level). These actions are deterministic,
given the agents' policies, A and , and their belief states. Thus, in addition to summing
over the possible states of the world, we must also sum over the possible states of the agents'

407

Pynadath & Tambe

beliefs (both pre- and post-communication):
T (t0; i;  )
X
X
X
=
Pr S T = sT ; b T =  T ; b T = T
sT 2(S )T  T 2(B)T   T 2(B)T

jti0 = G; TG = t0; KG = i; bti0 = 


X

X

X

T
X
t=0

sT 2(S )T   T 2(B)T   T 2(B)T





R(sT [t];  A (  T [t]);   ( T [t]))

Pr

S T

= sT ; b T =  T ; bT = T

jti0 = null; TG = t0; KG = i; bti0 = 

T
X
t=0



R(sT [t];  A (  T [t]);   ( T [t]))

(17)

We can rewrite these summations more simply using our various shorthand notations:
=

X

X

sT 2(S )T  T 2(B)T

Pr((h0; T i ; s;  T )jti0 = G)


X

X

T
X
t=0

sT 2(S )T   T 2(B)T



R(sT [t];  A ( ( T [t];  G ));  G (  T [t]))

Pr((h0; T i ; s;  T )jti0 = null)

T
X
t=0

R(sT [t];  A ( ( T [t];  null));  null( T [t]))

(18)

The remaining derivation exploits our Markovian assumptions to rearrange the summations
and cancel like terms to produce the theorem's result. 2
Theorem 7 states, informally, that we prefer sending G whenever the the cost of execution after achieving G outweighs the cost of communication of the fact that G has been
achieved. More precisely, the outer summations on the left-hand side of the inequality
iterate over all possible past histories of world and belief states, producing a probability
distribution over the possible states the team can be in at time t0. For each such state, the
expression inside the parentheses computes the dierence in domain-level reward, over all
possible future sequences of world and belief states, between sending and not sending G.
By our theorem's assumption that no communication other than G is possible after G has
been achieved, we can ignore any communication costs in the future. However, if we relax
this assumption, we can extend the left-hand side in a straightforward manner into a longer
408

The Communicative Multiagent Team Decision Problem

Individually
Observable
No Comm.

(1)
General Comm.

(1)
Free Comm.

(1)

Collectively
Collectively
NonObservable Partially Observable Observable

(1)

(1)

(1)
T
T
O((jS j  j
 j) )
O((jS j  j
 j) )

(1)

(1)

(1)

(1)

Table 3: Time complexity of locally optimal decision.
expression that accounts for the dierence in future communication costs as well. Thus, the
left-hand side captures our intuition that, when not communicating, the team will incur a
cost if the agents other than i are unaware of G's achievement. The right-hand side of the
inequality is a summation of the cost of sending the G message over possible current states
and belief states.
We can use Theorem 7 to derive the locally optimal communication decision across
various classes of problem domains. Under no communication, we cannot send G. Under
free communication, the right-hand side is 0, so the inequality is always true, and we know
to prefer sending G. Under no assumptions about communication, the determination is
more complicated. When the domain is individually observable, the left-hand side becomes
0, because all of the agents know that G has been achieved (and thus there is no dierence
in execution when sending G). Therefore, the inequality is always false (unless under free
communication), and we prefer not sending G . When the environment is not individually
observable and communication is available but not free, then, to be locally optimal at time
t0 , agent i must evaluate Inequality 16 in its full complexity. Since the inequality sums
rewards over all possible sequences of states and observations, the time complexity of the
corresponding algorithm is O((jS jj
j)T ). While this complexity is unacceptable for most
real-world problems, it still provides an exponential savings over searching the entire policy
space for the globally optimal policy, where any agent could potentially send G at times
other than TG. Table 3 provides a table of the complexity required to determine the locally
optimal policy under the various domain properties.
We can now show that although Theorem 7's algorithm for locally optimal communication provides a signicant computational savings over nding the global optimum, it still
outperforms existing teamwork models, as exemplied by our J and S policies. First,
we can use the criterion of Theorem 7 to evaluate the optimality of the policy, J . If
T (t0; i;  )  0 for all possible times t0, agents i, and belief states  that are consistent
with the achievement of the goal G, then the locally optimal policy will always specify
sending G. In other words, J will be identical to the locally optimal policy. However,
if the inequality of Theorem 7 is ever false, then J is not even locally, let alone globally,
optimal.
Second, we can also use Theorem 7 to evaluate STEAM by viewing STEAM's inequality,
  Cmt > Cc, as a crude approximation of Inequality 16. In fact, there is a clear correspondence between the terms in the two inequalities. The left-hand side of Inequality 16
computes an exact expected cost of miscoordination. However, unlike STEAM's monolithic
 parameter, the optimal criterion evaluates a complete probability distribution over all
possible states of miscoordination by considering all possible past sequences consistent with
409

Pynadath & Tambe

the agent's current beliefs. Likewise, unlike STEAM's monolithic Cmt parameter, the optimal criterion looks ahead over all possible future sequences of states to determine the true
expected cost of miscoordination. Furthermore, we can view STEAM's parameter, Cc, as an
approximation of the communication cost computed by the right-hand side of Inequality 16.
Again, STEAM uses a single parameter, while the optimal criterion computes an expected
cost over all possible states of the world.
STEAM does have some exibility in its representation, because Cmt ,  , and Cc are
not necessarily xed across the entire domain. For instance, Cmt may vary based on the
specic joint plan that the agents may have jointly committed to (i.e., there may be a
dierent Cmt for each goal G). Thus, while Theorem 7 suggests signicant additional exibility in computing Cmt through explicit lookahead, the optimal criterion derived with the
COM-MTDP model also provides a justication for the overall structure behind STEAM's
approximate criterion. Furthermore, STEAM's emphasis on on-line computation makes the
computational complexity of Inequality 16 (as presented in Table 3) unacceptable, so the
approximation error may be acceptable given the gains in eÆciency. For a specic domain,
we can use empirical evaluation (as demonstrated in the next section) to quantify the error
and eÆciency to precisely judge this tradeo.
5. Empirical Policy Evaluation

In addition to providing these analytical results over general classes of problem domains, the
COM-MTDP framework also supports the analysis of specic domains. Given a particular
problem domain, we can construct an optimal communication policy or, if the complexity of
computing an optimal policy is prohibitive, we can instead evaluate and compare candidate
approximate policies. To provide a reusable tool for such evaluations, we have implemented
the COM-MTDP model as a Python class with domain-independent methods for the evaluation of arbitrary policies and for the generation of both locally optimal policies using
Theorem 7 and globally optimal policies through brute-force search of the policy space.
This software is available in Online Appendix 1.
This section presents results of a COM-MTDP analysis of an example domain involving
agent-piloted helicopters, where we focus on the key communication decision faced by many
multiagent frameworks (as described in Section 4), but vary the cost of communication and
degree of observability to generate a space of distinct domains with dierent implications
for the agents' performance. By evaluating communication policies over various congurations of this particular testbed domain, we demonstrate a methodology by which one can
use the COM-MTDP framework to model any problem domain and to evaluate candidate
communication policies for it.
5.1 Experimental Setup
Consider two helicopters that must y across enemy territory to their destination, as illustrated in Figure 1. The rst, piloted by agent Transport, is a transport vehicle with
limited repower. The second, piloted by agent Escort, is an escort vehicle with signicant
repower. Somewhere along their path is an enemy radar unit, but its location is unknown
(a priori) to the agents. Escort is capable of destroying the radar unit upon encountering
it. However, Transport is not, but it can escape detection by the radar unit by traveling
410

The Communicative Multiagent Team Decision Problem

Figure 1: Illustration of helicopter team scenario.
at a very low altitude (nap-of-the-earth ight), though at a lower speed than at its typical,
higher altitude. In this scenario, Escort will not worry about detection, given its superior
repower; therefore, it will y at a fast speed at its typical altitude.
The two agents form a top-level joint commitment, GD , to reach their destination.
There is no incentive for the agents to communicate the achievement of this goal, since they
will both eventually reach their destination with certainty. However, in the service of their
top-level goal, GD , the two agents also adopt a joint commitment, GR, of destroying the
radar unit. We consider here the problem facing Escort with respect to communicating the
achievement of goal, GR. If Escort communicates the achievement of GR, then Transport
knows that it is safe to y at its normal altitude (thus reaching the destination sooner).
If Escort does not communicate the achievement of GR, there is still some chance that
Transport will observe the event anyway. If Transport does not observe the achievement
of GR , then it must y nap-of-the-earth the whole distance, and the team receives a lower
reward because of the later arrival. Therefore, Escort must weigh the increase in expected
reward against the cost of communication.
In the COM-MTDP model of this scenario (presented in Figures 2, 3 and 4), the world
state is the position (along a straight line between origin and destination) of Transport,
Escort, and the enemy radar. The enemy is at a randomly selected position somewhere
in between the agents' initial position and their destination. Transport has no possible
communication actions, but it can choose between two domain-level actions: ying nap-ofthe-earth and ying at its normal speed and altitude. Escort has two domain-level actions:
ying at its normal speed and destroying the radar. Escort also has the option of communicating the special message, GR , indicating that the radar has been destroyed. In the tables
of Figures 2, 3 and 4, the \" symbol represents a wild-card (or \don't care") entry.
If Escort arrives at the radar, then it observes its presence with certainty and can
destroy it to achieve GR. The likelihood of Transport's observing the radar's destruction is
a function of its distance from the radar. We can vary this function's observability parameter
411

Pynadath & Tambe

S

A



= fEscort (E ); Transport (T )g
= E  T  R
Position of Escort: E = f0; 1; : : : ; 8; 9; Destinationg
Position of Transport: T = f0; 0:5; : : : ; 9; 9:5; Destination;
Destroyedg
Position of Radar: R = f1; 2; : : : ; 8; Destroyedg
= AE  AT = fy; destroy; waitg  fy-NOE; y-normal; waitg
= E  T = fclear (GR ); nullg  fnullg
E
0; : : : ; 9
0; : : : ; 9

T
a
0; : : : ; 9:5; Destroyed 

RA

0
Destination

rT
Destination 0; : : : ; 9:5; Destroyed  rE
Destination
 rE + rT
Destination
R (s; hnull; nulli) = 0
R (s; hGR ; nulli) = r 2 [0; 1]
Figure 2: COM-MTDP model of states, actions, and rewards for helicopter scenario.

RA (hE ; T ; R i ; a)

=

( in Figure 4) within the range [0; 1] to generate distinct domain congurations (0 means
that Transport will never observe the radar's destruction; 1 means Transport will always
observe it). If the observability is 1, then they achieve mutual belief of the achievement of
GR as soon as it occurs (following the argument presented in Section 4.1). However, for any
observability less than 1, there is a chance that the agents will not achieve mutual belief
simply by common observation. The helicopters receive a xed reward for each time step
spent at their destination. Thus, for a xed time horizon, the earlier the helicopters reach
there, the greater the team's reward. Since ying nap-of-the-earth is slower than normal
speed, Transport will switch to its normal ying as soon as it either observes that GR has
been achieved or Escort sends the message, GR . Sending the message is not free, so we
impose a variable communication cost (r in Figure 2), also within the range [0; 1].
We constructed COM-MTDP models of this scenario for each combination of observability and communication cost within the range [0; 1] at 0.1 increments. For each combination,
we applied the Jennings and STEAM policies, as well as a completely silent policy. For this
domain, the policy, J , dictates that Escort always communicate GR upon destroying
the radar. For STEAM, we vary the  and Cc parameters with the observability and communication cost parameters, respectively. We used two dierent settings (low and medium)
for the cost of miscoordination, Cmt . Following the published STEAM algorithm (Tambe,
1997), Escort sends message GR if and only if STEAM's inequality   Cmt > Cc, holds.
Thus, the two dierent settings, low and medium, for Cmt generate two distinct communication policies; the high setting is strictly dominated by the other two settings in this domain.
We also constructed and evaluated locally and globally optimal policies. In applying each
of these policies, we used our COM-MTDP model to compute the expected reward received
by the team when following the selected policy. We can uniquely determine this expected
reward given the candidate communication policy and the particular observability and communication cost parameters, as well as the COM-MTDP model specied in Figures 2, 3,
and 4.
412

The Communicative Multiagent Team Decision Problem

 P (hE0; T 0; R0 i ; haE ; aT i ; hE1; T 1; R1 i) =
PE (E 0 ; aE ; E 1 )  PT (hT 0 ; R0 i ; aT ; T 1 )  PR (hE 0 ; R0 i ; aE ; R1 )

Escort: Initial distribution, Pr(0E = 0) = 1
E 0

aE

E 1

PE

Destination  Destination 1
0; : : : ; 8
y
E 0 + 1
1
0; : : : ; 8 destroy E0 + 1 1
9
y Destination 1
9
destroy Destination 1

wait
E 0
1
Transport: Initial distribution, Pr(0T = 0) = 1
T 0

R0

aT

Destination


Destroyed


0; : : : ; 9

y-NOE
9:5

y-NOE
0; : : : ; 8:5 Destroyed y-normal
9; 9:5
Destroyed y-normal

6= Destroyed y-normal


wait

T 1

Destination
Destroyed
T 0 + 0:5
Destination
T 0 + 1
Destination
Destroyed
T 0

PT

1
1
1
1
1
1
1
1

Radar: Initial distribution, 8 2 f1; 2; : : : ; 8g, P r(0R = ) = 0:125
E 0

R0

aE

R1

PR

 E0 destroy Destroyed 1

 6= destroy
R0
1
 6= E0

R0
1

Figure 3: COM-MTDP model of transition probabilities for helicopter scenario (excludes
zero probability rows).

413

Pynadath & Tambe

 
 = 
E  
T

{ 
E = E  T  
RE , where agent Escort's possible observations of the radar
consist of 
RE = fpresent; destroyed; nullg
{ 
T = E  T  
RT , where agent Transport's possible observations of the radar
consist of 
RT = fdestroyed; nullg
 O (s; haE ; aT i ; h!E ; !T i) = OE (s; haE ; aT i ; !E )  OT (s; haE ; aT i ; !T )
{ OE (hE ; T ; R i ; haE ; aT i ; hE ; T ; !RE i) =
E

R

aE

!RE

OE

destroyed destroy destroyed 1
destroyed 6= destroy null
1
R 1; : : : ; 9

present 1
6= R 1; : : : ; 9

null
1
{ OT (hE ; T ; R i ; haE ; aT i ; hE ; T ; !RT i) =



T
R
0; : : : ; 9:5 
0; : : : ; 9:5 
0; : : : ; 9:5 

aE

!RT

destroy destroyed
destroy
null 1
6= destroy null
destroyed 

null

OT

e (R T )(1 )
e (R T )(1 )

1
1

 2 [0; 1]

Figure 4: COM-MTDP model of observability for helicopter scenario. These tables exclude
both zero probability rows and input feature columns from which O is independent. For example, both agents' observation functions are independent of the
transport's selected action, so neither table includes a aT column.

414

The Communicative Multiagent Team Decision Problem

Figure 5: Suboptimality of silent and Jennings policies.

Figure 6: Suboptimality of STEAM policy under both low and medium costs of miscoordination.
5.2 Experimental Results
Figures 5 and 6 plot how much utility the team can expect to lose by following the Jennings,
silent, and the two STEAM policies instead of the locally optimal communication policy
(thus, higher values mean worse performance). We can immediately see that the Jennings
and silent policies are signicantly suboptimal for many possible domain congurations. For
example, not surprisingly, the surface for the policy, J, peaks (i.e., it does most poorly)
when the communication cost is high and when the observability is high, while the silent
policy does poorly under exactly the opposite conditions.
Previously published results (Jennings, 1995) demonstrated that the Jennings policy
led to better team performance by reducing waste of eort produced by alternate policies
like our silent one. These earlier results focused on a single domain, and Figure 5 partially
conrms their conclusion and shows that the superiority of the Jennings policy over the
silent policy extends over a broad range of possible domain congurations. On the other
hand, our COM-MTDP results also show that there is a signicant subclass of domains (e.g.,
when communication cost and observability are high) where the Jennings policy is actually
inferior to the silent policy. Thus, with our COM-MTDP model, we can characterize the
types of domains where the Jennings policy outperforms the silent policy and vice versa.
415

Pynadath & Tambe

Figure 6 shows the expected value lost by following the two STEAM policies. We can
view STEAM as trying to intelligently interpolate between the Jennings and silent policies
based on the particular domain properties. In fact, under a low setting for Cmt , we see
two thresholds, one along each dimension, at which STEAM switches between following the
Jennings and silent policies, and its suboptimality is highest at these thresholds. Under
a medium setting for Cmt , STEAM does not exhibit a threshold along the dimension of
communication cost, due to the increased cost of miscoordination. Under both settings,
STEAM's performance generally follows the better of those two xed policies, so its maximum suboptimality (0.587 under both settings) is signicantly lower than that of the silent
(0.700) and Jennings' (1.000) policies. Furthermore, STEAM outperforms the two policies
on average, across the space of domain congurations, as evidenced by its mean suboptimality of 0.063 under low Cmt and 0.083 under medium Cmt . Both values are signicantly
lower than the silent policy's mean of 0.160 and the Jennings' policy's mean of 0.161. Thus,
we have been able to quantify the savings provided by STEAM over less selective policies
within this example domain.
However, within a given domain conguration, STEAM must either always or never
communicate, and this inexibility leads to signicant suboptimality across a wide range
of domain congurations. On the other hand, Figure 6 also shows that there are domain
congurations where STEAM is locally optimal. In this relatively small-scale experimental
testbed, there is no need to incur STEAM's suboptimality, because the agents can compute
the superior locally optimal policy in under 5 seconds. In larger-scale domains, on the other
hand, the increased complexity of the locally optimal policies may render its execution
infeasible. In such domains, STEAM's constant-time execution would potentially make it a
preferable alternative. This analysis suggests a possible spectrum of algorithms that make
dierent optimality-eÆciency tradeos.
To understand the cause of STEAM's suboptimality, we can examine its performance
more deeply in Figures 7 and 8, which plot the expected number of messages sent using
STEAM (with both low and medium Cmt ) vs. the locally optimal policy, at observability
values of 0.3 and 0.7. STEAM's expected number of messages is either 0 or 1, so STEAM
can make at most two (instantaneous) transitions between them: one threshold value each
along the observability and communication cost dimensions.
From Figures 7 and 8, we see that the optimal policy can be more exible than STEAM
by specifying communication contingent on Escort's beliefs beyond simply the achievement
of GR. For example, consider the messages sent under low Cmt in Figure 7, where STEAM
matches the locally optimal policy at the extremes of the communication cost dimension.
Even if the communication cost is high, it is still worth sending message GR in states where
Transport is still very far from the destination. Thus, the surface for the optimal policy,
makes a more gradual transition from always communicating to never communicating. We
can thus view STEAM's surface as a crude approximation to the optimal surface, subject
to STEAM's fewer degrees of freedom.
We can also use Figures 7 and 8 to identify the domain conditions under which joint
intentions theory's prescription of attaining mutual belief is or is not optimal. In particular,
for any domain where the observability is less than 1, the agents will not attain mutual belief
without communication. In both Figures 7 and 8, there are many domain congurations
where the locally optimal policy is expected to send fewer than 1 GR message. Each of
416

The Communicative Multiagent Team Decision Problem

Figure 7: Expected number of messages sent by STEAM and locally optimal policies when
the observability is 0.3.

Figure 8: Expected number of messages sent by STEAM and locally optimal policies when
the observability is 0.7. Under both settings, STEAM sends 0 messages.

417

Pynadath & Tambe

Figure 9: Suboptimality of locally optimal policy.
these congurations represents a domain where the locally optimal policy will not attain
mutual belief in at least one case. Therefore, attaining mutual belief is suboptimal in those
congurations!
These experiments illustrate that STEAM, despite its decision-theoretic communication
selectivity, may communicate suboptimally under a signicant class of domain congurations. Previous work on STEAM-based, real-world, agent-team implementations informally
noted suboptimality in an isolated conguration within a more realistic helicopter transport domain (Tambe, 1997). Unfortunately, this previous work treated that suboptimality
(where the agents communicated more than necessary) as an isolated aberration, so there
was no investigation of the degree of such suboptimality, nor of the conditions under which
such suboptimality may occur in practice. We re-created these conditions within the experimental testbed of this section by using a medium Cmt . The resulting experiments (as shown
in Figure 7) illustrated that the observed suboptimality was not an isolated phenomenon,
but, in fact, that STEAM has a general propensity towards extraneous communication in
situations involving low observability (i.e., low likelihood of mutual belief) and high communication costs. This result matches the situation where the \aberration" occurred in the
more realistic domain.
The locally optimal policy is itself suboptimal with respect to the globally optimal
policy, as we can see from Figure 9. Under domain congurations with high observability,
the globally optimal policy has the escort wait an additional time step after destroying
the radar and then communicate only if the transport continues ying nap-of-the-earth.
The escort cannot directly observe which method of ight the transport has chosen, but
it can measure the change in the transport's position (since it maintains a history of its
past observations) and thus infer the method of ight with complete accuracy. In a sense,
the escort following the globally optimal policy is performing plan recognition to analyze
the transport's possible beliefs. It is particularly noteworthy that our domain specication
does not explicitly encode this recognition capability. In fact, our algorithm for nding the
globally optimal policy does not even make any of the assumptions made by our locally
observable policy (i.e., single agent is deciding whether to communicate or not, regarding
a single message, at a single point in time); rather, our general-purpose search algorithm
traverses the policy space and \discovers" this possible means of inference on its own. We
418

The Communicative Multiagent Team Decision Problem

expect that such COM-MTDP analysis can provide an automatic method for discovering
novel communication policies of this type in other domains, even those modeling real-world
problems.
Indeed, by exploiting this discovery capability within our example domain, the globally
optimal policy gains a slight advantage in expected utility over the locally optimal policy,
with a mean dierence of 0.011, standard deviation of 0.027, and maximum of 0.120. On the
other hand, our domain-independent code never requires more than 5 seconds to compute
the locally optimal policy in this testbed, while our domain-independent search algorithm
always required more than 150 minutes to nd the globally optimal policy. Thus, through
Theorem 7, we have used the COM-MTDP model to construct a communication policy
that, for this testbed domain, performs almost optimally and outperforms existing teamwork theories, with a substantial computational savings over nding the globally optimal
policy. Although these results hold for an isolated communication decision, we expect the
relative performance of the policies to stay the same even with multiple decisions, where the
inexibility of the suboptimal policies will only exacerbate their losses (i.e., the shapes of
the graphs would stay roughly the same, but the suboptimality magnitudes would increase).
6. Summary

The COM-MTDP model is a novel framework that complements existing teamwork research
by providing the previously lacking capability to analyze the optimality and complexity of
team decisions. While grounded within economic team theory, the COM-MTDP's extensions to include communication and dynamism allow it to subsume many existing multiagent
models. We were able to exploit the COM-MTDP's ability to represent broad classes of
multiagent team domains to derive complexity results for optimal agent teamwork under
arbitrary problem domains. We also used the model to identify domain properties that can
simplify that complexity.
The COM-MTDP framework provides a general methodology for analysis across both
general domain subclasses and specic domain instantiations. As demonstrated in Section 4,
we can express important existing teamwork theories within a COM-MTDP framework and
derive broadly applicable theoretical results about their optimality. Section 5 demonstrates
our methodology for the analysis of a specic domain. By encoding a teamwork problem as
a COM-MTDP, we can use the leverage of our general-purpose software tools (available in
Online Appendix 1) to evaluate the optimality of teamwork based on potentially any other
existing theory, as demonstrated in this paper using two leading instantiations of joint
intentions theory. In combining both theory and practice, we can use the theoretical results
derived using the COM-MTDP framework as the basis for new algorithms to extend our
software tools, just as we did in translating Theorem 7 from Section 4 into an implemented
algorithm for locally optimal communication in Section 5. We expect that the COM-MTDP
framework, the theorems and complexity results, and the reusable software will form a basis
for further analysis of teamwork, both by ourselves and others in the eld.

419

Pynadath & Tambe
7. Future Work for COM-MTDP Team Analysis

While our initial COM-MTDP results are promising, there remain at least three key areas
where future progress in COM-MTDPs is critical. First, analysis using COM-MTDPs (such
as the one presented in Section 5) requires knowledge of the rewards, transition probabilities, and observation probabilities, as well as of the competing policies governing agent
behavior. It may not always be possible to have such a model of the domain and agents'
policies readily available. Indeed, other proposed team-analysis techniques (Nair, Tambe,
Marsella, & Raines, 2002b; Raines, Tambe, & Marsella, 2000), do not require a priori handcoding of such models, but rather acquire them automatically through machine learning
over large numbers of runs. Also, in the interests of combating computational complexity
and improved understandability, some researchers emphasize the need for multiple models
at multiple levels of abstraction, rather than focusing on a single model (Nair et al., 2002b).
For instance, one level of the model may focus on the analysis of the individual agents' actions in support of a team, while another level may focus on interactions among subteams
of a team. We can potentially extend the COM-MTDP model in both of these directions
(i.e., machine learning of model parameters, and hierarchical representations of the team to
provide multiple levels of abstraction).
Second, it is important to extend COM-MTDP analysis to other aspects of teamwork
beyond communication. For instance, team formation (where agents may be assigned specic roles within the team) and reformation (where failure of individual agents leads to role
reassignment within in the team) are key problems in teamwork that appear suitable for
COM-MTDP analysis. Such analysis may require extensions to the COM-MTDP framework (e.g., explicit modeling of roles). Ongoing research (Nair, Tambe, & Marsella, 2002a)
has begun investigating the impact of such extensions and their applications in domains
such as RoboCup Rescue (Kitano, Tadokoro, Noda, Matsubara, Takahashi, Shinjoh, & Shimada, 1999). Analysis of more complex team behaviors may require further extensions
to the COM-MTDP model to explicitly account for additional aspects of teamwork (e.g.,
notions of authority structure within teams).
Third, extending COM-MTDP analysis beyond teamwork to model other types of coordination may require relaxation of COM-MTDP's assumption of seless agents receiving
the same joint reward. More complex organizations may require modeling other non-joint
rewards. Indeed, enriching the COM-MTDP model in this manner may enable analysis of some of the seminal work in multiagent coordination in the tradition of PGP and
GPGP (Decker & Lesser, 1995; Durfee & Lesser, 1991). Such enriched models may rst
require new advances in the mathematical foundations of our COM-MTDP framework, and
ultimately contribute towards the emerging sciences of agents and multiagent systems.
Acknowledgments

This article is a signicantly extended version of a paper, \Multiagent Teamwork: Analyzing
the Optimality and Complexity of Key Theories and Models", by the same authors, in the
Proceedings of the International Joint Conference on Autonomous Agents and Multi-Agent
Systems, 2002. This article extends the initial content by providing proofs missing in the
original paper, as well as new theoretical results, a detailed description of our experimental
420

The Communicative Multiagent Team Decision Problem

setup, new experimental results, and additional discussion and explanations of key points.
This research was supported by DARPA award No. F30602-98-2-0108, under the Control
of Agent Based Systems program, and managed by AFRL/Rome Research Site. We would
like to thank Daniel Bernstein, Ashish Goel, Daniel Marcu, Stacy Marsella, Ranjit Nair,
and Paul Rosenbloom for valuable discussion and feedback. We also thank the anonymous
reviewers for their helpful comments and suggestions.
References

Bernstein, D. S., Zilberstein, S., & Immerman, N. (2000). The complexity of decentralized
control of Markov decision processes. In Proceedings of the Conference on Uncertainty
in Articial Intelligence, pp. 32{37.
Boutilier, C. (1996). Planning, learning and coordination in multiagent decision processes.
In Proceedings of the Conference on Theoretical Aspects of Rationality and Knowledge,
pp. 195{210.
Boutilier, C., Dean, T., & Hanks, S. (1999). Decision-theoretic planning: Structural assumptions and computational leverage. Journal of Articial Intelligence Research,
11, 1{93.
Cohen, P. R., & Levesque, H. J. (1991a). Conrmation and joint action. In Proceedings of
the International Joint Conference on Articial Intelligence.
Cohen, P. R., & Levesque, H. J. (1991b). Teamwork. Nous, 25 (4), 487{512.
Decker, K., & Lesser, V. (1995). Designing a family of coordination algorithms. In Proceedings of the International Conference on Multi-Agent Systems.
Dunin-Keplicz, B., & Verbrugge, R. (1996). Collective commitments. In International
Conference on Multi-Agent Systems, pp. 56{63.
Durfee, E., & Lesser, V. (1991). Partial global planning: a coordination framework for
distributed planning. IEEE transactions on Systems, Man and Cybernetics, 21 (5).
Goldberg, D., & Mataric, M. J. (1997). Interference as a tool for designing and evaluating multi-robot controllers. In Proceedings of the National Conference on Articial
Intelligence, pp. 637{642.
Grosz, B. (1996). Collaborating systems. Articial Intelligence Magazine, 17 (2), 67{85.
Grosz, B., & Kraus, S. (1996). Collaborative plans for complex group actions. Articial
Intelligence, 86, 269{358.
Grosz, B. J., & Sidner, C. L. (1990). Plans for discourse. In Cohen, P. R., Morgan,
J., & Pollack, M. E. (Eds.), Intentions in Communication, pp. 417{444. MIT Press,
Cambridge, MA.
Ho, Y.-C. (1980). Team decision theory and information structures. Proceedings of the
IEEE, 68 (6), 644{654.
Jennings, N. (1995). Controlling cooperative problem solving in industrial multi-agent
systems using joint intentions. Articial Intelligence, 75, 195{240.
421

Pynadath & Tambe

Kitano, H., Tadokoro, S., Noda, I., Matsubara, H., Takahashi, T., Shinjoh, A., & Shimada,
S. (1999). Robocuprescue: Search and rescue for large-scale disasters as a domain for
multiagent research. In Proceedings of the IEEE International Conference on Systems,
Man and Cybernetics.
Levesque, H. J., Cohen, P. R., & Nunes, J. (1990). On acting together. In Proceedings of
the National Conference on Articial Intelligence.
Marschak, J., & Radner, R. (1971). The Economic Theory of Teams. Yale University Press,
New Haven, CT.
Nair, R., Tambe, M., & Marsella, S. (2002a). Team formation for reformation for multiagent domains like robocup rescue. In Proceedings of the International Symposium on
RoboCup.
Nair, R., Tambe, M., Marsella, S., & Raines, T. (2002b). Automated assistants for analyzing
team behaviors. Journal of Autonomous Agents and Multiagent Systems, to appear.
Papadimitriou, C. H., & Tsitsiklis, J. N. (1987). The complexity of Markov decision processes. Mathematics of Operation Research, 12 (3), 441{450.
Peshkin, L., Kim, K.-E., Meuleau, N., & Kaelbling, L. P. (2000). Learning to cooperate via
policy search. In Proceedings of the Conference on Uncertainty in Articial Intelligence, pp. 489{496.
Pynadath, D. V., & Tambe, M. (2002). An automated teamwork infrastructure for heterogeneous software agents and humans. Journal of Autonomous Agents and MultiAgent Systems: Special Issue on Infrastructure and Requirements for Building Research Grade Multi-Agent Systems, to appear.
Pynadath, D. V., Tambe, M., Chauvat, N., & Cavedon, L. (1999). Toward team-oriented
programming. In Jennings, N. R., & Lesperance, Y. (Eds.), Intelligent Agents VI:
Agent Theories, Architectures and Languages, pp. 233{247. Springer-Verlag.
Raines, T., Tambe, M., & Marsella, S. (2000). Automated agents that help humans understand team behaviors. In Proceedings of the International Conference on Autonomous
Agents.
Rich, C., & Sidner, C. (1997). COLLAGEN: When agents collaborate with people. In
Proceedings of the International Conference on Autonomous Agents.
Smallwood, R. D., & Sondik, E. J. (1973). The optimal control of partially observable
Markov processes over a nite horizon. Operations Research, 21, 1071{1088.
Smith, I. A., & Cohen, P. R. (1996). Toward a semantics for an agent communications
language based on speech-acts. In Proceedings of the National Conference on Articial
Intelligence, pp. 24{31.
Sonenberg, E., Tidhar, G., Werner, E., Kinny, D., Ljungberg, M., & Rao, A. (1994). Planned
team activity. Tech. rep. 26, Australian AI Institute.
Tambe, M. (1997). Towards exible teamwork. Journal of Articial Intelligence Research,
7, 83{124.
422

The Communicative Multiagent Team Decision Problem

Tambe, M., Pynadath, D. V., Chauvat, N., Das, A., & Kaminka, G. A. (2000). Adaptive
agent integration architectures for heterogeneous team members. In Proceedings of
the International Conference on Multi-Agent Systems, pp. 301{308.
Tambe, M., & Zhang, W. (1998). Towards exible teamwork in persistent teams. In Proceedings of the International Conference on Multi-Agent Systems, pp. 277{284.
Tidhar, G. (1993). Team-oriented programming: Preliminary report. Tech. rep. 41, Australian Articial Intelligence Institute.
Xuan, P., Lesser, V., & Zilberstein, S. (2001). Communication decisions in multi-agent
cooperation: Model and experiments. In Proceedings of the International Conference
on Autonomous Agents, pp. 616{623.
Yen, J., Yin, J., Ioerger, T. R., Miller, M. S., Xu, D., & Volz, R. A. (2001). CAST:
Collaborative agents for simulating teamwork. In Proceedings of the International
Joint Conference on Articial Intelligence, pp. 1135{1142.
Yoshikawa, T. (1978). Decomposition of dynamic team decision problems. IEEE Transactions on Automatic Control, AC-23 (4), 627{632.

423

Journal of Articial Intelligence Research 16 (2002) 359-387

Submitted 12/01; published 6/02

Collective Intelligence, Data Routing and Braess' Paradox

David H. Wolpert

NASA Ames Research Center, Mailstop 269-2
Moett Field, CA 94035

Kagan Tumer

NASA Ames Research Center, Mailstop 269-3
Moett Field, CA 94035

dhw@ptolemy.arc.nasa.gov
kagan@ptolemy.arc.nasa.gov

Abstract

We consider the problem of designing the the utility functions of the utility-maximizing
agents in a multi-agent system (MAS) so that they work synergistically to maximize a global
utility. The particular problem domain we explore is the control of network routing by
placing agents on all the routers in the network. Conventional approaches to this task have
the agents all use the Ideal Shortest Path routing Algorithm (ISPA). We demonstrate that
in many cases, due to the side-eects of one agent's actions on another agent's performance,
having agents use ISPA's is suboptimal as far as global aggregate cost is concerned, even
when they are only used to route innitesimally small amounts of traÆc. The utility
functions of the individual agents are not \aligned" with the global utility, intuitively
speaking. As a particular example of this we present an instance of Braess' paradox in
which adding new links to a network whose agents all use the ISPA results in a decrease
in overall throughput. We also demonstrate that load-balancing, in which the agents'
decisions are collectively made to optimize the global cost incurred by all traÆc currently
being routed, is suboptimal as far as global cost averaged across time is concerned. This
is also due to \side-eects", in this case of current routing decision on future traÆc. The
mathematics of Collective Intelligence (COIN) is concerned precisely with the issue of
avoiding such deleterious side-eects in multi-agent systems, both over time and space.
We present key concepts from that mathematics and use them to derive an algorithm
whose ideal version should have better performance than that of having all agents use
the ISPA, even in the innitesimal limit. We present experiments verifying this, and also
showing that a machine-learning-based version of this COIN algorithm in which costs are
only imprecisely estimated via empirical means (a version potentially applicable in the real
world) also outperforms the ISPA, despite having access to less information than does the
ISPA. In particular, this COIN algorithm almost always avoids Braess' paradox.
1. Introduction

There is a long history of AI research on the design of distributed computational systems,
stretching from Distributed AI (Huhns, 1987) through current work on multi-agent systems
(MAS's) (Claus & Boutilier, 1998; Hu & Wellman, 1998a; Jennings, Sycara, & Wooldridge,
1998; Sandholm, Larson, Anderson, Shehory, & Tohme, 1998; Sycara, 1998). When the
individual agents in such a system each have personal utility functions they are trying to
maximize and we also have a `world utility' that rates the possible dynamic histories of
the overall system, such a MAS constitutes a `collective'. In this paper we are particularly
concerned with agents that use machine learning techniques (e.g., Reinforcement Learning

c 2002 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

Wolpert & Tumer
(RL) Kaelbing, Littman, & Moore, 1996; Sutton & Barto, 1998; Sutton, 1988; Watkins &
Dayan, 1992) to try to maximize their utilities.
The eld of Collective Intelligence (COIN) is concerned with the central design problem
for collectives (Wolpert, Tumer, & Frank, 1999; Wolpert & Tumer, 1999): How, without
any detailed modeling of the overall system, can one set utility functions for the individual
agents in a COIN so that the overall dynamics reliably and robustly achieves large values
of the provided world utility? In other words, how can we leverage an assumption that
our learners are individually fairly good at what they do, to have the collective as a whole
perform well? 1
An example of where this question looms very large is the problem of how to optimize the
ow of certain entities (e.g., information packets, cars) from sources to destinations across
a network of routing nodes. Here we are concerned with the version of the problem in
which \optimization" consists of minimizing aggregate cost incurred by the entities owing
to their destinations, and where an agent controls the routing decisions of each node in
the network. This problem underlies the distributed control of a large array of real-world
domains, including internet routing, voice/video communication, traÆc ows, etc. From
the COIN perspective, the problem reduces to the question of what goals one ought to
provide to each router's agent so that each agent's self-interestedly pursuing its own utility
results in maximal throughput of the entire system (\incentive engineering").
In this paper we investigate the application of recently developed COIN techniques,
to this routing domain. Like all work concerning COINs, these techniques are designed
to be very broadly applicable, and in particular are not designed for the routing domain.
Accordingly, their performance in this domain serves as a good preliminary indication of
their more general usefulness.
To ground the discussion, we will concentrate on the telecommunications data routing
problem where the entities being routed are packets. Currently, many real-world algorithms
for this problem are based on the Shortest Path Algorithm (SPA). In this algorithm each
routing node in the network is controlled by an agent who maintains a \routing table" of the
\shortest paths" (i.e., sequences of links having minimal total incurred costs) from its node
to each of the possible destination nodes in the net. Then at each moment the agent satises
any routing requests for a particular destination node by sending all its packets down the
associated shortest path. Many Ideal SPA (ISPA) algorithms exist for eÆciently computing
the shortest path when agent-to-agent path-cost communication is available and the costs
for traversing each agent's node are unvarying in time, e.g., Dijkstra's Algorithm (Ahuja,
Magnanti, & Orlin, 1993; Bertsekas & Gallager, 1992; Deo & Pang, 1984; Dijkstra, 1959).
If a non-innitesimal amount of traÆc is to be routed to a particular destination at some
moment by some agent, then that agent's sending all that traÆc down a single path will
not result in minimal cost, no matter how that single path is chosen. However if it must
choose a single path for all its traÆc, and if the routing decisions by all other agents are
xed, then tautologically by using the ISPA the agent chooses the best such path, as far as
the traÆc it is routing is concerned. Accordingly, in the limit of routing an innitesimally
1. The lack of detailed modeling ensures that we do not face the problems of \brittleness" that sometimes
accompany mismatch between the real world and the assumptions concerning it built into non-adaptive,
\hard-wired" agents in large MAS's. In turn, this lack of modeling is what causes us to concentrate on
adaptive, RL-based agents.

360

Collective Intelligence, Data Routing and Braess' Paradox
small amount of traÆc, with all other agents' strategies being a \background", the ISPA is
the optimal (least aggregate incurred cost) routing strategy for the traÆc of the associated
single agent considered individually.
One might hope that more generally, if the agent must allot all of its traÆc to a single
path and all other agents' traÆc decisions are xed, then its choosing that path via the
ISPA would be the choice that minimizes total incurred cost of all traÆc across the net, at
least in the limit of innitesimally little traÆc. This is not the case though, because in using
the SPA the agent is not concerned with the deleterious side-eects of its actions on the
costs to the traÆc routed by other agents (Korilis, Lazar, & Orda, 1997a; Wolpert et al.,
1999). The problem is made all the worse if the other agents are allowed to change their
decisions in response to our agent's decision. In the extreme case, as elaborated below, if
all agents were to try to minimize their personal costs via ISPA's, then the agents would
actually all receive higher cost than would be the case under an alternative set of strategies.
This is an instance of the famous Tragedy Of the Commons (TOC) (Hardin, 1968).
Deleterious side-eects need not be restricted to extend over space; they can also extend
over time. Indeed, consider the algorithm of having all agents at a given moment make
routing decisions that optimize global cost incurred by the traÆc currently being routed,
an algorithm often called \load-balancing" (LB) (Heusse, Snyers, Guerin, & Kuntz, 1998).
By denition, LB avoids the deleterious side-eects over space that can result in the TOC
for the costs incurred by the traÆc currently being routed. However, due to side-eects
over time, even conventional LB can be suboptimal as far as global cost averaged across
time is concerned. Intuitively, one would have to use \load-balancing over time" to ensure
truly optimal performance. So even if one could somehow construct a distributed protocol
governing the the agents that caused them to implement LB, still one would not have
gotten theme to all act in a perfectly coordinated fashion. Such diÆculties make this an
appropriate domain in which to investigate how well COIN techniques work in practice.
Real-world SPA's (RSPA) work by applying an ISPA to the estimated costs for traversing
each path of every agent. Typically those estimates will be in error because agent-to-agent
communication is not instantaneous, and therefore routing tables may be based on out of
date information. More generally though, even if that communication were instantaneous,
the cost to traverse an agent's node may be dierent by the time the packet arrives at
that node. Accordingly, in general the performance of RSPA's is bounded above by that
of the associated ISPA. In this paper we do not wish to investigate such topics, but rather
to highlight the issue of side-eects. Accordingly we \rig the game" in our experimental
comparisons in favor of the SPA, by using ISPA's rather than RSPA's.
In general, even without side-eects, determining the optimal solution to a ow problem
(e.g., determining what the loads on each link need to be to maximize throughput on a
non-cooperative data network) can be nontractable (Ahuja et al., 1993; Orda, Rom, & Sidi,
1993b). Therefore, we will concern ourselves with providing good solutions that avoid the
diÆculties the ISPA has with side-eects. It is not our aim here to present algorithms
that nd the best possible (perfectly load-balanced over time) solution. Previous work on
using machine learning to improve routing has sometimes resulted in better performance
than (non-idealized) SPA's (Littman & Boyan, 1993; Boyan & Littman, 1994; Stone, 2000;
Marbach, Mihatsch, Schulte, & Tsisiklis, 1998). That work has not grappled with the
central COIN design problem however.
361

Wolpert & Tumer
In Section 2 we discuss SPA's deciencies and in particular their manifestations in
Braess' paradox. Then, in Section 3 we present the theory of collective intelligence, an
approach that promises to overcome those deciencies. We then discuss the routing model
we will use in our experiments, and show how the theory of COINs can be applied to that
model to provide an alternative to shortest path algorithms in Section 3. In Section 5
we present simulation results with that model comparing ISPA to COINs. These results
demonstrate that in networks running ISPA, the per packet costs can be as much as 32
% higher than in networks running algorithms based on COIN theory. In particular, even
though it only has access to imprecise estimates of costs (a handicap that does not hold for
ISPA), the COIN-based algorithm almost always avoids Braess' paradox, in stark contrast
to the ISPA. In that the cost incurred with ISPA's is presumably a lower bound on that
of an SPA not privy to instantaneous communication, the implication is that COINs can
outperform such real-world SPA's. We conclude that the techniques of the eld of collective
intelligence can be highly eective in designing the utility functions of the members of a MAS
to ensure they work in a coordinated and eÆcient manner to optimize overall performance.
2. Suboptimality of Shortest Path Routing and Braess Paradox

In this section we rst demonstrate the suboptimality of an SPA when we have multiple
agents making simultaneous routing decisions, where no agent knows ahead of time the
other's choice, and therefore does not know ahead of time exactly what the costs will be.
We then demonstrate that such suboptimality can hold even when only one agent is making
a decision, and it knows what decisions the others have previously made. Next we present
Braess' paradox, a particularly pointed instance of these eects (for other discussion of
Braess' paradox in SPA routing, see Bass, 1992; Cohen & Kelly, 1990; Cohen & Jeries,
1997; Hogg, 1995; Glance & Hogg, 1995; Korilis, Lazar, & Orda, 1999).

2.1 Suboptimality of SPA
Perhaps the simplest example of how individual greed on the part of all agents can lead
to their collective detriment occurs when two agents determine that their shortest path is
through a shared link with a limited capacity, while both have a second option that is slightly
less preferable. In such a case, their using the common link degrades the performance of
both parties, since due to limited capacity the performance of that link will quickly fall
below that of their second option.
More precisely, consider the case where the shared link has a cost given by x3 when
traversed by x packets, and where each router has an optional second link to the destination
where the cost for traÆc x to traverse such a second link is 2x. Acting alone, with a single
packet to send, they would both send that packet through the shared link (cost of 1).
However by both doing so, they incur a larger cost (cost of 8) than if they had both used
their second choices (cost of 4). Without knowing what each other will do ahead of time
(information not conventionally contained in routing tables), the agents will necessarily
have mistaken cost estimates and therefore make incorrect routing decisions. In this, even
in the limit of dierentially small packets, use of SPA will lead to a wrong routing decision.
362

Collective Intelligence, Data Routing and Braess' Paradox
2.2 Suboptimality of ISPA
We now analyze a situation where the routers may know what the loads are but are each
acting to optimize the delays experienced by their packets alone. Consider the network
shown in Figure 1. Two source routers X and Y each send one packet at a time, with X
sending to either intermediate router A or B , and Y sending to either B or C . This type
of network may arise in many dierent topologies as a subnetwork. Accordingly, diÆculties
associated with this network can also apply to many more complex topologies.

y
JJ
J

y



 JJ

 J

A

B

JJ




JJ 


J
y

y

C

JJ

X

JJ 


J
y












Y

Figure 1: Independent decisions at the source
Let xA , xB , yB , and yC , be the packet quantities at a particular xed time t, at A, B ,
or C , and originating from X or Y , as indicated. At t, each source has one packet to send.
So each of our variables is binary, with xA + xB = yB + yC = 1. Have Vi (zi ) be the cost,
per packet, at the single instant t, at router i, when the total number of packets at that
instant on that router is zi . So the total cost incurred by all packets at the time t, G(~x; ~y),
equals xA VA (xA ) + (xB + yB )VB (xB + yB ) + (yC )VC (yC ).
In an ISPA, X chooses which of xA or xB = 1 so as to minimize the cost incurred by
X's packet alone, gX (~x)  xA VA (xA ) + xB VB (xB + yB ). In doing this the ISPA ignores the
yB VB (xB + yB ) term, i.e., it ignores the \side eects" of X 's decision. Real-world SPA's
typically try to approximate this by having X choose either A or B according to whether
VA (0) or VB (yB ) is smaller, where those two values can be estimated via pings, for example.
The right thing to do from the point of view of minimizing the global cost of course
is instead to have X minimize G(~x; ~y), or more precisely, the components of G(~x; ~y) that
depend on X . Writing it out for this case, X ought to act to minimize xA VA (xA ) + (xB +
yB )VB (xB + yB ). Due to the constraint that xA + xB = 1, this means sending down A i
VA (1) < (yB + 1)VB (yB + 1) yB VB (yB ), which diers from the ISPA result in that X is
concerned with the full cost of going through router B , not just the portion of that cost
that its packet receives.
In the context of this example, this G-minimizing algorithm constitutes \load-balancing"
(LB). Note that so long as sgn[VA (0) VB (yB ) yB VB0 (yB )] 6= sgn[VA (0) VB (yB )], even
in the limit of innitesimally small traÆc (so that xA + xB equals some innitesimal Æ),
ISPA and LB still disagree. LB considers side-eects of current routing decisions on other
traÆc currently being routed. However because it does not consider side-eects of routing
decisions on future traÆc, even LB may not optimize global cost averaged across all time,
363

Wolpert & Tumer
depending on the details of the system. However through the use of \eect sets" COINs
can account even for such delayed side-eects2 .

2.3 Braess' Paradox
Let us conclude this section with an illustration of Braess' paradox (Bass, 1992; Cohen
& Kelly, 1990; Cohen & Jeries, 1997; Glance & Hogg, 1995; Hogg, 1995; Korilis, Lazar,
& Orda, 1997b; Korilis et al., 1999), a phenomenon that dramatically underscores the
ineÆciency of the ISPA. This apparent \paradox" is perhaps best illustrated through a
highway traÆc example rst given by Bass (Bass, 1992): There are two highways connecting
towns S and D. The cost associated with traversing either highway (either in terms of tolls,
or delays) is V1 + V2 , as illustrated in Net A of Figure 2. So when x = 1 (a single traveler) for
either path, total accrued cost is 61 units. If on the other hand, six travelers are split equally
among the two paths, they will each incur a cost of 83 units to get to their destinations. Now,
suppose a new highway is built connecting the two branches, as shown in Net B in Figure 2.
Further, note that the cost associated with taking this highway is not particularly high (in
fact for any load higher than 1, this highway has a lower cost than any other highway in the
system). The benet of this highway is illustrated by the dramatically reduced cost incurred
by the single traveler: by taking the short-cut, one traveler can traverse the network at a
cost of 31 units (2 V1 + V3 ). Adding a new road has seemingly reduced the traversal cost
dramatically.

V2

V1

"y
bDb
"
"
bb
y"
"
byV1

V2

y
bb
"yV2
"
bb ""
b"
yS

V1

Net A
Figure 2: Hex network with V1 = 10x ;

"ybDb
"
"
bb
"y"
byV1

V3

y



yb
"yV2
bb
"
bb"yS""
V2

Net B
= 50 + x ;

V3

= 10 + x

However consider what happens when six travelers are on the highways in net B. If
each agent uses an ISPA, then at equilibrium each of the three possible paths contains two
travelers.3 Due to overlaps in the paths however, this results in each traveler incurring a
cost of 92 units, which is higher than than what they incurred before the new highway was
built. The net eect of adding a new road is to increase the cost incurred by every traveler.
This phenomenon is known as Braess' paradox.
2. A detailed discussion and proof of the suboptimality of LB is shown in appendix A. Since LB is not
used in current systems and is hard to imagine ever being used, our experiments do not consider it; it is
discussed here for pedagogical reasons.
3. We have in mind here the Nash equilibrium for this problem, where no traveler (or equivalently, no
router) can gain advantage by changing strategies.

364

Collective Intelligence, Data Routing and Braess' Paradox
3. Mathematics of Collective Intelligence

One common solution to these types of side-eect problems is to have particular agents
of the network (e.g., a \network manager" Korilis, Lazar, & Orda, 1995) dictate certain
choices to other agents. This solution can incur major brittleness and scaling problems
however. Another kind of approach, which avoids the problems of a centralized manager,
is to provide the agents with extra incentives that can induce them to take actions that are
undesirable to them from a strict SPA sense. Such incentive can be in the form of \taxes"
or \tolls" added to the costs associated with traversing particular links to discourage the
use of those links. Such schemes in which tolls are superimposed on the agents' goals are
a special case of the more general approach of replacing the goal of each agent with a new
goal. These new goals are specically tailored so that if they are collectively met the system
maximizes throughput. A priori, a agent's goal need have no particular relation with the
SPA-type cost incurred by that agent's packets. Intuitively, in this approach, we provide
each agent with a goal that is \aligned" with the global objective, with no separate concern
for of that goal's relation to the SPA-type cost incurred by the traÆc routed by that agent.
In this section, we summarize the salient aspects of a Collective Intelligences (COIN) (Wolpert,
Wheeler, & Tumer, 2000; Wolpert & Tumer, 1999). In this paper we consider systems that
consist of a set of agents, connected in a network, evolving across a set of discrete, consecutive time steps, t 2 f0; 1; :::g. Without loss of generality, we let all relevant characteristics of
a agent  at time t | including its internal parameters at that time as well as its externally
visible actions | be encapsulated by a Euclidean vector  ;t with components  ;t;i . We
call this the \state" of agent  at time t, and let  ;t be the state of all agents at time t,
while  is the state of all agent across all time.
World utility, G( ), is a function of the state of all agents across all time. When 
is an agent that uses a Machine Learning (ML) algorithm to \try to increase" its private
utility, we write that private utility as g ( ), or more generally, to allow that utility to
vary in time, g; ( ).
We assume that  encompasses all physically relevant variables, so that the dynamics
of the system is deterministic (though of course imprecisely known to anyone trying to
control the system). Note that this means that all characteristics of an agent  at t = 0
that aects the ensuing dynamics of the system must be included in  ;0 . For ML-based
agents, this includes in particular the algorithmic specication of its private utility, typically
in the physical form of some computer code (the mathematics can be generalized beyond
ML-based agents, as elaborated in Wolpert & Tumer, 1999).
Here we focus on the case where our goal, as COIN designers, is to maximize world utility
through the proper selection of private utility functions. Intuitively, the idea is to choose
private utilities that are aligned with the world utility, and that also have the property
that it is relatively easy for us to congure each agent so that the associated private
utility
P
achieves a large value. In this paper, all utilities we consider are of the form t Rt ( ;t )
P
for reward functions Rt (simply t Rt ( ;t ) for non-time-varying utilities). From now on,
we will only consider world utilities whose associated set of fRt g are all time-translations of
one another. In particular, as shown below, overall network throughput is expressible this
way.
365

Wolpert & Tumer
We need a formal denition of the concept of having private utilities be \aligned" with
Constructing such a formalization is a subtle exercise. For example, consider systems
where the world utility is the sum of the private utilities of the individual agents. This might
seem a reasonable candidate for an example of \aligned" utilities. However such systems
are examples of the more general class of systems that are \weakly trivial". It is well-known
that in weakly trivial systems each individual agent greedily trying to maximize its own
utility can lead to the tragedy of the commons (Hardin, 1968; Crowe, 1969) and actually
minimize G. In
particular, this can be the case when private
utilities are independent of
P
P
time and G =  g . Evidently, at a minimum, having G =  g is not suÆcient to ensure
that we have \aligned" utilities; some alternative formalization of the concept is needed.
Note that in the simple network discussed in Section 2.1, the utilities are weakly trivial,
since G(~x; ~y) = gX (~x) + gy (~y ). This provides another perspective on the suboptimality of
ISPA in that network.
G.

A more careful alternative formalization of the notion of aligned utilities is the concept
of \factored" systems. A system is factored at time  when the following holds for each
agent  individually: A change at time  to the state of  alone, when propagated across
time, will result in an increased value of g; ( ) if and only if it results in an increase for
G( ) (Wolpert & Tumer, 1999).
For a factored system, the side-eects of any change to 's t =  state that increases its
private utility cannot decrease world utility. There are no restrictions though on the eects
of that change on the private utilities of other agents and/or times. In particular, we don't
preclude an agent's algorithm at two dierent times from \working at cross-purposes" to
each other, so long as at both moments the agent is working to improve G. In game-theoretic
terms, in factored systems optimal global behavior corresponds to the agents' always being
at a private utility Nash equilibrium (Fudenberg & Tirole, 1991). In this sense, there can
be no tragedy of the commons for a factored system. As a trivial example, a system is
factored for g; = G 8, a system conventionally called a `team game'.

Furthermore, if our system is factored with respect to private utilities fg; g, we want
each agent to be in a state at time  that induces as high a value of the associated private
utility as possible (given the initial states of the other agents). Assume  is ML-based and
able to achieve fairly large values of most private utilities we are likely to set it for time
 , i.e., assume that given that private utility g; , the rest of the components of  ; are
set by 's algorithm in such a way so as to achieve a relatively high value of g; . So our
problem becomes determining for what fg; g the agents will best be able to achieve high
g (subject to each other's actions) while also causing dynamics that is factored for G and
the fg; g.

Dene the eect set of the agent-time pair (;  ) at  , C(eff
; ) ( ), as the set of all agents
 0 ;t which under the forward dynamics of the system have non-zero partial derivative with
respect to the state of agent  at t =  . Intuitively, (;  )'s eect set is the set of the states
of all agents  0 ;t that would be aected by a change in the state of agent  at time  .
Next, for any set  of agents (0 ; t), dene CL ( ) as the \virtual" vector formed by
clamping the components of the vector  delineated in  to an arbitrary xed value, which
366

Collective Intelligence, Data Routing and Braess' Paradox
in this paper is set to 0. 4 This operation creates a new state vector (e.g., worldline) where
the clamped components of that worldline (e.g., one player's action at a particular time
step) are \zeroed" (e.g., removed from the system).
The value of the wonderful life utility (WLU for short) for  is dened as:
W LU ( )

 G( )

G(CL ( )):

(1)

In particular, we are interested in the WLU for the eect set of agent-time pair (;  ). This
WLU is the dierence between the actual world utility and the virtual world utility where
all agent-time pairs that are aected by (;  ) have been clamped to a zero state while the
rest of  is left unchanged.
Since we are clamping to ~0, we can loosely view (;  )'s eect set WLU as analogous
to the change in world utility that would have arisen if (;  ) \had never existed", hence
the name of this utility - cf. the Frank Capra movie. Note however, that CL is a purely
\ctional", counter-factual operator, in that it produces a new  without taking into account
the system's dynamics. The sequence of states the agent-time pairs in  are clamped to
in constructing the WLU need not be consistent with the dynamical laws of the system.
This dynamics-independence is a crucial strength of the WLU. It means that to evaluate
the WLU we do not try to infer how the system would have evolved if agent 's state were
set to ~0 at time  and the system evolved from there. So long as we know  , extending over
all time, , and the function G, we know the value of WLU.
As mentioned above, regardless of the system dynamics, having g; = G 8 means the
system is factored at time  .

Theorem: Regardless of the system dynamics, setting
factored system at time  .

g;

=

W LUC eff

(; )

8 results in a

Proof: The second term, G(CLC eff ( )) is, by denition, independent of  ; . Therefore
(; )

a change to only the (;  ) component of  will only aect the rst term, G( ). Therefore
the eect of such a change on the value of the world utility is the same as its eect on the
value of the wonderful life utility. QED.
Since factoredness does not distinguish the team game and wonderful life utilities, we
need some other means of deciding which to use as our choice of fg; g. To determine
this, note that since each agent is operating in a large system, it may experience diÆculty
discerning the eects of its actions on G when G sensitively depends on all the agents in the
system. Therefore each  may have diÆculty learning from past experience what to do to
achieve high g; when g; = G. In particular, in routing in large networks, having private
rewards given by the world reward functions means that to provide each router with its
reward at each time step we need to provide it the full throughput of the entire network
at that step. This is usually infeasible in practice. Even if it weren't though, using these
private utilities would mean that the routers face a very diÆcult task in trying to discern
4. The choice of the clamping parameter used in an associated COIN can aect its performance. However
within wide ranges, it doesn't aect whether such a COIN outperforms alternatives like team games.

367

Wolpert & Tumer
the eect of their actions on their rewards, and therefore would likely be unable to learn
their best routing strategies.
This problem can be mitigated by using eect set WLU as the private utility, since the
subtraction of the clamped term removes much of the \noise" of the activity of other agents,
leaving only the underlying \signal" of how the agent in question aects the utility (this
reasoning is formalized as the concept of \learnability" in Wolpert & Tumer, 1999). Accordingly, one would expect that setting private utilities to WLU's ought to result in better
performance than having g; = G 8;  . This is the primary theoretical consideration that
we leverage in the COIN techniques investigated in this paper.
In practice, we will sometimes only be able to estimate the \primary", most prominent
portion of the eect set. Technically, the associated WLU is not the eect set WLU, and
therefore not exactly factored. However assuming that that associated WLU is close enough
to being factored, we would expect the advantage in learnability with such a WLU to still
result in better performance than would using g; = G 8;  (see Wolpert et al., 2000;
Wolpert & Tumer, 1999). Indeed, for the sake of improving learnability, sometimes we will
elect to exclude certain agent-time pairs from our estimate of the eect set of (;  ), even
if we are sure that that are aected by  ; . This will be the case if we expect that the
changes in G due to varying  ; that are \mediated" through those agent-time pairs are
relatively insignicant, and therefore eectively constitute noise for the learning process, so
that their eect on learnability is more important than their eect on factoredness.
4. Collective Intelligence for Network Routing

In this section, we use the theory summarized in Section 3 to derive individual goals for
each router, in the form of private utility functions to be maximized by appropriate choice
of routing decisions. The routers tried to achieve those maximizations by using algorithms
that only require limited knowledge of the state of the network (in particular knowledge
that is readily available to routers in common real data networks). In our simulations each
router used a Memory Based (MB) machine learning algorithm (nearest neighbor) to make
routing decisions. More precisely, for each potential routing decision, the routers look for
the past state that most closely closely matches their current state (e.g., load). They then
assign an "estimated" utility value to each potential routing decision and select the action
with the highest estimated utility value. We call this algorithm an MB COIN5 .

4.1 Model Description
To apply the COIN formalism to a network routing model, we must formally describe
that as a set of deterministically evolving vectors  ;t . In the model used in this paper, at
any time step all traÆc at a router is a set of pairs of integer-valued traÆc amounts and
associated ultimate destination tags. At each such time step t, each router r sums the
integer-valued components of its current traÆc at that time step (one component for each
5. Relatively minor details of the algorithm concerning exploration/exploitation issues along with a \steering" parameter are discussed at the end of this section.

368

Collective Intelligence, Data Routing and Braess' Paradox
ultimate destination) to get its instantaneous load. We write that load as:
zr (t)



X
d

xr;d (t);

where the index d runs over ultimate destinations, and xr;d (t) is the total traÆc at time
going from r towards d. After its instantaneous load at time t is evaluated, the router
sends all its traÆc to the next downstream routers, in a manner governed by the underlying
routing algorithm. We indicate such \next routers" by writing:
t

xr;d (t)

=

X
r0

xr;d;r0 (t);

where r0 is the next router for traÆc (r; d), i.e., the rst stop on the path to be followed
from router r to ultimate destination d. After all such routed traÆc goes to those next
downstream routers, the cycle repeats itself, until all traÆc reaches its destinations.
In our simulations, for simplicity, traÆc was only introduced into the system (at the
source routers) at the beginning of successive disjoint waves of L consecutive time steps
each6 . We use (t) to indicate either the integer-valued wave number associated with time
t or the set of all times in that wave, as the context indicates.
In a real network, the cost of traversing a router depends on \after-eects" of recent
instantaneous loads, as well as the current instantaneous load. To simulate this eect, we
use time-averaged values of the load at a router rather than instantaneous load to determine
the cost a packet incurs in traversing that router. More formally, we dene the router's
windowed load, Zr (t), as the running average of that router's load value over a window
of the previous W timesteps (W is always set to an integer multiple of L):
Zr (t)

 W1

t
X
t0 =t W +1

zr (t0 )

=

X
d

Xr;d (t);

where the value of Xr;d (t) is set by
Xr;d (t)

=

1

t
X

W 0
t =t W +1

xr;d (t0 )):

Intuitively, for large enough W , using such a window to determine costs across routers
means that typically those costs will only change substantially over time scales signicantly
larger than that of the individual routing decisions. Formally, the windowed load is the
argument to a load-to-cost function, V (), which provides the cost accrued at time t by
each packet traversing the router at this timestep. That is, at time t, the cost for each
packet to traverse router r is given by V (Zr (t))7 . Note that in our model, the costs are
accrued at the routers, not the links. Also note that for simplicity we do not physically
instantiate the cost as a temporal delay in crossing a router. Dierent routers have dierent
6. L was always chosen to be the minimal number necessary for all traÆc to reach its destination before
the next wave of traÆc is initiated.
7. We also introduce \dummy routers" denoted by V0 () = 0 which help in translating the mathematics
into the simulations. Omitting them will have no eect on the simulations.

369

Wolpert & Tumer
V (), to reect the fact that real networks have dierences in router software and hardware
(response time, queue length, processing speed etc). For simplicity, W is the same for all
routers however. With these denitions, world utility is given by
G( )

=
=

X
t;r
X
t;r;d

=

X
t;r;d

=

X
t;r;d

zr (t) Vr (Zr (t))
xr;d (t)Vr (Zr (t))
0

xr;d (t)Vr @
xr;d (t)Vr

1

t
X

X

W 0
t =t W +1 d0

X
d0

1

xr;d0 (t0 )A

!

Xr;d0 (t)

(2)

:

Our equation for G explicitly demonstrates
that, as claimed above, in our representation
P
we can express G( ) as a sum of rewards, t Rt ( ;t ), where R( ;t ) can be written as function
of a pair of (r; d)-indexed vectors:
Rt (xr;d (t); Xr;d (t))

=

X
r;d

xr;d (t)Vr

X
d0

!

Xr;d0 (t)

:

Also as claimed, the Rt are temporal translations of one another.
Given this model, some of the components of  ;t must be identied with the values
xr;d;r0 (t) 8 r; d; r 0 and t, since those x's are set by the actions the agents will take. Since all
arguments of G must be components of  , we also include the Xr;d (t) 8r; d; t as components
of  ;t . Formally, for routing based on ML agents, the internal parameters of the ML agents
must also be included in  . This is because those parameters aect the routing, and in
turn are aected by it. So to have  evolve deterministically, since it includes the routing
variables, it must also contain internal parameters of the agents. We won't have any need
to explicitly delineate such variables here however, and will mostly phrase the discussion as
though there were no such internal parameters.
Now the values fxr;d;r0 (t 1)g 8r; d; r0 specify the values fxr;d (t)g 8r; d directly. Therefore, in concert with the fxr;d (t0 < t)g, they also set the fXr;d (t)g directly. Moreover in our
simulations the decisions fxr;d;r0 (t)g 8r; d; r0 xed by the routing
algorithms at all times t
P
are given by a xed function of the fxr;d (t)g and the fZr (t) = d0 Xr;d0 (t)g. So in point of
fact we can map the set of fxr;d;r0 (t 1); Xr;d0 (t)g 8r; d; r0 to the full set fxr;d;r0 (t)g 8r; d; r0 ,
not just to fxr;d (t)g. Accordingly, the xr;d;r0 undergo deterministic evolution. Since their
values across time set all the values of the Xr;d (t) across time, we see that the entire set of
the components of  ;t undergo deterministic evolution in this representation, as required.
For evaluating the wonderful life utility we will need to group the components of  ;t
into disjoint agents . Here we will have two types of agent, both types being indexed by
router-destination pairs. For each such agent index (r; d), the rst agent type is the variable
Xr;d (t), and the second agent type is the Euclidean vector with components indexed by r 0 ,
(xr;d )r0 (t). In setting \actions" we are concerned with setting the states of the agents of
the second type. Accordingly, our learners will all be associated with agents of this second
370

Collective Intelligence, Data Routing and Braess' Paradox
type. Unless explicitly indicated otherwise, from now on we will implicitly have that second
type of agent in mind whenever we refer to a \agent" or use the symbol .

4.2 ISPA Routing and COIN Routing
Based on the COIN formalism presented in Section 3 and the model described above, we
now present the ISPA and COIN-based routing algorithms. At time step t, ISPA has access
to all the windowed loads at time step t 1 (i.e., it has access to Zr (t 1) 8r), and assumes
that those values will remain the same at all times  t. Note that for large window sizes
and times close to t, this assumption is arbitrarily accurate. Using this assumption, in
ISPA, each router sends packets along the path that it calculates will minimize the costs
accumulated by its packets.
The COIN-based routing algorithms, in contrast, do not have such direct access to the
Zr . So to evaluate the WLU for a agent (r; d) at any time  , such an algorithm must
estimate the (primary members of the) associated eect set. This means determining what
components of  ; will, under the dynamics of the system, be changed by altering any of the
components of the vector xr;d( ).
As a rst approximation, we will ignore eects on traÆc that changing xr;d;r0 ( ) may
have that are \mediated" by the learning algorithms running in the system. That is, we
ignore changes that arise due to the the eects that changing xr;d;r0 ( ) has on rewards,
changes which induce changes in future training sets, which then in turn get mapped to
changes in the fxr;d;r0 (t)g (and therefore the fXr;d (t)g) via the learning algorithms running
on the agents.
As another approximation, we will ignore eects mediated by the routing algorithms'
observations of the state of the network. That is, we ignore changes in the fxr00 ;d0 ;r000 (t)g that
varying xr;d ( ) may cause due to associated changes in the state of the network perceived by
(r00 ; d0 )'s routing algorithm, changes that in turn cause that algorithm to modify its routing
decisions accordingly. We only consider the behavior of those routing algorithms that are
(potentially) directly aected by xr;d ( ) in that they (potentially) have to route packets
that, at time  , passed through r on the way to d. So in particular we ignore eects of
xr;d ( ) on the fxr00 ;d0 =
6 d;r000 (t)g.
Since all packets routed in a wave arrive at their destinations by the end of the wave,
these approximations mean that the only xr00 ;d00 ;r000 (t) that are in our estimate for xr;d ( )'s
eect set have t in the same wave as  . These are the only ones that are, potentially, directly
aected by the fxr;d;r0 (t)g by \chaining together" the sequence of xr00 ;d00 ;r000 (t) that get the
packets in xr;d (t) to their ultimate destination. Due to the wave nature of our simulations
though, the only xr00 ;d00 ;r000 (t) within  's wave that are aected by xr;d ( ) all have d00 = d.
For reasons of coding simplicity, we do not concern ourselves with whether t <  within a
given wave and then exclude some xr00 ;d00 ;r000 (t) accordingly. In other words, all t within  's
wave are treated equally.
So one set of members of xr;d ( )'s eect set is fxr00 ;d;r000 (t) 8r00; d; r000 ; t 2 ( )g. Note
that some of these members will be relatively unaected by xr;d ( ) (e.g., those with r00 far
in the net away from r). Again for simplicity, we do not try to determine these and exclude
them. As with keeping the xr00 ;d;r000 (t <  ), this inclusion of extra agents in our estimate of
the eect set should hurt learnability, but in general should not hurt factoredness. Therefore
371

Wolpert & Tumer
it should delay how quickly the learners determine their optimal policies, but it won't aect
the quality (for G) of those policies nally arrived at. Note also that trying to determine
whether some particular xr00 ;d;r000 (t 2 ( )) should be included in xr;d ( )'s eect set would
mean, in part, determining whether packets routed from (r; d) would have reached r00 if
(r; d) had made some routing decision dierent from the one it actually made. This would
be a non-trivial exercise, in general.
In contrast to the case with the xr00 ;d0 ;r000 (t), there are Xr00 ;d0 (t) with t in the future of  's
wave that both are aected by xr;d (t) and also are not excluded by any of our approximations
so far. In particular, the Xr00 ;d (t) with either r00 = r or r00 one hop away from r will be
1
directly aected by xr;d (t), for t 2 [W
i=0 ( + iL)) (cf. the denition of the X variables).
For simplicity, we restrict consideration of such Xr00 ;d variables to those with the same router
as r, r00 = r.
This nal estimate for the eect set is clearly rather poor | presumably results better
than those presented below would accrue to use of a more accurate eect set. However it's
worth bearing in mind that there is a \self-stabilizing" nature to the choice of eect sets,
when used in conjunction with eect set WLU's. This nature is mediated by the learning
algorithms. If one assigns the same utility function to two agents, then the reward one
agent gets will be determined in part by what the other one does. So as it modies its
behavior to try to increase its reward, that rst agent will be modifying its behavior in a
way dependent on what the other agent does. In other words, if two agents are given the
same WLU because they are estimated to be in each other's eect set, then ipso facto they
will be in each other's eect set.
Using our estimate for the eect set, the WLU for (;  ) is given by the dierence
between the total cost accrued in  's wave by all agents in the network and the cost accrued
by agents when all agents sharing 's destination are \erased." More precisely, any agent 
that has a destination d will have the following eect set WLU's, g; :
g; ( )=

=

G( )
X
t;r0 ;d0


=

G(CLC eff ( ))
(; )

xr0 ;d0 (t) Vr0
Vr0

X
d00

X
d0

!

X 

Xr0 ;d0 (t)

[ Xr0 ;d00 (t) (1

t;r0 ;d0

I (t

2[

xr0 ;d0 (t)(1

W 1
i=0 (

I (t

2 ( ))I (d0 = d))

+ iL))I (d00 = d)) ]

!

0
1
X
X
X
X
@
xr0 ;d0 (t) Vr0 (
Xr0 ;d00 (t))
xr0 ;d0 (t) Vr0 (
Xr0 ;d00 (t))A
d0
d00
d0 6=d
d00 6=d
t2( ) r0
0
1
X
X X
X
X
@
+
xr0 ;d0 (t) [Vr0 (
Xr0 ;d00 (t)) Vr0 (
Xr0 ;d00 (t))]A
(3)
0
0
00
00
W
1
r
d
d
d
=
6
d
t2[
( +iL)
X X

i=1

where I (:) is the indicator function that equals 1 if its argument is true, 0 otherwise.
To allow the learner to receive feedback concerning its actions in a wave immediately
following that wave rather than wait for  W L time steps, we will approximate the second
sum in that last equality, the one over times following  's wave, as zero. There is another
way we can view the resultant expression, rather than as an approximation to the eect
372

Collective Intelligence, Data Routing and Braess' Paradox
set WLU. That is to view it as the exact WLU of an approximation to the eect set, an
approximation which ignores eects on future windowed loads of clamping a current traÆc
level. Regardless of what view we adopt, presumably better performance could be achieved
if we did not implement this approximation.
Given this approximation, our WLU becomes a wave-indexed time-translation-invariant
WL \reward function" (WLR):
g; ( ;t2( ) )

X

X

t2( );r0

d0

=

X
d0 6=d

xr0 ;d0 (t) Vr0 (

xr0 ;d0 (t) Vr0 (

X
d00

X

d00 6=d

Xr0 ;d00 (t))
1

Xr0 ;d00 (t))A :

(4)

Notice that traÆc going from a router r0 6= r to a destination d0 6= d aects the value of
the WLR for agent (r; d). This reects the fact that WLR takes into account side-eects
of (r; d)'s actions on other agents. Note also that each r0 -indexed term contributing to the
WLR can be computed by the associated router r0 separately, from information available
to that router. Subsequently those terms can be propagated through the network to , in
much the same way as routing tables updates are propagated.
Given this choice of private utility, we must next specify how the COIN-based routing
algorithm collects the initial data that (in conjunction with this utility) is to be used to
guide the initial routing decisions that every agent with more than one routing option must
make. In our experiments that data was collected during a preliminary running of an ISPA.
In this preliminary stage, the routing decisions are made using the ISPA, but the resulting
actions are \scored" using the WLR given by Equation 3. We use the ISPA to generate the
routing decisions in the initial data since it is likely in practice that some kind of SPA will
be the routing algorithm running prior to \turning on" the COIN algorithm. Alternately
one can generate the initial data's routing decisions by having the routers make random
decisions, or by having them implement a sequence of decisions that \sweeps" across a grid
through the possible set of actions. The data collected in this stage provides us with initial
input-output training sets to be used by the machine learning algorithm on each agent: for
each router-destination agent, inputs are identied with windowed loads on outgoing links,
and the associated WLR values for the destination in question are the outputs.
After suÆcient initial data is collected using the ISPA, the system switches to using
the COIN algorithm to make subsequent routing decisions. In this stage, each agent routes
packets along the link that it estimates (based on the training set) would provide the best
WLR. To perform the estimation, the MB COIN makes use of a single-nearest-neighbor
algorithm as its learner. This algorithm simply guesses that the output that would ensue
from any candidate input is the same as the output of the element of the training set
that is the nearest neighbor (in input space) of that candidate input.8 In other words, the
learner nds the training set input-output pair whose input value (loads on outgoing links)
8. This is a very simple learning algorithm, and we use it here only to demonstrate the potential practical
feasibility of a COIN-based routing algorithm. The performance can presumably be improved if more
sophisticated learning algorithms (e.g., Q-learning Sutton & Barto, 1998; Watkins & Dayan, 1992) are
used.

373

Wolpert & Tumer
is closest to that which would result from each potential routing decision. Then the learner
assigns the WLR associated with that training data pair as the estimate for what WLR
would result from said routing decision. These WLR values are then used to choose among
those potential routing decisions. The input-output data generated under this algorithm is
adding to the training set as it is generated.
In this routing algorithm, the routers only estimate how their routing decisions (as
reected in their loads at individual time steps) will aect their WLR values (based on
many agents' loads). It is also possible to calculate exactly how the routing decisions aect
the routers' WLR's if, unlike the MB COIN, we had full knowledge of the loads of all
agents in the system. In a way similar to ISPA, for each router we can evaluate the exact
WLR value that would ensue from each of its candidate actions, under the assumption
that windowed loads on all other routers are the same one wave into the future as they are
now. We call this algorithm for directly maximizing WLR (an algorithm we call the full
knowledge COIN, or FK COIN).
Note that under the assumption behind the FK COIN, the action  chooses in wave ( )
that maximizes WLR will also maximize the world reward. In other words, WL reward is
perfectly factored with respect to (wave-indexed) world reward, even though the associated
utilities are not related that way (due to inaccuracy in our estimate of the eect set). Due
to this factoredness, the FK COIN is equivalent to load balancing on world rewards. Since
LB in general results in inferior performance compared to LB over time, and since the FK
COIN is equivalent to LB, one might expect that its performance is suboptimal. Intuitively,
this suboptimality reects the fact that one should not choose the action only with regard
to its eect on current reward, but also with concern for the reward of future waves. In the
language of the COIN framework, this suboptimality can be viewed as a restatement of the
fact that for our inexactly estimated eect set, the system will not be perfectly factored.
The learning algorithm of the MB COIN as described is extraordinarily crude. In addition, the associated scheme for choosing an action is purely exploitative, with no exploration
whatsoever. Rather than choose some particular more sophisticated scheme and tune it to
t our simulations, we emulated using more sophisticated algorithms in general. We did
this by modifying the MB COIN algorithm to occasionally have the FK COIN determine
a router's action rather than the purely greedy learner outlined above. The steering parameter discussed in Section 5.5 determines how often the routing decision is based on the
MB COIN as opposed to the FK COIN.
5. Simulation Results

In practice, it is very diÆcult to implement either FK COIN or LB. In this section we use
experiments to investigate behavior of algorithms that can conceivably be used in practice.
More precisely, based on the model and routing algorithms discussed above, we have performed simulations to compare the performance of ISPA and MB COIN across a variety of
networks, varying in size from ve to eighteen routers. In all cases traÆc was inserted into
the network in a regular, non-stochastic manner at the sources. The results we report are
averaged over 20 runs. We do not report error bars as they are all lower than 0:05.
In Sections 5.1 - 5.4 we analyze traÆc patterns over four networks where ISPA suers
from the Braess' paradox. In contrast, the MB COIN almost never falls prey to the paradox
374

Collective Intelligence, Data Routing and Braess' Paradox
for those networks (or for no networks we have investigated is the MB COIN signicantly
susceptible to Braess' paradox). Then in Section 5.5 we discuss the eect on the MB
COIN's performance of the \steering" parameter which determines the intelligence of the
MB COIN.9

5.1 Bootes Network
The rst network type we investigate is shown in Figure 3. It is in many senses a trivial
network, as in Net A, the sources do not even have any choices to make. The loads introduced at the sources do not change in time and are listed in Tables 1 and 2, along with the
performances of our algorithms.

y
@D@

V1

@
@@yV2
y
@@
AA
@y@V0
AyV0
AAy
@yS1
S2

y@D
@

V1

@@
y
@yV2
@@
AA
yV3 AyV0
@yV0
@@y
A
S1
S2 Ay

Net A

Net B
Figure 3: Bootes Network

Loads at (S1 ; S2 ) Net
1,1
A
B
2,1
A
B
2,2
A
B
4,2
A
B

ISPA MB COIN
6.35
6.35
8.35
5.93
8.07
8.07
10.40
7.88
9.55
9.55
10.88
9.71
10.41
10.41
11.55
10.41

Table 1: Average Per Packet Cost for BOOTES2 networks for V1 = 10 + log(1 + x) ;
4x2 ; V3 = log(1 + x) .

V2

=

The MB COIN results are identical to the ISPA results in the absence of the additional
link (Network A). However, Braess' paradox arises with ISPA, in that the addition of the
new link in network B degrades the performance of the ISPA in six of the eight traÆc
regimes and load-to-cost functions investigated. The MB COIN on the other hand is only
9. In Sections 5.1 - 5.4, the steering parameter is set at 0.5.

375

Wolpert & Tumer

Loads at (S1 ; S2 ) Net ISPA MB COIN
1,1
A 30.35
30.35
B 20.35
20.35
2,2
A 35.55
35.55
B 40.55
34.99
4,2
A 41.07
41.07
B 50.47
44.13
6,3
A 44.63
44.63
B 51.40
44.63
Table 2: Average Per Packet Cost for BOOTES4 network for
10x ; V3 = log(1 + x) .

V1

= 50 + log(1 + x) ;

V2

=

hurt by the addition of the new link once, and manages to gainfully exploit it seven times.
When their behavior is analyzed innitesimally, the MB COIN either uses the additional
link eÆciently or chooses to ignore it in those seven cases. Moreover, the MB COIN's
performance with the additional link is always better than the ISPA's. For example, adding
the new link causes a degradation of the performance by as much as 30 % (loads = f2; 1g)
for the ISPA, whereas for the same load vector MB COIN performance improves by 7 %.

5.2 Hex Network
In this section we revisit the network rst discussed in Section 2.1 (redrawn in Figure 4 to
include the dummy agents). In Table 3 we give full results for the load-to-delay functions
discussed in that section. We then use load-to-cost functions which are qualitatively similar
to those discussed in Section 2.1, but which incorporate non-linearities that better represent
real router characteristics. That load-to-cost function and associated results are reported
in Table 4.

V2
V0
V1

"y
bDb
"
"
bb
y"
"
byV1
y
yV0
y
bb
"yV2
"
bb ""
b"
yS
Net A

V2
V0
V1

"ybDb
"
"
bb
"y"
byV1

y Vy3  yV0
yb
"yV2
bb
"
bb"yS""

Figure 4: Hex network

Net B

This network demonstrates that while the addition of a new link may be benecial in
low traÆc cases, it leads to bottlenecks in higher traÆc regimes. For ISPA although the
376

Collective Intelligence, Data Routing and Braess' Paradox
per packet cost for loads of 1 and 2 drop drastically when the new link is added, the per
packet cost increases for higher loads. The MB COIN on the other hand uses the new
link eÆciently. Notice that the MB COIN's performance is slightly worse than that of the
ISPA in the absence of the additional link. This is caused by the MB COIN having to use
a learner to estimate the WLU values for potential actions whereas the ISPA simply has
direct access to all the information it needs (costs at each link).
Load Net ISPA MB COIN
1
A 55.50
55.56
B 31.00
31.00
2
A 61.00
61.10
B 52.00
51.69
3
A 66.50
66.65
B 73.00
64.45
4
A 72.00
72.25
B 87.37
73.41
Table 3: Average Per Packet Cost for HEX network for V1 = 50+ x ;
.

V2

= 10x ;

V3

= 10+ x

Load Net ISPA MB COIN
1
A 55.41
55.44
B 20.69
20.69
2
A 60.69
60.80
B 41.10
41.10
3
A 65.92
66.10
B 61.39
59.19
4
A 71.10
71.41
B 81.61
69.88
Table 4: Average Per Packet Cost for HEX network for
10x ; V3 = log(1 + x) .

V1

= 50 + log(1 + x) ;

V2

=

5.3 Buttery Network
The next network we investigate is shown in Figure 5. It is an extension to the simple
network discussed in Section 5.1. We now have doubled the size of the network and have
three sources that have to route their packets to two destinations (packets originating at
S1 go to D1 , and packets originating at S2 or S3 go to D2 ). Initially the two halves of the
network have minimal contact, but with the addition of the extra link two sources from the
two two halves of the network share a common router on their potential shortest path.
377

Wolpert & Tumer

y

 TT

yD2

 TT
 T  T

TTy
TTy
y
V1 
V2
T
T
 V3
T
T yV1
V0 Ty
V0 Ty
T
T  @@
y @yS3
S1 Ty
S2 T
D1

y

 TT

yD2

 TT
 T  T

TTy
TTy
y
V1 
V2
T
T
 V3
T
 T
V0 Ty V3 y V0 Ty
y@V1
T 
T @
y S2 Ty @yS3
S1 T
D1

Net A

Net B
Figure 5: Buttery Network

Table 5 presents two sets of results: rst we present results for uniform traÆc through
all three sources, and then results for asymmetric traÆc. For the rst case, the Braess'
paradox is apparent in the ISPA: adding the new link is benecial for the network at low
load levels where the average per packet cost is reduced by nearly 20%, but deleterious at
higher levels. The MB COIN, on the other hand, provides the benets of the added link
for the low traÆc levels, without suering from deleterious eects at higher load levels.
Loads (S1 ; S2 ; S3 ) Net ISPA MB COIN
1,1,1
A 112.1
112.7
B
92.1
92.3
2,2,2
A 123.3
124.0
B 133.3
122.5
4,4,4
A 144.8
142.6
B 156.5
142.3
3,2,1
A
81.8
82.5
B
99.5
81.0
6,4,2
A
96.0
94.1
B 105.3
94.0
9,6,3
A 105.5
98.2
B 106.7
98.8
Table 5: Average Per Packet Cost for BUTTERFLY network for V1 = 50+ log(1+ x) ;
10x ; V3 = log(1 + x).

V2

=

For the asymmetric traÆc patterns, the added link causes a drop in performance for the
ISPA, especially for low overall traÆc levels. This is not true for the MB COIN. Notice also
that in the high, asymmetric traÆc regime, the ISPA performs signicantly worse than the
MB COIN even without the added link, showing that a bottleneck occurs on the right side
of network alone (similar to the Braess' paradox observed in Section 5.1).
378

Collective Intelligence, Data Routing and Braess' Paradox
5.4 Ray Network
In all the networks and traÆc regimes discussed so far the sources are the only routers with
more than one routing option. The nal network we investigate is a larger network where
the number of routers with multiply options is signicantly higher than in the previous
networks. Figure 6 shows the initial network (Net A) and the \augmented" network (Net
B), where new links have been added. The original network has relatively few choices for
the routers, as packets are directed toward their destinations along \conduits." The new
links are added in the augmented networks to provide new choices (crossing patterns) that
could be benecial if certain of the original conduits experience large costs.

V2
V0
V1

bDb1 ""y
bDb2
"y
"
"
b"
b
y" V1 y"" bbyV1 bbyV2
"
y V0 y
yV0
yV0
yV
yV
y V2 y
JJ 


JJ 2 

 1
J 

J 

J%
yV3
V3 J
e
y
ee
%
%
e
y
y
%
S1
S2
Net A

V2
V0
V1

"ybDb1 ""ybDb2
"
"
"b
b
"yc" V1 "y" bbyV1 b#byV2
yVc3 cy yV0 V0 y #y#V3 yV0
y Vc2cyc ##yV#2
yV
JJ 

 c # JJ 

 1
J 
 #c#c J 

V3 J
e
ye #yV3 V3cy %J%
yV3
%
e
y
%
e
y
S2
S1

Figure 6: Ray network

Net B

Table 6 shows the simulation results for these networks (S1 and S2 send packets to D1
and D2 respectively). At low load levels both the ISPA and the MB COIN use the new links
eectively, although the MB COIN performs slightly worse. This is mainly caused by the
diÆculty encountered by the simple learner (single nearest neighbor algorithm) in quickly
learning the traÆc patterns in this large network. Unlike the ISPA however, the MB COIN
avoids the Braess' paradox in all cases except the very high traÆc regime. Moreover, even
there, the eect is signicantly milder than that encountered by the ISPA.

5.5 Steering the MB COIN
The nal aspect of COIN-based routing we investigate is the impact of the choice for the
value of the steering parameter. This parameter both controls the amount of exploration
the algorithm performs and determines the \intelligence" of the MB COIN at estimating
the surface directly calculated by the FK COIN. In Figures 7 - 8, the FK COIN results
correspond to setting the steering parameter of the MB COIN to 1:0. This provides an
upper bound on the performance that can be achieved though MB COIN.
For the HEX network (Figure 7), the performance at the worst setting for the MB COIN,
which corresponds to no steering, is comparable to ISPA. In contrast, with moderate steering
379

Wolpert & Tumer

Loads at S1 andS2 ) Net ISPA MB COIN
2,2
A 143.6
143.7
B 124.4
126.9
3,3
A 154.6
154.9
B 165.5
151.0
4,4
A 165.4
166.0
B 197.7
165.6
6,6
A 186.7
187.4
B 205.1
191.6
Table 6: Average Per Packet Cost for RAY network for
10x ; V3 = 10 + log(1 + x).

= 50 + log(1 + x) ;

V2

=

180

80

Per Packet Delay

Per Packet Delay

85

V1

ISPA
FK COIN
MB COIN

75
70
65

ISPA
FK COIN
MB COIN

170
160
150
140

0

0.1 0.2 0.3 0.4
Steering Parameter

0.5

0

0.1 0.2 0.3 0.4
Steering Parameter

0.5

Figure 7: Impact of steering on Hex4 (left) and Ray4 (right) networks.
(0.5) the results are similar to that of the FK COIN, as the learner has more information
to work with (arising from the extra parts of the input space represented in the training
set due to the occasional use of the FK COIN), it bridges the gap between a suboptimal
algorithm susceptible to Braess' paradox and one which eÆciently avoids that paradox.
For the RAY network (Figure 7), the value of the steering parameter is more critical.
With no steering at all, the MB COIN performs poorly in this network | even worse than
ISPA. This is not surprising in that because there are many routing choices that aect
the performance, the simple memory-based learner needs proper \seeding" to be able to
perform well. Even with minimal steering though, the MB COIN quickly outperforms the
ISPA.
Finally, for both the Buttery and Bootes networks (Figure 8) the MB COIN needs
very little steering to perform well. Although for the Buttery network the performance of
MB COIN improves slightly with more information, it is signicantly better than the ISPA
across the board.
380

105

Per Packet Delay

Per Packet Delay

Collective Intelligence, Data Routing and Braess' Paradox

ISPA
FK COIN
MB COIN

100

95

40
ISPA
FK COIN
MB COIN
35

90
0

0.1 0.2 0.3 0.4
Steering Parameter

0.5

0

0.1 0.2 0.3 0.4
Steering Parameter

0.5

Figure 8: Impact of steering on Buttery4 (left) and Bootes4 (right) networks.
6. Conclusion

Eective routing in a network is a fundamental problem in many elds, including data
communications and transportation. Using a shortest path algorithm (SPA) on each of the
routers to determine that router's decisions is a popular approach to this problem. However
under certain circumstances it suers from a number of undesirable eects. One such eect is
Braess' paradox, where for the same pattern of introduced traÆc into a network, increasing
the capacity of that network results in lower overall throughput, due to the harmful sideeects of the decisions made by each router on the traÆc in the rest of the system. Even
the theoretical load-balancing algorithm, which addresses some of these eects to produce
decisions that are optimal for any single moment of time, can still suer from side-eects
that result in sub-optimal performance. This is because such eects extend across time
(i.e., what you do now aects performance later) as well as space.
The Collective Intelligence approach is a novel way of controlling distributed systems so
as to avoid deleterious side-eects of routing decisions. The central idea is to have learning
algorithms control the autonomous agents that constitute the overall distributed system.
In such a Collective Intelligence (COIN), the central issue is to determine the personal
objectives to be assigned to each of those autonomous agents. One wants to choose those
goals so that the greedy pursuit of those goals by the associated learning algorithms leads to
desirable behavior of the overall system. In this paper we have summarized the mathematics
of designing such goals and derived a routing algorithm based on that mathematics.
We ran computer simulations to compare a COIN-based algorithm with an ideal SPA
(whose performance upper-bounds all real-world SPA's) for routing. The COIN-based algorithm was severely handicapped. The estimation of the \eect sets" used by that algorithm
was exceedingly crude. In addition, the learning algorithms of the agents were particularly
unsophisticated, and therefore were not able to eectively maximize their individual performances. In contrast, the ideal SPA had access to more information concerning the state of
the system than the (real-world-implementable) COIN did, information that no real-world
SPA could access.
381

Wolpert & Tumer
Despite these biases in favor of the ideal SPA, in our experiments the ideal SPA induced
average costs as much as 32 % higher than the COIN-based algorithm. Furthermore the
COIN-based algorithm almost always avoided the Braess' paradox that seriously diminished
the performance of the SPA.
These techniques have also been very successfully employed in many other, non-routing
domains, such as coordination of autonomous rovers (Tumer, Agogino, & Wolpert, 2002),
combinatorial optimization, \congestion games" (Wolpert & Tumer, 2001), and control of
data-upload from a planet (Wolpert, Sill, & Tumer, 2001). We conclude from these results
that the techniques of the eld of collective intelligence can be highly eective in designing
the utility functions of the members of a MAS to ensure they work in a coordinated and
eÆcient manner to optimize overall performance. We are currently investigating extensions
of our COIN algorithm that involve novel goals for the agents, goals that are more \learnable" for the learning algorithms. We are also expanding the simulations to larger networks
using a commercial event driven simulator. Future work will focus on not making the approximation that current traÆc levels do not aect future windowed loads (Equation 3).
It will also involve investigating better estimates of eect sets, in particular not including
all agents with the same destination in one's eect set, and more generally using a more
\ne-grained" representation of the agents, for example including each packet's originating
source, to allow a more ne-grained eect set (and resultant WLU).
Acknowledgments

The authors thank Joe Sill and the reviewers for their helpful comments.
Appendix A. Suboptimality of Load-Balancing

In this appendix we we present an existence proof of the suboptimality of Load-Balancing
(LB) by explicitly constructing a situation where conventional LB is suboptimal.
Consider a system with discrete time, in which the source agent X under consideration
must route one packet to the (xed) destination at each time step. Presume further that
no traÆc from any source agent other than X enters any of the agents X sends to, so that
traÆc coming from X is the sole source of any costs associated with X 's outbound links. Let
S (t) be the number of times our agent sent a packet down some link A in the W time steps
preceding t, and take s(t) = A; B to mean that the router uses link A or B , respectively, at
time t. Model queue backups and the like by having the cost to send a packet down link
A at time t be CA (S (t)=W ), and have the cost for our router to instead send the packet
down link B be CB (1 S (t)=W ), For simplicity we assume that both CA (:) and CB (:) are
monotonically increasing functions of their arguments.
Restrict attention to agents that work by having s(t) = A i S (t)  k for some realvalued threshold k. The LB algorithm will choose s(t) = A i CA (S (t)=W )  CB (1
S (t)=W ). So the LB algorithm's behavior is indistinguishable from this kind of threshold
algorithm, with k set so that CA (k=W ) = CB (1 k=W ). (We implicitly assume that CA (:)
and CB (:) are chosen so that such a solution exists for 1 < k < W 1.) The question is
382

Collective Intelligence, Data Routing and Braess' Paradox
what k should be to optimize total averaged cost across time, and in particular if that k is
the same as kLB , the k that LB uses.
Now as we go from one time step to the next, the routing decision made W time steps
ago drops out of the computation of S (t), while the routing decision just made is newly
included. In general, S (t + 1) = S (t) + 1 if the router just used A at time t and used link B
at the time W time steps into the past. On the other hand, S (t + 1) = S (t) 1 if the router
just used B and used A W time steps ago, while S (t + 1) = S (t) if the routing decision just
made is the same as the routing decision W time steps ago. So in general, S (t) can only
change by -1, 0, or +1 as we go from one time step to the next.
Consider cases where 1 < k < W 1, so that eventually the router must choose an A,
and at some subsequent time t the router switches from A to B . At that time s(t 1) = A
and s(t ) = B . This implies that S (t 1)  k; S (t ) > k. Dene the value S (t 1) as k .
Note that S (t ) = k + 1, and k 1 < k  k.
Now for any time t0 , if S (t0 ) = k + 1, s(t0 + 1) = B , and the only possible next values
are S (t0 + 1) = k or S (t0 + 1) = k + 1, depending on the old decision s(t W ) that gets
dropped out of the window. Similarly, if S (t0 ) = k , s(t0 + 1) = A, and the only possible
next values are S (t0 + 1) = k or S (t0 + 1) = k + 1, again depending on the old decision
being dropped. So we see that once S (t0 ) 2 fk ; k + 1g, it stays there forever.
This means that because of the relationship between k and k , in any interval of W
consecutive time steps subsequent to t , the number of packets sent along A by router X
must be 2 (k 1; k +1]. (Note that it is possible to send k +1 packets along A, but not k 1
packets. Therefore the number sent along B must be 2 [W (k + 1); W (k 1)). Each
time that a packet is sent along A the cost incurred is the cost of link A with average traÆc
level S (t)=W , CA (S (t)=W ). Similarly, each time the link B is chosen, the cost incurred is
CB (1 S (t)=W ). Since S (t) 2 fk  ; k  + 1g, and both CA (:) and CB (:) are monotonically
increasing, the cost for sending the packet down link A 2 (CA ((k 1)=W ); CA ((k + 1)=W ],
and that for sending it down link B is contained in [CB (1 (k +1)=W ); CB (1 (k 1)=W )).
Now we know that the choice of A must have average frequency (across all time) between

k =W and (k  + 1)=W . Similarly, B will have average frequency between (1 (k  + 1)=W )
and 1 k =W . Accordingly, the average cost is bounded above by






k+1
k
k 1
k + 1
CA
+ 1
CB 1
;
(5)
W

W

W

W

where the rst term provides the maximum possible average cost for using link A, while
the second term independently provides the maximum possible average cost for using link
B . Note that the actual cost will be lower since the two frequencies in this bound, one for
A and one for B , cannot both have the values indicated. Because k 1 < k   k and since
+1 , our upper bound is itself bounded above by
1 kW1 = 1 + W2 kW
k+1
W



CA

k+1
W



+



1+

2

k+1

W

W





CB

1+

2

k+1

W

W



:

(6)

The optimal k will result in an average cost lower than the minimum over all k of the
upper bound on average cost, given in Equation 6. So the average cost for the optimal
k is bounded above by the minimum over k of this upper bound. Lable this argmin of
Equation 6 k'.
383

Wolpert & Tumer
Since other values of k besides kLB result in behavior equivalent to LB, it does not
suÆce to simply test if k' = kLB . Instead let us evaluate some lower bounds in a similar
fashion to how we evaluated upper bounds. Using the average frequencies discussed above,
the average cost is bounded below by:






k 1
1
k
k+1
k
CA
+ 1
CB 1
;
(7)
W

W

W

W

W

where the rst term provides the minimum possible average cost for using link A, while the
second term provides the minimum possible average cost for using link B . Again, because
k 1 < k   k , the term is Equation 7 is further bounded below by
1

k
W



CA

1

k



W

+



1

2
W

1

k
W





CB

1

2

1

k

W



In particular this bound holds for the average cost of the LB algorithm:





kLB 1
kLB 1
2 kLB 1
2 kLB
CA
+ 1
CB 1
W

W

W

W

W

(8)

:

W

W

1



;

(9)

where as before kLB satises CA (kLB =W ) = CB (1 kLB =W ).
By appropriate choice of CA (:) and CB (:), we can ensure that the lower bound on the
cost with the LB algorithm (Equation 9 evaluated with k = kLB ) is higher than the upper
bound on the average cost incurred by the optimal algorithm (the minimum over k of Equation 6). That is, the best possible average cost achieved by load balancing will be worse
than the worst average cost that could arise through the optimal routing strategy. This
establishes that LB does not engage in optimal routing.

Example: Let CA (x) = x2 and CB (x) = x. Balancing the loads on A and B | setting

2
C
pA (S (t)=W ) = CB (1 S (t)=W ) | results in (S (t)=W ) = 1 S (t)=W , leading to kLB =W =
5 1 = :618. For W = 1000, the associated lower bound on average cost (Equation 9) is
2
(:618)3 + (:998 :618)2 = :380. On the other hand, with CA and CB given as above, Eq 6
k+1 2
is ( k+1 )3 + (1 + 2
) . Dierentiating with respect to k and setting the result to
W

k0
W

W

1
3

W

1

p28+48=W

zero leads to
=
. For a window size of W = 1000, this yields
W +
6
k 0 =W = :548, a dierent result than kLB . Plugging into Equation 6, the upper bound on
the cost with k0 is (:549)3 + (1:002 :549)2 = :371, which is less than :380.
References

Ahuja, R. K., Magnanti, T. L., & Orlin, J. B. (1993). Network Flows. Prentice Hall, New
Jersey.
Bass, T. (1992). Road to ruin. Discover, 13 (5), 56{61.
Bertsekas, D., & Gallager, R. (1992). Data Networks. Prentice Hall, Englewood Clis, NJ.
Bonabeau, E., Henaux, F., Guerin, S., Snyders, D., Kuntz, P., & Theraulaz, G. (1999a).
Routing in telecommunications networks with \smart" and-like agents. (pre-print).
Bonabeau, E., Sobkowski, A., Theraulaz, G., & Deneubourg, J.-L. (1999b). Adaptive task
allocation inspired by a model of division of labor of social insects. (pre-print).
384

Collective Intelligence, Data Routing and Braess' Paradox
Boyan, J. A., & Littman, M. (1994). Packet routing in dynamically changing networks:
A reinforcement learning approach. In Advances in Neural Information Processing
Systems - 6, pp. 671{678. Morgan Kaufman.
Choi, S. P. M., & Yeung., D. Y. (1996). Predictive Q-routing: A memory based reinforcement
learning approach to adaptive traÆc control. In Touretzky, D. S., Mozer, M. C., &
Hasselmo, M. E. (Eds.), Advances in Neural Information Processing Systems - 8, pp.
945{951. MIT Press.
Claus, C., & Boutilier, C. (1998). The dynamics of reinforcement learning cooperative
multiagent systems. In Proceedings of the Fifteenth National Conference on Articial
Intelligence, pp. 746{752, Madison, WI.
Cohen, J. E., & Jeries, C. (1997). Congestion resulting from increased capacity in singleserver queueing networks. IEEE/ACM Transactions on Networking, 5 (2), 305{310.
Cohen, J. E., & Kelly, F. P. (1990). A paradox of congestion in a queuing network. Journal
of Applied Probability, 27, 730{734.
Crowe, B. L. (1969). The tragedy of the commons revisited. Science, 166, 1103{1107.
Deo, N., & Pang, C. (1984). Shortest path algorithms: Taxonomy and annotation. Networks,
14, 275{323.
Dijkstra, E. (1959). A note on two problems in connection with graphs. Numeriche Mathematics, 1 (269-171).
Fudenberg, D., & Tirole, J. (1991). Game Theory. MIT Press, Cambridge, MA.
Glance, N. S. (1993). Dynamics with Expectations. Ph.D. thesis, Stanford University.
Glance, N. S., & Hogg, T. (1995). Dilemmas in computational societies. In Lesser, V.
(Ed.), Proc. of the 1st International Conference on Multi-Agent Systems (ICMAS95),
pp. 117{124, Menlo Park, CA. AAAI Press.
Hardin, G. (1968). The tragedy of the commons. Science, 162, 1243{1248.
Heusse, M., Snyers, D., Guerin, S., & Kuntz, P. (1998). Adaptive agent-driven routing
and load balancing in communication networks. Advances in Complex Systems, 1,
237{254.
Hogg, T. (1995). Social dilemmas in computational ecosystems. In Proceedings of the
Fourteenth International Joint Conference on Articial Intelligence, pp. 711{716, San
Mateo, CA. Morgan Kaufmann.
Hu, J., & Wellman, M. P. (1998a). Multiagent reinforcement learning: Theoretical framework and an algorithm. In Proceedings of the Fifteenth International Conference on
Machine Learning, pp. 242{250.
Hu, J., & Wellman, M. P. (1998b). Online learning about other agents in a dynamic multiagent system. In Proceedings of the Second International Conference on Autonomous
Agents, pp. 239{246.
Huberman, B. A., & Hogg, T. (1988). The behavior of computational ecologies. In The
Ecology of Computation, pp. 77{115. North-Holland.
385

Wolpert & Tumer
Huberman, B. A., & Lukose, R. M. (1997). Social dilemmas and internet congestion. Science,
277 (5325), 535{537.
Huberman, B. A., & Hogg, T. (1993). The emergence of computational ecologies. In Nadel,
L., & Stein, D. (Eds.), 1992 Lectures in Complex Systems, Vol. V of SFI Studies in
the Sciences of Complexity, pp. 185{205. Addison-Wesley, Reading, MA.
Huhns, M. E. (Ed.). (1987). Distributed Articial Intelligence. Pittman, London.
Jennings, N. R., Sycara, K., & Wooldridge, M. (1998). A roadmap of agent research and
development. Autonomous Agents and Multi-Agent Systems, 1, 7{38.
Kaelbing, L. P., Littman, M. L., & Moore, A. W. (1996). Reinforcement learning: A survey.
Journal of Articial Intelligence Research, 4, 237{285.
Kelly, F. P. (1996). Modeling communication networks, present and future. Philosophical
Trends Royal Society of London A, 354, 437{463.
Korilis, Y. A., Lazar, A. A., & Orda, A. (1995). Architecting noncooperative networks.
IEEE Journal on Selected Areas in Communications, 13 (8), 1241{1251.
Korilis, Y. A., Lazar, A. A., & Orda, A. (1997a). Achieving network optima using Stackelberg routing strategies. IEEE/ACM Transactions on Networking, 5 (1), 161{173.
Korilis, Y. A., Lazar, A. A., & Orda, A. (1997b). Capacity allocation under noncooperative
routing. IEEE Transactions on Automatic Control, 42 (3), 309{325.
Korilis, Y. A., Lazar, A. A., & Orda, A. (1999). Avoiding the Braess paradox in noncooperative networks. Journal of Applied Probability, 36, 211{222.
Kumar, S., & Miikkulainen, R. (1997). Dual reinforcement Q-routing: An on-line adaptive
routing algorithm. In Articial Neural Networks in Engineering, Vol. 7, pp. 231{238.
ASME Press.
Littman, M. L., & Boyan, J. (1993). A distributed reinforcement learning scheme for network
routing. In Proceedings of the 1993 International Workshop on Applications of Neural
Networks to Telecommunications, pp. 45{51.
Marbach, P., Mihatsch, O., Schulte, M., & Tsisiklis, J. (1998). Reinforcement learning for
call admission control and routing in integrated service networks. In Advances in
Neural Information Processing Systems - 10, pp. 922{928. MIT Press.
Orda, A., Rom, R., & Shimkin, N. (1993a). Competitive routing in multiuse communication
networks. IEEE/ACM Transactions on Networking, 1 (5), 510{521.
Orda, A., Rom, R., & Sidi, M. (1993b). Minimum delay routing in stochastic networks.
IEEE/ACM Transactions on Networking, 1 (2), 187{198.
Sandholm, T., Larson, K., Anderson, M., Shehory, O., & Tohme, F. (1998). Anytime coalition structure generation with worst case guarantees. In Proceedings of the Fifteenth
National Conference on Articial Intelligence, pp. 46{53.
Sandholm, T., & Lesser, V. R. (1995). Issues in automated negotiations and electronic commerce: extending the contract net protocol. In Proceedings of the Second International
Conference on Multi-Agent Systems, pp. 328{335. AAAI Press.
386

Collective Intelligence, Data Routing and Braess' Paradox
Schaerf, A., Shoham, Y., & Tennenholtz, M. (1995). Adaptive load balancing: A study in
multi-agent learning. Journal of Articial Intelligence Research, 162, 475{500.
Shenker, S. J. (1995). Making greed work in networks: A game-theoretic analysis of switch
service disciplines. IEEE Transactions on Networking, 3 (6), 819{831.
Stone, P. (2000). TPOT-RL applied to network routing. In Proceedings of the Seventeenth
International Machine Learning Conference, pp. 935{942. Morgan Kauman.
Subramanian, D., Druschel, P., & Chen, J. (1997). Ants and reinforcement learning: A case
study in routing in dynamic networks. In Proceedings of the Fifteenth International
Conference on Articial Intelligence, pp. 832{838.
Sutton, R. S. (1988). Learning to predict by the methods of temporal dierences. Machine
Learning, 3, 9{44.
Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: An Introduction. MIT Press,
Cambridge, MA.
Sycara, K. (1998). Multiagent systems. AI Magazine, 19 (2), 79{92.
Tumer, K., Agogino, A., & Wolpert, D. (2002). Learning sequences of actions in collectives
of autonomous agents. In Proceedings of the First International Joint Conference on
Autonomous Agents and Multi-Agent Systems, Bologna, Italy.
Tumer, K., & Wolpert, D. H. (2000). Collective intelligence and Braess' paradox. In
Proceedings of the Seventeenth National Conference on Articial Intelligence, pp. 104{
109, Austin, TX.
Watkins, C., & Dayan, P. (1992). Q-learning. Machine Learning, 8 (3/4), 279{292.
Wolpert, D. H., Kirshner, S., Merz, C. J., & Tumer, K. (2000). Adaptivity in agent-based
routing for data networks. In Proceedings of the fourth International Conference of
Autonomous Agents, pp. 396{403.
Wolpert, D. H., Sill, J., & Tumer, K. (2001). Reinforcement learning in distributed domains:
Beyond team games. In Proceedings of the Seventeenth International Joint Conference
on Articial Intelligence, pp. 819{824, Seattle, WA.
Wolpert, D. H., & Tumer, K. (1999). An Introduction to Collective Intelligence. Tech.
rep. NASA-ARC-IC-99-63, NASA Ames Research Center. URL:http://ic.arc.nasa.gov/ic/projects/coin pubs.html. To appear in Handbook of Agent Technology,
Ed. J. M. Bradshaw, AAAI/MIT Press.
Wolpert, D. H., & Tumer, K. (2001). Optimal payo functions for members of collectives.
Advances in Complex Systems, 4 (2/3), 265{279.
Wolpert, D. H., Tumer, K., & Frank, J. (1999). Using collective intelligence to route internet
traÆc. In Advances in Neural Information Processing Systems - 11, pp. 952{958. MIT
Press.
Wolpert, D. H., Wheeler, K., & Tumer, K. (2000). Collective intelligence for control of
distributed dynamical systems. Europhysics Letters, 49 (6).

387

Journal of Artificial Intelligence Research 16 (2002) 259-292

Submitted 9/01; published 4/02

Efficient Reinforcement Learning Using
Recursive Least-Squares Methods
Xin Xu
Han-gen He
Dewen Hu

XUXIN_MAIL@263.NET
HEHANGEN@CS.HN.CN
DWHU@NUDT.EDU.CN

Department of Automatic Control
National University of Defense Technology
ChangSha, Hunan, 410073, P.R.China

Abstract
The recursive least-squares (RLS) algorithm is one of the most well-known algorithms used
in adaptive filtering, system identification and adaptive control. Its popularity is mainly due to its
fast convergence speed, which is considered to be optimal in practice. In this paper, RLS methods
are used to solve reinforcement learning problems, where two new reinforcement learning
algorithms using linear value function approximators are proposed and analyzed. The two
algorithms are called RLS-TD( λ ) and Fast-AHC (Fast Adaptive Heuristic Critic), respectively.
RLS-TD( λ ) can be viewed as the extension of RLS-TD(0) from λ =0 to general 0≤ λ ≤1, so it is
a multi-step temporal-difference (TD) learning algorithm using RLS methods. The convergence
with probability one and the limit of convergence of RLS-TD( λ ) are proved for ergodic Markov
chains. Compared to the existing LS-TD( λ ) algorithm, RLS-TD( λ ) has advantages in
computation and is more suitable for online learning. The effectiveness of RLS-TD( λ ) is
analyzed and verified by learning prediction experiments of Markov chains with a wide range of
parameter settings.
The Fast-AHC algorithm is derived by applying the proposed RLS-TD( λ ) algorithm in the
critic network of the adaptive heuristic critic method. Unlike conventional AHC algorithm,
Fast-AHC makes use of RLS methods to improve the learning-prediction efficiency in the critic.
Learning control experiments of the cart-pole balancing and the acrobot swing-up problems are
conducted to compare the data efficiency of Fast-AHC with conventional AHC. From the
experimental results, it is shown that the data efficiency of learning control can also be improved
by using RLS methods in the learning-prediction process of the critic. The performance of
Fast-AHC is also compared with that of the AHC method using LS-TD( λ ). Furthermore, it is
demonstrated in the experiments that different initial values of the variance matrix in RLS-TD( λ )
are required to get better performance not only in learning prediction but also in learning control.
The experimental results are analyzed based on the existing theoretical work on the transient
phase of forgetting factor RLS methods.

1. Introduction
In recent years, reinforcement learning (RL) has been an active research area not only in machine
learning but also in control engineering, operations research and robotics (Kaelbling et al.,1996;
Bertsekas, et al.,1996; Sutton and Barto,1998; Lin,1992). It is a computational approach to
©2002 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

XU, HE, & HU

understand and automate goal-directed learning and decision-making, without relying on
exemplary supervision or complete models of the environment. In RL, an agent is placed in an
initial unknown environment and only receives evaluative feedback from the environment. The
feedback is called reward or reinforcement signal. The ultimate goal of RL is to learn a strategy
for selecting actions such that the expected sum of discounted rewards is maximized.
Since lots of problems in the real world are sequential decision processes with delayed
evaluative feedback, the research in RL has been focused on theory and algorithms of learning to
solve the optimal control problem of Markov decision processes (MDPs) which provide an
elegant mathematical model for sequential decision-making. In operations research, many results
have been presented to solve the optimal control problem of MDPs with model information.
However, in reinforcement learning, the model information is assumed to be unknown, which is
different from the methods studied in operations research such as dynamic programming. In
dynamic programming, there are two elemental processes, which are the policy evaluation process and the policy improvement process, respectively. In RL, there are two similar processes.
One is called learning prediction and the other is called learning control. The goal of learning
control is to estimate the optimal policy or optimal value function of an MDP without knowing its
model. Learning prediction aims to solve the policy evaluation problem of a stationary-policy
MDP without any prior model and it can be regarded as a sub-problem of learning control.
Furthermore, in RL, learning prediction is different from that in supervised learning. As pointed
out by Sutton (1988), the prediction problems in supervised learning are single-step prediction
problems while those in reinforcement learning are multi-step prediction problems. To solve
multi-step prediction problems, a learning system must predict outcomes that depend on a future
sequence of decisions. Therefore, the theory and algorithms for multi-step learning prediction
become an important topic in RL and much research work has been done in the literature (Sutton,
1988; Tsitsiklis and Roy, 1997).
Among the proposed multi-step learning prediction methods, temporal-difference (TD)
learning (Sutton, 1988) is one of the most popular methods. It was studied and applied in the early
research of machine learning, including the celebrated checkers-playing program (Minsky, 1954;
Samuel, 1959). In 1988, Sutton presented the first formal description of temporal- difference
methods and the TD( λ ) algorithm (Sutton,1988). Convergence results are established for tabular
temporal-difference learning algorithms where the cardinality of tunable parameters is the same
as that of the state space (Sutton, 1988; Watkins,et al.,1992; Dayan,et al., 1994; Jaakkola, et
al.,1994). Since many real-world applications have large or infinite state space, value function
approximation (VFA) methods need to be used in those cases. When combined with nonlinear
value function approximators, TD( λ ) can not guarantee convergence and several results
regarding divergence have been reported in the literature (Tsitsiklis and Roy,1997). For TD( λ )
with linear function approximators, also called linear TD( λ ) algorithms, several convergence
proofs have been presented. Dayan (1992) showed the convergence in the mean for linear TD( λ )
algorithms with arbitrary 0 ≤ λ ≤ 1 . Tsitsiklis and Roy (1994) proved the convergence for a
special class of TD learning algorithms, known as TD(0), while in Tsitsiklis and Roy (1997), they
extended the early results to general linear TD( λ ) case and proved the convergence with
probability one.
The above linear TD( λ ) algorithms have rules for updating parameters similar to those in
gradient-descent methods. However, as in gradient-learning methods, a step-size schedule must
be carefully designed not only to guarantee convergence but also to obtain good performance. In
260

EFFICIENT REINFORCEMENT LEARNING USING RLS METHODS

addition, there is inefficient use of data that slows the convergence of the algorithms. Based on
the theory of linear least-squares estimation, Brartke and Barto (1996) proposed two
temporal-difference algorithms called the Least-Squares TD(0) algorithm (LS-TD(0)) and the
Recursive Least- Squares TD(0) algorithm (RLS-TD(0)), respectively. LS-TD(0) and RLS-TD(0)
are more efficient in a statistical sense than conventional linear TD( λ ) algorithms and they
eliminate the design of step-size schedules. Furthermore, the convergence of LS-TD(0) and
RLS-TD(0) has been provided in theory. The above two algorithms can be viewed as the
least-squares versions of conventional linear TD(0) methods. However, as has been shown in the
literature, TD learning algorithms such as TD( λ ) with 0< λ <1 that update predictions based on
the estimates of multiple steps are more efficient than Monte-Carlo methods as well as TD(0). By
employing the mechanism of eligibility traces, which is determined by λ , TD( λ ) algorithms
with 0< λ <1 can extract more information from historical data. Recently, a class of linear
temporal-difference learning algorithms called LS-TD( λ ) has been proposed by Boyan
(1999,2002), where least-squares methods are employed to compute the value-function estimation
of TD( λ ) with 0 ≤ λ ≤1. Although LS-TD( λ ) is more efficient than TD( λ ), it requires too much
computation per time-step when online updates are needed and the number of state features
becomes large.
In system identification, adaptive filtering and adaptive control, the recursive least-squares
(RLS) (Young,1984; Ljung, 1983; Ljung,1977) method, commonly used to reduce the
computational burden of least-squares methods, is more suitable for online estimation and control.
Although RLS-TD(0) makes use of RLS methods, it does not employ the mechanism of
eligibility traces. Based on the work of Tsitsiklis and Roy (1994, 1997), Boyan (1999,2002) and
motivated by the above ideas, a new class of temporal-difference learning methods, called the
RLS-TD( λ ) algorithm, is proposed and analyzed formally in this paper. RLS-TD( λ ) is superior
to conventional linear TD( λ ) algorithms in that it makes use of RLS methods to improve the
learning efficiency in a statistical point of view and eliminates the step-size schedules.
RLS-TD( λ ) has the mechanism of eligibility traces and can be viewed as the extension of
RLS-TD(0) from λ =0 to general 0≤ λ ≤1. The convergence with probability 1 of RLS-TD( λ ) is
proved for ergodic Markov chains and the limit of convergence is also analyzed. In learning
prediction experiments for Markov chains, the performance of RLS-TD( λ ) and TD( λ ) as well as
LS-TD( λ ) is compared, where a wide range of parameter settings is tested. In addition, the influence of the initialization parameters in RLS-TD( λ ) is also discussed. It is observed that the
rate of convergence is influenced by the initialization of the variance matrix, which is a
phenomenon investigated theoretically in adaptive filtering (Moustakides, 1997; Haykin, 1996).
As will be analyzed in the following sections, there are two benefits of the extension from
RLS-TD(0) to RLS-TD( λ ). One is that the value of λ (0≤ λ ≤1) will still affect the performance
of the RLS-based temporal-difference algorithms. Although for RLS-TD( λ ), the rate of
convergence is mainly influenced by the initialization of the variance matrix, the bound of
approximation error is dominantly determined by the parameter λ . The smallest error bound can
be obtained for λ =1 and the worst bound is obtained for λ =0. These bounds suggest that the
value of λ should be selected appropriately to obtain the best approximation error. The second
benefit is that RLS-TD( λ ) is more suitable for online learning than LS-TD( λ ) since the
computation per time-step is reduced from O(K3) to O(K2), where K is the number of state
features.
The Adaptive-Heuristic-Critic (AHC) learning algorithm is a class of reinforcement learning
261

XU, HE, & HU

methods that has an actor-critic architecture and can be used to solve full reinforcement learning
or learning control problems. By applying the RLS-TD( λ ) algorithm in the critic, the Fast-AHC
algorithm is proposed in this paper. Using RLS methods in the critic, the performance of learning
prediction in the critic is improved so that learning control problems can be solved more
efficiently. Simulation experiments on the learning control of the cart-pole balancing problem and
the swing-up of an acrobot are conducted to verify the effectiveness of the Fast-AHC method. By
comparing with conventional AHC methods which use TD( λ ) in the critic, it is demonstrated that
Fast-AHC can obtain higher data efficiency than conventional AHC methods. Experiments on the
performance comparisons between AHC methods using LS-TD( λ ) and Fast-AHC are also
conducted. In the learning control experiments, it is also illustrated that the initializing constant of
the variance matrix in RLS-TD( λ ) influences the performance of Fast-AHC and different values
of the constant should be selected to get better performance in different problems. The above
results are analyzed based on the theoretical work on the transient phase of RLS methods.
This paper is organized as follows. In Section 2, an introduction on the previous linear
temporal-difference algorithms is presented. In Section 3, the RLS-TD( λ ) algorithm is proposed
and its convergence (with probability one) is proved. In Section 4, a simulation example of the
value-function prediction for absorbing Markov chains is presented to illustrate the effectiveness
of the RLS-TD( λ ) algorithm, where different parameter settings for different algorithms
including LS-TD( λ ) are studied. In Section 5, the Fast-AHC method is proposed and the
simulation experiments on the learning control of the cart-pole balancing and the acrobot are
conducted to compare Fast-AHC with the conventional AHC method as well as the
LS-TD( λ )-based AHC method. Some simulation results are presented and analyzed in detail. The
last section contains concluding remarks and directions for future work.

2. Previous Work on Linear Temporal-Difference Algorithms
In this section, a brief discussion on the conventional linear TD( λ ) algorithm and RLS-TD(0) as
well as the LS-TD( λ ) algorithm will be given. First of all, some mathematical notations are
presented as follows.
Consider a Markov chain whose states lie in a finite or countable infinite space S. The states
of the Markov chain can be indexed as {1,2,…,n}, where n is possibly infinite. Although the
algorithms and the results in this paper are applicable to Markov chains with general state space,
the discussion in this paper will be restricted within the cases with a countable state space to
simplify the notation. The extension to Markov chains with a general state space only requires the
translation of the matrix notation into operator notation.
Let the trajectory generated by the Markov chain be denoted by {xt |t=0,1,2,…; xt ∈S}.The
dynamics of the Markov chain is described by a transition probability matrix P whose (i,j)-th
entry, denoted by pij, is the transition probability for xt+1=j given that xt=i. For each state transition
from xt to xt+1, a scalar reward rt is defined. The value function of each state is defined as follows:
∞

V (i ) = E{∑ γ t rt x 0 = i}

(1)

t =0

where 0< γ ≤ 1 is a discount factor.
In the TD( λ ) algorithm, there are two basic mechanisms which are the temporal difference
262

EFFICIENT REINFORCEMENT LEARNING USING RLS METHODS

and the eligibility trace, respectively. Temporal differences are defined as the differences between
two successive estimations and have the following form.
~
~
δ t = rt + γVt ( xt +1 ) − Vt ( xt )
(2)
~
where xt+1 is the successive state of xt, V ( x) denotes the estimate of the value function V(x) and rt
is the reward received after the state transition from xt to xt+1.
The Eligibility trace can be viewed as an algebraic trick to improve learning efficiency
without recording all the data of a multi-step prediction process. This trick is based on the idea of
using the truncated return of a Markov chain. In temporal-difference learning with eligibility
traces, an n-step truncated return is defined as
~
Rtn = rt + γrt +1 + ... + γ n −1 rt + n −1 + γ nVt ( s t + n )
(3)
For an absorbing Markov chain whose length is T, the weighted average of truncated returns
is
T −t −1

Rtλ = (1 − λ )

∑ λ n−1 Rtn + λ T −t −1 RT

(4)

n =1

where 0 ≤ λ ≤ 1 is a decaying factor and RT= rt + γrt +1 + ... + γ T rT is the Monte-Carlo return at
the terminal state. In each step of the TD( λ ) algorithm, the update rule of the value function
estimation is determined by the weighted average of truncated returns defined above. The
corresponding update equation is
~
~
∆Vt ( s i ) = α t ( Rtλ − Vt ( s i ))
(5)
where αt is a learning factor.
The update equation (5) can be used only after the whole trajectory of the Markov chain is
observed. To realize incremental or online learning, eligibility traces are defined for each state as
follows:

γλ z t ( s i ) + 1,
z t +1 ( s i ) = 
γλ z t ( s i ),

if s i = s t
if s i ≠ s t

The online TD( λ ) update rule with eligibility traces is
~
~
Vt +1 ( si ) = Vt ( si ) + α t δ t z t +1 ( si )

(6)

(7)

where δt is the temporal difference at time step t, which is defined in (2) and z0(s)=0 for all s.
Since the state space of a Markov chain is usually large or infinite in practice, function
approximators such as neural networks are commonly used to approximate the value function.
TD( λ ) algorithms with linear function approximators are the most popular and well-studied ones.
Consider a general linear function approximator with a fixed basis function vector

φ ( x ) = (φ1 ( x ), φ 2 ( x ),..., φ n ( x ))T
The estimated value function can be denoted as

~
Vt ( x) = φ T ( x)Wt
263

(8)

XU, HE, & HU

where Wt =(w1, w2,…,wn)T is the weight vector.
The corresponding incremental weight update rule is

r
Wt +1 = Wt + α t (rt + γφ T ( xt +1 )Wt − φ T ( xt )Wt ) z t +1
r
where the eligibility trace vector z t ( s ) = ( z1t ( s ), z 2t ( s ),..., z nt ( s )) T is defined as
r
r
z t +1 = γλz t + φ ( xt )

(9)

(10)

In Tsitsiklis and Roy (1997), the above linear TD( λ ) algorithm is proved to converge with
probability 1 under certain assumptions and the limit of convergence W* is also derived, which
satisfies the following equation.
E 0 [ A( X t )]W * − E 0 [b( X t )] = 0

(11)

where Xt =(xt,xt+1,zt+1) (t=1,2,…) form a Markov process, E0[·] stands for the expectation with
respect to the unique invariant distribution of {Xt}, and A(Xt) and b(Xt) are defined as
r
A( X t ) = z t (φ T ( xt ) − γφ T ( xt +1 ))
(12)

r
b( X t ) = z t rt

(13)

To improve the efficiency of linear TD(λ) algorithms, least-squares methods are used with the
linear TD(0) algorithm, and the LS-TD(0) and RLS-TD(0) algorithms are suggested (Brartke and
Barto, 1996). In LS-TD(0) and RLS-TD(0), the following quadratic objective function is defined.
T −1

J = ∑ [rt − (φ tT − γφ tT+1 )W ] 2

(14)

t =1

Thus, the aim of LS-TD(0) and RLS-TD(0) is to obtain a least-squares estimation of the real
value function which satisfies the following Bellman equation.
V ( xt ) = E[rt ( xt , xt +1 ) + γV ( xt +1 )]

(15)

By employing the instrumental variables approach (Soderstrom and Stoica, 1983), the
least-squares solution of (14) is given as
T

T

t =1

t =1

W LS −TD ( 0) = (∑ (φ t (φ t − γφ t +1 ) T )) −1 (∑ φ t rt )

(16)

where φ t is the instrumental variable chosen to be uncorrelated with the input and output noises.
In RLS-TD(0), recursive least-squares methods are used to decrease the computational burden of LS-TD(0). The update rules of RLS-TD(0) are as follows:
Wt +1 = Wt + Pt φ t (rt − (φ t − γφt +1 ) T Wt ) /(1 + (φ t − γφt +1 ) T Pt φ t )

(17)

Pt +1 = Pt − Pt φ t (φ t − γφ t +1 ) T Pt /(1 + (φ t − γφ t +1 ) T Pt φ t )

(18)

The convergence (with probability one) of LS-TD(0) and RLS-TD(0) is proved for periodic and
absorbing Markov chains under certain assumptions (Brartke and Barto,1996).
264

EFFICIENT REINFORCEMENT LEARNING USING RLS METHODS

In Boyan (1999,2002), LS-TD( λ ) is proposed by solving (11) directly and the model-based
property of LS-TD( λ ) is also analyzed. However, for LS-TD( λ ), the computation per time-step is
O(K3), i.e., the cubic order of the state feature number. Therefore the computation required by
LS-TD(λ) increases very fast when K increases, which is undesirable for online learning.
In the next section, we propose the RLS-TD( λ ) algorithm by making use of recursive
least-squares methods so that the computational burden of LS-TD( λ ) can be reduced from O(K3)
to O(K2). We also give a rigorous mathematical analysis on the algorithm, where the convergence
(with probability 1) of RLS-TD( λ ) is proved.

3. The RLS-TD( λ ) Algorithm
For the Markov chain discussed above, when linear function approximators are used, the
least-squares estimation problem of (11) has the following objective function.
J=

T

T

t =1

t =1

∑ A( X t )W − ∑ b( X t )

2

(19)

where A( X t ) ∈ R n×n , b( X t ) ∈ R n are defined as (12) and (13), respectively, ⋅ is a Euclid norm
and n is the number of basis functions.
In LS-TD( λ ), the least-squares estimate of the weight vector W is computed according to the
following equation.
T

T

t =1

t =1

W LS −TD ( λ ) = AT−1bT = (∑ A( X t )) −1 (∑ b( X t ))

(20)

T
T
r
AT = ∑ ( A( X t )) = ∑ z t (φ T ( xt ) − γφ T ( xt +1 ))

(21)

T
T
r
bT = ∑ b( X t ) = ∑ z t rt

(22)

where

t =0

t =0

t =0

t =0

As is well known in system identification, adaptive filtering and control, RLS methods are
commonly used to solve the computational and memory problems of least-squares algorithms. In
the sequel, we present the RLS-TD( λ ) algorithm based on the above idea. First, the matrix inverse lemma is given as follows:
Lemma 1(Ljung, et al.,1983). If A ∈ R n×n , B ∈ R n×1 , C ∈ R 1×n and A is invertible, then

( A + BC ) −1 = A −1 − A −1 B ( I + CA −1 B ) −1 CA −1

(23)

Pt = At−1

(24)

Let

265

XU, HE, & HU

P0 = δI

(25)

r
K t +1 = Pt +1 z t

(26)

where δ is a positive number and I is the identity matrix.
Then the weight update rules of RLS-TD( λ ) are given by
r
r
K t +1 = Pt z t /( µ + (φ T ( xt ) − γφ T ( xt +1 )) Pt z t )
Wt +1 = Wt + K t +1 (rt − (φ T ( xt ) − γφ T ( xt +1 ))Wt )

Pt +1 =

1

µ

r
r
[ Pt − Pt z t [ µ + (φ T ( xt ) − γφ T ( xt +1 )) Pt z t )] −1 (φ T ( xt ) − γφ T ( xt +1 )) Pt ]

(27)
(28)

(29)

where for the standard RLS-TD(λ) algorithm, µ=1; for the general forgetting factor RLS-TD(λ)
case, 0<µ≤1.
The forgetting factor µ (0<µ≤1) is usually used in adaptive filtering to improve the
performance of RLS methods in non-stationary environments. The forgetting factor RLS-TD( λ )
algorithm with 0<µ≤1 can be derived using similar techniques as in Haykin (1996). The detailed
derivation of RLS-TD(λ) is referred to Appendix A.
In the follows, the descriptions of RLS-TD( λ ) for two different kinds of Markov chains are
given. First, a complete description of RLS-TD( λ ) for ergodic Markov chains is presented below.

Algorithm 1 RLS-TD( λ ) for ergodic Markov chains

1: Given:
• A termination criterion for the algorithm.
• A set of basis functions { φ j (i ) } (j=1,2,…,n) for each state i, where n is the
number of basis functions.
2: Initialize:
(2.1) Let t=0.
(2.2) Initialize the weight vector Wt, the variance matrix Pt , the initial state x0.
r
(2.3) Set the eligibility traces vector z 0 =0.
3: Loop:
(3.1) For the current state xt, observe the state transition from xt to xt+1 and the
reward r(xt ,xt+1).
(3.2) Apply equations (27)-(29) to update the weight vector.
(3.3) t=t+1.
until the termination criterion is satisfied.

The RLS-TD( λ ) algorithm for absorbing Markov chains is a little different from the above
algorithm in coping with the state features of absorbing states. Following is a description of
266

EFFICIENT REINFORCEMENT LEARNING USING RLS METHODS

RLS-TD( λ ) for absorbing Markov chains.

Algorithm 2 RLS-TD( λ ) for absorbing Markov chains

1: Given:
• A termination criterion for the algorithm.
• A set of basis functions { φ j (i ) } (j=1,2,…,n) for each state i, where n is the
number of basis functions.
2: Initialize:
(2.1) Let t=0.
(2.2) Initialize the weight vector Wt, the variance matrix Pt , the initial state x0.
r
(2.3) Set the eligibility traces vector z 0 =0.
3: Loop:
(3.1) For the current state xt,
• If xt is an absorbing state, set φ (xt+1)=0, r(xt)=rT, where rT is the terminal
reward.
• Otherwise, observe the state transition from xt to xt+1 and the reward
r(xt ,xt+1).
(3.2) Apply equations (27)-(29) to update the weight vector.
(3.3) If xt is an absorbing state, re-initialize the process by setting xt+1 to an initial
r
state and set the eligibility traces z t to a zero vector.
(3.4) t=t+1.
until the termination criterion is satisfied.

In the above RLS-TD( λ ) algorithm for absorbing Markov chains, the weight updates in the
absorbing states are treated differently and the process is re-initialized in absorbing states to
transform the absorbing Markov chain into an equivalent ergodic Markov chain. So in the
following convergence analysis, we only focus on ergodic Markov chains.
Under similar assumptions as in Tsitsiklis and Roy (1997), we will prove that the proposed
RLS-TD( λ ) algorithm converges with probability one.
Assumption 1. The Markov chain {xt}, whose transition probability matrix is P, is ergodic, and
there is a unique distribution π that satisfies

π

P =π T
(30)
with π (i)>0 for all i∈S andπ is a finite or infinite vector, depending on the cardinality of S.
T

Assumption 2. Transition rewards r(xt,xt+1) satisfy

E 0 [r 2 ( xt , xt +1 )] < ∞

(31)

where E0[ ] is the expectation with respect to the distribution π .
Assumption 3. The matrix Φ = [φ1 , φ 2 ,..., φ n ] ∈ R N ×n has full column rank, that is, the basis
267

XU, HE, & HU

functions φ i (i=1,2,…,n) are linearly independent.
Assumption 4. For every i (i=1,2,…,n), the basis function φ i satisfies
2

E 0 [φ i ( xt )] < ∞

(32)

1 T
∑ A( X t )] is non-singular for all T>0.
T t =1
Assumptions 1–4 are almost the same as those for the linear TD(λ) algorithms discussed in
Tsitsiklis and Roy (1997) except that in Assumption 1, ergodic Markov chains are considered.
Assumption 5 is specially needed for the convergence of the RLS-TD(λ) algorithm.
Based on the above assumptions, the convergence theorem for RLS-TD(λ) can be given as
follows:
Assumption 5. The matrix [ P0−1 +

Theorem 1. For a Markov chain which satisfies Assumptions 1–5, the asymptotic estimate found
by RLS-TD( λ ) converges, with probability 1, to W* determined by (11).

For the proof of Theorem 1, please refer to Appendix B. The condition specified by
Assumption 5 can be satisfied by setting P0= δI appropriately.
According to Theorem 1, RLS-TD( λ ) converges to the same solution as conventional linear
TD( λ ) algorithms do, which satisfies (11). So the limit of convergence can be characterized by
the following theorem.
Theorem 2 (Tsitsiklis and Roy ,1997) Let W* be the weight vector determined by (11) and V* be
the true value function of the Markov chain, then under Assumption 1–4, the following relation
holds.
1 − λγ
ΦW * − V * ≤
(33)
ΠV * − V *
D
D
1−γ

where

X

D

=

X T DX , Π = Φ (Φ T DΦ ) −1 Φ T D .

For more explanations on the notations in Theorem 2, please refer to Appendix B.
As discussed by Tsitsiklis and Roy (1997), the above theorem shows that the distance of the
limiting function Φ W* from the true value function V* is bounded and the smallest bound of
approximation error can be obtained when λ=1. For every λ<1, the bound actually deteriorates as
λ decreases. The worst bound is obtained when λ=0. Although this is only a bound, it strongly
suggests that higher values of λ are likely to produce more accurate approximations of V*.
Compared to LS-TD(λ), there is an additional parameter in RLS-TD(λ), which is the value δ
for the initial variance matrix P0. As was pointed out by Haykin (1996,pp.570), the exact value of
the initializing constant δ has an insignificant effect when the data length is large enough. This
means that in the limit, the final solutions obtained by LS and RLS are almost the same. For the
influence of δ on the transient phase, when the positive constant δ becomes large enough or goes
to infinity, the transient behavior of RLS will be almost the same as that of LS methods (Ljung,
1983). But when δ is initialized with a relatively small value, the transient phases of RLS and LS
will be different. In practice, it is observed that there is a variable performance of RLS as a
function of the initialization of δ (Moustakides, 1997). In some cases, RLS can exhibit a
significantly faster convergence when initialized with a relatively small positive definite matrix
than when initialized with a large one (Haykin,1996; Moustakides, 1997; Hubing and Alexander,
268

EFFICIENT REINFORCEMENT LEARNING USING RLS METHODS

1989). A first effort toward this direction is the statistical analysis of RLS for soft and exact
initialization but limits to the case that the number of iterations is less than the size of the
estimation vector (Hubing and Alexander, 1989). Moustakides (1997) provided a theoretical
analysis on the relation between the algorithmic performance of RLS and the initialization of δ.
By using the settling time as the performance measure, Moustakides proved that the well-known
rule of initialization with a relatively small matrix is preferable for cases of high and medium
signal-to-noise ratio (SNR), whereas for low SNR, a relatively large matrix must be selected for
achieving best results. In the following learning prediction experiments of RLS-TD(λ), as well as
the learning control simulation of Fast-AHC, it is observed that the value of the initializing
constant δ also plays an important role in the convergence performance, and the above theoretical
analyses provide a clue to explain our experimental results.

4. Learning Prediction Experiments on Markov Chains
In this section, an illustrative example is given to show the effectiveness of the proposed
RLS-TD(λ) algorithm. Furthermore, the algorithmic performance under the influence of the
initializing constant δ is studied.
The example is a finite-state absorbing Markov chain called the Hop-World problem (Boyan,
1999). As shown in Figure 1, the Hop-World problem is a 13-state Markov chain with an
absorbing state.

Figure 1: The Hop-World Problem
In Figure 1, state 12 is the initial state for each trajectory and state 0 is the absorbing state.
Each non-absorbing state has two possible state transitions with transition probability 0.5. Each
state transition has reward –3 except the transition from state 1 to state 0 which has a reward of –2.
Thus, the true value function for state i (0≤i≤12) is –2i.
To apply linear temporal-difference algorithms to the value function prediction problem, a set
of four-element state features or basis functions is chosen, as shown in Figure 1. The state
features of states 12,8,4 and 0 are, respectively, [1,0,0,0], [0,1,0,0], [0,0,1,0], [0,0,0,1] and the
state features of other states are obtained by linearly interpolating between these.
In our simulation, the RLS-TD( λ ) algorithm as well as LS-TD(λ) and conventional linear
TD( λ ) algorithms are used to solve the above value function prediction problem without
knowing the model of the Markov chain. In the experiments, a trial is defined as the period from
the initial state 12 to the terminal state 0. The performance of the algorithms is evaluated by the
averaged root mean squared (RMS) error of value-function predictions over all the 13 states. For
each parameter setting, the performance is averaged over 20 independent Monte-Carlo runs.
Figure 2 shows the learning curves of RLS-TD(λ) and conventional linear TD(λ) algorithms with
three different parameter settings. The parameter λ is set to 0.3 for all the algorithms and the
269

XU, HE, & HU

step-size parameter of TD(λ) has the following form.

αn = α0

N0 +1
N0 + n

(34)

The above step-size schedule is also studied in Boyan (1999). In our experiments, three
different settings are used, which are
(s1) α 0 = 0.01 , N 0 = 10 6
(s2) α 0 = 0.01 , N 0 = 1000
(s3) α 0 = 0.1 , N 0 = 1000 .

(35)

Different from those in Boyan (1999), the linear TD(λ) algorithms applied here are in their
online forms, which update the weights after every state transitions. So the parameter n in (34) is
the number of state transitions. In each run, the weights are all initialized to zeroes. In Figure 2,
the learning curves of conventional linear TD(λ) algorithms with step-size schedules (s1), (s2)
and (s3) are shown by curves 1,2 and 3, respectively. For each curve, the averaged RMS errors of
value function predictions over all the states and 20 independent runs are plotted for each trial.
Curve 4 shows the learning performance of RLS-TD(λ). One additional parameter for RLS-TD(λ)
is the initial value δ of the variance matrix P0. In this experiment, δ is set to 500, which is a
relatively large value. From Figure 2, it can be concluded that by making use of RLS methods,
RLS-TD(λ) can obtain much better performance than conventional linear TD(λ) algorithms and
eliminates the design problem of the step-size schedules. Other experiments for linear TD(λ) and
RLS-TD(λ) with different parameters λ are also conducted and similar results are obtained when
the initial values δ of RLS-TD(λ) are large and the conclusion is confirmed.

Figure 2: Performance comparison between RLS-TD(λ) and TD(λ)
1,2,3 ---TD(0.3) with step-size parameters specified by (s1),(s2) and (s3)
4—RLS-TD(0.3) with initial variance matrix P0=500I
We have done demonstrative experiments to investigate the influence of δ on the performance
of the RLS-TD(λ) algorithm. Figure 3 shows the performance comparison between RLS-TD(λ)
270

EFFICIENT REINFORCEMENT LEARNING USING RLS METHODS

algorithms using two different initial parameters of the variance matrix P0, which are P0=0.1I and
P0=1000I, respectively. The forgetting factor is µ=0.995. The performance of the suggested
algorithm is measured by the averaged RMS errors of the value function prediction in the first
200 trials over 20 independent runs and all the 13 states. In the experiments, 11 settings of the
parameter λ are tested, which are 0.1n (n=0,1,…,10).
In Figure 3, it is clearly shown that the performance of RLS-TD(λ) with a large initial value
of δ is much better than RLS-TD(λ) with a small initial value of δ. In other experiments with
different parameter settings of λ and δ, similar results are also obtained. We may refer this
phenomenon to the low SNR case of the forgetting factor RLS studied in Moustakides (1997).
For the Hop-World problem, the stochastic state transitions could introduce high equation
residuals A( X t )W − b( X t ) in (19), which corresponds to the additive noise with large variance,
i.e., the low SNR case. As has been discussed in Section 2, for the forgetting factor RLS in low
SNR cases, a relatively large initializing constant δ must be selected for better results. A full
understanding of this phenomenon is yet to be found.

Figure 3: Performance comparison of RLS-TD(λ) with different initial value of δ (µ=0.995)
The performance of RLS-TD(λ) with unit forgetting factor µ=1 is also tested in our
experiments. Although the initial value effect in RLS with µ=1 has not been discussed intensively
(Moustakides,1997), the same effects of δ are observed empirically in the case of µ=1 as that in
µ<1, which is shown by Figure 4.
In our other experiments, it is also found that when δ is initialized with a small value, the
performance is sensitive to the values of δ and the parameter λ. In this case, the convergence
speed of RLS-TD(λ) increases as λ increases from 0 to 1, which is shown in Figure 3.
Furthermore, when λ is fixed, the performance of RLS-TD(λ) deteriorates as δ becomes smaller,
as shown in Figure 5 .

271

XU, HE, & HU

Figure 4: Performance comparison of RLS-TD(λ) with different initial value of δ (µ=1)

Figure 5: Learning curves of LS-TD(λ) and RLS-TD(λ) with different δ (µ=1)

In Figure 5, the learning curves of RLS-TD(λ) with different initializing constants δ are
shown and compared with that of LS-TD(λ). In the experiment, λ is set to 0.5. From Figure 5, it is
shown that the performance of RLS-TD(λ) approaches that of LS-TD(λ) when δ becomes large.
As is well known, when δ becomes large enough, the performance of RLS and LS methods will
be almost the same. Figure 6 shows the performance comparison between LS-TD(λ) and
RLS-TD(λ) with a large value of δ. The initial variance matrix for RLS-TD(λ) is set to 500I in
every runs, where I is the identity matrix.

272

EFFICIENT REINFORCEMENT LEARNING USING RLS METHODS

Figure 6: Performance comparison of LS-TD(λ) and RLS-TD(λ) with µ=1 and large initial
value of δ
Based on the above experimental results, it can be concluded that the convergence speed of
RLS-TD( λ ) is mainly influenced by the initial value δ of the variance matrix and the parameter
λ . Detailed discussions on the properties of RLS-TD( λ ) are given as follows:
(1) When δ is relatively large, the effect of λ becomes small. If δ is large enough or goes to
infinity, the performance of RLS-TD( λ ) and LS-TD( λ ) will be almost the same, as was
discussed above. In such cases, the effect of λ on the speed of convergence is insignificant,
which coincides with the discussion in Boyan (1999). However, as described in Theorem 2, the
value of λ still affects the ultimate error bound of value function approximation.
(2) When δ is relatively small, it is observed that the convergence performance of
RLS-TD(λ) is different from that of LS-TD(λ) and is influenced by the values of both δ and λ. In
the experiments of the Hop-World problem, the results show that smaller values of δ lead to
slower convergence. These results may be explained by the theoretical analysis on the transient
phase of the forgetting factor RLS (Moustakides,1997). According to the theory in Moustakides
(1997), larger values of δ are needed for better performance in the cases of low SNR while
smaller δ values are preferable for fast convergence in the cases of high and medium SNR. So
different values of δ must be selected for faster convergence of RLS-TD( λ ) in different cases.
Especially, in some cases, such as the high SNR case discussed in Moustakides (1997), RLS
methods with small values of δ can obtain a very fast speed of convergence.
(3) Compared to conventional linear TD( λ ) algorithms, the RLS-TD( λ ) algorithm can
obtain much better performance by making use of RLS methods for value function prediction
problems. Furthermore, in TD( λ ), a step-size schedule needs to be carefully designed to achieve
good performance, while in RLS-TD( λ ), the initial value δ of the variance matrix can be selected
according to the criterion of a “large” or a “small” value.
(4) For the comparison of LS-TD( λ ) and RLS-TD( λ ), which one is preferable depends on
the objective. In online applications, RLS-TD( λ ) has advantages in computational efficiency
because the computation per step for RLS-TD( λ ) is O(K2) and for LS-TD( λ ), it is O(K3), where
273

XU, HE, & HU

K is the number of state features. Moreover, as will be seen later, RLS-TD( λ ) can obtain better
transient convergence performance than LS-TD( λ ) in some cases. On the other hand, LS-TD( λ )
may be preferable to RLS-TD( λ ) in the long-term convergence performance, as can be seen in
Figure 5. And from a system identification point of view, LS-TD( λ ) can obtain unbiased
parameter estimates in face of white additive noises while RLS-TD( λ ) with finite δ would
possess large parameter discrepancies.

5. The Fast-AHC Algorithm and Two Learning Control Experiments
In this section, the Fast-AHC algorithm is proposed based on the above results on learning
prediction to solve learning control problems. Two learning control experiments are conducted to
illustrate the efficiency of Fast-AHC.
5.1 The Fast-AHC Algorithm

The ultimate goal of reinforcement learning is learning control, i.e., to estimate the optimal
policies or the optimal value functions of Markov decision processes (MDPs). Until now, several
reinforcement learning control algorithms including Q-learning (Watkins and Dayan,1992),
Sarsa-learning (Singh, et al.,2000) and the Adaptive Heuristic Critic (AHC) algorithm (Barto,
Sutton and Anderson,1983) have been proposed. Among the above methods, the AHC method is
different from Q-learning and Sarsa-learning which are value-function-based methods. In the
AHC method, value functions and policies are separately represented while in value-functionbased methods the policies are determined by the value functions directly. There are two
components in the AHC method, which are called the critic and the actor, respectively. The actor
is used to generate control actions according to the policies. The critic is used to evaluate the
policies represented by the actor and provide the actor with internal rewards without waiting for
delayed external rewards. Since the objective of the critic is policy evaluation or learning
prediction, temporal-difference learning methods are chosen as the critic’s learning algorithms.
The learning algorithm of the actor is determined by the estimation of the gradient of the policies.
In the following discussion, a detailed introduction on the AHC method is given.
Figure 7 shows the architecture of a learning system based on the AHC method. The learning
system consists of a critic network and an actor network. The inputs of the critic network include
the external rewards and the state feedback from the environment. The internal rewards provided
by the critic network are called the temporal-difference (TD) signals.
As in most reinforcement learning methods, the whole system is modeled as an MDP denoted
by a tuple {S,A,P,R},where S is the state set, A is the action set, P is the state transition probability
and R is the reward function. The policy of the MDP is defined as a function π :S→Pr(A), where
Pr(A) is a probability distribution in the action space. The objective of the AHC method is to
estimate the optimal policy π* satisfying the following equation.
∞

J = max J π = max Eπ [∑ γ t rt ]
*

π

π

(36)

t =0

where γ is the discount factor and rt is the reward at time-step t，Eπ[ ] stands for the expectation
with respect to the policy π and the state transition probabilities and Jπ is the expected total
reward.

274

EFFICIENT REINFORCEMENT LEARNING USING RLS METHODS

Figure 7: The AHC learning system
The value function for a stationary policy π and the optimal value function for the optimal
policy are defined as follows:
∞

V π ( s ) = Eπ [∑ γ t rt s 0 = s ]

(37)

V * ( s ) = Eπ *[∑ γ t rt s0 = s ]

(38)

t =0
∞

t =0

According to the theory of dynamic programming, the optimal value function satisfies the
following Bellman equation.
(39)
V * ( s ) = max[ R ( s, a ) + γEV * ( s ' )]
a

where R(s,a) is the expected reward received after taking action a in state s.
In AHC, the critic uses temporal-difference learning to approximate the value function of the
current policy. When linear function approximators are used in the critic, the weight update
equation is
Wt +1 = Wt + α t [rt + γV ( s t +1 ) − V ( s t )]z t

(40)

where zt is the eligibility trace defined in (10).
The action selection policy of the actor is determined by the current state and the value
function estimation of the critic. Suppose a neural network with weight vector u=[u1, u2,…, um] is
used in the actor, and the output of the actor network is

y t = f (u , st )

(41)

The action outputs of the actor are determined by the following Gaussian probabilistic distribution.
( y − y )2
p r ( y t ) = exp(− t 2 t )
(42)

σt

where the mean value is given by (41) and the variance is given by

σ t = k1 /(1 + exp(k 2V ( s t ))

(43)

In the above equation, k1 and k2 are positive constants and V(st) is the value function es275

XU, HE, & HU

timation of the critic network.
To obtain the learning rule of the actor, an estimation of the policy gradient is given as
follows:
∂J ∂y t
∂J π
y − y t ∂y t
= π
≈ rˆt t
∂u
∂y t ∂u
σ t ∂u

(44)

where r̂t is the internal reward or the TD signal provided by the critic:

rˆt = rt + γV ( st +1 ) − V ( st )

(45)

Since in the AHC method, the critic is used to estimate the value function of the actor’s policy
and provide the internal reinforcement using temporal-difference learning algorithms, the
efficiency of temporal-different learning or learning prediction will greatly influence the whole
learning system’s performance. Although the policy of the actor is changing, it may change
relatively slowly especially when fast convergence of learning prediction in the critic can be
realized. In the previous sections, RLS-TD( λ ) is shown to have better data efficiency than
conventional linear TD( λ ) algorithms and a very fast convergence speed can be obtained when
the initializing constant is chosen appropriately. Thus, applying RLS-TD( λ ) to the policy
evaluation in the critic network will improve the learning prediction performance of the critic and
is promising to enhance the whole system’s learning control performance. Based on the above
idea, a new AHC method called the Fast-AHC algorithm is proposed in this paper. The efficiency
of the Fast-AHC algorithm is verified empirically and detailed analysis of the results is given.
Following is a complete description of the Fast-AHC algorithm.

Algorithm 3: The Fast-AHC algorithm
1: Given: a critic neural network and an actor neural network, which are both linear in
parameters, a stop criterion for the algorithm.
2: Initialize the state of the MDP and the learning parameters, set t=0.
3: While the stop criterion is not satisfied,
(3.1) According to the current state s t , compute the output of the actor network y t ,

(3.2)

determine the actual action of the actor by the probability distribution given by
(42).
Take the action y t on the MDP, and observe the state transition from s t to

s t +1 , set reward rt = r ( st , st +1 ) .
(3.3)
(3.4)

(3.5)

Apply the RLS-TD( λ ) algorithm described in (27)-(29) to update the weights of
the critic network.
Apply the following equation to update the weights of the actor network,
∂J
at +1 = at + β t π
(46)
∂at
where βt is the learning factor of the actor.
Let t=t+1, return to 3.

276

EFFICIENT REINFORCEMENT LEARNING USING RLS METHODS

5.2 Learning Control Experiments on The Cart-Pole Balancing Problem
The balancing control of inverted pendulums is a typical nonlinear control problem and has been
widely studied not only in control theory but also in artificial intelligence. In the research of
artificial intelligence, the learning control of inverted pendulums is considered as a standard test
problem for machine learning methods, especially for RL algorithms. It has been studied in the
early work of Michie’s BOXES system (Michie,et al.,1968) and later in Barto and Sutton (1983),
where the learning controllers only have two output values: +10(N) and –10(N). In Berenji, et
al.(1992) and Lin, et al.(1994), AHC methods with continuous outputs are applied to the cart-pole
balancing problem. In this paper, the cart-pole balancing problem with continuous control values
is used to illustrate the effectiveness of the Fast-AHC method.
Figure 8 shows a typical cart-pole balancing control system, which consists of a cart moving
horizontally and a pole with one end fixed at the cart. Let x denote the horizontal distance
between the center of the cart and the center of the track, where x is negative when the cart is in
the left part of the track. Variable θ denotes the angle of the pole from its upright position (in
degrees) and F is the amount of force (N) applied to the cart to move it towards its left or right. So
the control system has four state variables x, x& ,θ ,θ& , where x& ,θ& are the derivatives of x and θ ,
respectively.
In Figure 8, the mass of the cart is M=1.0kg, the mass of the pole is m=0.1kg, the half-pole
length is l=0.5m, the coefficient of friction of the cart on the track is µc=0.0005 and the coefficient
of friction of the pole on the cart is µp=0.000002. The boundary constraints on the state variables
are given as follows.
− 12 o ≤ θ ≤ 12 o
(47)
− 2.4m ≤ x ≤ 2.4m
(48)
The dynamics of the control system can be described by the following equations.

µ p (m + M )θ&
(m + M ) g sin θ − cos θ [ F + mlθ& 2 sin θ − µ c sgn( x& )] −

ml
θ&& =

4
2
(49)

( M + m)l − ml cos θ
3


F + ml (θ& 2 sin θ − θ&& cos θ ) − µ c sgn( x& )
&x& =
M +m

where g is the acceleration due to the gravity, which is –9.8m/s2. The above parameters and
dynamics equations are the same as those studied in Barto et al. (1983).

Figure 8: The cart-pole balancing control system
277

XU, HE, & HU

In the learning control experiments of the pole-balancing problem, the dynamics (49) is
assumed to be unknown to the learning controller. In addition to the four state variables, the only
available feedback is a failure signal that notifies the controller when a failure occurs, which
means the values of the state variables exceed the boundary constraints prescribed by inequalities
(47) and (48). It is a typical reinforcement learning problem, where the failure signal serves as the
reward. Since an external reward may only be available after a long sequence of actions, the critic
in the AHC learning controller is used to provide the internal reinforcement signal to accomplish
the learning task. Learning control experiments on the pole-balancing problem are conducted
using conventional AHC method which uses linear TD(λ) algorithms in the critic and the
Fast-AHC method proposed in this paper.
To solve the continuous state space problem in reinforcement learning, a class of linear
function approximators, which is called Cerebellar Model Articulation Controller (CMAC) is
used. As a neural network model based on the neuro-physiological theory about human
cerebellar，CMAC was first proposed by Albus (1975) and has been widely used in automatic
control and function approximation. In CMAC neural networks, the dependence of adjustable
parameters or weights with respect to outputs is linear. For detailed discussion on the structure of
CMAC neural networks, one may refer to Albus (1975) and Sutton & Barto (1998).
In the AHC and Fast-AHC learning controllers, two CMAC neural networks with four inputs
and one output for each are used as the function approximators in the critic and the actor,
respectively. Each CMAC has C tilings and M partitions for every input. So the total physical
memory for each CMAC network is M4C. To reduce the computation and memory requirements,
a hashing technique described by the following equations is employed in our experiments. (For
detailed discussion on the parameters of the CMAC networks, please refer to Appendix C).
A( s ) =

4

∑ [a(i) + M i −1 ]

(50)

i =1

F(s)=A(s) mod K
(51)
In (50) and (51), s represents an input state vector, a(i) (0≤ a(i) ≤M) is the activated tile for
the i-th element of s, K is the total number of the physical memory and F(s) is the physical
memory address corresponding to the state s, which is the remainder of A(s) divided by K.
In order to compare the performance of different learning algorithms, the initial parameters of
each learning controller are selected as follows: The weights of the critic are all initialized to 0
and the weights of the actor are initialized to random numbers in interval [0,0.1]. The other
parameters for the AHC and Fast-AHC algorithms are γ = 0.95 , k1 = 0.4 and k 2 = 0.5 .
In all the experiments, a trial is defined as the period from an initial state to a failure state and
the initial state of each trial is set to a randomly generated state near the unstable equilibrium
(0,0,0,0) with a maximum distance of 0.05. Equation (49) is employed to simulate the dynamics
of the system using the Euler method, which has a time step of 0.02s. When a trial lasts for more
than 120,000 time steps, it is said to be successful and the learning controller is assumed to be
able to balance the pole. The reinforcement signal for the problem is defined as

− 1, if failure occurs
rt = 
 0, otherwise

(52)

The performance of the Fast-AHC method is tested extensively, where different parameter
settings including λ and the initial variance matrix P0 are chosen. In the experiments, the
278

EFFICIENT REINFORCEMENT LEARNING USING RLS METHODS

forgetting factor of RLS-TD(λ) in the critic is set to a value that is equal to 1 or very close to 1.
The learning control experiments using conventional AHC methods are also conducted for
comparison. The performance comparisons between the two algorithms are shown in Figure 9, 10
and 11.
In the above experiments, the initial variance matrixes of the Fast-AHC algorithm are all set
to P0=0.1I. The performance of Fast-AHC is compared with AHC for different λ. The numbers of
physical memories of the critic network and the actor network are chosen as 30 and 80,
respectively. For each parameter setting of the two algorithms, 5 independent runs are tested. The
performance is evaluated according to the trial number needed to successfully balance the pole.
The learning factors for the actor networks are all set to 0.5, which is a manually optimized value
for both algorithms. In all the experiments, 11 settings of λ are tested.

Figure 9: Performance comparison between Fast-AHC and AHC with α=0.01

Figure 10: Performance comparison between Fast-AHC and AHC with α=0.03
279

XU, HE, & HU

Figure 11: Performance comparison between Fast-AHC and AHC with α=0.05

In Figure 9, 10 and 11, the learning factors of the critic networks in AHC are chosen as
α=0.01, 0.03 and 0.05, respectively. It is found that when α<0.01, the performance of AHC
becomes worse. For the learning factors that are greater than 0.05, the AHC algorithm may
become unstable, and even when α=0.03 and α=0.05, the AHC algorithm becomes unstable for
λ=1. For the time-varying learning factors specified in (s1)-(s3), the performance is worse than
the above constant learning factors. So the above three settings of the learning factor α are typical
and near optimal for the AHC algorithm.
From the above experimental results, it can be concluded that by using RLS-TD(λ) in the
critic network, the Fast-AHC algorithm can obtain better performance than conventional AHC
algorithms. Although Fast-AHC requires more computation per step than AHC, it is more
efficient than AHC in that less trials or data are needed to successfully balance the pole.
As has been discussed in the previous sections, the convergence performance of RLS-TD(λ)
is influenced by the initial value of the variance matrix. This is also the case in Fast-AHC. In the
above learning control experiments, a small value δ=0.1 is selected. In other experiments, when δ
is set to other small values, the performance of Fast-AHC is satisfactory and is better than AHC.
However, when δ is equal to a relatively large value, for example δ=100 or 500, the performance
of Fast-AHC deteriorates significantly. Since RLS-TD(λ) with a large initializing constant has
similar performance as LS-TD(λ), it can be deduced that the AHC method using LS-TD(λ) in the
critic will also have bad performance in the cart-pole balancing problem. To verify this,
experiments are conducted using Fast-AHC with large initializing constant δ and AHC using
LS-TD(λ). For each parameter setting, 5 independent runs are tested. In the experiments, the
maximum trials for each algorithm in one run is 200 so that if an algorithm fails to balance the
pole within 200 trials, its performance is set to 200.When using LS-TD(λ) in the AHC method,
there may be computational problems in the matrix inversion during the first few steps of learning
and two methods are tried to avoid this problem. One is the usage of TD(λ) in the first 60 steps of
updates. The other is that the actor is not updated in the early stage of learning until LS-TD(λ) is
280

EFFICIENT REINFORCEMENT LEARNING USING RLS METHODS

stable. However, similar results are found for the two methods. Figure 12 shows the experimental
results which clearly verify that the performance of Fast-AHC with a large initializing constant δ
is similar to AHC using LS-TD(λ) and it is much worse than Fast-AHC with a small δ. A detailed
discussion of this phenomenon is provided in subsection 5.4.

Figure 12: Performance comparison of Fast-AHC with different initial variance
In the following Figure 13 and Figure 14, the variations of the pole angle θ and the control
force F are plotted, where a successfully trained Fast-AHC learning controller is used to control
the cart-pole system.

Figure 13: Variation of the pole angle

Figure 14: Variation of the control force

5.3 Learning Control Experiments of The Acrobot

In this subsection, another learning control example, which is the swing-up control of the acrobot
in minimum time, is presented. The learning control of the acrobot is a class of adaptive optimal
control problem that is more difficult than the pole-balancing problem. It has been investigated in
Sutton (1996), where CMAC-based Sarsa-learning algorithms were employed to solve it and only
the case of discrete control actions was studied. In our experiments, the case of continuous actions
281

XU, HE, & HU

is considered.
An acrobot moving in the vertical plane is shown in Figure 15, where OA and AB are the first
link and the second link, respectively. The control torque is applied at point A. The goal of the
swing-up control is to swing the tip B of the acrobot above the line CD which is higher than the
joint O by an amount of the length of one link.

Figure 15: The acrobot
The dynamics of the acrobot system is described by the following equations.

θ&&1 = −(d 2θ&&2 + φ1 ) / d1

(53)

θ&&2 = (τ + d 2φ1 / d1 − φ 2 )

(54)

d1 = m1l c21 + m2 (l12 + l c22 + 2l1l c 2 cosθ 2 ) + I 1 + I 2

(55)

d 2 = m2 (l c22 + l1l c 2 cosθ 2 ) + I 2

(56)

φ1 = −m2 l1l c 2θ&22 sin θ 2 − 2m2 l1l c 2θ&1θ&2 sin θ 2 + (m1l c1 + m2 l1 ) g cos(θ 1 − π / 2) + φ 2

(57)

φ 2 = m2 l c 2 g cos(θ 1 + θ 2 − π / 2)

(58)

where

In the above equations, the parameters θ i , θ&i , mi , li , I i , l ci are the angle, the angle velocity,
the mass, the length, the moment of inertia and the length of the center of mass for link i (i=1,2),
respectively.
Let sT denote the goal state of the swing-up control. Since the control aim is to swing up the
acrobot in minimum time, the reward function rt is defined as
1, if s = sT
rt = 
0, else

(59)

In the simulation experiments, the control torque τ is continuous and is bounded by [-3N, 3N].
Similar to the cart-pole balancing problem, CMAC neural networks are applied to solve the above
282

EFFICIENT REINFORCEMENT LEARNING USING RLS METHODS

learning control problem with continuous states and actions. In the CMAC-based actor-critic
controller, the actor network and the critic network both have C=4 tilings and M=7 partitions for
each input. In the actor network, uniform coding is employed and non-uniform coding is used in
the critic network. For details of the coding parameters, please refer to Appendix C. The sizes of
the physical memories for the actor network and the critic network are 100 and 80, respectively.
In the CMAC networks, the following hashing techniques are used. (For the definition of A(s),a(i)
and F(s), please refer to Subsection 5.2.)
4

A( s ) = ∑ [ a(i ) × M i −1 ]

(60)

i =1

F(s)=A(s) mod K
(61)
In the simulation, the parameters for the acrobot are chosen as m1=m2=1kg, I1=I2=1kgm2,
lc1=lc2=0.5m, l1=l2=1m and g=9.8m/s2. The time step for simulation is 0.05s and the time interval
for learning control is 0.2s. The learning parameters are λ=0.6, γ=0.90, β=0.2, k1=0.4, k2=0.5. A
trial is defined as the period that starts from the stable equilibrium and ends when the goal state is
reached. After each trial, the state of the acrobot is re-initialized to its stable equilibrium. For each
parameter setting, 5 independent runs are tested. Each run consists of 50 trials and after 50-th trial,
the actor network is tested by controlling the acrobot alone, i.e., by setting the action variance
defined in (43) to zero. The performance of the algorithms is evaluated according to the steps
used by the actor networks to swing up the acrobot.
The performance comparisons between Fast-AHC and AHC are shown in Figure 16,17 and
18. In the experiments, both algorithms are tested with different λ and AHC is also tested with
different learning factors of the critic networks.
From the results, it is also shown that Fast-AHC can achieve higher data efficiency than AHC.
However, in this example, a relatively large δ is used, which is different from the previous
cart-pole balancing example. In other experiments, good performance is obtained with large
initializing constant and when δ is very small, the performance deteriorates significantly. Thus
this problem may be referred to the low SNR case in Moustakides (1997), where large values of
δ are preferable for best convergence rate of RLS methods.

Figure 16: Performance comparison between Fast-AHC and AHC with α=0.02
283

XU, HE, & HU

Figure 17: Performance comparison between Fast-AHC and AHC with α=0.05

Figure 18: Performance comparison between Fast-AHC and AHC with α=0.1

The following Figure 19 shows the performance comparison between Fast-AHC with a large
(300) and a small (0.01) value of δ , where 6 settings of the parameter λ are tested for each
algorithm. The performance of AHC using LS-TD(λ) is also shown. In Figure 20, a typical curve
of the angle of the first link is plotted, where the acrobot is controlled by the actor network of the
Fast-AHC method (λ=0.6) after 50 trials.

284

EFFICIENT REINFORCEMENT LEARNING USING RLS METHODS

Figure 19: Performance comparison of Fast-AHC and AHC using LS-TD(λ)

Figure 20: Variation of the angle of link 1(Controlled by Fast-AHC after 50 trials)

5.4

Analysis of The Experimental Results

Based on the above experimental results, it can be concluded that by using the RLS-TD(λ)
algorithm in the critic network, the Fast-AHC algorithm can obtain better performance than
conventional AHC algorithms in that less trials or data are needed to converge to a near optimal
policy. As is well known, one difficulty for the applications of RL methods is their slow
convergence, especially in the cases where learning data are hard to be generated. For the
Fast-AHC algorithm, although more computation per step is required than conventional AHC
methods, it will not be a serious problem when the number of linear state features is small. In all
of our learning control experiments, hashing techniques are used to reduce the state features in
CMAC networks so that the computation of Fast-AHC can be reduced to an economical amount.
Nevertheless, when the state feature number is large, conventional AHC methods may be
preferable.
In the experiments, it is observed that the performance of Fast-AHC is affected by the
initializing constant δ. These results are consistent with the property of RLS-TD(λ) and the RLS
285

XU, HE, & HU

method in adaptive filtering, which has been discussed in Section 4. In the learning control
experiments of the cart-pole balancing problem, better performance of Fast-AHC is obtained by
using small values of δ. While in the learning control of the acrobot, higher data efficiency is
achieved using Fast-AHC with a relatively large δ. These two different properties of Fast-AHC
may be referred to the different SNR cases for RLS methods (Moustakides,1997). A thorough
theoretical analysis on this problem is an interesting topic for future research.
In our experiments, the performance of the AHC method using LS-TD(λ) is also tested. As
has been studied in Section 4, when the initializing constant δ is large, the performance of
RLS-TD(λ) and LS-TD(λ) does not differ much. So the performance of AHC using LS-TD(λ) is
similar to that of Fast-AHC with large values of δ.
As studied in Moustakides (1997), the RLS method can converge much faster than other
adaptive filtering methods if the environment is stationary and the initializing constant is selected
appropriately. In some cases, RLS may converge almost instantly. This is also verified in the
learning prediction experiments of the RLS-TD(λ) algorithm. When applying RLS-TD(λ) in an
actor-critic learning controller, although the policy of the actor will change over time, it can still
be assumed that the changing speed of the policy is slow when compared with the fast
convergence speed of RLS-TD(λ). Thus good performance of learning prediction can be obtained
in the critic. Moreover, since the learning prediction performance of the critic is important to the
policy learning of the actor, the improvement in learning prediction efficiency will contribute to
the whole performance improvement of the controller.
6. Conclusions and Future Work

Two new reinforcement learning algorithms using RLS methods, which are called RLS-TD( λ )
and Fast-AHC, respectively, are proposed in this paper. RLS-TD( λ ) can be used to solve learning
prediction problems more efficiently than conventional linear TD( λ ) algorithms. The
convergence with probability 1 is proved for RLS-TD( λ ) and the limit of convergence is also
analyzed. Experimental results on learning prediction problems show that the RLS-TD( λ )
algorithm is superior to conventional TD( λ ) algorithms in data efficiency and it also eliminates
the design problem of the step sizes in linear TD( λ ) algorithms. RLS-TD( λ ) can be viewed as
the extension of RLS-TD(0) from λ =0 to general 0< λ ≤1. Although the effect of λ on the
convergence speed of RLS-TD( λ ) may not be significant in some cases, the usage of λ >0 will
still affect the approximation error bound. Thus, when there are needs for value function
estimation with high precision, large values of λ are preferable to λ =0. Furthermore, RLSTD( λ ) is superior to LS-TD( λ ) in computation when the weight vector must be updated after
every observations.
Since learning prediction can be viewed as a sub-problem of learning control, we extend the
results in learning prediction to a learning control method called the AHC algorithm. Using
RLS-TD( λ ) in the critic network, Fast-AHC can achieve better performance than conventional
AHC method in data efficiency. Simulation results on the learning control of the pole-balancing
problem and the acrobot system confirm the above analyses.
In the experiments, it is found that the performance of RLS-TD( λ ) as well as Fast-AHC is
influenced by the initializing constant δ of RLS methods. Different values of δ are needed for best
performance in different cases. This is also a well-known phenomenon in RLS-based adaptive
286

EFFICIENT REINFORCEMENT LEARNING USING RLS METHODS

filtering and the theoretical results in Moustakides (1997) provide some basis for the explanations
of our results. A complete investigation of this problem is our ongoing work.
The idea of using RLS-TD( λ ) in the critic network may be applied to other reinforcement
learning methods with actor-critic architectures. In Konda and Tsitsiklis (1998), a new actor-critic
algorithm using linear function approximators is proposed and the convergence under certain
conditions is proved. One condition for the convergence of this algorithm is that the convergence
rate of the critic is much faster than that of the actor. Thus the application of RLS-TD( λ ) in the
critic may be preferable in order to ensure the convergence of the algorithm. The theoretical and
empirical work on this problem deserves to be studied in the future.

Acknowledgements
This work is supported by the National Natural Science Foundation of China under Grants
60075020, 60171003 and China University Key Teacher’s Fellowship. We would very much like
to thank the anonymous reviewers and Associate Editor Michael L. Littman for their insights and
constructive criticisms, which have helped improve the paper significantly.

287

XU, HE, & HU

Appendix A. Derivation of the RLS-TD(λ) Algorithm

For the derivation of RLS-TD(λ), there are two different cases, which are determined by the value
of the forgetting factor.
(1) RLS-TD(λ) with a unit forgetting factor.
Since

Pt = At−1

(62)

P0 = δI

(63)

r
K t +1 = Pt +1 z t

(64)

According to Lemma 1,

Pt +1 = At−+11

r
r
= Pt − Pt z t [1 + (φ T ( xt ) − γφ T ( x t +1 )) Pt z t )] −1 (φ T ( x t ) − γφ T ( xt +1 )) Pt

r
K t +1 = Pt +1 z t
r
r
= Pt z t /(1 + (φ T ( xt ) − γφ T ( xt +1 )) Pt z t )

(65)

(66)

Wt +1 = At−+11bt +1
t
r
= Pt +1 ( ∑ z i ri )

(67)

i =0

r
= Pt +1 ( Pt −1Wt + z t rt )
Thus

r
r
Wt +1 = Pt +1 [( Pt −+11 − z t (φ T ( xt ) − γφ T ( x t +1 )))Wt + z t rt ]
r
r
= Wt + Pt +1 ( z t rt − z t (φ T ( xt ) − γφ T ( x t +1 ))Wt )

(68)

= Wt + K t +1 [rt − (φ T ( xt ) − γφ T ( xt +1 ))Wt ]
(2) RLS-TD(λ) with a forgetting factor µ<1
The derivation of RLS-TD(λ) with a forgetting factor µ<1 is similar to the exponentially weighted
RLS algorithm in Haykins (1996, pp.566-569). Here we only present the results:

Pt +1 =

1

µ

r
r
K t +1 = Pt z t /( µ + (φ T ( x t ) − γφ T ( x t +1 )) Pt z t )

(69)

Wt +1 = Wt + K t +1 (rt − (φ T ( x t ) − γφ T ( xt +1 ))Wt )

(70)

r
r
[ Pt − Pt z t [ µ + (φ T ( xt ) − γφ T ( xt +1 )) Pt z t )]−1 (φ T ( xt ) − γφ T ( xt +1 )) Pt ]

288

(71)

EFFICIENT REINFORCEMENT LEARNING USING RLS METHODS

Appendix B. Proof of Theorem 1
To study the steady property of the Markov chain defined in Section 3, we construct a stationary
process as follows. Let {xt} be a Markov chain that evolves according to the transition matrix P and is
already in its steady state, which means that Pr{xt=i}= π (i) for all i and t. Given any sample path of
the Markov chain, we define

r
zt =

t

∑ (γλ ) t −τ φ ( xτ )

(72)

τ = −∞

r

Then X t = {xt , xt +1 , z t } is a stationary process, which is the same as that discussed in (Tsitsiklis
and Roy, 1997).
Let D denote a N×N diagonal matrix with diagonal entries π (1), π (2),…, π (N), where N is
the cardinality of state space X. Then Lemma 2 can be derived as follows.
Lemma 2. (Tsitsiklis and Roy, 1997) Under Assumption 1-4, the following equations hold.
1) E 0 [φ ( xt )φ ( xt + m )] = Φ T DP m Φ , for m>0

r
2) E 0 [ z t φ T ( xt )] =

(73)

∞

∑ (γλ ) m Φ T DP m Φ ,

(74)

m =0

r
3) E 0 [ z t rt ( xt , xt +1 )] =

∞

∑ (γλ ) m Φ T DP m r

(75)

m =0

where r ∈ R N , whose Nth component is equal to E[r ( xt , xt +1 ) xt = i ] .
According to Lemma 2, E0[A(Xt)] and E0[b(Xt)] are well defined and finite. Furthermore, E0[A(Xt)]
is negative definite, so it is invertible.
From equation (67),
T

T

WRLS −TD ( λ ) = [ P0−1 + ∑ A( X t )] −1 [ P0−1W0 + ∑ b( X t )]
t =1

t =1

1
1
1
1 T
= [ P0−1 + ∑ A( X t )] −1 [ P0−1W0 + ∑ b( X t )]
T
T t =1
T
T t =1
T

(76)

Since

1 T
∑ A( X t )
T →∞ T
t =1

(77)

1 T
∑ b( X t )
T →∞ T
t =1

(78)

E 0 [ A( X t )] = lim

E 0 [b( X t )] = lim
and E0[A(Xt)] is invertible,
−1

lim W RLS −TD ( λ ) = E 0 [ A( X t )]E 0 [b( X t )] = W *

T →∞

289

(79)

XU, HE, & HU

Thus W RLS −TD ( λ ) converges to W* with probability 1.

Appendix C. Some details of the coding structures of CMAC networks
In the following discussion, the coding structures of CMAC networks in the cart-pole balancing
problem and the acrobot control problem are presented.
(1) CMAC coding structures in the cart-pole balancing problem
In the CMAC networks, the state variables have the following boundaries.

θ ∈ [−12 o ,12 o ] ,

θ& ∈ [−50 deg/ s, 50 deg/ s]

x ∈ [−2.4, 2.4] ,
x& ∈ [−1,1]
For the critic network, C=4 and M=7. The hashing technique specified in equations (50) and (51)
is employed and the total memory size is 30.
For the actor network, C=4 and M=7. The hashing technique specified in equations (60) and (61)
is employed and the total memory size is 100.
(2) CMAC coding structures in the acrobot swing-up problem
In the simulation, the angles are bounded by [−π , π ] and the angular velocities are bounded by

θ&1 ∈ [−4π ,4π ] , θ&2 ∈ [−9π ,9π ] . The tiling numbers of the actor and the critic both are equal to 4
(C=4). The total memory sizes for the critic and the actor are 80 and 100, respectively. In the actor
network, each tiling partitions the range of each input into 7 equal intervals (M=7). In the critic
network, the partitions for each input are non-uniform, which are given by

θ 1 : { -π, -1, -0.5, 0, 0.5, 1, π},

θ&1 : {-4π, -1.5π, -0.5π, 0, 0.5π, 1.5π, 4π}

θ 2 : {-π, -1, -0.5, 0, 0.5, 1, π},

θ&2 : {-9π, -2π, -0.5π,0, 0.5π,2π, 9π}

290

EFFICIENT REINFORCEMENT LEARNING USING RLS METHODS

References
Albus,J.S.(1975). A new approach to manipulator control: the cerebellar model articulation
controller (CMAC). Journal of Dynamic Systems, Measurement, and Control, 97(3), 220-227.
Barto,A.G., Sutton R.S., & Anderson C.W. (1983). Neuronlike adaptive elements that can solve
difficult learning control problems. IEEE Transactions on System, Man, and Cybernetics,13,
834-846.
Bertsekas D.P. & Tsitsiklis J.N. (1996). Neurodynamic Programming. Belmont, Mass.: Athena
Scientific.
Berenji H.R. & Khedkar P. (1992). Learning and tuning fuzzy logic controllers through reinforcements, IEEE Trans.On Neural Networks, 3(5), 724-740.
Boyan. J.(1999). Least-squares temporal difference learning. In Bratko, I., and Dzeroski, S., eds.,
Machine Learning: Proceedings of the Sixteenth International Conference (ICML).
Boyan, J.(2002). Technical update: least-squares temporal difference learning. Machine Learning,
Special Issue on Reinforcement Learning, to appear.
Brartke. S.J. & Barto A. (1996). Linear least-squares algorithms for temporal difference learning.
Machine Learning, 22, 33-57.
Dayan P.(1992). The convergence of TD(λ) for general λ. Machine Learning, 8, 341-362.
Dayan P.. & Sejnowski T.J. (1994). TD(λ) converges with probability 1. Machine Learning, 14,
295-301.
Eleftheriou E. & Falconer,D.D. (1986). Tracking properties and steady state performance of RLS
adaptive filter algorithms. IEEE Transactions on Acoustics, Speech, and Signal Processing, 34,
1097-1110.
Eweda E. & Macchi, O. (1987). Convergence of the RLS and LMS adaptive filters. IEEE Trans.
Circuits and Systems, 34, 799-803.
Haykin S. (1996), Adaptive Filter Theory, 3rd edition, Englewood Cliffs, NJ: Prentice-Hall.
Hubing N.E. & Alexander S.T. (1989). Statistical analysis of the soft constrained initialization of
RLS algorithms. In Proc. of the IEEE International Conference on Acoustics, Speech and
Signal Processing.
Jaakkola T., Jordan M.I., & Singh S.P. (1994). On the convergence of stochastic iterative dynamic
programming algorithms. Neural Computation. 6(6), 1185-1201.
Kaelbling L.P., Littman M.L., & Moore A.W. (1996). Reinforcement learning: a survey. Journal
of Artificial Intelligence Research, 4, 237-285.
Konda V.R, & Tsitsiklis J.N. (2000). Actor-critic algorithms. In Neural Information Processing
Systems, 2000, MIT Press.
291

XU, HE, & HU

Lin L.J. (1992). Self-improving reactive agents based reinforcement learning, planning and
teaching. Machine Learning, 8(3/4), 293-321.
Lin C.T. & Lee C.S.G. (1994). Reinforcement structure/parameter learning for neural-networkbased fuzzy Logic control system. IEEE Transactions on Fuzzy System, 2(1), 46-63.
Ljung L. & Soderstron T. (1983). Theory and Practice of Recursive Identification. MIT Press.
Ljung L. (1977). Analysis of recursive stochastic algorithm. IEEE. Transactions on Automatic
Control, 22, 551.
Michie D. & Chambers R.A. (1968). BOXES: An experiment in adaptive control. Machine
Intelligence 2, Dale E. and Michie D., eds., Edinburgh: Oliver and Boyd, 137-152.
Minsky M.L. (1954). Theory of neural-analog reinforcement systems and its application to the
brain-model problem. Ph.D. Thesis, Princeton University.
Moustakides G.V. (1997). Study of the transient phase of the forgetting factor RLS. IEEE Trans.
on Signal Processing, 45(10), 2468-2476.
Samuel A.L. (1959). Some studies in machine learning using game of checkers. IBM Journal on
Research and Development, 3, 211-229.
Singh, S.P., Jaakkola T., Littman M.L., & Szepesvari C. (2000). Convergence results for singlestep on-policy reinforcement-learning algorithms. Machine Learning, 38, 287-308.
Sutton R. & Barto A. (1998). Reinforcement Learning, an Introduction. Cambridge MA, MIT
Press.
Sutton R. (1988). Learning to predict by the method of temporal differences. Machine Learning,
3(1), 9-44.
Tsitsiklis J.N. (1994). Asynchronous stochastic approximation and Q-learning. Machine Learning,
16, 185-202.
Tsitsiklis J.N. & Roy B.V. (1994). Feature-based methods for large scale dynamic programming.
Neural Computation. 6(6), 1185-1201.
Tsitsiklis J.N. & Roy B.V. (1997). An analysis of temporal difference learning with function
approximation. IEEE Transactions on Automatic Control. 42(5), 674-690.
Watkins C.J.C.H. & Dayan P. (1992). Q-Learning. Machine Learning. 8, 279-292.
Young P. (1984). Recursive Estimation and Time-Series Analysis. Springer-Verlag.

292

Journal of Artificial Intelligence Research 16 (2002) 1-58

Submitted 7/01; published 1/02

Fusions of Description Logics and
Abstract Description Systems
Franz Baader
Carsten Lutz

baader@cs.rwth-aachen.de
lutz@cs.rwth-aachen.de

Teaching and Research Area for Theoretical Computer Science,
RWTH Aachen, Ahornstraße 55, 52074 Aachen, Germany

Holger Sturm

holger.sturm@uni-konstanz.de

Fachbereich Philosophie, Universität Konstanz,
78457 Konstanz, Germany

Frank Wolter

wolter@informatik.uni-leipzig.de

Institut für Informatik, Universität Leipzig,
Augustus-Platz 10-11, 04109 Leipzig, Germany

Abstract
Fusions are a simple way of combining logics. For normal modal logics, fusions have
been investigated in detail. In particular, it is known that, under certain conditions, decidability transfers from the component logics to their fusion. Though description logics
are closely related to modal logics, they are not necessarily normal. In addition, ABox
reasoning in description logics is not covered by the results from modal logics.
In this paper, we extend the decidability transfer results from normal modal logics to
a large class of description logics. To cover different description logics in a uniform way,
we introduce abstract description systems, which can be seen as a common generalization
of description and modal logics, and show the transfer results in this general setting.

1. Introduction
Knowledge representation systems based on description logics (DL) can be used to represent the knowledge of an application domain in a structured and formally well-understood
way (Brachman & Schmolze, 1985; Baader & Hollunder, 1991; Brachman, McGuinness,
Patel-Schneider, Alperin Resnick, & Borgida, 1991; Woods & Schmolze, 1992; Borgida,
1995; Horrocks, 1998). In such systems, the important notions of the domain can be described by concept descriptions, i.e., expressions that are built from atomic concepts (unary
predicates) and atomic roles (binary predicates) using the concept constructors provided
by the description logic employed by the system. The atomic concepts and the concept
descriptions represent sets of individuals, whereas roles represent binary relations between
individuals. For example, using the atomic concepts Woman and Human, and the atomic
role child, the concept of all women having only daughters (i.e., women such that all their
children are again women) can be represented by the description Woman u ∀child.Woman,
and the concept of all mothers by the description Woman u ∃child.Human. In this example,
we have used the constructors concept conjunction (u), value restriction (∀R.C), and existential restriction (∃R.C). In the DL literature, also various other constructors have been
considered. A prominent example are so-called number restrictions, which are available in
almost all DL systems. For example, using number restrictions the concept of all women
c
2002
AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

Baader, Lutz, Sturm, & Wolter

having exactly two children can be represented by the concept description
Woman u (≤ 2child) u (≥ 2child).
The knowledge base of a DL system consists of a terminological component (TBox) and
an assertional component (ABox). In its simplest form, the TBox consists of concept
definitions, which assign names (abbreviations) to complex descriptions. More general TBox
formalisms allow for so-called general concept inclusion axioms (GCIs) between complex
descriptions. For example, the concept inclusion
Human u (≥ 3child) v ∃entitled.Taxbreak
states that people having at least three children are entitled to a tax break. The ABox
formalism consists of concept assertions (stating that an individual belongs to a concept)
and role assertions (stating that two individuals are related by a role). For example, the
assertions Woman(MARY), child(MARY, TOM), Human(TOM) state that Mary is a woman,
who has a child, Tom, who is a human.
DL systems provide their users with various inference capabilities that allow them to
deduce implicit knowledge from the explicitly represented knowledge. For instance, the subsumption problem is concerned with subconcept-superconcept relationships: C is subsumed
by D (C v D) if, and only if, all instances of C are also instances of D, i.e., the first description is always interpreted as a subset of the second description. For example, the concept
description Woman obviously subsumes the concept description Woman u ∀child.Woman.
The concept description C is satisfiable iff it is non-contradictory, i.e., it can be interpreted
by a nonempty set. In DLs allowing for conjunction and negation of concepts, subsumption can be reduced to (un)satisfiability: C v D iff C u ¬D is unsatisfiable. The instance
checking problem consists of deciding whether a given individual is an instance of a given
concept. For example, w.r.t. the assertions from above, MARY is an instance of the concept
description Woman u ∃child.Human. The ABox A is consistent iff it is non-contradictory,
i.e., it has a model. In DLs allowing for negation of concepts, the instance problem can be
reduced to (in)consistency of ABoxes: i is an instance of C w.r.t. the ABox A iff A∪{¬C(i)}
is inconsistent.
In order to ensure a reasonable and predictable behavior of a DL system, reasoning
in the DL employed by the system should at least be decidable, and preferably of low
complexity. Consequently, the expressive power of the DL in question must be restricted in
an appropriate way. If the imposed restrictions are too severe, however, then the important
notions of the application domain can no longer be expressed. Investigating this trade-off
between the expressivity of DLs and the complexity of their inference problems has thus
been one of the most important issues in DL research (see, e.g., Levesque & Brachman,
1987; Nebel, 1988; Schmidt-Schauß, 1989; Schmidt-Schauß & Smolka, 1991; Nebel, 1990;
Donini, Lenzerini, Nardi, & Nutt, 1991, 1997; Donini, Hollunder, Lenzerini, Spaccamela,
Nardi, & Nutt, 1992; Schaerf, 1993; Donini, Lenzerini, Nardi, & Schaerf, 1994; De Giacomo
& Lenzerini, 1994a, 1994b, 1995; Calvanese, De Giacomo, & Lenzerini, 1999; Lutz, 1999;
Horrocks, Sattler, & Tobies, 2000).
This paper investigates an approach for extending the expressivity of DLs that (in many
cases) guarantees that reasoning remains decidable: the fusion of DLs. In order to explain
2

Fusions of Description Logics and Abstract Description Systems

the difference between the usual union and the fusion of DLs, let us consider a simple
example. Assume that the DL D1 is ALC, i.e., it provides for the Boolean operators u, t,
¬ and the additional concept constructors value restriction ∀R.C and existential restriction
∃R.C, and that the DL D2 provides for the Boolean operators and number restrictions
(≤ nR) and (≥ nR). If an application requires concept constructors from both DLs for
expressing its relevant concepts, then one would usually consider the union D1 ∪ D2 of D1
and D2 , which allows for the unrestricted use of all constructors. For example, the concept
description C1 := (∃R.A) u (∃R.¬A) u (≤ 1R) is a legal D1 ∪ D2 description. Note that this
description is unsatisfiable, due to the interaction between constructors of D1 and D2 . The
fusion D1 ⊗D2 of D1 and D2 prevents such interactions by imposing the following restriction:
one assumes that the set of all role names is partitioned into two sets, one that can be used
in constructors of D1 , and another one that can be used in constructors of D2 . Thus, the
description C1 from above is not a legal D1 ⊗ D2 description since it uses the same role R
both in the existential restrictions (which are D1 -constructors) and in the number restriction
(which is a D2 -constructor). In contrast, the descriptions (∃R1 .A) u (∃R1 .¬A) u (≤ 1R2 )
and (∃R1 .(≤ 1R2 )) are admissible in D1 ⊗ D2 since they employ different roles in the D1 and D2 -constructors. If the concepts that must be expressed are such that they require
both constructors from D1 and D2 , but the ones from D1 for other roles than the ones from
D2 , then one does not really need the union of D1 and D2 ; the fusion would be sufficient.
What is the advantage of taking the fusion instead of the union? Basically, for the union
of two DLs one must design new reasoning methods, whereas reasoning in the fusion can be
reduced to reasoning in the component DLs. Indeed, reasoning in the union may even be
undecidable whereas reasoning in the fusion is still decidable. As an example, we consider
the DLs (i) ALCF, which extends the basic DL ALC by functional roles (features) and
the same-as constructor (agreement) on chains of functional roles (Hollunder & Nutt, 1990;
Baader, Bürckert, Nebel, Nutt, & Smolka, 1993); and (ii) ALC +,◦,t , which extends ALC by
transitive closure, composition, and union of roles (Baader, 1991; Schild, 1991). For both
DLs, subsumption of concept descriptions is known to be decidable (Hollunder & Nutt,
1990; Schild, 1991; Baader, 1991). However, their union ALCF +,◦,t has an undecidable
subsumption problem (Baader et al., 1993). This undecidability result depends on the fact
that, in ALCF +,◦,t , the role constructors transitive closure, composition, and union can
be applied to functional roles that also appear within the same-as constructor. This is not
allowed in the fusion ALCF ⊗ ALC +,◦,t . Of course, failure of a certain undecidability proof
does not make the fusion decidable.
Why do we know that the fusion of decidable DLs is again decidable? Actually, in
general we don’t, and this was our main reason for writing this paper. The notion “fusion” was introduced and investigated in modal logic, basically to transfer results like finite
axiomatizability, decidability, finite model property, etc. from uni-modal logics (with one
pair of box and diamond operators) to multi-modal logics (with several such pairs, possibly satisfying different axioms). This has led to rather general transfer results (see, e.g.,
Wolter, 1998; Kracht & Wolter, 1991; Fine & Schurz, 1996; Spaan, 1993; Gabbay, 1999
for results that concern decidability), which are sometimes restricted to so-called normal
modal logics (Chellas, 1980). Since there is a close relationship between modal logics and
DLs (Schild, 1991), it is clear that these transfer results also apply to some DLs. The question is, however, to which DLs exactly and to which inference problems. First, some DLs
3

Baader, Lutz, Sturm, & Wolter

allow for constructors that are not considered in modal logics (e.g., the same-as constructor
mentioned above). Second, some DL constructors that have been considered in modal logics, such as qualified number restrictions (≤ nR.C), (≥ nR.C) (Hollunder & Baader, 1991),
which correspond to graded modalities (Van der Hoek & de Rijke, 1995), can easily be
shown to be non-normal. Third, the transfer results for decidability are concerned with the
satisfiability problem (with or without general inclusion axioms). ABoxes and the related
inference problems are not considered. ABoxes can be simulated in modal logics allowing
for so-called nominals, i.e., names for individuals, within formulae (Prior, 1967; Gargov
& Goranko, 1993; Areces, Blackburn, & Marx, 2000). However, as we will see below, the
general transfer results do not apply to modal logics with nominals.
The purpose of this paper is to clarify for which DLs decidability of the component DLs
transfers to their fusion. To this purpose, we introduce so-called abstract description systems
(ADSs), which can be seen as a common generalization of description and modal logics.
We define the fusion of ADSs, and state four theorems that say under which conditions
decidability transfers from the component ADSs to their fusion. Two of these theorems
are concerned with inference w.r.t. general concept inclusion axioms and two with inference
without TBox axioms. In both cases, we first formulate and prove the results for the
consistency problem of ABoxes (more precisely, the corresponding problem for ADSs) and
then establish analogous results for the satisfiability problem of concepts.
From the DL point of view, the four theorems shown in this paper are concerned with
the following four decision problems:
(i) decidability of consistency of ABoxes w.r.t. TBox axioms (Theorem 17);
(ii) decidability of satisfiability of concepts w.r.t. TBox axioms; (Corollary 22);
(iii) decidability of consistency of ABoxes without TBox axioms (Theorem 29); and
(iv) decidability of satisfiability of concepts without TBox axioms (Corollary 34).
These theorems imply that decidability of the consistency problem and the satisfiability
problem transfers to the fusion for most DLs considered in the literature. The main exceptions (which do not satisfy the prerequisites of the theorems) are
(a) DLs that are not propositionally closed, i.e., do not contain all Boolean connectives;
(b) DLs allowing for individuals (called nominals in modal logic) in concept descriptions;
and
(c) DLs explicitly allowing for the universal role or for negation of roles.
Results from modal logic for problem (iv) usually require the component modal logics to
be normal. Our Theorem 29 is less restrictive, and thus also applies to DLs allowing for
constructors like qualified number restrictions.

2. Description logics
Before defining abstract description systems in the next section, we introduce the main
features of DLs that must be covered by this definition. To this purpose, we first introduce
4

Fusions of Description Logics and Abstract Description Systems

ALC, the basic DL containing all Boolean connectives, and the relevant inference problems.
Then, we consider different possibilities for extending ALC to more expressive DLs.
Definition 1 (ALC Syntax). Let NC , NR , and NI be countable and pairwise disjoint sets
of concept, role, and individual names, respectively. The set of ALC concept descriptions
is the smallest set such that
1. every concept name is a concept description,
2. if C and D are concept descriptions and R is a role name, then the following expressions are also concept descriptions:
• ¬C (negation), C u D (conjunction), C t D (disjunction),
• ∃R.C (existential restriction), and ∀R.C (value restriction).
We use > as an abbreviation of A t ¬A and ⊥ as an abbreviation for A u ¬A (where A is
an arbitrary concept name).
Let C and D be concept descriptions. Then C v D is a general concept inclusion axiom
(GCI). A finite set of such axioms is called a TBox.
Let C be a concept description, R a role name, and i, j individual names. Then C(i) is
a concept assertion and R(i, j) a role assertion. A finite set of such assertions is called an
ABox.
The meaning of ALC-concept descriptions, TBoxes, and ABoxes can be defined with
the help of a set-theoretic semantics.
Definition 2 (ALC Semantics). An ALC-interpretation I is a pair (∆I , ·I ), where ∆I
is a nonempty set, the domain of the interpretation, and ·I is the interpretation function.
The interpretation function maps
• each concept name A to a subset AI of ∆I ,
• each role name R to a subset RI of ∆I × ∆I ,
• each individual name i to an element iI of ∆I such that different names are mapped
to different elements (unique name assumption).
For a role name R and an element a ∈ ∆I we define RI (a) := {b | (a, b) ∈ RI }. The
interpretation function can inductively be extended to complex concepts as follows:
(¬C)I := ∆I \ C I
(C u D)I := C I ∩ DI
(C t D)I := C I ∪ DI
(∃R.C)I := {a ∈ ∆I | RI (a) ∩ C I 6= ∅}
(∀R.C)I := {a ∈ ∆I | RI (a) ⊆ C I }
An interpretation I is a model of the TBox T iff it satisfies C I ⊆ DI for all GCIs C v D
in T . It is a model of the ABox A iff it satisfies iI ∈ C I for all concept assertions C(i) ∈ A
and (iI , j I ) ∈ RI for all role assertions R(i, j) ∈ A. Finally, I is a model of an ABox
relative to a TBox iff it is a model of both the ABox and the TBox.
5

Baader, Lutz, Sturm, & Wolter

Given this semantics, we can now formally define the relevant inference problems.
Definition 3 (Inferences). Let C and D be concept descriptions, i an individual name,
T a TBox, and A an ABox. We say that C subsumes D relative to the TBox T (D vT C)
iff DI ⊆ C I for all models I of T . The concept description C is satisfiable relative to the
TBox T iff there exists a model I of T such that C I 6= ∅. The individual i is an instance of
C in the ABox A relative to the TBox T iff iI ∈ C I for all models of A relative to T . The
ABox A is consistent relative to the TBox T iff there exists a model of A relative to T .
These three inferences can also be considered without reference to a TBox: C subsumes
D (C is satisfiable) iff C subsumes D (C is satisfiable) relative to the empty TBox, and i
is an instance of C in A (A is consistent) iff i is an instance of C in A (A is consistent)
relative to the empty TBox.
We restrict our attention to DLs that are propositionally closed (i.e., allow for the
Boolean operators conjunction, disjunction, and negation). Consequently, subsumption
can be reduced to (un)satisfiability since C vT D iff C u ¬D is unsatisfiable relative to T .
Conversely, (un)satisfiability can be reduced to subsumption since C is unsatisfiable relative
to T iff C vT ⊥. For this reason, it is irrelevant whether we consider the subsumption or the
satisfiability problem in our results concerning the transfer of decidability of these problems
from component DLs to their fusion (informally called transfer results in the following).
Similarly, the instance problem can be reduced to the (in)consistency problem and vice
versa: i is an instance of C in A relative to T iff A ∪ {¬C(i)} is inconsistent relative to T ;
and A is inconsistent relative to T iff i is an instance of ⊥ in A relative to T , where i is an
arbitrary individual name. Consequently, it is irrelevant whether we consider the instance
problem or the consistency problem in our transfer results.
Finally, the satisfiability problem can be reduced to the consistency problem: C is satisfiable relative to T iff the ABox {C(i)} is consistent relative to T , where i is an arbitrary
individual name. However, the converse need not be true. It should be obvious that this
implies that a transfer result for the satisfiability problem does not yield the corresponding
transfer result for the consistency problem: from decidability of the consistency problem
for the component DLs we can only deduce decidability of the satisfiability problem in their
fusion. What might be less obvious is that a transfer result for the consistency problem need
not imply the corresponding transfer result for the satisfiability problem: if the satisfiability
problems in the component DLs are decidable, then the transfer result for the consistency
problem can just not be applied (since the prerequisite of this transfer result, namely, decidability of the consistency problem in the component DLs, need not be satisfied). However,
we will show that the method used to show the transfer result for the consistency problem
also applies to the satisfiability problem.
2.1 More expressive DLs
There are several possibilities for extending ALC in order to obtain a more expressive DL.
The three most prominent are adding additional concept constructors, adding role constructors, and formulating restrictions on role interpretations. In addition to giving examples
for such extensions, we also introduce a naming scheme for the obtained DLs. Additional
concept constructors are indicated by appending caligraphic letters to the language name,
role constructors by symbols in superscript, and restrictions on roles by letters in subscript.
6

Fusions of Description Logics and Abstract Description Systems

We start with introducing restrictions on role interpretations, since we need to refer to
such restrictions when defining certain concept constructors.
2.1.1 Restrictions on role interpretations
These restrictions enforce the interpretations of roles to satisfy certain properties, such as
functionality, transitivity, etc. We consider three prominent examples:
1. Functional roles. Here one considers a subset NF of the set of role names NR ,
whose elements are called features. An interpretation must map features f ∈ NF to
functional binary relations f I ⊆ ∆I × ∆I , i.e., relations satisfying ∀a, b, c.f I (a, b) ∧
f I (a, c) → b = c. We will sometimes treat functional relations as partial functions,
and write f I (a) = b rather than f I (a, b). ALC extended with features is denoted by
ALC f .
2. Transitive roles. Here one considers a subset NR+ of NR . Role names R ∈ NR+
are called transitive roles. An interpretation must map transitive roles R ∈ NR+ to
transitive binary relations RI ⊆ ∆I × ∆I . ALC extended with transitive roles is
denoted by ALC R+ .
3. Role hierarchies. A role inclusion axiom is an expression of the form R v S with
R, S ∈ NR . A finite set H of role inclusion axioms is called a role hierarchy. An
interpretation must satisfy RI ⊆ S I for all R v S ∈ H. ALC extended with a role
hierarchy H is denoted by ALC H(H) . If H is clear from the context or irrelevant, we
write ALCH instead of ALC H(H) .
The above restrictions can also be combined with each other. For example, ALC HR+ is ALC
with a role hierarchy and transitive roles.
Transitive roles in DLs were first investigated by Sattler (1996). Features were introduced in DLs by Hollunder and Nutt (1990) and (under the name “attributes”) in the
CLASSIC system (Brachman et al., 1991), in both cases in conjunction with feature agreements and disagreements (see concept constructors below). Features without agreements
and disagreements are, e.g., used in the DL SHIF (Horrocks & Sattler, 1999), albeit in a
more expressive “local” way, where functionality can be asserted to hold at certain individuals, but not necessarily on the whole model. According to our naming scheme, we indicate
the presence of features in a DL by the letter f in subscript.1
A remark on role hierarchies is also in order: in our definition, if H1 and H2 are different
role hierarchies, then ALC H(H1 ) and ALC H(H2 ) are different DLs. In the DL literature,
usually only one logic ALCH is defined and role hierarchies are treated like TBoxes, i.e.,
satisfiability and subsumption are defined relative to TBoxes and role hierarchies (see, e.g.,
Horrocks, 1998). For our purposes, however, it is more convenient to define one DL per role
hierarchy since distinct role hierarchies impose distinct restrictions on the interpretation of
roles. The advantages of this approach will become clear later on when frames and abstract
description systems are introduced.
1. Note that some authors (e.g., Horrocks & Sattler, 1999) use an appended F to denote local features.
Following Hollunder and Nutt (1990), we will use F to denote a DL that allows for feature agreements
(see below).

7

Baader, Lutz, Sturm, & Wolter

Name
Unqualified
number restrictions
Qualified
number restrictions
Nominals
Feature agreement
and disagreement

Syntax
≥nR
≤nR
≥nR.C
≤nR.C
I
u1 ↓u2
u1 ↑u2

Semantics
{a ∈ ∆I | |RI (a)| ≥ n}
{a ∈ ∆I | |RI (a)| ≤ n}
{a ∈ ∆I | |RI (a) ∩ C I | ≥ n}
{a ∈ ∆I | |RI (a) ∩ C I | ≤ n}
I I ⊆ ∆I with |I I | = 1
{a ∈ ∆I | ∃b ∈ ∆I . uI1 (a) = b = uI2 (a)}
{a ∈ ∆I | ∃b1 , b2 ∈ ∆I .
uI1 (a) = b1 6= b2 = uI2 (b1 )}

Symbol
N
Q
O
F

Figure 1: Some description logic concept constructors.
2.1.2 Concept constructors
Concept constructors take concept and/or role descriptions and transform them into more
complex concept descriptions. In addition to the constructors available in ALC, various
other concept constructors are considered in the DL literature. A small collection of such
constructors can be found in Figure 1, where |S| denotes the cardinality of a set S. The
symbols in the rightmost column indicate the naming scheme for the resulting DL. As
mentioned above the name modifiers for concept constructors are not written in subscript,
they are appended to the language name. For example, ALC HR+ extended with qualified
number restrictions is called ALCQHR+ . The syntax of the extended DLs is as expected, i.e.,
the constructors may be arbitrarily combined. The semantics is obtained by augmenting
the semantics of ALC with the appropriate conditions, which can be found in the third
column in Figure 1. Nominals and feature (dis)agreements need some more explanation:
• Nominals. We consider a set NO of (names for) nominals, which is pairwise disjoint
to the sets NC , NR , and NI . Elements from NO are often denoted by I (possibly
with index). An interpretation must map nominals to singleton subsets of ∆I . The
intention underlying nominals is that they stand for elements of ∆, just like individual
names. However, since we want to use the nominal I ∈ NO as a (nullary) concept
constructor, I must interpret them by a set, namely the singleton set consisting of
the individual that I denotes.
• Feature (dis)agreements. ALCF is the extension of ALC f with feature agreements
and disagreements. Beside the additional concept constructors, ALCF uses feature
chains as part of the (dis)agreement constructor. A feature chain is an expression of
the form u = f1 ◦ · · · ◦ fn . The interpretation uI of such a feature chain is just the
composition of the partial functions f1I , . . . , fnI , where composition is to be read from
left to right.
DLs including nominals or feature (dis)agreements and additional concept constructors or
restrictions on role interpretations are defined (and named) in the obvious way.
Number restriction are available in almost all DL systems. The DL ALCN (i.e., ALC
extended with number restrictions) was first treated by Hollunder and Nutt (1990), as was
ALCF. The DL ALCQ was first investigated by Hollunder and Baader (1991), and ALCO
by Schaerf (1994).
8

Fusions of Description Logics and Abstract Description Systems

Name
Role composition

Syntax
R1 ◦ R2

Semantics
{(a, b) ∈ ∆I × ∆I |
∃c ∈ ∆I . (a, c) ∈ R1I ∧ (c, b) ∈ R2I }
Role complement R
{(a, b) ∈ ∆I × ∆I | (a, b) ∈
/ RI }
Role conjunction
R1 u R2 {(a, b) ∈ ∆I × ∆I | (a, b) ∈ R1I ∧ (a, b) ∈ R2I }
Role disjunction
R1 t R2 {(a, b) ∈ ∆I × ∆I | (a, b) ∈ R1I ∨ (a, b) ∈ R2I }
Inverse roles
R−1
{(a, b) ∈ ∆I × ∆I | (b, a) ∈ RI }
Transitive closure R+
{(a, b) ∈ ∆I × ∆I | (a, b) ∈ (RI )+ }
Universal role
U
∆I × ∆I
For a binary relation R, R+ denotes the transitive closure of R.

Symbol
◦
·
u
t
−1
+
U

Figure 2: Some description logic role constructors.
2.1.3 Role constructors
Role constructors allow us to build complex role descriptions. A collection of role constructors can be found in Figure 2. Again, the rightmost column indicates the naming scheme,
where name modifiers for role constructors are written in superscript and separated by
commas. For example, ALCQ with inverse roles and transitive closure is called ALCQ+,−1 .
In DLs admitting role constructors, the set of role descriptions is defined inductively, analogously to the set of concept descriptions. The semantics of role constructors is given in
the third column of Figure 2. As with concept descriptions, it can be used to extend the
interpretation function from role names to role descriptions.
In a DL with role constructors, role descriptions can be used wherever role names may
be used in the corresponding DLs without role constructors. For example,
∃(R1 u R3 ).C u ∀(R2 t R2 ).¬C
·,u,t

is an ALC
-concept description. This concept description is unsatisfiable since R2 t R2
is equivalent to the universal role. Note that role descriptions can also be used within role
assertions in an ABox.
The DL ALC ◦,t,+ was first treated by Baader (1991) (under the name ALC trans ); Schild
(1991) has shown that this DL is a notational variant of propositional dynamic logic (PDL).
DLs with Boolean operators on roles were investigated by Lutz and Sattler (2000). The
inverse operator was available in the system CRACK (Bresciani, Franconi, & Tessaris,
1995), and reasoning in DLs with inverse roles was, for example, investigated by Calvanese
et al. (1998) and Horrocks et al. (2000). The universal role can be expressed using DLs with
Boolean operators on roles (see the above example), and it can in turn be used to simulate
general concept inclusion axioms within concept descriptions.
2.2 Restricting the syntax
Until now, constructors could be combined arbitrarily. Sometimes it makes sense to restrict
the interaction between constructors since reasoning in the restricted DL may be easier than
reasoning in the unrestricted DL. We will consider DLs imposing certain restrictions on

9

Baader, Lutz, Sturm, & Wolter

1. which roles may be used inside certain concept constructors,
2. which roles may be used inside certain role constructors,
3. the combination of role constructors, and
4. the role constructors that may be used inside certain concept constructors.
As an example for the first case, consider the fragment of ALCQR+ in which transitive roles
may be used in existential and universal restrictions, but not in number restrictions (see,
e.g., Horrocks et al., 2000).
As the result of taking the fusion of two DLs, we will obtain DLs whose set of roles NR
is partitioned. For example, the fusion of ALCQ with ALC −1 yields a fragment of ALCQ−1
where NR is partitioned in two sets, say NR1 and NR2 . In this fragment, the inverse role
constructor and roles from NR2 may not be used within qualified number restrictions, while
roles from NR1 may not be used inside the inverse role constructor.2 Thus, this DL is an
example for the first, the second, and the fourth case.
Now consider the DL ALCF introduced above, which does not only extend ALC f with
feature (dis)agreement as a concept constructor, but also provides the role composition constructor. However, the role chains built using composition have to be comprised exclusively
of features and non-functional roles may not appear inside feature (dis)agreement. Hence,
ALCF is also an example for the first, second, and fourth case.
As an example for the third case, the fragment of ALC ·,u in which role conjunction
may not be used inside the role complement constructor is considered by Lutz and Sattler
(2000).
For these restricted DLs, we do not introduce an explicit naming scheme. Note that,
in this paper, we do not deal with DLs in which the combinability of concept constructors
with each other is restricted since these DLs would not fit into the framework of abstract
description systems introduced in the next section. An example of such a DL would be
one with atomic negation of concepts, i.e., where negation may only be applied to concept
names (e.g., the DL AL discussed by Donini et al., 1997).

3. Abstract description systems
In order to define the fusion of DLs and prove general results for fusions of DLs, one needs
a formal definition of what are “description logics”. Since there exists a wide variety of DLs
with very different characteristics, we introduce a very general formalization, which should
cover all of the DLs considered in the literature, but also includes logics that would usually
not be subsumed under the name DL.
3.1 Syntax and semantics
The syntax of an abstract description system is given by its abstract description language,
which determines a set of terms, term assertions, and object assertions. In this setting,
concept descriptions are represented by terms that are built using the abstract description
2. This will become clearer once we have given a formal definition of the fusion.

10

Fusions of Description Logics and Abstract Description Systems

language. General inclusion axioms in DLs are represented by term assertions and ABox
assertions in DLs are represented by object assertions.
Definition 4 (Abstract description language). An abstract description language (ADL)
is determined by a countably infinite set V of set variables, a countably infinite set X of
object variables, a (possibly infinite) countable set R of relation symbols of arity two,3 and
a (possibly infinite) countable set F of functions symbols f , which are equipped with arities
nf . All these sets have to be pairwise disjoint.
The terms tj of this ADL are built using the follow syntax rules:
tj

−→ x, ¬t1 , t1 ∧ t2 , t1 ∨ t2 , f (t1 , . . . , tnf ),

where x ∈ V , f ∈ F, and the Boolean operators ¬, ∧, ∨ are different from all function
symbols in F. For a term t, we denote by var(t) the set of set variables used in t. The
symbol > is used as an abbreviation of x ∨ ¬x and ⊥ as an abbreviation for x ∧ ¬x (where
x is a set variable).
The term assertions of this ADL are
• t1 v t2 , for all terms t1 , t2 ,
and the object assertions are
• R(a, b), for a, b ∈ X and R ∈ R;
• (a : t), for a ∈ X and t a term.
The sets of term and object assertions together form the set of assertions of the ADL.
From the DL point of view, the set variables correspond to concept names, object
variables to individual names, relation symbols to roles, and the Boolean operators as well
as the function symbols correspond to concept constructors. Thus, terms correspond to
concept descriptions. As an example, let us view concept descriptions of the DL ALCN u ,
i.e., ALC extended with number restrictions and conjunction of roles, as terms of an ADL.
Value restrictions and existential restrictions can be seen as unary function symbols: for
each role description R, we have the function symbols f∀R and f∃R , which take a term tC
(corresponding to the concept description C) and transform it into the more complex terms
f∀R (tC ) and f∃R (tC ) (corresponding to the concept descriptions ∀R.C and ∃R.C). Similarly,
number restrictions can be seen as nullary function symbols: for each role description R
and each n ∈ N, we have the function symbols f≥nR and f≤nR . Hence, the ALCN u -concept
description A u ∀(R1 u R2 ).¬(B u (≥ 2R1 )) corresponds to the term xA ∧ f∀(R1 uR2 ) (¬(xB ∧
f(≥2R1 ) )). We will analyze the connection between ADLs and DLs more formally later on.
The semantics of abstract description systems is defined based on abstract description
models. These models are the general semantic structures in which the terms of the ADL
are interpreted. It should already be noted here, however, that an abstract description
system usually does not take into account all abstract description models available for the
language: it allows only for a selected subclass of these models. This subclass determines
the semantics of the system.
3. To keep things simpler, we restrict our attention to the case of binary predicates, i.e., roles in DL.
However, the results can easily be extended to n-ary predicates.

11

Baader, Lutz, Sturm, & Wolter

Definition 5. Let L be an ADL as in Definition 4. An abstract description model (ADM)
for L is of the form
D
E
W = W, F W = {f W | f ∈ F}, RW = {RW | R ∈ R} ,



where W is a nonempty set, the f W are functions mapping every sequence X1 , . . . , Xnf
of subsets of W to a subset of W , and the RW are binary relations on W .
Since ADMs do not interpret variables, we need an assignment that assigns a subset
of W to each set variable, before we can evaluate terms in an ADM. To evaluate object
assertions, we need an additional assignment that assigns an element of W to each object
variable.



Definition 6. Let L be an ADL and W = W, F W , RW be an ADM for L. An assignment
for W is a pair A = (A1 , A2 ) such that A1 is a mapping from the set of set variables V into
2W , and A2 is an injective4 mapping from the set of object variables X into W . Let W be
an ADM and A = (A1 , A2 ) be an assignment for W. With each L-term t, we inductively
associate a value tW,A in 2W as follows:
• xW,A := A1 (x) for all variables x ∈ V ,
∪ t2W,A ,
, (t1 ∨ t2 )W,A := tW,A
∩ tW,A
• (¬t)W,A := W \ (t)W,A , (t1 ∧ t2 )W,A := tW,A
1
2
1
• f (t1 , . . . , tnf )W,A := f W (tW,A
, . . . , tW,A
nf ).
1
If x1 , . . . , xn are the set variables occurring in t, then we often write tW (X1 , . . . , Xn ) as
shorthand for tW,A , where A is an assignment with xA
i = Xi for 1 ≤ i ≤ n.
The truth-relation |= between hW, Ai and assertions is defined as follows:
• hW, Ai |= R(a, b) iff A2 (a)RW A2 (b),
• hW, Ai |= a : t iff A2 (a) ∈ tW,A ,
.
⊆ tW,A
• hW, Ai |= t1 v t2 iff tW,A
2
1
In this case we say that the assertion is satisfied in hW, Ai. If, for an ADM W and a set of
assertions Γ, there exists an assignment A for W such that each assertion in Γ is satisfied
in hW, Ai, then W is a model for Γ.
There are two differences between ADMs and DL interpretations. First, in a DL interpretation, the interpretation of the role names fixes the interpretation of the function
symbols corresponding to concept constructors that involve roles (like value restrictions,
number restrictions, etc.). The interpretation of the concept names corresponds to an assignment. Thus, a DL model is an ADM together with an assignment, whereas an ADM
alone corresponds to what is called frame in modal logics. Second, in DL the roles used in
concept constructors may, of course, also occur in role assertions. In contrast, the definition
of ADMs per se does not enforce any connection between the interpretation of the function
symbols and the interpretation of the relation symbols. Such connections can, however, be
enforced by restricting the attention to a subclass of all possible ADMs for the ADL.
4. This corresponds to the unique name assumption.

12

Fusions of Description Logics and Abstract Description Systems

Definition 7. An abstract description system (ADS) is a pair (L, M), where L is an ADL
and M is a class of ADMs for L that is closed under isomorphic copies.5
From the DL point of view, the choice of the class M defines the semantics of the
concept and role constructors, and it allows us, e.g., to incorporate restrictions on role
interpretations. In this sense, the ADS can be viewed as determining a (description) logic.
To be more concrete, in a DL interpretation the interpretation of the function symbols
is determined by the interpretation of the role names. Thus one can, for example, restrict
the class of models to ADMs that interpret a certain role as a transitive relation or as the
composition of two other roles. Another restriction that can be realized by the choice of
M is that nominals (corresponding to nullary function symbols) must be interpreted as
singleton sets.
Let us now define reasoning problems for abstract description systems. We will introduce
satisfiability of sets of assertions (with or without term assertions), which corresponds to
consistency of ABoxes (with or without GCIs), and satisfiability of terms (with or without
term assertions), which corresponds to satisfiability of concept descriptions (with or without
GCIs).
Definition 8. Given an ADS (L, M), a finite set of assertions Γ is called satisfiable in
(L, M) iff there exists an ADM W ∈ M and an assignment A for W such that hW, Ai
satisfies all assertions in Γ. The term t is called satisfiable in (L, M) iff {a : t} is satisfiable
in (L, M), where a is an arbitrary object variable.
• The satisfiability problem for (L, M) is concerned with the following question: given
a finite set of object assertions Γ of L, is Γ is satisfiable in (L, M).
• The relativized satisfiability problem for (L, M) is concerned with the following question: given a finite set of assertions Γ of L, is Γ is satisfiable in (L, M).
• The term satisfiability problem for (L, M) is concerned with the following question:
given a term t of L, is t satisfiable in (L, M).
• The relativized term satisfiability problem for (L, M) is concerned with the following
question: given a term t and a set of term assertions Γ of L, is {a : t} ∪ Γ satisfiable
in (L, M).
In the next section, we will define the fusion of two ADSs, and show that (relativized)
satisfiability is decidable in the fusion if (relativized) satisfiability in the component ADSs
is decidable. For these transfer results to hold, we must restrict ourselves to so-called local
ADSs.



Wp , RWp over pairwise
Definition 9. Given a family (Wp )p∈P
 of ADMs W
p = Wp , F

disjoint domains Wp , we say that W = W, F W , RW is the disjoint union of (Wp )p∈P iff
S
• W = p∈P Wp ,
5. Intuitively, this means that, if an ADM W belongs to M, then all ADMs that differ from it only w.r.t.
the names of the elements in its domain W also belong to M.

13

Baader, Lutz, Sturm, & Wolter

S
• f W (X1 , . . . , Xnf ) = p∈P f Wp (X1 ∩ Wp , . . . , Xnf ∩ Wp ) for all f ∈ F and
X1 , . . . , Xnf ⊆ W ,
S
• RW = p∈P RWp for all R ∈ R.
An ADS S = (L, M) is called local iff M is closed under disjoint unions.
In the remainder of this section, we first analyze the connection between ADSs and DLs
in more detail, and then comment on the relationship to modal logics.
3.2 Correspondence to description logics
We will show that the DLs introduced in Section 2 correspond to ADSs. In order to do this,
we first need to introduce frames, a notion well-known from modal logic. Let L be one of
the DLs introduced in Section 2.
Definition 10 (Frames). An L-frame F is a pair (∆F , ·F ), where ∆F is a nonempty set,
called the domain of F, and ·F is the interpretation function, which maps
• each nominal I to a singleton subset I F of ∆F , and
• each role name R to a subset RF of ∆F × ∆F such that the restrictions for role
interpretations in L are satisfied. For example, in ALC R+ , each R ∈ NR+ is mapped
to a transitive binary relation.
The interpretation function ·F can inductively be extended to complex roles in the obvious
way, i.e., by interpreting the role constructors in L according to their semantics as given in
Figure 2.
An interpretation I is based on a frame F iff ∆I = ∆F , RI = RF for all roles R ∈ NR ,
and I I = I F for all nominals I ∈ NO .
A frame can be viewed as an interpretation that is partial in the sense that the interpretation of individual and concept names is not fixed. Note that (in contrast to the case of
concept and individual names) the interpretation of nominals is already fixed in the frame.
The reason for this is that, if we do not interpret nominals in the frame, then we have to
treat them as set variables on the ADS side. These would, however, have to be variables
to which only singleton sets may be assigned. Since such a restriction is not possible in the
framework of ADSs as defined above, we interpret nominals in the frame. The consequence
is that they correspond to functions of arity 0 on the ADS side.
Now, we define the abstract description system S = (L, M) corresponding to a DL L.
It is straightforward to translate the syntax of L into an abstract description language L.
Definition 11 (Corresponding ADL). Let L be a DL with concept and role constructors
as well as restrictions on role interpretations as introduced in Section 2. The corresponding
abstract description language L is defined as follows. For every concept name A in L, there
exists a set variable xA in L, and for every individual name i in L there exists an object
variable ai in L. Let R be the set of (possibly complex) role descriptions of L. The set of
relation symbols of L is R, and the set of function symbols of L is the smallest set containing
1. for every role description R ∈ R, unary function symbols f∃R and f∀R ,
14

Fusions of Description Logics and Abstract Description Systems

2. if L provides unqualified number restrictions, then, for every n ∈ N and every role
description R ∈ R, function symbols f≥nR and f≤nR of arity 0,
3. if L provides qualified number restrictions, then, for every n ∈ N and every role R ∈ R,
unary function symbols f≥nR
and f≤nR
,
˙
˙
4. if L provides nominals, then, for every I ∈ NO , a function symbol fI of arity 0,
5. if L provides feature agreement and disagreement, then, for every pair of feature chains
(u1 , u2 ), two function symbols fu1 ↓u2 and fu1 ↑u2 of arity 0.
For an L-concept description C, let tC denote the representation of C as an L-term,
which is defined in the obvious way: concept names A are translated into set variables xA ,
the concept constructors ¬, u, and t are mapped to ¬, ∧, and ∨, respectively, and all other
concept constructors are translated to the corresponding function symbols. Obviously, both
the sets of function and relation symbols of L may be infinite.
An example of the translation of concept descriptions into terms of an ADL was already
given above: the ALCN u -concept description A u ∀(R1 u R2 ).¬(B u (≥ 2R1 )) corresponds
to the term xA ∧ f∀(R1 uR2 ) (¬(xB ∧ f(≥2R1 ) )).
We now define the set of abstract description models M corresponding to the DL L.
For every L-frame, M contains a corresponding ADM.
Definition 12 (Corresponding
Let
F = (∆F , ·F ) be a frame. The corresponding

 ADM).

abstract description model W = W, F W , RW has domain W := ∆F . The relation symbols
of L are just the role descriptions of L, and thus they are interpreted in the frame F. For
each relation symbol R ∈ R we can hence define RW := RF .
To define F W , we need to define f W for every nullary function symbol f in L, and
W
f (X) for every unary function symbol f in L and every X ⊆ ∆I . Let A be an arbitrary
concept name. For each X ⊆ ∆F , let IX be the interpretation based on F mapping the
concept name A to X and every other concept name to ∅.6 To define f W , we make a case
distinction according to the type of f :
W (X) := (∃R.A)IX ,
1. f∃R

W (X) := (∀R.A)IX ,
f∀R

W := (≥nR)I∅ , f W := (≤nR)I∅ ,
2. f≥nR
≤nR
W (X) := (≥nR.A)IX , f W (X) := (≤nR.A)IX ,
3. f≥nR
˙
˙
≤nR

4. fIW := I I∅ ,
5. fuW1 ↓u2 = (u1 ↓u2 )I∅ , fuW1 ↑u2 = (u1 ↑u2 )I∅ .
The class of ADMs M thus obtained from a DL L is obviously closed under isomorphic copies since this also holds for the set of L-frames (independently of which DL L we
consider). Hence, the tuple S = (L, M) corresponding to a DL L is indeed an ADS.
As an example, let us view the DL ALCN u as an ADS. The ADL L corresponding to
ALCN u has already been discussed. Thus, we concentrate on the class of ADMs M induced
6. Taking the empty set here is arbitrary.

15

Baader, Lutz, Sturm, & Wolter

by the frames of ALCN u . Assume that F is such a frame, i.e., F consists
of a nonempty



domain and interpretations RF of the role names R. The ADM W = W, F W , RW induced
by F is defined as follows. The set W is identical to the domain of F. Each role description
yields a relation symbol, which is interpreted in W just as in the frame. For example,
(R1 u R2 )W = R1F ∩ R2F . It remains to define the interpretation of the function symbols.
We illustrate this on two examples. First, consider the (unary) function symbol f∀(R1 uR2 ) .
W
Given a subset X of W , the function f∀(R
maps X to
1 uR2 )
W
f∀(R
(X) := {w ∈ W | v ∈ X for all v with (w, v) ∈ R1F ∩ R2F },
1 uR2 )

i.e., the interpretation of the concept description ∀(R1 u R2 ).A in the interpretations based
on F interpreting A by X. Accordingly, the value of the constant symbol f(≥2R) in W is
given by the interpretation of (≥ 2R) in the interpretations based on F.
It is easy to show that the interpretation of concept descriptions in L coincides with the
interpretation of the corresponding terms in S = (L, M).



Lemma 13. Let F be a frame, W = W, F W , RW be the ADM corresponding to F, A =
(A1 , A2 ) be an assignment for W, C be a concept description, and let the concept names
used in C be among A1 , . . . , Ak . For all interpretations I based on F with AIi = A1 (xAi )
for all 1 ≤ i ≤ k, we have that
C I = tW,A
.
C
As an easy consequence of this lemma, there is a close connection between reasoning
in a DL L and reasoning in the corresponding ADS. Given a TBox T and an ABox A of
the DL L, we define the corresponding set S(T , A) of assertions of the corresponding ADL
(L, M) in the obvious way, i.e., each GCI C v D in T yields a term assertion tC v tD , each
role assertion R(i, j) in A yields an object assertion R(ai , aj ), and each concept assertion
C(i) yields an object assertion ai : tC .
Proposition 14. The ABox A is consistent relative to the TBox T in L iff S(T , A) is
satisfiable in the corresponding ADS.
We do not treat non-relativized consistency explicitly since it is the special case of
relativized consistency where the TBox is empty.
As already mentioned above, our transfer results require the component ADSs to be
local. We call a DL L local iff the ADS (L, M) corresponding to L is local. It turns out
that not all DLs introduced in Section 2 are local.
Proposition 15. Let L be one of the DLs introduced in Section 2. Then, L is local iff L
does not include any of the following constructors: nominals, role complement, universal
role.
Proof. We start with the “only if” direction, which is more interesting since it shows why
ADSs corresponding to DLs with nominals, role complement, or the universal role are not
local. We make a case distinction according to which of these constructors L contains.
• Nominals. Consider the disjoint union W of the ADMs W1 and W2 , and assume
that W1 and W2 correspond to frames of a DL with nominals. By definition of the
16

Fusions of Description Logics and Abstract Description Systems

disjoint union, we know that ∆W1 ∩ ∆W2 = ∅. If I ∈ NO is a nominal, then the
definition of the disjoint union implies that fIW = fIW1 ∪ fIW2 . Since nominals are
interpreted by singleton sets in W1 and W2 , and since the domains of W1 and W2
are disjoint, this implies that fIW is a set of cardinality 2. Consequently, W cannot
correspond to an ADM induced by a frame for a DL with nominals, since such frames
interpret nominals by singleton sets.
• Universal role. Again, consider the disjoint union W of the ADMs W1 and W2 , and
assume that W1 and W2 correspond to frames of a DL with the universal role. Let U
denote the universal role, i.e., a role name for which the interpretation is restricted to
the binary relation relating each pair of individuals of the domain. By the definition of
the disjoint union, we have U W = U W1 ∪U W2 = ∆W1 ×∆W1 ∪∆W2 ×∆W2 6= ∆W ×∆W .
Consequently, W cannot correspond to an ADM induced by a frame for a DL with
universal role, since such a frame would interpret U by ∆W × ∆W .
• Role complement. Again, consider the disjoint union W of the ADMs W1 and W2 ,
and assume that W1 and W2 correspond to frames of a DL with role negation. For an
W
W
W
arbitrary role name R, we have R = R 1 ∪ R 2 = (∆W1 × ∆W1 \ RW1 ) ∪ (∆W2 ×
∆W2 \ RW2 ) 6= (∆W1 ∪ ∆W2 ) \ (RW1 ∪ RW2 ) = ∆W \ RW .
It remains to prove the “if” direction. Assume that L is one of the DLs introduced in
Section 2 that does not allow for nominals, role complements, and
 the universal role.
Let

(Fp )p∈P be a family of L-frames Fp = (∆Fp , ·Fp ) and let Wp = Wp , F Wp , RWp be the
ADMs corresponding to them. By definition, ∆Fp = Wp for all p ∈ P . Assume that the
domains (Wp )p∈P are pairwise disjoint. We must show that the disjoint union of (Wp )p∈P
also corresponds to an L-frame. To this purpose, we define the frame F = (∆F , ·F ) as
follows:
• ∆F :=

S

• RF :=

S

p∈P

∆Fp and

p∈P

RFp for all R ∈ NR .




Let W = W, F W , RW ∈ M be the
S ADM corresponding
S to F.WpBy Definition 12 (corW
responding ADM), we have W = p∈P Wp and R = p∈P R
for all R ∈ NR . By
induction on the structure of complex roles, it is easy to show that this also holds for
all R ∈ R, i.e., all complex role descriptions. For example, consider the role description
S
S
W
W
R1 ◦ R2 . By induction, we know that R1W = p∈P R1 p and R2W = p∈P R2 p . Since the
sets (Wp )p∈P are pairwise disjoint,
(R1 ◦ R2 )W = R1W ◦ R2W =

[

p∈P

Wp

R1

◦

[

Wp

R2

p∈P

=

[

p∈P

Wp

R1

Wp

◦ R2

=

[

(R1 ◦ R2 )Wp .

p∈P

Since RWp = RFp for all R ∈ R and p ∈ P , we obtain the following fact:
(∗) For all p ∈ P , a ∈ ∆Fp , and role descriptions R ∈ R, the following holds: RF (a) =
RFp (a); in particular, RF (a) ⊆ ∆Fp .
17

Baader, Lutz, Sturm, & Wolter

It remains to show that, for all n ≥ 0, all X1 , . . . , Xn ⊆ W , and all function symbols f of
arity n, we have
[
f W (X1 , . . . , Xn ) =
f Wp (X1 ∩ Wp , . . . , Xn ∩ Wp ).
p∈P

This can be proved by making a case distinction according to the type of f . We treat two
cases exemplarily.
S
• f = fu1 ↓u2 . Since W = p∈P Wp and the sets Wp are pairwise disjoint, fuW1 ↓u2 is the
disjoint union of the sets fuW1 ↓u2 ∩ Wp for p ∈ P . It remains to show that fuW1 ↓u2 ∩ Wp =
W

W

W

p
p
p
fu1 ↓u
(p ∈ P ). By definition of fu1 ↓u
, we know that a ∈ fu1 ↓u
iff a ∈ ∆Fp , both
2
2
2

F

F

F

F

u1 p (a) and u2 p (a) are defined, and u1 p (a) = u2 p (a). By (∗), this is the case iff
a ∈ ∆Fp , both uF1 (a) and uF2 (a) are defined and uF1 (a) = uF2 (a), which is equivalent to
a ∈ fuW1 ↓u2 ∩ Wp .
S
W (X) is
• f = f≥nR
. Since W = p∈P Wp and the sets Wp are pairwise disjoint, f≥nR
˙
˙

W (X) ∩ W for p ∈ P . It remains to show that
the disjoint union of the sets f≥nR
p
˙
W

W

W (X) ∩ W = f p (X ∩ W ) (p ∈ P ). By definition of f p , we know that
f≥nR
p
p
˙
˙
˙
≥nR
≥nR
W

p
a ∈ f≥nR
(X ∩ Wp ) iff a ∈ ∆Fp and |RFp (a) ∩ (X ∩ Wp )| ≥ n. By (∗), this is the case iff
˙

W (X) ∩ W .
|RF (a) ∩ (X ∩ Wp )| ≥ n iff |RF (a) ∩ X| ≥ n, and hence iff a ∈ f≥nR
p
˙

❏

It should be noted that arguments similar to the ones used in the proof of the “only
if” direction show that, in the presence of the universal role or of role negation, function
symbols (e.g., f∀U ) may also violate the locality condition.
The transfer results for decidability that are developed in this paper only apply to fusions
of local ADSs. Hence, the “only if” direction of the proposition implies that our results
are not applicable to fusions of ADSs corresponding to DLs that incorporate nominals, role
complement, or the universal role.
3.3 Correspondence to modal logics
In this paper our concern are fusions of description logics and not modal logics. Nevertheless,
it is useful to have a brief look at the relationship between ADSs and modal logic. Standard
modal languages can be regarded as ADLs without relation symbols and object variables
(just identify propositional formulas with terms). Given such an ADL L, a set L of L-terms
is called a classical modal logic iff is contains all tautologies of classical propositional logic
and is closed under modus ponens, substitutions, and the regularity rule
x1 ↔ y1 , . . . , xnf ↔ ynf
f (x1 , . . . , xnf ) ↔ f (y1 , . . . , ynf )
for all function symbols f of L. The minimal classical modal logic in the language with one
unary function symbol is known as the logic E (see Chellas, 1980).
Any ADS (L, M) based on L determines a classical modal logic L by taking the valid
terms, i.e., by defining
t ∈ L iff tW,A = W for all W ∈ M and assignments A in W.
18

Fusions of Description Logics and Abstract Description Systems

The logic E is determined by the ADS with precisely one unary operator whose class
of ADMs consists of all models. Chellas formulates this completeness result (Theorem
9.8 in Chellas, 1980) for so-called minimal models (alias neighborhood-frames), which are,
however, just a notational variant of abstract description models with one unary operator
(Došen, 1988). If the classical modal logic L is determined by an ADS with decidable term
satisfiability problem, then L is decidable since t ∈ L iff ¬t is unsatisfiable.
A classical modal logic L is called normal iff it additionally contains
f (x1 , . . . , xj−1 , xj ∧ yj , xj+1 , . . . , xnf ) ↔ f (x1 , . . . , xj−1 , xj , xj+1 , . . . , xnf ) ∧
f (x1 , . . . , xj−1 , yj , xj+1 , . . . , xnf )
and
f (>, ⊥, . . . , ⊥), f (⊥, >, ⊥, . . . , ⊥), . . . , f (⊥, . . . , ⊥, >),
for all function symbols f and all j with 1 ≤ j ≤ nf (Jónsson & Tarski, 1951; Jónsson &
Tarski, 1952; Goldblatt, 1989). This definition of normal modal logics assumes that the
formulas (terms) are built using only necessity (box) operators.7 We will work here only
with necessity operators; the corresponding possibility-operators are definable by putting
f 3 (x1 , . . . , xnf ) = ¬f (¬x1 , . . . , ¬xnf ).
The minimal normal modal logic in the language with one unary operator is known as K
(Chellas, 1980).
We call a function F : W n → W normal iff for all 1 ≤ j ≤ n and X1 , . . . , Xn , Yj ⊆ W
F (X1 , . . . , Xj−1 , Xj ∩ Yj , Xj+1 , . . . , Xn ) = F (X1 , . . . , Xj−1 , Xj , Xj+1 , . . . , Xn ) ∩
F (X1 , . . . , Xj−1 , Yj , Xj+1 , . . . , Xn ))
and
F (W, ∅, . . . , ∅) = F (∅, W, ∅, . . . , ∅) = · · · = F (∅, . . . , ∅, W ) = W.
Note that a unary function F is normal iff F (W ) = W and F (X ∩ Y ) = F (X) ∩ F (Y ), for
any X, Y ⊆ W . A function symbol f is called normal in an ADS (L, M) iff the functions
f W are normal for all W ∈ M.
For any role R of some DL, the function symbol f∀R is normal in the corresponding
ADS. To the contrary, it is readily checked that neither f≥nR
and f≤nR
nor their duals
˙
˙
3
3
f≥nR
and
f
are
normal.
˙
˙
≤nR
Obviously, an ADS (L, M) determines a normal modal logic iff all function symbols of
L are normal in (L, M). Completeness of K with respect to Kripke semantics (Chellas,
1980) implies that the logic K is determined by the ADS with one unary operator whose
class of ADMs consists of all models interpreting this operator by a normal function.
7. Note that some authors define normal modal logics using possibility (diamond) operators, in which case
the definitions are the duals of what we have introduced and thus at first sight look quite different.

19

Baader, Lutz, Sturm, & Wolter

4. Fusions of abstract description systems
In this section, we define the fusion of abstract description systems and prove two transfer theorems for decidability, one concerning satisfiability and the other one concerning
relativized satisfiability.
Definition 16. The fusion S1 ⊗ S2 = (L1 ⊗ L2 , M1 ⊗ M2 ) of two abstract description
systems S1 = (L1 , M1 ) and S2 = (L2 , M2 ) over
• disjoint sets of function symbols F of L1 and G of L2 ,
• disjoint sets of relation symbols R of L1 and Q of L2 , and
• the same sets of set and object variables
is defined as follows: L1 ⊗ L2 is the ADL based on
• the union F ∪ G of the function symbols of L1 and L2 , and
• the union R ∪ Q of the relation symbols of L1 and L2 ,
and M1 ⊗ M2 is defined as
E
E
D
E D
D
{ W, F W ∪ G W , RW ∪ QW | W, F W , RW ∈ M1 and W, G W , QW ∈ M2 }.
As an example, consider the ADSs S1 and S2 corresponding to the DLs ALCF and
ALC +,◦,t introduced in Section 2. We concentrate on the function symbols provided by
their fusion. In the following, we assume that the set of role names employed by ALCF
and ALC +,◦,t are disjoint.
• The ADS S1 is based on the following function symbols: (i) unary functions symbol
f∀R and f∃R for every role name R of ALCF, (ii) nullary functions symbols corresponding to the same-as constructor for every pair of chains of functional roles of
ALCF.
• The ADS S2 is based on the following function symbols: (iii) unary functions symbol
f∀Q and f∃Q for every role description Q built from role names of ALC +,◦,t using
union, composition, and transitive closure.
Since we assumed that the set of role names employed by ALCF and ALC +,◦,t are disjoint,
these sets of function symbols are also disjoint. The union of these sets provides us both
with the symbols for the same-as constructor and with the symbols for value and existential restrictions on role descriptions involving union, composition, and transitive closure.
However, the role descriptions contain only role names from ALC +,◦,t , and thus none of
the functional roles of ALCF occurs in such descriptions. Thus, the fusion of ALCF and
ALC +,◦,t yields a strict fragment of their union ALCF +,◦,t .
4.1 Relativized satisfiability
We prove a transfer result for decidability of the relativized satisfiability problem, show that
this also yields a corresponding transfer result for the relativized term satisfiability problem,
and investigate how these transfer results can be extended to ADSs that correspond to DLs
providing for the universal role.
20

Fusions of Description Logics and Abstract Description Systems

4.1.1 The transfer result
This section is concerned with establishing the following transfer theorem:
Theorem 17. Let S1 and S2 be local ADSs, and suppose that the relativized satisfiability
problems for S1 and S2 are decidable. Then the relativized satisfiability problem for S1 ⊗ S2
is also decidable.
The idea underlying the proof of this theorem is to translate a given set of assertions Γ
of S1 ⊗ S2 into a set of assertions Γ1 of S1 and a set of assertions Γ2 of S2 such that Γ is
satisfiable in S1 ⊗ S2 iff Γ1 is satisfiable in S1 and Γ2 is satisfiable in S2 . The first (naive)
idea for how to obtain the set Γi (i = 1, 2) is to replace in Γ alien terms (i.e., subterms
starting with function symbols not belonging to Si ) by new set variables (the surrogate
variables introduced below). With this approach, satisfiability of Γ would in fact imply
satisfiability of the sets Γi , but the converse would not be true. The difficulty arises when
trying to combine the models of Γ1 and Γ2 into one for Γ. To ensure that the two models
can indeed be combined, the sets Γi must contain additional assertions that make sure that
the surrogate variables in one model and the corresponding alien subterms in the other
model are interpreted in a “compatible” way. To be more precise, there are (finitely many)
different ways of adding such assertions, and one must try which of them (if any) leads to
a satisfiable pair Γ1 and Γ2 .
For the proof of Theorem 17, we fix two local ADSs Si = (Li , Mi ), i ∈ {1, 2}, in which
L1 is based on the set of function symbols F and relation symbols R, and L2 is based on G
and Q. Let L = L1 ⊗ L2 and M = M1 ⊗ M2 .
In what follows, we use the following notation: for a set of assertions Γ, denote by
term(Γ) and obj(Γ) the set of terms and object names in Γ, respectively.
We start with explaining how alien subterms in the set Γ can be replaced by new set
variables. For each L-term t of the form h(t1 , . . . , tn ), h ∈ F ∪ G, we reserve a new variable
xt , which will be called the surrogate of t. We assume that the set of surrogate variables
is disjoint to the original sets of variables. As sketched above, the idea underlying the
introduction of surrogate variables is that the decision procedure for S1 (S2 ) cannot deal
with terms containing function symbols from G (F). Thus, these “alien” function symbols
must be replaced before applying the procedure. To be more precise, we replace the whole
alien subterm starting with the alien function symbol by its surrogate. For example, if the
unary symbol f belongs to F, and the unary symbol g belongs to G, then f (g(f (x))) is a
“mixed” L-term. To obtain a term of L1 , we replace the subterm g(f (x)) by its surrogate,
which yields f (xg(f (x)) ). Analogously, to obtain a term of L2 , we replace the whole term
by its surrogate, which yields xf (g(f (x))) . We now define this replacement process more
formally.
Definition 18. For an L-term t without surrogate variables, denote by sur1 (t) the L1 -term
resulting from t when all occurrences of terms g(t1 , . . . , tn ), g ∈ G, that are not within the
scope of some g 0 ∈ G are replaced by their surrogate variable xg(t1 ,...,tn ) . For a set Θ of
terms, put sur1 (Θ) := {sur1 (t) | t ∈ Θ} and define sur2 (t) as well as sur2 (Θ) accordingly.
Denote by sub(Θ) the set of subterms of terms in Θ, and by sub1 (Θ) the variables
occurring in Θ as well as the subterms of alien terms (i.e., terms starting with a symbol
21

Baader, Lutz, Sturm, & Wolter

from G) in Θ. More formally, we can define
sub1 (Θ) := sub{t | xt ∈ var(sur1 (Θ))} ∪ var(Θ).
Define sub2 (Θ) accordingly.
For example, let f ∈ F be unary and g ∈ G be binary. If t = f (g(x, f (g(x, y)))), then
sur1 (t) = f (xg(x,f (g(x,y))) ). Note that the restriction “not within the scope of some g 0 ∈ G”
is there to clarify that only the top-most alien subterms are to be replaced. For the term t
of this example, we have sub1 ({t}) = {g(x, f (g(x, y))), f (g(x, y)), g(x, y), x, y}.
Note that the Boolean operators occurring in terms are “shared” function symbols in
the sense that they are alien to neither L1 nor L2 . Thus, sur1 (f (x)∧g(x, y)) = f (x)∧xg(x,y)
and sur2 (f (x) ∧ g(x, y)) = xf (x) ∧ g(x, y).
Of course, when replacing whole terms by variables, some information is lost. For
example, consider the (inconsistent) assertion (∃R1 .((≤1 R2 )u(≥2 R2 )))(i) and assume that
R1 is a role of one component of a fusion, and R2 a role of the other component. Translated
into abstract description language syntax, the concept description ∃R1 .((≤1 R2 ) u (≥2 R2 ))
yields the term t := f∃R1 (f(≤1 R2 ) ∧ f(≥2 R2 ) ), where f∃R1 is a function symbol of L1 and
the other two function symbols belong to L2 . Now, sur1 (t) = f∃R1 (x ∧ y), where x is the
surrogate for f(≤1 R2 ) and y is the surrogate for f(≥2 R2 ) . If the decision procedure for the
first ADS only sees f∃R1 (x ∧ y), it has no way to know that the conjunction of the alien
subterms corresponding to x and y is unsatisfiable. In fact, for this procedure x and y are
arbitrary set variables, and thus x ∧ y is satisfiable. To avoid this problem, we introduce
so-called consistency set consisting of “types”, where a type says for each “relevant” formula
whether the formula itself or its negation is supposed to hold. The sets Γ1 and Γ2 will then
contain additional information that basically ensures that their models satisfy the same
types. This will allow us to merge these models into one for Γ.
Definition 19. Given a finite set Θ of L-terms, we define the consistency set C(Θ) of Θ as
C(Θ) := {tc | c ⊆ Θ}, where the type tc determined by c ⊆ Θ is defined as
tc :=

^

{χ | χ ∈ c} ∧

^

{¬χ | χ ∈ Θ \ c}.

Given a finite set Γ of assertions in L, we define subi (Γ) := subi (term(Γ)). We abbreviate
C i (Γ) := C(subi (Γ)), for i ∈ {1, 2}.
In the example above, we have
sub1 (f∃R1 (f(≤1 R2 ) ∧ f(≥2 R2 ) ) = {f(≤1 R2 ) , f(≥2 R2 ) },
and thus C 1 ({ai : f∃R1 (f(≤1 R2 ) ∧ f(≥2 R2 ) )}) consists of the 4 terms
f(≤1 R2 )
f(≤1 R2 )
¬f(≤1 R2 )
¬f(≤1 R2 )

∧
∧
∧
∧

f(≥2 R2 ) ,
¬f(≥2 R2 ) ,
f(≥2 R2 ) , and
¬f(≥2 R2 ) .
22

Fusions of Description Logics and Abstract Description Systems

Given a set of terms Θ, an element tc of its consistency set C(Θ) can indeed be considered
as the “type” of an element e of the domain of an ADM w.r.t. Θ. Any such element e
belongs to the interpretations of some of the terms in Θ, and to the complements of the
interpretations of the other terms. Thus, if c is the set of terms of Θ to which e belongs,
then e also belongs to the interpretation of tc and it does not belong to the interpretation
of any of the other terms in C(Θ). In this case we say that e realizes the type tc .
We are now ready to formulate the theorem that reduces the relativized satisfiability
problem in a fusion of two local ADSs to relativized satisfiability in the component ADSs.
A proof of this theorem can be found in the appendix.
Theorem 20. Let Si = (Li , Mi ), i ∈ {1, 2}, be two local ADSs in which L1 is based on
the set of function symbols F and relation symbols R, and L2 is based on G and Q, and
let L = L1 ⊗ L2 and M = M1 ⊗ M2 . If Γ is a finite set of assertions from L, then the
following are equivalent:
1. Γ is satisfiable in (L, M).
2. There exist
(a) a set D ⊆ C 1 (Γ),
(b) for every term t ∈ D an object variable at 6∈ obj(Γ),
(c) for every a ∈ obj(Γ) a term ta ∈ D,
such that the union Γ1 of the following sets of assertions in L1 is satisfiable in
(L1 , M1 ):
W
(d) {at : sur1 (t) | t ∈ D} ∪ {> v sur1 ( D)},
(e) {a : sur1 (ta ) | a ∈ obj(Γ)},

(f ) {R(a, b) | R(a, b) ∈ Γ, R ∈ R},
(g) {sur1 (t1 ) v sur1 (t2 ) | t1 v t2 ∈ Γ} ∪ {a : sur1 (s) | (a : s) ∈ Γ};
and the union Γ2 of the following sets of assertions in L2 is satisfiable in (L2 , M2 ):
W
(h) {at : sur2 (t) | t ∈ D} ∪ {> v sur2 ( D)},
(i) {a : sur2 (ta ) | a ∈ obj(Γ)},

(j) {Q(a, b) | Q(a, b) ∈ Γ, Q ∈ Q}.
Intuitively, (2a) “guesses” a set D of types (i.e., elements of the consistency set). The
idea is that these are exactly the types that are realized in the model of Γ (to be constructed
when showing (2 → 1) and given when showing (1 → 2)). Condition (2b) introduces for
every type in D a name for an object realizing this type, and (2c) “guesses” for every object
variable occurring in Γ a type from D.
W Regarding (2d) and (2h), one should note that the set of assertions {at : t | t ∈ D}∪{> v
D} states that every type in D is realized (i.e., there is an object in the model having
this type) and that every object has one of the types in D. The sets of assertions (2d) and
(2h) are obtained from this set through surrogation to make it digestible by the decision
procedures of the component logics.
23

Baader, Lutz, Sturm, & Wolter

The assertions in (2e) and (2i) state (again in surrogated versions) that the object
interpreting the variable a has type ta . This ensures that, in the models of Γ1 and Γ2
(given when showing (2 → 1)), the objects interpreting a have the same type ta from D.
Otherwise, these models could not be combined into a common one for Γ.
The sets (2f) and (2j) are obtained from Γ by distributing its relationship assertions
between Γ1 and Γ2 , depending on the relation symbol used in the assertion.
The set (2g) contains (in surrogated version) the term assertions of the form t1 v t2 and
the membership assertions of the form a : s of Γ.
Condition 2 is asymmetric in two respects. First, it guesses a subset of C 1 (Γ) rather than
a subset of C 2 (Γ). Of course this is arbitrary, we could also have chosen index 2 instead
of 1 here. Second, the set Γ2 neither contains the assertions {sur2 (t1 ) v sur2 (t2 ) | t1 v
t2 ∈ Γ} nor {a : sur2 (s) | (a : s) ∈ Γ}. If we added these assertions, the theorem would
still be true, but this would unnecessarily increase the amount of work to be done by the
combined decision procedure. In fact, since the other assertions in Γ1 and Γ2 enforce a tight
coordination between the models of Γ1 and Γ2 , the fact that the membership assertions and
term assertions of Γ are satisfied in the models of Γ1 implies that they are also satisfied in
the models of Γ2 (see the appendix for details).
To prove Theorem 17, we must show how Theorem 20 can be used to construct a
decision procedure for relativized satisfiability in S1 ⊗ S2 from such decision procedures for
the component systems S1 and S2 . For a given finite set of assertions Γ of S1 ⊗ S2 , the set
C 1 (Γ) is also finite, and thus there are finitely many sets D in (2a) and choices of types for
object variables in (2c). Consequently, we can enumerate all of them and check whether
one of these choices leads to satisfiable sets Γ1 and Γ2 . By definition of the sets Γi and of
the functions suri , the assertions in Γi are indeed assertions of Li , and thus the satisfiability
algorithm for (Li , Mi ) can be applied to Γi . This proves Theorem 17.
Regarding the complexity of the obtained decision procedure, the costly step is guessing
the right set D. Since the cardinality of the set sub1 (Γ) is linear in the size of Γ, the
cardinality of C 1 (Γ) is exponential in the size of Γ (and each element of it has size quadratic
in Γ). Thus, there are doubly exponentially many different subsets to be chosen from. Since
the cardinality of the chosen set D may be exponential in the size of Γ, also the size of Γ1
and Γ2 may be exponential in Γ (because of the big disjunction over D). From this, the
following corollary follows.
Corollary 21. Let S1 and S2 be local ADSs, and suppose that the relativized satisfiability
problems for S1 and S2 are decidable in ExpTime (PSpace). Then the relativized satisfiability problem for S1 ⊗ S2 is decidable in 2ExpTime (ExpSpace).
p (n)

Proof. Assume that Γ has size n. Then we must consider 22 1 (for some polynomial p1 )
p (n)
different sets D in (2a). Each such set has size 2p1 (n) and thus we have of 22 2 choices
in (2c) (for some polynomial p2 ). Overall, this still leaves us with doubly exponentially
many choices. Now assume that the relativized satisfiability problems for S1 and S2 are
decidable in ExpTime. Since each call of these procedures is applied to a set of assertions of
p (n)
p (n)
exponential size, it may take double exponential time, say 22 3 and 22 4 (for polynomials
p3 and p4 ). Overall, we thus have a time complexity of
22

p1 (n)

· 22

p2 (n)

· (22
24

p3 (n)

+ 22

p4 (n)

),

Fusions of Description Logics and Abstract Description Systems

p(n)

which can clearly be majorized by 22
for an appropriate polynomial p. This shows
membership in 2ExpTime.
The argument regarding the space complexity is similar. Here one must additionally
take into account that doubly exponentially many choices can be enumerated using an
exponentially large counter.
❏
4.1.2 The relativized term satisfiability problem
The statement of Theorem 17 itself does not imply a transfer result for the relativized term
satisfiability problem. The problem is that decidability of the relativized term satisfiability
problem in S1 and S2 does not necessarily imply decidability of the relativized satisfiability
problem in these ADSs, and thus the prerequisite for the theorem to apply is not satisfied.
However, if we consider the statement of Theorem 20, then it is easy to see that this theorem
also yields a transfer result for the relativized term satisfiability problem.
Corollary 22. Let S1 and S2 be local ADSs, and suppose that the relativized term satisfiability problems for S1 and S2 are decidable. Then the relativized term satisfiability problem
for S1 ⊗ S2 is also decidable.
Proof. Consider the satisfiability criterion in Theorem 20. If we are interested in relativized term satisfiability, then Γ is of the form {a : t} ∪ Γ0 , where Γ0 is a set of term
assertions. In this case, the sets of assertions Γ1 and Γ2 do not contain object assertions
involving relations. Now, assume that Γi is of the form {a1 : t1 , . . . , an : tn } ∪ Γ0i , where Γ0i
is a set of term assertions. Since two assertions of the form b : s1 , b : s2 are equivalent to
one assertion b : s1 ∧ s2 , we may assume that the ai are distinct from each other. Since Si
is local, it is easy to see that the following are equivalent:
1. {a1 : t1 , . . . , an : tn } ∪ Γ0i is satisfiable in Si .
2. {aj : tj } ∪ Γ0i is satisfiable in Si for all j = 1, . . . , n.
Since (1 → 2) is trivial, it is enough to show (2 → 1). Given models Wj ∈ Mi of {aj :
tj } ∪ Γ0i (j = 1, . . . , n), their disjoint union also belongs to Mi , and it is clearly a model of
{a1 : t1 , . . . , an : tn } ∪ Γ0i .
The second condition can now be checked by applying the term satisfiability test in Si
n times.
❏
4.1.3 Dealing with the universal role
As stated above (Proposition 15), ADSs corresponding to DLs with the universal role are
not local, and thus Theorem 17 cannot be applied directly. Nevertheless, in some cases
this theorem can also be used to obtain a decidability result for fusions of DLs with the
universal role, provided that both of them provide for a universal role. (We will comment
on the usefulness of this approach in more detail in Section 5.4).
Definition 23. Given an ADS S = (L, M), we denote by S U the ADS obtained from S by
1. extending L with two function symbols f∃US and f∀US , and
25

Baader, Lutz, Sturm, & Wolter




W and
2. extending every ADM W = W, F W , RW ∈ M with the unary functions f∃U
S
W , where
f∀U
S
W (X) = ∅ if X = ∅, and f W (X) = W otherwise;
• f∃U
∃US
S
W (X) = W if X = W , and f W (X) = ∅ otherwise.
• f∀U
∀US
S

For ADSs S corresponding to a DL L, the ADS S U corresponds to the extension of L
with the universal role, where the universal role can only be used within value and existential
restrictions.8 There is a close connection between the relativized satisfiability problem in S
and the satisfiability problem in S U .
Proposition 24. If S is a local ADS, then the following conditions are equivalent:
1. the relativized (term) satisfiability problem for S is decidable,
2. the (term) satisfiability problem for S U is decidable,
3. the relativized (term) satisfiability problem for S U is decidable.

Proof. We restrict our attention to the term satisfiability problem since the equivalences
for the satisfiability problem can be proved similarly.
The implication (3 → 2) is trivial, and (2 → 1) is easy to show. In fact, t is satisfiable in
S relative to the term assertions {s1 v t1 , . . . , sn v tn } iff t∧f∀US .((¬t1 ∨s1 )∧. . .∧(¬tn ∨sn ))
is satisfiable in S U .
To show (1 → 3), we assume that the relativized term satisfiability problem for S is
decidable. Let S = (L, M) and S U = (LU , MU ). In the following, we use fU as an
abbreviation for f∀US . Since we can replace equivalently in any term the function symbol
f∃US by ¬fU ¬, we may assume without loss of generality that f∃US does not occur in terms
of LU .
Suppose a set Σ = {a : s} ∪ Γ from LU is given, where Γ is a set of term assertions. We
want to decide whether Σ is satisfiable in some model W ∈ MU . To this purpose, we transform Σ into a set of assertions not containing fU . The idea underlying this transformation
is that, given a model W ∈ MU , we have fU (t)W ∈ {W, ∅}, depending on whether tW = W
or not. Consequently, if we replace fU (t) accordingly by > or ⊥, the evaluation of this term
in W does not change. However, in the satisfiability test we do not have the model W (we
are trying to decide whether one exists), and thus we must guess the right replacement.
A term t from LU is called a U -term iff it starts with fU . The set of U -terms that
occur (possibly as subterms) in Σ is denoted by ΣU . Set, inductively, for any function
8. Note that it is not necessary to add the universal role U to the set of relation symbols since an assertion
of the form U (a, b) is trivially true. However, the use of the universal role within (qualified) number
restrictions is not covered by this extension.

26

Fusions of Description Logics and Abstract Description Systems

σ : ΣU → {⊥, >} and all subterms of terms in Σ:
xσ := x,
(t1 ∧ t2 )σ := tσ1 ∧ tσ2 ,
(t1 ∨ t2 )σ := tσ1 ∨ tσ2 ,
(¬t)σ := ¬tσ ,
(f (t1 , . . . , tn ))σ := f (tσ1 , . . . , tσn ) for f 6= fU of arity n,
(fU (t))σ := σ(fU (t)).
Thus, tσ is obtained from t by replacing all occurrences of U -terms in t by their image under
σ, i.e., by ⊥ or >. Define, for any such function σ,
Σσ := {tσ1 v tσ2 | t1 v t2 ∈ Γ} ∪ {a : sσ } ∪
{> v tσ | fU (t) ∈ ΣU and σ(fU (t)) = >} ∪
{at : ¬tσ | fU (t) ∈ ΣU and σ(fU (t)) = ⊥},
where the at are mutually distinct new object variables. Note that Σσ does not contain the
function symbol fU , and thus it can be viewed as a set of assertions of S. In addition, though
it contains more than one membership assertion, it does not contain assertions involving
relation symbols. Consequently, the satisfiability of Σσ in S can be checked using the term
satisfiability test for S (see the proof of Corollary 22 above). Decidability of the relativized
term satisfiability problem for S U then follows from the following claim:
Claim. Σ is satisfiable in a member of MU iff there exists a mapping σ : ΣU → {⊥, >}
such that Σσ is satisfiable in a member of M.
To 
prove this claim, first suppose that Σ is satisfied under an assignment A in a member
W = W, F W ∪ {fUW }, RW of MU . Define σ by setting σ(fU (t)) = > if (fU (t))W,A =
W , and σ(fU (t))
 = ⊥ otherwise.
Obviously, this implies that Σσ is satisfied under the

W
W
assignment A in W, F , R , which is a member of M.
suppose Σσ is satisfiable for some mapping σ. Take a member W =

 Conversely,

W
W
σ
0
and an assignment A such such that hW, Ai |= Σ . Set W :=

W, F W , R W of M
W
W, F ∪ {fU }, R , and prove, by induction, for all terms t that occur in Σ:
(∗)

0

tW ,A = (tσ )W,A .

The only critical case is the one where t = fU (s). First, assume that σ(fU (s)) = (fU (s))σ =
0
>. Then Σσ contains > v sσ , and thus W = (sσ )W,A = sW ,A , where the second identity
0
0
holds by induction. However, sW ,A = W implies (fU (s))W ,A = W = >W,A . The case where
σ(fU (s)) = (fU (s))σ = ⊥ can be treated similarly. Here the term assertion as : ¬sσ ensures
that sσ (and thus by induction s) is not interpreted as the whole domain. Consequently,
applying fU to it yields the empty set.
Since hW, Ai |= Σσ , the identity (∗) implies that hW0 , Ai |= Σ. This completes the proof
of the claim, and thus also of the proposition.
❏
For normal modal logics, the result stated in this proposition was already shown by
Goranko and Passy (1992). The proof technique used there can, however, not be transfered
27

Baader, Lutz, Sturm, & Wolter

to our more general situation since it strongly depends on the normality of the modal
operators.
Using Proposition 24, we obtain the following corollary to our first transfer theorem.
Corollary 25. Let S1 , S2 be local ADSs and assume that, for i ∈ {1, 2}, the relativized
(term) satisfiability problem for Si is decidable. Then the relativized (term) satisfiability
problem for S1U ⊗ S2U is decidable.
Proof. We know by Theorem 17 (Corollary 22) that the relativized (term) satisfiability
problem for S1 ⊗ S2 is decidable. Hence, Proposition 24 yields that the relativized (term)
satisfiability problem for (S1 ⊗ S2 )U is decidable. But S1U ⊗ S2U is just a notational variant
of (S1 ⊗ S2 )U : the function symbols f∃US1 and f∃US2 can be replaced by f∃US1 ⊗S2 (and
analogously for f∀US1 ⊗S2 ) since all three have identical semantics.
❏
4.2 Satisfiability
Note that Theorem 17 does not yield a transfer result for the unrelativized satisfiability
problem. Of course, if the relativized satisfiability problems for S1 and S2 are decidable,
then the theorem implies that the satisfiability problem for S1 ⊗ S2 is also decidable (since
it is a special case of the relativized satisfiability problem). However, to be able to apply
the theorem to obtain decidability of the satisfiability problem in the fusion, the component
ADSs must satisfy the stronger requirement that the relativized satisfiability problemWis decidable. Indeed, the set Γi in Theorem 20 contains a term assertion (namely > v suri ( D))
even if Γ does not contain any term assertions.
There are cases where the relativized satisfiability problem is undecidable whereas the
satisfiability problem is still decidable. For example, Theorem 17 cannot be applied for
the fusion of ALCF and ALC +,◦,t since the relativized satisfiability problem for ALCF is
already undecidable (Baader et al., 1993). However, the satisfiability problem is decidable
for both DLs.
4.2.1 Covering normal terms
Before we can formulate a transfer result for the satisfiability problem, we need to introduce
an additional notion, which generalizes the notion of a normal modal logic.
Definition 26 (Covering normal terms). Let (L, M) be an ADS and f be a function
symbol of L of arity n. The term tf (x) (with one variable x) is a covering normal term for
f iff the following holds for all W ∈ M:
• tW
f (W ) = W
W
W
• for all X, Y ⊆ W , tW
f (X ∩ Y ) = tf (X) ∩ tf (Y ), and

• for all X, X1 , . . . , Yn ⊆ W : X ∩ Xi = X ∩ Yi for 1 ≤ i ≤ n implies
W
W
W
tW
f (X) ∩ f (X1 , . . . , Xn ) = tf (X) ∩ f (Y1 , . . . , Yn ).

An ADS (L, M) is said to have covering normal terms iff one can effectively determine a
covering normal term tf for every function symbol f of L.
28

Fusions of Description Logics and Abstract Description Systems

Intuitively, the first two conditions state that the covering normal term behaves like a
value restriction (or box operator). Consider the term f∀R (x), where f∀R is the function
symbol corresponding to the value restriction constructor for the role R. Then f∀R (x)
obviously satisfies the first two requirements for covering normal terms. Note that the
second condition implies that the function induced by tf is monotonic, i.e., X ⊆ Y implies
W
tW
f (X) ⊆ tf (Y ). The third condition specifies the connection between the covering normal
term and the function symbol it covers. With respect to elements of tW
f (X), the values
W
W
of the functions f (X1 , . . . , Xn ) and f (Y1 , . . . , Yn ) agree provided that their arguments
agree on X. It is easy to see that f∀R (x) is a covering normal term for the function symbols
corresponding to the value, existential, and (qualified) number restrictions on the role R
(see Proposition 35 below).
Given covering normal terms tf for the function symbols f of a finite set of function
symbols E, one can construct a term tE that is a covering normal term for all the elements
of E.
Lemma 27. Suppose the ADS (L, M) has covering normal terms and L is based on a set
of function symbols F . Denote by tf the covering normal term for the function symbol f ,
for all f ∈ F . Then, for every finite set E ⊆ F of function symbols, the term
tE (x) :=

^

tf (x)

f ∈E

is a covering normal term for all f ∈ E.
4.2.2 Correspondence to normal modal logics
The following result shows that any ADS in which every function symbol is normal has
covering normal terms. Hence, the notion of covering normal terms generalizes the notion
of normality in modal logics.
Proposition 28. Let (L, M) be an ADS, and assume that f is a normal function symbol
in (L, M). Then
tf (x) := f (x, ⊥, . . . , ⊥) ∧ f (⊥, x, . . . , ⊥) ∧ · · · ∧ f (⊥, . . . , ⊥, x)
is a covering normal term for f . In particular, if f is nullary (unary), then tf (x) = >
(tf (x) = f (x)) is a covering normal term for f .
Proof. The first two conditions in the definition of covering normal terms immediately
follow from the definition of normal function symbols. Thus, we concentrate on the third
condition. Assume, for simplicity, that f is binary. Suppose W ∈ M and X, X1 , X2 , Y1 , Y2 ⊆
W with X ∩ Xi = X ∩ Yi for i = 1, 2, and set F := f W . Then F (X ∩ X1 , X ∩ X2 ) =
F (X ∩ Y1 , X ∩ Y2 ). Since F is normal, we know that
F (X ∩ X1 , X ∩ X2 ) = F (X, X) ∩ F (X, X2 ) ∩ F (X1 , X) ∩ F (X1 , X2 ),
F (X ∩ Y1 , X ∩ Y2 ) = F (X, X) ∩ F (X, Y2 ) ∩ F (Y1 , X) ∩ F (Y1 , Y2 ),
29

Baader, Lutz, Sturm, & Wolter

and thus
F (X, X) ∩ F (X, X2 ) ∩ F (X1 , X) ∩ F (X1 , X2 ) =
F (X, X) ∩ F (X, Y2 ) ∩ F (Y1 , X) ∩ F (Y1 , Y2 ).
Since, by normality of F ,
F (X, X) ∩ F (X, X2 ) ∩ F (X1 , X) ⊇ tW
f (X),
F (X, X) ∩ F (X, Y2 ) ∩ F (Y1 , X) ⊇ tW
f (X),
W
this implies tW
f (X) ∩ F (X1 , X2 ) = tf (X) ∩ F (Y1 , Y2 ).

❏

4.2.3 The transfer result
Using covering normal terms, we can now formulate the second transfer theorem, which is
concerned with the transfer of decidability of (non-relativized) satisfiability.
Theorem 29. Let S1 and S2 be local ADSs having covering normal terms, and suppose
that the satisfiability problems for S1 and S2 are decidable. Then the satisfiability problem
for S1 ⊗ S2 is also decidable.
As in the proof of Theorem 17, we fix two local ADSs Si = (Li , Mi ), i ∈ {1, 2}, in which
L1 is based on the set of function symbols F and relation symbols R, and L2 is based on G
and Q. Let L = L1 ⊗ L2 and M = M1 ⊗ M2 .
The proof of Theorem 29 follows the same general ideas as the proof of Theorem 17.
There are, however, notable differences in the way satisfiability in S1 ⊗ S2 is reduced to
satisfiability in S1 and S2 . In Theorem 20 we had to “guess” a set D of types, and then
based on this set and some additional guesses, a pair of satisfiability problems Γ1 and Γ2 in
S1 and S2 , respectively, was generated. In the proof of Theorem 29, we do not need to guess
D. Instead, we can compute the right set. However, this computation requires us to solve
additional satisfiability problems in the fusion S1 ⊗ S2 . Nevertheless, this yields a reduction
since the alternation depth (i.e., number of alternations between function symbols of S1
and S2 ) decreases when going from the input set Γ to these additional mixed satisfiability
problems.
Before we can describe this reduction in more detail, we must introduce someWnew
notation. In the case of relativized satisfiability, term assertions of the W
form > v suri ( D)
were used to assert that all elements of theW domain belong to suri ( D). Now, we use
covering normal terms to “propagate” suri ( D) into terms up to a certain depth. For a
set of function symbols E, define the E-depth dE (t) of a term t inductively:
dE (xi ) = 0
dE (¬t) = dE (t)
dE (t1 ∨ t2 ) = dE (t1 ∧ t2 ) = max{dE (t1 ), dE (t2 )}
dE (f (t1 , . . . , tn )) = max{dE (t1 ), . . . , dE (tn )} + 1 if f ∈ E
dE (f (t1 , . . . , tn )) = max{dE (t1 ), . . . , dE (tn )} if f 6∈ E
30

Fusions of Description Logics and Abstract Description Systems

If Γ is a finite set of assertions, then
dE (Γ) := max{dE (t) | t ∈ term(Γ)}.
Put, for a term t(x) with one variable x, t0 (x) := x, tm+1 (x) := t(tm (x)), t≤0 (x) := x, and
t≤m+1 (x) := tm+1 (x) ∧ t≤m (x).
We are now in the position to formulate the result that reduces satisfiability in the fusion
of two local ADSs with covering normal terms to satisfiability in the component ADSs.
Theorem 30. Let Si = (Li , Mi ), i ∈ {1, 2}, be two local ADSs having covering normal
terms in which L1 is based on the set of function symbols F and relation symbols R, and
L2 is based on G and Q, and let L = L1 ⊗ L2 and M = M1 ⊗ M2 . Let Γ be a finite set
of object assertions from L. Put m := dF (Γ), r := dG (Γ), and let c(x) (d(x)) be a covering
normal term for all function symbols in Γ that are in F (G).
For i ∈ {1, 2}, denote by Σi the set of all s ∈ C i (Γ) such that the term s is satisfiable in
(L, M). Then the following three conditions are equivalent:
1. Γ is satisfiable in (L, M).
2. There exist
• for every t ∈ Σ1 an object variable at 6∈ obj(Γ)
• for every a ∈ obj(Γ) a term ta ∈ Σ1
such that the union Γ1 of the following sets of object assertions is satisfiable in
(L1 , M1 ):
W
• {at : sur1 (t ∧ c≤m (sur1 ( Σ1 )) | t ∈ Σ1 },
W
• {a : sur1 (ta ∧ c≤m (sur1 ( Σ1 )) | a ∈ obj(Γ)},
• {R(a, b) | R(a, b) ∈ Γ, R ∈ R},
• {a : sur1 (s) | (a : s) ∈ Γ};
and the union Γ2 of the following sets of object assertions is satisfiable in (L2 , M2 ):
W
• {at : sur2 (t ∧ d≤r (sur2 ( Σ1 )) | t ∈ Σ1 },
W
• {a : sur2 (ta ∧ d≤r (sur2 ( Σ1 )) | a ∈ obj(Γ)},
• {Q(a, b) | Q(a, b) ∈ Γ, Q ∈ Q}.

3. The same condition as in (2) above, with Σ1 replaced by Σ2 .
The sets Γi in the above theorem are very similarWto the ones in Theorem 20. The
main difference is that
W the term assertion > v suri ( D) is no longer there. Instead,
the disjunction suri ( Σ1 ) is directly “inserted” into the terms using the covering normals
terms. As already mentioned above, another difference is that the set D, which had to be
guessed in Theorem 20, is replaced by the set Σ1 in (2) and Σ2 in (3). Actually, guessing the
set D is no
W longer possible in this case. In the proof of Theorem 30 we need to know that
> v suri ( D) is satisfiable in Si (i.e., holds in at least one model in Mi ). But we have no
way to check this effectively since we do not have an algorithm for relativized satisfiability
31

Baader, Lutz, Sturm, & Wolter

in Si . Taking the set Σi ensures that this property is satisfied (see the proof in the appendix
for details).
By definition, Σi is the set of all s ∈ C i (Γ) such that the term s is satisfiable in (L, M).
Recall that the term s is satisfiable iff {a : s} is satisfiable in (L, M) for an arbitrary
object variable a. Since the elements of C i (Γ) are still mixed terms (i.e., terms of the
fusion), computing the set Σi actually needs a recursive call to the decision procedure for
satisfiability in (L, M). This recursion is well-founded since the alternation depth decreases.
Definition 31. For a term s of L, denote by a1 (s) and a2 (s) the 1-alternation and the
2-alternation depth of s, respectively. That is to say, a1 (s) is the length of the longest
sequence of the form (g1 , f2 , g3 , . . .) such that
g1 (. . . (f2 . . . (g3 . . .)))
with gj ∈ G and fj ∈ F appears in s. The 2-alternation depth a2 (s) is defined by exchanging
the roles of F and G. Put a(s) := a1 (s) + a2 (s), and call this the alternation depth. For a
finite set Θ of terms, a(Θ) is the maximum of all a(s) with s ∈ Θ.
Thus, a1 (s) counts the maximal number of changes between symbols from the first and
the second ADS, starting with the first symbol from S2 (i.e., the first symbol from S2
counts as a change, even if it does not occur inside the scope of a symbol from S2 ). The
2-alternation depth is defined accordingly. The alternation depth sums up the 1- and the
2-alternation depth.
Lemma 32. If a(term(Γ)) > 0, then a(C 1 (Γ)) < a(term(Γ)) or a(C 2 (Γ)) < a(term(Γ)).
Proof. We show that, if a(term(Γ)) > 0, then we have a(sub1 (Γ)) < a(term(Γ)) or
a(sub2 (Γ)) < a(term(Γ)), which, by definition of C i , clearly implies the lemma. First
note that, by definition of subi , we have
ai (subj (Γ)) ≤ ai (term(Γ)) for all i, j.

(∗)

We now make a case distinction as follows:
1. a1 (term(Γ)) ≥ a2 (term(Γ)). We want to show that a1 (sub2 (Γ)) < a1 (term(Γ)),
since, by (∗), this implies a(sub2 (Γ)) < a(term(Γ)). Assume to the contrary that
a1 (sub2 (Γ)) ≥ a1 (term(Γ)). Then (∗) implies a1 (sub2 (Γ)) = a1 (term(Γ)). Hence,
there exists a term s ∈ sub2 (Γ) and a sequence (g1 , f2 , g3 , . . . ) of function symbols
gi ∈ G, fi ∈ F of length a1 (term(Γ)) such that g1 (. . . (f2 . . . (g3 . . .))) occurs in s. By
definition of sub2 , this implies the existence of a term t ∈ term(Γ) and a function
symbol f ∈ F such that f (. . . g1 (. . . (f2 . . . (g3 . . .)))) occurs in t. Since the length of
(g1 , f2 , g3 , . . . ) is a1 (term(Γ)), this obviously yields a2 (term(Γ)) > a1 (term(Γ)) which
is a contradiction.
2. a1 (term(Γ)) ≤ a2 (term(Γ)). Similar to the previous case: just exchange the roles of
a1 and a2 , F and G, and sub1 and sub2 .
❏
32

Fusions of Description Logics and Abstract Description Systems

To prove Theorem 29, we must show how Theorem 30 can be used to construct a decision
procedure for satisfiability in S1 ⊗ S2 from such decision procedures for the component
systems S1 and S2 . Let us first consider the problem of computing the sets Σ1 and Σ2 .
If a((term(Γ)) = 0, then Γ consists of Boolean combinations of set variables. In this
case, C i (Γ) consists of set variables, and Σi , i = 1, 2, can be computed using Boolean
reasoning. If a(term(Γ)) > 0, then Lemma 32 states that there is an i ∈ {1, 2} such
that a(C i (Γ)) < a(term(Γ)). By induction we can thus assume that Σi can effectively be
computed. Consequently, it remains to check Condition (i + 1) of Theorem 30 for i ∈ {1, 2}.
Since Σi is finite, we can guess for every object variable a occurring in Γ a type ta in Σi . The
sets Γ1 and Γ2 obtained this way are indeed sets of assertions of L1 and L2 , respectively.
Thus, their satisfiability can effectively be checked using the decision procedures for S1 and
S2 . This proves Theorem 29.
The argument used above also shows why in Theorem 30 it was not sufficient to state
equivalence of (1) and (2) (as in Theorem 20). In fact, the induction argument used above
does not necessarily always apply to the computation of Σ1 . In some cases, the alternation
depth may not decreases for Σ1 , but only for Σ2 . It should be noted that Theorem 20 could
also have been formulated in this symmetric way. We have not done this since it was not
necessary for proving Theorem 17.
Regarding the complexity of the combined decision procedure, we must in principle also
consider the complexity of computing covering normal terms and the size of these terms.
In the examples from DL, these terms are just value restrictions, and thus their size and
the complexity of computing them is linear. Here, we assume a polynomial bound on both.
Under this assumption, we obtain the same complexity results as for the case of relativized
satisfiability. In fact, the complexity of testing Condition (2) and (3) of Theorem 30 agrees
with the complexity of testing Condition (2) of Theorem 20: it adds one exponential to the
complexity of the decision procedure for the single ADSs. In order to compute Σi , we need
exponentially many recursive calls to the procedure. Since the recursion depth is linear in
the size of Γ, we end up with at most exponentially many tests of Condition (2) and (3).
Corollary 33. Let S1 and S2 be local ADSs having covering normal terms, and assume
that these covering normal terms can be computed in polynomial time. If the satisfiability
problems for S1 and S2 are decidable in ExpTime (PSpace), then the satisfiability problem
for S1 ⊗ S2 is decidable in 2ExpTime (ExpSpace).
With the same argument as in the case of relativized satisfiability, we can extend the
transfer result also to term satisfiability.
Corollary 34. Let S1 and S2 be local ADSs having covering normal terms, and suppose
that the term satisfiability problems for S1 and S2 are decidable. Then the term satisfiability
problem for S1 ⊗ S2 is also decidable.

5. Fusions of description logics
Given two DLs L1 and L2 , their fusion is defined as follows. We translate them into the
corresponding ADSs S1 and S2 , and then build the fusion S1 ⊗ S2 . The fusion L1 ⊗ L2
of L1 and L2 is the DL that corresponds to S1 ⊗ S2 . Since the definition of the fusion of
ADSs requires their sets of function symbols to be disjoint, we must ensure that the ADSs
33

Baader, Lutz, Sturm, & Wolter

corresponding to L1 and L2 are built over disjoint sets of function symbols. For the DLs
introduced in Section 2, this can be achieved by assuming that the sets of role names of L1
and L2 are disjoint and the sets of nominals of L1 and L2 are disjoint. The DL L1 ⊗ L2 then
allows the use of the concept and role constructors of both DLs, but in a restricted way.
Role descriptions are either role descriptions of L1 or of L2 . There are no role descriptions
involving constructors or names of both DLs. Concept descriptions may contain concept
constructors of both DLs; however, a constructor of Li may only use a role description of
Li (i = 1, 2).
Let us illustrate these restrictions by two simple examples. The fusion ALC + ⊗ ALC −1
of the two DLs ALC + and ALC −1 is the fragment of ALC +,−1 whose set of role names is
partitioned into two sets NR1 and NR2 such that
• the transitive closure operator may only be applied to names from NR1 ;
• the inverse operator may only be applied to names from NR2 .
For example, if A is a concept name, R ∈ NR1 and Q ∈ NR2 , then ∃R+ .A u ∀Q−1 .¬A is
a concept description of ALC + ⊗ ALC −1 , but ∃R+ .A u ∀R−1 .¬A and ∃(Q−1 )+ .A are not.
Note that, although the two source DLs have disjoint sets of role names, in ALC + ⊗ ALC −1
role names from both sets may be used inside existential and value restrictions since these
concept constructors are available in both DLs.
The fusion ALCQ ⊗ ALC R+ of the two DLs ALCQ and ALC R+ is the fragment of
ALCQR+ whose set of role names NR (with transitive roles NR+ ⊆ NR ) is partitioned into
two sets NR1 and NR2 with NR+ ⊆ NR2 such that, inside qualifying number restrictions,
only role names from NR1 may be used. In particular, this means that transitive roles
cannot occur within qualified number restrictions.
In the following, we give examples that illustrate the usefulness of the transfer results
proved in the previous section. First, we will give an example for the case of satisfiability and
then for relativized satisfiability. Subsequently, we will consider a more complex example
involving so-called concrete domains. Here, our general transfer result can be used to prove
a decidability result that has only recently been proved by designing a specialized algorithm
for the fusion. Finally, we will give an example that demonstrates that the restriction to
local ADSs is really necessary.
5.1 Decidability transfer for satisfiability
In this subsection, we will give an example for an application of Theorem 29 where the
decidability result could not be obtained using Theorem 17.
Theorem 29 requires the ADSs to have covering normal terms. This is, however, satisfied
by all the DLs that yield local ADSs.
Proposition 35. Let L be one of the DLs introduced in Section 2, and let the corresponding
ADS S = (L, M) be local. Then S has covering normal terms, and these terms can be
computed in linear time.
Proof. For all function symbols f in L, the term tf has the form f∀R (x) for some role
description R. The semantics of value restrictions implies that terms of this form satisfy
34

Fusions of Description Logics and Abstract Description Systems

the first two properties of Definition 26. This completes the proof for all function symbols
f of arity 0 since for these the third condition of Definition 26 is trivially satisfied. Thus,
for nullary function symbols, f∀R (x) for an arbitrary role name R does the job.
It remains to show that, for every unary function symbol f ∈ {f∃R , f∀R , f≥nR
, f≤nR
},
˙
˙
the term f∀R (x) also satisfies the third property. This is an immediate consequence of the
W (X) ∩ f W (Y ) = f W (X) ∩ f W (X ∩ Y )
fact that, for these function symbols f , we have f∀R
∀R
for all models W ∈ M and X, Y ⊆ W .
❏
In the following, we consider the two description logics ALCF and ALC +,◦,t . Hollunder
and Nutt (1990) show that satisfiability of ALCF-concept descriptions is decidable. The
same is true for consistency of ALCF-ABoxes (Lutz, 1999). Note, however, that relativized
satisfiability of ALCF-concept descriptions and thus also relativized ABox consistency in
ALCF is undecidable (Baader et al., 1993). For ALC +,◦,t , decidability of satisfiability is
shown by Baader (1991) and Schild (1991).9 Decidability of ABox consistency in ALC +,◦,t
is shown in Chapter 7 of (De Giacomo, 1995).
The unrestricted combination ALCF +,◦,t of the two DLs is undecidable. To be more precise, satisfiability of ALCF +,◦,t -concept descriptions (and thus also consistency of ALCF +,◦,t ABoxes) is undecidable. This follows from the undecidability of relativized satisfiability of
ALCF-concept descriptions and the fact that the role operators in ALCF +,◦,t can be used
to internalize TBoxes (Schild, 1991; Baader et al., 1993). In contrast to the undecidability
of ALCF +,◦,t , Theorem 29 immediately implies that satisfiability of concept descriptions
in the fusion of ALCF and ALC +,◦,t is decidable.
Theorem 36. Satisfiability of concept descriptions and consistency of ABoxes is decidable
in ALCF ⊗ ALC +,◦,t , whereas satisfiability of ALCF +,◦,t -concept descriptions is already
undecidable.
Taking the fusion thus yields a decidable combination of two DLs whose unrestricted
combination is undecidable. The price one has to pay is that the fusion offers less expressivity than the unrestricted combination. The concept f1 ↓f2 u ∀f1+ .C is an example of a
concept description of ALCF +,◦,t that is not allowed in the fusion ALCF ⊗ ALC +,◦,t .
5.2 Decidability transfer for relativized satisfiability
As an example for the application of Corollary 22 (and thus of Theorem 17), we consider the
DL ALC +,◦,u,t
. For this DL, satisfiability of concept descriptions is undecidable. However,
f
an expressive fragment with a decidable relativized satisfiability problem can be obtained
by building the fusion of the two sublanguages ALC +,◦,t
and ALC +,◦,t,u .
f
Theorem 37. Satisfiability of ALC +,◦,u,t
-concept descriptions is undecidable.
f
Undecidability can be shown by a reduction of the domino problem (Berger, 1966;
Knuth, 1973) (see, e.g., Baader & Sattler, 1999, for undecidability proofs of DLs using such
a reduction). The main tasks to solve in such a reduction is that one can express the ×
grid and that one can access all points on the grid. One square of the grid can be expressed

N N

9. Note that ALC +,◦,t is a notational variant of test-free propositional dynamic logic (PDL) (Fischer &
Ladner, 1979).

35

Baader, Lutz, Sturm, & Wolter

by a description of the form ∃(x◦yuy◦x).>, where x, y are features. In fact, this description
expresses that the “points” belonging to it have both an x ◦ y and a y ◦ x successor, and
that these two successors coincide. Accessing all point on the grid can then be achieved by
using the role description (x t y)+ .
Note that this undecidability result is also closely related to the known undecidability
of IDPDL, i.e., deterministic propositional dynamic logic with intersection (Harel, 1984).
However, the undecidability proof for IDPDL by Harel (1984) uses the test construct, which
is not available in ALC +,◦,u,t
.
f
Next, we show that relativized satisfiability in two rather expressive sublanguages of
ALC +,◦,u,t
is decidable.
f
Theorem 38. Relativized satisfiability of concept descriptions is decidable in ALC f+,◦,t and
ALC +,◦,t,u .
Proof sketch. In both cases, TBoxes can be internalized as described by Schild (1991)
and Baader et al. (1993). Thus, it is sufficient to show decidability of (unrelativized)
satisfiability.
, this follows from decidability of DPDL (Ben-Ari, Halpern, & Pnueli,
For ALC +,◦,t
f
1982), the known correspondence between PDL and ALC +,◦,t (Schild, 1991), and the fact
that non-functional roles can be simulated by functional ones in the presence of composition
and transitive closure (Parikh, 1980).
For ALC +,◦,t,u , decidability of satisfiability follows from decidability of IPDL, i.e., PDL
with intersection (Danecki, 1984).
❏
Given this theorem, Corollary 22 now yields the following decidability result.
Corollary 39. Relativized satisfiability of concept descriptions is decidable in the fusion
ALC f+,◦,t ⊗ ALC +,◦,t,u .
5.3 A “concrete” example
Description logics with concrete domains were introduced by Baader and Hanschke (1991)
in order to allow for the reference to concrete objects like numbers, time intervals, spatial
regions, etc. when defining concepts. To be more precise, Baader and Hanschke (1991)
define the extension ALC(D) of ALC, where D is a concrete domain (see below). Under
suitable assumptions on D, they show that satisfiability in ALC(D) is decidable. One of the
main problems with this extension of DLs is that relativized satisfiability (and satisfiability in DLs where TBoxes can be internalized) is usually undecidable (Baader & Hanschke,
1992) (though there are exceptions, see Lutz, 2001). For this reason, Haarslev et al. (2001)
introduce a restricted way of extending DLs by concrete domains, and show that the corresponding extension of ALCN HR+ has a decidable relativized satisfiability problem.10 In
the following, we show that this result can also be obtained as an easy consequence of
10. To be more precise, they even show that relativized ABox consistency is decidable in their restricted
extension of ALCN HR+ by concrete domains. Here, we restrict ourself to satisfiability of concepts
since the ABoxes introduced by Haarslev et al. (2001) also allow for the use of concrete individuals and
for predicate assertions on these individuals, which is not covered by the object assertions for ADSs
introduced in the present paper.

36

Fusions of Description Logics and Abstract Description Systems

our Theorem 17. Moreover, ALCN HR+ can be replaced by an arbitrary local DL with a
decidable relativized satisfiability problem.
Definition 40 (Concrete Domain). A concrete domain D is a pair (∆D , ΦD ), where ∆D
is a nonempty set called the domain, and ΦD is a set of predicate names. Each predicate
name P ∈ ΦD is associated with an arity n and an n-ary predicate P D ⊆ ∆nD . A concrete
domain D is called admissible iff (1) the set of its predicate names is closed under negation
and contains a name >D for ∆D , and (2) the satisfiability problem for finite conjunctions
of predicates is decidable.
Given a concrete domain D and one of the predicates P ∈ ΦD (of arity n), one can
define a new concept constructor ∃f1 , . . . , fn .P (predicate restriction), where f1 , . . . , fn are
concrete features.11 In contrast to the abstract features considered until now, concrete
features are interpreted by partial functions from the abstract domain ∆I into the concrete
domain ∆D . We consider the basic DL that allows for Boolean operators and these new
concept constructors only.
Definition 41 (B(D)). Let NC be a set of concept names and NFc be a set of names for
concrete features disjoint from NC , and let D be an admissible concrete domain. Concepts
descriptions of B(D) are Boolean combinations of concept names and predicate restrictions, i.e., expressions of the form ∃f1 , . . . , fn .P where P is an n-ary predicate in ΦD and
f1 , . . . , fn ∈ NFc .
The semantics of B(D) is defined as follows. We consider an interpretation I, which
has a nonempty domain ∆I , and interprets concept names as subsets of ∆I and concrete
features as partial functions from ∆I into ∆D . The Boolean operators are interpreted as
usual, and
(∃f1 , . . . , fn .P )I = {a ∈ ∆I | ∃x1 , . . . , xn ∈ ∆D .
fiI (a) = xi for all 1 ≤ i ≤ n and (x1 , . . . , xn ) ∈ P D }.
Note that concept descriptions are interpreted as subsets of ∆I and not of ∆I ∪ ∆D .
Thus, if we go to the ADS corresponding to B(D), the concrete domain is not an explicit
part of the corresponding ADMs. It is only used to define the interpretation of the function
symbols corresponding to predicate restrictions. The predicate restriction constructor is
translated into a function symbol f∃f1 ,...,fn .P of arity 0, and, for an ADM W corresponding
W
to a frame F, f∃f
is defined as (∃f1 , . . . , fn .P )I∅ , where I∅ is the interpretation based
1 ,...,fn .P
on F that maps all concept names to the empty set.
Theorem 42. Let D be an admissible concrete domain. Then, B(D) is local and the
relativized satisfiability problem for B(D)-concept descriptions is decidable.
Proof. Given the family (Wi )i∈I of ADMs Wi corresponding to the frames Fi over pairwise
disjoint
domains ∆Fi (i ∈ I), we first build the union F of the frames: the domain of F is
S
F
i and it interprets the concrete features in the obvious way, i.e., f F (x) := f Fi (x) if
i∈I ∆
11. Note that the general framework introduced by Baader and Hanschke (1991) allows for feature chains in
predicate restrictions. Considering only feature chains of length one is the main restriction introduced
by Haarslev et al. (2001).

37

Baader, Lutz, Sturm, & Wolter

x ∈ ∆Fi . Let W be the ADM induced by F. ToSprove that W is in fact the disjoint union of
Wi
W
(Wi )i∈I , it remains to show that f∃f
= i∈I f∃f
. This is an easy consequence
1 ,...,fn .P
1 ,...,fn .P
of the semantics of the predicate restriction constructor, the interpretation of the concrete
features in F, and the fact that the domains ∆Fi are pairwise disjoint.
Decidability of the unrelativized satisfiability problem is an immediate consequence of
the decidability results for ALC(D) given by Baader and Hanschke (1991). Since B(D) is a
very simple DL that does not contain any concept constructors requiring the generation of
abstract individuals, it is easy to see that a B(D)-concept description C0 is satisfiable relative
to the TBox C1 v D1 , . . . , Cn v Dn iff it is satisfiable in a one-element interpretation. But
then the TBox can be internalized in a very simple way: C0 is satisfiable relative to the
TBox C1 v D1 , . . . , Cn v Dn iff C0 u (¬C1 t D1 ) u . . . u (¬Cn t Dn ) is satisfiable.
❏
Given this theorem, Corollary 22 now yields the following transfer result, which shows
that concrete domains with the restricted form of predicate restrictions introduced above can
be integrated into any local DL with a decidable relativized satisfiability problem without
losing decidability.
Corollary 43. Let D be an admissible concrete domain and L be a local DL for which
relativized satisfiability of concept descriptions is decidable. Then, relativized satisfiability
of concept descriptions in B(D) ⊗ L is also decidable.
5.4 Non-local DLs
By Proposition 15, DLs allowing for nominals, the universal role, or role negation are not
local. It follows that the decidability transfer theorems are not applicable to fusions of such
DLs. In the following, we try to clarify the reasons for this restricted applicability of the
theorems.
First, we show that there are DLs with decidable satisfiability problem such that their
fusion has an undecidable satisfiability problem. The culprit in this case is the universal
role (or role negation).
Theorem 44. Satisfiability of concept descriptions is decidable in ALC U and ALCF, but
undecidable in their fusion ALC U ⊗ ALCF.
Proof. Decidability of ALCF was shown by Hollunder and Nutt (1990) and of ALC U by
Baader et al. (1990) and Goranko and Passy (1992). Undecidability of ALC U ⊗ ALCF
(which is identical to ALCF U ) follows from the results by Baader et al. (1993) and the fact
that the universal role can be used to simulate TBoxes (see Proposition 24).
❏
Note that role negation can be used to simulate the universal role: just replace ∀U.C
by ∀R.C u ∀R.C and ∃U.C by ∃R.C t ∃R.C. In addition, decidability of ALC · is known
to be decidable (Lutz & Sattler, 2000). Consequently, the theorem also holds if we replace
ALC U by ALC · .
It should be noted that the example given in the above theorem depends on the fact
that one of the two DLs allows for the universal role and the other becomes undecidable
if the universal role is added. In fact, Corollary 25 shows that decidability does transfer if
both DLs already provide for the universal role.
38

Fusions of Description Logics and Abstract Description Systems

Concerning nominals, we do not have a counterexample to the transfer of decidability
in their presence. However, we think that it is very unlikely that there can be a general
transfer result in this case. In fact, note that for each DL L without nominals introduced in
Section 2, its fusion with ALCO is identical to L extended with nominals. Since (relativized)
satisfiability in ALCO is decidable, a general transfer result in this case would imply that
this extension is decidable provided that L is decidable. Consequently, this would yield a
general transfer result for adding nominals.

6. Conclusion
Regarding related work, the work that is most closely related to the one presented here is
(Wolter, 1998). There, analogs of our Theorems 20 and 30 are proved for normal modal
logics within an algebraic framework. The present results extend the ones from Wolter
(1998) in two directions. First, we have added object assertions, and thus can also prove
transfer results for ABox reasoning. Second, we can show transfer results for satisfiability in
non-normal modal logics as long as we have covering normal terms. This allows us to handle
non-normal concept constructors like qualified number restrictions (graded modalities) in
our framework.
We also think that the introduction of abstract description systems (ADSs) is a contribution in its own right. ADSs abstract from the internal structure of concept constructors
and thus allow us to treat a vast range of such constructors in a uniform way. Nevertheless, the model theoretic semantics provided by ADSs is less abstract than the algebraic
semantics employed by Wolter (1998). It is closer to the usual semantics of DLs, and thus
easier to comprehend for people used to this semantics. The results in this paper show
that ADSs in fact yield a good level of abstraction for proving general results on description logics. Recently, the same notion has been used for proving general results about
so-called E-connections of representation formalisms like description logics, modal spatial
logics, and temporal logics (Kutz, Wolter, & Zakharyaschev, 2001). In contrast to fusions,
in an E-connection the two domains are not merged but connected by means of relations.
Regarding complexity, our transfer results yield only upper bounds. Basically, they
show that the complexity of the algorithm for the fusion is at most one exponent higher
than of the ones for the components. We believe that the complexity of satisfiability in the
fusion of ADSs can indeed be exponentially higher than the complexity of satisfiability in
the component ADSs. However, we do not yet have matching lower bounds, i.e., we know
of no example where this exponential increase in the complexity really happens.
Note that Spaan’s results (1993) on the transfer of NP and PSpace decidability from
the component modal logics to their fusion are restricted to normal modal logics, and that
they make additional assumptions on the algorithms used to solve the satisfiability problem
in the component logics. Nevertheless, for many PSpace-complete description logics it is
easy to see that their fusion is also PSpace-complete. In this sense, the general techniques
for reasoning in the fusion of descriptions logics developed in this paper give only a rough
complexity estimate.

39

Baader, Lutz, Sturm, & Wolter

Appendix A. Proofs
In this appendix, we give detailed proofs of criteria for (relativized) satisfiability in the
fusion of local ADSs. Recall that, from these criteria, the transfer theorems for decidability
easily follow. We have deferred the proofs of these theorems to the appendix since they are
rather technical.
A.1 Proof of Theorem 20
Before we can prove this theorem, we need a technical lemma. In the proof of Theorem 20,
we are going to merge models W1 ∈ M1 and W2 ∈ M2 by means of a bijective function b
from the domain W1 of W1 onto the domain W2 of W2 in such a way that the surrogates
suri (t), t ∈ C 1 (Γ), are respected by b in the sense that
1

w ∈ sur1 (t)W1 ,A ⇔ b(w) ∈ sur2 (t)W2 ,A

2

for all w ∈ W1 and t ∈ C 1 (Γ). The existence of such a bijection is equivalent to the condi1
1
2
2
tion that the cardinalities |sur1 (t)W1 ,A | of sur1 (t)W1 ,A and |sur2 (t)W2 ,A | of sur2 (t)W2 ,A
coincide for all t ∈ C 1 (Γ): if t 6= t0 for t, t0 ∈ C 1 (Γ), then t contains a conjunct which is
i
(equivalent to) the negation of a conjunct of t0 ; hence, for all such t, t0 , we have suri (t)Wi ,A ∩
i
suri (t0 )Wi ,A = ∅ for i ∈ {1, 2}, which clearly yields the above equivalence. The following
lemma will be used to choose models in such a way that this cardinality condition is satisfied.
(We refer the reader to, e.g., Grätzer, 1979 for information about cardinals.)
Lemma 45. Let (L, M) be a local ADS and Γ a set of assertions satisfiable in (L, M).
Then there
exists a cardinal κ such that, for all cardinals κ0 ≥ κ, there exists a model


W = W, F W , RW ∈ M with |W | = κ0 and an assignment A with hW, Ai |= Γ and
|sW,A | ∈ {0, κ0 } for all terms s.



Proof. By assumption, there exists an ADM W0 = W0 , F W0 , RW0 ∈ M and an assignment B = hB1 , B2 i in it such that hW0 , Bi |= Γ. Let κ = max{ℵ0 , |W0 |}. We
show that
Let κ0 ≥ κ. Take κ0 disjoint isomorphic copies hWρ , B1ρ i,

 κ isWas required.

W
Wρ = Wρ , F ρ , R 
ρ , ρ < κ0 , of hW0 , B1 i. (The first member of the list coincides
with W0 .) Let W = W, F W , RW be the disjoint union of the Wρ , ρ < κ0 , and define
hW, A = hA1 , A2 ii by putting A2 (a) = B2 (a), for all a ∈ X , and
[ ρ
A1 (x) =
B1 (x),
ρ<κ0

for all x ∈ V . Note that all object variables are interpreted in W0 . It follows from the
definitions of term semantics and disjoint unions that
[
sW,A =
sWρ ,Bρ ,
(∗)
ρ<κ0

for all terms s. Hence |W | = κ0 and hW, Ai |= Γ. It remains to show that |sW,A | ∈ {0, κ0 }
for every term s. Suppose |sW,A | =
6 0. Then, by (∗), κ0 ≤ |sW,A | ≤ κ × κ0 = κ0 , which means
0
W,A
κ = |s
|.
❏
40

Fusions of Description Logics and Abstract Description Systems

i

i

As noted above, the disjointness of the sets suri (t)Wi ,A and suri (t0 )Wi ,A (for t 6= t0 )
is required in order to ensure the existence of the bijection b. More precisely, in order to
i
merge models W1 , W2 , the sets suri (t)Wi ,A for t member of some “relevant” subset of C 1 (Γ)
must form a partition of Wi ’s domain that satisfies a certain cardinality condition. This is
formalized by the following definition:
Definition 46. Let κ be a cardinal. A set {X1 , . . . , Xn } is called a κ-partition of a set W
iff
1. |Xi | = κ, for all 1 ≤ i ≤ n,
2. Xi ∩ Xj = ∅ whenever i 6= j, and
S
3. W = 1≤i≤n Xi .
{X1 , . . . , Xn } is a κ-partition of an ADM W with domain W iff it is a κ-partition of W .
In the proof, we will enforce that Properties 1 and 3 hold by appropriate constructions,
while Property 2 holds by definition of C 1 (Γ).
Before proving Theorem 20, we repeat its formulation.
Theorem 20. Let Si = (Li , Mi ), i ∈ {1, 2}, be two local ADSs in which L1 is based on
the set of function symbols F and relation symbols R, and L2 is based on G and Q, and
let L = L1 ⊗ L2 and M = M1 ⊗ M2 . If Γ is a finite set of assertions from L, then the
following are equivalent:
1. Γ is satisfiable in (L, M).
2. There exist
(a) a set D ⊆ C 1 (Γ),
(b) for every term t ∈ D an object variable at 6∈ obj(Γ),
(c) for every a ∈ obj(Γ) a term ta ∈ D,
such that the union Γ1 of the following sets of assertions in L1 is satisfiable in
(L1 , M1 ):
W
(d) {at : sur1 (t) | t ∈ D} ∪ {> v sur1 ( D)},
(e) {a : sur1 (ta ) | a ∈ obj(Γ)},

(f ) {R(a, b) | R(a, b) ∈ Γ, R ∈ R},
(g) {sur1 (t1 ) v sur1 (t2 ) | t1 v t2 ∈ Γ} ∪ {a : sur1 (s) | (a : s) ∈ Γ};
and the union Γ2 of the following sets of assertions in L2 is satisfiable in (L2 , M2 ):
W
(h) {at : sur2 (t) | t ∈ D} ∪ {> v sur2 ( D)},
(i) {a : sur2 (ta ) | a ∈ obj(Γ)},

(j) {Q(a, b) | Q(a, b) ∈ Γ, Q ∈ Q}.
41

Baader, Lutz, Sturm, & Wolter

sur1 (s1 )W1 ,A

b

1

b

W1 ,A1

sur1 (s2 )

sur2 (s1 )W2 ,A

2

sur2 (s2 )W2 ,A

2

.
.
.

.
.
.

sur1 (sk )W1 ,A

.
.
.

b

1

sur2 (sk )W2 ,A

W1

2

W2
Figure 3: The mapping b.

Proof. We start with the direction from (2) to (1). Take a set D ⊆ C 1 (Γ) satisfying
the properties listed in the theorem. Take

 cardinals

κi1, i 1∈{1, 2} 
as in Lemma

 245 2for

1
2
(Li , Mi ), put κ = max{κ
1 , κ2 }, and
take W1 , A = A1 , A2 and W2 , A = A1 , A2

with Wi ∈ Mi such that Wi , Ai |= Γi for i ∈ {1, 2}. By Lemma 45, for i ∈ {1, 2} we can
i
assume |Wi | = κ and, |suri (s)Wi ,A | ∈ {0, κ} for all s ∈ D.
i
The sets {suri (s)Wi ,A : s ∈ D}
are κ-partitions
of WiWfor i ∈ {0, 1} since (i) for each s ∈

i
D, we have (as : suri (s)) ∈ Γi , (ii) Wi , A |= > v suri ( D), and (iii) s, s0 ∈ D and s 6= s0
i
i
implies suri (s)Wi ,A ∩ suri (s0 )Wi ,A by definition of D and C 1 . Moreover, obj(Γ1 ) = obj(Γ2 )
1
2
and, for all a ∈ obj(Γ1 ) and s ∈ D, we have A12 (a) ∈ sur1 (s)W1 ,A iff A22 (a) ∈ sur2 (s)W2 ,A .
Together with the fact that A12 and A22 are injective, this implies the existence of a
bijection b from W1 onto W2 such that
1

2

{b(w) : w ∈ sur1 (t)W1 ,A } = sur2 (t)W2 ,A ,
for all t ∈ D, and

b(A12 (a)) = A22 (a),

for all a ∈ obj(Γ1 ). Figure 3, in which it is assumed that D = {s1 , . . . , sk }, illustrates the
mapping b.



Define a model W = W, (F ∪ G)W , (R ∪ Q)W ∈ M by putting
• W = W1 ,
• f W = f W1 , for f ∈ F,
• for all g ∈ G of arity n and all Z1 , . . . , Zn ⊆ W ,
g W (Z1 , . . . , Zn ) = b−1 (g W2 (b(Z1 ), . . . , b(Zn ))),
where b(Z) = {b(z) : z ∈ Z},
• RW = RW1 , for all R ∈ R,
• QW (x, y) iff QW2 (b(x), b(y)), for all Q ∈ Q.
42

Fusions of Description Logics and Abstract Description Systems

Since M2 is closed under isomorphic copies, it is not hard to see that W ∈ M1 ⊗ M2 . Let
A = A1 . To prove the implication from (2) to (1) of the theorem it remains to show that
hW, Ai |= Γ. To this end it suffices to prove the following claim:
Claim. For all terms t ∈ sub1 (Γ), we have
2

1

tW,A = sur1 (t)W1 ,A = b−1 (sur2 (t)W2 ,A ).
Before we prove this claim, let us show that it implies hW, Ai |= Γ. First note that, from
the claim, we obtain
1
tW,A = sur1 (t)W1 ,A for all t ∈ term(Γ).
(1)
This may be proved by induction on the construction of t ∈ term(Γ) from terms in sub1 (Γ)
using the booleans and function symbols from L1 , only. The basis of induction (i.e., the
equality for members of sub1 (Γ)) is stated in the claim and the induction step is straightforward.
We now show that hW, Ai |= Γ is a consequence of (1). Suppose R(a, b) ∈ Γ. Then
R(a, b) ∈ Γ1 and thus hW, Ai |= R(a, b). Similarly, Q(a, b) ∈ Γ implies Q(a, b) ∈ Γ2 and
1
hW, Ai |= Q(a, b). Suppose (a : t) ∈ Γ. Then (a : sur1 (t)) ∈ Γ1 and so A12 (a) ∈ sur1 (t)W1 ,A
which implies, by (1), A12 (a) ∈ tW,A . Hence hW, Ai |= (a : t). If t1 v t2 ∈ Γ, then
sur1 (t1 ) v sur1 (t2 ) ∈ Γ1 and so, by (1), tW,A
⊆ tW,A
. Hence hW, Ai |= t1 v t2 .
1
2
We come to the proof of the claim. It is proved by induction on the structure of t.
Due to the following equalities holding for all t ∈ sub1 (Γ), it suffices to show that tW,A =
1
sur1 (t)W1 ,A .
sur1 (t)W1 ,A

1

1

=

[

{sur1 (s)W1 ,A : s ∈ D, t is a conjunct of s}

=

[

{b−1 (sur2 (s)W2 ,A ) : s ∈ D, t is a conjunct of s}

2

2

= b−1 (sur2 (t)W2 ,A )
W
1
The first equality holds since sur1 ( D)W1 ,A = W1 and, for all s ∈ D, either t or ¬t
is a conjunct of s. The second equality is true by definition of b and the validity of the
thirdWequality can be seen analogously to the validity of the first one by considering that
2
sur2 ( D)W2 ,A = W2 .
1

Hence let us show tW,A = sur1 (t)W1 ,A . For the induction start, let t be a variable. The
1
equation tW,A = sur1 (t)W1 ,A is an immediate consequence of the fact that A = A1 . For
the induction step, we distinguish several cases:

• t = ¬t1 . By induction hypothesis, tW,A
= sur1 (t1 )W1 ,A1 . Hence, tW,A = W \ tW,A
=
1
1
1
1
W
,A
W
,A
1
1
W \ sur1 (t1 )
= sur1 (t)
(since W = W1 ).
• t = t1 ∧ t2 . By induction hypothesis, tW,A
= sur1 (ti )W1 ,A1 for i ∈ {1, 2}. Hence,
i
1
1
1
tW,A = tW,A
∩ tW,A
= sur1 (t1 )W1 ,A ∩ sur1 (t2 )W1 ,A = sur1 (t)W1 ,A .
1
2
• t = t1 ∨ t2 . Similar to the above case.
43

Baader, Lutz, Sturm, & Wolter

1

• t = f (t1 , . . . , tn ). By induction hypothesis, tW,A
= sur1 (ti )W1 ,A for 1 ≤ i ≤ n. Hence,
i
1
1
1
W,A
W,A
tW,A = f W (t1 , . . . , tn ) = f W (sur1 (t1 )W1 ,A , . . . , sur1 (tn )W1 ,A ) = sur1 (t)W1 ,A
(since f W = f W1 ).
• t = g(t1 , . . . , tn ). In this case, tW,A = b−1 (g W2 (b(tW,A
), . . . , b(tW,A
))). Since, by the
n
1
2
2
1
W
,A
−1
W
,A
1
2
above equalities, sur1 (t)
= b (sur2 (t)
), it remains to show that sur2 (t)W2 ,A =
2
2
2
g W2 (b(tW,A
), . . . , b(tW,A
)). Since we have sur2 (t)W2 ,A = g W2 (sur2 (t1 )W2 ,A , . . . , sur2 (tn )W2 ,A ),
n
1
2
this amounts to showing that b(tW,A
) = sur2 (ti )W2 ,A for 1 ≤ i ≤ n. This, however,
i
follows by induction hypothesis together with the above equations.
This concludes the proof of the direction from (2) to (1).
It remains to prove the direction from (1) to (2). Suppose hW, Ai |= Γ, for some W ∈ M
and A = hA1 , A2 i. Put
D = {s ∈ C 1 (Γ) : sW,A 6= ∅}.
Note that the fusion of local ADLs is a local ADL again. Hence (L, M) is local and we may
assume, by Lemma 45, that the sets sW,A are infinite.
Take a new object name as 6∈ obj(Γ) for every s ∈ D and let, for a ∈ obj(Γ),
^
^
ta = {t ∈ sub1 (Γ) : A2 (a) ∈ tW,A } ∧ {¬t : t ∈ sub1 (Γ), A2 (a) 6∈ tW,A }.
We prove that set of assertions Γ1 based on D, ta , a ∈ obj(Γ), and as , s ∈ D, is satisfiable
in (L1 , M1 ).
W
Let F W denote the restriction of (F ∪ G)W to the
 symbols in F.
R
 Similarly,

 1 is the

W
W
W
1
restriction of (R∪Q) to the symbols in R. Set W1 = W, F , R
∈ M1 , A = A1 , A12 ,
where
A11 = A1 ∪ {xt 7→ tW,A : t = g(t1 , . . . , tk ) ∈ sub1 (Γ)},
A12 (a) = A2 (a), for a ∈ obj(Γ), and A12 (as ) ∈ sW,A , for all s ∈ D. Note that we can choose
an injective function A12 because the sW,A are infinite. We show by induction that
sur1 (t)W1 ,A1 = tW,A for all t ∈ term(Γ).

(2)

Let t = x be a variable. Then x is not a surrogate, and so A11 (x) = A1 (x). For the induction
step, we distinguish several cases:
• The inductive steps for t = ¬t1 , t = t1 ∧ t2 , t = t1 ∨ t2 , and t = f (t1 , . . . , tn ), f ∈ F,
are identical to the corresponding cases in the proof of Equation 1, which occurs in
the direction that (2) implies (1) above.
• t = g(t1 , . . . , tn ), where g ∈ G. Then sur1 (t) = xt . Hence A11 (xt ) = tW,A and the
equation is proved.






From Equation 2,
 we obtain
W1 , A1 |= Γ1 : we prove W1 , A1 |= R(a, b) whenever

R(a, b) ∈ Γ1 and W1 , A1 |= sur1 (t1 ) v sur1 (t2 ) whenever sur1 (t1 ) v sur1 (t2 ) ∈ Γ1 . The
remaining formulas from Γ1 are left

 to thereader. Suppose R(a, b) ∈ Γ1 . Then R(a, b) ∈ Γ
and so hW, Ai |= R(a, b). Hence W1 , A1 |= R(a, b). Suppose sur1 (t1 ) v sur1 (t2 ) ∈ Γ1 .
44

Fusions of Description Logics and Abstract Description Systems

⊆ t2W,A . By Equation 2,
Then t1 v t2 ∈ Γ. Hence hW, Ai |= t1 v t2 which means tW,A
1



1
1
sur1 (t1 )W1 ,A ⊆ sur1 (t2 )W1 ,A which means W1 , A1 |= sur1 (t1 ) v sur1 (t2 ).
The construction of a model in M2 satisfying Γ2 is similar and left to the reader.
❏
A.2 Proof of Theorem 30
As in the proof of Theorem 17, we fix two local ADSs Si = (Li , Mi ), i ∈ {1, 2}, in which
L1 is based on the set of function symbols F and relation symbols R, and L2 is based on
G and Q. Let L = L1 ⊗ L2 and M = M1 ⊗ M2 . We assume that S1 and S2 have covering
normal terms.
Similarly to what was done in the previous section, we will merge models by means
1
of bijections which map points in sets sur1 (t)W1 ,A to points in the corresponding sets
2
sur2 (t)W2 ,A . For a finite set of object assertions Γ of L, let Σi (Γ) denote the set of all
s ∈ C i (Γ) such that the term s is satisfiable in (L, M) (for i ∈ {1, 2}). To ensure that
the merging of models succeeds, we must enforce that the elements of Σ1 (Γ) and Σ2 (Γ)
form κ-partitions (for some appropriate κ) of the models to be merged. For Σ1 (Γ), this
is captured by the following lemma. Explicitly stating a dual of this lemma for Σ2 (Γ) is
omitted for brevity.
Lemma 47. Let Γ be a finite set of object assertions of L, κ a cardinal satisfying the
conditions of Lemma 45 for (L, M) and Γ, and Σ1 = Σ1 (Γ). If κ0 ≥ κ, then
1. there exists a model W ∈ M1 and an assignment A such that
{sur1 (s)W,A | s ∈ Σ1 }
is a κ0 -partition of W; and
2. there exists a model W ∈ M2 and an assignment A such that
{sur2 (s)W,A | s ∈ Σ1 }
is a κ0 -partition of W.
Proof. 1. By definition of Σ1 , for each s ∈ Σ1 , we find a model Ws ∈ M and an
assignment As such that sWs ,As 6= ∅. Since the fusion of two local ADSs is again local,
the set of models M is closed under disjoint unions. Hence, there exists a model WΣ1
and an assignment AΣ1 such that sWΣ1 ,AΣ1 6= ∅ for all s ∈ Σ1 . It follows that the set
Γ1 := D{as : s | s ∈ Σ1 } is satisfiable
E in (L, M). By Lemma 45, there thus exists a model
0
0
0
0
W
W
W = W , (F ∪ G) , (R ∪ Q)
∈ M and an assignment A0 such that W0 , A0 |= Γ1 and
0

0

{sW ,A | s ∈ Σ1 } is a κ0 -partition of W 0 . Now let W denote the restriction of W0 to L1 and
define
0
0
A1 = A01 ∪ {xt 7→ tW ,A | t = g(t1 , . . . , tk ) ∈ sub1 (Γ)}.
0

0

Then hW, Ai is as required. To prove this note that sur1 (t)W,A = tW ,A for all t ∈ term(Γ).
2. is similar and left to the reader.
❏
45

Baader, Lutz, Sturm, & Wolter

We repeat the formulation of the theorem to be proved.
Theorem 30. Let Si = (Li , Mi ), i ∈ {1, 2}, be two local ADSs having covering normal
terms in which L1 is based on the set of function symbols F and relation symbols R, and
L2 is based on G and Q, and let L = L1 ⊗ L2 and M = M1 ⊗ M2 . Let Γ be a finite set
of object assertions from L. Put m := dF (Γ), r := dG (Γ), and let c(x) (d(x)) be a covering
normal term for all function symbols in Γ that are in F (G).
For i ∈ {1, 2}, denote by Σi the set of all s ∈ C i (Γ) such that the term s is satisfiable in
(L, M). Then the following three conditions are equivalent:
1. Γ is satisfiable in (L, M).
2. There exist
• for every t ∈ Σ1 an object variable at 6∈ obj(Γ)
• for every a ∈ obj(Γ) a term ta ∈ Σ1
such that the union Γ1 of the following sets of object assertions is satisfiable in
(L1 , M1 ):
W
• {at : sur1 (t ∧ c≤m (sur1 ( Σ1 )) | t ∈ Σ1 },
W
• {a : sur1 (ta ∧ c≤m (sur1 ( Σ1 )) | a ∈ obj(Γ)},
• {R(a, b) | R(a, b) ∈ Γ, R ∈ R},
• {a : sur1 (s) | (a : s) ∈ Γ};
and the union Γ2 of the following sets of object assertions is satisfiable in (L2 , M2 ):
W
• {at : sur2 (t ∧ d≤r (sur2 ( Σ1 )) | t ∈ Σ1 },
W
• {a : sur2 (ta ∧ d≤r (sur2 ( Σ1 )) | a ∈ obj(Γ)},
• {Q(a, b) | Q(a, b) ∈ Γ, Q ∈ Q}.

3. The same condition as in (2) above, with Σ1 replaced by Σ2 .
We start the proof with the direction from (1) to (2) and (1) to (3). The proofs are
dual to
so we only give a proof for (1) ⇒ (2). Suppose hW, Ai |= Γ, where

 each other,
W
W = W, (F ∪ G) , (R ∪ Q)W . By Lemma 45, we can assume that that, for every t ∈ Σ1 ,
|tW,A | is infinite. Take a new object name as 6∈ obj(Γ) for every s ∈ Σ1 and let, for
a ∈ obj(Γ),
^
^
ta = {t ∈ sub1 (Γ) : A2 (a) ∈ tW,A } ∧ {¬t : t ∈ sub1 (Γ), A2 (a) 6∈ tW,A }.
We prove that the set Γ1 of assertions based on ta , a ∈ obj(Γ), and as , s ∈ Σ1 , is satisfiable
in (L1 , M1 ) (the proof is rather similar to the proof of the direction from (1) to (2) in the
proof of Theorem 20). Let F W (resp. G W ) denote the restriction of (F ∪ G)W to the symbols
in F (resp. G). Similarly, RW and
 QW are therestrictions of 
(R ∪ Q)W to the symbols in
R and Q, respectively. Set W1 = W, F W , RW ∈ M1 , A1 = A11 , A12 , where
A11 = A1 ∪ {xt 7→ tW,A | t = g(t1 , . . . , tk ) ∈ sub1 (Γ)},
46

Fusions of Description Logics and Abstract Description Systems

A12 (a) = A2 (a), for a ∈ obj(Γ), and A12 (at ) ∈ tW,A , for all t ∈ Σ1 (we can choose an injective
function for A12 since the sets tW,A are infinite).
As in the corresponding part of the proof of Theorem 20, it can show by induction that
sur1 (t)W1 ,A1 = tW,A for all t ∈ term(Γ).



Let us see now why W1 , A1 |= Γ1 follows from
For R(a, b) ∈ Γ1 we have

 this equation.

1 |= R(a, b). We have hW, Ai |=
R(a,
b)
∈
Γ
and
so
hW,
Ai
|=
R(a,
b).
Hence
W
,
A

 1 1
W
W
( Σ1 ) = > (by the definition
of
Σ
).
Hence
W1 , A |= sur1 ( Σ1 ) = > and so, by
1



W
the definition of c≤m , W1 , A1 |= (c≤m (sur1 ( Σ1 ))) = >. It remains to observe that
A12 (a) ∈ sur1 (ta )W1 ,A1 for all a ∈ obj(Γ), A12 (a) ∈ sur1 (s)W1 ,A1 whenever (a : s) ∈ Γ, and
A12 (at ) ∈ sur1 (t)W1 ,A1 for all t ∈ Σ1 .
The construction of a model in M2 satisfying Γ2 is similar and left to the reader.
It remains to show the implications (2) ⇒ (1) and (3) ⇒ (1). They are similar, so
we concentrate on the first. In the proof of Theorem 20 it was possible to construct the
required model for Γ by merging models for Γ1 and Γ2 . The situation is different here. It
is not possible to W
merge models for Γ1 and
W Γ2 in one step, since we do not know whether
they satisfy sur1 ( Σ1 ) = > and sur2 ( Σ1 ) = >,
W respectively. We only know that
W they
satisfy the approximations a : sur1 (s) ∧ c≤m (sur1 ( Σ1 )) and a : sur2 (s) ∧ d≤r (sur2 ( Σ1 )),
respectively, for a : s ∈ Γ. To merge models of this type we have to distinguish various
pieces of the models and have to add new pieces as well. To define those pieces we need a
technical claim. As in the proof of Theorem 17, take cardinals κi , i ∈ {1, 2} as in Lemma 45
for (Li , Mi ) and put κ = max{κ1 , κ2 }.
Claim 1. Suppose (2) holds.



(a) There exist W1 = W1 , F W , RW ∈ M1 , an assignment A = hA1 , A2 i into W1 , and
a sequence X0 , . . . , Xm of subsets of W1 such that
[a1] A2 (a) ∈ Xm , for all a ∈ obj(Γ1 ),
[a2] hW1 , Ai |= Γ1 ,
[a3] Xn+1 ⊆ Xn ∩ cW1 (Xn ), for all 0 ≤ n < m,
[a4] The set {sur1 (s)W1 ,A ∩ Xm : s ∈ Σ1 } is a κ-partition of Xm ,
[a5] The sets
{sur1 (s)W1 ,A ∩ (Xn − Xn+1 ) : s ∈ Σ1 }
are κ-partitions of Xn − Xn+1 , for 0 ≤ n < m.
[a6] |W1 − X0 | = κ.



(b) There exist W2 = W2 , G W , QW ∈ M2 , an assignment B = hB1 , B2 i, and a sequence
Y0 , . . . , Yr of subsets of W2 such that
[b1] B2 (a) ∈ Yr , for all a ∈ obj(Γ1 ),
[b2] hW2 , Bi |= Γ2 ,
47

Baader, Lutz, Sturm, & Wolter

A−1 = W1 − X0
A0 = X 0 − X 1

..
.

..
.

Am−2 = Xm−2 − Xm−1
Am−1 = Xm−1 − Xm
Xm

W1
Figure 4: The sets Xi .

[b3] Yn+1 ⊆ Yn ∩ dW2 (Yn ), for all 0 ≤ n < r,
[b4] The set {sur2 (s)M,A ∩ Yr : s ∈ Σ1 } is a κ-partition of Yr ,
[b5] The sets
{sur2 (s)M,A ∩ (Yn − Yn+1 ) : s ∈ Σ1 }
are κ-partitions of Yn − Yn+1 , for 0 ≤ n < r.
[b6] |W2 − Y0 | = κ.
Figure 4 illustrates the relation between the sets Xi . (We set Ai = Xi − Xi+1 for 0 ≤ i < m
and A−1 = W
W1 − X0 .) Intuitively, Xm is the set of points for which we know that points in
W1 − sur1 ( Σ1 )W1 ,A are “very far away”. For Xm−1 they are possibly less “far away”, for
Xm−2 possibly even “less far”, and so on for W
Xi , i < m − 1. Finally, for members of A−1 it
is not even known whether they are in sur1 ( Σ1 )W1 ,A or not. Note that all object names
are interpreted in Xm . We now come to the formal construction of the sets Xi .
Proof of Claim 1. We prove (a). Part (b) is proved
andleft to the reader. By

 similarly
W
a
assumption and Lemma 45, we find an ADM Wa = Wa , F , RWa ∈ M1 with |Wa | = κ
and an assignment Aa = hAa1 , Aa2 i such that hWa , Aa i |= Γ1 .
Let
_
Zn = (c≤n (sur1 ( Σ1 )))Wa ,Aa ,
for 0 ≤
 n ≤ m. By Lemma
47 (1) we can take for every n with −1 ≤ n ≤ m an ADM

Wn = Wn , F Wn , RWn ∈ M1 and assignments An such that
n

{sur1 (s)Wn ,A : s ∈ Σ1 }
48

Fusions of Description Logics and Abstract Description Systems

are κ-partitions of Wn .



Take the disjoint union W (with W = W, F W , RW ) of the Wn , −1 ≤ n ≤ m, and Wa .
Define A = hA1 , A2 i in W by putting
[
A1 (x) = Aa1 (x) ∪
Ai1 (x),
−1≤i≤m

for all set variables x and A2 (b) = Aa2 (b), for all object variables b. Let, for 0 ≤ n ≤ m,
[
Xn = Zn ∪
Wi .
n≤i≤m

We show that hW, Ai and the sets Xn , 0 ≤ n ≤ m, are as required.
[a1] We have hWa , Aa i |= Γ1 and so A2 (b) = Aa2 (b) ∈ Zm for all b ∈ obj(Γ1 ). Hence
A2 (b) ∈ Xm = Zm ∪ Wm for all b ∈ obj(Γ1 ).
[a2] By the definition of disjoint unions and because hWa , Aa i |= Γ1 .
[a3] Firstly, we have, by the definition of c≤n t and since cW is monotone (it distributes
over intersections),
Zn+1 ⊆ Zn ∩ cW (Zn ) ⊆ Xn ∩ cW (Xn ).
(3)
Secondly, by the definition of disjoint unions, the first property of covering normal
terms, and since cW is monotone
[
[
[
[
Wi ⊆
Wi ⊆
Wi ∩ cW (
Wi ) ⊆ Xn ∩ cW Xn .
(4)
n+1≤i≤m

n≤i≤m

n≤i≤m

n≤i≤m

From (3) and (4) we obtain
Xn+1 = Zn+1 ∪

[

Wi ⊆ Xn ∩ cW Xn .

(5)

n+1≤i≤m

[a4] We show that the three properties from Definition 46 are satisfied. Since
{sur1 (s)Wm ,Am : s ∈ Σ1 }
is a κ-partition of Wm , we have |sur1 (s)Wm ,Am | = κ for all s ∈ Σ1 . This implies
Property 1 since sur1 (s)W,A ∩ Wm = sur1 (s)Wm ,Am , Wm ⊆ Xm , and |Xm | ≤ κ.
Property 2 is an immediate consequence of the definition of Σ1 . As for Property 3,
we show that, for all w ∈ Xm , we have w ∈ sW,A for an s ∈ Σ1 . Fix a w ∈ Xm . We
distinguish two cases: firstly, assume w ∈ Wm . Then, by the fact that {sur1 (s)Wm ,Am :
s ∈ Σ1 } is a κ-partition of Wm , it is clear
W that there exists an s ∈ Σ1 as required.
≤m (sur ( Σ )))Wa ,Aa . By definition of c≤m t, we have
Secondly, assume
w
∈
Z
=
(c
m
1
1
W
w ∈ (sur1 ( Σ1 ))Wa ,Aa and so again w ∈ sur1 (s)W,A for some s ∈ Σ1 .
[a5] The proof is similar to that of Property [a4].
49

Baader, Lutz, Sturm, & Wolter

[a6] By definition.
This finishes the proof of Claim 1.
Suppose now that we have
E
D
E
D
W1 = W1 , F W1 , RW1 , A, Xm , . . . , X0 and W2 = W2 , G W2 , QW2 , B, Yr , . . . , Y0
satisfying the properties listed in Claim 1. We may assume that
(W1 − Xm ) ∩ (W2 − Yr ) = ∅.
Using an appropriate bijection b from Xm onto Yr we may also assume that Xm = Yr ,
A2 (a) = B2 (a) for all object variables a ∈ obj(Γ1 ), and
sur1 (s)W1 ,A ∩ Xm = sur2 (s)W2 ,B ∩ Xm for all s ∈ Σ1 .

(6)

This follows from the fact that all object variables are mapped by A2 and B2 into Xm and
Yr ([a1], [b1]), respectively, the injectivity of the mappings A2 and B2 , and the conditions
[a4] and [b4] which state that {sur1 (s)W1 ,A ∩ Xm : s ∈ Σ1 } and {sur2 (s)W2 ,B ∩ Yr : s ∈ Σ1 }
both form κ-partitions of Xm = Yr . Some abbreviations are useful: set
• Ai = Xi − Xi+1 , for 0 ≤ i < m,
• Bi = Yi − Yi+1 , for 0 ≤ i < r,
• A−1 = W1 − X0 , B−1 = W2 − Y0 .
So far we have merged the Xm -part of W1 with the Yr -part of W2 . It remains to take care
of the sets Ai , −1 ≤ i < m, and Bi , −1 ≤ i < r: the sets Ai will be merged with new
models Wi ∈ M2 and the sets Bi will be merged with new models Vi from M1 . Thus,
the final model will be obtained by merging the disjoint union of W1 and Wi , −1 ≤ i < m
with the disjoint union of W2 and Vi , −1 ≤ i < r. Figure 5 illustrates this merging. In the
figure, we assume that Σ1 = {s1 , . . . , sk }.
Of course, when merging Ai , i ≥ 0, with a new model Wi we have to respect the partition
{sur1 (t)W1 ,A ∩ Ai | t ∈ Σ1 }
of Ai . And when merging Bi , i ≥ 0, with a new model Vi we have to respect the partition
{sur1 (t)W1 ,B ∩ Bi | t ∈ Σ1 }
of Bi . Note that for A−1 and B−1 there is no partition
care
D to take
E of. We now proceed with
i
i
i
W
W
the formal construction. We find models W = Ai , G , Q
∈ M2 with assignments

 i i
i
B = B1 , B2 , −1 ≤ i ≤ m − 1, such that, for 0 ≤ i ≤ m − 1,
i

i

sur2 (s)W ,B = sur1 (s)W1 ,A ∩ Ai for all s ∈ Σ1 .
This follows from [a5], [a6], and Lemma 47 (2).
50

(7)

Fusions of Description Logics and Abstract Description Systems

Xm Am−1

...

A0 A−1 Vr−1

...

V0 V−1

sur1 (s1 )

.
.
.

...

...

...
Wm−1 . . .

...
...

sur1 (sk )

Yr

W0 W−1 Br−1

B0 B−1

sur2 (s1 )

.
.
.

...

.. .

sur2 (sk )
Figure 5: The bijection.

D
E
i
i
We find, now using [b5], [b6], and Lemma 47 (1), models Vi = Bi , F V , RV ∈ M1



with assignments Ai = Ai1 , Ai2 , −1 ≤ i ≤ r − 1, such that, for 0 ≤ i ≤ r − 1,
i

i

sur1 (s)V ,A = sur2 (s)W2 ,B ∩ Bi for all s ∈ Σ1 .
Let

(8)

D
E
0
0
W01 = W1 ∪ (W2 − Yr ), F W1 , RW1 ∈ M1

be the disjoint union of the Vi , −1 ≤ i < r, and W1 , and let
D
E
0
0
W02 = W2 ∪ (W1 − Xm ), G W2 , QW2 ∈ M2
be the disjoint union of the Wi , −1 ≤ i < m, and W2 . We assume Xm = Yr and so the
domain of both ADMs is
 W1 ∪ W2 .

Define a model W = W, (F ∪ G)W , (R ∪ Q)W ∈ M based on W = W1 ∪W2 by putting
0

• RW = RW1 ,
0

• F W = F W1 ,
0

• QW = QW2 ,
0

• G W = G W2 .
51

Baader, Lutz, Sturm, & Wolter

Define an assignment C = hC1 , C2 i in W by putting
• C2 (a) = A2 (a)(= B2 (a)), for all a ∈ obj(Γ1 ).
S
• C1 (x) = A1 (x) ∪ −1≤i<r Ai1 (x), for all set variables x in term(Γ).
S
Notice that C1 (x) = B1 (x) ∪ −1≤i<m B1i (x), for all set variables x ∈ term(Γ).
• C1 (xt ) = A1 (xt ) ∪

S

• C1 (xt ) = B1 (xt ) ∪

S

−1≤i<r

Ai1 (xt ), for all t = g(t1 , . . . , tk ) ∈ sub1 (Γ).

i
−1≤i<m B1 (xt ),

for all t = f (t1 , . . . , tk ) ∈ sub1 (Γ).

We will show that hW, Ci |= Γ. Firstly, however, we make a list of the relevant properties
of hW, Ci:
Claim 2.
[c1] C2 (a) ∈ Xm = Yr , for all a ∈ obj(Γ);
[c2] hW, Ci |= Γ1 ∪ Γ2 ;
[c3] sur1 (t)W,C ∩ (X0 ∪ Y0 ) = sur2 (t)W,C ∩ (X0 ∪ Y0 ), for all t ∈ Σ1 ;
[c4] sur1 (s)W,C ∩ (X0 ∪ Y0 ) = sur2 (s)W,C ∩ (X0 ∪ Y0 ), for all s ∈ sub1 (Γ);
[c5] Xn+1 ⊆ Xn ∩ cW (Xn ), for all 0 ≤ n < m;
[c6] Yn+1 ⊆ Yn ∩ dW (Yn ), for all 0 ≤ n < r;
[c7] for all g ∈ G of arity l, 0 ≤ n < m, and all C1 , . . . , Cl ⊆ W :
g W (C1 , . . . , Cl ) ∩ Xn = g W (C1 ∩ Xn , . . . , Cl ∩ Xn ) ∩ Xn ;
[c8] for all f ∈ F of arity l, 0 ≤ n < r, and all C1 , . . . , Cl ⊆ W :
f W (C1 , . . . , Cl ) ∩ Yn = f W (C1 ∩ Yn , . . . , Cl ∩ Yn ) ∩ Yn .
Proof of Claim 2. [c1] follows from [a1] and [b1] and the construction of hW, Ci. [c2] follows
from [a2] and [b2]. [c3] follows from the construction of hW, Ci and equations (6), (7), and
(8). [c4] follows from [c3]. [c5] and [c6] follow from [a3] and

 [b3], respectively. It remains
to prove [c7] and [c8]. But [c7] follows from the fact that W, GW is the disjoint union of
structures based on Xn and W − Xn , for 0 ≤ n < m, and [c8] is dual to [c7]. Claim 2 is
proved.
We now show hW, Ci |= Γ. To this end we first show the following:
Claim 3. For all k1 , k2 with 0 ≤ k1 ≤ m and 0 ≤ k2 ≤ r and all s ∈ sub1 (Γ) with dF (s) ≤ k1
and dG (s) ≤ k2 we have, for Z ∈ {Xk1 , Yk2 },
Z ∩ sM,C = Z ∩ sur1 (s)M,C = Z ∩ sur2 (s)M,C .
52

Fusions of Description Logics and Abstract Description Systems

Proof of Claim 3. By [c4] it suffices to prove the first equation. The proof is by induction
on the cardinal k1 + k2 . The induction base k1 = k2 = 0 follows from sur1 (s) = sur2 (s) for
dF (s) = dG (s) = 0.
Suppose the claim is proved for all Xk , Yk0 with k ≤ m, k 0 ≤ r and k + k 0 < k1 + k2 . We
prove the claim for Xk1 , Yk2 . The proof is by induction on the construction of terms s with
dF (s) ≤ k1 and dG (s) ≤ k2 . The boolean cases are trivial.
Suppose s = f (s1 , . . . , sl ) with dF (s) ≤ k1 and dG (s) ≤ k2 . We have to show the
following two statements:
(i) Xk1 ∩ sW,C = Xk1 ∩ sur1 (s)M,C .
(ii) Yk2 ∩ sW,C = Yk2 ∩ sur1 (s)M,C .
Consider (i) first. The induction hypothesis yields
Xk1 −1 ∩ sW,C
= Xk1 −1 ∩ sur1 (si )W,C
i
for 1 ≤ i ≤ l. We have
Xk1 −1 ∩ cW (Xk1 −1 ) ∩ sW,C = Xk1 −1 ∩ cW (Xk1 −1 ) ∩ f W (s1W,C , . . . , slW,C )
= Xk1 −1 ∩ cW (Xk1 −1 ) ∩ f W (sur1 (s1 )W,C , . . . , sur1 (sl )W,C )
= Xk1 −1 ∩ cW (Xk1 −1 ) ∩ sur1 (s)W,C .
The second equation is an immediate consequence of the third property of covering normal
terms as given in Definition 26. Now the equation follows from [c5], i.e. Xk1 ⊆ Xk1 −1 ∩
cW (Xk1 −1 ). (i) is proved.
(ii) Suppose first that k2 = r. Then Yk2 = Xm and the claim can be proved as above
since Xm ⊆ Xk1 and, by induction hypothesis, Xk1 −1 ∩ sW,C
= Xk1 −1 ∩ sur1 (si )W,C , for
i
1 ≤ i ≤ l.
Assume now that k2 < r. By induction hypothesis,
Yk2 ∩ sW,C
= Yk2 ∩ sur2 (si )W,C ,
i
for 1 ≤ i ≤ l. Hence
, . . . , Yk2 ∩ sW,C
) = f W (Yk2 ∩ sur2 (s1 )W,C , . . . , Yk2 ∩ sur2 (sl )W,C ).
f W (Yk2 ∩ sW,C
1
l
We intersect both sides of the equation with Yk2 and derive with the help of [c8]:
Yk2 ∩ f W (sW,C
, . . . , sW,C
) = Yk2 ∩ f W (sur2 (s1 )W,C , . . . , sur2 (sl )W,C ).
1
l
This means Yk2 ∩ sW,C = Yk2 ∩ sur2 (s)W,C , and the equation follows. The statements are
proved.
The case s = g(s1 , . . . , sl ) is dual and left to the reader. We have proved claim 3.
By induction (c.f. in the proof of Theorem 20 the proof of (1) from the corresponding
claim), we obtain from Claim 3:
Xm ∩ sW,C = Xm ∩ sur1 (s)M,C for all s ∈ term(Γ).
53

(9)

Baader, Lutz, Sturm, & Wolter

Let us see how hW, Ai |= Γ follows from (9). We distinguish three cases: Suppose R(a, b) ∈
Γ. Then R(a, b) ∈ Γ1 and therefore hW, Ci |= R(a, b). Similarly, Q(a, b) ∈ Γ implies
Q(a, b) ∈ Γ2 and hW, Ci |= Q(a, b). Suppose (a : t) ∈ Γ. Then (a : sur1 (t)) ∈ Γ1 and so, by
[c2], C2 (a) ∈ sur1 (t)W,C which implies, by (9), C2 (a) ∈ tW,C . Hence hW, Ci |= (a : t). This
finishes the proof of Theorem 30.

References
Areces, C., Blackburn, P., & Marx, M. (2000). The computational complexity of hybrid
temporal logics. Logic Journal of the IGPL, 8 (5), 653–679.
Baader, F. (1991). Augmenting concept languages by transitive closure of roles: An alternative to terminological cycles. In Proc. of the 12th Int. Joint Conf. on Artificial
Intelligence (IJCAI’91).
Baader, F., Bürckert, H.-J., Hollunder, B., Nutt, W., & Siekmann, J. H. (1990). Concept
logics. In Lloyd, J. W. (Ed.), Computational Logics, Symposium Proceedings, pp.
177–201. Springer-Verlag.
Baader, F., Bürckert, H.-J., Nebel, B., Nutt, W., & Smolka, G. (1993). On the expressivity
of feature logics with negation, functional uncertainty, and sort equations. J. of Logic,
Language and Information, 2, 1–18.
Baader, F., & Hanschke, P. (1991). A schema for integrating concrete domains into concept
languages. In Proc. of the 12th Int. Joint Conf. on Artificial Intelligence (IJCAI’91),
pp. 452–457.
Baader, F., & Hanschke, P. (1992). Extensions of concept languages for a mechanical engineering application. In Proc. of the 16th German Workshop on Artificial Intelligence
(GWAI’92), Vol. 671 of Lecture Notes in Computer Science, pp. 132–143, Bonn (Germany). Springer-Verlag.
Baader, F., & Hollunder, B. (1991). A terminological knowledge representation system with
complete inference algorithm. In Proc. of the Workshop on Processing Declarative
Knowledge (PDK’91), Vol. 567 of Lecture Notes in Artificial Intelligence, pp. 67–86.
Springer-Verlag.
Baader, F., & Sattler, U. (1999). Expressive number restrictions in description logics. J. of
Logic and Computation, 9 (3), 319–350.
Ben-Ari, M., Halpern, J. Y., & Pnueli, A. (1982). Deterministic propositional dynamic logic:
Finite models, complexity, and completeness. J. of Computer and System Sciences,
25, 402–417.
Berger, R. (1966). The undecidability of the dominoe problem. Mem. Amer. Math. Soc.,
66, 1–72.
Borgida, A. (1995). Description logics in data management. IEEE Trans. on Knowledge
and Data Engineering, 7 (5), 671–682.
Brachman, R. J., McGuinness, D. L., Patel-Schneider, P. F., Alperin Resnick, L., & Borgida,
A. (1991). Living with CLASSIC: When and how to use a KL-ONE-like language. In
54

Fusions of Description Logics and Abstract Description Systems

Sowa, J. F. (Ed.), Principles of Semantic Networks, pp. 401–456. Morgan Kaufmann,
Los Altos.
Brachman, R. J., & Schmolze, J. G. (1985). An overview of the KL-ONE knowledge representation system. Cognitive Science, 9 (2), 171–216.
Bresciani, P., Franconi, E., & Tessaris, S. (1995). Implementing and testing expressive description logics: Preliminary report. In Proc. of the 1995 Description Logic Workshop
(DL’95), pp. 131–139.
Calvanese, D., De Giacomo, G., & Lenzerini, M. (1999). Reasoning in expressive description
logics with fixpoints based on automata on infinite trees. In Proc. of the 16th Int.
Joint Conf. on Artificial Intelligence (IJCAI’99), pp. 84–89.
Calvanese, D., De Giacomo, G., & Rosati, R. (1998). A note on encoding inverse roles and
functional restrictions in ALC knowledge bases. In Proc. of the 1998 Description Logic
Workshop (DL’98), pp. 69–71. CEUR Electronic Workshop Proceedings, http://ceurws.org/Vol-11/.
Chellas, B. F. (1980). Modal logic. Cambridge University Press, Cambridge, UK.
Danecki, R. (1984). Nondeterministic Propositional Dynamic Logic with intersection is
decidable. In Proc. of the 5th Symp. on Computation Theory, Vol. 208 of Lecture
Notes in Computer Science, pp. 34–53. Springer-Verlag.
De Giacomo, G. (1995). Decidability of Class-Based Knowledge Representation Formalisms.
Ph.D. thesis, Dipartimento di Informatica e Sistemistica, Università di Roma “La
Sapienza”.
De Giacomo, G., & Lenzerini, M. (1994a). Boosting the correspondence between description
logics and propositional dynamic logics. In Proc. of the 12th Nat. Conf. on Artificial
Intelligence (AAAI’94), pp. 205–212. AAAI Press/The MIT Press.
De Giacomo, G., & Lenzerini, M. (1994b). Concept language with number restrictions and
fixpoints, and its relationship with µ-calculus. In Proc. of the 11th Eur. Conf. on
Artificial Intelligence (ECAI’94), pp. 411–415.
De Giacomo, G., & Lenzerini, M. (1995). What’s in an aggregate: Foundations for description logics with tuples and sets. In Proc. of the 14th Int. Joint Conf. on Artificial
Intelligence (IJCAI’95), pp. 801–807.
Donini, F. M., Hollunder, B., Lenzerini, M., Spaccamela, A. M., Nardi, D., & Nutt, W.
(1992). The complexity of existential quantification in concept languages. Artificial
Intelligence, 2–3, 309–327.
Donini, F. M., Lenzerini, M., Nardi, D., & Nutt, W. (1991). Tractable concept languages. In
Proc. of the 12th Int. Joint Conf. on Artificial Intelligence (IJCAI’91), pp. 458–463,
Sydney (Australia).
Donini, F. M., Lenzerini, M., Nardi, D., & Nutt, W. (1997). The complexity of concept
languages. Information and Computation, 134, 1–58.
Donini, F. M., Lenzerini, M., Nardi, D., & Schaerf, A. (1994). Deduction in concept languages: From subsumption to instance checking. J. of Logic and Computation, 4 (4),
423–452.
55

Baader, Lutz, Sturm, & Wolter

Došen, K. (1988). Duality between modal algebras and neighbourhood frames. Studia
Logica, 48, 219–234.
Fine, K., & Schurz, G. (1996). Transfer theorems for stratified modal logics. In Copeland,
J. (Ed.), Logic and Reality: Essays in Pure and Applied Logic. In Memory of Arthur
Prior, pp. 169–213. Oxford University Press.
Fischer, M. J., & Ladner, R. E. (1979). Propositional dynamic logic of regular programs.
J. of Computer and System Sciences, 18, 194–211.
Gabbay, D. M. (1999). Fibring Logics, Vol. 38 of Oxford Logic Guides. Clarendon Press,
Oxford.
Gargov, G., & Goranko, V. (1993). Modal logic with names. J. of Philosophical Logic, 22,
607–636.
Goldblatt, R. I. (1989). Varieties of complex algebras. Annals of Pure and Applied Logic,
38, 173–241.
Goranko, V., & Passy, S. (1992). Using the universal modality: Gains and questions. Journal
of Logic and Computation, 2 (1), 5–30.
Grätzer, G. (1979). Universal Algebra. Springer-Verlag, New York.
Haarslev, V., Möller, R., & Wessel, M. (2001). The description logic ALCN HR+ extended
with concrete domains: A practically motivated approach. In Proceedings of the International Joint Conference on Automated Reasoning IJCAR’01, Lecture Notes in
Artificial Intelligence. Springer-Verlag.
Harel, D. (1984). Dynamic logic. In Handbook of Philosophical Logic, Vol. 2, pp. 497–640.
D. Reidel, Dordrecht (Holland).
Hollunder, B., & Baader, F. (1991). Qualifying number restrictions in concept languages.
Tech. rep. RR-91-03, Deutsches Forschungszentrum für Künstliche Intelligenz (DFKI),
Kaiserslautern (Germany). An abridged version appeared in Proc. of the 2nd Int.
Conf. on the Principles of Knowledge Representation and Reasoning (KR’91).
Hollunder, B., & Nutt, W. (1990). Subsumption algorithms for concept languages. Tech. rep.
RR-90-04, Deutsches Forschungszentrum für Künstliche Intelligenz (DFKI), Kaiserslautern (Germany).
Horrocks, I. (1998). Using an expressive description logic: FaCT or fiction?. In Proc. of the
6th Int. Conf. on Principles of Knowledge Representation and Reasoning (KR’98),
pp. 636–647.
Horrocks, I., & Sattler, U. (1999). A description logic with transitive and inverse roles and
role hierarchies. J. of Logic and Computation, 9 (3), 385–410.
Horrocks, I., Sattler, U., & Tobies, S. (2000). Practical reasoning for very expressive description logics. J. of the Interest Group in Pure and Applied Logic, 8 (3), 239–264.
Jónsson, B., & Tarski, A. (1951). Boolean algebras with operators. I. American Journal of
Mathematics, 73, 891–939.
Jónsson, B., & Tarski, A. (1952). Boolean algebras with operators. II. American Journal
of Mathematics, 74, 127–162.
56

Fusions of Description Logics and Abstract Description Systems

Knuth, D. E. (1973). The Art of Computer Programming, Vol. 3. Addison-Wesley, Mass.
Kracht, M., & Wolter, F. (1991). Properties of independently axiomatizable bimodal logics.
The Journal of Symbolic Logic, 56 (4), 1469–1485.
Kutz, O., Wolter, F., & Zakharyaschev, M. (2001). Connecting abstract description systems.
Submitted. Available from http://www.informatik.uni-leipzig.de/∼wolter/.
Levesque, H. J., & Brachman, R. J. (1987). Expressiveness and tractability in knowledge
representation and reasoning. Computational Intelligence, 3, 78–93.
Lutz, C. (1999). Reasoning with concrete domains. In Dean, T. (Ed.), Proc. of the 16th
Int. Joint Conf. on Artificial Intelligence (IJCAI’99), pp. 90–95, Stockholm, Sweden.
Morgan Kaufmann, Los Altos.
Lutz, C. (2001). Interval-based temporal reasoning with general TBoxes. In Proc. of the
17th Int. Joint Conf. on Artificial Intelligence (IJCAI 2001), pp. 89–94.
Lutz, C., & Sattler, U. (2000). Mary likes all cats. In Proc. of the 2000 Description
Logic Workshop (DL 2000), pp. 213–226. CEUR Electronic Workshop Proceedings,
http://ceur-ws.org/Vol-33/.
Nebel, B. (1988). Computational complexity of terminological reasoning in BACK. Artificial
Intelligence, 34 (3), 371–383.
Nebel, B. (1990). Terminological reasoning is inherently intractable. Artificial Intelligence,
43, 235–249.
Parikh, R. (1980). Propositional logics of programs: Systems, models and complexity. In
Proc. of the 7th ACM SIGACT-SIGPLAN Symp. on Principles of Programming Languages (POPL’80), pp. 186–192, Las Vegas (USA).
Prior, A. N. (1967). Past, Present and Future. Oxford University Press.
Sattler, U. (1996). A concept language extended with different kinds of transitive roles. In
Görz, G., & Hölldobler, S. (Eds.), Proc. of the 20th German Annual Conf. on Artificial
Intelligence (KI’96), No. 1137 in Lecture Notes in Artificial Intelligence, pp. 333–345.
Springer-Verlag.
Schaerf, A. (1993). On the complexity of the instance checking problem in concept languages
with existential quantification. J. of Intelligent Information Systems, 2, 265–278.
Schaerf, A. (1994). Reasoning with individuals in concept languages. Data and Knowledge
Engineering, 13 (2), 141–176.
Schild, K. (1991). A correspondence theory for terminological logics: Preliminary report. In
Proc. of the 12th Int. Joint Conf. on Artificial Intelligence (IJCAI’91), pp. 466–471.
Schmidt-Schauß, M. (1989). Subsumption in KL-ONE is undecidable. In Brachman, R. J.,
Levesque, H. J., & Reiter, R. (Eds.), Proc. of the 1st Int. Conf. on the Principles of
Knowledge Representation and Reasoning (KR’89), pp. 421–431. Morgan Kaufmann,
Los Altos.
Schmidt-Schauß, M., & Smolka, G. (1991). Attributive concept descriptions with complements. Artificial Intelligence, 48 (1), 1–26.
57

Baader, Lutz, Sturm, & Wolter

Spaan, E. (1993). Complexity of Modal Logics. Ph.D. thesis, Department of Mathematics
and Computer Science, University of Amsterdam, The Netherlands.
Van der Hoek, W., & de Rijke, M. (1995). Counting objects. J. of Logic and Computation,
5 (3), 325–345.
Wolter, F. (1998). Fusions of modal logics revisited. In Kracht, M., de Rijke, M., Wansing, H., & Zakharyaschev, M. (Eds.), Advances in Modal Logic, pp. 361–379. CSLI
Publications.
Woods, W. A., & Schmolze, J. G. (1992). The KL-ONE family. In Lehmann, F. W. (Ed.),
Semantic Networks in Artificial Intelligence, pp. 133–178. Pergamon Press. Published
as a special issue of Computers & Mathematics with Applications, Volume 23, Number
2–9.

58

Journal of Artificial Intelligence Research 16 (2002) 321–357

Submitted 09/01; published 06/02

SMOTE: Synthetic Minority Over-sampling Technique
Nitesh V. Chawla

chawla@csee.usf.edu

Department of Computer Science and Engineering, ENB 118
University of South Florida
4202 E. Fowler Ave.
Tampa, FL 33620-5399, USA

Kevin W. Bowyer

kwb@cse.nd.edu

Department of Computer Science and Engineering
384 Fitzpatrick Hall
University of Notre Dame
Notre Dame, IN 46556, USA

Lawrence O. Hall

hall@csee.usf.edu

Department of Computer Science and Engineering, ENB 118
University of South Florida
4202 E. Fowler Ave.
Tampa, FL 33620-5399, USA

W. Philip Kegelmeyer

wpk@california.sandia.gov

Sandia National Laboratories
Biosystems Research Department, P.O. Box 969, MS 9951
Livermore, CA, 94551-0969, USA

Abstract
An approach to the construction of classiﬁers from imbalanced datasets is described.
A dataset is imbalanced if the classiﬁcation categories are not approximately equally represented. Often real-world data sets are predominately composed of “normal” examples
with only a small percentage of “abnormal” or “interesting” examples. It is also the case
that the cost of misclassifying an abnormal (interesting) example as a normal example is
often much higher than the cost of the reverse error. Under-sampling of the majority (normal) class has been proposed as a good means of increasing the sensitivity of a classiﬁer to
the minority class. This paper shows that a combination of our method of over-sampling
the minority (abnormal) class and under-sampling the majority (normal) class can achieve
better classiﬁer performance (in ROC space) than only under-sampling the majority class.
This paper also shows that a combination of our method of over-sampling the minority class
and under-sampling the majority class can achieve better classiﬁer performance (in ROC
space) than varying the loss ratios in Ripper or class priors in Naive Bayes. Our method
of over-sampling the minority class involves creating synthetic minority class examples.
Experiments are performed using C4.5, Ripper and a Naive Bayes classiﬁer. The method
is evaluated using the area under the Receiver Operating Characteristic curve (AUC) and
the ROC convex hull strategy.

1. Introduction
A dataset is imbalanced if the classes are not approximately equally represented. Imbalance
on the order of 100 to 1 is prevalent in fraud detection and imbalance of up to 100,000 to
c
2002
AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

Chawla, Bowyer, Hall & Kegelmeyer

1 has been reported in other applications (Provost & Fawcett, 2001). There have been
attempts to deal with imbalanced datasets in domains such as fraudulent telephone calls
(Fawcett & Provost, 1996), telecommunications management (Ezawa, Singh, & Norton,
1996), text classiﬁcation (Lewis & Catlett, 1994; Dumais, Platt, Heckerman, & Sahami,
1998; Mladenić & Grobelnik, 1999; Lewis & Ringuette, 1994; Cohen, 1995a) and detection
of oil spills in satellite images (Kubat, Holte, & Matwin, 1998).
The performance of machine learning algorithms is typically evaluated using predictive
accuracy. However, this is not appropriate when the data is imbalanced and/or the costs of
diﬀerent errors vary markedly. As an example, consider the classiﬁcation of pixels in mammogram images as possibly cancerous (Woods, Doss, Bowyer, Solka, Priebe, & Kegelmeyer,
1993). A typical mammography dataset might contain 98% normal pixels and 2% abnormal
pixels. A simple default strategy of guessing the majority class would give a predictive accuracy of 98%. However, the nature of the application requires a fairly high rate of correct
detection in the minority class and allows for a small error rate in the majority class in
order to achieve this. Simple predictive accuracy is clearly not appropriate in such situations. The Receiver Operating Characteristic (ROC) curve is a standard technique for
summarizing classiﬁer performance over a range of tradeoﬀs between true positive and false
positive error rates (Swets, 1988). The Area Under the Curve (AUC) is an accepted traditional performance metric for a ROC curve (Duda, Hart, & Stork, 2001; Bradley, 1997; Lee,
2000). The ROC convex hull can also be used as a robust method of identifying potentially
optimal classiﬁers (Provost & Fawcett, 2001). If a line passes through a point on the convex
hull, then there is no other line with the same slope passing through another point with a
larger true positive (TP) intercept. Thus, the classiﬁer at that point is optimal under any
distribution assumptions in tandem with that slope.
The machine learning community has addressed the issue of class imbalance in two ways.
One is to assign distinct costs to training examples (Pazzani, Merz, Murphy, Ali, Hume, &
Brunk, 1994; Domingos, 1999). The other is to re-sample the original dataset, either by oversampling the minority class and/or under-sampling the majority class (Kubat & Matwin,
1997; Japkowicz, 2000; Lewis & Catlett, 1994; Ling & Li, 1998). Our approach (Chawla,
Bowyer, Hall, & Kegelmeyer, 2000) blends under-sampling of the majority class with a
special form of over-sampling the minority class. Experiments with various datasets and
the C4.5 decision tree classiﬁer (Quinlan, 1992), Ripper (Cohen, 1995b), and a Naive Bayes
Classiﬁer show that our approach improves over other previous re-sampling, modifying loss
ratio, and class priors approaches, using either the AUC or ROC convex hull.
Section 2 gives an overview of performance measures. Section 3 reviews the most
closely related work dealing with imbalanced datasets. Section 4 presents the details of
our approach. Section 5 presents experimental results comparing our approach to other
re-sampling approaches. Section 6 discusses the results and suggests directions for future
work.

2. Performance Measures
The performance of machine learning algorithms is typically evaluated by a confusion matrix
as illustrated in Figure 1 (for a 2 class problem). The columns are the Predicted class and the
rows are the Actual class. In the confusion matrix, T N is the number of negative examples
322

SMOTE

Predicted
Negative

Predicted
Positive

Actual
Negative

TN

FP

Actual
Positive

FN

TP

Figure 1: Confusion Matrix
correctly classiﬁed (True Negatives), F P is the number of negative examples incorrectly
classiﬁed as positive (False Positives), F N is the number of positive examples incorrectly
classiﬁed as negative (False Negatives) and T P is the number of positive examples correctly
classiﬁed (True Positives).
Predictive accuracy is the performance measure generally associated with machine learning algorithms and is deﬁned as Accuracy = (T P + T N )/(T P + F P + T N + F N ). In the
context of balanced datasets and equal error costs, it is reasonable to use error rate as a
performance metric. Error rate is 1 − Accuracy. In the presence of imbalanced datasets
with unequal error costs, it is more appropriate to use the ROC curve or other similar
techniques (Ling & Li, 1998; Drummond & Holte, 2000; Provost & Fawcett, 2001; Bradley,
1997; Turney, 1996).
ROC curves can be thought of as representing the family of best decision boundaries for
relative costs of TP and FP. On an ROC curve the X-axis represents %F P = F P/(T N +F P )
and the Y-axis represents %T P = T P/(T P +F N ). The ideal point on the ROC curve would
be (0,100), that is all positive examples are classiﬁed correctly and no negative examples are
misclassiﬁed as positive. One way an ROC curve can be swept out is by manipulating the
balance of training samples for each class in the training set. Figure 2 shows an illustration.
The line y = x represents the scenario of randomly guessing the class. Area Under the ROC
Curve (AUC) is a useful metric for classiﬁer performance as it is independent of the decision
criterion selected and prior probabilities. The AUC comparison can establish a dominance
relationship between classiﬁers. If the ROC curves are intersecting, the total AUC is an
average comparison between models (Lee, 2000). However, for some speciﬁc cost and class
distributions, the classiﬁer having maximum AUC may in fact be suboptimal. Hence, we
also compute the ROC convex hulls, since the points lying on the ROC convex hull are
potentially optimal (Provost, Fawcett, & Kohavi, 1998; Provost & Fawcett, 2001).

3. Previous Work: Imbalanced datasets
Kubat and Matwin (1997) selectively under-sampled the majority class while keeping the
original population of the minority class. They have used the geometric mean as a performance measure for the classiﬁer, which can be related to a single point on the ROC curve.
The minority examples were divided into four categories: some noise overlapping the positive class decision region, borderline samples, redundant samples and safe samples. The
borderline examples were detected using the Tomek links concept (Tomek, 1976). Another
323

Chawla, Bowyer, Hall & Kegelmeyer

ROC

(100, 100)

100
Ideal point

Percent
True

y=x

Positive
increased undersampling
of the majority class moves
the operating point to the
upper right
original data set

0

Percent False Positive

100

Figure 2: Illustration of sweeping out a ROC curve through under-sampling. Increased
under-sampling of the majority (negative) class will move the performance from
the lower left point to the upper right.

related work proposed the SHRINK system that classiﬁes an overlapping region of minority (positive) and majority (negative) classes as positive; it searches for the “best positive
region” (Kubat et al., 1998).
Japkowicz (2000) discussed the eﬀect of imbalance in a dataset. She evaluated three
strategies: under-sampling, resampling and a recognition-based induction scheme. We focus
on her sampling approaches. She experimented on artiﬁcial 1D data in order to easily
measure and construct concept complexity. Two resampling methods were considered.
Random resampling consisted of resampling the smaller class at random until it consisted
of as many samples as the majority class and “focused resampling” consisted of resampling
only those minority examples that occurred on the boundary between the minority and
majority classes. Random under-sampling was considered, which involved under-sampling
the majority class samples at random until their numbers matched the number of minority
class samples; focused under-sampling involved under-sampling the majority class samples
lying further away. She noted that both the sampling approaches were eﬀective, and she also
observed that using the sophisticated sampling techniques did not give any clear advantage
in the domain considered (Japkowicz, 2000).
One approach that is particularly relevant to our work is that of Ling and Li (1998).
They combined over-sampling of the minority class with under-sampling of the majority
class. They used lift analysis instead of accuracy to measure a classiﬁer’s performance. They
proposed that the test examples be ranked by a conﬁdence measure and then lift be used as
the evaluation criteria. A lift curve is similar to an ROC curve, but is more tailored for the
324

SMOTE

marketing analysis problem (Ling & Li, 1998). In one experiment, they under-sampled the
majority class and noted that the best lift index is obtained when the classes are equally
represented (Ling & Li, 1998). In another experiment, they over-sampled the positive
(minority) examples with replacement to match the number of negative (majority) examples
to the number of positive examples. The over-sampling and under-sampling combination
did not provide signiﬁcant improvement in the lift index. However, our approach to oversampling diﬀers from theirs.
Solberg and Solberg (1996) considered the problem of imbalanced data sets in oil slick
classiﬁcation from SAR imagery. They used over-sampling and under-sampling techniques
to improve the classiﬁcation of oil slicks. Their training data had a distribution of 42 oil
slicks and 2,471 look-alikes, giving a prior probability of 0.98 for look-alikes. This imbalance
would lead the learner (without any appropriate loss functions or a methodology to modify
priors) to classify almost all look-alikes correctly at the expense of misclassifying many of
the oil slick samples (Solberg & Solberg, 1996). To overcome this imbalance problem, they
over-sampled (with replacement) 100 samples from the oil slick, and they randomly sampled
100 samples from the non oil slick class to create a new dataset with equal probabilities.
They learned a classiﬁer tree on this balanced data set and achieved a 14% error rate on the
oil slicks in a leave-one-out method for error estimation; on the look alikes they achieved
an error rate of 4% (Solberg & Solberg, 1996).
Another approach that is similar to our work is that of Domingos (1999). He compares
the “metacost” approach to each of majority under-sampling and minority over-sampling.
He ﬁnds that metacost improves over either, and that under-sampling is preferable to minority over-sampling. Error-based classiﬁers are made cost-sensitive. The probability of
each class for each example is estimated, and the examples are relabeled optimally with
respect to the misclassiﬁcation costs. The relabeling of the examples expands the decision
space as it creates new samples from which the classiﬁer may learn (Domingos, 1999).
A feed-forward neural network trained on an imbalanced dataset may not learn to discriminate enough between classes (DeRouin, Brown, Fausett, & Schneider, 1991). The
authors proposed that the learning rate of the neural network be adapted to the statistics
of class representation in the data. They calculated an attention factor from the proportion
of samples presented to the neural network for training. The learning rate of the network
elements was adjusted based on the attention factor. They experimented on an artiﬁcially
generated training set and on a real-world training set, both with multiple (more than two)
classes. They compared this to the approach of replicating the minority class samples to
balance the data set used for training. The classiﬁcation accuracy on the minority class was
improved.
Lewis and Catlett (1994) examined heterogeneous uncertainty sampling for supervised
learning. This method is useful for training samples with uncertain classes. The training
samples are labeled incrementally in two phases and the uncertain instances are passed on
to the next phase. They modiﬁed C4.5 to include a loss ratio for determining the class
values at the leaves. The class values were determined by comparison with a probability
threshold of LR/(LR + 1), where LR is the loss ratio (Lewis & Catlett, 1994).
The information retrieval (IR) domain (Dumais et al., 1998; Mladenić & Grobelnik,
1999; Lewis & Ringuette, 1994; Cohen, 1995a) also faces the problem of class imbalance
in the dataset. A document or web page is converted into a bag-of-words representation;
325

Chawla, Bowyer, Hall & Kegelmeyer

that is, a feature vector reﬂecting occurrences of words in the page is constructed. Usually,
there are very few instances of the interesting category in text categorization. This overrepresentation of the negative class in information retrieval problems can cause problems
in evaluating classiﬁers’ performances. Since error rate is not a good metric for skewed
datasets, the classiﬁcation performance of algorithms in information retrieval is usually
measured by precision and recall:
recall =

TP
TP + FN

precision =

TP
TP + FP

Mladenić and Grobelnik (1999) proposed a feature subset selection approach to deal
with imbalanced class distribution in the IR domain. They experimented with various
feature selection methods, and found that the odds ratio (van Rijsbergen, Harper, & Porter,
1981) when combined with a Naive Bayes classiﬁer performs best in their domain. Odds
ratio is a probabilistic measure used to rank documents according to their relevance to the
positive class (minority class). Information gain for a word, on the other hand, does not
pay attention to a particular target class; it is computed per word for each class. In an
imbalanced text dataset (assuming 98 to 99% is the negative class), most of the features will
be associated with the negative class. Odds ratio incorporates the target class information in
its metric giving better results when compared to information gain for text categorization.
Provost and Fawcett (1997) introduced the ROC convex hull method to estimate the
classiﬁer performance for imbalanced datasets. They note that the problems of unequal
class distribution and unequal error costs are related and that little work has been done to
address either problem (Provost & Fawcett, 2001). In the ROC convex hull method, the
ROC space is used to separate classiﬁcation performance from the class and cost distribution
information.
To summarize the literature, under-sampling the majority class enables better classiﬁers
to be built than over-sampling the minority class. A combination of the two as done in
previous work does not lead to classiﬁers that outperform those built utilizing only undersampling. However, the over-sampling of the minority class has been done by sampling with
replacement from the original data. Our approach uses a diﬀerent method of over-sampling.

4. SMOTE: Synthetic Minority Over-sampling TEchnique
4.1 Minority over-sampling with replacement
Previous research (Ling & Li, 1998; Japkowicz, 2000) has discussed over-sampling with
replacement and has noted that it doesn’t signiﬁcantly improve minority class recognition.
We interpret the underlying eﬀect in terms of decision regions in feature space. Essentially,
as the minority class is over-sampled by increasing amounts, the eﬀect is to identify similar
but more speciﬁc regions in the feature space as the decision region for the minority class.
This eﬀect for decision trees can be understood from the plots in Figure 3.
326

SMOTE

2−attributes, 10% data of the original Mammography dataset

2−attributes, 10% data of the original Mammography dataset
450

200

400

350

150

Attribute 2

Attribute 2

300

250

200

100

150

100

50

50

0

0

2

4

6

8

10

12

14

0

16

1

2

3

4

Attribute 1

5

6

7

8

Attribute 1

(a)

(b)

2−attributes, 10% data of the original Mammography dataset
200

Attribute 2

150

100

50

0

1

2

3

4

5

Attribute 1

6

7

8

(c)
Figure 3: a) Decision region in which the three minority class samples (shown by ’+’) reside
after building a decision tree. This decision region is indicated by the solid-line
rectangle. b) A zoomed-in view of the chosen minority class samples for the same
dataset. Small solid-line rectangles show the decision regions as a result of oversampling the minority class with replication. c) A zoomed-in view of the chosen
minority class samples for the same dataset. Dashed lines show the decision region
after over-sampling the minority class with synthetic generation.

327

Chawla, Bowyer, Hall & Kegelmeyer

The data for the plot in Figure 3 was extracted from a Mammography dataset1 (Woods
et al., 1993). The minority class samples are shown by + and the majority class samples
are shown by o in the plot. In Figure 3(a), the region indicated by the solid-line rectangle
is a majority class decision region. Nevertheless, it contains three minority class samples
shown by ’+’ as false negatives. If we replicate the minority class, the decision region for the
minority class becomes very speciﬁc and will cause new splits in the decision tree. This will
lead to more terminal nodes (leaves) as the learning algorithm tries to learn more and more
speciﬁc regions of the minority class; in essence, overﬁtting. Replication of the minority
class does not cause its decision boundary to spread into the majority class region. Thus,
in Figure 3(b), the three samples previously in the majority class decision region now have
very speciﬁc decision regions.
4.2 SMOTE
We propose an over-sampling approach in which the minority class is over-sampled by creating “synthetic” examples rather than by over-sampling with replacement. This approach
is inspired by a technique that proved successful in handwritten character recognition (Ha
& Bunke, 1997). They created extra training data by performing certain operations on
real data. In their case, operations like rotation and skew were natural ways to perturb
the training data. We generate synthetic examples in a less application-speciﬁc manner, by
operating in “feature space” rather than “data space”. The minority class is over-sampled
by taking each minority class sample and introducing synthetic examples along the line
segments joining any/all of the k minority class nearest neighbors. Depending upon the
amount of over-sampling required, neighbors from the k nearest neighbors are randomly
chosen. Our implementation currently uses ﬁve nearest neighbors. For instance, if the
amount of over-sampling needed is 200%, only two neighbors from the ﬁve nearest neighbors are chosen and one sample is generated in the direction of each. Synthetic samples
are generated in the following way: Take the diﬀerence between the feature vector (sample)
under consideration and its nearest neighbor. Multiply this diﬀerence by a random number
between 0 and 1, and add it to the feature vector under consideration. This causes the
selection of a random point along the line segment between two speciﬁc features. This
approach eﬀectively forces the decision region of the minority class to become more general.
Algorithm SMOTE , on the next page, is the pseudo-code for SMOTE. Table 4.2 shows
an example of calculation of random synthetic samples. The amount of over-sampling
is a parameter of the system, and a series of ROC curves can be generated for diﬀerent
populations and ROC analysis performed.
The synthetic examples cause the classiﬁer to create larger and less speciﬁc decision
regions as shown by the dashed lines in Figure 3(c), rather than smaller and more speciﬁc
regions. More general regions are now learned for the minority class samples rather than
those being subsumed by the majority class samples around them. The eﬀect is that decision trees generalize better. Figures 4 and 5 compare the minority over-sampling with
replacement and SMOTE. The experiments were conducted on the mammography dataset.
There were 10923 examples in the majority class and 260 examples in the minority class
originally. We have approximately 9831 examples in the majority class and 233 examples
1. The data is available from the USF Intelligent Systems Lab, http://morden.csee.usf.edu/˜chawla.

328

SMOTE

in the minority class for the training set used in 10-fold cross-validation. The minority class
was over-sampled at 100%, 200%, 300%, 400% and 500% of its original size. The graphs
show that the tree sizes for minority over-sampling with replacement at higher degrees of
replication are much greater than those for SMOTE, and the minority class recognition of
the minority over-sampling with replacement technique at higher degrees of replication isn’t
as good as SMOTE.
Algorithm SMOTE (T, N, k)
Input: Number of minority class samples T ; Amount of SMOTE N %; Number of nearest
neighbors k
Output: (N/100) * T synthetic minority class samples
1. (∗ If N is less than 100%, randomize the minority class samples as only a random
percent of them will be SMOTEd. ∗)
2. if N < 100
3.
then Randomize the T minority class samples
4.
T = (N/100) ∗ T
5.
N = 100
6. endif
7. N = (int)(N/100) (∗ The amount of SMOTE is assumed to be in integral multiples of
100. ∗)
8. k = Number of nearest neighbors
9. numattrs = Number of attributes
10. Sample[ ][ ]: array for original minority class samples
11. newindex: keeps a count of number of synthetic samples generated, initialized to 0
12. Synthetic[ ][ ]: array for synthetic samples
(∗ Compute k nearest neighbors for each minority class sample only. ∗)
13. for i ← 1 to T
14.
Compute k nearest neighbors for i, and save the indices in the nnarray
15.
Populate(N , i, nnarray)
16. endfor
Populate(N, i, nnarray) (∗ Function to generate the synthetic samples. ∗)
17. while N = 0
18.
Choose a random number between 1 and k, call it nn. This step chooses one of
the k nearest neighbors of i.
19.
for attr ← 1 to numattrs
20.
Compute: dif = Sample[nnarray[nn]][attr] − Sample[i][attr]
21.
Compute: gap = random number between 0 and 1
22.
Synthetic[newindex][attr] = Sample[i][attr] + gap ∗ dif
23.
endfor
24.
newindex++
25.
N = N −1
26. endwhile
27. return (∗ End of Populate. ∗)
End of Pseudo-Code.

329

Chawla, Bowyer, Hall & Kegelmeyer

Consider a sample (6,4) and let (4,3) be its nearest neighbor.
(6,4) is the sample for which k-nearest neighbors are being identiﬁed.
(4,3) is one of its k-nearest neighbors.
Let:
f1 1 = 6 f2 1 = 4 f2 1 - f1 1 = -2
f1 2 = 4 f2 2 = 3 f2 2 - f1 2 = -1
The new samples will be generated as
(f1’,f2’) = (6,4) + rand(0-1) * (-2,-1)
rand(0-1) generates a random number between 0 and 1.
Table 1: Example of generation of synthetic examples (SMOTE).

Pruned decision tree size vs the degree of minority over−sampling
260

240

Decisiion tree size (Number of nodes)

220

200

180

160

140
Synthetic data
Replicated data
120

100

80

60

0

50

100

150

200
250
300
350
Degree of minority over−sampling

400

450

500

Figure 4: Comparison of decision tree sizes for replicated over-sampling and SMOTE for
the Mammography dataset

330

SMOTE

% Minority Correct vs the Degree of Minority Over−sampling
75

%Minority Correct

70

65

60

Synthetic data
Replicated data

55

50
0

50

100

150

200

250

300

350

400

450

500

Degree of Minority Over−sampling

Figure 5: Comparison of % Minority correct for replicated over-sampling and SMOTE for
the Mammography dataset

4.3 Under-sampling and SMOTE Combination
The majority class is under-sampled by randomly removing samples from the majority class
population until the minority class becomes some speciﬁed percentage of the majority class.
This forces the learner to experience varying degrees of under-sampling and at higher degrees
of under-sampling the minority class has a larger presence in the training set. In describing
our experiments, our terminology will be such that if we under-sample the majority class at
200%, it would mean that the modiﬁed dataset will contain twice as many elements from the
minority class as from the majority class; that is, if the minority class had 50 samples and
the majority class had 200 samples and we under-sample majority at 200%, the majority
class would end up having 25 samples. By applying a combination of under-sampling and
over-sampling, the initial bias of the learner towards the negative (majority) class is reversed
in the favor of the positive (minority) class. Classiﬁers are learned on the dataset perturbed
by “SMOTING” the minority class and under-sampling the majority class.

5. Experiments
We used three diﬀerent machine learning algorithms for our experiments. Figure 6 provides
an overview of our experiments.
1. C4.5: We compared various combinations of SMOTE and under-sampling with plain
under-sampling using C4.5 release 8 (Quinlan, 1992) as the base classiﬁer.
331

Chawla, Bowyer, Hall & Kegelmeyer

SMOTE
and Undersampling.

C4.5

Loss-Ratio
Modify costs of majority and minority
varied from 0.9 to 0.001.
classes by changing priors.

Ripper

Naive Bayes

ROC’s generated for SMOTE, Undersampling
and Loss Ratio comparisons. Performance
evaluated with AUC and ROC convex hull.

ROC’s generated for comparison between
SMOTE and Under-sampling using C4.5, and
SMOTE using C4.5 and Naive bayes.
Performance evaluated with AUC and ROC convex hull.

Figure 6: Experiments Overview

2. Ripper: We compared various combinations of SMOTE and under-sampling with
plain under-sampling using Ripper (Cohen, 1995b) as the base classiﬁer. We also
varied Ripper’s loss ratio (Cohen & Singer, 1996; Lewis & Catlett, 1994) from 0.9 to
0.001 (as a means of varying misclassiﬁcation cost) and compared the eﬀect of this
variation with the combination of SMOTE and under-sampling. By reducing the loss
ratio from 0.9 to 0.001 we were able to build a set of rules for the minority class.
3. Naive Bayes Classifier: The Naive Bayes Classiﬁer2 can be made cost-sensitive
by varying the priors of the minority class. We varied the priors of the minority
class from 1 to 50 times the majority class and compared with C4.5’s SMOTE and
under-sampling combination.

These diﬀerent learning algorithms allowed SMOTE to be compared to some methods
that can handle misclassiﬁcation costs directly. %FP and %TP were averaged over 10-fold
cross-validation runs for each of the data combinations. The minority class examples were
over-sampled by calculating the ﬁve nearest neighbors and generating synthetic examples.
The AUC was calculated using the trapezoidal rule. We extrapolated an extra point of TP
= 100% and FP = 100% for each ROC curve. We also computed the ROC convex hull
to identify the optimal classiﬁers, as the points lying on the hull are potentially optimal
classiﬁers (Provost & Fawcett, 2001).
2. The source code was downloaded from http://fuzzy.cs.uni-magdeburg.de/˜borgelt/software.html.

332

SMOTE

5.1 Datasets
We experimented on nine diﬀerent datasets. These datasets are summarized in Table 5.2.
These datasets vary extensively in their size and class proportions, thus oﬀering diﬀerent
domains for SMOTE. In order of increasing imbalance they are:
1. The Pima Indian Diabetes (Blake & Merz, 1998) has 2 classes and 768 samples. The
data is used to identify the positive diabetes cases in a population near Phoenix,
Arizona. The number of positive class samples is only 268. Good sensitivity to
detection of diabetes cases will be a desirable attribute of the classiﬁer.
2. The Phoneme dataset is from the ELENA project3 . The aim of the dataset is to
distinguish between nasal (class 0) and oral sounds (class 1). There are 5 features.
The class distribution is 3,818 samples in class 0 and 1,586 samples in class 1.
3. The Adult dataset (Blake & Merz, 1998) has 48,842 samples with 11,687 samples
belonging to the minority class. This dataset has 6 continuous features and 8 nominal
features. SMOTE and SMOTE-NC (see Section 6.1) algorithms were evaluated on
this dataset. For SMOTE, we extracted the continuous features and generated a new
dataset with only continuous features.
4. The E-state data4 (Hall, Mohney, & Kier, 1991) consists of electrotopological state
descriptors for a series of compounds from the National Cancer Institute’s Yeast AntiCancer drug screen. E-state descriptors from the NCI Yeast AntiCancer Drug Screen
were generated by Tripos, Inc. Brieﬂy, a series of about 60,000 compounds were
tested against a series of 6 yeast strains at a given concentration. The test was a
high-throughput screen at only one concentration so the results are subject to contamination, etc. The growth inhibition of the yeast strain when exposed to the given
compound (with respect to growth of the yeast in a neutral solvent) was measured.
The activity classes are either active — at least one single yeast strain was inhibited
more than 70%, or inactive — no yeast strain was inhibited more than 70%. The
dataset has 53,220 samples with 6,351 samples of active compounds.
5. The Satimage dataset (Blake & Merz, 1998) has 6 classes originally. We chose the
smallest class as the minority class and collapsed the rest of the classes into one as
was done in (Provost et al., 1998). This gave us a skewed 2-class dataset, with 5809
majority class samples and 626 minority class samples.
6. The Forest Cover dataset is from the UCI repository (Blake & Merz, 1998). This
dataset has 7 classes and 581,012 samples. This dataset is for the prediction of forest
cover type based on cartographic variables. Since our system currently works for binary classes we extracted data for two classes from this dataset and ignored the rest.
Most other approaches only work for only two classes (Ling & Li, 1998; Japkowicz,
2000; Kubat & Matwin, 1997; Provost & Fawcett, 2001). The two classes we considered are Ponderosa Pine with 35,754 samples and Cottonwood/Willow with 2,747
3. ftp.dice.ucl.ac.be in the directory pub/neural-nets/ELENA/databases.
4. We would like to thank Steven Eschrich for providing the dataset and description to us.

333

Chawla, Bowyer, Hall & Kegelmeyer

Dataset
Pima
Phoneme
Adult
E-state
Satimage
Forest Cover
Oil
Mammography
Can

Majority Class
500
3818
37155
46869
5809
35754
896
10923
435512

Minority Class
268
1586
11687
6351
626
2747
41
260
8360

Table 2: Dataset distribution
samples. Nevertheless, the SMOTE technique can be applied to a multiple class problem as well by specifying what class to SMOTE for. However, in this paper, we have
focused on 2-classes problems, to explicitly represent positive and negative classes.
7. The Oil dataset was provided by Robert Holte and is used in their paper (Kubat et al.,
1998). This dataset has 41 oil slick samples and 896 non-oil slick samples.
8. The Mammography dataset (Woods et al., 1993) has 11,183 samples with 260 calciﬁcations. If we look at predictive accuracy as a measure of goodness of the classiﬁer
for this case, the default accuracy would be 97.68% when every sample is labeled noncalciﬁcation. But, it is desirable for the classiﬁer to predict most of the calciﬁcations
correctly.
9. The Can dataset was generated from the Can ExodusII data using the AVATAR
(Chawla & Hall, 1999) version of the Mustafa Visualization tool5 . The portion of
the can being crushed was marked as “very interesting” and the rest of the can was
marked as “unknown.” A dataset of size 443,872 samples with 8,360 samples marked
as “very interesting” was generated.
5.2 ROC Creation
A ROC curve for SMOTE is produced by using C4.5 or Ripper to create a classiﬁer for
each one of a series of modiﬁed training datasets. A given ROC curve is produced by ﬁrst
over-sampling the minority class to a speciﬁed degree and then under-sampling the majority
class at increasing degrees to generate the successive points on the curve. The amount of
under-sampling is identical to plain under-sampling. So, each corresponding point on each
ROC curve for a dataset represents the same number of majority class samples. Diﬀerent
ROC curves are produced by starting with diﬀerent levels of minority over-sampling. ROC
curves were also generated by varying the loss ratio in Ripper from 0.9 to 0.001 and by
varying the priors of the minority class from the original distribution to up to 50 times the
majority class for a Naive Bayes Classiﬁer.
5. The Mustafa visualization tool was developed by Mike Glass of Sandia National Labs.

334

SMOTE

Phoneme ROC
100

95

90

85

%TP

Under−C4.5
200 SMOTE−C4.5
Naive Bayes
Hull

80

75

70

65
10

20

30

40

50

60

70

80

90

100

%FP

Figure 7: Phoneme. Comparison of SMOTE-C4.5, Under-C4.5, and Naive Bayes. SMOTEC4.5 dominates over Naive Bayes and Under-C4.5 in the ROC space. SMOTEC4.5 classiﬁers are potentially optimal classiﬁers.

Figures 9 through 23 show the experimental ROC curves obtained for the nine datasets
with the three classiﬁers. The ROC curve for plain under-sampling of the majority class
(Ling & Li, 1998; Japkowicz, 2000; Kubat & Matwin, 1997; Provost & Fawcett, 2001) is
compared with our approach of combining synthetic minority class over-sampling (SMOTE)
with majority class under-sampling. The plain under-sampling curve is labeled “Under”,
and the SMOTE and under-sampling combination ROC curve is labeled “SMOTE”. Depending on the size and relative imbalance of the dataset, one to ﬁve SMOTE and undersampling curves are created. We only show the best results from SMOTE combined with
under-sampling and the plain under-sampling curve in the graphs. The SMOTE ROC curve
from C4.5 is also compared with the ROC curve obtained from varying the priors of minority
class using a Naive Bayes classiﬁer — labeled as “Naive Bayes”. “SMOTE”, “Under”, and
“Loss Ratio” ROC curves, generated using Ripper are also compared. For a given family
of ROC curves, an ROC convex hull (Provost & Fawcett, 2001) is generated. The ROC
convex hull is generated using the Graham’s algorithm (O’Rourke, 1998). For reference, we
show the ROC curve that would be obtained using minority over-sampling by replication
in Figure 19.
Each point on the ROC curve is the result of either a classiﬁer (C4.5 or Ripper) learned
for a particular combination of under-sampling and SMOTE, a classiﬁer (C4.5 or Ripper)
learned with plain under-sampling, or a classiﬁer (Ripper) learned using some loss ratio or
a classiﬁer (Naive Bayes) learned for a diﬀerent prior for the minority class. Each point
represents the average (%TP and %FP) 10-fold cross-validation result. The lower leftmost
point for a given ROC curve is from the raw dataset, without any majority class under335

Chawla, Bowyer, Hall & Kegelmeyer

Phoneme ROC with Ripper
100

95

%TP

90

85

Under−Ripper
200 SMOTE−Ripper
Loss Ratio
Hull

80

75

70

0

10

20

30

40

50
%FP

60

70

80

90

100

Figure 8: Phoneme. Comparison of SMOTE-Ripper, Under-Ripper, and modifying Loss
Ratio in Ripper. SMOTE-Ripper dominates over Under-Ripper and Loss Ratio
in the ROC space. More SMOTE-Ripper classiﬁers lie on the ROC convex hull.

Pima ROC
100

95

90

85

%TP

80

75

Under−C4.5
100 SMOTE−C4.5
Naive Bayes
Hull

70

65

60

55

50
10

20

30

40

50

60

70

80

90

100

%FP

Figure 9: Pima Indians Diabetes. Comparison of SMOTE-C4.5, Under-C4.5, and Naive
Bayes. Naive Bayes dominates over SMOTE-C4.5 in the ROC space.

336

SMOTE

Pima ROC with Ripper
100

95

90

85

%TP

80
Under−Ripper
100 SMOTE−Ripper
Loss Ratio
Hull

75

70

65

60

55
10

20

30

40

50

60

70

80

90

100

%FP

Figure 10: Pima Indians Diabetes. Comparison of SMOTE-Ripper, Under-Ripper, and
modifying Loss Ratio in Ripper. SMOTE-Ripper dominates over Under-Ripper
and Loss Ratio in the ROC space.

sampling or minority class over-sampling. The minority class was over-sampled at 50%,
100%, 200%, 300%, 400%, 500%. The majority class was under-sampled at 10%, 15%,
25%, 50%, 75%, 100%, 125%, 150%, 175%, 200%, 300%, 400%, 500%, 600%, 700%, 800%,
1000%, and 2000%. The amount of majority class under-sampling and minority class oversampling depended on the dataset size and class proportions. For instance, consider the
ROC curves in Figure 17 for the mammography dataset. There are three curves — one for
plain majority class under-sampling in which the range of under-sampling is varied between
5% and 2000% at diﬀerent intervals, one for a combination of SMOTE and majority class
under-sampling, and one for Naive Bayes — and one ROC convex hull curve. The ROC
curve shown in Figure 17 is for the minority class over-sampled at 400%. Each point on
the SMOTE ROC curves represents a combination of (synthetic) over-sampling and undersampling, the amount of under-sampling follows the same range as for plain under-sampling.
For a better understanding of the ROC graphs, we have shown diﬀerent sets of ROC curves
for one of our datasets in Appendix A.
For the Can dataset, we had to SMOTE to a lesser degree than for the other datasets
due to the structural nature of the dataset. For the Can dataset there is a structural
neighborhood already established in the mesh geometry, so SMOTE can lead to creating
neighbors which are under the surface (and hence not interesting), since we are looking at
the feature space of physics variables and not the structural information.
The ROC curves show a trend that as we increase the amount of under-sampling coupled
with over-sampling, our minority classiﬁcation accuracy increases, of course at the expense
of more majority class errors. For almost all the ROC curves, the SMOTE approach dom337

Chawla, Bowyer, Hall & Kegelmeyer

Satimage ROC
100

95

90

85
Under−C4.5
200 SMOTE−C4.5
Naive Bayes
Hull

%TP

80

75

70

65

60

55

50

0

10

20

30

40

50
%FP

60

70

80

90

100

Figure 11: Satimage. Comparison of SMOTE-C4.5, Under-C4.5, and Naive Bayes. The
ROC curves of Naive Bayes and SMOTE-C4.5 show an overlap; however, at
higher TP’s more points from SMOTE-C4.5 lie on the ROC convex hull.

Satimage ROC with Ripper
100

95

90

85

%TP

80
Under−Ripper
300 SMOTE−Ripper
Loss Ratio
Hull

75

70

65

60

55

50

0

10

20

30

40

50
%FP

60

70

80

90

100

Figure 12: Satimage. Comparison of SMOTE-Ripper, Under-Ripper, and modifying Loss
Ratio in Ripper. SMOTE-Ripper dominates the ROC space. The ROC convex
hull is mostly constructed with points from SMOTE-Ripper.

338

SMOTE

Covtype ROC
100

90

80

70

%TP

60
Under−C4.5
300 SMOTE−C4.5
Naive Bayes
Hull

50

40

30

20

10

0

10

20

30

40

50
%FP

60

70

80

90

100

Figure 13: Forest Cover. Comparison of SMOTE-C4.5, Under-C4.5, and Naive Bayes.
SMOTE-C4.5 and Under-C4.5 ROC curves are very close to each other. However, more points from the SMOTE-C4.5 ROC curve lie on the ROC convex
hull, thus establishing a dominance.

inates. Adhering to the deﬁnition of ROC convex hull, most of the potentially optimal
classiﬁers are the ones generated with SMOTE.
5.3 AUC Calculation
The Area Under the ROC curve (AUC) is calculated using a form of the trapezoid rule. The
lower leftmost point for a given ROC curve is a classiﬁer’s performance on the raw data.
The upper rightmost point is always (100%, 100%). If the curve does not naturally end at
this point, the point is added. This is necessary in order for the AUC’s to be compared
over the same range of %FP.
The AUCs listed in Table 5.3 show that for all datasets the combined synthetic minority over-sampling and majority over-sampling is able to improve over plain majority
under-sampling with C4.5 as the base classiﬁer. Thus, our SMOTE approach provides
an improvement in correct classiﬁcation of data in the underrepresented class. The same
conclusion holds from an examination of the ROC convex hulls. Some of the entries are
missing in the table, as SMOTE was not applied at the same amounts to all datasets. The
amount of SMOTE was less for less skewed datasets. Also, we have not included AUC’s
for Ripper/Naive Bayes. The ROC convex hull identiﬁes SMOTE classiﬁers to be potentially optimal as compared to plain under-sampling or other treatments of misclassiﬁcation
costs, generally. Exceptions are as follows: for the Pima dataset, Naive Bayes dominates
over SMOTE-C4.5; for the Oil dataset, Under-Ripper dominates over SMOTE-Ripper. For
the Can dataset, SMOTE-classifier (classifier = C4.5 or Ripper) and Under-classifier ROC
339

Chawla, Bowyer, Hall & Kegelmeyer

Covtype ROC with RIPPER
100

98

96

%TP

94
Under−Ripper
100 SMOTE−Ripper
Loss Ratio
Hull

92

90

88

86

0

10

20

30

40

50
%FP

60

70

80

90

100

Figure 14: Forest Cover. Comparison of SMOTE-Ripper, Under-Ripper, and modifying
Loss Ratio in Ripper. SMOTE-Ripper shows a domination in the ROC space.
More points from SMOTE-Ripper curve lie on the ROC convex hull.

Oil ROC
100

90

80

70

%TP

60

50

40
Under−C4.5
500 SMOTE−C4.5
Naive Bayes
Hull

30

20

10

0

0

10

20

30

40

50
%FP

60

70

80

90

100

Figure 15: Oil. Comparison of SMOTE-C4.5, Under-C4.5, and Naive Bayes. Although,
SMOTE-C4.5 and Under-C4.5 ROC curves intersect at points, more points from
SMOTE-C4.5 curve lie on the ROC convex hull.

340

SMOTE

Oil ROC with Ripper
100

90

80

%TP

70
Under−Ripper
300 SMOTE−Ripper
Loss Ratio
Hull

60

50

40

30

0

10

20

30

40

50
%FP

60

70

80

90

100

Figure 16: Oil. Comparison of SMOTE-Ripper, Under-Ripper, and modifying Loss Ratio
in Ripper. Under-Ripper and SMOTE-Ripper curves intersect, and more points
from the Under-Ripper curve lie on the ROC convex hull.

Mammography ROC
100

90

80

70
Under−C4.5
400 SMOTE−C4.5
Naive Bayes
Hull

%TP

60

50

40

30

20

10

0

0

10

20

30

40

50
%FP

60

70

80

90

100

Figure 17: Mammography. Comparison of SMOTE-C4.5, Under-C4.5, and Naive Bayes.
SMOTE-C4.5 and Under-C4.5 curves intersect in the ROC space; however, by
virtue of number of points on the ROC convex hull, SMOTE-C4.5 has more
potentially optimal classiﬁers.

341

Chawla, Bowyer, Hall & Kegelmeyer

Mammography ROC with RIPPER
100

95

90

85

%TP

80
Under−Ripper
400 SMOTE−Ripper
Loss Ratio
Hull

75

70

65

60

55

0

10

20

30

40

50
%FP

60

70

80

90

100

Figure 18: Mammography. Comparison of SMOTE-Ripper, Under-Ripper, and modifying
Loss Ratio in Ripper. SMOTE-Ripper dominates the ROC space for TP > 75%.
Mammography ROC with C4.5
100

95

90

85

%TP

80

75

70
400 SMOTE
400 Replicate
Hull

65

60

55

50

0

10

20

30

40

50
%FP

60

70

80

90

100

Figure 19: A comparison of over-sampling minority class examples by SMOTE and oversampling the minority class examples by replication for the Mammography
dataset.

342

SMOTE

E−state ROC
100

90

80

70

%TP

60

50

40
Under−C4.5
500 SMOTE−C4.5
Naive Bayes
Hull

30

20

10

0

0

10

20

30

40

50
%FP

60

70

80

90

100

Figure 20: E-state. (a) Comparison of SMOTE-C4.5, Under-C4.5, and Naive Bayes.
SMOTE-C4.5 and Under-C4.5 curves intersect in the ROC space; however,
SMOTE-C4.5 has more potentially optimal classiﬁers, based on the number
of points on the ROC convex hull.

E−state ROC with Ripper
100

90

80

70

%TP

60

50

40
Under−Ripper
100 SMOTE−Ripper
Loss Ratio
Hull

30

20

10

0

0

10

20

30

40

50
%FP

60

70

80

90

100

Figure 21: E-state. Comparison of SMOTE-Ripper, Under-Ripper, and modifying Loss
Ratio in Ripper. SMOTE-Ripper has more potentially optimal classiﬁers, based
on the number of points on the ROC convex hull.

343

Chawla, Bowyer, Hall & Kegelmeyer

Can ROC
100

90

80

70

%TP

60

50

40

Under−C4.5
100 SMOTE−C4.5
Naive Bayes
Hull

30

20

10

0

0

10

20

30

40

50
%FP

60

70

80

90

100

Figure 22: Can. Comparison of SMOTE-C4.5, Under-C4.5, and Naive Bayes. SMOTEC4.5 and Under-C4.5 ROC curves overlap for most of the ROC space.

Can ROC with Ripper
100

90

80

70

%TP

60

50

40

Under−Ripper
50 SMOTE−Ripper
Loss Ratio
Hull

30

20

10

0

0

10

20

30

40

50
%FP

60

70

80

90

100

Figure 23: Can. Comparison of SMOTE-Ripper, Under-Ripper, and modifying Loss Ratio
in Ripper. SMOTE-Ripper and Under-Ripper ROC curves overlap for most of
the ROC space.

344

SMOTE

Dataset

Under

Pima
Phoneme
Satimage
Forest Cover
Oil
Mammography
E-state
Can

7242
8622
8900
9807
8524
9260
6811
9535

50
SMOTE

9560

100
SMOTE
7307
8644
8957
9832
8523
9250
6792
9505

200
SMOTE

300
SMOTE

400
SMOTE

500
SMOTE

8661
8979
9834
8368
9265
6828
9505

8963
9849
8161
9311
6784
9494

8975
9841
8339
9330
6788
9472

8960
9842
8537
9304
6779
9470

Table 3: AUC’s [C4.5 as the base classiﬁer] with the best highlighted in bold.

curves overlap in the ROC space. For all the other datasets, SMOTE-classifier has more
potentially optimal classiﬁers than any other approach.
5.4 Additional comparison to changing the decision thresholds
Provost (2000) suggested that simply changing the decision threshold should always be
considered as an alternative to more sophisticated approaches. In the case of C4.5, this
would mean changing the decision threshold at the leaves of the decision trees. For example,
a leaf could classify examples as the minority class even if more than 50% of the training
examples at the leaf represent the majority class. We experimented by setting the decision
thresholds at the leaves for the C4.5 decision tree learner at 0.5, 0.45, 0.42, 0.4, 0.35, 0.32,
0.3, 0.27, 0.25, 0.22, 0.2, 0.17, 0.15, 0.12, 0.1, 0.05, 0.0. We experimented on the Phoneme
dataset. Figure 24 shows the comparison of the SMOTE and under-sampling combination
against C4.5 learning by tuning the bias towards the minority class. The graph shows that
the SMOTE and under-sampling combination ROC curve is dominating over the entire
range of values.
5.5 Additional comparison to one-sided selection and SHRINK
For the oil dataset, we also followed a slightly diﬀerent line of experiments to obtain results
comparable to (Kubat et al., 1998). To alleviate the problem of imbalanced datasets the
authors have proposed (a) one-sided selection for under-sampling the majority class (Kubat
& Matwin, 1997) and (b) the SHRINK system (Kubat et al., 1998). Table 5.5 contains the
results from (Kubat et al., 1998). Acc+ is the accuracy on positive (minority) examples and
Acc− is the accuracy on the negative (majority) examples. Figure 25 shows the trend for
Acc+ and Acc− for one combination of the SMOTE strategy and varying degrees of undersampling of the majority class. The Y-axis represents the accuracy and the X-axis represents
the percentage majority class under-sampled. The graphs indicate that in the band of
under-sampling between 50% and 125% the results are comparable to those achieved by
SHRINK and better than SHRINK in some cases. Table 5.5 summarizes the results for the
SMOTE at 500% and under-sampling combination. We also tried combinations of SMOTE
at 100-400% and varying degrees of under-sampling and achieved comparable results. The
345

Chawla, Bowyer, Hall & Kegelmeyer

Phoneme: ROC comparison between SMOTE and C4.5 variation of decision thresholds
100

95

%TP

90
SMOTE
Varying C4.5 decision thresholds
Hull
85

80

75
10

20

30

40

50

60

70

80

90

100

%FP

Figure 24: SMOTE and Under-sampling combination against C4.5 learning by tuning the
bias towards the minority class

SMOTE and Under−sampling
100

90

Accuracy

80

Accuracy on majority (negative class)
Accuracy on minority (positive class)

70

60

50

40

30

0

100

200

300
400
500
600
Percentage under−sampling of majority class

700

800

Figure 25: SMOTE (500 OU) and Under-sampling combination performance

SHRINK approach and our SMOTE approach are not directly comparable, though, as they
see diﬀerent data points. SMOTE oﬀers no clear improvement over one-sided selection.
346

SMOTE

Method
SHRINK
One-sided selection

Acc+
82.5%
76.0%

Acc−
60.9%
86.6%

Table 4: Cross-validation results (Kubat et al., 1998)

Under-sampling %
10%
15%
25%
50%
75%
100%
125%
150%
175%
200%
300%
400%
500%
600%
700%
800%

Acc+
64.7%
62.8%
64.0%
89.5%
83.7%
78.3%
84.2%
83.3%
85.0%
81.7%
89.0%
95.5%
98.0%
98.0%
96.0%
90.7%

Acc−
94.2%
91.3%
89.1%
78.9%
73.0%
68.7%
68.1%
57.8%
57.8%
56.7%
55.0%
44.2%
35.5%
40.0%
32.8%
33.3%

Table 5: Cross-validation results for SMOTE at 500% SMOTE on the Oil data set.

347

Chawla, Bowyer, Hall & Kegelmeyer

6. Future Work
There are several topics to be considered further in this line of research. Automated adaptive
selection of the number of nearest neighbors would be valuable. Diﬀerent strategies for
creating the synthetic neighbors may be able to improve the performance. Also, selecting
nearest neighbors with a focus on examples that are incorrectly classiﬁed may improve
performance. A minority class sample could possibly have a majority class sample as its
nearest neighbor rather than a minority class sample. This crowding will likely contribute
to the redrawing of the decision surfaces in favor of the minority class. In addition to
these topics, the following subsections discuss two possible extensions of SMOTE, and an
application of SMOTE to information retrieval.
6.1 SMOTE-NC
While our SMOTE approach currently does not handle data sets with all nominal features,
it was generalized to handle mixed datasets of continuous and nominal features. We call this
approach Synthetic Minority Over-sampling TEchnique-Nominal Continuous [SMOTE-NC].
We tested this approach on the Adult dataset from the UCI repository. The SMOTE-NC
algorithm is described below.
1. Median computation: Compute the median of standard deviations of all continuous
features for the minority class. If the nominal features diﬀer between a sample and
its potential nearest neighbors, then this median is included in the Euclidean distance
computation. We use median to penalize the diﬀerence of nominal features by an
amount that is related to the typical diﬀerence in continuous feature values.
2. Nearest neighbor computation: Compute the Euclidean distance between the feature
vector for which k-nearest neighbors are being identiﬁed (minority class sample) and
the other feature vectors (minority class samples) using the continuous feature space.
For every diﬀering nominal feature between the considered feature vector and its
potential nearest-neighbor, include the median of the standard deviations previously
computed, in the Euclidean distance computation. Table 2 demonstrates an example.
F1 = 1 2 3 A B C [Let this be the sample for which we are computing nearest
neighbors]
F2 = 4 6 5 A D E
F3 = 3 5 6 A B K
So, Euclidean Distance between F2 and F1 would be:
Eucl = sqrt[(4-1)2 + (6-2)2 + (5-3)2 + Med2 + Med2 ]
Med is the median of the standard deviations of continuous features of the minority class.
The median term is included twice for feature numbers 5: B→D and 6: C→E,
which diﬀer for the two feature vectors: F1 and F2.

Table 6: Example of nearest neighbor computation for SMOTE-NC.

348

SMOTE

3. Populate the synthetic sample: The continuous features of the new synthetic minority
class sample are created using the same approach of SMOTE as described earlier. The
nominal feature is given the value occuring in the majority of the k-nearest neighbors.
The SMOTE-NC experiments reported here are set up the same as those with SMOTE,
except for the fact that we examine one dataset only. SMOTE-NC with the Adult dataset
diﬀers from our typical result: it performs worse than plain under-sampling based on AUC,
as shown in Figures 26 and 27. We extracted only continuous features to separate the eﬀect
of SMOTE and SMOTE-NC on this dataset, and to determine whether this oddity was
due to our handling of nominal features. As shown in Figure 28, even SMOTE with only
continuous features applied to the Adult dataset, does not achieve any better performance
than plain under-sampling. Some of the minority class continuous features have a very high
variance, so, the synthetic generation of minority class samples could be overlapping with
the majority class space, thus leading to more false positives than plain under-sampling.
This hypothesis is also supported by the decreased AUC measure as we SMOTE at degrees
greater than 50%. The higher degrees of SMOTE lead to more minority class samples in
the dataset, and thus a greater overlap with the majority class decision space.
Adult SMOTE−NC
100

95

90

85

%TP

80
Under−C4.5
50 SMOTE−NC−C4.5
Naive Bayes
Hull

75

70

65

60

55

50

0

10

20

30

40

50
%FP

60

70

80

90

100

Figure 26: Adult. Comparison of SMOTE-C4.5, Under-C4.5, and Naive Bayes. SMOTEC4.5 and Under-C4.5 ROC curves overlap for most of the ROC space.

6.2 SMOTE-N
Potentially, SMOTE can also be extended for nominal features — SMOTE-N — with the
nearest neighbors computed using the modiﬁed version of Value Diﬀerence Metric (Stanﬁll
& Waltz, 1986) proposed by Cost and Salzberg (1993). The Value Diﬀerence Metric (VDM)
looks at the overlap of feature values over all feature vectors. A matrix deﬁning the distance
349

Chawla, Bowyer, Hall & Kegelmeyer

Adult ROC with Ripper
100

95

90

%TP

85

80

Under−Ripper
50 SMOTE−Ripper
Loss Ratio
Hull

75

70

65

60

0

10

20

30

40

50
%FP

60

70

80

90

100

Figure 27: Adult. Comparison of SMOTE-Ripper, Under-Ripper, and modifying Loss Ratio in Ripper. SMOTE-Ripper and Under-Ripper ROC curves overlap for most
of the ROC space.
Adult only continuous [C4.5]
100

90

%TP

80

70

Under
50 SMOTE

60

50

40

0

10

20

30

40

50
%FP

60

70

80

90

100

Figure 28: Adult with only continuous features. The overlap of SMOTE-C4.5 and UnderC4.5 is observed under this scenario as well.

350

SMOTE

between corresponding feature values for all feature vectors is created. The distance δ
between two corresponding feature values is deﬁned as follows.
δ(V1 , V2 ) =

n

C1i

|

i=1

C1

−

C2i k
|
C2

(1)

In the above equation, V1 and V2 are the two corresponding feature values. C1 is the total
number of occurrences of feature value V1 , and C1i is the number of occurrences of feature
value V1 for class i. A similar convention can also be applied to C2i and C2 . k is a constant,
usually set to 1. This equation is used to compute the matrix of value diﬀerences for each
nominal feature in the given set of feature vectors. Equation 1 gives a geometric distance
on a ﬁxed, ﬁnite set of values (Cost & Salzberg, 1993). Cost and Salzberg’s modiﬁed VDM
omits the weight term wfa included in the δ computation by Stanﬁll and Waltz, which has
an eﬀect of making δ symmetric. The distance ∆ between two feature vectors is given by:

∆(X, Y ) = wx wy

N


δ(xi , yi )r

(2)

i=1

r = 1 yields the Manhattan distance, and r = 2 yields the Euclidean distance (Cost &
Salzberg, 1993). wx and wy are the exemplar weights in the modiﬁed VDM. wy = 1 for a
new example (feature vector), and wx is the bias towards more reliable examples (feature
vectors) and is computed as the ratio of the number of uses of a feature vector to the number
of correct uses of the feature vector; thus, more accurate feature vectors will have wx ≈
1. For SMOTE-N we can ignore these weights in equation 2, as SMOTE-N is not used for
classiﬁcation purposes directly. However, we can redeﬁne these weights to give more weight
to the minority class feature vectors falling closer to the majority class feature vectors; thus,
making those minority class features appear further away from the feature vector under
consideration. Since, we are more interested in forming broader but accurate regions of the
minority class, the weights might be used to avoid populating along neighbors which fall
closer to the majority class. To generate new minority class feature vectors, we can create
new set feature values by taking the majority vote of the feature vector in consideration and
its k nearest neighbors. Table 6.2 shows an example of creating a synthetic feature vector.
Let F1 = A B C D E be the feature vector under consideration
and let its 2 nearest neighbors be
F2 = A F C G N
F3 = H B C D N
The application of SMOTE-N would create the following feature vector:
FS = A B C D N
Table 7: Example of SMOTE-N

351

Chawla, Bowyer, Hall & Kegelmeyer

6.3 Application of SMOTE to Information Retrieval
We are investigating the application of SMOTE to information retrieval (IR). The IR problems come with a plethora of features and potentially many categories. SMOTE would have
to be applied in conjunction with a feature selection algorithm, after transforming the given
document or web page in a bag-of-words format.
An interesting comparison to SMOTE would be the combination of Naive Bayes and
Odds ratio. Odds ratio focuses on a target class, and ranks documents according to their
relevance to the target or positive class. SMOTE also focuses on a target class by creating
more examples of that class.

7. Summary
The results show that the SMOTE approach can improve the accuracy of classiﬁers for
a minority class. SMOTE provides a new approach to over-sampling. The combination
of SMOTE and under-sampling performs better than plain under-sampling. SMOTE was
tested on a variety of datasets, with varying degrees of imbalance and varying amounts of
data in the training set, thus providing a diverse testbed. The combination of SMOTE and
under-sampling also performs better, based on domination in the ROC space, than varying
loss ratios in Ripper or by varying the class priors in Naive Bayes Classiﬁer: the methods
that could directly handle the skewed class distribution. SMOTE forces focused learning
and introduces a bias towards the minority class. Only for Pima — the least skewed dataset
— does the Naive Bayes Classiﬁer perform better than SMOTE-C4.5. Also, only for the Oil
dataset does the Under-Ripper perform better than SMOTE-Ripper. For the Can dataset,
SMOTE-classifier and Under-classifier ROC curves overlap in the ROC space. For all the
rest of the datasets SMOTE-classifier performs better than Under-classifier, Loss Ratio,
and Naive Bayes. Out of a total of 48 experiments performed, SMOTE-classifier does not
perform the best only for 4 experiments.
The interpretation of why synthetic minority over-sampling improves performance where
as minority over-sampling with replacement does not is fairly straightforward. Consider
the eﬀect on the decision regions in feature space when minority over-sampling is done
by replication (sampling with replacement) versus the introduction of synthetic examples.
With replication, the decision region that results in a classiﬁcation decision for the minority
class can actually become smaller and more speciﬁc as the minority samples in the region are
replicated. This is the opposite of the desired eﬀect. Our method of synthetic over-sampling
works to cause the classiﬁer to build larger decision regions that contain nearby minority
class points. The same reasons may be applicable to why SMOTE performs better than
Ripper’s loss ratio and Naive Bayes; these methods, nonetheless, are still learning from
the information provided in the dataset, albeit with diﬀerent cost information. SMOTE
provides more related minority class samples to learn from, thus allowing a learner to carve
broader decision regions, leading to more coverage of the minority class.

Acknowledgments
This research was partially supported by the United States Department of Energy through
the Sandia National Laboratories ASCI VIEWS Data Discovery Program, contract number
352

SMOTE

DE-AC04-76DO00789. We thank Robert Holte for providing the oil spill dataset used in
their paper. We also thank Foster Provost for clarifying his method of using the Satimage
dataset. We would also like to thank the anonymous reviewers for their various insightful
comments and suggestions.

353

Chawla, Bowyer, Hall & Kegelmeyer

Appendix A. ROC graphs for Oil Dataset
The following ﬁgures show diﬀerent sets of ROC curves for the oil dataset. Figure 29 (a)
shows the ROC curves for the Oil dataset, as included in the main text; Figure 29(b) shows
the ROC curves without the ROC convex hull; Figure 29(c) shows the two convex hulls,
obtained with and without SMOTE. The ROC convex hull shown by dashed lines and stars
in Figure 29(c), was computed by including Under-C4.5 and Naive Bayes in the family of
ROC curves. The ROC convex hull shown by solid line and small circles in Figure 29(c) was
computed by including 500 SMOTE-C4.5, Under-C4.5, and Naive Bayes in the family of
ROC curves. The ROC convex hull with SMOTE dominates the ROC convex hull without
SMOTE, hence SMOTE-C4.5 contributes more optimal classiﬁers.
Oil

90

90

80

80

70

70

60

60

%TP

100

50

40

30

20

Under−C4.5
500 SMOTE−C4.5
Naive Bayes

30

20

10

0

50

40
Under−C4.5
500 SMOTE−C4.5
Naive Bayes
Hull

10

0

10

20

30

40

50
%FP

60

70

80

90

0

100

0

10

20

30

40

(a)

50
%FP

60

70

80

90

(b)
Oil ROC Convex Hulls
100

90

80

70

60

%TP

%TP

Oil ROC
100

50
Convex Hull with SMOTE
Convex Hull without SMOTE

40

30

20

10

0

0

10

20

30

40

50
%FP

60

70

80

90

100

(c)
Figure 29: ROC curves for the Oil Dataset. (a) ROC curves for SMOTE-C4.5, UnderC4.5, Naive Bayes, and their ROC convex hull. (b) ROC curves for SMOTEC4.5, Under-C4.5, and Naive Bayes. (c) ROC convex hulls with and without
SMOTE.

354

100

SMOTE

References
Blake, C., & Merz, C. (1998).
UCI Repository of Machine Learning Databases
http://www.ics.uci.edu/∼mlearn/∼MLRepository.html. Department of Information
and Computer Sciences, University of California, Irvine.
Bradley, A. P. (1997). The Use of the Area Under the ROC Curve in the Evaluation of
Machine Learning Algorithms. Pattern Recognition, 30(6), 1145–1159.
Chawla, N., Bowyer, K., Hall, L., & Kegelmeyer, P. (2000). SMOTE: Synthetic Minority
Over-sampling TEchnique. In International Conference of Knowledge Based Computer Systems, pp. 46–57. National Center for Software Technology, Mumbai, India,
Allied Press.
Chawla, N., & Hall, L. (1999). Modifying MUSTAFA to capture salient data. Tech. rep.
ISL-99-01, University of South Florida, Computer Science and Eng. Dept.
Cohen, W. (1995a). Learning to Classify English Text with ILP Methods. In Proceedings of the 5th International Workshop on Inductive Logic Programming, pp. 3–24.
Department of Computer Science, Katholieke Universiteit Leuven.
Cohen, W. W. (1995b). Fast Eﬀective Rule Induction. In Proc. 12th International Conference on Machine Learning, pp. 115–123 Lake Tahoe, CA. Morgan Kaufmann.
Cohen, W. W., & Singer, Y. (1996). Context-sensitive Learning Methods for Text Categorization. In Frei, H.-P., Harman, D., Schäuble, P., & Wilkinson, R. (Eds.), Proceedings
of SIGIR-96, 19th ACM International Conference on Research and Development in
Information Retrieval, pp. 307–315 Zürich, CH. ACM Press, New York, US.
Cost, S., & Salzberg, S. (1993). A Weighted Nearest Neighbor Algorithm for Learning with
Symbolic Features. Machine Learning, 10 (1), 57–78.
DeRouin, E., Brown, J., Fausett, L., & Schneider, M. (1991). Neural Network Training on
Unequally Represented Classes. In Intellligent Engineering Systems Through Artificial
Neural Networks, pp. 135–141 New York. ASME Press.
Domingos, P. (1999). Metacost: A General Method for Making Classiﬁers Cost-sensitive.
In Proceedings of the Fifth ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining, pp. 155–164 San Diego, CA. ACM Press.
Drummond, C., & Holte, R. (2000). Explicitly Representing Expected Cost: An Alternative
to ROC Representation. In Proceedings of the Sixth ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining, pp. 198–207 Boston. ACM.
Duda, R., Hart, P., & Stork, D. (2001). Pattern Classification. Wiley-Interscience.
Dumais, S., Platt, J., Heckerman, D., & Sahami, M. (1998). Inductive Learning Algorithms and Representations for Text Categorization. In Proceedings of the Seventh
International Conference on Information and Knowledge Management., pp. 148–155.
355

Chawla, Bowyer, Hall & Kegelmeyer

Ezawa, K., J., Singh, M., & Norton, S., W. (1996). Learning Goal Oriented Bayesian
Networks for Telecommunications Risk Management. In Proceedings of the International Conference on Machine Learning, ICML-96, pp. 139–147 Bari, Italy. Morgan
Kauﬀman.
Fawcett, T., & Provost, F. (1996). Combining Data Mining and Machine Learning for Effective User Proﬁle. In Proceedings of the 2nd International Conference on Knowledge
Discovery and Data Mining, pp. 8–13 Portland, OR. AAAI.
Ha, T. M., & Bunke, H. (1997). Oﬀ-line, Handwritten Numeral Recognition by Perturbation
Method. Pattern Analysis and Machine Intelligence, 19/5, 535–539.
Hall, L., Mohney, B., & Kier, L. (1991). The Electrotopological State: Structure Information
at the Atomic Level for Molecular Graphs. Journal of Chemical Information and
Computer Science, 31 (76).
Japkowicz, N. (2000). The Class Imbalance Problem: Signiﬁcance and Strategies. In Proceedings of the 2000 International Conference on Artificial Intelligence (IC-AI’2000):
Special Track on Inductive Learning Las Vegas, Nevada.
Kubat, M., Holte, R., & Matwin, S. (1998). Machine Learning for the Detection of Oil
Spills in Satellite Radar Images. Machine Learning, 30, 195–215.
Kubat, M., & Matwin, S. (1997). Addressing the Curse of Imbalanced Training Sets: One
Sided Selection. In Proceedings of the Fourteenth International Conference on Machine
Learning, pp. 179–186 Nashville, Tennesse. Morgan Kaufmann.
Lee, S. (2000). Noisy Replication in Skewed Binary Classiﬁcation. Computational Statistics
and Data Analysis, 34.
Lewis, D., & Catlett, J. (1994). Heterogeneous Uncertainity Sampling for Supervised Learning. In Proceedings of the Eleventh International Conference of Machine Learning, pp.
148–156 San Francisco, CA. Morgan Kaufmann.
Lewis, D., & Ringuette, M. (1994). A Comparison of Two Learning Algorithms for Text
Categorization. In Proceedings of SDAIR-94, 3rd Annual Symposium on Document
Analysis and Information Retrieval, pp. 81–93.
Ling, C., & Li, C. (1998). Data Mining for Direct Marketing Problems and Solutions. In
Proceedings of the Fourth International Conference on Knowledge Discovery and Data
Mining (KDD-98) New York, NY. AAAI Press.
Mladenić, D., & Grobelnik, M. (1999). Feature Selection for Unbalanced Class Distribution
and Naive Bayes. In Proceedings of the 16th International Conference on Machine
Learning., pp. 258–267. Morgan Kaufmann.
O’Rourke, J. (1998). Computational Geometry in C. Cambridge University Press, UK.
Pazzani, M., Merz, C., Murphy, P., Ali, K., Hume, T., & Brunk, C. (1994). Reducing
Misclassiﬁcation Costs. In Proceedings of the Eleventh International Conference on
Machine Learning San Francisco, CA. Morgan Kauﬀmann.
356

SMOTE

Provost, F., & Fawcett, T. (2001). Robust Classiﬁcation for Imprecise Environments. Machine Learning, 42/3, 203–231.
Provost, F., Fawcett, T., & Kohavi, R. (1998). The Case Against Accuracy Estimation
for Comparing Induction Algorithms. In Proceedings of the Fifteenth International
Conference on Machine Learning, pp. 445–453 Madison, WI. Morgan Kauﬀmann.
Quinlan, J. (1992). C4.5: Programs for Machine Learning. Morgan Kaufmann, San Mateo,
CA.
Solberg, A., & Solberg, R. (1996). A Large-Scale Evaluation of Features for Automatic
Detection of Oil Spills in ERS SAR Images. In International Geoscience and Remote
Sensing Symposium, pp. 1484–1486 Lincoln, NE.
Stanﬁll, C., & Waltz, D. (1986). Toward Memory-based Reasoning. Communications of
the ACM, 29 (12), 1213–1228.
Swets, J. (1988). Measuring the Accuracy of Diagnostic Systems. Science, 240, 1285–1293.
Tomek, I. (1976). Two Modiﬁcations of CNN. IEEE Transactions on Systems, Man and
Cybernetics, 6, 769–772.
Turney, P. (1996). Cost Sensitive Bibliography. http://ai.iit.nrc.ca/bibiliographies/costsensitive.html.
van Rijsbergen, C., Harper, D., & Porter, M. (1981). The Selection of Good Search Terms.
Information Processing and Management, 17, 77–91.
Woods, K., Doss, C., Bowyer, K., Solka, J., Priebe, C., & Kegelmeyer, P. (1993). Comparative Evaluation of Pattern Recognition Techniques for Detection of Microcalciﬁcations
in Mammography. International Journal of Pattern Recognition and Artificial Intelligence, 7(6), 1417–1436.

357

	
  	

 
  	 !#"$%%$&'%()**

+,-. /0$1%23,
  /.$1%$

46587:9;<9=.9>8?A@B9CEDFG?IH8JLKMCG>8CE?GJ ;<J >E7ONP97RQTSPJ#9>8UFEVRW.J ;<J >E7
XYJ#C V0>89>8?[Z]\_^85`J.VR9;<J >E7:aPNP97RQT7RQ8JcbcdIe[H[>gfGh8a7:J ;

i:j'klmRnRo'pqiRlm:rRs

tuv'wxu:yGz'{}| z'~'}~''u':~0| w

`R'
 ]  _}
Ylj:m:o_#lk}j:m

'#u':yGz'{}| '0| w

   ¡G0¢IR¡.'£}#¤¤I¥I¦§  
¨ ©ªG¢#«.ª¬£}­®
«.ª¬£}­®}«'¯6°±}²



³Pl´s:j'o'µ ¶YojpmR·
  ¡G0¢IR¡.'£} ¥8¹¢¡G[¤¤
¨ ©ªG¢#«.}ªº©
«R®ºº¥ ®:«'¯O}»
³6jp}lµ¼.m¾½Pjµ¿o'p

#¸wu''{yGz{}| 'w'0| w

À#u'¸w:yE'w{wu''zÁ0| u}'0| z'~'

¯EÂRÃGÂ`¦¬ª Ä0§.ª¤®
Å º®¡Æ«. EÇ

ÈÉ±

ÊË#ÌÍÎÏ:ÐÍ
Ñ#ÒÓÔºÕÖÔºÖÕØ×ÙÒ[ÚÔÛÜºÝÕÞÒIßÝÜºÔºàáYÝâEÛØÓßÝãÒÖÚÔÛÜºÝÕÞÒIÓá}Ó×Òä<ÔºÖ}åÝÜºåÒÓEä[ÛÖ}á`ÖÝÖ}×æÔºå}ÔÛÜ
àÙÝÔºàÒÓçRè.ÙÔºÓ0ßÛßÒæ#ßæÒÓÒÖ}×Ó ÛEæÒÔºÖ}âÝæàÒä8ÒÖ}×.ÜºÒÛæÖÔºÖÕIÛßßæÝ}ÛàÙIâÝæ#ÛÞ×Ýä[Û×ÔºàÛÜºÜºá Ýß×Ôºä8Ôºéê
ÔºÖÕØÛ8ÚÔÛÜºÝÕÞÒEßÝÜºÔºàá}ë'ì.ÙÔºàÙYÛÚÚæÒÓÓÒÓI×ÙÒI×ÒàÙÖÔºàÛÜRàÙÛÜºÜºÒÖÕÒÓEÔºÖYÛßßÜºá}ÔºÖÕ8æÒÔºÖ}âÝæàÒä8ÒÖ}×
ÜºÒÛæÖÔºÖÕ[×ÝØÛ8ì0Ýæã}ÔºÖÕ8ÚÔÛÜºÝÕÞÒEÓá}Ó×ÒäBì.Ôº×Ù`Ù}Þä[ÛÖ[ÞÓÒæÓç8íYÒEæÒßÝæ×GÝÖ`×ÙÒGÚÒÓÔºÕÖëàÝÖ}ê
Ó×æÞà×ÔºÝÖ[ÛÖÚIÒä8ßÔºæÔºàÛÜÒåÛÜºÞÛ×ÔºÝÖEÝâî#ï}ðÞÖë}ÛÖIÒñ}ßÒæÔºä8ÒÖ}×ÛÜÓßÝãÒÖ8ÚÔÛÜºÝÕÞÒ0Óá}Ó×ÒäO×ÙÛ×
ßæÝå}ÔºÚÒÓRÞÓÒæÓRì.Ôº×ÙIÛààÒÓÓ0×ÝEÔºÖ}âÝæä[Û×ÔºÝÖ ÛòÝÞ×âÞÖG×ÙÔºÖÕÓR×Ý ÚÝ ÔºÖGî#ÒìqïÒæÓÒá}ç0ó#ÞæRæÒÓÞÜº×Ó
ÓÙÝìq×ÙÛ×:ò}á Ýß×Ôºä8ÔºéÔºÖÕ0Ôº×Ó:ßÒæâÝæä[ÛÖàÒ0å}ÔÛ.æÒÔºÖ}âÝæàÒä8ÒÖ}×ÜºÒÛæÖÔºÖÕëî#ï}ðÞÖGä8ÒÛÓÞæÛòÜºá#ÔºäIê
ßæÝåÒÓ.Óá}Ó×ÒäPßÒæâÝæä[ÛÖàÒç

ôRõØö÷ ÍÎø.ù#ú#ÐÍûø ÷
üGýþýÿÿþý	
ÿ}ýÿÿý'ÿ'ýÿ
ÿý'ý

ºý '
 ý	ý	
ý

!ý""#$"ÿ!%
ºþ
ÿ&(' ý)ºý*#ý*
ý+ÿý,
ÿ%þ	%!ý"
-

ÿý} þ	
ÿ-[
 ÿ/. !""
 ý	-ýý#þ	ºý	ý0ý0ý0!ý1
'ý	
ÿý	2
&,'!º
 þ!34 ÿqý	5'
 ý'ý	

 ÿ,-

 ý-
 ÿ
 ý[
 ýÿº
 þ	!6!2
 ÿ73
 ÿ+
} ý0 ÿØ
! ÿ
 ÿ

/'
 ý	

 ÿ`þ	º
 þý	&8$
#$ýÿ
 `
9 þ" ý	ý"
 
: þ

 ÿ#7ý	 ý
þ	º
 þý	,'
 ýþ ý,ý"'
 ý;#$ ÿþý,#"

 ýº
 þ	!2'
 ý'
 ýÿ,
 ÿ*
 ÿ!*ý#;} þ	3
 þ	
 ý, ý 

 ÿ<3/ý,ÿý	#4ý,
ºþ0'
 ýýþ	2 ýþ	
 ÿ
= ý">@?
A üB	3
 ÿ*

 `
9 þ!C>$D*3<E<
 ÿ<3<FHG6} ý	34IJJKLM,
 ÿº
 ý	
FOG
N ý
 ÿ/34IJJPB	& ' 
,'
 ýº
 ý	
 ý	
 ÿ#$ þý[

 ýÿ*ºý ÿ
 ÿH> üE7BRQST$UV"QT$W@XQY@YZ)º ý ÿC'
 ý	

 ÿÆþ	º
 þý	2-
"
= ý+!ý
 ý;#$ ÿþý0#$8
'
 þ	 ýÿ*'
 ý;#$ ÿþý[
 ý ý->$:
E ý	
 ÿ<3/[4º
 ý} þþ	
 ÿ
$37F1.
\ þ	} ý3]^^^LG6} ý	3
_<[
 ý	3FH`0! ÿ ÿ<3/IJJKB	&
 $%%$R'b/	 R	/c
aI

	4d:	º-.	4e,
  ;f
 
} @g/f

Á'#u'Ewu''{
	Yu'¸w

A<I+G_ý	ºþ	[ý,-`_<'ÿ<& .(!*8ý	2!
,I 8  2
} ý,":
: ÿ) . 
 ÿý	
ÿ-
ÿ2E7"'ý
ºý"
ÿ*ý,"ÿ
ÿ/&
> 
 -Y"W !#,T$%
U $& US
T '4(W &#*)(W #,+(T -.#(W &2(T -.#0/7Q2
V 1#*)T 3W@Y@4Y #,(W &)(T -.#,V"U)5&/W(&.6.7 B
A
] +M
2!-!-!- ý
 ÿý ý	ý	2
 ÿ2E7"'
 ý
º ý*
0] %8.ý	&
A9+M
2!-!-!.  ÿ "
 ÿ*ý," ÿ
 ÿ.
 
%9%8.ý	&
A.:684#$'
 ÿ2". 
 ÿýq
! ÿý E7"'
 ý
º ý
0'
 ýÿ*
 ÿ*ý," ÿ
 ÿ/&
8$0
 ý"[#
 ü0º
 þ	

   GR
 ÿý!-
 ÿ)E7"'
 ý
º ý&
'  ÿ-!"#$ 
 ÿ-ý!ý*&
[4º ý ý,
 ý"[
 ý0# ýý	/} þ	-!*!
 ÿ<
 ; 

 
3 ;  =;
 3%
 ;

 &
:,N07&
A
P %N0/! ý, ÿ) ý,[
 ÿº
 þý"/
! >
_4
ýI4?Iÿ`ý	5ºý,
ý,. 
2`_<'ÿ<&

? ÿ
'ý ý}ýÿ*
ý"!ýcÿ[ý	)`_<'ÿ<3/.0
ºþ	2. 
ý 
ºý[ýÿý	)-
'ý

2`
 _<'ÿ

.Gÿ+
ÿ%_4
ý)I34. 
6!ý ýÿþý	"'ý	ºý	(A
A ÿCýýÿþý	"'ý	ºý	B%A &
8ÿ%

ý30!6
ÿ). 
%ý*'ýÿ= ýÿ'ý	Rýý	
ÿBC5 . !68"ý	%!,/
D 3ý
!ý1ºý	ý,S+,#*0
) }ý ý,W(/& W@T$W@QT$W(3*
# 
ÿ-

ÿ"
ÿ#$
ÿ-ý0}þ	

!ý	!ý

ÿýý	ý	+
ÿ<&< ý,ý	ÿý	"
ÿ+þ	þý	"!)'ý*ý	
ý	!6'ÿþ	ÿ
ÿý	7&*8ÿ_þ	ÿ3
ýE	+ Z*	+ T# V<þ	+}ý"ý"
ÿ


ý*!)!
ÿ*ý"ýý	
ºþ	
ý-ýFC [4ºýý"ý	[ý
ý0þ
ÿ!ý 
ÿýý	ý	-
ÿ./
D 3 þ	ÿ
ÿ
ÿ"ýý4"
'ý0
ÿ#$
ÿ-
ý	ºýÿý}þþý	0-"/ý#}þ	


ºý	
ÿ)`Eý	.@ýý	!&?1ºý,
ý".

ý þ
ÿ"#<ý }þ	

!&4G(
ºþ	"#<ý	ýEþ	ÿ
ÿGþ	
ºþý	#7ý!ý 
ÿ


ý0

'ý
0!-'ý'ýÿ+ÿ!-ÿ*ý,'ý
ºý	#4ý"'ÿ'ý!
ÿ2ÿ2
'ý;#ýþ	?Aü"3ý


 ÿ#< ý34. ý	/4ý

 ý 0#;	&4' 
.
 þ	º
 þý #<
 ÿ



 ý0
 þþ ý'
 ýý	!
0,

 ý3< ÿ2
00ÿýIý	5º ý,#[
 þ	 #4
 `
9 þ'ý	

 ÿ*'
 ýþ	


 ÿ&
8 ÿ"ý0
 ÿ<3 ý	
  ý	
 ý þ	ýý	"ý0'
 ýþ	
 
: þ

 ÿ-#<ý0

 ý
 ÿ
 ý[
 ýÿ
º
 þ	!)0 ÿ-
ý
 ý'
 ý	

 ÿ)º ý<
 4 ý	
 ý7
 ý

 ÿ #"!ýO ýGþ ýý	%>@.0
 ý ýIý} þ	
ý

 ÿ" ý	0
 ÿº ý 

 ý0º
 þ	!3
 ÿ


 ý	!"'
 ý	

 ÿý	*!,
 ÿ8ý	5'
 ýB	3

 ýEþ	0 ý
þ	º ýþ	ý	6. 
+
 ÿ) ý
 ÿý} þ	
ÿ2. 
)
 GRý ýÿý

 ÿ,#ý!ý*37Y
 ÿ"'
 ý0#
ý	

 ÿ-[
 ý	º
 þ	 ýEþ	º ýþ	ý	#$0
 ý} þ	"

 ý3
 ÿý 
 GRý ýÿý

 ÿ ý 

ºþ!
þ	
 ý	%>@M, ÿº
 ý	
4FHG
N ý
 ÿ/3IJJPLA
 ÿ'
 ý
 ÿ<3<A*3'
 ýÿIH0
3 J
 ý	3/F ?  ý[
 ý3<IJJKL
D*34IJJPL<G6} ý	37E<
 ÿ<3D*37FH?'
 ý	3IJJKB	&M,
 ý"*ý[þ	0# ý	5'
 ý
[
 ýÿ=


 ÿ<37
 ÿ!+2 ÿ#;# º
 þ	º
 ý	- ý-_
! ý	5 ý	6
 ÿ+
 ÿ!)
 ÿýØý	5'
 ý
[
 ýÿ&28.ý	3
 ÿ!
 ÿ"#, ý
 ÿº ý-

 ý)º
 þ	º
 ý	2 ý-!º
 þ!C
º ý&C8 ÿ%
` _<'
 ÿ<34#$I
 ý	5º ý3
ý ý
" ý þ	-} þý#] K $ ýÿ
7

 ýº
 þý	3< . 
4'
 ý,'
 ý	
º ý	)'
 ý	.,&
üGýþýÿ." 
 ý	ý	- ,

 ý,º
 þ	q
! þ
 ÿ-'
 ý'
 ý	

 ÿý	)
 ÿý0#$
"

# L+,'
 ýþ	


 ÿ2
 þý	 ý	"(> L)M,[4B4
 ÿ2 ý	
 ÿ#$ þý[
 ýÿºý ÿ
 ÿ+> üE7B0> Jº
 ý
 ÿ'ÿ*F E<
 ÿ/3
IJJ ML:
E ý	
 ÿ]ý	-$&3]^^^LG6} ý[
 ý	-$&30IJJKLA
 ÿ<3 G
D ý ÿ3E<

 ÿ<3 F G6} ý	30IJJJL
G6} ý	3/]^^^B	3.0º
 þ	2 ý,'
 ýþ	[
 ý""ÿ/*} þ	--
 ÿ!?8º ý"0
ÿ
 ý
 ÿ+ ýÿ0ºý ÿ
 ÿ)*
 ý-'

 ý;#$
 ÿþý!)
 ÿý} þ	

 ÿ). 
)
8ýÿ

 ÿ[
 ýÿ*>$Aÿ)F

N5O*P

'# u'}~'w`u''uw#w'

J/3 IJJKL D} ý	
 ÿ/30E<
 ÿ<3F L) ý3 IJJ MB	& L) ý*' ýþ	
 : þ!30ý<L)M,[Hÿ¾üE
#$
",ý	"2[ý	)#$
"
=	
ÿ+
ý*
ºþ	
ºý	#; ºý-
ý-/3
 ÿ 

 ý) ÿ!%# ý ý	*. ý	 =;
ý	16ý6º ý #"

 ý+'ý	
ÿ<& ' ý	ý2#ýý	

 ÿþ	'
 ý+ý*#;} þ	-ØüE(
-'
 ý	

 ÿý	(_þ	'
 ý)} þý#;!C. 
]ÿ
!C ýÿ)>@
 þ	C-ý
?
A üB	3/þ	
ºþ'
 ý

 ÿ2ý[ýÿ

 ÿ[
 ýÿ*>@.0º
 þ	2
 ÿ)
8
 þ ý"
ý ý

 ÿB	3

 ÿ*'

 ý	! ý	2 ý	. ,>@.0º
 þ	2 ý0!º
 þ<
 ÿ*} ýÿ-

 ý,!ý"B	& ' 
 ý,
 ÿ2
 ÿ
 ý
#
,} þ	2
ýýÿ
#$E
 þ	
ÿ)
 ÿ2


 ý-º
 þ	!+. 

 ÿ+*"
 þ	
 ý4 ý þ	,} þý3
 ÿ ý	
 ý	!
 ÿ"'
 ý4#<
 ÿ
 ÿ"

 ý	&' 
 ýEüE*} þ	

" ý/*=ý`
9 þ	º
 ýÿ'ýþ ý 
.ý	ý	} þ	

 ÿ4 #;'
 ÿþ	

 ÿ,#/ý3.0
º ý0ý


 ÿ

ý
 ý,[
 ý	q
 ý	ý	G
 ýÿ
 ý,º
 þ	º
 ý	&
Gÿ#$'ÿý	!3/ý} þ	
ºþ4
ºþ
ÿ+##üE+-ýý#}ýÿ2
ýÿý5=
[ýÿ"ý	ýÿ"ÿ!)ýþ	'ÿ
ºþ þ	ºýÿý	&*G(
ºý*ýý	!)#EüE%

ý*ÿþý	73=
º
 þ

 ÿ ý'
 ýýÿ-
"
ý	+" ý	5þ	
ý	!*ºý" 
ÿ`þ	ÿ$3'ý
ÿ0ý	ýþ	<3
 [
 ý5=!
 ÿ6> ý& /&37> ? 
ý	F J/37IJ
J ML/R
' ý	/3IJJPBB	&M

 ý
 ÿ
 ý[
 ýÿý
 =
 ý	 ýÿ"*ý
 GRý ýÿ,!'

 ý# º ý*3
 ÿ+.0º
 þ	+ý2L)M,[("'
 ý	-.
 ÿ2!ý<
 

ÿý} þ	

 ÿ%. 
%+

 ÿC#,
 ÿ% ý3 
 ÿ¾
 üER
* ý	C+
"
= ý2ý2!ý<
 
 ý;#$ ÿþý&_/ 
!'
'
 ý"#º
 þ

 ÿ<3ý"'
 ÿ0#
 ÿ
 ÿ*/
, ý	
 ý ý	!2
"
ý	
!%ý) ý
 ý[
 ýÿ--6 ÿ%
 ÿý} þ	. 
%ý2!ý*&R_<ý" ý3ýÿýý	C#$
ý	5!/"" '
 ý, ÿþý	2. 
-ý8ÿýý	-#$#;'
 ÿþ	

 ÿ
 ÿ-!ý*3
$& ý.
& ý} þ	`
 þ	º
 þý
ý0!ý 0
º ý,
 ÿ*"
ºþ þ	
 ÿý	5 " } ý0 ýÿ ý
 ÿ- þ	
 ÿý	5#;
ý, ý,  0'
 ý'
 ýþ	
 ý&
' 
'
 ý, ý	 ýÿ*'
 ý	
º ý	C[
 ý	!2#$,
 ÿ
 üE%2
"
=ý-ý-'ý	
ÿ+#0

ý-ÿý[ýÿ,
ºþ	!6ý	+ÿ2
"
ý	6
ÿý}þ	
ÿ,. 
+ÿ)ý3ÿ_ý	5'ý
 =
 ýÿ!*'
[
 ý"
 ÿý	 ý,

!2#4ý,} þ	-
 ÿ*ý8þ	
 ÿý	5 #4ý,`_<'ÿ*!ý*&4?
2
)º ý	 ý	$34I
 üE%[
 ý	!)
 ÿ
 ý	"ýØþ	º
 þý-# 
ý-'
 ý;#$
 ÿþýØþ
ý

>@
$& ý&3 ý	. ,[
 ý ý	B ÿ8
 ý	
ý	7#$<

 ýý3ý'
 ý![
 ýÿ4#/
 ÿ
 ÿ


 ÿ
 ÿ
!ý   ýÿýý	 '
 ý	
'
 ýý	
! ý	5!-

 ý"/3ýIþ	
 ÿ
 þ	

 ÿ*#
 ÿ<L)M,[
"'
 ý	7#4 ý 

 ÿ2 ý} þ	

 ÿ 
 GRý ýÿ0}þ	

 ÿ`þ	º
 þý	3/
 ÿ*ý, ý	'
 ý![
 ýÿ #4ý
!ýO
 ÿ-ý
7

 ý"º
 þ	!)} þþ	
 ÿ
0º ý ÿý	2 ý	
ý	2"'
 ý	$&
A ýþ	


 ÿ+]-'
 ý	 þ
'
 ý	"[
 ý#ý
ý-
ºþ	!_þ	
ºþý	",-
ý*ÿý"
}ý&Aýþ	
ÿI9Øý	5
ÿ,. ý	
ÿ#$þý[ýÿ0ºýÿ
ÿYþÿ2'ý"ý	2
"
=ý"þ	Yþ	
ºþý	

ÿR)
: ý	'
 ý	(

 ý+!ý . 
CÿRý& Aýþ	
ÿ :6'ý	þ
'ý	2ý+þ	
ýþ	ý2#
ý6
` _<'
 ÿR!ý*30.0
º ý%
A ýþ	

 ÿ P%'
 ý	 þ
'
 ý	+. 
` _<'
 ÿ(
"
= ý	)
*

 ý%º
 þ	!
#; ý	5'
 ý
[
 ýÿ!2
 ÿý	2

 ý,/&
A ýþ	

 ÿIM" ýEý
º
 þ4 ý	Gý	
ÿ
ý'
 ý;#$ ÿþý#
` _<'
 ÿ ,º ý ÿý	+

 ý-º
 þ	!34
 ÿ+'
 ý"
 ÿý	00} þ	

 ý	
` _<'
 ÿ G
 þ	º ý	

 ÿ-ý,>@0
 þ	 ýÿ[
 ý ý#$4'
 ý;#$
 ÿþý 
"
=

 ÿB	&
A ýþ	


 ÿIM- ý	 ýÿ0 ý	Gý	

 ÿ*ý
 ý} þ	
!-#ý,º ý ÿý	I
 L)M,[3
 ÿY
 þ	 ý	
ý '
 ý;#$ ÿþý#/ýº ý ÿý	-º
 þ	!"0ý '
 ý;#$
 ÿþý#/ÿ/
 ÿ.
 =;'
 ý	

 ÿý	*º
 þ	º
 ý	

 ÿ)ý"
ý ý0
& H ý	,
'
 ýØý
º
 þ#
 ý	
'
 ýÿþý-3/.0
 ýÿ)'
 ý!+º
 ý	70
3 üE
þ
 ÿ	 ÿ

 ý	!* ÿ-ÿ
!*

 ý0ý'
 ý;#$
 ÿþý0#4,} ýÿ

 ý,!ý*&


 !#"  $%&	')((#*+-,."  (#/ (01) $#&/ (01)/ 1)1) $/ 	/ ($#	')*
$#3245&#*4" "675(989
 ::;<>=" 8+-13?>3896+-0/@89ABB#
C

N5O#D

Á'#u'Ewu''{
	Yu'¸w

ASR
User

Dialogue
Policy

TTS
_4
ý,] ?

Database

þ	6
 ýý	ýÿ
ÿ%#"+}ýÿ%
ý)!ý*&(' ý+ý
ÿ
}þþý	0-/ý,!*'ý
ÿ*ý,!ý 
ÿÿ7ÿý,*ý

ºþ,'
 ýýþ	+ ýþ	
 ÿ


 ÿ)!ý >@?
A üB	&<' ý!ý ,}þ	*-ý-ý
-"ý	5 "'
 ýýþ	%>$' ' AB!ý*&

 ûÏø0ú	cÏ ÷ Ï



0õ

 ø  
÷  ûÏø0ú  ÌÍ
OÌ

÷ ÍYû ÷

8 ÿ6-!
ºþ}ýÿ)
ý-!ý
>@.Gÿ2
ÿ6þ	=;
 #$ 
ÿ+_4
ý-]B	37ý-ý
'ý ý!ý(
ÿ"ý
[ý ý	ºýÿý"
ºþÿý3
ÿ0#;ýý5=$#$Oÿ
 ÿ ý3
ÿ-'ýý	
ºý	ý0'ý	
ý	*
ÿ#$
ÿ#;H"}þ	=ýÿ*þ	- ,/ý&4' ý
 ý,  '
 ýýþ	,
4
 ÿý ý	ý	"
 ÿ"
ºþ4'
 ýýþ	" ýþ	
 ÿ
= ý >@?
A üB	3ÿ"ý!ý< 
ÿ
 ÿ ý0 ý	
 ÿ ý	 ýEþ	
 ÿ
 ý	
! ý	ý0 ý4
,ý	5 =;=;'
 ýýþ	2>$' ' A0
B þ	
 ÿýÿ&
' 
 ý

 ý ÿ ý7#<ý!ý1 ý	0
 W@QY5U 6.
S # UYW@XZ'
 ýþ	
'
 ý .04ý!ý 
!+>@
 ÿYüE)ý"
 ÿ!3.0º
 þ	+QXT$W@
U &)
 2} ýB  ý} þ	*
 ÿ0
ÿ*ý

 ý&
_/< ý	3 ÿ?
A ü¾þ ÿ"'
 ýº
 ý	. ý	
 ÿ,
'
 ý;# ýþ	3ÿ
!, ýÿ7. 
,
 ÿ, º ý
C[
 ý	ý D2>@ýYQ &.6S*Q 6#"V"*U #Y
 6)QV"V"
Q )B  þ
 ÿ2'
 ý,'ÿý	2"
 ÿ <
 ýÿþýý!'
 ý	 #
'
 ýýþ	) ýþ	
 ÿ


 ÿ)"
} ý	'
 ý& 8 ÿ)


 ÿ2-
 ÿ!2'
 ý þý	

 ý	6þ	
 ý	 
 ÿ2ý"ý
 ÿþý3
ý*?
A ü + ý	 ÿ-2 þ	 ý6>@!º
 þ!% ý	ý	%) =;
} ý	
 '
 ÿ'
 ý)
'
 ýÿ L+
"'
 ý	B*

 ÿR6 ýþ	
 ý_ý	
ý)[
# þ	
 ÿ:/'
 ýÿþý6
 ÿRý+þ	
 ý	-#$'
 ÿ7& ' 
2 þ	 ý)


ÿ 
 ÿ*
 ÿý ý	
ÿ-ý?
A ü1 ý	&
H.G
 þ	
 ÿþýÿý	
 ÿ"
ÿ0.0
ÿ!'
 ý	4#/'
 ýþ	


 ÿ#;} þý	"
 ÿ"

 ý
º
 þ	!6'
 ý	

 ÿ<3+# .0º
 þ	% ý-
 ý
! þ	 ý	%!+ý?
A ü #;} þ	"
 ý&2' 
 ý:<,!'
 ý
#4'
 ýþ	


 ÿ37#4.0º
 þ	*. ý" ý, ý!* ýýÿ)
 ÿ`ý	5º ý3<
. "
 þ	+(W &/W@T$W@QT$(W 3*#"ý!ý
2.(ý ý
ÿ[
 ý	!3.0
 ý	ýý0!ý  
 ÿ!

 ýÿ-
 ÿ 2ý
 ý 
 ÿ2- ý	
 ý	!2'
 ýÿ=ýÿ'
 ý	+ ÿ'ÿý">@#$ýÿ* ý# ý ý	2-,
S +,#*)"
 ÿ



 ýB0 - ý	

 ý	!
 ý	º
 þ	


 ý" ÿ'ÿý,> +	*Z +	T #V 
 ÿ



 ýB	&
' 
 ý ýþ	
 ÿ+!'
 ý# þ	º
 þý-. ý
 ÿ
 ý	
ý"
P
. þ	
 ÿ ý

 ýý!ý %'
 ý
 ÿ
XU &,$)V"(W &.6 
0'
 ÿ'
 ýÿ
 ÿ#ý, ý	&4? #$ý
 0º
 ý	2ý?
A ü(" ýý
 ÿþý3
 ÿ-
 ÿý	*

 ý0#$4[
 ý
ý #7
 ÿý ý	,>#$4
 ÿÿþý3G
. ÿ
E7"'
 ý
º ýB	3ý
!ý "'ýþ	
'
 ý*.0
 ý	ýqþ	
 ÿ:< ý-'
 ý þý	

 ý	Cý
 ÿþý. 
+ý- ý	&-? #$ýý
 ý,   ý	
 ÿ ý%,I 
 ÿ"_4
 ý,I3#$0
 ý	5º ý3
` _<'
 ÿ"4'ýþ	
'
 ý0.0
 ý	ý4
Ø
 ý	5º
 þ	
!
XU &,$)V(
'
 ÿ'
 ýÿ
 ÿ/3< 
 ÿ2ý
 ÿþý	0A]
 ÿ)
A 9&
` _<'
 ÿYþ
 ÿ*-
Y
! þ	
 ÿ
ÿ
 ý,
 ÿ
. 
)ý-

 ý34,.0
 ýÿ+
,
 ý	[
 ÿ8ý	5º
 þ	
¾
! þ	
 ÿ:< ,ý- ý. 
 ÿ*:
: ÿ+
4. 
 ÿýº
 ý	&4G(
º ý . ý"

40þ	
 ÿ:<

 ÿ,
'
 ÿ'ÿýþý	!#$
"
 ý	#/ý
?
A ü þ	
 ÿ:/'
 ýÿþý34 ÿ_
 ÿýþý	!2#$ .1
 ý	3ý'
 ý'
 ý:
: ÿ


 ÿ"0
# C
.
 D2
 ÿB
 C
. D
.+
'
 ý!6'
 ý-'
 ý	ý"
 ÿý	_
 ý
º
 þ!6#$ ýØþ ýÿý2>#$0
 ÿÿþý37'
 ý'
 ýÿ
 ÿ+
 ÿ
.0
 ý	ýý ý0'
 ýýÿ"
 `
9 þ!
 ÿ" ý	
#
 ý	
5 þ	
 ÿ
 ý	B	3
 ÿ-"
4'ý'
 ýÿ-
 ÿ,4[
 ý ý
#4!ý 
 þþý	&











N5O



'# u'}~'w`u''uw#w'

?0. 
'ý'ý	
ºý	%'ý	.,3<
ÿ)ý`_<'ÿ)!ý*3<. ý"
'ýÿ
 :ý	%ÿ!2
 GRýýÿ
ý
ý	#$ .0
ºþ	2. ý,. ÿý	22Y4#Q)5&).0ý	ý0}ý"ý  !ýO
ÿ


ý"#$ ý[ÿý	5
&1A
"
!3,. ý2
'ýÿ
 :ý	1ÿ!C
 GRýýÿ*
ý+ý	
ÿR.0
ºþ	R. ý2. ÿý	R
ºý ÿ).0
 ý	ýYþ	
 ÿ:< ý?
A ü='
 ý þý	

 ý	% ý,ý
 ÿþý37I
 ÿYþ	
 ÿ:<*& $ G_ýØÿý
ý ý
  ýÿ
 ÿý ÿ*

ý	2'
 ýý
 ý#
 þ	º
 þý	0#
 ÿ



 ý
 ÿY
 þ	
 ÿ:<

 ÿ*"
 ÿ


 ý!ýO'
 ý	

 ÿý->@G6} ýFHG(
} ý	3IJJ^L/M,
 ÿº
 ý	
FOG
N ý
 ÿ/34IJJP
L 0º ý,F
Lþü0!3IJJK3IJJJL<A"
<3IJJKL<G6} ýG
 ý	,$&34IJJKB	&0?0,-
º ý`ý	5º ý37[
 ý ý
ýÿ !6!ý""[þ	
 ÿ:< #; ý
 ýÿ!#
3 ý	
 ýÿ6
 #,'
 ÿ'ÿýþý	
!3 
 ÿþý2
-
'
 ý	Ø
 þ	
 ÿ:/'
 ýÿþý
ý!ý1
0'
 ÿ'
 ýÿ
 ÿý ý	&' 
 ý	 ý, ýGÿ. ý	 ='
 ÿ'
 ýq
 þ	º
 þý	 
 ÿ.0º
 þ	
ý ý0
0" ý	

 ÿ`
 þ	
 ÿ ýÿ3.0º
 þ	-
  ýþ	
 ý	!*.0!. ý0. 
-"ý3
 ÿ*"
 ÿþ	
º ý	
. !3ý,
 þý	0#
 ÿ
 þ	`
 þ	º
 þý	0
 ÿ*ý,
 .
# ý
º
 þ/&



 û ÷ øRÎÐ 
 ÷ Í Ï:Î

.õ

÷ û ÷

.øRÎ  ûÏø0ú
	8øûÐ  Ì}û 
÷

8 ÿR
*ýþ	
ÿ<30. ý)'ý	þ
'ý6ý+}þ	*[ý	!C. ý+ý)%!ÆüE 6
*=
ý"
ºþ	!)'ý	
ÿ<& 8ÿ2ý[ÿý	50ýþ	
ÿ<3/. ý. 
4'ý	þ
'ý"
ÿ2'ý	
ý,
ÿÿ

ÿ*#

 ý	!-
 ÿ*ý"
[
` _<'ÿ*!ý*&



8ÿ'ý<0!IüE" ý'ý	
ÿ#
ý 
ºþ	!3
7
.ÿýþý	! 'ý::ÿý+	T$QT# 1Q+,#5
ýý	 ýÿ

 ÿ*#$0

 ý	&EJ!2
,. ý"
!6[ýÿ2,4"0#ý
ÿ#$
ÿ
0ý,

 ý#;0
 ý	º ý	
 ÿ0#$ 'ýþ	

ÿ2.0}þ	
ÿ*ý"!ý +}ý
ÿý	5 
G
 þ	
 ÿ
 ÿý	2
 ÿ2,
 ÿº ý"
=	
 ÿ`
 ýÿ
!`þº ý	)ýý& HIÿý,
0 
} þ5=

ºþ0
 þ	º
 þý"#$ 
ý,
,- ÿ þ
0 !ýO*#ý[ýÿ
 ý"

 ý37.0º
 þ	).

ÿþ	'
 ý*ý-
)-#;	37ý-ý
 ÿþý	,þ	
 ý	6!)ý?
A ü"3<ý
 ÿ
 ý-"'
 ý	 ý	73
ýEþ	
 ÿ:/'
 ýÿþý0 þ	 ý	 ý	 ÿý	-!"ý?
A ü"3
 ÿ-'
 ý
 ÿ!"ý
 
 ÿ

ºý	&48 ÿ-} þ	
ºþý3
. ý[ÿýý	)Øþ	 ý	0
0ý,"
 þ	20
º ý
 ý ý	 ýÿ
ÿ-ý	0!*ý,

 ý	#
 ý	0#4# ý ý	
. 
0
 ÿ*
 ÿ#$

 ÿÿýþý	!-#$0
 ÿ-)'
 ýþ	


 ÿ&
G_ý,º
 ý	.1ý,'
 ý	

 ÿ2# ÿ2
ý,ý} þý,Q <YW@XQT$W@
U & # #*&#*&/T3<
 ÿ)#$
"
º ý	)!ý '
 ý	

 ÿý	&







 

N0
 ýÿØþ	º
 þý	#$ý0ý # ý ý	3ý0!ýH'
 ý	

 ÿý þ
 ÿ-
 ÿ
ÿ-ý"#7ýý
}þý3ÿ%
ý}þ	
ÿ,2}ý"
ÿ_ý}þ	2ý&G_ý'ý::ÿý* W@QYU56S.# UYW@XZ,)'ý-

 ÿ-#; ý, ý	0
# +	T$QT #,+"
 ÿ*ý,ý,} þý,- ý	0# QXT$W@
U &+&_/[ý,ý	3ý
'
 ý"} þ	

 ÿ62} ý-!6'
 ýYþ	º ý*>#$
 ÿÿþý3 ýý	
ÿ)ý* ý"
 ÿ6ý-,ý37

 ý!
 ÿ"ý0/ ý .0
 ýÿ-/
 ÿ#$

 ÿ<
ý	 ý 
 ÿÿ
ý	/B	&_/4ý4ý	3
þº ý	1,
X -UW@5X # +	T$QT #,+34ý ý2!6'
 ý)"
º ý+ ý
 ÿº ý2} þ	

 ÿ þ	º
 þý	+>@
 þ	%Ø
 þ	º
 þý	#

ÿ


 ý- ÿ
 þ	
 ÿ:<

 ÿB	&,\} þ	2
 ÿ*#;O
 þ	q
 þ	º
 þý5=;ý	*-
ºþ,} þ	

 ÿ

 

ÿþ	

 ý,º
 þ	!&'!º
 þ!-ý !ý1'
 ý	

 ÿý  ý	
 ÿ


 ÿ-8þ	 ý ý'
 ý	
 þ	

}
 ÿ"} ý
 ÿ[ý} þ	[
 þ	º
 þý5=;ý& H.
 ü
E = ý	-} þ	"

 ÿý-} ýý	 ýEþ	º
 þý	
!)4Y #Q )5&/(W &.6<&





8ÿ6
ºþ	34*
ý*!ý 8ý	5ý	}þ	
ÿþ	
ºþý	
ÿ6*!ý
ºþ. !þÿ
ºýÿ*"
"
= ý,
'
 ý
 !-
 ÿý}þ	
ÿ-. 
*ýý	ýÿ
ý,ÿ*ý&' ý!ý
þ	ÿ
 ý ý	. 
 ÿ ý,'
 ý;#$H0 ý	#7ýý	ýÿ
ý 4
ÿý 
ý0
ÿ<&



A -" &0



3  1

( "  ( $

/(



&#>8-? / &"

1)$#8 0# 8






1)(

!# (#- &#" ' $#?

N5O



- !> '>$/ " 0&3!>" /

&/  



2@,>/ 1)(98

 

$# / / (



(9896=" 8 
 :: C

Á'#u'Ewu''{
	Yu'¸w

_/0ý}þ	"
ý
ÿý}þ	
ÿ<3þ'ý;#$ÿþý0[ýý3þºý	20) #*'4Q) 3
#þºþý	7& *
' 
 ý, ý	
ÿ

 ýIþ	 
0 ý	-[þ	
 ÿ
 þ	  )Q)!
U 30#X"W +	W@
U & )UX5#,+5+0>(L)M,[B4.0
ºþ	
"'
 ý	 ý0 ý* 
 ÿý} þ	

 ÿ. 
ý0!ý*&GR

 } þ	<3ýº ýH#º ý ÿ
 ÿ


 ýº
 þ	!-
 ý	/
 þý	-8þ	
ÿ,ý0
/º
 þ	!#$0
 þ	
 ÿ} þ	

 ÿ

ÿ" ÿL)M,[
7
3ý!ý<
  7
4 } ý} þ	

 ÿ05
"
= ý ý	5'
 ýþ	ý	 ý	. 7&
' 
 ýEþ	

 ÿ"#<ý 
<º
 þ	E
! 6(W 3*#*&-ý º ý ÿý	E
 L)M,
[ þ
 ÿ'
 ý0
 ÿýEý`
9 þ	º
 ýÿ!-
 ÿ
ÿ/*'
! ÿ"º
 þ""
 ÿ
""> J#ýý0FH'


3IJ
J MLAÿ*
F J/3
IJJKB	&
A
 ÿþý2


 `
9 þ*+ ý	º
 þ	Yÿý	5-}þ	

 ÿ34ý	3
 ÿC ý	. "
 ÿC
 ÿþý3. ý2

ý2'
 ý	
 ý	 L)M,[ #; º ý)

 ý	&(_/. 
 ÿ%A
 ÿ]
 ý	*$&>IJJJB	34. ýqþ
 ÿ%º
 ý	. 


 ý2"* ýþ	!2
 ÿ+ý`þ	 ýÿ+ý} þý-'
 ý	ý"
 ÿý	C!)ý-!ý } þ	

 ÿ
 ÿ
 ý  ý	
 ÿ ý	* 









 
	   $	 
  *	 


 	  
 

Eýý



. 
ÿ*ý
3'ý	5ýþý	
 
 ÿº
 þý	00ý A$`ý	5þ	ÿý3ý!ý
}þ	
ÿ
3/ýþý	
ý	+ý	. 
3/ÿ2ýÿ*ý,ýGþ	ÿý	2
& 8ÿ*Eý	5'ý
[ýÿ0ÿ!
ý"
 ÿ7
ý"ý	 ý8ÿÿ=ý*ý	. &4M
ý,ýýÿþý	0
ÿý	2#;H
ÿ
ÿ
/Yþ ÿ%'
 ý2 ý	6ý

ºþ!¾ý	
ý-ý*ÿ

ÿ6


ºý	 >
B->@'ýÿ
ÿ
ý-

!6#0* ÿ


 ÿ)2ý
3

 ýÿ+ý-!ý . 
 ÿ+ý
 ÿ6

 þ	

}
 ÿ B	37 ÿ)ý ý	. *#;'
 ÿþ	

 ÿ > B">@'
 ýÿ
ÿ*ý[ý	5'
 ýþ	ý	6 ý	. )
 ÿý	73<

 ýÿ
*ý)!ý . *
 ÿRý
 ÿ(%} þ	


 ÿ B	&H_/`
 ý	5º ý3`
 ý	
ý)#"ý
 ÿ


 ÿ

!-

!ýGÿ"'
 ý#7
[
 ý	3
 ÿ-/#7ý 

 ý	34ý !ý
. ,
 ÿ 34 /34 ÿ6
 ý	6
 ÿ
3

'
 ý	C!+ýYÿ"'
 ý,# 
[
 ý	"ý!ý . ,
 ÿ
 ÿ6 %>$ ý	º ý	"G

# ÿý	5"ýB	&*' 
 ýØý	
ý	6
 ÿ


 ÿ6


ºý	*
 ÿ% ý	. 
#;'
 ÿþ	

 ÿ`þ	
 ÿ
ý, ÿ2L)M,[%"'
 ý	<#ý, ý

 ÿ 0
 ÿý} þ	

 ÿ. 
-ý!ý*&48$
>$'
 ý#;!E
B þ ý	ý0þ	
ºþ'
 ý
#ý ý.0
 ýÿ-
 ÿý} þ	
ÿ. 
ý!ý*&
` ý4
ÿ"'
 ý4, ý  ÿ8
! þ	
 ÿ:/'
 ýÿþý
 ÿ"
"'
 ý	$3
 ÿýº ý0

 ý	ý ! =
ýH"
 ý º
 ý	* ÿ!
º ý,} þ	

 ÿ#;H
 ÿ!
º ýý	3
 ÿ- ý# ý!-
 ÿ!

[
 ý	&28 ÿ+ý.37ý
 ÿ
 ÿ)/2""'ý # <Y
U )QT$
U )Z). 
6 ý	'
 ýþ	,2ý`þ	 ýÿ
ý	  ÿ2} þ	

 ÿ&8@#4. ý8ÿý	 ý!-
 ÿ*. ý	2} þ	

 ÿ#;H[
 ýý3. ýGþ
 ÿ'ÿEý	5'
 ýþ	0
 ÿ.%ý 

 ý0#7
 ÿ}þ	

 ÿ"
 ÿ4ý&0
[ ýý0"4
#$. ,. !#
ýÿ
 ÿ[
 ý	5!"
 ÿ
 ÿ/0
,} ý0} þ	

 ÿ 
 ÿ".
! K&G(
º ý

ý0} þ	
. ý. 
7} ý
 ÿ2
` _<'
 ÿ<3
0ý
 ý	0. ý,'
 ý8ý	
5 þý

 ÿq
! þ ý#;<
 ÿ*'
 ý	

 ÿ
 ÿ*ý,} þ	

 ÿ
. ý	68ý} þ	
 þ	º
 þý5=;ý3
 ÿ)'
 ý2
 ÿýý"ý-
 ÿ<
 þ	º
 þý	'
 ý-. !
 ý	 
 ÿ2"


 ý, ýÿ
º ý,-
 ÿ* ý& >$G
D ýý*
 ÿ2"
 ÿ* ý ý
G
 ÿØ
 ý	5

 ÿ-
 ÿ
ÿ
 ÿþ	º
 þý5=;ý	.0
 ý ýý-
ý} þ	

 ÿ)
" ý!+
 ÿG
. ÿ)
 ÿ):/
5 ý	6!)ý"!ý
 ý	

'
 ÿý	& E
B H0ý } þ	
 ý	 " ýÿý
ÿ`
 ý	5!/ ý,
º ý&
` ý	537
 ýÿ)
E
 L)M,[3<ý`ý	5'
 ýþ	ý	 þ"

 ý* ý	. C>@
3QY.S #B *> B # 
 ÿ
 þ	

}
 ÿ #;Hý
þ
 ÿ*'
 ý8þº þý	)
 ÿ*ý"#4ý =;
 ý	#4
 þþý	ý	
ý

 



"


$# ! 





"

"

 
 ! 



%





& 

-

+

  
 
. 

/












#5=3$/  &

/ &

&(#/ 

"

#-'

$/ 

&#8# (

/

/ 



/ (

'  &(# 89($
!#??#/ " / /  

 '@-#/ - $

?/ (?#" 

/ 

1)) 3/ " "
(

($#1% !#" / (98/ 5/ (5!>/ ?#" 3/ (

1)




 

2 


1) &#3" 8#?#&-/ (

' 1.3 !>/ 1)(#" *@&#!98& 

10

&#31))'@(( 

/  $

('

*,

'@(



(

!>(#/ " " / 1



' / (#'  &(#3*




3( 3 >

 ))

!>(# 8 *
/ (

!/  

N*N5O

&#

!#

*) ! 



&#3 !>/ 1)(# $

-&*/ '@
/

/ (



" 8-($	&



1)

&#

(/ / (






/ "  
1

33 !#" 3" "9  &" "

-/ 33 3

/ (!/ 3/ " "5?>





!#"  / (9



'@(9



'@(/ " "5 
!#??#/ " / /  

'@

&#)()(/ / (

'# u'}~'w`u''uw#w'

State

Users
Utterances
DB access

ASR/DB
Reward

User utterances
log-likelihood
semantic tags

Dialogue Estimated
Policy
State
_4
ý 9 ?

State
Estimator


ý2!ý 
ºý	. ý	R-ÿ L)M,[&4' ý2
ÿC#,ýØþ	ý	ÿC
ýGýÿ

 ÿ[
 ýÿ.0ý0ý 
0"ÿ,ý
ÿ 'ý::ÿý	2!ý0#ý

ºþ'
 ýýþ	 ýþ	
 ÿ


 ÿ*>@?AüB7!ý1ÿ"ý/ý>@M JB	&' ý
ý
º
 þ	!2'
 ý:
: ÿý	ý ýÿ3ý,ý5=ý	
'
 ý:
: ÿý	ý"
 ýÿ*  ýÿ3<ÿ2ý
/ ý,} þ	

 ÿ0 . ý	4 ý"
º ý" ý	0#' ' A*ý
 ÿþý	0'
 ý:
: ÿý,ý"
 ýÿ* 
 þ	

}
 ÿ- ý	&

#$. 
ÿ*ýþ
ý8ý
ÿ+>@G6
ÿ37IJKJLAÿ*FJ/3<IJJKB,

)*> ! B 

#> ! B  >    ! B/ 5 )*>     B	


 
 ! 

>IB

+# ! 

.0ýý >
B4
#ý	
ý	-ÿ

ÿ-"'ý	7ÿ > B4.ý	
ý	*ý	. -"'ý	$&
Eý ý2^
I-
-2
þ	'ÿ"#;}þ	,"
 #ý	"+2ý*ºý	-ÿ+ÿý*.6
þ	'ÿ
 ý	. 
ÿý	-ý4
ÿ-
[ý&G_ý #$'ÿ-4#$`_<'ÿý
ºþ	!-ºýÿý	-. 
ÿýÿ

ý

0 ý
 ÿº ý.þ	º
 þý	4#  ÿý ý#$ý4. ýý	[ÿ0
þ	'ÿ
ÿ/3 1I3	#$<ý.ý	5'ý
[ýÿ
 ýý	6

 ý ý&-' 
 ý =;
 ý	,'
 ý:
: ÿý	C!)3
\ 

 ÿ%[
I þ
 ÿ+'
 ý`ý	
ý	)*. 

 ÿ6*'
 ý	
 ý	
 ý	C
 ÿ+ý =;
 ý2 ý

 ÿ6# ý*ÿ/ 3QY.
S #2W@T #*)QT$W@
U &R
 > J#ýý
F '


3IJJ MB	3.0º
 þ	2
ý
 ý	!+/ý	0ý[ý	
ý,# *> B  ý	2
 ÿ2ý8þ ýÿ
=; ý	 R
# ÿý	

 ÿ"ý	 ÿ-4.0
 ýÿ"ý0/ý0!º
 ý	 
 GRý ýÿþý04
 '
 ý	.R
 ý	7& HIÿþý
 ý
ý

 ÿ-
 þ	º ý	ý	73ý0
<

 ý,º
 þ	!6>$} þþ	
 ÿ",
ý	
ý	6"'
 ý	B,
"
 ÿý	%!) ý	º ýþ	
ÿ+ý-} þ	

 ÿ+. 
+ý-5
" =;
 ý28ý} þ	


 ý*ý&2'7)ý`ý	5ýÿ",ý`ý	
ý	 L)M,[(
-
 ÿ6} þþý-"'
 ý	#0ý* ý


 ÿ<3/
0
"
= ý	)º
 þ	!2)5
"
= ý"ý, ý	. -
 ÿý	*#; 	ST$.
S ) # ý&
G(
º ý+
2} þ	%
2ý	 ý	
ºþ!('
 ý
 ÿ/30ýþ	*#,
 ÿ
 ÿCº ý+
 ÿ


 ý	-} ý	"
[þ
 þ	
 )
"
ý*
= ý*#0ý-ý} þý3)"
 ÿ
"
= ý)/*
!
º ý"3.0
º ý* ý	
 ÿ
 ÿq
 ýÿ+
 ÿ#$

 ÿ2
 ÿ+ýý"*º ý ÿ+
 ÿ+} þþý"'
 ý	$&*8@#
º ý-/*. ý ý-
 ÿ:
: ÿ
ý3ý
'
 ý
= ý	Rý"
"
ÿþ	'
 ýÿ,ÿ!+ý-

 ý**#;	3
*% ÿ!%'
 ý
 ý	C# ý ý	)> ý& /&R?
A ü  ý	3  =;
} ý	
  þ	 ý	* ý ý	 ýÿ
ÿ6?
A ü
þ	
 ÿ:/'
 ýÿþý3/ ý ÿ
ºþ, ÿ!
3/ý, ý	 #/ ý 
 ýº
 ý	'
3 ý	þ& B	& 8.ý	Eý	
 ýÿ*"ý ý	
ÿ*
 ÿ!)-.
 ÿ"'
 ý0#4# ý ý	G
 þ
 ÿ*!º
 ý	6
 ÿqýÿ"0ý,} þý&0G(
º ý"ý
 ý
 ý	@
 +	W@V"SYQT$(W &.62ý+ ý-
 ÿý} þ	

 ÿ26
 ÿ]ýÿC
 ÿ
 ÿC/R>$:
E ý	
 ÿÆý	*$&3
]^^^
L 84'
 ÿ/3 ]^^^B	3-} þ	6
*6.+
 ýþ	!C
 ÿR+`þ ý#;!R'
 ý	

 ÿý	
ý	
ý	2ý0}
 þý*>$A
 ÿY
 ý	0$&37IJJJB	3 G
. ÿ-
 ÿ*_4
 ý09& J!2
 ÿ*"
 ÿ
ý
 ý ý	 ýÿ


 ÿ%65
ý2ý2
 ý2ý3ý)"'
 ÿ#,/+ ý
 ý	R+º ý ÿCý

7

 ý"º
 þ	!*#$ý,º ý ÿý	I
 L)M,[%
 ÿ-
 ý"
ý

 ÿ`þ
 ÿ2'
 ý ý!* ý	/
 þý	7&


  


)
+,



 

1) ! 

,

,



N*N*N

Á'#u'Ewu''{
	Yu'¸w

' 
 ýIþ	
 ÿ


 ÿ2#4
0'ý 
0Øý

ºþ!)
/ý"
}þ	
ºþ[ý	!-#$

ÿ6ý	
ÿ#$þý[ýÿ"ºýÿ
ÿ+ 1	SW@Y4*2
ý*!ý "
"
=ý	
'ý
,#;
 ÿ=þ	ý
 ÿ
 ÿ-
ý"/&48ÿ2[ÿý	$3< ý	2}þ	-
*
I& ? ýÿ+
ýý	. +[ýý"#$0
ý	34ÿ)
ý-ýý	ýÿ
ÿ
#$"
ý)ý	3ÿ%'ý	
ÿR+
ý+
ºþ	!C-Øý}þ	%ý*6+ý	#
 ý

 ÿº ý,} þ	

 ÿ&8 ÿ2 ÿ!-ý	ý ý,!*'
 ý,
 ÿ!-
 ÿý" ý
 ÿº ý,} þ	

 ÿ<&
]&J
)ÿ
ÿ

ý5=ý	)T)QW(&/W(&.6"!ýH#þýý	 ÿ`ý	5!"/,ý	,>@ÿý
,º
 ý	34 ÿ!)
[
 ý	,#;<
 ý} þ	_
 þ	º
 þý5=;ý0
3 ý} þ	+# ý*}þ	
ÿ,. ý-.6
}ý*
þ	
 ý "
 ÿB	&7I
M ý	
ý0'
 ý	
 ÿ8
 ý	5!3
4!ý -
/
'ý ý 'ý	
ý	
º
 þ#;'
 ÿþ	

 ÿ
!&

9& ýý	ý
ÿ
ÿ,
ý	
-ÿ8ý

ºþL)M,[)"'ý	ÿ,ýý}þý&4' ý
ÿ

ÿ#
)
L M,[6. 
7'ý,"'ý	
ÿ-ýý
ÿ 0ý}þ	
ÿ ÿ2ý	. 
#$ý
0!ýO}þ	
ÿ&

:/& ? ýý
7
ý"
ºþ	!)}þþ	
ÿ
0ºýÿý	IL)M,[&
P&

üGý	
ºý[ýÿ0ý!ýO
ÿ-ýºýÿý	2
ý
ºþ	!&

' ý8ÿý	50ýþ	
ÿ-'ý	
ý,ý#4
[ý	!-'ý	
ÿ*ý,`_<'ÿ*!ý*&

  .ú 
÷
 ÌÍ


.õ

` _<'ÿ+
2ý =;
[ý-}ýÿ+
ý-!ý "
'ý	ý,. 
+
ÿ#$
ÿ+


ÿ"2)
ÿ6`Eý	. ýý	!&)`_<'ÿ+

-
ÿ6*ýÿýý*#$ #$}ýÿ

ý!ý">$E:ý	
ÿ<3[4
ºý}þþ	
ÿ
$34\.þ	}ý3/_<
=	
/3F `0!ÿÿ<37IJJJB	3/. 
2
#$"/º ý	#$
ºþ '
 ýýþ	* ýþ	
 ÿ


 ÿ)>@?
A üB	3} ýÿ
 ÿ
 ý'
 ÿ'
 ýÿ
ÿ/3ý	5 =
=;'
 ýýþ	H>$' ' AB	3/ ý)} þþý	3
 ÿR

 ý6
 ÿ
 ý[
 ýÿ&H
` _<'
 ÿ( ý	2ý)G6
 ÿ
'
 ýýþ	+ ýþ	
 ÿ
= ý0. 
2þ	
ºþ,
 ÿ
 ý
 ÿ+'
 ÿ'
 ýÿ
 ÿ)"'
 ý	
 ÿý	2#;c
 ý	5 =
º ý, ý ý ÿþý	,>$:
E ý	
 ÿYý	 $&3<IJJJL:
E ý	
 ÿ2F [4º
 ý} þþ	
 ÿ
$34IJJPB	3
 ÿ*"' ' A-!ý  ý	
 ÿYþ	

 ÿþýÿ
 ý"

 ÿý'
! ÿý	
->$A0F H0

 ý3IJJPB	
& H"

5 ý	.
 =;
 ÿ



 ý-

 ý
 ÿ ý". 
2
 ÿ6ý*
M L)M  þ

ÿ6
 ÿ
 ý%>$:
E ý	
 ÿ¾ý	-$&3IJJJB	&%' 
 ý2
` _<'
 ÿ
/ ý,
,ý	)#;Oý
". ý
 ý"`þ	
 ÿ
 ÿ2
 ÿ#$

 ÿ2ý,#$ =
. 
 ÿ} þ	

!"!'
 ý	* 4" ý[
 ýÿ3 
"
3 þ
 ý	3
º
 þ0
ý	3" ý"33
ýý3/. 
 ÿýº
 ý	3 ÿ2=	&
` _<'
 ÿ2
 ÿ'
 ý	
5 ý	,
/ ý"
 ÿ* ýý
ý	*  } þ	

!
!'
 ý3
 þ

 ÿ<3< ÿ*
[
 ý#4/!+>@.0º
 þ	Y
 þ
 ÿ*[
 ý
 ý	," ÿ
 ÿ/3/#$ý ÿ
 ÿ<3 ý	
 ýÿ
 ÿB	&
8 ÿ#$!30ý)
` _<'
 ÿR

 ý6
 ÿ
 ý" ý
 ýÿ
! 
 ýº
 ý	2ý) ý* ý	
 ÿ%ý
 þ	

!3
}
 þ

 ÿ- ÿ
[
 ý0
ý	3 ý	'
 ýþ	

 ý	!&
` _<'
 ÿ":<4ý0 ý#$ýEþ ýÿ

ý+>$ ÿ%
!6ý-ý"
ý	3'
 ý'
 ýÿ
 ÿ6
 ÿ+ý-
 ÿ



 ýB	&68@#0ý`þ ýÿ

ý *
 ý6

 ÿ*
 ÿý	73,
` _<'
 ÿ(-#$-ý+
ýR>$
 ÿ(
!(ý+ý

ý	B
 ÿ<&C8@#"
` _<'
 ÿ%
0
 ý	Y
 ÿ
 ÿ%)
 ý30
` _<'
 ÿC"
 ý	"
 ÿ%)ýÿý	5

ý>@B	&)G(
 ýÿý	 ý
` _<'
 ÿ6
 þþý	#;!%
 ÿ-2
 ý3
[þ
 ÿ þ	
 ÿ:< ý*
 ý3
" ý 
 ÿ"ýIÿý	5 
ý>@B	&G(
 ýÿ-
` _<'
 ÿ*:
: ÿ

 ý	)} þ

 ÿ-
ý	3
)
 ýº
 ý	
ý0/ ý">$
 ÿ-. 
'
 þ-#$#
 ý} þ	-'
 ÿ
 ÿý	2
ý 
 ýB	&_/
 ÿ!

 ýÿ-
 ÿ
 ÿ
#ý0 ýý,
ý	3ý ý!-'
 ý,"
º ý,/ ý0þ	
 ý	3.0º
 þ	-. 
'
 ý, ý	 ÿý	


			

N*N

'# u'}~'w`u''uw#w'

N

üGý	
ºþ	
ý

` ÿüGý	
ºþ	
ý

[ 
' !'ý
H'ýÿ
M
ýþ	
ý
Mý	ÿ 0}ý0ýÿ ý
A!ýO8ÿ


ý
 ý 8ÿ


ý
L)
5 ý	)8 ÿ


 ý

_4
ý:4MIý::ÿ

ÿ*#8ÿ


ý,#$A!ýO[&

ý,ý	&' ýºýÿ*#`_<'ÿ*
ý	,ÿý	#; I2I]ý ýÿþý	0'ý#$ý,ý
/ýý!&-?0)ý-`_<'ÿ+
ý	ý,#;
!+->@
ÿþý*`_<'ÿ+#$ÿ

ý". º
 þýB	3ý0
 ÿ#$

 ÿ-} þ



 ÿ2#7ý0

 ý,

"
"" ý
þ	º ý	5*
 þ	*  ý	< ÿ'ÿ
 ÿ6>@M,
 ÿº
 ý	
FHG
N ý
 ÿ/37IJJPLA
 ÿ'
 ý
 ÿ`ý	0$&3<IJJKB	& (
?0
 þ ý	C ý37[
 ý	!2#$,
 ÿ) ý	
 ÿ#$ þý[
 ýÿ"ºý ÿ
 ÿ)*
"
= ý-
 =

 ýº
 þ	!+ ý
 ý	,4ýÿ
} þ	

 ÿ0#$E
 ý} þ	*ý"'
 ý'
 ýþ	
 
: ý	78
& üGýþ4
[
 ý"ý	0
,
8
 ý!*#$* ÿ22} ý"ý[þ	 ýþ	,}þ	

 ÿþ	º
 þý)> ý& /&3/. ý"
 ÿ .  ÿ
ý"!ýO*'
 ýº ý-! C/
! ý,D-
 ÿ2ý"
 ÿ

4ý3<
 ÿ2ý"
"

 ÿ# :
E ý	
 ÿ
ý	 $&7>$]^^^BB	&7_
G ý'
 ý0
 

 ý,º
 þ	Y
! þ	º
 þý	 
 ÿ*
 ÿþý3/
 ÿ* ý	*º ý ÿ
 ÿ
 ÿ!

"
= ý"ý,
 `
9 þIþ	º
 þý	->@G6} ý ý	$&37IJJKB	&8 ÿ)
` _<'
 ÿ<3/. ý" ý	º
 þ	ý	2ý"} þ	

 ÿ
þ	º
 þý	-%IB,ý*!'
 ý-#
 ÿ


 ý2+ ý*.0
 ýÿC
 ÿ) ý
 ÿ)#$"
 ÿ6
ý3
 ÿ
]B,.0
 ý	ý"_þ	
 ÿ:<  ÿ6
ý*
 ý2
 ÿþý2
 ÿý	7&%' 
 ý*
0} þ	

 ÿ-!+!
. 
2

 ý"ý3< ÿ+ ý, ýþ	0*} þ	

 ý"'
 ýý"
 ÿ2ý,
ý ý&,' 
 ý"} þ	

 ÿqþ	º
 þý	

º ý"
` _<'
 ÿ2 ýG
. ÿ-
 ÿ*_4
 ý	P"
 ÿ M&
' 
 ý ýý!'
 ý	 #4
 ÿ


 ý" ý!ýO ý	0 ý'
 ý:
: ÿý	2
 ÿ*_4
 ý :/3 ý	2
 ÿ-ý
þ	"
 ÿ

 ÿ2#ý".
 ÿ*#ý"!ý >U #*&-
 ý0
 W() #XT$(W 3*#>$D*3IJJPBB ! 3
 ÿ2ý!'

 ý,#4
` _<'
 ÿ) ý	 /
 ÿ*?
A üO> ) #,+	T )W@XT$(W 3*# 
 ý &/
U & ) #,+	T )W@XT$(W 3*#B	&' 
 ý
ý	5º ý	-
 ÿ6_4
 ý2P).
`_<'
 ÿ¾þ
 ÿ%)ý2 ýý-:<".)
ý	

 ÿ2ý" ýý!'
 ý	#
 ÿ


 ý&-8@# 
` _<'
 ÿ+ ý	"
 ÿ2'
 ýÿ
 ý	

 ÿ). 
)Y
 ÿ
 ÿ= ý	º
 þ	
 ý
	3/

,
 ÿ6S +,#*)"(W &/W@T$W@QT$(W 3*#> ý& /&37N ýý	50B	&<' 
 ýØÿ
 ÿ= ý	º
 þ	

 ý
". !
 ý	R. 
R% ý
 ÿ


 ý%3 '
 ýþ ý+ýþ	º
 þý)#"ý) ý	º
 þ	

 ý)
 ý	
ÿ"}
 ý ýÿ ý-
 ÿ68þ ý&28@#
` _<'
 ÿ+
 ÿý% ý	*
 ýþ	

 ý2,. 
6) ý	º
 þ	ý	
	3ý !ý1

 ÿE
 +	*Z +	T #VH(W &/W@T$W@QT$(W 3*#0> ý& /&3N ýý	AB	
& Eý ý ý !ý6
 þ?
A üR
 ÿ
ý0 ýý ÿþý0
 ÿ0ýþ	
 ÿ
= ý	
 ÿ!ý0
ºþ
ý0[
 ýÿ

 ÿý	

ÿ6ý2&+8@#,
` _<'
 ÿ% ý	-2
 ýþ	

 ý
 ý	

 ÿ6. 
%
 ÿ
 ÿ= ý	º
 þ	

 ý*	3
"


 ÿ6V"W #52W(&/W@T$W@QT$(W 3*#37'
 ýþ ý
,. ý ý-} ý"ý"
 ÿ



 ý*!2!
 ÿ
 ý	5

ÿ#$

 ÿR> ý& /&R
3 üGý	?0/,I L+B	&7' 
 ýYÿ
 ÿ= ý	º
 þ	

 ý*0
"'
 ý	

 ÿý	%) ýþ	
 ÿ
= ý2
ý0
ýGý	5º
 þ	
!2[
 ýÿ

 ÿý	-
 ÿý 
 ýþ	

 ý,34. ý	7
 ÿ#$

 ÿ" GRý ý	
 ÿ
ý,ý 
ý	& ' 
 ý,0..  #4ý:/ ý,. 0`_<'
 ÿ2. !0 ý	0!ý

ÿ


 ý"#$ý"
)
ý3<'
 ýþ ý00
 ÿý" ýG
 þ
 ÿ*
 ÿ!)
'
 ý,ý"
[
 ý
#4/!&







&

 0



)&#!#!>



(#/ (&&&8

  
  1

' &#(

 

/ (" / 



&#" $



?>3 ($# $

/ (

 

(&13?>3'5 -& -

#5=	#/ "      '$##(#/ (0	/ (#/ / /  2@="  6 =	#/ 83
 ::B#<345&#*4" "36 75(98

 ::;C8#/ !>/ (" / / (/  1)1)(#"  !#!#" /  $/ ( !>($/ " 0&) 1) 2@,9/ ( "@ 89
 :::C
;
	   ) / -&#/ " (# )/ (0)'@#-/ ?#&
" 0" / )$#?

($

&#!#!>-'@'@" " &#!

& / (?

N*N

& 

Á'#u'Ewu''{
	Yu'¸w

?Gþ	
ÿ
N ýý	A

[
G_ý	º þ	[
 ý`_<'ÿ<&[4ºýý,!ÿ*}þ5=


!Øÿ[
 ý 42
! ; 
 } þ	


ºý	* #$4

0#} þ	


ºý	8
 ÿ.(&
G_ý	º þ	[
 ý2
` _<'
 ÿ<E
&  .H!)80
 ý	
!
 
8 
 ÿ.
 " ý[
 ýÿ 3
 
"

3 þ
 ý	3<
º
 þ"
ý	3<"
 =
ý"303 ýý3 . 
 ÿýº
 ý	+
 ÿ
=	& [4º ý ýR!H
 ÿH} þ	

!Bÿ[
 ý
#;H
0
&
[4º ý ýý	[
 ý"ý-} þ	

!2!'
 ý0
& 84
þ
 ÿ,ý	<[
 ýý 
 þ

 ÿ-
 ÿ
[
 ý&
[4º ý ý+!%ý ÿ[
 ý)#"ý)G
. ÿ%
þ	
!- !* ý
 ÿý
 ý	ý	*
 ÿ<&
[4º ý ý,
 ý,[
 ý," ý
 ÿ#$

 ÿ<&
[4º ý ý ý	/[
 ýýGÿ[
 ý#<ýG
. ÿ
þ	
!- !* ý
 ÿý
 ý	ý	*
 ÿ<&
[4º ý ý)ý	,[
 ý2ý)
 þ

 ÿC-!
 ý 
 ÿý ý	ý	-
 ÿ<& 84Ø
 þ
 ÿ"ý	7[
 ý
ý
[
 ý&
G( 
[
 ý,#4ý/!--!-. 
 ÿ
.
M!-.  ÿ "
 ÿ2ý"" ÿ
 ÿ/3
 ÿ
ý,#$ý ÿ
 ÿ<3
 ÿ*ýIý	
 ýÿ
 ÿ.
 

Nýý	5
üGý	?0/IA

üGý	?0/I,L

?0]A
?0]
üGý	?0]A
üGý	?0]L

?0.9A
üGý	?0.9A

[  '!'ý


ýþ	
ý

N
ý	º
 þ	

 ý

'ýÿ

ÿÿý	
ºþ	
ý


ýþ	
ý

ý	
ºþ	
ý


ýþ	
ý

ÿÿý	
ºþ	
ý


ýþ	
ý

ý	
ºþ	
ý

'ýÿ

 ýþ	
ý

ÿÿý	
ºþ	
ý


ýþ	
ý

ÿÿý	
ºþ	
ý


ýþ	
ý

ý	
ºþ	
ý


ýþ	
ý

ý	
ºþ	
ý

ý	
ºþ	
ý

_4
ý,P08ÿ


ýIþ	
ºþý	0
ºý`_<'ÿ<&' ý :< þ	Øÿ-'ýþ	
 :ý	 ýIÿ[ý	#ý
 þ	

}
 ÿI
 þ	 ý	
 ÿ
 ÿ)*ý-
ÿ+ý"ýþ	ÿ þ	Øÿ<&-' ý
_þ	Øÿ
'
 ýþ	
 
: ý	"ý-!'
 ý
 ÿ+ý"#$qþ	Ø
 ÿ+'ýþ	
 :ý	"ý!'ý"#
 ý	7&4G
? þ	

 ÿ0 þ ÿ*'
 ý,} ýÿ-
 ÿ*ý[
 ýý, ý'
 ý	*
 ý	ý	&

` _<'

 ÿ`þÿ*!-ý,}þ	
ÿ#$#þ	ÿ:<"
ÿØý}þ	*
ý3/.Gÿ-
ÿ-_4
ý M&8@#
`_<'ÿ2 ý,ý [ý	5
ºþ	
!)ý
 #$!2ÿ*
ý3
 

ÿ # <YW@XW@TXU&,$)V"QT$W@U&)>ý& /&3
\45 ? 
 ÿ#;]#$ýþ
ÿ<3Rý	5ý
 :ý	R!+A]-
ÿ+_4
ý2IB	&"?0#ý	5
ºþ	
Øþ	ÿ:<
ÿ"ý
!ý(
 ÿ


 ý340 ý	º
 þ	
 ý! ý	 ÿ0<
4 ý	73
 ÿ" ý
 ýÿýý	,#;Rýý	&
_/E
 ý	5º ý3<ý0`þ	
 ÿ:<Oý"
[
 ý
ý,
<
 CM
)!*!*!*. 
 ÿ --
 ÿ
ý
A
,D/37.0 ý ý
A

, ý} þý	6!2ý'
 ý þý	

 ý	+
 ý#ý"
[
 ý
ý
>$" ÿ
 ÿ/3/#$ý ÿ
 ÿ<3 ý	 ýÿ
 ÿB	&8@#
` _<'
 ÿ*
 ý	I
 ÿ 
 ýÿýý,
 ÿ`
! þ	
 ÿ:<

 ÿ*3



 ÿ &/U-XU &,$)V"QT$W@U &2>@ý,`  ? 
 ÿ#} þ	

 ÿB	&
Aº ý	!2#$0ý- ý	,# þ	
 ÿ
 ÿ)
'
 ý

 ÿC>$ ý	+*ý"º ý ÿ
 ÿ/3.0º
 þ	
. ý
 þ
 ÿ-"[
 ýÿB	3
` _<'
 ÿ
 ÿý ÿ!-
 ÿ
 ÿ ý ý	 ýÿ

 ÿ"#<ý 

 ý0ý3

 ÿ ÿ*U #*)QT$W@U &+%3*#XT$U )0#4,I :,
º ý	&]
º ý	 } þ	.0
 ý	ý4ý !ýH ýý	ý	

& 

 	

 	



N*N


'# u'}~'w`u''uw#w'

?Gþ	
ÿ
\45 ? ÿ#I

[  'Rýý

M
,!0!0!ý
ÿýý	ý	,
ÿ
ÿ

A.A  

[ 0'!'ý


ýþ	
ý

N
ý	º
 þ	

 ý

`  ? 
 ÿ#
\45 ? 
 ÿ#;]

M



ÿ


ýþ	
ý

ý	
ºþ	
ý

!R!R!(. ÿ*RC
ÿ(ý


ýþ	
ý

ý	
ºþ	
ý

    	 

=



!

`  ? 
 ÿ#
\45 ? 
 ÿ# 9

=

`  ? ÿ#

=

M


!O!

  A
	 B



ý1
ÿýý	ý	

  A 

_4
ý M ? ÿ:<
ÿqþ	
ºþý	
ºý*2`_<'ÿ<&*' ý:<Iþ	Øÿ+'ýþ	
 :ý	ý`ÿ[ý	
#0ý*}þ	
ÿØþ	ý	ÿ
ÿ6)ý*"
ÿ%ý-ýþ	ÿ]þ	Øÿ<&%' ý-

þ	Ø
 ÿ%'
 ýþ	
 
: ý	*ý)!'
 ý)
 ÿ%ý*#$ þ	Ø
 ÿC'
 ýþ	
 
: ý	*ý2!'ý*#
?
 ý	7&' 
 ý,#$ý"`  
 ÿ# > ÿ =þ	
 ÿ:<

 ÿB } þ	

 ÿ*
E
 ý!&

Roj'k
Rpo

8jµ:o'·

0µj:m:j'klRm

Nýý	">;NB
? 
ý->@?B
?  ÿ:/' ýÿþý ? ÿ:<[ý	
>? B

 ý*> B
'º
 ý	>$' B
N(> L+B

^3I
I3 ]3 93 :
^3I3 ]3 93 :

 
!+>0B

^3I

G(ý	ýý!ýO ýý	ý	*ý,ý
G(º
 þ	*
ý,
0'
 ý	
 ÿ*.}ý	-ÿ
^3I3 ]#$ .,3<[
 ý	
*3
 ÿ)
2?
A ü þ	
 ÿ:/'ýÿþý&93 :
#$#
 ý	5º
 þ	

! þ	
 ÿ:<[
 ý	73/
 ÿ2
 þ	
 ÿ:<[
 ý	
G(
 ý	ý
 ý0'
 ýýÿ
 ÿý	"#$R
 þ ýÿ
ý
 .( ÿ!-
[
 ý	E
 þ ýÿ0
ý,0'
 ýýÿ)} ý	
G(
 ý	ýq
 ÿ
 ÿ= ý	º
 þ	

 ý62 ý	º
 þ	

 ý6. 
 ý	
G(
 ý	ýý ý. º ý,
 ÿ*
 ÿ!* ý	

ý

^3I
^3I3 ]
^3I

_4
ý4Aý0#ýý	0ÿ*ý	&
ýý	3ÿ*.0
ºþ	*
ý ý!ý1
Eþýÿ!*ý
ÿ,"
ÿ<&4_/.ý}þ	#ý
9*
ý	3
:2
ºý	"}þ	*.0ý	ýý"!ý 
ÿý	6ý-
ý ý*ÿ
.00ý"
 ý
37ý"!ý<
 G
 þ	
 ÿ:/'
 ýÿþý
 ÿ)ý"ý)>@
 #
ÿý	/B	3<ýØÿ"'ý0#
[ý	
ý-!ý } ý	+ý2 ý""ý*
ý34
 ÿ%ý-!'
 ý-# ?
A üO,"
 ýþýÿ!2 ý	2"#$ý,
ý&

' 
 ý#$4ý} þýH
 ÿ
 ÿý	C!6
` _<'
 ÿ)#$,ý* ý	"#0º ý ÿ
 ÿ+
"
 þ	

º ý ÿ+ý*'
 ý

 ÿ" ýþ		34/
 ý*)ý-/2
!_þ	
 ÿþý ÿ- ý!6
 þ ý	7&
' 
 ý2

 ý)ý-} þýBþ	
 ÿ
 ÿ-
 ÿ
! )
º ý	30
= ý	R
 ÿ%_4
 ý
& H

þ	ý	,#;(ý'
 ý

 ÿ4 ýþ	
 ÿ,0
 ÿ.
 =;'
 ý	

 ÿý	*
*&4' 
 ý0C	N ýý	D# ý ý
} þ	.0
 ý	ýý !ý  ýý	ý	-ý ý4 ÿ>ÿ ^3
! ý	 "IB	%
& C? 
ý,D,'
 ýþ	
 
: ý	
.0º
 þ	*
ý,
` _<'
 ÿ-
E
 þ ýÿ!*ý
ÿ""
 ÿ-
 ý
 #$!)>$} þ	

! "I3
 þ

 ÿ ]3

[
 ý 93/
 ÿý,. 
)
ý	 %:B	& C ? 
 ÿ:/'
 ýÿþý ? 
 ÿ:<[
 ý	
 D* ý ý	 ýÿ0ý8þ	
 ÿ:/'
 ýÿþý
` _<'

 ÿ6,#$ý0
 ÿ
 ÿ+-
 ý#$
 ÿ+
ý&' 
 ý
 ý	^3I3
 ÿ6]* ý ý	 ýÿ,ý







N*N







Á'#u'Ewu''{
	Yu'¸w

. ý	30"
ºý%ÿ(
ý	2?Aü þ	ÿ:/'ýÿþý+ý	&
' ý)ý	F9%ÿ :Cý)ý	-.0ýÿ
? Aü ý C!ý	D)ICÿD6#$ý"qþ	ÿ:<
ÿ%ý	
ÿ<&@C ý,D+}þ	".0ý	ý`_<'ÿ

0
ÿý	6ý"#$ý
ý*>ÿ ^3<!ý	 "IB	&2C'
ºý	D*}þ	 ýØÿ"'ý0#
[ý	
,`_<'
 ÿ6,} ý	+ý- ý,,ý-
ý& C	N D-} þ	ý!'ý#?Aü
,>@ ÿ ý"'
 ý	B,"ýþýÿ!) ý	+-
 ÿ2ý
ý2>$^ Iÿ
 ÿ= ý	º
 þ	

 ý3
I  ý	º
 þ	
 ýB	&_4
 ÿ!3 C5 
.
! D ý ý	 ýÿ.0
 ý	ý
` _<'
 ÿº ý0'
 ÿ'
 ýÿ
 ÿ"ý
 ý0
 ÿ2ý8ýº
 ý,0#4ý[þ	
 ÿ
 ý

 ÿ6>$ ^3/ "IB	& _
G ý""
0ý,#;4'
 ý:
: ÿ


 ÿ<3
0
 ÿ`ý	5º ý3/.0
 ýÿ2
` _<'
 ÿ2
0.
 ÿ
 ÿ-ý, ýþ	
 ÿ)
ý->@
 þ

 ÿB	3ý"
!

º ý0
 ý	,^
 #
` _<'
 ÿ
 ý	E
 ÿ
 ý0
 ÿ} þ	

!3
 ÿ} þ	

! #
 ÿ8
 þ	
 ÿ:/'
 ýÿþý

ÿ*ý
 ý3/E
 ÿýý	'
 ý	).
 
 ýº
 ý	"
 ÿ*ý,} þ	

!&
G ýIÿý0
 ý0 ý ý	 ýÿ

_
 ÿ<3
 ÿ-ý
 ÿý ý	#} ýý
 ÿ-ý0ý } þý$3
'ý	
'
 ýý	!*

 ÿ ý	 ýÿ
!*
 ý	#;7
 ÿ#$

 ÿ-ý 

 ý,#;	&7_/.
 ý	5º ý3
ý ý
 ÿý# ý ý ý	5º
 þ	
!-} þ	
 ÿý 
 ý
 ý?
A üC þ	 ý
 ý4/ ý4ý
 ÿþý	4
#;	
3 ÿ4,. ý0} ýý
 ÿ#$

 ÿý.6# ý ý 
 ý	#$4 ý	
ý	& E . ý	
 ý	3
"[
 ýÿ

 ÿý	% ý3ý4
"2'
 ý	

 ÿ%*ý"} þý-"} ý	8
 ýÿ_
 þ

ºþ


ÿþ	

 ÿ0,ºý ÿ
 ÿ/&' 
 ý ý# C ý	/
 þý	 ýIÿ"'
 ý#7ý	"
 ÿE
! M]3
 ÿ
ý þ	
 ÿ
 þ	

 ÿ"# ÿ L)M,[+"'
 ý	/4
 ÿ4 ý. 
 ý	'
 ýþ	 0}3 ý	
 ýÿ
 ÿ

"
ý	-
 ÿ
 ÿ,/& % ' 
 ýý} þý . ý 

= ý,
 ý ý3""
 ÿ
$3/. 
} ý,
 ÿ


 ý'
 ýþ	


 ÿ" ý	)
 ÿ*ý,
 þþý	#
# ýº
 ýG
 ý	
5 þ	
 ÿ
 ý	37
 ÿq
 þ	
 ÿ:<

 ÿ2'
 ýþ	
 =


 ÿ0 ý	*
 ÿ-?
A üOþ	
 ÿ:/'
 ýÿþý, þ	 ý	 
 ÿ*3
 ý	ý	2Ø
! ýº
 ý .2>@M,
 ÿº
 ý	

F G
N ý
 ÿ/37IJJPLG6} ý ý	0$&3<IJJK<LE<

 ÿ<3/G6} ý	3/F1G
D ý ÿ37IJJJB	&
GR
-ý,ý} þý" ÿ)} þ	

 ÿ`þ	º
 þý	, ýþ	
 ý	!2'
 ý:
: ÿý	73<. ýIþ
 ÿqÿ.('
 ý	
ý UYW@XZ
XYQ +5+8ý	5 ý	)
 ÿ2E
 ý	5'
 ý
[
 ýÿ3<'
 ý:
: ÿý	)*'
 ý"ý, ý	0#'
 ý	ý"
 ÿ

ºþ-
 ÿ0#;
ý,ý	 
 ÿ2.0º
 þ	2ý,!ý 0Ø
 þ	º
 þý"--
ºþ	3/:/
5 ý	q
 þ	º
 þý&' 
 ý,ý } þ	

 ÿ

 ÿ% ý ý	 ýÿ
ÿ%
` _<'
 ÿ -

 ý)º
 þ	]
! þ	*\8 ? >$\45!)#$8 ÿ



 ý+
 ÿ
?  ÿ:<
 ÿB4
G
. ÿ"
 ÿ_4
 ýK&_/0
 ý} þ	Ø
 þ	º
 þý5=;ý3. ý 
ý0.I
 þ	º
 þý	#} þ	

 ÿ

º ý&*>$' 
 ý"} þ	

 ÿqþ	º
 þý	,
 ÿ)#;} þý- ý,ý"
 ÿý	G
 ý	
 ýÿ!)
'
 ýÿ
 
: ý	%0
4!
ý*º ý ÿ
 ÿ%
 þý	3 ÿC ý*
 þ ý	R
 ÿ6'
 ý	
 ý	& B A
 ÿþý)ý ý2 ýE:
] þ	º
 þý5=;ý	
. 
R]6} þ	

 ÿ¾þ	º
 þý	q
 ý} þ	<3ý)G
 ÿ"'
 ý#"'
 ÿ
 
 ý6º
 þ	º
 ý	)
 ÿC
Y
 þ	*
2] K $ & 8 ÿ
 ýý
 ÿ*. 
-ý8üE6[
}
 ý	!-'
 ý	 þ
'
 ý	6
 ý3 <
0Øþ	ý"
 ÿ2
º ý[
 ýÿ
 ÿ"5
ý	!,
/º
 þ	!
 ÿ"
4

 ý þ	
 ÿ,ý 
4:
# üE*º
 ý	-Gý	5!

 ÿ
 ÿ-

 ý	&
' 
 ýº
 þ	Y
! þ	
 ÿ-_4
 ý,K
 
 ÿý	2!-. 
 ÿ-8
 þ	º
 þý#!ý1 ý
 ÿ



 ý
.0
 ýÿý	 ý,ý*!ý ÿýý	)), ý2#$,
 ÿ6
ý3
 ÿ%!6. 
 ÿ6Y
 þ	º
 þý*#
þ	
 ÿ:<"
 ÿ
!"
 ÿ0
 ÿ,0ýEÿý	5
ý.0
 ýÿý	
 ýý!ý  
 ÿý	

 ý #$ ÿ
ý&_/.
 ý	5º ý3
 ÿý 
 ÿ

7ý.0
 ý ý0ý0 ý ÿ!ý	 ýý	ý	
ý ý5> C	N ýý	D,ý0
 ý,^B	3ý0!ýH8
 þ	º
 þý0#ý
 ÿ"ý0!ý1
 ÿ


 ý



















 

# 





  

&/


/



 

 
  


 

  
 
   

	
 0

&(

  
 
 


 


( $#(

' 1%

( $#(

8-







+



&!#&

/ ( " &$# 

7 $(	$#

" & / (#

(

)!#!#/ 1)"

!>" /




 B# A

/ ((

 8#

'@-)

3/ (#/ / "-$/ " 0&

 

/ " " ( 



B




(

B)B





0(#/

$

/ (0#8-?#&



B #



!/ / ( 

&  - 

&#/ ()$/ " 0&

N*N5P





 /  $

$# #( $	

1)!#!#/ (0



31)3/ (#'@1)/ (989& -
$#

 1





(-/ ( #&(



!#" 890   B

& 8>" "5 -?> 0/ (#(#/ (0/ B

&#

" 	(

$# " !1)(# 8

-'@ &#  

&" " 

B)B



!>!#&#"  $



 (#&"5$#?

( $

 -



 &" "

:# -$/  & $?> 8>3  1.& -/ -!>/ (
" & 3' !# / &3/ ?#& -'@

(#"

?/ ( $	$&#/ (0  1



/ (#"

2@ 0#



&"

' &&#3$/ " 0&

	B




3B

!>/ ?#" )/ (
B




B



B C

'# u'}~'w`u''uw#w'

B

4



 /
*

 

B

B

B

0




B

B







B




B







B




B













B













B







A




B







A




B












.


B

B

B



B

B


B


B



B

.
B

B

B
B

B

B

B
B

B
B




A



A

B

B




A

B

B




A

B

B




A

B




B

B




A

B




B

B




A

B




B




A

B




B




A







B

B




A







B

B




A







B




A







B




A

A




B

B




A

A




B

B




A

A




B




A




B




A



A



A

.
.











-

-



B





B





B

B

B



B




B

B
B
B




B







B




B

B

B




B




B

B








B







B

B







B

B







B




B





B








B



B

B

A




B

B

A




B




A




B




B

A










B




B
B

B















B




B




B




B

B







B

B




B







B

A




B

B



.

B

B
B

A

B

B

B

.




B







_4
ý"K4\8 ?

45/









B


B



/ (45/



 

-   / 8 	

58 +->

4(#'8 
4(#'8 
4(#'8 
4(#'8 
!" 8 5# !>4(#'

!" 8 5# !>4(#'

+->
 / 8 +->

5 8 +->

A / 8 $%

A / 8 $%

+-A / 8 $%&
+-A / 8 $%&
4(#'8 '$
4(#'8 '$
4(#'8 '$
4(#'8 5# !>4(#'A
4(#'8 '$
4(#'8 '$
!" 8 5# !>4(#'A
4(#'8 '$
!" 8 5# !>4(#'A
4(#'8 '$
!" 8 5# !>4(#'A
!" 8 5# !>4(#'A
$%5 8 +-A
+-A / 8 +-A
+-A / 8 $%&
+-A / 8 $%&
4(#'8 5# !>4(#'4(#'8 5# !>4(#'!" 8 5# !>4(#'4(#'8 '(
4(#'8 '(
4(#'8 5# !>4(#'!" 8 5# !>4(#'4(#'8 '(
4(#'8 '(
4(#'8 5# !>4(#'!" 8 5# !>4(#'4(#'8 '(

[
ºþ	! ? &4MIý::ÿ

ÿ0#$ý0#ýý	 ý
ýÿ*
ÿ*_4
ý&

IC[4ºýý-!+ÿ6}þ	

!_ÿ[ý-! ; 
}þ	


ºý	*#$,*
"#}þ	


ºý	8ÿ.
& D)ý, ý
 ÿ


 ý"2C5 .R!-8ý	*!,D+?00ÿý#ý	5ºý3'þ	
ºþý	

ÿþ	
 ÿ:<

 ÿ) ý
º ý-ý	 #$ .0º
 þ	)ý C 
 ý,D-# ý ý"
-I&8 ÿ)ý	 ý"ý	3
ý-!ý þ ÿ_ý	
ý[
 þ	
 ÿ:< ý*
ý-
 ý*
 ÿý	+#; ý-?
A ü"37"} þþý"ý
þ
 ýÿ0
 ÿ
 ÿ2 ÿ)" ý0
 ÿ-ý8ÿý	50
ý&

N*ND

Á'#u'Ewu''{
	Yu'¸w

'7I
 ý	5ýþý0
ºþ
ºþ	!
ÿý 
ºþ	!Øþ	\8 ? 3`_<'ÿ[þ	ý	)Q&UV"YZ"'ý	. ýýÿ
ý .}þ	
ÿ4#$.0ý	ý0þ	
ºþý5=;ý0


ÿ<35
"
=	
ÿ[ý	5
ÿ-ÿ-"
ÿ
"
=5=

ÿ/ ýÿý	.0ýÿ8þ	ÿþ	
ÿ
L)M,[)"'ý	$&4` ý/ý0ý ÿ"
=
ÿ
 ý	#$}þ	
ÿØþ	
ºþý3ý
ÿ-_4
ý	 P,ÿ<M"ý 'ý	
ÿý	28ýÿý0ýGþ	ýýÿþý
#
º ý} þ	

 ÿ- ý
 ýÿþý	&
A ý

[
 þ,-0O
^-I,^^^^^
I"I,]*I,^^^
I]]*I,^^*I
I 9]*I,^^*I

I :-^^^^^
%

?Gþ	
ÿ

'ÿ

üGý	.

Nýý	5
`  ? 
 ÿ#
\45 ? 
 ÿ#;]
\45 ? 
 ÿ# 9
'Rý	

A<I

^

A]

^

=



^

A9
^

A.:

I

_4
ý"JNGýÿý
ÿý,
ý,
ÿ*_4
ýI&
_4
 ý"J
ý	,. ý"

 ýº
 þ	
! þ	
 ÿ2_4
 ý"K
 ýÿýý	0ý"

 ý"
 ÿ
_4
ý-I&\}þ	2.R
ÿ
ºþý	ý,ý0`_<'ÿ2
0
ÿ<3/ý"}þ	
ÿYý	5ýþý	2
ÿ2
0ý3
ýØþ	 ý	
 ÿ
 ÿ2 ÿ)
 ÿ)_4
 ý2I3
 ÿ+ý ý	. + ýþý	

 ý	7&*' 
 ý"
 ÿ

ý ý ý	 ýÿ
-`_<'
 ÿ%. 
 :<-ý"+
 ÿ%
ý+I&C
` _<'
 ÿ¾ý	
5 ýþý	2N ýý	5 >$
G
. ÿ)
 ÿ+_4
 ý-K3N ýý	A)
")
º ýB	34
 ýÿý
ÿ2ý":<,ý
 ÿþý
 ÿ+_4
 ý2I&
? #$ý0ý- ý,  , ý	
 ÿ ý37ýØÿý	5,ý" ý ý	 ýÿ,`_<'
 ÿ68
 ÿ.1 ýý	ý	)ý- ý
 ÿ2
 ÿý	)ý} þ	

!*

 ý. 
)
q
 þ	
 ÿ:/'
 ýÿþý37!)
 ÿ2`
 ÿ
 ÿ= ý	º
 þ	

 ý"	&
` _<'

 ÿ%ýÿ¾þ	 ý	-ý2`  ? 
 ÿ#,} þ	

 ÿ<3+

 ý	Y
 ÿ-ý_þ	
 ÿ:< ý)} þ	

!3
.0º
 þ	Ø
 þ ý	ý ýIþ	 ÿ ý0 ÿ"4"'
 ý 
 ýÿýý	7&4' 
 ý 
-ý  ý ý	 ýÿ
`_<'
 ÿ"
E
 ÿ.%.
 ÿ
 ÿ"ý  ýþ	
 ÿ-
ý,>@
 þ

 ÿB	34
 ý!

 ý
. 
)

 þ	
 ÿ:/'
 ýÿþý)>@
 þ

 ÿ2. 0
 ÿý	). 
)} þ	

!)#$ý ý ý,   :<,ý
 ÿþýB	3
 ÿ6ý-


 ý*
!)
"7&  ' 
"
[
 ý-
` _<'
 ÿ þ	 ý	,ý-\45 ? 
 ÿ#;]2} þ	

 ÿ<3
 ÿq

 þ	
 ÿ:<" ý,
ý. 
*ý, ýþ	
 ÿ2
` _<'
 ÿ)ý
 ÿþý3/
 ÿ*ýýIþ	
 ÿ
 ý	0
 ÿ<&
' 
 ý"
 þý	
 ÿ*#4
[
 ý,
0
"
0 #
 þ

 ÿ<3/.0º
 þ	2º ý
` _<'
 ÿ2ý:
: ÿ7ý3
.0
 ý ý*
'ý;#$""ý2} þ	

 ÿBCR
' ý	4 D(> þ	 ý	
 ÿ
 ÿ+
 ý!
 ÿ+ý*/ ý34 ý	 ýÿ
ÿ
ý, ý	0ý, ý	3< ÿ2
 ÿ-ý, ý -
'
 ý" ý	. /B	&4` ý 
 ÿ2
` _<'
 ÿ<3/ý
 ý	. *
0. !0[

^ ý	
5 þý0 ýý"
 ÿ7ý3 G
. ÿ-
 ÿ*ýEþ	Ø
 ÿ*#4_4
 ý,J&
_4
 ý-I^
ý	" ÿý0
` _<'
 ÿ2

 ý0.  
 ýÿýý	+
 ÿ*ý\8 ? º
 þ	!
þ	&` ý 4ý 

 ý	 
 ÿ_4
 ý	0I0
 ÿ)I^0
 ÿÿ
ý0.2
 W #*) #*&/T

 ý,º
 þ	º
 ý	

ÿ+ý-\8 ? º
 þ	! þ	&-_/I
 ý	5º ý346
` _<'
 ÿ6'
 ý	
 ÿ+

 ý	"
 ÿ+ý":<
ý0
 ÿ*_4
 ý"K3
` _<'
 ÿYý	
5 ýþý	,N ýý	5(
 ÿ*
 ÿý

 ý
 ÿ)N ýý	A-
 ÿ*ýý	&

0õ Îû 

    Íû O
 û	'û ÷ ¾Ï 	8øûÐ 

÷ ÍÏ

G_ýØþ	ºýþ	ý	 ý	5'ý
[ýÿ
ý	,#$)
ÿ
ÿ)ÿ+ý	
ÿ2!ý*&'72
ÿ

 ÿ
 ÿ)
ý	34. ý
ºý[ýÿý	C`_<'ÿ6
ÿ)ý-\8 ? 
ý*
ºþ	! þ	"'ý	þ
'ý	





5+-

" "95(#"







 5'@ &# 5/ (

&#(#5/ ?#&

/ (#'@1)/ ( 0$/ (0



!# / &3/ ?#&  

N*N







 

-  8-!>/ ( 





(#/ (

'# u'}~'w`u''uw#w'

A<I+G_ý	ºþ	[ý"*`_<'ÿ<&[4ºýý"!2ÿ2}þ	

!qÿ[ý"! ; 
,}þ	


ºý	*/#$0
#
 þ	


ºý	,8
}
 ÿ. &
,I 8.2
} ý,"


º
 þ,
ý,
 ÿ2Aÿ' ý,
0"ÿ
ÿ/&
> 1UST <ST %'4US4Y *Y"W !#"T$U-(T -.# U2
U -"W +	T$
U )W@X +	W@T #,+(W &I+	T$
Q &-U # -W"+	T$U)W@XB
A
] +M
2!-!-!- ý
 ÿý ý	ý	2
 ÿ*
 ÿ-"=	.
 
0] ` /&
A968
 ÿ.(0" ý[
 ýÿ 3/ 
"
3 þ
 ý	3<
º
 þ,
ý	3" ý"3/3
ýý3. 
 ÿýº
 ý	3< ÿ*=	&[4º ý ý,!-
 ÿ*} þ	

!qÿ[
 ý0#;H
0
&
%984.*
} ý,"

0"
º
 þ,
ý&0> (UST <ST %%'4US4Y *Y"W !#,T$E
U 3"W +	W@
T -"W +	T$
U )W@X +	W@T #,+B
A.:+M
2!-!-!- ý
 ÿý ý	ý	2
 ÿ*
 ÿ-
º
 þ,
ý*
:%8.ý	&
A
P 6[4º ý ý,
 ý"[
 ý," ý
 ÿ#$

 ÿ<&
0P  ;S +,#*)%+	Q*Z + &/U(T -(W &.6
AM6[4º ý ý0ý	<[
 ý0ý 
 þ

 ÿ4! ý 
 ÿý ý	ý	-
 ÿ<& 84[
 þ
 ÿ-,ý	<[
 ý ý 
[
 ý&
%M 0

,"
º
 þ&>  UST <ST  E-QT -"W +	T$U )W@XB
A +G( 
[
 ý#4ý,/!-!. 
 ÿ.
 
 Aÿ' ý&> &/0
U  UST <STB
A
K +M!-.  ÿ"
 ÿ*ý," ÿ
 ÿ/3
 ÿ2ý,#$ý ÿ
 ÿ<3
 ÿ*ýIý	
 ýÿ
 ÿ.
 
0K %L) ÿ
 ÿ/&
A
J +M
2!-!-!.  ÿ "
 ÿ*ý," ÿ
 ÿ.
 
0J %8.ý	&
A<I
^ 8 #$'
 ÿCII
º
 þ-
ý	"
 ÿ+E
` ý	. ý ý	!+, ý'
 ýÿ)
 ÿ+ý-" ÿ
 ÿ/&*' 
 ý":<09
&	&	& G+2!-
} ý"
 ý " ý*
,I^ ` /&
A<II '  ÿ-!#$ 
 ÿ*ý!ý*&[4º ý ý,

 ý"[
 ý# ýý	/} þ	*!-!
 ÿI
 ; 

 
3 ;  =;
 3
%
 ;

 &
,II 4J7&











 



 	

_4
ý-I^?Iÿý 	ý 5ºý,
ý". 
*`_<'ÿ<&

ÿ)Aýþ	
ÿ<:/&G_ý"ý	2ý	ý,
ý	-
6ÿ`ý

ºþ L)M,[3/ÿ2ýÿYþ	ý	2ý

/

 ýº
 þ	!-
 ÿ
 L)M,[R>$4'
 ý	 þ
'
 ý	*
 ÿ*
A ýþ	

 ÿE9B	&8ÿ
ýþ	
ÿ". ý 'ý	þ
'ý
8
 ý	5'
 ý
[
 ýÿ'
 ý	

 ÿ% ÿ6ý-º ý ÿý	%

 ý2º
 þ	!&68 ÿ6ýYÿý	5"ýþ	

 ÿ+. ý*ý	ýÿ
 ý	#; ý	
ÿ,4º ý ÿý	*º
 þ	!*

 ÿ.C4


 ý	I
 þ	º ý	

 ÿ-ý	3ý
 ý;#$ ÿþý,[
'
 ý ý,. ýGþ	 ý,"
"
= ý&
\45'
 ý
[
 ýÿ4 ýþ	,. ý ý"?' FP
' ý
! ýý	[
 ÿ"
 þ	
ý	+. 
)ý-
` _<'
 ÿ+ ýþ	&
' 
 ý ý-. ý ý*P :2 ýþ	,#$
 ÿ
 ÿ6
 ÿ%]I"#$,ý	
ÿ/&)A ýþ	". ý ý-

ý	%)ý

 ÿ
 ÿ- ÿ-ý	
ÿ . ý ý
 ÿþý	-#$4
 ýÿ'
 ý	3#
\ ÿ
2:<
 ÿ
 ý3
 ÿ`
 ý	5'
 ý =

 ý". 
)} ýÿ2

 ý!ý"& $ '
 ÿ
 ÿ) ýþ	0. ý ý"
 ÿ#$[
 ý	60ý'
 ý	
 ÿ'ÿ
 ÿ)#
ý[ý	5'
 ý
[
 ýÿ`_<'
 ÿ)"
Gþ	
 ÿ
 ý"
'
 ý
0/
 ÿ*ý[ý	5'
 ý
[
 ýÿ3<
* ý	0#
. ý = ý	2
 ÿ
 þ	

 ÿ>@ ýý?'
 ýÿ
52?B	&












A

/



&#? &(#



'@

 



("  



/ ($/  $



)  1



!>'@1)(

N*N



$/ $	()$#!>($

/ 0(#/

 (#" 

(



( 	' 

Á'#u'Ewu''{
	Yu'¸w

')I& 84) ý ý	+,[ý"
ÿ L)
.Gÿ-ÿ+-
ÿ!)#$ýÿÿ<&  ý-`_<'ÿ)
::ÿ)""ýO"/&
'2]& 84)
ý
ÿ ? 'ý2L+!2ÿ+. ÿ0*}ý"[ý,#;
ºýÿ,ÿ+ÿqý	ýÿ
ÿqþ
ý&
  ý,
` _<'ÿ*"::ÿ* .0 !
ÿ0ý&
'E
 9& 842 ý,
 ý	)
 ÿ2Aÿ'
 ý,#$ 
 ÿ!-
! ý0ý[ÿý	ý0ÿý	*



"

ºþ-
ý	&*'7/!)!+ý"#ýý	
ÿ+
&< ý-`_<'ÿ+*::ÿ6,.0!
þ
 ÿ- ýý
" ÿ
 ÿ/&
'2:/& 84-#ýý	7
!*ÿ2. ÿ [ý,. 
ÿý	
ÿ-
ÿ*ý""ÿ
ÿ/&?ý,ýý
ÿ!. 
 ÿý
ºý	Iþ	ý"!-! ý
ÿ2E7"'ý
ºý*
'P&4? #$ý-/!-#. ?' F'R
ÿ-_4O[4/3!.*
}ý,-ý	5
. 
2 ÿYý	ýÿ
ÿ2 ý,ýý& ý"`_<'ÿ2"::ÿ) 
 #
0
,
ºý"-ýý".
ÿý_4O[4/&



'EM& 84*
ý"
ÿIýý	! ? 
!3<ÿ2. ÿ-'ýÿ2ý"#$ýÿÿYýÿ !
ÿYÿý,
ý. ýý
0'ý
 #;$&?ýýý,ÿ!*Gÿý!
_4
ýII4'þýÿ
&



M,
 ÿCR
 ÿ
 ÿR ÿ(ý	
ÿ/30 ýþ	Yþ
ºý	(*#;ýý5=$#$Tþ	ÿý
ÿ*. 

`_<'ÿ2Øþ	ºý	ý,ý,
52
ºþ
ÿ) 
ÿ*_4
ý-II&_/ ý	5ºý3/ý,Øý	5ýþý	
!)ý- ý
 ÿ+_4
 ý2I. ,'I
 :2
 ÿ+_4
ý2II&-A ýþ	"ý_ý}þ	)*'ý	þ

ÿ%!

 ÿ++) ýý*. ý% ý#$[
 ý} þ	6C>$} þþý	
º ý2#; ý2
 ÿ¾ý	5'
 ý
[
 ýÿ . ý
 ýB	3ýÿYþº ý	+
` _<'
 ÿ-#;Hý	
 `
9 þý,
 ÿý&? ýIýÿ2#4ý/3
` _<'
 ÿ)} ý	-#$
#ýý	/} þ	,
 ÿ"ý	
#
 ý	5'
 ýº
 ýÿþý-> ý& /&3ý
 ÿþý0.
A :,
 ÿ_4
 ý,IB	&   ýýÿ'
 ÿ"ý0
 ÿý
 ÿ,:/º ý	*4 ý4 ý	!,

 ÿ,ý. ý<3G
. ÿ,
 ÿ"_4
 ý,I]&[
º ý0 ý	
 ÿ ý	4#$ 
 ý	

 ÿ
I ÿ+]- ý"G
. ÿ<&' 
 ý ÿ. ý-ý,:< 
 ý	

 ÿC> 6U*U
+	U +	U 1Q B0 ý' ý	)+I3
^37 ÿ =I37 ý	'
 ýþ	
 ý	!&-_/0ý ý
 ÿ
 ÿ
 
 ý	

 ÿ3 ý,
 ÿº
 þý	6ý"ýÿ2#ý	

 ýý[
 ýÿ0ÿ2-P-
 ÿE<
} ýþº ý2(> } þ	/3/_/ý	3/F Aýÿ
 #$73IJJ]B	3. 
*ý ý	
 ÿ ý	
> +	T )U &.6YZ)*Q 6) #5# +	U0
V #*'-QT"*Q 6) #5# &#W@(T -.#*)**Q 6) #5# &/
U )<W"+	*Q 6) #5# +	U0
V #*'-Q0
T W"+	*Q 6) #5# +	T )
U &.6YZ
W"+	*Q 6) #5#B	3.0º
 þ	2 ý,'
 ý	2P")I3 ý	'
 ýþ	

 ý	!&
?0,º
 þ	ý	6!+Aý6]*#ý`üEC[
 ý	!)'
 ý	 þ
'
 ý	%
 ÿ6
A ýþ	

 ÿ 937. ý":<"

T )Q(W &/(W &.6) ý
 ÿ6#0ý*!ý*34
 ÿ+ý2\8 ? ý-} þý2 ÿ%} þ	
 ÿ þ	º
 þý	
 ÿý	C
 ÿ
ý- ýþý	
 ÿ+ ýþ	

 ÿ<3" ý	 )
Q &UV # <Y
U )QT$W@
U &<
& J!+
,. ý-[
 ý
 ÿ),
ÿ6
 ÿ!)ý
#$.0º
 þ	2. ý"2'
 ýþ	
 
: ý	6[
 þ	º
 þý"#!ýO} þ	

 ÿ3/ý,
 ÿ
 ÿ-!ýc
 þ	 ý"
 ÿ"!
"
 ÿ+ý2. ý	R} þ	

 ÿ. 
%'
 ÿ
 #$ 

!&R_
G ý2
 ÿ ý
= ý)ý-#;} þ	
ý*. ý	 þ	º
 þý	. ý ý'
 ý	

 ÿý	%
 ÿ%*. !)8ýÿ ý	%"ÿ!)

 ý*
 ýÿýý	%!

[
 ý	5!2
 ÿ
 ÿ)!ý . ,
 ÿ


 ý	!6 ýÿ
º ý*)2
 ÿ+ ý	34
 ÿ6'
 ý"
ý	
ý
 þþý	#;R
 þ	º ý	

 ÿ*#4 ÿ!-"ý!ýH. 
 ÿýÿ'
 ý	)'
 ý;#$*&4E
` ý	
 ýý	º ý	3/


,
ÿ0Yÿý" ý ý	
"
º ý`þ,*ý"!ý*3/
 ÿ
 ÿ) ý,!2
 ý
ý5GRýþ	

 ý	
! ý	5'
 ýº
 ýÿþý	%"
º ý-

 ý-º
 þ	º
 ý	2>$
 ÿ/
 þý	%!*ý-
 ÿc
 ý	5

 ÿB	3
.0
º ý"ý	  ýG
 ý	5'
 ýº
 ýÿþý	+"
 ÿº ý3:/
5 ý	73/'
 ý	ý"
 ÿ

ºþº
 þ	!&













& 

N*O





'# u'}~'w`u''uw#w'

[4ºýý,ý'ý>@
ýB!#ýý	/}þ	ÿ*
Eþ	ÿý
ÿ<&0>6UU*


+	U +	U

M
*!`þ	ºý	ý,ý-ÿ*ý	 ý
ÿ#$
ÿ*!Yÿýý	'ý	C>Z#,+

1Q"B


&/U"B


8ÿ-
Gþ	ÿý
ÿ<3
0.  ý !-"::ÿ2ý,}þý,084. ÿý	7&
8ÿ-
Gþ	ÿý
ÿ<38ÿý	.(.008#þ	2!-Eý}þ	*
ÿ0
ÿ*ý
ý&
8ÿ-
Gþ	ÿý
ÿ<3`_<'ÿ2'ÿ'ý2.0084
7&

Jý	*ÿ-,!ØþýÿEý	5'ý
ºýÿþý". 
*
ÿ-`_<'ÿ<3/8 2ý,`_<'ÿ2ý	!-,::ÿ2
}þý,".0ýÿ28 O. !,#;O,!`þ	ý	&
_4
ý-I]  ýý	!&

ýþ	

' ý
ÿ
ÿ,ý#/ý 	ý 5'ý
[ýÿý	ý	
ÿ09II.þ	ºý	ý 
ý	0>ÿ4

þ	ºý	ý	)<B	3#$.0
ºþ	2`_<'ÿ-ý	*ýýýÿþý,#ý	ÿ*ýIþ	ý	ÿ
ÿ

ý	5ýþý	-}þ	
ÿ&4' 
 ýý	4ÿ"ÿý	
ý	
ÿý	-290ÿ*IIý4ýÿþý	3

ý	'ýþ	
ý	!& 8ÿ-
ÿ
ÿý	3ýIÿ"'ý#ºý	'ýý#$ý
ÿ

4[þ	
ºþý	
 ý
^*I,^^"^^^
Nýý	A "IPP
Nýý	5 "IPM
I,]^^"^^^
?0]A J 9
?0
] 
]
I,]^^"^^*I
?0]A 9M
?0
]  %:K
A
 þ	)/-
ý	"ý- ÿ } þ	

 ÿþ	º
 þý*[
 ý	+# ý	5

 ÿ)º ý	62#;
!
 ÿþý	%} þ	

 ÿ2



 ÿ6'
 ýý&,A
"
!34ý4ý,} þý3
 ÿ)ý"#;} þ	
. ý
 ÿ!+. ý	6]2} þ	

 ÿþ	º
 þý	'
 ýý37 ý	
 ýÿý	%-/- ýÿý	"º ý*&*' 
,


ÿ'ýþ ý0ý 
/

 ýº
 þ	!
 ÿý	-
I
 üE-
 '
 ÿ ý	
º ý,4
ÿ#; ý
 ýÿ!


ý	2ý	&4' 
 ý0:< ý0
 ÿ*_4
 ý,K3ý
 ÿ

ý #$ ý	
 ý!-

 ý3.  ý,"
#; ý
 ýÿ!"

ý	ý>@. 
09II

B	& HIÿ!-K ý	4þþ.
 ÿýý ýÿ#<0

 ý
. ý ý

ý	2º ý	0 ÿ)I^"
[
 ý	&
' 
 ý  ý	-/. ýÿ- ý	-8þ	
 ÿ
 þ	ýGý
º
 þ
 L)M,[&?0. ý0
 ý[
 ýÿ

 ÿý	73
ý [
 ý ý. ý#þ	 ý 
"
= ý 
0
 ÿ!" ý	. #;'
 ÿþ	

 ÿ" ý	"
 ÿý
 ÿ
 ý	
º ý
 ý ý"#`
[
 þ	º ý	

 ÿ<R
3 þº ý	 [lm:jp¼
R 0µoklRm4370}
 ý	
 ÿ2
 ý2I"
 # 
` _<'
 ÿ

 ýº
 ý	"ý"/ ý
 ÿ
 ý	5} þ	!2ý-
ý	'
 ýþ	
 
: ý	%
 ÿ+ý"*'
 ý	 þ


 ÿ<34
 ÿ =I
ý. 
 ý&2A
 ÿþý*!ý [
 þ	C'
 ý*þ	
 ý	+. 
+.0º
 þ	6# ý-
5+ý* ý,. 
ý
ÿ/37
". ,
º ý**
 ýþ	! þ	ý"#; ý!ý ,.0
 ý	ý,I
 ÿ,ý
 ý4[
 þ	º ý	ý	ý /
& JI
! Cþ	º ý	ý	
 D. ý [
 ý
 ÿ"
 ÿ
 ÿ ýý 
ý	0>$} þ	

!
!'
 ý3
 þ

 ÿ<3 ÿ"
[
 ý#</!B7ý ý	5} þ	4
 ý	'
 ýþ	
 
: ý	-
 ÿ"ý'
 ý	 þ


 ÿ"

 ýÿ"
 ÿ
ý"
 þ	
ý	2. ý2 ý& 8 ÿ2
0. !'
3 ý} þ	2
 ÿ
 ÿ-

 ý". 0
ºþ!2'
 ý	º ý	6!

I
 ÿ*ýIþ ý#48
 þ	º ý	ý	2/3 Iý. 
 ý&4_
G ý8ÿý0
0'
 ý:
: ÿ


 ÿ*#4
þ	º ý	

 ÿ) ÿýý	 0ý" ý
 ý)
 ÿ2
 ÿ!2ý"/ ý8ýÿº
 ý	þ	
 ÿ*ý
'
 ýþ	
 
: þ

 ÿE
& üGý	5

 ÿ #4
 ý	. 2[
 ý ý3/ . ý	4 ý!'
 ý	0#[
 ý ý	
 þ	+ ý'
 ýýÿ) ý	)  ý	. 2[
 ý ý3/ ý
 þ ý	2
 ÿ*ý[ÿý	5  ýþ	

 ÿ<&
_4
 ÿ!34. ýØþ	ý	+ý


 ý*º
 þ	!6
 ÿ+
"º ý ÿý	 L)M,[(
 ÿ =;
 ý

ý

 ÿ+> þ#&
A ýþ	

 ÿI9B	&4' 
 ý,} þ	

 ÿYþ	º
 þý	G
 þ	
 ÿ

ÿýº ý ÿý	)º
 þ	!) ý
 ÿ2#;} þý



















$,

NN

Á'#u'Ewu''{
	Yu'¸w


ÿ-_4
ýK&4` ý Eÿ8þ	
ºþý. 4:/5ý	-#$4ý	ý/ý	>ý& /&3CI"I:^,^"^,^DB	3[ýÿ
ÿ
ý =;ý	". ýý"
'ýÿ
ºþ#$ý ý-
ý
ÿ<&"' 3:ý	ýÿ).0ýÿ+
ÿ2ý"ºýÿý	
º
 þ	!37
` _<'
 ÿ*
7[ý	
[ý	Gþ	ý	0ÿ"!*'ý	. ýýÿYþý
ÿ*}þ	
ÿ2
&
8 ÿ


 ý	!3ý º ý ÿý	-º
 þ	!!4ý 
ý #<
ÿ


ý0
,'ý	
ÿ". 
ý

ÿ


 ý3/ýÿ-} þ	" G2[ý	
ý"

5 ý	*!ý1
 ÿ



 ý,.0
 ýÿ* ý
 ÿ,#$
 ÿ-
ý&
` ý3. ý	 ý	34ý'
 ýþ	
 
: þ} þ	 G*[
 ý	"
 GRý4. 

ý,> ý& /&3!ý(
 ÿ



 ý
#$
ýI34ýÿý!"

5 ý	
 ÿ



 ý#$
ý ]B	&7GR
" ý	'
 ýþ	4Gþ	
 ÿ:<

 ÿ<3
ý
º
 þ	!"

 ÿI
! þ	
 ÿ:< . ý:
 þ	
 ÿ:/'
 ýÿþý 
 ý	&?0
 ÿ<3. ý	
 ý	3	ý
 ÿ
.0
 ý ýØþ	
 ÿ:<

 ÿ6'
 ýþ	[
 ý	'
 ÿ'ÿýþý	!+
 GRý"} þ"
ý	*> ý& /&:
3 þ	
 ÿ:/'
 ýÿþý*º ý	
 ý	]
#$"
ý)I3[
 ý	
[
 ý	". ý,º ý	
 ý	#$"
ý	]+
 ÿ 9B	3
 ÿ%+'
 ý'
 ýÿ-
 ÿ
ý# ý ý	#7ý0ý0'
 ý	
'
 ý	E
 þ	
 ÿ:/'
 ýÿþý*> ý& /&34
 ÿ*
!B	&4' 
0 ý0#7?
A ü
þ	
 ÿ:/'
 ýÿþý !ý

 ý º
 þ	!,
" ý4

ºþý	"
 ÿ, ý	
4} þ	
 ý	3 ý& /&>$` 

"

FHD0!
$&3<IJJ MLE<
 ÿ2FH[4 ÿ<3/]^^^B	&4
` _<'
 ÿYþ
 ÿ*º ý ÿ*
 þ	:
: ÿý5=;
 ÿý	)

ÿþ	

 ÿ
 ýþ ý-ý-
º
 þ	!6
" ý	6
'
 ÿ+Y
 þ	

 ÿ+#0] K $ 
º ýYý	5!+º
 þ	º
 ý	&
Jý
 ÿ


 ý" ÿY
 þ	
 ÿ:<

 ÿ* ý	 
 ý	ý'
 ý	
 ÿ'ÿ
 ÿ*#ý

 ý,. 
ý"º ý
ºþ0#$
` _<'
 ÿ<&4_4
 ý"I0
0
 ÿØý	5º ý

 ý,
 ÿý0
<º
 þ	!&

,

 Îû 

.õ

    Ï ú#ÏÍû ÷ ]Í     Íû O
 û	 ù	8øûÐ 

÷ ÍÏ

_/,ý-ý	
ÿ+ý3`_<'ÿ6. ý	
ºý[ýÿý	%+ý*ý+>ÿ.H'ý	ý"
ÿ

ºþBºýÿý	
º
 þ	!&]I,ý	0 ýþ	ýÿ)'
 ý;#$[ý	)ý"[ý,
52ý	+/
ÿ*
ÿ
ÿ/3ý	
ÿ

ÿCI] :Yþ	º ý	ýý	,

 ý	&-' 
 ý-

! ý
º
 þý	# ý- ý	6[
 ý	!

3 I
# þ	 ý3ýqý	5ýÿ*ÿC

ºþ 

 ÿ
 
: þ
 ÿþý+#,ý2

 ý[
 ýÿ
ÿCý)º ý	
 ý	!

"
= ý	)[
 ý ý->$
 ÿ!-[
 þ	º ý	

 ÿB#;Hý
 ÿ
 ÿ"ý	 

 ÿ&8 ÿ-#;} þ	3
[
 þ	º ý	

 ÿ2 [
 ý ý	2! [lm:jp¼
R 0µoklRm+
 ý	 
 ÿþ ý ý3#; P
] H
 ÿ-
 ÿ
 ÿ
2M:H
 ÿ-ý	
ÿ/&' 
 ý0#$. 
 ÿ ýþ	

 ÿ0 ý'
 ý	ý	-"ý,
 ÿ!
 #4
 ý	3. ý	7
ý	 ý7 ý	ý	2ý	&








	

R



Rjp}lm:r_k}s:o_.ojpm:o'n

:µl´}¼]k 



k}s:o



pjlmRlm:r

:µl´}¼

'ºý)I
=ý	"ý
ÿ
ÿ)ý"ý	
ÿ)'ý;#$ÿþý#0`_<'ÿ<3#$
[ý	=


 ÿ6[
 ý ý	q
& üGýþ"
ÿ+ý<9II
 ÿ
 ÿ+

 ý	3
` _<'
 ÿ% ý	C
 ÿ"_
! þ	 ýÿ
º
 þ	º
 ý	0
 ÿý\8 ? º
 þ	`
! þ	&8 ÿý"I] :ý	
ÿ"

 ý	3
` _<'
 ÿ* ý	-ý 
 ÿº ýº ý ÿý	
º
 þ	!&-?0)ýº ý ÿý	%º
 þ	!+. 
"
= ý	+#$0
 ÿ!)ý*
 þþý	"[
 ý ý [l
m:jp¼
R 0µoklRm437
 ÿ!*!'
 ý	0#[
 ý ý	
 ý"'
 ýýÿ+ ý	2`ý	ý"

 ý"!ý"
> ý& /&3/*
 þþý	37

 ý 
!R
3 ý`
9 þ	º
 ýÿþ	!34

!R>@M,
 ÿº
 ý	
FOG
N ý
 ÿ/3IJJPL7D
ý	 $&3<IJJKBB	&7_
G ý0 ý	ý,ý'
 ý;#$
 ÿþý0#ýº ý ÿý	2º
 þ	!*. 
- ý	'
 ýþ	 
ý

 ÿ4 ý	. *[
 ý ý" ÿ2Ø
 ÿ"'
 ý #4ýýÿ
 ý	. 2[
 ý ý	  . ý

ÿ 
"

= ý,ýý	 !ýH#$	&
[ ý,,",
ÿ"ý	 ý
= ý	6
 ÿ6ý":<,.). #0'º ý+I&
0
8 ÿ-ý0:< .,3. ý0

= ý,'
 ý;#$
 ÿþý #$ý [lm:jp¼
R 0µoklRm6
 ý	. -[
 ý ý3

 þ ý	6
 ÿ)ý ýþý	
 ÿ) ýþ	

 ÿ<&' 
 ý-
 ý
 ý,
 ý#
" ý	. +[
 ý ý	+} þý
9II,
 ý	 ýÿýý	+
 ÿ*ý" ÿ"
= ý	+
 ÿ
 ÿ*!ýO. 0^ ^ :K2>$ ýþ4ý" ÿ ý

 I0-IB	3.0
º ýý0 ý ý 
 ý#7
[
 ý0[
 ý ý} þ4ý"I] :,

 ý	0
 ÿ"ý
ºý ÿý	6ý	!ý . ^ ] :/37 ÿ2

 ý[
 ýÿ,,2
 =;
 ý-# ^ ^PJ
 ÿ+-ÿ/









N







'# u'}~'w`u''uw#w'



jµ:j'klRmO³6oj·
Rpo


J
ÿ! ? ºý	
ÿ
G_ý ? ºý	
ÿ



pjlm

^ ^ :K
I ]
] :K
^ IK
9 9K
9 I
9 :]
] K 



^ ] :
] IK





9 P]





 

 












9 M:






 



] 
 ]



jµ:o

^ ^PJ
^ ^]J
^ 
^ 9K
^ :]
^ JK
^ I
^ PK
^ PP









^ .
: M
^ IJ
^ ^ 
^ ^I
^ ^ 
^ I
^ IP



] M 
^ II
9 9J




^ ]]M





?Aü
G_ý#ýý	/}þ	
\!
G(!
` _<'

 ÿ2'
 ÿ'
 ý
üGý
ý



#o'·k



'ºý-I '
ÿ2ýý	'ý;#$ÿþý"#$ 
Iý	
ÿ+[ýý	&,' ý":<Gþ	Øÿ
 ý	 ýÿý2
 GRý ýÿ-[ý ý	Ø
 þ	ÿ
'ýý	H>@ýý*ý	5"#$,'ý	
B	L ý2ýþ	ÿ¾þ	 =
Ø
 ÿ2
ý" ý ý,
 ý"#ý"[
 ý ý"
 ÿý	)
 ÿ2ý"
 ÿ
 ÿ*/L/ý,

þ	Ø
 ÿ+
"ý- ý ý"
 ý-
 ÿý	6
 ÿ+ýý	,/Lý"#$þ	Ø
 ÿ+. 
ý"
 GRý ýÿþý'
 ý	. ýýÿ2ý,ý	
 ý
 ý"
 ÿ2ý"
 ÿ2
 ý
 ý->$-


 ý`ÿ"'
 ý

- C. 
 ÿ.D/3.0
º ý)_
 ÿý	

 ýYÿ"'
 ý
- C DB	Lý:#$ þ	Ø
 ÿC ý	 ýÿý


ºþ7

 ÿ
 
: þ ÿþý"
 ý,
 ÿý	)
 ÿ-ýÿ/* =;ý	&



.=;ºý" =;ý	0ý0 ýþ	,[ýÿ& * ' 
,ý	8þ	ý	ÿ,*ÿ)
ý[ýÿ0#;
-P]cþ	ºý	
ÿ)ý""ÿ-ý,
ÿ
ÿ*
ý	,-EM:cþ	ºý	
ÿ)ý""ÿ-ý
ý	
ÿ

 ý	&
' 
 ý, ýþ	
 ÿ).(#'º ý-I,.  0'ý;#$
 ÿþý"

 ý	 #; 
 ÿ
 ÿ--ý	

#$ý`þ	 ý	!% ý	ý	%[
 ý ý`½Poj¿
R 0µoklRm KY
& ½Poj¿
R 0µoklRmC
-2
 ý	
5 ý	
 ý


 ÿ#E
 þ	º ý	

 ÿ7
 ý	4
} þ ý	
*
 #<
ý4
 ý	 ý.ý	
ýR
 þ	 ýþ	7
. 
'
 þ3ý0
 ý,
ý0 #7ýGþ	 ýþ	Eÿ"'
 ý#4
ý	& H0ý. 
 ý3/ºýÿý

ý0
0.0
 ÿ2> ý& /&3ý ý!0
 CE7"'
 ý
º ý,D* ý!ý 
 ý0
 CL)
G
. ÿ.DB	3
 ÿý

 ý0
 =I&' 
 ý0"


 ÿ,#$
" ý  ý:
: ÿý	*[
 ý ý
ý	. 
 =I 
 ÿº
 þý	
ý
 ÿ#$

 ÿ,'
 ý	
 ý	". .
 ÿ.þ	
 ÿ
 ÿý	"
 ÿ,ý/ ý#ýÿº
 ý	 ý	 ýÿý	"0ý  ý	3
.0
º ýÿ
 ÿ=ÿý	
 ý2 ý	. %[
 ý ÿ,ý*
 ÿ#$

 ÿ6'
 ý	
 ý	C. " ý	 ýÿ3'ý
º
 ý	C
 ÿC) ý" ý	#0
 ý	º ý	 ÿ-
ý""#$"º ý
 ý	-#0ý2 ý	. 7&%' 
 ý*
 ÿ
 ÿ


 ý6 ý ý2#,. ý þ	º ý	

 ÿR. )I ]R>@.0
 ý ý2ý+
 ÿ
 ý)
 I) 9B	3 .0
º ý+ý
ý	,

 ý2 ý ý". "] IK&*' ". ý*
 ý-*
 ý-

 ý[
 ýÿ3
"
[
 ý-

 ÿ
 
: þ
 ÿ
ý-^ ^]Jº ý	 ý	$&*_
G ýØÿýý-º
 þ	!6º
 þ	ý	6!)
"
=	
 ÿ)ý
 ÿ
 ÿI
 L)M,[R#$

 ÿ`
! þ	º ý	

 ÿ6>@.0º
 þ	*. 
º ý[
 ýÿý	2
 ÿ*ýý	!ýB	3
 ÿ*ý,º
 þ	!2º
 þ	ý	2!

"
=	
 ÿ-ý
 ÿ
 ÿE
 L)M,[+#$. ý[
 þ	º ý	

 ÿ6>@.0º
 þ	-. E
 ÿ 
º ý[
 ýÿý	/B . ý ý0
 ý!

"
	3/. 
*
 ÿ!- ý!*"
 ÿ 
 GRý ýÿþý	0
 ÿ2} þ	

 ÿ`þ	º
 þý	&





 


 

2


 #4( (#/ (" " 89)!#* " &
(	 
 B)


 #5=



!/ 1

 1

!#/

/



(/ $# $









.



 
 

	
 



 

' "  (	 B 3/ 

/ ($/



#/ )/ 

1

!#"  / (

/ 

(/ $# $

?>

 

/ /

" " / 0(#/

'5)/ / "5($>



-/ (

/  8>

(0 5'@5 ">$/ >(# " &/ (

(#"

" $# $

1) &# #/ 

N



1

!#"  / (/ (
/ (0" 

&#" $





   1





 (# 8

  1



8>?#& 1



#/ " 3!#* " & "  
)$# / 0( $



/ ( $!>'@1)(

" 3 ?> ()& $)5&#5 $



1) &#

Á'#u'Ewu''{
	Yu'¸w

' ý)[ýý2
ÿCý2
(.,3qi234
2ÿý

ÿ%#



[lm:jp¼

0µoklRm4&

R

 . 	ý ý	3
ÿý*#Rý	
ÿ",þþý	3qiBý	ý	
ý  
!&8ÿ-
ºþ	3

H5
ý	4'ýýþ	ýþ	ÿ

ÿ}þþ}þ	!#$ý/ý)ý!3ÿ
.þ	ý	-!

qi


ÿ*I#$0ý}þ	[þ	ýþ	
ý ýÿ*& P #$.ý	ý!,. 
'þ7&' 3
 #7ý 
,
. 
 ÿý	
ÿYÿý0E7"'ý
ºý
ÿ2ý""ÿ
ÿ/3<ÿ2ý,!ý ý
ºý	ý,/ý#$ ÿ
 þ	

!-
ÿ2`Eý	.Býý	!*
ÿ*ý,"ÿ
ÿ/3 [lm:jp¼
}
R 0µoklRm =I3½Poj¿
R 0µoklRm "I3
 ÿ

 qi ]&6'º ý6I-. ""ý2
 ý
 ý-
 ý2#0?
A ü 
 ÿþ ý ý	%#; ] :K*/
ÿ

 ÿ
 ÿ-*] M ,/
 ÿ*ý	
ÿ)>@.0
 ý ý,ý"
 ÿ
 ý
,^"E9B	3/"

 ÿ
 
: þ
 ÿ

 ý[
 ýÿ>
^ ^ :B	&"?0
 ÿ<37
"
 ý[
 ýÿþþ ý	 ý	
 ýÿ))ýº ý ÿý	%º
 þ	!% ý	+#$0ý	
ÿ
. E
 ÿ 
"
= ý	2#$
 qi2&
' 
 ý" ýý[
 ý ý	I
 þ	
 ÿ
'
 ý ý	+-#;0 ý*.
U 1	,#XT$(W 3*#- ý	. )[
 ý ý	3<
 ÿ)ý" ýÿ ý
ý- ý	. )
" ýþ	
 ý	!6'
 ý:
: ÿý	%"#;'
 ÿþ	

 ÿ+#ý!ý 2
 ÿ)*

 ý34
 ÿ_
 þ
 ÿ+'
 ý
þ	ý	2
 ýþ	!-#;H
0/&4_
G ý8ÿO
. ý	5"
 ÿý".('
 ý;#$
 ÿþý8þ	
 ÿ
 ý	#;H
 ÿ
 ÿ
-ý	.0
 ýÿ)- ý	0%
# +	
S 1	,#XT$(W 3*#

!+[
 ý ý	->$
'
 ý	+!2ý
 ÿ) ý #$. 
 ÿ
ý}
 þ	-

 ýB  ýIþ	
 ÿ
'
 ý ý	7#
& üGýþ< ý} þ	-

 ý,".  } þþ	
 ÿº
 ý	)!ý. ý
 ý	!)
 ÿ+_4
 ý)I]&-' 
 ý-[
 ý ý`½Po
oo'n
Rj´}¿%
"
 ÿý	+#; ý":<
 ý	

 ÿ+
 ÿ

-
 ý	!(>$ ýþ ý2 ÿ ý*
 I*CIB	&C' 
 ý2[
 ý ý	
 Ej·¼#
3 ½ s:j'k k  ·j¼
3   0m
0mRnRo'p}·k  Rn(
 ÿ
 Øo R·o6 ý
 ÿý	+#; ý-,#$ 
 ý	

 ÿ2>$ ýþý*
 ÿ
 ý
*I
*PB	&0A
 ÿþý. ý"
_
 ÿ
"
= ý,#$0
 ÿ!2#ý	 ý, ýþ	

 ý-[
 ý ý	3/. ý"_
 ÿ+Q )W@U )W
ý	5'
 ýþ	

 ÿ,#$
 ý[
 ýÿ,'
 ý	/

 ÿ<&2' 
 ý-:/
 ý*. #0'º ý+I. ,. ý
 ÿ
#;} þ	"
O
 ÿ,::ÿR ÿ!6

ºþ!%

 ÿ
 
: þ
 ÿ`þ	
 ÿ
 ý	
 ÿ6ý)[
 ý
 ÿ6
 ÿ ý	
ý
 ýþ	

 ÿ%#$
ý	 ý[
 ý ý	&  . ý	 ý	3. ý  ý
 ý	*I
 þ
V"
U 3*#,T$U(T -.#,V"(W Y4#Iý5GRýþ	
ÿº ý
#;} þ	

 ÿ-# ý0Y
 ý	5ý[
 ý	!2


 ý, ý	5ý[
 ý	q
! ÿý	

 ý
 ÿ0"!* ý	
!ý  ÿ-
) ý,
 ÿ
 ÿ!ý*&4_4
 ý*I 93.0º
 þ	*. ý8ýÿ
 ý



 ÿ
#4ý
 ý	0#$*ý
 ÿ* ÿ2ý	 !ý"#$ý	 ý, ýþ	

 ý,[
 ý ý	3.  

 ÿ
"
=	
 ÿ"ý ý	4!ý(#$ý I
 þ	º ý	

 ÿ-[
 ý ý3. ý  ýý1,
 ý þ	
 ÿ
ýÿ!

 #$ý	-. ý	
. !0#;1ý 
#<ý0 ýþ	

 ý0[
 ý ý	3
 ÿ. 4ý 
 ÿý[
 ý	
ý

 ý	&(?0C. ý) ýqÿ+:<A
 ý	5
 ÿ

 ÿ%#$"
2
 ýÿ[
 ýÿ
 ÿ<3 
`þ	
 ÿ
ýÿþ	!1>@

 þþ0"!
 ÿ-'

 ý	 ýý0#$ P" ýþ	

 ý"[
 ý ý	B
I
 ÿý	.!&
8 ÿ6*3[
 ý
º
 þ ý	-
 ý*'
 ý"
 ÿý	%

 ý[
 ýÿ"
ÿ%ý*
"
= ý	R
þ	º ý	

 ÿ%[
 ý ý3 ÿ%)

 ý[
 ýÿ"
ÿ6.
 ÿ
 ÿ=;
"
= ý	1>$ý	ý	/B, ýþ	
 ý
 ý ý	&8 ÿYþ	
[
 ÿ3  ý	06
. ÿ

ºþ!*

 ÿ
 
: þ
 ÿIþ	
 ÿ
 ý	#$ Ø
 ÿ"'
 ý#
ÿ
 ÿ=;
"
= ý	) ýþ	
 ý"[
 ý ý	3ÿ-
 ÿý ý	
ÿ*"
 ý0ý,"
º ý[ý5GRýþ	&



































  



o'´}k


0o'pkl·o

8 ÿ%

ÿ6)ý-=;
ÿ'ý'ýÿ'ýÿ*'ý;#$ÿþý`þ	ÿý	,#;

ÿ
ÿ+2ý	
ÿ+
ºþ	!
"
þý	73ýý*. ýý*)=;'ý'ýÿ'ýÿ-'ý;#$ÿþýYþ	ÿý	&)_/Iý	5ºý3ýý
. 26

 ÿ
 
: þ ÿ)
ÿý} þ	

 ÿÆý5GRýþ	2'ý	. ýýÿ(º
 þ	! 
 ÿ( >$ & ^IB-.0
 ýÿ('
 ý;#$
 ÿþý


(
. `
 ý	ý	R#$ [lm:jp¼
R 0µoklRm4&
G ý)'
_
 ý	º
 ý	
 ý6-
Y
 þ	 '
 ý)ýý5GRýþ	-#
 ýY
 ý	5'
 ý
 ý6. 
Cý+!ý 
 ÿþý% ý	
).6
 ý	*qÿº
 þý6 ý)'
 ý;#$
þ	!*`ý	5'
 ý#$ý 
 ÿ!*.>$DB
 ý	$&3IJJKB	& A
 ÿþý" º ý ÿý	+º
 þ	!










 -&#- !>/ 1)(#"9$# / 0(



'@



!>" /



  



($

=
>

&





(/  $



 
   

'9'@



* (" / 

'



-/ #/ (#*0&#!

/ (

N




2

3



3C

 
 

'@





1

!#&

($



/ (#

?>  (#*0&#!
/ (


2 
 >

3?>  (

'# u'}~'w`u''uw#w'

>$B

>$B

0.7
Train
Test

0.45
Train
Test

0.4

0.6

0.35

0.5
0.3

0.4

0.25
0.2

0.3

0.15

0.2
0.1

0.1

0

>þB

0.05

−1

0

0

1

1

>@/B

0.7
Train
Test

2

3

4

5

0.45
Train
Test

0.4

0.6

0.35

0.5
0.3

0.4

0.25
0.2

0.3

0.15

0.2
0.1

0.1

0

>ýB

0.05

1

2

3

4

0

5

1

2

3

4

5

0.35
Train
Test
0.3

0.25

0.2

0.15

0.1

0.05

0

1

_4
ýI*9

2

3

4

5

 

 RÛÓá}çà0í_ÙÛ×R×ÝGÓÛá}ç

Ñ#ÔºÓ×æÔºòÞ×ÔºÝÖÓ0Ýâ×ÙÒ#ÓÞò 
Ò à×ÔºåÒ ä8ÒÛÓÞæÒÓç Û RíYÒòIâÒÒÚòÛàã'ç ò
Ú 0î#ï}ðÞÖ[ÞÖÚÒæÓ×Ý}Ý}Úç Ò .ÒÞÓÒç

 

	 


N


Á'#u'Ewu''{
	Yu'¸w

_4
ýI,: 8 ÿý}þ	
ÿ¾ý5GRýþ	-'ý	. ýýÿ%+ÿR
ºþ	!&(' ý)[þ	.Oý2
ÿ!
þ	ºý	
ÿ)ý #$ý
5-">@
ÿ-ý,'ýý	!*. ýý,ý	ýÿý	/B#$ý,ý	
 ÿ2
 ÿ2º
 þ	º
 ý	&,' 

 ý,ý	º
 þ	!)'
 ý;#$
 ÿþý,
,'
 ý	ý#$ý, #$ 
.0
º ý)ý-
 ÿ%º
 þ	!R'
 ý;#$
 ÿþý*
-'
 ý	ý"
 ÿ+ý-:<.23

 ÿ
ý	
'
 ýÿþý" ýº ý ÿý	2ý	0º
 þ	!2
 
!2
"
= ý	*#$ ý	5'
 ý ý&

.  *ý	CÿC
5C. 
]ý}þ	Rý	3
*
2
ºý+-ý2ºýÿý	 
ºþ	!R
*
!

"
=ý	#$0ý	5'ýý&'7Iý	5ý0
!ý	
3. ý 

'ý	*0þ	
ÿ,
ý	
. 
 Cÿº
 þý,D6>@"I ÿ6]B ÿ Cý	5'
 ýD6>@ 9*= MB0ý&"G_ý,#$'ÿ+0ýºýÿý	
º
 þ	!2
)
 ÿ*#;} þ	 º ý2- ý, ÿ2

 ÿ
 
: þ
 ÿ

 ý[
 ýÿ 
 ÿ [lm:jp¼
R 0µoklRm+#$
ý	5'
 ý34
 ÿþ ý
 ÿ+ýYÿ"'
 ý,E
# þ	º ý	ý	%

 ý	"#; :.M /
 ÿ+
 ÿ
 ÿ)FMJ 
/
 ÿ)ý	
ÿC>$ & ^^IB	&*8 ÿ_þ	
 ÿ3<ý ý-. "q
 ÿ
 ÿ=;

 ÿ
 
: þ
 ÿ'ý	/

 ÿ2#$8
 ÿº
 þý	
>@
 ÿ MM*3ý	 PP *34 & 9B	&+8 ÿ6
ºþ	3"G
. ÿ+
 ÿ6_4
 ý),I :/3ý*ý	"[ý
 ÿ ý
. ý  ÿ*ý,
 ÿ2[
 ý ÿ #$ ý:<0.3/

 ý #$ý" #$& ' 


"
ý,#$0-!ýO, ý'
 ý,
 ýL. ý	
 ý +
,'ýý[þ ý"0
!ý 
0

!) ý	)Y
! ÿº
 þý" ý3ý!ýO"
Gÿýý	2'
 ý" ý	
 ÿý	7&













R

Rjp}l· Rm







k Yj:mRnÆ`o'·lrRm:o'n

:µl´lo'·

?02ýý	,ý	ýÿý	)-#; 
ÿ
ºþý-ÿ2
ý[ýÿ #;O
ÿ
ÿ*-ý	
ÿ/37
ýÿ
 
"


 ÿ%

 ÿ%2 ý	#,
ºþ	
ºý	*
ÿ6ý2\8 ? þ	*! ÿ'ý2ý2'ý	
 ý	
 ÿý,#$ þ	

 ÿ*" º ý ÿý	)º
 þ	!& ?1" ýÿ/2ýÿ
ý,.)'ý8þ	 =


 ÿ-ý ý!*'
 ý	0 ÿ.
 =;'
 ý	

 ÿý	2:/
5 ý	)º
 þ	!
&  . ý	
 ý	3ý ý
I
 ÿ- ýý[
 ýÿ
ÿ*ý

ý ýR
3 ÿ0"
 ÿ ý3<0.00ý'
 ý	,
 ÿ.
 =;'
 ý	

 ÿý	6º
 þ	!+"

 ý
 ýýÿ<&CE
'
` ý	 ýý	º ý	3

`
 ÿ+6. ,
"
= ý	R!ý þ	 ý	")!ý"
ý!
 ÿ2"

 ýº
 þ	!)º
 þ	} ý	+!2
 ÿYý	5'
 ý&?0*
º ý[
 ýÿ
ÿ)`
 ÿ"'
 ý
# ÿ.
 =º
 þ	} ý	+º
 þ	º
 ý	37ý
 ÿ

 ý	0#; ý*3/
 ÿq
 þ	
 ÿº ý ÿý	)! =
ýO.)'
 ý"
[
 ý5=þ	
 ÿ"
 ÿ) ÿq
 ý	5'
 ýÿ

 ý)>$
 ÿ2
 ÿ*#;} þ	3
I
 ý	5} þ	!2ý"
 ÿ)# ý'
 ýý	73
ý
 ýÿ

º ý[
 ýÿ = ÿ.
 =;ý	 [
 ý	!,. ý  ý ý
ÿ, ý} þýB	3
 ÿ
 ÿ,! =
ý

'
 ý	"Ø
 þ	
 ÿ ýÿº
 ýÿ,ÿ+ý
ºþ!)'
 ÿ+5!&8 ÿ)
 ýþ	

 ÿ2. ý,.1

N*P

'# u'}~'w`u''uw#w'

ý-'ý;#$ÿþý#ýºýÿý	%
ºþ	!6
"'ý	ýÿ)ý	ýCÿ/D-:/5ý	6
ºþ	
ºý	3!
þ	
ÿ"ý0ý	. ,#$/ý  ýþ	
ºý	4
ÿýGý

ºþL)M,[)ýEþ	ÿ
ýÿ. 

ý}
 þ	-ý ÿ
 ý,º
 þ	!&' 
 ýÿ<3/'
 ýþ ýIý} þ	-#7ý	 ý,ý ÿ

 ý	 
 ÿ!*"
 ÿ#;70
# þ	
 ÿ=

ýÿ, ýþ	º
 ý	
 ÿ+ý2L)M,[3<
 ÿ+ý`ÿý	5,ýþ	

 ÿ+. ý- ý	 ýÿ"ÿ+
 ÿ!
,# ý2L)M,
[ 
 þþ} þ	!&
}





A
 ÿþý, 
 ÿ
 ÿ-
ý	ýýÿýý	)
ÿI)Q&UVcþ	
ºþý	3<ÿ!-
ý"
ÿ*ý

ÿ
ÿ,ý	4
 XU&+	W"+	T#*&/T<. 
"
ºþ	!

ÿ,4
ºþ	!Øþ	
'ý	ÿ"'ÿ
ý	2L)ÿý
? -
# 
& J!qþ	ÿ
ýÿ0. ý[ýÿ*04ý"ÿcþ	
ºþý	
ÿ2ý"
ýýý
. 
" ýº
 þ	ý	-! &7_
G ýEþ ÿ ý
 ýý0 ý	. 4
 ý7ýEþ	
 ÿ
ýÿ
 ÿ
 ÿ,

 ý	

 ÿ* ÿ*'
 ÿ
 ý	q
 ý	
ý,#ý" ý	 ÿ-# &





:µl´}¼

'Rý	
A!` þ	ÿ:<
A! ? ÿ:<
  ý` þ	ÿ:<
  ý ? ÿ:<
L)
5 ý	
P

 


I]
I I

pj·



I




^ M 
^ 
^ K
^ M
^ ]
^ ] ] 
^ ^  

 
 
 


IP
I I

 

I*9



r



³P



^ P9:
^ ^KP
^ ^
^ M
^ 
^ M:
^ 9]
^ 
^ M9









8jµ:o




jµ:o



^ ^M
^ ^I
^ ^I
^ 9^
^ 
^ M






'ºý"] ? 
ÿ)2ÿ/6
ºþ	
ºý	&FEýý-. ýØþ	ý-ý	"
ºþ	!6. 
+ý	ý
ÿ/6
ºþ	
ºý	-
ÿ)ý2L)ÿý ? 2[ý	7&*' ý":<Iþ	Øÿ6ý	ýÿ,ý

 GRý ýÿ*º
 þ	º
 ý	q
 þ	
 ÿ
'
 ý ý	 >@ ýý*ý	5#$"'ý	
B	L0ý2ýþ	ÿ]þ	ØÿC. ý
ÿ"'
 ýI
# þ	
 ÿ
ýÿ- ýþ	º
 ý	
 ÿ%ý2
 ÿ
 ÿ%/Lý2
]
 þ	Ø
 ÿC. 
ýØý
º
 þ ý ý ý	. )
 ÿ2ý	 ýØþ	
 ÿ
ýÿ, ýþ	º
 ý	L<ý"#$qþ	Ø
 ÿ
. ýØý	
ý	6
 ý-#ý-º
 þ	!%} þþ	
 ÿ)*º ý ÿý	 L)M,[37
 ÿ+ý
:#$_þ	Ø
 ÿ6. ,ý-

ºþ

 ÿ
 
: þ
 ÿþý%>$
 =;
 ýB"# ý*º
 þ	
!  . 

 ý	'
 ýþ	0"ý,ý	 º
 þ	!&







'ºý*]Yþ	ý	,ý*'ý;#$ÿþý-# ºýÿý	%ý	,!ý*37ÿ+ý [lm:jp¼
R
0µoklRm(
 ý	. %[
 ý ý3)P*:/
5 ý	Cº
 þ	
ºý	-
ÿ68þ	""ý`þ	"ÿþ	
ºþý	
ÿ6ý


 ý)!ý"-
ý ý3 -. ý ý2
 ý	ý	C%2!%

 ý)!ý '
 ý	

 ÿý&
' 
 ýA!` 
 þ	
 ÿ:< º
 þ	!2. ! ý	 !ý1
 ÿ



 ý"
 ÿY
 ÿý	
 ý#
 þ	
 ÿ:<"LýA! ? 
 ÿ:<
º
 þ	!C. !" ý	!ý 
 ÿ



 ý)
 ÿ þ	
 ÿ:<"LýI  ý` 
 þ	
 ÿ:< º
 þ	!C. ! ý	
 ý0
 ÿ


 ý* ÿ ÿý	 ýG
 þ	
 ÿ:<"L7ý2  ý ? 
 ÿ:< º
 þ	!6. ! ý	" ý0
 ÿ



 ý*
 ÿ
þ	
 ÿ:<"L<ý0L)

5 ý	+º
 þ	!+º
 ý	ý"
 ÿ



 ý/
 ÿ2ý"

 ý&_/0ý2  ý =
?  ÿ:<Hº
 þ	!3ý ý	º
 þ	!
 ' ý	ý4. 
-
 ÿ
 : þ ÿþý8ÿý44' ý	.Rý0^ ^P0º ý	 ý	$3/ ÿ
ý0
 GRý ýÿþý. 
E  ý ? 
 ÿ:<1
E
 ÿ

 ÿ
 
: þ
 ÿ&>$` 

 ÿ!3ý :/
5 ý	<
   ý ? 
 ÿ:<
º
 þ	!) #; ý	+'
 ý	
ÿ2
I
 þ	

 ÿ2
,"0
"
-ýº
 þ	!). ý,º ý ÿý	7& B+' 3

ÿ+


 ÿ2-
"
=	
 ÿ) ý0
 ý[þ	#º
 þ	
! þ	º
 þý	,0
I
 þ	
 ÿ
'
 ý!6" ý" ý5=
::ÿý	*
 ÿ
!º
 þ$3ý ý	
 ÿ#$ þý[
 ýÿ º ý ÿ
 ÿ-} þ	'ý;#$"[
 ÿ"'
 ý.
# ÿ
ÿ/2º
 þ	º
 ý	&



N#D

Á'#u'Ewu''{
	Yu'¸w

 [s:o





Rn.m:o'··



Rp`³P





_4
ÿ!3. ý#þÿ, .0ý	ý7Rý	
ý#ý. }þ	!, 8ý	
ý<.0ý	ý7. ý
 ý 
!*'ýýÿ"#$'ÿý

3.0ý	ý4 L)M,[6"
ý}þ	!-'ýýÿ-"ý
  ý	º
 þ	#4ý
 ý,#}þ	
ÿ3/ . ý,'ýÿý	2-ýIÿý	ýý	ºý	Gþ	ýÿ*
)º
 þ	!+q
! þ	 ÿþý&0?00[
 ý8þ	
 ÿq
 ý	
'
 ýÿþý-
 ÿ0
º
 ý	.,3<. ý, GRý ý ý	0#

º ýØý	5'
 ý
[
 ýÿ
ÿ2.0º
 þ	2. ý"
 ÿ"!*
 ýÿýý	)
 ÿ!6>@'
 ý	ý"
 ÿ

ºþB,º
 þ	º
 ý	,
 ÿ2
º
 þ	! þ	&-_/G
 ý} þ	)
 þ	6º
 þ	!
37. ý ý	6ý
 ÿ
 ÿ)

 ý	[
 þ	
 ÿ
ýÿ". 


þ	ý
 ÿ*'
 ÿ
 ý	<
 L)
 ÿý ? [
 ý	
ý	 "#ýIý	5'
 ýþ	ý	6>$
 ÿ`
! þ	º ý	

 ÿB  ý	 ÿ
#
> ý	5}
 þ	!2 .  
 ÿý#$ý"
 ÿ.
 =º
 þ	} ý	B
 Cý	5'
 ýD-º
 þ	º
 ý	,
 ÿ)'º ý"]B	&' 
G
 ý	
ý
. 4ýÿ"
 ý	-. 
,ý 
 ý 	,#
>#$7ý ýB7
 ÿ"ý º ý ÿý	2
 L)M,[&8@#<ýL)M,[
. ý ý,'
 ý;# ýþ	"'
 ý	7#4ý, ý0

 ÿ  ý	
 ÿ ý	0!ýO} þ	

 ÿ3ýÿ-ý L)
 ÿý
? [
 ý	
ý	 ".*
!2'
 ý,*> ÿ
!#
B ý	
ý0# 	/3ýGþ	 ý	

 ÿ*'
 ý	. ýýÿ-ý	 ý
.	
 
 ÿ

ºý	.+'
 ý"

 ÿ
 
: þ ÿ->$0#
# þ	 ý,'
 ý'
 ýÿ'
 ýÿ,ÿ*ýØÿ"'
 ý #º ý	
 ÿ
ýL)
 ÿý ? G
 ý	
ýB	3 ÿ,ý '
 ý	 =$:/4
 ÿý ý	

 ÿ
"."'
 ý 


! 	 
	 
>@'
 ý-I, ÿ2
 ÿý þý^B	3.0
 ý ý  
Ø
 ÿ!*

ý	_
 ÿ
 ý,
º ý". 
* º ý
 ý ÿ6 ÿ6
 ÿþý*'
[
 ýþ ý
 ÿ6"ýYÿ"'
 ý,G
# þ	
 ÿ
ýÿ" ýþ	º
 ý	,
 ÿþ ý ý	&)? "ý
ýI
 ý	5ý[
 ý3
 #
 L)M,[ ¾
 ÿ+ ý	

 ÿ+2ý* ý"

 ÿ  ý	
 ÿ ý	"2!ý
 þ	

}
 ÿ3ýÿ 	 ) ÿ 	).%'
 ý*'
 ÿþ	 ý	ý	734
 ÿ6ý-'
 ý	". ýØþ	62
 ÿ6ý"#0

 ÿý,:/".%'
 ý	 
>@'
 ý*
 ÿ%
 ÿý þý^B
,
34. ý

 ÿ ý 	+
 ÿ6
!


"'
 ý	 	)[
 ÿ
 ý&2' 
 ý- ý	"
= ý	6
 ÿ6'º ý<9*
 ÿº
 þý*. ý- ý-"
 þ	_
 þ	 ý
2ý#$[
 ýI
 þ ý- ÿ+ý-ý	& H0
 ý,ý)I^^^*
 ÿ º
 þ	º
 ý	
,. ý
 ýÿýý	73
ý8þ	 ý	

 ÿ)'
 ý	. ýýÿ 	 * ÿ 	-. 0


 ý-
 ÿ) ý ýþ	ý	)ý[ÿ!ý	
0ý

º ý	 ý-'
 ÿþ	 ý	ý	6. ý	'
 ý	.Hý-^ ^I"º ý	
 ý	# 

 ÿ
 
: þ
 ÿþýL4#;ý" ý37ýº ý
 ý	
 ÿý:/ ý '
 ýEþ	
 ý`
9 þ	º
 ýÿ.þ	 ý"I ^0
 ÿ"0
! =;
 ÿý þý.þ	 ý^3 ý	º
 þ	ý	
!-ý
'
 ý
= ý	_
 þ ý, ý&



#

#

#

#

# %
 #




#

#

#

#



#






õ

$#

#







ûÌ}Ð'ú#Ì}Ì}ûø ÷

8 ÿ*
'ý0. ý,ý	ýÿý	)}þ	
ºþ4[ý	!-#$ !
ÿ2ý	
ÿ#$þý[ýÿ0ºýÿ
ÿ*
ýºý #
"
=	
ÿ
ý"
ºþ	!-'ý	
ÿ-
ÿ-}ýÿ-
ý!ý"& H [ý	.=
!2}ý	-ý	
ý	!).ÿ"'ý##ý	5!*
ý	3ÿ)
ýþ	!þ	ý	ý
 ýÿ4
/º
 þ	!. 

 ÿ-0} þý#7'
 ý
 ÿ4#7º
 þ	º
 ý	3
 ÿý#7'
 ý;#$ =

ÿ)- ý
 ýÿþý-#
º ý[
 ýÿ

 ÿ"#
 ÿ!+*
 ÿ#;# 
ºþ,º
 þ	º
 ý	&*_
G ý
 ý ý	

 [
 ý	-Iþ	
 ÿ
 þ	 
 ÿ
 ÿ"
 ý

 ÿ#7ý0
` _<'
 ÿ} ýÿ

 ý!ý*3
 ÿ- ý
ý
º
 þ!C'
 ý"
 ÿý	6
 ý	C'
 ý;#$
 ÿþý-
 ÿC
` _<'
 ÿ%#$ý,
"
=

 ÿ<&68 ÿ%
 þ	
 ÿ=
º ý	q
 ý	5'
 ý
[
 ýÿ0. 
2 ÿ* ý0
 ÿ*
` _<'
 ÿ<3/. ý
 ý
 
: ý	2

 ÿ
 
: þ
 ÿ0

 ý[
 ýÿ 
 ÿ
ý, ý	. 2[
 ý ý0#$.0º
 þ	*ý,
"
=

 ÿ*. 0'
 ý;#$[
 ý	7&4_
G ý". ý	* ý ý
. ý ý

 ÿ
 
: þ ÿ
 ý[
 ýÿ4#$ ý	
 ýý ýþ	

 ý0 ý	. [
 ý ý	0> ý	
 ýÿ""ý
ý	,º
 þ	!+. 8
 ÿ
"
= ý	6#$0ý	 ý[
 ý ý	B	3[ÿ*

 ý[
 ýÿ0#$* ý	#
 =
ýþ	

 ý[
 ý ý	>@'
 ý	
ý- ÿ*
 ÿý ý	
ÿq
 þ	
 ÿ
 ý,
 ÿ)ý	
0



 ÿB	&_4
 ÿ!37. ý,. ý	
 ý,º ý ÿý	)º
 þ	!)
I
 ÿ 
 ÿ!2'
 ý	ý 
 ÿ-ý[ÿ
 ÿ=;'
 ý	ý"
 ÿ

ºþ-\8 ? º
 þ	q
! þ	3<
+'
 ý	ý" ÿ+ý:/
5 ý	]
 þ	º
 þý	- ý	%
 ÿ6ý*
ý ý& H ý	'
 ý"
 ÿý
ý0º
 þ

 ÿ*# ý	
 ÿ#$ þý[
 ýÿºý ÿ
 ÿ-. 
 ÿý08ý
º
 þ!*
"
= ý,!ý<
 


 ý,º
 þ	!2! ý þ	
 ÿ"-,"
 þ	
 ý ý þ	} þý0
 ÿØþ
 ÿ-'
 ýIý	5 ý	*. 

" ý


 ÿ[
 ý	&





N

'# u'}~'w`u''uw#w'

C^

 


pj·

CP

(I^
'ºý09?



 


I^^^
KMK
9MJ

:µl´lo'·







:p}p

^ 9I
^ 9J
^ P





:o

   



^ ^^
^ ^^
^ ^^







jµ:o

iRµ 0o



^ 
J P9
I ^PK
I II





mko'p





^ ^M
^ ^K
^ II










ý	#L)M,[%}þþ}þ	!&4G_ý0ýÿýý	+I^^^'ý	ý"
ÿ

ºþ
ºþ	
ºý	,ÿ"!&4_/

##ÿ"'ý*
 
Gý	
ý	2ý}þþ	
ÿ*ý
L)M,[34ÿ%
ý)ý	Cÿ+ý*ýþ	
ºý	[þ	ÿ
ýÿ. 
6
-
ÿ6ý*
ÿ
ÿ
ý}þ	2
ºþ	!2. ý8þ	ý	)-




/&' 
 ý`ÿ"'
 ý,# þ	
 ÿ
ýÿ, ýþ	
ºý	
ºý	6. 
+
ºþ	!&2' ý":<". 

#$,I^^^+
ºþ	
ºý	30ý*ýþ	ÿR. #$0
ºþ	
ºý	2-R"ºý*Pþ	ÿ
 =
ýÿ ýþ	º
 ý	37
 ÿ)ý,.(#$
ºþ	
ºý	",60ºý-I^`þ	ÿ
ýÿ
 ýþ	º
 ý	&)' 
 ý* ý	


!C# ý`ý
º
 þE
 ý	
ý-#)º
 þ	!%
 ÿþ ý ý	. 


 ÿþ ý
 ÿ
 ÿ"'
 ý#
# þ	
 ÿ
ýÿ, ýþ	º
 ý	&' 
 ý"
_
 þ	Ø
 ÿ+ ý	 ýÿý[þ	 =
 ý	

 ÿ þ	
 ý`
9 þ	º
 ýÿ-'ý	. ýýÿ6ý`ý
º
 þ0
 ÿ L)M,[ 
 ý	&6' 
 ý#$_þ	Ø
 ÿ
 ý	 ýÿ0ý,

ºþ7

 ÿ
 
: þ
 ÿþý#ý8þ	 ý	

 ÿYþ	
 ý`
9 þ	º
 ýÿ&0' 
 ý"
 ÿ) ý	

ý !ý	
4ý	 ý.0 ý	#<
 ý	 ý '
 ÿþ	 ý	ý	Ø
 þ
 ÿ"'
 ý '
 ÿ!
 ý ýþ	ý	7&_4
 ÿ!34ý,.`
 þ	Ø
 ÿ ý	 ýÿ,ý'
 ý-
 ÿ+
 ÿý þýý	
ÿ
#; ý,'
 ý	 
 ÿý :/0'ý	. ýýÿ-ý,., ý	 #4
 ý	&









üGý	
 ÿ#$ þý[
 ýÿºý ÿ
 ÿ*0'ýýÿ2
ºý	)"
ý,!ý"
ÿ2ý	
0./3 
}þ	"
 GRý#;1ý	
 .
ÿý	ý<ý	'ýþ	& J
ºýÿ'ÿ-ÿ*E<ÿ*>IJJMB
Yÿ
ý	0ý	
 ÿ#$ þý[
 ýÿ0ºý ÿ
 ÿ-
 ÿ)ÿ-
ºý[ýÿý	)!ý*3/ÿ2ýIý	5'ý
[ýÿ#E:ý	
ÿqý	0$&
>$]^^^B<

= ý	
"ý	" ý"'
 ý	$&G6} ý:
 ý	$&>IJJK,B  /[
 ý	!

"
7 
 ý	-
 ý ý3
 ÿ"ý	
ÿ" ý	
 ÿ#$ þý[
 ýÿºý ÿ
 ÿ". 

 ÿ"
º ý[
 ýÿý	-!ý . 

 ÿ ý&
G6} ý0
 ý	4$&/>IJJK:
B ý	5 ý
 ÿ



 ýº
 þ	º
 ý	 
 ÿº
 þ	º
 ý	#$7
 ÿ#$

 ÿ" ý	 ýÿ

 ÿ,
 ÿ"
} ýÿ

 ý!ýC#$} þþý	
 ÿG
 ý

 ý<ý
 ÿý&  . ý	
 ý<7. 
 ÿI
! ý	5 ý	
º
 þ	Ø
! þ	º
 þý	  *I 90ý	4
 ÿý 

 ý3.0º
 þ	Ø
 þ	
 ÿþý	
`
! þ	-
 ý0'
 ýýÿØý	5 ý	-. 

" ý


 ÿ[
 ý	">$ þ	 ý	2"ý:[
] þ	º
 þý,ý	 ý	5 ý	+
 ý ýB	&
G ý`
_
 ÿýº ý ÿý	)º
 þ	!2'
 ý

 ý,'
 ýþ	


 ÿ ý	*
 ÿ-?
A üOþ	
 ÿ:/'
 ýÿþý

ÿ¾þ	
 ÿ '
 ÿþ	

 ÿC. 
%ý,# ý ý	3
 ÿR+º
 ý	R
 ÿ



 ý+
 ÿ]
 þ	
 ÿ:<

 ÿ6'
 ýþ	


 ÿ
"-:
: ÿý,
 ÿ+ ÿ6 ý	
"./L4,
 þ	<34º ý ÿý	Cº
 þ	!6
Ø
 ÿ*ÿ/6º
 þ	!

ÿ ý	
ý	)
 ÿ)ý

 ý!ý 
ý ý&,_/E
 ý	5º ý3. ý,. ÿ,
 ý ý	º
 þ	ý	
ý8þ	º ý	52 ÿ2
 ÿý ý	
ÿ*} þ	 =; G6º
 þ	!). 
2 ý	'
 ýþ	0
 ÿ



 ý".0
 ýÿ2 ý
 ÿ#$  ÿ

ý&
H0!ý  ÿ
 ý	5'
 ý
[
 ýÿ"
 ý"'
 ý	'
 ÿ)2/ ý	[
 ý,#ý[þ	º ýÿ
 ý	"} ýÿ2
 =

 ý,!ý" ý	 ýÿ0-ý" ý	

 ÿ)ý	!*
 ÿ+º
 þ

 ÿ).
# üER> ý& /&3/
 ÿþ	
 ÿ2ý
þ	'
 ý	
ÿ8
 þ	
 ÿþý ÿ4#< ÿ6
 ý	5

 ÿ,. 
" ý0
 ý	5'
 ýº
 ýÿþý0
 ÿ 
: ý	'
 ý	
 ÿ
 ÿ,!ý*L
 ýý
 ÿ*ý"ý} þý"04
º ý
 ÿ2'
}
 ý *} ý,º ý ÿ
 ÿ*/*=ý`
9 þ	º
 ýÿ3/.0
º ý
 ý	
 ÿ
 ÿ-7
 ÿ#$


 ÿYÿýþý	!"#$'
 ýþ	


 ÿ=
 ÿB	
&  . ý	
 ý	3ý#
 þ	º ýÿ
 ý	, ý
 ÿ
-'
 ý"/ ý	 ý	7&_
G ý`
 ÿ0
'
 ý""
 ýÿý[
 ý	!-#$ ý	/
 þ	
 ÿ*ýý} þý,
, ÿ
 ýº ý0
= ý&_<ý" ý3
 ÿ4.,º ý ÿý	E
 L)M,[6"'
 ý	<
 'ý	 
 ÿ
5 =



 ÿ<3. ý-!)'
 ý-
 ÿ/
 þ	
 ÿ)ý-º ý # 
'
 ýÿ6ý",
4 ý

!6
 ÿ



N

Á'#u'Ewu''{
	Yu'¸w

ýºý ##þ	
ÿ*
}þ	
ÿ
ÿý}þ	2ý&0_/ 

ÿ. 
)
'ýÿ+ý"
º
 þ	ý [ H%L)M,[C"'ý	<
0#$ýÿ-"ý,
ý->$D}ý	
ÿ`ý	0$&3<IJJMB	&0ü0!3[4
ÿý<3<ÿ
' '
 ÿ*>$]^^^B7 ý#þ ýÿ8
! ý	5
 ÿ,.0
 ý	ý40[ H%L)M,
[ =;!º ý } þ	I
 þ
 ÿ,!º
 ý	2
 L)M,
[ =;
} ý
'
 ýý	
 ÿ2} ýÿ*

 ý"!ýH#$ 3.0
 ý ý,ý
 ý	)- ý ý	 ýÿ ý" ý,  

ÿýÿ

 ÿý ÿ*ý!ý<
  ý&



? ,#;ý*./34. ý*. 
66'ÿ'ýÿ%ý2#$ý[ýÿ
ÿý	Cý	-ÿ+ý2 ýþ	
ý
0
[ýý	3ý	5ýý,ýÿ
<
 GRýýÿþý"'ý	. ýýÿ-
"
=	
ÿ#$#ý	5'ý ý0ÿqÿ
ºþý	3
ýýEþ	º
 þý #<ý} þý  ÿ- ý	. ,#$7
ý0!ý"0>@.0
ºþ	"
ÿ"4[ý	 =
!"
 [
 ý	-"'
 ý0
 ýÿB	3
 ÿ ý	
ý0ý0 ý0#,º ý ÿý	* ý	. "#;'
 ÿþ	

 ÿ+>@G6} ý.
 ý	$&3
IJJKB	3 ÿY
 ý	5 ý,ý" ý#" ý
 ÿ#$

 ý8ÿ
 ÿ=;ý"
 ÿ ý	. &



ÊÐ

 ù

÷ ø

÷ ÍÌ

' 
 ý*,ÿ)_<ÿF
ÿ2#$,
ÿ
#ý5G7,
ÿ6
ºý[ýÿ
ÿ6`_<'ÿ<3GR
ºý	ÿ
\.þ	}ý3/\4ý0E:ý	
ÿ<3:ü0'ý*[4
ºý}þþ	
ÿ
$3ÿIL+=	
ÿqü
 #$ý	
0ýþ	'ÿ
ºþ4ý	<3

 
 þ	' ý%#$* ý`
 þ	[
 ýÿ*
 ÿR6/#$*#"
2'
 ý	3
 ÿ(M,
 Lþ	?0º ý	ý	I
3 ü0º
 þ	
Aÿ<3/\4ý :
E ý	
 ÿ2 ÿq
 ü0'
 ý[4º
 ý} þþ	
 ÿ
7#$ 
 ý	#;0
 þ	
 ÿ
 ý

 ÿ&

 
Ê



÷ ù#û

 

 0m

`om:o'pjµ



[s:o

Ê
õ

 Îû 



÷ ÍÏ

ö÷ ÌÍÎú#ÐÍûø ÷ Ì

Yo :o'p}·o¼ 8µj´}ok   r


Øo'´
R



omRnRo'p

`o'·´p}lRklRm

` _<'ÿ2
,ÿYý	5'ý
[ýÿ4}ýÿ2
ý"!ýO. 0!**}þþý	,/ý#


ÿ,
ÿ-`Eý	. ýý	!"
,ý	ºýÿýGþ	ÿý
ÿ<&
84". 
7'ý0}ý	Iþ<`_<'ÿ
2
 M
 GRý ýÿ

& 84*!",8
 ý} þ	"#
 ý`
9 þ	º
 ýÿ!*!Øþÿ<&4` ý !
. 
'
 ý-'
 ý
 ÿ)2-
 GRý ýÿ"ý

 ÿ)# 
` _<'
 ÿ+/
 ÿq
 ý} þ	+
 ÿý`þ$34
 ÿ+,`_<'
 ÿ
"
Eý	
 ýÿ*!-
0'
 ý
 . 

 ÿ2"
 ÿº ý
 ÿýIþ$&
8 ÿ
 þ	

 ÿ#$ þ
 ÿ*
` _<'
 ÿYþÿ*'ý#$'ÿ2 ý}þ	-þýÿ
/&[4ºýý,ý*
ý*
ÿþ	
ÿ-'ý#$ýYþ
ÿ/& HIÿ%ý-þþ
ÿ3!6!)ý	ÿ%ýÿ!+'ý%
ÿý
.0ýÿ*!Øþ$&' 
0
ÿ
ºþý	 7
ÿý	,ý,!&8@#4
0þþ3/ÿ-2ÿYþ7ý	&
?0/3/[E7\4?A\CM H1%
` H@
' 0A\%?1A[\4?D\.ü1[ %H`0\ &

? 0ý[ýÿ)# ý} þ	2/3/!*. 
'
 ý} ý	)-! CD/3 C=;D/3/2CD+3<
ÿ2'ý
-
'ý,#ýý	/}þ	-ÿ*!0ÿý[þ. 
2`_<'ÿ<&0[E7\4?A\RM HH`%H'@ ?`N 0[R'0\
[ %H`0\BJ\4_ HGü\C[.ü%H8$M,8;`NH'08;A*_\\4M J? ? D"&/? #$ý!2ÿ*2ý"ÿý3<ýý
. 
<"'
 ý0 # ý	.Rº
 ý# 
 ý	

 ÿ4#$!,,
 ÿ. ý	&\4ýÿ"
 #`_<'ÿý	-'ý#$ý !8þ	
þ	º ý	ý"ý,/3<[E7\4?A\C_8;`08;
A H
' 0\R
A Eü\ 8H
 ÿ
 þ	
 ÿ
ÿ
 ý"ýØÿý	50/
& HIÿþý
!+ ý":
: ÿ

 ý	%?E7EC# ý-3<ý ý-. 
 )'
 ý*
 ÿ)'ÿ
!)#$!)2
'
 ý
#;ý þ	[
 ýÿ&
8@#<!"ý ÿ!"ºý"/
ÿ,ýEý	5'ý
[ýÿ3þ/M
ÿý04J 
 9*= 9M^*=K9I,:/3	4A
ÿ'ý
 0J 9*= 9M*^ =IP:/&
' ÿ!#$
ºþ	

ÿ*
ÿ*
Eý	5'ý
[ýÿ*>

N*O

'# u'}~'w`u''uw#w'

#j·¿]iR´}om:jp}l:·
84Cý M)6!6
ÿC
`ý	5'ý
[ýÿ&B84%R6ÿý26-+
[ý3
ÿCý
ý	þ
'ý	)'ý	&? #$ý!"::ÿ
qý}þ	-ÿ2ý
'ý	2!#ýý	/}þ	/3/ÿ*ý

 ÿý"
 ÿ-:
: ÿ
*ýý	!"#$/& HIÿþý,!-ý0::ÿ
ý	2?E7E+#ý3ºýý

'
 ý" ÿ!:
: ÿR
 þ	[
 ýÿ&

? 
ºþ	*ýý!*'*I
? 
ºþ	*ýý!*']
? 
ºþ	*ýý!*'29
? 
ºþ	*ýý!*'0:
? 
ºþ	*ýý!*'P
? 
ºþ	*ýý!*'2M
? 
ºþ	*ýý-
'ý::ÿRþ	[ýÿ

   Î



÷ Ð Ì

J#ýý3M&[&3FC'


3/&`,&>IJJMB	&#S.)UZ&/QV"W@X)U56)QV"V"W(&.6&? ýÿ Aþ	
ºýÿ
 :þ&
J
ºýÿ'ÿ<3<?"&/G1&3/FHE<ÿ/3<[&L%&4>IJJMB	&' ý8þ	

ÿ2#[ý	ý	 
 ÿ2'ýýþ	=;
ºþ	

ÿý}þ	
ý"!ý"&,8ÿ) UX5#5#5W(&.6
+ U T(-.#		
E5&/T#*)5&/QT$W@U&/QY
<ZV U+	W@SV U&FU!#*&
W@QYU56 S.# 3/<&/J <I^^&



? = ? $3*/&3F J.Gÿ<3,L%&D"&>IJJ B	&'}þ	
ÿ0
ÿ


ý
ÿIþ	
ý
ý
ÿý}þ5=

ÿ&8ÿ)UX5#5#5W(&.6+U T(-.#T(- &&/SQY! #5#T$W(&.6U T(-.#+5+	UXW@QT$W@U& 	U)UV <ST$QT$W@U&/QY
/ W(&.6 SW"	+ T$W@X,	+ 3<&/]M ]] ^&
4







? 
ý	3'ü"&3FJ/3?"&>IJJMB	&8;
ÿØý	ºý	0'ý;#$ÿþý,
ÿ*ý	
ÿ#$þý[ýÿ ºýÿ=

ÿ/&8ÿ) UX5#5#5W(&.6
+ % 
 3/<&7I^I <I^]9 &
M,ÿ
ºý	
$3L%&37FONGý
ÿ/3\ &>IJJPB	&Lý	
ºþ	0#$Gý	
ÿ)
ýý	
ºý	
ÿ6-}ýÿ
 ÿ ý,!ý*&08 ÿ)UX5#5#5W(&.6+U T(-.#		E%%% )W(&.6E<ZV U+	W@SV U&V <W()W@XQY
#(T -*U +,(W &"W +	XU.S )+,# 5&/T #*) ) #T$QT$W@U &)Q &#*&#*)QT$W@U &/3/<& 9: 9J&











Lþü0!37A<& >IJJKB	&-A'ýþ	

ý ? 
ÿ"'ý	"#0"
5ý	.=;
ÿ


ý

ÿý}þ	
ÿ+>$,IB	&
+,#*) )U*#YW(&.6-Q&
+,#*) %Q <T#525&/T#*)QXT$W@U&/34>9*= :B	&

0ºý	3A<&3F







Lþü0!37A<& >IJJJB	&-A'ýþ	

ý ? 
ÿ"'ý	"#0"
5ý	.=;
ÿ


ý

ÿý}þ	
ÿ+>$0]B	&
+,#*) )U*#YW(&.6-Q&
+,#*) %Q <T#525&/T#*)QXT$W@U&/3 	>I5=]B	&

0ºý	3A<&3F







}þ	/3.L%&3_/ý	3/& ? &3F1Aýÿ
 #$73_ &G1&<>IJJ]B	&<8ÿý	
ýÿ0
ý	 
ÿ-ý	ý	ºý5=
ÿýý
ºþý	&8ÿ 5/
& T#*)5/& QT$W@U/& QY!U& ,#*) #*&/X5#U&<U!#*&</7Q&.6SQ*6#")UX5#,+5+	W(&.6  /!3
<& 
 IP 
 IK&

	



NN

Á'#u'Ewu''{
	Yu'¸w

D}ý	
ÿ/3E4&[&3E<
ÿ<3L%&E4&3F L)ý3?"&G1&>IJJMB	&}üGý	
ÿ#$þý[ýÿ4ºýÿ
ÿ?%ý	!&
U.
S )5&/QY7U %)T$W $XW@Q
Y 5&/T #Y@Y4W 6#*&/X5##,+,#Q)X,-33/]9 ]KP&



D*3 ? &">IJJPB	&  ý)
ÿý;#;}þý	2#$2
ºþý%
ºþ
ÿ& 8ÿ6ü0ý3,M&30F GR
ÿ<30/&
>$\4& B	3/UW@X5#UV"V"S.&/W@XQT$W@U& 1#T' #5#*&SV"Q&+Q& )QX,-W(&#,+	3<&:]].::]&`0
ÿ
? þ'
G
 ý,!*[ ý	&

(

D*3 ? &3E<
ÿ<3M&3FCG6}ý	3L%&	?"&>IJJKB	&_<6ÿ
ºþýGý	5'ý*' 
 ý ý5GRýþ	#/
 =
4ÿ,ý0ý	5'ý
ý . 
"}ýÿ,
ý !ý"&8ÿ)UX5#5#5W(&.6+U (T -.#5&/T#*)5&/QT$W@U&/QY
U & ,#*) #*&/5X #U &I U !#*&</7Q&.6SQ*6#")UX5#,+5+	W(&.6  /!	&

	









E:ý	
ÿ<37\ &3/F [4
ºý}þþ	
ÿ
$3Rü"&>IJJPB	& ? ÿ3/ý[ÿý	50ýÿý
ÿ<&08ÿ)UX74U 		2
 U !#*&</7Q&.6SQ*6# <Z*+	T#V +#X,-.&/UYU56Z *U)!*+5-U S+	T$W(&	# Q+	&







&



E:ý	
ÿ<3\ &3[4
ºý}þþ	
ÿ
$3Gü"&3F \.þ	}ý3G1&0>$]^^^B	&C? þ	
ºþ)"'ý	0#,ÿC}þ	
ÿý

 ÿý}þ	
ÿ)#$,ºýÿ
ÿ6
+ý	
ºý	&   
)Q&+	QXT$W@U&+U&  #5#X,-)Q& S.W@U
 )U5X #,+5+	(W &.63 37II ] 9&




E:ý	
ÿ<3\ &3[4
ºý}þþ	
ÿ
$3#ü"&37\.þ	}ý37G1&37_<
=	
/3N"&7M&3FO`0!ÿÿ<37A<&>IJJJB	&A}ýÿ
ÿý
ý_< ý	!--}þ	
ºþý& 8ÿ)UX7   *U)!*+5-U %U&<ST$UV"QT$W@X
 #5#,X -2#X5U 6&/W@T$W@U &*Q &&#*)+	T$Q&W(&.6  		&









E<
ÿ<3<M&/&3<F [4ÿ<3/A<&4>$]^^^B	& [ý	
ºþ	
ÿ2ÿ+/
ÿ-* 'ýýþ	)ýþ	ÿ

ÿ2
ÿ)
} ýÿ"
ý !ý*&<8ÿ)UX7/U 0T(-.#%#*3*#*&/T#5#*&/T(-"QT$W@U&/QYU& ,#*) #*&/X5# U&2)T$W $XW@QY
5&/T #Y@Y4W 6#*&/5X # %% &







	

E<
ÿ<3M&./&3[4ÿ<3A<&3F G6}ý	3.L%&?"&7>IJJKB	&7\4
ÿØüGý	ÿý,Aý	
ºý	
ÿ*,G_ý=
J ý	2A} ýÿ*M
ý,?0ýÿ&48ÿ)UX5#5#5W(&.6+0U -W()T$Z2<W T(-2&&/SQY #5#T$W(&.6U "T(-.#
+5+	UXW@QT$W@U &2U UV <ST$QT$W@U &/Q

Y /4(W &.6S"W +	T$W@,X +	3<& K^ K &









&

E<
ÿ<3M&./&3G6}ý	3.L%&?"&3F1DGýÿ3.L%&/&7>IJJJB	&<?
ºþ 'ý	ýþ	
ÿ-#4'ýýþ	
 ýþ	

 ÿ


 ÿý

 ý º ý	 ý	$&78 ÿ
 )U5X #5#5W(&.6+U 0(T -.#-(W )T$Z%#*3*#*&/T(-&&/SQY #5#T$W(&.6
U ,(T -.# +5+	UXW@QT$W@U &2U UV <ST$QT$W@
U &/Q

Y /4(W &.6S"W +	T$W@,X +	3<
& 9^J
 9*I M&









!

` 

"
$3 "
8 &3FOD0!
$&3
8"&>IJJMB	&"?  
þ	ÿ4ý	!)ý	+ÿ)ý*ý	


!6#
'
 ýýþ	*ýþ	ÿ

ÿ<&48ÿ)UX7<U ,T(-.# 5 &/T#*)5&/QT$W@U&/QY<ZV U+	W@SV U&< U!#*&W@QYU56S.#3<&
IP <*I M^&



ü0!3`,&3[4
ÿý<3./&3F







' '
 ÿ<3A<&<>$]^^^B	&/A}ýÿ
ÿý[ýÿ#$&/8ÿ)UX5#5#5
W(&.6+U ,T(-.#	T(-E&&/SQY #5#T$W(&.6U "T(-.#+5+	UXW@QT$W@U& 	U)UV <ST$QT$W@U&/QY
/4W(&.6SW"+	T$W@X,+	&









Aÿ'ýÿ<3?"&3A*3 /&34'ýÿ H03\ &3 Jý	3E4&3F ? ý[ý34?"& >IJJKB	&+\4
ÿ6#
ý2/þ	
 ÿC
[
 ý	ºý)
ÿ#$
ÿ%!ý 'ý	ý	'ý	 
ÿCý2?Gü8;A\O ýþ	&(8ÿ
5&/T #*)QXT$(W 3*#/UW@5X ##,X -.&/UY5U 6Z 	U )#4Y #XUV"V".S &/W@XQT$W@U&+% <YW@XQT$W@U&+ ,3/<&JI 
J M&





A
ÿ<3A<&3<DGýÿ3L%&<A<&37E<
ÿ<3<M&/&37FHG6}ý	3L%&/?"&>IJJJB	&
#$} ýÿ*

 ý,!ý"&48 ÿ
 )UX 7 %  		&

N







üGý	
ÿ#$þý[ýÿºýÿ
ÿ

'# u'}~'w`u''uw#w'

A"
<3}ü"&G1&>IJJKB	&?Iÿ8ý	
ÿ,#/ý	
ºý	7#$7ý	ºýþ	
ý	!"ý
 #$!
ÿ,ýÿþý[ýÿ
ÿ

 ÿ}
 ýÿ8ÿ ÿ ý
/
& 5&/T #*)5&/QT$W@
U &/QY U.
S )5&/QYU SV"
Q & UV <ST #*)<T$.
S W(#,+	3
 
3 M] 
 M: &









A3'ü"&3F 0
H 
ý3/&>IJJPB	&4?Iÿ2}þ	-ý	5 =;=;'ýýþ	*!'ÿý	
&8ÿ2D0ºý	
 ÿ<37G1&J0&3
F1[4
. $ 3/D"&<D"&>$\4& B	3 #5#X,-U*W(&.6Q&2<Z&/T(-.#,+	W"+	3<&MII M99&\4ý	
ºý	&



	

Aÿ<3'ü"&A<&3/FJ/3?"&<N"&7>IJJKB	& #W(& 	U)X5#V0#*&/T/
#Q)5&/W(&.6&
L+8;'([ý	&
'Rý	/3N"&/&>IJJPB	&'Rý
 GRýýÿþý-ºýÿ
ÿ)ÿ).=;"ÿ<&UV"V"S.&/W@XQT$W@U&+"U
(T -.# )33/PK MK&



G6}ý	3*L%&	?"&>$]^^^B	&	?Iÿ,
ºþ
ÿ,#/ý	
ÿ#$þý[ýÿºýÿ
ÿ 
ýý	!0ý	ºýþ	
ÿ

 ÿ*,}
 ýÿ-

 ý,!ý1#$#
 ý
$
& U.
S )5&/QY7U %)T$W $XW@QY5&/T#Y@YW46#*&/X5#%#,+,#Q)X,-3 3
9K . :/*I M&



G6}ý	3L%&?"&3_<[ý	3./& ? & 3FH`0!ÿÿ<3A<&>IJJKB	&E:ýÿ
ÿ*
<
ý"ý5=
º
 ý	* B
? þ ý!)# - }ýÿ)
ý*ýÿ0#$Gý
$&*8ÿ)UX5#5#5W(&.6+"U T(-.#
T(&&/SQY #5#T$(W &.6U "(T -.# 5+ +	UXW@QT$W@U&2U UV <ST$QT$W@U&/QY
/4W(&.6SW"+	T$W@X,+  /. / 	3
<&7*I 9:P<*I 9P]&











G6}ý	3 L%&?"&3E<
ÿ<34M&/&3D*3 ? &?"&3F ?'ý	3?"& > IJJKB	&)\4
ÿ6}ýÿ

ý,ýÿ. 
*[/?Gü0?0M,8;A\'.[þý0
ºý	&UV <ST#*)% #5#X,-Q&0/7Q&.6SQ*6#3
 4> 9B	&





G6}ý	3L%&3Rü".,3H"&34Fcü0
$3
L%&>$]^^IB	&*A*,?O
ÿºý-ýÿýÿþý*ÿ'ÿý	&)8ÿ
 )U5X #5#5W(&.6+*U +(T -.#U)(T - 0

V #*)W@X
Q &
#5#T$(W &.6%U +(T -.# +5+	UXW@QT$W@U & 	U )UV <ST$QT$W@U &/QY
/4(W &.6S"W +	T$W@,X +	&









G6}ý	3L%&?"&3F G(
}ý	3A<&>IJJ^B	&
L)
5ý	*
ÿ


ý"
ÿ*
ý4?Iÿ*
ÿý	

ÿ-
ÿ

 þ	 ý, ý	[ýÿ
ÿ<&48ÿ)UX7 T(-E&&/SQY #5#T$W(&.6U ,T(-.#  /43<& ^ J&



84'ÿ/3A<&
/&@>$]^^^B	&,[

ºþELý	,
ÿ6A}ýÿ)M
ý-A!ý"&&8ÿ -W@YU+	U  -W@XQY
) Q&	+ QXT$W@U&0
+ U ,T(-.#0
 UZQY<
 UXW(# T$Z#*) W(#,+   
	 3<<&7I*9 KJ<I,: ^]&





	

G6
ÿ3 ? &/&/>IJKJB	& )U*#Y + U #YQZ#5 #W(& 	U)X5#V0#*&/T/
#Q)5&/W(&.6&[<& M&ý	
3 ? "
ý
Gÿ
ý
!<&

N



Journal of Artificial Intelligence Research 16 (2002) 209-257

Submitted 5/01; published 4/02

Structured Knowledge Representation for Image Retrieval
Eugenio Di Sciascio
Francesco M. Donini
Marina Mongiello

disciascio@poliba.it
donini@poliba.it
mongiello@poliba.it

Dipartimento di Elettrotecnica ed Elettronica, Politecnico di Bari
Via Re David, 200 – 70125 BARI Italy

Abstract
We propose a structured approach to the problem of retrieval of images by content and
present a description logic that has been devised for the semantic indexing and retrieval of
images containing complex objects.
As other approaches do, we start from low-level features extracted with image analysis
to detect and characterize regions in an image. However, in contrast with feature-based approaches, we provide a syntax to describe segmented regions as basic objects and complex
objects as compositions of basic ones. Then we introduce a companion extensional semantics for defining reasoning services, such as retrieval, classification, and subsumption. These
services can be used for both exact and approximate matching, using similarity measures.
Using our logical approach as a formal specification, we implemented a complete clientserver image retrieval system, which allows a user to pose both queries by sketch and queries
by example. A set of experiments has been carried out on a testbed of images to assess the
retrieval capabilities of the system in comparison with expert users ranking. Results are
presented adopting a well-established measure of quality borrowed from textual information
retrieval.

1. Introduction
Image retrieval is the problem of selecting, from a repository of images, those images fulfilling to the maximum extent some criterion specified by an end user. In this paper, we
concentrate on content-based image retrieval, in which criteria express properties of the
appearance of the image itself, i.e., on its pictorial characteristics.
Most of the research in this field has till now concentrated in devising suitable techniques
for extracting relevant cues with the aid of image analysis algorithms. Current systems result
effective when the specified properties are so-called low-level characteristics, such as color
distribution, or texture. For example, systems such as IBM’s QBIC1 can easily retrieve,
among others, stamps containing the picture of a brown horse in a green field, when asked
to retrieve images of stamps with brown central area over a greenish background.
Nevertheless, present systems fail at treating correctly high-level characteristics of an
image — such as, “retrieve stamps with a galloping horse”. First of all, most systems cannot
even allow the user to specify such queries, because they lack a language for expressing highlevel features. Usually, this is overcome with the help of examples: “retrieve images similar
to this one”. However, examples are quite ambiguous to interpret: which are the features
1. See e.g., http://wwwqbic.almaden.ibm.com/cgi-bin/stamps-demo
c
°2002
AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

Di Sciascio, Donini & Mongiello

in the example that should appear in retrieved images? This ambiguity produces a lot of
“false positives”, as any one can experience.
Even if relevant features are pointed out in the example, the system cannot tell whether
what is pointed out is the color distribution, or its interpretation — after all, a galloping
brown horse produces a color distribution which is more similar to a running brown fox than
to a galloping white horse. In this aspect, image retrieval faces the same problems of object
recognition, which is a central problem in robotics and artificial vision. The only effective
solution overcoming this problem is to associate to a query some significant keywords, which
should match keywords attached in some way to images in the repository. Here ambiguities
in image understanding are just transferred to text understanding, as now a brown portrait
of Crazy Horse — the famous Indian chief — could be considered relevant.
Resorting to human experts to specify the expected output of a retrieval algorithm can,
in our opinion, only worsen these ambiguities, since it makes the correctness of an approach
to depend from a subjective perception of what an image retrieval system should do. What
is needed is a formal, high-level specification of the image retrieval task. This need motivates
the research we report here.
1.1 Contributions of the Paper
We approach the problem of image retrieval from a knowledge representation perspective,
and in particular, we refer to a framework already successfully applied by Woods and
Schmolze (1992) to conceptual modeling and semantic data models in databases (Calvanese,
Lenzerini, & Nardi, 1998). We consider image retrieval as a knowledge representation
problem, in which we can distinguish the following aspects:
Interface: the user is given a simple visual language to specify (by sketch or by example)
a geometric composition of basic shapes, which we call description. The composite shape
description intuitively stands for a set of images (all containing the given shapes in their
relative positions); it can be used either as a query, or as an index for a relevant class of
images, to be given some meaningful name.
Syntax and semantics: the system has an internal syntax to represent the user’s
queries and descriptions, and the syntax is given an extensional semantics in terms of sets
of retrievable images. In contrast with existing image retrieval systems, our semantics is
compositional, in the sense that adding details to the sketch may only restrict the set of
retrievable images. Syntax and semantics constitute a Semantic Data Model, in which the
relative position, orientation and size of each shape component are given an explicit notation through a geometric transformation. The extensional semantics allows us to define
a hierarchy of composite shape descriptions, based on set containment between interpretations of descriptions. Coherently, the recognition of a shape description in an image is
defined as an interpretation satisfying the description.
Algorithms and complexity: based on the semantics, we prove that subsumption
between descriptions can be carried out in terms of recognition. Then we devise exact and
approximate algorithms for composite shapes recognition in an image, which are correct with
respect to the semantics. Ideally, if the computational complexity of the problem of retrieval
was known, the algorithms should also be optimal with reference to the computational
complexity of the problems. Presently, we solved the problem for exact retrieval, and
210

Structured Knowledge Representation for Image Retrieval

propose an algorithm for approximate retrieval which, although probably non-optimal, is
correct.
Experiments: while the study of the complexity of the problem is ongoing, the syntax,
semantics, and sub-optimal algorithms obtained so far are already sufficient to provide the
formal specification of a prototype system for the experimental verification of our approach.
The prototype has been used to carry out a set of experiments on a test database of images,
which allowed us to verify the effectiveness of the proposed approach in comparison with
expert users ranking.
We believe that a knowledge representation approach brings several benefits to research
in image retrieval. First of all, it separates the problem of finding an intuitive semantics for
query languages in image retrieval from the problem of implementing a correct algorithm
for a given semantics. Secondly, once the problem of image retrieval is semantically formalized, results and techniques from Computational Geometry can be exploited in assessing
the computational complexity of the formalized retrieval problem, and in devising efficient
algorithms, mostly for the approximate image retrieval problem. This is very much in the
same spirit as finite model theory has been used in the study of complexity of query answering for relational databases (Chandra & Harel, 1980). Third, our language borrows from
object modeling in Computer Graphics the hierarchical organization of classes of images
(Foley, van Dam, Feiner, & Hughes, 1996). This, in addition to an interpretation of composite shapes which one can immediately visualize, opens our logical approach to retrieval of
images of 3D-objects constructed in a geometric language (Paquet & Rioux, 1998), which is
still to be explored. Fourth, our logical formalization, although simple, allows for extensions
which are natural in logic, such as disjunction (OR) of components. Although alternative
components of a complex shape are difficult to be shown in a sketch, they could be used
to specify moving (i.e., non-rigid) parts of a composite shape. This exemplifies how our
logical approach can shed light to extensions of our syntax suitable for, e.g., video sequence
retrieval.
1.2 Outline of the Paper
The rest of the paper is organized as follows. In the next section, we review related work
on image retrieval. In Section 3 we describe our formal language, first its syntax, then its
semantics, and we start proving some basic properties. In the following section, we analyze
the reasoning problems and the semantic relations among them, and we devise algorithms
that can solve them. Then in Section 5 we illustrate the architecture of our system and
propose some examples pointing out distinguishing aspects of our approach. In Section 6
we present a set of experiments to assess retrieval capabilities of the system. Last section
draws the conclusions and proposes directions for future work.

2. Related Work
Content-Based Image Retrieval (CBIR) has recently become a widely investigated research
area. Several systems and approaches have been proposed; here we briefly report on some
significant examples and categorize them in three main research directions.
211

Di Sciascio, Donini & Mongiello

2.1 Feature-based Approaches
Largest part of research on CBIR has focused on low-level features such as color, texture,
shape, which can be extracted using image processing algorithms and used to characterize
an image in some feature space for subsequent indexing and similarity retrieval. In this
way the problem of retrieving images with homogeneous content is substituted with the
problem of retrieving images visually close to a target one (Hirata & Kato, 1992; Niblak
et al., 1993; Picard & Kabir, 1993; Jacobs, Finkelstein, & Salesin, 1995; Flickner et al.,
1995; Bach, Fuller, Gupta, Hampapur, Horowitz, Humphrey, Jain, & Shu, 1996; Celentano
& Di Sciascio, 1998; Cox, Miller, Minka, & Papathomas, 2000; Gevers & Smeulders, 2000).
Among the various projects, particularly interesting is the QBIC system (Niblak et al.,
1993; Flickner et al., 1995), often cited as the ancestor of all other CBIR systems, which
allows queries to be performed on shape, texture, color, by example and by sketch using as
target media both images and shots within videos. The system is currently embedded as a
tool in a commercial product, Ultimedia Manager. Later versions have introduced an
automated foreground/background segmentation scheme. Here the indexing of an image is
made on the principal shape, with the aid of some heuristics. This is an evident limitation:
most images do not have a main shape, and objects are often composed of various parts.
Other researchers, rather than concentrating on a main shape, which is typically assumed located in the central part of the picture, have proposed to index regions in images;
so that the focus is not on retrieval of similar images, but of similar regions within an
image. Examples of this idea are VisualSeek (Smith & Chang, 1996), NETRA (Ma
& Manjunath, 1997) and Blobworld (Carson, Thomas, Belongie, Hellerstein, & Malik,
1999). The problem is that although all these systems index regions, they lack of a higher
level description of images. Hence, they are not able to describe — and hence query for —
more than a single region at a time in an image.
In order to improve retrieval performances, much attention has been paid in recent
years to relevance feedback. Relevance feedback is the mechanism, widely used in textual
information systems, which allows improving retrieval effectiveness by incorporating the
user in the query-retrieval loop. Depending on the initial query the system retrieves a set
of documents that the user can mark either as relevant or irrelevant. The system, based on
the user preferences, refines the initial query retrieving a new set of documents that should
be closer to the user’s information need.
This issue is particularly relevant in feature-based approaches, as on one hand, the user
lacks of a language to express in a powerful way her information need, but on the other
hand, deciding whether an image is relevant or not takes just a glance. Examples of systems
using relevance feedback include MARS (Rui, Huang, & Mehrotra, 1997), DrawSearch
(Di Sciascio & Mongiello, 1999) and PicHunter (Cox et al., 2000).
2.2 Approaches Based on Spatial Constraints
This type of approach to the problem of image retrieval concentrates on finding the similarity of images in terms of spatial relations among objects in them. Usually the emphasis
is only on relative positions of objects, which are considered as ”symbolic images” or icons,
identified with a single point in the 2D-space. Information on the content and visual appearance of images are normally neglected.
212

Structured Knowledge Representation for Image Retrieval

Chang, Shi, and Yan (1983) present the modeling of this type of images in terms of
2D-strings, each of the strings accounting for the position of icons along one of the two
planar dimensions. In this approach retrieval of images basically reverts to simpler string
matching.
Gudivada and Raghavan (1995) consider the objects in a symbolic image associated
with vertexes in a weighted graph. Edges — i.e., lines connecting the centroids of a pair of
objects — represent the spatial relationships among the objects and are associated with a
weight depending on their slope. The symbolic image is represented as an edge list. Given
the edge lists of a query and a database image, a similarity function computes the degree of
closeness between the two lists as a measure of the matching between the two spatial-graphs.
The similarity measure depends on the number of edges and on the comparison between
the orientation and slope of edges in the two spatial-graphs. The algorithm is robust with
respect to scale and translation variants in the sense that it assigns the highest similarity to
an image that is a scale or translation variant of the query image. An extended algorithm
includes also rotational variants of the original images.
More recent papers on the topic include those by Gudivada (1998) and by El-Kwae
and Kabuka (1999), which basically propose extensions of the strings approach for efficient
retrieval of subsets of icons. Gudivada (1998) defines θR-strings, a logical representation of
an image. Such representation also provides a geometry-based approach to iconic indexing
based on spatial relationships between the iconic objects in an image individuated by their
centroid coordinates. Translation, rotation and scale variant images and the variants generated by an arbitrary composition of these three geometric transformations are considered.
The approach does not deal with object shapes, nor with other basic image features, and
considers only the sequence of the names of the objects. The concatenation of the objects is
based on the euclidean distance of the domain objects in the image starting from a reference
point. The similarity between a database and a query image is obtained through a spatial
similarity algorithm that measures the degree of similarity between a query and a database
image by comparing the similarity between their θR-strings. The algorithm recognizes rotation, scale and translation variants of the image and also subimages, as subsets of the
domain objects. A constraint limiting the practical use of this approach is the assumption
that an image can contain at most one instance of each icon or object.
El-Kwae and Kabuka (1999) propose a further extension of the spatial-graph approach,
which includes both the topological and directional constraints. The topological extension of
the objects can be obviously useful in determining further differences between images that
might be considered similar by a directional algorithm that considers only the locations
of objects in term of their centroids. The similarity algorithm they propose extends the
graph-matching one previously described by Gudivada and Raghavan (1995). The similarity
between two images is based on three factors: the number of common objects, the directional
and topological spatial constraint between the objects. The similarity measure includes the
number of objects, the number of common objects and a function that determines the
topological difference between corresponding objects pairs in the query and in the database
image. The algorithm retains the properties of the original approach, including its invariance
to scaling, rotation and translation and is also able to recognize multiple rotation variants.
213

Di Sciascio, Donini & Mongiello

2.3 Logic-based and Structured Approaches
With reference to previous work on Vision in Artificial Intelligence, the use of structural
descriptions of objects for the recognition of their images can be dated back to Minsky’s
frames, and some work by Brooks (1981). The idea is to associate parts of an object (and
generally of a scene) to the regions an image can be segmented into. The hierarchical
organization of knowledge to be used in the recognition of an object was first proposed by
Marr (1982). Reiter and Mackworth (1989) proposed a formalism to reason about maps as
sketched diagrams. In their approach, the possible relative positions of lines are fixed and
highly qualitative (touching, intersecting).
Structured descriptions of three-dimensional images are already present in languages
for virtual reality like VRML (Hartman & Wernecke, 1996) or hierarchical object modeling. However, the semantics of such languages is operational, and no effort is made to
automatically classify objects with respect to the structure of their appearance.
Meghini, Sebastiani, and Straccia (2001) proposed a formalism integrating Description
Logics and image and text retrieval, while Haarslev, Lutz, and Möeller (1998) integrate
Description Logics with spatial reasoning. Further extensions of the approach are described
by Moeller, Neumann, and Wessel (1999). Both proposals build on the clean integration of
Description Logics and concrete domains of Baader and Hanschke (1991). However, neither
of the formalisms can be used to build complex shapes by nesting more simple shapes.
Moreover, the proposal by Haarslev et al. (1998) is based on the logic of spatial relations
named RCC8, which is enough for specifying meaningful relations in a map, but it is too
qualitative to specify the relative sizes and positions of regions in a complex shape.
Also for Hacid and Rigotti (1999) description logics and concrete domains are at the
basis of a logical framework for image databases aimed at reasoning on query containment.
Unfortunately, the proposed formalism cannot consider geometric transformations neither
determine specific arrangements of shapes.
More similar to our approach is the proposal by Ardizzone, Chella, and Gaglio (1997),
where parts of a complex shape are described with a description logic. However, the composition of shapes does not consider their positions, hence reasoning cannot take positions
into account.
Relative position of parts of a complex shape can be expressed in a constraint relational
calculus in the work by Bertino and Catania (1998). However, reasoning about queries
(containment and emptiness) is not considered in this approach. Aiello (2001) proposes a
multi-modal logic, which provides a formalism for expressing topological properties and for
defining a distance measure among patterns.
Spatial relation between parts of medical tomographic images are considered by Tagare,
Vos, Jaffe, and Duncan (1995). There, medical images are formed by the intersection of the
image plane and an object. As the image plane changes, different parts of the object are
considered. Besides, a metric for arrangements is formulated by expressing arrangements
in terms of the Voronoi diagram of the parts. The approach is limited to medical image
databases and does not provide geometrical constraints.
Compositions of parts of an image are considered in the work by Sanfeliu and Fu
(1983) for character recognition. However, in recognizing characters, line compositions
are “closed”, in the sense that one looks for the specified lines, and no more. Instead in our
214

Structured Knowledge Representation for Image Retrieval

framework, the shape “F” composed by three lines, is subsumed by the shape “Γ” — something unacceptable in recognizing characters. Apart from the different task, this approach
does not make use of an extensional semantics for composite shapes, hence no reasoning is
possible.
A logic-based multimedia retrieval system was proposed by Fuhr, Gövert, and Rölleke
(1998); the method, based on an object-oriented logic, supports aggregated objects but it
is oriented towards a high-level semantic indexing, which neglects low-level features that
characterize images and parts of them.
In the field of computation theories of recognition, we mention two approaches that have
some resemblance to our own: Biederman’s structural decomposition and geometric constraints proposed by Ullman, both described by Edelmann (1999). Unfortunately, neither of
them appears suitable for realistic image retrieval: the structural decomposition approach
does not consider geometric constraints between shapes, while the approach based on geometric constraints does not consider the possibility of defining structural decomposition of
shapes, hence reasoning on them.
Starting with the reasonable assumption that the recognition of an object in a scene
can be eased by previous knowledge on the context, in the work by Pirri and Finzi (1999),
the recognition task, or the interpretation of an image, takes advantage of the information
a cognitive agent has about the environment, and by the representation of these data in a
high-level formalism.

3. Syntax and Semantics
In this section we present the formalism dealing with the definition of composite shape descriptions, their semantics, and some properties that distinguish our approach from previous
ones.
We remark that our formalism deals with image features, like shape, color, texture, but
is independent of the way features are extracted from actual images. For the interested
reader, the algorithms we used to compute image features in our implementation of the
formalism are presented in the Appendix.
3.1 Syntax
Our main syntactic objects are basic shapes, position of shapes, composite shape descriptions, and transformations. We also take into account the other features that typically
determine the visual appearance of an image, namely color and texture.
Basic shapes are denoted with the letter B, and have an edge contour e(B) characterizing
them. We assume that e(B) is described as a single, closed 2D-curve in a space whose origin
coincides with the centroid of B. Examples of basic shapes can be circle, rectangle, with
the contours e(circle) = °, e(rectangle) =
, but also any complete, rough contour
— e.g., the one of a ship — is a basic shape. To make our language compositional, we
consider only the external contour of a region. For example, if a region is contained in
another, as in ° , the contour of the outer region is just the external rectangle.
The possible transformations are the simple ones that are present in any drawing tool:
rotation (around the centroid of the shape), scaling and translation. We globally denote a
215

Di Sciascio, Donini & Mongiello

Figure 1: The graphical interface with a query by sketch.
rotation-translation-scaling transformation as τ . Recall that transformations can be composed in sequences τ1 ◦ . . . ◦τn , and they form a mathematical group.
The basic building block of our syntax is a basic shape component hc, t, τ, Bi, which
represents a region with color c, texture t, and edge contour τ (e(B)). With τ (e(B)) we
denote the pointwise transformation τ of the whole contour of B. For example, τ could
specify to place the contour e(B) in the upper left corner of the image, scaled by 1/2 and
rotated 45 degrees clockwise.
Composite shape descriptions are conjunctions of basic shape components — each one
with its own color and texture — denoted as
C = hc1 , t1 , τ1 , B1 i u · · · u hcn , tn , τn , Bn i
We do not expect end users of our system to actually define composite shapes with this
syntax; this is just the internal representation of a composite shape. The system can
maintain it while the user draws — with the help of a graphic tool — the complex shape by
dragging, rotating and scaling basic shapes chosen either from a palette, or from existing
images (see Figure 1).
For example, the composite shape lighted-candle could be defined as
lighted-candle = hc1 , t1 , τ1 , rectanglei u hc2 , t2 , τ2 , circlei
216

Structured Knowledge Representation for Image Retrieval

with τ1 , τ2 placing the circle as a flame on top of the candle, and textures and colors defined
accordingly to the intuition.
We remark that, to the best of our knowledge, the logic we present is the first one
combining shapes and explicit transformations in one language.
In a previous paper (Di Sciascio, Donini, & Mongiello, 2000) we presented a formalism
including nested composite shapes, as it is done in hierarchical object modeling (Foley et al.,
1996, Ch.7). However, nested composite shapes can always be flattened by composing their
transformations. Hence in this paper we focus on two levels: basic shapes and compositions
of basic shapes. Also, just to simplify the presentation of the semantics, in the following
section we do not present color and texture features, which we take into account from
Section 4.2 on.
3.2 Semantics
We consider an extensional semantics, in which syntactic expressions are interpreted as
subsets of a domain. For our setting, the domain of interpretation is a set of images ∆, and
shapes and components are interpreted as subsets of ∆. Hence, also an image database is
a domain of interpretation, and a complex shape C is a subset of such a domain — the
images to be retrieved from the database when C is viewed as a query.
This approach is quite different from previous logical approaches to image retrieval that
view the image database as a set of facts, or logical assertions, e.g., the one based on
Description Logics by Meghini et al. (2001). In that setting, image retrieval amounts to
logical inference. However, observe that usually a Domain Closure Assumption (Reiter,
1980) is made for image databases: there are no regions but the ones which can be seen in
the images themselves. This allows one to consider the problem of image retrieval as simple
model checking — check if a given structure satisfies a description2 .
Formally, an interpretation is a pair (I, ∆), where ∆ is a set of images, and I is a
mapping from shapes and components to subsets of ∆. We identify each image I with the
set of regions {r1 , . . . ,rn } it can be segmented into (excluding background, which we discuss
at the end of this section). Each region r comes with its own edge contour e(r). An image
I ∈ ∆ belongs to the interpretation of a basic shape component hτ, BiI if I contains a
region whose contour matches τ (e(B)). In formulae,
hτ, BiI = {I ∈ ∆ | ∃r ∈ I : e(r) = τ (e(B))}

(1)

The above definition is only for exact recognition of shape components in images, due to
the presence of strict equality in the comparison of contours; but it can be extended to
approximate recognition as follows. Recall that the characteristic function f S of a set S is a
function whose value is either 1 or 0; fS (x) = 1 if x ∈ S, fS (x) = 0 otherwise. We consider
now the characteristic function of the set defined in Formula (1). Let I be an image; if I
belongs to hτ, BiI , then the characteristic function computed on I has value 1, otherwise
it has value 0. To keep the number of symbols low, we use the expression hτ, BiI also to
2. Obviously, a Domain Closure Assumption on regions is not valid in artificial vision, dealing with twodimensional images of three-dimensional shapes (and scenes), because solid shapes have surfaces that
will be hidden in their images. But this is outside the scope of our retrieval problem.

217

Di Sciascio, Donini & Mongiello

denote the characteristic function (with an argument (I) to distinguish it from the set).
I

hτ, Bi (I) =

(

1 if ∃r ∈ I : e(r) = τ (e(B))
0
otherwise

Now we reformulate this function in order to make it return a real number in the range [0, 1]
— as usual in fuzzy logic (Zadeh, 1965). Let sim(·, ·) be a similarity measure from pairs of
contours into the range [0, 1] of real numbers (where 1 is perfect matching). We use sim(·, ·)
instead of equality to compare edge contours. Moreover, the existential quantification can
be replaced by a maximum over all possible regions in I. Then, the characteristic function
for the approximate recognition in an image I of a basic component, is:
hτ, BiI (I) = max{sim(e(r), τ (e(B)))}
r∈I

Note that sim depends on translations, rotation and scaling, since we are looking for regions
in I whose contour matches e(B), with reference to the position and size specified by τ .
The interpretation of basic shapes, instead, includes a translation-rotation-scaling invariant recognition, which is commonly used in single-shape Image Retrieval. We define the
interpretation of a basic shape as
B I = {I ∈ ∆ | ∃τ ∃r ∈ I : e(r) = τ (e(B))}
and its approximate counterpart as the function
B I (I) = max max{sim(e(r), τ (e(B)))}
τ

r∈I

The maximization over all possible transformations maxτ can be effectively computed by
using a similarity measure simss that is invariant with reference to translation-rotationscaling (see Section 4.2). Similarity of color and texture will be added as a weighted sum
in Section 4.2. In this way, a basic shape B can be used as a query to retrieve all images
from ∆ which are in B I . Therefore, our approach generalizes the more usual approaches
for single-shape retrieval, such as Blobworld (Carson et al., 1999).
Composite shape descriptions are interpreted as sets of images that contain all components of the composite shape. Components can be anywhere in the image, as long as
they are in the described arrangement relative to each other. Let C be a composite shape
description hτ1 , B1 i u · · · u hτn , Bn i. In exact matching, the interpretation is the intersection
of the sets interpreting each component of the shape:
C I = {I ∈ ∆ | ∃τ : I ∈ ∩ni=1 h(τ ◦ τi ), Bi iI }

(2)

Observe that we require all shape components of C to be transformed into image regions
using the same transformation τ . This preserves the arrangement of the shape components
relative to each other — given by each τi — while allowing C I to include every image
containing a group of regions in the right arrangement, wholly displaced by τ .
To clarify this formula, consider Figure 2: the shape C is composed by two basic shapes
B1 and B2 , suitably arranged by the transformations τ1 and τ2 . Suppose now that ∆
contains the image I. Then, I ∈ C I because there exists the transformation τ , which
218

Structured Knowledge Representation for Image Retrieval

Figure 2: An example of application of Formula (2).
globally brings C into I, that is, τ ◦ τ1 brings the rectangle B1 into a rectangle recognized
in I, and τ ◦ τ2 brings the circle B2 into a circle recognized in I, both arranged according
to C. Note that I could contain also other shapes, not included in C.
We can now formally define the recognition of a shape in an image.
Definition 1 (Recognition) A shape description C is recognized in an image I if for
every interpretation (I, ∆) such that I ∈ ∆, it is I ∈ C I . An interpretation (I, ∆) satisfies
a composite shape description C if there exists an image I ∈ ∆ such that C is recognized in
I. A composite shape description is satisfiable if there exists an interpretation satisfying it.
Observe that shape descriptions could be unsatisfiable: if two components define overlapping
regions, no image can be segmented in a way that satisfies both components. Of course, if
composite shape descriptions are built using a graphical tool, unsatisfiability can be easily
avoided, so we assume that descriptions are always satisfiable. Anyway, unsatisfiable shape
descriptions could be easily detected, from their syntactic form, since unsatisfiability can
only arise because of overlapping regions (see Proposition 4).
Observe also that our set-based semantics implies the intuitive interpretation of conjunction “u” — one could easily prove that u is commutative and idempotent.
For approximate matching, we modify definition (2), following the fuzzy interpretation
of u as minimum, and existential as maximum:
n

C I (I) = max {min {h(τ ◦ τi ), Bi iI (I)}}
τ

i=1

(3)

Observe that our interpretation of composite shape descriptions strictly requires the presence of all components. In fact, the measure by which an image I belongs to the interpreta219

Di Sciascio, Donini & Mongiello

tion of a composite shape description C I is dominated by the least similar shape component
(the one with the minimum similarity). Hence, if a basic shape component is very dissimilar
from every region in I, this brings near to 03 also the measure of C I (I). This is more strict
than, e.g., Gudivada & Raghavan’s (1995) or El-Kwae & Kabuka’s (1999) approaches, in
which a non-appearing component can decrease the similarity value of C I (I), but I can be
still above a threshold.
Although this requirement may seem a strict one, it captures the way details are used
to refine a query: the “dominant” shapes are used first, and, if the retrieved set is still too
large, the user adds details to restrict the results. In this refinement process, it should not
happen that other images that match only some new details, “pop up” enlarging the set of
results that the user was trying to restrict. We formalize this refinement process through
the following definition.
Proposition 1 (Downward refinement) Let C be a composite shape description, and
.
let D be a refinement of C, that is D = C u hτ 0 , B 0 i. For every interpretation I, if shapes
are interpreted as in (2), then D I ⊆ C I ; if shapes are interpreted as in (3), then for every
image I it holds D I (I) ≤ C I (I).
Proof. For (2), the claim follows from the fact that D I considers an intersection of the same
components as the one of C I , plus the set h(τ ◦ τ 0 ), B 0 iI . For (3), the claim analogously
follows from the fact that D I (I) computes a minimum over a superset of the values considered for C I (I).

The above property makes our language fully compositional. Namely, let C be a composite shape description; we can consider the meaning of C — when used as a query — as
the set of images that can be potentially retrieved using C. At least, this will be the meaning perceived by an end user of a system. Downward refinement ensures that the meaning
of C can be obtained by starting with one component, and then progressively adding other
components in any order. We remark that for other frameworks cited above (Gudivada &
Raghavan, 1995; El-Kwae & Kabuka, 1999) this property does not hold. We illustrate the
problem in Figure 3. Starting with shape description C, we may retrieve (among many
others) the two images I1 , I2 , for which both C I (I1 ) and C I (I2 ) are above a threshold t,
while another image I3 is not in the set because C I (I3 ) < t. In order to be more selective, we try adding details, and we obtain the shape description D. Using D, we may still
retrieve I2 , and discard I1 . However, I3 now partially matches the new details of D. If
Downward refinement holds, D I (I3 ) ≤ C I (I3 ) < t, and I3 cannot “pop up”. In contrast,
if Downward refinement does not hold (as in Gudivada & Raghavan’s approach) it can be
DI (I3 ) > t > C I (I3 ) because matched details in D raise the similarity sum weighted over
all components. In this case, the meaning of a sketch cannot be defined in terms of its
components.
Downward refinement is a property linking syntax to semantics. Thanks to the extensional semantics, it can be extended to an even more meaningful semantic relation, namely,
3. Not exactly 0, since every shape matches every other one with a very low similarity measure. Similarity
is often computed as the inverse of a distance. Similarity 0 would correspond to infinite distance.
Nevertheless, the recognition algorithm can force the similarity to 0 when it is below a threshold.

220

Structured Knowledge Representation for Image Retrieval

Figure 3: Downward refinement: the thin arrows denote non-zero similarity in approximate
recognition. The thick arrow denotes a refinement.

221

Di Sciascio, Donini & Mongiello

Figure 4: An example of subsumption hierarchy of shapes (thick arrows), and images in
which the shapes can be recognized (thin arrows).

subsumption. We borrow this definition from Description Logics (Donini, Lenzerini, Nardi,
& Schaerf, 1996), and its fuzzy extensions (Yen, 1991; Straccia, 2001).
Definition 2 (Subsumption) A description C subsumes a description D if for every
interpretation I, D I ⊆ C I . If (3) is used, C subsumes D if for every interpretation I and
image I ∈ ∆, it is D I (I) ≤ C I (I).
Subsumption takes into account the fact that a description might contain a syntactic variant
of another, without both the user and the system explicitly knowing this fact. The notion
of subsumption extends downward refinement. It enables also a hierarchy of shape descriptions, in which a description D is below another C if D is subsumed by C. When C and
D are used as queries, the subsumption hierarchy makes easy to detect query containment.
Containment can be used to speed up retrieval: all images retrieved using D as a query can
be immediately retrieved also when C is used as a query, without recomputing similarities.
While query containment is important in standard databases (Ullman, 1988), it becomes
even more important in an image retrieval setting, since the recognition of specific features
in an image can be computationally demanding.
Figure 4 illustrates an example of subsumption hierarchy of basic and composite shapes
(thick arrows denote a subsumption between shapes), and two images in which shapes can
be recognized (thin arrows).
Although we did not consider a background, it could be added to our framework as a
special basic component hc, t, , backgroundi with the property that a region b satisfies the
222

Structured Knowledge Representation for Image Retrieval

background simply if their colors and textures match, with no check on the edge contours.
Also, more than one background could be added; in that case background regions should
not overlap, and the matching of background regions should be considered after the regions
of all the basic shapes recognized are subtracted to the background regions.

4. Reasoning and Retrieval
We envisage several reasoning services that can be carried out in a logic for image retrieval:
1. shape recognition: Given an image I and a shape description D, decide if D is recognized in I.
2. image retrieval: given a database of images and a shape description D, retrieve all
images in which D can be recognized.
3. image classification: given an image I and a collection of descriptions D 1 , . . . , Dn , find
which descriptions can be recognized in I. In practice, I is classified by finding the
most specific descriptions (with reference to subsumption) it satisfies. Observe that
classification is a way of “preprocessing” recognition.
4. description subsumption (and classification): given a (new) description D and a collection of descriptions D1 , . . . , Dn , decide whether D subsumes (or is subsumed by)
each Di , for i = 1, . . . , n.
While services 1–2 are standard in an image retrieval system, services 3–4 are less obvious,
and we briefly discuss them below.
The process of image retrieval is quite expensive, and systems usually perform off-line
processing of data, amortizing its cost over several queries to be answered on-line. As an
example, all document retrieval systems for the web4 , both for images and text, use spiders
to crawl the web and extract some relevant features (e.g., color distributions and textures
in images, keywords in texts), that are used to classify documents. Then, the answering
process uses such classified, extracted features of documents — and not the original data.
Our system can adapt this setting to composite shapes, too. In our system, a new
image inserted in the database is immediately segmented and classified in accordance with
the basic shapes that compose it, and the composite descriptions it satisfies (Service 3). Also
a query undergoes the same classification, with reference to the queries already answered
(Service 4). The more basic shapes are present, the faster will the system answer new
queries based on these shapes.
More formally, given a query (shape description) D, if there exists a collection of descriptions D1 , . . . , Dn and all images in the database were already classified with reference
to D1 , . . . , Dn , then it may suffice to classify D with reference to D1 , . . . , Dn to find (most
of) the images satisfying D. This is the usual way in which classification in Description
Logics — which amounts to a semantic indexing — can help query answering (Nebel, 1990).
For example, to answer the query asking for images containing an arch, a system may
classify arch and find that it subsumes threePortalsGate (see Figure 4). Then, the system
4. e.g., Altavista, QBIC, NETRA, Blobworld, but also Yahoo (for textual documents).

223

Di Sciascio, Donini & Mongiello

can include in the answer all images in which ancient Roman gates can be recognized,
without recomputing whether these images contain an arch or not.
The problem of computing subsumption between descriptions is reduced to recognition
in the next section, and then an algorithm for exact recognition is given. Then, we extend
the algorithm to realistic approximate recognition, reconsidering color and texture.
4.1 Exact Reasoning on Images and Descriptions
We start with a reformulation of (2), more suited for computational purposes.
Theorem 2 (Recognition as mapping) Let C = hτ1 , B1 i u · · · u hτn , Bn i be a composite
shape description, and let I be an image, segmented into regions {r 1 , . . . ,rm }. Then C is
recognized in I iff there exists a transformation τ and an injective mapping j : {1, . . . , n} →
{1, . . . , m} such that for i = 1, . . . , n it is
e(rj(i) ) = τ (τi (e(Bi )))
Proof. From (2), C is recognized in I iff
∃τ [I ∈

n
\

h(τ ◦ τi ), Bi iI ] which is equivalent to ∃τ [

i=1

n
^

I ∈ h(τ ◦ τi ), Bi iI ]

i=1

Expanding h(τ ◦ τi ), Bi iI with its definition (1) yields
∃τ [

n
^

∃r ∈ I.e(r) = τ (τi (e(Bi )))]

i=1

and since regions in I are {r1 , . . . ,rm } this is equivalent to
∃τ [

m
n _
^

e(rj ) = τ (τi (e(Bi )))]

i=1 j=1

Making explicit the disjunction over j and conjunctions over i, we can arrange this conjunctive formula as a matrix:




(e(r1 ) = τ (τ1 (e(B1 ))) ∨ · · · ∨ e(rm ) = τ (τ1 (e(B1 )))) ) ∧


..
.
..
∃τ 
.
∧ 
.
∨ .. ∨
(e(r1 ) = τ (τn (e(Bn ))) ∨ · · · ∨ e(rm ) = τ (τn (e(Bn )))) )

(4)

Now we note two properties in the above matrix of equalities:
1. For a given transformation, at most one region among r1 , . . . ,rm can be equal to each
component. This means that in each row, at most one disjunct can be true for a given
τ.
2. For a given transformation, a region can match at most one component. This means
that in each column, at most one equality can be true for a given τ .
224

Structured Knowledge Representation for Image Retrieval

We observe that these properties do not imply that regions have all different shapes, since
the equality of contours depends on any translation, rotation, and scaling. We use equality
to represent true overlap, and not just equal shape.
Properties 1–2 imply that the above formula is true iff there is an injective function
mapping each component to one region it matches with. To ease the comparison with the
formulae above we use the same symbol j as a mapping j : {1, . . . , n} → {1, . . . , m}. Hence,
Formula (4) can be rewritten into the claim:
∃τ [∃j : {1..n} → {1..m}

n
^

e(rj(i) ) = τ (τi (e(Bi )))]

(5)

i=1

Hence, even if in the previous section the semantics of a composite shape was derived from
the semantics of its components, in computing whether an image contains a composite shape
one can focus on groups of regions, one group rj(1) , . . . , rj(n) for each possible mapping j.
Observe that j injective implies m ≥ n, as one would expect. The above proposition
leaves open which one between τ or j must be chosen first. In fact, in what follows we
show that the optimal choice for exact recognition is to mix decisions about j and τ . When
approximate recognition will be considered, however, exchanging quantifiers is not harmless.
In fact, it can change the order in which approximations are made. We return to this
issue in the next section, when we discuss how one can devise algorithms for approximate
recognition.
Subsumption in this simple logic for shape descriptions relies on the composition of
contours of basic shapes. Intuitively, to actually decide if D is subsumed by C, we check
if the sketch associated with D — seen as an image — would be retrieved using C as a
query. From a logical perspective, the existentially quantified regions in the semantics of
shape descriptions (1) are skolemized with their prototypical contours. Formal definitions
follow.
Definition 3 (Prototypical image) Let B be a basic shape. Its prototypical image is
I(B) = {e(B)}. Let C = hτ1 , B1 i u · · · u hτn , Bn i be a composite shape description. Its
prototypical image is I(C) = {τ1 (e(B1 )), . . . , τn (e(Bn ))}.
In practice, from a composite shape description one builds its prototypical image just applying the stated transformations to its components (and color/texture fillings, if present).
Recall that we envisage this prototypical image to be built directly by the user, with the
help of a drawing tool, with basic shapes and colors as palette items. The system will
just keep track of the transformations corresponding to the user’s actions, and use them in
building the (internal) shape descriptions stored with the previous syntax. The feature that
makes our proposal different from other query-by-sketch retrieval systems, is precisely that
our sketches have also a logical meaning. So, properties about description/sketches can be
proved, containment between query sketches can be stated in a formal way, and algorithms
for containment checking can be proved correct with reference to the semantics.
Prototypical images have some important properties. The first is that they satisfy (in
the sense of Definition 1) the shape description they exemplify — as intuition would suggest.
225

Di Sciascio, Donini & Mongiello

Proposition 3 For every composite shape description D, if D is satisfiable then the interpretation hI, {I(D)}i satisfies D.
Proof. From Theorem 2, using an identical transformation τ and the identity mapping for
j.

A shape description D is satisfiable if there are no overlapping regions in I(D). Since
this is obvious when D is specified by a drawing tool, we just give the following proposition
for sake of completeness.
Proposition 4 A shape description D is satisfiable iff its prototypical image I(D) contains
no overlapping regions.
We now turn to subsumption. Observe that if B1 and B2 are basic shapes, either they
are equivalent (each one subsumes the other) or neither of the two subsumes the other. If we
adopt for the segmented regions an invariant representation, (e.g. Fourier transforms of the
contour) deciding equivalence between basic shapes, or recognizing whether a basic shape
appears in an image, is just a call to an algorithm computing the similarity between shapes.
This is what usual image recognizers do — allowing for some tolerance in the matching
of the shapes. Therefore, our framework extends the retrieval of shapes made of a single
component, for which effective systems are already available.
We now consider composite shape descriptions, and prove the main property of prototypical images, namely, the fact that subsumption between shape descriptions can be
decided by checking if the subsumer can be recognized in the sketch of the subsumee.
Theorem 5 A composite shape description C subsumes a description D if and only if C
is recognized in the prototypical image I(D).
Proof. Let C = hτ1 , B1 i u · · · u hτn , Bn i, and let D = hσ1 , A1 i u · · · u hσm , Am i. Recall that
I(D) is defined by I(D) = {σ1 (e(A1 )), . . . , σm (e(Am ))}. To ease the reading, we sketch the
idea of the proof in Figure 5.
If. Suppose C is recognized in I(D), that is, I(D) ∈ C I for every interpretation (I, ∆)
such that I(D) ∈ ∆. Then, from Theorem 2 there exists a transformation τ̂ and a suitable
injective function j from {1, . . . , n} into {1, . . . , m} such that
e(rj(k) ) = τ̂ ◦ τk (e(Bk ))

for k = 1, . . . , n

Since I(D) is the prototypical image of D, we can substitute each region with the basic
shape of D it comes from:
σj(k) (e(Aj(k) )) = τ̂ ◦ τk (e(Bk ))

for k = 1, . . . , n

(6)

Now suppose that D is recognized in an image J = {s1 , . . . ,sp }, with J ∈ ∆. We prove that
also C is recognized in J. In fact, if D is recognized in J then there exists a transformation
σ̂ and another injective mapping q from {1, . . . , m} into {1, . . . , p} selecting from J regions
{sq(1) , . . . , sq(m) } such that
e(sq(h) ) = σ̂ ◦ σh (e(Ah ))
226

for h = 1, . . . , m

(7)

Structured Knowledge Representation for Image Retrieval

(prototypical image of) C
¾»

S
¶½¼
S
¶
S
S S
¶ ¶¶
S S
¶ ¶
S S
¶ ¶
S S
¶ ¶
S S τ̂
¶
S S
σ̂ ◦ τ̂ ¶ ¶
S S ¾»
¶
¶ ¶
S S
¶ ¶
»»S»
»
¶ ¶
»
S½¼
»
»»
¶ ¶²¯
»
»
»
S
»
»
»
»
»
»
¶ ¶ ±°
»
»
»
»
»
σ̂
»
¶ »
»»
»
»»
m
»¶
»»»
»»»
»
»
»
»
¶
»
»»
»»
¶ »»»
»»»
»
prototypical image I(D)
»
»»»

image J
Figure 5: A sketch of the If-proof of Theorem 5
Now composing q and j — that is, selecting the regions of J satisfying those components
of D which are used to recognize C — one obtains
e(sq(j(k)) ) = σ̂ ◦ σj(k) (e(Aj(k) ))

for k = 1, . . . , n

(8)

Then, substituting equals for equals from (6), one finally gets
e(sq(j(k)) ) = σ̂ ◦ τ̂ ◦ τk (e(Bk ))

for k = 1, . . . , n

which proves that C too is recognized in J, using σ̂ ◦ τ̂ as transformation of its components,
and q(j(·)) as injective mapping from {1, . . . , n} into {1, . . . , p}. Since J is a generic image,
it follows that D I ⊆ C I . Since (I, ∆) is generic too, C subsumes D.
Only if. The reverse direction is easier: suppose C subsumes D. By definition, this
amounts to D I ⊆ C I for every collection of images I. For every I that contains I(D), then
I(D) ∈ D I for Proposition 3. Therefore, I(D) ∈ C I , that is, C is recognized in I(D).

This property allows us to compute subsumption as recognition, so we concentrate on
complex shape recognition, using Theorem 2. Our concern is how to decide whether there
exists a transformation τ and a matching j having the properties stated in Theorem 2.
It turns out that for exact recognition, a quadratic upper bound can be attained for the
possible transformations to try.

227

Di Sciascio, Donini & Mongiello

Theorem 6 Let C = hτ1 , B1 i u · · · u hτn , Bn i be a composite shape description, and let I
be an image, segmented into regions {r1 , . . . ,rm }. Then, there are at most m(m − 1) exact
matches between the n basic shapes and the m regions. Moreover, each possible match can
be verified by checking the matching of n pairs of contours.
Proof. A transformation τ matching exactly basic components to regions is also an
exact match for their centroids. Hence we concentrate on centroids. Each correspondence
between a centroid of a basic component and a centroid of a region yields two constraints
for τ . Now τ is a rigid motion with scaling, hence it has four degrees of freedom (two
degrees for translations, one for rotation, and one for uniform scaling). Hence, if an exact
match τ exists between the centroids of the basic components and the centroids of some of
the regions, then τ is completely determined by the transformation of any two centroids of
the basic shapes into two centroids of the regions.
Fixing any pair of basic components B1 , B2 , let p1 , p2 denote their centroids. Also,
let rj(1) , rj(2) be the regions that correspond to B1 , B2 , and let vj(1) , vj(2) , denote their
centroids. There is only one transformation τ solving the point equations (each one mapping
a point into another)
(
τ (τ1 (p1 )) = vj(1)
τ (τ2 (p2 )) = vj(2)
Hence, there are only m(m − 1) such transformations. For the second claim, once a τ
matching the centroids is found, one checks that the edge contours of basic components
and regions coincide, i.e., that τ (τ1 (e(B1 ))) = e(rj(1) ), τ (τ2 (e(B2 ))) = e(rj(2) ), and for
k = 3, . . . , n that τ (τk (e(Bk )) coincides with the contour of some region e(rj(k) ).
Recalling Formula (5) in the proof of Theorem 2, this means that we can eliminate the
outer quantifier in (5) using a computed τ , and conclude that C is recognized in I iff:
∃j : {1..n} → {1..m}

n
^

e(rj(i) ) = τ (τi (e(Bi )))

i=1

Observe that, to prune the above search, once a τ has been found as above, one can
check for k = 3, . . . , n that τ (τk (centr(Bk ))) coincides with a centroid of some region rj ,
before checking contours.
Based on Theorem 6, we can devise the following algorithm:
Algorithm Recognize (C,I);
input a composite shape description C = hτ1 , B1 i u · · · u hτn , Bn i, and
an image I, segmented into regions r1 , . . . ,rm
output True if C is recognized in I, False otherwise
begin
(1) compute the centroids v1 , . . . ,vm of r1 , . . . ,rm
(2) compute the centroids p1 , . . . ,pn of the components of C
(3) for i, h ∈ {1, . . . , m} with i < h do
compute the transformation τ such that τ (p1 ) = vi and τ (p2 ) = vh ;
228

Structured Knowledge Representation for Image Retrieval

if for every k ∈ {1, . . . , n}
τ (τk (e(Bk ))) coincides (for some j) with a region rj in I
then return True
endfor
return False
end
The correctness of Recognize (C,I) follows directly from Theorems 2 and 6. Regarding
the time complexity, step (1) requires to compute centroids of segmented regions. Several
methods for computing centroids are well known in the literature (Jahne, Haubecker, &
Geibler, 1999). Hence, we abstract from this detail, and assume there exists a function
f (Nh , Nv ) that bounds the complexity of computing one centroid, where Nh , Nv are the
horizontal and vertical dimensions of I (number of pixels). We report in the Appendix how
we compute centroids, and concentrate on the complexity in terms of n, m, and f (N h , Nv ).
Theorem 7 Let C = hτ1 , B1 i u · · · u hτn , Bn i be a composite shape description, and let I be
an image with Nh × Nv pixels, segmented into regions {r1 , . . . ,rm }. Moreover, let f (Nh , Nv )
be a function bounding the complexity of computing the centroid of one region. Then C can
be recognized in I in time O(m · f (Nh , Nv ) + n + m2 · n · Nh · Nv ).
Proof. From the assumptions, Step (1) can be performed in time O(m·f (Nh , Nv )). Instead,
Step (2) can be accomplished by extracting the n translation vectors from the transformations τ1 , . . . ,τn of the components of C. Therefore, it requires O(n) time. Finally, the
innermost check in Step (3) — checking whether a transformed basic shape and a region
coincide — can be performed in O(Nh · Nv ), using a suitable marking of pixels in I with
the region they belong to. Hence, we obtain the claim.

Since subsumption between two shape descriptions C and D can be reduced to recognizing C in I(D), the same upper bound holds for checking subsumption between composite
shape descriptions, with the simplification that also Step (1) can be accomplished without
any further feature-level image processing.
4.2 Approximate Recognition
The algorithm proposed in the previous section assumes an exact recognition. Since the
target of retrieval are real images, approximate recognition is needed. We start by reconsidering the proof of Theorem 2, and in particular the matrix of equalities (4). Using
the semantics for approximate recognition (3), the expanded formula for evaluating C I (I)
becomes now the following:

max min
τ



 max{sim(e(r1 ), τ (τ1 (e(B1 )))),



..
.
max{sim(e(r1 ), τ (τn (e(Bn ))),



. . . , sim(e(rm ), τ (τ1 (e(B1 ))))) } 

..
..
.
.
...,

sim(e(rm ), τ (τn (e(Bn ))))

}




Now Properties 1–2 stated for exact recognition can be reformulated as hypotheses about
sim, as follows.
229

Di Sciascio, Donini & Mongiello

1. For a given transformation, we assume that at most one region among r 1 , . . . ,rm is
maximally similar to each component. This assumption can be justified by supposing
its negation: if there are two regions both maximally similar to a component, then
this maximal value should be a very low one, lowering the overall value because of the
external minimization. This means that in maximizing each row, we can assume that
the maximal value is given by one index among 1, . . . , m.
2. For a given transformation, we assume that a region can yield a maximal similarity for
at most one component. Again, the rationale of this assumption is that when a region
yields a maximal similarity with two components in two different rows, this value can
be only a low one, which propagates along the overall minimum. This means that in
minimizing the maxima from all rows, we can consider a different region in each row.
We remark that also in the approximate case these assumptions do not imply that regions
have all different shapes, since sim is a similarity measure which is 1 only for true overlap,
not just for equal shapes with different pose. The assumptions just state that sim should
be a function “near” to plain equality.
The above assumptions imply that we can focus on injective mappings from {1..n} into
{1..m} also for the approximate recognition, yielding the formula
max
τ

n

min{sim(e(rj(i) ), τ (τi (e(Bi ))))}

max

j:{1..n}→{1..m} i=1

The choices of τ and j for the two maxima are independent, hence we can consider groups
of regions first:
max

n

j:{1..n}→{1..m}

max min{sim(e(rj(i) ), τ (τi (e(Bi ))))}
τ

i=1

(9)

Differently from the exact recognition, the choice of an injective mapping j does not directly
lead to a transformation τ , since now τ depends on how the similarity of transformed shapes
is computed, that is, the choice of τ depends on sim.
In giving a definition of sim, we reconsider the other image features (color, texture) that
were skipped in the theoretical part to ease the presentation of semantics. This will introduce weighted sums in the similarity measure, where weights are set by the user according
to the importance of the features in the recognition.
Let sim(r, hc, t, τ, Bi) be a similarity measure that takes a region r (with its color c(r)
and texture t(r)) and a component hc, t, τ, Bi into the range [0, 1] of real numbers (where 1
is perfect matching). We note that color and texture similarities do not depend on transformations, hence their introduction does not change Assumptions 1–2 above. Accordingly,
Formula (9) becomes
max

j:{1..n}→{1..m}

n

max min{sim(rj(i) , hc, t, (τ ◦ τi ), Bi i)}
τ

i=1

(10)

This formula suggests that from all the groups of regions in an image that might resemble
the components, we should select the groups that present the higher similarity. In artificially
constructed examples in which all shapes in I and C resemble each other, this may generate
an exponential number of groups to be tested. However, we can assume that in realistic
230

Structured Knowledge Representation for Image Retrieval

images the similarity between shapes is selective enough to yield only a very small number
of possible groups to try. We recall that in Gudivada’s approach (Gudivada, 1998) an
even stricter assumption is made, namely, each basic component in C does not appear
twice, and each region in I matches at most one component in C. Hence our approach
extends Gudivada’s one, also for this aspect — besides the fact that we consider shape,
scale, rotation, color and texture of each component.
In spite of the assumptions made, finding an algorithm for computing the “best” τ
in Formula (10) proved for us a difficult task. The problem is that there is a continuous
spectrum of τ to be searched, and that the best τ may not be unique. We observed that
when only single points are to be matched — instead of regions and components — our
problem simplifies to Point Pattern Matching in Computational Geometry. However, even
recent results in that research area are not complete, and cannot be directly applied to
our problem. Cardoze and Schulman (1998) solve the nearly-exact point matching with
efficient randomized methods, but without scaling. They also observe that best match is
a more difficult problem than nearly-exact match. Also Chew, Goodrich, Huttenlocher,
Kedem, Kleinberg, and Kravets (1997) propose a method for best match of shapes, but
they analyze only rigid motions without scaling.
Therefore, we adopt some heuristics to evaluate the above formula. First of all, we
decompose sim(r, hc, t, τ, Bi) as a sum of six weighted contributions.
Three contributions are independent of the pose: color, texture and shape. The values of color and texture similarity are denoted by simcolor (c(r), c) and simtexture (t(r), t),
respectively. Similarity of the shapes (rotation-translation-scale invariant) is denoted by
simshape (e(r), e(B)). For each feature, and each pair (region, component) we compute a
similarity measure as explained in the Appendix. Then, we assign to all similarities of a
feature — say, color — the worst similarity in the group. This yields a pessimistic estimate
of Formula (10); however, for such estimate the Downward Refinement property holds (see
next Theorem 8).
The other three contributions depend on the pose, and try to evaluate how the pose
of each region in the selected group is similar to the pose specified by the corresponding
component in the sketch. In particular, simscale (e(r), τ (e(B)) represents how similar in scale
are the region and the transformed component, while simrotation (e(r), τ (e(B)) denotes how
e(r) and τ (e(B) are similarly (or not) rotated with reference to the arrangement of the
other components. Finally, simspatial (e(r), τ (e(B)) denotes a measure of how coincident are
the centroids of the region and the transformed component.
In summary, we get the following form for the overall similarity between a region and a
component:
sim(r, hc, t, τ, Bi) = simspatial (e(r), τ (e(B)) · α +
simshape (e(r), e(B)) · β +
simcolor (c(r), c) · γ +
simrotation (e(r), τ (e(B)) · δ +
simscale (e(r), τ (e(B)) · η +
simtexture (t(r), t) · ²
231

Di Sciascio, Donini & Mongiello

where coefficients α, β, γ, δ, η, ² weight the relevance each feature has in the overall similarity
computation. Obviously, we impose α + β + γ + δ + η + ² = 1, and all coefficients are greater
or equal to 0. The actual values given to these coefficients in the implemented system are
reported in Table 2 in Section 6.
Because of the difficulties in computing the best τ , we do not compute a maximum over
all possible τ ’s. Instead, we evaluate whether there can be a rigid transformation with scaling
from τ1 (e(B1 )), . . . , τn (e(Bn )) into rj(1) , . . . , rj(n) , through similarities simspatial , simscale ,
and simrotation . There is a transformation iff all these similarities are 1. If not, the lower
the similarities are, the less “rigid” the transformation should be to match components and
regions. Hence, instead of Formula (10) we evaluate the following simpler formula:
max

n

min{sim(rj(i) , hc, t, τi , Bi i)}

j:{1..n}→{1..m} i=1

(11)

interpreting pose similarities in a different way. We now describe in detail how we estimate
pose similarities.
Let C = hc1 , t1 , τ1 , B1 i) u · · · u hcn , tn , τn , Bn i), and let j be an injective function from
{1..n} into {1..m}, that matches components with regions {rj(1) , . . . , rj(n) } respectively.
4.2.1 Spatial Similarity
For a given component — say, component 1 — we compute all angles under which the other
components are seen from 1. Formally, let αi1h
c be the counter-clockwise-oriented angle with
vertex in the centroid of component 1, and formed by the lines linking this centroid with
the centroids of component i and h. There are n(n − 1)/2 such angles.
Then, we compute the correspondent angles for region rj(1) , namely, angles βj(i)j(1)j(h)
d
with vertex in the centroid of rj(1) , formed by the lines linking this centroid with the
centroids of regions rj(i) and rj(h) respectively. A pictorial representation of the angles is
given in Figure 6.
Then we let the difference ∆spatial (e(rj(1) ), τ1 (e(B1 )) be the maximal absolute difference
between correspondent angles:
∆spatial (e(rj(1) ), τ1 (e(B1 )) =

max

i,h=2,...,n,i6=h

|}
{|αi1h
d
c − βj(i)j(1)j(h)

We compute an analogous measure for components 2,. . . ,n, and then we select the maximum
of such differences:
n

∆spatial [j] = max{∆spatial (e(rj(i) ), τi (e(Bi ))}
i=1

(12)

where the argument j highlights the fact that this measure depends on the mapping
j. Finally, we transform this maximal difference — for which perfect matching yields 0
— into a minimal similarity — perfect matching yields 1 — with the help of the function Φ described in the Appendix. This minimal similarity is then assigned to every
simspatial (e(rj(i) ), τi (e(Bi )), for i = 1, . . . , n.
Intuitively, our estimate measures the difference in the arrangement of centroids between
the composite shape and the group of regions. If there exists a transformation bringing
components into regions exactly, every difference is 0, and so simspatial raises to 1 for every
232

Structured Knowledge Representation for Image Retrieval

f2

α 214

f3

f2

α213

f1

f1

f3

α 215

f2

α 314

f1

f3

α 315

f4

α 415

f4

f4

f5

f5

R2

R3

f5

R2

R3

R2

R3

β 215
β 214
β 213
β 315

R1
R4

β 314

R4

R5

R1

R1
R4

R5

β415

R5

Figure 6: Representation of angles used for computing spatial similarity of component 1
and region rj(1) .

233

Di Sciascio, Donini & Mongiello

R1

f1

β 51u

α 51h
α 41h
α 31h
α 21h

f2

u

R2

h

β 41u

β 31u

F5

β 21u

R5
R3

f3
R4

f4

Figure 7: Representation of angles used for computing rotation similarity of component 1
and region rj(1) .

component. The more an arrangement is scattered with reference to the other arrangement,
the higher its maximum difference. The reason why we use the maximum of all differences
as similarity for each pair component-region will be clear when we prove later that this
measure obeys Downward Refinement property.
4.2.2 Rotation Similarity
For every basic shape one can imagine a unit vector with origin in its centroid and oriented
horizontally on the right (as seen on the palette). When the shape is used as a component
— say, component 1 — also this vector is rotated according to τ1 . Let ~h denote such a
rotated vector. For i = 2, . . . , n let γ c~ the counter-clockwise-oriented angle with vertex in
i1h
the centroid of component 1, and formed by ~h and the line linking the centroid of component

1 with the centroid of component i.
For region rj(1) , the analogous ~u of ~h can be constructed by finding the rotation phase
for which cross-correlation attains a maximum value (see Appendix). Then, for i = 2, . . . , n
let δj(i)j(1)~
u and the line
d u be the angles with vertex in the centroid of rj(1) , and formed by ~
linking the centroid of rj(1) with the centroid of rj(i) . Figure 7 clarifies the angles we are
computing.
Then we let the difference ∆rotation (e(rj(1) ), τ1 (e(B1 )) be the maximal absolute difference
between correspondent angles:
∆rotation (e(rj(1) ), τ1 (e(B1 )) = max {|γ c~ − δj(i)j(1)~
d u |}
i=2,...,n
i1h

If there is more than one orientation of rj(1) for which cross-correlation yields a maximum —
e.g., a square has four such orientations — then we compute the above maximal difference
for all such orientations, and take the best difference (the minimal one).
234

Structured Knowledge Representation for Image Retrieval

fi

mi

Ri

Mi

Dj
dj
Rj
fj

Figure 8: Sizes and distances for scale similarity computation of component 1 and region
rj(1) .

We repeat the process for components 2 to n, and we select the maximum of such
differences:
n

∆rotation [j] = max{∆rotation (e(rj(i) ), τi (e(Bi ))}
i=1

(13)

Finally, as for spatial similarity, we transform ∆rotation [j] into a minimal similarity with
the help of Φ. This minimal similarity is then assigned to every simrotation (e(rj(i) ), τi (e(Bi )),
for i = 1, . . . , n.
Observe that also these differences drop to 0 when there is a perfect match, hence the
similarity raises to 1. The more a region has to be rotated with reference to the other
regions to match a component, the higher the rotational differences. Again, the fact that
we use the worst difference to compute all rotational similarities will be exploited in the
proof of Downward Refinement.
4.2.3 Scale Similarity
We concentrate again on component 1 to ease the presentation. Let m 1 be the size of
component 1, computed as the mean distance between its centroid and points on the contour.
Moreover, for i = 2, . . . , n, let d1i be the distance between the centroid of component 1 and
the centroid of component i. In the image, let Mj(1) be the size of region rj(i) , and let
Dj(1)j(i) be the distance between centroids of regions j(1) and j(i). Figure 8 pictures the
quantities we are computing.
We define the difference in scale between e(rj(1) ) and τ1 (e(B1 ) as:
¯)
(¯
¯
min{Mj(1) /Dj(1)j(i) , m1 /d1i } ¯¯
¯
∆scale (e(rj(1) ), τ1 (e(B1 )) = max ¯1 −
¯
i=2,...,n ¯
max{Mj(1) /Dj(1)j(i) , m1 /d1i } ¯
235

Di Sciascio, Donini & Mongiello

We repeat the process for components 2 to n, and we select the maximum of such differences:
n

∆scale [j] = max{∆scale (e(rj(i) ), τi (e(Bi ))}
i=1

(14)

Finally, as for the other similarities, we transform ∆scale [j] into a minimal similarity with
the help of Φ. This minimal similarity is then assigned to every simscale (e(rj(i) ), τi (e(Bi )),
for i = 1, . . . , n.
4.2.4 Discussion of Pose Similarities
Using the same worst difference in evaluating pose similarities of all components may appear
a somewhat drastic choice. However, we were guided in this choice by the goal of preserving
the Downward Refinement property, even if we had to abandon the exact recognition of the
previous section.
Theorem 8 Let C be a composite shape description, and let D be a refinement of C, that
.
is, D = C uhc0 , t0 , τ 0 , B 0 i. For every image I, segmented into regions r1 , . . . ,rm , if C I (I) and
DI (I) are computed as in (11) using similarities defined above, then it holds D I (I) ≤ C I (I).
Proof. Every injective function j used to map components of C into I can be extended to
a function j 0 by letting j 0 (n + 1) ∈ {1, . . . , m} be a suitable region index not in the range
of j. Since D I (I) is computed over such extended mappings, it is sufficient to show that
values computed in Formula (11) do not increase with reference to the values computed for
C.
Let j1 be the mapping for which the maximum value C I (I) is reached. Every extension
I
j10 of j1 leads to a minimum value minn+1
i=1 in Formula (11) which is lower than C (I). In fact,
all pose differences (12), (13), (14), are computed as maximums over a strictly greater set
of values, hence the pose similarities have either the same value, or a lower one. Regarding
color, texture, and shape similarities, adding another component can only worsen the values
for components of C, since we assign to all components the worst similarity in the group.
Now consider another injective mapping j2 that yields a non-maximum value v2 < C I (I)
in Formula (11). Using the above argument about pose differences (12), (13), (14), every
extension j20 leads to a minimum value v20 ≤ v2 . Since v2 < C I (I), also every extension of
every mapping j different from j1 yields a value which is less than C I (I). This completes
the proof.

5. A Prototype System
In order to substantiate our ideas we have developed a prototype system, written in C++.
The system is a client-server application working in a MS-Windows environment.
The client side avails of a graphical user interface that allows one to carry out all the
operations necessary to query the knowledge base, including a canvas for query by sketch
composition using basic shapes and a module for query by example using new or existing
images as queries. The client also allows a user to insert new shape descriptions and images
in the knowledge base. The client has the logical structure shown in Figure 9. It is made
up of three main modules: sketch, communication and configuration.
236

Structured Knowledge Representation for Image Retrieval

Figure 9: Architecture of the prototype system.

237

Di Sciascio, Donini & Mongiello

Figure 10: The process of reclassification of images when a new description is inserted: a)
before insertion of description (No. 9); b) after insertion.

The communication module manages the communication with the server side, using
a simple application-level protocol. The configuration module allows one to modify the
parameters relative to the preview of images and shapes transferred from the server and
placed in a cache managed with a FCFS policy for efficient display. The sketch module
allows a user to trace basic shapes as palette items, and properly insert and modify them
by varying the scale and rotation factor. The available shapes may be basic ones such as
ellipse, circle, rectangle, polygons or obtained by composing the basic shapes or complex
shapes defined during previous sessions of the application and inserted in the knowledge
base, but also shapes extracted from segmented images.
The system keeps track of the transformations corresponding to the user’s actions, and
uses them in building the (internal) shape descriptions stored with the previously described
syntax. The color and texture of the drawn shapes can be set according to the user requirements, as the client interface provides a color palette and the possibility to open images in
JPEG format with texture content. The user can also load images from the local disk and
transmit them to the server to populate the knowledge base. Finally, the user can define
new objects endowing them with a textual description and insert them into the knowledge
base.
The server side, which is also shown in Figure 9, is composed by concurrent threads
that manage the server-side graphical interface, the connections and communications with
the client applications and carry out the processing required by the client side. Obviously,
238

Structured Knowledge Representation for Image Retrieval

Figure 11: A query and the retrieved set of images.

239

Di Sciascio, Donini & Mongiello

the server also carries out all tasks related to the insertion of images in the knowledge base,
including segmentation, feature extraction and region indexing, and allows one to properly
set the various parameters involved. To this end, the server has three main subcomponents:
1. the image features extractor that contains an image segmentation module and a region
data extraction one;
2. the image classifier that is composed by a classifier module and a module used in the
image reclassification;
3. the database management system.
The feature extractor segments and processes images to extract relevant features from
each detected region, which characterize the images in the knowledge base. Image segmentation is carried out with an algorithm that starts with the extraction of relevant edges and
then carries out a region growing procedure that basically merges smaller regions into larger
ones according to their similarity in terms of color and texture. Detected regions obviously
have to comply with some minimal heuristics. Each region has associated a description of
the relevant features.
The classifier manages a graph that is used to represent and hierarchically organizes
shape descriptions: basic shapes, and more complex ones obtained by combining such elementary shapes and/or by applying transformations (rotation, scaling and translation).
The basic shapes have no parents, so they are at the top of the hierarchy. Images, when
inserted in the knowledge base after the segmentation process, are linked to the descriptions
in the structure depending on the most specific descriptions that they are able to satisfy.
The classifier module is invoked when a new description D has to be inserted in the
system or a new query is posed. The classifier carries out a search process in the hierarchy
to find the exact position where the new description D (a simple or a complex one) has to be
inserted: the position is determined considering the descriptions that the new description
is subsumed by. Once the position has been found, the image reclassifier compares D with
the images available in the database to determine those that satisfy it; all the images that
verify the recognition algorithm are tied to D. This stage only considers the images that
are tied to descriptions that are direct ancestors of D, as outlined in Figure 10.
As usual in Description Logics, also the query process consists of a description insertion,
as both a query Q and a new description D are treated as prototypical images: a query
Q to the system is considered a new description D and added to the hierarchical data
structure; all images that are connected either to Q or to descriptions below the query in
the hierarchical structure are returned as retrieved images.
The database management module simply keeps track of images and/or pointers to
images.
Using the system is a straightforward task. After logon a user can draw a sketch on
the canvas combining available basic shapes, and enrich the query with color and texture
content. After that the query can be posed to the server to obtain images ranked according
to their similarity. Figure 11 shows a query by sketch with two circles and the retrieved
set. The system correctly retrieves pictures of cars in which the two circles are recognized
in the same relative positions of the sketch and represent the wheels, but also a snow man
with black buttons.
240

Structured Knowledge Representation for Image Retrieval

Figure 12: Downward refinement (contd.): A more detailed query, picturing a car, and the
retrieved set of images.

241

Di Sciascio, Donini & Mongiello

Figure 13: A Subsumption example: increasing the number of objects in the query leads to
a correct reduction in the retrieved set.
242

Structured Knowledge Representation for Image Retrieval

The introduction of more details restricts the retrieved set: adding a chassis to the
previous sketch makes the query more precise, as well as the retrieval results, as it is shown
in Figure 12. This example points out how we expect a user will use the system. He/she will
start with a generic query with a few objects. If the number of images in the retrieved set is
still too large, he/she will increase the number of details obtaining a downward refinement.
Notice that the presence of regions/objects not included in the query is obviously accepted but not the lack of a region that was explicitly introduced in the query. The idea
underlying this approach is that there is an enormous amount of available images, and at
the current stage of research and technology no system can always ensure a complete recognition; yet we believe that the focus should be on reducing false positives, accepting without
much concern a higher ratio of false negatives. This basically means increasing precision,
even at the cost of a possibly lower recall. In other words we believe it is preferable for a
user looking for an image containing a yellow car, e.g., using the sketch in Figure 12, that
he/she receives as result of the query a limited subset of images containing almost for sure
a yellow car, than a large amount of images containing cars, but also several images with
no cars at all.
Subsumption is another distinguishing feature of our system. Figure 13 shows queries
composed of basic shapes that have been obtained by segmentation of an image picturing
aircrafts, i.e., the aircraft is now a basic shape for the system. Here, to better emphasize
the example, only shape and position contribute to the similarity value. The process of
subsumption is clearly highlighted: a query with just a single aircraft retrieves images with
one aircraft, but also with more than one aircraft. Adding other aircrafts in the graphical
query correctly reduces the retrieved set. The example also points out that the system is
able to correctly deal with the presence of more than one instance of an object in images,
which is not possible in the approaches by Gudivada and Raghavan (1995) and Gudivada
(1998). On the negative side it has to be noticed that the system did not recognize the
presence of a third aircraft (indeed a strange one, the B2-Spirit) in the second image of
Figure 13-b), which was not segmented at all and considered part of the background.
The ability of the system to retrieve complex objects also in images with several other
different objects, that is with no “main shapes”, can be anyway seen in Figure 14. Here a
real image is directly submitted as query. Notice that in this case the system has to carry
out the segmentation process on the fly, and detect the composing shapes.

6. Experiments and Results
In order to assess the performance of the proposed approach and of the system implementing
it, we have carried out an extensive set of experiments on a test dataset of images. It is
well known that evaluating performances of an image retrieval system is difficult because
of lack of ground truth measures. To ease the possibility of a comparison, we adopted the
approach first proposed by Gudivada and Raghavan (1995). The experimental framework is
hence largely based on the one proposed there, which relies on a comparison of the system
performances versus the judgement of human experts.
It should be noticed that in that work test images were iconic images, which were
classified only in terms of spatial relationships between icons; in our experiments images
243

Di Sciascio, Donini & Mongiello

Figure 14: A query by example and retrieved images.

244

Structured Knowledge Representation for Image Retrieval

Figure 15: A sample of the images used in the experiments.

245

Di Sciascio, Donini & Mongiello

are real and classification has been carried out on all image features, including color, texture,
shape, scale, orientation and spatial relationships.
The test data set consists of a collection of 93 images; a sample of them is shown in
Figure 15, while the complete set is available at URL:
http://www-ictserv.poliba.it/disciascio/jair images.htm.
Images have been acquired using a digital camera, combining 18 objects, either simple
objects (i.e., a single shape) or composite ones, of variable size and color. All images had
size 1080 × 720 pixels, 24 bits/pixel. It should be noticed that actually there were more
than 18 different objects, but we considered very similar variants of an object, e.g., two
pens with a different color, as a single test object.
We selected from the test data set 31 images to be used as queries. The query set formed
two logical groupings.
The first one (namely queries 1 through 15 and queries 27, 30 and 31) had as primary
objective testing the performance of the system using as query single objects composed by
various shapes. That is, assessing the ability of the system to detect and retrieve images
containing the same object, or objects similar to the query.
The query images in the second group (remaining images in the test data set) pictured
two or more objects and they were chosen to assess the ability of the system to detect and
retrieve images according to spatial relationships existing between the objects in the query.
Obviously the difference between queries containing single objects composed by several
shapes, and queries containing two or more objects, is just a cognitive one: for our system
all queries are composite shapes. However, we observed that performances changed for the
two groupings.
We then separately asked five volunteers to classify in decreasing order, according to
their judgment, the 93 images based on their similarity to each image of the selected query
set. The volunteers had never used the system and they were only briefly instructed that
rank orderings had to be based on the degree of conformance of the database images with
the query images. They were allowed to group images when considered equivalent, and for
each query, to discard images that were judged wholly dissimilar from the query.
Having obtained five classifications, which were not univocal, we created the final ranking
merging the previous similarity rankings according to a minimum ranking criterion. The
final ranking of each image with respect to a query was determined as the minimum one
among the five available.
As an example consider the classification of Query nr.1, which is shown in Table 1.
Notice that images grouped together in the same cell have been given the same relevance.
Here Image 2 was ranked in third position by users 1,4, and 5, but as users 2 and 3 ranked
it in fourth position, it was finally ranked in position four. Notice that for image 24 the
same criterion leads to its withdrawal from ranked images. This approach limits the weight
that images badly classified by single users have on the final ranking.
Then we submitted the same set of 31 queries to the system, whose knowledge base was
loaded only with the 93 images of the test set.
The behavior of the system obviously depends on the configuration parameters, which
determine the relevance of the various features involved in the similarity computation. The
configuration parameters fed to the system were experimentally determined on a test bed of
246

Structured Knowledge Representation for Image Retrieval

user
1
2
3
4
5
final

1st
1
1
1
1
1
1

2nd
44, 88
44, 88
44, 88
44, 88
44, 88
44, 88

ranking
3rd
2, 3, 68, 80
3, 68, 80
3, 68, 80
2, 3, 68, 80
2, 3, 68, 80
3, 68, 80

4th
26
2, 26
2, 26
26
24 26
2, 26

5th
24

24

Table 1: Users rankings for query nr.1
Parameter
Fourier descriptors threshold
Circular symmetry threshold
Spatial similarity threshold
Symmetry maxima threshold
Spatial similarity weight α
Spatial similarity sensitivity f x
spatial similarity sensitivity f y
shape similarity weight β
shape similarity sensitivity f x
shape similarity sensitivity f y
color similarity weight γ
color similarity sensitivity f x
color similarity sensitivity f y
rotation similarity weight δ
rotation similarity sensitivity f x
rotation similarity sensitivity f y
texture similarity weight ²
texture similarity sensitivity f x
texture similarity sensitivity f y
scale similarity weight η
scale similarity sensitivity f x
scale similarity sensitivity f y
global similarity threshold

Value
0.98
0.99
0.30
0.10
0.30
90.0
0.40
0.30
0.005
0.20
0.11
110.0
0.40
0.11
90.0
0.40
0.07
110.0
0.40
0.11
0.50
0.40
0.70

Table 2: Configuration parameters, grouped by feature type.

approximately 500 images before starting the test phase. They are shown in Table 2. The
parameters reported here are described in the Appendix. Notice that, dealing with welldefined objects, we gave an higher relevance to shape and spatial features and a reduced
relevance to scale, rotation, color and texture.
The resulting classification gave us what was called a system-provided ranking. We then
adopted the Rnorm as quality measure of the retrieval effectiveness. Rnorm has been first
introduced in the LIVE-Project (Bollmann, Jochum, Reiner, Weissmann, & Zuse, 1985)
for the evaluation of textual information retrieval systems and it has been used in the
experiments of the above referenced paper by Gudivada and Raghavan. To make the paper
self-contained we recall here how Rnorm is defined.
Let G be a finite set of images with a user-defined preference relation ≥ that is complete
and transitive. Let ∆usr be the rank ordering of G induced by the user preference relation.
Also, let ∆sys be a system-provided ranking. The formulation of Rnorm is:
Rnorm (∆sys ) =

1
S+ − S−
· (1 +
)
+
2
Smax

where S + is the number of image pairs where a better image is ranked by the system
ahead of a worse one; S − is the number of pairs where a worse image is ranked ahead of a
+
better one and Smax
is the maximum possible number of S + . It should be noticed that the
calculation of S + , S − , and S max is based on the ranking of image pairs in ∆sys relative to
the ranking of corresponding image pairs in ∆usr .
247

Di Sciascio, Donini & Mongiello

Query nr.
†1
†2
†3
†4
†5
†6
†7
†8
†9
†10
†11
†12
†13
†14
†15
16
17
18
19
20
21
22
23
24
25
26
†27
28
29
†30
†31
Average Rnorm

Image nr.
1
2
3
4
5
6
7
10
11
12
13
14
15
18
20
25
26
27
28
31
33
34
35
36
37
39
41
42
50
78
79

Rnorm
0.92
0.92
0.93
0.95
0.99
0.94
0.93
0.93
0.95
0.74
0.60
0.84
0.83
0.99
0.91
0.89
0.80
1.00
0.74
1.00
1.00
0.99
0.91
0.89
1.00
0.99
0.93
0.98
1.00
0.88
1.00
0.92

Table 3: Rnorm values. (†indicates single-object queries)

Rnorm values are in the range [0,1]; a value of 1 corresponds to a system-provided
ordering of the database images that is either identical to the one provided by the human
experts or has a higher degree of resolution, lower values correspond to a proportional
disagreement between the two.
Table 3 shows results for each query and the final average Rnorm =0.92. Taking a closer
look at results, for the first group of queries (single compound objects) the average value
was Rnorm =0.90, and Rnorm =0.94 for the second grouping (various compound objects).
(The complete set of result for users’ ranking and system ranking is available in the online
appendix).
As a comparison, the average Rnorm resulted 0.98 in the system presented by Gudivada
and Raghavan (1995), where 24 iconic images were used both as queries and database
images, and similarity was computed only on spatial relationships between icons. We remark
here that our system works on real images and computes similarity on several image features,
and we believe that results prove the ability of the system to catch to a good extent the
users information need, and make refined distinctions between images when searching for
composite shapes. Furthermore, our algorithm is able to correctly deal with the presence
of more than one instance of an object in images, which is not possible in other approaches
(Gudivada, 1998). It is also noteworthy that, though the parameters setting has been the
object of several experiments, it cannot be considered optimal yet, and we believe that there
is room for further improvement in the system performance, as it is also pointed out in the
following paragraph.
Obviously the system can fail when segmentation does not provide accurate enough
results. Figure 16 shows results for Query 11, which was the one with the worst R norm .
Here the system not only did not retrieve all images users had considered relevant, but
248

Structured Knowledge Representation for Image Retrieval

Figure 16: Query results for query 11, which had the lowest Rnorm =0.60.
more important wrongly confused the sugar-drop with a wrist-watch, which resulted in a
false positive. As a matter of fact in various images the sweet-drops resulted not properly
segmented. Nevertheless, highly relevant images were successfully retrieved and the wrongly
retrieved one was slightly above the selection threshold.
Another observation we made was that human users, when comparing a query with a
single object, were much more driven by the color than any other feature, including the
spatial positioning. This appeared in various queries and is again clearly visible using as
example results for Query 11. Here users selected in the highest relevance class only images
with the same color sugar-drop, and gave a lower ranking to images (with sugar-drops) with
closer spatial relationships but different colors. This observation may be significant in the
related field of object recognition.
A final comment. With reference to the system behavior in terms of retrieval time, we
did not carry out a systematic testing, as it depends on several variables: number of images
in the database, number of objects in the query, but more important depth in the hierarchy
- as the search time decreases as more basic shapes are available. Limiting our analysis
to the database loaded with the 93 test images, the system required on average 12 secs to
answer a query, on a machine with Celeron 400 MHz CPU and 128 MB RAM running both
the client and the server.
249

Di Sciascio, Donini & Mongiello

7. Conclusion
We proposed a Knowledge Representation approach to Image Retrieval. We started from
the observation that current sketch-based image retrieval systems lack of a compositional
query language — that is, they are not able to handle queries made by several shapes, where
the position, orientation and size of the shapes relative to each other is meaningful.
To recover this, we proposed a language to describe composite shapes, and gave an
extensional semantics to queries, in terms of sets of retrieved images. To cope with a
realistic setting from the beginning, we also generalized the semantics to fuzzy membership
of an image to a description. The composition of shapes is made possible by the explicit
use in our language of geometric transformations (translation-rotation-scale), which we
borrow form hierarchical object modeling in Computer Graphics. We believe that this
is a distinguishing feature of our approach, that significantly extends standard invariant
recognition of single shapes in image retrieval. The extensional semantics allows us to
properly define subsumption (i.e., containment) between queries.
Borrowing also from Structured Knowledge Representation, and in particular from Description Logics, we stored shape descriptions in a subsumption hierarchy. The hierarchy
provides a semantic index to the images in a database. The logical semantics allowed us
to define other reasoning services: the recognition of a shape arrangement in an image, the
classification of an image with reference to a hierarchy of descriptions, and subsumption
between descriptions. These tasks are aside, but can speed up, the main one, which is Image
Retrieval.
We proved that subsumption in our simple logic can be reduced to recognition, and
gave a polynomial-time algorithm to perform exact recognition. Then, for a realistic application of our setting we extended the algorithm to approximate recognition, weighting
shape features (orientation, size, position), color and texture.
Using our logical approach as a formal specification, we built a prototype system using
state-of-the-art technology, and set up experiments both to assess the efficacy of our proposal, and to fine tune all parameters and weights that show up in approximate retrieval.
The results of our experiments, although not exhaustive, show that our approach can catch
to a good extent the users information need and make refined distinctions between images
when searching for composite shapes.
We believe that this proposal opens at least three directions for future research. First,
the language for describing composite shapes could be enriched either with other logicoriented connectives — e.g., alternative components corresponding to an OR in compositions — or to sequences of shape arrangements, to cope with objects with internal movements in video sequence retrieval. Second, techniques from Computational Geometry could
be used to optimize the algorithms for approximate retrieval, while a study in the complexity of the recognition problem for composite shapes might prove the theoretical optimality
of the algorithms. Finally, large-scale experiments might prove useful in understanding the
relative importance attributed by end users to the various features of a composite shape.
Acknowledgements
We wish to thank our former students G. Gallo, M. Benedetti and L. Allegretti for their
useful comments and implementations, Marco Aiello for comments on an earlier draft,
250

Structured Knowledge Representation for Image Retrieval

Dino Guaragnella for discussions on Fourier transforms, and an anonymous referee for
constructive criticism that helped us improving the paper.
This research has been supported by the European Union, POP Regione Puglia sottomisura 7.4.1 (“SFIDA 3”), by the Italian Ministry of Education, University and Research
(MIUR, ex-MURST) projects CLUSTER22 subcluster “Monitoraggio ambiente e territorio”, workpackage: “Sistema informativo per il collocamento dei prodotti ortofrutticoli
pugliesi” and by Italian National Council for Research (CNR), projects LAICO, DeMAnD,
and “Metodi di Ragionamento Automatico nella modellazione ed analisi di dominio”.

Appendix A.
In this appendix we briefly revise the methods we used for the extraction of image features.
We also describe the smoothing function Φ and the way we compute similarity for the image
features that were introduced in Section 4.2.
A.1 Extraction of Image Features
In order to deal with objects in an image, segmentation is required to obtain a partition
of the image. Several segmentation algorithms have been proposed in the literature; our
approach does not depend on the particular segmentation algorithm adopted. It is anyway
obvious that the better the segmentation, the better our system will work. In our system
we used a simple algorithm that merges edge detection and region growing.
Illustration of this technique is beyond the scope of this paper; we limit here to the
description of image features computation, which assume a successful segmentation. To
→
−
make the description self-contained we start defining a generic color image as { I (x, y) | 1 ≤
x ≤ Nh , 1 ≤ y ≤ Nv }, where Nh , Nv are the horizontal and vertical dimensions, respectively,
→
−
and I (x, y) is a three-components tuple (R, G, B). We assume that the image I has been
partitioned in m regions (ri ), i = 1, . . . , m satisfying the following properties:
• I=

S

(ri ), i = 1, 2, . . . , m

• ∀ i ∈ {1, 2, . . . , m}, ri is a nonempty and connected set
• ri ∩ rj = ∅ iff i 6= j
• each region satisfies heuristic and physical requirements.
We characterize each region ri with the following attributes: shape, position, size, orientation, color and texture.
Shape. Given a connected region a point moving along its boundary generates a complex
function defined as: z(t) = x(t) + jy(t), t = 1, . . . , Nb , with Nb the number of boundary
sample points. Following the approach proposed by Rui, She, and Huang (1996) we define
the Discrete Fourier Transform (DFT) of z(t) as:
Z(k) =

Nb
X

z(t)e

−j 2πtk
N
b

t=1

with k = 1, . . . , Nb .
251

= M (k)ejθ(k)

Di Sciascio, Donini & Mongiello

In order to address the spatial discretization problem we compute the Fast Fourier
Transform(FFT) of the boundary z(t); use the first (2Nc + 1) FFT coefficients to form a
dense, non-uniform set of points of the boundary as:
zdense (t) =

Nc
X

Z(k)e

−j 2πtk
N
b

k=−Nc

with t = 1, . . . , Ndense .
We then interpolate these samples to obtain uniformly spaced samples zunif (t), t =
0, . . . , Nunif . We compute again the FFT of zunif (t) obtaining Fourier coefficients Zunif (k),
k = −Nc , . . . , Nc . The shape-feature of a region is hence characterized by a vector of 2N c +1
complex coefficients.
Position and Size. Position is determined as the region centroid computed via moment
invariants (Pratt, 1991). Size is computed as the mean distance between region centroid
and points on the contour.
Orientation. In order to quantify the orientation of each region r i we use the same
Fourier representation, which stores the orientation information in the phase values. We
obviously deal also with special cases when the shape of a region has more than one symmetry, e.g., a rectangle or a circle. Rotational similarity between a reference shape B and
a given region ri can then be obtained finding maximum values via cross-correlation:
C(t) =

2N
Xc
2π
1
ZB (k)Zri (k) · ej 2Nc kn with t ∈ 0, . . . , 2Nc
2Nc + 1 k=0

Color. Color information of each region ri is stored, after quantization in a 112 values
color space, as the mean RGB value within the region:
Rri =

X

R(p)

G ri =

X

G(p)

B ri =

p∈ri

p∈ri

X

B(p)

p∈ri

Texture. We extract texture information for each region ri with a method based on
the work by Pok and Liu (1999). Following this approach, we extract texture features
convolving the original grey level image I(x, y) with a bank of Gabor filters, having the
following impulse response:
h(x, y) =

2
2
1
− x +y
2σ 2
· ej2π(U x+V y)
·
e
2πσ 2

where (U, V ) represents the filter location in the frequency-domain, λ is the central frequency, σ is the scale factor, and θ the orientation, defined as:
λ=

p

U2 + V 2

θ = arctan U/V

The processing allows to extract a 24-components feature vector, which characterizes
each textured region.
252

Structured Knowledge Representation for Image Retrieval

A.2 Functions for Computing Similarities
Smoothing function Φ. In all similarity measures, we use the function Φ(x, f x, f y). The
role of this function is to change a distance x (in which 0 corresponds to perfect matching)
to a similarity measure (in which the value 1 corresponds to perfect matching), and to
“smooth” the changes of the quantity x, depending on two parameters f x, f y.
Φ(x, f x, f y) =


πx

 f y +"(1 − f y) · cos( 2·f x )

 fy · 1 −

arctan[

π·(x−f x)·(1−f y)
]
f x·f y

π

#

if 0 ≤ x < f x
if x > f x

where f x > 0 and 0 < f y < 1.

The input data to the approximate recognition algorithm are a shape description D,
containing n components hck , tk , τk , Bk i and an image I segmented into m regions r1 , . . . ,rm .
The algorithm provides a measure for the approximate recognition of D in I.
The first step of the algorithm in Section 4.2 considers all the m regions the image is
segmented into and all the n components in the shape description D and finds — if any — all
the groups of n regions rj(k) satisfying the higher shape similarity with the shape components
of D. To this purpose we compute shape similarity, based on the Fourier representation
previously introduced, as vector of complex coefficients. Such measure denoted with sim ss
is invariant with respect to rotation, scale and translation and is computed as the cosine
distance between the two vectors. The similarity gives a measure in the range [0,1] assuming
the higher similarity simss = 1 for perfect matching.
Given the vectors X and Y of complex coefficients describing respectively the shape of
a region ri and the shape of a component Bk , X = (x1 , . . . , x2Nc ) and Y = (y1 , . . . , y2Nc )
P2Nc

l=1 xl yl
simss (Bk , ri ) = qP
P2Nc 2
2Nc 2
l=1 xl ×
l=1 yl

Shape Similarity. The quantity simshape measures the similarity between shapes in
the composite shape description and the regions in the segmented image.
n

simshape = Φ(max[1 − simss (Bk , rj(k) )], f xshape , f yshape )
k=1

Color Similarity. The quantity simcolor measures the similarity in terms of color
appearance between the regions and the corresponding shapes in the composite shape description. In the following formula, ∆color (k).R denotes the difference in the red color
component between the k-th component of D and the region rj(k) , and similarly for the
green and the blue color components.
∆color(k) =

q

[∆color (k).R]2 + [∆color (k).G]2 + [∆color (k).B]2

Then the function Φ takes the maximum of the differences to obtain a similarity:
n

simcolor = Φ(max{∆color (k)}, f xcolor , f ycolor )
k=1

253

Di Sciascio, Donini & Mongiello

Texture Similarity. Finally, simtexture measures the similarity between the texture
features in the components of D and in the corresponding regions.
∆texture (k) denotes the sum of differences in the texture components between the k-th
component of D and the region rj(k) and dividing by the standard deviation of the elements.
n

simtexture = Φ(max ∆texture (k), f xtexture , f ytexture )
k=1

References
Aiello, M. (2001). Computing spatial similarity by games. In Esposito, F. (Ed.), Proceedings of the Eighth Conference of the Italian Association for Artificial Intelligence
(AI*IA’99), No. 2175 in Lecture Notes in Artificial Intelligence, pp. 99–110. SpringerVerlag.
Ardizzone, E., Chella, A., & Gaglio, S. (1997). Hybrid computation and reasoning for
artificial vision. In Cantoni, V., Levialdi, S., & Roberto, V. (Eds.), Artificial Vision,
pp. 193–221. Academic Press.
Baader, F., & Hanschke, P. (1991). A schema for integrating concrete domains into concept
languages. In Proceedings of the Twelfth International Joint Conference on Artificial
Intelligence (IJCAI’91), pp. 452–457, Sydney.
Bach, R., Fuller, C., Gupta, A., Hampapur, A., Horowitz, B., Humphrey, R., Jain, R.,
& Shu, C. (1996). The Virage image search engine: an open framework for image
management. In Storage and Retrieval for Image and Video Databases, Vol. 2670, pp.
76–87. SPIE.
Bertino, E., & Catania, B. (1998). A constraint-based approach to shape management in
multimedia databases. MultiMedia Systems, 6, 2–16.
Bollmann, P., Jochum, F., Reiner, U., Weissmann, V., & Zuse, H. (1985). The LIVEProject-Retrieval experiments based on evaluation viewpoints. In Proceedings of the
8th Annual International ACM SIGIR Conference on Research and Developement in
Information Retrieval (SIGIR ’85), pp. 213–214. ACM, New York.
Brooks, R. (1981). Symbolic reasoning among 3-D models and 2-D images. Artificial
Intelligence, 17, 285–348.
Calvanese, D., Lenzerini, M., & Nardi, D. (1998). Description logics for conceptual data
modeling. In Chomicki, J., & Saake, G. (Eds.), Logics for Databases and Information
Systems, pp. 229–264. Kluwer Academic Publisher.
Cardoze, D., & Schulman, L. (1998). Pattern matching for spatial point sets. In Proceedings of the Thirtyninth Annual Symposium on the Foundations of Computer Science
(FOCS’98), pp. 156–165, Palo Alto, CA.
Carson, C., Thomas, M., Belongie, S., Hellerstein, J. M., & Malik, J. (1999). Blobworld: A
system for region-based image indexing and retrieval. In Huijsmans, D., & Smeulders,
A. (Eds.), Lecture Notes in Computer Science, Vol. 1614, pp. 509–516. Springer-Verlag.
Celentano, A., & Di Sciascio, E. (1998). Features integration and relevance feedback analysis
in image similarity evaluation. Journal of Electronic Imaging, 7 (2), 308–317.
254

Structured Knowledge Representation for Image Retrieval

Chandra, A., & Harel, D. (1980). Computable queries for relational databases. Journal of
Computer and System Sciences, 21, 156–178.
Chang, S., Shi, Q., & Yan, C. (1983). Iconic indexing by 2D strings. IEEE Transactions
on Pattern Analysis and Machine Intelligence, 9 (3), 413–428.
Chew, L., Goodrich, M., Huttenlocher, D., Kedem, K., Kleinberg, J., & Kravets, D. (1997).
Geometric pattern matching under euclidean motion. Computational Geometry, 7,
113–124.
Cox, I., Miller, M., Minka, T., & Papathomas, T. (2000). The bayesian image retrieval
system, PicHunter. IEEE Transactions on Image Processing, 9 (1), 20–37.
Di Sciascio, E., Donini, F. M., & Mongiello, M. (2000). A Description logic for image
retrieval. In Lamma, E., & Mello, P. (Eds.), AI*IA 99: Advances in Artificial Intelligence, No. 1792 in Lecture Notes in Artificial Intelligence, pp. 13–24. Springer-Verlag.
Di Sciascio, E., & Mongiello, M. (1999). Query by sketch and relevance feedback for contentbased image retrieval over the web. Journal of Visual Languages and Computing,
10 (6), 565–584.
Donini, F., Lenzerini, M., Nardi, D., & Schaerf, A. (1996). Reasoning in description logics.
In Brewka, G. (Ed.), Foundations of Knowledge Representation, pp. 191–236. CSLIPublications.
Edelmann, S. (1999). Representation and Recognition in Vision. The MIT Press.
El-Kwae, E., & Kabuka, M. (1999). Content-based retrieval by spatial similarity in image
databases. ACM Transactions on Information Systems, 17, 174–198.
Flickner, M., Sawhney, H., Niblak, W., Ashley, J., Huang, Q., Dom, B., Gorkani, M., Hafner,
J., Lee, D., Petkovic, D., Steele, D., & Yanker, P. (1995). Query by image and video
content: The QBIC system. IEEE Computer, 28 (9), 23–31.
Foley, J., van Dam, A., Feiner, S., & Hughes, J. (1996). Computer Graphics. Addison
Wesley Publ. Co., Reading, Massachussetts.
Fuhr, N., Gövert, N., & Rölleke, T. (1998). DOLORES: A system for logic-based retrieval
of multimedia objects. In Proceedings of the 21st Annual International ACM SIGIR
Conference on Research and Developement in Information Retrieval (SIGIR ’98), pp.
257–265, Melbourne, Australia.
Gevers, T., & Smeulders, A. (2000). Pictoseek: Combining color and shape invariant features
for image retrieval. IEEE Transactions on Image Processing, 9 (1), 102–119.
Gudivada, V. (1998). θR-string: A geometry-based representation for efficient and effective
retrieval of images by spatial similarity. IEEE Transactions on Knowledge and Data
Engineering, 10 (3), 504–512.
Gudivada, V., & Raghavan, J. (1995). Design and evaluation of algorithms for image
retrieval by spatial similarity. ACM Transactions on Information Systems, 13 (2),
115–144.
Haarslev, V., Lutz, C., & Möeller, R. (1998). Foundations of spatioterminological reasoning with description logics. In Proceedings of the Sixth International Conference on
Principles of Knowledge Representation and Reasoning (KR’98), pp. 112–123.
255

Di Sciascio, Donini & Mongiello

Hacid, M.-S., & Rigotti, C. (1999). Representing and reasoning on conceptual queries over
image databases. In Proceedings of the Twelfth International Symposium on Methodologies for Intelligent Systems (ISMIS’99), No. 1609 in Lecture Notes in Artificial
Intelligence, pp. 340–348, Warsaw, Poland. Springer-Verlag.
Hartman, J., & Wernecke, J. (1996). The VRML 2.0 Handbook. Addison-Wesley.
Hirata, K., & Kato, T. (1992). Query by visual example. In Pirotte, A., Delobel, C., &
Gottlob, G. (Eds.), Advances in Database Technology — Proc. 3rd Int. Conf. Extending Database Technology, EDBT, Vol. 580 of Lecture Notes in Computer Science, pp.
56–71. Springer-Verlag.
Jacobs, C., Finkelstein, A., & Salesin, D. (1995). Fast multiresolution image querying. In
Proceedings of the 22nd Annual Conference on Computer Graphics and Interactive
Techniques (SIGGRAPH ’95), pp. 277–286.
Jahne, B., Haubecker, H., & Geibler, P. (1999). Handbook of Computer Vision and Applications. Academic Press.
Ma, W., & Manjunath, B. (1997). NETRA: A toolbox for navigating large image database.
In Proceedings of the IEEE International Conference on Image Processing (ICIP ’97),
Vol. 1, pp. 568–571, Santa Barbara.
Marr, D. (1982). Vision. W.H. Freeman and Co., Oxford.
Meghini, C., Sebastiani, F., & Straccia, U. (2001). A model of multimedia information
retrieval. Journal of the ACM, 48 (5), 909–970.
Moeller, R., Neumann, B., & Wessel, M. (1999). Towards computer vision with description
logics: some recent progress. In Proceedings of the IEEE Integration of Speech and
Image Understanding, pp. 101–115.
Nebel, B. (1990). Reasoning and Revision in Hybrid Representation Systems. No. 422 in
Lecture Notes in Artificial Intelligence. Springer-Verlag.
Niblak, W., Barder, R., Equitz, W., Flickner, M., Glasman, E., Petkovic, D., Yanker, P.,
& Faloustos, C. (1993). The QBIC project: Querying images by content using color,
texture, and shape. In Storage and Retrieval for Still Image and Video Databases,
Vol. 1980, pp. 173–182. SPIE.
Paquet, E., & Rioux, M. (1998). A content-based search engine for VRML databases.
In Proceedings of IEEE International Conference on Computer Vision and Pattern
Recognition (CVPR’98), pp. 541–546, Santa Barbara, CA.
Picard, R., & Kabir, T. (1993). Finding similar patterns in large image databases. In
Proceedings of the IEEE International Conference on Acoustics Speech and Signal
Processing (ICASSP ’93), pp. 161–164, Minneapolis, MN.
Pirri, F., & Finzi, A. (1999). An approach to perception in theory of actions: part 1. In
Linkoping Electronic Articles in Computer and Information Science, No. 41. Linkoping University Electronic Press.
Pok, G., & Liu, J. (1999). Texture classification by a two-level hybrid scheme. In Storage
and Retrieval for Image and Video Databases VII, Vol. 3656, pp. 614–622. SPIE.
256

Structured Knowledge Representation for Image Retrieval

Pratt, W. (1991). Digital Image Processing. J. Wiley & Sons Inc., Englewood Cliffs, NJ.
Reiter, R., & Mackworth, A. (1989). A logical framework for depiction and image interpretation. Artificial Intelligence, 41 (2), 125–155.
Reiter, R. (1980). Equality and domain closure in first-order databases. Journal of the
ACM, 27 (2), 235–249.
Rui, Y., Huang, T., & Mehrotra, S. (1997). Content-based image retrieval with relevance
feedback in MARS. In Proceedings of the IEEE International Conference on Image
Processing (ICIP ’97), pp. 815–818.
Rui, Y., She, A., & Huang, T. (1996). Modified Fourier descriptors for shape representation
- a practical approach. In Proceedings of 1st Workshop on Image Databases and
Multimedia Search, Amsterdam.
Sanfeliu, A., & Fu, K. (1983). A distance measure between attributed relational graphs for
pattern recognition. IEEE Transactions on Systems, Man, and Cybernetics, 13 (3),
353–362.
Smith, J., & Chang, S. (1996). VisualSEEK: a fully automated content-based image query
system. In Proceedings of the fourth ACM International Conference on Multimedia
(Multimedia’96), pp. 87–98.
Straccia, U. (2001). Reasoning within fuzzy description logics. Journal of Artificial Intelligence Research, 14, 137–166.
Tagare, H., Vos, F., Jaffe, C., & Duncan, J. (1995). Arrangement: A spatial relation between
parts for evaluating similarity of tomographic section. IEEE Transactions on Pattern
Analysis and Machine Intelligence, 17 (9), 880–893.
Ullman, J. D. (1988). Principles of Database and Knowledge Base Systems, Vol. 1. Computer
Science Press, Potomac, Maryland.
Woods, W. A., & Schmolze, J. G. (1992). The KL-ONE family. In Lehmann, F. W. (Ed.),
Semantic Networks in Artificial Intelligence, pp. 133–178. Pergamon Press. Published
as a special issue of Computers & Mathematics with Applications, Volume 23, Number
2–9.
Yen, J. (1991). Generalizing term subsumption languages to Fuzzy logic. In Proceedings of
the Twelfth International Joint Conference on Artificial Intelligence (IJCAI’91), pp.
472–477.
Zadeh, L. (1965). Fuzzy sets. Information and Control, 8, 338–353.

257

	
 

 
  !"$#%&')(*,+.-//-10321-46521*4

789:; <=/*1>/"(?A@9
  &'<B/*1>/-

CEDGFH;IKJML1NOIPJQNORTS)L8UWVPX1HZY[NOIP\]H^V_FM`PaOXcbedaOVPfPJhg
FfKHiY[NjUWVkX1H]DlLFnmoNORcpq`KX1H;JraOIKstY[NOIPJ3FudvaOL1IwFMJ

xzy|{%}~8z{%}$k{3uy

n%uuw3w

q{3y~8{%$ycqhM}]y|

uM%Mw3w

%¡ =¢k¢¤£6¥%¦, =§©¨«ªu¢¬®­"¯h°±A°_²³|´=µ,¶¸·
¹ºn¹¸»¸¼

¢¾½A¿|ÀÁ´ÂÂÃ´²¯,¥Ä¶¸´6ÅPÆ	¯Ç3²6·	¿ÉÈ´

ÊÌË=Í¸ÎÏÐzÑÉÎ
§ÉÃÒÓÁÔÂÕ´BÈ½	¿ÉÈ´®ÁÉÀ³|·	Â¸Ö¸²¡·6Á|×ØÓÙAÚ6Û^Ü1Ý¸Þnßà.áÛÚ6Û8áwÙ¸ßMâ¡ã|Û;ä¸ÛÚ6ÞÛ8åÝ¸ænç)ÝèßâväÞ|Ý	é;åÕÛ"áê¸Û]Ú¡Û8ëÚ6Û8ß¡ÛÞâ6ÙAâ¡àìÝ¸Þ
æÝèÚ¡çíÙAåìà.ßçíßî|ïàÕåÕâhï|ënÝèÞKðÝ	é^Ùñ ßzç)ÝáÛåòvóÓÛ8Ù¸ß¡Ý¸Þ|àÕÞêôàìÞíâ6ãàìßhç)ÝáÛåÔÜÙ¸ÞíînÛ,Û1õëÚ6Û8ß6ßÛ"á)îö)ÙôêèÚ6Ù¸ëã
ãÝèç)Ý¸ç)Ý¸Ú6ëãà.ßç÷Ü8ÙAåìåÕÛ"áøëÚ6ÝAùÛ"Üâ¡àìÝ¸Þuúzé;ãÝèß¡ÛPß¡ÛçíÙ¸Þèâ6àìÜ8ßjà.ß)ï|ß¡ï|ÙAåìåìöûêèàÕüèÛÞýàÕÞþâ¡ÛÚ6çíßGÝAæëÉÝèß¡àâ6àÕüèÛ¸ú
ÜÝ¸Þ	ùïÞnÜâ¡àìü¸ÛèúnÛõàìßâ¡Û8Þèâ6àìÙ¸åM
ÿ 
ò  ÛwëÚ¡Û"ßÛ8ÞâãÛÚ6ÛjÙlæÙAç)àÕåìökÝAæzÛ1õâ6ÛÞ|ß¡àÕÝèÞ|ßÓÝ¸æzâ¡ãà.ß,çGÝáÛ8åúÔî|ÙèßÛ"á
ÝèÞø²³ÂÕ´1ØwÙAÞ|áýÈ6½A¿ØÀ²¡·	Ã¿nÀØúÉä¸ÛÛ8ëàìÞêlê¸ÚÙAë|ã ãÝ¸ç)Ý¸ç)ÝèÚ¡ëã|àìß¡çqÙèß;â6ãÛwînÙ¸ß¡àìÜôÝèënÛ8Ú6ÙAâ¡àìÝ¸Þ%
ò  ÛjæÝÜ1ï|ß
ÝèÞâ¡ã|ÛwæÝèÚ¡çíÙ¸åvá
Û |ÞàÕâ¡àìÝ¸Þnß,Ý¸æâ¡ã|Û)á
à 	ÔÛÚ6ÛÞâôç)ÝáÛå.ß,Ýèîâ6Ù¸àÕÞ|Û8á3ú3àìÞ|Ü1åìï|áàìÞêKâ¡ãÛ8àÕÚôÝèënÛ8Ú6ÙAâ¡àìÝ¸Þ|Ù¸åß¡
Û 
çíÙAÞâ6àìÜ8ßÙAÞ|áGÚ6Ûå.Ù	â6àÕÝèÞ|ßã|àÕë|ßé;àÕâ¡ãl
ÿ ú¸Ù¸Þ|ájé]ÛÓÙAÞnÙAåì
ö 8Û]â¡ãÛáÛ8Ü1à.áÙ¸îàÕåìàÕâöjÙAÞ|á)ÜÝ¸ç)ëåìÛ1õàâöwÝAæÉâ¡ãÛ
Ùèß¡ß¡ÝÜ1à.Ù	â¡Û"á_ë|Ú¡ÝèîåÕÛ8çí
ß Ü1ÝèÞ|ß¡àìßâ¡Û8Þ|Ü1ö_Ù¸Þ|ákáÛ8áï|Üâ6àÕÝè
Þ 
ò ,ßÓß¡ÝÝèÞPÙèß^Ú¡ï|åÕÛ"ßÓÙAÚ6Û,àìÞü¸ÝèåÕüèÛ8áKàÕÞkÚ6Û8Ù¸ß¡Ý¸
Þ 
àìÞêèß8úâ¡ãÛ"ßÛ=ëÚ6Ý¸îåìÛçíß]ÙAÚ6ÛÞÝ¸â^áÛ8Ü1à.áÙ¸îåÕÛèúîïâ^éhÛ=Û1õãàìîàÕâ^ÙGÜ1ÝèÞ|áàÕâ¡àìÝ¸ÞlïÞnáÛÚ^é;ãà.Üãlâ6ãÛö)æÙ¸åÕåÔàìÞ
â6ãÛ)ënÝèåÕöÞÝèçGà.ÙAåvãàìÛÚÙAÚÜãö¸
ò ^ã|Û8ß¡ÛwÚ6Û8ß¡ïåÕâ6ßBÛ1õâ6ÛÞ|áûÙAÞ|á Ü1ÝèçGë|åÕÛâ¡ÛGâ¡ãÛ)ÝèÞÛ8ßBÙAåìÚ6Û8Ù¸áö ëïîåìàìß¡ãÛ"á
îö)â¡ã|ÛBÙ¸ïâ¡ã|Ý¸Úß
ò  ÝèÚ¡Û8Ý	ü¸ÛÚhéhÛBß¡ößâ¡Û8çíÙ	â¡à.ÜÙ¸åÕåìöíßâ6ï|áöíâ6ãÛôÜ1ÝèçGë|åÕÛõàÕâöíÝAævßÝèç)Û,ë|Ù¸Úâ6àìÜïå.ÙAÚ^ÜÙ¸ß¡Û8ß
Ýèîâ6Ù¸àÕÞÛ"á_îöKÚ¡Û"ßâ6Ú¡à.Üâ6àÕÞêwâ¡ã|ÛBæÝ¸Ú6çQÝAæzÜ1ÝèÞ|ßâ6Ú6Ù¸àÕÞâß]Ù¸Þ|
á 	Ý¸Ú^Ú¡ï|åÕÛ"ßò

 ÎÏ!"ÑÉÎ#$ 
%&('*),+.-0/214357698:3-0;*<>=$%?@<BA;43,C+ED+,+.'F-08&(-G&9<:+,HI3(<J3>K'*&ML5N+,HO6+P8+.-08+,<+.'Q/:3/2RN&('S3'*HT8+M3(<&('0RU'06
V &H0+.5$W V 3/2;*+ V 3/2RN)M35U5UXZY[&(10'*H0+,HZD&(/2;\&('5N&(69RN),<]3'*HZ698:3-0;\/2;*+,&(82XF=$^&ML_3OWa`Mb9cdAfehg_;*&(1069;\/2;*+.X
;43,C+iD+,+.' V 3RU'05UXj<2/21*HORN+,Hk3(<l3I698:3-0;0RN)M35_RU'Q/+.8mY$3(),+\Yn&(8>5N&(69RN),<l&(8l3(<Z3IHORo3698:3 VV 3/2RN)T<2XO<2/+ V
&Y5N&(69RN),<I=pYn&(8ZRU'*<2/:3'*),+9Wq<+,+srt+.8 V +.5URU'06+.8MWu`Mb9b9vOWhY[&(8Z6+.'*+.8:35%?E<+,w10RUC(35N+.'/Z/&yx{zu|}AfWh/2;*+.RU8
698:3-0;O~$/2;*+,&(8+./2RN)uYn&(10'*H*3/2RN&('*<];43MC+D+,+.'5N+,<:<qRU'QC+,</2RU6Q3/+,He]y&9<2/qL&(82KO<RU'/2;0RN<_38+M3>38+5UR V RU/+,H
/&TfpaNl(a:G[O99mBafWG&(8@BaN9mBaT=$^&L3OW{`Mb9cd*%;*+.RU'S1069'0RN+.8MW}`Mb9b9AfW4L;0RN):;
),&(828+,<2-&('*HI/&/2;*+P-G&9<2RU/2RUC+9Wa),&('(10'*)./2RUC+l3'*HI+fORN<2/+.'Q/2Ro35Y8:36 V +.'/u&Y!x}zu|LRU/2;*&(10/JY[10'*)./2RN&('*<Me
g_;0RN< V &H0+.57;43(</2;08+,+EY[10'*H*3 V +.'Q/:35h);438:3()./+.82RN</2RN),<M
`9eJ&(DO2+,)./<38+\D0RU-4382/2RU/+yUQfU(2B4t='*&H0+,<>8+.-08+,<+.'/f4[[[nBT3'*H fU9[[90iD+./¡L+,+.'
/2;*+,<:+P+.'Q/2RU/2RN+,<BAf
Oe8+M3(<:&('0RU'06<38+@D43(<+,H&('F698:3-0;O~$/2;*+,&(8+./2RN)¢&(-+.8:3/2RN&('*<MW08+.5UXRU'06&('£3lKRU'*HI&Yh698:3-0;I;*& V &~
V &(82-0;0RN< V )M35U5N+,Hsa2m¤M2,[n(h
¥ eRU/lRN<¢5N&(69RN)M35U5UXtYn&(10'*H0+,HWh8+M3(<&('0RU'06<ZDG+.RU'06y<&(10'*H¦3'*Hk),& V -05N+./+sLPe 8Me /Meyx}zu|§<+ V 3'/2RN),<MW
1*<1435U5UXsDXiL_3,XI&Y{/2;*+@/28:3'*<25o3/2RN&('£)M35U5N+,Hy¨Ee
 3RU'j+fO/+.'*<2RN&('*<¢&Y/2;*+\<R V -05N+\698:3-0;*< V &H0+.5$W{K+,+.-0RU'06698:3-0;;*& V & V &(82-0;0RN< V D43(<:+,Ht&(-O~
S
+.8:3/2RN&('*<@3'*H£<:&(10'*Hy3'*Hy),& V -05N+./+Z<+ V 3'Q/2RN),<MW38+ip©,ffaBlBNBF=$?@&9<2;yªr«1QL&('06<+9W!`Mb9b9vO
^O35UC93/]¬1069'0RN+.8MWa`Mb9b9­O^O35UC93/MW*`Mb9b9cA!3'*HTGB.¡2E(2B4¢=$%;*+.RU'7W1069'0RN+.8MWQ®^R V &('*+./MWa`Mb9b9cO
¯ 8+.5U5N+.8MWO£1069'0RN+.8MWO°%;*+.RU'7W`Mb9b9cAfY[&(8_QfGf2(]±_²+,w10RUC935N+.'Q//&¢x}zu|]WO3'T&(82RU69RU'435H0+,HO1*)./2RN&('
³

-//-]Éu&&4´	<	6 ô<_µB!1¶z"ì:Ó"·|9
  &'"&¸|M
 
 !'&M&N¹1<º¸

»

3M¼¾½øuM%

<2XO<2/+ V =[¿@+.8HORU5N+,<MW0`Mb9bÀ9A}),& V D0RU'*+,<]3'435UX/2RN)/:3D05N+M31O¢LRU/2;Z/2;*+_<2R V -05N+]698:3-0;*<h-08&2+,)./2RN&('7eq^& V +
KRU'*Hj&Y¢(*f[2(pai;43,C+sD+,+.'j-08&(-&9<+,H/&C935URNH*3/+s3IK'*&L5N+,HO6+sD43(<+i),& V -&9<+,H&Y<2R V -05N+
698:3-0;*<¢=[£RU'*+M31£Á£RN<<:3(&(10R$W7`Mb9bÀ4ÂRUD0RN+9W0ÃE3(+ VV +.825NÄ9WaÅ|7&(RN<+M317W7`Mb9b9cAfe
rt+-08+,<+.'Q/;*+.8+3uY$3 V RU5UXZ&Y7+fO/+.'*<2RN&('*<]&Y/2;*+J<R V -05N+J698:3-0;*< V &H0+.5$ehg_;*+),& VV &('i698&(10'*H
Yn&(8/2;*+,<+F+f/+.'*<RN&('*<RN<Z/2;43/&(DO2+,)./<\38+j(U(2jBGU(mf48+.-08+,<+.'/2RU'06I©,,fWfNB&(8
(*f[2(pafWq3'*Hk&(-G+.8:3/2RN&('*<38+iD43(<+,Hj10-&('k-08&m+,)./2RN&('7e«?uRUC+.'Æ3IK'*&ML5N+,HO6+sD43(<+sÇÈ3'*H¦3
<2R V -05N+698:3-0;ÉÁ=L;0RN); V 3MX>8+.-08+,<+.'/!3uw1*+.82XW3J6&35$W4e,e,e,W9H0+.-G+.'*HORU'06@&('Z/2;*+3-0-05URN)M3/2RN&('aAfW9/2;*+
Q29O,[n(¢a2QfNfª3(<2KO<{L;*+./2;*+.8ÉÊ)M3'lD+_H0+,HO1*),+,HlY8& V ÇehË),),&(8HORU'06@/&u/2;*+KRU'*H0<h&YG&(DO2+,)./<
),&('*<2RNH0+.8+,HRU'ÇWHORÍÌ+.8+.'Q/8+M3(<&('0RU'06 V &H0+.5N<38+&(D0/:3RU'*+,HW),& V -&9<2RU'06¢/2;*+ÎÏ£Y$3 V RU5UXe!g_;*&(1069;
<2R V RU5o38q'*&(/2RN&('*<&Y82105N+,<3'*H),&('*</28:3RU'Q/<)M3'\DG+Yn&(10'*H\RU'/2;*+%?¬5URU/+.8:3/2108+9W/2;*+.RU8]),& V D0RU'43/2RN&('
RU'\8+M3(<&('0RU'06<];43(H'*+.C+.8]D+,+.'\<2/21*HORN+,He]z'*+RU'/+.8+,<2/&Y&(1083-0-08&3():;i/2;1*<q8+,<2RNH0+,<]RU'-08&MCRNHORU'06
3l10'0RÍY[XRU'06Y[8:3 V +.L&(82KF),& V D0RU'0RU'06i82105N+,<3'*H),&('*<2/28:3RU'Q/<RU'IHORÍÌ+.8+.'/L_3,XO<Me
Ð 'F/2;0RN<J-43-+.8MW0L+@Y[&).1*<J&('I/2;*+EYn&(8 V 35H0+fÑ*'0RU/2RN&('*<&Yh/2;*+,<:+ V &H0+.5N<MW*RU'*).5U1*HORU'06/2;*+.RU8&(-+.8:3º~
/2RN&('435<+ V 3'Q/2RN),<3'*Hi8+.5o3/2RN&('*<;0RU-*<LRU/2;Fx}zu|qW*3'*HsL+E<2/21*HOX\/2;*+EH0+,).RNH*3D0RU5URU/XF3'*HT),& V -05N+fORU/¡X
&Y!/2;*+.RU8u3(<<:&).Ro3/+,HIH0+,).RN<RN&('-08&(D05N+ V <MW4'43 V +.5UXI),&('*<2RN<2/+.'*).X3'*HIH0+,HO1*)./2RN&('7eg_;*+,<+>8+,<2105U/<+f~
/+.'*HÒ3'*HÆ),& V -05N+./+I/2;*+F&('*+,<\35U8+M3(HOX¦-010D05URN<2;*+,H¦DX/2;*+I310/2;*&(8<y=[Ó36+./Ô1069'0RN+.8MW_9Õ9ÕO`Afe
g_;*&(1069;yDG&(/2;y),&('*<2RN<2/+.'*).X£3'*H£H0+,HO1*)./2RN&('«38+>10'*H0+,).RNH*3D05N+lRU'/2;*+ V &9<2/6+.'*+.8:35 V &H0+.5{&Yq/2;0RN<
Y$3 V RU5UXWL+\;43(Hj35U8+M3(HOX«1*<+,H3FH0+,).RNH*3D05N+i<10D*<+./>&Y_82105N+,<>/&I<:&(5UC+/2;*+TÖG×Ø.Ù{Ú*ÛÜ7Ø.Ý:ÞP-08&(D05N+ V W
3T/+,<2/m~$D+,Ht-08&(-&9<+,H«RU'j/2;*+\K'*&ML5N+,HO6+T3(),wQ10RN<2RU/2RN&('k),& VV 10'0RU/Xß=[Ó36+./MWh?E+.'*+,</MW}à£1069'0RN+.8MW
`Mb9b9bAfeÒrt+I-08+,<+.'Q/\;*+.8+FY[&(8/2;*+TÑ*8</\/2R V +3SH0+./:3RU5N+,Hß3'435UXO<2RN<\&Y@),& V -05N+fORU/¡XÆL;*+.'ÒL+I8+f~
<2/282RN)./_/2;*+uK'*&L5N+,HO6+@D43(<+u/&l/2;0RN<KRU'*HT&Y}82105N+,<P=[)M35U5N+,HS2(@Bf[fn,¡2T82105N+,<BAfehrt+@35N<&Z<2/21*HOX
-4382/2RN).105o38)M3(<:+,<J&Yh),&('*</28:3RU'Q/<Me
Ð 'Æ<+,)./2RN&('ÒD43(<RN)FH0+fÑ*'0RU/2RN&('*<3'*Hk8+,<2105U/<\3DG&(10/\<R V -05N+i698:3-0;*<i38+i8+,)M35U5N+,HeÆ^+,)./2RN&(' ¥
0- 8+,<+.'/<3'I&MC+.82CRN+.Lá&Yh/2;*+@Î_ÏtY$3 V RU5UXe Ð 'F-4382/2RN).105o38MW*L+P+f-05o3RU'L;QXsL+P),&('*<2RNH0+.8698:3-0;0RN)M35
Yn+M3/2108+,<J&Y/2;*+@<2R V -05N+E698:3-0;*< V &H0+.573(<+,<<+.'/2Ro35Y[&(8_K'*&ML5N+,HO6+ V &H0+.5URU'063'*HT-&(RU'Q/J&(10/_/2;43/
/2;*+,<+T-08&(-+.82/2RN+,<i38+T-08+,<+.82C+,HÒRU'Ò/2;*+TÎÏâY$3 V RU5UXe Ð 'Æ'*+fO/\<+,)./2RN&('*<L+I<2/21*HOXk/2;*+IHORÍÌ+.8+.'/
V + V D+.8<s&YE/2;*+IYn3 V RU5UXe¬ã105N+,<i38+IRU'/28&HO1*),+,HßRU'ß<:+,)./2RN&(' d*W_),&('*<2/28:3RU'Q/<sRU' <:+,)./2RN&('ÊvOW3'*H
<+,)./2RN&('t­i<2/21*HORN+,< V &H0+.5N<E),& V D0RU'0RU'06F82105N+,<@3'*HS),&('*<2/28:3RU'/<Me@Ë<u<&&('S3(<82105N+,<@38+lRU'QC&(5UC+,HSRU'
8+M3(<&('0RU'06<MW/2;*+\3(<:<&).Ro3/+,HSH0+,).RN<2RN&('S-08&(D05N+ V <>38+l'*&(/@H0+,).RNH*3D05N+9WD010/@L+l+fO;0RUD0RU/>3i),&('*HORU/2RN&('
=pÑ*'0RU/++fO-43'*<2RN&('Ê<+./<BAl10'*H0+.8iL;0RN);¬),& V -010/:3/2RN&('*<T35UL_3,XO<i</&(-7e Ð 'Ò/2;*+I-4382/2RN).105o38T)M3(<+I&Y
2(Q2B.[Bn,¡2y82105N+,<Wa/2;*+Z),& V -05N+fORU/¡Xy&Y]/2;*+,<+¢-08&(D05N+ V <uYn35U5{RU'Q/&s/2;*+¢-G&(5UX'*& V Ro35h;0RN+.8:38);QXe
^+,)./2RN&('sÀRN<!H0+.C&(/+,H/&u/2;*+,<+H0+,).RNH*3D05N+J)M3(<:+,<Me Ð '<+,)./2RN&('cOW98+.5o3/2RN&('*<2;0RU-*<qLRU/2;&(/2;*+.8!L&(82KO<q38+
+,<2/:3D05URN<2;*+,He Ð 'I-4382/2RN).105o38L+P-&(RU'Q/&(10/35U6&(82RU/2; V RN)>),&('0'*+,)./2RN&('*<LRU/2;),&('*<2/28:3RU'/<:3/2RN<mY$3()./2RN&('
-08&(D05N+ V <«=$%^ ¯ Ai3'*H <2;*&Lä/2;43/s/2;*+I-08&(D05N+ V &Y@):;*+,)KRU'06¦/2;*+),&('*<2RN<2/+.'*).XÒ&Y>3tK'*&L5N+,HO6+
D43(<+¢),& V -G&9<+,Hy&Yq<2R V -05N+¢698:3-0;*<u3'*Hy),&('*<2/28:3RU'Q/<=Î_Ï7å~¡),&('*<2RN</+.'*).X0AJRN<+,w10RUC(35N+.'//&i/2;43/&Y
H0+,).RNHORU'06/2;*+@),&('*<RN<2/+.'*).XF&Y!3 V RÍ0+,H£%^ ¯ =[ Ðæuç Â~^Ë!g@WIxa38269RN+.8MW4|3'06*W4¾^);0RN+fW7`Mb9b9­Afe
èh\é

ÐzÍ(#ÑtêzÎ#$

 Í ëkÎìqíîuïñðà!qí4ò

rt+8+,)M35U5*RU'/2;0RN<<+,)./2RN&('\D43(<2RN)_'*&(/2RN&('*<3DG&(10/<2R V -05N+J),&('*),+.-0/214354698:3-0;*<=$^&ML3OW`Mb9cd*0%;*+.RU'i
£1069'0RN+.8MW`Mb9b9Afe{g_;*+,<+]698:3-0;*<}38+]),&('*<RNH0+.8+,H¢3(<7/2;*+qK+.82'*+.5Yn&(8 V &9<2/K'*&ML5N+,HO6+8+.-08+,<+.'/:3/2RN&('
Yn&(8 V 35URN< V <JD010RU5U/10-&('y^&ML_3Oóô<L&(82KGe]g_;*+.XT38+>35N<:&Z/2;*+@D43(<2RN) V &H0+.5Y[&(8/2;*+PÎÏY$3 V RU5UXe
õöM÷

 úûM]ü|è9ýM.þtûMÿ=uèwu«úûMÔÔM3
øù F

	
 y ;}]¸}$k{%}

uA{Ô¸M}h

Ó3(<2RN)Z&('Q/&(5N&(69RN)M35qK'*&ML5N+,HO6+ZRN<E+.'*),&H0+,HSRU'S3s<2/2821*)./2108+)M35U5N+,H«3BO9fnePxa3()./21435!K'*&L5N+,HO6+
RN<l+.'*),&H0+,HjRU'Q/&jBGUZ(2B4QS=$^0?E<BAfWhH0+fÑ*'*+,HLRU/2;8+,<-G+,)./¢/&£3F69RUC+.'¦<210-0-&(82/MeIË ^0?àRN<Z3
D0RU-4382/2RU/+5o3D+.5U5N+,HZ698:3-0;=[<2/282RN)./25UX¢<-G+M3KRU'06*W9RU/hRN<q3lZÍ[Í9mBaW<2RU'*),+_/2;*+.8+)M3'D+_<+.C+.8:35*+,HO6+,<
D+./¡L+,+.'S/L&i'*&H0+,<BAfeuz'*+>).5o3(<<u&Yq'*&H0+,<8+.-08+,<+.'Q/<@+.'/2RU/2RN+,<MWa/2;*+¢&(/2;*+.8u).5o3(<<8+.-08+,<:+.'Q/<u8+.5o3º~
/2RN&('*<2;0RU-*<]DG+./L+,+.'s/2;*+,<+J+.'Q/2RU/2RN+,<
e &H0+,<]38+5o3D+.5U5N+,H\DX+.5N+ V +.'Q/<_&YG/2;*+<210-0-&(82/Me ç 5N+ V +.'Q/:382X
8+M3(<&('0RU'06<u38+P),& V -010/+,HFDQXI3l698:3-0;I;*& V & V &(82-0;0RN< V )M35U5N+,HsGmm¤M2,[n(4e
Î "%$'&)(+*,&.-+*0/1*324657&)( (a8
 &.-Å(T	 9]

 y;}]¸}  ÓM¸ <10-0-G&(82/soT ![aUZ#
O(.[n(p;:j(2Qf2 <q*[¡i,,>=PB$0,['?(f@:Æm©¬),&('*),+.-0//¡X-G+,<y(a¦8+.5o3/2RN&('Æ/X-+,<A5B&.-ªpP0(!
[[[[(2S4$yB*BM.C&E-8
D F6F6F &H- G m©s2.Í9[n(Ê	::*BTm©F(f	:JI F6F6FLK 2B¡02,[M?f;:ON KQP ISRT5VU9]
fNff4l2©>(o.[pG,qf0f,.¢(¢a(O(2QfNW5YX£(mf:Z(Z&)(á(a[&)-®92ZQ.a9¡2IS:Z\
N^]\Q_2(*¢9`
 ]ßolif0,	 ::*\mY
© _R5+/Åp¢O¢M.Jm©tRU'*HORUCRNHO1435 V 382K+.8A< 5Y&.(a=&.-â(Gb
 /
(PO( 9!p,s(pp¤,(4c 5 2Òp\BQap>©f2(#
 /à$8
 &)(d5eifa9¡FS :gfS0s6+.'*+.82RN) V 382K+.L8 =
9hOfC
 fgi h /j5  0(f[n(h(mfZ9k
 /JlmTfTn£90BnQfBZfNff4m
© /ª_O9pS 9!oM¢pG(O(2QfN =
(ao
 fI@(29¡B.JfU.\.4c 5
Ë5U5-4382/2Ro35&(8H0+.8<\LRU5U5DG+FH0+.'*&(/+,HÆDX\>W3'*HWRÍYu'*+,+,H0+,HWRU'*H0+f0+,HÆDQXk/2;*+F'43 V +I&Yu/2;*+
<+./Z&('L;0RN):;Æ/2;*+.X38+TH0+fÑ*'*+,He Ð 'k/2;0RN<l-43-G+.8Z/2;*+iRU'Q/210RU/2RUC+ V +M3'0RU'06t&Y1]p\q_tRN<35UL_3,XO<r]
pZs¡02.n( t s9[[9kmY
© _GeEx{RU6*e`l-4382/2Ro35U5UX£H0+,<).82RUD+,<@3s<210-0-G&(82/MWGL;0RN):;«LRU5U5{D+¢1*<+,HyRU'Y[1082/2;*+.8
+f*3 V -05N+,<Me
uv
wyx>z,{y|>}~

u.

w3|,x,z

>|>|y,x}c>|,x

yL}|

 |  |,x

zx,S>06~,

>>,3|,x

3|3zyx3y6}3x3|3,,~Lz
0

>|y,>ywyx>z,{y|>}~

>|y,x
,3{3z0

& (

&.-"Vm6&H-  n

/"m7+T ¢¡¤£T¥¦§3n
28"m©¨L«ª­¬¯®¬°±¢²´³­¬±¢µ.¶¨3a«ª­¬¯®¬°±¢²´³­¬±¢µ.O¨y¢¡¤£T¥g·¸¸¹²¬µ)p§
n

x}RU69108+`9]^10-0-G&(82/

= QMq
< G(? fSfM0(fÎÀ>
= pToq
< *[¡

 y ;}]¸}  	 ºB`»yB¼û{­½¾ <R V -05N+F698:3-0;Q¿CZ
f
O(.[¡SlÍ[Í(2B4¦$ÁÂ"Ã$Á¢(Ä*Á¢-4*LÅÄ*Æ¢465ÇÁ(È(aBÁ¢-ä(«0£aMQS,.=\2B¡02,[M?f;:ßm©
),&('*),+.-0/s'*&H0+,<«(a¦m©§8+.5o3/2RN&('Ê'*&H0+,<A5Å pF0£lÍ[oM.l2©®+,HO6+,<A5p
È MBa.nQf4Z(®
fÍ[[(¦aQs(2s$$(p;£
: (2Qf2¤>
É 0Sy
: (*\:f2©fm(ËI
Ê $yOsQn92m©\OaMW5  
2Mi*.22Z\
Ì .	
9 :f IfU9[n(GMQ[j
Í (ay£9a:¡GaMEI
Î o\Qfa¡2«S:¾$MÍ¤*yÌ3*3ÎWi
4 9a
nQf4[ 
< B>*0.Ï *fNff4_m©bÅ5ÀÅÐ!
9 p( .T>,:ft¢M._m©EB0fI[B
aNB65
È QfIaMQ>OliÍf('(? fST

: O¢\BaÆ5  2.Í9[n(«aQH
Í pPÍfU2ySF
: /¡X-+=MÍ A>=
(tfNff42©Ñ&)-]
= (U2s[>/X-+¤
= (aOlQn(m©ÑI
Í Zf_Zy.Ï 0(}$iO¢(B[	
: m©S/¡X-+=MÍ A65
U Q>{

=  ©Í i & - G =ÓÒÔm§$MÍ¤*ÀÌ3*dÎW46ÒÕ$MÍA*ÀÌ>*ÑÎW4 i ÅEn¯Ò" K (GCmWÌSÒÕ$MÍA*1Ì3*dÎ64 i ÅEnb"VmI* FtFtF­K n¯5  :(a:¡

õöAÖ

3M¼¾½øuM%

»

aMbÎp>UQfN2£S:F>O(y=/X-+=	ÎMAfW V 382K+.8=	Î,A2A>=d9hO.2\/¡X-G+=	ÎMA¢pl(jfNff4Jm©1&)(a=(U2
[s/X-¤+ =>(a V 382K+.8	= ÎMAsps(ß.UffaPm©1/l×mTfTnT=¢(U2t V 382K+.8A5BØp©9>Ù(.¤N'Î>RyoT(
a(M ?M[9O(\( Ù(f1
 Ú©=]Of«	 :B0 NÛÎRTÜp2.$MÚ¾465
Ë ),&('*),+.-0/]'*&H0+_LRU/2;i3E6+.'*+.82RN) V 382K+.8RN<q)M35U5N+,H3PfGff[uGMQl=RU/!8+fY[+.8<]/&P3'\10'*<2-+,).RÍÑ4+,H
Ê
+.'Q/2RU/XÆ&Y@3S),+.82/:3RU'Ò/X-+Af&(/2;*+.82LRN<+FRU/RN<)M35U5N+,H 3'§pG('?[(0(_aMj=RU/\8+fYn+.8</&t3S<2-+,).RÍÑ4)
RU'*HORUCRNHO1435}H0+fÑ*'*+,H£RU'I/2;*+><210-0-&(82/BAfert+PLRU5U5h3(H0&(-0//2;*+EYn&(5U5N&MLRU'06T).5o3(<<2RN)M35{),&('QC+.'Q/2RN&('*<P3D&(10/
^0?E<Me Ð 'Æ/2;*+£HO8:3,LRU'06k&YP3^0?ZWq),&('*),+.-0/'*&H0+,<38+8+.-08+,<+.'Q/+,H DQX¦8+,)./:3'0695N+,<s3'*H 8+.5o3/2RN&('
'*&H0+,<DQXs&MC935N<Me Ð 's/+fO/214357'*&(/:3/2RN&('7W08+,)./:3'0695N+,<u38+E8+.-05o3(),+,HFDQ¦
X ÝÞi3'*HF&MC935N<DQ¶
X ¨6µe]?E+.'*+.82RN)

3
2
8

K
.
+

8
¢
<

3

8

+
&
U
R
2
/

/
,
+

H

e
_
g
Q
;
*
1
>
<
s
3

6
.
+
*
'
.
+
2
8
N
R
\
)
,
)
(
&
*
'
,
)
.
+
0
>
/
o
5

3
G
D
.
+
5
1
M
$
S
ß
L
*
¤
f
E
4
N
R
@
<
2
<
R
0
U
5
y
X
*
'
(
&

/
,
+
H
J
.
ß
Z
e

Ë
'«RU'*HORUCRNHO1435
V
V
V
),&('*),+.-0/5o3D+.k
5 $MßS*yÚ¾4lRN<'*&(/+,¶
H ß àÑÚteßrß;*+.'ÒRU'Ê&(108+f*3 V -05N+,<L+I1*<+FD0RU'4382X¦8+.5o3/2RN&('*<MW_L+
,
3
s
X

8
.
+
0
o
5
(
3
,
)
E
+
Q
'
1
G
D
.
+

8

<
(
&
I
'
,
+
O
H

6
+,<_DQXTHORU8+,)./+,HI+,HO6+,<Mq3¢D0RU'4382Xs8+.5o3/2RN&('I'*&H0+uRN<_/2;*+.'IRU'*).RNH0+.'/J/&
V
V
+f*3()./25UX£&('*+ZRU'*),& V RU'063'*H«&('*+Z&(10/26&(RU'06I+,HO6+9e¢x{RU6*es<2;*&MLJ<E/L&j=[),&('0'*+,)./+,H4A@<2R V -05N+l698:3-0;*<
¿Å3'*HÉª3(<<21 V +,HF/&ZD+PH0+fÑ*'*+,HI&C+.8J/2;*+P<210-0-&(82/J&Y!x}RU6*e`9e
¿bê

wyx>z,{y|>}~

w3|,x,z

 |  |,x

 |  |,x
>|>|y,x}c>|,x

 |  |,x

>|>|y,x}c>|,xáVéè

>|>|y,x}c>|,xáçæTè

 |  |,x

wyx>z,{y|>}~

wyx>z,{y|>}~

É
0

0
yL}|TápâLãcä,å

w3|,x,z

 |  |,x

zx,S>06~,
0

zx,S>06~,

>|y,x

yL}|

¿

x{RU69108+>O]^R V -05N+>698:3-0;*<Me
g ;*+@+.5N+ V +.'/:382Xs8+M3(<:&('0RU'06&(-G+.8:3/2RN&('7W*-08&m+,)./2RN&('7W0RN<J3lKRU'*HT&Y}698:3-0;I;*& V & V &(82-0;0RN< V /2;43/
_
-08+,<+.82C+,<_/2;*+-4382/2Ro357&(8H0+.8H0+fÑ*'*+,Hs&('T5o3D+.5N<Meh|7+./_1*<Ñ*8<2/_-08+,).RN<+u/2;0RN<&(8H0+.8Yn&(8),&('*),+.-0/'*&H0+
5o3D+.5N<Me¦rt+T;43,C+£H0+fÑ*'*+,HÆ/2;*+sY[&(5U5N&LRU'06j-4382/2Ro35&(8H0+.8i&('Ò/2;*+ V 382K+.8<+.j
/ /¶lëmTfTnQJ
 fRN<Z/2;*+
698+M3/+,<2/l+.5N+ V +.'Q/F=pY[&(8¢35U+
5 Ú i /
W Úì\ÐfA@3'*H+.5N+ V +.'Q/<Z&Ó
Y /°38+-43RU82LRN<+\'*&('k),& V -438:3D05N+9e
g_;*+.'T/2;*+0(f[n((2QfP(£9a:¡G]aMQ@Íf ERN</2;*+-08&HO1*)./&Y7/2;*+-4382/2Ro35&(8H0+.8<_&(' &)(3'*H
e $Mß*yÚ¾4Ñ\$Mß ê *yÚ ê 4RÍ
Ì ßÑ\ß ê 3'*7
H Úî\Ú ê e Ð 'T&(/2;*+.8L&(8H0<MW43Z),&('*),+.-0/5o3DG+.a
5 $MßS*yÚ¾4RN<
í lgmTfTnQW0R$eô+9H
5 $Mß ê *yÚ ê 4RÍÓ
Y ßRN<3\<210D0/X-+P&Ó
Y ß ê 3'*HW4RÍ`
Y Ú ê "fQW*/2;*+.g
' Ú )M3'
V &(8+><-G+,).RÍÑ4)@/2;43'S3),&('*),+.-0/u5o3DG+.+
D+P3'QX V 382K+.8MW*&(/2;*+.82LRN<E
+ Ú V 1*<2/D+P+,w1435/
& Ú7êe
 ¿ E	 9]C
 õ}²M <qG2(¢BO(.b
Î 5  -08&2+,)./2RN&('

 y;}]¸}ðï ,ñ òyó¸}ÓJô .7Éà(G[
©fm( É pa$¿ pj\BQap¾öß©fm(÷Á ( $$ÉC4$JÁ ( $¿[4y(ai©B2(÷Á - $$ÉE4£$JÁ - $¿[4g9hQnf
aB,.?f>MQBN$[hoEf
O(.[¡9mBa(\(\(¡4QpBYRl(H9fGEOf4ff¤=](al\:
$*2.n( ^ sZ:(a:¡_9a\fU9[n(SaMQ>UQf 6 ø
Ê5ÄùÓ$MÍA*yÌ3*3ÎW4 i År$$ÉC4*´$	ö$MÍ4*yÌ3*3ö$	ÎW4y4 i År$¿[4>É

õöWú

 úûM]ü|è9ýM.þtûMÿ=uèwu«úûMÔÔM3
øù F

û 5Äùü] i Á $$ÉE4*[Æ$	ö$M])4y4d\OÆ$M]4

rt+¢'*&(/+ZÉ P ¿È=$É¾<210D*<21 V +,j
< ¿PAJRÍYq/2;*+.8+¢+fORN<2/<3-08&2+,)./2RN&('Y[8& V ÉªRU'Q/& ¿ZegqX-0RN)M35U5UXW
É 8+.-08+,<+.'/<J3Pw1*+.82XW­¿°3PYn3()./MW03'*Hi-08&m+,)./2RN&('*<Y[8& V É®/&¿°H0+fÑ*'*+E3'*<2L+.8<_/&Ée Ð 'sx{RU6*eqOW
á
<210-0-&9<+[ýJBM2(2fOf \ÿþJ.:,(4WO/2;*+.'F/2;*+.8+ERN<&('*+E-08&2+,)./2RN&('TY8& V É°RU'/&8¿Zeqg_;*+ER V 36+@&YqÉ
DQXT/2;0RN<-08&2+,)./2RN&('IRN</2;*+><210D0698:3-0
; ¿ ê &a
Y ¿Ze



Û



y§»{Ô¸M}h´½hM]



¾´½[ 

g_;*+T<+ V 3'Q/2RN),<¨ V 3-*<\^0?E<l/&£/2;*+s+fORN<2/+.'/2Ro35_),&('(m10'*)./2RUC+I3'*Hk-G&9<RU/2RUC+\Y[8:36 V +.'Q/\&Yx{zu|qe
?uRUC+.'3I<210-0-G&(82/@ÎuW}3F),&('*</:3'Q/PRN<l3(<<2RU69'*+,HS/&I+M3():;jRU'*HORUCRNHO1435 V 382K+.8l3'*Hj3' ~3(HORN)=8+,<2-7e
310'4382X0AJ-08+,HORN)M3/+lRN<u3(<<RU69'*+,H/&s+M3(); ~3(HORN)¢8+.5o3/2RN&('Æ=8+,<-7e),&('*),+.-0/BA/¡X-+9ex*&(8E<2R V -05URN).RU/XW
L+u),&('*<2RNH0+.8_/2;43/_+M3();F),&('*<2/:3'Q/&(8-08+,HORN)M3/+u;43(<]/2;*+u<:3 V +'43 V +E3(</2;*+E3(<<&).Ro3/+,Hi+.5N+ V +.'/_&Y
/2;*+u<210-0-G&(82/Me!Ëâ<+./&Y7Yn&(8 V 105o3(<Jj
¨ $d
Î 4!RN<3(<<RU69'*+,H/&Z3'QX<10-0-G&(82/ÎW/28:3'*<25o3/2RU'06-4382/2Ro35&(8H0+.8<
&('«/¡X-+,<Me\y&(8+<2-G+,).RÍÑ4)M35U5UXW7Y[&(8>35U5HORN<2/2RU'*)./P/¡X-+,j
< ß D 3'*J
H ß  <21*);j/2;43[
/ ß  \Vß D W}&('*+Z;43(<@/2;*+
Yn&(8 V 105o7
3 ù¢] D FtFtF ] $Mß  $M] D * FtFtF *y] §4
ß $M] * FtFtF *y] ¯4y4fW}L;*+.8+ ë"îIYn&(8¢),&('*),+.-0/l/¡X-G+,<MWh3'*H kRN<
D D
&(/2;*+.82LRN<+/2;*+382RU/¡X&Y/2;*+J8+.5o3/2RN&('i/¡X-G+9eq?uRUC+.'T3'QX^0ÿ
? ¿W3uYn&(8 V 105o3lj
¨ $¿[4!RN<qD010RU5U/3(<qY[&(5U5N&LJ<Me
Ëá/+.8 V RN<3(<<RU69'*+,HT/&\+M3();y),&('*),+.-0/'*&H0+9]3ZHORN<2/2RU'*)./C9382Ro3D05N+EYn&(8J+M3();£6+.'*+.82RN)P'*&H0+9W*3'*HF/2;*+
),&('*<2/:3'/P),&(828+,<2-G&('*HORU'06T/&sRU/< V 382K+.8P&(/2;*+.82LRN<+9ePg_;*+.'t3'«3/& V ß6$	ÎW4Z=8+,<2-7¢e ßL$	Î D * FtFtF *3Î G 42ARN<
3(<<&).Ro3/+,Hs/&¢+M3():;I),&('*),+.-0/'*&H0+Z=8+,<2-7e8+.5o3/2RN&('F'*&H0H
+ Í¢&Yh382RU/¡X K AfWL;*+.8H
+ ßRN</2;*+/X-+u&Y/2;*+
'*&H0+9W*3'*7
H ÎZ=8+,<-7­e Î $ARN<_/2;*+E/+.8 V 3(<<2RU69'*+,HT/&Z/2;0RN<_'*&H0+\=8+,<2-7e*3(<<RU69'*+,HT/&¢/2;*b
+ Ì¡/2;F'*+.RU69;QD&(108
&`
Y ÍAfe|7+./ Ä$¿[4_D+@/2;*+P),&('(m10'*)./2RN&('£&Yh/2;*+,<+>3/& V <ej
¨ $¿[4_RN<J/2;*+P+fORN<2/+.'Q/2Ro35{).5N&9<2108+P&Y +$¿E4fe
; ¿Yê4RU'ix{RU6*eq@RN< ¯] _$ýJf,2(2fO.A $M]4 þ2m¤M2, $M_4
ç e 6*eh/2;*+Y[&(8 V 105o3¢3(<:<2RU69'*+,H/&>/2;*+<10D0698:3-07
ýJBM2(2fOf¤ $ J4 £\.\:f´ $M]*y_4 yffW $ ¾*y_­4 9]( ÙM !9! $M]* B4y4fe
¯ 8&2+,)./2RN&('jRN<><&(10'*Ht3'*Ht),& V -05N+./+\LPe 8Me /MeZ/2;*+<+ V 3'Q/2RN),<Z¨EW10-t/&I3T'*&(8 V 35URU/X«),&('*HORU/2RN&('
Yn&(8),& V -05N+./+.'*+,<</2;*+la9B\(º©.(fñ&Y{3l^0ç
? ¿âRN</2;*+E^0?ªM`
© $¿[4q&(D0/:3RU'*+,HTDX V +.8269RU'06),&('*),+.-0/
'*&H0+,<;43MCRU'06E/2;*+]<B3 V +]RU'*HORUCRNHO1435 V 382K+.8Mehg_;0RN<q^0?ß35UL3,XO<h+fRN</<=n3'*H¢RN<}),& V -010/:3D05N+RU'l5URU'*+M38
/2R V +LRU/2;T3>'43RUC+u35U6&(82RU/2; V Afe]x}RU69108+ ¥ <2;*&MLJ<3P),&(10'/+.8m~¡+f03 V -05N+E/&¢-08&2+,)./2RN&('T),& V -05N+./+.'*+,<:<
L;*+.'t^0?E<38+¢'*&(/RU'£'*&(8 V 35Yn&(8 V À
 ¿ÁYn&(8RU'*<2/:3'*),+lH0&+,<'*&(/-08&m+,).//& kW4+.C+.'yRÍY!DG&(/2;«^0?E<
;43,C+¢/2;*+l<:3 V +P5N&(69RN)M35h<+ V 3'Q/2RN),<W4D010/uRU/-08&2+,)./</&M
© $ J4feJËª^0?ÅRU''*&(8 V 35}Y[&(8 V RN<<B3RNHI/&
D+Za(f9 e






	




	 


	





 



 

 







r

s

t

t:a

r

t:a

s

t



!



r



s

t

t:a


"$#&%('*)+"$#-,.'*)0/21435#617'9835#6:;'<8=3>#6:4'98@?A#61CBD:;'<8FEG#61CBD:;'<8@HC#61CB:;'
%IKJMLF,ON4IPRQTSUIVQTWYXZR[Y\]IW
^`_aIJ4S`WbI^U[bXJdce^UN2f4SDSUIVQ$J4X_UV=IKW7geX_UV@hi;f;^^UN;Q>jIK_UQ([YJ4\5XVkMI_aIi4WYQ(ilj@k;_UXmQ5\n^U[bXJ
o
¿

u

u

t:a

t:a

u

'OY3$¿[4+"ß'OYy$ J4

p

x{RU69108+ ¥ ]g_;*+E'*+,+,HTY[&(8'*&(8 V 35Y[&(8 V <

q

sr


t uvu w

xrzy {

*t Cu|u|}

½hy|Mèy¯º  ½hyn }
qhM}]y|
« K}$MAy
ô .\É (a¶¿
 ü ¼ûM´½

	9] ¿¢¢QM<]G2T(«\fMQO(.Îj5kU0fFÉ P M©L$¿[4> ©>(Gi(4@:\ ©¨j$ÎÑ4*B¨[$¿[4 I¨[$$ÉE465

~

2

õö



:

»

3M¼¾½øuM%

rt+y).5o3R V +,H¬RU'ß/2;*+£RU'Q/28&HO1*)./2RN&('§/2;43/^0?E<T38+£+,w10RUC(35N+.'/F/&j/2;*+£-&9<2RU/2RUC+9W),&('(m10'*)./2RUC+
3'*Hj+fORN<2/+.'/2Ro35qY[8:36 V +.'Q/Z&Yx{zu| LRU/2;*&(10/¢Y10'*)./2RN&('*<s=5N+./>1*<¢H0+.'*&(/+\RU/>DX«x}zu|]= _W *A2AfeFz'*+
+ V D+,H0HORU'06FRN<ER VV +,HORo3/+I=pY[8& V x{zu|Æ/&I^0?E<BAfWD010/E8+,wQ10RU8+,<E/2;*+ZH0+fÑ*'0RU/2RN&('t&Y3<210-0-&(82/E/2;43/
H0&+,<J'*&(/3(H0H3'X/2;0RU'06s/&/2;*+P<:+ V 3'Q/2RN),<u&Y{/2;*+>RU'QC&(5UC+,H£698:3-0;*<Me]Ë 9qfMQO(._RN<3<210-0-&(82/
L;*&9<+¢/28:3'*<25o3/2RN&('«DQXS¨§RN<E+ V -0/¡XWh 5W 5uL;*+.8+Z35U5hHORN</2RU'*).//X-+,<@38+>'*&('«),& V -438:3D05N+9e Ð Ä
Y Á RN<
/2;*+JC&)M3D0105o382X£=[),&('*<2/:3'/<3'*H\-08+,HORN)M3/+,<BA!Y[&(8_3P<+./&YY[&(8 V 105o3(<MWL+),&('*<RNH0+.8/2;*+ a3/<210-0-&(82/
Î ­$Ár4"$'&.(+*,&)-+*0/Ñ4L;*+.8j
+ &)(RN<8+,<2/282RN)./+,H/&Z/2;*+P+.5N+ V +.'Q/ j(WO/2;*+@8+.5o3/2RN&('I/X-+,<J&
Y & - 38+
/2;*+@-08+,HORN)M3/+,<&Y!382RU/Z
X ÌRU¾
' Á\W*3'*HI/2;*+@RU'*HORUCRNHO1435 V 382K+.8<&Y /Ê38+E/2;*+P),&('*<2/:3'/<JRU
' Áe

U 

s



=





D;
 5 
  t 
d  =


  0 
D; ` D; 
þ2Mm©Wø«|7+./ß
 D+F3Sx}zu|]=U_W*APY[&(8 V 105o3«&MC+.83yC&)M3D0105o382XÁekg_;*+^0?D;ü$`.4lH0+fÑ*'*+,HÒ&('
/2;*+P<210-0-&(82/JÎ­ $Ár4RN<D010RU5U/u3(<Yn&(5U5N&MLJ<M!/&+M3();/+.8 V &Y(yL+¢3(<<&).Ro3/+P3),&('*),+.-0/'*&H0+@/X-+,H
 (¬=6+.'*+.82RN)@RÍYh/2;*+E/+.8 V RN<3lC9382Ro3D05N+9W0RU'*HORUCRNHO14357LRU/2;£3 V 382K+.81ÎuRÍYh/2;*+@/+.8 V RN</2;*+P),&('*<2/:3'/
j
ÎMAfW3'*Hk/&S+M3(); 3/& V ß6$M] * F6F6F *y]{W 4PL+I3(<<&).Ro3/+F38+.5o3/2RN&('Æ'*&H0+ZÍ/X-+,HëßfW]<21*);¦/2;43/MW!Yn&(8
I[\Ì+\xO
 WO/2;*+jÌ$/2;I'*+.RU69;DG&(D8&Y`ÍZRN</2;*+P),&('*),+.-0/J'*&H0+>3(<<:&).Ro3/+,HT/&]  e
g_;*+ V 3-0-0RU'06D;
 RN<_).5N+M3825UXRU'(2+,)./2RUC+9W05W5hRU/ V 3-*<HORÍÌ+.8+.'Q/_Yn&(8 V 105o3(<P='*&(/_RNH0+.'Q/2RN)M3510-T/&
ñ

I\BaZOM.
Óyn¸
_ }A Î_Ï  UOfo\. ¤M2,[n(
 º Óy§^ }$T  
m ©
ô N += ¯R>©.9BZÍT?fI?ºM:QfÍ(S:Á $SOiM.Pm©G(B\(+õ}²iQ	<qG2(ÒO 9
BO9f{Î ­$Ár4EfO.9M=*©,(¢(:i	9]©,(fZU j(a =
k ÁOf¢o>Pa2m¤M2,[n(©B2(
ü$ ü4P4$
ü$ 465

C9382Ro3D05N+@8+.'43 V RU'06A_/&\HORÍÌ+.8+.'Q/E^0?E<>='*&(/JRNH0+.'/2RN)M35}10-F/&3'FRN<:& V &(82-0;0RN< V Afe]y&(8+,&MC+.8MW4RU/JRN<3
D0R 2+,)./2RN&('IRÍY{L+@8+,<2/282RN)./u^0?@</&Z/2;*&9<+@RU'I'*&(8 V 357Y[&(8 V e
|7+./!1*<h'*&L ),&('*<2RNH0+.8!/2;*+x}zu|= _W *A7Yn&(8 V 105o3  " ] $ Ä$ ] 4y4_=L;*+.8+ Ä$ ] c4}RN<q3u),&('(m10'*)./2RN&('
&Y\3/& V <FL;*&9<+«C9382Ro3D05N+,<FD+.5N&('06Ò/& ] Afeàg_;*+ ( ~¡+.'082RN);*+,H®Y[&(8 V 105o3Æ&Y âRN<I/2;*+SY[&(8 V 105o3
ß $ .4k"
] $ Ä$ ] 4
Ä$ ] 4y4PL;*+.8+ +$ ] 4@RN<>/2;*+s),&('(m10'*)./2RN&('¦&Y/2;*+i3/& V < j(Ñ$M]4fW{Yn&(8l+.C+.82X
/+.8 V ]yRU' he_rt+>'*&Lá-08&C+l/2;*+P-08&(-+.82/¡XIDXI-G&(RU'/2RU'06s&(10/u/2;43/MW{`A_Yn&(8 t3'*H T/¡L&Tx}zu|= _W
*A}Yn&(8 V 105o3(<W
ZRÍ7
Ì ß §$ .4 Zß $ 4fWO3'*HiAhY[&(83'X\x}zu|]= _W *A}Yn&(8 V 105o3 hW ß $ .4Ó"®[
¨ $ ü$ .4y4fW
3'*HI),&('*).5U1*H0+@1*<RU'06g_;7e7`9e
x*&(8E/2;*+l&(/2;*+.8@HORU8+,)./2RN&('7W/2;*+l3-0-438+.'/@-08&(D05N+ V RN<u/2;43/Y[&(8 V 105o3(<P3(<<2RU69'*+,H£/&/2;*+Z<210-0-&(82/
DQX¨§38+P10'0RUC+.8<:35U5UXIwQ143'/2RÍÑ4+,H£3'*H38+P1*<+,HFRU'I/2;*+PH0+,HO1*)./2RN&('£-08&),+,<:<MeqÃu&ML+.C+.8MWaL+>)M3'£H0&
LRU/2;*&(10/J/2;*+ V W4DQXT+.'*),&HORU'06\/2;*+P-4382/2Ro35&(8H0+.8&('I/X-+,<JHORU8+,)./25UXTRU'F/2;*+¢^0?E<Me

] ` |  ` |v  ( |v 


C+ 5 `  ] 
 5 

U C
z 
! || 

 v  ` |v 


= |v 


 0
U
 ] ` `D; `
¡

U  

  t 

C7

£f¢!
6 UOfoM¤M2,[M?_Ba n9[n(
ñ Óyn¸  º Óy§^ }$ ÎÏ  }AT  
aI0ZM.m©Za(f\(õ}²\QM<qG£(¦TfM0(f]Î $£OZ,.um©
ô N += ¯Ru©,(flU¢fO.
9M =©.(S( :Æ	 9]
 õ}²«
 ¿ (a
QM <q2 (Æ1
Î =iOfSpy£Gmm¤M2,[n(©B2(
4$B¿ 

C7Ó$¿[4£!C7Ó$J465



  

¢

 <



þ2Mm©Wø|7+./C¿¾D+3i698:3-0;tH0+fÑ*'*+,Ht&('t3T<210-0-G&(82/EÎue>g_;*++fO-43'*<2RN&('«&Yd¿ZW W] $¿E4fWRN<E/2;*+^0?
H0+fÑ*'*+,H¦&('j/2;*+ a3/l<10-0-G&(82/¢Î $ÁCi
4 =L;*+.8+ Á RN<>/2;*+iC&)M3D0105o382X«Y[&(8¢/2;*+\Yn&(8 V 105o3(<Z&Yu¨j$Îd42AfW
D010RU5U/@3(<JYn&(5U5N&MLJ<ME`A_Y[&(8u+.C+.82X),&('*),+.-0/'*&H0+[]¾" ßHà§Ú h&YÄZ
¿ W W] $¿EJ
4 ),&('/:3RU'*<E3'«3(<<&).Ro3/+,H
( àTÚ ¡W0<Me /MeUWYn&(8J+M3();£),&('*),+.-0/J/¡X-G+Yß ê i ÎÒ698+M3/+.8&(8J+,w1435/&rfß W*3l10'4382X
),&('*),+.-0/J'*&H0+b] ê "
8+.5o3/2RN&('j'*&H0+\&Y/¡X-+ßh
ê 5URU'0K+,Hj/&7]]
ê 3'*HjAuY[&(8>+.C+.82X«8+.5o3/2RN&(''*&H0+ok
] &YH¿ =[&Y/X-+I
Í 3'*H
382RU/¡X K AfW4Yn&(8+.C+.82XF8+.5o3/2RN&('y/¡X-G+EÍ ê i Î¬<Me /MeÑÍ8\Í ê W4L+Z3(H0HIRU' 6] `$¿[
4 3\8+.5o3/2RN&('£'*&H0+P/X-+,H
Í7
ê LRU/2;«<:3 V +¢'*+.RU69;QD&(8<>3(<Y}
] eurt+>'*&LÅH0+fÑ*'*+l/2;*+Z3-0-05URN)M3/2RN&('
3(<P¨ W] }W3'*HS),&('*).5U1*H0+
1*<2RU'06g_;7e`9W*'*&(/2RN).RU'06\/2;43/u¨j$ Î $Ák4y4" Oe



¨¤Y §¦





¥¤ §¦

{ <

 <
7 ª©@ <

¬«

;­A®
õ

¡

 úûM]ü|è9ýM.þtûMÿ=uèwu«úûMÔÔM3
øù F

¯

<2RU'06\<2R V RU5o38/28:3'*<mYn&(8 V 3/2RN&('*<MWG3Z).5N&9<+E8+.5o3/2RN&('*<2;0RU-I/&Z/2;*+@-08&(D05N+ V &YdÏ.*fS:s94$(*f4
<2/21*HORN+,HsRU's/2;*+H*3/:3D43(<+Ñ4+.5NHs;43(<DG+,+.'T<2;*&L'7!);*+,)KRU'06\w1*+.82X),&('Q/:3RU' V +.'/Y[&(8'*&('T8+,).108<2RUC+
),&('(m10'*)./2RUC+FwQ1*+.82RN+,<lRN<Z+,wQ10RUC935N+.'Q/Z/&S);*+,):KRU'06«-08&2+,)./2RN&('¦DG+./L+,+.'ß^0?E<F=$%;*+.RU'Æ+./35$eUWJ`Mb9b9cO
£1069'0RN+.8MW49Õ9Õ9ÕAfe
 ï

p

v`» ¯º±° q

½hy 
 §
y ]ó¸M} ñ



y

¢º×]$A{Ô¸M}h{»

q

<² K

üºB`»y $

x*&(8/2;*+E<:3K+E&Y}D08+.CRU/¡XWOL+@),&('*<2RNH0+.8_RU'FL;43/Y[&(5U5N&LJ</2;43/^0?E<J38+u69RUC+.'FRU's'*&(8 V 35Yn&(8 V W03'*H
-010/_RU'Q/&Z'*&(8 V 35Yn&(8 V RÍY'*+,+,H0+,HI3ºY[/+.83 V &HORÍÑ4)M3/2RN&('7e]Ë'*HWO<2RU'*),+@3Z^0?°H0&+,<_'*&(/_'*+,+,HT/&lDG+@3
),&('0'*+,)./+,HI698:3-0;7W*L+P),&(' a3/+l3Z<+./&Y]^0?E<LRU/2;I/2;*+¢^0?&(D0/:3RU'*+,HIDQXs-+.8mY[&(8 V RU'06\/2;*+>HORN<[m&(RU'/
10'0RN&('£&YhRU/<+.5N+ V +.'/<Me Ð 'F/2;*+@Y[&(5U5N&LRU'06sH0+fÑ*'0RU/2RN&('7W*Y[&(8JRU'*</:3'*),+9W*/2;*+¢^0?ªÏk8+.-08+,<+.'Q/<E3<+./&Y
^0?E<Me



´µ*´Ü¶|·×¹¸º Bô .Ï¬(a>É

x³

 Î_Ï{Ý


 y ;}]¸}

Q29O:@©fm( Ï§ ©JÉ P Ïd5

@	9]rõ}²uQM<]G29lBO(.Îj5Éä(S:

% ;*+.RU'«3'*H££1069'0RN+.8\=m`Mb9b9A;43MC+Z<2;*&ML'y/2;43/-08&2+,)./2RN&('«);*+,):KRU'06TRN<Y ¯ ~¡),& V -05N+./+ZLRU/2;«3

8+,HO1*)./2RN&('SY[8& V
× {Ü e ç wQ10RUC935N+.'*),+ZLRU/2;j%^ ¯ =[<:3/2RN<mÑa3D0RU5URU/Xy&Y3s),&('*<2/28:3RU'/@'*+./¡L&(82K0AL_3(<
35N<&l1*<+,Hs5o3/+.8>=[x*+,H0+.8 ]38HOR$W`Mb9b ¥ *£1069'0RN+.8%;*+.RU'7W`Mb9b9­AfW43'*HsRU'*H0+.-G+.'*H0+.'/25UXTRU'3>C+.82X
<2R V RU5o38 V &H0+.5{DQX£ãJ1*H0&(5ÍY=m`Mb9b9cA¢=[<+,+>-4382/@c\&Yq/2;0RN<u-43-+.8BAfeJrt+¢69RUC+>D+.5N&ML3'*&(/2;*+.8E-08&&Y]&Y
/2;0RN<u8+,<2105U/ED43(<+,Hy&('«38+,HO1*)./2RN&('yY8& V ¥ ~^Ë!g@eg_;*&(1069; V &(8+Z),& V -05URN)M3/+,HS/2;43'y/2;*+l-08+.CRN&(1*<
&('*+,<MW0/2;0RN<J8+,HO1*)./2RN&('RN</2;*+ED43(<2RN<Y[&(8J&(/2;*+.8J8+,HO1*)./2RN&('*<-08+,<+.'/+,HI5o3/+.8JRU'F/2;0RN<-43-+.8Me
g_;*+lYn&(5U5N&MLRU'06I/2;*+,&(8+ V K+,+.-*<@RU'Q/&I3(),),&(10'/P/2;*+),& V -05N+fRU/X«&Y),&('*),+.-0/¢3'*HS8+.5o3/2RN&('t/X-+
);*+,):KRU'06*W/2;*&(1069;\RU'/2;0RN<!-43-+.8!/2;0RN<!/+,<2/q)M3'i&(DQCRN&(1*<25UX¢D+_-+.8mY[&(8 V +,HZRU'-&(5UX'*& V Ro354/2R V +J<2RU'*),+
),&('*),+.-0/3'*HF8+.5o3/2RN&('£/¡X-G+,<38+@&('05UXs5o3D+.5N<-4382/2Ro35U5UXF&(8H0+.8+,HIRU'3l;0RN+.8:38):;QXe

¶» ¼ µ

p

½hy|Mèy¯º

q



½hyn

¾½

sr
}

d¿


t  uvuü  Î_ÏÝK´µ*´Ü¶{·×¹¸ºào£À¿1þÑ!(aN.¡samfU.C=\ 

qhM}]y|

	:B0lfO2LÙpTpiÎªfU(¢$ HþÀ5

K´µv´ ¶{· ¸$º

þ2MmW© øZx{RU8<2/@<+,+l/2;43/@RÍY/X-+Z);*+,)KRU'06IRN<uRUB
'  ¯ WG/2;*+.'«ÎÏ}Ý Ü × ÒRN<P35N<&sRU'© ¯ 3i-08&~
2+,)./2RN&('7Wq+.'082RN);*+,H¦DX),+.82/2RÍÑ4)M3/+,<lYn&(835U5/¡X-+s):;*+,)KO<Z1*<+,HW!RN<3-G&(5UX'*& V Ro35),+.82/2RÍÑ4)M3/+9etg_;*+
8+,).RU-08&)M357RN<J&(DQCRN&(1*<25UXT/2821*+9eqrt+E'*&Lá<2;*&L®/2;43/MW*+.C+.'IRÍYh/¡X-+@);*+,)KRU'06i)M3'DG+@H0&('*+@RU' $,I´4fW
ÎÏ}Ý Ü × jRNÀ
<  ¯ ~¡),& V -05N+./+9e
|7+./1*<'*&ML D010RU5NH 3y8+,HO1*)./2RN&('ÒY[8& V ¥ ~^Ë!g@e]g_;*+TRU'0-010/s&Y ¥ ~^Ë!gàRN<i3£Y[&(8 V 105o3
RU' ¥ ~
),&('(m10'*)./2RUC+@'*&(8 V 35Yn&(8 V = ¥ ~Ä
% xqAfW0R$eô+9eq3Z),&('(m10'*)./2RN&('£&YhHORN<[10'*)./2RN&('*<l=[).5o31*<+,<BAfW0+M3():;ILRU/2;£3/
V &9<2//2;08+,+@5URU/+.8:35N<W43'*HT/2;*+@wQ1*+,</2RN&('IRN<_L;*+./2;*+.8J/2;*+.8+@RN<3l/28210/2;3(<:<2RU69' V +.'Q/&Yh/2;*+EC9382Ro3D05N+,<
&Y à<21*);T/2;43/ ñRN</2821*+9Ó
e u&(/2RN),+u/2;*+E).5o3(<<2RN)M35 ¥ ~^Ë!gÊ-08&(D05N+ V ),&('*<2RNH0+.8<).5o31*<+,<_LRU/2;F+f03()./25UX
/2;08+,+@5URU/+.8:35N<MW*D010/Y[&(8_Y[1082/2;*+.8J-08&&Y[<_L+P-08+fYn+.8/&1*<+E/2;*+>3D&MC+PC(382Ro3'/Me
|7+./ q"
DG+>3'RU'*<2/:3'*),+>&Y ¥ ~^Ë!g@e*rÁe 5$eô&0e 6*e]L+P<210-0-&9<+@/2;43/+M3():;C9382Ro3D05N+
F6F6F
D
G
3-0-+M38<3/ V &9<2/&('*),+RU'i3E).5o31*<+9e!|7+./]1*<q).8+M3/+Yn&(108]),&('*),+.-0/q/X-+,<!Yn&(8q+M3();iC(382Ro3D05Nd
+ ]{ GW ¯¸4W
F3'*H aert+¢35N<:&\).8+M3/+>&('*+>8+.5o3/2RN&('£/X-+ hYn&(8+M3():;y).5o31*<+ Wa3'*H£38+.5o3/2RN&('£/¡X-G+ ° 0e
ç 3():;k),&('*),+.-0/l/¡X-G+ SRN<P698+M3/+.8l/2;43' «3'*H ¯¸4W}/2;*+,<+i38+/2;*+&('05UX«-&9<<2RUD05N+),& V -4382RN<:&('*<
D+./¡L+,+.'yHORN<2/2RU'*)./J/X-+,<Me
rt+lD010RU5NHS/2;*+Z698:3-0×
; ¿$ 4@3(<uYn&(5U5N&MLJ<MY[&(8@+.C+.82X£C(382Ro3D05Nr
+ ]tRU' IWL+Z;43MC+Z/2;08+,+),&('*),+.-0/
'*&H0+,Z
< Ý §Þ4Ñ
W Ý §Þ3'*Q
H Ý §¸§ÞlRU7
' ¿$ 43'*Hi/¡L&l8+.5o3/2RN&('s'*&H0+,</X-+,H ­° ¢5URU'0KRU'06>/2;*+Ñ*8<2//&>/2;*+
5o3/2/+.8_&('*+,<u=RU'/210RU/2RUC+.5UXW0RU/ V +M3'*</2;43//2;*+JC9382Ro3D05N1
+ ]F)M3'sDG+C(35U143/+,HiDQX §± ¬¢&(Ñ
8 ¸¯° ¯®T¬Afeh|7+./

K´µv´ ¶{· ¸$º

Â

Â

ÃÂ

@Â ÅÄ 
Æ9Ç +Æ
È
UÆ `Æ
Ç

+Ä

Æ9È

`Æ

Â

É7
ªÆ9Ç Æ

Â

;­<Ì
õ

Æ <Æ
È 
Ê

Ä£

Â
È 9Ê

Á

dÇ 9Ë


Ê

3M¼¾½øuM%

»

a

b

val

val

val

at

af

bt

c

val

bf

val

val

val

ct

cf

dt

2
1

2
3

C1

C1

C1

C1

C1

C1

C1

1

d

C2

C2

b

c

d

val

val

val

val

val

df

av

bv

cv

dv

...

3

C2

a

C2

C2

C2

¿
C2

É

1

2

C1

2
3

1

3

C2

*Í|¸ÎGµ*¶{·×¸$º
1*<<B3,XF/2;43//2;*+>/28210/2;C935U1*+.Ç§±9Ë ¬£=8+,<2-7eÑ¸¯°
Ê¯®¬QA_RN<u3(<<&).Ro3/+,HFLRU/2;Ý`Æ9Ç¯Þy=8+,<-7e«ÝUÆ§¸§ÞAfe_g_;*+.'
Yn&(8¢+.C+.82X«).5o31*<+Ä£À"î$Ï-ÐÑÏ-ÒÑÏÓ´4ERU'Â =L;*+.8+!Ï&Ð0WÏ&ÒT3'*HÏ&Ói38+5URU/+.8:35N<¢&C+.8¢C9382Ro3D05N+,<C]}W
_£3'*HÔAfWGL+3(H0Hy/2;*+À8+.5o3/2RN&('«'*&H0+,<u/¡X-G+,HÉ  Wa;43,CRU'063(<Ñ*8</E382691 V +.'/×Ý`Æ9¯
Ç ÞF&(8©ÝU§Æ ¸§Þ4W3(<
<+,),&('*HI382691 V +.'/¾Ý`Õ
Ç§Þ&(8gÝ`Õ¯¸ÞaWO3'*HF3(<_/2;0RU8HI382691 V +.'/¾ÝUÖ9§Ç Þ\&(8 ÝU§Ö ¸ÞaW/2;43/J),&(828+,<-G&('*Hs/&\3'
+.C935U143/2RN&('£&Y!/2;*+P).5o31*<+@/&\/2821*+i= V &(8+@-08+,).RN<+.5UXW4RÍY!L+@8+.-05o3(),+>RU'I/2;*+>).5o31*<+Ä£h
 +M3():;-&9<2RU/2RUC+
=8+,<2-7e'*+.6Q3/2RUC+AE5URU/+.8:35£ÏØ×9WaI7\Ù×\ÛÚOW7DXy/2;*+\/28210/2;jC935U1*+=8+,<2-7e\/2;*+\'*+.6Q3/2RN&('&Y_/2;*+/28210/2;
C935U1*+A3(<<&).Ro3/+,HTLRU/2;I/2;*+@Ùß5'*+.RU69;QD&(8&Yh/2;*+@8+.5o3/2RN&(''*&H0+9WvÄ£}
 RN<+.C(35U143/+,H/&Z/2821*+Afe
x*&(8E).5o31*<+,<8+,<2/282RN)./+,H/&$Ï Ð ÑÏ Ò 4J&(8k$Ï Ð 4fWaL+>-08&),+,+,Hy<2R V RU5o3825UXW3(H0HORU'06 ¥ D0RU'4382XI8+.5o3/2RN&('
'*&H0+,<u&(8E&('*+l10'4382XI8+.5o3/2RN&('S'*&H0+9ebu&(/+>/2;43/E;43MCRU'06 K ~¡).5o31*<+,<MWGL;*+.8+ K RN<E3i),&('*<2/:3'/MWRN<u&Y
-082R V 382XSR V -G&(82/:3'*),+/&F;43,C+s3T-&(5UX'*& V Ro35q/28:3'*<2Y[&(8 V 3/2RN&('7W{<2RU'*),+L+&(D0/:3RU' G¦
Ü I8+.5o3/2RN&('
'*&H0+,<_Y[&(8J+M3():;£).5o31*<+9e
Ð 'i/2;*+698:3-0;Éo$Â 4fWO/¡L&Z),&('*),+.-0/'*&H0+,<7Ý`¯Æ Þ3'*HQÝUÆ9¯È Þ\38+).8+M3/+,HsYn&(8+M3():;FC(382Ro3D05N+H]3'*H
3ZD0RU'4382Xs8+.5o3/2RN&(''*&H0+¾¨5­È °9Ê µP5URU'0KO<gÝ`¯Æ Þ/&¶ÝUÆ9§È Þaeqx*&(8+M3():;£).5o31*<+Ä£)
 " $Ï-Ð@Ñ§Ï-ÒÑ§Ï&´Ó 4fW*/2;*+.8+@RN<
&('*+P8+.5o3/2RN&('ÿ¨KÉ7, µ¢5URU'0K+,H£/&OÝUÆ9¯È Þ4WHÝUÕ9¯È ÞT3'*HVÝUÖ9§È Þ«=n3'*H£<R V RU5o3825UXTY[&(8u).5o31*<+,<LRU/2;S&('*+>&(8/¡L&
5URU/+.8:35N<BAfeIÉo$Â 4@8+.-08+,<+.'Q/<¢/2;*+w1*+,<2/2RN&('¡Ý RN<>/2;*+.8+i3FC935U143/2RN&('&Y/2;*+C9382Ro3D05N+,<l<21*);/2;43/l35U5
).5o31*<+,<J+.C935U143/+@/&d§Ç ±9­Ë ¬9Þlß
g_;0RN<u/28:3'*<mYn&(8 V 3/2RN&('SY8& V /2;*+ ¥ ~^Ë!gáY[&(8 V 105o3$àÑ0áÑã`
â ÎW4 $UâTà Ñ ÎÃÑâT¯ä 4JRN<uRU5U5U1*<2/28:3/+,H
RU'tx{RU6*ed*e Ð '«/2;*+Z698:3-0;ë¿ZW7'*&(/>35U5]+,HO6+,<PRN<<21*+,HyY[8& V /2;*+).5o31*<+,<P;43MC+DG+,+.'tHO8:3ML'7W7Yn&(8E/2;*+
<:3K+Z&Y8+M3(H*3D0RU5URU/Xe Ð /uRN<ER VV +,HORo3/+/&T);*+,):KS/2;43/MWY[&(8P3Yn&(8 V 105o3!I
Â W/2;*+.8+ZRN<P3iC(35U143/2RN&('t&Y
RU/<_C9382Ro3D05N+,<J<21*);/2;43/J+M3();I).5o31*<+ERN<J+.C935U143/+,HT/&Z/2821*+ERÍYh3'*HF&('05UXsRÍY!É8$Â 4_)M3'FDG+u-08&2+,)./+,H
RU'Q/&Z¿$Â 4fe
¡
§  ó7
 ³æå 
u&(/+/2;43/l/2;*+i<10D*<21 V -0/2RN&('8+.5o3/2RN&('¦RU'*HO1*),+,HkDQXj-08&m+,)./2RN&('¦&MC+.8^0?E<¢RN<l3£w143(<2RÍ~¡&(8H0+.8MWhD010/
'*&(/l3'¦&(8H0+.8MlRU/¢RN<l3F8+R4 +fORUC+s3'*H/28:3'*<2RU/2RUC+iD010/>'*&(/3'Q/2RÍ~¡<2X VV +./282RN)M35_8+.5o3/2RN&('7egL&«^0?E<
x{RU69108+@d* ç * 3 V -05N+>&Yh/28:3'*<mYn&(8 V 3/2RN&('FY[8& V ¥ ~^Ë!g§/&Ú

%AyýM}

y ]]} ]{%}

3 8+P<:3RNHT/&\DG+yÏ,M?º(Nf4RÍYh/2;*+.Xs-08&m+,)./J/&+M3();£&(/2;*+.8Me]ËÁ^0?°RN<<:3RNHF/&ZD+Z229aQ(4RÍYhRU/RN<
+,w10RUC(35N+.'//&&('*+u&Y{RU/<<2/282RN)./<210D0698:3-0;*<>=R$eô+9e]3l<210D0698:3-0;F'*&(/+,w1435/&o¿°RU/<+.5ÍYfAfWO&(/2;*+.82LRN<+ERU/
RN<J<:3RNHT/&\DG+ZB2(a94ne

p

q

sr

ç¿


t uvu

½hy|Mèy¯ºÃï  ½hyn }
qhM}]y|
 ü  ýJ(G(aL :ÆfOS ÙÆp( 1þÄ!m(aN.¡ia2QS!
Nf85ÄÈJfyyÏ.M?º(Nfa:.Í(:>(Z[P*	Ï,0ZN¡Mt$io,(\($aQofYRlB2(a94{9mBa 5

g_;*+¢pf2(a(4*©.(f¾&Y}3Z^0?V®
¿ RN<_3'sRU828+,HO10'*H*3'Q/<210D0698:3-0;F&Y¿®+,w10RUC935N+.'Q/_/&PRU/@=L;*+.'
¿áRN<RU828+,HO10'*H*3'Q/MW4/2;0RN<_698:3-0;sRN<À¿áRU/<+.5ÍY2WO&(/2;*+.82LRN<+E/2;*+.8+ V 3,XsDG+u<+.C+.8:35<21*):;I<210D0698:3-0;*<MWD010/

/2;*+.XF38+>35U57RN<& V &(82-0;0RN)Afe

;­

õ ºö

 úûM]ü|è9ýM.þtûMÿ=uèwu«úûMÔÔM3
øù F

èhé

ëê Dì¬#¡òUí_ëîï 9í 

ìqíîuï

;Ð

^Î

Í(#$

ðdñh#aìsòò$í±ós  Oí*ò

Í 
 F

ô òì

Î"ÓÐò

Ñ

ÌÏÐ

Í

g_;0RN<<+,)./2RN&('iRN<H0+.C&(/+,Hi/&l3's&MC+.82CRN+.L¬&Y7/2;*+HORÍÌ+.8+.'/ V &H0+.5N<),& V -G&9<RU'06¢/2;*+ÎÏSY$3 V RU5UXehrt+
LRU5U5GÑ*8<2/_&(10/25URU'*+E/2;*+ V 3RU' V &(/2RUC93/2RN&('*<Y[&(8_&(108_698:3-0;O~$D43(<+,HI3-0-08&3();I&Y}K'*&L5N+,HO6+E8+.-08+,<+.'O~
/:3/2RN&('7e

Ûõ C8» § 
å º ) §» ±ö 9o
ï 	

}h

y ]èynAyn}A{Ô¸}[{%}

y hMy



y|{3¸M}]}hu

¾´½¦¼û{­½h

x08& V 3 V &H0+.5URU'06ICRN+.L-G&(RU'/MW7L+\<+,+Z/¡L&I+,<<+.'/2Ro35q-08&(-+.82/2RN+,<PRU'
 ]y  }$ $y
ÓM }
/2;*+Z<2R V -05N+l698:3-0; V &H0+.5$e@g_;*+FQ¤M2,.W<2R V -05N+l698:3-0;*<MW738+l+M3(<2RU5UX10'*H0+.8<2/:3'*H*3D05N+ZDXy3'S+.'*H~
1*<+.8=n3sK'*&ML5N+,HO6+i+.'069RU'*+,+.8>&(8P+.C+.'3't+fO-G+.82/BAfeË'*H¦2.(4p(i38++M3(<2RU5UX£10'*H0+.8</:3'*H*3D05N+
/&&0W9Yn&(8q/¡L&>8+M3(<&('*<-08&2+,)./2RN&('iRN<3E698:3-0; V 3/):;0RU'06l&(-+.8:3/2RN&('7W/2;Q1*<+M3(<2RU5UXRU'Q/+.82-08+./:3D05N+E3'*H
CRN<21435URN<:3D05N+943'*HF/2;*+@<B3 V +@5o3'0691436+@RN<1*<+,H£3/RU'Q/+.8mY$3(),+¢3'*HI&(-+.8:3/2RN&('43575N+.C+.5N<Me
Ë5U/2;*&(1069;/2;*+.8+RN<3E6Q3-\D+./¡L+,+.'i/2;*+/2;*+,&(8+./2RN)M35aY[&(10'*H*3/2RN&('*<<2/21*HORN+,H\;*+.8+3'*Hi3u5o3'0691436+
1*<:3D05N+TRU'Æ8+M353-0-05URN)M3/2RN&('*<MWL+IL&(105NHÆ5URUK+T/&SD082RN+ *X V +.'Q/2RN&('Ò/L&«-08&2+,)./<RU'ÆL;0RN):;Ò/2;*+,<+
-08&(-+.82/2RN+,<;43MC+lDG+,+.'S+f;0RUD0RU/+,HeEg_;*+¢Ñ*8<2/u&('*+¢RN<E3'S+f-+.82R V +.'Q/ERU'SH0&).1 V +.'/@8+./282RN+.C(35hH0&('*+
DQX\?E+.'*+,<2/=n9Õ9Õ9ÕAfe Ð 'Z/2;0RN<!L&(82KWQ),&('*),+.-0/21435a698:3-0;*<]38+_1*<+,HZ/&@H0+fÑ*'*+3u5o3'0691436+Y[&(8!RU'*H0+fORU'06
3'*HFw1*+.82XRU'06H0&).1 V +.'Q/<Me%&('*),+.-0//¡X-G+,<J38+u/:3K+.'TY[8& V /2;*+/2;*+,<B310821*<J&Y{ãË ç Ë
=n3D&(10/
dQÕ9ÕJÕ9Õ9Õ_/X-+,<BAfW(3H0&).1 V +.'Q/:382X@5o3'0691436+1*<+,H@RU' V &9<2/Y[8+.'*);¢-010D05URN)3'*H@10'0RUC+.8<RU/:382X@5URUD08:382RN+,<Me
g_;*+>+fO-+.82R V +.'Q/E-08&MC+,H£/2;*+@Yn+M3(<2RUD0RU5URU/¡X£&Yh/2;*+>-08&(-G&9<:+,H£<2XO<2/+ V =LPe 8Me /Me),& V -010/2RU'06s/2R V +A3'*H
3'ÒR V -08&C+,Hß8+.5N+.C93'*),+ILPe 8Me /MeÊ/&«/2;*+£+fRN</2RU'06j<2XO<2/+ V D43(<+,HÆ10-&('ßãË ç Ë W V 3RU'05UXÆHO1*+
/&¦/2;*+«1*<+«&Y<+ V 3'/2RN)t8+.5o3/2RN&('*<IRU'*</+M3(H§&YlK+.XL&(8H0<£&('05UXe z'*+t<2RNH0+«+fÌ+,)./IL3(<£35N<&Æ/&
-08&MC+y/2;*+£RU'Q/+.8+,<2/F&Y><2R V -05N+£698:3-0;*<iY8& V 3 V &H0+.5URU'06kCRN+.L-&(RU'Q/Me Ð '*H0+,+,HW/2;*+.RU8s698:3-0;0RN)M35
-08&(-+.82/2RN+,<+.'43D05N+,Hi/&@D010RU5NHi3'iRU'*H0+fRU'06 w1*+.82XRU'06¢/&&(5*/2;43/]L_3(<),&('*<RNH0+.8+,Hs3(<+M3(<2XZ/&P1*<+_Yn&(8
/2;*+RU'*H0+f0+.8<Mehg_;*+1*<+.8<!L+.8+ V 3(<2/+.8];Q1 V 3'0RU/2RN+,<_<2/21*H0+.'Q/<W'*&(/3ML38+Y[8& V ),&('*),+.-0/21435a698:3-0;*<
'*+.RU/2;*+.8Y8& V ãËu ç Ë QLRU/2;i/2;*+u<&Y[/¡L_38+E3'*HT3'sRU'*H0+fRU'06l6910RNH0+9WO/2;*+.XDG+,)M3 V +Ew10RN)K5UX3D05N+
/&ZD010RU5NHIRU'*H0+f*3/2RN&('*<MW0/2;43/L+.8+P),&('*<2RNH0+.8+,H£&Y{;0RU69;Iw1435URU/¡XTDXF3Z<:+.'0RN&(8J5URUD08:382Ro3'7e
g_;*+i<+,),&('*Hj-08&2+,)./>/:3K+,<¢-05o3(),+\RU'K'*&L5N+,HO6+T+.'069RU'*+,+.82RU'06¦=[Ó_&9<MWhÓ_&(/+.5U5o3OW} ]3'0;*+,+.69;*+9W
`Mb9bÀ9Afe Ð /<q-01082-&9<+JRN<]/2;*+),&('*<2/2821*)./2RN&('F&Y/&&(5N<qY[&(8 V &H0+.5URU'063'*H<R V 105o3/2RU'06l;Q1 V 3'T&(826Q3'0R 3º~
/2RN&('*<MW3(<E+ V +.826+.'*).X-08&),+,HO108+,<Y[&(8uRU'*<2/:3'*),+9ePz'*+ V 3RU'«HOR ).105U/XRU'yK'*&L5N+,HO6++.'069RU'*+,+.82RU'06
RN<_/&ZC935URNH*3/+P3 V &H0+.5URU'06*WOR$eô+9e!/&):;*+,)Ks/2;43//2;*+@+f-+.82/8+M3(<&('0RU'06RN<),&(828+,)./25UX V &H0+.5N+,Heqg_;0RN<
C935URNH*3/2RN&('yRN<E1*<1435U5UXH0&('*+lL;*+.'y/2;*+ZH0+,<2RU69'SRN<@3();0RN+.C+,HW7;*+.8+¢DX£<2R V 105o3/2RU'06F/2;*+¢),&('*</2821*)./+,H
V &H0+.5URU'06>&YG/2;*+&(826Q3'0R 3/2RN&('7e]Ë_/!/2;0RN<hÑ*'4354<2/:36+9W V &HORÍÑ4)M3/2RN&('*<38+JC+.82Xl),&9<2/25UXehg_;*+_K+.XlRNH0+M3
&Y/2;*+J-08&2+,)./]RN<]/&>&MC+.8),& V +/2;0RN<HOR ).105U/¡X\DX69RUCRU'06P/2;*++f-+.82/]/2;*+u3D0RU5URU/¡X/&>1*<+J<2R V 105o3/2RN&('
RU'*<2RNH0+E/2;*+PH0+,<RU69'I).X).5N+P3(<3 V +M3'£&Yh+.'082RN):;0RU'06s3'*HTD010RU5NHORU'06\;0RN< V &H0+.5URU'06*e]g_;0RN<JR V -05URN+,</2;43/
/2;*+@);*&9<:+.' V &H0+.5URU'065o3'0691436+P+.'43D05N+,</2;*+@+fO-G+.82//&lYn&(5U5N&ML®8+M3(<:&('0RU'06<J<2/+.-FDQXT<2/+.-7W0HORU8+,)./25UX
&('I;0RN<&ML' V &H0+.5UR 3/2RN&('7e Ð /L3(<uH0+,).RNH0+,HI/&D010RU5NH£<21*);S3Z5o3'0691436+P10-&('),&('*),+.-0/21435{698:3-0;*<Me
?E+.'*+.8:35q),&('*),+.-0/21435698:3-0;*<P+,wQ10RUC935N+.'Q/>/&sx{zu|ÒL+.8+\'*&(/P),&('*<2RNH0+.8+,Hj3(<E6&&HS)M3'*HORNH*3/+,<PD+f~
)M31*<+/2;*+.X38+RU'*H0+,+,H\3EHORo3698:3 VV 3/2RN)<2X</+ V &YG5N&(69RN)/2;43/!RN<h'*&(/]3/{/2;*+_+fO-G+.82/!5N+.C+.5$e Ð '*<2/+M3(HW
/2;*+E5o3'0691436+EL3(<J698&(10'*H0+,HF10-G&('F<2R V -05N+E698:3-0;*<3'*Hs+fO/+.'*<2RN&('*<>=[<1*);3(<_'*+,<2/2RU'06<&Y{698:3-0;*<BA
K+,+.-0RU'06I/2;*+.RU8@8+M3(H*3D0RU5URU/Xez-G+.8:3/2RN&('*< V RÍ0+,H«<2R V -05N+Z698:3-0;tH0+,HO1*)./2RN&('ß=R$eô+9e¢-08&2+,)./2RN&('aAuLRU/2;
'*&('H0+,).5o38:3/2RUC+>-08&),+,HO108+,<Me]x}RU8</J+f-+.82R V +.'Q/<L+.8+>),&('*).5U1*<RUC+9e

R

¯

¯


÷

¯

eú

6ù

ø½

6ù

eú

6ù

å

ö <

óüºB^A{Ô¸M}h{» $y oÓ } x08& V 3S),& V -010/:3/2RN&('435uCRN+.L-&(RU'Q/MWL+F/2;0RU'0K¦/2;43/\698:3-0;O~
D43(<+,Hj8+M3(<&('0RU'06<MWhD+.'*+fÑ*/2/2RU'06Y[8& V 698:3-0;O~$/2;*+,&(8+./2RN)M358+,<2105U/<W{)M3'kD082RU'06«3'jRU'Q/+.8+,</2RU'06y-+.8m~
<2-+,)./2RUC+s/&£5N&(69RN)s-08&(698:3 VV RU'06*ekÓX+f*3 V -05N+9W!/2;*+F+,wQ10RUC935N+.'*),+sDG+./L+,+.'Ê^0?ä-08&2+,)./2RN&(' 3'*H

;­A­
õ

»

3M¼¾½øuM%

U 
½

H0+,HO1*)./2RN&('TRU'ix}zu|+$ Ä* 4)M3'iD+<:+,+.'T3(<_3's35U/+.82'43/2RUC+uC+.8<2RN&('T&Y7/2;*+PO(\(\($aQof 02(f
=$%;43'*HO8:3k £+.825URU'7W@`MbÀ9À9AfW),&('*<RNH0+.8+,Hß3(<Y[10'*H*3 V +.'Q/:35Yn&(8H*3/:3D43(<+w1*+.82RN+,<s&(-0/2R V R 3/2RN&('
=[ËD0RU/+.DG&(105$WÃ105U5$W uRo3'Q17W>`Mb9b9vAfe§z/2;*+.8s8+,<2105U/<s38+&(D0/:3RU'*+,H Y8& V ),&('*</28:3RU'Q/s-08&(698:3 V ~
Ø }× Ö ×pØ 4Ý
V RU'06*eSg_;*+T<2/28&('06«+,wQ10RUC935N+.'*),+D+./¡L+,+.'ÆÎÏ{Ý Ü × §3'*Hk/2;*+
×
Á=[<:+,+u^+,)./MeOcOWL;*+.8+/2;*+/28:3'*<mYn&(8 V 3/2RN&('*<1*<+,H\K+,+.-T35U5a<&(5U10/2RN&('*<3'*H-08+,<+.82C+
/2;*+J<2/2821*)./2108+&Y/2;*+),&('*<2/28:3RU'/]'*+./¡L&(82K\RU'\/2;*+wQ1*+.82X*A!35U5N&MLJ</&@/28:3'*<25o3/+/2;*+8+,<2105U/<&(D0/:3RU'*+,H
RU'/2;0RN<h5o3/2/+.8]),& VV 10'0RU/¡X=DQXZ+f*3 V -05N+9W9/28:3()./:3D05N+J)M3(<+,<hD43(<+,HZ10-&('/2;*+<2/2821*)./2108+J&YG/2;*+_698:3-0;7W
?E&(/2/25N&(D7W|+,&('*+9W¬^)M38),+.5U5N&0W4`Mb9b9bAfW(Ñ*8<2/h/&uÎÏ}Ý }Ü × hWQ/2;*+.'Z/&EH0+,HO1*)./2RN&('RU'x}zua
| $ Ä* 4fe
g_;*+T698:3-0; </2821*)./2108+F)M3'ß35N<&yDG+T1*<:+,H¦/&yH0+.C+.5N&(-ß+ ).RN+.'Q/s35U6&(82RU/2; V <RU' V &(8+F6+.'*+.8:35
V &H0+.5N<]&Y7/2;*+Î_ÏyYn3 V RU5UX{RU'\/2;*+ V &H0+.54L+)M35U5aÎ =[<+,+JD+.5N&MLAfW0%&(105N&('*HO8+u3'*HT^O35UC(3/E=m`Mb9b9cA
1*<+l/2;*+Z698:3-0;O~$D43(<+,H«'*&(/2RN&('t&Y]a$2:/&sD010RU5NHt3't+ ).RN+.'Q/PD43():KL_38H~¡);43RU'0RU'06«35U6&(82RU/2; V elg}&
+.'0;43'*),+P/2;*+PY[&(82L_38H~¡);43RU'0RU'0635U6&(82RU/2; V 1*<+,HIRU'I/2;*+ V &(8+P6+.'*+.8:35 V &H0+.5N<&Yh/2;*+>ÎÏY$3 V RU5UXW
Ó36+./t=n9Õ9ÕO`As+f-08+,<<:+,<sH0+.-+.'*H0+.'*).RN+,<TD+./¡L+,+.'â82105N+,<I3'*HÊ),&('*</28:3RU'Q/<TRU'¬/+.8 V <F&Yl3698:3-0;
;*& V & V &(82-0;0RN< V e
z108!3R V RN</2;Q1*<{/&JD010RU5NH>Y[&(8 V 35O+fO/+.'*<2RN&('*<}&Y4<R V -05N+),&('*),+.-0/21435698:3-0;*<MW(K+,+.-0RU'06u8+M3(H*3D0RU5URU/¡X
&Y]&(DO2+,)./<u3(<L+.5U5!3(<8+M3(<&('0RU'06<WG3'*H£-08+fY[+.8:3D05UXWa5N&(69RN)M35U5UXFYn&(10'*H0+,Heg_;*+>ÎÏkY$3 V RU5UXFRN<u3Ñ*8<2/
<2/+.-FRU'I/2;0RN<HORU8+,)./2RN&('7e

· ¸$ºþÍv¸$ÿ|»
µ

6ù

K´µv´ ¶{· ¸$º

0ûF¸º 2·DÍ{ü ¹ºD· vü· ;ýü¶

K´µ*´ ¶{· ¹¸$º
Rú
Rú

å Oö ;ö <

U 

&

Î Ï z{ºT	»

|7+./}1*<'*&LjRU'OYn&(8 V 35U5UXP-08+,<+.'Q/}/2;*+qÎ_ÏsYn3 V RU5UXe{g_;*+q6+.'*+.82RN)-08&(D05N+ V /&JD+q<&(5UC+,HW Ü × hW
3(<2KO<MW(69RUC+.'3uK'*&ML5N+,HO6+JD43(<:+E=[¿@ÓJA{Çâ3'*H\3u<2R V -05N+J698:3-0;iÉW9L;*+./2;*+.8É§)M3'DG+H0+,HO1*),+,HZY[8& V
Çe!Ë),),&(8HORU'06>/&>/2;*+JKRU'*H0<]&Y7&(DO2+,)./<]),& V -&9<2RU'06¢ÇW&('*+&(D0/:3RU'*</2;*+HORÍÌ+.8+.'Q/ V + V DG+.8<&Y/2;*+
Y$3 V RU5UXe Ð '\/2;*+D43(<2RN) V &H0+.5aÎÏWÇâRN<]),& V -&9<+,Hs&Y73><+./Ït&Y<2R V -05N+J698:3-0;*<8+.-08+,<+.'Q/2RU'06lY$3()./<MW
3'*HÆ<&(5UCRU'06 Ü × á3 V &(10'Q/</&S);*+,):K¦L;*+./2;*+.8/2;*+.8+TRN<\3-08&2+,)./2RN&('¦Y[8& V ÉÔRU'Q/&tÏe
ãJ105N+,<u3'*HI),&('*<2/28:3RU'/<E38+ V &(8+P),& V -05N+f&(DO2+,)./<D43(<+,HI10-G&('y<2R V -05N+@698:3-0;*<MWG3'*H&(-+.8:3/2RN&('*<
H0+M35URU'06\LRU/2;I/2;*+,<:+P&(DOm+,)./<38+@D43(<+,HF10-&('F-08&m+,)./2RN&('7e
g_;08&(1069;*&(10//2;0RN<J<+,)./2RN&('7W0L+@LRU5U571*<+@+f*3 V -05N+,<JRU'*<2-0RU8+,HsY[8& V 3 V &H0+.5UR 3/2RN&('£&Yq3lK'*&L5Í~
+,HO6+\3(),w10RN<2RU/2RN&('j)M3(<+Z<2/21*HOXW7)M35U5N+,HÆÖ*Ù{Ø×Ú*Û7Ü7Ø,Ý:Þ.RU/@H0+,<).82RUD+,<>3i8+,<&(108),+35U5N&)M3/2RN&('«-08&(D05N+ V W
L;*+.8+/2;*+\3R V RN<E/&I3(<<RU69't& ),+,<@/&T-G+.8<:&('*<@&Y_3s8+,<+M38):;t698&(10-«L;0RU5N+ZY[105ÍÑ*5U5URU'06I<& V +),&('O~
<2/28:3RU'/<¢=[Ó36+./+./35$eUW7`Mb9b9bAfe
ï Û

û}

My| $y

ô´½$y

µ*´ ¶{· ¹¸º

µv´ ¶{· ¸$º

6ù

4ú

 D

Office

near

Office

near

 

Office

adjoin

Office

adjoin

Office

near


	

Researcher

member

Project

x}RU69108+¢vOqãJ105N+,<

Ý

Cß

ËÔBUs+fO-08+,<<+,<¢K'*&ML5N+,HO6+T&Y_Y[&(8 V ¡RÍYñRN<>-08+,<+.'/¢/2;*+.' )M3'kDG+s3(H0H0+,H :e Ð /PRN<
»y|
+.'*),&H0+,HFRU'Q/&s3Z<2R V -05N+@698:3-0;I-08&CRNH0+,HLRU/2;I/¡L&),&(5N&(8<MW0/2;*+@Ñ*8<2/J),&(5N&(8<210D0698:3-0;yH0+fÑ*'0RU'06\/2;*+

;­

õ Mõ

 úûM]ü|è9ýM.þtûMÿ=uèwu«úûMÔÔM3
øù F



Office: #1

adjoin

Office: #2

adjoin

near



Office: #1

Office: #3

adjoin

near

adjoin

Office: #2

Office: #4

near

adjoin

Office: #3

near

near

near

near

adjoin

Office: #4

x{RU69108+>­O!ãJ105N+¢3-0-05URN)M3/2RN&('*<
;QX-&(/2;*+,<2RN<>3'*H«/2;*+\<:+,),&('*H«),&(5N&(8P/2;*+\),&('*).5U1*<2RN&('7e Ð 'tHO8:3,LRU'06<WL+8+.-08+,<+.'Q/¢/2;*+;QX-&(/2;*+,<2RN<
DQXyL;0RU/+'*&H0+,<MW3'*HS/2;*+),&('*).5U1*<2RN&('jDQXy698:3,X«&('*+,<MeZx{RU69108+\vT<2;*&MLJ<@/2;08+,+\82105N+,<Me  D 3'*H  
8+.-08+,<+.'/PK'*&L5N+,HO6+3D&(10/P/2;*+TG2(s8+.5o3/2RN&('7W<10-0-G&9<+,Hy/&TD+H0+fÑ*'*+,H«D+./¡L+,+.'& ),+,<P&('05UXe
+ ]FRN<2(3'T& ),Y
+ _W/2;*+.Z
' _
 D +fO-08+,<<+,</2;43/_/2;*+E8+.5o3/2RN&('SG2(lRN<_<2X VV +./282RN)M35]= ¡RÍY{3'F& ),b
RN<uG2(E
 ] AfW   /2;43/ RÍY}3'F& ),1
+ ]j2¤.(0@3's& ),Y
+ _/2;43/Pm¤,(0u3'F& ),+ l/2;*+.«
' ]FRN<G2(
:eg_;*+P82105N+ 	 <:3,XO<J/2;43/E+.C+.82XI8+,<+M38):;*+.8ERN< V + V D+.8@&Y3-08&2+,)./Z= ¡RÍYq/2;*+.8+¢RN<E38+,<+M38):;*+.8
]}WO/2;*+.8+PRN<3Z-08&2+,)./J&Y{L;0RN):g
; ]RN<3 V + V D+.8 Afe
ã105N+,<>38+1*<+,HS/&F+.'082RN):;tY$3()./<MERÍY/2;*+\;QX-G&(/2;*+,<2RN<>&Y3s82105N+\)M3'jDG+Z-08&2+,)./+,H«RU'Q/&£3^0?ZW
/2;*+.'F/2;*+E82105N+ERN<3-0-05URN)M3D05N+@/&Z/2;0RN<^0?W*3'*HTRU/<),&('*).5U1*<2RN&(')M3'FD+E3(H0H0+,HI/&Z/2;*+>^0?Á3(),),&(8HORU'06
/&£/2;*+-08&2+,)./2RN&('7©
e &(/2RN),+s/2;43/Z+M3();¦-08&m+,)./2RN&('Æ&Y3£<:3 V +i82105N+i/&S3S^0? H0+fÑ*'*+,<\3£HORÍÌ+.8+.'/
L3MX &Y¢3-0-05UXRU'06k/2;0RN<i82105N+S3'*H RN<i5URUK+.5UXÆ/&k3(H0Hß'*+.LäRU'OYn&(8 V 3/2RN&('¬/&j/2;*+S^0?Ze%&('*<2RNH0+.8Yn&(8
RU'*<2/:3'*),+@/2;*+l^0#
? ¿&Y!x{RU6*eq­OW0L;0RN);yH0+,<).82RUDG+,<<2-43/2Ro357RU'OYn&(8 V 3/2RN&('£3DG&(10/& ),+,<MW43'*HF82105N+,<J&Y
x{RU69108+lvOe  D RN<E3-0-05URN)M3D05N+F=[<2RU'*),+sQm¤.9pB
 \ñG(9AfW3'*Hy<&\RN<   e|7+./E1*<u),&('*<2RNH0+.8   eg_;*+.8+
38+s/¡L&SL3,XO<&YE3-0-05UXRU'06S/2;0RN<Z82105N+9WqH0+.-+.'*HORU'06t&('kL;*+./2;*+.8RU/<l;X-&(/2;*+,<2RN<ZRN< V 3-0-G+,HÆ&('/&
/2;*+P-43/2V
; Ý·T¸§¸¹§²¬«
 I6Þ
 ¨° ¹!¢µ"
 Ý·T¸¸¹²T¬# Þ$
 ¨>°­ ¹%üµ"$a
 Ý·¸¸¹§²¬&# Þs&(8&('Q/&/2;*+
-43/2; Ý·¸¸¹§²¬&# Þ$
 ¨° ¹!¢µ$
 Ý·T¸§¸¹²T¬  Þ$
 ¨>°­ ¹%¢µ$a
 Ý·T¸§¸¹§²¬(' Þ4e Ð '/2;*+Ñ*8<2/
)M3(<+yYn&(8FRU'*<2/:3'*),+9W@3k8+.5o3/2RN&('®'*&H0ÿ
+ ¨ ¬§°±üµtLRU/2;§-08+,H0+,),+,<<&(V
8 Ý·T¸§¸¹§²¬«
 I6Þß3'*H§<1*),),+,<<&(8
Ý·¸¸¹²¬&# ÞkRN<s3(H0H0+,HÒ/&t/2;*+S^0?Za
e u&(/2RN),+I/2;43/iRU' /2;0RN<s+f03 V -05N+9WJ3-0-05UXRU'06Æ35U582105N+,<iRU'Ê35U5
-&9<<2RUD05N+@L_3,XO<u3(<5N&('06s3(<J/2;*+.X3(H0H'*+.LâRU'OYn&(8 V 3/2RN&('RN<u3ZÑ*'0RU/+P-08&),+,<<l=5N+M3(HORU'06i/&/2;*+>698:3-0;
&Yhx{RU69108+>­AD010/RU/RN<'*&(//2821*+@RU'I6+.'*+.8:35$e
rÊ;*+.'\/2;*+J¿@Ó¦RN<q),& V -&9<+,H\&Y73@<+./&YaY$3()./<]Ï«3'*H3@<:+./q&Y82105N+,<&£W/2;*+ Ü × -08&(DO~
5N+ V 3(<2KO<L;*+./2;*+.8@/2;*+.8+lRN<@3<:+,wQ1*+.'*),+Z&Y]82105N+3-0-05URN)M3/2RN&('*<P+.'082RN):;0RU'06F/2;*+>Y$3()./<E<21*);S/2;43/u/2;*+
6&35hÉª)M3'D+@8+M3():;*+,HW4R$eô+9e5N+M3(HORU'06s/&3698:3-0;£RU'Q/&\L;0RN):;£/2;*+Z^0?ªÉª)M3'D+@-08&2+,)./+,He ç e 6*e
),&('*<2RNH0+.8/2;*+_Yn3().Ñ
/ ¿§&Y7x{RU69108+­OW3'*H5N+./É§D+_/2;*+u^0%
? Ý·¸¸¹§²¬&#(' Þ$
 ¨) ¬§°±¢µ$a
 Ý·T¸§¸¹§²¬TÞs= ¡RN<
('u'*+M38h3'l& ),+ AfeqÉßH0&+,<'*&(/{-08&m+,)./{RU'Q/&@ÏWD010/h3-0-05UXRU'06u/2;*+]82105N+,<MW9&('*+_3(H0H0<}/2;*+]RU'OYn&(8 V 3º~
/2RN&(¦
' Ý·T¸§¸¹§²¬(' Þ
 ¨) ¬°T±¢µ$
 Ý·T¸§¸¹²T¬ ÞF=n35N<& Ý·T¸§¸¹²T¬(' Þ
 ¨­¬°T±¢µ"
 Ý·T¸¸¹²T¬# ÞAfW
/2;Q1*<u3'*<2L+.82RU'06FÉe

ÔMß

*ß

Ý

4ú

4ú

5ß

&Ý

4ú

&Ý

4ú Ô

4ú

4ú

4ú

dÚ


dÚ

d

dÚ

µv´ ¶{· ¸$º

4ú AÞGß

q

dÚ



&Ý

Ý

Ë (0.[m9p4>)M3'jD+-G&9<RU/2RUC+&(8>'*+.6Q3/2RUC+9W!+fO-08+,<<2RU'06£K'*&L5N+,HO6+T&YYn&(8 V ¡RÍY
M}h	A{% }A
 ;*&(5NH0<MW<& V 1*<2/* :W&(8 ¡RÍY+Ô;*&(5NH0<MW, V 1*<2/s'*&(/ :e Ð /iRN<s35N<:&3«D0RN),&(5N&(8+,HÊ<2R V -05N+£698:3-0;7
Ô
/2;*+lÑ*8<2/@),&(5N&(8PH0+fÑ*'*+,<@/2;*+),&('*HORU/2RN&('t-4382/=[&(8\[fUMQfAfW3'*HS/2;*+<+,),&('*H«),&(5N&(8@/2;*+ V 3'*H*3/&(82X
=[&(8PYn&(82D0RNH0H0+.'aAE-4382/MeFË ^0? ¿ <:3/2RN<2Ñ4+,<¢3F-&9<2RU/2RUC+i),&('*<2/28:3RU'Q/ ñRÍY¢2.j-08&m+,)./2RN&('Y[8& V /2;*+
),&('*HORU/2RN&('F-4382/J&Y °RU'/o
& ¿Á)M3'TDG+E+fO/+.'*H0+,Hi/&3¢-08&2+,)./2RN&('I&Y}/2;*+uL;*&(5N+ ehË'*7
H ¿°<B3/2RN<mÑ4+,<
3j'*+.6Q3/2RUC+y),&('*</28:3RU'Q/TRÍYa-08&2+,)./2RN&('¬&YP/2;*+y),&('*HORU/2RN&('®&Y
RU'Q/¶
& ¿ )M3'ßD+y+f/+.'*H0+,HÊ/&
3£-08&m+,)./2RN&('Ò&Yu/2;*+TL;*&(5N+ etx{RU6*e¦À<;*&MLJ<Z/¡L&t),&('*<2/28:3RU'/<Meg_;*+T'*+.6Q3/2RUC+F),&('*</28:3RU'Q/ D

ß dÝ

TÄ

0Ä

5ß

;­

õ !-

Ä
Ä

Ä

Ä

»

3M¼¾½øuM%

works−with

Person

HeadOfGroup

Secretary

in

in

Person

in

in
Office

Ä

Ä
D

Office

near

Office



x{RU69108+¢À%&('*<2/28:3RU'/<

=Ý

4ú Rß
4ú
Mß
Ä

+fO-08+,<<+,</2;43/ ¡/¡L&i-+.8<&('*<L&(82KRU'06s/&(6+./2;*+.8<2;*&(105NHF'*&(/u<2;438+>3'y& ),+ :eg_;*+Z^0? ¿&Yqx{RU6
iH0&+,<u'*&(/@<:3/2RN<mY[XF/2;0RN<E),&('*<2/28:3RU'Q/@D+,)M31*<+ ¡/2;*+.8+lRN<E38+,<+M38):;*+.8@L;*&iL&(82K<uLRU/2;S8+,<+M38):;*+.8
¿ s=-08&2+,)./2RN&('«&Y]/2;*+¢),&('*HORU/2RN&('«-4382/@&Y oIA 3'*Hy/2;*+.X<2;438+Z& ),+/.s`Md T=[+fO/+.'*<2RN&('«&Yq/2;*+
-08&2+,)./2RN&('£/&T3-08&2+,)./2RN&('y&Yq/2;*+¢L;*&(5N+ IAfeJg_;*+¢-G&9<RU/2RUC+¢),&('*<2/28:3RU'/  +f-08+,<:<+,</2;43//2;*+
& ),+P&Yq3l;*+M3(HI&Yh698&(10- V 1*<2/DG+E'*+M38J/2;*+>& ),+,<&Yq35U57<+,).8+./:382RN+,<Me
rÊ;*+.'Æ/2;*+F¿@ÓªRN<),& V -&9<+,HÆ&Y@3£<:+./\&YY$3()./<\Ï°3'*HÆ3S<+./&YE),&('*<2/28:3RU'Q/<\åhW]/2;*+i8&(5N+F&Y
),&('*<2/28:3RU'/<IRN<F/&ÆH0+fÑ*'*+S/2;*+t),&('*<RN<2/+.'*).XÊ&Yl/2;*+SD43(<+9WuR$eô+9eà&YZÏeñg_;*+«D43(<+SRN<F<:3RNH¬/&¦D+
),&('*<2RN<2/+.'/RÍY35U5{),&('*<2/28:3RU'Q/<P38+¢<:3/2RN<mÑ4+,He ¯ 8&MCRNH0+,H£/2;43//2;*+>D43(<:+PRN<u),&('*<2RN<2/+.'Q/MWH0+,HO1*)./2RN&('yRN<
H0&('*+3(<uRU'£Î_Ï_e ç C+.'yRÍY/2;*+.Xy38+¢DG&(/2;SD0RN),&(5N&(8+,Hy698:3-0;*<MW),&('*<2/28:3RU'/<>38+>'*&(/E/&iDG+Z),&('OY[1*<+,H
LRU/2;I82105N+,<Me]%&('*<RNH0+.8JYn&(8RU'*<2/:3'*),+@/2;*+ED0RN),&(5N&(8+,HI698:3-0; 	 &Y!x{RU69108+PvO]3(<3l82105N+9W0RU/J<B3,XO</2;43/
+.C+.82Xt8+,<+M38):;*+.8ZRN<l3 V + V D+.8l&YE3F-08&2+,)./Me£g{3K+/2;*+Yn3()./Ï1Ã
0 Ý0ª­¬¯®T¬§°±¢²´³ ¬T±2 acÞ«3'*H/2;*+
w1*+.82XiÉ+©
0 Ý0ª­¬¯®¬°±¢²´³­¬±2 aÞ$
 ¨43 ¬!3­5 ¬±üµ"$a
 Ý76 ±8¯ ¬ ² §ÞF= ¡RN<¿e V + V D+.8&Y}3@-08&2+,)./ Afe Ð Y{ÉâRN<
3(<2K+,Hi&('
Ç "$n+
Ï *) "ÿm  §n¤4fW/2;*+3'*<2L+.8]RN< ¡X+,< :
e u&MLPW<+,+  	 3(<3E-&9<2RU/2RUC+),&('*<2/28:3RU'/ \e Ð /
<:3MX<]/2;43/]+.C+.82XZ8+,<+M38);*+.8 V 1*<2/DG+J3 V + V D+.8&Y3E-08&2+,)./Me!
Ç "$n+
Ï *m¾
å "m kn¤4!RN<!RU'*),&('*<2RN<2/+.'/MW
/2;Q1*<'*&(/2;0RU'06)M3'ID+@H0+,HO1*),+,HFY[8& V RU/MW0RU'*).5U1*HORU'06sÉ\eqg_;*+@¿@Ó¬;43(</&ZD+@8+.-43RU8+,HTÑ*8<2/Me

ß
4ú

Ý

ÃÄ ÃÝ
dÄ
4ú

Ú

TÝ ]ß

;Ç &Ý

ÞGß

4Ä

Ä

q 

|7+./>1*<@),& V D0RU'*+\82105N+,<¢3'*H«),&('*<2/28:3RU'Q/<>RU'«8+M3(<&('0RU'06*e
¢º ^ }h }h »y| {%}ó}$AAè{% }A
rt+PHORN<2/2RU'06910RN<;I'*&ML®D+./¡L+,+.'/L&\KRU'*H0<J&Yh82105N+,<M_M©,.2fG:¢BNBl3'*HS?( O[n(SBUffe
Ð 'OY[+.8+.'*),+Z82105N+,<P8+.-08+,<+.'Q/PR V -05URN).RU/>K'*&L5N+,HO6+/2;43/@RN< V 3(H0++f-05URN).RU/@DX£82105N+\3-0-05URN)M3/2RN&('*<e
g_;0RN<PRN<>/2;*+\)M3(<+ZYn&(8P82105N+,<¢<+,+.'3D&MC+£=[x{RU69108+svAfex43()./<Z3'*H«RU'OYn+.8+.'*),+\82105N+,<>)M3'jDG+\<:+,+.'3(<
H0+,<).82RUD0RU'06£3sL&(825NHW}3'*Ht3-0-05UXRU'063s82105N+ V &HORÍÑ4+,<P/2;*+\+f-05URN).RU/PH0+,<:).82RU-0/2RN&('j&Y/2;*+ZL&(825NH =/2;*+
Y$3()./<BAfC
e u&MLPWRÍYL+),&('*<2RNH0+.8¢3T¿@Ó°),& V -G&9<+,Hj&Y_3T<+./@&Y]Y$3()./<>ÏW3T<+./@&YRU'OY[+.8+.'*),+82105N+,<9£W
3'*HÆ3y<+./l&YE),&('*<2/28:3RU'Q/<lå!W!/2;*+s'*&(/2RN&('Ò&Y),&('*<2RN</+.'*).Xj;43(<Z/&£/:3K+T82105N+,<¢RU'/&t3(),),&(10'Q/Mex*&(8
RU'*<2/:3'*),+9W03(H0Hi/&>/2;*+@^0?Ed
< ¿á3'*H
&Yx{RU69108+u­>/2;*+Y[&(5U5N&LRU'06lRU'OYn&(8 V 3/2RN&('I3DG&(10/_& ),+E3(<<2RU69'O~
 Ý;: ¬§° ·T¸"< ±8 "=24a
> Þ$
 ¨L¹!¢µ"
 Ý·T¸¸¹²T¬#7
 I6Þ4Ñ
W Ý4? ¬­²´±­¬ °T± @7+
: Þ
 ¨L¹!¢µ$
 Ý·T¸§¸¹²T¬ Þ
V +.'Q/<o
3'*Q
H Ý4? ¬­²´±­¬ °T± @Aa
6 Þ
 ¨L¹!¢µ$
 Ý·T¸§¸¹²T¬ Þ4eh|7+.À
/ ¿ ê 3'*H ê D+/2;*+¢='*&(8 V 35pA_^0?E<&(D0/:3RU'*+,He
%&('*<2RNH0+.8P/2;*+\L&(825NHj),& V -&9<+,Ht&Y_/2;*+i^0? ¿bê[WRU'OY[+.8+.'*),+\82105N+,
< m  D *   n&Y_x{RU69108+ivOW{3'*HS/2;*+
-&9<2RU/2RUC+F),&('*<2/28:3RU'Q/  &YEx{RU69108+ÀeÆg_;*+£^0î
? ¿ ê 35N&('*+IH0&+,<'*&(/\<:3/2RN<2YX/2;*+F),&('*<2/28:3RU'Q/
=D+,)M31*<+ ¡/2;*+T;*+M3(Hk&Yu698&(10-Æ|qehRN<lRU'¦& ),+B7
 I9W]3'*Hk/2;*+F<+,).8+./:382X ¯ ehRN<lRU'¦& ),+B :W!D010/
RU/ZH0&+,<¢'*&(/Z;*&(5NHj/2;43/ %7
 IRN<¢'*+M38C Afe£Ó10/3ºY/+.83£),+.82/:3RU'k'1 V D+.8&Y82105N+s3-0-05URN)M3/2RN&('*<W
RU/>H0&+,<Mesg_;Q1*<P/2;*+i¿@ÓÁRN<><:3RNHt/&FDG+),&('*<2RN<2/+.'Q/Me Ð 't/2;0RN<>)M3(<:+RU/PRN<>+M3(<Xy/&H0+fÑ*'*+i3'*Hj):;*+,)K
),&('*<2RN<2/+.'*).XDG+,)M31*<+>/2;*+>L&(825NHSH0+,<).82RU-0/2RN&('y)M3'yD+>),& V -05N+./+.5UX£+fO-05URN).RU/+,H£DQX£3Ñ*'0RU/+Z^0? =/2;*+
ê W7<:3RNH«/&FD+E©faLPe 8Me /MeCTAfW/2;Q1*<PRU/P<1 ),+,<P/&I):;*+,)K«/2;43/P/2;0RN<@698:3-0;RN<P),&('*<2RN<2/+.'/Me
698:3-0;
Ð '6+.'*+.8:35J)M3(<+9W!),&('*<RN<2/+.'*).Xj8+.5URN+,<&('kL;*+./2;*+.8\+M3(); ),&('*<2/28:3RU'/\CRN&(5o3/2RN&(' T)M3'D+s8+.-43RU8+,H

MÇ 9Õ

Ý

7Ë

Ä

MÇ 9Õ

dÚ

Ý

4ú

4ú
dÚ;ß

4ú Ú;ß



ú

;­

õ ÷

Ý

ß

d

Ä.

 úûM]ü|è9ýM.þtûMÿ=uèwu«úûMÔÔM3
øù F

DQXT82105N+l3-0-05URN)M3/2RN&('*<MWa3(<LRU5U5D+uY[&(8 V 35U5UXIH0+fÑ*'*+,H5o3/+.8MeËu<LRU/2;£<R V -05N+.8JL&(825NH0<uH0+,<).82RUD+,HIDQX
Y$3()./<J&('05UXW*H0+,HO1*)./2RN&('RN<J'*&(/-G&9<<RUD05N+@&('IRU'*),&('*<2RN<2/+.'/K'*&ML5N+,HO6+PD43(<:+,<Me
Person

in

Office

x}RU69108+¢cO!Ëâ82105N+
ç C&(5U10/2RN&('j82105N+,<E8+.-08+,<+.'Q/P-&9<<2RUD05N+3()./2RN&('*<@5N+M3(HORU'06TY[8& V &('*+ZL&(825NHS/&F3'*&(/2;*+.8>&('*+9e ç e 6*e
),&('*<2RNH0+.8/2;*+>),&(5N&(8+,HI698:3-0;y&Yqx}RU69108+lcOeËu<3'RU'OY[+.8+.'*),+>82105N+9W*RU/L&(105NH£35U5N&Lá/&\H0+,HO1*),+>/2;43/
35U5-G+.8<:&('*<_38+uRU'I35U5& ),+,<MeqËu<3'T+.C&(5U10/2RN&('F82105N+9WRU/<:3MX<_/2;43/ ¡L;*+.'T/2;*+.8+P38+@3>-+.8<&('F3'*H
3'I& ),+9W43l-&9<<2RUD05N+@3()./2RN&('IRN</&\3(<:<2RU69'T/2;0RN<J& ),+@/&Z/2;43/-+.8<&(' :e%&('*<2RNH0+.83Z¿@Ó¬),& V -&9<+,H
&Y3i<+./&YqY$3()./<EÏW3<+./u&Y]+.C&(5U10/2RN&('S82105N+,<D]W3'*HS3\<+./E&Y]),&('*<2/28:3RU'Q/<uå!eux43()./<EH0+,<).82RUDG+Z3'
RU'0RU/2Ro35{L&(825NH+.C&(5U10/2RN&('S82105N+,<8+.-08+,<:+.'Q/E-G&9<:<2RUD05N+P/28:3'*<2RU/2RN&('*<Y[8& V &('*+>L&(825NHy/&s&(/2;*+.8L&(825NH0<M
),&('*<2/28:3RU'/<H0+fÑ*'*+u),&('*<2RN<2/+.'*).X\&Y+M3():;iL&(825NH03P<21*),),+,<<:&(8&Y}3P),&('*<RN<2/+.'Q/L&(825NHiRN<]&(D0/:3RU'*+,HsDQX
3'I+.C&(5U10/2RN&('I82105N+P3-0-05URN)M3/2RN&('7069RUC+.'3\^0?É\WO/2;*+@H0+,HO1*)./2RN&('I-08&(D05N+ V 3(<2KO<_L;*+./2;*+.8J/2;*+.8+ERN<J3
-43/2;&Y!),&('*<2RN<2/+.'/JL&(825NH0<u+.C&(5UCRU'06\Y8& V /2;*+@RU'0RU/2Ro35}&('*+@/&\3ZL&(825NH<:3/2RN<mY[XRU'06iÉ\e
g_;*+ V &9<2/l6+.'*+.8:35 V &H0+.5&YJ/2;*+sÎÏ§Yn3 V RU5UXj),&('*<RNH0+.8<ZDG&(/2;kKRU'*H0<Z&Y82105N+,<W_0 5W 5«3£<+./(
&Y]RU'OYn+.8+.'*),+Z82105N+,<MW3'*H«3i<:+./EDÒ&Y+.C&(5U10/2RN&('«82105N+,<e Ð 'y/2;*+l-4382/2RN).105o38P)M3(<+Z&Y]/2;*+iÖ*Ù{Ø×Ú*Û7Ü7Ø,Ý:Þ
V &H0+.5UR 3/2RN&('7WÏI3'*H9H0+,<).82RUD+!/2;*+qRU'0RU/2Ro35RU'OYn&(8 V 3/2RN&('Z3D&(10/}& ),+]5N&)M3/2RN&('*<MW-+.8<&('*<}3'*H>/2;*+
698&(10-&(826Q3'0R 3/2RN&('7eFñ35N<&@+.'*),&H0+,<q6+.'*+.8:354K'*&ML5N+,HO6+>=[<21*):;i3(<!-08&(-+.82/2RN+,<q&Y/2;*+P( ©i8+.5o3/2RN&('
-010/D+./¡L+,+.'£/¡L&\),&('*),+.-0/J'*&H0+,<8+.-08+,<+.'Q/2RU'06iHORN<2/2RU'*)./+.'Q/2RU/2RN+,<fAfe!å£8+.-08+,<:+.'Q/<&(D05URU6Q3/2RN&('*<u3'*H
RU'Q/+.8HORN)./2RN&('*<£H0+fÑ*'0RU'06ÆL;43/3(),),+.-0/:3D05N+t3(<<2RU69' V +.'/<38+Æ=RU'*).5U1*HORU'06 )M38HORU'435URU/¡X§),&('*<2/28:3RU'/<
<21*):;j3(< 3-+.8<&('t)M3'0'*&(/@D+spk<+.C+.8:35!& ),+,< Z&(8 3s5o3826+& ),+)M3'0'*&(/P),&('/:3RU' V &(8+Z/2;43'
/¡L&«-+.8<&('*< :W!1*<2RU'06«/2;*+«( ©Ò8+.5o3/2RN&('aAfeGD®),&('*<2RN<2/<&YE&('*+T+.C&(5U10/2RN&('Ò82105N+TL;*&9<+s8+,<2105U/RN<Z/&
-05o3(),+>3Z-+.8<&('IRU'/&3'& ),+s=RU/),&(105NH35N<&D+@),& V -&9<+,HI&Yq<+.C+.8:35782105N+,<),&('*<2RNH0+.82RU'06i<2-+,).RÍÑ4)
-08+,),&('*HORU/2RN&('*<TD+fY[&(8+/282XRU'06¦3'Ê3(<<2RU69' V +.'/BAfeâg_;*+6&358+.-08+,<+.'/<F3t<2RU/2143/2RN&('ÊL;*+.8+£+M3():;
-+.8<&('ß&YP/2;*+£698&(10-ß;43(<T3'¬& ),+9eâË <&(5U10/2RN&('Ê/&t/2;*+£-08&(D05N+ V RN<T3jL&(825NHÊ&(D0/:3RU'*+,H Y[8& V
/2;*+RU'0RU/2Ro35]&('*+\DQXt3T<+,w1*+.'*),+\&Y_& ),+i3(<<2RU69' V +.'Q/<WL;*+.8+\+M3():;t-+.8<&('t;43(<>3'j& ),+9WL;0RU5N+
<:3/2RN<mY[XRU'06/2;*+>35U5N&)M3/2RN&('£),&('*<2/28:3RU'Q/<Me

4ú

4ú

6ù

ï ï

p

4ú

5ß

4ú 5ß Ý

4ú

½hy Î_Ï

ß

4ú

6ù

Ý

£Ý

z{º

4ú

4ú

4ú

4ú



	»

|7+./J1*<J'*&MLâ<2-+,).RÍY[XsH0+fÑ*'0RU/2RN&('*<u3'*HF'*&(/:3/2RN&('*<),&('*),+.82'0RU'06i/2;*+@ÎÏjY$3 V RU5UXe

}



9 0f2¿ p

 y;}]¸}  óü»uy  ¼© ),&(5N&(8+,Hj<2R V -05N+698:3-0;¬o\O( ì" $¿k)* H­4oh
õ ²ª9a/Hko\F\BQap@©fm( Á $¿[4\pa$Zm%I *WI¤n¯5ëUOZ*fB.M,[9¡£$£IGMQ\o(U2
}
Ol),&(5N&(8Zm©POPaMQW5 
e >fa9¡ZS: KJ ML OEf0$(mf4£m©H¿ pa9O:TL:[Ì3!:(Í922sGMQBW5UO
B*n(2B4 JON L Zf©.9B¾E}
õ ²$N p5 ´J
5 OG.Í02(Bum©¢2.Í9[n(TaMEm©
JPN L ZQ.}( .fU(
$ JON L RT5



 







g ;*+E5o3/2/+.8),&('*HORU/2RN&('k= JON L V 1*<2/_Yn&(8 V 3\^0?PARN<_'*+,),+,<<B382XT3(<<&&('I3(<_L+P),&('*<RNH0+.882105N+,<3(<
_
),&(5N&(8+,HI^0?E<Mh<2;*&(105NHT3P82105N+'*&(/_<:3/2RN<mY[X/2;0RN<),&('*HORU/2RN&('7WORU/<3-0-05URN)M3/2RN&('F&('F3l^0?á),&(105NHs6+.'*+.8:3/+
3l698:3-0;I/2;43/JRN<J'*&(/3\^0?Ze
Ë ¿@ÓªRN<ZH0+.'*&(/+,HDXî
Ç " $n+
Ï *)g
 *)
D *m
å 4fW]L;*+.8+FÏâRN<l3y<+./Z&Y<2R V -05N+i698:3-0;*<Z8+.-08+,<+.'/2RU'06
Y$3()./<MW£WDj3'*HsåS38+u/2;08+,+@<+./<_&Y{),&(5N&(8+,HF<R V -05N+E698:3-0;*<_8+,<2-G+,)./2RUC+.5UXi8+.-08+,<+.'Q/2RU'06pM©Mffa:
fNBfWS ?º( [n(BUffW3'*HÆ(*f[2(paI=-&9<2RU/2RUC+Z&('*+,<ERU'yåRQ_WG'*+.6Q3/2RUC+\&('*+,<ERU'yåTS}Afe¢?uRUC+.'j3

;­

õ ¤Ö

»

3M¼¾½øuM%

¿@ÓÆÇá3'*Hi3E6&35É\W/2;*+>Q(OM[[(amfU.ñ3(<2KO<qL;*+./2;*+.8É®)M3'DG+JH0+,HO1*),+,H\Y8& V Çª=L+'*&(/+
É P Ç>Afe Ð YL+R V -G&9<:+<& V +J&Y7/2;*+<+./<&yWDS&(8!åI/&PD+J+ V -0/XW&('*+&(D0/:3RU'*<<-G+,).RÍÑ4)8+M3(<&('0RU'06
e u&(/+E/2;43/RU'F/2;*+>3D*<+.'*),+>&Yh),&('*<2/28:3RU'/<l=p¾
å " AfW*RU'OY[+.8+.'*),+>3'*H+.C&(5U10/2RN&('82105N+,<J;43MC+
V &H0+.5N<M
/2;*+P<:3 V +PDG+.;43MCRN&(8MW4/2;Q1*< 3'*HUDk)M3'IDG+@),&('OY[1*<+,Heg_;*+PÎÏjY$3 V RU5UXTRN</2;*+.'£),& V -&9<+,HI&Yh/2;*+
<2RÍsY[&(5U5N&LRU'06 V &H0+.5N<Me

¬«

F« « «
/2;*+PÎ V &H0+.5Yn&(8JÇW0 $nÏ+*g*XD*«4
/2;*+PÎÏå V &H0+.5Yn&(8JÇW0Ð$nÏ+*¯« *¯« *Jå.4
/2;*+PÎ\å V &H0+.5Y[&(8JÇY0 $nÏa*Eg*@¯« *å4
/2;*+PÎDå V &H0+.57Y[&(8JÇW0 $nÏ+*F¯« *D*_å4

V /2;*+PÎÏ V &H0+.57Y[&(8JÇW0 $nÏ+* ¯* ¯* 4
V
V
V
V

V /2;*+PÎCD7å V &H0+.5Yn&(8JÇW0 $nÏ+*Xg*,Da*å.4

^RU'*),+3EYn3()./q;43(<q/2;*+J<:3 V +J<+ V 3'/2RN),<3(<3E82105N+LRU/2;i3'+ V -0/XZ;QX-G&(/2;*+,<2RN<W/2;*+J<+./ÏRN<]1*<+,H
RU' V &H0+.5N<h'43 V +,<!&('05UX¢L;*+.'DG&(/2;Z82105N+_<+./<F¾3'*H(D38+_+ V -0/¡Xe!g_;*+;0RN+.8:38):;QX&Ya/2;*+,<+ V &H0+.5N<
NR <8+.-08+,<+.'Q/+,HyRU'£x{RU6*eGbOe Ð /;0RU69;05URU69;Q/<u/2;*+lH0+,).RNH*3D0RU5URU/¡X-08&(-+.82/2RN+,<E3'*H/2;*+¢),& V -05N+fRU/X£&Y!/2;*+
3(<<&).Ro3/+,HsH0+,HO1*)./2RN&('s-08&(D05N+ V ea&(/2RN),+L+uHORUCRNH0+'*&('TH0+,).RNH*3D05N+-08&(D05N+ V <_RU'/&i,fZM!Q2,[fU
3'*H«[f; :GQ2.nQfN¢-08&(D05N+ V <Me Ð 'T/2;*+Ñ*8<2/J)M3(<+9W03'3'*<2L+.8J)M3'FD+E),& V -010/+,HFRU'sÑ*'0RU/+E/2R V +
Yn&(835U57-G&9<RU/2RUC+@RU'*<2/:3'*),+,<JD010/'*&(/Y[&(835U5'*+.6Q3/2RUC+>&('*+,<Me Ð 'F/2;*+P<:+,),&('*HI)M3(<+9W0/2;*+.8+@RN<J'*&ZÑ*'0RU/+
-08&),+,HO108+9W0'*+.RU/2;*+.8JYn&(835U57-&9<2RU/2RUC+ERU'*<2/:3'*),+,<MW0'*&(8JY[&(835U5'*+.6Q3/2RUC+¢&('*+,<Me
Z[\%]

g782105UXT10'*H0+,).RNH*3D05N+

Z[F]
Z\!]

^+ V RÍ~¡H0+,).RNH*3D05N+

Z[

_` ~¡),& V -05N+./+


Z8^]
Z8^

 ¯ ~¡),& V -05N+./+

x{RU69108+>bOqg_;*+@Î_ÏtY$3 V RU5UX V &H0+.5N<3'*HI),& V -05N+fRU/XF&Y{/2;*+>3(<:<&).Ro3/+,HFH0+,HO1*)./2RN&('£-08&(D05N+ V
aq

ñ£ô

EÍþÐ

 cb«"]ò$íMÍëkÎì]íjîEd

ðà!]í4ò

Ý

Ë

ß

B aUi(2B4ÒfN¦=$^0?Ô82105N+A+ V D+,H0<\K'*&ML5N+,HO6+y&YEY[&(8 V ¡RÍY9 /2;*+.'e :eÊg_;*+FY[&(5U5N&LRU'06
H0+fÑ*'0RU/2RN&('Ò3(<3),&(5N&(8+,HÒ^0?äRN<Z+,wQ10RUC935N+.'Q/Z/&£/2;*+ V &(8+s/28:3(HORU/2RN&('435H0+fÑ*'0RU/2RN&('Ò&Y3I82105N+F3(<3'
&(DO2+,)./Z),& V -&9<+,HÆ&Yu/¡L&j^0?@<Z8+.5o3/+,H¦LRU/2;¦),&(8+fYn+.8+.'*),+F5URU'0KO<l1*<+,HkDQX¦?@&9<2;Ò3'*H¦r«1QL&('06<:+
=m`Mb9b9vAfW*&(8u^O35UC93/3'*HF£1069'0RN+.8¢=m`Mb9b9­Afe

;­

õ ´ú

 úûM]ü|è9ýM.þtûMÿ=uèwu«úûMÔÔM3
øù F

³ 	


y;}]¸}$k{%}

uA{Ô¸M}h

oTt(U(2J
 õ{1
² 5  JON L pT:(pN2tT;QX~
»yn <2R V -05N+i698:3-0;¦82105N+ 

 y;}]¸}gf   ¼
-&(/2;*+,<2RN<L=(a  J D L [¢),&('*).5U1*<2RN&('5
ÂE+,HO1*)./2RN&('¬H0+.-G+.'*H0<i&(' /2;*+F'*&(/2RN&('¬&Y>3¦BN£fa [[[(h£RU/\RN<i3S698:3-0;ß/28:3'*<mYn&(8 V 3/2RN&('
D43(<+,HF10-&('F-08&2+,)./2RN&('7e

å

¿ Z8}
õ ²Ä
= (a  ZifNW5  o3-0-05URÍ~
»yô .ÓÔ

 y ;}]¸}ih  `» Mó{Ô¸M} j{  ¼
)M3D05N+S$7¿  ©\OfI)j9o.iGmm¤M2,[n(­=u.T: ö=}©f2(  JON L NO\:BO9OfBpsm©  RI4$Z¿85gØB
9,S
= OZBBÍm©ZOs3-0-05URN)M3/2RN&('j&Y  &('×¿ñ3(),),&(8HORU'06I/&«ö§plOrõ}²ÿ¿ ê Q.$(G2SS:
\¤Ù sO¢(o¤.9p4]4[(«m©H¿ (aTm©>sB¢F
: m©  J L N Ol(a. Bn(tm©  R´q
= O.­=4©,(¢S?fS:
D
2M7$MÍA*yÌ>*3Î64>=jh
9 O.2kÎ i  JPN L (a Í i  J L @
= (S(Ò2MQ«!
9 «O.9\*fF.	
9 f
D
ö$	ÎW>
4 9asO>:B¢F
: m©dÍ5+¿ ê oE.9[i$Fl(«R VV +,HORo3/+  ~¡H0+.82RUC93/2RN&('T©B2(q¿o5

Ë°H0+.82RUC(3/2RN&('RN<3I=-&9<<2RUD05UXi+ V -0/X0AJ<+,w1*+.'*),+@&Y{82105N+>3-0-05URN)M3/2RN&('*<

ö


 y;}]¸}gk ,
 yn 3{Ô¸M}©ô .l lM.2©@BUf>=(ar¿Ôlõ{²151el(\~¡H0+.82RUC93/2RN&('
©fm( ¿ $«¿ ê TMyÏ.*fa:F2©Cõ{²[¿ q
" ¿ N * F6F6F *¿
"Ç¿ ê fO.«O9M=7©.9rIZ\VÌj\ K =Ä¿ p\(
G
l29[9¡  !mQff'?º[[(l©fm( ¿ S D =h
9 Of  pPfN>pm©5





g}&lH0+,HO1*),+E3Z^0?°É\WQL+ V 1*<2/_DG+u3D05N+/&lH0+.82RUC+@3l^0?®RU'Q/&lL;0RN):;IÉ°)M3'sD+J-08&2+,)./+,Heqg_;0RN<
'*&(/2RN&('IRN<J)M3-0/2108+,HDQXs/2;*+EYn&(5U5N&MLRU'06iH0+fÑ*'0RU/2RN&('7

K´µv´ ¶{· ¸$º

u

Ü × ×
 ô .Ç " $nÏ+*)«4yonbXÔ(atU.EÉ :£Jõ}²15É :(§:

 y ;}]¸} ¶ Î2iÝ
Q29O:©fm( Ç ¡N a9$9[n(tÉ P n$ Ï+*)«4cR ©\OfF)j(pfi(pg!mQff'?9[[9s©f2( ÏÅ$S õ}²
B0fI9!É P ë5

³ Û

ÓMMMó{»

y º
 §

Å

{%}¸Mó

g_;*+<+ V 3'/2RN),<¢¨âRN<@+f/+.'*H0+,HS/&s/28:3'*<25o3/+Z82105N+,<Mu69RUC+.'j3i82105N+  W5N+./  N 3'*H  D DG+l/2;*+l/¡L&
^0?E<8+,<-G+,)./2RUC+.5UXÆ),&(828+,<2-&('*HORU'06j/&SRU/<;QX-G&(/2;*+,<2RN<i3'*HÆRU/<\),&('*).5U1*<2RN&('7W_R$eô+9e  N "  JON L 3'*H
 D RN<i/2;*+S^0? &(D0/:3RU'*+,HÒY[8& V  J D L DQX 3(H0HORU'06k/2;*+'*+.RU69;DG&(8<T&YP/2;*+£8+.5o3/2RN&('ß'*&H0+,<i&Y  J D L
L;0RN);§38+I),&('*),+.-0/s'*&H0+,<i&Y  JPN L e¬g_;*+.'¬[
¨ $  4Z" ù¢] D FtFtF ] ð$ +$  N 4
¯_ FtFtF _ Ä$  42A
D
D
N
N
L;*+.8+ Ä$  4_3'*H +$  D 4_38+E/2;*+@),&('(m10'*)./2RN&('*<&Y!3/& V <3(<<&).Ro3/+,HTLRU/2;  3'*H  D W ] D FtFtF ]
38+i/2;*+C9382Ro3D05N+,<Z&Y +$  N 4>3'*×
H _ D FtFtF _ \38+i/2;*+C9382Ro3D05N+,<Z&Y +$  D 4@/2;43/H0&'*&(/3-0-G+M38lRU'
Ä$  N 4feFx4&(8>RU'*<2/:3'*),+9Wh),&('*<2RNH0+.8l/2;*+\82105N+ 	 RU'x{RU6*e}vOeTg_;*+.'¦[
¨ $ 	 4E"Çù¢]`$ýJB,(m.OfA $M])4
¯_)$þ2m¤,,c $M_4 ßff´ $M]*y_4y4y4fe ^;*&(105NH§L+SRU'/+.82-08+.//2;*+«),&(5N&(8+,H§698:3-0;
RU'®x{RU6*eJÀ¦3(<
D
3s82105N+9W7RU/<@Y[&(8 V 105o3FL&(105NHtDG+j
¨ $ D 4b"ù¢]­ùü_$y$þJ.:,(¢ $M]4 JþJ.:,(¢ $M_4 ×9]( ÙMS !c9![¯ $M]*y_4y4
$ rq :´ $ §4 pü
 $M]* §4 ¢ $M_¢* ¯4y4y4f
e u&(/2RN),+9W10'05URUK+]RU'Z).5o31*<+,<MWC9382Ro3D05N+,<-08&(-+.8{/&J/2;*+),&('*).5U1*<2RN&('
38+P+fORN<2/+.'Q/2Ro35U5UXFw143'Q/2RÍÑ4+,He
g_;*+EYn&(5U5N&MLRU'06s<&(10'*HO'*+,<<3'*H),& V -05N+./+.'*+,<<J8+,<2105U/RN<J&(D0/:3RU'*+,H







Ô R

p

+

Ô G
³

=



Ô G

ö !r

C	 ` § 

¾Ä
T
$

<

Ô

UÄ


t Cuvu w ö 7t Cu|u


½hy|Mèy¯º
qhM}]y|
f + {» 3{Ô  kJô .!Ç
 {» 3{Ô

Zo}
õ ²15ÑUOfÉ P $nÏa*)74> §¨j$ÎÑ4*B¨j$nÏÓ4*B¨j$t74 I¨[$$ÉE465



<§

.


"Ð$nÏ+*)74\\snYX¾(aiÉ

u&(/2RN),+J/2;0RN<8+,<2105U/3(<<1 V +,<]/2;43/698:3-0;*<38+69RUC+.'RU'\'*&(8 V 35aY[&(8 V WO3'*HWRÍY'*+,+,H0+,HW-010/]RU'/&
/2;*+.RU8J'*&(8 V 35Yn&(8 V 3ºY[/+.8J+M3();£82105N+P3-0-05URN)M3/2RN&('7e

;­A
õ

	

3M¼¾½øuM%

»

³  ïëå

 `» ñ v`» §º
%&(105N&('*HO8+J3'*H^O35UC(3/=m`Mb9b9cA-08&MC+,HZ/2;43/{ÎÝK´µ*´Ü¶{·×¹¸ºsRN<h<+ V RÍ~¡H0+,).RNH*3D05N+_LRU/2;38+,HO1*)./2RN&('
Y[8& V /2;*+·Ûµ ×;Ú*»Q×¹¶|üC·×¹¸ºáÚ*Ív¸$ÿ{»9µ ý<¸$Ívu(w/lØeig_;*+\8+,HO1*)./2RN&('69RUC+.'tDX«Ó_36+./T=n9Õ9ÕO`A
=pY[8& V /2;*+(xü»R·×z
º y¬þ@Ív¸$ÿ{»9µ ¥¸$ýgü u>ÜÍ ×¹{º yi|ü¶ Û7×¹º*µ AJ-&(RU'Q/<u&(10//2;43/Î2 ÝK´µ*´ Ü¶{· ×¹¸º
RN<P3T),& V -010/:3/2RN&(' V &H0+.5$e>rt+Z69RUC+Z;*+.8+\3'*&(/2;*+.8@8+,HO1*)./2RN&('7W7Y8& V /2;*+~}¸$ÍD®
´ Ú*Í|¸ÿ{»9µ ×¹ºsü
ØAµ×NÝ·Û7ÜÆ
µ Ø.ÙhØ2·Dµ PW7/2;43/@L+ZLRU5U5!1*<+\3(<E/2;*+<2/:382/2RU'06I-&(RU'Q/@RU'«/2;*+Z-08&&Y&Y ¯ 8&(-7eq`MÕOeZg_;0RN<
8+,HO1*)./2RN&('IRN<35N<&lRU'Q/+.8+,</2RU'06\RU'FRU/<+.5ÍY}<2RU'*),+ERU/_-08&C+,</2;43/MW0+.C+.'FL;*+.'F82105N+,<J38+@&Y/2;*+uYn&(8 V ¡Ý RÍY
O9Kk] D F6F6F ] G >
 /2;*+.'TOUk_ D F6F6F _  G:ß W0Î2ÝK´µv´ Ü¶{· ×¸$tº 8+ V 3RU'*<<+ V RÍ~¡H0+,).RNH*3D05N+9e
y º
 ¯

~>hy§ó|Mh{

y



y

ö 7t Cu|u k Î2ÝK´µv´ Ü¶{· ×¸$Êº pE,fZM!Q2,[fU´5
þ2Mm©WøFx{RU8<2/>):;*+,)Kt/2;43/¢ÎiÝ´µ*´Ü¶|·×¹¸ºßRN<¢'*&(/>/282105UX«10'*H0+,).RNH*3D05N+S=5pW5F/2;*+.8+i+fORN<2/<l3'k35Í~
6&(82RU/2; V /2;43/P)M3'tH0+,).RNH0+ZRU'SÑ*'0RU/+Z/2R V +ZRÍY_/2;*+\3'*<2L+.8@/&T/2;*+Z-08&(D05N+ V RN<F¡Ý X+,<5ß AfuL;*+.'Éñ)M3'
p

½hy|Mèy¯º

}q

ãr

»}]èy

{ » 3{Ô
 

D+uH0+,HO1*),+,HFY8& V ÇW*3lD08+M3(HO/2;O~nÑ*8<2/<+M38);I&Yh/2;*+E/28+,+@&Yh35U57H0+.82RUC93/2RN&('*<_Y[8& V ÇÁ-08&MCRNH0+,</2;*+
3'*<2L+.8JRU'FÑ*'0RU/+@/2R V +9e
rt+¢/2;*+.'£-08&C+>/2;43/u'*&T35U6&(82RU/2; V RN<u+.'*<2108+,H£/&;435U/uL;*+.'£/2;*+l3'*<2L+.8E/&/2;*+>-08&(D05N+ V RN<
¡'*& :e|+./1*<'*&ML<2;*&ML°/2;43/Î2Ý Ü × kRN<'*&(/H0+,).RNH*3D05N+lDQXFD010RU5NHORU'06I3\8+,HO1*)./2RN&('£Y[8& V
/2;*+U}
¾Ú
 ×
Ø ×NÝ Û7Ü âØ.ÙhØ  =[g_;Q1*+9W@`MbO`.dAfeßg_;0RN<-08&(D05N+ V L_3(<\-08&C+.'
<+ V RÍ~¡H0+,).RNH*3D05N+>DQX ¯ &9</¢=m`MbdÀW08+,HO1*)./2RN&('/&Z;0RN<),&(828+,<2-&('*H0+.'*),+ ¯ 8&(D05N+ V Afe
g_;*+}
ÔÚ
 )M3'áDG+j+f-08+,<<:+,Hâ3(<MÒ5N+.g
/ Ú 3'*p
H Ú7êED+S/¡L&ßL&(8H0<W>3'*H "
m * F6F6F * nD+3@<+./]&Y82105N+,<MW+M3();i82105N+ D+.RU'06l3E-43RU8]&YL&(8H0Y
< $ ,* c4fRN<]/2;*+.8+3@H0+.82RUC93/2RN&('
D
G
Y[8& V Ú /Z
& Ú7ê Êg_;*+.8+ZRN<P3'«R VV +,HORo3/+\H0+.82RUC93/2RN&('«Y[8& V Ú /«
& Ú7ê=L+Z'*&(/r
+ Ú ÂÚ7êNARÍYmWGYn&(8
<& V ++ 9¢W Ú%"ÿÚ D 6Ú  3'*g
H Ú ê "pÚ D 6Ú  eJË QffM ?º9[n(«Y[8& V Ú /& Ú ê =L+l'*&(/C
+ ÚY Ú ê A
ê
RN<3Z<+,w1*+.'*),j
+ Ú "Ú N ÷Ú D
Ú
O
"
Ú
e
F6F6F

Ý 4ß

B

K´µv´ ¶{· ¸$º
¸$ÍD´ *Í|¸ÿ{»9µ º ü Aµ ]· µ 2·Dµ
¸$ÍD´ *Ív¸$ÿ{»9µ


&Þ
M×
{×
C×
   	
%Ð 
Ð 
s

s

s

s

E

u

` ]*

s
s

ÏÑ$MÚ¾4

Ò
Ó

¢

s

s

s

s

 $)4

Ò#
ÓA

s

u

s

¸$ÍD´ ÚvÍv¸$ÿ|»
µâRU'Q/&ÎiÝ´µ*´Ü¶|·×¹¸º
g_;0RN<_-08&(D05N+ V )M3'F+M3(<2RU5UXD+u+f-08+,<<:+,HiRU's/2;*+uÎ V &H0+.5$ez'*+E),&('*),+.-0/_/¡X-G+Æ9
 RN<J3(<<2RU69'*+,H
/&+M3():;Z5N+./2/+.8]  e}g_;*+.8+38+/2;08+,+&(/2;*+.8{),&('*),+.-0/h/¡X-G+,<M{=pYn&(8D¡Ý D+.69RU'ß AfWZ=pY[&(8Ý +.'*HCß A3'*Hâ
 =pYn&(8
Ý3'QX/2;0RU'06MßAfe£ßRN<!/2;*+J698+M3/+,<2/q),&('*),+.-0/]/X-+J3'*H35U5*&(/2;*+.8q/X-+,<]38+_-43RU82LRN<+'*&('O~¡),& V -438:3D05N+9e
g_;*+.8+RN<P&('*+\8+.5o3/2RN&('t/¡X-G+Z®«=pY[&(8Ý¡;43(<¢<21*),),+,<<&(85ß AfeË¾L&(8HBÚ " ] D F6F6F ] G RN<>3(<<&).Ro3/+,HS/2;*+
698:3-0;tÏÑ$MÚ¾4fW73'*H£/&F3'XI82105N+B"Ð$M_ D F6F6F _2	 *FÔ D F6F6F ÔAW 4RN<@3(<<:&).Ro3/+,Hy/2;*+¢698:3-0;y82105N+  $.4fW73(<
8+.-08+,<+.'/+,HRU'yx}RU6*e`MÕOeÓXI3<2/28:3RU69;/mY[&(82L_38Hy-08&&Y=n3Z8+,).10828+.'*),+l&('/2;*+P< V 35U5N+,<2/H0+.82RUC93/2RN&('
5N+.'069/2;aAfW9L+&(D0/:3RU'l/2;43/h/&E+.C+.82X>-43/2;lY[8& /2;*+'*&H0+/¡X-G+,H~â/&/2;*+'*&H0+/X-+,H~ª=&¡Ý D+.69RU'
ß /&
Ý+.'*HCß A_RU'y3l698:3-0;B\~¡H0+.82RUC+,HIY8& V ÏÄ$MÚ¾4fWaV ),&(828+,<2-&('*H0<3ZL&(8H=n3'*HF'*&(/3\<210DQL&(8H4AJH0+.82RUC93D05N+
Y[8& V ÚtW43'*HT8+,).RU-08&)M35U5UXe Ð /_Yn&(5U5N&MLJ</2;43/ÀÚÂÚ ê* ÏÑ$MÚ ê 4 P $nÏÑ$MÚ¾4*  $4y4fe
¡
x{RU69108+\`MÕOqg8:3'*<mY[&(8 V 3/2RN&('Y8& V /2;*+9}

;®

õõ

 úûM]ü|è9ýM.þtûMÿ=uèwu«úûMÔÔM3
øù F

ñ£ô

h

EÍþÐ



ói 

Í¸ÎÏÐ#

 ÎÍëkÎìqíîuï2ðà!qí4ò

| +./J1*<'*&MLáRU'Q/28&HO1*),+i(*f[2(pafW0L;0RN):;S38+@1*<:+,HF/&C935URNH*3/+@K'*&L5N+,HO6+9e_ËâK'*&ML5N+,HO6+¢D43(<+
7
LRU5U57D+uC(35URNH*3/+,HFRÍYhRU/J<:3/2RN<mÑ4+,<+.C+.82Xs),&('*<2/28:3RU'/MWa3'*HT'*&\H0+,HO1*)./2RN&('LRU5U57DG+@35U5N&L+,H£10'05N+,<<_/2;*+
¿@ÓÒ;43(<_D+,+.'sC(35URNH*3/+,H!RU's-08+,<+.'*),+@&Y}),&('*</28:3RU'Q/<MW0H0+,HO1*)./2RN&('FRN<_H0+fÑ*'*+,HT&('05UXi&('F3T(0fo.¡f4
K'*&ML5N+,HO6+PD43(<:+9e

}	


 º K
y 6º×º §
y ]{ÔAy ñ
 ¢

y;}]¸}$k{%}

q

è¢Óy|è¸y|

Ä

+ N$B$)
 5'*+.6Q3/2RUC+SR«),&('*<2/28:3RU'/
oF:(Í922õ{²15
ð
  M}h	Aè{% }AB -&9<2RU/2RUCO
JON L o(UO\/282RU696+.8im©ZO:(0f[2(4M = J D L o(U2[&(D05URU6Q3/2RN&('N$B$)5RU'/+.8HORN)./2RN&(' RT5
õ ²ð¿#öG~$CRN&(5o3/+,<¢EOf[M?8N$B$)5G$9[M?Ri(*f[2(pa à ©ÑöÆoPuGmm¤M2,[n(«m©EOP[fUMQf
 }
m© Åpa$>OB2(a94Q©,(f¾ma
© ¿ N$B$.
 54$b
 ¿HRP9h(*a{@)j¡faQ2«N¡2f$)5O9}9I:
)j9¡.aQ2S Rl$¢a2m¤,,[[9F2© ¾(JE
 9h(NW 5Ä¿§CRN&(5o3/+,<  ©[ ö`!c?Mn(U9¡B  ©,(_.(ha2m¤,,[[9
öa5 OfS 9!oM =`¿¾<:3/2RN<mÑ4+,< 85

 y ;}]¸}

Ä

£Ä

£Ä


Ä

£Ä

=Ä

t

r

t

t) ¢¡) ¢£¤%¥

r

Ä

ÃÄ

t
t



r



x{RU69108+\`9`9]ã+,HO10'*H*3'*).XF3'*HI),&('*<2/28:3RU'Q/CRN&(5o3/2RN&('
r +T;43MC+F/&S-G&(RU'/&(10//2;*+FR V -&(82/:3'*),+I&Y/2;*+IRU828+,HO10'*H*3'*).X¦),&('*HORU/2RN&('Ê&('Æ/2;*+T698:3-0;Ò/&
t
D+IC935URNH*3/+,HÒDQX -G&9<2RU/2RUC+£),&('*<2/28:3RU'Q/<y<;*&(105NH L+FYn&(826+./i/2;0RN<i),&('*HORU/2RN&('7WJ/2;*+.8+ V 3MXÒD+F/¡L&
+,w10RUC(35N+.'/^0?E<W}<21*):;j/2;43/l&('*+<:3/2RN<mÑ4+,<Z3F-&9<2RU/2RUC+\),&('*</28:3RU'Q/\3'*Ht/2;*+i&(/2;*+.8¢H0&+,<>'*&(/MeFx{RU6*e
`9`Z<2;*&MLJ<¢3'S+f*3 V -05N+&Y<1*);«698:3-0;*<M
e ¿ <:3/2RN<mÑ4+,< \WD010/u/2;*++,w10RUC935N+.'Q/=8+,HO10'*H*3'Q/BA@698:3-0;
kW}&(D0/:3RU'*+,HDQX V 3KRU'06/2;*+HORN<nm&(RU'/>10'0RN&('&H
Y ¿ 3'*Ht/2;*+/282RU696+.8¢&Y W}H0&+,<>'*&(/Mesg}&y3MC&(RNH
HORÍÌ+.8+.'Q/}),&('*<RN<2/+.'*).XC935U1*+,<Yn&(87+,w10RUC(35N+.'/7698:3-0;*<MWºL+!;43MC+]);*&9<:+.'P/&H0+fÑ*'*+q-&9<2RU/2RUC+!),&('*<2/28:3RU'/
<:3/2RN<mY$3()./2RN&('LPe 8Me /Meh/2;*+RU828+,HO10'*H*3'Q/Yn&(8 V &Y}3l^0?ZeQg_;0RN<-08&(D05N+ V H0&+,<]'*&(/&),).108]LRU/2;s'*+.6Q3/2RUC+
),&('*<2/28:3RU'/<Me Ð '*H0+,+,HW5N+.E
/ ¿ D 3'*×
H ¿  D+l/¡L&+,wQ10RUC935N+.'Q/@698:3-0;*<>3'*H«<10-0-G&9<o
+ ¿ D öG~$CRN&(5o3/+,<>3
'*+.6Q3/2RUC+\),&('*<2/28:3RU'/ <2RU'*),+Z/2;*+.8+\+fORN<2/<P3i-08&m+,)./2RN&('«Y[8& V ¿ D RU'Q/
& ¿  W7<:3M¾
X ö D.
W ö D Hö¦RN<P3
-08&2+,)./2RN&('FY8& V °/& ¿  WO/2;1*Y
< ¿  35N<&ZCRN&(5o3/+,< \e
gL&T),&('*<2/28:3RU'Q/< D 3'*H  38+l<:3RNH/&iD+Ty Ï,M ?º(Nf4RÍY3'QX£698:3-0;£/2;43/ECRN&(5o3/+,< D 35N<&
CRN&(5o3/+,<  3'*HT),&('C+.8<+.5UXe]Ë'QXi'*+.6Q3/2RUC+P),&('*<2/28:3RU'Q/RN<+,w10RUC935N+.'Q/J/&l/2;*+E'*+.6Q3/2RUC+@),&('*<2/28:3RU'/
&(D0/:3RU'*+,HßDQXÒ),&(5N&(82RU'06k35U5RU/<'*&H0+,<\DX®`9e¬x01082/2;*+.8 V &(8+9WJ'*+.6Q3/2RUC+y),&('*<2/28:3RU'Q/<T38+IRU'*H0+,+,H¬3
-4382/2RN).105o38)M3(<:+&Y-&9<2RU/2RUC+&('*+,<M{),&('*<2RNH0+.8q/2;*+J-G&9<2RU/2RUC+),&('*<2/28:3RU'Q/ ê &(D0/:3RU'*+,HY[8& V 3E'*+.6Q3/2RUC+
),&('*<2/28:3RU'/ âDX),&(5N&(82RU'06\35U5G'*&H0+,<&Y âDQXiÕOW/2;*+.'T3(H0HORU'06\3¢),&('*),+.-0/_'*&H0+u),&(5N&(8+,HsDQX`9WLRU/2;
/¡X-+¦8 § ³­¬± ¬*W9L;*+.8+,¦¨ "§§ ³ ¬T± ¬ERN<qRU'*),& V -438:3D05N+JLRU/2;i35U5*&(/2;*+.8q/X-+,<]3'*H\H0&+,<h'*&(/3-0-+M38qRU'
3'QXT698:3-0;y&Y{/2;*+¢¿@ÓuW4+fO),+.-0/JRU'£),&('*<2/28:3RU'Q/<Meg_;*+.'y3\<2R V -05N+@698:3-0©
; ¿CRN&(5o3/+,</2;*+P),&('*<2/28:3RU'/
ªRÍY3'*H£&('05UXRÍYqRU/CRN&(5o3/+,< ê e ¯ &9<2RU/2RUC+),&('*<2/28:3RU'Q/<E<2/282RN)./25UXRU'*).5U1*H0+¢'*+.6Q3/2RUC+Z),&('*<2/28:3RU'/<MWRU'
/2;*+J<+.'*<:+/2;43/q/2;*+3(<<:&).Ro3/+,H\),&('*<RN<2/+.'*).XZ-08&(D05N+ V <38+'*&(/]RU'\/2;*+J<:3 V +J),& V -05N+fORU/¡X\).5o3(<:<=/2;*+
-08&&Y}Yn&(5U5N&MLJ<JY8& V g_;7e4cAfe

Ä

Ä

@Ä

ñ

¶ïª© 4UBB

Óyn¸

(Gf65

MÇ

©
Ä

Ä

ÀÄ

=Ä

MÇ

Ä

Ä
Ä

Ä

Ä

TÄ

.Ä

¿

_ ` Ü°! Hþ+=aOB[[M?E(0.[m9p4E(2P¢f[f[,Qffm9 ^sM9[n(£2©JGn['?


9Ì

õõ

»

3M¼¾½øuM%

^RU'*),+F'*+.6Q3/2RUC+£),&('*<2/28:3RU'Q/<T38+TRU'*H0+,+,Hß3y-4382/2RN).105o38s)M3(<+I&YE-G&9<RU/2RUC+F&('*+,<MWL+FLRU5U5J'*&LPW
10'05N+,<<RU'*HORN)M3/+,H &(/2;*+.82LRN<+9WH0+.'*&(/+FDX 3«<+./&YP),&('*<2/28:3RU'/< 3«<+./&YE-G&9<RU/2RUC+I),&('*<2/28:3RU'Q/<
<& V +@&Yh/2;*+ V )M3'ID+@+,wQ10RUC935N+.'Q//&Z'*+.6Q3/2RUC+>&('*+,<Me

Ý

5ß

7
±

q

X Çî"Ë$nÏ+*må.4ToI),&('*<2RN<2/+.'/I ©ZÏ

 y ;}]¸}   M}h¸	Ayn}ó F« 
 y§]ó¸M}  } Î_Ï7å © nY¾
.[oM
< Bi((*f[2(paim©@åa5  OfS9!p,=Epl,(njRU'*),&('*<RN<2/+.'Q/A5  õ}²É (ßH0+,HO1*),+,H
©fm(¾Çä ©JÇäpP(0fo.¡f4_(aZÉ :(jZQ2(0:2@©B2( Ïd5
 &(/+P/2;43/3s^0?ªÉÅ/2;43/CRN&(5o3/+,<3),&('*</28:3RU'Q/E&Y!Ç V 3,XI<2/2RU5U5DG+PH0+,HO1*),+,HIY8& V
u
'*&(/ V 3/2/+.8<RU'*),+¢ÉÁRN<J3¢0(f[n({8+.-08+,<+.'Q/:3/2RN&('y&Y{K'*&ML5N+,HO6+¢H0+,HO1*).RUD05N+@Y[8& V Çe

Çe Ð /H0&+,<



}Û

y§»{Ô¸M}h´½hM]

¾´½[ÓMMMó

ÂE+,HO1*)./2RN&('FRU'FÎÏå£RN<+,<:<+.'Q/2Ro35U5UXi'*&(' V &('*&(/&('0RN)9e]ËH0HORU'06RU'OYn&(8 V 3/2RN&('F/&ZÏk)M3'T/282RU696+.83¢'*+.L
),&('*<2/28:3RU'/MW3'*HÒ/2;1*<i)M3'Ê).8+M3/+£3«'*+.L CRN&(5o3/2RN&('7S<2RU'*),+I'*&(/2;0RU'06k)M3'ßDG+IH0+,HO1*),+,H Y[8& V 3'
RU'*),&('*<2RN<2/+.'/K'*&ML5N+,HO6+¢D43(<+9W0-08+.CRN&(1*<H0+,HO1*)./2RN&('*<E38+@'*&5N&('06+.8C(35URNHeg_;43/JRN<JL;XiYn&(8ÎÏå
3'*H V &(8+Z6+.'*+.8:35 V &H0+.5N<\='*+fO/@<+,)./2RN&('*<BAfWRU/ERN<uR V -G&9<:<2RUD05N+l/&s&(D0/:3RU'«8+,<105U/<@&YqY[&(8 V ºÉ )M3'
D+H0+,HO1*),+,HsY[8& V /2;*+uK'*&ML5N+,HO6+ED43(<+EÇ°RÍÌSj
¨ $[E
Ç 4 Ij
¨ $$E
É 4 E3(<RU/_L_3(<_/2;*+u)M3(<:+JYn&(8Î_Ï3'*HsÎ2£e
Ãu&ML+.C+.8MWQ/2;*+'*&(/2RN&('s&Y),&('*<RN<2/+.'*).Xl)M3'DG+_/28:3'*<25o3/+,HRU'Q/&Px{zu|qeQx*&(8]'*+.6Q3/2RUC+J),&('*<2/28:3RU'Q/<W
/2;*+),&(828+,<2-&('*H0+.'*),+RN<!R VV +,HORo3/+9W3'*HZ8+.5URN+,<q&('-08&m+,)./2RN&('i<&(10'*HO'*+,<<]3'*H),& V -05N+./+.'*+,<<]LPe 8Me /Me
/2;*+l<+ V 3'Q/2RN),<>¨ =/2;*+,&(8+ V `Afe Ð 'Q/210RU/2RUC+.5UXW}3s^0? ¿ªCRN&(5o3/+,<@3'*+.6Q3/2RUC+Z),&('*<2/28:3RU'Q/ ~SjRÍY3'*H
&('05UXRÍY}/2;*+RU'OYn&(8 V 3/2RN&('F8+.-08+,<+.'/+,HFDQX S RN<H0+,HO1*).RUD05N+uY[8& V /2;*+uRU'OY[&(8 V 3/2RN&('F8+.-08+,<+.'/+,HFDQX
¿Ze



Ý

aß

Ä

Ä

p

Ä

UÄ



 UÄ

õ ²V¿ M? n(U9¡Bi£GnQ9['?(F(0.[m9p4
"î$ ê *H­4 Å¨j$ÎÑ4*B¨j$¿E4 Ò¨j$ ê 4>=
½hy|Mèy¯º¬fV }
9hOf bê!pPOjõ}²®aQff;:
N(Gl¨j$ jêÕ4PoPO>U(n(©.(fZUs:,M.n9¡2T$iQobõ}²R5

Ä

dÄ

UÄ

FÝ

%&('*<2RN</+.'*).Xl8+.5o3/2RUC+J/&@-G&9<RU/2RUC+),&('*<2/28:3RU'Q/<)M3'\D++f-05o3RU'*+,HLRU/2;ix}zu|qW/28:3'*<5o3/2RU'06 ¡-08&~
2+,)./2RN&(' ]RU'Q/&@3'*&(/2RN&('Z&Y ¡5N&(69RN)M350<210D*</2RU/210/2RN&(' E=$%;*+.RU' £1069'0RN+.8MW*`Mb9b9A7DG+./L+,+.'/2;*+]Y[&(8 V 105o3(<
3(<<&).Ro3/+,H«/&F698:3-0;*<ert+\)M35U5_3'õ!¡B*Bf[[[[n(kY[8& V ¨j$¿[4uRU'/&y¨j$ J4@3F<10D*<2/2RU/210/2RN&('®­Ò&Y
/+.8 V <]&Y}j
¨ $¿E4{DQX/+.8 V <&Y7j
¨ $ J4!<1*);\/2;43/),&('*<2/:3'Q/<&Y[
¨ $¿[4q38+K+.-0/]RU'QC9382Ro3'Q/3'*HWYn&(8]3'QX
3/& V ß6$ D * FtFtF * G 4&Y]j
¨ $¿[4fW*/2;*+.8+@RNd
< ß ê \ß_<21*):;F/2;43À
/ ß ê $
­ $ D 4* FtFtF *¯
­ $ G 4y4RN<3'3/& V &Yqj
¨ $ J4fe
g_;*+EYn&(5U5N&MLRU'06i-08&(-G+.82/Xs;*&(5NH0<

ß

Ý

`

ñ

K

±³

ß



`

`







ÈÄ?. :a2m¤,,[[9ðö ©f2(Ë¿ $
QM<]GBy(õ!¡B*Bf[[[O[[(°­ß©B2(
Óyn¸
¨j$ J465  :fZs9
o@£a9B\(9©,(fC=qOl9?fB,Z( .9ÍW5





¨j$¿[4£$



þ2Mm©WøJ|+./ÀöD+@3>-08&2+,)./2RN&('TY[8& V ¿á/& ke!x*&(8J+M3();TC9382Ro3D05N+b]&Yh¨j$¿E4fWO5N+./ÑÎD+/2;*+u10'0RNw1*+
6+.'*+.82RN)),&('*),+.-0/i'*&H0+<21*);Ò/2;43/8]" ¨[$	Î64fW/2;*+.'g­$M])4«" ¨j$	ö$	ÎW4y4feÊã+,).RU-08&)M35U5UXW_-08&MCRNH0+,H
/2;43/
RN<RU'I'*&(8 V 357Yn&(8 V W*/2;*+l3-0-05URN)M3/2RN&('Y[8& V ),&('*),+.-0/u'*&H0+,<&Ya
¿ /&),&('*),+.-0/'*&H0+,<&Y kW
Î /&>/2;*+u'*&H0+bÎa
ê <21*);T/2;43/,­$$ ¨j$	ÎW4y4a®
" ¨[$	ÎêÛq
4 RN<3>-08&2+,)./2RN&('sY8& V á
¿ /& eÓu
 &(/+
V 3-0-0RU'06\+M3();7
/2;43/MW010'05N+,<<
RN<RU''*&(8 V 35Y[&(8 V WÎ ê RN<'*&(/J10'0RNw1*+.5UXFH0+fÑ*'*+,HFL;*+.'y¨j$	Î ê 
4 RN<3Z),&('*<2/:3'/Me



q

;



@

Ä 

UÄ

(

¡

 ¿Vö`!c?Mn(U9¡BE(0.[m(4  §OH
 õ!¡B*Bf[[[[n(±­T©fm9¨j$ JPN L 44$
u¢»	»{3
  (2B4o
¨j$¿[4¢B.M.n9¡2Z9![öß(4a9)j9¡fGQ2T$s(õ!$f0B.[[O[n(¢©f2( ¨j$ C4E4$l¨[$¿[465
õõö

UÄ

 úûM]ü|è9ýM.þtûMÿ=uèwu«úûMÔÔM3
øù F

Ë'*&(/2;*+.8]D082RNHO6+)M3'D+D010RU5U/]1*<2RU'06>82105N+,<Me Ð '*H0+,+,HWO3E698:3-0;«¿â<:3/2RN<mÑ4+,<3E-&9<2RU/2RUC+J),&('*<2/28:3RU'/

ÄÒRÍY03'*H¢&('05UX@RÍYmWº),&('*<2RNH0+.82RU'06Ä 3(<}3J82105N+9W35U5O3-0-05URN)M3/2RN&('*<{&Y|ÄÒ&('r¿¦-08&HO1*),+3J698:3-0;¢+,w10RUC(35N+.'/

/&8¿Zez8MW V &(8+P<2-+,).RÍÑ4)M35U5UXG

 }

Ä 

Ä

 Ñ=¢(*BnQffp
Óyn¸
 õ}² ¿ ö`!?M[9Í9¡fFTOB[[M?I90f[2(4
BG n9[n(tm© È( ¿ä:(2(pF$Eöta2M(0:B¢(2B4IG9yÏ,M?º(Nf4_$¿o5
ñ

Ä

Ä

Ä

ISfN=¢0

þ2Mm©Wø¢|7+./ ªD+¢3i),&('*<2/28:3RU'Q/P3'*HJ¿ªDG+Z3s^0?ª<21*):;y/2;43/[¿¾<:3/2RN<mÑ4+,< e Ð Yaö N RN<E3\-08&2+,)./2RN&('
Y[8& V
=[),&('*<2RNH0+.8+,H
JPN L RU'Q/&8¿WO5N+./1*<),&('*<RNH0+.8/2;*+698:3-0;¾¿bêG&(D0/:3RU'*+,HTDX/2;*+P3-0-05URN)M3/2RN&('&Y
'*&ML3(<3\82105N+A&('Jª
¿ 3(),),&(8HORU'06s/&8ö N e|+./1*<J'*&LáD010RU5NH£/2;*+@Yn&(5U5N&MLRU'06s-08&2+,)./2RN&('ö ê Y[8& V ¿ ê
RU'Q/&7Z
¿ Yn&(8+M3():;£'*&H0++²GW¢öê0t$ ² 4d
" ²TRÍY&²TDG+.5N&('06<u/&«Z
¿ &(/2;*+.82LRN<+9W²sRN<E3\),&(-X&Y3'*&H0+³Á&Y
XJ D L W3'*HZRÍY)T
ö RN<q&('*+J&Y/2;*+-08&2+,)./2RN&('*<!Y[8& V ¬RU'Q/&k¬
¿ /2;43/]+fO/+.'*H0<ö N W9L+J;43MC+Àö ê t$ ²­4a"Qöt$ ³jf4 e
g_;*+.'Bö ê RN<>3i-08&m+,)./2RN&('j&YÀ¿ ê RU'Q/&gZ
¿ W}3'*Ht<2RU'*),+o¿ /282RUCRo35U5UX£-08&2+,)./<@RU'Q/&¿ ê W/2;*+.XS38+Z/2;1*<

Ä

Ä

TÄ

Ä

+,w10RUC(35N+.'/Me
g_;0RN<@-08&C+,<@/2;*+C´ -4382/P&Y-08&(-+.82/¡X«vOelx*&(8@/2;*+Cµ -4382/MWL+Z1*<:+Z/2;*+lY[&(5U5N&LRU'06F-08&(-G+.82/XW
-08&MC+,HtDQXS%&(69RN<¢3'*H«?E10RU'435NH0&j=m`Mb9b9vAfe Ð 'S/2;*+.RU8@-08&(-G+.82/X¦=-08&(-7eZ­s&Y/2;*+.RU8@-43-+.8BA/2;*+\^0?E<
),&('*<2RNH0+.8+,H38+>),&('0'*+,)./+,HI698:3-0;*<MW0D010//2;*+E-08&&Yh;*&(5NH0<Yn&(8'*&('),&('0'*+,)./+,HI698:3-0;*<e

 q !r

t uvu{}
À

 ¿:H
 õ}²¦(apf6 $¿[4(2©][y Ï.' ?º9Ufa
Óyn¸ ¶f 
u
¼©] }${»M] 
ô ,­
 B2(a(aqf0n9mBaZN¡ ©1¿äoEa9]2(G(4_OfyB6$¿[4a"¦¿YRT5UOfSOf)j(pf>iYn&(5NHORU'06
©fm( ¿ $FB6$¿[4>=J5pW5s¢Gmm¤M2,[n( y©B2( ¿Ô4$TfL$¿[4>=fO.y9OZBf[fn,[[9km© ¬$
aMB¢m©@B6 $¿[4PoPO>nQf4[[	 :gN ©,(>S ?. :saMQ1
 ]Òm©@B6 $¿[4>= Ó$M])4Ó"]R5
ñ



$

Ä

^10-0-&9<+'*&Lq¿ öG~$CRN&(5o3/+,< e^RU'*),+),&('*<2/28:3RU'Q/¢CRN&(5o3/2RN&('tRN<>H0+fÑ*'*+,H«LRU/2;t8+,<2-+,)./@/&T/2;*+
RU828+,HO10'*H*3'Q/Yn&(8 V &Y!3698:3-0;7W*L+>)M3'),&('*<2RNH0+.8MW*LRU/2;*&(10/5N&9<<J&Yh6+.'*+.8:35URU/¡XWa/2;43/Y¿ÁRN<RU828+,HO10'O~
H*3'Q/Me_rt+¢H0+.'*&(/+PDX¾¿Yê/2;*+P698:3-0;S&(D0/:3RU'*+,HIDXF/2;*+¢3-0-05URN)M3/2RN&('S&Y
=n36Q3RU'7WG),&('*<2RNH0+.8+,H'*&L
3(<3P82105N+Aq&(7
' ¿â3(),),&(8HORU'06l/E
& ö!e{rt+-08&MC+/2;43/ A¿ ê +,w10RUC(35N+.'//r
& ¿ 5N+M3(H0<]/&l3P),&('Q/28:3(HORN)./2RN&('7e
Y ¿ ê RN<]+,w10RUC(35N+.'/]/r
& ¿ZW/2;*+.'i/2;*+.8++fORN<2/<3E-08&2+,)./2RN&('iY8& V ¿ ê RU'Q/
& ¿ZehË'*H\<RU'*),Y
+ ¿®RN<3'
Ð
RU828+,HO10'*H*3'Q/E<210D0698:3-0;&a
Y ¿ ê WO/2;*+.8+P+fORN<2/<3u©,(Í9p Y[8& V ¿ ê RU'Q/Z
& ¿ =-08&(-G+.82/XF­Afe%&('*<2RNH0+.8
'*&ML ö ê /2;*+I-08&2+,)./2RN&('ÒY[8& V
/& ¿ H0+fÑ*'*+,HÊ3(<Yn&(5U5N&MLJ<MIY[&(8i3'XÆ'*&H0 
+ ]Ê&Y JON L Ñ
W ö ê $M])4C0
Ó$	ö$M]4y4fW&(/2;*+.82LRN<:+Z5N+.Y
/ ] ê D+>/2;*+),&(-X£&a
Y ]jRUB
' ¿ ê WGL+Z;43,C
+ ö ê $M]4
0 Ó$M] ê 4fe¢^RU'*),+lY[&(8@35U`
5 ]tRU'
< ö!ehg_;0RN<),&('/28:3(HORN)./<_/2;*+;X-&(/2;*+,<2RN< A¿ÿöG~$CRN&(5o3/+,< :ehg_;1*<
JON L W Ó$	ö$M]4y4"Qö$M])4fW öê4+f/+.'*H0d
¿ ê RN<'*&(/+,w10RUC935N+.'Q/J/8
& ¿Ze

Ý



Ä

Ä  

ÃÄ
ß

§

¥
Ý

Ä



Ä

@Äß

¡

4Ä

 õ}
² ¿,9[p'<BJOf[M?E90f[2(4 r=}OfI(:(2B4\TEm kn!mQff'?9[[9
Óyn¸ eh Øp©[
m©H¿äp>3Ï.M?º(Nf4_$¿o5
ñ

4Ä

F

þ2MmW© øJ|+.À
/ ¿"p¿ N * FtFtF *H¿ G D+@3m rn,~¡H0+.82RUC(3/2RN&('I&Y`¿eqx08& V -08&(-G+.82/XsvOWO+M3();¾¿ mWüI[\ÌÄ\ K W
RN<J+,w10RUC(35N+.'/J/& ¿ S D WO/2;1*<JDQXs/28:3'*<2RU/2RUCRU/¡XW4RN<J+,wQ10RUC935N+.'Q//& ¿Ze
<2RU'06S<&(10'*HO'*+,<<3'*H¦),& V -05N+./+.'*+,<<&Y/2;*+iÎ H0+,HO1*)./2RN&('7W]3'*Hk-08&(-+.82/2RN+,<\v£3'*HÆÀW!&('*+
&(D0/:3RU'*<J/2;*+@Y[&(5U5N&LRU'06\8+.5o3/2RN&('LRU/2;x{zu|jH0+,HO1*)./2RN&('7e

p

¯



FÄ 

¡

 ÔOfy¯j(o.£×õ}²Ç¿Yê>B0fÒ9
½hy|Mèy¯º·p
h  õ{²q¿ ?Mn(Í¡B£IOB[[M?y(0.[m(4
¨j$Îd4*B¨j$¿[4*B¨j$ C4 I¨j$¿ ê 4P(aG9¨j$ÎÑ4*B¨[$¿[4 I¨[$¿ ê 4>=9h0f2u¨j$ C4uoEO@[2(0fÍ[[(Sm©
(*BnQf2I>BU´5

UÄ 



;­

õõ

UÄ

@Ä

»

3M¼¾½øuM%

g_;0RN<s/2;*+,&(8+ V )M3'ÊDG+£8+fY[&(8 V 105o3/+,H¬RU'ß/+.8 V <T&Yl3DHO1*)./2RUC+yRU'OY[+.8+.'*),+Æ=1*<2RU'06kRU'ÊYn3()./sRU'O~
HORU8+,)./s3DHO1*)./2RN&('7W<+,+9WYn&(8+f03 V -05N+9W_¿&('*&(5URU6+9WP`Mb9b9­Afe Ð '*H0+,+,HW69RUC+.'Ê3«D43()K698&(10'*H /2;*+,&(82X
¨ $d
Î 4*Bj
¨ $¿[43'*HÆ3'Æ&(D*<+.82C93/2RN&('º¹%" ]¨j$ E4fWa¿ÈCRN&(5o3/+,<
RÍÌß/2;*+.8+TRN<\3'Ò3DHO1*)./2RUC+
¸ " j
+fO-05o3'43/2RN&('IYn&(8E¹&Yh/2;*+uY[&(8 V »\WOL;*+.8+9»RN<3ZY[&(8 V 105o3ZDG+.5N&('069RU'06/&\x}zu|a$ Ä* 4fe

} ï q

¢º×]$A{Ô¸M}h{»

Ý

â UÄ

â
q üºB`» <² K


Ä

y $

U 

Þlß

g_;*+£-08&(D05N+ V H0&+,<i3j69RUC+.' 698:3-0;¬<:3/2RN<mY[XÒ3«69RUC+.'¬),&('*<2/28:3RU'Q/
RN<i),&~c ¯ ~¡),& V -05N+./+yRÍYP/2;0RN<
),&('*<2/28:3RU'/RN<¢'*+.6Q3/2RUC+t=[<RU'*),+iL+ V 1*<2/);*+,):K/2;*+T3D*<+.'*),+T&Y-08&2+,)./2RN&('aAfW!D010/ZD+,),& V +,< _ ` ~

),& V -05N+./+@Yn&(83l-&9<2RU/2RUC+P&('*+\= _ ` RN<),&~c ¯2¼ · Afe


p

q

K¶¸$º7Ø×Ø2·Dµ*º¶4Ùtp _

<² K

Î Ïå  Î_ÏåÝ
_
aN.¡> ©>9p90f[2(4¢(Pn9[M?R5
½hy|Mèy¯º¬k 

üºB`»y $ [ }

¿

` !m(aN.¡bNmfGp]! HþÄ!:(r!


þ2Mm©WøSrÊRU/2;*&(10/i):;43'06+£&Y>),& V -05N+fORU/¡XWJ&('*+£)M3'ß),&('*<2RNH0+.8s/2;43/\å®RN<i),& V -G&9<:+,H &Y>&('05UXÆ&('*+
-&9<2RU/2RUC+i),&('*</28:3RU'Q/MWq<:3MX eIx{RU8<2/¢8+,)M35U5/2;43/ZH0+,).RNHORU'06SL;*+./2;*+.8\3£^0? ¿ <B3/2RN<mÑ4+,< äRN<lH0&('*+
&('j/2;*+RU828+,HO10'*H*3'Q/lYn&(8 V &YHZ
¿ eTrt+<;435U5]),&('*<2RNH0+.8l/¡L&£L3MX<l&YJRU'Q/+.698:3/2RU'06y/2;0RN<>Yn3()./¢RU't/2;*+
),& V -05N+fORU/¡XF&Y{Î_ÏåÝ 7Ø×Ø
4Ù]e_z'*+@L3MXTRN</&\3(<<21 V +E/2;43/J/2;*+ERU828+,HO10'*H*3'/Yn&(8 V &Ya°
¿ RN<

Ä
K¶¸$º 2·Dµ*º¶

Ä

),& V -010/+,H«D+fY[&(8+Z/2;*+Z),&('*<2RN</+.'*).Xy):;*+,)Keg_;0RN<P)M3'«DG+3():;0RN+.C+,H«LRU/2;j3s'Q1 V DG+.8>&Y_)M35U5N<@/&I3
-08&2+,)./2RN&('S&(8:3().5N+¢5URU'*+M38ERU'£/2;*+l<2R M+l&YÄ¿È=[1069'0RN+.8MW!`Mb9b9vAfeuÓ10/MWG<RU'*),+>L+>;43MC+¢/2;*+.'S/&s<&(5UC+
3\Y10'*)./2RN&('y-08&(D05N+ V =[),& V -010/+¢/2;*+lRU828+,HO10'*H*3'/EY[&(8 V &Ä
Y ¿PAJRU'*<2/+M3(H£&Y_3H0+,).RN<2RN&('y-08&(D05N+ V =RN<
¿ªRU828+,HO10'*H*3'Q/ AfWL+l-08+fYn+.8E/&RU'/+.698:3/+ZRU828+,HO10'*H*3'*).XRU'Q/&T/2;*+l),&('*<2RN<2/+.'*).X£);*+,)K/2;*+.'7W4Yn&(8
3-08&m+,)./2RN&(©
' ö N Y8& V /2;*+>/282RU696+.8@&Y ªRU'Q/ 
& ¿ZWG/2;*+¢-08&m+,)./2RN&('£Y[8& V ª/7
& ¿ÅL+>5N&&(KFYn&(8H0&+,<
'*&(/'*+,),+,<:<:382RU5UXF+f/+.'*H0H
< ö N W*D010/+fO/+.'*H0<J/2;*+¢),& V -G&9<RU/2RN&('£&Y]3Z-08&2+,)./2RN&('IY[8& V ¿RU'/&&('*+P&Y
RU/<J<210D0698:3-0;*<l=-G&9<:<2RUD05UXs+,w1435/& ¿°RU/<:+.5ÍYfA_3'* 
H ö N e
x{RU8<2/MW>ÎÏåGÝ 7Ø×Ø
4Ù D+.5N&('06<y/& _` <2RU'*),+RU/y),&(828+,<-G&('*H0<£/& /2;*+5o3'0691436+G½ "

mW] Òdù¢_ ¯_   $M]*_ *_  4>nQW¢L;*+.8+ ]Å+.'*),&H0+,<«3'ÁRU'*<2/:3'*),¦
+ $¿k* E4£&Y\/2;*+k-08&(D05N+ V 3'*H
D
D
$M]*d_ D *d_  4 i  RÍ
Ì _ D +.'*),&H0+,<3l-08&2+,)./2RN&( 
' ö N Y8& V XJPN L RU'Q/Z
& ¿3'*«
H _  +.'*),&H0+,<3l-08&2+,)./2RN&('
ö¾£Y[8& V ¿§RU'Q/&>&('*+&YRU/<<210D0698:3-0;*<3'*Hs3E-08&2+,)./2RN&(' öTY[8& V ¬RU'/k
& ¿®<Me /M`
e ö JON L ü"Qö¾ )ö N e
u&(/+E/2;43/JRÍ
Y ¿RN<RU'FRU828+,HO10'*H*3'Q/Yn&(8 V WO/2;*+.g
' ö¾RN<3'£310/& V &(82-0;0RN< V e
u&MLPW@5N+./1*<),&('*<2RNH0+.8£/2;*+«-08&(D05N+ V ~¿ Æ69RUC+.'Á3¦DG&&(5N+M3'§Yn&(8 V 105o3ºWP3'*Hâ3Æ-4382/2RU/2RN&('

mÁÀ *9À  ni&YRU/<@C(382Ro3D05N+,<W7RN<@RU/@/2821*+/2;43/EYn&(8>3'QXS/28210/2;3(<:<2RU69' V +.'Q/@Yn&(8@/2;*+ZC9382Ro3D05N+,<PRU'ÂÀ
D
D
/2;*+.8+>+fORN<2/<u3Z/28210/2;y3(<<RU69' V +.'Q/JYn&(8J/2;*+>C(382Ro3D05N+,<RU'BÀ  <Me /Me@¾RN<J/2821*+ Sg_;0RN<-08&(D05N+ V RN< _ ` ~

),& V -05N+./+9W<RU'*),+ZRU/<@),& V -05N+ V +.'Q/:382X  RN<P<2;*&ML'«/&TD+ ¸` ~¡),& V -05N+./+DQXt^/&)K V +.X+.8i=m`MbÀ9À9Afe

4Ù]W*L+E1*<+P3l8+,<2/282RN)./2RN&('&Y{/2;0RN<
Ð 'T&(8H0+.8/&ZD010RU5NHI3l-G&(5UX'*& V Ro358+,HO1*)./2RN&('I/&ZÎÏåÝ 7Øº×pØ
-08&(D05N+ V /& K ~Ä
% ux*<MWOR$eô+9e!),&('(m10'*)./2RN&('*<&YhHORN<[10'*)./2RN&('*<JLRU/2;3/ V &9<2/ K 5URU/+.8:35N<-G+.8J).5o31*<:+9e!|7+./
1*<u)M35U5 ¥ ~ F1
 &E¿ /2;*+><2-+,).Ro35})M3(<+>L;*+.8+~¾RN<E3 ¥ ~Ä
% ux_W*RU'S&(/2;*+.8L&(8H0<@3'RU'*<2/:3'*),+l&Y ¥ ~^Ë!g@e

g_;*+.' ¥ ~ F1
 &E¿ RN<J35N<& _ ` ~¡),& V -05N+./+9e Ð '*H0+,+,HW0RU'F/2;*+@<:3 V +E-43-+.8¢=[g_;7eOd*eU`AfWa^/&)K V +.X+.8<2;*&LJ<


/2;43/  LRU/2;®È8+,<2/282RN)./+,H/&£3 ¥ ~¡HORN<n10'*)./2RUC+i'*&(8 V 35]Yn&(8 V = ¥ ~¡b
Â uxqAE8+ V 3RU'*< ¸` ~¡),& V -05N+./+9e

^RU'*),+l/2;*+>'*+.6Q3/2RN&('t&Y3 ¥ ~¡b
Â uxÒRN<E3 ¥ ~Ä
% ux_WaRU/Yn&(5U5N&MLJ<E/2;43/u/2;*+l),& V -05N+ V +.'/:382X£-08&(D05N+ V ~¿

LRU/2;Bª8+,<2/282RN)./+,HI/&\3 ¥ ~Ä
% uxkRN< _` ~¡),& V -05N+./+9e

|7+./]1*<!'*&MLß8+,HO1*),+ ¥ ~ F1
 & ¿ /&@ÎÏåÝ 7Øº×pØ
4Ù]eqg_;*+/28:3'*<2Y[&(8 V 3/2RN&('i1*<+,HZRN<!C+.82X<2R V RÍ~

5o38q/&@/2;*+&('*+_Y8& V ¥ ~^Ë!gÆ/&@ÎÏ}Ý Ü × k=-08&&Y7&Y/2;*+,&(8+ V AfWQRU5U5U1*<2/28:3/+,HRU'x{RU6*e{d*eh|7+./
ÁD+3'sRU'*<2/:3'*),+&Y ¥ ~^Ë!g@eO|7+.À
/ ¿$r
 43'*HFo
É $r
 4!D+/2;*+E^0?E<&(D0/:3RU'*+,HsDQX/2;*+/28:3'*<mYn&(8 V 3/2RN&('
H0+,<).82RUD+,HZRU'/2;*+_-08&&Y&YGg_;7eOehg_;*+),&('*<2/28:3RU'/ o$r
 4"$$o
É $r
 4*)ü
H $tÀ  4y4}RN<!&(D0/:3RU'*+,HDQX3(H0HORU'06
3u),&(5N&(8:3/2RN&('/&Po
É $k
 4fh35U5O8+.5o3/2RN&(''*&H0+,<h&(D0/:3RU'*+,HZY[8& V ).5o31*<+,<J='*&H0+,<h/X-+,H $A{3'*HZ35U5O'*&H0+,<

Þ



>~

6ù

ÃÄ

Ä

K¶¸$º 2·Dµ*º¶

Ä

Ä

K¶¸º A·Dµ*º¶

>~

>~

K¶¸º A·Dµ*º¶
K´µv´ ¶{· ¸$º
ÃÄ
õõõ

Ä

¤YÄ ¦ ©

AÞ

dÉ7

 úûM]ü|è9ýM.þtûMÿ=uèwu«úûMÔÔM3
øù F

a

b

val

val

val

at

af

bt

c

val

bf

val

val

val

ct

cf

dt

2
1

C1

C1

C1

C1

C1

C1

1

C1

C2

C2

C2

a

b

c

d

val

val

val

val

val

df

av

bv

cv

dv

...

3

2
3

d

C2

C2

C2

Ä
¿

C2

>~

1

2

2
3

C1

1

K¶¸º7Øº×pØA·Dµ*º¶4Ù

3

C2

x{RU69108+\`MO ç 0 3 V -05N+>&Y{/28:3'*<mYn&(8 V 3/2RN&('IY[8& V ¥ ~ F1&E¿ /&Î_Ï7åÝ


Æ @Æ
È

0È 
Ê
6ù
Ä

&(D0/:3RU'*+,HFY[8& V C9382Ro3D05N+,<JRU'ÃÀ  =[),&('*),+.-0/'*&H0+,<J/X-+,H T&(8 T3'*HF8+.5o3/2RN&('£'*&H0+,</¡X-G+,H ° QA
38+@),&(5N&(8+,HFDXy`\=R$eô+9e!D+.5N&('06\/&Z/2;*+@&(D05URU6Q3/2RN&('aAfe_z'*),+>36Q3RU'7W0;43,CRU'06).5o31*<+,<&Y}D&(10'*H0+,HI<2R M+
5N+M3(H0<P/&£3T-G&(5UX'*& V Ro35q/28:3'*<mYn&(8 V 3/2RN&('7eTg_;*+\<2R V -05N+698:3-0
; ¿ 3'*H«/2;*+\-G&9<2RU/2RUC+),&('*<2/28:3RU'Q/
-08+,<+.'/+,HRU'x{RU6*e7`Mi38+P&(D0/:3RU'*+,HY8& V /2;*+ ¥ ~^Ë!g§Yn&(8 V 105o¾
3 $
`ÎW4 J$
 Î
43'*H
/2;*+@-4382/2RU/2RN&('KÀ D "Vm * ´n*)À  "Vm´ÎA* nQe
ç 3():;t/28210/2;t3(<<2RU69' V +.'/>&Y]/2;*+ZC9382Ro3D05N+,<@&Y@ <Me /Me+àRN<E/2821*+Z'43/2108:35U5UX69RUC+,<>3i-08&2+,)./2RN&('
Y[8& V ÈRU'Q/
& ¿W3'*H¦8+,).RU-08&)M35U5UX®=n3(<RU'*HORN)M3/+,HÆRU'Æ/2;*+F-08&&Yu&Y@g_;7eqAfeÆx01082/2;*+.8 V &(8+9W3'QX
/28210/2;y3(<:<2RU69' V +.'Q/Y[&(8/2;*+>C(382Ro3D05N+,<&YTÀ D '43/2108:35U5UXT69RUC+,<u3Z-08&m+,)./2RN&('Y8& V XJON L RU'Q/Z
& ¿W43'*H
8+,).RU-08&)M35U5UXeqg_;Q1*<MW/2;*+uwQ1*+,</2RN&(' ¡RN<RU/]/2821*+u/2;43/Y[&(8_3'QXi/28210/2;T3(<<RU69' V +.'Q/Y[&(8/2;*+uC(382Ro3D05N+,<RU'
À D /2;*+.8+l+fORN<2/<u3\/28210/2;S3(<:<2RU69' V +.'Q/Y[&(8u/2;*+PC9382Ro3D05N+,<uRU'BÀ  <Me /MeX RN</2821*+ «RN<u+,wQ10RUC935N+.'Q/E/&
/2;*+@w1*+,<2/2RN&(' ¡RN<_RU//2821*+E/2;43/_Y[&(8J3'QXs-08&2+,)./2RN&( 
' ö N Y8& V
& ¿Á/2;*+.8+@+fRN<2/<3l-08&2+,)./2RN&('
JPN L RU'Q/8
Y[8& V ÁRU'Q/Z
& ¿+fO/+.'*HORU'08
6 ö N :e
u&(/+l/2;43/@/2;0RN<E8+,HO1*)./2RN&('«RN<E5N+,<<@<2/28:3RU69;Q/mYn&(82L38Ht/2;43'«/2;*+l&('*+ZL+l-08&(-G&9<+,HSRU'Ò=[Ó36+./>
£1069'0RN+.8MW49Õ9ÕO`AfW0D010/JRU/JLRU5U5D+E1*<+,H3(<3lD43(<2RN<_Yn&(8/2;*+@-08&&Y!&Y!g_;7e7`MOe

Aà Ká

Ä

q

Ý

!Ý

Ä

;

u¢»	»{3

àÑ0áÑ+â  Uâ(àÑ Ñ+âTä

ä

Ä

Þlß

AÞGß

Ä

¡

1Ä (OM[[(«Î_Ïå o _` ! (aN.¡W5


Åh b«"]ò¡íuÍ©Ð 

¥ós 

ÍèÎÏÐ#

 ÎÍëZîXÆ&ÇQîXdpÇîEdoÆ&

' -08+,<:+.'*),+&Y),&('*<2/28:3RU'Q/<W7/2;*+l/¡L&FKRU'*H0<E&Y82105N+,<MWRU'OY[+.8+.'*),+Z82105N+,<9
Ðy
H0+fÑ*'*+@/L&i35U/+.82'43/2RUC+ V &H0+.5N<e
f 	
 y ;}]¸}$k{%}

3'*HS+.C&(5U10/2RN&('t82105N+,<
D]W

uA{Ô¸M}h

' Î2DåhWÏ RN<<+,+.'«3(<u/2;*+>RU'0RU/2Ro35hL&(825NHW8&&(/E&Y3-G&(/+.'/2Ro35U5UXRU'OÑ*'0RU/+l/28+,+¢&Y-G&9<<RUD05N+>L&(825NH0<MW
Ð£
3'*HoDÒH0+,<).82RUD+,<E/2;*+Z-G&9<:<2RUD05N+Z+.C&(5U10/2RN&('*<@Y[8& V &('*+ZL&(825NHS/&F&(/2;*+.8<Melg_;*+H0+,HO1*)./2RN&('t-08&(D05N+ V
3(<2KO<_L;*+./2;*+.8/2;*+.8+@RN<¢EOI2©>(0fo.¡f4+
 9](BU!©fm( Ï®$s8
 9]9BU,9[ppS© :lÉe

K´µ*´ ¶{· ¸$º

}Ü × ×ô .
Ç "#$na
Ï *)Da*må.4¢P+nbXd=!9alU,}É >kõ}²154É (S:
 ¶ ÎDåÝ
Q 29O:@©fm(¾Çä ©POf¢o>(*D!mQff'?9[[9FÏB"ÿ¿ N * F6F6F *¿ G B0fI9M=4©,(Io\ÌÄ\ K =+$¿ ,*må4
pP:(0Bpf¡.4(GZÉÈ9t:¢2(0:2@©f2(q¿ G 5


 y ;}]¸}



Ð 'ÎåhWÏy-08&MCRNH0+,HLRU/2;± RN<]3Ñ*'0RU/+JH0+,<).82RU-0/2RN&('s&Y3E-&(/+.'Q/2Ro35U5UXRU'OÑ*'0RU/+JL&(825NHW/2;43/q;43(<
/&TD+),&('*<2RN<2/+.'Q/MeiË-0-05UXRU'06£3s82105N+/&IÏ¬)M3't).8+M3/+\RU'*),&('*<2RN<2/+.'*).XW}D010/¢3iY1082/2;*+.8l3-0-05URN)M3/2RN&('
&Y3F82105N+ V 3,Xt8+,<2/&(8+i),&('*<2RN<2/+.'*).XeF|7+./l1*<@Yn&(8 V 35UR M+i/2;0RN<P'*&(/2RN&('¦&YP:(0Bpf¡.aL :y2B.$(29[[94e

6ù

õõ$-

»

3M¼¾½øuM%

Ä

UÄ

^10-0-&9<+Z/2;*+.8+ZRN<P«
3 öG~$CRN&(5o3/2RN&('t&Y3s-G&9<RU/2RUC+l),&('*</28:3RU'Q/ ¾RU'jÏ/2;0RN<ECRN&(5o3/2RN&('O$ b*3ö4uRN<@<:3RNH
/ &TD+~g!¡B.$(mfUiRÍY/2;*+.8+\+fORN<2/P3'Â\~¡H0+.82RUC93/2RN&('«Y8& V ÏßRU'/&3I^0?
3'*Ht3s-08&m+,)./2RN&('×öê
Y[8& V
RU'Q/&FRU828´$ J4@<21*):;t/2;43/>/2;*+\-08&m+,)./2RN&(' ö ê YöÆ&Y/2;*+/282RU696+.8¢&Y ñRU'/&IRU828´$ J4@)M3'tD+
+fO/+.'*H0+,HI/&i3\-08&m+,)./2RN&('y&Y ª3(<E3ZL;*&(5N+9eg_;*+PCRN&(5o3/2RN&('£&Y3'*+.6Q3/2RUC+¢),&('*<2/28:3RU'/u)M3'£'*+.C+.8
D+Z8+,<2/&(8+,Hr
e &(/+Z/2;43/P/2;*+~~$8+,<2/&(8:3/2RN&('j)M3'j).8+M3/+Z'*+.LªCRN&(5o3/2RN&('*<MW7/2;43/ V 1*<2/@/2;*+ V <:+.5UC+,<
D+E-08&MC+.'B~$8+,<2/&(8:3D05N+9e



©

£Ä

K¶¸º 2·Dµ*º¶
Û
Ä ! UÄ

K´µv´ ¶{·×¸$º ×

Ø×Ø
4Ù {%} Î\åÝ Ü

 y ;}]¸}  ï  Î\åÝ
<2RN<2/+.'/ ©>
= ©.(I(:Jõ}²
 9l(®Cg!mQff'?©f2(
S? .:kö`!cM? n(U9[[9Sm©
 ×=+$ Y*3ö4@p,g!2B.$(2QfNW5 
(*Bpf¡f4_(aZÉÈ(jlQ29O:@©fm( n$ Ïa)* 7465

Integer: Zero

ë
@Ä

Integer

n XÐ
Y
Ç " $n+
Ï *)¾
 *m.
å 4pi),&('O~
Ï =©,(S?fS:k:(0f[2(4
a
i å=©.(
õ}²ßÉÈ9«lQ(OB2@©fm9ÅÇä ©Ç p

¨

successor

Ëá<R V -05N+@698:3-0;¿



Ä

Integer

Ëá),&(5N&(8+,Hy^0?

x{RU69108+\` ¥ %&('*<2RN<2/+.'*).XTRU'FÎDåhºÎå
% &('*<2RNH0+.8ZYn&(8ZRU'*<2/:3'*),+F3y¿@Ó¾),&('/:3RU'0RU'06t/2;*+I^0? ¿ÈRU'Æx}RU6*e_` ¥ Wq+fO-08+,<<2RU'06S/2;*+T+fORN<2/+.'*),+

&Y@/2;*+'1 V D+.8TÕOWJ3j),&('*<2/28:3RU'Q/F3'*Hß3t82105N+9W_DG&(/2;ß8+.-08+,<+.'Q/+,HÊDXÆ/2;*+),&(5N&(8+,H§^0? ¦e¬g_;*+
),&('*<2/28:3RU'/l3(<<+.82/<P/2;43/J©.9iS ?fS :£4¡nf `=O.2ZQ.uT94¡nQ. ê =B0:BB.(Tm© qe Ð Y
/2;*+u82105N+ERN<3'I+.C&(5U10/2RN&('F82105N+9W ¿áRN<<+,+.'I3(<J3'sRU'*),&('*<RN<2/+.'Q/RU'0RU/2Ro35L&(825NHt=/2;*+.8+ERN<_'*&l<1*),),+,<<&(8
&YÕFRU
' ¿PAP3'*Hj'*&(/2;0RU'06£LRU5U5DG+iH0+,HO1*),+,HtY[8& V /2;0RN<¢¿@Óue Ð Y/2;*+82105N+\RN<Z3'jRU'OYn+.8+.'*),+\82105N+9W{RU/<
3-0-05URN)M3/2RN&('yR VV +,HORo3/+.5UXF8+.-43RU8</2;*+P),&('*</28:3RU'Q/uCRN&(5o3/2RN&('7W4L;0RU5N+>).8+M3/2RU'06s3'*+.L®RU'Q/+.6+.8MWa/2;43/
;43(<'*&<21*),),+,<<:&(8MW4/2;1*<u3\'*+.LáCRN&(5o3/2RN&('7eJx{RU'435U5UXW+.C+.82XI),&('*<2/28:3RU'Q/ECRN&(5o3/2RN&('£),&(105NHy+.C+.'Q/21435U5UX
D+E8+.-43RU8+,HIDQXF3Z82105N+P3-0-05URN)M3/2RN&('7W3'*HT/2;*+P¿@Ó¬<2;*&(105NHFD+E-08&MC+.'y),&('*<2RN<2/+.'Q/Me
|7+./1*<]-&(RU'Q/&(10/]/2;43//2;*+JÎ2 V &H0+.54RN<&(D0/:3RU'*+,H\Y[8& V Î2\å&(8]Î2DåFL;*+.'åFRN<+ V -0/¡XW03'*H
ÎÏå«RN<J&(D0/:3RU'*+,HTY[8& V Î2\åÒ=8+,<2-7e0ÎD7å7AL;*+.'K =8+,<2-7e¨D{ARN<+ V -0/¡Xe
g_;*+ÎCD7å V &H0+.5G),& V D0RU'*+,<DG&(/2;sH0+.82RUC(3/2RN&('T<):;*+ V +,<&Y/2;*+JÎ2\å£3'*HÎDå V &H0+.5N<M`
e &LPW
ÏÁH0+,<).82RUD+,<3'ÆRU'0RU/2Ro35JL&(825NHWRU'OYn+.8+.'*),+I82105N+,<&Y ),& V -05N+./+I/2;*+FH0+,<).82RU-0/2RN&('Ê&Y@3'XL&(825NHW
),&('*<2/28:3RU'/<s&Yuåâ+.C935U143/+I/2;*+),&('*<RN<2/+.'*).XÆ&YP3«L&(825NHWJ+.C&(5U10/2RN&('Ê82105N+,<&YÈDâ/282X¦/& V 3K+£3
),&('*<2RN<2/+.'/L&(825NH£+.C&(5UC+>RU'Q/&i3\'*+.LPW4),&('*<2RN</+.'Q/&('*+9e_g_;*+PH0+,HO1*)./2RN&('y-08&(D05N+ V 3(<2K<JL;*+./2;*+.8EÏ
)M3'+.C&(5UC+@RU'/&3),&('*<2RN</+.'Q/JL&(825NH<:3/2RN<mY[XRU'06l/2;*+P6&35$e

.



.

K´µ*´ ¶{· ¹¸º

³



Ü × × õ}¶
² ¿Yê{p(R VV +,HORo3/+CD7~¡+.C&(5U10/2RN&('\©B2(àCõ}²¶¿
  ÎCD7åÝ
 ©Of@)j(pfu9(¾!Q.BM?º9[n(@©fm(¿¾pa$b¿ ê ê (aZ(IR VV +,HORo3/+
Da!QffM?º9[n(@©B2(¿ ê ê 4$
¿ ê 5  ÉCD~¡+.C&(5U10/2RN&('©B2( o
 õ{¦
² ¿È$F8
 õ}p
² ¿ ê o¢iMyÏ.*fa:im©Eõ}²Y¿ç"V¿ N * F6F6F *¿ G "V¿ ê
B0ft9M =}©.(9J
I \çÌC\ K =Y$¿ ,*)g
 *m
å 4o(*Bpf¡f4u(a¤ =}©.(o
 I7\çÌC\ K =Ñ¿ Pp(Z2(n9¡
Ca
D !mS ?º9 O[[9\©B2(Ð
 ¿ S D 5\²_' ?(ft~b
n X®ç
Ç " $na
Ï *)¾
 *R
D *m
å 4>=_8
 õ}²ÊÉÔ:(H0+,HO1*),+,HT©f2(¾ÇÈ ©
Of¢pP9ss
D !mS ?( O[n(IB
Ï "p¿ N * F6F6F *¿ G B0f9hÉ :(jZQ2(0:2@©B2( $¿ G *)7
 465

 y ;}]¸}



¬«





«

rÊ;*+.'KD" =8+,<2-7eFÐ" AfW0&('*+P&(D0/:3RU'*<J/2;*+@Î2\å V &H0+.5=8+,<2-7ehÎDåAfe
õõº÷

 úûM]ü|è9ýM.þtûMÿ=uèwu«úûMÔÔM3
øù F

øq

f Û

7

M}h¸	AyÉ}ó

 }

Î2\å

{%}

K´µv´ ¶{· ¸$º
K¶¸º A·Dµ*º¶

ÓMMMó

g&/28:3'*<25o3/+£ÎåGÝ Ü × °RU'Ê5N&(69RN),<MWJ3<2/:382/2RU'06-&(RU'Q/T),&(105NHßDG+/&j+fO/+.'*H /2;*+£5N&(69RN)M35
/28:3'*<25o3/2RN&(' &YEÎÏåÝ 7Øº×pØ
4á
Ù 69RUC+.' RU' g_;7e]À£/&j3y/28:3'*<25o3/2RN&(' &YEÎåGÝ 7Ø×Ø
4Ù]e
Ãu&ML+.C+.8MW4/2;*+EYn&(5U5N&MLRU'06/2;*+,&(8+ V -G(& RU'/<&(10/J/2;*+E5UR V RU/:3/2RN&('*<u&Y{/2;0RN<3-0-08&3();7e

p

K¶¸$º 2·Dµ*º¶

u

4 EnbXY5­pØ ©0f2u)j(pfjõ}²×¿YêB0fZ9a¨j$Îd4*B¨j$nÏÓ4*B¨j$t«4*
½hy|Mèy¯º
ô .*ÇV"n$ Ï+)* gm* å
¨j$på4
¨[$¿ ê 4t(a¦a@¨[$ÎÑ4*B¨j$nÏÓ4*B¨j$t74 ñ¨j$¿ ê 4>= 9hOf¨[$på.4£pyO«[m(*BU9[[9ám©£0
(*f[2(paZm©å§90BnQf2(¢fNB>
= Of£ÇÔo>a90Bpf¡fac5ÈÊP9S?(f>=JO\(?.:Mp]©,(
M
yOQffm9h(,W5





þ2MmW© øirt+iÑ*8<2/Z-08&MC+T/2;*+s-G&9<RU/2RUC+i-4382/&Y/2;0RN<Z/2;*+,&(8+ V e Ð YJ/2;*+.8+F+fORN<2/<Z<21*):;Æ3£698:3-0ð
; ¿ êW
/2;*+.'â=[g_;7ehdA>/2;*+.8+TRN<\3$tÐlSå.4¡~¡H0+.82RUC93/2RN&('á=[),&('*<2RNH0+.82RU'06j/2;*+F),&(5N&(8+,H¦698:3-0;*<\&Yå§3(<82105N+,<BA
Ï "ç¿ N * F6F6F *¿ G <21*);y/2;43j

/ ¿bê-08&2+,)./</«
& ¿ G eu^+,+¢/2;43j
/ ¿ G )M3'0'*&(/D+lH0+,HO1*),+,HIY[8& V $n+
Ï *)7
 4fW
&(/2;*+.82LRN<7
+ ¿ ê L&(105NHk35N<&DG+iH0+,HO1*).RUD05N+iY8& V $na
Ï *)7
 4fe|7+./l1*<l),&('*<2RNH0+.8>/2;*+Ñ*8<2r
/ ¿ Y8& V /2;0RN<
H0+.82RUC93/2RN&('Ê/2;43/sRN<s'*&(/sH0+,HO1*).RUD05N+yY[8& V $na
Ï *)7
 4feÁg_;*+.p
' ¿ >RN<s&(D0/:3RU'*+,H Y[8& V ¿ S D =n3j698:3-0;
\~¡H0+,HO1*).RUD05N+FY8& V Ï!A¢DQXÆ3-0-05UXRU'063£82105N+
' ö!eÒ^RU'*),g
+ ¿ S D RN<
i åßYn&(5U5N&MLRU'06k3-08&2+,)./2RN&(ð
H0+,HO1*).RUD05N+Y8& V $n+
Ï *)«
 4fW/2;*+.'Ê/2;*+.8++fORN<2/<T3«698:3-0; Ë~¡H0+.82RUC(3D05N+£Y[8& V Ï<1*);Ê/2;43«
/ ¿ S D
-08&2+,)./<@RU'Q/& ke¢|+./@1*<@)M35U
5 ö ê <21*):;j3i-08&m+,)./2RN&('7W{3'*H«),&('*<2RNH0+.8@/2;*+Z-08&m+,)./2RN&(B
' ö ê ê " ö ê Hö
&Y/2;*+l;X-&(/2;*+,<2RN< º/282RU696+.8>&Y/2;*+Z82105N+ ),&('*<2/28:3RU'Q/
RU'Q/& ke@rt+Z'*&ML;43MC+Z/&s-08&MC+Z/2;43/\`A
öê ê ~$CRN&(5o3/+,< W43'*HA/2;0RN<JCRN&(5o3/2RN&('IRN<'*&(/X\~$8+,<2/&(8:3D05N+9e^10-0-&9<+\`A&(8ARN<_Y$35N<+9e!g_;*+.'
/2;*+.8+L&(105NH+fORN<2/q3698:3-0; ê ~¡H0+.82RUC+,HlY8& V
<1*);/2;43Ó
/ ö ê ê )M3'ZDG++fO/+.'*H0+,HZ/&E3-08&2+,)./2RN&('
_ &Y 3(<J3>L;*&(5N+ERU's/2;*+uRU828+,HO10'*H*3'/Y[&(8 V &Y gê[e!g_;0RN<_RN<3D*<2108HW0<2RU'*),+ _ RN<3¢-08&m+,)./2RN&('I&Y
¿ hRU'3Z698:3-0;K~¡H0+.82RUC(3D05N+@Y8& V Ïe
g_;*+Z),&(10'Q/+.8+f*3 V -05N+\-08+,<:+.'Q/+,HSRU'«x{RU6*e{`.dTRN<E<21 ).RN+.'/@/&i-08&C+Z/2;*+Z'*+.6Q3/2RUC+Z-4382/@&Y]/2;*+
/2;*+,&(8+ V e



(ÄÃ

F

0ÄÃ


÷
ÄÃ

1

t

O
Ä  

A÷



T

2

s

t




©

t

t

r

F

ú

1

Ëâ82105N+ 



1

FÄ

r

Ëâ-&9<2RU/2RUC+@),&('*<2/28:3RU'/

Ëâ698:3-0;©¿

x{RU69108+\`.d*!Ëá),&(10'/+.8+f03 V -05N+¢/&g_;7e4b

Ä

Ð /RN<uR VV +,HORo3/+Z/&T);*+,):K£/2;43/@+.C+.82X£698:3-0;y/2;43/@)M3'SD+om  * rn,~¡H0+.82RUC+,HyY8& V ¿ )M3't35N<&
D+[m  n,~¡H0+.82RUC+,HsY[8& V ¿e!Ã&L+.C+.8MW0/2;*+-08&m+,)./2RN&('F&Y/2;*+/282RU696+.8J&Y áRU'Q/&l/2;*+10'0RNwQ1*+u'*&H0+&Y
¿H0+fÑ*'*+,<3ZCRN&(5o3/2RN&('£&Y /2;43/LRU5U57'*+.C+.8JD+E8+,<2/&(8+,He

Ä

$Ä

¡

r +@LRU5U5}<2/21*HOXTRU'I/2;*+@'*+fO/J<+,)./2RN&('k=[g_;7e7`9`AJ3Z-4382/2RN).105o38)M3(<+>&Y{82105N+,<L;*+.8+@/2;*+>),&('C+.8<+
t
&Y!g_;7e4blRN</2821*+9e

  	»   ´½ ãå )ó  
 § ó ñ |» ¯º
p ½ ¯º 8¶q ¢º×» <²  ÎDåhºÎå  ÎDåÝK´µ*´}Ü¶{·×¹¸$ºSp!,fZM!Q2,[fU´5+X9JÎåGÝ
¶¸ºØ×Ø2·Dµ*º¶4Ùá(GPÎ2\åÝ´µ*´Ü¶|·×¹¸º®(2¢[f;:aQ.[QQfNW5
f  ïYÌø}hy§ó|Mh{
hy|Mèy

^ 


 ô hy

AA |{ÔAy

y ] ¸M}

y $ [}

õõÖ

è

y



3M¼¾½øuM%

»

þ2MmW© ølÎD7åRU'*).5U1*H0+,<@Î2 /2;Q1*<@Î2Dåa~¡H0+,HO1*)./2RN&('«RN<E'*&(/@H0+,).RNH*3D05N+9e¢rß;*+.'jÉ RN<EH0+,HO1*).RUD05N+ZY[8& V
Ç W]3£D08+M3(HO/2;O~nÑ*8<2/\<+M38):;Ò&Y/2;*+s/28+,+F&Yu35U5H0+.82RUC(3/2RN&('*<lY[8& V ÇWq+M3();Æ698:3-0;ÆD+.RU'06«);*+,):K+,H

Yn&(8P),&('*<2RN<2/+.'*).XW{+.'*<2108+,<P/2;43/k¿ G RN<@Y[&(10'*H«RU'tÑ*'0RU/+/2R V +9ex*&(8>Î\å!W7L+<2;*&LÅ/2;43/>):;*+,)KRU'06
),&('*<2RN<2/+.'*).XsRN<_/282105UXs10'*H0+,).RNH*3D05N+9e]|7+./JÇÁD+@3¢¿@ÓÊL;*+.8+uå«),&('Q/:3RU'*<3l-&9<2RU/2RUC+E),&('*<2/28:3RU'/ 9Q
3'*Hi3P'*+.6Q3/2RUC+),&('*</28:3RU'Q/ S WQD&(/2;LRU/2;T3's+ V -0/X/282RU696+.8Meqx*&(8-08&MCRU'06l),&('*<2RN</+.'*).XW&('*+;43(<
/&i-08&MC+Z/2;43/ SÎP Í $n+
Ï *)«
 4fW3'*H£/2;*+35U6&(82RU/2; V H0&+,<u'*&(/E'*+,),+,<<:382RU5UX<2/&(-yRU'y/2;0RN<u)M3(<:+T=pY[8& V
<+ V RÍ~¡H0+,).RNH*3D0RU5URU/Xß&YPH0+,HO1*)./2RN&('ßRU' ÎTAfe¬g_;*+£<:3 V +I;*&(5NH0<Y[&(8/2;*+),& V -05N+ V +.'Q/:382Xß-08&(D05N+ V
=-08&MCRU'06RU'*),&('*<RN<2/+.'*).X0A_/:3KRU'06 Q RU'*</+M3(HI&Y S W*;*+.'*),+@/2;*+@10'*H0+,).RNH*3D0RU5URU/¡Xe

Ä

@Ä

.Ä

!Ä

6ù

Ä

¡

Ëu<s36+.'*+.8:35UR 3/2RN&('®&Y>Î2\å!WJH0+,HO1*)./2RN&('§RU'ÊÎCD7åâRN<s/282105UXÒ10'*H0+,).RNH*3D05N+9e#u+f/s<+,)./2RN&('
<2/21*HORN+,<_3@H0+,).RNH*3D05N+Y8:36 V +.'/&YÎsDåqWL;0RN):;iRU'\-4382/2RN).105o38_L_3(<<21 ).RN+.'/]Yn&(8q/2;*+PÖ*Ù{Ø×Ú*Û7Ü7Ø,Ý:Þ
V &H0+.5UR 3/2RN&('7e

6ù

2í

Ï ±Ð íMÑ0#¡ÓÐvË#¡ò¡#Î

Ð

ú



óiìsòò¡í ïq# 2í§ð ìÊí®Ñ
®Î

ó

kÐvÏÎ#Ñ0"òÐvÏ

PÍ

ÐzÍíuÍ

Ë 28 105N+F3-0-05URN)M3/2RN&(' V 3MX¦3(H0H¦8+,HO10'*H*3'/\RU'OYn&(8 V 3/2RN&('Æ/&t3698:3-0;7e Ð '6+.'*+.8:35$WH0+./+,)./2RU'06t8+f~
HO10'*H*3'*).XSRN<@HOR ).105U/i=8+,)M35U5]H0+./+.8 V RU'0RU'06£L;*+./2;*+.8¢3s698:3-0;«RN<@8+,HO10'*H*3'Q/¢RN<P3'B ¯ ~¡),& V -05N+./+
-08&(D05N+ V AfWD010/E/2;*+.8+38+Z<& V +l/282RUCRo35!)M3(<+,<MWGL;0RN):;«L+lLRU5U5h6+./u82RNHS&Y2W<2RU'*),+l/2;*+.X V 3,Xy).8+M3/+
382/2RÍÑ4).Ro35U5UXRU'OÑ*'0RU/+ZH0+.82RUC93/2RN&('*<MeEx{RU8<2/MWa&('*),+382105N+>;43(<uD+,+.'S3-0-05URN+,Hy/&T3\698:3-0;«3(),),&(8HORU'06F/&
3F69RUC+.'k-08&2+,)./2RN&('7W!RU/¢)M3'kDG+s3-0-05URN+,Hk36Q3RU'k/&£/2;*+8+,<2105U/2RU'06y698:3-0;7Wq3(),),&(8HORU'06y/&/2;*+s<:3 V +
-08&2+,)./2RN&('7Wq3'*Hj/2;0RN<lRU'*H0+fÑ*'0RU/+.5UXeyg_;*+,<+\Y[1082/2;*+.83-0-05URN)M3/2RN&('*<&(DQCRN&(1*<25UXt-08&HO1*),+8+,HO10'*H*3'/
RU'OYn&(8 V 3/2RN&('7eg_;*+.X38+l<:3RNHI/&DG+QMfNB:.eË'*&(/2;*+.8u)M3(<+¢&Yq/282RUCRo35{8+,HO10'*H*3'*).XRU'S3698:3-0;yRN<
/2;43/q&Y}	 9!8+.5o3/2RN&(''*&H0+,<MW(R$eô+9e{LRU/2;\+f03()./25UX¢/2;*+_<:3 V +_'*+.RU69;QD&(8<!RU'Z/2;*+<:3 V +_&(8H0+.8Meq%&('*<2RNH0+.8
Yn&(8@RU'*<2/:3'*),+\3s82105N+&YKRU'*H ¡RÍÄ
Y Í$M]*j_­4/2;*+.B
' Í$M]*b_4 :eZg_;0RN<@82105N+)M3'tD+Z3-0-05URN+,HtRU'*H0+fÑ*'0RU/+.5UXW
+.C+.'SRÍY]1*<+.5N+,<<E3-0-05URN)M3/2RN&('*<>38+Z3,C&(RNH0+,HWD010/P35U5!3-0-05URN)M3/2RN&('*<P).8+M3/+l/¡LRU'S8+.5o3/2RN&('S'*&H0+,<e Ð '
L;43/{Y[&(5U5N&LJ<MW(L+),&('*<RNH0+.8{/2;43/h/2;*+),&('*<2/2821*)./2RN&('\&Y4/2;*+698:3-0;Z8+,<2105U/2RU'06uY8& V 382105N+3-0-05URN)M3/2RN&('
-08+.C+.'Q/<J/2;*+6+.'*+.8:3/2RN&('I&Y/LRU'T8+.5o3/2RN&('F'*&H0+,<MW03'*Hi/2;43/J3>H0+.82RUC93/2RN&('IH0&+,<'*&(/_),& V -082RN<+@3'QX
1*<+.5N+,<<J82105N+>3-0-05URN)M3/2RN&('7e
?uRUC+.'j3T<:+./E&Y82105N+,<È 3'*Ht3'Â~¡H0+.82RUC(3/2RN&('«5N+M3(HORU'06I/&F3I^0? kW
RN<@<B3RNHS/&iD+F.U,2
RÍY'*&£82105N+,<&YX )M3'¦DG+T3-0-05URN+,Hk/&
RU'¦3'¦&(82RU69RU'435L3MXWqR$eô+9e«35U5J3-0-05URN)M3/2RN&('*<\&Yu3'Xt82105N+
&YX &('
38+i1*<+.5N+,<<e«£&(8+iYn&(8 V 35U5UXW
RN<Z).5N&9<+,HkLPe 8Me /MeÂ 3'*HkLPe 8Me /Mej3'\~¡H0+.82RUC93/2RN&('
N ö D FtFtF ö G G " kWL;*+.8+ !,= IE\Ì+\ K AhRN<q/2;*+J698:3-0;s&(D0/:3RU'*+,HDX/2;*+3-0-05URN)M3/2RN&('T&Y3E82105N+
&YÈ&('
' ö W0RÍYhYn&(8+.C+.82XT82105N+  &YF W0Yn&(8+.C+.82XF-08&2+,)./2RN&('
S D 3(),),&(8HORU'06i/&\/2;*+P-08&2+,)./2RN&(
öY8& V  JON L RU'Q/& kW/2;*+.8++fRN<2/<@3i-08&2+,)./2RN&(B
' ö qY[8& V  JON L /&
S D ,= I8\pÌY\ K AfW<1*);S/2;43/
ög"Qö e
?uRUC+.'I3¢<+./_&Y82105N+,<@ 3'*Hs3¢698:3-0g
; ¿ZWRÍY}3l).5N&9<+,Hi698:3-0;sRN<@~¡H0+.82RUC(3D05N+uY[8& V ¿W/2;*+.'TRU/RN<
10'0RNw1*+9eq£&(8+,&C+.8MWORÍY}/2;0RN<_698:3-0;FRN<H0+.82RUC93D05N+ELRU/2; £82105N+P3-0-05URN)M3/2RN&('*<W0/2;*+.' yRN<_/2;*+ V 3ºOR V 35
5N+.'069/2;&Y!3'U\~¡H0+.82RUC93/2RN&('7W43'*HI35U57H0+.82RUC(3/2RN&('*<&Y}5N+.'069/2; S5N+M3(HT/&ZRU/MehrÊ;*+.'FRU/J+fRN<2/<WL+@)M35U5
RU//2;*+.Ufl&
Y ¿LPe 8Me /Me£WOL;0RN):;L+@'*&(/C
+ ¿È[Ò e
|7+./h1*<h35N<&uH0+fÑ*'*+_3'*&(/2;*+.8h'*&(/2RN&('7W(8+.5o3/+,Hl/&/2;*+]Y$3()./{/2;43/}L+_38+RU'Q/+.8+,</+,H¢RU'lRU828+,HO10'*H*3'Q/
698:3-0;*<Me Ð '¢/2;0RN<{-+.8<2-G+,)./2RUC+9W(5N+./{1*<h<:3,X>/2;43/!3'ZRU828+,HO10'*H*3'/!698:3-0;
RN<a©fp*LPe 8Me /Meh3u<+./h&Y482105N+,<
äRÍY!+.C+.82XT698:3-0;I/2;43/)M3'FD+P&(D0/:3RU'*+,HFDXI3-0-05UXRU'06s&('*+@&Yh/2;*&9<:+E82105N+,<&('
RN<J+,w10RUC(35N+.'//&
ke}Ëu<<21 V RU'06@/2;43+
/ ¿ÊRN<q3'RU828+,HO10'*H*3'/]698:3-0;3'*HZ/2;43/q698:3-0;*<]&(D0/:3RU'*+,HDQXZ3u82105N+J3-0-05URN)M3/2RN&('
38+@-010/RU'/&\RU828+,HO10'*H*3'Q/Y[&(8 V W*RÍY!3¢Y[105U5698:3-0;£)M3'FD+@H0+.82RUC+,HFY[8& V ¿Á/2;*+.'IRU/RN<J10'0RNwQ1*+9e
Ð 'OY[&(8 V 35U5UXW/2;*+Z'*&(/2RN&('j&Y_3T).5N&9<:+,H«698:3-0;«/28:3'*<25o3/+,<P/2;*+lY$3()./@/2;43/@'*&(/2;0RU'06)M3'«D+\3(H0H0+,H
/2;43/u;43(<'*&(/uDG+,+.'S35U8+M3(HOX£3(H0H0+,HWGL;*+.8+M3(<u/2;*+P'*&(/2RN&('«&Y3ZY[105U5698:3-0;S<:3,XO</2;43/'*&(/2;0RU'06T)M3'

eú

ãÝ

v

O
d


@

aß

ã



¥ 

v

*



§d

§

+



õõAú

0

 úûM]ü|è9ýM.þtûMÿ=uèwu«úûMÔÔM3
øù F

D+\3(H0H0+,Ht/2;43/P8+M35U5UXt3(H0H0<@'*+.L¾RU'OY[&(8 V 3/2RN&('t/&I/2;*+698:3-0;7e\rÊ;*+.'t/2;*+\).5N&9<2108+&YJ3s698:3-0;¿
+fORN<2/<MWO/2;*+.'/2;*+PRU828+,HO10'*H*3'Q/Y[&(8 V &Y!/2;0RN<J).5N&9<108+PRN<J+f*3()./25UXT/2;*+EY105U5698:3-0;£H0+.82RUC93D05N+EY8& V ¿Ze
Ó10/'*&(/+¢/2;43/uL;*+.'£/2;*+>Y105U5}698:3-0;«+fRN<2/<W*/2;*+l).5N&9<2108+¢H0&+,<'*&(/'*+,),+,<<B382RU5UX+fRN</<l=[<+,+>-08&&Y
&Y ¯ 8&(-7e7`MÕAfe
h 	

ô }hAy

 ².



}

9²

]{%}$è}

yA

6ù

g_;*+'*&(/2RN&('s&Y3Y[105U5*698:3-0;\D+.RU'06 V &(8+6+.'*+.8:35a/2;43'\/2;*+'*&(/2RN&('i&Y73@).5N&9<2108+9WQL+J)M3'6+.'*+.8:35UR M+
/2;*+H0+fÑ*'0RU/2RN&('¦&YÑ*'0RU/++fO-43'*<2RN&('k<+./<P1*<+,HjRU'k3I-08+.CRN&(1*<¢-43-G+.8T=[Ó36+./l £1069'0RN+.8MW!9Õ9ÕO`AfW
3'*H3(H0&(-0/J/2;*+@Y[&(5U5N&LRU'06&('*+9

 y;}]¸}  ¶ ô}]Ayýy .h{%}h¸M}[AyATJ M.Jm©lBNBE o(U2£FÑ*'0RU/+Z+fO-43'*<2RN&('«<+./
 ©>G= ©.(S?fS:«õ}²p¿C=Of)j9o.Z(K¾!Q.BM?º9[n(¿ F6F6F ¿ ê B0f£9_fL$¿ ê 4¢p]©f9+5N65oc5E©5
e ¢fa9¡ZS:¿ [ Qp!©B4(mf4 5


Ð Y RN<P3iÑ*'0RU/+Z+fO-43'*<2RN&('t<+./\=pYmeô+9eô<fAfWH0+,HO1*)./2RN&('tRU'SÎ D+,),& V +,<PH0+,).RNH*3D05N+=D010/ERU/@RN<u'*&(/
3 G:B:,(S:t),&('*HORU/2RN&('jYn&(8>H0+,).RNH*3D0RU5URU/¡X*Afe Ð '*H0+,+,HWRU'k&(8H0+.8>/&IH0+./+.8 V RU'*+iL;*+./2;*+.83^0?äÉ RN<
S
H0+,HO1*).RUD05N+sY[8& V 3y¿@Ó $nÏ+*)«4fWqRU/<21 ),+,<Z/&S),& V -010/+IÏ [ W!/2;*+.'¦/&S);*+,):K/2;*+T+fORN<2/+.'*),+T&YE3
-08&2+,)./2RN&('FY8& V ÉÁ/&\Ï [ e^R V RU5o3825UXW*),&('*<2RN</+.'*).XT):;*+,)KO<JRU'IÎ2\åt38+PH0&('*+P&('Ï [ e

ú

¶k

<²

 ô }hAycy .]{%}$¸} Ay|AJô . PÇ " $nÏa*)¾*må.4k®nbX 9hOfB pS <q*[¡
)jB0(0Bn(y,,c5kU0fsÇ pP:(0Bpf¡.4q V$mºÏ [ n *må4@p>(0fo.¡f4M=(Gi8õ}²ßÉÈ9t:ZQ2(0:2
©fm( $nÏa*)7>
4  §ÉÔ(jlQ2(0:2P©B2( $mºÏ [ n¤64 5
Óyn¸

ñ





g_;0RN<-08&(-+.82/¡XI35U5N&LJ<J1*</&Z-08&C+@/2;43/J/2;*+P),&('C+.8<+P&Y!g_;7e*blRN</2821*+EL;*+.'KäRN<J8+,<2/282RN)./+,H
/&\3lÑ*'0RU/+P+fO-43'*<2RN&('<:+./Me

p

½hy|Mèy¯º ¢ ô ,Ç " $nÏ+*)g*må4IBnbXÑ=Y9hOf~ osk<]*¡F¯jBO(0f[9Æ,.c5ÿUOftÇ p
a(0fo.¡f4l Ofj)j(pf« õ}² ¿Yê¢B0fÊO9>¨j$ÎÑ4*B¨[$nÏ`4*B¨[$t«4*B¨j$på4 ñ¨j$¿YêÛ4S(Gka9
¨j$d
Î 4*Bj
¨ $nÓ
Ï 4*Bj
¨ $t«4 «¨[$¿ ê 4>=Ä9hO.2¢¨j$på.4>p¢OZ[2(0fÍ[[(j2©¢O:(0f[2(4Z2©Jå®(0f[Q.22
@fNB6 5



0

=

þ2Mm©Wøj$7´¶4;*&(5NH0<u3(<u3-4382/2RN).105o38E)M3(<+P&Y]g_;7e4bOe|7+./1*<J'*&Lá-08&C+P/2;*+ $7µð4_-4382/Me^RU'*),+>ÇªRN<
RU'*),&('*<2RN<2/+.'/MWQ/2;*+J-08+.CRN&(1*<]-08&(-G+.82/X3(<:<+.82/<!/2;43/H$ºm Ï [ nm* åh
4 RN<!RU'*),&('*<2RN</+.'Q/Me!g_;7eÀE+.'*<108+,<!/2;43/
Í ¨j$ J4fe
/2;*+.8+_+fRN</<{3698:3-0; ä<21*);l/2;43/`A}¨j$ Îd4B* ¨jn$ Ï [ 4B* ¨jp$ å4 I¨j$ J4fW93'*HA}¨j$ Îd4B* ¨jn$ Ï [ 4 I
^RU'*),+i¨j$ Îd4B* ¨jn$ ÏÓ4B* ¨jt$ «4 Æ¨jn$ Ï [ Z
4 =[g_;7e7dAfW7L+\&(D0/:3RU'k¨j$ Îd4B* ¨jn$ ÏÓ4B* ¨jt$ «4B* ¨[p$ å.4 ¦¨j$ ©4fe|7+./
1*<E'*&MLÅ<10-0-G&9<+¢/2;43/¢¨j$ Îd4B* ¨jn$ ÏÓ4B* ¨jt$ «4 j¨j$ J4fW73'*HS-08&MC+Z/2;43/ERU/ERN<P3D*<2108He Ð 'y/2;43/P)M3(<+9W
/2;*+.8+PL&(105NHID+>3Z698:3-0;J¿ ê \~¡H0+.82RUC93D05N+@Y[8& V ÏÆ<21*):;I/2;43/
-08&2+,)./<JRU'/&Z¿ ê =[g_;7e4di36Q3RU'aAfe
[
[
Ë'*HF<2RU'*),+
P ¿Yê P Ï WOL+P<;*&(105NHF;43,C+¢¨[$ ÎÑ4B* ¨jn$ Ï 4 I¨[$ ©4@=[g_;7e`Afh/2;0RN<JRN<3D*<2108He





 

.

 



( 

 

 

¢¡

 &(8+E6+.'*+.8:35U5UXW4&('*+@&(D0/:3RU'*</2;*+@Y[&(5U5N&LRU'06H0+,).RNH*3D0RU5URU/¡XF8+,<2105U/<W0H0+.-G+.'*HORU'06&('FL;*+./2;*+.8X£W
y
D]W0&(8lmDtRN<3¢Ñ*'0RU/+¢+f-43'*<RN&('I<+./Me
ñ

 u¶q

Óyn¸

<² ±

¢º×»y $

9².

¾´½ð;}hAyøy

h{%}h¸M}

»yøAy|A

e 0fÃ pZ@©W5W5Í=Q2(0,[n(Î2 p2.nQfN=E:(0Bpf¡.aL:(a£Q2(0,[n(¦pÎ\å
V s
92ZQ.[QQfN=_Q(OM[[(«Î2CDåßoE,.lM!2.nQfNW5

;

õõ

»

3M¼¾½øuM%

e 0f®D¾oI©W5W5Í=lQ29O,[n(¬tÎDåÅpT2.nQfN=ifOPf\(p*T[f;:taQ2,[fU£
V s
Î2CDåa5

V es0f*çlmDÊo>©W5pW5U>=]Q(OM[[(«Î2CDåßo>Q2,[fU´5
þ2Mm©Wø]^10-0-&9<+E

NR <_3EY2eô+9eô<MehÂE+,).RNH*3D0RU5URU/¡Xs&Y7-08&(D05N+ V <RU'iÎ 3'*HiÎ\åFYn&(5U5N&MLJ<Y[8& V -08&(-+.82/¡X
cOe Ð 'IÎ2CDå!W*L;*+.'£/2;*+¢3'*<2L+.8RN<(ÓfX+,<%Ó(W*RU/)M3'£DG+>&(D0/:3RU'*+,HIRU'IÑ*'0RU/+>/2R V +9*L+P-08&),+,+,H£3(<Yn&(8
ÎD7åÒ=[<:+,+E-08&&Y!&Y!/2;*+,&(8+ V `MÕAD010/),&('*<2RN</+.'*).XT):;*+,)KO<38+PH0&('*+¢&('F/2;*+EY[105U57698:3-0;IRU'*<2/+M3(HI&Y
/2;*+@698:3-0;IRU/<:+.5ÍYme
u&MLPW<210-0-G&9<:+ÃDÁRN<F3tYmeô+9eô<MeÅÏ \ +fORN<2/<MWJ/2;Q1*<T/2;*+yH0+.82RUC(3/2RN&('§/28+,+yRU'ÊÎDå°RN<Ñ*'0RU/+9Wu3'*H
),&('*<2RN<2/+.'*).X¬);*+,):K< V 3,X¬&('05UXÊ).10/I<:& V +S-4382/<F&Yl/2;0RN<T/28+,+9eàÂE+,HO1*)./2RN&('®RU'¬ÎsDåÁ8+ V 3RU'*<
10'*H0+,).RNH*3D05N+lDG+,)M31*<:+>L;*+.'p
D " OWa&('*+l&(D0/:3RU'*<u/2;*+>Î2\å V &H0+.5$WaRU'£L;0RN);«H0+,HO1*)./2RN&('SRN</282105UX
10'*H0+,).RNH*3D05N+9e
x{RU'435U5UXWRÍYRO
 l9DSRN<3EY2eô+9eô<MeUWÏ [Ô\ +fORN<2/<MW/2;Q1*</2;*+H0+.82RUC93/2RN&('T/28+,+JRN<]Ñ*'0RU/+9W3'*Hs),&('*<2RN<2/+.'*).X
);*+,):K< V 3,XF&('05UXT).10/J-4382/<&Yh/2;0RN</28+,+9e
u&(/+/2;43/_/2;*+E),&('*HORU/2RN&(' p
 l~DSRN<3PÑ*'0RU/+u+fO-43'*<2RN&('T<+./ RN<_<2/28&('06+.8_/2;43' ¡DG&(/2;mä3'*HmD
38+EÑ*'0RU/+P+fO-43'*<2RN&('<:+./< :e!g_;*+uY[&(5U5N&LRU'06-08&(-+.82/¡Xlm1*<2/2RÍÑ4+,</2;0RN<),&('*HORU/2RN&('7

«

ñ



5ß

Øp©S29É
G2BB:,(B;:TQ.[QQfNW5
Óyn¸



!Ý

5ß

¡

!Ý

K´µ*´}Ü¶{·×¸$ºñpFa9

(aBD (C<q*[¡y¯jBO(0f[9ßM.>=\O.kÎ2CDåÝ

¸$ÍD´ vÍv¸$ÿ|»
µ º±ü Aµ ]· µ A·Dµ

þ2MmW© ørt+@D010RU5NH3Z8+,HO1*)./2RN&('Y8& V }
 Ú
 ×  Ø ×NÝ Û7Ü tØ.Ù{Ø  =[g_;Q1*+9W}`MbO`.dA
/&lÎsDåGÝ Ü × hW*L;*+.8+E/2;*+u&(D0/:3RU'*+,HT82105N+E<+./<@ä3'*HmDj38+uDG&(/2;sÑ*'0RU/+E+fO-43'*<2RN&('F<+./<Me
g_;0RN<E8+,HO1*)./2RN&('S8+.5URN+,<@&('S/2;*+l&('*+lD010RU5U/uYn&(8-08&CRU'06F/2;*+l<+ V RÍ~¡H0+,).RNH*3D0RU5URU/¡X«&Y]Î2\~ Ü ×
=/2;*+,&(8+ V vAfe
|7+./Z1*<¢Ñ*8<2/Z-08+,<+.'//2;*+i/L&yKRU'*Hk&YÑ*'0RU/+s+fO-43'*<2RN&('Ò<+./<¢1*<+,HkRU'¦/2;0RN<l8+,HO1*)./2RN&('7eÉD¬RN<
3Ñ*'0RU/++f-43'*<RN&('S<:+./E<RU'*),+l&('05UX£8+.5o3/2RN&('«'*&H0+,<P38+l-08+,<+.'/@RU'S/2;*+),&('*).5U1*<2RN&('t&Y]82105N+,<MEDÆRN<
RU'*H0+,+,HF3P-4382/2RN).105o38J)M3(<:+&Y78:3'06+f~$8+,<2/282RN)./+,HI82105N+,<E=[<:+,+ ¯ 8&(-7e`9`AfeFàRN<_35N<&Z3PÑ*'0RU/+u+fO-43'*<2RN&('
<+./P<2RU'*),+9WYn&(8P+.C+.82Xy82105N+\RU'É£W/2;*+Z;QX-G&(/2;*+,<2RN<>RN<PHORN<),&('0'*+,)./+,HjY8& V /2;*+),&('*).5U1*<2RN&('Ê=L+\)M35U5
/2;*+,<+u82105N+,<@(p.(4G2,¡2*AfÄ
e u&(/+/2;0RN</2R V +u/2;43/MWO/2;*&(1069;* RN</282RUCRo35U5UXT3@Y2eô+9eô<MeUW/2;*+E).5N&9<2108+E&Y{3
698:3-0;ILPe 8Me /MeÈH0&+,<J'*&(/J'*+,),+,<<:382RU5UXF+fORN<2/Me
ã+,)M35U5@/2;*+Ã}
äÚ
 /:3K+,<3(<TRU'0-010/F/¡L&¦L&(8H0 
< Ú 3'*
H Ú7ê@3'*H¬3¦<:+./T&Yl82105N+,<
 " m D * F6F6F * G nQWh+M3();k82105N+/ D+.RU'06«3F-43RU8¢&YJL&(8H0Z
¦
< $ ,* c4fW!3'*H3(<2KO<PL;*+./2;*+.8Z/2;*+.8+\RN<Z3
H0+.82RUC93/2RN&('\Y[8& V Ú /j
& Ú7ê[ehg_;*+.8+JRN<]3'iR VV +,HORo3/+H0+.82RUC93/2RN&('\Y[8& V Ú /j
& Ú7ê7=L+'*&(/d
+ Ú
Ú7êNA
RÍY2WhY[&(8Z<& V +s Q`
W Ú " Ú D WÚ  3'*H Ú ê " Ú D 6Ú  etË Q.BM ?º9[n(ÒY[8& V Ú /
& Ú ê =L+s'*&(/+
ÚÂ
 Ú ê ARN<3Z<+,w1*+.'*),j
+ Ú "Ú N
Ú D
Ú
"Ú ê e
F6F6F
rt+;43MC+\<2;*&L't;*&MLÅ/2;0RN<P-08&(D05N+ V )M3'«D++f-08+,<<:+,H«RU'«/2;*+Î V &H0+.5$@/&I3FL&(8J
H Ú "
] F6F6F ] RN<3(<<&).Ro3/+,H/2;*+u698:3-0;IÑ
Ï
$MÚ¾4fW03'*Hi/&Z3'QXi82105N+E7

"$M_ F6F6F _ ¯*
W
!
4
N
R

<
(
3

<

<

&
).Ro3/+,H
D
D
D F6F6F
G
/2;*+698:3-0;82105N+  $.
 4fW{3(<>8+.-08+,<+.'Q/+,HRU'jx{RU6*eq`Mvt=L;*+.8+
RN<P698+M3/+.8¢/2;43'k35U5]&(/2;*+.8l),&('*),+.-0/
/¡X-+,<BAfe!g_;*+. 
' Úì
 Ú ê RÍÌtÄ
Ï $MÚ ê 4 P $nÑ
Ï $MÚ¾4*  $`
 4y4>=[<:+,+E-08&&Y!&Yhg_;7eavAfe
|7+./F1*<s'*&L <2-05URU/F+M3();§&(D0/:3RU'*+,H¬82105N+  $)
 4RU'/&Æ&('*+yHORN<:),&('0'*+,)./+,H¬RU'OY[+.8+.'*),+S82105N+p
 $.
 4
3'*H&('*+>8:3'06+f~$8+,<2/282RN)./+,HS+.C&(5U10/2RN&('£82105N+++
D $)
 4feJrt+>HORN<2/2RU'06910RN<2;£RU'/2;*+>;QX-G&(/2;*+,<2RN<u&Y+
D $)
 4/¡L&
<210D0698:3-0;*<MZ/2;*+y(fÍ(4W}L;0RN);Æ),&(828+,<2-&('*H0<>/&£/2;*+\;X-&(/2;*+,<2RN<l&Y  $)
 4fWq3'*Hj/2;*+yBf[a9[n(4W
L;0RN);®),&(828+,<-G&('*H0<F/&k/2;*+S),&('*).5U1*<2RN&('®&Y(
 $)
 4fe Ð /TRN<T+M3(<2Xß/&k):;*+,)KÊ/2;43/I&('*+y-4382/I&Y>/2;*+
3D&MC+«+,w10RUC(35N+.'*),+t</2RU5U5u;*&(5NH0<
 ÚÕ Ú ê µ
Ï $MÚ ê 4 P $nÑ
Ñ
Ï $MÚ¾4*)
 $
 4Hl®+
D $
 4y4feñÃu&ML+.C+.8MW
/2;*+«),&('QC+.8<:+tRN<F'*&¦5N&('06+.8IC935URNHÆ);*+,):K§DQX¬+fO+ V -05N+t/2;43/MWRÍY/ " mÐ
 " $ ¢*3ÎW4>nQW@L+«;43MC+

K´µ*´ ¶{· ¹¸º

¸$ÍD´ *Í|¸ÿ{»9µ


M×
|×



C×

` ]*

 	





2®

õ$-

>´µ*´ ¶{· ¹¸º



2	 Ô

Ô;

à

 úûM]ü|è9ýM.þtûMÿ=uèwu«úûMÔÔM3
øù F

ÏÑ$MÚ¾4

B

 $)4
u

s

Ð

s

Ò

s

Ó

s

Ð%

s

s

s

s

s

Ò
ÓA

s

Ò
Ó¯

E

u

s

u

Origin
s
s

s

Ò
Ó¯

¸ÍD´ßÚ*Ív¸$ÿ|»
µâRU'/&

s

s

s

s

s

s

s

s

Ò
ÓA
Ò
ÓA

$.4
D+$.4
u

s
s

Destination

x{RU69108+\`MvOqg8:3'*<mY[&(8 V 3/2RN&('*<Y[8& V /2;*+È}

àáà

V &H0+.5N<&Y{/2;*+EÎ_ÏYn3 V RU5UX

+àáà

Í ÎZ=n3-0-05UXm$)4&('*),+9WO/2;*+.'F/L&Z/2R V +,<,D+$.41*<2RU'06
Ï $	ÎW4 P $nÏÑ$ ­4*)$`4)l/DÄ$4y4/2;*&(1069;
Ñ
ì
HORÍÌ+.8+.'Q/'*&H0+,<gÝ°TÞ\D010//2;*+@<:3 V +@'*&H0+BÝy²AÞOAfe
rt+/2;Q1*<{'*+,+,H¢/2;*+]'*&(/2RN&('Z&Ya3M3-0-05URN)M3/2RN&('&Ya382105N+2D+$)4fRU/}RN<{<21*);l/2;43/{/2;*+]-08&2+,)./2RN&('
&Y]RU/<EH0+,<2/2RU'43/2RN&('«-4382/ERN<@3 V 3-0-0RU'06F/&F3i<210D0698:3-0;S/2;43/EL3(<@&(D0/:3RU'*+,HSDQXy3-0-05UXRU'06F/2;*+¢82105N+
$.
 4fW03'*H/2;43/L3(<'*+.C+.81*<+,H\/&¢-08&m+,).//2;*+uH0+,<2/2RU'43/2RN&('T-4382/&Y}3'X\82105N+&Y{Ä
D $
 4fWRU'*).5U1*HORU'06
D+$.
 4_RU/<+.5ÍY2e]y&(8+,&MC+.8MWa/2;*+P&(82RU69RU'y3'*H£H0+,<2/2RU'43/2RN&(' V 1*<2/D+E-08&2+,)./+,HIRU'Q/&iHORN<[2&(RU'Q/-43/2;*<l=R$eô+9e
3S'*&H0+I&YE/2;*+I&(82RU69RU'ß)M3'0'*&(/i;43,C+F/2;*+£<:3 V +FR V 36+F;43(<s3S'*&H0+F&Y@/2;*+IH0+,</2RU'43/2RN&('aAfe Ð YuL+
8+,<2/282RN)./&(108<+.5UC+,<_RU'F<& V +uL3MX/&l6&&HT3-0-05URN)M3/2RN&('*<J&Y}82105N+,<_&YT+
D $
 4fW/2;*+.'TL+@)M3'TC+.82RÍY[X\/2;43/
Ï $MÚ ê 4 P $nÑ
Ñ
Ï $MÚ¾4*  $
 4y4RÍÌ«Ñ
Ï $MÚ ê 4 P $nÑ
Ï $MÚ¾4*)©
 $
 4l*+
D $
 4y4fe
g_;0RN<8+,<2/282RN)./2RN&('RN<&(D0/:3RU'*+,HDXT1*<2RU'06i),&('*<2/28:3RU'/<MWa/2;43/LRU5U5{35U5N&Lá+.C+.82XF6&&H£3-0-05URN)M3/2RN&('
&Y>3«82105N+I&Y9Ä
D $
 4fW3'*HÒD+FCRN&(5o3/+,H DXk/2;*+£&(D0/:3RU'*+,H 698:3-0;Ê&(/2;*+.82LRN<+9e§|7+./i1*<\'*&(/+K ê $`
 4
3'*HÉD ê $`
 4E/2;*+'*+.L¾<+./<¢&YJRU'OY[+.8+.'*),+82105N+,<l3'*H+.C&(5U10/2RN&('k82105N+,<eFg_;*+\'*+.Lª/28:3'*<2Y[&(8 V 3/2RN&('kRN<
H0+,<).82RUD+,H RU'Êx{RU6*e`M­Oe Ð /i35U5N&LJ<T/&j&(D0/:3RU'Ê/2;*+IYn&(5U5N&MLRU'06¦8+,<2105U/M©
 ÚÖ Ú7ê 
Ï ê$MÚ7êÛ4 P

$nÏ ê $MÚ¾4*) ê $
 4*)D ê $`
 4*Lm Q * S n¤4fe!g_;*+J'43 V +,<_&Y78+.5o3/2RN&('s/¡X-G+,d
< "ZW i 3'*H
;43,C+uD+,+.'i):;*&9<+.'
/&Z69RUC+>3'IRU'/210RU/2RUC+PRNH0+M3Z&Yh/2;*+.RU8J8&(5N+@D010/J/2;*+.XF38+_m1*<2/_/¡X-G+,<3(<J&(/2;*+.8<MeqËá8+.5o3/2RN&('I'*&H08
+ $i 4
Y[8& V 3T'*&H0ð
+ Ý 6Þ/&I3F'*&H0ð
+ Ý; 	Þ V +M3'*<>/2;43/P/2;*+\5N+./2/+.8 ;43(<>DG+,+.'&(D0/:3RU'*+,HtDQXt3-0-05UXRU'06
/2;*+@82105N+ e!Ëá8+.5o3/2RN&('I'*&H08
+ $ ¶4]Y[8& V Ý G Þ/ð
& Ý Þ V +M3'*<J/2;43/J/2;*+E5N+./2/+.À
8 _ G D+.5N&('06</&Z/2;*+
<210DL&(8H&('L;0RN);\/2;*+82105N+, G;43(<!DG+,+.'s3-0-05URN+,Ha
e "ÊRN<h1*<+,H/&ERU'*HORN)M3/+/2;43/q/¡L&>),&('*),+.-0/q'*&H0+,<
;43,C+/&PD+-08&2+,)./+,H&('\/2;*+<:3 V +'*&H0+>=RU'T%?§/+.8 V <MWL+JL&(105NHs<+,+RU/3(<3@),&~$8+fYn+.8+.'*),+5URU'0K*Afe
g_;*+Z+.C&(5U10/2RN&('«82105N+~.
D ê0$ c4fW<2/:382/2RU'06sY8& V 3i-43/2;S8+.-08+,<+.'Q/2RU'06/2;*+l<10DQL&(8H 1*<+,Hy/&T3-0-05UX
 _3'*H£Y8& V /2;*+l8+.-08+,<+.'Q/:3/2RN&('j&Y ]6+.'*+.8:3/+,HSDXB ê $ c4fW-08&HO1*),+,<u/2;*+¢/L&T8+.5o3/2RN&('«'*&H0+,<
/¡X-+,HK×P<2R V 105o3/2RU'06/2;*+P3-0-05URN)M3/2RN&('&Y  $ 4fWO/2;Q1*<, W03'*HF/2;*+E8+.5o3/2RN&('I'*&H0+,<_/¡X-G+,H
L;0RN):;
V 382KF/2;*+¢8+.-08+,<+.'Q/:3/2RN&('«&Y ]3(<1*<+,HDQX£3'S3-0-05URN)M3/2RN&('«&YT 2eg_;*+>'*+.6Q3/2RUC+l),&('*<2/28:3RU'Q/ S
-08+.C+.'Q/<_3'i3-0-05URN)M3/2RN&('T&YD ê $ 4hRU'\L;0RN);i/¡L&>'*&H0+,<&Y/2;*+J&(82RU69RU'i3'*HH0+,</2RU'43/2RN&('-4382/<q;43MC+
/2;*+P<:3 V +PR V 36+=n3Z'*&H0+@'*+,),+,<<:382RU5UXF&(D0/:3RU'*+,HIDXs<:& V +>3-0-05URN)M3/2RN&('y&Yh/2;*+@82105N+È ê	$ c42Af0L;0RU5N+
/2;*+\-&9<2RU/2RUC+s),&('*<2/28:3RU'Q/ Q -08+.C+.'/<l<1*);Æ3I<210D0698:3-0;k/&ID+\1*<+,Hj/¡LRN),+Y[&(8Z3-0-05UXRU'06pD ê $ c4
LRU/2;«HORÍÌ+.8+.'/@-08&m+,)./2RN&('*<@&YRU/<@&(82RU69RU'7RU/E<:3,XO<u/2;43/ERU'y/2;0RN<@)M3(<:+9Wa/2;*+l/L&T-08&2+,)./2RN&('*<@&Y]/2;*+
&(82RU69RU'*< V 1*<2/JD+E/2;*+P<:3 V +9e



UÖ4×

4Ä Ä









£

Ä



h Û

{%}$My

yn	A'óAy




U

£*



Ô×



`Õ












C

0
C

Ä



¡

»y|

|7+./_1*<_'*&ML¬Yn&).1*<&('T/2;*+u82105N+,<_/2;43/L+.8+E1*<:+,Hi/&Z<&(5UC+u/2;*+¢ÖG×Ø.Ù{Ú*ÛÜ7Ø.Ý:Þ-08&(D05N+ V eqË®D0RN),&(5N&(8+,H
698:3-0;£=82105N+&(8]),&('*</28:3RU'Q/BA{RN<q<B3RNHZ/&EDG+E2(QB.[Bn,¡2£=8Me 8Me
APRÍYRU/<!<+,),&('*H-4382/=[),&('*).5U1*<RN&('i&(8
&(D05URU6Q3/2RN&('aA_H0&+,<_'*&(/),& V -082RN<+P3'QXs6+.'*+.82RN)@),&('*),+.-0/'*&H0+9eqrt+1*<:+/2;0RN<+fO-08+,<<2RN&('FDXs3'435N&(69X

7Ì

õ$-

3M¼¾½øuM%

»

Ï ê $MÚ¾4

B

Ò
ê $  4


Ð

=

Ø
¯Ó 

=

s

s

s

ÙÜÚ

s

s

Ò#

s

Ø
s

=

Ð

=

Ó4
=

x{RU69108+\`M­OJã+,HO1*)./2RN&('TY8& V

u

=
s

Ý

E

Ä

=

u
u

S
Ý

s

Ò

Ý

s

Ý

ÙÛÚ

Ò
=

u

Ø

s

Ò

Ý

s

ÙÛÚ
Ý

Ý

s

s

s

Ý
Ý

=

Ò#
Ý

ÙÛÚ

Ä
u

s

Ò

Ý

s

Ý

Ò#

s

Q

=

s

u

s

u




D.ê0$ c4

Ý

Ø
Ø
Ó 
Ó
/2;*+}¸ÍD´ÒÚvÍv¸$ÿ|»
µ§/&¢Î2CDåÝK´µ*´}Ü¶{·×¸$ºhW*LRU/2;*Dj3'*HmàY2eô+9eô<Me
s

s

s

s

LRU/2;T/2;*+<:&~¡)M35U5N+,Hi82105N+,<_RU'TÂ@3/:35N&(6*WL;*+.8+E35U5C9382Ro3D05N+,<_&Y/2;*+u;*+M3(H V 1*<2/J3-0-G+M38_RU's/2;*+D&HOX
=[ËD0RU/+.DG&(105E+./s35$eUW@`Mb9b9vAfeÁ^1*);Ê82105N+,<T38+y35N<&j)M35U5N+,Hâ.2©,£RU'ß/2;*+5URU/+.8:3/2108+9eÁ%&('*<2RNH0+.8Yn&(8
RU'*<2/:3'*),+@/2;*+P82105N+,<J&Yhx{RU6*e4vO  D 3'*H   38+@8:3'06+@8+,</282RN)./+,HW0L;0RU5N+  	 RN<'*&(/Me
Ë5N<&S'*&(/2RN),+I/2;43/s3S8:3'06+F8+,<2/282RN)./+,H 82105N+  )M3' D+FH0+,),& V -G&9<:+,HÒRU'Q/&3' +,wQ10RUC935N+.'Q/s<+./
&Y]82105N+,<
7
Þ $  4LRU/2;«+f*3()./25UX&('*+l'*&H0+lRU'S),&('*).5U1*<2RN&(' =[+.RU/2;*+.8P3'SRU'*HORUCRNHO1435!),&('*),+.-0/@'*&H0+¢&(8P3
8+.5o3/2RN&('S'*&H0+AfeEg_;*+.8+lRN<E&('*+>82105N+>Yn&(8u+M3():;y'*&H0+Z&Yq/2;*+Z),&('*).5U1*<2RN&('«&Y  _Y[&(8E+M3();SRU'*HORUCRNHO1435
'*&H0d
+ ÎW&('*+_82105N+_LRU/2;<:3 V +_;X-&(/2;*+,<2RN<]3(<  3'*H\3E),&('*).5U1*<RN&('\8+,<2/282RN)./+,H/[
& Î(Y[&(8q+M3():;\8+.5o3/2RN&('
'*&H08
+ Í0W{&('*+82105N+iL;*&9<+i;QX-G&(/2;*+,<2RN<lRN<¢/2;*+HORN<[2&(RU'Q/Z10'0RN&('¦&YJ/2;*+;X-&(/2;*+,<2RN<l&Y  3'*H&Yu35U5
RU'*HORUCRNHO1435q),&('*),+.-0/@'*&H0+,<@&Y/2;*+l),&('*).5U1*<RN&('t&Y  W3'*H«),&('*).5U1*<2RN&('«RNb
< Í0WGLRU/2;t<:3 V +l'*+.RU69;QD&(8<
3(<@RU'  eig_;*+5N&(69RN)M35]RU'/+.82-08+./:3/2RN&('Æ&Y_<21*):;t82105N+,<¢38+y=pY10'*)./2RN&('tY8+,+Au8:3'06+8+,<2/282RN)./+,HjÃu&(82'
82105N+,<Me Ð Y]3^0?¾ÉRN<H0+,HO1*).RUD05N+@Y[8& V 3<:+./&Y!8Me 8Me]82105N+,<X£W*/2;*+.'£RU/JRN<H0+,HO1*).RUD05N+PY8& V /2;*+P<+./&Y
/2;*+.RU8H0+,),& V -&9<2RU/2RN&('*<E«
Þ $t7
 4fW43'*HI8+,).RU-08&)M35U5UXeÃu&ML+.C+.8MWG3(<<&&('3(<),&('*<2/28:3RU'Q/<E38+@RU'C&(5UC+,HW
/2;0RN<J+,w10RUC(35N+.'*),+>H0&+,<'*&(/;*&(5NH3'QX V &(8+9e
ñ



Óyn¸





M.2©@m(Q¢2ff[f[,¡sBUfPo>1<q*[¡¢)jfO(0f[(yM.c5

þ2MmW© øI^RU'*),+I35U5_698:3-0;*<\38+T-010/ZRU'Q/&S'*&(8 V 35_Yn&(8 V W]3'¦RU'*HORUCRNHO1435 V 382K+.83-0-+M38<3/ V &9<2/
(& '*),+sRU'¦3698:3-0;7eSg_;*+'1 V D+.8\&YRU'*HORUCRNHO1435'*&H0+,<l).8+M3/+,HDXj/2;*+s<+./Z&YJ82105N+,<¢RN<lD&(10'*H0+,H
DQXß " Ò ©Òrà¦\Áj¢- Ø [ Ò  J D L Ò e£^&I/2;*+'Q1 V D+.8&YJ8+.5o3/2RN&(''*&H0+,<l).8+M3/+,HÊ='*&/¡LRU'¦8+.5o3/2RN&('
'*&H0+,<>38+).8+M3/+,H4AuRN<ED&(10'*H0+,H«DQXoá "ãâ G
ä $3Ò Á ( $¿[46ÒèeßV4 ä WL;*+.8+ ä RN<E/2;*+Z'1 V D+.8
&Y]8+.5o3/2RN&('S/¡X-+,<LRU/2;t369RUC+.'t382RU/¡X Æ3-0-+Mä3å 82RUDç'0æ 6sRU't382105N+Z),&('*).5U1*<2RN&('7W73'*H æ K RN</2;*+l698+M3/+,<2/
382RU/¡XT&Y}<21*):;3P8+.5o3/2RN&('/¡X-G+9e]^&l/2;*+E).5N&9<2108+E&Yh3¢698:3-0;I)M3'TDG+E&(D0/:3RU'*+,HTLRU/2;I3lH0+.82RUC(3/2RN&('I&Y
5N+.'069/2;BO
½ \¶áãè¶ßªe!rt+E/2;1*<&(D0/:3RU'SÏ [ RU'TÑ*'0RU/+P/2R V +9e
u&(/+]/2;43/MW9),&('/28:382X¢/&6+.'*+.8:35Ñ*'0RU/+_+f-43'*<2RN&('Z<+./<MW(+fORN<2/+.'*),+&Y4/2;*+).5N&9<108+_3'*Hl+fORN<2/+.'*),+
&Yh/2;*+uY105U5698:3-0;£38+>+,wQ10RUC935N+.'Q/J'*&(/2RN&('*<JRU'I/2;*+@)M3(<+@&Yh8:3'06+@8+,<2/282RN)./+,HF82105N+,<Me Ð /_Yn&(5U5N&MLJ<Y[8& V
/2;*+q-08&&Y*&Y0-08&(-G+.82/X`9`q/2;43/}/2;*+q5N+.'069/2;¢&Y43H0+.82RUC(3/2RN&('>Y8& V ÏT/&Ï [ RN<RU'~«
é $ G Q D 4fWL;*+.8+ \RN<
/2;*+<2R M+&
Y $n+
Ï *)«
 4q3'*H K RN<q/2;*+_698+M3/+,<2/382RU/¡X&Y3u8+.5o3/2RN&('/¡X-+J3-0-G+M382RU'06PRU'3u82105N+),&('*).5U1*<2RN&('7e
g_;0RN<q8&(1069;10-0-G+.8qD&(10'*H),&(105NH\D+_8+fÑ*'*+,HD010/qRU/]RN<q<21 ).RN+.'Q//&@&(D0/:3RU'/2;*+_Yn&(5U5N&MLRU'06>-08&(-G+.82/XW
L;0RN);¦LRU5U5DG+1*<+,H/2;08&(1069;*&(10/l/2;*+i-08&&Y[<l&Y),& V -05N+fRU/Xj8+,<2105U/<lRU'C&(5UCRU'06y8:3'06+s8+,<2/282RN)./+,H
82105N+,<Me

0

¡

6ù

ú

õ$-ö

¹



 úûM]ü|è9ýM.þtûMÿ=uèwu«úûMÔÔM3
øù F



Óyn¸
  © aQfOE:fG[n(T9{O\Áj(l 9B[	 :¢m©fU9[[9I	 ::*BJoZ(*f$(4M =
(M?fSZm9QEB.[Bn,¡2,.qm©ufNB =!OuNf9Fm©u(Cg!fBM?º9[n(P©f2(ÅÏ pq0(@:(a9ln(@:
fÍ¡2T$sOEft sºlmE
© $n+
Ï *)«
 465

ñ

p

Ð 'FL;43/Yn&(5U5N&MLJ<MW0L+>3(<<21 V +P/2;43//2;*+>382RU/¡XF&Yh8+.5o3/2RN&('/¡X-+,<RN<D&(10'*H0+,HFDQXF3Z),&('*<2/:3'Q/Me

q

½hy|Mèy¯º

­
f[fn,¡2iBNB6ø

<² ± ´½
p1
¿ þÄ!m(aN.¡W5

¢º×»y $

V Ä 2(0,[n(«iÎ2

¾ [è{%}huyýèyn	A'óAy

»y|

esO.CDÊ9a


(2@m9QP2S!

_ ` !m(aN.¡W5
V ±!90Bpf¡fGL:i(asQ29O,[n(«Î2\åÊ( E

V Ä 2(0,[n(«iÎ2Dåß(a>ÎsDå p ¸`	 !m(aN.¡W5
þ2Mm©Wøkg_;*+£Y[&(5U5N&LRU'06k8+,<105U/<T;*+M3,CRU5UX 8+.5UX &('

¯ 8&(-7eE`MO35U5EH0+.82RUC93/2RN&('*<TRU'QC&(5UC+,H§D+.RU'06k&Y
-&(5UX'*& V Ro355N+.'069/2;7WO/2;*+.XF3(H V RU/3¢-G&(5UX'*& V Ro357),+.82/2RÍÑ4)M3/+=/2;*+@<+,w1*+.'*),+E&Y}-08&2+,)./2RN&('*<1*<+,HT/&
D010RU5NHF/2;*+PH0+.82RUC93/2RN&('aAfe
HþÄ!9GU.¡.GB:Pm©qÎ2g
 ! }Ü × he]g_;*+-08&(D05N+ V D+.5N&('06<q/C
&  ¯ e Ð '*H0+,+,HW3@-G&(5UX'*& V Ro35
),+.82/2RÍÑ4)M3/+£RN<69RUC+.' DXÆ3tH0+.82RUC(3/2RN&(' Y8& V Ï°/&k3S698:3-0
; ¿ ê WYn&(5U5N&ML+,H DQX 3S-08&2+,)./2RN&('ÒY[8& V
/2;*+Z6&35h/g
& ¿Yê[ePrÊ;*+.'Â " OW&('*+&(D0/:3RU'*<@ÎÏ~ Ü × á=-08&m+,)./2RN&('t):;*+,)KRU'06AfW/2;1*<E/2;*+
 ¯ ~¡),& V -05N+./+.'*+,<<Me
å ! Ø×Ø
4Ùª(aÎ\`
å ! Ü × !e\ã+,)M35U5h/2;*+),&('*<2RN<2/+.'*).X
_` !(aN.¡fB:im©EÎ2\`

);*+,):KÒRU'QC&(5UC+,<T/2;*+RU828+,HO10'*H*3'Q/TYn&(8 V &Y¢Ïe Ð 'ß&(8H0+.8s/&t5URU69;/+.'Ê/2;*+-08&(D05N+ V Y[&(8 V 105o3/2RN&('7W
L+3(<<1 V +>;*+.8+l/2;43/P35U5]^0?E<@38+>RU828+,HO10'*H*3'/MW7D010/ERU828+,HO10'*H*3'*).X£)M3'SD+>RU'/+.698:3/+,H«LRU/2;*&(10/
RU'*).8+M3(<2RU'06E/2;*+),&('*<2RN<2/+.'*).X>):;*+,)K¢),& V -05N+fORU/¡X{<+,+q/2;*+-08&&Y4&Y*/2;*+,&(8+ V cOe}ÎåGÝ 7Ø×Ø
4Ù
D+.5N&('06</& _ ` <2RU'*),+>RU/),&(828+,<2-&('*H0</&\/2;*+¢5o3'0691436+¶
½ "#mW]ðÒ§ù¢_ D ¯_   $M]*1_ D *1_  4>nQWaL;*+.8+

]S+.'*),&H0+,<u3'RU'*<2/:3'*),8
+ $nÏ2ê)Ãêm.
å 4&Yh/2;*+P-08&(D05N+ V 3'*H $M]*H_ D *1_  4 i  RÍJ
Ì _ D "Ç$ D 3ê ö N 4fW4L;*+.8+
N
ê
N
R
\
<
y
3
0
H
.
+
2
8
U
R
9
C

3
2
/
N
R
(
&
Æ
'

Y

8
&
á
Ï

/
&
B
¿
W
a
ö
N
R
\
<
£
3
0

8

&
2

,
+
.
)
2
/
N
R
(
&
Æ
'

Y

8
&
2
/
*
;
T
+
2
/
2
8
U
R
9
6

6
.
+
\
8
&Y@3S),&('*<2/28:3RU'Q/
JPN L
V
V
D
RU'Q/7
& ¿ ê W _  " $  3ê ö D 4fW  RN<u3\H0+.82RUC93/2RN&('Y[8& V ¿ ê /Z
& ¿ ê ê 3'*
H ö D RN<u3-08&2+,)./2RN&('Y[8& V
RU'/&
¿Yê ê!<Me /Mr
e ö D%ë JON L;ì q
0 ö N e  RN<E-&(5UX'*& V Ro35U5UX«H0+,).RNH*3D05N+3'*H«-&(5UX'*& V Ro35U5UXyD435o3'*),+,Hß=[<2RU'*),+Z/2;*+
5N+.'069/2;*<J&Y D 3'*H  38+u-G&(5UX'*& V Ro35RU'F/2;*+@<2R M+E&Y}/2;*+ERU'0-010/BAfeqrß;*+.'UÐ
 " OW0&('*+E&(D0/:3RU'*</2;*+
-08&(D05N+ V Î_ÏåGÝ Ø×Ø
4Ù]WO/2;1*<q/2;*+ _` ~¡),& V -05N+./+.'*+,<<Me]^RU'*),+Î2\åÝ Ü × £),&('*<2RN</<qRU'

<&(5UCRU'06@/¡L&@RU'*H0+.-G+.'*H0+.'/]-08&(D05N+ V <MWQÎåGÝ Ø×Ø
4ÙÆ= _ ` ~¡),& V -05N+./+Aq3'*HZÎ2\~ Ü ×

	=  ¯ ~¡),& V -05N+./+AfWG3'*HF<RU'*),[
+  ¯ RN<RU'*).5U1*H0+,HIRU' _` WOÎ\åG~ Ü × jRN<35N<& _` ~¡),& V -05N+./+9e


¸ `	 !:(aU,¡fGBBZm©Î2DåGÝ Ü × heËu<Y[&(8Î2\å =[<+,+P3D&MC+AfW0L+>3(<<21 V +@/2;43/u35U5}^0?E<
38+RU828+,HO10'*H*3'Q/Me]g_;*+uw1*+,<2/2RN&('iRN< 38+/2;*+.8+E3>H0+.82RUC(3/2RN&('sY[8& V Ït/&l3l^0ç
? ¿ ê 3'*HT3P-08&2+,)./2RN&('
Y[8& V É¬RU'/k
& ¿YênWQ<1*);\/2;43/!Yn&(835Uü5 ¿ &Y/2;0RN<]H0+.82RUC93/2RN&('7WQY[&(835U5a),&('*<2/28:3RU'Q/ 9W9Yn&(835U5*-08&2+,)./2RN&('
JPN L RU'/
ökY[8& V
& ¿ mW7/2;*+.8+\+fORN<2/<>3F-08&m+,)./2RN&(×
' ö ê Y[8& V
RU'/¾
& ¿ <Me /Mo
e ö ê JON L Ä"Çö :e 
RN<-G&(5UX'*& V Ro35U5UX£H0+,).RNH*3D05N+3'*H£-G&(5UX'*& V Ro35U5UXD435o3'*),+,HÆ=[<2RU'*),+¢/2;*+¢<R M+¢&Y]/2;*+lH0+.82RUC93/2RN&('£Y[8& V
Ï¦/«
& ¿ ê RN<-G&(5UX'*& V Ro35U5UXF8+.5o3/+,H/&/2;*+¢<R M+>&Y!/2;*+PRU'0-010/BAfeg_;Q1*<MWaÎDåG~ Ü × kRN<RU' ¸ `	 e
Ð 'T&(8H0+.8_/&l-08&MC+E/2;*+@),& V -05N+./+.'*+,<:<MWOL+uD010RU5NHI3¢8+,HO1*)./2RN&('TY8& V 3l<2-+,).Ro35)M3(<+E&Y/2;*+E-08&(D05N+ V
 	 WQL;*+.8+/2;*+JYn&(8 V 105o3>RN<_3 ¥ ~Ä
% ux =R$eô+9eq3'RU'*<2/:3'*),+u&Y ¥ ~^Ë!gAf69RUC+.'T3@Y[&(8 V 105o3iWQL;0RN):;iRN<_3
),&('(m10'*)./2RN&('&Yh).5o31*<:+,<LRU/2;£3/ V &9<2/ ¥ 5URU/+.8:35N<W43'*HI3l-4382/2RU/2RN&(B
' mÁÀ D *)À  *)À 	 n¢&Y{RU/<C9382Ro3D05N+,<MW
H0&+,<}/2;*+.8++fORN<2/!3/28210/2;3(<:<2RU69' V +.'Q/hYn&(8h/2;*+C9382Ro3D05N+,<hRU'~À D W9<21*);Z/2;43/hYn&(8h35U5O/28210/2;3(<<2RU69' V +.'/
Yn&(8q/2;*+C9382Ro3D05N+,<]&YRÀ  W9/2;*+.8++fORN<2/<]3@/28210/2;s3(<<2RU69' V +.'/qYn&(8q/2;*+C9382Ro3D05N+,<]&YRÀ 	 <21*):;/2;43/áRN<
/2821*+ g_;0RN<-08&(D05N+ V RN< ¸`	 ~¡),& V -05N+./+=$^/&):K V +.X+.8MW`MbÀ9ÀW/2;*+,&(8+ V d*eU`Afe!|7+./1*<_)M35U5aRU/ ¥ ~^Ë!g 	 e

¿

`´µ*´ ¶{· ¹¸$º
«
¶¸º 2·Dµ*º¶

>´µ*´ ¶{· ¹¸º
´µ*´ ¶|· ¹¸º

K¶¸$º 2·Dµ*º¶
ä
Ä
Ä



ä

Tä

Ä×

Ä

ä

{ä

ä
K¶¸º 2·Dµ*º¶


6ù

K´µ*´ ¶{· ¹¸º
Ý
F

K¶¸º 2·Dµ*º¶

>´µv´ ¶{· ¸$º
ÄT×

6ù

AÞ

2­

õ$-


6ù

¬«
´µ*´ ¶|· ¹¸º
>´µ*´ ¶{· ¹¸º
ÄT×

Y¤ Ä × ¦ Þlß
>´µv´ ¶{· ¸$º

3M¼¾½øuM%

»

a

b

at

af

c

bt

bf

val

val

val

ct

cf

dt

2
1

2
3

C1

C1

C1

C1

C1

C1

1

C1

C2

a

b

c

d

val

val

val

val

val

df

av

bv

cv

dv

d

...

3

C2

C2

C2

C2

C2

C2

val

av

b

val

bv

Q

1

>~

2

C1

É


a

Ä
¿

a

2
3

1

3

C2

val

av

K´µ*´}Ü¶{·×¸$º
b

val

bv

x}RU69108+`À ç 03 V -05N+¢&Y{/28:3'*<2Y[&(8 V 3/2RN&('FY[8& V ¥ ~ F1& 	 /&ÎDåÝ
g_;*+/28:3'*<mY[&(8

3/2RN&('L+1*<+RN<PRU5U5U1*</28:3/+,HtRU'jx{RU6*eq`Àesg_;*+ ¥ ~^Ë!gÅY[&(8 105o3F1*<+,H«RN<l36Q3RU'

àdÑáÃÑ âÓÎ64Të$UâTV àdÑÎ=ÑÀâTä¯4fWh3'*H/2;*+\-4382/2RU/2RN&('kRN<9À D " mAà¢*Ká´n*)À  " m´ÎAV n*)À 	 " mAänQeFg_;*+
698:3-0;×¿¾&(D0/:3RU'*+,H£RN<u/2;*+l<:3 V +3(<RU'S/2;*+¢-08&&Y&Y]g_;7ecOWx{RU6*e{`MOWG+f0),+.-0/u/2;43/E),&('*),+.-0/E'*&H0+,<
Ý`Æ¯Þ>),&(828+,<2-&('*HORU'06P/&@C9382Ro3D05N+,<!RU'±À D 38+'*&(/!5URU'0K+,H/&E/2;*+_'*&H0+,< Ý`Æ9Ç¯Þ¢3'*HðÝUÆ§¸§ÞP8+.-08+,<+.'/2RU'06
$

/2;*+.RU8J-&9<<2RUD05N+EC935U1*+,<Me
x{RU8<2/_);*+,):Ki/2;43/_RU's/2;0RN<RU'0RU/2Ro35L&(825NHWO'*&¢),&('*</28:3RU'Q/RN<CRN&(5o3/+,HWOD010//2;*+u6&35É°)M3'0'*&(/D+
<:3/2RN<mÑ4+,HeÓXF3-0-05UXRU'06F&('*),+P/2;*+l+.C&(5U10/2RN&('S82105N+iW4L+>/282XI<& V +>C(35U143/2RN&('S&Yq/2;*+¢C(382Ro3D05N+,<uRU'
À D 3'*HI&(D0/:3RU'£3lL&(825N
H ¿ D WO/2;43/),&('Q/:3RU'*<E3'3'*<2L+.8/&ÉeqÓ10//2;0RN<JL&(825NHF;43(<J/&<B3/2RN<mYXi/2;*+
-&9<2RU/2RUC+),&('*<2/28:3RU'Q/ Q W9+fO-08+,<<2RU'06@/2;43/ $Yn&(8q+.C+.82X>C935U143/2RN&('&YG/2;*+_C(382Ro3D05N+,<!RU'~À D lEÀ  W9/2;*+.8+
V 1*</¢+fORN<2/>3TC935U143/2RN&('&Y/2;*+C9382Ro3D05N+,<PRU'ÉÀ 	 <1*);t/2;43/¢/2;*+ZY[&(8 V 105o3I+.C935U143/+,<>/&j[B* :e Ð Y
¿ <:3/2RN<mÑ4+,</2;0RN<),&('*<2/28:3RU'/MW0RU/ V +M3'*<_/2;43/_L+E;43,C+Yn&(10'*Ht=DQXT3-0-05UXRU'06/lA3¢C935U143/2RN&('I&Y/2;*+
D
C9382Ro3D05N+,<RU'*À D <1*);T/2;43/_Y[&(8J35U5C935U143/2RN&('*<J&Y}C9382Ro3D05N+,<RU'*À D lCÀ  =L;0RN);I)M3'FD+E<2R V -05URÍÑ4+,H
RU' $Yn&(835U5aC(35U143/2RN&('*<&YC(382Ro3D05N+,<RU'CÀ  :W<2RU'*),+J/2;*+.8+RN<]&('05UX\&('*+<1*);C935U143/2RN&('iY[&(8&À D AfWQ/2;*+.8+
RN<¢3FC(35U143/2RN&('¦&Y/2;*+C(382Ro3D05N+,<¢RU'À 	 <1*);j/2;43/¢/2;*+Yn&(8 V 105o3+.C(35U143/+,<¢/&j[f0,esg_;*+.'/2;*+.8+
RN<3'¦3'*<L+.«
8 :QBs/&£/2;*+ ¥ ~ F1
 & 	 -08&(D05N+ V ej%&('QC+.8<+.5UXW]<210-0-G&9<:+s3'Ò3'*<2L+.8sG/&£/2;*+sÎDå
-08&(D05N+ V e Ð / V +M3'*<]/2;43/]Y[&(8+.C+.82XL&(825NZ
H ¿ D /2;43/)M3'iDG+J&(D0/:3RU'*+,HiDQX\3-0-05UXRU'06>/2;*+82105N+XWQ/2;*+
),&('*<2/28:3RU'/ Q RN<CRN&(5o3/+,H«=[&(/2;*+.82LRN<+>É°),&(105NHsD+-08&2+,)./+,HTRU'Q/o
& ¿ D 3'*Hs/2;*+@3'*<2L+.8_L&(105NHTD+
:QBºAfeg_;1*<E/2;*+.8+>RN<'*&T3(<<2RU69' V +.'Q/@&Yq/2;*+¢C(382Ro3D05N+,<uRU'pÀ
B
<

3
2
/
N
R
<mYXRU'06/2;*+l),&('*<2/28:3RU'/MWh0 5W 5/2;*+
D
3'*<2L+.8J/&/2;*+ ¥ ~ F1
 & 	 -08&(D05N+ V RN<@a9e
å ! Ü × hesÎsDåÝ Ü ×  <2/:3MX<>RU'«/2;*+\<:3 V +).5o3(<<P&Y
¸	` !:(aU,¡fGBBsm©@ÎsD`
),& V -05N+fORU/¡Xi3(<ÎDåÝ }Ü × he Ð '*H0+,+,HW/2;*+w1*+,<2/2RN&('RN< 38+J/2;*+.8+E3'CsD~¡H0+.82RUC(3/2RN&('iY[8& V Ï
/C
& ¿Yê43'*Hs3E-08&2+,)./2RN&('Y[8& V É®/&¢3>^0
? ¿YênWQ<21*):;/2;43/qYn&(835Uü5 ¿ 7&Y/2;0RN<H0+.82RUC(3/2RN&('s+.RU/2;*+.8+,w1435
/&ZÏt&(8_&(D0/:3RU'*+,HTDQXi3'sR VV +,HORo3/+
D~¡H0+.82RUC93/2RN&('7WQYn&(835U)
5 ¿ ê &Y7/2;0RN<_H0+.82RUC(3/2RN&('FH0+.82RUC+,HiY8& V ¿
JPN L /& ¿ ê W*/2;*+.8+¢+fORN<2/<
DQX3'B\~¡H0+.82RUC93/2RN&('7W*Yn&(835U5}),&('*</28:3RU'Q/
W0Yn&(835U5-08&2+,)./2RN&(¾
' ö«Y8& V
3'U\~¡H0+.82RUC93/2RN&('FY[8& V ¿Yê /&\3\^0#
? ¿Yê ê 3'*H£3>-08&2+,)./2RN&(g
' öêaY8& V
@/8
& ¿Yê ê <e /MÓ
e öê JON L "Qö
3'*HT/2;*+u5N+.'069/2;*<J&Yh35U57H0+.82RUC93/2RN&('*<38+E-&(5UX'*& V Ro35RU'T/2;*+@<2R M+E&Y{/2;*+ERU'0-010/Me!rß;*+.'* " OW0&('*+
&(D0/:3RU'*<JÎ2DåÝ Ü × !W4/2;1*<J/2;*+ ¸`	 ),& V -05N+./+.'*+,<<Me
|7+./_1*<-G&(RU'/&(10//2;43/MWL;*+.8+M3(<RU'T6+.'*+.8:35)M3(<+9WH0+,HO1*)./2RN&('FRN< V &(8+uHOR ).105U/_RU'sÎ2\å=/282105UX
10'*H0+,).RNH*3D05N+A\/2;43'ÒRU'ÆÎDåª=[<+ V RÍ~¡H0+,).RNH*3D05N+AfW_/2;*+),&('QC+.8<+;*&(5NH0<ZY[&(8/2;*+F-4382/2RN).105o38i)M3(<+F&Y
8:3'06+f~$8+,<2/282RN)./+,H82105N+,<Me

Ä

dÝ

$Ý

Ä

ß

>~

>~

K´µ*´ ¶{· ¸$º

´µ*´ ¶|· ¹¸º



Gß

´µv´ ¶{· ¸$º


´µ*´ ¶|· ¹¸º
Ý
F

Ä×
ÄT× 
6ù
eú

.Ä ×

õ$-,õ


 ¤YÄ ¦ Þlß
×
O«
¡

 úûM]ü|è9ýM.þtûMÿ=uèwu«úûMÔÔM3
øù F

q

h  ï ñ {3¸¸Mó|»{3 M}h	A{% }A
z'*+ V 3,X),&('*<2RNH0+.8u/2;*+>)M3(<:+>L;*+.8+¢'*&(/u&('05UXF82105N+,<D010/@35N<&),&('*<2/28:3RU'/<P38+>8+,</282RN)./+,He|7+./u1*<
Ñ*8<2/J),&('*<2RNH0+.8/2;*+ V +M3'0RU'06(Y105{)M3/+.6&(82XF&Y{'*+.6Q3/2RUC+P),&('*</28:3RU'Q/<Me

p

<² ±

q

½hy|Mèy¯º

ö

 ï  ¢º×»y $ ¾´½ }$ynu{Ô¸ Myó}$	A{%
fNBPsD§(g=fBi9*@:Gn9[M?Z90f[2(46ø

}A

eT[(OG9:uBBG[[99lO

K¶¸$º7Ø×Ø2·Dµ*º¶4Ù°:2(B!¿HþÄ!:(aU,¡W5
Î_ÏåÝK´µ*´Ü¶{·×¹¸º®:2(B Ä þÄ!m(aN.¡W5
Î2\åÝ:×º¶¸$7
º Ø×Ø2·Dµ*º*¶ ÙÇNNÎåGÝK¶¸$7º Ø×Ø2·Dµ*º4¶ Ùá:!Ua2QfNfYRF:2(B¢,fZM!Q2,[fU´5
Î2DåÝ´µ*
´ Ü¶|· ×¹¸¬º 2f\(0@MfZ'!mQ2.nQfNW5
Î2\åÝK´µ*}
´ Ü¶{· ×¹¸$§º (a>ÎsDåÝ´µ*´ Ü¶|· ×¹¸ßº f\(«[B@:a2.nQfNW5

V Î_ÏåÝ
V
V
V
V

þ2Mm©Wø
±!! 1þÄ!m(aN.¡fGf:¢m©_ÎÏåÝ

`¿

K¶{¸$º A·µvº¶
K´µ*´ ¶{· ¸$º

7Øº×pØ
4Ù@íY[8& V  ¯ ~¡),& V -05N+./+.'*+,<<J&Y{-08&m+,)./2RN&('F):;*+,)K~
RU'06£=/2;7e*cAfe
Ä þÄ!:(aU,¡fGBBZm©_ÎÏåÝ }Ü × ø/2;0RN<J-08&(D05N+ V )M3'IDG+E+fO-08+,<<+,H3(< ¡RN<JRU/J/2821*+E/2;43/
É )M3' D+F-08&m+,)./+,H RU'Q/&kÏÅ3'*HÒ/2;43/\'*&),&('*<2/28:3RU'Q/T&YEå®)M3' D+F-08&m+,)./+,H RU'Q/&kÏ
/2;1*<
D+.5N&('06<I/& Â ¯ 1
e u&ML 5N+./I1*<),&('*<2RNH0+.8£/2;43/IåÅ),&('Q/:3RU'*<S&('05UX§&('*+j),&('*</28:3RU'Q/Me Ë 8+,HO1*)./2RN&('
Y[8& V ¥ ~^Ë!g /&
× ¾=[<:+,+TYme R$e /2;*+F-08&&Y@&Y@/2;7eÊAl-08&MCRNH0+,<s3t<2/28:3RU69;Q/mYn&(82L38HÊ8+f~
HO1*)./2RN&('kY8& V Öî,u(ïð(ñZÖî,u /&Î_Ï7åÝ }Ü × =[<+,+\Yme R$e ¯ 3-43(HOR V RU/282RN&(17W`Mb9bdAfWh/2;Q1*<l/2;*+
Â ¯ ~¡),& V -05N+./+.'*+,<<Me
õ.lM !2.nQf [	 :l2©!Î\åÝ:×
7Øº×pØ
4Ä
Ù øJg}&E-08&MC+/2;*+_RU'*),&('*<RN<2/+.'*).X&Y3E¿@ÓEW(L+ V 1*<2/
Ñ*'*H<& V +CRN&(5o3/2RN&('&Y3E),&('*<2/28:3RU'Q//2;43/!LRU5U5*'*+.C+.8!DG+_8+,</&(8+,He!Ó10/!'*&ECRN&(5o3/2RN&('&Y73u'*+.6Q3/2RUC+
),&('*<2/28:3RU'/})M3'>+.C+.8}DG+h8+,<2/&(8+,Hi=pY1082/2;*+.8}82105N+]3-0-05URN)M3/2RN&('*<})M3'¢&('05UX@3(H0HPRU'OY[&(8 V 3/2RN&('7W/2;Q1*< V &(8+
-&9<<2RUD05N+J-08&2+,)./2RN&('*<MWO3'*Hi)M3'0'*&(/8+ V &MC+u/2;*+).105U-082RU/&('*+Afe]^&¢L+u&('05UX;43,C+/&P-08&C+/2;43/&('*+
),&('*<2/28:3RU'/u&Yhåj)M3'D+PH0+,HO1*),+,HY8& V $n+
Ï *)«
 4fRU/RN<u3<+ V RÍ~¡H0+,).RNH*3D05N+l-08&(D05N+ V e © a2.nQf [	 :
m©SÎåGÝ Ü × Yn&(5U5N&MLJ<L+ V 1*<2/u-08&MC+l/2;43/EÉ¾)M3'yDG+¢H0+,HO1*),+,HIY[8& V $n+
Ï *)«
 4fWD010//2;43/
'*&\),&('*<2/28:3RU'/&Y{å«)M3'7e
g_;*+j382691 V +.'/<-08&CRU'06ß<+ V RÍ~¡H0+,).RNH*3D0RU5URU/¡Xâ&YH0+,HO1*)./2RN&('âRU'§Î2Dåª3'*H§10'*H0+,).RNH*3D0RU5URU/¡X®&Y
H0+,HO1*)./2RN&('RU'FÎ2CDåj38+E/2;*+P<B3 V +>3(</2;*+@&('*+,<J1*<:+,HTRU'F/2;*+@-08&&Y!&Y!g_;7e7`MÕOe
g_;*+£8+,<2/282RN)./2RN&('¬/&j'*+.6Q3/2RUC+S),&('*<2/28:3RU'/<TH0+,).8+M3(<+,<T),& V -05N+fRU/Xß&YP-08&(D05N+ V <TRU'Ê/2;*+IÎÏå

&
0
H
+.5$WD010/RU/_H0&+,<'*&(/;*+.5U- V 1*);I3(<<:&&('F3(<]82105N+,<38+RU'QC&(5UC+,HW0<2RU'*),+/2;*+,<+-08&(D05N+ V <_8+ V 3RU'
V
10'*H0+,).RNH*3D05N+9eß%& V D0RU'0RU'06t8:3'06+F8+,<2/282RN)./+,HÆ82105N+,<\3'*HÒ'*+.6Q3/2RUC+I),&('*<2/28:3RU'Q/<W]L+I&(D0/:3RU' V &(8+
RU'Q/+.8+,</2RU'06i),& V -05N+fORU/¡XF8+,<2105U/<M

þÍv¸$ÎGµ*¶{· ¹¸$º

£Ý

TÞlß

K´µ*´ ¶{· ¸$º
º¶{¸$º A·µvº¶

K´µ*´ ¶{· ¹¸º

p

¡

³ q ¢º×» <² ± ´½   » 
&ö ¾ó

Bf[f[M¡2sBNB¢(aiGnQ9['?(Z(0.[m(4>(a2f,f4£O[ÙG9UMQ2MWø
V Î2\åÝK¶{¸$º7Øº×pØA·µvº¶4Ù°29\fZ!`¿1þÄ!m(aN.¡W5
´ Ü¶{· ×¹¸$®º 29\f Ä þÄ!9GU.¡´5
V Î2\åÝK´µ*}
´ Ü¶|· ×¹¸®º (a>ÎCD7åÝK´µ*´ Ü¶{· ×¹¸§º ( ¸` !:(aU,¡W5
V Î2DåÝ´µ*
½hy|Mèy¯º





y $

¾ [



 y|

õ$-%-

{%}

}hy|M{Ô¸ y

|M}h	Aè{% }A

Øp©s(*;:«2(QS!

»

condition

frontier

3M¼¾½øuM%

mandatory part
1

1
2

2

ì"<

Õ<

2
3

3

1

1

1

3

3

UÄ

2

Ä

UÄ

å S $ C4

D+$ C4

3

2

1

1

UÄ
ÎÏåÝK¶{¸$º7Øº×pØA·µvº¶4Ù/&3l8+,</282RN)./+,HIÎD7åGÝKº¸$ºGÝK´µ*´}Ü¶{·×¸$º
Õ<

Éo$ E4

2
3

2
3

x{RU69108+\`McO!g8:3'*<mYn&(8 V 3/2RN&('Y[8& V

þ2Mm©Wø Ð '*),&('*<2RN<2/+.'*).X«RU'tÎ2\åß3(H V RU/<Z3T-G&(5UX'*& V Ro35),+.82/2RÍÑ4)M3/+9Wq3IH0+.82RUC(3/2RN&('§=[&Y-G&(5UX'*& V Ro35

5N+.'069/2;aAY[8& V ÏÒ5N+M3(HORU'06I/&F3s698:3-0;«RU'/&TL;0RN);3s),&('*<2/28:3RU'/>&Y]å¦)M3'«DG+l-08&2+,)./+,HW3'*HS/2;0RN<
-08&2+,)./2RN&('7e Ð '*),&('*<2RN</+.'*).XRN<u/2;Q1*<ERU'© ¯ W3'*HS),& V -05N+./+.'*+,<<uY[&(5U5N&LJ<uY8& V /2;*+l-4382/2RN).105o38P)M3(<+
L;*+.'É RN<P+ V -0/¡Xeix*&(8>H0+,HO1*)./2RN&('7W{L+ V 1*<2/P-08&C+\/2;43/P'*&F),&('*<2/28:3RU'/¢)M3'tD+H0+,HO1*),+,H«Y[8& V
$n+
Ï *)«
 4fWQD010/!/2;43/É¬)M3'7eq^&E/2;*+_-08&(D05N+ V RN<hRU'Â ¯ ex*&(8q),& V -05N+./+.'*+,<:<MW8+ V 382Kl/2;43/!/2;*+_-08&(D05N+ V
RN<J<2/2RU5U57),& V -05N+./+>L;*+.'KäRN<+ V -0/¡Xt=[g_;7eJ` ¥ Afe
g}&¢-08&C+E/2;43/_ÎDåÝ }Ü × SLRU/2;s8Me 8Me!82105N+,<3'*Hi'*+.6Q3/2RUC+E),&('*<2/28:3RU'/<RN< ¸ ` ~¡),& V -05N+./+9W

L+yLRU5U5uÑ*8<2/F<2;*&LÈ/2;43/TRU/sDG+.5N&('06<T/& ¸ ` WJ/2;*+.'§+fO;0RUD0RU/I3t8+,HO1*)./2RN&('¬Y[8& V 3 _ ` ~¡),& V -05N+./+


-08&(D05N+ V /&ZRU/<),&~$-08&(D05N+ V ÎD7åGÝ GÝ }Ü × ¬=[<2RU'*),+P),&~ ¸` 0 _` Afe
Î2DåGÝ Ü × ¬),&(828+,<-G&('*H0<¢/&I/2;*+i5o3'0691436+s
½ " mW]pÒ ¯_ D ù¢_   $M]*y_ D *y_  4>nQW{L;*+.8+ ]
+.'*),&H0+,<Z3'RU'*<2/:3'*),©
+ $$É~´ê $n+
Ï *)
D *m
å 4y4Z&YJ/2;*+-08&(D05N+ V Wq3'*Q
H $M]*y_ D *y_  4 i  RÍÀ
Y _ D +.'*),&H0+,<l3'GD~
H0+.82RUC93/2RN&('Y[8& V Ï®/©
& ¿ ê 3'*Hk3-08&2+,)./2RN&('Y[8& V É /J
& ¿ ê Wq3'*×
H _  +.'*),&H0+,<3 V 3-0-0RU'06£Y[8& V
<& V +s),&('*<2/28:3RU'Q/&YJåß/©
& ¿Yê]/2;43/lRN<¢'*&(/\3F-08&2+,)./2RN&('®='*&(/+i/2;43/lRÍb
Y ¿YêH0&+,<l'*&(/lCRN&(5o3/+T3'QX
),&('*<2/28:3RU'/MW*/2;*+.'I'*&Z698:3-0;£RU'F/2;*+PH0+.82RUC(3/2RN&('IY8& V Ï/& ¿ ê H0&+,<BAfe
rt+k+f;0RUD0RU/S'*&L 3 8+,HO1*)./2RN&('°Y8& V /2;*+k6+.'*+.8:35ZÎÏåGÝ 7Ø×Ø
4Ù -08&(D05N+ V /&ßÎD7åGÝ
GÝ }Ü × ÁLRU/2;Ê8Me 8Meâ82105N+,<F3'*Hß'*+.6Q3/2RUC+S),&('*<2/28:3RU'Q/<MeÁ|7+.J
/ $n+
Ï *mq
å " m rn¤4D+y3'ÊRU'O~
<2/:3'*),+u&YÎÏåÝ 7Øº×pØ
4Ùß=LPe 5$eô&0e 6*eUWOL+u8+,<2/282RN).//2;*+u-08&(D05N+ V /&¢),&('*<2RNH0+.8&('05UX&('*+u-&9<2RU/2RUC+
),&('*<2/28:3RU'/BAfetg_;*+s/28:3'*<mY[&(8 V 3/2RN&('¦L+s),&('*<RNH0+.8lD010RU5NH0<\3'kRU'*<2/:3'*),+T&YÎ2DåGÝ GÝ Ü ×
$$o
É $ C4Û´ê $n+
Ï *)+
D $ E4*må S $ C4y4y4P3(<@Yn&(5U5N&MLJ<ert+\)M35U5/2;*+@©fm(a[nfF&Y/2;*+-&9<2RU/2RUC+\),&('*<2/28:3RU'/ à/2;*+
<+./l&Y_'*&H0+,<¢RU'j/2;*+\/282RU696+.8F= 5pW 5I),&(5N&(8+,HjDXjÕAE;43MCRU'06«3/>5N+M3(<2/l&('*+\'*+.RU69;DG&(8ZRU'j/2;*+i&(D05URU6Q3º~
/2RN&('7ePg_;*+ZH0+fÑ*'0RU/2RN&('t&Y),&(5N&(8+,HS698:3-0;*<ER V -05URN+,<E/2;43/EY[8&('Q/2RN+.8E'*&H0+,<P38+l),&('*),+.-0/@'*&H0+,<=/2;*+.RU8
'*+.RU69;QD&(8<i38+I/2;Q1*<8+.5o3/2RN&('ß'*&H0+,<BAfe¦|7+./1*<\H0+.'*&(/+F/2;*+,<+sY[8&('Q/2RN+.8i'*&H0+,<D
X I* F6F6F * K eÆg_;*+
+.C&(5U10/2RN&('S82105N++Ä
D $ E4_;43(<Yn&(8;QX-&(/2;*+,<2RN<u/2;*+>/282RU696+.8E&Y WG3'*HIYn&(8),&('*).5U1*<2RN&('t3\8+.5o3/2RN&('y'*&H0+
/¡X-+,
H ¸8 4WGL;*+.8r
+ ¸ "FRN<@3\'*+.L K ~382X8+.5o3/2RN&('«/X-+¢RU'*),& V -438:3D05N+LRU/2;t35U5h&(/2;*+.8E/X-+,<Me
g_;*C
+ Ì7òMó'*+.RU69;DG&(8@&Yq/2;0RN<'*&H0+¢RN</2;*+>),&('*),+.-0/E'*&H0E
+ Ì:eu%;*+,):K/2;43/+
D $ E4RN<u38:3'06+¢8+,<2/282RN)./+,H
82105N+9eqg_;*+E'*+.6Q3/2RUC+P),&('*</28:3RU'Q/Jå S $ E4RN<_/2;*+@<210D0698:3-0;£&Y Á),& V -&9<+,HI&Y{RU/<J&(D05URU6Q3/2RN&('= XJ D L 4
3(H0H0+,HyLRU/2;S'*&H0+,<E&Y]/2;*+¢Y[8&('Q/2RN+.8P3'*Hy/2;*+>8+.5o3/2RN&('«'*&H0+>/X-+,©
H ¸ "aW45URU'0K+,HS/&i/2;*+¢Y8&('/2RN+.8
'*&H0+,<JRU'/2;*+¢<:3 V +@L_3,X£3(<u3DG&C+9ex}RU'435U5UXW4/2;*+l^0? o
É $ C4RN< V 3(H0+¢&Y!&('*+>8+.5o3/2RN&('£'*&H0+P/X-+,H
¸ "i3'*HFRU/<'*+.RU69;DG&(8<JY8&('/2RN+.8'*&H0+,<Me!g_;0RN</28:3'*<mYn&(8 V 3/2RN&('RN<JRU5U5U1*<2/28:3/+,HFRU'x{RU6*e`McOe

K´µ*´ ¶{· ¹¸º

K´µ*´ ¶{· ¹¸$º
Kº¸$º K´µ*´ ¶{· ¸$º




K¶¸$º 2·Dµ*º¶

º¸$º K´µ*´ ¶{· ¸$º
K¶¸º A·Dµ*º¶
UÄ
UÄ UÄ
MË

UÄ

7Ë



ÃÄ

UÄ

UÄ

7Ë

õ$-M÷

(Ä

7Ë

UÄ

4Ä
Kº¸$º K´µv´ ¶{· ¸$º
dÄ

UÄ

 úûM]ü|è9ýM.þtûMÿ=uèwu«úûMÔÔM3
øù F

K¶¸º A·Dµ*º¶

rÁe 5$eô&0e 6*eEL+l)M3't3(<<21 V +¢/2;43/@ÏÒRN<uRU828+,HO10'*H*3'Q/MRU'£/2;43/@)M3(<+9WGÎÏåÝ 7Øº×pØ
4ÙÒRN<E<2/2RU5U5
_ ` ~¡),& V -05N+./+@=[<+,+]/2;43/}/2;*+/28:3'*<mYn&(8 V 3/2RN&('Z1*<+,H>RU'¢/2;*+]-08&&Y4&Yag_;7ecJ-08&HO1*),+,<!3'>RU828+,HO10'*H*3'Q/


698:3-0;g¿PAfeÓu&ML§<210-0-&9<+/2;43/j$nÏ+* E4]RN<_),&('*<2RN<2/+.'/MhRU/ V +M3'*<_/2;43/+.RU/2;*+.8_/2;*+/282RU696+.8&Y áH0&+,<
'*&(/u-08&m+,)./RU'Q/&FÏWG3'*H£RU'/2;43/E)M3(<+9Wa/2;*+P82105N+D+$ E4JLRU5U5'*+.C+.8u-08&HO1*),+¢/2;*+¢'*+,+,H0+,HQ¨3¸ ¢µ
'*&H0+9Wa&(8u+.C+.82Xj=[+fRN<2/2RU'06A-08&m+,)./2RN&('S&Yq/2;*+>),&('*HORU/2RN&('S&Y ÅRU'Q/&T
Ï "ÿÌÍÍ$n`
Ï 4J)M3'D+>+fO/+.'*H0+,H
/&>3E-08&2+,)./2RN&('i&Y â3(<]3EL;*&(5N+9e]^&P+.C+.82X3-0-05URN)M3/2RN&('s&YrÄ
D $ E4{-08&HO1*),+,<3ECRN&(5o3/2RN&('i&YGå S $ E4fe
É $ C4_)M3'0'*&(/D+@H0+,HO1*),+,HFY[8& V /2;*+@K'*&ML5N+,HO6+¢D43(<+9e_%&('QC+.8<+.5UXWG<210-0-&9<+E/2;43/
Ð 'IDG&(/2;I)M3(<:+,<uo
Ï öG~$CRN&(5o3/+,< \W/2;*+.'k/2;*+i3-0-05URN)M3/2RN&('Æ&Y,+
¦
D $ C4uYn&(5U5N&MLRU'0J
6 öÒ-08&HO1*),+,<l3I698:3-0;j/2;43/ZH0&+,<>'*&(/
CRN&(5o3/+Eåla
S $ C4fW*3'*HFL+P)M3'£H0+,HO1*),+¢o
É $ C4fe
g_;*+I3D&MC+T/2;*+,&(8+ V <2;*&LJ<\3yH0+,).8+M3(<+TRU'Æ),& V -05N+fRU/XL;*+.'Æ6+.'*+.8:35-&9<2RU/2RUC+F),&('*<2/28:3RU'/<
38+S8+,<2/282RN)./+,H¬/&¦'*+.6Q3/2RUC+«&('*+,<Me¾ÎÏåÝ 7Øº×pØ
4ÙªY$35U5N<sY8& V _` /&Æ),&c~  ¯ 3'*HWL;*+.'

35N<&i),&('*<2RNH0+.82RU'06i8:3'06+>8+,<2/282RN)./+,H£82105N+,<MW*Î2\åÝ 7Øº×pØ
4Ù¦Yn35U5N<JY8& V _ ` /&iÂ ¯ W3'*HIÎD7åGÝ

Ü × âY$35U5N<Y[8& V ¸`	 /& ¸,` e Ð /\L&(105NHßDG+IRU'Q/+.8+,<2/2RU'06k/&j+fO;0RUD0RU/-4382/2RN).105o38T)M3(<+,<&Y

),&('*<2/28:3RU'/<MW V &(8+Z6+.'*+.8:35!/2;43'«'*+.6Q3/2RUC+&('*+,<MW7/2;43/ V 3K+Z/2;0RN<@),& V -05N+fRU/X£Y$35U5hRU'Q/&TRU'/+.8 V +f~
HORo382XF).5o3(<<+,<P=DXT+f*3 V -05N+PÂ ¯ 3'*HÃô ` Y[&(8Î_Ï7åÝ 7Øº×pØ
4Ù{AfeJ^& V +P<2X'Q/:3()./2RN)@8+,</282RN)./2RN&('*<

L+uH0+fÑ*'*+,HY[&(882105N+,<38+6&&H)M3'*HORNH*3/+,<Mh/2;*&(1069;F3EÑ*'0RU/+u+fO-43'*<2RN&('s<:+./&Y7),&('*<2/28:3RU'Q/<_;43(<'*&
<+.'*<+9W5N+./q1*<]),&('*<2RNH0+.8m(Q2ff[f[,¡\(0.[m9p4.eh|7+./]1*<]35N<:&PH0+fÑ*'*+>(p.9*G2,¡(*f[2(pa
3(<E),&('*<2/28:3RU'Q/<EL;*+.8+l/2;*+l/282RU696+.8P3'*Hy/2;*+¢&(D05URU6Q3/2RN&('j38+¢'*&(/@),&('0'*+,)./+,H7<21*);«),&('*<2/28:3RU'/<@RU'O~
).5U1*H0+@/2;*+ ¡/&(-&(5N&(69RN)M35),&('*<2/28:3RU'/< P1*<+,HTRU'=[£RU'*+M31£Á£RN<<:3(&(10R$W`Mb9bÀ9Afe
g_;*+]Y[&(5U5N&LRU'06E-08&(-G+.82/XP;0RU69;05URU69;Q/<h/2;*+8+.5o3/2RN&('*<2;0RU-*<h&Y*/2;*+,<+-4382/2RN).105o38h)M3(<:+,<LRU/2;l'*+.6Q3/2RUC+
),&('*<2/28:3RU'/<M

Ä

UÄ

Ä
UÄ

Ä

UÄ

UÄ

´µv´ ¶{· ¸$º

ÃÄ

UÄ

UÄ

TÄ

MË

UÄ

¡

K¶{¸$º A·µvº¶
K¶{¸$º A·µvº¶

K¶¸º A·Dµ*º¶

Ý

5ß

¿



Óyn¸
 ï ¢n9[M ?l(*f[2(pa@(¢O(.[[,U(>M>2©P9s2(S!¡Bf[fn,¡2F(*f[2(pa
(as(p.9*G2,¡I(0.[m9p4W5

ñ

þ2MmW© øPËu<E'*&(/2RN),+,HtRU't<:+,)./2RN&('jvOW}3s'*+.6Q3/2RUC+\),&('*<2/28:3RU'/>RN<P+,w10RUC935N+.'Q/P/&I3s-&9<2RU/2RUC+),&('*<2/28:3RU'/
L;*&9<+F&(D05URU6Q3/2RN&('ÒRN<),& V -&9<+,HÆ&YE&('*+F),&('*),+.-0/\'*&H0+T&YE/¡X-G+m¦¨ "§§³ ¬T± ¬0W]L;*+.8+*¦8 "§³­¬±­¬yRN<
RU'*),& V -438:3D05N+lLRU/2;S35U5h&(/2;*+.8u/¡X-G+,<E3'*H£H0&+,<'*&(/u3-0-+M38RU'«3'QXy^0?ª+f0),+.-0/RU'åß=RU/RN</2;Q1*<@3
HORN<),&('0'*+,)./+,Hs),&('*<2/28:3RU'Q/BAfeqr°e 5$eô&0e 6*eh/2;0RN<]'*&H0+)M3'D+5o3DG+.5N+,HDQX3'iRU'*HORUCRNHO1435 V 382K+.8u=L;0RN):;7W
3(<9¦¨ § ³ ¬T± ¬*W{3-0-+M38<¢&('05UXSRU'jå7AfW}/2;Q1*<¢5N+M3(HORU'06£/&£3I),&('*<2/28:3RU'/¢L;0RN):;RN<>DG&(/2;jHORN<:),&('0'*+,)./+,H
3'*HF8:3'06+f~$8+,<2/282RN)./+,He

MÇ

7Ç

p

MÇ

¡

 } q

½hy|Mèy¯º

 

<² ±

¢º×»y $

(4G2,¡2(0.[m(4Wø

¾´½ð]Wó|M}]}$y§óAyóM}h	A{% }A

esOfuå«(4$(0(4@:9oS!

K¶¸$º7Ø×Ø2·Dµ*º¶4Ù°:2(B! Ä þÄ!m(aN.¡W5
Î2\åÝK¶{¸$º7Øº×pØA·µvº¶4Ùk(aÎ2\åÝ´µ*´Ü¶|·×¹¸º«2.9pZaQ2.nQ.U={.ÎåGÝK¶¸$º7Ø×Ø2·Dµ*º¶4Ù

V

V Î_ÏåÝ

:2(B! Ä þÄ!m(aN.¡r9hO.yfUB¢92>2(QS!2ff[f[,¡5

´µ*´ ¶|· ¹¸º

V Î2DåÝ Ü × äf\(0MfZ'!mQ2.nQfN=fOi29\f ¸ ` !m(aN.¡B9hOf®fNBt(
2(S!¡Bf[fn,¡25

K´µ*´ ¶{· ¸$º

V Î2CDåÝ }Ü ×
2(S !¡Bf[fn,¡25

f\(0aQ.[QQfN=t.(B ¸` !9GU.¡9hOfÅfUBÆ(


õ$-AÖ

»

º¶¸$º 2·Dµ*º¶

3M¼¾½øuM%

þ2MmW© øyÎÏåÝ:×
7Ø×Ø
*Ù°D+.5N&('06<Z/&yÂ ¯ W!<2RU'*),+sL+ V 1*</-08&MC+T/2;43/lY[&(8&('*+T),&('*<2/28:3RU'/
/2;*+.8+yRN<F3t-08&2+,)./2RN&('§&Y>RU/<s/282RU696+.83'*H '*&k-08&2+,)./2RN&('¬&Y¢RU/<s&(D05URU6Q3/2RN&('7e %& V -05N+./+.'*+,<<TRN<
-08&MC+,HyLRU/2;S3\8+,HO1*)./2RN&('£Y8& V ^Ë!g
E^Ë!gñ=n3(<RU'£-08&&Y]&Y]g_;7e¢` ¥ AfeÎÏåÝ
7Øº×pØ
4ÙÆRN<
/2;Q1*<),&~¡Â ¯ ~¡),& V -05N+./+9e
Ë82691 V +.'Q/<Y[&(810'*H0+,).RNH*3D0RU5URU/¡XI&Y!ÎåGÝ Ø×Ø
4Ù]WaÎåGÝ Ü × k3'*HIÎ2CDåÝ Ý
Ü × !W73(<L+.5U5h3(<u<+ V RÍ~¡H0+,).RNH*3D0RU5URU/¡XS&YqÎD7åGÝ Ü × hW38+>/2;*+¢<B3 V +l3(<RU'/2;*+¢-08&&Y]&Y
g_;7e7`MÕOh/2;*+P),&('*</28:3RU'Q/<L+@1*<+,HTL+.8+¢35U8+M3(HOXFHORN<),&('0'*+,)./+,He
rÊ;*+.'82105N+,<Z38+\8:3'06+f~$8+,</282RN)./+,HW!ÎåGÝ:×
7Øº×pØ
4Ù®D+.5N&('06<>/&£Â ¯ L+ V 1*<2/¢-08&C+
/2;43/P/2;*+Z/282RU696+.8>&Y/2;*+\),&('*<2/28:3RU'/>)M3'tD+lH0+,HO1*),+,H«Y8& V $n+
Ï *)«
 4fW}D010/P'*&(/@RU/<P&(D05URU6Q3/2RN&('7W{3'*H
/2;*+,<+E-08&(D05N+ V <DG+.5N&('06\8+,<-G+,)./2RUC+.5UXs/
&  ¯ 3'*HI),&c~  ¯ ea%& V -05N+./+.'*+,<<),& V +,<_Y[8& V /2;*+@-4382/2RN)f~
105o38)M3(<+EL;*+.8+9 RN<+ V -0/XeqÎåGÝ 7Ø×Ø
4Ù¦RN</2;1*<),&~¡Â ¯ ~¡),& V -05N+./+9e
Î2DåGÝ Ü × ÆDG+.5N&('06<E/& ¸` L;*+.'S82105N+,<uRU'QC&(5UC+,H38+>8:3'06+f~$8+,<2/282RN)./+,He¢g_;*&(1069;«/2;0RN<

-08&(-+.82/¡XjH0&+,<l'*&(/l3-0-+M38lLRU/2;Æ3'kR VV +,HORo3/+Yn&(8 V 105o3/2RN&('Æ&YJ/2;*+i-08&(D05N+ V W!RU/lDG+,),& V +,<l&(DO~
CRN&(1*<¢L;*+.'¦/2;*+i-08&(D05N+ V RN<l</:3/+,H¦3(<¢Yn&(5U5N&MLJ<M H0&+,<l/2;*+.8+T+fRN</Z3£<+,w1*+.'*),+i&Y698:3-0;*<ç
Ï "
¿ N * F6F6F *r¿ *¿ Q W{L;*+.8+T
Ï " ¿ N * F6F6F *r¿ £RN<l3'®D~¡H0+.82RUC93/2RN&('Æ3'*ë
H ¿ Q D RN<>/2;*+iHORN<[m&(RU'/
D
10'0RN&('t&1
Y ¿ 3'*H XJ D L W73s-08&m+,)./2RN&('«Y[8& V Éñ/ 
& ¿ 3'*Ht3s-08&2+,)./2RN&('SY8& V XJ D L /&I3F^0? ¿ G W
I \ K \ Uç
ë
è IT<21*);¦/2;43/lY[&(8Z+.C+.82Xt698:3-0ð
; ¿ ,*¯
I \qÌ±õ K 0W N0f6RTY[&(8Z+.C+.82X V 3-0-0RU'0B
6 öÊ&Y XJPN L
RU'Q/g
& ¿ m)
W ökRN<u'*&(/>3i-08&m+,)./2RN&(' :[
e u&(/2RN),+Z/2;43/E'*7
& ¿ D+fY[&(8o
+ ¿ G RU'«<21*);j3s<+,w1*+.'*),+l/282RU696+.8<
/2;*+Z),&('*<2/28:3RU'Q/s= XJON L H0&+,<E'*&(/@-08&m+,)./ERU'/g
& ¿ ¡A3'*Hy/2;43/>35Ua
5 ¿ 2W Ì PK W<:3/2RN<mY[XIRU/\=[<2RU'*),+ XJ D L
-08&2+,)./<J/& ¿ ¡AfW0/2;1*<u35U`
5 ¿ q&Y!/2;*+P<+,w1*+.'*),+>38+>),&('*<2RN</+.'Q/MÀ
e ¿ Q D +.'*<2108+,</2;43/ XJ D L -08&2+,)./<
RU'Q/&\3/_5N+M3(<2/J&('*+u698:3-0;I&Y{/2;*+u<:+,wQ1*+.'*),+9WOL;0RN):;£35U5N&MLJ</2;*+@3D&MC+uYn&(8 V 105o3/2RN&('&Y{/2;*+u-08&(D05N+ V e
%& V -05N+./+.'*+,<<JY[&(5U5N&LJ<Y[8& V /2;*+E-4382/2RN).105o38)M3(<+>&Y{'*+.6Q3/2RUC+P),&('*</28:3RU'Q/<Me
¯ 8&&YY[&(8EÎsDåÝ Ü × ÒRU'«/2;*+)M3(<+&Y8:3'06+8+,<2/282RN)./+,HS82105N+,<@RN<@<2R V RU5o38MERU'«/2;*++f~
-08+,<<2RN&('&YG/2;*+-08&(D05N+ V 3D&MC+9W/2;*+H0+.82RUC(3/2RN&('RN<{'*&ML 3 
' $t1
D l«
 4¡~¡H0+.82RUC93/2RN&('7W/2;*À
+ ¿ ),&('*<2RNH0+.8+,H
38+J&('05UXZ/2;*+J&('*+,<&(D0/:3RU'*+,Hs3ºY[/+.8q/2;*+3-0-05URN)M3/2RN&('s&Y73@82105N+_Y8& V D]W3'*B
H Nf6R $Yn&(8q+.C+.82X V 3-0-0RU'06
ö«&Y JON L RU'Q/& ¿ uRN<8+.-05o3(),+,HIDX $Yn&(8+.C+.82Xs698:3-0;I/2;43/)M3'ID+
\~¡H0+.82RUC+,HIY8& V ¿ :e
'OY[&(82/210'43/+.5UXW*8:3'06+f~$8+,<2/282RN)./+,H),&('*<2/28:3RU'/<38+E/282RN):KRN+.8J/&</21*HOXG{RU'Q/210RU/2RUC+.5UXWG),&('*<2RN<2/+.'*).X
);*+,):KRU'06I<;*&(105NH£D+,),& V ++M3(<2RN+.8u/2;43'«LRU/2;S6+.'*+.8:35h),&('*</28:3RU'Q/<MWD010/E/2;*+l8&(5N+Z&Y]RU828+,HO10'*H*3'*).X
RN<s<2/2RU5U510'*).5N+M38Meág_;*&(1069;ÊRU/iRN<i+M3(<Xk/&k);*+,):KÒ/2;43/sÎÏåÝ Ü × áLRU/2;Ê8:3'06+£8+,<2/282RN)./+,H
),&('*<2/28:3RU'/<RN<3/5N+M3(<2/\Â ¯ ~$;438Há=/28:3'*<mYn&(8 V 3/2RN&('ÒY[8& V ^Ë!g
E^Ë!gA\3'*HÆL+;43,C+F-08&C+.'
=/2;*&(1069;RU/RN<J'*&(/JRU'*).5U1*H0+,HIRU'F/2;0RN<-43-+.8BA/2;43/JRU/RN<RU'Bô ` =R$eô+9e
` AfWOL+>HORNHT'*&(/ V 3'436+P/&

æ+ö
3();0RN+.C+l3'I+f03()./),& V -05N+fRU/XF8+,<2105U/_Y[&(8/2;0RN<-08&(D05N+ V e
rt+iHORNHt'*&(/¢+.RU/2;*+.8 V 3'436+i/&3(<<2RU69'¦3I),& V -05N+fORU/¡Xj).5o3(<<PY[&(8>/2;*+\ÎÏå{÷.Ý }Ü × ¬3'*H
Îsøø:å ÷ Ý }Ü × t-08&(D05N+ V <W0/2;*&(1069;D&(/2;F-08&(D05N+ V <J/282RUCRo35U5UXTDG+.5N&('06\/&±ô  ¯ e
%& V -05N+fORU/¡X8+,<2105U/<]&(D0/:3RU'*+,H\RU'/2;0RN<!-43-+.838+<21 VV 382R M+,HRU'\/:3D05N+9e*`9e}rt+35N<&E-08+,<+.'/]RU'
x{RU6*e`Mb3 ),& V -05N+fORU/¡X V 3- E+ V -0;43(<2R ,RU'06\/2;*+E8+.5o3/2RN&('*<2;0RU-*<D+./¡L+,+.'I-08&(D05N+ V <Me Ð 'T/2;0RN<Ñ*69108+9W
RÍY9 H0+.'*&(/+,<s3«<:+./&Y@D0RN),&(5N&(8+,H 698:3-0;*<S=82105N+,<i&(8i),&('*<2/28:3RU'Q/<BAfWX ùú W øø W ÷ 8+,<-G+,)./2RUC+.5UX
H0+.'*&(/+sRU/<>8+,</282RN)./2RN&('k/&y3FÑ*'0RU/+s+fO-43'*<2RN&('k<:+./MWh8:3'06+8+,<2/282RN)./+,H¦+.5N+ V +.'/<MWq&(8¢HORN<:),&('0'*+,)./+,H
+.5N+ V +.'Q/<eå S H0+.'*&(/+,<@3i<+./u&Yq'*+.6Q3/2RUC+Z),&('*<2/28:3RU'/<MeuË5U5{-08&(D05N+ V <u8+.-08+,<+.'Q/+,Ht38+¢),& V -05N+./+
Yn&(8P/2;*+.RU8>).5o3(<<Me ç HO6+,<¢38+\HORU8+,)./+,HtY8& V DG&(/2/& V /&T/&(-7eË'j+,HO6+ZY[8& V 3T-08&(D05N+ V ¯ `/&3
-08&(D05N+ V ¯  V +M3'*<\/2;43/ ¯ `TRN<\3£-4382/2RN).105o38)M3(<+F&Y ¯ Oey&(8+,&MC+.8MWRU'Æ&(8H0+.8/2;43//2;*+ V 38+ V 3RU'*<_8+M3(H*3D05N+9W-08&(D05N+ V <_L;0RN);38+RU'Q/+.8 V +,HORo3/+ED+./¡L+,+.'F/¡L&Z-08&(D05N+ V < ¯ `@3'*H ¯ l&Y7/2;*+
<:3 V +),& V -05N+fORU/¡X«).5o3(<<MWH0&T'*&(/>3-0-+M38@RU'«/2;*+lÑ*69108+9eZg_;*+),& V -05N+fRU/X«&Y<21*):;«-08&(D05N+ V <P)M3'
D+>&(D0/:3RU'*+,HyDQX ).5o3(<:<2RÍYXRU'06 @/2;*+ V RU'/2;*+¢;0RN+.8:38);QXeEx*&(8uRU'*<2/:3'*),+9WGÎD7åGÝ Ü × kRN< V &(8+
6+.'*+.8:35G/2;43'ÎiÝ }Ü × ¦=L;0RN);sRN<&(D0/:3RU'*+,HiRÍY 
å " A3'*H V &(8+<2-+,).RÍÑ4)J/2;43'Î2 ùú D7åGÝ

@÷ ¯

´ ¶|· ¹¸º

F

	 	
	 Ä


UÄ



Ý
	
	

F


Þlß

	


	

¹ß

Ä

Ä

´µ*´ ¶|· ¹¸º

Ä
¯

=Ý

Ý


¹ß

´µ*´ ¶|· ¹¸º
@÷ ¯

K´µ*´ ¶{· ¹¸$º
Ý

§Ý

K´µ

K¶¸$º 2·Dµ*º¶

K´µ*´ ¶{· ¹¸º


K¶¸º 2·Dµ*º¶
K´µv´ ¶{· ¸$º
K´µv´ ¶{· ¸$º
¹º¶¸º A·Dµ*º¶

K¶¸º A·Dµ*º¶

ß

6ù

6ù

Mß
K´µ*´ ¶{· ¹¸$º

¬«

õ$-Wú

K´µ*´ ¶{· ¸$º



K´µv´ ¶{· ¸$º 

FÄ
Ä

¡

 úûM]ü|è9ýM.þtûMÿ=uèwu«úûMÔÔM3
øù F

û

Z^
	
Z^] 	
Z^] 	
Z
[ 
	
Z[F] 	
Z[F] 
	
Z\!] 
	
Z[\!] 
	

[



¡&
¼ ·|5 
 5 
  5 

&:; 5<2 ¸
<"2 ¸
<"2¸
&:; 5<2 ¸
<"2¸

Õ&

\

>

>

>
<2¸
<2 ¸
<2 ¸
>
&:; 5<2¸

>

ì&

>

>
>
>

>
<¸
"<2¸

[mÔ&\

[&ür\
¡¸ $¸

Õ&
>
>
>
<
 ¸
<
 ¸
<
 ¸
<
 ¸
<
 ¸

>
>
>

¼ ·5

 5 
  5
  5
  5

]"ý

[&ür\
] ý

¡¸ $¸ÿþ

>

¼ ·5
 ·5

5

>
5.&:; 5<2¸
"<2 ¸
&:; 5<2 ¸
"<2 ¸

>

¼ |· 5
·5
¼ |· 5
5 ¼ |
· 5

· 5
5

  5 
  5



[&ür\

$¸ ¡¸ÿþ ]
>
5 ·5



¼ · 5
5·5

  5 
  5



g}3D05N+\`9^1 VV 382XF&Y]%& V -05N+fRU/XIã+,<2105U/<

´µv´Ü¶{·×¸$º¬=L;0RN);t3(H0H0</2;*+><+./  ùú AfWG3'*HWG<2RU'*),+>/2;*+,<+P-08&(D05N+ V
<&ZRN<Î2DåÝ´µ*
´ Ü¶|· ×¹¸!º e

<@38+PD&(/2;£<:+ V RÍ~¡H0+,).RNH*3D05N+9W

h bSí4òÐMÎ9í4"! $Ï#;Í
z'*+RU'Q/+.8+,<2/2RU'06Z8+.5o3/2RN&('*<2;0RU-iY8& V 3's35U6&(82RU/2; V RN)uCRN+.L-G&(RU'/RN<LRU/2;s/2;*+E%^ ¯ Y[8:3 V +.L&(82Ke!ã+f~
)M35U5G/2;*+RU'0-010/_&Y{3¢),&('*<2/28:3RU'Q/J<B3/2RN<mYn3()./2RN&('s-08&(D05N+ V = PÖ A!RN<3>),&('*<2/28:3RU'/_'*+./¡L&(82KW0),& V -&9<+,H
&Y3I<+./¢&Y_C9382Ro3D05N+,<MW{<+./<>&YJ-&9<<2RUD05N+\C(35U1*+,<PY[&(8P/2;*+C(382Ro3D05N+,<T=[)M35U5N+,Ht/2;*+.RU8ZH0& V 3RU'*<BA>3'*H3
<+./&Y]),&('*</28:3RU'Q/<uDG+./L+,+.'y/2;*+PC9382Ro3D05N+,<Meg_;*+>w1*+,<2/2RN&('£RN<JL;*+./2;*+.8u/2;*+.8+PRN<E3<&(5U10/2RN&('y/&/2;*+
%^ ¯ W*R$eô+9eq3'£3(<<RU69' V +.'Q/&YhC935U1*+,</&Z/2;*+@C9382Ro3D05N+,<J/2;43/J<:3/2RN<mÑ4+,<J/2;*+P),&('*<2/28:3RU'Q/<e
g_;*+Z),&('*<2/28:3RU'/<ERU'QC&(5UC+,HSRU'«3i).5o3(<:<2RN)M35 >Ö á38+Z<2R V -05N+.8u/2;43'«&(108<MeEË)./21435U5UXW PÖ á),&(8m~
8+,<2-&('*H0</&/2;*+EÎ_Ï{Ý Ü × ß=-08&2+,)./2RN&('aA_-08&(D05N+ V e
^+.C+.8:35P310/2;*&(8<s'*&(/2RN),+,HÊ/2;*+£<2/28&('06¦+,w10RUC(35N+.'*),+yD+./¡L+,+.' PÖ È3'*H
y }Ú4Û
Û  F Ú*Û7×Ø$ =$?uRUC+.'/L&y5o3D+.5N+,Hj698:3-0;*o
< ¿È3'*H kW{RN<>/2;*+.8+T3;*& V & V &(82-0;0RN< V Y8& V ¿
/&
AfePËu<uYn38@3(<EL+ZK'*&MLPW/2;*+lÑ*8</u-43-+.8@&('S/2;0RN<@<210DOm+,)./EL_3(<=[x*+,H0+.8> ]38HOR$Wq`Mb9b ¥ Afe Ð '
=[£1069'0RN+.8MW_9Õ9Õ9ÕA),&(828+,<2-G&('*H0+.'*),+,<s38+IH0+./:3RU5N+,H¦Y[8& V
×
=$?uRUC+.'Æ/¡L&k^0?EZ
< ¿ 3'*H
RN<Z/2;*+.8+3y-08&m+,)./2RN&('ÒY8& V ¿È/&
AÅ/& PÖ @Wh3'*HÆ8+,).RU-08&)M35U5UX§=[H0+.C+.5N&(-0RU'06j/2;*+I&('*+,<
-08+,<+.'/+,HTRU'S=[£1069'0RN+.8JÁ%;*+.RU'7W`Mb9b9­A2Afeq|+./1*<_&(10/25URU'*+u/2;*+uRNH0+M3(<_&Y/2;*+u/28:3'*<mY[&(8 V 3/2RN&('TY[8& V
PÖ /&
× hW)M35U5N+,H
eÆ%&('*<RNH0+.8i3S),&('*<2/28:3RU'Q/i'*+./¡L&(82K
e
RN</28:3'*<mYn&(8 V +,H
æ
RU'Q/&£/¡L&y^0?E<¿ 3'*H
3(<@Yn&(5U5N&MLJ<Mæ e ¿ /28:3'*<25o3/+,<¢/2;*+Ff[f0,[l&Y >æ +M3():;k
),&('*),+.-0/l'*&H0+RN<
6+.'*+.82RN)T3'*H),&(828+,<2-&('*H0<l/&y3IC(382Ro3D05N+T3'*Hk+M3();k8+.5o3/2RN&('k'*&H0+s),&(82æ 8+,<2-G&('*H0<¢/&S3I),&('*<2/28:3RU'/

nû {þ

´µ*´ ¶|· ¹¸º

¸ ¸ ¸$Í
§Þ

û {þ þÍv¸$ÎGµ*¶{· ¹¸$º


Ä.

û {þ

 Þ ±û {þ

$û {þ
û {þ ¬»7üÿ{µ*»
»9µ*´ T{Í ü

½
þ@Í|¸ÎGµ*¶{· ¸$º

=RU/<[Ì¡/2;t'*+.RU69;QD&(8>RN<>/2;*+\),&('*),+.-0/>'*&H0+\),&(828+,<2-&('*HORU'06/&F/2;*+oÌ$/2;jC9382Ro3D05N+\&Y/2;*+\),&('*<2/28:3RU'/BAfe
8+.-08+,<+.'Q/</2;*+(*f[2(paQ	 <q*[[[(*fh/2;*+.8+PRN<&('*+@RU'*HORUCRNHO1435{),&('*),+.-0/'*&H0+uY[&(8+M3();C935U1*+
&Y_3sC9382Ro3D05N+\H0& V 3RU'7W{3'*H«&('*+Z8+.5o3/2RN&('t'*&H0+lYn&(8P+M3();j/210-05N+&Y_),& V -43/2RUD05N+C935U1*+,<MeZã&(1069;05UX
<:3RNHWG/2;*+.8+lRN<P3<:&(5U10/2RN&('y/&
RÍY]/2;*+.8+lRN<@3 V 3-0-0RU'06iY[8& V C(382Ro3D05N+,<\=[),&('*),+.-0/E'*&H0+,<@&Ñ
Y ¿PA/&
æ
C935U1*+,<i=[),&('*),+.-0/>'*&H0+,<>&Y «Au/2;43/¢<:3/2RN<2Ñ4+,<@/2;*+),&('*<2/28:3RU'/<s= V 3-*<>8+.5o3/2RN&('j'*&H0+,<>&YH¿à&('/&
8+.5o3/2RN&('k'*&H0+,<¢&Y «AfW0 5W 5T3F-08&2+,)./2RN&('tY[8& V ¿à/& keig_;*+i<:3 V +\8+,<105U/P;43(<>D+,+.'3():;0RN+.C+,H
RU'*H0+.-+.'*H0+.'Q/25UXFRU'I/2;*+@Ë_/2/282RUD010/+,HS?u8:3-0;y?u8:3 VV 38Yn&(8 V 35URN< V DXFãJ1*H0&(5ÍYJ=m`Mb9b9cAfe





0

û {þ

¶¸$º 2·Dµ*º¶

z'*+\),&(105NH35N<&F<+,+ PÖ 3(<¢3s-4382/2RN).105o38¢)M3(<+&Y_ÎÏåÝ 7Ø×Ø
*Ù>RU'*H0+,+,HW/2;*+.8+RN<>3
-08&2+,)./2RN&('Y[8& V 3s^0?Ç¿ÅRU'Q/&T3i^0?
RÍY]3'*H&('05UXFRÍY
<:3/2RN<mÑ4+,</2;*+>-&9<2RU/2RUC+¢),&('*<2/28:3RU'Q/uLRU/2;
3'+ V -0/Xs/282RU696+.8u3'*H¾¿3(<RU/<&(D05URU6Q3/2RN&('7e



2

õ$-

»

3M¼¾½øuM%

Z[\%]41A2*/

3 014%&657*/1,8%9

Z[F]  C*=>A2&

Z[F] ý 41A2*/

2>:(+* ;<*/1,81%9
Z[F] ý B*/>A2&

Z[EDGFH4\!]41A2*/ :(+*-;<*=1,81%9
Z[41A2*/

Z J [\ L DGFH ]41A2*=

;<*=1,81%9

Z[ED9FH4] ý C*/>A2&
$ %'&)(+*-,%.*/0,01.2&

·

Z[ID9FHJ41A2*/

Z[  \ c ]41A2*/

 

·

  ·
Z[  ]41A2*/
Z8^]41A2*=
Z8^] B*/>A2&

Z[  \¤#] 41A2*/
Z\ c ] ý 41A2*/

? 

·

 

·

? 

 

Z[ \  ]  41A2*/

·

2; $

Z[  ]C*/CA2&

Z[  ]ýK41A2*/

Z8^] C*/CA2&
2@ $

Z[  ] ý B*/>A2&

; $

Z^] ý 41A2*=
Z[  41A2*/
Z8^
41A2*=

Z^] ý B*/>A2&

x{RU69108+\`MbO%& V -05N+fORU/¡XFã+,<2105U/<q3\?E+,&(698:3-0;QX

A®

õº÷

@ $

 úûM]ü|è9ýM.þtûMÿ=uèwu«úûMÔÔM3
øù F

u&MLPWRU'ß&(8H0+.8T/&H0+M35uLRU/2;ÊRU'*),& V -05N+./+SK'*&L5N+,HO6+yxa38269RN+.8T+./F35$eE=m`Mb9b9­AMLT+f/+.'*Hß/2;*+
% ^ ¯ Y8:3 V +.L&(82K /& V RÍO+,H~%^ ¯ e Ð '¬3 V RÍ0+,H~%^ ¯ /2;*+£<:+./i&YPC9382Ro3D05N+,<iRN<sH0+,),& V -&9<+,H RU'/&

),&('Q/28&(5U5o3D05N+T3'*HS10'*),&('Q/28&(5U5o3D05N+iC9382Ro3D05N+,<MW<:3MXÃÀ 3'*HôFeZg_;*+s|¦ÞNPOX>ÝfÖî,uRQTSGU)VTWX1Y[Z)\9]+\

^`_ X1a _ X1S6ZbVTcedfZS9ghYPcji+XkKlJm`nKopc\rqU)ds\9c\9aGX1dta2u ^`_ cq _ q2ZdvVX6SGXw>U)S9YyxTWZaGXkzZ)\`w>U)WeWU ^ \2{|c\}cea~a9S9xsX
a _ ZayX1X1S9gz\GU)WexTa9cU)daGUha _ X\9xTVTdsX1a ^ U)S9]cedsk+xsqXkVtgÉôq2ZdVXPXiKaGX1dskTXkaGUZM\GU)WexTa9cU)dUwa _ X
^`_ U)WXdsX1a ^ U)S9] IrlJnKc\`\ _ U ^ daGUVX6lBqU)YPQTWX1aGX
I _ c\`SGX\9xTWea`QTSGUckTX\~xs\}ZdsU)a _ X1S
QTSGUKUwUw`  lBqU)YPQTWX1aGX1dsX\G\yw>U)S6|lBqU)ds\9c\9aGX1dsq1gdskTXXkuZdgzYPcji+XkKlJm`nKoq2ZdVXba9S Zds\9WZaGXk
cedtaGU¡Zdceds\9a ZdsqXzUwy¢£ ¤¥¦¢§¨'§©ªs¦¢¤f«E­¬\9cedT®¯a _ X°²±)³[SGXk+xsq1a9cU)d´kTX\Gq1S9ceVXkZVU2X
u}a _ X
YPcjiTXkKlJm`nKoµc\YZQTQXk¶aGU¡nT·\h¸[Zdskº¹»¸¼c\½a _ X1dpQTSGUckTXk ^ cea _ a ^ U»qU)WU)SG\u`®
cecedT®¡Z
QU
\9cea9ceXIqU)ds\9a9S Zceda<°Pu ^`_ U
\GX<a9S9ce®
®X1Sc\¢a _ XI\9xTVT®
S ZQ _ qU)S9SGX\9QU)dsk+cedT®}aGU~a _ X\9xTVTdsX1a ^ U)S9]²cedsk+xsqXk
Vtg»¾h _ X½YPcji+XkKlJm`nKo¿c\bqU)ds\9c\9aGX1daÀcjwrZdsk»U)dTWegcjw}¹Á\ Za9c\9ÂfX\b°ÃvÄ7ce®sÆÅ
ÇvceWeWexs\9a9S ZaGX\a _ c\
a9S Zds\w>U)S9YZa9cU)d¢E _ X6qU)ds\9a9S Zceda}dsX1a ^ U)S9]Mc\~qU)YPQU
\GXkhUw7a _ Xa ^ UP
ZS9cZVTWX²\GX1aG\ÈÊÉÌË2ÍÎ2Ï`Í Ð
Zdsk¾ÑÉÒËÓ Î Ï½Ó  Ð Zdskºa _ SGXXÆqU)ds\9a9S ZcedaG\v° Î u}°  ZdskÔ°|Õ"Í Î Zdsk¶Í  _ ZX\ ZYÃXkTU)YZced
ËtÖ)Ïy±KÏy× Ð ZdskzÓ>ÎyZdskÓ  _ Z2XP\ ZYÃXbkTU)YZced¡ËØÙÏyÚ Ð  _ XPqU)ds\9a9S Zceda²kTXÂsdTcea9cU)ds\ÀZSGXb®
ceX1dced
a _ XÂs®
xTSGX
IrWeW¢qU)dsqX1QTa}agQX\}ZSGX6\9xTQTQU
\GXkhaGUbVXcedsqU)YPQfZS ZVTWX


 Þ

ê ë

êÜ

ÛÜ¶ÛeÝ

ÛÜßÞ+ÜßÞÝ

b a
a b

b 2 2
b 1 3
a 1 1

à>á
êë

ê7Ý
ÛÝ

Þ Ý

1

ê Ý
ê Ý

1

àCç

2

2

1

ê1 ë


ê 2ë
âãäGæ

2

1
1
2

ê<Ü

3

âèéä

âèéä Î

3
1

1
1

ê<Ü

2

êÜ

2
2

1

ê7Ý

3

2

à>á



2
3

âè ä Õ

âãKäGå

a 2
b 1

êÜ

àCç
H

C

Äce®
xTSGXÀÅ
Ç+{¢S Zds\w>U)S9YZa9cU)dvwSGU)YìBIrlJnKÔaGUb|£ ¤¥¦¢§¨'§©ªs¦¢¤f«
í X1ayxs\6SGX1WZaGXÃU)xTS²kTXÂsdTcea9cU)ds\²aGUvU)a _ X1S²kTXÂsdTcea9cU)ds\ÀUwqU)ds\9a9S ZcedtaG\ywU)xTdskzceda _ Xîm`·RWeceaGX1S Zl
a9xTSGX
éïrxTS~qU)ds\9a9S ZcedaG\yðWX1a`xs\`q2ZWeWa _ X1YñnT·rlBqU)ds\9a9S ZcedaG\ò`ZSGX²ZÀQfZS9a9cq1xTWZS}q2Z)\GX6Uw7a _ XYPcedTceYZW
kTX\Gq1S9ceQTa9ceXqU)ds\9a9S ZcedtaG\kTXÂsdsXkvced»ðceVTcXÀX1aZWCeuó2ô
ô
õò{`ZbYPcedTceYZW<kTX\Gq1S9ceQTa9ceXqU)ds\9a9S Zcedtaq2Zd
VX~\GXX1d½Z)\|Z6\GX1aEUwnT·rlBqU)ds\9a9S ZcedaG\ ^ cea _ a _ X~\ ZYÃX}a9S9ce®
®X1S2ötceaG\Ecedta9xTcea9ceX\GX1YZdta9cq\éc\<÷Bcjwø _ U)WkT\
\GUÀYyxs\9a~ù Î U)Sù  U)S6eeùú2û ÌnT·\ Za9c\ÂfX\`ZÀYPcedTceYZW¢kTX\Gq1S9ceQTa9ceXqU)ds\9a9S Zceda`cjwcea\ Za9c\ÂfX\~Za
WX2Z)\9a|U)dsXrX1WX1YÃX1daUw¢a _ X\GX1a2<üU)aGX~a _ Za|a _ X`÷k+c\ýxTdsq1a9cU)d+ûrkTUKX\IdsU)a|cedsq1SGX2Z)\GXra _ XrqU)YPQTWXi+ceaBgUw
a _ XqU)ds\9c\9aGX1dsq1gbq _ Xq ]ÀSGX1WZa9ceXaGU²nT·rlBqU)ds\9a9S ZcedaG\2 _ XQTSGUKUwÙUwÙa _ XU)SGX1Y­õbðqU)YPQTWXi+ceaBgPUwf|
£ ¤¥¦¢§¨'§©ªs¦¢¤f«7òrq2ZdÆVX6xs\GXkvaGU\ _ U ^ a _ ZaqU)ds\9c\9aGX1dsq1gUwYPcedTceYZW<kTX\Gq1S9ceQTa9ceXÀqU)ds\Ga9S ZcedtaG\c\
ZW\GUÀr lBqU)YPQTWX1aGX
IceVTcXX1aZWCðó2ô
ô
õò _ Z2X}QU)cedtaGXkMU)xTaéa _ ZaéYPcedTceYZWkTX\Gq1S9ceQTa9ceXqU)ds\9a9S ZcedaG\
®X1dsX1S ZWeceþ2XîYÃU
\9abqU)ds\9a9S ZcedtaG\w>U)xTdskced»a _ Xhm`·ìWeceaGX1S Za9xTSGX
z`q1a9xfZWeWegua _ X\ XWZa9aGX1SPqU)ds\9a9S ZcedaG\
ZSGXyZW\GUbQfZS9a9cq1xTWZSq2Z)\GX\}UwEnT·rlBqU)ds\9a9S ZcedaG\ð'w>U)S`ceds\9a ZdsqX
uZ)\}ZWeSGX2Z)k+gMdsU)a9cqXkusa _ X6aGU)QU)WU)®
cq2ZW
qU)ds\9a9S ZcedaG\`xs\GXkîVtgîvcedsX2Zxÿvc\ \ Z)U)xTcCuó2ô

ô ÀZSGX6k+c\ qU)dTdsXq1aGXkvnT·rlBqU)ds\9a9S ZcedtaG\ò í X1axs\`Z)kTk
a _ Za2u7ceda _ X\GXMm`· ^ U)S9]K\u7qU)ds\Ga9S ZcedtaG\PZSGXÃxs\GXkaGUvq _ XqG]qU)ds\9c\GaGX1dsq1gUwrnT·\y\GU)WX1WegZdskdsU)a


		!#"%$&	'(")!*'+*
,-.

/1032547698;:=<>25?@A4B

UwéS9cq _ X1S6]dsU ^ WXk+®XbVfZ)\GX\6qU)YPQU
\GXkzUwéS9xTWX\Ãð>Z)\cedzDCÃòZdska _ X1gZSGXbdsU)acedtaGX1®
S ZaGXkcedaGU
YÃU)SGX²qU)YPQTWXihSGX2Z)\GU)dTcedT®\ð>Z)\`cedDE¢zU)S`cedFCGEò
 _ X1SGX\ _ U)xTWkºVXU)a _ X1SMqU)dTdsXq1a9cU)ds\ ^ cea _º^ U)S9]K\hZVU)xTaX1S9cjÂfq2Za9cU)dÔUw6]dsU ^ WXk+®XVfZ)\GX\
qU)YPQU
\GXkßUw6WU)®
cq2ZW}S9xTWX\ð'wU)SÃceds\Ga Zdsq=
X HrU)S9dºS9xTWX\òu|dfZYÃX1Weg ^ cea _ a _ X ^ U)S9]K\½Uw í X1g¡Zdsk
I U)xs\ \GX1aðó2ô
7ô Jòusced ^`_ cq _ qU)ds\9a9S ZcedtaG\rZSGX}·6\ua _ xs\ _ ZXa _ X\ ZYÃXrw>U)S9Yµa _ ZdMU)xTSG\u+VTxTa ^ X
k+ckhdsU)aÂsdskk+ceSGXq1a}SGX1WZa9cU)ds\ _ ceQs\}VX1a ^ XX1dva _ X1ceS`wS ZYÃX ^ U)S9]ZdskU)xTSG\
\MVU)a _ YÃUKkTX1W\ZSGXzSGUU)aGXkcedÔ\GX1YZda9cqdsX1a ^ U)S9]K\uqU)YPQfZS9cedT®ºqU)dsqX1QTa9xfZW²®
S ZQ _ \Zdsk
kTX\Gq1S9ceQTa9cU)ds\bWU)®
cq\bc\PZvQTSGU)VTWX1Y a _ Za _ Z)\PUwaGX1d VXX1d¯c\G\9xsXkL
 K`Z
Z)kTX1S2uIU)WeceaGU)S2u<Zdsk¯U)VTcX\
ðó2ô
ô
ôò _ Z2XÃckTX1da9cjÂfXk ZîwS Z®
YÃX1dtaUwa _ XÃ|pYÃUKkTX1Wrð ^`_ X1SGX\9ceYPQTWXÃ®
S ZQ _ \ZSGXPSGX\Ga9S9cq1aGXkaGU
a _ U
\GX _ ZKcedT®bZ²a9SGXXlCWece]X\9a9S9xsq1a9xTSGX
uKVTxTa|qU)d)ýxTdsq1a9ceX}agQX\`ZSGXrZWeWU ^ Xkfò ^ cea _ Z6WZdT®
xfZ®Xq2ZWeWXk
Î
E&M
NDCPO {a _ c\RX QxTce)ZWX1dsqX _ Z)\WXk²aGUZ`dsX ^ a9S Z)q1a ZVTceWeceaBgySGX\GxTWeacedÀkTX\ q1S9ceQTa9cU)dWU)®
cq\

 HU ^ X1X1S2u
a9S9gKcedT®}aGU`ckTX1da9cjwg²WZS9®X1SwS Z®
YÃX1daG\\ XX1YÃ\aGU`VXEZ}kTX2Z)kKlBX1dsk{Z)\¢QU)cedtaGXkU)xTaVg²vxT®
dTcX1Sð>Å
Ç
Ç
Çòu
QTSGUý9Xq1a9cU)d q2ZdTdsU)a _ Zdsk+WXÃdsX1®tZa9cU)d»U)dQTS9ceYPcea9ceXaBgKQX\½ïrda _ XU)a _ X1S _ ZdskuX1X1d a _ XPYÃU
\9a
Xi+QTSGX\G\9ceXkTX\Gq1S9ceQTa9cU)dhWU)®
cq\`q2ZdTdsU)a`XiKQTSGX\ \éa _ X ^`_ U)WX6Äï F
ô Jò
í ST Ï UVEwS Z®
YÃX1dtayð KU)S9®
cksZ+uó2ô
7
dsqUKk+cedT®\GU)YÃXhXi+c\9a9cedT®kTX\Gq1S9ceQTa9cU)dßWU)®
cq\ÃcedtaGUYÃUKkTX1W\ÃUwa _ XM|"w>ZYPceWeg»c\ÃZd¡cedtaGX1SGX\Ga9cedT®
QX1SG\9QXq1a9ceX
uKa _ Za~qU)xTWkhZWeWU ^ U)dsXaGUckTX1dta9cjwgîdsX ^ kTXq1cksZVTWX6q1WZ)\ \GX\|wU)SU)xTSYÃUkTX1W\usZ)kTk½agQX
Xi+QTSGX\G\9ceX1dsX\G\`aGUqU)dsqX1QTa9xfZW®
S ZQ _ \2usZdskhYZ2gMVX6q1g+q1WX\`ceda _ X6kTX\Gq1S9ceQTa9cU)dUw< í \}qU)dsqX1QTaG\2

WYX[Z]\
^D_3`baFcd\&^
e X _ ZXÃQTSGU)QU
\GXk Z½w>ZYPceWegzUwéYÃUKkTX1W\6a _ Zayq2ZdVXP\GXX1dZ)\a _ XPVfZ)\9c\6Uw~Zî®X1dsX1S9cqPYÃUKkTX1WecedT®

wS ZYÃX ^ U)S9]6ZcedÆwX2Za9xTSGX\6Uwéa _ c\}wS ZYÃX ^ U)S9]zZSGXa _ X²w>U)WeWU ^ cedT®s{Zq1WX2ZS6k+c\9a9cedsq1a9cU)dzVX1a ^ XX1d
k+)c fX1SGX1dta6]KcedskT\6UwE]dsU ^ WXk+®X
u¢a _ ZaÂsa ^ X1WeW ^ cea _ ceda9xTcea9ceXÃq2ZaGX1®U)S9cX\2uZ½xTdTcjw>U)S9Y ®
S ZQ _ lCVfZ)\ Xk
WZdT®
xfZ®Xba _ Za]XX1Qs\6X\G\GX1dta9cZW<QTSGU)QX1S9a9cX\UwEa _ XÃnT· YÃUKkTX1WCudfZYÃX1WegvSGX2Z)ksZVTceWeceagUwéU)V+ý9Xq1aG\6Z)\
^ X1WeWIZ)\rSGX2Z)\GU)dTcedT®\2 e XÀ®
xsX\G\a _ c\}WZa9aGX1SQU)cedtac\}QfZS9a9cq1xTWZS9WegÆceYPQU)S9a ZdawU)Sra _ Xxs\ ZVTceWeceaBgvUw
Zdtg]KdsU ^ WXk+®X½VfZ)\GXk \9gK\GaGX1Yîd U)xTSywS ZYÃX ^ U)S9]uZWeWé]cedskT\ÀUw~]dsU ^ WXk+®XîZSGX®
S ZQ _ \ÀX2Z)\9ceWeg
cedtaGX1S9QTSGX1aGXkuéZdskSGX2Z)\GU)dTcedT®\q2ZdVXP®
S ZQ _ cq2ZWeWegSGX1QTSGX\GX1daGXk»ced ZhdfZa9xTS ZW|YZdTdsX1SÀxs\GcedT®a _ X
®
S ZQ _ \~a _ X1YÃ\ X1WeX\2uTa _ xs\rXiKQTWZcedsXkaGUPa _ Xxs\GX1S}U)dhceaG\~U ^ dvYÃUKkTX1WeceþZa9cU)d¢
Xq _ dTcq2ZWqU)dta9S9ceVTxTa9cU)ds\2u ^  S2 a2<QTSGX1KcU)xs\ ^ U)S9]+\EU)dÃqU)dsqX1QTa9xfZW®
S ZQ _ \2uq2ZdÃVX`\GxTYPYZS9ceþ2Xk
Z)\w>U)WeWU ^ \2{

g a _ XéSGX1QTSGX\GX1da Za9cU)dÃUwÙk+c)fX1SGX1da<]cedskT\7Uws]dsU ^ WXk+®X~Z)\qU)WU)SGXkÃnT·\{w>Z)q1aG\uced+w>X1SGX1dsqX|S9xTWX\2u
X1U)WexTa9cU)dÆS9xTWX\}ZdskqU)ds\9a9S ZcedaG\2

g a _ XcedaGX1®
S Za9cU)dvUwqU)ds\9a9S ZcedaG\cedtaGUÃZySGX2Z)\GU)dTcedT®PYÃUkTX1WCöKYÃU)SGXU)SWX\G\\9ceYPceWZSdsU)a9cU)ds\`Uw7Z

qU)ds\Ga9S Zcedta _ )
Z kzZWeSGX2Z)k+gVXX1dcedta9SGUKk+xsqXkVTxTa ^ X1SGXbU)dTWegxs\GXkÆaGU½q _ XqG]vqU)ds\9c\GaGX1dsq1gvUw|Z
\GceYPQTWX®
S ZQ _ >ð Z)\cedha _ X|zYÃUkTX1W'òI _ X6qU)YPQTWXi+ceaBghUw<qU)ds\9c\9aGX1dsq1gMq _ XqG]KcedT® ^ Z)\`dsU)a
]KdsU ^ d¢

X U)VTa ZcedsXkwCZYPceWegzUwéYÃUKkTX1W\ ^ cea _ î
Z qU)YPQTWXiKceagzq1WZ)\ \9cjÂfq2Za9cU)d
g ZM\GgK\9aGX1YZa9cqb\9a9xsk+gzUwéa _ P
UwEZ)\G\ Uq1cZaGXkqU)ds\Gc\9aGX1dsq1g3hkTXk+xsq1a9cU)dQTSGU)VTWX1YÃ\2ufcedsq1Wexsk+cedT®½a _ ²
X \Ga9xsk+gMUwQfZS9a9cq1xTWZSq2Z)\GX\
Uw<S9xTWX\rZdskhqU)ds\Ga9S ZcedtaG\2u ^`_ cq _ QTSGUckTX²cedtaGX1SGX\9a9cedT®îqU)YPQTWXiKceaghSGX\9xTWeaG\2

e XyZW\ UPX\9a ZVTWec\ _ XkMWecedT]+\`VX1a ^ XX1dqU)ds\9c\9aGX1dsq1gMq _ X qG]KcedT®îZdskvÄï í kTXk+xsq1a9cU)d¢ufa9S Zds\9WZa9cedT®
a _ XIqU)ds\9c\GaGX1dsq1g3
h kTXk+xsq1a9cU)dQTSGU)VTWX1YÃ\¢ced²aGX1S9YÃ\Uw+Äï í kTX k+xsq1a9cU)d¢<Ba¢\ _ )U xTWk6VX<dsU)a9cqXk²a _ Za¢a _ X
U)QX1S Za9cU)dfZW7\GX1YZda9cq\rUwYÃUKkTX1W\}qU)YÀVTcedTcedT®½S9xTWX\ZdskvqU)ds\9a9S ZcedaG\2ufdfZYÃX1WeghFCG
E uTFCÃZdsk
D¢
E <u+c\`X2Z)\9g½aGUbxTdskTX1SG\9a ZdskhVTxTa ^ X ^ X1SGX6dsU)a}ZVTWXaGU®
ceX²Z®
WU)VfZW¢WU)®
cq2ZW¢\GX1YZda9cq\2IdskTXXku
,-i

jlk4Pm1n5oDprq47s5@)6utvn5wyx1<>q4rz{0>?>|}m1n5?>z~6B05@A?36z

a _ X1SGXc\IZdPxTdskTX1S9WegKcedT®²dsU)dPYÃU)dsU)aGU)dTcq`YÃXq _ ZdTc\GY ^`_ U
\GXWU)®
cq2ZWscedaGX1S9QTSGX1a Za9cU)d½\ _ )
U xTWkbSGXRQxTceSGX
d U)dz\9a ZdsksZSGkWU)®
cq\2r _ XykTXÂsdTcea9cU)dUwEZÃWU)®
cq2ZW<\GX1YZda9cq\}w>U)S}a _ X\ X²YÃUKkTX1W\}c\ra _ s
s
x \ZdU)QX1d
QTSGU)VTWX1Y

 _r^#\5`>D&>^
cuX
e XZSGXMcedskTX1VTaGXkßaGUÆcq _ X1Wm _ X1ced¶Zdskº·X1dsX1Kc1XvnceYÃU)dsX1aPwU)SPa
X2ZS9WecX1S6X1SG\9cU)dUwEa _ c\ ^ U)S9]Zdsk _ X1WeQ+wxTWqU)YPYÃX1daG\2 e XbZW\GU ^ c\ _
Q xTc\2uTZ)\ ^ X1WeW¢Z)\|ZdsU)dgYÃU)xs\SGXw>X1SGXX\2uw>U)Séa _
I U)xs\ \GX1a|ZdskîocX1S9SGXZS

_ 1X ceS½q2ZSGXwxTW`SGX2Z)k+cedT®Uw²Zd
aGUa _ ZdT]ZS9cXlJm _ S9c\Ga9cedsX
X1ceS|cedtaGX1SGX\9a9cedT®Ã\GxT®
®X\9a9cU)ds\

Zdsk\GU)YÃX6qU)S9SGXq1a9cU)ds\

 *>^F_>c
rVTceaGX1VU)xTWCuÙneu>H}xTWeWCu I eusÿrcZdx¢ub¢ðó2ô
ô7òF5 {¡¢7u£ 'R¤E`kTk+c\ U)d+l e

X\9WX1g

K`Z
Z)kTX1S2uÄeuÆU)WeceaGU)S2u I euÿµU)VTcX\2unIðó2ô
ô
ôòÀS Z)q1a ZVTWX½ZdskXq1cksZVTWXPÄsS Z®
YÃX1dtaG\yUw~m|U)d+l
qX1QTa9xfZW7·S ZQ _ \2Id¥1¦*¨§¨©*{ª«l«
¬®­ ¯¯°
±
²³ª¢´µ·¶5)
¸ usQTQ¢3t
¹ õ
Ç¨ºrt
¹ ô7+
» ÙnQTS9cedT®X1S2
K`Z®X1a2u½¼s lBÄeu¼·X1dsX\9a2u

 eu ÿ
b
ÆxT®
dTcX1S2u   l í  ðó2ô
ô
ôò
¾dsU ^ WXk+®X `qRQxTc\9cea9cU)d
Z
oxTSGX
·S ZQ _ lbK`Z)\GXk
¾dsU ^ WXk+®X I X1QTSGX\GX1da Za9cU)d UkTX1W¿º rQTQTWecq2Za9cU)d
^ cea _
aGU
a _ X
nc\9gKQ _ xs\9lB mZ)\GX
na9xsk+g
d
¥®¦*À§©Á*ÃÂÄ³ÅÆ­ ¯¯
Z2)ZceWZVTWX
Za
Z È9g-q2
Z h'¾ynK* h'¾6 e h'¾6 e ô
ôhÇfZ'ÇX·ÈG\ _ a9Y
_ a9a Ç¢{h7h\GX·È9d¢ xsq2ZWe®t'

K`Z®X1a2u(¼s lBÄeuÿ ÆxT®
dTcX·È2u» l í ð>Å
Ç
Ç+óòy _ Xb|ºÄZYPceWeg{<i+aGX1ds\9cÉ)ds\Éw`nceYyÇTWXm1É)dsqX·ÇTa9xfZW
·Ê È Z'Ç _ \IBd¥®¦*À§©*{ªË5«³{ª3­ ¸r´)uÇ3Ç¢sÅ
Ç7¨ºKÅ+ó2Ç+
K`Z®X1a2u(¼s lBÄIð>Å
Ç
Ç+óòÌ¤bÍ5¦ÎR¤5b¤¦]r¤Ï§>5Ð~·75§~¤]¤·l¦ Ð·>¤¦ÏÑ'¤ §Òr¤ÔÓrÕÍ3¤·¦Ö¦ Í>Ó3¤R×lu¤
Ç X1WeWecX·È
Ø ¢Í5¦ *ÙR¤§R7ÛÚ Ø PuÎ¦ÜÑ7LRr§>¦ Ü>b¤ }o _ -bsa _ X\9c\2uÙ¬}dTceX·GÈ \GceaBg9É wEÝ)É dta 
G

K®ÉÈ9®
cksZ+uÙðó2ô
ô7Jò7ïrda _ X{ÈGX1WZa9ceXrXiÇ3ÈGX\G\9ceX1dsX\G\1ÉwkTX\Gq·È9cAÇTa9cÉ)dîWÉ)®
cq\|Zdsk]Ç3ÈGXk+cq2ZaGXrWÉ)®
cq\2
³{¦· Þ1§· Ø ª>b¤ ØÜØ AÖr¤5§¤¢Ë¦5 Ø ußàtu>»77»¨º»7JK
K®É
\2umeu5K®É)aá·âAâäã+u(KeuÿåDãd _ Rá á1® _ á
uo7<ðó2ô
ô
ò6ÝÉKk3á·âecedT®ÒãdskncAæyx3âäãa9cedT®=Hrx3æGãd}K®á _ ãKcÉÈç
Ç a9x>ã'
â ·ÊÈ~ã'Ç _ 2ç Id¥1¦ À§¨© {ª«l«
¬®­ ¯>é·°±
²³{ª¢´'àuêé2u3Ç3Ç¢sÅ¨ºKÅ
õ
ô+nuÇ3È9cedT®á·È2
è cea _ m1)É dsqRá·T
m _ ãdskÈ~ã+u(¾PeuÿµÝá·È âeced¢u¢o7¢ Iðó2ô7
òMï{ÇTa9cAæGã'âIcAæyÇ3âá·æÏá1dta~ãa9cÉ)dëÉ)dqRÉ)d)ýxTdsq1a9ceáGQxá·È9cáRç
ceP
d Èá·âäãa9c É)>
d ã'â
k ã~a ãyì>ãçáRç2<Bd¥®¦*À§©³«
íî¬ª'ïD³«ñðv¬>Õò{Í(©óLÜÓ¤[ð&Ó¤ ¦Õ[*Ï«ò{Í5ÜuÖ
u
Ç3Ç¢5
 7ÀºKô
Ç+
m _ á1ced¢u»eu7ÿ

ÆxT®
dTcá·2È u  l í `ðó2ô
ô
Åò¯m1É)dsqRá·ÇTa9x>ã'âr·ÊÈ~ã'Ç _ ç2{<Ä7xTdskã'æÏá1dta~ã'ârüÊÉ)a9cÉ)dç2ôÌ¤·ÑÀ3¤
&­ ª>b¤ ØÜØ )Ör¤·5§~¤Ä³Ä¦· Þ1§·¤ ØÐØ ¤1u
µðÜ¹òu>»7J7¨ºr¹tÇ7J+

m _ á1ced¢uf»eufÆxT®
dTcá·È2uf» l í euÿ­ncAæÏÉ)dá1a2u·Pðó2ô
ô
õò`ü{áRçGaákÆ·ÊÈ~ã'Ç _ ç2{Ù ·ÄÈ~ã'Ç _ lì>ãçák9¾dÉ è âjl
ák+® á I á·Ç3ÈáRçá1dt~a ãa9c É)dpÉKk3á·â è cea _ Äï í ná·æGãdta9cqRç2¶Bdõ¥1¦ À§¨©*GÂÊÌ9­ ¯ßtuYÇ3Ç¢D
Å'¹'º7»'¹s
 ÉÈ9r
Ý
® ã9
d ¾ãx+w æGãdTd¢
m1É)®
cç2ufïeufÿ ·xTced>ã'âk3ÉTuÙï¢ðó2ô
ô7òöâecedáÀã'Èrk3áRçGq·È9cAÇTaÉÈ`wÉÈqRÉ)dsqRá·ÇTa9x>ã'â®7È~ã'Ç _ çãdsk9ãq·âäãççwÉÈ
Ç÷Éâeg
d ÉæPcäã'âcçÉæÏÉÈ Ç _ cçæ aáRç9a2d=¥1¦*¨§¨©Y*ª«l«
¬®­ ¯rê'°÷±
²³ªÊ¯uêR¶suÇ3Ç¢TÅ7J7»¨ºKÅ7KfnuÇ3È9cedT®á·È2
m1É)x3âÉ)dskÈá
uKneuÿ"nã'âeãa2ut~Ùðó2ô
ô
õòocáqRá I áRçÉâexTa9cÉ)d¢{lÉ è ã'ÈGk3ç í ã'È9®á·ÈéoDá·Èç Çáq1a9ceáRçÙd[¥1¦ À§¨©
*{ª«l«
¬l­ ¯ß7°±
²³ªÔ´·¶>ê7øt3
u Ç3Ç¢¨ó )ô¨ºÙó2ô7»+nuÇ3È9cedT®á·È2

,-¨ù

/1032547698;:=<>25?@A4B

cAìTcá
ul¼seuñHÄãá·æyæÏá·È âú
urïeu~ÿ í É)cçáÀãx¢urn²ðó2ô
ô
õòµ ná·æGãdta9cqvûã'âeckãa9cÉ)döÉwÃm1É)dsqRá·ÇTa9x>ã'â
· È~ã'Ç _ çIB
Ê
d ¥®¦*À§©*{ª«l«
¬®­ ¯ß°&±&²{³ª¢´R¶>ê7øu3Ç3Ç¢sõ
Ç¨ºKô7»+nuÇ3È9cedT®á·È2
Ä>ã'È9®
cá·È2uHeu í ãdT®su¼feu¢ÿìnKq _ cáiu¢6Iðó2ô
ô7Jòbvcji3ákqRÉ)dç9a È~ãcedtaÔç~ãa9cçwã)q1a9cÉ)d¢{ã½wÜÈ~ã'æÏá è ÉÈ üÆwÉÈ
k áq1c ç9c É)d9Ç3ÈÉì3âá·æÏç~xTdsk3á·È~cedsqRÉæyÇ3âá1aá¢üdÉ è âák+®á
Ed¥1¦*¨§¨©#*{³{³³{ª3­ ¯uµ
uÇ3Ç¢ó¨¨ºÙó2õ
Ç+
3
Äák3á·È2u<6eu<ÿýDã'ÈGk+cCu<»éðó2ô
ô7»òzÉ)dÉ)aÉ)dáîÝÉ)d>ã)k+cqhnKüoþãdsk¯m1É)dçGa È~ãcedta½nãa9cçwã)q1a9cÉ)d¢Æd
¥1¦ À§~¤~¤ ÜuÖ'Ï*ÜÓ¤¢àuê7ÜÓG³«
íÿ¬ðû«<
u Ç3Ç¢
 J+ó2¨Å ºJ
Å
Å+
·ÄááRç2uhbð>Å
Ç
Ç
Çò

b¤3ÿ7 òÏÀ
 	 Ø ¤år¤ Ö7¦*Í5Ó¤ §5§~¤!Í3¤ Ø 
&­ ÜÀ·7¦òÏ731o¢-báRçç2us¬eá·Èçú²ÝÉ
 Ç÷á·âAâá·È}G

Í7u¦

Ø

¦ ¤ §·Ó¤¦ §Ó¤

·ÄÉ7ç¢u
Kmeuÿ e x è ÉT®ç~á
u
bEðó2ô
ô7òhµAÈáqo#ÈÉuÉw~oÈÉKqRák+x3ÈáÃwÉÈyÄáÂáhm1ÉsqRá·Ç9x>ã'â
· È~ã'Çç}oÈÉ)®7È~ã'æÏç2E¥1¦ À§¨©D*{ª«l«
¬®­ ¯rê'°&±&²³{ªû¯rêÀ¶suÇ3Ç¢¢óÀ
õ¨ºÙó¨)Å+ÙnuÇ3ÈT®á·È2
Ê
·ÄÉ âÉì¢uf·beu í áRÉá
uTüeuTÿnKqÀã'ÈGqRá·âAâÉTusÄðó2ô
ô
ôò<Ìm1ÉæyÇ>ã'ÈçÉ=Éw<n È9xsq9x3È~ã'â7m`nKo¡ÄáqRÉæyÇ÷Él
çÉÆáÉKk3ç2¥1¦*¨§¨©*{ªË«³ª3­ ¯¯uÇ3Ç¢>»
ô'¹'º»
ô
ô+

¾ûá·ÈGkAâáRç2u)·bðó2ô
ô
òoÈÉý áqÉ¢{¯¬jÂfqÀãÉÀoÈÉKqRák+x3ÈáwÉÈ¢ñã'ì3âáÀãxm1ÉsqRá·Ç9x>ã'âs·ÊÈ~ã'Çç2
¥1¦ À§¨©*Òðu
³ F
± #
³ Ý­ ¯éR°&±
²³{ª¢´'àà52é uÇ3¢
Ç fÅ+óÀJ¨K
º Å7
» Ç+
¾ÉÉâe®á
u'¾Pðó2ô
ô7Jòì!+xsqeáE"áRÉÈáRçÀ{ÈjÂfqäã'â
á·âAâe®ásqRá
K ¥1¦Ð5§RÍ Ø ¤1 YÂ¢5# Ø ¤ ÀÖr¤
Ìñ¤!Í5¦ ¤R¤>Ù
 uÇ3¢
Ç ó2Å
ô¨Ù
º óÀ
 Å+m`n í |oIx3ì3â qÀã É 2ç 

í á1%$uf&PeuÙÿ I É)xççá2us» 'Jmðó2ô
ô7Jò®#á·ÈjÂfqÀãÉLÉwD¾(É è âá)+®á KlãçáRçKlãçá)Ézm1É~ã'
æÏá
m áqü%T®sE¥1¦ À§¨©# {³³³{ª3­ ¯µ)uÇ3Ç¢
õ7¨º
ô+ó


*áÀãx¢u|·b e euEÿ*çç~ãÉ)xCu I }ðó2ô
ô
ò"á I á·Ç3ÈáRçá
~ãÉ ÉwÀná·æGã
qm1Éç È~ã
ç+
m ÉsRq á·Ç9x>ã'â·ÊÈ~ã'Çç`n$çá·æÏç2,Ò¥1¦*¨§¨©ó*®ª«l«
¬®­ ¯é·°±
²³{ª{´'àê3é2uuÇ3Ç¢fóÀ»
õ¨ºÙóÀ
Å+TnuÇ3ÈT®á·È2
1

ÆxT®-á·È2uK» ' í ðó2ô
ô7òï·ûáá·È~ã'âeþ¨ãÉhnuÇ÷áqäã'âeþ¨ãÉMwÉÈ`m1ÉsqRá·Ç9x>ã'â·ÊÈ~ã'ÇçDËu7u¦5 Ø
*.Í3¤¦ÐòG¤5 Ø Ýð&Ó¤¦ ¤R§ Ø ³Ä¦· ÞF§· Ø ª>b¤ ØÜØ AÖr¤§~¤1D
u é
u »
7
Å ¨º»'¹7¹s
ÆxT®-á·È2uÙ» ' í <
 ð>Å
Ç
Ç
Çò{¾(É è âá)+®á I á·Ç3ÈáRçá~ãÉ}ã I áÀãç~ÉT®ç{ì>ãç~á)9É®7È~ã'ÇÝHÊÉæÏÉ'
æÏÉÈ Çç æE,¥1¦ À§¨©D*{ª«l«
¬®­ ¸¸)uÇ3Ç¢ó¨)Å¨ºÙó2ô
Å+nuÇ3ÈT®á·È2
ÆxT®-á·È2u  ' í eu¢ÿìmá¢u»ðó2ô
ô7Jò I á·Ç3ÈúRçá
á·È/3áRç6qRÉ>ãçç~ãsqRáRçáÄÈ~ãçÉá·ÈÔã2áq03áRç
®7È~ã'ÇáRç21Ì¤ÑÀ¤&­ ª>b¤ ØÜØ AÖr¤5§¤Ê³û¦ ÞF§·¤ ØÜØ ¤u
´¸ðóòu5Àº7J+
oYã'Ç>ãAæ0 ÈÉ)x¢umH¢ðó2ô
ô'¹ò¢«ò{Í575 Ø «7òÍ Ø ¤7ÜÕ
çÉ' e

áRçâá$

oóÉ7ç2ut~ í Ùðó2ô'¹u
ò I áq1x3Èçeá~xç~Éâeã'ìAâ$ÏÉwãÇ3ÈÉì3âá·æ;Éw¢"txá
DËu¦ Ø *¬>ÕòG£  Ø §ñ±&Ö§u
´'àðóòu}óºÙó
ó
 I á·Ç3Èá)1¢{I»Iûã%çÆð.=òuE"ám1ÉâAâáqá) e ÉÈ üçGÉw6æ0Aâ í IoóÉ7ç2u
K2AÈ ü%>ã
x çá·È2
u K®É7çÉó2ô
ô'¹su3Ç3Ç¢>
Ç7»3'!+óÀ»+

oÈá·âAâá·È2uÀeuÙvxT®-á·È2uÙ  ' í euÿRmá¢uf»ðó2ô
ô
õò í É)®-qywÉÈü{áRçá)·ÊÈ~ã'Çç2y«ò{Í575 Ø
ª>b¤ ØÐØ )Öu¤5§~¤1Y
u ´·¶ð »òu>»7»7¨º»7K

I x3Éâjw9ut»Ùðó2ô
ô
õò¬4Aâeþ)T®Ãm1Éç È~ã
}nãçwã)qÉ½láq5QtxáRç|wÉÈé6qá
}·ÊÈ~ã'Ç½oFãá·È
L
ã GqT®ssG¥1¦ À§¨©÷*µÜÓ¢ª>b¤¦575 Ø Å5¦ 7¨~ÓÍ}ð&Ó¤ ¦ÕÔ{³FÍrÍ Ø §7Ò*ï®¦*Í>Ó
ð¦*73ÐR¦òy~°
±&²G«
¬}´éµRs
¶ uÇ3¢
Ç fÅ7
» õ¨K
º Å7+
 ó
nuÇ3È T®á·2È 

nã'âe7ã2u~|ðó2ô
ô
õòî"áRÉÈá·æ Ç3ÈÉ2%T®vxçT®v®7È~ã'ÇÛÉÇ÷á·È~ãÉç/8áqRÉsqRá·Ç9x>ã'â|®7È~ã'Çç²wÉÈ9'
æGã'âç æE, ¥1¦ À§¨©#*û«³ª3­ ¯ßuÇ3Ç¢5»77J¨º»7J
Ç+
nã'âe7ã2u~eu)ÿºvxT®-á·È2u  ' í Kðó2ô
ô7JòTnÉ)xyãbm1ÉæyÇ3âááÄYÉÈ è ã'Èyã K®ã)q~ü è ã'ÈÃm>ãT®ç
ÉwEÊ
· È~ã'Ç I 3
x âáRç2, ¥®¦*À§©*{ª«l«
¬®­ ¯uµ°
±&²{³ª´r´´7ê
u3Ç3Ç¢ÙÅ'¹tõ¨ºKÅ7J
Å+ÙnuÇ3ÈT®á·È2

,-À,

jlk4Pm1n5oDprq47s5@)6utvn5wyx1<>q4rz{0>?>|}m1n5?>z~6B05@A?36z

nÉ è ã+u&¼sÄ|Iðó2ô
õ'¹òv«75§~¤bÍ3 Ø ¬¦3§R¦ ¤À×DªÀR¦òÏ77Ý¥1¦ À§~¤ÜuÖÝÐôí9Ü59ÒíÝ§·ÓrÐ÷¤1
 çÉ' e áRç âá$


nÉKqüæÏá$á·È2u í u¼fðó2ô7
ò7"áÊÇÉâ$%Éæ0äã'â:';AæÏá(á·È~ã'ÈGq$¢ð&Ó¤ ¦¤·§ Ø «ò{Í5b¤¦Ê¬§·¤5§¤1u(øu
ó ºKÅ
Å+

"txá
uTðó2ô+ó·¹òoÈÉì3âá·æÏá(<3ì÷á·È1Êá·È5=3á·È9xT®áÉ?>áqá3Èáá*>ã)qM®á1®á·ì÷áá I á1®á·â¢
¬7¦R©(@¤ u¤3577©
¬÷¤ Ø 57©&ª&
u ´¸)

e á·È æÏá·âT®á·È2u»<ðó2ô
ô7òym1ÉsqRá·Ç9x>ã'âé·ÄÈ~ã'ÇçãÄAAÈç9'Jï{È3á·È í É)®-q
y,v¥1¦ À§¨©1*ª«l«
¬®­ ¯uê'°
±
²³ª¯rêRs
¶ uÇ3¢
Ç 5
» Å7»¨º»7»K

,-3B


	
 
			 ! #"$ % 
'&)( *,+.-//-102-346574!( 3

89:;<  =)((?>
/!(@BA:	%&=DC1>
/-

EGFIHKJMLONPHKQ1R<NTS9SUWVYXZNTQ[\Q9[^]_Na`bXZJdc\S1efLONPHKQ1RhgiQ1NTSJ)]dF^ej`bXZelkmQRnHJMXpoqJ)X
NsrItuJ)v)e,[wgxQNTS1J)]dF^eyrzU|{2He,L

}p~$Yn~2

,M92Z ¡¢

£¤#¦¥P~2#§2'¨#©ªu~$

«q2¬­2«M«79«®¯°2±

²¦b¤§³´µ²¦~$¶B´

$«M92Z ¡¢

·Z¤¸¹§³´

º6z«7­M92Z ¡2¢

»'¼ªu½2'

2­¡M92Z ¡¢

¾T¿KÀÁ¿ÃÂÄÅBÆÆÇÆÉÈÅqÊ
ÇË6ÅÌ®ÇËÍ
ÎBÏ¤ÐdÑ ÅË?ÒÁ¾,ÓÔ!Õ Ö×lØ ÙÚ
à Ø ÇË?ÄÅÝ

Ñ ÅBË?ÒÖá)â

ÎqÐqÛ ÖZÜfÇ!ÇÝßÞ ÎqÐBÛ
Ðã9äÛBå

æèçPéqêëìZíê
îïð¤ñBò9óõôö.÷BøùðqúûòMü?ýü?þ ò!ÿÁüPï ð¤ÿMö.ü?òMò
 ö ò!ó¤þP÷óôõó÷Bþ?û?÷qø÷1ò!ü?ü,þ ð^÷Iøù÷ úò÷	?ö ò9þ®ý\ð
ö.ó

7ð?ÿÁ÷Bþ?ö ð¤ó ü ð¤û1ò9ü#÷qóô|ü òö1ò9ü
 ð¤ÿß÷qó¤ý ïðóò	fðnòò	û?ò9ó¤þ#ü6ïð¤ñBò!ó ôöù÷qø ðúûòPü ýü?þ ò!ÿdü
÷ ò<ôò1
 öùò9ó¤þö.ódþ ò9ö!ü?þ 6÷Bþ?òúö ò!ü"
7ðZï?òò9ó¤þ ö.óúqöùôò!ó¤þ ö#
7ý¤ö.óú)÷óô$ ò!ï÷Bö?öùóúDï?ð%øùò9ÿÁüZþ÷Bþ÷ ö.ü?ò
ö.ó»þ 
 ò&1 ð¤ó ò6ü?÷qþ öùðó'&()ö.ü)ï÷ïò?ò9ïð?þ?ü*?ò9ü6ûøùþ?ü ð¤ó ÷qûþ?ðÿÁ÷Bþ?ö!9÷Bøùø ýõþ 6÷Bö.óöùóúµ÷,+-?ð%øùò9ÿÁ÷qþ ö
. öù÷qø ðúûò&+-?ò9ôö! þ ðdþ?ð»ï ò!ôö! þ ï ð% øùò9ÿÁ÷Bþ?ö!, ûÿÁ÷qó/1ð¤ÿÁïûþ òÁôöù÷qø ðúûò!üÁûü ö.óú ÷01ð?ïûüMð	

: ÅÍ8< 7 ÔØ =?
> Ç@	AB ü6ïðñBò!óõôöù÷qø ðúûòÁü ýü?þ ò!ÿC() ò
 öùþ u
 þ  ò87 Ç9;µ
12	34 ôö.÷Bøùðqúûò9ü51 ðø øùò þ ò9ô6<
+D ð% ø ò!ÿÁ÷Bþ ö . ö.÷Bøùðqú¤ûòC+D ò!ôö1 þ ð$÷qóE
% ò\ö.ÿÁÿdò9ôö.÷Bþ?òøùý¦÷qïïø öùò9ôYþ ð»þ  òmü ýü?þ ò9ÿ&F üÁôò öùü?ö ð¤ó¦ð	

G ò9þ  òDþ ð^þ 6÷qóüH7
 ò,þ òI ÷qø øKþ?ð^÷, ûÿÁ÷qóJ ûü þ?ðÿdò5÷ òÁ÷Búò9ó¤þ2
 ð5%ò ûü?ò9ôu÷qü ÷,9 ûòÁþ ð^þ  ò
ü?ýü þ?ò9ÿ&F ü ôöù÷qø ðúûòÁÿÁ÷qó÷qúqòPþ?ð^ÿdðôö#7
 ýµöùþ?üK
% ò ÷L öùðPþ ðM?ò9ï÷BöPï ð% ø ò!ÿÁü2
 ÷óôõòq ò!óõïò÷ïü
þ?ðuï?ò
 ò9ó¤þ)þ ò9ÿ&Ou
N òÉü ð þ ÷Bþ ÷M+D ð% øùò9ÿÁ÷Bþ?ö! . ö.÷Bøùðqú¤ûò8+D ò!ôö! þ ð)ûü?öùóúõ÷qûþ ðÿÁ÷qþ ö ÷Bøùøùý
ð
% þ?÷qöùó÷% øùòP7
 ò!÷Bþ6û ò!ü5
?ðÿþ ò6ü þDþ/n
 ð\òRQS ÷óúqò!ü,ö.óuþ  òzôöù÷qø ðúûò ÷ó»ï ò!ôö1 þTï?ð% øùò9ÿÁ÷qþ ö
ôö.÷Bøùðqú¤ûò9üUTV 4W ÿdð?ò ÷	
 û6÷Bþ?òøùý þ  ÷ó|þ ò*% ÷qü?òøùö.óò	

XZY\[]

êë^)_a`fíêbH^

]

c dfhghijIkmlnhopfhqr'iGsStusSvSiwMsZdyxRfwMlzsSi)iL{J|lpijv-nhjmkIjmnvRr'xnhonh||LisRs-vSfn*oznxRqhi~}nxlzivt$fh'lzj'fhxwMnvRlpfj
e
sSfr'x|Lis\nhjmksSixR}ulz|Lis&xRfwnhjtdymfj'ihcetusSvSiwMs&vRmnv\sRr'dmdfhxRv&sR'fhxRv\r'vSvSixnhjm|Lis,vSfsSiopi|LvMn
dynxRvRl|rmoznx\rmjm|LvRlpfjvRmxRfr'qnsSvRnvSiw\ijv6sRry|nhs;cun	t|LxRikmlpvM|nxk5|Lfoopi|Lvfhx6d"ixsSfjuHvSf
dixsSfjmUnxi8sRn}ulzj'qM|LfwMdynhjmlpis*wlzozozlpfjysGfh)k'fozoznxsadix*thinx	~idyopf	thikEsStusSvSiwMsnhjyk0xRisSinx|
dmxRfhvSfhv tdisiL'lzsSvfhxGndmdyozlz|nvRlzfjms-srm|\nhsdixsSfjynhoiwnhlzounhjmk,|nhopijmkmnxshvSxn}hiomnhjykCxisSvRnhr'xnhjv
lzj'fhxwMnvRlzfjZ"nhjykEdixsRfjmnhoynhjmgelzjmq5nqhqlznuKnhsSvRnqj'ixl/$nhjmlpiozlHDhh e¡-¢£nhopghix¤'xRfwMix
¦¥nxntnhjmnhjPhh e¡Pceij'iL§U¨rmih~©DfozlpxRfjml/)©nf'aªPivR'ixlzjmqhvSfjZ5«fukmk'inhr~¬«$oznhsRsPhh­e¡
cunhjmkmixwMnhjZcuvRr'xwOk'ij¯®$s$af}hisI°UxRiw\ixsChh e¡M5eru5nxRxRfoo°5nxd"ijvSix&hh
±²y³´Lµ\¶·!±¶ ¸Giv$vR'ixRiCnxi&sSvRlozowMnhjtOxRisSinx|¹|mnhozozij'qhisº*|r'xRxijvsStesRvSiwMsPnxi&ozlwMlpvSik»lzj¼vR'i
lzjvSixnh|LvRlpfjOvRmit0sr'dmdfhxRv5nhjmkOmxlzvSvRopilzjOwMnhjtJxisSdi|LvRs
½ ylzsdyndix~lzj}hisSvRlpqnvSisUw\ivR'fukms)et,¾mlz|MsSdfhghijMkmlznhozfhqr'isStusSvSiwMsa|nhj ·z´R¶µ² vSf&sRr'dmdfhxRv
w\fhxRiMjynvRr'xnho)lzjvSixnh|LvRlpfjfj£vR'i\ynhsRlzs$fhUvR'ilpxdyxRi}elzfrmsiLedixlpijy|LihM®j'i\¾Un	t¹vRmnvI|r'xRxRijv
sSdfhghijkmlznhopfhqr'i&sStusSvSiwMs$nxRi,¿rmlzvSiCozlzwlpvSik»lzslzj»vRmilpxsRvSxnvSiqlpisfhxk'ivSi|LvRlj'qJnhjyk¼xRidÀnhlpxlzj'q
dmxRfhÀopiwMsvRmnvInxlzsRi,lj|Lfj}hixsnvRlpfjZ-srm|nhsIwlzsRrmjmkmixsSvRnhjmkmlj'qskmrmi&vSfEsSdii|¹xRi|LfhqjmlzvRlpfj
ixRxRfhx,fhxMwMlsRlzjvSixRdmxRivRnvRlpfjÁndmxRfhÀopiwÂ|nhji0k'ivSi|LvSikZavR'iOsStesRvSiwÃ|nhjilzvR'ix,vSxnhjmsSix
vR'i\|nhozo-vSfOnJermwMnhj|rmsSvSfwMixI|nxRi\nqhijvfhxw\fukmlpt»lpvRskmlznhopfhqr'i,sSvSxnvSiqht¹lzjnhj¹nvSvSiw\dmv$vSf
Ä

-//-n %%ÀÅ!=6T
=5ÆD1
UÇZ
! ;l
~È:!	%&%É		q&1%2%Ê1 =É

Ë

2¤ZÌyÍ¬2­2«¤°2ÎSÏÁ2Ð-Ì

Ë

«7­¼ÑM1«mÌ

Ë

«7­¼ÒÓÏÁ¡2«¬

xRidynhlzxvR'iMdmxRfhÀopiwO,¢i6|nhjvSxnhlzjsStusSvSiwMs8vSf¼lzw\dmxf	}hi\vR'ilpxInÀlzozlpv t¼vSfEkmivSi|LvIdmxRfhyoziwMs$t
iLudyopflpvRlzjmq6kmlznhozfhqr'is$|Lfozopi|LvSiklzjlzjvSixnh|LvRlpfjms¾lpvR¹ermwMnhjrmsSixs¾mixRiCvRmi,ljmlpvRlznho-sSiqw\ijvRs
fhZvR'isSiPkmlznhopfhqr'isanxRiPrysSik\vSf&vSxnhlzjMnC©GxRfhyoziwMnvRlz|*$lznhopfhqrmi©GxRikylz|LvSfhx©a©5vSfIÔ µS´Õ±/Ö³ vRmnv
n»dyxRfhyopiw¬ls8ozlpghioztvSfEfe||rmx ½ 'iMfrmvSdyr'vIfhKvR'iJ©~$©×|nhjiJlzwMw\ikmlnvSioptndydyozlpik¹vSfvR'i
sStusSvSiwOØÙsGkmi|lzsRlpfj,fh"¾'ivR'ix~vSfvSxnhjmsSixGvR'i*|nhozomvSfInIrywMnhj\|rmsSvSfw\ixa|nxRinqhijvfhx~lzvG|Lfrmozk
dfhvSijvRlnhozopt"iMrysSik£nhs8n¼|r'iMvSf¼vRmisStusSvSiwOØÙs8$lznhozfhqr'iÚnhjmnqhixCvSfw\fukmlptElpvRsimn	}elzfhxIvSf
xRidynhlzxKdmxRfhyopiws'nhjmkOi}hij»dixyndysuvSfMdmxRi}hijv*vR'iw»
ÁÛjdmxRi}ulpfrmsP¾afhxRg"Z¾Ui&xid"fhxvSikljmlpvRlznhoÜxRisRrmopvRsPfhxvSxnhlzjmlzjmq6n0©~$©ÝrmsRlj'q6nJ}nxlpivtEfhakmlz
ixRijvinvRr'xi8sSivRsCÞ-nhj'qhgulzozk'ih'¢£nhopghix	m¢xlpqv«fhxlzjZyßÞ-lpvRwMnhjZhhe¡À¢£nhopghixÀÞ-nhj'qhgulzozk'ih
¢xlpqv$«$fhxlzjZÂÞÜlpvRwnhjZàáháhá"ß¢â'ij?nhjynhoptãlj'qvR'idixRfhxwMnhjm|LifhvR'irmooptänhr'vSf
wMnvRlz|,invRr'xRi6sSivÜ¾Ui\iLunhwlzj'ik¹¾ml|mnhjmk'ozniozopikEinvRr'xisIwMnhk'iMoznxqhi\d"ixfhxwnhjm|LiMlzw,
dmxRf}hiw\ijvRs"ryjmk'ix*vR'i&nhsRsRrmwMdmvRlpfjOvRmnvPrmvRr'xRiI¾UfhxRgOsR'frmokOfu|rmsfj¼k'i}hiopfhdÀlzj'qnhr'vSfwnvRlz|
invRr'xRisvRmnvCndmdmxRf	ulzwnvSi\vR'ilzj'fhxwMnvRlzfjEdyxRf	}ulzk'ik¹etEvRmisSiMmnhjmkuon"ioopik¼invRr'xRis ½ 'i
nhjmnhoptusRlzslzjmkylz|nvSik¼vRynvvRmi&mnhjykuozniozopik¹å'æ$çDèéê ÖÖ´ éé*invRr'xRihZ¾ml|Eijm|LfekmisP¾P'ivR'ix$vR'i
sSdfhghij£oznhjmqrmnqhiMrmjmk'ixsSvRnhjmkmlzjmq¹Hëìí-|Lfw\dfj'ijvI|ndmvRr'xikvR'iMw\inhjmlj'qOfhainh|£iL'|mnhjmqhi
|LfhxRxRi|LvRozth~¢â'ij»vRmlsKmnhjmkuozniozozik6invRr'xRiClzsKnhkmk'ikOvSf6vR'i8nhr'vSfwnvRlz|invRr'xRisylzvlzw\dmxf	}hik
vR'i*dixRfhxwMnhjy|Li*fhvR'i©~$©t\nhozwMfsSvUîðïñJ ½ ylzsòÀjmkylzj'q$opikMrms~vSf8k'i}hiopfhdJnhjOåuæç-è éê ÖÖ´ éé
dmxRikylz|LvSfhx¼¢£nhopghixK¢xlzqvKóÞÜnhjmqhgelzok'ihUàáháháh|	Mnhjmkn£j'i¾ô}hixsRlpfjfh$vR'i»©a©õvRmnv\¾Ui
xRidfhxRvafjJmixRih ½ 'i$j'i¾ö}hixsRlpfjJfhvR'i$©~$©vRnghis*nhs5lzjmdyr'v~nCryozopt\nhr'vSfwMnvRlz|}hixslpfjJfhvR'i
åuæç-è éê ÖÖ´ ééainvRr'xRihm¾ylz|0¾Ui8|nhozo ¶ ê ³H÷ èåuæç-è éê ÖÖ´ éé
¢i*vSxnhlzj\nhjmk,vSisSv)fhvR,vR'i ¶ ê ³H÷ è åuæç-è éê ÖÖ´ ééÜdmxRikml|LvSfhxGnhjmk,vR'i*©~$©fjn|LfhxRdyrmsDfh"øïhhà
kmlznhozfhqr'isI|Lfozopi|LvSiklzjnhjiLudixlzw\ijvRnho)vSxlznhofhKù ½  ½ ØÙsCú ÷ûÝü¶ýJþ ú ´· Ô ÿ ÷ ê£ 
	 
sSdfhghijkmlznhopfhqr'iCsStesRvSiwH«$fhxlzjZ
 lz||nxkyl/À ¢xlpqvhî¡ùPiozoznMÓ«fhxlzj-hhe
¡ l||nxkml
 «fhxljZuàáháháu
¡ *'ùwMwMlz|v* ùPozfjmsSf'ZhhaÁÛjJvRmlzsUvSxlznhoHvR'i  sStesRvSiwÓ¾UnhsKlzjysSvRnhozopik
nv\nhjù ½  ½ |rmsSvSfw\ix\|nxRiO|LijvSix  nhjmsS¾UixRik|nhozozsCxfwÃolp}hi6|rmsRvSfw\ix,vSxn{6|0nhjmk
sRrm||LissSryozopt£nhr'vSfwMnvSik?noznxRqhi»jermwC"ix,fh$|rmsSvSfw\ix\xi¿r'isRvRs;ùjiL'nhw\dyopi»kmlnhopfhqr'iJvRmnv
 |Lfw\dyozivSik;srm||LisRsSrmozoptlzsCsR'f¾jlj¤lpqr'xiE ½ 'idÀ'fj'i6jermwCixs)|nxk;jrmwCixs
nhjmkOdÀlzj0jrmwCixsKlzj0vR'iCsRnhw\dyopikmlnhopfhqr'is*nxRiCnxRvRlòÀ|lznhoH
îeT
 T 
î 4 

 4 
îV
 V
î 1 
 1 
î " 

 (K
Z
 (£,ð ÿÁ÷ý
 òø.ïÉýqð¤û
#óòò9ôÉþ?ðûïûþl÷$÷qø ø2ðóÉÿTý89÷Bøùø ö.óú÷?ôÉïøùò9÷qü?ò
 ÷ýD
m
 ÷LqòDýðû÷?ôÉóûÿ%òïøùò9÷ü ò 
! 2#
" 1 V 4 T%$ 3'& ! 2#P
" 1
N£÷qþló¤ûÿ%ònðûø.ô|ýðûIø ö.ñBòDþ?ðI÷Bøùø(
& T 1 !#!)! 2$2$22+* Ý,.S- @ÆÙqÔË/
- Ì®Ç!Ç9Ù 0
 ÷ýD
m
 ÷LqòDþ÷BþlóûÿP%ò<÷Bú÷qöùó1
& T 1 !#!)! 2$2$22
()÷óñ

ýqð¤û'

¤lpqrmxRiMºUcunhw\dÀopi324Dë )
5 ëí
67698Àë	ë$lznhopfhqr'i
¥PfhvSiCvRynv*vR'iCsRtesSvSiw»ØÙsr'vSvSixnhjy|LiClzjEcuø|LfjmsRlzsRvRsKfhGn\xRidynhlzxlzjmlpvRlnvRlpfjZ'w\fhvRlp}nvSik¼et0vR'i
sStusSvSiwOØÙsCnylzozlpv t¼vSf¼kmivSi|LvIvRmnvIvR'i6rmsSixØÙsIrmvSvSixnhjm|Li:);0¾5nhs8ozlpghiozt¼vSf¼mn	}hiiijwMlzsrmjmk'ixS
sSvSfefek ½ miJqhfnho*fhPvR'i ¶ ê ³H÷ è åuæç-è éê ÖÖ´ ééCdmxRikylz|LvSfhx\lzs,vSf£lzw\dmxf	}hiOvR'iOsStusSvSiwOØÙsMnÀlzozlpv t£vSf
k'ivSi|LvJsRrm|?wMlzsRryjmk'ixsSvRnhjykmlzj'qs ½ 'iEkmlznhopfhqr'isMvRmnvmn	}hi¼vR'i¼kmisRlpxRikäfrmvR|Lfw\ih*lzj¾ml|
i 24-<ë 5ë

í 676=8"ë	ëkmlzn
 srm||LisRsSrmozopt6nhr'vSfwMnvSis*vRmiI|rmsSvSfw\ixØÙsK|nhoo/mnxRixRiixRxRik0vSfMnhsKvRm#
431

>

°«7«¬2­

> ¡9?¢f«7A@d«.¤¡­2±2

opfhqr'is$lznhozfhqr'is~lzjM¾mlz|\vR'i  sStusSvSiw kylzk\j'fhvasrm||LisRsSrmozopt&|Lfw\dyopivSiPvR'i|nhozozixØÙs)vRnhsSg
nxRiIxiixRxik0vSfnhC
s BEDF
Gy
ì 8  4E2  6 ½ misSiInxRi8k'is|Lxlpik0lzj0rmxRvR'ix*k'ivRnhlzoiopf¾I
½ ylzs5dyndix*xRidfhxRvRsKxisRrmopvRs5xRfw iLudixlzw\ijvRs5vRmnvPvSisSv*¾'ivRmixlpvlzs5dfsRslpyopi$vSfopinxjOvSf
nhr'vSfwMnvRl|nhozoptdmxRikmlz|Lv$vRmnvCn»kmlznhopfhqrmi&¾PlzozoDi&dyxRfhyopiwMnvRl|Cfj£vR'iMynhsRls$fhUlzjmfhxwnvRlpfj¹vR'i
sStusSvSiwÓmnhsº*Û	~inxoptljvR'i$kmlznhozfhqr'ih¡enhjyk/àUlzjxRinho"vRlzw\ih¢ivSxnhlzjJnhj0nhr'vSfwMnvRlz||oznhsRslòyix
fhx»dmxRikml|LvRlzj'q;dmxRfhyopiwnvRlz|¹kmlznhopfhqr'is»xRfw invRr'xRis¼vRmnv¼|nhjÝi£nhr'vSfwnvRlz|nhozoptöiLevSxnh|LvSik
xRfw vR'i  |LfhxRdyrmsùPsMkmisR|Lxlpikänf	}hih5fj'i»fhvR'isSi¼invRr'xisMlzs\vR'iOfrmvSdyr'v\fh$vR'i
¶ ê ³H÷ è åuæ$çDè éê ÖÖ´ éédmxikmlz|LvSfhxDvR'i ¶ ê ³H÷ èåuæç-è éê ÖÖ´ ééinvRr'xih)¾mlz|dmxRikml|LvRsI¾'ivRmixCfhx,j'fhv
vR'i0|r'xRxRijvCrmvSvSixnhjm|LiJ¾Unhs,|LfhxRxRi|LvRoztrmjmk'ixsSvSffuk¢£nhopghix\iv,nho/p~àáháháh|	 ½ 'i6xRisRrmozvRs8sR'f¾
vRmnv8lzv$ls$d"fssRlpyopi&vSfJÔ µR´RÕ±/Ö³ dmxRfhyoziwMnvRlz|,kmlznhopfhqrmisrmsRlzj'qJrmozopt¼nhrmvSfwMnvRlz|\invRr'xRis¾PlpvRnhj
nh||r'xnh|LtExnhj'qlzjmqMxfw ïheðïñ vSf» áuH ;ñJZk'idijmkmlj'q\fj¾'ivR'ixvR'iCsRtesSvSiw¦mnhssSiijfj'i&fhx
v¾Uf,iLu|mnhj'qhis~Á vUlzsGdfsRsRlzyopiKvSf ±Õ´²y³± Iý dmxRfhyopiwnvRlz|*kmlznhozfhqr'isG¾lzvRnhjJnh||r'xnh|Lt6rmdvSf\ îhñJ
cei|LvRlzfj¯àk'isR|Lxlpis  nhjmkâvRmi£kmlznhopfhqr'i¹|LfhxRdyrys0vRmnvOvR'i¹iLedixlw\ijvRsOnxiÀnhsSik
fjZcei|LvRlpfjJ;¼kmlsR|rmsRsSis8vR'iJvted"i6fhwMnh|mlzj'iJopinxjmlzjmq¼nhopqhfhxlpvRywÂnhk'fhdyvSikZ)jmnhw\ioptKD  BEBE8ED
nhjmkäqlz}hisnk'isR|LxlpdmvRlpfjfhvR'i»iLudixlzw\ijvRnhoKk'isRlpqj?cei|LvRlpfjäø£qlz}hisn¹mxRinguk'f¾jäfh$vR'i
invRr'xRis5rmsSikJlzj6vR'isSiiLedixlzwMijvRs~cei|LvRlzfj0­8dmxRisRijvRsUvR'i$w\ivR'fukfhÜdmxRikmlz|LvRlj'qIvR'iinvRrmxRi
¶ ê ³H÷ è åuæ$çDè éê ÖÖ´ éé5nhjmkOqlp}hisnh||r'xnh|Lt0xRisRrmozvRsacei|LvRlpfj¼ï&dyxRisSijvRs*w\ivR'fukms*rmsRik0fhxrmvRlzozlpãlzjmq
D  B=BE8ED;vSf»vSxnhlzj¹vRmiMnhr'vSfwMnvRlz|M©~xRfhyopiwnvRlz|,lnhopfhqr'iM©Gxikmlz|LvSfhx8nhjmk¹qlz}hisvR'i\xRisRryopvRs,¢i
k'iozn	t6frmx*kmlzsR|rmssRlpfj6fh-xRionvSik0¾afhxRgJvSf6cei|LvRlpfjîC¾'ijJ¾aiC|nhj»|Lfw\dynxRiIlzvUvSf\frmx*ndmdmxRfnh|Z
cei|LvRlpfjE \sRrmwMwnxlpãis5vR'iIdÀnd"ix*nhjyk»k'isR|Lxlz"isUr'vRr'xRi¾UfhxRg"

LYNMPORQJSUT [SWVYX

ìêì

 lzsn6sSdfhghij¼kmlnhopfhqr'i8sStusSvSiw ynhsSik¼fj¼vR'i&j'fhvRlpfj¼fh Ö¶··-µS÷ ê ³±²1Z H«$fhxlzj»iv$nho/pDhî¡
5eru5nxRxfozoÜ 5nxRdijvSix-hhÁÛj¼vRmi  |nhozo-xRfr'vRlj'q6sStusSvSiwOsSixR}ulz|LisvRmnvvR'i,rmsSix
|nhj£nh||LisRsCnxRi|oznhssRlòyik¹lzjvSf£Lø»|nvSiqhfhxlpisDdyozrysnO|nvSiqhfhxt£|nhozopik ÷h³\u
[ ´µ fhxIvRnhsRgesvRynv8nxRi

j'fhv5|Lf	}hixRik»tMvRminhr'vSfwnvSikOsStesRvSiwnhjykJw&rmsSvUivSxnhjysSixxRikvSf\n&rywMnhjfhdixnvSfhxIH«fhxlzj
iv\nho/phîhJ~nh||nvSiqhfhxRtäk'isR|Lxlz"is&n¹kml§ixRijvCvRnhsSg"asrm|nhs,dixsSfjuHvSfHdixsRfj;kylznhozlzj'q'
fhx8xi|Lilp}elj'q¼|LxRikmlzvIfhx&n¼wMlsRkmlznhopik¹jermwC"ix	 ½ misStusSvSiw k'ivSixwMlzj'is8¾mlz|vRnhsSgvR'iJ|nhozopix
lzs8xRi¿rmisSvRlzj'qOfjvR'iÀnhsRlzsfh*lpvRsCrmjmk'ixsSvRnhjmkmlzjmqJfhKvRmi|nhozopixØÙs8xRisSdfjmsSivSf¼vR'i6fhd"ij'Hijmk'ik
sStusSvSiw¬qhxiivRlzj'^
q ]_a`b_caú ÷û¯ü£¶ýOþ ú ´L· Ôßÿ ÷ e
ê d0®$jm|LivR'i\vRnhsSg£mnhsiij£kmivSixwMlzj'ikvR'i
lzj'fhxwMnvRlzfjj'iik'ikIfhx-|LfwMdyopivRlzj'qvR'i~|nhozopix	ØÙsxRi¿er'isSvÜlsZfhmvRnhlzj'ikCrmsRlzjmq5kylznhopfhqr'i~sr'yw\fukmrmopis
vRmnvnxi8sSdi|lòÀ|fhx*inh|EvRnhsSg£ùiozon,õ«fhxlzjZZhh
½ mi 
Cf sStusSvSiw¬|LfjmslzsSvRs$fh5nhjnhr'vSfwMnvRlz|MsRd"ii|xRi|LfhqjmlzãixÜnOsSdfhghij£oznhjmqrmnqhiMrmju
k'ixsRvRnhjmkmlzj'qMwMfekmryopihynkylznhopfhqr'i8wnhjmnqhixnhjmk¼n6|Lfw\dyr'vSixvSiopidy'fjt0dyoznvSfhxwOK$r'xlzjmqMvR'i
vSxlznhoHvR'iimn}ulpfhxsUfhÜnhooyvR'isStusSvSiwÓw\fukmrmopisa¾UixRinhr'vSfwMnvRlz|nhozoztMxRi|Lfhxk'ik0lzjJn,opfhqCòÀopih'nhjmk
oznvSix,vR'i0kmlznhopfhqrmisI¾UixRi6vSxnhjmsR|LxlpiktermwMnhjys8nhjmk;ozniozopik¾lpvR£fjmi6fhx\w\fhxRi6fh*vR'i¹­
vRnhsSg|nvSiqhfhxlpis)xRidmxisSijvRlj'q¼vR'i6vRnhsSg£vRmnv&vR'iJ|nhozopix8¾5nhs,nhsSgulzj'q  vSfdixRfhxwO-fj;n
dix8r'vSvSixnhjy|Li6ynhslzs ½ 'iopfhq»òÀopis8nhosSf¼lzjm|ormk'ikozniozslzjykmlz|nvRlzj'qO¾P'ivR'ix8vRmiM¾lpãnxkmnhk
vRnghijf}hix8vR'iM|nhozoDfhxIvRmi,rysSixImnhkermj'qOr'd&®r'x$iLedixlzwMijvRsrmsRi&vRmiMopfhqJòÀopisvSfOiLevSxnh|Lv
nhr'vSfwMnvRl|nhozopt0fhmvRnhlzjmnÀopiinvRrmxRisrmsRik»nhs*dmxikmlz|LvSfhxsÀnhjmkOvSf6kmiLòÀj'ivR'i8|onhsRsSis*fh)kmlnhopfhqr'is
vRmnva¾aiP¾Unhjv~vSf&opinxjMvSfCdmxRikml|Lv ½ 'i*|LfhxRdyrms~fhZøïhhà8kylznhopfhqr'isGrysSiklzjMfr'x~iLudixlzw\ijvRsG¾5nhs
|Lfozopi|LvSikJlzj6sSi}hixnhoÀiLedixlzwMijvRnho'vSxlznhozsGfh 
Cf fjJozlp}hi|rysSvSfw\ixUvSxn{6|Cg Plz||nxkml" «$fhxlzjZ
àáháháu=
¡ eùwMwMlz|vK ùPozfjmsSf'hhynhjmk0lzsaxRiixxRikvSf\nhs5ªÚà&lzj¹g lz||nxkml"ß«fhxlzjZ'àáháhá
43"

Ë

2¤ZÌyÍ¬2­2«¤°2ÎSÏÁ2Ð-Ì

Ë

«7­¼ÑM1«mÌ

Ë

«7­¼ÒÓÏÁ¡2«¬

 i&kmlznhopfhqrmis*}nxRt¼lzjEopij'qhvRZZîhñ nxRiIòy}hi&iL'|mnhj'qhis$fhx$opisRsP¾lpvRàh;ñôfh~nhozovRmi&kmlnhopfhqr'is
½ '
|LfjmsRlsSvRlzj'q,fhfjmopt6v¾UfiL'|mnhj'qhis
ùsIw\ijvRlpfj'iknf	}hihDkmlznhopfhqrmislj¹¾mlz| 
Cf sRrm||LisRsRrmoopt¼nhr'vSfwMnvSis8vR'iM|rmsSvSfwMixØÙs
|nhozo/5nhslozozrmsSvSxnvSikälzj¤lpqr'xRi£KnxRiExRiixRxRikävSfnhsA24-ë 5)ëí
67698Àëë®vR'ix6|nhoozsU¾mlz|nxRi
dmxRfhÀopiwMnvRlz|ZnxRiMkmlz}elzkmik¼lzjvSf0vR'xRiiM|nvSiqhfhxlpis ½ miCòÀxsSv$|nvSiqhfhxRth-xiixRxikEvSf»nhs  4i
jÜ
í BZ
xRisRryopvRsxRfw¦n0|rmsSvSfw\ix	ØÙsk'i|lzsRlpfjEvSfOmnhj'q0r'dfj¹vR'i&sRtesSvSiw»Iù sRnhw\dÀopi  4i
j
í Bkylznhopfhqr'i
lzslzj¼¤lpqrmxRi&àeùß|nhozopix$wMn	tEmnhj'qJr'd"i|nhrysSi&ls k'i&ls*xrmsSvSxnvSik¾lzvR»vR'i,sStusSvSiwO¡fr'xqhfnho
lzs5vSfJopinxj0xRfw vR'i8|Lfhxdyrms5¾ml|OsStusSvSiw imn	}elzfhxsKopikOvSfMvRmiI|nhozopixØÙsKxrmsRvSxnvRlpfjZ
îeT
 T 
î 4 

 4 
îV
 V
î 1 

 (K
Z
 (£,ð ÿÁ÷ý
 òø.ïÉýqð¤û
#óòò9ô, ò!ôö þlïø ò!÷qü?ò	
m ñ÷ý	N£÷qþ<öùü þò* ò!÷qü?ðóI
7ð þ ò*?ò9ôöùþ/
P
 ö.ü?üû'\
\
 öùü6üôöon ò ò!óþ<÷ ò!÷Pðôò þ ÷ónóòò!ôò9ôm
î¤ð ?ý	 óò9ò9ôuþ ðõñ¤óð?Gò9þ ò ýqð¤û»óòò!ôJ ò!ôöùþK
7ðT÷,G?ðóú^óûÿP%ò
%÷ôCðóóò1þ?ö ð¤ó|ð<÷9÷Bøùøþ ÷qþ)n÷ü)ûþ<ðp"
n 
®þ<ö.ü<÷PG?ðóúÁóûÿP%ò * , ÝG=ÅÌ\, Ô1ÆÌÄ@ÝdÝ, ÆÚ 0
N£÷qþ)n÷ü#þòTóûÿ%òlþ ÷qþ<ýqðûIôö.÷Bøùò9ô
s tRu%v î  +
 îrq;
¤lpqrmxRi8àeºUcunhw\dÀopi  4i
Ü
j í»
B $lznhopfhqrmi

½ mi5sRi|Lfjmk,dmxRfhyoziwMnvRlz|U|nvSiqhfhxRt»\ w \x 4DyDhxRisRryopvRsDxRfwßn$ermwMnhj,|rmsSvSfwMixG|nxRi*nqhijvØÙs
k'i|lzslpfj¹vSf»vRnghif}hix8vR'i6|nhozo)xRfw¦vR'isStusSvSiwO6ai|nhrysSi  lzsiLud"ixlzw\ijvRnho/Zinh|;|nhozo
kmr'xlzj'q5vR'iGòÀiozkIvSxlnhoh¾UnhsDw\fjmlzvSfhxRikIetInermwMnhjCnqhijvsSixR}ulzj'qnhsDn*¾PlpãnxkI¾P'f|Lfrmozk8f	}hixRxlzk'i
vR'isRtesSvSiw» ½ 'ixiM¾aixin»jermw8ixIfhKnqhijvRs8¾P'f»dynxRvRl|lpdynvSik£nhs8¾lpãnxkmskyr'xlzj'q0vR'ivSxlznho
fh  nhjykOinh|E¾lpãnxk0¾5nhsslzw\dyoptvSfozkOvSfvRnghiCf	}hixvR'iI|nhozolzDzs kmiIdix|Lilp}hikOdmxfhyopiwMs
¾lpvR8vR'i5sStesRvSiwOØÙsDd"ixfhxwnhjm|Lih ½ mi~¾lpãnxkZØÙs-kmi|lzsRlpfj8¾Unhsopfhqhqhik&etvR'iaiLudixlzw\ijvRnhosRivRr'd
xRisRryopvRlzj'q&lzj0ozniozozlzj'q8vR'iI|nhozonhsKfj'i$vRmnvKvR'i$¾lzãnxkJvSffhgJf	}hixK®-|LfrmxsSi$¾aiI|nhj0fjyoptlzj'ix
¾mnvUwMlpqv~mn	}hiw\fhvRlz}nvSikJvR'iP¾lpãnxk\vSf&vRnghif	}hix5vR'i$|nhozo/Àr'vG¾UiPnhsRsRryw\ivRmnvavR'i¾Plpãnxk
mnhk¼qhffuk¼xinhsSfjfhx$k'flzj'q6sSf'ùßkmlznhozfhqr'iI¾'ixi8vR'iC¾lpãnxkEk'i|lzk'ik¼vRmnvPvRmiCkmlznhozfhqr'i8¾5nhs
dmxRfhÀopiwMnvRlz|$nhjmkOvSfefhg0f	}hixvR'iI|nhozolsKsR'f	¾Pj»lzjO¤lpqr'xR3
i ;e
îeT
 T 
î 4 

 4 
îV
 V
î 1 
 1 
î " 

Z(K(£,ð
* -{, Ø ÔÆ1
| Ô}0

òø.ïÉýqð¤û

ÿÁ÷ý

î¤ð ?ý	"+øùò9÷ü òK%?ö ò
~ ýzþ?òøùø2ÿdò*ðWnÿd÷ýCòø.ïÉýqðû1
SF ÿ¼þ ?ýöùóúdþ?ð÷BøùøZT & ûóô?ò9ô&÷qø øEä(;(5
. ðdýðûCn÷ó¤þnþ?ðzïø.÷	1ò ÷$÷qø ø(

()?ðûú|ÿ)ýC÷qø øùö.óú÷	6ô'
m÷ýD ÷Lq òDýðû÷?ôÉóûÿ%òïøùò9÷ü ò 
®þF ü & ! 
T $D÷qóôdþ ò9óÁÿTýdïö.ódóûÿP%òKöùü & ! 2" 
2 "a1 V 4 
î¤ð ?ý	"
+ øùò9÷ü òDò9ó¤þ?ò ð ü6÷ýzýqð¤û÷?ôÉóûÿ
% ò<÷qú÷Bö.ó'
Nas . î
( q-+ îu
¤lpqr'xRi3;eº5cunhw\dyopi)w

vSiw

* Ý',.-Ë?Ô/|
Ç?ÚqÆ,o!Ô
Ù0

gx 4Dylnhopfhqr'i

 iMvRmlpxk£dmxRfhyopiwnvRlz|\|nvSiqhfhxRthGvR'iP24-ë<5
p4  ìíD8kmlznhopfhqrmis-nxRiJ|nhsSisC¾'ixRiMvRmi6sStusÛ
½ m
|LfwMdyopivSikävR'iE|nhozo/~Àr'vM|nxRxlpikfr'vMnvRnhsSgvRmnvM¾5nhsjmfhvMvR'iOfj'i»vRynvMvR'i¼|rmsRvSfw\ix
43	2

>

> ¡9?¢f«7A@d«.¤¡­2±2

°«7«¬2­

¾5nhs8nh|LvRrmnhozoztxi¿r'isRvRlzj'q'ùj£iL'nhw\dyopi24-ë<5
<4  ìíD8kmlznhopfhqr'iMlsqlp}hij£lzj¤Dlzqr'xRi\ø'º 
Cf
lzjvSixRdmxRivSikEr'vSvSixnhjm|Lb
i :ànhsnxRi¿rmisSvvSfJwMnghiCnvRmlpxkuHdÀnxRvt0|nhozoZih q'KvSf ±··±³5³H÷P,ý[e÷hM´
Ô [e÷h²"´   vR'ijnhsRghik£vR'iJ|nhozopixIfhx8vR'i6lzj'fhxwMnvRlpfjlpvCj'iik'ik£vSf|nxRxRt¹fr'vIvRylzsvRnhsSg"
vR'i8|nhoopix*|Lfw\dyozlzikZ'nhjmkOvR'i8sRtesSvSiwô|Lfw\dyopivSik¼vR'iI|nhozo/
îeT
 T 
î 4 

 4 
îV
 V
î 1 
 1 
î " 
 " 
î 2 

Z(K(£,ð
* -{, Ø ÔÆ1
| Ô}0

òø.ïÉýqð¤û

ÿÁ÷ý

~

W

1

î¤ð ?ý	"+øùò9÷ü òK%?ö ò ýzþ?òøùø2ÿdò*ð nÿd÷ýCòø.ïÉýqðû
÷qó¤þ6÷óôÉðûþGð ÿ)ûSÉÿTýC%ö øùøF ü)nð?þ m
N£÷qþlï ðóòDóûP
ÿ %
ò )nðûø.ô|ýðû|ø ö.ñBò þò*÷qø øm%öùøùø ò!ôIþ?ð
Ý þ òT	
÷ 1ò!ü?ü óû
ÿ %
ò 
î¤
ð ?ý	 #ðûø.ô -L
÷ òDþ ÷qþl
ï ðóòDóûP
ÿ %
ò l÷Bú¤÷Bö.ó
T ¤ûóô ?ò9ô 4$4 $4

N£÷qþló¤û
ÿ %
ò nðûø.ô|ýðûIø ö.ñBòDþ?I
ð ÷Bøùø
Ì®
Ç @ 
ÄÌ®ÇÆÔ 
Æ =u@Ì
44 	4
()÷óñ ýqð¤'
û 

Ü

r



&



b



'")" )&)&

& $$ p"'" p&p&* |

C,

(

0

¤lpqr'xiø'ºUcunhw\dyozi#24-ë<5
<4  ìíD8J$lznhozfhqr'i

Yb%Q ë b QÀ] êì XKQ é b ]
®$r'x0iLudixlzw\ijvRs0ndmdyoptvRmi£wMnh|mlj'iopinxjmlzjmqdmxRfhqhxnh
w D  BEBE8=D
HUfmijZ&hh­eChhïJvSf
hn r'vSfwMnvRl|nhozopt|oznhssRlptävR'ikmlznhopfhqr'isJnhs0dmxRfhÀopiwMnvRlz|¼fhx»sRrm||LisRsSrmo/D  B=BE8ED lzs6n;nhsSvOnhjmk
iL{6|lpijv*xryopiopinxjmlzjmq&sStusSvSiw k'isR|Lxlpik0lzjOw\fhxiIk'ivRnhlzolzj°H5f'ijZhh­e-hhï¡"¾Ui8k'isR|Lxlz"i
lpv*yxlpi ytJ'ixRiIfhxP|Lfw\dÀopivSij'isRs
 D  B=BE8EDlzsynhsSikOfj¼vR'i ±²ÀÖµR´ ´²y³H¶·ÜµR´RÕ ê Ö´RÕ´LµµÛ÷µ Ô µ ê ²y±
² Z
/Á C~©5$nhopqhfhxlzvRmwók'isR|Lxlz"ik¹lzj?¤mr'xj'gexnhj'ã ¢ölzkyw\ix~høA
 D  BEB=8EDlzw\dmxRf}hisfj£/Á Ca©
¾lpvR0nhj»lj'fhxwMnvRlpfjJqnhlzjOw\ivSxl|PvSf\qrylzk'i$xrmopidmxryjmlzj'q&nhjmkOn\ÚEljmlzw&rmwõisR|LxlpdmvRlpfjOÞÜij'qhvR
fhx~Ú$ÞZHynhsSik'ir'xlzsRvRlz|Gfhx~k'ivSixwlzjmlzj'q'f	¾?wMnhjtCxrmopissRmfrmozk&i5ozinxj'ikOsSiiUfmijOhh­e
hhïEfhx,w\fhxRi0k'ivRnhlzos»ÞÜlpghi6fhvR'ix\opinxj'ixse
 D  BEBE8EDvRnghis,nhs&lj'dyr'vvR'i0jmnhw\isCfh*nsSivCfh
Ö·p¶ éé ´ éavSf&i$opinxj'ikvR'ijmnhwMisUnhjyk6xnhj'qhisUfhÜ}nhozr'isUfhÜnCòmuik6sSiv5fh I´¶h³ ê µS´ émnhjmk ³µS¶±²y±
² Z
Õ¶h³H¶ sSdi|lptulzj'qvR'i\|oznhsRs$nhjmkEinvRr'xi&}nhozr'isfhx$inh|¹iL'nhw\dyopi,lzjn6vSxnhlzjmlzj'qJsSivÁvRsPfrmvSdyr'v
lzsUn Ö·¶ éé ± aÖ¶h³±÷h
² M÷Õ´· fhxUdmxRikmlz|LvRlj'qIvR'i$|oznhsRsUfhr'vRr'xRiiLunhw\dÀopisuiLedyxRisRsSikJnhs5nhj6fhxk'ixRik
sSiv*fhlpHvR'ijOxryopis
ùopvR'fr'q¹nhjt¼fj'i\fhUn0jrmwCix$fhaopinxjmixs$|Lfrmozki&ndmdÀozlpikEvSfJvRylzsdmxRfhyopiw»"¾Ui\mnhkn
jermw8ixKfhDxRinhsSfjms*fhx|'fefsRlzj'N
q D  BEBE8ED)¤lpxsSvmlzvU¾5nhslw\dfhxRvRnhjv5vSfMinyopivSf6lzjvSiqhxnvSiIvR'i
xRisRryopvRs~fh-ndmdyoptulzj'qvR'i$opinxjmixaynh|g6lzjvSf8vRmi  sRd"fhghijJkmlznhozfhqr'iPsStusSvSiwOG©~xRi}ulpfrmsa¾afhxRg
sRr'qhqhisRvRs*vRmnv*vRmiIlpHvRmijOxrmopis5vRynC
v D  BEB=8ED¹rmsSisKvSfMiLudmxRissKvR'iIopinxjmik»|oznhsRsRlpòÀ|nvRlpfjOw\fuk'io
nxRi5inhsSt&fhx)difhdyoziavSfIrmjyk'ixsSvRnhjmk0H5nvRopivSv"hu¡'5f'ijZmhh­uwMngelj'qlzvDinhslpix)vSfIlzjvSiqhxnvSi
vR'iJopinxj'ikxrmopisIljvSf»vRmi  sStusSvSiwOEcei|Lfjmke
 D  BEBE8EDsr'dmdfhxRvRs|LfjvRlzjrmfrms)sStuw8fozlz|
nhjmkvSiLevRrynho~ynqäsSivIinvRrmxRisOHUf'ijZKhhïG¾ylzopiMfhvR'ix,opinxjmixssRrm|;nhsM5oznhsRslòÀ|nvRlpfj
nhjm
k *iqhxRisRslpfjMvSxRiisH5'
ù  ½ *UxlziwMnhjZ¤mxlpikmwMnhju®$ozs'ijZ cevSfj'ihh ømk'fCj'fhvUsRr'dmdfhxRv
vSiLuvRrmnho~ÀnqEinvRr'xRis ½ 'ixRinxiJsSi}hixnho~vSiLuvRrmnhoUinvRrmxRisClj£vRmlzsCkmnvRnhsSiv&vRmnv&dmxRf	}hi0rmsSirmo
lzjö|oznhsRsRlztulzj'q£vRmi¹kylznhopfhqr'is ®$jmiEfhCvR'iEinvRr'xRis0vRynvJ¾Ui¹¾lzsRmikvSfärmsSi¹¾5nhs6vRmi¹sRvSxlzj'q
xRidmxisSijvRlj'q8vR'ixRi|LfhqjmlzãixØÙsKtedfhvR'isRlzs ½ ylzsalsasRrmdmdfhxRvSiklz
j D  BEB=8ED»i|nhrmsSivR'ixRilzsUj'f ¶
Ô µ±÷hµ± olzwMlpvRnvRlpfj$fjCvR'iUsRlpãiGfh'vR'iUsSiv ½ 'i~rmsRirmoj'isRsZfhuvR'iavSiLevRrmnhoinvRr'xRisDlzsiLuiw\dyozlpòyiklzj
cei|LvRlpfj6ïeH ;e~¤lzjmnhozopthhdyxRi}elzfrms¾afhxg&lzjM¾mlz|,¾aiynhkMndmdyozlzikCfhvRmixaopinxjmixsvSf8vR'i ¶ ê ³H÷ èåuæç-è
43

!

Ë

2¤ZÌyÍ¬2­2«¤°2ÎSÏÁ2Ð-Ì

Ë

«7­¼ÑM1«mÌ

Ë

«7­¼ÒÓÏÁ¡2«¬

éê ÖÖ´ éé8dmxRikylz|LvSfhxGr'vRlzolpãlzj'q»vRmiJisSv,dixRfhxwMlzjmq»invRrmxRi»sSiv,¾lpvRvR'i0vSiLevRrynho5ynqinvRrmxRis
xRiw\f}hikZKsRr'qhqhisSvSik?vRmnvM¾Ui¼|Lfrmokäj'fhvMiLud"i|Lv6nhjtäsRlpqjylòÀ|nhjv\d"ixfhxwnhjm|Li»lzw\dmxf	}hiw\ijvRs
xRfw rmsRlj'q,fhvR'ixopinxjmixs8¢£nhopghixPivPnho/pyàáháháh|	
ÛÁ jIfhxkmixÜvSfvSxnhlzjIvRmi~dmxRfhÀopiwMnvRlz|)kmlnhopfhqr'iGdmxikmlz|LvSfhxU©a$©UrD  BEBE8=DMrmsSis-nsSiv-fh'invRr'xis
ùsakmlsR|rmsRsSik6nf	}hih'lzjmlpvRlnho'iLedixlw\ijvRsasR'f¾aikJvRmnvUvR'iPynhjmkuozniozopikJå'æ$çDèéê ÖÖ´ éé)invRrmxRih
¾ml|ijm|Lfuk'is-¾'ivR'ixDnhj8r'vSvSixnhjm|LiUynhsiij8wMlsRrmjmk'ixsSvSffukfhxDjmfhvlsmlpqmoztkmlsR|LxlzwMljmnvSfhxRt
lzjJlzk'ijvRlptelzjmq8dmxRfhÀopiwMnvRlz|Pkmlznhopfhqr'isGªf¾ai}hixÀnhozoyvRmiinvRr'xRisKrysSikJvSf\vSxnhlzj6vR'i©~$©w&rmsSv
iavSfhvRnhooptCnhr'vSfwnvRlz|Klpm¾Ui*nxRi5vSfIrmsSi5vR'iK©~$©£lj&n¾UfhxRgulzj'qsSdfhghij,kmlznhopfhqr'i5sStusSvSiwOÁÛjCfhxk'ix
vSf¹lzw\dmxRf}hivR'iJdixRfhxwMnhjm|LiMfhvR'irmozopt¹nhr'vSfwMnvRl|J©a$©-D¾UiJk'i}hiozfhd"ikn¼rmozoztnhr'vSfwnvRlz|
ndmdmxf'lzwMnvRlpfjfh$vR'i»mnhjykuozniozopikinvRrmxRih5¾mlz|¾ai¼|nhoo5vR'i ¶ ê ³H÷ è åuæ$çDè éê ÖÖ´ éé&invRrmxRih
lzjâsSidynxnvSi£iLedixlw\ijvRs0¾PlpvR
 D  BEBE8=D ½ mivSxnhlzjmlzjmqfh&vR'i ¶ ê ³H÷ è åuæ$çDè éê ÖÖ´ ééJinvRrmxRi£lzs
kmlzs|rmsRsSik0lzjEcui|LvRlpfj¼­e

~}elzkmijm|LiKxfwßdmxRi}ulpfrmsvSxlnhozsfh 
Cf sRr'qhqhisRv~vRmnv~lzvGlzs)lzw\dfhxRvRnhjv)vSf8lzk'ijvRlpt8dmxfhyopiwMs
¾lpvRylzjn|Lfrmdyopi0fhPiL'|ynhj'qhisnhjmkîhñfhPvR'iOkmlnhopfhqr'is\lzj;vR'i»|LfhxRdÀrms\nxRi0òy}hiOiL'|mnhjmqhis
fhxCozisRs ½ ermsinvRr'xRis8fhxIvRmi\òyxsSvv ¾af¼iLu|mnhj'qhis&nxRiMijm|Lfuk'ikslzjm|Li,vR'iMqhfnhoalzsvSf0Ô µR´RÕh±Ö	³
nhlzozr'xRis&ifhxRi0vR'it;yndmdijZ ½ miJiLudixlzw\ijvRnhoKnx|mlpvSi|LvRr'xRiOfhvR'i»©a©õlzs\lzozormsSvSxnvSik;lzj
¤lpqr'xRi»­e ½ mlzs,sRmf	¾s\'f
¾ D  B=BE8EDölzs\rmsSik;òyxsSvCvSfdmxRikmlz|Lv ¶ ê ³H÷ è åuæ$çDè éê ÖÖ´ éé&fhx\vRmi0òyxsSv
nhjmk;sSi|LfjmkiLu|mnhj'qhis ½ mlzs8invRrmxRi6lzsCiklzjvSf¼vR'i0©~$©×nhopfj'qE¾lpvRvR'i6fhvRmix&nhr'vSfwnvRlz|
invRr'xRis ½ miPfr'vSdÀr'v~fhvRmi$©a$©äk'ivSixwMlzjmis~¾mivR'ixavRmisStusSvSiwÓ|LfjvRlzjrmisufhx5lznCdyxRfhyopiw
lzsDdmxRikylz|LvSikZvR'iK$lznhopfhqr'i*Únhjmnqhix~wMn	tCnhkmndyvlzvRs)kmlznhopfhqr'i5sSvSxnvSiqht&fhx)vSxnhjmsRix)vR'iK|rmsRvSfw\ix
vSfnM|rysSvSfw\ixPnqhijv
culjm|Li¹hà ;ñ fhCvR'ikmlznhopfhqrmis6|LfjmslzsSvSikâfhIfjmoztv¾UfäiLu|mnhj'qhis$¾Ui¹iLu|ozryk'iEvRmi¹sRi|Lfjmk
iL'|mnhj'qhiPinvRrmxRis)fhxGvR'fsSi*kmlnhopfhqr'is¾'ixiKvR'i*sSi|Lfjmk\iL'|ynhj'qhiP|LfjmslzsSvRsfjmoptCfhvR'i*sStusSvSiw
dyozn	telj'qn|opfsRlzj'qdyxRfw\dmvD¢inhozsSfiL'|ozrmkmik\nhjt,invRr'xRis)vRmnvalzjmkmlz|nvSik&vSfIvRmi|oznhsRsRlpòyixvRmnv
vR'i~sRi|Lfjmk8iL'|ynhj'qhia¾5nhsvRmiaoznhsSvÜiLu|mnhj'qhi5lzjvR'i~kylznhopfhqr'ih-¢iU|Lfw\dÀnxRiGxRisRryopvRsZfhxÔ µR´RÕh±Ö	³±
² Z
dmxRfhÀopiwMnvRlz|5kmlznhozfhqr'ish¾lpvR,xisRrmopvRsDfhx ±Õ´L²y³± Iý±
y
d
R
x
h
f
y

p
o

i
M
w

n
R
v

l
U
|
y
k
z
l
h
n
p
o
h
f

q
'
r

i

s
h

P
¾
'


i
,
j
R
v
'

*
i

|
z
o
h
n
R
s

s

l
y
ò
ix
² Z
mnhs*nh||LissvSfMinvRr'xRisxRidmxRisRijvRlzjmq&vRmiI¾'fopikmlnhopfhqr'ih
ÛÁ j£fhxkmix8vSf¼vSisRvCvR'i ¶ ê ³H÷ èå'æ$çDèéê ÖÖ´ éédmxRikml|LvSfhxCnhs8lj'dyr'vvSfEvR'i6©a©D-¾aiòyxsSv8kmiLòÀj'ik
n»vSxnhlzjmlzj'q»nhjyk£vSisSv,sSiv8fhx&vR'i6|LfwCylzj'ikdmxRfhyoziwO ½ 'iMvSisSv,sSiv8fhx&vR'i ¶ ê ³H÷ è åuæç-è éê ÖÖ´ éé
dmxRikylz|LvSfhxÜ|LfjvRnhlzjms-vR'iGiL'|mnhj'qhisDvRmnv-fe||rmx-lzjvRmiakmlznhozfhqr'isZfhuvR'ia©a$©¼vSisSvsSivD¢iasSiozi|LvSik
n*xnhjmk'fw hïîkmlznhopfhqrmisnhsÜvRmi~vSisSvDsSiv-nhjmkIvR'ijIiLuvSxnh|LvSik&vR'ia|LfhxxRisSdfjmkmlzjmqUiL'|ynhj'qhisK ;h hàh
iL'|mnhj'qhis×culzwlzoznxoptfhx6vSxnhlzjmlzjmq'UvRmi¼©~$©vSxnhlzjmlj'q£sSiv0|LfjvRnhlzjyP
s ;h hàh­kmlznhopfhqrmisM¾ml|
|LfhxRxRisRd"fjykms5vSfn\vSfhvRnhoÜfh5ïhá'8iLu|mnhj'qhisPfhxvSxnhlzjmlzjmq&vRmi ¶ ê ³H÷ èå'æ$çDèéê ÖÖ´ éé5dmxRikmlz|LvSfhx	
½ miMinvRrmxRi ¶ ê ³H÷ è åuæç-è éê ÖÖ´ éé$lzs8dmxRikml|LvSikfhxCinh|r'vSvSixnhjy|Li6lzjvRmivSisSv&sSivvRrms8iju
nyozlj'q6vRmiMsStesRvSiwóvSfOiMrmsSik¹fjj'i¾ kmnvRn»¾lpvR'fr'v$vR'iMjmiik¹fhx8ynhjmkuozniozozlj'q'Iªf¾ai}hix	
vR'ixRi&nxRi&v¾Uf6dfsRsRlzylzozlpvRlzisafhxvR'i8fhxlzqlzj»fh)vRmls*invRr'xRiClj»vR'iCvSxnhlzjmlzjmqsSiv ½ miIòyxsRv*dfsRsRl
ylzolpvt»lzs$fhxvR'i,vSxnhlzjylzj'q0sSivvSf»nhozsSfO|LfjmsRlsSv$fhasSfopioztEnhr'vSfwMnvRl|,invRr'xis ½ mlzsw\ivR'fukmnhs
vR'i,dfhvSijvRlnho)nhk'}nhjvRnqhiMvRmnvvRmi\vSxnhlzj'ik¹©~$©Ý¾PlzozoD|Lfw\dijmsRnvSihÜlpaj'i|LisRsRnxRthÜfhx¾ynvSi}hix
j'flzsRiiL'lzsSvRslzj0vR'i ¶ ê ³H÷ è åuæ$çDè éê ÖÖ´ ééUdmxRikml|LvRlpfjms¢xlpqvÀàáháhá5ùPjOnhopvSixjmnvRlp}hiIvSfMvSxnhlzjmlzj'q
vR'iI©a©fjOvR'iInhr'vSfwnvRlz|nhozopt0k'ixlp}hik ¶ ê ³H÷ èåuæç-è éê ÖÖ´ ééainvRr'xRiIlzs5vSfvSxnhlzjOlpvKfjOvRmiImnhjmku
ozniozopikEåuæç-è éê ÖÖ´ ééa¾ylzopi$sSvRlzozo"vSisSvRlzjmqlpv5fj»vR'iInhrmvSfwMnvRlz|invRr'xRih ½ mlzsKsSi|Lfjmk¼w\ivR'fuk»lzs
xRiixRxRikOvSfJnhs6Synhjmkuozniozopik'HvSxnhlzjmlzjmqIfhx [·!³ è åuæ$çDè éê ÖÖ´ éé ½ mlzsKwMn	tOdmxRf}elzkmiInw\fhxRiCnh||ru
xnvSi\w\fuk'io-yr'vPlzvwMn	tEj'fhv$|ndmvRr'xiCvR'i\|mnxnh|LvSixlzsRvRlz|s$fhGvR'i,nhr'vSfwMnvRlz|&invRr'xRi\lzjEvR'i&vSisSv
sSiva
 isRrmopvRs*fhx*vRmisSiIv¾Ufw\ivRmfekmsnxRiIdmxRisRijvSik»lj¼cei|LvRlpfj¼ïe ø'
43p&

>

> ¡9?¢f«7A@d«.¤¡­2±2

°«7«¬2­

SLU Features
Exchange 1

SLU Features
Exchange 2

auto−SLU−success
Feature Predictor
Exchange 1

auto−SLU−success
Feature Predictor
Exchange 2

System
Continues

Yes
Automatic
Features
Exchange 1&2

PDP
P(Success)>T
No

¤lpqrmxRi8­eºUcetusSvSiw

D

B

C

nx|mlpvSi|LvRr'xi8rmsRlzjmq&invRr'xRisxfw
auto−SLU−success
predictor training and testing

A

A

B

C

D

PDP Training Set

−Adapt DM
−Transfer to
Human
Customer
Agent

vR'i$òyxsRvà,iLu|mnhj'qhis

A

B

C

D

Test

TEST
PDP Test set

¤lpqr'xRi8ïeºanvRnfhxPsSiqw\ijvRnvRlpfjErysRlzj'q\|LxRfsRsSH}nhozlkmnvRlpfj
½ miCdmxfhyopiw ¾lpvRrmsRlzj'q ¶ ê ³H÷ è åuæ$çDèéê ÖÖ´ ééfhx$vSxnhlzjmlj'qvR'i\©a©lzsvRynvvR'i&snhw\i\kmnvRn
zl sOrmsRikÝvSfvSxnhlzjâvRmi ¶ ê ³H÷ è åuæ$çDèéê ÖÖ´ ééJdmxRikmlz|LvSfhx	 ½ 'ixRifhxRih$¾airysSikÝn|LxRfsRsSH}nhozlkmnvRlpfj
vSi|yjmlz¿er'iEnhozsSf¼gej'f¾jnhs% Snh|gHgujmlò"j'qM¢ilzssC¢¡8rmozlpghf¾sSgul/~hu	)¾'ixitvR'ivSxnhlzjmlzj'q
sSivIlzs$dÀnxRvRlpvRlpfj'ikljvSfOø»sSivRs ½ 'xRii,fh5vR'isSiMsSivRs8nxRirmsSik¹fhxvSxnhlzjylzj'qOnhjmk¹vR'i\fr'xRvR¹fhx
vSisSvRlzjmq' ½ 'i&xRisRrmozvRsPfhxvR'i,fr'xRvR¹sSivnxRi\j'fhvSiknhjmkvR'i,dmxRfu|LisRslzsxRidinvSikZZxfhvRnvRlzj'q0vR'i
sSivRsPxfw vSxnhlzjmlj'q\vSfvSisSvRlj'q' ½ mlzs5xRisRryopvRs*lzj»n6|Lfw\dyopivSi&ozlzsSv5fh)dmxikmlz|LvSik ¶ ê ³H÷ è åuæç-è éê ÖÖ´ éé
fhxKvR'ivSxnhlzjmlj'qCsSiv ½ 'i$invRrmxRisKfhxKvR'ivSisSv*sSivKiL'|mnhjmqhisnxRik'ixlz}hik0t6vSxnhlzjmlzjmb
q D  BEBE8ED
fjOvR'i8¾'fopi$vSxnhlzjylzj'q\sSiv ½ ylzs5dmxRfu|LisRs*lzsKlozozrmsSvSxnvSikJljO¤Dlzqr'xRi8ïe
½ miCfozopf¾lzj'qsRi|LvRlpfjqlp}his$n6yxRingekmf	¾jEfhGvR'i\lzj'dÀr'v*invRr'xRisIcei|LvRlpfj­Jk'isR|Lxlz"isvR'i
vSxnhlzjylzj'q6nhjykExisRrmopvRsPfhGvR'i ¶ ê ³H÷ è åuæ$çDè éê ÖÖ´ éé*dyxRikmlz|LvSfhxnhjmk£cei|LvRlpfjï6xRidfhxRvRsPvR'i\nh||r'xnh|Lt
xRisRryopvRs5fhxvR'i8©~$©D

£GYNMPORQJ¤Q ìê`lë Q
é

43	3

Ë

2¤ZÌyÍ¬2­2«¤°2ÎSÏÁ2Ð-Ì

Ë

«7­¼ÑM1«mÌ

Ë

«7­¼ÒÓÏÁ¡2«¬

 ¦½§¶B´\¦¨ª©«­¬~´§#¶
¥ P

® xi|Lfhq'xRi|LfhqjermwC¾afhxkysnhsSxRkmr'xnvRlpfjkmvRw\"nq'xRqw\fukmnhozlpv thhxRqHqhxnhwMwnxvSiw\df
¥ ©Z¥°¯±¬~´§#¶
® n|Lfj'òÀk'ijm|LiOw\inhsRrmxRi0fhx\inh|fhvRmi¹­dfsRslpyopi6vRnhsSgesMvRmnv,vR'i»rmsSix\|Lfrmozki
vSxtelzjmq\vSfk'f

® snhozlpijm|LiL|Lf}hixnqhih ljm|LfjmsRlzsRvSijm|LthÝ|LfjvSiLuvÛsRmlpvvSfhdmHvRnhsSgÀ 'j iLevSvSfhdmHvRnhsSgÀvSfhd'
|Lfj'òÀk'ijm|Lihykyl§À|Lfj'òÀk'ijm|Lihm|Lfj'dixRvRlzw\ih'sRnhozd"ixvRlzw\ih'nhr'vSfcuÞ
*
: sRry||LisRs
¥J²

9§

~2½§ #è}p~2#~$§u~2#¨

² ¶<¦½§¤¶Bè²Y¶´½2³¬~´§#¶

® sRtesÛon"ioHurmvSvÛlzkZ'dmxRfwMdmv'xRidmxRfwMdmvm|LfjuòyxwnvRlpfjZ'sRr'Zkmlznho

® xrmjmjmlzjmq;vRnhoozlpisºjermw,r'vSvRsIjrmw\HxRidmxRfw\dyvRs$d"ix|LijvÛHxRidyxRfw\dmvRsjermw,|LfjuòÀxwMs
dix|LijvÛ|LfjuòyxwMsmjermw,sRr'Zkmlnhozsdix|LijvÛsRr'Zkmlnhozs

® ¾P'fopiIkmlznhozfhqr'ihºGkmlznhokyr'xnvRlpfjZ
´ '¨µ#
¬ ~$´
§ ¤¶
¥ ²Y~2#¨©¥P~El
® vRs|LxlpdmvÓrywMnhjuoznio/ nqhihÓqhijmkmix rmsSixSw\fukmnhozlzvthõ|ozinhjuHvRsR|Lxlpdyv|opvRs|LxlpdmvÛ
jermwC¾afhxkmsÀcuÞ
*
: sRry||LisRs
¤Dlzqr'xRiCîº~¤'invRrmxRisfhxsSdfhghij»kylznhopfhqr'is

ùÝkmlnhopfhqr'i|LfjmslzsSvRsGfhnCsSi¿er'ijm|LifhZiL'|ynhj'qhisU¾'ixRiPinh|JiLu|mnhj'qhi$|LfjmsRlzsRvRsGfhZfj'iPvRr'xj
etvRmisStusSvSiw¬fozopf¾aikt¹fj'iMvRrmxjetvRmirmsSixP~nh|kmlnhopfhqr'iMnhjmkiLu|mnhj'qhi6lsijm|Lfuk'ik
rmsRlj'q6vRmiMsSivIfhKh­ ;0invRrmxRisIlzj¹¤lpqr'xRi6î
 anh|£invRr'xRi\¾5nhsIilzvR'ixInhr'vSfwMnvRlz|nhooptozfhqhqhikt
fj'iMfh5vR'i6sStesRvSiwÂw\fukmrmozismnhjmkuon"ioopiktermwMnhjmsÜfhxCk'ixlz}hikxfw¬xn	¾ invRr'xRis ½ 'i
mnhjmk'ozniozopik&invRrmxRisanxiPrmsSikMvSfCdmxfekmry|Li*
n 2FByì  i8ZnhjMisRvRlzwMnvRlpfjfh'f	¾?¾aiozoÀnI|oznhsRslòyix
|Lfrmozk0k'f,vRmnv*ynhkOnh||LisRsKvSf\dixRi|Lv*lzj'fhxwMnvRlpfjZ ½ fMsSii¾'ivR'ix5fr'xKxisRrmopvRs5|nhjOqhij'ixnhozlpãih
¾Ui&nhozsRf6iLudixlzw\ijv¾lzvR¼rmsRlj'qnJsRr'ysSivPfhGinvRr'xRisvRmnv$nxRiCvRnhsRglzjyk'idijmk'ijvPk'isR|Lxlpik»lzj
k'ivRnhlzo"iozf	¾I
¤'invRrmxRisopfhqhqhiktvR'i»sStusSvSiw°nxRi»r'vRlozlpãik"i|nhrysSiOvR'itnxRi0dmxRfukmrm|Liknhr'vSfwMnvRlz|nhoopth
nhjmkövRerms0|nhjâ"i¹rmsSikâkmrmxlzj'q£xrmjvRlw\iEvSfänhopvSixOvRmi¹|LfrmxsSifh8vR'ikmlznhozfhqr'ih ½ 'i¹sStusSvSiw
w\fukmrmopisGfhxa¾mlz|opfhqhqlzjmq8lzj'fhxwMnvRlpfjM¾UnhsU|Lfozopi|LvSik6¾aixivR'inh|LfrmsSvRlz|dmxRfu|LisRsSfhlx knhr'vSfwnvRlz|
sSdii|,xi|Lfhqjmlpãixg 4-<ë DÜ~g Plz||nxkml'Ý«fhxlzjhàáháhávR'iKsSdfhghij,oznhj'qrmnqhiKrmjmkmixsSvRnhjmkmlj'qCHëìí-
w\fukmrmopi8H«$fhxlzj6ivanho/phîhmnhjmkMvRmiP$lznhopfhqr'iÚEnhjynqhixg y  ùiozon8 «$fhxlzjZ"hha
 ~nh|
w\fukmrmopinhjmk0vRmiIinvRrmxRis*fhmvRnhlj'ik0xfw lpv*nxRi8kmisR|LxlpikJiopf	¾I
A§´q½9¶ ~´\¦©·l¦³¸«õ1¦½2§#´½ º ½ 'i»nhr'vSfwMnvRlz|OsRd"ii|äxRi|LfhqjmlzãixEg 4-ë DÜCvRnghis6nhs
lzj'dÀr'vIvR'iO|nhozopix	ØÙs&sRd"ii|nhjmk;dmxRfukmrm|Lis&nEdfhvSijvRlznhozoptixxRfhxRrmoGvSxnhjysR|LxlpdmvRlzfjfh*¾Pmnv&lzvCiL
ozlpi}his*vR'i8|nhozopixPsRnhlzkZ ½ '
i 4-ë D¹invRr'xRisfhxinh|EiLu|mnhj'qhiCljm|ozrmk'i$vR'i8fr'vSdyr'vKfhvR'i8sRd"ii|
xRi|Lfhqjmlzãix µR´RÖ}÷ Z PvR'iEjermwCixfh¾UfhxkmsJlzjvR'iExRi|Lfhqjmlpãix0fr'vSdÀr'vE µR´RÖ÷ Z è ² ê &û~÷hµÛÕ éRvR'i
kmr'xnvRlpfjlzjsSi|Lfjmkysfh5vR'ilzj'dÀr'vPvSf¼vR'iMxRi|LfhqjmlzãixJ ¶ é µ è Õ ê µÛ¶³±÷² GA
n ÀnqOfhx8vSfrm|vSfj'iJlzju
Vp$p$

>

°«7«¬2­

> ¡9?¢f«7A@d«.¤¡­2±2

dyr'v Õh³gI èo¹ ¶<Z ÀvR'ilzj'dyrmvaw\fukmnhozlpv tMiLud"i|LvSik»t6vR'i$xRi|LfhqjmlpãixC µZ è M÷Õ¶·!±³ý 8fj'ifhºGj'fj'ih
sSdii|vSfrm|vSfj'ihsSdii|9º$vSfrm|vSfj'ihDvSfrm|vSfj'iL|nxkZsSdii|ºvSfrm|vSfj'iL|nxk-vSfrm|vSfjmiL
kmnvSihsSdii|9
 ºvSfrm|vSfj'iLkynvSihÜfhxj'fj'iL/òÀjynhoHdmxRfw\dyv"nhjmkvR'i,qhxnhwwMnxrmsSikt¼vR'iCxi|Lfhq
jmlpãix\ µ Z è ZhµSr¶ +\¶hµ ,g Plz||nxkml«$fhxlzjZàáháhá¢i\nhozsRfJ|nhoz|ryoznvSiCn6invRrmxRi&|nhoopik ³´  Ô ÷ t
kmlp}ulzkmlj'q8vR'i8}nhozrmifhvR'i ¶ é µ è Õ ê µS¶h³±/÷² invRr'xiItJvR'i µR´RÖ}÷ Z è ² ê ,û~÷µSÕ éinvRr'xRih
i 4-<ë DinvRr'xRislzs&vRmnv\nhjt;fj'i0fhPvRmiw wMnt;xRi yi|Lv,xRi|LfhqjmlzvRlpfj
½ mi0wMfhvRlp}nvRlzfjfhx\vR'»
dixRfhxwMnhjm|Li6¾lpvRn|Lfjm|LfwMlzvRnhjv,iL§i|Lv&fjsSdfhghij;oznhj'qrmnqhi0rmjmkmixsSvRnhjmkmlj'q'»¤'fhx,iLunhwMdyopih
fhvR'ixP¾afhxRgOmnhsfryjmk ¶ é µ è Õ ê µÛ¶h³±/÷² vSfiI|LfhxRxioznvSik»¾lzvR»lzjm|LfhxRxi|Lv*xRi|LfhqjmlpvRlzfjªPlzxsR|ixRq'
ÞÜlzvRwMnhjZce¾UixRvRsÀhh ½ 'iKjmnhw\iKfh"vR'iKqhxnhwwMnxP µ Z è ZhµSr¶ +\¶hµ ~|Lfrmozk\nhozsRfi*n$dmxikmlz|LvSfhx
fh~ëìíixRxRfhxssRlzjm|Li8lzv*lzsK¾UiozoZguj'f	¾j»vRmnvvR'iCoznxRqhix*vR'i8qhxnhwMwMnxlzsmvR'iCw\fhxRi8ozlzghiopt6nh
j 4-ë D
ixRxRfhx-lzsÜÁÛjnhkmkmlzvRlpfjZvR'i gµ Z è ZµÛr¶ +M¶µ invRr'xRianhozsSfKijm|Lfuk'isZiLudi|LvRnvRlpfjmsÜnfr'vrysSixÜr'vSvSixnhjy|Lis
nv\vRmnv,dflzjv&lzj;vR'iOkmlnhopfhqr'ihG¾ylz|;wMnt|LfhxRxRionvSiOvSf¹kyl§"ixijm|Lis\lzjvR'iOinhsSiO¾lpvR¾ml|
nhjtJfjmi8xRi|LfhqjmlzãixP|Lfrmozk¼|LfhxRxRi|LvRopt»rmjyk'ixsSvRnhjmk0vRmi8rmsSixØÙsxRisSdfjmsSihK®$j'iIw\fhvRlz}nvRlpfj¼fhxPvR'i
³´  Ô ÷ invRrmxRiKlzsDvRmnv)dmxRi}ulpfrms-¾afhxgCsRr'qhqhisRvRs)vRmnvGrmsSixs-vSijyk,vSfIsRopf	¾äk'f¾j,vR'ilpx)sSdii|,¾'ij
vR'i0sStusSvSiwmnhs,wMlzsRrmjyk'ixsSvSfefek£vR'iw Þi}hf	¾8hh e¡cu'xlpixRq'D¢£nhk'iha ©Gxlz|Lih*hhà¡5vRmlzs
sSvSxnvSiqhtMnh|LvRrynhozopt\opinhkms~vSf8w\fhxRiPixRxRfhxsGslzjm|Li*vR'iPsSdii|Mxi|LfhqjmlpãixalsGj'fhv~vSxnhlzj'ik\fjvRmlzs)v tdi
fh-sRd"ii|Z ½ mi ³´  Ô ÷ invRr'xRiIwMn	t6nhozsSfMljmkmlz|nvSi$'isRlpvRnvRlzfjmsudynhrmsSisefhx*ljvSixRxr'dmvRlpfjms¾ml|
|LfrmozknhozsRfopinhkvS
f 4-<ë DixxRfhxs®$j;vR'i0fhvR'ixMynhjmkZ)vSfrm|vSfj'i»lj'dyr'v&lzj|LfwCylzjynvRlpfj;¾lpvR
sSdii|unhs5ijy|Lfek'ik0etMvR'i$invRr'xRi Õhg³ I oè ¹ <¶ Z mwMlpqv5ljm|LxRinhsSivR'iozlpghiozl'ffukMfhDrmjmk'ixsSvRnhjmkmlzjmq
vR'i¼sRd"ii|Zº¼sRljm|LiOvR'iOvSfrm|vSfj'i¹lzj'dÀr'v&lsMrmjmnhwCylpqr'frys\lpvM|nhj|LfjmsSvSxnhlzjsSdfhghijonhj'qrmnqhi
rmjmkmixsSvRnhjmkmlj'q'
©·l½2ß¥P~2#§9§#~$§2¼¯Ã#¨#¤¶´q~2#¨n'#§ º ½ 'iIqhfnho-fh)vR'iCsRd"fhghijEoznhj'qrmnqhi&rmjmk'ixsSvRnhjmkmlzjmq
Hëìí-Dw\fukmrmopiKlzsvSfClzk'ijvRlptC¾mlz|,fhÀvRmi8­$dfsRsRlpÀopiavRnhsRges~vR'i*rmsSix~ls)nvSvSiw\dmvRlzj'qCnhjmk,iLevSxnh|Lv
xRfwÓvR'iIr'vSvSixnhjy|Li8nhjt0lpvSiwMs5fhlzj'fhxwMnvRlzfj6vRynvnxRixRiopi}nhjvKvSf|Lfw\dyopivRlj'q,vRmnvKvRnhsSg"mih q'
n\dymfj'ijrmwCix*lzs*j'iikmikOfhxvR'iIvRnhsSg Õ±/¶½· I÷
µ ´ 
¤lpvSiijfhUvR'i\invRrmxRisxRfwóvR'i6ëìíäw\fukmrmopi&xRidmxisSijvvRmiMkmlzsSvSxlzyr'vRlpfj¼fhxIinh|£fhUvR'i
­¼d"fssRlpyopi,vRnhsSgus&fhKvR'i0ëìí?w\fekyrmopihØÙsI|Lfjuò"k'ijm|Li6ljlpvRs8"iolpiavRynv8vR'iJrmsSix,lzs8nvSvSiw\dyvRlzj'q
vRmnvIvRnhsRgäH«$fhxlzjiv8nhoHpahîhJ¢i6nhozsSf»ljm|ozrmk'i\nOinvRr'xRi\vSfExRidmxRisRijv¾ylz|¹vRnhsSg£ynhsvR'i
mlpqmisSvK|LfjuòÀk'ijm|LisR|Lfhxi ³H÷ ÔÀè ³H¶ é ¾ynhjmk0¾ml|JvRnhsSg0mnhs5vR'isSi|Lfjmk»ylpq'isSv5|LfjuòÀk'ijy|Li$s|LfhxRi
 ²"´ ¿³/³H÷ ÔÀè ³H¶ zé ¾ynhsU¾UiozoÀnhsUvR'i}nhozr'ifhÜvR'iylpq'isSvU|LfjuòÀk'ijm|Li$sR|LfhxRi\ ³H÷ ÔÀè Ö÷h<² aÕ´²ÀÖ´ Ànhjmk6vR'i
kml§ixRijm|LiIlj0}nhozrmisKiv¾Uiij»vR'ivSfhdnhjmk»j'iLuvÛHvSfHvSfhd|Lfj'òÀk'ijm|LiIsR|LfhxisC Õ± À è Ö÷<² UÕ´L²ÀÖ´ 
®vRmixJinvRr'xRisJxRidyxRisSijv6fhvR'ix»nhsRd"i|LvRsJfhCvR'iëìí dmxRfu|LisRsRlzjmqfhIvR'i¹r'vSvSixnhjy|Lih ½ 'i
±²ÀÖ÷² é ± é ³´L²"Öý invRr'xRi¼lzs\nhjlzjvSxnr'vSvSixnhjm|Li¼wMinhsRr'xRiOfh$sSiwMnhjvRlz|Okmlp}hixsRlpvth5nh||Lfhxkmlj'qvSfn
vRnhsSg¼wMfek'ioÜfh)vR'i,k'fwMnhlzj;ùiozozn6«fhxlzjZ-hhIcefw\i&vRnhsSg»|oznhssSisfe||r'xvSfhqhivR'ixI¿ermlpvSi
jmnvRr'xnhozoptM¾lzvRmlzjJnMsRlzj'qozisSvRnvSiwMijvPfhxKxRi¿rmisSvmih q'GvR'i Õh±¶
· IL÷3
µ M´ vRnhsSg0lzsK|Lfw\dynvRlpÀopi$¾lpvR
vR'i Ö÷··z´RÖ	³DÖ¶·· vRnhsSg"Àr'v)lzsj'fhvG|Lfw\dynvRlpÀopi5¾lpvR&vR'
i  ±··#±
² Z,ÖµR´RÕ±³ vRnhsSg" ½ 'ié ¶h·#±H´L²ÀÖ´ è Ör÷ Áh´LµS<¶ Z´
invRr'xRi,w\inhsRr'xRisPvR'iCdmxRfhdfhxRvRlpfj¼fh)vR'i&rmvSvSixnhjm|Li&¾mlz|¼lzsP|Lf	}hixRik¹et»vR'i&sRnhozlpijvqhxnhwwMnx
xnqw\ijvRs ½ mlzsCwMnt;lzjm|ozrmkmiMvR'iJ¾'fopi6fhndy'fj'i6fhx,|nxk;jermwCix&lp*lzv8fu||r'xs&¾lpvRmljn
xnqw\ijv ½ 'i Ö÷h²y³}´ ¿³ èé [± IL³ invRr'xRiIlzsKnhjOljvSixSrmvSvSixnhjm|Li8w\inhsr'xRi$fh-vRmiiLevSijv*fhn&smlpvUfh
|LfjvSiLev*n	¾Un	tJxRfwvR'i|r'xRxijvUvRnhsSgfu|rms'|nhrmsSikJetvR'i$ndmdinxnhjm|Li$fh-snhozlpijvadymxnhsSisavRmnv
nxRi8ljm|Lfw\dynvRlpÀopiP¾PlpvROlpvmnh||Lfhxkmlj'qMvSfn\vRnhsRg0wMfek'iofhDvR'i8kmfwMnhlzjZ
ÁÛjnhkmkylpvRlpfjZsRlzwlzoznxOvSfövR'i¾5ntÝ¾Ui;|nho|rmoznvSik¯vRmi ³´  Ô ÷ invRr'xRihC¾ai;j'fhxwMnhozlzãi£vR'i
é ¶h·#±H´L²ÀÖ´ è Ör÷ Áh´LµS<¶ Z´ nhjyk ³H÷ ÔÀè Ö÷h<² aÕ´²ÀÖ´ invRr'xRisPtOkmlz}elzkylzj'q,vR'iw et ¶ é µ è Õ ê µÛ¶³±÷² vSf6dmxRfukmrm|Li
vR'ié ¶h· Ô ´µ³\± ´ nhjyk Ö÷<² I Ô ´µ³\± ´ invRr'xRis ½ 'i ³´  Ô ÷ nhjmk;vR'i Ö÷p² I Ô ´µ³\± ´ nhjmköé ¶· Ô ´LµL³f± ´
invRr'xRisnxiIrmsSikOfjmozt6fhx*dmxRikylz|LvRlzj'q ¶ ê ³H÷ è åuæ$çDèéê ÖÖ´ éé
Vp$T

Ë

2¤ZÌyÍ¬2­2«¤°2ÎSÏÁ2Ð-Ì

Ë

«7­¼ÑM1«mÌ

Ë

«7­¼ÒÓÏÁ¡2«¬

½ mi5wMfhvRlp}nvRlzfj\fhx)vRmisSiëìíJinvRr'xisGlzsvSf8wMnghi*rysSiKfh"lj'fhxwMnvRlpfj&vRmnv)vR'iPëìíOw\fukmrmopi
 nhs6nhsn£xisRrmopv\fh$dmxRfu|LisRsRlj'qvR'i¼frmvSdyr'vMfh#4-ë<DÝnhjmkvR'iE|r'xRxRijvkmlzs|Lfr'xsSi»|LfjvSiLev¯¤mfhx
m
iL'nhw\dyopihfhxCr'vSvSixnhjy|LisCvRynvCfozopf¾ vR'iòyxsSv8rmvSvSixnhjm|Lih)vR'iOëìí?w\fukmrmopiMguj'f¾sI¾ynv8vRnhsSg
lpvOiozlpi}his0vRmi|nhozopix¼ls0vSxRtelj'qävSf|Lfw\dyozivSih ½ 'i Ö÷²y³´ ¿³ è é [± I³ invRr'xilzjm|LfhxRdfhxnvSis»vRmlzs
guj'f	¾ozik'qhifhKvR'iJkmlzsR|LfrmxsSiMmlzsRvSfhxRth¾lpvRvR'iJw\fhvRlp}nvRlpfjvRmnvClpKlpvCndmdinxsIvRmnv&vR'iJ|nhozopix
mnhs*|mnhj'qhikE'ixwMlzjykZuvR'ijOvR'iCëìí£w\fukmrmoziwMn	tOmn}hi&wMlzsRrmjyk'ixsSvSfefekJnhj»r'vSvSixnhjm|Lih
² ~2½2§§ß}p~2#~$§2 º ½ 'iJrmjm|LvRlpfj;fhvRmi0$lznhozfhqr'iOÚEnhjmnqhix6lzs&vSfvRnghiEnhs\lzj'dyr'vCvR'i
fr'vSdyrmvfhGvR'iMëìíw\fukmrmozihÀk'i|lzkmi8¾mnvPvRnhsSg¼vRmiCrmsSix$lzsPvSxRtulzj'qvSf0nh||Lfw\dyolzsRZ"k'i|lzk'iC¾mnv
vR'iJsStesRvSiw¬¾lzoo)sRnt£j'iLuv)nhjmkrmdkynvSi\vR'i6kmlsR|Lfr'xsSiMylzsSvSfhxRtùP"ioozn» «fhxlzjZahh ½ 'i
$lznhopfhqr'i,ÚnhjmnqhixIk'i|lzk'isP¾'ivRmixlpviozlpi}hisvR'ixRi,lzsPnJsRlzjmqopiCrmjynhw8ylzqr'frms*vRnhsRg»vRmnv$vR'i
rmsSixPlzs5vSxRtulzj'q\vSfnh||Lfw\dÀozlzsRZ'nhjmk¼'f	¾¯vSfxRisSfop}hi8nhjtOnhw8Àlpqrmlpv th
¤'invRrmxRisKynhsSik0fjOlj'fhxwMnvRlpfj6vRmnvKvR'i$lznhopfhqr'iÚnhjmnqhixopfhqhqhikOnfr'vKlpvRsKk'i|lsRlpfjmsafhx
invRr'xRis*xidmxRisSijvRlzj'q\vR'iCfj'qhflzj'q6mlzsSvSfhxRt6fh)vR'i8kmlnhopfhqr'iIwMlpqv*iIrmsSirmodmxikmlz|LvSfhxsKfh~ëìí
ixRxRfhxs8fhx&vRnhsSg£nhlzozr'xihcefw\i6fh*vR'idfhvSijvRlznhozopt£ljvSixRisRvRlzj'q¼$lznhopfhqrmiJÚnhjmnqhix\i}hijvRs&nxlzsSi
kmr'ivSfJopf	¾ßëìí£|LfjuòÀk'ijy|Li8opi}hiozsK¾Pmlz|¼opinhkOvR'i&lnhopfhqr'i8ÚnhjmnqhixvSf µS´ Ô µSr÷  Ô ³ vR'i8rmsRix*fhx
Ö÷h<² Glµ  lzvRsrmjmk'ixsRvRnhjmkmlzj'q'$ù xidmxRfw\dmv$wMlpqv$i&nJ}nxlznhjvfhavR'i\sRnhw\i\¿er'isSvRlpfjvRmnv¾5nhs
nhsSghik"ifhxRihfhxUlpvG|Lfrmozk\ljm|ozrmk'i5nhsSgulzj'qvR'iPrmsSixGvSf8|'fefsSi*iv¾UiijMv ¾afCvRnhsSges~vRmnv~mn	}hiiij
nhsRsRlzqj'ik¹sRlzwMlzonx|LfjuòÀk'ijy|Lis$t»vRmiMëìí;w\fukmrmopih$¤'fhxiL'nhw\dyopihZlzjEvR'i\kmlznhopfhqrmi&lzj¤lpqr'xRi\à
vR'i&sStesRvSiw rmvSvSixnhjm|Li,lzjÂ
c ;|LfrmjvRsnhsn6xRidmxRfw\dyvi|nhrmsSi&lpvPlzsPn}nxlznhjvfh)vRmi&¿er'isSvRlpfjElzj
r'vSvSixnhjy|Li&c'àe
½ mi&invRr'xRis8vRmnv¾Ui\iLevSxnh|LvCxfw¦vR'iM$lznhopfhqr'iMÚnhjmnqhixCnxi\vR'i\vRnhsSgHvted"i6oznio/é ý éè
·p¶  ´· ¾mfsSi£sSiv»fh&}nhor'isOlzjm|ozryk'in}nhozrmivSf?lzjmkmlz|nvSi¹¾mijÝvR'i£sStusSvSiw mnhklzjmsRru{J|lpijv
lzj'fhxwMnvRlzfj0vSfk'i|lzk'i$fj»nsSdi|lòÀ|vRnhsSgHvted"ihÀvR'iIr'vSvSixnhjy|Li8lzk0¾lpvRylzjJvR'i8kmlznhozfhqr'iMê ³/³ è ±/Õ 
vR'ijmnhw\i*fhZvR'idmxRfw\dmv~dyoznthikvSfCvRmirmsSix$Ô µÛh÷  Ô ³ ynhjmkM¾P'ivR'ixGvR'iPvtedifhdmxRfw\dyvG¾UnhsUn
xRidmxfw\dmv µS´ Ô µÛh÷  Ô ³ "n\|LfjuòÀxwMnvRlpfj Ö÷h<² Glµ  yfhx*n\sRr'Zkmlznhopfhqrmi*dmxRfw\dyv$n\sRrmd"ixsSivafh-vR'i
xRidmxfw\dmvRs)nhjmk\|LfjuòÀxwMnvRlpfj,dmxfw\dmvRsK é=
ê  Õh±¶· S ½ miPé ý éè ·¶  ´L· invRr'xRi*lzs)lzjvSijmk'ik&vSf8|ndyvRr'xRi
vR'iJnh|Lv,vRmnv,sSfw\iJvRnhsSgus,wMnt"iJmnxk'ixCvRmnhj;fhvR'ixs ½ 'iEê ³/³ è ±/Õ invRr'xiJlzs&w\fhvRlp}nvSik;t
vR'ilk'in0vRmnvIvR'i6opij'qhvRfh5vR'ikylznhopfhqr'iMwMn	t¹"i6lzw\dfhxRvRnhjvdfsRsRlpyozt¼lzj|LfwCylzjmnvRlpfj£¾lpvR
fhvR'ix$invRr'xRisozlpghi6é ý éè ·p¶  ´·  ½ 'iCkmlp§"ixRijvdmxRfw\dmvPinvRrmxRis$fhxlzjylpvRlznhodyxRfw\dmvRs"xRidmxfw\dmvRs
|LfjuòyxwMnvRlpfjdmxRfwMdmvRs,nhjmkäsRr'Zkmlznhozfhqr'idmxfw\dmvRs\nxRiOw\fhvRlp}nvSikäetxisRrmopvRs,lzjmkylz|nvRlzj'qEvRmnv
xRidmxfw\dmvRs~nhjyk|LfjuòyxwMnvRlpfj\dmxfw\dmvRs~nxixrmsSvSxnvRlj'qfhxU|nhozopixsanhjmkMvRynva|nhozopixs~nxRiozlpghiopt&vSf
tdixnxRvRl|rmoznvSi¾P'ijvRmitmn}hivSf,xRidinvUvR'iwMsSioz}hisu¾mlz|xRisrmopvRsUlz
j 4Dë D»ixxRfhxs$Hcu'xlpixRq
ivnho/p-hhàe¡ÀÞi}hf¾I-hh e¡À¢£nhopghix
 ¡InhwMwOyßÞ-lpvRwMnhjZyàáháháhn
½ miEkmlzs|Lfr'xsSi¼ylzsSvSfhxRtäinvRr'xRis0lzjm|ormk'ikxrmjyjmlzj'qvRnhozolpisMfhx6vRmijermwC"ix6fhIxRidmxfw\dmvRs
 ² ê  è µR´ Ô µÛr÷  Ô ³ éRDjermwCixPfh~|Lfj'òyxwMnvRlpfjEdmxRfwMdmvRs\ ² ê  è Ö÷h<² Glµ  éRÜnhjmkjryw8ixfhasRr'Zkmlp
nhopfhqr'iCdmxRfw\dyvRs8 ² ê  èéE
ê  Õ±/¶· éRÀvRynvPmnhkOiij¼dyoznthik¼ifhxRi8vR'i8r'vSvSixnhjy|LiC|r'xRxijvRoptJilzj'q
dmxRfu|LisRsSikPnhsO¾Uiozo$nhs0xrmjmjylzj'q£dix|LijvRnqhisÔ ´µÛÖ´L²y³ è µR´ Ô µSr÷  Ô ³ é cMÔ ´LµSÖ´²y³ è Ö÷<² Glµ  é c&Ô ´µÛÖ´L²y³ è
é=
ê  Õ±¶h· éR ½ 'i8rmsRiIfhxrmjmjmlj'qCvRnhoozlpis*nhjmk¼dix|LijvRnqhis$lzs*ynhsSik»fj¼dmxRi}ulpfrmsK¾UfhxRgOsRr'qhqhisRvRlzj'q
vRmnv~jmfhxwMnhozlpãik&invRr'xRisGnxiw\fhxRi*ozlzghioptIvSfIdmxfekmry|LiUqhijmixnhozlpãik,dmxikmlz|LvSfhxs*Þ-lpvRwMnhjZ¢£nhozghix
 ¡inxjmsDhhù×invRr'xRi,n}nhlzoznÀopiIfhx ±/Õ´L²À³± Iý±
Ã
² Z dmxfhyopiwMnvRlz|8kmlznhopfhqr'isPlzs Õh±¶· è Õ ê µÛ¶h³±/÷²
vRmnvlsKj'fhvn}nhlzoznÀopifhxPlzjmlpvRlznhosSiqwMijvRsfh-vR'iCkmlznhopfhqr'ih
²Y~2¨Y¥,~=´l'''§ º	ùsÜw\ijvRlpfj'ikCn"f}hihvR'iGinvRr'xRisfhyvRnhlzj'ikI}ulznKmnhjykuozniozozlzjmqanxRiUrmsSik
vSf&dmxRf	}ulzk'i*+
n 2FByì  i8MnqnhlzjmsSva¾mlz|MvSf&|Lfw\dynxRivR'idixRfhxwMnhjy|Li*fhZvR'irmozoztCnhr'vSfwMnvRl|in
vRr'xRis ½ miamnhjmk'ozniozopikinvRr'xRislzjm|ormk'i~ermwMnhjCvSxnhjmsR|LxlpdmvRsfhyinh|\rmsSixr'vSvSixnhjy|Li ³ é Öµ± Ô ³ 
n£sSivfh$sRiwMnhjvRl|»ozniozs,vRmnvnxi¼|opfsSioptxRionvSikävSfvR'i»sRtesSvSiw vRnhsSgHvted"iozniozs» [ ê M¶² è
Vp$ 4

>

°«7«¬2­

> ¡9?¢f«7A@d«.¤¡­2±2

·p¶  ´· "nqhi6 ¶<Z´ 5nhjmk0qhijmkmixC Z´²ÀÕ´Lµ 5fhDvR'iIrmsRix'vR'iInh|LvRrmnho-w\fekynhozlpvt6fh-vRmi8rmsSix*r'vSvSixnhjm|Li
êeé ´µ è M÷Õ¶·!±³ý fjmifh ºGj'fhvRylzj'q'usSdii|ZuvSfrm|vSfj'ihÀsSdii|9ºvSfry|vSfj'ihyj'fjusRd"ii|Àmnhjmk0n
|opinhj'ik&vSxnhjysR|LxlpdmvÜ¾lpvR&j'fjuH¾UfhxkCjmflzsSialj'fhxwMnvRlpfjIxiw\f	}hik» Ö·p´¶² è ³ é Öµ± Ô ³ G¤'xRfw×vR'isRiain
vRr'xRis¾Ui|nho|rmoznvSik6v¾Uf,kmixlp}hik6invRr'xis ½ 'iòyxsSva¾UnhsUvR'ijrmwCix~fh¾UfhxkmsUlzjvR'i|ozinhj'ik
vSxnhjms|Lxlpdmv8 Ö·!³ é Öµ± Ô ³ è ² ê ,û~÷µSÕ éSnqnhlzj¼fj»vR'i&nhsRsRrmwMdmvRlpfj0vRmnvr'vSvSixnhjm|Li&opij'qhvR»lzsPsSvSxRfj'qozt
|LfhxRxRionvSik¹¾lpvR¼
 4-ë D;nhjmk£ëìí;ixRxRfhxs ½ 'i,sSi|Lfjmkk'ixlz}hikEinvRr'xRi,¾5nhs$ynhsSik¹fj|nhoz|ryoznvRlzj'q
¾'ivRmixPvR'i [ ê M¶² è ·¶  ´L· wMnvR|'is$vR'i6é ý éè ·¶  ´L· xfwôvR'i,$lznhopfhqr'i,Únhjmnqhix åuæ$çDè éê ÖÖ´ ééR
½ mls5invRr'xiIlzs*k'isR|LxlpikJljOk'ivRnhlzolzj0vRmiIj'iLevPsSi|LvRlpfjZ
ÁÛj¹vR'i,iLedixlw\ijvRs"vRmi\invRr'xislzj¹¤Dlzqr'xRiîZiLu|ormkmlzj'qJvR'i\mnhjmk'ozniozopik»invRr'xRisÜnxRi
xRiixRxRikCvSfnhsDvR'
i 4
í 2F  4E2  6CinvRr'xRi5sSiv ½ 'iaiLedixlzwMijvRsÜvSisSv)'f	¾;¾aioowMlsRrmjmk'ixsSvRnhjmkmlzjmqs
|nhj\i*lzk'ijvRlòyik,nhjmk,¾P'ivR'ix)dmxRfhÀopiwMnvRlz|5kmlznhozfhqr'is)|nhjMi5dmxRikml|LvSik\rmsRlzj'qvR'
i 4
í 2F  4E2  6
invRr'xRis)¢iI|Lfw\dÀnxRiPvRmiPdixRfhxwMnhjm|LifhvR')
i 4
í 2F  4E2  6JinvRr'xRi$sSiv5vSf,vR'irmoominvRr'xRi$sSiv
lzjm|ormkmlzj'qCvR'iImnhjmk'ozniozopik6invRr'xisnhjmk0vSfMvRmiIdixRfhxwMnhjm|Li$fhvR'
i 4
í 2F  4E2  6»invRr'xiIsSiv
¾lpvR8nhjmkI¾lzvR'fr'vZvR'i ¶ ê ³H÷ èåuæç-è éê ÖÖ´ ééZinvRr'xihD¤lpqr'xi~ Kqlp}hisDnhjIiL'nhw\dyopi~fhevRmi~ijm|Lfukmlzj'qKfh
sSfw\ifhZvR'inhr'vSfwMnvRl|*invRr'xRisGfhx~vRmisSi|LfjmkiLu|mnhj'qhifhvR'
i w \x 4Dy¼kmlnhopfhqr'i*lzjM¤lpqrmxRC
i ;e
½ 'idyxRiLòmä ´ Ä èMk'isRlzqjmnvSis*vR'iCsSi|LfjmkOiL'|mnhjmqhiha¢i&kmlzsR|rmssKsSi}hixnhofhvR'i8invRr'xis*}nhozr'is
'ixRi¼vSfijmsRrmxRiOvRmnvvRmi»xRinhk'ixJrmjmk'ixsRvRnhjmkms,vR'i»¾5ntljä¾mlz|ävR'i»invRr'xRis6nxRiErysSikZÁÛj
r'vSvSixnhjy|Li,c'àlzj»¤lpqr'xRb
i ;eyvR'i&sStesRvSiw sRn	tes8å ÷µµý Ô ·p´¶ é ´  µ±H´ ¹ ý0³´L·
· 
´ [e÷û?
þ M¶P
ý [u´L· Ô ý÷ êu
ÁÛj¤lpqrmxRiM eZvRmlzs$lzsijm|Lfuk'iktsSi}hixnhoinvRr'xRis ½ 'i&invRr'xi ´ Ä èÔ µÛh÷  Ô ³ qlp}his$vR'i\jmnhwMi&fh
vRmnvPdmxRfw\dmvÂ
 ÅÂÆhÇ=È½ÉÊ1Ë1ÊÂÌrÅÂÈ½ÉÂÊrÇZ ½ 'iIinvRr'xRi ´ Ä è µS´ Ô µSr÷  Ô ³ sSdi|lòyis5vRmnvc'à\lzs*nxRidmxRfwMdmvyn
sSi|LfjmknvSvSiw\dmvIet¹vR'isStusSvSiwóvSfEiozlz|lpvn»kmisR|LxlpdmvRlzfj¹fhUvRmiM|nhozopixØÙs8dmxRfhyopiw» ½ 'i\invRrmxRi
´ Ä è Ö÷<² Glµ  sSdi|lòÀis*vRmnvIc'àMlsj'fhvn6|LfjuòÀxwMnvRlpfj¼dmxRfw\dmv ½ 'i8invRr'xRi ´ Ä è é=ê  Õh±¶· sSdi|lòyis
vRmnvGc'àPlzjmlpvRlznvSis-n$sRr'ZkmlznhopfhqrmiGnhjmk ´ Ä è ² ê  è é=
ê  Õ±¶h· éÜijy|Lfek'is-vRmnvvRmlzsDlzsÜvR'i~òÀxsSv-sr'Zkmlznhopfhqr'i
sSf0nx¾mlopi ´ Ä èzÔ ´LµSÖ´L²À³ èéE
ê  Õ±/¶· é$ijm|Lfuk'is$vRmnvfr'vfhUnhozoDvR'i\sStusSvSiw¬r'vSvSixnhjy|LisIsSf0nx	Ü­áñ
fhvR'iw lzjylpvRlznvSisRr'Zkmlznhozfhqr'is
ùs\w\ijvRlpfj'ikinxozlzix)¾aiOnxRi»nhosSflzjvSixisSvSikälzjqhij'ixnhozlpãlj'qEfrmx\dmxRfhyopiwnvRlz|6kylznhopfhqr'i
dmxRikylz|LvSfhxMvSf£fhvR'ixJsStusSvSiwMs ½ rms~¾Ui»vSxnhlzj'iµ
k D  BEBE8=DörysRlzj'q¹fjmopt;invRr'xRisMvRynvnxRi»fhvR
nhr'vSfwMnvRl|nhozoptEnh|¿ermlpxnyopi,kmr'xlzjmqxrmjvRlzw\i,nhjmklzjyk'idijmk'ijvfh~vRmi 
Cf vRnhsSg" ½ mi,sr'ysSiv
fhKinvRr'xRisCxRfwÂ¤lpqr'xRiOî0vRmnv8òyv8vRmlsI¿rynhozlòÀ|nvRlpfjnxRi6lj£¤lpqr'xRi0eO¢i6xRiix8vSfvR'iwÃnhs
vR'N
i 4
í 2FtÍ°24-<ë 5Î  iy8EB=2invRr'xRiMsSiv
 GunhwMdyopis$fh5invRrmxRisvRmnv8nxij'fhvvRnhsSglzjmk'idijmkmijv
lzjm|ormk'i µS´Ö}÷ Z è ZµÛr¶ +M¶µ c5é ý éè ·¶  ´L· cÔ µÛr÷  Ô ³ nhjmkOvR'iCmnhjmkuozniozozikinvRr'xRis
æ `lê^ÐpÑÒÓ^Ðé`,íí Q ééªÔõë Q _~b?íêh^ë
ÏY 

 iJqhfnhoKfhPvR'i ¶ ê ³H÷ èå'æ$çDèéê ÖÖ´ ééIdmxRikylz|LvSfhx\lzs&vSf£lzk'ijvRlpth)fhx,inh|äiL'|ynhj'qhiha¾P'ivR'ix,fhx
½ '
j'fhv$vR'iMsStusSvSiwó|LfhxRxi|LvRoptryjmk'ixsSvSfefuk¼vR'iMrysSixØÙs$r'vSvSixnhjm|Lih\ùsw\ijvRlpfj'iknf	}hih¾P'ij¹vR'i
kmlznhozfhqr'isK¾UixRi8vSxnhjysR|Lxlpik0et0ermwMnhjysnvSixPvR'iCkmnvRn|Lfozozi|LvRlpfj»¾5nhsP|LfwMdyopivSikZmvRmiCermwMnhj
ozniopixsKjmfhv*fjmoptJvSxnhjmsR|Lxlpik0vR'i8rmsSixsØyr'vSvSixnhjy|Lisyyrmv*nhozsSfozniozozik6inh|ErmvSvSixnhjm|Li8¾PlpvR»n
sSiwMnhjvRlz|&|nvSiqhfhxRt¼xidmxRisSijvRlzj'q6vR'i8vRnhsSg¼vRmnvPvRmi&rmsRix¾5nhsnhsRgelzjmq  vSfJd"ixfhxw» ½ mlzs
ozniols6|nhozozikvR'i [ ê M¶² è ·¶  ´L·  ½ 'iEsRtesSvSiw»ØÙsJ$lznhozfhqr'iÚnhjmnqhix»k'i|lk'isnhw\fjmqsRi}hixnho
kml§ixRijvKtedfhvR'isSisKdmxfekmry|Lik6etJvR'iCëìíwMfekmryopih'nhjmkOopfhqs*lpvRsKted"fhvRmisRlzs5nfr'vK¾mnv5vRnhsSg
vR'irmsSixK¾5nhs*nhsSgulzj'q  vSf\dixRfhxwO¡uvR'i$lznhopfhqrmiIÚEnhjmnqhix	ØÙs*tedfhvR'isRlzs5lzsUguj'f	¾PjOnhsKvR'i
é ý éè ·p¶  ´· ä¢iEkmlzsSvRlzjmqrmlzsRfr'xM|onhsRsSis\fh$sSdfhghijäoznhj'qrmnqhi»ryjmk'ixsSvRnhjykmlzj'qEfr'vR|Lfw\isMÀnhsSik
fj»|Lfw\dÀnxlzj'q\vR'i [ ê \¶h² è ·p¶  ´L· ÀvR'i,é ý éè ·¶  ´L· nhjmk»xRi|LfhqjmlpvRlpfj»xRisRrmopvRs5fhxP|nxk»nhjmkOvSiopidÀ'fj'i
jermw8ixsºÛ	
 D67FDD8962-ºëìí|LfhxRxi|LvRopt¼lzk'ijvRlòyik¼vR'i&vRnhsSgEnhjmknhjt¼kmlpqlpvsSvSxlzjmqs¾UixRi,nhozsSf
Vp$	V

Ë

2¤ZÌyÍ¬2­2«¤°2ÎSÏÁ2Ð-Ì

Ë

«7­¼ÑM1«mÌ

Ë

«7­¼ÒÓÏÁ¡2«¬

ÕÖ}×(ØfÕ\ÙgÚgÛ{Ü  
P'&
 Z&1&==P 
		NÝÝ
Õ Ö}×(ØÞÛ}×(ßÚáà}â{ã äHå.æ{Ü %AB'&!5A	!%5.'&1! ÕÖ}×(ØfÕ\ÙgÚgÛ{×(ç èlßeéÚ{Øà}ê\Ü
ÕáÖ×(èzêÕØ×(ßÚáà}â{ã äHå.æ{Ü %AB'&
ÕáÖ×à{å.ßÂë× ìÂâíÛ{Ü
ÕáÖ×(ØÞÛ}×ÞÛ{Øfâ{ß
ßâ{ØÜ "2A;<A!5'
;
ÕÖ}×â{êgØ×à{èlØâ{å.äÞÚ{ç Ü
ÕáÖ}×å.Úï<×(åðâ{êfñÜ =
	 5. 5;<
ÕÖ}×(åðÚï<×fÙ\Ú}çò1à}Õáç<ÙgÕeÜ
ÕáÖ}×ç<Õgó}å.å.Úï<×(åðâ{êfñÜ 
ÕÖ}×à{ä ô=×ÙgÚ{çò1à}Õç<Ù\Õ
Ü
ÕÖ}×(êâ{ã äoÕç<ÙgÕá×fÙ\Ú}õíÕØâÛÕáÜ /É ///
ÕÖ}×(åðâ{êfñ}öÜ
ÕÖ}×(äHç<ÙgÚ{ç êgäoê\åðÕç<Ùáæ{Ü /É ///
ÕÖ}×(åðâ{êfñ{Ö}Ü
ÕÖ}×ÙgÚ{ç åðÕgó}å.×(êf÷zä ëå.Ü /É ///
ÕÖ}×(åðâ{êfñ}ø{Ü
ÕáÖ×ùï<ØÚ{ßï<åEÜ A95(ú ®5A
ÕÖ}×(åðâ{êfñáûÜ
ÕÖ}×(ØÕfï<ØÚ{ßï<å.Ü A;<A!
ÕÖ}×(åðâ{êfñ}ü{Ü
ÕáÖ×(ç èzße×(ØÕfï<ØÚ}ß9ï<å.êgÜ (
ÕÖ}×(åðâ{êfñzýíÜ
ÕáÖ}×HïzÕØÙgÕáç å.×(ØÕfï<ØÚ}ß9ï<å.êgÜ /É C
ÕÖ}×(åðâ{êfñzþíÜ
ÕáÖ}×fÙ\Ú}çòØß
Ü 
5!;
ÕÖ}×(åðâ{êfñ}ÿ{Ü
ÕÖ}×(ç èlße×ÙgÚ{çòØß
êgÜ /
ÕÖ}×(åðâ{êfñ{Ü
ÕÖ}×ùïlÕáØÙgÕç å.×ÙgÚ{çòØß
êgÜ /
ÕÖ}×(åðâ{êfñ}ö/Ü
ÕáÖ}×ê\è \à{äoâ}ã Ü %:B=
	
ÕÖ}×(åðâ{êfñ}ö}ö{Ü
ÕÖ}×(ç èlß
×ê\è \à{äoâ}ã êgÜ (
ÕÖ}×(åðâ{êfñ}ö{Ö}Ü
ÕÖ}×ùïzÕØÙgÕç åÞ×ê\è \à{äoâ}ã êgÜ /É C
ÕÖ}×(åðâ{êfñ}ö}ø{Ü
ÕÖ}×Ùã å.êÙØä ï<å.×(ç èlß
é1Ú{Øà{êgÜ ((
ÕÖ}×(åðâ{êfñ}öáûÜ
ÕáÖ×(êgæ{ê\×ã â \Õã 
Ü  	5pÅ
K"5zÆ
ÕÖ}×(åðâ{êfñ}ö}ü{Ü
ÕÖ}×.÷lèzßâ{ç ×(ã â \Õáã Ü 
5! n=! %
ÕáÖ}×ç<Ú{×(äHçëÚ{Ü
ÕáÖ×(å.êgÙØä ïpåÞÜÕfï<Ø  ;Ã!!nn?
		 è÷ (în&=!=P 
		¤Ý+Ý
ÕÖ}×Ùã Õ\â}ç ×(å.êgÙØä ïpåÞÜ  ;¦9n< 
		(î#&9!==P 
		Ý+Ý
¤Dlzqr'xRiI eºa¤'invRrmxRiIijm|Lfukmlzj'q\fhxcei|Lfjyk )
 '|mnhjmqhiIfhw

\x 4Dy

( /
/

{î

*É *
É !(
É !(

î
î

/
/
/
/
/

É î!(
/
/
/
/
/
/
/
/
/
(

ç ê.ï<ç

kmlznhopfhqrmih

 ¦½§¶B´\¦¨ª©«­¬~´§#¶
¥ P

® xi|Lfhq'-xRi|LfhqjermwC¾afhxkms-nhsRxSkmr'xnvRlzfjZk'vRw\Ànq'xRqwMfekmnholpvt¹nh|LvRrmnhoGw\fukmnhozlzvt¼fh
vRmi8rmsSixrmvSvSixnhjm|Lih

¥ ©Z¥°¯±¬~´§#¶
® snhozlpijm|Li£|Lf}hixnqhihClzjy|LfjmsRlzsSvSijy|Lth|LfjvSiLevÛsmlpvvSfhd |LfjuòÀk'ijy|Lih$kyl§À|Lfj'òÀk'ijm|Lih
nhrmvSfcuÞ
: sRrm||LisRs
¥J²

9§

P¬~´§#¶

~2½§ #è}p~2#~$§

® rmvSvSixnhjm|Li8et0r'vSvSixnhjm|Lihº~rmvSvÛlzkZ'xRidmxfw\dmvm|LfjuòyxwMnvRlpfjZmsRrmkylznho

® xrmjmjmlzjmq;vRnhoozlpisºjermw,r'vSvRsIjrmw\HxRidmxRfw\dyvRs$d"ix|LijvÛHxRidyxRfw\dmvRsjermw,|LfjuòÀxwMs
dix|LijvÛ|LfjuòyxwMsmjermw,sRr'Zkmlnhozsdix|LijvÛsRr'ZkmlnhozsukmlznhokmrmxnvRlpfj

¤lpqr'xRi8eº~ùr'vSfwMnvRl|vRnhsSglzjmk'idijmk'ijv5invRrmxRis*n}nhlzoznÀopiInv*xrmjvRlzw\ih

|LfhxRxRi|LvRozt;xi|LfhqjmlpãikZ¡,/à
 DBh4DÂ2  4
ì Î  4E26  ºEëìí¯|LfhxRxRi|LvRozt;xi|Lfhqjmlpãik?vR'i»vRnhsSgyr'vvR'ixRi
¾5nhsnhjäixRxfhxMlzjxRi|Lfhqjmlpãlj'q£n£|nhozozlj'q|nxkjermw8ix\fhxn¹dÀ'fj'i»jermw8ix¡I;+D  ë  4E26  º
ëìíkmlkj'fhv&|LfhxRxRi|LvRoptlk'ijvRlzt¹vR'i0rmsSixØÙs8vRnhsSg"¡ø
 i
FÎ/D86FejGºCvR'iJxRi|Lfhqjmlzãix,kylzk£j'fhv&qhiv
nhjtElzj'dÀr'v*vSf0dmxRfu|LisRs$nhjmk¹sSf0vR'iëìíw\fukmrmoziCkmlzkj'fhvilpvR'ix ½ mlzs|nhjnxlzsSi&ilpvR'ix$i|nhrmsSi
vR'i0rmsSix&kmlzkjmfhv&sRn	tnhjtvRmlj'q¼fhx&i|nhrmsSivRmi6xRi|Lfhqjylpãix,¾Unhs,j'fhv&ozlzsSvSijmlj'q»¾'ijvR'i0rmsSix
Vp$ 1

>

°«7«¬2­

> ¡9?¢f«7A@d«.¤¡­2±2

sSdfhghih ½ '
 i'D767FDD8962J|oznhsRsUnh||LfrmjvRs5fhx*îø u,;hïez	ñafhZvR'iPiL'|ynhj'qhisKlzjMvRmiP|LfhxRdyrys ½ 'i
DBh4DÂ2  4ì Î  4E26  nh||LfrmjvRsGfhxKá\áuð­ñMDfhÀvR'i5iLu|mnhj'qhis ½ 'i%D  ë  4E26  |onhsRs)nh||LfrmjvRs
fhx~ømî6/àáuðàñM)fhvR'iiLu|mnhj'qhisUnhjmkMvR'
i i
FÎ{D8967Fej»|onhsRs~nh||LfrmjvRsafhx5 h
ø ;6
ø ;ez	ñMGfhvR'i
iL'|mnhj'qhis
½ mi ¶ ê ³H÷ è åuæç-è éê ÖÖ´ ééMdmxRikmlz|LvSfhx0lzs6vSxnhlzj'ikörmsRlj'qø­rmozoptänhr'vSfwMnvRl|EinvRr'xRis ½ 'isSi
invRr'xRisnxRiIvR'i&ùP|LfrmsRvRlzp| k 4-ë D£invRr'xisZëìíinvRr'xRisnhjmk»$lznhozfhqr'iCÚnhjmnqhix$nhjmk¼$lzsR|LfrmxsSi
ªlzsSvSfhxRtJinvRrmxRismqlp}hij¼lzjO¤lpqr'xRiCîJaªPnhjmk'ozniozopik6invRr'xis*¾UixRi8j'fhvrysSikZ
¢iMi}nhozrmnvSi\vRmi\fr'xRH¾Un	t ¶ ê ³H÷ è åuæç-è éê ÖÖ´ éé|oznhsRslòyix$txRidfhxRvRlzjmqJnh||r'xnh|Lth-dmxi|lzsRlpfjZ
xRi|nhozoÜnhjmkOvR'i8|nvSiqhfhxlpãnvRlpfj¹|Lfj'rmsRlpfjOwMnvSxl" ½ mlzsK|onhsRsRlòyix*lsKvSxnhlzj'ik»fj¼nhozoZvRmiIinvRrmxRis
fhx*vR'iI¾mfopi$vSxnhlzjmlzjmq,sRivynhjmkOvR'ij»vSisSvSik»fjOvRmi8'iozkuHfrmvKvSisSvsSiv
½ nyopiEsRrmwMwnxlpãis\vR'iEf	}hixnhooPnh||r'xnh|LtäxRisRrmopvRsMfhvR'iEsStusSvSiw vSxnhlzj'ikfjvR'iE¾'fopi
vSxnhlzjylzj'q¹sSivnhjmkävSisRvSikäfjävR'i»vSisRvsSivMk'isR|Lxlpik;ljcei|LvRlpfµ
j ;e ½ mi0òyxsSv\ozlzjmiJfh ½ nyopi£
xRidmxisSijvRsCvR'i0nh||r'xnh|Lt£xRfwÃnhop¾5ntusCqrmisRsRlzj'qEvR'i6wn  Ûfhxlzvt|oznhssJg i
FÎ{D8967F
jD¡GvRmls8lzsCvR'i
G94-ë 8mì  i8nqnhlzjmsSvI¾Pmlz|£vR'ifhvR'ixCxRisRrmozvRsIsR'frmok¹"i6|Lfw\dynxRikZ ½ 'i6sSi|Lfjmk£xf	¾Iozniozopik
4í 2F  4E2  6ÜysRmf	¾svR'iCnh||r'xnh|Lt»ynhsSikEfj¼rmslzj'qnhozovR'i8invRr'xRisn}nhlzoznyozi8xRfw vR'i&sStusSvSiw
w\fukmrmopis ½ ylzs*|oznhsRslòyix|nhjlzk'ijvRlptOëìí£ixxRfhxs*øîÙáñôivSvSixvRynhj¼vR'iCynhsSiozlj'ihUùj»iLudixS
lzw\ijv¾5nhsxrmjOvSf0sSii,lp)vR'i&|LxRfsRsÛH}nhozlzkmnvRlzfj¼w\ivR'fukk'isR|Lxlpik»ljcei|LvRlpf¼
j ;d"ixfhxws*¾UfhxsSi
vRmnhjrmsRlzj'q0vR'i¾'fopikynvRnOfj£vR'iJsRnhw\iMvSisRvCsSiv ½ mlzs$iLudixlzw\ijvIsR'f¾aikvRmnvIvRmixRi¾5nhs
ozlpvSvRozi$ozfsRsKfhnh||r'xnh|LtO¾'ijOrysRlzj'q\|LxRfsRsSH}nhozlkmnvRlpfj£áuðïñM

¬~´§#¶N¯ ¶B¨
G=D
4 ë m8 ì  i£
8 wMn Sfhxlpv tO|oznhsRs
4í2F  4E2  6

P¦½¦§#~=¦
øe
; z	ñ


áuz&ñ

½ nyopiMºt*isRrmozvRs5fhxk'ivSi|LvRlzj'qJëìí~xRxRfhxsKrmslzj'qD

 BEB=8ED

¤lpqr'xiJáJsR'f¾s$sSfw\i&vSfhdd"ixfhxwlzj'q\xrmozisvRmnv)D  B=BE8EDozinxjmsP¾'ijEqlp}hij¹nhozoÜvRmiCin
vRr'xRis ½ 'isSi$xrmozisUkylpxRi|LvRoptMxiyi|LvKvR'iIrmsSirmozjmisRs~fh-vR'iCëìíinvRr'xis~¥PfhvSiIvRmnvKsSfw\ifhDvR'i
xrmozisDrysSi°4Dë D6invRr'xisGlzj&|Lfw8yljmnvRlpfj,¾lpvR\ëìíJinvRr'xisGsRrm|&nhsKé ¶· Ô ´LµL³±\M´ G©GxRi}ulpfrmssSvRrykmlpis
¢£nhopghixKivKnho/pmàáháháh|	Umn	}hiInhozsSf,sR'f	¾Pj0ëìíEinvRr'xis5vSfCi$rmsSirmo/D¢i$ynhkJnhosSf&ted"fhvRmisRlpãik
vRmnvKinvRr'xRisKxRfwÓvR'iI$lznhozfhqr'iÚEnhjmnqhixnhjmk0vR'ikmlzs|Lfr'xsSimlzsRvSfhxRtwMlpqv5i$rysSiryoÀdyxRikmlz|
vSfhxs$fhUëìí;ixRxRfhxsZ'f	¾Ui}hixvR'isSi,invRr'xRis$xnxRiozt¼ndmdinxlzj¼vRmiCxryopis¾PlpvR¼vRmi&iL'|LidmvRlpfj¹fh
é ý éè ·p¶  ´·  ½ mlzslsPlzjnh||Lfhxkmnhjy|Li&¾PlpvR¼dyxRi}elzfrmsiLudixlzw\ijvRsP¾mlz|EsRmf	¾ vRmnv$vR'isSi,invRrmxRis
k'f£j'fhvMnhkykäsRlpqjmlò"|nhjvRoptvSf£vR'iOdixRfhxwMnhjm|LiOfhvR'iEëìí Fiì  invRr'xi»sSivE¢£nhopghix6ivnho/p
àáháháh|	
¢iKnhozsSfxRidfhxRv-dmxRi|lzsRlzfjCnhjmkCxRi|nhozofhxDinh|\|nvSiqhfhxRt&fjCvRmiU'iokuHfr'vÜvSisRvsRiv ½ 'i~xRisrmopvRs
nxRiIsRmf	¾jOlzj ½ nyopis*àMnhjmk ;e ½ nyopiIà,sR'f¾sKvRmnvKvR'iC|oznhsRsRlò"|nvRlpfj0nh||r'xnh|Lt0xnvSi8lzsKn,xisRrmopv
fhnImlzqMxnvSiPfh|LfhxxRi|LvU|onhsRsRlòÀ|nvRlzfjMfhx~vR'C
i D67FDD8692Jnhjm
k i
FÎ/D86Fej¼|oznhsRsenvavR'iP|LfsSvafh
n0opf	¾Uix$xnvSi,fh#
x D  ë  4E26  nhjy^
k DBh4D2  4½ì Î  4E276   ½ mlzsPlzsdmxRfhynÀoptOkmr'i&vSfJvRmiCnh|Lv$vRmnv
vR'ixRiCnxRii¾UixiL'nhw\dyozisKfh-vRmisSi8|nvSiqhfhxlpislzj0vR'i8vSxnhlzjmlzjmq,sRiv
ÁÛj¹sSfw\iMsRlpvRrynvRlpfjmsfj'i\wMlpqv$j'fhvIj'iikvSf»kmlzsSvRlj'qrmlzsR»"iv ¾aiij£vR'i\kml§ixRijv$wMlzsrmjmk'ixS
sSvRnhjmkylzj'q|nvSiqhfhxlpisU
º ieFÎ{D8967FejaÍD C ë  4E26  nhjmk DBh4DÂ2  4
ì Î  4E26   ½ 'ixRifhxRih*iLudixl
w\ijvRsG¾UixRidixRfhxw\ikMvRmnv~|LfozozndÀsSikMvR'isR
i ;dmxfhyopiwMnvRlz|K|nvSiqhfhxlpis5lzjvSf8fj'i|nvSiqhfhxRtEg D  iÎ
Vp$

"

Ë

2¤ZÌyÍ¬2­2«¤°2ÎSÏÁ2Ð-Ì

Ë

«7­¼ÑM1«mÌ

«7­¼ÒÓÏÁ¡2«¬

Ë

PÁÛùÞZ¤-®)*Ú5ôk'vRwMÀnq¬á xRi|Lfhqä|LfjvRnhlzjys6xRfwMôxi|Lfhq
 sStesSoznio
jermw8¾Ufhxkms   ´³# µ Ô ¶µL³±¶· è \¶³HÖ[
o äÁÛùPÞ¤-®)KÚ^Uk'vRw\Ànqá £nhsRxSkmr'xnvRlzfj"!ø'Ùá #xRi|LfhqHqhxnhwMwMnx
 sStesSozni
Ý5lzoozw\ivR'fukuHqhxnhw6#
 xRi|Lfhq&|LfjvRnhlzjmsahw8tu$
 xRi|LfhqjermwC¾afhxkys%â  ´³# µ Ô ¶µL³±¶· è \¶³HÖ[
v Ó	'
 ¯sRnhopdixRvRlzw\(
i áuÙá­&
 ÝvSfhd'|Lfjuò"k'ijm|L"
i áuð h­u	 ´³# lµ &± é M¶h³HÖ [
 sSdfhghijukylpqlp&
v Ó	'
 ¯sRnhopdixRvRlzw\(
i áuÙá­&
 Ý|Lfj'dixRvRlzw\)
i áuÙáîï ´³# zµ ,± é M¶h³HÖ [
 sSdfhghijukylpqlp&
v Ó	'
 ¯vSfhd'|LfjuòÀk'ijy|L"
i áuðh  ;hï ´³ zµ ,± é M¶h³HÖ [
 sSdfhghijukylpqlp&
v  	
 snhopdixRvRlzw\)
i ×áuÙá­
 sStusÛozni*
o 5ùÞÜÞÜÁ¥«P5'
ù I ´³ lµ &± éè
 sSdfhghijukmlpqlp
M¶h³HÖ [
j ! Ùáø
 ×r'vSvÛl,
k ! à  sStusÛozni.
o ÁùÞZ¤D)
® K^
Ú U
  kmlp§À|Lfjuò"k'ijm|Li
 nhsSxSkyr'xnvRlpf+
áu#î­ ´³ z
µ ,± é M¶h³HÖ [

¤lpqr'xRiMáuºPùsRr'ÀsSiv~fhxrmopisUopinxj'ik6t µ± ÔÔ ´µ ¾'ij6qlp}hijJvR'i$nhr'vSfwMnvRlz|invRr'xRis5fhxUkmivSixS
wMlzjmlzjmq ¶ ê ³H÷ èåuæç-è éê ÖÖ´ éé

/

~$¶B¶

D6FDD8962
i
FÎ{D8967Fej
D C ë  4E26 
DBh4DÂ2  4 ìÎ  4E26 

«u¦~2'
hàeðïñ
h eð­ñ
îáuðïñ
àhàe#îhñ

0|1¦¶q½

 hïeð ñ
îð­ñ
 uÙáñ
øáuÙáñ

 i|nhozoZfhx ½ isRvsSivrmslzj'q\ùPrmvSfwMnvRlz|invRr'xRis
½ nyopi8àeºU©GxRi|lsRlpfj0nhjmk 

67FDD8692Z ½ mlzsIxRisRrmopvSiklzjn¼xRi|LfhqjmlpvRlpfjnh||r'xnh|Lt£fhhàe øñ0GnEàhe øñÂlzw\dmxf	}hiw\ijv8f}hix
vR'i$ynhsSiolzj'ifhïh; ñJ'¾Pmlz|0lzs5vRmidix|LijvRnqhiIfheD  i
67FDD896O
2 iL'|mnhj'qhis ½ 'i$dmxRi|lsRlpfj0nhjmk
xRi|nhozoÜwMnvSxl0lzsKqlp}hij»lj ½ nyoziø'

D67FDD8962
i
FÎ{D8967F
j
D  ë  4E26 
DBh4DÂ2  4 ìÎ  4E26 

D67FDDD8692
àî ø

øá
ï

i
FÎ/D86Fej
ï

;ø;u
 h;
á

D  ë  4E26 
àuh
øhø
àáø
àh 

DBh4DÂ2  4 ì
­
á
 á
 á

½ nyozi3;eºUUfj'rmsRlpfj0ÚnvSxlOfhx ½ isRvsSivrmslzj'q\ùPrmvSfwMnvRlz|invRr'xRis
Vp$ 2

>

°«7«¬2­

/

> ¡9?¢f«7A@d«.¤¡­2±2

«õ1¦~2'

~$¶q¶

D 67FDD8692
D  i
67FDD8692

uðàñ
h;ez	ñ

0z¤¦¶½

 heÙáJñ
ø'ð­ñ

 i|nhozoZfhx ½ isRvsSivrmslzj'q\ùPrmvSfwMnvRlz|invRr'xRis
½ nyopiø'ºU©GxRi|lsRlpfj0nhjmk 
1Y

Ôõë^çt Q ìêhb?í X bìH^Ü` Q Ôµë Q _~b íêh^ë

 iqhfnho-fhvR'i8©a©ölzsKvSf6dmxRikml|Lv'fj»vR'iIÀnhsRlzs5fhGlzj'fhxwMnvRlzfj0vRmnvlpvynhsKinxoptOlzj0vR'iCkmlzn
½ '
opfhqr'ihh¾P'ivR'ixDfhxjmfhvDvRmiUsStusSvSiw×¾lozohiUnÀopi~vSf|Lfw\dyozivSiUvRmiUrmsRixØÙsDvRnhsSgÀ ½ mi~fr'vSdyrmvD|oznhssSis
nxRi&ynhsSikEfjvR'iCfr'x$kmlznhopfhqrmiC|nvSiqhfhxlpiskmisR|Lxlpik¼nf}hih$ªPf	¾Ui}hixnhs  4iej
í B
Íw \x 4Dy
nhjm
k 24-ë 5e<4  ì
í D8nxRi,vSxRinvSik£nhs$i¿ermlp}nhopijvRopt»dmxRfhÀopiwMnvRlz|CtEvR'i\sStusSvSiwOnhsIlzoozrmsSvSxnvSikElzj
¤lpqr'xRi­euvR'isS
i ;&|nvSiqhfhxlpis*nxi$|LfoozndysSik0lzjvSb
f B=D7F
Gy
ì 8  4E2  6ÜD¥PfhvSivRmnv5vRmlzsU|nvSiqhfhxlpãnvRlpfj
lzs*ljm'ixRijvRopt6jmflzsStJ"i|nhrysSi8lpvls*lzw\dfsRsRlzyopivSfguj'f	¾ vR'iIxRinhoÜxRinhsSfjms¾t0n|nhoopixmnhj'qsPr'd
fhxn¹¾lzãnxkvRnghisMf}hixvR'i»|nhozoH ½ mi0|nhoopixMwMntämnhjmq¹rmdä"i|nhrysSi»sR'iOlzs,xrmsSvSxnvSik¾lpvR
vR'iJsStesRvSiwO)fhx&s'i6wMn	t£sRlzw\dÀoptkylzsRozlpghiMnhrmvSfwMnvRlpfjZ)fhx,'ixC|mlzozkwMntmn}hi0sSvRnxRvSik|LxRtulzj'q'
culzwlzoznxopthhfjmi¾lpãnxkMwMnt6mn}hi$opf	¾â|LfjuòÀkmijm|LiPlzjMvR'iPsStusSvSiwOØÙsUnylzolpvt,vSf8xi|Lf	}hixKxRfw ixRxfhxs
nhjmk,rmsSiKn$|LfjmsSix}nvRlp}hi*ndydmxRfnh|,vRynvDxisRrmopvRslzjCvRngelj'q$f	}hix~wMnhjtC|nhoozs¾mlzozianhj'fhvR'ix)¾Plpãnxk
wMn	tEi\w\fhxRi,¾lzoozlzj'qMvSf»ozivvRmiMsStesRvSiw¦vSxRtEvSfOxi|Lf	}hix\¥Pi}hixRvR'iopisRs¾ai\vRnghivR'isSiMermwMnhj
nh|LvRlpfjmsnhsnMermwMnhjOozniozolzj'q8fhvR'isRiI|nhozozs*nhsKdyxRfhyopiwMnvRl|a«$lp}hijOvRmls5ylzjmnxRtJ|oznhsRsRlpòÀ|nvRlpfjZ
ndmdmxf'lzwMnvSiopA
t ;h;ñfh-vRmiI|nhozozsKlzj0vR'i|LfhxRdÀrms5fh-øïhhàkmlznhopfhqrmisKnxR
i BEDFGÀ
ì 8  4E2  60nhjyk»ïîhñ
nxR
i 24-<ë 5ë

í 676=8"ë	ë
2 4350z¤½=´ 1¶

\¦ ²

~´

9§

\¦

A«õ¶p§n´¶

~2½§ #60z¤¨n ´q½

½ mlsKsSi|LvRlpfjOdmxisSijvRs*xRisRrmopvRs5fhx*dmxikmlz|LvRlzj'q,dmxfhyopiwMnvRlz|$kmlnhopfhqr'is ½ ngelj'qMlzjvSfMnh||LfrmjvPvR'i
 nh|LvCvRmnv,nEdmxRfhyopiwnvRlz|kmlnhopfhqr'iw&rmsSv&iMdmxRikml|LvSiknv,n¼dflzjv8lzjvR'i0kmlznhopfhqr'i6¾'ixRi6vR'i
sStusSvSiw |nhjkmf6sSfw\ivRylzj'q6nfr'vlpv"¾ai,|Lfw\dynxRi8Ô µR´RÕ±/Ö³±/÷² nh||r'xnh|LtEnvSixmn	}elj'q6sSiijfjmozt
vR'iòÀxsSv*iL'|mnhjmqhi8fhxvR'iòyxsRvKv¾Uf6iL'|mnhjmqhis¾lzvR ±Õ´L²y³± aÖ¶³±÷² nh||r'xnh|Lt»nvSix$mn}ulzj'q6sSiij
vR'i5¾'foziakmlznhozfhqr'ihD¤mfhx)inh|\fhmvRmisSiKsRlpvRrmnvRlpfjys¾aiKnhozsSf$|Lfw\dynxiUxisRrmopvRsDfhxDvRm°
i 4
í 2F  4E2  6
invRr'xRi,sSivMnhsk'isR|Lxlpik¼inxozlpixK¾lpvRnhjmkE¾lpvR'fr'vPvR'i ¶ ê ³H÷ èå'æ$çDèéê ÖÖ´ éé*invRr'xRi\nhjmkE¾lpvR
vR'i8ynhjmkuozniozopik6invRr'xRi\åuæç-è éê ÖÖ´ éé
½ nyopiC­MsRrmwMwMnxlpãis5vR'iIf}hixnhozoÜnh||rmxnh|LtOxRisRrmozvRs ½ 'ivRmxRii8|LfozrmwjmsKdmxRisRijv*xisRrmopvRs5fhx

)'|ynhj'qhiJ7)'|ynhj'qhis,Iànhjyk¼f}hixvRmi8¾'foziCkmlznhozfhqr'ih ½ 'i8òyxsSv*xf	¾ qlp}hisvR'i8ynhsRiozlzj'i
xRisRryopvC¾Pmlz|;xRidyxRisSijvRsCvRmiJdyxRikmlz|LvRlpfjnh||r'xnh|LtxRfwnhop¾5ntus\qr'isRsRlj'qEvRmi0wnÛ  fhxlzvt|onhsRs
culzjy|Liïîz	ñófh5vR'ikylznhopfhqr'isInxi2D
4 ë)
5 ëí
6769À8 ë	ë&kylznhopfhqr'isÜ¾ai|nhj;nh|ylpi}hiJïîz	ñ nh||r'xnh|Lt
xRfwósRlzw\dÀopt0qr'isRsRlzjmqA24 ë)
5 ëíe669À8 ëëfhxinh|kmlznhopfhqr'ih ½ 'i,sSi|Lfjmk¹xRf¾ßqlp}hisxRisRryopvRsPrysRlzj'q
fjmoptMnhrmvSfwMnvRlz|invRrmxRisuyr'va¾lpvR'fr'vUvR'i ¶ ê ³H÷ è åuæ$çDèéê ÖÖ´ ééGinvRr'xRih ½ miPvRmlzxkMxRf¾ÝrmsSisUvR'i
sRnhw\iMnhrmvSfwMnvRlz|\invRr'xRis$yrmv$nhkykmslzj ¶ ê ³H÷ è åuæ$çDèéê ÖÖ´ éé ½ mlzsinvRrmxRiMlzsfhmvRnhlzj'ik¹fhxIfhvR
vR'ivSxnhlzjmlj'q8nhjmk6vR'ivSisSvUsRivurysRlzj'qIvRmi|LxRfssÛH}nholzkmnvRlpfjJw\ivR'fuk6kylzsR|rmsRsRikMlzjOcei|LvRlpfjA;e ½ 'i
fr'xRvRnhjyk,òyvRMxRf¾s~sRmf	¾öxRisRrmopvRs~rmsRlzj'qvRmisRr'ysRivGfhZinvRrmxRisGvRmnvUnxRifhvRrmooptCnhr'vSfwnvRlz|
nhjmkOvRnhsRglzjyk'idijmk'ijv5nhsk'isR|LxlpikOlzj¼cui|LvRlpfjOø'
Vp$

!

Ë

2¤ZÌyÍ¬2­2«¤°2ÎSÏÁ2Ð-Ì

Ë

«7­¼ÑM1«mÌ

Ë

«7­¼ÒÓÏÁ¡2«¬

½ mi0nhrmvSfwMnvRlz|JxRisRrmozvRsCqlz}hijälzj;xRf	¾ôànxRiOsRlpqjylòÀ|nhjvRopt£mlpq'ix,etndynhlpxikvÛHvSisRv\vRmnhj
vR'i,ynhsSiolzj'i&fhxInhozoDvR'xii,sRi|LvRlpfjms$fh~vRmiMkmlznhopfhqr'iOk'7 hïhïev8àezÜd	$áuÙá½;h­e¡Ùk'7 hïhïeDv8Iîðàe
d	$áuÙáhá'¡Ùkm4  hïhïM8v ,< ;e ø'y9
d $áuÙáhá'	
f	¾s0ïnhjyköîsR'f	¾¦nh||r'xnh|Lt?lzw\dmxRf}hiw\ijvRsqnhlzjmiketävR'iEnhkykmlpvRlpfjäfhIynhjmkuozniozopik
invRr'xRis ½ misSi¹xRf	¾s»qlp}hi£µ
n 2FByì  i8önqnhljmsSvO¾ml|âvSf|Lfw\dÀnxRivR'ixRisRryopvRsOlzjöxRf	¾Ps¼àe
;eGønhjmkä­eW
 isRrmopvRs,rmsRlj'qEnhozoUvR'iOnhr'vSfwnvRlz|JinvRr'xis,dyozrmsCvR'iOmnhjmkuon"ioopikåuæç-è éê ÖÖ´ éé
nxRi0qlp}hijälzj;xRf¾ôïe£ÁÛjvR'isSi0iLedixlw\ijvRs)vR'iOmnhjmkuozniozozikäåuæç-è éê ÖÖ´ ééIinvRr'xi»lzs,rmsSik
fhx6vSxnhljmlzj'qnhjykvSisSvRlj'q'ß5fw\dynxlzjmq£vRmlzs6xRisRrmozv¾lpvRvR'i¹sSi|LfjmköxRf	¾¦sR'f¾sJvRmnv0lpfj'i
mnhkândixRi|LvJdyxRikmlz|LvSfhx0fh ¶ ê ³H÷ èåuæç-è éê ÖÖ´ éé6lzj?vR'ivSxnhlzjylzj'qnhjyk?vRmivSisRv»sSivPvRmijâvRmlzs
invRr'xRi\¾Ufrmozk¹lzjm|LxRinhsRi,nh||rmxnh|Lt¹t¹­eð­ñ¦fh
x )'|mnhj'qhi»»xRfw îáuz	ñóvSfEî­eðïñM¡tîðïñ
fh)
x Gu|mnhj'qhis\Ià¹xRfw¬î ez	ñ vSf» h­e#îhñM¡ÜnhjmketE­eðñ fhxvRmiC¾mfopi&kylznhopfhqr'i0/ îÙáñ vSf
hàeðñM ½ misSialzjy|LxRinhsSisDnxRiUslpqjmlòÀ|nhjvÜetInPdynhlpxRikCvÛHvSisSv*k'7  hïhïeh8v ­ezh	
d $áuÙáháhá'¡ek'7  hïhïe
v8àezÀ	
d $áuÙ½á ;h­e¡Àkm4  hïhïey8v ïe#îm	
d $áuÙáhá'	
UfwMdynxlzj'qvRmixRisRryopv~lzjxRf	¾âïI¾lzvR\vR'ixisRrmopv~lj\xRf	¾ ;Is'f	¾savRmnvavR'i ¶ ê ³H÷ è åuæç-è éê ÖÖ´ éé
dmxRikylz|LvSfhxGvRmnvG¾Uimn	}hi*vSxnhlzjmikM|nhjlzwMdmxRf	}hiKdixRfhxwMnhjy|Lihyr'vG|Lfrmok\dfsRsRlpyoztI'iopdw\fhxiK¾lpvR
kml§ixRijvvSxnhlzjmlj'qOw\ivR'fukmsMÁÛk'inhozopthÜvR'iMxRisRryopvlzjxRfÃ
¾ ;e-fhx8nhr'vSfwnvRlz|MinvRr'xRis8dyozrms ¶ ê ³H÷ è
åuæç-è éê ÖÖ´ ééÜsRmfrmozkEnhozoiv ¾aiijvRmi,òyqr'xRislzjxRf¾s8à0nhjmk£ïe-nhjmk¹i,|ozfsSixIvSfOvR'i\xRisrmopvRs
lzj;xRf¾ôïe¢âlpvRJ
 )'|mnhj'qhis¼Iàeanhkmkylzj'q ¶ ê ³H÷ èå'æ$çDèéê ÖÖ´ éé8xRisrmopvRs,lzj;nhjälzjm|LxRinhsSi0fh&z	ñ
¾ml|lsCj'fhv,sRlpqjylòÀ|nhjv6|Lfw\dynxRi0xRf¾s,à¼nhjmJ
k ;¹¤'fh
x )'|mnhj'qhi6fjmopth
 D  B=BE8EDk'feis,j'fhv
rmsSi$vR'i ¶ ê ³H÷ è åuæç-è éê ÖÖ´ ééGinvRr'xiIlzj6lzvRs5xrmopisSiv5nhjmk0k'feis5j'fhvKtelziozk6nhj0lzwMdmxRf	}hiwMijvKf}hix*vR'i
sStusSvSiw vSxnhlzj'ik¼fjmoptOfjEvR'iCnhr'vSfwnvRlz|8invRr'xRis ½ 'i&sStesRvSiwôvSxnhlj'ik»fjEvR'i8¾P'fopiCkylznhopfhqr'i
¾lpvRnhr'vSfwMnvRlz|invRr'xisGdyozrys ¶ ê ³H÷ èå'æ$çDèéê ÖÖ´ éé)nhozsSf8k'feis~jmfhv~tulpiozk\nhjlw\dmxRf}hiw\ijv~f	}hix5vR'i
sStusSvSiw vSxnhlzj'ik0¾lpvRmfr'v ¶ ê ³H÷ èå'æ$çDèéê ÖÖ´ éé
:9;<=;<?>

4Dë 

5 Î  iy8=BE8Eiy
8Ei2A@°8E4E2"íD8"ë

*f¾saøCnhjmkJ­qlp}hiPvR'i*xRisRryopvRs~rmslzj'qvR'i'4"í
27FtÍ724Dë 5
Î  iy8=B=26invRr'xiPsSivUk'isR|Lxlpik\lzj¤Dlzqr'xRi

E¾lpvR'frmvCnhjmk;¾lpvRvR'i ¶ ê ³H÷ è åuæ$çDèéê ÖÖ´ ééIinvRr'xRihGxisSdi|LvRlp}hiopth ½ 'isSiJxRisRryopvRsCnxi0slpqjmlòm
|nhjvRoptEnf	}hi\vRmi&ÀnhsSiozlzj'i,rmsRlj'q6n0dynhlzxRik¼vÛHvSisRvÜ¾lpvR^)'|ynhj'qhisMIàJqlp}ulzj'qJnhjlzjm|LxRinhsRi&fh
< ;ez	ñ k'7  hïhïe-8v I eðïeD9d $áuÙáhá'	IrysRlzj'ª
q 24-ë 5
Î  iy
8EB=2invRr'xRisI¾PlpvR ¶ ê ³H÷ è åuæ$çDè éê ÖÖ´ ééOat
|Lfw\dynxlzj'qxf	¾sPøJnhjyk­efj'i&fhysSixR}his$nhjlzjm|LxRinhsRi&lzj¼vR'+
i 4"

í 27FtÍ24-ë 5
Î  iy
8EB=2invRr'xRissSiv
¾'ijvR'iinvRr'xRi ¶ ê ³H÷ è åuæ$çDèéê ÖÖ´ ééGlzsanhkmk'ikJrmsRlzj'
q Gu|mnhj'qhis$Ià8nhjmk¾P'fopikmlnhopfhqr'ih ½ 'i
ðñôlzjm|LxRinhsSi8fh'
x )'|mnhj'qhis,IàMsR'f	¾PsnMvSxijmkk'7  hïhïeÀ8v ,#î 	
d $áuÙáîøZ¾mixRinhs*vR'i,àñ
lzjm|LxinhsSi$fhxKvR'i$¾mfopikmlznhopfhqr'i$lzs5sSvRnvRlzsRvRlz|nhozoptJsRlpqjmlò"|nhjvUtJn,dynhlpxRik6vÛHvSisSvCkm4  hïhïey8v #;eÙáu
d	$áuÙáh½á ;
ùopvR'fr'qevRm3
i 24-<ë 5Î  iy8EB92OinvRr'xRiIsSivRs*nxi8n\sRr'ysRivUfhDvR'fsSiinvRr'xRisrmsSikOlzjJxRf¾ ;emlpv
lzsUdfsRsRlpÀopifhxKvR'iwÓvSf\dixRfhxw"ivSvSixKi|nhrmsRivRm3
i 24-<ë 5Î  iy8EB920invRrmxRis*nxRiw\fhxRiqhijmixnho/
nhjmk¼"i|nhrysS3
i D  B=BE8ED£rmsRisnMqhxiik't»nhopqhfhxlpvRyw vSf6kmlsR|Lf	}hix$lpvRs*xrmopiIsSivRs*¤mfh'
x Gu|mnhj'qhis&Iàe
vR'iMlzjy|LxRinhsSi\xRfw¦xRf	¸
¾ ;JvSf»xRf	¾­"fhvR¹fhU¾ml|rmsSi ¶ ê ³H÷ èåuæç-è éê ÖÖ´ ééSlzsjmfhvIsRlpqjmlò"|nhjv
Ufw\dÀnxlzj'qCxRf	¾s*à&nhjmkJø'mj'ilzvR'ix5fhÜ¾ml|JrmsSi ¶ ê ³H÷ è åuæ$çDèéê ÖÖ´ ééefjmi$sRiisKn&sozlpqvUk'iqhxnhkmn
vRlpfj£ljExisRrmopvRs$fhxIvR'i\¾mfopi\kmlznhopfhqr'iMrysRlzj'»
q 24Dë 5
Î  iy8=B=2invRr'xRisMªPf	¾Ui}hixvR'iMlzjy|LxRinhsSi
xRfw×xRf	¾Ps~àvSfC­xRfw î ez	ñ×vSf8 áuH ;ñßfha
x Gu|mnhj'qhisPIà$lzs)sSvRnvRlzsRvRlz|nhozopt8slpqjmlòÀ|nhjv*k'7  hïhïe
v8àeÙáuD	
d $áuÙáøà ½ mlzs$sR'f¾svRmnv8rysRlzj'q ¶ ê ³H÷ è åuæ$çDè éê ÖÖ´ éé$lzj|LfwCylzjmnvRlpfj¹¾PlpvR¹vR'iMsSivIfh
24-ë 5
Î  iy
8EB=2¼invRr'xis*dmxRfukmrm|LisnMsSvRnvRlzsSvRl|nhozopt0sRlpqjmlò"|nhjvKlzjm|LxinhsSi8lzjOnh||r'xnh|LtOf	}hix$nMsSivfh
nhr'vSfwMnvRl|invRrmxRis*vRmnvPk'fisj'fhvlzjm|ormk'ivRmlzs5invRr'xRih
Vp$

&

>

«u½B


à

;
ø
ï

­
î

°«7«¬2­

> ¡9?¢f«7A@d«.¤¡­2±2

¬~´§#¶

UnhsRiozlzj'i
4"

í 27Fj'f ¶ ê ³H÷ è åuæç-è éê ÖÖ´ ééS
4"

í 27FUº ¶ ê ³H÷ è åuæ$çDè éê ÖÖ´ éé
4"

í 27FtÍ24-ë<5Î  iy8EB=2;j'f ¶ ê ³H÷ è åuæç-è éê ÖÖ´ ééS
4"

í 27FtÍ24-<ë 5Î  iy8EB=2¼º ¶ ê ³H÷ è åuæç-è éê ÖÖ´ éé
4"

í 27FUºõåuæç-è éê ÖÖ´ éé
4ìì¼g 4
í 2F º×ªnhjmkuozniozopik"

CD¦¤³#~2#§2E3

ïîz
îáuz
ïheðï
îáuz
ïheðà
î­eðï
îhîz

CD¦³~§,3GFIH

ïîz
î ez
îeðà
î e ø
 áuH ;
 h­e#î
 hïeð

y³#½

ïîz
 îÙá
 ø'ð
 h;e ø
 h­e ø
hàeð
u#î

½ nyozi8­eº~ùP||rmxnh|Lt¼ñxRisRrmozvRs5fhxPdmxRikmlz|LvRlj'qCdyxRfhyopiwMnvRl|kylznhopfhqr'is
/

~$¶B¶

2 4Dë 5)ëí
67698Àë	ë
B=D7F
Gyì8  4E2  6

JN¦½¦§#¤¨

ïîÙá6ñ
;h;eÙá6ñ

0z¤¨n\¦´q¨

 u#î6ñ
 eH ;Jñ

«õ1¦~2'
 h ez&ñ
;uðï6ñ

0z¤¦¶½

î àeð­6ñ
­hïeðï6ñ

 i|nhozoZ¾lzvR»)'|mnhj'qhiJùPrmvSfwMnvRlz|I¤'invRrmxRis
½ nyozi8ïeº~©GxRi|lsRlpfjOnhjmk 
½ miwMnhlzj\dÀr'xRdfsSi5fhZvR'isSi*iLudixlzw\ijvRs~ls)vSfCk'ivSixwMlzj'iK¾mivR'ixanIkylznhopfhqr'ilsDÔ ÷h³´²y³±¶h··!ý
dmxRfhÀopiwMnvRlz|vR'ixRifhxRiMrmslzj'qJvR'i,¾'fopi,kmlznhopfhqrmi,lsjmfhvIrmsSirmo-ljn0k'tujmnhwMl|CsStusSvSiwO+:sRlzj'q
)'|ynhj'qhisIàOdmxRfukmrm|Lis$nh||r'xnvSi6xRisRrmopvRsnhjyk¹¾afrmok¹ijmnyopi\vR'iMsRtesSvSiw¬vSf¼nhkmndmv8ljEfhxk'ix
vSf|Lfw\dÀopivSiIvR'i8kylznhopfhqr'ilzj0vR'iCndmdmxRfhdmxlznvSiwMnhjmj'ix
:9;<=;KML

4iyÎSì4G=8yìì8=y@°8=4E2ÀíD8Àë

*f¾öîPlzj&vRnyopi*­qlp}hisvR'iKxisRrmopvRsrmsRlj'qynhjmkuozniozopikCnhjmk,nhr'vSfwMnvRlz|5invRr'xRis~lzjm|ozrmkylzj'q*fhvR

åuæç-è éê ÖÖ´ ééKnhjyk ¶ ê ³H÷ è åuæç-è éê ÖÖ´ ééUt¼|Lfw\dÀnxlzj'qMxf	¾sïMnhjyk¹î"fj'i,|nhjsRiiCvRmnvPvR'ixRi,lzs
j fhvI}hixtw&rm|vSf»i,qnhlzj'iketnhkmkmlzj'qJvR'iMfhvRmixCmnhjmk'ozniozopikEinvRr'xisqlp}hijlj¤Dlzqr'xRi6î
'
vSfOvR'iMmnhjykuozniozopikEnhjmkåuæ$çDèéê ÖÖ´ ééinvRr'xRiMsRiv\®$jyopt»vR'i\lzjm|LxinhsSi,fhxGu|mnhj'qhi¼&xRfw
î­eðïñ¦vSf¹îhîz	ñólzssRlzqjmlòÀ|nhjvMk'4 I hïhïeÜ8v àeH ;eD	
d $áuÙáàø¤mfhx8vR'i\¾mfopi\r'vSvSixnhjm|LiMvRmixRiMlzs
nh|LvRrmnhozoztJnMkmiqhxnhkmnvRlpfjOfhxRisrmopvRs5xRfwôhàeðñÓvSfJu#îhñJ
2 HN0z¤1¦¶q½~2#¨

«u¦~2'

½ 'i8d"ixfhxwnhjm|Li8fh)vR'i&sStusSvSiwôvRynvrmsRisnhr'vSfwMnvRl|8invRr'xRis\lzjm|ormkmlzj'q ¶ ê ³H÷ è åuæç-è éê ÖÖ´ ééS
 fhxIvR'i,òyxsRvIr'vSvSixnhjm|Lils$qlp}hij£lzj ½ nyopiïe ½ ylzs$sStesRvSiw mnhsnhjf}hixnhozoanh||r'xnh|Lt¹fh5ïheðïñ0
½ 'isRi6xRisrmopvRs&sR'f	¾ÓvRmnvaqlp}hij;vR'iJòyxsSvCiLu|mnhj'qhihavR'i0xrmopisSivCdmxRikml|LvRsCvRynv0 eH;ñÂfhPvR'i
kmlznhozfhqr'isM¾lozoKi¼dmxfhyopiwMnvRlz|5¾ylzop
i ;h;ñ°fhIvR'iw nh|LvRrmnhozoptä¾PlzozoKih ®vRmi¼dmxRfhÀopiwMnvRlz|
kmlznhozfhqr'islpv-|nhj&dmxRikylz|L

v ;uðïñ fh'vR'iwOG®$jm|LiUlpvÜdyxRikmlz|LvRsÜvRmnvDnkmlznhozfhqr'iG¾lzoohi~dmxRfhÀopiwMnvRlz|
lpv*lzsK|LfhxxRi|Lv­hïeðïñ fh-vRmiIvRlzw\ih
x )'|ynhj'qhisIà&lzsUsRrmw,
½ miPdixRfhxwMnhjm|LiPfhvR'i$sStusSvSiwvRmnvUrysSis5nhr'vSfwMnvRlz|invRr'xRisUfh
wMnxlzãikälzj ½ nyopi¼î ½ 'isSi0xRisrmopvRs,sR'f¾ vRmnv~qlp}hijvRmi0òyxsSv&v¾Uf£iL'|mnhj'qhisavRmlsCxrmopisSiv
dmxRikylz|LvRsUvRmnv*àáñfhÜvR'ikmlnhopfhqr'isU¾lzozoÀiPdyxRfhyopiwMnvRl|e¾Pmlzop)
i ;h;ñõfhÜvR'iw nh|LvRrmnhoopt¾lozomih
®ÀvR'iKdmxRfhyoziwMnvRlz|5kmlznhopfhqrmislpvG|nhj\dmxikmlz|LvDøeð­ñßfh"vR'iwOG®$jm|Li*lpvdmxikmlz|LvRsvRmnv~nkylznhopfhqr'i
¾lzooZi8dmxRfhÀopiwMnvRlz|lpv$lzs|LfhxRxi|LvIîe#îhñ¦fhGvR'i&vRlzw\ih ½ mlzsP|oznhsRsRlòÀixPmnhs$nhj¹lzw\dmxf	}hiw\ijvPfh
Vp$ 3

Ë

2¤ZÌyÍ¬2­2«¤°2ÎSÏÁ2Ð-Ì

Ë

«7­¼ÑM1«mÌ

Ë

«7­¼ÒÓÏÁ¡2«¬

i	àsRnhozlpijm|LiL|Lf}hixnqhiOÓáu#îh( i	ànhsSxSkyr'xnvRlpfjP!õáuÙáø(õi	ànhr'vSfcuÞ
:*sRry||LisRsQ¢ieFÎ
´³# Ô µS÷  ·p´ \¶³±Ö
Þ :*srm||LisR5
s  D C ë  4E276  R i	àsStusÛoznioA ÁùÞZ¤D®)KÚ^U? i	ànhsSxR
 i	ànhr'vSfcu

kmr'xnvRlpfS
j ! ;ezà ´¤³ Ô µÛ÷  ·p´ M¶h³±Ö
i Âáu#îàîhS
  i	àsRnhozlpijm|LiL|Lf}hixnqhi?Ãáu#îáïT iHxRi|LfhqÝ|LfjvRnhljms
 isnhozlpijm|LiL|Lf}hixnqh?
S'iopdÀU
 ÝinhsSxSkmrmxnvRlpfO
j  àe øhø ´³# Ô µS÷  ·z´ M¶h³±/Ö
i  áuðhàøV
 Ói	ànhr'vSfc'
Þ :sRrm||LisRW
s  D  ë  4E26  (
  i	àsStusÛozni%
o 
 iHvSfhd'|Lfj'òÀk'ijm|L,
5ùÞÜÞÜÁ¥«P5'
ù I ´³# Ô µS÷  ·p´ \¶³±Ö
i  áuðhàø  i	àkml§"|LfjuòÀk'ijy|LV
i ×áuðu 
 i	à|Lfozozi|L)
v  áuðh  ;h  i	à
 iHvSfhd'|LfjuòÀk'ijy|LX
nhsSxSkyr'xnvRlpfS
j ! eH ;hï&
 Ýi	àkmlznhopHfhxSwM"
i !áuð­ ´¤³ Ô µÛ÷  ·p´ M¶h³±Ö


D8967Fej-

¤lpqr'xRiMhºPùÃsr'ysSiv0fh,xrmopis0opinxj'ikÝet D  BEBE8ED
k'ivSixwMlzjylzj'q,dmxRfhyoziwMnvRlz|$kmlznhopfhqrmis

¾'ijâqlz}hijÝvR'inhr'vSfwnvRlz|invRr'xRisOfhx

i	àHvSfhd'|LfjuòÀkmijm|LiYáuð hîh)i	ànhsSxRkmr'xnvRlpfjP!ÓáuÙáø) i	ànhrmvSfcuÞ:sRrm||LisRs¢ieFÎ
´³# Ô µS÷  ·p´ \¶³±Ö
Þ :*srm||LisR"
s ¸D C ë  4E26  &
 ×i	àHxRi|LfhqjermwC¾afhxkmsQõîh-×i	ànhsRxSkmr'xnvRlzfj!
 i	ànhr'vSfcu

àeðàh  ´¤³ Ô µÛ÷  ·p´ M¶h³±Ö
i õáuðZ
 ×i	ànhsSxSkyr'xnvRlpf[
j ! áuÙáøZ
 ßi	àlzjy|LfjmsRlzsSvSijy|L,
t ! áuÙáàhà\
 
 i	àsRnholpijm|LiL|Lf	}hixnqhT
inhsSxSkyr'xnvRlpfA
j  ;eðhï%
 Ýi	àljm|LfjmsRlzsRvSijm|L6
t ! áuz  ´³# Ô µS÷  ·p´ \¶³±Ö
i ÂáuðïhïîhS
  i	àsRnhozlpijm|LiL|Lf}hixnqh?
i ÃáuðïhhàT
  iHxRi|LfhqÝ|LfjvRnhljms
 isnhozlpijm|LiL|Lf}hixnqh?
S'iopdÀU
 ÝinhsSxSkmrmxnvRlpfO
j ×îH ;hï ´³# Ô µS÷  ·z´ M¶h³±/Ö
i ¯áuðhàø%
 âi	àkml§"|LfjuòÀkmijm|L"
i ¯áuðu %
 ¯i	àHxRi|Lfhq6|LfjvRnhlzjmsMSwCtu'
 
 iHvSfhd'|Lfj'òÀk'ijm|LV
inhsSxSkyr'xnvRlpfA
j !¯ø ´³# Ô µS÷  ·z´ M¶h³±/Ö
i  áuðïøîh"
 ÓinhsSxRkmr'xnvRlpf]
j !óáuðàøV
 õi	ànhsRxSkmr'xnvRlzf]
j !ô­eH ;hà
 isRnhozlzijm|LiL|Lf	}hixnqh+
´³# Ô µS÷  ·z
´ M¶h³±/Ö


D8967Fej-

¤lpqr'xRiMàeºPùõsRrmysSivfh~xrmozisozinxj'ikt^D  BEB=8ED¾P'ijqlp}hij¹vR'iN24Dë
k'ivSixwMlzjylzj'q,dmxRfhyoziwMnvRlz|$kmlznhopfhqrmis

5
Î  iy8=B=2invRr'xRis$fhx

	 îð îhñóljExi|nhozo)nhjmk£àh;eÙáñóljEdyxRi|lzsRlpfj"fhxInhj¹f	}hixnhozoGlzw\dyxRf	}hiw\ijvIlzj¹nh||r'xnh|Lt¹fh5eðïñ
f	}hix$rmsRlj'q,vR'i$òyxsSvKiL'|ynhj'qhiCnhopfjmih
2 _^`CD~=¶

ª«A§#¶B´q¶

'~´¤½¸½aM´³#

ù sRr'ysRiv*fhvR'i8xryopis5xfw vR'i8sRtesSvSiw vRmnvrmsSis*nhr'vSfwnvRlz|IinvRr'xRisPfhx')'|mnhjmqhisCIànxRi
×
qlp}hij6lzj\¤lpqr'xRiIh&xRf	¾;evRnyopi­a®$j'iKfhysSix}nvRlpfjxfwßvR'isSited"fhvRmisSis~lzsvRmi|oznhsRsRlpòyixØÙs
dmxRiixRijm|Li$fhx*vR'i ¶ é µ è Õ ê µÛ¶³±÷² invRr'xRif	}hixPvR'i$invRrmxRifhxKvRmiIjrmwCix5fh-¾Ufhxkms5xRi|Lfhqjylpãik
 µR´RÖ÷ Z è ² ê &û~÷hµÛÕ éR®$j'iK¾Ufrmozk\iLudi|Lv~opfj'qhixUr'vSvSixnhjm|Lis~vSf8i*w\fhxRikyl{6|rmopvyr'v)vR'iozinxj'ik
xrmozisSivRs,lzjmkmlz|nvSi0vRmnv\kmrmxnvRlpfjlzs,n¹ivSvSixMw\inhsRr'xRi0fhr'vSvSixnhjm|Li»opijmqhvRvRmnhjvR'iOjryw8ix
fhU¾afhxkys\ùPj'fhvRmixIfhysSixR}nvRlpfj£ls$vR'iMrmsSirmozj'issPfhUvR'iJëìíä|Lfjuò"k'ijm|LiMsR|LfhxRis8nhjmkvR'i6ëìí
VTz$

>

/

~$¶B¶

2 4Dë 5)ëí
67698Àë	ë
B=D7F
Gyì8  4E2  6

°«7«¬2­

JN¦½¦§#¤¨

ïîÙá6ñ
;h;eÙá6ñ

> ¡9?¢f«7A@d«.¤¡­2±2

0z¤¨n\¦´q¨

 áuÙá0ñ
àáuÙá0ñ

«õ1¦~2'
 ø'ð 6ñ
øeð­6ñ

0z¤¦¶½

îez&ñ
îe#îñ

 i|nhozo¾lpvR»)'|ynhj'qhiIà\ùr'vSfwMnvRl|I¤'invRr'xRis
½ nyopiCîº~©~xRi|lzsRlpfjOnhjyk *

Rs nhozlzijm|LiL|Lf	}hixnqhiClzjdyxRikmlz|LvRlzjmqIdmxRfhyoziwMnvRlz|kmlznhopfhqr'is ½ 'isSiinvRr'xisUsRiiwÓvSf&dyxRf	}ulzk'iPqhffuk
qhij'ixnhoDlzjmkylz|nvSfhxsKfhvR'i&sStesRvSiwOØÙsPsrm||LisRslzjOxRi|LfhqjmlzvRlpfj¼nhjmkErmjmk'ixsSvRnhjmkmlzjmq' ½ 'i8nh|LvPvRmnv
vR'iUwMnhlzjIfu|rmsfh'vR'iaxrmopisÜlzsÜk'ivSi|LvRlj'
q 4-<ë DMnhjmk,ëìíixRxRfhxs-nhjmkIvRynv-j'fj'iafh'vR'ity  "iyn}ulpfhxs
nxRi8rysSik»nhsKdmxikmlz|LvSfhxs*nhosSfMlzjmkml|nvSisKvRmnvylzj¼nhozoZozlpghiozl'ffukZevR'
i y  lzsKdixRfhxwMlj'q&nhs¾aioonhs
lpvI|nhjZ-qlp}hij£vRmij'flzsStlzj'dyrmvvRynv8lpvIlzsqhivSvRlj'q»xRfw 4-<ë Dänhjmkëìí)Mùj£nhopvSixjmnvRlz}hiM}elzi¾ lzs
vRmnvKv ¾afrmvSvSixnhjm|LisnxiIj'fhvKij'fr'q0vSf\dmxf	}ulzk'iw\inhjmlzjmqhrmo"kmlznhozfhqr'i$invRr'xis*sRrm|»nhsK|LfrmjvRs
nhjmkOdix|LijvRnqhis*fhxRidyxRfw\dmvRsm|Lfj'òyxwMnvRlpfjysuivR|p
® jmi$|nhjOsRiivRynvKvR'i$vSfhdOv¾Uf\xrmopis5rmsSi ¶ ê ³H÷ è åuæ$çDè éê ÖÖ´ éé ½ 'iòyxsRvaxryopiynhslz|nhozoptsRvRnvSis
$
vRmnvOlpvR'ixilzs0j'f;xRi|LfhqjmlzvRlpfjöfhx0vR'i¹sSi|LfjmköiL'|mnhj'qhinhs0dyxRikmlz|LvSik?tvR'i ¶ ê ³H÷ èåuæç-è
éê ÖÖ´ ééS6vR'ijövR'i£kylznhopfhqr'i¾lzozonhlo/ ½ 'isSi|Lfjmkâxrmopi¹lzs0w\fhxRilzjvSixRisSvRlzj'qnhsOlpvOsSvRnvSis»lz
nwMlzsrmjmk'ixsRvRnhjmkmlzj'qEmnhs,iijdmxRikmlz|LvSikfhx\vR'i»sSi|LfjykäiLu|mnhj'qhi¼nhjykvR'i»sStusSvSiw°oznio5lzs
b(cd)e Î@f)gÎhißnhjmk¹vR'iMrmvSvSixnhjm|Lilzs$opfjmqJvRmijvR'i\sStusSvSiwó¾lzooÜnhlzo/CÁj¹fhvR'ix¾UfhxkmsvR'i
sStusSvSiw¯xRi¿er'ijvRoptwlzsRlzjvSixRdmxRivRsZozfj'q*r'vSvSixnhjm|Lis-nhs b(c8d(e Î@$f)gÎhixRisRrmopvRlj'qKlzj$vRnhsSg$nhlozr'xRih
¤lpqr'xi0àOqlp}hisIn0sRr'ysRivfhUvR'i\xryopisSiv$fhxvRm
i 24-<ë 5Î  iy8EB92invRr'xRiMsSivfhx)'|mnhjmqhis
 Iàe*®$j'iI|nhjEsSii8nslzwMlzoznxlpvtMiv ¾aiij¼vRmlzsKxryopisSiv*nhjmkOvRmiIfj'iIqlp}hijElzj»¤lpqr'xiMh ½ ylzsKlzs
kmr'iCvSf6vRmi8nh|LvPvRmnv¾'ijEnhozo-vR'iCnhr'vSfwnvRlz|8invRr'xRis$nxRi,n}nhlzoznÀopih9D  BEBE8ED£ynhsPn6vSijmk'ijm|Lt
vSfdÀlz|RgJfr'vvRmi8w\fhxRiIqhijmixnhovRnhsSglzjmkmid"ijyk'ijvKfjmism¾lpvR»vR'iIiL'|LidmvRlpfj»fh5é ý éè ·¶  ´L· aÁfj'i
|Lfw\dynxis*vR'i&sSi|Lfjmk»xrmopiIlzj0fhvROòÀqr'xRis'fj'i&|nhj¼sSiiCvRmnC
v D  BEBE8EDrmsRis µR´RÖ÷ Z è ² ê &û~÷hµÛÕ é$nhs
nMsRrmysSvRlpvRr'vSi$fhx*vR'iIvRnhsRgsSdi|lò"|$invRr'xi\é ý éè ·p¶  ´· 
2 kj

/

¤½2¶q¶©l~2'¨n~´½

E´

}p´³½Z¨ml¶|²Y~2#¨©9~ l'¨©1´q¤~2'#'#§

}p´³#½Z¨

ùs~w\ijvRlpfj'ik6n"f}hihenhj6nhopvSixjmnvRlz}hivSf8vSxnhlzjmlzj'q$vR'i©~$©fjMvR'inhrmvSfwMnvRlz|nhozopt\k'ixlp}hik ¶ ê ³H÷ è
åuæç-è éê ÖÖ´ ééainvRr'xRi8lzs*vSfMvSxnhlzj»lzvKfjOvR'i8mnhjykuozniozopik¼åuæ$çDè éê ÖÖ´ ééU¾mlzozi$sRvRlzozo"vSisSvRlzj'q6lpvKfj
vR'i\nhr'vSfwMnvRl|,invRr'xih ½ mlsPsSi|Lfjykw\ivR'fuklsPxiixRxikEvSf»nhsOSynhjmkuozniozopik'HvSxnhlzjmlzjmqMnhjmk
vR'i6xRisRrmopvRlj'qOinvRrmxRi6lzs [·³ èåuæç-è éê ÖÖ´ éé ½ ylzsIwMn	tdmxRf	}ulzk'i6n¼w\fhxRiJnh||r'xnvSiOw\fuk'io)yrmv8lpv
wMn	t¼j'fhvP|ndyvRr'xRi&vR'iC|mnxnh|LvSixlzsRvRlz|sfh)vR'iCnhr'vSfwnvRlz|&invRr'xiClzj¼vR'i8vSisSv$sSiv ½ nyozi& qlp}his
xRisRryopvRs~fhx5vR'i$v¾UfMw\ivR'fukms~®$j'i$|nhjOsSii$xRfwvRmlzsUvRnyopivRmnv5vR'ixRilzsUn,sRozlpqveljmsRlpqjmlpòÀ|nhjv
lzjm|LxinhsSiKlzj,nh||r'xnh|Lt,fhR
x Gu|mnhj'qhiIKnhjmk,vRmiU¾P'fopiKkmlznhopfhqrmiUrmslzj'qvR'iKmnhjmkuozniozozikuHvSxnhlzjmlj'q
w\ivR'fukZ)ªPf	¾Ui}hixuvR'ivSfhvRnhozoztMnhr'vSfwMnvSikJw\ivR'fukMtulpiozkmsGn8ivSvSix~xRisRryopvPHîeðàñõ|Lfw\dynxRikvSf
îhî øñM-fh
x )'|mnhj'qhisK8àeh¾mlz|Cnhs)w\ijvRlpfj'ik,nf	}hihlzsÜvRmiUw\fsRvlw\dfhxRvRnhjv-xRisRrmozvÜfhxDvRmisSi
iLud"ixlzw\ijvRs ½ mlslzjm|LxinhsSiCsRmf	¾snvSxijmk¼Àr'vlzsj'fhvPslpqjmlòÀ|nhjv&km4  hïhïe8v ,ð e	
d áuÙáïhï
½ 'i8òÀjmnhoÜxRf	¾ fhGvR'iCvRnyopi8qlz}hisPvRmi8xRisRryopvRsrmslzj'qMvR'i,mnhjmk'ozniozopik0invRr'xRiMå'æ$çDèéê ÖÖ´ éé*lzj
fhvROvR'ivSxnhljmlzj'q\nhjmkOvSisRvRlzj'qMnhjmk»ls5vRnghijEnhsKvRmiIvSfhdyozlzjmixisRrmopv
VT	T

Ë

2¤ZÌyÍ¬2­2«¤°2ÎSÏÁ2Ð-Ì

¬~´§#¶

Ë

«7­¼ÑM1«mÌ

CD¦¤³#~2#§2+3

5nhsSiozlzj'i
4
í 2F
4
í 2FWº [·³ è åuæ$çDèéê Ö Ö´ éé
4
í 2FWº ¶ ê ³H÷ è åuæç-è éê ÖÖ´ éé
4
í 2FWºõåuæç-è éê ÖÖ´ éé

ïîz
îáuz
îáu ø
ïheðï
î­eðï

Ë

«7­¼ÒÓÏÁ¡2«¬

CD¦³~2#§2+3F6H

ïîz
î ez
îhî ø
îeðà
 h­e#î

y³½

ïîz
 îÙá
 hïeðà
 ø'ð
hàeð

½ nyopi8 eºù||r'xnh|Lt ñ xisRrmopvRsOlzjy|ozrmkmlzjmq 
[ ·³ è åuæ$çDèéê ÖÖ´ éé0k'ixlp}hik¯rysRlzj'qvR'iynhjmkuozniozopik'
vSxnhljmlzj'q\w\ivR'fuk

¬~´§#¤¶

5nhsSiozlzjmi
4-<ë D
ëìí
$lznhopfhqr'i
ªnhjmkuozniozopik
]ê ³H÷ è åuæ$çDè éê ÖÖ´ éé
ú ·!³ è åuæ$çDè éê ÖÖ´ éé

C&D¦³#~2§,3

ïîz
ïhïe#î
ïî#î
ïh­eð­
îïeð
ïheÙá
ïheÙá

CD¦¤³#~2#§2E3FIH

ïîz
î­eð
îeð
îø'ð­
 ø'#î
îáuð
îø'z

a³#½

ïîz
 h­eðï
îeð 
 hàeðï
 hïeðà
îhîz
îhîðà

½ nyozi8eº~ùP||rmxnh|Lt¼ñxRisRrmozvRs5fhxsRr'ysSivRs5fhinvRr'xRis

§ ¤©Z´¶
2 n¸¬#~´ 
ÁvÜlzslzjvSixRisSvRlj'qKvSf*iL'nhwMlzj'iG¾PmnvZvtedisfhuinvRrmxRisÜnxRi~vR'i~w\fsSvDkmlzsR|LxlzwMlzjmnvSfhxtlzjk'ivSixwlzjmlzj'q
¾'ivRmixUnCkmlznhopfhqr'ilzsGdyxRfhyopiwMnvRl|KfhxUjmfhvR
 D  BEBE8=DO¾UnhsUvSxnhlj'iksSidÀnxnvSioptMfjJsSivRsafhinvRrmxRis
ynhsSikfjvR'iOqhxRfr'dys,qlz}hijlzjä¤lpqr'xRi¼î5jmnhw\iopt;ùP|LfrysSvRlzp| k 4-<ë D5ëìí)a$lznhozfhqr'i»nhjmkäªnhjmku
ozniozopiklzjy|ozrmkmlzjmqMåuæç-è éê ÖÖ´ ééS ½ misSixRisRrmozvRsKnxRiIqlp}hij»lj ½ nyozi8e
¤'fh»
x Gu|mnhj'qhi*fjmoptävR'iëìí¯invRr'xRis*frmv6fhvR'i¹nhr'vSfwMnvRl|¼invRr'xRi¹sSivRs*tulpiozkysMnhj
lzw\dyxRf	}hiw\ijv\f	}hixvR'iOynhsSiozlj'ih£ÁÛjvSixRisRvRlzj'qopthavSxnhlzjmlzjmqEvR'iOsStusSvSiw fjvRmi 4-ë D?telziozkms&vR'i
isSv,xRisRrmozv&frmv\fhPvR'i»nhrmvSfwMnvRlz|OinvRr'xRi»sSivRsMfhN
x Gu|mnhj'qhiIà¹nhjykävR'iO¾'foziJkmlnhopfhqr'ih
½ 'isRi¼sStusSvSiwMsUfhx6iLunhwMdyopih5rmsSi ¶ é µ è Õ ê µS¶h³±÷h² jermw8ix\fh$xRi|Lfhqjmlzãik¾UfhxkmsKnhjmkäv tdi»fh
xRi|LfhqjmlzvRlpfjOqhxnhwMwnxnhs*invRr'xRisPlzj0vR'ilpxKxryopisSiv
¤lzjmnhoopth¾ai\qlp}hi\xisRrmopvRsfhxvR'iMsStusSvSiw¦vSxnhlzj'ikfjmozt¼fj ¶ ê ³H÷ è åuæ$çDè éê ÖÖ´ éé$nhjmk [·³ èåuæç-è
éê ÖÖ´ éé ®$j'i¹|nhjâsSiiEvRynv6vR'ixilzsJj'fhv0wCry|âkml§ixRijm|LilzjvR'iv¾UfäsSivRs0fhIxRisrmopvRs¤mfhx
)'|ynhj'qhis5IàevR'iasStusSvSiw vSxnhlzj'ik8fj [·!³ è åuæ$çDè éê ÖÖ´ éémnhs-nhjCnh||rmxnh|LtI¾ml|8lsÜsRlpqjylòÀ|nhjvRopt
mlpqmixvRmnhj?vR'iEsRtesSvSiw vSxnhlj'ikfj ¶ ê ³H÷ è åuæ$çDèéê ÖÖ´ ééMetndÀnhlpxRikvÛHvSisRv¹k'7  hïhïeP8v #;eÙáu
d	$áuÙ½á ;×®$jiL'nhwMlzjmlj'q£vR'iExrmopisSiv5fj'i¼òÀjmkmsMvRmnv6vRmi [·³ èå'æ$çDèéê ÖÖ´ ééMrmsSi
s DBh4DÂ2  4½ì Î
ë
E
4

2
6

¾
'


i
R
x
*
i
R
v
m

i
ê
è
u
å
$
æ
D
ç

è

é
ê

é

é

x
m
r
p
o

i
R
s

i
G
v
'
k

f

i
~
s
'
j
h
f

v

'


i
p
o

f
a
¾

i
U
x
h
n

|

|
'
r

x
h
n
L
|
M
t
M
w
n	t,"i*kyr'iKvSf
¶
H
³
÷

Ö

Ö
´
½
 

vR'i,nh|LvvRynvvRmi ¶ ê ³H÷ èåuæç-è éê ÖÖ´ éé*dmxRikml|LvSfhx$ynhsn0opf¾×xRi|nhozonhjmkEdmxRi|lzsRlzfj¼fh#
x DBh4DÂ2  4½ì Î
ë
E
4

2
6
h
n

s
S
s

i

i
»
j

l
j

n
y

z
o
8
i
e
à

½
 

2  2po ·l¶m½q%0z¤½=´ 1¶

\¦ ²

~´

§

~2½2§ ¶

ùs»w\ijvRlpfj'ikljcei|LvRlpfjàevR'ixinxRiU
; v tdisOfh,dmxfhyopiwMnvRlz|¹kmlnhopfhqr'isºµ24 ë 5e<4  ìíD8
Í
w gx 4Dynhjmk  4i
jÜíBZ&Áj¹fhxkmixvSf»k'ivSixwMlzjmi&¾P'ivR'ixIsSfw\i\fhUvR'isSi\v tdisfhUdmxRfhÀopiwMnvRlz|
VT 4

>

o r§6rz~2g§¶

24-ë 5)ëíe6698Àëë
24 ë 5e<4  ìíD8
w gx 4Dy
 4i
jíB
½ fhvRnho

°«7«¬2­

> ¡9?¢f«7A@d«.¤¡­2±2

0z¤¨n\¦´q¨¶p§¦¦¶q¶s§n

0z¤¨ \¦´q¨

­eðñ¬;ø
;uð­ñ¬ ;ø
­h e#îhñ¬/ïu	
ïø' øñ¬øîh
àáuH ;ñ¬Û	îï

ø'z	ñÂ/­ø 
ïh eð­ñÂHîø
ømH ;ñÂø ;
;h­eðïñÂ/àhï
îe#îhñÂ/ïhu	

·n¤½=´ ¶

½ nÀopiMáuº~ÚnvSxl0fhDxi|Lfhqjmlpãik24-ë<5ëí
676=8"ë	ëPnhjmk

o r§#Irz~2g§#¶

24-ë<5ëí
67698Àë	ë
24 ë<5
p4  ìíD8

½ fhvRnho

0z¨ f¦´q¨ß¶p§
¦½¦¶B¶sí§#

ïuz	ñ
àuH ;ñ
ømðàñ

;h eðñÂøà

î  eðïñÂ/ h­
­h eð ñÂÛàîh

½ nyopiMhºPÚnvSxlOfh)xRi|Lfhqjylpãik24-ë<5ëí
67698Àë	ënhjmk^24Dë
vSisRvRlzj'q

´q½$´~2

ïîz	ñ /­h hà
àeÙáñ Ûá 
àeð­ñ Ûáø
 e øñ H îr;
áháñ /  hïîh

24-ë 5e<4  ìíD8Àë

0|¨n\¦´¨·n½9´n¶

/ïhï
/hà ;
/ h

\¦

~´

f¦

~´¤

o ½2´q~2

­áñ Û á 
­áñ Û á 
áháñ / àuï

5e<4  ìíD8Àë$rysRlzj'qMi¿ermnhoÜvSxnhlzjmlzjmqnhjmk

kmlznhozfhqr'isMnxRi»w\fhxi¼kml{6|ryopv,vSf£dmxRikml|Lv&vRynhjfhvR'ixsa¾Ui¼|Lfjmkmry|LvSikndfsSvÛ'fu|»nhjmnhoptusRlzs,fh
vR'i,dmxRfhdfhxRvRlzfj»fh~dyxRikmlz|LvRlpfj¼nhlozr'xRisfhxinh|¹vted"i,fhGdyxRfhyopiwMnvRl|8kmlznhozfhqr'ih8culzjm|Li&¾ai&¾UixRi
dmxlwMnxlzoptlzjvSixRisSvSiklzj£vRmi6dixRfhxwMnhjm|Li6fhKvR'i0©~$©ßrmsRlzjmq»vR'irmozoanhr'vSfwMnvRlz|6invRr'xRi0sSiv
nvSixCmn	}elzjmq»sSiiW
j Gu|mnhj'qhisJIàe-¾Ui|Lfjmkyrm|LvSik£fr'xCnhjmnhoptusRlzs$fj£vRylzs$}hixsRlpfj£fhUvRmi©~$©D
½ nyopi0á6sRmf	¾svR'i,kmlzsSvSxlpyr'vRlpfj0fh~vR'i,ø6v tdisfh~kmlznhozfhqr'iClzjEvR'i&vSisSvsSiv$nhjmk¼¾P'ivR'ix$vR'i
)'|ynhj'qhisIàI©~$©£¾5nhs~nyoziUvSf8dmxRikmlz|LvG|LfhxxRi|LvRopt&vRmnvGvR'i*kmlnhopfhqr'iK¾Ufrmozk,
i 24-<ë 5ë

í 67698Àë	ë
fhR
x BEDFGÀì 8  4E2  6Ü)®$j'i5|nhjMsSii5vRmnv)vR'i5¾UfhxsSv)dixRfhxwMlzj'q|nvSiqhfhxRt\lz
s 24Dë 5e<4  ì
í D8&nhjmk&vRmnv
vR'i8©a$©dmxRikylz|LvRsKlzjm|LfhxRxi|LvRopt6vRynvPïh eð­ñÓfhvR'
i 24-<ë 5
<4  ì
í D86kmlnhopfhqr'is*nxRb
i 24-<ë 5ë

í 67698Àë	ëh
®$jmiIxRinhsSfjEvRmnvvRylzs*wMlpqv*fu||r'x$lzsKvRmnvPvRmlzssr''|nvSiqhfhxRtOfhGkmlnhopfhqr'is*nxRi&wCry|w\fhxRi
kml{J|rmopv,vSfdmxikmlz|LvMsRlzjy|Li¼lzjävRmlsM|nhsSivR'i  sStusSvSiw mnhs6j'fljmkmlz|nvRlpfjvRynv6lpvMlzs6j'fhv
sRrm||Liikylzj'qälzj?vR'ivRnhsSg"õªPf	¾Ui}hixInhj'fhvR'ixOdfsRsRlzylzozlpv tälzsJvRmnvOvR'i©~$© dixRfhxwMsJdffhxopt
fj?vRmlzsM|nvSiqhfhxRt?i|nhrmsSi¼vRmixRiEnxRiEi¾UixJiLunhw\dÀopislzjvR'i¼vSxnhljmlzj'q£sSivPnhopvR'fr'q?lpvk'feis
ivSvSixfjvR'i  4i
jÜ
í B¹sRr'ysRiv"¾Pmlz|lzs$nfr'vvR'i\sRnhw\i,dmxRfhdfhxRvRlpfj¢iM|nhj¹iolzwMlzjmnvSiCvR'i
òyxsRvUdfsRslpylzozlzvt,t6iLunhwlzjmlzj'q,'f¾n\opinxj'ixKdixRfhxwMsU¾mij6vSxnhlzj'ik0fj0i¿ermnhodmxRfhdfhxRvRlpfjysafh
24-ë 5)ë

í 67698Àëënhjyª
k 24Dë 5e<4  ì
í D80kmlznhopfhqrmis)¢iC|Lfjmkyrm|LvSik»nhjOiLudixlzw\ijv*rmsRlzjmq,nsRr'ysSivKfh
24-ë 5)ë

í 67698Àëë&kmlznhopfhqr'is8lzjvR'iJsRnhw\idyxRfhdfhxRvRlpfjnh+
s 24-<ë 5
p4  ì
í D8¹fhxCvR'iMvSxnhljmlzj'q»nhjmkvR'i
vSisSvsSivPnhjmk»vSxnhlzj'ik»nsSi|Lfjmk©~$©?rysRlzj'q,vR'iIrmozozt6nhr'vSfwMnvRl3
| )'|ynhj'qhi6IàMinvRrmxRis ½ mlzs
xRisRryopvSiklzjJnCvSxnhlzjmlzjmqIsSivafhDïhá&kylznhopfhqr'isUnhjmkJn8vSisSv5sSivUfh-àuïe ½ miylzjynxRt\|oznhsRsRlòÀixamnhsUnhj
nh||r'xnh|Ltfh-îáñJvRmiP|LfhxRxRisRd"fjykmlzj'qxRi|LfhqjylpvRlpfjwnvSxllzs)dyxRisSijvSik6lzjvRnyopi8h ½ 'i*xRisrmopvRs
sR'f¾ vRynvPi¾ai#
x 24-ë 5e<4  ì
í D8ÀëInxRi8dyxRikmlz|LvSiknhsPsrm||LisRsSrmo/"sRr'qhqhisSvRlzjmqvRmn#
v 24Dë 5e<4  ì
í D8Àë
nxRi¹j'fhv6ljm'ixRijvRoptäw\fhxRi¹kml{6|ryopv\vSfdyxRikmlz|LvMvRynhj?fhvRmixJ|oznhssSisJfhdmxRfhyopiwnvRlz|¼kmlnhopfhqr'is
Uiopf	¾¦¾UikylzsR|rmsRsMvR'iEdfhvSijvRlznhoPfh8rmsRlzjmW
q D  BEB=8EDØÙsopfssxnvRlzfvSf;¾ailpqv0kml§ixRijv6vtedis6fh
|oznhsRslòÀ|nvRlpfj0ixRxfhxs*lzj0r'vRr'xRi¾UfhxRg"
VTV

Ë

t )
Y u¼Q

2¤ZÌyÍ¬2­2«¤°2ÎSÏÁ2Ð-Ì

Ë

«7­¼ÑM1«mÌ

Ë

«7­¼ÒÓÏÁ¡2«¬

 ìê Q _wv ^ëx

½ 'i&xRisSinx|¹xRidfhxRvSik¹'ixRi,lzsPvR'i&òyxsSvvRmnv$¾Ui&guj'f¾ fhavSfOnhr'vSfwMnvRlz|nhozozt¼nhjmnhopteãi\nJ|Lfhxdyrms
fhopfhqsCxRfwÂnEsSdfhghijkylznhopfhqr'iJsStesRvSiw fhx,vR'idyrmxRdfsSiMfh*opinxjylzj'q»vSf¼Ô µR´RÕ±/Ö³ dmxRfhÀopiwMnvRlz|
sRlpvRrynvRlpfjms ½ mlzs$¾UfhxRgyrylzozkmsfj£v ¾af¹sSvSxnhjykmsIfh5inxozlzixIxRisSinx|Z»¤lpxsSvDvRmlzs8ndmdmxRfnh|¾5nhs
lzjmsRdylpxRik,et,¾afhxRg\fj6vR''
i Bh4D4y  ë 8\i}nhozrmnvRlzfjMxnhw\i¾UfhxRg\fhxUsSdfhghij6kylznhopfhqr'i*sStusSvSiwMsa¾ml|
r'vRlzolpãis0fhvRÝwCrmozvRlp}nxlznvSiozlzj'inxOxRiqhxisRsRlpfj¯nhjyk 5'
ù  ½ vSfdmxRikml|Lv0rysSix¼sRnvRlzsRnh|LvRlpfjnhs¼n
rmjm|LvRlpfjfhn¹jrmwCix8fh*fhvRmix,wMivSxlz|s0¢£nhopghix~Þ-lpvRwMnhjZ
 ¡InhwMw»~ôùPiozoznuKhî¡a¢£nhozghix
ivPnhoHpÀàáháháhn
 *isSinx|¼rysRlzj'N
q Bh4D4y  <ë 8Omnhs*frmjmk0vRynvvRnhsSgO|Lfw\dyozivRlpfj»lzs*nhoz¾Un	tesnMwMn  Sfhx
dmxRikylz|LvSfhxfhKrmsSixIsRnvRlzsRnh|LvRlpfj-nhjmkmnhsIiLunhwMlj'ikdmxRikylz|LvSfhxs$fhUvRnhsSg|Lfw\dyopivRlpfj,ªPixRih-fr'x
qhfnhozsanxRiPsRlwMlzoznx)lzj,vRmnva¾aiPnvSvSiw\dmv~vSf&rmjmk'ixsSvRnhjmk,vR'i*nh|LvSfhxsavRmnvGdmxikmlz|Lv)vRnhsSg\|Lfw\dyozivRlpfjZ
cei|LfjmkyopthuvRmlzsa¾afhxRg6yrmlzokms)fj0inxozlzixaxRisRinx|Ofj0opinxjmlzj'qCvSf ±/Õ´²y³± Iý kmlznhopfhqr'is5lzj6¾ml|JvR'i
rmsSixiLudixlpijm|Likdfefhx$sRd"ii|¹xRi|Lfhqjmlpãix8d"ixfhxwnhjm|Li0Þ-lpvRwMnhj¹ivInho/pGhhMUi|nhrmsRi\vRmnv
¾UfhxRgO¾UnhsynhsSikEfj»invRr'xRissStujvR'islpãik»f}hixPvR'iCijvRlzxRi8kmlznhozfhqr'ihyvR'iCtedfhvR'isSis*vRynv¾UixRi
opinxjmik|Lfrmokj'fhv&i6rmsRikfhxCdyxRikmlz|LvRlpfjkmr'xlj'q»xrmjvRlzw\ih¼ÁjnhkmkmlzvRlpfjZlzj|LfjvSxnhsSv,vSf¹vR'i
|r'xRxijvsSvRrmk'th"vR'i8dyxRi}elzfrms*¾UfhxRg¼nhr'vSfwnvRlz|nhozopt»ndmdyxRf'lzwMnvSikEvR'i,j'fhvRlpfjEfhGnqhfefekEfhx$ynhk
kmlznhozfhqr'irmsRlj'qInvR'xRis'fozk\fj6vR'i*dix|LijvRnqhiPfhZxi|LfhqjmlpvRlpfjixRxRfhxs ½ mixRilzsGnCkmnhj'qhixafhZvRmlzs
ndmdmxfnh|¹ilzj'q0|lpx|rmonxP¾mij¹xRi|LfhqjmlpvRlpfjdixRfhxwMnhjm|Li\nv$vR'iMr'vSvSixnhjm|LiMopi}hiolzs$n0dmxlzwnxRt
dmxRikylz|LvSfhxafhnCqhfefekJfhx5ynhkJkmlznhopfhqr'ihÁÛjMvRmls~¾UfhxRg"evRmiPj'fhvRlpfj6fhÜnCqhffuk 24Dë 5)ë

í 67698Àë	ëDnhjmk
ynhkg B=D7F
Gy
ì 8  4E2  6~kylznhopfhqr'i$¾5nhsozniozopikJetJermwMnhjys
ÁÛj£dmxi}elpfrys¾afhxgÀK¢£nhopghix,ivCnho/p)àáháhá"IxRidfhxRvSik£xisRrmopvRsxRfw vSxnhlzjmlzjmq»n»dmxRfhÀopiwMnvRlz|
kmlznhozfhqr'iIdmxRikylz|LvSfhxPlzj¼¾mlz|OvR'it¼jmfhvSik¼vR'iCiLevSijvvSf6¾ylz|OvRmi&mnhjykuozniozopikEåuæç-è éê ÖÖ´ éé
invRr'xRi\lzw\dmxf	}his$|oznhsRsRlpòyixPdixRfhxwMnhjy|LihùsnxisRrmopvfhGvRmlzsPdmxlzfhxnhjmnhoztesRls"lj¼vRmls¾UfhxRg»¾Ui
xRidfhxRvPxRisRrmopvRsxfw vSxnhlzjylzj'qnhj ¶ ê ³H÷ è åuæ$çDèéê ÖÖ´ éé*|oznhsRslòyixfhxinh|iLu|mnhj'qhi\nhjmkrmsRlzjmqlpvRs
dmxRikylz|LvRlpfjmsanhsanhj0lzj'dÀr'v)invRrmxRiPvSf&vR'i$©GxRfhÀopiwMnvRlz|Plnhopfhqr'iP©~xRikmlz|LvSfhx	 ½ 'ixRinxin&jryw8ix
fhydyxRi}elzfrmssSvRrmkmlpisDfj,dmxikmlz|LvRlzj'qPxRi|LfhqjmlpvRlzfj,ixRxRfhxs)nhjmk\rysSix)|LfhxRxRi|LvRlpfjmsG¾mlz|CnxRiKxioznvSik,vSf
vR'i ¶ ê ³H÷ è åuæ$çDèéê ÖÖ´ éé)dmxRikylz|LvSfhxavRynva¾UiPxid"fhxv~fj0'ixRi,ªPlpxsR|ixRq8ivKnho/phhe¡mªPlzxsR|ixRq'
ÞÜlzvRwMnhjZy ce¾UixRvRs"àáháháu"àáhá'L¡"Þi}hf	¾8-hh e¡ÞÜlpvRwMnhjmªPlpxsR|ixRq'y ce¾UixRvRsyàáháháu¡ce¾UixRvRs
ÞÜlzvRwMnhjZyßªlpxsR|ixRq'yàáháhá
ªlpxsR|ixRq,ivnhoHphh*ndmdyop
t D  BEBE8=DEvSf\dyxRikmlz|Lv5xRi|LfhqjmlzvRlpfj0ixRxRfhxsKljOn\|LfhxRdyrmsUfh)àáïî
r'vSvSixnhjy|LisÝÁj|LfjvSxnhsRv6vSffr'x¾UfhxRg"KvR'itär'vRlzozlpãiOdyxRfsSfukmlz|0invRr'xRislj|LfwCylzjmnvRlpfj¾lpvR
nh|LfrmsSvRl|M|LfjuòÀk'ijy|LiMsR|LfhxRis ½ mit¼xRidfhxRvnOisSvÛ|oznhssRlòyixnh||r'xnh|Lt¹fhK hñJÜ¾Pmlz|lsnLøñ
lzw\dyxRf	}hiw\ijvGf}hixavR'ilzxGynhsSiozlj'i5fhîøñ0 ½ mlzsxRisrmopv)|nhjMi*|Lfw\dynxikM¾lpvR,frmx~ylzjynxRt ¶ ê ³H÷ è
åuæç-è éê ÖÖ´ éé5dyxRikmlz|LvSfhx,g D767FDD8962}es
 D  i
67FDD8962KkmlzsR|rmssSik¼lzj¹cei|LvRlpfj¹­e
 GunhwMljmnvRlpfj
fhmvR'i5xryopisÜopinxj'ik8etIvR'ilzxD|oznhssRlòyixsRr'qhqhisSvRsvRynvDkmrmxnvRlpfjmnhoinvRrmxRisnxRiKlzw\dfhxRvRnhjvÜ¢âmlzopi
¾Ui~k'f*j'fhvrmsRiGnhw\dyozlpvRryk'ifhxÜ¤áKinvRrmxRis¾ai~kmf*mn}hi~nhj ¶ é µ è Õ ê µS¶h³±/÷² invRrmxRiG¾ml|lzsZopfhqhqhik8t
vR'ixRi|Lfhqjmlpãix	G¢ölzvR'fr'v5nhjt6fhvR'i$fhvR'ix5dmxRfsSfukmlz|invRrmxRisuvR'i ¶ ê ³H÷ è åuæ$çDèéê ÖÖ´ ééGdmxikmlz|LvSfhx
mnhs&nhjnh||rmxnh|Lt£fhPhàe øñJGnàhe øñÃlzw\dmxf	}hiw\ijv8f}hix\vR'iynhsRiozlzj'iMfhhï ;ñ0¼ÁvClzs8d"fssRlpyopi
vRmnv~ljm|ozrmkmlj'qdmxfsSfekylz|UinvRr'xis~lzj,vR'i ¶ ê ³H÷ èåuæç-è éê ÖÖ´ ééDdyxRikmlz|LvSfhxG|Lfrmok\lzw\dmxRf}hi*vRmlzsxisRrmopv
i}hij»r'xRvRmix
©~xRi}elzfrmssSvRrykmlpis*fjixRxfhx|LfhxRxi|LvRlpfj¼xi|LfhqjmlpvRlpfjnxRi,nhozsSfxioznvSikvSf6fr'x$w\ivR'fuk»fhawMlzsÛ
rmjmkmixsSvRnhjmkmlj'q$xRi|LfhqjmlpvRlpfjKÞÜi}hf	¾IZhh andmdyolpikMsRlzwlzoznx)vSi|yjmlz¿er'isGvSf&opinxjMvSf,kmlzsRvRlzj'qrmlzs
iv¾Uiijr'vSvSixnhjm|Lislj»¾ml|EvR'i\rmsSixfhxlpqlzjmnhoopt0dmxRf	}ulzk'ikEsSfw\i\lzj'fhxwMnvRlzfj»vSf0vR'i\sStusSvSiwO
nhjmk Ö÷µµR´RÖ³±/÷² éy¾ylz|dmxRf	}ulzk'ik6vR'i$sRnhw\ilzj'fhxwMnvRlzfjn,sSi|LfjmkJvRlzw\ihefozopf	¾Plzj'qCn&wMlzsrmjmk'ixS
sSvRnhjmkylzj'q' ½ mlswMn	t»i8w\fhxRi&xRioznvSikEvSf6frmxPxRisRinx|vRmnhjlpv*òÀxsSvndmdinxssRlzjy|LiC|LfhxRxRi|LvRlzfjms
VT 1

>

°«7«¬2­

> ¡9?¢f«7A@d«.¤¡­2±2

nxRi6fhvSijwMlzsrmjmk'ixsRvSffukkmr'iMvSf¹tdixSnxRvRl|rmoznvRlpfjZOÞÜi}hf	¾IØÙs&iLud"ixlzw\ijvRsIvSxnhlzjn¼k'i|lsRlpfj
vSxRii$rmsRlzjmqinvRr'xisasRry|JnhsakmrmxnvRlpfjZvSiwMd"f'edylpvR|ZnhwMdyozlpvRrmkmihnhjmk6¾lpvRmlzj'r'vSvSixnhjm|LiKdynhrysSis
)'nhwMlzjynvRlpfj¼fh~vR'iCvSxnhlzj'ik»vSxii,lj»vRmlzssSvRrmkmt»nhozsSfJxRi}hinhozsvRmnvvR'i&kyr'xnvRlpfjmnhoÜinvRrmxRisnxRi
vR'i$w\fsSvUkmlzsR|LxlwMlzjmnvSfhxRthGculzwlzoznxoptClzjMfr'xUiLud"ixlzw\ijvRs1
 D  BEBE8ED¼rmsSis ¶ é µ è Õ ê µS¶h³±/÷² xRi¿er'ijvRozt
lzj0vR'iCk'i}hiopfhdik0xrmopisSivUÞi}hf¾fhmvRnhlzjys*nhj»nh||r'xnh|LtOxnvSiIfh)î­ñ ¾lpvROn\ÀnhsSiozlzj'i$fhG­áñJ
Hce¾UixRvRsaivUnhoHpeàáháháanhjmkEªlpxs|"ixqIivUnhoHpuàáhá'L"GdixRfhxw sRlzwlzoznxGsSvRrmkylpisGfhxanhr'vSfwnvÛ
lz|nhozozt,lk'ijvRlztulzj'qI|LfhxRxi|LvRlpfjms5rmsRlzjmqIdmxRfsSfuk'th
 4-ë D»invRr'xisUnhjyk6kmlnhopfhqr'iP|LfjvSiLuvUUfhxRxRi|LvRlzfjms
nxRiolpghiopt&vSfIiwMlzsSxi|LfhqjmlpãikZkyr'iKvSfCtdixnxvRlz|rmoznvRlpfj ½ 'it&fhysSix}hivRmnv~|LfhxxRi|LvRlpfjms~vRmnv
nxRiw\fhxRiPkylzsSvRnhjv~xRfw vR'iPixRxRfhxUvR'itM|LfhxRxRi|Lv'nxRiw\fhxRiozlpghiopt&vSfCiL'mlpÀlpv)dmxRfsSfukmlz|Kkyl§"ixijm|Lis
½ 'ilzxsStusSvSiw nhr'vSfwnvRlz|nhozoptäkml§ixRijvRlznvSis|LfhxxRi|LvRlpfjmsxRfw j'fju|LfhxRxi|LvRlpfjmsM¾PlpvRnhjixxRfhx
xnvSiMfh$­e#îàñJM$lznhopfhqrmiM|LfjvSiLuvClzsrysSiklzj¹vR'iMsSvRryk't¼et;ªlpxsR|ixRq'-ÞÜlpvRwMnhjÜôce¾UixRvRs
àáhá'n5¾'ixRiet£vR'it;lzjm|LfhxRdfhxnvSi0¾mivR'ix,vR'iOrmsSix\lzs,n¾5nxRi»fhnwlzsSvRnghiOnv\vR'iO|r'xRxRijv
r'vSvSixnhjy|LiPvSf,'iopd6dmxRikmlz|LvawMlzsRrmjyk'ixsSvRnhjmkylzj'qs)nhjmk6wMlzsSxRi|LfhqjylpvRlpfjMfhÜvR'idmxi}elpfrys~r'vSvSixnhjy|Lis
½ mlssSvRrmkmt¼lzssRlzwMlzonxvSfJfr'xs$lzjEvRmnv$vR'it¼rmsSi,nJdmxRikml|LvSik¼invRr'xRi,nfr'vnhj¹r'vSvSixnhjm|Li»vR'i
ØÙn¾5nxRihØDinvRrmxRi$vSf»dyxRikmlz|LvI|Lfjm|Lidyv8fhx8¾Ufhxknh||r'xnh|Lth)nhsI¾UirmsSi6nOdmxRikml|LvSikinvRrmxRi ¶ ê ³H÷ è
åuæç-è éê ÖÖ´ ééalzj0vR'iI©a©DmªPf	¾Ui}hix"fr'x ¶ ê ³H÷ è åuæ$çDèéê ÖÖ´ ééUinvRr'xiIlzsKnhr'vSfwMnvRlz|nhooptJn	}nhloznyopi
nvKvR'i$vRlzw\i$vR'i$dmxikmlz|LvRlpfj0lzsUilzj'q,wMnhk'ihu¾'ixinhs5vR'itJnxi$wngelzjmq&vRmidyxRikmlz|LvRlpfjys~xRivSxfnh|
vRlp}hiopthÁÛj;nhkykmlpvRlpfjZDvR'it£vSxnhlzjvRmilpx&sRtesSvSiwÃfj;vR'i0mnhjmkuon"ioopikinvRr'xRiJxnvR'ix,vRmnhj;vR'i
dmxRikylz|LvSik0fj'iI¾ylz|0vR'itOopin	}hi8nhs*r'xRvRmixK¾afhxRg"
g ¡Ilzx|mmf§D'àáhá'	adixRfhxwMs~ixxRfhxK|LfhxRxRi|LvRlpfj0lzk'ijvRlòÀ|nvRlzfj6rmslzj'qIvRnhsSgJlzjmk'idijmkmijv~nh|LfrysÛ
vRlz|JnhjmkkmlzsR|LfrmxsSiM}nxlznyozis ½ mlzs8ls&nEv¾Uf¾5ntkylzsSvRlzjm|LvRlzfjiv¾Uiijd"fslpvRlp}hi6nhjyk;jmiqnvRlp}hi
ixRxRfhx|LfhxRxRi|LvRlpfj*c''i8rmsSisv¾UfJ|nhs|nhk'ikE|onhsRsRlòyixs'vR'iIòÀxsSvlzsnk'i|lzslpfjOvSxRiiCvSxnhlzj'ik»rysRlzj'q
 áñfhvR'i»kmnvRnnhjykä}nholzkmnvRlzj'qfj¯áñJ³
 GunhwMdyopis&vRmnvmn	}hi¼|LfjuòÀkmijm|Li»sR|LfhxRis\iopf¾ôn
vR'xRis'fozk»qhf0lzjvSfJnhjiL'|LidmvRlpfjEvSxnhlzjmlj'qsSivfhxnJsSi|Lfjmk|oznhsRsRlpòyix$r'xlj'qvSisSvRlj'q'"lzG|Lfjuòm
k'ijm|Li,sR|LfhxRisnxiCiopf¾ n6vR'xRisRmfozk¼vRmij¼vR'i\r'vSvSixnhjm|Li&lsdynhssSikfjvSf0vR'i,sSi|Lfjmk¹|oznhsRslòyix
cu'iIòÀjmkmsvRmnvPvRmiCw\fsSvkmlzsR|LxlzwMlzjmnvSfhxt6invRr'xRisnxRi,kmlznhopfhqr'iC|LfjvSiLuvMvR'iCv tdiCfh)dmxRi}ulpfrms
sStusSvSiw rmvSvSixnhjm|Li$fozopf¾aiktopiL'lz|nhoinvRr'xRisD¾lpvR£dmxRfsSfukmlz|&invRr'xRisIilzjmqOvR'iopinhsSvCkmlzsÛ
|LxlzwlzjmnvSfhxRth ½ 'i6sStesRvSiw xRi|Lfhqjylpãis8ixxRfhx&|LfhxxRi|LvRlpfjmsC¾lpvR£nhj;nh||r'xnh|Ltfháñ¬|Lfw\dÀnxRik
vSf6nynhsSiozlj'i$fh~ uðñJ5Áj¼vRmlzs*sSvRryk't¹g ¡8lpx|y'f§D"àáhá'	kmiozlpixnvSiopt6isR|'i¾Ps*vR'i&rmsSiIfh)sStusÛ
vSiw¦sSdi|lòÀ|invRr'xRisÀ¾ylzopi8lzj¼fr'x¾UfhxRg"¾aiCiLunhwMlj'i8vR'i,sSidynxnvSi&|LfjvSxlpyrmvRlpfj»fhGkmlp§"ixRijv
invRr'xRiCsRivRsP®$r'xPxRisRrmopvRssRr'qhqhisSvPvRmnvPvRmiCrmsSi8fhGw\fhxRi8qhijmixnhoinvRr'xRisk'feisPj'fhvPj'iqnvRlp}hiopt
lzw\dÀnh|LvKd"ixfhxwnhjm|Lih
g ¡xnhmw\ixMce¾UixRvRs ½ 'irmjmih, ¢iiqhiozsEhhn¹nhjmk g ¡xnhyw\ixMce¾aixvRs ½ 'irmj'ih,
¢iiqhiozshhGopfefhgMnv5kml§ixRijv~invRr'xis~xRionvSikvSf&xRisSdfjmsSis~vSfCdyxRfhyopiwMnvRl|*sStusSvSiw vRrmxjms
½ 'i Õh± é Ö÷<² ~zµ M¶h³±/÷² éIvR'it¹kmlzs|rmsRs$nxRiMxRisRd"fjysSis$vSf»iLudyozlz|lpvfhx8lzwMdyozlz|lpvsStusSvSiwó}hixlò"|nvRlpfj
¿er'isSvRlpfjms ½ mit»fhysSixR}hi&vRmnvkmlzs|LfjuòyxwMnvRlzfjmsnxRi,opfj'qhix	yn}hi\n0wMnxRghik¾afhxkEfhxk'ixZnhjmk
|LfjvRnhlzj¹sSdi|lòÀ|8oziLulz|Lfj¹sRry|nhsOSj'fuÁjnhkmkmlzvRlpfjZyvRmixRi\nxRi&sRd"i|lpòÀ|IdmxfsSfekylz|8|r'is$sRry|¹nhs
frmjmkmnxt£vSfj'isMnhjmkdynhrmsSiscefwMiOfhPvR'isRiOinvRr'xisMsRrm|nhsMopij'qhvRa|mflz|Li»fh¾afhxkysMnxRi
|ndmvRr'xik»lzj0fr'C
x D  BEBE8EDxryopisSiv*nhskylzsR|rmsRsRikJnf}hih
ùsk'is|Lxlpik0lzjEcei|LvRlpfjE­eyv¾Uf6wMivR'fekmfopfhqlpisK¾UixRi8|Lfw\dÀnxRik»fhxlzjm|Lfhxd"fhxnvRlzj'q,vR'iIin
vRr'xRiPåuæç-è éê ÖÖ´ ééÜlzjvSfvR'i5©~$©D ½ 'iaòyxsSv-¾UnhsvSfrmsSiUvR'i5mnhjmkuon"ioopikinvRr'xRi5lzj8vRmiUvSxnhlzjmlzj'q
sSivmvRmi8sSi|Lfjmk¼vSfMdixRfhxw sSidynxnvSiIiLudixlzw\ijvRsKvSfMdyxRikmlz|LvKvR'iinvRr'xRi8fhxPvR'ivSxnhlzjmlj'q\sSiv
ùsKvR'iinvRr'xRis*lzj0vRmivSxnhlzjmlzjmq&sSiv*nxiInhr'vSfwMnvRlz|nhozozt6dmxikmlz|LvSikZ'lpv*lzsKmfhd"ikJvRmnvvR'iIsStusSvSiw
¾Ufrmozk,dylz|gCr'd\vRmilzkmlpfsRtejm|LxnhsRlpis-fh"vRmi*j'flzsSt&kmnvRnu ½ mlzsDvSxnhljmlzj'q$w\ivR'fukMmnhs)iij\rmsRik,dmxRiL
}ulpfrmsRopt6lzj¢xlpqvÀàáháhá5¾mixRinhr'vSfwMnvRlz|nhozozt6lzk'ijvRlòyik0lzjvSfjmnvRlpfj0i}hijv*invRr'xRis*nxiIrmsSik
VT

"

Ë

2¤ZÌyÍ¬2­2«¤°2ÎSÏÁ2Ð-Ì

Ë

«7­¼ÑM1«mÌ

Ë

«7­¼ÒÓÏÁ¡2«¬

vSfvSxnhlzj¼nhjnhr'vSfwMnvRlz|CsSdii|unh|Lv$k'ivSi|LvSfhx ½ 'isSi&nhr'vSfwMnvRlz|nhozozt0kmixlp}hik»invRr'xRisPdmxRf}elk'i8n
ivSvSix5vSxnhlzjmlzjmq8w\fuk'iomvRmnhjJvR'i$mnhjmk'ozniozopik,fj'is ½ mlzs~ls~vSxrmiPnhozsSf,lzjvR'i|rmxRxRijvUsSvRryk'tMnhs
kmlzs|rmsRsSik0lzjEcui|LvRlpfj¼ïez
yYNX

b?éí'`féébH^ ]
ì

] _

¤ `lê`lë Q
v

^ëzx

½ mlsPdÀnd"ix$xRidfhxRvRs$xisRrmopvRs$fjnhr'vSfwnvRlz|nhozoptvSxnhlzjmlj'qJnO©~xRfhyopiwnvRlz|C$lznhozfhqr'iM©GxRikylz|LvSfhxvSf
dmxRikylz|LvPdyxRfhyopiwMnvRl|CermwMnhju|LfwMdyr'vSixkmlznhopfhqrmisrysRlzj'q0n0|LfhxRdyrms$fhaøïhhà0kmlznhopfhqr'is|Lfoopi|LvSik
¾lpvRCvR'iú ÷ûü£¶hýþ ú ´L· Ôÿ ÷ êsSdfhghij,kmlznhopfhqr'i5sStusSvSiwO ½ 'i5©GxRfhÀopiwMnvRlz|U$lznhopfhqr'iK©Gxikmlz|LvSfhx
|nhji6lzww\ikmlznvSiopt£ndydyozlpikvSfvRmi0sRtesSvSiw»ØÙs&kmi|lzsRlpfjfh¾mivR'ixCvSf¹vSxnhjysSix,vR'iO|nhozoavSf£n
ermwMnhjö|rmsSvSfw\ixO|nxRinqhijvPfhx0iErmsRik?nhs0n;|r'iEvSfvR'i¹sStusSvSiwOØÙs0$lznhopfhqr'i¹ÚnhjmnqhixOvSf
w\fukmlptlpvRsM"iyn}ulpfhxMvSf£xRidÀnhlpx\vR'i»dmxfhyopiwMs\lzkmijvRlòÀikZ ½ 'i»xRisrmopvRs\sR'f¾ vRmnvºÛ	\ÚEfsSv
invRr'xRi,sSivRs$sRlpqjmlò"|nhjvRoptOlzwMdmxRf	}hi&f	}hixvRmiCynhsRiozlzj'ih¡)/à
 :PsRlj'q6nhr'vSfwnvRlz|8invRr'xRisxRfw vR'i
¾'foziJkmlnhopfhqr'ihG¾Ui»|nhjälzk'ijvRlptdmxRfhyopiwnvRlz|6kylznhopfhqr'isMàáñÂivSvSix\vRmnhjvR'iOÀnhsSiozlzj'ih¡$ ;
{ rysSvvR'iCòyxsRv*iLu|mnhj'qhi,dmxRf}elk'isPslpqjmlòÀ|nhjvRopt0ivSvSixPdyxRikmlz|LvRlpfj; ;ñM*vRmnhjvR'i8ynhsRiozlzj'ih¡)ø
½ 'isSi|Lfjmk6iLu|mnhj'qhi$dmxRf}elk'is~nhjJnhkmkmlpvRlzfjmnhomsRlpqjylòÀ|nhjvPÛ< ;ñM~lzw\dmxRf}hiw\ijvZ/­~ùÝ|oznhsRslòyix
ynhsSikJfj0vRnhsSglzjmkmid"ijyk'ijv5nhr'vSfwMnvRl|PinvRr'xRis5dixRfhxwMs5sRolpqvRozt\"ivSvSixKvRynhj6fjmivSxnhlzj'ikJfj
vR'iIrmozonhr'vSfwnvRlz|invRr'xRi8sSiv
½ miGlzw\dmxRf}hikInylzolpvtPvSf*dmxRikml|Lv"dyxRfhyopiwMnvRl|)kmlznhopfhqr'isZlslzw\dfhxRvRnhjvfhxZòÀiozkmlzj'q5vR'i 
Cf
sStusSvSiw ¾lpvR'frmvPvR'i,j'iikfhxvRmi&f}hixsRlpqvfh~n0ermwMnhj|rmsSvSfw\ixI|nxRi\nqhijv ½ 'isRiCxRisrmopvRs
nxRi,dmxRfwlzsRlzj'qJnhjmk¾ai,iLudi|LvvSfOi,nyopi,vSfOlzw\dmxf	}hi\r'dfj¼vRmiwOZdfsRsRlpyoztJetEljm|LfhxRdfhxnvRlzj'q
dmxRfsRfek't6lzjvSf\vRmiinvRr'xi$sRivCªPlzxsR|ixRq,iv*nho/phhUfhx*iLudynhjmkylzj'q&fj0vR'iCëìíEinvRr'xRiIsRivRs
ÁÛj&nhkykmlpvRlpfjZvR'i5xRisrmopvRssRr'qhqhisSv)vRynvDvRmi*|r'xRxRijvD©a$©£lzsozlpghiopt8vSfqhij'ixnhozlpãi5vSf$fhvR'ix~kylznhopfhqr'i
sStusSvSiwMs
ÁÛj\r'vRr'xRi5¾UfhxRgÀ¾aidyoznhj,vSf8lzjvSiqhxnvSi*vRmiopinxj'ik,xrmopisSivRsGljvSfvR'i 
Cf kmlznhozfhqr'i*sStusSvSiw
nhjmkEi}nhormnvSiCvRmi&lzwMdynh|LvvRmnv$vRmls*¾Ufrmozkmn}hi&fjvR'i&sRtesSvSiw»ØÙsPf}hixnhozoDdixRfhxwMnhjm|Lih ½ 'ixRi
nxRi,sSi}hixnho-¾Un	tes¾Ui&wlpqvPiCnyopiCvSfJs'f	¾ vRmlzs
 iw\iwC"ixvRmnvfj'i,rmsSi8fh)vRmiC©~$©ÝlzsvSf
lzw\dyxRf	}hi5vR'iKsStusSvSiwOØÙsGkmi|lzsRlpfjCfhÀ¾P'ivR'ix)nhjmk,¾'ij&vSfvSxnhjysSix)n|nhozoevSfvR'iKermwMnhj\|rmsRvSfw\ix
|nxRi\nqhijv ½ 'i8fhvRmix$rysSiC¾Ufrmozk¼i&nhs$lzj'dÀr'v*vSfJvR'i&$lznhozfhqr'i&ÚnhjmnqhixØÙskylznhopfhqr'i,sSvSxnvSiqht
sSiopi|LvRlzfj¼w\i|mnhjmlzsRw»~iw\fjmsSvSxnvRlj'qMvR'i8rmvRlzozlpv tfhvR'i8©a©?fhxPkmlznhozfhqr'iIsSvSxnvSiqht»sSiozi|LvRlpfj
xRi¿ermlpxRisDiLudixlzw\ijvRsvRmnv)vSisSvGfrmvGsSi}hixnhomkmlp§"ixRijv¾Un	tesGvRmnv)vRmlzs)lzjmfhxwnvRlpfj,|Lfrmozk,iKrmsSik
et&vRmiP$lznhopfhqr'iÚEnhjynqhix~iw\fjmsSvSxnvRlzj'q8vRmir'vRlzozlzvt&fhZvR'iP©a©;fjvR'iPk'i|lsRlpfj\vSfCvSxnhjmsSix
nJ|nhozoj'i|LisRsRnxloptOlzj}hfoz}hisPiL'nhwMlzjylzj'qvRmiCvSxnhkmif§snhw\fjmqJkmlp§"ixRijvgelzjykms*fhGixxRfhxs ½ mlzsPlzs
i|nhrmsSiPi}hixRt6|nhozoyvRmnvUvR'i 
Cf sRtesSvSiwÓ|nhjJmnhjmkmozisRrm||LisRsRrmoopt\sRn}hisKnC|Lfw\dynhjtMvR'i$|LfsSv
fhGrmsRlj'qMnMermwMnhj¼|rysSvSfw\ix$|nxRiCnqhijvPvSfJmnhjmkmozivR'iC|nhozoH ½ ermsy¾ai&|nhjEnhsRsRfe|lznvSi&vRmlzs|LfsSv
¾lpvR£vR'i6k'i|lsRlpfjvRmnv  wMnghis&vSf¼vSxnhjmsRixCvR'i6|nhozoHJ¢â'ij Cf vSxnhjmsSixsIvR'iJ|nhozo
rmjmjmi|LisRsRnxlzozth¾Ui$|nhooyvRmlsa|LfsSv5vR'i ·p÷ é ³~¶ ê ³Hh÷ \¶³±÷²£Ö÷ é ³ U®jvR'ifhvR'ix*mnhjykZi}hixRtJ|nhozoÀvRmnv
 nvSvSiw\dmvRs$vSfOmnhjykmopi8nhjmkEnhlzozsÀ¾afrmok¼dfhvSijvRlznhozoptOnh||Lxr'i\nJkml§ixRijvP|LfsSvjmnhwMioptOvR'i
opfsSvCxRi}hijer'i6xRfwÃ|rmsSvSfw\ixs8¾mf¼i|Lfw\i0lpxRxlpvRnvSik¾lpvRnhrmozvt£|rmsSvSfwMix,sRixR}el|Li6nhjmkvRnghi
vR'ilpxÀrmsRlzj'issPiosSi¾'ixRih,¢i|nhoovRmlzs|LfsSvIvRmi0é ý é ³´  I¶±· ê µS´JÖ÷ é ³ MÁÛj¹vR'i\xRisrmopvRs$vRmnv¾Ui
dmxRisRijvSik'ixRih"¾ai&xRidfhxRvPfjmoptOf	}hixnhozonh||r'xnh|Lt»xRisrmopvRsnhjyk¼vSxRinv ·p÷ é ³*¶ ê ³Hh÷ \¶³±÷²äÖ÷ é ³ nhjmk
é ý é ³´  I¶±· ê µS´Ö÷ é ³ nhsPi¿ermnhozozt»|LfsSvRopthªf¾ai}hix	Ülzjnhjt»dÀnxRvRlz|rmoznxlzjmsSvRnhooznvRlpfj»fh~vR'i 
Cf
sStusSvSiwO"vR'ixRi&wMnt»i&kml§ixRijm|Lis*iv ¾aiijvR'isSi,|LfsSvRsvRmnvP¾afrmok¼j'iikEvSf6i&nh||LfrmjvSikfhx
lzj\vRmi*vSxnhlzjmlj'q$fh"vRmi©~$©DÁvG¾Ufrmozk\iKdfsRsRlpÀopi5vSf8rmsSC
i D  BEBE8ED0vSf&k'fvRmlzslp"vR'isSiP|LfsRvRsG¾UixRi
guj'f	¾j't0rmsRlzjmq,lzvRs*nylzozlzvtvSf}nxRtJvR'i8ozfsRsKxnvRlpf'
VT 2

>

°«7«¬2­

> ¡9?¢f«7A@d«.¤¡­2±2

ùj'fhvR'ixdfhvSijvRlznho)lzsRsRrmi8fhxr'vRrmxRiC¾UfhxRglzsvR'iMr'vRlzozlzvtOfhanOkylznhopfhqr'i,opi}hioDdmxRikml|LvSfhxZih q'
vR'i¼©a$©-~}es?nhjr'vSvSixnhjm|Liopi}hioKdmxikmlz|LvSfhxaih q'?vR'i ¶ ê ³H÷ èåuæç-è éê ÖÖ´ éé&dyxRikmlz|LvSfhxafhx6vR'i
qhfnhofhanhrmvSfwMnvRlz|nhozoptEnhkmndmvRlzj'q0nJsStesRvSiwOØÙskmlznhopfhqrmi&sSvSxnvSiqhth ½ mlzslzs$sR'f¾jEvSfO"iCiL§"i|LvRlz}hi
lzj Þ-lpvRwMnhj ©nhjZIàáháháC¾'ixRivR'itârmsSi£ndmxRfhyopiwnvRlz|¹kmlznhopfhqr'i£kmivSi|LvSfhxElzjâfhxkmix»vSf
nhkmndmvCvR'ikmlnhopfhqr'isSvSxnvSiqht£fhx&n»vSxnhljijm¿ermlpxRt¹sStusSvSiwO0Á v8¾afrmokiMdfsRsRlpyozihÜnhjmk£fhvRmixs
mn	}hinxRqr'ikõÞi}hf	¾8hh e¡MªPlzxsR|ixRqäiv¼nho/pMhheN
¡ ¡8lpx|y'f§Dàáhá'	»vRmnv»vR'ikylznhopfhqr'i
wMnhjmnqhix	ØÙsnhkmndmvRnvRlzfjk'i|lzslpfjms\|nhji»wMnhkmi»fjvR'i¼ynhsRlzs,fhopfu|nhoKimn}ulpfhx5l/ ihfjvR'i
ynhsRlsGfhZxRi|Lfhqjmlzãlzj'q8vRynvavR'i|r'xRxRijvarmvSvSixnhjm|Li$mnhs~iijJwMlzsRryjmk'ixsSvSfefukZhfhxavRynvavR'i|r'xRxRijv
r'vSvSixnhjy|Li»lzsCn¹|LfhxRxi|LvRlpfjZªPf	¾Ui}hixKlpv,lzsC|ozinx\vRmnv\vR'i0k'i|lzsRlpfj;vSf¹vSxnhjmsRix,vR'iO|nhozoUvSf£n
ermwMnhjO|rmsSvSfwMix*|nxRiInqhijvP|nhjmj'fhvKiwMnhk'i$fjOvR'i$ynhsRls5fhÜfjmoptJopfu|nho"lj'fhxwMnvRlpfjJi|nhrmsSi
vR'iJsStesRvSiwÂ|nhjfhvSijxRi|Lf}hix&xRfwÂn¼sRlzjmqopi\ixRxRfhx ½ ermsD¾UiiLud"i|LvCvRmnv8vRmi6nylzolpvtvSfEi
nyopi,vSf0dmxRikylz|LvPvRmiMkmlznhopfhqr'i&fr'vR|Lfw\iMnhs$¾UiMk'fO'ixRi,¾lozoÜ|LfjvRlzjer'i,vSfO"i,lzw\dfhxRvRnhjv$i}hijlzj
sStusSvSiwMsKvRynvrmsSiIopfu|nhoZdmxikmlz|LvSfhxs5fhxrmjmkmixsSvRnhjmkmlj'q&nhjyk»|LfhxRxRi|LvRlpfj
|Y
æ

ízx

] ^a}^ Q _a

Qy]

êé

f fj©~xnhsRsÜ$lznhjmiÞÜlpvRwnhjZ
 l|mnxkc'r'vSvSfjZ-ÚnãlzjKPnhmlzwónhjmkÚElz|mnioR¡inxjms
½ mnhjmges$vSª
fhxkmlzsR|rysRsRlpfjmsUfjO}nxlpfrysKnhsSdi|LvRs*fhvRmlzs5¾UfhxRg"
u¼Q~/Q ë

Qy] í Q
é

ùP"iooznuyùCpÓ«fhxlzjyù8)ÛhhIUfjmsSvSxry|LvnhopqhimxnuºKùjEnhjynhoptvRl|nhoÜw\ivR'fukEfhx$kmlznhopfhq6wMnhju
nqhiwMijvâÁÛm
j  µS÷Ö´´RÕ±
² Z é /÷ I _ [±µ³ý å ´ Á´L²À\³ [ ] ²y² ê ¶·aü´´³±
² Z/÷ I»\³ [u´ ]éé ÷	Ö±/¶h³±÷h^
² I÷µ
 h
÷  Ô"ê ³H¶³±÷²"¶· æ ±
² Z ê ± é ³±/Ö é
5nqhqlznu©Dp-5nhsSvRnqj'ixl/Ü«&pÜ $nhjmlziozl/Ú)Ûhh C¤lpiozk ½ xlznhozsPfhGvR'i,Á Rv nholznhjEù'*ÁRc ½ x nhlzj
½ lzw\ivRnyopiCcutesSvSiw»~ÁÛj þ²y³´µÛ¶Ö	³±fÁh´Sm÷±/Ö´ _ ´RÖ [²À÷·p÷}Zhý#I÷µ _ ´L·z´RÖ÷r+ ê ²y±Ö¶h³±÷h² é]5ÔÔ ·!/± Ö¶ è
³±/÷² zé c 
þ  _%_]Iudmdysî Àáàe
UxlpiwMnhj~ÞGp5¤'xlpikywMnhjZ { ªCp*®$ozsR'ijRIGùCp5¬cevSfjmih5 { KÛh øN ·¶ éé ± aÖ¶³±÷²¯¶²"Õ
 ´ ZhµR´ éé ±/÷² _ µS´´ éG¢£nhkmsS¾UfhxRvR¼nhjyk»UxRffhgusyÚEfjvSixRitE5nhozlpfhxjmlnu
5nvRopivSv


{ Ûhu	GÚEiqnhlzjmkyrm|LvRlpfjZºGùÝvSisRvÀlpqvÜÁÛjX µÛ÷	Ö´´Õ±²Z é ÷/I³\[u´5±ðZr[e³\[Mþ²y³´µ²"¶h³±÷h²À¶·
÷h²<I´µS´²ÀÖ´M÷²¼ü£¶Ö [±²´ æ ´R¶µ²m±²Z 

5eru5nxRxfozo/ { p'×5nxRdijvSix'Ûhh)i|LvSfhxSHÀnhsSik»jmnvRr'xnhoÀoznhjmqrmnqhi|nhooÀxfr'vRlzj'q'& ÷h è
Ô"ê ³H¶³±÷²"¶· æ ±²1Z ê ± é ³±Ö é Ä èh7;hïu81;h î
Uf'ij¢ "Ûhh­-¤ynhsSv~iL§i|LvRlp}hixrmopiljmkmrm|LvRlpfjmÁj µS÷Ö´´RÕ±²Z é ÷/I³\[u´
 ÷h²<I´µS´²ÀÖ´M÷²¼ü£¶Ö [±²´ æ ´R¶µ²m±²Z 

_ ûa´· IL³\[,þ²y³´µ²"¶h³±÷h²À¶·

Uf'ij"¢ ~Ûhhï,Þinxjmlj'q6vSxiisInhjmkxrmopisP¾lpvR¹sSivÛH}nhozr'ik¹invRr'xRisIÁjO ÷ ê µ³´´L²y³\[
I´LµR´L²"Ö´,÷/I8³\['´ ] ´Lµ±Ö¶² ]$éé ÷Ö±¶h³±/÷²÷/I ] µ³± aÖ±¶·þ²y³´L··#±ðZ´²ÀÖ´ 


÷² è

*ùPwMwlz|veùCe«&pu¯ùopfjmsSf' ½ ÀÛhh¡8j'f	¾ozik'qhi|Lfozopi|LvRlzfjMfhxajmnvRr'xnhoyoznhj'qrynqhisSdfhghij
kylznhopfhq8sStusSvSiwMs"ÁÛj µÛ÷	Ö´´Õ±²Z é ÷/P
I ³\'[ ´' ê µS÷ Ô ´R¶h²  ÷²<I ´LµR´L²"Ö´I÷h² åhÔ ´´Ö[  ÷r+ ê ²m±/Ö¶³±÷²
¶h²ÀÕ _ ´Ö[ ²"÷·÷hZ ý 
VT!

Ë

2¤ZÌyÍ¬2­2«¤°2ÎSÏÁ2Ð-Ì

Ë

«7­¼ÑM1«mÌ

Ë

«7­¼ÒÓÏÁ¡2«¬

¤mr'xj'gxnhj'ãh { pm¢âlzkmwMix'«,ZÛhø~Ájm|Lxiw\ijvRnho"xRikyrm|LikJixRxRfhx5dmxrmjylzj'q'ZÁÛjX µÛ÷	Ö´´Õ±²Z é ÷/I
\³ ['´ 5·z´Á´²y³\[V8¶³±÷²"¶·  ÷²pI´µS´²ÀÖ´,÷²¼ü¶Ö[±²"´ æ ´R¶µ²m±²Z 
«fhxljZùCphlz||nxkml/«&pä¢xlzqv
Ä h-h< ;Ààî
{

eÛhîh'ªf¾äÚEn	tIÁªiozd8¸GfrqmåÔ ´´Ö[


÷hb ê ²m±/Ö¶h³±/÷² 

ªlpxsR|ixRq' { mpyÞ-lpvRwMnhjZm& { p y ce¾UixRvRsmÚ-Ûhha©~xRfsSfukmlz|$|r'isKvSfMxi|LfhqjmlpvRlpfj0ixRxfhxs
ÁÛ6
j  µÛ÷ÖG÷/I8³\['´ ]ê ³H÷rM¶h³±Ö å Ô ´´Ö[  ´Ö÷}Z²m±³±/÷²¶h²ÀÕ ç ²"Õ´Lµ é ³H¶²"Õ±²1Z¼÷µ ¾	é [e÷ ÔÀ
ªlpxsR|ixRq' { pGÞÜlpvRwnhjZ)C { p)óce¾UixRvRs)Ú*/àáháhá«ij'ixnhozlzãlzj'q»dmxfsSfekylz|Mdmxikmlz|LvRlpfj
fhsSdii|xRi|LfhqjylpvRlpfjixRxRfhxs£ÁÛj µÛ÷	Ö´´Õ±²Z é ÷/IO³\[u´T³\[þ²À³´Lµ²À¶h³±/÷²À¶·  ÷h²<I´µS´²ÀÖ´÷/I
åÔ ÷ ¾ ´² æ ¶1
² Z ê <¶ Z´  µÛ÷	Ö´ éé ±
² ZYþ -åuæ Kè ÄGz8 
ªlpxsR|ixRq' { upuÞ-lpvRwMnhjZu& { p'×cu¾aixRvRsuÚZ/àáhá'nGPivSi|LvRlj'q\wMlzsSxRi|LfhqjylpvRlpfjmsUnhjmkJ|LfhxS
xi|LvRlpfjms)lzj&sSdfhghij\kmlznhopfhqrmiUsStusSvSiwMsDxRfwÓØÙn¾5nxRihØsRlzvSis'Áj" µÛ÷Ö´´Õ±²1Z é ÷/I*³\[u´V¼÷hµ ¾é [e÷ Ô
÷h²  µÛ÷ é ÷Õý0±² åhÔ ´´Ö [  ´Ö}÷ Z²m±³±÷²;¶²ÀÕ ç ²"Õ´Lµ é ³H¶²"Õ±1
² Z 
ªlpxsR|ixRq' { DPpGÞ-lpvRwMnhjZ& { pG ce¾UixRvRs)Ú5/àáhá'L¼ÁÛk'ijvRlztulzj'q¼rysSixC|LfhxRxi|LvRlpfjms,nhru
vSfwnvRlz|nhozopt¹lzjsSdfhghij£kmlnhopfhqr'i\sStusSvSiwO\ÁÛj, µS÷Ö´´RÕ±²Z é ÷/IM³\[u´ å ´Ö÷²ÀÕ»ü´´³±²Z÷/I³\['´
C÷µL\³ [ ] ´Lµ±Ö¶²  [e¶ Ô ³´µ&/÷ IC\³ [u´ ]$éé ÷Ö±¶³±÷
² I÷µ  ÷h Ô"ê ³H¶³±÷²"¶· æ ±²Z ê ± é ³±/Ö é

¡Ilpx|m'f§¡M/àáhá'	eù|Lfw\dynxlzsSfjfhu|oznhsRsRlpòÀ|nvRlpfjvSi|mjmlz¿er'isZfhxÜvR'ianhr'vSfwMnvRlz|GkmivSi|LvRlpfj8fh
ixxRfhx~|LfhxRxRi|LvRlzfjms~lzj\ermwMnhj'|Lfw\dyr'vSixGkmlnhopfhqr'isÀÁjQ µÛ÷Ö´´Õ±²1Z é ÷{
I ³\u[ ´'C÷µL³\[ ] 
 ´Lµ±Ö¶²
] æ ¼÷µ 	¾ é e[ ÷ Ô ÷² ] Õ¶ Ô ³H¶³±÷²±²W$þL¶·÷Z ê ´ å ý é ³´  é
ü´´³±²0
Z ÷/C
I ³\u[ ´- ]')
¡xnhyw\ixp'ce¾UixRvRseÚp ½ 'irmjmihÚpeÝ¢iiqhios'ÚÛhhnÜ©GxRfhÀopiw sSdfhvSvRlzj'qClzj\rywMnhju
wnh|mlzjmiIlzjvSixnh|LvRlpfjZGÁÛj6 µS÷Ö  ê µS÷ éHÔ ´´RÖ T
[  
¡xnhyw\ixp$ce¾UixRvRs$Úp ½ m irmj'ihPÚpÃ¢iiqhiozsÚ8Ûhh©~xRfsSfukmlz||LfhxRxRioznvSisOfh
kylzsR|LfjuòyxwMnvRlpfjmsÁÛj  å#] ¼÷µ ¾	é [e÷ Ô ÷h²Cþ²y³´LµS¶Ö³±\Á´8±¶·p÷}Z ê ´5±²Cü ê ·³± è ü÷Õ¶· å ý é ³´  é
ÞÜnhjmqhgelzok'ihKÁpP¢£nhopghixÚKùCp¢xlpqv { p«fhxljZùCpÃÞÜlpvRwnhjZ*&ÛhhõùPr'vSfwnvRlz|
dyxRikmlz|LvRlpfjfh*dmxRfhÀopiwMnvRlz|6rmwnhju|Lfw\dyr'vSix,kmlznhozfhqr'isCljªPf	¾ ÚntÁIªPiopd;¸GfrqEÁÛj
 µÛ÷	Ö´´Õ±
² Z é /÷ I*\³ ['´aRþ ¼÷µ ¾	é [u÷ Ô ÷² ]ê ³Hr÷ M¶h³±/Ö åhÔ ´´RÖ [  ´Ö}÷ Z²m±³±/÷²¼¶²"Õ ç ²ÀÕ´µ é ³H¶²ÀÕ è
±
² Z ce]$å  çç z 
Þi}hf¾I«& ùCuÛhh y5ynxnh|LvSixlpãlzjmqnhjmkIxi|Lfhqjmlpãlzj'qsSdfhghij8|LfhxRxi|LvRlpfjmsDlzj8ermwMnhju|LfwMdyr'vSix
kylznhopfhqr'ihUÁS
j  µS÷Ö´´RÕ±
² Z é /÷ IC\³ [u´  \³ [ ] ²m² ê ¶·ü´´³±1
² ZO/÷ IC\³ [u´ ]$éé ÷Ö±¶h³±/÷²{÷ I  r÷  ÔÀê ³H¶ è
³±/÷²À¶h· æ ±
² Z ê ± é ³±/Ö é'dmdÀrî ;hï uîøàe
ÞÜlzvRwMnhjZm& { pÀªPlpxsR|ixRq' { ypÀõce¾aixvRsyÚ-/àáháháK©GxRikml|LvRlzj'q\nhr'vSfwMnvRlz|CsSdii|Oxi|Lfhq
jylpvRlpfjd"ixfhxwnhjm|Li6rmslzj'q¼dyxRfsSfukmlz|M|r'isÁÛj µS÷Ö´´RÕ±²Z é ÷{IJ³\[u´  ±µ é ³ü´´³±²Z£÷{I0³\['´
C÷µL\³ [ ] ´Lµ±Ö¶²  [e¶ Ô ³´µ&/÷ IC\³ [u´ ]$éé ÷Ö±¶³±÷
² I÷µ  ÷h Ô"ê ³H¶³±÷²"¶· æ ±²Z ê ± é ³±/Ö é
ÞÜlzvRwMnhjZÀ& { pZ ©nhjZÜc"/àáháhá©GxRikml|LvRlzj'qnhjmknhkmndmvRlj'qvSfJdffhx$sSdii|ExRi|LfhqjmlpvRlzfjElzjn
sRd"fhghijkmlznhopfhqr'i*sRtesSvSiw»yÁÛjV µS÷ÖÜ÷/IP³\[u´ å ´Á´²y³´´²y³\[\8¶³±÷²"¶·  ÷h²<I´µS´²ÀÖ´$÷h² ] µ³± aÖ±¶·
þ²À³´L··#ð± Z´²ÀÖ´ c]]'] þ è ÄGz 
ÞÜlzvRwMnhjZuC { p¢£nhopghix	mÚ'ùCp' ¡inxjmsuÚ { ZÛhh)ùPrmvSfwMnvRlz|$k'ivSi|LvRlpfj0fhdfefhxUsRd"ii|
xi|LfhqjmlpvRlpfj\nv)vR'i*kylznhopfhqr'i5opi}hio/'ÁÛjQ µS÷Ö´´RÕ±²Z é ÷/I*³\[u´ _ [±µ³ý å ´Áh´L²y³\[ ] ²y² ê ¶·ü´´³±²1Z
{÷ I8\³ [u´ ]éé ÷	Ö±/¶h³±÷h²/÷ I  r÷  ÔÀê ³H¶h³±/÷²À¶· æ ±²Z ê ± é ³±Ö é'dmd=;á1;uïe
VT

&

>

°«7«¬2­

> ¡9?¢f«7A@d«.¤¡­2±2

l||nxkml/~«&pGó«fhxlzjùC*/àáháhá;cedfhghijoznhj'qrmnqhiOnhkmndyvRnvRlpfj;f	}hixMvRlzwMi6nhjmksSvRnvSi»lzj;n
jynvRr'xnhoGsSdfhghij£kylznhopfhqOsStusSvSiwO þR _ µS¶² é ¶Ö³±/÷² é ÷² åhÔ ´´Ö
] ê Õ±/÷  µS÷Ö´ éé ±²Z 
[ ¶²ÀÕ 
; Àáu
 Û	
cunhjmkmixwMnhjZGùCp5cevRrmxwO { p~k'ij®$st*paUf}hisKÞGpUóUxiw\ixs~ùCÛhh ³G}nhozrmnvRlzfjfh
vRmikmrmvR|vSxnhlzj?vRlzw\ivRnyopi¹lzj'fhxwMnvRlzfjsStusSvSiw k'i}hiopfhdikölzjvRmiù'*ÁRcdmxRf  Si|Lv ÁÛj
þ²À³´LµS¶Ö³\± Á
´ y÷±Ö´ _ ´Ö [²À÷h·}÷ Z+
ý IL÷µ _ ´·p´Ör÷ + ê ²m±Ö¶h³±/÷² é]5ÔÔ ·!±/Ö¶h³±/÷² ézc þ _%_1]dydÜu8
hïe
ceij'iL§c"pe¨Zr'ihCp©-folpxfjml/ { p©nf'u$pªivR'ixlzj'qhvSfjZÞ~p«fukmk'inhrZ&p¯«oznhsRs { 'Ûhh­
½ 'iMdmxRiolzwMlzjmnxt¼k'i}hiopfhdywMijvIfh*n¼kmlzsSdyontuopisRs©a5«$ùc:$csStesRvSiwO6ÁÛj ]  ]ôåhÔ ÷ ¾ ´²
æ ¶
² Z ê p¶ Z´ _ ´RÖ [²À÷·p}÷ Zh
ý ¼÷µ ¾	é [e÷ ÔÀ
cu'xlpixRq'ep)¢£nhk'ihapaô©~xlz|LihG©D*ÛhhàªrmwMnhjuwMnh|mlzj'i6dmxRfhyoziwÂsSfoz}elzjmqErmsRlj'q¼sSdf
ghijonhj'qrmnqhi,sStesRvSiwMs\HcuÞDcmº¤mnh|LvSfhxs8n§"i|LvRlzjmqJdixRfhxwMnhjy|LiCnhjmk¹rmsSix$sRnvRlzsRnh|LvRlpfjÁÛj
 µÛ÷	Ö´´Õ±
² Z é /÷ I8\³ [u´  ]  ] åhÔ ´´RÖ [E¶²À)
Õ  æ ¼÷µ ¾	é [u÷ ÔÀydyd'ø e­ø'
ce¾UixRvRsKÚp*ÞÜlpvRwMnhj5& { p*¬ªlpxsR|ixRq' { ~/àáháhá UfhxxRi|LvRlpfjms6lzjsSdfhghijkylznhopfhqr'i
sRtesSvSiwsÜÁÛ
j  µÛ÷	Ö´´Õ±²Z é ÷/I$³\[u´³\[þ²y³´Lµ²À¶h³±/÷²À¶·  ÷h²<I´µS´²ÀÖ´&÷/I åhÔ ÷ ¾ ´L² æ ¶h²Z ê ¶<Ze´  µÛ÷ è
æ 5è ÄG  
Ö´ éé ±
² ZSþ -åu*
¢£nhopghixÚZù8p¤mxRfw\ix { Zp¥nxntnhjmnhjDc")Ûhh CÞinxjmlzj'qJfhdmvRlzwMnhoDkmlznhozfhqr'i&sRvSxnvSiL
qlzisº8ùÓ|nhsSisSvRryk'tEfhKn»sRd"fhghijkmlznhopfhqr'iMnqhijv8fhxIiwMnhlo/\Áj+ µS÷Ö´´RÕ±²Z é ÷/I³\[u´  ³\[
] ²m² ê ¶·"ü´´³±² ZO/÷ IC\³ [u´ ]$éé ÷Ö±¶³±÷²;/÷ I  r÷  ÔÀê ³H¶h³±/÷²À¶· æ ±² Z ê ± é ³±Ö éc&¡~æ þRQ¢£ ])æ  
dyd< ;ø­ À< ;h­hàe
¢£nhopghix'ÚùCp1¡8nhwMwOu$ù8p'¯Þ-lpvRwMnhjZe& { /àáháháhn ½ f	¾5nxkmsUk'i}hiopfhdylj'qIqhij'ixnhoÀw\fuk'iozs
fh"rmsRnylozlpvt¾PlpvRC©'
ù ùÁS
c mÁÛj C¶h³ ê µS¶· æ ¶h²Z ê ¶<Ze´$K²Zh±²"´´Lµ±²Z¤ åhÔ ´Ö±/¶·eþ ééê ´÷²)¥$´ é ³
 µÛ¶Ö³±/Ö´&±² åÔ ÷ ¾ ´6
² 8±¶·p}÷ Z ê ´ å ý é ³´  é
¢£nhopghixaÚù8p)Þ-nhj'qhgelozk'ihÁp¢xlzqv { pG«$fhxlzjZ)ùCp~ôÞ-lpvRwMnhjZ)&5/àáháhá¹ÞÜinxjmlzjmq»vSf
©~xRikmlz|LvU©GxRfhÀopiwMnvRlz|$culpvRrmnvRlpfjysGlzjn\cedfhghijJlnhopfhqr'i$cutesSvSiw»ºGedixlw\ijvRs~¾lpvR6ªf¾
ÚntEÁªPiopd¼¸Gf	
r hÁY
j  µS÷Ö´´RÕh±
² Z é /÷ I&\³ ['Z
´ C÷µ\³ [ ] ´Lµ±Ö¶²ü´´³±
² Z»{÷ I&\³ [u´ ]$éé ÷Ö±¶³±÷²

"
Ô
ê
æ
ê
é

é

I÷µ h÷  ³H¶³±÷²"¶· ±² Z ± ³±/Ö
¢£nhopghixGÚù8pGÞ-lpvRwMnhjZ)&pR¡InhwMwO~Dù8p~ ùP"iooznuDùCKÛhîh¹©ù'ùÁScº-ù qhijmixnho
xnhw\i¾UfhxRg»fhxi}nhozrynvRlzj'q6sRd"fhghij¹kmlnhopfhqr'iCnqhijvRsÁjY µS÷Ö´´RÕh±²Z é ÷/I&³\['´  h³\[ ] ²m² ê ¶·
ü´´³±
² Z/÷ I6\³ [u´ ]$éé ÷Ö±¶³±÷²ö/÷ I  r÷  ÔÀê ³H¶h³±/÷²À¶h· æ ±
² Z ê ± é ³±/Ö éc])æ £ ]"æ ¦ GdmdDàîe8
àh áu
¢£nhopghixÀÚmùCpm¢xlpqv { py ÞÜnhj'qhgulzozk'iheÁÜ/àáháháh|	t:sRlzj'q\jmnvRr'xnhoZoznhj'qrmnqhidmxfe|LisRslzj'q\nhjmk
kylzsR|Lfr'xsRiMinvRrmxRis8vSflzk'ijvRlptrmjyk'ixsSvRnhjmkylzj'q0ixRxRfhxsClzjnEsSdfhghijkmlnhopfhqr'isStusSvSiwOOÁÛj
 µÛ÷	Ö´´Õ±
² Z é /÷ I8\³ [u´ å ´ Á´²y³´´²y\³ [6þ²y³´Lµ²À¶h³±/÷²À¶·  ÷<² I´LµR´L²"Ö´,÷²¼ü£¶Ö [±²"´ æ ´¶µ²m±1
² Z 
¢ilzsRsIc*Úp­¡8rmozlpghf¾sSgul/8Ûhu	§ ÷h Ô"ê ³´µ å ý é ³´  éµ_ [u¶h³ æ R´ ¶µ²q¤  · ¶ éé ± aÖ¶³±÷²
¶h²ÀÕ  µS´Õ±Ö	³±÷h²ü´\³ [e÷Õ é IµÛh÷  å ³H¶h³± é ³±/Ö éc &´ ê µS¶·¨C´³ éc £
ü ¶Ö [±²´ æ ´ ¶µ²m±²1Z c ¶ ²ÀÕR¿ Ô ´LµL³
å ý é ³´  éKcunhj»ÚnvSif'5ùCºyÚEfhxRqnhª
j ¡8nhr'wnhjmjZ
¢xlpqvªC$/àáháhá ü£÷	Õ´L··#±²Z  µÛ÷ é ÷Õ±/Ö;¶²ÀÕA8±/¶·÷Z ê ´Oþ²<I÷µzM¶h³±/÷²UIL÷µ 
] ê ³H÷rM¶h³±/Ö åhÔ ´´RÖ[
 ´RÖ
÷ Zh²m±³±÷h² U©aZÙ&mvR'isRlsE:Pjylp}hixsRlpv tfh~kylzjÀr'xRqZ
VT 3

Journal of Articial Intelligence Research 16 (2002) 135-166

Submitted 7/01; published 2/02

Improving the EÆciency of Inductive Logic Programming
Through the Use of Query Packs
hendrik.blockeel@cs.kuleuven.ac.be

Hendrik Blockeel

Katholieke Universiteit Leuven, Department of Computer Science
Celestijnenlaan 200A, B-3001 Leuven, Belgium

luc.dehaspe@pharmadm.com

Luc Dehaspe
PharmaDM, Ambachtenlaan 54D, B-3001 Leuven, Belgium

Bart Demoen
Gerda Janssens
Jan Ramon

bart.demoen@cs.kuleuven.ac.be
gerda.janssens@cs.kuleuven.ac.be
jan.ramon@cs.kuleuven.ac.be

Katholieke Universiteit Leuven, Department of Computer Science
Celestijnenlaan 200A, B-3001 Leuven, Belgium

henk.vandecasteele@pharmadm.com

Henk Vandecasteele

PharmaDM, Ambachtenlaan 54D, B-3001 Leuven, Belgium

Abstract

Inductive logic programming, or relational learning, is a powerful paradigm for machine
learning or data mining. However, in order for ILP to become practically useful, the
eÆciency of ILP systems must improve substantially. To this end, the notion of a query pack
is introduced: it structures sets of similar queries. Furthermore, a mechanism is described
for executing such query packs. A complexity analysis shows that considerable eÆciency
improvements can be achieved through the use of this query pack execution mechanism.
This claim is supported by empirical results obtained by incorporating support for query
pack execution in two existing learning systems.
1. Introduction

Many data mining algorithms employ to some extent a generate-and-test approach: large
amounts of partial or complete hypotheses are generated and evaluated during the data
mining process. This evaluation usually involves testing the hypothesis on a large data set,
a process which is typically linear in the size of the data set. Examples of such data mining
algorithms are Apriori (Agrawal et al., 1996), decision tree algorithms (Quinlan, 1993a;
Breiman et al., 1984), algorithms inducing decision rules (Clark & Niblett, 1989), etc.
Even though the search through the hypothesis space is seldom exhaustive in practical
situations, and clever branch-and-bound or greedy search strategies are employed, the number of hypotheses generated and evaluated by these approaches may still be huge. This is
especially true when a complex hypothesis space is used, as is often the case in inductive
logic programming (ILP), where the sheer size of the hypothesis space is an important
contribution to the high computational complexity of most ILP approaches. This computational complexity can be reduced, however, by exploiting the fact that there are many
similarities between hypotheses.

c 2002 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

Blockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteele
Most ILP systems build a hypothesis one clause at a time. This search for a single clause
is what we will be concerned with in the rest of this paper, and so the word \hypothesis"
further on will usually refer to a single clause. The clause search space is typically structured
as a lattice. Because clauses close to one another in the lattice are similar, the computations
involved in evaluating them will be similar as well. In other words, many of the computations
that are performed when evaluating one clause (which boils down to executing a query
consisting of the body of the clause) will have to be performed again when evaluating the
next clause. Storing certain intermediate results during the computation for later use could
be a solution (e.g., tabling as in the XSB Prolog engine, Chen & Warren, 1996), but may be
infeasible in practice because of its memory requirements. It becomes more feasible if the
search is reorganised so that intermediate results are always used shortly after they have
been computed; this can be achieved to some extent by rearranging the computations. The
best way of removing the redundancy, however, seems to be to re-implement the execution
strategy of the queries in such a way that as much computation as possible is eectively
shared.
In this paper we discuss a strategy for executing sets of queries, organised in so-called
query packs, that avoids the redundant computations. The strategy is presented as an adaptation of the standard Prolog execution mechanism. The adapted execution mechanism
has been implemented in ilProlog, a Prolog system dedicated to inductive logic programming. Several inductive logic programming systems have been re-implemented to make use
of this dedicated engine, and using these new implementations we obtained experimental
results showing in some cases a speed-up of more than an order of magnitude. Thus, our
work signicantly contributes to the applicability of inductive logic programming to real
world data mining tasks. In addition, we believe it may contribute to the state of the art in
query optimisation in relational databases. Indeed, in the latter eld there has been a lot of
work on the optimisation of individual queries or relatively small sets of queries, but much
less on the optimisation of large groups of very similar queries, which understandably did
not get much attention before the advent of data mining. Optimisation of groups of queries
for relational databases seems an interesting research area now, and we believe techniques
similar to the ones proposed here might be relevant in that area.
The remainder of this paper is structured as follows. In Section 2 we precisely describe
the ILP problem setting in which this work is set. In Section 3 we dene the notion of a
query pack and indicate how it would be executed by a standard Prolog interpreter and what
computational redundancy this causes. We further describe an execution mechanism for
query packs that makes it possible to avoid the redundant computations that would arise if
all queries in the pack were run separately, and show how it can be implemented by making a
few small but signicant extensions to the WAM, the standard Prolog execution mechanism.
In Section 4 we describe how the query pack execution strategy can be incorporated in two
existing inductive logic programming algorithms (Tilde and Warmr). In Section 5 we
present experimental results that illustrate the speed-up that these systems achieve by
using the query pack execution mechanism. In Section 6 we discuss related work and in
Section 7 we present conclusions and some directions for future work.

136

Improving the Efficiency of ILP through Query Packs
2. Inductive Logic Programming

Inductive logic programming (Muggleton & De Raedt, 1994) is situated in the intersection
of machine learning or data mining on the one hand, and logic programming on the other
hand. It shares with the former elds the goal of nding patterns in data, patterns that can
be used to build predictive models or to gain insight in the data. With logic programming
it shares the use of clausal rst order logic as a representation language for both data
and hypotheses. In the remainder of this text we will use some basic notions from logic
programming, such as literals, conjunctive queries, and variable substitutions. We will use
Prolog notation throughout the paper. For an introduction to Prolog and logic programming
see Bratko (1990).
Inductive logic programming can be used for many dierent purposes, and the problem
statements found in ILP papers consequently vary. In this article we consider the so-called
learning from interpretations setting (De Raedt & Dzeroski, 1994; De Raedt, 1997). It
has been argued elsewhere that this setting, while slightly less powerful than the standard
ILP setting (it has problems with, e.g., learning recursive predicates), is suÆcient for most
practical purposes and scales up better (Blockeel et al., 1999).
We formulate the learning task in such a way that it covers a number of dierent problem
statements. More specically, we consider the problem of detecting for a set of conjunctive
queries for which instantiations of certain variables each query succeeds. These variables
are called key variables, and a grounding substitution for them is called a key instantiation.
The intuition is that an example in the learning task is uniquely identied by a single key
instantiation.
The link with ILP systems that learn clauses is then as follows. The search performed
by an ILP system is directed by regularly evaluating candidate clauses. Let us denote such
a candidate clause by Head(X )
Body (X; Y ) where X represents a vector of variables
appearing in the head of the clause and Y represents additional variables that occur in the
body. We assume that the head is a single literal and that a list of examples is given, where
each example is of the form Head(X ) with  a substitution that grounds X . Examples
may be labelled (e.g., as positive or negative), but this is not essential in our setting. While
an example can be represented as a fact Head(X ) when learning denite Horn clauses, we
can also consider it just a tuple X. Both notations will be used in this paper.
Intuitively, when positive and negative examples are given, one wants to nd a clause
that covers as many positive examples as possible, while covering few or no negatives.
Whether a single example Head(X ) is covered by the clause or not can be determined
by running the query ? Body(X; Y ). In other words, evaluating a clause boils down to
running a number of queries consisting of the body of the clause. For simplicity of notation,
we will often denote a conjunctive query by just the conjunction (without the ? symbol).
In some less typical ILP settings, the ILP algorithm does not search for Horn clauses
but rather for general clauses, e.g., Claudien (De Raedt & Dehaspe, 1997) or for frequent
patterns that can be expressed as conjunctive queries, e.g., Warmr(Dehaspe & Toivonen,
1999). These settings can be handled by our approach as well: all that is needed is a mapping
from hypotheses to queries that allow to evaluate these hypotheses. Such a mapping is
dened by De Raedt and Dehaspe (1997) for Claudien; for Warmr it is trivial.

137

Blockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteele
Given a set of queries S and a set of examples E , the main task is to determine which
queries Q 2 S cover which examples e 2 E . We formalise this using the notion of a result
set:

Denition 1 (Result set) The result set of a set of queries S in a deductive database D
for key K and example set E , is
RS (S; K; D; E )

= f(K; i)jQi 2 S and K 2 E and Qi  succeeds in Dg

Similar to the learning from interpretations setting dened in (De Raedt, 1997), the
problem setting can now be stated as:

Given: a set of conjunctive queries S , a deductive database D, a tuple K of variables
that occur in each query in S, and an example set E
Find: the result set RS (S; K; D; E ); i.e., nd for each query Q in S those ground
instantiations  of K for which K 2 E and Q succeeds in D.
Example 1 Assume an ILP system learning a denition for grandfather/2 wants to evaluate the following hypotheses:

grandfather(X,Y) :- parent(X,Z), parent(Z,Y), male(X).
grandfather(X,Y) :- parent(X,Z), parent(Z,Y), female(X).

Examples are of the form grandfather(gf ,gc) where gf and gc are constants; hence
each example is uniquely identied by a ground substitution of the tuple (X; Y ). So in the
above problem setting the set of Prolog queries S equals f(?- parent(X,Z), parent(Z,Y),
male(X)), (?- parent(X,Z), parent(Z,Y), female(X))g and the key K equals (X; Y ).
Given a query Qi 2 S , nding all tuples (x; y) for which ((x; y); i) 2 R (with R the result
set as dened above) is equivalent to nding which of the grandfather(x,y) facts in the
example set are predicted by the clause grandfather(X,Y) :- Qi .

The generality of our problem setting follows from the fact that once it is known which
queries succeed for which examples, the statistics and heuristics that typical ILP systems
use can be readily obtained from this. A few examples:






discovery of frequent patterns (Dehaspe & Toivonen, 1999): for each query Qi the
number of key instantiations for which it succeeds just needs to be counted, i.e.,
f req (Qi ) = jfK j(K; i) 2 Rgj with R the result set.
induction of Horn clauses (Muggleton, 1995; Quinlan, 1993b): the accuracy of a
clause H :- Qi (dened as the number of examples for which body and head hold,
divided by the number of examples for which the body holds) can be computed as
jfKj(K;i)2R^Dj=Hgj with R the result set.
jfKj(K;i)2Rgj
induction of rst order classication or regression trees (Kramer, 1996; Blockeel &
De Raedt, 1998; Blockeel et al., 1998): the class entropy or variance of the examples
covered (or not covered) by a query can be computed from the probability distribution
of the target variable; computing this distribution involves simple counts similar to
the ones above.

138

Improving the Efficiency of ILP through Query Packs
After transforming the grandfather/2 clauses into
grandfather((X,Y)),I) :- parent(X,Z), parent(Z,Y), male(X), I = 1.
grandfather((X,Y)),I) :- parent(X,Z), parent(Z,Y), female(X), I = 2.

the result set can clearly be computed by collecting for all grounding 's where K 2 E the
answers to the query ?- grandfather(K,I) . In Section 3 the queries will have a literal
I = i at the end or another goal which by side-eects results in collecting the result set.
In practice, it is natural to compute the result set using a double loop: one over examples
and one over queries and one has the choice as to which is the outer loop. Both the \examples
in outer loop" and the \queries in outer loop" have been used in data mining systems; in
the context of decision trees, see for instance Quinlan (1993a) and Mehta et al. (1996). We
shall see further that the redundancy removal approach we propose uses the \examples in
outer loop" strategy. In both approaches however, given a query and a key instantiation, we
are interested only in whether the query succeeds for that key instantiation. This implies
that after a particular query has succeeded on an example, its execution can be stopped.
In other words: computing the result set dened above boils down to evaluating each
query on each example, where we are only interested in the existence of success for each such
evaluation. Computing more than one solution for one query on one example is unnecessary.
3. Query Packs

For simplicity, we make abstraction of the existence of keys in the following examples. What
is relevant here, is that for each query we are only interested in whether it succeeds or not,
not in nding all answer substitutions.
Given the following set of queries
p(X),
p(X),
p(X),
p(X),
p(X),

I = 1.
q(X,a),
q(X,b),
q(X,Y),
q(X,Y),

I = 2.
I = 3.
t(X), I = 4.
t(X), r(Y,1), I = 5.

we can choose to evaluate them separately. Since we are only interested in one { the rst {
success for each query, we would evaluate in Prolog the queries
once((p(X),
once((p(X),
once((p(X),
once((p(X),
once((p(X),

I = 1)).
q(X,a), I = 2)).
q(X,b), I = 3)).
q(X,Y), t(X), I = 4)).
q(X,Y), t(X), r(Y,1), I = 5)).

The wrapper once/1 is a pruning primitive and prevents the unnecessary search for more
solutions. Its denition in Prolog is simply
once(Goal) :- call(Goal), !.

139

Blockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteele
An alternative way to evaluate the queries consists in merging them into one (nested)
disjunction as in:
p(X), (I=1

;

q(X,a), I=2

;

q(X,b), I=3

;

q(X,Y), t(X), (I=4

;

r(Y,1), I=5)).

The set of queries can now be evaluated as a whole: the success of one branch in the
disjunctive query corresponds to the success of the corresponding individual query.
Compared to the evaluation of the individual queries, the disjunctive query has both an
advantage and a disadvantage:
+ all the queries have the same prex p(X), which is evaluated once in each individual
query, while in the disjunctive query, the goal p(X) is evaluated only once; depending
on the evaluation cost of p/1, this can lead to arbitrary performance gains.
the usual Prolog pruning primitives are not powerful enough to prevent all the unnecessary backtracking after a branch in the disjunctive query has succeeded; this is
explained further in Example 2.

Example 2 In this example the literals

contribute to the discussion:

= i have been left out, because they do not

I

p(X), q(X).
p(X), r(X).

Evaluating these queries separately means evaluating
once((p(X), q(X))).
once((p(X), r(X))).

or equivalently
p(X), q(X), !.
p(X), r(X), !.

The corresponding disjunctive query is
p(X), (q(X) ; r(X)).

We can now try to place a pruning primitive in the disjunctive query: !/0 at the end of
each branch results in
p(X), (q(X), ! ; r(X), !)

The scope of the rst cut is clearly too large: after the goal q(X) has succeeded, the cut
will prevent entering the second branch. It means that adding the cut in the disjunctive
query leads to a wrong result.
Using once/1 in the disjunctive query results in
p(X), (once(q(X)) ; once(r(X)))

140

Improving the Efficiency of ILP through Query Packs
This results in a correct query. However, both branches are still executed for every
binding that the goal p(X) produces, even if both branches have succeeded already.

The combination of the advantage of the disjunctive query with the advantage of the
individual query with pruning (once or cut) results in the notion of the query pack. Syntactically, a query pack looks like a disjunctive query where the ; control construct is
replaced by a new control construct denoted by or. So the query pack corresponding to the
disjunctive query above is
p(X), (I=1

or

q(X,a), I=2

or

q(X,b), I=3

or

q(X,Y), t(X), (I=4

or

r(Y,1), I=5))

This query pack can be represented as the tree in Figure 1. For a query pack Q such a
tree has literals or conjunctions of literals in the nodes. Each path from the root to a leaf
node represents a conjunctive query Q which is a member of Q, denoted Q 2 Q. The or
construct is implicit in the branching points.
p(X)
I=1

q(X,a),
I=2

q(X,b),
I=3

q(X,c),
I=4
I=5

q(X,Y), t(X)
r(Y,1),
I=6

r(Y,2),
I=7

Figure 1: A query pack.
The intended procedural behaviour of the or construct is that once a branch has succeeded, it is eectively pruned away from the pack during the evaluation of the query pack
on the current example. This pruning must be recursive, i.e., when all branches in a subtree
of the query pack have succeeded, the whole subtree must be pruned. Evaluation of the
query pack then terminates when all subtrees have been pruned or all of the remaining
queries fail for the example.
The semantics of the or construct and its eÆcient implementation is the subject of the
rest of this section. It should however be clear already now that in the case that all the
answers of each query are needed, pruning cannot be performed and the disjunctive query
is already suÆcient, i.e., query packs are useful when a single success per query suÆces.

3.1 EÆcient Execution of Query Packs
In Section 3.1.2, a meta-interpreter is given that denes the behaviour of query packs. In
practice this meta-interpreter is not useful, because in many cases the meta-interpreter itself
causes more overhead than the use of query packs can compensate for. Indeed, previously
reported results (Demoen et al., 1999; Blockeel, 1998) indicate that the overhead involved
in a high-level Prolog implementation destroys the eÆciency gain obtained by redundancy
reduction. Moreover as discussed in Section 3.1.2, the meta-interpreter does not have the
desired time-complexity. This shows that the desired procedural semantics of or can be

141

Blockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteele
implemented in Prolog itself, but not with the desired performance because Prolog lacks
the appropriate primitives.
The conclusion is that changes are needed at the level of the Prolog engine itself. This
requires an extension of the WAM (Warren Abstract Machine) which is the underlying
abstract machine for most Prolog implementations. The extended WAM provides the or
operator as discussed above: it permanently removes branches from the pack that do not
need to be investigated anymore. This extended WAM has become the basis of a new Prolog
engine dedicated to inductive logic programming, called ilProlog. This section continues
with the introduction of some basic terminology for query packs and explains at a high level
how query pack execution works. Next our meta-interpreter for the query pack execution
is given and nally the changes needed for the WAM are claried.
3.1.1 Principles of Query Packs (Execution)

Before we discuss query pack execution in detail, note the following two points: (1) during
the pack execution, the pruning of a branch must survive backtracking; (2) when executing
a pack we are not interested in any variable instantiations, just in whether a member of the
pack succeeds or not. In our previous description we were interested in the binding to the
variable I. Since each branch can bind I to only one value { the query number { we collect
these values in practice by a side eect denoted in Section 3.2 by report success.
The starting point for the query pack execution mechanism is the usual Prolog execution
of a query Q given a Prolog program P . By backtracking Prolog will generate all the
solutions for Q by giving the possible instantiations  such that Q succeeds in P .
A query pack consists of a conjunction of literals and a set of alternatives, where each
alternative is again a query pack. Note that leaves are query packs with an empty set of
alternatives. For each query pack Q, conj (Q) denotes the conjunction and children(Q)
denotes the set of alternatives. A set of queries is then represented by a so-called root query
pack. For every query pack Q, there is a path of query packs starting from the root query
pack Qroot and ending at the query pack itself, namely < Qroot , Q1 , ..., Qn , Q >. The
query packs in this path are the predecessors of Q. Every query pack has a set of dependent
queries, dependent queries(Q). Let < Qroot , Qi1 , ..., Qin , Q > be the path to Q, then
dependent queries(Q) = fconj (Qroot ) ^ conj (Qi1 ) ^ : : : ^ conj (Qin ) ^ conj (Q) ^ conj (Qj1 ) ^
: : : ^ conj (Qjm ) ^ conj (Ql ) j < Q; Qj1 , ..., Qjm , Ql > is a path from Q to a leaf Ql g. Note
that dependent queries(Qroot ) are actually the members of the query pack as described
earlier.

Qroot is the root of the tree. conj (Qroot ) is
Qroot ) contains the 4 query packs which correspond to the trees

Example 3 For the query pack in Figure 1,
p(X ). The set children(

rooted at the 4 sons of the root of the tree. Suppose that these query packs are named (from
left to right) Q1 , Q2 , Q3 , and Q4 . Then conj (Q2 ) equals (q(X; a); I = 2), children(Q2 )
equals the empty set, conj (Q4 ) equals (q(X; Y ); t(X )), and dependent queries(Q4 ) equals
f(p(X ); q(X; Y ); t(X ); I = 4), (p(X ); q(X; Y ); t(X ); r(Y; 1); I = 5)g.

Execution of a root query pack Qroot aims at nding out which queries of the set
dependent queries(Qroot ) succeed. If a query pack is executed as if the ors were usual
disjunctions, backtracking occurs over queries that have already succeeded and too many

142

Improving the Efficiency of ILP through Query Packs
0
1
2
3
4
5
6
7
8
9
10
11

execute qp( pack Q, substitution ) f
while (  next solution( conj (Q))

f

for each Qchild in children(Q) do

f
g

g

if ( execute qp( Qchild , ) == success)
children(Q)
children(Q) n fQchild g

if ( children(Q) is an empty set) return(success)

return(fail)

g

Figure 2: The query pack execution algorithm.
successes are detected. To avoid this, it should be the case that as soon as a query succeeds,
the corresponding part of the query pack should no longer be considered during backtracking. Our approach realises this by reporting success of queries (and of query packs) to
predecessors in the query pack. A (non-root) query pack Q can be safely removed if all the
queries that depend on it (i.e., all the queries in dependent queries(Q)) succeeded once.
For a leaf Q (empty set of children), success of conj (Q) is suÆcient to remove it. For a
non-leaf Q, we wait until all the dependent queries report success or equivalently until all
the query packs in children(Q) report success.
At the start of the evaluation of a root query pack, the set of children for every query
pack in it contains all the alternatives in the given query pack. During the execution, query
packs can be removed from children sets and thus the values of the children(Q) change
accordingly. When due to backtracking a query pack is executed again, it might be the case
that fewer alternatives have to be considered.
The execution of a query pack Q is dened by the algorithm execute qp(Q; ) (Figure
2) which imposes additional control on the usual Prolog execution.
The usual Prolog execution and backtracking behaviour is modelled by the while loop
(line 1) which generates all possible solutions  for the conjunction in the query pack. If
no more solutions are found, fail is returned and backtracking will occur at the level of the
calling query pack.
The additional control manages the children(Q). For each solution , the necessary
children of Q will be executed. It is important to notice that the initial set of children of a
query pack is changed destructively during the execution of this algorithm. Firstly, when a
leaf is reached, success is returned (line 8) and the corresponding child is removed from the
query pack (line 6). Secondly, when a query pack that initially had several children, nally
ends up with an empty set of children (line 6), also this query pack is removed (line 8).
The fact that children are destructively removed, implies that when due to backtracking
the same query pack is executed again for a dierent , not all of the alternatives that
were initially there, have to be executed any more. Moreover, by returning success the

143

Blockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteele
a qp(1)
ch(1)

ch(3)
ch(2)

b qp(2)
ch(1)

f

q(4)

g qp(3)
ch(1)

ch(3)
ch(2)

c q(1)

d q(2)

ch(3)
ch(2)

e q(3)

h q(5)

i q(6)

j

q(7)

Figure 3: Query pack numbers qp(i), Query numbers q(i) and Child numbers ch(i) in our
example.
backtracking over the current query pack conjunction conj (Q) is stopped: all branches
have reported success.
3.1.2 A Meta-interpreter for Query Packs

The rst implementation of the query pack execution algorithm is the meta-interpreter
meta execute qp(Q). The meta-interpreter uses the following labelling in its representation
of a query pack:

 Query pack number All the non-leaf query packs in the tree are numbered, depth
rst, from left to right (qp(i)).

 Query number Each leaf is numbered, from left to right. If the original queries were
numbered sequentially, then the numbers at the leaves correspond with these (q(i)).

 Child number For each non-leaf query pack with N children, all children are numbered
from 1 up to N sequentially (ch(i)).

Consider the query pack a, (b, (c or d or e) or f or g, (h or i or j)). Note that the
atoms in the example could in general be arbitrary conjunctions of non-ground terms. Its
labelling is shown in Figure 3.
A labelled query pack Q is then represented as a Prolog term as follows (with Qf the
father of Q):



A leaf

Q is represented by the term (c; leaf (qpnbf; chnb; qnb)) with c the conj (Q),
the query pack number of Qf , chnb the child number of Q w.r.t. Qf , and qnb
the query number of Q.



A non-leaf Q is represented by the term (c; or(cs; qpnbf; qpnb; chnb; totcs) with c the
conj (Q), cs the list children(Q), qpnbf the query pack number of Qf , qpnb the query
pack number of Q, chnb the child number of Q w.r.t. Qf , and totcs the total number
of children(Q)). The query pack number of the father of the root query pack is
assumed to be zero.

qpnbf

144

Improving the Efficiency of ILP through Query Packs
The example of Figure 3 has the following representation (as a Prolog term):
(a, or([(b,or([(c,leaf(2,1,1)),(d,leaf(2,2,2)),(e,leaf(2,3,3))],1,2,1,3)),
(f,leaf(1,2,4)),
(g,or([(h,leaf(3,1,5)),(i,leaf(3,2,6)),(j,leaf(3,3,7))],1,3,3,3))],
0,1,1,3))

During the execution of the meta-interpreter, solved/2 facts are asserted. Each fact
solved(qpnb, chnb) denotes that the child with number chnb from query pack with number

has succeeded. Such facts are asserted when reaching a leaf and also when all children
of a query pack have succeeded. The meta-interpreter only executes children for which no
solved/2 fact has been asserted.
Note that the time-complexity of this meta-interpreter is not yet as desired. Execution
of a query pack will always be dependent on the number of original children, instead of the
number of remaining (as yet unsuccessful) children.
qpnb

run QueryPack(Q) :preprocess(Q, Qlabeled, 0, 1, 1, 1, , ),
% The code for preprocessing is given in Appendix A
retractall(solved( , )),
meta execute qp(Qlabeled),
solved(0, ), !.
meta execute qp((A,B)) :- !,
call(A),
meta execute qp(B).
meta execute qp(or(Cs, QpNbF, QpNb, ChildNb, TotCs)) :!, % 'or' corresponds to a non-leaf query pack
handlechildren(Cs, QpNb, 1),
all solved(QpNb, 0, TotCs),
assert(solved(QpNbF,ChildNb)).
meta execute qp(leaf(QpNbF, ChildNb , QueryNb)) :!, % 'leaf' corresponds to the end of a query
write(succeed(QueryNb)), nl,
assert(solved(QpNbF,ChildNb)).
handlechildren([], , ).
handlechildren([C| ], QpNb, ChildNb) :not(solved(QpNb,ChildNb)),
once(meta execute qp(C)), fail.
handlechildren([ |Cs], QpNb, ChildNb) :ChildNb1 is ChildNb + 1,
handlechildren(Cs, QpNb, ChildNb1).
all solved(QpNb, ChildNb, TotCs) :(ChildNb = TotCs -> true
;
ChildNb1 is ChildNb + 1,
solved(QpNb, ChildNb1),
all solved(QpNb, ChildNb1, TotCs)
).

145

Blockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteele
3.1.3 WAM Extensions

To fully exploit the potential of a query pack (shared computation and avoidance of unnecessary backtracking) changes have to be made at the level of the Prolog engine itself. The
explanation assumes a WAM-based Prolog engine (At-Kaci, 1991) but a short explanation
of the execution of disjunction in Prolog is given rst, so that it becomes more easy to see
what was newly introduced in the WAM.
Assume that the body of a clause to be executed is a, (b,c ; d ; e). Assume also that
all predicates have several clauses. At the moment that execution has reached the rst
clause of c, the choice point stack looks like Figure 4(a): there are choice points for the
activation of a, the disjunction itself, b and c. The choice points are linked together so that
backtracking can easily pop the top most one. Each choice point contains a pointer to the
next alternative to be tried: only for the disjunction choice point, this alternative pointer
is shown. It points to the beginning of the second branch of the disjunction. After all
alternatives for b and c have been exhausted, this second branch is entered and d becomes
active: this is the situation shown in Figure 4(b). At that point, the alternative of the
disjunction choice point refers to the last alternative branch of the disjunction. Finally,
once e is entered, the disjunction choice point is already popped.
a, (b, c ; d ; e)

a, (b, c ; d ; e)

a, (b, c ; d ; e)

a

a

a

;

;

e

b

d

c

(a) Choice points just
after entering c.

(b) Choice points just
after entering d.

(c) Choice points just
after entering e.

Figure 4: Illustration of execution of disjunction in the WAM.
When the goal a produces a new solution, all branches of the disjunction must be tried
again. It is exactly this we want to avoid for query packs: a branch that has succeeded once,
should never be re-entered. We therefore adapt the disjunction choice point to become an
or-choice point which is set up to point into a data structure that contains references to
each alternative in the or disjunction. This data structure is named the pack table. Figure
5(a) shows the state of the execution when it has reached c: it is similar to Figure 4(a). The
or-choice point now contains the information that the rst branch is being executed. As the
execution proceeds, there are two possibilities: either this rst branch succeeds or it fails.
We describe the failing situation for the rst branch and explain what happens on success of

146

Improving the Efficiency of ILP through Query Packs
the second branch. If the rst branch has no solution, backtracking updates the alternative
in the or-choice point, to point to the next branch in the pack table. The situation after
the second branch is entered is shown in 5(b) and is again similar to 4(b). Suppose now
that the branch with the goal d succeeds: the entry in the pack table with or-alternatives
is now adapted by erasing the second alternative branch, backtracking occurs, and the next
alternative branch of the or-choice point is taken. This is shown in 5(c).
When a produces a new solution and the or-disjunction is entered again, the pack table
does no longer contain the second alternative branch and it is never re-entered. The pack
table is actually arranged in such a way that entries are really removed instead of just erased
so that they cause no overhead later.
a, (b, c or d or e)

a, (b, c or d or e)

a, (b, c or d or e)

a

a

a

or

or

or

b

d

e

c

(a) The choice points just
after entering c.

(b) The choice points just
after entering d (the rst
branch did not succeed).

(c) The choice points just
after entering e (d succeeded).

Figure 5: Illustration of execution of pack disjunction on the WAM.
Two more issues must be explained: rst, the pack table with alternatives must be
constructed at runtime every time the query pack is entered for evaluation. This is done by
emitting the necessary instructions in the beginning of the code for the query pack. As an
example, we show the code for the query pack a, (b,c or d or e) in Figure 6.
Finally, in the example it is clear that at the moment that all alternatives of an ordisjunction have succeeded, a can stop producing more solutions. So the computation can
be stopped. In general - with nested query packs - it means that one pack table entry of
the next higher or-node can be erased and this in a recursive way. The recursive removal
of entries from the pack tables, is done by the instruction query pack prune.
We have implemented this schema in ilProlog. Section 5 presents some measurements
in ilProlog.

3.2 Using Query Packs
Figure 7 shows an algorithm that makes use of the pack execution mechanism to compute
the result set R as dened in our problem statement. The set S of queries is here typically

147

Blockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteele
construct pack table @1, @2, @3
call a
query pack try
@1: call b
call c
query pack prune
@2: call d
query pack prune
@3: call e
query pack prune

Figure 6: Abstract machine code for a, (b,c or d or e) .
the set of all renements of a given query, i.e., it does not correspond to the whole hypothesis
space. From a query pack Q containing all queries in S , a derived pack Q0 is constructed
by adding a report success/2 literal to each leaf of the pack; the (procedural) task of
report success(K,i) is simply to add (K; i) to the result set R. Obviously a specic
ILP system not interested in the result set itself could provide its own report success/2
predicate and thus avoid the overhead of explicitly building the result set.1
1 evaluate(set of examples E , pack Q, key K ) f
2
Q0 Q;
3
q
1;
4
for each leaf of Q0 do f
5
add report success(K, q) to the right of the conjunction in the leaf
6
increment q
7
g
8
C
(evaluate pack(K ) :- Q0 );
9
compile and load(C);
10
for each example e in E do f
11
evaluate pack(e);
12
g
13 g
Figure 7: Using query packs to compute the result set.
Note that the algorithm in Figure 7 follows the strategy of running all queries for each
single example before moving on to the next example: this could be called the \examples in
outer loop" strategy, as opposed to the \queries in outer loop" strategy used by most ILP
1. In our current implementation the result set is implemented as a bit-matrix indexed on queries and
examples. This implementation is practically feasible (on typical computers at the time of writing) even
when the number of queries in the pack multiplied by the number of examples is up to a billion, a bound
which holds for most current ILP applications.

148

Improving the Efficiency of ILP through Query Packs
systems. The \examples in outer loop" strategy has important advantages when processing
large data sets, mainly due to the ability to process them eÆciently without having all data
in main memory at the same time (Mehta et al., 1996; Blockeel et al., 1999).

3.3 Computational Complexity
We estimate the speedup factor that can be achieved using query pack execution in two
steps: rst we consider one-level packs, then we extend the results towards deeper packs.
Lower and upper bounds on the speedup factor that can be achieved by executing a
one-level pack instead of separate queries can be obtained as follows. For a pack containing
n queries qi = (a; bi ), let Ti be the time needed to compute the rst answer substitution of
qi if there are any, or to obtain failure otherwise. Let ti be the part of Ti spent within a
and t0i the part of Ti spent in bi . Then Ts = i (ti + t0i ) and Tp = max(ti ) + i t0i with Ts
representing the total time needed for executing all queries separately and Tp the total time
needed for executing the pack. Introducing c = i ti = i t0i , which roughly represents the
ratio of the computational complexity in the shared part over that in the non-shared part,
we have
0
c+1
Ts
i ti +
i ti
=
= maxi ti
(1)
0
Tp
maxi ti + i ti
+1
t0

P

P

P

P P

P
P

P

i i

Now dening K as the ratio of the maximal ti over the average ti , i.e.

we can rewrite Equation (1) as

Since

P

i ti
n

Pmaxt =nt
i i

K

=

Ts
Tp

=

i i

c+1

K
nc

(2)

+1

 max ti  Pi ti we know 1  K  n, which leads to the following bounds:
1

Ts
Tp



c+1

c
n

+1

< min(c + 1; n)

(3)

Thus the speedup factor is bounded from above by the branching factor n and by the
ratio c of computational complexity in the shared part over the computational complexity
of the non-shared part; and a maximal speedup can be attained when max ti ' ti =n (or,
K ' 1), in other words when the ti for all queries are approximately equal.
For multi-level packs, we can estimate the eÆciency gain as follows. Given a query qi ,
let Ti be dened as above (the total time for nding 1 answer to qi or obtaining failure).
Instead of ti and t0i , we now dene ti;l as the time spent on level l of the pack when solving qi ;
counting the root as level 0 and denoting the depth of the pack with d we have Ti = dl=0 ti;l .
Further dene Ti;l as the time spent on level l or deeper: Ti;l = dj=l ti;j with d the depth
of the pack. (Thus Ti = Ti;0 .). We will assume a constant branching factor b in the pack.
Finally, we dene tl = i ti;l =n with n = bd . For simplicity, in the formulae we implicitly
assume that i always ranges from 1 to n with n the number of queries, unless explicitly

P

P

P

149

P

Blockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteele
specied otherwise. We then have
Tp

= max ti;0
i

X
+ T
i

i;1

= max ti;0
i

X
+ (max t
b

j =1

2

i Gj

i;1

XT

+

2

i Gj

i;2

)

(4)

where j = 1 : : : b is the index of a child of the root and Gj is the set of indexes of the
queries belonging to that child. Now dene K0 = maxi ti;0 =t0 and dene K1 as the smallest
number such that maxi2Gj ti;1  K1 tj;1 with tj;1 = i2Gj ti;1 =b. Note 1  K0 ; K1  b. It
then follows that
b
b
max ti;1  K1 tj;1 = K1 bt1
(5)
i2Gj
j =1
j =1

P

X

X

which allows us to rewrite Equation (4) into
Tp

 K0t0 + K1 bt1 +

XT
i

(6)

i;2

where the equality holds if maxi2Gj ti;1 is equal in all Gj . The reasoning can be continued
up till the lowest level of the pack, yielding
Tp

 K0t0 + bK1t1 + b2K2 t2 +    + bd

and nally
Tp

 K0 t0 + bK1 t1 + b2 K2t2 +    + bd



1K

d 1 td 1

1K

+



d 1 td 1

Xt

i;d

(7)

i

+ bd td

(8)

with all Kl between 1 and b. We will further simplify the comparison with Ts by assuming
8l : Kl = 1; the Kl can then be dropped and the inequality becomes an equality (because
all maxima must be equal):
Tp

= t0 + bt1 + b2 t2 +    + bd 1 td

1

+ bd td

(9)

1

+ bd td

(10)

Note that for Ts we have
Ts

= bd t0 + bd t1 + bd t2 +    + bd td

It is clear, then, that the speedup will be governed by how the bd tk terms compare to the
bk tk terms. (In the worst case, where Kk = b, the latter become bk+1 tk .) We therefore
introduce Rl;m as follows:
m
bm tk
(11)
Rl;m = km=l k

k =l b tk

P
P

The R coeÆcients are always between 1 (if tm dominates) and bm l (if tl strongly dominates);
for all tl equal, Rl;m is approximately m l.
Further, similar to c in our previous analysis, dene

P =0 b t
c = P

= +1 b t
l

l
k

d
k l

150

k

k

k

k

(12)

Improving the Efficiency of ILP through Query Packs
Some algebra then gives

Ts
Tp

=

bd l cl R0;l + Rl+1;d
cl + 1

(13)

which needs to hold for all l. We can interpret this as follows: for a certain level l, cl roughly
reects the speedup gained by the fact that the part up till level l needs to be executed
only once; the R factors reect the speedup obtained within these parts because of the pack
mechanism.
This inequality holds for all l, hence we will nd the best lower bound for the speedup factor by maximizing the right hand side. Note that cl increases and bd l decreases
monotonically with l. It is clear that if at some point cl becomes much larger than 1, a
speedup factor of roughly bd l is obtained. On the other hand, if cl is smaller than 1, then
the behaviour of bd l cl is crucial. Now,
bd l cl

tl + 1 tl 1 +    + b1l t0
=  1 b
:
td + b td 1 +    + bd 1l 1 tl+1

Our conclusion is similar to that for the one-level pack. If for some l, cl >> 1, i.e., if in
the upper part of the pack (up till level l) computations take place that are so expensive
that they dominate all computations below level l (even taking into account that the latter
are performed bd l times more often), then a speedup of bd l can be expected. If cl << 1,
which will usually be the case for all l except those near d, the speedup can roughly be
estimated as tl =td . The maximum of all these factors will determine the actual speedup.
4. Adapting ILP Algorithms to Use Query Packs

In this section we discuss how the above execution method can be included in ILP algorithms, and illustrate this in more detail for two existing ILP algorithms. Experimental
results concerning actual eÆciency improvements this yields are presented in the next section.

4.1 Renement of a Single Rule
Many systems for inductive logic programming use an algorithm that consists of repeatedly
rening clauses. Any of these systems could in principle be rewritten to make use of a query
pack evaluation mechanism and thus achieve a signicant eÆciency gain. We rst show this
for a concrete algorithm for decision tree induction, then discuss the more general case.
4.1.1 Induction of Decision Trees

The rst algorithm we discuss is Tilde (Blockeel & De Raedt, 1998), an algorithm that
builds rst-order decision trees. In a rst-order decision tree, nodes contain literals that
together with the conjunction of the literals in the nodes above this node (i.e., in a path
from the root to this node) form the query that is to be run for an example to decide which
subtree it should be sorted into. When building the tree, the literal (or conjunction of
literals) to be put in one node is chosen as follows: given the query corresponding to a path
from the root to this node, generate all renements of this query (a renement of a query

151

Blockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteele
is formed by adding one or more literals to the query); evaluate these renements on the
relevant subset of the data,2 computing, e.g., the information gain (Quinlan, 1993a) yielded
by the renement; choose the best renement; and put the literals that were added to the
original clause to form this renement in the node.
At this point it is clear that a lot of computational redundancy exists if each renement
is evaluated separately. Indeed all renements contain exactly the same literals except those
added during this single renement step. Organising all renements into one query pack, we
obtain a query pack that essentially has only one level (the root immediately branches into
leaves). When Tilde's lookahead facility is used (Blockeel & De Raedt, 1997), renements
form a lattice and the query pack may contain multiple (though usually few) levels.
Note that the root of these packs may consist of a conjunction of many literals, giving
the pack a broom-like form. The more literals in the root of the pack, the greater the benet
of query pack execution is expected to be.

Example 4 Assume the node currently being rened has the following query associated with

it: ?- circle(A,C),leftof(A,C,D),above(A,D,E), i.e., the node covers all examples A
where there is a circle to the left of some other object which is itself above yet another object.
The query pack generated for this renement could for instance be

circle(A,C), leftof(A,C,D), above(A,D,E),

triangle(A,F)
circle(A,H)
small(A,I)
large(A,J)
in(A,E,K)
in(A,D,L)
in(A,C,M)
above(A,E,N)
above(A,D,O)
above(A,C,P)
leftof(A,E,Q)
leftof(A,D,R)
leftof(A,C,S)

When evaluating this pack, all backtracking through the root of the pack (the \stick"
of the broom) will happen only once, instead of once for each renement. In other words:
when evaluating queries one by one, for each query the Prolog engine needs to search once
again for all objects C , D and E fullling the constraint circle(A,C), leftof(A,C,D),
above(A,D,E); when executing a pack this search is done only once.
4.1.2 Other Algorithms Based on Rule Refinement

As mentioned, any ILP algorithm that consists of repeatedly rening clauses could in principle be rewritten to make use of a query pack evaluation mechanism and thus achieve a
signicant eÆciency gain. Consider, e.g., a rule induction system performing an A search
through a renement lattice, such as Progol (Muggleton, 1995). Since A imposes a certain order in which clauses will be considered for renement, it is hard to reorganise the
computation at this level. However, when taking one node in the list of open nodes and
producing all its renements, the evaluation of the renements involves executing all of
them; this can be replaced by a pack execution, in which case a positive eÆciency gain is
guaranteed. In principle one could also perform several levels of renement at this stage,
2. I.e., that subset of the original data set for which the parent query succeeded; or, in the decision tree
context: the examples sorted into the node that is being rened.

152

Improving the Efficiency of ILP through Query Packs
adding all of the renements to A 's queue; part of the eÆciency of A is then lost, but
the pack execution mechanism is exploited to a larger extent. Which of these two eects
is dominant will depend on the application: if most of the rst-level renements would
be further rened anyway at some point during the search, clearly there will be a gain in
executing a two-level pack; otherwise there may be a loss of eÆciency. For instance, if
executing a two-level pack takes x times as much time as a one-level pack, it will bring an
eÆciency gain only if at least x of the rst level renements would afterwards be rened
themselves.

4.2 Level-wise Frequent Pattern Discovery
An alternative family of data mining algorithms scans the renement lattice in a breadthrst manner for queries whose frequency exceeds some user-dened threshold. The bestknown instance of these level-wise algorithms is the Apriori method for nding frequent
item-sets (Agrawal et al., 1996). Warmr (Dehaspe & Toivonen, 1999) is an ILP variant of
attribute-value based Apriori.
Query packs in Warmr correspond to hash-trees of item-sets in Apriori: both are used
to store a subgraph of the total renement lattice down to level n. The paths from the root
down to level n 1 in that subgraph correspond to frequent patterns. The paths from root
to the leaves at depth n correspond to candidates whose frequency has to be computed.
Like hash-trees in Apriori, query packs in Warmr exploit massive similarity between
candidates to make their evaluation more eÆcient. Essentially the Warmr algorithm starts
with an empty query pack and iterates between pack evaluation and pack extension (see
Figure 8). The latter is achieved by adding all potentially frequent renements3 of all leaves
in the pack, i.e., adding another level of the total renement lattice.
5. Experiments

The goal of this experimental evaluation is to empirically investigate the actual speedups
that can be obtained by re-implementing ILP systems so that they use the pack execution
mechanism. At this moment such re-implementations exist for the Tilde and Warmr
systems, hence we have used these for our experiments. These re-implementations are
available within the ACE data mining tool, available for academic use upon request.4 We
attempt to quantify (a) the speedup of packs w.r.t. to separate execution of queries (thus
validating our complexity analysis), and (b) the total speedup that this can yield for an
ILP system.
The data sets that we have used for our experiments are the following:



The Mutagenesis data set : an ILP benchmark data set, introduced to the ILP community by Srinivasan et al. (1995), that consists of structural descriptions of 230
molecules that are to be classied as mutagenic or not. Next to the standard Mutagenesis data set, we also consider versions of it where each example occurs n times;

3. Renements found to be specialisations of infrequent queries cannot be frequent themselves, and are
pruned consequently.
4. See http://www.cs.kuleuven.ac.be/~dtai/ACE/.

153

Blockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteele

circle(A,B)

triangle(A,B)

leftof(A,B,C) above(A,B,C) leftof(A,B,C)

EXPAND

circle(A,B)

leftof(A,B,C)

triangle(A,B)

above(A,B,C)

leftof(A,B,C)

circle(A,C)triangle(A,C) circle(A,C)triangle(A,C) circle(A,C)triangle(A,C)
EVALUATE
circle(A,B) triangle(A,B)
above(A,B,C)

leftof(A,B,C)

triangle(A,C) circle(A,C)triangle(A,C)

circle(A,B)

EXPAND

above(A,B,C)
triangle(A,C)

triangle(A,B)
leftof(A,B,C)

circle(A,C)

triangle(A,C)

leftof(A,C,D) leftof(A,C,D) above(A,C,D) leftof(A,C,D)

Figure 8: A sequence of 4 query packs in Warmr. Renement of the above left query
pack results in the 3-level pack above right. Removal of queries found infrequent
during pack evaluation results in the bottom left pack. Finally, another level is
added in a second query expansion step to produce the bottom right pack. This
iteration between expansion and evaluation continues until the pack is empty.
this allows us to easily generate data sets of larger size where the average example
and query complexity are constant and equal to those of the original data set.



Bongard data sets : introduced in ILP by De Raedt and Van Laer (1995), the so-called
\Bongard problems" are a simplied version of problems used by Bongard (1970) for
research on pattern recognition. A number of drawings are shown containing each a
number of elementary geometrical gures; the drawings have to be classied according
to relations that hold on the gures in them. We use a Bongard problem generator
to create data sets of varying size.

The experiments were run on SUN workstations: a Sparc Ultra-60 at 360 MHz for
Tilde, a Sparc Ultra-10 at 333 Mhz for Warmr. Tilde and Warmr were run with their
default settings, except where mentioned dierently.

5.1 Tilde
We consider three dierent ways in which Tilde can be run in its ilProlog implementation:
1. No packs: the normal implementation of Tilde as described by Blockeel and De Raedt
(1998), where queries are generated one by one and each is evaluated on all relevant
examples. Since queries are represented as terms, each evaluation of a query involves
a meta-call in Prolog.

154

Improving the Efficiency of ILP through Query Packs
2. Disjoint execution of packs: a query pack is executed in which all queries in the pack
are put beside one another; i.e., common parts are not shared by the queries. The
computational redundancy in executing such a pack is the same as that in executing
all queries one after another; the main dierence is that in this case all queries are
compiled.
3. Packed execution of packs: a compiled query pack is executed where queries share as
much as possible.
The most interesting information is obtained by comparing (a) the actual query evaluation time in settings 2 and 3: this gives a view of the eÆciency gain obtained by the
removal of redundant computation itself (we will abbreviate this as exec in the tables);
and (b) the total execution time in settings 1 and 3: this provides an indication of how
much is gained by implementing packs in an ILP system, taking all other eects into account (re-implementation of the computation of heuristics via a bit matrix, use of compiled
queries instead of meta-calls, etc.), or in other words: what the net eect of the whole
re-implementation is (indicated as net in the tables).
In a rst experiment we used Bongard problems, varying (1) the size of the data sets;
(2) the complexity of the target hypothesis; and (3) Tilde's lookahead parameter. The
complexity of the target hypothesis can be small, medium, or none. In the latter case the
examples are random, which causes Tilde to grow ever larger trees in an attempt to nd
a good hypothesis; the size of the nal tree then typically depends on the size of the data
set. The lookahead parameter is used to control the number of levels the pack contains;
with lookahead n, packs of depth n + 1 are generated.
Table 1 gives an overview of results for the Bongard problems. The total induction
time is reported, as well as (for pack-based execution mechanisms) the time needed for
pack compilation and pack execution. Note that the total time includes not only pack
compilation and execution, but also all other computations not directly related to packs
(e.g., the computation of heuristics from the bitmatrix). The results can be interpreted as
follows.
First of all, the table shows that signicant speedups can be obtained by using the pack
mechanism; net speedups of over a factor 5.5 are obtained, while the execution itself is up
to 75 times faster compared to disjoint execution.
A further observation is that for more complex target hypotheses greater speedups are
obtained. This can be explained by the broom-like form of the packs in Tilde. Complex
target hypotheses correspond to deep trees, and renement of a node at a lower level of
such a tree yields a pack with a long clause before the branching, which in accordance with
our previous analysis should yield a speedup closer to the branching factor b in the case
of lookahead 0 (and more generally, closer to bl+1 for lookahead l, although the latter is
much harder to achieve). Note that the maximum branching factor occurring in each pack
is included in the table in column bf .
Finally, deeper packs also yield higher speedups, and this eect is larger for more complex
theories. This is understandable considering the following. Let us call the clause that is
being rened c. With lookahead l, conjunctions of l + 1 literals are added to the clause. In
some cases the rst of these l + 1 literals may fail immediately, which causes this branch of
the pack to have almost no execution time, while cutting away bl queries. Remember that

155

Blockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteele
LA

bf

0
1
2
3

16
24
18
21

0
1
2
3

16
24
18
21

0
1
2
3

19
24
18
21

0
1
2
3

19
21
15
18

0
1
2
3

22
24
27
18

0
1
2
3

25
24
27
27

0
1
2
3

28
24
24
30

0
1
2
3

31
36
33
33

0
1
2
3

31
39
39
42

original

0.74
2.44
7.49
29.9

1.82
5.72
17.2
69.8

3.69
11.4
34.7
142

1.01
3.26
6.36
27.2

3.16
8.38
38.5
124

6.35
18.14
119
384

4.74
16.32
87.5
373

12.7
65.1
430
1934

25.3
154
1185
4256

disjoint
packed
comp exec total comp
Simple target hypothesis
1007 examples
0.62
0.14
0.13
0.49
0.05
1.64
0.35
0.45
1.09
0.14
4.07
0.8
1.57
2.15
0.27
16.52
3.65
7.26
7.18
1.26
2473 examples
1.43
0.17
0.34
1.13
0.07
3.34
0.34
1.17
2.24
0.11
8.45
0.78
3.95
4.4
0.27
33.0
3.57
17.5
13.7
1.13
4981 examples
2.72
0.29
0.67
2.16
0.12
6.22
0.35
2.41
4.17
0.13
16.0
0.74
8.14
8.24
0.25
62.4
3.61
36.5
24.9
1.09
Medium complexity target hypothesis
1031 examples
0.93
0.29
0.18
0.66
0.11
2.8
0.98
0.56
1.66
0.35
3.47
0.68
1.22
1.95
0.25
14.6
3.75
5.75
6.71
1.20
2520 examples
2.82
0.89
0.62
1.91
0.3
5.88
1.5
1.86
3.3
0.44
29.8
13.14 9.52
10.3
2.44
58.02
10.3
28.6
23.9
3.00
5058 examples
5.41
1.47
1.3
3.73
0.56
12.98
3.2
4.15
7.5
0.93
93.2
38.1
31.0
35.3
9.09
275
108
89.1
106
25.9
No target hypothesis
1194 examples
6.65
3.34
0.94
3.93
0.98
21.29
10.97 2.24 11.65 3.41
130
82.3
13.8
54.7
20.4
519
316
61.1
220
74.9
2986 examples
16.5
7.04
2.68
9.8
2.16
83.7
42.9
10.7
42.47
11.2
606
396
84
211.3
82.58
2592
1610
375
946
332
6013 examples
30.3
11.8
5.53
18.3
3.53
198
91.2
33.4
99.9
22.0
1733
1076
358
504
197
6932
4441 1091 2006
695
total

speedup

exec

net

exec

0.07

1.51

1.86

0.11

2.24

4.09

0.16

3.48

9.81

0.28

4.17

25.9

0.16

1.61

2.13

0.3

2.55

3.9

0.39

3.92

10.1

0.69

5.11

25.4

0.32

1.71

2.09

0.63

2.74

3.83

0.88

4.21

9.25

1.45

5.69

25.1

0.07

1.53

2.57

0.14

1.96

4

0.15

3.26

8.13

0.27

4.06

21.3

0.24

1.65

2.58

0.41

2.54

4.54

0.6

3.73

15.9

1.11

5.21

25.7

0.53

1.70

2.45

0.91

2.42

4.56

1.7

3.36

18.2

2.83

3.62

31.5

0.20

1.21

4.70

0.31

1.40

7.23

0.57

1.60

24.1

1.34

1.70

45.6

0.56

1.30

4.79

1.14

1.53

9.39

2.57

2.03

32.6

6.58

2.04

57.0

1.27

1.38

4.35

3.13

1.54

10.7

9

2.35

39.8

14.5

2.12

75.4

Table 1: Timings of Tilde runs on the Bongard data sets. LA = lookahead setting; bf =
maximum branching factor. Reported times (in seconds) are the total time needed
to build a tree, and the time spent on compilation respectively execution of packs.

156

Improving the Efficiency of ILP through Query Packs
LA original
0
1
2

31.5
194.99
2193

0
1
2

27.6
38.02
638

disjoint
packed
total comp exec total comp
Regression, 230 examples
52.9 1.96 25.5 45.5 1.02
248 55.9 109 107 12.6
{
{
{
891
192
Classication, 230 examples
27.3 1.83 4.71 25.4 1.13
40.3 7.55 9.09 30.6 3.11
{
{
{
149 74.3

Table 2: Timings of Tilde runs for Mutagenesis. A
ended prematurely.

exec

speedup ratio
net
exec

19.25 0.69
16.6 1.82
32.0 2.46

1.33
6.53
{

3.42
3.65
6.16

1.38
2.49
{

1.09
1.24
4.2

in the table indicates that that run

according to our analysis, the speedup can in the limit approximate bl if the complexity of
clause c dominates over the complexity of the rest of the pack; such \early failing branches"
in the pack cause the actual situation to approximate closer this ideal case.
We have also run experiments on the Mutagenesis data set (Table 2), both in a regression
and a classication setting. Here, query packs are much larger than for the Bongard data set
(there is a higher branching factor); with a lookahead of 2 the largest packs had over 20000
queries. For these large packs a signicant amount of time is spent compiling the pack, but
even then clear net speedups are obtained.5 A comparison of execution times turned out
infeasible because in the disjoint execution setting the pack structures consumed too much
memory.

5.2 Warmr
5.2.1 Used Implementations

For Warmr we consider the following implementations:
1. No packs: the normal implementation of Warmr, where queries are generated, and
for all examples the queries are evaluated one by one.
2. With packs: An implementation where rst all queries for one level are generated and
put into a pack, and then this pack is evaluated on each example.
5.2.2 Datasets

Mutagenesis We used the Mutagenesis dataset of 230 molecules, where each example is
repeated 10 times to make more accurate timings possible and to have a better idea of the
eect on larger datasets. We used three dierent language biases. 'small' is a language
5. In one case, with a relatively small pack, the system became slower. The timings indicate that this is
not due to the compilation time, but to other changes in the implementation which for this relatively
simple problem were not compensated by the faster execution of the packs.

157

Blockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteele

Level
1
2
3
4
5
6
7
8
9

small

Mutagenesis

medium

large

Queries Frequent Queries Frequent Queries Frequent
8
5
37
26
45
31
60
14
481
48
1071
211
86
24
688
114
3874
1586
132
31
699
253
37
21
697
533
29
18
1534
1149
23
15
{
{
17
12
{
{
4
4
{
{

Table 3: Number of queries for the Mutagenesis experiment with Warmr.
bias that was chosen so as to generate a limited number of renements (i.e., a relatively
small branching factor in the search lattice); this allows us to generate query packs that are
relatively deep but narrow. 'medium' and 'large' use broader but more shallow packs.
Table 3 summarises the number of queries and the number of frequent queries found for
each level in the dierent languages.

Bongard We use Bongard-6013 for experiments with

Warmr as this system does not
construct a theory and hence the existence of a simple theory is not expected to make much
dierence.
5.2.3 Results

In Tables 4, 5 and 6 the execution times of Warmr on Mutagenesis are given, with maximal
search depth varying from 3 for the large language to 9 levels for the small language. Here,
'total' is the total execution time and 'exec' is the time needed to test the queries against
the examples. In Table 7 the execution times of Warmr on Bongard are given.
5.2.4 Discussion

The execution time of Warmr has a large component that is not used to evaluate queries.
This is caused by the fact that Warmr needs to do a lot of administrative work. In
particular, theta-subsumption tests should be done on the queries to check wether a query
is equivalent to another candidate, or if a query is a specialisation of an infrequent one.
In the propositional case (the Apriori algorithm), these tests are very simple, but in the
rst order case they require exponential time in the size of the queries. Of course, when
using larger datasets, the relative contribution of these administrative costs will decrease
proportionally. It can be observed that at deeper levels, these costs are less for the setting
using packs. One of the causes is the fact that the no-packs version also uses more memory
than the packs setting (and hence causes proportionally more memory management).
Here again, the most important numbers are the speedup factors for the execution of
queries. Speedup factors of query execution do not always increase with increasing depth of

158

Improving the Efficiency of ILP through Query Packs

Level
1
2
3
4
5
6
7
8
9

No packs
With packs ilProlog
total
exec
total
exec
0.35
0.23
0.18
0.15
6.27
5.60
4.56
4.12
36.93
31.49 14.01
9.87
117.33 84.45
45.14
16.27
215.95 104.36 129.37
20.78
336.35 111.28 249.41
22.39
569.14 115.80 497.86
24.63
902.72 120.99 831.30
25.98
1268.16 119.60 1148.23
32.28

speedup ratio
net
exec
1.94 1.53
1.38 1.36
2.64 3.19
2.60 5.19
1.67 5.02
1.35 4.97
1.14 4.70
1.09 4.66
1.10 3.71

Table 4: Results for Warmr on the Mutagenesis dataset using a small language.

Level
1
2
3
4
5
6

No packs
With packs ilProlog
total
exec
total
exec
2.58
2.27
2.16
2.09
112.98
42.32
34.35
13.39
735.19 128.67 262.83
34.70
4162.15 287.72 1476.06
54.10
17476.98 444.44 6870.16
73.11
65138.72 866.85 25921.73
104.81

speedup ratio
net
exec
1.19 1.09
3.29 3.16
2.80 3.71
2.82 5.32
2.54 6.08
2.51 8.27

Table 5: Results for Warmr on the Mutagenesis dataset using a medium language.

Level
1
2
3

No packs
With packs ilProlog
total
exec
total
exec
2.82
2.42
2.28
2.11
408.85
102.38 102.29
50.67
27054.33 1417.76 3380.19
370.44

speedup ratio
net
exec
1.24 1.15
4.00 2.02
8.00 3.83

Table 6: Results for Warmr on the Mutagenesis dataset using a large language.

159

Blockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteele
Level
1
2
3
4
5
6
7
8
9
10

No packs
total
exec
0.24
0.22
0.83
0.75
3.28
2.82
11.56 9.31
38.34 28.11
75.51 46.97
135.64 71.60
186.23 84.93
210.82 88.97
216.61 89.38
Table 7:

With packs ilProlog
total
exec
0.24
0.23
0.77
0.68
2.34
1.92
6.08
4.28
16.20
8.15
36.57
12.22
68.96
15.59
102.46
17.82
120.76
18.52
125.84
18.88

Warmr

speedup ratio
net
exec
1.00 0.96
1.08 1.10
1.40 1.47
1.90 2.18
2.37 3.45
2.06 3.84
1.97 4.59
1.82 4.77
1.75 4.80
1.72 4.73

results on Bongard.

the packs, in contrast to Tilde where larger packs yielded higher speedups. At rst sight
we found this surprising; however it becomes less so when the following observation is made.
When rening a pack into a new pack by adding a level, Warmr prunes away branches that
lead only to infrequent queries. There are thus two eects when adding a level to a pack:
one is the widening of the pack at the lowest level (at least on the rst few levels, a new
pack typically has more leaves than the previous one), the second is the narrowing of the
pack as a whole (because of pruning). Since the speedup obtained by using packs largely
depends on the branching factor of the pack, speedup factors can be expected to decrease
when the narrowing eect is stronger than the widening-at-the-bottom eect. This can
be seen, e.g, in the small-mutagenesis experiment, where at the deepest levels queries are
becoming less frequent. For the mutagenesis experiment with the medium size language,
query execution speedup factors are larger as the number of queries increases much faster.
For the mutagenesis experiment with the large language, it is the total speedup that is large,
as the language generates so many queries that the most time-consuming part becomes the
administration and storage in memory. The packs version is much faster as it stores the
queries in trees, requiring signicantly less memory.

5.3 Comparison with Other Engines
Implementing a new special-purpose Prolog engine, dierent from the already existing ones,
carries a risk: given the level of sophistication of popular Prolog engines, it is useful to check
whether the new engine performs comparably with these existing engines, at least for the
tasks under consideration here. The eÆciency gain obtained through query pack execution
should not be oset by a less eÆcient implementation of the engine itself.
Originally the Tilde and Warmr systems were implemented in MasterProLog.
In an attempt to allow them to run on other platforms, parts of these systems were reimplemented into a kind of \generic" Prolog from which implementations for specic Prolog engines (SICStus, ilProlog) can easily be derived (the low level of standardisation of
Prolog made this necessary). Given this situation, there are two questions to be answered:

160

Improving the Efficiency of ILP through Query Packs
Data set
LA
Bongard-1194 0
Bongard-2986 0
Bongard-6013 0
Bongard-1007 0
Bongard-2473 0
Bongard-4981 0
Bongard-1007 2
Bongard-2473 2
Bongard-4981 2
Table 8:

MasterProLog ilProlog(original) ilProlog(packs)
7.8
17.8
35
0.77
2.07
4.1
7.1
17.7
38

4.74
12.7
25
0.74
1.82
3.7
7.5
17.2
35

3.93
9.8
18
0.49
1.13
2.2
2.2
4.4
8.2

compared to other engines (times in seconds) for several data sets and
lookahead settings.

ilProlog

(a) does the move from MasterProLog to other Prolog engines inuence performance in
a negative way; and (b) does the performance loss, if any, reduce the performance improvements due to the use of packs?
Tilde and Warmr have been tuned for fast execution on MasterProLog and ilProlog but not for SICStus, which makes a comparison with the latter unfair; therefore
we just report on the former 2 engines. Table 8 shows some results. These conrm that
ilProlog is competitive with state-of-the-art Prolog engines.

5.4 Summary of Experimental Results
Our experiments conrm that (a) query pack execution in itself is much more eÆcient than
executing many highly similar queries separately; (b) existing ILP systems (we use Tilde
and Warmr as examples) can use this mechanism to their advantage, achieving signicant
speedups; and c) although a new Prolog engine is needed to achieve this, the current state
of development of this engine is such that with respect to execution speed it can compete
with state-of-the-art engines. Further, the experiments are consistent with our complexity
analysis of the execution time of packs.
6. Related Work

The re-implementation of Tilde is related to the work by Mehta et al. (1996) who were
the rst to describe the \examples in outer loop" strategy for decision tree induction. The
query pack execution mechanism, here described from the Prolog execution point of view,
can also be seen as a rst-order counterpart of Apriori's mechanism for counting item-sets
(Agrawal et al., 1996).
Other lines of work on eÆciency improvements for ILP involves stochastic methods
which trade a certain amount of optimality for eÆciency by, e.g., evaluating clauses on a
sample of the data set instead of the full data set (Srinivasan, 1999), exploring the clause
search space in a random fashion (Srinivasan, 2000), or stochastically testing whether a

161

Blockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteele
query succeeds on an example (Sebag & Rouveirol, 1997). The rst of these is entirely
orthogonal to query pack execution and can easily be combined with it.
The idea of optimising sets of queries instead of individual queries has existed for a
while in the database community. The typical context considered in earlier research on
multi-query optimisation (e.g., Sellis, 1988) was that of a database system that needs to
handle disjunctions of conjunctive queries, or of a server that may receive many queries from
dierent clients in a brief time interval. If several of these queries are expected to compute
the same intermediary relations, it may be more eÆcient to materialise these relations
instead of having them recomputed for each query. Data mining provides in a sense a new
context for multi-query optimisation, in which the multi-query optimisation approach is at
the same time easier (the similarities among the queries are more systematic, so one need
not look for them) and more promising (given the huge number of queries that may be
generated at once).
Tsur et al. (1998) describe an algorithm for eÆcient execution of so-called query ocks
in this context. Like our query pack execution mechanism, the query ock execution mechanism is inspired to some extent by Apriori and is set in a deductive database setting.
The main dierence between our query packs and the query ocks described by Tsur et al.
(1998) is that query packs are more hierarchically structured and the queries in a pack are
structurally less similar than the queries in a ock. (A ock is represented by a single query
with placeholders for constants, and is equal to the set of all queries that can be obtained
by instantiating the placeholders to constants. Flocks could not be used for the applications
we consider here.)
Dekeyser and Paredaens (2001) describe work on multi-query optimisation in the context
of relational databases. They also consider tree-like structures in which multiple queries are
combined; the main dierence is that their trees are rooted in one single table from which
the queries select tuples, whereas our queries correspond to joins of multiple tables. Further,
Dekeyser and Paredaens dene a cost measure for trees as well as operators that map trees
onto semantically equivalent (but less costly) trees, whereas we have considered only the
creation of packs and an eÆcient top-down execution mechanism for them. Combining both
approaches seems an interesting topic for further research.
Finally, other optimisation techniques for ILP have been proposed that exploit results
from program analysis (Santos Costa et al., 2000; Blockeel et al., 2000) or from propositional
data mining technology (Blockeel et al., 1999). These are complementary to our pack
execution optimisation. Especially the approach of Blockeel et al. (1999) can easily be
combined with our pack mechanism. The techniques discussed by Santos Costa et al.
(2000) and Blockeel et al. (2000) involve optimisations for single query execution, some of
which can to some extent be upgraded to the pack setting. This is future work.
7. Conclusions

There is a lot of redundancy in the computations performed by most ILP systems. In this
paper we have identied a source of redundancy and proposed a method for avoiding it:
execution of query packs. We have discussed how query pack execution can be incorporated
in ILP systems. The query pack execution mechanism has been implemented in a new
Prolog system called ilProlog and dedicated to data mining tasks, and two ILP systems

162

Improving the Efficiency of ILP through Query Packs
have been re-implemented to make use of the mechanism. We have experimentally evaluated
these re-implementations, and the results of these experiments conrm that large speedups
may be obtained in this way. We conjecture that the query pack execution mechanism can
be incorporated in other ILP systems and that similar speedups can be expected.
The problem setting in which query pack execution was introduced is very general, and
allows the technique to be used for any kind of task where many queries are to be executed
on the same data, as long as the queries can be organised in a hierarchy.
Future work includes further improvements to the ilProlog engine and the implementation of techniques that will increase the suitability of the engine to handle large data sets.
In the best case one might hope to combine techniques known from database optimisation
and program analysis with our pack execution mechanism to further improve the speed of
ILP systems.

Acknowledgements
Hendrik Blockeel is a post-doctoral fellow of the Fund for Scientic Research (FWO) of
Flanders. Jan Ramon is funded by the Flemish Institute for the Promotion of Scientic
Research in Industry (IWT). Henk Vandecasteele was funded in part by the FWO project
G.0246.99, \Query languages for database mining". The authors thank Luc De Raedt for
his inuence on this work, Ashwin Srinivasan for suggesting the term \query packs", the
anonymous reviewers for their useful comments, and Kurt Driessens for proofreading this
text. This work was motivated in part by the Esprit project 28623, Aladin.
Appendix A. Preparing the Query for the Meta-interpreter

Note that the following preprocessor assumes that the pack of the form a, (b, (c or d
or e) or f or g, (h or i or j)) was already transformed to the form a , or([(b,
or([c,d,e])), f, (g, or([h,i,j]))]).
preprocess((A,B),(A,NewB),PrevNode,NodeNr0,LeafNr0,BranchNr,NodeNr1,LeafNr1):- !,
preprocess(B,NewB,PrevNode,NodeNr0,LeafNr0,BranchNr,NodeNr1,LeafNr1).
preprocess(or(Querys),or(NQuerys,PrevNode,NodeNr0,BranchNr,Length),
PrevNode,NodeNr0,LeafNr0,BranchNr, NodeNr1,LeafNr1):- !,
NodeNr2 is NodeNr0 + 1,
preprocessbranches(Querys,NQuerys,NodeNr0,NodeNr2,LeafNr0,
1,NodeNr1,LeafNr1,Length).
preprocess(A,(A,leaf(PrevNode,BranchNr,LeafNr0)),
PrevNode,NodeNr0,LeafNr0, BranchNr,NodeNr0,LeafNr1):LeafNr1 is LeafNr0 + 1.
preprocessbranches([],[], ,NodeNr,LeafNr,BranchNr, NodeNr,LeafNr,BranchNr).
preprocessbranches([QueryjQuerys],[NewQueryjNewQuerys],PrevNode,
NodeNr0,LeafNr0,BranchNr, NodeNr1,LeafNr1,Length):preprocess(Query,NewQuery,
PrevNode,NodeNr0,LeafNr0,BranchNr, NodeNr2,LeafNr2),
BranchNr1 is BranchNr + 1,
preprocessbranches(Querys,NewQuerys, PrevNode,
NodeNr2,LeafNr2,BranchNr1, NodeNr1,LeafNr1,Length).

163

Blockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteele

References

Agrawal, R., Mannila, H., Srikant, R., Toivonen, H., & Verkamo, A. (1996). Fast discovery
of association rules. In Fayyad, U., Piatetsky-Shapiro, G., Smyth, P., & Uthurusamy,
R. (Eds.), Advances in Knowledge Discovery and Data Mining, pp. 307{328. The MIT
Press.
At-Kaci, H. (1991). Warren's Abstract Machine: A Tutorial Reconstruction. The MIT
Press, Cambridge, Massachusetts.
http://www.isg.sfu.ca/~hak/documents/wam.html.
Blockeel, H. (1998). Top-down induction of rst order logical decision trees. Ph.D. thesis,
Department of Computer Science, Katholieke Universiteit Leuven.
http://www.cs.kuleuven.ac.be/~ml/PS/blockeel98:phd.ps.gz.
Blockeel, H., & De Raedt, L. (1997). Lookahead and discretization in ILP. In Proceedings
of the Seventh International Workshop on Inductive Logic Programming, Vol. 1297 of
Lecture Notes in Articial Intelligence, pp. 77{85. Springer-Verlag.
Blockeel, H., & De Raedt, L. (1998). Top-down induction of rst order logical decision trees.
Articial Intelligence, 101 (1-2), 285{297.
Blockeel, H., De Raedt, L., Jacobs, N., & Demoen, B. (1999). Scaling up inductive logic programming by learning from interpretations. Data Mining and Knowledge Discovery,
3 (1), 59{93.
Blockeel, H., De Raedt, L., & Ramon, J. (1998). Top-down induction of clustering trees.
In Proceedings of the 15th International Conference on Machine Learning, pp. 55{63.
http://www.cs.kuleuven.ac.be/~ml/PS/ML98-56.ps.
Blockeel, H., Demoen, B., Janssens, G., Vandecasteele, H., & Van Laer, W. (2000). Two
advanced transformations for improving the eÆciency of an ILP system. In 10th
International Conference on Inductive Logic Programming, Work-in-Progress Reports,
pp. 43{59, London, UK.
Bongard, M. (1970). Pattern Recognition. Spartan Books.
Bratko, I. (1990). Prolog Programming for Articial Intelligence. Addison-Wesley, Wokingham, England. 2nd Edition.
Breiman, L., Friedman, J., Olshen, R., & Stone, C. (1984). Classication and Regression
Trees. Wadsworth, Belmont.
Chen, W., & Warren, D. S. (1996). Tabled evaluation with delaying for general logic programs. Journal of the ACM, 43 (1), 20{74. http://www.cs.sunysb.edu/~sbprolog.
Clark, P., & Niblett, T. (1989). The CN2 algorithm. Machine Learning, 3 (4), 261{284.
De Raedt, L. (1997). Logical settings for concept learning. Articial Intelligence, 95, 187{
201.
De Raedt, L., & Dehaspe, L. (1997). Clausal discovery. Machine Learning, 26, 99{146.

164

Improving the Efficiency of ILP through Query Packs
De Raedt, L., & Dzeroski, S. (1994). First order jk-clausal theories are PAC-learnable.
Articial Intelligence, 70, 375{392.
De Raedt, L., & Van Laer, W. (1995). Inductive constraint logic. In Jantke, K. P., Shinohara, T., & Zeugmann, T. (Eds.), Proceedings of the Sixth International Workshop on
Algorithmic Learning Theory, Vol. 997 of Lecture Notes in Articial Intelligence, pp.
80{94. Springer-Verlag.
Dehaspe, L., & Toivonen, H. (1999). Discovery of frequent datalog patterns. Data Mining
and Knowledge Discovery, 3 (1), 7{36.
Dekeyser, S., & Paredaens, J. (2001). Query pack trees for multi query optimization. Tech.
rep. 01-04, University of Antwerp. ftp://wins.uia.ac.be/pub/dekeyser/qpt.ps.
Demoen, B., Janssens, G., & Vandecasteele, H. (1999). Executing query flocks for ILP. In
Etalle, S. (Ed.), Proceedings of the Eleventh Benelux Workshop on Logic Programming,
pp. 1{14, Maastricht, The Netherlands. 14 pages.
Kramer, S. (1996). Structural regression trees. In Proceedings of the Thirteenth National
Conference on Articial Intelligence, pp. 812{819, Cambridge/Menlo Park. AAAI
Press/MIT Press.
Mehta, M., Agrawal, R., & Rissanen, J. (1996). SLIQ: A fast scalable classier for data
mining. In Proceedings of the Fifth International Conference on Extending Database
Technology.
Muggleton, S. (1995). Inverse entailment and Progol. New Generation Computing, Special
issue on Inductive Logic Programming, 13 (3-4), 245{286.
Muggleton, S., & De Raedt, L. (1994). Inductive logic programming : Theory and methods.
Journal of Logic Programming, 19,20, 629{679.
Quinlan, J. R. (1993a). C4.5: Programs for Machine Learning. Morgan Kaufmann series in
machine learning. Morgan Kaufmann.
Quinlan, J. (1993b). FOIL: A midterm report. In Brazdil, P. (Ed.), Proceedings of the 6th
European Conference on Machine Learning, Lecture Notes in Articial Intelligence.
Springer-Verlag.
Santos Costa, V., Srinivasan, A., & Camacho, R. (2000). A note on two simple transformations for improving the eÆciency of an ILP system. In Proceedings of the Tenth
International Conference on Inductive Logic Programming, Vol. 1866 of Lecture Notes
in Articial Intelligence, pp. 225{242. Springer-Verlag.
Sebag, M., & Rouveirol, C. (1997). Tractable Induction and Classication in First-Order
Logic via Stochastic Matching. In Proceedings of the 15th International Joint Conference on Articial Intelligence. Morgan Kaufmann.
Sellis, T. (1988). Multiple-query optimization. ACM Transactions on Database Systems,
13 (1), 23{52.
Srinivasan, A. (1999). A study of two sampling methods for analysing large datasets with
ILP. Data Mining and Knowledge Discovery, 3 (1), 95{123.
Srinivasan, A. (2000). A study of two probabilistic methods for searching large spaces with
ILP. Tech. rep. PRG-TR-16-00, Oxford University Computing Laboratory.

165

Blockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteele
Srinivasan, A., Muggleton, S., & King, R. (1995). Comparing the use of background knowledge by inductive logic programming systems. In De Raedt, L. (Ed.), Proceedings of
the Fifth International Workshop on Inductive Logic Programming.
Tsur, D., Ullman, J., Abiteboul, S., Clifton, C., Motwani, R., Nestorov, S., & Rosenthal, A.
(1998). Query ocks: A generalization of association-rule mining. In Proceedings of
the ACM SIGMOD International Conference on Management of Data (SIGMOD-98),
Vol. 27,2 of ACM SIGMOD Record, pp. 1{12, New York. ACM Press.

166

Journal of Articial Intelligence Research 16 (2002) 59-104

Submitted 5/01; published 2/02

Accelerating Reinforcement Learning by Composing
Solutions of Automatically Identied Subtasks
Chris Drummond

School of Information Technology and Engineering
University of Ottawa, Ontario, Canada, K1N 6N5

cdrummon@site.uottawa.ca

Abstract

This paper discusses a system that accelerates reinforcement learning by using transfer
from related tasks. Without such transfer, even if two tasks are very similar at some
abstract level, an extensive re-learning eort is required. The system achieves much of its
power by transferring parts of previously learned solutions rather than a single complete
solution. The system exploits strong features in the multi-dimensional function produced
by reinforcement learning in solving a particular task. These features are stable and easy
to recognize early in the learning process. They generate a partitioning of the state space
and thus the function. The partition is represented as a graph. This is used to index and
compose functions stored in a case base to form a close approximation to the solution of
the new task. Experiments demonstrate that function composition often produces more
than an order of magnitude increase in learning rate compared to a basic reinforcement
learning algorithm.

1. Introduction
A standard reinforcement learning algorithm, applied to a series of related tasks, could learn
each new task independently. It only requires knowledge of its present state and infrequent
numerical rewards to learn the actions necessary to bring a system to some desired goal
state. But this very paucity of knowledge results in a slow learning rate. This paper shows
how to exploit the results of prior learning to speed up the process while maintaining the
robustness of the general learning method.
The system proposed here achieves much of its power by transferring parts of previously
learned solutions, rather than a single complete solution. The solution pieces represent
knowledge about how to solve certain subtasks. We might call them macro-actions (Precup,
Sutton, & Singh, 1997), with the obvious allusion to macro-operators commonly found in
Articial Intelligence systems. The main contribution of this work is in providing a way of
automatically identifying these macro-actions and mapping them to new tasks.
This work uses syntactic methods of composition much like in symbolic planning, but the
novelty arises in that the parts being composed are multi-dimensional real-valued functions.
These functions are learned using reinforcement learning as part of more complex functions
associated with compound tasks. The ecacy of this approach is due to the composition
occurring at a suciently abstract level, where much of the uncertainty has been removed.
Each function acts much like a funnel operator (Christiansen, 1992), so although individual
actions may be highly uncertain, the overall result is largely predictable.
c 2002 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

Drummond

The subtasks are identied on the basis of strong features in the multi-dimensional
function that arise during reinforcement learning. The features are not \in the world",
but in the system's interaction with the world. Here, \strong" means that the features are
stable (i.e. relatively insensitive to variations in the low level learning process) and easy
to recognize and locate accurately early in the learning process. One important aspect of
these features is that they largely dictate the shape of the function. If the features dier by
a small amount, one would expect the function to dier by a small amount.
The features generate a partitioning of the function. A popular technique in object
recognition, the snake (Kass, Witkin, & Terzopoulus, 1987; Suetens, Fua, & Hanson, 1992),
is used to produce this partition. In object recognition, the snake produces a closed curve
that lies along the boundary of an object, as dened by edges in an image. In this application, the snake groups together sets of features to dene a region of the function. The
boundary of the region is a low order polygon, demarcating an individual subtask. This
is repeated until the whole function is covered. The polygons are converted into discrete
graphs, a vertex of the polygon becoming a node of the graph. Merging these graphs
produces a composite graph representing the whole task.
The composite graph is used to control the transfer by accessing a case base of previously
learned functions. The case base is indexed by graphs. The relevant function is determined
by matching a subgraph of the composite graph with one acting as an index to a case. The
associated functions are transformed and composed to form a solution to the new task. This
is used to reinitialize the lower level learning process. It is not necessary for the transfer to
produce an exact solution for the new task. It is sucient that the solution is close enough
to the nal solution often enough to produce an average speed up. Reinforcement learning
will further rene the function and quickly remove any error.
This paper demonstrates the applicability of transfer in two dierent situations. In the
rst, the system learns a task for a particular goal position and then the goal is moved.
Although the function itself will change signicantly, the partition generated on the initial
task can be used to compose the function for the new task. In the second situation considered, the system is placed in a dierent environment within the same domain. Here, a new
partition has to be extracted to control the composition process.
This paper unies and signicantly extends previous work by the author (Drummond,
1997, 1998). Additional work has largely focussed on removing some of the limitations
inherent in the partitioning approach introduced in Drummond (1998). One limitation of
the original approach was that the snake could only extract polygons that were rectangles.
This paper relaxes this restriction, allowing it to be applied to a dierent environment
within the same domain and to a dierent task domain. Although lifting this restriction
removes some desirable bias, the experiments demonstrate that none of the ecacy of the
original system is lost. Further, the results are more broadly obtained on the larger set of
related tasks and in a dierent domain. Overall, the function composition approach often
produces more than an order of magnitude increase in learning rate when compared to a
basic reinforcement learning algorithm.
The rest of the paper begins with Section 2 giving a very high level discussion of the
approach taken. Section 3 gives a more in depth discussion of the techniques used. Sections 4 and 5 present and analyze the experimental results. Subsequent sections deal with
limitations and related research.
60

Accelerating Reinforcement Learning

2. An Overview
The intent of this section is to appeal to the intuitions of the reader, leaving much of the
detail to later sections in the paper. The subsections that follow will demonstrate in turn:
that there are features in the function produced by reinforcement learning; that graphs
based on these features can be used to control the composition of the function pieces; that
these features are easy to detect early in the learning process; that these features exist in
multiple domains.

2.1 Features in the Reinforcement Learning Function
This overview begins with a very high level introduction to reinforcement learning and the
function it produces. It will show that there are features in this function which can be
extracted and converted into a graphical representation.
One of the experimental test beds used is this paper is a simulated robot environment of
dierent congurations of interconnected rooms. The robot must learn to navigate eciently
through these rooms to reach a specied goal from any start location. Figure 1 shows one
example with 5 rooms and the goal in the top right corner. The robot's actions are small
steps in any of eight directions, as indicated by the arrows. Here, the location, or state,
is simply the robot's x and y coordinates. The thin lines of Figure 1 are the walls of the
rooms, the thick lines the boundary of the state space.
+1
Goal

Robot
10

Y

11

11
12

12
13

13

14

-1
X
-1

+1

Figure 1: Robot Navigating Through a Series of Rooms
61

Drummond

If each action is independent of preceding actions, the task becomes one of learning
the best action in any state. The best overall action would be one that takes the robot
immediately to the goal. But this is only possible in states close to the goal. Suppose
the robot is in a particular state and that the number of steps to goal from each of its
neighboring states is known, indicated by the numbered squares surrounding the robot in
Figure 1. Then a one step look ahead procedure would consider each step and select the
one that reaches the neighboring state with the shortest distance to goal. In Figure 1 the
robot would move to the state 10 steps from goal. If this process is repeated, the robot will
take the shortest path to goal. In practice we must, of course, learn such values. This can
be done using some type of reinforcement learning (Watkins & Dayan, 1992; Sutton, 1990)
which progressively improves estimates of the distance to goal from each state until they
converge to the correct values.
(-1.0,1.0)

(0.25,1.0)

(0.25,0.9) O

I
(-1.0,0.25)

(-0.9,0.25)
(0.25,0.25)

Figure 2: The Value Function Obtained Using Reinforcement Learning
The function shown in Figure 2 is called the value function. Subsequently, the term
function will mean the value function unless otherwise indicated. The function is the result
of reinforcement learning on the problem of Figure 1, but instead of it representing the
actual distance to goal, it represents essentially an exponential decay with distance to goal.
The reasons for this will be made clear in Section 3.1. The shaded areas represent large
gradients in the learned function. Comparing this to the environment shown in Figure 1, it
is apparent that these correspond to the walls of the various rooms. These are the strong
features discussed in this paper. They exist because of the extra distance for the robot
to travel around the wall to reach the inside of the next room on the path to the goal.
These features are visually readily apparent to a human, so it seems natural to use vision
processing techniques to locate them.
An edge detection technique called a snake is used to locate these features. The snake
produces a polygon, in this instance a rectangle, locating the boundary of each room. The
doorways to the room occur where the dierential of the function, along the body of the
snake, is at a local minimum. The direction of the dierential with respect to edges of
62

Accelerating Reinforcement Learning

the polygon, associated with the walls of the room, determines if it is an entrance or an
exit. A positive gradient into the room indicates an entrance; a positive gradient out of
the room indicates an exit. From this information, a plane graph, labeled with an (x; y)
coordinate for each node, is constructed. Figure 2 shows one such example, for the room
at the top left corner of the state space, subsequent graphs will not show the coordinates.
Nodes corresponding to the doorways are labeled \I" or \O" for in and out respectively;
their positions on the function are indicated by the dashed arrows.

2.2 Composing Function Pieces

This overview continues by showing how the graphs, extracted from the features in the
function learned by reinforcement learning, can be used to produce a good approximation
to the solution for a new goal position. The left hand side of Figure 3 shows plane graphs
for all the rooms (ignore the dashed lines and circles for now). The node representing the
goal is labeled \G". A directed edge is added from \I" to \O" or \I" to \G", as appropriate.
Associated with this edge is a number representing the distance between the nodes. This is
determined from the value of the function at the points of the doorways. Each individual
graph is then merged with its neighbor to produce a graph for the whole problem, the right
hand side of Figure 3. The doorway nodes have been relabeled to \D". The composite
graph represents the whole function. Each individual subgraph represents a particular part
of the function. This information is stored in a case base. Each subgraph is an index and
the corresponding part of the function is the case.

O

G

I

Extract
Graphs

G

I

Merge
Graphs

G

O

D

G

I
D
O

D

I
O

D

Figure 3: Graphical Representation
Now suppose the goal is moved from the top right corner to the top left corner of the
state space. Reinforcement learning in its most basic form would be required to learn the
new function from scratch. In this work if the goal is moved, once the new goal position
63

Drummond

is known, the node representing the goal can be relocated. The new goal position is shown
as the dashed circle in Figure 3. The edges connecting the doorways and the goal are
changed to account for the new goal position. The dashed lines representing the new edges
replace the arrows in the same subgraph. To produce a new function, the idea is to regress
backwards from the goal along these edges. For each edge, the small subgraph containing
the edge is extracted. The extracted subgraph is used to index the case base of functions.
The retrieved function is transformed and added to the appropriate region of the state space
to form the new function.
Rotate
Stretch

Rotate
I

G

Stretch

I

Figure 4: Function Composition
In this example, some of the existing subgraphs match the new conguration. The two
that do not are the subgraph originally containing the goal and the subgraph now containing
the goal. It is certainly possible to exchange these two, using an appropriate transform.
But other graphs in the case base may better match the new task. The best match for
the subgraph containing the new goal is, in fact, the subgraph for the goal in the original
problem. To t this to the new task, the plane graph is rotated and stretched slightly in
the new x direction by changing the coordinates of its nodes, see Figure 4. Then this same
transformation is applied to the function. But for the room containing the original goal, a
case obtained when solving another task is a better match. The other three rooms use the
functions from the original problem, since changing the goal position has little eect on the
actions taken. In fact, only the height of the functions must be changed. This is simply
a multiplication by a value representing the distance to goal from the \O" doorway (this
is discussed in detail at the end of Section 3.3). Because the matching of the subgraphs
allows some error and asymmetric scaling may be used, the resulting function may not be
exact. But as the experiments will demonstrate, the function is often very close and further
reinforcement learning will quickly correct any error.
64

Accelerating Reinforcement Learning

The new position of the goal must be established before the graph can be modied and
function composition can occur. The system is not told that the goal has moved, rather it
discovers this by determining that it is no longer at the maximum of the existing function.
There is some uncertainty in the exact boundary of the original goal. The robot may reach
a state which it believes is part of the original goal region, but fail to detect it even if
the goal has not moved. To be reasonably certain that the goal has in fact moved, this is
required to occur ten times with no intervening occurrence of the goal being detected at
the maximum.
The system then composes a search function, by assuming a particular room contains
the goal. Search functions are also produced by composing previously learned functions.
However, for the room assumed to contain the goal the function is a constant. This does
not bias the search to any particular part of the room and allows some limited learning to
encourage exploration of the room. The search function drives the robot into the room from
anywhere else in the state space. If it fails to nd the goal after a xed number of steps,
a new search function is composed with another room assumed to contain the goal. This
process is repeated until the goal has been located ten times, this ensures a good estimate
of the \center of mass" of the goal. The \center of mass" is used as the new position of
the goal node in the composite graph. Requiring that the old goal or new goal positions
are sampled a xed number of times has proven to be eective in the domains discussed in
this paper. Nevertheless, it is a somewhat ad hoc procedure and will be addressed in future
work, discussed in Section 6.2.

2.3 Detecting Features Early
In the previous section, the existing task and the new task were strongly related, the walls
and doorways were xed and only the goal position was dierent. In this section, no such
relationship is assumed. The robot is faced with a brand new task and must determine
what, if any, relationship exists between the new task and any previous tasks.
The experimental testbed is again a simulated robot environment, but this time the
problem is simplied to just an inner rectangular room and an outer L-shaped room. Figures
5 and 6 show two possible room congurations. Again, the thin lines are the walls of the
room, the thick lines the boundary of the state space. Suppose the robot had already
learned a function for the \Old Task" of Figure 5. We would hope that we could adapt the
old solution to t the closely related \New task" of Figure 6.
The steps, in this example, are essentially those in the previous one. But now as the
learning process is started afresh, there are no features and the system must wait until they
emerge through the normal reinforcement learning process. Then we can proceed much as
before. First a graph for the inner room is extracted. The best matching graph in the
case base from the old task is rotated and stretched to t the new task. Next a matching
graph for the outer L-shaped room is rotated and stretched around the larger inner room.
The same transforms are then applied to the associated functions, any height adjustments
carried out and the functions composed to form an approximate solution to the new task.
In this example, the rst step in the process is to locate the goal. As there is no
partition to aid the search, the initial value function is set to a mid-range constant value
(see Figure 7). This allows some limited learning which encourages the system to move
65

Drummond

Goal

Robot

Outer
Room

Inner
Room

Robot

Inner
Room

Outer
Room

Goal

Figure 5: The Old Task

Figure 6: The New Task

away from regions it has explored previously, to prevent a completely random walk through
state space. Once the goal is located, the learning algorithm is reinitialized with a function
for the same goal position but no walls (see Figure 8). If such a function does not exist in
the case base, any rough approximation could be used instead. The \no walls" function is
not used exactly as stored in the case base. The dierence between the goal and the rest of
the state space is reduced by scaling the function then adding a constant. This reduces the
\bias" of the function, allowing the learning algorithm to alter it relatively easily as new
information becomes available.

Figure 7: Start Function

Figure 8: Intermediate Function

Figure 9 shows the resultant function about 3000 exploratory steps from the beginning
of the learning process. Again, the large gradients associated with the walls are readily
66

Accelerating Reinforcement Learning

apparent. Figure 10 shows the function for the new task if it had been allowed to converge
to a good solution. Both functions have roughly the same form, the large gradients are
in the same position, although learning the latter took some 200,000 steps. After the \no
walls" function is introduced the features take some time to clearly emerge. The snake will
typically lter out features that are too small and not well formed. Additional ltering at
the graphical level further constrains acceptable features. The total set of features must
produce a consistent composite graph, the doorways from dierent subgraphs must align
and the graph must overlay the complete state space. There must also be a matching case
in the case base for every subtask. Many of these checks and balances will be removed when
the iterative updating technique of Section 6.2 is incorporated.

Figure 9: Early Function

Figure 10: New Task Function

2.4 A Dierent Task Domain

The previous sections dealt with a simple robot navigation problem. This section demonstrates that these features also exist in a quite dierent domain, that of a two degrees of
freedom robot arm, as shown in Figure 11. The shoulder joint can achieve any angle between  radians, the elbow joint any angle between =2 radians, zero is indicated by the
arrows. If the arm is straight and the shoulder joint rotated, the elbow joint will describe
the inner dotted circle, the hand the outer dotted circle. There are eight actions, small
rotations either clockwise or anti-clockwise for each joint separately or together. The aim
is to learn to move the arm eciently from any initial position until the hand reaches the
goal on the perimeter of the arm's work space.
The state space, for the purposes of reinforcement learning, is the conguration space
for the arm, sometimes called the joint space (see Figure 12). The x-axis is the angle of the
shoulder joint, the y-axis the elbow joint. The eight actions when mapped to actions in the
conguration space become much like the actions in the robot navigation problem, as shown
by the shaded diamond (labeled Arm) in Figure 12. To map an obstacle in the work space
to the conguration space, one must nd all pairs of shoulder and elbow angles blocked by
the obstacle. The obstacles in this space become elongated to form barriers much like the
67

Drummond

+π/2

Shoulder

Hand

0

Elbow Angle

Obstacle

00
11
11
00
00
11
00
11
11
00

G
O
A
L

1111111
0000000
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111

Arm

0

Obstacle

Elbow
0

−π/2
−π

Obstacle
00
11
11
00
00
11
00
11
11
00

Figure 11: Work Space

0000000
1111111
1111111
0000000
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111
0000000
1111111

Obstacle

G
O
A
L

0
Shoulder Angle

+π

Figure 12: Conguration Space

walls in the experiments of the previous sections. If this is not clear, imagine straightening
the arm in the work space and rotating it such that it intersects one of the obstacles, the
middle dotted line in Figure 11. The arm can then be rotated at the shoulder joint with a
roughly linearly proportional rotation in the elbow joint, but in the opposite direction, such
as to keep it intersecting the obstacle. This produces the \wall" in the conguration space.
This linearity holds only for small objects not too far from the perimeter of the work space.
More complex, larger objects, would result in more complex shapes in the conguration
space. At the moment the feature extraction method is limited to these simpler shapes,
this will be discussed further in Section 6.
The reinforcement learning function produced by this problem is shown in Figure 13. As
before the features are shaded for clarity. The large gradient associated with the obstacle
on the left hand side of the conguration space can be clearly seen. There is a similar large
gradient associated with the obstacle on the right hand side of the conguration space.
Again, these features can be used to control the composition of functions if the goal is
moved or for a dierent task in the same domain.

3. Details of the Techniques Used
This section will discuss in more detail the techniques used. These include: reinforcement
learning to produce the initial function, snakes to extract the features producing the graph,
and the transformation and composition of the subgraphs, and their corresponding functions, to t the new task.

3.1 Reinforcement Learning

Reinforcement learning typically works by rening its estimate of expected future reward.
In goal-directed tasks, such as the ones investigated here, this is equivalent to progressively
68

Accelerating Reinforcement Learning

Figure 13: The Robot Arm Function
improving the estimate of the distance to goal from each state. This estimate is updated
by the best local action, i.e. the one moving the robot, or arm, to the new state with the
smallest estimated distance. Early in the learning process, only states close to the goal are
likely to have accurate estimates of true distance. Each time an action is taken, the estimate
of distance at the new state is used to update the estimate at the old state. Eventually this
process will propagate back accurate estimates from the goal to all other states.
Rather than directly estimating Pthe distance to goal, the system uses the expected
t
discounted reward for each state E [ 1
t=1  rt ]. The inuence of rewards, rt , are reduced
progressively the farther into the future they occur by using a  less than one. In this work,
the only reward is for reaching the goal. So the farther the state is from the goal the smaller
the value. The use of an expectation allows the actions to be stochastic, so when the robot,
or arm, takes a particular action in a particular state, the next state is not always the same.
To carry out reinforcement learning, this research uses the Q-learning algorithm (Watkins
& Dayan, 1992). This algorithm assumes the world is a discrete Markov process, thus both
states and actions are discrete. For each action a in each state s, Q-learning maintains a
rolling average of the immediate reward r plus the maximum value of any action a0 in the
next state s0 (see Equation 1). The action selected in each state is usually the one with the
highest score. But to encourage exploration of the state space, this paper uses an -greedy
policy (Sutton, 1996) which chooses a random action a fraction  of the time. The only
eect that function composition has on the Q-learning algorithm is that the initial value
for each state-action pair is set to some value other than zero.
(1)
Qts;a+1 = (1 , )Qts;a + (r + maxa Qts ;a )
The Q-function over state and action is usually referred to as the action-value function.
In this paper, it is the action-value function that is transformed and composed to form a
solution to the new task. The value function, discussed in previous sections and shown in
0

69

0

0

Drummond

the gures, is the maximum value of the Q-function. It is used to generate the partition
and associated graphs needed to control the process.
Watkins and Dayan (1992) proved that Q-learning will converge to the optimal value
with certain constraints on the reward and the learning rate . The optimal solution is produced by taking the action with the greatest value in any state. So, for goal-directed tasks,
a greedy algorithm will take the shortest path to the goal, once learning is complete. The
extension to continuous spaces may be done using function approximation. The simplest
method, and the one used here, is to divide the state dimensions into intervals. The resulting action-value function has cells representing the average Q-value of taking each action
from somewhere within a region of the state space. In o-line learning, where any action
in any state can be executed, this representation has been proven to converge (Gordon,
1995). In on-line learning, where the current state is determined by the environment, this
approach is generally successful, but there exists no proof of its convergence.

3.2 Feature Extraction
Feature extraction uses a vision processing technique that ts a deformable model called
a snake (Kass et al., 1987) to edges in an image. After initializing the snake, the process
iterates until external forces, due to the edges, balance internal forces in the snake that
promote a smooth shape. Here, the external forces are due to steep gradients in the value
function. As a piecewise constant function approximator is used, a smoothed cubic b-spline
is tted to the value-function and used to generate the necessary derivatives. The left hand
side of Figure 14 is the gradient of the value function shown in Figure 9 when extracting
features early in the learning process. The system has added a gradient around the border
to represent the state space boundary.
To locate the features, a curve is found that lies along the ridge of the hills, a local
maximum in the dierential. On the right hand side of Figure 14, the dashed lines are
contour lines for the small inner room as indicated. The bold lines, on the right hand side
of Figure 14, are the snake at dierent stages of the process. The snake is rst positioned
approximately in the center of the room, the innermost circle. It is then expanded until
it abuts on the base of the hills. Now to simplify the exposition, we can imagine that the
snake consists of a number of individual hill climbers spread out along the line representing
the snake, indicated by the small white circles. But instead of being allowed to climb
independently, their movement relative to each other is constrained to maintain a smooth
shape. When the snake reaches the top of the ridge, it is further constrained to be polygon
{ in this instance a quadrilateral { the outside dark line in Figure 14. At this point, it
will tend to oscillate around an equilibrium position. By limiting the step size the process
can be brought into a stationary state. A more detailed mathematical treatment of this
approach is given in Appendix A.
The polygon forms the \skeleton" for the graph, as shown at the top left of Figure 14.
Nodes in a graph correspond to vertices of the polygon and to the doorways and the goal.
Looking at the gradient plot, the doorways are regions with a small dierential between
the ridges. Their locations can be determined from the magnitude of the gradient along
the boundary of the polygon. In this example, a node is added for the goal (labeled G)
and this is connected to the \in" doorway (labeled I). The polygon delimits a region of
70

Accelerating Reinforcement Learning

Graph

G

Polygon

I

Doorway

Figure 14: The Gradient and Resultant Polygon (Left) Extracted by the Snake (Right)
the state space, and therefore a region of the action-value function. This becomes a case
in the case base, and the corresponding graph its index. Constraining the snake to be a
polygon is done for two reasons. Firstly, the vertices are needed to produce nodes in the
plane graphs, which are important part of the matching process. Secondly, the additional
constraint results in a more accurate t to the boundaries of the subtask. This, in turn,
results in a more accurate solution after function composition.

3.2.1 Three Extensions to the Snake Approach
This section introduces three extensions to the basic snake approach to facilitate the extraction of features.
The rst extension aects the direction the snake moves when hill climbing the gradient.
In normal hill climbing, each step is taken in the direction of steepest ascent, the step size
being determined by the size of the dierential. Roughly, this translates into forces at points
along the body of the snake. Each force points in the direction of steepest ascent locally, but
interacts with other forces through the various shape constraints. Looking at the gradient
function and contour lines of Figure 14, there is a steep slope leading to the top of each
ridge. But there is also a signicant slope along each ridge away from the doorway towards
the boundary of the state space. Thus the force on a single point on the body of the snake
71

Drummond

is not directly towards the top of the ridge but turned towards its apex, as indicated by the
bold black arrow on the left hand side of Figure 15.
Snake

Steepest
Ascent
Tangent
Normal

Figure 15: Controlling Forces on the Snake
This force can be broken into two components with respect to the snake, a normal and
a tangential force. The latter force acts along the body of the snake. Once the shape is
constrained to be a quadrilateral, this will cause the relevant side to shrink. This eect will
be partially counteracted by the force towards the top of the ridge on the adjacent side of
the quadrilateral. But the net result will be a shrinking of the two sides associated with the
ridges inwards until the forces are balanced. This will push the corner of the quadrilateral
near the doorway inwards, as indicated by the thin black arrow in Figure 15. In an extreme
case, this might cause the snake to collapse into something close to a triangle. But the more
likely outcome will just be a degradation of the accuracy of registration of the ridges.
Drummond (1998) prevented this degradation of the accuracy by restricting the snakes
to rectangular shapes. But with the weakening of this constraint to more general polygons,
this eect again becomes a problem. This problem is addressed by removing the component
of the force tangential to the snake. Then hill climbing is always in the direction of the
normal. This does not signicantly restrict the motion of the snake: all that is being removed
is the component along the body of the snake. Thus it mainly prevents the stretching and
shrinking of the snake due to the gradient.
The second extension controls the way the snake is expanded to reach the base of the
hills. Drummond (1998) used a ballooning force, as introduced by Cohen and Cohen (1993).
But problems arose when extending the system to deal with more general shapes than
rectangles, such as the outer L-shaped room in Figure 6. The ballooning force expands the
snake in directions normal to its body. One deleterious eect of this is if the snake contacts
a sharp external corner, such as that of the inner room, the force tends to push the snake
through the corner. This can be seen in Figure 16; the bold continuous lines are the snake;
the bold dashed lines are the ridges. If we imagine starting o with a circular snake in the
72

Accelerating Reinforcement Learning

middle of the L-shaped outer room, by the time it reaches the walls of the inner room the
sides of the snake are roughly perpendicular to the ridges. Thus there is little to restrain
the expansion of the snake and it passes completely through the walls of the inner room.
Ridge

Ballooning
Force

Ridge

Figure 16: Using the Ballooning Force
The approach adopted here is analogous to the ow of mercury. If we imagine starting
somewhere in the middle of the L-shaped room and progressively adding mercury, it would
tend to ll up the lower regions of the valley rst and reach the bases of the hills roughly at
the same time. The analogy of mercury is used as it has a high surface tension preventing
it from owing through small gaps in the edges associated with doorways. To increase the
eectiveness of this idea, the absolute value of the dierential of the gradient is thresholded,
values above the threshold being set to one those below to zero. It is then smoothed with
a truncated Gaussian, as shown in Figure 17. Smoothing and thresholding are commonly
used techniques in machine vision (Tanimoto, 1990). They are typically used to remove
noise, but here the aim is to strongly blur the thresholded image. This produces bowls
associated with each room. In this example, the smoothing has almost completely obscured
the presence of the doorway, although this is generally not the case.
The snake is initialized as a small circle at the minimum of one of these bowls. This
is shown as the circle in the middle of Figure 18, where the dashed lines are the contour
lines of this function. It then ows outwards, so as to follow the contour lines of the bowl;
the largest component of the ow being in the direction of the arrows in Figure 18. This
is achieved by varying the force normal to the body of the snake according to the height
dierence with the average height of the snake. Thus points along the snake which are
higher than average tend to get pushed inwards, those lower pushed outwards. The surface
tension of the mercury is produced by various smoothing constraints on the rst and second
dierentials of the snake (see Appendix A).
The third extension limits changes in the shape of the snake as it expands from its initial
position to reach the base of the hills. The smoothness constraints on the snake, that give
the mercury-like properties, prevent the snake owing through the gaps associated with the
73

Drummond

Figure 17: Smoothed Function

Figure 18: Mercury Flow

doorways. But even this proved insucient if the width of the rooms and the width of
doorways were of similar sizes. In Figure 12, looking at the \room" on the left hand side
of the conguration space of the robot arm, the \doorway" and the \room" at the top are
of similar width. Increasing the surface tension of the mercury suciently to prevent ow
through the doorways also prevents the ow to the top of the room.
The solution is to limit the amount the snake can change its shape as it grows. This
is achieved by constraining how much the second dierential of the snake can change from
step to step. In Figure 18, it is apparent that the snake takes up a good approximation
to the shape of the room some time before it reaches the ridges. If the shape can be
locked-in before reaching the ridges, the problem just described can be avoided. When
the snake is initialized, the only constraint is smoothness. As the snake is expanded, this
smoothness constraint is progressively weakened and the curvature constraint progressively
strengthened. This progressively locks in the shape while still allowing the snake to make
small local adjustments to better t the features.
The extensions, discussed in this section, either modify the traditional forces that act
on the snake or add new ones. There are also forces associated with knot spacing and drag.
How the snake moves, with each iteration, depends on the vector addition of these forces.
The sum acts to accelerate the body of the snake which has both mass and velocity, and
therefore momentum. A schematic representation of these forces is shown in Figure 19; a
more detailed mathematical description is given in Appendix A. The dashed line represents
the body of the snake; the arrows are the forces applied to one point on the body. The snake
is a parameterized function, given by f^(s) = (x(s); y(s)) where x(s) and y(s) are individual
cubic b-splines giving the x and y coordinates associated with a variable s along the body
of the snake. The circles represent points equi-distant in s but not necessarily in x and y.
These points are kept roughly the same Euclidean distance apart in x and y due to the knot
spacing force. The momentum, although not strictly a force, encourages the point to move
74

Accelerating Reinforcement Learning

in constant direction; the drag opposes any motion. The stiness encourages the snake to
maintain a smooth shape. The overall stiness is reduced as the snake grows, to keep its
exibility per unit length roughly constant, and is also controlled locally to maintain its
shape.
Steepest Ascent

MercuryFlow
Momentum

Knot Spacing

Drag
Stiffness

Figure 19: The Forces on the Snake
The following is an algorithmic summary of the processing of the snake:

 Initialize the coecients to produce a circular snake in the middle of a room.
 Iterate until the forces are roughly in equilibrium and the snake oscillates around a
stationary value.

 Modify the stiness to enforce the polygonal constraints
 Iterate for a further 25 steps increasing the momentum and drag at each step to reduce
the oscillation to a small value.

 Use the nal position of the snake to form the polygon that delimits the boundary of
the room.

3.3 Transformation

This section discusses the matching process { how a subgraph is used to locate and transform
a function from the case base. The matching process rst nds all subgraphs in the case base
isomorphic to the extracted subgraph and all possible isomorphic mappings between their
nodes, using a labeling algorithm (MacDonald, 1992). The number of isomorphic mappings
75

Drummond

is potentially exponential in the number of nodes. Here, the graphs typically have only
a few nodes and a few symmetries, so only a few isomorphic mappings. Associated with
each node of a subgraph is an (x; y) coordinate. An ane transform, Equation 2, is found
that minimizes the distances between the coordinates of the mapped nodes for each of the
isomorphic subgraphs. The advantage of this transform is its relative exibility while having
a simple form.

x0 = C0 x + C1 y + C2 y0 = C3 x + C4 y + C5
(2)
Ideally the transformed nodes would be positioned exactly over the mapped nodes, but
this is not usually possible. Even with simple rectangular shapes, the case base may not
contain a graph with exactly the same doorway positions. Using a graph that is not an
exact match will introduce some error in the composed function for the new task. By
weighting some nodes more than others where the error occurs can be controlled. One aim
is to minimize the introduction of errors that aect the overall path length. However, of
equal importance is that the errors introduced be easily correctable by normal reinforcement
learning.
1

1

2 4

1

2

1

Figure 20: Weighting Graph Nodes
The left hand side of Figure 20 shows the composite graph for the new task. The right
hand side shows the result of overlaying it with a graph from the case base. If the t at the
doorway of the outer L-shaped room is in error, the robot will tend to miss the doorway
and collide with the wall on one side. The farther the doorway is out of position, the longer
normal reinforcement learning will take to correct the error. To encourage a good t at
the doorway, a weight of 4 is used. Nodes adjacent to the doorway are given a weight of 2,
all other nodes have a weight of one. This is based on the intuition that more trajectories,
from dierent parts of the state space, will be pass through the region close to the doorway.
Any error here is likely to have a broader eect, and take longer for normal reinforcement
76

Accelerating Reinforcement Learning

learning to correct, than in regions far from the doorway. So the t around the inner room
is improved by sacricing t far from the doorway.
The exact position of the doorway in the inner room is not critical and its weight is
set to 0.5. Whatever the position of the doorway, the shape of the function will be correct
inside the room as the goal is also in this room. However, the further the doorway is from
its correct position, the greater the error in the edge length. This will produce some error
in the composed function, but again the expectation is that this error will be small and
reinforcement learning will quickly correct it.
Not only should the t be good, but we would also prefer that the amount of transformation be small. All transforms produce some error and this is particularly true of
asymmetric scaling, as discussed later in this section. Generally the transform produces
translation, reection, rotation, shearing and independent scaling in each dimension. In
the robot navigation domain, the distance between points in the state space is just the
normal Euclidean distance. The reinforcement learning function is an exponential decay
in the distance to goal. If the transformation does not change the Euclidean distance, the
transformed function should be directly applicable.

Affine  Similar  Symmetric
(3)
The ane transformation is just one family in a hierarchy of transformations. At the
bottom of this hierarchy, shown in Equation 3, are the symmetric transformations. These
solid body transformations do not change the Euclidean distance. The next step up in
the hierarchy introduces scaling, equal in each dimension. This will aect the Euclidean
distance but only by a multiplicative factor. Thus the only change needed to the transformed
function is to scale the height. The ane transformations allow the addition of asymmetric
scaling and shear, which will distort the Euclidean distance. To determine the amount
of distortion, the transformation is applied to the unit circle. The symmetric, rigid body,
transformations will not alter the circle, but the other transformations will. The symmetric
scaling transform just changes the diameter of the circle. The asymmetric scaling and shear
transformations change the circle into the ellipse. The amount of distortion of the Euclidean
distance introduced by the transform can be determined by the ratio of lengths of the major
and minor axes of the ellipse.
error = sqrt
(P
wi(
x2 + yi2 )) (node misalignment)
2 i
 i


(Euclidean Distortion)
+ log2  rrmaj
(4)
min
2

j
r
+
r
j
maj
min
+ 0:05 log2
(scaling factor)
2
The error of t of the transformed subgraph can be combined with the transformation
error using the lengths of the major and minor axes, rmaj and rmin respectively, of the
ellipse. There is a penalty for Euclidean Distortion from asymmetric scaling and shear.
The log factor is added directly to the error of t as shown in Equation 4. Log factors are
used, so that the penalty functions are symmetric. There is a small penalty for symmetric
scaling. Once the best matching subgraph has been found, the same transformation can be
applied to the associated function. If no isomorphic graph is found with a total error less
than 1.5, a constant function will be used as a default. Where the new graph overlays the
old graph, values are assigned by using bilinear interpolation on the discrete values of the
77

Drummond

function. Where it does not, bilinear extrapolation is used, based on the closest values. In
both cases once the four values are selected, the value for the new point is calculated as
shown in Equation 5. As the action-value function is indexed by action as well as state, this
process is carried out for each action in turn. Any rotation or reection in the transform
is also applied to a predened matrix of actions. This produces the necessary mapping of
actions from the original to the new action-value function.

v = c1 x + c2 y + c2 xy + c3

(5)

Finally, the height of the new action-value function must be adjusted to account for the
change in overall distance to goal. The height of the value function at an \out" doorway is
 dg where dg is the distance to goal and  the discount factor. The value at some random
point within the room is  dg+dd where dd is the distance to the doorway. The action-value
function is rst normalized by dividing by  dg , the height of the function at the doorway
in the original problem. It is then multiplied by  dng , where dng is the distance to the
new goal; the value of the point becomes  dng+dd . Scaling will also aect the height of the
function. Assuming the scaling is symmetric then the new value function for anywhere in
the room will be  cdd where c is the scale factor. Thus raising the function to the power of c
i.e. ( dd )c will account for scaling. When scaling is symmetric the result is exact, assuming
distance is based on the linear combination of the two dimensions. With asymmetric scaling,
the result is not exact. But if the dierence between the two scale factors is relatively small,
it is a useful approximation to use their maximum.
The following is an algorithmic summary of the whole matching process:

 SG = subgraph extracted from the new task.
 For each subgraph G acting as an index to the case base

{ For each isomorphic mapping of G to SG
 Find minimum weighted least squares t of G to SG using mapping
 Ane transform = coecients of least squares t
 Penalized t = least squares error + transform penalty
 Keep graph and transform with lowest penalized t
 Retrieve function associated with best graph from case base (if none use default)
 Apply ane transform to function
 Apply bilinear interpolation/extrapolation
 Adjust function height
 Add new function to existing function
78

Accelerating Reinforcement Learning

3.4 Composition

This section describes function composition, how the transformation is applied successively
to the series of subgraphs extracted from the composite graph. Function composition uses a
slightly modied form of Dijkstra's algorithm (Dijkstra, 1959) to traverse the edges between
doorway nodes. The left hand side of Figure 21 shows the composite graph after moving
the goal in the robot navigation example of Section 2.2. The right hand side shows the
graph traversed by Dijkstra's algorithm.

G

d2

G

D

d1

D

Gr3

Gr1

D

D

d3

D

Gr2
D

D

Gr5

D

Gr4

Figure 21: Using Dijkstra's Algorithm
To begin the process, the subgraph which contains the goal is extracted and the best
matching isomorphic subgraph is found. The edge lengths in the composite graph are
then updated using the scaled length of the corresponding edge in the matching isomorphic
subgraph, d1 and d2 in Figure 21. As d2 is less than d1, the next subgraph extracted,
Gr2, is the one sharing the doorway node with the edge of length d2. The best matching
isomorphic subgraph is found and the edge of length d3 updated. The shortest path is
again determined. As d1 is less than d2 + d3 subgraph, Gr3 is extracted. The process is
repeated until all subgraphs have been updated. At each stage when a subgraph is matched,
the corresponding transformed function is retrieved and added to the new function in the
appropriate region.
In this example, there is only a single path to the goal from each room. Often there will
be multiple paths. Suppose room 5 had an additional doorway in the lower left corner of
the room, labeled \B" on the left hand side of Figure 22, in addition to the original doorway
labeled \A". The graph, shown on the right hand side of Figure 22, would result. There are
now two possible paths to the goal of lengths d4 and d5. If the length across room 5, d6, is
greater than the absolute dierence between d4 and d5, the choice of path from this room
will be determined by a decision boundary inside the room. This is produced by taking the
79

Drummond

0110
11111110 Room 3
000000
10
A
10
1111111
0000000
0
Room 2 1
1010
000 10 Room 5
111
000 10
111
Room 4 1
0
Room 1

d5
A
n2

d4

d6

n1

Gr5
B

B

n3

Figure 22: Multiple Paths to Goal
maximum of two functions as shown in Figure 23: one for entering by doorway \A" and
leaving by doorway \B"; one for entering by doorway \B" and leaving by doorway \A".
This principle can be repeated if there are more than two paths to the goal from a given
room.
If the cross-room distance, d6, had been smaller than the dierence (jd4-d5j) the decision
boundary would have to be in another room. In general, we want to nd the room in which
the cross-room distance is larger than the dierence between the incident paths. This is
repeated for every cycle in the path graph. A cycle is detected when a node is visited twice,
indicating that it is reachable by two separate paths. Let us suppose this is node n3 in the
graph of Figure 22. As Dijkstra's algorithm is being used, we know that all previous nodes,
on either path, such as n1 and n2 are already closed. This must be true for both paths
to have reached n3. All the rooms on paths up to these nodes cannot contain the decision
boundary, so it must be in either room 4 or 5. To decide which remaining room it is in, we
compare the two path lengths. If d4 is longer than d5 + d6 then the decision boundary will
be in room 4; otherwise it will be in room 5.
Whichever room is selected, the decision boundary is produced from the maximum of two
functions. The heights of the two functions, when adjusted for their path lengths, determine
where the decision boundary occurs within the room. If the paths are of equal length, taking
the maximum will correctly put the decision boundary at the doorway. If there are no such
functions in the case base, functions that already include decision boundaries may be used.
This technique produces a correct decision boundary if the dierence in the path lengths
entering the room is less than the dierence between the heights of the function at the \out"
doorways. On the left hand side of Figure 24 there is a room with two doorways. As path
1 is signicantly longer than path 2, the decision boundary is far to the left. The shortest
path to the goal from most of the room is via the right hand doorway. If this function is
combined with a mirror image of itself, it will produce a decision boundary in the middle
80

Accelerating Reinforcement Learning

Maximum
Decision
Boundary

Figure 23: Combining Two Functions

Decision
Boundary

Path 1
Path2

Room

Figure 24: Decision Functions

81

Drummond

of the room, as shown on the right hand side of Figure 25. This could be used for the new
problem shown on the left hand side of Figure 25 where the two paths are the same length.
Again the heights of the two functions can be changed to move the decision boundary. But
it cannot be moved to anywhere in the room. The decision boundary can be moved no
closer to a particular doorway than in the original function shown in Figure 24
Decision
Boundary
Path 1

Path2

Room

Figure 25: Combining Decision Functions

4. Experiments

This section compares learning curves for function composition and a simple baseline algorithm. Four sets of results are presented; one for each of the two types of related task
in each of the two domains. The learning curves represent the average distance to goal as
a function of the number of actions taken during learning. The distance is averaged over
64 dierent start positions, distributed uniformly throughout the state space, and over the
dierent experimental runs. To determine this distance, normal learning is stopped after a
xed number of actions and a copy of the function learned so far is stored. One of the 64
start positions is selected, learning is restarted and the number of actions needed to reach
the goal is recorded. If a trial takes 2000 actions and has not yet reached the goal, it is
stopped and the distance to goal recorded as 2000. The function is then reinitialized with
the stored version and another start state selected. This is repeated 64 times. Then the
function is reinitialized once more and normal learning resumed.
The baseline algorithm and the underlying learning algorithm for the function composition system is the basic Q-learning algorithm, using a discrete function approximator as
discussed in Section 3.1. The learning rate  is set to 0.1, the greedy policy uses an  of 0.1
(the best action is selected 90% of the time), the future discount  is 0.8 and a reward of 1.0
is received on reaching the goal. Although the state spaces for the dierent domains represent two quite dierent things { the robot's hx; yi location and the angle of the arm's two
joints { the actual representation is the same. The state space ranges between 1 for each
dimension. A step is 0:25 in each dimension either separately or together, giving the eight
possible actions. The actions are stochastic, a uniformly distributed random value between
0:125 being added to each dimension of the action. In the robot navigation examples if
82

Accelerating Reinforcement Learning

the robot hits the wall, it is positioned a small distance from the wall along the direction of
its last action. This has not been implemented for the robot arm as it is a somewhat more
complex calculation. Instead, if a collision with an obstacle occurs the arm is restored to
its position before taking the action.
Learning begins at a randomly selected start state and continues until the goal is reached.
Then a new start state is selected randomly and the process repeated. This continues until
the requisite total number of actions is achieved. Speed up is calculated by dividing the
number of learning steps at one specic point on the baseline learning curve by the number
of learning steps at an equivalent point on the function composition system's learning curve.
The knee of the function composition system's curve is used. This occurs where the low
level learning algorithm is initialized with the composed function. This is compared to the
approximate position of the knee of the baseline curve.

4.1 Robot Navigation, Goal Relocation
The rst experiment investigates the time taken to correct a learned function when the goal
is relocated in the robot navigation domain. There are nine dierent room congurations,
as shown in Figure 26, the number of rooms varying from three to ve and there are four
dierent goal positions. Each room has one or two doorways and one or two paths to the
goal. To initialize the case base, a function is learned for each of these congurations with
the goal in the position shown by the black square. The rooms are generated randomly,
with some constraints on the conguration of the rooms and doorways: a room can not
be too small or narrow, a doorway can not be too large. The case base also includes
functions generated for the experiments discussed in Section 4.3. This was necessary to
give a sucient variety of cases to cover most of the new tasks. Even with this addition,
not all subgraphs are matched. Constant valued default functions are used when there is
not a match. This reduces speed up signicantly, but does not eliminate it altogether.

1

2

3

4

5

6

7

8

9

Figure 26: The Dierent Suites of Rooms
83

Drummond

Once the case base is loaded, the basic Q-learning algorithm is rerun on each room
conguration with the goal in the position shown. After 400,000 steps the goal is moved,
this is denoted as time t on the x-axis of Figure 27. The goal is moved to one of the
three remaining corners of the state space, a task not included in the case base. Learning
continues for a further 300,000 steps. At xed intervals, learning is stopped and the average
number of steps to reach the goal is recorded. The curves in Figure 27 are the average of
27 experimental runs, three new goal positions for each of the nine room congurations.
Function Composition

Average No. of Steps to Goal

Q-Learning
Q-Learning (No Reinit)

10

10

3

2

1

10
t-400....t-100

t-50

t

t+50

t+100

t+150

t+200

t+250

t+300

t + No. of Learning Steps X 1000

Figure 27: Learning Curves: Robot Navigation, Goal Relocation
The basic Q-learning algorithm, the top curve of Figure 27, performs poorly because,
when the goal is moved, the existing function pushes the robot towards the old goal position.
A variant of the basic algorithm reinitializes the function to zero everywhere on detecting
that the goal has moved. This reinitialized Q-learning, the middle curve, performed much
better, but it still has to learn the new task from scratch.
The function composition system, the lowest curve, performed by far the best. The
precise position of the knee of this curve is dicult to determine due to the eect of using
default functions. If only those examples using case base functions are considered, the knee
point is very sharp at about 3000 steps. The average number of steps to goal at 3000 steps,
for all examples, is 40. The non-reinitialized Q-learning fails to reach this value within
300,000 steps giving a speed of over 100. The reinitialized Q-learning reaches this value
at about 120,000 steps, giving a speed up of about 40. Function composition generally
produces accurate solutions. Even if some error is introduced, further Q-learning quickly
renes the function towards the asymptotic value of about 17. After about 150,000 steps,
84

Accelerating Reinforcement Learning

normal Q-learning reaches an average value of 24 steps and then slowly renes the solution
to reach an average value of 21 after 300,000 steps.

4.2 Robot Arm, Goal Relocation
The second experiment is essentially a repeat of the rst experiment but in the robot arm
domain. The initial number of steps, before the goal was moved, was reduced to 300,000
to speed up the experiments. As the arm has only two degrees of freedom, and with the
restrictions discussed in Section 2.4, the number of variations is small. So only three obstacle
congurations were used, constructed by hand, with two obstacles in each. To increase the
number of experiments, to allow for greater statistical variation, each conguration was
repeated with the goal in each of three possible positions, as shown in Figure 28. The
black diamonds represent the obstacles, the black rectangles the goal. Solutions to all these
tasks were loaded into the case base. When composing a function, however, the system is
prevented from selecting a case that comes from the same goal and obstacle conguration.

1

2

3

4

5

6

7

8

9

Figure 28: The Robot Arm Obstacle and Goal Positions
The curves in Figure 29 are the average of 18 experimental runs, two new goal positions
for each of the three original goal positions in the three obstacle congurations shown in
Figure 28. There are only two learning curves, non-reinitialized Q-Learning being dropped.
As in the rst experiment, the function composition system, the lower curve, performed
much better than Q-learning. The knee of the function composition system occurs at 2000
steps, the knee of Q-learning at 50,000 steps, giving a speed up of 25. In this experiment,
the case base contained subgraphs that matched for all new tasks, so default functions were
not needed. The composed functions tend to be very accurate and little further renement
is necessary.
85

Drummond

Function Composition

Average No. of Steps to Goal

Q-Learning

10

10

3

2

1

10
t-300....t-100

t-50

t

t+50

t+100

t+150

t+200

t+250

t+300

t + No. of Learning Steps X 1000

Figure 29: Learning Curves: Robot Arm, Goal Relocation

4.3 Robot Navigation, New Environment
The third experiment investigates the time taken to learn in a new, but related, environment
in the robot navigation domain. Nine dierent inner rooms were generated randomly, again
under some constraints. All have a single doorway, but the size and position of the room
and the location of the doorway are varied as shown in Figure 30. To initialize the case base,
a function is learned for each of these congurations with the goal inside the small room as
indicate by the dark square. Learning is then repeated on each of the room congurations
in turn. However, when composing the new function the system is prevented from selecting
a case learned from the same goal and room conguration. Experimental runs for the Qlearning algorithm and the function composition system are initialized with a at function
of zero and 0.75 everywhere respectively, denoted as zero on the x-axis. Learning continues
for 100,000 steps. To improve the statistical variation, experiments for each conguration
were repeated three times, each time with a new random seed. The curves in Figure 31 are,
therefore, the average across 27 experimental runs.
The top curve is the Q-learning algorithm, the bottom curve the function composition
system. For these experiments, locating the goal took typically between 400 and 1200 steps,
although some took 2000 steps. The function composition system then introduces the \no
walls" function and typically a further 800 to 4000 steps are taken before usable features are
generated. Again, certain experimental runs took longer, this will be discussed in Section
5.2. Due to these runs, the knee of the function composition system's curve occurs at 12,000
steps. The knee of the basic Q-learning curve occurs at approximately 54,000 steps giving
86

10

10

10

3

2

0

1

1

5

2

9

6

3

30

40

50

60

70

Q-Learning

80

90

Function Composition

Accelerating Reinforcement Learning

4

8

20

Figure 30: The Single Rooms

7

10

No. of Learning Steps X 1000

87

100

Figure 31: Learning Curves: Robot Navigation, New Environment

Average No. of Steps to Goal

Drummond

a speed up of 4.5. As in previous experiments once initialized the function is very accurate
and little further renement is necessary. Basic Q-learning, on reaching the knee, takes a
long time to remove the residual error.

4.4 Robot Arm, New Environment

10

10

10

3

2

0

1

1

20

30

2

40

50

3

60

70

Q-Learning

80

90

Function Composition

Figure 32: The Dierent Obstacle Positions

10

No. of Learning Steps X 1000

Figure 33: Learning Curves: Robot Arm, New Environment
88

100

The fourth experiment is essentially the same as the third experiment except in the robot
arm domain. Here, three, hand crafted, congurations of a single obstacle with the goal in
a xed position were used, as shown in Figure 32. To increase the statistical variation each
conguration was run ve times with a dierent random seed. The curves in Figure 33 are
therefore the average across 15 experimental runs.

Average No. of Steps to Goal

Accelerating Reinforcement Learning

The top curve of Figure 31 is the Q-learning algorithm, the bottom curve the function
composition system. The knee of the function composition system's curve occurs at about
4400 steps. The knee of the basic Q-learning algorithm at about 68,000 steps giving a speed
up of about 15.

5. Analysis of Results

The experiments of the previous section have shown that function composition produces
a signicant speed up across two dierent types of related task and across two domains.
In addition, the composed solutions tend to be very accurate and little further renement
is required. This section begins by looking at possible concerns with the experimental
methodology that might aect the measurement of speed up. It then discusses various
properties of the task being solved that aect the speed up achieved by using function
composition.

5.1 Possible Concerns with the Experimental Methodology

The speed up obtained using function composition is suciently large that small variations
in the experimental set up should be unlikely to aect the overall result. Nevertheless, there
are a number of concerns that might be raised about the experimental methodology. Some
will be, at least partially, addressed in this section; others will be the subject of future work.
The rst concern might be how the estimated value of speed up is measured. The
value represents the speed up of the average of a set of learning tasks, rather than the
average of the speed up in each of the tasks. One of the diculties of estimation, with
curves for single tasks, is that the average distance to goal may oscillate up and down as
learning progresses, even though the general trend is downwards. This makes judging the
position of the knee of the curves dicult, and any estimate of speed up questionable. Even
experimental runs using the same conguration, but with dierent random seeds, exhibit a
considerable variation. In some instances, the speed up measured on individual curves may
benet the function composition system, in others, the baseline algorithm. Nevertheless,
probably overall most of these eects will cancel out.
The second concern might be the eect on speed up of the limit of 2000 steps when
measuring the distance to the goal. Comparing two averages of values limited in this way
is sometimes misleading (Gordon & Segre, 1996). But this limit primarily aects only the
baseline algorithm, and was only signicant when the goal was moved and the function not
reinitialized. Estimation of speed up is principally concerned with comparing the position
of the knees of the dierent curves. Here, the average distance to goal is relatively small,
so limiting the value is likely to have little eect.
The third concern might be that the value of speed up is dependent on the conguration
of the baseline algorithm. Certainly, it is the experience of this author that the way the
function is initialized, and how actions are selected, can have an impact on the speed of
learning. In previous work (Drummond, 1998), the function was initialized to a constant
value of 0.75, a technique termed \optimistic initial values" by Sutton and Barto (1998).
Tie breaking between actions of the same value was achieved by adding a small amount of
noise (circa 5  10,5). It was expected that this would increase exploration early on in
the learning process and speed up learning overall. However, using an initial value of zero
89

3

2

0

1

50

Drummond

100

150

200

250

300

and a strict tie-breaker, randomly selecting amongst actions with the same value, turned
out to produce a signicant speed up in the baseline learning algorithm. This conguration
was used for the preceding experiments, but on one experimental run this caused serious
problems for the baseline algorithm.

10

10

10

No. of Learning Steps X 1000

Figure 34: Learning Curves in a Partially Observable Domain

90

The upper learning curve of Figure 34 is for the baseline algorithm, for one run when
the goal was moved in the robot arm domain. As it had such a large impact on the average
learning curve, it was replaced by the lower curve, produced by repeating the experiment
with a dierent random seed. This very slow learning rate arises from the interaction
of the partial observability of the robot arm domain with the use of an initial value of
zero. Individual cells of the function approximator straddle the obstacles allowing a \leakthrough" of value from one side of the obstacle to the other. Starting with a zero value,
once an action receives some value it will remain the best action for some time. Continual
update of this action will decrease the value, but it can only asymptotically approach zero.
Until other actions for the same state are updated, it will always be selected as the greedy
action. This did not occur for higher initial values. It may be that in domains where there is
some degree of partial observability, small initial values are better than zero or some means
of improving exploration for very small values might be necessary.
Other variations in the parameters of the baseline algorithm have not been explored
in this paper. For instance, a constant learning rate of 0.1 was used. Alternatives, such
as starting with a higher rate and reducing it as learning progresses might also improve
the overall speed of the baseline algorithm. Some preliminary experiments were, however,

Average No. of Steps to Goal

Accelerating Reinforcement Learning

carried out using undiscounted reinforcement learning, the discounting being strictly unnecessary in goal-directed tasks. Room conguration 1 of Figure 26, with the goal in the
lower right hand corner, was used as the experimental task. The discounting, discussed in
Section 3.1, is turned o by setting  to 1. In addition, the value on reaching the goal state
is set to zero and a cost is associated with every action. This form of learning simplies
function composition, normalization procedures needed to compensate for the value function's exponential form being no longer required. With normalization disabled, the snake
successfully partitioned the function, the most critical part of the process. However, the
baseline learner took considerably longer to learn the function than in the discounted case.
With discounting, the learner reached an average distance to goal of about 72 steps after
80,000 learning steps. Without discounting, the learner reached an average of 400 steps at
the same point in time and only an average of 80 steps after 300,000 learning steps. The
action-value function was initialized to zero, which appears to be the standard practice in
the literature. However, the experience with initialization in the discounted case suggests
this might be the part of problem and this will be investigated in future work.
The baseline Q-learning algorithm used is the most basic and a more sophisticated one
would unquestionably reduce the speed up experimentally obtained. For instance, some
form of reinforcement learning using eligibility traces (Singh & Sutton, 1996) might be
used. For the experiments when the goal was moved, a baseline such Dyna-Q+ (Sutton,
1990) which was specically designed to deal with changing worlds would probably be a
better reference point.
The speed up obtained, by transferring pieces of an action-value function, has also not
been compared to alternatives, such as transferring pieces of a policy or transferring pieces
of a model. Transferring pieces of a policy would reduce memory requirements and not
require the rescaling applied to pieces of an action-value function. It does, however, have
two disadvantages. Firstly, a solution can not be directly composed, as the position of
decision boundaries can not be determined. Further learning would be necessary to decide
the appropriate policy for each room. Secondly, the policy only indicates the best action.
The action-value function orders the actions, indicating potentially useful small changes
to the policy which might improve the accuracy on a new task. Transferring pieces of a
model, would require rst learning a model consisting of a probability distribution function
for each action in each state. The memory requirement is considerably larger, unless the
states reachable by an action are limited beforehand. Nevertheless, a model would need
less modication in a changing world, such as when the goal is moved. It also carries
more information which might speed up learning. The action-value function seems a good
compromise in terms of complexity versus information content, but this would need to be
empirically validated and is the subject of future work.

5.2 Performance Variation with Task Conguration
Generally, function composition outperforms the baseline learning algorithm by an amount
dependent on the complexity of the learning problem. In the robot navigation domain
when the goal was moved, the amount of speed up increased with more rooms and fewer
paths to goal. A speed up of 60, against an average speed up of 40, was obtained on the
congurations with ve rooms and a single path to goal. Congurations with only three
91

Drummond

rooms had the least speed up, but this was not only due to the relative simplicity of the
problem.

10

10

10

3

2

0

1

50

6

100

Q-Learning

Function Composition

No. of Learning Steps X 1000

6

92

Figure 35: Failure in Robot Navigation Moving Goal

6

150

The top of Figure 35 shows the average of four learning curves for the three room
congurations. The bottom of Figure 35 shows one of the congurations that produced
these curves. Not only is it one of the easiest tasks (from the experimental set) for the
baseline algorithm, but also there are no solutions in the case base for the lowest room.
There are no isomorphic subgraphs of this form. Rather than not composing a solution,
the system introduces a constant value function for this room. This room represents almost
half the state space, so much additional learning is required. As the top of Figure 35 shows,
initially there is signicant speed up. Further renement reduces the advantage and for
a short while the baseline algorithm is better. But later, function composition gains the
upper hand and converges more quickly than the baseline algorithm towards the asymptotic
value.

Average No. of Steps to Goal

Accelerating Reinforcement Learning

In the robot navigation domain when learning a new task, the amount of speed up varied
with the size of the inner room. This was primarily due to the number of actions needed
before the features emerged with sucient clarity for the snake to locate them. Function
composition is most successful when the inner room is small. If a wall is long, the feature
takes more time to develop, more renement by Q-learning is needed to make it apparent.
Very short walls are also hard to identify. The likelihood of the robot colliding with them
is small and it takes many exploratory actions for the features to emerge clearly.
The features may be suciently clear for the snake to form a partition, yet not be well
enough dened to precisely locate the doorways. A doorway may appear to be a bit wider
than it actually is. More importantly, it may appear to be displaced from its true position.
Typically, the error in the composed function is small and normal reinforcement learning
quickly eliminates it. In one of the experimental runs, conguration 2 in Figure 30, the
speed up was reduced by a factor of 2 due to the doorway being incorrectly positioned.
The feature representing the lower wall had not completely emerged when the partition
was generated. This made the doorway appear to be almost exactly at the corner. The
algorithm, in fact, positioned the doorway just on the wrong side of the corner. This resulted
in the signicantly reduced speed up. But it is unclear why reinforcement learning took
so long to correct what seems, on the surface at least, to be a local error. This will be
investigated in future work.

6. Limitations

Limitations come in , roughly, two kinds: those arising from the overall approach and those
arising from the way it was implemented. In the former case, ways to address these limitations may be highly speculative, or impossible without abandoning some of the fundamental
ideas behind the approach. In the latter case, there is a reasonable expectation that future
work will address these limitations. The following sections will deal with these cases in
turn.

6.1 Limitations in the Approach

To explore the possible limitations in the approach, this section reviews the fundamental
assumptions on which it is based.
It is a fundamental assumption that features arise in the reinforcement learning function
that qualitatively dene its shape. The features used in this paper are the violation of a
smoothness assumption, that neighboring states have very similar utility values. A wall, by
preventing transitions between neighboring states, typically causes such a violation. Other
things, such as actions with a signicant cost, would have a similar eect. Smaller, and
much more varied costs, will not generate the features required by this approach, so it oers
little in the way of speed up in these cases. If there is a mixture of large and small costs,
it is expected that the system will capture features generated by the former, initialize the
function and normal reinforcement learning will address the latter.
The smoothness assumption is less clear if the dimensions are not numeric. The neighborhood relation, used here, is a predened distance metric over a continuous space. In
nominal, binary or mixed domains it is not obvious how such a metric would be dened,
although there is some work on such metrics for other applications (Osborne & Bridge,
93

Drummond

1997). If the dimensions are mixed, feature location might be limited to the continuous
ones. If the dimensions are purely nominal or binary, a generalization of the snake may be
appropriate. The snake is, at an abstract level, a constrained hill climber. But whether or
not this idea would usefully generalize in this way is at present somewhat speculative.
It is a fundamental assumption that the features clearly delimit subtasks. In the domains discussed in this paper, the obstacles and walls subdivide the state space into regions
connected by small \doorways". The subtask of reaching one doorway is not greatly aected
by the subsequent subtask. In other domains this may not be the case. As the doorways
become larger, the context sensitivity increases. As long as the composed solution is reasonably accurate, reinforcement learning can easily correct the error although speed up will
be reduced. At some point however, due to a very large amount of context sensitivity, the
advantage of dividing the task into subtasks will become questionable. It would be possible
to account for some of the context dependency in the graph matching stage, looking at
larger units than subgraphs. If two adjacent subgraphs match the new problem, they might
be used as a pair, thereby including any contextual relationship between them. Even if
single subgraphs were used, the context in which they appear, i.e. the shape of neighboring
subgraphs, could be taken into account. In the limit, graph matching the whole task might
be used. But, as was argued in the introduction, this would considerably limit when transfer
is applicable, and thus its overall eectiveness.
It is a fundamental assumption that the absolute position of the features is unimportant, it is the shape of the delimited region that matters. To increase the likelihood of
transfer, solutions to subtasks have been subjected to a variety of transformations. In
some domains, many, if not all, of these transformations will be invalid. If actions cannot
be rotated or reected, or if many small costs aect dierent regions of the state space,
the eectiveness of transfer will be reduced. This would be, to some extent, addressed by
additional penalties for dierent transformations, but again this would limit the opportunities for transfer. Which transformations are appropriate, and whether or not this can be
determined automatically from the domain, will be the subject of future research.
It is a fundamental assumption that a vision processing technique can locate these
features in a timely fashion, even in very high dimensional domains. Learning in very high
dimensional domains is likely to be slow whatever technique is used. Normal reinforcement
learning will take time to navigate the much larger space, slowing down the emergence of
the features. Although the time taken to partition the function will increase, the frequency
with which partitioning is applicable will decrease. Thus the amortized cost will rise more
slowly. Further, as high dimensional spaces are generally problematical, methods such as
principal components analysis and projection pursuit (Nason, 1995) can be used to reduce
dimensionality. It may prove in practice that the dimensionality which is important, and is
the focus of feature extraction, is much smaller than the actual dimensionality of the space.

6.2 Limitations in the Implementation
If the assumptions of the previous section are met, it is expected that the remaining limitations are due to the present implementation. These limitations are likely to become
apparent when the system is applied to other domains. Certainly other domains may dier
from those presented in this paper in a number of ways.
94

Accelerating Reinforcement Learning

A domain may dier in that the dimensionality of the space is higher than the two
dimensions of the tasks investigated in this paper. The implementation of the snake has
been updated to work in higher dimensions. The bold lines at the top of Figure 36 are
one of the simpler tasks from the robot navigation domain. The task has been extended in
the Z-dimension. The snake starts out as a sphere and then expands outwards until it lls
the room. In this example, the polygonal constraint has not been used, but everything else
remains the same. Figure 37 shows the complete partition of the task.

Figure 36: Adding a Z-Dimension

Figure 37: The Complete 3D Partition

The mathematics behind the snake is not limited to three dimensions. There also seems
to be nothing in principle that would prevent other processes such as graph matching,
planning or transformation from working in higher dimensions. Speed is the main problem.
This is not a problem unique to this approach and there is a large body of research addressing
this issue. For instance, although graph matching is in general NP-complete, there is
much active research in speeding up matching on the average or in special cases (Gold &
Rangarajan, 1996; Galil, 1986). At present, the snake represents the principal restriction
on speed. This is an issue of great importance to the vision processing community. Current
research is investigating this problem, at least in two or three dimensions. One example is
hierarchical methods (Schnabel, 1997; Leroy, Herlin, & Cohen, 1996) which nd solutions
for the snake at progressively ner and ner resolution scales. The results of such research
will undoubtedly be of importance here.
A domain may dier in that the value function learned might not produce features locatable by the snake with the present parameter settings. The values of the parameters
were empirically determined, using hand crafted examples from the robot navigation and
the robot arm domains. The obvious danger is that the parameters might be tuned to these
examples. To demonstrate that this is not the case, congurations for the experiments in
the robot navigation domain were generated randomly. As congurations for the robot arm
domain are more tightly constrained, the hand crafted examples were used in the experiments. Nevertheless, the experiments have shown that the parameters worked successfully
for random examples in the robot navigation domain. The same parameters also work successfully in the second domain, the robot arm. The following discussion demonstrates that
95

Drummond

they are also reasonably eective in a quite dierent domain, the \car on the hill". It is
anticipated that using the results of current research into snakes will automate the selection
of many parameters.
In the \car on the hill"domain (Moore, 1992), the task, simply stated, is to get a car
up a steep hill, Figure 38. If the car is stationary part way up the hill, in fact anywhere
within the dotted line, then it has insucient acceleration to make it to the top. So the
car must reverse down the hill and then achieve sucient forward velocity, by accelerating
down the other side, before accelerating up the hill. The state space, for the purposes of
reinforcement learning, is dened by two dimensions. These are the position and velocity
of the car, as shown in Figure 39. The goal is to reach the top of the hill with a small
positive or negative velocity. In this domain there are two possible actions: accelerate
forward, accelerate backwards. Unlike in previous domains, there is no clear mapping of
the actions onto the state space. The state achieved on applying an action is determined by
Newton's laws of motion. As the car has insucient acceleration to make it up the hill from
everywhere in the state space, a \wall" is eectively introduced, the bold line in Figure 39.
To reach the top of the hill, the car must follow a trajectory around this \wall", the dashed
line in Figure 39.
Goal

Velocity

+ve

Goal

0

y

cit

lo
Ve

-ve

0

Position

Figure 38: The Car on the Hill

Position

Figure 39: Car State Space

Figure 40 shows the reinforcement learning function. It exhibits the same steep gradient
as the other domains. The important point to note is that, unlike in the other domains,
no physical object causes this gradient. It is implicit in the problem itself, yet the features
still exist. Figure 41 shows the partition produced when applying the snake to the \car on
the hill" domain. The main dierence from the previous examples is that the polygonal
constraint has not been used. When the snake initially comes to rest, the mercury force
is turned o and then the snake is allowed to nd the minimum energy state. It was also
necessary to reduce the scaling of the edges, by about a factor of three quarters, to achieve
the accuracy of t. The t around the top left corner of the second snake, the dashed line,
96

Accelerating Reinforcement Learning

also has some problems: the snake is growing very slowly downwards and is, at present, only
stopped because it has reached the maximum number of iterations allowed. One diculty
in this example is that there is not such clear delimitation of the upper and lower regions
at the end of the feature. Future work will investigate altering the stopping condition to
eliminate this problem.

Figure 40: The Steep Gradient

Figure 41: The Regions Extracted

A domain may dier in that the shape of various regions in the partition is more complex than can be dealt with by the present snake. Fitting the snake to the task discussed in
the previous paragraphs goes some way towards mitigating that concern. Nevertheless, the
randomly generated examples of Section 4.1 were subject to certain constraints. Congurations with narrower rooms were tried informally, but the snake did not reliably locate the
features. The congurations in Section 4 represent the limit of the complexity of partition
the snake can produce at present. It is expected that using ideas from the large body of
already published research into snakes will go a long way towards addressing this limitation.
For complex regions, locating all the subtleties of the underlying shape may be unnecessary,
or even undesirable. The aim is to speed up low level learning. As long as the solution is
reasonably accurate, speed up should be obtained. Being too sensitive to minor variations
in shape may severely limit the opportunities for transfer and thus reduce speed up overall.
A domain may dier in that changes in the environment are more complex than those
investigated in this paper. At present, the system detects that the goal has moved by
counting how often a reward is received at the old goal position. Not only is this a rather
ad hoc approach, but it also does not account for other possible changes, such as paths
becoming blocked or short-cuts becoming available. At present, when learning a new task
the system is restarted and is not required to determine that its present solution is no longer
applicable. In future work, the system should decide when its model of the world is no longer
correct. It should also decide what, if any, relationship there is to the existing task and
how it might be best exploited. This will allow a more complex interaction of the function
composition system with reinforcement learning. For instance, the learning of a new task for
97

Drummond

the robot navigation domain used the relatively simple situation of two rooms. The function
composition system initialized the low level algorithm once on detecting suitable features. In
the future, to address more complex tasks, with many more rooms, an incremental approach
will be used. When a new task is being learned, the system will progressively build up a
solution by function composition as dierent features become apparent.
This approach also should handle any errors the system might make with feature extraction. In the experiments with these simple room congurations, the ltering discussed
in Section 2.3 proved sucient to prevent problems. But in more complex tasks, it is likely
that false \doorways" will be detected, simply because the system has not explored that
region of the state space. A composed function including that extra doorway will drive the
system into that region. It should then become quickly apparent that the doorway does not
exist and a new function can be composed.

7. Related Work
The most strongly related work is that investigating macro actions in reinforcement learning. Precup, Sutton and Singh (1997, 1998) propose a possible semantics for macro actions
within the framework of normal reinforcement learning. Singh (1992) uses policies, learned
to solve low level problems, as primitives for reinforcement learning at a higher level. Mahadevan and Connell (1992) use reinforcement learning in behavior based robot control.
To learn a solution to a new task, all these systems require a denition for each subtask
and their interrelationships in solving the compound task. The work presented here gives
one way that macro actions can be extracted directly from the system's interaction with
its environment, without any such hand-crafted denitions. It also shows how to determine
the interrelationships of these macro actions needed to solve the new task. Thrun's research (1994) does identify macro actions, by nding commonalities in multiple tasks. But
unlike the research presented here, no mapping of such actions to new tasks is proposed.
Hauskrecht et al. (1998) discuss various methods of generating macro actions. Parr (1998)
develops algorithms to control the caching of policies that can be used in multiple tasks.
But in both cases, they need to be given a partitioning over the state space. It is the
automatic generation of just such a partition that has been the focus of much of the work
presented in this paper. It may well be that this approach to generating partitions and to
determining the interrelationships between partitions of related tasks will prove useful to
this other work.
Another group of closely connected work is the various forms of instance based or case
based learning that have been used in conjunction with reinforcement learning. They have
been used to address a number of issues: (1) the economical representation of the state
space, (2) prioritizing states for updating and (3) dealing with hidden state. The rst issue
is addressed by Peng (1995) and by Tadepalli and Ok (1996) who use learned instances
combined with linear regression over a set of neighboring points. Sheppard and Salzberg
(1997) also use learned instances, but they are carefully selected by a genetic algorithm. The
second issue is addressed by Moore and Atkeson (1993) who keep a queue of \interesting"
instances, predecessors of those states where learning produces a large change in values.
These are updated most frequently to improve the learning rate. The third issue is addressed
by McCallum (1995b) who uses trees which expand the state representation to include prior
98

Accelerating Reinforcement Learning

states, removing ambiguity due to hidden states. In further work, McCallum (1995a) uses
a single representation to address both the hidden state problem and the general problem
of representing a large state space by using a case base of state sequences associated with
various trajectories. Unlike this other research, in the work presented here the case is not
an example of the value function during learning. Instead, it is the result of a complete
learning episode, so the method should be complementary to these other approaches.
This work is also related to case based planning (Hammond, 1990; Veloso & Carbonell,
1993), rstly through the general connection of reinforcement learning and planning. But
it is analogous in other ways. When there is a small change to the world, such as the
goal being moved, a composite plan is modied by using sub-plans extracted from other
composite plans.
Last, but not least, is the connection with object recognition in vision research (Suetens
et al., 1992; Chin & Dyer, 1986). In the work presented here, many of the methods { if not
the nal application { has come from that eld. The features in the reinforcement learning
function are akin to edges in an image. These are located by nding the zero crossing point
of the Laplacian as introduced by Marr (1982). In the work presented here, it was proposed
that the features largely dictate the form of the function. Mallat and Zhong (1992) have
shown that a function can be accurately reconstructed from a record of its steep slopes.

8. Conclusions

This paper described a system that transfers the results of prior learning to signicantly
speed up reinforcement learning on related tasks. Vision processing techniques are utilized
to extract features from the learned function. The features are then used to index a case
base and control function composition to produce a close approximation to the solution of
a new task. The experiments demonstrated that function composition often produces more
than an order of magnitude increase in learning rate compared to a basic reinforcement
learning algorithm.

Acknowledgements
The author would like to thank Rob Holte for many useful discussions and help in preparing
this paper. This work was in part supported by scholarships from the Natural Sciences and
Engineering Research Council of Canada and the Ontario Government.

Appendix A. Spline Representations

This appendix presents some of the underlying mathematics associated with spline representations and the snake. It is not meant to be an introduction to the subject. Rather it
is added for completeness to discuss certain important aspects of the system not addressed
elsewhere in this paper. Knowledge of these aspects is not necessary to understand the basic
principles of the approach discussed in this paper, but would be necessary if one wanted
to duplicate the system. More detailed explanation is given in Drummond (1999). Some
specic papers that address these ideas in much greater detail are: for splines (Terzopoulos,
1986) and for snakes (Cohen & Cohen, 1993; Leymarie & Levine, 1993).
99

Drummond

Splines are piecewise polynomials where the degree of the polynomial determines the
continuity and smoothness of the function approximation. Additional smoothing constraints
can be introduced by penalty terms which reduce the size of various dierentials. One way
then to view spline tting is in the form of an energy functional such as Equation 6.

Espline(f^) =

Z

R





Efit (f^) + Esmooth (f^) ds

(6)

Here, there is an energy associated with the goodness of t, some measure of how close
the approximating function is to the input function. This is typically the least squares
distance between the functions. There is an energy associated with the smoothness of the
function. Two very commonly used smoothness controls produce the membrane and thin
plate splines by restricting the rst and second dierentials of the function respectively. To
t the spline to the function, the total energy must be minimized. A necessary condition
for this is an Euler-Lagrange dierential equation such as Equation 7. Here !t controls the
tension in the spline (the resistance to stretching) and !s the stiness (the resistance to
bending). Often the error function will be based on individual data points and the left hand
side of Equation 7 would include delta functions.
^

2^

@ (! (s) @ f (s) ) + @ (! (s) @ f (s) ) = f (s) , f^(s)
, @s
t
in
@s
@s2 s @s2

(7)

In this work, such splines have been used for a number of purposes. When tting the
snake, measures of the rst and second dierential are needed. A two dimensional quadratic
spline is tted to the discrete representation of the maximum Q-values. An !t of 0.2 is used
(!s is zero) to limit overshoot (Drummond, 1996) to prevent false edges. Values from an
identical spline except using an !t of 2.0 are squared and then divided into the dierential
values. This normalizes the dierentials, so that the size of edges is not dependent on where
they occur in the function. The same type of spline is used to produce the bowls associated
with the rooms as discussed in Section 3.2.1. Here !t is 1.0 and !s is 0.5 giving roughly
Gaussian smoothing. The values used to produce this function are weighted. Values close
to one are given weights of 200, lower values a weight of 1. This prevents the sides of the
bowls from collapsing under smoothing.
A one dimensional cubic spline is used in locating the doorways. These are found by
steepest descent on the value of the dierential along the body of the snake. This dierential
contains many local minima not associated with doorways. These arise either from the
inherent noise in the process or from errors of t in the snake. The aim is to remove the
ones not associated with doorways by smoothing and thresholding. This is achieved by
rst sampling the gradient at points along the snake. The values are then normalized to lie
between zero and one. The spline has an !t of 0.15 (!s of 0.0). Here a weighted least mean
squares t is used. The weighting function is the inverse square of the values, preventing
the spline from being overwhelmed by large values. Starting points for steepest descent are
changes in the sign of the coecients of the gradient of the spline. The initial step size
is set to slightly larger than a knot spacing and then decreased over time. When a local
minimum is found if the value exceeds a threshold (of 0.5), it is rejected.
To represent the snake, the model of the spline must be changed somewhat. The snake
itself is a one dimensional cubic spline. But the energy minimum that is being sought is
100

Accelerating Reinforcement Learning

in the dierential of the Qmax function, subject to other constraints. The dynamics of the
snake are dened by the Euler-Langrange equation shown in Equation 8.
2 f^!!
2 f^!
2 f^
^ @ @
@
f
@
@
@
@
 @t2 +  @t + @t @s2 !c(s) @s2 + @s2 !tp (s) @s2 = F (f^)

(8)

An !c of 512 minimizes changes to the snake's shape as it grows, by penalizing the
dierence in the second dierential to the previous time step scaled by the ratio of their
lengths. An !s of 8.0 is the initial stiness of the snake. This is reduced proportionately to
the snake's length to give the spline more degrees of freedom. A  of 96 and a  of 96 control
the momentum and the drag on the snake respectively. As in Cohen and Cohen (1993), a
factor is added to the energy associated with the dierential that is in the direction normal
to the body of the snake, as shown in Equation 9. But instead of it being a constant, a
variable is used to produce the mercury model discussed in Section 3.2.1.
2
F (f^) = M (f^),!
n (s) + r(, rQmax(f^) ),!
n (s)




(9)

The energy minimization process is carried out iteratively interleaving steps for the x
and y directions. The dierential of r jQmax j2 for the x direction is given by Equation 10,
a similar equation is used for the y direction.
2
2 Qmax
@Qmax )( @ 2 Qmax )
)
+
(
, @ jrQ@xmax j = ,2 ( @Q@xmax )( @ @x
2
@y
@x@y
"

#

(10)

The snake grows under the forces of the mercury model until it reaches an approximately
stable position, subject only to small oscillations. It is then converted into a polygon by
 where n = 0 : : : 3). The
nding the corners (where the normal passes through (2n+1)
4
coecient !1 is set to zero everywhere. The coecient !2 is set to zero at the corners and
15 between them. This produces a polygon which is exible at its vertices.
To detect the features as early as possible in the learning process, as discussed in Section
2.4, the height of the gradient is scaled according to the signal to noise ratio. The noise
arises from variations in the low level learning process and the stochastic nature of the task.
Both the size of the features and the noise grow with time and are somewhat normalized by
this scaling process. The idea is to collect uniformly sampled values of the function shown
in Equation 10 for both the x and y directions and nd the median of their absolute values.
The median is not strongly aected by extreme values and thus largely ignores the size of
the features, measuring only the noise of the regions in between.

References
Chin, C. H., & Dyer, C. R. (1986). Model-based recognition in robot vision. Computing
Surveys, 18 (1), 67{108.
Christiansen, A. D. (1992). Learning to predict in uncertain continuous tasks. In Proceedings
of the Ninth International Workshop on Machine Learning, pp. 72{81.
101

Drummond

Cohen, L. D., & Cohen, I. (1993). Finite element methods for active contour models and
balloons for 2-d and 3-d images. IEEE Transactions On Pattern Analysis And Machine
Intelligence, 15 (11), 1131{1147.
Dijkstra, E. W. (1959). A note on two problems in connexion with graphs. Numerische
Mathematik, 1, 269{271.
Drummond, C. (1996). Preventing overshoot of splines with application to reinforcement
learning. Computer science technical report TR-96-05, School of Information Technology and Engineering, University of Ottawa, Ottawa, Ontario, Canada.
Drummond, C. (1997). Using a case-base of surfaces to speed-up reinforcement learning.
In Proceedings of the Second International Conference on Case-Based Reasoning, Vol.
1266 of LNAI, pp. 435{444.
Drummond, C. (1998). Composing functions to speed up reinforcement learning in a changing world. In Proceedings of the Tenth European Conference on Machine Learning,
Vol. 1398 of LNAI, pp. 370{381.
Drummond, C. (1999). A Symbol's Role in Learning Low Level Control Functions. Ph.D.
thesis, School of Information Technology and Engineering, University of Ottawa, Ottawa, Ontario, Canada.
Galil, Z. (1986). Ecient algorithms for nding maximum matching in graphs. ACM
Computing Surveys, 18 (1), 23{38.
Gold, S., & Rangarajan, A. (1996). A graduated assignment algorithm for graph matching.
IEEE Transactions On Pattern Analysis And Machine Intelligence, 18 (4), 377{388.
Gordon, G. J. (1995). Stable function approximation in dynamic programming. In Proceedings of the Twelfth International Conference of Machine Learning, pp. 261{268.
Gordon, G. J., & Segre, A. M. (1996). Nonparametric statistical methods for experimental evaluations of speedup learning. In Proceedings of the Thirteenth International
Conference of Machine Learning, pp. 200{206.
Hammond, K. J. (1990). Case-based planning: A framework for planning from experience.
The Journal of Cognitive Science, 14 (3), 385{443.
Hauskrecht, M., Meuleau, N., Boutilier, C., Kaelbling, L. P., & Dean, T. (1998). Hierarchical
solution for Markov decision processes using macro-actions. In Proceedings of the
Fourteenth Conference on Uncertainty In Articial Intelligence, pp. 220{229.
Kass, M., Witkin, A., & Terzopoulus, D. (1987). Snakes: Active contour models. International Journal of Computer Vision, 1, 321{331.
Leroy, B., Herlin, I. L., & Cohen, L. D. (1996). Multi-resolution algorithms for active
contour models. In Proceedings of the Twelfth International Conference on Analysis
and Optimization of Systems, pp. 58{65.
102

Accelerating Reinforcement Learning

Leymarie, F., & Levine, M. D. (1993). Tracking deformable objects in the plane using
an active contour model. IEEE Transactions On Pattern Analysis And Machine
Intelligence, 15 (6), 617{634.
MacDonald, A. (1992). Graphs: Notes on symetries, imbeddings, decompositions. Tech.
rep. Electrical Engineering Department TR-92-10-AJM, Brunel University, Uxbridge,
Middlesex, United Kingdom.
Mahadevan, S., & Connell, J. (1992). Automatic programming of behavior-based robots
using reinforcement learning. Articial Intelligence, 55, 311{365.
Mallat, S., & Zhong, S. (1992). Characterization of signals from multiscale edges. IEEE
Transactions On Pattern Analysis And Machine Intelligence, 14 (7), 710{732.
Marr, D. (1982). Vision: a Computational Investigation into the Human Representation
and Processing of Visual Information. W.H. Freeman.
McCallum, R. A. (1995a). Instance-based state identication for reinforcement learning. In
Advances in Neural Information Processing Systems 7, pp. 377{384.
McCallum, R. A. (1995b). Instance-based utile distinctions for reinforcement learning with
hidden state. In Proceedings of the Twelfth International Conference on Machine
Learning, pp. 387{395.
Moore, A. W., & Atkeson, C. G. (1993). Prioritized sweeping: Reinforcement learning with
less data and less real time. Machine Learning, 13, 103{130.
Moore, A. W. (1992). Variable resolution dynamic programming: Eciently learning action
maps in multivariate real-valued state spaces. In Proceedings of the Ninth International
Workshop on Machine Learning.
Nason, G. (1995). Three-dimensional projection pursuit. Tech. rep., Department of Mathematics, University of Bristol, Bristol, United Kingdom.
Osborne, H., & Bridge, D. (1997). Similarity metrics: A formal unication of cardinal
and non-cardinal similarity measures. In Proceedings of the Second International
Conference on Case-Based Reasoning, Vol. 1266 of LNAI, pp. 235{244.
Parr, R. (1998). Flexible decomposition algorithms for weakly coupled Markov decision
problems. In Proceedings of the Fourteenth Conference on Uncertainty In Articial
Intelligence, pp. 422{430.
Peng, J. (1995). Ecient memory-based dynamic programming. In Proceedings of the
Twelfth International Conference of Machine Learning, pp. 438{439.
Precup, D., Sutton, R. S., & Singh, S. P. (1997). Planning with closed-loop macro actions.
In Working notes of the 1997 AAAI Fall Symposium on Model-directed Autonomous
Systems, pp. 70{76.
103

Drummond

Precup, D., Sutton, R. S., & Singh, S. P. (1998). Theoretical results on reinforcement
learning with temporally abstract options. In Proceedings of the Tenth European
Conference on Machine Learning, Vol. 1398 of LNAI, pp. 382{393.
Schnabel, J. A. (1997). Multi-Scale Active Shape Description in Medical Imaging. Ph.D.
thesis, University of London, London, United Kingdom.
Sheppard, J. W., & Salzberg, S. L. (1997). A teaching strategy for memory-based control.
Articial Intelligence Review: Special Issue on Lazy Learning, 11, 343{370.
Singh, S. P., & Sutton, R. S. (1996). Reinforcement learning with replacing eligibility traces.
Machine Learning, 22, 123{158.
Singh, S. P. (1992). Reinforcement learning with a hierarchy of abstract models. In Proceedings of the Tenth National Conference on Articial Intelligence, pp. 202{207.
Suetens, P., Fua, P., & Hanson, A. (1992). Computational strategies for object recognition.
Computing Surveys, 24 (1), 5{61.
Sutton, R. S. (1990). Integrated architectures for learning, planning, and reacting based
on approximating dynamic programming. In Proceedings of the Seventh International
Conference on Machine Learning, pp. 216{224.
Sutton, R. S. (1996). Generalization in reinforcement learning: Successful examples using
sparse coarse coding. In Advances in Neural Information Processing Systems 8, pp.
1038{1044.
Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: An Introduction. MIT Press.
Tadepalli, P., & Ok, D. (1996). Scaling up average reward reinforcement learning by approximating the domain models and the value function. In Proceedings of the Thirteenth
International Conference of Machine Learning, pp. 471{479.
Tanimoto, S. L. (1990). The Elements of Artcial Intelligence. W.H. Freeman.
Terzopoulos, D. (1986). Regularization of inverse visual problems involving discontinuities.
IEEE Transactions On Pattern Analysis And Machine Intelligence, 8 (4), 413{423.
Thrun, S., & Schwartz, A. (1994). Finding structure in reinforcement learning. In Advances
in Neural Information Processing Systems 7, pp. 385{392.
Veloso, M. M., & Carbonell, J. G. (1993). Derivational analogy in prodigy: Automating
case acquisition, storage and utilization. Machine Learning, 10 (3), 249{278.
Watkins, C. J., & Dayan, P. (1992). Technical note: Q-learning. Machine Learning, 8 (3-4),
279{292.

104

