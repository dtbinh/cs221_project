Journal of Artificial Intelligence Research 10 (1999) 399-434

Submitted 10/98; published 6/99

Extensible Knowledge Representation: the Case of
Description Reasoners
Alex Borgida

borgida@cs.rutgers.edu

Dept. of Computer Science
Rutgers University
New Brunswick, NJ 08904 USA

Abstract
This paper offers an approach to extensible knowledge representation and reasoning for
the Description Logic family of formalisms. The approach is based on the notion of adding
new concept constructors, and includes a heuristic methodology for specifying the desired
extensions, as well as a modularized software architecture that supports implementing
extensions. The architecture detailed here falls in the normalize-compared paradigm, and
supports both intentional reasoning (subsumption) involving concepts, and extensional
reasoning involving individuals after incremental updates to the knowledge base.
The resulting approach can be used to extend the reasoner with specialized notions
that are motivated by specific problems or application areas, such as reasoning about
dates, plans, etc. In addition, it provides an opportunity to implement constructors that
are not currently yet sufficiently well understood theoretically, but are needed in practice.
Also, for constructors that are provably hard to reason with (e.g., ones whose presence
would lead to undecidability), it allows the implementation of incomplete reasoners where
the incompleteness is tailored to be acceptable for the application at hand.

1. Introduction and Motivation
Description Logics (DLs) are a family of object-centered formalisms for representing knowledge about and reasoning with individuals grouped into classes (here called concepts) and
related by binary relations (here called roles). Descriptions usually have a term-like notation that uses concept constructors and identifiers to build definitions of more complex
concepts from simpler ones. For example, the description in Figure 1 is supposed to capture
the noun phrase “A collection of objects that are books and that are written by two or more
authors, who are all Venusians”.
and(
BOOK
at-least(2,authoredBy)
all(authoredBy, VENUSIAN) )
Figure 1: An example description.
This is accomplished by using the concept constructor and to conjoin terms that represent
component notions:
c
1999
AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

Borgida

BOOK: objects that are books — a concept declared elsewhere, probably as a primitive;
at-least(2,authoredBy): objects that are related to at least 2 other objects by the authoredBy role; the concept constructor is at-least here;
all(authoredBy, VENUSIAN): objects that are related by the authoredBy role only to objects that are in the concept VENUSIAN; the concept constructor here is all.
The concept VENUSIAN might itself be defined as a being whose address includes the planet
value Venus: and(BEING, all(address, fills(planet, Venus))). (Note that descriptions
can be nested.) A more precise introduction to DLs is presented in Section 2.
Description logics reason both about intensional notions such as concepts, and about
extensional aspects having to do with individuals that can be ascribed descriptions and
participate in specific relationships. DLs have found a variety of applications in areas
such as data management (Borgida, 1995), software engineering (Devanbu & Jones, 1997),
configuration management (Wright et al., 1993), as well as general AI.
A particular description language is characterized, among others, by the choice of term
constructors in it, and the significant features of DLs are clear, precise semantics and terminating reasoning algorithms for tasks such as determining whether a concept is coherent,
or whether it is more general than another one.
A common difficulty faced both by designers and users of knowledge-base management
systems (KBMSs) based on DLs (or any other logic, for that matter) is that many applications need to keep information about specialized kinds of data, including strings, dates,
pictures, sequences of values of various kinds, etc., and it is practically impossible to anticipate all of these as part of language design.
A related problem is that if reasoning is to be complete and efficient, or even decidable,
then what can be expressed in the language must be limited. For example, if in Figure 1 we
also wanted to say that the authors speak the language in which the book is written, there
is a concept constructor already discussed in the literature, called subset-of, with which
one could express such a constraint as subset-of( [writtenIn] [authoredBy,speaks] ).
Unfortunately, reasoning in a language that supports constructors and, all and subset-of is
known to be undecidable (Schmidt-Schauss, 1989). This means that the selection of concept
constructors in the language is a matter of very careful consideration for the system designer,
who is faced with several choices: (a) Select a particular subset of constructors for which
a sound and complete reasoning algorithm is known; if the language is sufficiently limited,
this procedure is guaranteed to be “fast” (e.g., in polynomial time); otherwise, its worst case
complexity is non-polynomial, though in practice the algorithm may behave well. Living
with “limited languages” is however not always easy (Doyle & Patil, 1991). (b) Choose
a larger set of constructors (possibly one which is even undecidable), and implement an
incomplete reasoner; this however requires having to explain to the user which inferences will
or will not be made. Both alternatives have different shortcomings, but, from our viewpoint,
a significant common problem is that in all cases it is the designer of the DL system who
makes these decisions ahead of time, leaving the user to sort out the consequences later on.
We propose to attack the above problems by starting with a relatively small, kernel
language and system, and then providing facilities to extend it by adding new concept constructors. Such extensions are not to be undertaken lightly, since they provide opportunities
400

Extensible DL Representation and Reasoning

for errors. Some of the extensions will be standard DL constructors for which complete reasoning can be implemented. Such extensions could be readily available in a library1 . Other
extensions will involve standard DL constructors which are known to be hard to reason
with, and for which only an incomplete reasoning algorithm is provided, because, for example, the problem is undecidable or because the only algorithms currently known involve
combinatorial search. In this second case, consultation with the user may help determine
which inferences the implementation should make. For example, in classic, for the sake
of a clearer semantics the system designers chose to draw no inferences about an individual
based on its presence in a concept (Borgida & Patel-Schneider, 1994), although some of
these inferences are not hard to implement. Finally, new concept constructors can be added
for notions that are either domain specific (e,g,. plans, time), or which are of great practical utility but whose interaction with the full spectrum of DL constructors is not yet fully
understood theoretically; such notions include keys/unique identifiers (Borgida & Weddell,
1997) and part-whole relationships (Padgham & Lambrix, 1994).
To support this, we develop a well-modularized architecture for DL-KBMSs that are
implemented using the “normalize-compare” approach (see Section 2.4); this architecture
expects a set of procedures to be filled in for each new concept constructor extending the
original language. In addition, we propose methodological heuristics for specifying what
these procedures need to do. Note that our goal is to obtain close to the same efficiency as
would have been offered by a custom-built DL reasoner.
Of course, the approach presented here is not a panacea for knowledge representation
and reasoning. First of all, to the extent that normalize-compare algorithms are unable to
reason in a complete manner with DL constructors involving incomplete knowledge such as
disjunction, the present system is also likely to suffer the same deficiencies. Second, the
present work has not yet addressed DL notions such as role constructors, recursive concepts,
and general constraints (to be described later). Finally, there are many other notions in
knowledge representation, such as the full spectrum of epistemic and other non-monotonic
reasoning, abduction, case-based reasoning, etc., which are likely to require a thorough
overhaul of the entire reasoning architecture, and hence are likely not to be accommodated
properly by the present approach.
The outline of the rest of the paper is as follows: Section 2 provides an introduction to
DLs, their syntax and semantic description, and the services provided by KBMSs concerning
reasoning with concepts, especially the “subsumption” relationship. Section 3 introduces
the architecture of the proposed protodl approach to DL reasoning, provides an overview
of the methodology for extending it, and illustrates it with constructors involving dates; it
terminates by discussing successes and limitations of the proposed protodl approach to
extension, an its relationship to one particular other approach that is directly relevant.
In Sections 4 and 5 we repeat the above process, but considering this time reasoning
about individuals, and focusing on how to support efficiently incremental updates to the
knowledge base.
We conclude by discussing relevant related work and summarizing the contributions and
limitations of the protodl approach.
1. It is important to clarify from the beginning that the addition of constructors is often not a simple
incremental process: some constructors may behave well independently, but cause problems when brought
into the same language.

401

Borgida

2. Description Logics: An Introduction
DLs are used to describe situations using various kinds of individuals, related by roles, and
grouped into concepts. Roles that are restricted to be (partial) functions are distinguished,
and are called attributes.
In this section we present the syntax and semantics of DLs, as well as outlining the
interaction with a typical DL-based KBMS, and some implementation strategies.
2.1 Syntax and Semantics
As illustrated in Figure 1, DLs provide a compositional and structured language for
talking about these kinds of things. Composite concepts are obtained according to the
syntax presented in Table 1, which includes the concept constructors mentioned in this
paper. The meta-symbols have the following referents: CN is a concept name, p is an
atomic role (including an attribute), f is an attribute, C and D are general concepts, b is
an individual, while n is an integer; subscripts may occasionally be added to the above.
RoleChain ::= [p1, . . . , pn]
AttributeChain ::= [f1 , . . . , fn ]
C ::= thing | nothing | CN
| and( C1 , . . . , Cn ) | at-least(n,p) | at-most(n,p)
| all(p,C) | some(p,C) | fills(p,b) | one-of(b1 , . . . bn )
| same-as(AttributeChain1 , AttributeChain2 )
| subset-of(RoleChain1 , RoleChain2 )
Table 1: Syntax of Concept Constructors Used.
To give meaning to the above syntactic terms, one can give descriptions a denotational
semantics using an interpretation I=(∆I ,·I ). I starts by assigning to each concept name
a subset of the domain ∆I , to each role a subset of ∆I × ∆I , to each attribute an element
of ∆I × ∆I restricted to be functional, and to each individual some element of ∆I . The
interpretation is then extended to composite terms as follows. First, role chains (resp.
attribute chains) are interpreted as mappings resulting from relation composition:
I

[p1, · · · , pn] = {x 7→ Sx | Sx = {y | ∃z1 , ..., zn+1. z1 = x ∧ zn+1 = y ∧

n
^

(zi , zi+1 ) ∈ pIi }}

i=1

Table 2 then presents the interpretation of complex terms using the interpretation of their
components.
Alternatively, by noting that concepts are like unary predicates, and roles are like binary
predicates, we can offer translation schemes from descriptions to Predicate Calculus. For
example, and(AMERICAN,OLD) corresponds to the formula AMERICAN(γ)∧OLD(γ), where γ is
a free variable, while all(authoredBy,VENUSIAN) corresponds to ∀y.authoredBy(γ, y) ⇒
VENUSIAN(y).
The connection between these two kinds of specifications is that interpretations can be
applied to both predicate calculus formulas as well as concepts (Baader, 1996; Borgida,
402

Extensible DL Representation and Reasoning

TERM
thing
nothing
and( C1 , . . ., Cn )
at-least(n, p)
at-most(n, p)
all(p, C)
some(p, C)
fills(p, b)
one-of(b1 ,...,bm)
same-as(F C1 , F C2)
subset-of(RC1 , RC2)

INTERPRETATION
∆I
∅
C1I ∩ . . . ∩ CnI
{ d ∈ ∆I | |pI (d)| ≥ n }
{ d ∈ ∆I | |pI (d)| ≤ n }
{ d ∈ ∆I | pI (d) ⊆ C I }
{ d ∈ ∆I | pI (d) ∩ C I 6= ∅ }
{ d ∈ ∆I | bI ∈ pI (d) }
{ bI1 , . . . , bIm }
{ d ∈ ∆I | F C1I (d) = F C2I (d) ∧ F C1I (d) 6= ∅ }
{ d ∈ ∆I | RC1I (d) ⊆ RC2I (d) }

Table 2: Interpretation of DL Constructors.
1996): given a description C, with corresponding logical formula ΨC (γ), and an interpretation I, the denotation C I is identical to the set of values d ∈ ∆I for which ΨC (γ)I is true,
when I is extended to map γ to d.
Finally, we remark that many DLs also allow role constructors; for example, isAuthorOf
can be defined as the converse of the authoredBy relation, by writing inverse(authoredBy).
In this paper we do not consider role constructors (hence equating roles with role names).
2.2 Subsumption Reasoning with Concepts
The real significance of DLs is that one can reason about descriptions. Traditionally, the
standard question one asks is whether one description is more general than (subsumes)
another. For example, we would expect that the description in Figure 1 subsumes the
following description, which requires in addition that the books be published in at most the
four countries enumerated, and that there be at least three (rather than two) authors, who
are to be married to earthlings:
and(
BOOK
all(publishedIn, one-of(Usa,France,Germany,Italy))
at-least(3,authoredBy)
all(authoredBy, and( VENUSIAN,
all(marriedTo, TERRESTRIAL)))
)
Formally, subsumption between concepts C and D, written as C =⇒ D, holds iff C I ⊆ DI
for all interpretations I. In addition, we say that a description C is incoherent iff its
denotation C I is the empty set in all interpretations I. Note that this is the case iff
C =⇒ nothing.
The semantics of concept constructors, and especially the deductions performed by a
particular system can also be specified using proof theory. A proof-theoretic specification in
403

Borgida

the “natural semantics” style (Borgida, 1992a), would indicate, among others, that greater
bounds on the number of role fillers for role p lead to more specialized concepts:
m≥n
at-least(m, p) =⇒ at-least(n, p)

This rule can be paraphrased as “IF one can prove m ≥ n THEN one can write as the next
line of a proof that at-least(m, p) =⇒ at-least(n, p).” Such a rule allows us to prove that
at-least(2,authoredBy) =⇒ at-least(1,authoredBy).
As usual, it is possible (and desirable) to demonstrate that the rules of inference are
sound and complete with respect to the denotational semantics. Rules of inference are useful
in characterizing reasoners that are incomplete with respect to the standard denotational
semantics, by describing either the inferences performed, or the ones missing. Also, as
we shall argue below, rules of inference can form a good starting point for developing
implementations.
2.3 DL Concept KBMS
A concept knowledge base CKB (also known as a T-box) records constraints on concept
names, including definitions (such as the concept VENUSIAN mentioned in our examples) and
necessary conditions for primitive concepts (e.g., a BOOK would be required to have at least
one author). In some DLs it is possible to state general subsumption constraints between
arbitrary descriptions, but this will not be permitted in this paper.
Formally, CKB is a tuple (R, F , C, O, N , D) where R, F , C, O are respectively the sets
of role, attribute, concept and individual object identifiers declared. Concept names are
either primitive/atomic concept names, P N , which have associated a necessary condition
˙ C in the set N of necessary conditions; or defined concept names, DN , which have
PN ≤
.
associated a definition DN = C in the set D of definitions. An interpretation I is a model
.
˙ C iff P N I ⊆ C I , and is a model of DN =
of P N ≤
C iff DN I = C I . An interpretation is
a model of CKB if it is a model of all conditions in N and D.
C is said to subsume D in the presence of a knowledge base CKB (written CKB
|= C =⇒ D), iff C I ⊆ DI for all models I of CKB.
In this paper we are restricting ourselves to non-recursive knowledge bases, where definitions and necessary conditions are given at the same time as the name is declared, and
they can only involve previously declared identifiers.
A DL-based knowledge base management system supports certain update operations,
which affect the CKB (R, F , C, O, N , D) as follows:
Operation
declare-primitive-role(p)
declare-primitive-attribute(f )
declare-individual(b)
declare-primitive-concept(P N ,D)
declare-defined-concept(CN ,D)

Effect
p is added to R
f is added to F
b is added to O
˙ D to N
P N is added to C, and P N ≤
.
CN is added to C, and CN = D to D

In return, we expect the KBMS to respond to inquiries, which include retrieving the declarations entered and at least the following operations:
404

Extensible DL Representation and Reasoning

Question
ask-subsumes?(C, D)
ask-ancestors(C)
ask-is-incoherent?(C)

Answer type
Boolean
SET(ConceptName)
Boolean

Response
true iff CKB |= C =⇒ D
{CN ∈C | CKB |= C =⇒ CN }
true iff CKB |= C =⇒ nothing

A number of other operations on concepts have been found to be useful, including
(i) computing the least common subsumer of two concepts (Cohen, Borgida, & Hirsh,
1992) (useful for machine learning), (ii) matching concepts against patterns (Borgida &
McGuinness, 1996) (useful in large KBs for viewing only relevant aspects of concepts), (iii)
finding what additional information has been deduced about a concept or especially an
individual given the information in the KB (see Section 4.2).
To facilitate answering the above questions, and others like them, the DL-KBMS almost
always performs concept classification: named concepts (“classes”) are organized into the
so-called IsA hierarchy, finding for each class the most specific other classes that subsume
it. The classification algorithm relies on the =⇒ relationships, treating it as a subroutine,
and as such is largely DL-independent. Interesting previous work in this area has been
reported by Baader et al (Baader et al., 1994).
The KBMS is also charged with a number of clerical tasks, including keeping a symbol
table of the declarations, maintaining and accessing efficiently the precomputed IsA hierarchy, signaling definitions/declarations that are redundant (i.e., a concept which is equivalent
to a previously defined one) or are incoherent.
DL-KBMS perform inferences on individuals, as well as concepts. The operations involved will be described in Section 5.
2.4 Reasoning Strategies
There are two general approaches to answering the fundamental subsumption question
underlying the DL-KBMS operations.
One approach is based on theorem proving techniques specially adapted for descriptions,
particularly variants of tableau techniques that determine the subsumption A =⇒ B by
checking for the unsatisfiability of A∧¬B; systems such as kris (Baader et al., 1994),crack
(Bresciani, Franconi, & Tessaris, 1995), FaCT (Horrocks, 1998) and DLP (Patel-Schneider,
1998) follow this approach. Such systems have the advantage of being provably complete.
Although the worst-case complexity bounds of the subsumption problems are sometimes
quite high (EXPTIME complete), recent empirical evidence shows that their performance
for computing subsumption on large realistic KBs is quite effective (Horrocks & PatelSchneider, 1998).
All the implemented DL KBMS systems that have had wide distribution and use, such
as back (von Luck et al., 1987), classic (Borgida et al., 1989), and loom (MacGregor, 1986), follow a so-called “normalize-compare” paradigm, where most of the reasoning
work is performed in an initial “normalization” phase, whose goal is to find a normal
form for concepts which explicates implicit facts, eliminates redundancies and detects incoherencies. Once this is done, when, for example, it comes to comparing two concepts for
subsumption, it is often (but not always) a matter of comparing only “structurally similar” elements – ones built with the same constructor. For example, since the descriptions
405

Borgida

all(pet,nothing) and at-most(0,pet) are equivalent (subsume each other), in a normal form both would appear, so that subsumption comparison with all(pet,DOG) would
only require looking at all(pet,nothing), while comparison with at-most(3,pet) would
locate at-most(0,pet).
The present work was carried out over a period of several years within this “normalizecompare” paradigm. The original reasons for this choice included the following features,
which were only available for this paradigm: having a sizable user base; supporting additional KBMS operations, such as least common subsumer, pattern matching, explanation;
reasoning with large knowledge bases of individuals, and especially doing so incrementally
in an environment where one needs the “logical completion” of an individual.
We remark that the tableau technology has recently become competitive on sizable
knowledge bases of concepts. The promise of provably complete and effective reasoners for
expressive languages is very enticing, and therefore the study of extensibility in tableaux
approaches (Baader & Hanschke, 1991; Bresciani et al., 1995) is of great interest.

3. Concept Reasoning in protodl
Our approach to extensible KBMSs is based on the idea that in a case when the current
KBMS does not meet the users’ representation and reasoning needs, one can extend it
by adding one or more new description constructors – what would be considered logical
connectives.
Although this approach is clearly restrictive, it has the advantage of being very specific
and directed; it allows us to develop an implementation architecture and accompanying
methodology to support the process of extension. The approach is also supported by empirical evidence from the use of the classic system in many applications: the test-defined
concepts of classic have been crucial in escaping the expressive limitations of the basic
language, and each such test function acts essentially as a new concept constructor2.
3.1 The Modularized Implementation Architecture
As previously described, the concept reasoning services of our DL-KBMS are delivered by
operations which rely on the =⇒ relationship, to be computed by the function Subsumes?.
In our implementation paradigm, this function takes as arguments two normalized concepts.
Hence we need some way to take input and convert it into normalized concepts. This means
parsing the concept (function Parse) and normalizing it (function Normalize).
Because of the uniform prefix nature of DL syntax, parsing is easily performed by recursive descent with a single token look-ahead; so we associate with every concept constructor
Q, a function Q::Parse.
After examining earlier implementations and applications, a key decision underlying the
protodl implementation is that a normalized concept is viewed as the conjunction of a
collection of component concepts, which are either concept identifiers or are normalized
terms built with concept constructors Q other than and. Therefore, it is possible to view
a normalized concept as a data abstraction that encapsulates the way in which the various
2. Note however that reasoning with test-concepts in classic was minimal: no subsumption reasoning
other than identity checking was performed, and individual reasoning was limited to recognition.

406

Extensible DL Representation and Reasoning

components are stored and accessed thru a set of functions put Q(value) and get Q() —
one for each concept constructor Q. For example, the put one-of operation stores a set of
individuals S, while get one-of returns this set3. On the other hand, for the constructor
fills, the (normalized) value stored is a set of terms of type <Role × SET(Individual)>,
since for each role, we need to store the set of current fillers. For constructors such as
fills, which are associated with a single role, we overload the put and get functions so
they accept a separate role argument, allowing us to access each value independently (e.g.,
get fills(p:<Role>) returns <SET(Individual)>). In fact, for such constructors it is
more efficient to group them by the role identifier, but to simplify the exposition we shall
not pursue this distinction in the rest of this section.
As mentioned earlier, the ideal normalized concept would have the property that subsumption could be determined by comparing, using Q::Subsumes?, only components built
with the same constructor. In other words, Subsumes? would have the pseudo-code
Subsumes?(hiNC, lowNC: <NormalizedConcept>) returns <Bool>
;; structural subsumption
{For every Q(T) in getComponents(hiNC) do
{ lowComponent := get Q(lowNC);
if not Q::Subsumes?(T,lowComponent)
return false; }
return true; }
As we shall see in Section 3.3, this is too restrictive however, so we will pass as parameter
the entire normalized lower concept, lowNC, rather than just the lowComponent. Therefore,
for every constructor Q we expect a function
Q::Subsumes?(<NormalizedQ-term>,<NormalizedConcept>) .

In order to normalize a concept, we will normalize each component separately, and then
combine them. Since a normalized concept represents a conjunction, the combinator function will be named Conjoin. Here are then the remaining functions that are provided ahead
of time by the core implementation:
Normalize(pC : <ParsedConcept> )

returns <NormalizedConcept>
throws IncoherentExn;
/* Start ND to be a data structure having no constraints – i.e.like thing */
ND := copy of NormalFormthing;
{ /* Normalize each component and conjoin it onto ND */
For every Q(T) in pC do {
T norm := Q::Normalize(T);
Q::Conjoin(T norm,ND); }
/* Replace concept ids by normalized form (saved by declare ) */
For every concept identifier N in pC do {
N norm := look up normalized form of N;
Conjoin(N norm,ND); }

3. The type of a parameter will be indicated by enclosing it in angle-brackets. Thus, we would have referred
to put one-of(s: <SET(Individual)>).

407

Borgida

/* if any Normalize or Conjoin detects an incoherence, propagate it up,
since the whole conjunct is incoherent. */
}
catch IncoherentExn { throw IncoherentExn }
return ND;

Conjoin(fromNC, ontoNC: <NormalizedConcept>) throws IncoherentExn
/* Take each component of fromNC and conjoin it to ontoNC;
modifies ontoNC. */
{For every Q(T) in getComponents(fromNC) do
{Q::Conjoin( T, ontoNC)
} catch IncoherentExn {throw IncoherentExn }
}
Therefore, for every constructor Q, we also expect corresponding functions Q::Normalize
and Q::Conjoin . Note that the software architecture treats incoherent concepts (ones
equivalent to nothing) in a special manner: whenever they are encountered, a special exception IncoherentExn is raised. Conjunction propagates these exceptions, but other constructors may trap them and handle them in their own way. For example, all::Normalize
accepts the restriction being incoherent, but must ensure that at-most(0) is also added to
the normalized concept for the same role.
In retrospect, the above three functions (Subsumes?, Normalize and Conjoin) really
represent the semantics of the constructor and (and hence can be appropriately called
and::Subsumes?, etc.) as well as the expansion of necessary conditions/definitions for
named concepts (“inheritance”), and parts of the meaning of the built-in concepts nothing and thing. To make this more complete, we can add to the beginning of the Subsumes?
function the statement: if equal(hiNC,NormalFormthing) or equal(lowNC,NormalForm nothing) then return true;
In this sense, protodl starts from a minimal, core language specified by the syntax
C ::= thing | nothing | CN | (and C1 , . . . , Cn )
This is not to say that everyone must start from this minimalist language, which is hardly
useful. But it will have the advantage that all constructors (even the most useful ones,
like all, at-least, etc.) will be implemented as extensions, according to the same uniform
paradigm as the more esoteric extensions. This will be essential if we are to be able to
easily modify the implementation of standard constructors (like all) when called upon to
implement non-standard ones (like dates), which may interact with them.
3.2 An Overview of the Process of Extension.
Suppose we want to extend the system at some particular stage with a new concept constructor. The following is a suggested methodology for accomplishing this, illustrated with
a familiar concept constructor, all.
408

Extensible DL Representation and Reasoning

(1) Determine a syntax for the extension. If concepts will have a LISP-like syntax (as in
classic and loom), the constructor all might be given the syntax (:all Role Concept).
The terms following the constructor are called its arguments, and a version of them will
eventually be stored in the internal representation of our normalized concepts. One can
now implement the function all::Parse, which in this case would invoke Role::parse and
Concept::parse.
(2) Determine a semantics for the new concept constructor.
First, this requires settling on a domain of values from which its denotation will come. This
might be the set of ordinary objects with unique intrinsic identity — instances of a special
class any-object, which is a built-in direct subclass of thing. The denotation might also
be some new kind of value (e.g., triples for dates, or lists of objects), in which case it is
necessary to introduce (possibly as a new concept constructor, which takes no argument) a
top class for these kinds of values (e.g., any-date for dates).
It is now time to clarify the intended meaning of the new constructors. One alternative,
not explored here, is to express the semantics using First Order Predicate Calculus. Another
is to assign a denotation of values to concepts built with the new constructor. For all, this
is just the usual interpretation
all(p, C)I = { d ∈ ∆I | pI (d) ⊆ C I }
Rather than move on to implementation right away, our experience indicates that it is
easier to first describe the deductions to be performed in a more concise manner: through
rules of inference. Based on empirical evidence, we see these rules of inference as being
naturally grouped into several categories4
• Rules dealing with just one constructor, Q.
– Normalizing the arguments of Q, if these are themselves composite objects.
C ≡ D
all(p, C) ≡ all(p, D)

– Reasoning only with concepts of the form Q(args).
∗ When is such a concept incoherent by itself?
all(p, C) is never incoherent.
∗ When is such a concept equivalent to the entire domain of values?
all(p, thing) ≡ any-object
∗ When does Q(arg1) subsume Q(arg2) in terms of arg1 and arg2? (The socalled structural subsumption relationship.)
C =⇒ D
all(p, C) =⇒ all(p, D)
4. In each case, we give a general description of what is desired for a new constructor Q, and then illustrate
it with the specific constructor all.

409

Borgida

∗ When does Q(arg) entail some description built with some other constructor?
all(p, nothing) ≡ at-most(0, p)
– Reasoning with conjunctions of descriptions built with Q only. This usually
results in a normal-form that either combines the arguments into a single one,
or keeps the arguments as a list, set or multi-set.
and(all(p, C), all(p, D)) ≡ all(p, and(C, D))
• Rules of inference dealing with combinations of several concept constructors. These
rules can be grouped into similar families as above, except that they will involve two
or more kinds of constructors.
Since there is no such rule involving all, we offer an alternative example:
and(at-most(n, p), at-least(m, p)) ≡ nothing if n<m
The augmented set of inference rules should be proven sound and complete with respect
to the semantics specified earlier. As with any logic, soundness is relatively easy to show, but
completeness is much harder. Royer and Quantz propose one approach (Royer & Quantz,
1992) for generating inference rules that are complete, based on translation to First Order
Logic, but the technique is not easy to apply.
(3) Extend the implementation. This requires first determining an appropriate normal
form for the argument of constructor Q, declaring a data structure to hold the information,
and completing the put Q and get Q procedures to access them from a normalized concept.
For simplicity, we will not address detailed data structure issues here; instead, we use a
simple notation based on terms in the style of Prolog to represent data structures. In the
case of all, the representation is just a pair all(<Role>,<NormalizedConcept>). We
note that if we wanted to keep track of the original form of the concept (so it can be printed
out to users as entered), this could be added as an extra field of the data structure. We
emphasize that the normalized form of the description (e.g., a finite automaton) might not
even resemble the original syntax (e.g., a regular expression), though in our examples this
will not be the case.
Next, we need to implement the three procedures: Q::Normalize,Q::Conjoin, and
Q::Subsumes?, whose invocation is orchestrated by the corresponding functions for the
and constructor.
By analyzing the normalization algorithms for numerous constructors, we have arrived at
a more refined understanding of the prototypical Q::Conjoin procedure. This is presented
in the Appendix A as Figure 3, and uses the following other, smaller functions
Q::Universal? , Q::Incoherent? , Q::SubsumesSame? , Q::ConjoinToSame ,
Q::IncoherentWDifferent? , Q::SubsumesDifferent? , Q::ConjoinToDifferent ,
Q::FindOtherImplications .
These functions correspond to the categories of inference rules we have mentioned above.
When this decomposition can be applied, it provides two advantages: improved chances of
correct implementation by making smaller, specialized modules; and independent reuse, as
in
410

Extensible DL Representation and Reasoning

Q::Subsumes?(T:<NormalizedQ-Term>, lower:<NormalizedConcept>)

returns <Bool>
{if not Q::SubsumesSame?(T,get Q(lower)) then return false;
if not Q::SubsumesDifferent?(T,lower) then return false;
return true; }
Of course, if a specific constructor does not need to implement some of these subprocedures, the corresponding lines from the generic implementations are omitted, in order
to avoid the cost of useless function invocations.
For our simple example, when Q=all, all::Normalize(all(role,vr)) returns
all(role, and::Normalize(vr)).
If the only other constructor is at-most, the following functions used by all:Conjoin
and all::Subsumes? are needed:
• Q::Universal?(T): Is T equivalent to the top of the hierarchy for that set of values?
all::Universal?(all(role,vr)) returns true when vr is NormalFormthing.
• Q::SubsumesSame?(T,OldTs): Is T implied by the Q-constructed terms already seen
in oldTs? This is basically the “structural subsumption” algorithm.
all::SubsumesSame?(all(role,vr1),all(role,vr2)) would return true iff
and::Subsumes?(vr1,vr2) returns true.
• Q::ConjoinToSame(T,OldTs): Merge T with any preceding terms built with Q.
all::ConjoinToSame(all(role,vr1),all(role,vr2)) returns
all(role,and::Conjoin(vr1,vr2)).
• Q::FindOtherImplications(T,This,ImplicationsToDoList): If any additional
constructors have to be added because of Q, put them onto the ImplicationsToDoList.
all::FindOtherImplications adds to ImplicationsToDoList the description
at-most(0,role) if its first argument is all(role,nothing).
Once the Conjoin, Normalize and Subsumes? functions are implemented for the new
constructor Q, the corresponding functions for and need to have lines added to invoke
them according to the pattern presented in the preceding section (unless the programming
language is highly polymorphic).
Next, we use reasoning about dates, an extension desired in some classic applications,
to give a more complex example of the methodology for building extensions of protodl.
3.3 Dates: An Example Concept-Level Extension
We imagine an application where there will be individual dates as values of attributes or
even roles, and that concepts will describe collections of dates, specified in various ways
(e.g., as ranges or periods).
To begin with, it is important to clarify what the individuals look like about which
information will be kept. In the case of dates, we know that we wish to treat them as
temporal points, which have associated information about the year, month and day when
that date occurs. Given a date d, the above components will be referred to as year(d),
411

Borgida

month(d), day(d). There are two different ways of thinking of a date: as an abstract
mathematical value (e.g., a triple of integers) or as an individual object with attributes for
year, month, day. The last approach has the disadvantage that we need to develop a
separate theory of identity for dates (two dates are supposed to be identical if they have
the same components), although it has the advantage of allowing incomplete information
about the exact occurrence of a time point. Since this feature is not desired, we will adopt
the first approach, for convenience writing date individuals as 1996/7/25. In addition, we
will have the usual total (reflexive) order  on dates, as well as two special date constants,
BeginTime and EndTime, such that BeginTime  d  EndTime for all dates d.
We are now ready to introduce concept-forming operators for dates which are useful for
our application. First, when introducing a new kind of value, it is useful to define a top
concept, which will contain all such values. In our case, let us call it any-date.
One obvious grouping of dates is by ranges: “between June 1st and August 31, 1996”.
We might thus propose a concept constructor dateRange, which takes as argument a pair of
dates, denoting the ends of the range, e.g., dateRange(1996/6/1,1996/8/31). But since
the base language does not support disjunction, and we want to allow descriptions such as
“the summers of 1995 and 1996”, we will in fact have dateRange take as argument a set
of date pairs, as in dateRange({(1995/6/1,1995/8/31) , (1996/6/1,1996/8/31)}).
Having established the syntax of the concept constructors, and then implemented dateRange::Parse, we present its denotational semantics:
dateRange(SD)I = { d | ∃b, e.(b, e) ∈ SD such that b  d  e }
Next, we look for inference rules describing the desired reasoning for dateRange. Following the heuristics in Section 3.2, we come up with Table 3.
To implement the inferences for dateRange, we must find a normal form and write functions dateRange::Normalize, dateRange::Conjoin and dateRange::Subsumes?, or
their components.
It is useful to determine first the structural subsumption function, dateRange::SubsumesSame?, since this drives the requirements for the others. In our case, the obvious
representation works fine: a date is some data structure, such as a list of three values or
a record with three fields; a single date-pair is a list of two values or a record with two
fields; and the set of date-pairs making up the disjunction is just a list of date-pairs. It is
best to encapsulate the above implementation choices using abstract data types for Date,
DatePair and DateRange, with appropriate accessor functions and constructors. We must
also extend the representation of normalized concepts to implement put dateRange and
get dateRange.
Returning to dateRange::SubsumesSame?, this function now simply implements the
subsumption inference rules above
dateRange::SubsumesSame?(high,low : <SET(Date×Date)> ): returns <Bool>
{for every (b,e) in low
find (b’,e’) in high such that b’  b  e  e’;
}

412

Extensible DL Representation and Reasoning

Universal

dateRange({(BeginTime,EndTime)}) ≡ any-date

Incoherent

dateRange({}) ≡ nothing

Subsumption

b1  b2  e2  e1
dateRange({(b2,e2)}) =⇒ dateRange({(b1,e1)})
dateRange(α1 ) =⇒ dateRange(α2)
dateRange(β1) =⇒ dateRange(β2 )
dateRange(α1 ∪ β1) =⇒ dateRange(α2 ∪ β2)

Conjunction

and(dateRange({(b2,e2)}), dateRange({(b1,e1)})) ≡
dateRange({ (max(b1,b2),min(e1,e2))})
and(dateRange(α),dateRange(β1)) ≡ dateRange(γ1)
and(dateRange(α),dateRange(β2)) ≡ dateRange(γ2)
and( dateRange(α), dateRange(β1 ∪ β2)) ≡ dateRange(γ1 ∪ γ2)

Normalize

e  (b + 1 day)
dateRange({(b,e),α}) ≡ dateRange({α})
b1  b2  (e1 + 1 day)  e2
dateRange({(b1,e1),(b2,e2)}) ≡ dateRange({(b1,e2)})

Table 3: Inference rules for dateRange.

dateRange::Normalize verifies (if not already done so) that the dates b and e in
each pair (b,e) are valid according to our usual calendar, and that b  e. Any pairs not
satisfying these conditions are eliminated. It also needs to merge overlapping or adjacent
intervals into maximally long ones, since otherwise the above subsumption algorithm will not
recognize that dateRange({(1996/1/2,1996/1/4), (1996/1/5,1996/1/6)}) subsumes
dateRange({1996/1/2, 1996/1/6}).
The function dateRange::Conjoin has the standard implementation (see Appendix
A), but only functions dateRange::Universal?, dateRange::Incoherent?, dateRange::ConjoinToSame and dateRange::SubsumesSame? need to be implemented, performing
exactly the actions specified by the rules of inference.
Consider now adding another concept constructor for dates, to help represent periodic
time, such as “every summer” or “every Christmas”. A single period is just a range constraint on the possible values for the components of a date, other than year. So, “summer
days” would be represented by [(6 . 8) (1 . 31)], while “Christmas” would be [(12 . 12)
(25 . 25)]. For the sake of brevity, this new period constructor will take as argument
only a single period (rather than a set of them, interpreted disjunctively) and we will only
sketch the implementation extensions. Also not presented here, is a very useful extension to
413

Borgida

Universal

period([(1 . 12) (1 . 31)]) ≡ any-date

Incoherent

not( bm ≤ em and bd ≤ ed )
period([(bm.em) (bd.ed)]) ≡ nothing

Subsumption

bm1 ≤ bm2 ≤ em2 ≤ em1 and bd1 ≤ bd2 ≤ ed2 ≤ ed1
period([(bm2.em2)(bd2.ed2)]) =⇒ period([(bm1.em1)(bd1.ed1)])

Conjunction

and(period([(bm1.em1)(bd1.ed1)]), period([(bm2.em2)(bd2.ed2)]))
≡
period([(max(bm1,bm2) . min(em1,em2))
(max(bd1,bd2) . min(ed1,ed2))])

Table 4: Inference rules for period.
periods allowing constraints on the days of the week, such as “every Saturday to Sunday”,
or even “every 3rd Sunday”.
The denotation of period terms is also quite simple:
period([(m1.m2)(d1.d2)])I = {e | m1 ≤ month(e) ≤ m2, d1 ≤ day(e) ≤ d2}
The rules of inference for reasoning about period concepts alone, presented in Table 4
are also straightforward. The implementation of most functions follows immediately from
the rules of inference.
The interesting reasoning involves the conjunction of ranges with periods. These rules,
appearing in Figure 5, can be expressed most succinctly by showing how certain periods
are either eliminated or retained unchanged, and then relying on the dateRange normalization rule, applied in reverse, to cut up a range into appropriate strips. These inference
rules imply that we need to also implement period::ConjoinToDifferent (p:<Period>,
other:<NormalizedConcept>), which basically uses the period as a “cookie cutter” to
create the sub-interval ranges that satisfy the period’s restriction. Of course, this will
be done procedurally in a manner more efficient than suggested by the rules of inference.
Moreover, we must now revisit the implementation of dateRange, to put in a similar dateRange::ConjoinToDifferent function, since a concept with a range may be conjoined
onto one that already has a period in it.
Finally, in the presence of both dateRange and period constructors, structural subsumption is not enough, since we want period([(4 . 4) (1 . 31)]) to subsume dateRange((1988/4/1, 1988/4/21)), but not dateRange((1990/4/1, 1992/4/1)), and
there is no finite normal form which would list all the ranges satisfying a period. So we need
to also write the function period::Subsumes Different?(p:<Period>, lower:<NormalizedConcept>), which checks every interval (b,e) in get dateRange(lower) to make
sure that year(b)=year(e) and that the month and day meet the conditions of the period.
An interesting complication arises because dates are discrete, and hence one can count
the number of dates in a dateRange. If dateRange can appear as the value restriction
414

Extensible DL Representation and Reasoning

and(dateRange(α ∪ β), period(δ))
≡
and(and(dateRange(α), period(δ)), and(dateRange(β), period(δ)))
bm ≤ month(dt1) = month(dt2) ≤ em and
bd ≤ day(dt1) ≤ day(dt2) ≤ ed
and( dateRange({ (dt1,dt2) }) , period([(bm.em),(bd.ed)]) )
≡
dateRange({ (dt1,dt2) })
month(dt1)=month(dt2) and
not (bm ≤ month(dt1) ≤ em and bd ≤ day(dt1) ≤ day(dt2) ≤ ed )
and( dateRange({(dt1,dt2)}) , period([(bm.em),(bd.ed)]) ) ≡ nothing

Table 5: Inference rules for conjoining period and dateRange.
of general roles, as in all(freeForMeeting, dateRange({(1995/6/1,1996/6/5)})) attributes, there is no problem. Otherwise, we can however infer cardinality constraints on
the number of fillers: dateRange({(1995/6/1,1996/6/5)}) allows only 5 different values. In a language that supports constructor at-most, we would therefore have to conclude
at-most(5,freeForMeeting). The implementation achieves this by introducing a helper
function dateRange::countDays, which can be applied to a normalized dateRange object; then, function all::FindOtherImplications needs to be modified, so that it invokes
dateRange::countDays on its value restriction if it is of date type, and a normalized
at-most restriction is posted for that role on the ImplicationsToDoList. Later processing of that list will remove the at-most constraint and conjoin it onto the concept.
3.4 Experience with Extensions
As part of the development of the above architecture, we have considered extending the
original core with the constructors of classic (all, at-least, at-most, fills, one-of, integer
ranges), as well as primitive concept negation, and the negation of fills. In these cases we
have reproduced the inferences of classic and almost exactly the internal actions of the
classic implementation; i.e., we perform only a few more checks despite the fact that our
implementation is made up of “standard” modules for each constructor.
Two kinds of concept constructors seem difficult to add to a normalize-compare algorithm in a way that preserves completeness of reasoning and the architecture of the system.
Disjunction would most naturally be handled if there was a disjunctive normal form, where
each disjunct is purely conjunctive. This is difficult to achieve with nested disjunctions
(inside all restrictions say). Note that we had no problem with the one-level disjunction in
dateRange.
A second kind of construct that is difficult to add efficiently and completely is same-as.
The reason here is that same-as interacts with all in a way that generates a potentially infinite number of all restrictions; therefore, the implementation of same-as is best combined
415

Borgida

with that of all, resulting in a non-tree data structure (Borgida & Patel-Schneider, 1994).
A speculative way to preserve structural subsumption might be to allow all to apply to
chains of a attributes represented by regular expressions. (In general, the complications of
implementing same-as are the reason it does not appear in C-classic and neo-classic.)
Finally, as mentioned earlier, we do not currently cover role constructors and recursive
concept constraints. Furthermore, constructors that require entirely new deductive mechanism (e.g., epistemic reasoning, defaults, forward-chaining rules) will also have difficulty
being integrated properly into this framework.
On the positive side, we have considered extensions supporting strings (Borgida, Isbell,
& McGuinness, 1996), and most elaborately, a reconstruction of the clasp reasoner about
actions and plans (Borgida, 1992b). To summarize this “success” briefly, clasp (Devanbu &
Litman, 1996) was a system built on top of classic for reasoning about actions (which were
represented in propositional STRIPS-style, having concepts for pre- and post-conditions, as
well as add and delete lists); plans were represented by regular expressions of actions, as
illustrated below. Our goal was to apply the protodl approach to clasp, hoping to
be able to reproduce the original, custom-made implementation discussed by Devanbu and
Litman (Devanbu & Litman, 1996). First, we introduced a concept constructor for actions,
act(P reC, P ostC, AddC, DeleteC), with the expected logical properties expressed as rules
of inference in the various categories (e.g., if P reC was incoherent, then the action was also
incoherent). The implementation then followed immediately.
The more interesting problem was dealing with plans. The constructors single, seq,
loop, and altern can be used to build complex plans from actions, as in seq( single(DIAL),
loop(single(RING))). These plans denote sequences of action instances (e.g., in the above
example, a dialing action followed by any number of rings). Although we provided rules
of inference for plans too, it turns out that there is no normal form for regular expressions! Instead, in the implementation, Normalize for seq, altern and loop built a nondeterministic finite automaton, which then had to be made deterministic, and in which
certain chains of arcs had to be removed (if the post-condition of the action on the incoming edge was inconsistent with the pre-condition of the action on the outgoing edge).
Moreover, the containment algorithm for these finite automata had to take into account
the fact that actions on transitions (e.g., MOVE) may represent generalizations of others (e.g., MOVE-FAST). This implementation was achieved in protodl by introducing a
“hidden” concept constructor, top-plan-exp, which enclosed the top plan. It was then
top-plan-exp::Normalize that made the automaton deterministic and removed some
transitions, and top-plan-exp::Subsumes? that implemented the special subsumption algorithm. Moreover, the requirement to implement top-plan-exp::Conjoin, which was not
present in the original clasp system, made us realize that without this, clasp plans could
not appear in other concepts, because expressions like and(all(p,PLAN1), all(p,PLAN2))
could not be normalized. As a result we believe we reconstructed and improved the original
clasp proposal, by characterizing the inferences performed through rules of inference, and
by allowing plans to be first-class values, which could appear in ordinary roles.
416

Extensible DL Representation and Reasoning

3.5 Relationship to “Concrete Domain” Extensions
Although we shall address general work on extensible KR&R in the conclusion, there is
one specific approach involving description logics that deserves closer scrutiny at this stage,
while the details of the present work are still fresh.
Baader and Hanschke’s proposal (Baader & Hanschke, 1991) for extending DLs with
“concrete domains” allows concepts to consist of arbitrary predicates involving values from
some domain other than ordinary objects (i.e., other than elements of ∆I ), as long as
these values are fillers of attributes of ordinary objects. For example, suppose the concrete
domain is that of dates; as above, we have predicates like BEF ORE, corresponding to
 ; then, if we had two date-valued attributes arrival and departure, we could define
the concept BEFORE(arrival,departure), denoting ordinary objects (not sets of dates!)
whose attributes have appropriately related date values.
In order to keep reasoning decidable, this mechanism requires the concrete domain to
be “admissible”: (i) there must be a predicate denoting the universe of all values in that
concrete domain; (ii) the set of predicates must be closed under negation; and (iii) it must
be possible to decide the satisfiability of any finite conjunction of such predicates. It is
interesting to note that these requirements match in part our heuristics for new concept
constructors: we also argued for the need to add a top concept to the hierarchy of new values
(and its negation, the bottom of this hierarchy), and for the need to be able to compute
the conjunction of descriptions.
The admissibility of a concrete domain ensures that the protodl approach can implement any such extension as follows: Syntactically, a domain corresponds to a concept
constructor. Therefore, a concept like BEFORE(arrival,departure) in the domain DATE,
would be represented in protodl as DATE(’BEFORE’,arrival,departure). Then, the
necessary protodl functions are programmed as follows: DATE::Normalize tests that
the predication is satisfiable (otherwise signaling IncoherentExn), and creates a singleton
list containing the predication; DATE::Conjoin concatenates the list of predications of
its arguments, checking for the consistency of their conjunction; DATE::Subsumes?(C,D)
creates the conjunction of all the predicates in C, and their negation in D, and returns true
if the result is unsatisfiable.
Conversely, Baader and Hanschke’s approach could well be applied to date ranges, since
these are essentially closed under negation. And since it is offered in the context of the
tableau theorem-proving technique mentioned in Section 2.4, this continues to have the
advantages of elegance and complete reasoning, as long as the concrete domain reasoner is
proven complete. In our case, the entire system would have to be proven complete.
We believe though that protodl is somewhat more general, since it allows concrete
domains to be value of roles, not just attributes (see our earlier discussion of dates as values
of roles). Also, there is some advantage to being able to deal with non-admissible domains
in cases when negation is not absolutely needed, but its addition would cause an increase in
computational complexity; for example, adding negation/complement to regular expressions
makes the containment problem non-elementary (Stockmeyer, 1974).
417

Borgida

4. Processing of Individuals in DLs: An Introduction
Concept descriptions, as introduced above, are intensional objects, suited for capturing
generic information about a domain, such as the ontology of terms. DL-KBMSs must also
manage extensional/factual information about individual objects — the so-called A-box5 .
4.1 Inferences Involving Individuals
Normally, one can assert information such as the fact that some object Anni is known to
be an instance of a concept CHILD (written as Anni:CHILD), or that it has some other
object, Lego as a filler for its hasToys role (written as (Anni,Lego):hasToys). Based
on this information, the KBMS can deduce information about the individual’s membership in other descriptions (written using −→ ); for example, in this case we know Anni
−→ at-least(1,hasToys). Because DL-KBMS usually do not make the closed-world assumption, it is also necessary to record when some set of fillers is complete for an individual’s
role. This is done using an (auto-epistemic) assertion like
Anni:allFillersKnown(hasToys,{Lego,Barbie}). As a result of such an assertion, we
can then deduce that Anni −→ at-most(2,hasToys). (Note that we have distinguished
the three kinds of assertions in A, namely b : C, (b, e) : p, b : allFillersKnown(p, S), from
the corresponding judgements that can be deduced in the logic: b −→ C, b −→ fills(p,e),
b −→ closedFillers(p,S).)
Information about fillers and roles being closed (i.e., all fillers being known) can also be
deduced, as in the case of the KB that contains A={Lori:all(hasToys,one-of(Lego45)),
Lori:at-least(1, hasToys)}, from which we can conclude that Lego45 is a toy owned by
Lori (written as Lori −→ fills(hasToys,Lego45)) and that the complete set of fillers for
hasToys is { Lego45 } (written as Lori −→ closedFillers(hasToys,{ Lego45 })). We
note that an elegant formalization of these notions has been obtained by adding an epistemic
modal constructor K to DLs (Donini et al., 1998). This constructor has a number of other
uses, but to shorten the presentation we have not introduced it here explicitly.
Formally, we define a knowledge base KB to be a concept knowledge base CKB, extended
with a set A of assertions of the form b : C, (b, e) : p and b : allFillersKnown(p, S),
where S is some set of individuals. An interpretation I is said to be a model for b : C if
bI ∈ C I , a model for (b, e) : p if eI ∈ pI (bI ), and a model for b : allFillersKnown(p, S) if
(eI ∈ pI (bI ) ⇐⇒ e ∈ S)6.
The judgment KB |= b −→ C holds iff for every model I of KB, bI ∈ C I ; the judgement KB |= b −→ fills(p, e) holds iff for every model I of KB, (bI , eI ) ∈ pI ; finally,
KB |= b −→ closedFillers(p, S) holds iff KB |= b −→ fills(p, bi) for every bi ∈ S, and
for every other individual e not in S, there is some interpretation I of KB such that
6 KB |= b −→ fills(p, e) . Because our concept language may not have negation, and because
we have the open world assumption, we also need to be able to talk about non-membership
in a concept: b 6−→ C; naturally, KB |= b 6−→ C iff for some model I of KB, bI 6∈ C I . As
usual, a KB will be called inconsistent iff it has no models.
5. The most thorough theoretical investigation of individual reasoning has been presented in Andrea
Schaerf’s PhD thesis and derived publications (Schaerf, 1994). We note however that for some of the
most expressive DLs proposed recently, individual reasoning has not yet been addressed.
6. As usual, we make the unique-name assumption, and in fact include named individuals in the domain

418

Extensible DL Representation and Reasoning

The specification of reasoning about individuals can again be represented by inference
rules (Borgida, 1992a). For example, for the constructor all, we proffer the following three
rules of inference, which describe the “structural membership/non-membership” rules, as
well as a kind of inference called “propagation”, where information about some individual
b results in new information being deduced about another individual e:
KB ` b −→ closedFillers(p,S)
KB ` bi −→ C
KB ` b −→ all(p,C)

S = {b1, · · · , bn}, n ≥ 0

KB ` b −→ fills(p,e)
KB ` e 6−→ C
KB ` b 6−→ all(p,C)
KB ` b −→ all(p,C)
KB ` b −→ fills(p,e)
KB ` e −→ C

Note that for an inconsistent KB, we can have KB ` b −→ nothing, or we can deduce
information from fillers (e.g., KB ` b −→ at-least(3,pets)) that contradicts information
asserted or deduced from descriptors (e.g., KB ` b −→ at-most(2,pets)).
4.2 DL-KBMS Operations on Individuals
The point of living with the open-world assumption is to allow information to be accumulated incrementally, as in the case of designing some artifact (one of the most successful
applications of classic).
From the functional point of view, the DL-KBMS therefore supports the following update operations for incrementally adding information about individuals:
Operation
assert-member(b, C)
assert-fills(b, p, b1)
assert-closed(b, p)

Effect
b : C is added to A
(b, b1) : p is added to A
b:allFillersKnown(p,S) is added to A, where S is
the set of individuals returned in the current KB by the
operation ask-for-fillers(b, p), defined below.

If as a result of the update, the KB is inconsistent, then the update is rejected and the
state of the KB is supposed to remain unchanged.
At any point, the KBMS is able to respond to inquiry operations about relationships
involving individuals:
Question
ask-member?(b, C)
ask-non-member?(b, C)
ask-for-fillers(b, p)

Answer type
Boolean
Boolean
SET(Individual)

ask-closed?(b, p)

Boolean

Response
true iff KB |= b −→ C
true iff KB |= b 6−→ C
{ e | KB |= b −→ fills(p, e) }
true iff for some set S
KB |= b −→ closedFillers(p, S)

As with concepts, many DL-KBMS pre-compute the b −→ C judgment, for all individual
and concept names, by finding the most specific named descriptions to which the individual
b provably belongs. Similarly, the DL-KBMS pre-computes and caches the fillers and closed
419

Borgida

information for each individual’s roles. This is done in order to detect inconsistencies at the
time of the update, to decrease the amortized cost in case queries are much more frequent
than updates, and to support queries of the form “What additional information can you
deduce about v?”. The utility of such queries has been shown, among others, in applications
involving information discovery in software development (Devanbu, 1994).

5. Individuals in protodl
Reasoning about individuals The goal of our implementation is to support efficiently the
update operations, which are incremental, so that most of the inferences are precomputed:
for each individual, we know the least classes it is an instance of, all the fillers it can have
for each role, and whether the role is closed or not for that individual. The architecture
below describes an extension and rationalization of the individual processing that is usually
carried out in normalize-compare DL-KBMS such as classic. The novelty will be the
systematic separation of the interaction between various kinds of updates and various kinds
of inferences, and the concomitant use of truth-maintenance links.
5.1 The Basic Architecture of Individual Reasoning
In some systems, one can try to reduce individual reasoning to concept reasoning by associating some single, maximally complete description with each individual. However, this is
not always possible, as shown by Schaerf (Schaerf, 1994).
Instead, our data structure for every individual includes both a concept description (to
be called Descriptor), which may be an existing class or an unnamed complex description, and individual role-filler information recording the specific values assigned so far, and
whether the role is closed or not. (This information is accessed with built-in functions
add filler, put closed, get fillers and is closed?.)
In processing an update about some individual b, we must therefore resort to two
kinds of reasoning: (i) subsumption/incoherence reasoning involving only the description
Descriptor(b) and other concepts; (ii) reasoning specific to the individual and especially
its role fillers.
The former kind of reasoning is motivated by general inference rules connecting membership and subsumption (e.g., if b −→ C and C =⇒ D then b −→ D). Since subsumption
and its extensibility has been described in the preceding section, henceforth we concentrate
on the second aspect of individual reasoning.
To understand the tasks involved, let us illustrate what kinds of reasoning need to be
performed whenever any fact is asserted (or inferred) about an individual b
• The KB may become inconsistent, because of a conflict between the individual descriptor and the filler information either on b or some other individual. For example,
more fillers might be added to a role than permitted by an at-most restriction. This
requires the entire update to be rejected. Note that an update may result in several
individuals with inconsistent information on them. The system is only required to
detect one of them, before rejecting the update.
420

Extensible DL Representation and Reasoning

• The individual b may end up being re-classified. In a monotonic system, such as the
present one, this means that the individual may now belong to some more specialized
class(es) in the hierarchy.
• New information about the roles of individual b can be inferred. For example, learning
that a role is closed allows us to now count its fillers and hence obtain an exact upper
bound recordable by at-most.
• New assertions can be inferred about other individuals, usually ones related to b via
roles. For example, if an all(friends,HAPPY) description applies to some individual
x, and now y is asserted to be a friends-filler for x, then we can infer that y is an
instance of HAPPY.
To support the first task above, protodl might use the function ConsistentW?7, which
returns true to indicate that information to be added to an individual is consistent. For
the second task, we use function Recognizes?. For the third and fourth tasks, which
involve individuals other than the one on which the update has occured, we use function
InferFrom.
These functions are used to implement the various assert KBMS operations, as well
as the ClassifyIndividual function, which is used by protodl to find the lowest classes
in the hierarchy to which this individual belongs.
As in the case of concept reasoning, we use the and constructor to drive the processing,
and we modularize the implementation so each kind of constructor Q has its own set of functions: Q::Recognizes? , Q::ConsistentW? , Q::InferFrom . It now becomes more
important to distinguish constructors, like all and at-most, that have an associated single
role, in contrast to generic constructors such as one-of (which has no roles associated) and
same-as (which has many roles, none of which is special). For the former, so called branch
constructors, the above functions will have arguments that include not just the individual
and the normalized representation of Q-terms, but also the fillers and closed information
about the role. (This is done to prevent repeated retrieval of these values by each such
constructor.) Therefore, the general form of and::Recognizes?, provided in protodl, is
and::Recognizes?(b:<Individual>,NC:<NormalizedConcept>)returns <Bool>
{ For every Q(T) in getNonbranchComponents(NC) do
if not Q::Recognizes?(b,Q(T)) then return false;
For every role p in getRestrictedRoles(NC) do
{F:= get fillers(b,p);
clsd? := is closed?(b,p);
For every Q(T) in getBranchComponents(NC,p)
{if not Q::Recognizes?(b,Q(T),F,clsd?)
then return false};};
return true; }
7. Later, when we introduce incremental reasoning, we will identify a number of variants of this function.

421

Borgida

The functions and::ConsistentW? and and::InferFrom are similar in structure, and
are not presented due to space limitations. It is important to note that the ConsistentW?
functions return false only to indicate that they are unable to prove conclusively that the
individual is consistent or inconsistent; if an inconsistency is found, an InconsistentExcn
is raised. Also, after an update there may be several individuals about which incompatible
information will be asserted. The system only guarantees to find one such case, and then
rejects the update.
The following is an example of a specialized function for the case Q=all, which implements the first inference rule presented earlier
all::Recognizes?(b:<Individual>, all(r:<Role>,vr:<NormalizedConcept>),
fillers:<SET(Individual)>, clsd?:<Bool>) returns <Bool>
{if not clsd? then return false
/*More fillers might come later*/
else for every f in fillers do
{if not and::Recognizes?(f,vr)
then return false;}
return true }

5.2 Reasoning with Incremental Updates
Since updates to individuals are incremental in nature, in order to improve efficiency we
want to take into account the fact that the KBMS had already performed all the inferences
up to, but not including, the current update. For example, if some individual Tintin has
been asserted to be an instance of all(pet,DOG), and already has pet-fillers d1 and d2, then
if the current update is assert-fills(Tintin,pet,Fido), then we only need to propagate
the information that pet-fillers are DOGs to Fido, since the others would have been processed
earlier. And, if the current update is assert-closed(Tintin,pet), then no new role-filler
information can be inferred from this because of the all restriction, so we should not even
bother calling all::InferFrom. We will therefore distinguish the following three variants
of Q::InferFrom:
Q::InferFromFilling(<Individual>,<NormalizedQ-term>,<Role>,<Individual>)
Q::InferFromClosing(<Individual>,<NormalizedQ-term>,<Role>) , and
Q::InferFromAsserting(<Individual>,<NormalizedQ-Term>)

plus similar variants of Q::ConsistentW?. For example
• all:ConsistentWFilling?(ind, all(r,vr), r, newfiller) invokes and::ConsistentWAsserting?(newfiller,vr) to check that the new filler does not contradict the
role restriction vr;
• all::ConsistentWClosing?(ind,all(r,vr),r) just returns true, and hence is hopefully eliminated by the compiler;
422

Extensible DL Representation and Reasoning

• all::ConsistentWAsserting?(ind,all(r,vr)) verifies that all r-fillers y of ind are
consistent with vr by invoking and::ConsistentWAsserting?(y,vr).
One might also consider variants of Q::Recognizes?, but, as we shall see, in our case
these are of limited use since we do not propose to keep information on which parts of the
recognition test had succeeded already, and therefore we need to start from the beginning.
5.3 Dependency Links
Clearly, the results of function calls, such as Recognizes?, on some individual Bob might
change after an update to Bob itself. However, the membership of Bob in a class or Bob’s
consistency may depend on facts asserted about other individuals in the database. For
example, if all of Bob’s friends are known (i.e., the role friends is closed), and all but
one of them was MARRIED, and now that holdout, Larry, is also asserted or inferred to be
MARRIED, then Bob itself can be reclassified as an instance of all(friends,MARRIED).
This means that without some special data structure, after every update of some individual an unsophisticated implementation has to reconsider every other individual in the
KB.
One alternative, used in loom (MacGregor, 1986), is to keep track of all questions asked
about an individual as part of the previous processing (“hits” and “misses”), and if answers
to these do not change as a result of the update then no re-processing is needed. Another
alternative is to use an elaborate truth-maintenance system (as available in kl-two (Vilain,
1985)), for each kind of judgment. In our opinion, both these approaches might however
become very expensive in terms of space and often computation time, because they maintain
too many details.
We follow an intermediate stance, first suggested by Peter Patel-Schneider for the classic implementation, which is intended to reduce needless re-testing while incurring relatively less “dependency maintenance” overhead. Essentially, we have a “coarse-grained”
dependency structure, where one individual e may point to another, b, if the result of
a decision about the latter may change as a result of some (unspecified) additional information being added to the former. For example, in the presence of the definition
.
CanineLover=all(pet,DOG), if Tintin has Fido as a pet filler, and neither Recognizes?(Fido,DOG) nor not ConsistentW?(Fido,DOG) return true, then we add a link
−−−−−−−−−−−−→ Tintin. Thereafter, any change of status of Fido will
of the form: Fido RecognizeDependsOnMe
cause Tintin’s classification (with respect to CanineLover, as well as other pending classes)
−−−−−−−−−−−→
−−−−−−−−−→
to be re-done. Similarly, we will have −
ConsistentDependsOnMe and InferDependsOnMe links between
objects.
Note that when following such dependency links back, we do know that only properties
of the fillers of some role might have changed, so that once again we could have variants
and::RecheckConsistentW? and and::RedoInferFrom, which perform less work by omitting the checks involving constructors that are known not to be affected by such aspects
(e.g., at-most only cares about the count of the fillers, not their properties).
In order to set dependency links, every function such as Q::Recognizes? needs to
keep track of the list of individuals whose modification might change the result of the
function. These values must eventually be appropriately linked with dependencies either
by the functions themselves or by the calling environment.
423

Borgida

5.4 Coordinating the Components
As should be clear from the above examples, the task of the top-level KBMS update operations (asserts) will include not just invoking the appropriate functions on the individual
being updated, but also setting appropriate dependency links, gathering into queues other
objects whose dependency links have been “tickled” by the latest update, and then repeating these operations on the other individuals brought into focus by inferences or dependency
links.
An appropriate software architecture for representing this processing seems to be a
blackboard model, where we have 5 lists to which functions can post tasks to be carried
out:
• Two lists, ToRecheckConsistencyList, ToRedoInferFromList, for objects that are
reached from individual x via a corresponding kind of dependency link as a result of
a change to x.
• A list, ToPerformUpdateList, which collects the additional inferences to be made that
are found by the InferFrom and RedoInferFrom function calls. For simplicity, these
are recorded as additional calls to versions of the three kinds of assert functions.
• A list, ToReclassifyList, which receives objects that need to be checked in case
they can be classified further down the hierarchy; these objects come not just from
dependency links but also from any additional asserts that had been triggered.
• Finally, a list ToAddDependencyList, that keeps track of dependency links that need
to be added to the knowledge base; this list is augmented by the various functions, as
mentioned in the previous section.
Because, for example, re-classification may cause new inferences, which may cause reclassification due to some other constructor, there is no linear order in which these lists
can be processed. We may therefore have a loop where a “demon” removes an arbitrary
object from a list, invokes the required function, and then repeat the process. The only
requirement is that dependencies on ToAddDependencyList be also considered as having
been installed, whenever chasing objects that may have been affected by an update. Note
that, not surprisingly, it is hard to make any general statements about the termination of
the above algorithm skeleton, since the various functions, especially InferFrom. are free to
do whatever they want, including increasingly longer descriptions..
Several policies can help the performance of the system:
• In all cases, it is helpful to eliminate duplicates from the lists.
• Locality of context may improve performance; therefore grouping together operations
to be performed on one object is advisable (e.g., gather together all the dependencies
from object y on ToAddDependencyList).
• If we expect inconsistencies to arise infrequently, then the ToRecheckConsistencyList can be processed at the end.
424

Extensible DL Representation and Reasoning

assert-fills(ind, role, filler)
{if redundant information then signal RedundantExn;
add filler(ind,role,filler); /* this may be rolled back by an error */
initialize the blackboard lists to empty;
ind-descr := Descriptor(ind);
/* deal with consistency issues involving ind */
and::ConsistentWFilling?(ind, ind-descr, role, filler);
/* the preceding function will post dependencies if
the answer is not a definite TRUE */
ToRecheckConsistencyList += getConsistentDependsOnMe(ind);
/* this puts up for reconsideration objects
dependent on ind */
/* check for inferences */
and::InferFromFilling(ind,ind-descr,role,filler);
/* this may post new updates and/or dependencies */
ToRedoInferFromList += getInferDependsOnMe(ind)
/* reclassify at least this individual */
Reclassify(ind);
ToReclassifyList += getRecognizeDependsOnMe(ind);
/* Process tasks left on the blackboard */
ProcessBlackBoard;
}
catch InconsistentExcn
{roll back update; print error msg; }

Figure 2: protodl pseudo-code for assert-fills.
Figure 2 contains the pseudo-code for assert-fills, which is offered by protodl. Notice
the advantage in the above program of using exception handling and propagation up the
dynamic function call hierarchy as a way of dealing with inconsistency: wherever it is
detected by ConsistentW?, the exception passes up through levels of function calls, all of
which are interrupted, until a handler is encountered — usually by an external or internal
assert operation; this issues appropriate error messages, resets local changes made, and
then re-raises/propagates the exception further up, until the top level is reached.
5.5 Extending Individual Reasoning – An Example
Let us consider the extensions needed for a rather complex new concept constructor:
same-as. The semantics of same-as([f1 , · · ·, fn ],[g1, · · · , gm]), as introduced earlier, is
that it denotes individuals for which the two attribute chains [f1 , · · · , fn ] and [g1, · · · , gm]
have the same known filler. (The attributes must each have exactly one filler.)
This constructor is very useful in representing the relationship between actions and subactions. For example, suppose we try to define the action of BUYing in terms of two GIVEs:
425

Borgida

we would assert that BUY is subsumed by and(all(giving1,GIVE),all(giving2,GIVE)),
and then add further constraints about the attributes of BUY (such as buyer and seller)
and those of GIVE (such as giver and receiver), including same-as([buyer],[giving1
giver]) and same-as( [seller],[giving1 receiver]).
The procedures that need to be written to extend the implementation are: same-as::Recognize, same-as::InferFromFilling, same-as::InferFromClosing, same-as::InferFromAsserting, same-as::ConsistentWFilling?, same-as::ConsistentW Closing?, and same-as::ConsistentWAsserting?. In addition, some previously written procedures may need to be augmented.
Rules of inference for −→ and 6−→ can be presented as a way of describing the tasks
performed by the above functions. However, in this case, the functions also need to worry
about dependency pointers, so the mapping is less direct.
The following inference rule describes the standard recognition procedure for individuals
(there are additional rules for subsumption of course):
KB ` b −→ fills([f1, · · · , fn ], e)
KB ` b −→ fills([g1, · · · , gm], e)
KB ` b −→ same-as([f1, · · · , fn ], [g1, · · · , gm])
If the recognition function can only follow a chain up to an individual e, which is missing
the filler of the next attribute in the chain, then a dependency from e must be recorded.
same-as::Recognizes?(b, same-as(chain1,chain2))
{ (e1,p’) := follow chain1 from b, returning the furthest
individual e1 reached, and the remainder of the chain p’
which was not possible to follow;
if not(p’=nil)
−−−−−−−−−−−−→ b; return false;}
then { post dependency e1 RecognizeDependsOnMe
(e2,q’) := follow chain2 from b, as above;
if not(q’=nil)
−−−−−−−−−−−−→ b; return false;}
then { post dependency e2 RecognizeDependsOnMe
if (e1=e2) & p’=q’ then return true else return false.
}
This function will be called from inside and::Recognizes?(b,C) as follows:
...
for every same-as(chn1,chn2) in get sameas(C)
if not same-as::Subsumes?(same-as(chn1,chn2), Descriptor(b))
then if not same-as::Recognizes?(b,same-as(chn1,chn2))
then return false.
...
Reasoning with same-as concerning individuals is actually more complex, because there
are additional rule of inference, such as
KB ` b −→ fills(chain1, e)
KB ` b −→ same-as(chain1, chain2)
KB ` e −→ same-as(chain3, chain4)
KB ` b −→ same-as(chain1 ◦ chain3, chain2 ◦ chain4)
426

Extensible DL Representation and Reasoning

Applying this rule straightforwardly to verify whether some b −→ same-as([f1, · · · , fn ],
[g1, · · · , gm]) requires one to try all possible ways of dividing up the chain [f1, · · · , fn ] into
subchains, and for each, one needs to try to derive the subchain equalities alternately from
individual fillers along the chain, or from explicit assertions of same-as descriptions on
individuals. In this cases, the implementor, in consultation with the knowledge engineer
who is to use the extended system, would make a judgment on the necessity of implementing
this more expensive inference. The rules of inference can be used to describe the deductions
that have been implemented and those that have not.
In order to check consistency, we need to consider the three kinds of updates: assertions,
fillers, and closings. When an equality is first asserted of an individual, we would invoke:
same-as:: ConsistentWAsserting?(ind, same-as(chain1,chain2))
{ (e1,p’) := follow chain1 from ind;
if not(p’=nil)
−−−−−−−−−−−−→ ind; return true;}
then { post dependency e1 ConsistentDependsOnMe
(e2,q’) := follow chain2 from ind;
if not(q’=nil)
−−−−−−−−−−−−→ ind; return true;}
then { post dependency e2 ConsistentDependsOnMe
if e1=e2 then return true else signal InconsistentExcn;
}
Since the attributes can have at most one value, these attributes get closed automatically
when a filler is provided, so there is usually no explicit closing of the role that can affect
same-as, and there is no need for same-as::ConsistentWClosing?.
Finally, if C includes as a conjunct same-as(chain1,chain2), then and::ConsistentWFilling?(ind,C,p,newfiller) will have to invoke
same-as::ConsistentWFilling?(ind,same-as(chain1,chain2),p,newfiller)
{if (member(p,chain1) OR member(p,chain2) )
then same-as:ConsistentWAsserting?(ind,same-as(chain1,chain2))}
Equalities can lead to inferences when one of the chains is completely known, and all
values but that of the last attribute on the second chain are known, as illustrated by the
following example:
{ a : same-as([q] , [p, r]), (a, e) : q, (a, b) : p } |= b −→ fills(r, e)
−−−−−−−−−→ links to watch for cases when we have
This inference requires us to set up InferDependsOnMe
sufficient information to make the inference.
We point out that same-as presents one example of a situation where a performance
penalty is paid for separating out consistency checking, recognition and inference: each of
these functions attempts to traverse the individuals along the two chains of the equality in
an effort to reach the ends. This price is negligible if there are relatively few individuals with
same-as conditions attached, or if the chains are usually only one or two attributes long, as
is the case for the application of same-as illustrated earlier. Otherwise, we can introduce
427

Borgida

caching to speed up the code: associate with every equality and individual b two pairs (e1,r1)
and (e2 ,r2) representing the ends ei reached on each chain, and the remainder of the chains
ri left to be traversed. (So if the chain is completely known, r = nil.) A final alternative is
to add the code for same-as::InferFrom into same-as::ConsistentW? function, so the
latter performs all the deductions involving same-as. The disadvantage of this approach,
as of many optimizations, is the loss of modularity.
Finally, we mention that other extensions of reasoning at the individual level that we
have considered include “database aggregate functions” like sum (e.g., sum([departments
budget], totalBudget) can be used to model that totalBudget is the sum of the values
for budget fillers for all department fillers); and epistemic constructors that allow one to
query the state of knowledge (Donini et al., 1998) (e.g., known-all(friends, knownat-most(1,pets)) recognizes individuals all of whose known friend fillers have at most
one pet recorded in the KB, without having to have the roles be closed).

6. Conclusions
We began from the hypothesis that no “perfect” DL will ever be built, because of the
need for application-specific reasoning, and potential incompleteness of reasoning due to
the expressiveness-(tractability/decidability) trade-off. We argued that some of these issues
are best attacked on a per-application basis. To resolve this problem, we proposed the use
of an extensible DL-KBMS, where one tries to go as far as possible with an initial set of wellunderstood concept constructors, and then, when encountering unsolvable expressiveness
problems (Doyle & Patil, 1991), add new concept constructors to overcome them.
We have also pointed out the limitations of this approach, which include not being
conducive to including new forms of reasoning such as abduction, contexts, etc., and having
difficulties with complete inferences for useful concept constructors that require reasoning
by contradiction, and are best handled in the alternative DL reasoning paradigm – tableaux.
6.1 Implementation Status
Prototype implementations of aspects of both concept and individual reasoning in protodl
have been carried out at Rutgers. However, experience with all fielded systems indicates
that there is an order of magnitude more work to be done in making a system usable by
others than their developers. For this reason, our goal is to add the results of the protodl
research to an existing DL-reasoner. In fact, several ideas have been transfered, with the
collaboration of Charles Isbell, to the newest version of the classic system released by
AT&T Research. In particular, classic supports test-defined concepts – ones which allow
the recognition of individuals through the use of an arbitrary LISP function. (This function
can be seen as the combination of the Recognizes? and ConsistentW? functions discussed
in the present paper.) In the newest version of classic, one can simulate the addition of
new concept constructors by using them after the keyword test-c. For example, the concept
all(vacation,dateRange(1996/6/1,1996/8/31)) would be represented as
(test-concept dateRange vacation ’( (1996 6 1) (1996 8 31)) )
428

Extensible DL Representation and Reasoning

Although not all aspects of the protodl system have been implemented, the current
extensions (Borgida et al., 1996) allow significant subsumption reasoning to be done for test
extensions, and thus provide classic with the bases for extensible reasoning.
6.2 Related Work
In order to incorporate new concept constructors into a reasoner, we need to extend the
implementation. One approach to this would be to offer some form of “declarative description” of the inferences to be performed, and then have a meta-interpreter which executes
them. In fact, such approaches have been tried in the past for other kinds of representation formalisms (Greiner & Lenat, 1980; Genesereth, 1983). Except for cycl (Lenat &
Guha, 1990), which allows the addition of new forms of inference rule schemas in First
Order Predicate Calculus, we see little evidence that such a meta-interpreter has a chance
of being nearly as efficient as custom-built implementations, so we have opted for a different
approach.
Joshua (Rowley, Shrobe, & Cassels, 1986) is also an effort at providing extensible reasoning, which allows the user (knowledge system engineer) the ability to change at compile-time
the implementation of any or all of the elements of the protocol of inference, which describes
the reasoning of the system. Joshua is close in spirit to our work in the sense that it tries to
maintain a uniform “knowledge level” view of the system, and because it identifies, in the
“protocol of inference”, the specific aspects of the system that can be customized through
(re)programming of Lisp functions. Our efforts differ from Joshua in that we are interested
in DLs (Joshua’s protocol was concerned mostly with rule triggering and truth maintenance), we wish to support incrementing the syntax of the knowledge-level interface, and
we also care about the semantics of the extension.
Gaines has also advocated the utility of a declarative specification and of a clean, extensible modularization for a DL-reasoner (Gaines, 1993). At the concept level, one difference
between our approaches seems to be that protodl only assumes that the concepts will
form an upper-semilattice (the and constructor is built-in), so that a wider variety of inferences can be implemented for new constructors. At the individual-reasoning level, protodl
starts from a much more restricted basis, and uses its extensibility to deal with such aspects
as “propagations” (e.g., our example dealing with same-as reasoning appears to be built-in
in KRSn). On the other hand, KRSn has built-in support for rules and exceptions to them,
which are an important component for any knowledge-based environment.
Finally, it has been suggested that the tableau-based approach, such as that of crack,
is essentially extensible through the addition of new “completion” rules (Bresciani et al.,
1995), which are traditionally used to build a model of a certain knowledge base, or prove its
inconsistency. These tableau completion rules can also implement incomplete reasoners by
using only a subset of the inferences. As with concrete domain extensions (Section 3.5), the
advantages of extensible tableau techniques lie in a clean formalism that can lead to complete
reasoning, while the disadvantages involve language extensions that do not have negation
(e.g., clasp – see Section 3.4), and, for the moment, the lack of experience with large
A-boxes and incremental updates. One of the most exciting (though very likely difficult)
future prospects is combining the two implementation paradigms, and their extensibility
features.
429

Borgida

6.3 Summary
We have advocated an approach to extensible DL reasoning and implementation, for the
normalize-compare paradigm, which has two components: a declarative specification and
a modularized implementation framework.
The specification is offered using rules of
inference in the “natural semantics” style, and a heuristic methodology suggests various
categories of rules to be looked for. These rules often correlate well with the implementations of the various functions, but protodl offers the implementor the opportunity to
use a very different implementation. The later is needed in the case of constructors whose
argument is for example some regular expression – as in the case of plans or strings, when
the implementation needs to use some kind of finite automaton representation, since regular
expressions have no “normal form”.
We have modularized the software architecture of protodl reasoner, so that for every
new concept constructor added to the language, there is a well-defined set of functions that
need to be implemented. These, in turn, sometime have detailed skeletons composed of
other, smaller functions, which we have abstracted after analyzing a variety of implementations. The invocation of these functions is organized by the built-in functions of protodl,
usually involving the constructor and. We have paid particular attention to supporting
efficient implementations, by offering the implementor quite a lot of freedom within the
confines of our major functions. For individual reasoning, this is the first paper to consider
the need to be efficient in the face of incremental updates of DL-KBMSs, which live with
the open-world assumption, and which use concept descriptions to infer new properties,
rather than just verify the correctness of individual facts. Our solutions involved proposing
function variants based on the form of the update, and the use of various kinds of associated
dependency links.
The major open areas involve adding to this framework role constructors, epistemic
rules (like those in classic, characterized by Donini et al (Donini et al., 1998)), the ability
to express at least simple recursive declarations for primitive concepts (e.g., “the parents
of a person are persons”), and connections with the tableau-based implementations for DL
reasoning.

Acknowledgements
I am very grateful to Ron Brachman, who, among others, joined me in the initial explorations of the protodl idea; to Daniel Kudenko, who implemented a significant part of
the individual reasoning; to Charles Isbell, who implemented the extensibility features of
classic 2.3; and to Peter Patel-Schneider, for years of discussion on the subtleties of the
classic language and implementation. Extremely useful comments on the presentation
and organization were provided by Peter Clark and the anonymous reviewers.
This work was supported in part by NSF grants IRI-91-19310 and IRI-9619979.

Appendix A. A Generic Conjunction Function.
The following pseudo-code for Q::Conjoin shows how one can construct this function from
several, smaller functions.
430

Extensible DL Representation and Reasoning

/* Conjoin the new term Q(T) onto the already-normalized description This*/
Q::Conjoin(T:<NormalizedQ-term>,This:<NormalizedConcept>){

old := get Q(This) /* find the part of This dealing with constructor Q*/
if not(old=nil)
then if Q::SubsumesSame?(T,old)
then signal RedundantExn;
T := Q::ConjoinToSame(T,old); /* combine T with old*/
if Q::SubsumesDifferent?(T,This) /* T is implied by other constructors */
then signal RedundantExn;
T:= Q::ConjoinToDifferent(T,This) /* obtain a possibly stronger T*/
if (type(T) 6= Q) /* the stronger description might use another constructor*/
then {post T to ImplicationsToDoList; /* for later processing*/
return; }
Q::ConsistentWithDifferent?(T,This) /* Check if T is coherent with the rest
of This; if not, an exception is raised.*/
put Q(T,This) /* add the description to the normalized descriptor This*/
Q::FindOtherImplications(T,This,ImplicationsToDoList)
/* add any additional constructors implied by T and This */
Figure 3: Pseudo-code of a generic conjunction function.
Before we consider the individual functions introduced above, we remark that if the constructor Q implies terms built with other constructors (i.e., it adds entries to the ImplicationsToDoList), then the and::Conjoin function needs to be augmented with a loop at
the end, which conjoins to ontoNC all the normalized terms on the ImplicationsToDoList:
while notEmpty(ImplicationsToDoList)
{ another := removeAnElement(ImplicationsToDoList);
suppose type(another)=Q;
Q::conjoin(another,ontoNC)
Note that this processing may itself add new entries to the ImplicationsToDoList. In
the case that there are many additions being done to the ImplicationsToDoList, a useful
optimization might be to test for and remove redundancies from ImplicationsToDoList. If
there are very few constructors making additions, a different optimization might be applied:
add the above code only to the end of the corresponding constructor’s Conjoin program.
The following is the intended purpose of the component functions used in the
Q::Conjoin function in Figure 3. Note that for any particular constructor (e.g., all),

not every such function needs to be implemented. When using a good optimizing compiler,
default programs for these could be provided, which return constant values. Otherwise,
Conjoin itself should be edited.
431

Borgida

• Q::Universal?(T): Is T equivalent to the top of the hierarchy for that set of
values?
For example, at-least::Universal?
returns true when processing
at-least(0,players). This is used to eliminate unnecessary constructs from the
normal form.
• Q::Incoherent?(T): Is T incoherent by itself ?
For example, some(players ,nothing) is incoherent since nothing has no instances.
• Q::IncoherentWithDifferent(T,This): Is there an inconsistency if we consider
conjoining with other constructors? For example, when Q=at-least, conjoining
at-least(3,players) to a concept already containing at-most(1,players) would
lead to inconsistency.
• Q::SubsumesSame?(T,oldTs): Is T implied by the Q-constructed terms already seen
in oldTs? This is basically the “structural subsumption” part. For example, if
Q=at-least, and oldTs has at-least(4,players), then at-least(3,players) is redundant
• Q::SubsumesDifferent?(T,This): Is T implied by other constructors? For example,
at-least(1,players) is implied by some(players, OLD).
• Q::ConjoinToSame(T,OldTs): Merge T with any preceding terms built with K. For
example, when we combine all(players,GENTLEMAN) with all(players,SCHOLAR),
we obtain all(players,and(GENTLEMAN, SCHOLAR)).
• Q::ConjoinToDifferent(T,This): Produce a stronger T by using information from
other constructors. For example, if we are processing some(player, TALL),then if
the concept This already has all(player,OLD), then some::ConjoinToDifferent
returns the description of some(players,and(TALL,OLD)).
• Q::FindOtherImplications(T,This,ImplicationsToDoList): Add constructors
which are implied because of Q(T), possibly in conjunction with the rest of
the concept, This.
For example, when adding all(players,TALL) to a
concept with at-least(3,players), all::FindOtherImplications would add
some(players,TALL) to the list of constructors to be conjoined to This.

References
Baader, F. (1996). A formal definition for the expressive power of terminological knowledge
representation languages. J. of Logic and Computation, 6, 33–54.
Baader, F., & Hanschke, P. (1991). A scheme for integrating concrete domains into concept
languages. In Proceedings of IJCAI’91.
Baader, F., Hollunder, B., Nebel, B., Profitlich, H.-J., & Franconi, E. (1994). An empirical
analysis of optimization techniques for terminological representation systems - or making kris get a move on. Applied Intelligence, 4, 109–132.
432

Extensible DL Representation and Reasoning

Borgida, A. (1992a). From type systems to knowledge representation: Natural semantics
specifications for description logics. Int. J. of Intelligent and Cooperative Information
Systems, 1, 259–269.
Borgida, A. (1992b). Towards the systematic development of terminological reasoners:
clasp reconstructed. In Proceedings of KR’92.
Borgida, A. (1995). Description logics in data management. IEEE Trans. on Knowledge
and Data Engineering, 7, 671–682.
Borgida, A. (1996). On the relative expressiveness of description logics and predicate logics.
Artificial Intelligence, 82, 353–367.
Borgida, A., Brachman, R. J., McGuinness, D. L., & Resnick, L. A. (1989). classic: A
structural data model for objects. In Proceedings of SIGMOD’89.
Borgida, A., Isbell, C., & McGuinness, D. (1996). Reasoning with black boxes: Handling
test concepts in Classic. In Proceedings of Intern. Workshop on Description Logics
(DL’96).
Borgida, A., & McGuinness, D. L. (1996). Asking queries about frames. In Proceedings of
KR’96.
Borgida, A., & Patel-Schneider, P. F. (1994). A semantics and complete algorithm for subsumption in the classic description logic. Journal of Artificial Intelligence Research,
1, 277–308.
Borgida, A., & Weddell, G. (1997). Uniqueness constraints in description logics. In Proceedings of Conf. on Deductive and Object-Oriented Databases (DOOD’97).
Bresciani, P., Franconi, E., & Tessaris, S. (1995). Implementing and testing expressive
description logics: a preliminary report. In Proceedings of KRUSE’95 Symposium.
Cohen, W., Borgida, A., & Hirsh, H. (1992). Computing least common subsumers in
description logics. In Proceedings of AAAI’92.
Devanbu, P. (1994). Software Information Systems. Ph.D. thesis, Rutgers University, New
Brunswick, NJ, USA.
Devanbu, P., & Jones, M. (1997). The use of description logics in kbse systems. ACM
Transactions on Software Engineering and Methodology, 6.
Devanbu, P., & Litman, D. (1996). Taxonomic plan reasoning. Artificial Intelligence, 84,
1–35.
Donini, F., Lenzerini, M., Nardi, D., Nutt, W., & Schaerf, A. (1998). An epistemic operator
for description logics. Artificial Intelligence, 100, 225–274.
Doyle, J., & Patil, R. (1991). Two theses of knowledge representation: language restrictions, taxonomic classification, and the utility of representation services. Artificial
Intelligence, 48, 261–298.
433

Borgida

Gaines, B. (1993). A class library implementation of a principled open architecture knowledge representation server with plug-in data types. In Proceedings of IJCAI’93.
Genesereth, M. (1983). An overview of meta-level architecture. In Proceedings of AAAI’83.
Greiner, R., & Lenat, D. (1980). rll: A representation language language. In Proceedings
of KR’94.
Horrocks, I. (1998). Using an expressive description logic: Fact or fiction?. In Proceedings
of KR’98.
Horrocks, I., & Patel-Schneider, P. (1998). DL systems comparison. In Proceedings of of
the International Workshop on Description Logics - DL’98.
Lenat, D., & Guha, R. (1990). Building Large Knowledge-Based Systems. Addison Wesley.
MacGregor, R. (1986). A deductive pattern matcher. In Proceedings of AAAI’86.
Padgham, L., & Lambrix, P. (1994). A framework for part-of hierarchies in terminological
logics. In Proceedings of KR’94.
Patel-Schneider, P. (1998). dlp system description. In Proceedings of of the International
Workshop on Description Logics (DL’98).
Rowley, S., Shrobe, H., & Cassels, R. (1986). Joshua: Uniform access to heterogeneous
knowledge structures. In Proc AAAI’86.
Royer, V., & Quantz, J. (1992). Deriving inference rules for terminological logics. In
Proceedings of JELIA’92.
Schaerf, A. (1994). Reasoning with individuals in concept languages. Data and Knowledge
Engineering, 12, 141–176.
Schmidt-Schauss, M. (1989). Subsumption in KL-ONE is undecidable. In Proceedings of
KR’89.
Stockmeyer, L. (1974). The Complexity of Decision Problems in Automata Theory and
Logic. Ph.D. thesis, MIT, Cambridge, MA. Project MAC TR 138.
Vilain, M. (1985). The restricted language architecture of a hybrid representation system.
In Proceedings of IJCAI’85.
von Luck, K., Nebel, B., Peltason, C., & Schmiedel, A. (1987). The anatomy of the back
system. KIT 41, Technical University of Berlin, Berlin, Germany.
Wright, J., Weixelbaum, E., Vesonder, G., Brown, K., Palmer, S., Berman, J., & Moore, H.
(1993). A knowledge-based configurator that supports sales, engineering, and manufacturing at AT&T network systems. AI Magazine, 14, 69–80.

434

Journal of Articial Intelligence Research 10 (1999) 117-167

Submitted 2/98; published 3/99

Modeling Belief in Dynamic Systems
Part II: Revision and Update
Nir Friedman

nir@cs.huji.ac.il

Institute of Computer Science
Hebrew University, Jerusalem, 91904, ISRAEL



http://www.cs.huji.ac.il/ nir

Joseph Y. Halpern

halpern@cs.cornell.edu

Computer Science Department
Cornell University, Ithaca, NY 14853
http://www.cs.cornell.edu/home/halpern

Abstract

The study of belief change has been an active area in philosophy and AI. In recent years
two special cases of belief change, belief revision and belief update, have been studied in
detail. In a companion paper (Friedman & Halpern, 1997), we introduce a new framework
to model belief change. This framework combines temporal and epistemic modalities with a
notion of plausibility, allowing us to examine the change of beliefs over time. In this paper,
we show how belief revision and belief update can be captured in our framework. This
allows us to compare the assumptions made by each method, and to better understand the
principles underlying them. In particular, it shows that Katsuno and Mendelzon's notion
of belief update (Katsuno & Mendelzon, 1991a) depends on several strong assumptions
that may limit its applicability in articial intelligence. Finally, our analysis allow us to
identify a notion of minimal change that underlies a broad range of belief change operations
including revision and update.

1. Introduction
The study of belief change has been an active area in philosophy and articial intelligence.
The focus of this research is to understand how an agent should change her beliefs as a result
of getting new information. Two instances of this general phenomenon have been studied
in detail. Belief revision (Alchourron, Gardenfors, & Makinson, 1985; Gardenfors, 1988)
focuses on how an agent should change her (set of) beliefs when she adopts a particular
new belief. Belief update (Katsuno & Mendelzon, 1991a), on the other hand, focuses on
how an agent should change her beliefs when she realizes that the world has changed. Both
approaches attempt to capture the intuition that an agent should make minimal changes
in her beliefs in order to accommodate the new belief. The dierence is that belief revision
attempts to decide what beliefs should be discarded to accommodate a new belief, while
belief update attempts to decide what changes in the world led to the new observation.1
1. Throughout the paper we use \revision" to refer to AGM's proposal for revision (Alchourron et al., 1985)
not as a generic term for the general approach initiated by AGM; similarly, we use \update" to refer to
KM's proposal for update (Katsuno & Mendelzon, 1991a).

c 1999 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

Friedman & Halpern

Belief revision and belief update are two of many possible ways of modeling belief change.
In (Friedman & Halpern, 1997), we introduce a general framework for modeling belief
change. We start with the framework for analyzing knowledge in multi-agent systems,
introduced in (Halpern & Fagin, 1989), and add to it a measure of plausibility at each
situation. We then dene belief as truth in the most plausible situations. The resulting
framework is very expressive; it captures both time and knowledge as well as beliefs. Having
time allows us to reason in the framework about changes in the beliefs of the agent. It also
allows us to relate the beliefs of the agent about the future with her actual beliefs in the
future. Knowledge captures in a precise sense the non-defeasible information the agent has
about the world, while belief captures the defeasible assumptions implied by her plausibility
assessment. The framework allows us to represent a broad spectrum of notions of belief
change. In this paper, we focus on how, in particular, belief revision and update can be
represented.
We are certainly not the rst to provide semantic models for belief revision and update.
For example, (Alchourron et al., 1985; Grove, 1988; Gardenfors & Makinson, 1988; Rott,
1991; Boutilier, 1992; de Rijke, 1992) deal with revision, and (Katsuno & Mendelzon, 1991a;
del Val & Shoham, 1992) deal with update. In fact, there are several works in the literature
that capture both using the same machinery (Katsuno & Satoh, 1991; Goldszmidt & Pearl,
1996; Boutilier, 1998), and others that simulate belief revision using belief update (Grahne,
Mendelzon, & Rieter, 1992; del Val & Shoham, 1994). Our approach is dierent from most
in that we do not construct a specic framework to capture one or both of these belief
change paradigms. Instead, we start from a natural framework to model how an agent's
knowledge changes over time and add to it machinery that captures a defeasible notion of
belief.
We believe that our representation oers a number of advantages, and gives a deeper
understanding of both revision and update. For one thing, we show that both revision and
update can be viewed as proceeding by conditioning on initial prior plausibilities. Thus,
our representation emphasizes the role of conditioning as a way of understanding minimal
change. Moreover, it shows that that the major dierences between revision and update
can be understood as corresponding to dierences in initial beliefs. For example, revision
places full belief on the assumption that the propositions used to describe the world are
static, and do not change their truth value over time. By way of contrast, update allows for
the possibility that propositions change their truth value over time. However, the family of
prior plausibilities that we use to capture update in our framework have the property that
they prefer sequences of events where abnormal events occur as late as possible. Because of
this property, conditioning in update always \explains" observations by recent changes. The
fact that time appears explicitly in our framework allows us to make these issues precise.
In the literature, revision has been viewed as dealing with static worlds (although an
agent's beliefs may change, the underlying world about which the agent is reasoning does
not) while update has been viewed as dealing with dynamic worlds (see, for example, (Katsuno & Mendelzon, 1991a)). We believe that the distinction between static and dynamic
worlds is somewhat misleading. In fact, what is important for revision is not that the world
is static, but that the propositions used to describe the world are static. For example, \At
time 0 the block is on the table" is a static proposition, while \The block is on the table" is
not, since it implicitly references the current state of aairs. (Note that the assumption that
118

Modeling Belief in Dynamic Systems. Part II.

the propositions are static is not unique to belief revision. Bayesian updating, for example,
makes similar assumptions.) Because we model time explicitly in our framework, we can
examine this issue in more detail. In fact, in Section 7, we show how we relate these two
viewpoints. More precisely, given a system, we replace each proposition p used in the system
by a family of propositions \p is true at time m", one for each time m. The resulting system
describes exactly the same process as the original system, but from a dierent linguistic perspective. As we show, if the original system corresponds to KM update, then the resulting
system is very close to satisfying the requirements of AGM revision. The only requirement
that is not met is that the prior is totally ordered, or ranked. This requirement, however,
has been relaxed in several variants of revision (Katsuno & Mendelzon, 1991b; Rott, 1992).
Thus, a large part of the dierence between revision and update can be understood as a
dierence in the language used to describe what is happening.
The generality of our framework forces us to be clear about the assumptions we make
in the process of capturing revision and update. As a consequence, we have to deal with
issues that have been largely ignored by previous semantic accounts. One of these issues
is the status of observations. As we show below, to capture either revision or update, we
have to assume that observations are minimally informative|the only information carried
by an observation of ' is that ' should be believed. This is a strong assumption, since
most observations carry additional information. For example, when trekking in Nepal,
one does not expect to observe the weather in Boston. If an agent observes that it is in
fact raining in Boston, then this \observation" might well provide extra information about
the world (for example, that cable television is available in Nepal). We remark that in
(Boutilier, Friedman, & Halpern, 1998) there is a treatment of revision in our framework
where observations are allowed to convey additional information.
Finally, our representation makes it clear how the intuitions of revision and update
can be applied in settings where the postulates used to describe them are not sound. For
example, we consider situations where they may be irreversible changes (such as death,
or breaking a glass vase), and where the agent may perform actions beyond just making
observations. Revision and update, as they stand, cannot handle such situations. As we
show, our framework allows us to extend them in a natural way so they do.
The rest of the paper is organized as follows. In Section 2, we give an overview of the
framework we introduced in (Friedman & Halpern, 1997). In Section 3, we give a brief review
of belief revision and belief update. In Section 4, we dene a specic class of structures
that embody assumptions that are common to both update and revision. In Section 5,
we describe additional assumptions that are required to capture revision. In Section 6, we
describe the assumptions that are required to capture update. In Section 7, we reexamine
the dierences and similarities between belief revision and update. In Section 8, we consider
possible extensions to the setup of revision and update, and discuss how these extensions
can be handled in our framework. Finally, in Section 9, we conclude with a discussion of
related and future work.
119

Friedman & Halpern

2. The Framework
We now review the framework of Halpern and Fagin (1989) for modeling knowledge, and our
extension of it for dealing with belief change. The reader is encouraged to consult (Fagin,
Halpern, Moses, & Vardi, 1995) for further details and motivation.

2.1 Modeling Knowledge

The framework of Halpern and Fagin was developed to model knowledge in distributed
(i.e., multi-agent) systems (Halpern & Fagin, 1989; Fagin et al., 1995). In this paper, we
restrict our attention to the single agent case. The key assumption in this framework is that
we can characterize the system by describing it in terms of a state that changes over time.
Formally, we assume that at each point in time, the agent is in one of a possibly innite
set of (local) states. At this point, we do not put any further structure on these states
(although, as we shall see from our examples, when we model situations in a natural way,
states typically do have a great deal of meaningful structure). Intuitively, this local state
encodes the information the agent has observed thus far. There is also an environment,
whose state encodes relevant aspects of the system that are not part of the agent's local
state.
A global state is a pair (se ; sa ) consisting of the environment state se and the local state
sa of the agent. A run of the system is a function from time (which, for ease of exposition,
we assume ranges over the natural numbers) to global states. Thus, if r is a run, then
r(0); r(1); : : : is a sequence of global states that, roughly speaking, is a complete description
of what happens over time in one possible execution of the system. Given a run r, we can
dene two functions re and ra that map from time to states of the environment and the
agent, respectively, by taking re (m) to be the state of the environment in the global state
r(m) and ra(m) to be the agent's local state in r(m). We can thus identify run r with the
pair of functions hre; rai. We take a system to consist of a set of runs. Intuitively, these
runs describe all the possible behaviors of the system, that is, all the possible sequences of
events that could occur in the system over time.
Given a system R, we refer to a pair (r; m) consisting of a run r 2 R and a time m
as a point. We say two points (r; m) and (r0; m0) are indistinguishable to the agent, and
write (r; m) a (r0; m0), if ra(m) = ra0 (m0), i.e., if the agent has the same local state at both
points. Finally, an interpreted system I is a tuple (R;  ) consisting of a system R together
with a mapping  that associates with each point a truth assignment to a set  of primitive
propositions. In an interpreted system we can talk about an agent's knowledge: the agent
knows ' at a point (r; m) if ' holds in all points (r0; m0) such that (r; m) a (r0; m0).
Intuitively, an agent knows ' at (r; m) if ' is implied by the information in the local state
ra(m). We give formal semantics for a language of knowledge (and time and plausibility)
in Section 2.3.

Example 2.1: The circuit diagnosis problem has been well studied in the literature (see
(Davis & Hamscher, 1988) for an overview). Consider a circuit that contains n logical
components c1; : : :; cn and k lines l1; : : :; lk . The agent can set the values on the input lines
of the circuit and observe the values on the output lines. The agent then compares the actual
output values to the expected output values and attempts to locate faulty components.
120

Modeling Belief in Dynamic Systems. Part II.

Since a single test is usually insucient to locate the problem, the agent might perform a
sequence of such tests.
We want to model diagnosis using an interpreted system. To do so, we need to describe
the agent's local state, the state of the environment, and some appropriate propositions
for reasoning about diagnosis. Intuitively, the agent's state is the sequence of input-output
relations observed, while the environment's state describes the current state of the circuit.
This consists of the failure set , that is, the set of faulty components of the circuit and the
values on all the lines in the circuit. Each run describes the results of a specic series of
tests the agent performs and the results she observes. We make two additional assumptions:
(1) the agent does not forget what tests were performed and their results, and (2) the faults
are persistent and do not change over time.
To make this precise, we dene the environment state at a point (r; m) to consist of
the failure set at (r; m), which we denote fault(r; m), as well as the values of all the lines
in the circuit. We require that the environment state be consistent with the description
of the circuit. Thus, for example, if c1 is an AND gate with input lines l1 and l2 and
output line l3, then if re (m) says that c1 is not faulty, then we require that there is a
1 on l3 if and only if there is a 1 on both l1 and l2.2 We capture the assumption that
faults are persistent by requiring that fault(r; m) = fault(r; 0). For our later results, it is
useful to describe the agent's observations using our logical language. Consider the set
diag = ff1 ; : : :; fn ; h1; : : :; hk g of primitive propositions, where fi denotes that component
i is faulty and hi denotes that there is a 1 on line i (that is, line i in a \high" state). An
observation is a conjunction of literals of the form hi and :hi . The agent's state at time
m is a sequence of m such observations. Formally, we dene the agent's state ra(m) to
be ho1 ; : : :; omi, where, intuitively, ok is the formula describing the input-output relation
observed at time k. We use the notation io(r; k) to denote the formula describing the
observation made by the agent at the point (r; k). Given this language, we can dene the
interpretation diag in the obvious way. We say that an observation o is consistent with an
environment state re (m) if the states of the input/output lines in re (m) agree with these in
o. The system Rdiag consists of all runs r satisfying these requirements in which io(r; m) is
consistent with re (m) for all times m.
Given the system (Rdiag ; diag ), we can examine the agent's knowledge after making a
sequence of observations o1; : : :; om . It is easy to see that the agent knows that the fault set
must be one with which all the observations are consistent. However, the agent cannot rule
out any of these fault sets. Thus, even if all the observations are consistent with the circuit
being fault-free, the agent does not know that the circuit is fault-free, since there might be
a fault that manifests itself only in congurations that have not yet been tested. Of course,
the agent might strongly believe that the circuit is fault-free, but we cannot (yet) express
this fact in our formalism. The next section recties this problem. ut
2. Note that this means that we can recover the behavior of the circuit (although not necessarily its exact
description) by simply looking at the environment state at a point where there are no failures. Of course,
if we could have a yet richer environment state that encodes the actual description of the circuit, but
this is unnecessary for the analysis we do here.

121

Friedman & Halpern

2.2 Plausibility Measures

Most non-probabilistic approaches to belief change require (explicitly or implicitly) that
the agent has some ordering over possible alternatives. For example, the agent might
have a preference ordering over possible worlds (Boutilier, 1994b; Grove, 1988; Katsuno &
Mendelzon, 1991b) or an entrenchment ordering over formulas (Gardenfors & Makinson,
1988). This ordering dictates how the agent's beliefs change. For example, in (Grove, 1988),
the new beliefs are characterized by the most preferred worlds that are consistent with the
new observation, while in (Gardenfors & Makinson, 1988), beliefs are discarded according
to their degree of entrenchment until it is consistent to add the new observation to the
resulting set of beliefs. We represent this ordering using plausibility measures , which were
introduced in (Friedman & Halpern, 1995, 1998b). We briey review the relevant denitions
and results here.
Recall that a probability space is a tuple (W; F ; Pr), where W is a set of worlds, F is
an algebra of measurable subsets of W (that is, a set of subsets closed under union and
complementation to which we assign probability), and Pr is a probability measure, that is, a
function mapping each set in F to a number in [0; 1] satisfying the well-known probability
axioms (Pr(;) = 0, Pr(W ) = 1, and Pr(A [ B ) = Pr(A) + Pr(B ), if A and B are disjoint).
Plausibility spaces are a direct generalization of probability spaces. We simply replace
the probability measure Pr by a plausibility measure Pl, which, rather than mapping sets in
F to numbers in [0; 1], maps them to elements in some arbitrary partially ordered set. We
read Pl(A) as \the plausibility of set A". If Pl(A)  Pl(B ), then B is at least as plausible
as A. Formally, a plausibility space is a tuple S = (W; F ; Pl), where W is a set of worlds, F
is an algebra of subsets of W , and Pl maps sets in F to some domain D of plausibility values
partially ordered by a relation D (so that D is reexive, transitive, and anti-symmetric).
We assume that D is pointed : that is, it contains two special elements >D , and ?D such
that ?D D d D >D for all d 2 D; we further assume that Pl(W ) = >D and Pl(;) =?D .
As usual, we dene the ordering <D by taking d1 <D d2 if d1 D d2 and d1 6= d2 . We omit
the subscript D from D , <D , >D , and ?D whenever it is clear from context.
Since we want a set to be at least as plausible as any of its subsets, we require
A1 If A  B, then Pl(A)  Pl(B).
Some brief remarks on this denition: We have deliberately suppressed the domain D
from the tuple S , since for the purposes of this paper, only the ordering induced by  on
the subsets in F is relevant. The algebra F also does not play a signicant role in this
paper. Unless we say otherwise, we assume F contains all subsets of interest and suppress
mention of F , denoting a plausibility space as a pair (W; Pl).
Clearly plausibility spaces generalize probability spaces. In (Friedman & Halpern, 1998b,
1995) we show that they also generalize belief function (Shafer, 1976), fuzzy measures (Wang
& Klir, 1992), possibility measures (Dubois & Prade, 1990), ordinal ranking (or -ranking )
(Goldszmidt & Pearl, 1996; Spohn, 1988), preference orderings (Kraus, Lehmann, & Magidor, 1990; Shoham, 1987), and parameterized probability distributions (Goldszmidt, Morris,
& Pearl, 1993) that are used as a basis for Pearl's -semantics for defaults (Pearl, 1989).
Our goal is to describe the agent's beliefs in terms of plausibility. To do this, we describe
how to evaluate statements of the form B' given a plausibility space. In fact, we use a
richer logical language that also allows us to describe how the agent compares dierent
122

Modeling Belief in Dynamic Systems. Part II.

alternatives. This is the logic of conditionals. Conditionals are statements of the form
' , read \given ', is plausible" or \given ', then by default ". The syntax of the
logic of conditionals is simple: we start with primitive propositions and close o under
conjunction, negation and the modal operator . The resulting language is denoted LC .
A plausibility structure is a tuple PL = (W;Pl;  ), where W is a set of possible worlds,
Pl is a plausibility measure on W , and  (w) is a truth assignment to primitive propositions.
Given a plausibility structure PL = (W;Pl;  ), we dene [ '] PL = fw 2 W :  (w) j= 'g to
be the set of worlds that satisfy '. We omit the subscript PL, when it is clear from the
context. Conditionals are evaluated according to a rule that is essentially the same as the
one used by Dubois and Prade (1991) to evaluate conditionals using possibility measures:
 PL j= ' if either Pl([['] ) =? or Pl([[' ^ ] ) > Pl([[' ^ : ] ).
Intuitively, '
holds vacuously if ' is impossible; otherwise, it holds if ' ^ is more
plausible than ' ^ : . As we show in (Friedman & Halpern, 1998b), this semantics of
conditionals also generalizes the semantics of conditionals in -ranking (Goldszmidt & Pearl,
1996), and PPD structures (Goldszmidt et al., 1993). As we also show in (Friedman &
Halpern, 1998b), this semantics for conditionals generalizes the semantics of preferential
structures. As this relationship plays a role in the discussion below, we review the necessary
denitions here. A preferential structure is a tuple (W; ;  ), where  is a partial order
on W . Roughly speaking, w  w0 holds if w is preferred to w0 .3 The intuition (Shoham,
1987) is that a preferential structure satises a conditional '
if all the most preferred
worlds (i.e., the minimal worlds according to ) in [ '] satisfy . However, there may be
no minimal worlds in [ '] . This can happen if [ '] contains an innite descending sequence
: : :  w2  w1. What do we do in these structures? There are a number of options: the rst
is to assume that, for each formula ', there are minimal worlds in [ '] ; this is the assumption
actually made in (Kraus et al., 1990), where it is called the smoothness assumption. A yet
more general denition|one that works even if  is not smooth|is given in (Lewis, 1973;
Boutilier, 1994a). Roughly speaking, '
is true if, from a certain point on, whenever '
is true, so is . More formally,
(W; ;  ) satises ' , if for every world w1 2 [ '] , there is a world w2 such
that (a) w2  w1 (so that w2 is at least as normal as w1), (b) w2 2 [ ' ^ ] , and
(c) for all worlds w3  w2 , we have w3 2 [ ' ) ] (so any world more normal
than w2 that satises ' also satises ).
It is easy to verify that this denition is equivalent to the earlier one if  is smooth.

!

!

!
!

!

!

!

Proposition 2.2: (Friedman & Halpern, 1998b) If  is a preference ordering on W ,
then there is a plausibility measure Pl on W such that (W; ;  ) j= '! if and only if
(W; Pl ;  ) j= '! .
We briey describe the construction of Pl here, since we use it in the sequel. Given
a preference order  on W , let D0 be the domain of plausibility values consisting of one
3. We follow the standard notation for preference here (Kraus et al., 1990), which uses the (perhaps confusing) convention of placing the more likely (or less abnormal) world on the left of the  operator.
Unfortunately, when translated to plausibility, this will mean w  w0 holds i Pl(fwg > Pl(fw0 g).

123

Friedman & Halpern

element dw for every element w 2 W . We dene a partial order on D0 using : dv < dw
if w  v . (Recall that w  w0 denotes that w is preferred to w0.) We then take D to be
the smallest set containing D0 that is closed under least upper bounds (so that every set
of elements in D has a least upper bound in D). For a subset A of W , we can then dene
Pl (A) to be the least upper bound of fdw : w 2 Ag. Since D is closed under least upper
bounds, Pl(A) is well dened. As we show in (Friedman & Halpern, 1998b), this choice of
Pl satises Proposition 2.2.
The results of (Friedman & Halpern, 1998b) show that this semantics for conditionals
generalizes previous semantics for conditionals. Does this semantics capture our intuitions
about conditionals? In the AI literature, there has been little consensus on the \right"
properties for defaults (which are essentially conditionals). However, there has been some
consensus on a reasonable \core" of inference rules for default reasoning. This core is usually
known as the KLM properties (Kraus et al., 1990), and includes such properties as
AND From ' 1 and ' 2 infer ' 1 ^ 2
OR From '1 and '2 infer '1 _ '2
What constraints on plausibility spaces gives us the KLM properties? Consider the following
two conditions:
A2 If A, B, and C are pairwise disjoint sets, Pl(A[B) > Pl(C ), and Pl(A[C ) >
Pl(B ), then Pl(A) > Pl(B [ C ).
A3 If Pl(A) = Pl(B) =?, then Pl(A [ B) =?.
A plausibility space (W; Pl) is qualitative if it satises A2 and A3. A plausibility structure (W; Pl;  ) is qualitative if (W; Pl) is a qualitative plausibility space. In (Friedman &
Halpern, 1998b), we show that, in a very general sense, qualitative plausibility structures
capture default reasoning. More precisely, we show that the KLM properties are sound
with respect to a class of plausibility structures if and only if the class consists of qualitative plausibility structures. (We also provide a weak condition that we show is necessary
and sucient for the KLM properties to be complete.) These results show that plausibility
structures provide a unifying framework for the characterization of default entailment in
these dierent logics.

!
!

!
!

!

2.3 Plausibility and Knowledge

!

In (Friedman & Halpern, 1997) we show how plausibility measures can be incorporated into
the multi-agent system framework of (Halpern & Fagin, 1989). This allows us to describe
the agent's assessment of the possible states the system is in at each point in time. At the
same time we also introduce conditionals into the logical language in order to reason about
these plausibility assessments. We now review the relevant details.
An (interpreted) plausibility system is a tuple (R; ; P ) where, as before, R is a set
of runs and  maps each point to a truth assignment, and where P is a plausibility assignment function mapping each point (r; m) to a qualitative plausibility space P (r; m) =
(W(r;m); Pl(r;m)). Intuitively, the plausibility space P (r; m) describes the relative plausibility of events from the point of view of the agent at (r; m). In this paper, we restrict our
attention to plausibility spaces that satisfy two additional assumptions:
124

Modeling Belief in Dynamic Systems. Part II.

 W(r;m) = f(r0; m0)j(r; m) a (r0; m0)g. Thus, the agent considers plausible only situa-

tions that are possible according to her knowledge.
 if (r; m) a (r0; m0) then P (r; m) = P (r0; m0). This means that the plausibility space
is a function of the agent's local state.4
We dene a logical language to reason about interpreted systems. The syntax of the logic
is simple; we start with primitive propositions and close o under conjunction, negation,
the K modal operator (K' says that the agent knows '), the  modal operator (' says
that ' is true at the next time step), and the modal operator. The resulting language
is denoted LKPT .5 We recursively assign truth values to formulas in LKPT at a point (r; m)
in a plausibility system I . The truth of primitive propositions is determined by  , so that
(I ; r; m) j= p if  (r; m)(p) = true.
Conjunction and negation are treated in the standard way, as is knowledge: The agent
knows ' at (r; m) if ' holds at all points that she cannot distinguish from (r; m). Thus,
(I ; r; m) j= K' if (I ; r0; m0) j= ' for all (r0; m0) a (r; m).
' is true at (r; m) if ' is true at (r; m + 1). Thus,
(I ; r; m) j= ' if (I ; r; m + 1) j= '.
Finally, we dene the conditional operator to describe the agent's plausibility assessment
at the current time. Let [ '] (r;m) = f(r0; m0) 2 W(r;m) : (I ; r; m) j= 'g.

!

!

!

(I ; r; m) j= '

if either Pl(r;m) ([['] (r;m)) = ? or Pl(r;m)([[' ^ ] (r;m)) > Pl(r;m) ([[' ^ : ] (r;m)).

We now dene a notion of belief. Intuitively, the agent believes ' if ' is more plausible
than not. Formally, we dene B' , (true ').
In (Friedman & Halpern, 1997) we prove that, in this framework, knowledge is an S5
operator, the conditional operator satises the usual axioms of conditional logic (Burgess,
1981), and  satises the usual properties of temporal logic (Manna & Pnueli, 1992). In
addition, these properties imply that belief is a K45 operator, and the interactions between
knowledge and belief are captured by the axioms K' ) B' and B' ) KB'.

!

!

Example 2.3: (Friedman & Halpern, 1997) We add a plausibility measure to the system
dened in Example 2.1. We dene Idiag = (Rdiag ; diag ; Pdiag ), where Pdiag is the plausi-

bility assignment we now describe. We assume that failures of individual components are
independent of one another. If we also assume that the likelihood of each component failing
is the same, and also that this likelihood is small (i.e., failures are exceptional), then we
can construct a plausibility measure as follows. If (r0; m) and (r00; m) are two points in
W(r;m), we say that (r0; m) is more plausible than (r00; m) if jfault(r0; m)j < jfault(r00; m)j,
4. The framework presented in (Friedman & Halpern, 1997) is more general than this, dealing with multiple
agents and allowing the agent to consider several plausibility spaces in each local state. The simplied
version we present here suces to capture belief revision and update.
5. It is easy to add other temporal modalities such as until, eventually, since , etc. These do not play a role
in this paper.

125

Friedman & Halpern

that is, if the failure set at (r0; m) consists of fewer faulty components than at (r00; m). We
extend these comparisons to sets: Pl(r;m) (A)  Pl(r;m)(B ) if min(r0 ;m)2A (jfault(r0; m)j) 
min(r0 ;m)2B (jfault(r0; m)j); that is, A is less plausible if all the points in A have failure sets
of larger cardinality then the minimal one in B . With this plausibility measure, if all of
the agent's observations up to time m are consistent with there being no failures, then
the agent believes that all components are functioning correctly. On the other hand, if
the observations do not match the expected output of the circuit, then the agent considers
minimal failure sets that are consistent with her observations. Thus, if the observations are
consistent with a failure of c1, or a failure of c3 , or the combined failure of c2 and c7, then
the agent believes that either c1 or c3 is faulty, but not both.
We now make this more precise. A failure set (i.e., a diagnosis) is characterized by a
complete formula over f1 ; : : :; fn |that is, one that determines the truth values all these
propositions. For example, if n = 3, then f1 ^:f2 ^:f3 characterizes the failure set fc1g. We
dene D(r;m) to be the set of failure sets (i.e., diagnoses) that the agent considers possible
at (r; m); that is D(r;m) = ff 2 F : (Idiag ; r; m) j= :B :f g where F is the set of all possible
failure sets.
Belief change in Idiag is characterized by the following proposition.

Proposition 2.4: If there is some f 2 D(r;m) that is consistent with the new observation

io(r; m + 1), then D(r;m+1) consists of all the failure sets in D(r;m) that are consistent with
io(r; m +1). If all f 2 D(r;m) are inconsistent with io(r; m +1), then D(r;m+1) consists of all
failure sets of cardinality j that are consistent with io(r; 1); : : :; io(r; m + 1), where j is the
least cardinality for which there is at least one failure set consistent with these observations.

Thus, in Idiag , a new observation consistent with the current set of most likely explanations
reduces this set (to those consistent with the new observation). On the other hand, a
surprising observation (one inconsistent with the current set of most likely explanations)
has a rather drastic eect. It easily follows from Proposition 2.4 that if io(r; m + 1) is
surprising, then D(r;m) \ D(r;m+1) = ;, so the agent discards all her current explanations
in this case. Moreover, an easy induction on m shows that if D(r;m) \ D(r;m+1) = ;, then
the cardinality of the failure sets in D(r;m+1) is greater than the cardinality of failure sets
in D(r;m). Thus, in this case, the explanations in D(r;m+1) are more complicated than those
in D(r;m). ut

2.4 Conditioning

In an interpreted system, the agent's beliefs change from point to point as her plausibility
space changes. The general framework does not put any constraints on how the plausibility
space changes. If we were thinking probabilistically, we could imagine the agent starting
with a prior on the runs in the system. Since a run describes a complete history over
time, this means that the agent puts a prior probability on the possible sequences of events
that could happen. We would then expect the agent to modify her prior by conditioning
on whatever information she has learned. As we show below, this notion of conditioning is
closely related to belief revision and update. We remark that we are not the rst to applying
conditioning in the context of belief change (cf. (Goldszmidt & Pearl, 1996; Spohn, 1988));
the details are a little more complex in our framework, because we model time explicitly.
126

Modeling Belief in Dynamic Systems. Part II.

We start by making the simplifying assumption that we are dealing with synchronous
systems where agents have perfect recall (Halpern & Vardi, 1989). Intuitively, this means
that the agent knows what the time is and does not forget the observations she has made.
Formally, a system is synchronous if (r; m) a (r0; m0) only if m = m0 . In synchronous
systems, the agent has perfect recall if (r0; m + 1) a (r; m + 1) implies (r0; m) a (r; m).
Thus, the agent considers run r possible at the point (r; m + 1) only if she also considers
it possible at (r; m). This means that any runs considered impossible at (r; m) are also
considered impossible at (r; m + 1): the agent does not forget what she knew.
Just as with probability, we assume that the agent has a prior plausibility measure on
runs that describes her prior assessment on the possible executions of the system. As the
agent gains knowledge, she updates her prior by conditioning. More precisely, at each point
(r; m), the agent conditions her previous assessment on the set of runs considered possible
at (r; m). This results in an updated assessment (posterior) of the plausibility of runs. This
posterior induces, via a projection from runs to points, a plausibility measure on points.
We can think of the agent's posterior at time m as simply her prior conditioned on her
knowledge at time m.
Formally, the prior plausibility of the agent is a plausibility measure Pa = (R; Pla ) over
the runs in the system. If A is a set of points, we dene R(A) = fr : 9m((r; m) 2 A)g to be
the set of runs on which the points in A lie. The agent updates plausibilities by conditioning
in I if the following condition is met:
PRIOR There is prior Pa = (R; Pla) such that for all runs r 2 R, times m,
and sets A; B  W(r;m), Pl(r;m) (A)  Pl(r;m) (B ) if and only if Pla (R(A)) 
Pla (R(B )).
This denition implies that the agent's plausibility assessment at each point is determined,
in a straightforward fashion, by her prior.
As shown in (Friedman & Halpern, 1997), in synchronous systems that satisfy PRIOR
where agent have perfect recall, we can say even more: the agent's plausibility measure at
time m + 1 is determined by her plausibility measure at time m. To make this precise, if A
is a set of points, let prev(A) = f(r; m) : (r; m + 1) 2 Ag.

Theorem 2.5: (Friedman & Halpern, 1997). Let I be a synchronous system satisfying
PRIOR where agents have perfect recall. Then Pl(r;m+1)(A)  Pl(r;m+1) (B ) if and only if
Pl(r;m)(prev(A))  Pl(r;m)(prev(B )), for all runs r, times m, and sets A; B  W(r;m+1).
Thus, in synchronous systems where agents have perfect recall PRIOR implies a \local"
rule for update that incrementally changes the agent's plausibility at each step. This local
rule consists of two steps. First, the agent's plausibility at time m is projected to time
m + 1 points. Second, time m + 1 points that are inconsistent with the agent knowledge at
(r; m + 1) are discarded. This procedure implies that the relative plausibility of two sets of
runs does not change unless one of them is incompatible with the new knowledge.

Example 2.6: It is easy to verify that the system Idiag we consider in Example 2.3 satises
PRIOR. The prior Pa is determined by the failure set in each run in a manner similar to
the construction of Pl(r;m) . That is, R1 is more plausible than R2 if there is a run in R1
with a smaller failure set than all the runs in R2 . ut
127

Friedman & Halpern

3. Review of Revision and Update
We now present a brief review of belief revision and update.
Belief revision attempts to describe how a rational agent incorporates new beliefs. As
we said earlier, the main intuition is that as few changes as possible should be made. Thus,
when something is learned that is consistent with earlier beliefs, it is just added to the set of
beliefs. The more interesting situation is when the agent learns something inconsistent with
her current beliefs. She must then discard some of her old beliefs in order to incorporate
the new belief and remain consistent. The question is which ones?
The most widely accepted notion of belief revision is dened by the AGM theory (Alchourron et al., 1985; Gardenfors, 1988). This theory was originally developed in philosophy
of science, where one attempts to understand when a scientist changes her beliefs (e.g., theory of physical laws) in a rational manner. In this context, it seems reasonable to assume
that the world is static ; that is, the laws of physics do not change while the scientist is
performing experiments.
Formally, this theory assumes a logical language Le over a set e of primitive propositions with a consequence relation `L that contains the propositional calculus and satises
the deduction theorem. The AGM approach assumes that an agent's epistemic state is
represented by a belief set, that is, a set K of formulas in the language Le .6 There is also
assumed to be a revision operator  that takes a belief set A and a formula ' and returns a
new belief set A  ', intuitively, the result of revising A by '. The following AGM postulates
are an attempt to characterize the intuition of \minimal change":
e

(R1)
(R2)
(R3)
(R4)
(R5)
(R6)
(R7)
(R8)

A  ' is a belief set
'2A'
A  '  Cl(A [ f'g)7
If :' 62 A then Cl(A [ f'g)  A  '
A  ' = Cl(false) if and only if `L :'
If `L ' , then A  ' = A 
A  (' ^ )  Cl(A  ' [ f g)
If : 62 A  ' then Cl(A  ' [ f g)  A  (' ^ ).
e

e

The essence of these postulates is the following. After a revision by ' the belief set
should include ' (postulates R1 and R2). If the new belief is consistent with the belief set,
then the revision should not remove any of the old beliefs and should not add any new beliefs
except these implied by the combination of the old beliefs with the new belief (postulates
R3 and R4). This condition is called persistence . The next two conditions discuss the
coherence of beliefs. Postulate R5 states that the agent is capable of incorporating any
consistent belief and postulate R6 states that the syntactic form of the new belief does
not aect the revision process. The last two postulates enforce a certain coherency on the
6. For example, Gardenfors (1988, p. 21) says \A simple way of modeling the epistemic state of an individual
is to represent it by a set of sentences."
7. Cl(A) = f'jA `Le 'g is the deductive closure of a set of formulas A.

128

Modeling Belief in Dynamic Systems. Part II.

outcome of revisions by related beliefs. Basically, they state that if is consistent with
A  ' then A  (' ^ ) is just A  '  .
The notion of belief update originated in the database community (Keller & Winslett,
1985; Winslett, 1988). The problem is how a knowledge base should change when something
is learned about the world. For example, suppose that a transaction adds to the knowledge
base the fact \Table 7 is in Oce 2", which contradicts the previous belief that \Table 7
is in Oce 1". What else should change? The intuition that update attempts to capture
is that such a transaction describes a change that has occurred in the world. Thus, in our
example, by applying update we might conclude that the reason that the table is in Oce
2 is that it was moved, not that our earlier beliefs were false. This example shows that,
unlike revision, update does not assume that the world is static.
Katsuno and Mendelzon (1991a) suggest a set of postulates that an update operator
should satisfy. The update postulates are expressed in terms of formulas, not belief sets.
That is, an update operator  maps a pair of formulas, one describing the agent's current
beliefs and the other describing the new observation, to a new formula that describes the
agent's updated beliefs. This is not unreasonable, since we can identify a formula ' with
the belief set Cl('). Indeed, if  is nite (which is what Katsuno and Mendelzon assume)
every belief set A can be associated with some formula 'A such that Cl('A) = A, and
every formula ' corresponds to a belief set Cl('). Thus, any update operator induces an
operator that maps a belief state and an observation to a new belief state. We slightly
abuse notation and use the same symbol to denote both types of mappings. We say that
a belief set A is complete if, for every ' 2 Le , either ' 2 A or :' 2 A. A formula  is
complete if Cl() is complete.
The KM postulates are:
(U1) `L   ' ) '
(U2) If `L  ) ', then `L   ' , 
(U3) `L :  ' if and only if `L : or `L :'
(U4) If `L 1 , 2 and `L '1 , '2 then `L 1  '1 , 2  '2
(U5) `L (  ') ^ )   (' ^ )
(U6) If `L   '1 ) '2 and `L   '2 ) '1, then `L   '1 ,   '2
(U7) If  is complete then `L (  '1 ) ^ (  '2) )   ('1 _ '2)
(U8) `L (1 _ 2 )  ' , (1  ') _ (2  ').
The essence of these postulates is as following. After learning ', the agent believes '
(postulate U1, which is analogous to R2). If ' is already believed, then updating by ' does
not change the agent's beliefs (postulate U2, which is a weaker version of R3 and R4). The
next two postulates (U3 and U4) deal with coherence of the belief change process. They
are analogous to R5 and R6, respectively, with minor dierences. Postulates U5 and U6
deal with observations that are related to each other. U5 states that beliefs after learning
' that are consistent with are also believed after learning ' ^ . U6 states that if '2 is
believed after learning '1 and '1 is believed after learning '2, then learning either '1 or
'2 leads to the same belief set. Finally, U7 and U8 deal with decomposition properties of
the update operation. U7 states that if  is essentially a truth assignment to L, then if
e

e

e

e

e

e

e

e

e

e

e

e

e

e

e

129

Friedman & Halpern

is believed after learning '1 and is also believed after learning '2 then it is believed after
learning '1 _ '2 . U8 states that the update of the knowledge base can be computed by
independent updates on each sub-part of the knowledge. That is, if  = 1 _ 2 , then we
can apply update to each of 1 and 2 , and then combine the results.

4. Belief Change Systems

We want to model belief change|particularly belief revision and belief update|in the
framework of systems. To do so, we consider a particular class of systems that we call
belief change systems. In belief change systems, the agent makes observations about an
external environment. Just as is (implicitly) assumed in both revision and update, we
assume that these observations are described by formulas in some logical language. We
then make other assumptions regarding the plausibility measure used by the agent. We
formalize our assumptions as conditions BCS1{BCS5, described below, and say that a
system I = (R; ; P ) is a belief change system if it satises these conditions. We denote by
C BCS the set of belief change systems.
Assumption BCS1 formalizes the intuition that our language includes propositions for
reasoning about the environment, whose truth depends only on the environment state.

BCS1 The language L includes a propositional sublanguage Le over a set e
of primitive propositions. Le contains the usual propositional connectives and
comes equipped with a consequence relation `L . The interpretation  (r; m)
e

assigns truth to propositions in e in such a way that

(a)  (r; m) is consistent with `L , that is, fp : p 2 e ;  (r; m)(p) = trueg [
f:p : p 2 e; (r; m)(p) = falseg is `L consistent, and
(b)  (r; m)(p) depends only on re (m) for propositions in e ; that is,  (r; m)(p) =
(r0; m0)(p) whenever re (m) = re0 (m0 ).
e

e

Part (b) of BCS1 implies that we can evaluate formulas in Le with respect to environment
states; that is, if ' 2 Le and re (m) = re0 (m0), then (I ; r; m) j= ' if and only if (I ; r0; m0) j= '.
Since the environment is all that is relevant for formulas in Le , if ' 2 Le , we write se j= '
if (I ; r; m) j= ' for some point (r; m) such that re (m) = se .
BCS2 is concerned with the form of the agent's local state. Recall that, in our framework,
the local state captures the relevant aspects of the agent's epistemic state. The functional
form of the revision and update operators suggests that all that matters regarding how an
agent changes her beliefs are the agent's current epistemic state (which is taken by both
AGM and KM to be a belief set) and what is learned. In terms of our framework, this
suggests that agent's local state at time m + 1 should be a function of her local state of
time m and the observation made at time m. We in fact make the stronger assumption
here that the agent's state consists of the sequence of observations made by the agent. This
means that the agent remembers all her past observations. Note that this surely implies
that the agent's local state at time m + 1 is determined by her state at time m and the
observation made at time m. We make the further assumption that the observations made
by the agent can be described by formulas in Le . Although this is quite a strong assumption
on the expressive power of Le , it is standard in the literature: both revision and update
130

Modeling Belief in Dynamic Systems. Part II.

assume that observations can be expressed as formulas in the language (see Section 3).
These assumptions are formalized in BCS2:
BCS2 For all r 2 R and for all m, we have ra(m) = ho(r;1); : : :; o(r;m)i where
o(r;k) 2 Le for 1  k  m.
Intuitively, o(r;k) is the observation the agent makes immediately after the transition from
time k , 1 to time k in run r. Thus, it represents what the agent observes about the new
state of the system at time k. Note that BCS2 implies that the agent's state at time 0 is the
empty sequence in all runs. Moreover, it implies that ra(m + 1) = ra(m)  o(r;m+1), where 
is the append operation on sequences. That is, the agent's state at (r; m + 1) is the result
of appending to her previous state the latest observation she has made about the system.
It is not too hard to show that belief change systems are synchronous and agents in them
have perfect recall. (We remark that the agents' local states are modeled in a similar way
in the model of knowledge bases presented in (Fagin et al., 1995).)
Clearly we want to reason in our language about the observations the agent makes.
Thus, we assume that the language includes propositions that describe the observations
made by the agent.
BCS3 The language L includes a set obs of primitive propositions disjoint
from e such that obs = flearn(') : ' 2 Le g. Moreover,  (r; m)(learn(')) =
true if and only if o(r;m) = ' for all runs r and times m.
In a system satisfying BCS1{BCS3, we can talk about belief change. The agent's state
encodes observations, and we have propositions that allow us to talk about what is observed.
The next assumption is somewhat more geared to situations where observations are always
\accepted", so that after the agent observes ', she believes '. While this is not a necessary
assumption, it is made by both belief revision and belief update. We capture this assumption
here in what is perhaps the simplest possible way: by assuming that observations are
reliable, so that the agent observes ' only if the current state of the environment satises
'. This is certainly not the only way of enforcing the assumption that observations are
accepted, but it is perhaps the simplest, so we focus on it here. As we shall see, this
assumption is consistent with both revision and update, in the sense that we can capture
both in systems satisfying it.
BCS4 (I ; r; m) j= o(r;m) for all runs r and times m.
Note that BCS4 implies that the agent never observes false. Moreover, it implies that after
observing ', the agent knows that ' is true. In (Boutilier et al., 1998), we consider an
instance of our framework in which observations are unreliable (so that BCS4 does not hold
in general), and examine the status of R2, the acceptance postulate, in this case.
Finally, we assume that belief change proceeds by conditioning. While there are certainly
other assumptions that can be made, as we have tried to argue, conditioning is a principled
approach that captures the intuitions of minimal change, given the observations. And, as
we shall see, conditioning (as captured by PRIOR) is consistent with both revision and
update.
BCS5 I satises PRIOR.
131

Friedman & Halpern

Many interesting systems can be viewed as BCS's.

Example 4.1: Consider the systems Idiag;1 and Idiag;2 of Example 2.1. Are these systems

BCSs? Not quite, since diag is not dened on primitive propositions of the form learn('),
but we can easily embed both systems in a BCS. Let Ldiag the propositional language dened
over diag , and let +diag consist of diag together with all the primitive propositions of the
+ be the obvious extension of 
form learn(') for ' 2 Ldiag . Let diag
diag to +
diag , dened so
+
that BCS3 holds. Then in it is easy to see that (Rdiag ; diag ; Pdiag;i ) is a BCS: we take the
e of BCS1 to be diag , and dene `Ldiag so that it enforces the relationships determined
by the circuit layout. Thus, for example, if c1 is an AND gate with input lines l1 and l2
and output line l3, then we would have `Ldiag :f1 ) (h3 , h1 ^ h2 ). It is then easy to see
that BCS2{BCS5 hold by our construction. ut
These denitions set the background for our presentation of belief revision and belief
update.

5. Capturing Revision

Revision can be captured by restricting to BCSs that satisfy several additional assumptions. Before describing these assumptions, we briey review a well-known representation
of revision that will help motivate them.
While there are several representation theorems for belief revision, the clearest is perhaps
the following (Grove, 1988; Katsuno & Mendelzon, 1991b). We associate with each belief
set A a set WA of possible worlds that consists of those worlds where A is true. Thus, an
agent whose belief set is A believes that one of the worlds in WA is the real world. An agent
that performs belief revision behaves as though in each belief state A she has a ranking ,
i.e., a total preorder, over all possible worlds such that the minimal (i.e., most plausible)
worlds in the ranking are exactly those in WA . When revising by ', the agent chooses the
minimal worlds satisfying ' in the ranking and constructs a belief set from them. It is easy
to see that this procedure for belief revision satises the AGM postulates. Moreover, in
(Grove, 1988; Katsuno & Mendelzon, 1991b), it is shown that any belief revision operator
can be described in terms of such a ranking.
This representation suggests how we can capture belief revision in our framework. We
dene C R  C BCS to be the set of belief change systems I = (R; ; P ) that satisfy the
conditions REV1{REV4 that we dene below.
Revision assumes that the world does not change during the revision process. Formally this implies that propositions in e do not change their truth value along a run,
i.e., (I ; r; m) j= p if and only if (I ; r; m + 1) j= p for all p 2 e . This says that the state of
the world is the same with respect to the properties that the agent reasons about (i.e., the
propositions in e ).

REV1 (r; m)(p) = (r; 0)(p) for all p 2 e and points (r; m).
Note that REV1 does not necessarily imply that re (m) = re (m + 1). That is, REV1 allows
for a changing environment. The only restriction is that the truth value of propositions
that describe the environment does not change. We return to this issue in Section 7.
132

Modeling Belief in Dynamic Systems. Part II.

The representation of (Grove, 1988; Katsuno & Mendelzon, 1991a) requires the agent
to totally order possible worlds. We put a similar requirement on the agent's plausibility
assessment. Recall that BCS5 says that the agent's plausibility is induced by a prior Pla;
REV2 strengthens this assumption.
REV2 The prior Pla of BCS5 is ranked; that is, for all A; B  R, either
Pla (A)  Pla(B ) or Pla (B )  Pla (A), and Pl(A [ B ) = max(Pl(A); Pl(B )).
The representation of (Grove, 1988; Katsuno & Mendelzon, 1991a) also requires that
the agent considers all truth assignments possible. We need a similar condition, except that
we want not only that all truth assignments be considered possible, but that they have
nontrivial plausibility (i.e., are more plausible than ?) as well.
To make this precise, it is helpful to introduce some notation that will be useful for our
later denitions as well. Given a system I and two sequences '1 ; : : :; 'k and o1; : : :; ok0
of formulas in Le , let R['1; : : :; 'k ; o1; : : :; ok0 ] consist of all runs r where for each i with
1  i  k, the formula 'i is true at (r; i) and the agent observes o1 ; : : :; ok0 . That is,
R['0; : : :; 'k ; o1; : : :; ok0 ] = fr 2 I : (I ; r; i) j= 'i; i = 0; : : :; k; and ra(k0) = ho1; : : :; ok0 ig.
We allow either sequence of formulas to be empty, so, for example, R['; ] consists of all
runs for which ' is true at the initial state. (Note that if REV1 holds, this means that ' is
true in all subsequent states as well.) We use the notation R['1; : : :; 'm] as an abbreviation
for R['1; : : :; 'm; ].
REV3 If ' 2 Le is consistent, then Pla(R[']) > ?.
It might seem that REV1{REV3 capture all of the assumptions made by the representation of (Grove, 1988; Katsuno & Mendelzon, 1991a). However, there is another assumption
implicit in the way revision is performed in these representations that we must make explicit
in our representation, because of the way we have distinguished observing ' (captured by
the formula learn(')) from ' itself. Intuitively, when the agent observes ', she updates her
plausibility assessment by conditioning on '. This is essentially what we can think of the
earlier representations as doing. However, in our representation, the agent does not condition on ', but on the fact that she has observed '. Although we do require that ' must
be true if the agent observes it (BCS4), the agent may in general gain extra information by
observing '.
To understand this issue, consider the following example. Suppose that R is such that
the agent observes p1 at time (r; m) only if p2 and q are also true at (r; m), and she observes
p1 ^ p2 at (r; m) only if q is false. It is easy to construct a BCS satisfying REV1{REV3
that also satises these requirements. In this system, after observing p1 , the agent believes
p2 and q. According to AGM's postulate R7 (and also KM's postulate U5) the agent must
believe q after observing p1 ^ p2 . To see this, note that our assumptions about R can
be phrased in the AGM language as p2 ^ q 2 K  p1 and :q 2 K  (p1 ^ p2 ). Postulate
R7 states that K  (p1 ^ p2 )  Cl(K  p1 [ fp2g). Since p2 2 K  p1, we have that
Cl(K  p1 [fp2g) = K  p1. Thus, R7 implies in this case that q 2 K  (p1 ^ p2). However, in
R, the agent believes (indeed knows) :q after observing p1 ^ p2.8 Thus, revision and update
8. We stress this does not mean that p1 ^ p2 implies :q in R. There may well be points in R at which
p1 ^ p2 ^ q is true. However, at such points, the agent would not observe p1 ^ p2 , since the agent observes
p1 ^ p2 only if q is false.

133

Friedman & Halpern

both are implicitly assuming that the observation of ' does not provide such additional
knowledge. The following assumption ensures that this is the case for revision (a more
general version will be required for update; see Section 6).
REV4 Pla(R['; o1; : : :; om])  Pla(R[ ; o1; : : :; om]) if and only if Pla(R[' ^
o1 ^ : : : ^ om ])  Pla (R[ ^ o1 ^ : : : ^ om ]).
This assumption captures the intuition that observing o1; : : :; ok provides no more information than just the fact that o1 ^ : : : ^ om is true. That is, the agent compares the
plausibility of ' and in the same way after conditioning by the observations o1 ; : : :; om
as after conditioning by the fact that o1 ^ : : : ^ om is true. It easily follows from REV4 and
PRIOR that the agent believes after observing o1 ^ : : : ^ om exactly if o1 ^ : : : ^ om ^
was initially considered more plausible than o1 ^ : : : ^ om ^ : . Thus, the agent believes
after observing o1 ^ : : : ^ om exactly if initially, she believed conditional on o1 ^ : : : ^ om :
the observations provide no extra information beyond the fact that each of the oi 's are true.
REV4 is quite a strong assumption. Not only does it say that observations do not
give the agent any additional information (beyond the fact that they are true), it also says
that all consistent observations can be made (since if ' ^ o is consistent, we must have
Pla(R['; o]) = Pla (R[' ^ o]) > ?, by REV3 and REV4). We might instead consider using
a weaker version of REV4 that says that, provided an observation can be made, it gives no
additional information. Formally, this would be captured as
REV40 If Pla(R['; o1; : : :; om]) > 0, then Pla(R['; o1; : : :; om])  Pla(R[ ; o1; : : :; om])
if and only if Pla(R[' ^ o1 ^ : : : ^ om ])  Pla (R[ ^ o1 ^ : : : ^ om ]).
The following examples suggests that REV40 may be more reasonable in practice than
REV4. We used REV4 only because it comes closer to the spirit of the requirement of
revision that all observations are possible.

Example 5.1: Consider the system Idiag;1 described in Example 2.1. As discussed in Ex-

ample 4.1, this system can be viewed as a BCS. Is it a revision system? It is easy to see that
Idiag;1 satises REV2 and REV3. It clearly does not satisfy REV1, since propositions that
describe input/output lines can change their values from one point to the next. However,
as we are about to show, a slight variant of Idiag;1 does satisfy REV1. A more fundamental
problem is that Idiag;1 does not satisfy REV4. This is inherent in our assumption that the
agent never directly observes faults, so that, for example, we have Pldiag;1(R[; f1]) = ?,
while Pldiag;1 (R[f1]) > ?. It does, however, satisfy REV40 .
To see how to modify Idiag;1 so as to satisfy REV1, recall that in the diagnosis task, the
agent is mainly interested in her beliefs about faults. Since faults are static in Idiag;1 , we can
satisfy REV1 if we ignore all propositions except f1 ; : : :; fn . Let 0diag = ff1 ; : : :; fn g and let
L0diag be the propositional language over 0diag . For every observation o made by the agent
regarding the value of the lines, there corresponds a formula in L0diag that characterizes all
the fault sets that are consistent with o. Thus, for every run r in Idiag;1 , we can construct
0 be the
a run r0 where the agent's local state is a sequence of formulas in L0diag . Let Idiag
0
system consisting of all such runs r . We can clearly put a plausibility assignment on these
0 are isomorphic in an obvious sense. In particular, the agent
runs so that Idiag;1 and Idiag
has the same beliefs about formulas in L0diag at corresponding points in the two systems.
134

Modeling Belief in Dynamic Systems. Part II.

0 ; r; m) j= ' if and only if (Idiag;1; r; m) j= ' for all
More precisely, if ' 2 L0diag , then (Idiag
0 satises REV1{REV3 and REV40,
points (r; m) in Idiag;1. It is easy to verify that Idiag
although it still does not satisfy REV4.
0 instead of Idiag |Idiag seems to us a perfectly
We are not advocating here here using Idiag
reasonable way of modeling the situation. Rather, the point is that if we want a BCS to
satisfy properties that validate the AGM postulates, we must make some strong, and not
always natural, assumptions. ut

We want to show that a revision operator corresponds to a system in C R and vice
versa. To do so, we need to examine the beliefs of the agent at each point (r; m). First
we note that if (r; m) a (r0; m0) then (I ; r; m) j= B' if and only if (I ; r0; m0) j= B';
this is a consequence of the requirement that, as we have dened interpreted systems, the
agent's plausibility assessment is a function of her local state. Thus, we think of the agent's
beliefs as a function of her local state. We use the notation (I ; sa) j= B' as shorthand for
(I ; r; m) j= B' for some (r; m) such that ra(m) = sa . Let sa be some local state of the
agent. We dene the agent's belief state at sa as
Bel(I ; sa) = f' 2 Le : (I ; sa) j= B'g:
Since the agent's state is a sequence of observations, the agent's state after observing ' is
simply sa  ', where  is the append operation. Thus, Bel(I ; sa  ') is the belief state after
observing '. We adopt the convention that if the agent can never attain the local state sa
in I , then Bel(I ; sa) = Le . With these denitions, we can compare the agent's belief state
before and after observing ', that is Bel(I ; sa) and Bel(I ; sa  ').
We start by showing that every AGM revision operator can be represented in C R.

Theorem 5.2: Let  be an AGM revision operator and let K  Le be a consistent belief
state. Then there is a system I;K 2 C R such that Bel(I;K ; hi) = K and
Bel(I;K ; hi)  ' = Bel(I;K ; h'i)
for all ' 2 Le .
Proof: See Appendix A.1. ut
Thus, Theorem 5.2 says that we can represent a revision operator  in the sense that we
have a family of systems I;K 2 C R , one for each consistent belief state K , such that K is
the agent's initial belief state in I;K , and for each formula ' in Le , the agent's belief state
after learning ' is K  '. Notice that we restrict attention to consistent belief states K .
The AGM postulates allow the agent to \escape" from an inconsistent state, so that K  '

may be consistent even if K is inconsistent. We might thus hope to extend the theorem so
that it also applies to the inconsistent belief state, but this is impossible in our framework.
If false 2 Bel(I;K ; sa) for some state sa , and ra(m) = sa , then Pl(r;m) (W(r;m)) = ?. Since
we update by conditioning, we must have Pl(r;m+1)(W(r;m+1) ) = ?, so the agent's belief
state will remain inconsistent no matter what she learns. Although we could modify our
framework to allow the agent to escape from inconsistent states, we actually consider this
to be a defect in the AGM postulates, not in our framework. To see why, suppose that the
135

Friedman & Halpern

agent's belief set is inconsistent at sa , and ra(m) = sa . Thus, the agent considers all states
in W(r;m) to be completely implausible (since Pl(r;m) (W(r;m)) = ?). On the other hand, to
escape inconsistency, she must have a plausibility ordering over the worlds in W(r;m). These
two requirements seem somewhat inconsistent.9
Not surprisingly, this inconsistency creates problems for other semantic representations
in the literature. For example, Boutilier's representation theorem (1992) states that for
every revision operator  and belief state K , there is a ranking R such that 2 K  ' if and
only if is believed in the minimal '-worlds according to R. If we examine this theorem, we
note that he does not state that the minimal (i.e., most preferred) worlds in R correspond
to the belief state K (in the sense that the minimal worlds are precisely those where the
formulas in K hold); this would be the analogue of our requiring that Bel(I;K ; hi) = K .
In fact, if K is `L -consistent, the minimal worlds do correspond to K . However, if K is
inconsistent, they cannot, since any nonempty ranking induces a consistent set of beliefs.
We could state a weaker version of Theorem 5.2 that would correspond exactly to Boutilier's
theorem. We presented the stronger result (that does not apply to inconsistent belief states)
to bring out what we believe to be a problem with the AGM postulates. See (Friedman &
Halpern, 1998a) for further discussion of this issue.
Theorem 5.2 shows that, in a precise sense, we can map AGM revision operations to
C R. What about the other direction? The next theorem shows that the rst belief change
step in systems in C R satises the AGM postulates.
Theorem 5.3: Let I be a system in C R. Then there is an AGM revision operator I such
that
Bel(I ; hi) I ' = Bel(I ; h'i)
for all ' 2 Le .
Proof: See Appendix A.1. ut
We remark that if we used REV40 instead of REV4, then we would be able to prove this
result only for those formulas ' that are observable (i.e., for which Pl(R[']) > ?).
Both Theorems 5.2 and 5.3 apply to one-step revision, starting from the initial (empty)
state. What happens once we allow iterated revision? In our framework, observations are
taken to be known, so if the agent makes an inconsistent sequence of observations, then her
belief state will be inconsistent, and (as we observed above) will remain inconsistent from
then on, no matter what she observes. This creates a problem if we try to get analogues to
Theorems 5.2 and 5.3 for iterated revision. As the following theorem demonstrates, we can
already see the problem if we consider one-step revisions from a state other than the initial
state.
Theorem 5.4: Let I be a system in C R and let sa = h'1; : : :; 'ki be a local state in I .
Then there is an AGM revision operator I ;s such that
e

a

Bel(I ; sa) I ;s ' = Bel(I ; sa  ')
a

9. One strength of the AGM framework is that it can deal with an inconsistent sequence of observations,
that is, it can cope with an observation sequence of the form hp; :p; p; :p; : : :i. We stress that being able
to cope with such an inconsistent sequence of observations does not require allowing the agent to escape
from inconsistent belief sets. These are two orthogonal issues.

136

Modeling Belief in Dynamic Systems. Part II.

for all formulas ' 2 Le such that '1 ^ : : : ^ 'k ^ ' is consistent.

Proof: See Appendix A.1. ut

We cannot do better than this. If '1 ^ : : : ^ 'k ^ ' is inconsistent then, because of
our requirements that all observations must be true of the current state of the environment
(BCS4) and that propositions are static (REV1), there cannot be any global state in I
where the agent's local state in sa  '. Thus, Bel(I ; sa  ') is inconsistent, contradicting R5.
There is another problem with trying to get an analogue of Theorem 5.3 for iterated
revision, a problem that seems inherent in the AGM framework. Our framework makes a
clear distinction between the agent's epistemic state at a point (r; m) in I , which we can
identify with her local state sa = ra(m), and the agent's belief set at (r; m), Bel(I ; sa),
which is the set of formulas she believes. In a system in C R, the agent's belief set does
not in general determine how the agent's beliefs will be revised; her epistemic state does.
On the other hand, the AGM postulates assume that revision is a function of the agent's
belief set and observations. Now suppose we have a system I and two points (r; m) and
(r; m0) on some run r 2 I such that (1) the agent's belief set is the same at (r; m) and
(r; m0), that is Bel(I ; ra(m)) = Bel(I ; ra(m0)), (2) the agent observes ' at both (r; m) and
(r; m0), (3) Bel(I ; ra(m + 1)) 6= Bel(I ; ra(m0 + 1). It is not hard to construct such a system
I . However, there cannot be an analogue of Theorem 5.3 for I , even if we restrict to
consistent sequences of observations. For suppose there were a revision operator  such
Bel(I ; hi))  '1      'k = Bel(I ; h'1; : : :; 'k i) for all '1 ; : : :; 'k such that '1 ^ : : : ^ 'k is
consistent. Then we would have Bel(I ; ra(m +1)) = Bel(I ; ra(m))  ' = Bel(I ; ra(m0))  ' =
Bel(I ; ra(m0 + 1)), contradicting our assumption.
The culprit here is the assumption that revision depends only on the agent's belief set.
To see why this is an unreasonable assumption, consider a situation where at time 0 the
agent believes both p and q , but her belief in q is stronger than her belief in p (i.e., the
plausibility of q is greater than that of p). We can well imagine that after observing :p _:q
at time 1, she would believe :p and q . However, if she rst observed p at time 1 and then
:p _:q at time 2, she would believe p and :q, because, as a result of observing p, she would
assign p greater plausibility than q . Note, however, that the AGM postulates dictate that
after an observation that is already believed, the agent does not change her beliefs. Thus,
the AGM setup would force the agent to have the same beliefs after learning :p _ :q in
both situations.
There has been a great deal of work on the problem of iterated belief revision (Boutilier,
1996a; Darwiche & Pearl, 1997; Freund & Lehmann, 1994; Lehmann, 1995; Levi, 1988;
Nayak, 1994; Williams, 1994)). Much of the recent work moves away from the assumption
that belief revision depends solely on the agent's belief set. For example the approaches
of Boutilier (1996a) and Darwiche and Pearl (1997) dene revision operators that map
(rankings  formulas) to rankings. Because our framework makes such a clear distinction
between epistemic states and belief states, it gives us a natural way of maintaining the
spirit of the AGM postulates while assuming that revision is a function of epistemic states.
Rather than taking  to be a function from (belief states  formulas) to belief states, we
take it  to be a function from (epistemic states  formulas) to epistemic states.
This leaves open the question of how to represent epistemic states. Boutilier and Darwiche and Pearl use rankings to represent epistemic states. In our framework, we represent
137

Friedman & Halpern

epistemic states by local states in interpreted systems. That is, a pair (I ; sa) denotes the
agent's state in an interpreted system, and the pair determines the agent's relevant epistemic attitudes, such as her beliefs, how her beliefs changed given particular observations,
her plausibility assessment over runs, and so on. When the system is understood, we simply
use sa as a shorthand representation of an epistemic state.
We can easily modify the AGM postulates to deal with such revision operators on
epistemic states. We start by assuming that there is a set of epistemic states and a function
Bel() that maps epistemic states to belief states. We then have analogues to each of the
AGM postulates, obtained by replacing each belief set by the beliefs in the corresponding
epistemic state. For example, we have

(R10) E  ' is an epistemic state
(R20) ' 2 Bel(E  ')
(R30) Bel(E  ')  Cl(Bel(E ) [ f'g)
and so on, with the obvious transformation.10
We can get strong representation theorems if we work at the level of epistemic states.
Given a language Le (with an associated consequence relation `L ), let EL consist of all
nite sequences of formulas in Le . Note that we allow EL to include sequences of formulas
whose conjunction is inconsistent. We dene revision in EL in the obvious way: if E 2 EL ,
then E  ' = E  '.
e

e

e

e

e

Theorem 5.5: Let I be a system in C R whose local states are EL . There is a function

BelI that maps epistemic states to belief states such that

e

 if sa is a local state of the agent in I , then Bel(I ; sa) = BelI (sa), and
 (; BelI ) satises R10{R80 .
Proof: Roughly speaking, we dene BelI (sa) = Bel(I ; sa) when sa is a local state in I . If
sa is not in I , then we set BelI (sa) = Bel(I ; s0), where s0 is the longest consistent sux of
sa. See Appendix A.1 for details. ut
Notice that, by denition, we have BelI (I ; hiI '1 I : : : I 'k ) = BelI (I ; h'1; : : :; 'k i),

so, at the level of epistemic states, we get an analogue to Theorem 5.3. We remark that to
ensure that R50 holds for (; BelI ), we need to dene BelI (E ) appropriately for sequences
E 2 EI whose conjunction is inconsistent.
Theorem 5.5 shows that any system in C R corresponds to a revision operator over
epistemic states that satises the generalized AGM postulates. We would hope that the
converse also holds. Unfortunately, this is not quite the case. There are revision operators
on epistemic states that satisfy the generalized AGM postulates but do not correspond to
a system in C R. This is because systems in C R satisfy an additional postulate:

(R90) If 6`L :(' ^ ) then Bel(E  '  ) = Bel(E  ' ^ ).
e

10. The only problematic postulate is R6. The question is whether R60 should be \If `Le ' , then
Bel(E  ') = Bel(E  )" or \If `Le ' , then E  ' = E  ". Dealing with either version is
straightforward. For deniteness, we adopt the rst alternative here.

138

Modeling Belief in Dynamic Systems. Part II.

We show that R90 is sound in C R by proving the following strengthening of Theorem 5.5.
Proposition 5.6: Let I be a system in C R whose local states are EL . There is a function
BelI that maps epistemic states to belief states such that
 if sa is a local state of the agent in I , then Bel(I ; sa) = BelI (sa), and
 (; BelI ) satises R10{R90 .
Proof: We show that the function BelI dened in the proof of Theorem 5.5 satises R90.
See Appendix A.1 for details. ut
We can prove the converse to Proposition 5.6: a revision system on epistemic states that
satises the generalized AGM postulates and R90 does correspond to a system in C R .
Theorem 5.7: Given a function BelL mapping epistemic states in EL to belief sets over
Le such that BelL (hi) is consistent and (BelL ; ) satises R10{R90, there is a system I 2 C R
whose local states are in EL such that BelL (sa) = Bel(sa ) for each local state sa in I .
Proof: According to Theorem 5.2, there is a system I such that Bel(I ; hi) = BelL (hi)
and Bel(I ; h'i) = BelL (h'i) for all ' 2 Le . We show that Bel(I ; sa) = BelL (sa ) for local
states sa in I . See Appendix A.1. ut
Notice that, by denition, for the system I of Theorem 5.7, we have Bel(hi'1: : :'k ) =
Bel(h'1; : : :; 'k i) as long as '1 ^ : : : ^ 'k is consistent.
e

e

e

e

e

e

e

e

e

e

6. Capturing Update

Update tries to capture the intuition that there is a preference for runs where all the
observations made are true, and where changes from one point to the next along the run
are minimized.
We start by reviewing Katsuno and Mendelzon's semantic representation of update. To
characterize an agent beliefs, Katsuno and Mendelzon consider the set of \worlds" the agent
considers possible. In their representation, they associate a world with a truth assignment to
the primitive propositions. (In our terminology, we can think of a world as an environment
state.) To capture the notion of \minimal change from world to world", Katsuno and
Mendelzon use a distance function d on worlds. Given two worlds w and w0 , d(w; w0)
measures the distance between them. Intuitively, the larger the distance, the larger the
change required to get from world w to w0 . (Note that that distances are not necessarily
symmetric, that is, it might require a smaller change to get from w to w0, than from w0
to w.) Distances might be incomparable, so we require that d map pairs of worlds into a
partially ordered domain with a unique minimal element 0 and that d(w; w0) = 0 if and only
if w = w0.
Katsuno and Mendelzon show that there is a close relationship between update operators
and distance functions. To make this relationship precise, we need to introduce some
denitions. An update structure is a tuple U = (W; d;  ), where W is a nite set of worlds,
d is a distance function on W , and  is a mapping from worlds to truth assignments for Le
such that
 (w) is `L consistent,
e

139

Friedman & Halpern

 if 6`L :', then there is some w 2 W with (w)(') = true, and
 if w 6= w0 then (w) 6= (w0) for all w; w0 2 W .
Given an update structure U = (W; d;  ), we dene [ '] U = fw :  (w)(') = trueg. Kate

suno and Mendelzon use update structures as semantic representations of update operators.
Given an update structure U = (W; d;  ) and sets A; B  W , Katsuno and Mendelzon dene minU (A; B ) to be the set of worlds in B that are closest to worlds in A, according to
d. Formally, minU (A; B ) = fw 2 B : 9w0 2 A8w0 2 B d(w0; w0) 6< d(w0; w)g.

Theorem 6.1: (Katsuno & Mendelzon, 1991b) A belief change operator  satises U1{U8
if and only if there is an update structure U = (W; ; d) such that
[ '  ] U = minU ([['] U ; [ ] U ):

Thus the worlds the agent believes possible after updating with are these worlds that are
closest to some world considered possible before learning .
Katsuno and Mendelzon's account of update is \static" in the sense that it describes a
single belief change. Nevertheless, there is a clear intuition that each world w0 2 [ '  ] U
is the result of considering a minimal change from some world w 2 [ '] U . However, in
Katsuno and Mendelzon's representation, we do not keep track of the worlds that \lead to"
the worlds in the current belief set.
We now try to capture behavior similar to Katsuno and Mendelzon's semantics in our
framework. We dene systems where each run describes the sequence of changes, so that the
most plausible runs, given a set of observations, correspond the worlds that dene the belief
set in Katsuno and Mendelzon's semantics. More precisely, given a sequence of observations
1; : : :; n, each world in [ '  1  : : : n ] U can be \traced" back through a series of minimal
changes to a world in [ '] U . In our model, each such trace corresponds to one of the most
plausible runs, where the environment state at time m is the mth world in the trace. We
can capture this intuition by using a family of priors with a particular form.
We start with some preliminary denitions. Let I be a BCS, and let s0 ; : : :; sn be a
set of environment states in I . We dene [s0; : : :; sn ] as the set of runs where re (i) = si
for all 0  i  n. Thus, [s0 ; : : :; sn ] describes a set of runs that share a common prex of
environment states. A prior plausibility space Pa = (R; Pla ) is consistent with a distance
measure d if the following holds:
Pla ([s0; : : :; sn ]) < Pla ([s00; : : :; s0n ]) if and only if there is some j < n such that
sk = s0k for all 0  k  j , sj+1 6= s0j +1, and d(sj ; sj +1) < d(sj ; s0j+1).
Intuitively, we compare events of the form [s0 ; : : :; sn ] using a lexicographic ordering based
on d. Notice that this ordering focuses on the rst point of dierence. Runs with a smaller
change at this point are preferred, even if later there are abnormal changes. This point is
emphasized in the borrowed car example below.
Pla is prex-dened if the plausibility of an event is uniquely dened by the plausibility
of run-prexes that are contained in it, so that
Pla (R['0; : : :; 'm])  Pla (R[ 0; : : :; m]) if and only if for all [s0 ; : : :; sm ] 
R[ 0; : : :; m] , R['0; : : :; 'm] there is some [s00; : : :; s0m]  R['0; : : :; 'm] such
that Pla([s00 ; : : :; s0m]) > Pla ([s0; : : :; sm ]).
140

Modeling Belief in Dynamic Systems. Part II.

Roughly speaking, this requirement states that we compare events by properties of dominance. This property is similar to one satised by the plausibility measures that we get
from preference ordering using the construction of Proposition 2.2.
We dene the set C U to consist of BCSs I = (R; ; P ) that satisfy the following four
requirements UPD1{UPD4. UPD1 says that there are only nitely many possible truth
assignments, and that there is a one-to-one map between environment states and truth
assignments.
UPD1 The set e of propositions (of BCS1) is nite and  is such that for
all environment states s, s0 , if s 6= s0 , then there is a formula ' 2 Le such that
s j= ' and s0 j= :'.
UPD2{UPD4 are analogues to REV2{REV4. Like REV2, UPD2 puts constraints on
the form of the prior, but now we consider lexicographic priors of the form described above.
UPD2 The prior of BCS5 is prex dened and consistent with some distance
measure.
Recall that REV3 requires only that all truth assignments initially have nontrivial plausibility. In the case of revision, the truth assignment does not change over time, since
we are dealing with static propositions. In the case of update, the truth assignment may
change over time, so UPD3 requires that all consistent sequences of truth assignments have
nontrivial plausibility.
UPD3 If 'i 2 Le , i = 0; : : :; k, are consistent formulas, then Pl(R['0; : : :; 'k]) >
?.
Finally, like REV4, UPD4 requires that the agent gain no information from her observations beyond the fact that they are true.
UPD4 Pla(R['0; : : :; 'k+1; o1; : : :; ok])  Pla(R[ 0; : : :; m+1; o1; : : :; om]) if
and only if Pla (R['0; '1 ^ o1 ; : : :; 'm ^ om ; 'm+1 ])  Pla (R[ 0; 1 ^ o1 ; : : :; m ^
om; m+1])
We remark that in the presence of REV1, UPD4 is equivalent to REV4. We might consider
generalized versions of UPD4, where the two sequences of formulas can have arbitrary
relative lengths; this version suces for our purposes. We can also dene an analogue
UPD40 in the spirit of REV40 , which applies only if Pl(R['0; : : :; 'm+1; o1; : : :; om ]) > ?.
We now show that C U corresponds to (KM) update. Recall that Katsuno and Mendelzon
dene an update operator as mapping a pair of formulas (; '), where  describes the agent's
beliefs and ' describes the observation, to a new formula   ' that describes the agent's
new beliefs. However, as we discussed in Section 3, when e is nite, we can also treat 
mapping a belief state and a formula to a new belief state. Also recall that Bel(I ; sa) is the
agent's belief set when her local state is sa .
Theorem 6.2: A belief change operator  satises U1{U8 if and only if there is a system
I 2 C U such that
Bel(I ; sa)  = Bel(I ; sa  )
for all epistemic states sa and formulas 2 Le .
141

Friedman & Halpern

Proof: Roughly speaking, we show that any system in C U corresponds to a Katsuno and
Mendelzon update structure. Suppose that I =2 C U is such that the set of environment
states is Se and the prior of BCS5 is consistent with distance function d. We dene an
update structure UI . We then show that belief change in I corresponds to belief change in

UI in the sense of Theorem 6.1. Since Theorem 6.1 states that any belief change operation
dened by an update structure satises U1{U8, this will suce to prove the \if" direction
of the theorem. To prove the \only if" direction of the theorem, we show that that for any
update structure U , there is a system I 2 C U such that UI = U .
See Appendix A.2 for details. ut
This result immediately generalizes to sequences of updates.

Corollary 6.3: A belief change operator  satises U1{U8 if and only if there is a system
I 2 C U such that for all 1; : : :; k 2 Le , we have
Bel(I; sa )  1  : : :  k = Bel(I; sa  1  : : :  k ):
These results show that for update, unlike revision, the systems we consider are such that
the belief state does determine the result of the update, i.e., if Bel(I ; sa ) = Bel(I ; s0a), then
for any ' we get that Bel(I ; sa  ') = Bel(I ; s0a  '). Roughly speaking, the reason is that the
distance measure that determines the prior does not change over time. While this allows
us to get an elegant representation theorem, it also causes problems for the applicability of
update, as we shall see below.
Note that, since the world is allowed to change, there is no problem if we update by a
sequence 1; : : :; k of consistent formulas such that 1 ^ : : : ^ k is inconsistent. There
is no requirement that the formulas 1; : : :; k be true simultaneously. All that matters is
that i is true at time i. Also note that an update by an inconsistent formula does not pose
a problem for our framework. It follows from postulates U1 and U2 that once the agent
learns an inconsistent formula (i.e., false), she believes false from then on.
How reasonable is the notion of update? As the discussion of UPD2 above suggests, it
has a preference for deferring abnormal events. This makes it quite similar to Shoham's
chronological ignorance (1988), and it suers from some of the same problems. Consider
the following story, that we call the borrowed-car example.11 At time 1, the agent parks her
car in front of her house with a full fuel tank. At time 2, she is in her house. At time 3,
she returns outside to nd the car still parked where she left it. Since the agent does not
observe the car while she is inside the house, there is no reason for her to revise her beliefs
regarding the car's location. Since she nds it parked at time 3, she still has no reason
to change her beliefs. Now, what should the agent believe when, at time 4, she notices
that the fuel tank is no longer full? The agent may want to consider a number of possible
explanations for her time-4 observation, depending on what she considers to be the most
likely sequence(s) of events between time 1 and time 4. For example, if she has had previous
gas leaks, then she may consider leakage to be the most plausible explanation. On the other
hand, if her spouse also has the car keys, she may consider it possible that he used the car
in her absence. Update, however, prefers to defer abnormalities, so it will conclude that the
11. This example is based on Kautz's stolen car story (1986), and is due to Boutilier, who independently
observed this problem [private communication, 1993].

142

Modeling Belief in Dynamic Systems. Part II.

fuel must have disappeared, for inexplicable reasons, between times 3 and 4. To see this,
note that runs where the car has been taken on a ride have an abnormality at time 2, while
runs where the car did not move at time 2 but the fuel suddenly disappeared, have their
rst abnormality at time 4, and thus are preferred!
Suppose we formalize the example using propositions such as car-parked-outside, fueltank-full, etc. Let the agent's belief set at time i be i , i = 1; : : :; 4. Notice that 1 includes
the belief that the car is parked in front of the house with a full fuel tank. (That is,
`L 1 ) fuel-tank-full ^ car-parked-outside.) At time 2 the agent makes no observations
since she is in her house, so 2 = 1  true = 1 by U2. At time 3 the agent observes
the car outside her house, so 3 = 2  car-parked-outside = 1 , again by U2. Finally,
4 = 3  :fuel-tank-full. The observation of :fuel-tank-full at time 4 must be explained
by some means. In our semantics, the answer is clear. The most plausible runs are these
where the car was parked until time 3, and somewhere between time 3 and 4 some change
occurred.
Is this counterintuitive conclusion an artifact of our representation? To some extent
it is. This issue cannot be formally addressed within Katsuno and Mendelzon's semantic
framework, since that framework does not provide an account of sequences of changes.
Moreover, one might argue that within out framework there might be other families of priors
that satisfy U1{U8, which will oer alternative explanations of the surprising observation
at time 4. Nevertheless, we claim that our semantics captures, in what we believe to
be the most straightforward way, the intuition embedded in the Katsuno and Mendelzon's
representation. In particular, condition UPD2, which enforces the delay of abnormal events,
was needed in order to capture the \pointwise" nature of the update. It would be interesting
to know whether there is a natural way of capturing update in our framework that does not
suer from these problems.
Does this way of capturing update semantically ever lead to reasonable results? Of
course, that depends on how we interpret \reasonable". We briey consider one approach
here.
In a world w, the agent has some beliefs that are described by, say, the formula '. These
beliefs may or may not be correct (where we say a belief ' is correct in a world w if ' is true
of w). Suppose something happens and the world changes to w0 . As a result of the agent's
observations, she has some new beliefs, described by '0 . Again, there is no reason to believe
that '0 is correct. Indeed, it may be quite unreasonable to expect '0 to be correct, even if
' is correct. Consider the borrowed-car example. Suppose that while the agent was sitting
inside the house, the car was, in fact, taken for a ride. Nevertheless, the most reasonable
belief for the agent to hold when she observes that the car is still in the parked after she
leaves the house is that it was there all along.
The problem here is that the information the agent obtains at times 2 and 3 is insucient
to determine what happened. We cannot expect all the agent's beliefs to be correct at this
point. On the other hand, if she does obtain sucient information about the change and
her beliefs were initially correct, then it seems reasonable to expect that her new beliefs will
be correct. But what counts as sucient information?
We say that ' provides sucient information about the change from w to w0 if there
is no world w00 satisfying ' such that d(w; w00) < d(w; w0). In other words, ' is sucient
information if, after observing ' in world w, the agent will consider the real world (w0) one
e

143

Friedman & Halpern

of the most likely worlds. Note that this denition is monotonic, in that if ' is sucient
information about the change, then so is any formula that implies ' (as long as it holds at
w0). Moreover, this denition depends on the agent's distance function d. What constitutes
sucient information for one agent might not for another. We would hope that the function
d is realistic in the sense that the worlds judged closest according to d really are the most
likely to occur.
We can now show that update has the property that if the agent has correct beliefs and
receives sucient information about a change, then she will continue to have correct beliefs.

Theorem 6.4: Let I 2 C U . If the agent's beliefs at (r; m) are correct and o(r;m) provides

sucient information about the change from re (m) to re (m + 1), then the agent's beliefs at
(r; m + 1) are correct.

Proof: Straightforward; left to the reader. ut
As we observed earlier, we cannot expect the agent to always have correct beliefs. Nevertheless, we might hope that if the agent does (eventually) receive suciently detailed
information, then she should realize that her beliefs were incorrect. But this is precisely
what does not happen in the borrowed-car example. Intuitively, once the agent observes
that the fuel tank is not full, this should be sucient information to eliminate the possibility that the car remained in the parking lot. However, it is not. Roughly speaking, this
is because update focuses only on the current state of the world, and thus cannot go back
and revise beliefs about the past.
The problem here is again due to the fact that belief update is determined only by the
agent's belief state and not her epistemic state. Thus, update can only take into account
the agent's current beliefs and not other information, such as the sequence of observations
that led to these beliefs. In our example, if we limit our attention to beliefs about the car's
whereabouts and the fuel tank, then since the agent has the same belief state at time 1
and 3, she must change her beliefs in the same manner at both times. This implies that the
observation the fuel tank is not full at time 4 cannot be sucient information about the
past, since a fuel leak might be the most plausible explanation of missing fuel at time 2.12
Our discussion of update shows that update is guaranteed to be safe only in situations
where there is always enough information to characterize the change that has occurred.
While this may be a plausible assumption in database applications, it seems somewhat less
reasonable in AI examples, particularly in cases involving reasoning about action.13

7. Synthesis

In previous sections we analyzed belief revision and belief update separately. We provided
representation theorems for both notions and discussed issues specic to each notion. In
this section, we try to identify some common themes and points of dierence.
12. In this example the usual intuition is that, given the observation that the tank is not full, the agent
should revise her belief in some manner instead of performing update. This immediately raises the
question of how the agent knows what the right belief change operation should be here. We return to
this issue below.
13. Similar observations were independently made by Boutilier (1996b), although his representation is quite
dierent from ours.

144

Modeling Belief in Dynamic Systems. Part II.

Restriction on
Environment changes
Initial plausibility
Belief change

Revision
No change
(Static propositions)
Total preorder
Conditioning

Update
All possible sequences
Lexicographic
Conditioning

Table 1: A summary of the restrictions we impose to capture revision and update.
Katsuno and Mendelzon (1991a) focused on the following three dierences between AGM
revision and KM update:
1. Revision deals with static propositions, while update allows propositions that are not
static.
2. Revision and update treat inconsistent belief states dierently. Revision allows an
agent to \recover" from an inconsistent state after observing a consistent formula.
Update dictates that once the agent has inconsistent beliefs, she will continue to have
inconsistent beliefs. As we noted above, it seems that revision's ability to recover from
an inconsistent belief set leads to several technical anomalies in iterated revision.
3. Revision considers only total preorders, while update allows partial preorders.
Our framework suggests a dierent approach to categorizing the dierences between
revision and update (and other approaches to belief change): focusing on the restrictions
that have to be added to basic BCSs to obtain systems in C R and C U , respectively. In
particular, we focus on three aspects of a system:

 How does the environment state change?
 How does the agent form her initial beliefs? What regularities appear in the agent's

beliefs at the initial state?
 How does the agent change her beliefs?

Table 1 summarizes the answers to these questions for revision and update; it highlights
the dierent restrictions imposed by each. Revision puts a severe restriction on changes
of the environment (more precisely, on how we describe the environment in the language)
and a rather mild restriction on the agent's prior beliefs (they must form a total preorder).
On the other hand, update allows all sequences of environment states, but requires the
agent's prior beliefs to have a specic form. These formal properties match the intuitive
description of revision and update given in (Alchourron et al., 1985; Katsuno & Mendelzon,
1991b). However, the explicit representation of time in our framework allows us to make
these intuitions precise. Moreover, our framework makes explicit other assumptions made
by revision and update. For example, the lexicographic nature of update is not immediately
evident from the presentation in (Katsuno & Mendelzon, 1991b).
145

Friedman & Halpern

The key point to notice in this table is that belief change in both revision and update
is done by conditioning. This observation, and the naturalness of conditioning as a notion
of change, support our claim that conditioning should be adopted as semantic foundations
for minimal change.
How signicant are the dierences between revision and update? We claim that some
of these dierences are a result of dierent ways of modeling the same underlying process.
Recall that in the introduction we noted that the restriction to static propositions is not such
a serious limitation of belief revision, since we can always convert a dynamic proposition
to a static one by adding timestamps. More precisely, we can replace a proposition p by a
family of propositions pm that stand for \p is true at time m". This makes it possible to
use revision to reason about a changing world. We now show how revision and update can
be related under this viewpoint.
To make this discussion precise, we need to introduce some formal denitions. Let
I = (R; ; P ) be a BCS. We \statify" I into a system I  = (R; ; P ) by replacing the
underlying language with static propositions.
Let e = fpm : p 2 e ; m 2 N g be a set of timestamped propositions and let Le be the
logical language based on these propositions. We can easily \timestamp" every formula in L.
We dene timestamp('; m) recursively as follows. The base case is timestamp(p; m) = pm
for p 2 e . For standard logical connectives, we simply apply the transformation recursively,
for example timestamp(' ^ ) = timestamp('; m) ^ timestamp( ; m).
Next, we dene the set of runs in the \statied" system. For each run r 2 R, we
dene a r in R as follows. The environment states in r are dened to be the whole
sequence of environment states in r, that is, re(m) = re . If ra(m) = ho(r;1); : : :; o(r;m)i, we
dene ra(m) = htimestamp(o(r;1); 1); : : :; timestamp(o(r;m); m)i. We dene the interpretation   in the obvious way:  (r; m)(pm0 ) = true if and only if  (r; m0)(p) = true and
 (r; m)(learn(')) = true if and only if o(r ;m) = '.
Finally, we need to dene the prior plausibility Pla . We dene this prior to be isomorphic
to Pla under the transformation r 7! r. That is, for each set of runs R  R, we dene
Pla(R ) = Pla (fr 2 R : r 2 R g).
It is clear that the two systems I and I  describe the same underlying process. Perhaps
the most signicant dierence is that the environment state in a run of I  encodes the
future of the run. This was necessary so that the environment state could determine the
truth of all propositions of the form pm , so as to satisfy BCS1. Without this requirement,
we could have simply changed  and left R and P unchanged.
Because dierent base languages are used in I and I , the agent has dierent beliefs
in the two systems. It is easy to show that, for all ' 2 Le , we have (I ; r; m) j= B' i
(I  ; r; m) j= B (timestamp('; m)). However, at (r; m) the agent also has beliefs about
propositions that describe past and future times. Thus, the set of beliefs of the agent in I 
can be viewed as a superset of her beliefs in I at the corresponding points.
The following result makes precise the relationship between I and I  in terms of the
properties we have been considering.
Proposition 7.1: Let I be a BCS and let I  the transformed system dened above. Then
 I  is a BCS, that is, it satises BCS1{BCS5.
 I  satises REV1.
146

Modeling Belief in Dynamic Systems. Part II.

 If I satises UPD3, then I  satises REV3.
 If I satises UPD4, then I  satises REV40.

Proof: Straightforward; left to the reader. ut
Thus, if I is a BCS, so is I  . Moreover, if I 2 C U , then I  satises all but two of the
requirements for C R. First, I  does not necessarily satisfy REV2, since the prior of systems
in C U is, in general, not ranked. Second, I  satises REV40, the weaker version of REV4.
The reason for this is that runs I  do not allow all sequences of possible observations.
Remember that in the language of Le , the agent can observe the proposition p2 (i.e., that
p is true at time 2) at time 1. However, in the original system, the agent only observes
properties of the current time. Thus, o(r ;m) involves only propositions that deal with time
m.

Neither of these shortcomings is serious. First, variants of AGM revision that involve
partial orders were discussed in the literature (Katsuno & Mendelzon, 1991b; Rott, 1992).
It is fairly straightforward to show that these can captured in our systems using BCSs that
satisfy REV1, REV3, and REV4. Second, it is easy to add to I  runs so as to get a system
that satises REV4. Moreover, we can do this is a way that does not change the agent's
beliefs for sequences of observations that can be observed in I . Thus, the \statied" version
of a system in C U displays behavior much in the spirit of belief revision.
This result may seem somewhat surprising in light of the signicant dierences between
the AGM postulates and KM postulates. In part, it shows how much is bound up in our
choice of language. (Recall that similar issues arose in Example 5.1.) This highlights the
sensitivity of the postulate approach to the modeling assumptions we make. Unfortunately,
these modeling assumptions are rarely discussed in the belief change literature. (See (Friedman & Halpern, 1998a) for a more detailed discussion of this point.)
Table 1 emphasizes that, despite the well-known dierences between revision and update,
they can be viewed as sharing one very important feature: they both use conditioning to do
belief change. Thus, we have a common mechanism both for understanding and extending
them. To a certain extent, our results show that revision is more general than update, in
the sense that we can view the statied version of any system in C U as performing revision
(possibly with unranked prior) over runs.

8. Extensions
In the preceding sections, we introduced several assumptions that were needed to capture
revision and update. Of course, there are other ways of capturing these notions that require
somewhat dierent assumptions. Nevertheless, these assumptions give insight into the underlying choices made, either explicitly or implicitly, in the denition of revision and update.
In addition, thinking in terms of such restrictions makes it straightforward to extend the
intuitions of revision and update beyond the context where they were originally applied. In
this section, we consider a number of such extensions, to illustrate our point.
147

Friedman & Halpern

8.1 Knowledge
In many domains of interest, the agent knows that some sequences of observations are
impossible. We already saw in the circuit-diagnosis problem that observing failures was
impossible. In the context of update, we know that we cannot observe a person die and
then be alive, despite the fact that both being dead and being alive are consistent states.
We can easily maintain what we regard as the dening properties of revision and update,
as discussed in the previous section: no change in the environment state and a ranked prior
in the case of revision, and a lexicographic prior in the case of update, with belief change
proceeding by conditioning in both cases. We simply drop REV3 and replace REV4 by
REV40 (resp., drop UPD3 and replace UPD4 and UPD40 ). We remark that this change
aects the postulates. For example, consider update. Suppose that the agent considers
the possibility that Mr. Bond is dead. If she then observes Mr. Bond alive and well then,
according to update, she must account for the new observation by some change from the
worlds she previously considered possible. However, there is no transition from worlds
in which Mr. Bond is dead that can account for the new observation. Thus, once the
agent knows that certain transitions are impossible, some observations (e.g., observing that
Mr. Bond is alive) require her to remove from consideration some of the worlds that she
previously considered possible. As a consequence, postulate U8 does not hold, since the
agent's new beliefs are not determined by a pointwise update at each of the worlds she
previously considered possible. (Boutilier (1998) uses a related semantic framework to
draw similar conclusions in his analysis of update.)

8.2 Language of Beliefs
In our analysis of revision and update, we focused on the agent's beliefs about the current
state of the environment. Often we are also interested in how the agent changes her beliefs
about other types of statements, such as beliefs about future states of the environment,
beliefs about other agents' beliefs, and introspective beliefs about her own beliefs. Again,
it is straightforward in our framework to deal with an enriched language that lets us express such statements. For example, in (Friedman & Halpern, 1994) we examine Ramsey
conditionals. These are formulas of the form ' > , which can be read as saying \after
learning ', the agent believes ". This formula can be expressed as learn(') ) B in the
language LKPT . As is well known, if belief sets include Ramsey conditionals (and not just
propositional formulas), then the AGM postulates become inconsistent (at least, provided
we have at least three mutually exclusive consistent formulas in the language) (Gardenfors,
1986). Similar inconsistency results arise when one tries to add other forms of introspective
beliefs (Fuhrmann, 1989). In our setting, it is easy to see why the problem arises. Even
if we allow belief sets to include nonpropositional formulas, it still seems quite clear that
we want to distinguish the propositional formulas from formulas that talk explicitly about
an agent's beliefs. For example, it is not clear that we should allow an observation of a
formula such as ' > . What would it mean to observe such a formula? It clearly seems
quite dierent from observing a propositional formula. Nor does it make sense to extend an
assumption such as REV1 to arbitrary formulas. While it may be reasonable to restrict to
static propositions if we are viewing these as making statements about a relatively stable
148

Modeling Belief in Dynamic Systems. Part II.

environment, it seems far less reasonable to assume that formulas that talk about an agent's
beliefs will be static, especially when we are trying to model belief change!
Of course, if we allow only propositional formulas to be learned (or observed), and
restrict REV1 to propositional formulas, then it is easy to see that all of our results still
hold, even if the full language is quite rich; we avoid the triviality result completely.

8.3 Observations
One of the strongest assumptions made by revision and update involves the treatment of
observations. This assumption seems unreasonable in most domains. REV4 and UPD4
essentially assume that the observation that the agent makes is chosen randomly among
all formulas consistent with the current state of the world. Suppose that ' says that the
agent is outdoors, says that the agent is in the basement, and o1 says that the basement
light is on. We may well have Pla (R[' ^ o1 ]) > Pla (R[ ^ o1 ]). For example, the agent
may hardly ever go to the basement and frequently go outdoors, but her children may often
leave the basement light on. Nevertheless, we may also have Pla (R['; o1]) < Pla (R[ ; o1]),
contradicting REV4. Indeed, it may well be impossible for the agent to observe that the
basement light is on when she is outdoors, so that Pla (R['; o1]) = ?, but this is not
permitted according to REV4 or UPD4.
In many domains it is useful to reason about hidden quantities that simply cannot be
observed. For example, the event that component ci is faulty in Example 5.1 is a basic
event in our description of the problem, yet it cannot be observed. Similarly, the event
where a patient has a disease X or the opponent is planning to capture the queen are useful
in reasoning about medical diagnosis and game strategy, yet are not directly observable in
practice. Thus, the requirement that all formulas in the language can be observed seems
quite unnatural. We note that explicitly modeling sensory input is a standard practice in
control theory and stochastic processes (e.g., in hidden Markov chains). In these elds,
one models the probability of an observation in various situations. Making an observation
increases the probability of situations where that observation is likely to be observation and
decreases the probability of situations where it is unlikely. Again, it is straightforward to
consider a more detailed model of the observation process in our framework; see (Friedman,
1997, Chapter 6) and (Boutilier et al., 1998).

8.4 Actions
Our denition of belief change systems essentially assumes that the agent is passive. The
situation is more complex when the agent can inuence the environment. The agent's choice
of action interacts with her beliefs. It is clear that after performing an action, the agent
should change her beliefs.14 Moreover, the information content of observations depends on
the action the agent has just performed. For example, the agent might consider hearing a
loud noise to be surprising. However, it would be expected after the agent pulls the trigger
of her gun.
14. Indeed, an alternative interpretation of the update postulates is that they describe how the agent should
update her beliefs after doing the action \achieve '" (Goldszmidt & Pearl, 1996; del Val & Shoham, 1992,
1993). However, as these works show, the update postulates are problematic under this interpretation.

149

Friedman & Halpern

8.5 Summary

This list of possible extensions is clearly not exhaustive; there are many others that we
may want to consider. Nevertheless, these are extensions that seem to be of interest. The
main points we want to make here are (1) it is easy to accommodate these extensions in
our framework while still maintaining the main characteristics of revision and update, and
(2) it is dicult to deal with such extensions if we focus on postulates.

9. Conclusion

We have shown how the framework introduced in (Friedman & Halpern, 1997) can be used
to capture belief revision and update. Modeling revision and update in the framework also
gives us a great deal of further insight into their properties, and emphasizes the role of
conditioning as a way of capturing minimal change.
Of course, revision and update are but two points in a wide spectrum of possible types of
belief change. Our ultimate goal is to use this framework to understand the whole spectrum
better and to help us design belief change operations that overcome some of the diculties
we have observed with revision and update. In particular, we want belief change operations
that can handle dynamic propositions, while still being able to revise information about the
past.
Our framework suggests how to construct such belief change operations. In this framework, belief change operations can be determined by choosing a plausibility measure that
captures the agent's preferences among sequences of worlds. This is the agent's prior plausibility, and captures her initial beliefs about the relative likelihood of runs. As the agent
receives information, she changes her beliefs using conditioning. In this paper we show that
revision and update correspond to two specic families of priors. Clearly, however, there
are prior plausibilities that, when conditioned on a surprising observation, allow the agent
to revise some earlier beliefs and to assume that some change has occurred. One obvious
problem is that, even if there are only two possible states, there are uncountably many
possible runs. How can an agent describe a prior plausibility over such a complex space?
One approach to doing this is based on intuition from the probabilistic settings. In
these settings, the standard solution to this problem is to assume that state transitions are
independent of when they occur, that is, that the probability of the system going from state
s to state s0 is independent of the sequence of transitions that brought the system to state
s. This Markov assumption signicantly reduces the complexity of the problem. All that
is necessary is to describe the probability of state transitions. In (Friedman & Halpern,
1996; Friedman, 1997) we dene a notion of plausibilistic independence, and show how to
describe priors that satisfy the Markov assumption and the consequences for belief change.
See also (Boutilier, 1998; Boutilier et al., 1998) for recent proposals along these lines.
Whether or not this particular approach turns out to be a useful one, it is clear that
these are the types of questions we should be asking. As these works show, our framework
provides a useful basis for answering them.
Finally, we note that our approach is quite dierent from the traditional approach to
belief change (Alchourron et al., 1985; Gardenfors, 1988; Katsuno & Mendelzon, 1991a).
Traditionally, belief change was viewed as an abstract process. Our framework, on the other
hand, models the agent and the environment she is situated in, and how both change in time.
150

Modeling Belief in Dynamic Systems. Part II.

This allows us to model concrete agents in concrete settings (for example, diagnostic systems
are analyzed in (Friedman & Halpern, 1997) and throughout this paper), and to reason
about the beliefs and knowledge of such agents. We can then investigate what plausibility
ordering induces beliefs that match our intuitions. By gaining a better understanding of
such concrete situations, we can better investigate more abstract notions of belief change.
More generally, we believe that, when studying belief change, it is important to specify the
underlying ontology: that is, exactly what scenario underlies the belief-change process. We
have specied one such scenario here. While others are certainly possible, we view it as a
defect in the literature on belief change that the underlying scenario is so rarely discussed.
The framework we have introduced here provides a way of making formal what the scenario
is. (See (Friedman & Halpern, 1998a) for further discussion of this issue.)

Acknowledgments
The authors are grateful to Craig Boutilier, Ronen Brafman, Adnan Darwiche, Moises Goldszmidt, Adam Grove, Alberto Mendelzon, Alvaro del Val, and particularly Daphne Koller
and Moshe Vardi, for comments on drafts of this paper and useful discussions relating to
this work. Some of this work was done while both authors were at the IBM Almaden Research Center. The rst author was also at Stanford while much of the work was done. IBM
and Stanford's support are gratefully acknowledged. The work was also supported in part
by the Air Force Oce of Scientic Research (AFSC), under Contract F49620-91-C-0080
and grant F94620-96-1-0323 and by NSF under grants IRI-95-03109 and IRI-96-25901. The
rst author was also supported in part by an IBM Graduate Fellowship and by Rockwell
Science Center. A preliminary version of this paper appears in J. Doyle, E. Sandewall, and
P. Torasso (Eds.), Principles of Knowledge Representation and Reasoning: Proc. Fourth International Conference , 1994, pp. 190{201, under the title \A knowledge-based framework
for belief change, Part II: revision and update."

Appendix A. Proofs

A.1 Proofs for Section 5

We start with the proof of Theorems 5.2 and 5.3. To do this, we need some preliminary
denitions and lemmas. Figure 1 shows the general outline of the intermediate representations we use in these proofs. Roughly speaking, we show how to map from a revision
operator  and a consistent belief set K to a ranking, and similarly how to map from a
ranking to an AGM revision operator. These rankings correspond, in a direct way, to priors
in systems in C R , and thus have close connection to the beliefs of the agent in various states.
These mapping between AGM revision operators and rankings are related to the representation theorems of Boutilier (1994b), Grove (1988), and Katsuno and Mendelzon (1991a).
However, the exact details of our representations are dierent than those of Boutilier, Grove,
and Katsuno and Mendelzon. Thus, for completeness we provide the full proofs here.
We start with the mapping from revision operator applied to a specic belief set to a
ranking. As an intermediate step we construct a set of defaults as follows. We then will use
the results from (Friedman & Halpern, 1998b) to construct a ranked plausibility structure
that satises these defaults.
151

Friedman & Halpern

Lemma A.1

AGM
Revision
K;



Set of
Defaults

X
X





X
X

Lemma A.2

X
X



Ranked
Structure

Lemma A.3
C
 C

C 
C

Bel(I a)
;s



X
X

Lemma A.4

X
X



Characteristic
Structure
PLI

Figure 1: Schematic description of the entities and lemmas involved in the proof of Theorems 5.2 and 5.3.

Lemma A.1: Let  be an AGM revision operator, let K  Le be a consistent belief set,

and let

!

(;K ) = f'
Then the following is true:
(a)
(b)
(c)

: '; 2 Le ; 2 K  'g:

(;K ) is closed under the rules of system P,
' false 62 (;K) for all consistent ' 2 Le , and
(;K ) satises rational monotonicity; that is, if '
then ' ^ 
2 (;K).

!

!

!

2 (;K) and '!: 62 (;K),

Proof: We start with part (a):
LLE Assume that `L '  '0 and that '! 2 (;K ). Thus, 2 K  '. From R5, it
follows that 2 K  '0, and thus '0 ! 2 (;K ).
RW Assume that `L ) 0 and that '! 2 (;K ). Thus, 2 K  '. Since K  ' is a
belief set, it is closed under logical consequence. In particular, 0 2 K  ', and hence
'! 0 2 (;K).
REF By R2, ' 2 K  ', and thus, '!' 2 (;K ).
AND Assume that '! 1; '! 2 2 (;K ). Thus, 1; 2 2 K  '. Since K  ' is a belief
set, 1 ^ 2 2 K  '. Thus, '! 1 ^ 2 2 (;K ).
OR Assume that '1 ! ; '2! 2 (;K ). There are two cases. If K  ('1 _ '2 ) is
inconsistent, then 2 K  ('1 _ '2) and thus '1 _ '2 ! 2 (;K ). If K  ('1 _ '2) is
e

e

152

Modeling Belief in Dynamic Systems. Part II.

consistent, then, by R2, '1 _ '2 2 K  ('1 _ '2 ). Thus, we cannot have both :'1 and
:'2 in K  ('1 _ '2). Without loss of generality, assume that :'1 62 K  ('1 _ '2).
Using R7 and R8, we get that K  (('1 _ '2 ) ^ '1) = Cl(K  ('1 _ '2 ) [ f'1g).
Using R6, we get that K  (('1 _ '2) ^ '1) = K  '1. Thus, we conclude that
K  '1 = Cl(K  ('1 _ '2 ) [ f'1g). Since '1 ! 2 (;K ), we have that 2 K  '1.
Thus, we get that '1 ) 2 K  ('1 _ '2 ). If :'2 62 K  ('1 _ '2), by similar arguments
we get that '2 ) 2 K  ('1 _ '2 ). This implies that ('1 _ '2) ) 2 K  ('1 _ '2 ),
and thus 2 K  ('1 _ '2). On the other hand, if :'2 2 K  ('1 _ '2 ), then, since
'1 _ '2 2 K  ('1 _ '2), we get that '1 2 K  ('1 _ '2), and thus 2 K  ('1 _ '2).
CM Assume that '! 1 ; '! 2 2 (;K ). If K  ' is inconsistent, then using R5 we get
that ' is inconsistent. Thus, ' ^ 1 is inconsistent, so 2 2 K  (' ^ 1 ). Now assume
that K  ' is consistent. Since '! 1, we have that 1 2 K  '. Since K  ' is
consistent, we get that : 1 62 K  '. Applying R8, we get that K  '  K  (' ^ 1 ).
Since '! 2 2 (;K ), we have that 2 2 K  '. Thus, 2 2 K  (' ^ 1 ). This
implies that (' ^ 1 )! 2 2 (;K ).
We now prove part (b). Let ' 2 Le be a consistent formula. Then, using R5, we get
that K  ' is consistent. Thus, '!false 62 (;K ).
Finally we prove part (c). Assume that '! 2 (;K ), and ' ^  ! 62 (;K ). Since
'! 2 (;K), we have that 2 K  '. Now if : 62 K  ', then, using R8, we have that
Cl(K  ' [fg)  K  (' ^ ). This implies that 2 K  (' ^  ). However, since we assumed
that ' ^  ! 62 (;K ), we have that 62 K  (' ^  ); thus, we get a contradiction. We
conclude that : 2 K  '. Thus, '!: 2 (;K ). ut

We now use this result to show that there exists a plausibility structure that corresponds
to  applied to K .
Lemma A.2: Let  be an AGM revision operator, and let K  Le be a consistent belief set.
Then there is a plausibility structure PL = (W; Pl;  ) such that Pl is ranked, PL j= '
if
and only if 2 K  ', and Pl([['] ) > ? for all `L -consistent formulas ' 2 Le .
Proof: We use the basic techniques described in the proof of (Friedman & Halpern, 1998b,
Theorem 8.2). Let (;K ) be the set of defaults dened by Lemma A.1. We now construct
a plausibility space PL0 = (W; Pl0 ;  ) such that PL0 j= '
if and only if '
2 (;K).
We dene PL0 as follows:
 W = fwV : V  Le is a maximal `L -consistent setg,
 (wV )(p) = true if p 2 V , and
 Pl0([['] )  Pl0([[ ] ) if and only if (' _ ) ' 2 (;K).
Using (Friedman & Halpern, 1998b, Lemma 4.1), we get that PL0 j= '
if and only if
' 2 (;K). From Lemma A.1 (c) and and results of (Friedman & Halpern, 1998b), it
follows that there is a ranked plausibility measure Pl that is default-isomorphic to Pl0 , that
is (W; Pl;  ) satises precisely the same defaults as (W; Pl0;  ). Let PL = (W; Pl;  ).
Since PL is default-isomorphic to PL0, we have that PL j= '
if and only if '
2
(;K ). Moreover, using Lemma A.1, we have that '
2 (;K) if and only if 2 K  '.
Thus, PL j= '
if and only if 2 K  '. Finally, let ' be a `L -consistent formula. From

!

e

!

!

e

!

!

!

!

!

!

e

153

!

Friedman & Halpern

!

Lemma A.1 (b), we get that ' false 62 (;K ). Since (;K ) is closed under the rules of
system P, we conclude that (' _ false) false 62 (;K ). Thus, Pl0 ([['] ) 6 ? = Pl0([[false] ),
and thus Pl0 ([['] ) > ?. Since Pl is default-isomorphic to Pl0 , we conclude that Pl([['] ) > ?.

!

ut

We now prove the converse to Lemma A.2.

Lemma A.3: Let PL = (W; Pl; ) be a ranked plausibility structure such that (w) is `L consistent for all worlds w, and PL 6j= '!false for all `L -consistent formulas ' 2 Le ;
let K = f' 2 Le : PL j= true!'g. Then there is an AGM revision operator  such that
2 K  ' if and only if PL j= '! .
Proof: Let  be some belief change operation such that K  ' = f : PL j= '! g. Since
this requirement constrains only the result of applying  to K , we can assume without loss
of generality that  satises the AGM postulates when applied to belief sets other than K .
Thus, we need prove only that  satises the AGM postulates for revision applied to K .
e

e

(Note that the proofs for R3 and R4 follow from the proofs for R7 and R8, respectively.)

R1 Since PL is qualitative, we have that f : PL j= '! g is a belief set, that is, closed
R2
R5

under logical consequences.
Axiom C1 implies that PL j= ' '. Thus, ' 2 K  '.
By our assumptions, if ' is `L -consistent, then Pl([['] ) > ?, and thus PL 6j= ' false.
On the other hand, if ' is not `L -consistent, then [ '] = ;, and thus Pl([['] ) = ?.
We conclude that Pl([['] ) = ? if and only if `L :'. This implies that PL j= ' false
if and only if `L :'. Thus, K  ' = Cl(false) if and only if `L :'.
Assume that `L ' , '0 . Then, by our assumption,  (w)(') =  (w)('0). Thus,
[ ' ^ ] = [ '0 ^ ] for all formulas 2 Le . We conclude that PL j= '
if and only
if PL j= '0 . This implies that K  ' = K  '0.
There are two cases: either Pl([[' ^ ] ) = ? or Pl([[' ^ ] ) > ?. If Pl([[' ^ ] ) =
?, then ' ^ is inconsistent. According to R2, we have that ' 2 K  '. Thus,
' ^ 2 Cl(K  ' [ f g). This implies that Cl(K  ' [ f g) contains false, and thus
K  (' ^ )  Cl(K  ' [ f g). If Pl([[' ^ ] ) > ?, let  2 K  (' ^ ). We now show
that  2 Cl(K  ' [ f g). This will show that K  (' ^ )  Cl(K  ' [ f g). Since
 2 K  (' ^ ), we get that PL j= (' ^ ) . Since Pl([[' ^ ] ) > ?, we get that
Pl([['^ ^ ] ) > Pl([['^ ^: ] ). Then we have that Pl([['^( )  )]]) > Pl([['^:( )
 ))]]), since (' ^ ^ ) ) (' ^ ( ) )) and (' ^ :( )  )) ) (' ^ ^ : ). This
also implies that Pl([['] ) > ?. Thus, PL j= ' ( )  ). So, ( )  ) 2 K  ', and
thus  2 Cl(K  ' [ f g).
Assume that : 62 K  '. Let  2 Cl(K  ' [ f g). We now show that  2 K  (' ^ ).
This will show that Cl(K  ' [f g)  K  (' ^ ). Let A = [ ' ^: ] , B = [ ' ^ ^  ] ,
and C = [ ' ^ ^ : ] . It is easy to verify that these sets are pairwise disjoint. Since
' ^ ( ) )  (' ^ : ) _ (' ^ ^ ) and (' ^ :( )  ))  (' ^ ^ : ), we conclude
that [ ' ^ ( )  )]] = A [ B , and [ ' ^ :( )  )]] = C . Since  2 Cl(K  ' [ f g),
we have that ( )  ) 2 K  '. This means that PL j= ' ( )  ). Thus, either

!

!
!

e

e

e

R6
R7

e

!

e

!

e

!

!

R8

!

154

Modeling Belief in Dynamic Systems. Part II.

Pl([['] ) = ? or Pl(A [ B ) > Pl(C ). If Pl([['] ) = ?, then according to A1, we get that
Pl([[' ^ ] ) = ?. Thus, PL j= (' ^ )  vacuously, and  2 K  (' ^ ) as desired.
Now assume that Pl(A [ B ) > Pl(C ). Since Pl is ranked, it satises A40 and A50.
According to A50, we get that either Pl(A) > Pl(C ) or Pl(B ) > Pl(C ). Assume that
Pl(A) > Pl(C ) and Pl(B ) 6> Pl(C ). Then, using A40, we get that Pl(A) > Pl(B ).
Applying A2, we get that Pl(A) > Pl(B [ C ). However since A = [ ' ^ : ] and
B [ C = [ ' ^ ] , this implies that : 2 K  ', which contradicts our assumption.
Thus, we conclude that Pl(B ) > Pl(C ). Since B = [ ' ^ ^  ] and C = [ ' ^ ^ : ] ,
we get that PL j= (' ^ )  , and thus  2 K  (' ^ ).
R3 and R4 Our denition of  implies that K  true = K . According to R6, we have that
K  (true ^ ') = K  '. Combining these two facts, we get that R3 and R4 are special
cases of R7 and R8, respectively.

!

!

ut
These results show how to map between ranked plausibility structures and AGM revision
operators. We now relate systems in C R and ranked plausibility structures. Let I =
(R; ; P ) 2 C R. Recall that REV2 requires that the prior of I be a ranking. Thus, we
can construct a ranked plausibility structure where worlds are runs in R. We dene the
characteristic structure of I to be PLI = (R; Pla ; PlI ), where Pla is the agent's prior over
runs and PlI (r)(p) =  (r; 0)(p) for all p 2 e . Note that [ '] PLI = R['].
We now use PLI to describe the beliefs of the agent in each local state.

LemmaVA.4: Let I 2 C R and let sa = ho1; : : :; omi. Then
; sa) if and only if
Vm 'o2) toBelbe(Itrue
PLI j= ( m
o
)
!
'
.
(By
convention,
if
m
=
0
,
we
take
(
.)
i=1 i
i=1 i
Proof: Let I 2 C R and let sa = ho1; : : :; omi. There are two cases: either sa is a local state
in I , or it is not.
If sa is a local state in I , suppose that ra(m) = sa . Note that ' 2 Bel(I ; sa) if and
only if Pl(r;m)([['] (r;m)) > Pl(r;m)([[:'] (r;m)). Recall that, according to the denition of
conditioning, Pl(r;m) () is isomorphic to Pla (jR[; o1; : : :; om]). Thus, Pl(r;m)([['] (r;m)) >
Pl(r;m)([[:'] (r;m)) if and only if Pla (R['] j R[; o1; : : :; om ]) > Pla (R[:'] j R[; o1; : : :; om]).
Using C1, this is true if and only if Pla (R['V; o1; : : :; om ]) > Pla (R[:V'; o1; : : :; om ]). Using
REV4, this is true if and only if Pla (RV
[' ^ mi=1 oi ]) > Pla (R[:V' ^ mi=1 oi ]). We get that
' 2 Bel(I ; sa) if and only if Pla(R['V^ mi=1 oi ]) > Pla(R[:' ^ mi=1 oi ]). This implies that
' 2 Bel(I ; sa) if and only if PLI j= ( mi=1 oi )!'.
If sa is not a local state in I , then R[; o1; : : :; om] = ;, and by denition Pla (R[; o1; : : :; om ]) =
?. Using C1 and REV4, we get that PLa(R[Vmi=1 oi]) = ?, and thus PLI j= (Vmi=1 oi)!'
for all ' 2 Le . Since sa is not a local state in I , by denition
Bel(I ; sa) = Le . Hence, we
V
m
can conclude that ' 2 Bel(I ; sa) if and only if PLI j= ( i=1 oi )!'. ut
We now show that given a ranked plausibility structure PL we can construct a system
whose characteristic structure is default-isomorphic to PL.

Lemma A.5: Let PLK = (WK ; PlK ; K ) be a plausibility space that satises the conditions
of Lemma A.3. Then there is a system I 2 C R such that PLI = PLK .
155

Friedman & Halpern

Proof: Let PLK = (WK ; PlK ; K ) be a plausibility space that satises the conditions of
Lemma A.3. For each world w 2 WK and sequence of observations o1 ; o2; : : :, let rw;o ;o ;:::
be the run dened so that rew;o ;o ;:::(m) = w and raw;o ;o ;:::(m) = ho1 ; : : :; om i for all m. Let
R = frw;o ;o ;::: : k (w)(oi) = true for all ig. Dene  so that (r; m)(p) = K (re(m))(p)
for p 2 e , and so that  (r; m)(learn(')) = true if o(r;m) = ' for ' 2 Le . Finally, dene
the prior plausibility Pla so that Pla (R) = PlK (fw : 9r 2 R(w = re (0))g. It is easy to check
that this denition implies that Pla (R[']) = PlK ([['] PL ). Thus, PLI = PLK . Since PlK
is a ranking, Pla is also a ranking and thus qualitative.
We now verify that the resulting interpreted system is indeed in C R. It is easy to
check that I is a belief change system; that is, it satises BCS1{BCS5. The construction
is such that re (m) = re (0) for all runs r and times m. Thus, I satises REV1. Since
the prior Pla is a ranking, this system also satises REV2. Lemma A.2 implies that if '
is a consistent formula, then PlK ([['] PL ) > ?. This implies that Pla (R[']) > ?, and
thus the system satises REV3. Finally, it is easy to show that Pla (R['; o1; : : :; om ]) =
Pla(R[' ^ o1 ^ : : : ^ om ]) = PlK ([[' ^ o1 ^ : : : ^ om ] PL ). Thus, the system satises REV4.
1

1

1

2

1

2

2

2

K

K

ut

K

We are nally ready to prove Theorem 5.2.
Theorem 5.2: Let  be an AGM revision operator and let K  Le be a consistent belief
set. Then there is a system I(;K ) 2 C R such that Bel(I(;K ); hi) = K and
Bel(I(;K ); hi)  ' = Bel(I(;K ); h'i)
for all ' 2 Le .
Proof: Let  be an AGM revision operator and let K  Le be a consistent belief set. By
Lemmas A.2 and A.5, there is a system I(;K ) = (R(;K ); (;K ); P(;K )) 2 C R such that
PLI  j= '
if and only if 2 K  '. Our construction is such that 2 K  ' if and
only if PLI  j= ' . Using Lemma A.4, we get that PLI  j= '
if and only if
2 Bel(I(;K); h'i). Thus, K  ' = Bel(I(;K); h'i).
Finally, we show Bel(I(;K ); hi) = K . We start by showing that K  true = K . Using R3,
we get that K  true  Cl(K [ftrueg) = K . Since K is consistent, by R4, Cl(K [ftrueg) 
K  true. Thus, K  true = K . By Lemma A.4, we have that Bel(I ; hi) = Bel(I ; htruei).
Since Bel(I ; htruei) = K  true, we conclude that Bel(I(;K ); hi) = K . ut
We next prove Theorem 5.3.
Theorem 5.3: Let I be a system in C R. Then there is an AGM revision operator I such
that
Bel(I ; hi) I ' = Bel(I ; h'i)
for all ' 2 Le .
Proof: Let I = (R; ; P ) be a system in C R. It is easy to verify that PLI satises the
conditions of Lemma A.3 with K = Bel(I ; hi). This lemma implies that there is a revision
operator I such that 2 K I ' if and only if PLI j= ' . Using Lemma A.4, we have
that 2 Bel(I ; h'i) if and only if PlI j= ' . Thus, we have that K I ' = Bel(I ; h'i)
for all formulas '. ut
(

!

;K )

(

;K )

!

(

!

156

!

;K )

!

Modeling Belief in Dynamic Systems. Part II.

Theorem 5.4: Let I be a system in C R and sa = ho1; : : :; omi be a local state in I . Then
there is an AGM revision operator I ;s such that
Bel(I ; sa) I ;s ' = Bel(I ; sa  ')
for all formulas ' 2 Le such that o1 ^ : : :om ^ ' is consistent.
Proof: The structure of the proof is similar to that of Theorem 5.3. As in that proof,
a

a

we construct a ranked plausibility structure and use Lemma A.3 to nd an AGM revision
operator. The main dierence is that after observing '1 ; : : :; 'k , some events are considered
impossible. Lemma A.3, however, requires that all possible formulas are assigned a positive
plausibility. We overcome this problem by assigning a \ctional" positive plausibility to all
non-empty events that are ruled out by the previous observations.
We proceed as follows. Let d0 be a new plausibility value that is less plausible than
all positive plausibilities in Pla; that is, if Pla (A) > ?, then Pla (A) > d0 . Let I =
(R; ; P ) 2 C R ; let sa = hoV1 ; : : :; om i. We dene PL = (R; Pl; PLI ), where Pl is such that
m o ]); d ) for all consistent formulas '. This denition implies
Pl([['] ) = max(Pla (R[' ^ V
0
i=1 i
V
that if ' is consistent with mi=1 oi , then Pl([['] PLV) = Pla (R['1 ^ mi=1 oi ]).
We now Vprove that if ' is consistent with mi=1 oi , then PL j= '
if and only if
PLI j= (' ^ m
o
)
.
i
i=1
V
Vm o
For the \if" part, assume that PLI j=V('^ mi=1 oi ) . Since ' is consistent
with
i=1 i
m o ])) > ?. Thus, Pl (R[(' ^ (Vm o )) ^ ]) >
it follows, from
REV3,
that
Pl
(
R
[
'
^
(
a
i
a
i
i
=1
i
=1
V
V o . This implies
Pla(R[(' ^ ( mi=1 oi )) ^ : ])  ?V. Thus, ' ^ is consistent with mi=1
V i
that Pl([[' ^ ] ) = Pla (R[(' ^ ( mi=1 oi )) ^ ] > max(d0; Pla (R[(' ^ ( mi=1 oi )) ^ : ]) =
Pl([[' ^ : ] ). We conclude that PL j= ' .
Vm o )) . This implies that
For the \only
if"
part,
assume
that
PL
j
6
=
(
'
^
(
I
i=1 i
V
V
Pla(R[(' ^ ( mi=1 oi )) ^ V]) 6> Pla (R[(' ^ ( mi=1 oi ))V ^ : ]). Since Pla is a ranking, it
follows
that Pla(R[(' ^ ( mi=1 oiV)) ])  Pla (R[(' ^ ( mi=1 oi ))V ^ : ]). Since ? < Pla (R[' ^
V
m
( i=1 oi )]) =Vmax(Pla (R[(' ^ ( mi=1 oi )) ^ ]); Pla (R[(' ^ ( mi=1 oi )) ^ : ])), we have that
Pla(R[(' ^ ( mi=1 oi )) ^ : ]) > ?. We conclude that Pl([[' ^ : ] )  Pl([[' ^ ] ). Thus,
PL 6j= ' .
It is easy to verify that PL is ranked, and satises the requirements of Lemma A.3. Thus,
there exists a revision operator I ;s such that 2 K I ;s ' if and only Vif PL j= ' ,
where K = f' : PL j= true 'g. Moreover,Vsince for all ' consistent with mi=1 oi we have
thatPL j= '
if and only if PLI j= (' ^ ( mi=1 oi )) V , then, from Lemma A.4, it follows
that K = Bel(I ; sa) and that if ' is consistent with mi=1 oi , then PL j= '
if and only
if 2 Bel(I ; sa  '). ut

!

!

!

!

!

!

!

!

a

!

!

a

!

Theorem 5.5: Let I be a system in C R whose local states are EL . There is a function
e

BelI that maps epistemic states to belief states such that
 if sa is a local state of the agent in I , then Bel(I ; sa) = BelI (sa), and
 (; BelI ) satises R10{R80 .

Proof: As we said earlier, roughly speaking, we dene BelI (sa) = Bel(I ; sa) when sa is a
local state in I . If sa is not in I , then we set BelI (sa) = Bel(I ; s0), where s0 is the longest
157

Friedman & Halpern

consistent sux of sa . We now make this denition precise, and show that the resulting
BelI satises R10 {R80 .
We proceed as follows. We dene a function f () that maps sequences of observations
to suxes as follows: 8
><> hi
if m = 0,
i
if m > 0 and om is inconsistent,
f (ho1; : : :; omi) = > hhfalse
o
;
:
:
:;
o
i
otherwise, with k  m the minimal index
k
m
>:
s. t. 6`L :(ok ^ : : : ^ om ).
Aside from the special case where om is inconsistent, we simply choose the longest sux of
sa that is still consistent. We dene BelI (sa) = Bel(I ; f (sa)). Clearly, if sa is a local state
in I , then f (sa ) = sa , so BelI (sa ) = Bel(I ; sa).
We now have to show that (; BelI ) satises R10 {R80. The proof outline is as follows.
Given a particular state sa , we construct a ranked plausibility structure that corresponds,
in the sense of Lemma A.2, to belief change from sa . We then use Lemma A.3 to show that
belief changes from sa satises the AGM postulates, i.e., R1{R8. Since this is true from
any sa , we get that BelI satises R10 {R80 .
Let sa = ho1; : : :; om i. We dene a ranked plausibility space that has the following
structure. The most plausible events are the ones consistent with o1 ^ : : : ^ om . They are
ordered according to the prior ranking conditioned on o1 ^ : : : ^ om . The next tier of events
are those that are inconsistent with o1 ^ : : : ^ om but are consistent o2 ^ : : : ^ om . Again,
these are ordered according to the prior ranking conditioned on o2 ^ : : : ^ om . We continue
this way; the last tier consists of all events that are inconsistent with om .
V Formally, let PL = (RV; Pl; PLI ), where Pl is such that Pl([['] )  Pl([[ ] ) if Pla(R[' ^
( mi=k oi ]))  Pla (R[ ^ ( mi=k oi ])) where k V m + 1 is the greatest integer such that for all
j < k, ' and are both inconsistent with mi=j oi. It is easy to see that PL is ranked, and
that if ' is consistent, then Pl([['] ) > ?.
Let ' 2 Le . We now show that PL j= '
if and only if 2 BelI (sa  '). If ' is
inconsistent, then PL j= ' for all . Moreover, since ' is inconsistent, f (sa  ') = hfalsei,
and thus BelI (sa  ') = Le . We conclude that '
if and only if 2 BelI (sa  '). If ' is
consistent,
then
let
k

m
+1
be
the
greatest
integer
such
that for all j < k, ' is inconsistent
V
m
with i=j oi . It is easy to verify that f (sa  ') = hok ; : : :; om ; 'i. From Lemma
V A.4, it follows
that 2 BelVI (sa  ') = Bel(I ; hok ; : : :; om ; 'i) if and only if Pla (R[(' ^ ( mi=k oi )) ^ ]) >
Pla(R[(' ^ ( mi=k oi )) ^ : ]).VWe now show that this is the Vcase if and only if PL j= ' .
Suppose thatVPLa (R[(' ^ ^( mi=k oi )) ^ ]) > PLa (R[(' ^ ( mi=k oi )) ^ : ]). Then, clearly,
Pla(R[(' ^ ( mi=k oi )) ^ ]) > ?, and thus ' ^ is consistent with ok ; : : :; om . Since both
' ^ and ' ^ : are inconsistent with oj ; : : V:; om for all j < k, we have that
V Pl([[' ^ ] ) >
Pl([[' ^ : ] ). On other hand, if Pla (R[(' ^V( mi=k oi )) ^ ]) 6> Pla (R[(' ^ (V mi=k oi )) ^ : ]),
then since Pla is a ranking PLa(R[(' ^ ( mi=k oi )) ^ ])  PLa (R[(' ^ ( miV=k oi )) ^ : ]).
Moreover, since ' is consistent Vwith ok ^ : : : ^ om , we have that Pla (R[' ^ ( mi=k oi )]) > ?.
This implies that Pla (R[(' ^ ( mi=k oi )) ^ : ]) > ? and thus Pl([[' ^ ] )  Pl([[' ^ : ] ).
We conclude that PL j= '
if and only if 2 BelI (sa  ').
By Lemma A.3, there is a revision operator s that satises R1{R8 such that 2 K  '
if and only if PL j= ' . It is not hard to check that this implies that the change from
BelI (sa ) to BelI (sa  ') satises R10 {R80 . ut
e

!

!
!

!

!

!

a

158

Modeling Belief in Dynamic Systems. Part II.

Proposition 5.6: Let I be a system in C R whose local states are EL . There is a function
e

BelI that maps epistemic states to belief states such that
 if sa is a local state of the agent in I , then Bel(I ; sa) = BelI (sa), and
 (; BelI ) satises R10{R90 .
Proof: As we said in the main text, we show that the function BelI dened in the proof of
Theorem 5.5 satises R90 . Let sa = ho1; : : :; om i, and let '; 2 Le be formulas such that
6`L :(' ^ ). Since ' is consistent with , we get that f (sa  '  ) = hok ; : : :; om; '; i,
where k  m is the least integer such that ' ^ is consistent with ok ; : : :; om . For the same
reason, we get that f (sa  ' ^ ) = hok ; : : :; om; ' ^ i. Using Lemma A.4 we immediately
get that Bel(I ; hok ; : : :; om ; '; i) = Bel(I ; hok ; : : :; om ; ' ^ i). Thus, we conclude that
BelI (sa  '  ) = BelI (sa  ' ^ ). ut
e

Theorem 5.7: Given a function BelL mapping epistemic states in EL to belief sets over
Le such that BelL (hi) is consistent and (BelL ; ) satises R10{R90, there is a system I 2 C R
whose local states are in EL such that BelL (sa) = Bel(I ; sa) for each local state sa in I .
Proof: We show that Bel(I ; sa) = BelL (sa) for local states sa in I , where I is the system
guaranteed to exist by Theorem 5.2 such that Bel(I ; hi) = BelL (hi) and Bel(I ; h'i) =
BelL (h'i) for all ' 2 Le . We prove this by induction on the length m of sa . For
m  1, this is true by our choice of I . For the induction case, let sa = ho1; : : :; omi
be a local state in I . Thus,, o1 ^ : : : ^ om is consistent. From R90 , it follows that
BelL (ho1; : : :; om i) = BelL (ho1; : : :; om,2; om,1 ^ om i). Using the induction hypothesis,
we have that BelL (ho1; : : :; om,2; om,1 ^ om i) = Bel(I ; ho1; : : :; om,2 ; om,1 ^ om i). Using
Lemma A.4, we get that Bel(I ; ho1; : : :; om,2 ; om,1 ^ om i) = Bel(I ; ho1; : : :; omi). Thus, we
conclude that BelL (ho1 ; : : :; om i) = Bel(I ; ho1; : : :; om i). ut
e

e

e

e

e

e

e

e

e

e

e

e

e

A.2 Proofs for Section 6

In this section we prove Theorem 6.2. We now show that any system in C U corresponds to
an update structure. Suppose that I = (R; ; P ) 2 C U is such that the set of environment
states is Se and the prior of BCS5 is consistent with distance function d. Dene an update
structure UI = (Se ; e; d), where for p 2 e , e (se )(p) =  ((se; sa ))(p) for some choice of
sa. By BCS1, the choice of sa does not matter. It is easy to see that UPD1 ensures that
Se and e satisfy the requirements of the denition of update structures. We want to show
that belief change in I corresponds to belief change in UI in the sense of Theorem 6.1.
Since Theorem 6.1 states that any belief change operation dened by an update structure
satises U1{U8, this will suce to prove the \if" direction of Theorem 6.2. To prove the
\only if" direction of Theorem 6.2, we show that that for any update structure U , there is
a system I 2 C U such that UI = U .
We start with preliminary denitions and lemmas for the \if" direction of Theorem 6.2.
Let sa = ho1; : : :; omi. We dene States (I ; sa) = fs 2 Se : s j=  for all  2 Bel(I ; sa)g.
Clearly, if ' is such that Bel(I ; sa) = Cl('), then States (I ; sa) = [ '] UI . To show that
belief change in I corresponds to belief change in UI we have to show that
States (I ; sa  ) = minUI (States (I ; sa); [ ] UI ):
159

Friedman & Halpern

This is proved in Lemma A.8. To prove this lemma, we need some preliminary lemmas.

Lemma A.6: Let I 2 C U , and let sa = ho1; : : :; omi. Then ' 2 Bel(I ; sa) if and only if
(I ; r; 0) j= (o1 ^ : : : ^ m om )!m ' for some run r in R.
Proof: The proof of this lemma is analogous to the proof of Lemma A.4, using UPD3 and
UPD4 instead of REV3 and REV4. We do not repeat the argument here. ut
We now provide an alternative characterization of States (I ; sa) in terms of the agent's
prior on run-prexes.

Lemma A.7: Let I 2 C U and let sa = ho1; : : :; omi. Then sm 2 States (I ; sa) if and only if
there is a sequence of states [s0 ; : : :; sm]  R[true; o1; : : :; om] such that Pla ([s0; : : :; sm ]) <
6
Pla(R[true; o1; : : :; om] , [s0 ; : : :; sm]).
Proof: For the \if" direction, assume that there is a sequence s0; : : :; sm such that
[s0 ; : : :; sm ]  R[true; o1; : : :; om], and Pla ([s0; : : :; sm ]) <
6 Pla(R[true; o1; : : :; om] ,
[s0 ; : : :; sm ]). By way of contradiction, assume that sm 62 States (I ; m). Thus, there is a formula  2 Bel(I ; m) such that sm j= : . From Lemma A.6 it follows that since  2 Bel(I ; sa),
(I ; r; 0) j= (o1 ^ : : : ^ m om )!m  for some run r in R. From the denition of conditioning it follows that Pla (R[true; o1; : : :; om,1 ; om ^  ]) > Pla (R[true; o1; : : :; om,1; om ^ : ]).
Since sm j= : , we get that [s0; : : :; sm ]  R[true; o1; : : :; om,1 ; om ^ : ] and that
R[true; o1; : : :; om,1; om ^ ]  R[true; o1; : : :; om] , [s0; : : :; sm]. From A1, it follows that
Pla([s0 ; : : :; sm]) < Pla (R[true; o1; : : :; om ] , [s0; : : :; sm ]), which contradicts our starting
assumption. We conclude that sm 2 States (I ; sa).
For the \only if" direction, assume that sm 2 States (I ; a). Since Se is nite and e
assigns a dierent truth assignment to each state in Se , there is a formula  2 Le that
characterizes sm ; that is, s j=  if and only if s = sm . Since sm 2 States (I ; sa), we have that
: 62 Bel(I ; sa). Using Lemma A.6, we get that (I ; r; 0) 6j= (o1 ^ : : : ^ m om)!m :
for all runs r 2 R. By BCS5, this is true if and only if Pla (R[true; o1; : : :; om ]) > ?
and Pla(R[true; o1; : : :; om,1; om ^  ]) <
6 Pla(R[true; o1; : : :; om,1; om ^ :]). By UPD2,
there is a sequence [s0 ; : : :; sm]  R[true; o1; : : :; om,1 ; om ^  ] such that Pla ([s0; : : :; sm ]) <
6
Pla([s00 ; : : :; s0m]) for all [s00 ; : : :; s0m]  R[true; o1; : : :; om,1 ; om ^: ]. Moreover, without loss
of generality, we can assume that Pla ([s0; : : :; sm]) <
6 Pla([s00; : : :; s0m]) for all [s00; : : :; s0m] 
R[true; o1; : : :; om,1; om ^ ], since there are only nitely many such sequences. Thus, by
UPD2, Pla ([s0; : : :; sm ]) <
6 Pla(R[true; o1; : : :; om] , [s0; : : :; sm]). ut
We can now prove that belief change in I corresponds to belief change in UI .
Lemma A.8: Let I = (R; ; P ) 2 C U Then
States (I ; sa  ) = minUI (States (I ; sa); [ ] UI )
for all local states sa and formulas 2 Le .
Proof: Let Pla be the prior in I ; assume that Pla consistent with a distance function d.
Let sa = ho1 ; : : :; om i.
160

Modeling Belief in Dynamic Systems. Part II.

To show that minUI (States (I ; sa); [ ] UI )  States (I ; sa  ), suppose that s 2
minUI (States (I ; sa); [ ] UI ). Thus, there is a state sm 2 States (I ; sa) such that d(sm ; s0) 6<
d(sm ; s) for all states s0 that satisfy . We want to show that s 2 States (I ; sa 
). From Lemma A.7, it follows that, since sm 2 States (I ; sa), there is a sequence
s0 ; : : :; sm,1 such that [s0; : : :; sm ] 2 R[true; o1; : : :; om,1 ; om] and Pla ([s0; : : :; sm]) 6<
Pla(R[true; o1; : : :; om,1; om ] , [s0 ; : : :; sm ]). We now show that Pla ([s0; : : :; sm; s]) 6<
Pla(R[true; o1; : : :; om; ] , [s0 ; : : :; sm ; s]). By Lemma A.7, this suces to show that
s 2 States (I ; sa  ). Suppose that [s00 ; : : :; s0m+1]  R[true; o1; : : :; om ; ] , [s0; : : :; sm; s].
If [s0; : : :; sm ] = [s00 ; : : :; s0m ], then we have that d(s0m ; s0m+1 ) 6< d(sm ; s). Since Pla is consistent with d, it follows that Pla ([s0; : : :; sm ; s]) 6< Pla ([s00; : : :; s0m ; s0m+1]). If [s0 ; : : :; sm] 6=
[s00 ; : : :; s0m ], then, since Pla ([s0 ; : : :; sm ]) 6< Pla ([s00; : : :; s0m]) and Pla is consistent with d,
we have that Pla ([s0; : : :; sm ; s]) 6< Pla ([s00 ; : : :; s0m ; s0m+1 ]).
Since
Pla ([s0; : : :; sm ; s])
6<
Pla ([s00; : : :; s0m ; s0m+1 ])
0
0
for all [s0; : : :; sm+1 ]  R[true; o1; : : :; om ; ] , [s0 ; : : :; sm ; s] and Pla is prex-dened, we
have that Pla([s0 ; : : :; sm; s]) 6< Pla (R[true; o1; : : :; om ; ] , [s0; : : :; sm ; s]. By Lemma A.7,
s 2 States (I ; sa  ), as desired.
To show that States (I ; sa  )  minUI (States (I ; sa); [ ] UI ), suppose that s 2
States (I ; sa  ). By Lemma A.7, there is a sequence s0 ; : : :; sm such that [s0 ; : : :; sm ; s]) 
R[true; o1; : : :; om; ] and Pla([s0; : : :; sm; s]) 6< Pla(R[true; o1; : : :; om; ] , [s0; : : :; sm; s]).
We want to show that sm 2 States (I ; sa) and that d(sm ; s0) 6< d(sm ; s) for all s0 that satisfy
. This suces to prove that s 2 minUI (States (I ; sa); [ ] UI ).
To show that sm 2 States (I ; sa), by Lemma A.7, it suces to show that Pla ([s0; : : :; sm ]) 6<
Pla(R[true; o1; : : :; om] , [s0; : : :; sm ]). Let s00 ; : : :; s0m be a sequence such that [s00 ; : : :; s0m] 
R[true; o1; : : :; om]. By denition, [s00; : : :; s0m; s]  R[true; o1; : : :; om; ]. Thus, from our
choice of s0 ; : : :; sm , it follows that Pla ([s0; : : :; sm ; s]) 6< Pla ([s00; : : :; s0m; s]). Since Pla is
consistent with d, it follows that Pla ([s0; : : :; sm]) 6< Pla ([s00; : : :; s0m ]). Thus, by Lemma A.7,
sm 2 States (I ; sa). To see that d(sm; s0 ) 6< d(sm ; s) for all s0 that satisfy , let s0 6= s be such
that s0 j= . Thus, [s0 ; : : :; sm ; s0]  [true; o1; : : :; om; ]. From our choice of s0 ; : : :; sm,
it follows that Pla ([s0 ; : : :; sm ; s]) 6< Pla([s0 ; : : :; sm; s0 ]). Since Pla is consistent with d, it
follows that d(sm ; s0) 6< d(sm ; s). We conclude that s 2 minUI (States (I ; sa); [ ] UI ). ut
We now have the tools to prove the \if" direction of Theorem 6.2.

Lemma A.9: If I = (R; ; P ) 2 C U , then there is a belief change operator  that satises
U1{U8 such that

Bel(I ; sa)  = Bel(I ; sa  )
for all local states sa and formulas 2 Le .

Proof: Let I 2 C U . Using the arguments we presented above, it easy to check that UI
is an update structure. By Theorem 6.1, there is a belief change operator  that satises
U1{U8 such that [ '  ] UI = minUI ([['] UI ; [ ] UI ) for all '; 2 Le . From Lemma A.8, it
follows that Bel(I ; sa)  = Bel(I ; sa  ): ut
We now prove the \only if" direction of Theorem 6.2. Suppose that  is a belief change
operator that satises U1{U8. According to Theorem 6.1, there is an update structure U
that corresponds to . Thus, it suces to show that there is a system I such that UI = U.
161

Friedman & Halpern

Lemma A.10: Let U = (W; d; U ) be an update structure. Then there is a system I 2 C U
such that UI = U .

Proof: Given the sequences w0; w1; : : : 2 W and o1; o2; : : : 2 Le, let rw ;w ;:::;o ;o ;::: be the
run dened so that rew ;w ;:::;o ;o ;:::(m) = wm and raw ;w ;:::;o ;o ;:::(m) = ho1; : : :; om i. Let
R = frw ;w ;:::;o ;o ;::: : U (wm)(om) = true for all mg. Dene  such that (r; m)(p) =
U (re(m))(p) for p 2 e and  (r; m)(learn(')) = true if o(r;m) = ' for ' 2 Le.
It is clear that (R;  ) satises BCS1{BCS4 and UPD1. Thus, all that remains to show
0

0

0

1

1

1

1

2

0

1

1

1

1

2

2

2

is that there is a prior plausibility measure Pla that satises UPD2{UPD4. This will ensure
that (R; ; P ) 2 C U .
We proceed as follows. We dene a preferential space (R; ) where r  r0 if and only
if there is some m such that re (k) = re0 (k) for all 0  k  m, re (m + 1) 6= re0 (m + 1), and
d(re(m); re(m +1)) < d(re0 (m); re0 (m +1)). Recall that r  r0 denotes that r is preferred over
r0. Thus, this ordering is consistent with the comparison of events of the form [s0 ; : : :; sn ]
according to UPD2.
Using the construction of Proposition 2.2, there is a plausibility space (R; Pla ) such that
Pla(A)  Pla (B ) if and only if for all r 2 B , A, there is a run r0 2 A such that r0  r and
there is no r00 2 B , A such that r00  r0. By (Friedman & Halpern, 1998b, Theorem 5.5),
Pla is a qualitative plausibility measure. We now show that it satises UPD2{UPD4.
We start with UPD2. To show that PlA is consistent with d, we need to show that
Pla([s0 ; : : :; sn ]) < Pla ([s00; : : :; s0n ]) if and only if there is some m < n such that sk = s0k
for all 0  k  m, and d(sm ; sm+1) > d(s0m ; s0m+1 ). Suppose that Pla ([s0; : : :; sn ]) <
Pla([s00 ; : : :; s0n ]). Let r be some run in [s0 ; : : :;0n ]. Without loss of generality we can assume
that re (m) = re (n) for all m > n. Since Pla ([s0; : : :; sn ]) < Pla ([s00 ; : : :; s0n ]), there is a run
r0 2 [s00 ; : : :; s0n] such that r0  r. By denition, this implies that there is an m such that
re(k) = re0 (k) for all 0  k  m, and d(re0 (m); re0 (m + 1)) < d(re(m); re(m + 1)). We claim
that m < n. For if m  n, then re (m +1) = re (m) by construction, so d(re(m); re(m +1)) =
d(re(m); re(m))  d(re0 (m); re0 (m + 1)) and r0 6 r, a contradiction. Thus, sk = s0k for all
0  k  m, d(s0m ; s0m+1 ) < d(sm ; sm+1 ).
For the converse, suppose that there is an m < n such that sk = s0k for all 0  k  m,
and d(s0m ; s0m+1) < d(sm ; sm+1 ). Let r0 be the run where re0 (k) = s0k for k  n, re0 (k) = s0n
for k  n, and o(r0 ;k) = true for all k. It follows r0  r for all runs r0 2 [s0 ; : : :; sn ]. Thus,
Pla([s0 ; : : :; sn ]) < Pla ([s00; : : :; s0n ]).
To show that Pla is prex-dened, we must show that Pla (R['0; : : :; 'n ])  Pla (R[ 0; : : :; n])
if and only if for all [s0; : : :; sn ]  R[ 0; : : :; n] ,R['0; : : :; 'n], there is some [s00 ; : : :; s0n ] 
R['0; : : :; 'n] such that Pla([s00; : : :; s0n]) > Pla([s0; : : :; sn]). Suppose that Pla(R['0; : : :; 'n]) 
Pla(R[ 0; : : :; n ]). Let [s0; : : :; sn ]  R[ 0; : : :; n ] , R['0; : : :; 'n ]. Let r 2 [s0 ; : : :; sn ] be
a run such that re (m) = re (n) for all m  n. Since Pla (R['0; : : :; 'n])  Pla(R[ 0; : : :; n ])
there is a run r0 2 R['0; : : :; 'n] such that r0  r. This implies that there is an m such
that re (k) = re0 (k) for all 0  k  m, and d(re0 (m); re0 (m + 1)) < d(re(m); re(m + 1)).
As before, we have that m < n, and thus Pla([re0 (0); : : :; re0 (n)]) > Pla ([s0 ; : : :; sn ]). Since
r0 2 R['0; : : :; 'n], we also have that [re0 (0); : : :; re0 (n)]  R['0; : : :; 'n ], as desired.
For the converse, assume that for all [s0 ; : : :; sn ]  R[ 0; : : :; n ] , R['0; : : :; 'n] there
is some [s00; : : :; s0n ]  R['0; : : :; 'n] such that Pla([s00 ; : : :; s0n ]) > Pla ([s0; : : :; sn ]). This implies that Pla (R['0; : : :; 'n]) > Pla ([s0; : : :; sn ]) for all for all [s0 ; : : :; sn ]  R[ 0; : : :; n ] ,
162

Modeling Belief in Dynamic Systems. Part II.

R['0; : : :; 'n]. Since there are only nitely many sequences of states of length m, we can apply A2, and conclude that Pla(R['0; : : :; 'n ]) > Pla(R[ 0; : : :; n ] , R['0; : : :; 'n ]). Thus,
Pla(R['0; : : :; 'n ])  Pla ((R[ 0; : : :; n])).
For UPD3, recall that the construction of Proposition 2.2 is such that Pla(R) > ? for
all non-empty R  R. Since, by our construction, the set R['0; : : :; 'n] is non-empty for
all sequences '0 ; : : :; 'n of consistent formulas, UPD3 must hold.
Finally, we consider UPD4. We have to show that Pla(R['0; : : :; 'n+1 ; o1; : : :; on]) 
Pla(R[ 0; : : :; n+1 ; o1; : : :; on ]) if and only if Pla (R['0; '1^o1 ; : : :; 'n^on ; 'n+1 ])  Pla (R[ 0; 1^
o1 ; : : :; n ^on; n+1 ]). By construction, R['0; : : :; 'n+1; o1; : : :; on ]  R['0; '1^o1 ; : : :; 'n ^
on ; 'n+1]. On the other hand, for each run r 2 R['0; '1 ^ o1; : : :; 'n ^ on ; 'n+1 ] there is
a run r0 2 R['0; : : :; 'n+1 ; o1; : : :; on ] such that re0 (m) = re (m) for all m, and o(r;m) = om
for 1  m  n. Since the preference ordering on runs is a function only of the environment states, it is clear that r and r0 are compared in the same manner; that is for all
r00, r00  r if and only if r00  r0, and r  r00 if and only if r0  r00. Thus, we conclude
that for the purposes of the preference ordering, both R['0; '1 ^ o1 ; : : :; 'n ^ on ; 'n+1 ] and
R['0; : : :; 'n+1; o1; : : :; on] are compared in the same manner to other sets. It easy to see
that this suces to show that Pla satises UPD4. ut
Finally, we can prove Theorem 6.2.
Theorem 6.2: A belief change operator  satises U1{U8 if and only if there is a system
I 2 C U such that
Bel(I ; sa)  = Bel(I ; sa  )
for all epistemic states sa and formulas 2 Le .
Proof: The \if" direction follows from Lemma A.9. For the \only if" direction, assume that
 satises U1{U8. By Theorem 6.1, there is an update structure U such that [ '  ] UI =
minUI ([['] UI ; [ ] UI ) for all '; 2 Le . By Lemma A.10, there is a system I 2 C U such that
UI = U. From Lemma A.8, it follows that Bel(I ; sa)  = Bel(I ; sa  ) for all local states
sa and formulas 2 Le . ut

References

Alchourron, C. E., Gardenfors, P., & Makinson, D. (1985). On the logic of theory change:
partial meet functions for contraction and revision. Journal of Symbolic Logic, 50,
510{530.
Boutilier, C. (1992). Normative, subjective and autoepistemic defaults: adopting the Ramsey test. In Principles of Knowledge Representation and Reasoning: Proc. Third
International Conference (KR '92), pp. 685{696. Morgan Kaufmann, San Francisco,
Calif.
Boutilier, C. (1994a). Conditional logics of normality: a modal approach. Articial Intelligence, 68, 87{154.
Boutilier, C. (1994b). Unifying default reasoning and belief revision in a modal framework.
Articial Intelligence, 68, 33{85.
163

Friedman & Halpern

Boutilier, C. (1996a). Iterated revision and minimal change of conditional beliefs. Journal
of Philosophical Logic, 25, 262{305.
Boutilier, C. (1996b). Abduction to plausible causes: An event-based model of belief update.
Articial Intelligence, 83, 143{166.
Boutilier, C. (1998). A unied model of qualitative belief change: A dynamical systems
perspective. Articial Intelligence, 98, 281{316.
Boutilier, C., Friedman, N., & Halpern, J. Y. (1998). Belief revision with unreliable observations. In Proceedings, Fifteenth National Conference on Articial Intelligence
(AAAI '96), pp. 127{134.
Burgess, J. (1981). Quick completeness proofs for some logics of conditionals. Notre Dame
Journal of Formal Logic, 22, 76{84.
Darwiche, A., & Pearl, J. (1997). On the logic of iterated belief revision. Articial Intelligence, 89, 1{29.
Davis, R., & Hamscher, W. (1988). Model-based reasoning: troubleshooting. In Shrobe,
H., & for Articial Intelligence, T. A. A. (Eds.), Exploring AI, pp. 297{346. Morgan
Kaufmann, SF.
de Rijke, M. (1992). Meeting some neighbors. Research report LP-92-10, University of
Amsterdam.
del Val, A., & Shoham, Y. (1992). Deriving properties of belief update from theories of
action. In Proceedings, Tenth National Conference on Articial Intelligence (AAAI
'92), pp. 584{589. AAAI Press, Menlo Park, CA.
del Val, A., & Shoham, Y. (1993). Deriving properties of belief update from theories of action
(II). In Proc. Thirteenth International Joint Conference on Articial Intelligence
(IJCAI '93), pp. 732{737 San Francisco. Morgan Kaufmann.
del Val, A., & Shoham, Y. (1994). A unied view of belief revision and update. Journal of
Logic and Computation, 4.
Dubois, D., & Prade, H. (1990). An introduction to possibilistic and fuzzy logics. In
Shafer, G., & Pearl, J. (Eds.), Readings in Uncertain Reasoning, pp. 742{761. Morgan
Kaufmann, San Francisco, Calif.
Dubois, D., & Prade, H. (1991). Possibilistic logic, preferential models, non-monotonicity
and related issues. In Proc. Twelfth International Joint Conference on Articial Intelligence (IJCAI '91), pp. 419{424. Morgan Kaufmann, San Francisco.
Fagin, R., Halpern, J. Y., Moses, Y., & Vardi, M. Y. (1995). Reasoning about Knowledge.
MIT Press, Cambridge, Mass.
Freund, M., & Lehmann, D. (1994). Belief revision and rational inference. Tech. rep. TR
94-16, Hebrew University.
164

Modeling Belief in Dynamic Systems. Part II.

Friedman, N. (1997). Modeling Beliefs in Dynamic Systems. Ph.D. thesis, Stanford.
Friedman, N., & Halpern, J. Y. (1994). Conditional logics of belief change. In Proc. National
Conference on Articial Intelligence (AAAI '94), pp. 915{921. AAAI Press, Menlo
Park, CA.
Friedman, N., & Halpern, J. Y. (1995). Plausibility measures: a user's manual. In Besnard,
P., & Hanks, S. (Eds.), Proc. Eleventh Conference on Uncertainty in Articial Intelligence (UAI '95), pp. 175{184. Morgan Kaufmann, San Francisco.
Friedman, N., & Halpern, J. Y. (1996). A qualitative Markov assumption and its implications for belief change. In Proc. Twelfth Conference on Uncertainty in Articial
Intelligence (UAI '96), pp. 263{273.
Friedman, N., & Halpern, J. Y. (1997). Modeling belief in dynamic systems. part I: foundations. Articial Intelligence, 95 (2), 257{316.
Friedman, N., & Halpern, J. Y. (1998a). Belief revision: A critique. Journal of Logic,
Language and Information, To appear. Also available at http://www.cs.huji.ac.
il/~nir. A preliminary version appeared in L. C. Aiello, J. Doyle, and S. C. Shapiro
(eds.) Principles of Knowledge Representation and Reasoning: Proc. 5'th International Conference, pp. 421{431, 1996.
Friedman, N., & Halpern, J. Y. (1998b). Plausibility measures and default reasoning.
Journal of the ACM, To appear. Also available at http://www.huji.ac.il/~nir. A
preliminary version appeared in Proc., 13'th National Conference on Articial Intelligence, pp. 1297{1304, 1996.
Fuhrmann, A. (1989). Reective modalities and theory change. Synthese, 81, 115{134.
Gardenfors, P. (1986). Belief revision and the Ramsey test for conditionals. Philosophical
Review, 91, 81{93.
Gardenfors, P. (1988). Knowledge in Flux. MIT Press, Cambridge, Mass.
Gardenfors, P., & Makinson, D. (1988). Revisions of knowledge systems using epistemic
entrenchment. In Proc. Second Conference on Theoretical Aspects of Reasoning about
Knowledge, pp. 83{95. Morgan Kaufmann, San Francisco, Calif.
Goldszmidt, M., Morris, P., & Pearl, J. (1993). A maximum entropy approach to nonmonotonic reasoning. IEEE Transactions of Pattern Analysis and Machine Intelligence,
15 (3), 220{232.
Goldszmidt, M., & Pearl, J. (1996). Qualitative probabilities for default reasoning, belief
revision, and causal modeling. Articial Intelligence, 84, 57{112.
Grahne, G., Mendelzon, A., & Rieter, R. (1992). On the semantics of belief revision systems.
In Moses, Y. (Ed.), know92, pp. 132{142. Morgan Kaufmann, San Francisco, Calif.
Grove, A. (1988). Two modelings for theory change. Journal of Philosophical Logic, 17,
157{170.
165

Friedman & Halpern

Halpern, J. Y., & Fagin, R. (1989). Modelling knowledge and action in distributed systems.
Distributed Computing, 3 (4), 159{179. A preliminary version appeared in Proc. 4th
ACM Symposium on Principles of Distributed Computing, 1985, with the title \A
formal model of knowledge, action, and communication in distributed systems: preliminary report".
Halpern, J. Y., & Vardi, M. Y. (1989). The complexity of reasoning about knowledge and
time, I: lower bounds. Journal of Computer and System Sciences, 38 (1), 195{237.
Katsuno, H., & Mendelzon, A. (1991a). On the dierence between updating a knowledge base and revising it. In Principles of Knowledge Representation and Reasoning:
Proc. Second International Conference (KR '91), pp. 387{394. Morgan Kaufmann,
San Francisco, Calif.
Katsuno, H., & Mendelzon, A. (1991b). Propositional knowledge base revision and minimal
change. Articial Intelligence, 52 (3), 263{294.
Katsuno, H., & Satoh, K. (1991). A unied view of consequence relation, belief revision
and conditional logic. In Proc. Twelfth International Joint Conference on Articial
Intelligence (IJCAI '91), pp. 406{412.
Kautz, H. A. (1986). Logic of persistence. In Proceedings, Fifth National Conference on
Articial Intelligence (AAAI '86), pp. 401{405. AAAI Press, Menlo Park, CA.
Keller, A. M., & Winslett, M. (1985). On the use of an extended relational model to handle
changing incomplete information. IEEE Transactions on Software Engineering, SE11 (7), 620{633.
Kraus, S., Lehmann, D., & Magidor, M. (1990). Nonmonotonic reasoning, preferential
models and cumulative logics. Articial Intelligence, 44, 167{207.
Lehmann, D. (1995). Belief revision, revised. In Proc. Fourteenth International Joint
Conference on Articial Intelligence (IJCAI '95), pp. 1534{1540. Morgan Kaufmann,
San Francisco.
Levi, I. (1988). Iteration of conditionals and the Ramsey test. Synthese, 76, 49{81.
Lewis, D. K. (1973). Counterfactuals. Harvard University Press, Cambridge, Mass.
Manna, Z., & Pnueli, A. (1992). The Temporal Logic of Reactive and Concurrent Systems,
Vol. 1. Springer-Verlag, Berlin/New York.
Nayak, A. C. (1994). Iterated belief change based on epistemic entrenchment. Erkenntnis,
41, 353{390.
Pearl, J. (1989). Probabilistic semantics for nonmonotonic reasoning: a survey. In Brachman, R. J., Levesque, H. J., & Reiter, R. (Eds.), Proc. First International Conference
on Principles of Knowledge Representation and Reasoning (KR '89), pp. 505{516.
Reprinted in Readings in Uncertain Reasoning, G. Shafer and J. Pearl (eds.), Morgan
Kaufmann, San Francisco, Calif., 1990, pp. 699{710.
166

Modeling Belief in Dynamic Systems. Part II.

Rott, H. (1991). Two methods of constructing contractions and revisions of knowledge
systems. Journal of Philosophical Logic, 20, 149{173.
Rott, H. (1992). Two methods of constructing contraction and revisions of knowledge
systems. Journal of Logic, Language and Information, 1, 45{78.
Shafer, G. (1976). A Mathematical Theory of Evidence. Princeton University Press, Princeton, N.J.
Shoham, Y. (1987). A semantical approach to nonmonotonic logics. In Proc. 2nd IEEE
Symp. on Logic in Computer Science, pp. 275{279. Reprinted in M. L. Ginsberg (Ed.),
Readings in Nonmonotonic Reasoning, Morgan Kaufman, San Francisco, Calif., 1987,
pp. 227{250.
Shoham, Y. (1988). Chronological ignorance: experiments in nonmonotonic temporal reasoning. Articial Intelligence, 36, 271{331.
Spohn, W. (1988). Ordinal conditional functions: a dynamic theory of epistemic states.
In Harper, W., & Skyrms, B. (Eds.), Causation in Decision, Belief Change, and
Statistics, Vol. 2, pp. 105{134. Reidel, Dordrecht, Netherlands.
Wang, Z., & Klir, G. J. (1992). Fuzzy Measure Theory. Plenum Press, New York.
Williams, M. (1994). Transmutations of knowledge systems. In Principles of Knowledge
Representation and Reasoning: Proc. Fourth International Conference (KR '94), pp.
619{629. Morgan Kaufmann, San Francisco, Calif.
Winslett, M. (1988). Reasoning about action using a possible models approach. In Proceedings, Seventh National Conference on Articial Intelligence (AAAI '88), pp. 89{93.
AAAI Press, Menlo Park, CA.

167


	
 
			 ! #"$ % 
'&)( *,+( ---/.1020435062

789:;  <)( */=
->!?A@9	%&<B6/=
--

CEDGFIH1JKMLINOJQP8FIRSCEDGFITUP
JVP/DWFIXZY\[]Y/XZFIH_^a`bXdcEeIfgDGKVfihkjl[mKVDinWfgK

oMprqsqstvuwt'xysz1x#{|x

}~1$G~$}g~O$1~$)

l
  ) 
¡ 8¢A£   ¥¤$£  g¦/8¤/§     ¢
¨ ª©
«¬O'« ¨ ª

­s®¯°A®

 G±g²M¬M³v´

¨gµ·¶

¸º¹v»s¼½¾V¿¥¼
ÀÂÁÃ)ÄÃ!Å Ã!ÆAÄ
Ç
ÁÉÈsÊ·ÇÈsÊËÌªÍÌÈsÊlÆAÎ$ÏÎÐÆAÊÊÌªÊÑÒÄÃ ÓÃ8ÇÍ
ÅÂÍÁÃ)ÆsÅ4Å ÔÕWÏÍÌÈsÊÅÂÍ4ÁÆÍ;Í4ÁÃÄ4ÃÖÌÐÅgÊÈÒÔÊlÇ/ÃÄÍ4ÆsÌªÊÍ×
ÈÄZÌªÊlÇ/ÈsÕaÏÎÃ/Í4ÃÊÃ!ÅÅZÈAØ;ÙÊÈÚ;ÎªÃ!ËÑsÃaÚ;ÌªÍÁÛÄ4Ã8ÅÏlÃ!ÇÍÖÍ4È·ÍÁÃÜÅÍ
ÆÍÃÝÆsÊËÛÇ
ÁÆsÊÑsÃ!ÅBÈAØOÍÁÃÉÅ×ÅÍ4ÃÕÞÍÁÃ
ÏÎÐÆAÊlÅaÈsÏ¥ÃÄ
ÆÍÃIÈÊ$ßºàáÌÍ4ÁÈsÔÍÒÍ4ÁÃ8ÅÃ·ÆsÅ4Å ÔÕWÏÍÌÈsÊÅWÍ4ÁÃUÅ Ã!âÔÃÊÇÃ8ÅWÈAØBÈsÏ¥ÃÄ
ÆÍ4ÌªÈÊÅGÍÁÆAÍÝÆsÇ
ÁÌÃãÃ
Í4ÁÃZÑsÈÆAÎÐÅ;ËÃÏ¥ÃÊlËIÈsÊäÍÁÃ)ÌªÊÌªÍÌÐÆAÎÅÍ
ÆÍÃGÆAÊËÜÍÁÃZÈsÔÍ
Ç/ÈÕWÃ!ÅÂÈAØVÊÈÊËÃ/Í4ÃÄ4ÕaÌªÊÌÐÅ ÍÌÐÇÖÇ
ÁÆAÊÑÃ8ÅÂÌÊIÍÁÃ
Å×ÅÍ4ÃÕIßVÀÂÁÌÅ#Å ÃÍ Í4ÌªÊÑGÄ4ÆsÌÅÃ8ÅVÍÁÃiâÔÃ!ÅÍ4ÌªÈÊÅMÈsØ$ÁÈÚåÍÈZÄ4ÃÏÄÃ!Å Ã8ÊÍVÍ4ÁÃiÏÎÆsÊÅrÆsÊËaÁÈÚåÍÈGÏlÃ8Ä Ø5ÈÄÕ
ÏÎÐÆAÊäÅ Ã!ÆAÄ
Ç
Á$ßÀÂÁÃvÆsÊÅ ÚOÃÄ
ÅrÆsÄÃvâÔÌÍ4ÃvËÌæ|ÃÄ4ÃÊÍOØ5ÄÈÕmÍ4ÁÈÅÃiÌÊÝÍ4ÁÃBÅ ÌÕaÏÎªÃ8Ä;Ç/ÎÐÆsÅ4Å ÌÐÇÆsÎØ5Ä
ÆAÕaÃÚOÈsÄ4Ù|ß
çèÊWÍÁÌÅrÏÆAÏ¥ÃÄ!éAÚOÃgÆAÏÏÄ4ÈÆÇ
ÁGÇÈsÊËÌªÍÌÈsÊlÆAÎÏÎÐÆAÊÊÌªÊÑBØ5ÄÈÕmÆvÊÃÚºãÌÃÚ;Ï¥ÈsÌÊÍVÍ4ÁÆÍMÌÐÅVÕaÈAÍ4ÌªãÆAÍÃ8ËWê×
Í4ÁÃGÔlÅ ÃGÈAØ#Å4ÆÍ4ÌÅ ëlÆAêÌªÎÌÍ×·ÆsÎªÑÈsÄ4ÌÍ4ÁÕÒÅgÌÊìÇ/ÎÐÆsÅ4ÅÌÇ8ÆAÎ1ÏÎÆsÊÊÌÊÑßBÀ1Ä
ÆAÊlÅ ÎÐÆÍ4ÌªÊÑÜÇ/ÈsÊlËÌÍ4ÌªÈÊÆAÎÏÎÐÆAÊÊÌªÊÑ
Í4ÈìØ5ÈÄÕGÔÎÐÆAÃIÌªÊíÍÁÃ·ÏÄÈÏlÈÅ ÌªÍÌÈsÊlÆAÎÂÎªÈÑsÌÐÇÉÌÐÅÒÊÈsÍaØ5Ã8ÆsÅÌêÎªÃIê¥Ã8Ç8ÆAÔÅÃIÈAØBÌªÊÁÃÄ4ÃÊÍÝÇ/ÈsÕaÏÔÍ4ÆÍ4ÌªÈÊÆAÎ
ÎÌªÕaÌªÍ4ÆAÍÌÈsÊÅ8ßQçèÊÅÍ4Ã8ÆËésÚOÃÂÍÄ
ÆAÊÅÎÐÆÍÃgÇÈsÊËÌÍ4ÌªÈÊÆAÎÏÎÆsÊÊÌÊÑBÍÈ)âÔÆsÊÍÌªëÃ8ËÒîOÈÈsÎÃ8ÆsÊ)Ø5ÈÄÕGÔÎÆsÃsßàìÃ
ËÌÐÅ4Ç/ÔÅ4ÅÖÍ4ÁÄÃ8ÃÒØ5ÈsÄ4ÕÒÆAÎÌªï!ÆÍ4ÌªÈÊÅBÈAØgÇ/ÈÊËÌªÍÌÈsÊÆsÎrÏÎÐÆAÊÊÌªÊÑðÆsÅZâÔÆsÊÍÌªëÃ8ËÛîOÈÈsÎÃ8ÆsÊìØ5ÈÄÕGÔÎÐÆAÃséQÆAÊlË
ÏÄ4Ã8ÅÃÊÍ;Ã/ñÏ¥ÃÄ4ÌªÕaÃ8ÊÍ
ÆAÎÄ4Ã8ÅÔÎªÍ4ÅÂÈsêÍ4ÆAÌÊÃ!ËÉÚ;ÌªÍÁUÆGÍÁÃÈsÄ4ÃÕWò'ÏÄ4ÈãsÃÄ!ß
óVô·õö ¼½÷;ø,ùi¿¥¼ú÷ ö
ûZüýWþ1ÿþ/ý
	ÿ	ý

þ	ÿ ÿ !"#ä
	 þ	$"#%#&'(!*)+,)
) ü ü
 ·ýÜþ/ýý-ý.	/0	1%Qý	8üý02ý$34	56þQý05	5+/ü	/	7ý8	'ý0+9:	 
ÿý))üýý02ý0/ü$ý!Zþ/ý! !;	ý'ÿ<-=5ý$3Oû)üý+%	 />?	@/üýA+AB
ý	55 ý0Cý ý	5ü>(DE1
 þ	69 ýlF ÿ$ý ý;= þQý05	D6/ ü	G	/ýÖý|H ý ÿ ýU
 ÿ! !	!&I
/üý+/ þý0!1
- ý5ý0*3C4	6$/ ü6(DJ	/ý/ ÿLK'0 ý#6!&!/ üý)M5G
) üý0/ýÝ
	 þ=	AG0	55ý
ÿMN·
 þ= ý0 ý!·
& þ/ý 	% ý+	A7L*)+O"P	/ üý)ý|H ý ÿ !?$/ üýGþ	'	!)M	*&P 	5 / üý
 	·
 ýQ 	 ý3
R üýS@	T8 ü	 ýBU/ üýV)DW0	WQ
% ýºþ/ý ýU1@	TX	 B	Z
Y ý  þ	
ý|
H ý ÿ !1	ý,7P*)+@.	2Z	 ý"/ üý8ÿ/ ÿ/ýIÂ
 þ	Ö
 ü	;Q
% ý,ýI ý ý05	[3\]C/ üýI 	7
$T*2 ýM%L^ ý
_Q"*/ ü	
`, #baG
I PdcP"/	;D	/ ü0	$"/ üýN þý0D	 !O/ ü	
	 ü ý02 ý
/üýI	
 ýþQý?./ üý, 	=P0	 !@C_Q$
3 ûZüý0/ý,;A 5 ýT ý¥F ÿý ý
 þQý05	 !/ ü	
	 ü ý02 ý6/ üýM	Q%e/ ü80	/ ý036)
f ý ýBþ	5 9/ üýBþ	ä
 ü	2 ý;IQ
% ý! 	#  ý#
:	 gN/ üýh)M5$3I_ þ=	1/ ü	,	 ü ý02 ýg/ ü$ý8	65	&Lg/ ü	g-5Tii #ja"O6%L
^ ý,_
gg/ üý0/ýhi. PkcPM
" þ5\
7 ÿþl/ üýh%L^ ý0"e-=m	i5	/ ül0	$"O	l  þl/ üýh%L^ ý,m!03
R üý.X!*)/h/ üB
 þ	$" Pnch;2L ! ýi!&'!C%L^ ý+_oi5#pa3
q ./ ü$ýmý ýr.)M 7sW! !	G
 þ	 ü	i
% ýýt0	 DýU ÿ.s/ ü$ýl5 ý	vu
AA ·
 ýr;Öþ=	  	<uw5$ý0vþ=	É
 þ	5	!."P/ üýÝÿ ý0D!&P ý	8C)
) ü8 ü ü	B
 þQý0ü	 þ
%QýOQ
% ýýÒ
 ý|H þ0	 ýQI/ üýiþ	;	!5!/ üyxezh{N|~} q 0_T ý ý06+ ýr%=!0"LaLa*Dg
3 ûZü
	!5/ ü 	  g)+!/ üm	l·
 þ= ý0 ýÜþ=	m/ ü	I  TM ý 5þ !/ üýh	6	m/ üý
 	e 	 ý3;4N	;	ýX ÿi%P&?%=	 7P5	 7L? ý	5üOv
3 ûZü$ý, ü/ýi6	AL ýi/ ü$ý ý	58ü



( ---O¥ %%=!<4Z
<B/
MV
!ª:g
N¥9!	%&%		s&/%1%/ <

+!=

 0 ;05PLg ; ¡¢£¤!0M£¤$¥9¦L§ !¡§C ¡5 §£e¡8¡I¨X©¤<ª=¤¤
i§ ©¡¤9PBr ¡L© 0.0«E¡£e05 !¡m¡,§  ? ,lL§  ?¡£0D !¡l§g©§m¡
¨:©¤<ª=¤¤9!0¬6­ ¢¡®P1£e¡r ¤N ¡L¯=  §e0«M0°¡£e05 !¡§#±¢A£¡§5. ¡§5r §Q¡
 !;¡D05¥
¦B ¡ !¡¤;£¤V¤!¡D! ¢A§@²g³h´Nµ·¶:¸C0¡@¹»ºL¢! $¬g¼½½¾¿S²/ÀCÁ*Á0À`ÂOÃ`Ä$À
¶:¸G5¡+¹JÅM¡¤¤§0¬=¼½½Æ¿MLi£5 ¤<Çw¡50£¤8¤!¡5! ¢A§M Mª=i¡LÇ ¡! !¡¤
£¤§0¥m¦+?¡005¢A§ ¢p°¢8©¤! £¤!! ¤G§ § '50£ §#È§h¡£0D¡5§8 
*®/§0®05¤=¤!05 ®+¡©  ¡¢§¥G¸N¤A§ 5 5?h §T¤!¡5! ¢A§6£ ¡L 0§G¤!É /¡LÇ
 ¡ !¡¤=§ §¤!¡5 ¢Ê©r ¤=i¡£e05¡;«+ ?¢A¡ g i¡g¡©  ¡¢,§# ¡L© '¡
± ¡¢£¤!0£¤$¥¦V@ ¡#P8¢ 5§ ¢ Q¤!§I ¡! !¡¤!1§,££¤$ËT¨
 0 8 8ÌÍ¤!05 !®Q¡©  ¡¢§0¬e 5l 0© 5r/¡¤C§ 0£¤ 1P.ÌÍ0«o¡§/ 5l«+ 1
<Îe0 #G¤e¤ ¡  §£e¡T¡,¡¡¨ +¤!0D !®¡©  ¡¢A§0¥G¦;£¤§6 ¡¢£¤!0+«+
0®0 i¡¤`@§ ©¡¤eÏ«+! .¤¤$§  ¡rL/¤e¤§Ïi§¨X©¤<ª=¤¤!O¥
Ð s §£=£0?«Mm ¡§50i ¡! !¡¤£¤±¨X ¡¢ÑÈ¢¡ l§5 ?£e¡r'¡¨,®L!0«,¥
Ð §@¡¨9LAL§ A¤!¡D! ¢A§; +£ ¡L© ,¡LÇ ¡! ¡¤e£¤§¬«Q®P!0«d ¡LÇ
! ¡¤e£¤§/B©¡¢Am §¡A §É¬=¤!É. £!¡005«M¡ Éi¡1£=¤
PhÒT 0@¶v¼½Æ½¿D¬L8©  ®M£=¤Q¶:Ó¡§§  5$¬¼½ÔL¼*¿D¬P8Q5 r6«M¡ É¡h£=¤
Pi§5 §vª=¤!i¤!¡5 ¢A§¶:Õ,©Öh¹×ºP¤¢A$¬
¼½½¾P¬C¼½½Æ¿D¥ Ð § @¡¨G©§ AA®0 .05¤
¨X5¢0«M¡ É°¤!É' iª5§vÇw¡50£  0.¤!¡ '¡'VP¢A ?¤!¡ ¬N«M@ 5¡#¡§@V¤¡ ? 
§§ ©Ø' 0!# ¤!±L£ § § ®?¨X¡A 0£ §# l ¡! !¡¤£=¤1©¤§ ¡V §5 È¡©
¡­*®@£e¡r ¤;¨(¡Ø' 0!#A¢£¤!¢Ar  !¡O¥È¦+iØ' 0! ° ÙP©! ¢#¡0 0'«+! 
 ,5 r+§5© 0 § §;¡¨6§  §ª=¤¤!¡D! ¢A§;. 0¤§ §  0¤$£=¤?¶:Õ,©Ö8¹bºP¤¢AO¬O¼½½Æ¿
«M¡©¤h§ ©§N 65§ ¤ g£ ¡¤¢o§  §9¡¨e ¡! ¡¤P£¤+¡,§0 §G¡¨=¨X¡5¢8©¤
­ '£ ¡£e¡§ ! !¡¤N¤!¡ ­ ­ª=@ ¡ !¡¤G£=¤§,P±m§  §vª==¤!]m¤!¡D! ¢
«M¡©¤ie, §¡¤!I«i¡A£ ¡L 0$¥NÚ/¡*«M0®0¬= §; ©D§¡©¡¡I , 0§¥
Û .§ ¡«Ü Q®L!0«+1 ¡! ¡¤G£¤.§hm§  §vª==¤!]B£5¡¤!¢Ý§¡8¨(§5!¤!¥
Þ ®?«+ A / §5  ¡¡8£¤§N ®g£e¡¤!L¡¢A¤¤!  /£ ¡¤!¢b¡¨$§ 8 
§ I¡¨C ¡! !¡¤£¤§¤¢¡§; 0  ¤!'¡P§;¡e¤!¡8¡ I ¡¢£¤!!]' 0¤§ §;ßT¸C¥
¸N¤.P±§  §ª=¤V ¡§ §  §¡¨ ¡§ 5©  mB 0'£¤~¶:m§ÙP© ?¡¨¡£e05ZÇ
 !¡§à¿+mi£e¡¤!L¡¢A¤<Çw ¢,®0D<ª= 0 !¡l g ¡£e05 ¡§gm h£¤l 50® h¡¤
«+m§   '¨X ¡¢á h! ¤`§ ¥QÅM¡ !¡¤$£¤¬=¡*«M0®0¬O#®¡¤!®§g ¡§5©  
B£¤~¶vâXãäå ä1ä æçèâXè1£=¤=¿g§ © 5° Téêå.äëäåàì' ¡¢Q !¡­¡¨+ ¡#  0!§iâXãLä0åäBä æçèâXè
VL 0© !¡l Q 5!0®§, ¡¤[¥¦§g¤!0D !¡l¡¨Ù#©# <ª0D§Ií#î$íB É§ ¡! !¡¤
£¤8¡© § gßT¸C¥
Û ,£ ¡£e¡§T1££ ¡ Di¡A ¡! !¡¤=£=¤ §M§ i¡.5§ ¤ !¡?¡A ¡¢hÇ
£©  ¡¤$£ ¡=¤!¢Ê /§05¤!Ö !¡@¡¨6§  §vª=¤!'¡¨C£ ¡£e¡§ ! !¡¤e¨X¡5¢8©¤¥M¦§
£ ¡=¤!¢W§e G0®¤© ¡g¡¨PD© LÇw®¤©§e¡¨Ù#©r <ª=Iï¡P¡¤!¨(¡5¢8©¤¥6ðg©# <ªIïM¡P¡¤!
¨X¡5¢Q©¤ 55 05!Ö0? '¤0®¤§,¡¨; '£e¡¤!P¡¢A¤6!0D5 5#ñ¶:ïM¤ $ò Ö¬Góhô ò Ö¬G¹áÒg5ò¡ ¬
¼½½õ¿M¤!É+£ ¡£e¡§ ! !¡¤¨(¡D¢Q©¤/ 55 05!Ö0g T£ ¡¤¢A§N g ¡¢£¤!!A 0¤§ §ßT¸C¥Pö¡
¢£¤!¬O 8D© l¡¨MÙP©# <ªlïM¡#¡¤V¨(¡D¢Q©¤8«/! m £ ª±írî­§I. ¡¢£¤0£ ¡Ç
¤!¢÷¨(¡8 ? ¡¢£¤!!± 0¤§ §hø6ù ú¥mû/§Q«M'«+¤¤6§ ¡«,¬6005¢A.§ ?¡¨§¡¤© ¡§,¨X¡
 ¡ !¡¤9£¤?§Iü ù ú Ç5$¥AïM 0©§hÏl©0I§ 5± ¡¢£¤L!]rÇw 0¡ 0  A§ §5©¢£Ç
 !¡§Ï. 0 h§+¡?£e¡¤!L¡¢A¤$ ¢5§ ¤ !¡1¨( ¡¢ý ¡ !¡¤O£=¤¡?£ ¡£e¡§ ! !¡¤
§  §ª=¤¬!/§+¡/¨(§5!¤!,¡?§¡¤!®8!+P@1¤!¡D! ¢þ +ª=§§  § ¨(LA§ §5!¢# §
¡¨9£ ¡£e¡§ ! ¡¤¨X¡5¢8©¤¥
ÿ


	





	

"!#%$
&'$(#)+*,+-.)0/&.1*2#435&.,+67-88-9:,;=<>1@?A#4BDC0*-15EF9G#=3*,0BH
,0,IC0!#J)#4,0H8C0,K-1LC0!#MBD-N%$
HO
C0&'C0*-1&.8PBD-NQ$
8#DR*CTS=-.6UBD-1
3*C0*-1&.8($8&.11*1/VA9W!*B!X&')0#+C0!#YNQ-.C0*Z'&'C0*-1F67-.):C0!#[&'$$)0-&.B\!F9#
!&]Z.#YB!-,^#41_;:?A#4BDC0*-1X`J$)0#4,0#41aC0,W3*b(#)0#41aC:C^)&.1,08&'C0*-1,c-.6dBD-13*C0*-1&.8_$
8&.1
1*1/[C^-MeAH&.1C0*f
#43
g --8#4&.16h-.)N[H8&'#.;i"!#cNQ-.)#G/.#41#)\&.86h)&.N%#9G-.)0jY-.6BD-13
*C0*-1&.8$
8&.11
*1/:&.88-]9:,iNQ-.)0#c3#/.)##4,
-.6U67)0##43-Nk*1lB!-A-,0*1/=9:!&'CWjA*m13F-.6U$8&.1,:&=$
8m&.11#):$
)0-A3
HBD#4,;"n#QBD-1,0*m3#)o&M/.#41#)&.8p67-.)^O
N%&.8*24&'C0*-1Q*1[9:!*B\!*1aC^#)\1&.8,^C0&'C^#"C^)&.1,*C0*-1,p-.6(&I$
8&.1&')0#"3#4,0BD)\*q(#43[&.,pfr1*C^#c&.HC^-N%&'C0&V&.13
8#4,0,"/.#41#)&.8_67-.)N%&.8*24&'C0*-1,s9:*C0!tN%-.)0#u)0#4,^C^)\*BDC^#43tC^)&.1,*C0*-1v6wH1BDC0*-1,4;ix-.)W&.88(67-.)N%&.8*24&'C0*-1,
9#+$)0#4,0#41aCWC^)&.1,08&'C0*-1,"-.6d$)-.q
8#4Ny*1
,^C0&.1BD#4,WC^-MeAH&.1aC0*f
#43 g -A-8#4&.1X67-.)N[H8&'#.;"z{eAH&.1C0*f
#43
g --8#4&.1L67-.)N[H8&tC0!&'C[*88H
,^C^)&'C^#4,IC0!#MC^)&.1,08&'C0*-1,u*,+/*Z.#41L*1|?A#4BDC0*-15}A;tn#v!&]Z.#M,^-8Z.#43|&
1AHN+q(#)c-.6d,0*N%$
8#o$)0-.q
8#4NJ,c*1tBD-13*C0*-1&.8($
8&.11
*1/[qSvH,0*1/&%C0!#-.)0#4NO~$)-]Z.#):67-.)I g x|9#
!&]Z.#3#Z.#48-.$(#43_;W"!#+C0!#-.)0#4NQO~$)0-]Z.#)u*m,:q)\*#D
St3*,0BH
,0,^#43X*m1?A#4BDC0*-1M&.13lC0!#Y#DR$(#)*NQ#41C0,
*1X?A#4BDC0*-1l;xi*1&.88S.V*m1X?A#4BDC0*-1l[9#+3*m,0BH,0,s#4&')8m*#)c9G-.)j=C0!
&'C"*,c)0#48&'C^#43FC^-%-H),;
iQM
TU(a

 H&.1C0*f
#43 g -A-8#4&.1t67-.)NYH
8&'#u&')0#K-.6pC0!#K6h-.)\N'^04i4a
l9:!#)0#u*,s&.1FH1eAH&.1C0*f
#43
I
$)0-.$(-,0*C0*-1&.86h-.)\NYH8m&&.1
3C0!#t$)0#Df
R|BD-1,0*m,^C0,Q-.6IH1*Z.#),&.8G&.13#DR*,^C^#41C0*&.8: @eAH&.1aC0*f
#),
 ¡¢¢¢]¡   &.1
3XC0!#[$)0-.$(-,0*C0*-1&.8Z'&')*&'q8#4," D¡¢¢¢¡   C0!&'Co-BBH)K*1lP;I£W#Dfr1#i¤ ¥c¦§&.,oC0!#

67-.)NYH
8&IC0!&'C*,U-.qC0&.*1#43Q67)0-N¨=qAS[)0#$
8&.B*1/o-BBH)0)#41BD#4, -.6rC0!#"$)-.$r-,*C0*-1&.8AZ'&')*&'q
8#cMqS
C0!#[6h-.)\NYH8m&J¥W;u"!#+C^)\HC0!-.6eH
&.1aC0*f#43 g -A-8#4&.1©6h-.)\NYH8m&'#[*,o3#Df1#43X)0#4BH),0*Z.#48SF&.,I67-88-9:,;
"!#C^)HC0![-.6r&I6h-.)N[H8&WC0!&'Cd3-A#4,d1-.CdBD-1aC0&.*m1Zª&')*m&'q
8#4,V'C0!&'CU*,4VªC0!
&'CiBD-1
,0*,^C0,i-.6C0!#cBD-1,^C0&.1C0,
C^)H#J«¬&.1
3©67&.8,0#%­®&.1
3BD-11#4BDC0*Z.#4,Vp*,K3#Df1#43*m1lC0!#Q-.qZ*-H,I9s&4S©qASXC^)HC0!O~C0&'q
8#4,I67-.)uC0!#
BD-11#4BDC0*Z.#4,;cz¯67-.)N[H8&J A(©*,cC^)H#u*6p&.1
3F-18Sv*6di¤°«u¦§p-.)oi¤°­u¦§p*,"C^)H#.;Gz±6h-.)\NYH8m&Yr
*,C^)H#v*6W&.13@-18S5*6Wi¤°«u¦
§W&.13²i¤°­u¦
§:&')0#tC^)H#.;³dR&.NQ$
8#4,-.6:C^)H#FeAH&.1C0*f
#43 g -A-8#4&.1
67-.)NYH
8&'#[&')#+r( A´_µ7©¶·´¸W&.13 A( A´_µ7J¹t´¸\;u"!#[67-.)NYH
8&'#Q ´_µ7©¶·´¸W&.13Xr´(µ7%ºt´¸
&')0#W67&.8,0#.;G»s!&.1/*1/KC0!#:-.)3#)G-.6_CT9G-BD-1,^#4BHC0*Z.#WZ'&')*&'q
8#4,eAH&.1aC0*f
#43%qASC0!#o,&.NQ#WeAH&.1C0*f
#)
3-A#4,K1-.Cu&ªb(#4BDCuC0!#QC^)HC0!O~Zª&.8H#[-.6C0!#Q67-.)N[H8&;+<>Cu*,I-.67C^#41¼H,^#6wH8pC^-F*/1-.)#QC0!#-.)3#)*1/=-.6
BD-1,^#4BHC0*Z.#IZª&')*m&'q
8#4,&.1
3JZ*#9½#4&.B!teAH&.1aC0*f
#)G&.,seAH&.1aC0*6hS*1/[&Y,^#C-.667-.)N[H8&'#.VA6h-.)#DR&.N%$
8#
 A    ´  ´ ¾ ;="!#J,0*2#%-.6c&leH&.1C0*f
#43 g -A-8#4&.156h-.)\NYH8m&tB&.1Lq(#J3#Dfr1#43¼&.,uC0!#M1AHN+q(#)u-.6
-BBH)0)0#41BD#4,"-.6p$
)0-.$(-,0*C0*-1&.8rZ'&')*&'q
8#4,c*1t*C;
"!#=*1C^#)0#4,^C*15eH&.1C0*f
#43 g --8#4&.1567-.)N[H8&'#v*1¼C0!#MC0!#-.)S¼-.6:BD-NQ$
HC0&'C0*-1&.8sBD-NQ$
8#DRAO
*CTS¼,^C^#4N%,u67)0-N¿C0!#%6w&.BDCYC0!
&'CY8*j.#J$)0-.$(-,0*C0*-1
&.8d,0&'C0*,Àf&'q*8*CTSlB!
&')&.BDC^#)*2#4,C0!#J$)0-.q
8#4NJ,u*1
ÁoÂ VeAH&.1C0*f
#43 g -A-8#4&.1t67-.)NYH
8&'#I9:*C0!t3*b(#)0#41Cs$)0#DfR#4,cB!&')\&.BDC^#)*2#+3*br#)0#41C"B8&.,0,0#4,c*1vC0!#
$(-8S1-N%*&.8i!*#)\&')B!S²µ g &.8mB_'Ã& 24&')Y#C[&.8Ä;VGÅ4Æ.Æ.}¸\;F"!#%BD-NQ$
8#DR*CSB8&.,, Â BD-1
,0*,^C0,K-.6c3#4B*m,0*-1
$)0-.q8#4N%,IC0!&'C+&')#J,^-8Z'&'q
8#%*1¼$r-8SA1-NJ*&.8pC0*NQ#QqAS©&X3#C^#)N%*1
*,^C0*BpH)*1/tN%&.B\!*1#.; ÁWÂ *,
C0!#%B8&.,,I-.63#4B*m,0*-1$)0-.q
8#4N%,oC0!&'C+&')0#%,^-8Zª&'q
8#[*1©$(-8S1-N%*m&.8ÇC0*N%#[qAS©&t1-13#C^#)NJ*1*,^C0*mB
pH)*1/N%&.B\!*1#.;U"!#oB8&.,,cBD-'O ÁWÂ BD-1,0*,^C0,s-.6PC0!-,^#K$)-.q
8#4N%,C0!#KBD-NQ$
8#4NQ#41aC0,s-.6p9:!*mB!v&')0#
*1 ÁWÂ ;(<À1l/.#41#)&.8ÄV(C0!#B8&.,0,IBD-'O>»ÈBD-1,0*m,^C0,:-.6G$)0-.q
8#4N%,"9:!-,^#QBD-NQ$
8#4NQ#41C0,I&')0#Q*1lC0!#[B8m&.,0,
»o;
:!#u$(-8S1-N%*&.8_!*#)&')B!S ÂÉ *,:&.1l*1f1*C^#K!*#)\&')B!Sv-.6UBD-NQ$
8#DR*CStB8&.,,^#4,oÊiË Ì.VrÍGË Ì.Vr&.13
Î Ë ÌK67-.):&.88(ÏGÐÒÑC0!&'C:*,:3#Df1#43vqAS=H
,0*1/-.)&.B8#YPH)\*1/QN%&.B!
*1#4,"*1vC0!#K6h-88-]9:*1/[9s&4S.;
Ê Ë ÓÕÔ
ÊiË Ì×  Ô
Ö
ÁoÂGØÙÚ

Í Ë ÓÕÔ
ÍGË Ì×  Ô
Ö

BD-'OÀÊdË Ì× 

Î Ë ÓÕÔ
Î Ë Ì×  Ô

ÛÜÝÞiß\àÄàÄáªâcÞPã~ä'ßãÇåÞÀàwã~Þ^æoçáªß\åã~èêé'Þ>ë~àæ]ìsåªìãÇç4áªß\åã~èêíïî"ã~äªÞpà~ß\âcÞdð\ßë~èñß\òóñÞ\Ü
ôõ]ö

Ö
Ö Ø ÙÚ

÷:øùúûùüù











	





	






































	



"
	

!




$

%
#






&


!


'
(


	


)



&







$


*
$





"
	

	




	



+









/
,

.
+


!


0
8
7

>
1
+
!
/?"	@ +	2
.-3,/
.4+
!+
093
5+
2!&
<-!	;6
>! 
+
 +85
.3A9!
	
C4
BD,: .-+!&!'
0)-;,/
.++!!0A:<-
!+	!&=.	
$!T*$S/UWVY	(X 	Z[] \J	E<)	FG>^_FHIF`IJ
L+Ka-b/	cd$	 EefaJ
b6(L
99
gFh1
"!	M!HBC
<)!A	H!&`$=	L	
IN=	)FY$==	?!OP
/!
+% +1RgFQ i
!j

%k
Q|j;} )!M		4L
!l+l>^m~. $9	!I==`Fn N=j	!&
 I		!L
`;IoLX $p=qrLUs p.tL	Z`t+[ !uhvwyIx$=zt-Fn	G=!	{%!
	k	!	L!c%=5`
l	
 
	+!
;+
( 	!!	=!J=.D	AQ
|Y	 Q)gW?2\JOi4}
Q_%!E
!AS/=Uv1s Fo-%!8ztft"}!%Q!	/| I?M=H0=2	FA		 (		
>8J^.
$	!=!^8 Nef8 !&+ ?
J	
8a,(	1b8.m		¡+j.
 	3cYJ


+>9Y.<).
! N	;	!#<)!$	A¡#8*4Y%=$ #
*¢95g
 + 4	.  !A<)8
!%£$	ef$=D	L!8$=	$G#L*!"Y	 	J>
 8 $ ;ef!da¤)¥mb8$m=¦"
 	?j+	; 0
	!=
A+

  c
Y.
g	!#+c
¢ £ ef$=L	AJ
(+$#*Y)N  <)!	T¤d¥¦A
	1 	!=?
§2¨G©>ª:«¬8­y®¯°y±²³ªd´L©>ª:µ¶°y±=°yªkµ·I­)¸>­f·Iµ"µ°Wµ¹


	Fn!&>!E!&3$		!l=».<8	!`JF>


TFY¢
		!¼r` 	$=L	$ *n!	WFº+=

+T$=	>$!=	!=!
	!)=

%%!&
0?m!,(09<8h
.
I=	? ]
A	
¦#%Á
Á
TÃ=O½i

 	¢).+N	
]FMn	
+h

=0

 
+	+L!		A+Å
$=	Ä !		!!	=		

)Y	$&
9l	 M!	!50-
#%<"+ 4=..!!4 	fFGL!
3hj		J
L=I=¾<º
!	I¿A!==
!.
		!I=E5


+/4;.
ÀY0=!
 ;?Ecd

T`\¦	Á
Á
¾ÂY<  c
	J
+ 9	E.	 !&AE¼
4=L
1T.nÆ>!E!
g	E	EJ0

!1

?/!	fFHMJ

(!	!=+cY=g.	!&E0L$.=	E!!	!=!
 I	l
	 	(!&Y0.? 
N	!#M8Y=

	9

b"NdFL

a-Ib!=ef$Fn0=LN=F! 
		g-!&#%! 

c
!I&!	fDFL=!!L0=kI
	=Fn	>8==;$=!	L
Y%	!~$
*n$
!	"	f?2F	O ;
	3a+:bj
aef$b/+=!c 

&		
)+!
5
0cg3<)Ç
J4
I+<-		+!+
+!$	+	>		

0=A! ?¼
¿1

.	$Æ>
!TNÀY	)
!`+!=\¦GÁ
Á
Â=niE$.<È	E! 3	3		+A
&	 !	#%! 0%!!
	WFL
!:
J
+4&
. !A0!H	4	J
+4
.I =l!!	G!=	
 


!I0==L!	!=N	E

2
	0=!l!E
	I+=
!0=!	g!=	J

<35 
++4?".ÀY=A.!&	M!=N;.%
	!=3 ? 
	
!M
( 	!JFn!04	+.	ney¼ 
.
$=
	I%H=	>0H¾<É!		ME		# +	9	($<)=!	¼
y?Ê	iL$*>,(!	fF`!&E	L+
!&$A	
!a=(bÉ		]\~
	)I+=	.Fn!9=0H !&	
j 	!	I=LFn&I
==AFY$!&==
ey	!!
!L	/!=!	
++j
 +1&&
g Fh	!=!Y0H3AJY=
 	
$	=+
!0=!	g!	=J

<3n +
T	+!
0	 	!=
E+! +
$*n
=!g0	!

y?	,(A
I!N=	.!	!	!=!¼

n
 	=!&T#%J
)!&$!	f=F
?/Ë!	¼
!=
	%(
!!
0 
I	!0¼
=.1!	5Fn!!30Ha!b¡`I!2=	Fn	j=!

:	!;L/L!&	4a 	b!	

$	.E
=F`¼
!MNF9=0=&..	!=!?L0lÌ

#%!! 0>	ET=$=.	!=!	L!=

 



=	2!(90

L0=.+
YII
J
!+L 	39!A&
I=Fn.	2=	!	
!=	0!L	
 c=	
/		E3N
.9<8I
k'n
.!Í+2
g&	/!!++..		

$$
!	(!EF>!&IHl0
$*YI=+
kN	
!	E
I5=
M!	A	!lI
:J
	+Î$=
!	R!=!
	

$
?!,(04NFH$= 	!!#%1  	!!=!	fF;E
.0
0

0
1!		EM	?  	
(
,


M


	











Ï

I





¾

Ð
<






<
L


	




	

	


M














Ñ




l






	


+



&
!



!


h
0
)
<





	




L


	


T



0
=




(






º

I


87 
cN1
;;J	=ÇJ
¼
E+FÒ!¼
!	F!
n!'
	 F	lÒ!j=
	(
LI	9)IL=
I	8	$=L$=L$*$*
!%	fFL
+!"a	b/)?N,($=L)$
*+!	WF %!&
!	WF 

/	0
=
J=Î
!!	!
	 	-!3Y.!¼ 
g	3	L	$*!	$
/$=!	!=

"=F;J

Ó¾ÔÕ
ýuþÿ

ý

ý

ý

Ö8×%ØÙ+ÚÛNÜÝNÚÞØßÝn×%ØàÞÚÞ×%Øáâã=â¾áØÙ
ïëäúånìõ
æGéLêé$çäLîèéëèêgäúëëéhéìí4êé$ç$é$înéLînèäïò
ëðó3ééêõTä+ç$äé]èç$ñ
ò=élò
êóAôêèò
äëéëèï%èò=ò=õêêð+õ
ä"õ ì/ëò
ïéhókìõ
ç$çò=ê`ì&õ
êäç$ôäò¾èèñ
ëçèéõ
ò=ð+ì)êèêïõ
û]ììõ
ï%õ
êìì&ä;õ
ìjêó5èäêò
ö2ð>èë÷èéõ
ò
ñ
ì/ð(éäðøLëíõ ò
ëèðéêéäèö;ëðèéõ
üýäê`ìEëð1äèëëç$úõ ëééëäéô;éùnôçèòYõ
êéäôéä;ääAêò
ïò
ókð+ë>ç$òNò=ò
û=êó~åälôõ èò
ð+ëõ
ó8èò=êNþ8êëéÿõ
é ì
úèêõ ôð+éôéêôéäþ8äÿ ò
fó3úõïð+ìôõ
ê¡õ
êé$înô èäêëéò
êë4ç$éé>õ
äúèõéñ
ðé;ö ëjò îèäé>ëéôêè ç$Ié;éðò
éó(êgçë ì:õ
ò
ää+ó(èçç$õ
ò=ìåð+ï%äìé;õ
êïäAðòóJñnò
ðèôõ
éô¡ììëèêúèõ ëëèõ
ëìúäé;ëõ ïëðéò äLôìéòNø;éä4äAêõ ò
ðéë
êç$ò=éøç$éää+èêõ é4ð+èìõ
íTêgíMèøë ï"ìòGíHïëúìõ
é4êé$ä(înëèúäëõ éë ê8ç$éò
ðò
ùTóåç$ò=êêôôéèð)ëèôò=è êIõ
éìdðéïêNì&ë)õ
êçä)èð+óJçò
åðløé$äînëõ
õ
øêç$ïéìä-é ë-ò>úõGéê`ç$ò=èêë-ôèäèëèêò=ò
êëlõ
ïIìò=ïäìõ
äèêT%ìëéúëõ ò ë
8ò
ðùYä)ç$ò
ððéç$ëìí )úéêéñ
éð(ò=êéAò
ó2ëúéAç$ò=êäëèëåéêNë(ïìõ
êäEôòNéäö
ïð+ò ìéø èêäëõ
êç$é
úõ
äAõTäò=ìåëèò=ê










	



















 "!$#

	
%&('*)+& ,	%-.%/)+& 0+132 10+&4&4%&56%7809-.:;%<2 1>=?.@4A;BCA;DEGFHI=J:K=L@M%7
0M7N=-O)QP61R%-S=:Q0	1<7UT'HV0+:W0X'N-S=:;%>YJ%&5$-HI=Z%&4%-.%/0+1[7-\0X-S=7S]^8_G=J_G`;=J:;7Z)WPBa0+:K=b2I0	%:;7dcfe
ghTS-HI=
);2i=:Q0X-\)+:*7]bFHi=J:K=jc(0	& ,Cg0+:K=7=-7)WPk1l%.-S=J:W0+1l7*^m0+& ,CDn%o7081R%-S=:Q0+1pTS-HI=q5)N0+1 ]+r
# 2 :W)s`1=_t%&i7-\0	& ';=
u% PmP)+:b=Jv	=J:wx%&4%-.%/0+1y7J-\0	-S=6Tz0C2{:Q);2i)|7;%.-.%.)	& 0+1m_O)N,s=1 ]8}
7;~4'H-HV0	-y}
 h@-HI=J:K=d%7L0b7N=KN~4=& ';=sNAAK|)QPC);2i=J:W0	-\)+:b0;2X2 1R%.';0	-.%/)+&i7O-HV0	--.:W0+&i7PJ)	:;_-Hi=
%&4%-.%/0+1y7J-\0	-S=L}
-\)90x7J-\0	-S=L}"7;~4'JH-HV0	-}"p DOr3HI=0;2X2 1R%/'*0	-.%/)+&u)QPmceg%&6}k_G=K0+&i7
-HV0	-}   cU0	& ,PJ)+:-HI=jPJ)	11)+Fy%&587-\0	-S=} > [ g0+& ,[P)+:0	11I2{:Q);2i)|7;%.-.%.)	& 0+1yv|0	:;%/0s`J1>=7Z-HI0	,X)8& )	-m)N';'~I:k%&xg+^3}   $% P0+&{,)+&41RwG% P} >  r

(þ ÿ


é
+
ä

ú
ò
P

ë

ú
õ
(
ë
J
ó


ò
ð


õ
N
ê
í
Y

å


õ
N
ê

ë
è


é
ô
8
Y
ò
=
ò

ì

é


õ
T
ê
J
ó


ò
+
ð
4
ø

å

ì
õ
)

è

ë
H
ú

ï

ð
é

î
G

ë

ú

é
+
ð

é

è
E
ä

õ

ï

ð
ò


ì

é
ø
èèêêääëëõ
õ
êêç$ç$é>éLúèêõ
älç$ò=õGêäôò=èìëåèò=ëêèò=õ
êìjöAï÷ìõ
ò
êðAêëèúêéûTNäååç1õ
ú¡êgëëè %úéõ ô]ë4ëóJò
úð+é>ø4ó5åò
ìð+õ>ø4ëåò ìõ]èé4äAëëð+ð+ååé é;èóJóEò
ðAõ
êõ
ôìì:ò=ëð+êåìíëú èyó8ñ õ
ëìúåé>éäïðóJò
ò ðìëéúø é
åäò¡êèëñ
úéõð+äëõ
ëì2úñ é]õ ð+åèõê Nìåéõ
äêNèëëAè úéõ
ôäAóJëò
ò ð+ø4éLåìïIõ`ò=éäñä+èõ
ììåéõ ëëéò]ä;õ
ëäò¡ä+èû=ëð+ê¡åëé
ð+öåëüýú ê yñrëõ
úì&éTåéïälìõ
ëò]êêëèúêé;û`é$äînéèëäëëèéêêgû¡ëèëõ
úìèñräõ çð+õ
è&õ ê ìIééä
äçèõ
ø4ê åIìõ é ëéIôò
ëõ
úäëóJð+ò=åììéLò )ò
ðäö ó~õ
(ìäúé
éö;å÷êò
èð9ñ
ééð+õ
äç+õ
úìjèñ êõ èð+ëèè&õ õ
ì/ìäéëäAõ ëç$é;ò
ðëðúééäïIðé>ò=êúô¡õ
äëò]ëò ó~õ
Iç$éëä9õTèê¡äé ëNúåé>éêèêç$éèëèò
õ
ó3ìjò
äïëõ éëð1é>õ ëëèò=úêõ ëä
ëúõ ë(õ
éëää+èû=êä8éMëúõ
élêNíé$înYè&äåëõ
éêgêNëëè&è õ
ì%éôñ õ 8ð+èòNõ ò=%ììééõ
ä8êºëð+ó5åò
ëð+ú ø4yñ åõ
ìõìåéä8ëúõ ë(øõ ù
éëúélåê Nå)õ
úêgéëèð%é éô;KóJò
ç$ò=ð+ø4êä+åèäìõ9ëäëð+ò
åó é
ö
çõ`ìõ
äåò=äìåéäëèö ò=êö é8ç$ò=ò=êêääëëð+ð1ååç$ç$ëëèêõ>û ïðÄò ëìõ éù
ø éäLèêïIäò=ëìõ
íYêêç$ò=é øKèõ
õ
ìêëôhè&øLä+éHúò ò=êëëúúõ éMë ìéÎêû
èä-ëúëð+ò
åó éLèóö õ
ê(ôhúèò=ä4êäìí¢úò è)ó ä4Rëúúõ
õ ëä
ë)éúäëéèð+êé û;ëúé4é$înè&äëéêç$é4ò
óäò=ìåëèò=êä)èê¢ç$ò=êôèëèò=êõ
ìdïìõ
êêèêûèä-þ"ÿ fúõ ð+ôö é %êé
)õ
êô
4èä =ëúTçìõ
åäéèê
üò
êTïIéëð+úõ éëò
è&êð+ä èëèõ
ìäëõ ëçéõ
äê ëúIéé(ñré$õ înð+éè&çõ åëìééôGä ëòøøõõ íTù
é-úñ õõ ñ
ð+é9èõ õ
%êNìíMéä ñrõ
ì&åëéð+åõ
é
êö ô])ñrúõ é)ð+è&ëõ ð+åìëéúä ò
ókçõ ìðõ
é4åäõ
éìäìó~)õ
èìêäé
ö (çõ
úê é
Iõ ïé-ïñ
ì&éèéð1ô;è ëéòô ïYð+í;òYôé$înåéç$çé-åëëúèêélûû
ò
ò=ïIõ
ìdéð+èódõ ëõ
ò
ììIð+ä çìõ
åäéäEõ ðgélöë÷2ð+åèêé
õ
ö ìì(í Núëéúñrélõ ò
ð+è&ïIõ éð+ìõ é ëò
Að èä3êééôéôGëòLïð+éñ
éêgçë3õ
ó~ê õ
ìIäéé
óJò
ð+ø9åäìäõ åé-øõ é-ïïIëúéõõ ð3ëEëóJò
ð+åðEé õ
nììIìèõ
ù
äé äèû=êøLéêgëä8ò
ó:Yíëð+åëúëúéyïñ ìõ
õ
ìêåéä8ëò
ö


ë

ú
l
é
J
ó


ò
+
ð
4
ø

å

ì
õ


è
ä
ëñ ð+õ
åìåé
éö ä /õ ù
éõ
êNíGMè&êëèò ëèõ
ìäëõ ëé %ö ëúéõ ë ë)äõ ëè&ä éä ö -é4ò ëúé4ðéäôïIééëç$éëð+èøñ
éèêëéð+ä3åõ
ëúêTyñrõ
õ
ä+äìåèû=éêä)øLóJò
éð êNë3ò
ó:ëð1åëú
L V|V

2 10+&4&4%&5%7

3Hi=82 :W)s`J1>=J_)QP=K X%o7J-S=J& '=Z)QP97J)	1l~i-.%/)+&i7CPJ)	:G2{:Q)s`1=_¡%&i7-\0	& ';=J79%&¢';)+& ,+%.-.%.)	& 0+1
+£ HV0+:W,Xr

¤ :W)N)QP¥¦

§

¨

+
¨

®

©

xª

C¨

©


I



©
¯



d

I

+
U

®

+

O±²
q¦
¼



	

	
	

+

Z C
°

J© 8«­¬

¨

©

I

Mª
	

dº

9º

N¨
4¨
©
x« ³3µ´´´K³i¬V¶I{´´´;¶	·[¸f
®¸
¹
§
±
»º
± ¯


½ J© Lºf¾?.@4A;BdA;DE

Dh"70	-.



¿|Àj7J0	-\A;À¶  ANA;À¶ · A;ÀyÁ  AA;ÀÁÂWA*Ã	ÄXA



¿Ã[eÅ¶IAA*Ã[eÅ¶	·A§Æ.ÁNA§AKÁ ÂÇ eÈ70	-.Ä

@

B

É ¿§Ê  eËÁWÌ	A;À»ÃV Ê\3Í6´´´|ÍÊoÎ
+



©

Ã[eÖ¶ 


Ú

»¯
Ü§JAA*Ü;

ÐÏ

m³ 

®¸[ANÑqÒUÓjÒÕÔ ÄX
+

8

+

m¶ 

¯

»¶ 
¯
jÁ b¸
	
Æ.Á  ANAKÁÂ Ç e×7J0	
»¯
+ Ã
	
¬cÆlcqØGÀ c Ç 
9Æ\À ceÖÁ Ç A§Æ\eÙc Ç A§lÆ ceÖÁ  Ç A§Æ.Á  AKÁ e×70	- Ç
I
C³µAAW³
C¬V¶I{´´´*¶	·q¸
}
Q© m@ »Û §¢}
I
° Ü   ANA*Ü · 
b³3A§AW³
i
q¶IJA§AW¶	·
mÊµeËÁ|A;ÀyÃ

ÝÞß

àáâiãä â4åXâ

æ	çbèiéêWéë*ìOí>î4éNè(ïð(ñCòôó3éê8õö÷øøø§÷Kõ	ù8ïéxæçWéNúVûiéNî4üJé9üJýXî4çKí>çWêKíoîiþZý	ÿqéIæ	üJê>ðUêiýXçWéý{éë;æ+êWý	ë*ç
  ÿý !>ý#"péNè8ïVðGê4ýXçWéqý{éë;æ+êWý	ë*ç$ &%(' ÷)  çKû4ü*bê4æ+ê+$  
 æ	î4è
	
 çKû4ü8êæ+ê
 ,- ý	ë	$  ) 
 æ	î4è. 0/132546 æ	î4è87 îæ!ð % öN÷øøø÷ %9:
41 ò<;[ï>=VíýXûçð  õö÷øøø§÷Kõ	ùêKæ3?	éNç
êiéíoî4íêKí>æ{çWêKæ+êWéA@
êWýGæOçKêKæ+êWéA@Bç*û4ü*êæ+ê<@CED B41 òGF+4éëKéÿý	ë*éIHJ4æ	çæOçKý >ûiêKíýXî­ò
K çKçKû4ìOéIHL4æ	çæOçWý >ûiêKí>ýXî­òGFæ3?	éæ	îðæ	ç*çKíþXî4ìCéNîêM§ö÷øøø§÷*Nbý	ÿêWë;ûiêPOQ=+æ>ûiéNçmêWýSR3öN÷øøøN÷(RN{ò
óµéêT@
ïéæU4ë*ý{ýXç*íêKíýXî4æ4ìOýVèié6{çKû4üGêæ+êV@
D 0W æ	î4è8ÿý	ëæXZY \[^] ÷øøø§÷(_a`b@
D  R  ídce  
êWýi@BµçKû4üxê4æ+êj@CaD k41 ò
-Z òfýg""êiéë*éí>çæGçWéNúVûiéNî4üJéLõsö÷øøø÷Kõ+ùý	ÿyýéë*æ+êWý	ë*çêKæ3?Víoîiþh@
l ý	ëLæ!mY n[^] ÷øøø÷(o`8æ	çKçKíþXî - êWý 
 íÿ Sp
 ýVüüûië;çkí>î6õöN÷øøøN÷Kõ	ùïéÿý	ë*éCêiéq7ë*çWêb$ V
% '	÷)   æ	î4è /12546 ý	êiéë*"í>çWé	òVrêí>çméNæ	çWðêWýbçiý#""ê4æ+êê4éæ	çKçKíþXîìCéNîsêêWýhR ö ÷øøø÷(R N ÷ 
 ö ÷øøø§÷ 
s
çKæ+êKí>ç(7éNçMt[òuF+4éëKéÿý	ë*ékñfí>çmçKæ+êKíoçv7 æ+ïé	ò
w

x X
ý îè4íêKíýXî4æ>æ	îî4í>îiþbí>çqæ>çWýîiý84æ+ë*èiéëêæ	î4ëKý	ïéNìGçýXî6êiéOçKéNüJýXî4èyé=	é6ý	ÿpêiéq{ý >ð^O
îiýXìOíoæz4íéë*æ+ë*üsð	ò l ý	ëüJýXî4è4í>êKíýXî4æ{>æ	îçý	ÿý ðIîiýXìOí>æ{çKí}|ékí>êí>çéNæ	çWðêWýGçiýg"ôê4æ+ê7{î4è4í>îiþdæ
>æ	îíoçí>îêiéküJýXì~éIí>êSðü>æ	çKçj: òF+iéb4ëKýVý	ÿ íoçmïðüJýXî4çWêWë;û4üJêKí>îiþOæOî4ýXî4èiéêWéë*ìOíoî4í>çWêKí>üjFûië*í>îiþ
ìOæ	ü4í>îiéê4æ+êë*û4î4çí>îý ðIîiýXìOí>æ{êKí>ìOékæ	î4èû4çWéNçæ	îxý	ë*æ	üékÿý	ëæq4ëKý	ïéNìí>î8fj òF+iéIFûië*í>îiþ
ìOæ	ü4í>îié87 ë*çWêCþXûiéNçKçKéNç8æyý ðIîiýXìOíoæéNîiþ	êUçWêWë;í>îiþê4æ+ê8ëKé4ëKéNçWéNîêKçGæüæ	î4è4í>èæ+êWé>æ	î­òF+ié
ý	ë*æ	üéêiéNîOü*4éNü?Iç"MiéêiéëÐíê»íoçêiéüæ	çWéê4æ+êÐû4î4è4éë»çWýXìCéüíë;üû4ìOçWêKæ	î4üJéNç»êiéþ	ýXæ>çjüæ	î4îiý	êÐïé
ëKéNæ	üiéNè­ò:F+iéjý	ë*æ	üéí>ç3ë*é4ëKéNçWéNîêWéNèLïðkæqîiýXî4è4éêWéë*ìOí>î4íoçWêKí>ü:Fûië*í>îiþìOæ	ü*4íoîiéÐê4æ+êþXûiéNçKçKéNç êWë;ûiêPO
=+æ>ûiéNç»ÿý	ëæ!üJýXîêKí>îiþ	éNîêjÿ.æ	üJêKçb.í>îGî4ýXî4èiéêWéë*ìOíoî4í>çWêKí>üTý ðIîiýXìOíoæIêKí>ìCég  æ	î4èGê4éNîOéIéNüûiêWéNçêié
>æ	î.í>îè4éêWéë*ìOí>î4íoçWêKí>üA{ý >ðVîiýXìGí>æ3êKíoìCég[æ	î4èæ	üüJé4êKçíÿÐæþ	ýXæ»çKêKæ+êWéS"pæ	çîiý	êëKéNæ	ü*4éNè­ò~F+ié
üJýXì~û4êKæ+êKíýXîbý	ÿ­êiéý	ë;æ	üé[íoçjüéNæ+ëðOí>îhfjò K çpýXûiëTF ûië;í>îiþìOæ	ü4í>îiéë*û4î4çjí>îbîiýXî4èiéêWéë*ìGí>î4í>çWêKíoü
ý ðIîiýXìOí>æ{êKí>ìCéb"íêæ	îfjUý	ë*æ	üé  êiéb4ëKý	ïéNìíêçWý }=	éNçí>çí>îa |ò
F+4ébüJýXì~éIí>êSðZý	ÿüoæ	çKçKí>üæ>æ	î4îí>îiþ®í>çA?Iîiý#"îMí>îèiéêKæ	í!/òypðP>æ	î4èiéë8 ]6 Lçiýg"çLê4æ+ê
ü>æ	çKç*í>üæz>æ	îî4í>îiþCí>î7 îíêWékèiýXìOæ	í>îçí>ç+TP K xT OSüJýXì~éêWé	ò ýXç*çKíïí!oíêSð8ý	ÿêWë;æ	üJêKæ+ïé>æ	î4î4í>î4þ
û4î4è4éëçKðVîêKæ	üJêKí>ümëKéNçKêWë*í>üJêKíýXî4çýXîOêié>æ	îdýéë*æ+êWý	ë*çG4æ	çyïééNîCí>î=	éNçWêKíþXæ+êWéNèOïVðqjðP>æ	î4è4éë»æ	î4èdïð
bæ	
 ü?IçWêWëgýX ì²æ	î4èféïé6 ]6 ;ò+F ë*æ	üJêKæ+ïí!oíêSðüæ	î®ïékæ	ü4íé=	éNèýXîZð"íê8=	éëKðxçKé=	éëKéçWðIîêKæ	üJêKí>ü
ëKéNçWêWë;í>üJêKíýXî4çò
u~~GP:u ¡8E¢q£iGGQ¤ QG¥{¦M§i¦¥zGG¨u n¥z¡©ªu¥z¤ ¬«­¯®m¦Q­Z¥zk°:E±^²³ªG¦Q¥{­
´

é 4æ6=	émèié=Ií>çWéNèLçWé=	éë*æVêWë*æ	îç>æ+êKíýXî4ç3ý	ÿüJýXî4è4í>êKíýXî4æ>æ	î4î4íoîiþmêWý[úVû4æ	îêKíd7éNèUpýý éNæ	îLÿý	ë*ìLûZ>æ+é	ò

F+iéë*é6æ+ë*é9ê4ëKééçWéæ+ë*æ+êWéZí>ç*çKûiéNçí>îêié6êWë*æ	î4çoæ+êKíýXîý	ÿüJýXî4è4í>êKíýXî4æj>æ	î4îí>îiþZêWýUúVû4æ	îêKíd7éNè
pýý >éNæ	î$ÿý	ë*ìLûZ>æ+é	òJF<ié7 ë*çWê  ê4æ+êxíoç8îiý(è4í}c{éëKéNîêbÿëKýXì×êWë*æ	îç>æ+êKí>îiþMü>æ	çKç*í>üæ<>æ	î4î4í>î4þZêWý
4ëKýýXçKí>êKíýXî4æVý	þXí>ü  í>çdê4ébéNîüJýVè4íoîiþ6ý	ÿéIéNüûiêKíýXî4çCý	ÿM>æ	î4çNòµF+iéüJý	ëKëKéNç{ýXîèiéNî4üJéïéê"pééNî
>æ	îéIéNüûiêKíýXî4çCæ	î4è¶oæ	î4çdí>çî4ý	êdæ	çCü>ýXçWéæ	çCí>îMü>æ	çKçKí>üæVoæ	î4î4í>îiþ  æ	çdýXîié>æ	îìOæ§ð¶4æ#=	é
çWé=	éë*æ[è4ídcéëKéNîêOéIéNüûiêKíýXî4çò0F+iéçWéNüJýXî4èí>çKçKûiéxíoçCêié®ë*é4ëKéNçWéNîêKæ+êKíýXîUý	ÿb>æ	î4çònG>æ	î4ç8æ+ëKé
ý	ïP·WéNüJêKçê4æ+êkìOæ3ZæçKêKæ+êWéOêWýêiédýéë*æ+êWý	ë*çêWýïédéVéNüû4êWéNèÿý	ëbëKýVèû4üí>îiþbæçKû4üüJéNçKçWý	ëkçKêKæ+êWé	ò
F+iémêíë*èdí>çKçKû4é  ç(éNüíd7 üpêWýU¸	 l  í>ç»êiémëKé4ëKéNçKéNîsêKæ+êKíýXîGý	ÿ{úVû4æ	îêKíd7 üæ+êKíýXîOý#=	éëæ!ií>î4íêKíoæVçKêKæ+êWéNç
æ	î4èý	ê4éëû4î4üJéëKêKæ	íoîsêKíéNçNò:rzîeIéNüJêKíýXî4ç  ò5¹Vò ] æ	î4è  ò5¹Vò5º~"péI4ë*ý{ýXçKéê"pýS"pæ§ðVçý	ÿèiýXí>îiþCê4íoçò
» îZ>í}?	éxíoîUü>æ	çKçKíoüæ>æ	î4îí>îiþ."<iéëKé8oæ	î4çOçKí>ìSðç(éNüíÿðMæZçWéNúVûiéNî4üJéxý	ÿqýéë*æ+êWý	ë*çGê4æ+ê
æ+ëKékéIéNüûiêWéNè9üJýXî4çWéNüûiêKí!=	é6ðxæ	î4èêiéçWêKæ+êWéý	ÿêiééNî^=IíëKýXî4ìOéNîsêæ+ÿêWéë[éNæ	ü*ý{éë;æ+êKíýXîxí>çûî4æ	ìqO
ïíþXû4ýXû4çð~?Iîiý#"îbæ>ëKéNæ	èið8æ+êmê4éj>æ	î4î4í>î4þêKí>ìCé  üJýXî4èíêKíýXî4æ>æ	î4çT4æ#=	éêWýCïéqæ+ïéêWýCïé64æ#=	é
è4ídcéëKéNîêðûî4èiéëkè4ídcéëKéNîêküíë*üû4ìGçWêKæ	î4üJéNçò l ý	ëéIæ	ìSé  êiéGéNî^=IíëKýXî4ìOéNîsêkìOæ§ð6ï{éCè4í}c{éëKéNîê
ýXîè4ídcéëKéNîêjéIéNüûiêKíýXî4çý	ÿ3êié	>æ	îbæ	î4èGê4éëKéìOæNð8ï{éqîiýXî4è4éêWéë*ìOí>î4íoçWêKí>üé=	éNîêKçæc{éNüJêKíoîiþq>æ	î
éIéNüûiêKíýXî­ò:F+iéè4ídcéëKéNîsêyë*éNç(ýXî4çWéNçyëKéNúVû4íë*éNèÿëKýXì üJýXî4è4íêKíýXîæP>æ	î4çyüæ	îGï{é+æ	î4èZéNèdïVðCèié7 îPO
í>îiþ8üJýXî4è4íêKíýXîæz>æ	î4çæ	çý	ï¼·QéNüJêKçj"íêæ	îíoîsêWéë*îæµçWêKæ+êWédê4æ+êë*é½éNüJêKç[êiéüûië*ëKéNîsê[æ	î4èxéNæ+ë>íéë

¾g¿6À

ÁVÂÃÄ*Å¼ÆÇÈÅ¼É}ÃÊyÈPÂÃZËÉdÅ¼É!ÂÃ¼ÌÍqÎ ÍgÌÃÄ

Ï(ÐÑ3Ð(Ò6Ï	ÓÔÐÕ¼ÒAÒ6Ö×PØ}ÙÓ ÖZÚ~Ò6ÖÐ	Ø!ÖeÑÏÛ¼ÜiÝØ}Ò6ÖÐMÒÞPÐ(Ò6Ö^ÐbÏ(ÓÐÕZÑ3ÐbÝÓÙÙ*Ò6ÝÐjÓß{ÒÙ*Ñ3Ð(ÓÙÏbÝÑÖeà{ÒUÒÞ>Ò6ÝÛZÐ(Ò6ázâ
Õ¼Ò6ÖSá¼Ò×PØ!ÏØ!ÖZäjÑbÙ*ÒßZÙÒ6Ï(Ò6ÖÐÑ3ÐØ}Ó ÖSÔåÓÙGÝÓ ÖZáØ}ÐØ}Ó ÖZÑæ>ßæ!ÑÖÏçÐÕ¼Ò<á¼Ò6ÝØXÏØ}Ó ÖZÏmÐ(ÓIà{Ò+ÚSÑá¼Ò+ÝÓ ÖÝÒÙ*ÖhÕ¼Ógè
ÐÕ¼ÒIØ!ÖÐ(ÒÙ*ÖZÑæzÏÐÑ3Ð(ÒÒ×Ó æ}×Ò6ÏMáZÛ¼Ù*Ø!ÖZäAßæXÑÖiÒÞPÒ6ÝÛ¼ÐØ}Ó ÖEçÑÖZáÕ¼ÓgèéÐÕ¼ÒbÓß{ÒÙ*Ñ3Ð(ÓÙ*Ï+Ð(ÓSà{ÒbÒÞ>Ò6ÝÛ¼Ð(Ò6áeÑ3ÙÒ
á¼ÒÐ(ÒÙ*ÚhØ!Ö¼Ò6áà>êiÐÕ¼ÒAØ!Ö^Ð(ÒÙÖZÑæzÏ(ÐÑ3Ð(Òâ
ë ÕZÒqØXá¼Ò6ÑhÓÔTÝÓ ÖZáZØ!ÐØ}Ó ÖZÑæßæ!ÑÖZÏ	ÑÏ	ÓàPì(Ò6ÝÐÏbè<Ø}ÐÕÑÖyØ!ÖÐ(ÒÙ*ÖZÑæmÏ(ÐÑ3Ð(ÒhÖÑ3ÐÛ¼Ù*Ñæ!æ}êÏ*Û¼ääÒ6Ï(ÐÏIÕ¼Ógè
ÐÕ¼ÒjÖ¼ÓÐØ}Ó ÖSÓÔzÝæ!ÑÏ*ÏØ!ÝÑæZßæ!ÑÖZÏuÏÕZÓ ÛZæ!áqà{Ò+ÒÞPÐ(Ò6ÖZá¼Ò6ázâ ë ÕZÒ<ÝÓ ÖZáZØ}ÐØ!Ó ÖZÑæPßæ!ÑÖZÏGáZØ!ÏÝÛZÏ*Ï(Ò6áSØ!ÖiíPÒ6ÝÐØ}Ó Ö
î â5ï>â!ðIÒÞPßæ!ØXÝØ}Ðæ}ê~ÙÒßZÙ*Ò6Ï(Ò6Ö^ÐÐÕZÒÏ(ÐÑ3Ð(ÒIÓÔaÑqßæ!ÑÖ8ÑÏ+ÑÖÑÛ¼Ð(Ó ÚSÑ3Ð(Ó ÖÐÕÑ3Ð<ÚSÑ3ñÒ6Ï+Ð(ÙÑÖZÏØ}ÐØ}Ó ÖÏàÑÏ(Ò6á
Ó ÖqÓàÏ(ÒÙ*×Ñ3ÐØ}Ó ÖÏ:ÝÓ ÖZÝÒÙ*ÖZØ!ÖZäjÐÕZÒÒ6Ö^×PØ}ÙÓ ÖZÚSÒ6Ö^Ðâ ë Õ¼ÒÏ(ÐÑ3Ð(Ò+ÓÔÐÕ¼Ò+ÑÛ¼Ð(Ó ÚSÑ3Ð(Ó ÖhÑ3Ð:Ò6ÑÝ*ÕSÐØXÚ~ÒTßòÓ ØXÖ^Ð
á¼ÒÐ(ÒÙ*ÚhØ!Ö¼Ò6ÏVè<ÕZØ!ÝÕÓßòÒÙÑ3Ð(ÓÙ*Ï+Ñ3ÙÒbÒÞPÒ6ÝÛ¼Ð(Ò6ázâVí¼Ø!Ú~ßæ}ÒÙÔóÓÙÚSÏTÓÔmÝÓ ÖáZØ}ÐØ}Ó ÖZÑæßæ!ÑÖÏVÑ3Ù*ÒbßZÙÒ6Ï(Ò6ÖÐ(Ò6á
Ø!Öí>Ò6ÝÐØ!Ó ÖZÏ î â5ï>â5ïSÑÖá î â5ï>â5ô>â
ë ÕZÒ.Ð¨èÓ³ÔóÓÙ*ÚhÏÓÔUÛZÖÝÒÙÐÑØ!ÖÐêçbÚAÛæ}ÐØ}ßæ}Ò.Ø!ÖZØ}ÐØXÑæMÏ(ÐÑ3Ð(Ò6ÏÑÖZáõÖ¼Ó ÖZá¼ÒÐ(ÒÙÚSØ!ÖZØ!Ï*Ú8ç<Ñ3ÙÒyà{ÓÐÕ
Ø!Ú~ß{ÓÙÐÑÖÐuÑÖZáiÖZÑ3ÐÛ¼Ù*Ñæ!æ!êAÑ3Ù*Ø!ÏÒ<Ø!ÖSÚSÑÖê~Ñ3ßZßæ!ØXÝÑ3ÐØ}Ó ÖZÏâaö<ÓgèÒ×ÒÙ#ç>ÔåÓÙÏ*Ø!Ú~ßæ!ØXÝØ}ÐêAÓÔòßÙÒ6Ï(Ò6ÖÐÑ3ÐØ}Ó Ö
èVÒGß{Ó Ï(Ð(ß{Ó Ö¼ÒuÐÕ¼ÒVáZØ!ÏÝÛÏÏØ}Ó Ö	Ó ÖÙÒßZÙÒ6Ï(Ò6ÖÐØ!Ö¼äMÖ¼Ó ÖZá¼ÒÐ(ÒÙ*ÚhØ!ÖZØ!ÏÚ0Ð(ÓIí>Ò6ÝÐØ}Ó Ö î â î ç ÑÖZáb÷Ù*Ï(ÐÝÓ ÖZÏ*Ø!á¼ÒÙ
Ó ÖZæ}êißZÙÓàæ!Ò6Ú,Ø!ÖZÏ(ÐÑÖZÝÒ6Ï+è<Ø}ÐÕ8Ï(Ò×ÒÙ*ÑæØ!ÖZØ}ÐØXÑæòÏÐÑ3Ð(Ò6Ïâ
ø ÙÓàæ}Ò6Ú,Ø!ÖÏ(ÐÑÖZÝÒ6ÏùQú~ûüiûýqûþmÿTÝÓ ÖZÏ*Ø!Ï(ÐÓÔ
ã



ð3â<Ñ~÷ÖZØ}Ð(ÒbÏ(ÒÐjú¯ÓÔaÓßòÒÙÑ3Ð(ÓÙ*Ï+ÓÔmÐÕ¼ÒIÔåÓÙ*Ú
ï>â<ÑhÏ(ÒÐ<ü


		



ÓÔ

 

bè<Õ¼ÒÙ*Ò eÑÖZá

AÑ3ÙÒ	÷ÖZØ!Ð(ÒIÏ(ÒÐÏÓÔ:æ!Ø}Ð(ÒÙ*ÑæXÏç

VÐÕZÑ3Ð<á¼ÒÐ(ÒÙÚSØ!Ö¼ÒIÕ¼Ógèéßæ!ÑÖÒÞPÒ6ÝÛ¼ÐØ}Ó ÖßZÙÓPÝÒÒ6áZÏç

ô>â<ÑSÔóÓÙ*ÚUÛZæ!Ñhý¯Ý*ÕZÑ3Ù*ÑÝÐ(ÒÙØ 6Ø!Ö¼ä~ÐÕ¼ÒAØ!ÖZØ}ÐØ!Ñæ{Ï(ÐÑ3Ð(Ò6Ï6çÑÖZá
î â<ÑSÔóÓÙ*ÚUÛZæ!Ñ~þµÝ*ÕZÑ3ÙÑÝÐ(ÒÙ*Ø 6Ø!Ö¼ähÐÕ¼ÒbäÓ ÑæÏ(ÐÑ3Ð(Ò6Ï6â

$#%&')(* )+-,.
#/01)(*$2)+3,4 5!
 6789':( ;+
=<?>A@ #%&'0(CB+@ED
@ #/01(CBF+@@ BHG JI
K
LM
NLO
LP -#QRR0(ST+ #/01)(S:+ USVGWLM
X! ZYJ[,\@ ]@
^
/_
ZK
H`
Na/bdcfe;a/gJh
]b
ie
ig
-h

_
ã

"!

ÒÑÏÏÛZÚSÒÐÕZÑ3ÐÐÕ¼ÒeÖ>ÛZÚAà{ÒÙhÓÔÑ3Ð(Ó ÚSØXÝÔÑÝÐÏØXÏ~÷ÖZØ!Ð(Òâ MÒ÷òÖ¼Ò
õÑÖZá
â jÒ÷Ö¼Ò<ÐÕ¼ÒMÏØ Ò
Qú aÓÔEÑIÏÒÐTúéÓÔzÓßòÒÙÑ3Ð(ÓÙ*ÏGÑÏÐÕ¼Ò<ÏÛÚ
õú
â ã ÒÑÏ*ÏÛZÚ~ÒÐÕZÑ3ÐUÒ6ÑÝ*Õ¶Óß{ÒÙ*Ñ3Ð(ÓÙ~ÑÖZá ÔÑÝÐ~Ø!ÏÑÏ*ÏØ}ä Ö¼Ò6á¶ÑeÛÖZØ >Û¼ÒSØ!ÖÐ(ÒäÒÙ6â
ë Õ¼ÒIÏÒÐ+ÓÔmØXÖ^Ð(ÒäÒÙ*ÏMÑÏÏØ}ä ÖZÒ6áÐ(ÓSÓß{ÒÙ*Ñ3Ð(ÓÙ*Ï<ØXÏá¼Ò6Ö¼ÓÐ(Ò6á8à>ê
VçÐÕZÑ3ÐÓÔaÔåÑÝÐÏ<àê
VçZÑÖZá8ÐÕZÑ3Ð+ÓÔ
ÓàÏ(ÒÙ*×Ñ3àæ!ÒÔÑÝÐÏ	àê
ç{ÑÖá
MÑÖZá
+ÔåÓÙ
³ÕZÑ6×Ò~ÐÕ¼ÒUÓà>×>Ø}Ó ÛÏjÚSÒ6ÑÖZØ!Ö¼ä¼â ã Ò
ÓÔåÐ(Ò6ÖØ!á¼Ò6ÖÐØ}ÔåêiÑÖ8Óß{ÒÙ*Ñ3Ð(ÓÙMÓÙ<Ñ~ÔÑÝÐ+è<Ø}ÐÕ8Ø!ÐÏ+Ø!ÖZá¼ÒÞ{â jÒ÷Ö¼Ò
ú â
ÝÓ ÖZáZØ}ÐØ}Ó ÖÑæußæ!ÑÖ¶á¼ÒÐ(ÒÙ*ÚhØ!Ö¼Ò6ÏAÔóÓÙ~Ñæ!æTØ!ÖZØ!ÐØ!ÑæuÏ(ÐÑ3Ð(Ò6ÏSÑÖáµÝÓ ÚAàØ!ÖZÑ3ÐØ!Ó ÖZÏUÓÔ+ÓÐÕ¼ÒÙSÝÓ ÖÐØ!Ö
äÒ6ÖZÝØ}Ò6ÏjÑÖeÒÞ>Ò6ÝÛ¼ÐØ!Ó ÖÐÕZÑ3ÐMÙÒ6ÑÝ*ÕZÒ6ÏjÑhäÓ ÑæaÏ(ÐÑ3Ð(Òâ ë ÕZØXÏ+Ø!á¼Ò6ÑSØXÏ+ÐÕ¼ÒAàÑÏØ!Ï<ÓÔ:ÐÕ¼ÒÙÒßÙÒ6Ï(Ò6ÖÐÑ3ÐØ}Ó Ö
ÓÔÝÓ ÖZáZØ}ÐØ!Ó ÖZÑæ:ßæ!ÑÖÖZØ!Ö¼ä8ÑÏ >ÛZÑÖÐØd÷Ò6á VÓ>Ó æ}Ò6ÑÖµÔóÓÙ*ÚUÛZæ!Ñ3Ò
jçè<Õ¼ÒÙÒ
Ø!ÏbÐÕ¼ÒÏ(ÒÐÓÔ
ßZÙÓß{Ó ÏØ!ÐØ}Ó ÖZÑæ{×3Ñ3Ù*Ø!Ñ3àæ}Ò6Ï<ÐÕZÑ3ÐjÙÒßZÙÒ6Ï(Ò6ÖÐ<ßæ!ÑÖZÏçZ×3Ñ3Ù*Ø!Ñ3àæ}Ò6Ï<Ø!Ö JÙ*ÒßZÙÒ6Ï(Ò6ÖÐ<ÐÕ¼ÒUØ!ÖZØ}ÐØXÑæzÏ(ÐÑ3Ð(Ò6ÏbÑÖZá
ÓÐÕ¼ÒÙIÝÓ ÖÐØ!Ö¼äÒ6ÖZÝØ!Ò6ÏçEÑÖZá.×Ñ3ÙØ!Ñ3àæ}Ò6Ï	Ø!Ö
ÙÒßÙÒ6Ï(Ò6ÖÐMÒÞPÒ6ÝÛ¼ÐØ}Ó ÖZÏ	ÓÔßæ!ÑÖZÏ6â ë Õ¼ÒUÔóÓÙ*ÚUÛZæ!Ñ
Ø!Ï	Ñ
ÝÓ ÖìÛZÖZÝÐØ}Ó ÖÓÔ:ÔóÓÙÚAÛZæXÑ3ÒIÐÕZÑ3Ð<ÔåÓÙ*ÚSÑæXØ ÒÐÕ¼ÒAæ}Óä Ø!ÝÑæmÝÓ ÖZÖ¼Ò6ÝÐØ}Ó ÖZÏ<à{ÒÐèVÒÒ6ÖeßÙÓß{Ó ÏØ}ÐØ}Ó ÖZÏTÙ*ÒßZÙÒ
Ï(Ò6ÖÐØ!Ö¼ä~ßæXÑÖÒÞ>Ò6ÝÛ¼ÐØ!Ó ÖZÏçZßæXÑÖZÏç¼ÑÖZáØ!ÖØ}ÐØ!ÑæòÑÖZá8äÓ ÑæÏÐÑ3Ð(Ò6Ïâ
ë ÕZÒßZÙ*ÓßòÓ Ï*Ø}ÐØ}Ó ÖZÑæ×Ñ3ÙØ!Ñ3àæ}Ò6ÏmÛZÏ(Ò6áqØ!ÖUÒ6ÖZÝÓPáZØ!Ö¼äjÝÓ ÖZáZØ}ÐØ!Ó ÖZÑæ>ßæ!ÑÖZÖZØXÖ¼ä<Ñ3ÙÒá¼Ò6ÏÝÙØ}à{Ò6áAØ!Ö ë Ñ3àæ}Ò
ë
ð3â
Õ¼ÒUÙÒßZÙÒ6Ï(Ò6ÖÐÑ3ÐØ}Ó ÖÓÔTÝæ!ÑÏÏØXÝÑæßæ!ÑÖZÖZØ!ÖZäiØ!ÖeÐÕ¼Ò~ÔåÙ*ÑÚ~ÒèVÓÙñÓÔ IÑÛ¼Ð SÑÖZá í>Ò6æXÚSÑÖ vð ï>ç
ð
ÛZÏ(Ò6Ï:ÐÕZÒ<×3Ñ3Ù*Ø!Ñ3àæ}Ò6ÏVú ÑÖá
Ó ÖZæ}êâ
ßZÙÓß{Ó ÏØ}ÐØ}Ó ÖÑæP×Ñ3Ù*ØXÑ3àæ}Ò
ÙÒßÙÒ6Ï(Ò6ÖÐÏuÐÕ¼ÒMÐ(Ù*Û¼ÐÕ
ÓÔ:æ!Ø}Ð(ÒÙ*Ñæ :Ñ3ÐMÐØ!ÚSÒIß{Ó Ø!Ö^Ð -â ¼ÓÙjÑhß{Ó ÏØ}ÐØ}×ÒIæ!Ø!Ð(ÒÙ*Ñæ
ç
uèMÕ¼ÒÙÒ TØ!ÏÐÕ¼ÒUØ!ÖZá¼ÒÞÓÔ ç
ÑÖZá8ÔåÓÙ<ÑSÖZÒä Ñ3ÐØ}×Òæ!Ø}Ð(ÒÙÑæ
ç
vâ
Ø}ñÒ\Ø!Önßæ!ÑÖZÖØ!Ö¼ä à>êÏ*Ñ3ÐØ!Ïv÷Ñ3àØXæ!Ø}Ðê
IÑÛ¼Ð
í>Ò6æ!ÚhÑÖzçAð ï çIßæ!ÑÖZÏÛZÏÛZÑæXæ}ê ÝÑÖZÖ¼ÓÐà{Ò
ÔåÓ ÛZÖZáeàêeßòÒÙ*ÔóÓÙ*ÚhØ!Ö¼äSÓ ÖZæ!êÓ Ö¼Ò~ÝÑæ!æmÐ(Ó8ÑiÐÕZÒÓÙÒ6Ú QßZÙÓg×ÒÙIè<Ø}ÐÕeÓ Ö¼ÒqÔåÓÙ*ÚAÛæ!ÑPâ ë ÕZØ!ÏMØ!Ïjà{Ò6ÝÑÛZÏ(Ò
ÐÕ¼Ò~ßZÙ*Óàæ}Ò6Ú Ò6ÖZÝÓPáZØ!Ö¼ä Ïbá¼Òß{Ò6ÖZá.Ó ÖyÐÕZÒ~ßæ!ÑÖyÏØ ÒçÑÖZáÐÕ¼ÒÙÒSØ!ÏbÖZÓ8Óà×PØ}Ó ÛZÏbÛ¼ßßòÒÙ	à{Ó ÛZÖZá.ÔåÓÙ
Ø}Ðâ ë Õ¼ÒÙÒÔåÓÙÒhÐÕZÒiÐÕ¼ÒÓÙ*Ò6Ú QßZÙÓg×ÒÙSØ!ÏI÷Ù*Ï(ÐÝÑæ!æ!Ò6á è<Ø!ÐÕ ÑeÔóÓÙ*ÚUÛZæ!ÑÐÕZÑ3ÐUÒ6ÖZÝÓ>áZÒ6ÏAÐÕZÒÏÚhÑæ!æ}Ò6Ï(Ð
Ø!ÖÐ(ÒÙÒ6Ï(ÐØ!ÖZäeßæXÑÖzç:ÑÖZá ÐÕZÒÏ*Ø ÒØXÏäÙ*ÑáÛZÑæ!æ}ê\Ø!ÖÝÙÒ6ÑÏ(Ò6á¶ÛZÖ^ÐØXæÑeßæ!ÑÖ¶Ø!ÏAÔóÓ ÛZÖázâ ø æ!ÑÖ ÏØ ÒÝÑÖ

lFlFm+


ts

j &
Vno p ]bqnro p ^
Z(Cs1+Ep
vu w
xsq,y z(Cs1+Ep{,"btno p |S
fsf,~}Q t(Cs1+Epz,"}{bqno p
(Cj &W
lFl +
_

_

)

k( lFl
%


 )Q
qr '¡  
´   ¡
¹   º
¾  ¾ º¿
¾  ¾ ºÆ
¾   ¡
ÌV  ¡
Ó r  ¡

¢V£ R R 
¢V£ 66¤CFFµV'¥&F¶&'¥3¦Zv·/R¦§¨&6¸©6ªCV «FR|§¨-6©6RªCR¬ :«F­Q|¬R ¯®°RQ:­QFQ E®°±²*³ F±²*³
» $&R&Z¥'¼RFµR R½iª £ | R Q³&§° £ ;R¦R&F¶&R&F²
¢V£ |'¦R&F¶F¤z&R&;¥À5½Á ¤q £ ZR -6ÂCÃÄÅ²
¢V£ |'¦R&F¶F¤z&R&;¥À5½Á ¤q £ ZR -{ÇÈÉËÊÅ²
¢V£ 6QF-V-RR&|¥ÀVR¬§¨6©²
¢V£ 6Fµ'&F¶¥3v -VR§°6©6ª1Í/R -Î²ËÏA²ËÐ³VF-&R&;©Uª1ÍARvÎ²ËÏA²Ñ
F¢V£ -Î²ËÏA²ËÏ³Ò% £ ¬¼ Vv·/¦&¤q£  RvR RvR6&'¦F²
6Fµ'&F¶¥3VdV©Ò ¶¼ Vv f¼ RvR RR
&'¦F¼QF-&§¨|F¤X RV%RR R '|¤F¬&F²
¢ Q °ÑÔÀÕ¸F±¨F¤zRFµRR F%0 vN £ |/±

µ] £ 'F&' Ö?A®i £ Á ±F £ F¤V R|·/¦R£  Z©R×/£ØrÙFH£  £ ÁA¦§Zµ|F¤V¬&'F3&R&J 
§°9®Ú%°¬f²]Û3¬F£Ú·/¬&&ÁF'R&µU&¸£ °&'¦ £/ß F¤v ]ÜA¦FR ­HÝ
FH¤F'§;¦-£ 
ÜA¦&R f¼Fy -¬F?¬RR&
&kA®Þ -&'¦ F¦F¤dRFµR RF3'Q J 
R'&vQFN §¨
R²
¢ -¦R&'&Z £ &'FRR ¼%à¨
&' F¨ £ JR&
RR áF¤5 £ /±dà £ · ß
F§¨UÚ/±N£ -R§¨Q ;Q A'«AU£ àF'áRF£  §-² £ ¢V£ R¨R]¯¢ à$ /R«/¼xâ=£ FÚÝd² ¢V£ 
 /R«/J§°£ ®Þ%Á? ÁRQ ]F? &F?F¤ ÁF JQ A'«Q² ¸RR¢V&£ 
; ¬;R' 
àZ¦&| |¤FRJãäÂ1ÈåÉ Å£ æ¶¼qãäAæç|¼qèÉÅRÈFÃ&æ¶¼qãFäÂ1ÈåÉÅ'çZ¼qèÉ Å'ÈÃRç|¼QFWãäAçdæ² 6 /R«/V§°®-µ
§¨)FFR% ­N
® 6¤ )à±¤¦VFµ'&F'²
é ÔêãäAçdæVë9èÉ Å'ÈÃRç4ìíãäÂ1ÈåÉ ÅçZëîvãäAçdæë9èÉÅRÈÃRæ
Ñ6ÔêãäAæç6ë9èÉ Å'ÈÃRæïìíãäÂ1È
åÉÅ'æ¶ëîvãä/æçZë9èÉ Å'ÈÃ&ç
ÏÔêãäÂ1ÈåÉ Åç|ë9èÉ Å'ÈÃRæïìíãäAçdæëîvèÉÅRÈFÃ&æ¶ëîvãFäÂ1ÈåÉÅ'ç
ÐÔêãäÂ1ÈåÉ Åæ¶ë9èÉÅRÈÃRç4ìíãäAæç|ëîvèÉÅRÈFÃ&çZëîvãäQÂ1ÈåÉÅ'æ
ðxñóòõôö
÷zø0ö
ùö/ú%û9üû0ýrþ%úÿþ xö 	xû0ýrþ%útù]
þ üútù
  F y&ÜA¦áF¤ªCRRNF¤³°Fµ'&F-&'§°ÿA®ÿ?F F F4 R¬FV&R&F¼U £ 
£·/¦R ÚF¤ £ ¨¬FÚF¢ F|R/¦¬±-RÜ
¦°F¤vR¦R&F;&R&¼z £ £ ]F&6F¤à £ ¬£ £
 ¦áµ]$±FF&R&F² R'£ &ZFÚ·/¦R ;àÁ£ W¤rF'§J¦] ;£ '' µ¨ 
RF&R&5FZ'A¦3¤FzF &R&vUR¦R&FX&R& XFR'&µq&¶ vQR 
F¤ £ °Fµ'&F'Z&'§°Ú
®i £ °Q£ Ff² » HFRR¬FX£ F± £ °Fá·/¬ R ®±FZ£ 
&dF¤5Fµ'&F'¶&N%Z·A¦&ÚdF£/ ß µ
VF¤5R¬§¨F¼Qà £ RFd R Ft£ F¬±¨ 
&dF¤XFµ£'&F'U§°®¸£ µ-i&'¦ £ F¦F¤5¤CFR¶Fd 
&'FtRR&;F¤5 £ ZFx£ ² Ú£ 
'¦RU °¤F'§J¦¨ ;&'§°¨ °Fµ'&F£ 'Z&$µ¨·A¦&?&£|&F±F ;à  
 µR
v¤rF§°F ÖR F¤{ R F%¬F¼FV Z¤rF'§°VµN- Z¬&&²
ÛÀF¨·/¦R 5'R'&&] «FVFR'FF±UF3|'R:­Q¬ ¯®ZRF § ª ZF¦&Ö
 ÍA§]Ff¼VÑ FÏ³² ¢V£ JJµF¦&-yFRR¬FÀQF±$Fà  £  £  ¨¦¬Ü
¦
·/¦R Ô]£ %F £ RN£ &ÜA¦JF¤;ªC&RF¤³|Fµ'&F'²áÛ3FÞ·/¦R R£ ¤rF§°F Ö?F
¤F'§;¦$ &R&¸ $R R °Fkµ&R R¨F¤6Fµ'&F'iªCR §] Ñ²Ñ9³]F



"!$#&%
'&!$()
*+',.-
(!$(/$0
1324150



687"9:<;=9?>$@)A4:CBEDGF.9HDIBG9JLKF$;MN689OPDGB7G;QDG9@/MRDGF$;@/7EDS7"T$DGF,UWVH9X/T$;BYB"O"F$;:C9[ZH\^]4_`\
YaZHb/Z_cd8e f5ghYSYiWjk_lfmonQnQn?m+Yiqp,_lfrmsYi8tj _lfquvjwmonQnQn?m+Yi8p5t x _lfquvjP_
68A79X/X~}+,QbQbQb?S}S$~Z?
YaZHb^]4_=YiW_ fy YiW_ fquvjwy c p&zae fy nQnQn y c pH{|e f
 A7A~;Q7"9HDSA7"BE@qM[BGO`F$;:C9oZH\/ZHrS"5Y8a_EiWjQbQbQbGiqp.<9M.R$?kWHY8_Ei8tj QbQbQb5Gi8p?t x 4\F$;
687"9:<;<9?>,@/A4: BG9J,B¡DGF.9HD¡@)6X/@)DS;Q7"9X¢i£@qBI69X/BS;<9HD¡}9M.oDS7"T$;<9HD¡}¢¤¥ZH¦DGF$;MsA4M$;3A6§DGF.;<Ar;Q7`9HDSA7"B
¨ j QbQbQb ¨ª© DGF
9HD:C9H«;¬i¢DS7"T.;=@/BE;P>,;OQT$DS;[9HD}k\
­ 6K;N9X/X)A5KhDGF$;L;P>;OQT$DG@/A4M®A6IBS;QV;Q7`9XEA~;Q7"9HDSA7"B<BG@/:¯T.X)DG9M.;QA4T.BGX)J°K;NM$;Q;±68A7":¬T
X/9H;LDGF.9HD
BSDG9HDS;DGF.9HDD²KA¬A~;Q7"9HDSA7"B9H7G;M$AD£;P>,;OQT$DS;³9HD£DGF.;IBG9:<;IDG@/:<;@)6~DGF$;QJC9H7G;I.;Qr;M
$;M	DQ´DGF.9HD@/BQ&@/6
9¯.7GA~A4BG@)DG@/A4M.9X$VH9H7"@/9Hµ
X);@/M¶DGF$;rA4BGDGOPA4M..@)DG@)A4M¶A6¦A4M$;A,OQOQT$7"B·@/M¶DGF$;.7G;OPA4M..@/DG@)A4MCA6vDGF$;IADGF.;Q7\
­ 6vM$A3
9H7"9XqX);X/@/BG:¸@/B·9X/X)A5K£;ª$K;=F.9V;¡6A7":¯T.X/9H;¹EYWc d8e f mLcº e f _|68A7E}+,QbQbQb5S}G$
±Z?¬9M.³68A7
9X/X¢G²»$¯¼½±BGT.O"FNDGF.9HD®
¾ ».\
F.;oBG@/¿Q;ÀA6=DGF.;sBG;QD³A66A7":¯T.X/9H;oAµ.DG9@/M.;687GA4:ÁBGO"F.;:C9HDG9ÂZH\/Zs9M.ÃZH\^]Ä@qB¶A6DGF$;ÀA7`$;Q7
YGÅ QÆÅ¤½kÇ)È5GaÉQYWc_S_l}G,G\
ÊË¦Ì
ÍÄÎ¢Ï8Ð[ÑÓÒÕÔ ­ M³DGF$;µ
X)A,OG«,B·K£A7"Xq¶;P>$9:<
X/;DGF.;68A7":¯T.X/9H;¡$;BGOP7`@)µ
@/M$ÖDGF$;¡.7G;OPA4M.
@)DG@)A4M.B9M.
DGF$;=~A4BSDGOPA4M
.@)DG@)A4M.BA6wDGF$;¡A~;Q7"9HDSA7"BI9H7G;=DGF$;¡68A4X/X)A5K@/M$Ö368A7}+,Z?4\×
cIØ e f ghYSHÙ,ÚIÛ f m+Ü)"ÝHSÚ f m+HÙWÝ	ÞPÜ/"Ú fquvj mN¹EÙÚIÛ fquvj msÜ)"ÝHSÛ fquvj _
c jSe f5ghYSHÙ,ÛÚfm+Ü)"ÝHSÛ£fmHÙ
WÝ	ÞQÜ)`Û£fquvj¢mN¹EHÙÛ·ÚEfquvj¢m+QÜ/GÝHGÚfquvjk_
=
c × e f ghYSHÙWÝ	ÞPÜ/"Ú f m+Ü)"ÝHSÛ f m+ÙÚIÛ fquvj mN¹QÜ/GÝHGÛ fquvj mN¹EHÙWÝ	ÞPÜ/"Ú qf uvj _
cIß e f ghYSHÙWÝ	ÞPÜ/"Û f m+Ü)"ÝHGÚ f m+ÙÛ·Ú fquvj mN¹QÜ/GÝHGÚ fquvj m[¹EHÙ
WÝ	ÞQÜ)`Û qf uvj _
F$;¡687"9:<;=9?>$@)A4:CB9H7G;9B68A4X/X)A5KB·68A7}£,Z?4\
¹EHÙÚÛ§f y HÙÚÛ§fquvj y c Ø e f
HÙÚÛ fy ¹EHÙÚÛ fquvj¢y c × e f
HÙ
WÝ	ÞQÜ)`Ú fy ¹EHÙ
WÝ	ÞQÜ)`Ú fquvj¢y 
c Ø ef
¹EHÙ
WÝ&ÞPÜ/"Ú fy HÙ
WÝ	ÞQÜ)`Ú fquvj¢y c × e f
QÜ/GÝHGÚ fy ¹EQÜ/GÝSÚ fquvj¢y c jSe f
QÜ/GÝHGÛ fy ¹EÜ)"ÝHSÛ fquvj¢y cØ e f

¹EHÙ,ÛÚf y HÙÛ·Úfquvj y c=jSe f
HÙÛ·Ú fy ¹EHÙ,ÛÚ fquvj¢y cIß e f
HÙ
WÝ&ÞPÜ/"Û fy ¹EÙ
WÝ	ÞPÜ/"Û fquvj¢y c jSe f
¹EHÙWÝ	ÞPÜ/"Û fy HÙWÝ	ÞPÜ/"Û fquvj¢y cIß e f
¹EÜ)"ÝHSÚ fy Ü)"ÝHSÚ fquvj¢y cIß e f
¹EÜ)"ÝHSÛ fy Ü)"ÝHGÛ fquvj¢y c × e f

F$;¯BG@/:¯T.X)DG9M$;QA4T
BI9H.X/@/OQ9HDG@)A4M[A6|D²KALAr;Q7`9HDSA7"B@/BIM.AD9X/X/AK;ª~KF.@/O`F[@/BI7G;Q.7G;BG;M	DS;oµJNDGF$;
68A4X/X)AKI@/M$Ö36A7`:¬T.Xq9H;¡6A79XqX¢G²»,3¼  à,ZH"]"á&CBGT.O`FRDGF.9HD®
¾ »â9M
R6A7I9X/X~}·s,Z?4\
¹EYWc d8e f mNcº e f _
ã
vA7";Q.7G;BS;M&D¢OQXq9BGBG@/OQ9X
X/9M
M.@/M$Ö9Bw9BG9HDG@/BSä9Hµ
@/X/@/D²J.7GAµ
X/;:R9Bv
7GA~A4BS;µJ¬å9T$DS¿9M
<æ,;X/:C9M
YaZçç]$Zççè4_`	@/M=9
.@)DG@)A4M¡DSADGF$;§9Hµ~A5V;£68A7":¯T.X/9H;£@/DÓBGT,é¶OP;BÓDSAIÖ4@/V;£9BG;QDÓA6.X/@)DS;Q7`9X/BªDGF.9HDw$;BGOP7"@/µr;
9Mo@/M.@)DG@/9XªBGDG9HDS;¯9M.À9C68A7":¯T.X/9<DGF.9HD$;BGOP7`@)µ~;BEDGF$;ÖA49XqBQ\F$;MÀ9âBG9HDG@/BSä9Hµ
@/X/@/D²JL9X)ÖA7"@)DGF.:êOQ9M
µ~;=T.BS;R68A7ärM..@/M$Ö<9<DS7`T$DGF,UWVH9X/T$;=9BGBG@/Ö4M.:<;M&DEDGF.9HDIBG9HDG@qBaä
;BEDGF$;.7GA~A4BG@)DG@)A4M
9X~6A7":¯T.X/9H;\£F$;
DS7"T$DGF$UWV?9X/T.;Bw6A7°.7"ArA4B"@)DG@)A4M.9X&V?9H7`@/9Hµ
X);B|cd8e fSS§NS}·s,S} $ NZ?@/M
.@/OQ9HDS;KF.@/O`F3Ar;Q7`9HDSA7"B
BGF$A4T
X/³µr;=9H

X/@);³DSAC7G;9O`F[DGF.;¡ÖA49X/BQ\
ëìí?î"ï.ðañ^ò"ïWóõô8öQ÷kó^ø5ùôWúSòkû£î`ü4ý?ùÕóþø5ÿ5ïWîîkùÕóõôWóþîkø5ù 	
5úïWú	ó^ù$ô5ú~óþøHû5ú£î"ü	òvü)ò"ðôS÷
rúªùÕó?ñõö£ò"ôÕô²ò`ðô5ú~ùÕý5ùÕðïWó5ô
ú  "!$#%	Õì
 ôWî£ô ?úwø?ò Eúaùªî"ü$ô ?ú¢üò`ðôWùa÷5üî`ïÓú 5ò ?ñþ

&'&)(

*,+-/.102-43)-

5687:9<;=>;?@;AB'C/BDFEAGE2HJIKEAMLNDFB1DOE2A%CQPSRTPOCQA%?
USV)W4XQYZ[YV)W4\"]^Q]_\"WQ`\ba[cJV"defc@ghZ[`,Z[i4\bZjk\b^lZ[i/cTg m/aa[c@WnZ\"WQXo^Q\"`fZV"dQ`[c a[p\bZ[Y_V)W4`ZfVqZ[i/cTV"^c a\bZfV"a`
ZfVrdsctchuvc@g m4Zfc@XwGxSyzZ[i4c{U|ivm/agi/}~%m/aY_W/{Z[i/c@`[Y_` jV)`fZq"c@W/c a\"]ghV)j^Qm/Z[\bd2]clW/V"Z[YV)W4`V"`[m4gi
jq\b^4^2Y_W/)`t\ba[cc@mQYp\"]_c@WnZtZfV~m/aY_W/jq\"gi4Y_W/c@` w:,V1c p"c a'YZoY_`oW/V"ZoW/c@ghc@`[`[\bayZfVghV)W4`Y_X/c a
jq\b^4^2Y_W/)`FaV)j\ba[dQYZfa\ba[yTV"dQ`[c a[p\bZ[Y_V)W4`ZfVT`fc@vm/c@W4ghc@`V"V"^sc a\bZ[Y_V)W4` wc,ghV)W4`[Y_X4c aV)W4]y`fyv`[Zfc@jq`
Z[i4\bZJ\ba[ca[c ^4ac@`fc@WnZfc@Xdvyo2WQYZfc`[c Z[`V"$\"ghZ[` \"W4Xi/c@W4ghcZ[i/c^Q]_\"WQ`X/VtW/V"ZJi4\'p"cZfV<dsc\bdQ]cZfV
a[c@`f^sV)W4XtZfV\ba[dQYZfa\baY_]yqghV)j^Q]_chu<dsc@i4\'pvYV"a,V"%Z[i/cTc@WnpYa[V)W4jqc@WnZ w
cghV)W4`Y_X/c aNghV)W4X4YZ[YV)WQ\"])^Q]_\"WQ`MZ[i4\bZ\ba[c2W4Y_Zfc`fZ[\bZfc"Z[i4\bZY_` "Y_W\"X4X4YZ[YV)WTZfVZ[i/cY_W/OV"ajq\bZ[YV)W
V"d4Z[\"Y_W4c@X\"`V"dQ`fc a[pb\bZ[YV)W4`@V)W4]_yq\J2W4Y_Zfc\"jV)m4WZ$V"%Y_W/OV"ajq\bZ[YV)WY_WnZfc aW4\"]4ZfVZ[i/c,^2]_\"WkY_`Sm4`fc@XY_W
X/c Zfc ajkY_W4Y_W/,i4Y_giV"^sc a\bZ[Y_V)W4`ZfVt^c aFV"aj\"W4Xi/V1Z[i/cY_WZfc aW4\"]`fZ[\bZfcqc p"V)]p"c@` w~i/cghV)WnZfaV)]
QV1Y_WZ[i4Y_`Y_W4XQ`V"S^Q]_\"WQ`Y8`J`[Y_jqY_]8\baZfVlZ[iQ\bZV"$W4YZfc\"m/ZfV)jq\bZ[\V"ac@vm4Ypb\"]c@WnZ[]_ylZfVlZ[i4\bZV"
^4a[V""a\"jq`|Y_W\`[Y8j^Q]c^4a[V""a\"jqjkY_W/K]8\"W/)m4\b"c,YZ[i<YZfc a\bZ[YV)W<V"a\"V"ZfVb}`fZ[\bZfc@jc@WZ\"WQX<`Y_j^Q]c
YF}Z[i/c@W}c@]_`[clghV)W4X4YZ[YV)WQ\"]_` w~i/ctW4YZfcl\"jV)m4WZqV"JY_W/OV"ajq\bZ[Y_V)W$Z[i4\bZY_`Z[i/cY8WnZfc aWQ\"]`fZ[\bZfcV"
Z[i/c^Q]8\"W{XQm/aY_W/chuvc@g m4Z[YV)WMg \"WdscgiQ\ba\"ghZfc aY  c@X¡dy{\o`fZ[\bZfcqpb\baY_\bdQ]cZ[i4\bZghV"a[ac@`f^sV)W4X4`ZfV\
^4a[V""a\"j¢ghV)m4WZfc a@w
USV)WQX4YZ[YV)W4\"],^Q]_\"W4`<,Y_Z[im4W4a[c@`fZfaY_ghZfc@X£Zfa\"WQ`[YZ[YV)WOmQW4ghZ[YV)W4`<\ba[cp"c a[yGchu^4a[c@``[Yp"cdQm/Z<Z[i/c
Wvm4jTdsc aV"s^Q]_\"WQ`N,YZ[ic p"c@Wk\T`[jq\"]_]/Wvm4jKdc a$V"`fZ[\bZfc@`S\"W4XV"d2`fc a[pb\bdQ]c\"ghZ[`$Y_`p"c ayiQY)i",i4Y8gi
jq\b"c@`^Q]_\"W¤`fc@\bagi{XQY¦¥g m4]Z w§`Z[i/c a[cY_` 2Y8Wl"c@W/c a\"]\Zfa\"X/ch}Vb¨¡dsc Zc c@W{Z[i/cchuv^Qa[c@`[`[YpYZy<V"
Z[i/cac ^4a[c@`fc@WZ[\bZ[YV)Wk\"WQXqZ[i/c,XQY¦¥g m4]ZyTV"2W4XQY_W/^Q]_\"W4`@)c\"]_`fVTghV)W4`Y_X/c a$jV"aca[c@`fZfaY8ghZfc@XqOV"ajq`
V"ghV)W4X4YZ[Y_V)W4\"]^Q]_\"W4`Y_W©c@ghZ[YV)W4`ª/w¬«vw¬«k\"W4Xoª/w¬«vw¬­vw
® ¯8°2¯±³²´µ¶%·¸k¹Oº»G¼T¶M½¾2·@º½¹O¿º¾4ÀÂÁJ½µ¶· ¹Fº¹Ã¶GÄSÅ¶¿2º¹Ã¶%·
~i/cQa`[ZMOV"ajq\"]_Y @\bZ[Y_V)WTV"QghV)WQX4YZ[YV)W4\"]n^Q]_\"W4`m4`fc@`M2W4Y_Zfc\"m/ZfV)jq\bZ[\OV"aNa[c ^4a[c@`[c@WnZ[Y_W4,Z[i/c|Y_WZfc aW4\"]
`fZ[\bZfcJZfa\"WQ`[YZ[YV)W4`$Z[i/c^Q]_\"W<jq\b"c@` w$~,i/c`[mQg ghc@`[`fV"a`fZ[\bZfcJV"M\`fZ[\bZfcJY_`|X/c Zfc ajqY_W/c@XdykZ[i/cZfam/Z[i}
pb\"]_m/cSV"Q\"WV"dQ`fc a[pb\bdQ]cO\"ghZ\"`[`fVg Y_\bZfc@X,YZ[iKZ[i/c|`fZ[\bZfc"),iQY_giKcg \"]_]ÆOÇÈÉÊbËÌbÍOÆÍÎÊbËV"QZ[i/cS`[Z[\bZfc"w
~i/cZfa\"W4`[YZ[YV)Wm4W4ghZ[YV)WQ`NV"2Z[i/c\"m4ZfV)jq\bZ[\Tjq\'ydcghyg ]_Y_gY_WZ[i4c`fc@W4`fcZ[i4\bZ\"Wq\"m/ZfV)jq\bZfV)Wjq\@y
a[c Z[m/aWtZfVk\q`fZ[\bZfcYZi4\"`V)W4ghcK]c FZ w
Ï \"gi`fZ[\bZfcV"S\<ghV)WQX4YZ[YV)W4\"]%^Q]_\"Wi4\"`\"W\"`[`[Vvg Y_\bZfc@X`[c ZV"V"^sc a\bZfV"a` wc`[\'y¤Z[iQ\bZOV"a\
)Yp"c@Wo`fZ[\bZfc"/Z[i4c@`fcV"^c a\bZfV"a`\ba[ckÈhË2ÐÑhÒ_È[ÌY_W<YZ wÓM\"W<V"^c a\bZfV"aY_`Sc@W4\bdQ]c@X<Y_WZ[i/cJg m/a[a[c@WZS`[Z[\bZfc"
YZY_`|chuc@g m/Zfc@X{Y%Y_Z[`^4a[c@ghV)W4XQYZ[YV)W4`|\ba[cZfam/c"w
ÓÔW¡X/V)jk\"Y_W4`Y_Wr,i4Y_giV)W4]y{^Q]_\"Wchuc@g m/Z[YV)Wzjq\@yrg \"mQ`fcgi4\"W/"c@`Y_WZ[i/cqc@WpYa[V)W4jc@WZ Z[i4Y_`
OV"ajÕV"T^Q]8\"W4`tY_`t`[m¥g Yc@WZ Ö,i/c@W/c p"c al\×^4aV"dQ]c@jÕY_W4`fZ[\"WQghcY8W£ghV)WQX4YZ[YV)W4\"]^Q]8\"W4W4Y_W/zi4\"`l\
`fV)]_m4Z[YV)W4Z[i4\bZY_` 4Z[i4c a[cKY_`,^Q]_\"Wl\"g ghV"aX4Y_W/qZfVt`fV)jcKa[c@\"`fV)W4\bd2]cTW/V"Z[YV)WV"ghV)W4X4YZ[Y_V)W4\"]^Q]_\"WQ` 4YZ
i4\"`S\K`[V)]_m/Z[YV)W\"`Z[i4cY_W4XkV"^Q]_\"WkXQY_`[g m4`[`[c@XkY_WkZ[i4Y_`S`fc@ghZ[YV)WwØ/V"a|Z[i/c`[Y_jq^Q]c a$W/V"Z[Y_V)W4`$V"^2]_\"W4`
Y_W©vc@ghZ[Y_V)W4`ª/w¬«vw¬«q\"WQXoª/w¬«vw¬­Z[i4Y8`Y_`W/V"ZZ[i4cg \"`fc<Ù`fc c Ï u/\"j^Q]cª/w¬­qY8W©vc@ghZ[YV)Woª/w¬«vw¬«vwÛÚ
~i4cSWvm4jKdc aV"Q\"m/ZfV)jk\bZ[\,YZ[iKc p"c@W\`jq\"]_]vWm4jKdsc a%V"2`fZ[\bZfc@`Y_`%O\"Y_a]yi4Y)i\"W4XKZ[i/c a[cY_`W/V
\^4aY_V"aYQm/^Q^c aSdsV)m4W4X<V)WtZ[i/cJWvm4jTdsc a|V"%`[Z[\bZfc@`,W/c c@X/c@X`[V^2\ba\"jc Zfc aY @Y8W/Z[i/cc@W4ghVvXQY_W/,YZ[i
a[c@`f^sc@ghZZfVZ[i/cWvm4jKdsc aÜÝ|V"N`fZ[\bZfc@`Y_`W/c@ghc@`[`[\bay"w|©vV)]_m4Z[YV)W4`|\ba[cQa`[Z|`[V)m/)inZOV"advykamQW4W4Y_W/\
Z[i/c V"a[c@j}^4a[V'p"c a,YZ[i<c@W4ghVX4Y_W/)`S,Y_Z[i<\`jq\"]_]sWmQjTdsc a|V"`[Z[\bZfc@`,\"W4Xt^sV)Y_WZ[`SV"%Z[Y_jqc"\"WQXtZ[i/c@W
"a\"X4mQ\"]_]yY8W4gha[c@\"`[Y_W4Z[i4cJp\"]_m4c@`V"NZ[i/c@`fcJ^Q\ba\"jqc Zfc a` w
~i4cFV"ajm4]_\bc,FV"aOV"ajq\"]8Y @Y_W/JghV)W4X4Y_Z[YV)W4\"]^Q]_\"WQ`V"sZ[i4Y_`NOV"aj\ba[c)Yp"c@WqY_WqØNY)m4a[cÞbwßch2W/c
à@áãâåä Þbæ ç ç ç'æ[Ü Ý è wé©gi4c@jq\bZ[\×«vw_Þ¤\"W4XG«vw¬«z`fZ[\bZfcZ[iQ\bZkOV"akc p"c a[y`fZ[\bZfc¤Z[i/c a[c{Y_`chu/\"ghZ[]yÂV)W/c
ghV)W4X4Y_Z[YV)WwK©gi/c@jq\bZ[\l­vw_Þ}­vwêª`fZ[\bZfckZ[i4\bZFV"aJc p"c a[y{`fZ[\bZfcqZ[i/c acY8`chu/\"ghZ[]y¤V)W/c`[m4g ghc@`[`fV"aK`fZ[\bZfc
OV"aTdsV"Z[iZ[i/cZfam/ck\"W4XrZ[i/ck\"]_`fcpb\"]_m/cqV"|Z[i/c<ghV)W4X4YZ[Y_V)Wwk~i4Y8`Y_`W/c c@X4c@XrZfVc@WQ`[m/a[cZ[i4\bZKZ[i/c
ë'ë1ì

íSî2ïQðñ/òóQôñ/õïQöôî2ï4÷Qõ¦ñ/õ_î2ï/øQùú)ù1øQïQð
ûKüýOþMÿ4ü
	MüMý2ýü
 !#"$  %
&' (*),+- (/.0+2131314+5 (/6

Y
78:9;:<<=?>5@BA!CEDGF'CIHJLKM@BNP33ORQTSGUWVRUT;/VF5X H!Z
;:[T\-;:[W]B[QT^_]39G;/VR`a8'[Wb0c3C Cdbfeg8:7h@BN
ûKüýOþMÿ4ü
@ÿ,		i!jkmlT!KýFün!opjflMü, ý2ýüqÿü,	!ýMü
rs!sTEtu#"?s!s % t
Y
r&'s!sTBvw#"?s!s % v
A ORQiSIUWVRUT;/V{F-X H

7
:
8
x
9
:
;
y
<

<
B
D
R
=
z
C
:
F
I
C

H

J
n
K
@
r&r's!s tq+Ws!|s}Gtq+2131314+-ssf~dt
r*s!s c vM+-s!|s}EvM+2131314+5s!s~  v
78:9;:<<=?>5@BA
c
 *ljý8ü,mlT!
s  
c
ûKüýOþMÿ4ü
	2ÿjfjf4ü,B*lT!
s! #"$sI 

33
Y
7 8:9;:<<{>pDC CdRJ'CEDB=RCzFJ_Kn@BAWOIQTSIUWVRUi;/V=X F
 jflü ýýüfPln@ÿ,		jmlT!
s! -   % u
  %  5s!sTtu#sI y
&'s   -   %  "0 %  -s  s  vw#s R yc 
LTT ý	lTýMüPp  ijflTj

c

33

78:9x;:<<>
DC Cdd J'Z
DB=ICzFJ>5@ A CIHu>5@ N

|*  -sTR ip¡ ¢!w13131/p¡y(¢¢:#£x 
33>5
 @BACd=?>w@B §?Z
|*&'£ ¤d x -s c  z+2131314+¥  ~  Wsf~   ¢d 78:9x;:<<TF¦
{>pDC Cd    Y J ¡ 33 ¡y(
c
c
;:[T\W¨U]39R]©ªR«R¬ =
D cBC C J
/¯?°
­
`a®'Q9R]
[TSE8\T`[®8:7hSE8'[T\T`aVR`8'[T;:<!±i<;:[TO²¨x`VRUWQT[9R]BOdVd9G`SEVd]B\uVd9I;:[TOR`VR`a8'[u7Qi[TSEVR`a8'[TO
 
Vd9I;:[TOI`aVR`a8'[_7QT[TSEVR`a8'[iO$@BA³¦D4´LCGµ¶ J
@BA·8:7±i<y;:[TO$;/9R]¨]B<<a¸z\]E¹[]B\fº  8:9I^LQT<; º OdVR;/Vd]BO{VRUT;/VVRU]
±i<;:[»]E¼]BS3QVR`a8'[uOdVR;/9RVRO½`[¾OdVR;/Vd] ;/V²VR`^_ ] º¿U]SGU8'`SE]À78:9²ORVR;/Vd] `O²;/9RÁ`aVd9I;/9RÂ:Z;:[T\»8:Á*Ã`a8'QTOR<Â
\8]BO[T8:V{OR;:SE9G`Ä¹SE]x®:]B[T]39I ;: <`aV¢Â:ºÅSI U ]B^¦; º OdVR;/Vd]BO{VRUT;/V{VRU]±i<;:[¦S3;:[i[8:VÁ]`[·V¢¨8_OdVR;/Vd]BO½;/V{VRU]
OR;:^_]ÆVR`y^_]:ºÅSIUT]B^·;/VR; º ;:[T\ º SIUT8*8'Od]ÆVRUT]ÀOIQTS3SE]BOROd8:9xORVR;/Vd ]Æ 8'[uVRU]À Ái ;:OR`O{8:7VRU]ÀVd9IQVRU¸|Ã/;:<Q]
8:7ÆVRU]2SE8'[T\T`aVR`a8'[n;:[T\nVRUT]5Vd9I;:[TOI`aVR`a8'[P9R]B<y;/VR`a8'[fºgÅSIUT]B^·;/VR; º ;:[T\ º ;/±T±<aÂq]E¼;:SEVR<aÂPVRUT8'Od]
8:±]39I;/Vd8:9IOxVRUT;/V;/9R]Ç]B[T;/Á<a]B\-`[uVRU]ÇS3QT9R9R]B[*VOdVR;/Vd]¶;:[T\-78:9¨UT`SIUu­ VRUT]Ç±T9R]B SE8'[T\i`aVR`a8'R[TË ÌO²;/Ë } 9R]ÇVdË 9GÌ-Q]:Ë!º Í
}
}
}
}
Ë ÌÍ
9Ri]3Í¥
 VRU]ÆÍWORSG U]B^·Ë;/ÌWVR;·
Ë `y[ Í `a®'QT9R] ;/9I|]À
£É
 Ê Í 
¿UTËÍW
]ÀOI`a È3]BO²Î 8:7VRU]À7:8:ÍW
9I^L QT<;/]À
±T9R ]BOR]B[mVd]B\uÁÂ¦
É Ê ¦É Ê
É Ê
É Ê ¦É Ê R É Ê
R É ÊÏGÐÑ «IÒÓ
R É¶ÔGÉ Ê dº
ÕÉ Ê
]B[TSE]ÇVRU]OI`aÈ3]Æ8:70VRU]Æ¨xU8'<a]ÇOR]3V8:7,78:9I^LQT<;/]Ç`O8:7,8:9I\T]39
} Ë Ì-Ë
Î Í
Ë ÌWË } Í
Í
|£¶

É Ê
É Ê
É Ê
R É Ê3ÏGÐÑ «IÒÓ
d
­

ÖÖÖ

×xØaÙÚÛÙTÜ'Ù

ÝÞßiàáâã5äåyæèçé:êëRìí¶îiïaéðRñòxó{é:êIïô5íEõö:÷_øïaí:ùió{íøTêIéôTúiðEíÇëRìííBûiðEéôTüyûý·þé:êøiïyö:ûTò½óxüaëRì5ëzó{é
òdëRö/ëdíBò3
ÿ ìTíòIðIìíB÷·ö/ëR
ö ÿ 	ÿ 
üaíBïôwëRìí_þé'ïyïaéóxüyûý»þé:êI÷LúTïö/íþé:
ê '
ÿ pí·ö:òRòRúi÷_íëRìTö/ë
ëRìíÇþö:ðEëR
ò  "!#%$&'Ç)
ù (*$+&!,-' ö:ûT.
ô /'10nö/êIíÇé:îiòdí33ê 2/ö/îiïaí:ÿ

465-78:9<;>=@?+A BDC)EGFH465-7IA BJ=:KDC
465-78:9<;>=@?+A BDC)EGFH465-78:9	CZY
465-7IA B]=:KDC)EGFR465378:9<;>=@?+A B]C
465-7IA B]=:KDC)EGFR465378:9	CZY
465-78:9	CY[EGFR46537I+A B]=:KDC
4 5-78:9	CY EGFR4 5378:9	;>=@?A B]C
465-7IA B]=:KDCbUW465378:9	;>=@?A B]CcUa465-78:9	CY

LNML)MPOQEGFRL)MLTSO
LNMLTSXOQEGFRL)ML)M-O
L[S^L)MPOQEGFRLTS\LTSO
L[S^LTSXOQEGFRLTS\L)M-O
LNML)M3_EGFRL)MXLTS%_
L M L S _EGFRL M L M _
L[S^L)M3_EGFRLTS*LTS%_
L[S^LTS%_EGFRLTS*L)M3_

LNMLNM<OVUWL)MXLTSO
L[S\LNM<OVUWLTS*LTSO

LNMLNM-_`UaL)MLTS%_
L S L M _`UaL S L S _

,êIúëRìd"2/ö:ïúí_ö:òRòRüý'ûT÷_íBû*ëRòÀëRìTö/ëÇòRö/ëRüòdþ:2ëRìíBòdí_þé:êI÷¶úiïö/íêRí3øTêRíBòdíBû*ëÆëdêIö:ûTòIüaëRüaé'û2þúiûTðEëRüaé'ûTòé:þ²ðEé'ûd
ôTüaëRüé'ûTö:ïføiïö:ûiò3ÿeìTíÇêRíB÷·ö:üûiüûý_þé:êI÷¶úiïö/íôíBòRðEêGüaîíÇìéó ëRìíøïö:û-ôí3ëdí3êI÷¦üûíBò½óxìiüðIì5é:ø!í3êGö/ëdé:êIò
ö/êRíÇíEõíBð3úëdíBôfÿçé:b
ê fgh^id*Z_òRðIìíB÷¦ö/ëRj
ö 
ÿ Çö:ûT
ô kÿ lüaíBïô¾ëRìíÇþé'ïïaéóxüûýþé:êI÷¶úiïö/í:ÿ

L)M-7 m
L)M-7 noEpFRLTS7 nqL[S7 n*EpFRL)M-7 n
r ðGìíB÷·ö/ëRöjsÿÆö:ûTôasÿ>LëRìTö/ë½ôíBòRðEêGüaîíòdëRö/ëdíÆëdêGö:ûTòRüaëRüaé'ûiòH üaíBïô»þé:êco^tuvw¶ö:ûTôxfey^id*Z

ëRìíÇþé'ïïaéóxüûýLþé:êI÷¶úiïö/í:ÿ

Lz5-7 n {a46537I+A B]=:KDC1{ (\$&3!,3' n|{L[5L 5~} OQEGL 5"}u7 nu)M
Lz5-7 n {a46537I+A B]=:KDC1{F (\$&3!,3' n|{aL[5XL 5~} _EpL 5"}u7 nu)M
Lz5-7 n {a465378:9	;>=@?A B]Cc{  "!#\$+&X' n|{L[5L 5 } OQEGL 5 } 7 nu)M
Lz5-7 n {a465378:9	;>=@?A B]Cc{aF  "!#\$+&X' n|{aL[5XL 5~} _EpL 5"}u7 nu)M
Lz5-7 n {a465378:9~CY{ /'10 n|{WL[5L 5"} OaEGL 5~}7 nu)M
Lz5-7 n {a465378:9~CY{WF d'b0 n|{aL[5L 5 } _EGL 5 } 7 nu)M
r ðGìíB÷·ö/ëRöx*ÿö:ûTô*ÿ> üaíBïôuþé:êfg^id*Zö:ûiôWlëRìíÆþé'ïïaéóxüûýþé:êI÷¶úiïö/í:ÿ
 m7 5N{WL[537 n { /'10 n{ (\$&3!,3' n"Epm7 n
bm7 noE - m7MN{WL)M-7 n~zU  m7 SH{aLTS7 n	-
 M-7 5N{WL[537 n { /06' n{ (\$&3!,30 n	EGlM-7 n
lM-7 noE - M-7MN{WL)M-7 n~zU  M-7 SH{aLTS7 n	-
 S7 5N{WL[537 n {  "!#\$+&X' n|{ (\$&3!,30 n~EGbS7 nbS7 noE - S7MN{WL)M-7 n~zU  S7 SH{aLTS7 n	-
 7 5 {WL 537 n {  "!#\$+&X0 n { (\$&3!,3' n EG  7 n   7 n E -b 7M {WL M-7 n zU b 7 S {aL S7 n -


 û ëRìTüò¾þé:êG÷·ö:ïü+Bö/ëRüaé'û ðEé'ûTôiüaëRüaé'ûTö:ïøiïö:ûiò»ö/êRí¥ôTí3ëdí3êI÷·üûíBô î/nëRìíh2/ö:ïúTö/ëRüaé'û é:þ24ö/êIüyö/îiïaíBò
L"LO ù TL @L*_ ù 4e:7  ö:ûiô  37  ÿ,ék÷·ö/ñ:í2íEõøiïüð3üaë¦ëRìíw÷_íBö:ûiüûý é:þÆøïö:ûTò·ëRìTí3êRíwö/êRí
ö/ëuïaíBö:òdë
ëzó{éuøé'òRòRüaîiüyïüaëRüaíBò3ÿÀ
 ü+:2 íLö¦þé:êI÷·ö:ïôí%ûiüaëRüaé'ûWé:þ?ðEé'ûiôTüaëRüaé'ûTö:ïøiïö:ûTòxþé:êíEõö:÷_øiïaíLö:òøiêRé:ý:êIö:÷·òüû
ö-òRüy÷_øiïaíøTêRé:ý:êGö:÷·÷·üûý-ïyö:ûý'úTö/ý:í·óxüëRìpðEé'ûTôTüaëRüaé'ûiö:ïòÆö:ûTô üëdí3êIö/ëRüaé'ûfù,é:êÇý'ü+:2 í»ö5÷_íBðIìTö:ûiüòR÷ þé:ê
íEõíBð3úëRüûýëRìTí$øiïö:ûTòfüy÷_øiïüð3üëRï+½
 êRí3øTêRíBòRíBûmëdíBôîÀ ëRìíR/2 ö:ïúTö/ëRüé'ûTòfé:þëRìí?ö/þé:êRí%z ÷_íBû*ëRüaé'ûíBô42 ö/êIüyö/îiïaíBò3ÿ
pí¶ðGìéé'òdíÇëRìíïyö/ëdëdí3êxö:ïaëdí3êIûTö/ëRü:2 íÇîíBð3ö:úTòdíÇüaëüòx÷_é:êRíÇòdëdêIö:üý'ìmëdþé:êRó²ö/êIôfÿ
r éö:òRòRúi÷_íó{íÆìTö*:2 íÆö/2 ö:ïúTö/ëRüaé'û E ZXÆ ëRìTö/ë½ö:òRòIüaý'ûTòëdêIúëRìd"/2 ö:ïúíBòëdéëRìíÆòdí3ë é:þ
øTêRé:øé'òRüëRüaé'ûTö:ï|24ö/êIüyö/îiïaíBò²ëRìTö/ëxüy÷_øiïüð3üëRï+êRí3øTêRíBòdíBû*ëö_ðEé'ûTôTüëRüaé'ûTö:ï!øiïö:ûfùö:ûTô-ëRìíÆøiö/êIö:÷_í3ëdí3êf- =¡ 
ëRìTö/ëxüyò½ëRìíÇïaíBûý:ëRì-é:þëRìTíÆøiïö:ûuíEõíBð3úëRüaé'ûfÿHxìíÆøTêRéðEíBôTúêRíÇüyûWçüý'úêRíL
 íEõíBð3úëdíBòxëRìTíü÷_øiïyüð3üaëRï+
¢^¢*£

¤g¥|¦ §¨©ª «¨¬+¦ ­«d¥|¦® ¬D¨¬¥|¦¯ °±²°o¯ ¦ §
³µ´J¶¸·d¹
º ´J¶¼»¹
½x¾b¿-À)ÁÃÂeÄÅÂ-ÆÇ¡ÈHÉÊ
Ë6ÁµÌH¿-Í
Î%Ï/Î*Ð\Ñ ³ Îº3ÒÓÑÔ ³3ÕÖ Î\×²ÑºÔ+Ø Õ ÔÔ[×ÙTÎ\Ú Õ³ ×ÚXºÛeº3Ñ ÐÜ ³ Ü Õ³ÝÞßà:á âãR¶wä
ÕÖåQ³ ÜÎlÙÚ3Î*Ð%× Öå Ò ³ Ò+× Ö ºg×æç×ÙTÎ\Ú Õ³ ×ÚÛ Õ ÚÎ ³ ÚÑÎ ¹
Ð ´J¶ ÛHº3Ñ ÐÜ ³ Ü Õ³ÝÞ"è â3á à ãR¶ä¹
ºPé ´J¶ ÛeºÑÐÜ ³ Ü Õ³ÝÞ"ê[âêà¡ëcãì¶wä¹
º3í ´J¶ ÛHº3ÑÐXÜ ³ Ü Õ³ÝTÞ"ê[âXêTà:îãH¶wä¹
¿-ï æ Õ Ð ³bð Òº ³ ÚÑÎñ ¾1ÁHÍ º ´J¶ ºPé ÁeÀNòdÁ º ´J¶ º3í ¹
³µ´J¶ó³1ô¼»¹
ÁHÍ1É
õ Òö²ÑÚ3Îl÷ ´eø Ú3×/Ð%Î å ÑÚ3Îcæ¡×ÚÎ%Ï/Î*Ð\Ñ ³ Ò Ö ö Õ Ù Ô ÕÖ
Ú3Î\ÙÚÎ*º-Î Ö³ Î å Ù Ô ÕÖ[ùú ÜÎûe×Ú åýü º3ÒuÓÑÔ ³3ÕÖ Î\×²Ñº3Ô+ØdþÚ3Î\æ:Î\Úº ³ × ³ ÜÎÚÎ*ÿÑÒÚ3Î*ÓÎ Ö³³ Ü Õ³x³ ÜÎhº-Î ³ ×æ
×ÙTÎ\Ú Õ³ ×ÚºgÛçûÒ ³ Ü ³ ÚÑÎÙ Ú3Î*Ð%× Öå Ò ³ Ò× Ö º ÕÖåÝÞßà:á âXãR¶wä Ü Õ º ³ ×Î1Ò å Î Ö³ Ò Î å TÎ\æ:×Ú3Î ÕÖ Øj×æ ³ Ü×²º-Î
×ÙTÎ\Ú Õ³ ×Úº Õ Ú3ÎÎ%ÏdÎ*Ð\Ñ ³ Î å[ù × ³ Î ³ Ü Õ³ /Ø ³ ÜÎÑ Ö ÒÿÑÎ Ö Î*º3ºº3ÐXÜÎ*Ó Õ³3Õ ÷ ù»	/ù
a³ ÜÎlÛ6Ò Öè â3á à	 ê â ê à ë
ÕÖåêzâêàî ÒºÑ Ö ÒÿÑÎ*Ô+Ø å Î ³ Î\ÚÓÒ Ö Î å /Ø ù
 "!#$%!&'!()*!,+-(%)/.0+"!&1&+"!&24365&!&1&+(%1%
ú ÜÎ1Ù Ô ÕÖ ºgÒ Ö³ ÜÎcÙÚÎ87/Ò+×²Ñ ºgº3Î*Ð ³ Ò+× ÖaÕ Ú3Î97Î\Ú3ØöÎ Ö Î\Ú Õ Ô  ÕÖåx³ ÜÎ Ö ÑÓ:TÎ\Ú6×æ Î87Î Ö ÚÎ*Ô Õ³ Ò;7Î*Ô+ØºÓ Õ ÔÔ
Ù Ô ÕÖ ºaÐ ÕÖ TÎ<7Î\Ú3Ø Ü Ò+ö²Ü  ûÜÒÐXÜ Ó Õ>= Î*º? Ö å Ò Ö öÃÙ Ô ÕÖ º ÕÖåå Î ³ Î\ÚÓjÒ Ö Ò Ö ö ³ ÜÎyÒ Ö Î%ÏÒº ³ Î Ö Ð%Î×æ
Ù Ô ÕÖ º å Ò@xÐ\ÑÔ ³\ùAÕÖ ØÐ%× Öå Ò ³ Ò+× ÖÕ Ô Ù Ô ÕÖÖ Ò Ö öÙÚ3×B ÔÎ*ÓjºÜ Õ 7Îº3×²ÔÑ ³ Ò+× Ö º Õ ºbÓj×Ú3ÎÚÎ*º ³ ÚÒÐ ³ Î å ÕÖå
Ð%×²ÓÙ Ñ ³3Õ³ Ò+× ÖÕ ÔÔ+ØxÔ+Î*º3ºÎ%ÏdÙTÎ Ö º3Ò;7Îµæ:×ÚÓjº6×æçÙ Ô ÕÖ º ù
ú ÜÎµÙ Ô ÕÖ º å Òuº3Ð\Ñº3º-Î å Ò Öa³ ÜÒºº-Î*Ð ³ Ò× Ö Ü Õ 7Î ÕÖ Ò Ö³ Î\Ú ÖÕ Ô º ³3Õ³ ÎÔÒ = Î ³ ÜÎlÙ Ô ÕÖ º6×æ ³ ÜÎµÙÚ3Î87dÒ+×²Ñº
³
º-Î*Ð Ò+× Ö  ÕÖå Î Õ ÐXÜ º ³3Õ³ ÎÒuº Õ º3º-×dÐ\Ò Õ³ Î å ûÒ ³ Ü Õ º-Î ³ ×æe×ÙTÎ\Ú Õ³ ×ÚXºµÎ ÖÕ Ô+Î å Ò Öh³ ÜÎjº ³3Õ³ Î  Ñ ³c³ ÜÎ
º ³3Õ³ Î ³ Ú ÕÖ º3Ò ³ Ò+× Ö º Õ Ú3ÎÓ×Ú3ÎÚ3Î*º ³ ÚXÒÐ ³ Î å[ùlú ÜÎÙ Ô ÕÖ º ³3Õ Ø/ºµÒ Ö³ ÜÎº Õ ÓÎº ³3Õ³ Î Õ ºµÔ+× Ö ö Õ ºµº-×²ÓjÎ×æ
³ ÜÎ×ÙTÎ\Ú Õ³ ×Úº1Î ÖÕ ÔÎ å Ò Ö Ò ³1Õ Ú3Î Õ ÙÙ ÔÒuÐ Õ Ô+Î ¹³ Ü Õ³ Òº  Õ ºcÔ+× Ö ö Õ º ³ ÜÎ\Ú3ÎÒº ÕÖ Î Ö Õ Ô+Î å ×ÙTÎ\Ú Õ³ ×Ú
³ ÜÎÙÚ3Î*Ð%× Öå Ò ³ Ò+× Ö ºb×æRûÜÒuÐÜ Õ Ú3Î ³ ÚÑÎ ÕÖå º3×²ÓÎ×æ ³ ÜÎÙT×²º ³ Ð%× Öå Ò ³ Ò× Ö º Õ Ú3Îæ Õ Ôº-Î ù9C ÜÎ Ö ³ ÜÎ\Ú3Î
Õ Ú3Î Ö ×jº3ÑÐÜW×ÙÎ\Ú Õ³ ×Úº  ÕÖ Ñ Ö Ð%× Öå Ò ³ Ò× ÖÕ Ô ³ Ú ÕÖ º3Ò ³ Ò× ÖQ³ × Õ Ñ Ö ÒuÿÑÎcº3ÑÐ\Ð%Î*ºº-×Úbº ³3Õ³ ÎÒºÓ Õå Î ù
 × ³eÕ ÔÔÙÚ3×B Ô+Î*Ó¸Ò Ö º ³3ÕÖ Ð%Î*º ³ Ü Õ³ Ü Õ 7Î Õ º3×²ÔÑ ³ Ò+× ÖÕ º Õ Ù Ô ÕÖ ×æ ³ ÜÎæ¡×ÚXÓ å Òº3Ð\Ñ º3º-Î å Ò ÖED Î*Ð ³ Ò+× Ö

ù ÷ ù» Ü Õ 7Î Õ º-×²ÔÑ ³ Ò+× ÖQÕ º Õ Ù Ô ÕÖ ×æ ³ ÜÎlæ:×ÚÓ å Òuº3Ð\Ñº3º-Î å Ò ÖQ³ Ü Òºº-Î*Ð ³ Ò+× Özù
FHGI,JLKNMPORQ%SUTWV × Ö º3Ò å Î\Ú ³ ÜÎlæ:×²ÔÔ+×oûÒ Ö ö×ÙTÎ\Ú Õ³ ×Úº ù
·´ ËHXZY8[]\_^>`0[baZcdcdc*É9egfihRËHXZY8[]\_^>`0[baZcdcdc*É9ekjXËHXZYl[nmpo,[rqtsdXBuvX
»µ´ ËHXZY8[]\_^>`0[baZcdcdc*É9egfihRËHXZY8[]\_^>`0[baZcdcdc*É9ekjXËHXZYl[nmpo,[rwx^>y0mp`
÷ ´{z X{X{|>[nmPo&[rqtsdXBuvXZjXËHXZYl[nmPo&[rqtsdXBuvXdjXËHXZYl[	\_^}`[~^É9efhRËHXZY8[]\_^>`0[b~^É9e/j0hRËHXZYl[	\Zody0s
´{z X{X{|>[nmPo&[rwx^>ym`ljXËHXZYl[nmpo,[rwx^>y0mp`0jXËHXZY8[]\^}`0[b~^É9efhRËHXZYl[	\_^}`[~^É9e<j0hRËHXZYl[	\ZoBys
 Ö Ò ³ Ò Õ ÔÔØÎ%Ï Õ Ð ³ Ô+ØÃ× Ö Îa×æ ³ ÜÎQæ Õ Ð ³ º z XX{|>[nmpo&[vqtsdXBuvX ÕÖå/z X{X|>[	mPo&[vw^>ymp` Òuº ³ ÚXÑÎ  Õ ÔÔ6×æ ³ ÜÎaæ Õ Ð ³ º
ËHXZYl[	\_^}`[acdcdc*É9ekjXËXYl[	\_^}`0[b~^É9e ÕÖå ËHXZYl[	\ZoBys Õ Ú3Î ³ ÚÑÎ  ÕÖå`³ ÜÎÚ3Î*º ³ ×æ ³ ÜÎæ Õ Ð ³ º Õ Ú3Î
æ Õ Ôº-Î ùRú ÜÎµö× Õ Ô)Òº hRËHXZY8[]\_o_Bys ù
C Ò ³ ÜhÙ Ô ÕÖ ºb×æ ³ ÜÎæ:×ÚÓ å ÒºÐ\Ñº3º-Î å Ò ÖkD Î*Ð ³ Ò+× Ök
ù ÷ ù»³ ÜÎö× Õ ÔRÐ ÕÖ TÎ Õ ÐÜ Ò+Î87Î å Õ ºµæ:×²ÔÔ+×oûº ù
 Ö Ò ³ Ò Õ ÔÔØ Õx³ Ú ÕÖ ºÒ ³ Ò+× Ö³ ×x× Ö Î×æ ³ ÜÎÒ Ö³ Î\Ú Ö Õ Ô)º ³3Õ³ Î*ºl÷ ÕÖå< ÒºcÓ Õå Î  å Î\ÙTÎ Öå Ò Ö öj× Ö ûÜÒÐXÜ×æ


x;&d
6&%p"P%/&,ZP%Z<%&&&% 
¡r¢_£U¤¥¦x§P¨ ©ª
¡b¡¬«r­¥	©®/¯8¯8¯}®k¡¬«U°¥	©±®?²¡b¡¬«P³­ ¥	©®/¯8¯8¯>®<¡¬«P°}³ ´ ¥	©	¥®µ¡b¡¬¶x§P¨­·®?¸­b¨ ©¬¹­¥º/¯8¯8¯}ºk¡¬¶§P¨ »¼½®¾¸»¼¿¨ ©¬¹­0¥b¥b¥
ÀPÁBÂxÃBÄUÄ±ÅÇÆ<ÈÉÊ £8£8£ ÊbÅÌËÍpÎ±Ï ¤}Ð ÊbÑÇÆRÒ{ÓÕÔ&Öx×Ø8ÂÌØHÙ"ÚbÛ¿Ü ¡ Ñ ¥ÞÝ È « ­ Ê £8£8£ Ê « ° Ð ÊnÙß}àávÜ ¡ Ñ ¥ÞÝ È «P³­ Ê £8£8£ Ê «P°³ ´ Ð
â  N 8p"¬ãä {å±  L Z&"
¡ræ_£U¤¥¸"§P¨ ©®¾²·¦:­b¨ ©ç­%®µ¯8¯8¯}®¾²·¦9»±èl¨ ©ç­éê¸"§Uç­b¨ ©ç­ ÀPÁBÂxÃBÄUÄÑÞÆRÒ{î±ÔÅÇÆ<ÈÉÊ £8£8£ ÊbÅ ËÍpÎ Ï ¤}Ð
¡ræ_£ìëd¥¸"§P¨ ©®<¡¬¦í­b¨ ©ç­Nºµ¯8¯8¯}º¦9» è ¨ ©ç­0¥Béê¸"§P¨ ©ç­
ï  "ðã Z&"
¡¤ É £U¤¥H¸­b¨ ñ
òtPó%å&%  %µå&L {&"
¡¤B¤>£U¤¥H¸"§P¨ ©éê²ô¸õ¿¨ © ÀPÁBÂxÃBÄUÄ±ÅÇÆ<ÈÉÊ £8£8£ ÊbÅ ËÍpÎ Ð ÊlÈ{ÑÌÊ]ö Ð÷ Ò{î?ø¿ù&ú¿×?ûÌ×,Ã>ûÑxÝ ü ö
ý & &P&"P%ä%<&,&±%% 
¡¤{ë_£U¤¥t¡¬¶ §P¨ þ ®R¸ þb¨ © ®µ¡¬« ­ ¥ © ®ÿ¯8¯8¯>®µ¡¬« ° ¥ © ®¾²¡b¡¬«p³­ ¥ © ®/¯8¯8¯}®k¡¬«p°}³ ´ ¥ © ¥b¥Bé §P¨ ©
¡¤{ë_£ìëd¥t¡b¡¬« ³­ ¥	©®/¯8¯8¯>®<¡¬« °}³ ´ ¥	©	¥Béê² §P¨ ©
¡¤{ë_£ d¥t¡b¡v²·¶ §P¨ þ  º?²ô¸ þ n¨ © ¥®µ¯8¯8¯}®<¡v²·¶ §p¨ » ¼Nº¾²ô¸ » ¼ ¨ © ¥b¥Béê² §P¨ ©
ÀPÁBÂxÃBÄUÄ±ÅÇÆ<ÈÉÊ £8£8£ ÊbÅ ËÍpÎ Ï ¤}Ð ÊbÑÇÆRÒ Ó Ã 
	:ÆRÒ{î±Ô&Ã
	?Ö×Ø8ÂÌØHÙÚÌÛÌÜ ¡ Ñ ¥ôÝ È «v­ Ê £8£8£ Ê «°,Ð
Ã 
	 Ùß}àávÜ ¡ Ñ ¥ôÝ È «P³­ Ê £8£8£ Ê «P°³ ´ Ð
 ùÂÌØ  &úlÁ 	    ÁBÀ·úlÁ 
	  û  Á &ÃBÄ ,ÄUÃ &øÃBøxøbØ ù&Ø &úlØ{øÁBÀ  ûbØ8Â¿Ã>ûbØ 	RÁ "Ø8Â0Ã>ûbÁBÂ¿ø

8ß{ß!#"$&%('dßBávßÃ
	lß{ß)*+"
-,/.>Ú0pà  øíûbÂ¿ù&Ø1324*øÌûÌÃ>ûbØ ë ûÌ×&Ø Á±Ø8Â¿Ã>ûbÁBÂ¿ø6É¾Ã
	 ë Ã>ÂÌØEØ&Ã5,Ä;Ø	Ô  
øbûÌÃ>ûbØ  ûÌ×Ø Á± Ø8Â¿Ã>ûbÁBÂ¿ø ¤ Ã$	  176859  Ádù&øÌÄ:BÔ_ûÌ×Ø  ÁdÃBÄ  øÃBú¿×  Ø;9BØ	  ?ÃBÄUÄ±Ø=<Ø{ú8ùû  Á&øÁBÀNûÌ×&Ø>,ÄUÃ?1
 ÁBÂûÌ×ØRÀpÁBÂA@ ÁBÀB, ÄUÃ& øC	  øÌú8ù,øÌøbØ	  ûÌ×  ø øbØ{úlû  ÁûÌ×Ø8Â¿Ø  øCÁ*øbÁdÄUù&û  ÁäûbÁ ûÌ×  øD&Â¿Á5,Ä;Ø@E1
24  û  ÃBÄUÄF: ûÌ×ØtÁ" Ø8Â0Ã>ûbÁBÂ¿ø9É Ã
	 ¤ Ã>ÂÌØÃ
, Ä  ú8Ã,5 Ä;Ø1/6B& Ä: Á ØtÁBÀ½ûÌ×Ø{øbØ6Á± Ø8Â¿Ã>ûbÁBÂ¿øHú8ÃG5±ØíØ,Ã5,Ä;Ø	
±5 Ø{ú8ÃBù&øbØµù

	 Ø8ÂEûÌ×ØµøbûÌÃ
&	 Ã>ÂA	H ÁBû  Á4
 ÁBÀI	 Ø;± Ø
&	 Ø& ú=: ûÌ×Ø;: Ã>ÂÌØJ	 Ø;± Ø
	 Ø û8ÔÃ
	 ×Ø&úlØ/ûÌ×Ø  Â
Ø=< Ø{ú8ùû  Á  K, Ã>Â¿ÃBÄUÄ;Ø{Ä  øL ÁBû½ÖÇØ{ÄUÄNMO	 Ø=PQ& Ø	?1SHR øÌøÌù$@ ØÁ± Ø8Â¿Ã>ûbÁBÂÕÉ  ø·Ø& Ã,5 Ä;Ø	 Ã$-	 Á± Ø8Â¿Ã>ûbÁBÂ ¤  øL ÁBû
¡ ûÌ×ØÁBûÌ×Ø8Âôú8ÃBøÌØ  ø·øT:@U@ Ø8ûbÂ  ú ¥ ÔdÃ$	 ûÌ×Ø8ÂÌØ8ÀPÁBÂÌØÁ± Ø8Â¿Ã>ûbÁBÂôÉ  ø½Ã
, Ä  Ø	VP Â¿øbû;1xW ÁÖ  À8 ß{ß!+"
&%(d' ßBávß
X
 ø À¬ÃBÄUøbØíÃ
	Ul ß{ß)*+"
-,/>. Ú0pà  ø ûbÂ¿ùØBÔ&ûÌ×Ø  ÁdÃBÄú8Ã
 ÁBû/±5 ØíÃBú0×  Ø;B9 Ø	?1
 ÁBÂYt@ ù&ÄÃ>Ø<ûÌ×&Ã>û¾Ø& úlÁ	 ØJ, ÄUÃ& øÃ>ÂÌØ  B9 Ø    ùÂÌØ  1ZR ù[<  Ä  Ã>Â:\>9 Ã>Â  Ã,5 Ä;Ø{ø ¦§P¨ © &	 Ø=PQ Ø	
  øÌú0×Ø@ Ã ¢ 1 ¤ Ø=<& ÂÌØ{øÌø6ûÌ×&Ã>û-ûÌ×&ØE& ÂÌØ{úlÁ
	  û  Á& øtÁBÀHÃ Ø& Ã5 Ä;Ø	 Á" Ø8Â0Ã>ûbÁBÂ ÑíÃ>ÂÌØ?ûbÂ¿ùØ?Ã>û-ÅÃ
	
øbÁ@ Ø ÁBÀ  ûÌø>± ÁdøbûÌúlÁ
	  û  Á& ø Ã>ÂÌØ À¬ÃBÄUøbØ1]	2 À ¦§p¨ ©  ø ÀPÃBÄøbØ-ÀpÁBÂ6ÃBÄUÄ·Á± Ø8Â¿Ã>ûbÁBÂ¿ø:ÑÌÔûÌ×&Øk ÃBÄUÄôÃ
 Ä  ú8Ã,5 Ä;Ø
Á± Ø8Â¿Ã>ûbÁBÂ¿øH×&ÃB9 ØK±5 Ø8ØR
 Ã$, Ä  Ø¾	 Ã$R	 ÃEûbÂ¿Ã& ø  û  Á¾ ûbÁ ûÌ×&Ø^ Ø=< ûøÌûÌÃ>ûbØ  ø8@ Ã	 Ø^ Ø=< û ¡ øÌú0×Ø@ Ã æ 1 ¤¥ Ô
Ã

	 ÁBûÌ×Ø8ÂÌÖ  øÌØ?Ø=_< Ø{ú8ùû  Á4 úlÁ û  _ ùØ{ø  ã ûÌ×ØÿøÌÃ@ ØRøbûÌÃ>ûbØ ¡ øÌú¿×Ø@ Ã æ 1 ë 1 ¥  ÁBÂA6@ ù&ÄUÃ ¤ É1 ¤ øÌûÌÃ>ûbØ{ø
ûÌ×&Ã>ûíûÌ×&ØU, ÄUÃµ
 Ø=< Ø{ú8ùû  ÁL øbûÌÃ>ÂÌûÌø  k øbûÌÃ>ûbØ ¤ Ã>ûíû  -@ Ø ÉÔNÃ
*	 ø¿ú¿×Ø@ Ã ¤B¤ 1 ¤ øbûÌÃ>ûbØ{øtûÌ×&Ã>ûíûÌ×Ø], ÄUÃ
ú8Ã
 ÁBû_±5 Ø9ø  6@ ù&Ä;ûÌÃ Ø8Ádù,øÌÄ:   û]ÖÇÁU	 N` Ø8ÂÌØ ûøbûÌÃ>ûbØ{ø;1R8
 Á± Ø8Â¿Ã>ûbÁBÂ  ø Ã
, Ä  Ø	 Öx×&Ø  û  øÕØ, Ã,5 Ä;Ø	
a)a)b

c7dQe$fAg[hji$kjg[le$mnkdQe
o$lNg[lFdQe[p$qKrqsp$e$f
tFuwvx[y{z;|
}}yujv3~TvvTy8tv~C
}yz=u

tFvtu
~]}AyGvT}A|
yGu
H~TDy{Itv~C~Tvz=u

tvtFu
~]}y{F~Ty
 ~zYx[yUF!vx
y~TyUz=u

tvtFu
~B}yUu[v>|
NQFFy?Qvx
yDy;}YvT}ItF~Bu[vV
$ty  ~zAx[y]v
Vu$K8u]|[
y;}|
u
K+}Lvx[y~At;y/vx[y/+}A(|$Fy/tFuUt|[}Ay>tF~0s 4¡ -¢ !£K¤¥¦[§#¨)©
£^ª0£K¤T¥¦[§#¨)©nQ©  £G¤/« ¬ £K¤A*¥¦§#¨©{0s 4¡ -¢ !£K¤¥¦[§#¨)©{0s 4¡ -¢ *¥¦[§#¨s©E£^ª=£^¤T¥T¦[§#¨?­x$tFzAxUt~}Y[y;}
£ ¤ « ¥¦§#¨Q©®£(ª0£K¤T¥¦§#¨$©HYF) T¡ -¢ !£^¤¥T¦[§#¨4¯
°8±³²$´¶µS·+¸º¹¼»¹ [}(vx[yD$z½~>­7}AFJvx[y]yu
z=$tFu[EtF~V~>+Fs­~>+}V¥V¾H¿)ÀÁÃÂÄzAx[y]ºÅF
Æ tyF
~vx[y>+Fs­tFu[K+}A^|
Fy>vx
vtu

tFz;vTyB­x[yuy;}YvT}A~/}yI$$FtFz;$Fy
ÇÉÈ0Ê ËÍÌ   ÎÏ8Ð ËQÑÒ;Ó ÔÕÏ ËQÑºÖ   Î$×-ÔÙØ Ó YÏ ËQÑEÖ  ÎÏ8Ð ËQÑnÒ;Ó ÔÕÐ Ë 
Ñ TÚ È0ÊÜÛ ÑºÝ ÛTÊ ËÞ?Û ³ß Ú È0Ê « ÑºÝ « Ê ËÞ?Û TT
Ç ÛTÊ Ë Ì   ÎÐÏ Ë ÑÒ;Ó ÔÕÐ Ë ÑÖ   ÎQ×-ÔÙØ Ó AÐ Ë ÑÖ  ÎÐÏ Ë ÑnÒÓ AÔÕÏ Ë 
Ñ TÚ ÛTÊÜÛ ÑºÝ ÛTÊ ËÞ?Û ³ß Ú ÛTÊ « ÑºÝ « Ê ËÞ?Û TT
Ç « Ê Ë Ì   Î$×-ÔÙØ Ó YÏ Ë ÑJÒÓ AÔÕÐ Ë ÑÖ   ÎÏ8Ð Ë ÑÖ_ÒÓ AÔÕTÐ Ë ÑÖ  Î$×-ÔÙØ Ó YÏ Ë 
Ñ TÚ ÊÜÛSÑºÝÍÛTÊ ËÞ?Û ³ß Ú Ê ÑºÝ Ê ËÞ?Û TT
ÇÉà Ê Ë Ì   Î$×-ÔÙØ Ó YÐ Ë ÑnÒ;Ó ÔÕÏ Ë ÑÖ «  ÎÐÏ Ë ÑÖ_ÒÓ AÔÕTÏ « Ë « ÑÖ  « Î$×-ÔÙØ Ó AÐ Ë 
Ñ TÚ à ÊÜÛSÑºÝÍÛTÊ ËÞ?Û ³ß Ú à Ê « ÑºÝ « Ê ËÞ?Û TT
!u[áy;}AvT}VtF~>
QFtFz;$yávT}Au
~AtvtuGvTEvx[yU~|
z;z=y~~}V~TvvTy]tF~BU[y  ~zYx[yUºâF)YSu

vx[y;}­ÉtF~Ty>vx[yV~TvvTy^~Tv Æ ~/vx
yI~Dy  ~AzAx[yUCâ
Ý ÛTÊ Ë ÑEÖÇ È0Ê ËãÍÛ ÑÖÇ ÛTÊ ËãÍÛ ÑEÖÇ « Ê ËãÍÛ ÑÖÇ8à Ê ËãÍÛjä Ý « Ê ËãÍÛ
ÝÍÛTÊ ËQÑ  Ç8È0Ê ËãÍÛ ß ÇIÛTÊ ËãÍÛ ß Ç « Ê ËãÍÛ ß Ç à Ê ËãÍÛ  ä ÝSÛTÊ ËãÍÛ
Ý « Ê Ë Ñ  Ç È0Ê ËãÍÛ ß Ç ÛTÊ ËãÍÛ ß Ç « Ê ËãÍÛ ß ÇÉà Ê ËãÍÛ  ä Ý « Ê ËãÍÛ
ÄzYx[yUvº;ÀF(u
nF Æ tyFávx
y>#FF)­tFu
^+}A^|
Fy
Ý ÛTÊ È
ÝÍÛTÊ Ë ä ÖLÝ « Ê ËåÝ « Ê Ë ä ÖLÝÍÛTÊ Ë
ÄzYx[yU{F tyF
~
#}BFSæK¾ç¿ÙÁAjÂ?vx
yI+F)­ÉtFu[U+}A^|
FyIvx$vÉ[y~z=}YtyV­x[yuºy;}YvT}A~
}yI$$Fty? Æ
Ú È0Ê ¤ ÑEÝ ¤ Ê Ë Ñ  ÎÏ8Ð Ë ÑnÒ;Ó ÔÕTÏ Ë ÑÖ   ÎQ×-ÔÙØ Ó AÏ Ë ÑEÖ  ÎÏÉÐ Ë ÑnÒÓ AÔÕTÐ Ë T ä ¢ È0Ê Ë
Ú ÛTÊ ¤ ÑEÝ ¤ Ê Ë$Ñ  ÎÐÏ ËQÑnÒ;Ó ÔÕTÐ ËQÑÖ   Î$×-ÔÙØ Ó YÐ Ë
ÑºÖ  ÎÐÏ ËQÑnÒ;Ó ÔÕÏ Ë T ä ¢ ÛTÊ Ë
Ú « Ê ¤ ÑEÝ ¤ Ê Ë Ñ  Î$×-ÔjØ Ó AÏ Ë ÑJÒ;Ó ÔÕÐ Ë ÑÖ   ÎÏÉÐ Ë ÑÖ/Ò;Ó ÔÕÐ Ë ÑÖ  Î$×-ÔjØ Ó AÏ Ë T ä ¢ « Ê Ë
Ú à Ê ¤ ÑEÝ ¤ Ê Ë Ñ  Î$×-ÔjØ Ó AÐ Ë ÑnÒÓ AÔÕTÏ Ë ÑÖ   ÎÐÏ Ë ÑÖ/Ò;Ó ÔÕÏ Ë ÑºÖ  Î$×-ÔÙØ Ó YÐ Ë T ä ¢ à Ê Ë
8u
3Qu
F Æ ~zYx[yUvº]u
nU~A Æ ­x[yuEy;}AvT}Y~/}yIu[vÉ
$Fty³
  Î$×-ÔÙØ Ó AÏ Ë ÑÖ  ÎÏÉÐ Ë ÑnÒÓ AÔÕÐ Ë  ä Ö ¢ È0Ê Ë T Ö Ú È0ÊÜÛ ß ÖLÝ ÛTÊ Ë  Ñ  Ö Ú È0Ê « ß ÖLÝ « Ê Ë T ä Ö ¢ È0Ê Ë
  Î$×-ÔÙØ Ó AÐ Ë ÑºÖ  ÎÐÏ Ë ÑÒ;Ó ÔÕÏ Ë  ä Ö ¢ ÛTÊ Ë T Ö Ú ÛTÊÜÛ ß ÖLÝ ÛTÊ Ë  Ñ  Ö Ú ÛTÊ « ß ÖLÝ « Ê Ë T ä Ö ¢ ÛTÊ Ë
  ÎÏÉÐ ËQÑÖ/Ò;Ó ÔÕÐ ËQÑÖ  Î$×-ÔjØ Ó AÏ Ë  ä Ö ¢ « Ê Ë T Ö Ú « ÊÜÛ ß ÖLÝSÛTÊ Ë  Ñ  Ö Ú « Ê « ß ÖLÝ « Ê Ë T ä Ö ¢ « Ê Ë
  ÎÐÏ Ë ÑÖ/Ò;Ó ÔÕÏ Ë ÑºÖ  Î$×-ÔÙØ Ó YÐ Ë  ä Ö ¢ à Ê Ë T Ö Ú à ÊÜÛ ß ÖLÝ ÛTÊ Ë  Ñ  Ö Ú à Ê « ß ÖLÝ « Ê Ë T ä Ö ¢ à Ê Ë
è
é x
y3êF|
vtFu¶Évx[yá
}~tvtFu
Lê}AtF$Fy~ Úë Ê ¤D[y;vTy;}AUtu[y~(nz=u$
tvtu
$Fu³ é x[y

}z=y
|[}AyBtuEStF|[}y>ìUy=íyz;|[vTy~Évx[yVtFD$tFz;tv Æ }y;$}y~TyujvTyE$Fu?
î)îÃï

ðñò[ósôQò
õò
ö>÷øúùû
ýû
ü ÿ ÷øþ
	


 "! ö ($ü #&%'!)( $ö *,+ "-.!
ü/(10 * (&(2-,34"5 *ö -,5Yü76ü$!8/9 ö 9 *ö;:=<?>A@CB DFELøHGI*,+)J
ö 9385$ - +)J # ö #&- + ü -,K-,34"5 *ö -,56 * 5$ ö 5L! *,+)J
ü -.%M-,K ö 9)3=-ü ö - +)J # ö #1- + ü * 5$NK * (Fü û
O ö 9)"5$P#Fü + -Q-,3="5 *ö -,5A6$ü !8/9 ö 9 *ö;:=<?>A@CB DFELøHG
*,+)J 385$ - +)J # ö #&- + ü -,K6 * 5$ ö 5/!) *,+)J ü-.%R-,K ö 934-ü ö - +8J # ö #1- + ü
S  ÷ø ýû
ö>÷ø ö T ü ýû Fü T
U

* 5/NK * (ü

V #&W.!5$YX ÷Z $5 - J !5$YK-,5; "! ö # + W * 38( *,+

ö>÷øúùû
ÿ	


 "! ö ($ü #&%'!)( $ö *,+ "-.!
ü/(10 * (&(2-,34"5 *ö -,5Yü76ü$!8/9 ö 9 *ö;:=<?> @CB [ ELø\G
*,+)Jáö
+)J ö +
*ö * ö û
ö>÷ø ö T 9)Nýû 3)5$ - # #1- ü]-,K^-,34"5 -,5A6 5/ 5/!
U

V #&W.!5$N_ ÷Z $5 - J !5$YK-,5; "! ö # + W * 38( *,+

`2acbda1egf7hjilkmnimQo=pdqlrsp)ktdpdmnulvwodp8x2mRusvzyn{)p)|2i)x2us|sm
} 0, ö ü$#c%R38(1"5lKC-,5/%~-,K)38( *,+ ü# J  Ù+ ö #18 ü ö 97# j+ ö "5 +)* ( ü ö$* ö -,K * 38( *,+ # ö 9 ö 9"!5$5$ +jöSö #&%R]3=-.# +Ùö"
-,5 !)#1 * (1 Ù+ ö (&0 .* ö  * /9 ö #&%M]34-.# j+ öSö 9738( *,+ % *  ü *,+ ! + - +)J # ö #&- +)* ( ö 5 *,+ ü$# ö #1- +^ö - * ü$!)"üAü-,5
ü ö$* * ö ,*] ö * 
!* öü$ ö 9# j+ öÙ+ "ö 5 +)j+ * ö L( ü ö$+)* * ö ö$-.* ö# + "# J  ü  *,# + ö 9 ö *,#&+)%R¶J  S ö ö 9"5$+ #Fü J + + - + " J * KC-,ö 5(ü$"3 * * 5 *ö áü ö$*ö  
 5/# (1 ü 9 5$"3)5$ ü$ # "5 7( ü  ün-,KA38( ü
9 - # W#üP3 5 #&"!)( 5/(&0Jü/#&%R38(1
+
ö
+
+
*
+
- ü$# ü # Wn-,K^- V ü$L9 % - (10,
4< ý F ýE;;@CB [<?>;@B [8<?FE[d""<?cE[d7<<?C E[d""<?C   E[EE
KC-,5 * (&(,6¡¢ £ *,+)J  ¡¤ ù¦¥"""§¥ $¨ ý© 9"5/^ªd«$¬$­ < 6 LE ø ¤  ¥"""¥$&8©]*,+)J ª¦®¯F°­ < 6 E ø ¤   ¥""" ¥$    © 
± 9D ü$#&²"'-,K ö 9D ü ö -,KKC-,5/%'!)( * nKC5$-.% ü$/9 % n
* ý   ý F# üU-,K-,5 J "5n¯L³&´¬$®µ <E    ± 9'3)5$-¦ J !5$
+# V #1W.!5/P_n "! ö  ü ö 9N3d( *,+ 5$"3)5$ ü$ Ù+ ö  J¶ 0 ö 9 ö 5/! ö 9· * (&!) ü-,K ö 9) * 5/# * (1 ü >;@B [ 
¸U¹lº8»½¼¿¾CÀÁsÂcÃ V -,5 ö 9  (1-¦  ü  -,5/( J  * %R38(1 ö 9)NK-,5L%!)( *  * 5$ * ü7KC-.(&(1-  ü7KC-,5  ¡z¤ ù¦¥ ý© 
ÄFB [Å<?>;ÄFB [= ®,ÆÇ  [d ­ È1¬/É«$Ç [d¶A< ®Æ8°ÉËÊ"È1¬LÇ [d ®ÆÇ  [d ­"È&¬$É«  [EE
NB [Å<?>B [= ®,Æ  Ç [d ­ È1¬/É«  [dÌ7< ®Æ8°ÉjÊÈ&¬  [d¶ ®Æ  Ç [d ­ È1¬/É«Ç [EE
ÍFB [Å<?>;ÍFB [= ®,Æ8°ÉËÊÈ&¬/Ç [d ­ È1¬/É«  [d¶7< ®ÆÇ  [dÌ ­"È&¬$É,«  [d¶ ®,Æ8°ÉËÊÈ&¬/Ç [ÎEE
ÏFB [Å<?>;ÏFB [= ®,Æ8°ÉËÊÈ&¬  [d ­"È&¬$É«$Ç [d¶7< ®Æ  Ç [dÌ ­"È&¬$É,«Ç [dÌ ®Æd°ÉËÊÈ&¬  [ÎEE
Ð
ÑÑÒ

Ó]ÔdÕ8Ö/×ØjÙ8Új×Û1Õ8ÜÚ¦ÔdÕ)Ý8ÛÞ×Û&ÔdÕß8àná.à§ß8Õ8Ö
âlã&äæåQçè8é=ê§ëì¿íËèê§ëCîdéîjï=ðjñòî=é=ê§ë?ésódðéíËëCðô
õ~ö÷.ø)ù)ú1û$ú1÷.ø8ü,ýdþdý&ü,ø¶ùÿ"ûÿ Múcøÿ 	
÷ ü,ý&ý2ö÷ dú&ø)üû$ú1÷.ø÷
¿ûûü,ý)ÿ÷
Aþ$÷,þ4÷$ú1û$ú1÷.ø)ü,ýü/ú
ü8ý1ÿ ]û )üû $ÿ"þ /ÿÿ øËûû ÿYú&ø)ú&û$ú&ü,ý û$üûÿ 7ü,ø8ù÷,û )ÿ ö÷.øjû$ú&ø ,ÿ ø8ö"ú1ÿ Mü,ø!ÿ ¦ÿ ö û$ú1÷.øû )üû $ÿ ü,"ö ÿ Aü
,÷.ü,#
ý û$üû
ÿ $%&)'ú ú ($ÿ"þ /ÿÿ øËûÿ ù
ü  û ))ÿ ÿ *+ÿ ø)öÿA
÷ ,*+)ü,øjû$ú -8ÿ .0/21435.06879ÿ /ÿAû &ÿ -:û *+)ü,0ø 
û$ú -8ÿ ];÷ ,ÿ ;þ8ý&ü,ø $ÿ"þ $ÿÿ øjûÿ <
ù >=û ?ÿ ü Lú&ü 8ý1ÿ ú&øû @ÿ ÿ"Aû /CBû Dÿ ÿ ö÷.ø8ùE÷ ,ÿ ü,ýcý=ö÷.øjû$ú&ø ,ÿ ø8ö"ú1ÿ 
3FBü,ø)ùRû ÿû )Gú /ùn;
÷ ,ÿ ÿ!ÿ ö û$ú&÷.ø 6	$:H=nû ÿ;û û 0Îù!ÿ -=ø)ú1û$ú1÷.øn
÷ 4*+)ü,øËû$Gú -8ÿ Iù H]÷j÷.ý&ÿ ü,	ø C
÷ J)ý&ü
ÿ B
C

÷ ÿ ü,"ö þdý&ü,K
ø / ü,ý&ýû û 0ü,ý ÿP
ü $Gú .ø Rÿ øjû ûL÷ ü /ú&ü 8ý&ÿ ;ú&M
ø 3NJ)û =ÿþ4÷ $Gú 8ý&
ÿ $Oÿ ø)öÿ'û ÿ

ü /ú&ü 8ý1ÿ ú&P
ø 3QJ2û 4ÿPý1
÷ .ú&ö"ü,ý&ý =Ìú&ø)ùÿ"þ4ÿ ø)ùÿ øjû $R P
ø Mü,>ø =ö"
ü ÿ B4;÷ 7ÿ ,ÿ EB2û ÿPû )û 0ü,'ý ÿ ;
÷ 
ö÷.øjû$ú&ø ,ÿ øj2û ?ü,öû Yü $ÿnùÿ"þ4ÿ ø)ùÿ øjû;÷.øÿ ü,ö  ÷,û ÿ E$2S
÷ Yÿ!ü
Rþ8ý1ÿnú&øû 5ÿ dý1÷ö T+)7]
÷ /ý&4ù B4Gú (Ugú ÷.ø
û 4ÿP÷.M
ø U$D%L÷ T,ÿ"ÿ"þû )5ÿ ü /ú&ü 8ý&ÿ ;ú&W
ø 3 ý1
÷ .ú&ö"ü,ý&Gý =Ìúcø)ùÿ"þ4ÿ ø)ùÿ øjû B7]ÿÿ ú&û ÿ Uö"ü,ø8ø÷,û
V B V ö"ü,ø)ø÷,2
*+)ü,øËû$ú X=E
÷ ,ÿ AûÿNö÷.øjû$ú&ø ,ÿ øjAû ?ü,öû Aù)Gú $ÿ öû$ý =M
÷ A7@ÿ 8ü ,ÿNû÷Mö"ý&
ü $Gú Y=Q
ü $Gú .ø Rÿ øËû ûL÷ 3 û÷Rû )÷ ÿ
û)üLû $ÿ"þ $ÿÿ øjûQü,ý&ý&E÷ 7]ÿ ù ö÷ dú&ø)üû$ú1÷.ø M
÷ û û 0ü,ý ÿ Rü,ø)ùû÷wû ÷ $ÿÌû )üûù)÷zø÷,û B7ü,ø)ù ÷.ø)ý =
$ÿ*+)Gú $ÿû )ÿP!ÿ úûÿ ø)öÿ
÷ !ÿ ÿ ö û$ú&÷.ø ý&ÿ ü,ù)ú&ø Mû÷Iü ,÷.ü,Zý û$üûJÿ 
÷ Uûÿ C
÷ Rÿ E$[ÿnù)ú /ö A4÷,û 
÷
^û ÿ ÿNü,ý1ûÿ Lø)üû$Gú ,ÿ &4ÿ ý1;÷ 7@$
û ]?_<4ÿ¶û `
ÿ 
÷ "5)ýcW
ü 
÷ ûÿú&ø8ú1û$ú&ü,Aý û$üûP
ÿ 7;ú1û  ü,ýcý7þ $÷,þ4÷ $ú1û$ú&÷.ø C/!ö /ú1þ)ûÿ a
ù 7;ú&û cb0B
\ ÿ"^

g
X
h
i
ü,ø)e
ù d,fXghXiI$ú Qú&ý&ü /ýG=wû K
ÿ C
÷ J)ý&W
ü C
÷ Qû`
ÿ ,÷.ü,)ý $!ö /ú&þ)ûÿ a
ù 7;ú1û kj $ \ ÿ"<
û lm4ÿn
ü C
÷ J)ý&ü
$ÿ"þ /ÿÿ øËû$úcø Rþ8ý&ü,ø 7ü,ø8ù!ÿ ÿ ö û$ú&÷.ø ;
ü Aù8ú $ö $ÿ ù¶ú&K
ø oÿ öû$ú1÷.ø &p$qNü,ø)<
ù p$sr+$
t4uGvwuyx{zJ|,}~#'+'~ZcD|,'X},+c}4'}

ø¶û Dÿ -"ûAü,ý1ûÿ /ø)üû$ú ,@ÿ 75ÿ ÿN
ü 0ú&ý&ú&ü =IüLú&ü8ý1ÿA;Fü
9÷.ý&ý&÷E79$:%9ÿD÷
"5)ýcü	] _ ú
û/ü,ø÷
Mÿ ùNû÷Yü,øNÿ*+)úGü,ý1ÿ øËû÷
"5)ýcü)]?_ úcøNù)úY)ø)öû$ú,ÿ ø÷
Mü,ý÷
$R¦ûÿ$ÿú'süAþ$÷,þ4÷$ú1û$ú1÷.ø
ö  ú&	ø ] _ û ù÷ÿ  ø÷,û ÷¦ö"ö ]ú&øRüNù)úy)ø8öû(B0^)ü
û÷@4ÿA$ÿ"þ8ýcü,öÿ ùI+=ûÿù)úY)ø)öû
 û )üû÷ö"
  ü,ø)<
ù 5	  $ )õ Jü $ÿ8ý1û B¦ÿ ,ÿ =ù)'ú Y8ø)öû)ü
÷¦ö"ö/ÿ ø)öÿ]÷
sÿ!ü,öû$ýG=û)ÿ?/ü
Rÿ?ü/úcü8ý1ÿ$
û   {4ÿû ÿ'ù)ú Y)ø)öû 
÷ ] _ $%9ÿP+ø 4ÿ &w
÷  
ü 0¦úcý&ú&ü =Lü /úcü 8ý1ÿ Aú Aû 5ÿ Qü,ý&ý1ÿ û
\ ÿ"?
ú&øjûÿ ,ÿ &
$ÿ üûÿ A÷
;ÿ*>)ü,ý4û÷Mý&
÷ w WB÷nû )üAû C
÷ 7ÿ,ÿ =¶ù)ú Y)ø)öûû ÿ $ÿNú üRù)ú ¡4ÿ $ÿ øjûû û 0ü,ý ÿ
ü $ú .ø Rÿ øjûû÷ û ÿ¶® 
ü 0ú&ý&ú&ü =Pü /ú&ü dý1ÿ $MR¢9  ú nø÷,ûnüþ4E÷ 7]ÿ R÷
A£û 7]÷ Bù!ÿ -=ø^


ÿ ¤D¥§¦¨C
÷ Rü,ý&ý
$ \ ÿ"?
û ¯°4ÿû Dÿ C
÷ 58ý&ü
©ªM«  m¬­qEr
R

±± 
 ± ±
 ±±
 ±±
$$
$
 ±±

 ^  P²²²^ 0³
´  µ³
¶  ^  M²²²·^ 0³
´   ³
  (  M²²²·^ 0³
´ 
 ¸ ³
¶  (  `²²² ³
´ 
 ¹ ³
¶Z(  `²²²<¶F>º4Z¶F ³
´

 » ³ 

ÿ /ÿ"þ $ÿ ÿ øjû$üû$ú1÷.ø¶÷
üRþ/÷
8ý1ÿ ú&øû$ü,ø8öÿNú&øû)úAö"ü
$ÿPú

%& D  

.0/21,3.0¼ ± ¯k^d fXg0hXi l ³

ÿ /ÿ ö÷.ø$úû÷
AûÿLüLú&ü8ý1ÿ5    ü,ø)ù½ûÿ	ü/ú&ü8ý&ÿ@C÷
'ö÷.øjû$ú&ø,ÿ ø)ö"ú&ÿ57ú1û÷û
÷¦ö"ö $ÿ ø)öÿ;ú&øK]?_B)ü,ø)ù¼ ú'ûÿÿ"ûA÷
¿þ$÷,þ4÷$ú&û$ú1÷.ø)ü,ý#üLú&ü8ý1ÿ7ø÷,ûú&ø</e½3C$
79  ^3


è Cðâsã ÷ /ÿ"þ $ÿ ÿ øjûû )ÿ )ü,øjû$ú dö"üû$ú1÷.ø ÷ ,ÿ ¶û )ÿû /ÿ"ÿú&ø8ú1û$ú&ü,ý&û$Å üûÿ^7]ÆPÿÈ øÿ"ÿ ù û£7]÷
ü ú&ý&ú&ü ü Lú&ü 8ý1ÿ
,ü ø8ù
4ÿ ö"ü ÿ
¿÷ Nÿ 8ú ü,ý&ÿ øËû$ýG=aq ý1÷
>
r+$%&ÿ
 P*+
E  

¾2¿ ÀÂÁZÃ
Ä % Â  

 ÅÇÆ`È
C

0
=   @ 
n  

 Lr
r B 
 *> G
ÉEÉEÊ

Ë9ÌGÍÎ;ÏÍÐÍ

ÑÒÓ
ÔÕGÖ×ÙØÚÛÜÝ
ÚÞ!Ö@ØÛÒÖÑÒÖÛÖÚÜÖßKÔ>àÜáÖDâYÓÕÕGÓEã)ØÚäFâXÓ
Ò"×5åÕ'ÝæYâXÓ
Ò&ÑÕÝ
ÚÛâYÒÓ×èç+ÖÞ!ÜØGÓÚéêsë+êsì+êîí
ï ð9ñµò ñ?ðDóò ñDð)ôµò ñDð9õµò ñ?ð9ñµòöó9ð@óòöó9ð9ôµòöó9ð9õµòöó

÷wøó9øCô
ï,ùú+û2ü ñ ùú0üû ñCýþÿ  û ñIýþÿ  ü ñ ù
ú  !þÿ û ñ ùú þGÿ ü ñ
	)ñµò ñ
	Dóò ñ
	)ôµò ñ
	)õµò ñ5ó

ý

þ
ÿ



ý

þ
ÿ



ø
ó

^

C
ø
ô
2
û
ñ



ü
ñ

W

ù

ú  !þÿ û9ñWùú !þÿ üñAù
ú+û)üñ&ùú+üûAñ íí
æææ
íÙæ
 ææ ø
ó ¶øCô íÙæ ýþÿ  û2
ñ  ýþGÿ  ü
ñ !Aùú þGÿ û)ñnùú þGÿ üñWùú+û2üñ!Aùú+üû9ñ íí
 ææ ¶ø
ó ^øCô íÙæ  ýþGÿ  û)
ñ  ýþGÿ  ü
ñ nù
ú  þGÿ û9ñ&ùú þGÿ üñAùú+û2üñWùú+üû9ñ íí
 ææ ¶ø
ó ¶øCô í#"@í
&ùú+û2ü ô $ í
% áÖ2ÓåÜÖÒ×IÓÛÜÖ'&0ØÛÜÖÚÜØÝ
Õ)(+åÝ
Ú>ÜØ+*ÖÒ,(>åÝ
ÚÜØ+*ÖÛÜáÖ2ÑÒÓ
ÑwÓÛØGÜØGÓÚÝ
Õ-·ÝÒ"ØÝÔÕGÖÛßÖÛÞ!ÒØÔØÚä@ÑÕÝ
ÚÛ.

ÜáÖAåÚØ/-
ÖÒÛÝ
Õ0(>åÝ
Ú>ÜØ+*ÖÒ(+åÝ
Ú>ÜØ+*ÖÛZÓ1-
ÖÒÜáÖAØÚØGÜØÝ
Õ>ÛÜÝÜÖÛ.+Ý
ÚßJÜáÖAØÚÚÖÒ×IÓÛÜÖ'&ØÛÜÖÚ>ÜØÝ
Õ2(+åÝ
Ú23
Ü+Ø *Ö,
Ò (+åÝ
Ú>Ü+Ø *ÖÛÜáÖ?ÒÖÛÜÓ
âÜá4
Ö -ÝÒØÝÔÕGÖÛÜáÝÜÒÖÑÒÖÛÖÚ>Ü'Ö &+ÖÞåÜØGÓÚÛÓ
âÜáÖ2ÑÕÝ
ÚâXÓ
ÒAÑÝÒÜØÞåÕÝÒ
-Ý
ÕåÖÛAÓ
âZÜáÖåÚ5Ø -
ÖÒÛÝ
ÕÕ6
à (>åÝ
ÚÜ+Ø *Ö7
ß -·ÝÒØ'ÝÔÕGÖÛê
8
9;:5<):>=#?A@BDCDEGF>H0IDF>CJLKMDCDEGF>CNJDOPCDERQB;SGE;TVUAFXW;OSGEYZI
% áÖIÛÖÞ!ÓÚß

Ý ÕGÜÖÒ"ÚÝÜØ5-
Ö[(+åÝ
Ú>ÜØ+*ÖÛDÓ\-
ÖÒJÝ
Õ'Õ-·Ý
Õ'åÖÛDÓ
âÜáÖIÑÒÓ
Ñ#ÓÛØGÜØGÓÚÛ
]ÙÜáÝÜÒÖÑÒÖÛÖÚ>Ü@ÜáÖ


ÜÒåÜá^3_-·Ý
ÕåÖÛÓ
ââYÝ
Þ!ÜÛ9ØÚ	ÜáÖ?Ø'ÚØGÜØÝ
ÕÛÜÝÜÖÛê`â,ÜáÖ-Ý
ÕåÖÛÒÖÑÒÖÛÖÚÜAÝ
Ú<ØÚØGÜØÝ
ÕÛÜÝÜÖ.ÜáÖÒÖD×JåÛÜ
ÔwÖIÝ
ÚnÖ'&0ÖÞåÜØGÓÚ Ó
âÜáÖIÑÕÝ
ÚMÜáÝÜ5ÑÒÓ0ßåÞ!ÖÛDÝ<ä
ÓÝ
ÕÛÜÝÜÖ
ê % áÖCÒÖÑÒÖÛÖÚ>ÜÝÜØGÓÚnÓ
âAÝÑÒÓ
ÔÕGÖ×
ØÚÛÜÝ
ÚÞ!Ö@ØÚ^ÜáØÛAÞÝ
ÛÖ5ØÛAÝ
Û9âXÓÕÕÓEã9Ûê
ï2a?÷ ] ï2b ææ_c ñ edDfXg2hXií !$ í
!Þ ÓÚÛØÛÜÛ?Ó
âÜáÖFÑÒÓ
Ñ#ÓÛØGÜØGÓÚÝ
Õ-ÝÒØÝÔÕGÖÛ?ÚÓ
Ü@Ø'Ú alk ]Fê % áÖFâYÓ
Ò×JåÕÝ^ÛÝà0ÛDÜáÝÜÜáÖÒÖ
ØÛAÝFÑÕ'Ý
ÚLã)áØÞá^ÑÒÓ+ßåÞ!ÖÛÝCä
ÓÝ
Õ,ÛÜÝÜÖ@ã)áÖÚ^ÜáÖDÖ'&0ÖÞåÜØGÓÚÛÜÝÒÜÛ&ØÚ^Ý
Úà^Ó
âÜáÖ@ØÚØGÜØ'Ý
ÕÛÜÝÜÖÛê
m &0ÖÞåÜØGÓÚÛÞ!Ó
ÒÒÖÛÑwÓÚßØÚänÜÓaÜÒåÜ2
á 3_-Ý
ÕåÖPÝ
ÛÛØGäÚ×IÖÚÜÛÜn
Ó ] ÜáÝÜ<ßÓaÚÓ
ÜLÒÖÑÒÖÛÖÚ>Ü<ØÚØGÜØÝ
Õ
ÛÜÝÜÖo
Û c ñ ßÓIÚÓ
Ü9áZ
Ý -
ÖÜÓ	ÒÖÝ
ÞáKÜáÖDä
ÓÝ
ÕÛê
j ÖÒÖ

b

p4qrsutvxw!yDzx{|% áÖDÔÕGÓ0Þ}0ÛãÓ
ÒÕ'ß<Ö'&0Ý
×IÑÕGÖ@ØÚ^ÜáØ'ÛAÞÝ
ÛÖØÛAÒÖÑÒÖÛÖÚ>ÜÖßÝ
Û&âYÓÕÕGÓ;ã9Ûê

ï0ð9ñµò ñ?ð@óò ñDð9ôµò ñ?ð9õµò ñDð)ñµòöó9ðDóòöó&ð9ôµòöó9ð)õµòöó
ý þÿ û9ñ ýþÿ üñIùú þGÿ û)ñIùú þGÿ üñFù
ú+û)üñCùú0üû9ñ
÷ 
ï 	 ñµò ñ 	 óò ñ 	 ôµò ñ 	 õµò ñ  óùú+üû@óEùú+û2ü&ó5ùú+üû?ó ýþGÿ  û?ó ýþGÿ  ü9ó5ù
ú !þÿ û@ó 
ú  !þÿ û ñ Wù
ú  !þÿ ü ñ Aù
ú+û)ü ñ Aù
ú+üû ñ í
ææææ ýþÿ  û ñ  ýþÿ  ü ñ Mù
ÿ  û9
ñ  ýþGÿ  ü
ñ &ù
ú  þGÿ û&
ñ Mù
ú  !þÿ ü
ñ Wù
ú+û)üñAù
ú+üû&ñ í
~ æ ýþ
ñ  ýþÿ  ü
ñ Wù

ú  !þÿ û9
ñ Aù

ú  !þÿ ü
ñ &ùú+û2ü
ñ Wù
ú+üû&ñ íí ù
ú+û)üô í
~ æ  ýþGÿ  û9
$ í

8
yz5ywtwZw2G1r^XGnNNw1w0sRNx1s
% áÖ5ßØÛÞåÛÛØGÓÚ^ØÚ<ÜáÖ5ÑÒÖ-0ØGÓåÛAÛÖÞ!ÜØÓÚÛ&ÒÖÛÜÒØÞ!ÜÖßÜÓLÓÚÕGà^ÓÚÖ}0ØÚß^Ó
â:åÚÞ!ÖÒÜÝ
ØÚ>Ü£à.ÜáÖ@ÑwÓÛ3
ÛØGÔØÕØGÜ¢àLÓ
âÛÖ-
ÖÒÝ
Õ(ØÚØÜØÝ
Õ,ÛÜÝÜÖÛê j Ó;ãÖ-
ÖÒZ.ÓåÒ?âXÒÝ
×IÖãÓ
Ò}`áÝ
Û?ÝLä
ÖÚÖÒÝ
ÕØGÜ¢àÜáÝÜDØÛ2Ûå2LÞØGÖÚ>Ü

âYÓ
ÒAÒÖÑÒÖÛÖÚ>ÜØÚäJÓ
ÜáÖÒ,}0ØÚßÛÓ
âåÚÞ!ÖÒÜÝ
ØÚ>ÜØGÖÛ.ÕØ5}
Ö?ÚÓÚßÖÜÖÒ"×IØÚØÛÜØÞAÓ
ÑwÖÒÝÜÓ
ÒÛAÝ
Úß^ÚÓÚßÖÜÖÒ3
×IØÚØÛ×§ØÚMÜáÖLÖ
Ú -0ØGÒÓÚ×CÖÚÜê % áÖIÞ"áÝ
Úä
ÖÛ5ÜáÝÜ5ÝÒÖLÚÖÖßÖßÂÞ!ÓÚÞ!ÖÒÚ ÜáÖ	âYÒÝ
×CÖ	
Ý &ØGÓ×IÛ5Ý
Úß
Z\

 ^^5 2P¡+^/^¢£¥¤¦£\¢

§¨^©¥ªx«¬ ­¯®°/±©¥§¨P±§o²^©Z³´'¬ µ5¶)©¯§¨^©¥·P¬©Z´'«¦¸P²Pµ/§µ5«¦¸P³4±¸P²¹·)«¦³§´'«¦¸P²Pµ5§µ/«¦¸P³«ªº«·)©¬ ±§«¬ ³o±³o²Pµ/³ ´®P³³©Z²
µ/¸!»0©Z´'§µ/«¦¸¼^½/¾½º¿4°/°)«§¨^©¬ªX«¬ ­A®P°/±©o¬ ©Z­V±µ/¸®P¸P±À)©Z´'§©Z²;½
Á «¦¸³µ/²^©¬!±¸Â«·)©¬ ±§«¬Ãµ5§¨Ä·P¬©Z´'«¦¸²Pµ5§µ5«¦¸P³!ÅÇÆÈÉÉÉ1ÈÅ>Ê|±¸²l§ËÃ«|±°5§©¬ ¸P±§µ5Ì©Í©'ÀG©Z´'§³ ÎÆÐÏ
Æ
Ô
Ô
ÅxÑÆ ÈÉÉÉ\ÈÅxÊ
Ñ Ò Ó ±¸P²ÄÎ1ÔuÏÕÅxÑ Æ ÈÉÉÉ1ÈÅxÊ
Ñ ÒÖ\× «¦¸^©¹«ªÃ¨µ/´ ¨Lµ/³´ ¨^«¦³©Z¸|¸^«¦¸²^©§©¬ ­Vµ/¸µ/³§µ/´±°/°/Ø½ÂÙÚ¨^©Û¸^«¦¸2Ü
Æ

²^©§©¬ ­6µ/¸Pµ/³­Ýµ/¸§¨^©Þ©'ß2©Z´®^§µ5«¦¸¹«ª§¨µ/³4«·G©¬à±§«¬
±§o§µ/­Þ©A·)«¦µ/¸§áµ>³¬©·P¬©Z³©Z¸§©Z²¹¶0Ø±Ì±¬àµ/±¶°5©
âäã §¨P±§
µ/³«¦¸P©V«ªº§¨P©6®P¸Pµ5Ì©¬à³±°/°5Ø!å0®P±¸§µ+æ©Z²¹Ì±¬ /µ ±¶°/©Z³½¥çèª§¨^©Þ«·)©¬ ±§«¬¯µ>³©'ß0©Z´®^§©Z²u±§áo±¸P²
± ¸P²¹µ5ª âäã µ/³4ª±°/³© × §¨^©Z¸¹§¨^©¥©'À)©Z´'§
µ/³oÎZÔ½AÙÚ¨^©
âäã µ/³4§¬ ®^© × §¨^©Z¸¹§¨^©Þ«·)©¬ ±§«¬¨±³§¨^©¥©'ÀG©Z´'§¯ÎÆ × 
¸ ±§µ5Ì©o©'ÀG©Z´'§³4µ/³,«¶0Ì2µ5«¦®P³½
é ©Z¸^©¬ ±°>µ5êZ±§µ5«¦¸§«V§¨P©
´±³©Ãµ/§¨­Þ«¬©§¨P±¸§ËÃ«[±°5§©¬ 
ÙÚ¨P©Aªx¬ ±­Þ©Þ±ß^µ5«¦­V³o±¸P²¹§¨P©ÞªX«¬ ­A®P°/±©Þ²^©Z³ ´'¬ µ5¶µ/¸ é )
· «¦³§´'«¦¸P²Pµ/§µ5«¦¸P³4«ª«·)©¬ ±§«¬ ³
¨P±ZÌ©Þ§«¶)©
¬©ÃÚ¬àµ5§§©Z¸Û§«¬ ©'ë©Z´'§o§¨^©Þ¸^«¦¸P²^©§©¬à­Vµ/¸Pµ/³ ­½ÙÚ¨P©¥´à¨P±¸ é ©Z³o­V±ì©Þ§¨P©A©'À)©Z´'§³´'«¦¸P²µ5§µ5«¦¸P±°N«¦¸¹§¨^©
Ì±¬ µ/±¶°5© â ã ½íD©§Úîï!ðZñ ×0òóôõö îø÷ºÏúù1Å Æ ÈÉÉÉZÈÅ Êû ±¸P² ò2üý'þ_õö î÷Ïúù1Å ÑÆ ÈÉÉÉ\ÈÅ Ê Ñ Ò û ½

  ãöö ÅÇÆä÷ ãÆ 		
 ö Å/ÊP÷ ã ÷ Æ
   ã7âäãöö Å ÑÆ ÷ ã Æ 		
 ö Å ÊÑ Ò Ó ÷ ã Æ'÷
Ô
Ô
ö ¾'¼^É¦÷ÿ ã âäã

öö ÅxÑÆ ÷ ã Æ 		
 ö ÅxÊÑ ÒÖ ÷ ã Æä÷

 ¬ ±­V© ±ß^µ5«¦­V³µ/¸ é ©Z¸^©¬ ±°0±¬© «ª^§¨^©ªX«¬ ­ ö Å_÷ ã ö Å_÷ ã Æ  Æ 		 Ê½©¬© ªX«¬à­¯®P°>±©  ¬©·P¬©Z³©Z¸§
§¨^© ·)«¦³³µ5¶°5©º´±®P³©Z³ªX«¬§¨P© ´à¨P±¸ é ©,«ªGÅªx¬«¦­	! ýZô §« þó#
" ô ±§áà½ç¸6»0©Z´'§µ5«¦¸¥¼^½/¾ §¨^© «¦¸P°5Ø
·G«¦³ ³µ5¶°5©
´±®P³©Z³Ã©¬© §¨^© ±·P·°/µ/´±§µ/«¦¸P³«ªP«·)©¬ ±§«¬à³N§¨±§ ­6±ì© ÅP§¬ ®^©½%L
$ ¨P©Z¸¯±²^«·§µ/¸ é ¸^«¦¸P²^©§©¬ ­6µ/¸Pµ/³§µ>´
ö ¾'¼^É/¾1÷ÿ
ö ¾'¼^É ¦÷ÿ

«·)©¬ ±§«¬ ³±¸P²6³·G«¦¸§±¸^©«¦®P³´ ¨±¸ é ©4µ>¸V§¨^©©Z¸Ì2µ5¬«¦¸P­V©Z¸§ × 
§ ¨^©4´±®³©Z³ªx«¬ ´ ¨P±¸ é ©Z³º¶)©Z´'«¦­Þ©­Þ«¬©
´'«¦­Þ·°>µ/´±§©Z²;½ Á «¦¸P³µ>²^©¬§¨^©[ªX¬ ±­V©[±ß^µ5«¦­
ªx«¬A±°/µ5§©¬ ±°Å 
§ ¨P±§¯«2´´®^¬ ³¯µ/¸ÍÎÆZ½ «\Ã «¦¸^©[«ª,§¨^©

&


Ã
P
¨

©

¬
o
©

î
/
µ
,
³

§
P
¨

©
/
µ
P
¸
^
²
'
©

ß

«
N
ª

§
^
¨


©

«
G
·

©
¬à±§«¬Z½çèª Å«0´´®P¬ ³
*)
ãâäã

µ/¸Î1Ô × §¨^©Z¸ÿ ã âäã µ/³ «¦¸^©«ª §¨^©²µ/³'®P¸P´'§³½
&«¦¸P²^©§©¬ ­6 µ/¸Pµ/³§µ>´A´à¨P±¸ é ©´±¸Í¶)©V­Þ«2²^©Z°5©Z² ¶0Ø¹¬ ®P°5©Z³+-, ÎÆ
. ÎZÔV§¨P±§
Ã«¬ì °/µ5ì©V¸^«¦¸²^©§©¬Ü
('

²Pµ/³ ®P¸´'§³

µ/¸7§¨P©oªX¬ ±­V©±ß2µ5«¦­

µ/³ÿ

­Vµ/¸µ/³§µ/´¯«·)©¬ ±§«¬ ³o©'ß^´'©·P§§¨P±§o«¦¸P©Þ«ªº§¨^©[±°5§©¬ ¸P±§µ5Ì©Þ©'À)©Z´'§³¯ÎÆ«¬¯ÎZÔA¶)©Z´'«¦­Þ©Z³
§¬ ®^©Þ±°5Ã ±ZØ2³

+
0+

Ã¨^©Z¸V§¨^©Ú·P¬©Z´'«¦¸²Pµ5§µ5«¦¸ µ/³§¬ ®^©½ÙÚ¨P©ÚªX«¬à­¯®P°>±©²^©Z³´'¬ µ/¶µ/¸ é §¨^©©'À)©Z´'§³º«ªG§¨µ/³ì2µ/¸P²Þ«ª)¬ ®P°/©Z³±¬©
«¶0Ì0µ5«¦®³ º§¨P©
§¬ ®^§¨!«ª ¹µ>­Þ·°/µ5©Z³ §¨P©
§¬ ®^§¨!«ªÎÆ±§§¨^©A¸^©'ß0§·)«¦µ/¸§«ª§µ/­Þ©
Ã¨^©Z¸!±6Ì±¬ µ>±¶°5© â

	/

¬©·P¬ ©Z³©Z¸§µ>¸ é §¨P©¸P«¦¸P²^©§©¬ ­Vµ>¸Pµ/³­ µ/³§¬à®^© × ±¸P²§¨^©§¬ ®^§¨«ªÎ1ÔÃ¨^©Z¸ â µ/³ª±°/³©½ÙÚ¨^©o´'«¦¸P³§¬ ®P´äÜ
§µ5«¦¸[«ªªx¬ ±­Þ©±ß^µ5«¦­V³ªx«¬°>µ5§©¬ ±°/³ºµ/¸[ÎÆ ±¸P²7ÎZÔµ/³­Þ«0²µ+æ©Z²V°/µ/ì©µ/¸6§¨^©4´±³©4«ªN¸^«¦¸P²^©§©¬ ­6µ/¸Pµ/³§µ>´
«·)©¬ ±§«¬ ³½



'


'

«¬±Þ°/µ5§©¬à±°GÅ µ/¸ÎÆ × 
§ ¨^©oªX¬à±­Þ©±ß2µ/«¦­´'«¦¸§±µ/¸³Ú±Þ²Pµ/³ ®P¸P´'§§¨P±§Úµ/³ §¨P©´'«¦¸ ®¸P´'§µ5«¦¸
«ª Ð±¸P² â× ±¸P²Rªx«¬¥°>µ5§©¬ ±°Åµ/¸ Z
Î Ô[§¨^©¬©Z³·)©Z´'§µ5Ì©7ªX¬à±­Þ©±ß^µ5«¦­V³¥¨P±³¥±¹²Pµ/³ ®P¸´'§§¨P±§Þµ/³A§¨^©
´'«¦¸ ®P¸P´'§µ5«¦¸7«ª ±¸²
½
â

1+

'

2+



('

3%46587:9<;1=0>@?ACB
ED««¦°/©Z±¸ªX«¬à­¯®P°>±
ªx«¬

ÙÚ¨^©´'«¦­Þ·°/©§©å®P±¸§µ+æ©Z²

F

§¨^© \Ü_¶°5«2´ì©'ß2±­Þ·°5©4²P©Ì©Z°5«·)©Z²µ>¸[§¨P©4·¬©Z´'©Z²2Ü

µ/¸ é ³©Z´'§µ/«¦¸P³µ/³ é /µ Ì©Z¸¸^©'ß2§½ÙÚ¨Pµ/³ xª «¬ ­A®P°/±¥´'«¦¸P³µ>³§³,«ª±¥ªX«¬à­V±°/µ5êZ±§µ5«¦¸«ªN·°>±¸7©'ß0©Z´®^§µ/«¦¸P³,ªx¬«¦­
»0©Z´'§µ5«¦¸Í¼^½/¾ × ªX«¬ ­AP
® °/±©Þªx«¬ ­V±°>µ5êZµ/¸ é §¨^©[·°/±¸P³ªx¬«¦­
»2©Z´'§µ5«¦¸ ¼^½ 0½ × ±¸P² ªx«¬ ­A®P°/±©Vªx«¬¯å0®P±¸§µ+æPÜ
´±§µ5«¦¸ÍªX¬«¦­
»0©Z´'§µ5«¦¸ ¼^½ 0½/¾½7ÙÚ¨^©Þ·P¬ ©Z´'«¦¸P²Pµ5§µ5«¦¸³4±¸² §¨^©V·)«¦³§´'«¦¸P²µ5§µ5«¦¸P³«ª§¨^©V«·)©¬ ±§«¬ ³¯±¬©



²^©Z³´'¬àµ5¶)©Z²[¶0Ø7§¨^©oªx«¦°/°5«1Ãµ/¸ é

 

G

ªX«¬à­¯®P°>±©oªX«¬Úáï ù 2ÈZ¾ û ½

IH  ã öü!J*KIL ã  õ ô  óMK ã  ü!Jþ ONP ôQK ã
ÿÆ ãöü!J*LKÚã õ ô  óMLºã ü!Jþ ON	 ôLºã

ÿÔ ã
 öü!J þ ONP ôQK ã õ ô  óMLºãV üRJSKILã

ÿIW ã
 õ ô  óUKÚãV üRJSLTK,ã
  öü!J þ ONP ôQºL ã 

Æ

ÿ

Y[ZO\

Æ
Æ

Æ

 ,üRJSKIL ã Æ ¹õ ô  óML ã Æ ÷

,ü!JSLTK,ã Æ  õ ô  óUKã Æä÷
Ú õ ô  óUºL ã Æ ,ü!Jþ ONP ôQKÚã
Ú õ ô  óU,K ã Æ X,ü!Jþ ON	 ôLºã

Æä÷
Æä÷

]^`_bac_edf_
gihbjlkmQnRopjFn
qbr`sfo6tikusRmivw8xy*z[{
|pn!mUj}nRt~ksf`st	
~!SV8!SI# 
~!*i!STFM 
!S  ~!S  I  
!ST  ~!*  I  
!VCO	`  X~!VCO	`  X #  !VCPQ  ~RVCOPQ   M 
~!VCPQ  8!VCO	`  X   ~!COPQ  !COPQ  I  
 U!U    URM   M 
  `Q!M    `Q!M  I  
 U!U  `Q!MX# 
  `Q!M  `Q!U   
gihbjRsfnR%rti Ms¡hen[¢Rj£ Uhbj¤V`s*¥U¦§¨sf©ª MsR«sRk1¤V`s*¥U¦¬­n!ku Mj	m UhbjjPqSj[¥	®b Ursf©ªsRk1 Uhej«VnR©¯igihertIrt
mUj	«emQj[tMj[©O Mj[°X¤±¡ Uhbjn! Msfo6r¥lksRmQo<®en !*I ghbjFr©er` UrnR2tU Un! Mj[tIr© UhbjF«emUsR¤`j[o²¥Psf©etUrtM Ut~sRk1nR
 Uhbjl«0sftUtUr¤V`jIn!mQmQnR©bRj[opj[© Ut~ Uhbjl¤VsS¥Q¦St~§:nR©e°¬@¥	nR©¤0jr©¯³1§­rtTsf©¬´e¬rtTsf©§´bsRmi¤0sR Uhn!mUj
sf©¡ Uhbj Un!¤V`jRµghert«emUsR¤Vj[o¶henRt~nptUsf®b Ur`sf©Er©¡nR2 UhbmUj	jksRmQo6tTsRk·«nR©etTr©¸Sj[¥P Ur`sf©¡¹bºS´VnR©e°Ej
®etMjl UhejFsf©bjlkmUsfo»¸Sj[¥P Ur`sf©¹bºS¼S½8jFRj	 I UhbjFksf`sr©b<kusRmo®en!jlkusRmIvwxy*z[{
|f
 # ¾À¿(Á# 2Â RSI Â  `Q!U Â  ¿ !VCO	` Â ~!S Â  U!U ÄÃMÃ
 M ¾À¿(ÁlM 2Â RST Â  `Q!U Â  ¿ !VCPQ Â ~!* Â  `Q!M ÄÃMÃ
I  ¾À¿(Á   2Â RVCOPQ Â  `Q!U Â  ¿ !S Â   URM Â ~RVCOPQ ÅÃMÃ
    ¾À¿(Á    Â RVCOPQ Â  U!U Â  ¿ !STi Â   URMi Â ~!COPQ ÃMÃ
gsXmUj	«emQj[tMj[©O  UhbjÇÆS®enR© UrÉÈ¥	n! Ur`sf©Ês¢Rj	m£ UhbjËr©er` UrnR1tM Un! Mj[t<jË©bj	j[°Ê ÅsnR®bq*rrn!mU±X¢!n!mQrn!¤`j[tFÌ 
nR©e°Ì  ghbjFr©er` UrnR2tU Un! Mj[tn!mUjFmQj	«emUj[tMj[© Mj[°¤S±E Uhejlkusfsr©e<ksRmQo<®en!jR
¿ Ì  Â Ì  ÃRÍÎ¿  U!U µÂ  URM Â RVCOPQ Â !COPQ Â ~RSI Â i!ST Ã
¿ Ì  Â  Ì  ÃRÍÎ¿  URMI Â   `Q!U Â ~!VCO	`i Â !VCO	` Â !S Â ~!ST Ã
¿  Ì Â Ì  ÃRÍÎ¿   `Q!M Â  `Q!M Â !VCO	` µÂ i!VCO	` 1Â ~!S Â !ST 	Ã
¿  Ì Â  Ì  ÃRÍÐÏ
gihbjsf®b Mj	mQo6sftM TjPq*rtU Mj[©O UrnR0ÆS®enR© UrÉÈVj	m~Æ®VnR©O UrÉÈj[t Uhej«VmUsR«0sftUr` Ur`sf©enRV¢
n!mrn!¤V`j[t°bj[tU¥PmQr¤Vr©bF«nR©et	´
 Uhbj®e©er`¢Rj	mtUnRVÆS®enR© UrÉÈVj	mTÆ®enR© UrÉÈVj[ts¢Rj	m~ Uhejr©Vr` UrnRetM Un! Mj[t[´enR©e°Ç Uhejr©V©bj	mQopsftM jPq*rtU Mj[©O UrnR¢!n!mQrÉÑ
n!¤V`jFÆS®enR© UrÉÈVj[t~ UhejFmUj[tM isRk% Uhbj}¢
n!mQrn!¤V`j[tT Uhen! imQj	«emUj[tMj[© ijPq*j[¥	®b Ur`sf©etsRk UhejF«VnR©¡ksRm«Vn!mQ Ur¥	®en!m
¢!nR®bj[t~sRk Uhbj}®e©Vr`¢Rj	mQtUnR±ÇÆ®VnR©O UrÉÈj[°¡¢
n!mQrn!¤V`j[t	
Ò ÁI# ÁlM lÁ   Á   lÁ#ÓÁlMÓiÁ  ÓÁ  Ó
Ô Ì  Ì 
Ò RSI6!ST  U!U  U!U6!VCO	`I£RVCOPQ}I# }FM }   }   lÕÖØ×Ù¯Ú	Ú	Ú
gihejÆS®enR© UrÉÈVj[°<¬sSsf`j[nR©<ksRmQo®Vnir Uh} UhbjT¥Psf©
ÛU®e©e¥P Ur`sf©<sRke UhejksRmQo<®en!jT°bj[tU¥PmQr`¤0j[°}j[n!mQr`j	m%nRt
 Uhbj¤0sS°e±6nR©e°Ç Uhejn!¤0s¢RjFÆ®enR© UrÉÈVj	mtnRtT Uhbj«emQjPÈeq2´*rt MmQ®bjr`k·nR©e°Esf©e±6r`kØ Uhbj«emUsR¤Vj[o¶r©VtM UnR©e¥Pj
r©ÆS®bj[tM Ur`sf©henRtln¡tMsf®e Ur`sf©XIr` UhnR©jPqSj[¥	®b Ursf©sRk UhbmUj	j£«0sfr© UtsRk UropjRgihbjptMsf®b Ursf©ª¥	nR©8¤0j
ksf®e©e°p¤S±6nl Uhbj	sRmUj[opÑC«emUs¢Rj	mTksRmTÜ¬TÝ8 UhVn! mUj	 U®bm©etnl Mm®b Uh*ÑC¢!nR®bjnRtUtQr`f©eopj[© µ Ms< Uhbjisf®b Mj	mQo6sftM 
jPqbrtM Mj[© UrnR`±pÆS®enR©O Ur`ÈVj[°6¢!n!mQrn!¤Vj[t Á#  z ÁFM  z Á    z Á    kusRmvw8xy*z[{
|l Uhen! mQj	«emUj[tMj[© «VnR©et	µÞ©bj
tMsf®e Ur`sf©XnRtUtQr`f©et (ßV  Ms Á M  nR©V° Á  Ó ´0nR©e°Ëà Rá[  Ms¡nRØsR Uhbj	m¢!n!mQrn!¤V`j[t Áiâ   IãIj[©e¥PjR´¯n!  Uropj
y£ Uhbjl¤VsS¥Q¦Ë¬rt~ops¢Rj[°kumQsfoä MsR«sRk§­sf© Msp Uhbjl Un!¤V`jFr`kr` irtsf© MsR«sRk§­n! iy*´VnR©V°n! ~ Uropj6{
 UhbjF¤`sS¥Q¦§:rtiops¢Rj[°ªkmUsfoÎ Un!¤V`j}sf© UhbjF MsR«ªsRk%¤V`s*¥U¦¬år`k%§:rt~sf© Uhbj} Un!¤V`j}n! i UropjÇ{!Tgihert
sR¤S¢Sr`sf®VtU`±ÇmQj[nR¥Qhbj[t UhbjFRsfnRæM§çrtTsf©X MsR«sRk1¬Tè6tM Un!mU Ur©epkumUsfoénR0 UhbmUj	j}r©er` UrnR2tM Un! Mj[t	
ê[ë
ì

íîïVðQñbòóVôñbõ`ïVö8ô*îïe÷VõÉñbõîïbøVù£úfùøVïVð
ûüýFþØÿ¯üÿ	
	  !#"
$T&
ÿ %')(

!+*-,/.101
324!#" 5
')6798:!<;>I
= ÿ?( üiÿ#;@¯üA(CBDFEG)F5
')6H!I,J7;>I
= ÿ?( üiÿ#;@¯üA(C2)KL.F5
K	MONQPFRDFEE>PDKL
DSTE3	GU0NF2A
0!VBWKNMX	5
')6  ,C7Y;>I
= ÿ?( üiÿ#;@¯ üZ(C	
[0NF2ZF  Q    !R" 5
*
]
,
^
D
O
M
	

#
M
_
S
KANFB`a	5
\
ab*-,/ cd	egf5
')6:;>
= ÿ(
')6Y1	
Fa	1  !ahid	egfj"
;>I
= ÿ?( üiÿ#;@¯ üA(C2)KL.F5
ÿkm*l ÿ
')6Y01NF2Z	
  Q    !ah:d	enfj"
;>I
= ÿ?( üiÿ#;@¯ üA(CBDFEG)F5
üiÿ#;@¯ üA(C	
Qo  !phdjq`enfj"
ÿ?(@
rm
3s.KRtu*?vw1	
G
3N0yx1KLNuz	1.1KbBWNFKZ{u.1DF0|2
~}	NuNE3	DF0BNFKLM.1ED
m^H1nTzTg1
Y1DPFPF	E3NFx_	JDH2NFK	MO4x1KNPFKiBWNFK{u.1DF0|2
~}	N|NE	DF0JBWNFK M#.1E[D@
0|2DF0	0>9	FF"
DFGyDF0a \ 2)	01G
N0 NFBR2i¡bD	Po
G¢¤£?.201DFM¥x1KNoz	1.KLBNFK2¦GD2
G)}TDS
E
2¤§NFB&BWNFK M#.1E[Di
0 2
x1KNFx_NG
2
3N01DFE`E3NFs
¡bD	Po
G©¨gNFsF	M^DF010>`ª«¨nNPF	E[DF01>	FtF¬" ­^®¯2&
GbG)2)KLDF
s2)BNFK°±DKL2)N \ 2)	01
2¡²DPu
[G¢¤£.20DFM³x1KNoz	1.KL&2)N1DF01E3&.101
PFKLGDFEn{u.1DF0|2
~}KLG5N0RG.1  \ 2)	01G
N0DF01iG)NMO

MOxKNPF	MO	0|2GDK	GzK 
3S_	aSu§p´±DFNE[
@2DFE­µ¢	FF¶" ­+rm
3KLG22¦PDKL
DSE	G{u.1DF0|2
~}	pS|§
2N.2)KLMONG)29{u.1DF02
3}K#DKyzN01G
[K	>©2	0Y21PDKL
DSE3	GRS|§21G)	zN01H{u.1DF0|2
~}K	mDF01
G)NN0n­· \ 
G)2)	0|2
DFE¸PDKL
DSE	G¹zNFKK	G)x_N012)NNFK)¤0No	G&
0¦2G)	DKLL2)KF`.101
3PFKLGLDFEmPjDKL
[DSE3	G
zNFKK	GxºN02)NDF0o¤0No	G­U»A&STDFG
RDFEsFNFKL
321M³
[GAs
3PF	0:
0rm
3s.1K#tu­A»AR}KLG)2ZxDKLDFMO2)Kb
G
¼½¿¾1À 
3Bm2RN.2)KLMONG)2b{u.1DF02
3}KZ°Z
2DFz2
3PFPjDKL
[DSE3	GZ
[GU \ 
[G)2)	02
[DFE©DF01ÁzÂFÃÅÄ À NF21K°Z
G)FT2
G)	zN01:xDK DFMO2)K¹Kx1K	G	02G²2O{u.1DF02
3}KLG_DF01:2921
3KLi
G@2OM^D2)KL
 \ NFB29BWNFKLM.1ED
0
EDF.1GLDFEBNFKLM­mrNFK¸2±BNFKLM#.ED²Æue  e LÇTÈo)È ÆueTÉF)e FÊ±Èo "	Ë&e |Ê±ÈÊ eºÉ	")"n21DFE3sFNFK 
321Mw
GmDFEE3	
°Z
32¦DKs.MO	02G^ ¼½¿¾À Ìd	eg)eTjfzd È 	 È Qfzd	e É fj zd	en ÊÈ )eº ÊÈ  Ê e É fj" ­#»A1G.1S1x1KNoz	1.K
¾oÍ1Î¼ xºKLBWNFKLMG`.01
32mK	G)NE.12
3N09DF01O.101
32¸G.1SG.1MOx2
3N0>­g»A1STDFG
±DFE3sFNFKL
32M]°Z
3292AG)2DF01DKL
zÏ
3	0|2#
[MOxE3	MO	0|2D2
3N02)	 101
{u.	G¹BNFKR21¡bD	Po
G¢¤£?.201DFMÐxKNuz	.K^
G&DSTE3^2)NiGNE3PFN01E§
G
M^xE3¦xEDF010
0sYxKNFSE3	M^G	²DF01C°?YD	PF1PF	E3NFx_	C0°Ð2)	 101
{u.	GBNFKG)x_	1
01sH.1xC2
DFE3sFNFKL
21M­9Ñ¹.Kb2NFK	M94x1KLNPFKR°@
32:2^0°]2)	L10
{|.1	G¹1
GDSE	:DF00NF2&G)NE3PFODF0|§iNFB2
S_	01LM^DKÒoGU
0»©DSTE3RÓO
0E3	GLGU21DF0Ô1N.KLG&¢zÔFÔÕFÕG)	zN011G­-"
»A12)	L01
{u.	GRBNFK9
MOx1KNQPu
[0s2NFS|Po
3N.1G#DFE3sFNFKL
321M<DKSDFG)	N0YBDF
E3	E
32)KLDFE?2)	¿
2
3N0VrK	MDF0>	FFÖu5#¨g
¹ª×v²0|S.1EDsDF0>#	FØF" bDF0 BNFKyBWNFK M#.1E[DÆuÙ ÇºÚÛ N0px_KBNFKLM^
0s
zNMOx.12D2
3N0°@
322.101
3PFKLGLDFE_PjDKL
[DSE3	G Ú S_BNFKRDFEEgPjDKL
[DSE3	GA
0ÙÜD	PFSº	0iDFGG
3s01	D
2)KL.24PjDFE.1F­#rm
3KLG)2_S_BNFK9xºKLBWNFKLM
0s \ 1DF.1G2
3PF^G)	DKL N0DFEE`x_NGG
3SER2)KL.24PjDFE.1DFGGL
3s0o
MO	0|2GU2)N^PDKL
DSE	GU
0ÙYDFGGL
3s01
0s9DF0|§2)K .2o4PDFE.	G2)NG)NMORNFB©2¹PDKL
DSTE3	G±
0 Ú DF0y2	0
x_KBNFKLM^
0s¦.101
2#K	GNE.2
3N0HNFB2)	0§o
3	E1G2)KL.24PjDFE.1	G92)NG)NMONFB²2PDKL
DSE3	G9
0HÙ­»A
Ý	ÞQÝ

ßZà3áâQãTá1äá
å)æLçåèé4êjëFìç1í	îRïFð1åëFñ[òí	óëæLíïòí	î#åè1ëåOôç1î)åRð_íëFîîñ3õòí	óå)ï:åèïî)íyêjëæ ñëðì3í	îö¦÷uí	øzïò1ó>ù¸ëåOëFòú
òïoóíïFûZåèíî)í	ëæLø èå)æííFùñûZëFîîñ3õòñòõ:å)æLçíå)ïyüCýJþÿëFò1óHëFòúå)æLçåèoé4êëFìçí	îå)ïî)ïô^íïFû@åèí
êëæLñëðì3í	îUñ[
ò +ëFò1óyåèí	
ò ºíæLûWïFæLôñòõ9ç1ò1ñ3åæí	î)ïìç1åñ3ïòyúuñí	ìó1î±ëOøzïòå)æ ëFó1ñøzåñ3ïò>ùåè1í	ò9üè1ëFîUå)ï^ð_í
ëFîîñõòí	óûëFìî)íF
ö Aè1ñæLó>ùóíå)í	øzåñ[òõûëFñì3í	ó:ìñ3å)íæ ëFìîAðuúç1ò1ñåAæí	î)ïìç1åñ3ïòiøëFò¦ëFìîïð_
í _íæûïFæLôOí	óïò
êëæLñëðì3í	îåè1ëå@øëFò1òïFåUð_í¹øLèïî)í	òiëFîUåèí&òí oåUð1æLëFòøLè1ñò1õ#êëæLñëðìíFùuåèëåZñî±êëæLñëðì3í	

î 	uç1ëFò|åñ í	ó
ðuúî)ïô^í&ïFåèíæZåèëFòåèí&øçææLí	òåAïç1å)íæLôOïî)
å 	uç1ëFò|åñ íæ	ö
 òñô _ïFæåëFò|å@æLí	î)í	ëæLøLèå)ï ñøïò¦æí	ëFî)ïò1ñ[òõ @ñ3å
è 
 ñîbèï VûWïFæ&ëyå)æ çí#ûïFæLôç1ì
ë Zñ3å
è 
ç1ò1ñêFíæLîëFìì3
ú 	uç1ëFò|åñ í	óHêëæLñëðìí	îùõFïñòõåè1æïçõèëFììïFûbåè
í å)æLçåèoé4êëFìçíëFîîñõò1ôOí	ò|åî^øëFò
ð_í^ë	êFïñó1í	ó>
ö ±ç1ææí	ò|åì3úåèíïò1ì3ú:å)í	øLè1ò1ñ 	|ç
í í^í	
ô Tì3ïúñ
î ëæLåñ3åñ3ïò1ñò1õyøì[ëFç1î)í^î)íå"
î !:ëåRí	ëFø è
òïoóí²ïFûgåèí¹î)í	ëæLø èå)æí#
í !î)ï9åè1ëåUòï9$å ïî)íåîUèë	êFí¹êëæLñëðì3í	î±ñòøzïô^ôOïòn%ö ïFæAî)ïôO"
í TìëFò1ò1ñò1õ
1æïFðTì3í	ô^îùTåè&í 
añî²'î ìñåAå)ïî)íêFíæLëFì¸øìëFç1îí#î)íåî Zñåèiëì3(ï Vòuç1ô#ðºíæ²ïFûç1òñ3êFíæLîëFìgêjëæLñ[ëðì3í	î
ïoøøçææLñò1õyñ[òí	ëFøLè>ùmëFò1óåèñ"
î ±ë	ú¦åèíòuç1ô#ðºíæRïFûëFîîLñ3õò1ôOí	ò|åî&åè1ëå#è1ë	êFíå)ïð_í^øzïò1îñóíæLí	óñî
ôç1øLèìí	îîUåè1ëF
ò ºö

)+*,.-0/2143658791;:=<?>
@ íièë	êFíZ æLñ3å)å)í	òëA1æLïFõFæLëFô åè1ëåå)æLëFò1îìëå)í	îøzïò1ó1ñ3åñ3ïòëFì
ìëFò1ò1ñ[òõæïFðì3í	ô^î9å)ïB
?ùëFò1ó
_íæûïFæLôOí	ó¦øzïô çåëåñïò1ëFì¸íCºíæ ñôOí	ò|åî¹ñòDZè1ñø è¦øzïò1ó1ñ3åñ3ïòëFì+TìëFò1î¹è1ëêFí^ð_íí	ò¦ûWïç1òó¦ð|ú:åèí
åèíïFæí	ôOéE1 æïêFíæbó1ñîLøç1îî)í	óyñò÷uí	øzåñïòFuö
 ìì|åèí?å)æ ëFò1îìëåñ3ïòîgëæíUëFçå)ïô^ëåñ[øëFìì3ú¹õFí	òíæLëå)í	ó9ûæïô åèí±î)íåmïFû1ï_ íæLëå)ïFæLîmëFò1ó#åèí?ûïFæLôçoé
ìëíåè1ëåmóí	îøzæLñ3ð_í?åèíñ[ò1ñ3åñëFìëFòóRõFïëFìoî)åëå)í	îöGZ
 è1ñîH æïFõFæLëFôwñò1øìç1ó1í	înåèí±ëFçå)ïô^ëåñøõFí	òíæ ëåñ3ïò
ïFû?ñ[òêëæLñëFò|åîbûWïFæ¹åè1í. æïFðì3í	ôµñò1î)åëFòøzíFöIA
 èíOç1îíïFûñò|êjëæLñ[ëFòåîJE²K íæíêoñò1ñGL ÷oø è|ç1ðºíæLåùGMONNPRQ
S ñ[òåëFòí	ònùCMONNP?`T ëFòó#æLí	ìëå)í	óå)í	øLè1ò1ñ |	 çí	î`ûïFæU1 æLç1ò1ñ[òõAî)í	ëæLø èOî' ëFøzí	îmñî©ïòí±ïFû1åèí±ó1ñî)åñò1õç1ñîè1ñ[òõ
ûí	ëåçæí	î&ïFûæí	øzí	ò|å#øìëFîLîñøëFì0 ì[ëFò1òíæLîö
 ú¦ñòêëæLñëFò|åî" íôOí	ëFòYûWïFæLôç1ìëíOåèëåRëæí^å)æLç1í^ñòëFìì
æí	ëFø è1ëðì3í¹î)åëå)í	îUïFû©ëI æïFðì3í	ô+ñò1î)åëFòøzíFö0¯V ò|êjëæ ñëFòåî±ëæí¹óíå)íæ ô^ñòí	óð|úåèíbïº íæ ëå)ïFæLîUëFò1óåèí
ñò1ñåñëFì_î)åëå)í	îùëFò1óåèíúèí	ìWX ìëFòîí	ëæLøLèiëFìî)ï^ñòøzïò1óñ3åñ3ïò1ëFìY ì[ëFò1ò1ñòõö
@ íèë	êFíæ ç1òå$ ïî)íæLñí	î9ïFû@ð_í	ò1ø è1ô^ëæ[oZ îö\A èí æ î)å9ðºí	òøLè1ô^ëæ]
Z óí	ôOïòî)å)æLëå)í	î^T ìëFò1ò1ñò1õ
ç1ò1ó1íæ%
 ñòóí__ í	ò1óí	ò|åî)ïçæLøzí	î?ïFûgç1ò1øzíæLåëFñòåÌúOåè1ëå±øzïFææí	î'_ ïò1ó1îå)ï`1 æLïFðì3í	ô/ñòî)åëFò1øzí	îaZ ñ3åèoé
ïçå^ç1òøzíæåëFñò|å¤úFöbA
 èí ç1æ[_ ïî)íyïFû@åè1ñ[î#ð_í	ò1ø è1ô^ëæ[
Z ñî9å)ïYóí	ô^ïò1î)å)æLëå)íåè1ëåñ3åOøëFòð_íôOïFæí
ò1ëåçæ ëFì`ëFòó:ôç1ø è¦í	ëFîñ3íæbå)ïî)ïì3êFí9åèí`Z
 èïìíøzïò1óñ3åñ3ïò1ëFì+ ìëFò1òñòõ^1 æLïFðì3í	ô ïò1øzíFùgñò1îå)í	ëFóiïFû
î)ïì3êoñòõåèí&øzïFææLí	î'_ ïò1ó1ñòõøìëFîîñ[øëFì; æïFðì3í	ô«ñò1îåëFò1øzí	îUî)í_ ëæLëå)í	ìúFö%A
 èí¹î)í	øzïò1óyð_í	ò1ø è1ô^ëæ[Z ñî
åèíOðìïuø]uZ î"
 ïFæLìóD@ ñ3åèî)íêFíæLëFì?ñò1ñ3åñëFìmî)åëå)í	î	ö @ íì3íå¹ïç1æ&åèíïFæí	ô9éE æïêFíæT ò1óëøzïò1óñ3åñ3ïò1ëFì
ìëFòåè1ëåZæLí	ëFøLèí	îbëõñ3êFí	òõFïëFì`î)åëå)íOî)åëæåñ[òõûæïô³íêFíæLú_ ïîîñ3ðìí&î)åëå)íFöcA èñîUð_í	ò1øLèô^ëæ[
Z ñî
ëæLëFô^íå)íæLñWd í	óðuúåèí^òuç1ô#ð_íæ²ïFûðì3ïoø[oZ îùgëFòóD? í^øëFòîïì3êFíOåèí1 æïFðTì3í	ôeZ ñ3åèg
f ðì3ïoø[oZ î¹ñòë
æí	ëFî)ïòëðì3í9åñôOíFö. ïFæIuh ù+y
F ëFò1ói ðìïuø]uZ îbåèí`1 æLïFðì3í	ô è1ëFîbæí	î'_ í	øzåñ3êFí	ìúhkjlM ù=f?j?hC^M ëFòóm?ikFmm
ñò1ñåñëFì|îåëå)í	îùuëFòó9ïçæ¸å)æLëFò1îì[ëå)ïFæè1ëFîó1ñW
n øç1ì3åñ3í	î`ñò9å)æLëFòîìëåñòõ¹ë
:
 æí_1 æLí	î)í	òåëåñïòOïFûTåè1í	î)í
î)åëå)í	î@å)ïøìëFç1îLëFì_ûWïFæLôö
Aè1oí æLîå@îøzí	ò1ëæ ñ3ïøzïò1îLñî)åî@ïFûëî)íO	uçí	ò1øzí#ïFûæïuïô^îcZñ3åèëëFñ3æ@ïFûóïuïFæLî@øzïòòí	øzåñòõøzïòoé
î)í	øçåñêFí#æïuïô^î#
ö p0ëFøzåì3úïòí9óïuïFæ@ïFû¸í	ëFø D
è ëFñ3æbñîAï _í	ò>ù_ëFò1óið_íûWïFæí#í uí	øç1åñòõåèI
í TìëFòñ3å²ñî
@
òïFo
å Zoòï Z
ò ZèñøLè>
ö Aèí^õFïëFì?ñî&å)ïõFïiûWæLïôÐåè
í TæLî)å¹æïuïôÐå)ïiåèíìëFî)åö íæ ëFòåè1ñî¹ð_í	ò1ø èoé
ô^ë[æ ZZñ3åèiåèí9í	ò1øzïoó1ñòõûWæLïô ÷oí	øzåñ3ïD
ò fqö uqö muI
ö V¢ò:åè1ñîbøëFî)íOåèíæLí9ñ[î@ïòì3úïò`
í ëæLëFô^íå)íæ¹åè1ëå
ñî¹ñòøzæí	ëFî)í	óó1ç1æLñò
õ ìëFòî)í	ëæ øLè>ù`åèí^ì3í	òõFåèïFû?åè&
í ìëFò>
ö r@í	ò1øzí^åèí^åè1íïFæí	ô9Eé 1æïQêFíæ#ñ"
î æLî)å
øëFìì3í	
ó Zñ3åèëûWïFæLôç1ìëyåèëåRí	ò1øzïoóí	o
î TìëFò1tî sQí oí	øçåñ3ïò1î&ïFûAì3í	òõFåb
è Mù`åèí	
ò @ñ3åèëûïFæLôç1ìëyûïFæ
ì3í	òõFåu
è uù`ëFòóYî)ïiïò>X
ö æïô<åè^
í æ î)å¹ûWïFæ ô#ç1ì[ëåè1ëå#ñ[î¹ûWïçò1óå)ïiðºíå)æLçí
ë ìëFòåè1ëå#æí	ëFøLè1í	î
åèí&õFïëFì`øëFòð_í¹í oå)æLëFøzå)í	ó>

ö V¢
ò ©ëðTì3
í í&õñ3êFíî)åëåñî)åñøîAïòåèí&íêëFìç1ëåñïòïFûmûWïFæ ô#ç1ì[ë"
í Zñ3åè

vOw(w

xzy;{}|]~l}~lW{}ACy;{4}~ly;{l}`?}{}|
[R?^
O

O
O
(¢
O
O
 k
 C
  
 
 
¤

'[k'O _4'O kt ] 4[ lClO
??
6   
C ¡q  
O 
CO 
6 _?k
C¡q  
O
O
6  O ¢
C¡q 

 ?¢k
¢6 6 
C¡£ 
O

 OC(¢
C¡£ 
O
OC_6¢k 
  O k
C¡q 
(¢
  C O 6  k?
C¡q 
O
 6  O ?¢?    
C¡q 
O
_k6?¢k 6 ?¢k  kl
k¡ 
 k
 k??¢RO  O  ?¢k 
k¡£ 
 C
4O6kk (¢¢k  klO
k¡q 
  
k? O  k
k¡q 
 
k¥}W  R¦%§ 46[ O
¨©[ªl § R?^2«}[}¥ WO

[ªlO4C4l¬Db­RO[W? l¡q R¡qR¡\® z[ªl¨©tI4 kk]'tlX4\[[O'«Y?4¯'A[ªl[ª4['O'
«}AOl¬[ª4"¨°o±ª4 ]ª'? l[W?4²l'[ ¡&³  0_'O_´µ[ªl^]4[O¨°o_k4k[4¬X[ªl^¨¶'
¨°]I}kc[ª}k
][O'«Y?4'[ªl['_2«} WO4¬[ª4
k["[^W_ ¡µ¤ ª4c·;]'a? 4^[ªl[k¥}W
¬?WOz[ªl}¥Y_%¨=[?&_´[ª4#'O?}&[ªlR4¥Y_z¨H4W[ 4'[k'O_´l[ªl#[ª4Wt^[ªl#4I¥Y_a¨
_4[Oz [ª4¸R4[·}O¹z?O¨©].4C´C[ªl¨°?l[[ª[ªl"R4¥Y_z¨=«4]«º?]W[W?4}k] k¥}WO
D[ª4k¨©].4C´=[ªl`·}¨°[ªA[ªl]4[´H}A[ªl&[W²R[ªD[ªl^R4I¥Y_"¨
4?C»$WOk¨a4RlOD[ªl
'Ok]tª¼']_ ¡® 0[ª4^]44o±a_[?¼­l4½#W'] ³[³ ±z[¾R[[k[W?¼±cW[ª  ¿ÀcÁ «}[RO]' ¡
¤ ªl"t46[ O
±W[ª[ªlO4R}l¬`¨©]?Â­RO[W? l¡q R¡q  k[?«;k]k¥}W ¡
¤ k¥}W  ?[4'[k[ '[_X?Ã[ªl[?l[W?Ä¨`'?A¥}WC[¾C±z]Ä«4[¥}O^ ¡ ­l«}W
'?4[W?&«;4%k]#¬?O  ® «4«YO44² ®I¡C¤ ªlc¬?Y[ªlO'«4]¥}WO^az'I[k¾"[ªl¥}R]¾Ra'
"_[[&?C·}¬?l]k[?Å¶o'[[¾?[44¬ C[ªl2¥}WC[¾CtÆ+¨°[?Çl4[?l·}¬?l]k[W?} ¡µÈ 
O]ª¨G[ªl[²«}[¥}WOe4'[}O_´Y±W[ª[ªl[_`¨©?l¥}R]¾R4g?l.¨%[ªl`[ªl]_.«}[¥}WO
O4C4l¬?c«4[O[O6'OgOk]_O´;±z`ª4O`¬Ol_]k'O¨©].4kI¨©"'__t+«;k]_'_"klOc[ª4k
]ª}k]'_] Á D[ªlD[ Á O¨o[ªlD'?4[W?4 ¡É¤ ªlg[[k['[_¬?WOÃ ¤ k¥}  k[D¨©[ªlg']l
¨°]I}kÊ[ª4ka[_«4[O'O%I'?l[W?Å¶'%^O]ª'_G¨Ë¨°].4kÆt´}^[ªlÊ¨¶'¨©].4k[ª4k
[[O[«º?}'^[ªlª4¬?ªlO'
«}k]_'_c lO2¨°Ê±ª4tª[ªl_[k]l^'?4[W?«}4 ¡
È #[ªlI]442¨0[ª4[ªl_[O»E«4[(_¨°Otª¨°].4`±z¬?W.[ªlo¨°?W±l¬^ l¨©t^k[W? ¡
¤ ªl.·}t'"?4^D¬?WOo[ªl^'O[W? D±ª4tª[ª4O4R}l¬X"lO[tW¥YOË´Y[ªl^'O?4? 4^
[ªl#4I¥Y_G¨Y¥}WC[¾C_´6[ª4[ª4Wt`[ªlcR4I¥º_%¨Y 4W[l'[k'OO´R[ª4Ê¨©?4[[ª^[ªlcWOl¬[ª^¨H?l¬O'
²CO_l[W?Al_OlOH´º[ª4I·;¨©[ªg[ªl`}¥Y_¨a'[k'O" [ª4I«} BÅ¶¨%'_«}k]k'`¨°[?e[ªl}¥Y_
¨U[o«Y?[tÆt´4[ª4[²C[ª[ªlI4I¥Y_Ê¨0_4'OcX[ªl¨©].4C´}[ªl'_O[ªg[ªlR4¥Y_Ê¨
«4[«Y?[[W?4µktk¥}WO_´=[ªl&OW¬?ª[ªA[ªl4I¥Y_o¨2'O?44IW"[k¾O.¨©?l[ªl_]O`»E«4[_
'_k4k'"[ªl¨°]I}C´C[ªl"4[ª&[ªloR4I¥Y_a¨Ul?C»$WOk¨+lR4Oz [ª4[Ok]]ªX']_´44[ªl
'O[ª^[ªlÊ'tl[ªC»Ekl2¨Y[ªlÊ¨°].4 ¡µÌ W[ª^[ªlÊO4C4l¬"¨°[?Í­CO[W? l¡q R¡ [ªlÊ¨¶[cÎ]ÏÐÑÒ
l·;4OoÏÐÑÒ.ÓÎOÔWÕ]Ök×'ÑØk["¥}[_[k¥;W ¡aÙ [ªl_
¨¶[?4¥Y4'OX
±zOÚ´l4[ªl"]ª4?
¨U¨°[c^OÛXÜYO¥Y[ª[ªlo²l''O}o¨+«;424X[ª4o[ Á o¨µ«}4 ¡
¤ ª4A]4[OX ¤ k¥}W  [?4¬?ª4WÛ9?l·}]Ý[ªl lOB[ª4k[ªlA«;Ã[_«4[O[O6[k[W?}
­RO[W?} l¡q R¡ ´ l¡q R¡q  4 l¡q R¡q k[lO[O[ l¬?WÛA?«}l[k[?4WÛDlO^4}l¬ ¡¤ ªl]W¬?ª[WÛ
W±a_]4[g4Þl[ Ok¥}WÛbW±a_}¥Y_&¨IlR4O&Þ[ªlg[Ok]]ª9'[_g¨©[ªl  ¥}WC[¾
ßOàá

âãWälåæ;ä4ç?ä
èOé4êëCì4íé4î ï;ðWëRê]ñRò í ò'ó[ôkó'èOò [ó íõè ò'ó[ôkó'èOò ê_ðôö4ò'èOò ÷ôkøtò ø]ö4éó[íõè lé ëCìlèOò ÷ ôð ölè
ùRúlûqüRûý
þ
ýOþ
ú
ú
üÿü ü
Cûý ò

 ô ð ò'è
ùRúlûqüRûý
þ
ýOþ

þ
üÿü ü þúlû£ú ò þ ÿCý  ô ð ò'è
ùRúlûqüRûý
þ
ýOþ

ú
þü þü ÿRû ò

ó'tø ölè
ùRúlûqüRûqü
þ
ýOþ
ú
þ
üþþ üú	
Cûý ò

 ôð ò'è
ùRúlûqüRûqü
þ
ýOþ

ü
ü
 üü
Cû ò

 ôð ò'è
ùRúlûqüRûqü
þ
ýOþ

þ
þú?ü þkú
þRû£ú ò
ü ÿ ó'øtlö è
ùRúlûqüRûqþ
þ
ýOþ
ú

ýú6þþ ü?ü
Cû ò

 ôð 'ò è
ùRúlûqüRûqþ
þ
ýOþ


ýþ ü
ýkû ò
þ 
ó'øtölè
ùRúlûqüRûý
ú
kþ

ú ýkü kÿ Cýkû ò

 ôð ò'è
ùRúlûqüRûý
ú
kþ

þ ýüCýOÿ þ  ý


ùRúlûqüRûý
ú
kþ

ú ý þ  ý


ùRúlûqüRûqü
ú
kþ

þ ýCý þ ú4ýkûý ò

 ôð ò'è
ùRúlûqüRûqü
ú
kþ

ü ýkú	 ÿCý Rûqÿ ò

 ôð ò'è
ùRúlûqüRûqü
ú
kþ

þ üüÿÿ ý?üþ üþCýkûqþ ò ýOÿ ó'øtölè
ùRúlûqüRûqþ
ú
kþ


ÿCý kü ýýkûqü ò

 ôð ò'è
ùRúlûqüRûqþ
ú
kþ


ýýOþ?þ  üþÿRû ò ?ÿ ó'øtölè
 ôkï}ðWè þ 4
ö éó[íõèOò  ëøÊó  è
ðWëCê[ñCòAëø]ð ì
è lôõ!}ðWè#"íWó  ó  è$!}ðôéèOé4êëRì}íélî  ø[ë?õ ù èOêó[íWë?é úlûqüRûqü ó  ôé%"íWó  ó  èò]íõ!}ðWè_ø"èOé}êëRì4í élî  ø[ë?õ
ù èOêó[íWë?é úlûqüRûqþ õ^ô'&ó  è_ø[è  ëø[è"ïYèoò[ölø(!4øtíò[íélî û   è"ì4í*)ºè_ø[èOé}êè+"aë?ö4ð ìò'è_èOõ ó'ëïºè"ì4ö4è"ó'ë^ó  è  ôêó
ó  ôkóGó  èÊðW'ë "ÞéRö4õIïYè_øµë  íéó'è_ø]é4ôðCò'ó[ôkó'èOò-,°ó  ø[è_è/.0íé.ó  è!}ðôé}ò  ø[ë?õ ù èOêó[íWë?é úlûqüRûqü+ ëø]êèOò0ó  è0!}ðôé
ó'ë`ò'ó[ô &&í é&ò'ë?õècë  ó  ècò[ó[ôkó'èOò  ëøzò'è_÷è_ø]ôð1!Yë?íé6ó[ò%ë  ó[íõè û32 ëø4!}ðôé}ò  ø]ë?õ ù èOêó[íë?é úlûqüRûqþ ó  è_ø[è#íò
élë.ò[ö4ê  ø[èOò'ó'ø]í êó[íWë?é&ôé4ìó  è#ò'è_ó[ò%ë  ë!Yè_ø]ôkó'ëøtò%èOé4ôkï;ðWèOì&ôkózèOôê  !Yë?íéóGë  ó[íõèõ&ô&^ïYèì4í*)ºè_ø[èOéó û
  èIêë?é4ò'ó'ø]ôíéó[òÊë?éò'ë?ðöló[íë?5
é !}ðôé4òôkø[èoó  è_ø[è  ëø[è.élëóôòcó[íWî  ó  ëøcó  èIò[í õ!}ðWè_ø2ø[è!}ø[èOò'èOéó[ôkó[íWë?é76
ôé4ìõ^ëø[èoò'èOôkø]ê  íòÊé4è_èOìlèOì  ë0ø 8;é4ì4í élî.9ô !}ðôé û
ÃíWó  ó  èOò'èï}ðëRê]ñR
ò "aëø]ð 9ì !4ø[ëï;ðWèOõ íé4ò[ó[ôé4êèOòGó  è#ò'ë?ðöló[íë?éë  ó  èò'è !;ôkø]ôkó':è !}ø[ëï}ðWèOõ^ò%íòG÷è_(ø &
èOôò;&  ëøcó  èïYèOò'ócê_ð ôò[ò[íê_ôð7!;ðôé4élè_ø]ò û   ôkó#õ^ôkñèOò#ó  èOò'è<!}ø[ëï}ðWèOõ^òì4í>=ê_ö4ðóÊíòÊó  ôkócó  è<!;ðôé4ò
ø[è !4ø]èOò'èOé6ó`ôð?ð !Yë?ò[ò[íWï;ðWè^è CèOê_öló[íWë?é4ò 6Gôé}ì¯ó  èêë?é}ò'ó'ø]ôíéó[ò.ë?é¯ó  $è !;ðôé4ò.ôkø[èXélëó.ôò`ó[íî  óôò`íé
ó  èIïºèOé}ê  õ^ôkø]ñRò#íé  ôkï}ðWè ü ëøíéó  èIò'è!}ôkøtôkó'è`ê_ð ôò[ò[íê_ôð@!}ðôé4é4í élîA!4ø[ëï}ðWèOõ&ò û B ë/"aè_÷è_ø'67"  èOé
êë?é4ò[í ìlè_ø]íélî`ó  ôkócó  èéRö4õIïºè_ø2ë  èOðWèOõ^èOé6ó[ò#íéó  èoø]èOò[ö4ðWó[íé4î !}ðôé4ò2íòÊø[èOðôkó[íW÷èO*ð &  íWî  ,C8  ó'è_èOéëø
õëø[è  ëøoó  èï;íWîîè_+ø !4ø[ëï}ðèOõ^Dò .côé4ìDó  è^élëó[íë?éDë  !}ð ôé4òíò"õIö}ê  õëø]è^êë?õ !}ðíê_ôkó'èOìó  ôéAíé
ê_ðôò[ò]íê_ôEð !}ðôé4é}íélFî 6Ró  èoø]ö4éó[íõèOò2ôkø]èélëóÊì4íò]ô !G!Yë?íé6ó[í élî û
ù ë?õ^è%ë  ó  èaëï}ò'è_ø[÷kôkó[íWë?é4òµôkïYë?öl@ó !;ðôéoò'èOôkø]ê  íéoë?öløUô !G!4ø]ë?ôê  ôkø[èzí é6ó'è_ø[èOò[ó[íélî Iû H ÷èOéó  ë?ölî 
ó  è_ø[èIôkø[èoó  ø[è_è JRö4ôéó[>í 8}è_ø]ò 6lë?öløÊó  è_ëø[èOõ  !4ø[ë(÷è_øìlëRèOòÊélëó !Yè_ø  ëø]õ ò'èOôkøtê  ë?é÷ôkø]í ôkï}ðWèO0ò JRö4ôé 
ó[>í 8}èOì^	ï &ó  ècó  íWø]ì`ë?é4èó  ôkóaø[è !4ø[èOò'èOéó !;ðôéè CèOê_öló[íWë?é4ò û   íòGíò%ïºèOê_ôö}ò'èÊó  :è !}ðô7é 6?ø]è !4ø[èOò'èOéó'èOì
ï&ó  è`ë?öló'è_ø]õ^ë?ò'ó÷ôkø]í ôkï}ðWèOò 6ºó'ëîè_ó  è_<ø "cíWó  ó  è`ö}é4íW÷è_ø]ò[ôð *ð &5Jö4ôéó[>í 8}èOìg÷kôkø]íôkï}ðèOò  ëøó  èêë?é 
ó[íélîèOé}ê_íWèOò 6+ö}é4Kí JRölèO*ð &ìlè_ó'è_øtõ^íélèó  è&è RèOê_öló[íë?éó  ôkóí ò  ë?ö}é4L
ì "íWó  ë?ö4óoò'èOôkø]ê Hû   í ò"íòoé4íêèOKð &





ë?M
é !;ôk9ø "íWó ó è ôêó^ó ôkóêë?é4ì4íó[íWë?é4ô4ð !}ðôé}é4íélîDíò`ë?ébó èò'èOêë?é4ì9ðWè_÷èOð2ë  ó  N
è !Yë?*ð &Célë?õ^íôð
 íWè_øtôkø]ê  &6}élëó2ë?éó  è"ó  íWø]ìXôòÊó  
è !4ø[è 8O5PQ7Pí éó  èoèOé4êëCì4íélî?ò2õ&íWî  óÊò]ölîîèOò'ó û
R òUò  'ë "céIíé  ôkï;ðWè ü 6ó  èzø]ö4éó[íõèOò  ëS
ø !}ðôéIîèOélè_ø]ôkó[íë?é.ê_ôé.ïYè%õ.ö4ê  ðWèOò]ò=ó  ôé.ðíé4èOôkø=ó'ëó  è
éRö4õïYè_øUë  íé4íWó[íôðRò'ó[ôkó'èOò Uû T ë?élè2ë  ó  è2èOôkø]ðK&Iêë?é4ì4íó[íWë?é4ôð!}ðôé4é}íélîcôðîëø]íWó  õ^ò0í ò0ôkï}ðWè
ó'ëoè   íWï}íWó
ò[íõ&íðôkøïYè  ô(÷Ríëø VYó  ôkó#í ò 6Yó  è &N!4ø[ëCì4ö4êWè !}ðôé4òcë  è X!Yë?élèOé6ó[í ôð+ðWèOé4îó  ôé}ìó  è_ø]è  ëø[èêë?é4ò]ö4õè
è X!ºë?é4èOé6ó[íôð4ó[íõèÊè_÷èOéë?é&ò[í õ!}ðWè0!4ø]ëï}ðWèOõ^ò0ðíñèÊó  èOò'è û   è  ô(÷ëø]ôkï}ðWècø]ö4éó[íõèOòGôkø[è#ì4ölè2ó'ëIë?ölø
YZ/[

\?]_^O`baFc	dOe	aFf*^OgheX]_^GiOf>aFfK]_^FjOkAlk/jO^O`

m(nFopq(orsutGq(p'voqwxrtOy*oroz	m({m(w*pz7|3}Fpq4o ~F{rtOy*opqUm(nFotGq(p_y*or9?wKzS{Oy*o+FzG{ *voo ~Xm;ozG(wKpzG
p?m(nFo9-{vXwKsGm(zG{rtGq(pX oGFqbom;pL-4} pzO(wKFoq{yKyp?m(nFo
m;qbFm(nXsuv{yKFo{(bw*zGroz	m(-m;p
m(nFoGzGw*voqbb{yKy*#G{z	m(w>Oov
{qbwx{Oy*o(G;mm;p#voqbwKC m(nG{m-{9tOyx{z5m(nG{m-nG{EoozCpGzON{ m(G{yKy*
q(o{DnFo0m(nFop{y7wKz${yKyE{;o|}GGq(m(nFoq0Fovoy*ptOr9ozm(0wKz#m(nFopq(orsutGq(p'vXwKzFm;obnOzGwKFo?Cpq:-4}
{zG5tOq(ptEp(w*m(w*pzG{yE({m(wx_{OwKyxw*m{qboyKw*¡oy*#m;pwKrtGqbp'vom(nFo(o+qbGz	m(wKro4¢Fq(m(nFoq|
£¤¥L¦O§¨_©¦Oª¬«®­@¯°
?pm(nAIopm3{zG±Xr9wKm(n²³´´µS{zG¶q(pq{zG·?pyKyKwKzO²³´´¸µItGq(o;oz	mI{yKpqbw*m(nGr9@Cpq3 pzGOw*m(w*pzG{y
tOyK{zOzGwKzFm(nG{m{q(oO{;opzm(nGoy*o{;ms pr9rw*m(roz	mpq¶tO{qbm(wK{y>supqbFoq3t_yK{zGzGwKzG:tO{qD{Gw*r5|?pm(n
{y*pqbwKm(nGr94¹?pq(¡$yxw*¡o+ pq(q(o;tEpzGGwxzFyK{((wK{yEt_yK{zGzGwKzGW{y*pqbwKm(nGr90Gz	m(wKyE{9(FOp{y7wK0¢Gy>_yKyKo
Wm(nFo0{tGt_yKwK{m(w*pzpE{zptEoqb{m;pq¶m(nG{m¶Fpo3zFpm¶nG{'vo{+GzGwx	Fo?pFm( pro	m(nG{mwKm(nFo0ptEoqb{m;pq
wKzFpzOFom;oqbr9wKzOwK;m(wK|»º4mm(nO{mt1pwxzmAm(nFoNFovoyKptOroz	mp:m(nFo5 pzGOw*m(w*pzG{y?tOyK{z¼wx(tOyKw*mm;p»{
zGr<Eoqp0;ot_{qb{m;o(FOtGq(pOy*or:m(nO{mW{q(o(py*vo»;ot_{qb{m;oy*So{bn½ pq(q(o;tEpzGGwxzF m;ppzFo9p
m(nFo:pFm( pro?p7m(nFo:zGpzGFom;oqbr9wxzGwK;m(wK4ptEoqb{m;pq'|¶nFotGqbpOy*or¾¹wKm(n9m(nGwKU{tGtGq(p{Dn#wx¶m(nG{m?m(nFo
(w*¿oUpÀ pzGGwKm(w*pzG{yFtOyx{zG{q(o:o ~tEpzFoz	m(wK{yOpzm(nFo-zGr<Eoq¶pIGzG oq(m({wKz	m(w*o{zG{?ozFoqD{m(wKzF
{N;pyxFm(w*pzLm({¡o{m<Eo;myKwKzGo{q+m(wKro9pzhm(nGo(w*¿o9p?m(nFo(pyKFm(w*pzÁ²¢O(G{yKy*o ~tEpzFoz	m(wK{yCµDIm(nGwK
¡XwKzGp7{y*pqbw*m(nGr3wKzGnFoq(oz	m(y* pzG(Gro{+yKpm¶p1 pr9tOFm({m(w*pzG{yGq(o;pFqb o|}OFq(m(nFoqbr9pq(opm;oz
m(nFo wKrtGqbp'voroz	mWp/voqm(nFo$m;qbw*vXwK{y¶ pzGGwKm(w*pzG{y¶t_yK{zGzGwKzGN{y*pqbw*m(nGrÂm(nG{mA(wKrt_y*ÃqboGG om(nFo
tGq(p_y*orÄm;p{zGrW1oq7pFyK{b(wK{ytOyx{zGzGwKzFUtGq(pOyKor9Em(nG{m@{q(oU;py*vo<(otO{qb{m;oy*wKÀ(r{yKyÅ|ÀnFo
¢{q(o<Eom;m;oq-m(nG{zÃm(nFo<m;qbwKvwK{y@{y*pqbw*m(nGrÆ¹nFozFovoq+;pr9o<p¶m(nFo pzm(wxzFozGw*o{q(oAw*q(q(oy*ov{z	mwKz
q(o{DnGwKzFm(nFo<p{yÅGpqw*Sm(nFo;ot_{qb{m;o<tOyx{zG0nG{vo<tO{q(m(wKz5 prrpz7|
·4wxr9{m;m(w¶om{yÅ|%²³´´ÇµWtOq(ptEp;o{z½{y*pqbw*m(nGrÂpq pzGOw*m(w*pzG{ytOyK{zGzGwxzF m(nG{mWozGroqD{m;o
m(nFo$;m({m;o#;t_{ o|Ã±m({q(m(wKzF5q(prÈm(nFop{y?;m({m;om(nFo$;om(<p0;m({m;oq(prÉ¹:nGwKbn»{Np{y?;m({m;o
wKAq(o{DnG{Oy*o¹w*m(nËÊÍÌÏÎÐ;m;otOpq#y*o(9{q(oÃ prtOFm;o7|¼ÑÄnFoz¼pq;pr9o5ÊÒm(nFo;om9wKzOyKGFo
{yKySwKzGw*m(wx{y@;m({m;oÀ{$tOyx{zÃnG{EoozCpOzG7|-GqbwKzF#m(nFoAoz	Gr9oqb{m(w*pz7Eo{bnh(m({m;o9wK:{b;pwx{m;o
¹w*m(nÁ{zMptEoqb{m(w*pzÁm(nG{m#wK{y*pzF%{»(nFpq(m;o;m#tO{m(nMm;p½{Ðp{y;m({m;o|ÔÓ:p'¹Ïm(nFoNp{yK${zÁEo
q(o{DnFoCq(prÏ{z	Np3m(nFoAwKzGw*m(wK{y7(m({m;o-	5q(otEo{m;oGyKN{tGtOy*XwKzFm(nFoptEoqb{m;pq-{(;pXwK{m;o¹w*m(n
m(nFoFq(q(oz	m#;m({m;o|Õº:#m(nFoÃzGrWEoq9p;m({m;o s{ m(w*pzÄtO{wKqb9wKzÁm(nFo;ot_yK{zG9wK#{#nOw*nÁ{#m(nFo
zGr<Eoq-p4;m({m;o@tOq(pOy*orÖwKzG(m({zG o+¹w*m(nOwK (m({m;o;tO{ o pzO(Grorpq(o9r9orpq(m(nO{zÐwK
yKw*¡oyKm;pEo9{'v
{wKyx{Oy*o|9IpÃ{yKy*ovXwK{m;om(nGwx+tGq(pOyKorÈ·4wKr9{m;m(wom{yÅ|9tGq(ptEp;om(nGoG;op4OwKzO{q(
FowKbw*pzGwx{qb{r9+²¢?q({zmÀ³´´µUpq?ozG pOwKzF<m(nGo;m({m;o s{ m(wKpz5m({Oy*o|¶4--0{q(o-wKzozGoqb{y
zFpm{t_{Oy*o+pSq(otGq(o;oz	m(wKzFo ~XtEpzFoz	m(wK{y7(w*¿o<O{m({9;m;qbG m(Gq(o0wKz5tEpy*XzFpr9wK{y1;tO{ o|
±Xrw*m(nW{zOWÑhoyx ²³´´Çµo ~m;ozG$×AØ7ÙÀÚGÛÀÚOÜÙÀÝL²¢4yKGrßÞÄ}GFqb;mG³´´àµIm;pnO{zGGy*o?GzG oq(m({wKz	m
{zG;ovoqb{ywKzGwKm(wK{yÀ;m({m;o|+nGo<tOyK{zOtGq(pXGG o	m(nFow*qt_yK{zGzFoq{q(o(o	FozO o:ppt1oqD{m;pqb
yKw*¡owxzNyK{((wx{y7tOyK{zGzOwKzFFOFm{:m(nFoo áEo m(pptEoqb{m;pqb:r9{ Eo< pzGGwKm(w*pzG{yEpz(pro¢{ m(
m(nFotOyx{zG+r9{h{DnGw*ovo9m(nFop{yxovozÐ¹:nFozh;m({q(m(wKzG5m(nFotOyK{zLo ~XoFm(w*pzÐwxzhGw>áEoq(ozm(m({m;o
pq<¹:nFozÐm(nFoqbo#wKzGpzGFom;oqbr9wxzGwK(r5| ±Xr9w*m(nÐ{zOÐÑhoyK%{yKy¶m(nGwx pzFpqbr9{z	m<tOyK{zOzGwKzFF|$nFow*q
tOyK{zOzGwKzF{y*pqbwKm(nGrâo ~XtOyKwKw*m(yK9q(otGq(o(ozm(wKzFpqbr9{m(w*pz pzÃ{yKy7o ~XoFm(w*pzGp¶{tOyK{zÀ|UnGwx0r9{
EotEp((wKOy*o¹nGoz9m(nFo-z	Or<Eoq?p@wKzGw*m(wx{yG;m({m;o0wK?(r9{yKyu	Ft$m;p{A pFt_y*op@Gp¿oz#pq0{n	OzGFq(o
pzË(r9{yKyUtGq(p_y*orÂwxzG;m({zG o3_Fm<pq9rpq(o  prtOy*o ~%tGq(pOy*orWw*mwKAzFpmCo{(wKOy*oEo{G(o$p
nGw*n5r9orpq(  pzG(GrtOm(w*pz7|3ãotGqbo;ozm(wxzF9 pzFpqbr9{z	mtOyK{zGzOwKzFAwKz pFqqb{ro¹?pq(¡5wK4o{;|
ä Gq$¹?pq(¡{zGÄ({m(wK_{_wKyKw*må½t_yK{zGzGwKzGÐ	æ{Fm;¿h{zG¬±oyxr9{zç²³´´W³´´¸µ {q(ohy*p;oy*
q(oyK{m;oÀ|¶ºÕr9{/;pqGw>áEoq(ozG o+wK?m(nG{m0¹?o{zNGwKq(o m(y*{GGq(o(4{rWObn5¹wxFoqUqD{zFo+pIt_yK{zGzGwKzG
tGq(p_y*or9A¹w*m(n¼zGpzGFom;oqbr9wxzGwK;m(wK$bnO{zFoÃ{zGÁ;ovoqb{ywxzGw*m(wK{y4;m({m;o|?o{G;op-m(nFoÃ{GFo
èéê

ëì*íFî/ï_íGðí

    	


  
       
	 
 
 

 "! # $	   %! 	&

#   
'  
+

*
 
 %! # ' ()!
  
 '  , 
  $	



 -
# 
 .  / 


0
	 1
 	  )!
2   	
3	 %4  5
' )!
 76  98 	;:
	


=< > 
,?@7A/B 	DCFEHGJIKEL
 	
M , # 
N 

	
 # # O<P  
  ( Q 
2


  



 
  (	 	

 	
 T
	


R
S $ )!
    /
  O U 
V	
 $ "

# W 
T
'	
X Q
OY  ' ;
	     2 O  #
Z ! 	 X $	
$ +
[	


\

/  
 / M
 ]  (	
U
 
 
  	  N

  
  ^
  
 
 
  1 	
[ 
(_  >
'M
 

ñòóFòôbõöx÷*øùú:ø(ûFòLüGô(ýþOö*òÿ
?ò õó ;ýö ò Gý½óFýø ÷Kó ñòóFòôbõö-þEòö*ýóFñ%ø;ýËø(ûFò ýÿ9üOö*ò F÷*øù öxõ
õöKö ;ý Fô ò Wý Gó òô(ø(õ÷xóøåù%õô(ò òöK÷Kÿ÷KóGõø;ò 7úý FôAø;ôbõó böKõø(÷*ýó
ýóø(õ÷xóËýóGö*ùhò F÷ ;ø;òó	ø(÷Kõö
Gõóø(÷ Oòô úõó 9ø(ûFò ;ò Gõó	ø(÷ Oò Uýýö*òõó ýôbÿ GöKõò:õô(òø;ô Gòò Xõ ø(öKù :ûFòó9ø(ûFò (õÿò ýôbÿ GöKõò
÷*ø(ûGý Fø3ø(ûFò Gõó	ø(÷ Oòô õô(ò (õø(÷ _õþOö*ò
Fôø;ôbõó (öKõø(÷Kýó ¶÷Kóø(ûGò ;ò õ ;ò ;ø(÷Köxö ýóø(õ÷xó9ø(ûFòÿýô(ò
ýÿüOöKò »ô(òüGô(ò (òóø(õø(÷*ýó½ý
ýó G÷*ø(÷*ýóGõöüOöKõó úSþ Fø<ýø(ûFòô ÷ ;ò$ø(ûFò$ô(ò Gö*ø(÷xóFñ ;òø ý
ýôbÿ GöKõò
õô(ò b÷Kÿ9÷KöKõô0õó  ü_öKõó õóNþEò ý Gó  þù$õ (õø(÷ _õþ_÷KöK÷*øåùõö*ñýôb÷*ø(ûOÿ
Oó Gõÿòó	ø(õö G÷ Eòô(òó ò0þEòø ?òòóø(ûFò (õø(÷ _õþ_÷KöK÷*øåù<õö*ñýôb÷*ø(ûOÿ ý
õ Fø õó òöxÿ9õóõó
ý Fôø(ûFòýô(òÿ uüOô(ý òô9÷ Wø(ûGõøø(ûFò ýôbÿ9òôú
Ïõó
@úSõô(ò$þOõ ;ò ½ýó%öKý õö ;òõô Dû
ûFò (òNõö*ñýôb÷*ø(ûGÿ Wôbòü1òõø;ò Oö*ù%ø;ôbù»ø;ýÐñ Fò ø;ô Fø(û õö Fò5õ b÷*ñóGÿòó	ø Aø(ûGõø (õø(÷ ù%ø(ûFò ;òø9ý
öKõ (ò
ø?óFý<ü1ý÷xóø¶ý ø(÷xÿò÷ ø(ûFòô(ò:õ<ñ Gõôbõó	ø;òò:ø(ûOõøUõöKö_õ (÷*ñóGÿ9òóø UûGõ òþEòòó ýó (÷ Fòô(ò 7ú
õó ø(ûFòô(ò ýô(òø(ûFò (ò9õö*ñýôb÷*ø(ûGÿ õôbòAóGýø õü_õþOö*òAý Gòø;òôbÿ9÷KóG÷xóFñø(ûFò Gó (õø(÷ _õþ_÷KöK÷*øåù$ý õ ;òø
ý öKõ (ò
óñòóFòôDõöÅú_þEò õ (òWö*ý õö ;òõô bûLõö*ñýôb÷*ø(ûOÿ
Fý$óFýøò XûGõ ;ø(÷ òö*ù ñý$ø(ûFô(ý FñûÃø(ûFò
;òõô Dû (üOõ òú_ø(ûGòù õóOóFýø Fòø;òôDÿ9÷KóFò :÷*ø(û òô(ø(õ÷Kó	øùø(ûGõø:õóýþ ò ø ÷*ø(ûNõ òô(ø(õ÷KóÃüGô(ýüEòô(øåù
Fýò ¶óFýø¶ò F÷ ;ø
ö*ý õö ;òõô Dû#õöKñýôb÷*ø(ûGÿ õó _ó 9õ ýó G÷*ø(÷*ýóGõöXü_öKõóAþ Fø¶÷*ø õóOóFýø Fòø;òôDÿ9÷KóFò
÷*ø
ýôbô(ò ø(óFò
÷*ø(ûFý Fø (ù ;ø;òÿõø(÷ õöKö*ù ýó (÷ Fòôb÷KóFñõöKö ýÿ<þO÷xóGõø(÷*ýó 0ý
ýó	ø(÷KóFñòó ÷Kò úOýóGöKù
ý Gó	ø;òô(ò FõÿüOö*ò 4ø(ûGõø (ûFý Ôõ<ü_öKõó#÷xó ýô(ô(ò ø õó þEò ý Gó
ûFòôbò ýô(ò-õø0ö*òõ ;ø4ø(ûFý ;ò-üOõôbø Uý
õö*ñýôb÷Kø(ûGÿ
ýô ýó G÷*ø(÷KýóGõöGüOöxõóGóG÷KóFñ+ø(ûOõø òôb÷ ùø(ûGõø4õWüOöKõó÷ ýô(ô(ò ø0ûGõ ò-ø;ýWþEò (ù ;ø;òÿõø(÷

`acb;de_f3g5h[ikjPdUe[iTlme[npo+h+qh_rsutvdHrw
\ òüGôbýü1ý(ò-õóGòx¬
 õüGüGô(ýõD û5ø;ý ýóG	 ÷Kø(÷*ýóGõöEüOöKõóOóG÷KóFñWø(ûGõø÷4þOõ;ò	Nýó ô(òüGô(ò;òó	ø(÷KóFñüOô(ýþOö*òÿ
÷Kó(ø(õó òIõ G
 õóø(÷"O! ò	0?& ýýö*òõó  ýôbÿG öKõò?õó	0b÷KóFñõóõF ø;ýÿ9õø;ò	 ø(ûFòýô(òÿSu< üGô(ý> òô  ýôU1! óG	 ÷KóFñ
üOöKõó$  N ûG÷-õüGüGô(ýõD û»÷-þEýø(ûLø(ûFòýôbòø(÷ õöKö*ùLõóL
	 üGôbõ ø(÷( õöKö*ù.? òöKö3ÿýø(÷
 õø;ò	  2 õ üGôDõ ø(÷ õö

ÿýø(÷" õø(÷*ýóT?
 òX;òò-ø(ûFò+ô(ò òó	ø/x ò4ý (õø(÷9!_õþO÷KöK÷Køù9õö*ñýôb÷Kø(ûGÿzy 6 õF ø980{Z: òöKÿõó7ú}|~~4 ÷Kó
 öKõb÷ õöFüOöKõóOóG÷KóFñ  N ûFòüGôbýþOö*òÿ¾ý  F
	 òø;òôbÿ÷KóG÷KóFñ+ø;ôF ø(ûO<P õöF ò3ý  G õóø(÷"O! ò	?& ýýö*òõó  ýôbÿG öKõò


÷3õ-ñòóFòôDõöK÷"8 õø(÷*ýóý ø(ûFò0üGôbýþOö*òÿçý bõø(÷)!_õþO÷xöK÷*øù<ý  üGôbýü1ýb÷*ø(÷*ýóGõö  ýôDÿG
 öxõò  2 ¶õ+ø(ûFòýôbòø(÷ õö
Y;ø(÷%!- õø(÷KýóU òñ÷" ò; ýÿüOö*òF ÷*øùô(òOö*øø(ûGõø0F	 òÿýó$;ø;ôbõø;ò9ø(ûGõø÷Kø÷+÷KóLñòóFòôbõöóFýø  òõb÷*þOö*ò
ø;ý(òX(õø(÷)!_õþ_÷KöK÷*øåùõö*ñýôb÷*ø(ûOÿ÷Kó] ýóO
	 ÷*ø(÷*ýóGõö1üOöKõóOóG÷KóFñ 
N ûO÷/?ýôQ	G÷%4Eòô#  ôbýÿÆòõôböx÷*òôV?ýôNýó
 ýó	G÷*ø(÷KýóGõöÀüOöxõóGóG÷KóFñ9÷xó.;òxòôbõöSô(ò(ü1ò ø ' óGöK÷"ò
ø(ûFò4üOöKõóOóG÷KóFñõö*ñýôD÷*ø(ûGÿ+ U õó	4
 õ#(õóF	 ôbõy  òýø[{X: ÿ9÷*ø(û7úO|~~M  ô(ùýô+{? ýöKöK÷xóúO|~~D ú
?ò/	Fý+óFýøô(ò	 ò1 ýó	G÷Kø(÷*ýóGõö	üOöKõóGóG÷xóFñø;ý-ø(ûFò/(÷xÿüOö*òôõ;òý  ü_öKõóGóG÷KóGñ/÷*ø(ûFýGøGó$ òô(ø(õ÷Kó	ø(÷*ò 
2 +(ûFý^ óAþ	ùWýF ô3ø(ûFòýô(òø(÷( õöGõóGõö*ùO(÷úø(ûO÷Sô(ò	 ø(÷*ýó=? ýG ö	 þEò0÷KöKö%< ÿ9ýø(÷"
 õø;òÀ	 úõ÷*ø3ÿý;ø¶öK÷" òöKù
õóGóFýøþEò	FýóFò4÷Kó<üEýö*ùXóFýÿ9÷xõöø(÷Kÿò  ó(ýÿò,õ(òûFòó0!_ó	G÷xóFñõüOöKõó÷Sòõ;ùúø(ûG÷(@ô(ò	$ ø(÷*ýó
ÿ9õk
 ò÷*ø òô(ù ý;ø(öKù  4 ÷xÿ9õø;ø(÷òøõö  y)|~~W ñ÷" ò5õó%õöKñýôb÷*ø(ûGÿÂø(ûGõøòóJG ÿ9òôbõø;òAø(ûFòT;ø(õø;ò
;üOõ ò?ý  õ ýó	G÷*ø(÷*ýóOõöüOöKõóGóO÷KóFñ0üGô(ýþ_ö*òÿ  N ûFò¶üOöKõó$U ýó;ø;ô ø;ò	þ	ù+ø(ûFò÷KôIõö*ñýôb÷Kø(ûGÿÔòXüOöK÷÷Kø(ö*ù
õ;ýO ÷Kõø;ò õó½ýü1òôDõø(÷*ýó
 ÷Kø(û»òx òô(ùu;ø(õø;òú¶õó%
	 ø(ûG÷<÷xóGûFòô(òó	ø(ö*ùhö*òõ	Wø;ýÃþ_÷*ñNüOöKõó$ Q øW÷óFýø
ö*òõô/:ûFòø(ûFòôø(ûFò&,Rßø;òDûGóG÷ Fò0ø(ûFòù üGôbýü1ý(ò-ÿõkò<ø(ûG÷  òõ(÷*þ_ö*ò  ýôV ýÿ9üOö*ò üGô(ýþOö*òÿ 
\ òûOõ ò;G	 òx òö*ýüEòh
	 õ üGô(ýø;ýøùüEò÷Kÿü_ö*òÿòó	ø(õø(÷*ýóLý  õ ø(ûGòýô(òÿ=u< üGô(ý^ òô  ýôR&Ò
 õóL
	 òM<

N
üEòôb÷Kÿòó	ø;ò	c
 ÷*ø(û üGôbýM	$ ÷KóFñ ýó$G	 ÷*ø(÷*ýóGõö1üOöxõó÷*ø(û ÷*ø ûGò+ô(òGö*ø4õô(ò+üOô(òöK÷Kÿ9÷xóGõô(ùúþ-F ø4ñ÷" ò
õY;ø(÷%!7 õø(÷*ýó ø;ý9ýF
 ôõüGüOô(ýõb û}[(÷KÿüOöKòþEòóD ûGÿ9õô#
 üGô(ýþOöKòÿ?ø(ûGõø/? ýG ö 
	 þEò  õôø;ý	ýO	 ÷%;xG ö*ø
 ýô;ýÿ9òý  ø(ûFò<òõôböx÷*òô ýó$G	 ÷*ø(÷*ýóGõö@üOöKõóGóGòô#õô(ò G ÷X ö*ùQ;ýö òÃ
	 ÷KóÃø(÷KÿòWø(ûGõø-÷'#FþOöK÷KóGòõôýó

W

\
ø(ûFò óJO
 ÿ<þEòô<ý ÷KóG÷*ø(÷Kõö_;ø(õø;ò÷Kó%ø(ûFò#üOô(ýþOö*òÿÂ÷Kó;ø(õó ò ò þEòöK÷*òx ò#ø(ûGõøWòX üGô(ò#(÷KóFñ
 ýóG	 ÷%<
ø(÷*ýóGõöüOöxõóGóG÷KóFñõ3õ-ø(ûFòýô(òÿ=u< üOô(ý>X
 ÷KóFñ-ø(õ9Aÿ9õk ò¶÷*øòõ(÷Kòô3ø;ý÷F	 òó	ø(÷  ù+ñòóGòôbõöFø;òb ûOóG÷ F òSø(ûGõø

þEòóFòO
! ø¶ø(ûGòV ýó;ø;ô#$ ø(÷*ýóý  ýóO	 ÷*ø(÷*ýóGõöFü_öKõóúõó$	 õö;ýWø;ýW÷G	 òóø(÷  ùø;òb ûGóG÷ F òø(ûGõø[ õóOóFýøUþEò
 ýóJ òóG÷*òó	ø(ö*ù òÿ<þEò	F	 ò5
	 ÷xó üOõô(ø(÷xG öxõô0ø(ûFòýô(òÿ=u< üGôbý>X ÷KóFñ  ôbõÿòx? ýôM 
^

,-$#3J$J3"$ O-¡$%3-3¢$£=¤£^¢$$
¥§¦3¨¦3©«ªU¬
­M®O¯±°M²J­´³±µ ©M¨±¶ ¯·¸3¯O¹
­M®O¯±°M²J­½·¸O°O¯´³±µ ©M¨¶ °
­M®O¯±°M²J­½·¸O°3¹À³±µ ©M¨¶ °
­M®O¯±°M²J­½·¸¹J¯´³±µ ©M¨¶ ¹

º3»½¼J·k¸¯M¹·¸
º3»½¼J·k¸3°M¯·¸
º3»½¼J·k¸3°O¹·¸
º3»½¼J·k¸$¹±¯·¸

¦3¨¾
¦3¨¾
¦3¨¾
¦3¨¾

µ©¿
¯ ³±µ
µ © °À³±µ
µ © °À³±µ
µ © ¹½³±µ

¹

©M¨¶
©M¨¶
©M¨¶
©M¨¶
¯

¹
¯

¥§¦3¨¦3©Á+¬
­M®O¯±°M²J­½·¸O°O¯´³±µ ©M¨¶ ¹¿³µ ©M¨¶ ° º3»½¼±·¸3°M¯½¼3³µ ©J¨±¶ ¹Â·¸3°O¹¿³±µ ©M¨¶ ¯
­M®O¯±°M²J­´³±µ ©M¨±¶ ¯·¸3¯O¹ º3»½¼J·k¸¯M¹·¸ ¦3¨¾ µ © ¯¿³±µ ©M¨¶ ¹
­M®O¯±°M²J­½·¸ ¦3¨¾ µ © °À³±µ ©M¨¶ ¹À³±µ ©M¨¶ ° º3»½¼J·k¸ ¦O¨¾ µ © °¼3³±µ ©M¨¶ ¹·k¸3°3¹
¥§¦3¨¦3©Ã_¬
­M®O¯±°M²J­½·¸3¯J°«³±µ ©M¨¶ ¯ º3»½¼J·k¸¯±°½·¸
­M®O¯±°M²J­´³±µ ©M¨±¶ ¯·¸3¯O¹ º3»½¼J·k¸¯M¹·¸
­M®O¯±°M²J­½·¸¹J¯´³±µ ©M¨¶ ¹ º3»½¼J·k¸$¹±¯·¸
­M®O¯±°M²J­½·¸¹±°«³±µ ©M¨¶ ¹ º3»½¼J·k¸$¹°½·¸
¥§¦3¨¦3©ÂÄ[¬
­M®O¯±°M²J­´³±µ ©M¨±¶ ¯·¸3¯O¹ º3»½¼J·k¸¯M¹·¸
­M®O¯±°M²J­½·¸¹±°«³±µ ©M¨¶ ¹ º3»½¼J·k¸$¹°½·¸
­M®O¯±°M²J­½·¸ ¦3¨¾ µ © ¯¿³±µ ©M¨¶ ¯´³±µ ©M¨¶ °
­M®O¯±°M²J­½·¸ ¦3¨¾ µ © °À³±µ ©M¨¶ ¹À³±µ ©M¨¶ °

¦3¨¾
¦3¨¾
¦3¨¾
¦3¨¾

µ©¿
¯ ³±µ
µ © ¯¿³±µ
µ © ¹½³±µ
µ © ¹½³±µ

¦3¨¾ µ © ¯¿³±µ
¦3¨¾ µ © ¹½³±µ
º3»½¼J·k¸ ¦O¨¾
º3»½¼J·k¸ ¦O¨¾

©M¨¶
©M¨¶
©M¨¶
©M¨¶
°

°
¯

¹

©M¨¶ ¹
©M¨¶ °
µ © ¯¼3³±µ M© ¨¶ °½·k¸¯J°
µ © °¼3³±µ ©M¨¶ 
¹ ·k¸3°3¹

ÅÆ"ÇÈ3ÉÊËJÌ_Í[ÎÏkÐ$Ñ"ÊÒTÓÔmÊxÉ#ÏkÕ9ÓÉÖ/×ØÓÉ/ÊÏÙ#ÚWÖ9ÕÏkÕ9Ê
ÛcÜ^ÝHÞßMà;áØâJãä$âOåuâMÞ7æ>ç
è ÚÆ(Ö'É#ÊÖ9ÊÏkÉ#Ù#Úé,ÏÖ0×ØÈÎ$Ò3ÊÒ
ÐJêWÕÚ3ÊëÊÈ3ÕÖÙ#ÚÊÅ3ÓÉ#ÖÙÚJÈ$Î3ÇÖ9ÇÊìSÊÆÎ$ÖÙ#ÚÏk×ØÕ=í3ÅîZïðËJñ è ÚÊ=ÏÈÕÚ3ÓÉ
ÏÑÖ9Ó=éVÆ(ÖÚ3ÊÖ,Õ9ÓSÕÚÏÎ3ò;ÕÚ3ÊzÅÆ(ÎÎÆÖÚTóÈÑ"ÕÈÉ#ÏÑ-ÅÓÈÎÒÏkÕÆ"ÓÎ]ÏÎ$ÒTÕÚ3ÊzÅÆ(ÎÎÆÖÚ;ô'ÙxÏÒÊì0êTÓ×í3ÙxÆ"ÊÎÙÊ
ÏÎÒXõUÊxÕ9Õ9ÊxÉ#ÖH×ØÓÉUÏÒÒ$Æ"ÕÆ"ÓÎÏÑ§ö-Î$ÏÎÙxÆÏÑkÖÈ3ÔÔmÓÉÕxñ÷VÓÑ"ÇÊxÉø+×ØÊÆ"×ØÊxÉ}òMÆÎ$ÒÑ"êVÚ3ÊÑÔ7ÊÒRé'Æ"ÕÚRÔÉÓMÓ×(ùPÉ#ÊÏÒÆÎ3Ç3ñ
úû_û1ü-ý_þ_ÿ´ú	Âû
5ü
}ý
íOÏìSÔ-Ñ"Ê/Ô$ÑÏÎ$Ö_×ØÓÈÎÒÐJêSÓÈ3É,ÕÚ3ÊxÓÉÊìSùPÔÉÓÊxÉ/ÏkÉ#Ê'ÇÆÊÎcÐmÊÑ"Ó^éXñÎ;ÕÚ3Ê'ö$É#Ö9Õ+Ô$ÉÓÐ$Ñ"Êì éVÆ"ÕÚ;ÕÚ3ÉÊxÊ
Ð$Ñ"ÓOÙòOÖ /ÕÚÊWÇÓÏÑzÆÖ;Õ9ÓFÚÏ Ê ô ÓÎÂîvÏÎÒî ÓÎ½óñ è Ú3ÊÆÎÆ"ÕÆ(ÏÑ/Ö9ÕÏkÕ9ÊÖ]ÏkÉÊ ÏÑÑ'ÕÚ3Ê
Ô7ÓÖ#ÖÆ"Ð$Ñ"Ê
ÙÓÎOö$ÇÈÉ#ÏkÕÆ"ÓÎÖ1Ó×ÕÚÊXÕÚ3ÉÊxÊXÐ-Ñ"ÓMÙ#òMÖñ è Ú3Ê0Ô$ÑÏÎ]ÊÎÙÓOÒÆÎÇÆÖ1ÕÚ3ÊXÓÎÊ0Ò3ÊÖÙÉ#ÆÐ7ÊÒ]Æ(ÎWíMÊÙÕÆ"ÓÎ3ñ ðMñ
ÏÎÒDÆ"ÕÚ$ÏÖ×ØÓÈ3É=Ö9ÕÏkÕ9ÊÖx
ñ ÎuÊÏÙ#ÚFÖÕÏkÕ9ÊTÏ
ÎMÈì0ÐmÊxÉÓ×/ÓÔmÊxÉ#ÏkÕ9ÓÉ#Ö=ÏkÉÊcÊÎÏkÐ$Ñ"Ê	Ò ÏÖ=Ò3ÊÖÙÉÆ"ÐmÊÒÆÎ
ÅÆ"ÇÈ3ÉÊ=ËJñ è ÚÊXÊ MÊÙxÈÕÆ"ÓÎ.Ó×ÕÚ3Ê0Ô$ÑÏÎQÖ9ÕÏkÉ#ÕÖV×ØÉÓì ÖÕÏkÕ9Ê !-ÏÎ$ÒQÕÚ3ÊXÇÓÏÑÆÖ1É#ÊÏÙ#Ú3ÊÒ
ÏkÕVÕÆì"Ê 3ñ
ôÕÊ ÊxÉêcÔ7ÓÆ(Î±Õ[Ó×UÕÆìSÊRÏÕ9É#ÏÎÖÆÕÆ"ÓÎÕ9ÓSÏ=ÖÈÙxÙÊÖ#Ö9ÓÉ/Ö9ÕÏkÕ9ÊXÆÖ,ìÏÒ3ÊRÓÎcÕÚ3ÊRÐ$ÏÖÆÖ[Ó×UÕ9ÉÈ3ÕÚOù kÏÑÈ3ÊÖ
Ó×/× ÏÙÕ$
Ö #&%!')(*FÕÚ$ÏkÕ=ÏkÉ#ÊcÒ3Êö7Î3ÊÒÐM+
ê #,%!'-(.*+/ 01%!'-(.*324#5687!91(;:ñ è Ú3Ê;Õ9ÉÏÎÖÆ"ÕÆ"ÓÎ×ØÈ$ÎÙÕÆ"ÓÎ
ÆÖ0ÇÆ ÊÎÆÎ è ÏkÐ-Ñ"<Ê 3=
ñ )ÎÏÑÑ_Ê MÊÙxÈ3ÕÆÓÎÖ0Ó×ÕÚ3Ê;Ô$ÑÏ	Î Õ9É#ÏÎÖÆÕÆ"ÓÎÖXÕÚÉÓÈ3ÇÚÕÚÊÖÏìSÊTÖ9Ê >MÈ3ÊÎÙÊ
!@?) )
ð AcÓ×Ö9ÕÏkÕ9ÊÖÏkÉÊ0ìÏÒ3Êñ
è ÚÊ[Ö9ÊÙÓÎÒÔÉ#ÓÐ$Ñ"Êì¿Æ(ÎÖ9ÕÏÎÙÊÚÏÖ× ÓÈ3ÉÐ$Ñ"ÓOÙòOÖxñ B ÊÇÆ Ê,Ï'Ô$ÑÏÎÓÐÕÏÆÎÊÒ0éVÆÕÚXÕÚ3Ê,ÊÎÙÓOÒÆÎ3Ç
ÆÎíMÊÙÕÆ"ÓC
Î 3ñ ðMñ ðMñ è Ú3Ê=ÇÓÏÑ+ÆÖÕ9ÓQÚÏ Ê;ôpÓÎ Dî Hî´ÓÎDó }ÏÎÒóÀÓÎ ëñ è Ú3ÊSÆÎÆ"ÕÆ(ÏÑÖ9ÕÏkÕ9ÊÖÏkÉÊ
EFHG

IJKMLHNOKQPRK

S1T&UWVQX8YS8YZRV

[\Q]V

^`_ba

c,d!e)fhg

^`_ba

ijc,d!e)fhg

kl_bk

c,d!e)mng

kl_po

ijc,d!e)mng

al_bk

c,d!e)mng

al_bk

ijc,d!e)mng

oh_bk

c,d!e)mng

oh_q^

ijc,d!e)mng

r U!sut]

oMvr T,UWVQX8YS8YZRVwyxQVQzS8YZRV

{}|M~R|M
))-WM- )~R 

M-!QW |M~W    )~R 

))-WM )~R 

M-!Q)W |M~W    )~R 

))-WM )~R 

M-!QRW |M~W    )~R 

))-W )~R 

M-!M)W |M~W    )~R 

))-WM )~R 

M-!MW |M~W    )~R 

))-W- )~R 

M-!MW |M~W    )~R 

))-WQ- )~R 

M-!uW |M~W    )~R 

))-WQ )~R 

M-!uRW |M~W    )~R 

))-WQR )~R 

M-!uWW |M~W    )~R 

))-W)M )~R 

M-!W |M~W    )~R 

))-W) )~R 

M-!)W |M~W    )~R 

))-W)Q )~R 

M-!MW |M~W    )~R 

{}|M~R|M
))-W )~R R )~R 

MWM)MR -~ WM )~R 

))-W |M~W    )~R  )~R 

M-! |~W   M )~R !M

))-W |M~W    )~R  )~R 

M-! |~W   M )~R !uR

{}|M~R|M 
))-W |M~W    )~R  )~R 

¡ Y¢RxMT8]l£ v¤

M-! |~W   M )~R !Q-

VQU!sut]¥3ZW¦§]T&U!S1ZWT,X¨w©ZWT¨]UWz&\.X1S8U!S1]

UWttS8\M]ª¦§ZRX8X8YsOt]lzZRV«u¢RxQT&U!S8YZRVQXDZWwS8\Q]hw©ZRxMT¬sutZz8­X®

r

\Q]¯¦ut°UWV.\QUWX¬S8\QT8]]nX1S8U!S1]X®

r

\M]¯]VuU!sut]¥

ZW¦§]T&U!S1ZWT&XZWw±]UWz&\3X1S8U!S1];²¬U!T8]¬U!¦Q¦utY]¥nT8]¦§]U!S1]¥Qt³nxQV-S8YtQVMZh´nZWT8]DZW¦§]T&U!S1ZWT&XµU!T8]DU!¦u¦utYzU!sut]W¶UWVQ¥
S8\M]V3UhS1T&UWVQX8YS8YZRV·S1ZªS8\M];X8xuzz]X8X1ZWTjX1S8U!S1]l²¹¸
U!T8]¯¢RY¼W]V.Y°V

¡ Y¢RxMT8]¯£)®j½\M]V]¾YS8Y°VM¢·X1S8U!S1]

^

YXµ´<UW¥M]W® r

\Q]`]VQU!sOt]¥·ZW¦§]T&U!S1ZWT,Xºw»ZWTº]UWz&\X1S8U!S1]

^ ¶OUWttsutZz8­XU!T8]¯ZRV$S8\M]¯S8U!sut]W®º¿ÀVX1S8U!S1]

k ¶u«OT&X1SÁ

YX`´nZ¼W]¥ZRV.S1ZW¦.ZWwÂUWVQ¥ÄÃY°X`´nZH¼W]¥ZRV$S1ZW¦CZWwÅh¶OUWVQ¥.S8\M]VÁYX´<Z¼W]¥w»T&ZR´ÆÂZRV.S1ZW¦.ZWw
ÃD® ¡ YVQUWt°t³

YV=X8S8U!S1]

a ¶uÂYXj´nZH¼W]¥ZRV=S1ZW¦ZWwÁD®

ÇHÈÉ

ÊµËOÌuÍ&ÎMÏ-ÐuÑ-ÎMÒÌuÓÄÑËOÌQÔuÒÕÎMÒËOÌMÖu×ªØR×HÖuÌuÍ

ÙCÚQÛÀÚQÜRÚuÝÞÚuß
à;âW
á ã8äå1æ1ç èR
á =
é ê§ëDìêuíîïð§ïñòê à

 

ìóÀôõWõWöR÷,ìµëµèRénøOñïùúæüû·ç&ïå8ýQñæ8åþ»èWç`ÿ ¬ÿ

  !#"$%&'ê)((ó *-÷,ê,+-Wö/.0+WöWö)ì

21 3

54 26 879: 1 â3Wê8;


à

âWñã â â!çê Mì ìê
à ïç&ñ°ú 	ì
à

ñýQé=ê lì ìêHí

à

ç8ûRâ -æê

à

û)ñ°â

QúMì	



øuñâ

=<¬â!ðuâ!ç&çèM1 ê>4MìóÀôõWõWöR÷,ì@?ABC&DAE
	#GFH 

ìêí

CWïçJIK¹ïç&ñâMê

ìnÿ)øQç&ú

L M6 ONuýMç&å1æêP ìM6ìóÀôõWõQW÷,ìNQâWå1æøOñâCQúCæSRMç&èRýR¬øuñâCuúTWç&â!øRlâuâWñû)å&úåìUVAB WX&D
  !#"$%&'ê)Y[Z óÀôBI\-R÷,ê,-]ô'.0^__ì

 a`"ì5b¨ìjóÀôõWõ-R÷,ìÿ)ûélð§èRñúã à è)èRñïâé<âQúøuýQñâ!æ8úèdcúæSRèWçGeMïç8ïDeðuúQâ!ç&ûfeQïãúå8úègeQúâLI
 ç,âWé<åìTUh8ij
	 $"@?ABkHLl ê8m/nºóo^R÷,ê,-Wõ^/.0^ôD])ì
W

CeMïçêqp;ìóÀôõWõL*-÷,ìrpsRMï$ãèRénøOýMæ8â!æ8úèQâWñ¨ãèRé<øuñïùMúæüûèWþDøQç8èWø§èRå8úæ8úèuâWñjÿps`s;Etµÿøuñ°âCQúMì
UuAB WX&%o   !#"$%&' ê)vY óÀôBI\R- ÷,ê¹ôDW+ ö/.0-_M* ì

e

XP

< /w  Ge T¯ìê¨í ÿã'RQâ!ïç8þ êTPìDóÀôõWõ]R÷,ìx	+âWñ#WèWç&úæSRué æ1è ï%w!âWñýQâ!æ1ïzy)ýQâ-æ8ú|{uïDe

};~AE
D&BGG0"l
E 9a B' z
	
DDAS&'@
dUVAB WX&D
  !#"$%&' UVU	U ' Y@z z 
DDAS&B
  C
k kUqo&Go
l
EUVA 
 WX&D   !#"$%&'@  U	U ' YHêMøuø±ì-+-/.0-+Q-ì

ëºâ MèRñ°úòê ìê ¬úè !â Qâ!ç uúòê
à è)èRñïâ Ä©þ èWç&éhýQñâ!ïWì

lìês`è/wWïç&úòêsPìêíp ç&â/wWïç&å1èMêtìDóÀôõWõ]R÷,ì`ýQæ1èRé<â!æ8úã à 7u7	IðuâWå1ïDeWïDMïç,â!æ8úè èWþ
ýQú#W
w ïç&å8âWñøuñâQå úMèIeMïæ1ïç&é<úuúå1æ8úãeMèRé·âWúQåìr;ExAE
/&'GG $"l
E z G  
o

D%%AJ%&'
UuAB WX&%o   |"0&B UVU	U ' Y@ % 
DDAS&'

 
kLkUT[!o&G
Cl}
EVUVA WX&%o  %#"$&'  UVU ' Y} êQøQø±ìC]!Q ö/.0]] ô!ì

ëºúé·â!æ1æ8úòê

7¬âDwúåêP ìê6±èWïé·âC	ê<ªìêí 6±è/wWïñ°âCe	ê7¯ì§óÀôõ+-R÷,ì>é<âWã'RQúMï¨øuç8èWç&âWé

}9Co&Go
lh
E ¡U8iCê8¢!ê^WõL*L.0^WõQ-ì

SR

þ©èWçæ QïèWç8ïé

/w Mì

øuç8è ú

NMç8ïïé·â	ê	4Mìa£ì¬óÀôõWõWöR÷,ì  	AJ
k%% l
dAE
B
Ll'o
V?lWT[¤ !H?,SAE&%¥UV¦"[
AB  $§l
tX	
R ì¨h
7 ìQæSMR ïå8ú°åêC©	u
 ú#Ww ïç&å8úæ û·èWþtïDCQå1ûñ#w!âQúâì
ì

<Dïç8ï%wúQúêalìêí ÿMãGR)ýMð§ïç8æêa6ì¨óÀôõWõ]R÷,ìO;EMþ©ïç8ç&úCå1æ8â!æ1ï$ãèQå8æ1ç&âWú-æ8ånþ»èWçeQèRé<âWúIüúeMïø§ïDCeMïD-æ
øOñâCQ
 úCM ì;EqAJ
D&''S $"l
J@ @a G% §o

D%%AJ%&'
OUVAB WX&D  % 
"0&B UVU	U ' Y f% O
D%%AJ%&'
  C
kL khUqo&Go
l@
J§UVAB WX&D
  !#"$%&'@  U	U ' YH êMøQøìuõR_ ö/). õôD)- ì
<Dç8ïïD±ê¹ëDìµóÀôõ+WõR÷,ìzøuøuñúãâ!æ8úè èWþµæSRQïèWç8ïé9IøQç8èMw)úª$æ1èøuç8èWðuñïé å8èRñ#w)úªMì;Ed£ âWñäWïçê57hì«b¨ìê
í
î`èWç8æ1è	
 ê
6 ìX
P ìDóbau
e åì ÷,ê	qAJ
D&''S $"l
E (Ll  ABo
u¬
@
/%%AJ%&'


UuAB WX&%o  !#"$%&' êMøQø±ì- ôõ/.0-W^ õ£ âWåSQ
R úW æ1è±
 ê7"ëDìC£úññúâWé®­"âWýQþ©é<â	ì
­"âWýMæJ3Wê¯¯ìêQíÿïñé<â	ê à ì	óÀôõWõ-R÷,ìtñâCQúªlâWåjå8â!æ8úåJ{Oâ!ðuúñúæüûWì2;Eî`ïýQé<â	ê à ì±óbae±ì ÷,êCAE
/&'GG 
 $"l
E ([Z °qAJ
'S±
D%%AJ%&'
OUVAB WX&D  %#"$&'êøQø±ì^WöWõ/.0^+^£úïD	ê
DýQå1æ1ç,úâìW
4 èRC
£ úñïûí ÿ)èu
 åì
­"âWýMæJ3Wê,¯¯ìê§í ÿ)ïñé<â±ê à ìóÀôõWõ+R÷,ìutýQåGRQúnæSRMïhïD$wWïñèWø§ï²µøOñâCQúCMêMøQç8èWø§èRå8úæ8úèuâWñ±ñèRúã!ê§âCe
å8æ1è)ã'Q
R âWå1æ8úãhå1ïâ!ç&ã'R	ìq;~fqAJ
D&''S $"lh
E§ >[ AB' §o

DDAS&'
UVAB WX&D
  !#"$%&' }°q#"$   C
kk9UT!o&Go
l
JUuAB WX&%o  %|"0&Bz
D%%A 
%&' êQøQø±ì	ôWôõL*LO
. ôD-M_ ôh.
P ïDQ
 ñè
t â!ç8ä ê ëºâWñúþ»èWçGu
 úâì0VV;
t ç&ïå8å	³}psMR ïP;Ep´
t ç8ïå&åì
µM¶·

¸¹#º»M¼ºC½º

¾>¿À	ÁVÂTÃgÂ#ÀsÄÆÅVÇ$ÈÉCÊËÌËÇ±ÍEÎDÏÏÐÑ'ÂÓÒ	ÔDÉÕG¿ÖJ×S¿ªØ%ÖÈËÖSÔDÙÛÚÇxÉCÇC¿×ÜCÕSÚÜËÌË×S¿#ÚÇÛÝ ÚÕÖSË×S¿ÖEÞËÈ¿Ê¿#×\ß
ÜÕSÚÈÊ#ÔDàÖDÂâáEÇ´ãqäJåDæ'ç'çSèé ê$ëìdåEífî ïçdð[ñî ïOò'êîç%ä'êóîéåêóô¡õåéêîöåêDíDçäSçêæBçåêx÷VäBîé øXæDéóô
ò'êîçô ô!é#ë$ç%êæ'ç%ÀCÜCÜ8ÂCùúú/û0ùÐ0Î9ü	ËÌÚMßËÀ,ý[ËÜËÇ2Â
ÃØ%Å	ÊÊÔDÖJ×JÔ%ÕDÀuþ§ÂsÅ§Â#ÀÄ ÿsÚÖSÔDÇ[ÈÊª¿#×J×%ÀVþ}ÂÍEÎDÏÏÎ/Ñ'Â  ßÖJ×JÔDàË×S¿ªØÇCÚÇCÊ¿ÇÔDËÕ@ÜÊËÇÇC¿ÇÌÂ±áEÇrþVÔDËÇ2À
Ø ¡Ô%Ú 	Ç2ÀhÂÍ	aÙCÖ%Â!Ñ'À$ãäEå/æ'çGçGèé ê$ëì	åEísî ïç
î ï§óîéåêóô>öåêDíDçäSçêæ'çVåê÷VäBîé øXæDéóô
 ÂL¾aÂ#ÀÄÃ
ò'êîçô ô!é#ë$ç%êæ'ç%ÀCÜCÜ8ÂCúù Lû0úùÏ@Å	ÇË ÔD¿àÀÁqËÊ¿ÝÚÕGÇ¿ËÂ  Ô¡Ãzá  ÕSÔDÖSÖ%Â


Ô%Ú×%ÀÃgÂÅ§Â#ÀÄ  à¿#×2Àþ}ÂsÂ>ÍEÎDÏÏÑ'ÂÁTÚÇCÙ¿#×S¿#ÚÇCËÊ,ÇÚÇCÊª¿ÇÔDËÕqÜÊËÇCÇ¿ÇÌÂ5á~ÇÒ	ÔDÇCÙCÊÔ%ÕDÀýÂ>Í	XÙ2Â!Ñ'À
ãäEå/æ'çGçGèé ê$ëìåEíhî ïçaéä'ìBîqò'êîçäBêóîéoåêóô	öåêDíDçäSçêæBç@åêf÷Väîé øXæ%éoóô>ò'êîçô ôé|ë0çêæBç§ãô|óêêCéê0ë
 ìîç }ì'ÀÜCÜ8Â2
Î Ï/ûÎDÏÐ  ËÇÃË×JÔ%ÚÀ,ÁqËÊª¿#ÝÚÕ'ÇC¿ËÂÃzÚÕSÌËÇ ËÉÝàËÇCÇ  ÉÈÊ¿!Ö Ô%ÕGÖ%Â


ÕGßÚÕDÀ¾Â#ÀÄ ÁTÚÊÊ¿ªÇCÖ%À#"9ÂÍEÎDÏÏúÑ'Â  ÊËÇCÇ¿ÇÌÝ ÚÕhØÚÇ[×S¿ÇCÌÔDÇCØ%¿#ÔDÖ$Å
õ)å (äBêóô«åJíV÷Väîé øXæDéóôò'êîçô ô!é#ë$ç%êæ'ç+*çBì%çGóäJæï[À-,ÀÐDû0ùùÏ0Â

ÙÔDØ%¿ÖS¿ÚÇ&%ÈËÖJÔDÙgËÜCÜCÕSÚËØ'2Â

ÿ¿ªÇ[×SËÇÔDÇ8À0ýÂ,ÍEÎDÏÏÑ'Â)ÅxÜÊªËÇCÇC¿ÇÌ¡ËÊ#ÌÚÕ'¿#×Cà ÇCÚ×aÈËÖJÔDÙÚÇÙ¿#ÕSÔDØ×S¿#ÚÇCËÊÖJÔDËÕGØ!8Â2á~ÇÁTÚCÇ2À0ÅÂ."}Â#À
 !Ø 0ÉÈ,Ô%ÕS×%À$¾a/
Â hÂ#ÀÄ  CËÜ¿#ÕSÚÀ  ÂÁVÂ	Í XÙCÖ%Â!Ñ'Àãä'é êæDé10ôçBì¡åEí32§êå)4ô#çGèDë$ç5*sç60äJçì%çêîóîéåêfóêè
*çSóLì%åêCé ê$8
ë 7¡ãqäJåDæBçGçSèéê$ëìhåJíî ïç  :é 9î ïò'êîçäBêóîéoåêóôsöåê/í%ç%äJç%êæ'<
ç ;	2+*>= 
?@MÀÜCÜ8ÂúÎ/ÐDû0ú 
S
Õ
D
Ô
$
Ç
J
×

Ú

À
~
á
S
×

Ë
#
Ê

ß

Â

Ã

Ú
S
Õ

Ì

Ë
Ç
A



Ë

É
Ý

à

Ë
C
Ç
Ç

É

È

Ê

¿
Ö



%
Ô
'
Õ
%
Ö
Â


ÿ¿ªÇ[×SËÇÔDÇ8ÀýCÂ0ÍEÎDÏÏÏÑ'ÂáEàhÜCÕSÚCBÔDàhÔDÇ[×SÖ«×JÚV×ÔTÔBLËÊÉË×S¿#ÚÇÚÝD0ÉCËÇ$×S¿|ÞÔDÙFEXÚ0ÚÊ#ÔDËÇ§ÝÚÕ'à§ÉCÊªËÔÂ[áEÇ9ãäEå)G
æBçGçGèéê0ëìåEíuî ïç/ð Hî ïò'êîçäBêóîéoåêóô8õåé êîöåê/í%ç%äJç%êæ'ç§åê÷uäBîé øXæ%éoóôò'êîç%ôôé|ë0çêæBçÂÃzÚÕGÌËÇ
ËÉÝ àËÇCÇ  ÉÈÊ¿Ö Ô%Õ'Ö%Â>×JÚ@ËÜCÜ,ÔDËÕDÂ
ÿsÚÖSÔDÇCÖSØ!CÔD¿Ç2À  ÂýCÂÍEÎDÏÎ/Ñ'Â  ÊËÇ¥ÖJßÇ[×ÔDÖG¿Ö$Å Ê#ÚÌ¿Ø%ËÊqÜ,Ô%ÕGÖSÜÔDØ×S¿IBÔÂdá~ÇOÒVËDßÔDÖDÀ  ÂaýÂsÍ	XÙ2Â!Ñ'À
ãäEå/æ'çGçGèé ê$ëìåEíî ïçKJDî ïdò'êîçäBêóîéoåêóôqõåé êîöåêDíDçäSçêæBçåêg÷uäBîé øXæ%éoóôò'êîçô ô!é#ë$ç%êæ'ç%ÀÜCÜ8Â
ùùÎ'û0ùùÐ¾>ÚÖsÅ	Ê×JÚÖ%ÀÁqËÊ¿ÝÚÕGÇ¿Ë/Â Lx¿ÊÊª¿ËM
à ËÉÝàËÇCÇ2Â


à¿×2Àþ}Â8sÂ#À$ÄNLÔDÊªÙ2À$þ}Â  ÂÍEÎDÏÏÑ'Â)ÁqÚÇÝÚÕ'àËÇ[×O"uÕGËÜÜÊªËÇ2ÂCáEÇãqäJåDæ'ç'çSèé ê$ëì¡åEí	î ïçPé íîçGçêî ï
§óîéoåêóôVöåêDíDçäSçêæBçåê÷uäBîé øXæ%éoóô)ò'êîç%ôôé#ë$çêæ'çA; ÷V÷	÷Vò'GQ
?@óêèî ïçKRç%êî ïOöåêDí%ç%äJç%êæ'ç
åêò'êê)å SLóîTé SçU
÷ 080ô!éoæGóîéåêCì}åEíV÷Väîé øXæ%éoóôò'êîç%ôôé#ë$çêæ'V
ç ; òJ÷V÷	'ò GW
?@LÀCÜCÜ8X
Â Ï/Yû Ïú0Â

ZC[\

Factorized First Order

Factorized Second Order
300

120
250
200

Frequency

Frequency

100
80

150

60
40

100

20

50

0
0

0.02

0.04

0.06
0.08
absolute error

0.1

0.12

0
0

0.14

0.02

Decimatable First Order

0.04

0.06
0.08
absolute error

0.1

0.12

0.14

0.12

0.14

Decimatable Second Order

150

500
400
Frequency

Frequency

100

300
200

50

100
0
0

0.02

0.04

0.06
0.08
absolute error

0.1

0.12

0.14

0
0

0.02

0.04

0.06
0.08
absolute error

0.1

Factorised Paired First and Second Order

Decimatable Paired First and Second Order

60

60
Frequency

80

Frequency

80

40

40

20

0
0

20

0.02

0.04
0.06
absolute error

0.08

0.1

0
0

0.02

0.04
0.06
absolute error

0.08

0.1

Factorized First Order estimates of first moments

Factorized Second Order estimates of first moments

150

350
300
250
Frequency

Frequency

100

200
150

50

100
50

0
0

0.02

0.04
0.06
absolute error

0.08

0
0

0.1

Factorized First Order estimates of correlations

0.02

0.04
0.06
absolute error

0.08

0.1

Factorized Second Order estimates of correlations
350

150
300
Frequency

Frequency

250
100

200
150

50

100
50

0
0

0.02

0.04

0.06
0.08
absolute error

0.1

0.12

0
0

0.02

0.04

0.06
0.08
absolute error

0.1

0.12

Learning using second order estimates

Learning using standard MF estimates
2

total pattern likelihood

total pattern likelihood

2

1.5

1

0.5

0
0

10

20
time

30

40

1.5

1

0.5

0
0

50

100
time

150

200

Journal of Articial Intelligence Research 10 (1999) 291-322

Submitted 10/98; published 5/99

Variational Probabilistic Inference
and the QMR-DT Network

Tommi S. Jaakkola

tommi@ai.mit.edu

Articial Intelligence Laboratory,
Massachusetts Institute of Technology,
Cambridge, MA 02139 USA

Michael I. Jordan

Computer Science Division and Department of Statistics,
University of California,
Berkeley, CA 94720-1776 USA

jordan@cs.berkeley.edu

Abstract

We describe a variational approximation method for ecient inference in large-scale
probabilistic models. Variational methods are deterministic procedures that provide approximations to marginal and conditional probabilities of interest. They provide alternatives to approximate inference methods based on stochastic sampling or search. We describe
a variational approach to the problem of diagnostic inference in the \Quick Medical Reference" (QMR) network. The QMR network is a large-scale probabilistic graphical model
built on statistical and expert knowledge. Exact probabilistic inference is infeasible in this
model for all but a small set of cases. We evaluate our variational inference algorithm on a
large set of diagnostic test cases, comparing the algorithm to a state-of-the-art stochastic
sampling method.

1. Introduction
Probabilistic models have become increasingly prevalent in AI in recent years. Beyond
the signicant representational advantages of probability theory, including guarantees of
consistency and a naturalness at combining diverse sources of knowledge (Pearl, 1988),
the discovery of general exact inference algorithms has been principally responsible for the
rapid growth in probabilistic AI (see, e.g., Lauritzen & Spiegelhalter, 1988; Pearl, 1988;
Shenoy, 1992). These exact inference methods greatly expand the range of models that can
be treated within the probabilistic framework and provide a unifying perspective on the
general problem of probabilistic computation in graphical models.
Probability theory can be viewed as a combinatorial calculus that instructs us in how
to merge the probabilities of sets of events into probabilities of composites. The key operation is that of marginalization, which involves summing (or integrating) over the values
of variables. Exact inference algorithms essentially nd ways to perform as few sums as
possible during marginalization operations. In terms of the graphical representation of
probability distributions|in which random variables correspond to nodes and conditional
independencies are expressed as missing edges between nodes|exact inference algorithms
dene a notion of \locality" (for example as cliques in an appropriately dened graph), and
attempt to restrict summation operators to locally dened sets of nodes.
c 1999 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

Jaakkola & Jordan

While this approach manages to stave o the exponential explosion of exact probabilistic
computation, such an exponential explosion is inevitable for any calculus that explicitly
performs summations over sets of nodes. That is, there are models of interest in which
\local" is overly large (see Jordan, et al., in press). From this point of view, it is perhaps
not surprising that exact inference is NP-hard (Cooper, 1990).
In this paper we discuss the inference problem for a particular large-scale graphical
model, the Quick Medical Reference (QMR) model.1 The QMR model consists of a combination of statistical and expert knowledge for approximately 600 signicant diseases and
approximately 4000 ndings. In the probabilistic formulation of the model (the QMR-DT),
the diseases and the ndings are arranged in a bi-partite graph, and the diagnosis problem
is to infer a probability distribution for the diseases given a subset of ndings. Given that
each nding is generally relevant to a wide variety of diseases, the graph underlying the
QMR-DT is dense, reecting high-order stochastic dependencies. The computational complexity of treating these dependencies exactly can be characterized in terms of the size of
the maximal clique of the \moralized" graph (see, e.g., Dechter, 1998; Lauritzen & Spiegelhalter, 1988). In particular, the running time is exponential in this measure of size. For the
QMR-DT, considering the standardized \clinocopathologic conference" (CPC) cases that
we discuss below, we nd that the median size of the maximal clique of the moralized graph
is 151.5 nodes. This rules out the use of general exact algorithms for the QMR-DT.
The general algorithms do not take advantage of the particular parametric form of the
probability distributions at the nodes of the graph, and it is conceivable that additional
factorizations might be found that take advantage of the particular choice made by the
QMR-DT. Such a factorization was in fact found by Heckerman (1989); his \Quickscore
algorithm" provides an exact inference algorithm that is tailored to the QMR-DT. Unfortunately, however, the run time of the algorithm is still exponential in the number of positive
ndings. For the CPC cases, we estimate that the algorithm would require an average of
50 years to solve the inference problem on current computers.
Faced with the apparent infeasibility of exact inference for large-scale models such as
the QMR-DT, many researchers have investigated approximation methods. One general
approach to developing approximate algorithms is to perform exact inference, but to do so
partially. One can consider partial sets of node instantiations, partial sets of hypotheses,
and partial sets of nodes. This point of view has led to the development of algorithms for
approximate inference based on heuristic search. Another approach to developing approximation algorithms is to exploit averaging phenomena in dense graphs. In particular, laws
of large numbers tell us that sums of random variables can behave simply, converging to
predictable numerical results. Thus, there may be no need to perform sums explicitly, either
exactly or partially. This point of view leads to the variational approach to approximate
inference. Finally, yet another approach to approximate inference is based on stochastic
sampling. One can sample from simplied distributions and in so doing obtain information
about a more complex distribution of interest. We discuss each of these methods in turn.
Horvitz, Suermondt and Cooper (1991) have developed a partial evaluation algorithm
known as \bounded conditioning" that works by considering partial sets of node instan1. The acronym \QMR-DT" that we use in this paper refers to the \decision-theoretic" reformulation of
the QMR by Shwe, et al. (1991). Shwe, et al. replaced the heuristic representation employed in the
original QMR model (Miller, Fasarie, & Myers, 1986) by a probabilistic representation.

292

Variational Probabilistic Inference and QMR-DT

tiations. The algorithm is based on the notion of a \cutset"; a subset of nodes whose
removal renders the remaining graph singly-connected. Ecient exact algorithms exist for
singly-connected graphs (Pearl, 1988). Summing over all instantiations of the cutset, one
can calculate posterior probabilities for general graphs using the ecient algorithm as a
subroutine. Unfortunately, however, there are exponentially many such cutset instantiations. The bounded conditioning algorithm aims at forestalling this exponential growth by
considering partial sets of instantiations. Although this algorithm has promise for graphs
that are \nearly singly-connected," it seems unlikely to provide a solution for dense graphs
such as the QMR-DT. In particular, the median cutset size for the QMR-DT across the
CPC cases is 106.5, yielding an unmanageably large number of 2106:5 cutset instantiations.
Another approach to approximate inference is provided by \search-based" methods,
which consider node instantiations across the entire graph (Cooper, 1985; Henrion, 1991;
Peng & Reggia, 1987). The general hope in these methods is that a relatively small fraction
of the (exponentially many) node instantiations contains a majority of the probability mass,
and that by exploring the high probability instantiations (and bounding the unexplored
probability mass) one can obtain reasonable bounds on posterior probabilities. The QMRDT search space is huge, containing approximately 2600 disease hypotheses. If, however,
one only considers cases with a small number of diseases, and if the hypotheses involving
a small number of diseases contain most of the high probability posteriors, then it may
be possible to search a signicant fraction of the relevant portions of the hypothesis space.
Henrion (1991) was in fact able to run a search-based algorithm on the QMR-DT inference
problem, for a set of cases characterized by a small number of diseases. These were cases,
however, for which the exact Quickscore algorithm is ecient. The more general corpus of
CPC cases that we discuss in the current paper is not characterized by a small number of
diseases per case. In general, even if we impose the assumption that patients have a limited
number N of diseases, we cannot assume a priori that the model will show a sharp cuto
in posterior probability after disease N . Finally, in high-dimensional search problems it is
often necessary to allow paths that are not limited to the target hypothesis subspace; in
particular, one would like to be able to arrive at a hypothesis containing few diseases by
pruning hypotheses containing additional diseases (Peng & Reggia, 1987). Imposing such a
limitation can lead to failure of the search.
More recent partial evaluation methods include the \localized partial evaluation" method
of Draper and Hanks (1994), the \incremental SPI" algorithm of D'Ambrosio (1993), the
\probabilistic partial evaluation" method of Poole (1997), and the \mini-buckets" algorithm
of Dechter (1997). The former algorithm considers partial sets of nodes, and the latter three
consider partial evaluations of the sums that emerge during an exact inference run. These
are all promising methods, but like the other partial evaluation methods it is yet not clear if
they restrict the exponential growth in complexity in ways that yield realistic accuracy/time
tradeos in large-scale models such as the QMR-DT.2
Variational methods provide an alternative approach to approximate inference. They
are similar in spirit to partial evaluation methods (in particular the incremental SPI and
mini-buckets algorithms), in that they aim to avoid performing sums over exponentially
2. D'Ambrosio (1994) reports \mixed" results using incremental SPI on the QMR-DT, for a somewhat
more dicult set of cases than Heckerman (1989) and Henrion (1991), but still with a restricted number
of positive ndings.

293

Jaakkola & Jordan

many summands, but they come at the problem from a dierent point of view. From the
variational point of view, a sum can be avoided if it contains a sucient number of terms
such that a law of large numbers can be invoked. A variational approach to inference
replaces quantities that can be expected to be the beneciary of such an averaging process
with surrogates known as \variational parameters." The inference algorithm manipulates
these parameters directly in order to nd a good approximation to a marginal probability of
interest. The QMR-DT model turns out to be a particularly appealing architecture for the
development of variational methods. As we will show, variational methods have a simple
graphical interpretation in the case of the QMR-DT.
A nal class of methods for performing approximate inference are the stochastic sampling methods. Stochastic sampling is a large family, including techniques such as rejection
sampling, importance sampling, and Markov chain Monte Carlo methods (MacKay, 1998).
Many of these methods have been applied to the problem of approximate probabilistic inference for graphical models and analytic results are available (Dagum & Horvitz, 1993).
In particular, Shwe and Cooper (1991) proposed a stochastic sampling method known as
\likelihood-weighted sampling" for the QMR-DT model. Their results are the most promising results to date for inference for the QMR-DT|they were able to produce reasonably
accurate approximations in reasonable time for two of the dicult CPC cases. We consider
the Shwe and Cooper algorithm later in this paper; in particular we compare the algorithm
empirically to our variational algorithm across the entire corpus of CPC cases.
Although it is important to compare approximation methods, it should be emphasized
at the outset that we do not think that the goal should be to identify a single champion
approximate inference technique. Rather, dierent methods exploit dierent structural
features of large-scale probability models, and we expect that optimal solutions will involve
a combination of methods. We return to this point in the discussion section, where we
consider various promising hybrids of approximate and exact inference algorithms.
The general problem of approximate inference is NP-hard (Dagum & Luby, 1993) and
this provides additional reason to doubt the existence of a single champion approximate
inference technique. We think it important to stress, however, that this hardness result,
together with Cooper's (1990) hardness result for exact inference cited above, should not
be taken to suggest that exact inference and approximate inference are \equally hard." To
take an example from a related eld, there exist large domains of solid and uid mechanics
in which exact solutions are infeasible but in which approximate techniques (nite element
methods) work well. Similarly, in statistical physics, very few models are exactly solvable,
but there exist approximate methods (mean eld methods, renormalization group methods)
that work well in many cases. We feel that the goal of research in probabilistic inference
should similarly be that of identifying eective approximate techniques that work well in
large classes of problems.

2. The QMR-DT Network
The QMR-DT network (Shwe et al., 1991) is a two-level or bi-partite graphical model (see
Figure 1). The top level of the graph contains nodes for the diseases , and the bottom level
contains nodes for the ndings .
294

Variational Probabilistic Inference and QMR-DT

There are a number of conditional independence assumptions reected in the bi-partite
graphical structure. In particular, the diseases are assumed to be marginally independent.
(I.e., they are independent in the absence of ndings. Note that diseases are not assumed
to be mutually exclusive; a patient can have multiple diseases). Also, given the states
of the disease nodes, the ndings are assumed to be conditionally independent. (For a
discussion regarding the medical validity and the diagnostic consequences of these and
other assumptions embedded into the QMR-DT belief network, see Shwe et al., 1991).
diseases

d1

f1

dn

fm
findings

Figure 1: The QMR belief network is a two-level graph where the dependencies between
the diseases and their associated ndings have been modeled via noisy-OR gates.
To state more precisely the probability model implied by the QMR-DT model, we write
the joint probability of diseases and ndings as:

P (f; d) = P (f jd)P (d) =

"

Y

i

3
#2
Y
P (fi jd) 4 P (dj )5

j

(1)

where d and f are binary (1/0) vectors referring to presence/absence states of the diseases
and the positive/negative states or outcomes of the ndings, respectively. The conditional
probabilities P (fi jd) are represented by the \noisy-OR model" (Pearl, 1988):
Y
P (fi = 0jd) = P (fi = 0jL) P (fi = 0jdj )
(2)
= (1 , qi0 )



Y

j 2i

(1 , qij )dj

j 2
P i
,
i0 , j2i ij dj
e
;

(3)

(4)
where i is the set of diseases that are parents of the nding fi in the QMR graph, qij =
P (fi = 1jdj = 1) is the probability that the disease j , if present, could alone cause the
nding to have a positive outcome, and qi0 = P (fi = 1jL) is the \leak" probability, i.e.,
the probability that the nding is caused by means other than the diseases included in
the QMR model. In the nal line, we reparameterize the noisy-OR probability model
using an exponentiated notation. In this notation, the model parameters are given by
ij = , log(1 , qij ).
295

Jaakkola & Jordan

3. Inference
Carrying out diagnostic inference in the QMR model involves computing the posterior
marginal probabilities of the diseases given a set of observed positive (fi = 1) and negative
(fi0 = 0) ndings. Note that the set of observed ndings is considerably smaller than the set
of possible ndings; note moreover (from the bi-partite structure of the QMR-DT graph)
that unobserved ndings have no eect on the posterior probabilities for the diseases. For
brevity we adopt a notation in which fi+ corresponds to the event fi = 1, and fi, refers
to fi = 0 (positive and negative ndings respectively). Thus the posterior probabilities of
interest are P (dj jf + ; f , ), where f + and f , are the vectors of positive and negative ndings.
The negative ndings f , are benign with respect to the inference problem|they can be
incorporated into the posterior probability in linear time in the number of associated diseases
and in the number of negative ndings. As we discuss below, this can be seen from the
fact that the probability of a negative nding in Eq. (4) is the exponential of an expression
that is linear in the dj . The positive ndings, on the other hand, are more problematic. In
the worst case the exact calculation of posterior probabilities is exponentially costly in the
number of positive ndings (Heckerman, 1989; D'Ambrosio, 1994). Moreover, in practical
diagnostic situations the number of positive ndings often exceeds the feasible limit for
exact calculations.
Let us consider the inference calculations in more detail. To nd the posterior probability
P (djf + ; f ,), we rst absorb the evidence from negative ndings, i.e., we compute P (djf ,).
This is just P (f , jd)P (d) with normalization. Since both P (f , jd) and P (d) factorize over
the diseases (see Eq. (1) and Eq. (2) above), the posterior P (djf , ) must factorize as well.
The normalization of P (f , jd)P (d) therefore reduces to independent normalizations over
each disease and can be carried out in time linear in the number of diseases (or negative
ndings). In the remainder of the paper, we concentrate solely on the positive ndings as
they pose the real computational challenge. Unless otherwise stated, we assume that the
prior distribution over the diseases already contains the evidence from the negative ndings.
In other words, we presume that the updates P (dj ) P (dj jf , ) have already been made.
We now turn to the question of computing P (dj jf + ), the posterior marginal probability
based on the positive ndings. Formally, obtaining such a posterior involves marginalizing
P (f + jd)P (d) across the remaining diseases:

P (dj jf + ) /

X

dndj

P (f + jd)P (d)

(5)

where the summation is over all the possible congurations of the disease variables other
than dj (we use the shorthand summation index d n dj for this). In the QMR model
P (f + jd)P (d) has the form:

P (f + jd)P (d) =
=

"
"

Y

i

3
#2
Y
P (fi+ jd) 4 P (dj )5

j

3
2
# Y
1 , e ,i0 , j ij dj 4 P (dj )5

Y

i

(6)

P

j

296

(7)

Variational Probabilistic Inference and QMR-DT

which follows from Eq. (4) and the fact that P (fi+ jd) = 1 , P (f , jd). To perform the
summation in Eq. (5) over the diseases, we would have to multiply out the terms 1 , efg
corresponding to the conditional probabilities for each positive nding. The number of
such terms is exponential in the number of positive ndings. While algorithms exist that
attempt to nd and exploit factorizations in this expression, based on the particular pattern
of observed evidence (cf. Heckerman, 1989; D'Ambrosio, 1994), these algorithms are limited
to roughly 20 positive ndings on current computers. It seems unlikely that there is sucient
latent factorization in the QMR-DT model to be able to handle the full CPC corpus, which
has a median number of 36 positive ndings per case and a maximum number of 61 positive
ndings.

4. Variational Methods
Exact inference algorithms perform many millions of arithmetic operations when applied to
complex graphical models such as the QMR-DT. While this proliferation of terms expresses
the symbolic structure of the model, it does not necessarily express the numeric structure
of the model. In particular, many of the sums in the QMR-DT inference problem are sums
over large numbers of random variables. Laws of large numbers suggest that these sums
may yield predictable numerical results over the ensemble of their summands, and this fact
might enable us to avoid performing the sums explicitly.
To exploit the possibility of numerical regularity in dense graphical models we develop
a variational approach to approximate probabilistic inference. Variational methods are a
general class of approximation techniques with wide application throughout applied mathematics. Variational methods are particularly useful when applied to highly-coupled systems. By introducing additional parameters, known as \variational parameters"|which
essentially serve as low-dimensional surrogates for the high-dimensional couplings of the
system|these methods achieve a decoupling of the system. The mathematical machinery
of the variational approach provides algorithms for nding values of the variational parameters such that the decoupled system is a good approximation to the original coupled
system.
In the case of probabilistic graphical models variational methods allow us to simplify a
complicated joint distribution such as the one in Eq. (7). This is achieved via parameterized transformations of the individual node probabilities. As we will see later, these node
transformations can be interpreted graphically as delinking the nodes from the graph.
How do we nd appropriate transformations? The variational methods that we consider
here come from convex analysis (see Appendix 6). Let us begin by considering methods for
obtaining upper bounds on probabilities. A well-known fact from convex analysis is that
any concave function can be represented as the solution to a minimization problem:

f (x) = min
f  T x , f  ( ) g


(8)

where f  ( ) is the conjugate function of f (x). The function f  ( ) is itself obtained as the
solution to a minimization problem:
T
f  ( ) = min
x f  x , f (x) g:

297

(9)

Jaakkola & Jordan

The formal identity of this pair of minimization problems expresses the \duality" of f and
its conjugate f  .
The representation of f in Eq. (8) is known as a variational transformation. The parameter  is known as a variational parameter. If we relax the minimization and x the the
variational parameter to an arbitrary value, we obtain an upper bound:

f (x)  T x , f  ( ):

(10)

The bound is better for some values of the variational parameter than for others, and for a
particular value of  the bound is exact.
We also want to obtain lower bounds on conditional probabilities. A straightforward
way to obtain lower bounds is to again appeal to conjugate duality and to express functions in terms of a maximization principle. This representation, however, applies to convex
functions|in the current paper we require lower bounds for concave functions. Our concave functions, however, have a special form that allows us to exploit conjugatePduality in a
dierent way. In particular, we require bounds for functions of the form f (a + j zj ), where
f is a concave function, where zj for i 2 f1; 2; : : :; ng are non-negative variables, and where
a is a constant. The variables zj in this expression are eectively coupled|the impact of
changing one variable is contingent on the settings of the remaining variables. We can use
Jensen's inequality, however, to obtain a lower bound in which the variables are decoupled.3
In particular:

f( a +

X

j

qj zqj )
j
j
X

qj f ( a + zqj )
j
j

zj ) = f ( a +

X

(11)
(12)

where the qj can be viewed as dening a probability distribution over the variables zj . The
variational parameter in this case is theP probability distribution q . The optimal setting
of this parameter is given by qj = zj = k zk . This is easily veried by substitution into
Eq. (12), and demonstrates that the lower bound is tight.

4.1 Variational Upper and Lower Bounds for Noisy-OR

Let us now return to the problem of computing the posterior probabilities in the QMR
model. Recall that it is the conditional probabilities corresponding to the positive ndings
that need to be simplied. To this end, we write
P

P (fi+ jd) = 1 , e ,i0 ,

j ij dj

= e log(1,e,x )

(13)

P

where x = i0 + j ij dj . Consider the exponent f (x) = log(1 , e,x ). For noisy-OR, as
well as for many other conditional models involving compact representations (e.g., logistic
regression), the exponent f (x) is a concave function of x. Based on the discussion in the
P

P

3. Jensen's inequality, which states that f (a + j qj xj )  j qj f (a + xj ), for concave
f , where
P
and 0  qj  1, is a simple consequence of Eq. (8), where x is taken to be a + j qj xj .

298

P

qj

= 1,

Variational Probabilistic Inference and QMR-DT

previous section, we know that there must exist a variational upper bound for this function
that is linear in x:

f (x)  x , f  ()

(14)

Using Eq. (9) to evaluate the conjugate function f  ( ) for noisy-OR, we obtain:

f  () = , log  + ( + 1) log( + 1)

(15)

The desired
bound is obtained by substituting into Eq. (13) (and recalling the denition
x = i0 + Pj ij dj ):

P (fi+ jd)

=




P

e f (i0 + Pj ij dj )

e i (i0+ j ij dj ),f (i)
P (fi+ jd; i):

(16)
(17)
(18)

Note that the \variational evidence" P (fi+ jd; i) is the exponential of a term that is linear
in the disease vector d. Just as with the negative ndings, this implies that the variational
evidence can be incorporated into the posterior in time linear in the number of diseases
associated with the nding.
There is also a graphical way to understand the eect of the transformation. We rewrite
the variational evidence as follows:
P



P (fi+jd; i) = e i(i0 + j ij dj ),f (i)
id
Yh
= e i i0 ,f  (i) e iij j :
j

(19)
(20)

Note that the rst term is a constant, and note moreover that the product is factorized
across the diseases. Each of the latter factors can be multiplied with the pre-existing
prior on the corresponding disease (possibly itself modulated by factors from the negative
evidence). The constant term can be viewed as associated with a delinked nding node fi .
Indeed, the eect of the variational transformation is to delink the nding node fi from the
graph, altering the priors of the disease nodes that are connected to that nding node. This
graphical perspective will be important for the presentation of our variational algorithm|
we will be able to view variational transformations as simplifying the graph until a point
at which exact methods can be run.
We now turn
to the lower bounds on the conditional probabilities P (fi+ jd). The expoP
nent f (i0 + j ij dj ) in the exponential representation is of the form to which we applied
Jensen's inequality in the previous section. Indeed, since f is concave we need only identify
the non-negative variables zj , which in this case are ij dj , and the constant a, which is now
i0. Applying the bound in Eq. (12) we have:

P (fi+ jd)

=

P

e f ( i0 + j ij dj )

 e

ij dj 
j qjji f io + qjji

P



299

(21)
(22)

Jaakkola & Jordan

= e
= e

h

P





ij
j qjji dj f io + qjji +(1,dj ) f ( io )

i

i
ij 
j qjji dj f io + qjji ,f ( io ) +f ( io )

P

h 

(23)

(24)

(25)
where we have allowed a dierent variational distribution qji for each nding. Note that
once again the bound is linear in the exponent. As in the case of the upper bound, this
implies that the variational evidence can be incorporated into the posterior distribution in
time linear in the number of diseases. Moreover, we can once again view the variational
transformation in terms of delinking the nding node fi from the graph.

P (fi+ jd; qji)

4.2 Approximate Inference for QMR

In the previous section we described how variational transformations are derived for individual ndings in the QMR model; we now discuss how to utilize these transformations in
the context of an overall inference algorithm.
Conceptually the overall approach is straightforward. Each transformation involves
replacing an exact conditional probability of a nding with a lower bound and an upper
bound:
P (fi+ jd; qji)  P (fi+ jd)  P (fi+ jd; i):
(26)
Given that such transformations can be viewed as delinking the ith nding node from
the graph, we see that the transformations not only yield bounds, but also yield a simplied graphical structure. We can imagine introducing transformations sequentially until
the graph is sparse enough that exact methods become feasible. At that point we stop
introducing transformations and run an exact algorithm.
There is a problem with this approach, however. We need to decide at each step which
node to transform, and this requires an assessment of the eect on overall accuracy of
transforming the node. We might imagine calculating the change in a probability of interest
both before and after a given transformation, and choosing to transform that node that
yields the least change to our target probability. Unfortunately we are unable to calculate
probabilities in the original untransformed graph, and thus we are unable to assess the eect
of transforming any one node. We are unable to get the algorithm started.
Suppose instead that we work backwards. That is, we introduce transformations for
all of the ndings, reducing the graph to an entirely decoupled set of nodes. We optimize
the variational parameters for this fully transformed graph (more on optimization of the
variational parameters below). For this graph inference is trivial. Moreover, it is also easy
to calculate the eect of reinstating a single exact conditional at one node: we choose to
reinstate that node which yields the most change.
Consider in particular the case of the upper bounds (lower bounds are analogous). Each
transformation introduces an upper bound on a conditional probability P (fi+ jd). Thus the
likelihood of observing the (positive) ndings P (f + ) is also upper bounded by its variational
counterpart P (f + j ):
X
X
P (f + ) = P (f + jd)P (d)  P (f + jd;  )P (d)  P (f + j )
(27)
d

d

300

Variational Probabilistic Inference and QMR-DT

We can assess the accuracy of each variational transformation after introducing and optimizing the variational transformations for all the positive ndings. Separately for each
positive nding we replace the variationally transformed conditional probability P (fi+ jd; i)
with the corresponding exact conditional P (fi+ jd) and compute the dierence between the
resulting bounds on the likelihood of the observations:

i = P (f + j ) , P (f + j n i )

(28)

where P (f + j n i ) is computed without transforming the ith positive nding. The larger
the dierence i is, the worse the ith variational transformation is. We should therefore
introduce the transformations in the ascending order of i s. Put another way, we should
treat exactly (not transform) those conditional probabilities whose i measure is large.
In practice, an intelligent method for ordering the transformations is critical. Figure 2
compares the calculation of likelihoods based on the i measure as opposed to a method
that chooses the ordering of transformations at random. The plot corresponds to a representative diagnostic case, and shows the upper bounds on the log-likelihoods of the observed
ndings as a function of the number of conditional probabilities that were left intact (i.e.
not transformed). Note that the upper bound must improve (decrease) with fewer transformations. The results are striking|the choice of ordering has a large eect on accuracy
(note that the plot is on a log-scale).
−30

log−likelihood

−35
−40
−45
−50
−55
−60
0

2

4
6
8
10
# of exactly treated findings

12

Figure 2: The upper bound on the log-likelihood for the delta method of removing transformations (solid line) and a method that bases the choice on a random ordering
(dashed line).
Note also that the curve for the proposed ranking is convex; thus the bound improves
less the fewer transformations there are left. This is because we rst remove the worst
transformations, replacing them with the exact conditionals. The remaining transformations are better as indicated by the delta measure and thus the bound improves less with
further replacements.
We make no claims for optimality of the delta method; it is simply a useful heuristic
that allows us to choose an ordering for variational transformations in a computationally
ecient way. Note also that our implementation of the method optimizes the variational
parameters only once at the outset and chooses the ordering of further transformations
based on these xed parameters. These parameters are suboptimal for graphs in which
301

Jaakkola & Jordan

substantial numbers of nodes have been reinstated, but we have found in practice that this
simplied algorithm still produces reasonable orderings.
Once we have decided which nodes to reinstate, the approximate inference algorithm
can be run. We introduce transformations at those nodes that were left transformed by the
ordering algorithm. The product of all of the exact conditional probabilities in the graph
with the transformed conditional probabilities yields an upper or lower bound on the overall
joint probability associated with the graph (the product of bounds is a bound). Sums of
bounds are still bounds, and thus the likelihood (the marginal probability of the ndings)
is bounded by summing across the bounds on the joint probability. In particular, an upper
bound on the likelihood is obtained via:
X
X
P (f + ) = P (f + jd)P (d)  P (f + jd;  )P (d)  P (f + j )
(29)
d

d

d

d

dndj

dndj

and the corresponding lower bound on the likelihood is obtained similarly:
X
X
P (f + ) = P (f +jd)P (d)  P (f + jd; q )P (d)  P (f + jq )

(30)

In both cases we assume that the graph has been suciently simplied by the variational
transformations so that the sums can be performed eciently.
The expressions in Eq. (29) and Eq. (30) yield upper and lower bounds for arbitrary
values of the variational parameters  and q . We wish to obtain the tightest possible bounds,
thus we optimize these expressions with respect to  and q . We minimize with respect to
 and maximize with respect to q. Appendix 6 discusses these optimization problems in
detail. It turns out that the upper bound is convex in the  and thus the adjustment of the
variational parameters for the upper bound reduces to a convex optimization problem that
can be carried out eciently and reliably (there are no local minima). For the lower bound
it turns out that the maximization can be carried out via the EM algorithm.
Finally, although bounds on the likelihood are useful, our ultimate goal is to approximate
the marginal posterior probabilities P (dj jf + ). There are two basic approaches to utilizing
the variational bounds in Eq. (29) and Eq. (30) for this purpose. The rst method, which will
be our emphasis in the current paper, involves using the transformed probability model (the
model based either on upper or lower bounds) as a computationally ecient surrogate for the
original probability model. That is, we tune the variational parameters of the transformed
model by requiring that the model give the tightest possible bound on the likelihood. We
then use the tuned transformed model as an inference engine to provide approximations to
other probabilities of interest, in particular the marginal posterior probabilities P (dj jf + ).
The approximations found in this manner are not bounds, but are computationally ecient
approximations. We provide empirical data in the following section that show that this
approach indeed yields good approximations to the marginal posteriors for the QMR-DT
network.
A more ambitious goal is to obtain interval bounds for the marginal posterior probabilities themselves. To this end, let P (f + ; dj j ) denote the combined event that the QMR-DT
model generates the observed ndings f + and that the j th disease takes the value dj . These
bounds follow directly from:
X
X
P (f + ; dj ) = P (f + jd)P (d)  P (f + jd;  )P (d)  P (f + ; dj j)
(31)
302

Variational Probabilistic Inference and QMR-DT

where P (f + jd;  ) is a product of upper-bound transformed conditional probabilities and
exact (untransformed) conditionals. Analogously we can compute a lower bound P (f + ; dj jq )
by applying the lower bound transformations:

P (f + ; dj ) =

X

dndj

P (f +jd)P (d) 

X

dndj

P (f + jd; q )P (d)  P (f + ; dj jq )

(32)

Combining these bounds we can obtain interval bounds on the posterior marginal probabilities for the diseases (cf. Draper & Hanks 1994):

P (f +; dj j)
P (f + ; dj jq)
+) 

P
(
d
j
f
j
P (f +; dj j) + P (f + ; dj jq )
P (f + ; dj j ) + P (f + ; dj jq) ;
where dj is the binary complement of dj .

(33)

5. Experimental Evaluation

The diagnostic cases that we used in evaluating the performance of the variational techniques were cases abstracted from clinocopathologic conference (\CPC") cases. These cases
generally involve multiple diseases and are considered to be clinically dicult cases. They
are the cases in which Middleton et al. (1990) did not nd their importance sampling method
to work satisfactorily.
Our evaluation of the variational methodology consists of three parts. In the rst part
we exploit the fact that for a subset of the CPC cases (4 of the 48 cases) there are a
suciently small number of positive ndings that we can calculate exact values of the
posterior marginals using the Quickscore algorithm. That is, for these four cases we were
able to obtain a \gold standard" for comparison. We provide an assessment of the accuracy
and eciency of variational methods on those four CPC cases. We present variational
upper and lower bounds on the likelihood as well as scatterplots that compare variational
approximations of the posterior marginals to the exact values. We also present comparisons
with the likelihood-weighted sampler of Shwe and Cooper (1991).
In the second section we present results for the remaining, intractable CPC cases. We
use lengthy runs of the Shwe and Cooper sampling algorithm to provide a surrogate for the
gold standard in these cases.
Finally, in the third section we consider the problem of obtaining interval bounds on
the posterior marginals.

5.1 Comparison to Exact Marginals

Four of the CPC cases have 20 or fewer positive ndings (see Table 1), and for these cases
it is possible to calculate the exact values of the likelihood and the posterior marginals
in a reasonable amount of time. We used Heckerman's \Quickscore" algorithm (Heckerman 1989)|an algorithm tailored to the QMR-DT architecture|to perform these exact
calculations.
Figure 3 shows the log-likelihood for the four tractable CPC cases. The gure also shows
the variational lower and upper bounds. We calculated the variational bounds twice, with
diering numbers of positive ndings treated exactly in the two cases (\treated exactly"
303

Jaakkola & Jordan

case # of pos. ndings # of neg. ndings
1
20
14
2
10
21
3
19
19
4
19
33

−20

−20

−30

−30

−40

log−likelihood

log−likelihood

Table 1: Description of the cases for which we evaluated the exact posterior marginals.

−50

−40

−50

−60
−60
−70
−70

(a)

0

1

2
3
sorted cases

4

(b)

5

0

1

2
3
sorted cases

4

5

Figure 3: Exact values and variational upper and lower bounds on the log-likelihood
log P (f + j ) for the four tractable CPC cases. In (a) 8 positive ndings were
treated exactly, and in (b) 12 positive ndings were treated exactly.
simply means that the nding is not transformed variationally). In panel (a) there were 8
positive ndings treated exactly, and in (b) 12 positive ndings were treated exactly. As
expected, the bounds were tighter when more positive ndings were treated exactly.4
The average running time across the four tractable CPC cases was 26.9 seconds for
the exact method, 0.11 seconds for the variational method with 8 positive ndings treated
exactly, and 0.85 seconds for the variational method with 12 positive ndings treated exactly.
(These results were obtained on a 433 MHz DEC Alpha computer).
Although the likelihood is an important quantity to approximate (particularly in applications in which parameters need to be estimated), of more interest in the QMR-DT setting
are the posterior marginal probabilities for the individual diseases. As we discussed in the
previous section, the simplest approach to obtaining variational estimates of these quantities is to dene an approximate variational distribution based either on the distribution
P (f + j ), which upper-bounds the likelihood, or the distribution P (f + jq ), which lowerbounds the likelihood. For xed values of the variational parameters (chosen to provide
a tight bound to the likelihood), both distributions provide partially factorized approximations to the joint probability distribution. These factorized forms can be exploited as
4. Given that a signicant fraction of the positive ndings are being treated exactly in these simulations, one
may wonder what if any additional accuracy is due to the variational transformations. We address this
concern later in this section and demonstrate that the variational transformations are in fact responsible
for a signicant portion of the accuracy in these cases.

304

Variational Probabilistic Inference and QMR-DT

1

1

0.8

0.8
variational estimates

variational estimates

ecient approximate inference engines for general posterior probabilities, and in particular
we can use them to provide approximations to the posterior marginals of individual diseases.
In practice we found that the distribution P (f + j ) yielded more accurate posterior
marginals than the distribution P (f + jq ), and we restrict our presentation to P (f + j ). Figure 4 displays a scatterplot of these approximate posterior marginals, with panel (a) corre-

0.6

0.4

0.2

(a)

0
0

0.6

0.4

0.2

0.2

0.4
0.6
exact marginals

0.8

(b)

1

0
0

0.2

0.4
0.6
exact marginals

0.8

1

Figure 4: Scatterplot of the variational posterior estimates and the exact marginals. In
(a) 8 positive ndings were treated exactly and in (b) 12 positive ndings were
treated exactly.
sponding to the case in which 8 positive ndings were treated exactly and panel (b) the case
in which 12 positive ndings treated exactly. The plots were obtained by rst extracting
the 50 highest posterior marginals from each case using exact methods and then computing
the approximate posterior marginals for the corresponding diseases. If the approximate
marginals are in fact correct then the points in the gures should align along the diagonals
as shown by the dotted lines. We see a reasonably good correspondence|the variational
algorithm appears to provide a good approximation to the largest posterior marginals. (We
quantify this correspondence with a ranking measure later in this section).
A current state-of-the-art algorithm for the QMR-DT is the enhanced version of likelihoodweighted sampling proposed by Shwe and Cooper (1991). Likelihood-weighted sampling is
a stochastic sampling method proposed by Fung and Chang (1990) and Shachter and Peot
(1990). Likelihood-weighted sampling is basically a simple forward sampling method that
weights samples by their likelihoods. It can be enhanced and improved by utilizing \selfimportance sampling" (see Shachter & Peot, 1990), a version of importance sampling in
which the importance sampling distribution is continually updated to reect the current
estimated posterior distribution. Middleton et al. (1990) utilized likelihood-weighted sampling with self-importance sampling (as well as a heuristic initialization scheme known as
\iterative tabular Bayes") for the QMR-DT model and found that it did not work satisfactorily. Subsequent work by Shwe and Cooper (1991), however, used an additional
enhancement to the algorithm known as `Markov blanket scoring" (see Shachter & Peot,
1990), which distributes fractions of samples to the positive and negative values of a node
in proportion to the probability of these values conditioned on the Markov blanket of the
node. The combination of Markov blanket scoring and self-importance sampling yielded
305

Jaakkola & Jordan

an eective algorithm.5 In particular, with these modications in place, Shwe and Cooper
reported reasonable accuracy for two of the dicult CPC cases.
We re-implemented the likelihood-weighted sampling algorithm of Shwe and Cooper,
incorporating the Markov blanket scoring heuristic and self-importance sampling. (We did
not utilize \iterative tabular Bayes" but instead utilized a related initialization scheme{
\heuristic tabular Bayes"{also discussed by Shwe and Cooper). In this section we discuss
the results of running this algorithm on the four tractable CPC cases, comparing to the
results of variational inference.6 In the following section we present a fuller comparative
analysis of the two algorithms for all of the CPC cases.
Likelihood-weighting sampling, and indeed any sampling algorithm, realizes a timeaccuracy tradeo|taking additional samples requires more time but improves accuracy.
In comparing the sampling algorithm to the variational algorithm, we ran the sampling
algorithm for several dierent total time periods, so that the accuracy achieved by the
sampling algorithm roughly covered the range achieved by the variational algorithm. The
results are shown in Figure 5, with the right-hand curve corresponding to the sampling runs.
The gure displays the mean correlations between the approximate and exact posterior
marginals across ten independent runs of the algorithm (for the four tractable CPC cases).
1

mean correlation

0.98
0.96
0.94
0.92
0.9
0.88
0.86 −1
10

0

1

10
10
execution time in seconds

2

10

Figure 5: The mean correlation between the approximate and exact posterior marginals as
a function of the execution time (in seconds). Solid line: variational estimates;
dashed line: likelihood-weighting sampling. The lines above and below the sampling result represent standard errors of the mean based on the ten independent
runs of the sampler.
Variational algorithms are also characterized by a time-accuracy tradeo. In particular,
the accuracy of the method generally improves as more ndings are treated exactly, at
the cost of additional computation. Figure 5 also shows the results from the variational
algorithm (the left-hand curve). The three points on the curve correspond to up to 8, 12 and
5. The initialization method proved to have little eect on the inference results.
6. We also investigated Gibbs sampling (Pearl, 1988). The results from Gibbs sampling were not as good
as the results from likelihood-weighted sampling, and we report only the latter results in the remainder
of the paper.

306

Variational Probabilistic Inference and QMR-DT

16 positive ndings treated exactly. Note that the variational estimates are deterministic
and thus only a single run was made.
The gure shows that to achieve roughly equivalent levels of accuracy, the sampling
algorithm requires signicantly more computation time than the variational method.
Although scatterplots and correlation measures provide a rough indication of the accuracy of an approximation algorithm, they are decient in several respects. In particular, in
diagnostic practice the interest is in the ability of an algorithm to rank diseases correctly,
and to avoid both false positives (diseases that are not in fact signicant but are included
in the set of highly ranked diseases) and false negatives (signicant diseases that are omitted from the set of highly ranked diseases). We dened a ranking measure as follows (see
also Middleton et al., 1990). Consider a set of the N highest ranking disease hypotheses,
where the ranking is based on the correct posterior marginals. Corresponding to this set
of diseases we can nd the smallest set of N 0 approximately ranked diseases that includes
the N signicant ones. In other words, for any N \true positives" an approximate method
produces N 0 , N \false positives." Plotting false positives as a function of true positives
provides a meaningful and useful measure of the accuracy of an approximation scheme.
To the extent that a method provides a nearly correct ranking of true positives the plot
increases slowly and the area under the curve is small. When a signicant disease appears
late in the approximate ordering the plot increases rapidly near the true rank of the missed
disease and the area under the curve is large.
We also plot the number of \false negatives" in a set of top N highly ranked diseases.
False negatives refer to the number of diseases, out of the N highest ranking diseases,
that do not appear in the set of N approximately ranked diseases. Note that unlike the
previous measure, this measure does not reveal the severity of the misplacements, only their
frequency.
With this improved diagnostic measure in hand, let us return to the evaluation of the
inference algorithms, beginning with the variational algorithm. Figure 6 provides plots of
60

7

50

6

false negatives

false positives

5
40
30
20

4
3
2

10

(a)

0
0

1

10

20
30
true positives

40

(b)

50

0
0

10

20
30
approximate ranking

40

50

Figure 6: (a) Average number of false positives as a function of true positives for the variational method (solid lines) and the partially-exact method (dashed line). (b) False
negatives in the set of top N approximately ranked diseases. In both gures 8
positive ndings were treated exactly.
the false positives (panel a) and false negatives (panel b) against the true positives for the
307

Jaakkola & Jordan

40

4

35

3.5

(a)

3
false negatives

false positives

30
25
20
15

2.5
2
1.5

10

1

5

0.5

0
0

10

20
30
true positives

40

(b)

50

0
0

10

20
30
approximate ranking

40

50

Figure 7: (a) Average number of false positives as a function of true positives for the variational method (solid line) and the partially-exact method (dashed line). (b) False
negatives in the set of top N approximately ranked diseases. In both gures 12
positive ndings were treated exactly.
tractable CPC cases. Eight positive ndings were treated exactly in the simulation shown
in this gure. Figure 7 displays the results when 12 positive nding were treated exactly.
As we noted earlier, 8 and 12 positive ndings comprise a signicant fraction of the
total positive ndings for the tractable CPC cases, and thus it is important to verify that
the variational transformations are in fact contributing to the accuracy of the posterior
approximations above and beyond the exact calculations. We did this by comparing the
variational method to a method which we call the \partially-exact" method in which the
posterior probabilities were obtained using only those ndings that were treated exactly in
the variational calculations (i.e., using only those ndings that were not transformed). If
the variational transformations did not contribute to the accuracy of the approximation,
then the performance of the partially-exact method should be comparable to that of the
variational method.7 Figure 6 and Figure 7 clearly indicate that this is not the case. The
dierence in accuracy between these methods is substantial while their computational load
is comparable (about 0.1 seconds on a 433MHz Dec Alpha).
We believe that the accuracy portrayed in the false positive plots provides a good indication of the potential of the variational algorithm for providing a practical solution to
the approximate inference problem for the QMR-DT. As the gures show, the number of
false positives grows slowly with the number of true positives. For example, as shown in
Figure 6 where eight positive ndings are treated exactly, to nd the 20 most likely diseases
we would only need to entertain the top 23 diseases in the list of approximately ranked
diseases (compared to more than 50 for the partially-exact method).
The ranking plot for the likelihood-weighted sampler is shown in Figure 8, with the
curve for the variational method from Figure 7 included for comparison. To make these
plots, we ran the likelihood-weighted sampler for an amount of time (6.15 seconds) that was
7. It should be noted that this is a conservative comparison, because the partially-exact method in fact
benets from the variational transformation|the set of exactly treated positive ndings is selected on
the basis of the accuracy of the variational transformations, and these accuracies correlate with the
diagnostic relevance of the ndings.

308

Variational Probabilistic Inference and QMR-DT

40
35

false positives

30
25
20
15
10
5
0
0

10

20
30
true positives

40

50

Figure 8: Average number of false positives as a function of true positives for the likelihoodweighted sampler (dashed line) and the variational method (solid line) with 12
positive ndings treated exactly.
comparable to the time allocated to our slowest variational method (3.17 seconds; this was
the case in which 16 positive ndings were treated exactly. Recall that the time required
for the variational algorithm with 12 positive ndings treated exactly was 0.85 seconds.) As
the plots show, for these tractable CPC cases, the variational method is signicantly more
accurate than the sampling algorithm for comparable computational loads.

5.2 The Full CPC Corpus

We now consider the full CPC corpus. The majority of these cases (44 of 48 cases), have
more than 20 positive ndings and thus appear to be beyond the reach of exact methods.
An important attraction of sampling methods is the mathematical guarantee of accurate
estimates in the limit of a suciently large sample size (Gelfand & Smith, 1990). Thus
sampling methods have the promise of providing a general methodology for approximate
inference, with two caveats: (1) the number of samples that is needed can be dicult to
diagnosis, and (2) very many samples may be required to obtain accurate estimates. For
real-time applications, the latter issue can rule out sampling solutions. However, long-term
runs of a sampler can still provide a useful baseline for the evaluation of the accuracy of faster
approximation algorithms. We begin by considering this latter possibility in the context of
likelihood-weighted sampling for the QMR-DT. We then turn to a comparative evaluation
of likelihood-weighted sampling and variational methods in the time-limited setting.
To explore the viability of the likelihood-weighted sampler for providing a surrogate for
the gold standard, we carried out two independent runs each consisting of 400,000 samples.
Figure 9(a) shows the estimates of the log-likelihood from the rst sampling run for all
of the CPC cases. We also show the variational upper and lower bounds for these cases
(the cases have been sorted according to the lower bound). Note that these bounds are
rigorous bounds on the true log-likelihood, and thus they provide a direct indication of the
accuracy of the sampling estimates. Although we see that many of the estimates lie between
the bounds, we also see in many cases that the sampling estimates deviate substantially
from the bounds. This suggests that the posterior marginal estimates obtained from these
samples are likely to be unreliable as well. Indeed, Figure 9(b) presents a scatterplot of
309

Jaakkola & Jordan

−20
1

−40
0.8
sampling estimates 2

log−likelihood

−60
−80
−100
−120
−140
−160

0.6

0.4

0.2

−180

(a)

−200
0

10

20
30
sorted cases

40

50

(b)

0
0

0.2

0.4
0.6
sampling estimates 1

0.8

1

Figure 9: (a) Upper and lower bounds (solid lines) and the corresponding sampling estimates (dashed line) of the log-likelihood of observed ndings for the CPC cases.
(b) A correlation plot between the posterior marginal estimates from two independent sampling runs.
estimated posterior marginals for the two independent runs of the sampler. Although we
see many cases in which the results lie on the diagonal, indicating agreement between the
two runs, we also see many pairs of posterior estimates that are far from the diagonal.
These results cast some doubt on the viability of the likelihood-weighted sampler as a
general approximator for the full set of CPC cases. Even more problematically we appear
to be without a reliable surrogate for the gold standard for these cases, making it dicult
to evaluate the accuracy of real-time approximations such as the variational method. Note,
however, that the estimates in Figure 9(a) seem to fall into two classes|estimates that
lie within the variational bounds and estimates that are rather far from the bounds. This
suggests the possibility that the distribution being sampled from is multi-modal, with some
estimates falling within the correct mode and providing good approximations and with
others falling in spurious modes and providing seriously inaccurate approximations. If the
situation holds, then an accurate surrogate for the gold standard might be obtained by using
the variational bounds to lter the sampling results and retaining only those estimates that
lie between the bounds given by the variational approach.
Figure 10 provides some evidence of the viability of this approach. In 24 out of the 48
CPC cases both of the independent runs of the sampler resulted in estimates of the loglikelihood lying approximately within the variational bounds. We recomputed the posterior
marginal estimates for these selected cases and plotted them against each other in the gure.
The scatterplot shows a high degree of correspondence of the posterior estimates in these
cases. We thus tentatively assume that these estimates are accurate enough to serve as a
surrogate gold standard and proceed to evaluate the real-time approximations.
Figure 11 plots the false positives against the true positives on the 24 selected CPC
cases for the variational method. Twelve positive ndings were treated exactly in this
simulation. Obtaining the variational estimates took 0.29 seconds of computer time per
case. Although the curve increases more rapidly than with the tractable CPC cases, the
variational algorithm still appears to provide a reasonably accurate ranking of the posterior
marginals, within a reasonable time frame.
310

Variational Probabilistic Inference and QMR-DT

1

sampling estimates 2

0.8

0.6

0.4

0.2

0
0

0.2

0.4
0.6
sampling estimates 1

0.8

1

Figure 10: A correlation plot between the selected posterior marginal estimates from two
independent sampling runs, where the selection was based on the variational
upper and lower bounds.
70
60

false positives

50
40
30
20
10
0
0

10

20
30
true positives

40

50

Figure 11: Average number of false positives as a function of true positives for the variational method (solid line) and the likelihood-weighted sampler (dashed line).
For the variational method 12 positive ndings were treated exactly, and for the
sampler the results are averages across ten runs.
To compare the variational algorithm to a time-limited version of the likelihood-weighted
sampler we ran the latter algorithm for a period of time (8.83 seconds per case) roughly comparable to the running time of the variational algorithm (0.29 seconds per case). Figure 11
shows the corresponding plot of false positives against true positives, where we have averaged over ten independent runs. We see that the curve increases signicantly more steeply
than the variational curve. To nd the 20 most likely diseases with the variational method
we would only need to entertain the top 30 diseases in the list of approximately ranked
diseases. For the sampling method we would need to entertain the top 70 approximately
ranked diseases.

5.3 Interval Bounds on the Marginal Probabilities

Thus far we have utilized the variational approach to produce approximations to the posterior marginals. The approximations that we have discussed originate from upper and lower
311

Jaakkola & Jordan

bounds on the likelihood, but they are not themselves bounds. That is, they are not guaranteed to lie above or below the true posteriors, as we see in Figure 4. As we discussed in
Section 4.1, however, it is also possible to induce upper and lower bounds on the posterior
marginals from upper and lower bounds on the likelihood (cf. Eq. 33). In this section we
evaluate these interval bounds for the QMR-DT posterior marginals.
Figure 12 displays histogram of the interval bounds for the four tractable CPC cases, the
24 selected CPC cases from the previous section, and all of the CPC cases. These histograms
include all of the diseases in the QMR-DT network. In the case of the tractable cases the
0.8

0.8

0.8

0.6

0.6

0.4

0
0

0.6

0.4

0.2

(a)

Frequency

1

Frequency

1

Frequency

1

0.4

0.2

0.2

0.4

0.6

Interval size

0.8

1

(b)

0
0

0.2

0.2

0.4

0.6

Interval size

0.8

1

(c)

0
0

0.2

0.4

0.6

0.8

Interval size

Figure 12: Histograms of the size of the interval bounds on all of the diseases in the QMRDT network for (a) the four tractable CPC cases, (b) the 24 selected CPC cases
from the previous section, and (c) all of the CPC cases.
variational method was run with 12 positive ndings treated exactly. For the remaining
CPC cases the variational method was run with 16 positive ndings treated exactly. The
running time of the algorithm was less than 10 seconds of computer time per CPC case.
For the tractable CPC cases, the interval bounds are tight for nearly all of the diseases
in the network. However, (1) few of the positive ndings are treated variationally in these
cases, and (2) there is no need in practice to compute variational bounds for these cases.
We get a somewhat better picture of the viability of the variational interval bounds in
Figure 12(b) and Figure 12(c), and the picture is decidedly mixed. For the 24 selected
cases, tight bounds are provided for approximately half of the diseases. The bounds are
vacuous for approximately a quarter of the diseases, and there are a range of diseases in
between. When we consider all of the CPC cases, approximately a third of the bounds are
tight and nearly half are vacuous.
Although these results may indicate limitations in our variational approximation, there
is another more immediate problem that appears to be responsible for the looseness of
the bounds in many cases. In particular, recall that we use the Quickscore algorithm
(Heckerman, 1989) to handle the exact calculations within the framework of our variational
algorithm. Unfortunately Quickscore suers from vanishing numerical precision for large
numbers of positive ndings, and in general we begin to run into numerical problems,
resulting in vacuous bounds, when 16 positive ndings are incorporated exactly into the
variational approximation. Thus, although it is clearly of interest to run the variational
algorithm for longer durations, and thereby improve the bounds, we are unable to do so
within our current implementation of the exact subroutine.
312

1

Variational Probabilistic Inference and QMR-DT

While it is clearly worth studying methods other than Quickscore for treating the exact ndings within the variational algorithm, it is also of interest to consider combining
variational methods with other methods, such as search-based or other partial evaluation
methods, that are based on intervals. These methods may help in simplifying the posterior
and obviating the need for improving the exact calculations.
It is also worth emphasizing the positive aspect of these results and their potential
practical utility. The previous section showed that the variational method can provide accurate approximations to the posterior marginals. Combined with the interval bounds in
this section|which are calculated eciently|the user can obtain guarantees on approximately a third of these approximations. Given the relatively benign rate of increase in false
positives as a function of true positives (Figure 11), such guarantees may suce. Finally,
for diseases in which the bounds are loose there are also perturbation methods available
(Jaakkola, 1997) that can help to validate the approximations for these diseases.

6. Discussion
Let us summarize the variational inference method and evaluate the results that we have
obtained.
The variational method begins with parameterized upper and lower bounds on the individual conditional probabilities at the nodes of the model. For the QMR-DT, these bounds
are exponentials of linear functions, and introducing them into the model corresponds to
delinking nodes from the graph. Sums of products of these bounds yield bounds, and thus
we readily obtain parameterized bounds on marginal probabilities, in particular upper and
lower bounds on the likelihood.
We exploited the likelihood bounds in evaluating the output of the likelihood-weighted
sampling algorithm. Although the sampling algorithm did not yield reliable results across
the corpus of CPC cases, when we utilized the variational upper and lower bounds to select
among the samples we were able to obtain sampling results that were consistent between
runs. This suggests a general procedure in which variational bounds are used to assess the
convergence of a sampling algorithm. (One can also imagine a more intimate relationship
between these algorithms in which the variational bounds are used to adjust the on-line
course of the sampler).
The fact that we have bounds on the likelihood (or other marginal probabilities) is
critical|the bounding property allows us to nd optimizing values of the variational parameters by minimizing the upper-bounding variational distribution and maximizing the
lower-bounding variational distribution. In the case of the QMR-DT network (a bipartite noisy-OR graph), the minimization problem is a convex optimization problem and the
maximization problem is solved via the EM algorithm.
Once the variational parameters are optimized, the resulting variational distribution can
be exploited as an inference engine for calculating approximations to posterior probabilities.
This technique has been our focus in the paper. Graphically, the variationally transformed
model can be viewed as a sub-graph of the original model in which some of the nding
nodes have been delinked. If a sucient number of ndings are delinked variationally
then it is possible to run an exact algorithm on the resulting graph. This approach yields
approximations to the posterior marginals of the disease nodes.
313

Jaakkola & Jordan

We found empirically that these approximations appeared to provide good approximations to the true posterior marginals. This was the case for the tractable set of CPC cases
(cf. Figure 7) and|subject to our assumption that we have obtained a good surrogate for
the gold standard via the selected output of the sampler|also the case for the full CPC
corpus (cf. Figure 11).
We also compared the variational algorithm to a state-of-the-art algorithm for the QMRDT, the likelihood-weighted sampler of Shwe and Cooper (1991). We found that the variational algorithm outperformed the likelihood-weighted sampler both for the tractable cases
and for the full corpus. In particular, for a xed accuracy requirement the variational algorithm was signicantly faster (cf. Figure 5), and for a xed time allotment the variational
algorithm was signicantly more accurate (cf. Figure 8 and Figure 11).
Our results were less satisfactory for the interval bounds on the posterior marginals.
Across the full CPC corpus we found that for approximately one third of the disease the
bounds were tight but for half of the diseases the bounds were vacuous. A major impediment
to obtaining tighter bounds appears to lie not in the variational approximation per se but
rather in the exact subroutine, and we are investigating exact methods with improved
numerical properties.
Although we have focused in detail on the QMR-DT model in this paper, it is worth
noting that the variational probabilistic inference methodology is considerably more general.
Specically, the methods that we have described here are not limited to the bi-partite
graphical structure of the QMR-DT model, nor is it necessary to employ noisy-OR nodes
(Jaakkola & Jordan, 1996). It is also the case that the type of transformations that we
have exploited in the QMR-DT setting extend to a larger class of dependence relations
based on generalized linear models (Jaakkola, 1997). Finally, for a review of applications of
variational methods to a variety of other graphical model architectures, see Jordan, et al.
(1998).
A promising direction for future research appears to be in the integration of various
kinds of approximate and exact methods (see, e.g., Dagum & Horvitz, 1992; Jensen, Kong,
& Kjrul, 1995). In particular, search-based methods (Cooper, 1985; Peng & Reggia,
1987, Henrion, 1991) and variational methods both yield bounds on probabilities, and, as
we have indicated in the introduction, they seem to exploit dierent aspects of the structure of complex probability distributions. It may be possible to combine the bounds from
these algorithm|the variational bounds might be used to guide the search, or the searchbased bounds might be used to aid the variational approximation. Similar comments can
be made with respect to localized partial evaluation methods and bounded conditioning
methods (Draper & Hanks, 1994; Horvitz, et al., 1989). Also, we have seen that variational
bounds can be used for assessing whether estimates from Monte Carlo sampling algorithms
have converged. A further interesting hybrid would be a scheme in which variational approximations are rened by treating them as initial conditions for a sampler.
Even without extensions our results in this paper appear quite promising. We have
presented an algorithm which runs in real time on a large-scale graphical model for which
exact algorithms are in general infeasible. The results that we have obtained appear to
be reasonably accurate across a corpus of dicult diagnostic cases. While further work
is needed, we believe that our results indicate a promising role for variational inference in
developing, critiquing and exploiting large-scale probabilistic models such as the QMR-DT.
314

Variational Probabilistic Inference and QMR-DT

Acknowledgements
We would like to thank the University of Pittsburgh and Randy Miller for the use of the
QMR-DT database. We also want to thank David Heckerman for suggesting that we attack
QMR-DT with variational methods, and for providing helpful counsel along the way.

Appendix A. Duality
The upper and lower bounds for individual conditional probability distributions that form
the basis of our variational method are based on the \dual" or \conjugate" representations
of convex functions. We present a brief description of convex duality in this appendix, and
refer the reader to Rockafellar (1970) for a more extensive treatment.
Let f (x) be a real-valued, convex function dened on a convex set X (for example,
X = Rn ). For simplicity of exposition, we assume that f is a well-behaved (dierentiable)
function. Consider the graph of f , i.e., the points (x; f (x)) in an n + 1 dimensional space.
The fact that the function f is convex translates into convexity of the set f(x; y ) : y  f (x)g
called the epigraph of f and denoted by epi(f ) (Figure 13). It is an elementary property
f(x)
epi(f)

x ξ - y - f*(ξ) ≤ 0

x ξ’ - y - f*(ξ’) ≤ 0

xξ-y-µ≤0

Figure 13: Half-spaces containing the convex set epi(f ). The conjugate function f  ( )
denes the critical half-spaces whose intersection is epi(f ), or, equivalently, it
denes the tangent planes of f (x).
of convex sets that they can be represented as the intersection of all the half-spaces that
contain them (see Figure 13). Through parameterizing these half-spaces we obtain the dual
representations of convex functions. To this end, we dene a half-space by the condition:
all (x; y ) such that xT  , y ,   0

(34)

where  and  parameterize all (non-vertical) half-spaces. We are interested in characterizing the half-spaces that contain the epigraph of f . We require therefore that the points
in the epigraph must satisfy the half-space condition: for (x; y ) 2 epi(f ), we must have
xT  , y ,   0. This holds whenever xT  , f (x) ,   0 as the points in the epigraph have
the property that y  f (x). Since the condition must be satised by all x 2 X , it follows
315

Jaakkola & Jordan

that
max
f xT  , f (x) ,  g  0;
x2X

(35)

as well. Equivalently,

  max
f xT  , f (x) g
x2X

(36)

where the right-hand side of this equation denes a function of  , which is known as the
\dual" or \conjugate" function f ( ). This function, which is also a convex function, denes
the critical half-spaces which are needed for the representation of epi(f ) as an intersection
of half-spaces (Figure 13).
To clarify the duality between f (x) and f  (x), let us drop the maximum and rewrite
the inequality as:

xT   f (x) + f  ( )

(37)

In this equation, the roles of the two functions are interchangeable and we may suspect that
also f (x) can obtained from the dual function f  (x) by an optimization procedure. This is
in fact the case and we have:

f (x) = max
f xT  , f () g
2

(38)

This equality states that the dual of the dual gives back the original function. It provides
the computational tool for calculating dual functions.
For concave (convex down) functions the results are analogous; we replace max with
min, and lower bounds with upper bounds.

Appendix B. Optimization of the Variational Parameters

The variational method that we have described involves replacing selected local conditional
probabilities with either upper-bounding or lower-bounding variational transformations.
Because the product of bounds is a bound, the variationally transformed joint probability
distribution is a bound (upper or lower) on the true joint probability distribution. Moreover, because sums of bounds is a bound on the sum, we can obtain bounds on marginal
probabilities by marginalizing the variationally transformed joint probability distribution.
In particular, this provides a method for obtaining bounds on the likelihood (the marginal
probability of the evidence).
Note that the variationally transformed distributions are bounds for arbitrary values of
the variational parameters (because each individually transformed node conditional probability is a bound for arbitrary values of its variational parameter). To obtain optimizing
values of the variational parameters, we take advantage of the fact that our transformed
distribution is a bound, and either minimize (in the case of upper bounds) or maximize
(in the case of lower bounds) the transformed distribution with respect to the variational
parameters. It is this optimization process which provides a tight bound on the marginal
probability of interest (e.g., the likelihood) and thereby picks out a particular variational
distribution that can subsequently be used for approximate inference.
316

Variational Probabilistic Inference and QMR-DT

In this appendix we discuss the optimization problems that we must solve in the case
of noisy-OR networks. We consider the upper and lower bounds separately, beginning with
the upper bound.

Upper Bound Transformations

Our goal isPto compute a tight upper bound on the likelihood of the observed ndings:
P (f + ) = d P (f + jd)P (d). As discussed in Section 4.2, we obtain an upper bound on
P (f + jd) by introducing upper bounds for individual node conditional probabilities. We
represent this upper bound as P (f + jd;  ), which is a product across the individual variational transformations and may contain contributions due to ndings that are being treated
exactly (i.e., are not transformed). Marginalizing across d we obtain a bound:

P (f + ) 

X

d

P (f + jd;  )P (d)  P (f + j):

(39)

It is this latter quantity that we wish to minimize with respect to the variational parameters
.
To simplify the notation we assume that the rst m positive ndings have been transformed (and therefore need to be optimized) while the remaining conditional probabilities
will be treated exactly. In this notation P (f + j ) is given by

P (f + j )

=

/

2
X Y
4

3"

#
Y
Y
+
+
P (fi jd; i)5
P (fi jd) P (dj )
i>m
j
d im
8
9
<Y
=
E : P (fi+ jd; i); ;
im

(40)
(41)

where the expectation is taken with respect to the posterior distribution for the diseases
given those positive ndings that we plan to treat exactly. Note that the proportionality
constant does not depend on the variational parameters (it is the likelihood of the exactly
treated positive ndings). We now insert the explicit forms of the transformed conditional
probabilities (see Eq. (17)) into Eq. (41) and nd:

P (f + j) /
=

8
9
< Y  ( +P  d ),f  ( ) =
i
E : e i i0 j ij j
;
im
 P

P

e im (i i0 ,f (i)) E e j; im i ij dj

(42)
(43)

where we have simply converted the products over i into sums in the exponent and pulled
out the terms that are constants with respect to the expectation. On a log-scale, the
proportionality becomes an equivalence up to a constant:
 P

X


d
i
ij
j
+

j;i

m
log P (f j ) = C + (i i0 , f (i)) + log E e
im

317

(44)

Jaakkola & Jordan

Several observations are in order. Recall that f (i ) is the conjugate of the concave function
f (the exponent), and is therefore also concave; for this reason ,f (i ) is convex. In
Appendix C we prove that the remaining term:
 P

log E e

j;im iij dj



(45)

is also a convex function of the variational parameters. Now, since any sum of convex
functions is convex, we conclude that log P (f + j ) is a convex function of the variational
parameters. This means that there are no local minima in our optimization problem. We
may safely employ the standard Newton-Raphson procedure to solve r log P (f + j ) = 0.
Alternatively we can utilize xed-point iterations. In particular, we calculate the derivatives
of the variational form and iteratively solve for the individual variational parameters k such
that the derivatives are zero. The derivatives are given as follows:
8

9

@ log P (f + j) =  + log k + E <X  d =
k0
kj j ;
:
@k
1 + k
j

(46)

@ 2 log P (f + j) = 1 , 1 + Var <X  d = ;
: j kj j ;
@ 2 k
k 1 + k

(47)

8

9

where the expectation and the variance are with respect to the posterior approximation
P (djf + ;  ), and both derivatives can be computed in time linear in the number of associated diseases for the nding. The benign scaling of the variance calculations comes from
exploiting the special properties of the noisy-OR dependence and the marginal independence
of the diseases.
Calculating the expectations in Eq. (7) is exponentially costly in the number of exactly
treated positive ndings. When there are a large number of positive ndings, we can have
recourse to a simplied procedure in which we optimize variational parameters after having
transformed all or most of the positive ndings. While the resulting variational parameters
are suboptimal, we have found in practice that the incurred loss in accuracy is typically quite
small. In the simulations reported in the paper, we optimized the variational parameters
after approximately half of the exactly treated ndings had been introduced. (To be precise,
in the case of 8, 12 and 16 total ndings treated exactly, we optimized the parameters after
4, 8, and 8 ndings, respectively, were introduced).

Lower Bound Transformations

Mimicking the case of upper bounds, we replace individual conditional probabilities of
the ndings with lower-bounding transformations, resulting in a lower-bounding expression
P (f + jd; q). Taking the product with P (d) and marginalizing over d yields a lower bound
on the likelihood:
X
P (f + )  P (f + jd; q )P (d)  P (f + jq):
(48)
d

We wish to maximize P (f + jq ) with respect to the variational parameters q to obtain the
tightest possible bound.
318

Variational Probabilistic Inference and QMR-DT

Our problem can be mapped onto a standard optimization problem in statistics. In
particular, treating d as a latent variable, f as an observed variable, and q as a parameter
vector, the optimization of P (f + jq ) (or its logarithm) can be viewed as a standard maximum
likelihood estimation problem for a latent variable model. It can be solved using the EM
algorithm (Dempster, Laird, & Rubin, 1977). The algorithm yields a sequence of variational
parameters that monotonically increase the objective function log P (f + jq ). Within the EM
framework, we obtain an update of the variational parameters by maximizing the expected
complete log-likelihood:


	

E log P (f + jd; q )P (d) =

X

i

n

o

E log P (fi+ jd; qji) + constant;

(49)

where q old denotes the vector of variational parameters before the update, where the constant term is independent of the variational parameters q and where the expectation is with
respect to the posterior distribution P (djf + ; q old ) / P (f + jd; q old)P (d). Since the variational
parameters associated with the conditional probabilities P (fi+ jd; qji) are independent of one
another, we can maximize each term in the above sum separately. Recalling the form of the
variational transformation (see Eq. (24)), we have:
!

"

#

E
=
qjji E fdjg f io + qij , f ( io )
j ji
j
+f ( io )
(50)
which we are to maximize with respect to qj ji while keeping the expectations E fdj g xed.
n

log P (fi+ jd; qji)

o

X

This optimization problem can be solved iteratively and monotonically by performing the
following synchronous updates with normalization:

qj ji

!

"

!

E fdj g qjji f io + qij , ij f 0 io + qij , qjji f ( io )
j ji
j ji

#

(51)

where f 0 denotes the derivative of f . (The update is guaranteed to be non-negative).
This algorithm can be easily extended to handle the case where not all the positive
ndings have been transformed. The only new feature is that some of the conditional
probabilities in the products P (f + jd; q old) and P (f + jd; q ) have been left intact, i.e., not
transformed; the optimization with respect to the variational parameters corresponding to
the transformed conditionals proceeds as before.

Appendix C. Convexity

The purpose of this appendix is to demonstrate that the function:
 P

log E e

j;im iij dj



(52)

is a convex function of the variational parameters i . We note rst that
ane transformaP
tions do not change convexity properties. Thus convexity in X = j;im i ij dj implies
319

Jaakkola & Jordan

convexity in the variational parameters  . It remains to show that
n

o

log E e X = log

X

i

pi e Xi = f (X~ )

(53)

is a convex function of the vector X~ = fX1 : : :Xn gT ; here we have indicated the discrete
values in the range of the random variable X by Xi and denoted the probability measure
on such values by pi . Taking the gradient of f with respect to Xk gives:

@ f (X~ ) = Ppk e Xk  q
k
@Xk
i pi e Xi

(54)

2
Hkl = @X@ @X f (X~ ) = kl qk , qk ql

(55)

X
X
X
Z~ T HZ~ = qk Zk2 , ( qk Zk )( ql Zl) = VarfZ g  0

(56)

where qk denes a probability distribution. The convexity is revealed by a positive semidenite Hessian H, whose components in this case are
k

l

To see that H is positive semi-denite, consider
k

k

l

where VarfZ g is the variance of a discrete random variable Z which takes the values Zi
with probability qi .

References

D'Ambrosio, B. (1993). Incremental probabilistic inference. In Proceedings of the Ninth
Conference on Uncertainty in Articial Intelligence. San Mateo, CA: Morgan Kaufmann.
D'Ambrosio, B. (1994). Symbolic probabilistic inference in large BN20 networks. In Proceedings of the Tenth Conference on Uncertainty in Articial Intelligence. San Mateo,
CA: Morgan Kaufmann.
Cooper, G. (1985). NESTOR: A computer-based medical diagnostic aid that integrates
causal and probabilistic knowledge. Ph.D. Dissertation, Medical Informatics Sciences,
Stanford University, Stanford, CA. (Available from UMI at
http://wwwlib.umi.com/dissertations/main).
Cooper, G. (1990). The computational complexity of probabilistic inference using Bayesian
belief networks. Articial Intelligence, 42, 393{405.
Dagum, P., & Horvitz, E. (1992). Reformulating inference problems through selective
conditioning. In Proceedings of the Eighth Annual Conference on Uncertainty in
Articial Intelligence.
Dagum, P., & Horvitz, E. (1993). A Bayesian analysis of simulation algorithms for inference
in Belief networks. Networks, 23, 499{516.
320

Variational Probabilistic Inference and QMR-DT

Dagum, P., & Luby, M. (1993). Approximate probabilistic reasoning in Bayesian belief
networks is NP-hard. Articial Intelligence, 60, 141{153.
Dechter, R. (1997). Mini-buckets: A general scheme of generating approximations in automated reasoning. In Proceedings of the Fifteenth International Joint Conference on
Articial Intelligence.
Dechter, R. (1998). Bucket elimination: A unifying framework for probabilistic inference.
In M. I. Jordan (Ed.), Learning in Graphical Models. Cambridge, MA: MIT Press.
Dempster, A., Laird, N., & Rubin, D. (1977). Maximum likelihood from incomplete data
via the EM algorithm. Journal of the Royal Statistical Society B, 39, 1{38.
Draper, D., & Hanks, S. (1994). Localized partial evaluation of belief networks. In Proceedings of the Tenth Annual Conference on Uncertainty in Articial Intelligence.
Fung, R., & Chang, K. C. (1990). Weighting and integrating evidence for stochastic simulation in Bayesian networks. In Proceedings of Fifth Conference on Uncertainty in
Articial Intelligence. Amsterdam: Elsevier Science.
Gelfand, A., & Smith, A. (1990). Sampling-based approaches to calculating marginal Densities. Journal of the American Statistical Association, 85, 398{409.
Heckerman, D. (1989). A tractable inference algorithm for diagnosing multiple diseases. In
Proceedings of the Fifth Conference on Uncertainty in Articial Intelligence.
Henrion, M. (1991). Search-based methods to bound diagnostic probabilities in very large
belief nets. In Proceedings of Seventh Conference on Uncertainty in Articial Intelligence.
Horvitz, E. Suermondt, H., & Cooper, G. (1989). Bounded conditioning: Flexible inference
for decisions under scarce resources. In Proceedings of Fifth Conference on Uncertainty in Articial Intelligence.
Jaakkola, T. (1997). Variational methods for inference and learning in graphical models.
PhD thesis, Department of Brain and Cognitive Sciences, Massachusetts Institute of
Technology.
Jaakkola, T., & Jordan, M. (1996). Recursive algorithms for approximating probabilities
in graphical models. In Advances of Neural Information Processing Systems 9. Cambridge, MA: MIT Press.
Jensen, C. S., Kong, A., & Kjrul, U. (1995). Blocking-Gibbs sampling in very large
probabilistic expert systems. International Journal of Human-Computer Studies, 42,
647{666.
Jensen, F. (1996). Introduction to Bayesian networks. New York: Springer.
321

Jaakkola & Jordan

Jordan, M., Ghaharamani, Z. Jaakkola, T., & Saul, L. (in press). An introduction to
variational methods for graphical models. Machine Learning.
Lauritzen, S., & Spiegelhalter, D. (1988). Local computations with probabilities on graphical structures and their application to expert systems (with discussion). Journal of
the Royal Statistical Society B, 50, 157{224.
MacKay, D. J. C. (1998). Introduction to Monte Carlo methods. In M. I. Jordan (Ed.),
Learning in Graphical Models. Cambridge, MA: MIT Press.
Middleton, B., Shwe, M., Heckerman, D., Henrion, M., Horvitz, E., Lehmann, H., & Cooper,
G. (1990). Probabilistic diagnosis using a reformulation of the INTERNIST-1/QMR
knowledge base II. Evaluation of diagnostic performance. Section on Medical Informatics Technical report SMI-90-0329, Stanford University.
Miller, R. A., Fasarie, F. E., & Myers, J. D. (1986). Quick medical reference (QMR) for
diagnostic assistance. Medical Computing, 3, 34{48.
Pearl, J. (1988). Probabilistic Reasoning in Intelligent Systems. San Mateo, CA: Morgan
Kaufmann.
Peng, Y., & Reggia, J. (1987). A probabilistic causal model for diagnostic problem solving {
Part 2: Diagnostic strategy. IEEE Trans. on Systems, Man, and Cybernetics: Special
Issue for Diagnosis, 17, 395{406.
Poole, D. (1997). Probabilistic partial evaluation: Exploiting rule structure in probabilistic
inference. In Proceedings of the Fifteenth International Joint Conference on Articial
Intelligence.
Rockafellar, R. (1972). Convex Analysis. Princeton University Press.
Shachter, R. D., & Peot, M. (1990). Simulation approaches to general probabilistic inference
on belief networks. In Proceedings of Fifth Conference on Uncertainty in Articial
Intelligence. Elsevier Science: Amsterdam.
Shenoy, P. P. (1992). Valuation-based systems for Bayesian decision analysis. Operations
Research, 40, 463{484.
Shwe, M., & Cooper, G. (1991). An empirical analysis of likelihood { weighting simulation
on a large, multiply connected medical belief network. Computers and Biomedical
Research, 24, 453-475.
Shwe, M., Middleton, B., Heckerman, D., Henrion, M., Horvitz, E., Lehmann, H., & G.
Cooper (1991). Probabilistic diagnosis using a reformulation of the INTERNIST1/QMR knowledge base I. The probabilistic model and inference algorithms. Methods
of Information in Medicine, 30, 241{255.

322

Journal of Articial Intelligence Research 10 (1999) 199-241

Submitted 9/98; published 4/99

Probabilistic Deduction with
Conditional Constraints over Basic Events
Thomas Lukasiewicz

Institut fur Informatik, Universitat Gieen
Arndtstrae 2, D-35392 Gieen, Germany

lukasiewicz@informatik.uni-giessen.de

Abstract

We study the problem of probabilistic deduction with conditional constraints over basic
events. We show that globally complete probabilistic deduction with conditional constraints
over basic events is NP-hard. We then concentrate on the special case of probabilistic
deduction in conditional constraint trees. We elaborate very ecient techniques for globally
complete probabilistic deduction. In detail, for conditional constraint trees with point
probabilities, we present a local approach to globally complete probabilistic deduction,
which runs in linear time in the size of the conditional constraint trees. For conditional
constraint trees with interval probabilities, we show that globally complete probabilistic
deduction can be done in a global approach by solving nonlinear programs. We show how
these nonlinear programs can be transformed into equivalent linear programs, which are
solvable in polynomial time in the size of the conditional constraint trees.

1. Introduction
Dealing with uncertain knowledge plays an important role in knowledge representation and
reasoning. There are many dierent formalisms and methodologies for handling uncertainty.
Most of them are directly or indirectly based on probability theory.
In this paper, we focus on probabilistic deduction with conditional constraints over basic
events (that is, interval restrictions for conditional probabilities of elementary events). The
considered probabilistic deduction problems consist of a probabilistic knowledge base and
a probabilistic query. We give a classical example. As a probabilistic knowledge base, we
may take the probabilistic knowledge that all ostriches are birds, that the probability of
Tweety being a bird is greater than 0.90, and that the probability of Tweety being an ostrich
provided she is a bird is greater than 0.80. As a probabilistic query, we may now wonder
about the entailed greatest lower and least upper bound for the probability that Tweety
is an ostrich. The solution to this probabilistic deduction problem is 0.72 for the entailed
greatest lower bound and 1.00 for the entailed least upper bound.
More generally, probabilistic deduction with conditional constraints over propositional
events can be done in a global approach by linear programming or in a local approach by
the iterative application of inference rules. Note that it is immediately NP-hard, since it
generalizes the satisability problem for classical propositional logic (see Section 2.2).
Research on the global approach spread in particular after the important work on probabilistic logic by Nilsson (1986) (see also the work by Paa, 1988). The main focus was
on analyzing the computational complexity of satisability and entailment in probabilistic logic and on developing ecient linear programming algorithms for these problems.
c 1999 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

Lukasiewicz

Georgakopoulos et al. (1988) show that the satisability problem in probabilistic logic is
NP-complete and propose to apply column generation techniques for its processing. This
approach was further developed by Kavvadias and Papadimitriou (1990), Jaumard et al.
(1991), Andersen and Hooker (1994), and Hansen et al. (1995). In particular, Jaumard et
al. (1991) report promising experimental results on the eciency in special cases of probabilistic satisability and entailment. Moreover, Kavvadias and Papadimitriou (1990) and
Jaumard et al. (1991) identify special cases of probabilistic satisability that can be solved
in polynomial time. Other work on the global approach concentrates on reducing the number of linear constraints (Luo et al. 1996) and the number of variables (Lukasiewicz, 1997).
Finally, Fagin et al. (1992) present a sound and complete axiom system for reasoning about
probabilities that are expressed by linear inequalities over propositional events. They show
that the satisability problem in this quite expressive framework is still NP-complete.
In early work, Dubois and Prade (1988) use inference rules to model default reasoning with imprecise numerical and fuzzy quantiers. For this reason, subsequent research
on inference rules especially aims at analyzing patterns of human commonsense reasoning
(Dubois et al. 1990, 1993; Amarger et al. 1991; Thone, 1994; Thone et al. 1995). Frisch
and Haddawy (1994) discuss the use of inference rules for deduction in probabilistic logic.
Recent work on inference rules concentrates on integrating probabilistic knowledge into description logics (Heinsohn, 1994) and on analyzing the interplay between taxonomic and
probabilistic deduction (Lukasiewicz 1998a, 1999a).
We now summarize the main characteristics of the global and the local approach.
The global approach can be performed within quite rich probabilistic languages (Fagin
et al., 1992). Crucially, probabilistic deduction by linear programming is globally complete
(that is, it really provides the requested tightest bounds entailed by the whole probabilistic
knowledge base). However, a main drawback of the global approach is that it generally does
not provide useful explanatory information on the deduction process. Finally, results on
the special-case tractability of global approaches are driven by the technical possibilities of
linear programming techniques and not by the needs of articial intelligence applications.
Hence, they do not seem to be very useful in the articial intelligence context.
A main advantage of the local approach is that the deduced results can be explained
in a natural way by the sequence of applied inference rules (Amarger et al. 1991; Frisch
& Haddawy, 1994). However, the iterative application of inference rules is generally restricted to quite narrow probabilistic languages. Moreover, it is very rarely and only within
very restricted languages globally complete (Frisch and Haddawy, 1994, give an example
of globally complete local probabilistic deduction in a very restricted framework). Finally,
as far as the computational complexity is concerned, there are very few experimental and
theoretical results on the special-case tractability of local approaches.
The main motivating idea of this paper is to elaborate ecient local techniques for
globally complete probabilistic deduction. Inspired by previous work on inference rules, we
focus our research on the language of conditional constraints over basic events:
Dubois and Prade (1988) study the chaining of two bidirectional conditional constraints
over basic events (\quantied syllogism rule") and some of its special cases. Dubois et
al. (1990) additionally discuss probabilistic deductions about conjunctions of basic events.
Furthermore, they describe the open problem of probabilistic deduction along a chain of
more than two bidirectional conditional constraints over basic events. In later work, Dubois
200

Probabilistic Deduction with Conditional Constraints over Basic Events

et al. (1993) use a qualitative version of the \quantied syllogism rule" in an approach to
reasoning with linguistic quantiers. Amarger et al. (1991) propose to apply the \quantied syllogism rule" and the \generalized Bayes' rule" to sets of bidirectional conditional
constraints over basic events. They report promising experimental results on the global completeness and the computational complexity of the presented deduction technique. However,
this deduction technique is generally not globally complete. Thone (1994) examines trees of
bidirectional conditional constraints over basic events. He presents a linear-time deduction
technique that is based on a system of inference rules and that computes certain logically
entailed greatest lower bounds (in the technical notions of this paper, which will be dened
below, tight lower answers to conclusion-restricted queries are computed).
As a rst contribution of this paper, we show that globally complete probabilistic deduction with conditional constraints over basic events is NP-hard. It is surprising that this
quite restricted class of probabilistic deduction problems is still computationally so dicult. Hence, it is unlikely that there is an algorithm that eciently solves all probabilistic
deduction problems with conditional constraints over basic events. However, we can still
hope that there are ecient special-case, average-case, or approximation algorithms.
In this paper, we then elaborate ecient special-case algorithms. In detail, we concentrate on probabilistic deduction in conditional constraint trees. It is an interesting subclass of all probabilistic deduction problems with conditional constraints over basic events.
Conditional constraint trees are undirected trees with basic events as nodes and with bidirectional conditional constraints over basic events as edges between the nodes (that is,
deduction in conditional constraint trees is a generalization of deduction along a chain of
bidirectional conditional constraints over basic events). Like Bayesian networks, conditional
constraint trees represent a well-structured probabilistic knowledge base. Dierently from
Bayesian networks, they do not encode any probabilistic independencies.
As a main contribution of this paper, we have the following results. For conditional constraint trees with point probabilities, we present functions for deducing greatest lower and
least upper bounds in linear time in the size of the conditional constraint trees. Moreover, for
conditional constraint trees with interval probabilities, we show that greatest lower bounds
can be deduced in the same way, in linear time in the size of the conditional constraint trees.
However, computing least upper bounds turns out to be computationally more dicult. It
can be done by solving special nonlinear programs. We show how these nonlinear programs
can be transformed into equivalent linear programs. The resulting linear programs have a
number of variables and inequalities linear and polynomial, respectively, in the size of the
conditional constraint trees. Thus, our way of deducing least upper bounds still runs in
polynomial time in the size of the conditional constraint trees, since linear programming
runs in polynomial time in the size of the linear programs.
Another important contribution of this paper is related to the question whether to
perform probabilistic deduction with conditional constraints by the iterative application of
inference rules or by linear programming. On the one hand, the idea of inference rules carries
us to very ecient techniques for globally complete probabilistic deduction in conditional
constraint trees. In particular, the considered deduction problems generalize patterns of
commonsense reasoning. However, on the other hand, the corresponding proofs of soundness
and global completeness are technically quite complex. Hence, it seems unlikely that the
results of this work can be extended to signicantly more general probabilistic deduction
201

Lukasiewicz

problems. Note that a companion paper (1998a, 1999a) reports similar limits of the local
approach in probabilistic deduction under taxonomic knowledge.
The rest of this paper is organized as follows. In Section 2, we formulate the probabilistic deduction problems considered in this work. Section 3 focuses on the probabilistic
satisability of conditional constraint trees. Section 4 deals with globally complete probabilistic deduction in exact and general conditional constraint trees. In Section 5, we give a
comparison with Bayesian networks. Section 6 summarizes the main results of this work.

2. Formulating the Probabilistic Deduction Problem

In this section, we introduce the syntactic and semantic notions related to probabilistic
knowledge in general and to conditional constraint trees in particular.

2.1 Probabilistic Knowledge

Before focusing on the details of conditional constraint trees, we give a general introduction
to the kind of probabilistic knowledge considered in this work. We deal with conditional
constraints over propositional events. They represent interval restrictions for conditional
probabilities of propositional events. Note that the formal background introduced in this
section is commonly accepted in the literature (see especially the work by Frisch and Haddawy, 1994, for other work in the same spirit).
We assume a nonempty and nite set of basic events B = fB1 ; B2 ; : : : ; Bn g. The set of
conjunctive events CB is the closure of B under the Boolean operation ^. We abbreviate the
conjunctive event C ^ D by CD . The set of propositional events GB is the closure of B under
the Boolean operations ^ and :. We abbreviate the propositional events G ^ H and :G
by GH and G, respectively. The false event B1 ^ :B1 and the true event :(B1 ^ :B1 ) are
abbreviated by ? and >, respectively. Conditional constraints are expressions of the form
(H jG)[u1 ; u2 ] with real numbers u1 ; u2 2 [0; 1] and propositional events G and H . In the
conditional constraint (H jG)[u1 ; u2 ], we call G the premise and H the conclusion.
To dene probabilistic interpretations of propositional events and of conditional constraints, we introduce atomic events and the binary relation ) between atomic and propositional events. The set of atomic events AB is dened by AB = fE1 E2    En j Ei = Bi
or Ei = B i for all i 2 [1: n]g. Note that each atomic event can be interpreted as a possible
world (which corresponds to a mapping from B to ftrue; falseg). For all atomic events A
and all propositional events G, let A ) G i AG is a propositional contradiction.
A probabilistic interpretation Pr is a mapping from AB to [0; 1] such that all Pr (A) with
A 2 AB sum up to 1. Pr is extended in a well-dened way to propositional events G by:
Pr (G) is the sum of all Pr (A) with A 2 AB and A ) G. Pr is extended to conditional
constraints by: Pr j= (H jG)[u1 ; u2 ] i u1  Pr (G)  Pr (GH )  u2  Pr (G).
Note that conditional constraints characterize conditional probabilities of events, rather
than probabilities of conditional events (Coletti, 1994; Gilio & Scozzafava, 1994). Note also
that Pr (G) = 0 always entails Pr j= (H jG)[u1 ; u2 ]. This semantics of conditional probability
statements is also assumed by Halpern (1990) and by Frisch and Haddawy (1994).
The notions of models, satisability, and logical consequence for conditional constraints
are dened in the classical way. A probabilistic interpretation Pr is a model of a conditional
constraint (H jG)[u1 ; u2 ] i Pr j= (H jG)[u1 ; u2 ]. Pr is a model of a set of conditional
202

Probabilistic Deduction with Conditional Constraints over Basic Events

constraints KB , denoted Pr j= KB , i Pr is a model of all (H jG)[u1 ; u2 ] 2 KB . KB is
satisable i a model of KB exists. (H jG)[u1 ; u2 ] is a logical consequence of KB; denoted
KB j= (H jG)[u1 ; u2 ], i each model of KB is also a model of (H jG)[u1 ; u2 ].
For a conditional constraint (H jG)[u1 ; u2 ] and a set of conditional constraints KB , let
u denote the set of all real numbers u 2 [0; 1] for which there exists a model Pr of KB with
u  Pr (G) = Pr (GH ) and Pr (G) > 0. Now, we easily verify that (H jG)[u1 ; u2 ] is a logical
consequence of KB i u1  inf u and u2  sup u.
This observation yields a canonical notion of tightness for logical consequences of conditional constraints. The conditional constraint (H jG)[u1 ; u2 ] is a tight logical consequence
of KB; denoted KB j=tight (H jG)[u1 ; u2 ], i u1 = inf u and u2 = sup u.
The set u is a closed interval in the real line (Frisch & Haddawy, 1994). Note that for
u = ;, we canonically dene inf u = max [0; 1] = 1 and sup u = min [0; 1] = 0. Thus, u = ;
i KB j= (Gj>)[0; 0] i KB j=tight (H jG)[1; 0] i KB j= (H jG)[u1 ; u2 ] for all u1 ; u2 2 [0; 1].
Based on the just introduced notion of tight logical consequence, probabilistic deduction
problems and their solutions are more formally specied as follows.
A probabilistic knowledge base (B; KB ) consists of a set of basic events B and a set of
conditional constraints KB over GB with u1  u2 for all (H jG)[u1 ; u2 ] 2 KB . A probabilistic
query to a probabilistic knowledge base (B; KB ) is an expression of the form 9(F jE )[x1 ; x2 ]
with E; F 2 GB and two dierent variables x1 and x2 . Its tight answer is the substitution
 = fx1 =u1 ; x2 =u2 g with u1 ; u2 2 [0; 1] such that KB j=tight (F jE )[u1 ; u2 ] (we call 1 =
fx1 =u1 g the tight lower answer and 2 = fx2 =u2 g the tight upper answer). A correct answer
is a substitution  = fx1 =u1 ; x2 =u2 g with u1 ; u2 2 [0; 1] such that KB j= (F jE )[u1 ; u2 ].
Finally, we dene the notions of soundness and of completeness related to inference
rules and to techniques for probabilistic deduction. An inference rule KB ` (H jG)[u1 ; u2 ] is
sound i KB j= (H jG)[u1 ; u2 ], where (H jG)[u1 ; u2 ] is a conditional constraint and KB is a
set of conditional constraints. It is sound and locally complete i KB j=tight (H jG)[u1 ; u2 ].
A technique for probabilistic deduction is sound for a set of probabilistic queries Q i it computes a correct answer to any given query from Q. It is sound and globally complete for Q
i it computes the tight answer to any given query from Q.

2.2 Computational Complexity

In the framework of conditional constraints over propositional events, the optimization problem of computing the tight answer to a probabilistic query is immediately NP-hard, since it
generalizes the satisability problem for classical propositional logic (the NP-complete problem of deciding whether a propositional formula in conjunctive normal form is satisable;
see especially the survey by Garey and Johnson, 1979).
Surprisingly, the optimization problem of computing the tight answer to a probabilistic
query remains NP-hard even if we just consider conditional constraints over basic events:

Theorem 2.1 The optimization problem of computing the tight answer to a probabilistic

query over basic events that is directed to a probabilistic knowledge base over basic events
is NP-hard.

Proof. The NP-complete decision problem of graph 3-colorability (Garey & Johnson, 1979)
can be polynomially-reduced to the optimization problem of computing the tight answer
203

Lukasiewicz

to a probabilistic query over basic events that is directed to a probabilistic knowledge base
over basic events. The proof follows similar lines to the proof of NP-hardness of 2PSAT
given by Georgakopoulos et al. (1988).
Let (V; E ) be a nite undirected graph. We construct a probabilistic knowledge base
(B; KB ) as follows. We initialize (B; KB ) with (fB g; ;). For each node v 2 V , we increase
B by the new basic events Bv1, Bv2, and Bv3. For each node v 2 V and for each i 2 f1; 2; 3g,
we increase KB by (B jBvi )[1; 1] and (Bvi jB )[1=3; 1=3]. For each node v 2 V and for each
i; j 2 f1; 2; 3g with i < j , we increase KB by (Bvj jBvi )[0; 0]. For each edge fu; vg 2 E and for
each i 2 f1; 2; 3g, we increase KB by (Bvi jBui )[0; 0]. It is easy to see that the probabilistic
knowledge base (B; KB ) can be constructed in polynomial time in the size of (V; E ).
Now, we show that (V; E ) is 3-colorable i fx1 =1; x2 =1g is the tight answer to the
probabilistic query 9(B jB )[x1 ; x2 ] to (B; KB ), or equivalently, i KB is satisable:
If (V; E ) is 3-colorable, then there exists a mapping c1 from V to f1; 2; 3g with c1 (u) 6=
c1 (v) for all edges fu; vg 2 E . Thus, if  is a cyclic permutation of the members in f1; 2; 3g
and if c2 ; c3 : V ! f1; 2; 3g are dened by c2 (v) = (c1 (v)) and c3 (v) = (c2 (v)) for all
nodes v 2 V , then also c2 (u) 6= c2 (v) and c3 (u) 6= c3 (v) for all edges fu; vg 2 E . For
j 2 f1; 2; 3g, let Aj 2 AB such that Aj ) B and Aj ) Bvi i cj (v) = i for all nodes v 2 V
and i 2 f1; 2; 3g. If Pr : AB ! [0; 1] is dened by Pr (A) = 1=3 for all A 2 fA1 ; A2 ; A3 g and
by Pr (A) = 0 for all A 2 AB n fA1 ; A2 ; A3 g, then Pr is a model of KB .
Conversely, if there is a model Pr of KB , then there is an atomic event A 2 AB with
Pr (A) > 0. Thus, if c : V ! f1; 2; 3g is dened by c(v) = i i A ) Bvi for all nodes v 2 V ,
then c(u) 6= c(v) for all edges fu; vg 2 E . Hence, (V; E ) is 3-colorable. 2
Hence, it is unlikely that there is an ecient algorithm for computing the tight answer
to all probabilistic queries over basic events that are directed to any given probabilistic
knowledge base over basic events. However, there may still be ecient algorithms for
solving more specialized probabilistic deduction problems.
The rest of this work deals with probabilistic deduction in conditional constraint trees.
The next section provides a motivating example, which gives evidence of the practical
importance of this kind of probabilistic deduction problems.

2.3 Motivating Example
A senior student in mathematics describes her experience about being successful at the university as follows. The success of a student (su) is inuenced by how well-informed (wi) and
how well-prepared (wp) the student is. Well-informedness can be reached by interviewing
professors (pr) or by asking senior students (st). Being well-prepared is inuenced by how
much time is invested in books (bo), exercises (ex), and hobbies (ho).
It is estimated that the probability of a student being successful given she is wellinformed lies between 0.60 and 0.70, that the probability of a student being well-informed
given she is successful is greater than 0.85, that the probability of a student being successful
given she is well-prepared is greater than 0.95, and that the probability of a student being
well-prepared given she is successful is greater than 0.95.
This probabilistic knowledge completed by further probabilistic estimations is given by
the probabilistic knowledge base (B; KB ) in Fig. 1, where B is the set of nodes fsu; wi; wp; pr;
204

Probabilistic Deduction with Conditional Constraints over Basic Events

st; bo; ex; hog and KB is the least set of conditional constraints that contains (Y jX )[u1 ; u2 ]
for each arrow from X to Y labeled with u1 ; u2 .
st

ho
.6,.7

.95,1

.35,.4

.6,.7

wi

su
.85,1

.95,1

.35,.4

.95,1

.85,.9

wp
.95,1

.05,.1

.95,1

pr

ex
.85,.9
.95,1

bo

Figure 1: A Conditional Constraint Tree
We may wonder whether it is useful for being successful at the university to interview the
professors, to study on books, to spend the time on one's hobbies, or to do both studying
on books and spending the time on one's hobbies. This can be expressed by the probabilistic queries 9(sujpr)[x1 ; x2 ], 9(sujbo)[x1 ; x2 ], 9(sujho)[x1 ; x2 ], and 9(sujbo ho)[x1 ; x2 ],
which yield the tight answers fx1 =0:00, x2 =1:00g, fx1 =0:90; x2 =1:00g, fx1 =0:30; x2 =0:46g,
and fx1 =0:71; x2 =1:00g, respectively.
We may wonder whether successful students at the university interviewed their professors, whether they studied on books, whether they spent their time with their hobbies, or
whether they both studied on books and spent their time with their hobbies. This can be
expressed by the probabilistic queries 9(prjsu)[x1 ; x2 ], 9(bojsu)[x1 ; x2 ], 9(hojsu)[x1 ; x2 ], and
9(bo hojsu)[x1 ; x2 ], which yield the tight answers fx1=0:00, x2=0:17g, fx1=0:90; x2 =1:00g,
fx1 =0:30; x2 =0:45g, and fx1=0:25; x2 =0:45g, respectively.

2.4 Conditional Constraint Trees

We formally dene conditional constraint trees and queries to conditional constraint trees.
We provide some additional examples, which are subsequently used as running examples.
A (general) conditional constraint tree is a probabilistic knowledge base (B; KB ) for
which an undirected tree (a singly connected undirected graph) (B; $) exists such that
KB contains exactly one pair of conditional constraints (B jA)[u1 ; u2 ] and (AjB )[v1 ; v2 ] with
u1 ; v1 > 0 for each pair of adjacent nodes A and B (note that B = fB g implies KB = ;).
A basic event B 2 B is called a leaf in (B; KB ) i it has exactly one neighbor in (B; $).
A conditional constraint tree is exact i u1 = u2 for all (B jA)[u1 ; u2 ] 2 KB .
A query to a conditional constraint tree is a probabilistic query 9(F jE )[x1 ; x2 ] with two
conjunctive events E and F that are disjoint in their basic events and such that all paths
from a basic event in E to a basic event in F have at least one basic event in common.
A query 9(F jE )[x1 ; x2 ] to a conditional constraint tree is premise-restricted i E is a basic
event. It is conclusion-restricted i F is a basic event. It is strongly conclusion-restricted
i F is the only basic event that is contained in all paths from a basic event in E to F .
It is complete i EF contains exactly the leaves of (B; $).
205

Lukasiewicz

Fig. 2 shows two conditional constraint trees of which the one on the left side is exact.

9(STUjMNQR)[x1 ; x2] is a query, while 9(MSjQU)[x1 ; x2 ] is not a query to the conditional
constraint trees of Fig. 2. Furthermore, 9(STUjM)[x1 ; x2 ] is a premise-restricted query,
9(OjQRSTU)[x1 ; x2] a strongly conclusion-restricted query, and 9(QRSTUjM)[x1 ; x2 ] a prem-

ise-restricted complete query to the conditional constraint trees of Fig. 2.
1)

2)

T
.85

.85

P
1

.85

M

N
.85

.3,.4

M

Q

.9,1

.5,.6

N
.8,.9

.95
.95

.15

1

.8,.9

O

U

.8,.9

.95

1

.8,.9

P

.95

.55

.9,1

.9,1

S

U

.85
.35

.8,.9

.95

.95

S

T

.9,1

O
1
.1,.2

R

Q
.9,1
.9,1

R

Figure 2: Two Conditional Constraint Trees
For conditional constraint trees (B; KB ), conjunctive events C , and basic events B , we
write C ) B i there exists a path G1 ; G2 ; : : : ; Gk from a basic event G1 in C to the basic
event Gk = B such that (Gi+1 jGi )[1; 1] 2 KB for all i 2 [1 : k , 1]. We write B ) C i for
all paths G1; G2 ; : : : ; Gk from the basic event G1 = B to a basic event Gk in C , it holds
(Gi+1 jGi )[1; 1] 2 KB for all i 2 [1 : k , 1]. That is, the conditions C ) B and B ) C
immediately entail KB j= (B jC )[1; 1] and KB j= (C jB )[1; 1], respectively.
Note that the restriction u1 ; v1 > 0 for all (B jA)[u1 ; u2 ], (AjB )[v1 ; v2 ] 2 KB is just made
for technical convenience. The deduction technique of Section 4 can easily be generalized
to conditional constraint trees (B; KB ) that satisfy only the restriction u1 > 0 i v1 > 0 for
all (B jA)[u1 ; u2 ]; (AjB )[v1 ; v2 ] 2 KB (Lukasiewicz, 1996).
The restriction that for each query 9(F jE )[x1 ; x2 ], all paths from a basic event in E
to a basic event in F have at least one basic event in common is crucial for the deduction
technique of Section 4. It assures that the problem of computing the tight answer to a
complete query can be reduced to the problems of computing the tight answer to a premiserestricted complete query and the tight answer to a strongly conclusion-restricted complete
query. Note that this restriction is trivially satised by all premise- and conclusion-restricted
queries (for example, by all the queries in Section 2.3).
Especially tight answers to conclusion-restricted queries seem to be quite important in
practice. They may be used to characterize the probability of uncertain basic events given
a collection of basic events that are known with certainty.
206

Probabilistic Deduction with Conditional Constraints over Basic Events

3. Probabilistic Satisability

In this section, we show that conditional constraint trees have the nice property that they
are always satisable. That is, within conditional constraint trees, the user is prevented
from specifying inconsistent probabilistic knowledge.
First, note that conditional constraint trees always have a trivial model in which the
probability of the conjunction of all negated basic events is one and in which the probability
of all the other atomic events is zero.
The next lemma shows that, given a model Pr of a conditional constraint tree and a
real number s from [0; 1], we can construct a new model Pr s by setting Pr s (A) = s  Pr (A)
for all atomic events A that are dierent from the conjunction of all negated basic events.
Note that Pr 0 coincides with the trivial model and that Pr 1 is identical to Pr . This lemma
is crucial for inductively constructing models of conditional constraint trees.

Lemma 3.1 Let (B; KB ) be a conditional constraint tree with B = fB1 ; B2 ; : : : ; Bng. Let
Pr be a model of KB and let s be a real number from [0; 1].
The mapping Prs : AB ! [0; 1] with Prs (A) = s  Pr (A) for all A 2 AB n fB 1 B 2    B n g
and Prs (B 1 B 2    B n ) = s  Pr (B 1 B 2    B n ) , s + 1 is a model of KB.
Proof. We easily verify that Prs is a probabilistic interpretation. It remains to show that
Prs is also a model of KB . Let (H jG)[u1 ; u2 ] 2 KB . Since Pr is a model of KB , we have
Pr j= (H jG)[u1 ; u2 ], hence u1  Pr (G)  Pr (GH )  u2  Pr (G), and thus also u1 s  Pr (G) 
s  Pr (GH )  u2 s  Pr (G). Since neither B 1 B2    B n ) G nor B 1 B 2    B n ) GH , we get
u1  Prs (G)  Prs (GH )  u2  Prs (G) and thus Prs j= (H jG)[u1 ; u2 ]. 2

Finally, the following theorem shows that conditional constraint trees always have a
nontrivial model in which all the basic events have a probability greater than zero.

Theorem 3.2 Let (B; KB ) be a conditional constraint tree with B = fB1 ; B2 ; : : : ; Bn g.
There is a model Pr of KB with Pr (B1 B2    Bn ) > 0.
Proof. It is sucient to show the claim for exact conditional constraint trees. The claim

is proved by induction on the number of basic events.
Basis: for (B; KB ) = (fB g; ;), a model Pr of KB with Pr (B ) > 0 is given by B; B 7! 0; 1
(note that B; B 7! 0; 1 is an abbreviation for Pr (B ) = 0 and Pr (B ) = 1).
Induction: let (B; KB ) = (B1 [ B2 ; KB 1 [ KB 2 ) with two exact conditional constraint trees
(B1 ; KB 1 ) = (fB; C g; f(C jB )[u; u]; (B jC )[v; v]g) and (B2 ; KB 2 ) = (fC; D1 ; : : : ; Dk g; KB 2 )
such that B1 \ B2 = fC g. A model Pr 1 of KB 1 with Pr 1 (BC ) > 0 is given by:

B C; BC; BC; BC 7!

uv v,uv u,uv uv
u+v ; u+v ; u+v ; u+v

:

By the induction hypothesis, there is a model Pr 2 of KB 2 (that is dened on the atomic
events over B2 ) with Pr 2 (CD1    Dk ) > 0. By Lemma 3.1, we can assume Pr 2 (C ) = Pr 1 (C ).
A probabilistic interpretation Pr on the atomic events over B is now dened by:
Ac )Pr 2 (Ac A2 )
Pr (Ab Ac A2 ) = Pr 1 (AbPr
2 (Ac )

207

Lukasiewicz

for all atomic events Ab , Ac , and A2 over fB g, fC g, and B2 n fC g, respectively. We easily
verify that Pr (Ab Ac ) = Pr 1 (Ab Ac ) and Pr (Ac A2 ) = Pr 2 (Ac A2 ) for all atomic events
Ab , Ac , and A2 over fB g, fC g, and B2 n fC g, respectively. Hence, Pr is a model of KB .
Moreover, Pr 1 (BC ) > 0 and Pr 2 (CD1    Dk ) > 0 entails Pr (BCD1    Dk ) > 0. 2

4. Probabilistic Deduction

In this section, we present techniques for computing tight answers to queries directed to
exact and general conditional constraint trees, and we analyze their computational complexity. More precisely, the problem of computing the tight answer to a query is reduced to
the problem of computing the tight answer to a complete query. The latter problem is then
reduced to the problems of computing the tight answer to a premise-restricted complete
query and the tight answer to a strongly conclusion-restricted complete query.

4.1 Premise-Restricted Complete Queries
4.1.1 Exact Conditional Constraint Trees

We now focus on the problem of computing tight answers to premise-restricted complete
queries that are directed to exact conditional constraint trees.
Let (B; KB ) be an exact conditional constraint tree and let 9(F jE )[x1 ; x2 ] be a premiserestricted complete query. To compute the tight answer to 9(F jE )[x1 ; x2 ], we start by
dening a directed tree (that is, a directed acyclic graph in which each node has exactly
one parent, except for the root, which does not have any):

A ! B i A $ B and A is closer to E than B .
This directed tree (B; !) is uniquely determined by the conditional constraint tree and the
premise-restricted complete query. Fig. 3 shows (B; !) for the premise-restricted complete
query 9(QRSTUjM)[x1 ; x2 ] to the exact conditional constraint tree in Fig. 2, left side.

Now, the set of nodes B is partitioned into several strata. The lowest stratum contains
only nodes with no children in (B; !), the highest stratum contains the nodes with no
parents in (B; !) (that is, exactly the node of the premise E of the query). Fig. 3 also
shows the dierent strata in our example.
At each node of (B; !), we compute certain tightest bounds that are logically entailed
by KB . More precisely, the tightest bounds at a node B are computed locally, by exploiting
the tightest bounds that have previously been computed at the children of B . Hence, we
iteratively compute the tightest bounds at the nodes of each stratum, starting with the
nodes of the lowest stratum and terminating with the nodes of the highest stratum. We
distinguish three dierent ways of computing tightest bounds at a node:
 initialization of a leaf (Leaf),
 chaining of an arrow and a subtree via a common node (Chaining),
 fusion of subtrees via a common node (Fusion).
Let us consider again the premise-restricted complete query 9(QRSTUjM)[x1 ; x2 ] to the
exact conditional constraint tree in Fig. 2, left side. Fig. 4 illustrates the three dierent ways
208

Probabilistic Deduction with Conditional Constraints over Basic Events

S
P
T
O
M

N

U

Q

R
3

4

1

2

0

strata

Figure 3: Directed Tree (B; !)
of computing tightest bounds at a node (the common nodes for Chaining and Fusion are
lled black). Table 1 shows the greatest lower and the least upper bounds that are computed
at each node B of each stratum. More precisely, these bounds are 1 = inf Pr (BD )=Pr (B ),
2 = sup Pr (BD )=Pr (B ), 2 = sup Pr (BD )=Pr (B ), and 2 = sup Pr (D )=Pr (B ) subject to
Pr j= KB and Pr (B ) > 0. Table 1 also shows the requested tight answer fx1 =0:02; x2 =0:17g,
which is given by the tightest bounds 1 and 2 that are computed at the premise M.
strata B
S
0 T
U
P
1 P
P
P
1 Q
R
O
2 O
O
2 O
3 N
4 M

D

S
T
U
S
T
U
STU
Q
R
STU
Q
R
QRSTU
QRSTU
QRSTU

1

1:0000
1:0000
1:0000
0:8500
0:8500
0:8500
0:5500
1:0000
1:0000
0:4474
0:9500
0:9500
0:3474
0:1911
0:0169

2

1:0000
1:0000
1:0000
0:8500
0:8500
0:8500
0:8500
1:0000
1:0000
0:7605
0:9500
0:9500
0:7605
0:4183
0:1722

2

0:0000
0:0000
0:0000
0:0447
0:0447
0:0000
0:0000
0:0000
0:0000
0:0447
0:0500
5:3833
0:0447
0:0246
0:0719

2

1:0000
1:0000
1:0000
0:8947
0:8947
0:8500
0:8500
1:0000
1:0000
0:7605
1:0000
6:3333
0:7605
0:4183
0:1722

(Leaf)
(Leaf)
(Leaf)
(Chaining)
(Chaining)
(Chaining)
(Fusion)
(Leaf)
(Leaf)
(Chaining)
(Chaining)
(Chaining)
(Fusion)
(Chaining)
(Chaining)

Table 1: Locally Computed Tightest Bounds
209

Lukasiewicz

S

Initialization of a leaf:
P

T
O
M

Q

N

U

R

S

Chaining of an arrow and a subtree:
P

T
O
M

Q

N

U

R

S

Fusion of subtrees:
P

T
O
M

N

Q

R

Figure 4: Local Computations in (B; !)
210

U

Probabilistic Deduction with Conditional Constraints over Basic Events

We now focus on the technical details. We present the functions H1 , H2 , H2 , and H2 ,
which compute the described greatest lower and least upper bounds. For this purpose, we
need the following denitions. Let Pr (C jB ) denote u for all (C jB )[u; u] 2 KB .
A node B is a leaf if it does not have any children. For all leaves B , let B " = B . For all
the other nodes B , let B " be the conjunction of all the children of B . For all leaves C , let
L(C ) = C . For all the other conjunctive events C , let L(C ) be the conjunction of all the
leaves that are in C or that are descendants of a node in C .
In the sequel, let B be a node and let C = B " . The case C = B refers to the initialization
of the leaf B , the case C = B1 with a node B1 6= B to the chaining of the arrow B ! B1
and a subtree via the common node B1 , and the case C = B1 B2 : : : Bk with k > 1 nodes
B1; B2 ; : : : ; Bk to the fusion of k subtrees via the common node B .
We dene the function H1 for computing greatest lower bounds: let H1 (B; C ) = 1
(note that 1 will coincide with the greatest lower bound of Pr (BL(C )) = Pr (B ) subject to
Pr j= KB and Pr (B ) > 0), where 1 in Leaf (C = B ), Chaining (C = B1 ), and Fusion
(C = B1 B2 : : : Bk with k > 1) is given as follows:
Leaf

:

1 = 1
:

"
1 = max(0; Pr (C jB )  (1 + H1Pr(C;(BCjC)),1 ))

Chaining

Fusion

:

1 = max(0; 1 , k + P H1 (B; Bi))
k

i=1

To express that H1 computes greatest lower bounds, we need the following denitions.
Let B(B; C ) comprise B , all nodes in C and all descendants of a node in C . Let KB (B; C )
be the set of all conditional constraints of KB over B(B; C ). Let Mo (B; C ) be the set of all
models of KB (B; C ) that are dened on the atomic events over B(B; C ).
Now, the function H1 is sound and globally complete with respect to B and C i

H1 (B; C ) = 1 is the greatest lower bound of Pr (BL(C )) = Pr (B ) subject to Pr 2 Mo (B; C )
and Pr (B ) > 0. Thus, the next theorem shows soundness and global completeness of H1 .

Theorem 4.1

a) For all probabilistic interpretations Pr 2 Mo (B; C ), it holds 1  Pr (B )  Pr (BL(C )).
b) There exists a probabilistic interpretation Pr 2 Mo (B; C ) with Pr (B ) > 0, 1  Pr (B ) =
Pr (BL(C )), and Pr (BL(C )) = 0 i L(C ) ) B .

Proof. The proof is given in full detail in Appendix B. 2

Next, we present the functions H2 , H2 , and H2 for computing least upper bounds. Note
that H2 , H2 , and H2 show the crucial result that for exact conditional constraint trees,
there are local probabilistic deduction techniques that are sound and globally complete.
211

Lukasiewicz

In detail, let H2 (B; C ) = 2 , H2 (B; C ) = 2 , and H2 (B; C ) = 2 (note that 2 , 2 ,
and 2 will coincide with the least upper bound of Pr (BL(C )) = Pr (B ), Pr (BL(C )) = Pr (B ),
and Pr (L(C )) = Pr (B ), respectively, subject to Pr j= KB and Pr (B ) > 0), where 2 , 2 ,
and 2 in Leaf (C = B ), Chaining (C = B1 ), and Fusion (C = B1 B2 : : : Bk with k > 1)
are given as follows:
Leaf

:

2 = 1
2 = 0
2 = 1
:

"

"
2 = min(1; Pr (C jB )  HPr2 ((C;BjCC )) ; 1 , Pr (C jB )  (1 , HPr2 ((C;BjCC ) ) );

Chaining



Pr (C jB )  (1 + HPr2 ((C;BjCC ) ) ))


"



H2 (C; C )
2 = min(Pr (C jB )  ( H2Pr(C;(BCjC)+1
) , 1); Pr (C jB )  Pr (B jC ) )


"

"

2 = Pr (C jB )  HPr2 ((C;BjCC ))
Fusion

"

:

2 = i2min
H  (B; Bi )
[1:k] 2
2 = i2min
H  (B; Bi )
[1:k] 2

2 = min(i2min
H2 (B; Bi ); min (H2 (B; Bi ) + H2 (B; Bj )))
[1:k]
i;j 2[1:k];i6=j
The functions H2 , H2 , and H2 are sound and globally complete with respect to B
and C i H2 (B; C ) = 2 , H2 (B; C ) = 2 , and H2 (B; C ) = 2 are the least upper bounds
of Pr (BL(C )) = Pr (B ), Pr (BL(C )) = Pr (B ), and Pr (L(C )) = Pr (B ), respectively, subject
to Pr 2 Mo (B; C ) and Pr (B ) > 0. Hence, the following theorem shows soundness and
global completeness of H2 , H2 , and H2 (actually, it shows even more to enable a proof by
induction on the recursive denition of H2 , H2 , and H2 ).

Theorem 4.2

a) For all probabilistic interpretations Pr 2 Mo (B; C ), it holds Pr (BL(C ))  2  Pr (B ),
Pr (BL(C ))  2  Pr (B ), and Pr (L(C ))  2  Pr (B ).
b) There exists a probabilistic interpretation Pr 2 Mo (B; C ) with Pr (B ) > 0, Pr (BL(C )) =
2  Pr (B ), and Pr (L(C )) = 2  Pr (B ).
c) There exists a probabilistic interpretation Pr 2 Mo (B; C ) with Pr (B ) > 0, Pr (BL(C )) =
2  Pr (B ), and Pr (L(C )) = 2  Pr (B ).
212

Probabilistic Deduction with Conditional Constraints over Basic Events

Proof. The proof is given in full detail in Appendix B. 2
Note that Theorem 4.2 also shows that H2 (B; Bi )  H2 (B; Bi ) + H2 (B; Bi ) for all
i 2 [1: k]. Thus, the expression mini;j 2[1:k];i6=j (H2 (B; Bi ) + H2 (B; Bj )) in the denition of

2 in Fusion can be replaced by 2 + 2 for an increased eciency in computing 2 by
exploiting the already computed values of 2 and 2 .
Briey, by Theorems 4.1 and 4.2, the tight answer to the premise-restricted complete
query 9(F jE )[x1 ; x2 ] is given by fx1 =H1 (E; E " ); x2 =H2 (E; E " )g.
4.1.2 Conditional Constraint Trees

We now focus on computing the tight answer to premise-restricted complete queries to
general conditional constraint trees. In the sequel, let (B; KB ) be a conditional constraint
tree and let 9(F jE )[x1 ; x2 ] be a premise-restricted complete query.
We may think that the local deduction technique for exact conditional constraint trees
of Section 4.1.1 can easily be generalized to conditional constraint trees. In fact, this is true
as far as the computation of greatest lower bounds is concerned. However, the computation
of least upper bounds cannot be generalized that easily from exact conditional constraint
trees to conditional constraint trees. More precisely, generalizing the computation of least
upper bounds results in solving nonlinear programs. These nonlinear programs and our way
to solve them are illustrated by the following chaining example.
Let the conditional constraint tree (B; KB ) be given by B = fM; N; O; Pg and KB =
f(NjM)[u1 ; u2 ]; (MjN)[v1 ; v2 ], (OjN)[x1 ; x2 ], (NjO)[y1 ; y2 ], (PjO)[r1 ; r2], (OjP)[s1 ; s2]g. Let us
consider the premise-restricted complete query 9(PjM)[z1 ; z2 ].
By Theorem 4.2 and some straightforward arithmetic transformations, the requested
least upper bound is the maximum of z subject to u 2 [u1 ; u2 ], v 2 [v1 ; v2 ], x 2 [x1 ; x2 ],
y 2 [y1; y2 ], r 2 [r1 ; r2 ], s 2 [s1 ; s2 ], and the nonlinear inequalities in (1) to (5):
(1)
z 1
(2)
z  1 , u + uv , uxv + uxr
vy
uxr
ux
(3)
z  1 , u + v , vy + uxr
vys
uxr + uxr
z  u , uxv + ux
(4)
,
vy
vy
vys
uxr
(5)
z  vys
In this system of nonlinear inequalities, all upper bounds of z are monotonically decreasing
in v, y, and s. Hence, we can equivalently maximize z subject to u 2 [u1 ; u2 ], x 2 [x1 ; x2 ],
r 2 [r1 ; r2 ], and the nonlinear inequalities in (6) to (10):
(6)
z 1
uxr
z  1 , u + vu1 , ux
(7)
v1 + v1 y1
uxr
uxr
(8)
z  1 , u + ux
v1 , v1 y1 + v1 y1 s1
ux
uxr
uxr
(9)
z  u , ux
v1 + v1 y1 , v1 y1 + v1 y1 s1
z  v1uxr
(10)
y1 s1
For example, the requested least upper bound for u1 = u2 = u and x1 = x2 = x is shown in
Fig. 5 for u; x 2 [0; 1], r1 = r2 = 0:15, v1 = 0:8, y1 = 0:8, and s1 2 f0:05; 0:1g. The requested
least upper bound for u1 < u2 or x1 < x2 is the maximum value over [u1 ; u2 ]  [x1 ; x2 ].
213

Lukasiewicz

s1=0.05

z2
0.99
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1

1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

1
0.9
0.8
0.7
0.6
0.1

0.2

0.5
0.3

0.4
0.4

0.5

x

0.3
0.6

u

0.7

0.2
0.8

0.9

0.1
1

s1=0.1

z2
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1

0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
1
0.9
0.8
0.7
0.6
0.1

0.2

0.5
0.3

0.4
0.4
u

0.5

0.3
0.6

0.7

x

0.2
0.8

0.9

0.1
1

Figure 5: Least Upper Bound z2 in the Chaining Example
214

Probabilistic Deduction with Conditional Constraints over Basic Events

We now transform this nonlinear program into an equivalent linear program (by replacing 1, u, ux, and uxr by the new variables xM, xN , xO , and xP , respectively). More
precisely, the maximum of z subject to u 2 [u1 ; u2 ], x 2 [x1 ; x2 ], r 2 [r1 ; r2 ], and the nonlinear inequalities in (6) to (10) coincides with the maximum of z subject to the following
system of linear inequalities over z and xB  0 (B 2 B):

z
z
z
z
z







xM
xM + 1,v1v1  xN , vy1 1y1  xO + v1 ys11 s1  xP
xM , vv11  xN + vy1 1y1  xO + v11,y1ss11  xP
v1  x + 1,y1  x + 1,s1  x
v1 N
v1 y1 O
v1 y1 s1 P
1
v1 y1 s1  xP

1
u1  xM
x1  xN
r1  xO






xM
xN
xO
xP






1

u2  xM
x2  xN
r2  xO

More generally, tight upper answers to premise-restricted complete queries to conditional
constraint trees can be computed by solving similar nonlinear programs, which can similarly
be transformed into linear programs.
For example, let us consider the premise-restricted complete query 9(QRSTUjM)[x1 ; x2 ]
to the conditional constraint tree in Fig. 2, right side. The requested least upper bound
is the maximum of x subject to the system of linear inequalities in Fig. 6 (we actually
generated 72 linear inequalities of which 31 were trivially subsumed by others). Note that
the nine variables xM to xU correspond to the nine nodes M to U.

x
x
x
x
x
x
x
x
x
x
x
x














xM
25 x
18 Q
25 xR
2
25 x
18 S
25 x
18 T
25 x
18 U
xN + 19 xP
xN + 19 xQ
xN + 19 xR
5x + 5 x
4 O 36 P
5x + 5 x
4 O 36 Q
5 x + 45 x
4 O 4 R

x
x
x
x
x
x
x
x
x
x
x













5
5
4 xP + 36 xQ
5
5
36 xP + 4 xQ
5
5
36 xP + 4 xR
5
5
36 xQ + 4 xR
xM , xN + 45 xO + 365 xR
xM + 14 xN , 45 xO + 54 xP
xM + 14 xN , 45 xO + 54 xQ
xM + 14 xN , 45 xO + 54 xR
xM + 14 xN , 45 xP + 25
18 xS
1
5
xM + 4 xN , 4 xP + 25
18 xT
xM + 14 xN , 45 xP + 25
18 xU

1
3
10 xM
1x
2 N
9
10 xO
9
10 xO
4
5 xO
4
5 xP
4
5 xP
4
5 xP











xM
xN
xO
xR
xQ
xP
xS
xT
xU











1

2x
5 M
3x
5 N

xO
xO
9
10 xO
9
10 xP
9
10 xP
9
10 xP

Figure 6: Generated Linear Inequalities in the Chaining Example
Thus, in this example, the tight upper answer is computed by solving a linear program
that has 10 variables and 72 linear inequalities. Note that computing the tight upper answer
by the classical linear programming approach would result in solving a linear program that
has 29 = 512 variables and 4  9 , 2 = 34 linear inequalities (see Section 4.6).
215

Lukasiewicz

Let us now focus on the technical details. We subsequently generalize the function H1
of Section 4.1.1 in a straightforward way to compute greatest lower bounds in conditional
constraint trees. Moreover, we present a linear program for computing the requested least
upper bound in conditional constraint trees.
Let Pr 1 (C jB ) denote u1 for all (C jB )[u1 ; u2 ] 2 KB . In the sequel, let B be a node and
let C = B " . Again, the cases C = B , C = B1 with a node B1 6= B , and C = B1 B2 : : : Bk
with k > 1 nodes B1 ; B2 ; : : : ; Bk refer to Leaf, Chaining, and Fusion, respectively.
We dene the generalized function H1 for computing greatest lower bounds in conditional constraint trees: let H1 (B; C ) = 1 (note that 1 will coincide with the greatest
lower bound of Pr (BL(C )) = Pr (B ) subject to Pr j= KB and Pr (B ) > 0), where 1 in Leaf
(C = B ), Chaining (C = B1 ), and Fusion (C = B1 B2 : : : Bk with k > 1) is given by:
Leaf

:

1 = 1
:

"
1 = max(0; Pr 1 (C jB )  (1 + H1Pr(C;1 (BCjC),) 1 ))

Chaining

Fusion

:

1 = max(0; 1 , k + P H1 (B; Bi))
k

i=1

H1 is sound and globally complete with respect to B and C i H1 (B; C ) = 1 is the
greatest lower bound of Pr (BL(C )) = Pr (B ) subject to Pr 2 Mo (B; C ) and Pr (B ) > 0.
Thus, the next theorem shows soundness and global completeness of H1 .

Theorem 4.3

a) For all probabilistic interpretations Pr 2 Mo (B; C ), it holds 1  Pr (B )  Pr (BL(C )).
b) There exists a probabilistic interpretation Pr 2 Mo (B; C ) with Pr (B ) > 0, 1  Pr (B ) =
Pr (BL(C )), and Pr (BL(C )) = 0 i L(C ) ) B .

Proof. The claims follow from Theorem 4.1. 2

Next, we focus on the requested least upper bound, which is computed by solving a
linear program as described in the two examples.
We start by dening the functions I  , I  , and I  over the variables xB (B 2 B). Let
I  (B; C ) = 2 , I  (B; C ) = 2 , and I  (B; C ) = 2 , where 2 , 2 , and 2 in Leaf (C = B ),
Chaining (C = B1 ), and Fusion (C = B1 B2 : : : Bk with k > 1) are given as follows:
Leaf

:

2 = xB
2 = 0
2 = xB
216

Probabilistic Deduction with Conditional Constraints over Basic Events

:
I  (C; C " ) ; x + I  (C; C " ) ; x , x + I  (C; C " ) )
2 = min(xB ; Pr
C Pr 1 (BjC ) B
C Pr 1 (BjC )
1 (B jC )

Chaining

I (C; C ) ;
2 = min( 1,PrPr1 (1B(BjCjC) )  xC + Pr
1 (B jC )


2 =
Fusion

I  (C; C " )
Pr 1 (BjC )

"

I  (C; C " )
Pr 1 (BjC ) )

:

2 = i2min
I (B; Bi )
[1:k]
2 = i2min
I  (B; Bi )
[1:k]

2 = min(i2min
I  (B; Bi ); i;j 2min
(I  (B; Bi ) + I  (B; Bj )))
[1:k]
[1:k];i6=j
The system of linear inequalities J (B; C ) is dened as the least set of linear inequalities
over xG  0 (G 2 B(B; C )) that contains 1  xB  1 and u1  xG  xH  u2  xG for all
(H jG)[u1 ; u2 ] 2 KB (B; C ) with G ! H (that is, G is the parent of H ).

The intuition behind these denitions can now be described as follows.
Each xG (G 2 B(B; C )) that satises J (B; C ) corresponds to the exact conditional constraint tree (B(B; C ); KB 0 (B; C )), where KB 0 (B; C ) contains the pair (H jG)[xH =xG ; xH =xG ]
and (GjH )[v1 ; v1 ] for each pair (H jG)[u1 ; u2 ]; (GjH )[v1 ; v2 ] 2 KB (B; C ) with G ! H .
We will show that the least upper bound of Pr (BL(C ))=Pr (B ), Pr (BL(C ))=Pr (B ),
and Pr (L(C ))=Pr (B ) subject to Pr j= KB 0 (B; C ) and Pr (B ) > 0 is given by I  (B; C ),
I  (B; C ), and I  (B; C ), respectively. It will then follow that the least upper bound of
Pr (BL(C ))=Pr (B ), Pr (BL(C ))=Pr (B ), and Pr (L(C ))=Pr (B ) subject to Pr j= KB (B; C )
and Pr (B ) > 0 is given by the maximum of I  (B; C ), I  (B; C ), and I  (B; C ), respectively,
subject to all xG (G 2 B(B; C )) satisfying J (B; C ).
That is, we implicitly performed the variable transformation described in the two examples. This transformation is indeed correct for conditional constraint trees:

Lemma 4.4
a) If xG (G 2 B(B; C )) satises J (B; C ), then for all conditional constraints (H jG)[u1 ; u2 ] 2
KB (B; C ) such that G ! H , there exists uH 2 [u1 ; u2 ] with xH = uH  xG .
b) Let uH 2 [u1 ; u2 ] for all (H jG)[u1 ; u2 ] 2 KB (B; C ) such that G ! H . There exists xG
(G 2 B(B; C )) with J (B; C ) and xH = uH  xG for all nodes H with parent G.
Proof. a) For all nodes H with parent G, let uH be dened by uH = xH = xG .
b) Let xB = 1, and for all nodes H with parent G, let xH be dened by xH = uH  xG . 2

We are now ready to formulate an optimization problem for computing the requested
least upper bound.
Theorem 4.5 Let X2 be the maximum of x subject to x  I (E; E " ) and J (E; E " ).
a) Pr (EL(E " ))  X2  Pr (E ) for all Pr 2 Mo (E; E " ).
b) There exists Pr 2 Mo (E; E " ) with Pr (E ) > 0 and Pr (EL(E " )) = X2  Pr (E ).
217

Lukasiewicz

Proof. Let Pr (B jC ) = v1 for all (B jC )[v1 ; v2 ] 2 KB such that B ! C . By Theorem 4.2,
the requested least upper bound is the maximum of x subject to x  H2(E; E " ) and
Pr (C jB ) = uC 2 [u1 ; u2 ] for all (C jB )[u1 ; u2 ] 2 KB such that B ! C . By Lemma 4.4, we
can equivalently maximize x subject to x  I  (E; E " ) and J (E; E " ). 2
We now wonder how to solve the generated optimization problem, since I  (E; E " ) may
still contain min-operations that cannot be tackled by linear programming. Moreover, given
a method for solving this optimization problem, we are also interested in a rough idea on
the overall time complexity of computing the requested least upper bound this way. Finally,
we are interested in possible improvements to increase eciency. These topics are discussed
in the rest of this section.
If I  (E; E " ) does not contain any min-operations at all, then the generated optimization
problem is already a linear program. Otherwise, it can easily be transformed into a linear
program. In a rst transformation step, all inner min-operations are eliminated. This can
easily be done due to the well-structuredness of I  (E; E " ). In a second step, the only
remaining outer min-operation is eliminated by introducing exactly one linear inequality
for each contained operand. In these linear inequalities, the operands of the outer minoperation are upper bounds of x.
To get a rough idea on the time complexity of computing the requested least upper
bound this way, we must analyze the size of the generated linear programs. It is given
by the number of variables, the number of linear inequalities in J (E; E " ), and the number of linear inequalities extracted from x  I  (E; E " ). The latter is quite worrying,
since I  (B; C ) in Fusion seems to produce many min-operands. Moreover, I  (B; C ) in



"
Fusion contains I (B; Bi ), and I (B; C ) in Chaining contains I (C; C ). So, due to
this crossed dependency, the overall number of generated linear inequalities is likely to
`explode' for trees that branch very often.
To avoid these problems, we introduce the auxiliary functions J  , J  , and J  over the
variables xB (B 2 B). Let J  (B; C ) = 02 , J  (B; C ) = 20 , and J  (B; C ) = 20 , where 02 , 20 ,
and 20 in Leaf (C = B ), Chaining (C = B1 ), and Fusion (C = B1 B2 : : : Bk with k > 1)
are given as follows:
Leaf

:

02 = xB
20 = 0
20 = xB
Chaining

:




02 = min(xB ; xC + JPr(1C;(BCjC )) ; xB , xC + JPr (1C;(BCjC )) )
"


"
20 = 1,PrPr1 (1B(BjCjC) )  xC + JPr(1C;(BCjC ))

20 =

J  (C; C " )
Pr 1 (BjC )

218

"

Probabilistic Deduction with Conditional Constraints over Basic Events

Fusion

:

02 = i2min
J (B; Bi )
[1:k]
20 = i2min
J  (B; Bi )
[1:k]

20 = min(i2min
J  (B; Bi ); i;j 2min
(J  (B; Bi ) + J  (B; Bj )))
[1:k]
[1:k];i6=j
Note that 02 in Chaining can be separated into the cases C " = C and C " 6= C . Since
simply 02 = xC for C " = C , we reduce the number of generated linear inequalities this way.
The next lemma shows that the functions I  , I  , and I  can be expressed in terms of
the auxiliary functions J  , J  , and J  .

Lemma 4.6 For all xB (B 2 B) that satisfy J (E; E " ):
2 = min(02 ; 20 ), 2 = min(20 ; 20 ), and 2 = 20 :

Proof sketch. The claim can be proved by induction on the recursive denition of the

functions I  , I  , and I  . 2
Briey, by Theorem 4.3, Theorem 4.5, and Lemma 4.6, the tight answer to the premiserestricted complete query 9(F jE )[x1 ; x2 ] is given by fx1 =H1 (E; E " ); x2 =X2 g, where X2 is
the maximum of x subject to x  J  (E; E " ), x  J  (E; E " ), and J (E; E " ).
In our example, we get fx1 =0:00; x2 =0:27g as the tight answer to the premise-restricted
complete query 9(QRSTUjM)[x1 ; x2 ] to the conditional constraint tree in Fig. 2, right side.
The time complexity of computing the requested greatest lower bound and especially
the requested least upper bound this way is analyzed in Section 4.5.

4.2 Strongly Conclusion-Restricted Complete Queries

We now focus on computing the tight answer to strongly conclusion-restricted complete
queries to general conditional constraint trees. In the sequel, let (B; KB ) be a conditional
constraint tree and let 9(F jE )[x1 ; x2 ] be a strongly conclusion-restricted complete query.
The tight upper answer to 9(F jE )[x1 ; x2 ] is always given by fx2 =1g. To compute the
tight lower answer to 9(F jE )[x1 ; x2 ], we rst compute the tight lower answer fy1 =u1 g to the
premise-restricted complete query 9(E jF )[y1 ; y2 ]. We then distinguish the following cases:
If u1 > 0, then the tight lower answer to 9(F jE )[x1 ; x2 ] is computed locally by a function
H1 (like the tight lower answer to premise-restricted complete queries in Section 4.1.2).
If u1 = 0 and E ) F , then the tight lower answer to 9(F jE )[x1 ; x2 ] is given by fx1 =1g.
Otherwise, the tight lower answer to 9(F jE )[x1 ; x2 ] is given by fx1 =0g.
We now focus on the technical details. Let (B; !) be the directed graph that belongs
to the premise-restricted complete query 9(E jF )[y1 ; y2 ] (see Section 4.1.1). Let Pr 1 (B jC )
denote v1 for all (B jC )[v1 ; v2 ] 2 KB . In the sequel, let B be a node and let C = B " . Again,
the cases C = B , C = B1 with a node B1 6= B , and C = B1 B2 : : : Bk with k > 1 nodes
B1; B2 ; : : : ; Bk refer to Leaf, Chaining, and Fusion, respectively.
We dene the function H1 for computing greatest lower bounds in the case H1 (B; C ) > 0
as follows. Let H1 (B; C ) = 1 (note that 1 will coincide with the greatest lower bound
of Pr (BL(C )) = Pr (L(C )) subject to Pr j= KB and Pr (L(C )) > 0), where 1 in Leaf
219

Lukasiewicz

(C = B ), Chaining (C = B1 ), and Fusion (C = B1 B2 : : : Bk with k > 1) is given as
follows (note that H1 (C; C " ) and H1 (B; Bi ) are dened like in Section 4.1.2):
Leaf:
1 = 1
:
jC ),1 )
1 = H1 (C; C " )  (1 + PrH11((BC;C
")

Chaining

:

1,1
0


H (B;Bi )(1=H1 (B;Bi ),1) C
B1 + i2min
[1:k] 1
CA
1 = B
@
Pk

Fusion

1,k+

i=1

H1 (B;Bi )

By induction on the denition of H1 , it is easy to see that H1 (B; C ) > 0 entails that 1
is dened and that 1 > 0 (note that H1 (B; C ) = 1 in Leaf, Chaining, and Fusion is
dened like in Section 4.1.2). In this case, H1 is sound and globally complete with respect
to B and C i H1 (B; C ) = 1 is the greatest lower bound of Pr (BL(C )) = Pr (L(C )) subject
to Pr 2 Mo (B; C ) and Pr (L(C )) > 0. Thus, the next theorem shows soundness and global
completeness of H1 . It also shows that, for C = B1 B2 : : : Bk with k > 1, the least upper
bound of Pr (BL(C )) = Pr (L(C )) subject to Pr 2 Mo (B; C ) and Pr (L(C )) > 0 is given by 1.

Theorem 4.7

a) If 1 > 0, then for all Pr 2 Mo (B; C ), it holds 1  Pr (L(C ))  Pr (BL(C )).
b) If 1 > 0, then there is a probabilistic interpretation Pr 2 Mo (B; C ) with Pr (B ) > 0,
Pr (L(C )) > 0, 1  Pr (L(C )) = Pr (BL(C )), and 1  Pr (B ) = Pr (BL(C )).
c) If 1 > 0 and C = B1 B2 : : : Bk with k > 1, then there is some Pr 2 Mo (B; C ) with
Pr (B ) > 0, Pr (L(C )) > 0, 1  Pr (L(C )) = Pr (BL(C )), and 1  Pr (B ) = Pr (BL(C )).
d) If 1 = 0 and C = B1 B2 : : : Bk with k > 1, then for each " > 0 there is some Pr 2 Mo (B; C )
with Pr (B ) > 0, Pr (L(C )) > 0, 1  Pr (L(C )) = Pr (BL(C )), and "  Pr (B )  Pr (BL(C )).

Proof. The proof is given in full detail in Appendix C. 2

We are now ready to give the following characterization of tight answers to strongly
conclusion-restricted complete queries to conditional constraint trees.
Theorem 4.8 Let (B; KB ) be a conditional constraint tree and let 9(F jE )[x1 ; x2 ] be a
strongly conclusion-restricted complete query. Let the tight lower answer to the premiserestricted complete query 9(E jF )[y1 ; y2 ] be given by fy1 =u1 g.
(1) If u1 > 0, then the tight answer to 9(F jE )[x1 ; x2 ] is given by fx1 =H1 (F; F " ); x2 =1g.
(2) If u1 = 0 and E ) F , then the tight answer to 9(F jE )[x1 ; x2 ] is given by fx1 =1; x2 =1g.
(3) Otherwise, the tight answer to 9(F jE )[x1 ; x2 ] is given by fx1 =0; x2 =1g.
Proof. The proof is given in full detail in Appendix C. 2
220

Probabilistic Deduction with Conditional Constraints over Basic Events

4.3 Complete Queries

We now show that the problem of computing tight answers to complete queries can be
reduced to the problems of computing tight answers to premise-restricted complete queries
and of computing tight answers to strongly conclusion-restricted complete queries.
In detail, a complete query is premise-restricted, it is strongly conclusion-restricted,
or it can be reduced to premise-restricted complete queries and to strongly conclusionrestricted complete queries. For example, given the complete query 9(STUjMQR)[x1 ; x2 ]
to the conditional constraint tree in Fig. 2, right side, we rst compute the tight answer
fy1=u1 ; y2=u2 g to the premise-restricted complete query 9(MQRjO)[y1 ; y2] (directed to the
corresponding subtree) and the tight answer fz1 =v1 ; z2 =v2 g to the strongly conclusion-restricted complete query 9(OjMQR)[z1 ; z2 ] (directed to the corresponding subtree). We then
generate a new conditional constraint tree by replacing the subtree over the nodes M, N,
O, Q, and R by the pair of conditional constraints (BjO)[u1 ; u2 ] and (OjB)[v1 ; v2 ] over the
nodes B and O (note that B represents MQR). Finally, we compute the tight answer to the
premise-restricted complete query 9(STUjB)[x1 ; x2 ] to the new conditional constraint tree.
Note that this reduction can always be done, since for each query 9(F jE )[x1 ; x2 ], all
paths from a basic event in E to a basic event in F have at least one basic event in common.

Theorem 4.9 Let (B; KB ) be a conditional constraint tree and let 9(F jE )[x1 ; x2 ] be a com-

plete query that is not premise-restricted and not strongly conclusion-restricted.
a) There exists a basic event G 2 B and two conditional constraint trees (B1 ; KB 1 ) and
(B2 ; KB 2 ) such that B1 \ B2 = fGg, B1 [ B2 = B, and 9(GjE )[z1 ; z2 ] is a strongly conclusion-restricted complete query to (B1 ; KB 1 ).
b) Let the tight answer to the premise-restricted complete query 9(E jG)[y1 ; y2 ] to (B1 ; KB 1 )
be given by fy1 =u1 ; y2 =u2 g and let the tight answer to the strongly conclusion-restricted
complete query 9(GjE )[z1 ; z2 ] to (B1 ; KB 1 ) be given by fz1 =v1 ; z2 =v2 g.

(1) If u1 > 0, then also v1 > 0 and the tight answer to the complete query 9(F jE )[x1 ; x2 ]
to (B; KB ) coincides with the tight answer to the premise-restricted complete query
9(F jB )[x1 ; x2 ] to (B2 [ fB g; KB 2 [ f(B jG)[u1 ; u2 ]; (GjB )[v1 ; v2 ]g), where B is a new
basic event with B 62 B2 . In particular, for exact conditional constraint trees (B; KB ),
the tight answer to the complete query 9(F jE )[x1 ; x2 ] is given by:

fx1 = max(0; v1 , uv11 + vu1 s11 ); x2 = min(1; 1 , v1 + vu1 s12 ; t2 ,st22+u1 )g ;
where s1 = H1 (G; G" ), s2 = H2 (G; G" ), and t2 = H2 (G; G" ) (note that H1 , H2 , and
H2 are dened like in Section 4.1.1).

(2) If u1 =0, v1 =1, and G ) F , then the tight answer to the complete query 9(F jE )[x1 ; x2 ]
to (B; KB ) is given by fx1 =1; x2 =1g.
(3) Otherwise, the tight answer to the complete query 9(F jE )[x1 ; x2 ] to (B; KB ) is given
by fx1 =0; x2 =1g.

Proof. The proof is given in full detail in Appendix D. 2
221

Lukasiewicz

4.4 Queries

The problem of computing tight answers to queries can be reduced to the more specialized
problem of calculating tight answers to complete queries.
More precisely, given a query 9(F jE )[x1 ; x2 ] to a conditional constraint tree (B; KB ),
a complete query 9(F 0 jE 0 )[x1 ; x2 ] to a conditional constraint tree (B0 ; KB 0 ) is generated by:
1. While (B; KB ) contains a leaf B that is not contained in EF : remove B from B and
remove the corresponding pair (C jB )[u1 ; u2 ]; (B jC )[v1 ; v2 ] 2 KB from KB .
2. While EF contains a basic event B that is not a leaf in (B; KB ): increase B by a new
basic event B 0, increase KB by the pair (B 0 jB )[1; 1] and (B jB 0 )[1; 1], and replace each
occurrence of B in 9(F jE )[x1 ; x2 ] by the new basic event B 0 .
It remains to show that the generated probabilistic deduction problem has the same
solution as the original probabilistic deduction problem:
Theorem 4.10 The tight answer to the query 9(F jE )[x1 ; x2 ] to (B; KB ) coincides with the
tight answer to the complete query 9(F 0 jE 0 )[x1 ; x2 ] to (B0 ; KB 0 ).
Proof. Let (B00; KB 00 ) be the conditional constraint tree that is generated in step 1 and let
(F jE )[u1 ; u2 ] be a tight logical consequence of KB 00 . We now show that (F jE )[u1 ; u2 ] is also
a tight logical consequence of KB . First, (F jE )[u1 ; u2 ] is a logical consequence of KB , since
KB 00 is a subset of KB . Moreover, each model Pr 00 of KB 00 (that is dened on all atomic
events over B00 ) can be extended to a model Pr of KB (that is dened on all atomic events
over B) with Pr (A) = s  Pr 00 (A) for all atomic events A over B00 that are dierent from the
conjunction of all negated basic events in B00 , where s is a real number from (0; 1]. This
model can be constructed inductively like in the proof of Theorem 3.2. Thus, for u 2 [u1 ; u2 ],
Pr 00 (E ) > 0 and u  Pr 00 (E ) = Pr 00 (EF ) entails Pr (E ) > 0 and u  Pr (E ) = Pr (EF ).
Finally, (F jE )[u1 ; u2 ] is a tight logical consequence of KB 00 i (F 0 jE 0 )[u1 ; u2 ] is a tight
logical consequence of KB 0 , since we just introduce synonyms for basic events in step 2. 2

4.5 Computational Complexity
4.5.1 Exact Conditional Constraint Trees

We now show that for exact conditional constraint trees, our technique to compute the tight
answer to queries runs in linear time in the number of nodes of the tree. In the sequel, let
(B; KB ) be an exact conditional constraint tree and let n denote its number of nodes.

Lemma 4.11 The tight answer to a premise-restricted or strongly conclusion-restricted
complete query can be computed in linear time in n.

Proof. For exact conditional constraint trees, our approach
to compute the tight upper



answer to premise-restricted complete queries by H2 , H2 , and H2 runs in time O(n):
The directed tree can be computed in time O(n). An initialization of a leaf with a
constant number of assignments is performed exactly for each leaf of the directed tree, a
chaining with a constant number of arithmetic operations is performed exactly for each
arrow of the directed tree. Hence, initializing all leaves and performing all chainings runs
222

Probabilistic Deduction with Conditional Constraints over Basic Events

in time O(n). A fusion is done for each branching of the directed tree, using linear time in
the number of branches. Thus, all fusions together run in time O(n).
Even for general conditional constraint trees, the tight lower answer to premise-restricted
complete queries, and hence also the tight answer to strongly conclusion-restricted complete
queries, is analogously computed in time O(n). 2

Theorem 4.12 The tight answer to a query can be computed in linear time in n.
Proof. We assume that the set of basic events B is totally ordered and that the basic events
in the conjunctive events E and F of the query 9(F jE )[x1 ; x2 ] are written in this order.

First, the query is reduced to a complete query according to Section 4.4. This reduction
can be done in time O(n). Now, if the generated complete query is premise-restricted or
strongly conclusion-restricted, then the claim follows immediately from Lemma 4.11.
Otherwise, the generated complete query is reduced to premise-restricted and strongly
conclusion-restricted complete queries according to Section 4.3. Also this reduction can be
done in time O(n), since the basic event G in Theorem 4.9 a) is computable in time O(n).
Hence, the claim follows from Theorem 4.9 and Lemma 4.11. Note that t2 = H2 (G; G" ) in
Theorem 4.9 b) (1) can also be computed in time O(n). 2
4.5.2 Conditional Constraint Trees

For general conditional constraint trees, our technique to compute the tight lower answer
to queries runs still in linear time, while our technique to compute the tight upper answer
to queries runs in polynomial time in the number of nodes of the tree. In the sequel, let
(B; KB ) be a general conditional constraint tree and let n denote its number of nodes.

Lemma 4.13

a) The tight lower answer to a premise-restricted complete query and the tight answer to a
strongly conclusion-restricted complete query can be computed in linear time in n.
b) The tight upper answer to a premise-restricted complete query can be computed in polynomial time in n.

Proof. a) The claim is already shown in the proof of Lemma 4.11.

b) Our linear programming technique to compute the tight upper answer to premiserestricted complete queries runs in polynomial time in n:
Linear programming runs in polynomial time in the size of the linear programs (Papadimitriou & Steiglitz, 1982; Schrijver, 1986), where the size of a linear program is given
by its number of variables and its number of linear inequalities.
We now show that the size of our linear programs in Section 4.1.2 is polynomial in n.
The number of variables is n + 1. The number of linear inequalities in J (E; E " ) is 2n.
By induction on the recursive denition of J  , J  , and J  , it can be shown that the
number of min-operands in J  (B; C ), J  (B; C ), and J  (B; C ) is limited by jB(B; C )j2 ,
jB(B; C )j, and jB(B; C )j4 , respectively. Hence, the number of linear inequalities extracted
from x  J  (E; E " ) and x  J  (E; E " ) is limited by jB(E; E " )j2 + jB(E; E " )j4 = n2 + n4 .
Thus, the overall number of generated linear inequalities l is limited by lu = 2n + n2 + n4 .
223

Lukasiewicz

Finally, note that lu is a very rough upper bound for l, in many conditional constraint
trees (especially in those that branch very rarely), l is much lower than lu . For example,
taking a complete binary tree with n = 127 nodes, we get only l = 19 964 compared to
lu = 260 161 024. In the example of Section 4.1.2 with n = 9 nodes, we get only l = 72
compared to lu = 6 660. Another example is a tree that is degenerated to a chain of basic
events. In this case, we even get l = 5n + 1, that is, the overall number of generated linear
inequalities is linear in n. 2

Theorem 4.14

a) The tight lower answer to a query can be computed in linear time in n.
b) The tight upper answer to a query can be computed in polynomial time in n.

Proof. We assume that the set of basic events B is totally ordered and that the basic events
in the conjunctive events E and F of the query 9(F jE )[x1 ; x2 ] are written in this order.
Like in the proof of Theorem 4.12, the query is reduced to a complete query according
to Section 4.4. This reduction can be done in time O(n). Now, if the generated complete query is premise-restricted or strongly conclusion-restricted, then the claims follow
immediately from Lemma 4.13.
Otherwise, the generated complete query is reduced to premise-restricted and strongly
conclusion-restricted complete queries according to Section 4.3. Again, this reduction can
be done in time O(n), since the basic event G in Theorem 4.9 a) is computable in time O(n).
Thus, the claims follow from Theorem 4.9 and Lemma 4.13. Note that in Theorem 4.9 b) (1),
the tight lower answer to 9(F jB )[x1 ; x2 ] can be computed without u2 and v2 . 2
4.6 Comparison with the Classical Linear Programming Approach

As a comparison, we now briey describe how probabilistic deduction in conditional constraint trees can be done by the classical linear programming approach (Paa, 1988; van
der Gaag, 1991; Amarger et al. 1991; Hansen et al. 1995). In the sequel, let 9(F jE )[x1 ; x2 ]
be a query to an exact or general conditional constraint tree (B; KB ) over n nodes.
The tight answer to 9(F jE )[x1 ; x2 ] can be computed by solving two linear programs. In
detail, the requested greatest lower and least upper bound are given by the optimal values
of the following two linear programs with xA  0 (A 2 AB ) and opt 2 fmin; maxg:
opt

P

A2AB ; A)EF xA

subject to

P
A2AB ; A)E xA = 1
P
P
A2AB ; A)GH xA  u1  A2AB ; A)G xA for all (H jG)[u1 ; u2 ] 2 KB
P
P
A2AB ; A)GH xA  u2  A2AB ; A)G xA for all (H jG)[u1 ; u2 ] 2 KB
That is, the tight answer is computed by solving two linear programs with 2n variables
and 4n , 2 linear inequalities. For example, the tight answer to the premise-restricted
complete query 9(QRSTUjM)[x1 ; x2 ] to the conditional constraint trees in Fig. 2 yields two
linear programs with 29 = 512 variables and 4  9 , 2 = 34 linear inequalities.
224

Probabilistic Deduction with Conditional Constraints over Basic Events

Hence, if we now solve these two linear programs by the standard simplex method or
the standard interior-point technique, then we need immediately exponential time in n. It
is still an open question whether column generation techniques can help to solve the two
linear programs in less than exponential time in n in the worst case.

5. Comparison with Bayesian Networks
In this section, we briey discuss the relationship between conditional constraint trees and
Bayesian networks (Pearl, 1988).
A Bayesian network is dened by a directed acyclic graph G over discrete random variables X1 ; X2 ; : : : ; Xn as nodes and by a conditional probability distribution Pr (Xi jpa(Xi ))
for each random variable Xi and each instantiation pa(Xi ) of its parents pa(Xi ). It species
a unique joint probability distribution Pr over X1 ; X2 ; : : : ; Xn by:
Pr (X1 ; X2 ; : : : ; Xn ) =

n
Y
i=1

Pr (Xi j pa(Xi )) :

That is, the joint probability distribution Pr is uniquely determined by the conditional
distributions Pr (Xi jpa(Xi )) and certain conditional independencies encoded in G.
Hence, Bayesian trees (that is, Bayesian networks that have a directed tree as associated
directed acyclic graph) with only binary random variables seem to be very close to exact
conditional constraint trees. However, exact and general conditional constraint trees are
associated with an undirected tree that does not encode any independencies! For this reason, exact and general conditional constraint trees describe convex sets of joint probability
distributions rather than single joint probability distributions.
But, would it be possible to additionally assume certain independencies? Of course, with
each exact or general conditional constraint tree (B; KB ), we can associate all probabilistic
interpretations Pr that are models of KB and that have additionally the undirected tree
(B; $) as an I-map (Pearl, 1988). That is, we would have independencies without causal
directionality like in Markov trees (Pearl, 1988). However, this idea does not carry us
to a single probabilistic interpretation (neither for exact conditional constraint trees, nor
for general conditional constraint trees), and it is an interesting topic of future research to
investigate how the computation of tight answers in exact and general conditional constraint
trees changes under this kind of independencies (which yield tighter bounds, since they
reduce the number of models of exact and general conditional constraint trees).
Finally, if we additionally x the probability of exactly one node, then an exact conditional constraint tree under the described independencies species exactly one probabilistic
interpretation (note that, to keep satisability, the probability of a node must respect certain
upper bounds, which are entailed by the exact conditional constraint tree). But, such exact
conditional constraint trees are in fact Bayesian trees with only binary random variables.

6. Summary and Conclusions
We showed that globally complete probabilistic deduction with conditional constraints over
basic events is NP-hard. We then concentrated on the special case of probabilistic deduction
225

Lukasiewicz

in exact and general conditional constraint trees. We presented very ecient techniques for
globally complete probabilistic deduction. More precisely, for exact conditional constraint
trees, we presented a local approach that runs in linear time in the size of the conditional
constraint trees. For general conditional constraint trees, we introduced a global approach
that runs in polynomial time in the size of the conditional constraint trees.
Probabilistic deduction in conditional constraint trees is motivated by previous work
in the literature on inference rules. It generalizes patterns of commonsense reasoning that
have been thoroughly studied in this work. Hence, we presented a new class of tractable
probabilistic deduction problems, which are driven by articial intelligence applications.
It is also important to note that the deduction process in exact and general conditional
constraint trees can easily be elucidated in a graphical way. For example, the computation
of the tight answer to the premise-restricted complete query 9(QRSTUjM)[x1 ; x2 ] to the
exact conditional constraint tree in Fig. 2, left side, can be illustrated by labeling each node
of the directed tree in Fig. 3 with the corresponding tightest bounds of Table 1.
Like Bayesian networks, conditional constraint trees are well-structured probabilistic
knowledge bases that have an intuitive graphical representation. Dierently from Bayesian
networks, conditional constraint trees do not encode any probabilistic independencies. Thus,
they can also be understood as a complement to Bayesian networks, useful for restricted
applications in which well-structured independencies do not hold or are dicult to access.
Conditional constraint trees are quite restricted in their expressive power. However, in
more general probabilistic knowledge bases, probabilistic deduction in conditional contraint
trees may always act as local inference rules. For example, in case we desire explanatory
information on some specic local deductions from a subset of the whole knowledge base
(which could especially be useful in the design phase of a probabilistic knowledge base).
An important conclusion of this paper concerns the question whether to perform probabilistic deduction by the iterative application of inference rules or by linear programming.
The techniques of this paper have been elaborated by following the idea of inference rules in
probabilistic deduction. Hence, on the one hand, this paper shows that the idea of inference
rules can indeed bring us to ecient techniques for globally complete probabilistic deduction
in restricted settings. However, on the other hand, given the technical complexity of the
corresponding proofs, it seems unlikely that these results can be extended to probabilistic
knowledge bases that are signicantly more general than conditional constraint trees.
That is, as far as signicantly more general probabilistic deduction problems with conditional constraints are concerned, the iterative application of inference rules does not seem
to be very promising for globally complete probabilistic deduction. Note that a similar
conclusion is drawn in a companion paper (1998a, 1999a), which shows the limits of locally
complete inference rules for probabilistic deduction under taxonomic knowledge.
For example, probabilistic deduction from probabilistic logic programs that do not assume probabilistic independencies (Ng & Subrahmanian 1993, 1994; Lukasiewicz, 1998d)
should better not be done by the iterative application of inference rules. Note that much
more promising techniques are, for example, global techniques by linear programming
(Lukasiewicz, 1998d) and in particular approximation techniques based on truth-functional
many-valued logics (Lukasiewicz 1998b, 1999b).
226

Probabilistic Deduction with Conditional Constraints over Basic Events

Acknowledgements
I am very grateful to Michael Wellman and the referees for their useful comments. I also
want to thank Thomas Eiter for valuable comments on an earlier version of this paper. This
paper is an extended and revised version of a paper that appeared in Principles of Knowledge
Representation and Reasoning: Proceedings of the 6th International Conference, pp. 380{391.

Appendix A. Preliminaries of the Proofs for Sections 4.1 to 4.3

In this section, we make some technical preparations for the proofs of Theorems 4.1, 4.2,
4.7, 4.8, and 4.9. In the sequel, we use the notation

x1;1 x1;2
x2;1 x2;2
c1 c2

r1
r2

as an abbreviation of the following system of equations:
(11)

x1;1 + x1;2 = r1
x2;1 + x2;2 = r2

x1;1 + x2;1 = c1
x1;2 + x2;2 = c2 :

The next lemma provides the optimal values of two linear programs to be solved in the
proofs of Theorems 4.1, 4.2, 4.7, 4.8, and 4.9.
Lemma A.1 Let r1 ; r2 ; c1 ; c2  0 with r1 + r2 = c1 + c2 . For all i; j 2 f1; 2g:
a) min(ri ; cj ) = max xi;j subject to (11) and xn;m  0 for all n; m 2 f1; 2g.
b) max(0; ri , c3,j ) = min xi;j subject to (11) and xn;m  0 for all n; m 2 f1; 2g.
Proof. The claims can easily be veried (Lukasiewicz, 1996). 2
Let us assume that a conditional constraint tree is the union of two subtrees that have
just one node in common. A model of each subtree and a third model related to the
common node can now be combined to a model of the whole conditional constraint tree.
This important result follows from the next lemma.
Lemma A.2 Let B1 and B2 be sets of basic events with B1 \B2 = ;. Let B0 be a new basic
event that is not contained in B1 [ B2 . Let Pr 1 and Pr 2 be probabilistic interpretations on
the atomic events over B1 [fB0 g and B2 [fB0 g, respectively. Let B1 and B2 be conjunctive
events over B1 and B2 , respectively. Let Pr 0 be a probabilistic interpretation on the atomic
events over fB0 ; B1 ; B2 g with Pr 0 (H0 H1 ) = Pr 1 (H0 H1 ) and Pr 0 (H0 H2 ) = Pr 2 (H0 H2 ) for
all atomic events H0 , H1 , and H2 over fB0 g, fB1 g, and fB2 g, respectively.
There is a probabilistic interpretation Pr on the atomic events over B1 [B2 [fB0 g with:
(12)

Pr (H0 H1 H2 ) = Pr 0 (H0 H1 H2 );
Pr (H0 A1 ) = Pr 1 (H0 A1 ); and Pr (H0 A2 ) = Pr 2 (H0 A2 )
227

Lukasiewicz

for all atomic events H0 , H1 , H2 , A1 , and A2 over the sets of basic events fB0 g, fB1 g,
fB2 g, B1, and B2, respectively.

Proof. Let the probabilistic interpretation Pr on the atomic events over B1 [ B2 [ fB0 g

be dened as follows:

8
1 (H0 A1 ) Pr 2 (H0 A2 )
<Pr 0(H0 H1 H2 )  Pr
Pr 1 (H0 H1 )  Pr 2 (H0 H2 ) if Pr 1 (H0 H1 )  Pr 2 (H0 H2 ) > 0
Pr (H0 A1 A2 ) = :
0
if Pr 1 (H0 H1 )  Pr 2 (H0 H2 ) = 0
for all atomic events H0 , A1 , and A2 over fB0 g, B1 , and B2 , respectively, with atomic events
H1 over fB1 g and H2 over fB2 g such that A1 ) H1 and A2 ) H2 .

Now, we must show that Pr satises (12). Let H0 , H1 , and H2 be atomic events over
fB0 g, fB1 g, and fB2 g, respectively. For Pr 1(H0 H1 ) > 0 and Pr 2 (H0 H2 ) > 0, we get:
Pr (H0 H1 H2 ) =

P

A1 2AB1 ; A1 )H1
A2 2AB2 ; A2 )H2

1 (H0 A1 ) Pr 2 (H0 A2 )
Pr 0 (H0 H1 H2 )  Pr
Pr 1 (H0 H1 )  Pr 2 (H0 H2 ) = Pr 0 (H0 H1 H2 ) :

For Pr 1 (H0 H1 ) = 0 or Pr 2 (H0 H2 ) = 0, we get Pr (H0 H1 H2 ) = 0 = Pr 0 (H0 H1 H2 ).
Let H0 , H1 , and A1 be atomic events over fB0 g, fB1 g, and B1 , respectively, with
A1 ) H1. For Pr 1(H0 H1 ) > 0, Pr 2 (H0 B2 ) > 0, and Pr 2 (H0 B 2 ) > 0, it holds:

P

Pr (H0 A1 ) =

A2 2AB2 ; A2 )B2

+

P

A2 2AB2 ; A2 )B 2

=

Pr 1 (H0 A1 )  Pr 2 (H0 A2 )
Pr 0 (H0 H1 B2 )  Pr
1 (H0 H1 ) Pr 2 (H0 B2 )
1 (H0 A1 ) Pr 2 (H0 A2 )
Pr 0 (H0 H1 B 2 )  Pr
Pr 1 (H0 H1 )  Pr 2 (H0 B 2 )
1 (H0 A1 )
Pr 0 (H0 H1 )  Pr
Pr 1 (H0 H1 )

= Pr 1 (H0 A1 ) :

For Pr 1 (H0 H1 ) > 0, Pr 2 (H0 B2 ) > 0, and Pr 2 (H0 B 2 ) = 0, we get:
Pr (H0 A1 ) =

=

P

A2 2AB2 ; A2 )B2

Pr 1 (H0 A1 )  Pr 2 (H0 A2 )
Pr 0 (H0 H1 B2 )  Pr
1 (H0 H1 ) Pr 2 (H0 B2 )
1 (H0 A1 )
Pr 0 (H0 H1 )  Pr
Pr 1 (H0 H1 )

= Pr 1 (H0 A1 ) :

The proof is similar for Pr 1 (H0 H1 ) > 0, Pr 2 (H0 B2 ) = 0, and Pr 2 (H0 B 2 ) > 0.
For Pr 1 (H0 H1 ) = 0, we get Pr (H0 A1 ) = 0 = Pr 1 (H0 A1 ).
Finally, the proof of Pr (H0 A2 ) = Pr 2 (H0 A2 ) for all atomic events H0 over fB0 g and
A2 over B2 can be done analogously. 2

Appendix B. Proofs for Section 4.1

In this section, we give the proofs of Theorems 4.1 and 4.2. That is, we show the global
soundness and the global completeness of the functions H1, H2 , H2 , and H2 . The proofs
are done by induction on the recursive denition of H1 , H2 , H2 , and H2 .
228

Probabilistic Deduction with Conditional Constraints over Basic Events

To prove global soundness, we just have to show the local soundness of the computations
in Leaf, Chaining, and Fusion. To prove global completeness, we construct two models
of the conditional constraint tree, one related to the greatest lower bound and another one
related to the least upper bound computed in Leaf, Chaining, and Fusion.
For Leaf, such a model is trivially given. For Chaining, we combine a model of the
arrow, a model of the subtree, and a model connected to the common node to a model of the
extended conditional constraint tree. For Fusion, we combine models of the subtrees and
a model connected to the common node to a model of the extended conditional constraint
tree. More precisely, for Chaining and Fusion, the models of the subtrees are related to
previously computed tightest bounds, while the model connected to the common node is
related to the tightest bounds computed in the running Chaining or Fusion.
We need the following technical preparations. The next lemma helps us to show the
global completeness of the functions H2 , H2 , and H2 in Chaining and Fusion.
Lemma B.3 a) For all real numbers u; v 2 (0; 1], x2 2 [0; 1], and x2 ; z2 2 [0; 1) with
x2 ; x2  z2 and z2  x2 + x2, there is some x 2 [z2 , x2 ; x2 ] with:
(13)
min(1; uzv 2 ; 1 , u + uxv ; u , uxv + uzv 2 ) = min(1; uzv 2 ; 1 , u + uxv 2 ; u + uxv 2 ) :
b) For v2 ; x2 2 [0; 1] and v2 ; x2 ; w2 ; z2 2 [0; 1) with v2  w2 , v2  w2 , x2  z2 , x2  z2 ,
w2  v2 + v2 , and z2  x2 + x2 , there is v 2 [w2 , v2 ; v2 ] and x 2 [z2 , x2 ; x2 ] with:
min(w2 ; z2 ; v + z2 , x; x + w2 , v) = min(w2 ; z2 ; v2 + x2 ; x2 + v2 )
(14)
min(v; x) = min(v2 ; x2 ) :
Proof. The claims can easily be veried (Lukasiewicz, 1996). 2
The following lemma helps us to prove the local soundness and the local completeness
of the functions H1 , H2, H2 , and H2 in Chaining and Fusion.
Lemma B.4 a) Let u; v 2 (0; 1], x 2 [0; 1], and x 2 [0; 1). For all probabilistic interpretations Pr with Pr (B ) > 0, the conditions u  Pr (B ) = Pr (BC ), v  Pr (C ) = Pr (BC ),
x  Pr (C ) = Pr (CL(C " )), and x  Pr (C ) = Pr (C L(C " )) are equivalent to:
Pr (B C L(C " ))
Pr (B)
Pr (BC L(C " ))
Pr (B)

Pr (B CL(C " ))
Pr (B)
Pr (BCL(C " ))
Pr (B)

Pr (C L(C " ))
Pr (B)

ux
v

Pr (B C )
Pr (B)

1,u

Pr (BCL(C " ))
Pr (B)
Pr (BC L(C " ))
Pr (B)

Pr (B CL(C " ))
Pr (B)
Pr (BCL(C " ))
Pr (B)

u , ux
v
v

ux
v

u ,u
v

u

b) Let v; x 2 [0; 1] and v; x 2 [0; 1). For all probabilistic interpretations Pr with Pr (B ) > 0,
the conditions v  Pr (B ) = Pr (BL(G )), v  Pr (B ) = Pr (BL(G )), x  Pr (B ) = Pr (BL(H )),
and x  Pr (B ) = Pr (BL(H )) are equivalent to:
Pr (B L(G) L(H ))
Pr (B)
Pr (BL(G)L(H ))
Pr (B)

Pr (B L(G)L(H ))
Pr (B)
Pr (BL(G )L(H ))
Pr (B)

Pr (B L(H ))
Pr (B)

x

Pr (B L(G))
Pr (B)

v

229

Pr (BL(G) L(H ))
Pr (B)
Pr (BL(G )L(H ))
Pr (B)

Pr (BL(G)L(H ))
Pr (B)
Pr (BL(G )L(H ))
Pr (B)

1,x

x

1,v

v

Lukasiewicz

Proof. The claims can be veried by straightforward arithmetic transformations based on

the properties of probabilistic interpretations. 2
After these preparations, we are now ready to prove the global soundness and the global
completeness of the functions H1 , H2 , H2 , and H2 .
Proof of Theorem 4.1. The claims are proved by induction on the recursive denition
of H1 . The case C = B1 : : : Bk is tackled by iteratively splitting C into two conjunctive
events. Thus, it is reduced to C = GH with conjunctive events G and H that are disjoint in
their basic events. For C = B1 , we dene u = Pr (C jB ), v = Pr (B jC ), and x1 = H1 (C; C " ).
For C = B1 : : : Bk , hence C = GH , let v1 = H1 (B; G) and x1 = H1 (B; H ).
a) All models Pr 2 Mo (B; C ) with Pr (B ) = 0 satisfy the indicated condition. In the sequel,
let Pr 2 Mo (B; C ) with Pr (B ) > 0.
Basis: Let C = B . Since C = L(C ), we get:

1  Pr (B ) = 1  Pr (B ) = Pr (BC ) = Pr (BL(C )) :
Induction: Let C = B1 . For all models Pr 2 2 Mo (C; C " ), we get by the induction hypothesis
x1  Pr 2 (C )  Pr 2 (CL(C " )). Thus, Pr satises the same conditions. Since L(C " ) = L(C )
and by Lemmata A.1 and B.4 a), we then get:

1  Pr (B ) = max(0; u , uv + uxv 1 )  Pr (B )  Pr (BL(C " )) = Pr (BL(C )) :

Let C = GH . For all Pr 1 2 Mo (B; G) and Pr 2 2 Mo (B; H ), we get by the induction
hypothesis v1  Pr 1 (B )  Pr 1 (BL(G)) and x1  Pr 2 (B )  Pr 2 (BL(H )). Thus, Pr satises
the same conditions. Since L(G)L(H ) = L(GH ) = L(C ) and by Lemmata A.1 and B.4 b):
max(0; v1 + x1 , 1)  Pr (B )  Pr (BL(G)L(H )) = Pr (BL(C )) :
b)
Basis: Let C = B . A model Pr 2 Mo (B; C ) such that Pr (B ) > 0, 1  Pr (B ) = 1  Pr (B ) =
Pr (BL(C )), and Pr (BL(C )) = 0 is given by B; B 7! 0; 1.
Induction: Let C = B1 . Let the model Pr 1 of f(C jB )[u; u]; (B jC )[v; v]g with Pr 1 (B ) > 0
and Pr 1 (C ) > 0 be dened like in the proof of Theorem 3.2.
We now choose an appropriate model Pr 2 2 Mo (C; C " ). Let us rst consider the
case x1 > 0, v = 1, or not L(C " ) ) C . By the induction hypothesis, there exists a model
Pr 2 2 Mo (C; C " ) with Pr 2 (C ) > 0, x1  Pr 2 (C ) = Pr 2 (CL(C " )), and Pr 2 (CL(C " )) = 0
i L(C " ) ) C . Let us next assume x1 = 0, v < 1, and L(C " ) ) C . By Theorem 3.2, there
exists a model Pr 002 2 Mo (C; C " ) with Pr 002 (CL(C " )) > 0. By the induction hypothesis,
there exists a model Pr 02 2 Mo (C; C " ) with Pr 02 (C ) > 0 and 0  Pr 02 (C ) = Pr 02 (CL(C " )).
Hence, there exists a model Pr 2 2 Mo (C; C " ) with Pr 2 (C ) > 0 and
min(1 , v; Pr 002 (CL(C " )) = Pr 002 (C ))  Pr 2 (C ) = Pr 2 (CL(C " )) :
By Lemma 3.1, we can choose Pr 1 and Pr 2 with Pr 1 (C ) = Pr 2 (C ) and Pr 1 (B C ) 
Pr 2 (CL(C " )). By Lemmata A.1 and B.4 a), we can choose the probabilistic interpretation
230

Probabilistic Deduction with Conditional Constraints over Basic Events

Pr 0 over fB; C; L(C " )g with Pr 0 (A1 ) = Pr 1 (A1 ) and Pr 0 (A2 ) = Pr 2 (A2 ) for all atomic
events A1 and A2 over fB; C g and fC; L(C " )g, respectively, such that:
Pr 0 (BCL(C " )) = max(0; Pr 2 (CL(C " )) , Pr 1 (B C )) = 0
Pr 0 (BCL(C " )) = max(0; Pr 2 (CL(C " )) , Pr 1 (BC )) :

By Lemma A.2 with B1 = fB g, B2 = B(C; C " ) nfC g, B0 = C , B1 = B , and B2 = L(C " ),
there exists a probabilistic interpretation Pr over B(B; C ) with (12). Hence, it holds Pr 2
Mo (B; C ) and Pr (B ) > 0. By Lemma B.4 a), we get:

1  Pr (B ) = max(0; u , uv + uxv 1 )  Pr (B ) = Pr (BL(C " )) = Pr (BL(C )) :
Moreover, it is easy to see that Pr (BL(C )) = 0 i L(C ) ) B .
Let C = GH . By the induction hypothesis, there are models Pr 1 2 Mo (B; G) and
Pr 2 2 Mo (B; H ) with Pr 1 (B ) > 0, Pr 2 (B ) > 0, v1  Pr 1 (B ) = Pr 1 (BL(G)), x1  Pr 2 (B ) =
Pr 2 (BL(H )), Pr 1 (BL(G)) = 0 i L(G) ) B , and Pr 2 (BL(H )) = 0 i L(H ) ) B .
By Lemma 3.1, we can choose Pr 1 and Pr 2 with Pr 1 (B ) = Pr 2 (B ) and Pr 1 (B L(G)) 
Pr 2 (BL(H ). By Lemmata A.1 and B.4 b), we can choose the probabilistic interpretation
Pr 0 over fB; L(G); L(H )g with Pr 0 (A1 ) = Pr 1 (A1 ) and Pr 0 (A2 ) = Pr 2 (A2 ) for all atomic
events A1 and A2 over fB; L(G)g and fB; L(H )g, respectively, such that:
Pr 0 (BL(G)L(H )) = min(Pr 2 (BL(H )); Pr 1 (BL(G))
Pr 0 (BL(G)L(H )) = max(0; Pr 2 (BL(H )) , Pr 1 (BL(G))) :

By Lemma A.2 with B1 = B(B; G) nfB g, B2 = B(B; H ) nfB g, B0 = B , B1 = L(G), and
B2 = L(H ), there exists a probabilistic interpretation Pr over B(B; C ) with (12). Hence,
it holds Pr 2 Mo (B; C ) and Pr (B ) > 0. By Lemma B.4 b), we get:
max(0; v1 + x1 , 1)  Pr (B ) = Pr (BL(G)L(H )) = Pr (BL(C )) :
Moreover, it is easy to see that Pr (BL(C )) = 0 i L(C ) ) B . 2

Proof of Theorem
4.2. The claims are proved by induction on the recursive denition of


H2 , H2 , and H2 . Again, the case C = B1 : : : Bk is tackled by iteratively splitting C into
two conjunctive events. Thus, it is reduced to C = GH with conjunctive events G and H
that are disjoint in their basic events. For C = B1 let u = Pr (C jB ), v = Pr (B jC ), and

x2 = H2 (C; C " ); x2 = H2 (C; C " ); z2 = H2 (C; C " ) :
For C = B1 : : : Bk , hence C = GH , we dene:
v2 = H2(B; G); v2 = H2 (B; G); w2 = H2 (B; G)
x2 = H2 (B; H ); x2 = H2 (B; H ); z2 = H2 (B; H ) :
a) For Pr 2 Mo (B; C ) with Pr (B ) = 0, we get Pr (N ) = 0 for all N 2 B(B; C ). Thus, Pr
satises the indicated conditions. Next, let Pr 2 Mo (B; C ) with Pr (B ) > 0.
231

Lukasiewicz

Basis: Let C = B . Since L(C ) = C , we get:
Pr (BL(C )) = Pr (BC ) = 1  Pr (B ) = 2  Pr (B )
Pr (BL(C )) = Pr (BC ) = 0  Pr (B ) = 2  Pr (B )
Pr (L(C )) = Pr (C ) = 1  Pr (B ) = 2  Pr (B ) :
Induction: Let C = B1 . For all models Pr 2 2 Mo (C; C " ), we get by the induction hypothesis
Pr 2 (CL(C " ))  x2  Pr 2 (C ), Pr 2 (CL(C " ))  x2  Pr 2 (C ), and Pr 2 (L(C " ))  z2  Pr 2 (C ).
Hence, Pr satises the same conditions. Since L(C ) = L(C " ) and by Lemmata A.1 and
B.4 a), we then get:
Pr (BL(C )) = Pr (BL(C " ))  min(1; uzv 2 ; 1 , u + uxv 2 ; u + uxv 2 )  Pr (B ) = 2  Pr (B )
Pr (BL(C )) = Pr (BL(C " )) 
min( uxv 2 + uv , u; uzv 2 )  Pr (B ) = 2  Pr (B )
uz2  Pr (B ) = 2  Pr (B ) :
Pr (L(C )) = Pr (L(C " )) 
v
Let C = GH . For all models Pr 1 2 Mo (B; G) and all models Pr 2 2 Mo (B; H ), we get
by the induction hypothesis:
Pr 1 (BL(G))  v2  Pr 1 (B ); Pr 2 (BL(H ))  x2  Pr 2 (B )
Pr 1 (BL(G))  v2  Pr 1 (B ); Pr 2 (BL(H ))  x2  Pr 2 (B )
Pr 1 (L(G))  w2  Pr 1 (B ); Pr 2 (L(H ))  z2  Pr 2 (B ) :
Thus, Pr satises the same conditions. Since L(C ) = L(GH ) = L(G)L(H ) and by Lemmata A.1 and B.4 b), we get:
Pr (BL(C )) = Pr (BL(G)L(H ))  min(v2 ; x2 )  Pr (B )
Pr (BL(C )) = Pr (BL(G)L(H ))  min(v 2 ; x2 )  Pr (B )
Pr (L(C )) = Pr (L(G)L(H ))  min(w2 ; z2 ; v2 + x2 ; x2 + v 2 )  Pr (B ) :
b) and c)
Basis: Let C = B . A model Pr 2 Mo (B; C ) with Pr (B ) > 0 satisfying Pr (BL(C )) =
1  Pr (B ) = 2  Pr (B ), Pr (BL(C )) = 0  Pr (B ) = 2  Pr (B ), and Pr (L(C )) = 1  Pr (B ) =
2  Pr (B ) is given by B; B 7! 0; 1.
Induction: Let C = B1 . Let the model Pr 1 of f(C jB )[u; u]; (B jC )[v; v]g with Pr 1 (B ) > 0
and Pr 1 (C ) > 0 be dened like in the proof of Theorem 3.2.
For the proof of c), by the induction hypothesis, there is some Pr 2 2 Mo (C; C " ) with
Pr 2 (C ) > 0, Pr 2 (CL(C " )) = x2  Pr 2 (C ), and Pr 2 (L(C " )) = z2  Pr 2 (C ).
By Lemma 3.1, we can choose Pr 1 and Pr 2 with Pr 1 (C ) = Pr 2 (C ) and Pr 1 (B C ) 
Pr 2 (CL(C " )). By Lemma A.1, we can choose the probabilistic interpretation Pr 0 over
fB; C; L(C " )g with Pr 0 (A1 ) = Pr 1 (A1 ) and Pr 0(A2 ) = Pr 2(A2 ) for all atomic events A1
and A2 over fB; C g and fC; L(C " )g, respectively, such that:
Pr 0 (B CL(C " )) = min(Pr 1 (B C ); Pr 2 (CL(C " ))) = Pr 2 (CL(C " ))
Pr 0 (BCL(C " )) = min(Pr 1 (BC ); Pr 2 (CL(C " ))) :
232

Probabilistic Deduction with Conditional Constraints over Basic Events

By Lemma A.2 with B1 = fB g, B2 = B(C; C " ) n fC g, B0 = C , B1 = B , and B2 =
L(C "), there is a probabilistic interpretation Pr over B(B; C ) with (12). Hence, it holds
Pr 2 Mo (B; C ) and Pr (B ) > 0. By Lemma B.4 a), we get:
Pr (BL(C )) = Pr (BL(C " )) = min( uxv 2 + uv , u; uzv 2 )  Pr (B ) = 2  Pr (B )
uz2  Pr (B ) = 2  Pr (B ) :
Pr (L(C )) = Pr (L(C " )) =
v

For the proof of b), by the induction hypothesis, there are models Pr 1;2 ; Pr 2;2 2
Mo (C; C " ) with Pr 1;2 (C ) > 0, Pr 2;2 (C ) > 0, and
(15)

Pr 1;2 (CL(C " )) = x2  Pr 1;2 (C ); Pr 1;2 (L(C " )) = z2  Pr 1;2 (C )
Pr 2;2 (CL(C " )) = x2  Pr 2;2 (C ); Pr 2;2 (L(C " )) = z2  Pr 2;2 (C ) :

These conditions already entail x2  z2 and x2  z2 . With the results from a), we additionally get z2  x2 + x2 . By Lemma B.3 a), there is x 2 [z2 , x2 ; x2 ] with (13). By (15),
there is Pr 2 2 Mo (C; C " ) with Pr 2 (C ) > 0 and
Pr 2 (CL(C " )) = x  Pr 2 (C ); Pr 2 (L(C " )) = z2  Pr 2 (C ) :
By Lemma 3.1, we can choose Pr 1 and Pr 2 with Pr 1 (C ) = Pr 2 (C ). By Lemma A.1, we
can choose the probabilistic interpretation Pr 0 over fB; C; L(C " )g with Pr 0 (A1 ) = Pr 1 (A1 )
and Pr 0 (A2 ) = Pr 2 (A2 ) for all atomic events A1 and A2 over fB; C g and fC; L(C " )g,
respectively, such that:
Pr 0 (BCL(C " )) = min(Pr 1 (BC ); Pr 2 (CL(C " )))
Pr 0 (BCL(C " )) = min(Pr 1 (BC ); Pr 2 (CL(C " ))) :

By Lemma A.2 with B1 = fB g, B2 = B(C; C " ) n fC g, B0 = C , B1 = B , and B2 =
L(C "), there is a probabilistic interpretation Pr over B(B; C ) with (12). Hence, it holds
Pr 2 Mo (B; C ) and Pr (B ) > 0. By Lemma B.4 a), we get:
Pr (BL(C )) = Pr (BL(C " )) = min(1; uzv 2 ; 1 , u + uxv 2 ; u + uxv 2 )  Pr (B ) = 2  Pr (B )
uz2  Pr (B ) = 2  Pr (B ) :
Pr (L(C )) = Pr (L(C " )) =
v

Let C = GH . We just show b), the claim in c) can be proved analogously. By the induction hypothesis, there are models Pr 1;1 ; Pr 2;1 2 Mo (B; G) and Pr 1;2 ; Pr 2;2 2 Mo (B; H )
with Pr 1;1 (B ) > 0, Pr 2;1 (B ) > 0, Pr 1;2 (B ) > 0, Pr 2;2 (B ) > 0, and
(16)

Pr 1;1 (BL(G)) = v2  Pr 1;1 (B );
Pr 2;1 (BL(G)) = v 2  Pr 2;1 (B );
Pr 1;2 (BL(H )) = x2  Pr 1;2 (B );
Pr 2;2 (BL(H )) = x2  Pr 2;2 (B );

Pr 1;1 (L(G)) = w2  Pr 1;1 (B )
Pr 2;1 (L(G)) = w2  Pr 2;1 (B )
Pr 1;2 (L(H )) = z2  Pr 1;2 (B )
Pr 2;2 (L(H )) = z2  Pr 2;2 (B ) :

These conditions already entail v2  w2 , v 2  w2 , x2  z2 , and x2  z2 . With the results
from a), we additionally get w2  v2 + v2 and z2  x2 + x2 . By Lemma B.3 b), there is
233

Lukasiewicz

v 2 [w2 , v2 ; v2 ] and x 2 [z2 , x2; x2 ] with (14). By (16), there is Pr 1 2 Mo (B; G) and
Pr 2 2 Mo (B; H ) with Pr 1 (B ) > 0, Pr 2 (B ) > 0, and
Pr 1 (BL(G)) = v  Pr 1 (B ); Pr 1 (L(G)) = w2  Pr 1 (B )
Pr 2 (BL(H )) = x  Pr 2 (B ); Pr 2 (L(H )) = z2  Pr 2 (B ) :

By Lemma 3.1, we can choose Pr 1 and Pr 2 with Pr 1 (B ) = Pr 2 (B ). By Lemma A.1,
we can choose the probabilistic interpretation Pr 0 over fB; L(G); L(H )g with Pr 0 (A1 ) =
Pr 1 (A1 ) and Pr 0 (A2 ) = Pr 2 (A2 ) for all atomic events A1 and A2 over fB; L(G)g and
fB; L(H )g, respectively, such that:
Pr 0 (BL(G )L(H )) = min(Pr 1 (BL(G)); Pr 2 (BL(H )))
Pr 0 (BL(G )L(H )) = min(Pr 1 (BL(G)); Pr 2 (BL(H ))) :

By Lemma A.2 with B1 = B(B; G) n fB g, B2 = B(B; H ) n fB g, B0 = B , B1 = L(G),
and B2 = L(H ), there is a probabilistic interpretation Pr over B(B; C ) with (12). Hence,
it holds Pr 2 Mo (B; C ) and Pr (B ) > 0. By Lemma B.4 b), we get:
Pr (BL(C )) = Pr (BL(G)L(H )) = min(v2 ; x2 )  Pr (B )
Pr (L(C )) = Pr (L(G)L(H )) = min(w2 ; z2 ; v2 + x2 ; x2 + v2 )  Pr (B ) : 2

Finally, note that computing least upper bounds is more dicult than computing greatest lower bounds, since for each edge B ! C , by Lemmata 3.1 and B.4 a), the greatest lower
bound of Pr (BCL(C " ))=Pr (B ) subject to Pr 2 Mo (B; C ) and Pr (B ) > 0 is always 0, but
the least upper bound of Pr (BCL(C " ))=Pr (B ) subject to Pr 2 Mo (B; C ) and Pr (B ) > 0 is
generally not 1.

Appendix C. Proofs for Section 4.2

In this section, we give the proofs of Theorems 4.7 and 4.8.
We need some technical preparations as follows. The next lemma helps us to show the
local soundness of the function H1 in Fusion.

Lemma C.5 For all real numbers u1 ; u; v1 ; v; x1 ; x; y1; y 2 (0; 1] with u1  u, v1  v,
x1  x, y1  y, and u1 + x1 > 1, it holds:
min(u=v , u; x=y , x) = (u + x , 1)  min(u1 =v1 , u1 ; x1 =y1 , x1 ) = (u1 + x1 , 1) :

Proof. The claim can easily be veried (Lukasiewicz, 1996). 2

The following lemma helps us to show the local soundness and the local completeness
of the function H1 in Chaining and Fusion.

Lemma C.6 a) Let u, v, x, and y be real numbers from (0; 1]. For all probabilistic interpretations Pr with Pr (L(C " )) > 0, the conditions u  Pr (B ) = Pr (BC ), v  Pr (C ) = Pr (BC ),
x  Pr (C ) = Pr (CL(C " )), and y  Pr (L(C " )) = Pr (CL(C " )) are equivalent to:
234

Probabilistic Deduction with Conditional Constraints over Basic Events

Pr (B C L(C " ))
Pr (L(C " ))
Pr (BC L(C " ))
Pr (L(C " ))

Pr (B CL(C " ))
Pr (L(C " ))
Pr (BCL(C " ))
Pr (L(C " ))

Pr (C L(C " ))
Pr (L(C " ))

1,y

Pr (B C )
Pr (L(C " ))
yv yv
xu , x

Pr (BCL(C " ))
Pr (L(C " ))
Pr (BC L(C " ))
Pr (L(C " ))

Pr (B CL(C " ))
Pr (L(C " ))
Pr (BCL(C " ))
Pr (L(C " ))

y
x ,y

y

y yv
x, x
yv
x

b) Let u, v, x, and y be real numbers from (0; 1]. For all probabilistic interpretations Pr
with Pr (B ) > 0, the conditions u  Pr (B ) = Pr (BL(G )), v  Pr (L(G)) = Pr (BL(G )),
x  Pr (B ) = Pr (BL(H )), and y  Pr (L(H )) = Pr (BL(H )) are equivalent to:
Pr (B L(G) L(H ))
Pr (B)
Pr (BL(G)L(H ))
Pr (B)

Pr (B L(G)L(H ))
Pr (B)
Pr (BL(G )L(H ))
Pr (B)

Pr (B L(H ))
Pr (B)

x ,x
y

Pr (B L(G))
Pr (B)
u ,u
v

Pr (BL(G) L(H ))
Pr (B)
Pr (BL(G )L(H ))
Pr (B)

Pr (BL(G)L(H ))
Pr (B)
Pr (BL(G )L(H ))
Pr (B)

1,x

x

1,u

u

Proof. The claims can be veried by straightforward arithmetic transformations based on

the properties of probabilistic interpretations. 2
We are now ready to prove Theorems 4.7 and 4.8.
Proof of Theorem 4.7. The claims are proved by induction on the recursive denition of
H1 . The proof for C = B1B2 : : : Bk with k > 1 is done for k = 2. It can easily be generalized
to k  2. For C = B1 , we dene u1 = Pr 1 (C jB ), v1 = Pr 1 (B jC ), x1 = H1 (C; C " ), and
y1 = H1 (C; C " ). Note that 1 > 0 entails x1; y1 > 0 and v1 + x1 > 1. For C = B1 B2 ,
we dene G = B1 , H = B2 , u1 = H1 (B; G), v1 = H1 (B; G), x1 = H1 (B; H ), and
y1 = H1 (B; H ). Note that 1 > 0 entails u1 ; v1 ; x1 ; y1 > 0 and u1 + x1 > 1.
a) All models Pr 2 Mo (B; C ) with Pr (L(C )) = 0 satisfy the indicated condition. In the
sequel, let Pr 2 Mo (B; C ) with Pr (L(C )) > 0 and thus also Pr (B ) > 0.
Basis: Let C = B . Since C = L(C ), we get:

1  Pr (L(C )) = 1  Pr (L(C )) = Pr (CL(C )) = Pr (BL(C )) :
Induction: Let C = B1 . For all models Pr 2 2 Mo (C; C " ), we get x1 Pr 2 (C )  Pr 2 (CL(C " ))
by Theorem 4.3 a), and y1  Pr 2 (L(C " ))  Pr 2 (CL(C " )) by the induction hypothesis. Thus,
Pr satises the same conditions. Since L(C " ) = L(C ) and by Lemmata A.1 and C.6 a):

1 = y1 , xy11 + yx1 v11  Pr (CL(C " )) = Pr (L(C " )) = Pr (CL(C )) = Pr (L(C )) :
Let C = GH . For all models Pr 1 2 Mo (B; G) and Pr 2 2 Mo (B; H ), we get by
Theorem 4.3 a) and by the induction hypothesis, respectively:

u1  Pr 1 (B )  Pr 1(BL(G)); x1  Pr 2 (B )  Pr 2(BL(H ))
v1  Pr 1(L(G))  Pr 1(BL(G)); y1  Pr 2(L(H ))  Pr 2(BL(H )) :
235

Lukasiewicz

Hence, Pr satises the same conditions. Since L(G)L(H ) = L(GH ) = L(C ) and by Lemmata A.1, C.5, and C.6 b), we then get:
(BL(G)L(H ))=Pr (B )
1 = 1 = (1 + min(u1 =vu11,+ux11;,x11 =y1,x1 ) )  1 = (1 + Pr
Pr (BL(G)L(H ))=Pr (B) ) =

Pr (BL(C ))
Pr (L(C ))

:

b)
Basis: Let C = B . A model Pr 2 Mo (B; C ) such that Pr (B ) > 0, Pr (L(C )) > 0,
1  Pr (L(C )) = Pr (BL(C )), and 1  Pr (B ) = Pr (BL(C )) is given by B; B 7! 0; 1.
Induction: Let C = B1 . Let the model Pr 1 of f(C jB )[u1 ; u1 ]; (B jC )[v1 ; v1 ]g with Pr 1 (B ) > 0
and Pr 1 (C ) > 0 be dened like in the proof of Theorem 3.2.
By the induction hypothesis, there is Pr 2 2 Mo (C; C " ) with Pr 2 (C ) > 0, Pr 2 (L(C " )) > 0,
y1  Pr 2 (L(C ")) = Pr 2 (CL(C ")), and x1  Pr 2 (C ) = Pr 2 (CL(C ")). By Lemma 3.1, we can
choose Pr 1 and Pr 2 such that Pr 1 (C ) = Pr 2 (C ) and Pr 1 (B C )  Pr 2 (CL(C " )). By Lemmata A.1 and C.6 a), we can choose the probabilistic interpretation Pr 0 over fB; C; L(C " )g
with Pr 0 (A1 ) = Pr 1 (A1 ) and Pr 0 (A2 ) = Pr 2 (A2 ) for all atomic events A1 and A2 over
fB; C g and fC; L(C " )g, respectively, such that:
Pr 0 (BCL(C " )) = max(0; Pr 2 (CL(C " )) , Pr 1 (B C )) = 0
Pr 0 (BCL(C " )) = max(0; Pr 2 (CL(C " )) , Pr 1 (BC )) :

By Lemma A.2 with B1 = fB g, B2 = B(C; C " ) nfC g, B0 = C , B1 = B , and B2 = L(C " ),
there exists a probabilistic interpretation Pr over B(B; C ) with (12). Hence, it holds Pr 2
Mo (B; C ), Pr (B ) > 0, and Pr (L(C )) > 0. Moreover, by Lemma C.6 a), we get:

1 = y1 , xy11 + yx1v11 = Pr (CL(C ")) = Pr (L(C " )) = Pr (CL(C )) = Pr (L(C ))
= Pr (CL(C )) = Pr (C ) :
1 = u1 , uv11 + u1v1x1 = Pr (CL(C ")) = Pr (C )
Let C = GH . By the induction hypothesis, there are models Pr 1 2 Mo (B; G) and
Pr 2 2 Mo (B; H ) with Pr 1 (B ) > 0, Pr 2 (B ) > 0, Pr 1 (L(G)) > 0, Pr 2 (L(H )) > 0, and

u1  Pr 1 (B ) = Pr 1 (BL(G)); x1  Pr 2(B ) = Pr 2 (BL(H ))
v1  Pr 1(L(G)) = Pr 1 (BL(G)); y1  Pr 2 (L(H )) = Pr 2 (BL(H )) :
By Lemma 3.1, we can choose Pr 1 and Pr 2 with Pr 1 (B ) = Pr 2 (B ) and Pr 1 (B L(G)) 
Pr 2 (BL(H ). By Lemmata A.1 and C.6 b), we can choose the probabilistic interpretation
Pr 0 over fB; L(G); L(H )g with Pr 0 (A1 ) = Pr 1 (A1 ) and Pr 0 (A2 ) = Pr 2 (A2 ) for all atomic
events A1 and A2 over fB; L(G)g and fB; L(H )g, respectively, such that:
Pr 0 (BL(G)L(H )) = min(Pr 2 (BL(H )); Pr 1 (BL(G)))
Pr 0 (BL(G)L(H )) = max(0; Pr 2 (BL(H )) , Pr 1 (BL(G))) :

By Lemma A.2 with B1 = B(B; G) nfB g, B2 = B(B; H ) nfB g, B0 = B , B1 = L(G), and
B2 = L(H ), there exists a probabilistic interpretation Pr over B(B; C ) with (12). Hence,
236

Probabilistic Deduction with Conditional Constraints over Basic Events

it holds Pr 2 Mo (B; C ) and Pr (B ) > 0. By Lemma C.6 b), we get Pr (L(C )) > 0 and
Pr (BL(G)L(H ))=Pr (B) ) = Pr (BL(C ))
1 = 1 = (1 + min(u1 =vu11,+ux11;,x11=y1 ,x1) ) = 1 = (1 + Pr
(BL(G)L(H ))=Pr (B)
Pr (L(C ))

Pr (BL(G)L(H ))
(BL(C )) :
1 =
u1 + x1 , 1
=
= PrPr
Pr (B)
(B )
c) Let C = GH . By Theorem 4.3 b), there exist Pr 1 2 Mo (B; G) and Pr 2 2 Mo (B; H ) with
Pr 1 (B ) > 0, Pr 2 (B ) > 0, u1  Pr 1 (B ) = Pr 1 (BL(G)), and x1  Pr 2 (B ) = Pr 2 (BL(H )). By
Lemma 3.1, we can choose Pr 1 and Pr 2 such that Pr 1 (B ) = Pr 2 (B ) and Pr 1 (B L(G)) 
Pr 2 (BL(H ). By Lemmata A.1 and C.6 b), we can choose the probabilistic interpretation
Pr 0 over fB; L(G); L(H )g with Pr 0 (A1 ) = Pr 1 (A1 ) and Pr 0 (A2 ) = Pr 2 (A2 ) for all atomic
events A1 and A2 over fB; L(G)g and fB; L(H )g, respectively, such that:
Pr 0 (BL(G)L(H )) = max(0; Pr 2 (BL(H ) , Pr 1 (B L(G))) = 0
Pr 0 (BL(G)L(H )) = max(0; Pr 2 (BL(H )) , Pr 1 (BL(G))) :
By Lemma A.2 with B1 = B(B; G) nfB g, B2 = B(B; H ) nfB g, B0 = B , B1 = L(G), and
B2 = L(H ), there exists a probabilistic interpretation Pr over B(B; C ) with (12). Hence,
it holds Pr 2 Mo (B; C ) and Pr (B ) > 0. By Lemma C.6 b), we get Pr (L(C )) > 0 and
1 = Pr (BL(G)L(H )) = Pr (L(G)L(H )) = Pr (BL(C )) = Pr (L(C ))
1 = Pr (BL(G)L(H )) = Pr (B ))
= Pr (BL(C )) = Pr (B ) :
d) Let C = GH . By Theorem 3.2, there is a model Pr 000 2 Mo (B; C ) with Pr 000 (BL(C )) > 0.
By Theorem 4.3 b), there is a model Pr 00 2 Mo (B; C ) with Pr 00 (B ) > 0 and 0  Pr 00 (B ) =
1  Pr 00(B ) = Pr 00 (BL(C )). Hence, there is a model Pr 0 2 Mo (B; C ) with Pr 0 (B ) > 0 and
min("; Pr 000 (BL(C )) = Pr 000 (B ))  Pr 0 (B ) = Pr 0 (BL(C )) :
Let the models Pr 1 2 Mo (B; G) and Pr 2 2 Mo (B; H ) be dened by Pr 1 (A1 ) = Pr 0 (A1 ) and
Pr 2 (A2 ) = Pr 0 (A2 ) for all atomic events A1 and A2 over B(B; G) and B(B; H ), respectively.
By Lemma 3.1, we can choose Pr 1 and Pr 2 such that Pr 1 (B ) = Pr 2 (B ) and Pr 1 (B L(G)) 
Pr 2 (BL(H ). By Lemmata A.1 and C.6 b), we can choose the probabilistic interpretation
Pr 0 over fB; L(G); L(H )g with Pr 0 (A1 ) = Pr 1 (A1 ) and Pr 0 (A2 ) = Pr 2 (A2 ) for all atomic
events A1 and A2 over fB; L(G)g and fB; L(H )g, respectively, such that:
= 0
Pr 0 (BL(G)L(H )) = max(0; Pr 2 (BL(H ) , Pr 1 (B L(G)))
Pr 0 (BL(G)L(H )) = min("; Pr 000 (BL(C )) = Pr 000 (B ))  Pr 0 (B ) :
By Lemma A.2 with B1 = B(B; G) n fB g, B2 = B(B; H ) n fB g, B0 = B , B1 = L(G), and
B2 = L(H ), there is a probabilistic interpretation Pr over B(B; C ) with (12). Hence, it holds
Pr 2 Mo (B; C ), Pr (B ) > 0, Pr (L(C )) > 0, Pr (BL(C )) = 0, and "  Pr (B )  Pr (BL(C )). 2
Proof of Theorem 4.8. For u1 > 0, the claim is immediate by Theorem 4.7 a) to c).
Let u1 = 0 and E ) F . It holds 1  Pr (E ) = Pr (EF ) for all models Pr of KB . Moreover,
by Theorem 3.2, there exists a model Pr of KB with Pr (E ) > 0.
Let u1 = 0 and not E ) F . By Theorem 4.3 b), there exists a model Pr of KB
with Pr (E ) > 0 and Pr (EF ) = 0. By Theorem 4.7 d), there exists a model Pr of KB with
Pr (E ) > 0 and 1  Pr (E ) = Pr (EF ). 2

237

Lukasiewicz

Appendix D. Proofs for Section 4.3
In this section, we give the proof of Theorem 4.9.
The next lemma will help us to show the global tightness of the computed lower bound
in the case (3) of Theorem 4.9 b).

Lemma D.7 Let x 2 [0; 1] and v; x 2 [0; 1). For all probabilistic interpretations Pr with
Pr (G ) > 0, the conditions Pr (EG ) = 0, v  Pr (G) = Pr (EG ), x  Pr (G) = Pr (GF ), and
x  Pr (G) = Pr (GF ) are equivalent to:
Pr (E G F )
Pr (G)
Pr (EG F )
Pr (G)

Pr (E GF )
Pr (G)
Pr (EGF )
Pr (G)

Pr (G F )
Pr (G)

x

Pr (E G)
Pr (G)

v

Pr (EGF )
Pr (G)
Pr (EG F )
Pr (G)

Pr (E GF )
Pr (G)
Pr (EGF )
Pr (G)

1,x

x

1
0

Proof. The claim can be veried by straightforward arithmetic transformations based on

the properties of probabilistic interpretations. 2
We are now ready to prove Theorem 4.9.
Proof of Theorem 4.9. a) By the denition of queries to conditional constraint trees, all
paths from a basic event in E to a basic event in F have at least one basic event in common.
Hence, we can choose the basic event G from all such basic events in common such that
9(GjE )[z1 ; z2 ] is a strongly conclusion-restricted complete query to a subtree.
b) For u1 > 0, the claim follows from Theorem 4.7 a) to c). For the special case of exact
conditional constraint trees (B; KB ), the claim then follows from Theorems 4.3 and 4:5.
Let u1 = 0, v1 = 1, and G ) F . It holds 1  Pr (E ) = Pr (EF ) for all models Pr of KB .
Moreover, by Theorem 3.2, there exists a model Pr of KB with Pr (E ) > 0.
Let u1 = 0, v1 = 0, and G ) F . It is easy to see that by (1) and Theorem 4.7 d), the
tight upper answer is given by fx2 =1g. We now show that the tight lower answer is given by
fx1 =0g. By Theorem 4.3 b), there exists a model Pr 1 of KB 1 with Pr 1 (E ) > 0, Pr 1 (G) > 0,
and Pr 1 (EG ) = 0. By Theorem 3.2, there exists a model Pr 2 of KB 2 with Pr 2 (G) > 0. By
Lemma 3.1, we can choose Pr 1 and Pr 2 with Pr 1 (G) = Pr 2 (G) and Pr 1 (E G)  Pr 2 (GF ).
By Lemmata A.1 and D.7, we can choose the probabilistic interpretation Pr 0 over fE; G; F g
with Pr 0 (A1 ) = Pr 1 (A1 ) and Pr 0 (A2 ) = Pr 2 (A2 ) for all atomic events A1 and A2 over
fE; Gg and fG; F g, respectively, such that:
Pr 0 (EGF ) = max(0; Pr 2 (GF ) , Pr 1 (E G)) = 0
Pr 0 (EGF ) = 0 :

By Lemma A.2, there exists a probabilistic interpretation Pr over B with (12) for all atomic
events H0 , H1 , H2 , A1 , and A2 over the sets of basic events fGg, fE g, fF g, B1 n fGg, and
B2 n fGg, respectively. Hence, Pr is a model of KB with Pr (E ) > 0 and Pr (EF ) = 0.
For u1 = 0 and not G ) F , the claim follows from (1) and Theorem 4.7 d). 2
238

Probabilistic Deduction with Conditional Constraints over Basic Events

References

Adams, E. W. (1975). The Logic of Conditionals, Vol. 86 of Synthese Library. D. Reidel,
Dordrecht, Netherlands.
Amarger, S., Dubois, D., & Prade, H. (1991). Constraint propagation with imprecise
conditional probabilities. In Proceedings of the 7th Conference on Uncertainty in
Articial Intelligence, pp. 26{34. Morgan Kaufmann.
Andersen, K. A., & Hooker, J. N. (1994). Bayesian logic. Decision Support Systems, 11,
191{210.
Bacchus, F. (1990). Representing and Reasoning with Probabilistic Knowledge: A Logical
Approach to Probabilities. MIT Press, Cambridge, USA.
Bacchus, F., Grove, A., Halpern, J. Y., & Koller, D. (1996). From statistical knowledge
bases to degrees of beliefs. Articial Intelligence, 87, 75{143.
Carnap, R. (1950). Logical Foundations of Probability. University of Chicago Press, Chicago.
Coletti, G. (1994). Coherent numerical and ordinal probabilistic assessments. IEEE Transactions on Systems, Man, and Cybernetics, 24 (12), 1747{1754.
de Finetti, B. (1974). Theory of Probability. Wiley, New York.
Dubois, D., & Prade, H. (1988). On fuzzy syllogisms. Computational Intelligence, 4 (2),
171{179.
Dubois, D., Prade, H., Godo, L., & de Mantaras, R. L. (1993). Qualitative reasoning with
imprecise probabilities. Journal of Intelligent Information Systems, 2, 319{363.
Dubois, D., Prade, H., & Touscas, J.-M. (1990). Inference with imprecise numerical quantiers. In Ras, Z. W., & Zemankova, M. (Eds.), Intelligent Systems, chap. 3, pp. 53{72.
Ellis Horwood.
Fagin, R., Halpern, J. Y., & Megiddo, N. (1990). A logic for reasoning about probabilities.
Information and Computation, 87, 78{128.
Frisch, A. M., & Haddawy, P. (1994). Anytime deduction for probabilistic logic. Articial
Intelligence, 69, 93{122.
Garey, M. R., & Johnson, D. S. (1979). Computers and Intractability: A Guide to the
Theory of NP-Completeness. Freeman, New York.
Georgakopoulos, G., Kavvadias, D., & Papadimitriou, C. H. (1988). Probabilistic satisability. Journal of Complexity, 4 (1), 1{11.
Gilio, A., & Scozzafava, R. (1994). Conditional events in probability assessment and revision. IEEE Transactions on Systems, Man, and Cybernetics, 24 (12), 1741{1746.
Halpern, J. Y. (1990). An analysis of rst-order logics of probability. Artical Intelligence,
46, 311{350.
239

Lukasiewicz

Hansen, P., Jaumard, B., Nguetse, G.-B. D., & de Arag~ao, M. P. (1995). Models and algorithms for probabilistic and Bayesian logic. In Proceedings of the 14th International
Joint Conference on Articial Intelligence, pp. 1862{1868.
Heinsohn, J. (1994). Probabilistic description logics. In Proceedings of the 10th Conference
on Uncertainty in Articial Intelligence. Morgan Kaufmann.
Jaumard, B., Hansen, P., & de Arag~ao, M. P. (1991). Column generation methods for
probabilistic logic. ORSA Journal of Computing, 3, 135{147.
Kavvadias, D., & Papadimitriou, C. H. (1990). A linear programming approach to reasoning
about probabilities. Annals of Mathematics and Articial Intelligence, 1, 189{205.
Lukasiewicz, T. (1996). Precision of Probabilistic Deduction under Taxonomic Knowledge.
Doctoral Dissertation, Universitat Augsburg.
Lukasiewicz, T. (1997). Ecient global probabilistic deduction from taxonomic and probabilistic knowledge-bases over conjunctive events. In Proceedings of the 6th International Conference on Information and Knowledge Management, pp. 75{82. ACM
Press.
Lukasiewicz, T. (1998a). Magic inference rules for probabilistic deduction under taxonomic
knowledge. In Proceedings of the 14th Conference on Uncertainty in Articial Intelligence, pp. 354{361. Morgan Kaufmann.
Lukasiewicz, T. (1998b). Many-valued rst-order logics with probabilistic semantics. In Proceedings of the Annual Conference of the European Association for Computer Science
Logic. To appear.
Lukasiewicz, T. (1998c). Probabilistic deduction with conditional constraints over basic
events. In Principles of Knowledge Representation and Reasoning: Proceedings of the
6th International Conference, pp. 380{391. Morgan Kaufmann.
Lukasiewicz, T. (1998d). Probabilistic logic programming. In Proceedings of the 13th European Conference on Articial Intelligence, pp. 388{392. J. Wiley & Sons.
Lukasiewicz, T. (1999a). Local probabilistic deduction from taxonomic and probabilistic
knowledge-bases over conjunctive events. International Journal of Approximate Reasoning. To appear.
Lukasiewicz, T. (1999b). Probabilistic and truth-functional many-valued logic programming. In Proceedings of the 29th IEEE International Symposium on Multiple-Valued
Logic. To appear.
Luo, C., Yu, C., Lobo, J., Wang, G., & Pham, T. (1996). Computation of best bounds of
probabilities from uncertain data. Computational Intelligence, 12 (4), 541{566.
Ng, R. T., & Subrahmanian, V. S. (1993). A semantical framework for supporting subjective
and conditional probabilities in deductive databases. Journal of Automated Reasoning,
10 (2), 191{235.
240

Probabilistic Deduction with Conditional Constraints over Basic Events

Ng, R. T., & Subrahmanian, V. S. (1994). Stable semantics for probabilistic deductive
databases. Information and Computation, 110, 42{83.
Nilsson, N. J. (1986). Probabilistic logic. Articial Intelligence, 28, 71{88.
Nilsson, N. J. (1993). Probabilistic logic revisited. Articial Intelligence, 59, 39{42.
Paa, G. (1988). Probabilistic Logic. In Dubois, D., Smets, P., Mamdani, A., & Prade,
H. (Eds.), Non-Standard Logics for Automated Reasoning, chap. 8, pp. 213{251. Academic Press.
Papadimitriou, C. H., & Steiglitz, K. (1982). Combinatorial Optimization, Algorithms and
Complexity. Prentice-Hall, Englewood Clis, NJ.
Pearl, J. (1988). Probabilistic Reasoning in Intelligent Systems: Networks of Plausible
Inference. Morgan Kaufmann, San Mateo, CA.
Pittarelli, M. (1994). Anytime decision making with imprecise probabilities. In Proceedings
of the 10th Conference on Uncertainty in Articial Intelligence, pp. 470{477. Morgan
Kaufmann.
Schrijver, A. (1986). Theory of Linear and Integer Programming. Wiley, New York.
Thone, H. (1994). Precise Conclusion under Uncertainty and Incompleteness in Deductive
Database Systems. Doctoral Dissertation, Universitat Tubingen.
Thone, H., Kieling, W., & Guntzer, U. (1995). On cautious probabilistic inference and
default detachment. Annals of Operations Research, 55, 195{224.
van der Gaag, L. (1991). Computing probability intervals under independency constraints.
In Uncertainty in Articial Intelligence 6, pp. 457{466. North-Holland, Amsterdam.
Walley, P. (1991). Statistical Reasoning with Imprecise Probabilities. Chapman and Hall,
New York.

241

Journal of Articial Intelligence Research 10 (1999) 375-397

Submitted 2/99; published 6/99

EÆcient Heuristic Hypothesis Ranking
steve.chien@jpl.nasa.gov
andre.stechert@jpl.nasa.gov
darren.mutz@jpl.nasa.gov

Steve Chien
Andre Stechert
Darren Mutz
Jet Propulsion Laboratory
California Institute of Technology
4800 Oak Grove Drive, M/S 126-347
Pasadena, CA 91109-8099

Abstract

This paper considers the problem of learning the ranking of a set of stochastic alternatives based upon incomplete information (i.e., a limited number of samples). We describe
a system that, at each decision cycle, outputs either a complete ordering on the hypotheses
or decides to gather additional information (i.e., observations) at some cost. The ranking
problem is a generalization of the previously studied hypothesis selection problem|in selection, an algorithm must select the single best hypothesis, while in ranking, an algorithm
must order all the hypotheses.
The central problem we address is achieving the desired ranking quality while minimizing the cost of acquiring additional samples. We describe two algorithms for hypothesis
ranking and their application for the probably approximately correct (PAC) and expected
loss (EL) learning criteria. Empirical results are provided to demonstrate the eectiveness
of these ranking procedures on both synthetic and real-world datasets.
1. Introduction

In many applications, the cost of information can be quite high, imposing a requirement
that learning algorithms glean as much usable information as possible with a minimum of
data. For example:



Data may be scarce, making learning the most possible from limited training data
key.



In speedup learning, minimizing processing time is critical. Here, reducing the number
of necessary training examples is key since the expense of processing each example
can be signicant (Tadepalli, 1992).



In decision tree learning, the cost of using all available training examples when evaluating potential attributes for partitioning can be computationally expensive (Musick,
Catlett, & Russell, 1993).



In evaluating medical treatment policies, acquiring additional training examples might
imply that human subjects are exposed to an experimental treatment for a longer
period than is necessary.

When one wishes some sort of guarantee on the quality of a solution, a statistical decision
theoretic framework is useful. The framework answers the questions: How much information

c 1999 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

Chien, Stechert, & Mutz
is enough? At what point do we have adequate information to rank the alternatives with
some requested condence?
This paper focuses on parametric ranking problems, a general class of statistical machine learning problems in which the goal is to rank a set of alternative hypotheses where
the goodness of a hypothesis is a function of a set of parameters whose values are unknown
(e.g., Chien, Stechert, & Mutz, 1998; Gratch, 1992; Greiner & Jurisica, 1992; Kaelbling,
1993; Moore & Lee, 1994; Musick et al., 1993). The learning system determines and renes estimates of these parameters by using training examples, with a secondary goal of
minimizing learning cost.
The principal contributions of this paper are:



We dene two families of hypothesis ranking algorithms, based on recursive selection
and adjacency, respectively. We provide specic details on how to apply them using
the probably approximately correct (PAC) and expected loss (EL) decision criteria.



We provide empirical results demonstrating the eectiveness of these algorithms at
achieving the requested decision criteria on synthetic data.



We provide empirical results showing that these algorithms signicantly outperform
existing statistical methods on real-world data from spacecraft design optimization
and image compression applications.

The remainder of this paper is structured as follows. First, we describe the hypothesis ranking problem more formally, including denitions for the probably approximately
correct (PAC) and expected loss (EL) decision criteria. We then dene two algorithms for
establishing these criteria for the hypothesis ranking problem|a recursive hypothesis selection algorithm and an adjacent comparison algorithm. Next, we describe empirical tests
demonstrating the eectiveness of these algorithms as well as documenting their improved
performance over a standard algorithm from the statistical ranking literature. Finally, we
describe related work and future extensions to the algorithms.
2. Hypothesis Ranking Problems

Hypothesis ranking problems are an abstract class of learning problems where an algorithm
is given a set of hypotheses to rank. The ranking desired is that which orders the hypotheses
by their expected utility, which is determined by the hypothesis' underlying probability
distribution. These expected utilities are unknown to the algorithm and must be estimated
from the training data.
Hypothesis ranking problems are an extension of hypothesis selection problems (Chien,
Gratch, & Burl, 1995), in which a learning system attempts to select the best alternative
from a set of hypotheses. The distinction between hypothesis ranking and hypothesis selection is that in selection the learning algorithm is interested in a single best hypothesis, while
in ranking the learning algorithm must determine the relative order of all of the hypotheses1 .
Hypothesis selection and ranking is an important aspect of many machine learning
problems. For example, the utility problem in speedup learning can be viewed as a selection
1. The algorithms and results described in this paper extend in a straightforward fashion to hybrid rankingselection problems in which the system must select and rank the top M out of N hypotheses.

376

Efficient Heuristic Hypothesis Ranking
problem where a single problem-solving heuristic or strategy is chosen from a larger set of
candidates. In this case, the expected utility is typically dened as the average time to solve
a problem (Gratch, 1992; Greiner & Jurisica, 1992; Minton, 1988). The attribute selection
problem in machine learning can also be viewed as a hypothesis selection problem in which
one must select the best attribute split from a set of possible attribute splits and utility
is often measured by information gain (Musick et al., 1993). In reinforcement learning, a
system must learn the appropriate action for each context, where utility is interpreted as
expected reward (Kaelbling, 1993).2
A key observation regarding each of these problems (and all learning problems, in general) is that each of them could be viewed as an optimization problem, where the utility
is the function being optimized. Then, the application of traditional (or non-traditional)
optimization methods will yield good results within the guarantees provided by the algorithm and depending on the features of the landscape being optimized. However, with the
addition of a model of sampling cost, a new degree of freedom is added to the problem.
Where the cost of samples is very high, traditional optimization algorithms will fare poorly.
Additionally, while in many of the mentioned applications the system chooses a single
alternative and never revisits the decision, there are also many cases for which a system
will want to investigate several prioritized options (either serially or in parallel), and hence
a ranking is useful. Motivation is provided by the following scenarios:



Upper and lower bounds, span: Minimax search algorithms can use metaknowledge

(such as upper and lower bounds of a node) for pruning other parts of the tree. Also,
there are times when knowing the span of the expected utilities of the candidate set is
useful (e.g., when checking for convergence conditions in an adaptive algorithm such
as a GA).



Augmenting external knowledge: Another area in which hypothesis ranking may have



The entire ranking: In some cases, the entire ranking is signicant. For instance,

important applications is hypothesis selection with human supervision. When the
stochastic objective function (i.e., the hypothesis) represents only a part of the problem, the ranking can be used to augment external knowledge of the problem. For
example, engineering simulations usually capture the physical properties of the candidate designs, but usually choose to forego the details of manufacturing, logistics, and
economics.
in evolutionary algorithms, the individuals to be propagated to future generations
are often selected with likelihood that is proportionate to their rank in the current
generation (Goldberg, 1989). Another example arises in the case of search algorithms
that take advantage of node ordering heuristics, such as beam search or iterative
broadening (Ginsberg & Harvey, 1992).

In any hypothesis evaluation problem, always achieving a correct ranking is impossible
in practice, because the exact underlying probability distributions are unknown. Thus,
there is always a (perhaps vanishingly) small chance that the algorithms will be unlucky
2. Note that the analogous reinforcement learning problem is the one in which we are learning the appropriate action with immediate feedback rather than delayed feedback.

377

Chien, Stechert, & Mutz
because only a nite number of samples can be taken. Consequently, rather than always
requiring an algorithm to output a correct ranking, we impose probabilistic criteria on the
rankings to be produced. While several families of such requirements exist, in this paper
we examine two criteria: the probably approximately correct (PAC) model for selecting
a hypothesis function that approximates well a target function (Valiant, 1984) and the
expected loss (EL) requirement frequently used in decision theory and gaming problems
(Russell & Wefald, 1992). Informally, to satisfy the PAC requirement, an algorithm must
produce a result that with high probability is close to correct (e.g., incorrect orderings will
be most likely to occur between hypotheses with similar expected utilities). The satisfy the
EL requirement, on the other hand, a bound must be established on the expected loss of
the result, where loss is the dierence in utilities between two incorrectly ordered hypothese
in an incorrect ranking.
The expected utility of a hypothesis can be estimated by observing its values over a
nite set of training examples. However, to satisfy the decision criteria, an algorithm must
also be able to reason about the potential dierence between the estimated and true utilities
of each hypotheses. Let Ui denote the true expected utility of hypothesis i and let U^i be
the estimated expected utility of hypothesis i. Without loss of generality, let us presume
that the proposed ranking of hypotheses is U1 > U2 >; :::; > Uk 1 > Uk .
The PAC requirement states that, for some user-specied , with probability 1 Æ:
k^1

[(Ui + ) > MAX (Ui+1 ; :::; Uk )]

(1)

i=1

In the context of the PAC criterion, the number  is called the indierence interval and

Æ is the overall ranking error or total error rate. 3

The issue of how to allocate the overall ranking error among the many possible pairwise
comparisons of hypotheses is discussed in the next section.
Correspondingly, when selecting a hypothesis H1 to be the best from a set of k hypotheses H1 ; :::; Hk , let the selection loss L be as follows.
L(H1 ; fH1 ; :::; Hk g) = MAX (0; MAX (U2 ; :::; Uk )

U1 )

(2)

Then, the ranking loss RL of a ranking H1 ; :::; Hk would be:
RL(H1 ; :::; Hk ) =

k 1
X

L(Hi ; fHi+1 ; :::; Hk g)

(3)

i=1

3. The distinction betwen the true means and the estimated means (for which we use the sample means)
is a confusing one. When assessing the validity of a ranking produced by an algorithm, one would use
the true means of the distributions (if available, as in test distributions) or the most accurate estimation
possible (such as from an edxtremely large sampling of the distribution). However, a ranking algorithm
uses the estimated parameters (including sample mean) to estimate the error. For estimation of a single
mean the estimate of the mean is normally distributed around the true mean so that this usage is
justied. However, we have not proven (and indeed are unsure) whether using the estimate in more
complex ranking and selection contexts is guaranteed correct (see later section on the heuristic nture of
our algorithms).

378

Efficient Heuristic Hypothesis Ranking
A hypothesis ranking algorithm which obeys the expected loss requirement must produce
rankings that on average have less ranking loss than the requested expected loss bound. The
policy for loss allocation is also discussed in the next section.
As an example, consider ranking the hypotheses with expected utilities: U1 = 1:0; U2 =
0:95; U3 = 0:86. The ranking U2 > U1 > U3 is a valid PAC ranking for the indierence
interval  = 0:06 but not for  = 0:01 and the observed ranking loss is 0:05 + 0 = 0:05.
However, while the condence in a pairwise comparison between two hypotheses is well
understood to be the complement of the probability of the comparison's result being in
error, it is less clear how to dene and ensure that a desired condence is met in the set of
comparisons required for a selection or the even more complex set of comparisons required
for a ranking. Equation 4 denes the condence that Ui +  > Uj , when the utilities are
normally distributed with unknown and unequal variances.

pn 



 =  (U^i

j + )
^

Si

(4)

j

where  represents the cumulative standard normal distribution function, and n, U^i j ,
and S^i j are the size, sample mean, and sample standard deviation of the blocked dierential
distribution4, respectively.
Likewise, computation of the expected loss for asserting an ordering between a pair of
hypotheses is well understood, but the estimation of expected loss for an entire ranking is
less clear. Equation 5 denes the expected loss for drawing the conclusion Ui > Uj , again
under the assumption of normality (see Chien et al., 1995, for further details).
EL[Ui > Uj ] =

S^i

je

U^i j 2
)
j

0:5n( ^
Si

p

2n

+

U^i

p

j

2

Z

1

U^i j pn
S^i j

e

0:5z 2

dz

(5)

In the next two subsections, we describe two interpretations for estimating the likelihood
that an overall ranking satises the PAC or EL requirements by estimating and combining
pairwise PAC errors or EL estimates. Each of these interpretations lends itself directly to
an algorithmic implementation as described below.
2.1 Ranking as Recursive Selection

One obvious way to determine a ranking H1 ; :::; Hk is to view ranking as recursive selection
from the set of remaining candidate hypotheses. In this view, the overall ranking error,
as specied by the desired condence in PAC algorithms and the loss threshold in EL
algorithms, is rst distributed among k 1 selection errors which are then further subdivided
into pairwise comparison errors (Figure 1). Data is then sampled until the estimates of the
pairwise comparison error (as dictated by equation 4 or 5) satisfy the bounds set by the
algorithm.
4. Note that in our approach we block, or match, examples to further reduce sampling complexity. Blocking
makes estimates by using the dierence in utility between competing hypotheses on each observed example. Blocking can signicantly reduce the variance in the data when the hypotheses are not independent.
The dierential distribution is formed by taking the dierences of the blocked individual samples to form
a new distribution. It is trivial to modify the formulas to address the cases in which it is not possible to
block data (see Moore & Lee, 1994; Chien et al., 1995, for further details).

379

Chien, Stechert, & Mutz

H1

H2

H3

H4

H5

H2

H3

H4

H5

H3

H4

H5

H4

H5

Σ
γ*

Figure 1: Computing the overall error of a recursive ranking. The per-comparison errors
are summed at each level in the recursion, and the overall sum (across all levels)
is compared with the specied total error,   .

Thus, another degree of freedom in the design of recursive ranking algorithms is the
method by which the overall ranking error is ultimately distributed among individual pairwise comparisons between hypotheses. Two factors inuence the way in which we compute
error distribution. First, our model of error combination determines how the error allocated
for individual comparisons or selections combines into overall ranking error and therefore
how many candidates are available for the distribution of error.
Using Bonferroni's inequality, which asserts that the probability of a union of events is
no greater than the sum of the probabilities of the individual events5 , one would be inclined
to combine the errors additively. However, following a more conservative approach, one
can assert that because the predicted \best" hypothesis may change during sampling in the
worst case, the conclusion might dependon all possible pairwise comparisons and that the
error should be distributed among all n2 pairs of hypotheses.6
Second, our policy with respect to allocation of error among the candidate comparisons
or selections determines how samples will be distributed. For example, in some contexts, the
consequences of early selections far outweigh those of later selections. For these scenarios,
we have implemented ranking algorithms that divide overall ranking error unequally in
5. Note that this is only the simplest of the Bonferonni inequalities, which fall into clean correspondence
with the terms of the expansion of the probability of a union of events according to the principle of
inclusion and exclusion in a natural way.
6. For a discussion of this issue, see pp. 18-20 of (Gratch, 1993).

380

Efficient Heuristic Hypothesis Ranking
favor of earlier selections.7 Also, it is possible to divide selection error into pairwise error
unequally based on estimates of hypothesis parameters in order to reduce sampling cost
(for example, Gratch, Chien, & DeJong, 1994, allocates error rationally).
Within the scope of this paper, we only consider algorithms that: (i) combine pairwise
error into selection error additively, (ii) combine selection error into overall ranking error
additively, and (iii) allocate error equally at each level.
One disadvantage of recursive selection is that once a hypothesis has been selected, it is
removed from the pool of candidate hypotheses. This is an issue in rare cases when, while
sampling to increase the condence of some later selection, the estimate for a hypothesis'
mean changes enough that some previously selected hypothesis no longer dominates it.
However, it remains that the original hypotheses were shown to dominate the others with
a specied level of certainty,   .
These assumptions result in the following formulations (where Æ(U1  fU2 ; :::; Uk g) is
used to denote the error due to the action of selecting hypothesis 1 under Equation 1
from the set fH1 ; :::; Hk g and Æ(U1  fU2 ; :::; Uk g) denotes the error due to selection loss in
situations where Equation 2 applies):
Ærec (U1 > U2 > ::: > Uk ) =

Ærec (U2 > U3 > ::: > Uk )
+Æ (U1  fU2 ; :::; Uk g)

(6)

where Ærec (Uk ) = 0 (the base case for the recursion) and the selection error is as dened
in (Chien et al., 1995):
Æ (U1  fU2 ; :::; Uk g) =

k
X

Æ1;i

(7)

i=2

using Equation 4 to compute pairwise condence.

Algorithmically, we implement this with the following pseudo-code:

ensure there are n0 samples per hypothesis
distribute the error to individual selections
while (stopping criteria has not been met)
take more samples
if (means are ordered dierently than ranking)
restart the algorithm
An analogous recursive selection algorithm based on expected loss is dened as follows
ELrec (U1 > U2 > ::: > Uk ) =

ELrec (U2 > U3 > ::: > Uk )
+EL(U1  fU2 ; :::; Uk g)

(8)

where ELrec(Uk ) = 0 and the selection EL is as dened in (Chien et al., 1995):
EL(U1  fU2 ; :::; Uk g) =

k
X
i=2

7. Space constraints preclude their description here.

381

EL(U1 ; Ui )

(9)

Chien, Stechert, & Mutz

γ*

Σ

γ1,2

H1

γ2,3

H2

γk-1,k

H3

Hk-1

•••

Hk

Figure 2: Computing the overall error in an adjacent ranking. Per-comparison errors between neighboring hypotheses in the proposed ranking are summed and compared
with the required total error,   .

2.2 Ranking by Adjacency Comparison

Another interpretation of ranking condence (or loss) is that only adjacent elements in the
ranking need be compared. In this case, the overall ranking error is divided directly into
k 1 pairwise comparison errors (Figure 2). This leads to the following condence equation
for the PAC criteria:
Æadj (U1 > U2 > ::: > Uk ) =

k 1
X

Æi;i+1

(10)

i=1

And the following equation for the EL criteria.
ELadj (U1 > U2 > ::: > Uk ) =

k 1
X

EL(Ui ; Ui+1 )

(11)

i=1

Because ranking by comparison of adjacent hypotheses does not establish dominance
or loss bounds between non-adjacent hypotheses (where the hypotheses are ordered by
observed mean utility), it has the advantage of requiring fewer comparisons than recursive
selection (and thus may require fewer samples than recursive selection). However, for the
same reason, adjacency algorithms may be less likely than the recursive selection algorithms
to bound the probability of a correct ranking (or average loss) correctly. In the case of the
PAC algorithms, this is because -dominance is not necessarily transitive. In the case of the
EL algorithms, it is because expected loss is not necessarily additive when considering two
hypothesis comparisons sharing a common hypothesis.8
8. An example where ranking loss between non-adjacent hypotheses exceeds the desired loss bound for
the ranking, even though the sum of the adjacent losses does not, occurs when the blocked dierential
distribution induced by two non-adjacent hypotheses has high variance relative to an hypothesis adjacent

382

Efficient Heuristic Hypothesis Ranking
2.3 The Heuristic Nature of the Algorithms

Both the recusrsive selection and adjacency algorithms are heuristic in the sense that they
are not proven to statistically meet the specied decision criteria (i.e., for the PAC criteria
select a ranking that satises equation (1) with probability 1 Æ and similarly for the EL
criteria average a ranking loss specied by equation (3) less than the requested bound.
Indeed, several aspects of these algorithms make it extremely diÆcult to prove that they
would (probabilistically) achieve the corresponding decision criteria. These aspects include:



Sharing of samples: In order to have n1 samples for a dierential distribution (i.e.



Heuristic error combination: Both the recursive selection and adjacency error com-



Ignorance of lead switches and multiple comparison paths: During the sampling pro-



blocking) for H1 and H2 , it takes n1 samples of H1 and n1 samples on the the same
problems for H2 . Our algorithms further reduce the sampling cost by reusing these
samples in dierential distributions comparing H1 to other hypotheses and H2 to
other hypotheses. This makes the errors derived from these samples not independent.
Hence we have traded accuracy and ease of analysis of the algorithms for heuristic
eÆciency. Particularly in the recursive selection approach, samples for the lowest
ranking hypothesis would have been used in k 1 dierential comparisons.
bination models are heuristic means of combining pairwise errors. This is because
the pairwise errors are not independent (see above). Empirically we have observed
that the pairwise errors tend to be overestimated but the error combination function
tends to under-combine. Overall empirically the combined error estimates tend to be
reasonably accurate, as the remaining sections show.
cess, the ordering of the hypotheses may change (e.g., the ordering of sample means
may change). This means that implicitly, the decision depended on an additional
pairwise comparison that may not be reected in the nal set of comparisons contributing a pairwise error. This complexity could be avoided by xing the order of the
hypotheses after n0 samples. However, this would require more samples as is would
involve showing -dominance of a hypothesis over a higher sample mean hypothesis
(indeed, it may never converge). We choose to ignore this complexity and base the
combined error used in the stopping condition on the nal ordering.

Use on non-normal distributions: In many of the applications described in the re-

mainder of this article, the real-world data is distributed in a manner not very simlar
to normal distributions (we further investigate this issue later in the article). The
algorithms we describe are heuristic in that they presume that the data is normally
distributed even though this is not the case.

to both (i.e., currently ranked between them). The variance of the dierential distribution makes its
maximum contribution when the sample set is small, so, e.g., with 1 2 = 2, 1 2 = 2, n1 2 = 2,
2 3 = 2, 2 3 = 2, and n2 3 = 2, there exists a conguration for which 1 3 = 4, 1 3 = 8. The
expected losses are EL(H1 ; H2 ) = 2:05, EL(H2 ; H3 ) = 2:05, but EL(H1 ; H3 ) = 4:80 > 4:10.

383

Chien, Stechert, & Mutz
2.4 Other Relevant Approaches

Most standard statistical ranking/selection approaches make strong assumptions about the
form of the problem (e.g., the variances associated with underlying utility distribution of
the hypotheses might be assumed known and equal). Among these, the method of Turnbull
and Weiss (Turnbull & Weiss, 1984) is most comparable to our PAC-based approach.9
Turnbull and Weiss' algorithm is a sequential interval-based procedure for selecting
the member of a population with the largest mean. They treat hypotheses as normally
distributed random variables of unknown mean that have unknown and possibly unequal
variance. Their algorithm also carries the additional stipulation that the hypotheses be
independent. The procedure consists of taking an initial sample of n0 observations on each
of the hypotheses and then taking samples sequentially according to their stopping criteria.
When the stopping criteria has been satised, the hypothesis with the highest sample mean
2
is chosen. The stopping criteria is that the inequality Snii  n1 is satised, where Si and
ni are the sample mean and the number of samples of the ith hypothesis and n is chosen
2
according to the indierence
interval  and the condence level   . In particular, n = d2
R1
and d is chosen to satisfy 1 (F (y + d))k 1f (y)dy =   where F (y) and f (y) are the cumulative
distribution function and probability density function of the standard normal distribution.
While it is still reasonable to use this approach when the candidate hypotheses are not
independent, excessive statistical error or unnecessarily large training set sizes may result. In
the case that the hypotheses are truly independent, Turnbull and Weiss' technique should
be able to exploit this knowledge and outperform our methods which do not adopt this
assumption.
3. Empirical Performance Evaluation

We now turn to empirical evaluation of the hypothesis ranking techniques on both synthetic
and real-world datasets. This evaluation serves three purposes. First, it demonstrates that
the techniques perform as predicted (in terms of bounding the probability of incorrect selection or expected loss). Second, it validates the performance of the techniques as compared
to standard algorithms from the statistical literature. Third, the evaluation demonstrates
the robustness of the new approaches to real-world hypothesis ranking problems.
An experimental trial consists of solving a hypothesis ranking problem with a given
technique and a given set of problem and control parameters. We measure performance
by (1) how well the algorithms satisfy their respective criteria; and (2) the number of
samples taken or, alternatively, the cost (in seconds) of executing the algorithm. Since the
performance of these statistical algorithms on any single trial provides little information
about its overall behavior, each trial is repeated multiple times and the results are averaged
across trials. Synthetic experimental trials were repeated 500 times, while trials on the
real-world data were repeated 100 times. Because the PAC and expected loss criteria are
not directly comparable, the approaches are analyzed separately.
9. PAC-based approaches have been investigated extensively in the statistical ranking and selection literature under the topic of condence interval based algorithms (see Haseeb, 1985, for a review of the recent
literature).

384

Efficient Heuristic Hypothesis Ranking
Hk

H4

H3

H2

H1

µ-(k-1)ε

µ-3ε

µ-2ε

µ-ε

µ

utility

Figure 3: The stepped means hypothesis conguration.
3.1 Evaluation on Synthetic Datasets

Evaluation on synthetic data is used to show that: (1) the techniques correctly bound probability of incorrect ranking and expected loss as predicted when the underlying assumptions
are valid even when the underlying utility distributions are inherently hard to rank 10 , and
(2) that the PAC techniques compare favorably to the algorithm of Turnbull and Weiss in
a wide variety of circumstances.
For the synthetic datasets, the utility distributions of the hypotheses were modeled as
random variables dened on some underlying parameterized distribution. Thus, characterizing a ranking problem consists of choosing some number of hypotheses to rank and then
assigning values for parameters representing each utility distributions for these hypotheses. In our case, we model the utilities as independent normal random variables with some
mean and standard deviation. Thus, if we let k be the number of hypotheses, then each hypothesis ranking problem is described by the 2k parameters specifying the expected utility
and utility standard deviation for each hypothesis. In general, while several more parameters may be required to characterize a ranking problem fully11, the number of hypotheses
and the choices for the parameters of the utility distributions underlying these hypotheses
characterize the overall diÆculty of the ranking problem.
The statistical ranking and selection community uses a standard family of selection
problems with known diÆculty to analyze the performance of hypothesis selection strategies.
The method, called the least favorable conguration (LFC) of the population means is that
assignment of the parameters to distributions which is most likely to cause a technique to
choose a wrong hypothesis and thus provides the most severe test of the technique's abilities.
Under this conguration, all utilities are independent normally distributed variables of equal
variance. k 1 of the hypotheses have utilities with equal expectation, , and the remaining
hypothesis has expected utility  + .
Because we are interested in hypothesis ranking problems rather than selection problems,
we use a generalization of the LFC that we call stepped means. In this conguration, one
of the hypotheses is assigned expected utility  and successive hypotheses are assigned
expected utility  i for i from 1; :::; k 1 (Figure 3).
In general, problems based on the least favorable conguration become more diÆcult
(i.e., require more samples) when the number of hypotheses k increases, the common utility
variance 2 increases, or the dierence in the means of the utility distributions decreases. In
the standard methodology, a technique is evaluated by its ability to achieve a condence of
10. Congurations that contain hypotheses with high variance relative to the separation between their means
are more diÆcult to rank.
11. For instance, when samples are allocated rationally in (Chien et al., 1995), it becomes necessary to assign
parameters to a cost distribution as well, or if only a few of the candidate hypotheses were to be ranked,
the number of hypotheses to rank would be another problem parameter.

385

Chien, Stechert, & Mutz
correct selection   using several settings for k and  . This last ratio combines  and  into
a single quantity which, as it increases, makes the problem more diÆcult. This methodology
extends to stepped means directly.
The hypothesis ranking strategies themselves have algorithm control parameters that
govern how they attack a problem. The PAC techniques have three control parameters: an
initial sample size n0 , a desired condence of correct ranking   and an indierence setting
12 . The expected loss techniques have two control parameters: an initial sample size n0
and a loss threshold H  .
The observed number of samples required and achieved accuracy of the PAC techniques
on the stepped means conguration are shown in Table 3.1. The results indicate that all
systems are roughly comparable in the number of examples required to choose a hypotheses.
As expected, the number of examples increases with k,   , and  . The P ACadj algorithm
required the least number of samples but was inconsistent in meeting the desired accuracy
bound (as indicated by its failure to meet the prescribed error bound in several cases). It is
interesting that the Turnbull and Weiss method did not signicantly outperform the PAC
techniques despite the fact that the algorithm assumes that the hypotheses are independent
(as is the case in the stepped means conguration), while the PAC approaches do not make
this assumption. In this comparison, the principal performance metric is the number of
samples required to achieve the requested ranking, both methods were eective at achieving
the requested accuracy.
In the expected loss experiments, we ran the expected loss hypothesis ranking algorithms
on the same stepped means congurations described above with a range of expected loss
bounds. Table 3.1 shows the results of this experiment, displaying the number of samples
required to produce a ranking and the average observed loss for each conguration. These
results show that the ELrec algorithm correctly bounded the loss and that the ELadj algorithm required less samples than the ELrec algorithm, but did not correctly bound the
expected loss (since the observed loss was greater than the loss bound H  .13
3.2 Evaluation on Real Datasets

The test of real-world applicability is based on data drawn from several datasets relating
to spacecraft design and the processing of science data gathered in the context of planetary
exploration. The rst two datasets we investigate relate to spacecraft design optimization
problems in which the hypotheses we wish to rank are candidate solutions to the design
problem. The third and last dataset we examine involves ranking various lossless image
compression approaches based on their performance on a large set of terrestrial images collected by the spacecraft Galileo. Cost of evaluation is given in seconds for all empirical data
12. Note that in our formulation of the stepped means test for the PAC approaches,  is both the dierence
in the expected mean of successive hypotheses and the indierence interval of the algorithm. Thus, 
plays the roles of both problem parameter and control parameter here.
13. One confusing point is that for identical hypothesis and ranking algorithm settings, one can observe a
lower loss when ranking a larger number of hypotheses. This is because the algorithm rst divides the
loss over the number of pirwise comparisons. Thus, for the same overall error (or expected loss bound),
with more hypotheses, the pairwise expected error (or loss) will be smaller if there are more hypotheses.
The ranking loss is dened previously. Thus, it is possible for the observed loss to increase or decrease
compared to the same settings with fewer hypotheses.

386

Efficient Heuristic Hypothesis Ranking

k
3
3
3
3
3
3
5
5
5
5
5
5
10
10
10
10
10
10



0.75
0.75
0.90
0.90
0.95
0.95
0.75
0.75
0.90
0.90
0.95
0.95
0.75
0.75
0.90
0.90
0.95
0.95




2
3
2
3
2
3
2
3
2
3
2
3
2
3
2
3
2
3

TURNBULL
62 (0.88)
117 (0.89)
97 (0.96)
183 (0.99)
130 (0.97)
231 (0.96)
177 (0.83)
321 (0.95)
245 (0.98)
445 (0.98)
299 (0.98)
541 (0.98)
558 (0.92)
1,015 (0.94)
700 (0.97)
1,254 (0.97)
821 (1.00)
1,462 (0.99)

P ACrec

55 (0.95)
101 (0.86)
86 (0.94)
152 (0.96)
122 (0.97)
204 (0.95)
165 (0.95)
314 (0.93)
245 (0.97)
409 (0.91)
294 (0.98)
538 (0.98)
624 (0.91)
1,042 (0.95)
742 (0.96)
1,359 (0.97)
877 (0.97)
1,569 (0.98)

P ACadj

38 (0.78)
49 (0.80)
58 (0.92)
96 (0.89)
89 (0.97)
146 (0.94)
105 (0.87)
161 (0.75)
163 (0.91)
290 (0.92)
216 (1.00)
377 (0.92)
345 (0.85)
635 (0.83)
523 (0.91)
883 (0.90)
661 (0.94)
1,164 (0.93)

Table 1: Estimated expected total number of observations by PAC algorithms in the
stepped means conguration. Achieved probability of correct ranking is shown
in parenthesis.

Parameters
k  H
3 2 1.0
3 2 0.75
3 2 0.5
3 2 0.25
5 2 1.0
5 2 0.75
5 2 0.5
5 2 0.25
10 2 1.0
10 2 0.75
10 2 0.5
10 2 0.25

ELrec

Samples
96
102
139
235
320
343
464
575
1,136
1,325
1,533
1,856

Loss
0.6
0.5
0.2
0.1
0.7
0.4
0.4
0.2
0.5
0.5
0.3
0.1

ELadj

Samples
43
56
73
139
140
169
247
350
572
668
872
1,153

Loss
1.2
1.0
0.6
0.4
1.3
1.2
0.7
0.5
1.4
1.1
0.7
0.4

Table 2: Estimated expected total number of observations of EL algorithms in stepped
means conguration. Observed average loss of produced rankings.

387

Chien, Stechert, & Mutz
because, unlike the synthetic problems, the cost of sampling a hypothesis is not constant in
these domains. Table 3 gives a summary of the three ranking problems we considered.
Dataset
DS-2 Penetrator

xed parameters
penetrator diameter
penetrator length

DS-2 Aeroshell

fore body overlap
nose cone angle
bluntness ratio
llet radius
outer diameter
tail geometry
compression method

Lossless Image Comp.

random variables
impact orientation
impact velocity
soil density
stagnation pressure coef.

optimization criteria
maximize penetration probability
maximize penetration depth

randomly selected test image

maximize compression ratio

minimize weight
achieve target entry velocity

Table 3: Description of datasets used for algorithm evaluation.

3.2.1 DS-2 Penetrator

The goal of the New Millennium Deep Space Two (DS-2) mission is to deliver a pair of
microprobes to the planet Mars for scientic study of the Martian soil. The probes will
be released from orbit, travel through the Martian atmosphere, and embed themselves in
the soil near the southern polar ice cap. The primary science objectives for the mission are
(Balacuit., 1997):





to determine if ice is present below the surface of Mars,
to measure the local atmospheric pressure,
and to characterize the thermal properties of the Martian subsurface soil.

The goal of this spacecraft design problem is to determine a good set of physical dimensions for the penetrator|a small, robust probe designed to impact the surface at extremely
high velocity and to operate in the extreme cold. Specically, we use design and simulation
data from the DS-2 mission penetrator design.
For our casting of the design problem, we hold the shape of the penetrator constant and
generate design candidates based on dierent values for the variables of penetrator diameter
and length. For a specic design a sample is taken by acquiring impact orientation, impact
velocity, and soil density from a parameterized multivariate distribution and then calling a
complex physical simulation to determine if and to what depth the penetrator bored into
the Martian surface. The goal of the penetrator design problem is to determine the physical
dimensions of the penetrator that maximize the probability of penetration, and in cases of
penetration, maximize penetration depth.
Tables 4 and 5 show the results of applying the PAC-based, Turnbull, and expected loss
algorithms to a ranking problem in which the system is requested to rank 10 penetrator
designs.14 In this problem the utility function is the depth of penetration of the penetrator,
14. \True" expected utility values were computed by performing 20,000 samples and using the sample mean
for this large sample as ground truth. These expected utilities were then used to compute PAC -validity
of rankings and observed loss using the provided denitions.

388

Efficient Heuristic Hypothesis Ranking
with those cases in which the penetrator does not penetrate being assigned zero utility. As
shown in Table 4, both PAC algorithms signicantly outperformed the Turnbull algorithm,
which is to be expected because the hypotheses are somewhat correlated (via impact orientations and soil densities). Table 5 shows that the ELrec expected loss algorithm eectively
bounded actual loss but the ELadj algorithm was inconsistent.
k
10
10
10



0.75
0.90
0.95




2
2
2

TURNBULL
534 (0.96)
667 (0.98)
793 (0.99)

P ACrec

144 (1.00)
160 (1.00)
177 (1.00)

P ACadj

92 (0.98)
98 (1.00)
103 (0.99)

Table 4: Estimated expected total number of observations to rank DS-2 spacecraft designs.
Achieved probability of correct ranking is shown in parenthesis.

Parameters
k
H
10
0.10
10
0.05
10
0.02

ELrec

Samples
152
200
378

Loss
0.05
0.03
0.03

ELadj

Samples
77
90
139

Loss
0.14
0.06
0.03

Table 5: Estimated expected total number of observations and expected loss of an incorrect
ranking of DS-2 penetrator designs.

3.2.2 DS-2 Aeroshell Design Ranking

The objective of this problem is to design an aeroshell for the soil penetrator described in
the previous section that gives the appropriate entry velocity with minimum weight. Design
candidates are dened by six continuous variables that represent various geometric quantities: the extent to which the fore body overlaps the aftbody, nose cone angle, bluntness
ratio, llet radius, outer diameter, and the tail geometry. Candidate designs (hypotheses)
are evaluated by running a simple physical simulation of the aeroshell's behavior. Such a
sample is taken by running the simulation with the xed design variables of the hypothesis
and a value for the stagnation pressure coeÆcient taken from a normal distribution. The
simulation computes values for the achieved entry velocity and the mass of the aeroshell;
then the weighted sum of the reciprocals of these values is maximized.
We give the results of ranking three, ve, and ten hypotheses using the Turnbull, PAC,
and expected loss algorithms in Tables 6 and 7.15
As in the previous experiment, the PAC-based algorithms outperformed the Turnbull
algorithm in all cases. While the P ACadj algorithm represents a signicant increase in
15. Again, deep sampling (500 samples) was performed to obtain the \correct" ranking, against which these
algorithms are compared.

389

Chien, Stechert, & Mutz
performance here, we note that it did not achieve the desired level of condence in all cases;
both the Turnbull and P ACrec algorithms did achieve the required condence.

k
3
3
3
3
3
3
5
5
5
5
5
5
10
10
10
10
10
10



0.75
0.75
0.90
0.90
0.95
0.95
0.75
0.75
0.90
0.90
0.95
0.95
0.75
0.75
0.90
0.90
0.95
0.95




2
3
2
3
2
3
2
3
2
3
2
3
2
3
2
3
2
3

TURNBULL
8.9 (1.00)
22.9 (1.00)
17.1 (1.00)
38.2 (1.00)
22.6 (1.00)
52.0 (1.00)
29.1 (0.92)
69.0 (1.00)
42.4 (0.99)
94.7 (0.99)
51.9 (0.98)
117.9 (0.99)
84.0 (0.99)
196.6 (1.00)
112.0 (0.98)
252.9 (0.99)
129.1 (1.00)
315.7 (1.00)

P ACrec

8.4 (1.00)
11.3 (1.00)
14.0 (1.00)
18.6 (1.00)
21.6 (1.00)
32.1 (1.00)
20.1 (0.94)
33.9 (0.96)
30.0 (0.93)
54.8 (0.96)
43.6 (1.00)
81.5 (0.99)
42.0 (0.94)
57.9 (0.96)
53.8 (0.98)
85.5 (1.00)
61.3 (0.97)
125.7 (1.00)

P ACadj

3.5 (1.00)
3.8 (1.00)
7.1 (1.00)
7.2 (1.00)
7.1 (1.00)
7.3 (1.00)
11.8 (0.91)
11.7 (0.91)
11.7 (0.91)
11.8 (0.84)
11.7 (0.91)
11.5 (0.92)
22.1 (0.92)
22.1 (0.90)
22.6 (0.89)
21.6 (0.91)
20.6 (0.90)
20.4 (0.92)

Table 6: Estimated expected cost (in seconds) to rank aeroshell designs. Achieved probability of correct ranking is shown in parenthesis.

Parameters
k
H
3
20
3
30
3
40
5
20
5
30
5
40
10
20
10
30
10
40

ELrec

Execution Cost
9.5
7.6
7.3
21.7
18.1
15.0
55.3
42.6
38.2

Loss
4.3
3.4
4.1
7.0
12.0
9.3
9.7
8.9
10.4

ELadj

Execution Cost
7.9
7.3
6.9
7.2
6.4
10.5
18.3
14.2
13.1

Loss
3.4
3.7
2.7
8.6
12.4
8.5
7.9
9.8
9.6

Table 7: Estimated expected cost (in seconds) and expected loss of an incorrect ranking of
DS-2 aeroshell designs.

390

Efficient Heuristic Hypothesis Ranking
3.2.3 Lossless Image Compression on Galileo Image Data

This problem utilizes a large set of raw image data acquired by the Galileo spacecraft. Each
of the images is 256 by 256 in size and is made up of greyscale pixels ranging from 0 to 255 in
intensity. The goal is to select the lossless compression method16 that performs best on this
class of images. The performance of an image compression algorithm on a particular image
could be measured in a number of ways. For example, execution time, compression ratio,
and image quality (in the case where lossy compression methods are being considered) could
dene algorithm performance. In our tests we chose to consider only the compression ratio
achieved by a given compression method as our utility function. To sample each method
(hypothesis), an image is randomly selected, the method is applied to that image, and the
achieved compression ratio is recorded.
Given below (Tables 8 and 9) are the results of ranking three, ve, and seven hypotheses
using the Turnbull, PAC, and expected loss algorithms. Ranking correctness was determined
by comparison to a \correct" ranking established by sampling each compression method on
a set of 1500 distinct images.
We again note the substantial performance improvement the PAC-based algorithms
have over the Turnbull algorithm. Although both the Turnbull algorithm and the PAC
algorithms (Table 8) achieved the desired condence level, the adjacent version of the EL
algorithm (Table 9) failed to bound the loss to the specied level in over half the cases.
It is interesting to consider the results presented in this section in light of the fact that
each of the statistical techniques being used makes some form of normality assumption. In
fact, all three of the problem domains we investigate have some number of hypotheses whose
utility functions are not normally distributed. From past experience it is known that utility
functions in the DS-2 Penetrator domain (Section 3.2.1) are highly non-normal; Figure 4
illustrates the dierence between data that is normally distributed and data that is not.
0.08

0.12

0.07
0.1
0.06
0.08
0.05

0.04

0.06

0.03
0.04
0.02
0.02
0.01

0
0.2

0
0.3

0.4

0.5

0.6

0.7

0.8

0

50

100

150

200

250

300

350

400

450

500

Figure 4: A comparison of (a) data that is normally distributed with high likelihood and (b)
data that is very likely not normally distributed. In each case, the histogram of
experimental data is shown in solid boxes; data drawn from a normal distribution
with the same mean and standard deviation is shown with dashed lines.
To determine the extent to which the utilities of hypotheses in the remaining two domains are normally distributed we applied the Kolmogorov-Smirnov test (see Appendix A
16. The seven compression methods we considered were: CALIC, lossless JPEG, GIF, TIFF, pack, gzip, and
compress.

391

Chien, Stechert, & Mutz

k
3
3
3
3
3
3
5
5
5
5
5
5
7
7
7
7
7
7



0.90
0.90
0.95
0.95
0.99
0.99
0.90
0.90
0.95
0.95
0.99
0.99
0.90
0.90
0.95
0.95
0.99
0.99




2
3
2
3
2
3
2
3
2
3
2
3
2
3
2
3
2
3

TURNBULL
62.8 (1.00)
150.8 (1.00)
84.6 (1.00)
206.8 (1.00)
142.0 (1.00)
359.4 (1.00)
134.7 (1.00)
329.9 (1.00)
176.1 (1.00)
399.8 (1.00)
249.3 (1.00)
598.1 (1.00)
210.8 (1.00)
499.3 (1.00)
250.3 (1.00)
608.7 (1.00)
339.6 (1.00)
813.7 (1.00)

P ACrec

30.1 (1.00)
30.5 (1.00)
28.6 (1.00)
29.0 (1.00)
30.1 (1.00)
30.6 (1.00)
39.5 (1.00)
39.9 (1.00)
39.3 (1.00)
39.3 (1.00)
39.2 (1.00)
39.2 (1.00)
35.6 (1.00)
35.7 (1.00)
37.4 (1.00)
36.0 (1.00)
36.5 (1.00)
37.2 (1.00)

P ACadj

14.8 (1.00)
14.8 (1.00)
15.0 (1.00)
20.5 (1.00)
23.3 (1.00)
23.2 (1.00)
29.9 (1.00)
30.0 (1.00)
29.8 (1.00)
29.6 (1.00)
29.9 (1.00)
30.7 (1.00)
37.2 (1.00)
34.5 (1.00)
35.6 (1.00)
35.0 (1.00)
34.5 (1.00)
35.3 (1.00)

Table 8: Estimated expected cost (in seconds) to rank lossless image compression approaches on Galileo image data. Achieved probability of correct ranking is shown
in parenthesis.

Parameters
k
H
3
10
3
5
3
1
5
10
5
5
5
1
7
10
7
5
7
1

ELrec

Execution Cost
31.7
32.5
33.7
80.6
83.5
101.0
99.5
105.7
119.8

Loss
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0

ELadj

Execution Cost
24.9
24.9
24.9
32.7
33.7
32.3
42.3
33.3
30.4

Loss
0.0
0.0
0.0
17.4
69.4
49.4
17.4
34.7
86.8

Table 9: Estimated expected cost (in seconds) and expected loss of an incorrect ranking of
DS-2 penetrator designs.

392

Efficient Heuristic Hypothesis Ranking
for details). The test determined that none of the ten hypotheses from the DS-2 Aeroshell
domain (Section 3.2.2) had normally distributed utility. Additionally, only two of the seven
hypotheses from the image compression domain (Section 3.2.3) were shown to have greater
than 90% likelihood of having normally distributed utility functions17. For these reasons,
evaluating the ranking strategies on these datasets provides a particularly strong test of the
applicability of the techniques.
We draw the reader's attention to the particularly large disparity in performance between
the Turnbull algorithm and the PAC-based algorithms in the image compression domain,
especially apparent when the number of hypotheses, and the condence level, are high.
Additionally, this problem domain has two hypotheses with normally distributed utility
and ve that are non-normal. These observations suggest that the PAC-based algorithms
perform better (in relative terms) when faced with a domain that violates the assumption
of normality.
4. Discussion and Conclusions

There are a number of areas of related work. First, there has been considerable analysis of
hypothesis selection problems. Selection problems have been formalized using a Bayesian
framework (Moore & Lee, 1994; Rivest & Sloan, 1988) that does not require an initial
sample, but uses a rigorous encoding of prior knowledge. Howard (Howard, 1970) also
details a Bayesian framework for analyzing learning cost for selection problems. If one
uses a hypothesis selection framework for ranking, allocation of pairwise errors can be
performed rationally (Gratch et al., 1994). Reinforcement learning work (Kaelbling, 1993)
with immediate feedback can also be viewed as a hypothesis selection problem.
The framework presented invites future work in a number of directions. Currently, the
stopping criteria used are relaxations of the ranking requirement. Another approach that
could be used is to bound the resources available for ranking. Limiting the number of
samples where sample cost is high and limiting the time of computation (so that we have
an anytime algorithm) are two straightforward application areas.
Another area for future work is discovery of composite strategies or hypotheses. Thus
far we have examined ranking (and in other articles, selection) of a hypothesis with highest expected value over an entire distribution. For example, learning a scheduling control
strategy that will do well over a distribution of problems. However, it is likely that for
most distributions of problems, there exists a composite strategy which would outperform
any single strategy. For example, a single strategy might be to apply method A to solve
a problem. A composite strategy would be, test the problem for feature X, if X true apply method A, else apply method B. These composite strategies correspond to algorithm
portfolios as named in Operations Research. Indeed the results of applying methods could
also be viewed as strategies. One might have the composite strategy of trying method A
for 10 CPU seconds, then if that fails trying method B. Of course, in all these composition and portfolio approaches, the diÆculty iseÆciently proposing and evaluating plausible
compositions. For even a small set of base strategies the number of copositions is enormous.
17. For reference, the data in Figure 4 (a) was normally distributed with 97.5% likelihood, according to the
Kolmogorov-Smirnov test.

393

Chien, Stechert, & Mutz
In summary, this paper has described the hypothesis ranking problem, an extension to
the hypothesis selection problem. We dened the application of two decision criteria, probably approximately correct and expected loss, to this problem. We then dened two families of
algorithms, recursive selection and adjacency, for solution of hypothesis ranking problems.
Finally, we demonstrated the eectiveness of these algorithms on both synthetic and realworld datasets, documenting improved performance over existing statistical approaches.
Acknowledgments

This work was performed by the Jet Propulsion Laboratory, California Institute of Technology, under contract with the National Aeronautics and Space Administration.
Appendix A. Applying the K-S Test to Real Datasets

The Kolmogorov-Smirnov Test is a statistical means of accepting, with a certain level of
condence, the hypothesis that some sampleset ts a parametric distribution with a given
set of parameters. The method compares the CDF generated by the empirical distribution
to that of the corresponding parametric distribution (i.e., with estimated parameters). The
K-S test gives a condence based on the maximum, D, of the discrepancies between these
two CDFs:
D = maxjF1 (x)

F2 (x)j

For our purposes we wish to determine, for each hypothesis in a given domain, whether
the values of the utility function are normally distributed or not. In each case, half of the
utility samples taken are used to compute the mean and standard deviation of the normal;
the remaining half are used to compute the CDF.
A.1 DS-2 Penetrator

20000 samples taken.
design number
1
2
3
4
5
6
7
8
9
10

maxjF1 (x)

F2 (x)j
0.1415
0.1202
0.1020
0.1261
0.1207
0.1261
0.1020
0.1493
0.1461
0.1261

394

normally distributed?
 90% likely
 90% likely
 90% likely
 90% likely
 90% likely
 90% likely
 90% likely
 90% likely
 90% likely
 90% likely

Efficient Heuristic Hypothesis Ranking
A.2 DS-2 Aeroshell Design Ranking

500 samples taken.
design number
1
2
3
4
5
6
7
8
9
10

maxjF1 (x)

F2 (x)j

0.08
0.08
0.08
0.08
0.08
0.08
0.08
0.08
0.08
0.08

normally distributed?
< 90% likely
< 90% likely
< 90% likely
< 90% likely
< 90% likely
< 90% likely
< 90% likely
< 90% likely
< 90% likely
< 90% likely

A.3 Lossless Image Compression on Galileo Image Data

200 samples taken.
compression method
gif
compress
calic
gzip
jpegls
pack
ti

maxjF1 (x)

F2 (x)j

0.10
0.14
0.19
0.09
0.18
0.12
0.11

normally distributed?
90% likely
< 90% likely
 90% likely
97.5% likely
 90% likely
< 90% likely
< 90% likely

References

Balacuit., C. P. (1997). Deep Space 2 { Mars Microprobe Home Page (mission objectives
statement). Tech. rep. http://nmp.jpl.nasa.gov/ds2, NASA/JPL.
Chien, S. A., Gratch, J. M., & Burl, M. C. (1995). On the EÆcient Allocation of Resources
for Hypothesis Evaluation: A Statistical Approach. IEEE Trans. Pattern Analysis
and Machine Intelligence, 17 (7), 652{665.
Chien, S. A., Stechert, A. D., & Mutz, D. H. (1998). EÆcient Heuristic Ranking of Hypotheses. In Advances in Neural Information Processing Systems 10 (Jordan, Kearns,
and Solla eds.), pp. 444{450 Denver, Colorado. NIPS.
Ginsberg, M., & Harvey, W. (1992). Iterative Broadening. Articial Intelligence Journal,
55, 367{383.
395

Chien, Stechert, & Mutz
Goldberg, D. (1989). Genetic Algorithms in Search, Optimization, and Machine Learning.
Addison-Wesley.
Gratch, J. (1992). COMPOSER: A Probabilistic Solution to the Utility Problem in Speed-up
Learning. In Proceedings of the Tenth National Conference on Articial Intelligence,
pp. 235{240 San Jose, CA. AAAI.
Gratch, J. (1993). COMPOSER: A Decision-theoretic Approach to Adaptive Problem Solving. Tech. rep. UIUCDCS-R-93-1806, Department of Computer Science, University of
Illinois.
Gratch, J., Chien, S., & DeJong, G. (1994). Improving Learning Performance Through
Rational Resource Allocation. In Proceedings of the Twelfth National Conference on
Articial Intelligence, pp. 576{582 Seattle, WA. AAAI.
Greiner, R., & Jurisica, I. (1992). A Statistical Approach to Solving the EBL Utility
Problem. In Proceedings of the Tenth National Conference on Articial Intelligence,
pp. 241{248 San Jose, CA. AAAI.
Haseeb, R. M. (1985). Modern Statistical Selection. American Sciences Press, Columbus,
OH.
Howard, R. A. (1970). Decision Analysis: Perspectives on Inference, Decision, and Experimentation. Proceedings of the IEEE, 58 (5), 823{834.
Kaelbling, L. P. (1993). Learning in Embedded Systems. MIT Press, Cambridge, MA.
Minton, S. (1988). Learning Search Control Knowledge: An Explanation-Based Approach.
Kluwer Academic Publishers, Norwell, MA.
Moore, A. W., & Lee, M. S. (1994). EÆcient Algorithms for Minimizing Cross-Validation
Error. In Proceedings of the International Conference on Machine Learning New
Brunswick, MA.
Musick, R., Catlett, J., & Russell, S. (1993). Decision Theoretic Subsampling for Induction on Large Databases. In Proceedings of the International Conference on Machine
Learning, pp. 212{219 Amherst, MA.
Rivest, R. L., & Sloan, R. (1988). A New Model for Inductive Inference. In Proceedings of
the Second Conference on Theoretical Aspects of Reasoning about Knowledge.
Russell, S., & Wefald, E. (1992). Do the Right Thing: Studies in Limited Rationality. MIT
Press, Cambridge, MA.
Tadepalli, P. (1992). A theory of unsupervised speedup learning. In Proc. of the Tenth
National Conference on Articial Intelligence, pp. 229{234 San Jose, CA. AAAI.
Turnbull, B. W., & Weiss, L. I. (1984). A Class of Sequential Procedures for k-sample
Problems Concerning Normal Means with Unknown Equal Variances. In Santner,
T. J., & Tamhane, A. C. (Eds.), Design of Experiments: Ranking and Selection, pp.
225{240. Marcel Dekker.
396

Efficient Heuristic Hypothesis Ranking
Valiant, L. G. (1984). A Theory of the Learnable. Communications of the ACM, 27,
1134{1142.

397

Journal of Articial Intelligence Research 10 (1999) 1-38

Submitted 4/98; published 1/99

Order of Magnitude Comparisons of Distance
Ernest Davis

davise@cs.nyu.edu

Courant Institute
New York, NY 10012 USA

Abstract
Order of magnitude reasoning | reasoning by rough comparisons of the sizes of quantities | is often called \back of the envelope calculation", with the implication that the
calculations are quick though approximate. This paper exhibits an interesting class of constraint sets in which order of magnitude reasoning is demonstrably fast. Specically, we
present a polynomial-time algorithm that can solve a set of constraints of the form \Points
a and b are much closer together than points c and d." We prove that this algorithm can be
applied if \much closer together" is interpreted either as referring to an innite dierence in
scale or as referring to a nite dierence in scale, as long as the dierence in scale is greater
than the number of variables in the constraint set. We also prove that the rst-order theory
over such constraints is decidable.
1. Introduction
Order of magnitude reasoning | reasoning by rough comparisons of the sizes of quantities |
is often called \back of the envelope calculation", with the implication that the calculations
are quick though approximate. Previous AI work on order of magnitude reasoning, however,
has focussed on its expressive power and inferential structure, not on its computational
leverage (Raiman, 1990; Mavrovouniotis and Stephanopoulos, 1990; Davis, 1990; Weld,
1990).
In this paper we exhibit an interesting case where solving a set of order of magnitude
comparisons is demonstrably much faster than solving the analogous set of simple order
comparisons. Specically, given a set of constraints of the form \Points a and b are much
closer together than points c and d," the consistency of such a set can be determined in
low-order polynomial time. By contrast, it is easily shown that solving a set of constraints
of the form \The distance from a to b is less than or equal to the distance from c to d" in
one dimension is NP-complete, and in higher dimensions is as hard as solving an arbitrary
set of algebraic constraints over the reals.
In particular, the paper presents the following results:
1. The algorithm \solve constraints(S )" solves a system of constraints of the form \Points
a and b are innitely closer than points c and d" in polynomial time (Section 5).
2. An improved version of the algorithm runs in time O(max(n2 (n)); ne; s) where n is
the number of variables, (n) is the inverse Ackermann's function, e is the number of
edges mentioned in the constraint set, and s is the size of the constraint set. (Section
6.1).
3. An extended version of the algorithm allows the inclusion of non-strict constraints of
the form \Points a and b are not innitely further apart than points c and d." The
c 1999 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

Davis

running time for this modied algorithm is slower than that of solve constraints, but
still polynomial time. (Section 6.2)
4. A dierent extension of the algorithm allows the combination of order of magnitude
constraints on distances with order comparisons on the points of the form \Point a
precedes point b." (Section 6.3)
5. The same algorithm can be applied to constraints of the form \The distance from a
to b is less than 1=B times the distance from c to d," where B is a given nite value,
as long as B is greater than the number of variables in the constraint set. (Section 7)
6. The rst-order theory over such constraints is decidable. (Section 8)
As preliminary steps, we begin with a small example and an informal discussion (Section
2). We then give a formal account of order-of-magnitude spaces (Section 3) and present
a data structure called a cluster tree, which expresses order-of-magnitude distance comparisons (Section 4). We conclude the paper with a discussion of the signicance of these
results (Section 9).

2. Examples
Consider the following inferences:

Example 1: I wish to buy a house and rent oÆce space in a suburb of Metropolis. For
obvious reasons, I want the house to be close to the school, the house to be close to the
oÆce, and the oÆce to be close to the commuter train station. I am told that in Elmville
the train station is quite far from the school, but in Newton they are close together.
Infer that I will not be able to satisfy my constraints in Elmville, but may be able to
in Newton.
Example 2: The Empire State Building is much closer to the Washington Monument than
to Versailles. The Statue of Liberty is much closer both to the Empire State Building and
to Carnegie Hall than to the Washington Monument.
Infer that Carnegie Hall is much closer to the Empire State Building than to Versailles.
Example 3: You have to carry out a collection of computational tasks covering a wide
range of diÆculty. For instance
a.
b.
c.
d.
e.
f.

Add up a column of 100 numbers.
Sort a list of 10,000 elements.
Invert a 100  100 matrix.
Invert a 1000  1000 matrix.
Given the O.D.E. x = cos(et x), x(0) = 0, nd x(20) to 32-bit accuracy.
Given a online collection of 1,000 photographs in GIF format, use state-ofthe-art image recognition software to select all those that show a man on
horseback.

2

Order of Magnitude Comparisons of Distance

g. Do a Web search until you have collected 100 pictures of men on horseback,
using state-of-the-art image recognition software.
h. Using state-of-the-art theorem proving software, nd a proof that the medians of a triangle are concurrent.
i. Using state-of-the-art theorem proving software, nd a proof of Fermat's
little theorem.
It is plausible to suppose that, in many of these cases, you can say reliably that one
task will take much longer than another, either by a human judgment or using an expert
system. For instance, task (a) is much shorter than any of the others. Task (b) is much
shorter than any of the others except (a) and possibly (h). Task (c) is certainly much
shorter than (d), (f), (g), or (i). However, with certain pairs such as (c) and (h) or (c) and
(e) it would be diÆcult to guess whether one is much shorter than another, or whether they
are of comparable diÆculty.
You have a number of independent identical computers, of unknown vintage and characteristics, on which you will schedule tasks of these kinds. Note that, under these circumstances, there is no way to predict the absolute time required by any of these tasks within a
couple of orders of magnitude. Nonetheless, the comparative lengths presumably still stand.
Given: a particular schedule of tasks on machines, infer what you can about the relative
order of completion times. For example, given the following schedule
Machine M1: tasks a,b,h,d.
Machine M2: tasks c,i.
it should be possible to predict that (a) and (b) will complete before (c); that (c) will
complete before (d); and that (d) will complete before (i); but it will not be possible to
predict the order in which (c) and (h) will complete.
In all three examples, the given information has the form \The distance between points
W and X is much less than the distance between Y and Z ". In examples 1 and 2, the
points are geometric. In example 3, the points are the start and completion times of the
various tasks, and the constraints on relative lengths can be put in the form \The distance
from start(a) to end(a) is much less than the distance from start(c) to end(c)", and so on.
In example 3, there is also ordering information: the start of each task precedes its end; the
end of (a) is equal to the start of (b); and so on. The problem is to make inferences based
on this weak kind of constraint.
It should be noted that these examples are meant to be illustrative, rather than serious applications. Example 1 does not extend in any obvious way to a class of natural,
large problems. Example 2 is implausible as a state of knowledge; how does the reasoner
nd himself knowing just the order-of-magnitude relations among distances and no other
geometric information? Example 3 is contrived. Nonetheless, these illustrate the kinds of
situations where order-of-magnitude relations on distance do arise; where they express a
substantial part of the knowledge of the reasoner; and where inferences based purely on the
order-of-magnitude comparisons can yield useful conclusions.
The methods presented in this paper involve construing the relation \Distance D is much
shorter than distance E" as if it were \Distance D is innitesimal as compared to distance
E." As we shall see, under this interpretation, systems of constraints over distances can be

3

Davis

solved eÆciently. The logical foundations for dealing with innitesimal quantities lie in the
non-standard model of the real line with innitesimals, developed by Abraham Robinson
(1965). (A more readable account is given by Keisler, 1976.) Reasoning with quantities of
innitely dierent scale is known as \order of magnitude" reasoning.
The reader may ask, \Since innitesimals have no physical reality, what is the value
of developing techniques for reasoning about them?" In none of the examples, after all, is
the smaller quantity truly innitesimal or the larger one truly innite. In example 1 and
2, the ratio between successive sizes is somewhere between 10 and 100; in example 3, it
is between 100 and a rather large number diÆcult to estimate; but one can always give
some kind of upper bound. It is essentially certain, for instance, that the ratio between the
times required for tasks (a) and (i) is less than 10100;000 . Why not use the best real-valued
estimate instead?
The rst answer is that this is an idealization. Practically all physical reasoning and
calculation rest on one idealization or another: the idealization in the situation calculus
that time is discrete; the idealization that solid objects are rigid, employed in most mechanics programs; the idealization that such physical properties as density, temperature, and
pressure are continuous rather than local averages over atoms, which underlies most uses of
partial dierential equations; the idealization involved in the use of the Dirac delta function;
and so on. Our idealization here that a very short distance is innitesimally smaller than a
long one simplies reasoning and yields useful results as long as care is taken to stay within
an appropriate range of application.
The second answer is that this is a technique of mathematical approximation, which we
are using to turn an intractable problem into a tractable one. This would be analogous to
linearizing a non-linear equation over a small neighborhood; or to approximating a sum by
an integral.
There are circumstances where we can be sure that the approximation gives an answer
that is guaranteed exactly correct; namely if the actual ratio implicit in the comparison
\D is much smaller than E " is larger than the number of points involved in the system of
constraints. This will be proven in Section 7. There is also a broader, less well-dened, class
of problems where the approximation, though not guaranteed correct, is more reliable than
some of the other links in the reasoning. For instance, suppose that one were to consider
an instance of example 3 involving a couple of hundred tasks, apply order-of-magnitude
reasoning, and come up with an answer that can be determined to be wrong. It is possible
that the error would be due to the order-of-magnitude reasoning. However, it seems safe
to say that, in most cases, the error is more likely to be due to a mistake in estimating the
comparative sizes.

3. Order-of-magnitude spaces
An order-of-magnitude space, or om-space, is a space of geometric points. Any two points
are separated by a distance. Two distances d and e are compared by the relation d  e,
meaning \Distance d is innitesimal compared to e" or, more loosely, \Distance d is much
smaller than e."
For example, let < be the non-standard real line with innitesimals. Let <m be the
corresponding m-dimensional space. Then we can let a point of the om-space be a point in

4

Order of Magnitude Comparisons of Distance

Rm . The distance between two points a; b is the Euclidean distance, which is a non-negative
value in < . The relation d  e holds for two distances d; e, if d=e is innitesimal.
The distance operator and the comparator are related by a number of axioms, specied
below. The most interesting of these is called the om-triangle inequality: If ab and bc are
both much smaller than xy, then ac is much smaller than xy. This combines the ordinary
triangle inequality \The distance ac is less than or equal to distance ab plus distance bc"
together with the rule from order-of-magnitude algebra, \If p  r and q  r then p+q  r."
It will simplify the exposition below if, rather than talking about distances, we talk about
orders of magnitude. These are dened as follows. We say that two distances d and e have
the same order of magnitude if neither d  e nor e  d. In < this is the condition that d=e
is nite: neither innitesimal nor innite. (Raiman, 1990 uses the notation \d Co e" for this
relation.) By the rules of the order-of-magnitude calculus, this is an equivalence relation.
Hence we can dene an order of magnitude to be an equivalence class of distances under
the relation \same order of magnitude". For two points a; b, we dene the function od(a; b)
to be the order of magnitude of the distance from a to b. For two orders of magnitude p; q,
we dene p  q if, for any representatives d 2 p and e 2 q, d  e. By the rules of the orderof-magnitude calculus, if this holds for any representatives, it holds for all representatives.
The advantage of using orders-of-magnitude and the function \od", rather than distances
and the distance function, is that it allows us to deal with logical equality rather than the
equivalence relation \same order of magnitude".
For example, in the non-standard real line, let Æ be a positive innitesimal value. Then
values such as f1; 100; 2 50Æ + 100Æ2 : : :g, are all of the same order of magnitude, o1. The
values fÆ; 1:001Æ; 3Æ + e 1=Æ : : :g are of a dierent order of magnitude o2  o1. The values
f1=Æ; 10=Æ + Æ5 : : :g are of a third order of magnitude o3  o1.
Denition 1: An order-of-magnitude space (om-space) 
 consists of:







A set of points P ;
A set of orders of magnitude D;
A distinguished value 0 2 D;
A function \od(a; b)" mapping two points a; b 2 P to an order of magnitude;
A relation \d  e" over two orders of magnitude d; e 2 D

satisfying the following axioms:
A.1 For any orders of magnitude d; e
e  d, d = e.

2 D, exactly one of the following holds: d  e,

A.2 For d; e; f 2 D, if d  e and e  f then d  f .
(Transitivity. Together with A.1, this means that  is a total ordering on orders of
magnitude.)
A.3 For any d 2 D, not d  0.
(0 is the minimal order of magnitude.)

5

Davis

A.4 For points a; b 2 P , od(a; b) = 0 if and only if a = b.
(The function od is positive denite.)
A.5 For points a; b 2 P , od(a; b) = od(b; a).
(The function od is symmetric.)
A.6 For points a; b; c 2 P , and order of magnitude d 2 D,
if od(a; b)  d and od(b; c)  d then od(a; c)  d.
(The om-triangle inequality.)
A.7 There are innitely many dierent orders of magnitude.
A.8 For any point a1 2 P and order of magnitude d
a2 ; a3 : : : such that od(ai ; aj ) = d for all i 6= j .

2 D, there exists an innite set

The example we have given above of an om-space, non-standard Euclidean space, is wild
and woolly and hard to conceptualize. Here are two simpler examples of om-spaces:
I. Let Æ be an innitesimal value. We dene a point to be a polynomial in Æ with integer
coeÆcients, such as 3 + 5Æ 8Æ5 . We dene an order-of-magnitude to be a power of Æ. We
dene Æm  Æn if m > n; for example, Æ6  Æ4 . We dene od(a; b) to be the smallest power
of Æ in a b. For example, od(1 + Æ2 3Æ3 ; 1 5Æ2 + 4Æ4 ) = Æ2 .
II. Let N be an innite value. We dene a point to be a polynomial in N with integer
coeÆcients. We dene an order of magnitude to be a power of N . We dene N p  N q if
p < q; for example, N 4  N 6 . We dene od(a; b) to be the largest power of N in a b. For
example, od(1 + N 2 3N 3 ; 1 5N 2 + 4N 4 ) = N 4 .
It can be shown that any om-space either contains a subset isomorphic to (I) or a subset
isomorphic to (II). (This is just a special case of the general rule that any innite total
ordering contains either an innite descending chain or an innite ascending chain.)
We will use the notation \de" as an abbreviation for \d  e or d = e".

4. Cluster Trees
Let P be a nite set of points in an om-space. If the distances between dierent pairs of
points in P are of dierent orders of magnitude, then the om-space imposes a unique treelike hierarchical structure on P . The points will naturally fall into clusters, each cluster C
being a collection of points all of which are much closer to one another than to any point in
P outside C . The collection of all the clusters over P forms a strict tree under the subset
relation. Moreover, the structure of this tree and the comparative sizes of dierent clusters
in the tree captures all of the order-of-magnitude relations between any pair of points in P .
The tree of clusters is thus a very powerful data structure for reasoning about points in an
om-space, and it is, indeed, the central data structure for the algorithms we will develop in
this paper. In this section, we give a formal denition of cluster trees and prove some basic
results as foundations for our algorithms.

Denition 2: Let P be a nite set of points in an om-space. A non-empty subset C  P is
called a cluster of P if for every x; y 2 C , z 2 P C , od(x; y)  od(x; z ). If C is a cluster,
the diameter of C , denoted \odiam(C )", is the maximum value of od(x; y) for x; y 2 C .

6

Order of Magnitude Comparisons of Distance

n1
5
n2

n3

4

3

n4

n5

a

d

0

3

0

0

e

g

f

b

c

0

0

0

0

0

Figure 1: Cluster tree
Note that the set of any single element of P is trivially a cluster of P . The entire set P
is likewise a cluster of P . The empty set is by denition not a cluster of P .

Lemma 1: If C and D are clusters of P , then either C
disjoint.

 D, D  C , or C and D are

Proof: Suppose not. Then let x 2 C \ D, y 2 C D, z 2 D C . Since C is a cluster,
od(x; y)  od(x; z ). Since D is a cluster, od(x; z )  od(x; y). Thus we have a contradiction.

2

By virtue of lemma 1, the clusters of a set P form a tree. We now develop a representation of the order of magnitude relations in P by constructing a tree whose nodes correspond
to the clusters of P , labelled with an indication of the relative size of each cluster.

Denition 3: A cluster tree is a tree T such that

 Every leaf of T is a distinct symbol.
 Every internal node of T has at least two children.
 Each internal node of T is labelled with a non-negative value. Two or more nodes
may be given the same value. (For the purposes of Sections 5-7, labels may be taken
to be non-negative integers; in Section 8, it will be useful to allow rational labels.)

 Every leaf of the tree is labelled 0.
 The label of every internal node in the tree is less than the label of its parent.
For any node N of T , the eld \N .symbols" gives the set of symbols in the leaves in the
subtree of T rooted at N , and the eld \N .label" gives the integer label on node N .

7

Davis

Thus, for example, in Figure 1, n3.label=3 and n3.symbols = fa; dg; n1.label = 5 and
n1.symbols = fa; b; c; d; e; f; gg.
As we shall see, the nodes of the tree T represent the clusters of a set of points, and the
labels represent the relative sizes of the diameters of the clusters.

Denition 4: A valuation over a set of symbols is a function mapping each symbol to a
point in an om-space. If T is a cluster tree, a valuation over T is a valuation over T .symbols.
If N is any node in T and is a valuation over T , we will write (N ) as an abbreviation
for (N .symbols).
We now dene how a cluster tree T expresses the order of magnitude relations over a
set of points P .
Denition 5: Let T be a cluster tree and let be a valuation over T . Let P = (T ), the
set of points in the image of T under . We say that j=T (read satises or instantiates
T ) if the following conditions hold:
i. For any internal node N of T , (N ) is a cluster of P .
ii. For any cluster C of P , there is a node N such that C = (N ).
iii. For any nodes M and N , if M .label < N .label then odiam( (M ))  odiam( (N )).
iv. If label(M ) = 0, then odiam(M ) = 0. (That is, all children of M are assigned the
same value under .)
The following algorithm generates an instantiation
procedure

variable

given a cluster tree T :

instantiate(in T : cluster tree; 
 : an om-space)
return : array of points indexed on the symbols of T

G[N ] : array of points indexed on the nodes of T ;

Let k be the number of internal nodes in T ;
Choose Æ0 = 0  Æ1  Æ2  : : :  Æk to be k + 1 dierent orders of magnitude;
/* Such values can be chosen by virtue of axiom A.7 */
pick a point x 2 
;
G[root of T ] := x;
instantiate1(T; 
; Æ1 : : : Æk ; G);
return the restriction of G to the symbols of T .
end instantiate.
instantiate1(in N : a node in a cluster tree; 
 : an om-space; Æ1 : : : Æk : orders of magnitude;
in out G : array of points indexed on the nodes of T )
if N is not a leaf then
let C1 : : : Cp be the children of N ;
x1 := G[N ];
q := N .label;
pick points x2 : : : xp such that
for all i; j 2 1 : : : p, if i 6= j then od(xi ; xj ) = Æq ;
/* Such points can be chosen by virtue of axiom A.8 */
8

Order of Magnitude Comparisons of Distance

for

i = 1 : : : p do
G[Ci ] := xi ;

instantiate1(Ci ; 
; Æ1 : : : Æk ; G);

endfor
endif end

instantiate1.

Thus, we begin by picking orders of magnitude corresponding to the values of the labels.
We pick an arbitrary point for the root of the tree, and then recurse down the nodes of the
tree. For each node N , we place the children at points that all lie separated by the desired
diameter of N . The nal placement of the leaves is then the desired instantiation.
Lemma 2: If T is a cluster tree and 
 is an om-space, then instantiate(T; 
) returns an
instantiation of T .
The proof is given in the appendix.
Moreover, it is clear that any instantiation of T can be generated as a possible output
of instantiate(T; 
). (Given an instantiation , just pick G[N ] at each stage to be of some
symbol of N .)
Note that, given any valuation over a nite set of symbols S , there exists a cluster
tree T such that T .symbols = S and satises T . Such a T is essentially unique up to an
isomorphism over the set of labels that preserves the label 0 and the order of labels.

5. Constraints
In this section, we develop the rst of our algorithms. Algorithm solve constraints tests
a collection of constraints of the form \a is much closer to b than c is to d," for consistency. If the set is consistent, then the algorithm returns a cluster tree that satises the
constraints. The algorithm builds the cluster tree from top to bottom dealing rst with the
large distances, and then proceeding to smaller and smaller distances.
Let S be a system of constraints of the form od(a; b)  od(c; d); and let T be a cluster
tree. We will say that T `S (read \T satises S ") if every instantiation of T satises S . In
this section, we develop an algorithm for nding a cluster tree that satises a given set of
constraints.
The algorithm works along the following lines: Suppose we have a solution satisfying S .
Let D be the diameter of the solution. If S contains a constraint od(a; b)  od(c; d) then,
since od(c; d) is certainly no more than D, it follows that od(a; b) is much smaller than D.
We label ab as a \short" edge.
If two points u and v are connected by a path of short edges, then by the triangle
inequality the edge uv is also short (i.e. much shorter than D). Thus, if we compute the
connected components H of all the edges that have been labelled short, then all these edges
in H can likewise be labelled short. For example, in table 3, edges vz , wx, and xy can all
be labelled \short".
On the other hand, as we shall prove below, if an edge is not in the set H , then there is
no reason to believe that it is much shorter than D. We can, in fact, safely posit that it is
the same o.m. as D. We label all such edges \long".
We can now assume that any connected component of points connected by short edges
is a cluster, and a child of the root of the cluster tree. The root of the cluster tree is then
given the largest label. Its children will be given smaller labels. Each \long" edge now

9

Davis

connects symbols in two dierent children of the root. Hence, any instantiation of the tree
will make any long edge longer than any short edge.
If no edges are labelled \long" | that is, if H contains the complete graph over the
symbols | then there is an inconsistency; all edges are much shorter than the longest edge.
For instance, in table 4, since vw, wx, and xy are all much smaller than zy, it follows
by the triangle inequality that vy is much smaller than zy. But since we also have the
constraints that zy is much smaller than vz and that vz is much smaller than vy, we have
an inconsistency.
The algorithm then iterates, at the next smaller scale. Since we have now taken care of
all the constraints od(a; b)  od(c; d), where cd was labelled \long", we can drop all those
from S . Let D now be the greatest length of all the edges that remain in S . If a constraint
od(a; b)  od(c; d) is in the new S , then we know that od(a; b) is much shorter than D, and
we label it \short". We continue as above. The algorithm halts when all the constraints in
S have been satised, and S is therefore empty; or when we encounter a contradiction, as
above.
We now give the formal statement of this algorithm. The algorithm uses an undirected
graph over the variable symbols in S . Given such a graph G, and a constraint C of the
form od(a; b)  od(c; d), we will refer to the edge ab as the \short" of C , and to the edge
cd as the \long" of C . The shorts of the system S is the set of all shorts of the constraints
of S and the longs of S is the set of all the longs of the constraints. An edge may be both a
short and a long of S if it appears on one side in one constraint and on the other in another
constraint.
procedure

type:

solve constraints(in S : a system of constraints of the form od(a; b)  od(c; d))
return either a cluster tree T satisfying S if S is consistent;
or false if S is inconsistent.

A node N of the cluster tree contains
pointers to the parent and children of N ;
the eld N.label, holding the integer label;
and the eld N.symbols, holding the list of symbols in the leaves of N .

variables:

begin if

m is an integer;
C is a constraint in S ;
H; I are undirected graphs;
N; M are nodes of T ;

S contains any constraint of the form, \od(a; b)  od(c; c)" then return false;

m := the number of variables in S ;
initialize T to consist of a single node N ;
N .symbols:= the variables in S ;
repeat

H := the connected components of the shorts of S ;
if H contains all the edges in S then return(false) endif;
for each leaf N of T do
if not all vertices of N are connected in H then
N .label := m;
for each connected component I of N .symbols in H

10

do

Order of Magnitude Comparisons of Distance

construct node M as a new child of N in T ;
M .symbols:= the vertices of I ;

endfor endif endfor

S := the subset of constraints in S whose long is in H ;
m := m 1;
until
for

S is empty;

each leaf N of T
N .label := 0;
if N .symbols has more than one symbol
then create a leaf of N for each symbol in N .symbols;
label each such leaf 0;
endif endfor end solve constraints.

Tables 3 and 4 give two examples of the working of procedure solve constraints. Table
3 shows how the procedure can be used to establish that the following constraints are
consistent:
The Empire State Building (x) is much closer to the Washington Monument (w)
than to Notre Dame Cathedral (v).
Bunker Hill (y) is much closer to the Empire State Building than to the Eiel
Tower (z ).
The distance from the Eiel Tower to Notre Dame is much less than the distance
from the Washington Monument to Bunker Hill.
Table 4 shows that the following inference can be justied:

Given: The distances from the Statue of Liberty (v) to the World Trade Center
(w), from the World Trade Center to the Empire State Building (x), and from
the Empire State Building to the Chrysler Building (y) are all much less than
the distance from the Chrysler Building to the Washington Monument (z ).
Infer: The Washington Monument is not much nearer to the Chrysler Building
than to the Statue of Liberty.
This inference is carried out by asserting the negation of the consequent, \The Washington Monument is much nearer to the Chrysler Building than to the Statue of Liberty," and
showing that that collection of constraints is inconsistent. Note that if we change \much
less" and \much nearer" in this example to \less" and \nearer", then the inference no longer
valid.
Theorem 1 states the correctness of algorithm solve constraints. The proof is given in
the appendix.
Theorem 1: The algorithm solve constraints(S ) returns a cluster tree satisfying S if S is
consistent, and returns false if S is inconsistent.
There may be many cluster trees that satisfy a given set of constraints. Among these,
the cluster tree returned by the algorithm solve constraints has an important property: it
has the fewest possible labels consistent with the constraints. In other words, it uses the
minimum number of dierent orders of magnitude of any solution. Therefore, the algorithm
can be used to check the satisability of a set of constraints in an om-space that violates

11

Davis

S contains the constraints
1. od(w; x)  od(x; v).
2. od(x; y)  od(y; z ).
3. od(v; z )  od(w; y).
The algorithm proceeds as follows:
Initialization:
The tree is initializes to a single node with n1.
n1.symbols := f v; w; x; y; z g.
First iteration:
The shorts of S are f wx; xy; vz g.
Computing the connected components, H is set to f wx; xy; wy; vz g.
n1.label := 5;
Two children of n1 are created:
n11.symbols := w; x; y ;
n12.symbols := v; z ;
As xv is not in H , delete constraint #1 from S .
As yz is not in H , delete constraint #2 from S .
S now contains just constraint #3.
Second iteration:
The shorts of S are f vz g.
The connected components H is just fvz g.
n11.label := 4;
Three children of n11 are created:
n111.symbols := w;
n112.symbols := x;
n113.symbols := z ;
As wy is not in H , delete constraint #3 from S .
S is now empty.
Cleanup:
n12.label := 0;
Two children of n12 are created:
n121.symbols := v;
n122.symbols := z ;
(See Figure 2.)
Table 1: Example of computing a cluster tree

12

Order of Magnitude Comparisons of Distance

n1
0th iteration
v,w,x,y,z

n1

1st iteration

5
v,w,x,y,z
n11

n12

w,x,y

v,z

n1
2nd iteration
5
v,w,x,y,z
n11
4

n12
w,x,y
v,z

w

x

y

n1
Cleanup
5
v,w,x,y,z
n11
4

w

x

n12
w,x,y

0

y

v

Figure 2: Building a cluster tree

13

v,z

z

Davis

S contains the constraints
od(v; w)  od(z; y).
od(w; x)  od(z; y).
od(x; y)  od(z; y).
od(z; y)  od(v; z ).
The algorithm proceeds as follows:
Initialization:
The tree is initializes to a single node with n1.
n1.symbols := f v; w; x; y; z g.
First iteration:
The shorts of S are f vw; wx; xy; zy; vz g.
H is set to its connected components, which is the complete graph over v; w; x; y; z .
The algorithm exits returning false
Table 2: Example of determining inconsistency
axiom A.7 and has only nitely many dierent orders of magnitude. If the algorithm returns
T and T has no more dierent labels than the number of dierent orders of magnitude in
the space, then the constraints are satisable. If T uses more labels than the space has
orders of magnitude, then the constraints are unsatisable.
The proof is easier to present if we rewrite algorithm solve constraints in the following
form, which returns only the number of dierent non-zero labels used, but does not actually
construct the cluster tree.1

num labels(S );

function
if
then return
else return

S is empty

(0)
(1 + num labels(reduce constraints(S )))
function reduce constraints(S )
H := connected components of the shorts of S ;
if H contains all the edges in S then return(false) to top-level
else return(the set of constraints in S whose long is in H )

It is easily veried that the sequence of values of S in successive recursive calls to
num labels is the same as the sequence of values of S in the main loop of solve constraints.
Therefore num labels returns the number of dierent non-zero labels in the tree constructed
by solve constraints.
1. The reader may wonder why this simpler algorithm was not presented before the more complicated
algorithm solve constraints. The reason is that the only proof we have found that the system of constraints is consistent if num labels does not return
the constructive solve constraints.

14

false

relies on the relation between num labels and

Order of Magnitude Comparisons of Distance

Theorem 2: Out of all solutions to the set of constraints S , the instantiations of
solve constraints(S ) have the fewest number of dierent values of od(a; b), where a; b range
over the symbols in S . This number is given by num labels(S ).
The proof is given in the appendix.

6. Extensions and Consequences
We next present a number of modications of the algorithm solve constraints. The rst
is a more eÆcient implementation. The second extends the algorithm to handle non-strict
comparisons. The third extend the algorithm to handle a combination of order-of-magnitude
comparisons on distance with order comparisons, in a one-dimensional space.

6.1 An EÆcient Implementation of Solve constraints
It is possible to implement algorithm solve constraints somewhat more eÆciently than the
naive encoding of the above description. The key is to observe that the graph H of connected
components does not have to be computed explicitly; it suÆces to compute it implicitly using
merge-nd sets (union-nd sets). Combining this with suitable back pointers from edges to
constraints, we can formulate a more eÆcient version of the algorithm.
We use the following data structures and subroutines:

 Each node N of the cluster tree contains pointers to its parents and children; a eld

N .label, holding the integer label; a eld N .symbols, holding the list of symbols in
the leaves of N ; and a eld N .mfsets, holding a list of the connected components of
the symbols in N . As described below, each connected component is implemented as
an merge-nd set (MFSET).

 An edge E in the graph over symbols contains its two endpoints, each of which is a

symbol; a eld E .shorts, a list of the constraints in which E appears as a short; and
a eld E .longs, a list of the constraints in which E appears as a long.

 A constraint C has two elds, C .short and C .long, both of them edges. It also has

pointers into the lists C .short.shorts and C .long.longs, enabling C to be removed in
constant time from the constraint lists associated with the individual edges.

 We will use the disjoint-set forest implementation of MFSETs (Cormen, Leiserson,

and Rivest, 1990, p. 448) with merging smaller sets into larger and path-compression.
Thus, each MFSET is a upward-pointing tree of symbols, each node of the tree being
a symbol. The tree as a whole is represented by the symbol at the root. A symbol A
has then the following elds:

{
{
{
{

A.parent is a pointer to the parent in the MFSET tree.
A.cluster leaf is a pointer to the leaf in the cluster tree containing A.
If A is the root of the MFSET then A.size holds the size of the MFSET.
If A is the root of the MFSET, then A.symbols holds all the elements of the
MFSET.

15

Davis

{ If A is the root of the MFSET then A.leaf ptr holds a pointer to the pointer to
A in N .mfsets where N = A.cluster leaf.
We can now describe the algorithm.
procedure

variables:

0.
1.
2.
3.
4.
5.
6.
7.

begin if

8.
9.
10.
11.
12.
13.
14.
15.
16.
17.
18.
19.
20.
21.
22.
23.
24.
25.
26.
27.
28.
29.
30.
31.

solve constraints1(in S : a system of constraints of the form od(a; b)  od(c; d)).
return either a cluster tree T satisfying S if S is consistent;
or false if S is inconsistent.
m is an integer;
a; b are symbols;
C is a constraint in S ;
H is an undirected graph;
E; F are edges;
P is an MFSET;
N; M are nodes of T ;

S contains any constraint of the form, \od(a; b)  od(c; c)" then return false;

H := ;;

each constraint C in S with short E and long F
add E and F to H ;
add C to E .shorts and to F .longs endfor;
m := the number of variables in S ;
initialize T to contain the root N ;
N .symbols := the variables in S ;
for

do

each leaf N of T , INITIALIZE MFSETS(N );
each edge E = ab in H do
if E .shorts is non-empty and FIND(a) 6= FIND(b) then
MERGE(FIND(a), FIND(b)) endif endfor
if every edge E = ab in H satises FIND(a) = FIND(b)

repeat for
for

then return(false) endif

for

each current leaf N of T do
if N .mfsets has more than one element then
for each mfset P in N .mfsets do
construct node M as a new child of N in T ;
M .symbols:= P .symbols;
endfor endif endfor

each edge E = ab in H do
if FIND(a) 6= FIND(b) then
for each constraint C in E .longs do
delete C from S ;
delete C from E .longs;
delete C from C .short.shorts endfor
delete E from H endif endfor
m := m 1;
until S is empty;
for

for

each leaf N of T
N .label := 0;
if N .symbols has more than one symbol
16

Order of Magnitude Comparisons of Distance

32.
33.

create a leaf of N with label 0 for each symbol in N .symbols;
solve constraints1.

then
endif endfor end

INITIALIZE MFSETS(N : node)
: symbol;
N .mfsets := ;;
for A in N .symbols do
A.parent := null;
A.cluster leaf := N ;
A.symbols := fAg;
A.size := 1;
N .mfsets := cons(A,N .mfsets);
A.leaf ptr := N .mfsets;
endfor end INITIALIZE MFSETS.
procedure
var A

MERGE(in A; B : symbol)
.size
.size then swap(A; B );
A.parent := B ;
B .size := B .size + A.size;
B .symbols := B .symbols [ A.symbols;
Using A.leaf ptr, delete A from A.cluster leaf.mfsets;
end MERGE.
procedure
if A
>B

FIND(in A : symbol) return symbol;
: symbol;
.parent = null then return A
:= FIND(A.parent);
A.parent := R; /* Path compression */
return(R)
end FIND.
procedure
var R
if A
else R

Let n be the number of symbols in S ; let e be the number of edges; and let s be the
number of constraints. Note that n=2  e  n(n 1)=2 and that e=2  s  e(e 1)=2.
The running time of solve constraints1 can be computed as follows. As each iteration of the
main loop 8-28 splits at least one of the connected components of H , there can be at most
n 1 iterations. The MERGE-FIND operations in the for loop 9-11 take together time
at most O(max(n(n); e)) where (n) is the inverse Ackermann's function. Each iteration
of the inner for loop lines 16-18 creates one node M of the tree. Therefore, there are
only O(n) iterations of this loop over the entire algorithm. Lines 14, 15 of the outer for
loop require at most n iterations in each iteration of the main loop. The for loop 22-26
is executed exactly once in the course of the entire execution of the algorithm for each
constraint C , and hence takes at most time O(s) over the entire algorithm. Steps 20-21
require time O(e) in each iteration of the main loop. It is easily veried that the remaining
operations in the algorithm take no more time than these. Hence the overall running time
is O(max(n2 (n); ne; s)).

17

Davis

6.2 Adding Non-strict Comparisons
The algorithm solve constraints can be modied to deal with non-strict comparisons of the
form od(a; b)  od(c; d) by, intuitively, marking the edge ab as \short" on each iteration if
the edge cd has been found to be short.
Specically, in algorithm solve constraints, we make the following two changes. First,
the revised algorithm takes two parameters: S , the set of strict constraints, and W , the set
of non-strict constraints. Second, we replace the line
H := the connected components of the shorts of S

with the following code:

1.
2.
3.
4.
5.

H := the shorts of S ;
repeat H := the connected components of H ;
for each weak constraint od(a; b)  od(c; d)
if cd is in H then add ab to H endif endfor
until no change has been made to H in the last iteration.

The proof that the revised algorithm is correct is only a slight extension of the proof of
theorem 1 and is given in the appendix.
Optimizing this algorithm for eÆciency is a little involved, not only because of the new
operations that must be included, but also because there are now four parameters | n, the
number of symbols; e, the number of edges mentioned; s, the number of strict comparison;
and w, the number of non-strict comparisons | and the optimal implementation varies
depending on their relative sizes. In particular, either s or w, though not both, may be
much smaller than n, and each of these cases requires special treatment for optimal eÆciency.
The best implementation we have found for the case where both s and w are 
(n) has a
running time of O(max(n3 ; nw; s)). The details of the implementation are straightforward
and not of suÆcient interest to be worth elaborating here.
An immediate consequence of this result is that a couple of problems of inference are
easily computed:

 To determine whether a constraint C is the consequence of a set of constraints S ,
form the set S [ :C and check for consistency. If S [ :C is inconsistent then Sj=C .
Note that the negation of the constraint od(a; b)  od(c; d) is the constraint
od(c; d)  od(a; b).
 To determine whether two sets of constraints are logically equivalent, check that each
constraint in the rst is a consequence of the second, and vice versa.

6.3 Adding Order Constraints
Example 3 of Section 2 involves a combination of order-of-magnitude constraints on distances together with simple ordering on points, where the points lie on a one-dimensional
line. We next show how to extend algorithm solve constraints to deal with this more complex situation.

18

Order of Magnitude Comparisons of Distance

In terms of the axiomatics, adding an ordering on points involves positing that the
relation p < q is a total ordering and that the ordering of points is related to order of
magnitude comparisons of distances through the following axiom.
A.9 For points a; b; c 2 P , if a < b < c then od(a; b)  od(a; c).
The following rule is easily deduced: If C and D are disjoint clusters, then either every
point in C is less than all the points in D, or vice versa.
In extending our algorithm, we begin by dening an ordered cluster tree to be a cluster
tree where, for every internal node N , there is a partial order on the children of N . If A
and B are children of N and A is ordered before B , then in an instantiation of the tree,
every leaf of A must precede every leaf of B . Procedure instantiate1 can then be modied
to deal with ordered cluster trees as follows:

instantiate1(in N : a node in a cluster tree; 
 : an om-space; Æ1 : : : Æk : orders of magnitude;
in out G : array of points indexed on the nodes of T )
if N is not a leaf then
let C1 : : : Cp be the children of N in topologically sorted order;
x0 := G[N ];
q := N .label;
pick points x1 : : : xp in increasing order such that
for all i; j 2 0 : : : p, if i 6= j then od(xi ; xj ) = Æq ;
/* Such points can be chosen by virtue of axiom A.8 */
for i = 1 : : : p do
G[Ci ] := xi ;
instantiate1(Ci ; 
; Æ1 : : : Æk ; G)
endfor
endif end

instantiate1.

Algorithm solve constraints is modied as follows:
procedure

fNEWg

variables:

begin if

solve constraints2(in S : a system of constraints of the form od(a; b)  od(c; d) ;
O : a system of constraints of the form a < b)
return either an ordered cluster tree T satisfying S
if S is consistent;
or false if S is inconsistent.
m is an integer;
C is a constraint in S ;
H; I are undirected graphs;
M; N; P are nodes of T ;
a; b; c; d are symbols;

S contains any constraint of the form, \od(a; b)  od(c; c)"

then return false

;

fNEWg if O is internally inconsistent (contains a cycle) then return false;
m := the number of variables in S ;
initialize T to consist of a single node N ;
N .symbols:= the variables in S ;
repeat

H := the connected component of the shorts of S ;

19

Davis

fNEWg

H := incorporate order(H; O);
if H contains all the edges in S
for

then return false

each leaf N of T do
if not all vertices of N are connected in H then
N .label := m;
for each connected component I of N .symbols in H do
construct node M as a new child of N in T ;
M .symbols:= the vertices of I ;
endfor endif

fNEWg
fNEWg
fNEWg
fNEWg
fNEWg

for

each constraint a < b 2 O
if a is in M .symbols and b is in P .symbols
where M and P are dierent children of N
then add an ordering arc from M to P ;
endif endfor

endfor

S := the subset of constraints in S whose long is in H ;
m := m 1;
until
for

S is empty;

each leaf N of T
N .label := 0;
if N .symbols has more than one symbol
then create a leaf of N for each symbol in N .symbols;
label each such leaf 0;
endif endfor

end

solve constraints2.

fNEWg

function

incorporate order(in H : undirected graph;
O : a system of constraints of the form a < b)
return undirected graph;

variables:

G : directed graph;
a; b : vertices in H ;
A; B : connected components of H ;
V [A] : array of vertices of G indexed on connected components of H ;
I : subset of vertices of G;

connected component A of H create a vertex V [A] in G;
constraint a < b 2 O
let A and B be the connected components of H containing a and b respectively;
if A 6= B then add an arc in G from V [A] to V [B ] endif endfor;
for each strongly connected component I of G do
for each pair of distinct vertices V [A]; V [B ] 2 I do
for each a 2 A and b 2 B add the edge ab to H endfor endfor

for each
for each

endfor

20

Order of Magnitude Comparisons of Distance

end

incorporate order.

Function incorporate order serves the following purpose. Suppose that we are in the
midst of the main loop of solve constraints2, we have a partially constructed cluster tree,
and we are currently working on nding the sub-clusters of a node N . As in the original
form of solve constraints, we nd the connected components of the shorts of the order-ofmagnitude constraints. Let these be C1 : : : Cq ; then we know that the diameter of each Ci
is much smaller than the diameter of N . Now, suppose, for example, that we have in O the
constraints a1 < a5 ; b5 < b2 ; c2 < c1 , where a1 ; c1 2 C1 ; b2 ; c2 2 C2 ; and a5 ; b5 2 C5 . Then
it follows from axiom A.9 that C1 , C2 , and C5 must all be merged into a single cluster,
whose diameter will be less than the diameter of N . Procedure incorporate order nds all
such loops by constructing a graph G whose vertices are the connected components of H
and whose arcs are the ordering relations in O and then computing the strongly connected
components of G. (Recall that two vertices u; v in a directed graph are in the same strongly
connected component if there is a cycle from u to v to u.) It then merges together all of
the connected components of H that lie in a single strongly connected component of G.
The proof of the correctness of algorithm solve constraints2 is again analogous in structure to the proof of theorem 1, and is given in the appendix.
By implementing this in the manner of Section 6.1, the algorithm can be made to run
in time O(max(n2 (n); ne; no; s)), where o is the number of constraints in O.

7. Finite order of magnitude comparison
In this section, it is demonstrated that algorithm solve constraints can be applied to systems
of constraints of the form \dist(a; b) < dist(c; d) / B " for nite B in ordinary Euclidean
space as long as the number of symbols in the constraint network is smaller than B .
We could be sure immediately that some such result must apply for nite B . It is
a fundamental property of the non-standard real line that any sentence in the rst-order
theory of the reals that holds for all innite values holds for any suÆciently large nite
value, and that any sentence that holds for some innite value holds for arbitrarily large
nite values. Hence, since the answer given by algorithm solve constraints works over a
set of constraints S when the constraint \od(a; b)  od(c; d)" is interpreted as \od(a; b)
< od(c; d)/B for innite B ", the same answer must be valid for suÆciently large nite B .
What is interesting is that we can nd a simple characterization of B in terms of S ; namely,
that B is larger than the number of symbols in S .
We begin by modifying the form of the constraints, and the interpretation of a cluster
tree. First, to avoid confusion, we will use a four-place predicate \much closer(a; b; c; d)"
rather than the form \od(a; b)  od(c; d)" as we are not going to give an interpretation to
\od" as a function. We x a nite value B > 1, and interpret \much closer(a; b; c; d)" to
mean \dist(a; b) < dist(c; d) / B ."
We next redene what it means for a valuation to instantiate a cluster tree:

Denition 6: Let T be a cluster tree and let be a valuation on the symbols in T . We say
that `T if the following holds: For any symbols a; b; c; d in T , let M be the least common
ancestor of a; b and let N be the least common ancestor of c; d. If M .label < N .label then
much closer(a; b; c; d).

21

Davis

Procedure \instantiate", which generates an instantiation of a cluster tree, is modied
as follows:
procedure

instantiate(in T : cluster tree; 
 : Euclidean space; B : real);
return : array of points indexed on the symbols of T ;

Let n be the number of nodes in T ;
 := 2 + 2n + Bn;
Choose Æ1 ; Æ2 : : : Æn such that Æi < Æi+1 =;
pick a point x 2 
;
G[T ] := x;
instantiate1(T; 
; Æ1 : : : Æn ; G);
return the restriction of G to the symbols of T .
end instantiate.
instantiate1(in N : a node in a cluster tree; 
 : a Euclidean space;
Æ1 : : : Æn : orders of magnitude;
in out G : array of points indexed on the nodes of T )
if N is not a leaf then
let C1 : : : Cp be the children of N ;
x1 := G[N ];
q := N .label;
pick points x2 : : : xp such that
for all i; j 2 1 : : : p, if i 6= j then Æq  dist(xi ; xj ) < nÆq
/* This is possible since p  n. */
for i = 1 : : : p do
G[Ci ] := xi ;
instantiate1(Ci ; 
; Æ1 : : : Æn ; G)
endfor
endif end

instantiate1.

The analogue of lemma 2 holds for the revised algorithm:
Lemma 22: Any cluster tree T has an instantiation in Euclidean space <m of any dimensionality m.
We can now state theorem 3, which asserts the correctness of algorithm \solve constraints"
in this new setting:

Theorem 3: Let S be a set of constraints over n variables of the form \dist(a; b) <
dist(c; d) / B ", where B > n. The algorithm solve constraints(S ) returns a cluster tree
satisfying S if S is consistent over Euclidean space, and returns false if S is inconsistent.
The proofs of lemma 22 and theorem 3 are given in the appendix.
An examination of the proof of lemma 22 shows that this result does not depend on
any relation between n and B . Therefore, if solve constraints(S ) returns a tree T , then S
is consistent and T satises S regardless of the relation between n and B . However, it is
possible for S to be consistent and solve constraints(S ) to return false if n  B . On the
other hand, one can see from the proof of theorem 3 (particularly lemma 23) that if B > n
and solve constraints(S ) returns false then S is inconsistent in any metric space. However,
there are metric spaces other than <m in which the cluster tree returned by solve constraints
may have no instantiation.

22

Order of Magnitude Comparisons of Distance

8. The rst-order theory
Our nal result asserts that if the om-space is rich enough then the full rst-order language
of order-of-magnitude distance comparisons is decidable. Specically, if the collection of
orders of magnitude is dense and unbounded above, then there is a decision algorithm for
rst-order sentences over the formula, \od(W; X )  od(Y; Z )" that runs in time O(4n (n!)2 s)
where n is the number of variables in the sentence and s is the length of the sentence.
The basic reason for this is the following: As we have observed in corollary 4, a cluster
tree T determines the truth value of all constraints of the form \od(a; b)  od(c; d)" where
a; b; c; d are symbols in the tree. That is, any two instantiations of T in any two omspaces agree on any such constraint. If we further require that the om-spaces are dense
and unbounded, then a much stronger statement holds: Any two instantiations of T over
such om-spaces agree on any rst-order formula free in the symbols of T over the relation
\od(W; X )  od(Y; Z )". Hence, it suÆces to check the truth of a sentence over all possible
cluster trees on the variables in the sentence. Since there are only nitely many cluster
trees over a xed set of variables (taking into account only the relative order of the labels
and not their numeric values), this is a decidable procedure.
Let L be the rst-order language with equality with no constant or function symbols,
and the single predicate symbol \much closer(a; b; c; d)". It is easily shown that L is as
expressive as the language with the function symbol \od" and the relation symbol .

Denition 7: An om-space 
 with orders of magnitude
following axiom:

D is dense if it satises the

A.9 For all orders of magnitude Æ1  Æ3 in D, there exists a order of magnitude Æ2 in D
such that Æ1  Æ2  Æ3 .

 is unbounded above if it satises the following:
A.10 For every order of magnitude Æ1 in D there exists Æ2 in D such that Æ1  Æ2 .
If D is the collection of orders of magnitude in the hyperreal
line, then both of these
p
are satised. In axiom [A.9], if 0  Æ1  Æ3 , choose Æ2 = Æ1 Æ3 , the geometric mean.
If 0 = Æ1  Æ3 , choose Æ2 = Æ3 Æ where Æ  1. In axiom [A.10] choose Æ2 = Æ1 =Æ where
0 < Æ  1.

Denition 8: Let T be a cluster tree. Let l0 = 0; l1 ; l2 : : : lk be the distinct labels in T
in ascending order. An extending label for T is either (a) li for some i; (b) lk + 1 (note that
lk is the label of the root); (c) (li 1 + li )=2 for some i between 1 and k.
Note that if T has k distinct non-zero labels, then there are 2k + 2 dierent extending
labels for T .

Denition 9: Let T be a cluster tree. Let x be a symbol not in T . The cluster tree
0
T extends T with x if T 0 is formed from T by applying one of the following operations (a
single application of a single operation).
1. T is the null tree and T 0 is the tree containing the single node x.

23

Davis

2. T consists of the single node for symbol y. Make a new node M , make both x and y
children of M , and set the label of M to be either 0 or 1.
3. For any internal node N of T (including the root), make x a child of N .
4. Let y be a symbol in T , and let N be its father. If N .label 6= 0, create a new node M
with an extending label for T such that M .label < N .label. Make M a child of N ,
and make x and y children of M .
5. Let C be an internal node of T other than the root, and let N be its father. Create
a new node M with an extending label for T such that C .label < M .label < N .label.
Make M a child of N and make x and C children of M .
6. Let R be the root of T . Create a new node M such that M .label = R.label + 1. Make
R and x children of M . Thus M is the root of the new tree T 0 .
(See Figure 3.)
Note that if T is a tree of n symbols and at most n 1 internal nodes then

 There are n 1 ways to carry out step 3.
 There are n possible ways to choose symbol y in step 4, and at most 2n 2 for the
label on M in each.

 There are at most n 2 dierent choices for C in step 5, and at most 2n 3 choices
for the label on M in each.

 There is only one way to carry out step 6.
Hence, there are less than 4n2 dierent extensions of T by x. (This is almost certainly
an overestimate by at least a factor of 2, but the nal algorithm is so entirely impractical
that it is not worthwhile being more precise.)

Denition 10: Let T be a cluster tree, and let  be a formula of L open in the variables
of T . T satises  if every instantiation of T satises .
Theorem 4: Let T be a cluster tree. Let  be an open formula in L, whose free variables
are the symbols of T . Let 
 be an om-space that is dense and unbounded above. Algorithm
decide(T; ) returns true if T satises  and false otherwise.

decide(T : cluster tree;  : formula) return boolean
convert  to an equivalent form in which the only logical symbols in  are
: (not), ^ (and), 9 (exists), = (equals) and variable names,
and the only non-logical symbol is the predicate \much closer".
function

case

 has form X = Y : return (distance(X; Y; T ) = 0);
 has form \much closer(W; X; Y; Z )": return distance(W; X; T ) < distance(Y; Z; T ));
 has form : : return not(decide(T; ))
 has form ^ : return(decide(T; ) and decide(T; ))
 has form 9X ;

24

Order of Magnitude Comparisons of Distance

P

P

P

2

2

2
w

Q

Q

1

w

Q

w

x

1

1

u

u

v

u

v

v

x

Operation 3:

Operation 3:
Original T

N = P

N = Q

P
2
w

Q
1

P

P

2

2
w

Q
1

Operation 4:

Operation 4:
y=v

y=u

M

Q

0/0.5/1/1.5

1
u

v

M

M
0/0.5

0/0.5

u

u

v

x

w

Operation 4:

x

y=w

M
P

3

2
x
M

w

P
2

1.5
Operation 5:
x

w

Q
1

C=Q, N=P

Q
1
u

u

v

v

v
Operation 6:
R=P

Figure 3: Extensions of a cluster tree

25

x

Davis

extension

of by , decide(T ; ) = true

if for some
T0 T X
then return true
else return false endif endcase

end

0

decide

distance(X; Y : symbol; T : cluster tree) return
N := the common ancestor of X and Y in T ;
return(N .label)
function

end

integer

distance

The proof of theorem 4 is given in the appendix.
Running time: As we have remarked above, for a tree T of size k there are at most 4k2
extensions of T to be considered. The total number of cluster trees considered is therefore
bounded by nk=1 4k2 = 4n (n!)2 . It is easily veried that the logical operators other than
quantiers add at most a factor of s where s is the length of the sentence. Hence the running
time is bounded by O(4n (n!)2 s).
A key lemma, of interest in itself, states the following:
Lemma 28: Let T be a cluster tree. Let  be an open formula in L, whose free variables
are the symbols of T . Let 
 be an om-space that is dense and unbounded above. If one
instantiation of T in 
 satises  then every instantiation of T in 
 satises .
That is, either  is true for all instantiations of T or for none. The proof is given in the
appendix.
It should be observed that the above conditions on 
 in lemma 28 are necessary, and
that the statement is false otherwise. For example, let 
 be the om-space described in
example I, Section 3, of polynomials over an innitesimal Æ. Then 
 is not unbounded
above; there is a maximum order-of-magnitude O(1). Let T be the starting tree of Figure
3 (upper-left corner). Let  be the formula \9X od(V; W )  od(W; X )", free in V and W .
Then the valuation fU ! Æ; V ! 0; W ! 1g satises T but not , whereas the valuation
fU ! Æ2 ; V ! 2Æ2 ; W ! Æg satises both T and .

9. Conclusions
The applications of the specic algorithms above are undoubtedly limited; we are not aware
of any practical problems where solving systems of order-of-magnitude relations on distances
is the central problem. However, the potential applications of order-of-magnitude reasoning
generally are very widespread. Ordinary commonsense reasoning involves distances spanning a ratio of about 108 , from a fraction of an inch to thousands of miles, and durations
spanning a ratio of about 1010 , from a fraction of a second to a human lifetime. Scientic
reasoning spans much greater ranges. Explaining the dynamics of a star combines reasoning
about nuclear reactions with reasoning about the star as a whole; these dier by a ratio
of about 1057 . The techniques needed to compute with quantities of such vastly diering
sizes are quite dierent from the techniques needed to compute with quantities all of similar
sizes. This paper is a small step in the development and analysis of such computational
techniques.
The above results are also signicant in the encouragement that they give to the hope
that order-of-magnitude reasoning specically, and qualitative reasoning generally, may lead

26

Order of Magnitude Comparisons of Distance

to useful quick reasoning strategies in a broader range of problems. It has been often found
in AI that moving from greater to lesser precision in the mode of inference or type of
knowledge does not lead to quick and dirty heuristic techniques, but rather to slow and
dirty techniques. Nonmonotonic reasoning is the most notorious example of this, but it
arises as well in many other types of automated reasoning, including qualitative spatial and
physical reasoning. The algorithms developed in this paper are a welcome exception to
this rule. We are currently studying algorithmic techniques for other order-of-magnitude
problems, and are optimistic of nding similar favorable results.

Acknowledgements
This research has been supported by NSF grant #IRI-9625859. Thanks to Ji-Ae Shin,
Andrew Gelsey, and the reviewers for helpful comments.

Appendix A. Proofs
In this appendix, we give the proofs of the various results asserted in the body of the paper.

Proof of Lemma 2
Lemma 2: If T is a cluster tree and 
 is an om-space, then instantiate(T; 
) returns an
instantiation of T .
Proof: Let Æ0 = 0. For any node N , if i=N .label, we dene (N ) = Æi . The proof then
proceeds in the following steps:
i. For any nodes M ,N , if M is a descendant of N in T then od(G[M ]; G[N ])  (N ).
Proof: If M is a child of N , then this is immediate from the construction of x2 : : : xp
in instantiate1. Else, let N = N1 ; N2 : : : Nq = M be the path from N to M through
T . By the denition of a cluster tree, it follows that Ni .label < N .label, for i > 1 and
therefore (Ni )  (N ). Thus od(G[M ]; G[N ])  (by the o.m.-triangle inequality)
maxi=1:::q 1 (od(G[Ni+1 ]; G[Ni ]))  maxi=1:::q 1 ((Ni )) (since Ni+1 is the child of
Ni )  (N ).
ii. Let N be a node in T ; let C1 and C2 be two distinct children of N ; and let M1
and M2 be descendants of C1 and C2 respectively. Then od(G[M1 ]; G[M2 ]) = (N ).
Proof: By the construction of x2 : : : xp in instantiate1(N ), od(G[C1 ]; G[C2 ]) = (N ).
By part (i.), od(G[M1 ]; G[C1 ])  (C1 )  (N ) and likewise od(G[M2 ]; G[C2 ]) 
(N ). Hence, by axiom A.6, od(G[M1 ]; G[M2 ]) = (N ).
iii. Let a and b be any two leaves in T , and let N be the least common ancestor in T of
a and b. Then od(G[a]; G[b]) = (N ). Proof: Immediate from (ii).
iv. For any node N , odiam( (N )) = (N ). Proof: From (iii), any two leaves descending
from dierent children of N are at a distance of order (N ), and no two leaves of N
are at a distance of order greater than (N ).

27

Davis

v. For any node N , (N ) is a cluster of (T ). Proof: Let a and b be leaves of N ,
and let c be a leaf of T N . Let I be the common ancestor of a and b in T and
let J be the common ancestor of a and c. Then I is either N or a descendant of N
and J is a proper ancestor of N . Therefore by part (i), (I )  (J ). But by (iii),
od( (a); (b)) = (I )  (J ) = od( (a); (c)).
vi. For any internal nodes N; M if M .label < N .label then odiam( (M ))  odiam( (N )).
Proof: Immediate from (iv) and the construction of .
vii. If C is a cluster of (T ) then there is a node N in T such that C = (N ). Proof: Let
S be the set of symbols corresponding to C and let N be the least common ancestor
of all of S . Let a and b be two symbols in S that are in dierent subtrees of N . Then
by (iii), od(G[a]; G[b]) = (N ). Let x be any symbol in N .symbols. Then by (iii)
od(G[a]; G[x])  (N ). Hence G[x] 2 C .

2
Proof of Theorem 1
We here prove the correctness of algorithm solve constraints. We will assume throughout
that the two variables in the long of any constraint in S are distinct.
Lemma 3: Let T be a cluster tree and let be an instantiation of T . Let a and b be
symbols of T . Let N be the least common ancestor of a and b in T . Then od( (a); (b)) =
odiam( (N )).
Proof: Since (a) and (b) are elements of (N ), it follows from the denition of odiam that
od( (a); (b))  odiam( (N )). Suppose the inequality were strict; that is, od( (a); (b))
 odiam( (N )). Then let C be the set of all the symbols c of T such that od( (a); (c))
 od( (a); (b)). Then odiam( (C )) = od( (a); (b))  odiam( (N )). It is easily shown
that (C ) is a cluster in (T ). Therefore, by property (ii) of denition 5, there must be
a node M such that M .symbols = C . Now, M is certainly not an ancestor of N , since
odiam( (M ))  odiam( (N )) but M .symbols contains both a and b. But this contradicts
the assumption that N was the least common ancestor of a and b. 2
Corollary 4: Let T be a cluster tree and let be an instantiation of T . Let a; b; c; d be
symbols of T . Let N be the least common ancestor of c and d in T , and let M be the
least common ancestor of a and b in T . Then od( (a); (b))  od( (c); (d)) if and only if
M .label < N .label.
Proof: Immediate from lemma 3 and property (iii) of denition 5 of instantiation. 2

Lemma 5: Let S be any set of constraints of the form od(a; b)  od(c; d). Let H be the
connected components of the shorts of S . If S is consistent, then not every edge of S is in
H.
Proof: Let be a valuation satisfying S . Find an edge pq in S for which od( (p); (q)) is
maximal. Now, if ab is a short of S | that is, there is a constraint od(a; b)  od(c; d) in
S | then od( (a); (b))  od( (c); (d))  od( (p); (q)).

28

Order of Magnitude Comparisons of Distance

Now, let ab be any edge in H , the connected components of the shorts of S . Then there
is a path a1 = a; a2 : : : ak = b such that the edge ai ai+1 is a short of S for i = 1 : : : k 1.
Thus, by the om-triangle inequality, od( (a); (b))  maxi=1::k 1(od( (ai ); (ai+1 ))) 
od( (p); (q)). Hence pq 6= ab, so pq is not in H . 2

Lemma 6: The values of S and H in any iteration are supersets of their values in any later
iteration.

Proof: S is reset to a subset of itself at the end of each iteration. H is dened in terms of
S in a monotonic manner. 2

S cannot be the same in two successive iterations of the main loop.
Proof: by contradiction. Suppose that S is the same in two successive iterations. Then H
will be the same, since it is dened in terms of S . H is constructed to contain all the shorts
of S , Since the resetting of S at the end of the rst iteration does not change S , H must
contain all the longs as well. Thus, H contains all the edges in S . But that being the case,
the algorithm should have terminated with failure at the beginning of the rst iteration. 2
Lemma 7:

Lemma 8: Algorithm solve constraints always terminates.
Proof: By lemma 7, if the algorithm does not exit with failure, then on each iteration some
constraints are removed from S . Hence, the number of iterations of the main loop is at
most the original size of S . Everything else in the algorithm is clearly bounded. (Note that
this bound on the number of iterations is improved in Section 6.1 to n 1, where n is the
number of symbols.) 2

Lemma 9: If algorithm solve constraints returns false, then S is inconsistent.

Proof: If the algorithm returns false, then the transitive closure of the shorts of S contains
all the edges in S . By lemma 5, S is inconsistent.

Lemma 10: If constraint C of form od(a; b)  od(c; d) is in the initial value of S , and
edge cd is in H in some particular iteration, then constraint C is in S at the start of that
iteration.
Proof: Suppose that C is deleted from S on some particular iteration. Then edge cd, the
long of C , cannot be in H in that iteration. That is, it is not possible for edge cd to persist
in H in an iteration after C has been deleted from S . Note that, by lemma 6, once cd is
eliminated from H , it remains out of H . 2
Lemma 11: The following loop invariant holds: At the end of each loop iteration, the
values of L.symbols, where L is a leaf in the current state of the tree, are exactly the
connected components of H .

Proof: In the rst iteration, T is initially just the root R, containing all the symbols, and
a child of R is created for each connected component of H .
Let Ti and Hi be the values of T and H at the end of the ith iteration. Suppose that
the invariant holds at the end of the kth iteration. By lemma 6, Hk+1 is a subset of Hk .
Hence, each connected component of Hk+1 is a subset of a connected component of Hk .

29

Davis

Moreover, each connected component J of Hk is either a connected component of Hk+1 or
is partitioned into several connected components of Hk+1 . In the former case, the leaf of
Tk corresponding to J is unchanged and remains a leaf in Tk+1 . In the latter case, the leaf
corresponding to J gets assigned one child for each connected component of Hk+1 that is a
subset of J . Thus, the connected components of Hk+1 correspond to the leaves of Tk+1 . 2

Lemma 12: If procedure solve constraints does not return false, then it returns a wellformed cluster tree T .
Proof: Using lemma 11, and the cleanup section of solve constraints which creates the nal
leaves for symbols, it follows that every symbol in S ends up in a single leaf of T . As m is
decremented on each iteration, and as no iteration adds both a new node and children of
that node, it follows that the label of each internal node is less than the label of its father.
Hence the constraints on cluster trees (denition 3) are satised. 2
Lemma 13: Let a; b be two distinct symbols in S and let T be the cluster tree returned
by solve constraints for S . Let N be the least common ancestor of a; b in T . Then either N
is assigned its label on the rst iteration when the edge ab is not in H , or the edge ab is in
the nal value of H when the loop is exited and N is assigned its label in the nal cleanup
section.
Proof: As above, let Hi be the value of H in the ith iteration.
If N is the root, then it is assigned its label in the rst iteration. Clearly, a and b, being
in dierent subtrees of N , must be in dierent connected components of H1 .
Suppose N is assigned its label in the kth iteration of the loop for k > 1. By lemma 11,
at the end of the previous iteration, N .symbols was a connected component of Hk 1 , and it
therefore contained the edge ab. Since N is the least common ancestor of a; b, it follows that
a and b are placed in two dierent children of N ; hence, they are in two dierent connected
components of Hk . Thus the edge ab cannot be in Hk .
Suppose N is assigned its label in the cleanup section of the algorithm. Then by lemma
11, N .symbols is a connected component of the nal value of H . Hence the edge ab was in
the nal value of H . 2
Lemma 14: Let S initially contain constraint C of form od(a; b)  od(c; d). Suppose that
solve constraints(S ) returns a cluster tree T . Let M be the least common ancestor of a; b
in T and let N be the least common ancestor of c; d. Then M .label < N .label.
Proof: Suppose N is given a label in a given iteration. By lemma 13, cd is eliminated
from H in that same iteration. By lemma 10, constraint C must be in S at the start of the
iteration. Hence ab is a short of S in the iteration, and is therefore in H . Hence M is not
given a label until a later iteration, and therefore is given a lower label.
It is easily seen that cd cannot be in H in the nal iteration of the loop, and hence N
is not assigned its label in the cleanup section. 2
Lemma 15: Suppose that solve constraints(S ) returns a cluster tree T . Then any instantiation of T satises the constraints S .
Proof: Immediate from lemma 14 and corollary 4.

30

Order of Magnitude Comparisons of Distance

Theorem 1: The algorithm solve constraints(S ) returns a cluster tree satisfying S if S is
consistent, and returns false if S is inconsistent.
Proof: If solve constraints(S ) returns false, then it is inconsistent (lemma 9). If it does
not return false, then it returns a cluster tree T (lemma 12). Since T has an instantiation
(lemma 2) and since every instantiation of T is a solution of S (lemma 15), it follows that
S is consistent and T satises S . 2
Proof of Theorem 2
Lemma 16: If S1 and S2 are consistent sets of constraints, and S1  S2 then
reduce constraints(S1 )  reduce constraints(S2 ).
Proof: Immediate by construction. The value of H in the case of S1 is a superset of its value
in the case of S2 , and hence reduce constraints(S1 ) is a superset of reduce constraints(S2 ).
Lemma 17: If S1 and S2 are consistent sets of constraints, and S1  S2 then num labels(S1)
 num labels(S2).
Proof by induction on num labels(S2). If num labels(S2) = 0, the statement is trivial.
Suppose that the statement holds for all S 0 , where num labels(S 0) = k.
Let num labels(S2) = k + 1.
Then k + 1 = num labels(S2 ) = 1 + num labels(reduce constraints(S2 )), so
k =num labels(reduce constraints(S2 )). Now, suppose S1  S2 . By lemma 16
reduce constraints(S1 )  reduce constraints(S2 ). But then by the inductive hypothesis
num labels(reduce constraints(S1 ))  num labels(reduce constraints(S2 )), so
num labels(S1)  num labels(S2). 2
Lemma 18: Let S be a set of constraints, and let be a solution of S . For any graph G
over the symbols of S , let nd(G; ) be the number of dierent non-zero values of od(a; b)
where edge ab is in G. Let edges(S ) be the set of edges in S . Then nd(edges(S ), ) 
num labels(S ).
Proof: by induction on num labels(S ). If num labels(S ) = 0, then the statement is trivial.
Suppose for some k, the statement holds for all S 0 where num labels(S 0) = k, and suppose
num labels(S ) = k + 1. Let pq be the edge in S of maximal length. For any set of edges E ,
let small-edges(E; ) be the set of all edges ab in E for which
od( (a); (b))  od( (p); (q)). Since small-edges(E ) contains edges of every order of
magnitude in E except the order of magnitude of pq, it follows that
nd(small-edges(E; ), ) = nd(E; ) 1. Let G be the complete graph over all the symbols
in S . By the same argument as in lemma 5, small-edges(G; )  H , where H is the connected
components of the shorts of S , as computed in reduce constraints(S ). Let S 0 be the set of
constraints whose longs are in small-edges(G; ). It follows that S 0  reduce constraints(S ).
Now small-edges(G; )  edges(S 0 )  edges(reduce constraints(S )).
Hence nd(edges(S ), ) = nd(G; ) = nd(small-edges(G; ), ) + 1
 nd(edges(reduce constraints(S ))) + 1  (by the inductive hypothesis)
num labels(reduce constraints(S )) + 1 = num labels(S ). 2

31

Davis

Theorem 2: Out of all solutions to the set of constraints S , the instantiations of
solve constraints(S ) have the fewest number of dierent values of od(a; b), where a; b range
over the symbols in S . This number is given by num labels(S ).
Proof: Immediate from lemma 18.
Corollary 19: Let 
 have all the properties of an om-space except that it has only k
dierent orders of magnitude. A system of constraints S has a solution in 
 if and only if
the tree returned by solve constraints(S ) uses no more than k dierent labels.
Proof: Immediate from theorems 1 and 2. 2
Proof of Algorithm for Non-strict Comparisons
We now prove that the revised algorithm presented in Section 6.2 for non-strict comparisons
is correct. The proof is only a slight extension of the proof of theorem 1, given above.
Recall that the revised algorithm in Section 6.2 replaces the line of solve constraints
H := the connected components of the shorts of S
with the following code:

1.
2.
3.
4.
5.

H := the shorts of S ;
repeat H := the connected components of H ;
for each weak constraint od(a; b)  od(c; d)
if cd is in H then add ab to H endif endfor
until no change has been made to H in the last iteration.

We need the following new lemmas and proofs:

Lemma 20: Let S be a set of strict comparisons, and let W be a set of non-strict comparisons. Let H be the set of edges output by the above code. If S [ W is consistent, then
there is an edge in S that is not in H .
Proof: As in the proof of lemma 5, let be a valuation satisfying S [ W and let pq be
an edge in S such that od( (p); (q)) is maximal. We wish to show that, for every edge
ab 2 H , od( (a); (b))  od( (p); (q)), and hence ab 6= pq. Proof by induction: suppose
that this holds for all the edges in H at some point in the code, and that ab is now to be
added to H . There are three cases to consider.

 ab is added in step [1]. Then, as in lemma 5, there is a constraint od(a; b)  od(c; d)
in S . Hence od( (a); (b))  od( (c); (d))  od( (p); (q)).
 ab is added in step [2]. Then there is a path a1 = a; a2 : : : ak = b such that the edge
ai ai+1 is in H for i = 1 : : : k 1. By the inductive hypothesis, od( (ai ); (ai+1 )) 
od( (p); (q)). By the om-triangle inequality,
od( (a); (b))  maxi=1::k 1(od( (ai ); (ai+1 )))  od( (p); (q)).

 ab is added in step [4]. Then there is a constraint od(a; b)  od(c; d) in W such that
cd is in H . By the inductive hypothesis, od( (c); (d))  od( (p); (q)).
32

Order of Magnitude Comparisons of Distance

2

Lemma 21: Let W contain the constraint od(a; b)  od(c; d). Suppose that the algorithm
returns a cluster tree T . Let M be the least common ancestor of a and b in T , and let N
be the least common ancestor of c and d. Then M .label  N .label.
Proof: By lemma 13, N is assigned a label in the rst iteration where H does not include
the edge cd. In all previous iterations, since cd is in H , ab will likewise be put into H .
Hence M does not get assigned a label before N , so M .label  N .label.
The remainder of the proof of the correctness of the revised algorithm is exactly the
same as the proof of theorem 1.
Validation of Algorithm Solve constraints2
The proof of the correctness of algorithm solve constraints2 is again analogous in structure
to the proof of theorem 1. We sketch it below: the details are not diÆcult to ll in.
1. (Analogue of lemma 2:) If T is an ordered cluster tree, then the revised version of
instantiate(T ) returns an instantiation of T . The proof is exactly the same as lemma
2, with the additional verication that instantiate2 preserves the orderings in T .
2. (Analogue of lemma 5:) Let S be a set of order-of-magnitude constraints on distances,
and let O be a set of ordering constraints on points. Let H be the graph given by the
two statements

H := the connected components of the shorts of S ;
H := incorporate order(H; O);
If S and O are consistent, then H does not contain all the edges of S .
Proof: As in the proof of lemma 5, choose a valuation satisfying S ; O and let pq be
an edge in S for which od( (p); (q)) is maximal. Following the informal argument
presented in Section 6.3, it is easily shown that pq is longer than any of the edges
added in these two statements, and hence it is not in H .
3. (Analogue of lemma 9:) If solve constraints2 returns false, then S ; O is inconsistent.
Proof: Immediate from (2).
4. (Analogue of lemma 12:) If solve constraints2(S ; O) does not return false, then it
returns a well-formed ordered cluster tree.
Proof: By merging the strongly connected components of G, incorporate order always
ensures that the ordering arcs between connected components of H form a DAG. These
arcs are precisely the same ones that are later added among the children of node N as
ordering arcs. Thus, the ordering arcs over the children of a node in the cluster tree
form a DAG. Otherwise, the construction of the tree T is the same as in lemma 12.
The remainder of the proof is the same as the proof of theorem 1.

33

Davis

Proof of Theorem 3
We begin by proving lemma 22, that the revised version of \instantiate", given in Section
6.3, gives an instantiation of a cluster tree in Euclidean space.
Lemma 22: Any cluster tree T has an instantiation in Euclidean space <m of any dimensionality m.
The proof is essentially the same as the proof of Lemma 2, except that we now have
to keep track of real quantities. For any node N , if i=N .label, we dene (N ) = Æi . The
proof then proceeds in the following steps:
i. For any i < j , Æi < Æj =j i . Immediate by construction.
ii. For any nodes M ,C , if M is a descendant of C in T then
dist(G[M ]; G[C ]) < n(C )=( 1).
Proof: Let C = C0 ; C1 : : : Cr = M be the path from P
C to M through T . Then
dist(
the triangle inequality) ri=01 dist(G[Ci+1]; G[Ci ]) 
Pr 1G(n[M(];CG)[=C ])i) < (by
(=( 1))(n(C )).
i=0
iii. Let N be a node in T ; let C1 and C2 be two children of N ; and let M1 and M2 be
descendants of C1 and C2 respectively. Then
(N )(1 2n=( 1)) < dist(G[M1]; G[M2 ]) < n(N )(1 + 2=( 1))
Proof: By the triangle inequality,
dist(G[C1 ]; G[C2 ])  dist(G[C1 ]; G[M1 ]) + dist(G[M1 ]; G[M2 ]) + dist(G[M2 ]; G[C2 ]).
Thus, dist(G[C1]; G[C2 ]) dist(G[C1]; G[M1 ]) dist(G[M2 ]; G[C2 ])  dist(G[M1 ]; G[M2 ]).
Also, by the triangle inequality,
dist(G[M1 ]; G[M2 ])  dist(G[C1]; G[C2 ]) + dist(G[C1]; G[M1 ]) + dist(G[M2 ]; G[C2 ]).
By construction, (N )  dist(G[C1]; G[C2 ]) < n(N ),
and by part (ii), for i = 1; 2, dist(G[Mi]; G[Ci ]) < n(C )=( 1) < n(N )=( 1)
as (C ) < (N )=.
iv. For any symbols a; b; c; d in T , let P be the least common ancestor of a; b and let N
be the least common ancestor of c; d. If P .label < N .label then
much closer(G[a]; G[b]; G[c]; G[d]).
Proof: By part (iii), dist(G[a]; G[b]) < n(P )(1 + 2=( 1))
and dist(G[c]; G[d]) > (N )(1 2n=( 1)). Since (P ) < (N )= and since
 = 2 + 2n + Bn, it follows by straightforward algebra that
dist(G[a]; G[b]) < dist(G[c]; G[d]) / B .

2

We next prove the analogue of lemma 5.

Lemma 23: Let S be a set of constraints over n variables of the form
\dist(a; b) < dist(c; d) / B ", where B > n. If S is consistent, then there is some edge in S
which is not in the connected components of the shorts of S .
Proof: Let be a valuation satisfying S . Let pq be the edge in S for which dist( (p); (q))
is maximal. Now, if ab is a short of S | that is, there is a constraint much closer(a; b; c; d)
in S | then dist( (a); (b)) < dist( (c); (d))/B  dist( (p); (q))/B .

34

Order of Magnitude Comparisons of Distance

Now, let ab be any edge in H , the connected components of the shorts of S . Then
there is a simple path a1 = a; a2 : : : ak = b such that the edge ai ai+1 is a short of S for
i = 1 : : : k 1. Note that k  n. Then, by the triangle inequality,
dist( (a); (b)) 
dist( (a1 ); (a2 )) + dist( (a2 ); (a3 )) + . . . + dist( (ak 1 ); (ak )) 
(k 1)dist( (p); (q)) / B < dist( (p); (q))

Hence pq 6= ab, so pq is not in H . 2

Theorem 3: Let S be a set of constraints over n variables of the form \dist(a; b) < dist(c; d)
/ B ", where B > n. The algorithm solve constraints(S ) returns a cluster tree satisfying S
if S is consistent over Euclidean space, and returns false if S is inconsistent.
Proof: Note that the semantics of the constraints \much closer(a; b; c; d)" enters into the
proof of Theorem 1 only in lemmas 2 and 5. The remainder of the proof of Theorem 1 has to
do purely with the relation between the structure of S and the structure of the tree. Hence,
since we have shown that the analogues of lemmas 2 and 5 hold in a set of constraints of
this kind, the same proof can be completed in exactly the same way. 2
Proof of Theorem 4
Lemma 24: Let T be a cluster tree and let be a valuation over om-space 
 satisfying T .
Let x be a symbol not in T , let a be a point in 
, and let 0 be the valuation [ fx ! ag.
Then there exists an extension T 0 of T by x such that 0 satises T 0 .
Proof: If T is the empty tree, the statement is trivial. If T contains the single symbol y,
then if a = (y) then operation (2) applies with M .label=0; if a 6= (y) then operation (2)
applies with M .label=1.
Otherwise, let y be the symbol in T such that od( (y); a) is minimal. (We will deal
with the case of ties in step (D) below.) Let F be the father of y in T .
Let D=od( (y); a). Let V be the set of all orders of magnitude od( (p); (q)), where
p and q range over symbols in T . We dene L to be the suitable label for D as follows: If
D 2 V , then L is the label in T corresponding to D. If D is larger than any value in V
then L is the label of the root of T plus 1. If D 62 V , but some value in V is larger than D,
then let D1 be the largest value in V less than D; let D2 be the smallest value in V greater
than D; let L1 , L2 be the labels in T corresponding to D1 , D2 ; and let L = (L1 + L2 )=2.
One of the following must hold:
A. (y) = a, and F .label=0. Then apply operation (3) with N = F .
B. (y) = a and F .label 6= 0. Then apply operation (4) with M .label = 0.
C. (y) 6= a, but od( (y); a) is less than od( (z ); a) for any other symbol z =
6 y in T .
Apply operation (4) with M .label set to the suitable value for D in T .
D. There is more than one value y1 : : : yk for which od( (yi ); a) = D. It is easily shown
that in this case there is an internal node Q such that y1 : : : yk is just the set of symbols
in the subtree of Q. There are three cases to consider:

35

Davis

D.i D=odiam( (Q.symbols)). Then apply operation (3) with N = Q.
D.ii D > odiam( (Q.symbols)), and Q is not the root. Then apply operation (5)
with C = Q. Set M .label to be the suitable value for D. (It is easily shown that
D < odiam( (N .symbols)), where N is the father of Q.)
D.iii D > odiam( (Q.symbols)), and Q is the root. Apply operation (6).

2

Lemma 25: Let A = fa1 : : : ak g be a nite set of points whose diameter has order-ofmagnitude D. Then there exists a point u such that, for i = 1 : : : k, od(u; ai ) = D.
Proof: Let b1 = a1 . By axiom A.8 there exists an innite collection of points b2 ; b3 : : :
such that od(bi ; bj ) = D for i 6= j . Now, for any value ai there can be at most one value bj
such that od(ai ; bj )  D; if there were two such values bj 1 and bj 2, then by the om-triangle
inequality, od(bj 1; bj 2 )  D. Hence, all but k dierent values of bj are at least D from any
of the ai . Let u be any of these values of bj . Then since od(u; a1 ) = D and od(a1 ; ai )  D
for all i, it follows that od(u; ai )  D for all ai . Thus, since od(u; ai )  D but not od(u; ai )
 D, it follows that od(u; ai) = D. 2
Lemma 26: Let T be a cluster tree; let be a valuation over om-space 
 satisfying T ;
and let T 0 be an extension of T by x. If 
 is dense and unbounded above, then there is a
value a such that the valuation [ fx ! ag satises T 0 .
Proof: For operations (1) and (2) the statement is trivial.
Otherwise, let L be an extending label of T . If L = 0, then set D = 0. If L is in T ,
then let D be the order of magnitude corresponding to L in T under . If L1 < L < L2
where L1 and L2 are labels of consecutive values in T , then let D1 and D2 be the orders of
magnitude corresponding to L1 , L2 in T under . Let D be chosen so that D1  D  D2 .
If L is greater than any label in the tree, then choose D to be greater than the diameter of
the tree under .
If T 0 is formed from T by operation (3), then using lemma 25 let a be a point such that
od(a; (y)) = odiam(N ) for all y in N .symbols.
If T 0 is formed from T by operation (4), then let a be a point such that od(a; (y)) =
D.
If T 0 is formed from T by operation (5), then let a be a point such that od(a; (y)) =
D for all y in C .symbols. (Note that, since M .label < N .label, D < odiam(N .symbols).)
If T 0 is formed from T by operation (6), then let a be a point such that od(a; (y)) =
D for all y in R.symbols.
In each of these cases, it is straightforward to verify that [ fx ! ag satises T 0 . 2
As we observed in Section 8 regarding lemma 28, the conditions on 
 in lemma 26
are necessary, and the statement is false otherwise. For example, let 
 be the om-space
described in example I, Section 3, of polynomials over an innitesimal Æ. Then 
 is not
unbounded above; there is a maximum order-of-magnitude O(1). Let T be the starting tree
of Figure 3 (upper-left corner), and let T 0 be the result of applying operation 6 (middle
bottom). Let be the valuation fu ! Æ; v ! 2Æ; w ! 1g. Then satises T , but it cannot
be extended to a valuation that satises T 0 , as that would require x to be given a value
such that od(v; w)  od(x; w), and no such value exists within 
. The point of the lemma

36

Order of Magnitude Comparisons of Distance

is that, if 
 is required to be both dense and unbounded above, then we cannot get \stuck"
in this way.

Lemma 27: Let T be a cluster tree. Let X be a variable not among the symbols of T .
Let  be an open formula in L, whose free variables are the symbols of T and the variable
X . Let  be the formula 9X . Let 
 be an om-space that is dense and unbounded above.
Then there exists an instantiation of T in 
 that satises  if and only if there exists an
extension T 0 of T and an instantiation 0 of T 0 that extends and satises .
Proof: Suppose that there exists an instantiation of T that satises 9X . Then, by
denition, there is a point a in 
 such that satises (X=a). That is, the instantiation
[ fX ! ag satises . Let 0 = [ fX ! ag. By lemma 24, the cluster tree T 0
corresponding to 0 is an extension of T .
Conversely, suppose that there exists an extension T 0 of T and an instantiation 0 of T 0
satisfying . Let be the restriction of 0 to the symbols of T . Then clearly satises the
formula 9X . 2
Lemma 28: Let T be a cluster tree. Let  be an open formula in L, whose free variables
are the symbols of T . Let 
 be an om-space that is dense and unbounded above. If one
instantiation of T in 
 satises  then every instantiation of T in 
 satises .
Proof: We can assume without loss of generality that the only logical symbols in  are :
(not), ^ (and), 9 (exists), = (equals) and variables names, and that the only non-logical
symbol is the predicate \much closer". We now proceed using structural induction on the
form of . Note that an equivalent statement of the inductive hypothesis is, \For any formula
, either is true under every instantiation of T , or is false under every instantiation of
T ."
Base case: If  is an atomic formula \X = Y " or \much closer(W; X; Y; Z )" then this
follows immediately from corollary 4.
Let  have the form : . If  is true under , then is false under . By the inductive hypothesis, is false under every instantiation of T . Hence  is true under every
instantiation of T .
Let  have the form ^ . If  is true under then both and  are true under . By
the inductive hypothesis, both and  are true under every instantiation of T . Hence  is
true under every instantiation of T .
Let  have the form 9X . If  is true under then by lemma 27, there exists an
extension T 0 of T and a instantiation 0 of T 0 such that  is true under 0 . By the inductive
hypothesis,  is true under every instantiation of T 0 . Now, if 0 is an instantiation of T 0
that satises , and  is the restriction of 0 to the variables in T , then clearly  satises
9X . But by lemma 26, every instantiation  of T can be extended to an instantiation 0
of T 0 . Therefore, every instantiation of T satises . 2
Theorem 4: Let T be a cluster tree. Let  be an open formula in L, whose free variables
are the symbols of T . Let 
 be an om-space that is dense and unbounded above. Algorithm
decide(T; ) returns true if T satises  and false otherwise.
Proof: Immediate from the proof of lemma 28. 2

37

Davis

References
Cormen, T.H., Leiserson, C.E., and Rivest. R.L. (1990). Introduction to Algorithms. Cambridge, MA: MIT Press
Davis, E. (1990). Order of Magnitude Reasoning in Qualitative Dierential Equations. In
D. Weld and J. de Kleer (Eds.) Readings in Qualitative Reasoning about Physical Systems.
San Mateo, CA: Morgan Kaufmann. 422-434.
Keisler, J. (1976). Foundations of Innitesimal Calculus. Boston, MA: Prindle, Webber,
and Schmidt.
Mavrovouniotis, M. and Stephanopoulos, G. (1990). \Formal Order-of-Magnitude Reasoning in Process Engineering." In D. Weld and J. de Kleer (Eds.) Readings in Qualitative
Reasoning about Physical Systems. San Mateo, CA: Morgan Kaufmann. 323-336.
Raiman, O. (1990). \Order of Magnitude Reasoning." In D. Weld and J. de Kleer (Eds.)
Readings in Qualitative Reasoning about Physical Systems. San Mateo, CA: Morgan Kaufmann. 318-322.
Robinson, A. (1965). Non-Standard Analysis. Amsterdam: North-Holland Publishing Co.
Weld, D. (1990). \Exaggeration." In D. Weld and J. de Kleer (Eds.) Readings in Qualitative
Reasoning about Physical Systems. San Mateo, CA: Morgan Kaufmann. 417-421.

38


	
 
			 ! #"$ % 
'&)( *,+( ---/.$0/1/243022

56789  :)((4;
-<!=?>7	%&:A@/;
--

BDC9EFCHGJIHK9LNMPOJQRC
SUTWVYX[Z\Z^]`_ba/]dcfe9gihjRkmloniprqWets
~

Znqprh6qW

lvuwZ^x9Vy]znWuwV|{|V,a}Wj

Z^]VFaj

$$r#

 $¡$¢£¤ $¥£

'¦§¦§©¨«ª9¨,¬­'H®¯°

±£²6³£ $¡$¢£¤ $¥£

´µ­¶·¸·¹º·'»)¼½¾°¼¿FÀ§¹º·¤»ÁAÂÃ¸»/µÃÄ»
ÅÆ»AÇ)»!ÈÁ4»/ÉUÊµ­¸Ë»/Á
¶¸·Ì
ÍÎÍÏÐÑ »Á¹¶ÒÓ¥»¿)Ô´¶Á4Ò»Ó

Õ×ÖÙØÚºÛÜwÝ§Ú
Þ,ßÙàáß,ß4âãà9äzåÄæ6çæäéè4êìëí§îá?äëï¥îJð§ãå4èÄáäèAÞyñyð­å4ãòê¥æ6îßFåÄæ6óéôïìå4æ«ç/ãô­äèÄï¥ä­õ\èÄâæ«äôî«òmæ6å,ãö
îJãº÷ºæêøßã?öFð­å4ãðmãéß ï¥è4ïìãä­áêHöùãå4î«ôêøáß6úüûýâ­æiðåÄãò­ê¥æ6îfãö,ç/ãôäéè4ïìäõîãº÷ºæ6êìßãö,ß ômç
âþöùãåÄî)ôêøáß«ïøßí
áçç/ãåÄ÷ï¥äõAèÄã«ð­å4æ!ß æ6äè#ÿéä­ãà9ê¥æ!÷ºõæíç/ãîJðôºèÄá?è4ïìãä­áê¥êìëJï¥äéèÄåÄáçèÄáòêìæyï¥äiátàãå
ßè#ç6áß4æúýáß4æ6÷ãäè4âæ
 á ïìß Hôºè4ämá?îoðå4ãºçæ6÷ºôåÄæíà#æ,ðåÄæ6ß4æäéè#á?äiá?êìõãåÄï¥è4âîW
í 	  ríè4â­á?èýçãîJðôºèÄæ6ßwèÄâæÙæ áç/èHäôî)ò§æå
ãöÙîJãº÷ºæêøßãöAáðåÄãð§ãß4ï èÄï¥ãä­á?
ê 	vãå   öùãå4î«ôêø
á «
ú $æ/è ¿
á?äm÷ µ òmæWèÄâæäôî)ò§æå^ãö
çêìáô­ß æ!ß9á?ä­
÷ á?åÄïìáòêìæ6ßã?
ö «íåÄæ6ß4ðmæ!çè4ï æ6ê¥ëíá?ä­÷iêìæ/è À ÷ºæ6äã?èÄæAè4âæ ðåÄãòmá?òïìê¥ï¥èëJè4âmáèFáJêìï èÄæå
á?ê Ó ãö
 ãºçç/ô­åÄßïìäJáAçêìáô­ß æ ¾ ã?ö «íè4â­æäè4âæyá æå
á?õæHåÄôääïìäõÙè4ïìîJæ9ã?ö 	  üïøßwß âãà9ä«è4ãAò§
æ !#"$í
à9âæ6å4&
æ %('*)
+,
úAûýâ­æ«ðå
áç/è4ïøçáêð§æå4öùãåÄîá?ä­çæ)ã?:
ö 	   â­áß,ò§ææä©æ6ß è4ïìîáè4æ!÷zïìäáiß æ6å4ïìæ6ß

- .0/2143 ,5+764829

ãöæ4ð§æåÄïìîæ6äéèÄßýãäWáà9ïì÷æ;áå4ïìæ/èë\ã?ö<	þöùãå4î«ôêìáßú

=<>!?A@ ÚºÛ7B:CDFÝ§Ú7EFB @
G HJILKNMPORQTSULQU7VHJWHU7MTOLXLYZULS4[\XO&]^HMP_a`&bcULS:d`Rbfe
U7MK;[gONhjifOLMkWlW5URmnMUoipirqO
WHVWqKaMk\[jsKtS

uvwx ULYHJWV;[!UnyKNXVtezWqTO
W{HVteOLVV4HJ|7MT[!KNMkWVaULYW5S4\TWq}I
OLX\KNVaW5UgHWVaIAO
S4H~O
sXJKNVWqTO
W{VO
WHV5YZh]PT{qTHV
QTSULsXJKN[ULY4LzkgNqTOLVMz\T[!KtS4U7\TVO
QTQXHtO
WHU7MTV v ULWq<ePNLL x OLMkh^H[gQULS4WOLMW
R QTSULsXJKN[gV}SKN k\HJSK¡U7\TMWH~M|¢[!UzyTKNXV£ULY(QTSULQU7VHWHJU7MTOLX{YZULS4[(\TXOLV¤ULScO
SK¥SKNy\TtHJsXJK¦W5U¢WqTHV
QTSULsXJKN[  [!U7M|¥WqKNVKQTSULsXJKN[£VO
SKL§ v O x _aU7[!Q\WHMT|yKt|LS4KtKULYrsKNXHJKtYrH~M¨O¡QSULQU7VHJWHJU7MTOLX
V5WO
W5KN[!KNMkWf©{irHJWqPSKNVQKNW:W5UOQTSULQU7VHJWHJU7MOLXmnMUoiRXJKNy|LK;sOLV5K{ª¡«¬OLV­O®U7MTyHJWHJU7MTOLXzQTSULsO
sHXHJW¯h
ULY©®|7HJILKNMª¡«}  M¤WqK®O
sV5KNMTKULYOPV\°}tHJKNMkWfV5WO
WH~V5WHtVaWqTHVfQTS4ULsO
sHXHWh!tOLMsKRKNV5WH~[gO
W5KNyskh
± uv ª¡«²´³µ©7¶ x ±·± uv ª¡« x ±  v s x  MYKtS4KNMTK;HMP¸fOohLKNVHOLM!sKNXHKtYMKtWifULSmnVt  V  ULWq v NLL x VqTUoifKNy<e
WqK;QTS4ULsXJKN[¬ULY<U7\TMkWHM|´[!UnyKNXVlULYO®QTSULQU7VHWHJU7MTOLXkYULS4[(\TXO®tOLMgsK;S4KNyT\TKNy!W5U´WqTK;QTSULsXJKN[¬ULY
U7[!Q\TWHM|(WqKQTSULsO
sH~XHJWh!WqO
WaOPMUnyK®HM¤O!¸aONhLKNVHOLMcsKNX~HJKtY¹MKtWifULSmHVfW5S4\KL v  x _fU7[gQ\WHM|
WqK¥Mz\T[jsKtSULYVU7X\WHJU7MTV}ULYO¢U7MV5W5S4OLHMkWVO
WHV5YOLWHJU7MºQTSULsXJKN[  _a`&b*YULS4[(\TXO w U7M^»
I
O
S4HO
sXJKNV¤¼ (½t¾t¾t¾µ½ ¼¿À[£ONh^sK¡SKt|7O
SÁyKNyÂOLVO¢U7MTV5W5S4OLH~MWVO
WHVYZOLWHJU7MºQSULsXJKN[ÃHM^irqTH~4q^WqK
yU7[gOLH~M£ULYKNOL4qI
O
S4HO
sXJK&HVR³oÄ ½ A¶7eOLMTy}KNOL4qctX~OL\TV5K´ÅÆHVO(SKNX~O
WHJU7M}Ç¬ÈÉ³oÄ ½ A¶ ¿ ULYOLX~XMnÊFW\TQXJKNV
YZULSirqH4qËO
WPXJKNOLV5WU7MKXHJW5KtS4OLX:ULYRÅÌOLVV4\T[!KNV´WqTK}I
OLX\K¦
Í{qKNMËWqTK£QTSULsXJKN[ÎULY{U7[!Q\WHM|
WqKMk\[jsKtSjULY{VU7X\WHJU7MTVjULYrV\TÁqÏQSULsXJKN[gVHV´WqTK}U7MK¤ULY{U7[!Q\TWHM| uvw(x  v y xjÐ V5WH~[gO
WHM|
WqK®\WHX~HJWhgULYSKNOLV5U7MTH~M|PirHJWq¤O
QTQTSUoÑnH[£O
W5K®WqKtULSh}ÒrÓÔHMTVW5KNOLy}ULYWqKULS4HJ|7H~MTOLXWqTKtULSh£Ó­{qTHV
\WHX~HJWh¤yKtQKNMTyTVfU7McWqK´V4HJÕtK®ULY ± uv Ò{Ó x ±
Ö^± uv Ó x ± v ULWq<eNLL x 
 MULWqKtSlH[!QULSWOLMkWO
QTQX~HtO
WHJU7MjH~V¹W5UrS4KNOLV5U7MTHM|RirHJWqHMTU7[!QXKtW5KHMYZULS4[gO
WHJU7M v G&SUoILKaKtWlOLX×Je
NLAØÙÚULÕNHMTV5mnHH×e<NLÛLzeNLLÜ x   MTyKtKNy<eTHYl]ÝyTKNVS4HJsKNV;O!SKNOLX¹iULS4X~yÂÞßYOLHJWqY\TXXJhLezWqKNM|7HILKNM¦O
YZULS4[\XO´àV\TÁq!WqTO
WMTKNHJWqKtSàMULSaá:à¤HV­O´XJUL|7H~tOLXU7MTV5KN z\KNMTKrULY¹]ezO®SKNOLV5U7MTO
sXJK{OLVV\T[gQTWHJU7M
HVaWqTO
WrWqKj[!ULSK´[gUzyKNX~V;ULY:]âOLVV5KtSW&àeWqTKj[!ULSK´XHmLKNXJh}HV{WqTO
WRàHV;W5S4\TK´HMÂÞ
ã

( ---§ %%ä!:Ät
:aåA/
fæw
!¥8y
ç§7!	%&%è­		&/%%~é/ :µè

ê

£R²ë­R¡TìÂíÝî±£²³££

{qTKcQTSULsXKN[ïULY´U7\TMkWHM|Ï[gUzyKNX~V£HV}ð!ñ:ÊU7[!QXKtW5KHM|LKNMKtS4OLX vZò OLXHOLMkWte´N7ó
 x eROLMTyôV5Ue
OLtULS4yTH~M|rW5UWqKQTSKNV5KNMkWVWO
W5KULYTWqTKfO
SWlHMjWqK­õKNX~y<eAU7[gQ\WO
WHJU7MTOLX~XJh®HMW5SÁOLWO
sXJKaHM´WqKfifULS4V5W
tOLV5KL{d\sU7HV v NLn x HMkW5SUnyT\TKNycOLMÍOLXJ|LULS4HJWq[öWqTO
WRYULS&OLMhYZULS4[(\TXO}]âULYl»ËIAO
SÁHO
sXJKNV{OLMyc÷
û
tXOL\TVKNVtekKNOLÁqctXOL\TVK&U7MkWOLHMTHMT|jøX~HJû W5KtS4OLXVtû ezU7\TMkWVf[gUzyKNX~VULY]ÆH~M£WH[gKù v ÷cú ¿û x enú sKNHM|WqK
QU7VHJWHJILK}SUzULW(ULYrWqKQU7XhzMU7[£HOLX:ü Ö ü ý ( ÖÔþtþtþTÖ  v ú
ÿ
 ¾   ½ 
ú   ¾ ÛAØ ½ ú 0
 ¾   ½t¾t¾t¾
û
û
OLMTy}XH[ 
	 ú   x   KNKNMWXJhLe qOLM| v NLL x QTSKNV5KNMkW5KNy¤OLM£OLXJ|LULS4HWqT[âsOLVKNygU7M¤VH[gHX~O
S­HyKNOLV
OLMTypirHWq¨V4H[gHXO
S(WH[!KU7[!QXJKÑnHWhLp{qKWH[!KcU7[!QXJKÑnHWhOLÁqTHJKtILKNy¢szh¨WqKNV5KcOLXJ|LULS4HWqT[gVPHV
OLM¡H[!QULSWOLMkWRH[gQTSUoILKN[gKNMW&UoILKtS®WqTO
W&ULYO¤MTOLHJILKPOLXJ|LULS4HJWq[ irqH4qÍ4qKN4mzV´OLX~XOLVVH|7MT[!KNMkWVRULY
W5S4\WqcIAOLX\TKNVaW5UgWqK´I
O
S4HO
sXKNVaULYlOPYZULS4[(\TXO£]âHMWH[!Kù v 
÷ ¿ x
UV4O
WHV5YZh¥QTS4OLWHtOLXfO
QTQXH~tO
WHJU7MTVteU7MKqTOLVjKNHWqKtSW5USKNV5ULS4WW5U¡O¦|LUzUn
y 2 LZ
 7
ÂULY
&
e
L
U
c
S
T
\
5
V
¥
K
L
O
º
M
L
O
J
X
L
|
L
U
4
S
J
H

W

q
[
Z
Y
L
U
c
S


7
U
!
[

Q
T
\

W

H

M
|






N





À

r
i
J
H

W
º
q
¨
O

S
N
K
L
O
5
V
7
U

M


O

s
J
X
K








 okËWH[!K
uvwx
uvwx
U7[!QXKÑnHJW¯hL
 Kt|7O
S4yTHM|WqK¤õS4VWOLXJW5KtS4MO
WHJILKLeÚ\TskhÏOLMy ò KNX~"H ! mLUoInH  # v NLn x QTSKNVKNMW5KNypO¡yKtW5KtS4[gH~MTHV5WH
OLXJ|LULS4HWqT[ÉYZULSO
QQTSUNÑH[gO
WH~M|{WqKQTSULQULSWHJU7M®ULYW5SÁ\WqjOLVV4HJ|7MT[!KNMkWVWqO
WVO
WHVYh´ORd&`&bcYZULS4[(\TXO
¿
]Ú¹Kt%
W $´'ø & )
w ( yKNMULW5K´WqTH~VaQTSULQULSWHJU7M v $®*ø & +
w (  uvw(x ·  iRqKtSKPH~VaWqK´Mk\[jsKtS;ULYIAO
S4H~O
sXJKNV
ULY] x G®HJILKNM}V4[gOLXXTMz\T[sKtSÁV , /½ .10 ÄnenWqK&OLXJ|LULS4HJWq[ U7[!Q\TW5KNVOLM}KNV5WH[gO
W53
K 2ÉUL4
Y $´'ø & )
w ( irqTH~4q
VO
WHV5õKNV
v  Ö . x $®*ø & +
w ( Ö ,6587958$®*ø & +
w (;: , ¾
ÚKtW£ OLMTy¢sKgWqTK}Mz\T[jsKtS´ULY{tX~OL\TV5KNV(OLMTyËI
O
S4HO
sXKNV®ULYR]eSKNVQKNWHILKNXJhL{qK£SÁ\TMTMTHMT|
WH[!K®ULYlWqK´OLX|LULS4HJWqT[öH~VaKNV5WH[gO
W5KNy¦skhO!QU7XJhnMU7[gHOLXHM¡¥OLMTy¥ [(\TXJWHQXHJKNy}skh
»=<

/?> +ì	A@BDC	@EF> .¤+¥		;BGC	-F> C	H?> .. ¾
+

IzUeTWqTK®S4\TMTMTH~M|WH~[!K®ULYWqTKjOLXJ|LULS4HJWq[|LSUoirVrYZOLVW{irHJWqWqK®QSKNtHVHJU7MS4KN k\THSKNy<
ÚHMTHOLXTOLMy}`&HVOLM v NL
Ä x V5W\TyTHKNygWqK&QTSULsXKN[âULYU7[!Q\WHM|´WqTK&VHÕtKRULY¹O(\TMTHJU7M£ULYO|7HJILKNM
YOL[gHXJh}ULYV5KtWV+J ( ²KJ ÿ² þtþtþ ²KJ B szh¤[gKNOLMTV{ULYWqK  MTtX\TV4HJU7MnÊ Ð ÑtX\TV4HJU7MgYZULS4[(\TXO
B
± L J M±  P
± J M ±PÖ
± J M'W J U ± :
± J MW J UHW J Y ±(ÖÀþtþtþ
P
P
MO#N (
(RQ*MSQ*B
(RQ*MSTVUQ*B
(RQ*MSTVUXTYZQ*B
: v Ö  x BG#C ( ± J ( W þtþtþ W J B ± ¾
g
vx

 qTKth¤VqTUoifKNyWqTO
W{WqK´V4HJÕtK®ULYlWqK´\TMTHJU7MtOLM¦sK®O
QTQSUNÑH[gO
W5KNycOLtt\TS4O
W5KNXJhirqKNMWqK´V4HJÕtKNV
{
ULYaU7MTXJhÍQO
SW®ULYaWqKgV5KtWjH~MW5KtS4VKNWHJU7MTV´O
SK£mzMUµirM<[In\TQTQU7V5KPWqKgHMkW5KtS4V5KNWHJU7MVHJÕtKNV´O
SK!mnMUµirM
YZULS(OLXXV\sTYOL[gHX~HJKNV®U7MWOLH~MTHM|¦O
WP[!U7V5]
W \ËV5KtWVt  _
Y ^a`9b dv c ÷ x elWqKNMÏWqTK}\TMTHU7MËVHJÕtK¤tOLMsK
O
QTQTS4UNÑH[gO
W5KNyirHWqO!SKNXO
WHJILK®KtS4SULS{ULYù fv e ý ÿ YhgRi B x 
 V!ÚHMHOLXOLMTyp`&HVOLM v NL
Ä x QU7HMkW5KNyÏU7\TWte­WqTHV(SKNV\XJWtOLMpsKO
QTQXHJKNyW5U¥O
QTQTSUoÑnH~[gO
WHM|
WqK!Mz\T[jsKtS&ULY[!UnyKNXVRULYOd`&bÀYZULS4[(\TXOk
] j KNOL4qÏtXOL\TV5K(ULYa] qTOLVHJWVV5KtWULYf[!UzyTKNXVte<OLMTy
W \W5KtS4[gVRULY­WqK
uvwx HV{KN z\TOLXW5U}WqTK(VHÕtKjULY­WqK(\TMTHJU7M¦ULY­OLXX¹WqTU7V5K(VKtWVtR{qz\TVteU7MTXJhWqKjõS4V5l
YZULS4[\XO v  x O
SKRMTKtKNyKNy£YZULSaO´|LUzUzy¤O
QTQTSUoÑnH~[gO
WHJU7M<ekirqKtSK c m
÷ 5n^o5÷¥q
 pRUoifKtILKtSNeYZULSfOqTHJ|7q
QTSKNtH~VHJU7M<re \¤O
QQTSU7OL4qTKNV´PbULS&HMTV5WOLMTKLeYZULS{÷  tÄLÄ}OLMTycOLMKtS4SULS{ULYatÄ ý  e ^]sAØ ¾
 ifOL[£O v NLÛL x H~MW5SUnyT\TKNy!OLM£OLXJ|LULS4HJWqT[âYULS­W5KNVWHM|jVO
WH~V2õO
sHX~HJWh´ULY<Oj_a`&b¡YZULS4[\XOj]ºUµILKtS
»^IAO
S4H~O
sXJKNV(skhU7\TMWH~M|¡WqKW5S4\WqpOLVVHJ|7M[!KNMWV(YOLXVHJYZhnHM|¡] OLMy¨ÁqKNmnHM|ËHY;WqKNHJS!Mk\[jsKtS
HVXJKNVVWqOLt
M  ¿ {qK¥U7\TMkWHM|¢HVOLtU7[!QXHVqKNy^WqS4U7\|7qºOLM  MtX\TVHJU7MÊ Ð ÑtX\TVHJU7MQTSUnKNVVte
irqKtS4K´WqKjVHÕtKjULYlWqKVKtWrULYlW5S4\WqÍOLVVHJ|7MT[gKNMWVrYZOLXV4HJYhnHM|£]âHVrU7[!Q\W5KNycirHWqWqKOLH~yULY:WqK
ULsV5KtS4IAO
WHJU7MWqO
W;WqTHV;V5KtW{HVaWqTK\MTHJU7M¤ULYWqTK´V5KtWV;ULYW5SÁ\WqOLVVHJ|7M[!KNMWVaYOLXVHYhnHM|KNOL4q¦tX~OL\TV5K

uwvXx

y w z£ùR{d|,¡'}R²Rì8|,±§~¡$R]w­lÙ±¡$²'}R£²3 ± ~
ULYR](  iaOL[gO¦OLMOLXJhkÕtKNyÏWqK£OoILKtS4O
|LKS4\TMTMTH~M|WH[!KgULY{qTH~V´OLXJ|LULS4HJWq[ U7MËWqK¤VOL[!K}YS4OL[gKtiULSm
OLV®ifKgyTHyÍYULSjWqK!OLXJ|LULS4HJWqT[ ifK!QTSKNVKNMW®HMWqKgV5KN z\KNX×prKgV4qUoifKNy¥WqTO
W®YZULS´O¦_a`&bôYZULS4[(\TXO
Ö  ÿ »:e<irqKtSK(»¢HV&WqK
VO
WHVYhnHM|¤WqK!U7MTyTHJWHU7MÍWqO
W&YZULS´OU7MTV5WOLMkl
W Ae¹V\TÁq¡WqTO
W®X6
M ` X~Ma÷ 
Mz\T[jsKtS­ULYI
O
S4HO
sXKNVte÷ H~V:WqKrMz\T[sKtSULY¹tXOL\TV5KNVtezOLMTy  HV:WqKRQTSULsO
sHXHJW¯h´WqTO
WOj|7HJILKNM£X~HJW5KtS4OLX
O
QTQKNO
S4V{H~MOgtXOL\TV5K v WqKjVOL[!KjYULS&OLXX<XHJW5KtS4OLX~V x eWqKjOoILKtS4O
|LKSÁ\TMTMTHMT|WH[gK®ULYWqTKjOLXJ|LULS4HJWq[öHV
ù vK
÷  C#( x 
ÚULÕNHMTV5mnHH v NL  x KN[!QXJUµhLKNy¢OLM¨OLX|LULS4HJWqT[ irqTHÁqH~V(V4H[gHXO
SW5U¡WqTO
WPQTSKNV5KNMkW5KNy¨skh  iaOL[gO
v NLÛL x eYZULSPU7\TMWH~M|Í[!UnyKNXVNK
 prKVqUµiKNyWqTO
WP\TMTyKtSSKNOLV5U7MTO
sXK}OLVV\[!QTWHJU7MTVNeWqK¤ONILKtS4O
|LK
S4\TMMTHM|gWH~[!KULYfU7[!Q\WH~M|}WqTKKÑOLW´Mk\[jsKtSULY[!UnyKNXV&ULYO¤YZULS4[\XO£iRHJWqÏÎtX~OL\TV5KNV&U7Mp
I
O
S4HO
sXJKNV;H~Vrù v ÷  » x eTirqTKtS

K   ù v XJUL|÷ x 
 M¤WqK&VKN k\KNXifKQTSKNV5KNMkWfOLMOLX|LULS4HJWqT[*irqTHÁq£ifK®tOLXX¹_adñ v _fU7\TMkWHM|(skh}d&OoIzH~V2Êñ\WMOL[ x
YZULSPU7[gQ\WHM| uvwx QTSKNtHVKNXJhL  XJ|LULS4HJWq[ _adñÝHVsOLV5KNy¨U7M¨WqKdONInHV2Êñ\TWMTOL[ QTSUnKNyT\SK
V  ñ\WMOL[e´NL
Ä x YULSV5U7XJInHM|ÏWqKV4O
WHV2õO
sH~XHJWh¨QTSULsXJKN[ v I   x  ¥K¥V5W\TyTh
v dññ x¦v dONInHK
YZKNO
W\SKNVgULY®dññefOLMTyVqUµiÌqUµiÌHJWVgS4\TXJKNVgtOLMÀsKc[!UzyH õKNy<eSKNV\TXJWH~M|¥HM¢OLMÀOLXJ|LULSÁHJWqT[ YZULS
U7\TMkWHM|c[!UnyKNXVN  MËOLMTOLXJhnVHVVqTUoirV®WqO
W´YULS´OcYULS4[(\TXOc] iRHJWqp tXOL\TVKNV®U7M¢¨IAO
S4H~O
sXJKNVte
y HV­WqK{QTSULsO
sHXHJW¯h
WqKrOoILKtS4O
|LKS4\TMTMHM|&WH[!K{ULY_adñ¨HVù v K
÷ » x ekirqKtS
K   	 ý +( ( . ezOLMT
ý


@
WqTO
WrOLMkhXHJW5KtS4OLXUntt\S4VrHMOP|7HJILKNM¦tX~OL\TV5KL
IzKNWHU7MpÜÍyKNVSÁHJsKNVMz\T[!KtSU7\V´KÑnQKtSÁH[!KNMkWVjirHWqp_adñÝVqTUoirHMT|¦WqTO
W!HJWV(OLW\TOLXaONILKtS4O
|LK
WH[!KcU7[gQXJKÑHJWhpHVgVH|7MTH õtOLMkWXJhÏXJUµiKtS}WqTOLM¢WqKÍ\QTQKtSPsU7\MTyTV(QTSUµIzHyTKNypskh¢[gO
WqKN[£O
WHtOLX
OLMTOLXJhnVHV®H~
M IzKNWHJU7
M cOLMTyËHM¡QTS4KtIzHJU7\ViULSmnV v d\sU7HVteNLn
Ù  iaOL[gOneaNLÛLzÙ­Ú¹ULÕNHMTVmzHHFe­NL zÙ
qTOLMT|e¹NLL x - ¥KjOLX~V5U!QU7HMW;U7\TW{OLyIAOLMkWO
|LKNVRULYWqTH~V{MKtiÉOLXJ|LULS4HWqT[ UoILKtSRWqK´U7MKNV{QTSKNV5KNMkW5KNy
HM£WqKNV5KQTSKtInHJU7\TViULSmnVt­blHMTOLX~XJhLeifKRKNVWH[gO
W5KNyc_adñpQKtSYULSÁ[gOLMTKrU7M}YZULS4[\XOLViRHJWo
q µÊX~HJW5KtS4OLX
tXOL\TVKNVteOLMTyU7[!QO
SKNy¤WqKSKNV\XJWVW5UPWqU7VK&ULY4qKN4mzH~M|PWqK®VO
WHV2õO
sHXHJW¯h(ULYV\T4qYZULS4[(\TXOLVskh
dññÀQTSKNV5KNMkW5KNycszh¤HJWÁqKNXX<KtWrOLXF v NL  x 
Õ ¹B°ÛEÚ-
2B°Û}BD
l> 

@ Ú7E @



B:Cq 4Ø


M WqKjV5KN z\KNX<ifKjU7MTV4HyKtS;QTSULQU7VHWHJU7MTOLXYULSÁ[\TX~OLV;UoILKtSOgV5KtW¢¡  ³N¼ (N½t¾t¾t¾N½ ¼¿¶jULYIAO
SÁHO
sXJKNVte<
yKNMULW5KNVROgXHJW5KtSÁOLX v"£E¤ ³N¼ (N½t¾t¾t¾N½ ¼¿ ½¼ ¥ (½t¾t¾t¾µ½¼¥ ¿¶ x eOLMTy £ ¥ V5WOLMyTV;YZULS{WqK´MKt|7O
WHJU7M¦ULY¯

¦ fª §©¨ªH¦«þ¬H®h­/®i4¯#°®^é¬²±¦V³ý#¦

{qK¥dONInHV2Êñ\WMTOL[ÃQTS4UzKNyT\TSK v dññ x¡v dONInHV ñ\TWMTOL[ePNL
Ä x HVHMkW5KNMTyKNy^YULScyTKNtHyTHM|
VO
WHV5õO
sHXHWhULYOQSULQU7VHJWHJU7MTOLXl_a`&bôYZULS4[(\TXO] v SKt|7O
S4yTKNy¥OLV®OV5KtW®ULYtXOL\V5KNV x eOLMTy¡tOLM¥sK
QTSKNVKNMW5KNycOLVRO!SKNt\SÁVHJILKsUkU7XJKNOLMcYZ\TMWHJU7M v OLVV\T[£HM|PWqTO
WrMUgtX~OL\TV5K´ULY­]ÝHV;OgWOL\W5U7XJUL|Lh x §
YZ\TMWHJU7Mdññ v ]P§QTSULQU7VHWHJU7MTOLX<_a`RbpYZULS4[(\TXO x Ù

rHY w ~H VaKN[!QTWhWqKNM
SKtW\S4MË"#Ù
zrHY:]¬U7MkWOLHMTVROLMKN[!QTW¯htXOL\TV5K®WqKNM
SKtW\S4
M ´
ttÙ
z vdµ {qK®Q\S4K´XHJW5KtS4OLXS4\TXK µAx
HYWqKtS4K®KÑnHVWV{O!Q\S4KX~HJW5KtS4OLXllHM¦] vdµ V4\T4qWqO
W £¥ yUkKNVrMULWrO
QTQKNO
SrHM¦] Aµ x WqKNM
w (  ³AÅ ± Å ¤Íw ½ £D¤ ¶ Å(¶7Ù dv µ yKNXJKtW5K´YZSU7[Ì]¬OLX~X¹tXOL\TV5KNVrU7MWOLHMHM| µAx
SKtW\S4Mcdññ vw ( x Ù dv µ ]ÝH~V;VO
WHV2õO
sXJK´¸H · w ( HV{VU µAx

uwvX¹

ê

£R²ë­R¡TìÂíÝî±£²³££

Ø dv µ {qK´\TMTHWatX~OL\TV5K®S4\TXK µAx
HY:]¬U7MkWOLHMTVROg\TMTHWatX~OL\TV5KP³ £ ¶ vdµ OgtX~OL\TV5K´U7MTVH~V5WHM|PULY:O!VHM|7XKX~HJW5KtS4OLX µAx WqKNM
w (  ³AÅ Ö ³ £¥ ¶ ± Å ¤¦w ½ £G¤ ¶ Å(¶7Ù vdµ yKNXJKtW5K´YZSU7[ ] £¥ OLMycOLXX<tXOL\TVKNV{U7MWOLH~MTHM| Aµ x
SKtW\S4Mcdññ vw ( x Ù dv µ ]ÝH~V;VO
WHV2õO
sXJK´H¸· w ( HV{VU µAx
Üz vdµ {qK´V5QX~HJW5WHM|(S4\TXJK µAx
ÁqUzU7V5KOPI
O
S4HO
sXl
K cULY](Ù
Ö
±
A
³
Å
³

¼
¶
w ( 
¥ ± Å ¤¦w ½ ¼ ¤ ¶ Å(¶7Ù
Ö
ÿ
A
³
Å
N
³
¹
¼
¶ Å ¤¦w ½ ¼ ¥ ¤ ¶ Å(¶7Ù
w 
S4KtW\S4M v dññ vw ( _
x º dññ vw ÿ x5x  dv µ ]ÝHV;VO
WH~V2õO
sXJK®¸H · vw ( ºw ÿ x HV;V5U µAx
 WrtOLMcsK´V5KtKNM¦WqTO
W{WqKjQ\SK®XHJW5KtSÁOLXS4\TXJK´OLMTycWqK´\TMTHJW{tX~OL\TV5K®S4\TXKO
S4KjOLW\TOLXXJhQO
S4WHt\TXO
S
tOLV5KNVaULY¹WqTKVQXHJW5WHMT|´S4\TXJKL  Y¹WqKtSKKÑHV5WVfOQ\SKRX~HJW5KtS4OLXHM]­enOLMTy¤WqKV5QXHW5WHM|´S4\XJKRÁqUkU7VKNV
eWqKNM w ( È w ÿ
e¹OLMTy¥qKNMK vw ( ºÍw ÿ x HV®VO
WH~V2õO
sXJKP¸H · w ( HVV5U  tULSÁyTHM|W5UcWqK!V5QXHJW5WHM|
S4\TXKLez]ÉH~VVO
WHV5õO
sXJKr»H · vw ( ºjw ÿ x HVV5UenOLMTy£qKNMKLen]ÔHVVO
WH~V2õO
sXJKR¸H · w ( H~VV5U­{qHV:HV­KÑOLWXJh
WqK´Q\SK®XHJW5KtS4OLXSÁ\TXJKL
 Y&] U7MkWOLHMTV!O\TMTHJW(tXOL\TV5K³ £ ¶7eOLMTy¨WqKV5QX~HJW5WHM|cSÁ\TXJK}ÁqUzU7V5KNVeWqKNM w ÿ U7MWOLH~MTV!OLM
KN[!QTW¯htXOL\V5K v WqK\TMHJWtXOL\V5K}iRHJWqU7\W(HJWV(U7MTXJhËXHJW5KtSÁOLX x e:OLMTypV5Ue­HV(\TMTVO
WHV5õO
sXJKL
 IzUe] HV
VO
WHV5õO
sXJK!¸H · w ( H~V®V5U£{qTH~V®HVWqKg\TMTHWtX~OL\TV5K!S4\TXKL v  MTtH~yKNMWOLX~XJhLe<WqK£V5QXHJW5WHM|¤S4\TXK(W5S4KNO
WV
ifKNXXWOL\TW5U7XJUL|7HtOLX:tXOL\TVKNVrW5UzU  Y­OtXOL\V5
K ¼âULYf]*U7MWOLHMV&OXHW5KtS4OLX­OLMyÍHJWVU7[!QXJKN[!KNMkW £¥ e
OLMTyWqTK´V5QXHJW5WH~M|SÁ\TXJK®HV{O
QTQXHJKNy¤W5UceTWqKN8
M ¼ irHX~XsK®KtS4OLV5KNy¦YS4U7[ sULWq w ( OLMTy w ÿ
 x
{qz\TVteAifKf[gOoh´U7MTVHyTKtSdññ¥OLVsKNHM|{sOLVKNy´U7MWqKfVQXHJW5WHMT|fSÁ\TXJK­U7MTXhLeAiRqTHXJK:WqKWifUULWqKtS
S4\TXKNVV5KtSILK®OLVf|7\THyTKNVYZULS;4qUzU7VHM|(OX~HJW5KtS4OLXK°}tHJKNMkWXJhL  MyKtKNy<enHJY]ÆU7MWOLHMVfO(\TMTHWtXOL\TV5K³ £ ¶
ULSO®Q\SK{XHJW5KtSÁOLXe7WqTKNMgO
QTQXJhnHM|WqK{VQXHJW5WHMT|&SÁ\TXJKaW5UghzHJKNX~yTVU7MTXJh
RYZULS4[\XOneLs\W­ÁqUkU7V4HM|
OgMU7MÊFQ\SK®OLMTycMTU7MnÊ\TMTHJW2ÊtX~OL\TV5KXHJW5KtS4OLX<XJKNOoILKNVrW¯iU}YULSÁ[\TX~OLVaYULS{Y\SWqTKtS;QTSUnKNVVHM|
 Y]ºU7MkWOLHMTV:MTKNHJWqKtS­O\TMTHJWltXOL\TVK{MULS:OQ\SK;XHJW5KtSÁOLX×e
WqKNMPWqK{XHJW5KtSÁOLXYZULS­WqK;V5QX~HJW5WHM|RS4\TXJK
VqU7\Xy¤sK®ÁqU7V5KNMcHMV4\T4qOPiaONhWqTO
W;QTS4UzyT\KNV;V5KtWV w ( OLMTy w ÿ&WqTO
WRO
SK´OLV{V[gOLX~XOLV{QU7V4VHJsXJKL
¥KOLyySKNVVaWqTH~V;HVV\K´H~MWqK´V5KN z\KNX×

¦ ª¾
¦ ½

r¯ À¿Áb¬²³¦§®

¬# é

{qTH~MmzH~M|ULYRU7\TMkWHM|¡[!UnyKNXVULYROÍQTSULQU7VHJWHU7MTOLX­YZULS4[(\TXO¥]­elifK¤MTULWHKWqTO
WPskhÏÁqUzU7VHM|¥O
I
O
S4HO
sXJK)LenWqK®V5QXHJW5WHM|S4\TXJK&OLW\TOLXXJh¤V5QXHWVWqK®V5KtWaULY[!UzyTKNXVfULYl]ÆHMkW5UPWifUgyTHVSÂ5U7HMkWV\sV5KtWVt§
U7MK!HMÍirqTHÁ
q ¥HV&W5S4\K v MTOL[!KNXhLe<WqK([gUzyKNX~VRULY w ( x eOLMyÍWqTKULWqKtS v [gUzyKNX~VRULY w ÿ x HMÍirqTH~4q
PHVRYZOLX~V5KL®{qKP4qU7V5KNMI
O
S4HO
sXK ¥O
QTQKNO
S4VMKNHWqKtS&H~M w ( MULS®HM w ÿ
eOLMy¦WqKtS4KP[£ONhcsK(ULWqKtS
I
O
S4HO
sXJKNVWqTO
W­O
QTQKNO
S:HM!]s\WMTULWlH~M w ( v ULS­MULW:HM w ÿ x l{qKNV5K;O
SKaWqKaI
O
S4HO
sXKNVirqH4q(sKNXJU7M|
U7MTXJh¡W5UÍWqK}tXOL\V5KNV´WqTO
W(U7MWOLH~MÏWqK¤XHJW5KtS4OLX  v ULS ¼¹¥ elSKNVQKNWHILKNXJh x 
 pRKNMTKLelKtILKtShË[!UnyKNX­ULY
ÿ
t

L
O
¦
M

s
j
K


7
U
g
[

Q
J
X
t
K
5
W
N
K
c
y
5
W

U
£
O
g
[
z
U

y
N
K
¹
X
L
U

Y
¬
]
z
s
c
h
L
O

V

V
J
H
7
|
T
M
~
H

M
c
|

"
Á





´





t



eSKNV5QKNWHJILKNXh x W5Ã
U LeOLMTy
w ( vw x
v
" #TRULÀS ´hL N&O
SsHJW5S4O
SÁHXJh´W5UKtILKtSh!IAO
SÁHO
sXJKaULY]ÂWqO
WyUzKNVMULWO
QQKNO
SHM w ( vw ÿ ekSKNV5QKNWHJILKNXJh x 
Ú¹KtW uvw(x VWOLMTyYULS;WqTK´Mk\T[sKtSaULY[!UnyKNXVfULYl]eTOLMTy» ( v »¹ÿ x yKNMULW5K®WqK®Mz\T[sKtSaULYIAO
S4H~O
sXJKNV
¿
¿
v ULWqKtSRWqTOLM x irqTHÁqUztt\SRHM¦]¬s\TW{MULW{HM w ( vw ÿ x eWqKNM uvwx   > uvw ( ²
x :  @ uvw ÿ x 
 VHWqTOLVsKtKNMVqTUoirM(H
M InKNWHJU7
M z
e7HYT4qKN4mzHMT|&VO
WH~V2õO
sHX~HJWhHV¹WqTK|LU7OLX×e7OLMyjORQ\SKX~HJW5KtS4OLX
iv rqTH~4q!HV­MTULW­O´\TMTHJWltXOL\TVK x HV:4qTU7V5KNMgYZULSV5QX~HJW5WHM|e
WqKNM!U7MXJh w ( VqU7\TX~yPsKaQTS4UzKNVVKNy!YZ\TSWqKtSNe
irqTH~XJK w ÿ´[£ONhsK´yTHV5S4Kt|7O
S4yKNy<G
 prUµiKtILKtSNeYZULSRU7\TMkWHM|£[gUzyKNX~V;sULWq w ( OLMTy w ÿ´[gO
W5W5KtSN;`RULW5K
WqTO
WHMcWqHVRtOLVK w ÿU7MkWOLHMTVRWqKPVOL[!KPMk\[jsKtSrULYtXOL\TV5KNV&OLV´]­4
 IzUeHM¦U7MkW5S4OLV5WW5U4qKN4mzH~M|
VO
WHV5õO
sHXHWhLenWqK®Q\S4K´XHJW5KtS4OLXS4\XJKW\S4MTVaU7\W;W5U£sK´H~MK°}tHJKNMkW;YULSRU7\TMWH~M|g[!UnyKNXVt

uZÄÅ

y w z£ùR{d|,¡'}R²Rì8|,±§~¡$R]w­lÙ±¡$²'}R£²3 ± ~
¸aOLV5KNy¦U7MWqKNV5K´ULsV5KtSI
O
WHJU7MTVteTWqTK®YU7XXUoirHMT|(Y\TMTWHU7M¦_adñôU7\TMkWV{[!UnyKNXV{ULYO!YZULS4[(\TXO£]
UoILKtS(IAO
S4H~O
sXJKNVt
YZ\TMWHJU7M¦_adñ v ](§QTSULQU7VHJWHJU7MOLX<_;`RbpYZULS4[(\TXOnÙ§HMW5Kt|LKtS x Ù

rHY w H~VaKN[!QTWhWqKNM
SKtW\S4
M ¿ Ù
zrHY:]¬U7MkWOLHMTVROLMKN[!QTW¯htXOL\TV5K®WqKNM
SKtW\S4McÄnÙ
zrHY:]¬U7MkWOLHMTVROg\TMTHWatX~OL\TV5KP³ £ ¶jWqKNM
w (  ³AÅ Ö ³ £¥ ¶ ± Å ¤¦w ½ £G¤ ¶ Å(¶7Ù
SKtW\S4MÍ_;d&ñ vw (N½ » Ö  x Ù
ØrÁqUzU7V5KOPI
O
S4HO
sXl
K cULY]Ù
w (  ³AÅ Ö ³ ¼¥ ¶ ± Å ¤¦w ½ ¼ ¤ ¶ Å(¶7Ù
w ÿ  ³AÅ Ö ³N¼¹¶ ± Å ¤¦w ½ ¼ ¥ ¤ ¶ Å(¶7Ù
S4KtW\S4MÍ_adñ vw ( ½ » Ö  _
x : _adñ vw ÿ ½ » Ö  x 
 Mh´HW5KtS4O
WHJU7M®ULY_adñyKNXJKtW5KNVWqKÁqU7V5KNMIAO
S4H~O
sXJKLeµOLMyjV5UeASKNyT\TKNVWqKMz\T[sKtS¹ULYnIAO
S4H~O
sXJKNV
ULY­] skhO
W{XJKNOLV5W;U7MKL­rqTHVf|7\TO
S4OLMkW5KtKNV{WqTO
WR_;d&ñW5KtS4[gHMTO
W5KNV v KNHJWqKtS;U7MV5W5KtQÏULS;U7MVW5Kt
Q  x
Õ Ç= ÛÜÈ4 É¥D
Æl> 

@@ E @

sÊ¤E 

£
M WqK®OLMTOLXhzVH~V­ULYWqTK&OoILKtS4O
|LK´S4\TMMTHM|®WH[gKRULY¹WqTK&Y\TMTWHU7M¤_adñpifK&YZU7XXJUµiÂGU7XysKtS| v N7ó
 x
OLMTyÍGU7XysKtS|PKtWrOLX× v NLÛ x eirqU!V5W\yTHJKNyWqKjOoILKtS4O
|LK(S4\TMTMTH~M|jWH[gK®ULYldññ

Ë fª §©¨ªH¦Ì©¦;±­#é¦=±¦ + Í°#'¯¬

Ú KtWR OLMTyccyKNMTULW5KrWqK&Mk\T[sKtSULY¹tXOL\V5KNVOLMygI
O
S4HO
sXJKNV­ULY]­ezSKNV5QKNWHJILKNXhL  VV\[!KrWqTO
WfOLXX
¹
WqKPXHJW5KtS4OLX~VRqTOoILKPWqK(V4OL[!KPQTSULsO
sH~XHJWh]W5UO
QTQKNO
SHM¦KNOLÁq¥tXOL\TV5K¼¬ULY;]­ v UV4H[!QXHYh¤WqK
OLMTOLXJhnVHVriKPOLXXJUµiÝ] W5UU7MWOLH~My\QXHtO
W5KtXOL\TV5KNV&OLMTyÍWOL\W5U7XJUL|7HJKNVt x  VV\T[!K(OLXV5U¤WqTO
W&WqKtSK
HV&MU}yTKtQKNMyKNMThOL[!U7M|¤WqK(Uztt\S4SKNMTKNVRULYyT¸H ·KtSKNMkWrI
O
S4HO
sXJKNVROLMTyOL[!U7M|¤WqKUntt\SS4KNMTKNV
ULYWqTK(VOL[gK(I
O
S4HO
sXJKHM¡yT»H ·KtSKNMkWtXOL\TV5KNVt®bULSO£|7HJILKNM¥yHV5W5S4HJs\WHJU7MULE
Y e¹XJKtW&Ó v ÷ ½ » x yTKNMULW5K
WqKjOoILKtS4O
|LK(S4\TMTMTH~M|jWH[gK®ULY­_;d&ñ vw ½ » x irHWq¦]ÝU7MkWOLHMTHM| tXOL\TV5KNVt
 Y] U7MkWOLHMTVïtX~OL\TV5KNVPU7MºÀI
O
S4HO
sXJKNVte­WqKNMºPôsU7\MTyTVWqKcVHJÕtKULY] Ð OL4qV5W5KtQ¢ULY
Y\TMTWHJU7M¦_adñôtOLMcsK´OLtU7[!QXH~VqKNyyT\SÁHM|PO
Wr[!U7V5W{W¯iU£QOLVV5KNVrUoILKtS]
N¸ LkN#c
Ñ
 wÁf Ò#ÓSÔntÀSÔnhc~KË4L#Ð
¡#ThÔ¨SÔÕL
 a§ÏÎ ´!]4
Ð L
tPÒLzAjSÔnPZ£R´(ztZk
hRL×
 ´Ö´#nN×
¼4×+Ø%Ù

¨Ù¦§

 W;[gHJ|7qkWsK&WqU7\|7qkWteWqTO
W;HM¤ULS4yKtSaW5UPULsTWOLHMO(|LUkUnysU7\TMTy}U7M}WqTKOoILKtS4O
|LK´S4\MTMTHM|jWH[!K
ULYaYZ\MTWHJU7MÏ_adñe¹U7MKg[(\TV5WjV4qUoiâWqO
W´WqK£\TMHJW&tX~OL\TV5KgS4\XJK!HV®O
QTQXHKNyÍYZSKN z\KNMkWXJhLeVH~MTK!WqK
V5QX~HJW5WHM|(S4\TXJKHVaWqKjU7MK®WqTO
WrHMkW5SUnyT\TKNVfWqK®QU7VVHsHXHJW¯h!ULYKÑnQU7MKNMkWHOLXXJh£XU7M|gU7[!Q\WO
WHU7MTVt
¥KVqUoi^WqTO
WKtILKNM¤HYU7MXJhPWqKRV5QXHJW5WHM|S4\XJKrHVO
QTQXHJKNy¹e7XJUoi^sU7\TMTyTV­O
S4KrULsTWOLHMTKNy<:{qKtSKtYZULSKLe
ifK£OLVV\T[gKgWqTO
WjMUÍ\TV5KgULYaWqK£\MTHJW®tXOL\TV5K£S4\TXJK!HV´[£OLyKLeOLMTyOLMTOLXJhzÕtK£OI
O
S4HOLMkW´ULYr_adñeHM
irqTH~4qcV5W5Kt3
Q !HVrU7[gHJW5W5KNy<6
 Ú&skInHJU7\TV4XJhLeWqTHV{ÁqTOLM|LKPyUzKNV{MULWRwO ·KNWRÚKN[g[gOÍ
 ¥K(OLXV5U£OLVV4\T[!K
WqTO
W{WqTKjXHJW5KtS4OLXYZULSrWqK´VQXHJW5WHMT|S4\XJK®HV{4qTU7V5KNMcS4OLMyU7[gXJhL
ÚKtW{sK;WqKRXHJW5KtS4OLXnWqTO
WfqTOLV:sKtKNMgÁqU7V5KNMgYZULSWqTK{V5QXHJW5WH~M|S4\TXJKLq
 InHMTKaWqKrQTSULsO
sH~XHJWhjWqTO
W
Ö  xB ý Y 
Untt\S4V:H~M(O®tX~OL\TV5K{H=
V ekWqKaQTSULsO
sH~XHJWh®WqO
6
W \jU7\WlULY tXOL\TV5KNV:U7MkWOLHMHV v BY x  Y v  +

uZÄÛ

ê

£R²ë­R¡TìÂíÝî±£²³££

{qK®VOL[gK´qU7XyTVfYZULS £¥ ­{qK®Mk\[jsKtS;ULYltXOL\TV5KNVaULYYULSÁ[\TX~OLV w ( e w ÿQTSUnyT\TKNy¤skh¤V5QXHW5WHM|g]¬HV
KN z\TOLXW5U(WqKMk\[jsKtSULYOLXXtXOL\V5KNVfULY]Ô[£HMk\V­WqKMk\[jsKtSULYtXOL\TV5KNVULY]ÔirqTHÁq£U7MkWOLHM¤WqK
XHJW5KtSÁOLXle £¥ eSKNVQKNWHILKNXJhL

 Ô ´_´t#(n»A w Ó w ÿ]5N
TÁ4Ò¦×Zk¦] 4LÐ
Z(÷ Ö ^ºt»
zt]Þ:SÔ
¨Ù¦§   ¦ÝÜ 7
5ÒVÒZ" v BY x  Y v  Ö x B ý Y Ù (
InH~MTK;KNOL4q}ULY w ( e w ÿ{U7MkWOLHMTVO
W[!U7V5W» Ö {IAO
S4H~O
sXJKNVteLWqKRYU7X~XJUoirH~M|SKNt\SSKNMKrHMKN z\TOLXHJW¯h
YZULS;Ó v ÷ ½ » x qU7X~yTVt
Ó v÷ ½» x

ßàà #÷» :
à ã BYN#( v BY x  Y v  Ö x B ý Y Ó
á
5 à ã BYNr* v BY x  Y v  Ö x B ý Y Ó
ààâ

v÷ Ö
v÷ Ö

^
^

½ » Ö  Rx :
½» Ö x



» ½m
÷ ` 
»

 ]Ä äµøP÷ 

v x
Ä

 qKgõS4V5W´W5KtSÁ[ v #÷» x HVjWqKgWH[gK£MKtKNyKNyYULSU7MK}HW5KtS4O
WHJU7MËULYr_adñrqK£V5KNU7MTy¨OLMTyÏWqTHJS4y
{
W5KtS4[gV(O
SK}WqK£KÑnQKNW5KNyÏWH[gKNVjMKtKNyKNyYZULSU7[!Q\TWHM|cWqK¤Mk\[jsKtSjULY{[gUzyKNX~V®ULY w ( OLMTy w ÿ
e
SKNV5QKNWHJILKNXhL6
 InH~MTK®WqKX~HJW5KtS4OLXlTO
QTQKNO
S4V{H~MÍ]eHJWrH~V{H[!QU7VVHsXJK&WqTO
WrWqKMk\T[sKtS{ULY:tXOL\TV5KNVRHM
irqTH~4qcUntt\S4VfHVÄneOLMTy}V5UezWqKRV\[g[gO
WHJU7M£ULY¹WqKRVKNU7MTy£W5KtSÁ[*V5WO
S4WVfO
W&
­{qK&XHJW5KtS4OLX £ ¥ [gONh
MULW;O
QTQKNO
S{O
W;OLXXHMc] v HJYHVfQ\SK x _fU7MV5KN k\TKNMWXJhLenWqK®V\[g[gO
WHJU7M¤ULYWqTK&WqHJS4y}W5KtS4[sKt|7HMTV
O
WrÄn
{qTK&SÁHJ|7qW2ÊqOLMTyVHyK&ULY v  x UµILKtSKNV5WH[gO
W5KNV{Ó v ÷ ½ » x VHMKLekõS4V5WtenWqK®Mk\[jsKtSaULYI
O
S4HO
sXKNVULY
e
V L;gAl» Ö 
eOLMTy<e<V5KNU7My<e<YZ\MTWHJU7MË_adñÉ[gOohÍV5W5ULQ¥irqTKNM¥] U7MWOLHMV®OLM¡KN[!QTWh
w ( w ÿPH
tXOL\TVKLeKtILKNM¦sKtYZULSKP ULS´¡sKNU7[!KNV{Än
UgKNV5WH[£O
W5K´Ó v ÷ ½ » x eTifKjVqTUoi´eõS4V5WteTWqTO
WrYULS    · zeÓ v ÷ ½ » x  ù v ÷ ÿ » x eOLMTy<eVKNU7MTy<e
WqTO
W{YZULSrOLMk[
h eÓ v ÷ ½ » x  ù v ÷  » x irqKtS4

K  å 	 ý +( ( . ¾
@ ý
¦ ç4¬  
Ë ª ¦ ¨ªH¦æ[¬¦§*¿¦3Ì#'=¿k¨i' 

· 
bU7XXUoirHMT|GU7XysKtS| v N7ó
 x e´ifKËV5WO
SWirHJWq^WqKËOLMOLXJhzV4HV¤ULYWqKËOoILKtS4O
|LKÏSÁ\TMTMTHMT|ÏWH[!K¡YZULS
   · z  M¤WqTHVatOLV5KLeKNOL4qI
O
S4HO
sXJK&Untt\S4V;HM}KNOL4qctX~OL\TV5KQU7VHJWHJILKNXJhLenMKt|7O
WHJILKNXh£ULS{MULW;O
W;OLXX
irHJWqWqTKjVOL[!K®QTS4ULsO
sHXHWh v  ·  x %IzUeTSKNt\TSSKNMTK v  x WO
mLKNVRWqK´YZULS4[
Ó v÷ ½» x

ßàà Á÷ÿ » :
à v  x B Ó v ÷ ½ » Ö  xR:
á
5 à  ã BYN#( v BY xv ( x Y v ÿ x B ý Y Ó
ààâ


¨ªH¦§¬é¦§ § ]   ( Ó<Ó

v÷ ½» x
ñ­S4UkULYlHVa|7HJILKNMÍHM  QQKNMyTH Ñ  



ù v÷ ÿ » x ¾

v÷ Ö

^

÷ ½ »`Ô

½» Ö x
»

 èÄ äAø(÷ 

v x
Ä

Ë ª Ë ¨ªH¦æ[¬¦§*¿¦3Ì#'=¿k¨i' ¦ç4¬Ãæré 
{qKOLVV4\T[!QTWHJU7MULY    · ¡
 HVPU7[g[!U7MTXhOLyULQTW5KNy¢H~MQSULsO
sHX~HV5WHgOLMOLXJhzV4HV(ULYROLXJ|LULS4HWqT[gV
qTOLMTyXHM|c_a`&bºULSjd`RbÂYZULS4[(\TXOLV v bSÁOLMTU ñOL\XX×e­NLÛz ÙfG&U7X~ysKtS|eN7ó
zÙG&U7XyTsKtS4|KtWjOLX×Je
uZÄZê

y w z£ùR{d|,¡'}R²Rì8|,±§~¡$R]w­lÙ±¡$²'}R£²3 ± ~
NLÛ  x eLirqTH~4q®[!KNOLMTVWqTO
W¹YZULS¹KNOL4qI
O
S4HO
sXJKLeAHJWV<Untt\SSKNMK­HM´O{tXOL\V5K:irHJWqULSirHJWqU7\W¹MTKt|7O
WHJU7M
ULS{MU7MnÊFUntt\SS4KNMTKLeTOLXXqTONILK®WqTK´VOL[!K®QTSULsO
sHXHJW¯hLpRUoifKtILKtSNeHM¤SKNOLXtOLV5KNV{WqTH~Vf[£ONhMULW;qU7Xy<e
V5U(iKOLMTOLXJhzÕtKrWqTK&OoILKtS4O
|LK®S4\TMTMHM|®WH[!KRULY_adñpYULSaOLMkhgQTSULsO
sHXHJW¯

h !ULYO(XHJW5KtS4OLXUztt\S4SKNMTK
HMOgtX~OL\TV5K®ULY]
¸fKtYZULSKÍOLMTOLXhkÕNHMT|¥WqKcSKNt\S4SKNMTKcKN z\TO
WHJU7MôXJKtW£\TVg[£O
mLK¦WqKcYZU7XXJUµirHM|¡KNV5WH~[gO
WHJU7M<^{qK
Y\TMTWHJU7M¦_adñ v iRHJWqU7\W;WqK´\MTHJWatXOL\TV5K®S4\XJK x [gONh¤sK®SKt|7O
S4yKNyOLVROLMOLXJ|LULS4HJWqT[iRqTH4qV4tOLMTV
OcsHMTO
ShW5SKtKLc{qK£SUkULWjULY;WqK£W5SKtK}SKtQTSKNVKNMWVWqK£HMTQ\W®YZULS4[\XOÍ]Ù{qTK£4qTH~XySKNM¡ULY;KNOLÁq
HMkW5KtS4MTOLXlMUnyKPSKtQTSKNVKNMW®WqKPYZULS4[(\TXOLVULsTWOLHMTKNy¥OLV´OSKNV\TXWRULYaO
QTQXJhnHM|}WqKgV5QX~HJW5WHM|}S4\TXJK(W5U
WqK®YZULS4[(\TXO!O
W{WqTO
WRHMW5KtSÁMTOLX<MUnyKLeTOLMTyWqKjXKNONILKNV{ULYlWqK®W5S4KtK´SKtQTSKNVKNMW{KN[gQTWh¤YULSÁ[\TX~OLV{OLMTy
YZULS4[\XOLVairqTHÁqcU7MkWOLHMcOLMcKN[gQTWhtXOL\TV5KL
 YOLMHMkW5KtS4MTOLXMUnyKSKtQTS4KNV5KNMWV;OPYZULS4[(\TXO(irHJW
q \}tX~OL\TV5KNVtenWqK®KÑnQKNW5KNycMk\[jsKtSaULYtXOL\V5KNV
Ö  x :{qK;KÑnQKNW5KNygqKNHJ|7qkWlULYWqK;W5S4Kt)
HM(KNOL4q£ULYHWV:4qTHX~ySKNMPHq
V ^ v +
K ÔPH~VlWqKtSKtYZULSK{O
sU7\W:XJULV| ëz÷
W Ô¦HV{O
sU7\¢
W  þ íe
irqKtS41
K ì  ( ( f{qKjMz\T[sKtS;ULYlMTUzyKNVRHMO£U7[gQXJKtW5K´sH~MTO
Sh¤W5SKtK´ULY:qKNHJ|7qk)
ý


OLMTyWqHV{HVaWqKjKÑzQKNW5KNy¦Mz\T[sKt6
S î¤ULY:HJW5KtSÁO
WHJU7MTV;ULYlWqK´Y\TMTWHU7M¦_adñÈ IzU*e î   þ  í  AK
÷ Le
(
irqKtS41
K   	 ý +( . &{qTKjS4\TMMTHM|!WH[gKULY­KNOLÁq¥HJW5KtS4O
WHJU7MHV®ù *v ÷ ï » ï x irqKtSK ÷ ï HVRWqKPMk\[jsKtS
ULYtXOL\V5KNVaOLMTy @ »
ï ý HV WqK®Mz\T[jsKtSULYI
O
S4HO
sXJKNVULY¹WqKYZULS4[(\TXO´WqO
WaH~VW5SKNO
W5KNy¦O
WfWqO
WfHJW5KtSÁO
WHJU7M<

Ó v ÷ ½ » x  ù v ÷  » x ÓqÞEÔh+ å 	 ý +( ( .  Ù
@ ý
ñ­S4UkULYlHVa|7HJILKNMÍHM  QQKNMyTH Ñ  
 YZKti SKN[gO
S4mzVO
SK£HM¥ULSÁyKtSN}blHJSÁV5WteifK£OLVV\[!KNyËWqTO
WjWqKgQTSULsO
sHXHJW¯h¦ULYaUntt\SS4HMT|cHMËO
tXOL\TVKjHV;WqK(VOL[!KYULS&OLXX¹XHJW5KtSÁOLXVt  YlWqTHV{H~V{MULWrWqTKjtOLV5KLeWqKNM¦{qTKtULSKNð
[ £qU7XyTV;YZUL6
S ¥sKNHM|
WqKjXUoifKNV5W{Untt\SSKNMTK®QSULsO
sHX~HJWh£OL[gU7M|£OLXX<XHW5KtS4OLXVaULY­]­È IzKNU7MTy<eH²
Y ¡H~V{OLVV\T[gKNyU7MTV5WOLMkWte
WqKNMWqKPVHJÕtKPULYtXOL\V5KNVteirqTHÁqÍH~VrULYULS4yKt

S   »:e<HVRQTSULQULSWHJU7MTOLXW5UWqK!Mk\T[sKtSRULYIAO
S4H~O
sXJKNVte
OLMTycqTKNMTKLeHV;V\TQTQU7V5KNy¤W5U£4qTOLMT|LKjirHJWq¡

¨ªH¦§¬é¦§ ¦

ñ­> É3 'ò

@ E@

vÚH oóõô

{qTH~V;V5KNWHJU7McyKNV4S4HJsKNV;V5U7[!K´S4KõMKN[!KNMkWV;W5U¤_adñôH[!QTSUµIzH~M|!HJWVaQKtSYULSÁ[gOLMTKL
 ÷^$é$ý¦ç4¬[¯Zª#¦õø²ù'ú¯X¯'À¿õÌü#¦
ö fª § ½ ª#¬w¬®À¿ õ

{qKÍYZ\MTWHJU7M^_;d&ñeaXHJmLKcWqTKÍdONInHV2Êñ\WMTOL[ QTSUnKNyT\SKLea|7HJILKNVMUSKNU7[g[!KNMyTO
WHJU7M^qUoi W5U
4qTUkU7V5KOpIAO
S4H~O
sXJK¡YULScO¢VQXHJWt9
 prUµiKtILKtSNeOp|LUkUnyÉ4qTU7HKËULY(WqTHV¤IAO
SÁHO
sXJK¥[gOohôSKNy\TK¥WqK
S4\TMMTHM|}WH[!KPULYWqTK!YZ\TMWHJU7M<P¸
h û |LUzUzyËÁqU7HK ü¹ifKg[!KNOLM¥U7MTK!WqTO
W´tOL\TV5KNV®WqTK!YULS4[(\TXOLV w (
OLMTy w ÿ W5UgsK´OLV{V[£OLXX<OLV{QU7VVHsXJKL
{qTK{VHJÕtKaULYWqTKNV5K{YZULS4[\XOLV:HV:yKtW5KtS4[£HMKNy(skh(sULWq*OLMTy  V­[gH~MTH[gHJÕNH~M|{WqK{Mz\T[sKtS:ULY
I
O
S4HO
sXJKNVHM w ( e w ÿtOL\TV5KNVlOLM(\TwM Â\TV5WH õKNy´U7[!Q\WO
WHU7MjUµILKtS4qKNOLy<e7ifKaU7MTKNMW5SÁO
W5KNyPU7MjSKNy\TtHM|
WqKaMk\[jsKtSULYtXOL\TV5KNV÷ ( e
÷cÿHM w ( e w ÿ
e
KNHJWqKtSskhj[£HMTH[gHÕNHM|a÷ ( : ÷cÿ v szhj[!KNOLMTVULYÁqUkU7V4HM|
O´I
O
S4HO
sXJKrO
QTQKNO
S4HMT|jHM£O[gOAÑH[gOLXMz\T[sKtSULY¹tXOL\TVKNVULY] x ezULSszhg[gHMTH~[gHJÕNHM|&K
÷ ýk¼ v ÷ (N½ ÷cÿ x 
{qKXO
W5W5KtSRtOLMÍsK´OL4qTHJKtILKNyszh[gOAÑnH~[gHJÕNHM|PUµILKt+
S WqK k\TOLMkWHJW¯h
÷ þF» v  äL© v ¼ x ½ » ehÿv ¼ x5x eiRqKtSK
 äL© v ¼ x&v » ehÿv ¼ x5x yKNMULW5KNVaWqTKMz\T[sKtSfULYtXOL\TV5KNVfULY:]¬HM}irqTHÁÃq cUztt\TS4Va\TMTMKt|7O
W5KNy v MKt|7O
W5KNy¹e
SKNV5QKNWHJILKNXh x ¦rqKNV5K£W¯iU¡O
QTQTS4U7OL4qKNVP[gOohËsK£U7[jsHMKNy<  MTyKtKNy<elKÑnQKtS4H[!KNMkWV´SKtQULSW5KNyHM
IzKNWHJU7M¡Ü}VqUoifKNysKNV5WrQKtSYZULS4[gOLMTK(HJYlWqKPV5QXHJWrIAO
S4H~O
sXJKjqTOLVRsKtKNMÍÁqU7V5KNM¡yT\KW5U}
÷ þ» v ÷ ( :
÷cÿ x es\WRHJYWqKtSKPqTOoILKsKtKNM¦[gULSKjWqTOLMÍU7MK(V\T4qÍI
O
S4HO
sXJKLeWqKNM¦O}Y\SWqKtSrÁqU7HKPOL[!U7M|¤WqK
U7[!QKtWHM|!I
O
S4HO
sXJKNV;qTOLV;sKtKNMc[gOLyTK´yT\K®W5Ug
÷ þF»<K
÷ ýk¼ v ÷ (t½ ÷cÿ x 

uZÄ

ê

£R²ë­R¡TìÂíÝî±£²³££

 V;qTOLVasKtKNMV\|L|LKNV5W5KNycskh¤OLMOLMU7Mhn[!U7\TVaS4KtIzHJKtifKtSNeszh}\TV4HM|(QTSULQKtS;yTO
WO!V5W5S4\TW\TSKNVtenWqK
U7[!Q\TWO
WHJU7MULY  äL© v ¼ x OLMTy¤» ehÿv ¼ x YZULS{OLXXIAO
S4H~O
sXJKNVDctOLMsKyU7MKK°}tHJKNMkWXJhLetOL\TVHMT|U7MTXh}O
V[gOLX~X<U7[!Q\WO
WHJU7McUoILKtS4qKNOLy¹

ö ª
¦  =³ý''=¿øw

'#¬

#$®

{qKPY\TMTWHJU7MË_adñÉVW5ULQV®irqKNMË]U7MkWOLHMTVjOLM¡KN[!QTWh¡tXOL\TVK(ULS®iRqKNMÏ]HV&KN[!QTW¯hL^qTO
W´HY
]ÝU7MVHV5WV;ULYU7MTXJh¤U7MK´tXOL\V5KjU7MkWOLHMTHMÃ
| \XHJW5KtS4OLX~V {qK´VQXHJW5WHMT|S4\XJKirHXXsK´O
QTQXHKNy}W5U](e
SKNO
WHMT| w ( OLMTy w ÿV\T4qcWqTO
W;U7MKULYWqTKN[ö[gONh¤sKKN[!QTWhLes\WaWqK®ULWqKtSrV5WH~XXU7MVHV5WVaULYU7MK
tXOL\TVK´HMILU7XIzHMT_
| Â\TV5W;U7MTK®IAO
S4H~O
sXJK®XJKNVV;WqOLMÍ]r IzUeTV5QX~HJW5WHM|(ULYWqTKjVHM|7XKtX~OL\TV5K®ULY­]¬irHX~XsK
SKtQKNO
W5KN
y ^WH~[!KNVt
 V4H[gHXO
S;QSUzKNV4VrULYH~MK°}tHJKNMkWRV5QXHJW5WHM|!WO
mLKNVQXOLKOLXVU£U7MYULSÁ[\TX~OLVrU7MTVH~V5WHM|gULYSKNXOAÊ
WHJILKNXJh¡YZKti*tXOL\V5KNVt  WjW\TS4MTVU7\WWqTO
WjWqK}OLXJ|LULS4HJWqT[ÎQTSKNV5KNMkW5KNyËszh¥Ú¹ULÕNHMTVmzHH v NL  x HVj[!ULSK
K°}tHJKNMkW¹YZULSqTOLMTyXHM|aV[gOLXX
V5KtWVULYtXOL\TV5KNVt Ð ÑnQKtS4H[!KNMkWVU7M´S4OLMTyTU7[gXJhrÁqU7V5KNM´YZULS4[(\TXOLV¹V4qUoifKNy
WqTO
WaYZULSYZULS4[(\TXOLVfirHJWq}XJKNVVfWqTOLMtX~OL\TV5KNVfWqKOLXJ|LULS4HJWqT[*ULYÚULÕNHMTV5mnHH v NL  x QKtSYZULS4[gVsKtW5W5KtS
WqTOLM£YZ\TMWHJU7M}_adñ¨HMgHJWV:ULSÁHJ|7HMTOLXYZULS4[l{qKtS4KtYULSKLekirqKNM£WqKrMz\T[jsKtS­ULY<tXOL\V5KNV­ULY<O´YZULS4[(\TXO
sKNHM|PQTSUnKNVV5KNy¦HVaSKNyT\TKNy¦\TMTyKtSrze_;d&ñÀS4\TMTVaWqTK´OLXJ|LULS4HJWqT[öULYÚULÕNHMTV5mnHH v NL  x 

  dn 

l>
	 $ÛE

@

ÚØ

 JX |LULS4HJWqT[Ô_;d&ñ¦QTSKNV5KNMkW5KNy´HMWqTK­QTSKtInHJU7\TV<V5KNWHU7MTV¹qTOLV<sKtKNMQTS4UL|LS4OL[g[!KNy´H~M !e
OLMTyS4\M}U7M¦ñf_&enirHJWq¤WqK®Q\SQU7V5K&ULYyKtW5KtSÁ[gHMTHMT|OLMK°}tHKNMW;iaONhULYÁqUzU7VHM|gOPI
O
S4HO
sXKRYZULS
WqKPV5QXHW5WHM|gS4\XJKLeTõMyTHM|£OLMO
QTQTS4ULQTS4HO
W5K(Mk\T[sKtSRULYtXOL\TV5KNVHMÍO£YZULS4[(\TXO}YULSV5irHJWÁqTHM|}WqK
Y\TMTWHJU7M¥_adñºW5UWqK(OLX|LULS4HJWqT[ ULYÚULÕNHMTV5mnHH v NL  x eOLMTyOLVV5KNVVH~M|}WqTK(OLW\TOLXlSÁ\TMTMTHMT|!WH[!K
ULY_adñ
 MjWqTKfKÑnQKtS4H[!KNMkWVte_adñ¥qTOLVsKtKNM(O
QQXHJKNyjW5URS4OLMyU7[gXJh®QTS4UzyT\KNyjV5KtWVlULYtX~OL\TV5KNVirHJWqWqK
YZU7XXJUoiRHM|!QO
S4OL[gKtW5KtS4Vt§®t]
Ä 5^÷ 5s
ÄLÄne:t]
Ä 5^
» 5ÂÛ
Ä£OLMy  ( ½  ÿ ¤ ³oÄ ¾  ½ Ä ¾  ½ Ä ¾ k¶7eirqKtSK  ( e  ÿ
yKNMULW5KWqKQTS4ULsO
sHXHWh!ULYO(I
O
S4HO
sXKRW5UPUntt\S{HMOPtXOL\TV5K\TMTMKt|7O
W5KNyULS{MTKt|7O
W5KNy<eTSKNV5QKNWHJILKNXh
v  ( OLMTy  ÿ O
S4K¦MULWgMKNKNVV4O
S4HXJhWqKcVOL[!K x ÀbTULSgKNOL4q^U7[jsHMTO
WHJU7MpULY&WqKcQO
SÁOL[!KtW5KtS4VtetÄLÄ
S4OLMTyTU7[ HMTV5WOLMTKNV´ULY;]qONILKgsKtKNM¡QTSUnKNVV5KNy¹PñKtSYZULS4[gOLMKgULY;_;d&ñ qTOLVsKtKNMË[!KNOLV\TSKNy¡skh
HJWV;SÁ\TMTMTHMT|jWH[!K´OLMyskhWqK´Mz\T[sKtS;ULYS4KNt\S4VHJILK®tOLXX~V;W5UgWqKj[£OLHMYZ\MTWHJU7M<
¥K(qTONILK´ULsV5KtSILKNycWqO
W{YULSrKNOL4qcQOLHJS;ULYlQTSULsO
sH~XHJWHJKNV  (t½  ÿAeTWqKtSK´H~V{O!WqSKNV4qU7XyMk\[jsKtS
ULY{tXOL\TVKNV ÷¥
¥ elV\T4qÏWqTO
WjYZULSj÷ ` ÷ï
¥ WqK¤qTO
S4yËtOLV5KNVPXHKgO
SU7\TMTyËOÍULSSKNV5QU7MTyHM|cMz\T[jsKtS´ULY
I
O
S4HO
sXJKNVNbULS(HMTV5WOLMTKLeWqK!qTO
S4y¥tOLV5KNVjYULS  (   ÿ  Ä ¾ gOLMTy ÷ ¥  
ÄcO
SKgXUztO
W5KNyËO
S4U7\TMTy
»  Ü
Än­blHJ|7\S4KNV{rOLMT[
y QTSKNV5KNMkW­WqKRONILKtS4O
|LK®Mz\T[jsKtS­ULYSKNt\TS4VHJILK{tOLXX~V:QKtSYULSÁ[!KNy!szh!_adñ¨HM
WqKqTO
S4y}tOLV5KNVtÍULSKyTO
WOO
S4KR|7HJILKNM¤HM¤O
sXJKNVR#Ê¯jULY  QTQKNMTyTH ÑP¸&nbTU7XXJUoiRHM|jO(V\|L|LKNV5WHU7M}ULY
U7MKaULYWqTKSKtInHJKtifKtS4VteLifK;4qKN4mLKNygWqKaV5WOLMTyTO
SÁy(yTKtIzHO
WHU7M(H~MOLXXztOLV5KNV v VKtKaO
sXJK{óRHM  QQKNMyTH Ñ
¸ x   XXWqKjKÑnQKtS4H[!KNMkWV{S4OLM¦U7MÍO£QKNMWH\[ösOLV5KNyÍñf_ v LL£
 pRÕ x R{qK(OLW\TOLXS4\TMTMTH~M|PWH[!K
ULY_adñS4OLMT|LKNyYS4U7[öXJKNVV;WqOLMU7MK´V5KNU7MTy¦W5U}Ü!qU7\TS4Vt
b U7X~XJUoirH~M|WqKgyTHV4UoILKtShULYfqO
S4y¥tOLV5KNV´YZULSI   v HJWÁqKNXX:KtWjOLXFJeNL x eifKgS4OLMÏ_;d&ñÔU7M
O£VKtS4HJKNVRULY:S4OLMTyU7[ÌV5KtWV&ULYHµÊXHJW5KtS4OLXtXOL\TV5KNVRirHJWqWqTKS4O
WHU£ULY:÷ · »ÏYZSU7[ÌÄn gW5UÛz ÄnRbULSKNOLÁq
U7[sHMTO
WHJU7M¤ULY¹÷ OLMTy¤»:*e 
ÄLÄPHMTV5WOLMTKNVfifKtSK®U7MTVHyTKtSKNy<:blHJ|7\SK)|7HJILKNVfWqK®[!KNyTHOLM¤Mk\[jsKtS
ULYS4KNt\S4VHJILKPtOLXXVRQKtSYZULS4[!KNyskh¡_adñºYULS´OVOL[!QXJKULY»  
Ä ½ Ø7Ä ½ Ü
ÄnP¦ULSKgyO
WO¤H~MÍO
sXJKgÛ

uZÄXu

y w z£ùR{d|,¡'}R²Rì8|,±§~¡$R]w­lÙ±¡$²'}R£²3 ± ~
#%
#$
##
#"
'&
'%
1. 8 9 . / '$
5 ) * + ,. / 0 2 113 '#
'"
&

: ; < = > ?= @ AB C D E F G E H G ; IF
J ; < = > ? = @ A B C D E F G E H G ; IH
H ; < = > ?= @ A B C D E F G E H G ; IJ

%
$
#
"
"

#"

$" %"
&" '"" '# " '$ " '%"
( ) * + , - . / 0 12 ) 3 , 3 45 67 , /. - * ) 12

'&"

#""

blHJ|7\SKg
§  ILKtS4O
|LKPMk\[jsKtS;ULYSKNt\S4VHILK´tOLXXV;YZULSryTH¸·KtSKNMkW;IAOLX~\KNVaULY

  ½ 

LK
PO
PN
PM
PL
ZW a b W X
^ R S T U V PK
W X Y [ ZZ\
O
N

c d e f g h f i j k l m n o p d q o n r p d qr
s d e f g hf i jk l m n o p d q o n r p d qs
r d e f g h f i j k l m n o p d qr n r p d qs

M
L
K
K

LK

M K N K OK PK K PL K PM K PN K
Q R S T U V W X Y Z[ R \U \ ]^ _` U XW V S R Z[

POK

LKK

blHJ|7\TSKlz§  ILKtS4O
|LKMz\T[sKtS;ULYlSKNt\TS4VHJILK´tOLXX~VaYULSryH¸·KtS4KNMW;I
OLX\KNV;ULY

  ½ 

v U7MWHMz\KNy x

ULY  QTQKNMTyH Ñ}¸& v ¦KNyHOLMcMz\T[jsKtS{HV;V4qUoirMW5U£KNMTO
sXJK´U7[!QO
S4HV5U7MirHWqWqK®SKNV\TXWVaQTSKNV5KNMkW5KNy
zs h¤HJW4qTKNXX<KtWrOLX×Je¹NL x 

uZÄZv

ê

£R²ë­R¡TìÂíÝî±£²³££

~    
       
u v }  ~~
uu
ut

            
            
            

yx
yw
yv
yu
yt
x
w
v
u
t
t

y

u

z
v
{
w
} ~         ~    

|

x

blHJ|7\SK
z§ÍKNyTHOLMMz\T[sKtS;ULYS4KNt\S4VHJILK´tOLX~XVaYULS¢µÊXHJW5KtS4OLX<YZULS4[(\TXOLVt
 MÍOLX~X¹KÑnQKtSÁH[!KNMkWV{irHJWqÍU7\TMkWHM|}[gUzyKNX~V{ifK(qTOoILKPULsV5KtSILKNyO£QqKNMU7[!KNMU7MÍO
mzH~McW5U¤WqTO
W
4 qO
S4OLW5KtS4HV5WH~´ULY:4qKN4mzH~M|£VO
WHV5õO
sHXHWhLeTMTOL[!KNXhLeTYULS&O!|7HJILKNMÍXJKNM|LWqULY:tXOL\TVKNV{øneTWqK´SÁ\TMTMTHMT|
WH[!K(ULYOLXJ|LULSÁHJWqT[ _adñºSKNOL4qKNV®HWVR[gOAÑH[(\T[ O
W&OKtSWOLHMÍI
OLX\K(ULY­WqKPtXOL\TV5KNV2ÊFW5U
ÊFI
O
S4HO
sXJKNV
S4O
WHJU:bULS:ø   v blHJ|7\S46
K  x WqH¡
V  5qTO
S4£y ¢RS4O
WHJU®HVa
 zeiRqTHXJKfHJWqOLVlsKtKNM(SKtQULSW5KNyPHMP[gOLMkhjifULSmnV
Kv L |JeÍHW4qKNXXTKtWOLX×JeNL  x WqTO
WfqTO
S4ygtOLVKNVUL4
Y µÊ I  ôXHJK{O
SU7\TMy!÷ · »  Ø ¾ z{qHV:VqTHJYZW:ULYWqK
[gOAÑH[(\T[ SÁ\TMTMTHMT|&WH~[!KRW5U(WqKXJKtYZW v YZSU7[ ÷ · »  Ø ¾ W5U÷ · »   ¾  x tOLM¤sKrKÑnQXOLHMTKNygszhgWqK
YOLWWqTO
WirqKNMOcQTSUL|LSÁOL[ YZUL
S I   yTHV4UoILKtS4V(OÍV4O
WHV5YZhzHMT|cOLVVHJ|7MT[gKNMWte:HJWjVW5ULQVjQSUzKNV4VHM|e
irqTH~XJK!U7\TMWH~M|¦[!UnyKNXV®qTOLVjW5U¦|LUcU7MÏUoILKtSPOLXX­VO
WH~V5YhnHM|cOLV4VHJ|7MT[!KNMkWVt
 IzUeWqK}qTHJ|7qKtSjH~V®WqK
QTSULsO
sHXHJW¯h£WqTO
WOgYZULS4[(\TXOgH~VrVO
WHV5õO
sXJKLeOLMycWqK([!ULSK[gUzyKNX~V{HJWRH~VrXHJmLKNXh}W5U¤qTONILK v OLMTyÍWqTHV
HV;iRqTO
W{qTO
QTQKNMTV;HJYWqK´S4O
WHUg÷ · »ËyKNSKNOLV5KNV x eWqKjXU7M|LKtSr[!UnyKNX<U7\TMkWHM|gWO
mLKNV&U7[!QO
S4KNyW5U
4qTKNmnHM|£VO
WH~V2õO
sHX~HJWhL
¤l>

}B @ Ý'DCE @ 8É3 oÜrÛ¦¥9Ø

¥KPqTONILKQTSKNV5KNMkW5KNyÍOLMÍOLXJ|LULS4HJWq[

v _adñ x YULS&U7\TMWH~M|}[!UnyKNXV{ULYlO£QTSULQU7VHJWHU7MTOLXYULSÁ[\TX~O£](
{qKQSKtIzHU7\TV!V5KNWHJU7MTV£U7MTVHyKtS4KNyÀ_a`RbÆYZULS4[(\TXOLVtefqUoifKtILKtSNe{HJWgHVPKNOLVh¨W5UU7MTV5W5S4\TW}O¥yT\TOLX
OLXJ|LULS4HWqT[YULS&d`RbpYZULS4[(\TXOLVt
_fU7[gQO
S4HM|ROLXJ|LULS4HJWqT[¬_adñirHJWq´WqO
WULY  ifOL[gO v NLÛL x OLMTy(Ú¹ULÕNHMTVmzHH v NL  x e7iKaMULW5KWqTO
W
sULWqqTONILKjOPU7[g[gU7McKNMW5SÁOLXYKNO
W\S4KL§­WqK®[!ULSK®I
O
S4HO
sXKNVqTOoILK´sULWqMKt|7O
W5KNycOLMTy\TMMKt|7O
W5KNy
Untt\SSKNMTKNVHM´WqTKtXOL\TV5KNVULYTO{|7HJILKNMjYULSÁ[\TX~OneµWqKsKtW5W5KtSHVWqKQKtSYZULS4[gOLMTK:ULYWqTKOLXJ|LULS4HWqT[gVt
{qTH~VrYZKNO
W\SKgHVOLXVUcU7[g[!U7M¡W5UWqKgOLXJ|LULSÁHJWqT[gV&QTSKNVKNMW5KNy¡szhÍd\sU7HV v NLn x OLMyÍszõ
h qTOLM|

uZÄÄ

y w z£ùR{d|,¡'}R²Rì8|,±§~¡$R]w­lÙ±¡$²'}R£²3 ± ~
v NLL x   MÏU7MkW5S4OLV5WPW5U4qKN4mzHMT|VO
WH~V2õO
sHX~HJWhLe¹Q\SK£XHW5KtS4OLXV´VXUoiyUoirMU7\TMkWHM|Í[gUzyKNX~V®skh
WqKNV5KOLXJ|LULS4HJWqT[£Vt
{qTKgKÑzQKtS4H~[!KNMWVj[gOLyKgirHWq¥OLXJ|LULS4HJWqT[ _adñ qTOoILK}VqTUoirMÏWqTO
WjHJW´QKtSYZULS4[gVsKtW5W5KtSWqTOLM
WqTO
W­ULY<ÚULÕNHMTV5mnHH v NL  x H
 pRUoifKtILKtSfWqTKr[gOLHM!OLyI
OLMkWO
|LKrULY_adñÏHVHMPWqKrOL[!U7\MW­ULYV5W5ULS4O
|LK&HJW
SKN z\THJSKNVN  M!WqK{KÑnQKtS4H[!KNMkWVlWqTO
WfqTONILKRsKtKNMgQKtS4YULS4[gKNyPskhPÚ¹ULÕNHMV5mzH~H v NL  x YZULS­÷ 5ÔtÄLÄOLMTy
»õ5n
ÄneWqKtSK´ifKtSKjtOLVKNVrirHWqWqU7\TVOLMyTVaULY:tXOL\TV5KNVRV5W5ULSKNy¦y\S4HM|(WqK´SÁ\TMULYlWqKjOLXJ|LULSÁHJWqT[
InHMKgOLXJ|LULS4HJWqT[ _adñÉQKtSYZULS4[gV´OcyTKtQTWqnÊ×õS4VW´V5KNO
S44qÏULYaWqK£V5QX~HJWW5SKtKLeOLMy¥skh¡KNOLÁqV5QXHJW®O
W
XJKNOLV5WrU7MK®IAO
SÁHO
sXJK®HV{yTKNXJKtW5KNy<eWqKj[£OAÑnH[£OLX<Mk\T[sKtS;ULY:V5W5ULSKNyctXOL\V5KNV{HV;sU7\TMyKNy¤skh¤÷»:
d\S4H~M|jWqKKÑnQKtS4H[!KNMkWVfiK®4qTKNmLKNy¦OLX~V5UWqTK[£OAÑnH[£OLXMz\T[sKt¨
S § ULYV5W5ULSKNytXOL\TVKNVt:{qK
SKNV\XJWV¹VqUµiKNyjWqTO
©
W §ïyUkKNVOLX[!U7V5WMTULWyKtQKNMTyU7MgeAV\4q®WqTO
©
W ª 5^©N¬
÷ «2eAirqKtS
K ­G5Ô ¾ {H~V¹MULW
yKtQKNMTyTH~M|rU7M  ( OLMy  ÿ e7irqTHXKrryKtQKNMTyVU7M  ( OLMy  ÿ lO
sXJK´;yHV5QXOohzV{OLV­OY\TMTWHJU7MPULY  (
OLMTy  ÿAblHJ|7\S4K{HM  QTQKNMTyTHJÑ&¸ËVqTUoirVONILKtS4O
|LKaI
OLX\KNV<UL£Y ª YZULS»  Ü
Ä ½  (   ÿ  Ä ¾  ½ Ä ¾  ½ Ä ¾ z
{qK´[£OAÑnH[(\T[UL
Y ª HMOLXXU7\S{KÑnQKtS4H[!KNMkWV;iaOLV´Øn v YZULSr»  Ü
Ä ½ ÷  
ÄLÄ x 



(

Än
Än
Än
Än 
Än 
Än 

ÿ
Än
Än 
Än 
Än 
Än 
Än 



  ÜAØ
Än Û
Än Ü7ó
ÄnóµØ
Än Ü
Ä
Än Ø

O
sXJKg
§;jOLV{OgYZ\TMWHJU7MULY


(

OLMTy


ÿ

 qTK}OLMTOLXJhnVHVjULY{WqK¤S4\TMTMHM|WH[!K}ULY&_adñ¬YU7X~XJUoirVjWqK[!KtWqUnyyKtILKNXULQKNyszhG&U7XysKtS|
{
v N7ó
 x OLMTy¡szh¡GU7XysKtS|¤KtW´OLX× v NLÛ x grqTHV&[!KtWqUnyÍiaOLV´\TVKNyOLX~V5Uskh  iaOL[gO v NLÛL x !{qK
ifKNXXmzMTUoirMcSÁHJWHtHV[£VszhbS4OLMTU}OLMTycñlOL\TXX v NLÛ  x eOLMTyszh¤HJWÁqKNXXKtWrOLX× v NL  x QU7HMkWV;U7\W
WqTO
W&WqKPHMTV5WOLMTKNV&|LKNMKtSÁO
W5KNy¡skhWqTH~VR[!KtWqTUzy¡O
SKP[!U7V5WXJhcV4O
WHV2õO
sXKLeOLMTyÍWqTO
WHV&HMTyKtKNyÍWqK
SKNOLV5U7MËYULS´WqTK!|LUkUny¡QKtSYULSÁ[gOLMTKPULYfV4O
WHV2õO
sH~XHJWhÍ4qKN4mzHMT|cOLXJ|LULS4HJWqT[£Vt§WqKgOLXJ|LULS4HJWq[gVRõMTy
S4O
QH~yTXJhcU7MKg[gUzyKNXlULYfWqK!YZULS4[(\TXOn!{qTHVQU7HMkW®yUzKNV´MULW´O
QTQXh¦irqKNM¡ifKgV5KtKtm¥MULW®U7MTXè
h Â\TV5W
U7MKj[gUzyKNXs\W{OLXXWqK´[!UnyKNXVN
blHMTOLX~XJhLe­HJWPVqU7\TXysKMULW5KNypWqTO
WPWqKcOLXJ|LULS4HWqT[gVYULSgU7\TMkWHM|¥[!UnyKNXVPyKtILKNXULQKNypV5U¡YO
S
O
SK¡yKNVHJ|7MTKNyYZULè
S 5 n
Á
r 
PYULS4[(\TXOLVN  V¤HJW¤qTOLV£sKtKNM^[!KNMkWHJU7MKNy^HMWqK¡HMkW5SUnyT\TWHJU7M<e
U7MKO
QTQXHtO
WHU7M¢ULY®U7\TMWH~M|[!UnyKNXV£HVgHM¢S4KNOLV5U7MTHM|ÏirHJWqÀH~MTU7[!QXJKtW5KcH~MYULSÁ[gO
WHJU7MHMÀXJUL|7H
V5hnV5W5KN[gV{\V\TOLXXJh£KÑzQTS4KNVV5KNycH[
M r54
 Lg 
JtnzLrqKtSKtYZULSKLeTyKtILKNXJULQH~M|gU7\TMkWHM|gOLXJ|LULS4HWqT[gV
YZULS{QTSKNyTH~tO
W5K´tOLXt\TX\TVaYZULS4[(\TXOLV{H~V;OgMKÑnW{4qTOLXXKNM|LK´ULYlO!|LSKNO
WRH~[!QULSWOLMTKL
Õ

Ý¦¥

@ B¯® CqÀn  @

ÚØ

¥KO
SKr|LS4O
W5KtY\TXW5UWqTKROLMU7Mkhz[gU7\TVS4KtYKtSKtKNVYZULSWqKNHS[!U7V5WfO
QTWOLMy£HMTVQHJS4HMT|&U7[g[gKNMWVt{qTHV
SKNV5KNO
SÁ4qqTOLV{sKtKNMcQO
SWXJhV\QTQULSW5KNyszhWqK  V5S4O
KNXEnI tHJKNMTKjbTU7\TMTyTO
WHJU7MÍOLyT[gHMHV5W5S4O
W5KNyszhWqK
 V5S4O
KNX  tOLyKN[h¤ULYHnI tHKNMTKNV{OLMTyK&
p \T[gOLMHJWHJKNVt
uZÄ±°

ê

4
¨ªH¦§¬é¦§ § ]   ( Ó<Ó v ÷ ½ » x  ù v ÷ ÿ » x ¾
®^é¬w¬çª bULS   ( eWqK´SKNt\TSSKNMTK´HMTKN k\TOLX~HJWh}WO
mLKNV{WqK´YZULS4[
ßàà Á ÷ÿ » :
à v  x B Ó v ÷ ½ » Ö  xR:
B ( Y ÿ B Y Ó v÷ Ö ^ ½» Ö
Ó v ÷ ½ » x 5 á à qã BY#
N
( v Y xv  x v  x ý
ààâ
Õ



 

@ CE 

Õ

ô

£R²ë­R¡TìÂíÝî±£²³££

>

Û7BlB Ø



÷ ½ »`Ô

x

G&U7XyTsKtS4| v N7ó
 x VqUµiKNy¹eTWqTO
W{YZULS{WqK´YZU7XXJUµirHM|PSKNt\TSSKNMTKLeJ v ÷
ßàà Á÷» :
ÿ
J v ÷ ½ » x  á à qã BYN#( v BY xv ( x Y v  x B ý Y J v ÷ Ö ^ ½ » Ö  x
àâ 
»

»

 ÄèäAø(÷ 
ÿ
½» x  ù v÷ »

vx
Ä
x

÷ ½ »`Ô

 Ä äAø(÷ 

v x
Ä

{qKËyH¸·KtS4KNMTKËsKtWifKtKNM v  x OLMTy v  x ejWqTKËSKNt\SS4KNMTK¥YULSJ v ÷ ½ » x OLMTyÉWqKÏSKNt\TSSKNMTK¥YZULS
Ó v ÷ ½ » x eTHVWqKKÑnW5S4OPW5KtS4[ v ÿ x B Ó v ÷ ½ » Ö  x H~M£WqK®XO
W5W5KtSoU!U7[!QO
SK&Ó v ÷ ½ » x OLMTyJ v ÷ ½ » x
ifK®õS4V5W;MKtKNy¦WqK®YZU7XXJUoiRHM|PSKNV\TXWt
 
m
÷ `À
Ä L
 
ZT»`ÀÄ;ÓEJ v ÷ ½ » x 5 v ÿ x B ý ( #÷»HÙ
¨Ù¦§  a§ ]¹
®^é¬w¬çª G&U7XysKtS| v N7ó
 x V4qUoifKNy¦WqO
)W J v ÷ ½ » x 5s#÷ ÿ »:+InHMTK´÷³² v ÿ x B ý ( YULSR÷ `ÉÜzeWqTHV
QTSUµILKNV&WqKXJKN[£[gOgYZULSROLXX÷ `ÉÜ}OLMTy¦OLX~X¹k
» `^Än&d&HSKNWRU7[!Q\WO
WHJU7MÍULY J v ÷ ½ » x ey\KjW5U v  x e
YZULS{÷  Ä ½  ½  ½  ½ ØU7[!QXJKtW5KNVrWqK´QTS4UkULYYULSrOLX~X<m
÷ `ÀÄ!OLMTycOLX~X
» `ÀÄn
`RUoiÔÓ v ÷ ½ » x tOLMsK®KNV5WH[£O
W5KNy¦OLV;YZU7XXJUµirVt
 
 L
 
Z¹' Ó<Ó v ÷ ½ » x 5 þ J v ÷ ½ » x Ù
¨Ù¦§   ¦ ]¹
®^é¬w¬çª ¸hHMyT\TWHJU7M¤U7M¥
{qK´OLV4V5KtSWHJU7McH~VaW5S4\K´YZULS{3
» 5Ô

In\QQU7VKHWaH~V;W5S4\K®YZULS{KtILKtSÃh þ²À»:eWqKNM
B B  Y  B Y

Ó v ÷ ½ » x 5 #÷» :Âv x B Ó v ÷ ½ » Ö  4

x : P v Y xv  x v  x ý Ó v ÷ Ö ^ ½ » Ö  x


 tULS4yTHM|!W5U v  x e

YhN#(

5 #÷» :  þ v  x B J v ÷ ½ » Ö  x4:
B
 þ  P v BY xv  x Y v  x B ý Y J v ÷ Ö ^ ½ »
YN#(

Ö x¾

B B  Y  B Y
þ


#


÷
»


:

P v Y xv  x v  x ý J v ÷ Ö ^ ½ » Ö  x ½
YN#(
ÿ
B
Ö
V5UenÓ v ÷ ½ » x 5nJ v ÷ ½ » x²:  v  x J v ÷ ½ »
 x Ö #÷»:bTULSrOLXX» 0 ÄneJ v ÷ ½ » Ö  x 5ÏJ v ÷ ½ »
ÿ
OLMTyszhÚ¹KN[g[gO¦
eTYULSROLXXlÌOLMTyOLX~X:Te v  x B J v ÷ ½ » x 5n#÷»:{qHVaU7[!QXJKtW5KNVrWqK´QTSUzULY0
InH~MTK-J v ÷ ½ » x  ù v ÷ ÿ » x OLMTyÓ v ÷ ½ » x 5 þ J v ÷ ½ » x e
ifK­|LKtWYZULS   ( eoÓ v ÷ ½ » x  ù v ÷ ÿ »
J

v÷ ½» x

uZÄx

xe
x¾

y w z£ùR{d|,¡'}R²Rì8|,±§~¡$R]w­lÙ±¡$²'}R£²3 ± ~
¨ªH¦§¬é¦§ ¦ Ó v ÷ ½ » x  ù v ÷  » x ÓqÞEÔ h + å 	 ý +( ( ý .  Ù
@
 K{OLMTOLXhkÕtKfWqKaSKNt\SS4KNMTKfH~MKN k\OLXHJWh®YZULS:OLMh
e7\TVH~M|RU7MTV4HyKtS4O
WHJU7MVVH~[gHXO
SW5U&WqTU7V5K
®^é¬w¬ç ª ¥
ULYG&U7XysKtS|PKtWrOLXF v NLÛ x 
{qK®S4KNt\SSKNMTK´H~MKN k\OLXHJWh}WO
mLKNVrWqTK®YULS4[c§
Ó v÷ ½» x

ßàà #÷» :
à v  Ö x B Ó v ÷ ½ » Ö  xR:
á
5 à qã BYN#( v BY x  Y v  ÖK x B ý Y Ó
ààâ

v÷ Ö

^

÷ ½ »` 

½» Ö x



v x

 ]Ä äµøP÷ 

»

 W{HV;KNOLV5hW5U£VqTUoi´eTszhHMTyT\TWHU7M}U7MËTeTWqTO
W;Ó v ÷ ½ » x |LSUoirVrirHJWq¡T-prKNMTKLe
Ó v÷ ½» x

58#÷» :Âv  Ö  x B

B
 P v BY x  Y v  Ö x B ý Y Ó
YN#(

Ó v ÷ ½ » x4:

^

v÷ Ö

Ä

½» x¾

vØ x

 V5U7X\WHJU7M¤ULY v Ø x HVaXHMKNO
S;HMTeTV4HMTKWqTHVaSKNt\TSSKNMTK®HVaXHMTKNO
SaH~M}WqTKÓµ´ ©­`RUoiÉYZULSrOLMkh£I
OLX\K
* XJKtW{\TVr4qUzU7V5KjOgU7MV5WOLMW}V4\T4qWqO
W{YULSROLXX<÷m5÷ *
÷

irqKtS4K


å 	 @ ý +( ( ý .

Ó v ÷ ½ » x 58ýk÷  » ½
{qKNMYZULSROLXX÷m5À÷ * e v Ø x e v Ü x Hg
[ QXJh

v  Ö v  Ö x B x Ó v ÷ ½ » x

B
5 #÷» :  P v BY x  Y v  Ö x B ý Y Ó v ÷ Ö ^ ½ » x
YB N#(
5 # ÷» :  P v BY x  Y v  Ö x B ý Y ý v ÷ Ö ^ x  »
Y#N ( B
^
 # ÷» : ký ÷  » þ  P v BY x  Y v  Ö x B ý Y v  Ö ÷ x  ¾
YN#(

 VRG&U7XysKtS|!KtWROLX× v N LÛ x V4qUoifKNy<e

OLMTyWqTKtSKtYULS4KLe

#÷» 

P v BY x  Y v  Ö x B ý Y
Y

v  Ö v  Ö x B x Ó v ÷ ½ » x
ù v ÷» x eTOLMycV5Ue
Ó v÷ ½» x

^ 


v Ö ÷ x

5#÷» : ýk÷  »

5 ýk ÷ Ö  »  v ÖK Ö  B x  : ýk»
v
x

v  Ö x

v

x

uZÄ¹

:

v  ÖK x

ù v÷ ý ( x ½

 : ký »

B·¶¸+(º¹  ý

þ ù v÷

¥KO
S4K®|LU7HM|£MUµiÉW5U!õMyU7\WrU7MTyTHWHJU7MTV;\TMTyTKtSfiRqTH4q
ý ÷  » v  Ö x  ýk» þ ù ÷ »B ¶¼¸+(º¹  ý
v
Ö
Ö B :


vÜ x

(4.

x

þ ù v÷

(4.

5ný÷  »
½

x¾

v x

ý
(

x¾

ê

WqTO
WrH~V

£R²ë­R¡TìÂíÝî±£²³££

Ö  x
 v 
vó x
Ö  xB (¾
 Ö v K
blHJS4V5Wte<XJKtW´ÍyKNMULW5KPWqK!V\sKÑnQTSKNVV4HJU7McULY v ó x H~MV4 k\TO
S4KsTSÁOLmLKtWVt(bULS´OLXX;
eÍHVXJKNVV&WqTOLMp
e
qKNMTKLe[\V5W;sK®|LSKNO
W5KtSRWqOLMËW5U}VO
WH~V5Yhù v ÷ B»¶¼¸+(º¹  ý (4. x 5ÀK
÷ 
G
 IzUe
ù v÷

B»¶¼¸+(º¹  ý

(4.

 &

5 ÷
x ¢

 0



Ö

vÛ x

v  Öè x B yTH[gH~MTHVqKNV:[gU7MULW5U7MTHtOLXXhLezOLMTy}W5KNMTyTVfW5UPÄPOLV÷¾½À¿^eqKNMTK
W5U£[gO
mLK(QU7VHJWHJILKLenifKjMKtKNy
 0 XJUL| ÿ Ö   K
v x
v Ö  x
{qz\TVteÁqUzU7VHM|g v OLMTy}qKNMTKLez÷ * x V\n°}tHJKNMkWXJhPXO
S|LK v yKtQKNMTyTHM|U7M£WqKrI
OLX\K;ULY<WqKù v ÷ ý ( x
KÑnQTSKNVVHU7M}HM v  x5x eTOLMTyyKtW5KtS4[gH~MTHM|®WqKI
OLX\KNVULY !OLMTy¡¤VO
WHV5YZhnHM|U7MyTHJWHJU7MTV v Ü x e v Û x e v  x e
KNV5WO
sX~HVqKNVfÓ v ÷ ½ » x  ù v K
÷ t» x eirqTKtS

K  ¾ 	 ý +( ( ./ 
ý

IzKNU7MTy¹ekYZULS;Ä
² 

²Ô
e

@

uÁ°Å

Õ

y w z£ùR{d|,¡'}R²Rì8|,±§~¡$R]w­lÙ±¡$²'}R£²3 ± ~


 



@ CE ÃÂ¡>

B°Û 

    @ ÚºÜ²ó

	 $ÛE

ÜÚºÜ

`&\T[sKtS;ULY:tXOL\V5KNV
tÄ

Ä

Ä
Ø7Ä
Ü
Ä

Ä
óAÄ
Û
Ä

Ä
tÄLÄ
X 
Ä
Ø7Ä
N
Ä
NÛ
Ä

ÄLÄ

Ø7Ä!I
O
S4HO
sXJKNV
N
AØ
N
ÄLÄ
 LAØ
NLÛLÜL
ØLAØÜ
tÄN
Äó
NÛLnNL
LL 
Ä
Ü
Äó
ÛLÛLÛ
tÄ7 LÛ 
NAØÜLÛ7óµØ

Ä7LÜLÛAØÛ
ØLØLØToó

Ä
 7óLó
Ü
Ä

Ü
ÄgI
O
S4HO
sXJKNV
NÜ
Nn
X 
Ä 
Ü
Äó

N LÛAØ
Ü LL
tÄ7 7ó
AØLØ AØÛ
Ø LnNL
Û
Äó
LL
AØL
ÜLÜ
Äó AØ7Ä
LNÛ AØ LÜ
AØLØLØ7Ä7ÛL
LnLN
Ä
ØÜ

O
sXJKg
§  ILKtS4O
|LKPMk\[jsKtS;ULYSKNt\S4VHILK´tOLXXV;YZULS
`&\T[sKtS;ULY:tXOL\V5KNV
tÄ

Ä

Ä
Ø7Ä
Ü
Ä

Ä
óAÄ
Û
Ä

Ä
tÄLÄ
X 
Ä
Ø7Ä
N
Ä
NÛ
Ä

ÄLÄ


Ä!I
O
S4HO
sXJKNV 
ÄgI
O
S4HO
sXJKNV
Û
ó
ØT
A Ø
LtÄ
ÛLÛ
A Ø
NÛLÜ
Ø

AØÛ
ÜAØÜ
7ó
ÛL Ü
X
 Ä
XA Ø7Ä
NLÛ
oón 

 Ä7ÛL
A Ø
n XL Û
L AØkó
L A Ø
AØn
Ü
 Ä7
LÛn 

Ä7Ün
XL Ln
LÜnX
NÛLLL

O
sXJKlz§  ILKtS4O
|LKPMk\[jsKtS;ULYSKNt\S4VHILK´tOLXXV;YZULS

uÁ°Û


Ä!I
O
S4HO
sXJKNV
X
NÜ
ÛLLÛ
LLL
LX 7óAÄ
LÛAØ7ó
ó
ÜAØkó
NÜ LÛAØ
nLNLLÛ
 LÜ7ózX 
NLÛ7ózØkó
Ø LÛL7ózX 
tÄ7ÛnX L n

Ä 
Ä LÜ 
7ó LÛnX 
Äó

( ÿ 

Ä ¾

Ø7Ä!I
O
S4HO
sXJKNV
ó
L
ó

NÜ
Ä
LL
Ø AØ
 L
nN
X LÜ
NAØkó
7ó
n
Ø L
AØLØ

ÄLÄ
X nN 

( ÿ 

Ä ¾

ê

£R²ë­R¡TìÂíÝî±£²³££

`&\T[jsKtS;ULY:tXOL\TVKNV
tÄ

Ä

Ä
Ø7Ä
Ü
Ä

Ä
óAÄ
Û
Ä

Ä
tÄLÄ
X 
Ä
Ø7Ä
N
Ä
NÛ
Ä

ÄLÄ


Ä!I
O
S4HO
sXKNV 
ÄgIAO
S4H~O
sXJKNV
Ü
o ó

NÜ


Ü 

L

ØÜ
LÜ
ÛL
LØ
Ø
oó
Û
nNÜ
LLÜ
LÛAØ
ØÛL

Äó
ó AØ

ó
Û
tÄ
Ø
XAØ
oó

nNÛ
LLÜ
L 
ØLÜ

Û
Äó
LL

O
sXJKlz§  ILKtS4O
|LKPMk\[jsKtS;ULYSKNt\S4VHILK´tOLXXV;YZULS

`&\T[sKtS;ULY:tXOL\V5KNV
tÄ

Ä

Ä
Ø7Ä
Ü
Ä

Ä
óAÄ
Û
Ä

Ä
tÄLÄ
X 
Ä
Ø7Ä
N
Ä
NÛ
Ä

ÄLÄ


Ä!I
O
S4HO
sXJKNV
L
ÛL

A Ø
tÄLÜ

noó

ØTNLÜ
ó
 Ä7
LoóµØ7Ä
NA Ø
LÜLÛLL
ØLØkóL 
óµØL Û
Ä
tÄ7nXA Ø
ØLØLLÛ
NÛL ÜnN

uÁ°Xê

( ÿ 

Ø7ÄgI
O
S4HO
sXJKNV
tÄ
ó
Ü
L
Ä
ó
Ü
oóAÄ7
AØ LÛ
 LÜ
Ä
tÄ7nN
oó
nN
7ó
ÛAØkó
Ü7ó
ÜAØÛ
tÄ7AØL
NÛLÜLÜLLÛ

Ä
ØLÛ 
Ø LÜ
Ä 

O
sXJK®Ø§  ILKtS4O
|LK(Mk\T[sKtS;ULYS4KNt\S4VHJILK´tOLX~XV;YZULS

Ü

(

Ä ¾

Ü
Ä!I
O
S4HO
sXJKNV


Ä
nL
Ü7ó
X LÜ 
AØkó 
Ø nL
ó

tÄ7LL
N7ó AØ
7óAÄ7Ün
LÛ LÜAØ
Loózoó
Ü

ÄNÛ 

Äó
ÛLÜn
Ä ¾ 
 e  ÿ



Ä ¾

y w z£ùR{d|,¡'}R²Rì8|,±§~¡$R]w­lÙ±¡$²'}R£²3 ± ~

`&\T[sKtS;ULY:tXOL\V5KNV
tÄ

Ä

Ä
Ø7Ä
Ü
Ä

Ä
óAÄ
Û
Ä

Ä
tÄLÄ
X 
Ä
Ø7Ä
N
Ä
NÛ
Ä

ÄLÄ


Ä!I
O
S4HO
sXJKNV

nÜ 
ØT


L Ü
tÄ
ØÛ
NL Û
L
Ä
LÛ
Ä
ØÛnX
ÛLÜLn
Ø7Ä
Ø
nX7 ó
L7ó
Û

Ø7Ä7ÜLÜ
Ä

Ø7ÄgI
O
S4HO
sXJKNV

ØT
LØ
L
ØLØ7Ä
ó
Û
LLoó
oóAÄ7
AØ 
LÜ 

Ä7Û7ó
tÄ n
NÜ
Ä7Û7ó
LÛ 
nNÛLÛ 

O
sXJKjÜz§  ILKtS4O
|LK(Mk\T[sKtS;ULYS4KNt\S4VHJILK´tOLX~XV;YZULS

`&\T[jsKtS;ULY:tXOL\TVKNV
tÄ

Ä

Ä
Ø7Ä
Ü
Ä

Ä
óAÄ
Û
Ä

Ä
tÄLÄ
X 
Ä
Ø7Ä
N
Ä
NÛ
Ä

ÄLÄ

(

Ü
Ä!I
O
S4HO
sXJKNV
Û
L
7ó

Ä7
Ln
ÜLL

Ä
X noó
NnNÜ
LÜLLÛ
ØLØ7Ä
ó LÜAØ
tÄó n
NÜ 7óz

Äó

Ä
Ä ¾ 
 e  ÿ



Ä ¾



Ä ¾


Ä!I
O
S4HO
sXKNV 
ÄgIAO
S4H~O
sXJKNV


A Ø
n
LÜ 
tÄ
NAØ
AØ
7ó
ØÜL

Ä7
ó

LNÛ 
N
Ä7Û
nNÛAØ
LÛLÛ7ó
LÜ 

O
sXJKjz§  ILKtS4O
|LK(Mk\T[sKtS;ULYS4KNt\S4VHJILK´tOLX~XV;YZULS

uÁ°Ä

ØÜ
Û
Ä
XAØ
NÛL
LÜLÜ
LÜ 
ØLØkó
ÜL7ó
ÛLÜn
XLÜ
N n
nNÜL
7óµØ 

(

Ä ¾ ze  ÿ

ê

ñ­SULsO
sHXHJWHJKNV
 (   ÿ  Ä ¾

ò O
S4HO
sXKNV
Ø7Ä
Ü
Ä

( ÿ 

Ä ¾


Ä
Ø7Ä

( ÿ 
(

Ä ¾


Ä

Ä

Ä ¾ 
 e  ÿ

Ä ¾



Ø7Ä
Ü
Ä

(

Ä ¾ 
 e  ÿ

Ä ¾




Ä
Ø7Ä

(

Ä ¾ ze  ÿ



£R²ë­R¡TìÂíÝî±£²³££

Ä ¾


Ä

Ä

_aXOL\TV5KNV
X 
Ä

ÄLÄ
X 
Ä

ÄLÄ
X 
Ä

ÄLÄ
X 
Ä

ÄLÄ
X 
Ä

ÄLÄ
X 
Ä

ÄLÄ
X 
Ä

ÄLÄ
X 
Ä

ÄLÄ
X 
Ä

ÄLÄ
X 
Ä

ÄLÄ
X 
Ä

ÄLÄ
X 
Ä

ÄLÄ

 LI KtS4O
|LK
tÄ7LÛ
 7óLó
Ü
Ä
AØL
LnLN
Ä
ØÜ
LAØkó
NÛLLL
7ó
n
X nN 
L 
LL
LLÜ
ó AØ
Ü7ó
ÜAØÛ
Ø LÜ
Ä 
7óAÄ7Ün

Äó
ÛLÜn
ÛLÜLn
Ø7Ä7ÜLÜ
Ä

Ä7Û7ó
nNÛLÛ 
LNÛ
LÜ 
ÛLÜn
7óµØ 

IzWOLMyTO
S4yyKtInHO
WHJU7M
ØTXA Ø
L n tÄL 

L ØTN
Ä7
ØÜLÛ7óAÄ7L

Ä7
LÛ7ó
Økó

Ä77ó
Ø
tÄ7
LÜ

nNAØ
X LÜnoóz
LtÄ7Ûn

Ä7ÛL7ó
AØLØ
óAÄLÄ
X AØ
 LAØ
NÛ
ÜnØ
X L
L 

O
sXKók§GInOL[!QXKNVaULYV5WOLMyTO
S4ycyKtInHO
WHJU7MULY:Mz\T[sKtS;ULYSKNt\SÁVHJILK´tOLXXV

uÁ°hu

y w z£ùR{d|,¡'}R²Rì8|,±§~¡$R]w­lÙ±¡$²'}R£²3 ± ~

_aXOL\TV5KNV5ÊFW5U
ÊFIAO
S4H~O
sXJKNV;S4O
WHU
Än 
Än Ø
Än 
Än Û

§$ªÆÅ

 

¦


 Ø

 

 Û

ªÆÅ


Ä!I
O
S4HO
sXJKNV
ÜL
7 ó
L Ü
L
X
 Ä
NÜn 
ØLØÜ
XL Û
XL Û
tÄ7Ü
Ä
ó
ÛL
LAØ
ÜLÜLÛ
LÛ7ó
AØT
X LÜ
ÛL
LÜ
ÜLÜ
ØÛ

z 
z Ø

z 
ö

Ë

z Û

ªÆÅ

ªÆÅ

Ç ªÆÅ
È Æª Å
É ªÆÅ
Ê ªÆÅ

Ø7Ä£IAO
S4H~O
sXJKNV
tÄ7ÜL
oóLózNÜ
LX nNÛLÜ
LÜ 
Ä
ØLØ
Ü
Ä LLL
Ü LÛLÜ7ó

Ü LLÜ 
Ä
ØTX LÜL 

Äó
 L
NAØkó
ÜAØ
tÄ7Ü
Ä7ÛL

Ä7ÜAØÛ
AØ7Ä7Ü7ó
NÛLÛ7ó
Ü
LÜ7óµØ
ÛnN
LÜ
LÜ
N
Ä
X LÛ

Ü
Ä!I
O
S4HO
sXJKNV

Ä7 
LÜ
ÄLÄ7LÛ7ó
LN AØ7óAÄ
nX 7ó
LLÛL
AØÛAØ 
Ä LÜ
ÜLAØLØ LÜLÛ
Ä
ØÛLÛ
Ä7ÜAØLØ7Ä
LAØTNnX AØ
LAØAØ7Ä7Ü7ó
Loó
 LÜn
Û 7óLó
Ü L
Ø7Ä 7ó
LÛL

Ä7ÛnØkó
 LÛ
 AØ7Äó
nX L
ØLØ
ÛL
ÜLÜLÛ
Økó


O
sXJKjÛz§ÍKNyTHOLMcMz\T[sKtS;ULYSKNt\TS4VHJILK´tOLXX~V;YULS¢µÊXHJW5KtS4OLX<tXOL\V5KNVteT»

uÁ°Xv

 
Ä

½ 7Ø Ä ½ Ü
Ä

ê

£R²ë­R¡TìÂíÝî±£²³££

ÌÎ Ë Ë
ÌÍ Ë Ë
æ Ì ç æ Í ç Ë èÌ
æ Ì ç æ Í ç Ë èÍ
æ Ì ç æ Í ç Ë èÎ

Ì ÌË Ë
ÌË Ë Ë
Ô Ë Ë
Ó Ë Ë
Õ Ö × Ø Ù Ú
Û Ü Ý Þß Ö à Ù à
àãÛ ÚÙ å

Ò Ë Ë
Ñ Ë Ë
Ð Ë Ë
Ï Ë Ë
Î Ë Ë
Í Ë Ë
ÌË Ë
Ë
Ë

Í Ë

Ï Ë

Ñ Ë
Ó Ë
ÌË Ë
ÌÍ Ë
ÌÏ Ë
Õ Ö × Ø Ù Ú Û Ü Ý Þß Ö à Ù à áâ ãä Ù ÜÛ Ú × Ö Þß

ÌÑ Ë

ÌÓ Ë

Í Ë Ë

blHJ|7\SKg
§  ILKtS4O
|LK(ULY­[gOAÑH[gOLX¹Mz\T[sKtSrULY:tXOL\TV5KNVRV5W5ULSKNyyT\S4H~M|PWqKjS4\MTMTHM|PULY_adñ^YULSÜ
Ä
IAO
S4H~O
sXJKNVt

uÁ°Ä

y w z£ùR{d|,¡'}R²Rì8|,±§~¡$R]w­lÙ±¡$²'}R£²3 ± ~
É3 *  $Û  @ ÝÕ Ø
dONInHVtezÏJeÕÂñ\WMOL[eVp v NL
Ä x 
Rj
´ SnÔ ë¼ §¥eíìte
 Äî;nNÜz

 U7[!Q\WH~M|®QTSUnKNyT\SKaYZULS z\TOLMkWH õtO
WHJU7M!WqTKtULShLêén
Õ#


d\sU7HVteðïT v NLn x n_fU7\MWHMT|;WqK­Mk\[jsKtS¹ULYnV5U7X\WHU7MTVYULSHMTV5WOLMTKNV¹ULYnV4O
WHV2õO
sH~XHJWhLñ=Ôn5N

¼:L_ nòN×tÁteôóöõ v  x eØîzAØ
bS4OLMUe©ïJe=ñlOL\TX~X×e¹Ï v NLÛ x }ñ­SULsO
sHXHV5WH~´OLMTOLXJhnVHV&ULYfWqKgdONInHV2Êñ\TWMTOL[ QTSUnKNyT\S4KYZULS
VU7XJIzH~M|PWqKjVO
WHV5õO
sHXHWhgQTS4ULsXJKN[H×j~ttëD×4
§õLSÔntèLtÁeê÷
eóLóøîzÛ7ók

G&U7XyTsKtS4|e   v N7ó
 x   ILKtS4O
|LK(tOLVKjU7[!QXJKÑHJW¯h¤ULYWqKjV4O
WHV2õO
sH~XHJWh£QTSULsXJKN[c  MØ62oÁ44
Zk

R ´jS ÔnúùTSÔÀÞ¦/\µ/Ôz¨LûënFL7è×P
To
  \V5WHM<eKÑnOLVt

G&U7XyTsKtS4|e  Jeñ\S4yU7[eñJeÝ¸fSUµirM<e_ v NLÛ x   ILKtS4O
|LKjWH~[!K´OLMTOLXJhnVHVfULY:VH[!QXH õKNy}d&OoIzH~V2Ê
ñ\WMTOL[ QSUzKNy\SKNVt Î X´t#7
3ØD5NÁ4ÁZkýüt×4#eõ¦÷ v  x e<óînó
Üz

G&SUµILKLe  JepROLXQKtSÁM<eÁïTJeÿþ´U7XXJKtSNe
d( v NLAØ x   OLMTyU7[ÆifULS4XyTVOLMTy([gOAÑH[\[ÔKNMkW5SULQzhLén
Õ#

R´úë¢ N"L Î Z z#r#t/5hÔe7eîzÛLÛz
 ifOL[gOne£þg v NLÛL x f
 _;`Rb¨VO
WHV2õO
sHXHJW¯hPW5KNV5W;skh}U7\TMWH~M|!OLMTy¤QU7XhzMU7[£HOLXOoILKtS4O
|LK´WH[!KL·ò
é
Õ
 #
L ¼:L_nZk7e©õ ó v  x eÈLÛLÜî;Ln


Î ëú§

ÚH~MTHOLX×el`jJeqÌ`RH~VOLM<e­` v NL
Ä x   QTQSUNÑH[gO
W5KHMTtX\VHJU7MnÊFKÑtX\TVHU7M<¼:
]ÒZLF#
eõ v Ø x e
AØ î;LLÜz
Ú¹ULÕNH~MTV5mnHH×e Ð  v NLÛL x   TM V5ifKtS4HM|gO
W5U7[gH~j z\KtS4HJKNV{H~McHMTyKõMTHJW5K´yKNyT\WHJILKjyTO
WO
sOLVKNVt Î  h#
×
Lôé
ÕÁL ´ Î  ZJktòA(Áe ù v Ø x eØ7ÄîØLz
Ú¹ULÕNH~MTV5mnHH×e Ð  v NL x _fU7\TMkWHM|QTSULQU7VHWHJU7MTOLXz[!UzyTKNXVt Î X ´tÁèL×
oØ62oÁ#ÁÁZküN×hÁÁe
7øó î;z
Ú¹ULÕNH~MTV5mnHH×e Ð  v NLLÜ x   VWqKtSKOLM¤OLXJW5KtS4MTO
WHJILK&W5U(QO
S4VH[gU7MTHJU7\TV­VKN[gOLMWH~tV¨7é
ÕÁL<R´
Z£ÐL
 ñ=Ôn4t×/
ôë¢ ftf
 Î Z z#eìterLnî;7ó
Ûz

ù¯õ

v xe

Ü A	

Ú\TskhLenÏJe' ò KNXH"! mLUoInH
# eT¸& v NLn x qÚM¤yKtW5KtS4[gHMHV5WH;O
QTQSUNÑH[gO
WHJU7M£ULY¹d`Rbf  MÃØ62oÁ44
Zk

R´òêñ

¼ ¦õ

HJW4qKNX~X×erd(Je+IzKNX~[gOLM<e{¸&Je+ Ú¹KtILKNV4 k\KLe+p v NL x  &
p O
S4yºOLMTy^KNOLV5h^yTHV5W5S4Hs\WHJU7MTVPULYI  
QSULsXJKN[gVN  
M Ø62N#44
z
( ´¡ë ëúë Î 7
 ULWq¹ed( v NLL x nÚMpWqKcqO
S4yTMKNVV(ULY&O
QTQTSUoÑnH[£O
W5KSKNOLV5U7MTHMT|
7ó î;
Äz

¢ tf
 Î Z z#e ó 7e
ë

ò OLXHOLMkWteÚ v N7ó
 x ¢{qTK¤U7[!QXJKÑnHWhÏULY&U7[!Q\WH~M|ÍWqTK¤QKtS4[£OLMKNMWt
òtF#eôóLeNÛLî;
Ä


=Ônt×/L1¼:
h
ñ

qTOLMT|e_Æ v NLL x `&\T[sKtS}ULYP[!UnyKNXV¤OLMTyÂVO
WHV2õO
sHXHJW¯h¢ULYV5KtWVULY(tXOL\TV5KNVN =ñ Ôn5N

¼ L_ nòN×tÁteõ¦÷¦÷ v  x e²7óLóøî;LÛLÛz
:
uÁ°°

Journal of Articial Intelligence Research 10 (1999) 271-289

Submitted 11/98; published 5/99

Issues in Stacked Generalization
Kai Ming Ting

kmting@deakin.edu.au

Ian H. Witten

ihw@cs.waikato.ac.nz

School of Computing and Mathematics
Deakin University, Australia.
Department of Computer Science
University of Waikato, New Zealand.

Abstract

Stacked generalization is a general method of using a high-level model to combine lowerlevel models to achieve greater predictive accuracy. In this paper we address two crucial
issues which have been considered to be a `black art' in classication tasks ever since the
introduction of stacked generalization in 1992 by Wolpert: the type of generalizer that is
suitable to derive the higher-level model, and the kind of attributes that should be used as
its input. We nd that best results are obtained when the higher-level model combines the
condence (and not just the predictions) of the lower-level ones.
We demonstrate the eectiveness of stacked generalization for combining three dierent
types of learning algorithms for classication tasks. We also compare the performance of
stacked generalization with majority vote and published results of arcing and bagging.

1. Introduction
Stacked generalization is a way of combining multiple models that have been learned for a
classication task (Wolpert, 1992), which has also been used for regression (Breiman, 1996a)
and even unsupervised learning (Smyth & Wolpert, 1997). Typically, dierent learning
algorithms learn dierent models for the task at hand, and in the most common form of
stacking the rst step is to collect the output of each model into a new set of data. For each
instance in the original training set, this data set represents every model's prediction of that
instance's class, along with its true classication. During this step, care is taken to ensure
that the models are formed from a batch of training data that does not include the instance
in question, in just the same way as ordinary cross-validation. The new data are treated
as the data for another learning problem, and in the second step a learning algorithm is
employed to solve this problem. In Wolpert's terminology, the original data and the models
constructed for them in the rst step are referred to as level-0 data and level-0 models,
respectively, while the set of cross-validated data and the second-stage learning algorithm
are referred to as level-1 data and the level-1 generalizer.
In this paper, we show how to make stacked generalization work for classication tasks
by addressing two crucial issues which Wolpert (1992) originally described as `black art'
and have not been resolved since. The two issues are (i) the type of attributes that should
be used to form level-1 data, and (ii) the type of level-1 generalizer in order to get improved
accuracy using the stacked generalization method.
Breiman (1996a) demonstrated the success of stacked generalization in the setting of
ordinary regression. The level-0 models are regression trees of dierent sizes or linear
c 1999 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

Ting & Witten

regressions using dierent number of variables. But instead of selecting the single model
that works best as judged by (for example) cross-validation, Breiman used the dierent level0 regressors' output values for each member of the training set to form level-1 data. Then
he used least-squares linear regression, under the constraint that all regression coecients
be non-negative, as the level-1 generalizer. The non-negativity constraint turned out to be
crucial to guarantee that the predictive accuracy would be better than that achieved by
selecting the single best predictor.
Here we show how stacked generalization can be made to work reliably in classication
tasks. We do this by using the output class probabilities generated by level-0 models to
form level-1 data. Then for the level-1 generalizer we use a version of least squares linear
regression adapted for classication tasks. We nd the use of class probabilities to be crucial
for the successful application of stacked generalization in classication tasks. However,
the non-negativity constraints found necessary by Breiman in regression are found to be
irrelevant to improved predictive accuracy in our classication situation.
In Section 2, we formally introduce the technique of stacked generalization and describe
pertinent details of each learning algorithm used in our experiments. Section 3 describes
the results of stacking three dierent types of learning algorithms. Section 4 compares
stacked generalization with arcing and bagging, two recent methods that employ sampling
techniques to modify the data distribution in order to produce multiple models from a single
learning algorithm. The following section describes related work, and the paper ends with
a summary of our conclusions.

2. Stacked Generalization

Given a data set L = f(y ; x ); n = 1; : : : ; N g, where y is the class value and x is a vector
representing the attribute values of the nth instance, randomly split the data into J almost
equal parts L1 ; : : : ; L . Dene L and L(, ) = L , L to be the test and training sets for
the j th fold of a J -fold cross-validation. Given K learning algorithms, which we call level-0
generalizers, invoke the kth algorithm on the data in the training set L(, ) to induce a
model M(, ) , for k = 1; : : : ; K . These are called level-0 models.
For each instance x in L , the test set for the j th cross-validation fold, let z denote
the prediction of the model M(, ) on x . At the end of the entire cross-validation process,
the data set assembled from the outputs of the K models is
n

n

n

J

j

j

n

j

j

j

k

n

j

kn

j

n

k

L = f(y ; z1 ; : : : ; z ); n = 1; : : : ; N g:
CV

n

n

Kn

These are the level-1 data. Use some learning algorithm that we call the level-1 generalizer
~ for y as a function of (z1 ; : : : ; z ). This is the level-1
to derive from these data a model M
model. Figure 1 illustrates the cross-validation process. To complete the training process,
the nal level-0 models M , k = 1; : : : ; K , are derived using all the data in L.
Now let us consider the classication process, which uses the models M , k = 1; : : : ; K ,
~ . Given a new instance, models M produce a vector (z1 ; : : : ; z ).
in conjunction with M
~ , whose output is the nal classication result for
This vector is input to the level-1 model M
that instance. This completes the stacked generalization method as proposed by Wolpert
(1992), and also used by Breiman (1996a) and LeBlanc & Tibshirani (1993).
K

k

k

k

272

K

Issues in Stacked Generalization

~
M

L CV
Level-1
Level-0

(-j)

(-j)

M1

(-j)

Mk

MK

(-j)

L

Figure 1: This gure illustrates the j -fold cross-validation process in level-0; and the level-1
~.
data set L at the end of this process is used to produce level-1 model M
CV

~ , the
As well as the situation described above, which results in the level-1 model M
present paper also considers a further situation where the output from the level-0 models is
a set of class probabilities rather than a single class prediction. If model M(, ) is used to
classify an instance x in L , let P (x) denote the probability of the ith output class, and
the vector
P = (P 1 (x ); : : : ; P (x ); : : : ; P (x ))
gives the model's class probabilities for the nth instance, assuming that there are I classes.
As the level-1 data, assemble together the class probability vector from all K models, along
with the actual class:
L0 = f(y ; P1 ; : : : ; P ; : : : ; P ); n = 1; : : : ; N g:
~ 0 to contrast it with M
~.
Denote the level-1 model derived from this as M
The following two subsections describe the algorithms used as level-0 and level-1 generalizers in the experiments reported in Section 3.
j

k

j

ki

kn

CV

n

k

n

n

ki

kn

n

kI

n

Kn

2.1 Level-0 Generalizers

Three learning algorithms are used as the level-0 generalizers: C4.5, a decision tree learning
algorithm (Quinlan, 1993); NB, a re-implementation of a Naive Bayesian classier (Cestnik,
1990); and IB1, a variant of a lazy learning algorithm (Aha, Kibler & Albert, 1991) which
employs the p-nearest-neighbor method using a modied value-dierence metric for nominal
and binary attributes (Cost & Salzberg, 1993). For each of these learning algorithms we
now show the formula that we use
P for the estimated output class probabilities P (x) for an
instance x (where, in all cases, P (x) = 1).
C4.5: Consider the leaf of the decision tree at which the instance x falls. Let m be the
number of (training) instances with class i at this leaf, and suppose the majority class
i

i

i

i

273

Ting & Witten

P
at the leaf is I^. Let E = 6= ^ m . Then, using a Laplace estimator,
i

I

i

P ^(x) = 1 , PEm+ +1 2 ;
I

i

i

P (x) = (1 , P ^(x))  mE ; for i 6= I^:
i

i

I

Note that only pruned trees and default settings of C4.5 are used in our experiments.
NB: Let P (ijx) be the posterior probability of class i, given instance x. Then
P (x) = PP P(ij(xij)x) :
i

i

Note that NB uses a Laplacian estimate for estimating the conditional probabilities
for each nominal attribute to compute P (ijx). For each continuous-valued attribute,
a normal distribution is assumed in which case the conditional probabilities can be
conveniently represented entirely in terms of the mean and variance of the observed
values for each class.
IB1: Suppose p nearest neighbors are used; denote them by f(y ; x ); s = 1; : : : ; pg for
instance x. (We use p = 3 in the experiments.) Then
s

s

P f (y )=d(x; x )
P (x) = P=1 1=d(x; x ) ;
p

s

s

i

s

p

=1

s

s

where f (y ) = 1 if i = y and 0 otherwise, and d is the Euclidean distance function.
s

s

In all three learning algorithms, the predicted class of the level-0 model, given an instance
x, is that I^ for which
P ^(x) > P (x) for all i 6= I^:
I

i

2.2 Level-1 Generalizers

We compare the eect of four dierent learning algorithms as the level-1 generalizer: C4.5,
IB1(using p = 21 nearest neighbors),1 NB, and a multi-response linear regression algorithm,
MLR. Only the last needs further explanation.
MLR is an adaptation of a least-squares linear regression algorithm that Breiman (1996a)
used in regression settings. Any classication problem with real-valued attributes can be
transformed into a multi-response regression problem. If the original classication problem
has I classes, it is converted into I separate regression problems, where the problem for
class ` has instances with responses equal to one when they have class ` and zero otherwise.
The input to MLR is level-1 data, and we need to consider the situation for the model
0
~
M , where the attributes are probabilities, separately from that for the model M~ , where
1. A large value is used following Wolpert's (1992) advice that \ it is reasonable that `relatively global,
smooth ' level-1 generalizers should perform well."
p

:::

:::

274

Issues in Stacked Generalization

they are classes. In the former case, where the attributes are already real-valued, the linear
regression for class ` is simply

X
LR (x) = 
K

`

k`

P (x):
k`

k

In the latter case, the classes are unordered nominal attributes. We map them into binary
values in the obvious way, setting P (x) to 1 if the class of instance x is ` and zero otherwise;
and then use the above linear regression.
Choose the linear regression coecients f g to minimize
k`

X X
j

(

yn ;xn

)2Lj

k`

(y ,
n

X

P (, )(x ))2 :
j

k`

k`

n

k

The coecients f g are constrained to be non-negative, following Breiman's (1996a) discovery that this is necessary for the successful application of stacked generalization to regression problems. The non-negative-coecient least-squares algorithm described by Lawson
& Hanson (1995) is employed here to derive the linear regression for each class. We show
later that, in fact, the non-negative constraint is unnecessary in classication tasks.
With this in place, we can now describe the working of MLR. To classify a new instance
x, compute LR (x) for all I classes and assign the instance to that class ` which has the
greatest value:2
LR (x) > LR (x) for all `0 6= `:
In the next section we investigate the stacking of C4.5, NB and IB1.
k`

`

`

`0

3. Stacking C4.5, NB and IB1

3.1 When Does Stacked Generalization Work?

The experiments in this section show that
 for successful stacked generalization it is necessary to use output class prob~ 0 rather than M
~;
abilities rather than class predictions|that is, M
 only the MLR algorithm is suitable for the level-1 generalizer, among the four
algorithms used.
We use two articial datasets and eight real-world datasets from the UCI Repository of
machine learning databases (Blake, Keogh & Merz, 1998). Details of these are given in
Table 1.
For the articial datasets|Led24 and Waveform|each training dataset L of size 200
and 300, respectively, is generated using a dierent seed. The algorithms used for the
experiments are then tested on a separate dataset of 5000 instances. Results are expressed
as the average error rate of ten repetitions of this entire procedure.
For the real-world datasets, W -fold cross-validation is performed. In each fold of this
cross-validation, the training dataset is used as L, and the models derived are evaluated
2. The pattern recognition community calls this type of classier a linear machine (Duda & Hart, 1973).

275

Ting & Witten

Datasets # Samples # Classes # Attr & Type
Led24
200/5000
10
10N
Waveform 300/5000
3
40C
Horse
368
2
3B+12N+7C
Credit
690
2
4B+5N+6C
Vowel
990
11
10C
Euthyroid
3163
2
18B+7C
Splice
3177
3
60N
Abalone
4177
3
1N+7C
Nettalk(s)
5438
5
7N
Coding
20000
2
15N

N-nominal; B-binary; C-Continuous.

Table 1: Details of the datasets used in the experiment.
on the test dataset. The result is expressed as the average error rate of the W -fold crossvalidation. Note that this cross-validation is used for evaluation of the entire procedure,
whereas the J -fold cross-validation mentioned in Section 2 is the internal operation of
stacked generalization. However, both W and J are set to 10 in the experiments.
~ and
In this section, we present results of model combination using level-1 models M
0
~
M , as well as a model selection method, employing the same J -fold cross-validation procedure. Note that the only dierence between model combination and model selection here
is whether the level-1 learning is employed or not.
Table 2 shows the average error rates, obtained using W -fold cross-validation, of C4.5,
NB and IB1, and BestCV, which is the best of the three, selected using J -fold crossvalidation. As expected, BestCV is almost always the classier with the lowest error rate.3
~ , for which
Table 3 shows the result of stacked generalization using the level-1 model M
~ 0 , for
the level-1 data comprise the classications generated by the level-0 models, and M
which the level-1 data comprise the probabilities generated by the level-0 models. Results
are shown for all four level-1 generalizers in each case, along with BestCV. The lowest error
rate for each dataset is given in bold.
Table 4 summarizes the results in Table 3 in terms of a comparison of each level-1
~ 0 derived
model with BestCV totaled over all datasets. Clearly, the best level-1 model is M
using MLR. It performs better than BestCV in nine datasets and equally well in the tenth.
~ is derived from NB, which performs better than BestCV in seven
The best performing M
datasets but signicantly worse in two (Waveform and Vowel). We regard a dierence of
more than two standard errors as signicant (95% condence). The standard error gures
are omitted in this table to increase readability.
The datasets are shown in the order of increasing size. MLR performs signicantly
better than BestCV in the four largest datasets. This indicates that stacked generalization
is more likely to give signicant improvements in predictive accuracy if the volume of data
is large|a direct consequence of more accurate estimation using cross-validation.
3. Note that BestCV does not always select the same classier in all folds. That is why its error rate is
not always equal to the lowest error rate among the three classiers.
W

276

Issues in Stacked Generalization

Datasets

Level-0 Generalizers
C4.5 NB
IB1
Led24
35.4 35.4
32.2
Waveform 31.8 17.1
26.2
Horse
15.8 17.9
15.8
Credit
17.4 17.3
28.1
Vowel
22.7 51.0
2.6
Euthyroid 1.9 9.8
8.6
Splice
5.5 4.5
4.7
Abalone
41.4 42.1
40.5
Nettalk(s) 17.0 15.9
12.7
Coding
27.6 28.8
25.0

BestCV
32.8 0.6
17.1 0.3
17.1 1.6
17.4 1.2
2.6 0.2
1.9 0.3
4.5 0.4
40.1 0.6
12.7 0.4
25.0 0.3

Table 2: Average error rates of C4.5, NB and IB1, and BestCV|the best among them
selected using J -fold cross-validation. The standard errors are shown in the last
column.
Datasets

~
Level-1 model, M
C4.5 NB IB1 MLR
34.0 32.4 35.0 33.3
17.7 19.2 18.7 17.2
16.9 14.9 17.6 16.3
18.4 16.1 16.9 17.4
2.6 3.8 3.6
2.6

BestCV
Led24
32.8
Waveform
17.1
Horse
17.1
Credit
17.4
Vowel
2.6
Euthyroid
1.9 1.9 1.9 1.9
Splice
4.5 3.9 3.9 3.8
Abalone
40.1 38.5 38.5 38.2
Nettalk(s)
12.7 12.4 11.9 12.4
Coding
25.0 23.2 23.1 23.2

1.9
3.8

38.1
12.6
23.2

~0
Level-1 model, M
C4.5 NB IB1 MLR
41.7 35.7 32.1 31.3
20.6 17.6 17.8 16.8
18.0 18.5 17.7 15.2
15.4 15.9 14.3 16.2
2.7 7.2 3.3 2.5
2.2 4.3 2.0 1.9
4.0 3.9 3.8 3.8
43.3 37.1 39.2 38.3
14.0 14.6 12.0 11.5
22.3 21.2 21.2 20.7

Table 3: Average error rates for stacking C4.5, NB and IB1.
~
~0
Level-1 model, M
Level-1 model, M
C4.5 NB IB1 MLR C4.5 NB IB1 MLR
#Win vs. #Loss 3-5 2-7 4-5 2-5 7-3 6-4 4-6 0-9
~ and M
~ 0.
Table 4: Summary of Table 3|Comparison of BestCV with M

277

Ting & Witten

When one of the level-0 models performs signicantly much better than the rest, like in
the Euthyroid and Vowel datasets, MLR performs either as good as BestCV by selecting
the best performing level-0 model, or better than BestCV.
MLR has an advantage over the other three level-1 generalizers in that its model can
easily be interpreted. Examples of the combination weights it derives (for the probability~ 0 ) appear in Table 5 for the Horse, Credit, Splice, Abalone, Waveform, Led24
based model M
and Vowel datasets. The weights indicate the relative importance of the level-0 generalizers
for each prediction class. For example, in the Splice dataset (in Table 5(b)), NB is the
dominant generalizer for predicting class 2, NB and IB1 are both good at predicting class
3, and all three generalizers make a worthwhile contribution to the prediction of class 1.
In contrast, in the Abalone dataset all three generalizers contribute substantially to the
prediction of all three classes. Note that the weights for each class do not sum to one
because no such constraint is imposed on MLR.

3.2 Are Non-negativity Constraints Necessary?
Both Breiman (1996a) and LeBlanc & Tibshirani (1993) use the stacked generalization
method in a regression setting and report that it is necessary to constrain the regression
coecients to be non-negative in order to guarantee that stacked regression improves predictive accuracy. Here we investigate this nding in the domain of classication tasks.
To assess the eect of the non-negativity constraint on performance, three versions of
~ 0:
MLR are employed to derive the level-1 model M
i. each linear regression in MLR is calculated with an intercept constant (that is,
I + 1 weights for the I classes) but without any constraints;
ii. each linear regression is derived with neither an intercept constant (I weights
for I classes) nor constraints;
iii. each linear regression is derived without an intercept constant, but with nonnegativity constraints (I non-negative weights for I classes).
The third version is the one used for the results presented earlier. Table 6 shows the
results of all three versions. They all have almost indistinguishable error rates. We conclude
that in classication tasks, non-negativity constraints are not necessary to guarantee that
stacked generalization improves predictive accuracy.
However, there is another reason why it is a good idea to employ non-negativity constraints. Table 7 shows an example of the weights derived by these three versions of MLR on
the Led24 dataset. The third version, shown in column (iii), supports a more perspicuous
interpretation of each level-0 generalizer's contribution to the class predictions than do the
other two. In this dataset, IB1 is the dominant generalizer in predicting classes 4, 5 and 8,
and both NB and IB1 make a worthwhile contribution in predicting class 2, as evidenced
by their high weights. However, the negative weights used in predicting these classes render
the interpretation of the other two versions much less clear.
278

Issues in Stacked Generalization

Horse
Credit
Class C4.5 NB IB1 C4.5 NB IB1
1
0.36 0.20 0.42 0.63 0.30 0.04
2
0.39 0.19 0.41 0.65 0.28 0.07
C4.5 for 1 ; NB for 2 ; IB1 for 3 .
~ 0 ) for the Horse and Credit datasets.
Table 5: (a) Weights generated by MLR (model M
Class
1
2
3

C4.5
0.23
0.15
0.08

Splice
NB
0.43
0.72
0.52

IB1
0.36
0.12
0.40

Abalone
C4.5 NB IB1
0.25 0.25 0.39
0.27 0.20 0.25
0.30 0.18 0.39

Waveform
C4.5 NB IB1
0.16 0.59 0.34
0.14 0.72 0.07
0.04 0.65 0.23

~ 0 ) for the Splice, Abalone and Waveform
Table 5: (b) Weights generated by MLR (model M
datasets.
Vowel
C4.5 NB IB1
0.04 0.00 0.96
0.03 0.00 0.97
0.01 0.00 1.00
0.05 0.25 0.86
0.01 0.08 0.97
0.15 0.00 0.92
0.03 0.01 1.02
0.04 0.01 0.96
0.03 0.00 1.02
0.08 0.01 0.93
0.00 0.04 0.96
~ 0 ) for the Led24 and Vowel datasets.
Table 5: (c) Weights generated by MLR (model M
Class
1
2
3
4
5
6
7
8
9
10
11

C4.5
0.46
0.00
0.47
0.00
0.00
0.35
0.15
0.00
0.00
0.00
{

Led24
NB
0.65
0.37
0.00
0.13
0.19
0.14
0.43
0.00
0.38
0.50
{

IB1
0.00
0.43
0.54
0.65
0.64
0.35
0.36
0.68
0.29
0.24
{

279

Ting & Witten

Datasets

MLR with
No Constraints No Intercept Non-Negativity
Led24
31.4
31.4
31.3
Waveform
16.8
16.8
16.8
Horse
15.8
15.8
15.2
Credit
16.2
16.2
16.2
Vowel
2.4
2.4
2.5
Euthyroid
1.9
1.9
1.9
Splice
3.7
3.8
3.8
Abalone
38.3
38.3
38.3
Nettalk(s)
11.6
11.5
11.5
Coding
20.7
20.7
20.7
Table 6: Average error rates of three versions of MLR.
Class
1
2
3
4
5
6
7
8
9
10

0

0.00
0.02
0.00
0.04
0.03
0.01
0.01
0.02
0.04
0.04

1

(i)

2

3

1

(ii)

2

3

1

0.45 0.65 0.00 0.46 0.65 0.00 0.46
{0.42 0.47 0.56 {0.40 0.49 0.56 0.00
0.46 {0.01 0.54 0.47 {0.01 0.54 0.47
{0.33 0.15 0.84 {0.29 0.21 0.81 0.00
{0.37 0.26 0.84 {0.32 0.26 0.84 0.00
0.35 0.12 0.35 0.36 0.14 0.35 0.35
0.15 0.43 0.36 0.15 0.43 0.36 0.15
{0.05 {0.25 0.72 {0.03 {0.19 0.72 0.00
{0.08 0.32 0.32 {0.05 0.40 0.30 0.00
{0.06 0.43 0.25 {0.01 0.50 0.24 0.00

(iii)

2

0.65
0.37
0.00
0.13
0.19
0.14
0.43
0.00
0.38
0.50

3

0.00
0.43
0.54
0.65
0.64
0.35
0.36
0.68
0.29
0.24

Table 7: Weights generated by three versions of MLR: (i) no constraints, (ii) no intercept,
and (iii) non-negativity constraints, for the LED24 dataset.

280

Issues in Stacked Generalization

Dataset
#SE BestCV Majority MLR
Horse
0.5
17.1
15.0 15.2
Splice
2.5
4.5
4.0 3.8
Abalone
3.3
40.1
39.0 38.3
Led24
8.7
32.8
31.8 31.3
Credit
8.9
17.4
16.1 16.2
Nettalk(s) 10.8
12.7
12.2 11.5
Coding
12.7
25.0
23.1 20.7
Waveform 18.7
17.1
19.5 16.8
Euthyroid 26.3
1.9
8.1 1.9
Vowel
242.0
2.6
13.0 2.5
~ 0 ), along with
Table 8: Average error rates of BestCV, Majority Vote and MLR (model M
the number of standard error (#SE) between BestCV and the worst performing
level-0 generalizers.

3.3 How Does Stacked Generalization Compare To Majority Vote?
~ 0 , derived from MLR, to that of majority vote,
Let us now compare the error rate of M

a simple decision combination method which requires neither cross-validation nor level1 learning. Table 8 shows the average error rates of BestCV, majority vote and MLR.
In order to see whether the relative performances of level-0 generalizers have any eect
on these methods, the number of standard errors (#SE) between the error rates of the
worst performing level-0 generalizer and BestCV is given, and the datasets are re-ordered
according to this measure. Since BestCV almost always selects the best performing level-0
generalizer, small values of #SE indicate that the level-0 generalizers perform comparably
to one another, and vice versa.
MLR compares favorably to majority vote, with eight wins versus two losses. Out of
the eight wins, six have signicant dierences (the two exceptions are for the Splice and
Led24 datasets); whereas both losses (for the Horse and Credit datasets) have insignicant
dierences. Thus the extra computation for cross-validation and level-1 learning seems to
have paid o.
It is interesting to note that the performance of majority vote is related to the size of
#SE. Majority vote compares favorably to BestCV in the rst seven datasets, where the
values of #SE are small. In the last three, where #SE is large, majority vote performs
worse. This indicates that if the level-0 generalizers perform comparably, it is not worth
using cross-validation to determine the best one, because the result of majority vote|which
is far cheaper|is not signicantly dierent. Although small values of #SE are a necessary
condition for majority vote to rival BestCV, they are not a sucient condition|see Matan
(1996) for an example. The same applies when majority vote is compared with MLR. MLR
performs signicantly better in the ve datasets that have large #SE values, but in only
one of the other cases.
281

Ting & Witten

M~ versus M~ 0

C4.5 NB IB1 MLR
#Win vs. #Loss 8-2 5-4 3-6 1-7
~ versus M
~ 0 for each generalizer|summarized results from Table 3.
Table 9: M
It is worth mentioning a method that averages P (x) for each i over all level-0 models,
yielding P (x), and then predicts class I^ for which P^(x) > P (x) for all i 6= I^: According to
Breiman (1996b), this method produces an error rate almost identical to that of majority
vote.
i

i

I

i

3.4 Why Does Stacked Generalization Work Best With M~ 0 Generated From
MLR?
We have shown that stacked generalization works best when output class probabilities
(rather than class predictions) are used with the MLR algorithm (rather than C4.5, IB1,
NB). In retrospect, this is not surprising, and can be explained intuitively as follows. The
level-1 model should provide a simple way of combining all the evidence available. This
evidence includes not just the predictions, but the condence of each level-0 model in
its predictions. A linear combination is the simplest way of pooling the level-0 models'
condence, and MLR provides just that.
The alternative methods of NB, C4.5, and IB1 each have shortcomings. A Bayesian approach could form the basis for a suitable alternative way of pooling the level-0 models' condence, but the independence assumption central to Naive Bayes hampers its performance in
some datasets because the evidence provided by the individual level-0 models is certainly not
independent. C4.5 builds trees that can model interaction amongst attributes|particularly
when the tree is large|but this is not desirable for combining condences. Nearest neighbor methods do not really give a way of combining condences; also, the similarity metric
employed could misleadingly assume that two dierent sets of condence levels are similar.
~ with M
~ 0 for each level-1
Table 9 summarizes the results in Table 3 by comparing M
generalizer, across all datasets. C4.5 is clearly better o with a label-based representation,
because discretizing continuous-valued attributes creates intra-attribute interaction in addition to interactions between dierent attributes. The evidence from Table 9 is that NB
is indierent to the use of labels or condences: the normal distribution assumption that
it embodies in the latter case could be another reason why it is unsuitable for combining
condence measures. Both MLR and IB1 handle continuous-valued attributes better than
label-based ones, since this is the domain in which they are designed to work.
Summary

We summarize our ndings in this section as follows.

 None of the four learning algorithms used to obtain model M~ perform satisfactorily.
282

Issues in Stacked Generalization

 MLR is the best of the four learning algorithms to use as the level-1 generalizer for
~ 0.
obtaining the model M
 When obtained using MLR, M~ 0 has lower predictive error rate than the best model
selected by J -fold cross-validation, for almost all datasets used in the experiments.

 Another advantage of MLR over the other three level-1 generalizers is its interpretability.
The weights  indicate the dierent contributions that each level-0 model k makes
to the prediction classes `.
k`

 Model M~ 0 can be derived by MLR with or without non-negativity constraints. Such
constraints make little dierence to the model's predictive accuracy.

 The use of non-negativity constraints in MLR has the advantage of interpretability. Non-

negative weights  support easier interpretation of the extent to which each model
contributes to each prediction class.
k`

 When derived using MLR, model M~ 0 compares favorably with majority vote.
 MLR provides a method of combining the condence generated by the level-0 models into
a nal decision. For various reasons, NB, C4.5, and IB1 are not suitable for this task.

4. Comparison With Arcing And Bagging
This section compares the results of stacking C4.5, NB and IB1 with the results of arcing
(called boosting by its originator, Schapire, 1990) and bagging that are reported by Breiman
(1996b; 1996c). Both arcing and bagging employ sampling techniques to modify the data
distribution in order to produce multiple models from a single learning algorithm. To
combine the decisions of the individual models, arcing uses a weighted majority vote and
bagging uses an unweighted majority vote. Breiman reports that both arcing and bagging
can substantially improve the predictive accuracy of a single model derived using a base
learning algorithm.

4.1 Experimental Results

First we describe the dierences between the experimental procedures. Our results for
stacking are averaged over ten-fold cross-validation for all datasets except Waveform, which
is averaged over ten repeated trials. Standard errors are also shown. Results for arcing and
bagging are those obtained by Breiman (1996b; 1996c), which are averaged over 100 trials.
In Breiman's experiments, each trial uses a random 9:1 split to form the training and test
sets for all datasets except Waveform. Also note that the Waveform dataset we used has 19
irrelevant attributes, but Breiman used a version without irrelevant attributes (which would
be expected to degrade the performance of level-0 generalizers in our experiments). In both
cases 300 training instances were used for this dataset, but we used 5000 test instances
whereas Breiman used 1800. Arcing and bagging are done with 50 decision tree models
derived from CART (Breiman et al., 1984) in each trial.
283

Ting & Witten

Dataset
#Samples stacking arcing bagging
Waveform
300
16.8 0.2 17.8
19.3
Glass
214
28.4 2.9 22.0
23.2
Ionosphere
351
9.7 1.5
6.4
7.9
Soybean
683
4.3 1.1
5.8
6.8
Breast Cancer
699
2.7 0.8
3.2
3.7
Diabetes
768
24.2 1.2 26.6
23.9
Table 10: Comparing stacking with arcing and bagging classiers.
The results on six datasets are given in Table 10, and indicate that the three methods
are very competitive.4 Stacking performs better than both arcing and bagging in three
datasets (Waveform, Soybean and Breast Cancer), and is better than arcing but worse than
bagging in the Diabetes dataset. Note that stacking performs very poorly on Glass and
Ionosphere, two small real-world datasets. This is not surprising, because cross-validation
inevitably produces poor estimates for small datasets.

4.2 Discussion

Like bagging, stacking is ideal for parallel computation. The construction of each level-0
model proceeds independently, no communication with the other modeling processes being
necessary.
Arcing and bagging require a considerable number of member models because they
rely on varying the data distribution to get a diverse set of models from a single learning
algorithm. Using a level-1 generalizer, stacking can work with only two or three level-0
models.
Suppose the computation time required for a learning algorithm is C , and arcing or
bagging needs h models. The learning time required is T = hC . Suppose stacking requires
g models and each model employs J -fold cross-validation. Assuming that time C is needed
to derive each of the g level-0 models and the level-1 model, the learning time for stacking
is T = (g(J + 1) + 1)C . For the results given in Table 10, h = 50, J = 10, and g = 3; thus
T = 50C and T = 34C . However, in practice the learning time required for the level-0
and level-1 generalizers may be dierent.
Users of stacking have a free choice of level-0 models. They may either be derived from a
single learning algorithm, or from a variety of dierent algorithms. The example in Section
3 uses dierent types of learning algorithms, while bag-stacking|stacking bagged models
(Ting & Witten, 1997)|uses data variation to obtain a diverse set of models from a single
learning algorithm. In the former case, performance may vary substantially between the
level-0 models|for example NB performs very poorly in the Vowel and Euthyroid datasets
compared to the other two models (see Table 2). Stacking copes well with this situation.
The performance variation among the member models in bagging is rather small because
they are derived from the same learning algorithm using bootstrap samples. Section 3.3
a

s

a

s

4. The heart dataset used by Breiman (1996b; 1996c) is omitted because it was very much modied from
the original one.

284

Issues in Stacked Generalization

shows that a small performance variation among member models is a necessary condition
for majority vote (as employed by bagging) to work well.
It is worth noting that arcing and bagging can be incorporated into the framework of
stacked generalization by using arced or bagged models as level-0 models. Ting & Witten
(1997) show one possible way of incorporating bagged models with level-1 learning, employing MLR instead of voting. In this implementation, L is used as a test set for each
of the bagged models to derive level-1 data rather than the cross-validated data. This is
viable because each bootstrap sample leaves out about 37% of the examples. Ting & Witten
(1997) show that bag-stacking almost always has higher predictive accuracy than bagging
models derived from either C4.5 or NB. Note that the only dierence here is whether an
adaptive level-1 model or a simple majority vote is employed
According to Breiman (1996b; 1996c), arcing and bagging can only improve the predictive accuracy of learning algorithms that are `unstable.'5 An unstable learning algorithm
is one for which small perturbations in the training set can produce large changes in the
derived model. Decision trees and neural networks are unstable; NB and IB1 are stable.
Stacking works with both.
While MLR is the most successful candidate for level-1 learning that we have found,
other algorithms might work equally well. One candidate is neural networks. However,
we have experimented with back-propagation neural networks for this purpose and found
that they have a much slower learning rate than MLR. For example, MLR only took 2.9
seconds as compare to 4790 seconds for the neural network in the nettalk dataset; while
both have the same error rate. Other possible candidates are the multinomial logit model
(Jordan & Jacobs, 1994), which is a special case of generalized linear models (McCullagh
& Nelder, 1983), and the supra Bayesian procedure (Jacobs, 1995) which treats the level-0
models' condence as data that may be combined with prior distribution of level-0 models
via Bayes' rule.

5. Related Work

Our analysis of stacked generalization was motivated by that of Breiman (1996a), discussed
earlier, and LeBlanc & Tibshirani (1993). LeBlanc & Tibshirani (1993) examine the stacking
of a linear discriminant and a nearest neighbor classier and show that, for one articial
dataset, a method similar to MLR performs better with non-negativity constraints than
without. Our results in Section 3.2 show that these constraints are irrelevant to MLR's
predictive accuracy in the classication situation.
LeBlanc & Tibshirani (1993) and Ting & Witten (1997) use a version of MLR that
employs all class probabilities from each level-0 model to induce each linear regression. In
this case, the linear regression for class ` is

LR (x) =
`

XX
K

I

k

i

ki`

P (x):
ki

This implementation requires the tting of KI parameters, as compared to K parameters
for the version used in this paper (see the corresponding formula in Section 2.2). Both
5. Schapire, R.E., Y. Freund, P. Bartlett, & W.S. Lee (1997) provide an alternative explanation for the
eectiveness of arcing and bagging.

285

Ting & Witten

versions give comparable results in terms of predictive accuracy, but the version used in
this paper runs considerably faster because it needs to t fewer parameters.
The limitations of MLR are well-known (Duda & Hart, 1973). For a I -class problem, it
divides the description space into I convex decision regions. Every region must be singly
connected, and the decision boundaries are linear hyperplanes. This means that MLR is
most suitable for problems with unimodal probability densities. Despite these limitations,
MLR still performs better as a level-1 generalizer than IB1, its nearest competitor in deriving
M~ 0. These limitations may hold the key to a fuller understanding of the behavior of stacked
generalization. Jacobs (1995) reviews linear combination methods like that used in MLR.
Previous work on stacked generalization, especially as applied to classication tasks,
has been limited in several ways. Some only applies to a particular dataset (e.g., Zhang,
Mesirov & Waltz, 1992). Others report results that are less than convincing (Merz, 1995).
Still others have a dierent focus and evaluate the results on just a few datasets (LeBlanc
& Tibshirani, 1993; Chan & Stolfo, 1995; Kim & Bartlett, 1995; Fan et al., 1996).
One might consider a degenerate form of stacked generalization that does not use crossvalidation to produce data for level-1 learning. Then, level-1 learning can be done `on the
y' during the training process (Jacobs et al., 1991). In another approach, level-1 learning
takes place in batch mode, after all level-0 models are derived (Ho et al., 1994).
Several researchers have worked on a still more degenerate form of stacked generalization
without any cross-validation or learning at level 1. Examples are neural network ensembles
(Hansen & Salamon, 1990; Perrone & Cooper, 1993; Krogh & Vedelsby, 1995), multiple
decision tree combination (Kwok & Carter, 1990; Buntine, 1991; Oliver & Hand, 1995), and
multiple rule combination (Kononenko & Kovacic, 1992). The methods used at level 1 are
majority voting, weighted averaging and Bayesian combination. Other possible methods are
distribution summation and likelihood combination. There are various forms of re-ordering
class rank, and Ali & Pazzani (1996) study some of these methods for a rule learner. Ting
(1996) uses the condence of each prediction to combine a nearest neighbor classier and a
Naive Bayesian classier.

6. Conclusions
We have addressed two crucial issues for the successful implementation of stacked generalization in classication tasks. First, class probabilities should be used instead of the single
predicted class as input attributes for higher-level learning. The class probabilities serve as
the condence measure for the prediction made. Second, the multi-response least squares
linear regression technique should be employed as the high-level generalizer. This technique
provides a method of combining level-0 models' condence. The other three learning algorithms have either algorithmic limitations or are not suitable for aggregating condences.
When combining three dierent types of learning algorithms, this implementation of
stacked generalization was found to achieve better predictive accuracy than both model
selection based on cross-validation and majority vote; it was also found to be competitive with arcing and bagging. Unlike stacked regression, non-negativity constraints in the
least-squares regression are not necessary to guarantee improved predictive accuracy in
classication tasks. However, these constraints are still preferred because they increase the
interpretability of the level-1 model.
286

Issues in Stacked Generalization

The implication of our successful implementation of stacked generalization is that earlier
model combination methods employing (weighted) majority vote, averaging, or other computations that do not make use of level-1 learning, can now apply this learning to improve
their predictive accuracy.

Acknowledgment

The authors are grateful to the New Zealand Marsden Fund for nancial support for this
research. This work was conducted when the rst author was in Department of Computer
Science, University of Waikato. The authors are grateful to J. Ross Quinlan for providing
C4.5 and David W. Aha for providing IB1. The anonymous reviewers and the editor have
provided many helpful comments.

References

Aha, D.W., D. Kibler & M.K. Albert (1991). Instance-Based Learning Algorithms. Machine Learning, 6, pp. 37-66.
Ali, K.M. & M.J. Pazzani (1996). Error Reduction through Learning Multiple Descriptions. Machine Learning, Vol. 24, No. 3, pp. 173-206.
Blake, C., E. Keogh & C.J. Merz (1998). UCI Repository of machine learning databases
[http:// www.ics.uci.edu/ mlearn/MLRepository.html]. Irvine, CA: University of California, Department of Information and Computer Science.
Breiman, L. (1996a). Stacked Regressions. Machine Learning, Vol. 24, pp. 49-64.
Breiman, L. (1996b). Bagging Predictors. Machine Learning, Vol. 24, No. 2, pp. 123-140.
Breiman, L. (1996c). Bias, Variance, and Arcing Classiers. Technical Report 460. Department of Statistics, University of California, Berkeley, CA.
Breiman, L., J.H. Friedman, R.A. Olshen & C.J. Stone (1984). Classication And Regression Trees. Belmont, CA: Wadsworth.
Cestnik, B. (1990). Estimating Probabilities: A Crucial Task in Machine Learning. In
Proceedings of the European Conference on Articial Intelligence, pp. 147-149.
Chan, P.K. & S.J. Stolfo (1995). A Comparative Evaluation of Voting and Meta-learning
on Partitioned Data. In Proceedings of the Twelfth International Conference on Machine Learning, pp. 90-98, Morgan Kaufmann.
Cost, S & S. Salzberg (1993). A Weighted Nearest Neighbor Algorithm for Learning with
Symbolic Features. Machine Learning, 10, pp. 57-78.
Fan, D.W., P.K. Chan, S.J. Stolfo (1996). A Comparative Evaluation of Combiner and
Stacked Generalization. In Proceedings of AAAI-96 workshop on Integrating Multiple
Learned Models, pp. 40-46.
Hansen, L.K. & P. Salamon (1990). Neural Network Ensembles. IEEE Transactions of
Pattern Analysis and Machine Intelligence, 12, pp. 993-1001.
287

Ting & Witten

Ho, T.K., J.J. Hull & S.N. Srihari (1994). Decision Combination in Multiple Classier
Systems. IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 16,
No. 1, pp. 66-75.
Jacobs, R.A. (1995). Methods of Combining Experts' Probability Assessments. Neural
Computation 7, pp. 867-888, MIT Press.
Jacobs, R.A., M.I. Jordan, S.J. Nowlan & G.E. Hinton (1991). Adaptive Mixtures of Local
Experts. Neural Computation 3, pp. 79-87.
Jacobs, R.A. & M.I. Jordan (1994). Hierachical Mixtures of Experts and the EM Algorithms. Neural Computation 6, pp. 181-214.
Kim, K. & E.B. Bartlett (1995). Error Estimation by Series Association for Neural Network
Systems. Neural Computation 7, pp. 799-808, MIT Press.
Kononenko, I. & M. Kovacic (1992). Learning as Optimization: Stochastic Generation
of Multiple Knowledge. In Proceedings of the Ninth International Conference on
Machine Learning, pp. 257-262, Morgan Kaufmann.
Krogh, A. & J. Vedelsby (1995). Neural Network Ensembles, Cross Validation, and Active
Learning. Advances in Neural Information Processing Systems 7, G. Tesauro, D.S.
Touretsky & T.K. Leen (Editors), pp. 231-238, MIT Press.
Kwok, S. & C. Carter (1990). Multiple Decision Trees. Uncertainty in Articial Intelligence 4, R. Shachter, T. Levitt, L. Kanal and J. Lemmer (Editors), pp. 327-335,
North-Holland.
Lawson C.L. & R.J. Hanson (1995). Solving Least Squares Problems. SIAM Publications.
LeBlanc, M. & R. Tibshirani (1993). Combining Estimates in Regression and Classication. Technical Report 9318. Department of Statistics, University of Toronto.
Matan, O. (1996). On Voting Ensembles of Classiers (extended abstract). In Proceedings
of AAAI-96 workshop on Integrating Multiple Learned Models, pp. 84-88.
McCullagh, P. & J.A. Nelder (1983). Generalized Linear Models. London: Chapman and
Hall.
Merz, C.J. (1995). Dynamic Learning Bias Selection. In Proceedings of the Fifth International Workshop on Articial Intelligence and Statistics, Ft. Lauderdale, FL:
Unpublished, pp. 386-395.
Oliver, J.J. & D.J. Hand (1995). On Pruning and Averaging Decision Trees. In Proceedings
of the Twelfth International Conference on Machine Learning, pp. 430-437, Morgan
Kaufmann.
Perrone, M.P. & L.N. Cooper (1993). When Networks Disagree: Ensemble Methods for
Hybrid Neural Networks. Articial Neural Networks for Speech and Vision, R.J.
Mammone (Editor). Chapman-Hall.
Quinlan, J.R. (1993). C4.5: Program for machine learning. Morgan Kaufmann.
288

Issues in Stacked Generalization

Schapire, R.E. (1990). The Strength of Weak Learnability. Machine Learning, 5, pp.
197-227, Kluwer Academic Publishers.
Schapire, R.E., Y. Freund, P. Bartlett, & W.S. Lee (1997). Boosting the margin: A new
explanation for the eectiveness of voting methods. In Proceedings of the Fourteenth
International Conference on Machine Learning, pages 322-330, Morgan Kaufmann.
Smyth, P. & D. Wolpert (1997). Stacked Density Estimation. Advances in Neural Information Processing Systems.
Ting, K.M. (1996). The Characterisation of Predictive Accuracy and Decision Combination. In Proceedings of the Thirteenth International Conference on Machine Learning,
pp. 498-506, Morgan Kaufmann.
Ting, K.M. & I.H. Witten (1997). Stacking Bagged and Dagged Models. In Proceedings of
the Fourteenth International Conference on Machine Learning, pp. 367-375, Morgan
Kaufmann.
Weiss S. M. & C. A. Kulikowski (1991). Computer Systems That Learns. Morgan Kaufmann.
Wolpert, D.H. (1992). Stacked Generalization. Neural Networks, Vol. 5, pp. 241-259,
Pergamon Press.
Zhang, X., J.P. Mesirov & D.L. Waltz (1992). Hybrid System for Protein Secondary
Structure Prediction. Journal of Molecular Biology, 225, pp. 1049-1063.

289

	
 	


 ! #"$ % 	'&)( *,+'( ---.$/10 24315

A

64789 :;/1<-3!=>7
%&:@?<--

BDCFEHGJIKMLNKPORQTSVUHW4KXICZY\[HK]CFLNKMSV^_Ca`bBDC;OcQdGHegfih!GjK

kmlonqpsrutwvyx,z|{~}'r,p

oTssooo

Ns,~ ¡¢PN£]¤¦¥'M§s¨1s¨©Mªd«¤¬1£a¦
­ ®¬¨¬¢°¯j±³²´µ¶q·
®¤s¸ ¹º¹»m»m»½¼¨¼¨s¼©¾q¥¹®¿£F«¹¦®¬ ¤1

ÀyÁ;ÂºÃ¿ÄÅmÆÃ
Ç#ÈÉÊ ËaÌ#Í4ÎÎÏ«ÐÑÈÌ,ÑÓÒ©Ô¿ÍÈÕ Í!ÖØ× ÙËÚÒ ÛÜ ÝÛÞÑ¿ß|Ò©Ô¿ÍHÙËÚÍjÈqÜ@àÕÚÈáâá¿ÛÎãÛãÒ«Ý|ÛãËäËÚÔ¿ÈÌ,ÑåÑ¿ÈÒFÒ È|Ô¿ÈÎãæåÛÞÑ
ç 
Ñ ÛÒÚÍTæ¿ÈÖaâqÛÞÑËè;é9Ô¿ÍdêÈÙÑÒÚÍ4ÕÚÍ1ÉâºÖaà¿ÎãÍ)âqÎÞËÚÈäËÚÙßºßºÍ!Ë Ò©Ë,Ò©ÔâqÒëÇ#ÈÉÊ Ë]âºË©ËÚÙÖaà¿ÒÚÛÈÑËPâÕ ÍdÛãÑËÚÙìJêÛÍ!ÑÒ
ÒÚÈaàÕ ÈíÍ]Ò©Ô¿Í@Õ Í!ËÚÙ¿ÎãÒuÍíÍ4ÑîÛãÑîÛãÑ ç Ñ¿ÛãÒ Íëæ¿ÈÖTâºÛãÑËèmé9Ô¿Í@Ë©âºÖTÍ@ê1ÈÙÑÒÚÍ4ÕÚÍ1ÉâºÖaà¿ÎãÍ;ÛãË9ÙËÚÍ4æîÒ ÈFæ¿ÛÞË©àÕ ÈíÍ
âaÕÚÍ4Ë©Ù¿ÎÒ9ÈºÜ~ï°ÛÞÑ¿Í@ÈÑðê1ÈÖTàâºÕ©âqÒ ÛãíºÍMê1ÈÑæ¿ÛãÒ ÛãÈÑâºÎ$àÕÚÈáâá¿ÛÎãÛãÒ«Ýºè
ñNòjóô Ã¿Äõ9ö]÷PÆÃøõ ô
ùFúû]ü¿ýþÿû°û
 þ ú$ü	d
 ú¿
 ú1 ûû	  úH
 ü þ ü° û  ú!1þ"#$	
 þ" üú9 ü¿ýþÿû%1û]ü¿ý1& ü'
(Þ þ
)*ûqú+,+-Mü	.0/132(45,6"7%8°ü1û9MûFÿ
*û:
ðý;$úþ"üú+<;ûþÿ
þ=
("1ü>?
þ1û=
&1û	
(mú,$°û&@=Þþÿ
û	
(4
 ÿA$
(&B/DCFEHGI6 ü¿ýJKûþ", ü¿ýL
M$ üN
(  úAOPH4ÿRþÿ$
 þ9CRSU
Q T 7V û==&"Þ þ1ûW]< û/GAXYC6Z&K
 þÿûP& þÿ¿
 ú
< û[/DCFEHG6"\]K  ú û; ûRþÿ  ú|
;
 ü¿ý;< û[/G^XYC_6B
(a
 þÿ$ûI1& ûÞ þ`å
 ü&M¿ û  ÿüü> ü¿ý%Ga* ûqúbC7 ( M
- ü.

 ý;$ú þ" üúHü¿ýc;
< û[/G+XYC6/;d
 ÿû& û Gd$ ûqúüþ1û] þÿûB ü û	 ûqúþ
ý;&þÿû&@
(KKHûP
 þÿ
 þ;< û[/ G+XYC6%J
ü¿ýGe  úfOg6"o
\ þÿ
 þ9$\ þÿû& û:=j

 ý;$ú þ" üúihjK4ÿ þÿ
 þ

Q T\
kflox <;û[/ G^XYC_6 S h%/[;< û/G^XYC_6!6F ýFCRSU

 ú þÿ
 þ;< û[/GdmnG:opXYC6q
|ý;$úþ"üúiü¿ý9<;û[/G_opXrGdmsC6q
¿úb<]û/G^XYC6"\9þÿ
þ	\
¿
ý;$ú
 þ" üúuteH4ÿ|þÿ
 þ

& NI


þÿ$û 1û

Q T7
kuv°x <;û[/GwmuG o XYC6 S t/[<;û[/G o XrGwmfC_6"EK<;û[/G+XYC_6!6ýxGymfCzS{
| üþ" û)þÿ$
 þ@ ýL]< û$F
M&ü$
(Þþjý;$úþ"üúJ\¦þÿûqúMû9	
¿újþK
(¿ûMh%/;}]6 S 1]~N}^
¿útN/;}]E"$6 S
}''7@M
- ü.+N
(¿ û%4ÿIM
 û	
(¿ û&9
("K$ þ" üú	 ÿûW
("K û, þÿ
 þ%t;
 þ`= ûB$û&1ûqúþ"?
(û(\=Þþÿ^

 üúþ"  ú,üB1 û üúf$ û&K*(
 þ"* û(\c¿
 úÓ

 þÿ
 þqhë
 þ`= û û& ûqúþ"?
(û(79a
 ú$ û)
& þÿû1 û
("KN þ" üú\
ÿû4
 ÿü	=î
 þÿ
 þ]< ûF üH
 ü&"o ÿR
 þ1ü0
i1& ü$
(Þ þ`n þ"&"'sþ" üún  ú þÿûN1 ûqú1 ûjþÿ
 þîþÿû1& ûN

 üúþ"  ú,ü üú$û þ1ü üúû@üúþ1üTý;$ú þ" üú:A { H4ÿäþÿ
 þZJ>]< ûx
B1& ü$
(Þ þ`_ þ"&K$sþ" üú

üúiO\$¿

 ú
'/[;< û/G^XYC_6!6Fu'/[;
< û/DC_6!6 S '/[;
< û/GymfC6!6F ýCS{
Q T\
/1(6
dÿû& û:]< û/DC_6F=¿
 úf
(&1û*?
 þ" üú|ýü&=;
< û[/DCXrOg6"7
- ü.JW& ûKÞþFÿ
(W
 þþ"&H
( þ1ûn
N1& û	
 þM$ û	
( ü¿ý  úþ1û1& û þ\L$
(& þ"	?
(&"i  ú³þÿû
| üþMK&"&K"  ú\J@
N
.? ûqúþ"& üu üN$úÞ þu¿
 úL\$H
 ü& ûW& û ûqúþ"\  ú þÿû:B üA$úÞ þ7o üd
& û.
 û
!q c¡;¢£[¤!¥¦)§ ¨©¡[ªK£[«¤¡Z£[«ªH¬:­J¤D®°¯°¦%§r¨±²,ªK¬(³q£ªH´¤¥@¨©ªK¬(³¦µ£[=¶¤F·¡p·¥¸¢£p¢Y¬¥Z¢Y¬_¥;¹)¤®ºªK¬»H¼(ªH»H¤%¡[ªK£[«¤¡
£[«(ªK¬M¤½¤¬£¥D²(¢? ¤²¥;¼¶¥;¤D£¥cH¾ª9»K¢Y½¤¬:¥;¤D£!¿J«¢À¥³	¢Á¤¡p¤¬(Â`¤@¢À¥Z¹%¢Y¬¡¸ÃA£[«¤¡p¤@ªH¡p¤ J¤`®Y®ÄÅ´	¬! c¬:¹9ªH··¢Y¬»¥c¾º¡p¹
·¡pH·¥¸¢£p¢Y¬¥L£[F¤½¤¬£¥D²3ªK¬(³B½¢ÀÂD¤Z½¤¡[¥pª3$Æ$¼(¥;¤Ç¤D½¤¬£¥«¤D¡p¤x¥¸¢Y¬(ÂD¤£[«¤DÈ=ªH¡p¤¹)¡p¤Ç¥¸£ªK¬(³ªH¡[³=¢Y¬=£[«¤·¡p¶ªH¶¢®¢£¸È
®¢£[¤¡[ªK£[¼¡p¤
É

Ê

%Ë

Ì

FÍ

Î

ÅÏ Î

( ---  %% !:	©ë	: M1	 m	!8,	 ¦7!
%&% 

º&1%o% 1 :

Ð

o

- ÿûû1û	N
¿úA/132ÒÒ,6½ÿ
(Ç	
(ûÞþ#þÿûÓ"þ"&1üú¿ûþ
(&"Hûqúþ½ýü&x1ûPü¿ý1þK
¿ú$
(&"^/[<%
û"?
¿ú6
Ñ ë
$&1ü$
(Þþ`ðþÿ$ûü&!>Ô7F8??
(&1ûqúþ"?Hûqúþ"F
(&ûëû.$&1û"1û,IÕ
úûB/132Ö(Ò>\c7>×4>6"Ø> ú$ûûL\
- ü.J=)
@
Ù ÿûü& û	)
 üúûFü¿ý þÿû_ ü& úû&" þ1üú$ûë
 ü¿ýxÕ
 úû'1& û ûqúþBüü0/13225,6"7
 ýü&= ü$
(&" üú ü¿ýZ$1& ü$

ÑÛÚ ü&!*Þ þ"Ü(\ Ú ûK¿ û&KA¿
 úJ\'¿
 úiÝZ¿
 ú üþ"ÜA/132Ò5,6%1ûiÞ þB
(=
I$
(Kë
$Þ þi¿
 ú üþÿûT
& úüú& ü$
( þ":
($1& ü
(4 ÿû)
 þ1üN1& û	
( üú  ú
(°üsþ=$ú û1& þK
(  úþ`7
ÑÛÚ ûK¿ û&HN¿
 úf/132ÒÒ,6xûÞ þF
(F
:$
("P ýü&@$1& ü	*  ú:¿
 úA
. üA
 þ"Ü	
 þ" üú ýü&@°û ûýJJ$
 þ1û(7
Ù)ÿûIA
(  úf üúþ"&"$þ" üú ü¿ýPþÿM$
(° û&Ma
 þ1üu ÿü	a/p,©H
 û	¿
 úF
 ü¿ý¿
 úyû.Þ þ ü$úþ1û& û.
N û6
þÿ

 þBM
- ü	.=1& ûKÞþ)$ üû)
 úüþëÿüu  ú^~# úÞ þ1ûM$ üN
(  ú	\ û* ûqúf$ú$ û&% þ"1& üú
(KK$ þ" üúM
 üúÞhj¿
 ú
t/p1 þ"1& üú¿ û,& þÿ$¿
 újþÿü1 ûBN
($ û),NM
- ü.A¿
 úH
 þÿü1 û=A
($ û)  úN
('$
(° û&"x1& ü3*>  ú_*(
(&K?¿
 úþ"] ü¿ýL@
- ü.J
& ûKÞþ"6"7^8  ú û# úÞ þ1û$ üA
(  ú:
(1& ûN
(&"$
(³
1
 þÿ$ü1 ûHü¿ý)H
 ü þ:  úþ1û1& û þ  únBq
($	
 þ" üú\ þÿ
K¿ û1 þ"½ þÿ
 þx
(&" ûqúþ"# ýü&"  ú=1& ü$
(Þ þ`:$
(1 ûð
 üúM
- ü	.Ç1& ûHÞþDßw¿
 úî
 üþÿû&"þ"#$	
 þ" üú
"?N?
(&:  ún"$&"Þ þDßwþM°ûRþK
(¿ ûqúnBÞ þÿµ
u&K
(  ú ü¿ý%K
(Þ þ\¿
 ú þÿû&1& üü¿ý°:	
(& ûý¸©1& û* ûM
 ûL7
- ü.J
("H þ" üú@
(1& û9  úHáN ûqúþPþ1ü_$1& ü	* ûdþÿû
à ü1& ûü	* û&\ þÿ$û9 ü$úþ1û1& û.
N û=H¿ û þ"] þÿ
 þ)@
& ûKÞþëû* ûqúÞ  úu  ú# úÞ þ1ûM$ üN
(  ú7
1
© þ
 ú$ü	d
 ú þÿ
 þ1 üH
 ûN
(KK$ þ" üú:1& û
(&"$  úftâ¿
 úÛhãþû^N
($ ûHþ1üi1& ü3* û+@
- ü.J
& ûKÞþ7äqüA¿
 úå@&H
($ û©/1322æ,6* û0¿
 úwû.
N û ü¿ýMy
1

 ý¸oú þ" üú;
< ûp\%$ û~# úûw
 üú
©~# úÞ þ1û
 üA
(  úJs\ þÿ
 þ9)
$
 úüþ)1 ü ü&"o ÿT
 þ1ü
1& ü'
(Þ þ+ þ"&"'sþ" üúJ7$ ü@
& þÿ94 ÿü ûäü¿ý;
< ûp\M
 ûM	¿
 ú
þK
(¿
 ûut/;}ZE"6 S   úJ/;}]E"$6_¿
 újh%/;}c6 S 1_~j}Z7©8  ú û^N  úµj
 úüþðþ= ûu$ û1& ûqúþ"?
(û(\@
- ü.J

("K$ þ" üú)$ü,H þÿ$ûMäqü!å@&K
($ ûFû.
$ û(7
ùTþÿ$û&:
sþÿü&"ä
 ÿ$
* ûNA
($ û$ û1& ûqúþ_
("K$ þ" üú	7WÜ$ûç B/13255>\@s8 û þ" üúµÖ0/p)
Ù ÿûü& û	è1(6!6
 üûä
$
 úüþ_A
(¿ û¿
 ún
("KN þ" üúM
(°üsþMtI\Z'sþJÿûI$ üû:N
(¿ ûRþM
 ü|üþÿû&
("KN þ" üúN\ û	
(! ÿ
ü¿ýd
 ÿ! ÿ©ü>Kå
 þÿûäM°üåF&K
($ ûHû.
 û(7A)
Ù ÿû#$&"1 þ:J
 þÿ
 þJþÿ$ûN;
< û[/GAXYC)
6 þK
(¿ ûR
 üú û* û&!
*
(?ûM  ú+1 üH
 ûq&K¿
 ú¿ ûNérê(E"ë:ìp\'=Þ þÿÞê_íë7x ú þÿûMäM°üå@&H
($ ûaû.
N û(\ þÿûM$ üA
(  úA9~# úÞ þ1û(\
 ü þÿq û& þK
(  úî	¿
 ú$úüþJÿüc7qd
1
Ù ÿû û üú©T
 þÿ
 þ: ýFGa¿
 ú©G:oZ
(1& ûp ü  úþm\ þÿûqú³þÿû1& û:

 üúþ"  ú,ü)ý;$ú þ" üúiïg  ? è \' þ"&" þ"u  ú1& û	
("  ú  ú û	
(4 ÿ0
(&" ûqúþ\H4ÿ þÿ$
 þ

k+mð x ;< û[/GwñuG_opXYC6 S ï/[]< û/GAXYC6"EK]< û`/G_opXYC6!6"7
VwÞ þÿHþÿû ûB
("K$ þ" üú	¦\ ÿû=* û)
_1& üü¿ýJ!ÿ  ú þÿû=K&"Þ þPü¿ý°þÿ
 þ;ü¿ý]M
- üH
. þ1ü ÿü3 þÿ$
 þ;
< û
; û"1 ûqúþ"?
(A
:& ü$
(Þ þA þ"&"$þ" üúJ7äM°ü%¿
 úNåF&K
($ û9° ü  úþ]üsþ]þÿ
 þ\  újþÿû;
& û.
N û(\
þÿû1
& ûW@
 úüðý¸$ú þ" üú+ïK
 þ" ýÅ  úWòA«/ û* ûqú+ ýLM
 ûq1& ü þÿûB& ûó>& û	H
 ûqúþPþÿ
 þ=ï°û= üúþ"  ú,ü

 úÞ1 þ"&" þ"u  ú1& û	
("  úN  ú û	
(4 ÿ0
(&" ûqúþ6"7 ?
¿
6 û	
(&" û&B$1& ü	* ûi
1& ûKÞþ=K??
(M
& þ1üNWÜ$ûç ;\L$ú$ û&)1 ü ûd
 ÿ
 þ9 þ"& üú¿ û&
ô û4 ÿûqú,$
(4 ÿs/132(42,@

("K$ þ" üú	7 úu$
(1& þ"	?
(&~\ ÿû:
(KKHû+qò>\$=Þ þÿfïg°û  úõ7
ùTþÿ$û&%*(
(&"?¿

 úþ"ë
 ü¿ýÇM
- ü.J)1& ûKÞþëÿ
	* û_
(1 üI°ûûqú^ üú"$ û& ûu  ú þÿûqÞ þ1û&K
 þK&1û(7@o üë
& û.
N û(\

û
K


¿

û
K
&
A



¿
µ
ú

/
3
1

2

Ò
,
Ò
9
6


¿

ú


ü
!
&

*

Þ
"
þ
(
Ü
\

û
K


¿

û
K
&
A



¿
J
ú

\


¿

ú
Þ

Z
Ý


¿

ú





ü
"
þ
^
Ü

/
3
1

2

Ò
,
5
9
6
(


"

K


a
û

þ

ÿ



B
þ
ö
t
= üúþ"  ú>
Ú
Ú
Ú
üW¿

 úi1 þ"&" þ"i  ú1& û	
(K  úA  úÓû	
(4 ÿî
(&" ûqúþW¿
 úîhB üúþ"  ú>üM¿
 úi1 þ"&" þ"i$ û1& û	
(K  ú7
8  ú û9N  ú, úüþ þ"&" þ"I üúþ"  ú,ü  újû	
(4 ÿN
(&"Hûqúþ\Þ þ,ý;
(9 þÿ& û þ"&" þ" üúRþ1üü7÷+B û?$ú$
(
/132ÒÒ,6@* û ûþ%¿
 ú$üþÿû&% ü û þ" üú ü¿ý]
("KN þ" üú@¿
 úA?
(?NP þÿ
 þ]þÿûNKáN ûëþ1ü
(&K¿
 úþ1ûû
þÿ

 þB;< ûcd
 û"1 ûqúþ"?
(i
I1& ü'
(Þ þu þ"&K$sþ" üúJ7
ø	$Æ¸¬_¾ªHÂ`£!²$ùÂDú¤Dû ®Jª"®®À! ]¥£[«¤¡p¤%£[q¶¤9ªM³	¢Á¤¡p¤¬£x¾¼¬(Â`£p¢Y¬NüFýN¾H¡F¤ªÂ[«I¥;¤D£=¨sH¬£[«¤)¡;¢Y»H«	£pÄÅ«ªH¬(³¥¸¢À³¤)H¾L£[«¤
ÂDH¬(³3¢£p¢Y¬ªK®?$þ! J¤D½¤¡²3£[«¤ÇÿÇ¼¶H¢À¥¸Ä '¡[ªH³¤x¤DªK¹)·®Y¤x³¤¥c¬H£]¤½¤D¬q¥pªK£p¢À¥¸¾ÀÈW£[«¢À¥ ¤!ªH´¤D¡ZÂ`¬(³	¢£p¢ÀH¬,
3'ùÂ£[¼(ªK®®È²"£[«¤'¡p¤!¥¸£[¡;¢ÀÂ`£p¢Y¬F£[«ªK
£ N¶¤J¥¸£[¡;¢ÀÂ`£p®Èx¢Y¬(ÂD¡p¤!ªH¥¸¢Y¬»¢Y¬@¤!ªÂ[«%ªK¡p»¼¹)¤D¬	£,¢À¥ªc®¢£p£p®Y¤£[Ç¥¸£[¡pH¬»Æ°¾ +­J¤D®°¯ 	±²
£[«¤D¬9¢£cÂDªH¬W¶¤¥;«! c¬9£[«(ªK
£ ¯ ± ¯ H± ]¾¡cª"®® >²3¥;@£[«(ª"£ Þ¢À¥J¬K£c¥¸£[¡;¢ÀÂ`£p®È9¢À¬ÂD¡p¤!ªH¥¸¢À¬»F¢¾H¬¤ÇK¾>¢£¥
ªH¡p»H¼¹)¤¬£¥'¢À¥ 




o$s$!P"$$#@$~%PF!&


åo$('*)$

Ù ÿ$ûI#$&" þäþ1üÓü1û&"* ûN° üþ1ûqúþ"?
(1& ü$û	M=Þ þÿbM
)
- ü.J&1ûKÞþ_åx
(&"^/1322(4>6"7fWîÿûA$sþ"
Þþ\_ÓH-@ü.J&1üü¿ý=Húüþ\Fû&4ÿ
(\@
(&K¿ü&1ü
(I1ü û^°û$
¿úþ"IÿþI&1ûýû&
¿úÛdÿûqúÛ
¿ú

 þþ1û	$ þWMN
(o ûFþ1ü^#$Z  ú0
( þÿû$ ûþK
(q1 üH

 ûðü¿ýuþÿû
þþ"&K
(þ"*ûqúû"îü¿ý9þÿûðü&" ú
(ÇBü1þ7Ô
åx
(&"_$1& ü	*$ û_
u&K¿ ü1& ü:& ü¦ü¿ý]ü¿ý]þÿ$ûI1& ûKÞþ\Ç
("KN  ú þÿ
 þJþÿûI&K¿
 ú¿ ûHü¿ý;
< û üúþK
(  ú$û
 úé æ>E1ì%¿
 úµ"  úÞ
("KN þ" üúM"?N?
(F
& þ1ü þÿü1 û ü¿ý Ú ü&!*Þ þ"Ü(\ Ú ûK¿ û&HN¿
 úJ\x¿
 únÝ¿
 ú üþ"Ü(7A ú
$
(& þ"	?
(&N\ ÿû
("HHû)
 þÿ
 þWtzW üúþ"  ú>üM¿
 ú0 þ"&" þ"0  ú1& û	
("  úA  ús/[æ>E1ì ? ¿
 ú|
 þÿ
 þ_h
$û1& û	
(K  ú7 Ú ü	M
 û* û&#\ ÿûN
(¿ û:ûîü¿ý,üú$û
($Þ þ" üú
(x
("KN þ" üúÓþÿ
 þ\]
(J
 ÿûRÿ?1 û ýxH
\
)
 úüþ=* û&!Þ
(° û	
(  ú
Q T\
k,+Nx $ü&W
(]æ.-0/@E21ÇE435-{1
¿ú687æ>\$þÿ$û&1û_
(&1û:ûþ"MC (:9 C ?;9 C ÷ 9 C<:K!ÿ þÿ
þMC ÷ S{

 ú|
¿
 û	
(4 ÿ³ü¿ý%X ;< û[/DC < XYC ÷ 6Z=
~ /XÀ\X ;
< û[/DC ÷ XYC ? 6]>
~ 1FXÀ\'
¿úsX <;û[/DC ? XYC ( ]6 ~53xX9û")þÿ
¿ú67
| üþ"ûîþÿ$
þ)þÿW
("KNþ"üú ýü&"û)þÿ$û_&K
¿ú¿ûîü¿ý<;ûNþ1üN°û:oûqú1û_ úbé æ>E1ìp7=Ù)ÿWHû	
¿úëþÿ
þ\
 úu$
(&1þ"	?
(&\$þÿû_$üN
( úÞO üú+dÿ4ÿÞ<;ûcB$û#~úûu	
¿ú$ú$üþ=°ûq#~úÞþ1û(7
)
 þÿq
(KK$ þ" üúÞ1& û	
(³ú$ûû"K
(&!?Ûåx
(&"qK¿ûþ"Tþÿ
þMWÜ$ûç ,úûûW1üHûþÿ úN¿ûÞþ7
/p)
Ù ÿ"KûNK	"1 ûn  úiý;&þÿû&:o ûþK
(F°û ü	_76jd
Ù ÿû ü$úþ1û1& û.
 û ü¿ýMþÿ_$
(° û&* û
ý;&þÿûë
& û*$ ûqú û(7%© þB ÿ$ü	=)
 þÿ
 þqM
- ü	.W1& ûKÞþ)ý¸
(W  úu# úÞ þ1û:$ üA
(  úo\ û* ûqúf ý;
 û
("K ûaþÿ
 þ
þÿûB&K¿

 ú¿ ûëü¿ýc;< û$  úfé æ>E1ìp\$h%/;}]6 S 1~N}©/p1 üäþÿ
 þ\>  úN$
(& þ"	?
(&	\hnP þ`= ûB$ û1& ûqúþ"?
(ûq¿
 ú
 üú$üþ1üú	
(n$ û1& û	
("  ú>6"\FïI/;}]E"$6 S }+õy$\x¿
 úµt   ú~# úÞ þ1û©° û1& ûqúþ"?
($û^¿
 ús þ"&" þ"
H
  ú1
& û	
(K  úR
 üúf/[æ>E1ì ? 7xV ûM	¿
 ú ý;&þÿ$û&
("HHû)þÿ
 þ)td% üAþK
 þ"* û(\t/[æ>E!}c6 S t/;}]EKæ,6 S æ>\

 úå
¿
 þÿ
 þMt/;}ZE1(6 S t/1E!}]6 S }Z7:)
Ù ÿûðû.
N ûîû	No ÿ
("Ü ûT
 þÿû° ü  úþaþÿ
 þaþÿû
(	
($Þ þ
ü¿ý@
- ü.J:1& ûKÞþMJ
 ý;
(J
& ú
(&"& ü	M
 ûa
& þÿ¿
 ú0%
(_1& û* ü"f°û û* ûL7© þq& û	N
(  úM¿
 úyü° ûqúîó>$û þ" üú

(F
 þ1üuT
 ÿûþÿûa
& þÿû1& ûI¿
 ún
(1& ü$&"?
 þ1ûI þ"1& ûqú þÿ$ûqú  ú ü¿ý;þÿû
("K$ þ" üúT
 þÿ
 þ$ ü¦ûM* û^
- ü	.B1& ûKÞþ9  ú+# úÞ þ1û:1 ûþþ"  ú	7@)
M
Ù ÿû1& ûMd
 ý¸&þÿû&)"	"" üú ü¿ý þÿ9"HûM  úfs8 û þ" üú(@,7
 úåý¸
( þ#\ þÿûRû.
N û ÿü	BF

 û* ûqú©H
 ü1& û(7: úåþÿû ü&" ûðü¿ý;ÿM1& üü¿ý`\ZM
- ü.î?
(?a
 þ1üu ÿü3
þÿ

 þ9tgþ%°ûq¿
 ú+
(" ü,?
 þ"* ûîý¸$ú þ" üúJs\ þÿ
 þ9s\ þÿ
 þ9t/;}ZE"t/p$2E A6!6 S t/ptN/;}]E"$6"2E A>6"7o ü@
& þÿû
< û# ü¿ý þÿû ü$úþ1û1& û.
N û(\ þÿû1& û_	¿
 úf°ûäúüN
(K1 ü,?
 þ"* ûRý;$ú þ" üúftK
 þ" ýÅ  ú^q×,7)© þ=d
;
 þÿ
ü1û&"*(

 þ" üúÓþÿ
 þB)
 þÿû_¿ û þ1üA ÿü3=  új
 þÿ
 þdþÿû1& ûd
 úü$1& ü$
(Þ þ`Þ þ"&"$þ" üúÞ1 ü ü&"o ÿ
þ1üN;
< ûp7
V ÿ
 þ]c¿ ü  ú)
D
 üúJÿû& û?^B þK
(\M
- ü	.Z1& üü¿ý"þc ÿ$ü	=m þÿ$
 þ]t/;}]E"tN/p$2E A>6!6 S t/ptN/;}]E"$6"2E A>6
üú_
 ýü& þÿ$ü1 û þ"&" û/;}ZE"$2E A>60K4ÿ_þÿ$
 þH
\ ýü&©1 ü ûs ûþ"ÛC ( \^C ? \+C ÷ \¿
 úRC < \;
 ûbÿ
	* û
} S ;< û[/DC < XYC ÷ mµC ? mµC ( 6"\x S ;< û[/DC ÷ XYC ? mµC ( 6"\@¿
 úB
 A S ]< û/DC ? XYC ( 6"70© ýMþÿ$ûA1 ûþRü¿ý)K!ÿ
þ"&" ûq/;}ZE"$2
E A>6@%$ ûqú1 û=  ú©é æ>E1ì ÷ s\ þÿûqúAM
 ûB üú?$ûB,N üúþ"  ú,Þþ þÿ
 þ)td)
(" ü,?
 þ"* û(7)
Ù ÿû
 üúþ1ûqúþjü¿ý)W4f1& û1 û þÿ
 þîþÿ$ûN1 ûþRü¿ý)K!ÿ þ"&"$ û$ ûqú1 ûA  úyé æ>E1ì?÷å

7 ùaý% ü&"1 û(\x ýBO
B~# úÞ þ1û(\$M
 û_	¿
 úoúüþaÿ$
* û$ ûqú"Þ þ`79Bq+ üoúþ1û1& û.
$ û_ ÿü3=\';
 û$ ü úüþW  úÞ¿ ûqúû&H
( ÿ
	* û

("1 ü>?
 þ"*Þ þi  ú+# úÞ þ1ûM$ üN
(  ú7 à ü& ûü	* û&\ þÿ9?
(H ü¿ý
(" ü,?
 þ"*Þ þi	¿
 úi1& ûKÞþ9  ú þÿûJý;
(?&1û
ü¿ýM
- ü.Jë
 þÿ$ûü1& û	u7
UK??
(&1& üû	1 ûû	] þ1üîû. þ)  úABÜ'ûç ;9& ü¦ü¿ýx/[
()
(1& û	
( ü1û&!* û+,åÇ
(&KW/1322(4>6!6"7
VDÿ ûMBÜ'ûç ;W1& üü¿ý]$ üûë
 úüþ9  ú* ü* û: ÿü3=  úR
 þÿ
 þ9tgB
("1 ü>?
 þ"* û(\'Þ þ9$ üû)  ú* ü* û ÿü3=  ú
þÿ

 þïa
(" ü,?
 þ"* û(7uW
(  úJ\Þ þî
 úüþîÿ$
(&"y
 þ1üi ÿ$ü	 þÿ
 þIï_
(K1 ü,?
 þ"* û ýü&_
(& ü&"?
 þ1û
þ"&" û	\$"þ
(J
 þÿûA	
(1 û ýü&_t7+<%sþÞ þ1 ûû	NF
 þÿ
 þWÜ$ûç )
(1 ü³úûû$¿
 úµ
(KK$ þ" üúåþÿ
 þ

(&K¿
 úþ1ûû# þÿ
 þ½þÿûF
(1& ü&K?
 þ1û1 ûþ#ü¿ýþ"&"$ û]]o ûqú1 û(\¿
 ú:Þ þ] úüþZ û	
(#& þÿ
 þ#ÿ
("KN þ" üú
C

Ð

o

$ü ú ý;
(þ9
(&K
¿úþ1ûûaþÿ7 < W)ÿü	Tú+ ú+8ûþ"üúi×,\þÿûq&1üû	
(ü
(&"1û) ú ô û!ÿûqú,$
(4ÿJ
1& üü¿ý`7
Ù ÿ$ûNü$úþ1û&1û.
û þ1üî-Mü	.ðþÿûü&û	u\=ÞþÿµKÿþHü>#$	
þ"üú\	
¿úb
(1ü0°ûA1û þ1ü
)
ÿü3 þÿ
 þ9¿
 úüþÿû&; ûºs úü3d
 ú+1& ûKÞþ%  ú þÿûWÞ þ1û&K
 þK&1ûq@
 úüþ) ü ûþ1û^ ü&"1& û þ7 ú ÿ%1 û	
 ú
(Ç°ü¦ü³
 üúî1& ü$
($Þ þ0¿
 ú©ó>
(Þ þK
 þ"* ûN1& ü$
(Þ þ`b/132Ö(ò,6"\ÇÇ  úû üú"$ û&K:
 ú$üú>Ú ú,$Hû&"
úüþ" üújü¿ýEDGFHJIKLMKNPORQTSVU4D2FWXYORNPOFWKZ [JI!L\F^]_K%]`ORZaORNPb\>d
 ÿ! ÿ
( ü	=%uþ1ü:H
0ÓCw* ûqú^GU@
 þF û	
( þ

(1& ü$
(û^
(CWo* ûqújGMoÔ\x$ ûqúüþ1ûCIXrd
G caCBo[XrG:o¸7fM
- üú$Þ þ" üúî
 üúecz
(1& ûN* ûqúiþÿ
 þI
(1& û
?
(?H
 ûR
 þ1üFýü&" û;þÿû@û. þ1ûqú û@ü¿ýZ/[
H
 üúa
 üþÿû9& þÿ  ú6]T

 ý¸$ú þ" üúI]< ûH4ÿðþÿ
 þCXrf
G c{C o XrG o
j]< û/DCIXrGI;
6 gd]< û/DCBoXrGMo¸6=¿
 ún¿
 ú©
(" ü,?
 þ"* û ý¸$ú þ" üúîtaK
 þ"1 ý°>  úuq×,7+/p)
Ù ÿMM)
Ù ÿ$ûü1& û	
Ò ü¿ý@
H
- ÿ$
( þ1û&9")  úµ/p  ú$û(\]132Ö(ò,6"76 Ú ü	M
 û* û&°\ þÿû_;
< û$ û~# úûi  úi^ üoúþ1û1& û.
$ ûJþ1ü^@
- ü.J
þÿûü1
& û	 	¿
 úu°û:1û þ1üN* û
I ü$úþ1û1& û.
 ûaþ1üHþÿ=1& ûHÞþ=
(9M
 û;7
 úþ1û& û þ"  úa

\ þÿ+ úüþ þÿû0#$&" þ þ"?H
 ûî
sK??
(& û&"1& ü& ÿ
(+°ûûqú úüþ1ûw  ú þÿ$ûî1û³ü¿ý
ý;$ú
 þ" üú
(N ûó
þ" üú	7%'
(?N
( úûA/132Ò>1(6%* ûq¿
 úüþÿûT
& û.
N ûI/p  úi
N	
(1 û_  ú* ü*  úA
Asþ"Þ þ
 ü>$ û ü¿ýZ! ÿü û:°ûqÿ
	*> ü&6@¿
 úÞ ûqúþ" üúM
H
 þÿ
 þ)ÿûq ú$ü	=1Ó ü¿ýÇ
 þ9 û	
( þ@þM
 ü"?N?
(M
& û.
N û)  ú
þÿû:$!>!
 ÿü ü	
(Þ þ1û&K
 þK&1ûÔ7
Ù ÿ$ûW& û	N
(  ú$ ûM
)
& ü¿ý½þÿ9$
(° û&%@
 ü&"¿
 úÜ û0
(@
 ýü ü3=7@ ú þÿûJúûs. þ91 û þ" üú þÿû& ûM9
IH
 ü1& û
 ûþK
( ûÞ$"	"" üú ü¿ýmþÿ$ûW$1& üû	R  úuM
$
- ü.J)1& üü¿ý7d
Ù ÿûB üoúþ1û1& û.
$ ûdþ1üM
- ü	.M
 þÿ$ûü1& û	z
* ûqú©  ú©s8 û þ" üú©ò>7_d
Ù ÿûîýü ü	B  úu1 û þ" üú© ÿ$ü	=T
 þÿ
 þ:Þ þMM
(1 üÞ
^ ü$úþ1û1& û.
N ûðþ1ü+  ú$û(
þÿûü1
& û	Þ7x8 û þ" üúh@= üú?oûZBÞ þÿ_1 ü û@K	"" üúJ\$
(1& þ"	?
(&"ä
 ü¿ý
("H þ" üúZ$úo û&cd
 ÿ! ÿ
- ü	.)
M
 þÿûü1& û	 N ÿþ)ÿ$üL7
i#òkj,lnmBo

Äõ½Áqp

m!r

s

ø«Ã

lt

õu8vÂ
o

Äõuõ
w

Ù üÛoú$û&"þK
¿úbþÿûî&1ü$û	BÞþÿw-@ü.Ju&1üü¿ý\9^
(þK
(yüú"$û& ô û!ÿûqú'
(4ÿJÞ$&1ü¦ü¿ý`\
dÿ! ÿ0WK??
(&W úfK&"Þþ:-Mü.JM&1üü¿ý)/pÞþMq
(þK$
(åû*ûqúîü1û&aþ1ü+WÜ$ûç ;:&1üü¿ý6"\L$sþW1û
 ü û
($Þ þ" üú
(@
("H þ" üú\Ld
1
 ÿ! ÿnN
(¿ û:Þ þîû	
(" ûJ
& þ1ü û.?
(  ún  úîo ûþK
(;7NBÜ'ûç ;\FM
- ü	.\Ç¿
 ú
ô û! ÿûqú,$
(4 ÿf
(cN
(¿ ûq&"Þ þ"	
(]ûTü¿ý#ý¸oú þ" üú
(m ûó
þ" üú9  ú þÿû&)$1& ü¦ü¿ý`\¿
 ú þÿûuN
(¿ ûTþÿû
K
 ûI/p1 ûû	  úu$ú"þ"~# ûJ6 û	
(f
 þ= ü&"& û"° üú  úI° ü  úþ"9  ú þÿû&9$1& ü¦ü¿ý¸7
 úRþÿû)ú$üþK
 þ" üú ü¿ýþÿF$
(° û&\ ô û! ÿûqú'
(4 ÿ0/132(42>\L7xY5 @`x>5Ö6x
("HHû9/1(#6 þÿ
 þPþÿû=&K¿
 ú¿ û

ü¿ýZ;
< û[M/ y°zX y69
K1ûþMü¿ý)é æ>E1ìp\]/×6F;
< û[/G+XYC_6 S 1M ý|
C { GN\L/[ò,,6 þÿ
 þ9 ýGö¿
 úÞG o 
(1& ûqp ü  úþ\
þÿûqúA]
< û`/GnñGMo[XYC_6 S ;< û[/G+XYC_6õf;< û[/G_o[XYC_6%'/ þÿ,	s\ ÿûB
("K û, þÿ
 þWî
ò ÿü\>=Þ þÿAïã°û  ú
õ6"\Z¿
 ú/p4>ë
6 þÿ
 þ_M× ÿüMBÞ þÿ©
 ý¸oú þ" üúît þÿ
 þ_M$ û1& ûqúþ"?
(û(7i/ Ú û1& û	A
(&">d
 þÿ$
 þJþÿû
& ûKÞþMÿü$] û* ûqú^=Þ þÿ$üsþ
("H þ" üúf/p4>6"\
(Þ þÿüÿ þÿûW1& üü¿ýL)H
1
 ü1& ûB ü	
 þ1ûLØWÜ$ûç L  ú
ý;
(
 þ=$ üû)
 úüþBA
(¿ û:¿
 úi
("K$ þ" üú^¿ ûN/p4>6"76
 ýü ü3= ô û$?
(  ú^G o   úÞM×I,fG ( ñÞG ? \$d
 ÿû& ûG ( ¿
 ú
ô û4 ÿûqú,$
(4 ÿLM1& üü¿ý$1& ü, ûû$B
(T
G ? 
(1& û:; ü  úþ\; ûM¿ ûþdþÿ
 þ
< û[/Gymî/G ( ñÞG ? 6XYC6 S tN/[]< û/G ( ñÞG ? XrGwmfC_6"EK;
;
< û/G^XYC_6!_6 }
/×6
W"  új
 þÿûFý;
( þëþÿ
 þqïgWõ\; û:?AH
 û?
 þ1û^¿ ûþ
< û[/Gwm0/G ( ñiG ? 6XYC6 S ;
;
< û[/GwmuG ( XYC6Jõj;
< û[/GymÞG ? XYC_6
/[ò,6
~$ÆL¥;«¼®À³:¥¸£[¡p¤!¥p¥c£[«(ªK£Z¹FÈBÂDH¼¬£[¤¡p¤DªK¹)·®Y¤x¢º¥c¬K£Çª9ÂDH¼¬£[¤¡p¤DªK¹)·®Y¤Ç£[=ùÂDú¤`û ®  ¥c£[«¤H¡p¤¹q²¥¸¢Y¬(Â`¤F«¤@¤`·3®¢ºÂ¢Y£p®È
ª¥p¥;¼¹)¤!¥J£[«(ª"£Z£[«¤x¡[ªH¬»H¤H¾$­J¤D®,¢º¥L¢Y¬ ¬¢£[¤JþZ! J¤½¤D¡²¢£Ç³3¤!¥c·H¢Y¬£H¼£]·H£[¤¬£p¢ÀªK®·¡p¶3®Y¤¹9¥J L¢Y£[«M«3¢À¥]·¡pH¾¸²
ªH¬³Â`¤¡;£ªK¢Y¬®È¥;«! ]¥£[«ªK£x«3¢º¥xªK¡p»¼¹)¤¬£x³¤¥Ç¬H£@ªK··3®YÈM£[:
 (¬3¢£[¤%³H¹9ªK¢Y¬(¥DùÂ`ú¤Dû ®¢À¥¢À¬:¾ªHÂ`£@ª LªK¡p¤)H¾£[«¤
·¡pH¶®Y¤¹9¥L L¢£[«_«3¢À¥Z·¡pK*¾  ·¡;¢À½HªK£[¤FÂDH¹)¹¼¬3¢ÀÂªK£p¢Y¬²>M _?xþ¤x®ÀªK£[¤¡·¡p"½¤!³q¡p¤!¥;¼3®£¥]¢Y¬_ª=¥¸¢Y¹%¢®ÀªH¡¥;·¢Y¡;¢£Ç L¢£[«
£[«¤@ª"¢º³MK¾Jª)¡p4¤ ¼¢Y¡p¤¹)¤D¬	£]K¾ TG2\¯?ùÂ`ú¤Dû ® µÿxªH¡p	ÂDú`È²4 	²··,% M`±² c«3¢ÀÂ«M¢À¥Z¢Y¬q¾ªHÂ`£ª9¥¸£[¡p¬»¤¡
¡p4¤ ¼¢Y¡p¤¹)¤D¬	££[«(ªH¬Wù ~3²(ªK¬(³=£[«	¼¥LªK®À¥;)¡p4¤ ¼¢Y¡p¤!¥J£[«¤Ç³¹9ª"¢Y¬B£[%¶¤Ç¢Y¬ ¬¢£[¤




o$s$!P"$$#@$~%PF!&


åo$('*)$


¿ú

t/[<;û[/G ( ñÞG ? XrGwmfC6"EK<;û/G^XYC_6!6
S t/[<;û`/G ( XrGymfC_6Lõj<;û[/G ? XrGymfC6"EK<]û`/GAXYC6!6
à ü&1ûü	*û&\J,^M×,\Mû_
(1 ü ÿ
	* û(~\ ýü&: S 1EH×,\

/p4>6

<;û/GymÞG"XYC_6 S t/[<;û/GymÞG!XrGwmfC6"EK<]û`/GAXYC6!6_}
Få þþ" újþ1ü¿ûþÿû&/×6"\Z/[ò,6"\Z/p4>6"\J¿
 ú©/@6"\$Mû:¿ûþëþÿ$
þ

/@6

t/[<;û[/GwmÞG ( XrGym0C_6"EK<;û[/G+XYC_6!6qõjt/[<;û/GymÞG ? XrGymfC6"EK<]û`/G+XYC_6!6
/[5,6
S t/[;< û`/GymuG ( XrGwmiC_6Jõ<]û/GymiG ? XrGwmiC_6"EK<;û/G+XYC6!6_}
ÙÇ
(, ú} S ;< û[/GÛmG ( XrGbm^C_6"\ S <]û/GbmAG ? XrGÛmAC6"\
¿úA S <;û[/G+XYC_6 úi/[5,6"\Mûq¿ûþ
þÿûJý;$úþ"üú$
(m
 ûó>
þ" üú
t/;}]2E A>6cõÛt/p'2E A>6 S tN/;}IõÛ'2E A>_6 }
/Ö6
8° ü1 û)þÿ$
 þ9; û
("K û/[
( ô û4 ÿ$ûqú$
(! ÿi?NÞ þ"u$ üû,6 þÿ
 þëþÿ)
 ý¸$ú þ" üú
(m ûó>$
þ" üú
ÿüP
 ýü&@
(Z/;}]E"'2E A>6  |
;
/
]
}
"
E
'

E
2
A> 
6
sé æ>E1ì ÷ }9õu"

-{
1
¡7)
Ù

ÿ
)
û
&
1

û

1
P
þ
¿
ü

ý

þ
ÿû)1
& üü¿ýú$ü	 ýü ü	B
S 
û	
("7&K
 þ$\ þK
(>  ú} S æ  ún/Ö6"\$Þ þdýü ü3=)
 þÿ$
 þ
t/[æ>2E A>6Lõjt/p$2E A6 S t/p'2E A>6"E
¸& zdÿ!ÿ+Mû:¿ûþëþÿ
þ
ý 1ü

t /[æ>E2A>6 S æ}
N
| û.þ\J#.¢A+
¿úfûþBY£(/;}c6 S t/;}ZE2A>6"7:8 úûtö\J,f
("KNþ"üúJ\$$û&1ûqúþ"?
(û(\Ný¸&1ü /Ö6Mû
ÿ
	*ûJþÿ

þ
 £o /;}c6 S ? /pt/;}õÛ'2E A>6Z~nt/;}Z2E A>\6 §$6 S ? t/p'2E A>\6 §! }
¤¦¥

*

¤¦¥

*

©þ)þÿ>dýüü	Bdþÿ$
þ=£o /;}c6)W
AüúþK
¿úþ\L ú$û°ûqú$ûqúþ)ü¿ýx}Z7W8 úûäþÿû_üúþK
¿úþ:A
Þ$û°ûqú
üúBA9
\ þÿû1& û^ üH
 û ý;$úþ"üú©¨bK!ÿ þÿ$
þ_ £o /;}c6 S ¨c/A>6"7©BK ú|þÿû ý;
(þîþÿ
þt/[æ>E2A>6 S æ>\
û û	H
 ûqúþK
(&!u	
(	?)þ1ûBëþÿ
 þ
Y£/;}]6 S t/;}]E2A6 S ¨c/A>6[}}
W" újþÿû:
(KK$þ"üú þÿ
þ)ýü&=
(ÇCFEHGN\Mûäÿ
	*û<;û[/G^XYC_6 S 1ýCª{ G\;û:¿ûþdþÿ
þ
<]û/G^XYC6 S <;û[/GwmuG+XYC_6 S tN/[]< û`/G+XrG mfC6"EK;
< û/G^XYC_6!6 S t/1EK<;û/G^XYC_6!6_}
Ù)ÿ>\MûJÿ
*ûäþÿ
þ

t/1E2A6 S c¨ /A>6 S

A}

V û_üú?$ûaþÿ
þ=tN/;}]E2A>6 S }«A7
| üþ1û(\Pÿü	Mû*û&\9þÿ
þîþÿüú?"üús$û°ûqúM úb
Þ&K?
()
 üú þÿûA
("Hþ"üú þÿ
þ
þÿû ý¸$ú
 þ" üú
(P ûó
þ" üúy/ÖF
6 ÿ$üä
 ýü&
(B/;}]E"'2E A>.
6 ¬I7 5  ú ý;
( þ\x
(]þÿ
þ;ûA	
¿úsüú?$û
ý¸1
& ü /[5,6FM
 þÿ
 þ)Þ þ)ÿüM
 ýü&9
(x/;}]E"'2E A>6@K!ÿ þÿ
 þMþÿû1& ûFû. þWC\'G\G ( \¿
 úiG ? \BÞ þÿ+G ( ¿
 ú
G ? ; ü  úþ\$H4ÿ þÿ$
 þ9} S ;< û[/GwmÞG ( XrGwmfC_6"\ S ;
< û/GymÞG ? XrG mfC6"\'¿
 ú
 A S ;
< û[/G+XYC_6"7
	'ùÂ£[¼(ªK®®È²¼¥¸¢Y¬»Ç£[«¤cÂ`¬£p¢Y¬3¼3¢£¸È@H
¾ F²¢£¥;¼ ­9Â`¤!¥£[«ªK£$£[«¤J¾º¼¬(Â£p¢ÀH¬(ª"®(4¤ ¼(ª"£p¢Y¬)«K®À³¥¾¡'ªx¥;¤D£'H¾£[¡;¢Y·®Y¤!¥ c«¢ÀÂ[«
¢À¥c³¤¬¥;¤¢Y¯
¬ ®F
T°

Ð

o

Ý ûþ@ÇK
ð
#
 þÿ
 þ@d

 þ"&" û;þÿ
 þK
 þ""o# û9þÿxüú$Þþ"üú²±;³\DGFW´¦NPL\KOµW!S2X_/p" úû)Þþ@þZK
þ"ýÅ
û&þK
( úsüúþ"&K
( úþ"_?N°ü1û©åþÿût 
¿úsï ý¸$úþ"üúØ þÿû ÿû&1ûIîýü& ô û4ÿ$ûqú$
(!ÿJ\uþ1ü
 þ"  ú ÿ þÿ úüþ" üúbý¸1& ü
î"?N?
(&HüúûÞoû#~úûj ú þÿû|ú$û.þNûþ"üúJ76RWIIHûqúþ"üúû
û	
(&" û&\LWÜ$ûç Ç
(
 ü^
("HHû)
 þÿ
 þW;< û[/G+XYC_M
6 þK
(¿ ûa
 üúf
(Z*
(?ûB  úÛérê(E"ë_ìp\Jd
 ÿû1& ûê S ;
< û[/ T XYC6

 úÞë S ;< û[/DCXYC_6"7q/; ú ô û! ÿûqú'
(4 ÿJa
¿
 ýü&K?
 þ" üúJ\ê S æ¿
 úÞë S 176d
Ù ÿû1& û_
(1& ûJþM
 ü)

þ1ü  úþ1û&K1
& ûþMþÿ)
("KN þ" üúJ7x)
Ù ÿûBM
 û	
(N  úþ1û&"1& ûþK
 þ" üúu;
 þÿ
 þ@ýüM
& û	
(4 ÿ+(
} sé æ>E1ìp$\ þÿû1& ûTû. þ
CFEHG H4ÿ þÿ
 þ;< û[/G^XYC_6 S }]7u)
Ù ÿûI þ"& üúi  úþ1û&"1& ûþK
 þ" üúbä
 þÿ
 þîýüä
& û	
(! ÿCa¿
 úµ}]\ þÿû1& û
û.
 þ"WGK!ÿ þÿ
 þB;< û[/G^XYC_6 S }]7© þ9)
 úüþ9 û	
(&Bd
 ÿ! ÿ+  úþ1û&"$1& ûþK
 þ" üúi=  úþ1ûqúo ûÞ+WÜ$ûç ;7
& üú$ûäü,*> üKÞKáN û)
 þ1üN1& ü3* ûJþÿ
 þTû* û&! þ"&" û  úö ô  üú þ"&K
(  úûL\L
(Þ þÿüÿiÞ þ
| ûÞ þÿûd
 üû91 ûû	 ?
"ûaþÿ$
 þ=Þ þB ÿþëýü ü	Ø
$
 ý°1& ü þÿûM1 û üú0
("KN þ" üúJ7
 úu¿
 ú^	
(1 û(~\ úûÞ þÿ$û&)BÜ'ûç # ú$ü& ô û4 ÿûqú,$
(! ÿÞ1 ûû:R


 úûû þ1üI! ÿûK þÿ
 þ:¶Fó>
þ" üúî/Ö]6 ÿ$ü
þÿ1
& üÿüsþ·I7W/ | ü&W$ üûWM
- ü	|
. ýüT
& ÿ=¿
 ú
( ü¿ üaý;$ú þ" üú
(½ ûó>
þ" üúL\ úü&B$ üjþÿû_
þÿü&")
 ü¿ý
 ü& û& û ûqúþ¿
 ú© ü4 ÿû©1& û1 ûqúþK
 þ" üúJ
H
 ü¿ý)M
- ü	.1& ûKÞþ\]H4ÿ©
(_Õ,
 úû/13225,6M¿
 ú©ÙZ&K$
/13252,6"76 Ú ü3; û* û&\'Þ þ;þK&úM
 üsþ;þ1üIûWóÞþ1ûFúû û"K
(&! þ1üI$ üäþÿ7 à ü& ûü	* û&\Þ þ%% û	
(@
& þÿ$
 þ% ý
O ~# úÞ þ1û(\ þÿ$û1& ûW
(& ûTüú~# úÞ þ1ûH
 þK û%  ú"_þÿ
 þ9
(1& û ô  üú þ"&K
(  úûL\$¿
 úAÞ þ)@
 úüþMþÿûW	
(1 û
þÿ

 þ
( ü¿ýw7ÇBM
 ûF ÿ$
(> ûûF  úîþÿûMúûs. þ1 û þ" üúL\ þÿu ü1û&!*
 þ" üújÿ
(1 û&" üÇ üú ûó>ûqú û

()
 ý;
(&=
(=
(½ þÿû1 ûM& ü¦ü¿ý¸=
(1& û: üú û& úûL7
¸uòkj,lnm0t

õ½÷ ô Ã

Ä
m

m u9Å

rº¹

p m

Ãõ

õ!u8vÂ
t

õ½Ä

j,lnm

mr

Ù)ÿûM¿ü
(#ü¿ý½þÿ=1ûþ"üúiëþ1ü&ü	*û
Pðmx;l¾½$¿À

tNpl~p¼
»

´¦KYNPO´µÂbTOµW^È.ÉËÊ

Ñ

ÅJS`Z

*

Æ

ÉÍÌ
Æ

îO

SL4SÁO´hKÃÂ¦ÄW!D`NPOFW5ÅJSZ
*Æ K¯Ç²WORNS"XYFH.KOµW
KWXkÉÃÎ"L4S´ÏIS_DNPORQTSZabk´¦ÄD À
N À KN

/G^XYC_6qbé æ>E1ì«ÂFL:CRS{
Q T

_h Æ t

KWXÃÂ¦ÄW!D`NPOFW´
Æ

Ñ ï/;}]E"$6 S }^õwÕU´F5N À KN=ïÖO´k´¦NPLGOD`NPZab$ORWDLMS2KÑ´OµW^È×ORW0S2KYD
Æ

Æ

KYLÈYÄHkS`WN¯KWX5O´,OµWÇ²WORNS`Zzb

KLPÈÄHkSWN
OµW

KLPÈÄHkSWN*OµW+é æ>E1ì ?
KWXÃ´NPLOµDNPZzbÃORW³
Æ
tO´D2FYHVHhÄNKNPOµQÑS Æ t/;}]EKæ,6 S t/[æ>E!}c6 S

WFWX%S2D`L4S_KÑ´¦ORWÈ.OµWS2KYD À

I/[æ>E1ì ?%Ù8Ú
æ Æ KWXt/;}ZE1(6 S t/1E!}]6 S } Ù
DLMS2KÑ´OµW^ÈÃORWÁS2KYD À

FÜ²SQTSL

À

Æ

Æ

Ñ tØO´8OµWÇ²WORNS`ZzbVXO Ó;SL4SWNPOK%]ZS

Û

+ï

KWX

Æ

Ñ h)/;}c6 S 1B~©}ºU´¦FN À KNÇhÐO´;´NPLOµDNPZzbX%S_DLMS2KÑ´OµW^ÈÒKYWXORW`Ç²WOµNSZab"XO ÓÔSL4SWNPOµK%]`ZS4[
XYO ÓÔS`LMS`WNPOK%]ZSM[

Æ

FL4S_FYQÑSL
Æ

NAJé æ>E1ìJ é æ>E1ì´¦KYNPO´µÂbTOµW^È¢U4Ê¦[

N À SL4SVO´ÃWFFW!S³\NF³MFW!ShFWNFÔÂÄWDNPOµFW

Ù



>°üþÿûû,üúI<;û * \>h\>ïI\
¿úItU
(&1û9
þû	
(þF
(x1þ"&1üú:
(9þÿüû9N
($û úI
(
þÿûJüþÿ$û&9*
(&"?
¿úþ"dü¿ý-Mü.J=&1ûHÞþ\dÿûaþÿ$û_
("KNþ"üú@üú^Þ
(&1ûMMû	
(¿û&ëþÿ$
¿ú þÿü1ûN
($û
 ú þÿ$û*
(&"?¿
 úþ"	7Þ$ üî
& û.
$ û(#\ þÿû& ûð
 ú$üÞ1& ûó1& û	H
 ûqúþJþÿ
 þ_î°û üúþ"  ú>üðü&_ ú&1û	
(K ú
úü&aþÿ

 þqW;< û * :
u& ü$
(Þ þî þ"&K$sþ" üúÛ/[
(Þ þÿüÿnåÇ
(&K_¿
 ú©WÜ$ûç °üþÿî1& ü3* ûRþÿ
 þ\
$úo
 û)
& þÿû&M
("H þ" üú\$i	¿
 úî°ûîþK
(¿ ûqúåþ1ü+K
 þ"1 ý°0
( þÿû1 û1& ûó1& û	 ûqúþ"6"7:d
Ù ÿB û&!* ûa
 þ1ü
N
(¿ ûaþÿ$û: ü$úþ1û1& û.
N û:óÞþ1û: þ"& üú7
|

üþ1û@þÿ þ9þÿû@ÿ

`Ý



(
Þ

o$s$!P"$$#@$~%PF!&


åo$('*)$

Ù ÿ$ûµ&1üü¿ýjü¿ýÙ)ÿ$ûü&1û	 ò>71jîüúþ"&Hþ"*û(7 M
)
- üú"$û&0
oüN
( ú O =Þþÿ1×°ü úþ"
E}}}E Þ (Ú? 7V û
("1ü>?
þ1û:=ÞþÿÓû	
(4ÿÞ°ü úþ Þ 0O 
I;
 ûÿþJßÇ/ Þ 6"\J
(ëýüü	=7
Ç/ Þ
ßÇ/ Þ
ßÇ/ Þ

<
6 S ò
ßÇ/ Þ < 6
S @©13æ <
ßÇ/ Þ
? 6 S ×
5 6 S 5I©13æ
<
ßÇ/ Þ
/ 6 S ÒI©13æ
÷6 S 5
3
( 3
ßÇ/ Þ
ßÇ/ Þ
0 6 S ò©13æ
( * 6 S ò©13æ
3
( 3
ßÇ/ Þ
ßÇ/ Þ
3 6 S Ò©13æ
(( 6 S ×©13æ
ßÇ/ Þ
6- S Ò©13æ 3 ßÇ/ Þ (Ú? 6 S 1	4©13æ ( 3
$ü&
0K$1ûþNC ü¿ýqO\x;û+$û#~ú$û"ßÇ/DC_6 Sáà×âãYä ßÇ/ Þ 6"7µÙ)ÿ>\Ç;û+	
¿úÛ$û#úû^
f&1ü'
(Þþ
þ"&K$sþ"üúuåF&@üúfO  þK
(> úå@&3/DC_6 S ßÇ/DC\6 §TßÇ/Og6"7
Ý#ûþßo=°ûf$ûqúþ"	
(Tþ1üåßë
\ û. û þ þÿ$
 þÒßo¸/ Þ ( * 6 S /[ò^~Õæ6: 13æ ( 3 
¿úçßo°/ Þ (( 6 S /×õ
æ6_
13æ ( 3 \=dÿû&1û(æ©+$ û~# úû û ü3:7W
(  úJ\B;
 ûåû. þ1ûqúç
 ß o þ1übK$1ûþ" ü¿ýO o û~# ú  ú
ßo;/DC_6
Q T \$o û~# úû
S à×âãYä ßo°/ Þ 6"7½Ý ûþWOão |
S  Þ ( * E Þ (( E Þ (Ú? ¡7 ý@CRS{
ßo°/GwmfC\
6 §TßÇ/DC_6 ýxOUéo {wC
<;û * /GAXYC6 Ø
S è ßÇ/GymiC_\6 §TßÇ/DC_6 üþÿû&!B1 û(7
ß

(

<;û * û	
(&"*û&!ü1û@þ1üMåF&7ýLCSw
Q T \þÿ$ûqúÞþ,û	
(!ðþ1ü:1ûûMþÿ
þBX <;û * /G^XYC_6~Iå@&3/GAXYC6X S
X ß o /GymiC6Z~>ßÇ/GymfC_6Xê§TßÇ/DC6q-0æ7@V û:!ÿüü1ûÃæh7æ1üHþÿ
þ
ýÇåF&/G^XYC6q7jå@&3/G:o[XYCBo°6"\$þÿûqúi<]û * /GAXYC6q7<;û * /G:o[XYCWoÅ6"7

/[Ò,6

8 úûaþÿ$û:&K
¿ú¿ûJü¿ýå@&=)#~úÞþ1û(\'
(]KáNûqúþ"uKN
(
æK
þ"1ý°©/[Ò,6"7
Ù ÿ$ûÓû.
( þ+! ÿü ûyü¿ýq; û ÿþ"Þ
(°ü	* û0 úüþA$
(1& þ"	?
(&"?N ü&1þK
¿úþ7_ùJúû|þÿ ú þÿ
þ+
)
?° ü& þK¿
 úþ@þÿüÿÞ@
 þÿûJýü ü	=  ú ü û þ" üúåü¿ý ûó
(Þ þ" û
åF&	/ Þ ( X  Þ ( E Þ ? ¡(6 S åF&/ Þ ( * X  Þ ( * E Þ (( ¡(6 S Yò §@
åF&	/  Þ ( E Þ ? ¡,X  Þ ( E Þ ? E Þ ÷ ¡(6 S åF&	/ Þ <,X  Þ <E Þ 5 ¡(6 S @§,11
åF&	/  Þ < E Þ 5 ¡,X  Þ < E Þ 5 E Þ / ¡(6 S åF&	/  Þ 0 E Þ 3 ¡,X  Þ 0 E Þ 3 E Þ - ¡(6 S 11 §,132
/[2,6
åF&	/ Þ <X  Þ <E Þ 5 E Þ / ¡(6 S åF&/  Þ ( * E Þ (( ¡,X  Þ ( * E Þ (( E Þ (Ú? ¡(6 S @§,132
åF&	/ Þ ( X  Þ ( E Þ ? E Þ ÷ ¡(6 S åF&/ Þ 0 X  Þ 0 E Þ 3 ¡(6 S Yò §,11 }
©þ9)
 û	
(! þ1ü! ÿûK þÿ
 þdû.
( þ" þÿû_K
H
 ûaûó
(Þ þ" ûT
 ÿ$üÞ ý;
 û:& û?
( û:å@&=u;
< û * 7
V û ÿü	 þÿ
 þB;< û * H
 þ"!o# ûë
 þÿ$û:1& ûó1& û	H
 ûqúþ"ë
 ü¿ýÇ)
Ù ÿûü& û	 ò>71,Þ
I1 ûóûqú ûJü¿ýÇû	AN
(7
Ù ÿû9#$&" þ û	AN
q, þÿ$û9¿ ûj
)
 þ1ü_ ÿ$ü	=  úä
 þÿ
 þF;
< û * 	¿
 úoúüþF°û)1 ü ü&"o ÿM
 þ1ü
:1& ü'
(Þ þH
 ý;$ú
þ" üúJ7BÚ þM1û)
 þÿûîý;
( þ/p1& ü	* ûî  úf½Ý û	AN
ò>7Yò,@
6 þÿ
 þW ý@;
< û * M
 û1& û üH
 ü&"o ÿJ
 þ1ü+
1& ü'
(Þ þ
ý;$ú
 þ" üúJ#\ þÿûqúyþÿû1& ûM
 ü ÿ$
* ûHþ1üiû|

 ý¸$ú þ" üú©taK
 þ"1 ý°  úÞM× þÿ
 þ_
("1 ü>?
 þ"* û(7^Wº
þÿüÿL\
(x
 ÿü3d
 ú  ú½Ý û	AN
=ò>7ÀÖ,¦\ þÿû@ý;$ú þ" üút{K
 þ"1 ý°  úMq×W	¿
 ú°û;þK
(¿ ûqúRþ1üM°û%  ú~# úÞ þ1û
° û1& ûqúþ"?
(û=¿
 ú  ú1& û	
("  úM  újû	
(! ÿN
(&"$Hûqúþ\ þÿû@ûó
(Þ þ" ûF  ú+/[2,6KáN ûMþ1ü:$
(&K¿
 úþ1ûûëþÿ
 þ
Þ þ=	¿

 ú$ú$üþ=°ûaþK
(¿ ûqú þ1ü°û:
("1 ü>?
 þ"* û(\ þÿ
 þ=\M
 û:$ üHú$üþ=  úu¿ ûqúû&K
(# ÿ
* û
t/;}ZE"t/p'E2A>6!6 S t/pt/;}]E"$6"E2A>6_}
ú$ûûL\þÿû&1ûJúü+
("1ü>?
þ"*ûjý¸$ú þ" üúftzK
 þ"ýÅ ú+q×,\Nû*ûqúîý;û&1üåþÿû&1ûó&1û	Hûqúþ"
þÿ
þ=tûM$û&1ûqúþ"?
(ûîü&9 ú1
& û	
("  ú7
ë

Ð

ì]p¼=¼

µðNx?vé½Ôí
{

ïJlmlð2½


¿ú þÿ$
þ

FL¯ÅJSZ

KÑ´ËX%SPÇ²W!S2XÒK%]_FQTS
Æ

^tî´¦KYNPO´µÂbTOµW^ÈkÉ¯Ì

N À SL4SVO´ÃWFKÑ´G´¦F`DOµKYNPORQTSÂÄWDNPOµFYW

Ù

8°ü1ûTþÿû&1ûqMû&1û:H4ÿÞ
Hý¸$úþ"üúutI7@&ü [/ 2,6"\$Mû:þ)ÿ
	*ûFþÿ
þ
t/ @§,11E11 §,132,6
< û * /  Þ < E Þ 5 ¡,X  Þ < E Þ 5 E Þ / ¡(6!6
S t/[;< û * / Þ < X  Þ < E Þ 5 ¡(6"EK;
<
;

û

/
X
E
E
(
¡
6
<
<
Þ 5 Þ /
S
 Þ
S @§,132
* Þ
S

©þëýüü3=)þÿ$
þ

¿ú þÿ$
þ

*

o

S

t/[òY§@,EG@§,11(6
t/[;< û * / Þ ( X  Þ ( E Þ ? ¡(6"EK<;û * /  Þ ( E Þ ? ,¡ X 
< û * / Þ ( X  Þ ( E Þ ? E Þ ÷ ¡(6 S òY§,11}
;
Þ

(

E Þ ? E Þ ÷ (¡ 6!6

t/[òY§@,E"t/@§,11E11§>132,6K6 S t/[òY§@,EG@§,132,6

t /ptN/[òY§@,EG@§,11(6"E11§>132>6 S tN/[òY§,11E11§,132,6_}

Ù)ÿ>\ýtgMû&1û_
("1ü>?
þ"*û(\;ûMMüÓÿ$
*û
ùFú

t/[òY§@,EG@§,132,6 S t/[òY§,11E11§,132,6_}
þÿ$ûFüþÿû&dÿ
¿úL\ý°&1ü
/[2,6%
(
(  úJ\M
 û:1 ûûJþÿ
þ
t/[òY§@,EG@§,132,6
< û * /  Þ ( * E Þ (( ¡,X  Þ
S t/[<;û * / Þ ( * X  Þ ( * E Þ (( ¡(6"EK;
<
;

û

/
X
E
E
(
¡
~ æ\6 §,132>E
S
* Þ ( *  Þ ( * Þ (( Þ (Ú? 6 S /[ò:×

dÿû

( *

EÞ

((

EÞ

(Ú?

(6!6
¡

t/[òY§,11E11§,132,6
S t/[;< û * / Þ 0 X  Þ 0 E Þ 3 ¡(6"EK<;û * /  Þ 0 E Þ 3 ¡,X  Þ 0 E Þ 3 E Þ - ¡(6!6
S ;< û * / Þ 0 X  Þ 0 E Þ 3 E Þ - ¡(6 S òY§,132}
©þëýüü3=)þÿ$
þ=te	
¿ú$úüþBû:
(K1 ü,?
 þ"* û(7Jòñ
Ù üf$ú$û&"þK
¿ú ÿ$ü	z½Ý û	NA
+ò>7À×u1& û?
 þ1ûðþ1üÓü&_"	""üú© úb8sûþ"üúb×|ü¿ý;þÿûN&üû	
=Þþÿ ô û!ÿûqú'
(4ÿJx& ü¦ü¿ý`\M
 ûK
N/;}ZE"$2E A6LÇV

 D2FW´¦NPL\KYORW!S2XVNPLGOóI!ZS0 ýþÿû1& û]û. þÇ1 ûþ"FC ( 9 C ? 9
C ÷ 9 C < =ÞþÿbC ÷ S
Q T H4ÿyþÿ$
 þM} S ;
< û * /DC < XYC ÷ 6"\] S ;
< û * /DC ÷ XYC ? 6"\¿
 ú×
 A S ;
< û * /DC ? XYC ( 6"7
©þHû	
(! þ1ü©1 ûû þÿ
 þMy
× ýü&" ût þ1üµûu
(" ü,?
 þ"* ûåüúÛ üú þ"&K
(  ú$ûb
 þ"&" û	\F"  ú ûi ý Þ S
<;û * /DC ÷ XYC ( 6%¿
 ú Þ o S ;< û * /DC <,XYC ? 6"\,uq×,\M
 ûðÿ
	* ûtN/;}]E"t/p'2E A>6!6 S t/;}]E Þ 6 S ;
< û * /DôC <,XYC ( 6

 ú0t/pt/;}ZE"6"2E A>6 S t/ Þ o 2E A>6 S ;< û * /DC < EC ( 6"7BW4+K
T
¿
 þÿ
 þdþÿ$û1 ûþaü¿ýx üú þ"&H
(  úûå
 þ"&" ûq
 ûqú ûM  úµé æ>E1ì?÷7
$
V ûÞK??
(&"Û$ û~# úûî/;}ZE"ä
6 þ1üµûuå

 DGFW´NPLMKOµW!S_X$IKOµL0 ýdþÿû1& û û. þN ûþ"+C ( 9 C ? 9 C ÷
=Þ þÿC ? S Q T K4ÿiþÿ
 þ} S ;< û * /DC ÷ XYC ? 6:¿
 ús S ;
< û * /DC ? XYC ( 6"7©V û+K
i
 þÿ
 þu/DC ( EC ? EC ÷ 6
D2FYLGL4S´ÏIFWXÑ´ þ1ü þÿû
 üú þ"&H
(  úûn$
(&I/;}ZE"6"7+/ | üþ1ûHþÿ
 þFþÿû1& ûA
f°ûH
 ü1& ûðþÿ¿
 úyüú$ûRþ"&" û
ü¿ýÇ1
 ûþ"= ü&K1& û"° üú  úR
 þ1üA
I üú þ"&K
(  ú$ûi$
(&76© ý/DC ( EC ? EC ÷ 6F ü&K1& û"° üúM
 þ1ü þÿû: üú þ"&H
(  úû
$
(&I/;}ZE"6B¿
 ú©t K
 þ"!o# û:M×,N\ þÿûqú0M
 ûþFÿ
* ûNt/;}]E"$6 S ;
< û * /DC ÷ XYC ( 6"7 | üþ1ûjþÿ
 þ:°üþÿ
/[Yò §@,GE @§,11(6¿
 ú / @§,11E11 §,132,6
(1& û üú1 þ"&K
(  úûb$
(&"\Ç
(Þ þÿüÿ þÿ$ûHþ"&" ûi/[Yò §@,GE @§,11E11 §,132>6
)
 úüþB üú þ"&K
(  úûc7Ú þ9)
 þÿë
 ý;
( þëþÿ
 þ9M
 û_ûM  úu½Ý û	AN
ò>7À×,7
Ù ÿ$ûJúû. þB û	NN
 ÿü3=ë
)
 þÿ$
 þB;< û * 	¿
 ú$úüþ=°ûM1 ü ü&"o ÿT
 þ1üA
$1& ü$
(Þ þ` ý;$ú þ" üúL7
¦õ



o$s$!P"$$#@$~%PF!&


åo$('*)$

{µN
ð xôð ½.í FLVÅJS`Z * KT´.X%SPÇ²W!S2X¢K%]2FQÑS Æ N À SL4S"O´.WF(FW!S`³ÏNF³MFW!S"FWNFÃÂ¦ÄW!D`NPOFWuîÇé æ>E1ì
é æ>E1ì´¦KNPO´RÂ¦bTORWÈ¢U4Ê[ Ù
 ü1 ûMþÿû&1û=;û&ûBK4ÿ^
Jý;$úþ"üú$7@Ç&"þMúüþ1û)þÿ$
þ@'/[<;û * /DC6!6BS Q æýCRS{
Q T 7oü&
ïJlmlð2½ 8°
ý]'/[;< û * /DC_6!6 S æ>$\ þÿûqúuÞ þdýü ü3=d
 ý¸1& üâ/1(;
6 þÿ
 þ)ýü&=
(Zö
G {wC\M
 ûäÿ
	*û
'/[;< û * /G6!6 S '/[;< û * /G+XYC_6!6F+/[]< û * /DC_6!6 S '/[;
< û * /G+XYC_6!6Fiæ S æ }
ì]p¼=¼

Ù)ÿ>\3'/[<;û * /G6!6 S '/[<;û * /DC6!6ýü&Z
(K1ûþ"G ü¿ý'C7x8 úû9þÿ$û$û#~úÞþ"üúJü¿ý<;û * 
(&K
¿úþ1ûû
þÿ

 þB;< û * /G6=S Q <;û * /DC6FýÇGB
1þ"&"þ=K$1ûþëü¿ýC\$þÿ9üúþ"&K
(þ")þÿû_
("Hþ"üú þÿ$
þ%
ë
 üúû þ1ü üú$û(7)
Ù ÿ>\/[<]û * /DC_6!6WS Q æý@CzS{
Q T 7©þ)úü	_ýüü3=)ý¸&1ü /1(6;þÿ
þ=ý@CRS{
Q T \oþÿûqú
'/[<;û * /G^XYC_6!6 S '/[<;û * /GwmfC_6!6\§3'/[<;û * /DC_6!6_}
/13æ,6
| ü	{$û#~ú$û=t/;}ZE"6 S  ÷ ( /¸'/;}c6c'/p$6!6"7V ûBÿ$ü	 þÿ
þFt $û#úûN ú þÿF%
	AK
þ"!#~ûFM×

¿úÞB
("1ü>?
þ"*û(7%Ùdÿ%=c* û9
I üúþ"&K
(þ"üúÓþ1üNÝ½û	AN
ò>7À×,7
Ù ü1ûûTþÿ
þ)tgK
þ"!o# û)M×,o\ úüþ" ûaþÿ
 þ\,^
(  úî
 þÿûaü1û&!*
 þ"üúu
(°ü	*ûM&1û°û	
þ1û\ý
GymfCRS{
Q T \$;û:¿ ûþ
S

t/[<;û * /G o XrGymiC6"EK<;û * /G^XYC_6!6
÷ ( /!/¸'/[<;û * /G:o[XrGwmfC_6!6^'/[<;û * /G+XYC_6!6
 ÷ ( /!/¸'/[;< û * /G o mÞGwmiC_6!6\§3/[<]û * /GwmfC_6!6!6n/¸'/[<;û * /GymfC_6!6\§3/[<]û * /DC_6!6!6!6
÷ ( /¸'/[;< û * /G:omÞGymfC_6!\6 §3/[]< û * /DC_6!6!6
÷ ( /¸'/[;< û * /G:omÞG^XYC_6!6!6
< û * /G o miGAXYC_6 }
;

S
S
S

S
Ù)ÿ>\teH
þ"!#oû=M×,7
Ù ü1 ûûFþÿ$
 þ=teB
(K1ü,?
þ"*û(\múüþ1ûFþÿ$
þ

t/pt/;}ZE"6"E2A6 S  ÷ ( /¸'/¸ ÷ ( /¸'/;}c6%+'/p$6!6!6+'/A6!6
S ÷ ( /¸'/;}]6+'/p$6F+/A>6!6
S  ÷ ( /¸'/;}]6+'/¸÷ ( /¸'/p$6+'/A6!6!6!6
S t/;}]E"tN/p$E2A>6!6_}
Ù)ÿ:*ûIFþÿûo û"1& ûµ üúþ"&K
( þ" üúiþ1üf½Ý û	NA
+ò>7À×,7^©þäýüü	=îþÿ
þ<;û * 	
¿ú$úüþ°û
1ü ü&"oÿTþ1üN
I$&1ü$
(Þ þ` ý;$ú þ" üúL8
7 ñò
äaû"Þþ1û]þÿû,ý;
( þ þÿ
 þ;< û * u úüþ]1 ü ü&"o ÿ, þ1üB
9$1& ü$
(Þ þ`J
 ý¸$ú þ" üúJ\ ý;$ú þ" üúh\(tI\
¿ú
ïg	
¿úi°û:$û~# úû þÿ$
 þBK
 þ"1 ý°u_1\q×,\J¿
 úÞqò>\'1& ûK û þ"* û\L¿
 úi
(½ þÿûJüþÿû&B1& ûó1& û	H
 ûqúþ"
þK
þ1û©  úf)
Ù ÿûü1& û	âò>717M)
Ù ÿû
(&" ûqúþTýü&:hy¿
 ú©ïa
 û	
(!Ø]
( þÿû;
 ü&"i¿ ü¦ûq  úþ1ü^$1& ü	*  ú
þÿ

 þB¿
 úi
(1& ü&K?
 þ1û:t û. þ"7
µðNx+V½ø¿À S`LMSºS_ù%O´¦Nµ´©KWfORWÇqWORNS`ZzbÕXYO ÓÔS`LMS`WNPOK%]ZS Æ ´NPLOµDNPZzbúX%S2D`L4S_KÑ´¦ORWÈ×Â¦ÄWD`NPOFWh 
é æ>E1ìV´¦ÄD À N À KN¯ÅJS`Z * / G+XYC_6 S h)/\Å·S`Z * /G+XYC_6!6;ÂFLKZµZ ´S`Nµ´^CEHGû{ O ÜEORN À C S Q T Ù
Ü²ShD2KYW(NKTýSMh%/;}]6
ü WVÂ¦K%D`N
S 1=~©} Ù
Æ
Ù ÿF?AH
 û?
 þ1û@ý¸1& üØ
 þÿ$ûëü1û&!*
 þ" üú þÿ
 þ;
< û * / G+XYC_6 S 1Z~+]< û * /G^XYC_u6 ýü&9CFEHf
G {
ïJlmlð2½ )
O 
7 ñò

ì]p¼=¼

é æ>E1ì_

{

`þ

Ð
µðNxÿ½.¿À

ì]p¼=¼
OµWÒS2KYD À

{

KYLÈYÄHkS`WN

o

ïg'é æ>E1ì ?  é æ>E1ì Æ ORW!D`L4S_KÑ´¦ORW^È
´¦ÄD À N À KN*O Â)CFEHGEHG_o¾{
O Æ Gîm_G:o SUT Æ KWXCzS{
Q T Æ N À SW,ÅJSZ * /G©ñ_GMopXYC6 S
Ù
/G o EC6!6 ü WVÂ¦K%D`N Æ Ü²ShD2KYW(NKTýSMïI/;}ZE"6 S }õÛ Ù

S`LMSÍS2ùYO´Nµ´JKWOµWÇ²WOµNSZabÃXO ÓÔS`LMS`WNPOµK^]ZSôÂÄWDNPOµFYW
Æ

ïI/\ÅJS`Z * /G+XYC_6"E¦ÅJSZ *

Ù ÿ99?AHû?
þ1ûFý¸&1ü þÿ$ûM$û#~úÞþ"üú ü¿ýx<;û * 78ñò
)
Ù)ÿ>\>
($þÿ
þ&1û	N
( úxPþ1ü_ÿ$ü	 þÿ$
þF
¿úN
($&1ü&"?
þ1û9t û.1þ"7Ù)ÿû9¿ûIþ1ûA@&ü	*$û
, þÿûyýü ü	=  új û	AN
>\9T
 ÿ4 ÿ û"1ûqúþ"?
({ÿü3= þÿ
þ þÿû&1ûîÞ
s;ûMoû#~úûwt þÿ
þÞ
 ú&1û	
(K  ú7
ïJlmlð2½

Q T KWXIG ? miG ( S{
Q T Æ N À SW
µðNx ¾½Jü ÂMC ? mfC ( S{
U4K¦[BO ÂJÅ·S`Z /G
*
÷ XrG ? mNG ( 6²-çÅJS`Z * /DC ÷ XYC ? mAC ( 6JKYWX.ÅJS`Z * /G ? XrG ( 6²-çÅJS`Z * /DC
G ? XrG ( 6 -çÅJSZ * /DC ÷ miC ? XYC ( 6 Æ
U_]M[=O Â8ÅJSZ /G
*
÷ XrG ? m:G ( 6@íçÅJSZ * /DC ÷ XYC ? mC ( 6 Æ ÅJSZ * /G ? XrG ( 6q-çÅJSZ * /DC ? XYC (
æ Æ KWX"ÅJSZ * /DC ? XYC ( 6²7 æ Æ N À SW¢ÅJSZ * /G ÷ mÞG ? XrG ( 6@íçÅJSZ * /DC ÷ mfC ? XYC
U4D4[=O Â8ÅJSZ /G
*
÷ XrG ? m:G ( ²6 -çÅJSZ * /DC ÷ XYC ? mC ( 6 Æ ÅJSZ * /G ? XrG ( 6FíçÅJSZ * /DC ? XYC (
æ Æ KWX"ÅJSZ * /DC ? XYC ( ²6 7 æ Æ N À SW¢ÅJSZ * /G ÷ mÞG ? XrG ( 6@íçÅJSZ * /DC ÷ mfC ? XYC

ì]p¼=¼

{



?

6Æ
(

6Æ
(

XYC ( 6 Æ
6Æ
6Æ

N À SWÅ·S`Z

*

/G ÷ m

ÅJSZ

*

/DC ÷ YX C ? mC ( 6²7

ÅJSZ

*

/DC ÷ YX C ? mC ( 6²7

Ç&"1 þ³ü1û&"*û þÿ
þ0ý<;û * /G ÷ XrG ? m G ( 6¬- <;û * /DC ÷ XYC ? mwC ( 6+
¿úd<;û * /G ? XrG ( 6å< û * D/ C ? XYC ( 6"\þÿûqú ý°&1üa/[Ò,6"\>ÞþPýüü	BPþÿ
þFå@&	/G ÷ XrG ? mG ( 6q-å@&/DC ÷ XYC ? mC ( 6
¿úåF&/G ? XrG ( 6²;
å@&/DC ? YX C ( 6"7Çý;ûMÿ
*ûMûÞþÿû&ÇåF&/G ÷ XrG ? m9G ( 6@íå@&	/DC ÷ XYC ? mBC ( 6mü&Çå@&/G ? XrG ( 6@íåF&	/DC ? XYC ( 6"\¿þÿûqú
MûRÿ$
* ûjûÞþÿû&MåF&	/G ÷ mfG ? XrG ( 6Wíãå@&/DC ÷ m©C ? XYC ( 6@ü&qåF&	/DC ÷ XYC ? m©C ( 6 S æ ü&MåF&/DC ? XYC ( 6 S æ>7
©þ ýü ü3= þÿ
 þ ûÞ þÿ$û&A<;û * /G ÷ mbG ? XrG ( 6uí <;û * /DC ÷ mjC ? XYC ( 6+/'þÿAûi/[Ò,6
(
( úJ6Rü& þÿ
þ
< û * /G ÷ muG ? XrG ( 6 S ;< û * /DC ÷ miC ? XYC ( 6 S æ>7@ ú ûÞ þÿ$û&=	
(1 û(~\ þÿûMû	NA
ðÿ$ü7
;
Ù ÿ>\MÞ þi& û	N
(  ú þ1ü $ û	
(M=Þ þÿ þÿ$ûn	
(1 û þÿ$
 þiå@&	/G ÷ XrG ? mG ( 6 S å@&/DC ÷ XYC ? m C ( 6^
¿ú
)
å@&/G ? XrG ( 6 S å@&/DC ? XYC ( 6"\@¿
 ú ÿûqú û^å@&/G ÷ mnG ? XrG ( 6 S åF&	/DC ÷ msC ? XYC ( 6"70d
Ù ÿûAo ûþK
(ð
 ü¿ýëþÿ

 ú
("B
(& û: ûýþ)þ1üjþÿû:
(° ûqúº.J 
¿
7 òñ
ïJlmlð2½

ì]p¼=¼

µðNx 
½=¿À
{



¿À S2FLMS`HáÎ Ù ÊUMÜEORN À

0t xé æ>E1ì ? 

SL4S,S2ùYO´Nµ´ÁKÃÂÄWDNPOµFW
L4S´IS_D`N8NFÁÅJSZ

*

é æ>E1ìJ´¦KNPO´RÂ¦bTORW^È(KZµZnN À

S,KÑ´G´ÄHJI!NPOFW´,FMÂ

[ Ù

äaû#~úûI
^$
(&þ"?
(uý;$úþ"üú0t o üúé æ>E1ì ? dÿ$ü1û$üN
( ú
üú"1þ"Fü¿ýF
(xüúþ"&H
( úû
$
(&"	7zoü&f
Û üú þ"&H
(  úûU$
(&\qM
 û©$û#~úûîtMoq ú þÿûnoúó>$ûf)
{&1ûó&1û þ1üK
þ"1ý°yM×,7
É
I!LOFLGO°\Bt:o=N

ú$üþ^°ûuM
 ûBo û~# úûLØqÞ þA+° ü""û|þÿ
þ þÿ$û&1û³û.þ þ"&"û0/DC ( EC ? EC ÷ 6

¿ú{/G ( EHG ? EHG ÷ J
6 þÿ
 þI°üþÿÛ ü&"1& û"° üú þ1üj/;}]E"$6N/p;7 û(7\} S ;
< û * /DC ÷ XYC ? 6 S ;
< û * /G ÷ XrG ? 6
¿ú
 S ;< û * /DC ? XYC ( 6 S ;< û * /G ? XrG ( 6!6@K!ÿ þÿ
 þ=;
< û * /DC ÷ XYC ( 6BS Q ;
< û * /G ÷ XrG ( 6"7x ý½þÿ%M
 û1& ûFþÿ$ûM	
(1 û(\
þÿûqúIt o /;}ZE"6]M
 ü ú$üþû%M
 û$ û# úûL7 Ú ü3;
 û* û&\½Ý û	AN
Wò>7Y5MK
	>P þÿ
 þ,þÿ	¿
 úoúüþPÿ
(° ûqúJ7
 üú i\$¿
 úu þ"&" þ"+  ú1& û	
("  ú
(= üú
à ü1& ûü	* û&\½Ý û	AN
ò>7Y5
("K&û9Mþÿ
 þ9tMoJ)  ú1& û	
("  új

(J
 üúû ü¿ýFÞ þ"
(&"Hûqúþ"Mä
 úüþæ>7I úo ûûL\] ý]þÿû1& ûI_
 þ"&K ûu/DC ( EC ? EC ÷ 6= ü&"1& ûK üú  ú þ1ü
/;}]E"$6FK4ÿ þÿ
 þ  Þ ( * E Þ (( E Þ (Ú? ¡N{w
Q C ( o\ þÿûqú+M
 û_þëÿ
* û_t o /;}]E"$6 S }''7
Ù ÿ$ûu$ üN
(  ú
)
ü¿ýBtMo)I
# úÞ þ1û(7j½Ý ûþ Ao°û þÿûu üAþK
 þ"* ûÞ üK&1û ü¿ý f\F1 üyþÿ$
 þ No
 üú"1 þ"j

 ü¿ý ¿
 úÛ
()'
(&"+/p$E!}]6_K4ÿ þÿ$
 þ+/;}ZE"6_I  ú f>
7 ¶xs. þ1ûqúÛt o þ1ü©
f üAsþK
 þ"* û
ý;$ú
 þ" üú^tMo ~o üú Ao',N$ û~# ú  út:o o;/p'E!}c6 S tMo¸/;}ZE"6 ýF/;}]E"$q6  f7tMo o'%M
 ûo û~# úû+°û	
1û(\

(_	¿
 ú û	
("n°û* û&"o# ûL\ ýq/;}]E"$6q¿
 ú/p'E!}c6q
(1& ûN°üþÿ©  ú f#\ üú$ûHü¿ý} ü&0þ:°û+1\x¿
 ú
ïJlmlð2½









	












 





o$s$!P"$$#@$~%PF!&


åo$('*)$

tMo;/;}]E1(6 S tMop/1E!}c6 S }Z7Û-%û	
(&"ÛtMo oFIüAsþK
þ"*û(7s©þI
(1ü© ú&1û	
(K ú7boü&IK°ü1û
/;}]E"$6"E	/;}$opE",o°6Ô Ao¸\L}B-ã}$o¸\]
¿ú©$-ã,o°7:ý@°üþÿb/;}]E"$6B
¿úÛ/;}$o;E",oÅ6B
(&û ú f\J;û1þaÿ
	*û
t o o /;}]E"$J
6 -Ut o o /;} o E" o 6"\cK úût o M ú&1û	
(K ú78?N?
(&"\Lý@°üþÿb/p$E!}]69
¿úb/p o E!} o 6=
(&1û ú f\
Mû_þ)ÿ
	* û_tMo op/;}]E"$6 S tMo¸/p'E!}c 
6 -tMop/p,o°E!}'o¸6 S tMo op/;}$o¸E",o°6"7Ç  ú
(\ ý%/;}ZE"6)
¿ún/p,o¸E!}'oÅ6)
(&1û
  ú f\]
+
 þ"&K
( ÿþ1ýü&!)
(&"n! ÿûKå
 ü	* û&
(x° ü""ûRû û	H
 ûqúþ"M  ú
 ÿü	=a
4
 þÿ$
 þFþÿM	¿
 ú ÿ
(° ûqú
üúi ý,þÿûäþ"&K û/DC ( EC ? EC 69¿
÷ 
 ús/G ( EHG ? EHG ÷ 6% ü&K1& û"° üú  ú þ1üî/;}]E"$69¿
 ús/p,o°E!}'o¸6)
(1& ûK!ÿ
þÿ

 þ  Þ ( * E Þ (( E Þ (Ú? ¡Aî
 ú$üþ
uK$1ûþäü¿ýMûÞ þÿû&IC ( ü&G ( 7A© þäýü ü	=î
 þÿ
 þtMo¸/;}ZE"6 S }'©¿
 ú
t o /p o E!} o 6 S } o  o \1 üA
(
(  úiM
 û_¿ ûþ)þÿ$
 þBt o o =  ú1& û	
("  ú7) "??
(&W
(&" ûqúþ=4 ÿü	=)
 þÿ
 þ=t o o
9 þ"&K þ"Þ  ú1& û	
("  úA
(9 üúN
(d
 üúûJü¿ýÞ þ"B
(&" ûqúþ"=)
 úüþBæ>7
© þ
 þ"&K
( ÿþ1ýü&!%
(&Ki
 þ1üyûs. þ1ûqúbtMo ,o þ1ü0
f üNsþK
 þ"* û(\  ú~# úÞ þ1ûn° û1& ûqúþ"?
(û(\F¿
 úb  ú>
1& û	
("  ú)
 ý;$ú þ" üú:t $ û~# úûä
 üú_
( ü¿ýcé æ>E1ì ? \(d
 ÿ4 ÿM þ"&" þ":  ú& û	
("  úë
 üúN/[æ>E1ì ? \¿
 ú:K
 þ"!~# û
t/;}ZE1(6 S t/1E!}]6 S }µ¿
 ú0tN/;}]EKæ,6 S t/[æ>E!}c6 S æ>7MV ûI1& ü> ûûî
(F
 ýü ü	B7:V û#$&" þaûs. þ1ûqú
?
t o o 1 üTþÿ
 þÞ þ$ û~# ú$ûð
 ýü&
($
(&")/;}ZE" 
6 µé æ>E1ì K!ÿðþÿ
 þx¢
} g_1 üaþÿ
 þÞ þPÿ$
(u þÿû)1& ûó1& û
1& ü° û& þ" û	7 ý}jíd$\cM
 ûRþÿûqúî$ û# úû1 ü þÿ
 þ_t/;}ZE"6 S tN/p$E!}]6"78  ú ûItMo oM üAsþK
 þ"* û(\
þÿA$
 û~# úÞ þ" üú
(& ûûN=Þ þÿtMo o;/;}ZE"ð
6 ýü&I}eí '7y-% û	
(&"jt A üNsþK
 þ"* ûi¿
 ú  ú~# úÞ þ1û
° û1& ûqúþ"?
(û(7WÙ ü^1 ûûðþÿ
 þWtRq  ú1& û	
("  ú\JH° ü1 ûFþÿ
 þW>
} -y} o ¿
 úf
 -{ o 7WÕ,þW
(q  úÓþÿû
	
(1 ûTü¿ýctMo o¸\>Þ þ%%?NH
 û$?
 þ1û@þÿ
 þ%t%  ú1& û	
(K  ú ýL°üþÿN¢
} g¿
 úN}'«o g,$o ü&%°üþÿI}fíN¿
 ú
} o í  od
7 ùaþÿû&!=1 û(\K° ü1 ûq×
} gyu¿
 úi o g } o 7))
Ù ÿûqúÞ;
 ûðÿ
* û
 - $
} -y} o -y o 798  ú û_tR
  ú1
& û	
(K  úd
 üú  /;}ZE"6(
} g! ¡\(; û@ÿ
	* û%t/;}]E"$q6 -t/;}'o;E"q6 -jtN/;}$o;E!}$o¸²6 -t/p,o;E!}$o¸6 S t/;}'o;E"o°6"7
K??
(&x
(&" ûqúþÇ ÿü3=u þÿ
 þxt{Ç þ"&" þ"  ú1& û	
("  úM$ú û"u üúû%Þ þ"@
(&" ûqúþ"Çxæ>7x  ú$
(\
t  û	
(&"+K
 þ"!o# û)M×,\"  ú û/pA üú þ"&Kþ" üúJ6@t o $ üû\¿
 ú+q×_$sþ"% üú1 þ"&K
(  úþ"@
 üú üú þÿû
 üA
(  ú ü¿ýt:o°8
$
7 òñ
Ù ÿ$ûü1& û	aò>7ð
)
1 ú$ü	 ýü ü	=T
 ý¸1& üz½Ý û	AN
(9ò>7Yò>\ò>74\ò>z7 @,\¿
 úiò>7ÀÖ,7










,òkj,lnm0t

õ½÷ ô Ã

Ä
m

m u9Å

rº¹

p m

ÃõJø ô²m v Â

j"l²m

õNÄ

mr

Ç úû úþ1û&1û1þ1ûs úndÿ
þîÿûN	
(,DGFHJIKLMKNPORQTSDGFWXOµNPOFWKZI!LMF%]_K%]`ORZaOµNPb7ÞÙdÿ,	\]&K
þÿû&äþÿ
¿ú

("1 ü>?
 þ"  ú0
u1& û	
(P ú>°û&q=Þ þÿ û	
(4 ÿãÓ" üúÞ þ" üú$
(P üû þ"Ô0G^XYCu\ ÿû$sþ":¿
 ú ü&"$ û&"  ú5
 c üú
K!ÿåüû þ"	7qWMK
(;\]G^XYC G o XYC o T
 þK
(¿ ûqúåþ1ü+°û¿
 úî
(&û*>?
 þ" üúyýü&:GAXYC cãG o XYC o ¿
 ú
úüþ	/G_o[XYCB¾
o c G^XYC_6"7
Ç  úûM  úþ1û1& û þ1ûn  ú0d
 ÿ$ûqúiK4ÿ©¿
 úyü&"$ û&K  úAM  ú$ûî0
+1& û	
(º[*(
(?$û©û ûý]ý¸oú þ" üú
=Þ þÿ©& û	
(1 üú
(ûA1& ü° û& þ" û7 Ú ûK
	>ä
 þÿ
 þ
Þ1& û	
(º[*(
(?$ûi
 ý;$ú þ" üú5 üúnK!ÿ üû þ",
 KÈL4S2S´
ÜEOµN À
c ý /G^XYC_Ë
6 gª/G o XYC o 6B G^XYC cG o XYC o 7^Ç  úû þÿûqún üúK$ û&"Ó

 ú,°ûF
& ü¿ý)
. üN
þÿ

 þ;c{ ÿþFK
 þ"1 ý°7@$ üM
& ü&$&K ü û\ þÿûqH
 ü1 þF1& û û*¿
 úþ)
(1& ûTþÿûdüúû%  ú$ûB$ ûqú$üþ1û _-9-W1\
:-9-=×,\ :-9:
- @,\$¿
 ú :-9-9Ö,7
:-=-W1%!þ9K
ë
 þÿ$
 þÃcU=
I  ú$û	
()
& ü&"$ û&	














l~x G+XYC|cyGMoXYCBo°ü&WG:o[XYCBo¾c G^XYC7

:-=-9×K
ëþÿ$
þÃcU@þ"&K
¿ú"Þþ"*û(


G ÷ YX C ÷ \þÿûqúiG ( XYC ( c G ÷ XYC ÷ 7
:-=-:@B
Rþ1û!ÿ$ú	
(üúÞþ"üúi ú*ü*  ú ú$üþ"üúdü¿ý ü&"$û&)þ1ü°üü(7Ù)ÿ$ûM&1ûû*(
¿úþq$û#~úº
þ"üú_
(&ûHüÞþþ1û ÿ$û&1ûu/p1ûûÞ/pÇ úû(\F132Ö(ò,T
6 ýü&:$ ûþK
(6"\Ç" úû :-=-:@,\Z
(:Ç úûHü$1û&!*û\#ÿ$ü
*
(	ü"u ú+#~úÞþ1ûM$üN
( úM/'þÿ$ûJüú üúûë
 ü¿ýÇ  úþ1û1& û þdÿû& û6"7


vmx ýÇG ( XYC

(

yG ? XYC
c

?


¿úfG ? XYC

?

c







Ð

ÿmx



o

Ù)ÿ$ûM1ûþ  G+XYCË¡îÿ$
(=
Iü$úþK
(û:$
(K= ú

&K$û&@þ1ü°üü(Þ ú$ûu, M7

þÿûFü

Ç ú
(\ :-9-9Öðû"ûqúþ"?
(ÞK
	>)þÿ
þÃcUB ú&1û	
(" ú\$ ú




M1ûqú1ûJü¿ýÝ½û	NA
ò>7Y5>7

þÿû

x



[/ 
,6NýxG ÷ XrG ? muG ( c{C ÷ XYC ? miC ( 
¿úfG ? XrG ( cwC ? XYC ( þÿûqúfG ÷ muG ? XrG ( c{C ÷ miC ? XYC ( 7
/pJ6ýxG ÷ XrG ? muG ( c{C ? XYC ( 
¿úiG ? XrG ( cwC ÷ XYC ? mfC ( þÿûqúfG ÷ muG ? XrG ( c{C ÷ miC ? XYC ( 7
/p6N ýG ÷ XrG ? mÞG ( {C ÷ XYC ? mfC ( \G ? XrG ( cUC ? XYC ( \J
¿úfG ? XrG ( T XrO\$þÿûqú0G ÷ mfG ? XrG (
C ÷ mfC ? XYC ( 7
Ç úûFþÿ$ûqúu?
(?@þÿ$ûJýüü3= ú þÿûü&1û	u
- ÿ
(þ1û&Z"\Ù)ÿûü&û	dÒ,6 ü Â cç´¦KNPO´RÇ S´
nÊ
ôÌ
½p n » t½p¦lºp¼©½ /pÇ  úû(\132Ö(ò>\@
Æ
Æ
S`WN À SL4SVS_ùYO´Nµ´J´¦FHkSÃKÈL4S2S`ORW^È:Â¦ÄW!D`NPOFWk Ù ¿À SL4SVS_ùYO´Nµ´ÍK Â¦ÄW!D`NPOFWt
FMÂ;NPÜnFkQÑKLGOK%]`ZS¦´J´¦ÄD





N À



#"%$$

!

"%$$



"%$$'&

Æ
À

N À KN

N/GymiG o XYC_6 S t/P/G o XrGwmfC6"E_/G+XYC_6!6 Æ /
tN/;}]E"$6 S t/p'E!}c6 Æ
tN/;}]E"$Í
6 O´¯ORW!D`L4S_KÑ´¦ORW^ÈÒORW^}Â¦FYL9"70/ T XrOe6 Æ

Ê Ù
Ì Ù



Î Ù
Ù
(
& Ù
) Ù

O Ó|c

tN/;}]E"t/p'E2A>6!6 S 
t /pt/;}ZE"6"E2A>6 Æ
tNP/ /OzXYC_6"E"$6 S  Æ
tNP/ / T XYC_6"E"$6 S / T XYC_6 Ù
KZó´¦F"´¦KYNPO´µÇS´*"%$$,+ Ù

Ù ÿ$ûTüú^1& û û*¿
 úþ=?
1ûë
)
 ýüë
& ü&)'&"° ü1 û%
(1& û_-%?
1ûI/1(6"\$d
 ÿ4 ÿÞ!1þ%M×,\'¿
 úi-)?
1û
p/ 4>6"\dÿ!ÿ+K
Mþÿ
þ)tg9
("1ü>?
þ"*û(7%B%Ý½û	AN
ò>7À×ÿü	B\sþÿû&1ûq@úüI
("1ü>?
þ"*ûJý¸oúþ"üú
K
þ"1ý° úM×Rýü&B<]û * 7FB)@úü3ãÿü3:\$þÿ= û	
¿úMþÿ
þ=Ç úû()þÿûü&1û	oü¦û)ú$üþ=ó>Þþ1ûJÿü
ûÞ þÿû&7
< ûýü1& û$ ü  úu ü\Z ûþ û$&" û å
;
 þ1ü4ÿ üúµ
uKþ" ûIKKû1& û
(&"  ú þÿûI$ üA
(  úyü¿ýJcM7I ú
þÿû
 üoúþ1û1& û.
$ ûHü¿ýPþÿ$û1& û* ü:1 û þ" üúL\Ç;
< û * /G^XYC_6B$ û~# úûn
( üúi
(C Sz
Q T 7NÇ  úû
 üûH
$
 úüþN
("K$Hû þÿ
 þjþÿû5c1& û?
 þ" üúH
 úû û"K
(&"j$ û# úû üú
(@
 üû þ"AGAXYCâK!ÿ þÿ
 þ
CFEHG {dO ¿
 úbC Sg
Q T 7 Ú ûI
("K ûT
 þÿ
 þaþÿû1& û:¿
 ú©
(¿ û&K
 ü¿ý@K1ûþ"a
 ü¿ýO '/ þÿ
 þ:\]

 ûþ)ü¿ýK$1ûþ"9 ü1 û0$ú$ û&%~# úÞ þ1ûM  úþ1û&" û þ" üúW¿
 úu ü û	 ûqúþK
 þ" üú6%¿
 úi
IK1ûþ I°o ü¿ý
1
 ü1 ûu$úo û&~# úÞ þ1ûW  úþ1û&"1 û þ" üú9¿
 ú úüþ% üúþK
(  ú  úð
 þÿûdû	N þ ûþK4ÿ þÿ
 þÔcy%$ û~# úû üú
 üúÞ þ" üú$
( üû þ"9G^XYCãK4ÿ þÿ
 þ9

G  z¿
 úi|
C  Io¸7F8  ú û Io$F ü û+oú$ û&@  úþ1û&"1 û þ" üú

 úno ü¦ûð
¿
 úüþ üúþK
(  ú þÿ$ûHû	 þ`©1 ûþ\ o 	¿
 ú$ú$üþ_ üúþK
(  úbp ü  úþ_1 ûþ"7^ ý)O ~# úÞ þ1û(#\ þÿûqú
þÿûaüú)
+

 ü û þ" üú Io'	¿
 úu ûûþÇ  úû()1& û1 þ"&" þ" üúu% ýmþÿû1& ûq%1 ü ûTúüú$û	 þ`N1 ûþBC *
K!ÿ þÿ
 þB
(½ û û	H
 ûqúþ"=  ú IoL üúþK
(  únC * 7@d
Ù ÿ91& û þ"&K þ" üúÞ9 û	
(&" þ1üü þ"& üúj
 þ1üjþÿûäû. þ1ûqúþ
þÿ

 þI ü'
(&K
 þ"* û+ üúÞ þ" üú
()& ü$
(Þ þb  úþ1ûqúo ûi
 þ1ü©¿ ûqú$û&K
(Ü ûu1& ü$
($Þ þ7n ý)å@&

1& ü'
(Þ þH
 ý;$ú þ" üúJ\ þÿûqúAÞ þF û& þK
(  úAN
(¿ û1 ûqú1 û)þ1ü üN$
(1& û9åF&	/G^XYC_6¿
 úNåF&	/GMo[XYCBo¸u6 û* ûqú
3 ¢Y¬¤ª¥p¥;¼¹)¤¥Z£[«(ª"²
£ ®¯°¦ :¦ °§r¨
± >¯ ®¯°¦)§ ¨± Ï®¯°¦ ¸§ ¦ ¨±p±@ÆZ«ª"½¤F¡p¤H¡[³¤¡p¤³_£[«¤ªH¡p»H¼¹)¤¬£¥Z«¤¡p¤F¾º¡
ÂDH¬(¥¸¢À¥¸£[¤¬(ÂÈB L¢£[«:!Y  ¥L£[«¤¡p¤D¹q
.-

/

0/

/

/

2/

/

*/

!3

4

65

75 4

 


/

1/

o$s$!P"$$#@$~%PF!&





åo$('*)$

ý)Cz
¿úbCBoÇ
(&1ûI;ü úþM1ûþ"	7Ç úûié &K*(
þ1ûIüAoú	
þ"üúJ\x1322Y@ì@K¿ûþ1û þÿ
þMÞþ_ÿþ
°û)°ûþþ1ûP
& þ1ü: üú þ"&K
(  ú :-9-9ÖW1 üäþÿ
 þM
 û=$ üîúüþ@ üúÞ þ" üú üúHû* ûqúþ"=C þÿ
 þ%
(&1û)ûó*
(ûqúþ]þ1ü
 ÿ$û1& ûCg)
 ûó*(
( ûqúþTþ1ü T  ý T cUCg¿
 úîC c T 6"7=8  ú ûFþÿûäüú û* ûqúþaûó>*(
( ûqúþ)þ1ü T   ú
T /;d
þÿû
 ü$úþ1û& û.
N ûîü¿ýuþÿ$û_1& û* üW1 û þ" üú0 T Þ þ"1 û ý`°\ þÿW û	¿
 úë
 þÿ$
 þ)þÿû ü$úþ1û1& û.
N û
	¿
 úu°ûq1û+=Þ þÿüþ%! ÿ¿
 ú¿ û(7)
Ù ÿ)%d
 ÿ
 þ)9o üúûq  ú þÿûM1& üü¿ýc°û ü	:7@F ÿü3U°û ü	 ÿü3D
 þ1ü
 ü> ý° þÿûM üoúþ1û1& û.
$ û:1 üjþÿ
 þ9Þ þBK
 þ"!o# ûB  ú$û()
H
 ü&"  ú
(Z1& û þ"&" þ" üú7


;l

tNpl~p¼
»

´ÄD À

+Nx ½å¿À SL4SÒS_ù%O´¦Nµ´,KWåFLMX%SLOµW^È5cî´¦KNPO´RÂ¦bTORWÈ8"%$$nÊ

N À KYNÂFLÁSQTSLb;ÂÄWDNPOµFYW¢ÖKÈL4S2S`ORWÈÜEOµN À

QKYLGOK%]ZS´Ã´ÄD À

c

Æ

Æ

"%$$ôÌ

Æ

"%$$'&

Æ

KWX8"%$$,+

ftdF4ÂkNPÜnF

Æ

N À SL4S,O´.W!F¢KÑ´G´¦F`DOµKYNPORQTSJÂÄWDNPOµFW

/GwmÞG:oÅ6XYC6 S t/PN/G:oXrGymfC_6"E_N/GuXYC_6!6 Ù

N À KN*

Ý ûþNO ¿
 úÛ;< û * °û^
( ú þÿû^ü$úþ1û&1û.
Nû+ úiþÿûA$&1û*>üûþ"üúJ7µäaû#~úû(c
½
ïJlmlð2½
1ü þÿ
þ^<;û * 
(&ûûN=Þþÿ cM7{Ù)ÿ>\9GAXYC c G:o[XYCBo9ã<;û * /G+XYC_6g <]û * /GMoXYCBo°6"7ã-%û	
(&"
cK
þ"!#~û :-9-q1u
¿ú
:-9-9×,7jWI%
(AHûqúþ"üúûwû	
(&"û&\%" úûfO I#~úÞþ1û(\Jc*
(	ü"
K
 þ"!~# û :-=:
- @,7x½Ý û	NA
Mò>7Y5_4ÿü	=Pþÿ
þ;cK
þ"!#~ûF$
(&1þ"B/[
,6
¿úi/p69ü¿ý :-9-=Ö,7Ù ü4ÿü	 þÿ
þ
c

( ü_K
 þ"!~# ûF$
(1& þ=/pJ6 ü¿ý :-=-9Ö,\M
 ûBþ$1& ü	* û)þÿ
 þF ýL;
< û * /G ÷ XrG ? mG ( 6g<;û * /DC ? XYC ( 6x
¿ú
< û * /G ? XrG ( Ã
;
6 gg;< û * /DC ÷ XYC ? mµC ( 6"\ þÿûqún;
< û * /G ÷ m0G ? XrG ( Í
6 ge;
< û * /DC ÷ mnC ? XYC ( 6"7Ad
Ù ÿûI1& üü¿ý]ü¿ý
þÿ
(?H
 ü þo ûqúþ"	
(o þ1üJþÿ
 þPü¿ý½Ý û	AN
qò>7Y5>Ø>;
 û9K?ð
 û.! ÿ¿
 ú¿ ûëþÿ$û)1& ü ûP ü¿ýJå@&/G ? XrG ( 6¿
 ú
å@&/G ÷ XrG ? mqG ( 6c  úðþÿ
 þ$1& ü¦ü¿ý`7Z û	
* û)þÿû%$ ûþK
(9 þ1üaþÿû%1& û	
(o û&7x½Ý û	NA
=ò>7À×q4 ÿü	=u þÿ$
 þ þÿ$û1& û)
úü_
(K1
 ü,?
 þ"* ûaý;$ú þ" üúNtãK
 þ"1 ý°  ú_Ma
× ýü&F;
< û * 7xBo þÿ
 þ@)
(F1ûN  úRþÿ$û=1& üü¿ý'%
(] þÿûëý;
( þ
þÿ

 þ:;< û * K
 þ"!o# ûy
 þÿ$û  ú$ûó>
(Þ þ" ûä
 ü¿ý=/[2,6"7<%sþaþÿû ûðûó
(Þ þ" û_1þaÿü ýü&M¿
 úå
 ý¸oú þ" üú

(1& ûû  ú:=Þ þÿcM7Ç)
Ù ÿ,\ û.
( þ"R
 þÿû)H
H
 û%1& üü¿ý ÿü3=u þÿ
 þ ý«{@¿
 úî
 ý;$ú þ" üúI
(1& ûû  ú:=Þ þÿ
cM
\ þÿûqúaþÿû& û# úüB
("1 ü>?
 þ"* û;ý;$ú þ" üú:tK
 þ"1 ý°  ú·
 /GmFG o XYC_6 S tP/ /G o XrGImC_6"_E N/G^XYC6!6"7
*

9

,

2

:

ñò

% üú?$ûJþÿ91 û þ" üúi+&" û ^"¿ ûþ"4 ÿ ú ÿü3\þÿûMü$úþ1û&1û.
û_	
¿úu°û:Hü>#oû+1ü

 ÞþIK
þ"!#~ûI ú$û(Hü&" ú
()&1û1þ"&"þ"üúJ7 ô û$û#~úûÞO Û
( úyüúûuHü&û ûû	 ûqúþ Þ * 7
ô ûoû#~úû;ßf
¿úÒßo$üäþÿ
þ:ßÇ/ Þ * 6 S ßo;/ Þ * 6 S 13æ^÷ 5 Ø ú+
(Þþ"üúL\&û$û#~úû;ßi
¿úÒßooüú Þ ÷ \ Þ / \

 ú Þ (Ú? \ üN
(@
 þ1üNo û1& û	
(1 ûFþÿû&9;
 û ÿþB,f13æ ÷ 5 \þÿûMMûÿþTü¿ý Þ * 7Ù)ÿ>\
Þ - \$¿
.-

þÿ þ

5 ~j13æ^÷ 5 \
Ñ ßÇ/ Þ ÷ 6 S ßo¸/ Þ ÷ 6 S :
Ò ©13æ < ~j31 æ
Ñ ßÇ/ Þ / 6 S ß o / Þ / 6 S 
÷

5

\

~ 13æ^÷ 5 '\ 
¿ú
Ñ Çß / Þ - 6 S ß o¸/ Þ - 6 S Ò©13æ 3 j
Ñ Çß / Þ

(Ú?

6 S
ß

o/Þ

(Ú?

6 S 1	4©13æ

( 3

~j13æ
÷

5

7

Ç ú
(\'&û$û#~úû_Oãoþ1ü°û  Þ * E Þ ( * E Þ (( E Þ (Ú? ¡7@Ù)ÿûM$û#úÞþ"üú ü¿ýÇ<]û *  ú þ1û&K@ü¿ýEß\ßo¸\'
¿ú
Oão1& û	N
(  úm þÿûK
H
 û(7ZVyÞ þÿîþÿû1ûF&1û$û#~úÞþ"üú\þÿûF$&1ü¦ü¿ý¸½ü¿ýsþÿ$û@&1û*ü1ûþ"üú¿ü)þÿ&1üÿ
û"1
 ûqúþ"?
($ú! ÿ¿
 ú¿ ûL7 ú$
(1& þ"	?
(&¿\ þÿûMûó
(Þ þ" û@  ú^/[2,#6 úü3 ÿü ýM
 û%
($ Þ * þ1üFû* û&!1 ûþ7
Ý½ûþ Io üú" þ]ü¿ýc
('Kûþ", ü¿ýcO  üúþK
(  ú  ú Þ * 7 | üþ" û)þÿ
 þ Io ü1 û+$ú$ û&x  úþ1û&"1 û þ" üú

 úno ü¦ûð
¿
 úüþ_ üúþK
(  ú þÿû û	 þ`î ûþ7A)
Ù ÿûN?
(K ü¿ý)
("1 ü>?
 þ"*>Þ þ`s  ú©#Ý û	NA
uò>7À×+	¿
 úiú$ü	ö°û
$û	 üú þ"&K
 þ1û^A üúÞ þ" üú  úð
 üú^1 ûþ"%  ú o¸7W%
 üú1 ûóûqú û(\M
 ûW¿ ûþ)
 ü$úþ1û1& û.
 ûdþ1ü
Ç  úû(ë
 þÿ$ûü1& û	 û* ûqúÞd
 ÿûqú+1& û þ"&K þ"  úH
 þ1ü üúÞ þ" üú
(N üû þ"ë
 þÿ$
 þ=K
 þ"1 ý°|
 ÿ91& û þ"&K þ" üúJ7
;/

;/

/

 C

Ð

<#ò>=

o

øÚÂÆ÷PÂÂøõ ô

Ý½ûþHûKAN
(&"ÜûîþÿûIþK
þKîü¿ý@*
(&"ü_&1ûKÞþ": ú
$
(° û&

Iÿþðü¿ýPþÿ$ûIü$úþ1û&û.
NûHü¿ý]þÿ

þÿû

- ü.Jäþÿûü&û	 
(ðü&" ú
(nþK
þ1ûb$üûîúüþîÿ$üµ ú©#úÞþ1û$üA
( ú7 à ü&1ûü	*û&	\,û*ûqú
Ñ @
  úf ú#~úÞþ1û_$üA
( ú\$þÿûü$úþ1û&1û.
û
¿úÓþÿ$û_"	""üúÞ úî8sûþ"üú©×IH¿ûþTþÿ
þ
 ü1& û9
("K$ þ" üú
(& û)1& ûó>1& ûH
 ýü&Þ þ"@ ü&"& û þúû"7x úI$
(& þ"	?
(&\ þÿû)?
(?ö  úHÿ@1& üü¿ý
þÿ$

 þ=t=
(K1 ü,?
 þ"* û$ üû)
 úüþ)ýü ü	_7
Ñ WÞþÿüÿ þÿû0ü$úþ1û&1û.
Nûi*ûqú ÿû&ûi úüþ+
µü$úþ1û&1û.
Nû|þ1übWÜ$ûç ;|þÿûü
& û	uo\ ÿ=
(KK$þ"üú)$ü úüþB1ûû	aþ"&üújûqúüÿ|þ1ü
(&K
¿úþ1ûûJþÿ
þdþÿûFý;$úþ"üúfïe


(K1 ü,?
 þ"* û(\c
()
 ÿ$ûM?
(?=ÞþB7
Ñ Ùdÿû9*
(&"?
¿úþ"]ü¿ý]-Mü	.;þÿûü&û	þK
þ1û+, Ú ûH¿û&KN
¿ú0/132ÒÒ,6"\ Ú ü&!*>Þþ"Ü(\ Ú ûK¿û&KA
¿úJ\
¿ú
Ý¿
 ú üþ"ÜN/132Ò5,6"\L¿
 úÞW û?$ú
(/132ÒÒ,6)
(]K	 þ1üjþÿû_ü$úþ1û&û.
Nû(7
Ñ ÙdÿûÞ?
(? þÿ
þHþÿû³ý¸$úþ"üújt þ°ûÞ
("ü,?
þ"*ûî úÇ úû( þÿûü&1û	 N úü&K&1ûþ7
Ç  úûHÿ$
(:
¿ú©
¿ú
(ü¿ü_&ûKÞþI/pÇ úû(\@132Ö(ò>\x-@ÿ
(þ1û&q"\JÙ)ÿûü&1û	â4>6)ýü&_$úüúÞþ"üú
(
 üN$
(&K
 þ"* û1& ü'
(Þ þÞ  ú* ü*>  ú+
 ý;$ú þ" üúfïR
(W  úiWÜ$ûç ;F

 þÿûü1& û	Þ7=)
Ù ÿd
 ý¸oú þ" üú
þ1üü?
(? û þ1ü°ûB
("
 ü,?
 þ"* û(\'¿
 úA
(
(  úJ\ þÿ$ üû;
 ú$üþF1 ûû	 þ1üðýü ü3e/[
(Þ þÿüÿ+
 üoúþ1û1& û.
$ û:$ üû)

 úüþB
($ þ1üjþÿ$
 þëþÿûü1& û	u6"7
ùaýB
 ü&"1 û(]\ þÿû+  úþ1û& û þ"  únóû þ" üúwúü3 d
 ÿ
 þIÞ þIM
 ü þK
(¿ û þ1ü©&1ûü3*û&^-Mü	.Hþÿûü
&1û	Þ7åx
(&"q
("K$þ"üúuW4NHáNû\J
(=$üûëþÿûþ"&1üú¿û&q
("K$þ"üú ü¿ý9úüú$
þ1üÞþs/p1ûû
$üüþúüþ1ûI4>6"7BWB; ûRÿ
* ûRüû&!* ûL\JB4 ýü&K ûd
 þÿ$û_$ üA
(  úÓü¿ý;
< û# þ1ü^°û: ú#~úÞþ1û(\L
(Woü¦ûdþÿû

("K$ þ" üúiþÿ
 þjþÿû+&K¿
 ú¿ û ü¿ýB;< û9
(@
 ü¿ýIé æ>E1ìp7bV ûu	¿
 ú
(%
	> û. þ1ûqú
îo üN
(  úiþ1ün¿
 ú
 ú~# úÞ þ1ûHßy  ú$ ûûL\$ú ü$úþK
(ûHßy$ üA
(  úî©
("K$  ú þÿ
 þMM
 û ÿ
	* ûN¿
 ú©  ú~# úÞ þ1ûI ü û þ" üúiü¿ý
 ú$ û° ûqúo ûqúþaý¸
(&M ü  ú\Z¿
 úå
 þÿ
 þMM
 ûI	¿
 úåþK
(0
(°üsþFüsþ" ü ûF
 ü¿ý@ ü  úyþ1üK1 û_
(qM
 û
(F
 þÿû
ü&"  ú
( û
* ûqúþ"W  úÓþÿû$ üN
(  úJ7M/p)
Ù ÿë
 þ° ûäü¿ýq1Ó ûs. þ1ûqúÞ þ`>Ôu
("H þ" üúi)
 ý;
(&"i þK¿
 ú$
(&"LØ
ýü@
& û.
N û(\Þ þ99N
($ ûq,+8
	*(
(¿ û/13Y2 @4>6  ú+ó>Þþ1û:
° û1& ûqúþ9 üúþ1ûs. þ76 ú+K!ÿu¿
 ú û. þ1ûqú$ û
$üA
(  úJ\Þ þ1 ûû	1& û	
(1 üú
($û þ1üî
(1 üf
(KKHûHþÿ
 þ;
< ûF*(
(&K û$ú ýü&KN0°ûþ`;
 ûûqúbæµ/p û1& þK
(  ú
ý;
(1
 ûqÿüü,J6)¿
 ú©1^/p û& þK
(  ú³þ"&Ksþÿ6"7% ýZM
 û
( üA
("K$Hû:W4i«/ ü&W1 üH
 ûþÿ  ú¿ û_Þ þ6"\M
 û_	¿
 úÓþÿûqú
&1û ü3* û&AM
- ü.Jj
 þÿûü& û	u7 | üþ" û(;\ ÿü3;
 û* û&;
\ þÿ
 þRþÿ* û=° ü  úþIK
( ü3=Ny

 úüþ" üú ü¿ýBû ûý
þÿ

 þëþK
(¿ ûT
 üú üú+~# úÞ þ1û+A¿
 ú+&K
($
 þ" üú	7
 úüþÿû&9° ü"KÞ þ+@
a
 þ1üHüû&!* ûaþÿ
 þ9M
 û:
(1& ûJúüþ9  úþ1û1& û þ1ûf  ú!þ@üúûM$ üN
(  ú+  ú+ ü?

þ" üúJ7 ô 

 þÿû&\T
 ÿ
 þM
 ûB
(1& ûB  úþ1û1& û1 þ1ûA  úNFä

 ú$üþ" üú ü¿ýJ°û ûýL]< û~ þÿ
 þF
($ ûoú ýü&Hä
 þ1ü
(
 üA
(  ú7_)
$
Ù ÿ>N\ û* ûqún ý=/DCFEHG6=¿
 új/DC o EHG o 6=
(1& ûI$
(&"F
 ü¿ýFK1ûþ"F
 ü¿ýF° û1& ûqúþ/p° û& ÿ$
(a
 û* ûqú
; ü  úþ6)o üN
(  ú\ ý@;< û[/G+XYC_69¿
 úî]< û/G:o[XYCBo¸69
(1& ûüþÿµ1 §×,m\ þÿûqúfM
 û_M
 üy
 û.° û þTþÿT
 þ1ü
 ûqúüþ1ûîþÿûK
H
$
 û_1& û?
 þ"* ûI þ"1& ûqú þÿ³ü¿ý°û ûý`7= ú|þÿW1 ûþþ"  ú\c¿
 úî¿
 ú
( üûRü¿ýxW4A ûû	qH
 ü1& û
& û	
(1 üú$
(û(7N)
1
Ù ÿ
 þ:	\]M
 û	¿
 úµ
("HHûðþÿ
 þJýü&_
(F(
æ -ª/@2E 1Ç4E 3e-R1N¿
 ú=
 6V7eæ>#\ þÿû1& ûI1 üH
 û
 üA
(  ú0O ¿
 úîK1ûþ"C ( \ÇC ? \ÇC ÷ \]¿
 úsC < ü¿ýFO H4ÿ³þÿ
 þaþÿû üú?K üúyü¿ý@W4 ÿ$ü7q© ý
$
Mûdý;&þÿû&
("K ûëþÿ
 þ;þÿûTý¸oú þ" üútI\ïI\¿
 ú+hb
(1& ûq
(1 ü$ú ýü&Kö
(& ü"%$ üN
(  úB'/ þÿ
 þ)\
þÿ

 þ:1\]M×,\¿
 úîqò ÿü ýüa
& þÿûK
H
 û4 ÿ$ü ûHü¿ýFt\ï\]¿
 úµhy  úyû* û&"0$ üA
(  ú6"m\ þÿûqú0M
 û
0
	¿
 úi
(
(  úi1& û ü	* û&MM
- ü	.)
 þÿûü1& û	u7

	'¿J«¢À¥L·H¢Y¬£L LªH¥c¢Y¬³¤·¤¬³¤¬£p®È9¶¥;¤¡p½¤!³B¶	È K¤DÁÃªH¡;¢À¥q ·¡;¢À½HªK£[¤Â`¹)¹¼¬¢ÀÂª"£p¢ÀH¬,²M_?


@?

 



o$s$!P"$$#@$~%PF!&


åo$('*)$

Ù ÿ$ûM$ û	H
)

 ü¿ýuÿ
*  ú^H

 úüþ" üú|ü¿ýx$ú û& þK
(  úþ` þÿ
 þB
($ ûB$ú ýü&KNN  úi
(co üN
(  ú9 ûû	
?$Þþ ú1üHû%"	""üú úðþÿ
þFÕ,
úû&1ûûqúþ@°üüäüú&1ü'
(Þþðþÿûü&!+/13225,6"7Õ,
úû
ýü,	ûF
(?H
 ü1 þ]û.?"* û üúN~# úÞ þ1û9o üN
(  ú7 3 W;
 ÿû=K
_Ó! ú$&"  ú û(s\ û* û&!1& ü$û	þ
þK
(& þ=Þ þÿsK!ÿn~# úÞ þ1ûN1 ûþ1& ü$
($Þ þ" û]Ø ûs. þ1ûqú" üúð
 þ1ü0  ú~# úÞ þ1ûA1 ûþ"° û&KNÞ þþ1û üúµd
 ÿûqú
þÿW)
 þÿ$û_1& ûKÞþdü¿ý
IM
 ûº$ û~# ú$û0¿
 úi;
 ûº°ûqÿ
	* ûî?Þ þ"  úA1& ü> û"d
 ý¸1& ü 
I~# úÞ þ1û1 ûþ7ÔÙ ü
N
(¿ û1 ûqú1 ûðü¿ý9þÿW?Þ þ"  úN1& ü> û"\JÞ þq1 ûû	d
 þÿ
 þMÕ
 úûMþ=°û
("KN  új
 þÿ
 þTþÿûK
H
 û
úüþ" üú ü¿ý$ú
 û& þK
(  úþu
( û)  ú+
(L$ üA
(  ú7 à ü& ûü	* û&o\ üú$ûW	¿
 úuA
(¿ ûM
(&"Hûqúþ")
(° û	
(  ú
þ1ü
 üúþ"  ú>Þþ þÿ
 þd
 ÿûqú; ûW üú"$ û&%K4ÿA?Þ þ"  ú1& ü> û"1 û\M
 ûB	¿
 ú^
(%
	>%# úNK1ûþ"=C ( \
C ? \C ÷ \L¿
 úµôC <  úî üH
 ûKáN ûqúþ"f&"! ÿÛ/p$sþW~# úÞ þ1ûë
6 ûs. þ1ûqú" üúyü¿ý,þÿ$ûðü&K  ú
(x$ üN
(  úfK!ÿ
þÿ

 þ=W4 ÿü$7
V ÿ ûRþÿM1 ûû	NM¿ ûI° û& ÿ
(d
D
 þÿûH
 ü1 þW1& û	
( üú
(û
(Þ þ" üú$
(
("KN þ" üúq1& ûó1& ûå
 þ1ü
 ûþ@
¿
- ü.J:1& ûKÞþ\Þ þ_$ üû:1& ûó1& ûJþ1üÞ üú"$ û&N¿
 ú0$ üA
(  ú:
 þäüú û(7 à ü1& ûü3* û&\xÞ þ_$ üû
úüþI
( ü	

 úüþ" üú ü¿ý)°û ûý@þÿ
 þjÿ
(î
å
 üún~# úÞ þ1ûsA¿
 ú©&K
('
 þ" üú\@ ûþI
( üúûu³

 ú$üþ" üúiü¿ý
°û ûý½þÿ$

 þB
( ü	=W1 ü ûFû* ûqúþ"d
 þ1ü°ûq üú"$ û1& ûf  ú ü'
(&K
(ûM  úu¿ û  ÿüü>L7
8° ü1 û; ûA1& û	
(µ
(1& ûA  úþ1û1& û1 þ1ûs  ú üúûN$
(1& þ"	?
(&:~# úÞ þ1ûN$ üA
(  úJ\¿
 ún;
 ûA$ üÓúüþ%¿
 úþ
þ1üåû
. þ1ûqúÛÞ þRü& üú"$ û&
(M
 üþÿû& üK"ûNo üN
(  ú7iV ÿ
 þI
("K$ þ" üú$ üf;
 û þÿûqú úûû
þ1ü¿
 ûþMM
- ü.J)
 þÿ$ûü1& û	"
 ?i)
Ù ÿû: üoúþ1û1& û.
$ û:* ûqúÓÿû& û: üi°ûM&"	$_* ûqúþ1ûi,+1& ûó>&"  ú
þÿ

 þtã°û=
("1 ü>?
 þ"* ûaüúN
(o þK û=/p&H
 þÿû,& þÿ¿
 úM!þPüújþÿ$û9 üú þ"&K
(  ú$û þ"&"$ û6"7 Ú ü3;
 û* û&	\ ý
Mû:1& û	
(Þ
(1& ûM  úþ1û1& û þ1ûi  úi
"  ú û:$ üA
(  úJs\ þÿû_ üþ"*(
 þ" üú ýü&=A
(,  úI& ûó>& û	H
 ûqúþ"@
 üú þÿû
°ûqÿ
* üP
& ü¿ýJt üú°û ûý*(
(?û] þÿ
 þ@o üäúüþF
(&" û=] ú$üþ@1 ü: û	
(&7 à ü1& ûü3* û&\Þ þF] ý¸
(,& ý¸1& ü û	
(&
þÿ

 þ%
("KN  úF
 þÿ
 þt%
("1 ü>?
 þ"* ûMKáN û] þ1ü_$1& ü	* ûdþÿûëþÿ$ûü1& û	u7x$ üM
& û.
 û(\M
- ü.J%1& üü¿ý
N
(¿ û)û)ü¿ýL*
(&" ü;ý¸oú þ" üú
( ûó>
þ" üú)  ú* ü*  útg¿
 ú+h%\¿
 ú
( ü¿ üMþ1üäþÿûTûó
þ" üúî/Ö6
þÿ

 þI
(° û	
(&"_  úÛs8 û þ" üúj×,7fd
Ù ÿû1 û ý;$ú þ" üú$
(P ûó
þ" üúI
(1& û û	
("µ1 ûûqú þ1üåÿ$üi
 ýü& û1& þK
(  ú
þK û	7 Ú ü	M
 û* û&\
(; û^K
	z  újs8 û þ" üúj×,9\ þÿû^1& üü¿ý)1& û	
(µ& ûó>& ûä
 þÿ
 þðþÿûi
 ÿ$üi
 ýü,
& KYZRZ
þK û	7@Õþ
("KN  úF
 þÿ
 þ%t 
(" ü,?
 þ"* ûM$ üûM
 úüþ%
($ û	
(P& þ1üKáN û)þ1ü
(&H¿
 úþ1ûûTþÿ
 þ;þÿû
ý;$ú
 þ" üú
(° ûó
þ" üú%  ú* ü*  úNh ÿü ýü&%
( þK$ û7$&þÿ$û&%
(KK$ þ" üúF
(° û	
(@
& úû û"H
(&!7
ì ÿ
(u üú( û þK&û þÿ
 þ þÿû ýü ü3=  új üú$Þ þ" üúJ\
| &u&" û$A¿
 úgé &"*
 þ1û© üN$ú	
 þ" üúJ
dÿ! ÿuK
	>)
 þÿ
 þ)û"1 ûqúþ"?
(i
(]°û ûý¸=
(1& û:$ þ"  ú þ\$KáN û
GN\ T CWo G_o¸\$¿
 ún/DCEHGI6WS Q /DCBo¸EHG_oÅ6"$\ þÿ$ûqúÞ;
< û[/DCIXrG6BS Q ;
< û[/DCWopXrG_o°6"7
Ñ  ý T C
¶
* ûqús ýMþÿ üúÞ þ" üúbKáA ûu\ ú$üþ1û þÿ
 þÞ þ$1& û?$ûu\ ýüî
& û.
 û(\x
0$ú ýü&K 1& ü'
(Þ þ
 þ"&K$sþ" üúJ\$¿
 ú|
 þÿ,B
(
(  úÞ1 ûû	N=$ú$N1& û þ"&" þ"* û(7
 úüþÿû&)° ü""$A  úþ1û1& û þ"  úI  úûFü¿ý1& û1 û	
(&K4 ÿuM
a
 þÿ
 þëü¿ýZ4 ÿ
(&H
( þ1û&"Ü  úH
 þÿ$ûTý;$ú þ" üúM
 þÿ
 þ
K
 þ"1 ý°bM
- ü	.I
("H þ" üú7ÞBð
 þÿû û.
N û^* ûqú ÿ$û1& ûN ÿ$ü	=9\ þÿ$ûN?
("j
 ü¿ý)K4ÿiý¸$ú þ" üú
  ú?oû;
 ý;$ú þ" üú] þÿ$
 þ)
(& ûaú$üþ% üH
 ü&"o ÿë
 þ1üI¿
 ú^1& ü$
($Þ þ ý;$ú þ" üúL7x@ üú û þK&1ûTþÿ
 þ)  ú
ý;
(
 þBÞ þ=  ú?$ûë
 üú ý;$ú þ" üú@
 þÿ$
 þB
(1& û_  úÞ1 üH
 ûM1 ûqú1 ûuÓ" ü1 ûÔ þ1üNj

 ý;$ú þ" üúu üH
 ü&"o ÿa
 þ1üA

1& ü'
(Þ þ^ þ"&"$þ" üúJ\
(Þ þÿ$üÿ^Þ þ%@
 úüþ% û	
(@
& û.
( þ" ÿü3zÓ" ü1 ûÔ ÿüA°û=o û~# úû0/ úü&
ÿü3ã  úþ1û
& û þ"  úH
 þÿ9?
("W1& û	
(u9  úu&K
( þ" û6"7
8 üµd
s
 ÿ
 þ^$ ü¦û^
()
 þÿAK
	1& û
(&"$  ú þÿû01û³ü¿ýM1& ü$
(Þ þ` ? | üþ+!ÿJ7{BÞ þÿ$üÿ
ÿ
	
* û|þ"&" ûw
 þ1üs
(&"ûÓÿû& û þÿ
 þ^M
- ü	.:!þ"#$	
 þ" üúbü¿ýW1& ü'
(Þ þj ú$üþó>Þþ1ûf
(N þ"1& üúµ
(
3'ùÂ£[¼(ªK®®È² ªÈ3¬¤!¥ª¥p¥¸¢Y»¬¥·¡p¶ªH¶¢®¢£¸ÈM£[=·¡pH·¥¸¢£p¢Y¬(¥D²>¬K£¥;¤D£¥D²¶¼3£!²>ªH¥¬K£[¤!³:¤!ªH¡;®¢Y¤¡²£[«¤¡p¤@¢º¥Ç¤¥p¥;¤¬£p¢ºª"®®YÈ
¬³3¢Á¤¡p¤¬ÂD¤x¶¤D£° J¤¤¬=£[«¤Ç£° J
3$Æ¸¬£[¤¡p¤¥¸£p¢À¬»H®È² ªÈ3¬¤!¥$¯;4
 G3²ùZ··¤¬(³	¢Yùx±ª³3¹%¢Y£¥£[«(ª"£>«ª"½¢Y¬»c·3®ºªK¼(¥¸¢Y¶¢®¢£¸È½HªK®Y¼¤¥,¶¤$¤D®Y¤¹)¤¬£¥,K¾(ªc·(ªK¡;£p¢ºª"®®YÈ	Ä
¡[³3¤¡p¤!³:®ºª"£p£p¢ÀÂD¤9¹9ª!È_¶¤9ªW¡p¤ª¥;¬ªH¶3®À¤=ª"®Y£[¤D¡p¬(ªK£p¢Y½¤%£[B£[¡[ª³3¢£p¢Y¬ªK®·¡p¶ªH¶3¢Y®¢£¸È_£[«¤D¡;È Z¢Y¡ (¡;¢Y¤!³3¹9ªH¬ªK¬(³_Æ
¯;4 G¦²4 G3²4 G¦±]«(ª!½¤@¡p¤!ÂD¤¬£p®È:³3¤½¤D®Y·¤³M¥;¼(Â[«ª%£[«¤¡;È:ªK¬(³M¥;«" c¬:£[«(ª"£Z¢£·¡p"½¢º³3¤!¥ª9¼(¥;¤`¾¼®¶(ª¥¸¢À¥Z¾º¡
£[«¢Y¬´	¢Y¬»%ªH¶H¼£]³3¤D¾ªK¼®£]¡p¤!ª¥;H¬¢Y¬»9ªK¬(³W¶¤D®¢Y¤D¾¡p¤½¢À¥¸¢Y¬
C

BA

A

>A

A

D?

E?

GF

 °

63

Ð

o

1& û* ü"sû û* ûc\F¿
 ú þÿû+
("KNþ"üú$ú$û&" úÓþÿûN*
(&"?
¿úþ"Hü¿ý9ÞþHúûûÛ?
(&"#$	
þ"üúL\
 
 úüþJþ"&"> ú|þ1üÞK¿ûþîþÿ
þ_&ü$
(Þþ©ÿ$ün°û
($
¿ú$üú$ûL7NÙ)ÿû&û
(&1ûNN
¿úyüþÿû&
M
"þ"#$	
þ"üúdýü&=Þþ"B1û(7
À

ÆIH ô õ!J¢p

ö K
m 6

rem~ô

ÃÂ

¿û|þ1ü þÿ
¿újÕ
¿ú$üNWÜ$ûç ;\Wåuûþ1û&+-@ÿ$ûû1û	N
¿úJ\%Ù û&"&!Û ú$û(\ ô üú'
( úJ\ | &A&"û$A
¿úJ\
äM
* Ú ûK¿û&KA
¿úJ\¶@&K Ú ü&!*Þþ"Ü(\-@ÿ&Kþ1üoÿû& à ûû$\'Õû0åx
(&"	\$
¿ú þÿûM
¿úüú ü)&1ûýû&1ûû
ýü&+1ûý¸=
 üN ûqúþ" üú þÿûf'
(û&	7ãy
(1üÛ¿ûåþ1ü þÿ
¿úÕ,$û	
nåuû	
(&"aýü&+ü úþ" ú üsþ
 þ1ü^ û¿
 úîÕ¿
 úüqWÜ$ûç , ýü&W° ü  úþ"  ú üsþM$
(?A
( úû(M$
(° û&7W)
Ù ÿB;ü&"
ô û! ÿûqú,$
(4 ÿJ:; ü&"|
)
(F?
(&"¿ û	
(&K&" û üsþFd
 ÿ û)Ç)
(
 þ]þÿû)!< à B?A
($ ûqú ô û û	
(&"4 ÿ+M
- ûqúþ1û&7x< à @K° ü& þ
&K
 þ1ûý;_
(Ks úü3= û¿ ûL7x)
Ù ÿûÇM
 ü&"W)
(Z
(1 üBK° ü& þ1ûM  úM'
(& þ],Tþÿ$û | 8F\$ú$ û&L&K¿
 úþ"c ô `
2 @3`æò>13æ2u¿
 úi ô `25D× @(2æ>1\]¿
 úÓ
Y
 þÿû:W&Bo ü&" ûRùqáN ûJü¿ý@8 ûqúþ"#$ ô û1 û	
(&"! ÿµ/pW8-B6"\oú$ û&
&K¿
 úþx2(45×(æ`25"1`æò×ò>7{ & û?  ú
(&!µ* û&"" üúwü¿ýdþÿ$
(° û&I
(° û	
(&"I  ú :L\F`D Ù KNPOFWKZ
EFWÂ`SL4SW!DGShFWÉ;LNPO ÇqD`OKZ ü WNS`ZRZaOÈ^SWDSÁUPÉÔÉJÉ ü
[
IYI Ù ÊTÎ^ÊTÎ ÊTÎ^Ê
7
Æ
ML

$

À

P Q )

¹²¹8m~ô

öPøu_À

òho

Äõ õwJõ
w#S

mrçr

Å

IR

ON

Q

¸uòT

ô û	
(¦þÿ
þÇ
(þÿ
þ&1û	N
( ú] úJþÿû@&1üü¿ýü¿ýÝ#û	NN
)ò>7Y5=½þ1üB$û	
(BÞþÿFþÿûF	
(1û,þÿ
þå@&	/G ÷ XrG ? m
G ( 6 S å@&	/DC ÷ XYC ? m)C ( 6L
¿ú:å@&3/G ? XrG ( 6 S å@&/DC ? XYC ( 6"\
¿úäÿ$ûqúû@åF&/G ÷ mFG ? XrG ( 6 S åF&	/DC ÷ m%C ? XYC ( 6"7
< ûýü1& ûF$1& ü, ûû$  ú)=Þ þÿJþÿû@& ü¦ü¿ý`\Þ þûý¸þ1üB ü û þx1 üH
;
 û¿ ûqú$û&K
( ý;
( þ"x
(üþ]å@&7ÇÛ1ûþ
C xK
(R
 þ1üM°ûJ´NKYWXYKLMX ýcC 
qKûþ ü¿ýüúûMü¿ý  Þ ( E Þ ? E Þ ÷ ¡\  Þ < E Þ 5 E Þ / ¡\  Þ 0 E Þ 3 E Þ - ¡\ ü&
E
E ¡71& û	
(m ú,°û& N)K
( þ1üûVL4SZSQKYWN% ýmþÿû1& ûaû. þ")1 üH
 ûW þK¿
 ú'
(&"fCd¿
 ú
 Þ ( * Þ (( Þ (Ú?
1ü û_
(&"Þþ"&K
(&"ÞGöK4ÿ þÿ$
 þ S åF&	/G^XYC_6"7 | üþ" ûîþÿ
 þTû* ûqúi ýFCaSã
Q T T
 úüú þK¿
 ú$
(&"c\ þÿûqúJ\
þK
(>  úÞCWm
o þ1üA°ûFþÿ$û_ þK¿
 ú'
(&"iK1ûþdü¿ýCgd
 ÿ4 ÿåÿ
(ë
 þÿû1& û	
 þ1û þqM
 û ÿþ°\ þÿûqúÛXDå@&	/G^XYC_6Ç~
å@&/G+XYCWo°6Xxí }Yææ×,7s/pd
Ù ÿî
 þÿûA1& û	
(1 üú þÿ
 þäþÿûAM
 û ÿþ"I
(1& û^Þþ" ûs, ý¸
( þ1ü&KH4ÿb
(
13æ < \J13æ 3 \¿
 úf13æ ( 3 76_)
Ù ÿ>s\ ýü&)¿
 úAK$1ûþ"9Gg¿
 úfC ü¿ýO\>;
 ûFÿ
	* ûdþÿ$
 þ%åF&	/G^XYC_6) ü1 ûTþ1ü

I1& û û*¿
 úþdú,$°û&M/;d
 ÿ$û1& û+Ó" ü1 ûÔA û	¿
 úIÓ!=Þ þÿ  úî7Yææ×Ô>6"7
-)
(Wy

 þ"&" ûµ/DCFEHGEHGoÅî
6 ü¿ýqK1ûþ"H
 ü¿ý_O ÈYFF`X ýM;
< û * /G_omµG+XYC6 S ;
< û * /G_opXrGemjC_6q
< û * /G+XYC_6"7î-) û	
(&"µ ý)°üþÿ/DC ( EC ? EC ÷ 6q¿
 úy/G ( EHG ? EHG ÷ 6:
(1& û^¿ ü¦ü>Lu\ þÿûqú þÿûN û	AN|
;

 ÿ$ü7
 úüþF¿ üü,c\ þÿûqúÞC 9  Þ ( * E Þ (( E Þ (Ú? ¡W¿
 ú,
 ßÇ/Gnm  Þ ( * E Þ (( E Þ (Ú? ¡(6BS Q
| üþ" ûdþÿ$
 þF ýx/DCFEHGEHG_o¸6M
ß o /Gjm
E E ¡(6"\d
 ÿ! ÿuH
 û	¿
 ú] þÿ
 þ=Gjm  Þ ( * E Þ (( E Þ (Ú? ¡M1þF üúþK
(  ú üúûaü¿ý Þ ( * ¿
 ú
 Þ ( * Þ (( Þ ((

\
$
sþ
)
$
ú

ü
=
þ
°ü


þ
J
ÿ
$
\


¿

ú


þ
>
ÿ

=



þ9°ûaüúûJü¿ý  Þ ( * ¡\  Þ (( ¡\  Þ ( * E Þ (Ú? ¡o
\ ü&  Þ (( E Þ (Ú? ¡7
Þ ((
Ù ÿ>\,; ûWN
	N
(@M
)
 û
(KKHûMþÿ$
 þ%
 þ û	
( þ;üú$û)ü¿ýx/DC ( EC ? EC ÷ u6 ü&B/G ( EHG ? EHG ÷ 6M
 úüþ¿ ü¦ü>L7
ú þÿ
 þ=	
(1 û(\$?
(? þÿ
 þ)üúûFü¿ý þÿûäýü ü3=  úNþ)ÿ$üL
VU

WU

m G ? rX G ( 6 S ê `/G ÷ XrG ? mÞG ( 6 S <]û * /DC ÷ XYC ? mfC ( 6 S <;û * D/ C ÷ mfC ? XYC ( 6 S æ
Ñ <;û * /G ÷ Þ
m C ( S C ? m0C ( 
¿úfG ÷ mÞG ? miG ( S G ? mÞG (
Ñ C ÷ mfC ? f
Ñ ßÇ/DC ( 6 S ßÇ/G ( 6%
¿úßÇ/DC ( mfC ? 6 S ßÇ/G ( miG ? 6
YX

[Z

ú|þÿû#$&"1þB	
(1û(\LMûðÿ$
*ûI
(&1û	
(01ûûqú³þÿ
þdþÿ$ûû	AN
 ÿ$ü7WúÓþÿû1ûüúî	
(1û(\J;ûjÿ
	*û
< û * /G ÷ mîG ? XrG ( 6 S ]< û * /G ? XrG ( 6"\x;< û * /DC ÷ m©C ? XYC ( 6 S ;
;
< û * /DC ? XYC ( 6"\x
¿ús<;û * /G ÷ XrG ? m©G ( 6 S
< û * /DC ÷ XYC ? mÞC ( 6 S 1\1 üRþÿûM û	AN
@
;
 û	
("u1 ûûqú þ1ü ÿüL7Ç ú
(\' ú þÿûaþÿ&"u	
(1û(\úüþ"û
þÿ

 þI"  ú ûuåF&/DC ? mbC ÷ XYC ( 6 S åF&	/G ? msG ÷ XrG ( 6"\@M
 ûuþ
(üyÿ$
*û þÿ
þÁßÇ/DC ( msC ? mbC ÷ 6 S
 Ý



o$s$!P"$$#@$~%PF!&

åo$('*)$


Çß /G ( m_G ? m_G ÷ 6"7 à ü&1ûü	*û&	\ÞþFPû	
(!Rþ1ü_ûû@þÿ
þF
(oþÿû1ûëûó
(Þþ"û%þPÿüý¾ß+&1û$?
(û
,ßo¸7@W
( úJ\$þÿûMû	AN
?N û?
þ1û ýüü	B7
Ù ü+1& ü	* ûîþÿû?
(?u°\ ýü&Wo û#~úÞþ1ûqúû"	\L
(KKHûJþÿ
þI/DC ( EC ? EC ÷ 6%Fúüþq¿üü,Û/[
¿ú0$ûqúþ"	
(

(&" ûqúþM
 ü&",) ýF/G ( EHG ? EHG ÷ 6ë
 úüþ)¿ üü,L6"71& ü þÿûq! ÿ
(&K
( þ1û&"Ü	
 þ" üú0
(°ü	* ûFü¿ýmþ"&"$ ûM
 þÿ
 þ

(1& ûjúüþq¿ ü¦ü>L\LÞ þFýü ü3=F
 þÿ
 þÍßÇ/DC ( mîC ? 6 S +µ13æ ( 3 õ :¿
 ú5
 ßÇ/DC ( 6 S 132As13æ ( 3 õ \T
 ÿû1& û
"
×,EKò>E135>E1^Ö ¡A/p$ û° ûqú$  úJ
 üúÞC ? m  Þ ( * E Þ (( E Þ (Ú? ¡(6"\¿
 úA°üþÿ 	E qíy×(æB+13æ 3 7F-% û	
(&"s\ þÿû

&1û û*¿
 úþTú,°û& ü1 û þëþ1üIåF&/DC ? XYC ( 6@ §,132>7%8  ú ûMå@&/G ? XrG ( 6 S å@&	/DC ? XYC ( 6@+
("KN þ" üúJ\
å@&/G ? XrG ( 6W
(1 üf ü û þ1ü §,132>70)
Ù ÿ>\;
 û^þîÿ
	* û þÿ
 þ.ßÇ/G ( m©G ? 6 S iÛ13æ qõ o ¿
 ú
ßÇ/G
6( S 132%I13æ õ Ho°\T
 ÿû1& û ,  æ>E"4EKÒ>E13Ò ¡7 úHý¸
( þ\>Þ þP û	
(!ð
 þ1ü:1 ûû@þÿ$
 þ , ûÞ þÿû&@J
Ò ü&)13Ò>\
"  ú ûîþÿû1& ûI
(1& ûRúü^1& û û*¿
 úþJú>û&K)
 ü¿ý9þÿûðýü&K §,1320«/ ýü& ¢  ×,EKò>E135>E1^Ö ¡(F
6 þÿ
 þM
(1& û ü1 û
þ1üÞåF&/G^XYC6B ý=î
C {  Þ ( E Þ ? E Þ ÷ E Þ < E Þ 5 E Þ / ¡7I ún
(Þ þ" üúL\] ý S 13Ò>½\ þÿ$ûqú Ko°E HoFíe×(æ^b13æ 3 \
dÿ ûM ý S Ò>o\ þÿûqú o E o í ×(æ©13æ < 7F<F^1 þK¿
 ú$
(&"i
(&KÞ þÿH
 ûþ"_A¿
 ú$?
 þ" üúL\>M
 ûäÿ
	* ûJþÿ
 þ
13æ ( 3 / o ~j132 o 6Jõy13æ /132 %~ 36Jõw/ o ~ o 36 S æ }
ý S Ò>o\ þÿûqúuÞ þ=d
 û	
(! þ1ü1 ûûFþÿ
 þ=;
 û_1þ@ÿ$
* û
/11(6
o ~j132 o S æ>\c132 ~
S æ¿
 ú o ~ o S æ>\
dÿ ûM ý S 13Ò>~\ þÿûqú+M
 û:þ)ÿ
	* û
132/ %~ "o°6Jõ '/ Ho~ 36 S æI¿
 ú Ho~ Ko S æ>7
/1×6
 ûq
A	
(1 û¿
 ú$
(>"	7BÇ&" þqK° ü1 ûaþÿ$
 þ S Ò>7B)
Ù ÿ$ûqúuM
 ûþTÿ
* û Ko S Ho S æ>\
| ü	g üH
"  ú ûI ý Ho=S Q æ>½\ þÿûqúyý¸1& ü /11(6=M
 ûHÿ
	* ûjþÿ
 þ Ko § Ko S §,132>\x¿
 ú©Þ þ:J
 û	
(!å
 þ1üÞ1 ûûRþÿ
 þäþÿû1& û
 ü úüþ û. þ+1 ûþ" ( ¿
 ú ? K4ÿ þÿ
 þßÇ/ ( 6 S "o¸J
$
\ ßÇ/ ? 6 S Ho¸\B¿
 ú Ko § Ho S §,132>\B=Þ þÿ
Ù ÿ,	\'Þ þaýü ü3=a
 þÿ
 þqå@&/DC ? XYC ( 6 S å@&/G ? XrG ( 6 S §,132>7 à ü1& ûü	* û&	\c;
 ûþ
o E o -ã×(æNµ13æ < 7Wd
ÿ
	
* ûqG ( |
 üú $7ÇÚ þ;ýü ü3=] þÿ
 þ
S  Þ 0 E Þ 3 E Þ - ¡W¿
 ú+G ? mG ( ûÞ þÿû&  Þ 0 ¡dü&  Þ 3 E Þ - ¡\,$ û° ûqú$  úF
å@&/G ÷ XrG ? mÞG ( 6F1þ%°ûFüúûäü¿ý  æ>E1 §×,E1 ¡7B8  ú û:å@&/DC ÷ XYC ? mfC ( 6 S å@&/G ÷ XrG ? miG ( 6"\M
 û_þ
ÿ
	
* ûëþÿ
 þ@åF&/DC ÷ XYC ? mC ( q6   æ>E1 §×,E1 ¡798  ú ûWC ? mC (  üúþK
(  ú;
 û.
( þ"H
 üúû)ü¿ý Þ ( * ¿
 ú Þ (( \Þ þ
 û	
(!J
 þ1üW1 ûûPþÿ$
 þZå@&3/DC ÷ XYC ? m=C ( 6L	¿
 ú$úüþÇ°û)1 §×,7Ç© ýåF&	/DC ÷ XYC ? m=C ( 6 S å@&/G ÷ XrG ? m)G ( 6 S æ>\ þÿûqú
C ÷ mC ? mIC ( S G ÷ mG ? mG ( S{T \¿
 úA;
 ûWþ]ÿ
	* ûW;
< û * /DC ÷ mC ? XYC ( 6 S ;
< û * /G ÷ mG ? XrG ( 6 S æ>\
 üåþÿû+?
(?V
1
 ýü ü	=	7 ùFúiþÿû üþÿûH
& ÿ¿
 úL\ ý9å@&3/DC ÷ XYC ? mÛC ( 6 S å@&/G ÷ XrG ? mµG ( 6 S 1P\ þÿûqú
C ÷ m0C ? mfC ( S C ? mfC ( ¿
 úfG ÷ muG ? mÞG ( S G ? miG ( \'¿
 ú|
 þÿûM?
(? 
(
(  úÓýü ü3=7
 û_þ)ÿ$
* ûîþÿ
 þ S "o¸7Ú þW?NH
 û$?
 þ1û
| ü	 K° ü1 û S 13Ò>7% ý S Ho¸~\ þÿûqúu,©/1×6"\M
ýü ü	=d
 þÿ
 þJßÇ/DC ( 6 S ßÇ/G ( 6%¿
 ú
 ßÇ/DC ( mfC ? 6 S ßÇ/G ( mÞG ? 6"\'1 üjþÿû:?
(? ÿü	7@)
Ù ÿ>\M
 û:	¿
 ú
K$ ü û îS Q Ho°7i8$ ü ûîþÿ$
 þ îS Q æµ/[¿
 ún$ ûqúþ"	
()
(&"Hûqúþ:M
 ü&">_ ý îS Q æ,6"7u)
Ù ÿûqú þÿû1& û
û.
 þ"F üH
 û%}ÛS Q 1BK!ÿjþÿ
 þ S } Ho;7@8  ú û Ho	~ Ko S æ>\,Þ þ;ýü ü3=] þÿ
 þ S } "o¸7F8$þ"Þ þKsþ"  ú
} o ýü& =¿
 úÞ} o ýü& q  úî/1×6"\$M
 ûM¿ ûþëþÿ
 þ:/19~î}]6 o §>/19~î}]6 o S §,132>\ ý°1& üRT
 ÿ4 ÿ+Þ þ)ýü ü	B
þÿ

 þ "o § Ho S §,132>7 à ü1& ûü3* û&\J; û
(1 üA¿ ûþdþÿ
 þTûÞ þÿû& S S H
æ ü& ¦§ S §,132>7)© þBT
 û	
(! þ1ü
 ÿ$ûK³
4
 þÿ
 þ Þþq°ûîûÞ þÿû&ò ü&135>7© ý § S §,132>½\ þÿûqú0;
 ûIþaÿ
* û S o ¿
 ú S o 7
WFM
 ûFÿ
* ûM ûûqúJs\ þÿ)KáN û; þ1ü1& ü3* ûaþÿûW?
(?u7)
Ù ÿ>\>;
 ûq	¿
 úu
("HHû)þÿ
 þ S S æ>7F<%sþ
þÿH
 û	¿
 úF
 þÿ$
 þIC ( S  Þ ( * E Þ (( E Þ (Ú? ¡\Ç¿
 ú þÿ
 þC ( mnC ? ä
 ûÞ þÿ$û&  Þ ( * ¡ ü&  Þ (( E Þ (Ú? ¡7A© þ
ýü ü	=d
 þÿ
 þ)þÿ$ûJüúu° ü""Þ þ" ûT
 ýü&Bå@&/DC ÷ XYC ? m0C ( 6%
(1& û_æ>\Z1 §(Ò>\LÖ §(Ò>\ ü&:17%© þ=)
 û	
(! þ1üN1 ûû
þÿ

 þ)å@&/G ÷ XrG ? mG ( 6x	¿
 ú$úüþ)°û:1 §(ð
Ò ü&=Ö §(Ò>\d
 ÿ û)þÿûW	
(1 û%d
 ÿ$û1& û=Þ þ)M
 ûÞ þÿû&)ð
æ ü&B1M
(1& ûaû	
("
þK
(¿
 ûqúÞ	
(& ûäü¿ý`\$
(B
(°ü	* û(7
Ù ÿ9 ü ûþ1ûë
)
 þÿû:1& üü¿ý ü¿ý½þÿû_?
(? ¿
 ú|
 ü¿ý#þÿû: û	AN
>
7 ñò
U

\

O]

U

*\ ^]

GU

U

_

]

U


a

bU

c\

Y\

	U

Ga

6a

`_

Va

\

^]

^]

dUD]

_

I\

I\

Ue]

f\g]

\

]

7a

Ue]

I\

I\

Ue]

\g]

h\

]

6a

f\

\

8U

d]

]

\g]

h\ i]

%a

,]

j\

*l

\

9l

k]

>\

]

U

ml

\

ml

]

n\

^]

k]

U

U

oU

#a

]

p]

]

W\

%\

q]

k]

W\

j]

0]

r\

]

]

q]

@\g]

\ ]

G]

,\

s\

U

#U

\

t]

%\

,\ k]

U

]

\

U

W\ k]

U

\

\


\

 ë

]

]

]

Ð

m w m
u

Ä o
m ô Æ

o

Â
m

WÜ$ûç ;\Õ7/13255,6"7 S2D`NPÄL4S´·FW í ÄWD`NPOFWKZ `ÄKNPOFW´:KWX ¿À SOµLnÉ I%I!ZzOD2KYNPOµFW´H7$W	
($û	å@&û"\
| û Pü&K$7
WÜ$ûç ;\JÕ7\ äM
(1& ü>Ü\ 7L/132Ö@6"7  W Ú S_KÑ´¦ÄLMS¦´¯F4Â ü W`Â¦FLH.KNPOFW×KWX ¿À SOµL À KLMKYDNSLO KNPOµFYW´H7
W	
($ û	N:å@1& ûK\ | û Pü&"'7
W û?$ú
(\ ô 7B/132ÒÒ,6"7g KAN
(&! ü¿ý:
 úû úü&HN
þ"*û³þÿûü&!bü¿ý:&ü$
(þ"0ü(7ú
:L\FDGS2S2XOµW^ÈÑ´¢FMÂÒN À S í FYÄLN À
FL2ý´ À FIúFYW
ôWDGS`LGNKYORWNPb5OµWBÉÍLGNPO ÇqD`OKZ ü WNSZµZaOÈ^SWDS
à   ú>
Æ
ú$û	
(
 ü	\ àf| \L7ZÒ x$1	47ÞW1 üf  ú ô 7Ç8 ÿ
(4 ÿþ1û&\xÙM7]#Ý û*>Þ þþ\xÝ@7 _¿
 ú
(;\x¿
 úsÕ7]½Ý û	AH
 û&\
û$Þ þ1ü&"\ ôWDGS`LGNKYORWNPb¢ORW$É;LNPO ÇqDOµKYZ ü WNSZµZzOÈ%S`WDGS
$
(¿ ûI1322 x×(æ5>7 | ü1& þÿ> Ú ü?¿
 úL\ | û
Æ
Pü&K$\c1322æ>7
- ÿûû û	N¿
 úJ\xå7)/132ÒÒ,6"7sa
@
 úµ  úó&!s  úþ1üî ü'sþ1û&oú$ û&" þK¿
 ú  ú7 EFYH·I«ÄNKYNPOµFW!KZ ü WNS`ZRZaOR³
È^SWDS\
/1(6"é\ @(Ò x>55>7
- ü	.\ ô 7x/132(45,6"7åF1& ü$
(Þ þ`½\ ý¸1& ûó>$ûqú\]¿
 ú©1& û	
(1 üú$
(ûRû.° û þK
 þ" üúJk
M
7 É;HkSLOµDGKW ^FÄLWKZnFMÂ
\ Ê /1(6"\Z1 x$13ò>7
À b´OD¦´ô
äM°ü\ä7\ åF&K
($ û(\ Ú 7/1322æ,6"7µd
Ù ÿûA ü	
(%* û ü¿ý9 üúÞ þ" üú  ú©¿
 úÛÞ þ"
($	
 þ" üú þ1ü
 ü"KÞ þs¿
 úi
°
 û*$ ûqú û þÿûü&" û7 ü WNSLWKNPOFWKYZ FÄLWKZ FMÂhÉ8IYI!LMF`ùYOµH.KNS±:S_KT´¦FWOµW^È\
/1(6"\c×(ò x,45>7
$
(?A
( úû(\%Õ7@-W7)/132Ò>1(6"b
7 ùJúj
f& û	&"1& ûqúþKû ü¿ýW
î?
(""	
(ë
 ý;$ú þ" üú
(@
 ûó
þ" üúj& ûKÞþ7
FÄLWKZF4Â Ú
KN À SH.KNPOD2KZ ´¦bTD À FZF2Èb
\ Ì%ÎZ/×6"\132æ x$132ò>7
Ç  úû(\$ÙM7Ý@7]/132Ö(ò,6"7 ¿À S_FLOPS´VFMÂ :L\F^]_K%]`ORZaORNPb7%B	
(o û	Må@& û"\ | û Pü&"'7
&" û'N¿
 úJ\ | 7\
Ú 
(° û& úJ\Õ7 7/132Y2 @6"7 å@?
"Þ þe û	
(K&1ûd
{1û&©N¿
 ú>
(;7 ú
:L\FD Ù :ZS`QÑS`WN À
EFYWÂS`LMS`WDGS×FW
WDSLNKOµWNPb=OµWåÉ;LGNPO ÇqDOµKZ ü WNSZµZzOÈ%S`WDGS>U éÉ ü
¦[\9L7
1Ö @`x$13Ò(47
&" û'N¿
 úJ\ | 7\ Ú 
( û4& úJ\@Õ7 7)/13225,6"7nå@?
"Þ þÛH
 û	
(K&1û¿
 ús$ ûý;
Þþ1& û	
(1 üú  ú70 ú
:L\FDGS2S2XOµW^ÈÑ´
KNPOµFYWKZ EFYWÂS`LMS`WDGS$FYWåÉÍLGNPO ÇqD`OKZ ü WNS`ZRZaOÈ%SW!DGS>UPÉÔÉÔÉ ü
[\
¿À ORLNS2S`WN À
Æ
$L7L1×(2`Ö x$13òæ(47
&" û'N¿
 úJ\ | 7\ Ú 
(° û& úJ\JÕ7 7/1322Ö6"7 à ü>$ û  ú^°û ûýx  ú0s ú$
:! þ1û	N7'$
(1& þ=~ ýü$ú>
'
 þ" üú7 É;LNPO ÇqD`OKZ ü WNS`ZRZaOÈ%SW!DGS\ ]/×6"\c× @`Ö x>ò>135>7
 ún
. üN
 þ" ý°&K
 û;
 ü&K³
 ýü&:°û ûý'
 þ1û7 úî#Ý û	NH
 û&	\LÕ7c7\
Ú ûK¿ û&KA¿
 úJ\Zä7@/132ÒÒ,6"7^T
¿
 ú
(;\Ý7 | 7P/ ¶@$76"\ W!DGSLNKOµWNPbÍOµWVÉ;LNPO ÇD`OKZ ü WNSZµZzOÈ%S`WDGS:Ì\L7,11 x××,7 | ü1& þÿ> Ú ü?¿
 úL\
q1 þ1û&"$
u7
 ý°&H
H
 ûM
 ü&"j
 ýü&% üN$
(&"  ú
(Þ þ1û&
Ú ü&!*>Þ þ"Ü(\ ¶=7>Õ7\ Ú ûK¿ û&HN¿
 úJ\ä7\ ãÝ¿
 ú üþ"Ü(\'-W7åZ7J/132Ò5,6"7xD
ú$

 þ"* ûðýü&KA
(Kë
 ýü&W?
"û1& û	
(1 üú  ú7= ú :L\F`DS2S2XORWÈÑ´ Æ í O ÂN À KNPOFWKYZ EFYWÂS`LMS`WDGS
FYWÒÉÍLGNPO ÇqD`OKZ ü WNSZµZzOÈ%S`WDGSkUPÉÔÉÔÉ ü
[3\'$L7$×,13
æ x×,1	47
Õ
	s ú$ûY\ ¶97ÙM7/132Ö(Ò,6"7D
V ÿû1& û%$ üB; û þK¿
 úR
 üúN
.?\ûqúþ"1& ü, ?7 ú½Ý û*  úû(\ ô 7ä7\ yÙZ&K$\
à 7)P/ ¶@	76"\ ¿À S Ú KùYOµHVÄH 8WNPL\FI«b í FLH.KZzO´H\%L7F1 @`x$113Ò>7 à ÙRå@1& û"	\F-)
&"¿ û(\
à 
("7
qv

xw
y

nz
|{

q}

~

$

i

z

L





2

#

(

z

$

(



L

(

7{

,

(



L

@L

#{

L

w

nz

Wz

$



'{

k

9P Q &

2z

N

L

:{

$

MP Q )

z

Q &



1{

6

|{

L

N

,$

P  )

I{

w

 õ



o$s$!P"$$#@$~%PF!&


åo$('*)$

Õ
	sú$û\¶97'ÙM7c/13225,6"7 8LMF%]_K%]`ORZaOµNPb ¿À S2FLb ¿À S F2ÈODkFMÂ !D`OPSWDS7@aú$ÿûLØ
*
(?
(û
þ
ÿþþ"L $
	
 û7rB1þ";7û$J7
åx
(&"\Õ7<=7/1322(4>6"7 ¿À S ôWDGS`LGNKYORW>±:S2KÑ´¦FYW!SL ´ EFHJIKWOFW7î-)
&"¿ûaú*û&"KÞþnå@&û"\
-9
$&"¿ û(\7 I7
ô û! ÿûqú,$
(4 ÿJ\ Ú 7/132(42,6"7 ¿À S ¿À S_FLbVF4Â 8LMF%]_K^]OµZzOµNPb7aú*û&""Þþ`jü¿ýJ-)
(ýü&ú?
qåF&1û"\<;û&"¿ûû7
Ù ÿ:
 þ"&K¿
 ú"?
 þ" üús¿
 ún1& û*" üú ü¿ý;þÿû aû&KN¿
 ú ûÞ þ" üúJ\Z' ÿûn
( K À L2´¦D À SOµW³
d
ZaOD À ýYSOµNµ´ZS À L4S\  úî132Y
ò @,7
8
	*(
(¿ û(\Ý7'Õ7c/13Y2 @4>6"7 í FÄWXYKNPOFW´.FMÂ NKNPO´NPOD¦´7FÕ üÿoú+Vy û ös8 üú\ | û Pü&"'7
Ù&"$\ à 7J/13252,6" 
7 ±8KNPOFWKZ hS¦´¦D`LOóI!NPOµFYW´ Æ hS_DO´¦OµFYW´ Æ KW!X hS´¦OÈYW´H7uå û&"
N üúAåF1& û"\ | û
Pü&K$7

L

`

v

#

`



P $



0L

*







c{



j

z

 þ

nz

	
 	


	"!$#%'&#(((*)+#,-(."#(/

0*12345(67(/891
!4;:6((

<>=?=A@CB3D5E$FHG-=JILKMBNFPOQBRB$ILST=A@?UVW=ROXILEAI?Y[Z\=]FF^=J_`UbaW@
Sdc?B'=]D5B$_

efD5='gAB3D5h

ikjlnmpoNq5rs5t

uvxwyz{}|~+vn+'x+~ w++~ u

A¡ ¢$£^¤*¥¦ §¨©¥7¥ª©«x
¬P­-¬¬}®¯§A©¥¥ª©«x*x¢3°3*¨±
²´³lxrko3q5rµs¶t

vnwyz{-|~+vn++Rx+~ +w+'w+yz+µ u

 «ª©¦ P«n¦ R-¨¡ }¢'·R£¹¸>«x¦ *
ºn»}¼n½»¾¸¿«x¦ *x¢$°*A±

ÀÂÁ'ÃÄÅÆ^ÇÄ
ÈHÉÊxË"ÌÉÍ3ÎMÏÎµÌkÐPÉÑÑÉÒJË"ÓÊÔÑÕÖÉ×ÖÒWÊ×ÉØxÙ©ÎÚÔÏÊµÊ×ÉxÏÛÕÖÜAÖÏÛÕkÕPÏ*ØÖ¨ÜÊPÖ-ÛÙÞÝPÛßÏ}ÌØÏÎxÑÏ}ÚÖÜ
Ï ÎÌkÌÙ©ÜÏ}ÌØÏÎxÑÏ}ÚÖÜ*àâáãÉÑÑÉÒJË"ÓÊCÊ×ÉØÖ×Ü]Ê×É}ÝPÑä×ÉÒåÜÑ×ÉÎµÚM×ÖÌÓÎÌÏÎÛækÛ-ÉÎxÑ×Éç;ÐÓÑAÜÓxè+Ö×
}
ä×ÉÒéÑÕÖ;çÏÛê$ÉäÚÉxÏçÞË"É×Ù©ÖÎxÑÏÑÙ©ÉÎëÍ3ÕÖ-×ÖÏ}ÜHÑÉÊxË"ÌÉÍ3ÎÊµ×ÉØÖ-×Ü5Ï×Ö5ÚÉxÏçÞËìÉ×Ù©ÖÎxÑÖ-ÌÐÓÑÉäÑÖÎÕPÏ*ØÖ
Í;ÖÏê$ÛÏ}ç©ÛÓç©ÙxÍ3ÕÖÎAÑÕÖÙ©×^Ê×ÉnÉ}äPç©ÖÎÚÑÕÜ5Ï×ÖãÛ-ÉÎÜÙíÌµÖ×ÖÌà^î"Î¨É×ÌÖ×^ÑÉ'Ù©ÎxÑÖÚ×ÏÑÖãÐÉÑÕ¾Ï}ÊÊ×ÉnÏÛÕÖ-Üë
Í;Ö'Ñ×æAÑÉ¨Ï}ÛÕµÙíÖ-ØÖ'Û-ÉnÉÊPÖ-×ÏÑÙ©ÉÎ?ÐÖÑ"Í;ÖÖÎâÏ$ÑÉÊxËìÌµÉÍ3Î?ÏÎÌâÏ$ÐPÉÑÑÉÒJË"ÓÊÊµ×ÉØÖ-×ãÙ©ÎJÑ"Í;ÉÌÙÞèÖ-×ÖÎxÑ
Í3Ï*æxÜïÈ3ÕÖ3ÝP×ÜÑ3ÑÖÛÕÎÙ©ðxÓÖÏÙ©Ò?Ü5ÏÑñÜÓÊÊÉ×ÑÙ©ÎÚJÏÐÉÑÑÉÒJË"ÓÊ¨Í3Ù©ÑÕßÏ$ÑÉÊxË"ÌÉÍ3ÎJÊ×ÉØÖ×*à^òóÑÉÊxË
ÌÉÍ3Î]Ê×ÉØÖ×ÚÖÎÖ×ÏÑÖ-Ü5ÜÓÐµÚÉnÏ}çxÛçÏÓÜÖÜëÑÕÖæ¨Ï}×Ö5ÑÕÖÎAÊ×ÉxÛÖ-ÜÜÖ-Ì?ÐxæÏ3ÐÉÑÑÉÒ¯ËìÓÊRÊ×ÉØÖ×àÈ3ÕÖ
ÜÖÛÉÎµÌßÑÖÛÕÎÙ©ðxÓÖ$ÌÖÏ}çíÜ;Í3Ù©ÑÕJÑÕÖ$ÓÜÖRÉäÐÉÑÑÉÒ¯ËìÓÊJÚÖÎÖ×ÏÑÖÌâçíÖ-Ò?ÒßÏ}ÜÙ©Î?Ï]ÑÉÊbËìÌÉÍ3ÎJÊµ×ÉØÖ-×à
ôkÖ?Ï}ÊÊç©æMÉÓ×AÛÉÎÛ-ÖÊÑJÑÉõÑÕÖâÏ×Ö*ÏÜJÉä'ÒöÉxÌÖç5Öç©Ù©Ò?Ù©ÎPÏ}ÑÙ©ÉÎÔÏ}ÎÌTÜÓÊPÖ-×ÊÉÜÙ©ÑÙíÉÎàCôkÖJÌÙ©ÜÛÓµÜÜ
ÑÕÖ¨ÏÐµÙíç©Ù©Ñ"æAÉä5ÉÓ×3ÑÖÛÕÎÙ©ðxÓÖÜRÑÉJÜÕµÉ×ÑÖÎCÊ×ÉxÉäÜ'ÏÜ3Í;Öç©çÏÜ'ÑÉJ×ÖÉ×ÌÖ-×'ÑÕµÖÜÖÏ}×ÛÕÔÜÊPÏÛÖ]ÙíÎÔÏ}Î
Ï}ÊÊ×ÉÊ×ÙÏ}ÑÖÒâÏÎÎÖ-×àã÷µÓ×ÑÕÖ×Ò?É×ÖëµÙíÎâÉ×ÌÖ×RÑÉJÙ©ÌÖÎxÑÙ¡äæ?ÜÓµÐÚÉxÏçÛ-çøÏ}ÓÜÖ-ÜùÏÎµÌßç©ÖÒöÒßÏ}Ü5Í3ÕÙ©ÛÕ
Ï}×ÖùÏ}ÛÑÓÏç©ç©æ×Öç©ÖØÏ}ÎxÑ^äÉ×ñÑÕÖRÊ×ÉxÉäÑÏÜêëÍ;Ö'ÌÖØÖç©ÉÊJÒöÖÑÕÉxÌÜ¶äÉ×ãÏR×Öç©ÖØÏÎÛ-æË"ÐPÏ}ÜÖÌöÝPç©ÑÖ-×Ù©ÎÚPà
ú^ûxÊÖ×Ù©ÒöÖÎxÑÜ;Í3ÙíÑÕJÑÕÖRÊ×ÉØÖ×ÜRü +z+P Ï}ÎÌâüý {*{ ÊPÖ-×"äÉ×Ò?Ö-ÌJÙíÎJÑÕÖ'Êµ×ÉÐµçíÖ-ÒQç©ÙíÐµ×Ï×æ¨È'þ¶È'þ
×ÖØÖÏ}çÑÕÖÕÙ©ÚÕöÊPÉÑÖÎxÑÙøÏ}ç+Éä^ÉÓ×3ÛÉxÉÊPÖ×ÏÑÙíÉÎÔÏÊÊ×ÉnÏ}ÛÕµÖÜà

 ÄÅ	
'ÇÄ 
ÿ

!"#$!&%('$)!&%+*&,-%.*&/*0'$1%23(45367*&2894)%:5#%+4;<=%23(4
%95%>@?#A94B5%+C#DE!0F23(2#<)2*&2*"!4/B7G2#$/<*"5H!I#J3(23KL5M,N!&94
53(7*&2O%QP3(R94S<3(2OPTCK943(2U536V/!W#;>TXY%%2#<!W*&*"DZ[P\3Y]^3(%6_3(23-943(2
53(/!I#;O(,-`a!I#)5<3!&;O%P\32*&2*"!b3(c!I#)%dSegf:hi(jfk	l+m:no&m2po&qb*"!WrKsOf2jto^to&qusOqvlnw\qvfl
xvy XNZ{zg/*W#Z	|2}~GZ^|}-25N.3623(%!&/*&D73(2<rKV,c#+#{93#%(P\3RO;<*!W#<
%97;*&%T94	2<#]^#*&*&D7G53(/2#!WO!W*"DK,N!&94O:4!"O%T3b,Q!":4.%%95!&#%-
3(!W#;)94S53(P>NNfw\w\f<sSi(phLm9n<o"mpo&q*&!Ira.pht2hfaqvw\quf<l x >;[>WZa4a!I3cR#!W#;23Z|}}
;M94=:423,ND17DE53(!I#;*&;!&=#%2#%{P36:4!W#5{%+#!"*S<#17/!&%
!W##%!&%2#D{!&%23(!&/>
 42#C536!I#;3(%:*"%aP/V36!"%536V/<23(% x >;>WZ*"!0FSH9#23Zg|2}}<b!&!&%N7/!&%
94	53(/23(%b7%O#!0F23(2#<5<3!&;O%	P\2#724/T!&-!0F2362#*&D>T Q423(3653(7*&2O%
,423(7<_¡5C94362¢536V/<23(%N523£P\3¤#%!&237*&D),-*&*¥Z[75<_,#.536V/<23(%N53(*&DZ
#=/!&/23(%:> N4.a!I#¦3(2%#§P\3c94!&%S!&%94S7<_¡5¦53(/23(%cP¥2#¨%9<F23QP36©94
*WrMPS;*0_36!"2#<9!"#MPS94!W3%23(4gZN753(a]P3(ª:4!I3C%936#;B3(##D#<93(*
O4#!&%9O%2>$?£#L#<93a%2Z5<_,#L53(/23(%K53(]OP3(ª:4!I3K;<*0_3(!&2#<9!&#L7K%9<F23
P3(«!W#%9<¬.!&2#K3(##DL#<93(*\>= N4!&%O2#<9!&*&%.*&#;=53(P*&2#;94%­P¥3O<#D=53(7*&2O%
®ö #((-(ã+¯4	5	4°$-		±^	*í23		²1
!³

x!*Pv´4³

µ

¶ µ

wyz{

wyz{

x >;[>WZzgO*\>WZ	|2}}a>N N423(:P\3(ZgC5!&O944%OO!I#<K94P¥2%P3(%23(4)!&%94
!W#;3!&#MaP·7G94L553(4%>¸5G!0]2*&*WDZc5G23!&#L7G(,2#¹943(2ª53(/236% x >;>ºZ
»-#36DN*\>WZg|2}}¼½4##gZ¾|2}}½<¿2#!W#;23Z|2}<}À½#a!I#CÂÁQ%!W#;Z|}}À½T#!W#Z
|2}}<~½  *0P^MÃg4%2Z|2}}<½2Ãg4%Z|2}<}7gZ|2}}a27%#c5<_,#<#S7_¡553(!W#!W5*&%
55G23(%N7GS53(O!&%!W#;)72%S7<DK4#;!W#;!W#<P\3!"#K24)<553(42<#)53(]-P3(
94{9423>E?\K!&%*&%L5<%%!W7*&¸O!0P¥DL2a*"2*&!3C53(/23(%,4!&4,3r=36!I#;L=#
53a!";Ä%S%!W#:3(%95G%	P94N<9423	53!&;¤!W#!&2>	 N4!&%2Z4V,-/23Z3(!W3(%-
*&TaP!W5*&2O2#<9!"#*:F3(	`O!0P¥DO94536V/<23(%2Z,c423(2%T3	553(4O%#-3(!I36
4#;%Pc94536V/<23(%7#*&DB4#;%OP94!W3O!W#52>  K2#L42#+2C5*"DL37!&93<3(D
%9a:_Pv_94:_¡3(N53(/23(%>
?£#<P¥3!&#§94c!&%,*&*0_%9!&¨P\3Q!W53(/!W#;)945G23£P¥3#OPT5<_V,c#+53(/23(%c3(
*&2%OE7DB7G_¡5B536V/<23(%2>¨ N4%K*"2C%3()L{94)!W#5P{5<_
,#L53(/23O#L2#L4*W5¹¨%943(2#M:4+53(aP*&2#;94L7<DM!ICO!W*&DL%*&/!I#;M%97;*&%2>
Å 3*&*&DZc94¨25*&DÂ53(P`53(3(%+2<#1%!";#!Æ]2<#*&DÂ536]P3(Ç:4È536PS*&2#;:4
3(!&#{7:!W#>N N4`%PT*&2%Z4,/<23Z*&%K!W536%a!"!"#*36##D+!W#<
942*&2*I%> Q4!"%S­2#%N94#{#7G#=%OPY7G_¡5);2#23+*&2C%,Q!":4
%!W#;K4#!&%cP¥3-4%!W#;K#*&D=(t2o&t2Énlw*&2% x !¥>>*&2a%N,4!&4{*&2{.3(!"#
Pg94N%2364O:F362#­23NS536P!&%#<T%2#%!W7*&>-?#O94!&%-3(!&*&Z!I#C#<93%<9423
553(4%,4!&4K;<2#23N*&2C%-D#­!"2a*"*&DK3(!W#;O94536P3# x c%93a4#OH!&ra*¥Z
|2}}<Ê½%:34#.Ëzg/*W#Z|2}<}Z<,,N#<-25*&D)7_¡5)53(/23YP\3-;2#23!W#;
*&2%)!W#$L536253(%%!W#;A54a%>ÌQP\23K94¨;2#23!"#1aP­L5*P)o&t2sOsOnLm9nl[jqvjnw\t
3(*&/V<#N*&2C%3(c%*&§P3(Ì:4!"%c5*#)94QP¥3`*WO­7GS3(:P)!&%;O2#<)7D
94%S7G_¡5K;2#23)P\3O*W%2>
 Q4%#C!W#+%95GN94Q,#%!&23N!&%c5<_,#Í7G`_¡5K!I#<;3!&#)7<D.93#%(_
P\233(!W#;B!W#<P\3a!&#¦P36ª¨5<_,#L53(/23­==7_¡5L53(/23 x >;>WZYÃ^4%2Z|}}>
Î3S<553(4¨!&%S{93#%6P¥23c5<_V,c#+;<2#23LpÏÐ<f2no	mo"n<pt'E,4!&4{%%2#!W*&*&DL3(253(:_
%2#<­93#%(P\3C!&#KP#§3(!&;!W#*b;*g*W%O!W#<.%:7;*&%('E.K7_¡5+536V/<23N#
¨;O2#<!&%S!W#5.7<D¨94%*W%%>+ N4!&%S!W#<93(%­§;*0_36!"2#<M5G#2#!W#¨
7<_¡5¦53(/23,4!&4=2<#¨2#7*&)!&`)%*&/)53(aPQ5367*&2O%O#%!&237*&D¦P%23>.ÁQ,-_
/23Z[%!&%c94S2a%S,N!&94§*&2%2Zg#)#7#¦93#%(P\23-P	%97;**W%%!&%#N%2#%!W7*&>
 N4%2Z[,;<2#23O;!W#)%:7;**W%%!W#¨53(253(%%!W#;+54%`#{!I#<;3S#*"D)%O
PT94%S*W%%!W#<)94S!W#5%cPK7_¡5{53(/23>N N4!&%S#%%!&9a%4#!"%P\3
t2o&t9mw\qulÐS(to"tÉ2nl[wpÏÐ<f2no[m2o&np<tZ!\>>4#!&%-P\3	%*&!W#;.·%-P%97;a**W%%-,4!&4
2#K23(2a%S94%23(4K:F3(-PYC7_¡5)53(/23!W#)3623-O]^#¨53(P6>
?£#)3623NKO!W#O94!&%r<!W#=P	5<_,#Í7G`_¡5)!W#;3!&#§,-`3(%:3(!&36%*&/%
M947G_¡5L%95G235<%!&!&#E2*&2*W%#E94{5<_,#¹##!&#E9<7*"2<12a*"2*W%2>
 N4%O2*&2*&!N3(/23(D+!W5G3(9<#%!W#:4D3(O947%!"%cP\3<#D+4!&;4<_¡5G23£P¥3#K94:_
3(2«53(/23(%2>CÃ3·!W#%9#Z	:4.7_¡5=536V/<23(%.ÑÒÓÔÔ x  !&2#74¦`*\>WZ-|2}}<~#
<#*0P x  <O2Z|}}94Q,236`O%N%9%%(P*b!I#¨3(2#<53(/!W#;K5!"!"#%25*&VD
%95G235%!"!"#B#¦3(23(=53<O*W!"#gZ36%95!&/*&D>K N4##!&#È97*&2¨2*&2*W%
x 3!&%36%93(!&!&#{O*g*&!WO!W#!&#c!&%*&%C94S7%!&%QP¥3/236D%9%%(P*b5<_,#K53(/23(%2Z
>;>ºZÑÕÖ×ÕØ x¥y <%23O.*\>WZ|}}O3 y XT NXÎcÙ x c%934<#LÚzg/*W#Z|2}<}|2>E?#¹3
5!W#!&#{94#25%c!W#:3({P\3%95235%!&!&#¨#{94##!&#{9<7*"2<)2*&2*W%2#
3:423T2a%!&*"D¨793#%(P\233()O9423Q7_¡5)#)5<_V,c#K2*&2*"!\>NÁQ2#Z944!&SP
94%(,-O2*&2*&!	%93(*&D)!&%	Û6%!0]>
Ü9Ý2Þ

ß

¨àáJ¦âù ý ã  áJÂ++uMä'++'å

 ý +x+~+

ý

â'z+++Äæ;ç+µ{

 Q4S3(!&*&S!&%N36;#!&%P\*&*&V,Q%2>  %:3(-,N!&94)73(!&:PT/23(/!&,EP%:5235G%!&!&#¨#
 **&!I­!I#a!&# x !&#Ê<> y 3(/23Z,-!&%2%%-%:3(2#;94%T#C,2<r#%%%	P^94Q2*&2*"!
O
!W#¨O3(9!&*<#+!W#:3(C3N553(4P¥3NO7!W#!W#;)94O%93(2#;<94%NP7G94)2a*"2*&!\>S?£#
!&#Kèc,-3(%%:F%	P94N!W#<;3!"#SaP y X¨%:7;**W%%-!W#<S94Q%23(4%9-P
C%95235G%!&!&#<_¡7%¸53(/23>Ãg3(9423­3(Z[,O%236!I7G(,-./3(!W#<%aPK3(*&/V#D<_¡7%
]*&23(!W#;P%97;a**W%%2>	!&#N2*&%	,N!&94·94%TP7_¡5·;2#23*&2C%2>  
!&%2%%c!W#+:!&*94S7!&*&!&¡D{P	94S53(*W%%!W#)3(23-.4*W5{23(2%S53(aP*&2#;94%
P\336:P!W#;+K;!&/2#{%aPT*I<%%`%,-*&*	%)3(3(23c94O%2<3(4§%95O!W#=#¨553(53(!W
##23>S-%¨#):4!"%!&%2%%!&#gZb,!W#936%/23*	3(*&/V#D=O2a%93(%2>S?£#¨!&#=ÀZ
#K523(!WO2#<9*¾%9D#+,N!&94K944!&;4<_¡523¡P¥3#S:43(2R53(/23(%ÑÕÖ×ÕØM#
ÑÒÓÔÔ.3(/<2*&%S94.5G2#<!W*TaP34#!&%2>  .4/O4<%2#=:4%%D%2O%!W#=3623
%94,Ì:4S3·#252#È2%!&*&D¸7G.!W#<;3B!W#<+!&%!W#;=%D%2O%O#M!"%O/2#M7*&)
!W53(/#)94O523£P\3C#SPT/<23(D5G,23¡P*536V/<23(%2>-Ã	!W#*&*&DZg!I#¨!&#¨~K#)/236/!&,$P
3(*W¨553(a4%-P\35<_,#Í<7_¡5K!W#;3!&#K#*I%:4S3(!&*&>
À
ê3ÅÆgì$íî.ñÅïð95Å¦ñ.
Tòó 	ôõ òYö÷=Gî 
é ë
Æ

 Äø)¶ÄnÄìAöù=òJúÔÅûbíÅÃ

?#¦94CP¥<*"*&,N!W#;Z	,-!W#<93()(D5!&2*-3(253(%2#<9!&/%OPN5<_V,c#=#L7_¡5¦2*&2*"!
#!&%2%%N94!W3	%:3(2#;94%-#.,-2r#%%%!W#9a!"*\>	QP\23	94a2Z,-N%9r4O947%!&%P3
O94*&;DK!W#)3623-O7!W#S:4%2*&2*&!¥>
üývþÌÿ q Â³	
sHl?lãjCjxs;q+lHtjj>³>²"!#j j H³j
 N4;2#23*5367*&2©!I#§]^3(%(_3(23-:43(2©53(/!W#;!&%%:4V,J94S!W##%!&%2#DaPYC%"$
P*W%%2>Y*W%!&%·%TaP*&!&23a*"%>	%-*W3(2D!&%2%%Z943(2Ë53(/23(%T%9*&*&D)!&*"!&
!&9423Q5<_,#K3-7<_¡5K2a*"2*&!bP\3-5*&!&%94!W#;+:4!"%Q9%9r[>
 D5!&2*&*"DZ7G_¡5¨2*&2*W%#<9!W#%O%/23a*	!I#<P\23(2#¨3*&%`,c4!"4¦2#B7G<55*"!&
¨)%P*W%%O94aS#%!":94K%23(4¨%:>)c2#23*&*&DZ	94!W#<P\23(2#+3*&%O2#=7G
!&/!&!I#<¨(,-)*Ia%%%2d&%('hnlqvflM!I#<P\23(2#¨3*&%­5G23O!&94K;2#23a!&#=aPQ#,R*W%%
#¨m9f<lw\(nm2w\qvfl)!W#<P\23(2#`3*"%Q*"*I<%%N3-3(25*W942R7<D94236%2>	 N4SO%-55*W3
7<_¡5K2a*"2*W%!&%N94(tfo&pw\quf<l2*&2*W% x Ù7!W#%#gZ|2}~À<> N4236Z945#%!&#+3*"%
3(¨3(%*W!&#E#¹Pa3(!W#;>$ N4¨3(%*W!&#2*&2*W%+2<#17¨2#E,N!&94L#93!&#
3*&%2Z¾>;>[94*&!&#¦PT9<*"<;!&%2>`?¥PN*&!&(D¨!"%!W#</*&/=!W#=)5367*&2 !&S!&%%2#%!W7*&)
25*&D94N%:5235G%!&!&#K2*&2*W% x -4!W3T¤<#!I#;<23Z|2}<}Z,4!&42#%N3(%<*I!"#
,N!&94O%:5!0]S3*&%T%9!&9<7*"QP\3T4#*&!W#;Oa!&#%2>T N4Q5#%!"#3*&%-P^94Q%95235G%!&!&#
2*&2*W%<3(.%:5235G%!&!&#gZ-*&!"(DL3(%*W!&#gZ-#Ma*"!&(D¦P3(!W#;>¨c;!W#gZa!"!"#*
#<93!"#3*"%O%94=%9<*"<;D+*&!&#gZ	%:7%95!&#gZb#2#%!W#;Z	#M3(,3(!&!W#;¨2#
7¨25*&D>R?\)!&%)L7=2C54%!&$94CP\33K%9D1,-{25*&VDE94{/23(%!&#PO94
%95G235%!"!"#$2*&2*W%¨!W#936Â7<D-4!W3)#H#!W#;23 x |}}>H5!0]2*&*WDH94!&%
2#<9!&*&%94aTP3(!W#;!&%#*&D+55*&!&¨5%!"!"/<S*&!&23*&%2>
E7_¡594362Ä53(/23	%9*&*&D.!W#<9!W#%T%*),++Pg%_2*&*&Ohfw\t2l[w\quno[3¾hn9qvÉ2t
m2o&np<tP3(U,4!&4{!"%*"%`#=3(2O/%c#*I<%,-@C!WO>S N4!&%*W%!&%S5!W#<
94%#)/.BPNnmw\quÉnw\t9j)mo&npt>-!&/¨*W%%3(Zg#*"!WrK52#<!W**W%%2Z*&*&V,-¨
53(#,Ä*I<%%/!WK9455*&!&2!&#ÈPT%O!W#<P¥23(2#K3*&%2> N4O!I#<P\233(=#,Ä*W%%
3(5-!W#0),+->	?#!&!W*&*&DZ),.132S#4),+516$T>	 N4!W#23O!W#!&%!&O%*&!&#K3cnmw\quÉnw\quf<l
Ü9ÝÜ

µ

¶ µ

wyz{

wyz{

 w\t(h!&%3(2*&!&7<D4236!"%!&­­2#%2>T ¾94!&%N2#Zg423(!&%!&07@%%!W%O#93*#`7G23
8:9<; ? Å ,N!&94M24=- ; ),+TZ-#L944- ; ),+$,N!&94M94)%:*&*&%.,-!&;4< 8:9 !&%%*&>
#+!W5G3(9<#53(5G23((D)P423(!&%!"%!&%94!W3?>nqv:lt:>N¢4236!"%!&!&%2*&*"¦P!W3N!0P!&%*&%
5<2#!Ia**W%%!W#+%:4¨)##23c:4#K*W%.362!W#%S5%%!&/O!W#<]^#!&*&D=*&#;>A@Q%9*&*&D
94·P!W3#%%PT94`%È4236!"%!&!W5*&!"%O94aN9453(/23-!&%5*&Zg!\>>g!&c2#{23(!&/O94
25(D*W%,c42#K79!W#!W#;.#K!W##%!&%2#N!W#5c% x 53(/!"):4#23(*&D!W#;.2*&2*W%c!"%
5*&2>
 Q4a!I#C%9362#;94CP7<_¡5­2*&2*"!	#)53(/23(%!"%Q94!W3T%93(#;O3(##D)#<93(*\>
Î#¨94C#.4#Z	#<D+!W#<P\23(2#%O,4!&4M3(O:]^#!&*&DL##%%93(D¨!W#M+53(PZg>;>g!W#<P¥23¡_
2#%-!W#/<*"/!W#;O9*&;<!"%Z3(-­!">TÎ#O94Q9423T4<#Z#<93!"#O!W#<P¥23(2#3*&%-*&!Ira
%97%9C5!&#=/!&=943(25G!&!&#¦P5#%!&#¨!W#<P\23(2#%O!W#/<*"/!W#;¨94O%9O x 3­3(O!W#<_
%9<#!W*W%%>E7!&;!"%:/V#<9;<aP^7_¡52*&2*&!!&%	94!W3b*Wr·P;a*Æ_3(!&2#9a!&#g>
2%23(9!W#)!W#<P\23(2#%S3(cP/3(K/239423(%QS:4c]{%23(4K%93a;D.#{94
423(!&%!&,-!&;4<aP94c*I<%%N53(-P!&2Z!"cO!&;4-794c2%c94YP¥3·/23(D*&#;O!WOc#*&D
*W%%c,4!&4{3(S#c53(-PT#D)53(PT3(2#O23>
y **&!WO!W#!&#¦!&%S(D5!&2*	5<_,#§2*&2*I%,4!&4È,%94*&*	!W#:3(O!W#¨94P\3
P94Sm:fl[lt:m2w\qvfl.w\nÏo&t9n<pm9n<o"mpo&p< x -ABC-O x zgQ*\>WZ[|2}}>?#C3(23YS!W#<93(#-DBC-$,-
,N#<T%93(	,Q!":4947%!& x P3(/3(!W7*&297*&2K2*&2*W% x >;>WZÃ	!&!W#;Zg|2}}<~¾P¥3T*W%%2>
Ä97*&2EBJP¥3?$B!&%S:3(S,4<%`##<_¡36c#%S36S*W7*&=,Q!":4+*&!&23a*"%S<#+94QP*Æ]*&*&%
94)#!&!&#gd¨?vP94{!ICO!W+%:%%3#%GF #IHIJJIJKH FL=P=#F¦P#B©3()*W7*&
,N!&94C*&!"23*&%#M #IHIJIJJNH MLZ942#K:4*W%DOPM #QHJIJJKH MLR x w\nÏo&t:np.mo&npt9Y!&%<#!W#%9<#PS*W%
!W#5$T>?£#¨949<7*"2<¨2*&2*W%(,)!W#<P\23(2#)3*&%­<3(%Z	#O*&D¨94+t'hnlGqvfl+<#=94
(t9j<pmw\quflK3*& x >;>WZÃ	!&!W#;Zb|2}}~>#+55*&!&2!&#{P	94S5#%!&#{3*&`O2<#%N%*&!W#;+
*W%OP3(S$1#Ba94!W#;)94*&!&23*&%OPK/3(!W#<SP-!&S+{pÏ£ÐfnoT,4!&4¨!&%`§*"!&23*
-94*&2P	PT#+fht2lK73#4 x O73#4K94-%#-#<9!W#K(,OC5*"2­2#9<3(D*&!&23*&%9>
 b7*&2)3(!&#§*"<%%O73#4)7DK#!ÆP\D!I#;)%97;a*T·,N!&94K94c5*&2O2#<NPT*"!&23*
U x 2#.7<D,V U b#O94-%9<O73#4gZ<#.55*&D!W#;O94-%97%!":!&#94N,4*&N:7*&2g>
»##!&#{97*&2{2*&2*&!-,3rK#)##=97*&2g>Ä97*&2¨!&%2*&*&m:fl[lt:m2w\t:j
3=m:fll[t9mw\quflMw\nÏo"t:npK!0P24=!W##23#4F x ##<_*&2P#2S,c4!"4¦!"%O*W7G*",N!&94¦*"!&23*
MN4%O)*&2P#4FXW	O#;{!&%S!WO!W)%9%%3#%O94a!"%O*W7G*",N!&94=§*"!&23*CMYW
5*&2O2#<936DZM(>b N4T!W#<P\23(2#3*&%T36Nw\n9w\Zt['Vw\tlqufl[Z2#)(t9j<pmw\qufl[> N4%9363*&-!"%
*&,ND%94N]^36%-!I#<P\23(2#%25P	S236!"/!&#g>T?N523O!&%cS:7*&25#%!&#K:4T2#C#*&D
755*&!&+O936!"/!W*g97*&2gZ!\>>#c#%!&%!W#;OP#*&D.##> Å N94aT94c%936T3*&
2#¨73(%93(!&¨K%_2*&*&Lw\n9w-(t2o&tÉ2nl[w-*I<%%,N!&942%!I#;)!W#C5*"2#%%2>O93(
3(*&/V<#DBP+*W%.!&%:]^#1%P\*&*&V,Q%2>?¥PC$!&%#M#%9!&%(]^<7*"{%SaP*W%%2Z	,-K2*&*
\ ; $+%93(-3(*&/V#<-!ÆP	9423(c!&%N%9!"%6]^7*&%97%?$ W] $+%:4K94a*$ W_^ OP\"R!&%N#%9!&%(]^<7*">
!W#94c%TP	#;!&/c*W%%-#<9!W#%NT*&2%-#c%9<3(T3(*&/V#<-*W%Z,-*&%O#%!"23
S36%93(!&K2*&2*W%N,4!&4C#*&D25*&D%#;!&/c*I<%%P¥3Y94N%:3(T5#%!&# x -DBC-a`Ibdc2>
 N4¨3(!&#E3*&¨!"%):4+%9­%K!W#L94¨#</2#<!&#*N9<7*"2<12a*"2*W%2>ÄXY2#%!"#1!&%)
O7!W#!&#¦PN5<#%!&#L#L3(!&#g>¨?\O!&%­5G23£P\3OL7D¨%*&!W#;B{%97;<*(TK!W#M94
97*&2EBSZg55*&D!I#;¨#)5#%!&#{%25+eT<Z^#¨!WO!W*"D=5G23£P¥3O!W#;+.36!&#{%25
,N!&94=T)#M#.aP!&%#,N*&D=2362M%9%%36%2> Å 94aS!W#M94.362+aPQÁQ3#È*I<%%!&
!&%%:<¬.!&2#cO25*&D)%93(N#)2#%!&#gZ[!\>>94S36!&#)!W#<P\23(2#O!"%##%%9<3(D x >;>ºZ
##!"Rz<#;25Z|2}}>N N4%2Zg,-­a%%9O94c,%O/236%!&#%aPf-ABg-¢3C-DBC-a`Ibdc
94-)#-25*&D+3(!&#)%25%N!W#)94O3(2PTÁN3#K*W%%2>
Ü9ÝIh

ß

¨àáJ¦âù ý ã  áJÂ++uMä'++'å

 ý +x+~+

ý

â'z+++Äæ;ç+µ{

-DBC-13-DBC-a`Ibdc-#<T42/<T%95G!Æ]Q!I#<P\23(2#3*"%bP\3b4#*&!W#;`*&!&(D>?£#%2Z,c42#
2*&!W#;=,N!&94¨*&!&(DZ	94.!&!"2a!&#=O%`7G.2#L7D¨94K3(ji!&/!&¡DZY%DCO93(DZ
93<#%!&!&/!&(DZ#%97%!&9!"#!"O%	P94-*&!"(D%DO7G*\>?£#Z94N%-P^#O!"!&
P\3ÄaPa*"!&(DK!"%-!W#)#O%2#%c5!W*\>T--!&N!&%-/23(D!0¬.2*&NO/*&5)­94%P\3T%!I#;
7!&*&(_!W#¨a*"!&(D)!W#)9<7*"2<K2*&2*"!	:4-D!&*&¨#/!W#!W#;+3(%9*&%N!W#+53!&>
?¥P%97;*Tc7­% x P¥23	%­N!W#<P¥23(2#%:42a.P·*"<% x %97<_¡(:7*&2O,-N2*&*g94
79a!I#{%97%!&9!"#+Kfo&pw\qvflCP:T>
 Q4#!&#Pc97*&2­23(!&/V!&#K#.·%23(493(N!&%!IC53(:#d  N%:2DDBlk4B W !0P x #
#*&D!0PY97*&20BCW2<#7c23(!&/CP3(mB7<D55*&D!W#;%93(T3*&c!0PnB1!&%T:4936!"/!W*:7*&2gZ
37D#C2#%!&#Í3(!&#K3*&S·%97;*[!W#,BS>	 N4c##!&#C97*&2C2*&2*W%N!&%N#
x 53(Pb#oi^2#2>	?£#3623	%94,94#%9!"%6]^7!&*"!&(DKPc*I<%%*$TZ·%23(493(Z;<!"/<2#
%-P\*&*&,N%2Z4%c.7GSO!W#+!W#¨p>nqvO,D x 24)#OP	9493(O`%7/!&%!&=P\23-
]^#!&O#<-PT!WO2N#<!&*	O*&%¨97*&2§23(%>TRt9n<¡m[qw\(t:t#r¤:]^#È7<D+O2*&2*W%
#.·%	Pg*I<%%?$!&%-;!&/2#7<Dc93(N,4<%3(	!&%T*W7G*"),Q!":4O94N936!"/!W*:7*&2g>	X	/23(D
!W##23#.!W#sr *I<7*&1,N!&94¦97*&2tBU4%`a%`!W­!Ia.%:%%3(%O94)#%SP3( 94
!W*%aOPF #QHJIJJKH FLRZ,4236uFv!&%N*W7G*&=,N!&94wBv<#xBlkwBv¡Z¾|aylz*yl{b>
!W#S##*&D94#O723P53(P7Û(%7N*&%O94!W3%!&c!I#2362%%-3(!W#;94536P
53(%%2Z-5*&!"!&)9<7*"2<L2#O23!&#15363(%K94C#%93K*&*9<7*"2<L!I#6r«!I#
73(2:4<_\]^3(%	##23b3(#<3(2a%#7*&>	ÁN2#Z!W5*&!&!&T2#O23!"#`5363(%	:455*&D
m:flt9mpw\qvÉ2tod|Ïfpljt:jSqvw\t2(nw\qvÉ2tcjt:t(htlqvlÐct:n(mqSk	qvwYqCÏnm[}Vw\(nm}qulÐ x~ 3£PZ|}Àb3(-#3*&*&D
%>T?£#:4!"%N55364O!&23!&/*&D*W36;23b]^#!&c!W#!"!Ia*53(%P^:4%2<3(4­93(#rÄ36N5*&36
,N!&94¦2594<_\]^3(%%23(4g>)Ë]^#!&K%;O2#<S!&%#3a*"*&D=:]^#17<D=)%a_2*&*"$m:fsQh^o&t2w\tlt9
Ïfpl[j x ,c4!"4)5<%%-%9393*^3(%93(!&!&#%-#C94:7*&2,4!&4)3(*&*&,-.!W#K94c233(2#<
%;­2#2Z[%7*&,c#=O]=#93a*#O723Zg%_2*&*&1(tfp(m:t>c?\23!&/O252#!W#;
!&%.523¡P¥3O17D¦%93(!I#;¨,N!&94L¨7%!"+36%3(K/V*W5{ ; ? Å #L!&23!&/*&DB!W#23(2a%!W#;{
#<!&*+536P-!&%P\#B,Q!":4!I#¦94O]^#!&C!I#!&!W*-%;O2#Pr :]^#L7D¨#.7G#L#{b>
 36O!W#2#O5*&%P¥3S5*&2#%%.7G#%3(K94j<t(h^wYq¸ÏfpljZ-qvl>t2(t2l[m9t)Ïfpl[jZ	#
k	t2q&Ðqw\t9ji(jt(hgwYqÏfplj<>
 Q4N2594)7#.*&!WO!&%N94!W*[2594aP!W##23#% x ##<_*"2VP#%:T!W#K97*&2
,423(:4233(2#<3(%36A{¨!&%N94S!W*25:4)523O!& x 94S36N#`4%-2594{¼>
?#¦53!&Zb942594¦7#M!&%S!".%9%%(P* x zgCS*\>WZT|2}<}½Ác336!"%#gZT|2}<}~c7S!&
%9<F23(%¾P36$:4*W36;T!W#23(2%NP94%;O2#< x :]^#7DO36%3(C{g2<%7DO#!W#23(2%
Pn{b>	 N4N!W#<P¥2362#S7#)*&*&V,Q%c*&/*7DO*&/*[5*&3a!&#OP94N%23(4O93( x >;[>WZ!&ra*¥Z
|2}<>?£#)C53(!&%#K,N!&94K:42594+7G#Z94!W#<P\23(2#7#¨r%NO%9­:4!W#23(2%
PT94O%2<3(4{%95a­5G%%!W7*&Z	7!&!"%!W#<P¥23(!&3c)94O2594¨7#=!W#=53!&>S?#È3(23c
O7!W#94/#:;%cPT94O2594=#¨94O!W#<P\23(2#.7#Z94O,-!&;4_2594=7#
,N%	!W#:3()7<D y %23bT*\> x |2}<}> N4!&%N7#%23(!W7%cc*Ia%%TP5G%%!W7*&7G#%-94
3(%:3(!&N9497*&2§2594+<#)94S#O7G23NP	!W#<P¥2362#%*&*&,-+!W#<P\23%95G!0]`:7*&2g>
c*0_3(!&2#<9!&#caP-ABC-KZV%¾3(D5!&2*5<_,#·2*&2*W%2Z!&%b;!&/2#O7D94###%%
#!&!&#g>- N4!&%-#!&!&#K2#:!&*"%Q94T/<23(D*&!&23*g!W#)97*&2K723(%N3(*W!&#K94%93(
*W%>S Q4`%P5%%!W7*"C%93(c*W%%2#¨#3*&*&D7K3(%93(!&¨K!"­K%:*&*%P
*W%%O,4!&4B36%9<¬.!&2#<!W#=3623{;3#<O5*&2#%% x >;>ºZ y <%23O*\>WZ-|2}}Z
>;>:4%	P#;!&/-*W%%-%*W3(2aD`O2#<!&#>T N4%2Z<#*&D`2369!W#O%2##<%-42/!W#;
##!&#§S%93( x ;*W*W%O3(c2#O23>	ÂC!W#)53(7*&2RPT53(P¥%-,N!&94w-DBC-

Ü9ÝI

µ

¶ µ

wyz{

wyz{

TD

CTD

TD

BU

CBU

BU

C

Ã	!&;3(|d»-523!"#)7(,-2#)O5<_,#)#+C7_¡5)53(/23
!&%-94T!W#K;2#23*94D363a9423	*&#;>	?£#CPZX-ABg-Â!&%NO#;94N,-2r%T2*&2*&!,42#C94
*&2#;94%NaP!&%!W#;.53(P\%3(c#%!&23(>- N423(:P\3(ZzN*\> x |2}}aT53(5%)2#%!&#%
P(-DBC-Ì,4!&4¨3(`7a%+#{#936*&*"¨!W#<;3!"#)PT94Km2pw-9po&t>c N4%O2#%!&#%2#
*&%+7G%2#¨%S3(%:3(!&¨*"2C)O4#!&%9O%2>ÄP3(942353(7*"2 !&%94cP¥2#+36!I#;{94
%2364M9<7*"2<B,N!&94¹94)%9­.3­%97%9O%97;*&%23K3(252*"D> N423(<3(.%O
2#%!&#%cP:42*&2*I%O53(5G%)/236O%94)53(7*&2O%2>-XN>;>WZ7D)zg*\> x |2}}
K3(%93(!&{%97%95!"#+#25S#7<D)%934#+<#!&r* x |2}}Ê24!W#;)4#!&%
4/S72#§!W#936>
üýWüRÿ

rµs5jãjsDl³js?l	;l5rttj

³3q

ÿ q 5³j

Î 3K553(4¦P!W#<;3a!W#;=5<_,#L#17G_¡5L53(/23(%.7<DM5G23!&#M!&%K4<3:_

23(!&17<D=hg¡t6h^(f2m:t:qvlÐ¨#Eqvlh^pwSnpÐsOtlw\nw\qvfl>=ÁQ2#:P\3(94gZ*&A$$7)94)!W#!&!W*N*W%
%O,4%!W##%!&%2#DL%94*"L7)%:4V,c#g>+?#¦94)53(253(%%!W#;B54%K94)7_¡5¦%9<_
5235%!&!&#E53(/23;2#23%.¨%`aP*W%%/$:J%94M940$ 1$*T>M#*&;%*&DZ-,-
93cP3(©K23(9!W#=#O723·P53(PN25%P-94 y X$53(/23K*W%%p$	Â%94
94$ 1$  >+ N42#gZb94K!W#5%a$1aP:4.%95G235<%!&!&#L53(/23!&%;­2#M7D5$  Z
#)94!W#5cP	94 y X153(/23,N!&94/$:>	QP¥23T:4N794{53(/23(%-2#)53(+`,-3rO!W#
53a*"*&*\>Ã	!";3(|c!"%:5*ID%N94!&%r<!W#+P5G23!&#K94a!&%N%%2#!Ia*"*&D)7%)#)%2#<!W*
#22#!&#)aPY7G94+536V/<23(%2>T N4O553(a4§2#+7GS%2#{%C%95!0]O!W#%9#<!W!&#{P	94
;2#23a*523!"#)553(4) NX»NÁ x ¿2#!I#;<23¤Ã^4%2Z|2}}<>
!W#O94%95235G%!&!&#=536V/<23N,-3r<%N#{%23(4)%9a,4!&4{#<9!W#%%PT*W%%2Z
!&S!&%O/23(D¨2%D¨);<2#23.§%SaP/*&!&B*W%%O!W#M+53(253(%%!W#;=54%>KU/<23(D+%!W5*&
O94S!&%b523£P\3$]`#`7G23nz[P!&/!&#%25%	#SN;2#23	94T*W%-%%),. v
#5) + v aP!&/#5a%%!&/O*W%%2>S Q42#gZg,O%*&S*&*>nm2wvZ[!¥>>5%!&!&/#!&S*W%%2Z
P3() . v >H!W#=94¨!W#<P¥23(2#%{PS=%95G235<%!&!&#<_¡7%Ä53(/23K3(+%#ZN!&)53(%
#*&DL*&;!&+#%2#%)aPC$T>L%C,)%:4*&*5*W!W#1!W#!&#L=!W#O3()9a!"*\Z-!&K!"%K#
%2#%!W7*&K=*&*;2#235<%!&!&/#!"%94O!W#5P	94S5<_V,c#+53(/23ZG!¥>>C%
$ : 1OI-Úd-Ë!&%P H - ; ) . v R>+ÁQ,-/23Z!&O!&%O,N!&%.+%*&#*&D=%O.#!&%O,N!&94M
P#!&#x*	Z!\>>$	*x13: x OI-Ìd-Ì!&%P H - ; )/. v RV>
2%##!&#:7*&2<_¡7%.536V/<23(%4/NQ%23(4%9T,4!&4O#<9!W#%T!&#%
x 9<7*"2<!W#%2MP*W%%2Z	!&O!"%K]^3(%`%!";4#7/!&%4,¢+93O/Va*"!&L*W%%
P3( %94=%23(4L%9a+,4!&4,N!&*"*S7G¨,*&*0_%9!&EP\3K=%:5235G%!&!&#<_¡7%H53(/23>$
Ü9Ý

ß

¨àáJ¦âù ý ã  áJÂ++uMä'++'å

 ý +x+~+

ý

â'z+++Äæ;ç+µ{

­#¨O94!W#¨3(23c)93c/V*&!&M*I<%%S!&%)25*&D¨*&2)O4#!&%9O%P y X
53(/23(%>Tc%%9O94O*&!&23**TO!&%C*W7*bPT94O3(#`aPYC*&%¨%9797*&2&B#>Nzg
M #QHJIJIJH ML­7G94c*"!&23*&%94a3(%)!W#+36!&#K%25%P\3*"<%!W#;,B  #):436%!&
P*B#>- N42#gZ[94*W%wOPVT H VM #QHJIJJKH VMLR`C2D)723(!&/a%.#,J*"2C x %!W#`!&N!&%
*&;!&2*b#%2#PT9497*&2§*I<%%!W#xB  >N4¨*&2C*&=7O93#%(P\233(+.
7<_¡5{53(/23>-c%S552a*"!W#;¨%:4!"%c!&2K%#%2Zg!&4%%­S%/236`3(%:3(!&!&#%2dN4
*&2%%9*&*&D<3(Z>;>O!W#%9<#!W!"#%,4!&4{,236`53(/!&%*&D#¨K*&%S<9423
73#4%2Zg#%Q;2#23*a%94DK*&=7>NÁQ2#ZaP¥2#§94DK2##7`%+!W#{!I#<P\23(2#%2Z
#O%95G!Ia*"*&D#b!W#O#<93!W#;N!W#<P\23(2#%T,c4!"4O3(/23(D!W53(9#<P\3b7_¡553(/23(%2>
!W#94%C*I<%%S3(O;2#23a¨3(!W#;)9453(aP3#{!W#=K39423#%D%2C!&O,D)94D
`#<362*&*"DC!I#<93(SO4­;*0_3(!&2#<9!&#K#)42##-rc%aP:4/#<9;%
P	94%2364K%42O¡D5!&2*gP\3 y XN>
 Q4S#25PT%:7;*b*W%%S523O!&%94O;2#23!"#)PT*W%%23(!&/=7D)!W#<P\23(2#%
!W#/<*&/!W#;)53(P;<*\d
iwof5jj

üývþ tbq³rX³^q¶t[ 'tbq³$rX³^q5t [t ¡¢

|<>NzgC$L7%PT*W%%2Zg*&aB 7G­C97*&2§P\3$Y>QRpÏ£Ðf2n<omo"n<pt,\  3(;3(!W#;wB
!"%Q94*W%u\x1OM #HIJJIJKH MLRZ,423(:4*"!&23*&%ZMv3(c94%97;<*&%NP:49<7*"2<wBS>
ÊG>Nzg#£R7O7#Z{ ; ? Å 7O3(%3(Z#w$B7OO%NaP*W%%2>
?vP-ABC-E!&%N%Z:4pÏ£Ðf2n<om2o&np<tQtw¤   L  ¥,S>Æ3>>P£KZX{bZ#¦$YZ<!&%T:]^#)7DD¤   L  ¥u1
OP\LdBH!"%O:7*&2{!I#È94O!I#!&!W*	%;O2#<PT94O%23(4):3(P¥3$¸#5-DBC-R94c!"%
:]^#7<De£R#5{R"§?$T>
?vP-DBC-a`Ibdc-!&%	!W#%Z94cpÏ£Ðfnomo&nptQtw¤ `I bdc L  ¥ !"%94-%¤ `I b¨c L  ¥ 1OP\d\ ; ¤   L  ¥ Z
94%9365#%!&#§P*B$!&%523£P\3­+,N!&94)#;!&/S*W%R>
Å Q94-%97;a**W%%<3(N/Va*"!&{*I<%%2Z!\>>*&;!&2*g#%2#%NPb94!W#!&!W**W%
%2> N4cP¥<*"*&,N!W#;KC5*"!&*"*W%:3%c3N#!"#)P%:7;**W%%2>
! ©5³ª ü¾ývþ zg"$x1OXO«¬R H OP«­ #KHIJJIJKH «­L H ¬R H OP«*® #KHIJJIJKH «*®j¯ H ¬RXR>b N42#gZOP«­ #IHIJJIJNH «­LR
g
!&%T94Q%97;**W%a\  7*&#;<!I#;O:4N97*&2O79!W#,42#O2#!W#;O94-;*«¬,N!&94
94*I<%4OP«­ #HIJJIJKH «­L H ¬R>-?vP-,-S25*&Dx°l1H!W#<P\23(2#7# x²± l>c#=3(%36u³41ÄÊZ
942#&¤f´ µ ¥A1¤f`I´bd c µ[ ¥ 1OXOP«­ #IHJIJJ¶H «­LR H OP«*® #HIJIJJKH «*®j¯RXR>

 %97;*[*W%A\¨3(253(%2#<%N93#%(P\3C!&#P#C3(!&;!W#*g;**W% x ,4!&4C!&%N94
J
%9<3(O*I<%)P94)97*&2=B!W#<B#,U%97;<*&%.3(2*&!&$7DM94)!&#¹,4!&4¹*&1
94O97*&2EBS> N4O%p¤f· `¹¸  µ[ ¥!&%94O%cP*&*T5G%%!W7*&;a*93#%(P\3!"#%N!W#)%:7;*
*W%%,N!&94!W#G³O!W#<P\23(2#%-!0P,-N#%!&23Nnovoqvlh^pwbm2o&np<tS7G;<**I<%%2Z94-%(¤ `I· `¹b¨¸c  µ ¥
!&%:4%aPY*&*5G%%!W7*&O;*g93#%(P\3!"#%!W#<K%97;*g*W%%c,N!&94!W#5³K!W#<P¥23(2#%!0PT,-
#*&D¨#%!&23wYqt.l[t¡Ð<nw\quÉtm2o&np<tO7G;a**W%%2> y 3(a*&DZ¤f· `¹¸  µ ¥+!&%94O*&%936
PN*&* x ;*WQ*W%%S,>Æ3>2> x O]B#O723a³{PQ2#%!&#=#=3(!&#È%25%2Z¤ `I· `¹bd¸c  µ[ ¥ !"%
94*&%936SPT*&*#;!"/< x ;*W-*W%%,S>03>2>³K2#%!"#+#¨3(!&#)%25%2>
?£#K3(23-5*&`# y XL#¨%95235G%!&!&#¨53(/23Z,-;2#23a!W#)94S53(2536%%!I#;
54%,Q!":4)94!W#<P\23(2#`7G##+`]¨3(%3(A³wº$|·!":423N94%C¤f· `¹¸  µ ¥.3T:4%
Ü9ÝI»

µ

¶ µ

wyz{

wyz{

¤ `I· ¹` db ¸c  µ[ ¥ Z25G2#!W#;=#¦,49423a-DBC-©3p-ABC-`Ib¨cK!&%%>)?\O!&%#%2#%!W7*&+)%a$¼1
¤f· `¹¸  µ[ ¥+3p$m1<¤"`I· `¹bd¸c  µ[ ¥ #=;­2#94C!I#5OPN94K7_¡5=53(/237D¨94!&%%
x %c!&#.è<>	 N4%Z,-%;!W#]*&23YP#!&#wMP\3b%*&!W#;%ON%97;<**W%%2>
 N4Q!"%Z$	13 x ¤f· `¹¸  µ ¥"½s¤"· `¹¸  µ ¥.3*$s1 x ¤"`I· `¹bdc¸  µ[ ¥ "½s¤f`I· `¹bd¸c  µ[ ¥ >
Ã	!W#*&*&DZ	,-O,N#)5*W!W#L4,Ä3S­94'$53(253(%%!W#;=#B;O2#:!&#{PN94
!W#5NP9453(/23(%('E!&%T!W#+,-*&*0_%9!&KP¥3T/236O!W#;S94c!&%9/#:;%-P9453(/23(%2>
 %93(-,N!&94K:45<_,#)53(/23>*@Q%9*&*&D)94S*W%%C$:È;2#23+7<D+%95235%!0_
!&#{53(/23-3(!"S;2#23a*72%`%:5!W*&!&=*W%%3(*&!WO!W#B7<D.%:7%95!&#§3
3(,36!"!I#;[>T?\N!&%42#S!&`53(77*&S94-94DK2#KP\2#)7G`%KP\3-*&%!W#;K52#{73#4%
PN97*&2¦2#O23L7DB§5<_,#=536V/<23k	qvwYqfpwSqvlw\nlw\qvnw\qvlÐ{wYqt)w\nÏo&t:npo'V>¨?vP%94
Kr!W#=P-*&2)4!W#; x >;[>WZ?\,N#Zb|2}}<N!&%S5G%%!W7*&.,-O3(7*&O.*&%.73#4%
,N!&94!W#<93(!W#;È#,Ä%:7;*&%33(!W#;{94.5<%%!W7!&*"!&(D=94a94K3(2!W#!W#;+%97;<*&%
3(K%*&/7*&>B?vPc%97;*&%O,4!&4MP¥2#=23!I#M:7*&2=2#L7G.%<*"/<Z	94K*"2C%.36.
;¨O2#%QP¥3N3(##D¨#<93(*\> y 3(/23Z%!I#O94O%2<3(4K%42OOPTC%95235G%!&!&#
53(/23Q!0F236%P3( 94cP# y XE53(/23Q!"!&%+7O5M94c!&2#{;2#23O*W%%
,N!&94CP\,Â!W#<P\23(2#%c94N2#K*&%`73<#4K,4!&4)*&{#*&D+7S*&%7<D<#D!W#<P\23(2#%
,42#M%!W#;B#¨*&2%2>= Q42#B53(P*&2#;:4%­<3(.3%!&2*&*&D¸36>B)!&#M{P¥3
O369!&*&+%23(!W5!&#{P	94S%P	*"2C%2>
 Q4!W#5	PN%:5235G%!&!&#K53(/23!&%T;O2#`7<DS%97;**W%%T,4!&4`<3(-94N3(%9*&
PT:3#%(P\3a!&#aP#K3(!&;!W#*b;*¾*I<%O!I#<%:7;*&%2>NÁQ2#Zg94S;<*0_3(!&2#<9!&#KP
%95235%!&!&#{53(/23	!&%N!W#23(2a%+!0P!&%%-%94K93<#%(P¥3O;**W%%Q!I#K!&%Q!I#<P\23(2#%2>
!W#S94 y X53(/2325*&VD%O!0F23(2#<N%2364K%42O!&N2#K/<23(D.!&r<*&D)#c23(9!W#
%25%Q94-94S%:5235G%!&!&#+536V/<23-2##36#%93N7G2%SaP!&%4236!"%!&`%23(4g>T N4
%2364CP\3NO53(P	2#)942#)7G`3(>
¾	w¿ 
'Á ô 5Ægóñ.óÆg
'ÃíÃð95Å õ ò	ö÷=Gî "À ø)^ÄxÄìEöù=ò 2 Ä í ô

 

ÅÆÄ

?#M:4!"%C%!&#M,-)<O!W#)94)!W#;3!&#¦P%97;<*-*W%%!W#<=94K!W#5.%OP¨%9<_
5235%!&!&#¦53(/23>NQN]^3(%,-`a%%9OO94*&*b%97;*b*W%%;2#23¨,N!&94!W#¨K23(9!W#
#`7G23cP!W#<P\23(2#%`<3(¨.:4`!W#5%S#¨,-S;!&/%O`36%9*&%S3(;36!I#;+536P
*&2#;94L#M%2364M3(!&#g>¨QP¥2394Z,-K5*W!W#M94)#%%!&(DMPN%*&!W#;B#*&D=%O
%97;*g*I<%%<#+!W#:3((,O%*&!&#{O94%7a%)#K94943(!&!&%2%%!"#g>
Áývþ¼Â 	Nq5rjlÃp?lÃaÄ*xs ³ 3³lxrµsxs5lIñqñsãq³p0³^q5t+t

  45G23!&#=­94¦!I#<93(M!I#È94.53(!W#;¨%!&#¨;<!"/<%`3(!&%)94%!&#¨P
N
,49423O{hg¡ffN>)o"tlÐ<wYqÈ(t:jpm2w\qvfl1!&%.5G%%!W7*&Z!¥>>	,494239423(+<3(.%:43(23·%95235G%!&!&#
53(P\%`aP94)!W##%!"%2#DLPp$ ^ ¤ · `¹¸  µ ¥ 3a$ ^ ¤ `I· `¹b¨c¸  µ ¥ 94<#MP94)!W##%!&%2#DLP#$T>
x Å 94N,-O2%936S94*"2#;<94¨PK53(PfÅR7D)#<!W#;)94O#O723caPT!I#<P\23(2#%25%
ÆÅ,b!W#¹!">ÆU!W#¨%O)!W#<P\23(2#¨%25%.36+#%%93(D¦P\3O2#O23!W#;M%97;a**W%%.,-
%94*&{93(DK]^#+N,c49423-94%!W#<P¥23(2#%2<#)7S%:2/<),42#)%!W#;.:4*I<%%2>
 Q4!"%K%!&#L!&%+a!I#*&DP:43(!&2*c!W#236%.72<%¨!I#;2#23*7<_¡553(/23(%
1#K2#­23=O!W#!W*O53(aP¥%2> y 3(/23ZN7_¡51536V/<23(%%:*&*"DH523£P\3ÇM*&
P##%%93(DL!W#<P\23(2#%2>1?!&%.O3()!W5G3(9<#O=#*&D+,4:423¨7_¡5L53(/23
Ü9ÝIÇ

ß

¨àáJ¦âù ý ã  áJÂ++uMä'++'å

 ý +x+~+

ý

â'z+++Äæ;ç+µ{

2#L7G2#:]P3(«94+%)aP%97;a**W%%!W#L94KP\3«Ph^(f2fN>Kt:n(mqM¡t:jpm2w\qvflZY!¥>>WZ
=3(!"#MP:4+#O723­P!W#<P¥2362#%)94+53(/23O#%!W#L3623O{]^#¨53(P>¸?O!"%
53(!"2*W36*"D)!W#<23(%!I#;K!&2#<!0P¥D):4S2%%QP!W*536P	%2364)3(!"#g>
È ÉÊÉÊ ÑËÌÍØÓnÎ4ÏÎÓËÔ2Õ5ÍbÕÐÕÑ[ÓÖÒvØÐsÓnÒºÓ-DBCÃ	!W3(%*&DZ,-.O!W#+:4)2%K,423(),-)25*&DB2*&2*W%w-ABC-KZ	!\>>	;2#23aG¤ · `¹¸  µ ¥ >  
%%:OP3(:423c94#)*&!&(D¨!"%!W#</*&/=!W#¨:4­5367*&2)Z!\>>g%95G235<%!&!&#=33(%95G#%
 x 3(23(-3(%<*I!"#g>

âsHl

Áývþ

ÔXÕÖ t w$ Ïtn)t2w-fN>SÐ<¡f<pl[j)m2o&np<t`lf<wNm9f<lw\nqvlqvlÐKtj×2pno&quw|ØNo&t2w"Ù¼; Ú $*ØNnl[j)o"tw(³5ºÄ|Ït
n.l[nw\p(no¾lps­Ït2 ÕÖ twÅ # nlj0ÅÛÏtOsOqul[qusOnogo&t2lÐwYq.(tfo&pw\quf<l(t>pw\nw\qvflCh^(f2fN>:n>f?$
nlj$ ^ ¤ · `¹¸  µ ¥ ØT(t£ht:m2w\qvÉ2tod| Õ eqt2lØTquwÜqfo&jIÝaÆÅ # ºÞÆÅ Û  Õ
ß¡Õà <f +t:nmq³º |LwYqt2(tBqºnMt2wOfN>lá£lflGi¥Ð<¡f<pl[jjâBm2o&np<t,$ µ l[fwOm9f<lw\nqvlqvlÐMtj×2pno&quw|
á¹Ù3; Ú $ µ âPØ	pmq)wYqnw-lfKsOqul[qusOnoo&tlÐwYqK¡tf<o"pw\qvfl¨¡t>pw\nw\qvflCh^(f2fN>?>f<?$ µ ^ ¤ · `¹¸  µ[ ¥[ã qW
_qf<9w\twYqnl=nKsOqul[qusOnoo&tlÐwYq)(tfo&pw\qvfl{¡t>pw\nw\qvflKh^(ffN>*>f<"$ µ Õ
ä (ffN>[Ý

|<> Å 94N#OP3(!&2!"#)%25%c3(S#+!W#{942%P;3(#)*W%% x 362*&*94
*I<%%<3(+%%PS*&!&23*&%9>$ Q42#gZ-94+*W!WÇ!&%.:3(!&/!W*c%!W#¨943(%:*"KP94)]^36%
3(%*W!&#§%25KP	24)O!W#!IC*536Pb!"%#K*&2O2#<aP:¤ · `¹¸  µ[ ¥ >
ÊG>Nzge³º|<>$zg,$ µ 7¨:]^#$7D=$ µ 1åOXOP«­ xæ #  HIJJIJNH «­ xæ µ QR H O_­ xç #  HIJIJJKH ­ xç µ jRXR>
zg4ºC1è2¨7K94K3(23(!W#;=%MP\33(23(L3(%*W!&#g>¨ N42#gZT¨O!W#!W*N3(%<*I!"#
3(:P:!&#O53(PgP¥3$ µ 3(!W3(%"³Cé)|c7!I#<3(DP3(!&2!&#%25% x 3(%9*&!W#;O!W#O94N*W%
O_­ xç # jRVc#ê³36%*W!&#{%25%2>·Ã^3(9423O3(Z[!&2#{2%!&*&DÈ7G.3(;#!"¦94c9423(
3(T!W#D¤f· `¹¸  µ ¥Iã#*&DS*W%%	,c4!"4O#<9!W#*&2%#-5%!"!"/<#S##;!&/T*&!&23a*¥>
 N4%Z##NaP^94%c*W%%2#O*&2KSS3(:P9!"#53(PP\3$ µ ^ ¤ · `¹¸  µ[ ¥ ãQ!W#*&%%94#
ÊX³0éL|!W#<P¥2362#%2>
Ù
ÁQ2#ZNM3(!&#P9453(PS*&2#;94¹!&%+*&2%)5%%!W7*"¨!W#94+;3(#12a%>$ N4
x 423(!&%!"253(P%2<3(4{P)36%*W!&#<_¡7%L53(/23cD+#S53(]cP3( 94.536PT*&2#;:4
3(!&#C79a!I#>YÃ3YC5*"!&!"%N5G%%!W7*&94-*&*^*W%%aP¾O!W#!W*3(:P9!&#536P
P$4/-%9*&*&23	423(!&%!&c,!&;4<%	94<#S:4*W%%bP3(¤ · `¹¸  µ[ ¥ #O,N!&*&*^42#7GN!&/V
7:P\3(:42)>T»-#%!"23P\*&*",N!W#;K<5*&d
!g5
© ³ª Á¾ývþ zg"ºC12N7G-94T3623(!W#;%·P¥33623(`3(%*W!&#g>	zg:4T*W%%$.7G
;!&/2#7Dp$x1OXOP«*ë H «*ì Hjí R H O«¬ H ì[R H OPëR H Oj¬R H O[« í RoR> N4-423(!&%!&C7Ä336%95#%bN:4TÃT?\Ã	Î
423(!&%!&>Ã^3(:423O3(ZP\3¾94-]^3(%({)!&/V!"#O%25% x { ; ? Å H {5î1}Z3(%*&/2#%TPg94-¡,-
O%S3(2#*"D=!"/=*W%%`3(53(:P\233(M7D57+> N42#gZ¾P\*&*&V,Q!I#;{*W%%`<3(!&/V
7<D.9453(/23 x !W#K94!&%N3623d?OP«*ë H «*ì H_í R H OP«¬ H ìR H OP«*ë H «¬ HKí R H OIëR H OP«¬ HKí R H O[¬R H O í R H O« í R H Ùc>
Ã^369423O36Z!0P:4`%:7;*b*W%%P"¤f· `¹¸  µ[ ¥+3(O!W#%23(=724!W#M94O3(!&;!W#*	!"O%94
53(/23-,Q!"*&*b]^#¨94%9OO3(%*W!&#¨3(:P9!&#{53(PP\3$ ^ ¤ · `¹¸  µ[ ¥ x ³Eî¼<#{94`536P
%2364K%#<7G2#:]cP36R5%%!W7*"53(P	*&2#;94+36!&#g>

Ü9Ý2Ý

µ

¶ µ

wyz{

wyz{

!W#94S7/c5*& x %95G!Ia*"*&D{944<%2#)423(!&%!&2Q!"%Q%O,4a#936!"/<Z!&N2#
7 K5MP\3SC#DM53(7*&2O%O94*I<%%P3(ï¤f· `¹¸  µ[ ¥,N!&*&*N7+!"/>¨?#¦94!&%O2%
9423(Q!"%N*&%S#;3<#Q94	94536Pg%23(4O!&%-!W53(/.7G2%c94N%97;**W%%-2#
!W53(!&!&#*	3(##D>
-DBC-R!0F236%('A5<3(NP3( 94O*Wr)PP3(!&2!&#<'$!W#*&D+!W#¨944#*&!W#;¨PTa*"!&(D
P3(«94)%95G235%!"!"#L2*&2*W%2>1?£#L94)2%.94a`*&!&(DL!"%C!I#</*&/!W#M94+53(7*&2)Z-
53(P	*"2#;<94+3(!"#)/2#CP\3-;36#)*W%%c!"%#N;3#<>

 sHl ÁýWü à ft:nmqB(tfp(m9tw³lº |¦wYqt2(t+qº)n¨twfN>Ð(fplj=plqvwt_×pn<w\quflGA$èá²Ùï; Ú
â
$â+kqt2(tKwYqt)sOqul[qusOnobpht2hfqvw\quflM(t>pw\n<w\qufl§h^(f2fð>9C>fg$ ^ ¤ · `¹¸  µ[ ¥ n(t)l[fw-jqf:w\t2wYqn<l
sOqul[qusOnoh^(f2fN>:*>f<?$ Õ
ä (ffN>[ÝzgaºC12`7G94c3(23(!W#;.%KP\3%95G235%!"!"#g>N»-#%!&23-94c%-P#!&ca!&#%
$ñ1òOoOPëê1ïìR H OPó µô # x ëE1ï
Ú ó µ[ô # x ìjRXR>  )%%:O.:44ºC1ï2¨!&%­%1%#M3(23(!W#;¨P\3
%95G235%!"!"#g> N42#gZO!W#!W*%95G235%!"!"#.3(:P9!"#`536P[P¥3$§3(!W3(%T(,-c!I#<P\23(2#%2Z
%95235%!&!&#{%25!W#<Gó µô # x ëp1
Ú ó µ[ô # x ìT36%9*&!W#;.!W#K94!W#!&#xó µ[ô # x ëp13
Ú ó µ[ô # x ëZ
¹
`
¸
#¨942#¨#§*&!&(D=3(%*W!&#{%25g>?£#+:4`%a¤f·  µ[ ¥+3(O!&9423##<_¡#!&S*W%%,c4%
3(:P9!&#C3(!W3(%cT*&2%NÊ·!I#<P\23(2#%N3	94#!&%*õÞ1OXOó v x ëp1
Ú ó v x ìjR H Oóö x ë*1óö x ìjRd
¼5ymza÷m³wé| H ¼E÷ùøty¼³,é$|úR>!W#.94K3(:P:!&#¨P?$ ^ õ@*&%¨3(!I36%`Ê)!W#<P\23(2#%
3(!&#§P	94S53(P*&2#;:4)!&%!W5G%%!W7*&>
Ù
?£#=%:3(D={3(!&#MPN94)423(!&%!&)%2364ÈP¥3S+536PN2##<­7G.;3#<B7G:_
2%K94.536Pc*"2#;<94BC2D=#O7)3(!W7*&ZT94K%97;*T*W%%D=7K!&;#3(L7<D=94
%95G235%!"!"#=53(/23Z3N94%97;a**W%%SC2DK!W53(.O4{!&!&#*T3(##D>
 N4¡,-O*W23c5<!I#<%*&%)4*&+!W#{94S;36#+2%,N!&94c*&!&(D+,4236`N*&2%536P
*&2#;94{3(!&#)!&%c;3<#>
 Q4%#5G!W#!&%#S3(2*5367*&2Ì%!I#:'$%T3b5G23(!WO2#%%:4V,-'$%9*&*&D`%:7;*
*W%%,N!&*"*g7a!&/V#C,N!&*"*g7-!W#/<*&/!W#O94N%23(4`536%%	aP53(/23>b N4N3(!&%9r94
%97;**W%%­<3(S!&;#36=2#=7G.O!W#!WO!&¸7<D¨%*&!W#;+%95G!Ia*"*&DM%94¨%97;a**W%%
,4!&4,N!&*&*g9rN536T!W#:4N%23(4O,N!&94KS4!&;4K53(7<7!"*&!&(DZ>;>*W%%,Q!":4.c%9C*&*^423(!&%!&
,-!&;4S36;3(!W#;K94423(!&%!&PN%95G235<%!&!&#B536V/<23>?#{3Q%*&!&#B536%%,-O#
#%S%94+P\2%3(!W#;.C945G23(!WO2#<9*	3(%9*&%2>N N4c]^36%<#)94!W3(5G!W#%94,
%­`:43(!&2*	,-2r#%%%O7!I#È##!&#¦,N!&94=553(53(!W3(*&/V#D<_¡7%L%*"!"#
4#!&%,-S*"¨7%23(/S!W#¨53!"943(%:393(!W#;KPT94S%23(4)2%¨7D+%!I#;
%97;*g*I<%%a*"*&,N%53(P¥%Q7P\#KP%23>
ÈÉÊÉû ÑËÌÍØÓnÎ4ÏÎÓËÔ2Õ5ÍbÕÐÕÑ[ÓÖÒvØÐsÓnÒºÓ-DBC-a`Ibdc

#*&DZ,-NO!W#94N2a%,c423(,-N2C5*"D:42*&2*W%C-DBC-a`IbdcZ!\>>;2#23C¤ `I· `¹bdc¸  µ[ ¥ >
 N42#gZ/2#ÈP¥3;36#B*W%%#O#<9!W#!W#;=*&!&¡DM!&!&%.5<%%!W7*&+94OO!W#!W*53(P\%
2##c7S%:43(2#),42#§25*&D!W#;K%97;*¾*I<%%2>

âsHl ÁýÁ eqt2(t=qºn¹twOfN>+Ð(fplj1mo&npt0$@kqt2(t=lfsOqul[qusOnoco&t2lÐ<wYq1(tfo&pw\qvfl
(t>pw\n<w\quflCh^(ffN>*>f<?$ ^ ¤ `I· `¹b¨c¸  Û  ¥ qºjqf:w\t2wYqnl¨n.sOqvlqvs`n<o^o&tlÐwYq)(tfo&pw\qvfl{¡t>pw\nw\qvflCh^(f2fN>
>f"$ Õ

Ü9ÝIü

ß

¨àáJ¦âù ý ã  áJÂ++uMä'++'å

 ý +x+~+

ý

â'z+++Äæ;ç+µ{

ä (ffN>[Ý»-#%!"23Q94cP\*&*&V,Q!I#;K%"$=Pb*I<%% x ;!W#K,-25*&DêºC12d
ýþ OM H M ,IH M[RZ
OPM :PH «*M , RZ
OP«*M Û H M  RZ

þ
OPM H M ,IH «*M[RZ
OPM :H «*MRZ
O«*M Û H «*MIRZ OPM H «*M H «*M , RZ 	þ
OPM # H M Û H «*M : RZ OP«*M # H M Û H «*M : R 

XTa4)O!W#!W*	3(:P9!&#)536PbP\394!&%%c3(!W3(%}3(%*W!&#)%25%2Z>;>Wd

$&1 ÿ þ

| H ë æ OPM H M ,PH MjR
 Ê
H ë æ OPM  H M , H «*M  R
 è
H ë æ OPM :H «*MIR

H ë æ OPM :H «*M , R
 À
H ë æ OP«*MYÛ H «*MR
 ~
H ë æ OPM H «*M H «*M , R
 
H ë æ OP«*MYÛ H MjR
 
H ë æ OPM #H MYÛ H «*M : R
 }
H ë æ OP«*M # H M Û H «*M : R
Å ,SZ!&4*&%2d


|2¼
 ||
 |2Ê
 |2è
 |
 |2À
 |2~
 |2
 |2


H U
H U 
H U 
H U
H U 
H U 
H U
H U 
H U 

T x| H
T x~ H
T xè H
T x H
T xÀ H
T x H
T x H
T x |
T x |2À

Ê 
|¼ 
|¼ 
||2 
|è 
|Ê 
} 
H |2~< 
H |2< 

OM H M , R
OM  H «*M  R
OM :H M , R
O«*M Û H MIR
O«*M Û[R
OM : R
OM Û H «*M : R
O«*M : R
Ù

OP«*MYÛ H M ,IH *
« MRZ OPM #QH «*M :H «*MRZ
OP«*MYÛ H «*M H *
« M, R

 42#§2#O23!W#;a*"*	53(P\%NP\3?$ ^ ¤ `I· `¹b¨¸c  Û  ¥ #O2#+3(<;#!&`:4N94OO!W#!IC*536P
*&2#;94§2##7G`3(>
Ù
?£#E94¨2%¨,4236=a*"!&(DE!&%+!W#/<*&/$!W#E3)53(P53(7*&2O%2Z,-¨79a!I#EM943(2
#*&;<%NO94O53(/!&%c#d
¤ `I· ¹` bd¸c  Û  ¥ 
1 

OP«*MYÛ H M ,H M RZ
OP«*M #IH «*M :H *
« MIRZ


âsHl Áý à fTt:nm[q­(tfp(m9t?³4º$|SwYqt2(tqºNnt2wfð>plqvwtj×2pnw\qvfl$Bkqt¡tcwYqtcsOqul[qusOno
pht2hfquw\qvfl¨(t>pw\n<w\quflCh^(ffN>9*>f$ ^ ¤ `I· `¹b¨¸c  µ ¥ n<¡tClfwY_qf<9w\twYqnl=sOqvlqvs`n<oh^(f2fN>:*>f?$ Õ
Ù
ä (ffN>[Ý?#{#*&;DK N4362Uè>ÆÊ>
 S2#{3(;#!&O94QP¥3C-DBC-a`IbdcS:4`3(%9*&%S<3(S%%2#!W*&*&D+:4`%:O`a%-P¥3C-DBC-.>N?£#
;2#23a*T94)3(!&#¦PN94)423(!&%!&)%23(4ÈP¥3¨53(PN2##O7K;3<#L#B536P
*&2#;94%D#<`*&,ND%S7G3(>{?#M53!&Z	4,/<23Z,-*&L;!W#¨7%23(/:4S
3(%:393(!W#;OP94c%23(4O2%)7<D%97;a**I<%%NP\2#*&*&,N%N53(P¥%`7GNP\#CPa%23>
?£#K94cP\*&*",N!W#;,-%!W5*&D+%%9O94-!W#<P\23(2#%,Q!":4K%97;*g*W%%3(S#<O!&
7<D1=%95G235<%!&!&#$53(/23Z!\>>9494DE3()!W#</*&/E!W#1:453(PS%2364g>  ¨,N#<
2*N!W#LO3()9!&*N,N!&94M:4+53(7*&2aP!&2#!0P\D!W#;L%97;<*-*W%%K,4!&4M2#M*&2=
*W3(;3(!"#+aPT94O%23(4{:F3(#=4,Â,-O2#§:¬.!&2#*&D¨%*&S%:4{%97;**W%%2>
 N4!&%53(7*&24%7G)9r*&M,N!&94M423(!&%!&%%!W#)9423(C!"%6'A%O,-.4/O!W#'A#
9436!&2*;3##¨*&%.#.­94)!&`,c49423-%97;**W%%3(S%:P*\>
ÁýWü<Â 	+³¶rö³t[	w+l³jsÃA;q³gu³^q5t+t
X	/<2#=,42#M%!W#;=%9C*&*3(%3(%,³=94C%%0¤ · `¹¸  µ[ ¥ #=¤ `I· `¹bdc¸  µ ¥ 2#=7GO)!&.*W36;>
 N4%2Z!"C!"%K#O%2#%!W7*&!W#<;3a+*&*-%97;*-*W%%CP3(ò¤f· `¹¸  µ[ ¥È3A¤"`I· `¹b¨¸c  µ ¥ !W#=94

Ü9Ý

µ

¶ µ

wyz{

wyz{

%2364O%9NaP¾·%95235%!&!&#<_¡7a%53(/23>?£#;3!W#;O#<DO*I<%%%9*&*&D%N#
2#<9!&*P/37*&36233#;<2O2#P	94%23(4)72%94423(!&%!&;<%-*"<% !W#K94S4;
#`7G23NaP*W%%c,4!&4)2#)7GS23(!&/{P3(R#<D.%:7;**W%%2>?N!&%42#3(2a%#7*&
M/*&54#!"%)P\3­]*&23(!W#;L%97;a**W%%):4<5523K¦2#9a!"*S¦*W3(;{;!W#!W#
:¬.!&2#D¦P¥3)%95G235<%!&!&#153(/23·!0P94D=2#¦7+53(/2#g>+ Q4S!&%2Zb,-<3(!W#23(%M!W#
]*&23(!W#;L(t2o&t2Énlw-%97;<*	*W%%2>Oc%`a*I362D+%236!I7GL!W#=!&#=ÊZ¾,-`;<2#23{t2wNfN>
pÏ£Ðfnom2o&np<tcm:nljqvjnw\t#942#,-N%*&%O-%97;**W%%	P3(J94!&%T%2>	 N4N4%2#
%97;*T*W%%36.M+94C%23(4=%9OPN94)7_¡5=536V/<23>)?#¦94P\*&*&,N!W#;Z
,-O,N!&*"*-c]^3(%c!W#:3(K%­`236!"23(!WCP¥3­2%93(!W#;+:4­36*"/#D=PK*W%> N42#gZ,-
%94*&*	!W#<93(`(,-K4#!&%cP¥3N;2#23!W#;)%97;a**W%O2#!&%`#¨2*b,N!&94{94
%*&!&#{P36*"/#<%97;<**W%%>
ÈÉûÉÊ! ÕÎ<ÕÓÓnÐÏ#"%$pÑÒWÖÕÑÒWÓ'&ØÑ1ÑËÌÍbØgÓnÎ($pÎÓËÔ2ÕÔ

 -,-!W#4323(!&%!&%	P%97;**W%%	2##:3(!W7-c%95G_¡5OP94-53(aP^%2364g>
Ã	!W3(%*&DZ%!W#3(!W#;K.!&#¨è>W|·%97;*¾*I<%%!W#<93(!&!&#*	3(##D
!&-!"%Q!IC53(:#-94aT%­Pb94*W%%2#K7S536V/<2#!&2%!&*&DZ94!&%O3(c2%!&*&DK94#
94K3(!&;!W#*-;a* x %9>)?#¦3(23{%!WC94!&%2Z	!&O!"%#%%:3(D=CÛ6;<.,4:423S:4D=2#
h^(fÏnÏod|)ÏtCfo&É2t:j),N!&94{944*W5¨PT*W%%PT94O!W#5S%2> y 2%936!I#;)%!I­!"*W36!"(D=7(,-2#
{;*N#L<9423*I<%%.,Q!":4M94)4#!"%K/*&5E7DM¿2#!W#;23#LÃg4% x |2}}Z
¿2#!W#;23Q*\> x |2}<}Z<3-Ã^4% x |}}-D.7GS,-*&*Æ_%:!"+P\3-:4!"%c%!Wa!&#g>
#*"DZN{%<*I!"#LP¨#,N*&DL!W#<93(1%97;*-*I<%=jqfpo&j=lfwno&k	nX|tlw\nqvo-n
fo&pw\qvfl=fN>Onl=f:q&ÐqvlnogÐfnok	qvwYqqul¦>tk1w\t(h[`fN>OwYqtpht2hfaqvw\quf<li6Ïnt9j·h^(fÉt2:>N?vP:4!"%c,-23(
94c2%N:42#94Q!I#<;3!&#CP#,1%97;**W%%-,-*&)#53(O!&%O4O;!W#g>T»Q3(!&23(!W
!W#¨3(23·)%!WaO94!&%`3(d·Ã	!I36%*&DZ94C93#%(P\3C!&#)aP#¨3(!&;!W#*T;**W%.!W#<+
%97;*g*I<%S7DK# y XL53(/23%94*"+4/72#)5G23£P\3O+7<D.%!W#;.<#D!W#<P\23(2#%2Z[!\>>
³¨%94*"L7C!&)4!&;4g>) N42#gZ§%*W!&#¨P)#,Ë%97;**W%.%9a*"*&D=%#2#<9!&*
K%*W!&#ÈP#{36!";<!I#a*T;a*,N!&94!W#{P\,Ä%25%O72%9453(77!&*&!&(D=!&%`3:4234!";4¨94
O7_¡5K53(/232##('E`!&%c423(!&%!&S%2<3(4<'E!&r*&D)3(#%:3-94!W#<P\23(2#%
#1!W#<P\23:4.36!";<!I#a*N;*\>L#*&DZ-!0P:423()!&%.{%97;*-*W%5\$#L%­.P
949<7*"2<K*I<%%aP94:7*&2wBÂ4/SO4!&;4+423(!&%!"O,-!&;4<N,S>Æ3>2>94S4236!"%!&SP	94
%95G235%!"!"#<_¡7%+53(/23Z4!&;4;!W#OP:¬.!&2#D2#7G5.!0P9453(/23b2<#.53(/
\	> N4!&%S!&%O):4SP94a!I#<P\23(2#%#M)!W#<P¥23·943(!&;!W#*;*	%!W#;\13(
!0¬.2*&cP¥3T:4S%95G235%!"!"#<_¡7%=53(/23>
ÈÉûÉû*)

Ò ÏÒvÕÐgÖ',`ÕÐÕÑ[ÓÖÒvØnÐMÓnÐ-EÑÕÎÕÏ[ÖÒuØÐLØ.&MÑËÌÍbØgÓnÎ/$#ÎaÓË¾Ô2ÕÔ

&+&

? #È3(23c);2#23K%P-!I#<23(%!W#;+%97;*	*W%%S!&!"%!W5369#<94c,C25*&VD¨
*W3(;c3(%3(P¥3b;<2#23!W#;S%:7;**W%%>	%,-4/N*W3(2D!&%2%%Z%:7;**W%%
94O3(;<2#23=,Q!":4B§%9*&*N#O7G23PN!W#<P¥2362#%=#`53(O!&%O4¨;!W#M72%
K7_¡5¨53(/23cD)2%!&*&D3(#%9394!I#<P\23(2#%#=K!W#<P¥23c:42)>ÁN,-/23Z
!&S!&%`#<S5%%!I7*&K);2#23a*&*T%97;**W%%u¤"· `¹¸  µ ¥)3p¤f`I· `¹bd¸c  µ[ ¥ P¥3K%9<¬.!&2#*"D¦*I<3(;
3(%3(A³.a%%:7;*g*W%2#!&%72%S94!W3N4;#O723QO2#%-94-94%%TP
;2#23a!&#)#)!&!&#*%*&!&#{3(c­4!&;4g>ÁN2#Z,-O%N3(%93(!&N3(%*&/%-%
P	%97;a**W%2#!&%94aN!&%SKpÏ:t2w-aP(¤ · `¹¸  µ[ ¥ 3"¤ `I· `¹bd¸c  µ[ ¥ Z³§%9<¬.!&2#*"D{*W3(; x %
!&#{À>
Ü_ü2Þ

ß

¨àáJ¦âù ý ã  áJÂ++uMä'++'å

 ý +x+~+

ý

â'z+++Äæ;ç+µ{

Ã	!&;3(OÊd	?#<P\23(2#:_¡7%¦;2#23!&#KaPYO%aP%97;<**W%2#!&%
Î3]^3(%-/V36!I<#2Z[#¨qul[>t(t2lm:tiÏnat:jO94Z%9<3(%N7DK;2#23a!W#;%97;a*^*W%%NP3(
¤ · ¹` ¸  µ[ ¥ 3¤ `I· `¹b¨¸c  µ ¥ P\3Q39423g*W36;3(%3(f³#S%5%,42#10 2 %:7;**W%T2#!&%
3(;2#23>S N4/V<#9a;SPT:4!"%S­94¨!&%94c!&!&%S/23(D)2a%D+#¨2#¨7:¬K!"2#<*&D
!W5*&2O2#<>Ä 7*&2E3({2#O231,Q!":41È]E%93;D¦P¥3O%*&!W#;L%97;a*"%KP\3
!W#<P¥2362#% x %9a*"*&D¨*&:P¥6_¡O%9Ía2594<_\]^3(%9c#{P\3N2a4§97*&2¨!&%c%97;a**W%C!"%%3(>
 N4)!W#¦!"%:/V#<9;<.PN94!&%O94M!"%O94aSK+94C]B%:3;D=#M94*&!WO!&P
94=#`7G23KPS%97;*N*W%%2Zc,-+#*"DE7:!W#L%97;**W%%),4!&4$<3(+!W#<P\233(EP3(
;a**W%%7D)5#!W#;+53(!&2*W3Q%97;a*"%c,N!&94{*W3(;<`#`7G23NaP!W#<P\23(2#%S#+<9423
%97;*&%S,N!&94¦#*&DB)%:*&*#O723PN!W#<P¥23(2#%> x K*&%¨Ã	!";3(.ÊdOÎc/V*&%.<3(97*&2
!W#E{]^#!&¨%;O2#<P94+%23(4L93(xrKZ94+*&!W#%+3(253(%2#K94kJ3(*W!&#g>H36DLV/*&%
3(253(%2#2#O23:7*&2^Zg!\>>g:4!I3·%97;a**W%%S<3(O%3(Z[,4!&/*&%S3(253(%2#<
97*&2),c4!"4+<3(S#N2#O23>ÆO N4%Z94`­94)!&%c%O,c4N#!I#<*&*&!&;2#O72%
#=!W#<P\3!"#L7C94.*&!&(DLP94)93#%(P\3!"#=P#M3(!&;!W#*N;<*-*W%)!W#B
%97;**W%O!&%%>N»-23(9!W#§93#%(P\3C!&#%36cP/36+;!W#%N<9423(%c#*&D)`94
#!W#<P¥3O+%:7;*%*"!"#)%93;D>
Î3c%#¨/V3(!W#<2Zb#=nj<n:h^w\qvÉ2t+O:4Zg936!"%./23(OO94%O!&%9/V<#9a;%!W#¨94
P\*&*",N!W#;),ND^d?#%2a+P5G23O!&!W#;+O36!I#<P\23(2#%,42#);2#23!W#;.%:7;*b*W%%c
¨#=#!W#<P¥3OM%97;*%*&!&#¦%93;DZ,-,N#<a*"*&,¢­3(!W#<P\23(2#%.23(9!W#
qvlw\t2(tw\qvlÐhfquw\qvflGaP94S%23(4K93(ArHP\3N­;!&/2#K%NP	*W%%g$T>
?£#{9!&*\Z355364+!&%S%cP\*&*&,N%2dNQc]^3(%2Z[,-`;<2#23*&*b%97;*	*W%%a¤ · `¹¸  4µ 3K ¥
30¤ `I· `¹b¨¸c  4µ 3K ¥ ,N!&94B36%3(x³ # ,4!&4L!&%)%9a*"*&23C5361M94K]^3(%K/V<3(!W#>$ N42#gZN
]#`7G25
3 076 b ¸OaP%97;<*g*W%%c!"%c4%2#K,4!&4+53(­!"%S94S4!&;4%Q;!W#)Pb:¬.!&2#D
3(;<3(!W#;S9453(/!"%*&D.O2#<!&#)23(!&23(!W> y 3(N*&DZ,-N4%N%97;a**W%%-,4!&4
3(SC!Wa*^,>Æ3>2>O%*"!"#KP#!&
# 8c>	Î#`5G%%!W7*&3(2*&!&2!&#{9
P 8!&%2d

8

8

x \g*1%:

#<;=

x \^?>@:nÛ ; a x O7 x -`-d-Ë!&%97*&2§*W%S!W#&BaRV
x
x \ H -`d- ; $ H  -e1Ä|RV
>':
:5; C OPTzBA

 Q44!&;423O:4+#O723­P!W#<P¥2362#% = x \gS,c4!"4L3(+#L!W#<P\23,\TZY944!&;423
x \g%94*&L7>KÁN2#ZC: # %94*&L7.5G%!&!&/>)!W#;(:nÛwºÄ¼)!&%O*&%+%2#%!I7*&>+?¥PN9423(
Ü_üÜ

µ

¶ µ

wyz{

wyz{

Ã	!&;36`èdbc5!&/S;<2#23!&#KPTO%QP%:7;*g*W%2#!&%
 3(C97*&2¦*I<%%!W#êBR,4!&4B4/K4!&;4M423(!&%!&),-!&;4<`3(;<3(!W#;:4423(!&%!"47ªP
94%95235G%!&!&#<_¡7%È536V/<23-,-S2#<'$%N*W3(2D)!&%2%%'E;!W#¨O*&cP:¬K!"2#D>c N4
P#!&#êTIDz AªO2%93(%,c49423c*&!"23*&%P3(\L2#¨53(7<7*"D=7G`%*&/=,N!&94¨#!&S*W%%
P3(ò$T>E?\)5%.M5!W3aP*W%%)B=3(2*#`7G23>E N4+*W3(;<23GTBz A x \ H -`94+*W36;23
94¨%!WO!&*W3(!&(D7G¡,-2#\Ä#E94=#!&)*I<%5-.>  =!&*&!"L¦/V3(!W#<KPS94{P#!"#
T F	,c4!"4K!&%-:]^#+7DO¿2#!W#;23N#KÃ^4% x |2}}agP\35*&!&%94!W#;.:49a%9r>  c%
E íí {  G
:
º :nÛa@
º : : î1¼OO94S!W#23(2a%!W#;./;2#%%cP	9423(!&23(!W>
# @
 H%JCKMLONx½m¤"· `¹¸  4µ 3N ¥1
3 H%JCKMLON4½m¤f`I· `¹bdc¸  4µ 3N ¥ 7K94%PN4%2#=%97;<*T*W%%2>
Å ,SZ*&I
 N42#gZ,-N;2#23aN%97;**W%%N,N!&94CS3(%3(Z³ Û 7-25*&VDC94N*W%%P3(
 H J KMLONN%
%9<3(*W%%¾P¥394%97;a**W%T2#O23a!&#g>  T2*&*94T%P%97;**W%%	;2#23
,N!&94M94!&%.­94s¤ · `¹¸  Qµ Pj ¥¡ RTS KOLMN > x »#%!&23*&%=Ã	!&;36èd) N4)<L*&!W#+%94,N%O,4!&4
%97;**W%%-3(	;2#23aO,N!&94S3(%3(C³ # >	 N42#%OTaP942Â<3(T%*& x 7*Wrc/*&%9
#.%.%	%9<3(!W#;S5!W#<%	P\3¾94N;2#23!&#OP#,L%97;a**I<%%T,N!&94C3(%3(p³¡Û>ÆO N4
3(%3(#³ Û %94*&);!W##-7NO4!";4!W#C3(23	S*&*",EcP%	2#O23!&#CP94N%:7;*
*W%%2>c N4O%cP%:7;*b*W%O2#!&%!&%c942#{;!&/2#+7<D4¤ · `¹¸  4µ 3K ¥ ^ ¤ · `¹¸  Qµ P ¥ R S KMLON x !ÆP
,-25*&D-DBC-`c3`7<D5¤f`I· `¹bdc¸  4µ 3N ¥ ^ ¤"· `¹¸  µ P_ ¥ RTS KOLMN x !0P,-25*&Dê-ABg-a`Ib¨c>¨ N4%Z%:7;*
*W%2#!&%3(c#C94#4#+*&*g%97;*[*W%%c23(!&/),N!&94KS2369!W#)#O7G23C³ #
P-!I#<P\23(2#%O%94¨94!&2#¦7.%%9O=94a94K53(aP*&2#;94¨!&%O3(>.Î#¨:4`<9423
4#Zg,-`4/%O%97;a**W%2#!&%,4!&4¨3(23(!&/=,N!&94{.4!&;423#O7G23NP
!W#<P¥2362#%2ZNO%f³ # >t³ Û >	 N4%c%97;*g*I<%%53(­!"%O4!&;4K;!W#CP:¬.!&2#D+72%
94D¨3(O23(!&/¨P3( %97;a**W%%%*&=,N!&94P#!&U
# 8> N4a!"%Zg94D36`236!"/<
P3( *W%%,4!&4L<3(.#%!&23(L=7K/23(DB36*"/#<OP¥3S{%95235%!&!&#<_¡7a%1943(2
53(/23>
Ã[3	%*"!I#;K%97;*g*I<%%NP3(¤94%-P%:7;*g*W%2#!&%N,-c25*&VDCP#:_
!&#0¾',c4!"4!&%T!W#*&D­7a%O#94P#!&V
# 8Y'A<#%*&T*W%%	,N!&9494N4!&;4%	,-!&;4<
3(;<3(!W#;G->(M!&%N:]^#=7D
 x \*1W8 x \^*é(X x \ J

Ü_üIh

ß

¨àáJ¦âù ý ã  áJÂ++uMä'++'å

 ý +x+~+

ý

â'z+++Äæ;ç+µ{

X§%!W5*&DB#%{,-!&;4B%9«Pc94#O723P/3(!W7*&%!W#s\$#M(,{!WO%O94
#`7G23-PbP#!"#K3-53(!&2S%DO7<*"%Q!I#E\	>TÁQ2#Z!&Y;2#23a*ZC%97;*g*W%%c3(
53(:P\233(>T Q4!"%c!&%%2#%!W7*"7G2%S:4D.2#{%9*&*&D+7%*&/­3(c2%!&*&D>

	õ]\ íMù Ã íL[ð_^cíì$ìQÆ^Ã *` 	Tí[ó5aOó£ì$ 
[

£ 

ÆÄ

?#È94!&%S%!&#È,OO!W#943(!&2*T#=53!"2a*%95G%#23#!W#;¨94O!W#;3!&#{P
%95G235%!"!"#<_;2#23¦*"2C%c!I#<:4S!W#5%NPCO*b*&!WO!W#!&#=53(/23>TN]^3(%2Z
,-53(%2#%O36%9*&%36;3(!W#;53(aP*"2#;<94S#%23(4S36!&#%2>b%	7:P\3(Z,-O2a%93(
9453(P*"2#;<94)7DO94#`7G23P!W#<P¥2362#%N!W#K!">  3(P%23(4!&%NO2%:3(7<D94#`7G23
P-!I#<P\23(2#%:4­536V/<23`%`523¡P¥3©!I#¦3(23cK]^#¸)53(P>. N42#gZ¾,-!W#936%O
O94%-P\3N36*"/#D<_¡7%{]*&23(!W#;.aP*&2a%2>
ývþ ölIÃ#Ä*xs Â 	Nq¶rúj


 4 2#.a!I#;K5%!&!&/#!&N*&2%?$:{PO7<_¡5C53(/23	94!&C!&2!&#¦$+P
5<_,#K53(/23ZO53(P	*"2#;<94)3(!&#§!"%c5%%!I7*&!ÆPT:4NP\*&*&V,Q!I#;K%!&9!"#K23(%>T?vP*B
!&%Tc97*&294T36253(%2#<%536P^<#GTj¬S!&%Tc*&!&23*,4!&44%TQ2594O%9C*&*"23b:4#0{CéK|TP
S73#4C!W#wB1,N!&94C25944{§,Q2#.369453(P*&2#;94C!09
P b*Tj¬!&%N#!0]^7*&S,N!&94K*"2C
M ; $ * >ÁQ2#Z[,S<3(!W#236%+!W#§94S%!&#§P,c49423-,-2#K]^#{*&2%%:P*!W#
94%23(!W7L%2#%K!0P,-4%0$	*l1S: x OI-Úd-Ì!&%P H - ; )/. v RV%`5365%=!W#
!&#¨Ê>p@#<P\3(9#a*&DZ/2#{!0P*¦%*&%S*&*bPa%N!W#tOI-Ud-Ì!&%`P H - ; ) . v R#5z
!&%<37!&933(DC*I<3(;9423(!&%#;3#94a,-2#C]^#¨%:P**&2O!W#§94!&%N%2>T Q4!"%Q!"%
/2#§93!0P:4`7<_¡5)536V/<23T2C5*"D%P!W34236!"%!&>

âsHl ývþ à fOt9n<mqez ; d± c wYqt2(t)qº`n¨m2o&np<tt2w$vSnl[j+nD>nquDqtp:qºw\qvm07,vpm[qwYqn<w
lfhfquw\qvÉ2t{pl[quwo&ts`sOn/>(fs),. v ávÐtlt¡n<w\t9j=Ï|¨nM(tfo&pw\qvfl{h^(fÉt2Kw\n9w\qvlÐ¦k	quwYqE$v`nl[j
t2sQh^o&fX|qvlÐ/qtp:qWw\qvm#7/vYâ.m9nl{(t9jpm:t`wYqtch^(f2fN>So&tlÐwYq)fN>Snh^(ffN>*>f<"$vNk	quwYq,-DBC- á-ABC-`Ib¨cQâ Õ
ä (ffN>[Ýbzgz7-N#93*#`7G23<#,ºC1Þ2N7GT94	3(23(!W#;%P\3g3(236S3(%*W!&#g>bÃ3
*&!&23*M(ZÆMK2#<%T94c#O723YP^%DO7<*"%!W#,M(>Ü$	v1OXOj­ x ëjR H O«­ xæ  H ­ x ó xæ R H OP«*® x ëjR H
OP«*® x ì H ® x ëQR H OP® x ì:jRR>^zf7/v x OM #HIJJIJNH MLRV*%
1 e L # V
7 gv x M h ö Z<,N!&94 M h ö 1M ö Z!0P:M ö !"%N5G%!&!&/Z#
öf
hM
y
ö 1 b M ö Z9423(,Q!"%> 3(/23Z
ÆMK
H M#i ­ x F¡ H FT!&%­23
7 vg x M\
1 
Ê >ljz >ÆMK H #M i3® x F¡ H FT!&%O23)>
5

 Q42#)!&4<*"%d-Ã3N­]53<O23pzZ7,v	!&%SP!W3c423(!&%!&> y 3(/23Z9423(O3(#*&D
y =
X 53(P\%	P^94Q!I##%!&%2#DP$	v[,4!&4C#<9!W#*&!"23*&%-,N!&94O5<_%DO7<*	®>),. v #<9!W#%
#*&D=*&!&23*&%,Q!":4=5<_%DO7G*n­Zb94;4g>+ÁQ2#Z	!&`!&%O!W5<%%!W7*&+94O)*&2{PC) . v !"%
55*&!&27*&>
Ù
Ãg3(Ä·943(!&2*g5!W#<-P/!&,E,-4/;a!I#­94#;!"/<3(%:*"94!I#C;2#23a*^%:P*
*&2%3(S#<N*&2O2#%P) . v >TÁQV,-/23Z2C5!I36!"2a*%:!"% x %S!&#+À<N3(/2*g94aN!W#
94O%2%%%:P*	*&2%S<3(S;2#23=7D+C%95G235%!"!"#B53(/23>ÁQ2#Z,-`%%9O
94K%:P*c*&2%)3()!W#$	*Ä#142#:P\3(94¹­!I#¨,4!&4L*&2a%('A7G!I#;15<3(PS
53(Pv'2#C*&2+K4!&;4+53(P	%23(4)3(!&#§PT# y XL53(/23>
Ü_üI

µ

¶ µ

wyz{

wyz{

ýWü ölIÃa³lxrµs Â 	Nq¶rúj


 N4O:F%3(;3(!W#;)94S%9393(PT94%23(4)%95a`aP,-DBC- x -DBC-a`Ibdc2c53(/23-2%
7<D`:4%cP*&2%-3(N*&%*"D)3(*WK94Spw\quo&qvw|Nhg¡fÏo&t2s x >;>ºZ y !W#<#gZ[|2}}¼¾P3(¤94
3(2caP^5*I<#!&#<_¡7%K*&23#!W#; x XT-z	<#.23(5233*&23#!I#; x %*&% y 3r/!&4
H2Z[|2}}è>N94-]^3(%%!&;4<2Z*"2CS%c*&+7c!W#2353()%T!W#<93(!W#;.#,E;%
!W#943(!&;!W#*¾%23(4K93(arR72%S­%97<_!&# x 53(PPT*&2-2<#)7`36
#Q!I#<P\23(2#S7<D55*&D!W#;c*&2>T Q4!"%33(%:5#%-Sa23(5233b*&23#!W#;O3	Xz
,423(c!W#<P¥2362#4!W#%N3(c;2#23a*"!&+#K!&%\Û#!&/*&D)%3(K%#,E5G2336%	3	#25
%23(!W5!&#% x >;>ºZ y !I#<#gZb|2}}<¼Z3(%:5!&/*&D>  O%94*"=#!"Z4,-/23Z[94Q94%SP
*&2%-%N#-#*&D!W#%23(N#,E;%N7a*"%­#,Äl[f2jt!W#<O94c%23(4O93(> N4!&%O%
P3(R94·Pa94aN94S%9393(PT9<7*"2<xB # ,4236`C*"2C!&%55*&!&=!0F236%cP3(R94
%9393(cP#!W#K:4235<3(%T*g97*&2/BÛN,c423(:4*&2O53(P!&I
% 5#j >T Q4!"%
4%#¨!W#oi^2#+#¦94K!I#<P\23(2#%.5G%%!W7*&+,Q!":4êB # #=BÛ x 94K;%O;<!W#;+P3( 94
#%AF # #êFÛ:4<3(O*I<7*&=,N!&945B # #xBÛZg3(%95!"/<*"DO7!&S4%S<#+:Fc#{94
/Va*IOO5*&2#%%7G#4°$%%!&;#%N`:497*&2g>T»-#%!&23(!W#;K94S7#%!W#<93(
!W#B!"#BÊZB # 2#=7G.2#O23=,N!&94M+3(%3(/Va*I),c4!"4¦!"%%9*&*&2394#¦3c*
{94`#L+2#O23wBÛ2>¨?#M#*&;<D=C23(+5233*&23#!W#;=#M#%!&23(!W#;
94%)3(2<3r%Z,-)#,Ì%9C3(!&)94)/V#<9;<%`#M!&%9/V<#9a;%OP%!W#;¨*&2%+qvl
m:fll[t9mw\qufl{k	quwYq)qvw\t2(nw\qvÉ2tOjt:t(htlqvlÐh^(f2m:t9jp(t>
$O!W#3/V<#9a;-P!I#<93(!W#;*&2·!"%-94c/V#<9;<aPYj<t9m¡t:nqulÐhn<wYq.m9fawvZ!\>>
94%%NPT3(253(!W#;)94!W#<P¥23(2#%S#{P\3-!&%536P>T N4OÛ(3/V#<9;<PY%!I#;
*&2%Q!"%c94Q94DCrSK(tw\9pm2w\p9qvlÐ§fN>SwYqtwYqtt9n<¡m[q.£hn<m9thf:q\Ïo&t>
Î#94-#c4#Z#N2#%9/945G%%!W7*&D4!";4O%23(4:F3(	#OP¥3	53(/!W#;S%:P*
*&2 x a%%9O!W#;+:4`*&2C)53(aP2#¨7C5#¦,N!&94!W#=94]^#!&%;O2#<PfrU7G
#%!&23(>TÎ#:4:423T4#Z!&-!"%N5G%%!W7*&94-*&%K97*&2C2#K73(24.,N!&94!W#K
%9a*"*&23N36%3(c/V*W x :3(%3(3(!&k# >T N42#gZ94S3(3(23(!W#;O:F%%:*&*"D)*&*&,Â%
%*&/`53(7*"2­%94a,-23(O53(/!"%*&D+NaPY3(2a4)7G2%O94%2364{53(36S;%Q*"<%
!W#:4 x %9*&*&DK5G#2#!Ia*"*&D-*W3(;23Y%;O2#<	P94c%23(4O936N:]^#7<D*W3(;<23T3(%3(>
?\-!&%-*&23Z4,-/23Z<94T:4!"%N/#<9;c#*&D.4*&%N!0P94c%;­2#-P94c%23(4C93(c:]^#
7<DS94-*&,23	36%3(-/Va*Ic!&%T#	!W#23(2%CSO4O7D94N%NP94Q*"2C%2>	»-#%!"236!I#;
3b%2<3(4O7G#%-,-2#­%-94T#3C*&*"D3(%3(3(!"#%T2##T7GN;3#`,c42#
%!W#;)%95G235%!"!"#=;2#23¨*&2%c!W#=# y X536V/<23>  42#=%!W#;)94O!W#<P\23(2#.7#
M3(%3(=3(!"#1!&%);<3#<1!0P­7<D1%!W#;L*&2%+M53(PS*&2#;94E3(!&#A2#17G
79a!I#>?#{94S2a%OPT94O2594¨#¨,-!";4_25:47G#=!W#{;2#23*	#c/2#¨.536P
*&2#;94{3(!&#)*&2%c3(%3(`36!&#g>
%!&%:45G%!&!&/+:F%P%!W#;=*&2C%2Z	%O#;!&/K:F%­a*"%23>M N4%
%2 P3(©#{!W#23(2%M3(##D> N4!W#{!&%9/#:;.3(;3(!W#;)94%OP*&2C%
!&%94)!W#23(2%+P:4+73#4!I#;L3.P94K%23(4M93(>L?!&%.5%%!W7*"¨94a­MsOqºo&t:njqvlÐ
fo&pw\qvfl{PY­%97;*D)77:!W#+94Q*&#N7·P¥#7:P\3(,Q!":4!I#¨;!&/2#]^#!"
%;­2#2>	XY/2#!ÆP3(%3(3(!"#P36m{Ka{ W ÷6{K23(%	!&!"%-5%%!W7*"c94	%*W!&#%TP
%97;*&%:4T*&+#-7cP\#K,N!&94.36%3(a{ x ,Q!":4-*"2C%92#K#,7QP\#),N!&94
3(%3(#{ W #C*"2C%2>	 N4!&%-2#K3(3(23Y94N%2364O%:5!W#KS436*"DC#:3(*&*W7*&<##23>
»-#%!"236!I#;¦94)!W#<P¥23(2#¨7#L!W#M%O.2a%%O97*&2M,4!&4M*&1#7G)2#O23
,N!&94K3(%36A{)2#K#,A7G2#O23a),N!&94C*"2C%2>T?-!"%N5G%%!W7*&S94a:4%cP*&2C%
Ü_ü

ß

¨àáJ¦âù ý ã  áJÂ++uMä'++'å

 ý +x+~+

ý

â'z+++Äæ;ç+µ{

%95<3(% =O3(K94#={êé6{ W !W#<P\23(2#%2>L?vP,-%):4)2594L7#L!&.­!";4.7G)94O!W#L
97*&2§%OS73#4%Q,4!&4{2#)7GS*&%{!I#¨O25:4);3(2a2394#4{¨,N!&94N*&2%c2#
#,Â7O*&%¨!W#¨O2594{%9a*"*&23c94<#K3N*bG{ W >N N42#+C*&cP%:523²i^%!W#<P\23(2#%
2#=7G!W#:3(¦)94.#,ÌO!W#!W*-53(PN%;O2#<2>#*&;<%:F%9r5*W,c42#
%!W#;94c,-!&;4_2594)7# x %95G!W*&*"D¨*&%S,c42#)%!W#;`:4#<];3!&#KP947#
%N%23(!W7=7D y %23-c*\> x |2}}<>
c!&!&#*&*&DZjph^o&qum:nw\qvfl¨fN>+t(ÐsOt2l[wv+fN>wYqt¦t9n(m[qB£hnm:tK2#23>Ä%%9O!W#;L94
5#¨*"2C.536PT*&!&%,N!&94!W#¨94!W#!"!Ia*	%;O2#<aPÜrR.7O#%!&23(Zg:4`%P#
!W33(*&/V<#*&2C2#§2%`K3(25G2+5*&3!"#)P536%NP	94S%23(4)%95,4!&4{%
##:!W#S53(Pd	!I#S·%9523¶i^%-%*W!&#CP%97;*!&%TP\#K(,N!& x /!I·94c*"2C
#E7D15G23£P¥3O!W#;B:4+!W#<P¥2362#%+#B53(/+:4)*"2CC943(%:*"!I#;L%:523²i^%
!W#<P¥2362#%4/K=7¨523£P\3OM(,N!&ZT>= Q4!"%K!&%9/#:;ZT4,-/23Z	2<#B%9a*"*&D17G
/23(­7<D%!I#;K*&2a*P!&*W3(S24!W#; x zg*\>WZ¾|2}}>
%!&%N:4%:F%Z,c4!"4K2%O3(%9393(!W#;P94c%23(4C%95Z!&-!&%N/2#K5%%!I7*&
94Q94`%P	*"2C%Oqul[m2(t9natwYqtClps­Ït2fð>Sfo&pw\qvfl-P	23(9!W#§%97;*&%c94N!&%%c!W#
94O,4*&O%2364§93(> N4!&%!&%S72%O94%OPT*&2C%2#)%:4,Â,-*&*0_¡r#,#=53#!I#;
4#!&%O*&!Wr36;*W3(!&(D+%!W#)#3(;*W36!"(D¨4r<%S3(.5G%%!W7*&K!I#¦9453(PNPK*&2C>
Ã^369423O36Z-94=#,N*&D!W#<93($*&2%)2<%¨9453(7*"2 94K!W#12a4!W#<P¥2362#B
5<%%!W7*&D)*I<3(;S#`7G23-P*&2C%4%-7%K!W#)3623T`23O!W#S,4:423T!W#<P\23(2#%
3(S5G%%!W7*& x n:hhgo"qvm:nÏqvo&quw|Ow\twW>T Q4!"%c#%%!&9%#,Ä#!Æ]2a!&#+25%2>
?£#L%9C!&#M3­*"2CB­4#!&%9 !&%.!W#¹;2#23*#<.7*&+M53({*&2%K94
*&2+.53(P	*"2#;<94+3(!"#+#{94%Q.3(%3(S3(!&#g> Å /23(:4*"%%523(!&2#
%94,N%94!W#BC#D¨2%%­36!&#%OPN94.53(PN*&2#;94M#=94)#¸36%3(K2#=7G
79a!I#>  42#C%9a*"*g#O7G23	P*&2%!&%%:<¬.!&2#P\3	S3(%3(3(!"#94#`7G23
P!W#<P¥23(2#%	,c4!"42#S7GT%95<3(`7<D%!I#;*&2C%2<#cO94-#O723¾P#,B%:523²i^%
!W#<P¥2362#%7DK;#!&9%2> N4%Z­4#!&%9­%<3(#)!W#K3623TS%*&S(t2o&tÉ2nl[w*&2C%
P3(OI-Ud-Ë!"%·Pa H - ; ) . v R`94a%94*"=7G`!W#%236¨!I#</$	*	>c?vP,-2#§]^#=K39423
%9a*"*¾*"2C%,4!&4+5G23O!&%3(%36`3(!&#{942#K!W#¨*WO%*&*2%%c,-2#K]^#¨
53(PO4CP%2394#K,-*&+7S5G%%!W7*&O,N!&94N%!W#;.*&2C% x %S!"#)À> Å <94
94c2%cP*W3(;3(!&#KaP:453(P*&2#;:4K,N!&94NO3(!&#KP94S3(%3(#
#3C*&*"D+5G23£P\3O%N%!";#!Æ]2<#*&D{,3(%94#K:4S2%aPYC%9*&*536P	*&2#;94{3(!&#{,N!&94
3(!"#)P	94S3(%3(S#>

ýÁ<Â 	+³¶rö³t[	ÄÜ=Â³+rj


#*&;%cK94P¥36;!W#;.%!&#{,O#,Â,N#<!W#936%O`<7%93c53(!W#!I5*&%OP\3
]*&23(!W#;*&2a%7%K#C94!&%2%%!&#+3(;3(!W#;O94%9393(cP:4%2<3(4C%95> N42#gZ
,-2*,N!&94K#23(`4236!"%!&%55*&!&¨P\3%*&!W#;)*&2%2>
ÉÈÉÊ! ÕÎ<ÕÓÓnÐÏ#"%$pÑÒWÖÕÑÒWÓ'&ØÑnmbÕjopoQÓÔ
l

 !W#)%95235%!&!&#L536V/<23(%25*&DB)!0F23(2#<`%23(4¨%42O.:4# y XÂ536V/<23(%S#M%!W#
94D=4/O:F!&/.O4#!&%9O%P\34#*&!W#;*&!&(DZ,-2<#=%%9­94SCP\,Ì%97;<*&%
,4!&4+3(S4<3()O%*&/ x :4S53(aPY#%%!":%O*W36;S3(%36,S>Æ3>>;!&/2#§5*&2#%%
7#S,Q!":4=# y X$53(/23c2<#=7K%*&/=,Q!":4¨*&2%2>)ÁQ,/<23Zg,42#=%!W#;¨*&2%!W#
Ü_üI»

µ

¶ µ

wyz{

wyz{

3(23¨*&%)%O)%97;*&%`aP#M5G2#M97*&2M94)3(2!W#!W#;M52#M%97;<*&%%94*&17G
2%DKO%*&/,>Æ3>2><94c;!&/2#+7G#>TÎc9423(,Q!"%Z,-c%!&*&*2##N%*&/94S53(7*&2R,Q!":4!I#{
%9a*"*&233(%3(> Å O94,-%9*&*&D=2##594*&*T73#4%SPN)53(P2#¨7G
%943(2#j
 +7<D)%95235G%!&!&#<_;2#23M*"2C%2>S!W#3c*"2CK;2#23!"#536V/!&%S#
;3#:4%:P*[*"2C%T3(-;2#23 x %!"#O>W|2b%9*&*&D#*&Dc%9a*"*#O723bP
*&2%2#7G25*&D!W#K53(P6>bc*&*!W#.a*"*[,-79!W#O94q
 !I#<23(%!W#r; `53(P\% x !\>>:4%
,-S,N#<NO]^#QP\3N<#+55*&!&2!&#¨aPT*"2C%3(`536P\%N94a#<9!W#{#<D.%97;<*&%94
3(2a%D)%<*"/<:'A#{2#+42#O7O%*&/@
 #</2#!"#*&*"kD K,N!&94!W#C%9a*"*b3(%3(:'$#
#*&D.P¥,E43(%97;<*&%T94aT`%7c%*&/C,N!&94*&2C%2>	 N42#gZ,-N2#O5-94T%!I#;
*&2%-*&2%N`3(%3(36!&#%2>-Î3	]*&234#!&%N%94*&+42#936D]^#)*&2C%
94NO!&;4<7S53(QP%:4)53(P\%2>
Ãg3(9423­3(Z,-S%:4*&=%!W`4, C#D+#,H%95G23²i^%S!W#<P\23(2#%`<3(S!W#<93(
7<D`c*&2>	 N4-!W#<;3!"#SaP^#,1*&2%TO%	#	!W#23(2%N94N73#4!W#;`3TO4g>
Îc9423(,Q!"%Z94;!W#{PK5%%!W7*"K3(%3(3(!"#¨!&%S#;=7<D)94O*I<3(;O/2342 x %
!&#§>ÆÊ>
 Q4%=23(!&23(!W¹*"2aÂ%+L:43(=!0F23(2#K]*&23P#!"#%:4)#2#<93¨#A23(9!W#
%95G%-P3(*&/V#D>N Q4N]*&23YP#!&#%3(Q,*&*0_%9!&§P¥3*&*gP9453(/!"%*&D.!W#<93(
5*&2#%%7G#%2>¿SO94S/;2#%%NaP94c]*&23Q23(!&23(!WO,-S%2a4]*"23P#!"#
!W#3(23O¦4%{%O{*"2C% x %!"#1À> Å ):4!&.!&%+7G23C=%*&+{P\,
##%%9<3(D)*&2%N:4#K­!"Q94%*&!&#{P	!IC53(:#-#%>
ÉÈÉû*)ts ÒÓnÐÔIÒvØÐCuj$ØÐgÖÑ[ÓÏ[ÖÒvØnÐ?vxwNÓÔÕj-LÑÕÎÕÏ[ÖÒvØnÐ
l

  4O]^36%c]*&23cP#!&#¨!&%S2a*"*&sC:
N
y  >O N4!&%P#!&#=!&%O39423c%!W5*&)#=!WO%`ac]^#!I#;
y 
*&2%94`#*"2a`4!&;4!W#23(2a%aP:473#4!W#;­3>n *
5*&!&%94%-94!&%N7D
%!W#;.r#,N*&;79!W#)!W#K94c*&2;2#23!"# x 53(253(%%!W#;N54a%aP947_¡5
y 
53(/23>O?#È9!&*\Zn *
%*&%·P%,N!&94{94.4!&;4%/V*W.3(;3(!W#;Û;O2#<cP#!"#
y  >
8 *
iwof5jj

ývþQz q,Ã-qn5 rj 8 :y  ¢
Ã3TS5G%!&!&/S#!&CM(Z;2#23!W#K9453(253(%%!W#;54%Z*&|{ x M\#T} x M\T7c94#O7G23(%
P	5<#%!&#+#)#93!&#K!W#<P¥2362#%2Z^36%95!&/*&DZg94a#M,N%Q!I#</*&/{!W#g>T N42#


8

:y  x M\n1%} x M\é/{ x M\ J

 y  #<%:4)!I#<P\23(2#%)94a`2a4¹*"2C¨2#!&{,N%!W#/<*&/1!W#1<#13%<_
*
5#!W#;+!W#<P\23(2#%`#;!&/Zg#<93!I#;)!W#<P\23(2#%`5G%!&!&/>O?vPNCPaM	,N%aP¥2#§!W#/<*"/<
!W#B<#¨5<#!I#;¦!I#<P\23(2#K*&!Ira+3(%*W!&#¦3c%95G235%!"!"#gZ	942#=M-3#<D¨%9723­%SPN!&
3(#!0]^7*&S,N!&94 x %9723O%-P x a!W*WY*"!&23*&%P	!&­%3	23(!&/{*I<%%2>TÁQ2#Z!0PÜM
!&%a+:4`!&!&2!"#)P	945<_,#)536V/<23-!&2#{75G¨94#M¾3Q23(9!W#
%2##<%aP!&2<#=/236DaP¥2#¦9ra536S!W#M2#%!&#M%25%2>¨!W#+94!&%O*&2%¨¨4!";4
!W#23(2%cP9473#4!W#;­3N,-3aN94!&%N#;!&/>	ÎQP3(%Z,-3(N!W#<23(%.!W#C94NP
94NO*&2C2#)7G`55*&!&=7DK94 y XL53(/23>	ÁQ,/<23Z%!W#S*&2%cP­%95235G%!&!&#
53(/23N<3(`%9a*"*&D¨!"`;<2#23*O<%aP942©D+7%§P¥3N*&%!W#;)233(!W#;)%97;*&%2>
8

Ü_üIÇ

ß

¨àáJ¦âù ý ã  áJÂ++uMä'++'å

 ý +x+~+

ý

â'z+++Äæ;ç+µ{

g(b) = f(h(b))
transitivity "="
g(b) = f(f(b))

f(f(b)) = f(h(b))

symmetry "="

congruence "="
f(f(b)) = g(b)

f(b) = h(b)

f(f(b)) = g(b)

h(b) = f(b)

axiom

symmetry "="
axiom
h(b) = f(b)

Ã	!&;36dT!WO*Ia!W#;O%:5235G%!&!&#{%25K,N!&94 y X
Î3Q23(!&23(!&#¨!WO%!W#*&DÈaN*W!W#;+*&2C%:4<3(S55*&!&27*&.!W#{.#<D)2%%#
42#O!W#936.C#D)%*W!&#%PT%97;*&%94N+#c*&2¨.K3(:P9!&#{PT94!W#<_
5*W%%2>?£#¨#<93%N)5#!W#;+!W#<P¥2362#%`,-3S#<93!"#+!W#<P\23(2#%5%!"!"/<*"D>
?#Z y XM53(/23(%`#-4/N#<93!I#;!W#<P¥23(2#%>-N%T%:4V,c#7DzgN*\> x |2}}ÊZ
%97%9C5!&#{2#¨53(*&D+7O%!WO*W=7<D=pÏpsQh^w\quf<l=m9f<lw\¡n<qul[wv>-ÁN2#Z¾*W%%94c3(
7*&S#<93N#<D:423-*W%%c2#)%955G3(N%23(4)53#!W#;.4#!&%>
ÉÈÉÈ*~ ÕÑÒÓÓÖÒvØnÐ?vxwNÓÔÕj-EÑÕÎÕÏ[ÖÒuØÐ
l

  4%#)]*&23P#!&#x * :3(!&%C%*&NP%N:43(S<7*"OC*"<%S%97;<*&%N94c3(
N
/23(D=436=+%*&/,N!&94MK##!&#<_9<7*"2<<_¡7%536V/<23>.?£#=3623)%!IC94!&%2Zb,-
#%!&23·94S23(!&/!&#=4!&%3(D+PCP2>  25*&D:4!"%c]*&23QP#!&#¨#*"D{!0P*&!"(D{!"%
!W#/<*&/+!W#+C53(7*&2)>
!g©5³ª bývþ zgtOPó x ó xæ E1å¬ xæ QR#mO  x ìx1 ó x ìQRB7B!&O%2>R N42#gZ:4*W%
O¬ x ì*1ó x  x ìQR2<#+7O23(!&/=7<D)#S%:5235G%!&!&#¨%25g>NÁN,-/23Z!0Pf«¬ x ì(1ó x  x ì!"%
O%97;<*gPT# y X153(PZ!&%53(P	!"%cO3(C5*"!&2 x %Ã	!&;3(>

?£#=;<2#23*\Z	!0P:4.%95G235<%!&!&#L%25=!&%.5G23£P¥3OL`¨5<%!&!&#5­L#ñ ­n¾2#%O94
2594¨aP945<%!&!&# x 7G/x ­n1©|2Zg:42#aSO%, ­n>EÀK!I#<P\23(2#%O3(#B!W#¨3(23
.536V/<94O3(%9*&NP	%94+O%:5235G%!&!&#{%25g>T Q4`53(PT#%%!&9%cO%2594)P
 ­n4 >è>
 Q4!"%<5*&)%94,N%9494%!WO*W!&#MPN94%:5!0])a!&#*T523!"#%`aPQ§%9<_
5235%!&!&#{53(/23-#%%!&9%O4!&;4)25:4)%N,-*&*%-!W#<P¥23(2#O3(%36!I#{# y XL53(/23>
 N4!&%2Z*&2a%236!"/<7<D#<D`%:5235G%!&!&#C%25%<3(7*&cS*&%Q%97;*&%-94	2<##
7C%*&/L7D¨# y X$53(/23c,N!&94!W#¦%9*&*-3(%3(%>.ÁQ2#Z!0PN%94¨*&2%O3(.<55*"!&27*&
*W3(;S36%3(O3(!&#%5%%!I7*&D{23P¥3T25:4)3-!W#<P\23(2#O3(!&2#<7G#%2>- N4NÛ;_
O2#<P#!&
# 8 *  25*&D%N94!&%N23(!&23(!&#g>Y;a!I#gZG94N]*&23P#!&#E : %*&%-P%-,N!&94
94S4!&;4%c/Va*I3(;3(!W#;94!&%	Û;O2#<-P#!&#g>
Ü_ü2Ý

¶ µ

µ

wyz{

wyz{

ýWüsQz q,Ã-qn5 rj 8 :  ¢
Ã3NO5%!&!&/#!&aM;2#23)!W#)94O53(253(%%!W#;)54%Z*&q8 :  x M\7GS:]^#=7<D
iwof5jj



ýþþþ

¼

þþ

8

8


* x M\*1 ÿ þ
þþþ
þ


 >8
  xM#?
:
L 8
e
vf #

H M¾!&%#)!&
H M¾!&%N23(!&/¨7D+O%:5235G%!&!&#)%25),N!&94)5362O!&%%
M # #xM Û
MH ¾!&%N23(!&/¨7D+##<_%95235G%!&!&#{!W#<P¥2362#
!W#</*&/!W#;)94*&!&23a*"%aM #IHIJIJJKH ML x { ; ? Å  J


  x MYÛ9?>J|
*

: x Mvv

$ ØocÒÎÕ s º
Ò Ö"v N
w ÓbÔ2Õj-EÑÕÎÕÏ[ÖÒvØnÐ
ÉÈÉl 
l

9  !WO%%*&!W#;=*&2%O94a`3(K7*&.{%*&/K%OK43(
Î 394!W3(¦]*"23P#!&#= :

y
%97;*&%NP X¹%97;a*^*W%%%94K94Q94S3(%9*&!W#;K52#§%97;*&%N2<#K2%!&*&D+7S%*&/>
9  #%!"236%:4N%%P%97;**W%%C¤ ´ L  ¥
ÁQ2#Z:4	Û6;O2#P#!&]
# 8 :9  %7<D, :
L
3¤ `I´bd c  ¥ P\3	23(:!W#3(%36#{b>	Ã3b2a4O%:7;**W%aTj¬Z!0P*&2CAMg,N!&97
4 8 :9   2 x M\?º1¼
!"%%2Z94*&2,Mb,N!&94§94S4!&;4%Û6;O2#q
 8 *9   2 x M\!&%c%*&#<!&*C!IC*#`7G23
P	*&2%N!&%c%*& x %S!&#¨À>	 N4!&%Û6;­2#N!&%N5a%-P¥<*"*&,N%2>

ýÁsQz q,Ã-qn5 rj 8 :9   2 ¢
Ã3)15<%!&!&/¸#!&êM;2#23$!W#$94M53(253(%%!W#;$54%B#ÄM%97;*S*W%=Tj¬1
OPM # HJIJJKH M ¯ RZ*"q
 8 *9   2 x M\-7GS:]^#+!W#§94P\*&*&V,Q!I#;)##23d
?vP#%97;a*2#O7G%*&/,N!&940M(Z!\>>C
« z H |ay6z*n
y A H  d  W
1 A/¬  x bnMv H M\Z:42_
# 8 *9   2 x M\*1$¼>
Îc9423(,Q!"%Z*&CTj¬¡51O  #IHIJJIJKH  µ Ru½6Tj¬.7%-P*&!&23*&%<#  7GS%97%!":!&#%`:4 
!&%­%N;2#23*,N!&94g
d  H |a'
y ,y³)d  x bj2<
 i  x M\> y 36V/<23Z#23*&*b%97%%QPfTj¬+#
%97%!":!&#%T,N!&9494!&%-53(5236¡DZ*&	94Q%:TQ¬¡<#`:4%:7%!&9!&#  7Gc!IOHPg94
P#!&/
#   2 Z[:]^#=7
D   2 x O  #HIJJIJKH  µ R 4H  *1
ã  µ &Z  ) ô   > #  Q42#gZg94`3(2C!W#!I#;
B
# e
3+ 
 
*&!&23*&%cP:Tj¬)3(aTjr¬ ê1O U #HIJJIJNH U ö RZ1TQ¬g§"TQ¬o>Tzg
 +7S
OC
5*"!&(DP#!&#gZ!\>j> +C5%
*&!&23*&%S  ¼½2|  #=4!&;4¨/Va*I%
P ¦!I#!&2.94a94K3(%95!"/<*&!"23* x %97;<*W552<3(%
.7G%*&/V<7*">N Q42#gZ
iwof5jj



8

 9  2 x M\*1
*






x  x U é






  2G 

 2

x  x [é4ø J

 8 *9   2 x M\3(2*&*&DB3%AM,N!&94¦+4!&;4¨/*W.!0P<#D¨43(=%97;<*&%
 `2<#=3(;#!&K94¡
x ,S>03>2>bPnTj¬K2#.7G%*&/.,Q!":44M(> y 3(/23ZMg!&%N3K,N!&94KS4!&;4K/Va*I!0P:423(<3(N#*&D
­P¥,H%97;a*"%c!W#)94O%97;<**W%,TQ¬94aN2##7O%*&/¨7D)*&2C%<#:455G23
S7G%<*"/7*&S39423b2a%!&*"D x ,S>Æ3>2> >b?#C3T362*&!"2a!&#gkZ .#%!"236%%:7;*&%T`7Q%*&/V7*&
94T<3(T%9C*&*¥Z4/Nc39423i^	23H%93:3(Z##<DS/3(!W7*&%-!I#­53(!&%#S,Q!":4O94
23 %!&>?£#§P936S,-S,N!&*&*bP3(9423N3(:]^#V
 8 *9   2 7D)5*&!&!"*"D¦#%!&23(!W#;+945*&2#%%
7#+,4!&4)!&%%)P\394S5<_V,c#.53(P	%23(4g>
¢4£¤D¥  ¦O§¨q©B¨4ª«¬D©5­O¨x©B®¬q§¯¬Qªt° ±C§²³®°4¨x­O§pª«¨ª5´Q¨xµV³r¬q§¯° ­O¶4¬Q·T¸¹¦Oª«»º§²´¼«»ª«¨ª|µ°4ª5ª¯°G°1½¨xµ¾V§¯¾G½³¿°x­O§À¨ ©B¬
¦dµª©B°G·G²´¬Q·Á³¾5ª«¬²µ¦dÂ¬D© £Ã

«¦O§Ä¦O§§¯¬Dµ§¦d³­O¬³r¬´Q¨x²§¯¬|°ª«¬B©B¸¹¦O§¯¬Cª«¬År°§¯§¦d³¦d­d¦Zª¾qª«¨4ª?ª«¬©B¬Q½t¨ ¦dµ¦dµ®À§²³®4°4¨ ­O§

´Q¨ µq³r¬C§¯°x­O¶¬Q·À¦O§·¬Q´D©B¬¨4§¯¬Q·qª¯°G°t½C²´¼« £

Ü_üIü

ß


Æ

¨àáJ¦âù ý ã  áJÂ++uMä'++'å

 ý +x+~+

ý

â'z+++Äæ;ç+µ{

TòNíÅì$í  ÄÆgó ¿ Ä 
TCÈ

a1Ç

?#{3623-K#<#)523(!WO2#<9*	/*W!&#{P	3N!W#<;3a!&#)PT5<_,#Í7<_¡5
53(/23(%Z,-S5*&=(,-.3(2#,#¨53(/23(%2d94 y X536V/<23ÑÕÖ×ÕØL#¨94%95235G%!&!&#
53(/23OÑÒÓÔÔ>  .4/.%¦94./<23(%!&#¨PÑÕÖ×ÕØE%S%23(!W717<D y %23c`*\> x |2}}>
ÑÒÓÔÔS4%7G2#)25*&D{!I#§/23(%!&#)¼G>ÆÀÀ>
ývþÌÿ
É

lxrµs¶j+rxq¶l

³'Ds^³ãj^l,Ã#xsê!C©lxj³g;t

Î35G23(!WO2#<9*T2#</!I36#O2#<`2<#=7K%23(!W7E%P\*&*&,N%2dOXT4=53(/233#%O#È!"%S,#
53(%%3K#79!W#%)94{!I#!&!W**W%%,$ a%.!W#52>  {25*&VD<AM3:423O:¬.!&2#
O94¨36;#!&O9453(253(%%!W#;>SXY%%2#<!W*&*"DZg:4`5<_,#+53(/23Q;2#23a%%:7;*
*W%%,N!&94#TPg94-(,Q/V3(!W#<%2>	?£#S32#</!W3(#O2#	:4!"%%T#<3(!W3(N4#;%b!W#O94
5<_,#K53(/2372<#.7G5G23£P¥3O),N!&94K7!&*"6_!I#%cP:4  ÙÎzÎN_%¡D*&!W#5N*W#;;
P`Ñ[ÕÖ×¾ÕØT>M!I#MÑÕÖ×ÕØJ25*&VD%,-DBC-a`Ibdc),-.5236!I­2##*&DB,Q!":4M%97;*-*W%%
79a!I#C,N!&94#;!"/<N%936	*I<%%2>T N42#gZ<94%N%:7;**W%%-3(-]*&236Z93<#%(P¥233(
94-7_¡5S536V/<23ZV<#S!W#;3!W#c!&%b%23(4%:> N4N53(253(%%!W#;P:47<_
5S536V/<23!&%	523£P\3O!W#`5<3*&*&*,N!&9494-53(253(%%!W#;SaP945<_,#53(/23> N4N53(/23
!&/%	*W%%,N!&94O!&%T7%!&4236!"%!&#<!&*94-5<_V,c#`536V/<23g]^#!&%94%-!&%T53(253(%%!W#;>
 N4%2Z[,O4!"/<`%D#43(#!&2!&#ÈP:4­536V/<23(%2>-QP¥23Q94Z,-S93a94O5%!"!"/<­#!&%
P3(H94N%TP!&/-P%PÑÒÓÔÔ<#O]*&23	%O-P%T%	%236!I7G>N!W#,-N2#­25*&VD
9  :4;2#23)%:7;*
94;2#23)%97;*g*I<%%aPÑÕÖ×ÕØÈP\394c]*&23-P#!&#4 *
*W%%2#{7%¨%a!"!"#*!W#5PÑ[Ò2ÓbÔ2ÔO%N,-*&*a%NP\3-94%*&!&#¨P	*&2%cP\3
ÑÕÖ×ÕØ>	Ã	!W#*&*&DZ94S536V/<23(%53(+`:r<*&9453(7*&2U!W#)53*&*"*¾,N!&94K94!W3-%9<#3(
%!I#;<%2>D1%!W#;L94!&%K2#/!W3(#O2#<K,)2<#14!&/¨5G23!&#7DM4#;<!I#;L*&2C%
#¨%97;**W%%,N!&94#O#25!&%937!I#;{94O9423>?£#+#93%2Zg7:4+#25%
%955G3(T2a4C942372%3(%9*&%-7:!W#P3(H#53(253(%%!W#;O2#K7c25*&D.!W#C94
9423>
 T523(!WO2#<O!W#S:4	*"!&;4<	P53(7*&2O%	%2O!W#;NP3(A94T,-*&*0_¡r#,#O53(7*&2J*&!I733(D
      /g>W|>0Ê>W| x *&!0Fca*¥>ºZ|2}}a½*&!0FSJ9#23Zg|2}}<>?#C3(23YS79!W#S36*"!W7*&
*&*&!&#KPg9Z,-N25*&D.a*"*[!W#%-#<9!W#!W#C94      %	3Y%	%>2%
94%Q!W#%	/23	c,N!&3<#;-P^/236DS!0F23(2#-53(7*&2O%	,-%%9O-94b94!&%T!&%36*"!W7*&
%Q%2>
!W#O94O      #<9!W#%c.#<D+53(7*&2O%cK*"!&%#¨!&%2%%94O3#<!WO%aPT%!W#;*&
53(7*&2O%Z,-{,N!&*"*O53(%2#<<#1/236/!&, PS94=#O723KPS%<*"/<Â53(7*&2O%)!W#E94¨     
*&!W733(D>Ã^3(:423O3(Z[,-S%:D+!W#¨,4!&4+!W#%S523!&#{!&%%95!W*&*&D=!W53(9#<S#
2*b,N!&94{94!W#§P¥2a93(%3(%95#%!W7*"­P¥3Q94!&%2>?#¦!&!&#{,%9D{943(%9*&%!W#{943(
a!I#%!W#=­3(O9!&*	K;!&/.#{!W53(%%!&#{P\3N:4`2362%!W#=3#{!WO>O N4!&%#23#%
94K!W#%.»T  x 2;36D+9436DZ	zg¿c x z¿c_¡*&;273%9ZT#L»NÎz x O7!W#3(D¦*"<;!&2>
 N4S53(7*"2­%!W#):4Sa!I#%c»-T $#¨zg¿H#<9!W#K*&!"(D+%Q,*&*a%##<_¡ÁQ3#)*W%%2>
»NÎz¦!&%ÁQ3#<_*&!"(D)C!W#g>
?£#O9!&*\Z:453­23(%	Pg3b5G23(!WO2#<9*%D%2Ä3(d Q4N%97;a**I<%N2#!&%
,-23(;2#23=!W#M%94=),ND¨94cP\3/3(!W#<.|C,C25*&VD<B94)3(%3(G³ê1 |¼),4!&4
523¡P¥3O7G%-!W#94c523(!WO2#<%2>T Q4%QP4!&;423-3(%36%T!&+#TD!&*&+723-3(%:*"%2>
D 0  2 1$À¼¼G>Ã3	/V<3(!W#NÊ,-N25*&D4³ # 1³Û"1$}
 c*&!I­!")94%aP%:7;*[*I<%%7<Ê
Ü_ü

µ

¶ µ

wyz{

wyz{

%.36%3(%2>c%%936*W%%CP¥3C#L5!&/¨3(:]^#2O2#<.,-)%*&%076 b ¸1ªÀ¨%:7;*
*W%%2>H N4%=53<O23(%.a*"*&,-194{:¬.!&2#);<2#23!&#¹P`*&*%:7;*N*W%%),N!&94!W#
94{!I#!&!W*%;O2#<%KPS94{%23(4L936>Þ@Q%9*&*&D,Q!":41:4!"%)O94$)O%.À<¼¼=%:7;*
*W%%,-23(;2#23Z[!\>>g7c94O%9­S#O723a%,42#§25*&D!W#;+/3(!W#<`|<>-Ã3Q94
%*&!&#KP%97;<**W%%N94-3(NO793#%9O!&C.ÑÒÓÔÔN,-%K!W#<_252#2#<
53<O23(%2>HÃ[3)»-T Z-»NÎz	Zc#$zg¿«,-%Ì|¼¼=*W%%2>¢?£#E94¨9423K!W#%)!W#
53(*&!WO!W#3(D{5G23(!WO2#%94S%SPTè¼*W%%4!&/{94`7G%3(%:*"%2>

9  >  T%*"
y  ZP * ZV#, *
 Q47<_¡5·*&2%b,-23(T%*&O/!Wc94	P#!&#%* :
,N!&94§24KaP94cP#!&#%!WORPN|2¼*I<%%2>
 Q4`%!W#;+PÑ[ÕÖ×¾ÕØ1,N%!&2*&*&D¨4%2#=%%23(!W7G¸7<D y %23cSa*¥> x |2}}>
 N4+Ñ[Ò2ÓbÔ2ÔO%:#3(B4236!"%!&.%%2#!W*&*&D=%*&%O*W%%OP-94%9C*&*"%S%!&>  23(!&!&2*&*&DZ
*W%%3(%*&{,N!&94+736294<_\]^3(%Q%23(4g>
ýWü !g©n+lnj5³ Â tbqt
É

?#{94P\*&*&V,Q!I#;{,-S5<3(O94`3(%:*"%P3Q523a!&/53(/23N,Q!":4+:4`%!I#;<*"K53(/23(%2>
 N4!&%S53(!&%#È!"%O523£P\3­B3(;36!I#;{94O,4*&.      *&!W733(D>KQP¥23c942Zg,-#*&D
3#<!WO%c!I#P¥,J%*&+C!W#%P	      >
$ ØocÒ2ÓÑÒvÔ2ØÐMØ.&/-Ò&+&ÕÑgÕÐgÖsÓÓnÑÒWÓnÐÖÔ/Ò ÐMÖ×ÕUÌ¡ÍÀÌ¡Í
ÉûÉÊ 
Ë

 b7*&|O53(%2#<%3(%9*&%cPT3Q5G23(!WO2#<%2>?%:4V,Q%94O#O7G23NPT%*&/43653(7*&2O%
!W#2369!W#K!W#%-P      >*&/)O2#%-94-S53(P*&+7QP\#.,Q!":4!I#)è<¼¼%#%2>
 #%!&23K53(7*&2 .7G`43({!0P#!":423SÑÒÓÔÔS#3ÑÕÖ×ÕØM3(O7*&S%*&/S!&c,N!&94!W#
|2¼%#%>T N497*&#*&D)53(%2#<%N94S36%9*&%NP%:4KC!W#%N,423(S43653(7*"2­%!&%
#M,423(+O*&2%O#)43(15367*&2ª*&17)%<*"/<¸7<D¸<#D=aP:4)#%!&23(L/V<3(!W#%2>
Å c94-9497*&2##<;<!"/<S4!I#<%N#K945G,23Pb94%!W#;*&`53(/236%2>	 N4!&%N!&%72%S!&
%#	;!&/Q94N5*&c#O723YP5367*&2O%-,4!&4O2<#7N%*&/.7<D`2a4%!W#;*&53(/23b!W#
94,4<*"!W#g>T!W#`<#D.##<_¡43(+53(7*&2O%c3(c!I#§94S      94!&%#`7G23-!&%%9*&*&D
O4)4!&;42394#K94S#O723-Pb%*&/+43(+5367*&2O%2> Å /23694*&%%2Z94:7*&!"%Q%9<¬.!&2#
P\3N#*&D!W#;+94O523£P\3<#SPT35G23!&/O%D%2 %!W##*&D)9443(¨53(7*&2O%3(
!W#23(%!W#;CP¥3%:D!W#;K94`5G2#<!W*gP5G23!&#g>
»*W#=|PT94O97*&!"%:5*ID%S94O#OPT94O!W#g>c»-*W#%SÊK#=è.53(%2#c94
#`7G23P%*&/.53(7*"2­%aPYÑ[Ò2ÓbÔ2Ôc#Ñ[ÕÖ×¾ÕØ x #S  cÙ»-%:!&#<_¡Ê¼Í<|2Ê¾,42#C,3r_
!W#;`*&#>»-*W#O%94,N%	:4#O723YP^%<*"/<.53(7*&2O%PÑÒÓÔÔ-,42#O!&79!W#%T%:7;*
*W%%YP3(RÑÕÖ×ÕØ{,4!&4<3(N;2#23a3(;3(!W#;/V3(!W#<TÊ>	 N4!&%T/3(!W#<5G23£P¥3O%T723
94#K/3(!W#<| x %S*&%C94NP\*&*&,N!W#;.%97%!&#>T»-<*IC#+À!&%95*W2D%c94S#O7G23-P	%*&/
53(7*&2O%CPSÑÕÖ×ÕØ$,c42#=!&7:!W#%­7G_¡5=;<2#23M*&2%P3(ÇÑÒÓÔ2Ô<>?£#M94
2%,-S*&,D%N25*&D+/3(!W#<Ê­P¥3;2#23!W#;%:7;**W%% x 3(2*&*94aN94S%*"!"#
P*&2C%O252#%#¦94K,N2D=4,R%97;a*T*W%%.<3(.;<2#23>{»-*W#L~{;!&/%O94
#`7G23P%*&/+5367*&2O%-P5G!&!&//23(%!&#CPÑ[Ò2ÓbÔ2Ô#¨ÑÕÖ×ÕØ¨!W#K3(23O%94,
94b3¾523!"/<53(/23¾!&%	!I#K`4S­3(5G,23¡P*94#N%!W5*&N5!&!&/N53*&*"*
53(/23>bÃ	!W#*&*&DZg!W#)*W#{O,-2#C]^#+94S#O723QP%<*"/<53(7*&2O%cP	3-523!&/
%D%2)>
Ü2Þ

ß

¨àáJ¦âù ý ã  áJÂ++uMä'++'å

 ý +x+~+

!W#
 Å 
-ÎÎ
»-T 
»N?¯Î
»NÎz
XÎ
Ù 
ÁX Å
z»Nz
zg¿c
Å @ y
 zg
Ù Å 
ÙÎ
XT 
 Ï Å
k

Ñ[Ò2ÓbÔ2Ô ÑÕÖ×ÕØ
¼
Ê

è
~

|
¼
Ê
|¼

|¼
è¼
|

À
ÊÀ

À
|
|
¼
è
Ê

~
Ê
|
Ê|
Êa
¼
¼
||2
<

5!&/ &* 2
Ê
Ê
À

||

|
¼
Ê
|

||
è~
è
}

Ê~
}
}
|
|
¼
è
Ê

~
è
|
Ê
èÀ
|
¼
|À
|2¼è

ý

â'z+++Äæ;ç+µ{

5!&!&/ 5G23!&/
Ê

À
~

|
|
|
|Ê
|2~
|
|2À
è<¼
è
|¼
|2Ê
è<¼
è|
~
}
|
|
è
è
}
}
è
è
è<}

¼
|
|2Ê
Ê||

 b7*&.|dN?£#;3!&#P5<_,#Í<7_¡51<553(4%+7DE523!&/B53(/236%2dM%*&/
436+53(7*&2O%
 Q4S3(%9*&%3(/2*:4`4!&;4+5G2#<!W*P	3c553(a4KC%!&;#!0]2#*"D{!W53(/#§%!W#;*&
5 3(/23(%>.ÑÒÓÔÔO!&%S#*&D=7*&K%*&/KÀÀ>Æ}rÐ P-94.53(7*&2O%,4!&4È2#¨7%<*"/<B7D¨5<_
23!"#gZ	ÑÕÖ×ÕØ2#{#*&D%*&/.è~>0ÀrÐ)>S»-5!&!&#ÈP53(/236%!&%S/<23(D+%9%%(P*-72%
P-94O/23(D+!0F23(2#<`7G242/!&3aP9453(/23(%>S-S/2#¨K5G!&!&/)53(/23N#%!&%!W#;+P
ÑÒÓÔÔ`<#BÑÕÖ×ÕØM2#{#*&D)%<*"/<­G|>ÆrÀ ÐRaP9453(7*"2­%%<*"/7*&.7<D)5G23!&#g>cÁN2#Z
523a!&#!&%-3(2*&*&D!W5369#<T!W#3(23	!W#23(2%c94N%9%%3>  42#O!W#;3!W#;S%:7<_
;a**W%%N!W#<)ÑÒÓÔ2Ôc!&%-%<*"/7!&*&!"(D+3aN!&%N!W#23(2%+7<D.ÊÊG>Ær} Ð)>b?#K94O%-2%%%:7;*
*W%%O9ra.53(!I#M:4%23(4M53(%%`#M2#M4*I5M3(362394K%23(4¨!W#M)P/3<7*"
##23>+ N4)%.aP*&2C%O!I#2362%%+ÑÕÖ×Õ|
Ø Ñ%O523£P\3<#7<D=èè>Ær Ð§> Q4.!W#23(2%.P
94%<*"/7!&*&!"(D=3PÑ[ÕÖ×¾ÕØ=!&%3(2*&*&D)S233(!W#;)3(%36`3(!&#%>?£#+*WO%*&*
2%%	,c423(Nc%97%9#<!W*%95_¡5C!&%T7:!W#`,--*&O]^#.536P,Q!":4N%:*&*&23T3(%3(>
 N42#gZ94c*&2%<3(%+%5GZ!\>>94D)3(<7*"S*&%%97;<*&%-94T23NP\23
P\,$!W#<P¥23(2#%S<#),4% y X1536P	,-*&+3(!I36`#<DK!I#<P\23(2#%2>
 42#9r<!W#;¸M*&%23K*"r.:4È36%9*&%),-2<#36;#!&=94{P\*&*",N!W#;>¤ 53(/23
,4!&41*W3(2D¦%94,N%=39423%9a!&%(Pa3(D=724/!&3!W#L{%95G!Æ]¨C!W#M2#MP\2#B536]
P3( 9423(%2>»-5G23!&#§2#{2#9a!"*	:4<94234<3(=53(7*&2O%2#¨!&!&#*&*&DB7G`%*&/>
ÁQV,-/23Z!ÆP	S53(/23Y!"%N#%9!&97*&cP\3T·23(9!W#C!W#C942#O523a!&#,Q!"*&*#3C*&*"DK#
3(%9*&O!W#L{%!&;#!0]2#O!W#23(2%)PN!"%.523£P\3C#>2%.PN94CPO94.Ñ[ÕÖ×¾ÕØ$#
ÑÒÓÔÔN%94,$/<23(D!0F23(2#N7G242/!&3!W#K94­%T2a%%NT*&2%-#53(/23Y2#.7G!W53(/
!W#+O2369!W#)C!W#g>
ÜÜ

µ

¶ µ

wyz{

wyz{

?S!&%S!W#<23(%!I#;¨K]^#¦S,4:42323(9a!I#È4323(!&%!&%OPN53(7*&2O%O*&2=¨)4!";4
3O*&,@5G23£P¥3#{P:4+523a!&/+%D%2§>  +O!W#{,49423C94+4323(!&%!&%
9§!W#M#<9!W#%Oa*"!&(k
D È<#Ò
 9{C!W#=#<9!W#%##<_¡ÁQ3#M53(7*&2O% ¦!I#oi^2#{94
523¡P¥3#>Ã	!I36%2Z,-%94*&=#:4N94%4<323(!&%!"%Q#Q5*&*&D+23O!W#
94)523£P\3C#.aP94K5G23!&/K%D%2)>{ N423(+3(C;!W#%OP:¬.!&2#D¦P¥3O*&*-r!W#%P
53(7*&2)Zb3(;36*"%%P94O(D5OP*W%%2336!I#;{!W#¨9453(7*&2O%2>O-,-`2<#a*"2a%
7%236/%O2#2#!"%>
Ã	!W3(%*&DZ,-c2#C7%23(/c94-94c523a!&#)553(a4O!&%N%:5!W*&*&D+,-*&*Æ_%:!")P\3-53(7<_
*&2O%#<9!W#!W#;=*&!&¡D>= Q47G%.3(%9*&%36.7:!W#L!I#M:4.C!W#%­»T ZÙ  Zb#
XT J,4!&4+#9a!I#{#<D+53(7*&2O%,N!&94§a*"!&(D>  42#<#*&D!W#;+53(P3#%c,-S2#]^#
(,-3(2a%#%	P\3b94!&%2>	?£#O%94O!W#%cÑÒÓÔ2ÔQ!&%7*&N%:553(cÑÕÖ×ÕØ¨72%N!&4%-`4
%936#;23Q!I#<P\23(2#%·P¥3c4#*&!W#;+*&!&¡D¨94<#BÑ[ÕÖ×¾ÕØT>OÑÒÓÔÔS2<#+aP¥2#{23(!&//
 !0¬.2*& 
*&2%O,N!&94ÈP\,¢!W#<P\23(2#%2Z!\>>*&2a%`,c4%K23(!&/V!&#M,-*&L3(!I36+#<D!W#<P\23(2#%
7<D=ÑÕÖ×ÕØT>cÑÕÖ×ÕØ¦2#)%:553(OÑÒÓÔÔS72<%S!&c!"%7*&O.<r93#%6P¥3!&#%-P	94
53(P	;*:4SÑÒÓÔÔ2##523¡P¥3U72%`aP!&%Q]{3(23(!W#;)%{P¥3-%95235%!&!&#g>
 N4!&%c2#K!W#23(2%94ai!W7!"*&!&(D+P	94S53(P	%23(4)523¡P¥3O7<DÑ[Ò2ÓbÔ2Ô>
#*"DZ,-T#%!&23	,49423Y94Pa94aTc!W##<9!W#%TO%*"DOÁN3#3	##<_¡ÁQ3#
53(7*&2O%!W#oi^2#%N94N523£P\3C#NPg94N523a!&#553(4g>b»-#%!&23(!W#;O94N!W#%
,423(94523a!&#+55364K*&+%9%%6P*&*&D7G`55*&!&¨,2<#+#!&94-%9%%%
*&L7K79!W#¦P¥3ÁN3# x >;[>WZ»NÎzO%,*&*-%`##<_¡ÁQ3#È!W#% x >;>ºZXT N>b?#¦94
a!I#%b,423(N#43(O53(7*&2O%b*&­7G-%*&/ x #!":423b%2#<!W*&*&D#3,Q!":4523a!&#
P\2#¨94)52362#9a;.aPQ##<_¡ÁN3#=*W%%O!&%394234!&;4 x #94aS94%Ka!I#%O¨#
55G23O!W#94)97*&2>1 Q4!W#L3(2a%#¦P\3O94!&%2Z-4,/<23Z<5523(%CB7{94O94{%!W#;*&
53(/23(%C%94,@¨,-2rM523£P\3<#+!W#L94%+a!I#%>1 %:3(#;B3(*W!"#%94!W57G(,2#¹94
523¡P¥3#cP94N523a!&/536V/<23T#K94-PT,c49423-S53(7*&2Ë!&%NÁN3#3##<_¡ÁQ3#
*&#<3(2*&*&D+7·P¥#{!W#)94523(!WO2#<%2>
ÉûÉûÒÓ ÐgÓnÎ4"ÔÒuÔOØ&xÑËÐgÖÒocÕÔ,ÒYÐLÔ2ÕÎÕÏ[ÖÕj-'-ØoNÓnÒYÐÔ
Ë

@c5K#V,E,-#*&DK#%!&23(+:4S#O723P%*&/+5367*&2O%2>T?£#+!&!&#gZ!&N!&%N!W#<23(%!I#;
)#*&DS,49423c:4`%OP	%97;a**W%%3-*&2%2#§%95_¡5È94`53(PT%2<3(4§!W#
;2#23a*¥ZY!¥>>a*"%+P\3O53(7*&2O%O94a`2<#B7G)%*&/L7D=%!I#;<*"+536V/<23(%2>¨43(3#¦!WO%3(
%95G!Ia*"*&D!IC53(:#O!0P943(2ª53(/23(%O3()%L,N!&94!W#L!W#<23!"/<+53(/232#</!W3(#O2#%2>
 O3(%93(!&N3(%*&/%c94943(a!I#%»-T Zg»NÎz	Z[#zg¿cÌ#+36S;!W#;.#*&D
94S3#<!WO%c!W#+O369!&*\>
 b7*&ÊQ53(%2#<%94-3#!I­%,42#·9r*&!W#;43(S53(7*&2O%bP94T:43(	%!W#%2>  
O!&`*&*53(7*&2O%	:4*"#!&94237-%*&/7<DSN%!W#;*&536V/<23,42#,-3r<!W#;a*"#Z#3
7<D`#<DSPg94-523!"#O/V36!I<#%>»-*W#§|-P^94-9<7*"Q!"%:5*ID%T94N#­NP945367*&2)>
»-*W#%cÊ`<#+è53(%2#<-94S3#<!WO%NPÑ[Ò2ÓbÔ2Ô#=ÑÕÖ×ÕØ x #K  cÙ»-%9a!&#<_¡Ê¼ÍG|2Ê
,42#O,-3r!W#;S*&#Z<*W#%TS#KÀc943#<!WO%	P	ÑÒÓÔ2Ô-,c42#O!&T79a!I#%%97;a**W%%
P3(«ÑÕÖ×ÕØM,4!&4¨36S;2#23a=3(;3(!W#;K/V36!I<#%O|O#=ÊZ^36%95!&/*&D> Å 94c94
3#<!WO%-!W#*I94c;2#23!&#K#%*"!"#)!WOcP%97;a**W%%2Z#K94c93#%:O!&%%!&#
LÑÒÓÔÔ>B»*W#L~¨!&%95*WD%:4+3#!I­)P­Ñ[ÕÖ×¾ÕØE!0PS!"C79!W#%7_¡5M;2#23
*&2%CP3(ÇÑÒÓÔ2Ô<>1?#¹942a%),-+*&,D%25*&D1/3(!W#<.Ê{P\3O;2#23!W#;B%:7;*
*W%%2>cc*&%)94%O3#!I­%!I#*WK94`536253(%%!W#;)PÑÒÓÔ2ÔO#¨9493#%:O!&%%!&#¨#

ÜIh

ß

Å©B° ³­O¬Q½

¨àáJ¦âù ý ã  áJÂ++uMä'++'å

 ý +x+~+

ÔÕ4Ö+×Q×

Ý4ÞGßàGàGáGâGã

ä4å æ §

Ý4ÞGßàGàGìGâGã

ä4å è §

Ý4ÞGßàGàGðGâñ
Ý4ÞGßàGàGðGâGã

ÔØÙÚrØÛ

¦dµ±¬D©B¬Dµ´Q¬DÜ³¨4§¯¬Q·

¨·¨ Åª¦O¶¬

â'z+++Äæ;ç+µ{
ý

­O¬Q½t½t¨

´Q°½|År¬Qª¦Oª¦O¶¬

ë4§

ç

ä4å æ §

ë4§

¢ î4§
ç

ä4å è §

¢ î4§

í ¢4¢ §

¢ è §

ä ¢ §

¢ ï4§

é î4§

å §

ä ï4§
ç

ç

ä ï4§

ç

æ §
ç

ç

æ §

ç

ä è §
ç

ç

äxè §

ç

é ë4§

æ §
ç

é ï4§

æ §

ç

í é §

å §
ç

ä ¢ §

å §

ç

äxèêé §
ç

í4îï4§

¢ è §

í è4è §

¢ æ §

ä ¢ §

ç

é î§

å §

å §

Ý4ÞGßàGàGòGâGã
ç

ç

ç

Ý4ÞGßàñ àGâñ
ç

ç

Ý4ÞGßàñ àGâGã
ç

ç

Ý4ÞGßàñGñ âñ

é ï4§

Ý4ÞGßàñGñ âGã

ä ¢ §

´Q°G° År¬D©B¨ª¦O¶4¬

óGßGôàGàñ âñ
ç

ç

ç

ç

æ §
ç

æ §

óGßGôàGàñ âGõ

¢ íï4§

í ä §

è §

è §

¢4¢ §

í ä §

è §

óGßGôàGàñ â4ö

íí4§

¢4¢ §

é §

é §

è §

¢¢ §

é §

óGßGôàGàGãGâGã
ç

ç

ç

ç

æ ë4§
ç

æ ë4§

óGßGôàGàGõGâñ
ç

ç

ç

ç

í4ë4§

ç

í4ë4§

óGßGôàGà4öâGõ
ç

ä í§
ç

æ §

¢ î4§

ä í4§

æ §

óGßGôàGàG÷Gâñ

æ ¢ §

¢ äxè §

è §

è §

ï4ë4§

æ ¢ §

è §

¢ î4§
ç

ç

¢ î4§

óGßGôàGàGòGâñ
ç

ç

¢ î4§

óGßGôàGàGòGâGõ
ç

ç

ç

ä æ §

¢ å §
ç

¢ å §

óGßGôàGàGòGâ4ö

é í4§
ç

ï å §

é î4§
ç

é í4§

é î4§

óGßGôàñ àGâñ
ç

ç

¢¢ §

æ §
ç

ç

æ §

óGßGôàñGñ âGõ

¢ å §
ç

¢ ä §

¢ ä §
ç

¢ å §

¢ ä §

óGßGôàñQöâGõ

¢ ë4§
ç

¢¢ §

¢¢ §
ç

¢ ë4§

¢4¢ §

ç

óGßGôàñ ÷GâGõ
ç

ç

ç

å ï4§

ç

å ï4§

óøGÝGàGàGõGâGã
ç

ç

ç

ç

ï æ ï§
ç

ï æ ï4§

óøGÝGàGàGõGâGõ
ç

è î§
ç

ç

é ï4§

è î4§

é ï4§

óøGÝGàGàGõGâ4ö
ç

¢ æ §
ç

ç

í é §

¢ æ §

í é §

óøGÝGàGàGõGâGá
ç

ç

ç

ç

¢ î4î§
ç

¢ î4î4§

óøGÝGàGàGõGâGð
ç

ä ë é §
ç

ç

í ä §

ä ë é §

í ä §

óøGÝGàGàGõGâGò
ç

ä4å §
ç

ç

ä ¢ §

äå §

ä ¢ §

óøGÝGàGõ4öâñ
ç

è î§
ç

ç

å î4§

è î4§

å î4§

óøGÝGàGõGìGâñ
ç

¢ î4ë§
ç

ç

¢ î è §

¢ îë4§

¢ î è §

óøGÝGàGõGðGâñ

ç

ç

í è §

¢4¢ î4§

í è §

¢4¢ î4§

¢ î4ë4§

ç

¢4¢ î§

óøGÝGàGõG÷Gâñ
ç

¢4¢ î§
ç

ç

¢ î4ë§

óøGÝGà4örñ âñ
ç

í æ §
ç

ç

í4ë4§

í æ §

í4ë4§

óøGÝGà4öãGâGã
ç

ç

ç

ç

ï4ë4§

ç

ï4ë4§

óøGÝGà4öãGâGõ
ç

ç

ç

ç

ë ¢ §
ç

ë ¢ §

óøGÝGà4öãGâ4ö
ç

ç

ç

ç

é4ä §
ç

é4ä §

óøGÝGàGáGðGâñ
ç

¢ ä §
ç

ç

ë4§

¢ ä §

ë4§

óøGÝGàGìGàGâñ

ï è §
ç

ä î4§

ä î4§
ç

ï è §

ä î4§

óøGÝGàGìñ âñ

ï è §
í ä £ é4ù

ç
ïî £ î ù

¢ å §

¢ è §

ïî £ î ù

é4é £ î ù

ç
èêä £ é4ù

ï è §
èêä £ é4ù

¢ è §
¢ îî ù

 b7*&`Êd	?#<;3!&#KP	5<_,#Í7G_¡5.<553(4%7<D.523!&/`536V/<23(%2d	3#<!WO%

ÜI

µ

¶ µ

wyz{

wyz{

!W#;3!&#{PT:4`*&2C%2>S»-<*IC#K;<!"/<%943#<!WOOPNC5!&!&//<23(%!&#{PÑÒÓÔÔ
#MÑÕÖ×ÕØ x ­!I#!WO©P	943#<!WO%aPT*W#%SÊ.<#è>-Ã	!W#*&*&DZ!W#{*W#¨C,2#
]^#)943#<!WOP3523!&/%D%2 x O!W#!WORP94S3#<!WO%-P<*IC#%ÀO#+~>
 N42#<93(ú
D Qû+.­2#%N94-94S5367*&2U*&=#N7%*&/{,N!&94!W#=|2¼¼<¼S%#%2>
!W#S*&*ga!I#%-#<9!W#Ca*"!&(DK9436%9*&%N3(72394<#943(%9*&%-/23Y94,c4*&
      >Î3Q523a!&/S53(/232#K%*&/Sa*"*¾*"!&%53(7*&2O%Z,42362%ÑÒÓÔ2Ô·!"%Q#*&D+7*&S
%*&/KèÊ>ÆrÀ Ð§ZÑÕÖ×ÕØ¹#*&D¨¼>Ær¼ Ð§>ÌC5!&!&/)53(/23Q#%!&%!W#;¨PÑÒÓÔÔ#1ÑÕÖ×ÕØ
2#=­23(*&D%*&/~Ê>ÆrÀ Ð©aP9453(7*&2O%> Å #*"D¨94C%9%%`37`*&%):4.3#<!WO%
3(Q*"2<3(*&D.!W53(/C,42#.%!I#;K523a!&/536V/<23> N43#<!WO%N3(NaP¥2#­23(2%)7D
%97%:#!Ia*bP3(% x !W#¨%95!&OP:4OPa94aS3##!W#;+94O(,-53(/236%!I#¦53*&*&*T#%:O%
(,N!&S%O4K9*»  @$!I­2>
 42#O%9D!W#;943#<!WO%N#.53(P\%	79!W#)7DKÑÕÖ×ÕØ{,-N2#O7%23(/N94P¥*&*&,-_
!W#;>S?¥PT%95_¡5%OPÑÕÖ×ÕØL<3(3(2*&*&D+OK2336!I#;¨3(%36`3(!&#%Z!W#¨*WO%*&*
2%%N·%97%9#<!W*[%95_¡5K!&%N7:!W#>TO!WO%6'1P\3b!W#%9#!W#C94»QÎz+!W#<',-
4/N94Q%!&9!&#C,423(#O3(%363(!&#K9<r%T5*W7-3(3(236!I#;O:F%-*&*",¹]^#_
!W#;536P\%QP%23>-?#):4!"%%!":!&#gZ[94S%95G_¡5%S3(*",S>-zgS%c9rS­*"<%23c*&r)aN94
3#<!WO%PÑÒÓÔÔ,42#¨%!W#;)%97;*b*W%%2>  42#{#%!&23(!W#;+:4`3(%9*&%aPT/V3(!W#<|Z
9436%9*&%T%94,L94aTS#!&/<#.#!W#<P¥3O.;<2#23!&#P%97;**W%%%:*&*"DC%-#
2#<9!&*`4O;a!I#g>Z#*&Dr¼ Ð¤P945367*&2O%N2#7G%*&/)%!W#;94!&%-/V36!I<#2
> ÎT36!I<#NÊZ
4,-/23Z%94,N%-!&OO%9!"%6P3(D.7G242/!&3>TÁQ2#Zg#K!W#*&*&!&;2#<;2#23!&#KaPYO%:7;*
*W%O5*3(2*&*&D)%%:3(#;*&DK!I#oi^2#O94:¬K!"2#D>
	 ÷=ÃxÇ
'ÃxÃ 
ü

? #<;3!&#P5<_,#O#.7G_¡5O53(/23(%T7<DS25*&D!W#;O523a!&#O!&%T/236D`53(­!"%!I#;
!W#=:4]*&MPa=!&#g>)¿SK{23(9!W#¨%:3(2#;94%O#B,-2r#%%%P53(/23(%
P\*&*",N!W#;!0F23(2#<53a!";O%2Z4#!&%c94-936DOO7!W#S94%:3(2#;94%N7<D.523!&#
2#{*&*",Ì#§!W53(/2O2#<aPT94S!&/C%D%2)>Î3c553(4§PTO7!W#!W#;)5<_,#
#=7<_¡5¨53(/236%7<D53(%%!W#;{5<_,#);<2#23¨%97;**W%%S!W#=K7_¡5
53(/234!&/%S:4!"%`7!W#!"#B7<D+!W#<93(!I#;¨;*0_3(!&2#:!&#{!W#+{7_¡5¨53(/23
94%O7!W#!I#;{%93(#;3(#<#D#936*O4#!&%9O%O#¨;*0_!W3(=%23(4g>S N4%
P7<_¡5­;2#23K*&2%-!W#K5<_,#C53(/23	2#­#:3(!W7S%!&;#!0]2#<*&D36
53(P	*"2#;<94%%:4K94a53(P¥%-2#{7·P¥#),Q!":4)%9a*"*&23c3(%36%2>
Ùc*W)553(a4%P\3	%955G3(!W#;5<_,#.7<D.7G`_¡5O!W#<P¥23(2#O*&%!W#*&Da!I­
c25*&D!W#;7G_¡5)23(2a¨*"2C%c!I#¦5<_V,c#+53(/23>!WO!&*W3.3cO94=7D
4<## x |2}}a<#Ã^4% x |}}Z<|2}}}¾*&2%-3(N2362O!W#.53(2536%%!I#;54%#
94-!W#5T*W%%-3(N;­2#7<DS94%-P¥3O*Ia%2> N4Na!I#­!ÆF23(2#QP^94%<553(4%
#¨3c553(a4{!&%94r!W#=aPT94%=*&2%> Q423(Zg94 y XE!W#<P¥23(2#KO4<#!"%:©!"%
%{!I#§3(23-;2#23*"2C%2>- N4!&%4a%N94`a/V#<9;:4-!I#§%O2%%('E!W#K#:3%
34#!&:'A53(P*&2#;:433(%363(!"#%3(N;3#<>	ÁN,-/23Z<94c*"2C
O4#!&%9O%T%7<DSÃg4% x |}}7gZ|}}Z<|2}}};2#23!&7
 2%kD *&2C%2>	ÁN2#Z:4!I3
5<2#!Ia*,S>Æ3>2>94%!&SPb94`3(%3(S3(!&#§!&%*&!WO!&>
Îc:423S553(4%O936D+D#O!&2*&*&DB23(2a#!&O*&2%O3(!W#;=:4.53(P3#¦PN94
y XU53(/23 x c%934# !"r*\ZO|2}}ÊG½?,N#CZS|2}<}½c%934#Eªzg/*W#ZO|2}}>
Ü

ß

¨àáJ¦âù ý ã  áJÂ++uMä'++'å

 ý +x+~+

ý

â'z+++Äæ;ç+µ{

QP¥23Q24{%9%%(P*	%*W!&#{PN%97;<*	*&2)­!";4S7G`;<2#23=#=¨K94
!W#5*W%%2>= Q4+!WÚaP94!&%r!W#LP*&2C+;<2#23!&#M!&%O=53()*"2C%O94O3(
7*&K3(K94K%23(4=­#O7D¨*&!WO!W#!W#;L3(252B%97<_!"#%2>Î#K23(!&!&!&%9
3(;<3(!W#;94!&%r<!W#+Pb*"2C;<2#23!&#K!&%N94·Pa:4-!"c!&%#*&23Q,49423Q3-#%:P*
*&2%K2#7+;<2#23>E N423({!"%)#M;3#<K94*&2C%.2<#17¨53(36!I#;
9453(P3#¨,4!&4È2#{#:3(!W7))53(P6Zg!\>>g,c4!"4¨2#¦7(
 936:_¡%j >Ã^3(9423O3(Z
%*W3(2D¨O2#!"#Z94O;2#23a¨*"2C%S3(O%9*&*&D=#S%c;2#23*	%S5<%%!W7*&
!W#%9#<!W!&#%CO!W#;=P3(«94)%*W!&#%P%97;a*"%K53(/!&%*"DL%*&/>1 N4!&%2#L36
94S55*&!&27!&*&!&¡D{PTS*&2C*&94;4K:4
 ;2#23*&!&j )53(aP*&7GS3(:_¡%KP\3N3(:P!W#;
94{!I#5)*W%%2>Â N4%2ZN*&94;4L%O43653(7*&2O%)*"E#*&D17G%*&/1,N!&94%94
*&2K4#!&% x %`c%934<#+Rzg/*W#ZT|}}Zg#)%9<7*"O%9%%`4%S7G2#=3(253(
/23O{*I<3(;)%OP5367*&2O%2>L N4+!W#M!&%9/#<9;%aP*&*553(4%O,4!&4L#*&DL!W
N%:553(!I#;K5<_,#)536V/<23(%-3(!&;!W#·P3(R94cPN94Q!I#§%O!W#%2Z%95G!W*&*"D¨!0P
*&!"(D{!"%!W#</*&/Zg%95G235<%!&!&#<_¡7%B536V/<23(%N*&23(*&D¨95G23£P¥3 y XE53(/23(%2>N N4%2Z[!W#
%94{!W#%c!"SC2D)7O3(S%2#%!I7*&./*&5{4#!&%!W#+3(23N.%955G3(c94`­3(
5,-23£P*7_¡5)53(/23-:4#K94,-2r23-5<_,#.536V/<23>
?£#O3(23b!IC53(/7<_¡5C53(aP^%2364O7<D­%!I#;5<_,#5G23£P\3O!W#<P\23(2#%-94
P\*&*",N!W#;553(4%T4/c72#C25*&VD<>	Ã	!W3(%*&DZa;!W#O#536V/<23 x 94N7G`_¡553(/23
!&%%%!&%L7<D=*W%%23(!&/MP3(«#942353(/23 x 94.5<_,#=53(/23>+ N4)553(4
P3(U*&!0F x |}}Ê-%%N*&2C%;<2#23+7<D­;!&*&!W#23c!&#§%D%2 x <#+#
%97;**W%%9N!W#¨3(23N.%955G3(3(%*W!&#<_¡7a%B53(/23(%>-¿S`.94*Wr§PT;a*3(!0_
2#<9!&# x %O%23(!W7J!I#E!&#Ê>ÆÊ­94!&%O:4*&#KD!&*&E#</!W#!W#;13(%9*&%K!W#
53!">#*&DZ94236S3(553(4%N<r7G_¡5.536V/<23(%NO3(c;*0_!W3(¨7D
P\3(!W#;.:42R,-3r­#*&D),N!&94)%OS3(*&/V#<c*I<%%,c4!"4¨3(7<D.5<_V,c#K2*0_
2*W!&#%2> N4­94%-%236!I7G7<D<#!"*W4#§N*\> x |2}<~Z!&r* x |2}}aZ#)Áa%;,N
*\> x |2}}Y93#%6P¥3¢­%NP*W%%!W#<.#:423-*W%S%N,4!&4§!&%942#K/*W{!I#{
7<_¡5¨<##23> N4%95G!0])93#%(P\3C!&#+536V/!&%`KO7!W#!&#ÈPN5<_,#¨#
7<_¡5C53(%%!W#;.#)53#%-947G_¡5O/Va*Ia!&#K`36*"/#<*W%% x ,4!&4.7G23
C##!&#¨)K53(aP;a*I> N4%2Zg7</!&%*"D{947_¡5{53(aP%2364{7O%S­3(
;a*	3(!&2#>)*&%{94)O94=%23(!W7E7D=zg/*W#M`a*¥> x |2}}<À53(/!&%+36*"/#D
%!I#;ÈP¥3C7_¡5M2*&2*W!&#%2>$-%1#M5<_V,c#L53(aP·25%O94¨3(*&/V#DLP
)*W%.!&%SD#O!&2*&*&DM23O!W#M3(!W#;:47G`_¡5+2a*"2*W!"#g>+?#¦#<93%)3
O94)!W#)94%`553(4%Q94S7_¡5)53(/23-4%Q9r<*":4,4*&`53(P:%9r[>TÎ3
553(4¦P\3%!I#;L5<_,#M;2#231%97;*N*W%%K!W#¦7_¡5L53(/23O%)#
53(/!")+36*"/#D=%!W#;aP7<_¡5¦!W#<P¥2362#7O%955G3(%94.7<_¡5È!I#<P\23(2#
53(%%7<DO%!W5*&!0P¥D!W#;.94Q3(!&;!W#*;<*\>	 N4%Z94536P*&2#;94KD`7G%:43(2#>bÃ^369423£_
O36Z53(%TP94N%23(4%95aNP947_¡553(/23Z,4!&4#<9!W#36*"/#<N*W%%N7
D+7O!0¬.2*&S.2#O23Z2#¨7G`:3/23(%+7<DC%!W#;*&!W#<P¥2362#,4!&4¨53(/!&%*I<3(;
%2364)3(!"#%2>
¨íð9íÅ<í  Ç íÃ
ý

##!"gZ`>ºZV$z¾#;25GZXQ> x |2}}a>55*&D!W#;.z¿c_¡3(%*W!&#OSc*Ia%%TP##<_¡43#­*"<;!&
53(;3<O%2>	Npouo&tw\qul¨fN>SwYqt ± þ ä Ö Z ß x Ê<ZÊè|4ûÊaè>
ÜI»

µ

¶ µ

wyz{

wyz{

c%934#gZ-ÎO>WZT«zg/*W#Z-¿> x |2}<}|2> y XT NXÎcÙgdÁN!&;4523£P\3<#+9436253(/23(%
%!W#;O**&!WO!W#!&#g>?£#¡ÿpw\fsOnw\t:j-t9nfl[qulÐ¡Ý%9nX|Tqvlfl[fTfN>)f2fjX|cNo"t:jf2t>
~ *I<,-23-c22O!&  7*&!&%9423(%2>
c%934#gZÎO>WZËzg/*W#Z¿> x |2}}> N4S%P	*"2C%N!W#):4`O**&!WO!W#!&#¨53(:_
3(
> fp:ln<ofN> ÿ·pw\fsOnw\t:jt:nflqvlÐ<Z Ô
	 x |2Z^|<|2û^|[|>
c%934#gZÎO>WZJ!&r*\Z y > x |2}}Ê>»Q4!W#;S#C*"2C!&!W#;`!W#­*[*"!WO!W#!"#943(2
53(/23(%2>	?# ä (f2m:t9t:jqvlÐcfN>.ÿp%Ti ÔoÔ Z55g>ÊÊaûÊèG>53(!W#;23Z[z Å ?N~¼<>
-4!W3Z-z	>WZT #!W#;23ZNÁ> x |}}>¦Ù,c3(!&:_¡7%!"#*N9436253(/!W#;M,N!&94
%*&!&#+#{%!W5*&!0]2!&#g>fp:ln<ofN> Ö f:ÐqvmSnl[jTf<sNhgpw\nw\qvfl[Z x èZÊ|ûÊG>
-#!&*W4#gZ	ÃN>WZ y !&23Zg¿>WZa;!&/^ZÏ`>WZb @Q*"*W<##gZ[> x |2}~<> y ;!&%%S#=9423c%93#;
,D%+!W5*&2O2#<*&;!&+53(<;3O%>.?# ä (f2m:t9t:jqvlÐOfN>wYq/ÿ ±þ ci ±þ ÿe
|sQhfqupsUfl ä 9qvlmqh^o&tfN
> nw\nÏn
t |w\t2sZ55g>¾|4û^|2À>
#!W#Z y > x |2}}~<>.Î#¦94)3(#%93!&#¨P536P\%S!W#¦!&%93(!W7L943(2ª53(/!W#;dO
O!0]{*I<%:_!0F¾%!"#­94>fp9l[nogfN>|sÏf<o"qvmfsQh^pw\n<w\qufl[Z ß¡Ô x ZÀ¼<ûÀÊÊG>
#!W#Z y >WZUÁQ%!W#;Z > x |2}}À<> N4*W%:_!0F%!&#LO:4*&;<D+P\3·!"%93(!W7M:_
!&#g> à pl[jnsOt2l[w\n ± l> f9sOnw\qvm:nt2Z ß Z|2ûÊ¼>
»-#36DZg>XN>ºZ y 2?#<%94gZG¿>![>WZ y D23ZÙ`>O> x |2}<}¼>b¿cÙXTgdÄ!&%93(!W7=
3(2%#!W#;%D%2)>	?# ä (f2m:t9t:jqvlÐcfN>pÿpÿÀÿ ± i 	#" Z55g>ûÀ>
¿2#!W#;23Z$[> x |2}}À> ~ #V,Q*";<:_¡7%+!&%:3(!W7)%23(4)%!W#;. -2<S,-3r>g?# ä ¡fm9t:t:jqulÐ
fN> ± ÿ[i 	 Z55g>G|4û><c?v_  36%%2>
¿2#!W#;23Z%>WZAÃ^4%2Z¿> x |}}>XT#4#!W#;O#</2#<!&#*%2364O%D%2O%	,N!&94O*&!0_¡;2#<
4#!&%2dT2%%9D>?£# ä (f2m:t9t:jqvlÐafð> ± »ÿi 	#& Z55g>[|2}ûÊ<¼>?XXTXL»-C523
!&(D>
¿2#!W#;23Z#>ºZ2LÃg4%2Z y > x |2}}>a*3(!&2#<S!&#*<943(2H53(/!W#;>?£# ä ¡fm9t:t:jqulÐ
fN
> ' ± i 	 Z55g>èè ûèÀ[>53(!W#;23Zgz Å ?-~G|>
¿2#!W#;23Z(>WZÃ^4%2Z y >WZVÃg4%2Z y > x |2}}<>ÁQ!";4`5G23£P\3#T   %D%2­%7DO7!W#!I#;
%/23*g?-O94%2>T?# ä (f2m:t9t:jqvlÐcfN> ± ).ÿ ±* 	$+ Z55g>|¼Êû^|2¼<>
Ã	!&!W#;Z y > x |2}<}~> à qvwvi,N(jt Ö f:ÐqvmSnl[j_ÿ·pw\fsOnw\t:j=eqt:f(t2s ä (fÉ2qvlÐ<>	53(!W#;23>
Ã^4%2Zb¿> x |2}<}>»5G23!&#ÈPN5<_,#=#M7_¡5¨943(2Ú53(/236%`7<D%:7;*
*I<%S93#%(P\23>	?# ä (f2m:t9t:jqvlÐNfN>qÿ ± 	i 	#& Z55g>|2Àû^|2~}>53(!W#;23Zgz Å ?c|<~>
Ã^4%2Zc¿> x |2}}7>Ì»-5*&!W#;E%993a!&#<_¡7%Â536V/<23(%+7DE4<#;!W#;5<%!&!&/2Í#;!"/<
!I#<P\3C!&#g>T?£# ä (f2m:t9t:jqvlÐafN>ejÿ·i 	-& Z55g>è|2ûèè|>53(!W#;23Zgz Å »Q¨|2è}>
Ã^4%2ZQ¿> x |}}2>EÙc!I362O2#6_¡7%$523!&/¨943(2Ç53(/!I#;[> ?£# ä (f2m:t9t:jqvlÐafN>
¡% Ö ± ÿ·i 	-& Z55g>|2è}ûg|2Àè>53(!W#;23Zgz Å ?c|}G>
ÜIÇ

ß

¨àáJ¦âù ý ã  áJÂ++uMä'++'å

 ý +x+~+

ý

â'z+++Äæ;ç+µ{

Ã^4%2Z y > x |2}}<>Ã	*"!W7*&+53(aPu_¡3(25*WD¨,N!&94M423(!&%!&%2>)?# ä (f2m:t:t9jqvlÐaSfN>,% ä ± ÿ
| û^|2Ê>53(!W#;23Zgz Å ?c|2èÊ<è>
4

* 	$+ Z	55g>

Ã^4%2Z y > x |}}>ÌÙc*&/V#D<_¡7%H*&2L%*"!"#JP¥3)­**"!WO!W#!"#Ä%!W#;1*WD
97*&2K2#O23!&#g>-?# ä (f2m:t9t:jqvlÐNfN>D%..ÿ ± i 	#& Z55g>^èa~ûèÀ<¼>#4#  !&*&DÄ#%2Z
zg>
Ã^4%2Z y > x |2}}<7>gD%2Ì7%:32db!I­!"*W36!"(D<_¡7%{*"2C;2#23!&#­P\3	O*^*&!WO!W#_
!&#g>T?# ä (f2m:t:t9jqvlÐaNfN>.ÿp%Ti Ô Z55g>èèûè>53(!W#;23Zgz Å ?c|Ê|<>
Ã^4%2Z y > x |2}}}<>)zg2{;2#23a!&#¨P\3O**&!I­!I#a!&#17<D=O7!W#!W#;=5<_,#M#
7_¡5K!W#<P¥2362#>?£# ä (fm9t:t9j<qulÐfN> ± /.ÿ ± i 	
	 > y 3(;# ~ <P##gZ.552<3>
Ác33(!&%#gZ#[> x |}}~>Î5!I­!"!W#;53(P%2364!W#OO**&!WO!W#!&#g>?# ä ¡fm9t:t:jqulÐ	fN>.ÿ#%i
#Ô 0 Z55g>èG|2èûèÊ<>53(!W#;23Z^z Å ?|<|2¼>
Ác%;,NZÙ`>WZ-?#Z ~ >ºZNÎ49GZtÏ`>WZN ~ %:4!IO3GZ y > x |2}<}> Å #<_¡43#;!&¨%%K
!I#353K5<_,#¨!W#<P\23(2#)!W#=7G`_¡5=943(2Ú53(/!W#;>?£# ä (f2m:t:t9jqvlÐa`fN>
.ÿp%Ti Ô Z55g>¾|2~ û^|}¼>536!I#;<23Zz Å ?·|2Ê}>
?\,N#Z ~ > x |2}<}>Kzg2¨4!W#;{P¥3S   N   _¡7%M5<_,#È943(2ª53(/23>)?£#
ä (f2m:t9t:jqvlÐafð>.ÿ#%i Ô GZ55g>|~û^|2~¼>53(!W#;23Zgz Å ?c|2Ê}>
~ 3£PZÙ`>XN> x |2}<À>[¿2594<_\]^3(%-!&23a!&/:_252#!W#;d-#K5!W*­!"%%!W7*"93(c%23(4g>.ÿ ± Z
ß + Z}Áû|¼}>	X	*&%/!&23  7*&!&%9423(%Sc>dÎO> x Å 3694<_¡ÁN<*"*W#>

zgZGÙ`>WZ y 2D3Z ~ >WZË*&*&23Z»> x |2}}a>»-#<93(<*"*&)!W#<;3!"#Pb942N3*&S!W#`##:_
!&#K97*&2§2*&2*"!\>fp9l[nofN>pÿpw\fsOnw\t:jt:nflqvlÐ<Z Ô-0 ZÊ}ûèè>
zgZÙO>WZ	4##gZ[>WZT-D23(*\Zg>ºZ !W7*\Z  > x |2}}<Ê>¨XT NÁcXTÎOdb 4!";4<_¡523£P\3<#
943(2U536V/<23
> fp:lnofðp
> ÿpw\f<s`n<w\t9j-t9nfl[qulÐZ & x ÊZ|2èûÊ|2Ê>
zg/*W#Z¿> x |2}~<> y 4<#!"2a*N943(2`_¡53(/!W#;B7<DBO*-*"!WO!W#!"#g>1f<p:lno-fN>+wYqt
ÿZ Ô  x Ê>
zg/*W#Z¿> x |2}<>.ÿpw\fsOnw\t:j=eqt:f(t2s ä (fÉ2qvlÐÝNn Ö f9Ðqvm:no[naqº> Å 3(94<_¡ÁQ*&*W#>
zg/*W#Z¿>WZ<ÙZ<¿>WZ  !&*&%#gZ¿> x |2}}À>T N»NÁ y ÎcÙXQdT N»NÁ y ÎJ,N!&94CÙXY*&/V#Dg>
fp:lnofðp> ÿpw\f<s`n<w\t9j-t9nfl[qulÐZ Ô Zè<ÊÀûèÀG|>
y 3r/!&4gZg>WZÄ2Z  > x |2}}<è>?#<P\3C!&#­]*"23(!W#;d*&!&#{O4#!&%9O%N!W#)*&23#!I#;
%D%2O%2
> n<mqqvlt Ö t9n<9l[qulÐZ Ô-" x Ê<Zg||2èû^|À|>
y !W##gZg> x |2}}¼<>!2#<!&9!"/<36%9*&%T#23#!I#;94N!&*&!"(DOPg5*W#!"#<_¡7%*&23#!W#;>
ÿ9w\q 3mqun<o ± lw\t2ovo&q"Ð<t2l[m9tZ
 ß Zè~<èûè}|<>X	*&%/!&23!&2#  7*&!"%:423(%2>
y %23Z y >WZ?£72#%2ZÎO>ºZzZÙ`>WZ!W#7a4gZ$[>WZ[*&*&23Z»>WZ4##gZ$[>WZ y D3Z ~ > x |2}}>
 N4O**&!WO!W#!&#$53(/236%X NÁXÎª#X_¡XT NÁcXTÎO>4fp:ln<ofN>ÿpw\fsOnw\t9j
t:nf<lqvlÐZ #Ô & x Ê>
Ü2Ý

µ

¶ µ

wyz{

wyz{

Ùc7!W#%#gZ%> x |2}~<À>ÂC4!W#36!"2#<K*&;!&S7%K#C9436%*W!&#K53(!W#!I5*&>5f<p:lnogfN>
wYqtqÿZ Ôß x |2>
4<##gZ> x |2}}>L¿*&9¨_=7<_¡553(253(%%3­P\3O5<_,#¹943(2 53(/23(%2>
%D%2R7%93a2>	?# ä (f2m:t9t:jqvlÐcfN>.ÿ#%i Ôß Z[55g>û>53(!W#;23Zgz Å ?-|>
!&r*\Z y > x |2}<>R53(*&;)4#*&;D¨94362 53(/23d?£5*&2O2#<9!&#=7<D=#{2#
53(*&;C5!"*&23>5fp:ln<ofN> ÿ·pw\fsOnw\t:j6t:nf<lqvlÐZ$Z[èÀèûè<¼>
!&r*\Z y > x |2}}>l@c5%!&:_V,c#1O9V_!I#<235369!&#¹P:4O*N*&!WO!W#!&#E943(2_
53(/!W#;S53(3(QP¥3b!"#)#.7G!&#g> f<p:lno[fN>ÿpw\fsOnw\t:jt:nflqvlÐ<Z Ô-0 Z
|2} ûÊG|2¼>
*&!0FZO> x |2}}<Ê>E423(;2#%53a*"*&*g!&#C%D%2)>?£# ä (f2m:t9t:jqvlÐ-fN> à
)fK}_qf:h7 0 >
þ

 * 	ß

*&!0FZ`>ºZV9#23Z»> x |2}<}> N4N      53(7*&2H*&!W733(Dgd	» Å Ã¨3(*&2%-/g|>ÆÊ>W|<>%fp:lno
fNp
> ÿpw\fsOnw\t9
j -t9nafl[qulÐZ ß¡Ô Z|2<ûÊ¼èG>
*&!0FZO>WZÄ9#23Z^»> x |2}}<> N4O3(%9*&%cP	94S»-c¿SXb_9|2èOT   %D%2R5!&!&#g>
fp:lnofðp> ÿpw\f<s`n<w\t9
j -t9nfl[qulÐZ Ô#& x ÊZÊ|êûÊ~>
*&!0FZO>WZ9#23Z»>WZ Ï	2O2#!&%2Z > x |2}}a> N4N      53(7*&2Ë*&!I733(D>g?# ä ¡fm9t:t:jqulÐ
fN
> .ÿ#%i Ôß Z[55g>ÊÀÊûÊ~~>z Å ?-|>
 bO2Z > x |2}}<>	#*0P6>8fp:lnofð> 
ÿ pw\fsOnw\t:j-t9nfl[qulÐZ Ô#& x ÊZg|2}}ûÊ¼>
 !&2#74gZ-»>WZZ	>ºZTUÙcr[Z`> x 2| }}~>5a%%UÃ	*&23¡Î	236%!&#B¼G>Ê>+?£# ä (f2m Õ
.ÿp%Ti #Ô 0 Z55g>¾|4| û^|À>536!I#;<23Zz Å  ?·||2¼>
 *0PZSO>WZÇÃ^4%2Z y > x |2}}>Ú»-523a!&/¸5<3*&*&*.C$943(2 53(/!W#;>?£#
4#2r2#73(;23Z >ºZ *"*W#23ZcO> x XY%2>ÆZa|Vl[nsOqum Ö f2n<j9qºw\9q\Ïpw\quf<lx>f ä n(nouo&to
ÿ-hhgo"qvm:nw\quf<lZ55g>b|2Ê
} û^|À> ¾27#23>

ÜIü

Journal of Articial Intelligence Research 10 (1999) 353-373

Submitted 8/98; published 5/99

\Squeaky Wheel" Optimization
David E. Joslin

david joslin@i2.com

i2 Technologies
909 E. Las Colinas Blvd.
Irving, TX 75039

David P. Clements

Computational Intelligence Research Laboratory
1269 University of Oregon
Eugene, OR 97403-1269

clements@cirl.uoregon.edu

Abstract

We describe a general approach to optimization which we term \Squeaky Wheel" Optimization (SWO). In SWO, a greedy algorithm is used to construct a solution which is
then analyzed to nd the trouble spots, i.e., those elements, that, if improved, are likely
to improve the objective function score. The results of the analysis are used to generate
new priorities that determine the order in which the greedy algorithm constructs the next
solution. This Construct/Analyze/Prioritize cycle continues until some limit is reached, or
an acceptable solution is found.
SWO can be viewed as operating on two search spaces: solutions and prioritizations.
Successive solutions are only indirectly related, via the re-prioritization that results from
analyzing the prior solution. Similarly, successive prioritizations are generated by constructing and analyzing solutions. This \coupled search" has some interesting properties,
which we discuss.
We report encouraging experimental results on two domains, scheduling problems that
arise in ber-optic cable manufacturing, and graph coloring problems. The fact that these
domains are very dierent supports our claim that SWO is a general technique for optimization.

1. Overview
We describe a general approach to optimization which we term \Squeaky Wheel" Optimization (SWO) (Joslin & Clements, 1998). The core of SWO is a Construct/Analyze/Prioritize
cycle, illustrated in Figure 1. A solution is constructed by a greedy algorithm, making decisions in an order determined by priorities assigned to the elements of the problem. That
solution is then analyzed to nd the elements of the problem that are \trouble makers." The
priorities of the trouble makers are then increased, causing the greedy constructor to deal
with them sooner on the next iteration. This cycle repeats until a termination condition
occurs.
On each iteration, the analyzer determines which elements of the problem are causing
the most trouble in the current solution, and the prioritizer ensures that the constructor
gives more attention to those elements on the next iteration. (\The squeaky wheel gets the
grease.") The construction, analysis and prioritization are all in terms of the elements that

c 1999 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

Joslin & Clements

Analyzer
Blame

Solution

Constructor

Priorities

Prioritizer

Figure 1: The Construct/Analyze/Prioritize cycle
dene a problem domain. In a scheduling domain, for example, those elements might be
tasks. In graph coloring, those elements might be the nodes to be colored.
The three main components of SWO are:

Constructor. Given a sequence of problem elements, the constructor generates a solution

using a greedy algorithm, with no backtracking. The sequence determines the order
in which decisions are made, and can be thought of as a \strategy" or \recipe" for
constructing a new solution. (This \solution" may violate hard constraints.)

Analyzer. The analyzer assigns a numeric \blame" factor to the problem elements that

contribute to aws in the current solution. For example, if minimizing lateness in
a scheduling problem is one of the objectives, then blame would be assigned to late
tasks.
A key principle behind SWO is that solutions can reveal problem structure. By analyzing a solution, we can often identify elements of that solution that work well, and
elements that work poorly. A resource that is used at full capacity, for example, may
represent a bottleneck. This information about problem structure is local, in that it
may only apply to the part of the search space currently under examination, but may
be useful in determining where the search should go next.
Prioritizer. The prioritizer uses the blame factors assigned by the analyzer to modify
the previous sequence of problem elements. Elements that received blame are moved
toward the front of the sequence. The higher the blame, the further the element is
moved.
The priority sequence plays a key role in SWO. As a dicult problem element moves
forward in the sequence it is handled sooner by the constructor. It also tends to be handled
better, thus decreasing its blame factor. Dicult elements rise rapidly to a place in the
sequence where they are handled well. Once there, the blame assigned to them drops,
causing them to slowly sink in the sequence as other parts of the problem that are not
handled as well are given increased priority. Eventually, dicult elements sink back to the
point where they are no longer handled well, causing them to receive higher blame and to
move forward in the sequence again. Elements that are always easy to handle sink to the
end of the sequence and stay there.
354

\Squeaky Wheel" Optimization

Iteration: 1 Priorities: C,A,B
Late: A (20), B (30)

0

10

20

C

Iteration: 2 Priorities: B,A,C
Late: A (20), C (10)

0

10

A

20

B
Iteration: 3 Priorities: A,C,B
Late: B (30)

0

10

A

30

A

C

50

B

30

20

40

40

Task
A
B
C

Duration Deadline
10
10
20
20
40
20

50

C
30

40

50

B

Figure 2: Simple example
To illustrate the SWO cycle, consider a simplied scheduling example. Suppose we have
a single production line, and three tasks to schedule, A, B and C . Only one task can be
performed at a time. Execution starts at t = 0. The duration and deadline for each task
is shown in Figure 2. The objective is to minimize the number of late tasks. An optimal
solution will have one late task.
Suppose our initial priority sequence is hC; A; B i, and the constructor schedules tasks
in order, at the earliest possible time. The resulting schedule has two late tasks (B and
A). Suppose that our analyzer assigns one point of \blame" to each late task, for each
unit of time it is late. In this case, A, B , and C receive 20, 30 and 0 units of blame,
respectively. Figure 2 shows the prioritization, the schedule that the constructor builds
from that prioritization, and the late tasks with the blame assigned to each.
For the next cycle, the prioritizer must take the previous priority sequence, and the
blame assigned by the analyzer, and generate a new priority sequence. A simple prioritizer
might just sort the tasks by their numeric blame in descending order, resulting in the new
priority sequence hB; A; C i.
After the second cycle, tasks A and C are late, scoring 20 and 10 points of blame,
respectively. The new priority sequence is then hA; C; B i.
The third solution, constructed from this priority sequence, has only one late task, B ,
which receives 30 points of blame. At this point we have an optimal solution. If we continue
running SWO, however, as we might expect to do since we typically do not know when we
have reached optimality, SWO will attempt to x what was wrong with the current solution.
Here, since task B was late, its priority would be increased, and the resulting solution would
x that problem at the expense of others. (We would also enter a short cycle, alternating
between the last two schedules. We address this by introducing some randomization in the
prioritizer.)
Although this example is highly simplied, and there would clearly be better and more
sophisticated ways to implement each of the three modules, Figure 3 shows that the behavior
illustrated by the simple example is reected in a real domain. The gure shows the changing
position in the priority sequence of three tasks in the scheduling domain that is described
in detail in the following section. One task (\Job 24") starts out with a high priority, and
remains at a relatively high priority level. We can see that when the task is scheduled
eectively, and therefore receives little or no blame, its priority tends to drop, but it does
355

Priority

(high)

Joslin & Clements

(low)

Job 24
Job 26
Job 39
1

2

3

4

5

6

7

8

9 10 11 12 13 14 15 16 17 18 19 20
Iteration

Figure 3: Examples of priority changes over time
not have to drop very far before it ceases to be scheduled well, acquires a signicant level
of blame, and moves quickly back to a higher priority.
The other two tasks shown in the gure behave quite dierently. One task (\Job 39")
starts out with a relatively high priority, but this task is \easy" to schedule, with little
blame, even when it is scheduled late in the sequence. Over successive iterations, the
priority of such a task will tend to decrease steadily. The other task illustrated here (\Job
26") does just the opposite, starting at a low priority and moving fairly steadily toward a
high priority.
The following section discusses the characteristics of SWO that make it an eective technique for optimization. We then discuss implementations of SWO for scheduling and for
graph coloring problems. The nal sections discuss related work, describe directions for
future research, and summarize our ndings.

2. Key ideas

As the experimental results below show, SWO is a general approach to optimization. In this
section, we explore a few insights into what makes SWO eective.
It is useful to think of SWO as searching two coupled spaces, as illustrated in Figure 4.
One search space is the familiar solution space, and the other is priority space. Moves in
the solution space are made indirectly, via the re-prioritization that results from analyzing
the prior solution. Similarly, successive prioritizations are generated by constructing and
analyzing a solution, and then using the blame that results from that analysis to modify
the previous prioritization.
A point in the solution space represents a potential solution to the problem, and a
corresponding point in priority space, derived by analyzing the solution, is an attempt to
capture information about the structure of the search space in the vicinity of the solution.
As SWO constructs a new solution from scratch, the priorities can be thought of as providing
356

\Squeaky Wheel" Optimization

Construct

p
Analyze/
Prioritize

p’

s

Construct

s’
Priority space
Solution space

Figure 4: Coupled search spaces
information about pitfalls common to the current region of the solution space. If some elements of the solution have tended to be sources of diculty over some number of iterations,
increasing their priority makes it more likely that the constructor will handle those elements
in a good way.
One consequence of the coupled search spaces is that a small change in the sequence of
elements generated by the prioritizer may correspond to a large change in the corresponding
solution generated by the constructor, compared to the solution from the previous iteration. Moving an element forward in the sequence can signicantly change its state in the
resulting solution. In addition, any elements that now occur after it in the sequence must
accommodate that element's state. For example, in the scheduling domain, moving a task
earlier in the priority sequence may allow it to be placed on a dierent manufacturing line,
thus possibly changing the mix of jobs that can run on that line, and on the line it was
scheduled on in the previous iteration. One small change can have consequences for any
element that follows it, with lower-priority tasks having to \ll in the gaps" that are left
after higher-priority tasks have been scheduled.
The result is a large move that is \coherent" in the sense that it is similar to what we
might expect from moving the higher priority task, then propagating the eects of that
change by moving lower priority tasks as needed. This single move may correspond to a
large number of moves for a search algorithm that only looks at local changes to the solution,
and it may thus be dicult for such an algorithm to nd.
The fact that SWO makes large moves in both search spaces is one obvious dierence
between SWO and traditional local search techniques, such as WSAT (Selman, Kautz, & Cohen,
1993). Another dierence is that with SWO, moves are never selected based on their eect
on the objective function. Instead, unlike hillclimbing techniques, each move is made in
response to \trouble spots" found in the current solution. The resulting move may be
uphill, but the move is always motivated by those trouble spots.
357

Joslin & Clements

In priority space the only \local optima" are those in which all elements of a solution are
assigned equal blame. SWO tends to avoid getting trapped in local optima, because analysis
and prioritization will always (in practice) suggest changes in the sequence, thus changing
the solution generated on the next iteration. This does not guarantee that SWO will not
become trapped in a small cycle, however. In our implementations we have introduced
small amounts of randomness in the basic cycle. We also restart SWO periodically with a
new initial sequence.
Another aspect of local search is that typically each point in the solution space is associated with a single value, the objective function score for that solution. When we talk about
hillclimbing, we generally refer to the \terrain" described by this objective function score,
over the space of solutions. The process of analysis in SWO can be thought of as synthesizing
a more complex description of that terrain, by breaking a solution down into its component
elements and assigning a score to each. Prioritization then translates the analysis into a
\strategy" that the constructor can use to generate the next solution.
Assigning scores to the individual elements of a solution allows SWO to take advantage
of the fact that real problems often combine some elements that are dicult to get right,
plus others that are easy. In the scheduling problems presented below, some tasks can be
assigned to just a few production lines, while others allow for much more exibility. Some
have due dates close to their release time, while others have a lot of leeway. It is sometimes
possible to identify \dicult" elements of a problem with static analysis, but interactions
can be complex, and elements that are causing diculty in one part of the search space may
be no trouble at all in another. Rather than trying to identify elements that are globally
dicult by analyzing the entire problem, SWO analyzes individual solutions in order to nd
elements that are locally dicult. Globally dicult elements tend to be identied over time,
as they are dicult across large parts of the search space.
By assigning blame and adjusting priorities based on identied problems in actual solutions, SWO avoids dependence on complex, domain dependent heuristics. It is our belief
that this independence is particularly important in complex domains where even the best
heuristics will miss some key interactions and therefore inhibit the search from exploring
good areas that the heuristic incorrectly labels as unpromising. SWO uses actual solutions
to discover which areas of the search space are promising and which are not.

3. SWO for scheduling
This section describes an application of SWO to a ber-optic production line scheduling
problem, derived from data provided by Lucent Technologies. In this particular plant, a
cable may be assembled on any one of 13 parallel production lines. For each cable type,
only a subset of the production lines are compatible, and the time required to produce the
cable will depend on which of the compatible lines is selected. Each cable also has a setup
time, which depends on its own cable type and that of its predecessor. Setups between
certain pairs of cable types are infeasible. Task preemption is not allowed, i.e. once a cable
has started processing on a line, it nishes without interruption.
Each cable is assigned a release time and due date. Production cannot begin before the
release time. The objective function includes a penalty for missing due dates, and a penalty
for setup times.
358

\Squeaky Wheel" Optimization

3.1 Implementation

We describe the implementation in terms of the three main components of SWO:

Constructor. The constructor builds a schedule by adding tasks one at a time, in the

order they occur in the priority sequence. A task is added by selecting a line and a
position relative to the tasks already in that line. A task may be inserted between
any two tasks already in the line or at the beginning or end of that line's schedule.
Changes to the relative positions of the tasks already in the line are not considered.
Each task in the line is then assigned to its earliest possible start time, subject to the
ordering, i.e., a task starts at either its release time, or immediately after the previous
task on that line, whichever is greater.
For each of the possible insertion points in the schedule, relative to the tasks already in
each line, the constructor calculates the eect on the objective function, and the task
is placed at the best-scoring location. Ties are broken randomly. After all tasks have
been placed, the constructor applies SWO to the individual line schedules, attempting
to improve the score for each line by reordering the cables that were assigned to it.

Analyzer. To assign blame to each task in the current schedule, the analyzer rst calculates

a lower bound on the minimum possible cost that each task could contribute to any
schedule. For example, if a task has a release time that is later than its due date,
then it will be late in every schedule, and the minimum possible cost already includes
that penalty. Minimum possible setup costs are also included. For a given schedule,
the blame assigned to each task is its \excess cost," the dierence between its actual
cost and its minimum possible cost. Excess lateness costs are assigned to tasks that
are late, and excess setup costs are split between adjacent tasks.

Prioritizer. Once the blame has been assigned, the prioritizer modies the previous sequence of tasks by moving tasks with non-zero blame factors forward in the sequence.
Tasks are moved forward a distance that increases with the magnitude of the blame.
To move from the back of the sequence to the front, a task must have a high blame
factor over several iterations. We call this a \sticky sort."

Our current implementation has considerable room for improvement. The analysis and
feedback currently being used are very simple, and the construction of schedules could take
various heuristics into account, such as preferring to place a task in a line that has more
\slack," all other things being equal.

3.2 Experimental results

We have six sets of test data, ranging in size from 40 to 297 tasks, all with 13 parallel
production lines. The largest problem was the largest that the manufacturer required in
practice. We compare the following solution methods:
SWO

Applies the SWO architecture to the problem, running for a xed number of iterations
and returning the best schedule it nds.
359

Joslin & Clements

Data
Set
40
50
60
70
148
297

Best
Obj
1890
3101
2580
2713
8869
17503

SWO

Avg
Obj
1890
3156
2584
2727
8927
17696

Avg
Time
48
57
87
124
431
1300

TABU

Obj
1911
3292
2837
2878
10421
|

Time
425
732
1325
2046
17260
|

IP

Obj
1934
3221
2729
2897
|
|

Time
20
175
6144
4950
|
|

Table 1: Experimental results: scheduling
TABU

IP

Uses TABU search (Glover & Laguna, 1997), a local search algorithm in which moves
that increase cost are permitted to avoid getting trapped at local optima. To avoid
cycling, when an \uphill" move is made, it is not allowed to be immediately undone.

Applies an Integer Programming (IP) solver, using an encoding described in (?).

On the 297 task problem, SWO was far more eective than either TABU or IP. TABU,
for example, failed to nd a feasible schedule after running for over 24 hours. On the
smallest problems, TABU and IP were able to nd solutions, but SWO outperformed both by
a substantial margin.
Table 1 presents results on each problem for SWO, TABU and IP. For SWO, ten trials were
run and the results averaged. The TABU and IP implementations were deterministic, so
only the results of a single run are shown. The second column of the table shows the best
objective function value we have ever observed on each problem. The remaining columns
show the objective function value and running times for SWO, TABU and IP. All but the IP
experiments were run on a Sun Sparcstation 10 Model 50. The IP experiments were run on
an IBM RS6000 Model 590 (a faster machine).
The best values observed have been the result of combining SWO with IP, as reported
in (?). In that work, SWO generated solutions, running until it had produced a number of
\good" schedules. An IP solver was then invoked to re-combine elements of those solutions
into a better solution. Although the improvements achieved by the IP solver were relatively
small, on the order of 1.5%, it achieved this improvement quickly, and SWO was unable to
achieve the same degree of optimization even when given substantially more time. While
noting that the hybrid approach can be more eective than SWO alone, and much more
eective than IP alone, here we focus on the performance of the individual techniques.
We also note that our very rst, fairly naive implementation of SWO for these scheduling
problems already outperformed both TABU and IP. Moreover, our improved implementation,
reported above, is still fairly simple, and is successful without relying on domain-dependent
heuristics. We take this as evidence that the eectiveness of our approach is not due
to cleverness in the construction, analysis and prioritization techniques, but due to the
eectiveness of the SWO cycle at identifying and responding to whatever elements of the
problem happen to be causing diculty in the local region of the search.
360

\Squeaky Wheel" Optimization

10

# of lines job in that position can run on

8
6
4
2
0

0

2

4

6

0

2

4

6

8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38
Position in priority sequence
Order based on # of lines job can run on

10
8
6
4
2
0

8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38
Position in priority sequence
Order after 14th iteration, producing a solution 0.05% over best known

Figure 5: Comparison of heuristic priorities and priorities derived by SWO
It is also instructive to compare the results of a good heuristic ordering, with the sequence derived by SWO. A good heuristic for this scheduling domain (and the one that is used
to initially populate the priority sequence) is to sort the tasks by the number of production
lines on which a task could be feasibly assigned in an empty schedule. A task that can be
scheduled on many lines is likely to be easier to schedule than one that is compatible with
only a small number of lines, and should therefore be expected to need a lower priority. The
top graph in Figure 5 shows the sequence of tasks, as determined by this heuristic. The
lower graph illustrates the changes in priority of these tasks, after SWO has run for fourteen
iterations (enough to improve the solution derived from the sequence to within 0.05 percent
of the best known solution).
As the gure illustrates, the heuristic is generally accurate, but SWO has had to move
some tasks that are compatible with most of the production lines to positions of relatively
high priority, reecting the fact that contrary to the heuristic, these tasks turned out to be
relatively dicult to schedule well. Other tasks that are compatible with only a few production lines are actually easy to schedule well, and have moved to relatively low priorities.

3.3 Restarts
The SWO solver used to produce the results reported in Table 1 restarted the priority
queue every n=2 iterations, where n is the number of jobs in the problem. The same noisy
heuristic that was used to initially populate the priority queue was also used to restart
it. This restart cuto was picked in a rather ad hoc manner. A more careful analysis of
361

Joslin & Clements

Iterations
Feasible
< 18000
< 17700
per Success Mean Success Mean Success
Mean Sample
Restart
Rate Cost
Rate Cost
Rate
Cost
Size
10 0.8542
5.9 0.0504 195.3 0.0002 49994.5 10000
20 0.9722
6.0 0.2052 90.9 0.0006 33328.3
5000
30 0.9955
5.8 0.3812 67.5 0.0030 9895.5
3300
40 0.9996
5.8 0.5488 56.7 0.0060 6658.2
2500
50 0.9995
6.0 0.6330 57.0 0.0160 3112.7
2000
60 1.0000
5.7 0.7242 52.9 0.0188 3170.4
1650
70 1.0000
5.7 0.8079 50.2 0.0350 1973.5
1400
80 1.0000
6.2 0.8552 49.5 0.0296 2670.0
1250
90 1.0000
5.8 0.8827 48.9 0.0300 2965.3
1100
100 1.0000
5.9 0.8840 52.4 0.0400 2452.3
1000
200 1.0000
6.0 0.9680 53.0 0.0600 3204.3
500
300 1.0000
5.3 0.9967 50.1 0.0567 5090.8
300
400 1.0000
5.8 1.0000 52.9 0.0720 5320.2
250
500 1.0000
5.8 1.0000 52.8 0.1000 4692.6
200
600 1.0000
5.8 1.0000 57.2 0.0867 6590.8
150
700 1.0000
6.1 1.0000 42.4 0.1200 5472.4
100
800 1.0000
5.6 1.0000 53.0 0.1200 6210.3
100
900 1.0000
5.3 1.0000 45.8 0.1700 4691.6
100
1000 1.0000
6.0 1.0000 45.4 0.1800 4838.1
100

Table 2: Experimental results: restarts in the scheduling domain
dierent restart cuto values might lead to producing better solutions faster, and to some
additional insight on the workings of SWO.
Restarts are often used in non-systematic search to avoid getting trapped in local optima
or in cycles. (See Parkes and Walser, 1996, for an empirical study of WSAT and further
references.) Restarts have also been used in systematic search to escape exponentially large
regions of the search space that do not contain a solution (Gomes, Selman, & Kautz, 1998).
Local optima pose little threat to SWO, since it is not directly driven by uphill/downhill
considerations. SWO, through its use of large coherent moves, also tends to escape unpromising parts of the search space quickly. However, SWO is open to getting trapped in a cycle,
and restarts are used as a means to escape them.
For these scheduling problems, SWO is unlikely to get into a tight cycle where priority
queues and solutions repeat exactly. This is due to the presence of random tie breaking in
several places, and to the presence of noise in the prioritizer. However, it is our belief that
SWO can get trapped in a cycle where similar priority queues and solutions repeat.
We ran a series of experiments with the 297 task problem to determine the impact of
various restart cutos. The results are summarized in Table 2. Restart cutos ranged from
after every 10 iterations to after every 1000 iterations. The success rate and mean cost are
shown for each value for each of three dierent solution qualities. The success rate indicates
the probability that a solution of at least the given quality was found in a given pass. The
mean cost is the average number of total iterations to get a solution of that quality.
For the feasible and 18000 solution thresholds, SWO reaches a 100 percent success rate
well before reaching the maximum restart cuto of 1000 used in these experiments. In some
sense, it is easy for SWO to produce solutions that are at least of these qualities. The results
362

\Squeaky Wheel" Optimization

for these 2 thresholds indicate that when it is easy for SWO to solve the problem, any cuto
greater than the average number of uninterrupted iterations it takes to produce a solution
can be used to solve the problem at minimum cost. For such \easy" problems, it appears
that too small a restart cuto can hurt, but that too big a cuto will not.
The numbers for the 17700 solution quality threshold, tell a dierent story. The success
rate is still climbing when the experiment ends, and the mean cost has actually risen above
its minimum. For this solution quality, the restart cuto that minimizes mean cost falls
around the range of 70 to 100. Mean costs rise steeply for restart cutos below this range,
and slowly for cutos larger than that. This is an example of a hard problem for SWO, and it
shows that some care needs to be taken when choosing a restart strategy for such problems.
Additional research is needed to determine how to set the restart cuto automatically for
arbitrary problems.
This data indicates that SWO does benet from restarts, up to a point. With the 17700
threshold, for restart cutos up to 100, each increase in the cuto in general led to a
superlinear increase in the success rate. (This is also another indicator that SWO is learning
from iteration to iteration.) Above 100 iterations per restart, the success rate initially
climbs sublinearly and then appears to level out. It is an open question what this tells us
about the search space.

4. SWO for graph coloring
We have also applied SWO to a very dierent domain, graph coloring. Here the objective
is to color the nodes of a graph such that no two adjoining nodes have the same color,
minimizing the number of colors.

4.1 Implementation

The priority sequence for graph coloring consists of an ordered list of nodes. The solver is
always trying to produce a coloring that uses colors from the target set, which has one less
color than was used to color the best solution so far. Again, we describe the implementation
in terms of the three main components of SWO:

Constructor. The constructor assigns colors to nodes in priority sequence order. If a

node's color in the previous solution is still available (i.e. no adjacent node is using
it yet), and is in the target set, then that color is assigned. If that fails, it tries to
assign a color in the current target set, picking the color that is least constraining on
adjacent uncolored nodes, i.e. the color that reduces the adjacent nodes' remaining
color choices the least. If none of the target colors are available, the constructor tries
to \grab" a color in the target set from its neighbors. A color can only be grabbed
if all neighbor nodes with that color have at least one other choice within the target
set. If multiple colors can be grabbed, then the least constraining one is picked. If no
color in the target set can be grabbed then a color outside the target set is assigned.
Nodes that are early in the priority sequence are more likely to have a wide range of
colors to pick from. Nodes that come later may grab colors from earlier nodes, but
only if the earlier nodes have other color options within the target set.
363

Joslin & Clements

SWO
IG
Dist. impasse
Par. impasse
TABU
Problem
colors
time colors
time colors
time colors
time colors
time
DSJC125.5
18.3
1.6 18.9
2.5 17.0
6.3 17.0 4043.6 20.0 153.3
DSJC250.5
31.9
8.3 32.8
6.9 28.0
268.5 29.2 4358.1 35.0 3442.2
DSJC500.5
56.3
40.9 58.6
18.2 49.0 8109.1 53.0 4783.9 65.0 3442.2
DSJC1000.5 101.5 208.6 104.2
67.6 89.0 41488.7 100.0 5333.8 117.0 3442.2
C2000.5
185.7 1046.2 190.0 272.4 165.0 14097.9
|
|
|
|
C4000.5
341.6 4950.8
346.9 1054.1
|
|
|
|
|
|
R125.1
5.0
0.2
5.0
2.0
5.0
0.2
5.0
64.6
5.0
0.4
R125.1c
46.0
5.1 46.0
1.1 46.0
0.2 46.0
85.0 46.0
0.9
R125.5
36.0
2.8 36.9
1.9 36.0
0.2 37.0
33.0 36.0
0.7
R250.1
8.0
0.5
8.0
7.0
8.0
0.2
8.0
22.0
8.0
0.2
R250.1c
64.0
30.6 64.0
4.6 64.0
0.5 64.0 278.2 65.0
46.4
R250.5
65.0
14.7 68.4
8.3 65.0
82.2 66.0
39.9 66.0
59.0
DSJR500.1
12.0
2.0 12.0
21.1 12.0
0.2 12.0
26.6 12.0
0.5
DSJR500.1c
85.2
96.9 85.0
14.6 85.0
59.1 85.2 5767.7 87.0 3442.2
DSJR500.5
124.1
68.7 129.6
26.1 123.0
175.3 128.0
90.5 126.0 395.1
R1000.1
20.0
8.0 20.6
87.2 20.0
8.2 20.0
49.9 20.0
1.7
R1000.1c
101.7 433.2 98.8
49.1 98.0
563.3 102.6 3940.0 105.0 3442.2
R1000.5
238.9
574.5 253.2 102.9 241.0
944.0 245.6 215.9 248.0 3442.2
at300 20 0
25.3
16.4 20.2
3.8 20.0
0.2 20.0 274.3 39.0 3442.2
at300 26 0
35.8
12.0 37.1
7.7 26.0
10.0 32.4 6637.1 41.0 3442.2
at300 28 0
35.7
11.9 37.0
9.6 31.0 1914.2 33.0 1913.5 41.0 3442.2
at1000 50 0 100.0 203.9 65.6 146.3 50.0
0.2 97.0 7792.7
|
|
at1000 60 0 100.7 198.0 102.5
87.3 60.0
0.2 97.8 6288.4
|
|
at1000 76 0 100.6 208.4 103.6
79.6 89.0 11034.0 99.0 6497.9
|
|
latin sqr 10
111.5 369.2 106.7
59.7 98.0 5098.0 109.2 6520.1 130.0 3442.2
le450 15a
15.0
5.5 17.9
17.0 15.0
0.2 15.0 162.6 16.0
17.8
le450 15b
15.0
6.1 17.9
16.2 15.0
0.2 15.0 178.4 15.0
28.4
le450 15c
21.1
8.0 25.6
14.5 15.0
57.2 16.6 2229.6 23.0 3442.2
le450 15d
21.2
7.8 25.8
13.5 15.0
36.3 16.8 2859.6 23.0 3442.2
mulsol.i.1
49.0
5.9 49.0
4.2 49.0
0.2 49.0
27.2 49.0
0.3
school1
14.0
8.4 14.0
10.5 14.0
0.2 14.0
46.3 29.0
90.7
school1 nsh
14.0
7.2 14.1
8.9 14.0
0.2 14.0
66.4 26.0
31.2

Table 3: Experimental results: graph coloring problems

Analyzer. Blame is assigned to each node whose assigned color is outside the target set,
with the amount of blame increasing for each additional color that must be added
to the target set. We ran experiments with several dierent variations of color-based
analysis. All of them performed reasonably.

Prioritizer. The prioritizer modies the previous sequence of nodes by moving nodes with
blame forward in the sequence according to how much blame each received. This is
done the same way it is done for the scheduling problems. The initial sequence is a list
of nodes sorted in decreasing degree order, with some noise added to slightly shue
the sort.
364

\Squeaky Wheel" Optimization

4.2 Experimental results
We applied SWO to a standard set of graph coloring problems, including random graphs and
application graphs that model register allocation and class scheduling problems. These were
collected for the Second DIMACS Implementation Challenge (Johnson & Trick, 1996), which
includes results for several algorithms on these problems (Culberson & Luo, 1993; Glover,
Parker, & Ryan, 1993; Lewandowski & Condon, 1993; Morgenstern, 1993). Problems range
from 125 nodes with 209 edges to 4000 nodes with 4,000,268 edges.
Glover et al. (1993) is the only paper that is based on a general search technique, TABU
with branch and bound, rather than a graph coloring specic algorithm. This approach
had the worst reported average results in the group. Morgenstern (1993) used a distributed
IMPASSE algorithm and had the best overall colorings, but also required that the target
number of colors, as well as several other problem specic parameters be passed to the
solver. Lewandowski & Condon (1993) also found good solutions for this problem set.
Their approach used a hybrid of parallel IMPASSE and systematic search on a 32 processor
CM-5. Culberson & Luo (1993) used an Iterated Greedy (IG) algorithm that bears some
similarity to SWO. IG is the simplest algorithm in the group. Its solution quality falls between
the IMPASSE algorithms and TABU but solves the entire set in 1 to 2 percent of the time
taken by the other methods. Both IG and IMPASSE are discussed further under related
work.
Table 3 compares SWO with the results for IG (Culberson & Luo, 1993), distributed
IMPASSE (Morgenstern, 1993), parallel IMPASSE (Lewandowski & Condon, 1993), and TABU
(Glover et al., 1993). For each, one column shows the number of colors required for each
problem, and the run time (in CPU seconds). Bold face indicates that the number of colors
is within 0.5 of the best result in the table.
We used a Pentium Pro 333MHz workstation running Linux for the SWO graph coloring
experiments. The times shown for the other four algorithms are based on those reported in
(Johnson & Trick, 1996). The results for IG, IMPASSE and TABU are normalized to our times
using the DIMACS benchmarking program dfmax, provided for this purpose. Therefore,
timing comparisons are only approximate. Our machine ran the dfmax r500.5 benchmark
in 86.0 seconds; the times reported for the machines used on the other algorithms were
86.9 seconds for the TABU experiments, 192.6 seconds for IG, 189.3 seconds for IMPASSE,
and 2993.6 seconds for parallel IMPASSE. Because the dfmax benchmark runs on a single
processor, it is unsuitable for normalizing the times for parallel IMPASSE. We report their
unnormalized times.
A variety of termination conditions were used. SWO terminated after 1000 iterations.
IG terminated after 1000 iterations without improvement. Distributed IMPASSE used a
wide variety of dierent termination conditions to solve the dierent problems. The only
common element across problems was that distributed IMPASSE stopped when the target
number of colors, provided as an input parameter, was reached. The times reported for
parallel IMPASSE are the times it took to nd the best solution that was found, not the time
it took the algorithm to terminate, which was always 3 hours. TABU ran until the algorithm
determined that it could make no further progress, or an hour had passed, whichever came
rst.
365

Joslin & Clements

25
TABU

Avg. percent over best in group

20

15
Iterated Greedy

10
Squeaky Wheel

5

Par IMPASSE

Dist IMPASSE
0
0

10000

20000

30000
Time (CPU seconds)

40000

50000

60000

Figure 6: Experimental results: quality of solution vs. time
The TABU numbers are for a single run on each problem. The numbers for the other
algorithms are averages for 4 runs (parallel IMPASSE), 5 runs (distributed IMPASSE, parallel
IMPASSE) or 10 runs (SWO, IG, distributed IMPASSE) on each problem.
Figure 6 summarizes the performance of each technique on the set of 27 problems that
all of the algorithms solved. For each solver the graph indicates the average solution quality
and the average amount of time needed to solve the set. The ideal location on the graph
is the origin, producing high quality solutions in very little time. The points shown for the
other techniques are the points reported in each of the papers. The curve shown for SWO
shows how it performs when given varying amounts of time to solve the set. As the graph
shows, SWO clearly outperforms TABU, the only other general purpose technique, both in
terms of quality and speed. SWO also outperforms IG, a graph coloring specic algorithm,
both in terms of quality and speed. The IMPASSE solvers clearly produce the best solutions
in the group. However, IMPASSE is a domain specic method, and both solvers represent
much more programming eort. The SWO solver uses a general purpose search technique
and was implemented in less than a month by a single programmer.

4.3 Alternate congurations of SWO
We note that, as with the scheduling work, our rst, naive implementation of SWO for graph
coloring produced respectable results. Even without color reuse, color grabbing, or the least
constraining heuristic (the rst free color found was picked), SWO matched IG on 6 problems
and beat it on 10. However, on half of the remaining problems IG did better by 10 or more
colors.
To explore the sensitivity of SWO to such implementation details we tried the following
approaches in the constructor and prioritizer, and ran SWO using all combinations:
366

\Squeaky Wheel" Optimization

Construction: With or without color grabbing
Analysis: Either blame all nodes that receive a color outside the target set, or only the

rst node (in the priority sequence) that causes a new color outside the target set to
be introduced. If color grabbing is used, the determination of blame is based on the
nal color assigned to the node.

The dierence in solution quality from the worst combination to the best combination
was less than 15 percent. Even when the alternative of using a standard sort instead of
the \sticky" sort (a fairly fundamental change) was added to the mix, the spread between
worst and best was still under 20 percent.

5. Related work

The importance of prioritization in greedy algorithms is not a new idea. The \First Fit"
algorithm for bin packing, for example, relies on placing items into bins in decreasing order
of size (Garey & Johnson, 1979). Another example is GRASP (Greedy Randomized Adaptive
Search Procedure) (Feo & Resende, 1995). GRASP diers from our approach in several ways.
First, the prioritization and construction aspects are more closely coupled in GRASP. After
each element is added to the solution being constructed, the remaining elements are reevaluated by some heuristic. Thus the order in which elements are added to the solution
may depend on previous decisions. Second, the order in which elements are selected in each
trial is determined only by the heuristic (and randomization), so the trials are independent.
There is no learning from iteration to iteration in GRASP.
Doubleback Optimization (DBO) (Crawford, 1996) was to some extent the inspiration for
both SWO and another similar algorithm, Abstract Local Search (ALS) (Crawford, Dalal, &
Walser, 1998). In designing SWO, we began by looking at DBO, because it had been extremely
successful in solving a standard type of scheduling problem. However, DBO is only useful
when the objective is to minimize makespan, and is also limited in the types of constraints
it can handle. Because of these limitations, we began thinking about the principles behind
DBO, looking for an eective generalization of that approach. DBO can, in fact, be viewed
as an instance of SWO. DBO begins by performing a \right shift" on a schedule, shifting all
tasks as far to the right as they can go, up to some boundary. In the resulting right-shifted
schedule, the left-most tasks are, to some extent, those tasks that are most critical. This
corresponds to analysis in SWO. Tasks are then removed from the right-shifted schedule,
taking left-most tasks rst. This ordering corresponds to the prioritization in SWO. As each
task is removed, it is placed in a new schedule at the earliest possible start time, i.e., greedy
construction.
Like SWO, ALS was the result of an attempt to generalize DBO. ALS views priority space
(to use the terminology from SWO) as a space of \abstract schedules," and performs a local
search in that space. Unlike SWO, if a prioritization is modied, and the corresponding
move in solution space is downhill (away from optimal), then the modied prioritization
is discarded, and the old prioritization is restored. As is usual with local search, ALS also
sometimes makes random moves, in order to escape local minima.
ALS, and also List Scheduling (Pinson, Prins, & Rullier, 1994), are scheduling algorithms
that deal with domains that include precedence constraints on tasks. Both accommodate
367

Joslin & Clements

precedence constraints by constructing schedules left-to-right temporally. A task cannot
be placed in the schedule until all of its predecessors have been placed. In order for the
analysis, prioritization and construction to be appropriately coupled, it is not sucient to
simply increase the priority of a task that is late, because the constructor may not be able
to place that task until after a lot of other decisions have been made. Consequently, some
amount of blame must be propagated to the task's predecessors.
The commercial scheduler OPTIFLEX (Syswerda, 1994) uses a genetic algorithm approach
to modify a sequence of tasks, and a constraint-based schedule constructor that generates
schedules from those sequences. OPTIFLEX can also be viewed as an instance of SWO, with
a genetic algorithm replacing analysis. In eect, the \analysis" instead emerges from the
relative tness of the members of the population.
Two graph coloring algorithms also bear some similarity to SWO. Impasse Class Coloration Neighborhood Search (IMPASSE) (Morgenstern, 1993; Lewandowski & Condon,
1993), like SWO, maintains a target set of colors and produces only feasible colorings. Given a
coloring, IMPASSE places any nodes that are colored outside of the target set into an impasse
set. On each iteration a node is selected from the impasse set, using a noisy degree-based
heuristic, and assigned a random color from the target set. Any neighbor nodes that are
now in conict are moved to the impasse set.
Iterated Greedy (IG) (Culberson & Luo, 1993), like SWO, uses a sequence of nodes to
create a new coloring on each iteration, and then uses that coloring to produce a new
sequence for the next iteration. The method used to generate each new sequence diers
from SWO. The key observation behind IG is that if all nodes with the same color in the
current solution are grouped together in the next sequence (i.e. adjacent to each other in
the sequence), then the next solution will be no worse than the current solution. IG achieves
improvement by manipulating the order in which the groups occur in the new sequence,
using several heuristics including random based on color, descending based on color, and
ascending based on the cardinality of each group. IG learns groupings of nodes as it runs,
but it does not learn about about the diculty of any nodes. A node's place in the sequence
indicates nothing about its expected or detected diculty.

6. Analysis and future work

This section summarizes several areas of future research suggested by the results reported
in the previous sections.

6.1 Scaling

While SWO uses fast, greedy algorithms for constructing solutions, and we have demonstrated
its eectiveness on problems of realistic size, the greatest threat to the scalability of SWO is
that it constructs a new solution from scratch on each iteration. A partial solution to this
problem is seen in the use of a \history" mechanism for the graph coloring problems. Using
the same color for a node as in the previous solution means that in many cases we do not
need to check any of the other possible colors. This signicantly speeds up the construction.
A more fundamental solution to this problem would be to develop an incremental version
of SWO. The selective reuse of colors in the graph coloring solver is a small step in this
direction. This allows the constructor to avoid spending time evaluating other alternatives
368

\Squeaky Wheel" Optimization

when the previous choice still works. More generally, it may be possible to look at the
changes made to a prioritization, and modify the corresponding solution in a way that
generates the same solution that would be constructed from scratch based on the new
prioritization. It seems feasible that this could be done for some domains, at least for small
changes to the prioritization, because there may be large portions of a solution that are
unaected.
A more interesting possibility is based on the view of SWO as performing local search
plus a certain kind of propagation. A small change in priorities may correspond to a large
change in the solution. For example, increasing the priority of one task in a scheduling
problem may change its position in the schedule, and, as a consequence, some lower priority
tasks may have to be shued around to accommodate that change. This is similar to what
we might expect from moving the higher priority task, then propagating the eects of that
change by moving lower priority tasks as well. This single move may correspond to a large
number of moves in a search algorithm that only looks at local changes to the schedule, and
may thus be dicult for such an algorithm to nd.
Based on this view, we are investigating an algorithm we call \Priority-Limited Propagation" (PLP). With PLP, local changes are made to the solution, and then propagation is
allowed to occur, subject to the current prioritization. Propagation is only allowed to occur
in the direction of lower-priority elements. In eect, a small change is made, and then the
consequences of that change are allowed to \ripple" through the plan. Because propagation
can only occur in directions of decreasing priority, these ripples of propagation decrease in
magnitude until no more propagation is possible. A new prioritization is then generated by
analyzing the resulting solution. (It should be possible to do this analysis incrementally,
as well.) The resulting approach is not identical to SWO, but has many of its interesting
characteristics.

6.2 Coordination of modules
For SWO to be eective, it is obvious that analysis, prioritization and construction must all
work together to improve the quality of solutions. We have already discussed the complications that can arise when constraints are placed on the order in which the constructor
can make decisions, as is the case for List Scheduling and ALS, where construction is done
strictly left-to-right. Without more complex analysis, the search spaces can eectively become uncoupled, so that changes in priority don't cause the constructor to x problems
discovered by analysis.
Another way the search can become uncoupled is related to the notion of \excess cost,"
discussed for the scheduling implementation. The calculation of excess cost in the analyzer
turned out to be a key idea for improving the performance of SWO. However, problems sometimes have tasks that must be handled badly in order to achieve a good overall solution. One
of the scheduling problems described previously has two such \sacricial" tasks. Whenever
a good solution is found, the analyzer assigns high blame to these sacricial tasks, and the
constructor handles them well on the next iteration. This means that the resulting solution
is of poor overall quality, and it is not until other aws cause other tasks to move ahead of
the sacricial tasks in the priority sequence that SWO can again, briey, explore the space
369

Joslin & Clements

of good solutions. In such cases, to some extent the analysis is actually hurting the ability
of SWO to converge on good solutions.
Ideally, we would like to generalize the notion of excess cost to recognize sacricial
tasks, and allow those tasks to be handled badly without receiving proportionate blame.
For problems in which a task must be sacriced in all solutions, it may be possible to use
a learning mechanism to accomplish this.
However, the notion of a sacricial task can be more subtle than this. Suppose for
example that we are scheduling the construction of two airplanes, P1 and P2, and that
each has a key task, T1 and T2, respectively, requiring all of some shared resource, R.
Because of the resource conict, we must either give R to T1 early in the schedule, starting
construction on plane P1 before P2, or we must give R to T2 early in the schedule, with
the opposite result. Whichever of the two tasks is started early will nish on time, but the
other will be late.
Suppose we construct a schedule in which T1 goes rst, and T2 is late, thus receiving a
heavy blame factor. SWO increases the priority on T2, and as a consequence, T2 goes rst
in the subsequent schedule. But then T1 is late, and on the next iteration it will again go
rst. We could alternate in this manner forever, and the result would be that SWO would
fail to explore either option very eectively, because it would be jumping back and forth
between the option of building plane P1 rst, and the option of building plane P2 rst,
without remaining in one region of the search space long enough to rene a solution.
The diculty is that neither T1 nor T2 can be identied as a sacricial task. Assuming
the two planes are not identical, we cannot simply argue from symmetry that we should
just pick one of the two tasks to be sacriced. If, however, we could identify a sacricial
task by the role it plays in a solution, we could achieve what we need. Here, the task to be
sacriced must be the one that belongs to whichever plane is started later. If the analyzer
could reduce the blame assigned to that task in a schedule, whichever task it happens to
be, it would allow SWO to explore that region of the search much more eectively.
This problem of interchangeable roles would arise even more clearly with the introduction of conditional elements in a solution. Suppose, for example, we have a scheduling
problem in which the constructor may choose to include or not include task instances of
some type, adding however many instances are needed to satisfy a resource requirement.
If those tasks are all instances of the same task type, then they are interchangeable, and
penalizing one may simply cause a shuing of those instances that does not really address
the problem. Moreover, with conditional tasks, it is not clear how the analyzer should
assign blame when the set of task instances in the current schedule may be very dierent
from the set of task instances in successor schedules.
To address these concerns, the notion of prioritization could be generalized to apply to
additional aspects of a problem. In scheduling this might mean not just prioritizing tasks,
but also resources over various time intervals. We also propose that the these prioritizations
be limited to the \xed" elements of a problem. In scheduling problems, for example, these
may be the non-conditional tasks, resources, etc. (In our example domains, all of the
elements are xed in this sense, so this was not an issue.)
One intuition behind this proposal is that these are the elements that will tend to dene
roles. In the earlier example with tasks T1 and T2, corresponding to the two planes being
built, the critical element is not either task per se, but actually resource R, early in the
370

\Squeaky Wheel" Optimization

schedule. If this phase of resource R receives a high priority, and the later phase of resource
R receives a lower priority, then whichever of the two tasks occurs later will be recognized
as less critical. While this does not exactly capture the notion of \role" that we would like,
it comes a lot closer than the current approach. In addition, assigning priorities to the xed
elements of a problem has the advantage of being applicable to problems with conditional
tasks. Research is currently under way to explore this approach.

6.3

SWO

and local search

Although the ability to make large, coherent moves is a strength of the approach, it is also
a weakness. SWO is poor at making small \tuning" moves in the solution space, but the
coupled-search view of SWO suggests an obvious remedy. SWO could be combined with local
search in the solution space, to look for improvements in the vicinity of good solutions.
Similarly, making small changes to a prioritization would generally result in smaller moves
in the solution space than result from going through the full analysis and re-prioritization
cycle.
Yet another alternative is genetic algorithm techniques for \crossover" and other types
of mutation to a pool of nodes, as is done in OPTIFLEX. Many hybrid approaches are possible, and we believe that the coupled-search view of SWO helps to identify some interesting
strategies for combining moves of various sizes and kinds, in both search spaces, adapting
dynamically to relative solution qualities.

7. Conclusions
Our experience has been that it is fairly straightforward to implement SWO in a new domain,
because there are usually fairly obvious ways to construct greedy solutions, and to analyze
a solution to assign \blame" to some of the elements. Naive implementations of SWO tend
to perform reasonably well.
We have found the view of SWO as performing a \coupled search" over two dierent
search spaces to be very informative. It has been helpful to characterize the kinds of moves
that SWO makes in each of the search spaces, and the eect this has on avoiding local optima,
etc. We hope that by continuing to gain a deeper understanding of what makes SWO work
we will be able to say more about the eective design of SWO algorithms.
As the number of directions for future research suggests, we have only begun to scratch
the surface of \Squeaky Wheel" Optimization.

Acknowledgments
The authors wish to thank Robert Stubbs of Lucent Technologies for providing the data
used for the scheduling experiments. The authors also wish to thank George L. Nemhauser,
Markus E. Puttlitz and Martin W. P. Savelsbergh with whom we collaborated on using SWO
in a hybrid AI/OR approach. Many useful discussions came out of that collaboration, and
without them we would not have had access to the Lucent problems. Markus also wrote
the framework for the scheduling experiments and the TABU and IP implementations.
371

Joslin & Clements

The authors also thank the members of CIRL, and James Crawford at i2 Technologies,
for their helpful comments and suggestions. We would like to thank Andrew Parkes in
particular for suggestions and insights in the graph coloring domain.
This eort was sponsored by the Air Force Oce of Scientic Research, Air Force Materiel Command, USAF, under grant number F49620-96-1-0335; by the Defense Advanced
Research Projects Agency (DARPA) and Rome Laboratory, Air Force Materiel Command,
USAF, under agreements F30602-95-1-0023 and F30602-97-1-0294; and by the National
Science Foundation under grant number CDA-9625755.
The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright annotation thereon. The views and conclusions
contained herein are those of the authors and should not be interpreted as necessarily representing the ocial policies or endorsements, either expressed or implied, of the Defense
Advanced Research Projects Agency, Rome Laboratory, the Air Force Oce of Scientic
Research, the National Science Foundation, or the U.S. Government.
Most of the work reported in this paper was done while both authors were at CIRL.

References

Crawford, J., Dalal, M., & Walser, J. (1998). Abstract local search. In Proceedings of the
AIPS-98 Workshop on Planning as Combinatorial Search. In conjunction with the
Fourth International Conference on Articial Intelligence Planning Systems (AIPS98).
Crawford, J. M. (1996). An approach to resource constrained project scheduling. In Proceedings of the 1996 Articial Intelligence and Manufacturing Research Planning Workshop, pp. 35{39.
Culberson, J. C., & Luo, F. (1993). Exploring the k{colorable landscape with iterated
greedy. In (Johnson & Trick, 1996), pp. 245{284.
Feo, T. A., & Resende, M. G. (1995). Greedy randomized adaptive search procedures.
Journal of Global Optimization, 6, 109{133.
Garey, M. R., & Johnson, D. S. (1979). Computers and Intractability: A Guide to the
Theory of NP-Completeness. W. H. Freeman.
Glover, F., & Laguna, M. (1997). Tabu Search. Kluwer.
Glover, F., Parker, M., & Ryan, J. (1993). Coloring by tabu branch and bound. In (Johnson
& Trick, 1996), pp. 285{307.
Gomes, C., Selman, B., & Kautz, H. (1998). Boosting combinatorial search through randomization. In Proceedings of AAAI-98, pp. 431{437.
Johnson, D. S., & Trick, M. A. (Eds.). (1996). Cliques, Coloring, and Satisability: Second
DIMACS Implementation Challenge, 1996, Vol. 26 of DIMACS Series in Discrete
Mathematics and Theoretical Computer Science. American Mathematical Society.
372

\Squeaky Wheel" Optimization

Joslin, D., & Clements, D. (1998). \Squeaky wheel" optimization. In Proceedings of AAAI98, pp. 340{346.
Lewandowski, G., & Condon, A. (1993). Experiments with parallel graph coloring heuristics
and applications of graph coloring. In (Johnson & Trick, 1996), pp. 309{334.
Morgenstern, C. (1993). Distributed coloration neighborhood search. In (Johnson & Trick,
1996), pp. 335{357.
Parkes, A., & Walser, J. (1996). Tuning local search for satisability testing. In Proceedings
of AAAI-96, pp. 356{362.
Pinson, E., Prins, C., & Rullier, F. (1994). Using tabu search for solving the resourceconstrained project scheduling problem. In EURO-WG PMS 4 (EURO Working
Group on Project Management and Scheduling), pp. 102{106 Louvain, Belgium.
Selman, B., Kautz, H. A., & Cohen, B. (1993). Local search strategies for satisability
testing. In (Johnson & Trick, 1996), pp. 521{531.
Syswerda, G. P. (1994). Generation of schedules using a genetic procedure.. U.S. Patent
number 5,319,781.

373

Journal of Articial Intelligence Research 10 (1999) 243-270

Submitted 10/98; published 5/99

Learning to Order Things
William W. Cohen
Robert E. Schapire
Yoram Singer

AT&T Labs, Shannon Laboratory, 180 Park Avenue
Florham Park, NJ 07932, USA

wcohen@research.att.com
schapire@research.att.com
singer@research.att.com

Abstract

There are many applications in which it is desirable to order rather than classify instances. Here we consider the problem of learning how to order instances given feedback
in the form of preference judgments, i.e., statements to the eect that one instance should
be ranked ahead of another. We outline a two-stage approach in which one rst learns by
conventional means a binary preference function indicating whether it is advisable to rank
one instance before another. Here we consider an on-line algorithm for learning preference
functions that is based on Freund and Schapire's \Hedge" algorithm. In the second stage,
new instances are ordered so as to maximize agreement with the learned preference function. We show that the problem of nding the ordering that agrees best with a learned
preference function is NP-complete. Nevertheless, we describe simple greedy algorithms
that are guaranteed to nd a good approximation. Finally, we show how metasearch can
be formulated as an ordering problem, and present experimental results on learning a combination of \search experts," each of which is a domain-specic query expansion strategy
for a web search engine.
1. Introduction

Work in inductive learning has mostly concentrated on learning to classify. However, there
are many applications in which it is desirable to order rather than classify instances. An
example might be a personalized email lter that prioritizes unread mail. Here we will
consider the problem of learning how to construct such orderings given feedback in the
form of preference judgments, i.e., statements that one instance should be ranked ahead of
another.
Such orderings could be constructed based on a learned probabilistic classier or regression model and in fact often are. For instance, it is common practice in information retrieval
to rank documents according to their probability of relevance to a query, as estimated by a
learned classier for the concept \relevant document." An advantage of learning orderings
directly is that preference judgments can be much easier to obtain than the labels required
for classication learning.
For instance, in the email application mentioned above, one approach might be to rank
messages according to their estimated probability of membership in the class of \urgent"
messages, or by some numerical estimate of urgency obtained by regression. Suppose,
however, that a user is presented with an ordered list of email messages, and elects to read
the third message rst. Given this election, it is not necessarily the case that message three
is urgent, nor is there suÆcient information to estimate any numerical urgency measures.

c 1999 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

Cohen, Schapire, & Singer
However, it seems quite reasonable to infer that message three should have been ranked
ahead of the others. Thus, in this setting, obtaining preference information may be easier
and more natural than obtaining the labels needed for a classication or regression approach.
Another application domain that requires ordering instances is collaborative ltering; see,
for instance, the papers contained in Resnick and Varian (1997). In a typical collaborative
ltering task, a user seeks recommendations, say, on movies that she is likely to enjoy. Such
recommendations are usually expressed as ordered lists of recommended movies, produced
by combining movie ratings supplied by other users. Notice that each user's movie ratings
can be viewed as a set of preference judgements. In fact, interpreting ratings as preferences
is advantageous in several ways: for instance, it is not necessary to assume that a rating of
\7" means the same thing to every user.
In the remainder of this paper, we will investigate the following two-stage approach to
learning how to order. In stage one, we learn a preference function, a two-argument function
PREF(u; v) which returns a numerical measure of how certain it is that u should be ranked
before v. In stage two, we use the learned preference function to order a set of new instances
X ; to accomplish this, we evaluate the learned function PREF(u; v) on all pairs of instances
u; v 2 X , and choose an ordering of X that agrees, as much as possible, with these pairwise
preference judgments.
For stage one, we describe a specic algorithm for learning a preference function from a
set of \ranking-experts". The algorithm is an on-line weight allocation algorithm, much like
the weighted majority algorithm (Littlestone & Warmuth, 1994) and Winnow (Littlestone,
1988), and, more directly, Freund and Schapire's (1997) \Hedge" algorithm. For stage two,
we show that nding a total order that agrees best with such a preference function is NPcomplete. Nevertheless, we show that there are eÆcient greedy algorithms that always nd
a good approximation to the best ordering.
We then present some experimental results in which these algorithm are used to combine
the results of several \search experts," each of which is a domain-specic query expansion
strategy for a web search engine. Since our work touches several dierent elds we defer
the discussion of related work to Sec. 6.
2. Preliminaries

Let X be a set of instances. For simplicity, in this paper, we always assume that X is
nite. A preference function PREF is a binary function PREF : X  X ! [0; 1]. A value of
PREF(u; v) which is close to 1 (respectively 0) is interpreted as a strong recommendation
that u should be ranked above (respectively, below) v. A value close to 1=2 is interpreted
as an abstention from making a recommendation. As noted earlier, the hypothesis of our
learning system will be a preference function, and new instances will be ranked so as to
agree as much as possible with the preferences predicted by this hypothesis.
In standard classication learning, a hypothesis is constructed by combining primitive
features. Similarly, in this paper, a preference function will be a combination of primitive
preference functions. In particular, we will typically assume the availability of a set of N
primitive preference functions R1 ; : : : ; RN . These can then be combined in the usual ways,
for instance with a boolean or linear combination of their values. We will be especially
interested in the latter combination method.
244

Learning to Order Things
1/4

a

a

c

c

3/4

a

1/8

c

1

b

d

b

f(a)=1 f(b)=2
f(c)=0 f(d)=⊥

d

g(a)=0 g(b)=2
g(c)=1 g(d)=2

b

7/8 1/8
1

7/8

d

1/4f() + 3/4g()

Figure 1: Left and middle: Two ordering functions and their graph representation. Right:
The graph representation of the preference function created by a weighted ( 41 and
3 ) combination of the two functions. Edges with weight of 1 or 0 are omitted.
4
2
It is convenient to assume that the Ri 's are well-formed in certain ways. To this end, we
introduce a special kind of preference function called a rank ordering which is dened by
an ordering function. Let S be a totally ordered set. We assume without loss of generality
that S  R . An ordering function into S is any function f : X ! S , where we interpret an
inequality f (u) > f (v) to mean that u is ranked above v by f . It is sometimes convenient
to allow an ordering function to \abstain" and not give a preference for a pair u, v. We
therefore allow S to include a special symbol ? not in R , and we interpret f (u) = ? to
mean that u is \unranked." We dene the symbol ? to be incomparable to all the elements
in S (that is, ? 6< s and s 6< ? for all s 2 S ).
An ordering function f induces the preference function Rf , dened as

8
>
<1
Rf (u; v) = 0
>
: 12

if f (u) > f (v)
if f (u) < f (v)
otherwise.

We call Rf a rank ordering for X into S . If Rf (u; v) = 1, then we say that u is preferred
to v, or u is ranked higher than v. Note that Rf (u; v) = 12 if either u or v (or both) is
unranked.
We will sometimes describe and manipulate preference functions as directed weighted
graphs. The nodes of a graph correspond to the instances in X . Each pair (u; v) is connected by a directed edge with weight PREF(u; v). Since an ordering function f induces
a preference function Rf , we can also describe ordering functions as graphs. In Fig. 1 we
give an example of two ordering functions and their corresponding graphs. For brevity, we
do not draw edges (u; v) such that PREF(u; v) = 12 or PREF(u; v) = 0.
To give a concrete example of rank orderings, imagine learning to order documents
based on the words that they contain. To model this, let X be the set of all documents in
a repository, and for N words w1 ; : : : ; wN , let fi(u) be the number of occurrences of word
wi in document u. Then Rf will prefer u to v whenever wi occurs more often in u than v.
As a second example, consider a metasearch application in which the goal is to combine the
i

245

Cohen, Schapire, & Singer
rankings of several web search engines on some xed query. For N search engines e1 ; : : : ; eN ,
one might dene fi so that Rf prefers web page u to web page v whenever u is ranked
ahead of v in the list Li produced by the corresponding search engine. To do this, one could
let fi (u) = k for the web page u appearing in the k-th position in the list Li , and let
fi (u) = M (where M > jLi j) for any web page u not appearing in Li .
Feedback from the user will be represented in a similar but more general way. We will
assume that feedback is a set element pairs (u; v), each representing an assertion of the form
\u should be preferred to v." This denition of feedback is less restricted than ordering
functions. In particular, we will not assume that the feedback is consistent|cycles, such as
a > b > a, will be allowed.
i

3. Learning a Combination of Ordering Functions

In this section, we consider the problem of learning a good linear combination of a set of
ordering functions. Specically, we assume access to a set of ranking experts, each of which
generates an ordering function when provided with a set of instances. For instance, in a
metasearch problem, each ranking expert might be a function that submits the user's query
to a dierent search engine; the domain of instances might be the set of all web pages
returned by any of the ranking experts; and the ordering function associated with each
ranking expert might be represented as in the example above (i.e., letting fi (u) = k for
the k-the web page u returned by i-th search engine, and letting fi (u) = M for any web
page u not retrieved by the i-th search engine). The user's feedback will be a set of pairwise
preferences between web pages. This feedback may be obtained directly, for example, by
asking the user to explicitly rank the URL's returned by the search engine; or the feedback
may be obtained indirectly, for example, by measuring the time spent viewing each of the
returned pages.
We note that for the metasearch problem, an approach that works directly with the
numerical scores associated with the dierent search engines might not be feasible; these
numerical scores might not be comparable across dierent search engines, or might not
be provided by all search engines. Another problem is that most web pages will not be
indexed by all search engines. This can be easily modeled in our setting: rather than
letting fi (u) = M for a web page u that is not ranked by search engine i, one could let
fi (u) = ?. This corresponds to the assumption that the search engine's preference for u
relative to ranked web pages is unknown.
We now describe a weight allocation algorithm that
functions Ri to
P usesw Rthe(u;preference
learn a preference function of the form PREF(u; v) = N
v
).
We
adopt
the on-line
i=1 i i
learning framework rst studied by Littlestone (1988) in which the weight wi assigned to
each ranking expert i is updated incrementally.
Formally, learning is assumed to take place in a sequence of rounds. On each round t, we
assume the learning algorithm is provided with a set X t of instances to be ranked, for which
each ranking expert i 2 f1; : : : ; N g provides an ordering function fit . (In metasearch, for
instance, fit is the ordering function associated with the list Lti of web pages returned by the
i-th ranking expert for the t-th query, and X t is the set of all web pages that appear in any
of the lists Lt1 ; : : : ; LtN .) Each ordering function fit induces a preference function Rf , which
we denote for brevity by Rit . The learner may compute Rit (u; v) for any and all preference
t
i

246

Learning to Order Things
functions Rit and pairs u; v 2 X t before producing a combined preference function PREFt ,
which is then used to produce an ordering ^t of X t . (Methods for producing an ordering
from a preference function will be discussed below.)
After producing the ordering ^t , the learner receives feedback from the environment.
We assume that the feedback is an arbitrary set of assertions of the form \u should be
preferred to v." That is, the feedback on the t-th round is a set F t of pairs (u; v).
The algorithm we propose for this problem is based on the \weighted majority algorithm" of Littlestone and Warmuth (1994) and, more directly, on Freund and Schapire's
(1997) \Hedge" algorithm. We dene the loss of a preference function R with respect to
the user's feedback F as
Loss(R; F ) =

P

2

(u;v) F (1

jF j

R(u; v))

1 X
jF j (u;v)2F R(u; v) :

=1

(1)

This loss has a natural probabilistic interpretation. If R is viewed as a randomized prediction
algorithm that predicts that u will precede v with probability R(u; v), then Loss(R; F ) is the
probability of R disagreeing with the feedback on a pair (u; v) chosen uniformly at random
from F .
It is worth noting that the assumption on the form of the feedback can be further relaxed
by allowing the user to indicate the degree to which she prefers u over v. In this case, the
loss should be normalized by the weighted sum of feedback pairs. Since this generalization
is rather straightforward, we assume for brevity that the feedback is an unweighted set of
assertions over element pairs.
We now can use the Hedge algorithm almost verbatim, as shown in Figure 2. The
algorithm maintains a positive weight vector whose value at time t is denoted by wt =
t ). If there is no prior knowledge about the ranking experts, we set all initial
(w1t ; : : : ; wN
weights to be equal so that wi1 = 1=N .
On each round t, the weight vector wt is used to combine the preference
functions of the
P
N
t
dierent experts to obtain the preference function PREF (u; v) = i=1 wit Rit (u; v). This
preference function is next converted into an ordering ^t on the current set of elements
X t . For the purposes of this section, the method of producing an ordering is immaterial; in
particular, any of the methods described in Sec. 4 could be used here. Based on this ordering,
the user provides feedback F t , and the loss for each preference function Loss(Rit ; F t ) is
evaluated as in Eq. (1). Finally, the weight vector wt is updated using the multiplicative
rule
wt   Loss(R ;F )
wit+1 = i
Zt
where  2 [0; 1] is a parameter, and Zt is a normalization constant, chosen so that the
weights sum to one after the update. Thus, in each round, the weights of the ranking
experts are adjusted so that experts producing preference functions with relatively large
agreement with the feedback are increased.
We now give the theoretical rationale behind this algorithm. Freund and Schapire (1997)
prove general results about Hedge which can be applied directly to this loss function. Their
results imply almost immediately a bound on the cumulative loss of the preference function
PREFt in terms of the loss of the best ranking expert, specically:
t
i

247

t

Cohen, Schapire, & Singer
Allocate Weights for Ranking Experts
P
Parameters:  2 [0; 1], initial weight vector w1 2 [0; 1]N with Ni=1 wi1 = 1
N ranking experts, number of rounds T
Do for t = 1; 2; : : : ; T

1. Receive a set of elements X t and ordering functions f1t ; : : : ; fNt . Let Rit denote the
preference function induced by fit .
2. Compute a total order ^t which approximates
PREFt (u; v) =

N
X
i=1

wit Rit (u; v)

(Sec. 4 describes several ways of approximating a preference function with a total
order.)
3. Order X t using ^t .
4. Receive feedback F t from the user.
5. Evaluate losses Loss(Rit ; F t ) as dened in Eq. (1).
6. Set the new weight vector
wit+1 =

wit   Loss(R ;F
Zt
t
i

t

where Zt is a normalization constant, chosen so that

)

PN

t+1
i=1 wi

= 1.

Figure 2: The on-line weight allocation algorithm.

Theorem 1 For the algorithm of Fig. 2,
T
X
t=1

Loss(PREFt ; F t )  a min

where a = ln(1= )=(1

P
Note that

i

 ) and c = 1=(1

T
X
t=1

Loss(Rit ; F t ) + c ln N

 ).

t t
t Loss(PREF ; F )
and t Loss(Rit ; F t )

is the cumulative loss of the combined preference funcP
tions
is the cumulative loss of the ith ranking expert. Thus,
Theorem 1 states that the cumulative loss of the combined preference functions will not be
much worse than that of the best ranking expert.
Proof: We have that
1 X X t t
w R (u; v)
Loss(PREFt ; F t ) = 1
F t (u;v)2F i i i
PREFt ,

=

0
X t@
wi 1
i

1

t

1 X
Rt (u; v)A
F t (u;v)2F i
t

248

Learning to Order Things

X

=

i

wit Loss(Rit (u; v); F t ):

Therefore, by Freund and Schapire's (1997) Theorem 2,
T
X
t=1

Loss(PREFt ; F t ) =



T X
X
t=1 i

a min

2

i

wit Loss(Rit (u; v); F t )
T
X
t=1

Loss(Rit ; F t ) + c ln N:

Of course, we are not interested in the loss of PREFt (since it is not an ordering), but
rather in the performance of the actual ordering ^t computed by the learning algorithm.
Fortunately, the losses of these can be related using a kind of triangle inequality. Let
DISAGREE(; PREF) =

X

u;v:(u)>(v)

(1

PREF(u; v)) :

(2)

Theorem 2 For any PREF, F and total order dened by an ordering function ,
Loss(R ; F ) 

DISAGREE(; PREF)
+ Loss(PREF; F ):
jF j

(3)

For x; y 2 [0; 1], let us dene d(x; y) = x(1 y) + y(1 x). We now show
that d satises the triangle inequality. Let x, y and z be in [0; 1], and let X , Y and Z be
independent Bernoulli (f0; 1g-valued) random variables with probability of outcome 1 equal
to x, y and z , respectively. Then

Proof:

d(x; z ) = Pr[X 6= Z ]
= Pr[(X 6= Y ^ Y = Z ) _ (X = Y
 Pr[X 6= Y _ Y 6= Z ]
 Pr[X 6= Y ] + Pr[Y 6= Z ]
= d(x; y) + d(y; z ):

^ Y 6= Z )]

For [0; 1]-valued functions f; g dened on X  X , we next dene
D(f; g) =

X
d(f (u; v); g(u; v)):
u;v:u=
6v

Clearly, D also satises the triangle inequality.
Let F be the characteristic function of F so that F : X  X ! f0; 1g and F (u; v) = 1
if and only if (u; v) 2 F . Then from the denition of Loss and DISAGREE, we have

jF j Loss(R ; F )

2

= D ( R ;  F )
 D(R; PREF) + D(PREF; F )
= DISAGREE(; PREF) + jF j Loss(PREF; F ):

Notice that the learning algorithm Hedge minimizes the second term on the right hand
side of Eq. (3). Below, we consider the problem of nding an ordering  which minimizes
the rst term, namely, DISAGREE.
249

Cohen, Schapire, & Singer
4. Ordering Instances with a Preference Function

4.1 Measuring the Quality of an Ordering
We now consider the complexity of nding a total order that agrees best with a learned
preference function. To analyze this, we must rst quantify the notion of agreement between
a preference function PREF and an ordering. One natural notion is the following: Let X
be a set, PREF be a preference function, and let  be a total ordering of X , expressed again
as an ordering function (i.e., (u) > (v) if and only if u is above v in the order). For
the analysis of this section, it is convenient to use the measure AGREE(; PREF), which is
dened to be the sum of PREF(u; v) over all pairs u; v such that u is ranked above v by :
AGREE(; PREF) =

X

u;v:(u)>(v)

PREF(u; v):

(4)

Clearly, AGREE is a linear transformation of the measure DISAGREE introduced in Eq. (2),
and hence maximizing AGREE is equivalent to minimizing DISAGREE. This denition is
also closely related to similarity metrics used in decision theory and information processing (Kemeny & Snell, 1962; Fishburn, 1970; Roberts, 1979; French, 1989; Yao, 1995) (see
the discussion in Sec. 6).

4.2 Finding an Optimal Ordering is Hard
Ideally one would like to nd a  that maximizes AGREE(; PREF). The general optimization problem is of little interest in our setting, since there are many constraints on the
preference function that are imposed by the learning algorithm. Using the learning algorithm of Sec. 3, for instance, PREF will always be a linear combination of simpler functions.
However, the theorem below shows that this optimization problem is NP-complete even if
PREF is restricted to be a linear combination of well-behaved preference functions. In particular, the problem is NP-complete even if all the primitive preference functions used in
the linear combination are rank orderings which map into a set S with only three elements,
one of which may or may not be ?. (Clearly, if S consists of more than three elements then
the problem is still hard.)

Theorem 3 The following decision problem is NP-complete for any set S with jS j  3:
Input: A rational number ; a set X ; a collection of N ordering functions fi : X ! S ;
and a preference function PREF dened as
PREF(u; v) =

N
X
i=1

wi Rf (u; v)

(5)

i

P

where w = (w1 ; : : : ; wN ) is a rational weight vector in [0; 1]N with N
i=1 wi = 1.
Question: Does there exist a total order  such that AGREE(; PREF)  ?

Proof: The problem is clearly in NP since a nondeterministic algorithm can guess a total

order and check the weighted number of agreements in polynomial time.
To prove that the problem is NP-hard we reduce from CYCLIC-ORDERING (Galil &
Megido, 1977; Gary & Johnson, 1979), dened as follows: \Given a set A and a collection
250

Learning to Order Things
C of ordered triples (a; b; c) of distinct elements from A, is there a one-to-one function
f : A ! f1; 2; : : : ; jAjg such that for each (a; b; c) 2 C we have either f (a) > f (b) > f (c) or
f (b) > f (c) > f (a) or f (c) > f (a) > f (b)?"
Without loss of generality, S is either f0; 1; ?g or f0; 1; 2g. We rst show that the
problem of nding an optimal total order is hard when S = f0; 1; ?g. Given an instance of
CYCLIC-ORDERING, we let X = A. For each triplet t = (a; b; c) we will introduce three
ordering functions ft;1 , ft;2 , and ft;3 , and dene them so that ft;1 (a) > ft;1 (b), ft;2 (b) >
ft;2 (c), and ft;3 (c) > ft;3 (a). To do this, we let ft;1 (a) = ft;2 (b) = ft;3 (c) = 1, ft;1 (b) =
ft;2 (c) = ft;3 (a) = 0, and ft;i () = ? in all other cases. We let the weight vector be uniform,
so that wt;i = 3j1C j . Let
=

P

5 jAj(jAj 1)=2
+
3
2

3

:

Dene Rt (u; v) = 3i=1 wt;i Rf (u; v), which is the contribution of these three functions
to PREF(u; v). Notice that for any triplet t = (a; b; c) 2 C , Rt (a; b) = 3j2C j whereas
Rt (b; a) = 3j1C j , and similarly for b; c and c; a. In addition, for any pair u; v 2 A such that
at least one of them does not appear in t, we get that Rt (u; v) = 2j1C j . Since a total order
 can satisfy at most two of the three conditions (a) > (b), (b) > (c), and (c) > (a),
the largest possible weighted number of agreements associated with this triple is exactly
=jC j.
If the number of weighted agreements is at least , it must be exactly , by the argument
above; and if there are exactly  weighted agreements, then the total order must satisfy
exactly 2 out of the possible 3 relations for each three elements that form a triplet from
C . Thus, the constructed rank ordering instance will be positive if and only if the original
CYCLIC-ORDERING instance is positive.
The case for S = f0; 1; 2g uses a similar construction; however, for each triplet t =
(a; b; c), we dene six ordering functions, ft;j 1 , ft;j 2 , and ft;j 3 , where j 2 f0; 1g. The basic
0 and f 1 , that agree on the single
idea here is to replace each ft;i with two functions, ft;i
t;i
ordering constraint associated with ft;i , but disagree on all other orderings. For instance,
we will dene these functions so that ft;j 1 (a) > ft;j 1 (b) for j = 0 and j = 1, but for all other
pairs u; v, ft;11 (u) > ft;11 (v) i ft;01 (v) > ft;01 (u). Averaging the two orderings ft;01 and ft;11
will thus yield the same preference expressed by the original function ft;1 (i.e., a preference
for a > b only).
In more detail, we let ft;j 1 (a) = ft;j 2 (b) = ft;j 3 (c) = 2 j , ft;j 1 (b) = ft;j 2 (c) = ft;j 3 (a) = 1 j ,
j
and ft;i
() = 2j in all other cases. We again let the weight vector be uniform, so that
P
j
wt;i = 6j1C j . Similar to the rst case, we dene Rt (u; v) = i;j wt;i Rf (u; v). It can be
veried that Rt is identical to the Rt constructed in the rst case. Therefore, by the same
argument, the constructed rank ordering instance will be positive if and only if the original
CYCLIC-ORDERING instance is positive. 2
Although this problem is hard when jS j  3, the next theorem shows that it becomes
tractable for linear combinations of rank orderings into a set S of size two. Of course, when
jS j = 2, the rank orderings are really only binary classiers. The fact that this special
case is tractable underscores the fact that manipulating orderings (even relatively simple
t;i

j
t;i

251

Cohen, Schapire, & Singer
ones) can be computationally more diÆcult than performing the corresponding operations
on binary classiers.

Theorem 4 The following optimization problem is solvable in linear time:
Input: A set X ; a set S with jS j = 2; a collection of N ordering functions fi : X ! S ;
and a preference function PREF dened by Eq. (5).
Output: A total order dened by an ordering function  which maximizes
AGREE(; PREF).
Assume
P without loss of generality that the two-element set S is f0; 1g, and
dene (u) = i wi fi(u). We now show that any total order1 consistent with  maximizes
AGREE(; PREF). Fix a pair u; v 2 X and let

Proof:

qb1 b2 =

X

i

s.t.

fi (u)=b1 ;fi (v)=b2

wi :

We can now rewrite  and PREF as
(u) = q10 + q11
(v) = q01 + q11

PREF(u; v) = q10 + 21 q11 + 21 q00
PREF(v; u) = q01 + 12 q11 + 12 q00 :

Note that both (u) (v) and PREF(u; v) PREF(v; u) are equal to q10 q01 . Hence, if
(u) > (v) then PREF(u; v) > PREF(v; u). Therefore, for each pair u; v 2 X , the order
dened by  agrees on all pairs with the pairwise preference dened by PREF. In other
words, we have shown that
AGREE(; PREF) =

X
maxfPREF(u; v); PREF(v; u)g
fu;vg

(6)

where the sum is over all unordered pairs. Clearly, the right hand side of Eq. (6) maximizes
the right hand side of Eq. (4) since at most one of (u; v) or (v; u) can be included in the
latter sum. 2

4.3 Finding an Approximately Optimal Ordering
Theorem 3 implies that we are unlikely to nd an eÆcient algorithm that nds the optimal
total order for a weighted combination of rank orderings. Fortunately, there do exist eÆcient algorithms for nding an approximately optimal total order. In fact, nding a good
total order is closely related to the problem of nding the minimum feedback arc set, for
which there exist good approximation algorithms; see, for instance, (Shmoys, 1997) and
the references therein. However, the algorithms that achieve the good approximation results for the minimum feedback arc set problem are based on (or further approximate) a
linear-programming relaxation (Seymour, 1995; Even, Naor, Rao, & Schieber, 1996; Berger
& Shor, 1997; Even, Naor, Schieber, & Sudan, 1998) which is rather complex to implement
and quite slow in practice.
1. Notice that in case of a tie, so that (u) = (v ) for distinct u; v ,  denes only a partial order. The
theorem holds for any total order which is consistent with this partial order, i.e., for any  so that
(u) > (v ) )  (u) >  (v ).
0

0

0

252

Learning to Order Things

Algorithm Greedy-Order
Inputs: an instance set X ; a preference function PREF
Output: an approximately optimal ordering function ^
let V = X
P
P PREF(u; v)
for each v 2 V do (v) = u2V PREF(v; u)
u2V
while V is non-empty do
let t = arg maxu2V (u)
let ^(t) = jV j
V = V ftg
for each v 2 V do (v) = (v) + PREF(t; v)

endwhile

PREF(v; t)

Figure 3: The greedy ordering algorithm.
We describe instead a simple greedy algorithm which is very simple to implement. Figure 3 summarizes the greedy algorithm. As we will shortly demonstrate, this algorithm
produces a good approximation to the best total order.
The algorithm is easiest to describe by thinking of PREF as a directed weighted graph,
where initially, the set of vertices V is equal to the set of instances X , and each edge u ! v
has weight PREF(u; v). We assign to each vertex v 2 V a potential value (v), which is the
weighted sum of the outgoing edges minus the weighted sum of the ingoing edges. That is,
 (v ) =

X
X
PREF(v; u)
PREF(u; v) :
u2V
u2V

The greedy algorithm then picks some node t that has maximum potential2 , and assigns it
a rank by setting ^(t) = jV j, eectively ordering it ahead of all the remaining nodes. This
node, together with all incident edges, is then deleted from the graph, and the potential
values  of the remaining vertices are updated appropriately. This process is repeated
until the graph is empty. Notice that nodes removed in subsequent iterations will have
progressively smaller and smaller ranks.
As an example, consider the preference function dened by the leftmost graph of Fig. 4.
(This graph is identical to the weighted combination of the two ordering functions from
Fig. 1.) The initial potentials the algorithm assigns are: (b) = 2, (d) = 3=2, (c) = 5=4,
and (a) = 9=4. Hence, b has maximal potential. It is given a rank of 4, and then node b
and all incident edges are removed from the graph.
The result is the middle graph of Fig. 4. After deleting b, the potentials of the remaining
nodes are updated: (d) = 3=2, (c) = 1=4, and (a) = 5=4. Thus, d will be assigned
rank jV j = 3 and removed from the graph, resulting in the rightmost graph of Fig. 4.
After updating potentials again, (c) = 1=2 and (a) = 1=2. Now c will be assigned
rank jV j = 2 and removed, resulting in a graph containing the single node a, which will
2. Ties can be broken arbitrarily in case of two or more nodes with the same potential.

253

Cohen, Schapire, & Singer
1/4

1/4
3/4

a

1/8

1

b

3/4

a

c

1/4

1/8

7/8 1/8
1

7/8

a

c

3/4

c

7/8 1/8
7/8

d

d

Figure 4: Behavior of the greedy ordering algorithm. The leftmost graph is the original
input. From this graph, node b will be assigned maximal rank and deleted,
leading to the middle graph; from this graph, node d will deleted, leading to the
rightmost graph. In the rightmost graph, node c will be ranked ahead of node a,
leading the total ordering b > d > c > a.
nally be assigned the rank jV j = 1. The ordering produced by the greedy algorithm is
thus b > d > c > a.
The next theorem shows that this greedy algorithm comes within a factor of two of
optimal.

Theorem 5 Let OPT(PREF) be the weighted agreement achieved by an optimal total order
for the preference function PREF, and let APPROX(PREF) be the weighted agreement
achieved by the greedy algorithm. Then
1
APPROX(PREF)  OPT(PREF) :
2

Proof:

Consider the edges that are incident on the node vj which is selected on the
j -th repetition of the while loop of Figure 3. The ordering produced by the algorithm will
agree with all of the outgoing edges of vj and disagree with all of the ingoing edges. Let
aj be the sum of the weights of the outgoing edges of vj , and dj be the sum of the weights
P
of the ingoing edges. Clearly APPROX(PREF)  jjV=1j aj . However, at every repetition,
the total weight of
Pall incoming edges must equal the total weight of all outgoing edges.
This means that v2V (v) = 0, and hence for the node v? that has maximal potential,
(v? )  0. Thus on every repetition j , it must be that aj  dj , so we have that
OPT(PREF)



jV j
X
j =1

(aj + dj )



jV j
X

(aj + aj )

j =1

 2  APPROX(PREF):

The rst inequality holds because OPT(PREF) can at best include every edge in the graph,
and since every edge is removed exactly once, each edge must contribute to some aj or some
dj . 2
254

Learning to Order Things
1

2
1
k+2
2
k

k+3
k+1
k+1

k+2

2k+3
k

2k+3

Figure 5: An example of a graph (left) for which the node-based greedy algorithm achieves
an approximation factor of 21 by constructing the partial order on the right.

In passing, we note that there are other natural greedy algorithms that do not achieve
good approximations. Consider, for example, an algorithm that starts from a graph consisting of all the nodes but with no edges, and iteratively adds the highest weighted edge in
the graph, while avoiding cycles. It can be shown that this algorithm can produce a very
poor partial order, given an adversarially chosen graph; there are cases where the optimal
total order achieves a multiplicative factor of O(jV j) more weighted agreements than this
\edge-based" greedy algorithm.

4.4 Improvements to the Greedy Algorithm
The approximation factor of two given in Theorem 5 is tight. That is, there exist problems
for which the greedy algorithm approximation is worse than the optimal solution by a
factor arbitrarily close to two. Consider the graph shown on the left-hand side of Fig. 5. An
optimal total order ranks the instances according to their position in the gure, left to right,
breaking ties randomly, and achieves OPT(PREF) = 2k +2 weighted agreements. However,
the greedy algorithm picks the node labeled k + 1 rst and orders all the remaining nodes
randomly, achieving as few as APPROX(PREF) = k + 2 agreements. For large k, the ratio
APPROX(PREF)=OPT(PREF) approaches 12 .
For graph of Figure 5, there is another simple algorithm which produces an optimal
ordering: since the graph is already a partial order, picking any total order consistent with
this partial order gives an optimal result. To cope with problems such as the one of Figure 5,
we devised an improvement to the greedy algorithm which combines a greedy method with
topological sorting. The aim of the improvement is to nd better approximations for graphs
which are composed of many strongly connected components.
As before, the modied algorithm is easiest to describe by thinking of PREF as a
weighted directed graph. Recall that for each pair of nodes u and v, there exist two edges:
one from u to v with weight PREF(u; v) and one from v to u with weight PREF(v; u). In
the modied greedy algorithm we will pre-process the graph. For each pair of nodes, we
255

Cohen, Schapire, & Singer
Algorithm SCC-Greedy-Order
Inputs: an instance set X ; a preference function PREF
Output: an approximately optimal ordering function ^
Dene PREF0 (u; v) = maxfPREF(u; v) PREF(v; u); 0g :
Find strongly connected components U1 ; : : : ; Uk of the graph G = (V; E ) where
V = X and E = f(u; v) j PREF0 (u; v) > 0g :

Order the strongly connected components in any way consistent with the partial order
<scc :

U <scc U 0 i 9u 2 U; u0 2 U 0 : (u; u0 ) 2 E

Use algorithm Greedy-Order or full enumeration to order the instances within each component Ui according to PREF0 .

Figure 6: The improved greedy ordering algorithm.
remove the edge with the smaller weight and set the weight of the other edge to be

j PREF(v; u)

PREF(u; v) j :

For the special case where PREF(v; u) = PREF(u; v) = 12 , we remove both edges. In the
reduced graph, there is at most one directed edge between each pair of nodes. Note that
the greedy algorithm would behave identically on the transformed graph since it is based
on the weighted dierences between the incoming and outgoing edges.
We next nd the strongly connected components3 of the reduced graph, ignoring (for
now) the weights. One can now split the edges of the reduced graph into two classes: intercomponent edges connect nodes u and v, where u and v are in dierent strongly connected
components; and intra-component edges connect nodes u and v from the same strongly
connected component. It is straightforward to verify that any optimal order agrees with all
the inter-component edges. Put another way, if there is an edge from node u to node v of
two dierent connected components in the reduced graph, then (u) > (v) for any optimal
total order .
The rst step of the improved algorithm is thus to totally order the strongly connected
components in some way consistent with the partial order dened by the inter-component
edges. More precisely, we pick a total ordering for the components consistent with the
partial order <scc , dened as follows: for components U and U 0 , U <scc U 0 i there is an
edge from some node u 2 U to some node u0 2 U 0 in the reduced graph.
We next order the nodes within each strongly connected component, thus providing a
total order of all nodes. Here the greedy algorithm can be used. As an alternative, in
cases where a component contains only a few elements (say at most ve), one can nd the
optimal order between the elements of the component by a brute-force approach, i.e., by
full enumeration of all permutations.
3. Two nodes u and v are in the same strongly connected component i there are directed paths from u to
v and from v to u.

256

Learning to Order Things
0.4

b

a

0.2

a

b

a

0.6

0.2

b

0.45

0.5
0.95

0.9

0.45

0.55
0.05
0.5

0.55
0.65

c

d
0.35

0.9

0.1

)

0.1

0.3

c

d

0.2
b

c

0.3

d

0.9

)

0.1

c

0.1

0.3

d

a

0.1

Figure 7: An illustration of the approximation algorithm for nding a total order from
a weighted combination of ordering functions. The original graph (top left) is
reduced by removing at least one edge for each edge-pair (u; v) and (v; u) (middle).
The strongly connected components are then found (right). Finally, an ordering
is found within each strongly connected component which yield the order b > c >
d > a (bottom).
The improved algorithm is summarized in Figure 6 and illustrated in Figure 7. There
are four elements in Figure 7 which constitute two strongly connected components in the
reduced graph (fbg and fa; c; dg). Therefore, b is assigned the top rank and ranked above
a, c and d. If the brute-force algorithm were used to order the components, then we would
check all 3! permutations between a, c and d and output the total order b > c > d > a,
which is the optimal order in this toy example.
In the worst case, the reduced graph contains only a single strongly connected component. In this case, the improved algorithm generates the same ordering as the greedy
algorithm. However, in the experiments on metasearch problems described in Sec. 5, many
of the strongly connected components are small; the average size of a strongly connected
component is less than ve. In cases such as these, the improved algorithm will often
improve on the simple greedy algorithm.

4.5 Experiments with the Ordering Algorithms
Ideally, each algorithm would be evaluated by determining how closely it approximates the
optimal ordering on large, realistic problems. Unfortunately, nding the optimal ordering
for large graphs is impractical. We thus performed two sets of experiments with the ordering
algorithms described above. In the rst set of experiments, we evaluated the algorithms on
small graphs|specically, graphs for which the optimal ordering could be feasibly found
with brute-force enumeration. In these experiments, we measure the \goodness" of the
resulting orderings relative to the optimal ordering. In the second set of experiments, we
evaluated the algorithms on large graphs for which the optimal orderings are unknown. In
these experiments, we compute a \goodness" measure which depends on the total weight
of all edges, rather than the optimal ordering.
257

Cohen, Schapire, & Singer
In addition to the simple greedy algorithm and its improvement, we also considered the
following simple randomized algorithm: pick a permutation at random, and then output
the better of that permutation and its reverse. It can be easily shown that this algorithm
achieves the same approximation bound on expected performance as the greedy algorithm.
(Briey, one of the two permutations must agree with at least half of the weighted edges
in the graph.) The random algorithm can be improved by repeating the process, i.e.,
examining many random permutations and their reverses, and choosing the permutation
that achieves the largest number of weighted agreements.
In a rst set of experiments, we compared the performance of the greedy approximation
algorithm, the improved algorithm which rst nds strongly connected components, and the
randomized algorithm on graphs of nine or fewer elements. For each number of elements, we
generated 10;000 random graphs by choosing PREF(u; v) uniformly at random, and setting
PREF(v; u) to 1 PREF(u; v). For the randomized algorithm, we evaluated 10n random
permutations (and their reverses) where n is the number of instances (nodes). To have
a fair comparison between the dierent algorithms on the smaller graphs, we always used
the greedy algorithm (rather than a brute-force algorithm) to order the elements of each
strongly connected component of a graph.
To evaluate the algorithms, we examined the reduced graph and calculated the average
ratio of the weights of the edges chosen by the approximation algorithm to the weights of
the edges that were chosen by the optimal order. More precisely, let  be the optimal order
and ^ be an order chosen by an approximation algorithm. Then for each random graph, we
calculated
X
maxfPREF(u; v) PREF(v; u); 0g
u; v : ^(u) > ^(v)
X
:
maxfPREF(u; v) PREF(v; u); 0g
u; v : (u) > (v)
If this measure is 0.9, for instance, then the total weight of the edges in the total order
picked by the approximation algorithm is 90% of the corresponding gure for the optimal
algorithm.
We averaged the above ratios over all random graphs of the same size. The results
are shown on the left hand side of Figure 8. On the right hand side of the gure, we
show the average running time for each of the algorithms as a function of the number of
elements. When the number of ranked elements is more than ve, the greedy algorithms
outperform the randomized algorithm, while their running time is much smaller. Thus, if
a full enumeration had been used to nd the optimal order of small strongly connected
components, the approximation would have been consistently better than the randomized
algorithm.
We note that the greedy algorithm also generally performs better on average than
the lower bound given in Theorem 5. In fact, combining the greedy algorithm with prepartitioning of the graph into strongly connected components often yields the optimal order.
In the second set of experiments, we measured performance and running time for larger
random graphs. Since for large graphs we cannot nd the optimal solution by brute-force
enumeration, we use as a \goodness" measure the ratio of the weights of the edges that were
left in the reduced graph after applying an approximation algorithm to the total weight of
258

Learning to Order Things

0.08
1

Greedy
SCC + Greedy
Randomized

Greedy
SCC + Greedy
Randomized

0.07

0.06

Running time (seconds)

Fraction of optimal solution

0.98

0.96

0.94

0.92

0.05

0.04

0.03

0.02
0.9
0.01

0.88

3

4

5

6

7

8

0

9

3

4

5

Number of elements

6

7

8

9

Number of elements

Figure 8: Comparison of goodness (left) and the running time (right) of the approximations
achieved by the greedy algorithms and the randomized algorithm as a function of
the number of ranked elements for random preference functions with 3 through 9
elements.

0.45

Greedy
SCC + Greedy
Randomized

0.95

0.9

0.35

Running time (seconds)

Fraction of total weight

Greedy
SCC + Greedy
Randomized

0.4

0.85

0.8

0.75

0.7

0.3

0.25

0.2

0.15

0.1
0.65
0.05
0.6
0
5

10

15

20

25

30

5

Number of elements

10

15

20

25

30

Number of elements

Figure 9: Comparison of goodness (left) and the running time (right) of the approximations
achieved by the greedy algorithms and the randomized algorithm as a function of
the number of ranked elements for random preference functions with 3 through 30
elements. Note that the graphs for Greedy and SCC+Greedy coincide for most
of the points.

259

Cohen, Schapire, & Singer
edges in the graph. That is, for each random graph we calculated

X

maxfPREF(u; v)

u; v : ^(u) > ^(v)
X
maxfPREF(u; v)
u; v

PREF(v; u); 0g

PREF(v; u); 0g

:

We ran the three algorithms with the same parameters as above (i.e., 10;000 random
graphs). The results are given in Figure 9. The advantage of the greedy algorithms over
the randomized algorithm is even more apparent on these larger problems. Note also that
for large graphs the performance of the two greedy algorithms is indistinguishable. This is
mainly due to the fact that large random graphs are strongly connected with high probability.
To summarize the experiments, when there are six or more elements the greedy algorithm
clearly outperforms the randomized algorithm even if many randomly chosen permutations
are examined. Furthermore, the improved algorithm which rst nds the strongly connected
components outperforms the randomized algorithm for all graph sizes. In practice the
improved greedy algorithm achieves very good approximations|within about 5 percent of
optimal, for the cases in which optimal graphs can be feasibly found.
5. Experimental Results for Metasearch

So far, we have described a method for learning a preference function, and a means of
converting a preference function into an ordering of new instances. We will now present
some experimental results in learning to order. In particular, we will describe results on
learning to combine the orderings of several web \search experts" using the algorithm of
Figure 2 to learn a preference function, and the simple greedy algorithm to order instances
using the learned preference function. The goals of these experiments are to illustrate the
type of problems that can be solved with our method; to empirically evaluate the learning
method; to evaluate the ordering algorithm on large, non-random graphs, such as might arise
in a realistic application; and to conrm the theoretical results of the preceding sections.
We thus restrict ourselves to comparing the learned orderings to individual search experts,
as is suggested by Theorem 1, rather than attempt to compare this application of learningto-order with previous experimental techniques for metasearch, e.g., (Lochbaum & Streeter,
1989; Kantor, 1994; Boyan, Freitag, & Joachims, 1994; Bartell, Cottrell, & Belew, 1994).
We note that this metasearch problem exhibits several properties that suggest a general
approach such as ours. For instance, approaches that learn to combine similarity scores
are not applicable, since the similarity scores of web search engines are often unavailable.
In the experiments presented here, the learning algorithm was provided with ordered lists
for each search engine without any associated scores. To further demonstrate the merits of
our approach, we also describe experiments with partial feedback|that is, with preference
judgments that are less informative than the relevance judgments more typically used in
improving search engines.
260

Learning to Order Things

ML Search Experts
NAME
\NAME"
title:\NAME"
NAME +LASTNAME title:\home page"
NAME +LASTNAME title:homepage
NAME +LASTNAME machine learning
NAME +LASTNAME \machine learning"
NAME +LASTNAME case based reasoning
NAME +LASTNAME \case based reasoning"
NAME +LASTNAME PLACE
NAME +LASTNAME \PLACE"
NAME +LASTNAME url:index.html
NAME +LASTNAME url:home.html
NAME +LASTNAME url:~*LASTNAME*
NAME +LASTNAME url:~LASTNAME
NAME +LASTNAME url:LASTNAME

UNIV Search Experts
NAME
\NAME"
\NAME" PLACE
title:NAME
title:\NAME"
title:\NAME" PLACE
NAME title:\home page"
NAME title:\homepage"
NAME welcome
NAME url:index.html
NAME url:home.html
\NAME" title:\home page"
\NAME" title:\homepage"
\NAME" welcome
\NAME" url:index.html
\NAME" url:home.html
\NAME" PLACE title:\home page"
\NAME" PLACE title:\homepage"
\NAME" PLACE welcome
\NAME" PLACE url:index.html
\NAME" PLACE url:home.html

Table 1: Search (and ranking) experts used in the metasearch experiments. In the associated queries, NAME is replaced with the person's (or university's) full name,
LASTNAME with the person's last name, and PLACE is replaced with the person's aÆliation (or university's location). Sequences of words enclosed in quotes
must appear as a phrase, and terms prexed by title: and url: must appear
in that part of the web page. Words prexed by a \+" must appear in the web
page; other words may or may not appear.

5.1 Test Problems and Encoding
We chose to simulate the problem of learning a domain-specic search engine|i.e., an engine
that searches for pages of a particular, narrow type. Ahoy! (Shakes, Langheinrich, & Etzioni,
1997) is one instance of such a domain-specic search engine. As test cases, we picked two
problems: retrieving the home pages of machine learning researchers (ML), and retrieving
the home pages of universities (UNIV). To obtain sample queries, we obtained a listing of
machine learning researchers, identied by name and aÆliated institution, together with
their home pages,4 and a similar list for universities, identied by name and (sometimes)
geographical location.5 Each entry on a list was viewed as a query, with the associated
URL the sole relevant web page.
4. From http://www.aic.nrl.navy.mil/aha/research/machine-learning.html, a list maintained by David
Aha.
5. From Yahoo!

261

Cohen, Schapire, & Singer
We then constructed a series of special-purpose \search experts" for each domain. These
were implemented as query expansion methods which converted a name/aÆliation pair (or
a name/location pair) to a likely-seeming Altavista query. For example, one expert for the
UNIV domain searched for the university name appearing as a phrase, together with the
phrase \home page" in the title; another expert for the ML domain searched for all the
words in the person's name plus the words \machine" and \learning," and further enforces
a strict requirement that the person's last name appear. Overall, we dened 16 search
experts for the ML domain and 22 for the UNIV domain; these are summarized in Table 1.
Each search expert returned the top 30 ranked web pages. In the ML domain, there were
210 searches for which at least one search expert returned the named home page; for the
UNIV domain, there were 290 such searches. The task of the learning system is to nd an
appropriate way of combining the output of these search experts.
To give a more precise description of the search experts, for each query t, we rst
constructed the set X t consisting of all web pages returned by all of the expanded queries
dened by the search experts. Next, each search expert i was represented as a preference
function Rit . We chose these preference functions to be rank orderings dened with respect
to an ordering function fit in the natural way: we assigned a rank of fit = 30 to the rst
listed page, fit = 29 to the second-listed page, and so on, nally assigning a rank of fit = 0
to every page not retrieved in the top 30 by the expanded query associated with expert i.
To encode feedback, we considered two schemes. In the rst, we simulated complete
relevance feedback|that is, for each query, we constructed feedback in which the sole
relevant page was preferred to all other pages. In the second, we simulated the sort of
feedback that could be collected from \click data"|i.e., from observing a user's interactions
with a metasearch system. For each query, after presenting a ranked list of pages, we noted
the rank of the one relevant web page. We then constructed a feedback ranking in which the
relevant page is preferred to all preceding pages. This would correspond to observing which
link the user actually followed, and making the assumption that this link was preferred to
previous links.
It should be emphasized that both of these forms of feedback are simulated, and contain
less noise than would be expected from real user data. In reality some fraction of the
relevance feedback would be missing or erroneous, and some fraction of click data would
not satisfy the assumption stated above.

5.2 Evaluation and Results
To evaluate the expected performance of a fully-trained system on novel queries in this
domain, we employed leave-one-out testing. For each query t, we trained the learning system
on all the other queries, and then recorded the rank of the learned system on query t. For
complete relevance feedback, this rank is invariant of the ordering of the training examples,
but for the \click data" feedback, it is not; the feedback collected at each stage depends on
the behavior of the partially learned system, which in turn depends on the previous training
examples. Thus for click data training, we trained on 100 randomly chosen permutations
of the training data and recorded the median rank for t.
262

Learning to Order Things
5.2.1 Performance Relative to Individual Experts

The theoretical results provide a guarantee of performance relative to the performance of
the best individual search (ranking) expert. It is therefore natural to consider comparing
the performance of the learned system to the best of the individual experts. However, for
each search expert, only the top 30 ranked web pages for a query are known; if the single
relevant page for a query is not among these top 30, then it is impossible to compute any
natural measures of performance for this query. This complicates any comparison of the
learned system to the individual search experts.
However, in spite of the incomplete information about the performance of the search
experts, it is usually possible to tell if the learned system ranks a web page higher than a
particular expert.6 Motivated by this, we performed a sign test: we compared the rank of
the learning systems to the rank given by each search expert, checking to see whether this
rank was lower, and discarding queries for which this comparison was impossible. We then
used a normal approximation to the binomial distribution to test the following two null
hypotheses (where the probability is taken over the distribution from which the queries are
drawn):

H1. With probability at least 0.5, the search expert performs better than the learning
system (i.e., gives a lower rank to the relevant page than the learning system does.)
H2. With probability at least 0.5, the search expert performs no worse than the learning
system (i.e., gives an equal or lower rank to the relevant page.)
In training, we explored learning rates in the range [0:001; 0:999]. For complete feedback
in the ML domain, hypothesis H1 can be rejected with high condence (p > 0:999) for every
search expert and every learning rate 0:01    0:99. The same holds in the UNIV domain
for all learning rates 0:02    0:99. The results for click data training are nearly as strong,
except that 2 of the 22 search experts in the UNIV domain show a greater sensitivity to
the learning rate: for these engines, H1 can only be rejected with high condence for
0:3    0:6. To summarize, with high condence, in both domains, the learned ranking
system is no worse than any individual search expert for moderate values of  .
Hypothesis H2 is more stringent since it can be rejected only if we are sure that the
learned system is strictly better than the expert. With complete feedback in the ML domain
and 0:3    0:8, hypothesis H2 can be rejected with condence p > 0:999 for 14 of the 16
search experts. For the remaining two experts the learned system does perform better more
often, but the dierence is not signicant. In the UNIV domain, the results are similar. For
0:2    0:99, hypothesis H2 can be rejected with condence p > 0:999 for 21 of the 22
search experts, and the learned engine tends to perform better than the single remaining
expert.
Again, the results for click data training are only slightly weaker. In the ML domain,
hypothesis H2 can be rejected for all but three experts for all but the most extreme learning
rates; in the UNIV domain, hypothesis H2 can be rejected for all but two experts for 0:4 
  0:6. For the remaining experts and learning rates the dierences are not statistically
6. The only time this cannot be determined is when neither the learned system nor the expert ranks the
relevant web pages in the top 30, a case of little practical interest.

263

Cohen, Schapire, & Singer
signicant; however, it is not always the case that the learned engine tends to perform
better.
To summarize the experiments, for moderate values of  the learned system is, with
high condence, strictly better than most of the search experts in both domains, and never
signicantly worse than any expert. When trained with full relevance judgments, the learned
system performs better on average than any individual expert.
5.2.2 Other Performance Measures

We measured the number of queries for which the correct web page was in the top k ranked
pages, for various values of k. These results are shown in Figure 10. Here the lines show the
performance of the learned systems (with  = 0:5, a generally favorable learning rate) and
the points correspond to the individual experts. In most cases, the learned system closely
tracks the performance of the best expert at every value of k. This is especially interesting
since no single expert is best at all values of k.
The nal graph in this gure investigates the sensitivity of this measure to the learning
rate  . As a representative illustration, we varied  in the ML domain and plotted the
top-k performance of the system learned from complete feedback for three values of k. Note
that performance is roughly comparable over a wide range of values for  .
Another plausible measure of performance is the average rank of the (single) relevant
web page. We computed an approximation to average rank by articially assigning a rank
of 31 to every page that was either unranked, or ranked above rank 30. (The latter case is
to be fair to the learned system, which is the only one for which a rank greater than 30 is
possible.) A summary of these results for  = 0:5 is given in Table 2, together with some
additional data on top-k performance. In the table, we give the top-k performance for three
values of k, and average rank for several ranking systems: the two learned systems; the naive
query, i.e., the person or university's name; and the single search expert that performed
best with respect to each performance measure. Note that not all of these experts are
distinct since several experts scored the best on more than one measure.
The table illustrates the robustness of the learned systems, which are nearly always
competitive with the best expert for every performance measure listed. The only exception
to this is that the system trained on click data trails the best expert in top-k performance for
small values of k. It is also worth noting that in both domains, the naive query (simply the
person or university's name) is not very eective: even with the weaker click data feedback,
the learned system achieves a 36% decrease in average rank over the naive query in the ML
domain, and a 46% decrease in the UNIV domain.
To summarize the experiments, on these domains the learned system not only performs
much better than naive search strategies, but also consistently performs at least as well as,
and perhaps slightly better than, any single domain-specic search expert. This observation
holds regardless of the performance metric considered; for nearly every metric we computed,
the learned system always equals, and usually exceeds, the performance of the search expert
that is best for that metric. Finally, the performance of the learned system is almost as
good with the weaker \click data" training as with complete relevance feedback.
264

Learning to Order Things
ML: queries answered in top k
250

Learned System - Full feedback
Learned System - Click data
Individual Rankers

# queries in top k

200
150
100
50
0
0

5

10

15

20

25

30

35

k
UNIV: queries answered in top k
Learned System - Full feedback
Learned System - Click data
Individual Rankers

# queries in top k

300
250
200
150
100
50
0
0

5

10

15

20

25

30

35

k

0.85
0.80

k=8

% Relevant

0.75
0.70
0.65

k=4

0.60
0.55
0.50

k=1

0.45
0.40
0

0.2

0.4
0.6
Learning Rate

0.8

1

Figure 10: Top and middle: Performance of the learned system versus individual experts
for two dierent domains. Bottom: the percentage of time the relevant web page
was in the top-k list for k = 1,4, and 8.
265

Cohen, Schapire, & Singer

Learned (Full Feed.)
Learned (Click Data)
Naive
Best (Top 1)
Best (Top 10)
Best (Top 30)
Best (Avg Rank)

Top 1
114
93
89
119

114
97
114

ML Domain
Top 10 Top 30

Avg Rank

185

198

4.9

185

198

4.9

165
170
182
181
182

176
184
190
194
190

7.7
6.7
5.3
5.6
5.3

Top 1
111
87
79
112

111
111
111

University Domain
Top 10 Top 30 Avg Rank
225
253
7.8
229

157
221
223
223
223

259

191
247
249
249
249

7.8

14.4
8.2
8.0
8.0
8.0

Table 2: Comparison of learned systems and individual search queries.

6. Related Work

Problems that involve ordering and ranking have been investigated in various elds such as
decision theory, the social sciences, information retrieval and mathematical economics (Black,
1958; Kemeny & Snell, 1962; Cooper, 1968; Fishburn, 1970; Roberts, 1979; Salton & McGill,
1983; French, 1989; Yao, 1995). Among the wealth of literature on the subject, the closest to
ours appears to be the work of Kemeny and Snell (1962) which was extended by Yao (1995)
and used by Balabanovc and Shoham (1997) in their FAB collaborative ltering system.
These works use a similar notion of ordering functions and feedback; however, they assume
that both the ordering functions and the feedback are complete and transitive. Hence, it
is not possible to leave elements unranked, or to have inconsistent feedback which violates
the transitivity requirements. It is therefore diÆcult to combine and fuse inconsistent and
incomplete orderings in the Kemeny and Snell model.
There are also several related intractability results. Most of them are concerned with the
diÆculty in reaching consensus in voting systems based on preference ordering. Specically,
Bartholdi, Tovey and Trick (1989) study the problem of nding a winner in an election
when the preferences of all voters are irreexive, antisymmetric, transitive, and complete.
Thus, their setting is more restrictive than ours. They study two similar schemes to decide
on a winner of an election. The rst was invented by Dodgson (1876) (better known by
his pen name, Lewis Carroll) and the second is due to Kemeny (1959). For both models,
they show that the problem of nding a winner in an election is NP-hard. Among these
two models, the one suggested by Kemeny is the closest to ours. However, as mentioned
above, this model is more restrictive as it does not allow voters to abstain (preferences are
required to be complete) or to be inconsistent (all preferences are transitive).
As illustrated by the experiments, the problem of learning to rank is closely related to
the problem of combining the results of dierent search engines. Many methods for this
have been proposed by the information retrieval community, and many of these are adaptive, using relevance judgments to make an appropriate choice of parameters. However,
generally, rankings are combined by combining the scores that were used to rank documents (Lochbaum & Streeter, 1989; Kantor, 1994). It is also frequently assumed that other
properties of the objects (documents) to be ranked are available, such as word frequencies.
In contrast, in our experiments, instances are atomic entities with no associated properties
except for their position in various rank-orderings. Similarly, we make minimal assump266

Learning to Order Things
tions about the rank-orderings|in particular, we do not assume scores are available. Our
methods are thus applicable to a broader class of ranking problems.
General optimization methods have also been adopted to adjust parameters of an IR
system so as to improve agreement with a set of user-given preference judgments. For instance, Boyan, Freitag, and Joachims (1994) use simulated annealing to improve agreement
with \click data," and Bartell, Cottrell and Belew (1994) use conjugate gradient descent
to choose parameters for a linear combination of scoring functions, each associated with
a dierent search expert. Typically, such approaches oer few guarantees of eÆciency,
optimality, or generalization performance.
Another related task is collection fusion. Here, several searches are executed on disjoint
subsets of a large collection, and the results are combined. Several approaches to this problem that do not rely on combining ranking scores have been described (Towell, Voorhees,
Gupta, & Johnson-Laird, 1995; Voorhees, Gupta, & Johnson-Laird, 1994). However, although the problem is supercially similar to the one presented here, the assumption that
the dierent search engines index disjoint sets of documents actually makes the problem
quite dierent. In particular, since it is impossible for two engines to give dierent relative
orderings to the same pair of documents, combining the rankings can be done relatively
easily.
Etzioni et al. (1996) formally considered another aspect of metasearch|the task of
optimally combining information sources with associated costs and time delays. Our formal
results are disjoint from theirs, as they assume that every query has a single recognizable
correct answer, rendering ordering issues unimportant.
There are many other applications in machine learning, reinforcement learning, neural
networks, and collaborative ltering that employ ranking and preferences, e.g., (Utgo &
Saxena, 1987; Utgo & Clouse, 1991; Caruana, Baluja, & Mitchell, 1996; Resnick & Varian,
1997), While our work is not directly relevant, it might be possible to use the framework
suggested in this paper in similar settings. This is one of our future research goals.
Finally, we would like to note that the framework and algorithms presented in this paper
can be extended in several ways. Our current research focuses on eÆcient batch algorithms
for combining preference functions, and on using restricted ranking experts for which the
problem of nding an optimal total ordering can be solved in polyomial time (Freund, Iyer,
Schapire, & Singer, 1998).
7. Conclusions

In many applications, it is desirable to order rather than classify instances. We investigated
a two-stage approach to learning to order in which one rst learns a preference function by
conventional means, and then orders a new set of instances by nding the total ordering
that best approximates the preference function. The preference function that is learned is
a binary function PREF(u; v), which returns a measure of condence reecting how likely
it is that u is preferred to v. This is learned from a set of \experts" which suggest specic
orderings, and from user feedback in the form of assertions of the form \u should be preferred
to v".
We have presented two sets of results on this problem. First, we presented an online
learning algorithm for learning a weighted combination of ranking experts which is based
267

Cohen, Schapire, & Singer
on an adaptation of Freund and Schapire's Hedge algorithm. Second, we explored the
complexity of the problem of nding a total ordering that agrees best with a preference
function. We showed that this problem is NP-complete even in a highly restrictive case,
namely, preference predicates that are linear combinations of a certain class of well-behaved
\experts" called rank orderings. However, we also showed that for any preference predicate,
there is a greedy algorithm that always obtains a total ordering that is within a factor of
two of optimal. We also presented an algorithm that rst divides the set of instances into
strongly connected components and then uses the greedy algorithm (or full enumeration,
for small components) to nd an approximately good order within large strongly connected
components. We found that this approximation algorithm works very well in practice and
often nds the best order.
We also presented experimental results in which these algorithms were used to combine
the results of a number of \search experts," each of which corresponds to a domain-specic
strategy for searching the web. We showed that in two domains, the learned system closely
tracks and often exceeds the performance of the best of these search experts. These results
hold for either traditional relevance feedback models of learning, or from weaker feedback
in the form of simulated \click data." The performance of the learned systems also clearly
exceeds the performance of more naive approaches to searching.
Acknowledgments

We would like to thank Noga Alon, Edith Cohen, Dana Ron, and Rick Vohra for numerous
helpful discussions. An extended abstract of this paper appeared in Advances in Neural
Information Processing Systems 10, MIT Press, 1998.
References

Balabanovc, M., & Shoham, Y. (1997). FAB: Content-based, collaborative recommendation. Communications of the ACM, 40 (3), 66{72.
Bartell, B., Cottrell, G., & Belew, R. (1994). Automatic combination of multiple ranked
retrieval systems. In Seventeenth Annual International ACM SIGIR Conference on
Research and Development in Information Retrieval.
Bartholdi, J., Tovey, C., & Trick, M. (1989). Voting schemes for which it can be diÆcult
to tell who won the elections. Social Choice and Welfare, 6, 157{165.
Berger, B., & Shor, P. (1997). Tight bounds for the acyclic subgraph problem. Journal of
Algorithms, 25, 1{18.
Black, D. (1958). Theory of Committees and Elections. Cambridge University Press.
Boyan, J., Freitag, D., & Joachims, T. (1994). A machine learning architecture for optimizing web search engines. Tech. rep. WS-96-05, American Association of Articial
Intelligence.
268

Learning to Order Things
Caruana, R., Baluja, S., & Mitchell, T. (1996). Using the future to `Sort Out' the present:
Rankprop and multitask learning for medical risk evaluation. In Advances in Neural
Information Processing Systems (NIPS) 8.
Cooper, W. (1968). Expected search length: A single measure of retrieval eectiveness
based on the weak ordering action of retrieval systems. American Documentation, 19,
30{41.
Dodgson, C. (1876). A method for taking votes on more than two issues. Clarendon Press,
Oxford. Reprinted with discussion in (Black, 1958).
Etzioni, O., Hanks, S., Jiang, T., Karp, R. M., Madani, O., & Waarts, O. (1996). EÆcient
information gathering on the internet. In Proceedings of the 37th Annual Symposium on Foundations of Computer Science (FOCS-96) Burlington, Vermont. IEEE
Computer Society Press.
Even, G., Naor, J., Rao, S., & Schieber, B. (1996). Divide-and-conquer approximation algorithms via spreading metrics. In 36th Annual Symposium on Foundations of Computer
Science (FOCS-96), pp. 62{71 Burlington, Vermont. IEEE Computer Society Press.
Even, G., Naor, J., Schieber, B., & Sudan, M. (1998). Approximating minimum feedback
sets and multicuts in directed graphs. Algorithmica, 20 (2), 151{174.
Fishburn, F. (1970). Utility Theory for Decision Making. Wiley, New York.
French, S. (1989). Decision Theory: An Introduction to the Mathematics of Rationality.
Ellis Horwood Series in Mathematics and Its Applications.
Freund, Y., Iyer, R., Schapire, R., & Singer, Y. (1998). An eÆcient boosting algorithm for
combining preferences. In Machine Learning: Proceedings of the Fifteenth International Conference.
Freund, Y., & Schapire, R. (1997). A decision-theoretic generalization of on-line learning
and an application to boosting. Journal of Computer and System Sciences, 55 (1),
119{139.
Galil, Z., & Megido, N. (1977). Cyclic ordering is NP-complete. Theoretical Computer
Science, 5, 179{182.
Gary, M., & Johnson, D. (1979). Computers and Intractability: A Guide to the Theory of
NP-completeness. W. H. Freeman and Company, New York.
Kantor, P. (1994). Decision level data fusion for routing of documents in the TREC3
context: a best case analysis of worst case results. In Proceedings of the third text
retrieval conference (TREC-3).
Kemeny, J. (1959). Mathematics without numbers. Daedalus, 88, 571{591.
Kemeny, J., & Snell, J. (1962). Mathematical Models in the Social Sciences. Blaisdell, New
York.
269

Cohen, Schapire, & Singer
Littlestone, N. (1988). Learning quickly when irrelevant attributes abound: A new linearthreshold algorithm. Machine Learning, 2 (4).
Littlestone, N., & Warmuth, M. (1994). The weighted majority algorithm. Information and
Computation, 108 (2), 212{261.
Lochbaum, K., & Streeter, L. (1989). Comparing and combining the eectiveness of latent semantic indexing and the ordinary vector space model for information retrieval.
Information processing and management, 25 (6), 665{676.
Resnick, P., & Varian, H. (1997). Introduction to special section on Recommender Systems.
Communication of the ACM, 40 (3).
Roberts, F. (1979). Measurement theory with applications to decision making, utility, and
social sciences. Addison Wesley, Reading, MA.
Salton, G., & McGill, M. (1983). Introduction to Modern Information Retrieval. McGrawHill.
Seymour, P. (1995). Packing directed circuits fractionally. Combinatorica, 15, 281{288.
Shakes, J., Langheinrich, M., & Etzioni, O. (1997). Dynamic reference sifting: a case study
in the homepage domain. In Proceedings of WWW6.
Shmoys, D. (1997). Cut problems and their application to divide-and-conquer. In
Hochbaum, D. (Ed.), Approximation algorithms for NP-Hard Problems. PWS Publishing Company, New York.
Towell, G., Voorhees, E., Gupta, N., & Johnson-Laird, B. (1995). Learning collection fusion
strategies for information retrieval. In Machine Learning: Proceedings of the Twelfth
International Conference Lake Taho, California. Morgan Kaufmann.
Utgo, P., & Clouse, J. (1991). Two kinds of training information for evaluation function
learning. In Proceedings of the Ninth National Conference on Articial Intelligence
(AAAI-91), pp. 596{600 Cambridge, MA. AAAI Press/MIT PRess.
Utgo, P., & Saxena, S. (1987). Learning a preference predicate. In Proceedings of the
Fourth International Workshop on Machine Learning, pp. 115{121 San Francisco,
CA. Morgan Kaufmann.
Voorhees, E., Gupta, N., & Johnson-Laird, B. (1994). The collection fusion problem. In Sev-

enteenth Annual International ACM SIGIR Conference on Research and Development
in Information Retrieval.

Yao, Y. (1995). Measuring retrieval eectiveness based on user preference of documents.
Journal of the American Society for Information Science, 46 (2), 133{145.

270

Journal of Articial Intelligence Research 10 (1999) 87-115

Submitted 9/98; published 2/99

Ecient Implementation of the Plan Graph in STAN
Derek Long
Maria Fox

d.p.long@dur.ac.uk
maria.fox@dur.ac.uk

Department of Computer Science
University of Durham, UK

Abstract

Stan is a Graphplan-based planner, so-called because it uses a variety of STate ANalysis techniques to enhance its performance. Stan competed in the AIPS-98 planning
competition where it compared well with the other competitors in terms of speed, nding
solutions fastest to many of the problems posed. Although the domain analysis techniques
Stan exploits are an important factor in its overall performance, we believe that the speed
at which Stan solved the competition problems is largely due to the implementation of
its plan graph. The implementation is based on two insights: that many of the graph
construction operations can be implemented as bit-level logical operations on bit vectors,
and that the graph should not be explicitly constructed beyond the x point. This paper
describes the implementation of Stan's plan graph and provides experimental results which
demonstrate the circumstances under which advantages can be obtained from using this
implementation.

1. Introduction
Stan is a domain-independent planner for STRIPS domains, based on the graph construc-

tion and search method of Graphplan (Blum & Furst, 1997). Its name is derived from the
fact that it performs a number of preprocessing analyses, or STate ANalyses, on the domain
before planning, using the Type Inference Module Tim described by Fox and Long (1998).
Stan competed in the AIPS-98 planning competition and achieved an excellent overall
performance in both rounds. The results of the competition, which can be found at the
URL given in Appendix A, show that Stan was able to solve some problems notably
quickly and that it could nd optimal parallel solutions to some problems which could not
be solved optimally by any other planner in the competition, for example in the Gripper
domain. The problems posed in the competition did not give Stan much opportunity to
exploit its domain analysis techniques, so this performance is due mainly to the underlying
implementation of the plan graph that Stan constructs and searches. A more detailed
discussion of the competition, from the competitors' point of view, is in preparation.
The design of Stan's plan graph is based on two insights. First, we observe that action
pre- and post-conditions can be represented using bit vectors. Checking for mutual exclusion
between pairs of actions which directly interact can be implemented using logical operations
on these bit vectors. Mutual exclusion (mutex relations) between facts can be implemented
in a similar way. In order to best exploit the bit vector representation of information
we construct a two-layer graph called a spike which avoids unnecessary copying of data
and allows layer-dependent information about a node to be clearly separated from layerindependent information about that node. The spike allows us to record mutex relations
c 1999 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

Long & Fox

using bit vectors, making mutex testing for indirect interaction much more ecient (we
distinguish between direct and indirect interaction in Section 2.1). Second, we observe that
there is no advantage in explicit construction of the graph beyond the stage at which the
x point is reached. Our plan graph maintains a wave front which keeps track of all of the
goal sets remaining to be considered during search. Since no new facts, actions or mutex
relations are added beyond the x point these goal sets can be considered without explicit
copying of the fact and action layers. The wave front mechanism allows Stan to solve very
large problem instances using a fraction of the time and space consumed by Graphplan and
Ipp (Koehler, Nebel, & Dimopoulos, 1997). For example, using a heuristic discussed in
Section 5.1, Stan can solve the 10-disc Towers of Hanoi problem (a 1023 step plan) in less
than 9 minutes.
In this paper we describe the spike and wave front mechanisms and provide experimental
results indicating the performance advantages obtained.

2. The Spike Graph Structure
Graphplan (Blum & Furst, 1997) uses constraint satisfaction techniques to search a layered graph which represents a compressed reachability analysis of a domain. The layers
correspond to snapshots of possible states at instants on a time line from the initial to the
goal state. Each layer in the graph comprises a set of facts that represents the union of
states reachable from the preceding layer. This compression guarantees that the plan graph
can be constructed in time polynomial in the number of action instances in the domain.
The expansion of the graph, from which solutions can be extracted, is partially encoded in
binary mutex relations computed during the construction of each layer. STAN implements
an ecient representation of the graph in which a wave front, discussed in Section 4, further
supports its compression. In Graphplan-style planners the search for a plan, from layer k,
involves the selection and exploration of a collection of action choices to see whether a plan
can be constructed, using those actions at the kth time step. If no plan is found the planner
backtracks over the action choices. Two important landmarks arise during the construction
of the plan graph. The rst is the point at which the graph opens in the sense that the
problem becomes, in principle, solvable. This is the layer at which all of the top level goals
rst become pairwise non-mutex and is referred to here as the opening layer. The second
is the x point, referred to as level o by Blum and Furst (1997), the layer after which no
further changes can be made to either the action, fact or mutex information recorded in the
graph at each layer.
In the original implementation of Graphplan the graph was implemented as an alternating sequence of layers of fact nodes and action nodes, with arcs connecting actions to
their preconditions in the previous layer and their postconditions in the subsequent layer.
The layers were constructed explicitly involving the repeated copying of large portions of
the graph at each stage in maintaining the graph structure. This copying was due to two
features of the graph. First, since actions with satised preconditions in one layer continue
to have satised preconditions in all subsequent layers, actions that have once been added
to a layer will appear in every successive action layer with the same name and the same
pre- and post-conditions. Second, since facts that have once been achieved by the eects
of an action will always be achieved by that action, they will continue to appear in every
88

Efficient Implementation of the Plan Graph in STAN

successive fact layer after the layer in which they rst appeared. Although the layers can
get deeper at every successive stage they each duplicate information present in the previous
layer, so there is only a small amount of new information added at every stage. The proportion of new material, relative to copied material, decreases progressively as the graph
develops.
In the original Graphplan, mutex relations were checked for by maintaining lists of facts,
corresponding to the pre- and post-conditions of actions, and checking for membership of
facts within these lists. Because of the need to copy information at each new layer, the preand post-conditions of actions were duplicated even though this information did not vary
from layer to layer (it can be determined once and for all at the point of instantiation of
the schema). It is possible to identify layer-independent information, with each node in the
graph, which can be stored just once using a dierent representation of the graph structure.
The spike representation reimplements the graph as a single fact array, called the fact
spike, and a single action array, called the action spike, each divided into ranks corresponding
to the layers in the original Graphplan graph structure. The observations leading to this
compressed implementation of the plan graph were made independently by Smith and Weld
(1998). In Stan, a fact rank is a consecutive sequence of fact headers storing the layerindependent information associated with their associated facts in the corresponding fact
layer. Similarly, an action rank is a consecutive sequence of action headers storing layerindependent information about their associated actions in the corresponding action layer.
Each header is a tuple containing, amongst other things, the name of the fact or action it
is associated with and a structure which stores the layer-dependent information relevant to
that fact or action. In the case of fact headers this structure is called a fact level package
and in the case of action headers it is an action level package. Figure 1 shows how a simple
graph structure can be viewed as a spike.
In the spike the positions of all fact and action headers are xed and can be referred to
by indexing into the appropriate array. At any point, the sizes of the arrays are referred
to using the constant MaxSize, a large number setting an upper bound on the size of the
spike. All of the vectors allocated are also initialised to this size, although they are used
in word-sized increments. This saves the eort of re-allocating and copying vectors as the
spike increases in size towards MaxSize. We now dene the data types so far introduced.

Denition 1 A spike vector is a bit vector of size MaxSize.
Denition 2 A fact header is a tuple of six components: a name which is the predicate

and arguments that comprise the fact itself; an index, i, giving the position of the fact in
the fact array; a bit mask which is a spike vector in which the ith bit is set and all other bits
are unset; a reference identifying its achieving no-op; a spike vector consumers with bits set
for all the actions which use this fact as a precondition and a fact level package storing the
layer-dependent information about that fact.

Denition 3 An action header is a tuple of eight components: the name of the action;

an index, i, giving the position of the action in the action array; a bit mask which is a
spike vector in which the ith bit is set and all other bits are unset; a ag indicating whether
the action is a no-op; three spike vectors, called precs, adds and dels and an action level
package storing the layer-dependent information about that action. Each bit in precs, adds
89

Long & Fox

Fact Layer 0

P

Action Layer 1

Noop

P

Noop

Q

Q
R

Fact Layer 1

Noop
op1
op2

P
Noop
Q
Noop

S

Noop

U

Fact Layer 2

Noop

R

T

Action Layer 2

R
S

Noop
T
Noop
U

op1
op2
op3

V
W

Fact Spike
and Fact Level Packages

rank 0

rank 1

Action Spike
and Action Level Packages

P

Noop
P

Q

Noop
Q

R

Noop
R

S

op1

T

op2

U

Noop
S

V

Noop
T

W

Noop
U

rank 2

rank 1

rank 2

op3

Figure 1: Representation of a plan graph as a spike. In the fact spike, ranks 0, 1 and 2
correspond to fact layers 0, 1 and 2 respectively. In the action spike, ranks 1 and
2 correspond to action layers 1 and 2 respectively.

90

Efficient Implementation of the Plan Graph in STAN

and dels corresponds to an index into the fact array and is set in precs if the fact at that
index is a precondition (and unset otherwise), in adds if the fact at that index is an add list
element (and unset otherwise) and in dels if the fact at that index is a delete list element
of the action (and unset otherwise).

Denition 4 A fact mutex vector (FMV) for a fact, f , is a spike vector in which the bits
correspond to the indices into the fact array and a bit is set if the corresponding fact is
mutex with f .
Denition 5 An action mutex vector (AMV) for an action, a, is a spike vector in which

the bits correspond to the indices into the action array and a bit is set if the corresponding
action is mutex with a.

Denition 6 A fact level package for a fact, f , is an array of pairs, one for each rank in

the spike, each containing a fact mutex vector for f and a vector of achievers, called the
achievement vector (AV), in the previous action rank.

Denition 7 An action level package for an action, a, is an array of triples, one for each
rank in the spike, each containing an action mutex vector for a and a list of actions mutex
with a (MAs).
Using these denitions we can now provide a detailed description of the spike construction process.

2.1 The Spike Construction Process

We will make use of these header access functions in the following discussion:
mvec : fact ! fact mutex vector
precs of : action ! precs
adds of : action ! adds
dels of : action ! dels
The spike construction process takes place within a loop which stops when all goals are
pairwise achievable, and thereafter alternates with search until the x point is reached and
the wave front mechanism takes over. The use of the wave front is discussed in Section 4.
The key component of the process is the rank construction algorithm which builds a fact
rank and an action rank by extending the previous fact and action ranks in the spike. The
action rank is started by adding no-ops for each of the fact headers in the previous fact
rank. As soon as these are added, the fact headers can be updated to refer, by index into
the action rank, to their achieving no-ops. This information allows Stan to give preference,
when searching, to plans that use the no-op to achieve a goal rather than some other
achiever. In Graphplan this preference was ensured by keeping all of the no-ops at the top
of the graph layers and considering the achievers in order during search.
All possible action instances are then considered. All applicable action instances are
enacted and then removed so that they will never be reconsidered for enactment. We then
identify mutex relations between the actions in the new action rank, and between facts in
the new fact rank.
91

Long & Fox

As in Graphplan, an action instance is applicable in a rank if all of its preconditions are
present and non-mutex in the previous rank. The way in which preconditions are tested for
mutual exclusion in Stan is based on our bit vector representation of fact mutex relations.
We take the logical or of all of the fact mutex vectors of the preconditions, and logically
and the result with the precondition vector of the action. If the result is non-zero then
there are mutex preconditions and the action is not applicable. This test corresponds to
checking whether the action being considered is mutex with itself - a condition we dene as
being self-mutex.

Denition 8 An action a, with preconditions a 1::a , is self-mutex if:
(mvec(a 1) _ mvec(a 2) _ ::: _ mvec(a )) ^ precs of (a)
p

p

pn

p

pn

is non-zero.

An applicable action is enacted by adding an action header to the new rank and setting
its name to the name of the action and its bit mask to record its position in the spike.
In Figures 2 and 3 no-ops are given the names of the facts they achieve and are identied
as no-ops by the ag components of their headers. We allocate space for the action level
package and create and set its pres, adds and dels vectors. We then add any new facts on
the add list of the action to the corresponding new fact rank. The addition of new facts
requires new fact headers to be initialised.
We then identify mutex actions and mutex facts in the new ranks. Mutex actions
are identied in two phases. Actions which were non-mutex in the previous rank remain
non-mutex and are not considered at this stage. First, existing action mutex relations are
checked to see whether they hold in the new rank. Second, new action mutex relations
must be deduced from the addition of new actions in the construction of this rank. We rst
consider the existing action mutex relations.
Two actions are mutex, as in Graphplan, if they have conicting add and delete lists,
conicting precondition and delete lists or mutex preconditions. In the rst two cases
the actions are directly, or permanently, mutex and never need to be re-tested although
their mutex relationship must be recorded at each rank. In the third case the actions are
indirectly, or temporarily, mutex and must be retried at subsequent ranks. We keep track of
which actions to retry in order to avoid unnecessary retesting. We conrm that two actions,
a and b, which were temporarily mutex in the previous rank are still temporarily mutex
using the following logical operations on the fact mutex vectors for the action preconditions.
We rst logically or together the mutex vectors for a's preconditions then and the result
with the precondition vector for b. If the result is non-zero then a and b are mutex. This
procedure, which is expressed concisely in Denition 9, is identical to that for checking
whether an action is self-mutex except that, in this case, the result of oring the fact mutex
vectors of the preconditions of one action is anded with the precondition vector of the other
action. Since mutex relations are symmetric it is irrelevant which action plays which role
in the test.

Denition 9 Two actions a (with n preconditions a 1::a ) and b are temporarily mutex

if

p

pn

(mvec(a 1) _ mvec(a 2) _ ::: _ mvec(a )) ^ precs of (b)
p

p

pn

92

Efficient Implementation of the Plan Graph in STAN

is non-zero.

We now consider what new mutex relations can be inferred from the introduction of
the new actions. It is necessary to check all new actions against all actions in the spike.
This check is done in only one direction - low-indexed actions against high-indexed actions
- so that the test is done only once for each pair. We check for both permanent and
temporary mutex relations. The permanent mutex test is done rst, because if two actions
are permanently mutex it is of no interest to nd that they are also temporarily mutex.
Denition 10 provides the logical operation used to conrm that two actions are permanently
mutex. Temporary mutex relations are checked for using the logical operation dened in
Denition 9.
Denition 10 Two actions a and b are permanently mutex if the result of
((precs of (a) _ adds of (a)) ^ dels of (b))_
((precs of (b) _ adds of (b)) ^ dels of (a))
is non-zero.

We add these mutex relations by setting the appropriate bits in the mutex vectors of
each of the new actions. This is done by oring the mutex vector of the rst action with the
bit mask of the second action, and vice versa. A list of mutex actions is also maintained for
use during search of the spike.
A renement of the action mutex checking done by Stan is the use of a record of actions
whose preconditions have lost mutex relations since the last layer of the graph. This record
enables Stan to avoid retesting temporary mutex relations between actions when the mutex
relations between their preconditions cannot have changed. We use a bit vector called
changedActs to record this information. Each fact which loses mutex relations between
layers adds its consumers to changedActs. The impact of this renement on eciency is
discussed in Section 3.
This concludes the construction of the new action rank. The new fact rank has already
been partially constructed by the addition to the spike of fact headers for any add list
elements, of the new actions, that were not already present. Now it is necessary to determine
mutex relations between all pairs of facts in the spike. To do this we must rst complete
the achievement vectors for all of the fact headers in the new rank. Any non-mutex pairs
remain non-mutex, as with actions, so eort is focussed on deciding whether previously
mutex facts are still mutex following the addition of the new actions, and whether new
facts induce new mutex relations. Two facts are mutex if the only way of achieving both
of them involves the use of mutex actions. We therefore consider every new fact with every
other fact, in only one direction. The pair f , g is mutex in the new rank if every possible
achiever of f is mutex with every possible achiever for g . The test for this exclusion is done
using g 's achievement vector and the result of logically anding the action mutex vectors for
all possible achievers of f . the following denition gives the details:

Denition 11 Two facts, f and g, are mutex if:
vec ^ all mutex = vec
g

f

93

g

Long & Fox

where vec is g 's achievement vector and all mutex is the consequence of anding all of the
action mutex vectors of all of f 's possible achievers.
f

g

It does not matter in which order f and g are treated. The computation of the above
condition corresponds to testing the truth of

8a  8b  (achiever(a; f ) ^ achiever(b; g) ! mutex(a; b))
Since mutex relations are symmetric and the quantiers can be freely reordered the expression equally corresponds to
vec ^ all mutex = vec
If f and g are found to be mutex then we set the fact mutex vector of f by oring it
with g 's bit mask and the fact mutex vector of g is set conversely. This concludes the rank
construction process and one iteration of the spike construction process.
f

g

2.2 Subset Memoization in Stan

f

Most of the search machinery used in Stan is essentially identical to that of Graphplan.
That is, a goal set is considered by identifying appropriate achieving actions in the previous
layer and propagating their preconditions back through the graph. The use of the spike
and bit vector representations does not impact on the search algorithm. We experimented
with using bit vector representations of bad goal sets in the memoization process, in order
to exploit logical bit operations to test for subset relations between sets of goals, but this
proved too expensive and we now rely upon a trie data structure. This benets marginally
from the spike because goal sets do not need to be sorted for subset testing. The order
in which the goals are generated in the spike can be taken as the canonical ordering since
goal sets are formed by a simple sweep through the spike at each successive layer. Stan
implements an improvement on the goal set memoization of Graphplan. In the original
Graphplan, when a goal set could not be achieved at a particular layer the entire set was
memoized as a bad set for that layer. In Stan version 2, only the subset of goals that
have been satised at the point of failure, within a layer, are actually memoized. More goal
sets are likely to contain the smaller memoized subset than would be likely to contain the
complete original failing goal set. This therefore allows us to prune search branches earlier.
This method is a weak version of Kambhampati's (1998, 1999) EBL (Explanation-Based
Learning) modications. EBL allows the identication of the subset of a goal set that is
really responsible for its failure to yield a plan. Memoization of smaller sets increases the
eciency of the planner by reducing the overhead necessary in identifying failing goal sets.
DDB (Dependency-Directed Backtracking) improves the search performance by ensuring
that backtracking returns to the point at which the last choice responsible for failure was
made. These modications result in smaller sets being memoized and a more ecient search
behaviour which, in combination with the trie, ensure that a higher proportion of failing
search paths are terminated early.
We have experimented with an implementation of the full EBL/DDB modications
proposed by Kambhampati, but there is an interaction between the EBL/DDB machinery
and the wave front of Stan which we are currently attempting to resolve. Our experiments
so far indicate that both the wave front and EBL/DDB have signicant benecial impact
94

Efficient Implementation of the Plan Graph in STAN

on search, but not consistently across the same problems. We believe that we can enhance
the advantages of the wave front by full integration with EBL/DDB, but this remains to
be demonstrated.

2.3 A Worked Example

We now demonstrate the spike construction process in action on a simple blocks world example in which there are two blocks and two table positions. In the initial state, both blocks
are on the table, one in each of the two positions. Consequently there are no clear table
positions. The initial spike consists of a fact rank containing fact headers for the four facts
that describe the initial state. There is a single operator schema, puton(Block; To; From),
as follows:

puton(X,Y,Z)

Pre:
on(X,Z), clear(X), clear(Y)
Add:
on(X,Y), clear(Z)
Del:
on(X,Z), clear(Y)
The action rank is initially empty. On the rst iteration of the loop the rst action rank
is constructed by creating no-ops for every fact in the zeroth fact rank. Two further actions
are applicable and are enacted, and the facts on their addlists are used to create a new fact
rank. This results in the partially developed spike shown in Figure 2.
It can be observed from Figure 2 that, following enactment, the fact headers associated
with the newly added facts are incomplete, and although the new fact level and action level
packages have been allocated they do not yet contain any values. The new fact headers are
missing references to the no-ops that will be used to achieve them in the next action rank.
The new fact level packages are blank because their corresponding fact headers will have
no level information for rank 0.
After identication of mutex actions and mutex facts, the picture is as shown in Figure 3.
In the action level packages, the lists of mutex actions are given as lists of indices for the
sake of clarity. In fact they are lists of pointers to actions, in order to avoid the indirection
involved in the use of indices. None of the action pairs are temporarily mutex at rank 1
because all of the fact mutex vectors from rank 0 are zero-valued.

3. Empirical Results

In this section we present results demonstrating the eciency of the spike and vector representation of the plan graph used by Stan. We consider graph construction only in this
section { the eciency of search in Stan will be demonstrated in Section 4. We show the
eciency of graph construction in Stan by showing relative performance gures for Stan
and the competition version of Ipp in several of the competition domains and two further
standard bench mark domains. These are the Graphplan version of the Travelling Salesman
domain (Blum & Furst, 1997), which uses a complete graph and is referred to here as the
Complete-Graph Travelling Salesman domain, and the Ferry domain available in the PDDL
release.
We compare Stan with Ipp because, to the best of our knowledge, Ipp is the only
other fast Graphplan-based planner currently publicly available. We use the competition
95

Long & Fox

Fact Spike
name: on(a,t1)
index: 0
msk 10000000
noop: 0

Action Spike

(rank 0)
FMV: 0...0
AV:

name: on(b,t2)
index: 1
msk 01000000
noop: 1

name: clear(b)
index: 3
msk 00010000
noop: 3
name: on(a,b)
index: 4
msk 00001000
noop:

0...0

0...0

FMV: 0...0
AV:

name: clear(a)
index: 2
msk: 00100000
noop?: True
precs: 00100000
adds: 00100000
dels: 00000000

0...0

FMV: 0...0
AV:

Action Level Packages
(rank 1 - as yet
uninstantiated)

name: on(b,t2)
index: 1
msk: 01000000
noop?: True
precs: 01000000
adds: 01000000
dels: 00000000

FMV: 0...0
AV:

name: clear(a)
index: 2
msk 00100000
noop: 2

name: on(a,t1)
index: 0
msk: 10000000
noop?: True
precs: 10000000
adds: 10000000
dels: 00000000

Fact Level Packages

0...0

name: clear(b)
index: 3
msk: 00010000
noop?: True
precs: 00010000
adds: 00010000
dels: 00000000

name: clear(t1)
index: 5
msk 00000100
noop:

name: puton(a,b,t1)
index: 4

name: clear(t2)
index: 6
msk 00000010
noop:

msk: 00001000
noop?: False
precs: 10110000
adds: 11000000
dels: 10010000

name: on(b,a)
index: 7
msk 00000001
noop:

name: puton(b,a,t2)
index: 5
msk: 00000100
noop?: False
precs: 01110000
adds: 00000011
dels: 01100000

Figure 2: The spike after enactment of the rank 1 actions.

96

Efficient Implementation of the Plan Graph in STAN

Action Spike

Fact Spike

name: on(a,t1)
index: 0
msk 10000000
noop: 0
name: on(b,t2)
index: 1
msk 01000000
noop: 1
name: clear(a)
index: 2
msk 00100000
noop: 2
name: clear(b)
index: 3
msk 00010000
noop: 3
name: on(a,b)
index: 4
msk 00001000
noop:

name: on(a,t1)

Fact Level Packages
(ranks 0 and 1)

FMV: 0..0

00001000

AV: 0..0

10000000

index: 0
msk: 10000000
noop?: True
precs: 10000000
adds: 10000000
dels: 00000000

AMV: 00001000
MAs: 4

name: on(b,t2)
FMV: 0..0

00000100

AV: 0..0

01000000

FMV: 0..0

00000011

AV: 0..0

00100000

FMV: 0..0

00001000

AV: 0..0

00010000

index: 1
msk: 01000000
noop?: True
precs: 01000000
adds: 01000000
dels: 00000000

AMV: 00000100
MAs: 5

name: clear(a)
index: 2
msk: 00100000
noop?: True
precs: 00100000
adds: 00100000
dels: 00000000

AMV: 00000100
MAs: 5

name: clear(b)
index: 3
msk: 00010000
noop?: True
precs: 00010000
adds: 00010000
dels: 00000000

10000011

name: clear(t1)
index: 5
msk 00000100
noop:

00001000

name: clear(t2)
index: 6
msk 00000010
noop:

00001000

AMV: 00001000
MAs: 4

name: puton(a,b,t1)
index: 4

01000011

msk: 00001000
noop?: False
precs: 10110000
adds: 11000000
dels: 10010000

00100100
00000100

name: on(b,a)
index: 7
msk 00000001
noop:

Action Level Packages
(rank 1)

name: puton(b,a,t2)
index: 5
msk: 00000100
noop?: False
precs: 01110000
adds: 00000011
dels: 01100000

00101100
00000100

AMV: 10010100
MAs: 0,3,5

AMV: 01101000
MAs: 1,2,4

Figure 3: The spike at the end of the rank 1 construction phase.

97

Long & Fox

100000

33 3
3

10000

3
3

1000

100
100
IPP

3

1000

10000

STAN

100000

Figure 4: Graph construction in the logistics domain: Stan shows a constant factor improvement over the performance of Ipp.
1000

100

3

IPP
10

3

3

3
3

33
3
3

10

3

100
STAN

Figure 5: Graph construction in the Gripper domain.
98

1000

Efficient Implementation of the Plan Graph in STAN

version of Ipp because this is the most up to date version available from the Freiburg
webpage at the time of writing. In order to focus on the graph construction phase, and
eliminate the search phase from both planners, we have constructed versions of Stan and
Ipp which terminate once the graph has opened. We have removed from Stan all of the
unnecessary pre-processing, domain analysis and additional features that contribute to later
search eciency. However, since Ipp is designed to build one more layer before opening
than is strictly necessary, to include a dummy goal corresponding to the achievement of the
conjunction of the top level goal set, we make Stan build one extra layer too so that the
two systems are comparable. We have removed all of the meta-strategy control from Ipp,
forcing Ipp directly into its graph construction. It is possible that a more streamlined graph
constructor could be built from Ipp by elimination of further processing, but we observed,
during experimentation with Ipp, that pre-processing accounts for insignicant proportions
of the timings reported below. We are therefore condent that any further streamlining
would have minimal eects on our results. In order to compare Stan and Ipp accurately it
was necessary to modify the timing mechanisms to ensure that precisely the same elements
are timed. A Unix/Linux di le is available at the Stan website, and in Online Appendix
1, for anyone interested in reconstructing the Ipp graph construction system we have used.
The domains and problems used, and our graph construction version of Stan, can also be
found at these locations.
All experiments reported in this paper were carried out on a P300 Linux PC, with
128Mb of RAM and 128Mb swap space. All of the timings in the data sets reported are in
milliseconds.
All the graphs are log-log scaled. This was necessary to combat the long scales caused by
very large timings associated with a few instances in each domain. The graphs show Ipp's
construction performance compared with Stan's construction performance measured on the
same problems in each of six domains. The straight line shows where equal performance
would be. Points above the line indicate superior performance by Stan and points below
the line indicate superior performance by Ipp. In all of the rst ve data sets, Stan clearly
out-performs Ipp. In the last data set (Figure 9), Ipp convincingly out-performs Stan and
we now consider a more detailed analysis of the characteristics of the domains and instances
which explain these data sets.
The rst four data sets reveal a very similar performance. The points are broadly parallel to the equal performance line, indicating that Stan performs at a constant multiple
of the performance of Ipp. Despite the trend that these data sets reveal, occasional data
points deviate signicantly from this behaviour. This reects the fact that dierent structures of particular problems exercise dierent components of the graph construction system.
Components include instantiation of operators, application of individual operator instances
and the corresponding extension of fact layers and checking and re-checking mutex relations
between facts and between actions. We observed that in some problem instances, 50 per
cent or more of the construction time was spent in action mutex checking, whilst in others
instantiation dominated. The density of permanent mutex relations between actions, and
the degree of persistence of temporary mutex relations between actions, are both very signicant in determining eciency of performance. For example in problem 8 in the Mystery
domain, where 21 layers are constructed before the graph opens, only 9 per cent of the
action pairs were discarded as permanently mutex and, of the temporary mutex pairs, the
99

Long & Fox

100000

3
3

10000

3 3
3

1000
IPP

3

3

100
10

3

10

100

1000
STAN

10000

100000

Figure 6: Graph construction in the Mystery domain. Stan's performance in this domain
is consistently better than that of Ipp, but shows more marked variation revealing
that the benets of the spike are problem-dependent.
100000

3

10000

3

3

3

33

3

IPP
1000
1000

10000
STAN

Figure 7: Graph construction in the Mprime domain.
100

100000

Efficient Implementation of the Plan Graph in STAN

1000

100

33
3
3
33
3

3
3
3

10
IPP
1

1

10

STAN

100

1000

Figure 8: Graph construction in the Ferry domain. Stan shows polynomially better graph
construction performance than Ipp.
average number of re-tests across the entire graph construction was over 7. The use of
the changedActs mechanism described in Section 2.1, to avoid retesting actions when their
precondition mutex relations had not changed from the previous layer, gave us a 50 per
cent improvement in performance and accounts for a more than 40 second advantage over
Ipp in the construction phase of this problem.
In other problems a much higher percentage of action pairs are permanently mutex,
allowing early elimination of many action pairs from further retesting. Where mutex relations are not highly persistent a similar elimination rate is possible. This allows much
faster construction for Stan. Ipp does not benet in the same way, because it does not
distinguish between temporary and permanent mutex and does not try to identify which
pairs of actions should be retested.
In the Ferry domain, Figure 8, 7 layers are constructed to open the graph regardless
of instance size. Analysis reveals that approximately 25 per cent of action pairs are permanently mutex and the average persistence of temporary mutex relations is slightly more
than 2 layers. Since Ipp does not intelligently eliminate actions from retesting, the implication of this is that Ipp unnecessarily re-checks mutex relations for a polynomially increasing
number of pairs of actions. This explains the polynomial advantage obtained by Stan in
this domain.
The last data set shows a rather dierent pattern of performance from that of the
others. The Complete-Graph Travelling Salesman domain used to produce the data set for
Figure 9 is a simplied version, in which the graph is fully connected, of the well known
101

Long & Fox

1000

100

3

IPP
10

10

3

3

100
STAN

3

3

3

1000

Figure 9: Graph construction in the Complete-Graph Travelling Salesman domain. Stan
displays a polynomially deteriorating graph construction performance. This is
further discussed in the text.

NP-hard TSP. It is, in principle, eciently solvable. In Figure 9 Ipp's performance appears
to be polynomially better than that of Stan. Analysis of the graph structure built for
dierent instances reveals that, on all instance sizes, the graph opens at layer 3. In these
graphs an interesting pattern can be observed in the mutex relations between actions: the
vast majority of action pairs are mutex after their rst application at layer 2 (because the
salesman can only ever be in one place). These mutex relations are considered, by both
Stan and Ipp, to be temporary although they in fact persist. The consequence is that both
Stan and Ipp retest all pairs at the next layer. Stan obtains no advantage from the use of
changedActs or the distinction between temporary and permanent mutex relations in this
domain. The number of mutex pairs to be checked increases quadratically with increase
in instance size, which is in line with Stan's performance. Ipp clearly pays much less for
this retesting, despite the fact that it does the same amount of work. This fact, together
with proling of both systems, leads us to believe that the disadvantage suered by Stan is
due to the overhead in supporting object member applications in its C++ implementation.
It is worth pointing out that in the Complete-Graph Travelling Salesman domain, as well
as in Gripper and Ferry, the construction time for both planners is under 1 second for all
instances tested so the discrepancies in performance in these three domains are insignicant
compared with the discrepancies measured in seconds (for large instances) in the other
domains.
102

Efficient Implementation of the Plan Graph in STAN

Fix Point

G1

Buffer

G

G2
G3
G4

G1

G5

G2

Figure 10: The wave front in Stan.

4. The Wave Front
When a layer is reached in which all of the top level goals are pairwise non-mutex Graphplanbased planners begin searching for a plan. If no plan can be found, new layers are constructed alternately with search until the x point of the graph is reached. In Graphplan
and Ipp the graph continues to be explicitly constructed beyond the x point, even though
the layers which can be built beyond this point are sterile (contain no new facts, actions or
mutex relations). Their construction is necessary to allow the conditions for achievement of
goal sets to be established, between the x point and the current layer. However, this constitutes signicant computational eort in copying existing structures and in unnecessary
searching of these duplicate structures. Instead of building these sterile layers explicitly,
Stan maintains a single layer, called the buer, beyond the x point together with a queue
of goal sets remaining to be considered. Each time a goal set is removed from this queue,
to be considered in the buer, those goal sets it generates in the x point layer, which have
103

Long & Fox

not been previously marked as unsolvable, are added to the queue. The goal sets in this
queue are considered in order, always for achievement in the buer layer. Thus, rather
than constructing a new layer each time the top level goal set proves unsolvable, and then
reconsidering all of the same achievers in the new layer, the goal sets in the queue are simply
considered in the buer layer. We call this mechanism a wave front because it pushes goal
sets forward from the x point layer into the buer, and then recedes to consider another
goal set from the x point layer. The goal sets generated at the x point, which join the
queue for propagation, are referred to as candidate goal sets. The wave front is depicted in
Figure 10. The underlying implementation of the plan graph remains based on the spike,
but the gure depicts the graph in the traditional way for simplicity.
In the picture, G represents the top level goal set and when it is used to initiate a plan
search from the buer layer it generates the sequence of goal sets G1, G2 and G3 at the
x point layer. Assuming that these all fail, the rst set in this queue, G1, is propagated
forward to the buer leading to the generation of goal sets G4 and G5 in the x point layer.
These are added to the end of the queue and G2 will be the next goal set selected from the
queue to propagate forward.
In order to demonstrate that the wave front machinery maintains an appropriate behaviour there are three questions to be considered.
1. Is every goal set that would have been considered in the buer layer, had the graph
been constructed explicitly, still considered using the wave front? This question concerns completeness of the search process.
2. Does every plan generated to achieve a goal set that is considered in the buer layer
correspond to a plan that would have been generated had the graph been explicitly
constructed? This question concerns soundness.
3. The nal question concerns whether the termination properties of Graphplan are
maintained.

Denition 12 A k-level goal tree for goal set G at layer n in a plan graph, GT , is a
general tree of depth k in which the nodes are goal sets and the parent-child relationship is
dened as follows. If the goal set x is in the tree at level i then the goal set y is a child of
x if y is a minimal goal set containing no mutex goal pairs such that achievement of y at
layer n , i , 1 in the plan graph enables the achievement of x at layer n , i in that graph.
We take the root to be at level 0 of the tree and the leaves to be at level k , 1.
k;G;n

Lemma 1 If n , k  FP then GT
point layer in the plan graph.

k;G;n

= GT

+1 ,

k;G;n

where FP is the number of the x

Proof By denition of the x point, all layers in a plan graph beyond the x point contain

an exact replica of the information contained at the x point layer. Since, by denition
of the goal tree, the parent-child relationship depends exclusively upon the relationship
between two consective layers in the plan graph, and layers cannot change after the x
point, it follows that if x is the parent of y at some layer beyond the x point then the
parent-child relationship between x and y must hold at any pair of consecutive layers beyond
the x point. Further, no new parent-child relationships can arise beyond the x point. The
104

Efficient Implementation of the Plan Graph in STAN

restriction that n , k  FP ensures that all layers in both goal trees lie in the region beyond
the x point.

2
The completeness of Stan follows from the completeness of Graphplan provided that
all of the goal sets that would appear in the layer after the x point in the explicit graph
arise as candidates to be considered in the buer layer using the wave front. We now prove
that this condition is satised by rst proving that the leaves of goal trees generated at
successive layers of a plan graph are all used to generate candidates in Stan. Since the goal
sets considered by Graphplan are always subsets of the leaves of goal trees it will be shown
that the completeness of Stan follows.

Theorem 1 Given a goal set, G, and a plan graph of n layers, containing no plan for G
of length n , 1, with x point at layer FP (n > FP ), all of the leaves of GT ,
are
n

generated as candidates by Stan.

F P;G;n

Proof The proof is by induction on n, with base case n = FP + 1. In the base case the

result follows trivially because the only leaf in GT1
+1 is the top level goal set G and
this is generated as the initial candidate by Stan.
Suppose n > FP + 1. The inductive hypothesis states that all of the leaves of the tree
GT ,1,
,1 are generated as candidates by Stan. Since the plan graph constructed by
Stan is identical to that of Graphplan up to layer FP + 1, and all candidates are used to
initiate search from layer FP + 1, the leaves of GT ,
,1 will also be generated as goal
sets in layer FP by Stan. These goal sets are then used by Stan to construct candidates.
Stan will not generate multiple copies of candidates, but each new goal set will generate a
new candidate.
By Lemma 1, GT ,
= GT ,
are gener,1 , so that the leaves of GT ,
ated as candidates by Stan.
;G;F P

n

F P;G;n

n

n

F P;G;n

n

F P;G;n

F P;G;n

n

F P;G;n

2
The denition of goal trees captures precisely the relationship between goal sets and
the search paths considered by Graphplan. However, because Graphplan memoizes failed
goal sets it can prune parts of a goal tree as it regresses through the explicit plan graph
during search. Whenever a goal set contains a memoized goal set search terminates along
this branch and none of its children will be generated. It can now be seen that Graphplan
will generate at layer FP + 1 a subset of the leaves of GT ,
, when searching from
layer n with goal set G, whereas Theorem 1 demonstrates that Stan will construct all of
these leaves as candidates.
This argument might suggest that Stan engages in unnecessary search by generating
candidates that Graphplan can prune, using memos, in layers that are not constructed
explicitly by Stan. In fact, Stan generates no more candidates than Graphplan generates
goal sets at layer FP +1. Indeed, Stan achieves a dramatic reduction in search by exploiting
the correspondence between the goal trees generated at layers n and n , 1, demonstrated by
Lemma 1. Because of this correspondence there is no need to construct the layers between
FP + 1 and n explicitly, and undertake all of the concommitant search from those layers.
n

105

F P;G;n

Long & Fox

Layer 0

FP

FP+1

n-1

n

G1

L1
L2

G2

G

G3

Ln

L1

G1

L2

G2

G

G3

Ln

Figure 11: The sliding window of layers between FP + 1 and n.
Graphplan rebuilds the sliding window, shown in Figure 11, of layers between FP and n , 1
as layers FP + 1 through to n. Stan simply promotes the leaves of the tree, generated at
layer FP in GT ,
,1 , into layer FP + 1.
It is straightforward to show that the wave front maintains soundness. The search that
Graphplan performs generates a goal tree of goal sets, as dened in Denition 12. In the
example in Figure 10, the tree is rooted at G, with G1, G2 and G3 its children and G4 and
G5 the children of G1. It can be seen from the picture that the tree structure generated
by Graphplan, in which each successive layer would be embedded in a separate layer of the
explicitly constructed graph, appears in a spiral of related goal sets between the x point
and buer layers. All of the candidate goal sets lie in this same search tree and therefore no
additional goal sets are generated. Graphplan constructs the nal plan by reading o the
sequence of action choices at each layer in the nal graph. In Stan, the plan is obtained
by reading o the initial fragment of the plan in the same way, from the layers preceding
the x point. The rest of the plan is extracted from the spiral. This extraction process
yields the same path of action choices from the top level goal set to the candidate goal set
as would be recorded explicitly in the Graphplan plan graph.
The only question remaining to be considered is whether the wave front has the same
termination properties as Graphplan. It can be seen that it does since, if no new unsolvable
goal sets are generated at the x point, the queue will become empty and the planner
terminates. This corresponds exactly to the termination conditions of Graphplan.
A subtlety concerns the interaction between the wave front and the subset memoization
discussed in Section 2.2. In principle, subset memoization could cause the loss of all three of
the desired properties of the graph. The way that Stan generates candidate goal sets is by
n

F P;G;n

106

Efficient Implementation of the Plan Graph in STAN

simultaneously generating a candidate set whenever a goal set is memoized at the x point.
If the candidate set and the memoized set are one and the same, then the memoization of
a subset of a goal set will lead to the propagation of only a subset of the actual candidate
goals into the buer and soundness might be undermined. If we use subset memoization at
the wave front then the question arises whether sets that contain a memoized subset should
be propagated forward as candidates. If they are not, then completeness is potentially
lost, since there might be action sequences that could have been constructed following
propagation that will not now be found. If they are, then termination is potentially lost,
since the set that led to the construction of the memoized subset might itself be generated
as a candidate. This could happen, for example in Figure 10, if G1 is unsolvable at the x
point but is generated again by consideration of a later candidate at the buer.
To avoid these problems we have restored full subset memoization at the wave front.
An alternative solution, which we are currently exploring, is to separate the subsets of
goals memoized from the identication of the candidate sets. Both solutions avoid the loss
of soundness because candidates are constructed from entire goal sets rather than from
subsets. In the rst solution, termination is preserved because memoizing full goal sets
ensures that repeated candidates can be correctly identied as they recur. In the second
solution, we would separately memoize candidates as they were generated to avoid repeated
generation, thereby maintaining termination. In both cases, completeness is preserved by
propagating goal-sets forward as new candidates provided only that they do not contain
previously encountered candidates as subsets. If a potential candidate is a superset of an
entire memoized candidate then it is correct not to propagate that potential candidate into
the buer because if the memoized candidate cannot be solved at the buer then no superset
of it can be solved there either.

5. Experimental Results
The results presented here use Stan version 2 (available at our website). We have performed
experiments comparing Stan with and without the wavefront in order to demonstrate the
advantages obtained by the use of the wave front. We have performed further experiments
to compare Stan with the competition version of Ipp. There are some minor discrepancies
in the timing mechanisms of these two systems. Stan measures elapsed time for the entire
execution, whereas Ipp measures user+system time for graph construction and search but
not for parsing of the problem domain and instance. On a single user machine as used for
these experiments the discrepancy is negligible.
The problem domains used in this section have been selected to emphasise the benets
oered by the wave front. The important characteristic is that there should be an early
x point relative to the length of plan as instances grow. In the comparisons with Ipp the
wave front accounts for the trends in performance, although Stan employs a range of other
mechanisms which give it some minor advantages. Amongst these is the Tim machinery,
which we have not decoupled as the problem domains used are the standard typed ones
so that no signicant advantage is obtained from inferring type structures automatically.
Only the resource invariants inferred by Tim are exploited by Stan version 2, and we
have indicated where this gives us an advantage over Ipp. Our ablation data sets conrm
107

Long & Fox

100000

3

10000

3
3

1000
IPP

3

100
10

10

3

100

STAN

1000

10000

Figure 12: Stan compared with Ipp: solving Towers of Hanoi problems of 3-7 discs.
that the wave front is the most signicant component in the performance of Stan in these
experiments.
Stan is capable of eciently solving larger Towers of Hanoi instances than are presented
in the graph in Figure 12, which accounts for the additional point in Figure 13. Stan with
the wave front found the 511-step plan for the 9-disc problem in less than 7 minutes using
about 15Mb of memory. During the experiments reported here, Ipp was terminated after
15 minutes having reached layer 179 out of 255 layers in the 8-disc problem. We observe
that on a machine with 1Gb of RAM, Ipp has solved this problem in 8 minutes.
The results for the Gripper domain demonstrate only a small advantage for Stan. The
reason is because the search space grows exponentially in the size of the graph in the Gripper
domain, so that the cost of searching dominates everything else. Although the search spaces
for Towers of Hanoi instances also grow exponentially, they grow as 2 whereas Gripper
instances grow as x (where x is the number of discs or balls respectively). Although the
wave front helps under these conditions, the size of the search space dwarfs the benets it
oers. The Ferry domain is a less rapidly growing version of the gripper domain since only
one vehicle can be carried on each journey, reducing the number of choices at each layer.
The dierence in benets obtained in the Towers of Hanoi domain relative to the Gripper
and Ferry domains can be explained by consideration of the table in Figure 16. The benets
of the wave front are proportional to the number of layers which exist implicitly between
the buer and the layer from which the plan is ultimately found. In the Towers of Hanoi
the number of implicit layers is exponential in the number of discs whereas the number of
layers between the initial layer and the buer is linear in the number of discs. Therefore
the benets oered by the use of the wave front are magnied exponentially as the problem
x

x

108

Efficient Implementation of the Plan Graph in STAN

1e+06

3

100000

3
3

10000

3

1000
100

3

10
STAN no wf 10

3
100

1000
STAN wf

10000

100000

Figure 13: Stan with and without the wave front: solving Towers of Hanoi problems of 3-8
discs.
1e+06

3

100000

3

10000
1000

3

IPP 100
10

3
10

100

1000

STAN

10000

100000

1e+06

Figure 14: Stan compared with Ipp: solving Gripper problems of 4-10 balls.
109

Long & Fox

1e+06

3

100000

3

10000
1000
100
10
STAN no wf 10

3
3
100

1000
10000
STAN wf

100000

1e+06

Figure 15: Stan with and without the wave front: solving Gripper problems of 4-10 balls.
Domain
Towers of Hanoi
Gripper
Ferry
Complete-Graph TSP

Parameter n Plan Length Buer
no. discs
2 ,1
n+3
no. balls
2n , 1
5
no. vehicles
4n , 1
7
no. cities
n
4
n

Figure 16: Relative values of plan length and number of layers to buer for four domains.
instance grows. On the other hand, in both Gripper and Ferry there is only a linear growth
in the dierence between plan length and x point layer, so benets are magnied only
linearly. This analysis can be conrmed by observation of Figures 12, 14 and 17.
The benet of the wave front is measured not only in terms of the cost of construction
that is avoided by not explicitly building the layers beyond the buer, but also in terms
of the search that is avoided in those layers. Crudely, the benets can be measured as
the number of layers not constructed multiplied by the search eort avoided at each of
those layers. Thus, the number of layers not constructed magnies the benets obtained
by not searching amongst them. This is a simplication, since the search eort avoided at
successive layers increases as they get further away from the x point, but it gives a guide
to the kind of benets that can be expected from the wave front.
Stan obtains signicant advantages over Ipp in the Complete-Graph Travelling Salesman domain, as Figure 19 demonstrates. Some of these advantages are obtained by ex110

Efficient Implementation of the Plan Graph in STAN

1e+06

3

100000

3

10000

3

1000

3
3

IPP 100
10

3
10

100

1000
STAN

10000

100000

Figure 17: Stan compared with Ipp: solving Ferry problems of 2-12 cars.
1e+06

3

100000

3

10000

3

1000

3

100
10
STAN no wf 10

3

3
100

1000
STAN with wf

10000

100000

Figure 18: Stan with and without the wave front: solving Ferry problems of 2-12 cars.
111

Long & Fox

1e+10

3

1e+09

3

1e+08

3

1e+07

3

1e+06

3

100000
IPP

10000

3

1000
100
100

1000
STAN

10000

Figure 19: Stan compared with Ipp: solving Complete-Graph Travelling Salesman problems of 10-20 cities.
ploiting the resource analysis techniques of Tim (Fox & Long, 1998), whilst a signicant
proportion of the advantage is obtained from the use of the wave front, as Figure 20 shows.
Resource analysis allows a lower bound to be determined on the number of layers that must
be built in a plan graph before it is worth searching for a plan. In the Complete-Graph
Travelling Salesman domain this is very powerful, as the calculated bound is n, the number
of cities in the instance, which is precisely the correct plan length. In this domain, if no
search is done until n layers are constructed, no search needs to be done at all since it
doesn't matter in what order the cities are visited. This would allow the problem to be
solved in polynomial time (of course, this only makes sense because the Complete-Graph
TSP used here is simpler than the NP-hard TSP). However, when the wave front is used,
the buer is at layer 4 and the only way of nding the plan is to generate all of the candidate
goal sets at layer 4, of which there are an exponential number. The use of the wave front
in this domain therefore forces Stan to take exponential time in the size of the instances.
Despite this the wave front oers great advantages. The benets increase exponentially as
instance sizes grow although the magnication of these benets at each layer is only linear,
see Figure 16, although the benets are oset by the exponential growth in the number of
candidates. It must be observed that in Figure 19, the gures are extrapolated for Ipp for
instances in which n is greater than 14. The extrapolation was based on Ipp's performance
on instance sizes between 2 and 14, which demonstrates a clear exponential growth.
It appears that we could allow the resource analysis to over-ride the wave front when a
domain is encountered in which it can be guaranteed that explicit construction of the graph
112

Efficient Implementation of the Plan Graph in STAN

10000

3
3
3
3

1000

3
3
100
STAN no wf 100

1000
STAN with wf

10000

Figure 20: Stan with and without the wave front: solving Complete-Graph TSP problems.
will be more ecient. In practice the Complete-Graph Travelling Salesman domain seems
exceptional, since search is eliminated if the graph is constructed to layer n, and if this were
not the case the explicit construction and subsequent search would be more costly than the
use of the wave front.

5.1 The Wave Front Heuristic
The queue of candidate goal sets considered in the buer can be implemented as an unordered structure in which goal sets are selected for consideration according to more sophisticated criteria than the order in which they were stored. In principle, this could save
much searching eort since it could avoid costly consideration of goal sets which turn out to
be unsolvable before meeting a solvable goal set. We have experimented with a number of
goal set selection heuristics which favour goal sets for which the search progresses deepest
into the graph structure. These sets are considered to be closer to being solvable than sets
which fail in a layer very close to the buer. Candidates are evaluated by considering the
length of the plan fragment associated with the candidate and the extent to which the failed
search penetrated into the graph when initiated from the x point layer when the candidate
was rst generated. The search penetration should be maximized while the plan fragment
length should be minimized. Considering the goal sets in some order other than that in
which they are generated does not aect any of the formal properties of the planner other
than the optimality of the plans generated. Non-optimal plans can be favoured because
113

Long & Fox

1e+06

3

100000

3

10000

3
Stanh

1000
100
100

3 33

3
1000

10000

Stan

100000

1e+06

Figure 21: Towers of Hanoi with (Stanh) and without the heuristic: 3-9 discs.
the balance between fragment length and penetration can cause candidates with shorter
fragments to be overlooked.
Using the heuristic Stan is able to solve Towers of Hanoi problems very eciently, as
Figure 21 shows. As previously, the graph is log-log scaled. The line indicates at least a
polynomial improvement in the size of instances. The heuristic was originally developed by
consideration of blocks world problems, in which it also performs well. However, it does not
provide a reliable advantage so it is not used in Stan version 2. It was used on all problems
in the competition but often represented a heavy overhead for Stan. We are continuing to
experiment with alternative domain-independent evaluation criteria.

6. Conclusion
This paper presents two improvements on the representation of the plan graph exploited by
Graphplan-based planners. These are: the representation of the graph as a single pair of
layers, called a spike, built around bit vectors and logical operations, and the use of a wave
front which avoids the explicit construction of the graph beyond the x point. We describe
a highly ecient procedure for checking mutex relations between actions and explain what
characteristics of problems allow its full exploitation. The spike and the wave front have
both been implemented in Stan, a Graphplan based planner version 11 of which competed
successfully in the AIPS-98 planning competition. We have presented empirical evidence
to support both improvements. The rst set of data demonstrates the increase in graph
1. Version 1 contained implementations of both the spike and the wave front. Version 2 enhances both
of these mechanisms with improved implementation and the addition of the changedActs mechanism
discussion in Section 2.1.

114

Efficient Implementation of the Plan Graph in STAN

construction eciency obtained by the use of the spike. The second set of data shows the
advantages obtained during the search of the plan graph by using the wave front.
Stan also employs the state invariant inference machinery of Tim (Fox & Long, 1998),
but in version 2 the integration of the invariants into the graph construction process is
still only partial. We observe that the mutex relations generated in the Complete-Graph
TSP, in particular, are almost entirely domain invariants of the kind inferred by Tim.
Integration of these inferred invariants into the graph would allow these mutex relations
to be identied immediately as permanent and eliminate them from retesting, dramatically
enhancing Stan's graph construction performance in this domain. A similar advantage
would be obtained across other domains since many of the mutex relations inferred during
graph construction correspond to invariants of the various forms inferred eciently by Tim
during a preprocessing stage.

Appendix A. Website Addresses

Online Appendix 1 contains a complete collection of the domains and problems used in this
paper, executables (Linux and Sparc-Solaris binaries) for Stan and the reduced version of
Stan for graph construction, and a di le showing how the graph constructing version of
IPP was generated.
The results of the AIPS-98 planning competition can be found at:
http://ftp.cs.yale.edu/pub/mcdermott/aipscomp-results.html.
The Stan website can be found at:
http://www.dur.ac.uk/dcs0www/research/stanstuff/planpage.html.

References

Blum, A., & Furst, M. (1997). Fast Planning through Planning Graph Analysis. Articial
Intelligence, 90, 281{300.
Fox, M., & Long, D. (1998). The Automatic Inference of State Invariants in TIM. JAIR,
9, 317{371.
Kambhampati, S. (1998). EBL and DDB for Graphplan. Tech. rep. ASU CSE TR 98-008,
Arizona State University.
Kambhampati, S. (1999). On the Relations Between Intelligent Backtracking and Explanation Based Learning in Planning and CSP. Articial Intelligence, 105 (1-2).
Koehler, J., Nebel, B., & Dimopoulos, Y. (1997). Extending Planning Graphs to an ADL
Subset. In Proceedings of 4th European Conference on Planning.
Smith, D., & Weld, D. (1998). Incremental Graphplan. Tech. rep. TR 98-09-06, University
of Washington.

115

