Journal of Artificial Intelligence Research 26 (2006) 153-190

Submitted 10/05; published 06/06

Convexity Arguments for Efficient Minimization of the
Bethe and Kikuchi Free Energies
Tom Heskes

t.heskes@science.ru.nl

IRIS, Faculty of Science, Radboud University Nijmegen
Toernooiveld 1, 6525 ED, Nijmegen, The Netherlands

Abstract
Loopy and generalized belief propagation are popular algorithms for approximate inference in Markov random fields and Bayesian networks. Fixed points of these algorithms
have been shown to correspond to extrema of the Bethe and Kikuchi free energy, both of
which are approximations of the exact Helmholtz free energy. However, belief propagation does not always converge, which motivates approaches that explicitly minimize the
Kikuchi/Bethe free energy, such as CCCP and UPS.
Here we describe a class of algorithms that solves this typically non-convex constrained
minimization problem through a sequence of convex constrained minimizations of upper
bounds on the Kikuchi free energy. Intuitively one would expect tighter bounds to lead to
faster algorithms, which is indeed convincingly demonstrated in our simulations. Several
ideas are applied to obtain tight convex bounds that yield dramatic speed-ups over CCCP.

1. Introduction
Pearl’s belief propagation (Pearl, 1988) is a popular algorithm for inference in Bayesian
networks. It is known to be exact in special cases, e.g., for tree-structured (singly connected)
networks with just Gaussian or just discrete nodes. But also on networks containing cycles,
so-called loopy belief propagation empirically often leads to good performance (approximate
marginals close to exact marginals) (Murphy, Weiss, & Jordan, 1999; McEliece, MacKay,
& Cheng, 1998). The notion that fixed points of loopy belief propagation correspond to
extrema of the so-called Bethe free energy (Yedidia, Freeman, & Weiss, 2001) is an important
step in the theoretical understanding of this success.
The Kikuchi free energy (Kikuchi, 1951) is a generalization of the Bethe free energy that
can lead to better approximations of the exact Helmholtz free energy. Just like fixed points
of loopy belief propagation correspond to extrema of the Bethe free energy, fixed points
of an algorithm called generalized belief propagation (Yedidia et al., 2001) correspond to
extrema of the Kikuchi free energy.
A problem with loopy and generalized belief propagation is that they do not always
converge to a stable fixed point. New algorithms (Yuille, 2002; Teh & Welling, 2002) have
been derived that therefore explicitly minimize the Bethe and Kikuchi free energy. As we will
describe in Section 2, minimization of the Kikuchi free energy corresponds to a usually nonconvex constrained minimization problem. Non-convex constrained minimization problems
are known to be rather difficult to solve, so in Section 3 we will first derive sufficient
conditions for the Kikuchi free energy to be convex (over the set of constraints). In Section 4
we will then derive a class of converging double-loop algorithms, in which each inner loop
corresponds to constrained minimization of a convex bound on the Kikuchi free energy,
c
2006
AI Access Foundation. All rights reserved.

Heskes

and each outer-loop step to a recalculation of this bound. Based on the intuition that the
tightest bound yields the fastest algorithm, we come up with several ideas to construct
tight bounds. We will see that Yuille’s (2002) CCCP algorithm corresponds to a special
case of a rather loose bound and discuss the relationship with the UPS algorithm by Teh
and Welling (2002) in Section 4.5. The simulations in Section 5 illustrate the use of tight
convex bounds on several inference problems. Implications and other issues are discussed
in Section 6. Technical details are treated in the appendices.

2. The Kikuchi Approximation
Exact inference in graphical models is often intractable. In this section we will introduce
the Kikuchi approximation as a particular example of a variational approach towards approximate inference.
2.1 Graphical Models
An undirected graph G = (V, E) consists of set of nodes or vertices V = {1, . . . , N } that
are joined by a set of edges E. We place at each node i a variable xi which takes values in
a finite discrete alphabet. The vector containing all variables is denoted x ≡ (x1 , . . . , xn ).
Let γ be a subset of V ; we call γ a region. A clique is any fully connected subset of V ; C is
a set of cliques. The potential, also referred to as compatibility or kernel function, ψα (xα )
is a strictly positive function that only depends on the variables that are part of the clique
α. We define the probability distribution or probability mass function
pexact (x) ≡

1 Y
ψα (xα ) ,
Z

(1)

α∈C

where Z is the normalizing constant, often called partition function. The HammersleyClifford theorem (Besag, 1974) guarantees us that the underlying probability process is
Markov with respect to the graph and, vice versa, that the distribution of any Markov random field over G that is strictly positive can be expressed in this form. Through the process
of moralization, any directed graphical model (Bayesian network) can be transformed into a
corresponding undirected model. Consequently, the probability distribution corresponding
to a Bayesian network can also be written in the form (1) (Lauritzen, 1996).
Computing the partition function Z, as well as computing marginals on subsets of variables, in principle requires summation over an exponential number of states. To circumvent
this exponential summation there are two kinds of approaches: sampling techniques and
variational methods. With sampling, one draws samples from the exact probability distribution. The variational methods try to find an approximation to the exact probability
distribution.
2.2 Variational Methods
Variational methods are often derived from an approximation of the so-called free energy
X
XX
p(xα ) log ψα (xα ) +
p(x) log p(x) ≡ E(p) − S(p) .
(2)
F (p) = −
α∈C xα

x

154

Efficient minimization of the Kikuchi free energy

The first term, E(p), is referred to as the energy, the second term S(p) as the entropy.
Functional minimization of F (p) with respect to functions p(x) under the constraint that
p(x) is properly normalized yields pexact (x). Furthermore, the partition function Z then
follows from
− log Z = F (pexact ) .
When we stick to the exact free energy (2), we do not really gain anything: the entropy
part S(p) still consists of a sum over exponentially many terms. Variational methods are
based on a tractable approximation of the free energy. They can be roughly divided into two
classes, the “mean-field” and the “Kikuchi” approximations. In the mean-field approach one
confines the minimization of the free energy to a restricted class T of (tractable) probability
distributions instead of considering the class P of all probability distributions:
− log Z = F (pexact ) = min F (p) ≤ min F (p) .
p∈P

p∈T

The crux is to choose the class T such that the entropy S(p) becomes tractable for all p ∈ T .
Note however that this restriction typically also affects the energy term E(p) (Jordan,
Ghahramani, Jaakkola, & Saul, 1998; Jaakkola & Jordan, 1999).
The Kikuchi approximation of the free energy (2) leaves the energy term as is and
approximates the entropy S(p) through a combination of marginal entropies:
X
X
−S(p) =
p(x) log p(x) ≈ −
cγ Sγ (p)
γ∈R

x

=

X

cγ

γ∈R

X

p(xγ ) log p(xγ ) .

(3)

xγ

Here R denotes a collection of so-called regions; the parameters cγ are called Moebius or
overcounting numbers.
2.2.1 Partially Ordered Sets
Following Pakzad and Anantharam (2002, 2005), we will use the language of partially ordered
sets or posets. Specifically, the collection R of regions can be viewed as such a poset where
the ordering is defined with respect to the inclusion operator ⊂. A region γ includes a
region γ ′ , written γ ⊇ γ ′ , if all variables in γ ′ are also part of γ. We use γ ⊃ γ ′ to denote
strict inclusion, i.e., γ ⊇ γ ′ and γ ′ 6⊇ γ. We say that γ covers γ ′′ in R, written γ ≻ γ ′′ , if
γ ⊃ γ ′′ and there exists no γ ′ ∈ R such that γ ⊃ γ ′ ⊃ γ ′ . We can visualize a poset with a
so-called Hasse diagram or region graph (see the examples below). Given a particular poset
R, its Hasse diagram GR is a directed acyclic graph, whose vertices are the elements of R,
and whose edges corresponds to the cover relationships. That is, there is an edge from γ to
γ ′ iff γ ≻ γ ′ .
2.3 The Cluster Variation Method
In Kikuchi’s (1951) original cluster variation method (CVM), the collections of regions and
overcounting numbers are constructed as follows. We start by defining a collection O of
outer regions. The minimal choice is the original set of cliques C, but we can also choose to
155

Heskes

combine cliques and construct larger ones, similar to the process of triangulation (Lauritzen,
1996). For convenience, we redefine the potentials correspondingly, i.e., such that there is
precisely one potential ψα (xα ) per outer region α (see the example below).
Given these outer regions, we construct new regions by taking the intersections of these
outer regions, the intersections of intersections, and so on, until no more intersections can
be made. We will refer to the regions constructed in this way as inner regions, combined
in the collection I. The collection of all regions R in (3) is now the union of the outer and
inner regions: R = O ∪ I.
The overcounting or Moebius numbers in the original CVM follow from the Moebius
formula
X
(4)
cγ = 1 −
cγ ′ .
γ ′ ⊃γ

By definition we have cα = 1 for all outer regions α ∈ O.
The Bethe free energy can be considered a special case of the Kikuchi free energy. In the
Bethe free energy there are no intersectionsPof intersections, i.e., there is only one level of
inner regions with cβ = 1 − nβ where nβ ≡ α∈O;α⊃β 1 equals the number of outer regions
covering inner region β.
2.3.1 Alternatives
Several alternatives to the original CVM, with weaker constraints and/or other constraints
on the choice of regions and overcounting numbers, have been proposed recently. Yedidia,
Freeman, and Weiss (2005) present an overview. The particular choice of inner regions
subsets and overcounting numbers in junction graphs (Aji & McEliece, 2001) and join
graphs (Dechter, Kask, & Mateescu, 2002) leads to an entropy approximation in which
all overcounting numbers for the inner regions are negative. The resulting algorithms are
very similar to the junction tree algorithm, but then applied to a graph with loops. The
entropy approximation that follows from the original cluster variation method takes into
account all entropy contributions up to the level of the outer regions in a consistent manner
and, on theoretical grounds, there seems to be no reason to deviate from that (Pakzad
& Anantharam, 2005). In this paper, we therefore focus on the original cluster variation
method, but our analysis holds much more generally for any poset or region graph.
2.4 Constrained Minimization
The Kikuchi approximation of the free energy only depends on the marginals p(xγ ) for
all γ ∈ R. We now replace the minimization of the exact free energy over the complete
distribution p(x) by minimization of the Kikuchi free energy
XX
X X
FKikuchi (q) = −
qα (xα ) log ψα (xα ) +
cγ
qγ (xγ ) log qγ (xγ )
(5)
α∈O xα

γ∈R

156

xγ

Efficient minimization of the Kikuchi free energy

over all pseudo-marginals q ≡ {qγ ; γ ∈ R} under the consistency and normalization constraints
qγ (xγ ) ≥ 0 ∀γ∈R ∀xγ
X

qγ (xγ ) = 1 ∀γ∈R

(positive)

(6a)

(normalized)

(6b)

(consistent)

(6c)

xγ

X

qγ ′ (xγ ′ ) = qγ (xγ ) ∀γ,γ ′ ∈R;γ ′ ⊃γ

xγ ′ \γ

Referring to the class of pseudo-marginals satisfying these constraints as Q, we have the
approximation
− log Z ≈ min FKikuchi (q) .
q∈Q

Furthermore, the hope is that the pseudo-marginals qγ (xγ ) corresponding to this minimum are accurate approximations of the exact marginals pexact (xγ ). The Kikuchi free
energy and corresponding marginals are exact if the Hasse diagram turns out to be singlyconnected (Pakzad & Anantharam, 2005).
2.5 Illustration
For illustration of the main concepts, we consider a probability model with 4 variables
(“nodes”) and pairwise interactions between each of the nodes as visualized in Figure 1(a).
In obvious shorthand notation, the exact distribution is of the form
1 Y
1
pexact (x) =
ψij (xi , xj ) = ψ12 ψ13 ψ14 ψ23 ψ24 ψ34 .
Z
Z
{i,j}

Note here that potentials originally defined on single nodes can always be incorporated in
the definition of the two-node potentials. The region graph corresponding to the minimal
choice of outer regions, i.e., equivalent to the potential subsets, is given in Figure 1(b).
With the outer regions all pairs of nodes, the inner regions subsets are all single nodes. In
fact, in this case the region graph is equivalent to a so-called factor graph (Kschischang,
Frey, & Loeliger, 2001) and the Kikuchi approximation of the free energy boils down to a
Bethe approximation:
XX
qij (xi , xj ) log ψij (xi , xj )
FKikuchi (q) = −
{i,j} xi ,xj

+

XX

qij (xi , xj ) log qij (xi , xj ) +

{i,j} xi ,xj

X
X
(1 − ni )
qi (xi ) log qi (xi ) ,
i

xi

where ni = 3 is the number of outer regions containing the inner region i.
The cluster variation method allows us to choose larger outer regions, for example,
consisting of all triples {i, j, k}. We redefine the factorization of the potentials such that
pexact (x) =

1 Y
ψijk (xi , xj , xk ) = ψ123 ψ124 ψ134 ψ234 ,
Z
{i,j,k}

157

Heskes

1
x1

x3

EE
EE yyy
EyEy
yy EEE
y
E
yy

1

1

1

1

1

1, 2 I 1, 3 I 1, 4 I 2, 3
2, 4
3, 4
66 II
II 
II 
u
u
u
u
II
II
u
66 III
uu
uu 
66 III  IIII  IuIuIuIu
uu 
u
66
I
II uu II uu

IuIu
Iu
6 IIII

uuuII
uu I
1
2
3
4

x2

x4

-2

(a) Markov random field.

-2

-2

-2

(b) Hasse diagram for the Bethe approximation.

1

1

1

1

1, 2, 3I 1, 2, 4I 1, 3, 4I 2, 3, 4

II  66
Iu
Iu

II
uuII
uuII 
 uuu III uuu III
 II 666


II 6
I
I
u
u



I
I
u
u I
II 66
I
u
u


II
II
 uuu
II 6
uu



I
I
u
I
 uu
 I
 I
uu

1, 2 I 1, 3 I 1, 4 I 2, 3
2, 4
3, 4
66 II
II 
II 
u
u
u
u
I
I
I
u
u
II
II uu -1 uu -1
II
-1 666 -1
-1
-1
u
66 IIII  IIII  uuIuIuII
uu 
II
II uuu
II uu
66



uI

 II
uuuII
uu I
1
2
3
4
1

1

1

1

(c) Region graph for the Kikuchi approximation.
Figure 1: Region graphs for the Bethe and Kikuchi approximations. Lines between nodes
in the Markov random field (a) indicate edges. In the region graphs (b) and (c),
the outer regions are drawn at the highest level. Lines indicate the “covering”
relationship, where lower regions are covered by the higher regions. The oblique
numbers are the overcounting numbers that follow from the Moebius formula.
The Bethe approximation (b) corresponds to the minimal approximation with
the outer regions equivalent to the cliques in the graph; here all pairs of nodes.
The particular Kikuchi approximation (c) follows by taking for the outer regions
all node triples.

158

Efficient minimization of the Kikuchi free energy

for example through (distribute symmetrically)
1

ψ123 ≡ [ψ12 ψ13 ψ23 ] 2

1

ψ124 ≡ [ψ12 ψ14 ψ24 ] 2

1

ψ134 ≡ [ψ13 ψ14 ψ34 ] 2

1

ψ234 ≡ [ψ23 ψ24 ψ34 ] 2 ,
or through (assign to the first outer region)
ψ123 ≡ ψ12 ψ13 ψ23
ψ124 ≡ ψ14 ψ24
ψ134 ≡ ψ34
ψ234 ≡ 1 .
The corresponding region graph is given in Figure 1(c). Now the first-level inner regions
are all pairs of nodes and the second-level inner regions are all single nodes, with overcounting numbers -1 and 1, respectively. The Kikuchi approximation of the entropy boils down
to
X
X
X
SKikuchi (q) =
Sijk −
Sij +
Si .
{i,j,k}

{i,j}

i

The intuitive reasoning behind this approximation is as follows. The sum over all threenode entropies overcounts the two-node interactions (each combination {i, j} appears twice
rather than once), which therefore have to be discounted once. But now the single-node
interactions are too much discounted (overcounting number -1 times 3 appearances, compared with the 3 appearances with overcounting number 1 in the three-node entropies),
yielding the overcounting number 1 − 3 × (1) − 3 × (−1) = 1.
2.6 Generalized and Loopy Belief Propagation
To summarize, finding the Kikuchi approximation of the partition function Z boils down
to minimization of the Kikuchi free energy with respect to a set of pseudo-marginals under
linear constraints between them. Introducing Lagrange multipliers for these constraints, it
can be shown that fixed points of a popular algorithm called loopy belief propagation correspond to extrema of the Bethe free energy and, more generally, fixed points of generalized
belief propagation to extrema of the Kikuchi free energy (Yedidia et al., 2001). However,
these algorithms are not guaranteed to converge to a minimum and in practice do get stuck
in for example limit cycles. This explains the search for convergent alternatives that directly
minimize the Kikuchi free energy, which will be the topic of the rest of this paper.

3. Convexity of the Kikuchi Free Energy
In this section we will derive sufficient conditions for the Kikuchi free energy to be convex
over the set of consistency constraints (6). This is relevant because if the Kikuchi free
energy is indeed convex over the constraint set, it must have a unique minimum and the
minimization problem is relatively straightforward. Furthermore, the argument that we will
159

Heskes

use in deriving these conditions will play an important role in the construction of efficient
minimization algorithms later on.
3.1 Sufficient Conditions
We have to consider the Kikuchi free energy (5) as a function of the pseudo-marginals q.
In reasoning about convexity, we can disregard the energy term being linear in q. The
entropy terms give either a convex or a concave contribution, depending on whether the
corresponding overcounting numbers are positive or negative, respectively. Ignoring the
constraints (6), the free energy (5) is convex if and only if all concave contributions vanish,
i.e., cβ = 0 for all β ∈ R− .
However, we really only care about the subspace induced by the constraints (6). Therefore we introduce the notion of convexity over the set of constraints. We call the free energy
convex over the set of constraints (6) if
F (λq1 + (1 − λ)q2 ) ≤ λF (q1 ) + (1 − λ)F (q2 ) ∀0<λ<1 ∀q1 ,q2 ∈Q .
Note that, since the constraints are all linear, if q1 and q2 satisfy the constraints (6), then
so does λq1 + (1 − λ)q2 . In the following, when we talk about convexity of the Kikuchi free
energy, the conditioning on the constraint set is implicitly assumed.
One way to proceed is to make use of the (consistency) constraints to express the Kikuchi
free energy in terms of the outer region pseudo-marginals only and then study its convexity.
Our approach is along these lines. In particular, we will replace inner region pseudomarginals that correspond to concave contributions by outer region pseudo-marginals. The
pseudo-marginals corresponding to convex contributions are of no concern. In fact, we may
be able to use these convex contributions as well to compensate for some of the concave
contributions.
To make this reasoning more precise, we define positive regions (or perhaps better,
nonnegative) γ ∈ R+ , with R+ ≡ {γ ∈ R; cγ ≥ 0} ≡ O ∪ I+ and negative regions β ∈ R− ,
with R− ≡ {γ ∈ R; cγ < 0} ≡ I− . The idea, formulated in the following theorem, is then
that the Kikuchi free energy is convex if we can compensate the concave contributions of
the negative regions R− by the convex contributions of the positive regions R+ .
Theorem 3.1. The Kikuchi free energy is convex over the set of constraints (6) if there
exists an “allocation matrix” Aγβ between positive regions γ ∈ R+ and negative regions
β ∈ R− satisfying
Aγβ 6= 0 only if γ ⊃ β

(γ can be used to compensate β)

(7a)

Aγβ ≥ 0
X
Aγβ ≤ cγ

(positivity)

(7b)

(sufficient amount of resources)

(7c)

(sufficient compensation)

(7d)

∀γ∈R+

β⊂γ

X

Aγβ ≥ |cβ |

∀β∈R−

γ⊃β

160

Efficient minimization of the Kikuchi free energy

Proof First of all, we note that we do not have to worry about the energy terms that are
linear in q. In other words, to prove the theorem we can restrict ourselves to showing that
minus the entropy


X
X
−S(q) = − 
cγ Sγ (qγ ) −
|cβ |Sβ (qβ )
γ∈R+

β∈R−

is convex over the set of constraints.
As an intermediate step, let us consider the combination of a convex entropy contribution
of a positive region γ ∈ R+ with the concave entropy contribution of a negative inner region
β ∈ R− , where β is a subset of γ:
X
X
∆γβ (q) ≡ −[Sγ (q) − Sβ (q)] =
qγ (xγ ) log qγ (xγ ) −
qβ (xβ ) log qβ (xβ )
xγ

=

X

qγ (xγ ) log qγ (xγ ) −

=

xβ

qγ (xγ ) log qγ (xβ )

xγ

xγ

X

xβ

X



qγ (xβ ) 

X

xγ\β



qγ (xγ\β |xβ ) log qγ (xγ\β |xβ ) ,

where we used the standard definitions
X
qγ (xγ )
qγ (xγ ) and qγ (xγ\β |xβ ) ≡
qγ (xβ ) ≡
.
qβ (xβ )
x
γ\β

In the first step, we applied the constraint qβ (xβ ) = qγ (xβ ) and extended the summation
over xβ in the second term to a summation over xγ . In the second step we basically turned
the difference between two entropies into (a weighted sum of) conditional entropies. The
difference ∆γβ , which now only depends on qγ , is, from Lemma A.1 in Appendix A, convex
in qγ . In other words, the concave contribution from Sβ is fully compensated by the convex
contribution Sγ , yielding an overall convex term in the relevant set of constraints.
The resulting operation is now a matter of resource allocation. For each concave contribution |cβ |Sβ we have to find convex contributions Sγ to compensate for it. Let Aγβ denote
the “amount of resources” that we take from positive region γ ∈ R+ to compensate for
negative region β ∈ R− . Obviously, a positive region can only compensate negative regions
that it contains, so Aγβ = 0 when β is not a subset of γ, which explains condition (7a).
Now, in shorthand notation and with a little bit of rewriting


X
X
|cβ |Sβ 
cγ Sγ −
−S(q) = − 
γ∈R+

=−

X

γ∈R+

=−

X

γ∈R+



cγ −



cγ −

β∈R−

X

Aγβ +

β⊂γ

X

β⊂γ

X

β⊂γ





Aγβ  Sγ −

Aγβ  Sγ −

X X

γ∈R+ β⊂γ

161

X

β∈R−



−

X

Aγβ +

γ⊃β

Aγβ [Sγ − Sβ ] −

X

γ⊃β

X

β∈R−






Aγβ − |cβ | Sβ

X

γ⊃β



Aγβ − |cβ | Sβ .

Heskes

P
Convexity of the first term is guaranteed
P if cγ − β Aγβ ≥ 0 (7c), of the second term if
Aγβ ≥ 0 (7b), and of the third term if γ Aγβ − |cβ | ≥ 0 (7d).

3.2 Checking the Conditions

Checking the conditions of Theorem 3.1 can be cast in the form of a linear programming
problem, for example as follows. We define an auxiliary variable θ replacing condition (7c)
by
X
(8)
Aγβ = θ|cβ | ∀β∈R− (variable compensation)
γ⊃β

Then we solve the linear programming problem that attempts to maximize the single variable θ under all constraints implied by the four conditions. The interpretation is that we
try to use the available resources to compensate for as much of the concave contributions
as we can. If we find a solution θ∗ ≥ 1 all conditions are satisfied: the Kikuchi free energy
is convex over the set of constraints and has a unique minimum. If the optimal θ∗ turns
out to be smaller than 1, there is no matrix A satisfying all constraints and convexity of
the Kikuchi free energy is not guaranteed by Theorem 3.1.
Instead of solving the linear program, we can often get away with simpler checks. For
example, we can guess a particular A and check whether the conditions (7) hold. An obvious
choice is
X
cγ
Aγβ = − with n−
1,
γ ≡
nγ
β∈R ,β⊂γ
−

which satisfies condition (7c) and when substituted into (7d) yields the condition
X

cβ +

γ∈R+ ,γ⊃β

cγ
≥0
n−
γ

∀β∈R− .

(9)

Similarly, the choice
Aγβ =

X
|cβ |
+
with
n
≡
1
β
n+
β
γ∈R ,γ⊃β
+

satisfies condition (7d) and yields the condition
X

β∈R− ,β⊂γ

cβ
+ cγ ≥ 0 ∀γ∈R+
n+
β

(10)

when substituted into (7c). If (9) or (10) holds, Theorem 3.1 guarantees convexity of the
Kikuchi free energy.
The above two conditions are sufficient, but not necessary for Theorem 3.1 to apply. A
necessary condition is
X
X
cγ ≥ 0
(11)
cβ +
β∈R−

γ∈R+

which is easily derived by summing condition (7d) over all β ∈ R− and substituting condition (7c). If condition (11) fails, we cannot use Theorem 3.1 to prove convexity of the
Kikuchi free energy.

162

Efficient minimization of the Kikuchi free energy

We would like to conjecture that the conditions in Theorem 3.1 are not only sufficient,
but also necessary for convexity of the Kikuchi free energy. We will not pursue this any
further here, because it is irrelevant for our current purposes. Furthermore, it may not
be that relevant in practice either, since convexity by itself is a sufficient but not necessary condition for a unique minimum. Tatikonda and Jordan (2002), Heskes (2004), Ihler,
Fisher, and Willsky (2005) give conditions for convergence of loopy belief propagation and
uniqueness of the minimum of the corresponding Bethe free energy. These conditions do not
only depend on the graphical structure, but also on the (strength of the) kernels ψα (xα ).
3.3 Related Work
Chiang and Forney (2001) present similar ideas, about convex entropy terms compensating
concave terms in the set of constraints, and derive conditions for convexity of the Bethe
free energy with pairwise potentials. The resulting conditions are formulated in terms of
single-node marginals, which may be difficult both to validate in practice and to generalize
to the Kikuchi case.
Closely related to our Theorem 3.1 is the following theorem of Pakzad and Anantharam
(2002, 2005).
Theorem 3.2. (Pakzad & Anantharam, 2002, 2005) The Kikuchi free energy (5) is convex
over the set of consistency constraints imposed by a collection of regions R (and hence the
constrained minimization problem has a unique solution) if the overcounting numbers cγ
and cγ ′ satisfy:
X
X
∀S ⊂ R,
cγ +
cγ ′ ≥ 0 .
(12)
γ ′ ∈R\S:
∃γ∈S,γ⊂γ ′

γ∈S

In words, for any subset S of R, the sum of overcounting numbers of elements of S and all
their ancestors in R must be nonnegative.
In fact, using Hall’s (1935) matching theorem, it can be shown that the conditions (7)
in our Theorem 3.1 are equivalent to the conditions (12) in Theorem 3.2. The latter are
more direct and do not require the solution of a linear program.
Both Theorem 3.1 and Theorem 3.2 can be used to show that the Bethe free energy for
graphs with a single loop is convex over the set of constraints (Heskes, 2004; McEliece &
Yildirim, 2003; Pakzad & Anantharam, 2002, 2005).
3.4 Minimization of the Convex Kikuchi Free Energy
If the Kikuchi free energy is convex, it is not only guaranteed to have a unique minimum,
but this minimum is also relatively easy to find with a message-passing algorithm similar
to standard (loopy) belief propagation.
The basic idea is as follows. We here focus on the case in which all overcounting numbers
are positive. The case with negative overcounting numbers is more involved and worked
out in Appendix B. Furthermore, here and in the rest of this paper we ignore the positivity
constraints (6a). It is easy to check that these are satisfied at the solutions we obtain. We
introduce Lagrange multipliers λγ ′ γ (xγ ) for the consistency constraints as well as λγ for the

163

Heskes

normalization constraints and construct the Lagrangian


XX
X
L(q, λ) = FKikuchi (q) +
qγ ′ (xγ ′ )
λγ ′ γ (xγ ) qγ (xγ ) −
γ ′ ,γ
γ⊂γ ′

+

X
γ



xγ ′ \γ

xγ

λγ 1 −

X
xγ



qγ (xγ ) .

(13)

Minimization of the Kikuchi free energy under the appropriate consistency and normalization constraints is, in terms of this Lagrangian, equivalent to
min FKikuchi (q) = min max L(q, λ) ,
q

q∈Q

λ

where the minimization over q is now unconstrained. Standard results from constrained
optimization (e.g., Luenberger, 1984) tell us that
min max L(q, λ) ≥ max min L(q, λ) ,
q

λ

λ

q

with equality for convex problems under linear equality constraints. That is, for convex
problems we are allowed to interchange the maximum over λ and the minimum over q.
Furthermore, the optimal q∗ (λ) corresponding to the minimum of the Lagrangian (13) as
a function of λ is unique, since L(q, λ) is convex in q for all λ. Substitution of the solution
then yields the so-called dual
L∗ (λ) ≡ min L(q, λ) = L(q∗ (λ), λ) .

(14)

q

This dual is concave in λ and has a unique maximum.
Many algorithms can be used to find the maximum of the dual (14). A particular
one, derived in Appendix B, is given in Algorithm 1. It slightly differs from those presented
by Yedidia et al. (2005) and Yuille (2002) by sending messages (messages are directly related
to Lagrange multipliers) only between inner regions and outer regions, i.e., never between
inner regions subsets and other inner regions. The price one has to pay is that the update in
line 7 depends on the overcounting number cβ . For the Bethe free energy, with cβ = 1 − nβ ,
we obtain the standard (loopy) belief propagation update rules. The particular ordering
in Algorithm 1, running over inner regions and updating the messages between an inner
region and all its neighboring outer regions, guarantees that the dual (14) increases at each
iteration1 . The local partition functions Zα and Zβ in lines 10 and 7 are chosen such as
to normalize the pseudo-marginals qα (xα ) and qβ (xβ ). This normalization is not strictly
necessary, but helps to prevent numerical instability. Algorithm 1 can be initialized by
setting all messages µα→β (xβ ) = 1 and skipping lines 3 to 6 at the first iteration.
1. For positive overcounting numbers cβ . The argumentation with negative overcounting numbers is more
complicated and may require damping of the updates to achieve convergence. See Appendix B for details.

164

Efficient minimization of the Kikuchi free energy

Algorithm 1 Message-passing algorithm for constrained minimization of a Kikuchi free
energy.
1:

while ¬converged do

2:

for all β ∈ I do

3:
4:

for all α ∈ O, α ⊃ β do
X
qα (xβ ) =
qα (xα )
xα\β

5:

µα→β (xβ ) =

qα (xβ )
µβ→α (xβ )

6:

end for

7:

qβ (xβ ) =

8:

for all α ∈ O, α ⊃ β do
qβ (xβ )
µβ→α (xβ ) =
µα→β (xβ )
Y
1
qα (xα ) =
ψα (xα )
µβ→α (xβ )
Zα
β∈I,

1
nβ +cβ
1 Y
µα→β (xβ )
Zβ α∈O,
α⊃β

9:
10:

β⊂α

11:

end for

12:

end for

13:

end while

4. Double-Loop Algorithms for Guaranteed Convergence
Even when the Kikuchi free energy is not convex, we can still run Algorithm 1 in the
hope that it converges to a fixed point. This fixed point then must correspond to an
extremum of the Kikuchi free energy under the appropriate constraints (Yedidia et al.,
2001). Even better, empirically for the general Kikuchi free energy and provably for the
Bethe free energy (Heskes, 2003), this extremum is in fact a minimum. However, in practice
this single-loop2 algorithm does not always converge and we have to resort to double-loop
algorithms to guarantee convergence to a minimum of the Kikuchi free energy.
4.1 The General Procedure
We introduce a class of such double-loop algorithms based on the following theorem.
2. Note that “single loop” here refers to the message-passing algorithm and has nothing to do with the
notion of a single loop in the graphical model.

165

Heskes

Theorem 4.1. Given a function Fconvex (q; q′ ) with properties
Fconvex (q; q′ ) ≥ FKikuchi (q)

∀q,q′ ∈Q

Fconvex (q; q) = FKikuchi (q) and

∂Fconvex (q; q′ ) 
∂FKikuchi (q)
 ′ =
∂q
∂q
q =q

Fconvex (q; q′ ) is convex in q ∈ Q

(bound)

(15a)

∀q∈Q

(touching)

(15b)

∀q′ ∈Q

(convex)

(15c)

the algorithm
qn+1 = argmin Fconvex (q; qn ) ,

(16)

q∈Q

with qn the pseudo-marginals at iteration n, is guaranteed to converge to a local minimum
of the Kikuchi free energy FKikuchi (q) under the appropriate constraints.
Proof It is immediate that the Kikuchi free energy decreases with each iteration:
FKikuchi (qn+1 ) ≤ Fconvex (qn+1 ; qn ) ≤ Fconvex (qn ; qn ) = FKikuchi (qn ) ,
where the first inequality follows from condition (15a) (upper bound) and the second from
the definition of the algorithm. The gradient property (15b) ensures that the algorithm is
only stationary in points where the gradient of FKikuchi is zero. By construction qn ∈ Q for
all n.
See Figure 2 for an illustration of the algorithm and the proof. In fact, the convexity
of Fconvex has not been used to establish the proof. But, as argued in Section 3.4, from an
algorithmic point of view constrained minimization of a convex functional is much simpler
than constrained minimization of a non-convex functional. This general idea, replacing
the minimization of a complex functional by the consecutive minimization of an easier
to handle upper bound of this functional, forms the basis of popular algorithms such as
the EM algorithm (Dempster, Laird, & Rubin, 1977; Neal & Hinton, 1998) and iterative
scaling/iterative proportional fitting (Darroch & Ratcliff, 1972; Jiroušek & Přeučil, 1995).
Intuitively, the tighter the bound, the faster the algorithm.
4.2 Bounding the Concave Terms
As a first step, to lay out the main ideas, we build a convex bound by removing all concave
entropy contributions for β ∈ I− . To do so, we will make use of the linear bound
X
X
−
qβ (xβ ) log qβ (xβ ) ≤ −
(17)
qβ (xβ ) log qβ′ (xβ ) ,
xβ

xβ

which directly follows from
0≤

KL(qβ , qβ′ )

=

X
xβ

"

qβ (xβ )
qβ (xβ ) log ′
qβ (xβ )

166

#

Efficient minimization of the Kikuchi free energy

(1)
(2)

(3)

Figure 2: Illustration of the proposed algorithm and corresponding convergence proof. At
iteration n, Fconvex (q; qn ) (dashed line) is a convex bound of the non-convex
FKikuchi (q) (solid line). They touch at qn , point (1), where Fconvex (qn ; qn ) =
FKikuchi (qn ).
At the minimum, point (2), we have Fconvex (qn+1 ; qn ) ≤
Fconvex (qn ; qn ). The corresponding Kikuchi free energy, point (3), obeys
FKikuchi (qn+1 ) ≤ Fconvex (qn+1 ; qn ) because of the bounding property.

with KL the Kullback-Leibler divergence. Our choice Fconvex then reads

 X
XX
X
qα (xα )
(1)
′
Fconvex (q; q ) =
qα (xα ) log
qβ (xβ ) log qβ (xβ )
cβ
+
ψα (xα )
α xα
xβ
β∈I+


X
X
X
X
|cβ | 1 −
qβ (xβ ) . (18)
|cβ |
−
qβ (xβ ) log qβ′ (xβ ) +
β∈I−

β∈I−

xβ

xβ

It is easy to check that this functional has properties (15a) and (15c). The last term has
been added to fulfill property (15b). Next we make the crucial observation that, using the
(1)
constraints (6) and for fixed q′ , we can rewrite Fconvex in the “normal form” (5):

 X X
XX
qα (xα )
(1)
Fconvex
(q; q′ ) =
qα (xα ) log
+
c̃β
qβ (xβ ) log qβ (xβ ) + C(q) , (19)
ψ̃
(x
)
α
α
α xα
xβ
β

where C(q) evaluates to zero for all q ∈ Q and where ψ̃, which implicitly depends on q′ ,
and c̃ are defined through

X |cβ |
0 ∀β∈I−
′
log qβ (xβ ) and c̃β ≡
.
(20)
log ψ̃α (xα ) ≡ log ψα (xα ) +
cβ ∀β∈I+
nβ
β∈I ,
−
β⊂α

That is, we can always to incorporate the terms now linear in qβ in the energy term by
redefinition of the potentials. Here we have chosen to distribute each of these terms equally
over the nβ neighboring outer regions, but other choices are possible as well.
167

Heskes

The term C(q) in (19) evaluates to zero for all q ∈ Q and is thus irrelevant to the
optimization in the inner loop. It consists of terms such as the last one in (18) that only
(1)
serve to make the bound Fconvex satisfy (15b). In the construction of other bounds below,
we will ignore such terms: they do not affect the algorithm in any way3 .
(1)
Now that we have Fconvex both convex and in normal form, we can use Algorithm 1 to
solve the constrained problem (16). The resulting double-loop algorithm can be described
in two lines.
Outer loop: recompute ψ̃ from (20) with q′ = qn .
Inner loop: run Algorithm 1 with ψ̃ for ψ and c̃ for c, yielding qn+1 .
In each inner loop, we can initialize the messages to the converged values of the previous
inner loop.
4.3 Bounding the Convex Terms
In this section we will show that in many cases we can make the algorithm both better
and simpler. The idea is to bound not only the concave, but also the convex entropy
contributions from inner regions. That is, we enforce c̃β ≡ 0 ∀β ∈ I and set


XX
qα (xα )
(2)
′
Fconvex (q; q ) =
qα (xα ) log
,
(21)
ψ̃α (xα )
α xα
with now
log ψ̃α (xα ) ≡ log ψα (xα ) −

X cβ
log qβ′ (xβ ) .
nβ

(22)

β⊂α

(2)

Let us first explain why the algorithm based on Fconvex is simpler than the one based on
In (21), all reference to inner regions has disappeared. In fact, the only constraints
that we have to care about are that the outer regions pseudo-marginals should agree on
their intersections. Consequently, in the inner loop (Algorithm 1), we only have to run over
those inner regions β that are direct intersections of the outer regions, that is, those β for
which there exist outer regions α and α′ such that xβ = xα ∩ xα′ . Similar arguments can be
used for the algorithm based on (19) as well, neglecting all negative inner regions β ∈ I−
that do not correspond to direct intersections of outer regions. In practice, however, most
negative inner regions are direct intersections of the outer regions, whereas many positive
inner regions arise at the next level, from intersections of intersections. See for instance the
example of Figure 1, where all six negative inner regions are direct intersections of outer
regions, in contrast with all four positive inner regions.
(2)
From (17), but now applied to the positive inner regions, it is clear that Fconvex (q; q′ ) ≤
(1)
(2)
(1)
Fconvex (q; q′ ): when it is a bound, Fconvex is a tighter bound than Fconvex and we can expect
(2)
the algorithm based on Fconvex to perform better. It remains to be shown under which
(2)
conditions FKikuchi (q) ≤ Fconvex (q; q′ ). This is where the following theorem comes in.
(1)
Fconvex .

3. Alternatively, we could relax condition (15b) to the statement that the gradients of Fconvex and FKikuchi
only have to be equal in the subspace orthogonal to the constraints. With this milder condition, C(q)
as well as the last term (18) are no longer needed.

168

Efficient minimization of the Kikuchi free energy

Theorem 4.2. The functional Fconvex in (21) is a convex bound of the Kikuchi free energy (5) if there exists an “allocation matrix” Aγβ between negative inner regions γ ∈ I−
and positive inner regions β ∈ I+ satisfying
Aγβ 6= 0 only if γ ⊃ β

(γ can be used to compensate β)

(23a)

Aγβ ≥ 0
X
Aγβ ≤ |cγ |

(positivity)

(23b)

(sufficient amount of resources)

(23c)

(sufficient compensation)

(23d)

∀γ∈I−

β⊂γ

X

Aγβ ≥ cβ

∀β∈I+

γ⊃β

Proof Not surprisingly, the proof follows the same line of reasoning as the proof of Theorem 3.1. First we consider the combination of a concave entropy contribution from γ ∈ I−
as in (17) with a convex entropy contribution from β ∈ I+ , β ⊂ γ:
X
X
−
qγ (xγ ) log qγ (xγ ) +
qβ (xβ ) log qβ (xβ ) ≤
xγ

xβ

−

X

qγ (xγ ) log qγ′ (xγ ) +

xγ

X

qβ′ (xβ ) log qβ′ (xβ ) ,

(24)

xβ

which follows from

qγ (xγ\β |xβ )
0 ≤
qβ (xβ ) qγ (xγ\β |xβ ) ′
qγ (xγ\β |xβ )
xγ



X
qγ (xγ )
qγ (xγ ) qγ′ (xβ )
=
qγ (xβ )
log
,
′ (x )
q
(x
)
q
(x
)
q
γ
γ
γ
β
β
γ
x
X





γ

where we recognize the term between braces as a Kullback-Leibler divergence between two
probability distributions.
(2)
To show that the difference between Fconvex and FKikuchi is nonnegative, we should be
able to compensate each of the concave contributions cβ for all β ∈ I+ with convex contributions from γ ∈ I− with γ ⊃ β, without exceeding the available amount of “resources”
|cγ |. In shorthand notation, with
#
"
X
qβ (xβ )
Kβ ≡
,
qβ (xβ ) log ′
qβ (xβ )
x
β

we have the decomposition
X
X
X
(2)
Fconvex
− FKikuchi = −
cβ Kβ =
cβ Kβ
|cγ |Kγ −
β∈I

=

X

γ∈I−



|cγ | −

X

β⊂γ



Aγβ  Kγ +

γ∈I−

X X

β∈I+

Aγβ (Kγ − Kβ ) +

γ∈I− β⊂γ

X

β∈I+

169




X

γ⊃β



Aγβ − cβ  Kβ ≥ 0 ,

Heskes

123456
1

2

3

4

5

1237

12457

13467

23567

4567

6

1

2

123
3

1245

1346

2356

456

127

137

237

147

257

457

367

467

567

−1 −1 −1 −1 −1 −1 −1 −1 −1 −1 −1 −1 −1 −1

4

5

6

12

13

23

14

25

45

36

46

56

17

27

37

47

57

67

1

1

1

1

1

1

1

1

1

1

1

1

1

1

1

7

(a) Outer regions.

7

1

2

3

4

5

6

−1

−1

−1

−1

−1

−1

−1

(b) Region graph.
Figure 3: Smallest example showing that the conditions for Theorem 4.2 need not always
hold for a region graph and overcounting numbers constructed with the cluster
variation method. (a) Visualization of the outer regions: black means that the
variable (1 to 7) is part of the outer region (1 to 6).
(b) Region graph with overcounting numbers in boldface. The positive overcounting numbers at the third level just outweigh the negative overcounting numbers at the second level.

where the inequality follows since each of the terms itself is guaranteed to be nonnegative
when the conditions (23) are satisfied.
As above, the conditions of Theorem 4.2 can be checked with a linear program. Having
generated many different sets of overcounting numbers resulting from the Moebius formula (4), we started wondering whether the conditions (23) are perhaps automatically satisfied. However, exhaustively checking all possible outer region combinations given a fixed
number of variables, we did come up with a counterexample. The smallest counterexample
that violates the conditions for Theorem 4.2, is illustrated in Figure 3.
Even if, as in this counterexample, not all positive inner regions can be compensated for
by negative inner regions, it will pay to get rid of as many as possible. Finding the optimal
assignment may be a complex problem, but heuristics are easy to find (see Appendix C).
4.4 Pulling Out a Tree or More
(1)

In the previous section we tightened the convex bound Fconvex of the Kikuchi free energy
FKikuchi by bounding convex contributions from positive regions as well. Another way to
get a tighter bound is to bound only part of the concave contributions from the negative

170

Efficient minimization of the Kikuchi free energy

inner regions. We will first illustrate this by considering the Bethe free energy, i.e., just
non-overlapping negative inner regions (nodes) with cβ = 1 − nβ .
The Bethe free energy is convex for singly-connected structures. Inspired by Teh and
Welling (2002), we choose a set of nodes β ∈ Ibound such that the remaining nodes β ∈ Ifree
become singly-connected and take


XX
X
X
qα (xα )
(3)
′
Fconvex (q; q ) =
qα (xα ) log
+
(1 − nβ )
qβ (xβ ) log qβ (xβ )
ψα (xα )
α xα
xβ
β∈Ifree
X
X
+
(1 − nβ )
(25)
qβ (xβ ) log qβ′ (xβ ) .
β∈Ibound

xβ

That is, we bound the entropy terms corresponding to the “bounded” nodes β ∈ Ibound and
simply keep the entropy terms correspond to the “free” nodes β ∈ Ifree . By construction
Fconvex satisfies all conditions (15). Furthermore, it can be rewritten in the normal form (5)
with definitions

X 1 − nβ
0
∀β∈Ibound
′
log ψ̃α (xα ) ≡ log ψα (xα ) −
.
log qβ (xβ ) and c̃β ≡
1
−
n
nβ
β ∀β∈Ifree
β∈I
,
bound

β⊂α

Note that the resulting inner-loop algorithm is not completely equivalent to running standard belief propagation on the tree of all free nodes: we do have to send messages to and
from the bounded nodes β ∈ Ibound as well to enforce the constraints qα (xβ ) = qα′ (xβ ) for
α, α′ ⊃ β.
Rather than pulling out a single tree, we can also pull out “a convex combination of
trees”. That is, suppose that we have several bounds, each of them the result of pulling
out a particular tree and with a corresponding set of overcounting numbers c̃i . Then any
convex combination
X
X
c̃β =
wi c̃iβ with wi ≥ 0 and
wi = 1
i

i

also corresponds to a convex bound. More generally, we can combine the ideas in this
and the previous section by choosing c̃β such that the resulting bound is just convex. A
procedure for doing so is given in Appendix C. Basically, we first try to shield as much of
the concave entropy contributions by convex entropy contributions as we can. Next, we
tighten the bound further by incorporating convex contributions in the linear bounds of the
concave contributions that we did not manage to shield in the first step. Both steps can be
cast in the form of an easy to solve linear programming problem.
4.5 Related Work
(1)

The double-loop algorithm described in Section 4.2 and based on Fconvex is closely related
to Yuille’s (2002) CCCP (concave-convex procedure) algorithm. Although originally formulated in a completely different way, CCCP applied for minimization of the Kikuchi free
energy can also be understood as a particular case of the general procedure outlined in
Theorem 4.1. More specifically, it is based on bounding the concave contributions with
X
X
X
−|cβ |
qβ (xβ ) log qβ (xβ ) ≤
qβ (xβ ) log qβ (xβ ) − (|cβ | − 1)
qβ (xβ ) log qβ′ (xβ ) , (26)
xβ

xβ

xβ

171

Heskes

which is to be compared with (17). That is, before bounding the concave entropy contributions, part of these concave terms are taken over to the “convex side”. The reason for
doing so is that the CCCP algorithm requires the functional to be convex, independent of
the constraints involved4 . Our procedure, on the other hand, makes use of the fact that
the functional only has to be convex over the set of constraints. This allows us to use
tighter bounds, yielding more efficient and sometimes simpler algorithms. On a less important note, the inner-loop algorithm and in particular the message-passing scheme applied
by Yuille (2002) is somewhat different.
(3)
The double-loop algorithm based on Fconvex in (25) is inspired by Teh and Welling’s
(2002) UPS (unified propagation and scaling) algorithm. The difference is that where we
bound the entropy contributions from nodes on the tree, in UPS these nodes (and thus
the entropy contributions) are clamped to the values resulting from the previous inner loop.
That is, each inner loop in the UPS algorithm corresponds to minimizing


XX
X
X
qα (xα )
UPS
′
Fconvex (q; q ) =
qα (xα ) log
+
(1 − nβ )
qβ (xβ ) log qβ (xβ )
ψα (xα )
α xα
xβ
β∈Ifree
X
X
−
(1 − nβ )
qβ′ (xβ ) log qβ′ (xβ ) .
β∈Iclamped

xβ

under the constraints
qα (xβ ) = qβ (xβ ) ∀β∈Ifree ,α⊃β , yet qα (xβ ) = qβ′ (xβ ) ∀β∈Iclamped ,α⊃β .
This boils down to an iterative scaling algorithm, which is also relatively easy to solve.
At each outer-loop iteration, a different choice is made for Ifree and Iclamped . The UPS
algorithm can be understood as coordinate descent and is guaranteed to converge to a
local minimum of Bethe free energy (under appropriate conditions on the choices made for
(3)
Ifree and Iclamped ). The inner loop that results from Fconvex also allows for changes in the
marginals qβ (xβ ) for β ∈ Ibound , i.e., is more flexible and can make larger steps. Loosely
(3)
UPS . Furthermore, in our approach we
speaking, Fconvex is again a tighter bound than Fconvex
can but do not have to choose different subdivisions between “bounded” and “free” nodes
within each inner loop.
Wainwright, Jaakkola, and Willsky (2002b, 2002a) present similar ideas, exploiting the
convexity of the Bethe free energy on tree structures. Wainwright et al. (2002b) use the
tree structure to obtain a more efficient implementation of loopy belief propagation, without
however guaranteeing convergence. Wainwright et al. (2002a) show that particular convex
combinations of convex Bethe free energies lead to convex bounds on the exact Helmholtz
free energy (2). In these bounds, the overcounting numbers of the inner regions still follow
the Moebius relation (4), but the overcounting numbers for the outer regions are smaller
than or equal to 1. Constrained minimization of such a bound is very similar to constrained
(3)
minimization of Fconvex and the algorithm used by Wainwright, Jaakkola, and Willsky (2003)
is indeed closely related to Algorithm 1.
4. The procedure described by Yuille (2002) often even moves part of the convex terms to the concave side.
This makes the (implicit) bound even worse and the corresponding algorithm slower. In the following
we will stick to the more favorable interpretation of the CCCP algorithm that is based on the implicit
bound (26).

172

Efficient minimization of the Kikuchi free energy

5. Simulations
Intuitively, we would expect the algorithms based on the tightest bound to converge the
fastest in terms of outer-loop iterations. However, with larger steps in the outer loop,
we might need more inner-loop iterations to achieve convergence in the inner loop. The
following simulations are designed to check this.
5.1 General Set-up
In the simulations we compare four different algorithms, each of them based on a different
bound.
just convex The tightest bound of the Kikuchi free energy that is just convex. Based on
the ideas described in Section 4.4 and Appendix C.
negative to zero The bound obtained by setting all negative overcounting numbers to
zero, as explained in Section 4.2.
all to zero The bound described in Section 4.3 that follows by setting all overcounting
numbers, both negative and positive, to zero. In all models considered below, the
overcounting numbers satisfy the conditions of Theorem 4.2, i.e., setting them to zero
indeed yields a bound on the Kikuchi free energy. Note further that all to zero is
equivalent to negative to zero for the Bethe free energy.
cccp The (rather favorable interpretation of the) bound implicit in Yuille’s (2002) CCCP
algorithm, as explained in Section 4.5.
Algorithm 1 is applied in the inner loop of all these algorithms: the only difference
between them is the setting of the overcounting numbers c̃β implied by the bound. Each
inner loop runs until a preset convergence criterion is met. Specifically, we end the inner loop
when all inner region marginals change less then 10−4 . With this criterion all algorithms
happened to converge, which probably would also have been the case with looser criteria.
For example, Yuille (2002) reports that two inner-loop iterations were sufficient to obtain
convergence.
In all simulations we report on the Kullback-Leibler (KL) divergence between exact and
approximate marginals, either summed over all nodes or over a subset of nodes. Plots for
the different error functions all look very much the same. The Kikuchi/Bethe free energy
itself is somewhat less illustrative: when it is very close to its minimum, the marginals and
thus KL divergence can still change considerably. We visualize the KL divergence both as
a function of outer-loop iterations and as a function of floating point operations, where we
count only the necessary operations involved in the inner-loop and outer-loop updates (i.e.,
not those involved in convergence checks, computing the KL divergence, and so on). In
comparing the number of inner-loop iterations used by the different algorithms to meet the
convergence criterion, we scale the outer-loop iterations relative to the outer-loop iterations
of the just convex algorithm. That is, for each number of outer-loop iterations used by an
algorithm to reach a particular level of accuracy, we consider the corresponding number of
outer-loop iterations used by the just convex algorithm to reach the same level.

173

Heskes

(a)

(b)
just_convex
negative_to_zero
cccp
kl−divergence

kl−divergence

just_convex
negative_to_zero
cccp
0

10

−2

0

10

−2

10

10
0

20

40
60
80
outer−loop iterations

100

0

1

2
flops

3

4
6

x 10

Figure 4: Bethe approximation on a 9 × 9 Boltzmann grid. Kullback-Leibler divergence
between exact and approximate single-node marginals as a function of the outerloop iterations (a) and floating point operations (b) for three different algorithms.

We have done simulations on quite a number of different problems and problem instances, involving both Markov random fields and Bayesian networks. The results shown
here are exemplary and meant to illustrate the more general findings that we will summarize
below.
5.2 Bethe Free Energy on a Boltzmann Grid
Our first set of simulations concerns the minimization of the Bethe free energy on a Boltzmann grid of 9 × 9 nodes with pairwise interactions of the form


tj
ti
(27)
ψij (xi , xj ) = exp wij (2xi − 1)(2xj − 1) + (2xi − 1) + (2xj − 1)
ni
nj
where ni is the number of neighbors of node i, i.e., 2 for a corner node, 3 for other nodes
on the boundary, and 4 for nodes in the middle. Weights wij and biases ti are drawn at
random from a normal distribution with mean zero and standard deviation 0.5. In the
Bethe approximation the outer regions are all pairs of neighboring nodes.
Figure 4 shows the summed KL divergence between exact and approximate single-node
marginals as a function of the number of outer loop iterations (a) and as a function of
the number of floating point operations (b) for the just convex, negative to zero, and
cccp algorithms. It can be seen that, as expected, the just convex algorithms converges
faster than the negative to zero algorithm, which itself converges faster than the cccp algorithm. The speed-up in terms of outer-loop iterations translates into an almost equivalent
speed-up in terms of flops. Indeed, as can be seen in Figure 5(a), the number of inner-loop
iterations required by the just convex algorithm is just slightly higher than that of the
other two algorithms.
The curves in Figure 4(a) can be mapped onto each other with a rough linear scaling
of the number of outer-loop iterations. This is also suggested by the straight lines in
174

Efficient minimization of the Kikuchi free energy

2

outer−loop iterations

10

(b)
number of inner−loop iterations

(a)
just_convex
negative_to_zero
cccp

1

10

0

10
0
10

8
6
4
2
0

1

just_convex
negative_to_zero
cccp

10
outer−loop iterations

10
20
30
40
outer−loop iterations (scaled)

Figure 5: Bethe approximation on a 9 × 9 Boltzmann grid. (a) Outer loop iterations of
the just convex algorithm versus the corresponding outer-loop iterations of the
other two algorithms. (b) Number of inner loop iterations needed to meet the
convergence criterion as a function of the outer-loop iterations, scaled according
to (a).

Figure 5(a). The slope of these lines relate to each other as 0.34, 1 (by definition), and 1.35
for just convex, negative to zero and cccp, respectively (see also the convergence rates
in Table 1). The following argumentation shows that there is a striking correspondence
between these numbers and the respective bounds.
The negative overcounting numbers
P
for the Bethe free energy FKikuchi
P add up to β∈I− cβ = −207. For the respective convex
bounds Fconvex , these sums are β∈I− c̃β = −144, 0, and 81. If we now translate these into
the fraction of “negative overcounting mass” that is “bounded”, i.e.,
P
P
β∈I− cβ −
β∈I− c̃β
P
,
β∈I− cβ

we obtain, respectively 0.30, 1 (by definition), and 1.39. That is, there appears to be an
almost linear relationship between the tightness of the bound (here expressed in the fraction
of concave entropy contributions that is bounded linearly) and the speed of convergence.
We have noticed the same almost linear relationship in all other simulations involving a
Bethe free energy (no positive overcounting numbers).
5.3 Kikuchi Free Energy on a Boltzmann Grid

Our second set of simulations is also on a 9×9 Boltzmann grid, where now the outer regions
are chosen to be all squares of four neighboring nodes. Potentials are of the form (27) with
weights and biases drawn from a normal distribution with standard deviation 4 and 0.5,
respectively. Note that the size of the weights is much larger than in the previous set of
simulations, to make the problem still a bit of a challenge for the Kikuchi approximation.
With these weights, the Bethe approximation does very badly (summed Kullback-Leibler
175

Heskes

(a)

(b)

2

2

10
just_convex
negative_to_zero
all_to_zero
cccp

1

10

kl−divergence

kl−divergence

10

0

10

just_convex
negative_to_zero
all_to_zero
cccp

1

10

0

10

0

200
400
600
outer−loop iterations

800

0

5

10
flops

15
7

x 10

Figure 6: Kikuchi approximation on a 9 × 9 Boltzmann grid. Kullback-Leibler divergence
between exact and approximate single-node marginals as a function of the outerloop iterations (a) and floating point operations (b) for four different algorithms.

divergence larger than 10). Both for the Bethe and for the Kikuchi algorithm, the singleloop algorithm has convergence problems: for the Bethe approximation it typically gets
stuck in a limit cycle and for the Kikuchi approximation it tends to diverge. In total there
are 8 × 8 = 64 outer regions and (8 × 7) × 2 = 122 negative inner regions (all node pairs
that correspond to intersections of the outer regions) and 7 × 7 = 49 positive inner regions
(all single nodes that correspond to intersections of the node pairs).
Figure 6 shows the KL divergence between approximate and exact single-node marginals
for the four different algorithms in terms of the outer-loop iterations (a) and floating point
operations (b). It can be seen that the ordering in (a) is again as expected: the tighter the
bound, the faster the algorithm. In terms of floating point operations, the just convex and
all to zero algorithm get much closer together.
Part of the explanation is given in Figure 7: the just convex algorithm requires considerably more inner-loop iterations to meet the same convergence criterion. The other
effect is that the all to zero algorithm in its inner loop only runs over the 112 negative
inner regions instead of all 161 positive and negative inner regions. This makes that each
inner-loop iteration of all to zero requires a factor 1.8 less floating point operations than
an inner-loop iteration of the other three algorithms.
Here it is more difficult to find a quantitative relationship between the tightness of
the bounds and the (asymptotic) convergence rates. One of the complications is that not
only the negative, but also the positive overcounting numbers play a role. In any case, all
algorithms still seem to converge linearly, with faster convergence rates for tighter bounds.
These convergence rates, expressed as the time scale of the corresponding exponential decay
(KL(t) − KL(∞) ∝ exp[−t/τ ], with t and τ in outer-loop iterations), are summarized in
Table 1.

176

Efficient minimization of the Kikuchi free energy

3

outer−loop iterations

10

(b)
number of inner−loop iterations

(a)
just_convex
negative_to_zero
all_to_zero
cccp

2

10

1

10

0

10
0
10

25
20
15
10
5
0

1

10
outer−loop iterations

just_convex
negative_to_zero
all_to_zero
cccp

5

10
15
20
25
outer−loop iterations (scaled)

Figure 7: Kikuchi approximation on a 9 × 9 Boltzmann grid. (a) Outer loop iterations of
the just convex algorithm versus the corresponding outer-loop iterations of the
other three algorithms. (b) Number of inner loop iterations needed to meet the
convergence criterion as a function of the outer-loop iterations, scaled according
to (a).

Figure 8: Graphical structure of the QMR-like network.
5.4 A QMR Network
Our third set of simulations concerns a QMR-like (Quick Medical Reference) Bayesian
network (Heckerman, 1989; Jaakkola & Jordan, 1999): a bipartite graph with a layer of
disease nodes and a layer of findings. The particular network used in these simulations has
been generated with the Bayes Net Toolbox (Murphy, 2001). It contains 20 finding nodes,
of which 18 are observed (positive), and 10 hidden disease nodes; see Figure 8. The diseases
have Bernoulli probability distributions with a prior drawn at random between 0 and 0.01.
The findings have noisy-or conditional probability distributions without leakage. Diseases
and findings are linked randomly with probability 0.5. The absence of leakage, large amount
of findings, and strong connectivity make this a relatively difficult inference problem. As
outer regions we take the subsets implied by the conditional probability distribution, i.e.,
each outer region consists of a disease and all findings linked to it. Figure 9 gives the
corresponding region graph.

177

Heskes

−1−1−1−1−1−1−1−1−1−1−1−1−1−1−1−1−1−1−1−1−1−1−1−1−1−1−1−1−1−1−1−1
1 0 0 1 0 0 0 1 1 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
0

0

1

−1

0

−1

1

−1

−1

0
−2

1

2

−2

0

1

−1

1

1

−1

0

−1

−1

1

1

−1

0

−1
1

Figure 9: Region graph resulting from the QMR-like network.

(a)
just_convex
negative_to_zero
all_to_zero
cccp

10

10

−2

10

0

200
400
600
outer−loop iterations

just_convex
negative_to_zero
all_to_zero
cccp

0

kl−divergence

0

kl−divergence

(b)

800

−2

10

0

2

4

6
flops

8

10
8

x 10

Figure 10: Kikuchi approximation on a QMR-like network. Kullback-Leibler divergence
between exact and approximate single-node marginals as a function of the outerloop iterations (a) and floating point operations (b) for four different algorithms.

178

Efficient minimization of the Kikuchi free energy

(b)
number of inner−loop iterations

outer−loop iterations

(a)
just_convex
negative_to_zero
all_to_zero
cccp

2

10

1

10

0

10
0
10

35

25
20
15
10
5
0

1

10
outer−loop iterations

just_convex
negative_to_zero
all_to_zero
cccp

30

5
10
15
outer−loop iterations (scaled)

20

Figure 11: Kikuchi approximation on a QMR-like network. (a) Outer loop iterations of the
just convex algorithm versus the corresponding outer-loop iterations of the
other three algorithms. (b) Number of inner loop iterations needed to meet the
convergence criterion as a function of the outer-loop iterations, scaled according
to (a).

original
just convex
negative to zero
all to zero
cccp

-207
-144
0
0
81

Bethe
+
τ
0
0
3.8
0 11.3
0 11.3
0 15.3

Kikuchi
+
τ
-112 49
-64
1
11
0 49
41
0
0
29
112 49 153

-54
-34
0
0
52

QMR
+
τ
35
15
6
35
67
0
17
35 166

Table 1: Summary of asymptotic convergence (τ is the time constant, with time in outerloop iterations, in the exponential decay) and sums of negative and positive overcounting numbers in the original Kikuchi/Bethe free energy and the convex bounds
used by the different algorithms.

The results can be found in Figure 10 and 11. They are comparable with those for the
Kikuchi approximation on the Boltzmann grid. Also here the single-loop algorithm fails
to converge. The just convex algorithm converges much faster than the other three algorithms, but requires more inner-loop iterations and is less efficient than the all to zero algorithm, which makes the latter preferable in terms of floating point operations. However,
it is relatively straightforward to speed-up the just convex algorithm. First, we probably
do not need that many inner-loop iterations for the outer loop to converge properly. And
secondly, where we now bound part of each entropy contribution, a more efficient choice
would have as many zero overcounting numbers as possible.

179

Heskes

5.5 General Findings
Here we summarize some of the points that have been illustrated above and that we have
encountered in many other simulations as well.
• The tighter the (convex) bound used in the inner loop, the faster the convergence in
terms of outer-loop iterations.
• The number of outer-loop iterations needed to meet a prespecified convergence criterion tends to decrease with a looser bound, but never nearly enough to compensate
for the slower convergence in the outer loop.
• In fact, we have only observed a strong dependency between this number of inner-loop
iterations and the tightness of the bound if the bound is just convex and the problem
is “hard” in the sense that a single-loop algorithm would fail to converge.
• In terms of floating point operations, a looser bound that sets all overcounting numbers
in the inner loop to zero, can beat a tighter bound with negative overcounting numbers:
the slower convergence in terms of outer-loop iterations is compensated by a more
efficient inner loop.
Pelizzola (2005) tests several convergent algorithms on Kikuchi approximations of problems in statistical physics and reports similar findings. Also in this study, the just convex algorithm, described for the first time by Heskes, Albers, and Kappen (2003), clearly outperforms all competitors.

6. Discussion
This article is based on the perspective that we are interested in minima of the Kikuchi
free energy under appropriate constraints. Finding such a minimum then becomes a possibly non-convex constrained minimization problem. Here, as well as in other studies, the
approach has been to solve this non-convex problem through sequential constrained minimization of convex bounds on the Kikuchi free energy. On the presumption that tighter
bounds yield faster algorithms, we have worked out several ideas to construct tight convex
bounds. The simulation results in this article as well as those obtained by Pelizzola (2005)
clearly validate this presumption and show that the speed-ups can be very significant.
Heskes, Zoeter, and Wiegerinck (2004) apply these bounds for (approximate) parameter
learning in directed graphical models.
The double-loop algorithms considered in this article are all based on convex bounds
of the Kikuchi free energy. In principle, this is not necessary: our only concern is that
the inner-loop algorithm converges and this might well be the case for tighter bounds. One
practical solution is to simply choose a (tight) bound on the Kikuchi free, check whether the
inner-loop algorithm does converge, and restart with a looser bound if not. Alternatively,
we can construct tighter bounds making use of conditions for guaranteed convergence of
belief propagation such as those derived by Tatikonda and Jordan (2002), Heskes (2004),
Ihler et al. (2005) for the Bethe approximation.
It has been suggested that non-convergence of single-loop generalized/loopy belief propagation by itself is an indication that the Kikuchi/Bethe approximation is inaccurate. The
180

Efficient minimization of the Kikuchi free energy

results in Section 5.3 and 5.4 show that this need not always be the case. Apparently, there
does exist a “middle range” of problems where the Kikuchi free energy is not easy to minimize, but does yield decent approximations. It is on these problems that the algorithms
described in this article are useful.

Acknowledgments
The author would like to thank Wim Wiegerinck, Onno Zoeter, Kees Albers, and Bert Kappen for fruitful discussions and the anonymous reviewers for their constructive comments.
This work has been supported in part by the Dutch Technology Foundation STW.

Appendix A: Convexity of the Difference between Two Entropies
This appendix treats two lemmas on the convexity of the difference between two entropies.
The first one is used in the proof of Theorem 3.1. A similar lemma is used by McEliece and
Yildirim (2003).
Lemma A.1. The difference between two entropies
X
X
qγ (xβ ) log qγ (xβ )
qγ (xγ ) log qγ (xγ ) −
∆γβ (qγ ) ≡
xβ

xγ

=

X
xβ

is convex in qγ .



qγ (xβ ) 

X

xγ\β



qγ (xγ\β |xβ ) log qγ (xγ\β |xβ )

Proof We take a step backwards and write ∆γβ out as

∆γβ (qγ ) =

X
xγ





 qγ (xγ ) 
.
qγ (xγ ) log 
X

qγ (x′γ ) 

x′γ\β

When taking derivatives, we best interpret the table qγ , specifying the value qγ (xγ ) for each
possible realization xγ , as a vector with xγ playing the role of an index. Taking second
derivatives, we then obtain
Hxγ ,x′γ (qγ ) ≡

∂ 2 ∆γβ (qγ )
1
1
′ .
=
Ix ,x′ −
I
∂qγ (xγ )∂qγ (x′γ )
qγ (xγ ) γ γ qγ (xβ ) xβ ,xβ

with Ix,x′ ≡ 1 if all elements of x and x′ are equal and zero otherwise.

181

Heskes

Next we would like to show that this matrix is positive semi-definite, i.e., that for all
tables q̃, again to be interpreted as vectors with indices xγ ,
0 ≤

X

q̃(xγ )Hxγ ,x′γ (qγ )q̃(x′γ ) =

xγ ,x′γ

xγ


 X q̃ 2 (x , x )
X
β
γ\β
−
=

qγ (xγ\β , xβ )
x x
β

γ\β

X q̃(xγ )q̃(x′γ )
′
I
qγ (xγ )
qγ (xβ ) xβ ,xβ
′
xγ ,xγ


′
q̃(xγ\β , xβ )q̃(xγ\β , xβ ) 

X q̃ 2 (xγ )

X

xγ\β ,x′γ\β

−

qγ (xβ )


i2 
hP



X  X q̃ 2 (xγ\β , xβ )
xγ\β q̃(xγ\β , xβ )
=
− P
.

qγ (xγ\β , xβ )

xγ\β qγ (xγ\β , xβ ) 
x x
β




γ\β

From Cauchy’s inequality,

X

a2k

k

X

b2k ≥

k

"

X
k

ak bk

#2

,

it follows that the term between braces is indeed semi-positive q
for each realization of xβ .
To see this, we make the substitutions xγ\β ⇒ k, q̃(xγ\β , xβ )/ qγ (xγ\β , xβ ) ⇒ ak , and
q
qγ (xγ\β , xβ ) ⇒ bk to find
{. . .} ⇒

X
k

a2k

P
2
k ak bk ]
− P
≥0.
2
k bk
[

The following related lemma is used in Appendix B.

Lemma A.2. The difference between two entropies
X
X
∆γβ (qγ , qβ ) ≡
qγ (xγ ) log qγ (xγ ) −
qγ (xβ ) log qβ (xβ )
xγ

xβ

is convex in {qγ , qβ }.
Proof The Hessian matrix has components
Hxγ ,x′γ

≡

∂ 2 ∆γβ (qγ )
1
=
Ix ,x′
′
∂qγ (xγ )∂qγ (xγ )
qγ (xγ ) γ γ

Hxγ ,x′β

≡

∂ 2 ∆γβ (qγ )
1
′
=−
I
′
∂qγ (xγ )∂qβ (xβ )
qβ (xβ ) xβ ,xβ

Hxβ ,x′β

≡

qγ (xβ )
∂ 2 ∆γβ (qγ )
′ .
I
= 2
′
∂qβ (xβ )∂qβ (xβ )
qβ (xβ ) xβ ,xβ

182

Efficient minimization of the Kikuchi free energy

Convexity requires that for any q̃ = (q̃γ (xγ ), q̃β (xβ )),
q̃γ (xγ ) q̃β (xβ )

0 ≤
=

X q̃γ2 (xγ )

−2

Hxγ ,x′γ
Hxβ ,x′γ

Hxγ ,x′β
Hxβ ,x′β

X q̃γ (xγ )q̃β (xβ )

qβ (xβ )


X
q̃γ (xγ ) q̃β (xβ ) 2
−
.
qγ (xγ )
=
qγ (xγ ) qβ (xβ )
x
xγ

qγ (xγ )



xγ

+

!

q̃γ (x′γ )
q̃β (x′β )



X qγ (xβ )q̃β2 (xβ )
qβ2 (xβ )

xβ

γ

Appendix B: Minimizing a Convex Kikuchi Free Energy
In this appendix, we derive Algorithm 1 for minimizing a convex Kikuchi free energy under
appropriate linear constraints. To simplify notation, we will use the convention that α runs
over outer regions, and β over inner regions.
First, we note that in principle it is not necessary to explicitly take into account all
constraints (6), since some constraints are implied by others. Obviously, the constraint
between two inner region marginals,
qβ ′ (xβ ) = qβ (xβ ) for some β ′ ⊃ β ,
is implied by corresponding constraints between the inner region marginals and an outer
region subsuming both inner regions,
qα (xβ ′ ) = qβ ′ (xβ ′ ) and qα (xβ ) = qβ (xβ ) for some α ⊃ β ⊃ β ′ .
That is, we do not have to take into account constraints between inner regions and other
inner regions. Similarly, normalization constraints on outer region pseudo-marginals follow
from normalization constraints on the inner region pseudo-marginals. So, a sufficient set of
constraints is
X
qα (xα )
∀α⊃β
qα (xβ ) = qβ (xβ ) with qα (xβ ) =
xα\β

X

qβ (xβ ) = 1

∀β .

xβ

Introducing Lagrange multipliers λαβ (xβ ) and λβ for the corresponding constraints, we
obtain the Lagrangian
 X X

XX
qα (xα )
qβ (xβ ) log qβ (xβ )
+
cβ
L(q, λ) =
qα (xα ) log
ψα (xα )
xβ
α xα
β




XXX
X
X
X
+
λαβ (xβ ) qβ (xβ ) −
qα (xα ) +
λβ 1 −
qβ (xβ ) . (B-1)
β α⊃β xβ

xα\β

183

β

xβ

Heskes

Convex Independent of the Constraints
Let us first consider the case that all overcounting numbers cβ are strictly positive (cβ >
0). Then, the Lagrangian is not just convex over the set of constraints, but convex in
q independent of the constraints. Minimization of the Lagrangian with respect to these
pseudo-marginals follows by setting its derivatives to zero, yielding
Y
eλαβ (xβ ) ∀α
(B-2)
qα∗ (xα ) = ψα (xα )e−1
β⊂α

qβ∗ (xβ )

λβ /cβ −1

= e

Y

e−λαβ (xβ )/cβ ∀β ,

(B-3)

α⊃β

where here and in the following it should be noted that qα∗ and qβ∗ are functions of the
Lagrange multipliers λ. Substituting this solution back into the Lagrangian, we obtain the
dual
X
XX
X X
L∗ (λ) ≡ L(q∗ (λ), λ) =
λβ −
qα (xα ) −
cβ
qβ (xβ ) .
(B-4)
β

α

xα

β

xβ

Now, consider optimizing L∗ (λ) with respect to the subset of the components corresponding
to the inner region β, collected in λβ ≡ (λβ , λαβ (xβ ) ∀α⊃β,xβ ), keeping all other λβ ′ for
β ′ 6= β fixed. Because of the concavity of the dual L∗ (λ), we can find the maximum in the
direction λβ by setting the corresponding derivatives to zero. This yields

∂L∗ (λ) 
= qβnew (xβ ) − qαnew (xβ ) = 0 ∀xβ ;α⊃β
∂λαβ (xβ ) λ=λnew

X
∂L∗ (λ) 
=
1
−
qβnew (xβ ) = 0 ,
(B-5)
∂λβ λ=λnew
xβ
where q new refers to the solution (B-2) and (B-3) with λαβ (xβ ) replaced by λnew
αβ (xβ ) and
λβ by λnew
.
Since
from
(B-2)
β
new

qαnew (xβ )

eλαβ (xβ )
= λ (x ) qα (xβ ) ,
e αβ β

the solution for λnew
αβ (xβ ) must obey
new
λnew
αβ (xβ ) = − log qα (xβ ) + λαβ (xβ ) + log qβ (xβ ) ,

where we still have to solve for qβnew (xβ ). Summing this expression over all α ⊃ β, substituting (B-3), and solving for qβnew (xβ ) we get
log qβnew (xβ ) =

X
1
1
[log qα (xβ ) − λαβ (xβ )] +
(λnew − cβ ) .
n β + cβ
n β + cβ β
α⊃β

Now, we obtain exactly the updates in Algorithm 1 if we define
µβ→α (xβ ) = eλαβ (xβ ) and µα→β (xβ ) = qα (xβ )e−λαβ (xβ ) ,
184

Efficient minimization of the Kikuchi free energy

and properly normalize qβ (xβ ), as in line 7. The normalization of qα (xα ) in line 10 is then
in fact unnecessary, since by construction the updates ensure that qα (xβ ) = qβ (xβ ) with
Zα = 1.
The bottom line is that with the particular ordering in Algorithm 1 the joint update of
all messages for a particular subset β can be interpreted as doing coordinate-wise gradient
ascent in the dual L∗ (λ), updating the Lagrange multipliers λβ and λαβ (xβ ) for a particular
β and all α ⊃ β at the same time. Therefore Algorithm 1 is guaranteed to converge to the
unique maximum in the case of all positive overcounting numbers cβ .
Convex over the Set of Constraints
Next, let us consider the more general case in which (some of) the overcounting numbers are
negative, but such that the Kikuchi free energy is still convex over the set of constraints.
We consider the case in which all inner region overcounting numbers are negative5 . We
will show that, with sufficient damping of the updates, Algorithm 1 is still guaranteed to
converge to the unique minimum of the Kikuchi free energy over the set of constraints.
Note that direct application of the above argumentation fails, because the solution (B-3)
for qβ (xβ ) with negative cβ corresponds to a maximum rather than a minimum. Consequently, the dual L∗ (λ) in (B-4) need not be concave. The updates in Algorithm 1 that
follow by setting derivatives to zero can be interpreted as fixed-point iterations, not as coordinate ascent in L∗ (λ). Still, in practice they do seem to work just fine and indeed without
always increasing L∗ (λ). In the following we will explain why: we will argue that the updates of Algorithm 1 do not correspond to coordinate ascent, but rather to something like
coordinate descent-ascent on a convex-concave saddle function. With sufficient damping,
such an algorithm will converge to the unique saddle point, which then corresponds to the
minimum of the Kikuchi free energy over the set of constraints.
Convexity over the set
P according to Theorem 3.1, that there exists
P of constraints implies,
a matrix Aαβ such that α Aαβ = |cβ | and β Aαβ ≤ 1. Using qβ (xβ ) = qα (xβ ), we replace
the Lagrangian (B-1) by

 XX
XX
X
qα (xα )
L̃(q, λ) =
qα (xα ) log
qα (xβ ) log qβ (xβ )
−
Aαβ
ψα (xα )
α xα
xβ
β α⊃β




XXX
X
X
X
X
1
+
λαβ (xβ ) 
qα′ (xβ ) −
qα (xα ) +
λβ 1 −
qβ (xβ ) . (B-6)
nβ ′
x
x
x
β α⊃β

α ⊃β

β

β

α\β

β

Now since, from Lemma A.2 in Appendix A,
X
X
qα (xα ) log qα (xα ) −
qα (xβ ) log qβ (xβ )
xα

xβ

is convex in {qα (xα ), qβ (xβ )}, the Lagrangian (B-6) is indeed convex in q independent of the
constraints. Thus we could apply the same argumentation as above: find the minimum of
5. Our argumentation does not hold if some of the negative inner region entropy contributions have to be
compensated by positive inner region subset entropy contributions to prove convexity of the Kikuchi free
energy. In that case, we might need a slightly different algorithm to guarantee convergence.

185

Heskes

the convex Lagrangian with respect to q, substitute the corresponding solution q∗ (λ) back
into the Lagrangian to obtain the concave dual L̃∗ (λ), and maximize this dual with respect
to λ. The problem is that we do not have a closed-form expression for the optimal q∗ (λ)
and thus also no closed-form expression for the dual L̃∗ (λ), which makes this procedure
rather awkward.
Instead, we distinguish between the outer region marginals, collected in qO , and the
inner region marginals, collected in qI . Having rewritten the consistency constraint in terms
of outer region marginals alone, we only replace the constrained minimization with respect
to qO by unconstrained maximization with respect to corresponding Lagrange multipliers
λO , leaving the minimization with respect to qI under the normalization constraint as
is. This gives us a saddle-point problem of the type minqI maxλO . Even without explicitly
writing out the equations, we can tell that maximization with respect to λαβ for a particular
β and all α ⊃ β corresponds to finding λαβ such that
qαnew (xβ ) = qαnew
′ (xβ )

∀α,α′ ⊃β .

Then, minimization with respect to qβ given fixed qαnew (xβ ) immediately yields
X
Aαβ qαnew (xβ ) ,
qβnew (xβ ) ∝
α⊃β

properly normalized to sum to 1. This is exactly what the updates for a particular inner
region β in Algorithm 1 amount to: they yield the unique maximum with respect to λαβ
and minimum with respect to qβ , while keeping all other λα′ β ′ and qβ ′ for β ′ 6= β fixed.
Such a “coordinate descent-ascent procedure” works fine if the saddle function is convex in the minimizing parameter and concave in the maximizing parameter (e.g., Seung,
Richardson, Lagarias, & Hopfield, 1998). The concavity in λ is immediate, the convexity
in qI follows from the convexity of the Lagrangian (B-6) in q = (qO , qI ): minimizing
an overall convex function over some of its parameters, here qO , yields a convex function
over its remaining parameters, qI . Technically, convergence to the unique solution of the
saddle-point problem can be proven through the construction of a Lyapunov function that
decreases under infinitesimal updates of the parameters in the descent and ascent direction
to zero at the unique saddle point (Seung et al., 1998). Convergence can be guaranteed for
sufficiently damped updates, not the “full” ones in Algorithm 1. Empirically the full updates, that correspond to full maximization and minimization for one inner region β before
moving on the next one, work fine in most cases, but occasionally indeed require a little
damping. Wainwright et al. (2003) successfully apply damping to a very similar algorithm
in an attempt to minimize a convexified Bethe free energy.

Appendix C: Constructing a Tight Convex Bound
In this appendix, we describe a procedure for constructing a tight convex bound Fconvex
of the Kikuchi free energy FKikuchi . It combines ideas from Section 4.3 and 4.4. That is,
we first convexify the Kikuchi free energy, bounding as little concave contributions from
negative inner regions as possible. Next, in the terms that we have to bound anyways, we
try to incorporate as many convex contributions as we can. This leads to the following
procedure.
186

Efficient minimization of the Kikuchi free energy

• Consider minus the entropy
−S = −


X

Sα +



α∈O

X

cβ Sβ +

X

cγ Sγ

,



γ∈I+

β∈I−




and choose c̃β ≥ cβ for β ∈ I− such that the first term in
 


 X
X

X
X
cγ Sγ −
c̃β Sβ +
(cβ − c̃β )Sβ ,
−S = −
Sα +
 
 α

γ∈I+

β∈I−

β∈I−

is (just) convex.

• With A the corresponding allocation matrix of Theorem 3.1, define the “used resources”
X
Aγβ |c̃β | ≤ cγ ,
ĉγ ≡
β∈I−

and rewrite
−S = −


X


Sα +

α

−

c̃β Sβ +

β∈I−


X


X

X

ĉγ Sγ

γ∈I+

(cβ − c̃β )Sβ +

X

γ∈I+

β∈I−

By construction, the first term is still convex.





(cγ − ĉγ )Sγ




.



• To guarantee convexity, we have to bound the entropy contributions Sβ in the second
term for each β ∈ I− . To make this bound tighter, we include as many of the convex
contributions Sγ as we can, while still satisfying the conditions in Theorem 4.2. Call
the corresponding overcounting numbers cγ − c̃γ ≤ cγ − ĉγ and put the remaining
c̃γ − ĉγ back into the first term:


X

X
X
c̃γ Sγ
−S = −
c̃β Sβ +
Sα +
 α

γ∈I+
β∈I−


X

X
−
(cγ − c̃γ )Sγ .
(cβ − c̃β )Sβ +


γ∈I+

β∈I−

• Choose Fconvex to be the first term plus a linear bound of the second term.

To find c̃β in the first step and similarly c̃γ in the third, we can use a linear program
similar to the one described in Section 3.2 for checking the conditions of Theorem 3.1. We
introduce slack variables θβ and replace condition (7d) by
X
Aγβ = θβ ∀β∈I− (variable compensation) ,
γ⊃β

187

Heskes

similar in spirit to (8). Furthermore, we add the inequality constraints θβ ≤ |cP
β | ∀β∈I−
(no need to compensate for more than |cβ |) and search for the maximum of θ ≡ β∈I− θβ
(compensate as much as possible). In terms of the corresponding solution θβ∗ , we set c̃β =
cβ − θβ∗ .

References
Aji, S., & McEliece, R. (2001). The generalized distributive law and free energy minimization. In Proceedings of the Allerton Conference on Communication, Control, and
Computing.
Besag, J. (1974). Spatial interaction and the statistical analysis of lattice systems. Journal
of the Royal Statistical Society Series B, 36, 192–236.
Chiang, M., & Forney, G. (2001). Statistical physics, convex optimization and the sum
product algorithm. Tech. rep., Stanford University.
Darroch, J., & Ratcliff, D. (1972). Generalized iterative scaling. Annals of Mathematical
Statistics, 43, 1470–1480.
Dechter, R., Kask, K., & Mateescu, R. (2002). Iterative join-graph propagation. In Darwiche, A., & Friedman, N. (Eds.), Proceedings UAI-2002, pp. 128–136.
Dempster, A., Laird, N., & Rubin, D. (1977). Maximum likelihood from incomplete data
via the EM algorithm. Journal of the Royal Statistical Society B, 39, 1–38.
Hall, P. (1935). On representatives of subsets. Journal of the London Mathematical Society,
10, 26–30.
Heckerman, D. (1989). A tractable inference algorithm for diagnosing multiple diseases. In
Kanal, L., Henrion, M., Shachter, R., & Lemmer, J. (Eds.), Proceedings of the Fifth
Workshop on Uncertainty in Artificial Intelligence, pp. 163–171, Amsterdam. Elsevier.
Heskes, T. (2003). Stable fixed points of loopy belief propagation are minima of the Bethe
free energy. In Becker, S., Thrun, S., & Obermayer, K. (Eds.), Advances in Neural
Information Processing Systems 15, pp. 359–366, Cambridge. MIT Press.
Heskes, T. (2004). On the uniqueness of loopy belief propagation fixed points. Neural
Computation, 16, 2379–2413.
Heskes, T., Albers, K., & Kappen, B. (2003). Approximate inference and constrained optimization. In Uncertainty in Artificial Intelligence: Proceedings of the Nineteenth
Conference (UAI-2003), pp. 313–320, San Francisco, CA. Morgan Kaufmann Publishers.
Heskes, T., Zoeter, O., & Wiegerinck, W. (2004). Approximate Expectation Maximization. In Thrun, S., Saul, L., & Schölkopf, B. (Eds.), Advances in Neural Information
Processing Systems 16, pp. 353–360, Cambridge. MIT Press.
Ihler, A., Fisher, J., & Willsky, A. (2005). Loopy belief propagation: Convergence and
effects of message errors. Journal of Machine Learning Research, 6, 905–936.
Jaakkola, T., & Jordan, M. (1999). Variational probabilistic inference and the QMR-DT
network. Journal of Artificial Intelligence Research, 10, 291–299.
188

Efficient minimization of the Kikuchi free energy

Jiroušek, R., & Přeučil, S. (1995). On the effective implementation of the iterative proportional fitting procedure. Computational Statistics and Data Analysis, 19, 177–189.
Jordan, M., Ghahramani, Z., Jaakkola, T., & Saul, L. (1998). An introduction to variational
methods for graphical models. In Jordan, M. (Ed.), Learning in Graphical Models,
pp. 183–233. Kluwer Academic Publishers, Dordrecht.
Kikuchi, R. (1951). The theory of cooperative phenomena. Physical Review, 81, 988–1003.
Kschischang, F., Frey, B., & Loeliger, H. (2001). Factor graphs and the sum-product algorithm. IEEE Transactions on Information Theory, 47 (2), 498–519.
Lauritzen, S. (1996). Graphical models. Oxford University Press, Oxford.
Luenberger, D. (1984). Linear and Nonlinear Programming. Addison-Wesley, Reading,
Massachusetts.
McEliece, R., MacKay, D., & Cheng, J. (1998). Turbo decoding as as an instance of Pearl’s
‘belief propagation’ algorithm. IEEE Journal on Selected Areas in Communication,
16 (2), 140–152.
McEliece, R., & Yildirim, M. (2003). Belief propagation on partially ordered sets. In
Gilliam, D., & Rosenthal, J. (Eds.), Mathematical Systems Theory in Biology, Communications, Computation, and Finance, pp. 275–300. Springer, New York.
Murphy, K. (2001). The Bayes Net toolbox for Matlab. Computing Science and Statistics,
33, 331–350.
Murphy, K., Weiss, Y., & Jordan, M. (1999). Loopy belief propagation for approximate
inference: An empirical study. In Laskey, K., & Prade, H. (Eds.), Proceedings of
the Fifteenth Conference on Uncertainty in Articial Intelligence, pp. 467–475, San
Francisco, CA. Morgan Kaufmann Publishers.
Neal, R., & Hinton, G. (1998). A view of the EM algorithm that justifies incremental,
sparse, and other variants. In Jordan, M. (Ed.), Learning in Graphical Models, pp.
355–368. Kluwer Academic Publishers, Dordrecht.
Pakzad, P., & Anantharam, V. (2002). Belief propagation and statistical physics. In 2002
Conference on Information Sciences and Systems, Princeton University.
Pakzad, P., & Anantharam, V. (2005). Estimation and marginalization using Kikuchi approximation methods. Neural Computation, 17, 1836–1873.
Pearl, J. (1988). Probabilistic Reasoning in Intelligent systems: Networks of Plausible Inference. Morgan Kaufmann, San Francisco, CA.
Pelizzola, A. (2005). Cluster variation method in statistical physics and graphical models.
Journal of Physics A, 38, R309–R339.
Seung, S., Richardson, T., Lagarias, J., & Hopfield, J. (1998). Minimax and Hamiltonian
dynamics of excitatory-inhibitory networks. In Jordan, M., Kearns, M., & Solla, S.
(Eds.), Advances in Neural Information Processing Systems 10, pp. 329–335. MIT
Press.
Tatikonda, S., & Jordan, M. (2002). Loopy belief propagation and Gibbs measures. In Darwiche, A., & Friedman, N. (Eds.), Uncertainty in Artificial Intelligence: Proceedings
189

Heskes

of the Eighteenth Conference (UAI-2002), pp. 493–500, San Francisco, CA. Morgan
Kaufmann Publishers.
Teh, Y., & Welling, M. (2002). The unified propagation and scaling algorithm. In Dietterich,
T., Becker, S., & Ghahramani, Z. (Eds.), Advances in Neural Information Processing
Systems 14, pp. 953–960, Cambridge. MIT Press.
Wainwright, M., Jaakkola, T., & Willsky, A. (2002a). A new class of upper bounds on the log
partition function. In Darwiche, A., & Friedman, N. (Eds.), Uncertainty in Artificial
Intelligence: Proceedings of the Eighteenth Conference (UAI-2002), pp. 536–543, San
Francisco, CA. Morgan Kaufmann Publishers.
Wainwright, M., Jaakkola, T., & Willsky, A. (2002b). Tree-based reparameterization for
approximate estimation on loopy graphs. In Dietterich, T., Becker, S., & Ghahramani,
Z. (Eds.), Advances in Neural Information Processing Systems 14, pp. 1001–1008,
Cambridge. MIT Press.
Wainwright, M., Jaakkola, T., & Willsky, A. (2003). Tree-reweighted belief propagation
algorithms and approximate ML estimation via pseudo-moment matching. In Bishop,
C., & Frey, B. (Eds.), Proceedings of the Ninth International Workshop on Artificial
Intelligence and Statistics. Society for Artificial Intelligence and Statistics.
Yedidia, J., Freeman, W., & Weiss, Y. (2001). Generalized belief propagation. In Leen,
T., Dietterich, T., & Tresp, V. (Eds.), Advances in Neural Information Processing
Systems 13, pp. 689–695, Cambridge. MIT Press.
Yedidia, J., Freeman, W., & Weiss, Y. (2005). Constructing free energy approximations
and generalized belief propagation algorithms. IEEE Transactions on Information
Theory, 51, 2282–2312.
Yuille, A. (2002). CCCP algorithms to minimize the Bethe and Kikuchi free energies:
Convergent alternatives to belief propagation. Neural Computation, 14, 1691–1722.

190

Journal of Artificial Intelligence Research 26 (2006) 417-451

Submitted 11/05; published 08/06

Multiple-Goal Heuristic Search
Dmitry Davidov
Shaul Markovitch

dmitry@cs.technion.ac.il
shaulm@cs.technion.ac.il

Computer Science Department
Technion, Haifa 32000, Israel

Abstract
This paper presents a new framework for anytime heuristic search where the task is to
achieve as many goals as possible within the allocated resources. We show the inadequacy
of traditional distance-estimation heuristics for tasks of this type and present alternative
heuristics that are more appropriate for multiple-goal search. In particular, we introduce
the marginal-utility heuristic, which estimates the cost and the beneﬁt of exploring a subtree
below a search node. We developed two methods for online learning of the marginal-utility
heuristic. One is based on local similarity of the partial marginal utility of sibling nodes, and
the other generalizes marginal-utility over the state feature space. We apply our adaptive
and non-adaptive multiple-goal search algorithms to several problems, including focused
crawling, and show their superiority over existing methods.

1. Introduction
Internet search engines build their indices using brute-force crawlers that attempt to scan
large portions of the Web. Due to the size of the Web, these crawlers require several weeks
to complete one scan, even when using very high computational power and bandwidth (Brin
& Page, 1998; Douglis, Feldmann, Krishnamurthy, & Mogul, 1997), and they still leave a
large part of the Web uncovered (Lawrence & Giles, 1998; Najork & Wiener, 1998). Many
times, however, it is necessary to retrieve only a small portion of Web pages dealing with a
speciﬁc topic or satisfying various user criteria. Using brute-force crawlers for such a task
would require enormous resources, most of which would be wasted on irrelevant pages. Is
it possible to design a focused crawler that would scan only relevant parts of the Web and
retrieve the desired pages using far fewer resources than the exhaustive crawlers?
Since the Web can be viewed as a large graph (Cooper & Frieze, 2002; Kumar, Raghavan,
Rajagopalan, Sivakumar, Tomkins, & Upfal, 2000; Pandurangan, Raghavan, & Upfal, 2002),
where pages are nodes and links are arcs, we may look for a solution to the above problem
in the ﬁeld of heuristic graph-search algorithms. A quick analysis, however, reveals that the
problem deﬁnition assumed by the designers of heuristic search algorithms is inappropriate
for focused crawling, which uses an entirely diﬀerent setup. The crucial diﬀerence between
heuristic search and focused crawling is the success criterion. In both setups there is a set
of goal states. In the heuristic search setup, however, the search is completed as soon as a
single goal state is found, while in the focused crawling setup, the search continues to reach
as many goal states as possible within the given resources.
Changing the success criterion of existing search algorithms is not enough. Most informed search algorithms are based on a heuristic function that estimates the distance from
a node to the nearest goal node. Such heuristics are usually not appropriate for multiplec
2006
AI Access Foundation. All rights reserved.

Davidov & Markovitch

goal search. Consider the search graph described in Figure 1. The grey area is the expanded
Start

B
A

Figure 1: Using a distance-estimation heuristic for a multiple-goal search problem
graph. Assume that we evaluate nodes A and B using a distance-based heuristic. Node A
has a better heuristic value and will therefore be selected. This is indeed the right decision
for traditional search where the task is to ﬁnd one goal. For multiple-goal search, however,
B looks like a much more promising direction since it leads to an area with a high density
of goal nodes.
For many problems in a wide variety of domains where we are interested in ﬁnding
a set of goals rather than a single goal. In genetic engineering, for example, we want to
ﬁnd multiple possible alignments of several DNA sequences (Yoshizumi, Miura, & Ishida,
2000; Korf & Zhang, 2000). In chemistry we may want to ﬁnd multiple substructures of
a complex molecule. In robotics, we may want to plan paths for multiple robots to access
multiple objects. In some of these cases, a possible solution would be to invoke single-goal
search multiple times. Such an approach, however, is likely to be wasteful, and for resourcebounded computation, we may wish to exploit the multiple-goal1 nature of the problem to
make the search more eﬃcient.
The speciﬁc multiple-goal task of focused crawling has received much attention (Chakrabarti,
van den Berg, & Dom, 1999; Cho & Garcia-Molina, 2000; Cho, Garcı́a-Molina, & Page, 1998;
Diligenti, Coetzee, Lawrence, Giles, & Gori, 2000; Rennie & McCallum, 1999) because of
the popularity of the Web domain. Most of these works, however, focused on Web-speciﬁc
techniques tailored for the particular problem of crawling.
The goal of the research described in this paper is to establish a new domain-independent
framework for multiple-goal search problems and develop anytime heuristic algorithms for
solving them eﬃciently. Our framework focuses mainly on problem domains where we are
looking for the goal states and the paths to the goals either are irrelevant, or their cost is
of no concern (except for its eﬀect on the search cost).
1. Note that the term “multiple-goal” is also used in the planning domain. There, however, the task is to
satisfy a set of dependent goals with possible order constraints.

418

Multiple-Goal Heuristic Search

We start with a formal deﬁnition of the multiple-goal search problem. We then describe
versions of existing heuristic search algorithms, modiﬁed for the multiple-goal framework.
The main diﬀerences between single-goal and multiple-goal search are the heuristic functions
used. We describe a new set of heuristics that are better suited for multiple-goal search. In
particular, we introduce the marginal-utility heuristic, which considers the expected costs
as well as the expected beneﬁts associated with each search direction. It is diﬃcult to
specify such heuristics explicitly. We therefore present adaptive methods that allow online
learning of them. Finally we describe an extensive empirical study of our algorithms in
various domains, including the focused crawling problem.
The contributions of this paper are fourfold:
1. We identify and deﬁne the framework of multiple-goal heuristic search. This is a novel
framework for heuristic search.
2. We deﬁne a set of search algorithms and heuristics that are appropriate for multiplegoal search problems.
3. We deﬁne a utility-based heuristic and present a method for automatic acquisition of
it via online learning.
4. We provide extensive empirical study of the presented methods in various domains
and show their superiority over existing general algorithms.

2. The Multiple-Goal Search Problem
Let S, E be a potentially inﬁnite state graph with ﬁnite degree, where S is a set of states
and E ⊆ S × S is a set of edges. The single-goal search problem can be deﬁned as follows:
1. Input:
• A set of initial states Si ⊆ S
• A successor function Succ : S → 2S such that Succ(s) = {s | s, s  ∈ E}.
(Sometimes Succ is given implicitly be a ﬁnite set of operators O.)
• A goal predicate G : S → {0, 1}. We denote Sg = {s ∈ S | G(s)}. Sometimes Sg
is given explicitly.
2. Search objective: Find a goal state g ∈ Sg such that there is a directed path in S, E
from a state in Si to g. Sometimes we are also interested in the path itself.
3. Performance evaluation: Although the performance evaluation criterion is not commonly considered to be an integral part of the problem deﬁnition, we do consider
it as such. This is because it determines the class of algorithms to be considered.
The most common criteria for evaluating a search are the solution quality, usually
measured by the solution path cost, and search eﬃciency, mostly evaluated by the
resources consumed during the search.
Although the multiple-goal search problem bears some similarity to the single-goal search
problem, it diﬀers in several ways:
419

Davidov & Markovitch

1. Input: Includes an additional resource limit R. For simplicity of presentation we
assume that R is given to us as a number of generated nodes2 . Later we will discuss
this assumption.
2. Search objective: Find a set of goal states SgR ⊆ Sg which satisﬁes:
• For each s ∈ SgR , there is a directed path in S, E from some si ∈ Si to s.
• The search resources consumed should not exceed R.
Sometimes we are also interested in the set of corresponding paths.






3. Performance evaluation: SgR . Obviously, higher values are considered better.
While it looks as if we mix here reasoning with meta reasoning by inserting resource
limit as part of problem input, many problems are much more naturally deﬁned with such
a resource limitation. Consider, for example, the minimax algorithm, where the maximal
depth of search (which determines the resources consumed) is given as part of the algorithm’s
input. The above formulation, where the resource limit is given as an input, falls under
the scope of problems solved by anytime algorithms (Boddy & Dean, 1994; Hovitz, 1990;
Zilberstein, 1996) and more speciﬁcally by contract algorithms (Russell & Zilberstein, 1991;
Zilberstein, Charpillet, & Chassaing, 1999).
Sometimes the resource limit is not known in advance. In such a setup, the search
algorithm can be interrupted at any time and required to return the current set of collected goals. This type of problem is solved by interruptible anytime algorithms (Hansen
& Zilberstein, 1996; Russell & Zilberstein, 1991). An alternative formalization is to require
the algorithm to ﬁnd a speciﬁed number of goals and to evaluate its performance by the
resources consumed during the search.

3. Multiple-Goal Heuristic Search Algorithms
Assume that hmg : S →  is a heuristic function that estimates the merit of states with
respect to the objective and performance evaluation criterion of a multiple-goal search
problem as deﬁned in the previous section.
Our objective is to develop search algorithms that can exploit such heuristics in a similar
manner to the heuristic search algorithms developed for single-goal search problems. We
start by describing the multiple-goal version of greedy best-ﬁrst search3 .
There are two main diﬀerences between the existing single-goal best-ﬁrst search algorithm and our newly deﬁned multiple-goal version:
1. While single-goal best-ﬁrst search stops as soon as it encounters a goal state, the
multi-goal version collects the goal and continues until the allocated resources are
exhausted.
2. Our framework is therefore applicable to any resource that is proportional to the number of generated
nodes. That can be CPU time, internet bandwidth, energy consumption by robots, etc. For best-first
search algorithms, the number also corresponds to the memory consumption.
3. We follow Russell and Norvig (2003, page 95) who use this term to describe a search algorithm that
always expands the node estimated to be closest to a goal.

420

Multiple-Goal Heuristic Search

2. While single-goal best-ﬁrst search typically uses a heuristic function that tries to
approximate the distance to the nearest goal, the multiple-goal version should use a
diﬀerent type of heuristic that is more appropriate for the multiple-goal task.
Most of the other heuristic search algorithms can also be modiﬁed to ﬁnd multiple goals.
The A∗ algorithm by Pearl and Kim (1982) can be converted to handle multiple goal search
by collecting each goal it ﬁnds in its focal list. These are goals with −optimal paths. A
multiple-goal heuristic can be used to select a node from the focal list for expansion. The
algorithm stops, as before, when the allocated resources are exhausted. In addition, we can
stop the algorithm when all the nodes in focal satisfy f (n) > (1 + )gmin , where gmin is the
minimal g value among the collected goals.
Multiple-goal hill-climbing uses a multiple-goal heuristic to choose the best direction.
We modify this algorithm to allow the search to continue after a goal is found. One possible
method for continuing the search is to perform a random walk from the found goal.
Multiple-goal backtracking works similarly to the single goal version. However, when a
goal is encountered, the algorithm simulates failure and therefore continues. A multiple goal
heuristic can be used for ordering the operators in each node. For constraint satisfaction,
that means ordering the values associated with a variable.

4. Heuristics For Multiple-Goal Problems
In the introduction, we illustrated the problem of using a traditional distance-estimation
heuristic for multiple-goal search. One of the main problems with using such a distanceestimation heuristic is that it does not take into account goal density but only the distance
to the nearest goal. This can lead the search into a relatively futile branch, such as the
left branch in Figure 1, rather than the much more fruitful right branch. In this section we
consider several alternative heuristic functions that are more appropriate for multiple-goal
search.
4.1 The Perfect Heuristic
Before we describe and analyze heuristic functions for multiple-goal search, we would like
to consider the function that we are trying to approximate. Assume, for example, that we
perform multiple-goal greedy best-ﬁrst search and that we have perfect knowledge of the
search graph. What node would we like our heuristic to select next? Assume that the given
resource limit allows us to expand additional M nodes, and look at all the search forests4
of size M rooted at the current list of open nodes. A perfect heuristic will select a node
belonging to the forest with the largest number of goals.
Definition 1 Let Sopen ⊆ S be the set of currently open states. Let R be the resource limit
and Rc be the resources consumed so far. Let Sgf ⊆ Sg be the set of goals found so far. Let
F be a set of all possible forests of size R − Rc starting from roots in Sopen . A forest f ∈ F
is optimal if and only if




∀f  ∈ F, (Sg \ Sgf ) ∩ f   ≤ |(Sg \ Sgf ) ∩ f | .
4. While the search space is a graph, the search algorithm expands a forest under the currently open nodes.

421

Davidov & Markovitch

A state s ∈ Sopen is optimal, denoted as OP T (s), if and only if there exists an optimal
forest f such that s ∈ f .
Definition 2 A heuristic function h is perfect with respect to a multiple-goal search problem
if for every possible search stage deﬁned by Sopen ,
∀s1 , s2 ∈ Sopen [OPT(s1 ) ∧ ¬OPT(s2 ) =⇒ h(s1 ) < h(s2 )] .
Thus a perfect heuristic never selects for expansion a state that is not in an optimal
forest. Using such a heuristic in multiple-goal best-ﬁrst search will make the search optimal.
Note that the optimality is with respect to search resources and not with respect to the
cost of paths leading to the goal states.
Obviously, the above deﬁnition does not lead to a practical multiple-goal heuristic. Even
for simple problems, and even when we have perfect knowledge about the graph, calculating
such a heuristic is very hard. This is because the number of possible forests is exponential
in the resource limit and in the number of nodes of the open list.
4.2 Sum Heuristics
Many search algorithms that look for a single goal state use a heuristic function that estimates the cost of the cheapest path to a goal state. Optimizing algorithms such as A∗
require admissible heuristics (that underestimate the real distance to the goal) while satisﬁcing search algorithms, such as greedy best-ﬁrst, can use non-admissible heuristics as well.
Distance-estimation heuristics were therefore developed for many domains. In addition,
several researchers have developed automatic methods for inferring admissible heuristics by
relaxation (Held & Karp, 1970; Mostow & Prieditis, 1989; Prieditis, 1993) and by pattern
databases (Culberson & Schaeﬀer, 1998; Gasser, 1995; Korf & Felner, 2002).
Figure 1 illustrates that a straightforward use of distance heuristics for multiple-goal
search is not appropriate. Here we deﬁne a method for utilizing (admissible or nonadmissible) distance heuristics for multiple-goal search. Assume that the set of goal states,
Sg , is given explicitly, and that we are given a common distance-estimation heuristic
hdist (s1 , s2 ) that estimates the graph distance between two given states5 . The sum-ofdistances heuristic, denoted as hsum , estimates the sum of distances to the goal set:
hsum (s) =



hdist (s, g).

(1)

g∈Sg

Minimizing this heuristic will bias the search towards larger groups of goals, thus selecting
node B in the example of Figure 1. This is indeed a better decision, provided that enough
resources are left for reaching the goals in the subgraph below B.
4.3 Progress Heuristics
One problem with the sum heuristic is its tendency to try to progress towards all of the
goals simultaneously. Hence, if there are groups of goals scattered around the search front,
all the states around the front will have similar heuristic values. Each step reduces some of
5. Assume that the Euclidean distance in the figure reflects the heuristic distance.

422

Multiple-Goal Heuristic Search

the distances and increases others, leading to a more-or-less constant sum. In such constantsum regions, an algorithm which relies only on the sum heuristic will have no information
about which node to choose for expansion. Even when there are a few distinct groups of

Figure 2: The behavior of the sum heuristic vs. that of the progress heuristic. The solidline ellipse indicates the area covered by a search using the sum heuristic. The
dotted-line ellipse marks the area searched using the progress heuristic.

goals in diﬀerent directions, the sum heuristic may lead to simultaneous progress towards
all the groups. The two groups of goal states shown in Figure 2 illustrate this problem. The
sum heuristic strategy will work only if there are enough enough resources to reach all the
groups. If, however, the resources are not suﬃcient, the sum heuristic may waste all the
available resources in trying to progress towards all the groups, but reaching none.
To avoid such problems, we deﬁne the progress heuristic, which takes into account the
number of goals towards which progress is made and the average distance to them. Thus,
instead of trying to pursue multiple groups of goals, this heuristic will pursue one group at
a time, preferring less distant groups.
Let Sopen be the set of currently opened states. As before, we assume that we have
the explicit goal list, Sg = g1 , . . . , gk , and a distance-estimation heuristic, hdist . Let
mi = mins∈Sopen hdist (s, gi ) be the minimal estimated distance from the search frontier to
the goal gi . For each s ∈ Sopen we deﬁne Gp (s) = {gi ∈ Sg | hdist (s, gi ) = mi } to be the set
of goals for which s is estimated to be the closest among the states in thesearch frontier.
g∈G (s)

hdist (s,g)

p
The average estimated distance between s and the states in Gp is Dp (s) =
|Gp (s)|
be their average distance from s. We are interested in states that have many members in
Gp with small average distance. Hence, we deﬁne the progress heuristic to be

hprogress (s) =

Dp (s)
.
|Gp (s)|

(2)

Minimizing this heuristic will direct the search to larger and closer groups of goals towards
which progress is made. For example, in the simple space shown in Figure 2, the progress
heuristic will advance correctly, towards the group at the left side as indicated by the dashed
ellipse. Note that although the right group is larger, the progress heuristic nonetheless
prefers the left one because of its smaller distance. Since the progress heuristic considers
each goal exactly once, it is not misled by multiple paths to the same goal.

423

Davidov & Markovitch

4.4 Marginal-Utility Heuristics
When comparing two search directions, we have so far considered only the concentration
of goal states, preferring directions that lead to larger groups of goals. Thus, the former
heuristics would have considered node A and node B in Figure 3 to be equivalent. This
reasoning, however, does not take into account the resources invested to reach the set of
goals. In the example of Figure 3, it is clear that visiting the set of goals under node B
requires less search resources than those under node A. Therefore node B is preferable.
Start

B
A

Figure 3: Searching from node A will result in the same number of goals as searching from
node B. It will consume, however, far greater resources.
We account for these cases by suggesting another approach for multiple-goal heuristics,
one that considers not only the expected beneﬁt of the search but also the expected cost.
Obviously, we prefer subgraphs where the cost is low and the beneﬁt is high. In other words,
we would like a high return for our resource investment. We call a heuristic that tries to
estimate this return a marginal-utility heuristic.
Assume (for now) that the search space S, E is a tree. Let T (s) be the set of all states
that are reachable from s. Let Tg (s) = T (s) ∩ Sg be the set of all goal states reachable from
s. Let Sv ⊆ S be the set of all states visited during a completed search process. We deﬁne
the marginal utility of state s ∈ Sv with respect to Sv as
MU(s) =

|Tg (s) ∩ Sv |
.
|T (s) ∩ Sv |

(3)

Thus, MU measures the density of goal states in the subtree expanded by the search process.
One possible good search strategy is to select states that are should eventually yield high
values of M U with respect to Sv . If the search process has consumed Rc ≤ R resources so
424

Multiple-Goal Heuristic Search

far, then the largest tree that can be visited is of size r = R − Rc . In Section 4.1 we deﬁne
the perfect heuristic by considering all the possible ways of distributing r among the open
nodes. This approach is obviously impractical, and we will take here a greedy approach
instead. We look for a heuristic function hM U (s, r) that tries to estimate the best marginal
utility of s, assuming that all the remaining resources, r, are consumed while exploring
T (s). Let T (s, r) be the set of all trees of size r under root s. hM U (s, r) tries to estimate
the resource-bounded marginal utility, deﬁned as
|Tg (s) ∩ T |
.
r
T ∈T (s,r)

MU(s, r) = max

(4)

MU(s, r) measures the best ratio between the number of goals achieved and the search
resources used for it. Naturally, it is very diﬃcult to build heuristics that estimate marginal
utility accurately. In the following sections we show how such heuristics can be learned.
4.5 Additional Considerations
One possible side-eﬀect of not stopping when discovering goals is the continuous inﬂuence
of the already discovered goals on the search process. The found goals continue to attract
the search front, where it would have been preferable for the search to progress towards
undiscovered goals. If an explicit set of goal states is given - as it is for the sum and progress
heuristics - we can disable the inﬂuence of visited goals by simply removing them from the
set. If a set of features over states is given instead, we can reduce the eﬀect of visited goals
by preferring nodes that are farther from them in the feature space. Speciﬁcally, let d(n)
be the minimal distance of n from members in the set of visited goals, and let h(n) be the
multiple-goal heuristic value of n. The modiﬁed heuristic will be h (n) = h(n)(1+c1 e−c2 d(n) )
where c1 and c2 are parameters that determine the magnitude of the eﬀect of d(n). The
second term is the penalty we add to the heuristic value. This penalty decays exponentially
with the distance from the visited goals.
Note that there is a tension between the tendency to search dense groups of goals and
and the tendency to push the search away from visited goals. When the groups of goals
are dense, the above method can be detrimental because ﬁnding some of the goals in a
group reduces the tendency to pursue the other goals of the same group. This eﬀect can
be controlled by the ci parameters. For domains with high goal density, ci should be set to
lower values. Hence, these values can be set dynamically during the search, according to
measurements of goal density in the explored graph.
One problem with using the marginal utility heuristic in non-tree graphs is the possible
overlap of marginal utility. That means that our search algorithm might pursue the same set
of goals from diﬀerent directions. One way to overcome this problem is to try to diversify
the search progress by measuring the feature-based average distance between the “best”
nodes and the set of recently expanded nodes, and prefer those with maximal diversity
from the nodes explored. This gives maximal diversity in exploration directions and should
minimize the expected overlap of visited subtrees.

425

Davidov & Markovitch

5. Learning Marginal Utility Heuristics
While it is quite possible that marginal-utility heuristics will be supplied by the user, in
many domains such heuristics are very diﬃcult to design. We can use a learning approach
to acquire such marginal-utility heuristics online during the search. We present here two
alternative methods for inferring marginal utility. One approach estimates the marginal
utility of a node based on the partial marginal utility of its siblings. The other approach
predicts the marginal utility using feature-based induction.
5.1 Inferring Marginal Utility Based on Marginal Utility of Siblings
The ﬁrst approach for predicting marginal utility is based on the assumption that sibling
nodes have similar marginal utility. We deﬁne the partial marginal utility of a state s at
step t of executing a multiple-goal search algorithm as the number of goals found so far in
the subtree below s divided by the number of states visited so far in this subtree. Thus, if
Sv (t) is the set of states visited up to step t, then the partial marginal utility is deﬁned as
M U (s, t) =

|Tg (s) ∩ Sv (t)|
.
|T (s) ∩ Sv (t)|

(5)

The method estimates the marginal utility of the siblings based on their partial marginal
utility, and the marginal utility of the node based on the average estimated marginal utility
of the siblings.
As discussed in the previous subsection, the expected marginal utility of a node strongly
depends on the resources invested in exploring it. Thus, to learn the heuristic hM U (s, r),
one would need to estimate partial marginal utility values for diﬀerent values of r. One
way of reducing the complexity of this two-dimensional estimation is to divide it into two
stages: estimating the depth of the tree under s that is searchable within r resources,

U depth (s, d) is the
and estimating the marginal utility for the predicted depth. Thus, if M
estimated marginal utility when searching node s to depth d, we compute the estimated
 r)),


U resources(s, r) = M
U depth (s, d(s,
marginal utility of a node s using r resources by M

where d(s, r) is the estimated depth when searching under node s using r resources. In the
following subsections we show how these values are estimated.
5.1.1 Updating Partial Marginal-Utility Values
We maintain for each node two vectors of D counters, where D is a parameter that limits
the maximal lookahead of the partial marginal utility. One vector, N (n), stores the current
number of visited nodes for node n for depth 1, . . . , D, where Ni (n) contains the current
number of visited nodes under n with depth of less or equal to i. The other vector, G(n)
holds similarly the number of visited goals.
Whenever a new node n is generated, the appropriate entries of its ancestors’ N vectors
are incremented. If n is a goal, then the G vectors are updated as well. If p is an ancestor
of n connected to it with a path of length l ≤ D, then Nl (p), . . . ND (p) are incremented by
one. If more than one path exists between n and p, we consider only the shortest one. The
memory requirements for this procedure are linear in D and in the number of stored nodes.
D
),
The number of operations required for one marginal-utility update is bounded by O(Bdegree
where Bdegree is the upper bound on the maximum indegree in the graph. Therefore, if the
426

Multiple-Goal Heuristic Search

backward degree is bounded, the number of calculations per node does not grow as the
search progresses. The depth limit D determines the complexity of the update for a given
search graph; hence, it is desirable to reduce its value. A value that is too low, however,
will make it possible to infer only “local” marginal-utility values.
5.1.2 Inferring Marginal Utility
The inference algorithm estimates the marginal utility of a node on the basis of the average
partial marginal utility of its siblings. Only nodes with suﬃcient statistics about partial
marginal utility are used to predict the marginal utility of new nodes. We call such nodes
supported nodes. If the node has no supported siblings, we base our estimate on the average
estimated marginal utility of its parents (computed recursively using the same procedure).
Figure 4 illustrates this method. In the left tree, the marginal utility of the grey node is

MU=0.4

MU=0.2

MU=(0.4+0.2)/2=0.3

MU=0.4

MU=0.2

MU=(0.4+0.2)/2=0.3

?

?

MU=0.3

Figure 4: Inferring marginal utility from partial marginal utility of supported siblings (left)
or supported uncles (right). Nodes with a question mark are unsupported.

computed as the average marginal utility of its siblings. In the right tree, the marginal
utility of the grey node is computed as the average marginal utility of its uncles. The input
to the marginal utility estimation heuristic is the remaining unconsumed resources, r. The
algorithm ﬁrst ﬁnds the largest depth, d, for which the number of predicted nodes is smaller
than r. This prediction is based on the supported siblings or the parent of the node just as
described above.
The found depth, d, is then used to determine which counters will be used to estimate
the marginal utilities of the supported uncles. The complete algorithm is listed in Figure
5.
5.1.3 Sibling Clustering
In the algorithm described in Figure 5, the marginal utility of a node is induced by averaging
the partial marginal utility of its siblings. If we can deﬁne a “meaningful” similarity metric
between nodes, we can try making this prediction less noisy by using only the node’s similar
siblings. One way of doing so is to use the similarity metric to cluster the set of siblings
and then generate a virtual node for each cluster. The virtual node is linked to the cluster
members and its parent is the parent of the original sibling set. This is the only required
change. The existing algorithm described in Figure 5 will do the rest. When predicting
the marginal utility for a node, the algorithm ﬁrst looks for the partial marginal utility
427

Davidov & Markovitch

procedure MU(s,d)
Gd (s)
if Supported(s,d) then return N
d (s)
else P ← Parents(s)
if |P | = 0 then return 0
SupportedSiblings ← {c ∈ Children(p) | p ∈ P, Supported(c)}
if |SupportedSiblings
 | > 0 then
	
Gd (c) 
c
∈
SupportedSiblings
return Avg

Nd (c)
else return Avg({M U (p, M in(d + 1, D)) | p ∈ P })
procedure TreeSize(s,d)
P ← Parents(s)
if Supported(s,d) or |P | = 0 then return Nd (s)
else
SupportedSiblings ← {c ∈ Children(p) | p ∈ P, Supported(c)}
if |SupportedSiblings | > 0 then
return Avg({{N
}) 


 d (c) | c ∈ SupportedSiblings

TreeSize(p,Min(d+1,D))  p ∈ P
else return Avg

|Children(p)|

procedure Get-marginal-utility(s,ResourceLimit )
Depth = max(d ≤ D|TreeSize(s, d) < ResourceLimit )
return MU(s, Depth)

Figure 5: An algorithm for marginal-utility estimation
of its siblings. In this case these are the members of its cluster. Only if these siblings
are unsupported will the algorithm use the information from the other clusters propagated
through the common parent.
This mechanism is illustrated in Figure 6. Without clustering, the predicted marginal
utility of the unsupported nodes would have been the average of the three supported siblings,
which is 0.5. Note that this average has a large variance associated with it. Clustering nodes
A and B under one virtual node, and C, D, and E under another, yields (we hope) more
accurate prediction, since it is based on more uniform sets. The similarity metric will
usually be the Euclidean distance between vectors of features of the states corresponding
to the sibling nodes. In some domains, we try to reduce the number of generated nodes by
deciding at each step which node-operator pair to proceed with. In such cases we need a
similarity measurement between operators to implement the above approach.
5.2 Feature-Based Induction of Marginal Utility
Unfortunately, partial marginal-utility information allows us to predict marginal utility only
for nodes that are in proximity to one another in the graph structure. In addition, there
428

Multiple-Goal Heuristic Search

Sibling clustering

0.5

A
B
? 0.1

C
0.7

D
0.7

0.5

E
?

0.1

A
?

B
0.1

C
0.7

D
0.7

E
0.7

?

Figure 6: The eﬀect of sibling clustering on marginal utility estimation
are domains where the local uniformity of sibling nodes with respect to marginal utility
cannot be assumed. We can overcome these problems if we view marginal-utility inference
as a problem of function learning and use common induction algorithms. For each depth
d, we induce the marginal utility function using the set of supported nodes (with respect
to d) as examples. The state features can be domain independent (such as the in-degree
and out-degree of the node) or domain speciﬁc, supplied by the user. As for any induction
problem, the quality of the induced function is highly dependent on the quality of the
supplied features.
Since the above learning scheme is performed on-line, he high cost of learning, and of
using the classiﬁer directly, reduce the utility of the learning process. One way to essentially eliminate the learning costs is to use a lazy learner, such as KNN (Cover & Hart,
1967). This approach also has the advantage of being incremental: each new example contributes immediately to the learned model. The problem with this approach is the high
costs associated with using the classiﬁer.
An alternative approach would be to learn an eﬃcient classiﬁer such as a regression
tree (Breiman, Friedman, Olshen, & Stone, 1984). This can be learned incrementally using
algorithms such as ID5 (Utgoﬀ, 1988). Batch learning algorithms such as C4.5 usually
yield better classiﬁers than incremental algorithms. However, due to the higher cost of
applying batch learning, one should decide how often to call it. Applying it after each node
generation would increase the induction cost, but yield better classiﬁers earlier - which may
improve the performance of the search process. Applying it at large intervals would reduce
the induction costs but lead to poorer search performance.
The on-line learning process gives rise to another problem: the initial search period
where there are not yet suﬃcient examples to make learning helpful. One way to reduce the
eﬀect of this lack of knowledge is by using classiﬁers that were induced beforehand, on-line
or oﬀ-line, for goals that are similar to the goals of the current search.

6. Empirical Evaluation
To test the eﬀectiveness of the methods described in the previous sections and to show their
versatility, we experimented intensively on several domains. The most challenging domain,
however, is focused crawling where we apply our algorithms to the task of collecting target
web pages from a sub-web of millions of pages. We ﬁrst compare the anytime behavior of
our distance-based methods with that of uninformed search and best ﬁrst search. Then
429

Davidov & Markovitch

we test the performance of our marginal utility methods. We also test the eﬀect of the
various suggested enhancements on the algorithms’ performance. We also show realtime
performance of our algorithm by allowing it to search the real web.
6.1 Experimental Methodology
We compare the performance of our algorithms to two competitors: breadth-ﬁrst search
and best-ﬁrst search using distance estimation heuristics. Both algorithms were adopted to
the multiple-goal framework by allowing them to continue the search after ﬁnding the ﬁrst
goal.
A basic experiment that compares two multiple-goal search algorithms is conducted in
the following way:
1. A set of initial states and a goal predicate are given.
2. The algorithms perform multiple-goal search.
3. The resources consumed and the number of goals found during the execution are
monitored.
4. The last two steps are repeated several times to accumulate suﬃcient statistics (all
the algorithms contain at least one random component).
5. The performance of the two algorithms, measured by the number of goals found for
the allocated resources, is compared.
The problem of estimating the performance of an algorithm when a resource allocation
is given is most extensively discussed in the context of anytime algorithms. Measuring
the performance of anytime algorithms is problematic (Hansen & Zilberstein, 1996). If
a probability distribution over the resource allocation is given, then we can compute the
expected performance of an anytime algorithm on the basis of its performance proﬁle. In
many cases, however, such a probability distribution is not available. We therefore measure
the performance of the tested algorithm by means of the obtained quality for diﬀerent
resource allocation values. For multiple-goal search, the quality is measured by the number
of goals found for the allocated resources. When we know the total number of goals, we
report instead the percentage of goals found.
Alternatively, anytime algorithms can be evaluated by measuring the amount of resources required to achieve a given quality. For multiple-goal search, the most obvious
measurement is time. Time, however, is overly aﬀected by irrelevant factors such as hardware, software, and programming quality. Moreover, in the Web domain, most of it is spent
accessing Web pages. How long this takes depends on many factors, such as network and
server loads, which are irrelevant to our research topic.
We thus decided to measure resource consumption by the number of generated nodes.
Nevertheless, we cannot ignore time completely: we must make sure that the overhead of
the methods described in this paper does not outweigh their beneﬁts. We therefore report
time results for an experiment that uses the real Web.
Many parameters aﬀect the performance of the algorithms described in this paper.
Ideally, we would like to perform factorial analysis (Montgomery, 2001) so that each combination of values is tested. Such experimentation, however, is infeasible for the large
430

Multiple-Goal Heuristic Search

number of variables involved. We therefore take the one-factor-at-a-time approach, where
we use a default value for all parameters except the one being tested. In addition, wherever
appropriate, we perform several experiments testing two factors together.
6.2 Tasks And Domains
Most of our experiments are conducted in the context of several Web domains. To show the
generality of our approach, we applied our methods to several additional domains, including
n-queens, open knight tours, multiple robot path planning and multiple sequence alignment.
Our algorithms were applied to the following tasks:
1. Focused crawling: One of the main motivations for this research is the problem of
focused crawling in the Web (Chakrabarti et al., 1999; Cho & Garcia-Molina, 2000;
Kleinberg, 1999; Menczer, Pant, Srinivasan, & Ruiz, 2001). The task is to ﬁnd as
many goal pages as possible using limited resources, where the basic resource unit
is usually the actual retrieval of a page from a link. While it looks as if the task of
retrieval information from internet could have been achieved using general-purpose
search engines, there are several circumstances where focused crawling is still needed:
(a) When the search criterion is complicated and is not expressible in the query
language of search engines.
(b) When one needs an updated set of goals – search engines are updated every few
weeks due to the huge space the brute-force crawlers have to cover.
(c) When the coverage of the general engines is not suﬃcient.
Previous work on focused crawling concentrated on Web-speciﬁc techniques for directing the search. Our experiments will test whether our generalization of single-goal
heuristic search to multiple-goal search can contribute to the task of focused crawling.
Performing rigorous empirical research on the Web is problematic. First, the Web
is dynamic and therefore is likely to be modiﬁed between diﬀerent runs of the algorithms (Douglis et al., 1997). Second, the enormous time required for crawling in the
Web disallows parametric experimentation. To solve the above problems we downloaded a signiﬁcant section of the Web to local storage and performed the experiments
using the local copy (Cho et al., 1998; Hirai, Raghavan, Garcia-Molina, & Paepcke,
2000). Speciﬁcally, we downloaded a large part of the .edu domain, containing, after some cleanup, approximately 8,000,000 valid and accessible HTML pages. The
resulting graph has an average branching factor of 10.6 (hyperlinks).
We tested the performance of the algorithms on the entire downloaded domain. Some
of the parametric experiments, however, were too time-consuming even when the local
copy was used. Therefore, we used small sub-domains for these experiments. A subdomain is generated by randomly selecting a root page out of a predesignated set of
roots and extracting a sub-graph of size 35,000 under it.
To ensure that the overhead of our algorithms does not signiﬁcantly aﬀect their performance, we also conducted several online experiments on the real Web.
We use three types of goal predicates:
431

Davidov & Markovitch

(a) Predicates that test for pages about speciﬁc topics: robotics, mathematics, football, food, and sport. The predicates were automatically induced by applying
decision tree learning to a set of manually supplied examples.
(b) Predicates that test for certain types of pages: pages containing publication lists,
laboratory pages, student home pages, project pages and news pages. These
predicates were also learned from examples.
(c) Predicates that test for home pages of people who are members of a speciﬁc
list. Each list of people was generated from a Web page listed the names of
people together some personal information (such as name, aﬃliation and area
of interest). The predicates employ commonly used heuristics for determining
whether an HTML document is a home page of a speciﬁc person. We use three
such predicates corresponding to three diﬀerent lists we found on the Web. We
limit each list to contain 100 names.
2. Finding paths to multiple goals: Path-ﬁnding algorithms usually search for a single
path to one of the goals. In some applications, however, we get a set of initial states
and a set of goal states and our task is to ﬁnd a set of paths from an initial state
to a goal state. These paths may then be used by another algorithm that evaluates
them and selects one to execute according to various criteria. We simulated a physical environment by a 500 × 500 grid with random “walls” inserted as obstacles (an
average of 210000 nodes with an average 3.9 branching factor). There are parameters
controlling the maximal length of walls and the desired density of the grid. Walls are
inserted randomly while making certain that the resulting graph remains connected.
The set of goal states is randomly generated using one of the following two methods:
(a) A set of states is independently and uniformly drawn from the set of all states.
(b) 10% of the goal states are generated as above. We then randomly and uniformly
select K states that are used as cluster centers. The rest of the goal states
are then randomly generated with distances from the centers that are normally
distributed.
Figure 7 shows an example of a multiple path-ﬁnding problem and a solution that
includes 9 paths.
3. Planning movement of multiple robots: Assume that we are given a set of N robots
located in various states, while their task is to collect a set of K > N objects scattered
around. In this case we need to plan N paths that will pass through as many objects
as possible. This situation is illustrated in Figure 8. Although the problem appears
to resemble the one in Figure 7, the solution here has two paths (while the solution to
the previous problem has 9). There are many similar planning problems: for example,
that of planning product delivery from several starting points to multiple customers
using a ﬁxed number of delivery trucks. For the experiments here we used the same
type of grids as for the previous problem. The robots were placed randomly. We
assumed that collisions are not harmful.
4. Open knight tours: This is a famous problem where the task is to ﬁnd a path for a
knight on a chess board such that each of the squares is visited and none is visited
432

Multiple-Goal Heuristic Search

G

G

G

G
G

G

G

G

G

G

G

G

G

G

G

G

G

G

S

S

S

S

Figure 7: Searching for a set of paths to multiple goals in a grid
G

G

G
G

G
G

G

G

G

G

G

G

G

G

G

G

G

R1

G

R2

R1

R2

Figure 8: Multiple-robot path planning in a grid
twice. We tried a multiple-goal version of it where the task is to ﬁnd as many such
paths as possible within the allocated resources. For our experiments, we used boards
of 6 × 6, 7 × 7 and 8 × 8 squares.
5. N-Queens: A constraint satisfaction problem where the goal is to place N queens on a
chessboard such that no two queens are in the same row, column or diagonal. In the
multiple goal version of this problem, we want to ﬁnd as many satisfying conﬁgurations
as possible within the allocated resources.
6. Multiple sequence alignment: A known bioinformatics problem where the goal is to
align several biological sequences optimally with respect to a given cost function.
In the multiple-goal version we are interested in obtaining as many almost optimal
solutions as possible within the allocated resources.
6.3 Performance with Distance-Based Heuristics
We experimented ﬁrst on the two multiple-goal heuristic functions that are based on graphdistance estimation: the sum heuristic and the progress heuristic. We compare the performance of multiple-goal best-ﬁrst search that uses these heuristics with:
433

Davidov & Markovitch

Domain

Task

BFS

Multiple path
ﬁnding
Multiple robot
movement

scattered
clustered
scattered
clustered

8.5(0.1)
10.2(0.1)
7.1(0.8)
10.1(0.9)

Focused
crawling
100-person search

Group 1
Group 2
Group 3

0.1(0.0)
3.2(1.4)
0.3(0.1)

Min. dist.
Sum
Without
With
Without
With
disab.
disab.
disab
disab
% of goals found at 20% resources
21.3(1.2) 29.0(0.5) 21.5(0.9) 28.9(0.3)
34.0(0.5) 45.1(0.4) 32.6(1.1) 59.2(0.3)
20.3(0.8) 26.5(0.4) 22.3(0.6) 25.8(0.2)
31.2(1.4) 47.4(1.2) 42.0(0.6) 64.1(0.7)
% of goals found at 2% resources
13.5(0.5) 17.3(1.3) 24.1(0.7) 28.0(1.1)
18.4(2.1) 26.2(1.9) 19.7(1.0) 23.5(1.1)
5.8(0.9)
10.7(1.4)
6.4(0.9)
11.7(0.9)

Progress

76.8(2.1)
94(1.2)
89.9(1.8)
98.6(0.9)
51.3(0.8)
78.1(3.1)
60.9(0.8)

Table 1: The performance of multiple-goal search with various heuristics. The numbers in parentheses are standard deviations.

1. Multiple-goal best-ﬁrst search that uses the distance estimation as its heuristic function.
2. Breadth-ﬁrst search (BFS) (shown by Najork & Wiener, 2001, to perform well for
Web crawling).
The sum heuristic requires distance estimates to individual goals. We deﬁne such distances for three of our domains. For the multiple path ﬁnding and multiple robot planning
we use the Manhattan distance. For focused crawling task we experiment with the personal
home page domain. We estimate the distance between a given page and the home page of a
list member by computing the cosine vector distance between the bag of words of the given
page and the bag of words of the description text for the person.
The distance heuristic and the sum heuristic were tested with and without disabling
the inﬂuence of visited goals. We did not use disabling with the progress heuristic since it
subsumes this behavior. For the two grid-based tasks, where all the goals are given, we used
complete disabling by removing the visited goals from the goal list as described in Section
4.5.
For the personal home page search task, where the set of goals is not explicitly given, we
used the feature-based method described in Section 4.5. The features used for determining
the distance between candidate pages and visited goals are the words with the highest
TFIDF value (Joachims, 1997; Salton & Buckley, 1988).
Table 1 summarizes the results of this experiment. Each number represents the average
of 50 experiments. We measure the performance after consuming 20% of the maximal
amount of resources, i.e., expanding 20% of the total number of nodes in the search graph.
The 100-person home page search proved to be a relatively easy domain where our methods
were able to ﬁnd most of the goals after consuming very little resources. Therefore, for
this domain, we measure the performance at 2% of the nodes. Figure 9 shows the anytime
behavior of the various methods for two of the domains. The graphs for the other domains
show similar patterns.
434

Multiple-Goal Heuristic Search

40

100
Breadth First Search
Distance-estimation heuristics
Sum heuristic

35

80
% Goals found

% Goals found

30
25
20
15

60

40

10
20

Breadth First Search
Distance-estimation heuristics
Sum heuristic
Progress heuristic

5
0

0
0

1

2

3

4

5

6

0

% Nodes generated

20

40

60

80

100

% Nodes generated

(a)

(b)

Figure 9: Anytime performance of the various heuristics: (a)Focused crawling (b)Multiple
path ﬁnding

On the basis of this table and corresponding graphs, we make the following observations:
1. The progress heuristic is superior to all other methods tested so far. That it is
advantageous for the case of clustered goals comes as no surprise because it leads
to one cluster being pursued at a time. That it is superior to distance estimation
for the case of scattered goals is far less obvious: we would expect both heuristics
to pursue one goal after another and therefore yield similar results. The weighted
progress heuristic, however, prefers pursuing goals that are closer to other goals, thus
yielding better results.
2. The results clearly demonstrate that the goal inﬂuence phenomenon is indeed signiﬁcant, and our method is eﬃcient in reducing this eﬀect.
3. In almost every case, heuristic methods are signiﬁcantly better than blind search. The
only exception is when using the sum heuristic without inﬂuence disabling in graphs
with scattered goals. In such cases, its behavior is only marginally better than blind
search.
6.4 Performance with Marginal-Utility Heuristics
None of the methods in the previous subsection take into account the expected search
resources involved in pursuing the alternative directions. In addition, they all assume
either knowledge of the speciﬁc set of goals or of the heuristic distances to each. In this
subsection we test the performance of the two methods that are based on marginal utility
as described in Section 5.1.2. The experiments described in this subsection are performed
for the focused crawling task with the 10 goal predicates described in Section 6.2.
For the topic-based goals, we cannot compare the performance of the marginal-utility
algorithms to that of the sum heuristic because we do not have access to the list of goals or
to a list of heuristic values for speciﬁc goals as in the previously tested domains. Therefore

435

Davidov & Markovitch

we use for comparison blind BFS and the common best-ﬁrst search using the distanceestimation heuristic. The heuristic is based on the list of words selected by the induction
algorithm when generating the goal predicates.
6.4.1 Inferring Marginal Utility from Partial Marginal Utility
We implemented and tested the marginal-utility estimation algorithm described in Section
5.1. Figure 10 shows the performance proﬁles of the tested algorithms for the robotics and
100

100
Distance-estimation heuristics
Breadth First Search
Marginal-utility inference

Distance-estimation heuristics
Breadth First Search
Marginal-utility inference

90

80

80

70

70
% Goals found

% Goals found

90

60
50
40

60
50
40

30

30

20

20

10

10

0

0
0

5

10

15

20

25

30

35

40

0

% Nodes generated

5

10

15

20

25

30

35

40

% Nodes generated

(a)

(b)

Figure 10: The performance of multiple-goal best-ﬁrst search using the marginal-utility
inference method applied to focused crawling (with D=4). The results are shown
for (a)Robotics pages (b) Mathematics pages

mathematics goal predicates. Each graph represents the average of 5 runs of the tested
algorithm using 5 starting pages randomly selected from the ﬁxed 200 root pages. In
both cases we see a signiﬁcant advantage of the marginal-utility method over the other
two methods. This advantage becomes evident only after an initial “training” period, in
which suﬃcient statistics are accumulated. The full data for the 10 domains with resource
allocation of 10% and 20% is available in the Appendix. Figure 11 shows the average
improvement factor (compared to distance estimation) for the 10 domains as a function of
the search resources. The graph shows very nicely the initial “exploratory” stage where the
statistics are accumulated until about 8% of the resources have been consumed, after which
the improvement factor becomes larger than 1. The improvement factor reaches a peak of
about 2.8 at 17%, and then starts to decline towards a value of 1 at 100% search resources,
where any algorithm necessarily ﬁnds all the goals.
Performance at the exploratory stage can be improved by combining the two methods.
We tested a hybrid method, which uses a linear combination of the marginal-utility prediction and the heuristic estimation. To determine the linear coeﬃcients of each part, we
conducted 100 experiments on the small Web subgraph (below 35,000 pages) using diﬀerent
goal predicates (unrelated to those tested in our main experiments). Figure 12 shows the
results obtained for the combined method compared to each of the individual methods. We
can see that indeed the combined method is better than each of the algorithms alone. An

436

Improvement factor for M.U. vs dist. estim. heuristics

Multiple-Goal Heuristic Search

3

2.5

2

1.5

1

0.5

0
0

10

20

30

40
50
60
70
% Nodes generated

80

90

100

Figure 11: The improvement factor for best-ﬁrst using marginal-utility inference compared
to best-ﬁrst using the distance-estimation heuristic

100

100
Distance-estimation heuristics
Marginal-utility inference
Combined approach

Distance-estimation heuristics
Marginal-utility inference
Combined approach

90

80

80

70

70
% Goals found

% Goals found

90

60
50
40

60
50
40

30

30

20

20

10

10

0

0
0

5

10

15

20

25

30

35

40

0

% Nodes generated

5

10

15

20

25

30

35

40

% Nodes generated

(a)

(b)

Figure 12: Combining marginal-utility inference with heuristic search for (a)Robotics pages
(b)Mathematics pages.

interesting phenomenon is that, at all points, the result for the combined method is better
than the maximal results for the other two. One possible explanation is that very early in
the search process the distance-estimation heuristic leads to a suﬃcient number of goals to
jump-start the learning process much earlier. The results for the 10 domains are available
in the Appendix.
6.4.2 Learning Marginal-Utility from Features
In Section 5 we describe a method for feature-based generalization of visited search nodes
in order to induce marginal-utility values. We conducted a set of experiments to test the

437

Davidov & Markovitch

eﬃciency of the learning mechanism for the problem of focused crawling with the same 10
goal types as in previous experiments.
During crawling, we accumulate the supported visited pages and tag them with their
marginal utility as measured at the time learning took place (see Section 5). We then convert
the tagged pages to feature vectors and hand them to the CART algorithm (Breiman et al.,
1984) for regression-tree induction6 . We then used the induced tree to estimate the marginal
utility of newly generated nodes.
For features, we use the bag-of-words approach, which is dominant in the ﬁeld of text
categorization and classiﬁcation. The value of each word-feature is its appearance frequency.
Words appearing in HTML title tags are given more weight. We apply feature selection to
choose words with the highest TFIDF (Joachims, 1997; Salton & Buckley, 1988).
100

100
Feature-based marginal-utility induction
Distance-estimation heuristics
Marginal-utility inference

Feature-based marginal-utility induction
Distance-estimation heuristics
Marginal-utility inference

90

80

80

70

70
% Goals found

% Goals found

90

60
50
40

60
50
40

30

30

20

20

10

10

0

0
0

5

10

15

20

25

30

35

40

0

% Nodes generated

5

10

15

20

25

30

35

40

% Nodes generated

(a)

(b)

Figure 13: The performance of best-ﬁrst search with marginal utility induced using the
regression trees classiﬁer. The experiments were performed on the problem of
focused crawling with: (a)Robotics pages (b) Mathematics pages

Figure 13 shows the results obtained for the robotics and mathematics goal predicates.
The full report for the 10 domains is available in the Appendix. In both cases, there is
an initial period where the sibling-based inference method outperforms the more sophisticated feature-based induction. After this period, however, the induction-based method
signiﬁcantly outperforms the sibling-based method. One possible reason for the initial inferior performance is that feature-based induction requires more examples than the simplistic
sibling-based method that only computes averages and therefore needs fewer examples.
We inspected the produced trees and found out that they reﬂect reasonable concepts.
They have several dozens of nodes and contain both features that are related to the searched
goal and features that correspond to hubs (such as repository and collection).
We have tested whether our choice of classiﬁer aﬀects the performance of the inductionbased method by performing the same set of experiments using the KNN classiﬁer. The
results obtained were essentially identical.
6. Other induction algorithms, such as SVM or Naive Bayes, could have been used as well.

438

Multiple-Goal Heuristic Search

6.5 Testing the Full System Architecture

100

100

90

90

80

80

70

70
% Goals found

% Goals found

We have described various enhancements of our marginal-utility methods, including sibling
clustering, overlap minimization, combining the marginal-utility heuristic with the distanceestimation heuristic, and disabling of visited goals. Figure 14 shows the performance of the
two marginal-utility methods with the full set of enhancements. The full results for the 10
domains are available in the Appendix.

60
50
40
30

60
50
40
30

Enhanced induction
Inference
Induction
Enhanced inference
Distance-estimation heuristics

20
10

Enhanced induction
Inference
Induction
Enhanced inference
Distance-estimation heuristics

20
10

0

0
0

5

10

15

20

25

30

35

40

0

% Nodes generated

5

10

15

20

25

30

35

40

% Nodes generated

(a)

(b)

Figure 14: The performance of best-ﬁrst search (using diﬀerent marginal-utility heuristics)
with all the enhancements enabled: (a)Robotics pages (b) Mathematics pages.
Each ﬁgure contains 5 plots: one for the baseline performance (distance estimation), two for the unenhanced methods (inference and induction) and two for
the enhanced methods (enhanced inference and enhanced induction).
Both the sibling- and feature-based methods indeed improve when all the enhancements
are enabled. Furthermore, the feature-based method maintains its advantage, albeit with a
slightly decreased magnitude. Although enabling all the enhancements does improve system
performance, it should be recalled that the same is true for enabling each enhancement separately. A question thus arises whether the improvements are at least partially cumulative.
In other words, would performance using all the enhancements be better than performance
using each of the enhancements separately? Figure 15 compares all the graphs for the
sibling-based method. We can see that the fully enhanced method is indeed superior to all
the rest.
6.6 Realtime Performance
In the previous experiments we took the number of generated nodes as a basic resource
unit. We must be careful, however, since this measurement does not take into account the
overhead in our method. To ensure that the overhead does not outweigh the beneﬁts, we
conducted a realtime evaluation of the system architecture performing focused crawling on
the online Web and measured the resources consumed in the time that elapsed.7 . Figures
7. The experiment was performed using a Pentium-4 2.53 GHz computer with 1GB of main memory and
a cable modem.

439

100

100

90

90

80

80

70

70
% Goals found

% Goals found

Davidov & Markovitch

60
50
40
30

60
50
40
30

No enchancements
Combined approach
Overlap minimization
Siblings clustering
All enchancements

20
10

No enchancements
Combined approach
Overlap minimization
Siblings clustering
All enchancements

20
10

0

0
0

5

10

15

20

25

30

35

40

0

5

10

% Nodes generated

15

20

25

30

35

40

% Nodes generated

(a)

(b)

100

100

90

90

80

80

70

70
% Goals found

% Goals found

Figure 15: The performance of best-ﬁrst search (using marginal-utility inference) with all
the enhancements enabled compared to the performance of the algorithm with
a single option enabled: (a)Robotics pages (b) Mathematics pages. Each ﬁgure
contains 5 plots: One for the marginal utility inference method with no enhancements, one for the same method enhanced by the combined approach, one for
enhancement by overlap estimation, one for enhancement by sibling clustering
and, ﬁnally, one for all the enhancements together.

60
50
40
30

60
50
40
30

20

20
Distance-estimation heuristics
Marginal-utility inference
Feature-based marginal-utility induction

10

Distance-estimation heuristics
Marginal-utility inference
Feature-based marginal-utility induction

10

0

0
0

10

20

30

40

50

60

70

80

90

0

10

20

30

40

50

Time (hours)

Time (hours)

(a)

(b)

60

70

80

90

Figure 16: The performance of the marginal-utility based methods as a function of real
time: (a)Robotics pages (b)Mathematics pages

16(a),(b) show the performance of our methods with all the enhancements enabled as a
function of real time. A comparison of these graphs to the graphs shown in Figure 14
reveals that the overhead of our methods does not noticeably aﬀect their performance. To
see if the overhead increases with the size of the visited graph, we plotted in Figure 17
the real time as a function of the number of generated nodes. The graphs show that the
majority of the time required for focused crawling tasks is indeed the loading time itself,

440

Multiple-Goal Heuristic Search

90
Pure loading time
Distance-estimation heuristics
Marginal-utility inference
Feature-based induction

80
70
Time (hours)

60
50
40
30
20
10
0
0

5

10

15
20
25
% Nodes generated

30

35

40

Figure 17: The average real time used by the marginal-utility methods as a function of the
number of generated nodes in the focused crawling domain

even when all calculations related to the discussed options are enabled. In fact, using
distance-estimation increases the computation time by a factor of no more than 1.07; using
similarity-based inference of marginal utility, by no more than 1.1; and using feature-based
induction, by no more than 1.17. Thus, if our improvement is greater than these factors,
our algorithms will beneﬁt focused crawling systems.
6.7 Contract Algorithms Versus Interruptible Anytime Algorithms
The experiments described so far test the performance of our methods as interruptible
anytime algorithms. Each point of the graph can also be considered as a test result for
a contract algorithm using the speciﬁc resource allocation. However, if a multiple-goal
search algorithm is called in contract mode, we can utilize the additional input (of resource
allocation) to improve the performance of our algorithm, as described in Section 5.1.2.
To test the eﬀect of exploiting the resource allocation, we repeated the experiment
described in Section 6.4.1 using the algorithm of Section 5.1.2. We found out that when
using the algorithm in contract mode, we obtained an average improvement factor of 7.6
(factor of 2.8 if dropping two extremes) for 5% resource allocation and 1.4 for 10% resource
allocation. The full results are available in the Appendix.
Our algorithms also allow a “contract by quality” mode where the input is the required
quality instead of the allocated resources. In our case the quality is speciﬁed by the percentage of goals found. The contract algorithm achieved an average improvement factor of
1.9 for 5% of the goals and 1.4 for 20% of the goals. The full results are available in the
Appendix.
6.8 The Performance of Other Multiple-Goal Search Algorithms
In previous subsections we test our heuristic methods on best-ﬁrst search. To show the
generality of our approach, we test whether marginal-utility heuristics can be used eﬃciently
for dynamic ordering of variables in backtracking, and for choosing a node from the focal
441

Davidov & Markovitch

group in the multiple-goal A∗ algorithm. In both cases we used the sibling clustering
method.
For backtracking we used the multiple-goal version of two known problems: open knight
tour and n-queens. We applied our marginal-utility inference algorithm which based on
similarity of siblings to sort variable values in the multiple-goal version of backtracking
search. For the open knight tour problem we used a 6 × 6 board (this board contains
524, 486 goal conﬁgurations, and this is the maximal size where we can collect all the goals
eﬃciently). For the n-queens problem we used a 16 × 16 board containing 14, 772, 512 goals.
In neither case did we use a domain-speciﬁc technique to increase search eﬃciency. Figure
100

100
90

80

80
% Goals found

% Goals found

70
60

40

60
50
40
30

20

20
10

Simple backtracking
Backtracking with marginal utility
0

Simple backtracking
Backtracking with marginal utility

0
0

10

20

30

40

50

60

70

80

90

100

0

% Nodes generated

10

20

30

40

50

60

70

80

90

100

% Nodes generated

(a)

(b)

Figure 18: Applying marginal-utility inference to backtracking search (a)Open knight tour
(b) N-queens task

18(a),(b) compares the performance of multiple-goal backtracking search with and without
marginal utility. We can see that applying marginal-utility inference signiﬁcantly increases
the performance for both problems.
We also tested the multiple-goal A∗ algorithm, described in Section 3, where the siblingbased marginal-utility heuristic selects a node from the focal group. The experiment was
performed on the known multiple-sequence alignment problem. Since the graph degree
is very large, we applied a modiﬁed version of A∗ described by Yoshizumi, Miura and
Ishida (2000). We used the same heuristic, methodology and data set described in this
paper, requiring the algorithm to collect all optimal and 1.1-suboptimal solutions.
Figure 19 shows the results obtained for two data sets. We can see that marginal utility
improves the performance of the search algorithm.

7. Related Work
The multiple-goal search framework deﬁned in this paper is novel. No previous work has
treated heuristic search for multiple goals as a general search framework and no previous
work provided general algorithms for multiple-goal search. The planning community has
dealt with multiple goals only in an entirely diﬀerent setup, where the goals are conjunctive

442

Multiple-Goal Heuristic Search

100

100

A*ε using regular heuristic
A*ε with marginal-utility inference

80
% Goals found

% Goals found

80

A*ε using regular heuristic
A*ε with marginal-utility inference

60

40

20

60

40

20

0

0
0

10

20

30

40

50

60

70

80

90

100

0

% Nodes generated

10

20

30

40

50

60

70

80

90

100

% Nodes generated

(a)

(b)

Figure 19: Applying marginal-utility inference to A∗ search (a)Data set 1 (b) Data set 2
and possibly conﬂicting. In particular, that setup is not easily applicable to generic graph
search.
Even domain-speciﬁc algorithms for multiple-goal heuristic search are not very common.
Of the domains mentioned in Section 6.2, the only one that given any attention as a multiplegoal problem domain was Web crawling. The sequence alignment domain was used in several
works on heuristic search (for example, Korf & Felner, 2002; Zhou & Hansen, 2002, 2003;
Schroedl, 2005), but only as a single-goal search problem.
The popularity of the Web has led many researchers to explore the problem of multiplegoal search in the Web graph. This problem is better known as focused crawling. Chakrabarti
et al. (1999) deﬁned a focused crawler as “a Web agent which selectively seeks out pages
that are relevant to a pre-deﬁned set of topics by retrieving links from the live Web.” Such
agents can be used for building domain-speciﬁc Web indices (see for example McCallum,
Nigam, Rennie, & Seymore, 1999). Focused Web-crawling algorithms use various methods
such as breadth-ﬁrst search (Najork & Wiener, 2001), best-ﬁrst search (Cho & GarciaMolina, 2000; Cho et al., 1998), and reinforcement learning (Boyan, Freitag, & Joachims,
1996; Rennie & McCallum, 1999). Most of the heuristic methods for focused crawling are
based on Web-speciﬁc features. For example, the page-rank model (Page, Brin, Motwani,
& Winograd, 1998) was used by Brin and Page (1998), and by Haveliwala (1999). The
hubs-and-authorities model (Kleinberg, 1999) was used by Borodin, Roberts, Rosenthal,
and Tsaparas (2001). In addition, several theoretical works provide analysis and bounds
for the problem of Web crawling (for example Cooper & Frieze, 2002; Kumar et al., 2000).
The approach most similar to ours is that taken by by Rennie and McCallum (Rennie &
McCallum, 1999), who apply reinforcement learning to Web crawling. Like our marginalutility induction method, their method also estimates a reward value and generalizes it over
unvisited nodes. There are, however, several important diﬀerences between the two methods, particulary in the deﬁnition of reward. While our approach is based on the maximal
number of goals achieved for the given resources, their method is focused on immediacy
of goal achievement. The sooner a goal can be achieved by an optimal algorithm starting
from a graph node, the more it contributes to the reward value of this node regardless of
whether the algorithm has enough resources to collect this goal. Thus, their setup does not
443

Davidov & Markovitch

allow a direct incorporation of supplied resource limit input. Furthermore, their approach
relies on relatively heavy oﬀ-line processing on a training set. We propose an online update
method to estimate and update the marginal-utility based system. Our approach not only
eliminates the need for fetching the ﬁxed training set, but also gives more ﬂexibility to the
algorithm.

8. Discussion
The work described in this paper presents a new framework for heuristic search. In this
framework the task is to collect as many goals as possible within the allocated resources.
We show that the traditional distance-estimation heuristic is not suﬃciently eﬀective for
multiple-goal search. We then introduce the sum and progress heuristics, which take advantage of an explicitly given goal set to estimate the direction to larger and closer groups
of goals.
One problem with the above heuristics is that they ignore the expected resources required
to collect goals in the alternative directions. We introduce the marginal-utility heuristic,
which attempts to estimate the cost per goal of each search direction. Thus, using it should
lead to a more productive search.
Designing an eﬀective marginal-utility heuristic is a rather diﬃcult task. We therefore
developed two methods for online learning of marginal-utility heuristics. One is based on
local similarity of the partial marginal-utility of sibling nodes, and the other generalizes
marginal-utility over the state feature space. Both methods infer marginal utility from the
partial marginal-utility values which are based on the number of visited goal and non-goal
nodes in partially explored subgraphs.
The sibling-based inference method requires only the basic input of a search problem:
a set of starting nodes, a successor function, and a goal predicate. The method can also
take advantage of an input resource allocation, as was demonstrated in Section 6.7. If a
distance-estimation heuristic is given, the sibling-based method can utilize it for the initial
stages of the search where the data on which to base the inference is not suﬃcient. The
marginal-utility generalization method requires a set of meaningful features over the set of
states. This is a common requirement for learning systems.
We applied our methodology to several tasks, including focused Web crawling, and
showed its merit under various conditions. We also applied it to the tasks of ﬁnding paths
to multiple goals, planning movement of multiple robots, knight-tour, n-queens, and ﬁnding
a set of multiple sequence alignments. The experiments show that even without any prior
knowledge about the goal type, and given only the goal predicate, our algorithm, after an
initiation period, signiﬁcantly outperforms both blind and best-ﬁrst search using a distanceestimation heuristic. When we enhance our method with a regular distance-estimation
heuristic, our method shows more than threefold improvement over the same distanceestimation heuristic alone.
Our framework and proposed algorithms are applicable to a wide variety of problems
where we are interested in ﬁnding many goal states rather than only one. We show, for
example, for the multiple sequence alignment problem, that our methods allow A∗ to reach
many more nearly-optimal conﬁgurations. The same methods can be also applied to con-

444

Multiple-Goal Heuristic Search

straint satisfaction problems where it may be useful to ﬁnd many solutions and apply
another algorithm for selecting a solution from the found set.
To apply our framework to new problems, the following requirements must be fulﬁlled:
1. The problem domain should be formulated as a state space.
2. There exists predicate that identiﬁes goal states.
3. For using the sum and progress heuristics:
(a) A traditional function that estimates the distance between two states should be
given.
(b) The set of goals states should be given explicitly.
4. For the sibling-based method of marginal utility inference we assume that the marginal
utility values of sibling nodes are relatively similar.
5. For the induction-based marginal utility inference we assume the availability of a set
of state features that are informative with respect to marginal utility.
The main message of this research is that the induction-based method for marginal
utility inference should be used when possible. Unlike the sum and the progress heuristics,
it takes into account the resources needed for collecting the goals. Unlike the siblingbased inference method, it makes no assumptions about similarity of marginal utility values
between siblings. It does require informative state features; however, for many domains, a
reach set of state features – suﬃcient for inducing the marginal utility estimation function
– is available.
Our marginal-utility based heuristic techniques are greedy in the sense that they always
choose the node leading to a subgraph where we would expect to ﬁnd the maximal number
of goals, were we to use all the remaining resources for that subgraph. A more sophisticated approach would try to wisely distribute the remaining resources between promising
directions, leading, we hope, to better performance than the greedy approach.
Although the marginal utility approach does not consider possible overlap between subgraphs, we propose, in Section 4.5, a technique to reduce it. A more interesting direction
could be to predict the actual overlap as the search progresses, using the same methods as
in the partial marginal-utility calculation.
The framework described in this paper opens a new research direction. The ﬁeld is wide
open for the development of new algorithms and for the application of multiple-goal search
algorithms to other tasks.

Acknowledgements
We would like to thank Adam Darlo, Irena Koifman and Yaron Goren, who helped us in
programming. This research was supported by the fund for the promotion of research at
the Technion and by the Israeli Ministry of Science.

445

Davidov & Markovitch

Appendix A. Detailed Results
In this appendix we provide a breakdown of the results for the 10 Web topics. Tables 2 and
3 refer to the results described in Section 6.4.1. Table 4 refers to the results described in
Section 6.4.2. Table 5 refers to the results described in Section 6.5. Tables 6 and 7 refers
to the results described in Section 6.7.
Goal type

Robotics
Students
Mathematics
Football
Sports
Laboratories
Food
Publications
Projects
News

% of goals found at 10% resources
BFS
Distance
Marginal
estimation
utility
2.6(0.9)
7.2(0.2)
18.1(0.6)
10.5(1.0)
11.8(0.5)
17.0(1.3)
7.2(0.1)
17.6(1.6)
15.4(0.8)
0.0(0.0)
31.4(0.5)
25.3(0.9)
3.6(0.4)
37.0(1.1)
45.1(2.7)
0.3(0.1)
12.5(0.7)
33.4(0.8)
7.2(1.2)
25.1(0.9)
30.3(1.7)
0.3(0.1)
12.6(1.0)
35.2(2.6)
0.1(0.0)
30.1(1.4)
41.2(1.6)
8.5(0.9)
23.1(0.8)
22.6(0.8)

% of goals found at 20% resources
BFS
Distance
Marginal
estimation
utility
9.3(1.6)
30.5(1.1)
58.3(2.0)
12.5(1.5)
23.7(0.6)
54.6(1.3)
13.1(1.2)
28.3(0.8)
60.3(2.9)
0.8(0.0)
42.1(1.7)
71.5(0.7)
16.2(0.7)
41.6(0.7)
68.5(1.4)
5.3(0.5)
18.1(0.8)
80.4(3.1)
26.5(3.9)
48.5(1.7)
92.7(2.2)
3.5(0.1)
18.5(1.1)
64.2(1.9)
0.8(0.2)
32.0(1.4)
80.5(2.0)
15.3(1.0)
40.4(1.2)
88.9(0.7)

Table 2: Marginal-utility and distance-estimation heuristics in focused crawling (with D=4). The
numbers in parentheses are standard deviations.

Goal type

Robotics
Students
Mathematics
Football
Sports
Laboratories
Food
Publications
Projects
News

% of goals found at 10% resources
Distance
Marginal Combined
estimation
utility
method
7.2(0.2)
18.1(0.6)
21.1(0.5)
11.8(0.5)
17.0(1.8)
23.3(0.6)
17.6(1.6)
15.4(0.8)
26.5(1.9)
31.4(0.5)
25.3(0.9)
33.9(1.0)
37.0(1.1)
45.1(2.7)
48.3(2.2)
12.5(0.7)
33.4(0.7)
40.2(0.9)
25.1(0.9)
30.3(1.7)
30.1(1.2)
12.6(1.0)
35.2(2.7)
42.0(2.4)
30.1(1.4)
41.2(1.6)
41.3(1.0)
23.1(0.8)
22.6(0.8)
30.5(1.9)

% of goals found at 20% resources
Distance
Marginal Combined
estimation
utility
method
30.5(1.1)
58.3(2.0)
65.1(2.1)
23.7(0.6)
54.6(1.3)
59.6(1.2)
28.3(0.8)
60.3(2.9)
68.7(2.5)
42.1(1.7)
71.5(0.7)
70.9(1.1)
41.6(0.7)
68.5(1.4)
75.0(1.3)
18.1(0.8)
80.4(3.1)
79.8(1.0)
48.5(1.7)
92.7(2.2)
93.3(1.6)
18.5(1.1)
64.2(1.9)
77.8(1.7)
32.0(1.4)
80.5(2.0)
84.7(1.8)
40.4(1.2)
88.9(0.7)
90.5(0.9)

Table 3: Combining marginal-utility with distance-estimation heuristics for focused crawling. The
numbers in parentheses are standard deviations.

446

Multiple-Goal Heuristic Search

Goal type

Robotics
Students
Mathematics
Football
Sports
Laboratories
Food
Publications
Projects
News

% of goals found at 10% resources
Distance
Inference
Inference
estim.
by siblings by induction
7.2(0.2)
18.1(0.7)
8.4(1.2)
11.8(0.6)
17.0(1.9)
12.4(1.1)
17.6(1.6)
15.4(0.9)
10.8(1.5)
31.4(0.5)
25.3(0.4)
21.1(0.7)
37.0(1.2)
45.1(2.7)
36.2(1.6)
12.5(0.7)
33.4(0.8)
19.4(1.3)
25.1(0.9)
30.3(1.7)
27.1(0.6)
12.6(1.0)
35.2(2.7)
21.8(2.4)
30.1(1.4)
41.2(1.8)
35.5(1.2)
23.1(0.8)
22.6(0.8)
23.2(0.9)

% of goals found at 20% resources
Distance
Inference
Inference
estim.
by siblings by induction
30.5(1.1)
58.3(2.0)
75.5(2.5)
23.7(0.6)
54.6(1.3)
68.2(1.6)
28.3(0.8)
60.3(2.9)
69.7(2.5)
42.1(1.7)
71.5(0.7)
71.6(1.1)
41.6(0.7)
68.5(1.4)
79.4(1.5)
18.1(0.8)
80.4(3.1)
86.0(1.3)
48.5(1.7)
92.7(2.2)
89.1(1.8)
18.5(1.1)
64.2(1.9)
78.9(1.2)
32.0(1.4)
80.5(2.0)
89.8(2.5)
40.4(1.2)
88.9(0.7)
93.9(1.1)

Table 4: The performance of the two methods of marginal-utility estimation for the focused crawling
task. The numbers in parentheses are standard deviations.

Goal type

Robotics
Students
Mathematics
Football
Sports
Laboratories
Food
Publications
Projects
News
Robotics
Students
Mathematics
Football
Sports
Laboratories
Food
Publications
Projects
News

% of goals found at 10% resources
Distance-estimation Inference by siblings Inference by induction
Without
With
Without
With
enhanc.
enhanc.
enhanc.
enhanc.
7.2(0.2)
18.1(0.7)
33.4(2.1)
8.4(1.2)
22.1(2.2)
11.8(0.5)
17.0(1.8)
26.5(1.0)
12.4(1.1)
25.2(1.6)
17.6(1.6)
15.4(0.8)
35.2(1.4)
10.8(1.4)
36.8(1.5)
31.4(0.6)
25.3(0.9)
46.9(1.4)
21.1(0.7)
39.5(1.4)
37.0(1.2)
45.1(2.7)
54.9(1.6)
36.2(1.6)
46.8(1.5)
12.5(0.7)
33.4(0.8)
46.4(1.6)
19.4(1.3)
39.5(1.4)
25.1(0.9)
30.3(1.7)
35.1(1.4)
27.1(0.6)
30.4(1.4)
12.6(1.1)
35.2(2.6)
46.8(1.5)
21.8(2.4)
30.0(1.4)
30.1(1.4)
41.2(1.6)
49.2(1.2)
35.5(1.2)
44.6(1.3)
23.1(0.8)
22.6(0.8)
41.1(1.6)
23.2(0.9)
42.3(1.1)
% of goals found at 20% resources
30.5(1.2)
58.3(2.0)
83.2(1.8)
75.5(2.6)
89.1(1.5)
23.7(0.6)
54.6(1.3)
65.4(1.7)
68.2(1.6)
78.3(1.6)
28.3(0.8)
60.3(2.9)
88.6(1.0)
69.7(2.5)
92.0(1.1)
42.1(1.7)
71.5(0.8)
80.6(1.4)
71.6(1.1)
91.3(1.4)
41.6(0.7)
68.5(1.4)
78.5(1.6)
79.4(1.6)
86.4(1.5)
18.1(0.8)
80.4(3.1)
86.4(2.0)
86.0(1.3)
92.1(1.4)
48.5(1.7)
92.7(2.2)
95.1(1.6)
89.1(1.8)
95.0(1.7)
18.5(1.1)
64.2(1.9)
87.2(2.1)
78.9(1.2)
94.7(1.4)
32.0(1.4)
80.5(2.1)
85.4(1.7)
89.8(2.5)
95.2(1.7)
40.4(1.3)
88.9(0.8)
93.8(1.2)
93.9(1.1)
96.5(1.5)

Table 5: The performance of the two marginal-utility based methods with all the enhancements
enabled. The numbers in parentheses are standard deviations.

447

Davidov & Markovitch

Goal type

Robotics
Students
Mathematics
Football
Sports
Laboratories
Food
Publications
Projects
News

% of goals found
Contract:
10% Resources
Anytime Contract
18.1(0.7) 24.6(1.1)
17.0(1.9) 29.3(1.5)
15.4(0.8) 24.1(0.9)
25.3(0.9) 29.9(1.0)
45.1(2.7) 60.4(1.1)
33.4(0.7) 40.7(0.9)
30.3(1.7) 32.1(1.6)
35.2(2.6) 55.0(2.3)
41.2(1.6) 48.6(0.9)
22.6(0.8) 41.5(1.0)

Contract:
5% Resources
Anytime Contract
0.1(0.0)
2.9(0.2)
0.7(0.0)
1.9(0.1)
1.8(0.3)
8.4(0.8)
4.2(0.2)
12.1(0.5)
12.7(0.6) 20.4(1.1)
10.5(1.0) 11.3(0.6)
9.4(0.9)
22.1(1.2)
2.1(0.3)
12.9(1.7)
0.9(0.0)
21.5(1.6)
8.8(1.0)
13.2(0.9)

Contract:
20% Resources
Anytime Contract
58.3(2.0) 69.5(2.2)
54.6(1.3) 62.8(1.3)
55.3(0.9) 64.0(1.1)
71.5(0.8) 75.6(0.8)
68.5(1.4) 77.7(1.3)
80.4(3.1) 81.6(0.1)
92.7(2.2) 92.8(2.2)
64.2(1.9) 76.2(1.5)
80.5(2.1) 86.5(1.6)
88.9(0.7) 91.1(1.0)

Table 6: Contract vs. anytime performance when supplying a resource limit. The numbers in
parentheses are standard deviations.

Goal type

Robotics
Students
Mathematics
Football
Sports
Laboratories
Food
Publications
Projects
News

Contract: 5% Goals
Anytime Contract
8.4(0.6)
6.2(1.1)
9.0(0.5)
7.1(0.4)
5.4(0.4)
3.9(0.2)
5.2(0.2)
2.1(0.2)
3.9(0.2)
1.9(0.1)
4.2(0.1)
1.8(0.1)
5.9(0.3)
2.2(0.3)
6.1(0.5)
3.3(0.4)
4.0(0.3)
1.7(0.1)
7.6(0.7)
5.9(0.4)

% of resources consumed
Contract: 20% Goals
Anytime Contract
12.1(0.7)
9.8(0.5)
11.3(0.5)
8.4(0.3)
10.3(0.5)
6.8(0.4)
8.4(0.3)
5.2(0.2)
7.1(0.6)
6.0(0.4)
7.4(0.4)
5.3(0.3)
8.8(0.5)
5.1(0.2)
7.7(1.1)
5.9(0.5)
8.3(0.5)
6.1(0.3)
9.8(0.2)
6.5(0.3)

Contract: 50% Goals
Anytime Contract
17.2(1.2)
10.2(1.0)
18.7(0.6)
9.9(0.5)
14.3(0.6)
9.9(0.4)
14.6(0.5)
9.9(0.7)
12.2(0.6)
6.5(0.6)
14.1(0.6)
6.6(0.2)
14.3(0.5)
7.0(0.6)
18.8(0.7)
10.3(0.6)
16.5(0.6)
9.0(0.5)
16.0(0.4)
10.3(0.6)

Table 7: Contract vs. anytime performance when supplying goal requirements. The numbers in
parentheses are standard deviations.

448

Multiple-Goal Heuristic Search

References
Boddy, M., & Dean, T. L. (1994). Deliberation scheduling for problem solving in time
constrained environments. Artiﬁcial Intelligence, 67 (2), 245–285.
Borodin, A., Roberts, G. O., Rosenthal, J. S., & Tsaparas, P. (2001). Finding authorities and
hubs from link structures on the www. In The 10th International WWW conference,
pp. 415–429. ACM Press.
Boyan, J., Freitag, D., & Joachims, T. (1996). A machine learning architecture for optimizing web search engines. In Proceedings of the AAAI Workshop on Internet-Based
Information Systems, pp. 324–335.
Breiman, L., Friedman, J. H., Olshen, R. A., & Stone, P. J. (1984). Classiﬁcation and
Regression Trees. Wadsworth International, Monterey, CA.
Brin, S., & Page, L. (1998). The anatomy of a large-scale hypertextual Web search engine.
Computer Networks and ISDN Systems, 30 (1–7), 107–117.
Chakrabarti, S., van den Berg, M., & Dom, B. (1999). Focused crawling: a new approach
to topic-speciﬁc Web resource discovery. Computer Networks, 31 (11–16), 1623–1640.
Cho, J., & Garcia-Molina, H. (2000). The evolution of the Web and implications for an
incremental crawler. In El Abbadi, A., Brodie, M. L., Chakravarthy, S., Dayal, U.,
Kamel, N., Schlageter, G., & Whang, K.-Y. (Eds.), VLDB 2000, pp. 200–209, Los
Altos, CA 94022, USA. Morgan Kaufmann Publishers.
Cho, J., Garcı́a-Molina, H., & Page, L. (1998). Eﬃcient crawling through URL ordering.
Computer Networks and ISDN Systems, 30 (1–7), 161–172.
Cooper, C., & Frieze, A. (2002). Crawling on web graphs. In Proceedings of STOC, pp.
419–427.
Cover, T. M., & Hart, P. E. (1967). Nearest neighbor pattern classiﬁcation. IEEE Transactions on Information Theory, 13, 21–27.
Culberson, J. C., & Schaeﬀer, J. (1998). Pattern databases. Computational Intelligence,
14 (4), 318–334.
Diligenti, M., Coetzee, F., Lawrence, S., Giles, C. L., & Gori, M. (2000). Focused crawling
using context graphs. In 26th International Conference on Very Large Databases,
VLDB 2000, pp. 527–534, Cairo, Egypt.
Douglis, F., Feldmann, A., Krishnamurthy, B., & Mogul, J. C. (1997). Rate of change
and other metrics: a live study of the www. In USENIX Symposium on Internet
Technologies and Systems, pp. 147–158.
Gasser, R. U. (1995). Harnessing Computational Resources for Eﬃcient Exhaustive Search.
Ph.D. thesis, ETH, Swiss Federal Institute of Technology, Zurich, Switzerland.
Hansen, E. A., & Zilberstein, S. (1996). Monitoring the progress of anytime problem-solving.
In Proceedings of the Thirteenth National Conference on Artiﬁcial Intelligence (AAAI96), pp. 1229–1234, Portland, Oregon, USA. AAAI Press / The MIT Press.
Haveliwala, T. (1999). Eﬃcient computation of PageRank. Tech. rep. 1999-31.

449

Davidov & Markovitch

Held, M., & Karp, R. M. (1970). The traveling salesman problem and minimum spanning
trees. Operations Research, 18, 1138–1162.
Hirai, J., Raghavan, S., Garcia-Molina, H., & Paepcke, A. (2000). Webbase: A repository of
web pages. In Proceedings of the 9th International WWW Conference, pp. 277–293.
Hovitz, E. (1990). Computation and Action under Bounded Resources. Ph.D. thesis, Stanford University.
Joachims, T. (1997). A probabilistic analysis of the Rocchio algorithm with TFIDF for
text categorization. In Proc. 14th International Conference on Machine Learning, pp.
143–151. Morgan Kaufmann.
Kleinberg, J. M. (1999). Authoritative sources in a hyperlinked environment. Journal of
the ACM, 46 (5), 604–632.
Korf, R. E., & Zhang, W. (2000). Divide-and-conquer frontier search applied to optimal
sequence allignment. In National Conference on Artiﬁcial Intelligence (AAAI), pp.
910–916.
Korf, R. E., & Felner, A. (2002). Disjoint pattern database heuristics. Artiﬁcial Intelligence,
134 (1–2), 9–22.
Kumar, R., Raghavan, P., Rajagopalan, S., Sivakumar, D., Tomkins, A., & Upfal, E. (2000).
The Web as a graph. In Proc. 19th Symp. Principles of Database Systems, PODS,
pp. 1–10. ACM Press.
Lawrence, S., & Giles, C. L. (1998). Searching the WWW. Science, 280 (5360), 98–100.
McCallum, A., Nigam, K., Rennie, J., & Seymore, K. (1999). Building domain-speciﬁc
search engines with machine learning techniques. In Proc. AAAI-99 Spring Symposium
on Intelligent Agents in Cyberspace, pp. 28–39.
Menczer, F., Pant, G., Srinivasan, P., & Ruiz, M. (2001). Evaluating topic-driven web
crawlers. In Proceedings of SIGIR-01), pp. 241–249, New York. ACM Press.
Montgomery, D. C. (2001). Design and Analysis of Experiments (5 edition). John Wiley
and Sons.
Mostow, J., & Prieditis, A. E. (1989). Discovering admissible heuristics by abstracting
and optimizing: a transformational approach. In Proceedings of IJCAI-89, Vol. 1, pp.
701–707.
Najork, M., & Wiener, J. L. (1998). A technique for measuring the relative size and overlap
of public web search engines. In Proceedings of the Seventh International WWW
Conference[WWW7], pp. 379–388.
Najork, M., & Wiener, J. L. (2001). Breadth-ﬁrst crawling yields high-quality pages. In
Proceedings of the 10th International WWW Conference, pp. 114–118.
Page, L., Brin, S., Motwani, R., & Winograd, T. (1998). The pagerank citation ranking:
Bringing order to the web. Tech. rep., Stanford Digital Library Technologies Project.
Pandurangan, G., Raghavan, P., & Upfal, E. (2002). Using PageRank to Characterize Web
Structure. In 8th Annual International Computing and Combinatorics Conference
(COCOON), pp. 330–339.
450

Multiple-Goal Heuristic Search

Pearl, J., & Kim, J. H. (1982). Studies in semi-admissible heuristics. IEEE Transactions
on Pattern Analysis and Machine Intelligence, 4 (4), 392–399.
Prieditis, A. E. (1993). Machine discovery of eﬀective admissible heuristics.. 12 (1–3),
117–141.
Rennie, J., & McCallum, A. K. (1999). Using reinforcement learning to spider the Web
eﬃciently. In Bratko, I., & Dzeroski, S. (Eds.), Proceedings of ICML-99, 16th International Conference on Machine Learning, pp. 335–343, Bled, SL. Morgan Kaufmann
Publishers, San Francisco, US.
Russell, S. J., & Zilberstein, S. (1991). Composing real-time systems. In Proceedings of
IJCAI-91, pp. 213–217, Sydney. Morgan Kaufmann.
Russell, S., & Norvig, P. (2003). Artiﬁcial Intelligence: A Modern Approach (2nd edition
edition). Prentice-Hall, Englewood Cliﬀs, NJ.
Salton, G., & Buckley, C. (1988). Term weighting approaches in automatic text retrieval.
Information Processing and Management, 24 (5), 513–523.
Schroedl, S. (2005). An improved search algorithm for optimal multiple-sequence alignment.
Journal of Artiﬁcial Intelligence Research, 23, 587–623.
Utgoﬀ, P. (1988). An incremental ID3. In Fifth International Conference on Machine
Learning, pp. 107–120. Morgan Kaufmann.
Yoshizumi, T., Miura, T., & Ishida, T. (2000). A * with partial expansion for large branching
factor problems. In AAAI/IAAI, pp. 923–929.
Zhou, R., & Hansen, E. A. (2002). Multiple sequence alignment using anytime a*. In
Proceedings of the Eighteenth National Conference on Artiﬁcial Intelligence, pp. 975–
976, Edmonton, Alberta, Canada.
Zhou, R., & Hansen, E. A. (2003). Sweep a*: Space-eﬃcient heuristic search in partially
ordered graphs. In Proceedings of the 15th IEEE International Conference on Tools
with Artiﬁcial Intelligence, pp. 427–434, Sacramento, CA.
Zilberstein, S. (1996). Using anytime algorithms in intelligent systems. AI Magazine, 17 (3),
73–83.
Zilberstein, S., Charpillet, F., & Chassaing, P. (1999). Real-time problem-solving with
contract algorithms. In IJCAI, pp. 1008–1015.

451

Journal of Artificial Intelligence Research 26 (2006) 371-416

Submitted 11/05; published 8/06

Clause/Term Resolution and Learning in the Evaluation of
Quantified Boolean Formulas
Enrico Giunchiglia
Massimo Narizzano
Armando Tacchella

giunchiglia@unige.it
mox@dist.unige.it
tac@dist.unige.it

DIST - Università di Genova
Viale Causa 13, 16145 Genova, Italy

Abstract
Resolution is the rule of inference at the basis of most procedures for automated reasoning. In these procedures, the input formula is first translated into an equisatisfiable
formula in conjunctive normal form (CNF) and then represented as a set of clauses. Deduction starts by inferring new clauses by resolution, and goes on until the empty clause is
generated or satisfiability of the set of clauses is proven, e.g., because no new clauses can
be generated.
In this paper, we restrict our attention to the problem of evaluating Quantified Boolean
Formulas (QBFs). In this setting, the above outlined deduction process is known to be
sound and complete if given a formula in CNF and if a form of resolution, called “Qresolution”, is used. We introduce Q-resolution on terms, to be used for formulas in disjunctive normal form. We show that the computation performed by most of the available
procedures for QBFs –based on the Davis-Logemann-Loveland procedure (DLL) for propositional satisfiability– corresponds to a tree in which Q-resolution on terms and clauses
alternate. This poses the theoretical bases for the introduction of learning, corresponding
to recording Q-resolution formulas associated with the nodes of the tree. We discuss the
problems related to the introduction of learning in DLL based procedures, and present
solutions extending state-of-the-art proposals coming from the literature on propositional
satisfiability. Finally, we show that our DLL based solver extended with learning, performs
significantly better on benchmarks used in the 2003 QBF solvers comparative evaluation.

1. Introduction
Resolution (Robinson, 1965) is the rule of inference at the basis of most procedures for
automated reasoning (see, e.g., Fermüller, Leitsch, Hustadt, & Tammet, 2001; Bachmair &
Ganzinger, 2001). In these procedures, the input formula is first translated into an equisatisfiable formula in conjunctive normal form (CNF) and then represented as a set of clauses.
Deduction starts by inferring new clauses by resolution, and goes on until the empty clause is
generated or satisfiability of the set of clauses is proven, e.g., because no new clauses can be
generated. Here we restrict our attention to the problem of evaluating Quantified Boolean
Formulas (QBFs). In this setting, the above outlined deduction process is known to be sound
and complete if given a formula in CNF and if a form of resolution, called “Q-resolution”,
is used (Kleine-Büning, Karpinski, & Flögel, 1995). However, most of the available decision
procedures for QBFs are based on and extend the Davis-Logemann-Loveland procedure
(DLL) (Davis, Logemann, & Loveland, 1962) for propositional satisfiability (SAT). In the
c
2006
AI Access Foundation. All rights reserved.

Giunchiglia, Narizzano & Tacchella

propositional case, it is well known that the computation performed by DLL corresponds
to a specific form of resolution called “regular tree resolution” (see, e.g., Urquhart, 1995).
In this paper we introduce Q-resolution on terms, to be used for formulas in disjunctive
normal form. We show that the computation performed by DLL based decision procedures
for QBFs corresponds to a tree in which Q-resolution on terms and clauses alternate. Such
correspondence poses the theoretical bases for the introduction of learning, corresponding
to recording Q-resolution formulas associated with the nodes of the tree. In particular,
recording Q-resolutions on clauses generalizes the popular “nogood” learning from constraint satisfaction and SAT literatures (see, e.g., Dechter, 1990; Bayardo, Jr. & Schrag,
1997): Each nogood corresponds to a set of assignments falsifying the input formula, and
it is useful for pruning assignments to the existential variables. Recording Q-resolutions on
terms corresponds to “good” learning: Each good corresponds to a set of assignments satisfying the input formula, and it is useful for pruning assignments to the universal variables.
We discuss the problems related to the introduction of learning in DLL based procedures for
QBFs, and present solutions extending state-of-the-art proposals coming from the literature
on SAT. To show the effectiveness of learning for the QBFs evaluation problem, we have
implemented it in QuBE, a state-of-the-art QBF solver. Using QuBE, we have done some
experimental tests on several real-world QBFs, corresponding to planning (Rintanen, 1999;
Castellini, Giunchiglia, & Tacchella, 2003) and circuit verification (Scholl & Becker, 2001;
Abdelwaheb & Basin, 2000) problems, which are our two primary application domains of
interest. The results witness the effectiveness of learning.
The paper is structured as follows. We first review the basics of Quantified Boolean
Logic, at the same time introducing some terminology and notation that will be used
throughout the paper. In Section 3, we introduce clause and term resolution, and their
relation to DLL based decision procedures for QBFs. Then, in Section 4, we introduce both
nogood and good learning, and then we show how they can be effectively integrated in DLL
based decision procedures for QBFs. The implementation and the experimental results are
presented in Section 5. The paper ends with the conclusions and some related work.
This paper builds on and extends in many ways our AAAI paper (Giunchiglia, Narizzano, & Tacchella, 2002). With respect to that paper, here (i) we introduce clause and
term resolution; (ii) we show the correspondence between clause/term Q-resolution and the
computation tree searched by DLL based decision procedures; (iii) on the basis of such
correspondence, we extend the basic backtracking search procedure, first with backjumping
and then with learning, and we prove their soundness and completeness; (iv) we discuss the
implementation in QuBE providing many more details, and (v) we present the results of a
much broader and detailed experimental analysis.
From here on, we simply write “resolution” for “Q-resolution”.

2. Quantified Boolean Logic
Consider a set P of symbols. A variable is an element of P. A literal is a variable or the
negation of a variable. In the following, for any literal l,
• |l| is the variable occurring in l; and
• l is the negation of l if l is a variable, and it is |l| otherwise.
372

Clause/Term Resolution and Learning for Quantified Boolean Formulas

For the sake of simplicity, we consider only formulas in negation normal form (NNF).
Thus, for us, a propositional formula is a combination of literals using the k-ary (k ≥ 0)
connectives ∧ (for conjunctions) and ∨ (for disjunctions). In the following, we use True and
False as abbreviations for the empty conjunction and the empty disjunction respectively.
A QBF is an expression of the form
ϕ = Q1 z1 Q2 z2 . . . Qn zn Φ

(n ≥ 0)

(1)

where
• every Qi (1 ≤ i ≤ n) is a quantifier, either existential ∃ or universal ∀,
• z1 , . . . , zn are distinct variables, and
• Φ is a propositional formula in z1 , . . . , zn .
For example,
∃x1 ∀y∃x2 ((x1 ∨ y ∨ x2 ) ∧ (y ∨ x2 ) ∧ (x2 ∨ ((x1 ∨ y) ∧ (y ∨ x2 ))))

(2)

is a QBF.
In (1), Q1 z1 . . . Qn zn is the prefix and Φ is the matrix. We also say that a literal l is
existential if ∃|l| belongs to the prefix, and it is universal otherwise. Finally, in (1), we
define
• the level of a variable zi , to be 1 + the number of expressions Qj zj Qj+1 zj+1 in the
prefix with j ≥ i and Qj 6= Qj+1 ;
• the level of a literal l, to be the level of |l|.
For example, in (2) x2 is existential and has level 1, y is universal and has level 2, x1 is
existential and has level 3.
The value or semantics of a QBF ϕ can be defined recursively as follows:
1. If the prefix is empty, then ϕ is evaluated according to the truth tables of propositional
logic.
2. If ϕ is ∃xψ, ϕ is true if and only if ϕx is true or ϕx is true.
3. If ϕ is ∀yψ, ϕ is true if and only if both ϕy and ϕy are true.
If ϕ is (1) and l is a literal with |l| = zi , ϕl is the QBF
• whose matrix is obtained from Φ by substituting
– zi with True and z i with False if l = zi , and
– zi with False and z i with True if l = z i .
• whose prefix is Q1 z1 Q2 z2 . . . Qi−1 zi−1 Qi+1 zi+1 . . . Qn zn .
It is easy to see that if ϕ is a QBF without universal quantifiers, the problem of determining
the value of ϕ reduces to the SAT problem.
Two QBFs are equivalent if they are either both true or both false.
373

Giunchiglia, Narizzano & Tacchella

3. Resolution and DLL Based Decision Procedures for QBFs
In this section we first introduce clause/term resolution and DLL based decision procedures
for QBFs, and then we show the correspondence between the two.
3.1 Clause and Term Resolution
According to our definition of QBF, the matrix can be any combination of conjunctions
and disjunctions of literals. However, using common clause form transformations based on
renaming —first used by Tseitin (1970)—, it is possible to perform a linear time conversion
from an arbitrary QBF into an equivalent one with the matrix in conjunctive normal form
(CNF). These conversions are based on the fact that any QBF (1) is equivalent to
Q1 z1 Q2 z2 . . . Qn zn ∃x((x ∨ Ψ) ∧ Φ[x/Ψ])

(n ≥ 0)

where
• Ψ is a propositional formula but not a literal;
• x is a variable distinct from z1 , z2 , . . . , zn ; and
• Φ[x/Ψ] is the propositional formula obtained from Φ substituting one or more occurrences of Ψ with x.
Thus, if Ψ is
((x1 ∨ y) ∧ (y ∨ x2 ))
then it follows that (2) is equivalent to
∃x1 ∀y∃x2 ∃x3 ((x1 ∨ y ∨ x2 ) ∧ (y ∨ x2 ) ∧ (x2 ∨ x3 ) ∧ (x1 ∨ y ∨ x3 ) ∧ (y ∨ x2 ∨ x3 ))

(3)

Thanks to such conversions, we can restrict our attention to QBFs with the matrix
in CNF, and represent the matrix of each formula as a set of clauses to be interpreted
conjunctively, where a clause is a finite set of literals to be interpreted disjunctively. Further,
we assume that each clause is non-tautological and minimal. A clause is tautological if it
contains both a variable and its negation. A clause C is minimal if the literals in C with
minimum level are existential. The minimal form of a clause C is the clause obtained from
C by deleting the universal literals which cause C to be non-minimal. For instance, in
(4), all the clauses are non-tautological and minimal. Our assumption that clauses are
non-tautological and minimal is not a restriction, as the following theorem states.
Theorem 1 Let ϕ be a QBF with the matrix in CNF. Let ϕ0 be the QBF obtained from ϕ
by
1. eliminating tautological clauses; and
2. replacing each non-tautological and non-minimal clause with its minimal form.
ϕ and ϕ0 are equivalent.
374

Clause/Term Resolution and Learning for Quantified Boolean Formulas

Proof. Clearly, tautological clauses can be eliminated from ϕ and the result is an equivalent
QBF. Let C = {l1 , . . . , ln , ln+1 , . . . , lm } be a non-tautological and non-minimal clause in ϕ
in which ln+1 , . . . , lm are the universal literals in C \ min(C) (0 ≤ n < m). Further, without
loss of generality, we assume that the level of li is less than or equal to the level of li+1 ,
1 ≤ i < m. Then, ϕ has the form (p ≥ m)
. . . Q1 |l1 | . . . ∃|ln | . . . ∀|ln+1 | . . . ∀|lm |Qm+1 zm+1 . . . Qp zp {{l1 , . . . , ln , ln+1 , . . . , lm }, . . .},
standing for
. . . Q1 |l1 | . . . ∃|ln | . . . ∀|ln+1 | . . . ∀|lm |Qm+1 zm+1 . . . Qp zp ((l1 ∨ . . . ∨ ln ∨ ln+1 ∨ . . . ∨ lm ) ∧ Φ).
Then, by applying standard rules for quantifiers, ϕ can be rewritten as
. . . Q1 |l1 | . . . ∃|ln | . . . ∀|ln+1 | . . . ∀|lm |((l1 ∨ . . . ∨ ln ∨ ln+1 ∨ . . . ∨ lm ) ∧ Qm+1 zm+1 . . . Qp zp Φ),
equivalent to
. . . Q1 |l1 | . . . ∃|ln | . . . ∀|ln+1 | . . . (∀|lm |(l1 ∨. . .∨ln ∨ln+1 ∨. . .∨lm )∧∀|lm |Qm+1 zm+1 . . . Qp zp Φ),
equivalent to
. . . Q1 |l1 | . . . ∃|ln | . . . ∀|ln+1 | . . . ((l1 ∨ . . . ∨ ln ∨ ln+1 ∨ . . . ∨ lm−1 ) ∧ ∀|lm |Qm+1 zm+1 . . . Qp zp Φ),
equivalent to
. . . Q1 |l1 | . . . ∃|ln | . . . ∀|ln+1 | . . . ∀|lm |Qm+1 zm+1 . . . Qp zp ((l1 ∨ . . . ∨ ln ∨ ln+1 ∨ . . . ∨ lm−1 ) ∧ Φ),
i.e., the QBF obtained from ϕ by deleting lm from the clause C. By iterating the above
reasoning process, all the literals in C \ min(C) can be eliminated from C, and hence the
thesis.

From here on, a QBF is in CNF if and only if the matrix is a conjunction of clauses,
and each clause is both minimal and non-tautological. If we represent the matrix of a QBF
as a set of clauses,
• the empty clause {} stands for False;
• the empty set of clauses {} stands for True;
• the formula {{}} is equivalent to False;
• the QBF (3) is written as
∃x1 ∀y∃x2 ∃x3 {{x1 , y, x2 }, {y, x2 }, {x2 , x3 }, {x1 , y, x3 }, {y, x2 , x3 }}.

(4)

Clause resolution (Kleine-Büning et al., 1995) is similar to an ordinary resolution where
only existential literals can be matched. More precisely, clause resolution (on a literal l) is
the rule
C1
C2
(5)
min(C)
where
375

Giunchiglia, Narizzano & Tacchella

(c1)
(c2)
(c3)
(c4)

{x1 , y, x2 }
{y, x2 }
{x2 , x3 }
{x1 , y, x3 }

Input
Input
Input
Input

formula
formula
formula
formula

(c5)
(c6)
(c7)
(c8)

{x1 }
{x3 , y}
{x1 }
{}

From
From
From
From

(c1),
(c2),
(c4),
(c5),

(c2)
(c3)
(c6)
(c7)

Table 1: A clause resolution deduction showing that (4) is false. The prefix is ∃x1 ∀y∃x2 ∃x3 .

• l is an existential literal;
• C1 , C2 are two clauses such that {l, l} ⊆ (C1 ∪ C2 ), and for no literal l0 6= l, {l0 , l0 } ⊆
(C1 ∪ C2 );
• C is (C1 ∪ C2 ) \ {l, l}.
C1 and C2 are the antecedents, and min(C) is the resolvent of the rule.
Theorem 2 ((Kleine-Büning et al., 1995)) Clause resolution is a sound and complete
proof system for deciding QBFs in CNF: a QBF in CNF is true if and only if the empty
clause is not derivable by clause resolution.
For instance, the fact that (4) is false follows from the deduction in Table 1.
Alternatively to the CNF conversion, we could have converted (2) into a QBF with the
matrix in disjunctive normal form (DNF), again in linear time, on the basis that any QBF
(1), is equivalent to
Q1 z1 Q2 z2 . . . Qn zn ∀y((y ∧ Ψ) ∨ Φ[y/Ψ])

(n ≥ 0),

assuming Ψ is a propositional formula but not a literal, and that y is a variable distinct
from z1 , z2 , . . . , zn .
A simple recursive application of the above equivalence to (2) leads to the following
equivalent QBF:
∃x1 ∀y∃x2 ∀y1 ∀y2 ∀y3 ∀y4 ∀y5 ∀y6 ((y1 ∧ y2 ∧ y3 )∨
(y 1 ∧ x1 ) ∨ (y 1 ∧ y) ∨ (y 1 ∧ x2 )∨
(y 2 ∧ y) ∨ (y 2 ∧ x2 )∨
(y 3 ∧ x2 ) ∨ (y 3 ∧ y4 )∨
(y 4 ∧ y5 ∧ y6 )∨
(y 5 ∧ x1 ) ∨ (y 5 ∧ y)∨
(y 6 ∧ y) ∨ (y 6 ∧ x2 )).

(6)

Given a QBF with the matrix in DNF, we can represent the matrix as a set of terms
to be interpreted disjunctively, where a term is a finite set of literals to be interpreted
conjunctively. Further, we can assume that each term is non-contradictory and minimal. A
term is contradictory if it contains both a variable and its negation. A term T is minimal
if the literals in T with minimum level are universal. The minimal form of a term T is the
term obtained from T by deleting the existential literals which cause T to be non-minimal.
All the terms in (6) are non-contradictory and minimal. Analogously to what we have said
before for QBFs in CNF, if ϕ is a QBF in DNF then we can assume that all the terms are
non-contradictory and minimal without loss of generality.
376

Clause/Term Resolution and Learning for Quantified Boolean Formulas

Theorem 3 Let ϕ be a QBF with the matrix in DNF. Let ϕ0 be the QBF obtained from ϕ
by
1. eliminating contradictory terms; and
2. replacing each non-contradictory and non-minimal term with its minimal form.
ϕ and ϕ0 are equivalent.
Proof. Analogous to the proof of Theorem 1.



As before, from here on, a QBF is in DNF if and only if the matrix is a disjunction of
terms, and each term is both minimal and non-contradictory.
We can introduce term resolution (on a literal l) which consists of the rule
T1
T2
min(T )
where
• l is an universal literal;
• T1 , T2 are two terms such that {l, l} ⊆ (T1 ∪ T2 ), and for no literal l0 6= l, {l0 , l0 } ⊆
(T1 ∪ T2 );
• T is (T1 ∪ T2 ) \ {l, l}.
T1 and T2 are the antecedents, and min(T ) is the resolvent of the rule.
Theorem 4 Term resolution is a sound and complete proof system for deciding QBFs in
DNF: a QBF in DNF is true if and only if the empty term is derivable by term resolution.
Proof. The fact that term resolution is a sound and complete proof system follows from
the soundness and completeness of clause resolution.
Let Φ be a set of sets of literals, and ϕ = Q1 z1 Q2 z2 . . . Qn zn Φ be a QBF in which Φ is
interpreted as a set of clauses. Without loss of generality we can assume that each clause
in Φ is non-tautological and minimal. Then the following chain of equivalences holds:
There exists a deduction ∆ of the empty clause from ϕ using clause resolution
if and only if
ϕ is false
if and only if
The QBF ϕ = Q1 z1 Q2 z2 . . . Qn zn Φ in which Φ is interpreted as a set of terms is true
if and only if
∆ is a deduction of the empty term from ϕ using term resolution.
In the above chain of equivalences, Q is ∃ if Q = ∀, and is ∀ if Q = ∃.



As an example of a term resolution deduction of the empty term, consider the QBF ϕ:
∀x1 ∃y∀x2 ∀x3 ((x1 ∧ y ∧ x2 ) ∨ (y ∧ x2 ) ∨ (x2 ∧ x3 ) ∨ (x1 ∧ y ∧ x3 ) ∨ (y ∧ x2 ∧ x3 ))
377

Giunchiglia, Narizzano & Tacchella

i.e., the QBF obtained from (3) by simultaneously replacing ∀ with ∃, ∃ with ∀, ∧ with ∨,
and ∨ with ∧. Then, the deduction in Table 1 is also a deduction of the empty term from
ϕ using term resolution.
If the QBF ϕ is not in DNF but in CNF then term resolution cannot be applied, and
thus term resolution is not sufficient for proving the truth or falsity of ϕ. However, if we
also have the following model generation rule
Φ
min(T )
where
• Φ is the matrix of ϕ; and
• T is a non-contradictory term such that for each clause C ∈ Φ, C ∩ T 6= ∅,
we get a sound and complete proof system for QBFs in CNF. Intuitively, the model generation rule allows us to start from the minimal form of terms which propositionally entail
the matrix of the input formula.
Theorem 5 Term resolution and model generation is a sound and complete proof system
for deciding QBFs in CNF: a QBF in CNF is true if and only if the empty term is derivable
by term resolution and model generation.
Proof. Given a QBF ϕ in CNF with matrix Φ, by the model generation rule we can derive
a set Ψ of terms of the form min(T ) such that
• each term T is a non-contradictory and such that for each clause C ∈ Φ, C ∩ T 6= ∅;
and
• the disjunction of all the terms in Ψ is propositionally logically equivalent to Φ.
Let ϕ0 be the QBF in DNF obtained by substituting Φ with Ψ in ϕ. ϕ and ϕ0 have the
same value. Hence the thesis thanks to Theorem 4.


3.2 DLL Based Decision Procedures for QBFs
Given what we have said so far, an arbitrary QBF ϕ can be converted (in linear time) into
an equivalent QBF in CNF. Because of this, from here to the end of the paper, we restrict
our attention to QBFs in such format. With this assumption, if ϕ is (1) and l is a literal
with |l| = zi , we redefine ϕl to be the QBF
• whose matrix is obtained from Φ by removing the clauses C with l ∈ C, and by
removing l from the other clauses; and
• whose prefix is Q1 z1 Q2 z2 . . . Qi−1 zi−1 Qi+1 zi+1 . . . Qn zn .
378

Clause/Term Resolution and Learning for Quantified Boolean Formulas

Further, we extend the notation to sequence of literals: If µ = l1 ; l2 ; . . . ; lm (m ≥ 0), ϕµ is
defined as (. . . ((ϕl1 )l2 ) . . .)lm .
Consider a QBF ϕ.
A simple procedure for determining the value of ϕ starts with the empty assignment 
and recursively extends the current assignment µ with z and/or z, where z is a heuristically
chosen variable at the highest level in ϕµ , until either the empty clause or the empty set of
clauses are produced in ϕµ . On the basis of the values of ϕµ;z and ϕµ;z , the value of ϕµ can
be determined according to the semantics of QBFs. The value of ϕ is the value of ϕ .
Cadoli, Giovanardi, Giovanardi and Schaerf (2002) introduced various improvements to
this basic procedure.
The first improvement is that we can directly conclude about the value of ϕµ if the
matrix of ϕµ contains a contradictory clause (Lemma 2.1 in Cadoli et al., 2002). A clause
C is contradictory if it contains no existential literal. An example of a contradictory clause
is the empty clause.
The second improvement allows us to directly extend µ with l if l is unit or monotone
in ϕµ (Lemmas 2.4, 2.5, 2.6 in Cadoli et al., 2002). In (1), a literal l is:
• Unit if l is existential and for some m ≥ 0,
– a clause {l, l1 , . . . , lm } belongs to Φ; and
– each literal li (1 ≤ i ≤ m) is universal and has a level lower than the level of l.
• Monotone or pure if
– either l is existential, l does not belong to any clause in Φ, and l occurs in Φ;
– or l is universal, l does not belong to any clause in Φ, and l occurs in Φ.
For example, in a QBF of the form
. . . ∃x1 ∀y∃x2 . . . {{x1 , y}, {x2 }, . . .},
both x1 and x2 are unit. In the QBF
∀y1 ∃x1 ∀y2 ∃x2 {{y 1 , y2 , x2 }, {x1 , y 2 , x2 }},
the only monotone literals are y1 and x1 .
With such improvements, the resulting procedure, called Q-DLL, is essentially the one
presented in the work of Cadoli, Giovanardi, and Schaerf (1998), which extends DLL in
order to deal with QBFs. Figure 1 is a simple, recursive presentation of it. In the figure,
given a QBF ϕ,
1. False is returned if a contradictory clause is in the matrix of ϕµ (line 1); otherwise
2. True is returned if the matrix of ϕµ is empty (line 2); otherwise
3. at line 3, µ is recursively extended to µ; l if l is unit (and we say that l has been
assigned as unit); otherwise
379

Giunchiglia, Narizzano & Tacchella

0 function Q-DLL(ϕ, µ)
1
if (ha contradictory clause is in the matrix of ϕµ i) return False;
2
if (hthe matrix of ϕµ is emptyi) return True;
3
if (hl is unit in ϕµ i) return Q-DLL(ϕ, µ; l);
4
if (hl is monotone in ϕµ i) return Q-DLL(ϕ, µ; l);
5
l := ha literal at the highest level in ϕµ i;
6
if (hl is existentiali) return Q-DLL(ϕ, µ; l) or Q-DLL(ϕ, µ; l);
7
else return Q-DLL(ϕ, µ; l) and Q-DLL(ϕ, µ; l).
Figure 1: The algorithm of Q-DLL.
4. at line 4, µ is recursively extended to µ; l if l is monotone (and we say that l has been
assigned as monotone); otherwise
5. a literal l at the highest level is chosen and
• If l is existential (line 6), µ is extended to µ; l first (and we say that l has been
assigned as left split). If the result is False, µ; l is tried and returned (and in
this case we say that l has been assigned as right split).
• Otherwise (line 7), l is universal, µ is extended to µ; l first (and we say that l
has been assigned as left split). If the result is True, µ; l is tried and returned
(and in this case we say that l has been assigned as right split).
Theorem 6 Q-DLL(ϕ, ) returns True if ϕ is true, and False otherwise.
Proof. Trivial consequence of Lemmas 2.1, 2.4, 2.5, 2.6 in the work of Cadoli, Giovanardi,
Giovanardi, and Schaerf (2002) and of the semantics of QBFs.

Given what we have said so far, it is clear that Q-DLL evaluates ϕ by generating a
semantic tree (Robinson, 1968) in which each node corresponds to an invocation of Q-DLL
and thus to an assignment µ. For us,
• an assignment (for a QBF ϕ) is a possibly empty sequence µ = l1 ; l2 ; . . . ; lm (m ≥ 0)
of literals such that for each li in µ, li is unit, or monotone, or at the highest level in
ϕl1 ;l2 ;...;li−1 ;
• the (semantic) tree representing a run of Q-DLL on ϕ is the tree
– having a node µ for each call to Q-DLL(ϕ, µ); and
– an edge connecting any two nodes µ and µ; l, where l is a literal.
Any tree representing a run of Q-DLL has at least the node .
As an example of a run of Q-DLL, consider the QBF (4). For simplicity, assume that
the literal returned at line 5 in Figure 1 is the negation of the first variable in the prefix
which occurs in the matrix of the QBF under consideration. Then, the tree searched by
Q-DLL when ϕ is (4) can be represented as in Figure 2. In the figure:
380

Clause/Term Resolution and Learning for Quantified Boolean Formulas

{}{{x1 , y, x2 }, {x1 , y, x3 }, {y, x2 }, {y, x2 , x3 }, {x2 , x3 }}{}
{x1 } hx1 , li {x1 }
{{y, x3 }, {y, x2 }, {y, x2 , x3 }, {x2 , x3 }}

{x1 } hx1 , ri {x1 }
{{y, x2 }, {y, x2 }, {y, x2 , x3 }, {x2 , x3 }}

hy, ri {x1 }
hy, li {y}
hy, li {y}
hy, ri {x1 }
hx2 , pi{y} {x1 , y, x2 }hx2 , ui{x1 }
hx2 , pi{y} {x1 , y, x3 }hx3 , ui{x1 }
{{}} {y, x2 }
{y} {} {y}
{y, x2 }hx2 , ui{y, x3 } {y} {} {y}
{{}} {x2 , x3 }

Figure 2: The tree generated by Q-DLL for (4). The matrix of (4) is shown at the root
node, and the prefix is ∃x1 ∀y∃x2 ∃x3 . u, p, l, r stand for “unit”, “pure”, “left
split”, “right split” respectively, and have the obvious meaning.

• Each node is labeled with the literal assigned by Q-DLL in order to extend the assignment built so far. Thus, the assignment corresponding to a node is the sequence
of labels in the path from the root to the node. For instance, the assignment corresponding to the node with label x3 is x1 ; y; x3 .
• When literals are assigned as unit or monotone, the corresponding nodes are aligned
one below the other. Further for each assigned literal l, we also show whether l
has been assigned as unit, monotone, left or right split by marking it as u, p, l, r
respectively.
• When l has been assigned as a left or right split, we also show the matrix of ϕµ;l ,
where µ is the sequence of literals assigned before l.
• When the node µ is a leaf, then the matrix of ϕµ is either empty (in which case we
write “{}” below the node), or it contains a contradictory clause (in which case we
write “{{}}” below the node).
Considering Figure 2, it is easy to see that Q-DLL would correctly return False, meaning that (4) (and thus also (2)) is false.
3.3 Resolution and DLL Based Decision Procedures for QBFs
The well known correspondence in SAT between semantic trees and resolution (see, e.g.,
Urquhart, 1995) gives us the starting point for our analysis, aimed to establish a correspondence between Q-DLL and clause/term resolution.
Consider a QBF ϕ. Let Π be the tree explored by Q-DLL for evaluating ϕ.
For the time being, assume that we are dealing with a SAT problem, i.e., ϕ does not
contain universal quantifiers. Then, Q-DLL reduces to DLL, and if ϕ is false then we can
use Π to generate a clause resolution deduction of the empty clause from ϕ. The basic idea
is to associate with each node µ of Π a clause C which is µ-falsified, i.e., such that for each
381

Giunchiglia, Narizzano & Tacchella

literal l ∈ C, l is in µ. (We say that a literal l is in or has been assigned by l1 ; . . . ; lm if and
only if l ∈ {l1 , . . . , lm }). More precisely:
• With every leaf µ of Π, we associate an arbitrarily selected clause in the matrix of
ϕ which is µ-falsified. At least one such clause exists because ϕµ contains the empty
clause.
• If C is the clause associated with a node µ; l, then
1. If l 6∈ C then C is also the clause associated with µ. Notice that if l is monotone
in ϕµ then l 6∈ C.
2. If l ∈ C and l is unit in ϕµ then the clause associated with µ is the resolvent of
C and an arbitrarily selected clause of ϕ which causes l to be unit in ϕµ .
3. If l ∈ C and l is not unit in ϕµ then we have to consider the clause C 0 associated
with the node µ; l. If l 6∈ C 0 then C 0 is the clause associated with µ (as in the
first case). If l ∈ C 0 , the clause associated with µ is the resolvent of C and C 0 .
Lemma 1 Let ϕ be a QBF without universal quantifiers. Let Π be the tree searched by
Q-DLL(ϕ, ). Let µ be an assignment for ϕ. If ϕµ is false, then the clause associated with
the node µ of Π
• is µ-falsified; and
• does not contain existential literals whose negation has been assigned as monotone
in µ.
Proof. Let S be the set of assignments in Π which extend µ. Clearly, for each assignment
µ0 ∈ S, ϕµ0 is false (ϕ does not contain universal quantifiers). On S, we define the partial
order relation  according to which two assignments µ0 and µ00 in S are such that µ0  µ00
if and only if µ0 extends µ00 . Clearly  is well founded and the minimal elements are the
assignments extending µ and corresponding to the leaves of Π.
If µ0 extends µ and is a leaf of Π, then ϕµ0 contains a contradictory clause C. Since
ϕ does not contain universal quantifiers, C is µ0 -falsified and is associated with the node
µ0 . Clearly, C does not contain existential literals whose negation has been assigned as
monotone.
By induction hypothesis, for each assignment µ0 = µ00 ; l  µ00 in S we have a µ0 -falsified
clause not containing existential literals whose negation has been assigned as monotone.
We have to show the thesis for µ00 . There are three cases:
1. l has been assigned as unit. Let C1 be the clause associated with µ00 ; l. By induction
hypothesis, the thesis holds for C1 . If C1 does not contain l, the thesis trivially follows.
Otherwise, the clause associated with µ00 is the resolvent C of C1 with a clause C2
that causes l to be unit in ϕµ00 . C2 is µ00 ; l-falsified and it does not contain existential
literals whose negation has been assigned as monotone. C = C1 ∪ C2 \ {l, l} and thus
the thesis trivially holds.
2. l has been assigned as monotone. In this case the clause C associated with µ00 is the
same clause associated with µ00 ; l. By induction hypothesis C does not contain l and
thus C is µ00 -falsified.
382

Clause/Term Resolution and Learning for Quantified Boolean Formulas

3. l is a split. In this case we have a clause C1 associated with µ00 ; l and a clause C2
associated with µ00 ; l. The thesis holds for both C1 and C2 by induction hypothesis.
If C1 does not contain l, then the clause associated with µ00 is C1 and the thesis
trivially holds. Otherwise, if C2 does not contain l, then the clause associated with
µ00 is C2 and again the thesis trivially holds. Otherwise, the clause associated with µ00
is C1 ∪ C2 \ {l, l} and again the thesis trivially holds.

Theorem 7 Let ϕ be a false QBF without universal quantifiers. The tree searched by QDLL(ϕ, ) corresponds to a clause resolution deduction of the empty clause.
Proof. Let ∆ be a sequence of clauses obtained by listing the clauses in the matrix of ϕ
according to an arbitrary order, followed by the clauses associated with the internal nodes
of the tree Π searched by Q-DLL(ϕ, ), assuming Π is visited in post order. Clearly, ∆ is
a deduction. ∆ is a deduction of the empty clause because the node  has an associated
-falsified clause (Lemma 1), i.e., the empty clause.

The theorem points out the close correspondence between the computation of Q-DLL
and clause resolution, assuming the input formula is false and that it does not contain
universal quantifiers. If the input formula does not contain universal quantifiers but is true,
still the tree explored by Q-DLL before generating the path ending with the empty matrix
corresponds to a sequence of clause resolutions, one for each maximal subtree whose leaves
µ are such that ϕµ contains an empty clause.
If we no longer assume that the input formula ϕ does not contain universal quantifiers,
and consider the case in which ϕ is an arbitrary QBF, the situation gets more complicated,
also because of the possibility of assigning unit literals which are not at the highest level.
So, we now assume that if a literal l is assigned as unit at a node µ, then l is at the highest
level in ϕµ .
Then, if the input formula ϕ is false, we can again use the tree Π searched by Q-DLL to
generate a clause resolution deduction of the empty clause. The construction is analogous
to the one described before. The only difference is that we have to restrict our attention
to the minimal false subtree of Π, i.e., the tree obtained from Π by deleting the subtrees
starting with a left split on a universal literal: These subtrees are originated from “wrong
choices” when deciding which branch to explore first. In the minimal false subtree Π0 of Π,
all the leaves terminate with the empty clause, and we can associate with each node of Π0 a
clause exactly in the same way described above for the SAT case. For instance, if ϕ is (4),
then Q-DLL assigns unit literals only when they are at the highest level. Figure 3 shows
the minimal false subtree of Q-DLL’s computation, and the associated clause resolution
deduction of the empty clause. In the figure,
• the clause associated with each node is written in red and to the right of the node
itself;
• when a node corresponds to the assignment of a unit literal l, a clause of ϕ which
causes l to be unit at that node (used in the corresponding clause resolution) is written
in red and to the left of the node.
383

Giunchiglia, Narizzano & Tacchella

{}{{x1 , y, x2 }, {x1 , y, x3 }, {y, x2 }, {y, x2 , x3 }, {x2 , x3 }}{}
{x1 } hx1 , li {x1 }
{{y, x3 }, {y, x2 }, {y, x2 , x3 }, {x2 , x3 }}

{x1 } hx1 , ri {x1 }
{{y, x2 }, {y, x2 }, {y, x2 , x3 }, {x2 , x3 }}

hy, ri {x1 }
{x1 , y, x3 }hx3 , ui{x1 }
{y, x2 }hx2 , ui{y, x3 }
{{}} {x2 , x3 }

hy, ri {x1 }
{x1 , y, x2 }hx2 , ui{x1 }
{{}} {y, x2 }

Figure 3: The clause resolution corresponding to the tree generated by Q-DLL for (4). The
prefix is ∃x1 ∀y∃x2 ∃x3 .

Lemma 2 Let ϕ be a false QBF. Let Π be the minimal false subtree of the tree searched by
Q-DLL(ϕ, ) and assume that for each node µ; l in Π, if l is unit in ϕµ then l is also at the
highest level in ϕµ . Let µ be an assignment for ϕ. If ϕµ is false, then the clause associated
with the node µ of Π
• is µ-falsified; and
• does not contain existential literals whose negation has been assigned as monotone
in µ.
Proof. Trivial extension of the proof of Lemma 1. The assumption that for each node µ; l
in Π, if l is unit in ϕµ then l is at the highest level in ϕµ , ensures that each clause associated
with a node µ of Π is µ-falsified.


Theorem 8 Let ϕ be a false QBF. Let Π be the minimal false subtree of the tree searched
by Q-DLL(ϕ, ) and assume that for each node µ; l in Π, if l is unit in ϕµ then l is also at
the highest level in ϕµ . Then Π corresponds to a clause resolution deduction of the empty
clause.
Proof. Given Lemma 2, the proof is analogous to the one of Theorem 7.



Regardless of whether the input formula is true or false, the tree explored by Q-DLL
may contain (exponentially many) subtrees whose nodes µ are such that ϕµ is false. The
procedure described above, allows us to associate a clause resolution deduction with each
of such subtrees.
If the input formula ϕ is true, the situation is simpler because so far we do not have “unit
universal literals”, and we can use the tree Π searched by Q-DLL to generate a deduction
of the empty term from ϕ. Intuitively, the process is analogous to the one described when
ϕ is false, except that the leaves of our term resolution deduction are terms corresponding
to the assignments computed by Q-DLL and entailing the matrix of ϕ. In details:
384

Clause/Term Resolution and Learning for Quantified Boolean Formulas

• First, we have to restrict our attention to the minimal true subtree of Π, i.e., the tree
obtained from Π by deleting the subtrees starting with a left split on an existential
literal: Analogously to the the case in which ϕ is false, each leaf in a minimal true
subtree of Π terminates with the empty matrix.
• Second, we associate with each node µ a term, represented as a set, as follows:
– The term associated with each leaf is a minimal term min(T ) in which T 1
1. does not contain universal literals assigned as monotone,
2. has to propositionally entail the matrix, i.e., for each clause C in the matrix
of ϕ, T ∩ C 6= ∅, and
3. has to be a subset of the literals in µ, i.e., T ⊆ {l : l is in µ}.
– If T is the term associated with a node µ; l, then
1. If l 6∈ T then T is the term associated with the node µ. Notice that if l is
either existential or both universal and monotone in ϕµ , then l 6∈ T .
2. If l ∈ T then we have to consider also the term T 0 associated with the node
µ; l. If l 6∈ T 0 then T 0 is the term associated with µ (as in the first case). If
l ∈ T 0 , the term associated with µ is the resolvent of T and T 0 .
It is easy to see that the term T associated with a node µ is µ-entailed: Each literal in T
is also in µ.
Lemma 3 Let ϕ be a true QBF. Let Π be the minimal true subtree of the tree searched by
Q-DLL(ϕ, ). Let µ be an assignment for ϕ. If ϕµ is true, then the term associated with
the node µ of Π
• is µ-entailed; and
• does not contain universal literals assigned as monotone.
Proof. Analogous to the proof of Lemma 2.



Theorem 9 Let ϕ be a true QBF. Let Π the minimal true subtree of the tree searched by
Q-DLL(ϕ, ). Then Π corresponds to a model generation and term resolution deduction of
the empty term.
Proof. Let ∆ be the sequence of terms obtained by listing the terms associated with the
nodes of Π visited in post order. Clearly, ∆ is a model generation and term resolution deduction. ∆ is a deduction of the empty term because the node  has an associated -entailed
term (Lemma 3), i.e., the empty term.

As before, regardless of whether the input formula is true or false, the tree explored
by Q-DLL may contain (exponentially many) subtrees whose nodes are associated with
1. For the sake of efficiency, it is also important that the term T satisfies other properties. However, they
are not necessary for the time being, and will be discussed in the next section.

385

Giunchiglia, Narizzano & Tacchella

{}{{x1 , y, x2 }, {x1 , y, x3 }, {y, x2 }, {y, x2 , x3 }, {x2 , x3 }}{}
{x1 } hx1 , ri {x1 }
{x1 } hx1 , li {x1 }
{{y, x3 }, {y, x2 }, {y, x2 , x3 }, {x2 , x3 }} {{y, x2 }, {y, x2 }, {y, x2 , x3 }, {x2 , x3 }}
hy, li {y}
hx2 , pi{y}
{y, x2 } {} {y}

hy, li {y}
hx2 , pi{y}
{y, x2 } {} {y}

Figure 4: The term resolutions corresponding to the tree generated by Q-DLL for (4). The
prefix is ∃x1 ∀y∃x2 ∃x3 .

{}{{x1 , y, x2 }, {x1 , y, x3 }, {y, x2 }, {y, x2 , x3 }, {x2 , x3 }}{}
{x1 } hx1 , li {x1 }
{{y, x3 }, {y, x2 }, {y, x2 , x3 }, {x2 , x3 }}

{x1 } hx1 , ri {x1 }
{{y, x2 }, {y, x2 }, {y, x2 , x3 }, {x2 , x3 }}

hy, li {y}
hy, li {y}
hy, ri {x1 }
hy, ri {x1 }
hx2 , pi{y} {x1 , y, x3 }hx3 , ui{x1 }
hx2 , pi{y} {x1 , y, x2 }hx2 , ui{x1 }
{y, x2 } {} {y}
{{}} {y, x2 }
{y, x2 }hx2 , ui{y, x3 } {y, x2 } {} {y}
{{}} {x2 , x3 }

Figure 5: The resolution corresponding to the tree generated by Q-DLL for (4). The prefix
is ∃x1 ∀y∃x2 ∃x3 .

assignments µ with ϕµ being true. The above described procedure allows us to associate
a term resolution deduction with each of such subtrees. For instance, if ϕ is (4) there are
two maximal such subtrees, having roots x1 ; y and x1 ; y. The associated deductions are
represented in Figure 4. In the figure,
• we represent also the nodes along the path from the root to the subtrees,
• the term associated with each node is written in green and to the right of the node
itself,
• if µ is a leaf, a non-contradictory term T entailing the matrix and whose minimal
form min(T ) is associated with µ, is written in green and to the left of µ.
Merging the trees in Figures 3 and 4 we obtain the whole tree of deductions corresponding to the search tree explored by Q-DLL (represented in Figure 5) in which clause and
term resolutions are intermixed.
386

Clause/Term Resolution and Learning for Quantified Boolean Formulas

Now we consider the case in which the input QBF ϕ is false and we no longer assume
that literals are assigned as unit only if they are at the highest level. We restrict our
attention to the minimal false subtree Π of the tree searched by Q-DLL(ϕ, ). Then, the
procedure described above for associating a clause with each node of Π may no longer work.
For one thing, given a leaf µ, there may be no µ-falsified clauses in the matrix of the input
formula. However, we are guaranteed about the existence of a µ-contradicted clause in the
matrix of the input formula. A clause C is µ-contradicted if2
• for each literal l in C, l is not in µ; and
• for each existential literal l in C, l is in µ.
As long as we can associate with each node µ of Π a µ-contradicted clause (either belonging
to the matrix of ϕ or obtained by clause resolution) Π corresponds to a clause resolution
deduction of the empty clause: Indeed the clause associated with the root of Π has to be
empty (remember that the resolvent of a clause resolution is in minimal form). Thus, the
obvious solution is to try to associate
1. with each leaf µ a µ-contradicted clause in the input formula, and
2. with each internal node µ a µ-contradicted clause obtained by resolving input clauses
and/or previously deduced clauses along the same lines outlined before.
In some cases the process runs smoothly. Consider for instance, a QBF of the form:
∃x1 ∃x2 ∀y∃x3 {{x1 , x3 }, {x2 , x3 }, {x2 , y, x3 }, . . .}.

(7)

Then, if we assume that a split on x1 occurs first, the following path will be explored (we
are using the same conventions of Figure 3):
hx1 , li
hx3 , ui
hx2 , ui
{{}}

(8)

and the clause associated with each node are:
hx1 , li
{x1 , x3 } hx3 , ui
{x2 , x3 } hx2 , ui
{{}}

{x1 }
{x1 }
{y, x3 }
{x2 , y, x3 }

where we see that:
1. the clause associated with the leaf µ = x1 ; x3 ; x2 is not µ-falsified but is µ-contradicted;
and
2. With respect to the definition of “contradictory clause” given in Section 3.2, it is clear that a clause C is
contradictory if and only if it is -contradicted. Further, for any QBF ϕ and assignment µ, there exists
a µ-contradicted clause in the matrix of ϕ, if and only if ϕµ contains a -contradicted clause, if and only
if ϕµ contains a contradictory clause.

387

Giunchiglia, Narizzano & Tacchella

0 function Rec-C-Resolve(ϕ, C1 , C2 , l, µ)
1
S := {l : l ∈ C1 , l ∈ C2 };
2
if (S = ∅) return C-Resolve(C1 , C2 );
3
l1 := han existential literal in C1 with level ≤ than the level of all the literals in C1 }i;
4
C := ha clause in ϕ which causes l1 to be unit in ϕµ0 , where µ0 ; l1 is a prefix of µi;
5
C3 := C-Resolve(C1 , C);
6
return Rec-C-Resolve(ϕ, C3 , C2 , l, µ).
Figure 6: The algorithm of Rec-C-Resolve.
2. we are able to associate with each node µ a µ-contradicted clause.
Unfortunately, in some cases things do not run so smoothly, i.e., it may not be possible
to associate a clause to an internal node by a simple single resolution between input and/or
previously deduced clauses. Indeed, some clause resolutions may be blocked because of
universal variables occurring both as y and y in the clauses to be used for the resolution.
Consider for instance a QBF of the form (obtained from (7) by replacing the clause {x2 , x3 }
with {x2 , y, x3 }):
∃x1 ∃x2 ∀y∃x3 {{x1 , x3 }, {x2 , y, x3 }, {x2 , y, x3 }, . . .}.

(9)

Then, (8) would be still a valid path, and the corresponding clause resolutions would be:
hx1 , li
{x1 , x3 } hx3 , ui
{x2 , y, x3 } hx2 , ui . . .
{{}} {x2 , y, x3 }

(10)

where it is not possible to perform the clause resolution associated with the node having
label hx2 , ui. As in the example, a clause resolution (5) may be blocked only because of
some “blocking” universal literal l
• with both l and l not in µ, and
• with l ∈ C1 and l ∈ C2 .
Since both C1 and C2 are in minimal form, this is only possible if both C1 and C2 contain
an existential literal l0
• having level less than or equal to the level of all the other literals in the clause; and
• assigned as unit.
Then, the obvious solution is to get rid, e.g., of the blocking literals l in C1 by resolving
away from C1 the existential literals with a level lower than the level of l.
This is the idea behind the procedure Rec-C-Resolve in Figure 6. In the figure, we
assume that
1. ϕ is the input QBF;
388

Clause/Term Resolution and Learning for Quantified Boolean Formulas

2. µ; l is an assignment;
3. l is an existential literal which is either unit or at the highest level in ϕµ ;
4. C1 is a clause containing l, in minimal form and µ; l-contradicted;
5. C2 is a clause containing l, in minimal form and µ; l-contradicted. Further, if l is unit
in ϕµ , then C2 is a clause which causes l to be unit in ϕµ ;
6. C-Resolve(C1 , C2 ) returns the resolvent of the clause resolution between the two
clauses C1 and C2 .
From here on, if hϕ, C1 , C2 , l, µi satisfies the first 5 of the above conditions, we say that
the pair hC1 , C2 i is to be µ; l-Rec-C-Resolved (in ϕ). Given two clauses hC1 , C2 i to be
µ; l-Rec-C-Resolved:
1. The set S of universal literals blocking the clause resolution between C1 and C2 is
computed (line 1).
2. If S is empty, then we can simply return the resolvent between C1 and C2 (line 2);
otherwise
3. we pick an existential literal l1 in C1 having minimum level in C1 (line 3): l1 has
been assigned as unit earlier in the search, and we consider a clause C which caused
l1 to be assigned as unit (line 4). If C3 is the resolvent between C1 and C (line 5),
Rec-C-Resolve(ϕ, C3 , C2 , l, µ) is returned (line 6).
If hC1 , C2 i are to be µ; l-Rec-C-Resolved in ϕ, Rec-C-Resolve(ϕ, C1 , C2 , l, µ) returns a minimal clause which is µ-contradicted and without existential literals whose negation has been
assigned as monotone in µ. This is formally stated by the following lemma.
Lemma 4 Let C1 and C2 be two clauses such that hC1 , C2 i is to be µ; l-Rec-C-Resolved in
a QBF ϕ. Rec-C-Resolve(ϕ, C1 , C2 , l, µ) terminates and returns a clause
• in minimal form and µ-contradicted; and
• which does not contain existential literals whose negation has been assigned as monotone in µ.
The proof of the lemma is quite long and it is reported in the appendix.
Assuming that the input QBF ϕ is false, the construction of the deduction of the empty
clause (associated with the minimal false subtree Π of the tree searched by Q-DLL) is the
following:
• With every leaf µ of Π, we associate a clause C in the input formula which is µcontradicted.
• If C is the clause associated with a node µ; l, then
1. If l 6∈ C or if l is universal then C is the clause associated with the parent of
µ; l, i.e., with the node µ. Notice that if l is existential and monotone in ϕµ then
l 6∈ C.
389

Giunchiglia, Narizzano & Tacchella

2. If l ∈ C and l is unit in ϕµ then the clause associated with the node µ is the
result of Rec-C-Resolve(ϕ, C, C 0 , l, µ), where C 0 is a clause of ϕ which causes l
to be unit in ϕµ .
3. If l ∈ C, l is existential and not unit in ϕµ , then we have to consider also the
clause C 0 associated with the node µ; l. If l 6∈ C 0 then C 0 is the clause associated
with µ (as in the first case). If l ∈ C 0 , the clause associated with the node µ is
the result of Rec-C-Resolve(ϕ, C, C 0 , l, µ).
In our example, if ϕ is (9) and with reference to the deduction in (10), the blocked resolution is the one associated with the node x1 ; x3 ; x2 . Rec-C-Resolve(ϕ, {x2 , y, x3 }, {x2 , y, x3 }, x2 , x1 ; x3 )
1. at line 5, resolves {x2 , y, x3 } and {x1 ; x3 }, and the resolvent C3 is min({x1 , x2 , y}) =
{x1 , x2 }; and
2. the following recursive call to Rec-C-Resolve(ϕ, {x1 , x2 }, {x2 , y, x3 }, x2 , x1 ; x3 ) at line 6
returns {x1 , y, x3 }.
Thus, the clause associated with each node are:
hx1 , li
{x1 , x3 } hx3 , ui
{x2 , y, x3 } hx2 , ui
{{}}

{x1 }
{x1 }
{x1 , y, x3 }
{x2 , y, x3 }

Notice that, with reference to Figure 6, the choice of eliminating the blocking literals
in C1 while maintaining C2 invariant, is arbitrary. Indeed, we could eliminate the blocking
literals in C2 and maintain C1 invariant. In the case of the deduction in (10), this amounts
to eliminate the universal literal y in {x2 , y, x3 }: By resolving this clause with {x1 , x3 } on
x3 , we get the resolvent {x1 , x2 }, which leads to the following legal deduction:
hx1 , li
{x1 , x3 } hx3 , ui
(From {x2 , y, x3 }, {x1 , x3 }) {x1 , x2 } hx2 , ui
{{}}

{x1 }
{x1 }
{x1 , y, x3 }
{x2 , y, x3 }

Lemma 5 Let ϕ be a false QBF. Let Π be the minimal false subtree of the tree searched by
Q-DLL(ϕ, ). Let µ be an assignment for ϕ. If ϕµ is false, then the clause associated with
the node µ of Π
• is in minimal form and µ-contradicted; and
• does not contain existential literals whose negation has been assigned as monotone
in µ.
Proof. By construction, each clause associated with a leaf µ of Π is µ-contradicted. We
now show that also the clause C associated with an internal node µ of Π is µ-contradicted,
assuming that the clause C 0 associated with its child µ; l is µ; l-contradicted. If µ has also a
child µ; l, we also assume that the clause C 00 associated with its child µ; l is µ; l-contradicted.
390

Clause/Term Resolution and Learning for Quantified Boolean Formulas

1. If l 6∈ C 0 or if l is universal then C = C 0 . Hence, C is in minimal form. Since l 6∈ C 0
or l is universal, C 0 is µ; l-contradicted if and only if C 0 is µ-contradicted. The thesis
follows because C = C 0 .
2. If l ∈ C 0 and l is unit in ϕµ then C =Rec-C-Resolve(ϕ, C 0 , C 00 , l, µ), where C 00 is a
clause of ϕ which causes l to be unit in ϕµ . The thesis follows from Lemma 4.
3. If l ∈ C, l is existential and not unit in ϕµ , then we have to consider also the clause
C 0 associated with the node µ; l. Assuming l ∈ C 0 (otherwise we would be in the first
case), the clause associated with µ is the result of Rec-C-Resolve(ϕ, C, C 0 , l, µ). As in
the previous case, the thesis follows from Lemma 4.

Theorem 10 Let ϕ be a false QBF. Let Π be the minimal false subtree of the tree searched
by Q-DLL(ϕ, ). Then Π corresponds to a clause resolution deduction of the empty clause.
Proof. Given Lemma 5, the proof is analogous to the one of Theorem 7.



4. Backjumping and Learning in DLL Based Procedures for QBFs
In this section we first show that computing the resolvent associated with each node allows
to backjump some branches while backtracking (Subsection 4.1). Then, we show that
learning resolvents allows to prune the search tree in branches different from the ones in
which resolvents were computed and learned (Subsection 4.2).
4.1 Conflict and Solution Directed Backjumping
The procedure described in Section 3.2 uses a standard backtracking schema whenever the
empty clause (resp. matrix) is generated: Q-DLL will backtrack up to the first existential
(resp. universal) literal assigned as left split. For instance, given the QBF
∀y1 ∃x1 ∀y2 ∃x2 ∃x3 {{y1 , y2 , x2 }, {y1 , y 2 , x2 , x3 }, {y1 , x2 , x3 },
{y 1 , x1 , x3 }, {y 1 , y2 , x2 }, {y 1 , y2 , x2 }, {y 1 , x1 , y 2 , x3 }},

(11)

the tree searched by Q-DLL is represented in Figure 7, where we use the same conventions
as in Section 3.
In the 2001 work of Giunchiglia, Narizzano, and Tacchella (2001), it is shown that the
exploration of some branches is not necessary. In particular, if ϕ is the input QBF and µ is
an assignment, we show how it is possible to compute a “reason” for the (un)satisfiability
of ϕµ while backtracking. Intuitively speaking, a reason for the result of ϕµ is a subset ν of
the literals in µ such that for any other assignment µ0
• which assigns to true or false the same literals assigned by µ (i.e., such that {|l| :
l is in µ0 } = {|l| : l is in µ}); and
• which extends ν (i.e., such that ν ⊆ {l : l is in µ0 }),
391

Giunchiglia, Narizzano & Tacchella

{}
{{y1 , y2 , x2 }, {y1 , y 2 , x2 , x3 }, {y1 , x2 , x3 },
{y 1 , x1 , x3 }, {y 1 , y2 , x2 }, {y 1 , y2 , x2 }, {y 1 , x1 , y 2 , x3 }}
{y 1 }hy 1 , li{y 1 }
{{y2 , x2 }, {y 2 , x2 , x3 }, {x2 , x3 }}
hy 2 , li{y 1 }
{y 1 , y 2 , x2 }hx2 , ui{y 1 }
{y 1 , x2 , x3 }hx3 , ui{y 1 }
{y 1 , x2 , x3 } {} {y 1 }

hy1 , ri{}
{{x1 , x3 }, {y2 , x2 }, {y2 , x2 }, {x1 , y 2 , x3 }}

hy2 , ri
{{x2 , x3 }, {x2 , x3 }}
hx2 , li
hx3 , ui
{}

hx1 , li{}
{y 1 , x1 , x3 }hx3 , ui{}
hy 2 , pi{}
{y 1 , y2 , x2 }hx2 , ui{}
{{}} {y 1 , y2 , x2 }

hx1 , ri
hx3 , pi
hy 2 , pi
hx2 , ui
{{}}

Figure 7: The resolution corresponding to the tree generated by Q-DLL for (11). The prefix
is ∀y1 ∃x1 ∀y2 ∃x2 ∃x3 .

ϕµ0 is equivalent to ϕµ . Then, by computing reasons, we can avoid to right split on a
literal l if l is not in the reason: assigning l to false would not change the result. The
resulting procedure is a generalization to QBF of the popular Conflict-directed Backjumping
(CBJ) (Prosser, 1993b), but also introduces the concept of Solution-directed Backjumping
(SBJ), for avoiding useless splits on universal variables.
In a later paper, Giunchiglia, Narizzano, and Tacchella (2003) show how it is possible
to optimize the computation of reasons. In particular, in that paper, it is shown that
• assuming ϕµ is unsatisfiable, we can consider reasons being a subset of the existential
literals in µ, while
• assuming ϕµ is satisfiable, we can consider reasons being a subset of the universal
literals in µ.
Apart from these optimizations, the tree searched by the procedures described in the former
and latter papers is the same, and, in the case of (11), the exploration of the branches
starting with hy2 , ri, hx1 , ri will be skipped (see Figure 7).
We now show that the computation of the resolutions corresponding to Q-DLL allows
to avoid the exploration of some branches pretty as much as CBJ and SBJ do: In the case
of the QBF (11), the branches being skipped will be the same skipped by CBJ and SBJ.
The key point is to think about Q-DLL as a procedure producing a clause (resp. term)
deduction of the empty clause (resp. term), proving that ϕ is unsatisfiable (resp. satisfiable).
Then, according to the rules we use for associating a deduction to the tree searched by QDLL, we have that:
• If C is the clause associated with a node µ; l and l 6∈ C, then the clause associated
with the node µ is C, even if l is existential and it has been assigned as left split.
392

Clause/Term Resolution and Learning for Quantified Boolean Formulas

0 function Q-DLL-BJ(ϕ, µ)
1
if (ha clause C is µ-contradictedi)
2
return C;
3
if (hthe matrix of ϕµ is emptyi) return ModelGenerate(µ);
4
if (hl is unit in ϕµ i)
5
C := ha clause in the matrix of ϕ which causes l to be unit in ϕµ i;
6
W R := Q-DLL-BJ(ϕ, µ; l);
7
if (hW R is a termi or l 6∈ W R) return W R;
8
return Rec-C-Resolve(ϕ, W R, C, l, µ);
9
if (hl is monotone in ϕµ i) return Q-DLL-BJ(ϕ, µ; l);
10
l := ha literal at the highest level in ϕµ i;
11
W R := Q-DLL-BJ(ϕ, µ; l);
12
if (hl is existentiali and (hW R is a termi or l 6∈ W R)) return W R;
13
if (hl is universali and (hW R is a clausei or l 6∈ W R)) return W R;
14
W R0 := Q-DLL-BJ(ϕ, µ; l);
15
if (hl is existentiali and (hW R0 is a termi or l 6∈ W R0 )) return W R0 ;
16
if (hl is universali and (hW R0 is a clausei or l 6∈ W R0 )) return W R0 ;
17
if (hl is existentiali) return Rec-C-Resolve(ϕ, W R0 , W R, l, µ);
18
return T-Resolve(W R0 , W R, l, µ).
Figure 8: The algorithm of Q-DLL-BJ.
• Analogously, if T is the term associated with a node µ; l and l 6∈ T , then the term
associated with the node µ is T , even if l is universal and it has been assigned as left
split.
The above rules do not take into account the clause/term associated with the node µ; l, and
thus there is no need to explore the branch starting with µ; l.
Consider for example Figure 7, in which we use the standard conventions and, e.g., write
the clause (resp. term) associated with each node µ in red (resp. green) to the right of
the node. With reference to the figure, it is clear that considering the term {y 1 } associated
with the node y 1 ; y 2 , there is no need to explore the branch starting with hy2 , ri in order to
associate a y 1 -entailed term with the node y 1 . Similarly, considering the empty clause {}
associated with the node y1 ; x1 , there is again no need to explore the branch starting with
hx1 , ri in order to associate a y1 -contradicted clause with the node y1 .
The procedure Q-DLL-BJ(ϕ, µ) in Figure 8 incorporates these ideas. In the figure,
• ModelGenerate(µ) returns the minimal form of a non-contradictory and µ-entailed
term T such that
– for each clause C ∈ Φ, C ∩ T 6= ∅; and
– for each universal literal l in µ assigned as monotone, l 6∈ T .
• Rec-C-Resolve(ϕ, C1 , C2 , l, µ) is as in Figure 6.
393

Giunchiglia, Narizzano & Tacchella

• T-Resolve(T1 , T2 ) returns the resolvent of the term resolution between the two terms
T1 and T2 .
The behavior Q-DLL-BJ can be illustrated in a few words by saying that Q-DLL-BJ(ϕ, µ)
computes and returns the clause/term that would be associated with the node µ in the tree
explored by Q-DLL. In particular, assuming
• that W R is the clause (resp. term) returned by Q-DLL-BJ(ϕ, µ; l);
• that l is existential (resp. universal); and
• that l has been assigned as left split,
Q-DLL-BJ(ϕ, µ) does not explore the branch starting with µ; l if l 6∈ W R (resp. l 6∈ W R),
see line 12 (resp. line 13) in Q-DLL-BJ.
So far, with reference to Figure 7, we can interpret the clause (resp. term) in red
(resp. green) to the right of a node µ as the value returned by Q-DLL-BJ(ϕ, µ). Then,
considering the term {y 1 } associated with the node y 1 ; y 2 , Q-DLL-BJ does not explore the
branch starting with hy2 , ri. Similarly, considering the empty clause {} associated with the
node y1 ; x1 , Q-DLL-BJ again does not explore the branch starting with hx1 , ri.
Theorem 11 Q-DLL-BJ(ϕ, ) returns the empty clause if ϕ is false, and the empty term
if ϕ is true.
Proof.(Sketch) It is enough to notice that:
• If a node µ has associated a clause C, then C is µ-contradicted, and C is the result
of a sequence of clause resolutions.
• If a node µ has associated a term T , then T is µ-entailed, and T is the result of a
sequence of model generations and term resolutions.
Then, as in the previous section:
• If the empty clause is associated with the initial node , then ϕ is false.
• If the empty term is associated with the initial node , then ϕ is true.



4.2 Learning
Learning is a well known technique in SAT for avoiding the useless traversal of branches. In
SAT, learning amounts to storing (clause) resolvents associated with the nodes of the tree
explored by DLL: these resolvents are called “nogoods” and can be simply added to the set
of input clauses.
In the case of QBFs, the situation is different and more complicated. Indeed, we have
two types of resolutions (“term” and “clause”), and while the resolvents of clause resolutions
can be added conjunctively to the matrix, the resolvents of term resolutions (that we will
call “goods”) have to be considered as in disjunction to the matrix.
In practice, we have to handle three sets of formulas:
394

Clause/Term Resolution and Learning for Quantified Boolean Formulas

• a set Ψ of terms corresponding to the goods learned during the search;
• a set Φ of clauses corresponding to the matrix of the input QBF; and
• a set Θ of clauses corresponding to the nogoods learned during the search.
Formally, if ϕ is a QBF of the form (1), a QBF ϕ Extended with Learning (EQBF) is an
expression of the form
Q1 z1 . . . Qn zn hΨ, Φ, Θi
(n ≥ 0)
(12)
where
• Ψ is a set of terms, also called goods, to be interpreted disjunctively. Each good is
obtained by model generation and/or term resolution from ϕ;
• Θ is a set of clauses, also called nogoods, to be interpreted conjunctively. Each nogood
is obtained by clause resolution from ϕ.
Clearly,
Q1 z1 . . . Qn zn (Ψ ∨ Φ)
and
Q1 z1 . . . Qn zn (Φ ∧ Θ)
are equivalent to (1).
Initially Ψ and Θ are the empty set, and Φ is the input set of clauses. As the search
proceeds,
• Nogoods are determined while backtracking from a contradiction (i.e., on an assignment µ and ϕµ is unsatisfiable) and are possibly added to Θ; and
• Goods are determined while backtracking from a solution (i.e., on an assignment µ
and ϕµ is satisfiable) and are possibly added to Ψ.
In the following, we will use the term constraints when we want to refer to goods and
nogoods indifferently.
Consider an EQBF (12). Because of the constraints in Ψ and/or Θ, the search can be
pruned considerably. Indeed, while descending the search tree, any literal can be assigned
as long as we are guaranteed that we can reconstruct a valid clause/term deduction –while
backtracking– of the empty clause/term. The availability of already derived clauses/terms
allows to prune the search because of the constraints in Ψ or Θ: Given an assignment µ,
if there exists a µ-contradicted clause C ∈ Θ (resp. a µ-satisfied term T ∈ Ψ) we can stop
the search and return C (resp. T ). A term T is µ-satisfied if
• for each literal l in T , l is not in µ; and
• for each universal literal l in T , l is in µ.
Clearly, a µ-entailed term is also µ-satisfied. Further, we can extend the notion of unit to
take into account the constraints in Ψ and/or Θ. A literal l is
• unit in a EQBF (12) if
395

Giunchiglia, Narizzano & Tacchella

0 function Rec-Resolve(ψ, W1 , W2 , l, µ)
1
S := {l : l ∈ W1 , l ∈ W2 };
2
if (S = ∅) return Resolve(W1 , W2 );
3
l0 := ha literal in W1 with level ≤ than the level of all the literals in W1 }i;
4
W := ha constraint in ψ which causes l0 to be unit in ψµ0 , where µ0 ; l0 is a prefix of µi;
5
W3 := Resolve(W1 , W );
6
return Rec-Resolve(ψ, W3 , W2 , l, µ).
Figure 9: The algorithm of Rec-Resolve.
– either l is existential and for some m ≥ 0,
∗ a clause {l, l1 , . . . , lm } belongs to Φ or Θ, and
∗ each expression ∀|li | (1 ≤ i ≤ m) occurs at the right of ∃|l| in the prefix of
(12).
– or l is universal and for some m ≥ 0,
∗ a term {l, l1 , . . . , lm } belongs to Ψ, and
∗ each expression ∃|li | (1 ≤ i ≤ m) occurs at the right of ∀|l| in the prefix of
(12).
As for the definition of monotone literals, the crucial property that has to be ensured when
dealing with EQBFs, is that an existential (resp. universal) literal l assigned as monotone
in µ; l should never enter in a nogood (resp. good) associated with a node extending µ; l.
This is guaranteed by defining a literal l as monotone or pure if and only if3
• either l is existential and l does not belong to any constraint in Φ ∪ Θ;
• or l is universal and l does not belong to any constraint in Ψ ∪ Φ.
Because of the possibility of assigning also universal literals as unit, it may be the case
that some term resolutions may be blocked because of some existential literals l and l, each
occurring in one of the terms to be used in the antecedents of the term resolution. However,
the procedure Rec-C-Resolve presented in in Subsection 3.3 can be easily generalized to
work also for the case in which the constraints to be resolved are terms. The result is the
procedure Rec-Resolve(ψ, W1 , W2 , l, µ) in Figure 9, where it is assumed that
1. ψ is an EQBF;
3. There are various ways to guarantee that an existential literal l assigned as monotone in µ; l does not
enter in a nogood associated with a node extending µ; l. Another one is to
• keep the definition of existential monotone literal unchanged: An existential literal can be assigned
as monotone in (12) if l does not belong to any clause in Φ; and
• update Θ to (or proceed in the search as if Θ has been updated to) Θ \ {C : C ∈ Θ, l ∈ C}.
Analogously for universal monotone literals. See the work of Giunchiglia, Narizzano and Tacchella (2004a) for more details and possibilities, including a discussion about the interaction between the
monotone rule and learning.

396

Clause/Term Resolution and Learning for Quantified Boolean Formulas

2. µ; l is an assignment;
3. l is an existential (resp. universal) literal which is either unit or at the highest level
in ψµ ;
4. W1 is a clause (resp. term) containing l (resp. l), in minimal form and µ; l-contradicted
(resp. µ; l-satisfied);
5. W2 is a clause (resp. term) containing l (resp. l), in minimal form and µ; l-contradicted
(resp. µ; l-satisfied). Further, if l is unit in ψµ , then W2 is a clause (resp. term) which
causes l to be unit in ψµ ;
6. for each existential (resp. universal) literal l0 assigned as unit in µ0 ; l0 , with µ0 ; l0 a
prefix of µ; l, there has to be a clause (resp. term) in ψ which causes l0 to be unit in
ψ µ0 .
7. Resolve(W1 , W2 ) returns C-Resolve(W1 , W2 ) (resp. T-Resolve(W1 , W2 )).
If hψ, W1 , W2 , l, µi satisfy the first 6 of the above 7 conditions, we say that the pair hW1 , W2 i
is to be µ; l-Rec-Resolved (in ψ).
In the above, if ψ is (12), ψl is defined as the EQBF obtained from ψ by
• removing from Φ and Θ (resp. Ψ) the clauses C (resp. terms T ) with l ∈ C (resp.
l ∈ T ), and by removing l (resp. l) from the other clauses in Φ ∪ Θ (resp. terms in
Ψ); and
• removing Q|l| from the prefix.
If µ = l1 ; l2 ; . . . ; lm (m ≥ 0), ψµ is defined as (. . . ((ψl1 )l2 ) . . .)lm .
If hW1 , W2 i are to be µ; l-Rec-Resolved in ψ, Rec-Resolve(ψ, W1 , W2 , l, µ) returns a
constraint in minimal form and µ-contradicted or µ-satisfied, as stated by the following
lemma.
Lemma 6 Let W1 and W2 be two clauses (resp. terms) such that hW1 , W2 i is to be µ; lRec-Resolved in a EQBF ψ. Rec-Resolve(ψ, W1 , W2 , l, µ) terminates and returns a minimal
clause (resp. term) which
• is µ-contradicted (resp. µ-satisfied); and
• does not contain existential literals whose negation has been (resp. universal literals
which have been) assigned as monotone in µ.
Proof.(Sketch) The proof is equal to (resp. analogous to) the proof of Lemma 4 if l is
existential (resp. universal).

The procedure Q-DLL-LN (ϕ, µ) incorporates the above new definitions and ideas, and
is represented in Figure 10. Considering the figure,
• the definition of ModelGenerate(µ) can be relaxed with respect to the definition provided in Subsection 4.1 in order to return the minimal form of a non-contradictory
and µ-satisfied term T such that
397

Giunchiglia, Narizzano & Tacchella

0 Ψ := {};
1 Θ := {};
2 function Q-DLL-LN (ϕ, µ)
3
Q := hthe prefix of ϕi;
4
Φ := hthe matrix of ϕi;
5
if (ha µ-contradicted clause C is in Φ ∪ Θi)
6
return C;
7
if (ha µ-satisfied term T is in Ψi)
8
return T ;
9
if (hthe matrix of ϕµ is emptyi) return ModelGenerate(µ);
10
if (hl is unit in (QhΨ, Φ, Θi)µ i)
11
W := ha constraint in Ψ ∪ Φ ∪ Θ which causes l to be unit in (QhΨ, Φ, Θi)µ i;
12
W R := Q-DLL-LN (ϕ, µ; l);
13
if (hl is existentiali and (hW R is a termi or l 6∈ W R)) return W R;
14
if (hl is universali and (hW R is a clausei or l 6∈ W R)) return W R;
15
W R := Rec-Resolve(QhΨ, Φ, Θi, W R, W, l, µ);
16
Learn(µ, W R);
17
return W R;
18
if (hl is monotone in (QhΨ, Φ, Θi)µ i) return Q-DLL-LN (ϕ, µ; l);
19
l := ha literal at the highest level in ϕµ i;
20
W R := Q-DLL-LN (ϕ, µ; l);
21
if (hl is existentiali and (hW R is a termi or l 6∈ W R)) return W R;
22
if (hl is universali and (hW R is a clausei or l 6∈ W R)) return W R;
23
W R0 := Q-DLL-LN (ϕ, µ; l);
24
if (hl is existentiali and (hW R0 is a termi or l 6∈ W R0 )) return W R0 ;
25
if (hl is universali and (hW R0 is a clausei or l 6∈ W R0 )) return W R0 ;
26
W R := Rec-Resolve(QhΨ, Φ, Θi, W R0 , W R, l, µ);
27
Learn(µ, W R);
28
return W R.
Figure 10: The algorithm of Q-DLL-LN.
– for each clause C ∈ Φ, C ∩ T 6= ∅; and
– for each universal literal l in µ assigned as monotone, l 6∈ T .
• Learn(µ, W R) updates the set of goods and nogoods according to a given policy. Here
we simply assume that Learn(µ, W R) updates Ψ and Θ to Ψ0 and Θ0 respectively, and
that Ψ0 and Θ0 satisfy the following conditions:
– Ψ0 is a subset of Ψ ∪ {W R} if W R is a term, and of Ψ otherwise;
– Θ0 is a subset of Θ ∪ {W R} if W R is a clause, and of Θ otherwise; and
– for each existential (resp. universal) literal l assigned as unit in an initial prefix
µ0 ; l of µ, Θ0 ∪ Φ (resp. Ψ0 ) still contains a clause (resp. term) that causes l to
be assigned as unit in (QhΨ0 , Φ, Θ0 i)µ0 .
398

Clause/Term Resolution and Learning for Quantified Boolean Formulas

With reference to Figure 9, this last condition is necessary in order to guarantee the
existence of a constraint W satisfying the condition at line 4.
The above conditions on Learn(µ, W R) are very general and ensure the soundness and
completeness of Q-DLL-LN.
Theorem 12 Q-DLL-LN(ϕ, ) returns the empty clause if ϕ is false, and the empty term
if ϕ is true.
Proof. Analogous to the proof of Theorem 11.



To understand the benefits of learning, assume the input QBF is (4). The corresponding
EQBF is
∃x1 ∀y∃x2 ∃x3 h{}, {{x1 , y, x2 }, {y, x2 }, {x2 , x3 }, {x1 , y, x3 }, {y, x2 , x3 }}, {}i,
and the search proceeds as in Figure 2, with the first path leading to the empty matrix,
which starts the term resolution process. Assuming the term min({y, x2 }) = {y} is added
to the set of goods before checking the value of ϕx1 ;y , as soon as x1 is assigned to true,
• y is detected to be unit and it is correspondingly assigned; and
• the path corresponding to the assignment x1 ; y is not explored.
As this example shows, (good) learning can avoid the useless exploration of some branches
that would be explored with a backtracking or backjumping schema. Indeed, we have been
assuming that the deduced term is learned while backtracking. A policy according to which
Learn(µ, W R) simply adds W R
• to Θ if W R is clause; and
• to Ψ otherwise,
can be easily implemented. However, such simple policy may easily lead to store an exponential number of goods and/or nogoods (notice that we have a call to Learn(µ, W R) for
each literal assigned as unit or right split). Thus, practical implementations incorporate
policies guaranteed to be space bounded, i.e., ones that store a polynomial number of goods
and nogoods at most. In SAT, the three most popular space bounded learning schemes are:
• Size learning of order n (Dechter, 1990): a nogood is added to Θ if and only if its
cardinality is less or equal to n. Once added, it is never deleted.
• Relevance learning of order n (Ginsberg, 1993): given a current assignment µ, a
nogood C is always added to Θ, and then it is deleted from Θ as soon as the number
of literals l in C and with l 6∈ µ is bigger than n.
• Unique Implication Point (UIP) based learning (Marques-Silva & Sakallah, 1996): a
nogood C is stored if and only if C contains only one literal at the maximum decision
level. Given an assignment µ, the decision level of a literal l in µ is the number of
splits done before l in µ. With UIP based learning, the set Θ of added clauses is
periodically inspected and clauses are deleted according to various criteria.
399

Giunchiglia, Narizzano & Tacchella

Thus, in size learning, once a nogood is stored, it is never deleted. In relevance and UIP
based learning, nogoods are dynamically added and deleted depending on the current assignment. See the work of Bayardo (1996) for more details related to size and relevance
learning (including their complexity analysis), and the work of Zhang, Madigan, Moskewicz
and Malik (2001) for a discussion of various UIP based learning mechanisms for SAT. Size,
relevance, UIP based learning are just a few of the various possibilities for limiting the
number of stored clauses, and each one can be generalized in various ways when considering
QBFs instead of SAT formulas. In the next section, we will present the particular learning
schema that we implemented in QuBE.

5. Implementation and Experimental Analysis
In this section we first describe in some details the implementation of nogood and good
learning in QuBE, and then we report on some experimental analysis conducted in order to
evaluate the (separate) benefits of nogood and good learning, but also the relative efficiency
of our solver when compared to other state-of-the-art QBF solvers.
5.1 Implementation in QuBE
To evaluate the benefits deriving from learning, we have implemented both good and nogood learning in QuBE. QuBE is a QBF solver based on search which, on non-random
instances, compares well with respect to other state-of-the-art solvers based on search, like
semprop (Letz, 2002), yquaffle (Zhang & Malik, 2002a), i.e., the best solvers based
on search on non-random instances according to (Le Berre, Simon, & Tacchella, 2003),
see (Giunchiglia, Narizzano, & Tacchella, 2004c) for more details.
Besides learning, the version of QuBE that we used features
• efficient detection of unit and monotone literals using lazy data structures as in (Gent,
Giunchiglia, Narizzano, Rowley, & Tacchella, 2004);
• a branching strategy that exploits information gleaned from the input formula initially,
and leverages the information extracted in the learning phase.
See (Giunchiglia, Narizzano, & Tacchella, 2004b) for a description of these characteristics.
As for learning, the computation of nogoods and goods corresponding to the internal
nodes of the search tree is carried out by doing clause and term resolution between a
“working reason” which is initialized when backtracking starts, and the “reasons” stored
while descending the search tree
• for each unit literal, the stored reason is a constraint in which the literal is unit;
• for each literal assigned as right split, the stored reason is the constraint computed
while backtracking on the left branch;
• for monotone literals, the way working reasons are initialized ensures that existential
(resp. universal) monotone literals never belong to a working reason computed while
backtracking from a contradiction (resp. solution).
400

Clause/Term Resolution and Learning for Quantified Boolean Formulas

Assume that µ = l1 ; l2 ; . . . ; lm is the assignment corresponding to the leaf under consideration. Considering the problem of initializing the working reason, the way we do it in
QuBE is to
• return a µ-contradicted clause in the matrix of the input QBF or in the set of learned
nogoods, if we have a contradiction; and
• compute the minimal form of a µ-satisfied prime implicant of the matrix which contains as few universal literals as possible, if we have a solution.
In the second case, the computation of a prime implicant is important in order to have short
reasons, while having as few as possible universal literals is important in order to backjump
nodes. The above requirements are met by recursively removing irrelevant literals from the
set of literals in µ, starting from the universals ones. Given a set S of literals, we say that
a literal is irrelevant in S if for each clause C in the matrix with l ∈ C there exists another
literal l0 in S with l0 V
∈ C. If prime(µ) is the set of literals being the result of the recursive
procedure, the term prime(µ)
• is satisfied by µ;
• is a prime implicant of the matrix of the input QBF;
• is such that there does not exist another term satisfying the first two properties and
with a smaller (under set inclusion) set of universal literals.
In order to further reduce the number of universal literals in the initial goods, we take
advantage of the fact that the assignment µ may be partial: For some literal l it may be
the case that neither l nor l is in µ. Then, we can use the existential literals not in µ,
and with level lower than the level of all the universal literals in µ assigned as left split, in
order to further reduce the number of universals in prime(µ). In fact, for any sequence µ0
of literals extending µ with existential literals, the set of universals in prime(µ0 ) is a subset
of prime(µ). For instance, considering the QBF (11) if µ = y 1 ; y2 ; x2 ; x3 , then
• prime(µ) is {y 1 , y2 , x2 , x3 }; and
• if we extend µ to µ0 = µ; x1 then prime(µ0 ) is {x1 , y2 , x2 , x3 }.
Finally, when evaluating which universal literals in µ are irrelevant, we follow the reverse
order in which they have been assigned, in order to try to backjump as high as possible in
the search tree.
As we said in the previous section, besides the problem of setting the initial working
reason, another problem with learning is that unconstrained storage of clauses (resp. terms)
obtained by the reasons of conflicts (resp. solutions) may lead to an exponential memory
blow up. In practice, it is necessary to introduce criteria
1. for limiting the constraints that have to be learned; and/or
2. for unlearning some of them.
401

Giunchiglia, Narizzano & Tacchella

The implementation of learning in QuBE works as follows. Assume that we are backtracking
on a literal l assigned at decision level n. The constraint corresponding to the reason for
the current conflict (resp. solution) is learned only if the following conditions are satisfied:
1. l is existential (resp. universal); and
2. all the assigned literals in the reason except l, are at a decision level strictly lower
than n; and
3. there are no open universal (resp. existential) literals in the reason that are before l
in the prefix.
Notice that these three conditions ensure that l is unit in the constraint corresponding
to the reason. Once QuBE has learned the constraint, it backjumps to the node at the
maximum decision level among the literals in the reason, excluding l. We say that l is
a Unique Implication Point (UIP) and therefore the lookback in QuBE is “UIP based”.
Notice that our definition of UIP generalizes to QBF the concepts first described by Silva
and Sakallah (1996) and used in the SAT solver grasp. On a SAT instance, QuBE lookback
scheme behaves similarly to the “1-UIP-learning” scheme used in zCHAFF (and described
in Zhang et al., 2001). Even if QuBE is guaranteed to learn at most one clause (resp. term)
per each conflict (resp. solution), still the number of learned constraints may blow up, as
the number of backtracks can be exponential. To stop this course, QuBE scans periodically
the set of learned constraints in search of those that became irrelevant, i.e., clauses (resp.
terms) where the number of open literals exceeds a parameter n, corresponding to the
relevance order. Thus, our implementation uses UIP based learning to decide when to store
a constraint, and a relevance based criteria to decide when to forget a constraint. In the
experimental analysis presented in the next subsection, the parameter n has been set to 20
and the set of learned constraints is scanned every 5000 nodes.
Besides the above learning mechanism, our current version of QuBE features lazy data
structures for unit literal detection and propagation (as described in Gent et al., 2004),
monotone literal fixing (as described in Giunchiglia et al., 2004a), and a Variable State Independent Decaying Sum heuristic (VSIDS) (as introduced in SAT by Moskewicz, Madigan,
Zhao, Zhang, & Malik, 2001). As in SAT, the basic ideas of our heuristic are to (i) initially
rank literals on the basis of the occurrences in the matrix, (ii) increment the weight of the
literals in the learned constraints, and (iii) periodically divide by a constant the weight of
each literal.
5.2 Experimental Results
To evaluate the effectiveness of our implementation, we considered the 450 formal verification and planning benchmarks that constituted part of the 2003 QBF solvers comparative
evaluation4 : 25% of these instances comes from verification problems (described in Scholl
& Becker, 2001; Abdelwaheb & Basin, 2000), and the remaining are from planning domains (described in Rintanen, 1999; Castellini, Giunchiglia, & Tacchella, 2001). We start
our analysis considering QuBE with and without learning enabled. Both versions of QuBE
4. With respect to the non-random instances used in the 2003 QBF comparative evaluation, our test set
does not include the QBF encodings of the modal K formulas submitted by Pan and Vardi (2003).

402

Clause/Term Resolution and Learning for Quantified Boolean Formulas

Figure 11: Effectiveness of learning: QuBE versus QuBE(cbj,sbj). CPU time (left) and
number of backtracks on the instances solved by both solvers (right).

compute goods and nogoods in order to backjump over irrelevant existential and universal
branching nodes. They differ in the treatment of the computed goods and nogoods:
• when learning is enabled, QuBE records both goods and nogoods;
• when learning is disabled, QuBE records neither nogoods nor goods.
We call the two versions QuBE(cln,sln) and QuBE(cbj,sbj) respectively, in order to
specify the type of look-back used by the two systems. Notice that we did not consider
QuBE with backtracking (i.e., the version which computes neither nogoods nor goods and
performs simple chronological backtracking) because it is not competitive with the other
solvers.
All the experiments were run on a farm of identical PCs, each one equipped with a
Pentium 4, 3.2GHz processor, 1GB of RAM, running Linux Debian (sarge). Finally,
each system had a timeout value of 900s per instance.
Figure 11 left shows the performances of QuBE(cln,sln) versus QuBE(cbj,sbj). In
the plot, the x-axis is the CPU-time of QuBE(cln,sln) and the y-axis is the CPU-time of
QuBE(cbj,sbj). A plotted point hx, yi represents a benchmark on which QuBE(cln,sln)
and QuBE(cbj,sbj) take x and y seconds respectively.5 For convenience, we also plot the
points hx, xi, each representing the benchmarks solved by QuBE(cln,sln) in x seconds.
The first observation is that learning pays off:
5. In principle, one point hx, yi could correspond to many benchmarks solved by QuBE(cln,sln) and
QuBE(cbj,sbj) in x and y seconds respectively. However, in this and in the other scatter diagrams that
we present, each point (except for the point h900, 900i, representing the instances on which both solvers
time-out) corresponds to a single instance in most cases.

403

Giunchiglia, Narizzano & Tacchella

Figure 12: Effectiveness of learning with a random heuristic: QuBE(rnd,cln,sln)[3] versus QuBE(rnd,cbj,sbj)[3]. CPU time (left) and number of backtracks on the
instances solved by both solvers (right).

• QuBE(cln,sln) (resp. QuBE(cbj,sbj)) is able to solve 16 (resp. 1) instances that
are not solved by QuBE(cbj,sbj) (resp. QuBE(cln,sln)); and
• among the instances solved by both solvers, QuBE(cln,sln) (resp. QuBE(cbj,sbj))
is at least one order of magnitude faster than QuBE(cbj,sbj) (resp. QuBE(cln,sln))
on 39 (resp. 0) instances.
In order to have an implementation-quality independent measure of the pruning introduced
by learning, the right plot in the figure shows the number of backtracks (i.e., the number
of solutions and conflicts found) of QuBE(cbj,sbj) versus QuBE(cln,sln) on the 358
problems solved by both systems. Here a plotted point hx, yi represents a benchmark
that is solved by QuBE(cln,sln) and QuBE(cbj,sbj) performing x and y backtracks
respectively. As it can be seen, learning substantially prunes the search space: There is no
point below the diagonal, meaning that it is never the case that QuBE(cbj,sbj) performs
less backtracks than QuBE(cln,sln).6 Still, learning has some overhead, and thus the
pruning caused by learning not always pays off in terms of speed, as proved by the few
points below the diagonal in the left plot.
The above experimental data are not entirely satisfactory for two reasons.
First, learning and the heuristic are tightly coupled in QuBE: Whenever QuBE learns a
constraint, it also increments the score of the literals in it. In QuBE(cbj,sbj) no constraint
6. This does not imply that the tree searched by QuBE(cln,sln) is a subtree of the tree searched by
QuBE(cbj,sbj): Indeed, the literal selected at each branching node by the two systems is not guaranteed
to be the same.

404

Clause/Term Resolution and Learning for Quantified Boolean Formulas

Figure 13: Effectiveness of conflict learning:
QuBE(rnd,cln,sln)[3] versus
QuBE(rnd,cbj,sln)[3]. CPU time (left) and number of conflict backtracks on
the instances solved by both solvers (right).

is ever learned. As a consequence, in QuBE(cbj,sbj), (i) literals are initially sorted on the
basis of their occurrences in the input QBF, and (ii) the score of each literal is periodically
halved until it becomes 0. When all the literals have score 0, then literals at the same prefix
level are chosen according to their lexicographic order.
Second, independently from the heuristic being used, a plot showing the performances of
QuBE with and without learning, does not say which of the two learning schemes (conflict,
solution) is effective (Gent & Rowley, 2004).
To address the first problem, we consider QuBE with a random heuristic, i.e., a heuristic
which randomly selects a literal among those at the maximum level and not yet assigned.
We call the resulting systems QuBE(rnd,cln,sln) and QuBE(rnd,cbj,sbj) respectively:
As the names suggest, the first has learning enabled, while in the second learning has been
disabled. Because of the randomness, we run each solver 5 times on each instance. Then,
we define QuBE(rnd,cln,sln)[i] to be the system whose performances are, on a each
instance, the i-th best among the 5 results obtained by running QuBE(rnd,cln,sln) on
that instance. QuBE(rnd,cbj,sbj)[i] is defined analogously.
Figure 12 shows the CPU time (left) and number of backtracks on the solved instances
(right) of QuBE(rnd,cln,sln)[3] and QuBE(rnd,cbj,sbj)[3]. From the plots, it is easy
to see that QuBE(rnd,cln,sln)[3] is faster than QuBE(rnd,cbj,sbj)[3] in most cases.
To witness this fact
• QuBE(rnd,cln,sln) (resp. QuBE(rnd,cbj,sbj)) is able to solve 21 (resp. 2) instances that are not solved by QuBE(cbj,sbj) (resp. QuBE); and
405

Giunchiglia, Narizzano & Tacchella

Figure 14: Effectiveness of solution learning:
QuBE(rnd,cln,sln)[3] versus
QuBE(rnd,cln,sbj)[3]. CPU time (left) and number of solution backtracks on the instances solved by both solvers (right).

• among the instances solved by both solvers, QuBE (resp. QuBE(cbj,sbj)) is at least
one order of magnitude faster than QuBE(cbj,sbj) (resp. QuBE) on 68 (resp. 2)
instances.
Still, it is no longer the case that enabling learning always causes a reduction in the number
of backtracks. This can be because of the different literals selected at each branching node,
but also because pruning a node may prevent a “long backjump” (Prosser, 1993a) which
would cause a vast reduction of the search space. Interestingly, comparing with the results
in Figure 11, it seems that with a random heuristic learning becomes more important. This
fact witnesses also in our setting the well known tension between look-ahead and look-back
techniques: A “smart” look-ahead makes the look-back less important, and viceversa.
To address the second problem, we considered the systems QuBE(rnd,cbj,sln) and
QuBE(rnd,cln,sbj), i.e., the systems obtained from QuBE(rnd,cln,sln) by disabling
conflict learning and solution learning respectively. As usual, each system was run 5 times
on each instance, and QuBE(rnd,cbj,sln)[i] and QuBE(rnd,cln,sbj)[i] (1 ≤ i ≤ 5)
are defined as before. The left plots in Figures 13 and 14 show the performances of
QuBE(rnd,cln,sln)[3] versus QuBE(rnd,cbj,sln)[3] and QuBE(rnd,cln,sbj)[3] respectively. We also measured the number of backtracks. However, in order to better
highlight the pruning due to conflict (resp. solution) learning, the right plot in Figure 13
(resp. 14) shows the number of conflict (resp. solution) backtracks of QuBE(rnd,cbj,sln)[3]
(resp. QuBE(rnd,cln,sbj)[3]). From the plots, we see that both conflict and solution
learning prune the search space and pay off: In each plot, there are only a few points
well below the diagonal. Comparing the two left plots, we also see that, on the test set
406

Clause/Term Resolution and Learning for Quantified Boolean Formulas

QuBE(rnd,cln,sln)[3]
QuBE(rnd,cln,sln)[1]
QuBE(rnd,cln,sln)[2]
QuBE(rnd,cln,sln)[4]
QuBE(rnd,cln,sln)[5]
QuBE(rnd,cbj,sbj)[1]
QuBE(rnd,cbj,sbj)[2]
QuBE(rnd,cbj,sbj)[3]
QuBE(rnd,cbj,sbj)[4]
QuBE(rnd,cbj,sbj)[5]
QuBE(rnd,cbj,sln)[1]
QuBE(rnd,cbj,sln)[2]
QuBE(rnd,cbj,sln)[3]
QuBE(rnd,cbj,sln)[4]
QuBE(rnd,cbj,sln)[5]
QuBE(rnd,cln,sbj)[1]
QuBE(rnd,cln,sbj)[2]
QuBE(rnd,cln,sbj)[3]
QuBE(rnd,cln,sbj)[4]
QuBE(rnd,cln,sbj)[5]

=
136
169
156
109
131
137
123
110
84
130
133
129
115
86
135
151
169
141
103

<
0
0
203
244
145
164
192
205
222
96
134
169
209
245
78
110
134
183
218

>
225
192
0
0
72
43
25
17
10
128
82
48
20
6
142
90
39
11
2


0
0
2
8
13
17
21
29
45
7
12
15
17
24
6
10
19
26
38


3
1
0
0
7
2
2
2
2
5
5
3
1
1
4
4
1
0
0

./
86
88
89
89
82
87
87
87
87
84
84
86
88
88
85
85
88
89
89

×10<
0
0
27
61
27
43
68
83
99
20
27
40
54
87
7
15
29
51
69

×0.1>
43
19
0
0
20
7
2
1
1
26
14
5
1
0
36
15
5
0
0

TO
86
88
91
97
95
104
108
116
132
91
96
101
105
112
91
95
107
115
127

Table 2: Comparison among various versions of QuBE. Each row compares a system written in the first column with respect to QuBE(rnd,cln,sln)[3] taken as reference.
If A is QuBE(rnd,cln,sln)[3] and B is a solver in the first column, then the other
columns report the number of problems that: “=”, A and B solve in the same
time; “<”, A and B solve but A takes less time than B; “>”, A and B solve but A
takes more time than B; “”, A solves while B does not; “”, A does not solve
while B does; “./”, A and B do not solve; “×10<”, both A and B solve but on
which A is at least one order of magnitude faster; “×0.1<”, both A and B solve
but on which A is at least one order of magnitude slower; “TO”, B does not solve.
The number of timeouts for QuBE(rnd,cln,sln)[3] is 89.
that we considered, solution learning helps in solving problems more than conflict learning:
QuBE(rnd,cbj,sln)[3] times out on 101 while QuBE(rnd,cln,sbj)[3] times out on 107.
On the other hand, the two right plots suggest that conflict learning prunes more than solution learning, but this conclusion is not correct. Indeed, each plot shows either the number
of conflicts or the number of solutions: Pruning a node (no matter whether existential or
universal) may avoid finding (exponentially many) solutions and/or conflicts. In particular,
given that all the instances are in CNF and thus have the form
. . . ∀y∃x1 ∃x2 . . . ∃xn Φ
(n ≥ 1) pruning any variable not in {x1 , x2 , . . . , xn } has the potential to prune 2n conflicts.
407

Giunchiglia, Narizzano & Tacchella

Some further and more detailed quantitative information about the CPU times is reported in Table 2. From the last column in the table we see that, if we indicate with TO(S)
the number of timeouts of system S, then, for each i ∈ {1, 2, 3, 4, 5},
TO(QuBE(rnd,cln,sln)[i]) <

TO(QuBE(rnd,cbj,sln)[i])
< TO(QuBE(rnd,cbj,sbj)[i]).
TO(QuBE(rnd,cln,sbj)[i])

The above gives an indication of the “capacity” of the solvers, i.e., of their ability to solve
problems. In order to get an indication of their “productivity”, i.e., considering the problems
that they solve, their ability to solve them quickly, we can consider the number FS(S) being
the difference between the “×0.1 >” and “10× <” columns: The lower FS(S) is, the better
S is. Here again we have
FS(QuBE(rnd,cln,sln)[i]) <

FS(QuBE(rnd,cbj,sln)[i])
< FS(QuBE(rnd,cbj,sbj)[i])
FS(QuBE(rnd,cln,sbj)[i])

for i ∈ {1, 2, 3, 4, 5}. From the above, it is clear that both conflict and solution learning
allow to improve on capacity and productivity. Our experimental results thus seem to
contradict the negative results reported in Gent’s and Rowley’s work (2004) for solution
based look-back mechanisms. However, those results are not comparable with ours, given
the different mechanisms implemented by the respective solvers (e.g., for computing the
initial solution and for monotone literal fixing), and the different experimental setting (e.g.,
the testset).

6. Conclusions and Related Work
This paper is based on and extends (Giunchiglia et al., 2002) which introduces nogood and
good learning for QBFs satisfiability. Here we show the correspondence between the computation trees searched by DLL based QBF solvers and clause/term resolution deductions.
Nogoods and goods are the clauses and terms respectively in the resolution deductions.
Under this perspective, learning simply amounts to storing nogoods and goods. We show
how to incorporate nogoods and goods learning in DLL based QBF solvers by considering
EQBFs (QBFs extended with learning), and then illustrate by means of examples that the
computation of nogoods and goods:
• allows for solution and conflict directed backjumping in the spirit of (Giunchiglia et al.,
2001, 2003); and
• if stored, allows for pruning branches in other parts of the search tree.
We present a high level description of algorithms incorporating such ideas, and formally
prove their soundness and completeness. We also discuss the problems related to effective
implementations in DLL based QBF solvers, and present (in some details) our implementation in QuBE, a state-of-the-art QBF solver. The experimental analysis shows that QuBE
enhanced with nogood and good learning is more effective, when considering a selection of
nonrandom problems consisting of planning and formal verification benchmarks. We also
show that QuBE is competitive with respect to the state of the art.
408

Clause/Term Resolution and Learning for Quantified Boolean Formulas

As we already said, our work builds on (Giunchiglia et al., 2002). Other papers dealing
with learning in QBFs satisfiability are (Letz, 2002), (Zhang & Malik, 2002a) and (Gent &
Rowley, 2004). In particular, in (Letz, 2002) conflict and solution learning are called lemma
and model caching. The paper also proposes a technique based on model caching for dealing with QBFs having variable-independent subformulas. Zhang and Malik (2002a) propose
conflict learning (which is then extended to solution learning in Zhang & Malik, 2002b). In
the second paper, terms are called cubes. Gent and Rowley (2004) introduce a new form
of solution learning: This new technique revisits less solutions than standard techniques,
but the experimental results reported in the paper are not positive. All these works share
the same intuitions and thus propose similar techniques. Though it is difficult to establish
a precise relation among these works due to the differences in the terminology and/or the
different level of detail in the presentations,7 we believe that the main differences are at the
implementation level, i.e., in the way solution and conflict learning have been implemented.
It is therefore quite difficult if not impossible to compare the different alternatives, without
re-implementing or recasting the different learning mechanisms or even the different solvers
in a common framework. Indeed, the specific learning mechanism implemented within a
solver may be motivated by the other characteristics of the solver, e.g., by the data structures being used or by the heuristic. For instance, watched data structures (used, e.g., in
QuBE, yquaffle but not in semprop) allow for more efficient detection and propagation of unit and pure literals (Gent et al., 2004). As a consequence, solvers with watched
data structures may profitably maintain huge databases for goods and nogoods. For solvers
with standard data structures, the costs involved in managing such huge databases may
overwhelm the advantages. Considering each of these solvers as a whole, the experimental
analysis conducted in (Giunchiglia et al., 2004c) shows that our solver QuBE compares
well with respect to semprop and yquaffle on the 450 formal verification and planning
benchmarks that we considered also in this paper.

Acknowledgments
We would like to thank Ian Gent and Andrew Rowley for discussions related to the subject
of this paper, and the anonymous reviewers for their suggestions and corrections. This work
has been partially supported by MIUR.

Appendix A. Proof of Lemma 4
The proof is by well founded induction. Thus, the steps we follow are:
1. the definition of a well founded order on tuples hC1 , C2 , l, µi;
2. the proof that the thesis holds for the minimal elements of the partial order; and
3. assuming that the thesis holds for all the tuples hC3 , C2 , l, µi such that hC3 , C2 , l, µi 
hC1 , C2 , l, µi, the proof that the thesis holds also for hC1 , C2 , l, µi.
7. For instance, in (Letz, 2002; Zhang & Malik, 2002b) but also in our initial work (Giunchiglia et al.,
2002), the method used for computing the initial working reason corresponding to a solution (procedure
ModelGenerate in Figure 10) is not detailed.

409

Giunchiglia, Narizzano & Tacchella

We have deliberately omitted what are the properties that the elements of the tuples
hC1 , C2 , l, µi in the partial order have to satisfy. Indeed, the standard assumption would be
that C1 and C2 be two clauses such that hC1 , C2 i is to be µ; l-Rec-C-Resolved. However,
this is not sufficient. Indeed, it may happen that starting from two clauses hC1 , C2 i to be
µ; l-Rec-C-Resolved (line numbers refer to Figure 6)
1. the set {l : l ∈ C1 , l ∈ C2 , l is universal} is not empty (see line 1);
2. the clause C3 computed as in line 5 of Figure 6 is not µ; l-contradicted; and thus
3. the tuple hC3 , C2 , l, µi is not an element of the partial order.
To better understand the problem, consider the following simple example:
∃x1 ∀y1 ∃x2 ∀y2 ∃x3 ∃x4 {{x4 }, {x2 , y2 , x4 }, {y 2 , x3 }, {x1 , y 1 , x3 }, {x1 , y1 , x2 , x3 }}.

(13)

For this QBF ϕ:
1. x4 ; x2 ; y2 ; x3 ; x1 is an assignment producing a contradictory clause;
2. h{x1 , y1 , x2 , x3 },{x1 , y 1 , x3 }i are to be x4 ; x2 ; y2 ; x3 ; x1 -Rec-C-Resolved;
3. Rec-C-Resolve(ϕ, {x1 , y1 , x2 , x3 }, {x1 , y 1 , x3 }, x1 , x4 ; x2 ; y2 ; x3 ; x1 ),
(a) causes a call to Rec-C-Resolve(ϕ, {x1 , y1 , y2 , x4 }, {x1 , y 1 , x3 }, x1 , x4 ; x2 ; y2 ; x3 ; x1 ),
in which the clause C3 = {x1 , y1 , y2 , x4 } is not x4 ; x2 ; y2 ; x3 ; x1 -contradicted; but
(b) returns the clause {y 1 , x3 } which is x4 ; x2 ; y2 ; x3 ; x1 -contradicted, as expected.
The fact that the universal literal y2 which causes C3 not to be x4 ; x2 ; y2 ; x3 ; x1 -contradicted
does not appear in the clause returned by Rec-C-Resolve is due to the following two facts:
1. y2 has a lower level than the blocking literal y1 ; and
2. the negation of all the existential literals in C3 with a level lower than y2 are assigned
before y2 in x4 ; x2 ; y2 ; x3 ; x1 .
To formally define these notions, we need some additional notation. First, consider a
given clause C2 . ResC2 (C1 ) is the set of literals in C1 with a level lower than a literal
blocking the resolution between C1 and C2 . Formally:
ResC2 (C1 ) = {l : l ∈ C1 , ∃l0 ∈ BlockingC2 (C1 )level(l) < level(l0 )},
where
• for each literal l, level(l) is the prefix level of l; and
• BlockingC2 () is the function defined by
BlockingC2 (C1 ) = {l : l ∈ C1 , l ∈ C2 , l is universal}
Let µ be an assignment. We say that a clause C1 is µ-contradictable (with respect to
C2 ) if
410

Clause/Term Resolution and Learning for Quantified Boolean Formulas

1. for each existential literal l in C1 , l is in µ;
2. for each universal literal l in C1 , if l is in µ then
(a) l ∈ ResC2 (C1 ); and
(b) for each existential literal l0 in C1 , if level(l0 ) < level(l) then l0 is to the left of l
in µ.
Clearly, if a clause is µ-contradicted then it is also µ-contradictable. Considering the QBF
(13), the clause {x1 , y1 , y2 , x4 } is not x4 ; x2 ; y2 ; x3 ; x1 -contradicted; but is x4 ; x2 ; y2 ; x3 ; x1 contradictable (with respect to {x1 , y 1 , x3 }).
Our well founded order and induction will be on the set of tuples hC1 , C2 , l, µi in which
C1 is µ; l-contradictable. As a preliminary step, we first define the well founded order on
literals according to which l0  l00 if and only if either l0 = l00 or both l0 and l00 are in µ and
l0 has been assigned before l00 in µ (i.e., l0 is to the left of l00 in µ).
We extend the partial order relation  from literals to clauses (i) in minimal form, (ii)
containing l, and (iii) µ; l-contradictable, by saying that for two such clauses C1 and C3 ,
C3  C1 if
• either C3 = C1 ;
E
E
E
E
00
0
00
• or ∃l0 ∈ (ResE
C2 (C1 )\ResC2 (C3 ))∀l ∈ (ResC2 (C3 )\ResC2 (C1 ))l  l , where ResC2 (C1 )
is the subset of existential literals in ResC2 (C1 ), and similarly for ResE
C2 (C3 ).

The above order is well founded, and the minimal elements are such that ResC2 (C) (or,
equivalently, BlockingC2 (C)) is empty.
Finally, consider the set W of tuples hC1 , C2 , l, µi such that
1. µ; l is an assignment;
2. l is an existential literal which is either unit or at the highest level in ϕµ ;
3. C1 is a clause containing l, in minimal form and µ; l-contradictable with respect to
C2 ;
4. C2 contains l, is in minimal form and is µ; l-contradicted. Further, if l is unit in ϕµ ,
then C2 is a clause which causes l to be unit in ϕµ .
On such set, we define a well founded order according to which hC3 , C2 , l, µi  hC1 , C2 , l, µi
if C3  C1 .
Now consider the procedure Rec-C-Resolve in Figure 6. We prove by well founded
induction that, for each tuple hC1 , C2 , l, µi ∈ W , Rec-C-Resolve(ϕ, C1 , C2 , l, µ) terminates
and returns a clause C in minimal form and µ-contradicted. At the end, we will also show
that if we further assume that C1 is µ; l-contradicted (and not simply µ; l-contradictable),
then C does not contain existential literals whose negation has been assigned as monotone
in µ.
In the base case, C1 is such that ResC2 (C1 ) is empty. Hence, for each universal literal
l ∈ C1 , l is not in µ and thus C1 is µ; l-contradicted. Since ResC2 (C1 ) is empty, the set S
computed at line 1 is empty and thus Rec-C-Resolve(ϕ, C1 , C2 , l, µ) terminates returning
411

Giunchiglia, Narizzano & Tacchella

the resolvent C of C1 and C2 . Clearly C is in minimal form, and it is easy to show that C
is µ-contradicted.
For the step case, by induction hypothesis, we have that the thesis holds for Rec-CResolve(ϕ, C3 , C2 , l, µ) and we have to show that it holds also for Rec-C-Resolve(ϕ, C1 , C2 , l, µ),
assuming hC3 , C2 , l, µi  hC1 , C2 , l, µi. If the set ResC2 (C1 ) is empty, then see the base case.
Assume that ResC2 (C1 ) is not empty, and thus that also BlockingC2 (C1 ) is not empty.
From here on, let l0 be a literal in BlockingC2 (C1 ) with the highest level. l0 is not in µ
because l0 6∈ ResC2 (C1 ) and C1 is µ; l-contradictable. l0 is not in µ because l0 ∈ C2 and C2
is µ; l-contradicted. Further, level(l0 ) < level(l). To see why, consider the only two possible
cases:
1. l is unit in ϕµ : Since l0 ∈ C2 , and C2 is a clause which causes l to be unit in ϕµ , it
must be level(l0 ) = level(l0 ) < level(l).
2. l is at the highest level in ϕµ : Since both l0 and l0 are not in µ and l is at the highest
level in ϕµ , level(l0 ) ≤ level(l). On the other hand, level(l0 ) 6= level(l) because l0 is
universal and l is existential.
Since C1 is in minimal form, there exists an existential literal l00 such that l00 ∈ C1 , l00 is
in µ, and with level(l00 ) < level(l0 ) < level(l). From here on, let l1 be an existential literal
in C1 (not necessarily distinct from l00 ) with level less than or equal to the level of all the
literals in C1 (see line 3). Since
level(l1 ) < level(l0 ) < level(l)

(14)

and l1 is in µ (because C1 is µ; l-contradictable), it follows that l1 has been assigned as unit,
and thus there exists a clause C in ϕ which causes l1 to be unit in ϕµ0 , where µ0 ; l1 is an
initial prefix of µ (see line 4).
Consider the set
BlockingC (C1 ) = {l : l ∈ C1 , l ∈ C, l is universal}.
BlockingC (C1 ) is empty. In fact, for each universal literal l00 ∈ C
• if level(l00 ) < level(l1 ) then l00 6∈ C1 since C1 is in minimal form;
• if level(l00 ) > level(l1 ) then l00  l1 . Assume that l00 ∈ C1 . Since C1 is µ; l-contradictable,
l1  l00 . However, l00  l1 and l1  l00 is not possible because l1 6= l00 (l1 is existential
and l00 is universal).
Since BlockingC (C1 ) is empty, we can resolve C and C1 on l1 , obtaining
C3 = min((C1 ∪ C) \ {l1 , l1 })
as resolvent. C3 is in minimal form and it contains l.
To show that C3  C1 it remains to be showed that C3 is µ; l-contradictable. Indeed,
for each existential literal l in C3 , l is in µ, while for the universal literals in C3 , consider
the two cases:
412

Clause/Term Resolution and Learning for Quantified Boolean Formulas

1. BlockingC2 (C3 ) is not empty. In this case, l0 ∈ BlockingC2 (C3 ). This is an easy
consequence of the following facts:
(a) for each literal l00 ∈ BlockingC2 (C), level(l00 ) < level(l0 ): l00 ∈ C2 by definition of
BlockingC2 (C), hence l00 is not in µ because C2 is µ; l-contradicted, and therefore
level(l00 ) < level(l1 ), and thus the thesis (see (14));
(b) BlockingC2 (C3 ) = (BlockingC2 (C1 )∪BlockingC2 (C))∩C3 and thus (BlockingC2 (C1 )∪
BlockingC2 (C)) \ BlockingC2 (C3 ) = (C ∪ C1 ) \ ({l1 , l1 } ∪ C3 ), i.e., the literals in
BlockingC2 (C1 ) ∪ BlockingC2 (C) and not in BlockingC2 (C3 ) are those that have
been omitted because of the minimal form of C3 ;
(c) BlockingC2 (C3 ) is not empty.
Since l0 ∈ BlockingC2 (C3 ), the literals in ResC2 (C1 ) which are also in C3 , also belong
to ResC2 (C3 ), i.e.,
ResC2 (C3 ) ⊇ ResC2 (C1 ) ∩ C3 .
(15)
Now consider a universal literal l00 ∈ C1 ∩ C3 . If l00 is in µ then
(a) l00 ∈ ResC2 (C1 ) because C1 is µ; l-contradictable, and hence l00 ∈ ResC2 (C3 )
(see (15));
(b) for each existential literal l000 in C1 , if level(l000 ) < level(l00 ) then l000  l00 because
C1 is µ; l-contradictable;
(c) for each existential literal l000 6= l1 in C, l000  l00 . In fact, level(l1 ) < level(l00 ),
l1  l00 because C1 is µ; l-contradictable, and for each existential literal l000 6= l1 ∈
C, l000  l1 .
Finally, consider a universal literal l00 ∈ C ∩ C3 . If l00 is in µ then level(l00 ) < level(l1 )
and hence
(a) l00 ∈ ResC2 (C3 ) because level(l1 ) < level(l0 ) (see (14)); and
(b) for each existential literal l000 ∈ C3 , if level(l000 ) < level(l00 ) then l000 ∈ C and hence
l000  l00 .
2. BlockingC2 (C3 ) is empty. Let m be the lowest among the level of the literals in C3 .
level(l0 ) < m since l0 6∈ C3 . Then, for each universal literal l00 ∈ C3 , l00 is not in µ, i.e.,
C3 is µ; l-contradicted. In fact, assume that there exists a universal literal l00 ∈ C3 in
µ. Then, level(l00 ) > m and either l00 ∈ C1 or l00 ∈ C. Consider the first case l00 ∈ C1 .
Then, l00 ∈ ResC2 (C1 ) because C1 is µ; l-contradictable, and then level(l00 ) < level(l0 ).
But this is not possible because level(l00 ) > m and level(l0 ) < m. Consider the case
l00 ∈ C. Then, level(l00 ) < level(l1 ) and hence level(l00 ) < level(l0 ) (see (14)) which is
again not possible.
Since C3  C1 , hC3 , C2 , l, µi  hC1 , C2 , l, µi, we can conclude by induction hypothesis that
Rec-C-Resolve(ϕ, C3 , C2 , l, µ) returns a clause in minimal form and µ-contradicted.
413

Giunchiglia, Narizzano & Tacchella

Now we make the further assumption that the input clause C1 is µ; l-contradicted.
Then, C1 does not contain existential literals whose negation has been assigned as monotone, and the same holds for C2 and for each clause C used at line 5. Hence, Rec-CResolve(ϕ, C3 , C2 , l, µ) returns a clause without existential literals whose negation has been
assigned as monotone in µ.

References
Abdelwaheb, A., & Basin, D. (2000). Bounded model construction for monadic second-order
logics. In 12th International Conference on Computer-Aided Verification (CAV’00),
No. 1855 in Lecture Notes in Computer Science, pp. 99–113, Chicago, USA. SpringerVerlag.
Bachmair, L., & Ganzinger, H. (2001). Resolution theorem proving. In Robinson, A., &
Voronkov, A. (Eds.), Handbook of Automated Reasoning, Vol. I, chap. 2, pp. 19–99.
Elsevier Science.
Bayardo, Jr., R. J., & Schrag, R. C. (1997). Using CSP look-back techniques to solve
real-world SAT instances. In Proceedings of the 14th National Conference on Artificial Intelligence and 9th Innovative Applications of Artificial Intelligence Conference
(AAAI-97/IAAI-97), pp. 203–208, Menlo Park. AAAI Press.
Bayardo, Jr., Roberto J., & Miranker, D. P. (1996). A complexity analysis of space-bounded
learning algorithms for the constraint satisfaction problem. In Proceedings of the
Thirteenth National Conference on Artificial Intelligence and the Eighth Innovative
Applications of Artificial Intelligence Conference, pp. 298–304, Menlo Park. AAAI
Press / MIT Press.
Cadoli, M., Schaerf, M., Giovanardi, A., & Giovanardi, M. (2002). An algorithm to evaluate
quantified Boolean formulae and its experimental evaluation. Journal of Automated
Reasoning, 28, 101–142.
Cadoli, M., Giovanardi, A., & Schaerf, M. (1998). An algorithm to evaluate Quantified
Boolean Formulae. In Proceedings of the 15th National Conference on Artificial Intelligence (AAAI-98) and of the 10th Conference on Innovative Applications of Artificial
Intelligence (IAAI-98), pp. 262–267, Menlo Park. AAAI Press.
Castellini, C., Giunchiglia, E., & Tacchella, A. (2001). Improvements to SAT-based conformant planning. In Proc. ECP.
Castellini, C., Giunchiglia, E., & Tacchella, A. (2003). SAT-based planning in complex
domains: Concurrency, constraints and nondeterminism. Artificial Intelligence, 147 (12), 85–117.
Davis, M., Logemann, G., & Loveland, D. W. (1962). A machine program for theorem
proving. Communication of ACM, 5 (7), 394–397.
de la Tour, T. B. (1990). Minimizing the Number of Clauses by Renaming. In Proc. of the
10th Conference on Automated Deduction, pp. 558–572. Springer-Verlag.
Dechter, R. (1990). Enhancement schemes for constraint processing: Backjumping, learning,
and cutset decomposition. Artificial Intelligence, 41 (3), 273–312.
414

Clause/Term Resolution and Learning for Quantified Boolean Formulas

Fermüller, C. G., Leitsch, A., Hustadt, U., & Tammet, T. (2001). Resolution decision procedures. In Robinson, A., & Voronkov, A. (Eds.), Handbook of Automated Reasoning,
Vol. II, chap. 25, pp. 1791–1849. Elsevier Science B.V.
Gent, I., Giunchiglia, E., Narizzano, M., Rowley, A., & Tacchella, A. (2004). Watched data
structures for QBF solvers. In Giunchiglia, E., & Tacchella, A. (Eds.), Theory and
Applications of Satisfiability Testing, 6th International Conference, SAT 2003. Santa
Margherita Ligure, Italy, May 5-8, 2003 Selected Revised Papers, Vol. 2919 of Lecture
Notes in Computer Science, pp. 25–36. Springer.
Gent, I. P., & Rowley, A. G. (2004). Solution learning and solution directed backjumping revisited. Tech. rep. APES-80-2004, APES Research Group. Available from
http://www.dcs.st-and.ac.uk/˜apes/apesreports.html.
Ginsberg, M. L. (1993). Dynamic backtracking. Journal of Artificial Intelligence Research,
1, 25–46.
Giunchiglia, E., Narizzano, M., & Tacchella, A. (2001). Backjumping for quantified Boolean
logic satisfiability. In Proc. of the International Joint Conference on Artificial Intelligence (IJCAI’2001).
Giunchiglia, E., Narizzano, M., & Tacchella, A. (2002). Learning for Quantified Boolean
Logic Satisfiability. In Proceedings of the Eighteenth National Conference on Artificial
Intelligence and Fourteenth Conference on Innovative Applications of Artificial Intelligence, July 28 - August 1, 2002, Edmonton, Alberta, Canada. AAAI Press, 2002,
pp. 649–654.
Giunchiglia, E., Narizzano, M., & Tacchella, A. (2003). Backjumping for Quantified Boolean
Logic Satisfiability. Artificial Intelligence, 145, 99–120.
Giunchiglia, E., Narizzano, M., & Tacchella, A. (2004a). Monotone literals and learning
in QBF reasoning. In Tenth International Conference on Principles and Practice of
Constraint Programming, CP 2004, pp. 260–273.
Giunchiglia, E., Narizzano, M., & Tacchella, A. (2004b). Qbf reasoning on real-world instances. In Theory and Applications of Satisfiability Testing, 7th International Conference, SAT 2004, Vancouver, BC, Canada, May 10-13, 2004, Revised Selected Papers,
pp. 105–121.
Giunchiglia, E., Narizzano, M., & Tacchella, A. (2004c). Qube++: An efficient qbf solver. In
5th International Conference on Formal Methods in Computer-Aided Design, FMCAD
2004, pp. 201–213.
Kleine-Büning, H., Karpinski, M., & Flögel, A. (1995). Resolution for quantified Boolean
formulas. Information and Computation, 117 (1), 12–18.
Le Berre, D., Simon, L., & Tacchella, A. (2003). Challenges in the QBF arena: the SAT’03
evaluation of QBF solvers. In Sixth International Conference on Theory and Applications of Satisfiability Testing (SAT 2003), Vol. 2919 of LNCS. Springer Verlag.
Letz, R. (2002). Lemma and model caching in decision procedures for quantified Boolean
formulas. In Proceedings of Tableaux 2002, LNAI 2381, pp. 160–175. Springer.
415

Giunchiglia, Narizzano & Tacchella

Marques-Silva, J. P., & Sakallah, K. A. (1996). GRASP - A New Search Algorithm for
Satisfiability. In Proceedings of IEEE/ACM International Conference on ComputerAided Design, pp. 220–227.
Moskewicz, M. W., Madigan, C. F., Zhao, Y., Zhang, L., & Malik, S. (2001). Chaff: Engineering an Efficient SAT Solver. In Proceedings of the 38th Design Automation
Conference (DAC’01), pp. 530–535.
Pan, G., & Vardi, M. Y. (2003). Optimizing a BDD-based modal solver. In Automated
Deduction - CADE-19, 19th International Conference on Automated Deduction Miami
Beach, FL, USA, July 28 - August 2, 2003, Proceedings, pp. 75–89.
Plaisted, D., & Greenbaum, S. (1986). A Structure-preserving Clause Form Translation.
Journal of Symbolic Computation, 2, 293–304.
Prosser, P. (1993a). Domain filtering can degrade intelligent backjumping search. In Proceedings of the 13th International Joint Conference on Artificial Intelligence (IJCAI99-Vol2), pp. 262–267.
Prosser, P. (1993b). Hybrid algorithms for the constraint satisfaction problem. Computational Intelligence, 9 (3), 268–299.
Rintanen, J. (1999). Constructing conditional plans by a theorem prover. Journal of Artificial Intelligence Research, 10, 323–352.
Robinson, A. (1965). A machine-oriented logic based on the resolution principle. Journal
of the ACM, 12 (1), 23–41.
Robinson, A. (1968). The generalized resolution principle. In Machine Intelligence, Vol. 3,
pp. 77–93. Oliver and Boyd, Edinburgh.
Scholl, C., & Becker, B. (2001). Checking equivalence for partial implementations. In
Proceedings of the 38th Design Automation Conference (DAC’01), pp. 238–243.
Tseitin, G. (1970). On the complexity of proofs in propositional logics. Seminars in Mathematics, 8.
Urquhart, A. (1995). The complexity of propositional proofs. The Bulletin of Symbolic
Logic, 1 (4), 425–467.
Zhang, L., Madigan, C. F., Moskewicz, M. W., & Malik, S. (2001). Efficient conflict driven
learning in a Boolean satisfiability solver. In International Conference on ComputerAided Design (ICCAD’01), pp. 279–285.
Zhang, L., & Malik, S. (2002a). Conflict driven learning in a quantified Boolean satisfiability solver. In Proceedings of International Conference on Computer Aided Design
(ICCAD’02).
Zhang, L., & Malik, S. (2002b). Towards a symmetric treatment of satisfaction and conflicts
in quantified Boolean formula evaluation. In Proceedings of the Eighth International
Conference on Principles and Practice of Constraint Programming, pp. 200–215.

416

Journal of Artificial Intelligence Research 26 (2006) 247–287

Submitted 01/06; published 07/06

How the Landscape of Random Job Shop Scheduling
Instances Depends on the Ratio of Jobs to Machines
Matthew J. Streeter
Stephen F. Smith

matts@cs.cmu.edu
sfs@cs.cmu.edu

Carnegie Mellon University
5000 Forbes Avenue, Pittsburgh, PA, 15213 USA

Abstract
We characterize the search landscape of random instances of the job shop scheduling
problem (JSP). Specifically, we investigate how the expected values of (1) backbone size,
(2) distance between near-optimal schedules, and (3) makespan of random schedules vary
N
N
N
as a function of the job to machine ratio ( M
). For the limiting cases M
→ 0 and M
→∞
N
we provide analytical results, while for intermediate values of M we perform experiments.
N
N
We prove that as M
→ 0, backbone size approaches 100%, while as M
→ ∞ the backbone
N
N
vanishes. In the process we show that as M → 0 (resp. M → ∞), simple priority rules
almost surely generate an optimal schedule, providing theoretical evidence of an “easyhard-easy” pattern of typical-case instance difficulty in job shop scheduling. We also draw
connections between our theoretical results and the “big valley” picture of JSP landscapes.

1. Introduction
1.1 Motivations
The goal of this work is to provide a picture of the typical landscape of a random instance
of the job shop scheduling problem (JSP), and to determine how this picture changes as
N
a function of the job to machine ratio ( M
). Such a picture is potentially useful in (1)
N
understanding how typical-case instance difficulty varies as a function of M
and (2) designing
or selecting search heuristics that take advantage of regularities in typical instances of the
JSP.

1.1.1 Understanding instance difficulty as a function of

N
M

The job shop scheduling literature contains much empirical evidence that square JSPs (those
N
with M
= 1) are more difficult to solve than rectangular instances (Fisher & Thompson,
1963). This work makes both theoretical and empirical contributions toward understanding
this phenomenon. Empirically, we show that both random schedules and random local
N
≈ 1. Analytically, we prove that in the two
optima are furthest from optimality when M
N
N
limiting cases ( M → 0 and M → ∞) there exist simple priority rules that almost surely
produce an optimal schedule, providing theoretical evidence of an “easy-hard-easy” pattern
of instance difficulty in the JSP.
c
2006
AI Access Foundation. All rights reserved.

Streeter & Smith

1.1.2 Informing the design of search heuristics
Heuristics based on local search, for example tabu search (Glover & Laguna, 1997; Nowicki
& Smutnicki, 1996) and iterated local search (Lourenço, Martin, and Stützle, 2003), have
shown excellent performance on benchmark instances of the job shop scheduling problem
(Jain & Meeran, 1998; Jones & Rabelo, 1998). In order to design an effective heuristic, one
must (explicitly or implicitly) make assumptions about the search landscape of instances
to which the heuristic will be applied. For example, Nowicki and Smutnicki motivate the
use of path relinking in their state-of-the-art i-TSAB algorithm by citing evidence that the
JSP has a “big valley” distribution of local optima (Nowicki & Smutnicki, 2005). One of
the conclusions of our work is that the typical landscape of random instances can only be
N
N
thought of as a big valley for values of M
close to 1; for larger values of M
(including values
common in benchmark instances), the landscape breaks into many big valleys, suggesting
that modifications to i-TSAB may allow it to better handle this case (we discuss i-TSAB
further in §9.3).
1.2 Contributions
The contributions of this paper are twofold. First, we design a novel set of experiments and
run these experiments on random instances of the JSP. Second, we derive analytical results
that confirm and provide insight into the trends suggested by our experiments.
The main contributions of our empirical work are as follows.
N
, we show that low-makespan schedules are clustered in a small
• For low values of M
region of the search space and many attributes (i.e., directed disjunctive graph edges)
N
are common to all low-makespan schedules. As M
increases, low-makespan schedules
become dispersed throughout the search space and there are no attributes common
to all low-makespan schedules.

• We introduce a statistic (neighborhood exactness) that can be used to quantitatively
measure the “smoothness” of a search landscape, and estimate the expected value of
this statistic for random instances of the JSP. These results, in combination with the
results on clustering, suggest that the landscape of typical instances of the JSP can
N
N
be described as a big valley only for low values of M
; for high values of M
there are
many separate big valleys.
For the limiting cases
we prove that

N
M

→ 0 and

N
M

→ ∞, we derive analytical results. Specifically,

N
• as M
→ 0, the expected size of the backbone (i.e., the set of problem variables that
N
have a common value in all global optima) approaches 100%, while as M
→ ∞, the
expected backbone size approaches 0%; and
N
N
• as M
→ 0 (resp. M
→ ∞), a randomly generated schedule will almost surely (a) be
located “close” in the search space to an optimal schedule and (b) have near-optimal
makespan.

248

The Landscape of Random Job Shop Scheduling Instances

2. Related Work
There are at least three threads of research that have conducted search space analyses
related to the ones we conduct here. These include literature on the “big valley” distribution
common to a number of combinatorial optimization problems, studies of backbone size in
Boolean satisfiability, and a statistical mechanical analysis of the TSP. We briefly review
these three areas below, as well as relevant work on phase transitions and the “easy-hardeasy” pattern of instance difficulty.
2.1 The Big Valley
The term “big valley” originated in a paper by Boese et al. (1994) that examined the
distribution of local optima in the Traveling Salesman Problem (TSP). Based on a sample
of local optima obtained by next-descent starting from random TSP tours, Boese calculated
two correlations:
1. the correlation between the cost of a locally optimal tour and its average distance to
other locally optimal tours, and
2. the correlation between the cost of a locally optimal tour and the distance from that
tour to the best tour in the sample.
The distance between two TSP tours was defined as the total number of edges minus
the number of edges that are common to the two tours. Based on the fact that both of
these correlations were surprisingly high, Boese conjectured that local optima in the TSP
are arranged in a “big valley”. Adapted from the work of Boese et al. (1994), Figure 1
gives “an intuitive picture of the big valley, in which the set of local minima appears convex
with one central global minimum” (Boese et al., 1994). We offer a more formal definition
of a big valley landscape in §6.
Boese’s analysis has been applied to other combinatorial problems (Kim & Moon, 2004),
including the permutation flow shop scheduling problem (Watson, Barbulescu, Whitley, &
Howe, 2002; Reeves & Yamada, 1998) and the JSP (Nowicki & Smutnicki, 2001). Correlations observed for the JSP are generally weaker than those observed for the TSP.
In a related study, Mattfeld (1996) examined cost-distance correlations in the famous
JSP instance ft10 (Beasley, 1990) and found evidence of a “Massif Central. . . where many
near optimal solutions reside laying closer together than other local optima.” §4 contains
related results on the backbone size of ft10.
2.2 Backbone Size
The backbone of a problem instance is the set of variables that are assigned a common value
in all globally optimal solutions of that instance. For example, in the Boolean satisfiability
problem (SAT), the backbone is the set of variables that are assigned a fixed truth value
in all satisfying assignments. In the JSP, the backbone has been defined as the number of
disjunctive edges (§3.2) that have a common orientation in all globally optimal schedules
(a formal definition is given in §4).
There is a large literature on backbones in combinatorial optimization problems, including many empirical and analytical results (Slaney & Walsh, 2001; Monasson, Zecchina,
249

Streeter & Smith

Figure 1: An intuitive picture of a “big valley” landscape.
Kirkpatrick, Selman, & Troyansky, 1999). In an analysis of problem difficulty in the JSP,
Watson et al. (2001) present histograms of backbone size for random 6x6 (6 job, 6 machine)
and 6x4 (6 job, 4 machine) JSP instances. Summarizing experiments not reported in their
paper, Watson et al. note that “For [job:machine ratios] > 1.5, the bias toward small backbones becomes more pronounced, while for ratios < 1, the bias toward larger backbones
is further magnified.” §4 generalizes these observations and proves two theorems that give
insight into why this phenomenon occurs.
2.3 Statistical Mechanical Analyses
A large and growing literature applies techniques from statistical mechanics to the analysis
of combinatorial optimization problems (Martin, Monasson, & Zecchina, 2001). At least
one result obtained in this literature concerns clustering of low-cost solutions. In a study of
the TSP, Mézard and Parisi (1986) obtain an expression for the expected overlap (number
of common edges) between random TSP tours drawn from a Boltzmann distribution. They
show that as the temperature parameter of the Boltzmann distribution is lowered (placing
more probability mass on low-cost TSP tours), expected overlap approaches 100%. Though
we do not use a Boltzmann weighting, §5 of this paper examines how expected overlap
between random JSP schedules changes as more probability mass is placed on low-makespan
schedules.
2.4 Phase Transitions and the Easy-hard-easy Pattern
Loosely speaking, a phase transition occurs in a system when the expected value of some
statistic varies discontinuously (asymptotically) as a function of some parameter. As an
example, for any  > 0 it holds that random instances of the 2-SAT problem are satisfiable
with probability asymptotically approaching 1 when the clause to variable ratio ( m
n ) is 1−,
but are satisfiable with probability approaching 0 when the clause to variable ratio is 1 + .
A similar statement is conjectured to hold for 3-SAT; the critical value k of m
n (if it exists)
must satisfy 3.42 ≤ k ≤ 4.51 (Achlioptas & Peres, 2004).
For some problems that exhibit phase transitions (notably 3-SAT), average-case instance
difficulty (for typical solvers) appears to first increase and then decrease as one increases
the relevant parameter, with the hardest instances appearing close to the threshold value
250

The Landscape of Random Job Shop Scheduling Instances

(A) JSP instance

J1 :

J11

J 12

J 2 : J12
€
€

€
€

€
€

J 13

J 22
€

(B) JSP schedule

J 14

J 32

J 42

€

€

J11

€

€

J12

J 22

€

€ time

(C) Disjunctive
€
€graph
€

€

J11

J 12

J 13

J 32

J 14
J 42

€

J 14
o*

o∅

J12
€

J 12 J 13

€

J 22
€

J 32
€

J 42

Figure 2: (A) A JSP instance,
€
€(B) a€feasible€schedule for the instance, and (C) the disjunctive graph representation of the schedule. Boxes represent operations; operation
durations are proportional to the width of a box; and the machine on which an
operation is performed is represented by texture. In (C), solid arrows represent
conjunctive arcs and dashed arrows represent disjunctive arcs (arc weights are
proportional to the duration of the operation the arc points out of).

(Cheeseman, Kanefsky, & Taylor, 1991; Yokoo, 1997). This phenomenon has been referred
to as an “easy-hard-easy” pattern of instance difficulty (Mammen & Hogg, 1997). In §7.4
we discuss evidence of an easy-hard-easy pattern of instance difficulty in the JSP, though
(to our knowledge) it is not associated with any phase transition.
The results in §§4-5 and the empirical results in §6 were previously presented in a conference paper (Streeter & Smith, 2005a).

3. The Job Shop Scheduling Problem
We adopt the notation [n] ≡ {1, 2, . . . , n}.
3.1 Problem Definition
Definition (JSP instance). An N by M JSP instance I = {J 1 ,J 2 , . . . , J N } is a set of N
k ) is a sequence of M operations. Each operation
jobs , where each job J k = (J1k , J2k , . . . , JM
k
o = Ji has an associated duration τ (o) ∈ (0, τmax ] and machine m(o) ∈ [M ]. We require
that each job uses each machine exactly once (i.e., for each J k ∈ I and m̄ ∈ [M ], there is
exactly one i ∈ [M ] such that m(Jik ) = m̄). We define
1. ops(I) ≡ {Jik : k ∈ [N ], i ∈ [M ]},
2. τ (J k ) ≡

PM

k
i=1 τ (Ji ),

and
251

Streeter & Smith

3. the job-predecessor J (Jik ) of an operation Jik as
J (Jik )


≡

k
Ji−1
o∅

if i > 1
otherwise

where o∅ is a fictitious operation with τ (o∅ ) = 0 and m(o∅ ) undefined.
Definition (JSP schedule). A JSP schedule for an instance I is a function S : ops(I) →
<+ that associates with each operation o ∈ ops(I) a start time S(o) (operation o is performed
on machine m(o) from time S(o) to time S(o) + τ (o); preemption is not allowed). We make
the following definitions.
1. The completion time of an operation o is S + (o) ≡ S(o) + τ (o).
2. The machine-predecessor M(o) of an operation o ∈ ops(I) is

M(o) ≡

arg maxō∈Oprev (o) S(ō)
o∅

if Oprev (o) 6= ∅
otherwise.

where Oprev (o) = {ō ∈ ops(I) : m(ō) = m(o), S(ō) < S(o)} is the set of operations
scheduled to run before o on o’s machine.
3. S is a feasible schedule if S(o) ≥ max(S + (J (o)), S + (M(o))) ∀o ∈ ops(I).
4. The quantity
`(S) ≡ max S + (o)
o∈ops(I)

is called the makespan of S.
We consider the makespan-minimization version of the JSP, in which the goal is to find
a schedule that minimizes the makespan.
For the remainder of the paper, whenever we refer to a JSP schedule S we shall adopt
the convention that S(o∅ ) = 0 and we shall assume that
S(o) = max(S + (J (o)), S + (M(o))) ∀o ∈ ops(I)

(3.1)

(i.e., S is a so-called semi-active schedule, French, 1982). In other words, we ignore schedules
with superfluous idle time at the start of the schedule or between the end of one operation
and the start of another.
Figure 2 (A) and (B) depict, respectively, a JSP instance and a feasible schedule for
that instance.
3.2 Disjunctive Graphs
A schedule satisfying (3.1) can be uniquely represented by a weighted, directed graph called
its disjunctive graph. In the disjunctive graph representation of a schedule S for a JSP
instance I, each operation o ∈ ops(I) is a vertex and a directed edge (o1 , o2 ) indicates that
operation o1 completes before o2 starts.
252

The Landscape of Random Job Shop Scheduling Instances

Definition (disjunctive graph). The disjunctive graph G = G(I, S) of a schedule S for
~ w) defined as follows.
a JSP instance I is the weighted, directed graph G = (V, E,
• V = ops(I) ∪ {o∅ , o∗ }, where o∗ (like o∅ ) is a fictitious operation with τ (o∗ ) = 0 and
m(o∗ ) undefined.
~ =C
~ ∪ D,
~ where
• E

	
~ = {(J (o), o) : o ∈ ops(I)}∪ (J k , o∗ ) : k ∈ [N ] is called the set of conjunctive
– C
M
arcs (which specify that o cannot start until J (o) completes), and
~ = {(o1 , o2 ) : {o1 , o2 } ⊆ ops(I), m(o1 ) = m(o2 ), S(o1 ) < S(o2 )} is called the set
– D
of disjunctive arcs (which specify, for each pair of operations performed on the
same machine, which of the two operations is to be performed first).
• w((o1 , o2 )) = τ (o1 ).
Figure 2 (C) depicts the disjunctive graph for the schedule depicted in Figure 2 (B).
The connection between a schedule and its disjunctive graph is established by the following
proposition (Roy & Sussmann, 1964).
Proposition 1. Let S be a feasible schedule for I satisfying (3.1), and let G = G(I, S) be
the corresponding disjunctive graph. Then `(S) is equal to the length of the longest weighted
path from o∅ to o∗ in G.
Proof. For any operation o, let L(o) denote the length of the longest weighted path from
o∅ to o in G. It suffices to show that for any o ∈ ops(I), S(o) = L(o). This follows by
induction on the number of edges in the path, with the base case S(o∅ ) = L(o∅ ) = 0.
The undirected version of a disjunctive arc is called a disjunctive edge.
Definition (disjunctive edge). Let I be a JSP instance. A disjunctive edge is a set
{o1 , o2 } ⊂ ops(I) with m(o1 ) = m(o2 ). We define the following notation.
• E(I) is the set of disjunctive edges for I.
• Let S be a schedule for I and let e = {o1 , o2 } be a disjunctive edge. We denote by
~e(S) the unique arc in {(o1 , o2 ), (o2 , o1 )} that appears in the disjunctive graph G(I, S)
(this arc is called the orientation of e in S).
We measure the distance between two schedules S1 and S2 for a JSP instance I by
counting the number of disjunctive edges that are oriented in opposite directions in G(I, S1 )
and G(I, S2 ).
Definition (disjunctive graph distance). The disjunctive graph distance kS1 − S2 k
between two schedules S1 and S2 for a JSP instance I is defined by
kS1 − S2 k ≡ |{e ∈ E(I) : ~e(S1 ) 6= ~e(S2 )}| .
253

Streeter & Smith

3.3 Random Schedules and Instances
We define a uniform distribution over JSP instances as follows. Our distribution is identical
to the one used by Taillard (1993).
Definition (random JSP instance). A random N by M JSP instance I is generated as
follows.
1. Let φ1 , φ2 , . . . , φN be random permutations of [M ].
2. Let G be a probability distribution over (0, τmax ] with mean µ and variance σ 2 > 0.
3. Define I = {J 1 , J 2 , . . . , J N }, where m(Jik ) = φk (i) and each τ (Jik ) is drawn (independently at random) from G.
Note that this definition (and likewise, our theoretical results) assumes a maximum
operation duration τmax , but makes no assumptions about the form of the distribution of
operation durations. For the empirical results reported in this paper, we choose operation
durations from a uniform distribution over {1, 2, . . . , 100}.
Our proofs will frequently make use of priority rules. A priority rule is a greedy schedulebuilding algorithm that assigns a priority to each operation and, at each step of the greedy
algorithm, assigns the earliest possible start time to the operation with minimum priority.
Definition (priority rule). A priority rule π is a function that, given an instance I and
an operation o ∈ ops(I), returns a priority π(I, o) ∈ <. The schedule S = S(π, I) associated
with π is defined by the following procedure.
1. U nscheduled ← ops(I), S(o∅ ) ← 0.
2. While |U nscheduled| > 0 do:
(a) Ready ← {o ∈ U nscheduled : J (o) ∈
/ U nscheduled}.
(b) ō ← the element of Ready with least priority.
(c) S(ō) ← max(S + (J (ō)), S + (M(ō))).
(d) Remove ō from U nscheduled.
A priority rule is called instance-independent if, for any N by M JSP instance I and
integers k ∈ [N ], i ∈ [M ], the value π(I, Jik ) depends only on k, i, N , and M .
We obtain a random schedule by assigning random priorities to each operation. The
resulting distribution is equivalent to the one used by Mattfeld (1996).
Definition (random schedule). A random schedule for an N by M JSP instance I is
generated by performing the following steps.
1. Create a list L containing M occurrences of the integer k for each k ∈ [N ] (we think
of the M occurrences of k as representing the operations in the job J k ).
2. Shuffle L (obtaining each permutation with equal probability).
3. Return the schedule S(πrand , I) where πrand (I, Jik ) = the index of the ith occurrence
of k in L.
254

The Landscape of Random Job Shop Scheduling Instances

4. Number of Common Attributes as a Function of Makespan
The backbone of a JSP instance is the set of disjunctive edges that have a common orientation in all schedules whose makespan is globally optimal. For ρ ≥ 1, we define the
ρ backbone to be the set of disjunctive edges that have a common orientation in all schedules whose makespan is within a factor ρ of optimal (a related definition appears in Slaney
& Walsh, 2001).
Definition (ρ backbone). Let I be a JSP instance with optimal makespan `min (I). For
ρ ≥ 1, let ρ opt(I) ≡ {S : `(S) ≤ ρ · `min (I)} be the set of schedules whose makespan is
within a factor ρ of optimal. Then
ρ backbone(I) ≡ {e ∈ E(I) : ~e(S1 ) = ~e(S2 ) ∀{S1 , S2 } ⊆ ρ opt(I)} .
In this section we compute the expected value of |ρ backbone| as a function of ρ for
random N by M JSP instances, and examine how the shape of this curve changes as a
N
function of M
.
4.1 Computing the ρ backbone
To compute the ρ backbone we use the following proposition.
Proposition 2. Let I be a JSP instance with optimal makespan `min (I). Let e = {o1 , o2 }
be a disjunctive edge with orientations a1 = (o1 , o2 ) and a2 = (o2 , o1 ). For any disjunctive
arc a, let `min (I|a) denote the optimum makespan among schedules whose disjunctive graph
contains the arc a. Then
e ∈ ρ backbone(I) ⇔ max {`min (I|a1 ), `min (I|a2 )} > ρ · lmin (I) .
Proof. If e ∈ ρ backbone, then e must have a common orientation (say a1 ) in all schedules
S with `(S) ≤ ρ · `min (I), which implies `min (I|a2 ) > ρ · `min (I). If e ∈
/ ρ backbone, then
there must be some {S1 , S2 } ⊆ ρ opt(I) with ~e(S1 ) = a1 and ~e(S2 ) = a2 , which implies
max{`min (I|a1 ), `min (I|a2 )} ≤ ρ · `min (I).

Thus to compute ρ backbone(I) we need only to compute `min (I|a) for the 2M N2
possible choices of a. Given a disjunctive arc a, we compute `min (I|a) using branch and
bound. In branch and bound algorithms for the JSP, nodes in the search tree represent
choices of orientations for a subset of the disjunctive edges. By constructing a root search
tree node that has a as a fixed arc, we can determine `min (I|a). We use a branch and bound
algorithm due to Brucker et al. (1994) because it is efficient and because the code for it is
freely available via ORSEP (Brucker, Jurisch,
& Sievers, 1992).


N
Computing `min (I|a) for the 2M 2 possible choices of a requires only 1 + M N2 runs
of branch and bound. The first run is used to find a globally optimal schedule,
which gives

N
N
the value of `min (I|a) for M 2 possible choices of a (namely, the M 2 disjunctive arcs
that are
 present in the globally optimal schedule). A separate run is used for each of the
M N2 remaining choices of a.
Figure 3 graphs the fraction of disjunctive edges that belong to the ρ backbone as a
function of ρ for instance ft10 (a 10 job, 10 machine instance) from the OR library (Beasley,
255

Streeter & Smith

Instance ft10
Normalized |ρ-backbone|

1
0.8
0.6
0.4
0.2
0
1.00

1.02

1.04

1.06

1.09

1.11

1.13

ρ

Figure 3: Normalized |ρ backbone| as a function of ρ for OR library instance ft10.
1990). Note that by definition the curve is non-increasing with respect to ρ, and that the
curve is exact for all ρ. It is noteworthy that among schedules whose makespan is within a
factor 1.005 of optimal, 80% of the disjunctive edges have a fixed orientation. We will see
N
that this behavior is typical of JSP instances with M
= 1.
4.2 Results
We plotted |ρ backbone| as a function of ρ for all instances in the OR library having 10 or
fewer jobs and 10 or fewer machines. The results are available online (Streeter & Smith,
2005b). Inspection of the graphs revealed that the shape of the curve is largely a function
of the job:machine ratio. To investigate this further, we repeat these experiments on a large
number of randomly generated JSP instances.
We use randomly generated instances with 7 different combinations of N and M to study
N
N
instances with M
equal to 1, 2, or 3. For M
= 1 we use 6x6, 7x7, and 8x8 instances; for
N
N
=
2
we
use
8x4
and
10x5
instances;
and
for
M
M = 3 we use 9x3 and 12x4 instances. We
generate 1000 random instances for each combination of N and M .
Figure 4 parts (A), (B), and (C) graph the expected fraction of edges belonging to the
N
ρ-backbone as a function of ρ for each combination of N and M , grouped according to M
.
N
Figure 4 (D) compares the curves for different values of M , and plots the 0.25 and 0.75
quantiles. For the purposes of this study the two most important observations about Figure
4 are as follows.
• The curves depend on both the size of the instance (i.e., N M ) and the shape (i.e.,
N
N
M ). Of these two factors, M has by far the stronger influence on the shape of the
curves.
• For all values of ρ, the expected fraction of edges belonging to the ρ backbone decreases
N
as M
increases.
256

The Landscape of Random Job Shop Scheduling Instances

(A) Job:machine ratio 1:1

(B) Job:machine ratio 2:1
1

0.8

E[frac. edges in ρ-backbone]

E[frac. edges in ρ-backbone]

1

6x6 instances
7x7 instances

0.6

8x8 instances
0.4

0.2

0.8

8x4 instances
10x5 instances

0.6
0.4
0.2
0

0
1

1.1

1.2

ρ

1.3

1.4

1

1.5

1.1

1.3

1.4

1.5

ρ

(C) Job:machine ratio 3:1

(D) Comparison

1

1

0.8

Frac. edges in ρ-backbone

E[frac. edges in ρ-backbone]

1.2

9x3 instances

0.6

12x4 instances

0.4
0.2
0

0.8

8x8 instances
10x5 instances

0.6

12x4 instances
0.4

0.2

0

1

1.1

1.2

1.3

1.4

1.5

ρ

1

1.1

1.2

ρ

1.3

1.4

1.5

Figure 4: Expected fraction of edges in ρ-backbone as a function of ρ for random JSP
N
instances. Graphs (A), (B), and (C) depict curves for random instances with M
= 1, 2, and 3, respectively. Graph (D) compares the curves depicted in (A), (B),
and (C) (only the curves for the largest instance sizes are shown in (D)). In (D),
top and bottom error bars represent 0.75 and 0.25 quantiles, respectively.

257

Streeter & Smith

4.3 Analysis
We now give some insight into Figure 4 by analyzing two limiting cases. We prove that as
N
M →0, the expected fraction of disjunctive edges that belong to the backbone approaches
N
1, while as M
→∞ this expected fraction approaches 0.
N
Intuitively, what happens is as follows. As M
→0 (i.e., N is held constant and M →∞)
each of the jobs becomes very long. Individual disjunctive edges then represent precedence
relations among operations that should be performed very far apart in time. For example,
if there are 10,000 machines (and so each job consists of 10,000 operations), a disjunctive
edge might specify whether operation 1,200 of job A is to be performed before operation
8,500 of job B. Clearly, waiting for job B to complete 8,500 of its operations before allowing
job A to complete 12% of its operations is likely to produce an inefficient schedule. Thus,
orienting a single disjunctive edge in the “wrong” direction is likely to prevent a schedule
from being optimal, and so any particular edge will likely have a common orientation in all
globally optimal schedules.
N
In contrast, when M
→∞, it is the workloads of the machines that become very long.
The order in which the jobs are processed on a particular machine does not matter much as
long as the machine with the longest workload is kept busy, and so the fact that a particular
edge is oriented a particular way is unlikely to prevent a schedule from being optimal. All
of this is formalized below.
We will make use of the following well-known definition.
Definition (whp). A sequence of events ξn occurs with high probability (whp) if limn→∞
P[ξn ] = 1.
Lemma 1 and Theorem 1 show that for constant N , a randomly chosen edge of a random
N by M JSP instance will be in the backbone whp (as M →∞). Lemma 2 and Theorem 2
show that for constant M , a randomly chosen edge of a random N by M JSP instance will
not be in the backbone whp (as N →∞).
Lemma 1. Let I be a random N by M JSP instance, and let S = S(π, I) be the schedule
for I obtained using some instance-independent priority rule π. For an arbitrary job J ∈ I,
define ∆SJ ≡ S + (JM ) − τ (J). Then E[∆SJ ] is O(N ).
Proof. We assume N = 2 and M > 1. The generalization to larger N is straightforward,
while the cases N = 1 and M = 1 are trivial. Let I = {J 1 , J 2 } and let J = J 1 .
Let T = (ō1 , ō2 , . . . , ōN M ) be the sequence of operations selected from Ready (in line
2(b) of the definition of a priority rule in §3.3) in constructing S. We say that an operation
Ji1 overlaps with an operation Jj2 if
1. Jj2 appears before Ji1 in T , and
1 ), S + (J 1 ) + τ (J 1 )] 6= ∅ .
2. [S(Jj2 ), S + (Jj2 )] ∩ [S + (Ji−1
i−1
i

If additionally m(Ji1 ) = m(Jj2 ), we say that Ji1 contends with Jj2 . Intuitively, if o ≡ Ji1
overlaps with o0 ≡ Jj2 then the start time of o might have been delayed because o’s machine
was being used by o0 . If o contends with o0 , then the start time of o actually was delayed.
258

The Landscape of Random Job Shop Scheduling Instances

Let θi,j (resp. δi,j ) be an indicator for the event that Ji1 overlaps (resp. contends) with
2
2
1
Let
S Ci ≡ {Jj : θi,j = 1} be the set of operations in J that Ji overlaps with. Then
|Ci ∩ i0 >i Ci0 | ≤ 1. Thus

Jj2 .

X
i

|Ci | =

X
i

|Ci \

[

Ci0 | +

i0 >i

X
i

|Ci ∩

[

Ci0 | ≤ 2M .

(4.1)

i0 >i

Let I¯ = IN,M −1 be a random N by M − 1 JSP instance, and define θ̄i,j , δ̄i,j , and C̄i
analogously to the above. Then for i, j ≤ M − 1,




P θi,j = 1|m(Ji1 ) = m(Jj2 ) = P θ̄i,j = 1 .
This is true because P[θi,j = 1] is a function of the joint distribution of the operations in
the set {Ji10 : i0 < i} ∪ {Jj20 : j 0 < j}; and, as far as this joint distribution is concerned,
conditioning on the event m(Ji1 ) = m(Jj2 ) is like deleting the operations that use the
machine m(Ji1 ).
h
i


 
1
1
1
P θi,j = 1|m(Ji1 ) = m(Jj2 ) = M
P θ̄i,j = 1 = M
E θ̄i,j .
Thus E [δi,j ] = P [δi,j = 1] = M
Therefore,
PM −1 PM −1
PM PM
j=1 E[δi,j ]
i=1
j=1 E[δi,j ] ≤ 2 +
i=1
1 PM −1 PM −1
= 2 + M i=1
j=1 E[θ̄i,j ]
1 PM −1
= 2 + M i=1 E[|C̄i |]
≤4
where in the last step we have used (4.1). It follows that E[∆SJ ] ≤ 4τmax (τmax is the
maximum operation duration defined in §3). When we consider arbitrary N , we get E[∆SJ ] ≤
4τmax (N − 1).
As a corollary of Lemma 1, we can show that a simple priority rule (π0 ) almost surely
N
→ 0.
generates an optimal schedule in the case M
Definition (priority rule π0 ). Given an N by M JSP instance I, let k ∗ = arg maxk∈[N ]
τ (J k ) be the index of the longest job. The priority rule π0 first schedules the operations in
∗
J k , then schedules the remaining operations in a fixed order.

i
if k = k ∗
k
π0 (I, Ji ) =
M k + i otherwise.
Corollary 1. Let I be a random N by M JSP instance. Then for fixed N , it holds
whp (as M → ∞) that the schedule S = S(π0 , i) is optimal and has makespan `(S) =
maxk∈[N ] τ (J k ).
Proof. Define the priority rule πk̄ by πk̄ (I, Jik ) = i if k = k̄; M k + i otherwise. Then πk̄ is
instance-independent, and π0 is equivalent to πk∗ . Thus for any J ∈ I we have
E[∆πJ0 ] ≤

X

E[∆πJk ] = O(N 2 )

k

259

Streeter & Smith

S(π,I)

where we define ∆πJ ≡ ∆J
, and the second step uses Lemma 1. By Markov’s inequal1
π0
ity, ∆J < M 4 ∀J ∈ I whp. By the Central Limit Theorem, each
√ τ (J) is asymptotically
normally distributed with mean µM and standard deviation σ M . It follows that whp,
1
∗
∗
∗
τ (J k ) − τ (J k ) > M 4 ∀k 6= k ∗ . This implies `(S) = τ (J k ). Because τ (J k ) is a lower
bound on the makespan of any schedule, the corollary follows.
Theorem 1. Let I be a random N by M JSP instance, and let e be a randomly selected
element of E(I). Then for fixed N , it holds whp (as M →∞) that e ∈ 1 backbone(I).
Proof. Let e = {Ji , Jj0 } with i ≤ j and let a = (Jj0 , Ji ). By Proposition 1 and Corollary 1,
it suffices to show that whp, all disjunctive graphs containing a contain a path from o∅ to
o∗ with weighted length > maxk∈[N ] τ (J k ).
3

Assume j − i ≥ M 4 (this holds whp because both i and j are selected uniformly at
random from [M ]), and consider the path
P = (o∅ , J10 , J20 , . . . , Jj0 , Ji , Ji+1 , . . . , JM , o∗ )
3

which passes through |P | ≥ 3+M +M 4 vertices and has weighted length w(P ). We want
to show that w(P ) > maxJ∈I τ (J) whp. By the Central Limit Theorem, (1) for any fixed
i and j, w(P
p) is asymptotically normally distributed with mean µ(|P | − 2) and standard
deviation σ (|P | − 2) and (2) for each √
J, τ (J) is asymptotically normally distributed
with mean µM and standard deviation σ M . That w(P ) > maxJ∈I τ (J) whp follows by
Chebyshev’s inequality.
N
→ ∞, a simple priority rule (π∞ ) almost surely generates
Lemma 2 shows that as M
a schedule in which no machine is idle until all the operations performed on that machine
have been completed (a schedule with this property is clearly optimal).

Definition (priority rule π∞ ). Given an N by M JSP instance I, the priority rule π∞
first schedules the first operation of each job (taking the jobs in order of ascending indices),
then the second operation of each job, and so forth. It is defined by π∞ (I, Jik ) = iN + k.
Lemma 2. Let I be a random N by M JSP instance. Then for fixed M , it holds whp (as
N → ∞) that the schedule S = S(π∞ , I) has the property that
S(o) = S + (M(o)) ∀o ∈ ops(I) .
Proof. Suppose that when executing π∞ we replace the line S(o) ← max(S + (J (o)),
S + (M(o))) (line 2(c) in the definition of a priority rule given in §3.3) with S(o) ← S + (M(o)).
If the resulting S is feasible then the replacement must have had no effect. Thus it suffices
to show that the resulting S is feasible whp. Equivalently, we want to show that whp,
S(o) ≥ S + (J (o)) ∀o ∈ ops(I) when S is constructed using the modified version of line 2
(c).
Let ops2+ (I) = {Jik ∈ ops(I) : i > 1} be the set of operations that are not first in their
job. It suffices to show that S(o) − S(J (o)) ≥ τmax ∀o ∈ ops2+ (I). To this end, consider
an arbitrary operation o = Jik ∈ ops2+ (I). Under π∞ , the number of operations with lower
260

The Landscape of Random Job Shop Scheduling Instances

priority than o is (i − 1)N + (k − 1). The number of operations that have lower priority
1
than Jik and run on machine m(o) is, in expectation, equal to M
[(i − 1)(N − 1) + (k − 1)]
(where the switch from N to N − 1 is due to the fact that o is the only operation in job J k
that uses machine m(o)). It follows that
E[S(o)] =

µ
[(i − 1)(N − 1) + (k − 1)]
M

so that
k
)] = µ
E[S(o) − S(J (o))] = E[S(Jik ) − S(Ji−1

N −1
.
M

In Appendix A we use a martingale tail inequality to establish the following claim.
Claim 2.1. With high probability, for all o ∈ ops2+ (I) we have
1
S(o) − S(J (o)) ≥ E[S(o) − S(J (o))] .
2
The Lemma then follows from the fact that 21 E[S(o) − S(J (o))] > τmax for N sufficiently
large.
Based on the results of computational experiments, Taillard (1994) conjectured that as
→ ∞ the optimal makespan is almost surely equal to the maximum machine workload.
The following corollary of Lemma 2 confirms this conjecture.
N
M

Corollary 2. Let I be a random N by M JSP instance with optimal makespan `min (I).
Let τ (m̄) ≡ τ ({o ∈ ops(I) : m(o) = m̄}) denote the workload of machine m̄. Then for fixed
M , it holds whp (as N →∞) that `min (I) = maxm̄∈[M ] τ (m̄).
Theorem 2. Let I be a random N by M JSP instance, and let e be a randomly selected
element of E(I). Then for fixed M , it holds whp (as N →∞) that e ∈
/ 1 backbone(I).
Proof. Let e = {Ji , Jj0 }. Remove both J and J 0 from I to create an N − 2 by M instance
¯ which comes from the same distribution as a random N − 2 by M JSP instance. Lemma
I,
2 shows that whp there exists an optimal schedule S̄ for I¯ with the property described in
the statement of the lemma.
¯ : m(o) = m̄}) denote the workload of machine m̄ in the
Let τ (m̄) ≡ τ ({o ∈ ops(I)
¯
instance I. By the Central Limit Theorem, each
√ τ (m̄) is asymptotically normally distributed
with mean µ(N −2) and standard deviation σ N − 2. It follows that whp, |τ (m̄)−τ (m̄0 )| >
1
N 4 ∀m̄ 6= m̄0 .
Thus whp there will be only one machine still processing operations during the interval
1
[`(S̄) − N 4 , `(S̄)]. Because max(τ (J), τ (J 0 )) ≤ M τmax = O(1), we can use this interval
to construct optimal schedules containing the disjunctive arc (Ji , Jj0 ) as well as optimal
schedules containing the disjunctive arc (Jj0 , Ji ).
261

Streeter & Smith

5. Clustering as a Function of Makespan
In this section we estimate the expected distance between random schedules whose makespan
is within a factor ρ of optimal, as a function of ρ for various combinations of N and M . We
N
then examine how the shape of this curve changes as a function of M
. More formally, if
• I is a random N by M JSP instance with optimal makespan `min (I),
• ρ opt(I) ≡ {S : `(S) ≤ ρ · `min (I)}, and
• S1ρ and S2ρ are drawn independently at random from ρ opt(I),
we wish to compute E[kS1ρ − S2ρ k].
Note that the experiments of §4 provide an upper bound on this quantity:
 
N
− E [|ρ backbone|]
E [kS1ρ − S2ρ k] ≤ M
2
but provide no lower bound (a low backbone size is not evidence that the mean distance
between global optima is large). The experiments in this section can be viewed as a test of
the degree to which the upper bound provided by §4 is tight.
5.1 Methodology
We generate “random” samples from ρ opt(I) by running the simulated annealing algorithm
of van Laarhoven et al. (1992) until it finds such a schedule. More precisely, our procedure
for sampling distances is as follows.
1. Generate a random N by M JSP instance I.
2. Using the branch and bound algorithm of Brucker et al. (1994), determine the optimal
makespan of I.
3. Perform k runs, R1 , R2 , . . . , Rk , of the van Laarhoven et al. (1992) simulated annealing
algorithm. Restart each run as many times as necessary for it to find a schedule whose
makespan is optimal.
4. For each ρ ∈ {1, 1.01, 1.02, . . . , 1.5}, find the first schedule, call it Si (ρ), in each run
Ri whose makespan is within a factor ρ of optimal. For each of the k2 pairs of
runs (Ri , Rj ), add the distance between Si (ρ) and Sj (ρ) to the sample of distances
associated with ρ.
We ran this procedure on random JSP instances for the same 7 combinations of N and
M that were used in §4.2. For the smallest instance sizes for each ratio (i.e., 6x6, 8x4 and
9x3 instances) we generate 100 random JSP instances and run the procedure with k = 100.
Setting k = 100 allows us to measure the variation in instance-specific expected values. For
the other 4 combinations of N and M , performing 10,000 simulated annealing runs is too
computationally expensive, so we instead generate 1000 random JSP instances and run the
procedure with k = 2.
262

The Landscape of Random Job Shop Scheduling Instances

Figure 5 (A), (B), and (C) plot the expected distance between random ρ-optimal schedN
ules as a function of ρ for each of the three values of M
. Figure 5 (D) shows the 0.75
and 0.25 quantiles of the 100 instance-specific sample means for each of the three smallest
instance sizes. Examining Figure 5 (D), we see that the variation among random instances
with the same N and M is small relative to the differences between the curves for different
N
values of M
.
5.2 Discussion
By examining Figure 5 we see that for any ρ, the expected distance between random ρN
optimal schedules increases as M
increases. Indeed, global optima are dispersed widely
N
N
throughout the search space for M
= 3, and this is true to a lesser extent for M
= 2.
An immediate implication of Figure 5 is that whether or not they exhibit the two
correlations that are the operational definition of a big valley, typical landscapes for JSP
N
= 3 cannot be expected to be big valleys in the sense of having a central
instances with M
cluster of optimal or near-optimal solutions. If anything, one might posit the existence of
multiple big valleys, each leading to a separate global optimum. The next section expands
upon these observations.

6. The Big Valley
In this section we define some formal properties of a big valley landscape, conduct experiments to determine the extent to which random JSP instances exhibit these properties as
N
N
N
we vary M
, and present analytical results for the limiting cases M
→ 0 and M
→ ∞.
Considering again the “intuitive picture” given in Figure 1, we take the following to be
necessary (though perhaps not sufficient) conditions for a function f (x) to be a big valley.
1. Small improving moves. If x is not a global minimum of f , there must exist a nearby
x0 with f (x0 ) < f (x).
2. Clustering of global optima. The maximum distance between any two global minima
of f is small.
Note that there is no direct relationship between these two properties and the cost-distance
correlations considered by Boese et al. (1994).
6.1 Formalization
The following four definitions allow us to formalize the notion of a big valley landscape.
Definition (Neighborhood Nr ). Let I be an arbitrary JSP instance, and let U be the set
of all schedules for I. Let r be a positive integer. The neighborhood Nr : U → 2U is defined
by
Nr (S) ≡ {S 0 ∈ U : kS − S 0 k ≤ r} .
Definition (local optimum L(S, N )). Let I and U be as above; let N : U → 2U be
an arbitrary neighborhood function; and let S be a schedule for I. L(S, N ) is the schedule
returned by the following procedure (which finds a local optimum by performing next-descent
starting from S using the neighborhood N ).
263

Streeter & Smith

(A) Job:machine ratio 1:1

(B) Job:machine ratio 2:1
0.5

E[dist. between schedules]

E[dist. between schedules]

0.5
0.4
0.3
0.2

6x6 instances
7x7 instances

0.1

8x8 instances
0

0.4
0.3
0.2

8x4 instances

0.1

10x5 instances

0
1

1.1

1.2

1.3

1.4

1.5

1

1.1

1.2

ρ

(C) Job:machine ratio 3:1

1.4

1.5

(D) Comparison

0.5

0.5

E[dist. between schedules]

E[dist. between schedules]

1.3

ρ

0.4
0.3
0.2

9x3 instances

0.1

12x4 instances

0.4
0.3
0.2

6x6 instances
8x4 instances

0.1

9x3 instances
0

0
1

1.1

1.2

1.3

1.4

1.5

1

1.1

1.2

1.3

1.4

1.5

ρ

ρ

Figure 5: Expected distance between random schedules within a factor ρ of optimal, as a
function of ρ. Graphs (A), (B), and (C) depict curves for random instances with
N
M = 1, 2, and 3, respectively. Graph (D) compares the curves depicted in (A),
(B), and (C) (only the curves for the smallest instance sizes are shown in (D)). In
(D), top and bottom error bars represent 0.75 and 0.25 quantiles (respectively)
of instance-specific sample means.

264

The Landscape of Random Job Shop Scheduling Instances

(A) An (r,δ)-valley

(B) Three (r,δ)-valleys

r

r

r

r
δ
δ

δ

δ

δ′

Figure 6: Two landscapes comprised of (r, δ)-valleys. (A) is a single (r, δ) valley (for the
values of r and δ shown in the figure), while (B) can either be viewed as three
distinct (r, δ) valleys or as a single (r, δ 0 )-valley. (The values of r shown in the
figure are slightly larger than necessary.)

1. Let N (S) = {S1 , S2 , . . . , S|N (S)| } (where the elements of N (S) are indexed in a fixed
but arbitrary manner).
2. Find the least i such that `(Si ) < `(S). If no such i exists, return S; otherwise set
S ← Si and go to 1.
Definition ((r, δ)-valley). Let I and U be as above, and let r and δ be non-negative
integers. A set V ⊆ U is an (r, δ)-valley if V has the following two properties.
1. For any S ∈ V , the schedule L(S, Nr ) is in V and is globally optimal.
2. For any two globally optimal schedules S1 and S2 that are both in V , kS1 − S2 k ≤ δ.
Figure 6 illustrates the definition of an (r, δ)-valley. We would say that the landscape
depicted in Figure 6 (A) is a big valley, while that depicted in 6 (B) is comprised of three
big valleys.
Definition ((r, δ, p) landscape). Let I and U be as above, and let S be a random schedule
for I. Then I has an (r, δ, p) landscape if there exists a V ⊆ U such that
1. V is an (r, δ)-valley, and
2. P[S ∈ V ] ≥ p.



Any JSP instance trivially has an (M N2 , M N2 , 1) landscape (because if r = M N2

then Nr includes all possible schedules). If a JSP instance I has an (r, M N2 , 1) landscape,
then a globally optimal schedule for I can always be found by starting at a random schedule
and applying next-descent using the neighborhood Nr .
We say that a JSP instance I has a big valley landscape if I has an (r, δ, p) landscape for
small r and δ in combination with p near 1. In contrast, if we have small r in combination
with p near 1 but require large δ, we say that the landscape consists of multiple big valleys.
265

Streeter & Smith

6.2 Neighborhood Exactness
In this section we seek to determine the extent to which random JSP instances have the
“small improving moves” property. We require the following definition.
Definition (neighborhood exactness). Let I, U , and N be as above, and let S be a
random schedule for I. The exactness of the neighborhood N on the instance I is the
probability that L(S, N ) is a global optimum.

If the exactness of Nr is p, then I has an (r, M N2 , p) landscape (let V consist of all
schedules S such that L(S, N ) is a global optimum). We will estimate the expected exactness
of Nr as a function of r for various combinations of N and M . By examining the resulting
curves, we will be able to draw conclusions about the extent to which the landscapes of a
random N by M JSP instance typically has the “small improving moves” property. We can
N
then determine how the presence or absence of this property depends on M
.

For fixed N and M , we compute the expected exactness of Nr for 1 ≤ r ≤ M N2 by
repeatedly executing the following procedure.
1. Generate a random N by M JSP instance I.
2. Using the algorithm of Brucker et al. (1994), compute the optimal makespan of I.
3. Repeat k times:
(a) S ← a random feasible schedule, r ← 1, opt ← f alse.
(b) While opt = f alse do:
• S ← L(S, Nr ).
• If S is a global optimum, opt ← true.
• Record the pair (r, opt).
• r ← r + 1.
(c) For all r0 such that r ≤ r0 ≤ M

N
2



record the pair (r0 , true).

The pairs recorded by the procedure (in step 3(c) and the third bullet point of 3 (b))
are used in the obvious way to estimate expected exactness. Specifically, for each r the
estimated expected exactness of Nr is the fraction of pairs (r, x) for which x = true.
The implementation of the first bullet point in step 3 (b) deserves further discussion. To
determine L(S, Nr ), each step of next-descent must be able to determine the best schedule
in {S 0 : kS −S 0 k ≤ r}. For large r it is impractical to do this by brute force. Instead we have
developed a “radius-limited” branch and bound algorithm that, given an arbitrary center
schedule Sc and radius r, finds the schedule arg min{S 0 :kSc −S 0 k≤r} `(S 0 ). Our radius-limited
branch and bound algorithm uses the branching rule of Balas (1969) combined with the
lower bounds and branch ordering heuristic of Brucker et al. (1994).
266

The Landscape of Random Job Shop Scheduling Instances

6.3 Results
N
We use three combinations of N and M with M
= 15 (3x15, 4x20, and 5x25 instances), three
N
N
combinations with M = 1 (6x6, 7x7, and 8x8 instances) and two combinations with M
=5
(15x3 and 20x4 instances). For the smallest instance sizes for each ratio (i.e., 3x15, 6x6,
and 15x3 instances) we generate 100 random JSP instances and run the above procedure
with k = 100. Otherwise, we generate 1000 random JSP instances and run the procedure
with k = 1.

Figure 7 (A), (B), and (C) plot expected exactness as a function of neighborhood radius
N
(normalized by the number of disjunctive edges) for each of these three values of M
. Figure
7 (D) shows the 0.75 and 0.25 quantiles of the 100 instance-specific sample means for each
of the three smallest instance sizes.
6.4 Discussion
Examining Figure 7, we see that for any normalized neighborhood radius, the neighborhood
N
exactness is lowest for instances with M
= 1 and higher for the two more extreme ratios
1
N
N
( M = 5 and M = 5). If we view neighborhood exactness as measuring the “smoothness”
of a landscape, the data suggest that typical JSP landscapes are least smooth at some
N
N
N
intermediate value of M
, but become more smooth as M
→ 0 or M
→ ∞. This in
itself suggests an easy-hard-easy pattern of typical-case instance difficulty in the JSP, a
phenomenon explored more fully in the next section.
Using the methodology of §§4-5, we found that the expected proportions of backbone
edges for 3x15, 4x20, and 5x25 instances are 0.94, 0.93, and 0.92, respectively, while the
expected distance between global optima was 0.02 in all three cases. In contrast, the
expected proportions of backbone edges for 15x3 and 20x4 instances are near-zero, while
the expected distances between global optima are 0.33 and 0.28, respectively. We conclude
that landcapes of random N by M JSP instances typically have the “clustering of global
N
N
optima” property for M
= 51 but not for M
= 5. However, Figure 7 suggests that the “small
N
N
improving moves” property is present for both M
= 51 and M
= 5. Accordingly, we would
N
1
N
say that typical landscapes for M = 5 are big valleys, while for M
= 5 the landscape is
comprised of many big valleys rather than just one.
N
The data from §§4-5 show that for M
= 1, typical landscapes have the “clustering of
global optima” property. Examining Figure 7 (B), we see that we are able to descend from
a random schedule to a globally optimal schedule with probability 12 when the (normalized)
neighborhood radius is about 6%. For this reason, we think of the landscapes of random
N
JSP instances with M
= 1 as having the “small improving moves” property to some extent.
This, in combination with the curve in Figure 5 (A) (which shows expected distance between
random ρ-optimal schedules as a function of ρ) leads us to say that typical landscapes of
N
random JSP instances with M
= 1 can still be roughly described as big valleys. However,
the valley is much rougher (meaning that larger steps are required to move from a random
schedule to a global optimum via a sequence of improving moves) than for the more extreme
N
values of M
.

Table 1 summarizes the empirical findings just discussed.
267

Streeter & Smith

(A) Job:machine ratio 1:5

(B) Job:machine ratio 1:1

1

1
0.8

3x15 instances
0.6

E[exactness]

E[exactness]

0.8

4x20 instances

0.4

5x25 instances

6x6 instances
0.6

7x7 instances
8x8 instances

0.4
0.2

0.2

0

0
0

0.1

0.2

0

0.3

0.2

0.3

Normalized radius

Normalized radius

(C) Job:machine ratio 5:1

(D) Comparison

1

1
0.8

E[exactness]

0.8

E[exactness]

0.1

15x3 instances
0.6

20x4 instances
0.4

3x15 instances

0.6

6x6 instances
0.4

15x3 instances

0.2

0.2

0

0
0

0.1

0.2

0.3

0

0.1

0.2

0.3

Normalized radius

Normalized radius

Figure 7: Expected exactness of Nr as a function of the (normalized) neighborhood radius
N
r. Graphs (A), (B), and (C) depict curves for random instances with M
= 15 ,
1, and 5, respectively. Graph (D) compares the curves depicted in (A), (B), and
(C) (only the curves for the largest instances are shown in (D)). In (D), top and
bottom error bars represent 0.75 and 0.25 quantiles (respectively) of instancespecific exactness.

268

The Landscape of Random Job Shop Scheduling Instances

N
M
1
5

N
Table 1. Landscape attributes for three values of M
.
Clustering
of Small
improving
Description
global optima? moves?
Yes
Yes
Big valley

1

Yes

Somewhat

(Rough) big valley

5

No

Yes

Multiple big valleys

6.5 Analysis
We first establish the behavior of the curves depicted in Figure 7 in the limiting cases
N
N
M → 0 and M → ∞. We then use these results to characterize the landscapes of random
JSP instances using the (r, δ, p) notation introduced in §6.1.
N
N
The following two lemmas show that as M
→ 0 (resp. M
→ ∞), a random schedule
will almost surely be “close” to an optimal schedule. The proofs are given in Appendix A.
Lemma 3. Let I be a random N by M JSP instance, and let S be a random schedule for
I. Let Ŝ be an optimal schedule for I such that kS − Ŝk is minimal. Let f (M ) be any
unbounded, increasing function of M . Then for fixed N , it holds whp (as M → ∞) that
kS − Ŝk < f (M ).
Lemma 4. Let I be a random N by M JSP instance, let S be a random schedule for I,
and let Ŝ be an optimal schedule for I such that kS − Ŝk is minimal. Then for fixed M and
 > 0, it holds whp (as N → ∞) that kS − Ŝk < N 1+ .
The following are immediate corollaries of Lemmas 3 and 4.
Corollary 3. For fixed N , the expected exactness of Nf (M ) approaches 1 as M → ∞, where
f (M ) is any unbounded, increasing function of M .
Corollary 4. For fixed M and  > 0, the expected exactness of NN 1+ approaches 1 as
N → ∞.

Because the total number of disjunctive edges is M N2 , these two corollaries imply that
N
N
→ 0 (resp. M
→ ∞), the curve depicted in Figure 7 approaches a horizontal line at
as M
a height of 1.
Using Lemmas 3 and 4, Theorems 3 and 4 characterize the landscape of random JSP
instances using the (r, δ, p) notation of §6.1. Before presenting these theorems, a slight
disclaimer is in order. Lemmas 3 and 4 (the proofs of which are fairly involved) indicate
N
N
that in the extreme cases M
→ 0 and M
→ ∞ we can jump from a random schedule to a
globally optimal schedule via a single small move. We strongly believe that in these cases
it is also possible to go from a random schedule to a global optimum by a sequence of many
(smaller) improving moves, although proving this seems difficult. Nevertheless, it should
be understood that our theoretical results do not strictly imply the existence of landscapes
like those depicted in Figure 6 (where for most starting points there is a sequence of two or
more small improving moves leading to a global optimum).
N
Theorem 3 shows that as M
→ 0, a random JSP instance almost certainly has an

(r, δ, p) landscape where r grows arbitrarily slowly as a function of M , δ is o(M N2 ), and
269

Streeter & Smith

N
p is arbitrarily close to 1. In other words, as M
→ 0 the landscape has both the “small
improving move(s)” property and the “clustering of global optima” property. In contrast,
N
Theorem 4 shows that as M
→ ∞, a random JSP instance almost surely does not have an
(r, δ, p) landscape unless δ is Ω(N 2 ). Instead, the landscape contains Ω(N !) (r, 1)-valleys,
N
where r is o(M N2 ). Thus, as M
→ ∞, the landscape has the “small improving move(s)”
property but not the “clustering of global optima” property. These analytical results confirm
the trend suggested by Figure 7 and discussed in §6.4.

Theorem 3. Let I be a random N by M JSP instance. Let f (M ) be any unbounded,
increasing function of M . For fixed N and  > 0, it holds whp (as M → ∞) that I has a
(r, δ, p) landscape for r = f (M ), δ = M N2 and p = 1 − .
Proof. Let V be the set of all schedules S such that L(S, Nr ) is a global optimum. It follows
by Corollary 3 that whp, the exactness of I on r is at least p, which means S ∈ V with
probability at least p. It remains to show that V is an (r, δ)-valley whp. Part 1 of the
definition of an (r, δ)-valley is satisfied by the definition of V . Part 2 follows from Theorem
1.
Theorem 4. Let I be a random N by M JSP instance, and let S be a random schedule for
I. There exists a set V (I) = ∪ni=1 Vi of schedules for I such that for fixed M and  > 0, V
has the following properties whp:
1. S ∈ V ;
2. Vi is an (r, δ)-valley with r = N 1+ and δ = 1 ∀i ∈ [n];
3. n > N !(1 − ); and
4. max{S1 ,S2 }⊆V kS1 − S2 k > Ω(N 2 ).
Proof. Let {Ŝ1 , Ŝ2 , . . . , Ŝn } be the set of globally optimal schedules for I, and define Vi ≡
{S : L(S, N 1+ ) = Ŝi }. Property 1 holds whp by Lemma 4. Property 2 holds by definition
of Vi .
The fact that property 3 holds whp is a consequence of Lemma 2. Recall that Lemma
N
2 showed that as M
→ ∞, the priority rule π∞ generates an optimal schedule whp, where
k
π∞ (I, Ji ) = iN + k. Because the indices assigned to the jobs are arbitrary, Lemma 2 also
applies to the priority rule π φ (I, Jik ) = iN + φ(k), where φ is any permutation of [N ]. There
are N ! possible choices of φ. Let f be the number of choices that fail to yield a globally
optimal schedule. Property 3 can only fail to hold if f ≥ N !. But by Lemma 1, E[f ] is
o(1)N !; hence f < N ! whp by Markov’s inequality.
To establish property 4, choose permutations φ1 and φ2 that list the elements of [N ]
in reverse order (i.e., φ1 (i) = φ2 (N − i) ∀i ∈ [N ]). By Lemma 2, the schedules S1 =
S(π φ1 , I) and S2 = S(π φ2 , I) are both globally optimal whp. But for any disjunctive edge
e = {J1 , J10 } we must have ~e(S1 ) 6= ~e(S2 ), hence kS1 − S2 k ≥ |{{J, J 0 } ⊆ I : m(J1 ) =
−1 
−1 
m(J10 )}| ≥ N M2
= Ω(N 2 ), where we obtain the expression N M2
using the pigeonhole
principle.
270

The Landscape of Random Job Shop Scheduling Instances

7. Quality of Random Schedules
7.1 Methodology
In this section we examine how the quality of randomly generated schedules changes as a
function of the job:machine ratio. Specifically, for various combinations of N and M , we
estimate the expected value of the following four quantities:
(A) the makespan of a random schedule,
(B) the makespan of a locally optimal schedule obtained by starting at a random schedule
and applying next-descent using the N1 move operator,
(C) the makespan of an optimal schedule, and
(D) the lower bound on the makespan of an optimal schedule given by the maximum of
the maximum job duration and the maximum machine workload:


X
max max τ (J), max
τ (o) .
J∈I

m̄∈[M ]

o∈ops(I):m(o)=m̄

N
considered in our experiments are those in the set R = { 17 , 16 , 51 , 14 ,
The values of M
1 1 2
3
3 , 2 ,S3 , 1, 2 , 2, 3, 4, 5, 6, 7 }. We consider all combinations of N and M in the set
N
S ≡ r∈R Sr , where Sr ≡ {(N, M ) : M
= r, min(N, M ) ≥ 2, max(N, M ) ≥ 6, N M < 1000}.
For each (N, M ) ∈ S, we estimate the expected value of (A) (resp. (B)) by generating 100
random N by M JSP instances and, for each instance, generating 100 random schedules
(resp. local optima). We estimate (D) by generating 1000 random JSP instances for each
(N, M ) ∈ S. For some combinations (N, M ) ∈ Ssmall ⊆ S, it was also practical to compute
N
quantity (C). Let nr = |Ssmall ∩ Sr | be the number of combinations (N, M ) with M
= r for
3
which we computed (C). We chose Ssmall so that nr ≥ 4 for r 6= 2 while n 3 = 3. For each
2
(N, M ) ∈ Ssmall , we estimate (C) using 1000 random JSP instances.

7.2 Results
Figure 8 plots the mean values of (A), (B), and (C), respectively, against the mean value of
(D), for various combinations of N and M . The data points for each combination of N and
N
M are assigned a symbol based on the value of M
. Top and bottom error bars represent 0.75
and 0.25 quantiles (respectively) of instance-specific sample means. Note that the width of
these error bars is small relative to the differences between the curves for different values
N
of M
.
N
Examining Figure 8, we see that the set of data points for each value of M
are approximately (though not exactly) collinear. Furthermore, in all three graphs the slope of the line
N
formed by the data points with M
= r is maximized when r = 1, and decreases as r gets
further away from 1 (see also Figure 9 (A)).
To further investigate this trend, we performed least squares linear regression on the set
N
of data points for each value of M
. The slopes of the resulting lines are shown as a function
N
of M in Figure 9 (A).
From examination of Figure 9 (A), it is apparent that
271

Streeter & Smith

(A) Random schedules
Mean makespan

7000
6000
5000
4000

Ratio 1:5

3000

Ratio 1:3
Ratio 1:1

2000

Ratio 3:1

1000

Ratio 5:1

0
0

1000 2000 3000 4000 5000 6000 7000

Mean lower bound

(B) Random local optima
Mean makespan

7000
6000
5000
4000

Ratio 1:5

3000

Ratio 1:3
Ratio 1:1

2000

Ratio 3:1

1000

Ratio 5:1

0
0

1000 2000 3000 4000 5000 6000 7000

Mean lower bound

(C) Optimal schedules
Mean makespan

7000
6000
5000
4000

Ratio 1:5

3000

Ratio 1:3
Ratio 1:1

2000

Ratio 3:1

1000

Ratio 5:1

0
0

1000 2000 3000 4000 5000 6000 7000

Mean lower bound

Figure 8: Expected makespan of (A) random schedules, (B) random local optima, and (C)
optimal schedules vs. expected lower bound, for various combinations of N and
N
M (grouped by symbol according to M
). Top and bottom error bars represent
0.75 and 0.25 quantiles (respectively) of instance-specific sample means.
272

The Landscape of Random Job Shop Scheduling Instances

(A) Results of least squares regression

Slope of E[makespan]
vs. E[lower bound]

4

Random schedules
Random local optima
Optimal schedules

3

2

1
0.1

1

10

Job:machine ratio

(B) Branch and bound search cost
2:1

Num. tree nodes

10000

3:2

1:1
2:3

1000
1:2

100

1:3

3:1
4:1
5:1

10

1:4

1:5
1:6

6:1

1:7
7:1

1
0

500

1000

1500

log(search space size)

1:7
1:6
1:5
1:4
1:3
1:2
2:3
1:1
3:2
2:1
3:1
4:1
5:1
6:1
7:1

2000

Figure 9: (A) graphs the slope of the least squares fits to the data in Figure 8 (A), (B),
N
N
and (C) as a function of M
(includes values of M
not depicted in Figure 8). (B)
th
graphs the number of search tree nodes (90 percentile) used by the branch and
bound algorithm of Brucker et al. (1994) to find an optimal schedule.

273

Streeter & Smith

N
• as the value of M
becomes more extreme (i.e., approaches either 0 or ∞), the expected makespan of random schedules (resp. random local optima) comes closer to
the expected value of the lower bound on makespan; and

• the difference between the expected makespan of random schedules (resp. random
local optima) and the expected value of the lower bound on makespan is maximized
N
at a value of M
≈ 1.
N
The first of these two observations suggests that as M
approaches either 0 or ∞, a
random schedule is almost certainly near-optimal. §7.3 contains two theorems that confirm
this.
The second of these two observations suggests that the expected difference between the
makespan of a random schedule and the makespan of an optimal schedule is maximized at a
N
value of M
somewhere in the neighborhood of 1. This observation is particularly interesting
N
in light of the empirical fact that square instances of the JSP (i.e., those with M
= 1) are
harder to solve than rectangular ones (Fisher & Thompson, 1963).
Figure 9 (B) graphs the number of search tree nodes (90th percentile) required by the
branch and bound algorithm of Brucker et al. (1994) to optimally solve random N by M
instances, as a function of the log (base 10) of search space size. We take the size of the
search space for an N by M JSP instance to be the number of possible disjunctive graphs,
M
namely 2N ( 2 ) . Note that some of these disjunctive graphs contain cycles and therefore do
not correspond to feasible schedules, so this expression overestimates the size of the search
space. Data points are given for each combination of N and M for which we could afford to
run branch and bound (i.e., each combination of N and M for which we computed quantity
N
(C)). The data points are grouped into curves according to M
.
Examining Figure 9 (B), we see that the curves are steepest for the ratios 23 , 1, 32 , 2,
N
and 3, and that the curves are substantially less steep for extreme values of M
such as 17
and 7. Thus, at least from the point of view of this particular branch and bound algorithm,
random JSP instances exhibit an “easy-hard-easy” pattern of instance difficulty. We discuss
this pattern further in §7.4.

7.3 Analysis
The following two theorems show that, as
will almost surely be near-optimal.

N
M

approaches either 0 or ∞, a random schedule

Theorem 5. Let I be a random N by M JSP instance with optimal makespan `min (I) and
let S be a random schedule for I. Then for fixed N and  > 0, it holds whp (as M → ∞)
that `(S) ≤ (1 + )`min (I).
Proof. The priority rule πrand associates a priority with each operation o ∈ ops(I). Let
the sequence T contain the elements of ops(I), sorted in ascending order of priority. The
schedule S = S(πrand , I) depends only on T , and there are N M ! possible choices of T . Thus
πrand can be seen as choosing at random from a set of N M ! instance-independent priority
rules. Because each of these instance-independent priority rules is subject to Lemma 1, πrand
is
to Lemma 1 and thus for each J, E[∆SJ ] is O(N ). Thus E[`(S) − `min (I)] ≤
Palso subject
S
2
J E[∆J ] = O(N ), so `(S) − `min (I) does not exceed `min (I) = Ω(M ) whp by Markov’s
inequality.
274

The Landscape of Random Job Shop Scheduling Instances

Theorem 6. Let I be a random N by M JSP instance with optimal makespan `min (I) and
let S be a random schedule for I. Then for fixed M and  > 0, it holds whp (as N → ∞)
that `(S) ≤ (1 + )`min (I).
Proof. See Appendix A.
The idea behind the proof of Theorem 6 is the following. As shown in Lemma 2, the
priority rule π∞ almost surely generates an optimal schedule. The relevant property of π∞
was that, when the operations were sorted in order of ascending priority, the number of
operations in between J (o) and o was Ω(N ). The key to the proof of Theorem 6 is that in
expectation, πrand shares this property for most of the operations o ∈ ops(I).
7.4 Easy-hard-easy Pattern of Instance Difficulty
N
N
The proofs of Corollary 1 (resp. Lemma 2) show that as M
→ 0 (resp. M
→ ∞) there exist
simple priority rules that almost surely produce an optimal schedule. Moreover, Theorems
5 and 6 show that in these two limiting cases, even a random schedule will almost surely
N
N
have makespan that is very close to optimal. Thus, both as M
→ 0 and as M
→ ∞, almost
all JSP instances are “easy”.
N
In contrast, for M
≈ 1, Figure 9 (A) suggests that random schedules (as well as random
local optima) are far from optimal. The literature on the JSP (as well the results depicted
N
in Figure 9 (B)) attests to the fact that random JSP instances with M
≈ 1 are “hard”.
Thus we conjecture that, as in 3-SAT, typical instance difficulty in the JSP follows an “easyhard-easy” pattern as a function of a certain parameter. In contrast to 3-SAT, the “easyhard-easy” pattern in the JSP is not (to our knowledge) associated with a phase transition
N
(i.e., we have not identified a quantity that undergoes a sharp threshold at M
≈ 1).
Furthermore, although the empirical results in Figures 9 (A) and (B) support the idea
that typical-case instance difficulty in the JSP follows as “easy-hard-easy” pattern, we
N
do not claim to have isolated any particular value of M
as being the point of maximum
difficulty. As shown in Figure 9 (B), random JSP N by M JSP instances are most difficult
N
for the branch and bound algorithm of Brucker et. al (1994) when M
≈ 2, but this may not
be true of other branch and bound algorithms or of JSP heuristics based on local search.
We leave the task of characterizing the “easy-hard-easy” pattern more precisely as future
work.
In related work, Beck (1997) studied a constraint-satisfaction (as opposed to makespanminimization) version of the JSP, and gave empirical evidence that the probability that a
random JSP instance is satisfiable undergoes a sharp threshold as a function of a quantity
called the constrainedness of the instance.

8. Limitations and Extensions
The primary limitation of the work reported in this paper is that both our theoretical and
empirical results apply only to random instances of the job shop scheduling problem. There
is no guarantee that our observations will generalize to instances drawn from distributions
with more interesting structure (Watson et al., 2002). The difficulty in extending our
analysis to other distributions is that analytical results similar to the ones presented in
275

Streeter & Smith

this paper may become much more difficult to derive. However, there are at least three
distributions that have been studied in the scheduling literature for which we believe it
should be not too difficult to adapt our proofs (the conclusions may change as part of the
adaptation process).
• Random workflow JSP instances. In a workflow JSP instance, the set of machines
is partitioned into sets (say M1 , M2 , . . . , Mk ). For i < j, each job must use all the
machines in Mi before using any machines in Mj . Mattfeld et al. (1999) define
a random distribution over workflow JSPs which generalizes in a natural way the
distribution defined in §3.3 (the difference is that the permutations φ1 , φ2 , . . . , φN are
chosen uniformly at random from the set of permutations that satisfy the workflow
constraints).
• Random instances of the (permutation) flow shop scheduling problem. An instance of
the flow shop scheduling problem (FSP) is a JSP instance in which all jobs use the
machines in the same order (equivalently, a FSP instance is a workflow JSP instance
with k = M ). The permutation flow shop problem (PFSP) is a special case of the FSP
in which, additionally, each machine must process the jobs in the same order. There
is a large literature on the (P)FSP; Framinan et al. (2004) and Hejazi and Saghafian
(2005) provide relevant surveys.
• Job-correlated and machine-correlated JSP instances. In a job-correlated JSP instance,
the distribution from which operation durations are drawn depends on the job to which
an operation belongs. Similarly, in machine-correlated JSP instance the distribution
depends on the machine on which the operation is performed. Watson et al. (2002)
have studied job-correlated and machine-correlated instances of the PFSP.
Regarding the difficulty of instances drawn from these three distributions, computational
experience shows that (i) random workflow JSPs are harder than random JSPs; (ii) random PFSPs are easier than random JSPs; and (iii) job-correlated and machine-correlated
PFSPs are easier than random PFSPs. Extending our theoretical analysis to each of these
distributions may give some insight into the relevant differences between them.
8.1 The Big Valley vs. Cost-Distance Correlations
In §6, we defined a “big valley” landscape as one that exhibits two properties: “small improving moves” and “clustering of global optima”. Our analytical and experimental results
were based on this definition. Although we believe this definition captures properties of JSP
landscapes that are important for designers of heuristics to understand, other properties
(e.g., cost-distance correlations) are likely to be important as well. In particular, it may be
possible for algorithms to exploit cost-distance correlations on landscapes that have neither
the “small improving moves” nor the “clustering of global optima” properties.
In the existing literature, the term “big valley” is used amorphously to mean either
(1) a landscape like that depicted in Figure 1 or (2) a landscape that exhibits high costdistance correlations. By making a sharper distinction between these two distinct concepts,
we can only improve our understanding of JSP landscapes as well as the landscapes of other
combinatorial problems.
276

The Landscape of Random Job Shop Scheduling Instances

9. Conclusions
9.1 Summary of Experimental Results
N
Empirically, we demonstrated that for low values of the job to machine ratio ( M
), lowmakespan schedules are clustered in a small region of the search space and the backbone
N
size is high. As M
increases, low-makespan schedules become dispersed throughout the
N
search space and the backbone vanishes. As a function of M
, the “smoothness” of the
landscape (as measured by a statistic called neighborhood exactness) starts out small for
N
N
N
low values of M
(e.g., M
= 15 ), is relatively high for M
≈ 1, and becomes small again for
N
N
N
high values of M (e.g., M = 5). For both extremely low and extremely high values of M
,
the expected makespan of random schedules comes very close to that of optimal schedules.
The quality of random schedules (resp. random local optima) appears to be the worst at a
N
value of M
≈ 1.
§6.4 discussed the implications of our results for the “big valley” picture of JSP search
N
≈ 1, we concluded that a typical landscape can be described as a big
landscapes. For M
N
N
valley, while for larger values of M
(e.g., M
≥ 3) there are many big valleys. §7.4 discussed
how our data support the idea that JSP instance difficulty exhibits an “easy-hard-easy”
N
.
pattern as a function of M

9.2 Summary of Theoretical Results
Table 2 shows the asymptotic expected values of various attributes of a random N by M
N
N
JSP instance in the limiting cases M
→ 0 and M
→ ∞.
Table 2. Attributes of random JSP instances.
Fixed N , M → ∞ Fixed M , N → ∞
Optimum makespan

Max. job length
(Corollary 1)

Max. machine workload
(Corollary 2)

Normalized backbone size

1 (Theorem 1)

0 (Theorem 2)

Normalized maximum distance between global optima
Normalized distance between random
schedule and nearest global optimum
Ratio of makespan of random schedule
to optimum makespan

0 (Theorem 1)

Ω(1) (Theorem 4)

0 (Lemma 3)

0 (Lemma 4)

1 (Theorem 5)

1 (Theorem 6)

9.3 Rules of Thumb for Designing JSP Heuristics
Though we do not claim to have any deep insights into how to solve random instances of
the JSP, our results suggest two general rules of thumb:
N
N
• when M
is low (say, M
≈ 1 or lower), an algorithm should attempt to locate the
cluster of global optima and exploit it; while

277

Streeter & Smith

N
N
• when M
is high (say, M
≥ 3) an algorithm should attempt to isolate one or more
clusters of global optima and deal separately with each of them.

We briefly discuss these ideas in relation to two recent algorithms: backbone-guided local
search (Zhang, 2004) and i-TSAB (Nowicki & Smutnicki, 2005).
9.3.1 Backbone-guided local search
Several recent algorithms attempt to use backbone information to bias the move operator employed by local search. For example, Zhang (2004) describes an approach called
backbone-guided local search in which the frequency with which an attribute (e.g., an assignment of a particular value to a particular variable in a Boolean formula) appears in
random local optima is used as a proxy for the frequency with which the attribute appears in global optima. The approach improved the performance of the WalkSAT algorithm
(Selman, Kautz, & Cohen, 1994) on large instances from SATLIB (Hoos & Stützle, 2000).
A similar algorithm has been successfully applied to the TSP (Zhang & Looks, 2005) to
improve the performance of an iterated Lin-Kernighan algorithm (Martin, Otto, & Felten,
1991). Zhang writes:
This method is built upon the following working hypothesis: On a problem
whose optimal and near optimal solutions form a cluster, if a local search algorithm can reach close vicinities of such solutions, the algorithm is effective
in finding some information of the solution structures, backbone in particular.
(Zhang, 2004, p. 3)
Based on the results of §§4-5, this working hypothesis is satisfied for random JSPs with
≈ 1 or lower. It seems plausible that backbone-guided local search could be used to boost
the performance of early local search heuristics for the JSP such as those of van Laarhoven
et al. (1992) and Taillard (1994) (whether the results would be competitive with those of
recent algorithms such as i-TSAB is a separate question).
N
The hypothesis is typically violated for random JSP instances with larger values of M
.
In these cases it makes more sense to attempt to exploit local clustering of optimal and
near-optimal schedules.
N
M

9.3.2 i-TSAB
Nowicki and Smutnicki (2005) present a JSP heuristic called i-TSAB which employs multiple
runs of the tabu search algorithm TSAB (Nowicki & Smutnicki, 1996). i-TSAB employs path
relinking to “localize the center of BV [big valley], probably close to the global minimum”
(Nowicki & Smutnicki, 2005). In other words, i-TSAB was designed based on the intuitive
picture depicted in Figure 6 (A), which is inaccurate for typical random JSP instances with
N
N
M ≥ 3. Note that although random JSP instances become “easy” as M → ∞, instances
N
with M
≈ 3 are by no means easy, as evidenced by Figure 9 (B).
For concreteness, we briefly describe how i-TSAB works. Initially, i-TSAB performs a
number of independent runs of TSAB and adds each best-of-run schedule to a pool of “elite
solutions”. It then performs additional runs of TSAB and uses the best-of-run schedules
from these additional runs to replace schedules in the pool of elite solutions. Starting points
278

The Landscape of Random Job Shop Scheduling Instances

for the additional TSAB runs are either (i) random elite solutions or (ii) schedules obtained
by performing path relinking on a random pair of elite solutions. Given two schedules S1
and S2 , path relinking uses a move operator to generate a new schedule that is midway
(in terms of disjunctive graph distance) between S1 and S2 . The pool of elite solutions
can be thought of as a cloud of particles that hovers over the search space and (hopefully)
converges to a region of the space containing a global optimum.
N
For random JSP instances with M
≈ 1, our results are consistent with the idea that
the cloud of elite solutions converges to the “center” of the big valley. For random JSP
N
instances with M
≥ 3, however, the cloud must either converge to one of many big valleys
or not converge at all. As an alternate approach one can imagine using multiple clouds,
with the intention that each cloud specializes on a particular big valley. It seems plausible
that such ideas could improve the performance of i-TSAB on random JSP instances with
N
larger values of M
.

Appendix A: Additional Proofs
P
For the proofs in this section, we define τ (O) ≡ o∈O τ (o), where O is any set of operations.
We make use of the following inequality (Spencer, 2005).
Azuma’s Perimetric Inequality (A.P.I.). Let X = (X1 , X2 , . . . , Xn ) be a vector of n independent random variables. Let the function f (x) take as input a vector x = (x1 , x2 , . . . , xn ),
where xi is a realization of Xi for i ∈ [n], and produce as output a real number. Suppose
that for some β > 0 it holds that for any two vectors x and x0 that differ on at most one
component,
|f (x) − f (x0 )| ≤ β .
Then for any α > 0,



√ 
α2
P X > E[X] + α n ≤ exp − 2 .
2β
√
The same inequality holds for P [X ≤ E[X] − α n].
Lemma 2. Let I be a random N by M JSP instance. Then for fixed M , it holds whp (as
N → ∞) that the schedule S = S(π∞ , I) has the property that
S(o) = S + (M(o)) ∀o ∈ ops(I) .
Proof. It remains only to prove Claim 2.1 from the proof in §4, which says that whp, for
all o ∈ ops2+ (I) we have
1
S(o) − S(J (o)) ≥ E[S(o) − S(J (o))] .
2
Pick some arbitrary operation o ∈ ops2+ (I), and suppose that the random choices used
to construct I were made in the following order:
1. Randomly choose m1 = m(o) and m2 = J (o).
2. For k from 1 to N :
279

Streeter & Smith

(a) Randomly choose the order in which job J k uses the machines (if o ∈ J k then
part of this choice has already been made in step 1).
(b) Randomly choose τ (Jik ) ∀i ∈ [M ].
Let the random variable Xk denote the sequence of random bits used in steps (a) and
(b) of the k th iteration of the loop. Define ∆o ≡ S(o) − S(J (o)). Then, for any fixed choices
of m1 and m2 , ∆o is a function of the N independent events X1 , X2 , . . . , XN , and it is easy
to check that altering a particular Xi changes the value of ∆o by at most 2τmax . Thus
h
i


−1)
P ∆o < 12 E[∆o ] = P ∆o < E[∆o ] − µ(N
2M
h
i
µN
≤ P ∆o < E[∆o ] − 2M


2
≤ exp − 2(4Mµ τN
2
max )
where in the first step we have used the fact (from the proof in §4) that E[∆o ] = µ(NM−1) and
in the last step we have used A.P.I. Taking a union bound over the N (M − 1) operations
in ops2+ (I) proves the claim.

Lemma 3. Let I be a random N by M JSP instance, and let S be a random schedule for
I. Let Ŝ be an optimal schedule for I such that kS − Ŝk is minimal. Let f (M ) be any
unbounded, increasing function of M . Then for fixed N , it holds whp (as M → ∞) that
kS − Ŝk < f (M ).
Proof. Let S̄ = S(π0 , I). The proof of Corollary 1 showed that for any J, E[∆S̄J ] is O(N 2 ).
Thus it holds whp that ∆S̄J < log(f (M )) ∀J. As in the proof of Theorem 5, the procedure
used to produce S is a mixture of instance-independent priority rules, each subject to
Lemma 1. Thus for any J, E[∆SJ ] is O(N ), so whp ∆SJ < log(f (M )) ∀J.
P
P
Let Onear (Ji ) = {Jj0 : J 0 6= J, | i0 <i τ (Ji0 ) − j 0 <j τ (Jj0 0 )| < log(f (M ))}. (Onear (Ji ) is
the set of operations that would be scheduled “near” in time to Ji if we ignored the fact
that a machine may only perform one operation at a time.) Let Enear = {e = {Ji , Jj0 } ∈
E(I) : Jj0 ∈ Onear (Ji )}. Under the assumptions of the previous paragraph (each of which
hold whp), kS − S̄k ≤ |Enear |. For any Ji , E[|Onear (Ji )|] is O(N log f (M )). Thus


E kS − S̄k ≤ E [|Enear |] =

X
o∈ops(I)


1
E [|Onear (o)|] = O N 2 log(f (M ))
M

so kS − Ŝk < f (M ) whp by Markov’s inequality.
For the purpose of the remaining proofs, it is convenient to introduce some additional
notation. Let T = (T1 , T2 , . . . , T|T | ) be a sequence of operations. We define
• T(i1 ,i2 ] ≡ {Ti : i1 < i ≤ i2 }, and
• T(im̄1 ,i2 ] ≡ {Ti ∈ T(i1 ,i2 ] : m(Ti ) = m̄} .
280

The Landscape of Random Job Shop Scheduling Instances

Lemma 4. Let I be a random N by M JSP instance, let S be a random schedule for I,
and let Ŝ be an optimal schedule for I such that kS − Ŝk is minimal. Then for fixed M and
 > 0, it holds whp (as N → ∞) that kS − Ŝk < N 1+ .
Proof. Let T be the sequence of operations o ∈ ops(I), sorted in ascending order by priority
πrand (I, o) (where πrand is the random priority rule used to create S). Note that for any
o ∈ ops(I) with J (o) 6= o∅ , J (o) must appear before o in T . Let Ti denote the ith operation
in T .
Consider the schedule S̄ defined by the following procedure:
1. S̄(o) ← ∞ ∀o ∈ ops(I).
2. Q ← (). Let Qj denote the j th operation in Q.
3. Let the function ready(o) return true if S̄ + (M(o)) ≥ S̄ + (J (o)), false otherwise.
4. For i from 1 to N M do:
(a) If ready(Ti ), then set S̄(o) ← S̄ + (M(Ti )). Otherwise append Ti onto Q.
(b) For j from 1 to |Q| do:
i. If ready(Qj ), then set S̄(Qj ) ← S̄ + (M(Qj )) and remove Qj from Q.
5. Schedule any remaining operations of Q in a manner to be specified (in the last
paragraph of the proof).
The construction of S̄ is just like the construction of S, except for the manipulations
involving Q. The purpose of Q is to delay the scheduling of any operation o that, if
scheduled immediately, might produce a schedule in which S̄(o) > S̄ + (M(o)). We first
show that kS − S̄k < N 1+ whp; then we show that S̄ is optimal whp.
Let P
Qi denote Q as it exists after i iterations of step 4 have been performed. Let
NM
i
of iterations during which o ∈ Q. We claim that
q(o) =
i=1
P |o ∩ Q | be the number
N
M
|. Letting E 6= = {e ∈ E(I) : ~e(S̄) 6= ~e(S)}, we have
kS − S̄k ≤ o∈ops(I) q(o) + (N − 1)|Q
kS − S̄k = |{e ∈ E 6= : e ∩ QN M = ∅}| + |{e ∈ E 6= : e ∩ QN M 6= ∅}|
≤ |{e ∈ E 6= : e ∩ QN M = ∅}| + (N − 1)|QN M |
P
so it suffices to show |{e ∈ E 6= : e ∩ QN M = ∅}| ≤
o∈ops(I) q(o). To see this, let
=
6
N
M
e = {o1 , o2 } ∈ E be such that e ∩ Q
= ∅. We must have q(o1 ) + q(o2 ) > 0. We charge e
to the operation in {o1 , o2 } that was inserted into Q first. It is easy to see that an operation
can be charged for at most one edge perPiteration it spends in Q, establishing our claim.
Thus it suffices to show that kS − S̄k ≤ o∈ops(I) q(o) + (N − 1)|QN M | ≤ N 1+ whp.
1

0

1

0

We divide the construction of S into n = M N 2 − epochs, each consisting of N 2 +
iterations of step 4, for a to-be-specified 0 > 0. Let zj denote the number of iterations of
step 4 that occur before the end of the j th epoch, with zj = 0 for j ≤ 0 by convention. Let
m̄
• Cjm̄ ≡ T(0,z
\ Qzj be the set of operations that have been scheduled to run on m̄ by
j]

the end of the j th epoch; and
281

Streeter & Smith

S
• Onear ≡ j∈[n] {o ∈ T(zj−1 ,zj ] : J (o) ∈ T(zj−(M +2) ,zj ] } be the set of operations whose
job-predecessor belongs to a nearby epoch.
1

0

For any i ∈ [N M ], P[Ti ∈ Onear ] ≤ (M + 2)N − 2 + . Thus for any j ∈ [n], E[|Onear ∩
0
T(zj−1 ,zj ] |] ≤ (M + 2)N 2 . Using A.P.I. it is straightforward to show that whp,
|Onear ∩ T(zj−1 ,zj ] | ≤ N

1+0
2

∀j ∈ [n] .

(9.1)

We claim that whp, the following statements hold ∀j ∈ [n]:
[

Qi ⊆ Onear ,

(9.2)

i≤zj

J ∩ Qzj−1 6= ∅ ⇒ |J ∩ Qzj−1 ∩ Qzj | < |J ∩ Qzj−1 |
zj

zj−M

Q ∩Q

|Qzj | ≤ M N

∀J ∈ I ,

(9.3)

= ∅ , and
1+0
2

(9.4)

.

(9.5)

We prove this by induction, where each step of the induction fails with exponentially
small probability. For j = 0, (9.3) and (9.4) hold trivially. (9.2) is true because the
operations in T(0,z1 ] \ Onear are the first operations in their jobs, hence cannot be added to
Q. (9.5) then follows from (9.2) and (9.1).
Consider the case j > 0. To show (9.2), let o be an arbitrary operation in T(zj−1 ,zj ] \Onear .
m(J (o))

By the induction hypothesis (specifically, equation (9.4)), J (o) ∈ Cj−2




m(J (o))
m(o)
0 ⇒ τ Cj−2
> τ Cj−1 . By the induction hypothesis,

. Thus q(o) >









1+0
m(o)
m(J (o))
m(o)
m(J (o))
.
τ Cj−1 − τ Cj−2
≥ τ T(0,zj−1 ] − M N 2 − τ T(0,zj−2 ]
Letting ∆ denote the right hand side of this inequality, we have E[∆] =
1+0
2

1
+0
1
2
MN

−

, and A.P.I. can be used to show that for some K > 0 independent of N , P[∆ <
MN
0
0
0] ≤ exp(− K1 N  ). Thus (9.2) holds with probability at least 1 − exp(− K1 N  ).
To show (9.3), let J be such that J ∩ Qzj−1 6= ∅, and let Ji ∈ Qzj−1 be
 chosenso that i is
m(J (Ji ))
m(J (Ji ))
m(J )
minimal. Then J (Ji ) ∈ Cj−1
. Thus Ji ∈ Qzj ⇒ τ Cj−1
> τ Cj i . By (9.1),
1+0

(9.2), and the induction hypothesis (equation (9.5)), |Qzj | ≤ (M + 1)N 2 . Using the same
0
technique as above, we can show that (9.3) holds with probability at least 1 − exp(− K1 N  )
for some K > 0 independent of N .
(9.3) implies (9.4). (9.2) and (9.4) together with (9.1) imply (9.5). Thus whp, (9.2)
through (9.5) hold ∀j ∈ [n].
By (9.2) and (9.4), we have


X
1
0
0
E
q(o) ≤ E[|Onear |]M N 2 + ≤ M 2 (M + 2)N 1+2
o∈ops(I)

and also
282

The Landscape of Random Job Shop Scheduling Instances

0

E[|QN M |] ≤ E[|T(zn−M ,zn ] ∩ Onear |] ≤ (M + 2)N 2
P
so setting 0 = 3 gives kS − S̄k ≤ o∈ops(I) q(o) + (N − 1)|QN M | ≤ N 1+ whp.
It remains to show that S̄ is optimal whp. We first prove the following claim.
Claim 4.1. For any non-negative integers a and b, the probability that T(a,b] contains
two operations from the same job is at most

(b−a)2
N .

Proof of Claim 4.1. Let X denote the number of pairs of operations in T(a,b] that belong to
1
(b−a)2
the same job. Then P[X > 0] ≤ E[X] ≤ b−a
2 N ≤
N .
To see that S̄ is optimal whp, note that the operations scheduled prior to step 5 do not
cause any idle time on any machine, so it is only the operations in QN M that can cause S̄
to be sub-optimal. Let τ (m̄) ≡ τ ({o ∈ ops(I) : m(o) = m̄}) denote the workload of machine
m̄. Let m̂ = arg maxm̄∈[M ] τ (m̄). Then the following hold whp.
• The set Z m̂ ≡ T m̂
last. (It holds

1

consists of operations belonging to jobs that use m̂

(N M −2M N 4 ,N M ]
whp that Z m̂ ⊂ Z,

where Z ≡ T

1

(N M −N 3 ,N M ]

. So if Z m̂ contains an

operation from a job that does not use m̂ last, then Z must contain two operations
from the same job. But by Claim 4.1, the probability that this happens is at most
1
(N 3 )2 N1 = o(1).)
1

• µN 4 ≤ τ (Z m̂ ) and τ (Z m̂ ) ≤ τ (m̂) − τ (m̄) ∀m̄ 6= m̂. (This follows by applying the
Central Limit Theorem to τ (Z m̂ ), τ (m̂), and τ (m̄)).
Thus whp it holds that prior to the execution of step 5, S̄ contains a period of length
1
at least τ (Z m̂ ) ≥ µN 4 during which the only operations being processed are those in Z m̂ ,
0
where {o ∈ ops(I) : J (o) ∈ Z m̂ } = ∅. Assuming |QN M | < N 3 (holds whp), we can always
schedule the operations in QN M so as to guarantee `(S̄) = τ (m̂), which implies S̄ is optimal.

Theorem 6. Let I be a random N by M JSP instance with optimal makespan `min (I) and
let S be a random schedule for I. Then for fixed M and  > 0, it holds whp (as N → ∞)
that `(S) ≤ (1 + )`min (I).
Proof. As in the proof of Lemma 4, let T be the sequence of operations o ∈ ops(I), sorted
in ascending order by priority πrand (I, o) (where πrand is the random priority rule used to
create S). Note that for any o ∈ ops(I) with J (o) 6= o∅ , J (o) must appear before o in T .
Let Ti denote the ith operation in T .
Rather than analyze S directly, we analyze a schedule S̄ defined by the following procedure:
1. t ← 0.
2. For i from 1 to N M do:
283

Streeter & Smith

(a) Set S̄(Ti ) = max(t, S̄ + (J (Ti )), S̄ + (M(Ti ))) .
(b) If S̄ + (J (Ti )) > S̄ + (M(Ti )), set t = maxi0 ≤i S̄ + (Ti0 ).
The procedure is identical to the one used to construct S, except that, whenever an
operation Ti is assigned a start time S̄(Ti ) > S̄ + (M(Ti )), the procedure inserts artificial
delays into the schedule in order to re-synchronize the machines. For any T , it is clear that
`(S) ≤ `(S̄). Thus, it suffices to show that `(S̄) ≤ (1 + )`min (I) whp.
We divide the construction of S̄ into n epochs, where each update to t (in step 2(b)) defines the beginning of a new epoch. Let zi be the number of operations scheduled before the
end of the ith epoch, with z0 = 0 by convention. Let ti = maxi0 ≤zi S + (oi0 ) be the (updated)
P
+
0
value of t at the end ofPthe ith epoch. Define ∆i ≡ M
m̄=1
Ptni − maxi0 <i,m(Ti0 )=m̄ S (Ti ).
n
Then `(S̄) − `min (I) ≤ i=1 ∆i , so it suffices to show that i=1 ∆i ≤ `min (I) whp.
P
2
Let I P
= [n], and let L = {i ∈ I : zi − zi−1 ≥ N 7 }. We first consider i∈L ∆i ; then we
consider i∈I\L ∆i .
2

Let i1 and i2 be arbitrary integers with 0 ≤ i1 , i2 ≤ N M and i2 − i1 ≥ N 7 . Let
−i1
. For any T , τ̄ is a function of the outcome of at most
τ̄ = τ (T(im̄1 ,i2 ] ). Then E[τ̄ ] = µ i2M
i2 − i1 events (namely, the definition of each of the jobs in {J : J ∩ T(i1 ,i2 ] 6= ∅}), each of
which alters the value of τ̄ by at most τmax . It follows by A.P.I. that
!
0
√
N 2
0
P[|τ̄ − E[τ̄ ]| > N
i2 − i1 ] ≤ 2 exp − 2
2τmax
√
for any 0 > 0. Thus, it holds whp that |τ̄ − E[τ̄ ]| ≤ N  i2 − i1 for all possible choices
0√
of i1 and i2 . In particular, whp
we have ∆i ≤ 2M N  zi − zi−1 ≤ ∀i ∈ L, which implies
p
P
5 P
6
2
0
0
7
2M N  N 7 = 2M N 7 + .
i∈L ∆i ≤ N
i∈L
P
Now consider
i∈I\L ∆i . As shown in the proof of Lemma 4 (Claim 4.1), for any
non-negative integers a and b the probability that T(a,b] contains two operations from the
2

2

7
same job is at most (b−a)
N . Thus the probability that an arbitrary subsequence of size N
4
− 37
contains two operations from the same job is at most N , so E[|I \ L|] ≤ N 7 . Clearly
P
2
6
∆i ≤ τmax N 7 ∀i ∈ I \ L, so E[ i∈I\L ∆i ] is O(N 7 ).
P
P
6
6
0
0
Thus E[ i∈I ∆i ] is O(N 7 + ) for any 0 > 0, so i∈I ∆i ≤ N 7 +2 whp, while it is easy
to see that `min (I) ≥ µ N2 whp.

References
Achlioptas, D., & Peres, Y. (2004). The threshold for random k-SAT is 2k log 2 − O(k).
Journal of the AMS, 17, 947–973.
Balas, E. (1969). Machine sequencing via disjunctive graphs: An implicit enumeration
algorithm. Operations Research, 17, 1–10.
Beasley, J. E. (1990). OR-library: Distributing test problems by electronic mail. Journal of
the Operational Research Society, 41(11), 1069–1072.
284

The Landscape of Random Job Shop Scheduling Instances

Beck, J. C., & Jackson, W. K. (1997). Constrainedness and the phase transition in job
shop scheduling. Tech. rep. CMPT97-21, School of Computing Science, Simon Fraser
University.
Boese, K. D., Kahng, A. B., & Muddu, S. (1994). A new adaptive multi-start technique for
combinatorial global optimizations. Operations Research Letters, 16, 101–113.
Brucker, P., Jurisch, B., & Sievers, B. (1992). Job-shop (C-codes). European Journal of Operational Research, 57, 132–133. Code available at http://optimierung.
mathematik.uni-kl.de/ORSEP/contents.html.
Brucker, P., Jurisch, B., & Sievers, B. (1994). A branch and bound algorithm for the
job-shop scheduling problem. Discrete Applied Mathematics, 49(1-3), 107–127.
Cheeseman, P., Kanefsky, B., & Taylor, W. M. (1991). Where the really hard problems are.
In Proceedings of the Twelfth International Joint Conference on Artificial Intelligence,
IJCAI-91, Sidney, Australia, pp. 331–337.
Fisher, H., & Thompson, G. L. (1963). Probabilistic learning combinations of local job-shop
scheduling rules. In Muth, J. F., & Thompson, G. L. (Eds.), Industrial Scheduling,
pp. 225–251. Prentice-Hall, Englewood Cliffs, NJ.
Framinan, J. M., Gupta, J. N. D., & Leisten, R. (2004). A review and classification of
heuristics for permutation flow-shop scheduling with makespan objective. Journal of
the Operational Research Society, 55(12), 1243–1255.
French, S. (1982). Sequencing and Scheduling: An Introduction to the Mathematics of the
Job-Shop. Wiley, New York.
Glover, F., & Laguna, M. (1997). Tabu Search. Kluwer Academic Publishers, Boston, MA.
Hejazi, S. R., & Saghafian, S. (2005). Flowshop-scheduling problems with makespan criterion: a review. International Journal of Production Research, 43(14), 2895–2929.
Hoos, H. H., & Stützle, T. (2000). SATLIB: An online resource for research on SAT. In
Gent, I. P., v. Maaren, H., & Walsh, T. (Eds.), Proceedings of SAT 2000, pp. 283–292.
SATLIB is available online at www.satlib.org.
Jain, A., & Meeran, S. (1998). A state-of-the-art review of job-shop scheduling techniques.
Tech. rep., Department of Applied Physics, Electronic and Mechanical Engineering,
University of Dundee, Dundee, Scotland.
Jones, A., & Rabelo, L. C. (1998). Survey of job shop scheduling techniques. Tech. rep.,
National Institute of Standards and Technology, Gaithersburg, MD.
Kim, Y.-H., & Moon, B.-R. (2004). Investigation of the fitness landscapes in graph bipartitioning: An empirical study. Journal of Heuristics, 10, 111–133.
Lourenco, H., Martin, O., & Stützle, T. (2003). Iterated local search. In Glover, F., &
Kochenberger, G. (Eds.), Handbook of Metaheuristics. Kluwer Academic Publishers,
Boston, MA.
Mammen, D. L., & Hogg, T. (1997). A new look at the easy-hard-easy pattern of combinatorial search difficulty. Journal of Artificial Intelligence Research, 7, 47–66.
285

Streeter & Smith

Martin, O. C., Otto, S. W., & Felten, E. W. (1991). Large-step Markov chains for the
traveling salesman problem. Complex Systems, 5, 299–326.
Martin, O. C., Monasson, R., & Zecchina, R. (2001). Statistical mechanics methods and
phase transitions in combinatorial problems. Theoretical Computer Science, 265(1-2),
3–67.
Mattfeld, D. C. (1996). Evolutionary Search and the Job Shop: Investigations on Genetic
Algorithms for Production Scheduling. Physica-Verlag, Heidelberg.
Mattfeld, D. C., Bierwirth, C., & Kopfer, H. (1999). A search space analysis of the job shop
scheduling problem. Annals of Operations Research, 86, 441–453.
Mézard, M., & Parisi, G. (1986). A replica analysis of the traveling salesman problem.
Journal de Physique, 47, 1285–1296.
Monasson, R., Zecchina, R., Kirkpatrick, S., Selman, B., & Troyansky, L. (1999). Determining computational complexity from characteristic ‘phase transitions’. Nature, 400,
133–137.
Nowicki, E., & Smutnicki, C. (1996). A fast taboo search algorithm for the job-shop problem.
Management Science, 42(6), 797–813.
Nowicki, E., & Smutnicki, C. (2001). Some new ideas in TS for job shop scheduling. Tech.
rep. 50/2001, University of Wroclaw.
Nowicki, E., & Smutnicki, C. (2005). An advanced tabu search algorithm for the job shop
problem. Journal of Scheduling, 8, 145–159.
Reeves, C. R., & Yamada, T. (1998). Genetic algorithms, path relinking, and the flowshop
sequencing problem. Evolutionary Computation, 6, 45–60.
Roy, B., & Sussmann, B. (1964). Les problèmes dordonnancement avec contraintes disjonctives. Note D.S. no. 9 bis, SEMA, Paris, France, Décembre.
Selman, B., Kautz, H., & Cohen, B. (1994). Noise strategies for local search. In Proceedings
of AAAI-94, pp. 337–343.
Slaney, J., & Walsh, T. (2001). Backbones in optimization and approximation. In Proceedings of the 17th International Joint Conference on Artificial Intelligence (IJCAI2001), pp. 254–259.
Spencer, J. (2005). Modern probabilistic methods in combinatorics. http://www.cs.nyu.
edu/cs/faculty/spencer/papers/stirlingtalk.pdf.
Streeter, M. J., & Smith, S. F. (2005a). Characterizing the distribution of low-makespan
schedules in the job shop scheduling problem. In Biundo, S., Myers, K., & Rajan, K.
(Eds.), Proceedings of ICAPS 2005, pp. 61–70.
Streeter, M. J., & Smith, S. F. (2005b). Supplemental material for ICAPS 2005 paper
‘Characterizing the distribution of low-makespan schedules in the job shop scheduling
problem’. http://www.cs.cmu.edu/~matts/icaps_2005.
Taillard, E. (1993). Benchmarks for basic scheduling problems. European Journal of Operational Research, 64, 278–285.
286

The Landscape of Random Job Shop Scheduling Instances

Taillard, E. (1994). Parallel taboo search techniques for the job shop scheduling problem.
ORSA Journal on Computing, 6, 108–117.
van Laarhoven, P., Aarts, E., & Lenstra, J. (1992). Job shop scheduling by simulated
annealing. Operations Research, 40(1), 113–125.
Watson, J.-P., Barbulescu, L., Whitley, L. D., & Howe, A. (2002). Contrasting structured
and random permutation flow-shop scheduling problems: search-space topology and
algorithm performance. INFORMS Journal on Computing, 14(2), 98–123.
Watson, J.-P., Beck, J. C., Howe, A. E., & Whitley, L. D. (2001). Toward an understanding
of local search cost in job-shop scheduling. In Cesta, A. (Ed.), Proceedings of the Sixth
European Conference on Planning.
Yokoo, M. (1997). Why adding more constraints makes a problem easier for hill-climbing
algorithms: Analyzing landscapes of CSPs. In Principles and Practice of Constraint
Programming, pp. 356–370.
Zhang, W. (2004). Configuartion landscape analysis and backbone guided local search: Part
I: Satisfiability and maximum satisfiability. Artificial Intelligence, 158(1), 1–26.
Zhang, W., & Looks, M. (2005). A novel local search algorithm for the traveling salesman problem that exploits backbones. In Proceedings of the 19th International Joint
Conference on Artificial Intelligence, pp. 343–350.

287

Journal of Artificial Intelligence Research 26 (2006) 1–34

Submitted 11/05; published 05/06

A Logic for Reasoning about Evidence
Joseph Y. Halpern

halpern@cs.cornell.edu

Cornell University, Ithaca, NY 14853 USA

Riccardo Pucella

riccardo@ccs.neu.edu

Northeastern University, Boston, MA 02115 USA

Abstract
We introduce a logic for reasoning about evidence that essentially views evidence as
a function from prior beliefs (before making an observation) to posterior beliefs (after
making the observation). We provide a sound and complete axiomatization for the logic,
and consider the complexity of the decision problem. Although the reasoning in the logic
is mainly propositional, we allow variables representing numbers and quantification over
them. This expressive power seems necessary to capture important properties of evidence.

1. Introduction
Consider the following situation, essentially taken from Halpern and Tuttle (1993) and
Fagin and Halpern (1994). A coin is tossed, which is either fair or double-headed. The coin
lands heads. How likely is it that the coin is double-headed? What if the coin is tossed
20 times and it lands heads each time? Intuitively, it is much more likely that the coin
is double-headed in the latter case than in the former. But how should the likelihood be
measured? We cannot simply compute the probability of the coin being double-headed;
assigning a probability to that event requires that we have a prior probability on the coin
being double-headed. For example, if the coin was chosen at random from a barrel with
one billion fair coins and one double-headed coin, it is still overwhelmingly likely that the
coin is fair, and that the sequence of 20 heads is just unlucky. However, in the problem
statement, the prior probability is not given. We can show than any given prior probability
on the coin being double-headed increases significantly as a result of seeing 20 heads. But,
intuitively, it seems that we should be able to say that seeing 20 heads in a row provides
a great deal of evidence in favor of the coin being double-headed without invoking a prior.
There has been a great deal of work in trying to make this intuition precise, which we now
review.
The main feature of the coin example is that it involves a combination of probabilistic outcomes (e.g., the coin tosses) and nonprobabilistic outcomes (e.g., the choice of the
coin). There has been a great deal of work on reasoning about systems that combine both
probabilistic and nondeterministic choices; see, for example, Vardi (1985), Fischer and Zuck
(1988), Halpern, Moses, and Tuttle (1988), Halpern and Tuttle (1993), de Alfaro (1998),
He, Seidel, and McIver (1997). However, the observations above suggest that if we attempt
to formally analyze this situation in one of those frameworks, which essentially permit only
the modeling of probabilities, we will not be able to directly capture this intuition about
increasing likelihood. To see how this plays out, consider a formal analysis of the situation
in the Halpern-Tuttle (1993) framework. Suppose that Alice nonprobabilistically chooses

c
2006
AI Access Foundation. All rights reserved.

Halpern & Pucella

one of two coins: a fair coin with probability 1/2 of landing heads, or a double-headed coin
with probability 1 of landing heads. Alice tosses this coin repeatedly. Let ϕk be a formula
stating: “the kth coin toss lands heads”. What is the probability of ϕk according to Bob,
who does not know which coin Alice chose, or even the probability of Alice’s choice?
According to the Halpern-Tuttle framework, this can be modeled by considering the
set of runs describing the states of the system at each point in time, and partitioning
this set into two subsets, one for each coin used. In the set of runs where the fair coin
is used, the probability of ϕk is 1/2; in the set of runs where the double-headed coin is
used, the probability of ϕk is 1. In this setting, the only conclusion that can be drawn is
(PrB (ϕk ) = 1/2) ∨ (PrB (ϕk ) = 1). (This is of course the probability from Bob’s point of
view; Alice presumably knows which coin she is using.) Intuitively, this seems reasonable:
if the fair coin is chosen, the probability that the kth coin toss lands heads, according to
Bob, is 1/2; if the double-headed coin is chosen, the probability is 1. Since Bob does not
know which of the coins is being used, that is all that can be said.
But now suppose that, before the 101st coin toss, Bob learns the result of the first 100
tosses. Suppose, moreover, that all of these landed heads. What is the probability that the
101st coin toss lands heads? By the same analysis, it is still either 1/2 or 1, depending on
which coin is used.
This is hardly useful. To make matters worse, no matter how many coin tosses Bob
witnesses, the probability that the next toss lands heads remains unchanged. But this
answer misses out on some important information. The fact that all of the first 100 coin
tosses are heads is very strong evidence that the coin is in fact double-headed. Indeed, a
straightforward computation using Bayes’ Rule shows that if the prior probability of the
coin being double-headed is α, then after observing that all of the 100 tosses land heads,
the probability of the coin being double-headed becomes
α
α + 2−100 (1 − α)

=

2100 α
.
2100 α + (1 − α)

However, note that it is not possible to determine the posterior probability that the coin is
double-headed (or that the 101st coin toss is heads) without the prior probability α. After
all, if Alice chooses the double-headed coin with probability only 10−100 , then it is still
overwhelmingly likely that the coin used is in fact fair, and that Bob was just very unlucky
to see such an unrepresentative sequence of coin tosses.
None of the frameworks described above for reasoning about nondeterminism and probability takes the issue of evidence into account. On the other hand, evidence has been
discussed extensively in the philosophical literature. Much of this discussion occurs in the
philosophy of science, specifically confirmation theory, where the concern has been historically to assess the support that evidence obtained through experimentation lends to various
scientific theories (Carnap, 1962; Popper, 1959; Good, 1950; Milne, 1996). (Kyburg (1983)
provides a good overview of the literature.)
In this paper, we introduce a logic for reasoning about evidence. Our logic extends a
logic defined by Fagin, Halpern and Megiddo (1990) (FHM from now on) for reasoning about
likelihood expressed as either probability or belief. The logic has first-order quantification
over the reals (so includes the theory of real closed fields), as does the FHM logic, for
reasons that will shortly become clear. We add observations to the states, and provide an
2

A Logic for Reasoning about Evidence

additional operator to talk about the evidence provided by particular observations. We also
refine the language to talk about both the prior probability of hypotheses and the posterior
probability of hypotheses, taking into account the observation at the states. This lets us
write formulas that talk about the relationship between the prior probabilities, the posterior
probabilities, and the evidence provided by the observations.
We then provide a sound and complete axiomatization for the logic. To obtain such an
axiomatization, we seem to need first-order quantification in a fundamental way. Roughly
speaking, this is because ensuring that the evidence operator has the appropriate properties
requires us to assert the existence of suitable probability measures. It does not seem possible to do this without existential quantification. Finally, we consider the complexity of the
satisfiability problem. The complexity problem for the full language requires exponential
space, since it incorporates the theory of real closed fields, for which an exponential-space
lower bound is known (Ben-Or, Kozen, & Reif, 1986). However, we show that the satisfiability problem for a propositional fragment of the language, which is still strong enough to
allow us to express many properties of interest, is decidable in polynomial space.
It is reasonable to ask at this point why we should bother with a logic of evidence. Our
claim is that many decisions in practical applications are made on the basis of evidence.
To take an example from security, consider an enforcement mechanism used to detect and
react to intrusions in a computer system. Such an enforcement mechanism analyzes the
behavior of users and attempts to recognize intruders. Clearly the mechanism wants to
make sensible decisions based on observations of user behaviors. How should it do this?
One way is to think of an enforcement mechanism as accumulating evidence for or against
the hypothesis that the user is an intruder. The accumulated evidence can then be used as
the basis for a decision to quarantine a user. In this context, it is not clear that there is a
reasonable way to assign a prior probability on whether a user is an intruder. If we want
to specify the behavior of such systems and prove that they meet their specifications, it is
helpful to have a logic that allows us to do this. We believe that the logic we propose here
is the first to do so.
The rest of the paper is organized as follows. In the next section, we formalize a notion
of evidence that captures the intuitions outlined above. In Section 3, we introduce our logic
for reasoning about evidence. In Section 4, we present an axiomatization for the logic and
show that it is sound and complete with respect to the intended models. In Section 5, we
discuss the complexity of the decision problem of our logic. In Section 6, we examine some
alternatives to the definition of weight of evidence we use. For ease of exposition, in most
of the paper, we consider a system where there are only two time points: before and after
the observation. In Section 7, we extend our work to dynamic systems, where there can be
multiple pieces of evidence, obtained at different points in time. The proofs of our technical
results can be found in the appendix.

2. Measures of Confirmation and Evidence
In order to develop a logic for reasoning about evidence, we need to first formalize an
appropriate notion of evidence. In this section, we review various formalizations from the
literature, and discuss the formalization we use. Evidence has been studied in depth in the
philosophical literature, under the name of confirmation theory. Confirmation theory aims

3

Halpern & Pucella

at determining and measuring the support a piece of evidence provides an hypothesis. As we
mentioned in the introduction, many different measures of confirmation have been proposed
in the literature. Typically, a proposal has been judged on the degree to which it satisfies
various properties that are considered appropriate for confirmation. For example, it may be
required that a piece of evidence e confirms an hypothesis h if and only if e makes h more
probable. We have no desire to enter the debate as to which class of measures of confirmation
is more appropriate. For our purposes, most confirmation functions are inappropriate:
they assume that we are given a prior on the set of hypotheses and observations. By
marginalization, we also have a prior on hypotheses, which is exactly the information we do
not have and do not want to assume. One exception is measures of evidence that use the
log-likelihood ratio. In this case, rather than having a prior on hypotheses and observations,
it suffices that there be a probability µh on observations for each hypothesis h: intuitively,
µh (ob) is the probability of observing ob when h holds. Given an observation ob, the degree
of confirmation that it provides for an hypothesis h is


µh (ob)
,
l(ob, h) = log
µh (ob)
where h represents the hypothesis other than h (recall that this approach applies only if
there are two hypotheses). Thus, the degree of confirmation is the ratio between these
two probabilities. The use of the logarithm is not critical here. Using it ensures that the
likelihood is positive if and only if the observation confirms the hypothesis. This approach
has been advocated by Good (1950, 1960), among others.1
One problem with the log-likelihood ratio measure l as we have defined it is that it can
be used only to reason about evidence discriminating between two competing hypotheses,
namely between an hypothesis h holding and the hypothesis h not holding. We would like
a measure of confirmation along the lines of the log-likelihood ratio measure, but that can
handle multiple competing hypotheses. There have been a number of such generalizations,
for example, by Pearl (1988) and Chan and Darwiche (2005). We focus here on the generalization given by Shafer (1982) in the context of the Dempster-Shafer theory of evidence
based on belief functions (Shafer, 1976); it was further studied by Walley (1987). The
description here is taken mostly from Halpern and Fagin (1992). While this measure of
confirmation has a number of nice properties of which we take advantage, much of the work
presented in this paper can be adapted to different measures of confirmation.
We start with a finite set H of mutually exclusive and exhaustive hypotheses; thus,
exactly one hypothesis holds at any given time. Let O be the set of possible observations
(or pieces of evidence). For simplicity, we assume that O is finite. Just as in the case of loglikelihood, we also assume that, for each hypotheses h ∈ H, there is a probability measure
µh on O such that µh (ob) is the probability of ob if hypothesis h holds. Furthermore, we
assume that the observations in O are relevant to the hypotheses: for every observation
ob ∈ O, there must be an hypothesis h such that µh (ob) > 0. (The measures µh are often
called likelihood functions in the literature.) We define an evidence space (over H and O)
1. Another related approach, the Bayes factor approach, is based on taking the ratio of odds rather than
likelihoods (Good, 1950; Jeffrey, 1992). We remark that in the literature, confirmation is usually taken
with respect to some background knowledge. For ease of exposition, we ignore background knowledge
here, although it can easily be incorporated into the framework we present.

4

A Logic for Reasoning about Evidence

to be a tuple E = (H, O, µ), where µ is a function that assigns to every hypothesis h ∈ H
the likelihood function µ(h) = µh . (For simplicity, we usually write µh for µ(h), when the
the function µ is clear from context.)
Given an evidence space E, we define the weight that the observation ob lends to hypothesis h, written wE (ob, h), as
µh (ob)
.
h0 ∈H µh0 (ob)

wE (ob, h) = P

(1)

The measure wE always lies between 0 and 1; intuitively, if wE (ob, h) = 1, then ob fully
confirms h (i.e., h is certainly true if ob is observed), while if wE (ob, h) = 0, then ob
disconfirms h (i.e.,
P h is certainly false
P if ob is observed). Moreover, for each fixed observation
ob for which
µ
(ob)
>
0,
h
h∈H
h∈H wE (ob, h) = 1, and thus the weight of evidence
wE looks like a probability measure for each ob. While this has some useful technical
consequences, one should not interpret wE as a probability measure. Roughly speaking, the
weight wE (ob, h) is the likelihood that h is the right hypothesis in the light of observation
ob.2 The advantages of wE over other known measures of confirmation are that (a) it is
applicable when we are not given a prior probability distribution on the hypotheses, (b) it
is applicable when there are more than two competing hypotheses, and (c) it has a fairly
intuitive probabilistic interpretation.
An important problem in statistical inference (Casella & Berger, 2001) is that of choosing
the best parameter (i.e., hypothesis) that explains observed data. When there is no prior
on the parameters, the “best” parameter is typically taken to be the one that maximizes
the likelihood of the data given that parameter. Since wE is just a normalized likelihood
function, the parameter that maximizes the likelihood will also maximize wE . Thus, if all
we are interested in is maximizing likelihood, there is no need to normalize the evidence as
we do. We return to the issue of normalization in Section 6.3
Note that if H = {h1 , h2 }, then wE in some sense generalizes the log-likelihood ratio
measure. More precisely, for a fixed observation ob, wE (ob, ·) induces the same relative order
on hypotheses as l(ob, ·), and for a fixed hypothesis h, wE (·, h) induces the same relative
order on observations as l(·, h).
Proposition 2.1: For all ob, we have wE (ob, hi ) ≥ wE (ob, h3−i ) if and only if l(ob, hi ) ≥
l(ob, h3−i ), for i = 1, 2, and for all h, ob, and ob 0 , we have wE (ob, h) ≥ wE (ob 0 , h) if and
only if l(ob, h) ≥ l(ob 0 , h).
2. We could have taken the log of the ratio to make wE parallel the log-likelihood ratio l defined earlier,
but there are technical advantages in having the weight of evidence be a number between 0 and 1.
3. Another representation of evidence that has similar characteristics to wE is Shafer’s original representation of evidence via belief functions (Shafer, 1976), defined as
wES (ob, h) =

µh (ob)
.
maxh∈H µh (ob)

This measure is known in statistical hypothesis testing as the generalized likelihood-ratio statistic. It is
another generalization of the log-likelihood ratio measure l. The main difference between wE and wES is
how they behave when one considers the combination of evidence, which we discuss later in this section.
As Walley (1987) and Halpern and Fagin (1992) point out, wE gives more intuitive results in this case.
We remark that the parameter (hypothesis) that maximized likelihood also maximizes wES , so wES can
also be used in statistical inference.

5

Halpern & Pucella

Although wE (ob, ·) behaves like a probability measure on hypotheses for every observation ob, one should not think of it as a probability; the weight of evidence of a combined
hypothesis, for instance, is not generally the sum of the weights of the individual hypotheses (Halpern & Pucella, 2005a). Rather, wE (ob, ·) is an encoding of evidence. But what
is evidence? Halpern and Fagin (1992) have suggested that evidence can be thought of as
a function mapping a prior probability on the hypotheses to a posterior probability, based
on the observation made. There is a precise sense in which wE can be viewed as a function
that maps a prior probability µ0 on the hypotheses H to a posterior probability µob based
on observing ob, by applying Dempster’s Rule of Combination (Shafer, 1976). That is,
µob = µ0 ⊕ wE (ob, ·),

(2)

where ⊕ combines two probability distributions on H to get a new probability distribution
on H defined as follows:
P
µ1 (h)µ2 (h)
(µ1 ⊕ µ2 )(H) = Ph∈H
.
h∈H µ1 (h)µ2 (h)
(Dempster’s Rule of Combination is used to combine belief functions. The definition of ⊕ is
more complicated when considering arbitrary belief functions, but in the special case where
the belief functions are in fact probability measures, it takes the form we give here.)
Bayes’ Rule is the standard way of updating a prior probability based on an observation,
but it is only applicable when we have a joint probability distribution on both the hypotheses
and the observations (or, equivalently, a prior on hypotheses together with the likelihood
functions µh for h ∈ H), something which we do not want to assume we are given. In
particular, while we are willing to assume that we are given the likelihood functions, we
are not willing to assume that we are given a prior on hypotheses. Dempster’s Rule of
Combination essentially “simulates” the effects of Bayes’ Rule. The relationship between
Dempster’s Rule and Bayes’ Rule is made precise by the following well-known theorem.
Proposition 2.2: (Halpern & Fagin, 1992) Let E = (H, O, µ) be an evidence space. Suppose
that P is a probability on H × O such that P (H × {ob} | {h} × O) = µh (ob) for all h ∈ H
and all ob ∈ O. Let µ0 be the probability on H induced by marginalizing P ; that is, µ0 (h) =
P ({h} × O). For ob ∈ O, let µob = µ0 ⊕ wE (ob, ·). Then µob (h) = P ({h} × O | H × {ob}).
In other words, when we do have a joint probability on the hypotheses and observations, then Dempster’s Rule of Combination gives us the same result as a straightforward
application of Bayes’ Rule.
Example 2.3: To get a feel for how this measure of evidence can be used, consider a
variation of the two-coins example in the introduction. Assume that the coin chosen by
Alice is either double-headed or fair, and consider sequences of a hundred tosses of that coin.
Let O = {m : 0 ≤ m ≤ 100} (the number of heads observed), and let H = {F, D}, where F
is “the coin is fair”, and D is “the coin is double-headed”. The probability spaces associated
with the hypotheses are generated by the following probabilities for simple observations m:



1 100
1 if m = 100
µF (m) = 100
µD (m) =
0 otherwise.
2
m
6

A Logic for Reasoning about Evidence

(We extend by additivity to the whole set O.) Take E = (H, O, µ), where µ(F ) = µF and
µ(D) = µD . For any observation m 6= 100, the weight in favor of F is given by

1 100
wE (m, F ) =

0

2100 m

1 100
+ 2100
m

= 1,

which means that the support of m is unconditionally provided to F ; indeed, any such
sequence of tosses cannot appear with the double-headed coin. Thus, if m 6= 100, we get
that
0
 = 0.
wE (m, D) =
1 100
0 + 2100 m
What happens when the hundred coin tosses are all heads? It is straightforward to check
that
1
1
1
2100
100
w
(100,
D)
=
;
wE (100, F ) = 2 1 =
=
E
1
1 + 2100
1 + 2100
1 + 2100
1 + 2100

this time there is overwhelmingly more evidence in favor of D than F .
Note that we have not assumed any prior probability. Thus, we cannot talk about the
probability that the coin is fair or double-headed. What we have is a quantitative assessment
of the evidence in favor of one of the hypotheses. However, if we assume a prior probability
α on the coin being fair and m heads are observed after 100 tosses, then the probability
that the coin is fair is 1 if m 6= 100; if m = 100 then, applying the rule of combination, the
posterior probability of the coin being fair is α/(α + (1 − α)2100 ).
t
u
Can we characterize weight functions using a small number of properties? More precisely,
given sets H and O, and a function f from O × H to [0, 1], are there properties of f that
ensure that there are likelihood functions µ such that f = wE for E = (H, O, µ)? As
we saw earlier, for a fixed observation ob, f essentially acts like a probability measure on
H. However, this is not sufficient to guarantee that f is a weight function. Consider the
following example, with O = {ob 1 , ob 2 } and H = {h1 , h2 , h3 }:
f (ob 1 , h1 ) = 1/4
f (ob 1 , h2 ) = 1/4
f (ob 1 , h3 ) = 1/2

f (ob 2 , h1 ) = 1/4
f (ob 2 , h2 ) = 1/2
f (ob 2 , h3 ) = 1/4.

It is straightforward to check that f (ob 1 , ·) and f (ob 2 , ·) are probability measures on H,
but that there is no evidence space E = (H, O, µ) such that f = wE . Indeed, assume that
we do have such µh1 , µh2 , µh3 . By the definition of weight of evidence, and the fact that f
is that weight of evidence, we get the following system of equations:
µh1 (ob 1 )
µh1 (ob 1 )+µh2 (ob 1 )+µh3 (ob 1 )
µh2 (ob 1 )
µh1 (ob 1 )+µh2 (ob 1 )+µh3 (ob 1 )
µh3 (ob 1 )
µh1 (ob 1 )+µh2 (ob 1 )+µh3 (ob 1 )

µh1 (ob 2 )
µh1 (ob 2 )+µh2 (ob 2 )+µh3 (ob 2 )
µh2 (ob 2 )
µh1 (ob 2 )+µh2 (ob 2 )+µh3 (ob 2 )
µh3 (ob 2 )
µh1 (ob 2 )+µh2 (ob 2 )+µh3 (ob 2 )

= 1/4
= 1/4
= 1/2

= 1/4
= 1/2
= 1/4.

It is now immediate that there exist α1 and α2 such that µhi (ob j ) = αj f (ob j , hi ), for
i = 1, 2, 3. Indeed, αj = µh1 (ob j ) + µh2 (ob j ) + µh3 (ob j ), for j = 1, 2. Moreover, since µhi is
a probability measure, we must have that
µhi (ob 1 ) + µhi (ob 2 ) = α1 f (ob 1 , hi ) + α2 f (ob 2 , hi ) = 1,
7

Halpern & Pucella

for i = 1, 2, 3. Thus,
α1 /4 + α2 /4 = α1 /4 + α2 /2 = α1 /2 + α4 /4 = 1.
These constraints are easily seen to be unsatisfiable.
This argument generalizes to arbitrary functions f ; thus, a necessary condition for f to
be a weight function is that there exists αi for each observation ob i such that µh (ob i ) =
αi f (ob i , h) for each hypothesis h is a probability measure, that is, α1 f (ob 1 , h) + · · · +
αk f (ob k , h) = 1. In fact, when combined with the constraint that f (ob, ·) is a probability
measure for a fixed ob, this condition turns out to be sufficient, as the following theorem
establishes.
Theorem 2.4: Let H = {h1 , . . . , hm } and O = {ob 1 , . . . , ob n }, and let f be a real-valued
function with domain O × H such that f (ob, h) ∈ [0, 1]. Then there exists an evidence space
E = (H, O, µ) such that f = wE if and only if f satisfies the following properties:
WF1. For every ob ∈ O, f (ob, ·) is a probability measure on H.
P
WF2. There exists x1 , . . . , xn > 0 such that, for all h ∈ H, ni=1 f (ob i , h)xi = 1.
This characterization is fundamental to the completeness of the axiomatization of the
logic we introduce in the next section. The characterization is complicated by the fact
that the weight of evidence is essentially a normalized likelihood: the likelihood of an
observation given a particular hypothesis is normalized using the sum of all the likelihoods
of that observation, for all possible hypotheses. One consequence of this, as we already
mentioned above, is that the weight of evidence is always between 0 and 1, and superficially
behaves like a probability measure. In Section 6, we examine the issue of normalization
more carefully, and describe the changes to our framework that would occur were we to
take unnormalized likelihoods as weight of evidence.
Let E = (H, O, µ) be an evidence space. Let O∗ be the set of sequences of observations
hob 1 , . . . , ob k i over O.4 Assume that the observations are independent, that is, for each basic
hypothesis h, take µ∗h (hob 1 , . . . , ob k i), the probability of observing a particular sequence of
observations given h, to be µh (ob 1 ) · · · µh (ob k ), the product of the probability of making
each observation in the sequence. Let E ∗ = (H, O∗ , µ∗ ). With this assumption, it is well
known that Dempster’s Rule of Combination can be used to combine evidence in this setting;
that is,
wE ∗ (hob 1 , . . . , ob k i, ·) = wE (ob 1 , ·) ⊕ · · · ⊕ wE (ob k , ·)
(Halpern & Fagin, 1992, Theorem 4.3). It is an easy exercise to check that the weight
provided by the sequence of observations hob 1 , . . . , ob k i can be expressed in terms of the
weight of the individual observations:
wE ∗ (ob 1 , h) · · · wE ∗ (ob k , h)
.
1 0
k 0
h0 ∈H wE ∗ (ob , h ) · · · wE ∗ (ob , h )

wE ∗ (hob 1 , . . . , ob k i, h) = P

(3)

4. We use superscript rather than subscripts to index observations in a sequence so that these observations
will not be confused with the basic observations ob 1 , . . . , ob n in O.

8

A Logic for Reasoning about Evidence

If we let µ0 be a prior probability on the hypotheses, and µhob 1 ,...,ob k i be the probability on
the hypotheses after observing ob 1 , . . . , ob k , we can verify that
µhob1 ,...,ob k i = µ0 ⊕ wE ∗ (hob 1 , . . . , ob k i, ·).
Example 2.5: Consider a variant of Example 2.3, where we take the coin tosses as individual observations, rather than the number of heads that turn up in one hundred coin
tosses. As before, assume that the coin chosen by Alice is either double-headed or fair. Let
O = {H, T }, the result of an individual coin toss, where H is “the coin landed heads” and
T is “the coin landed tails”. Let H = {F, D}, where F is “the coin is fair”, and D is “the
coin is double-headed”. Let E ∗ = (H, O∗ , µ∗ ). The probability measure µ∗h associated with
the hypothesis h are generated by the following probabilities for simple observations:
µF (H) =

1
2

µD (H) = 1.

Thus, for example, µ∗F (hH, H, T, Hi) = 1/16, µ∗D (hH, H, Hi) = 1, and µ∗H (hH, H, T, Hi) =
0.
We can now easily verify results similar to those that were obtained in Example 2.3.
For instance, the weight of observing T in favor of F is given by
wE ∗ (T, F ) =

1
2

0+

1
2

= 1,

which again indicates that observing T provides unconditional support to F ; a doubleheaded coin cannot land tails.
How about sequences of observations? The weight provided by the sequence hob 1 , . . . , ob k i
for hypothesis h is given by Equation (3). Thus, if H = hH, . . . , Hi, a sequence of a hundred
coin tosses, we can check that
wE ∗ (H, F ) =

1

1
2100
1
+ 2100

=

1
1 + 2100

wE ∗ (H, D) =

Unsurprisingly, this is the same result as in Example 2.3.

2100
1
.
=
1
1 + 2100
1 + 2100
t
u

3. Reasoning about Evidence
We introduce a logic Lfo -ev for reasoning about evidence, inspired by a logic introduced in
FHM for reasoning about probability. The logic lets us reason about the weight of evidence
of observations for hypotheses; moreover, to be able to talk about the relationship between
prior probabilities, evidence, and posterior probabilities, we provide operators to reason
about the prior and posterior probabilities of hypotheses. We remark that up to now we
have been somewhat agnostic about whether the priors exist but are not given (or not
known) or whether the prior does not exist at all. It is beyond the scope of this paper to
enter the debate about whether it always appropriate to assume the existence of a prior.
Although the definition of evidence makes sense even if the priors does not exist, our logic
implicitly assumes that there are priors (although they may not be known), since we provide
9

Halpern & Pucella

operators for reasoning about the prior. We make use of these operators in some of the
examples below. However, the fragment of the logic that does not use these operators is
appropriate for prior-free reasoning.
The logic has both propositional features and first-order features. We take the probability of propositions and the weight of evidence of observations for hypotheses, and view
probability and evidence as propositions, but we allow first-order quantification over numerical quantities, such as probabilities and evidence. The logic essentially considers two
time periods, which can be thought of as the time before an observation is made and the
time after an observation is made. In this section, we assume that exactly one observation
is made. (We consider sequences of observations in Section 7.) Thus, we can talk of the
probability of a formula ϕ before an observation is made, denoted Pr0 (ϕ), the probability
of ϕ after the observation, denoted Pr(ϕ), and the evidence provided by the observation ob
for an hypothesis h, denoted w(ob, h). Of course, we want to be able to use the logic to
relate all these quantities.
Formally, we start with two finite sets of primitive propositions, Φh = {h1 , . . . , hnh }
representing the hypotheses, and Φo = {ob 1 , . . . , ob no } representing the observations. Let
Lh (Φh ) be the propositional sublanguage of hypothesis formulas obtained by taking primitive propositions in Φh and closing off under negation and conjunction; we use ρ to range
over formulas of that sublanguage.
A basic term has the form Pr0 (ρ), Pr(ρ), or w(ob, h), where ρ is an hypothesis formula,
ob is an observation, and h is an hypothesis. As we said, we interpret Pr0 (ρ) as the
prior probability of ρ, Pr(ρ) as the posterior probability of ρ, and w(ob, h) as the weight of
evidence of observation ob for hypothesis h. It may seem strange that we allow the language
to talk about the prior probability of hypotheses, although we have said that we do not
want to assume that the prior is known. We could, of course, simplify the syntax so that
it did not include formulas of the form Pr0 (ρ) or Pr(ρ). The advantage of having them is
that, even if the prior is not known, given our view of evidence as a function from priors
to posteriors, we can make statements such as “if the prior probability of h is 2/3, ob is
observed, and the weight of evidence of ob for h is 3/4, then the posterior probability of h
is 6/7; this is just
Pr0 (h) = 1/2 ∧ ob ∧ w(ob, h) = 3/4 ⇒ Pr(h) = 6/7.
A polynomial term has the form t1 + · · · + tn , where each term ti is a product of integers,
basic terms, and variables (which range over the reals). A polynomial inequality formula
has the form p ≥ c, where p is a polynomial term and c is an integer. Let Lfo -ev (Φh , Φo )
be the language obtained by starting out with the primitive propositions in Φh and Φo
and polynomial inequality formulas, and closing off under conjunction, negation, and firstorder quantification. Let true be an abbreviation for an arbitrary propositional tautology
involving only hypotheses, such as h1 ∨ ¬h1 ; let false be an abbreviation for ¬true. With
this definition, true and false can be considered as part of the sublanguage Lh (Φh ).
It should be clear that while we allow only integer coefficients to appear in polynomial
terms, we can in fact express polynomial terms with rational coefficients by crossmultiplying.
For instance, 31 Pr(ρ) + 12 Pr(ρ0 ) ≥ 1 can be represented by the polynomial inequality formula
2Pr(ρ) + 3Pr(ρ0 ) ≥ 6. While there is no difficulty in giving a semantics to polynomial terms
that use arbitrary real coefficients, we need the restriction to integers in order to make use
10

A Logic for Reasoning about Evidence

of results from the theory of real closed fields in both the axiomatization of Section 4 and
the complexity results of Section 5.
We use obvious abbreviations where needed, such as ϕ ∨ ψ for ¬(¬ϕ ∧ ¬ψ), ϕ ⇒ ψ for
¬ϕ ∨ ψ, ∃xϕ for ¬∀x(¬ϕ), Pr(ϕ) − Pr(ψ) ≥ c for Pr(ϕ) + (−1)Pr(ψ) ≥ c, Pr(ϕ) ≥ Pr(ψ) for
Pr(ϕ) − Pr(ψ) ≥ 0, Pr(ϕ) ≤ c for −Pr(ϕ) ≥ −c, Pr(ϕ) < c for ¬(Pr(ϕ) ≥ c), and Pr(ϕ) = c
for (Pr(ϕ) ≥ c) ∧ (Pr(ϕ) ≤ c) (and analogous abbreviations for inequalities involving Pr0
and w).
Example 3.1: Consider again the situation given in Example 2.3. Let Φo , the observations,
consist of primitive propositions of the form heads[m], where m is an integer with 0 ≤ m ≤
100, indicating that m heads out of 100 tosses have appeared. Let Φh consist of the two
primitive propositions fair and doubleheaded. The computations in Example 2.3 can be
written as follows:
w(heads[100], fair) = 1/(1 + 2100 ) ∧ w(heads[100], doubleheaded) = 2100 /(1 + 2100 ).
We can also capture the fact that the weight of evidence of an observation maps a prior
probability into a posterior probability by Dempster’s Rule of Combination. For example,
the following formula captures the update of the prior probability α of the hypothesis fair
upon observation of a hundred coin tosses landing heads:
Pr0 (fair) = α ∧ w(heads[100], fair) = 1/(1 + 2100 ) ⇒ Pr(fair) = α/(α + (1 − α)2100 ).
We develop a deductive system to derive such conclusions in the next section.

t
u

Now we consider the semantics. A formula is interpreted in a world that specifies which
hypothesis is true and which observation was made, as well as an evidence space to interpret
the weight of evidence of observations and a probability distribution on the hypotheses to
interpret prior probabilities and talk about updating based on evidence. (We do not need
to include a posterior probability distribution, since it can be computed from the prior and
the weights of evidence using Equation (2).) An evidential world is a tuple w = (h, ob, µ, E),
where h is a hypothesis, ob is an observation, µ is a probability distribution on Φh , and E
is an evidence space over Φh and Φo .
To interpret propositional formulas in Lh (Φh ), we associate with each hypothesis formula
ρ a set [[ρ]] of hypotheses, by induction on the structure of ρ:
[[h]] = {h}
[[¬ρ]] = Φh − [[ρ]]
[[ρ1 ∧ ρ2 ]] = [[ρ1 ]] ∩ [[ρ2 ]].
To interpret first-order formulas that may contain variables, we need a valuation v that
assigns a real number to every variable. Given an evidential world w = (h, ob, µ, E) and a
valuation v, we assign to a polynomial term p a real number [p]w,v in a straightforward way:
[x]w,v = v(x)
[a]w,v = a
[Pr0 (ρ)]w,v = µ([[ρ]])
11

Halpern & Pucella

[Pr(ρ)]w,v = (µ ⊕ wE (ob, ·))([[ρ]])
[w(ob 0 , h0 )]w,v = wE (ob 0 , h0 )
[t1 t2 ]w,v = [t1 ]w,v × [t2 ]w,v
[p1 + p2 ]w,v = [p1 ]w,v + [p2 ]w,v .
Note that, to interpret Pr(ρ), the posterior probability of ρ after having observed ob (the
observation at world w), we use Equation (2), which says that the posterior is obtained by
combining the prior probability µ with wE (ob, ·).
We define what it means for a formula ϕ to be true (or satisfied) at an evidential world
w under valuation v, written (w, v) |= ϕ, as follows:
(w, v) |= h if w = (h, ob, µ, E) for some ob, µ, E
(w, v) |= ob if w = (h, ob, µ, E) for some h, µ, E
(w, v) |= ¬ϕ if (w, v) 6|= ϕ
(w, v) |= ϕ ∧ ψ if (w, v) |= ϕ and (w, v) |= ψ
(w, v) |= p ≥ c if [p]w,v ≥ c
(w, v) |= ∀xϕ if (w, v 0 ) |= ϕ for all v 0 that agree with v on all variables but x.
If (w, v) |= ϕ is true for all v, we write simply w |= ϕ. It is easy to check that if ϕ
is a closed formula (that is, one with no free variables), then (w, v) |= ϕ if and only if
(w, v 0 ) |= ϕ, for all v, v 0 . Therefore, given a closed formula ϕ, if (M, w, v) |= ϕ, then in fact
w |= ϕ. We will typically be concerned only with closed formulas. Finally, if w |= ϕ for
all evidential worlds w, we write |= ϕ and say that ϕ is valid. In the next section, we will
characterize axiomatically all the valid formulas of the logic.
Example 3.2: The following formula is valid, that is, true in all evidential worlds:
|= (w(ob, h1 ) = 2/3 ∧ w(ob, h2 ) = 1/3) ⇒ (Pr0 (h1 ) ≥ 1/100 ∧ ob) ⇒ Pr(h1 ) ≥ 2/101.
In other words, at all evidential worlds where the weight of evidence of observation ob for
hypothesis h1 is 2/3 and the weight of evidence of observation ob for hypothesis h2 is 1/3,
it must be the case that if the prior probability of h1 is at least 1/100 and ob is actually
observed, then the posterior probability of h1 is at least 2/101. This shows the extent to
which we can reason about the evidence independently of the prior probabilities.
t
u
The logic imposes no restriction on the prior probabilities to be used in the models.
This implies, for instance, that the formula
fair ⇒ Pr0 (fair) = 0
is satisfiable: there exists an evidential world w such that the formula is true at w. In other
words, it is consistent for an hypothesis to be true, despite the prior probability of it being
true being 0. It is a simple matter to impose a restriction on the models that they be such
that if h is true at a world, then µ(h) > 0 for the prior µ at that world.
12

A Logic for Reasoning about Evidence

We conclude this section with some remarks concerning the semantic model. Our semantic model implicitly assumes that the prior probability is known and that the likelihood
functions (i.e., the measures µh ) are known. Of course, in many situations there will be
uncertainty about both. Indeed, our motivation for focusing on evidence is precisely to deal
with situations where the prior is not known. Handling uncertainty about the prior is easy
in our framework, since our notion of evidence is independent of the prior on hypotheses. It
is straightforward to extend our model by allowing a set of possible worlds, with a different
prior in each, but using the same evidence space for all of them. We can then extend the
logic with a knowledge operator, where a statement is known to be true if it is true in all
the worlds. This allows us to make statements like “I know that the prior on hypothesis
h is between α and β. Since observation ob provides evidence 3/4 for h, I know that the
posterior on h given ob is between (3α)/(2α + 1) and (3β)/(2β + 1).”
Dealing with uncertainty about the likelihood functions is somewhat more subtle. To
understand the issue, suppose that one of two coins will be chosen and tossed. The bias of
coin 1 (i.e., the probability that coin 1 lands heads) is between 2/3 and 3/4; the bias of coin
2 is between 1/4 and 1/3. Here there is uncertainty about the probability that coin 1 will
be picked (this is uncertainty about the prior) and there is uncertainty about the bias of
each coin (this is uncertainty about the likelihood functions). The problem here is that, to
deal with this, we must consider possible worlds where there is a possibly different evidence
space in each world. It is then not obvious how to define weight of evidence. We explore
this issue in more detail in a companion paper (Halpern & Pucella, 2005a).

4. Axiomatizing Evidence
In this section we present a sound and complete axiomatization AX(Φh , Φo ) for our logic.
The axiomatization can be divided into four parts. The first part, consisting of the
following axiom and inference rule, accounts for first-order reasoning:
Taut. All substitution instances of valid formulas of first-order logic with equality.
MP. From ϕ and ϕ ⇒ ψ infer ψ.
Instances of Taut include, for example, all formulas of the form ϕ ∨ ¬ϕ, where ϕ is an
arbitrary formula of the logic. It also includes formulas such as (∀xϕ) ⇔ ϕ if x is not free
in ϕ. In particular, (∀x(h)) ⇔ h for hypotheses in Φh , and similarly for observations in
Φo . Note that Taut includes all substitution instances of valid formulas of first-order logic
with equality; in other words, any valid formula of first-order logic with equality where
free variables are replaced with arbitrary terms of our language (including Pr0 (ρ), Pr(ρ),
w(ob, h)) is an instance of Taut. Axiom Taut can be replaced by a sound and complete
axiomatization for first-order logic with equality, as given, for instance, in Shoenfield (1967)
or Enderton (1972).
The second set of axioms accounts for reasoning about polynomial inequalities, by relying
on the theory of real closed fields:
RCF. All instances of formulas valid in real closed fields (and, thus, true about the reals),
with nonlogical symbols +, ·, <, 0, 1, −1, 2, −2, 3, −3, . . . .

13

Halpern & Pucella

Formulas that are valid in real closed fields include, for example, the fact that addition on the
reals is associative, ∀x∀y∀z((x+y)+z = x+(y +z)), that 1 is the identity for multiplication,
∀x(x·1 = x), and formulas relating the constant symbols, such as k = 1+· · ·+1 (k times) and
−1 + 1 = 0. As for Taut, we could replace RCF by a sound and complete axiomatization
for real closed fields (cf. Fagin et al., 1990; Shoenfield, 1967; Tarski, 1951).
The third set of axioms essentially captures the fact that there is a single hypothesis
and a single observation that holds per state.
H1. h1 ∨ · · · ∨ hnh .
H2. hi ⇒ ¬hj if i 6= j.
O1. ob 1 ∨ · · · ∨ ob no .
O2. ob i ⇒ ¬ob j if i 6= j.
These axioms illustrate a subtlety of our logic. Like most propositional logics, ours is
parameterized by primitive propositions, in our case, Φh and Φo . However, while axiomatizations for propositional logics typically do not depend on the exact set of primitive
propositions, ours does. Clearly, axiom H1 is sound only if the hypothesis primitives are
exactly h1 , . . . , hnh . Similarly, axiom O1 is sound only if the observation primitives are
exactly ob 1 , . . . , ob no . It is therefore important for us to identify the primitive propositions
when talking about the axiomatization AX(Φh , Φo ).
The last set of axioms concerns reasoning about probabilities and evidence proper. The
axioms for probability are taken from FHM.
Pr1. Pr0 (true) = 1.
Pr2. Pr0 (ρ) ≥ 0.
Pr3. Pr0 (ρ1 ∧ ρ2 ) + Pr0 (ρ1 ∧ ¬ρ2 ) = Pr0 (ρ1 ).
Pr4. Pr0 (ρ1 ) = Pr0 (ρ2 ) if ρ1 ⇔ ρ2 is a propositional tautology.
Axiom Pr1 simply says that the event true has probability 1. Axiom Pr2 says that probability is nonnegative. Axiom Pr3 captures finite additivity. It is not possible to express
countable additivity in our logic. On the other hand, just as in FHM, we do not need an
axiom for countable additivity. Roughly speaking, as we establish in the next section, if
a formula is satisfiable at all, it is satisfiable in a finite structure. Similar axioms capture
posterior probability formulas:
Po1. Pr(true) = 1.
Po2. Pr(ρ) ≥ 0.
Po3. Pr(ρ1 ∧ ρ2 ) + Pr(ρ1 ∧ ¬ρ2 ) = Pr(ρ1 ).
Po4. Pr(ρ1 ) = Pr(ρ2 ) if ρ1 ⇔ ρ2 is a propositional tautology.

14

A Logic for Reasoning about Evidence

Finally, we need axioms to account for the behavior of the evidence operator w. What
are these properties? For one thing, the weight function acts essentially like a probability
on hypotheses, for each fixed observation, except that we are restricted to taking the weight
of evidence of basic hypotheses only. This gives the following axioms:
E1. w(ob, h) ≥ 0.
E2. w(ob, h1 ) + · · · + w(ob, hnh ) = 1.
Second, evidence connects the prior and posterior beliefs via Dempster’s Rule of Combination, as in (2). This is captured by the following axiom. (Note that, since we do not
have division in the language, we crossmultiply to clear the denominator.)
E3. ob ⇒ (Pr0 (h)w(ob, h) = Pr(h)Pr0 (h1 )w(ob, h1 ) + · · · + Pr(h)Pr0 (hnh )w(ob, hnh )).
This is not quite enough. As we saw in Section 2, property WF2 in Theorem 2.4 is
required for a function to be an evidence function. The following axiom captures WF2 in
our logic:
E4. ∃x1 . . . ∃xno (x1 > 0 ∧ · · · ∧ xno > 0 ∧ w(ob 1 , h1 )x1 + · · · + w(ob no , h1 )xno = 1∧
· · · ∧ w(ob 1 , hnh )x1 + · · · + w(ob no , hnh )xno = 1).
Note that axiom E4 is the only axiom that requires quantification. Moreover, axioms E3
and E4 both depend on Φh and Φo .
As an example, we show that if h and h0 are distinct hypotheses in Φh , then the formula
¬(w(ob, h) = 2/3 ∧ w(ob, h0 ) = 2/3)
is provable. First, by RCF, the following valid formula of the theory of real closed fields is
provable:
∀x∀y(x = 2/3 ∧ y = 2/3 ⇒ x + y > 1).
Moreover, if ϕ(x, y) is any first-order logic formula with two free variables x and y, then
(∀x∀y(ϕ(x, y))) ⇒ ϕ(w(ob, h), w(ob, h0 ))
is a substitution instance of a valid formula of first-order logic with equality, and hence is
an instance of Taut. Thus, by MP, we can prove that
w(ob, h) = 2/3 ∧ w(ob, h0 ) = 2/3 ⇒ w(ob, h) + w(ob, h0 ) > 1,
which is provably equivalent (by Taut and MP) to its contrapositive
w(ob, h) + w(ob, h0 ) ≤ 1 ⇒ ¬(w(ob, h) = 2/3 ∧ w(ob, h0 ) = 2/3).
By an argument similar to that above, using RCF, Taut, MP, E1, and E2, we can derive
w(ob, h) + w(ob, h0 ) ≤ 1,
and by MP, we obtain the desired conclusion: ¬(w(ob, h) = 2/3 ∧ w(ob, h0 ) = 2/3).
15

Halpern & Pucella

Theorem 4.1: AX(Φh , Φo ) is a sound and complete axiomatization for Lfo -ev (Φh , Φo ) with
respect to evidential worlds.
As usual, soundness is straightforward, and to prove completeness, it suffices to show
that if a formula ϕ is consistent with AX(Φh , Φo ), it is satisfiable in an evidential structure. However, the usual approach for proving completeness in modal logic, which involves
considering maximal consistent sets and canonical structures does not work. The problem
is that there are maximal consistent sets of formulas that are not satisfiable. For example,
there is a maximal consistent set of formulas that includes Pr(ρ) > 0 and Pr(ρ) ≤ 1/n for
n = 1, 2, . . . . This is clearly unsatisfiable. Our proof follows the techniques developed in
FHM.
To express axiom E4, we needed to have quantification in the logic. This is where the
fact that our representation of evidence is normalized has a nontrivial effect on the logic: E4
corresponds to property WF2, which essentially says that a function is a weight of evidence
function if one can find such a normalization factor. An interesting question is whether it
is possible to find a sound and complete axiomatization for the propositional fragment of
our logic (without quantification or variables). To do this, we need to give quantifier-free
axioms to replace axiom E4. This amounts to asking whether there is a simpler property
than WF2 in Theorem 2.4 that characterizes weight of evidence functions. This remains
an open question.

5. Decision Procedures
In this section, we consider the decision problem for our logic, that is, the problem of
deciding whether a given formula ϕ is satisfiable. In order to state the problem precisely,
however, we need to deal carefully with the fact that the logic is parameterized by the sets
Φh and Φo of primitive propositions representing hypotheses and observations. In most
logics, the choice of underlying primitive propositions is essentially irrelevant. For example,
if a propositional formula ϕ that contains only primitive propositions in some set Φ is
true with respect to all truth assignments to Φ, then it remains true with respect to all
truth assignments to any set Φ0 ⊇ Φ. This monotonicity property does not hold here. For
example, as we have already observed, axiom H1 clearly depends on the set of hypotheses
and observations; it is no longer valid if the set is changed. The same is true for O1, E3,
and E4.
This means that we have to be careful, when stating decision problems, about the role
of Φh and Φo in the algorithm. A straightforward way to deal with this is to assume that
the satisfiability algorithm gets as input Φh , Φo , and a formula ϕ ∈ Lfo -ev (Φh , Φo ). Because
Lfo -ev (Φh , Φo ) contains the full theory of real closed fields, it is unsurprisingly difficult to
decide. For our decision procedure, we can use the exponential-space algorithm of Ben-Or,
Kozen, and Reif (1986) to decide the satisfiability of real closed field formulas. We define
the length |ϕ| of ϕ to be the number of symbols required to write ϕ, where we count the
length of each coefficient as 1. Similarly, we define kϕk to be the length of the longest
coefficient appearing in f , when written in binary.
Theorem 5.1: There is a procedure that runs in space exponential in |ϕ| kϕk for deciding,
given Φh and Φo , whether a formula ϕ of Lfo -ev (Φh , Φo ) is satisfiable in an evidential world.
16

A Logic for Reasoning about Evidence

This is essentially the best we can do, since Ben-Or, Kozen, and Reif (1986) prove that
the decision problem for real closed fields is complete for exponential space, and our logic
contains the full language of real closed fields.
While we assumed that the algorithm takes as input the set of primitive propositions
Φh and Φo , this does not really affect the complexity of the algorithm. More precisely, if
we are given a formula ϕ in Lfo -ev over some set of hypotheses and observations, we can
still decide whether ϕ is satisfiable, that is, whether there are sets Φh and Φo of primitive
propositions containing all the primitive propositions in ϕ and an evidential world w that
satisfies ϕ.
Theorem 5.2: There is a procedure that runs in space exponential in |ϕ| kϕk for deciding
whether there exists sets of primitive propositions Φh and Φo such that ϕ ∈ Lfo -ev (Φh , Φo )
and ϕ is satisfiable in an evidential world.
The main culprit for the exponential-space complexity is the theory of real closed fields,
which we had to add to the logic to be able to even write down axiom E4 of the axiomatization AX(Φh , Φo ).5 However, if we are not interested in axiomatizations, but simply in
verifying properties of probabilities and weights of evidence, we can consider the following
propositional (quantifier-free) fragment of our logic. As before, we start with sets Φh and
Φo of hypothesis and observation primitives, and form the sublanguage Lh of hypothesis
formulas. Basic terms have the form Pr0 (ρ), Pr(ρ), and w(ob, h), where ρ is an hypothesis
formula, ob is an observation, and h is an hypothesis. A quantifier-free polynomial term
has the form a1 t1 + · · · + an tn , where each ai is an integer and each ti is a product of
basic terms. A quantifier-free polynomial inequality formula has the form p ≥ c, where
p is a quantifier-free polynomial term, and c is an integer. For instance, a quantifier-free
polynomial inequality formula takes the form Pr0 (ρ) + 3w(ob, h) + 5Pr0 (ρ)Pr(ρ0 ) ≥ 7.
Let Lev (Φh , Φo ) be the language obtained by starting out with the primitive propositions
in Φh and Φo and quantifier-free polynomial inequality formulas, and closing off under conjunction and negation. Since quantifier-free polynomial inequality formulas are polynomial
inequality formulas, Lev (Φh , Φo ) is a sublanguage of Lfo -ev (Φh , Φo ). The logic Lev (Φh , Φo )
is sufficiently expressive to express many properties of interest; for instance, it can certainly
express the general connection between priors, posteriors, and evidence captured by axiom
E3, as well as specific relationships between prior probability and posterior probability
through the weight of evidence of a particular observation, as in Example 3.1. Reasoning
about the propositional fragment of our logic Lev (Φh , Φo ) is easier than the full language.6
5. Recall that axiom E4 requires existential quantification. Thus, we can restrict to the sublanguage
consisting of formulas with a single block of existential quantifiers in prefix position. The satisfiability
problem for this sublanguage can be shown to be decidable in time exponential in the size of the formula
(Renegar, 1992).
6. In a preliminary version of this paper (Halpern & Pucella, 2003), we examined the quantifier-free fragment
of Lfo -ev (Φh , Φo ) that uses only linear inequality formulas, of the form a1 t1 + · · · + an tn ≥ c, where each
ti is a basic term. We claimed that the problem of deciding, given Φh and Φo , whether a formula ϕ of
this fragment is satisfiable in an evidential world is NP-complete. We further claimed that this result
followed from a small-model theorem: if ϕ is satisfiable, then it is satisfiable in an evidential world over
a small number of hypotheses and observations. While this small-model theorem is true, our argument
that the satisfiability problem is in NP also implicitly assumed that the numbers associated with the
probability measure and the evidence space in the evidential world were small. But this is not true

17

Halpern & Pucella

Theorem 5.3: There is a procedure that runs in space polynomial in |ϕ| kϕk for deciding,
given Φh and Φo , whether a formula ϕ of Lev (Φh , Φo ) is satisfiable in an evidential world.
Theorem 5.3 relies on Canny’s (1988) procedure for deciding the validity of quantifierfree formulas in the theory of real closed fields. As in the general case, the complexity is
unaffected by whether or not the decision problem takes as input the sets Φh and Φo of
primitive propositions.
Theorem 5.4: There is a procedure that runs in space polynomial in |ϕ| kϕk for deciding
whether there exists sets of primitive propositions Φh and Φo such that ϕ ∈ Lev (Φh , Φo ) and
ϕ is satisfiable in an evidential world.

6. Normalized Versus Unnormalized Likelihoods
The weight of evidence we used throughout this paper is a generalization of the log-likelihood
ratio advocated by Good (1950, 1960). As we pointed out earlier, this measure of confirmation is essentially a normalized likelihood: the likelihood of an observation given a particular
hypothesis is normalized by the sum of all the likelihoods of that observation, for all possible hypotheses. What would change if we were to take the (unnormalized) likelihoods µh
themselves as weight of evidence? Some things would simplify. For example, WF2 is a
consequence of normalization, as is the corresponding axiom E4, which is the only axiom
that requires quantification.
The main argument for normalizing likelihood is the same as that for normalizing probability measures. Just like probability, when using normalized likelihood, the weight of
evidence is always between 0 and 1, and provides an absolute scale against which to judge
all reports of evidence. The impact here is psychological—it permits one to use the same
rules of thumb in all situations, since the numbers obtained are independent from the context of their use. Thus, for instance, a weight of evidence of 0.95 in one situation corresponds
to the “same amount” of evidence as a weight of evidence of 0.95 in a different situation;
any acceptable decision based on this weight of evidence in the first situation ought to be
acceptable in the other situation as well. The importance of having such a uniform scale
depends, of course, on the intended applications.
For the sake of completeness, we now describe the changes to our framework required
to use unnormalized likelihoods as a weight of evidence. Define wEu (ob, h) = µh (ob).
in general. Even though the formula ϕ involves only linear inequality formulas, every evidential world
satisfies axiom E3. This constraint enables us to write formulas for which there exist no models where
the probabilities and weights of evidence are rational. For example, consider the formula
Pr0 (h1 ) = w(ob 1 , h1 ) ∧ Pr0 (h2 ) = 1 − Pr0 (h1 ) ∧ Pr(h1 ) = 1/2 ∧ w(ob 1 , h2 ) = 1/4
Any evidential world satisfying the formula must satisfy
Pr0 (h1 ) = w(ob 1 , h1 ) = −1/8(1 −

√
17)

which is irrational. The exact complexity of this fragment remains open. We can use our techniques to
show that it is in PSPACE, but we have no matching lower bound. (In particular, it may indeed be in
NP.) We re-examine this fragment of the logic in Section 6, under a different interpretation of weights
of evidence.

18

A Logic for Reasoning about Evidence

First, note that we can update a prior probability µ0 via a set of likelihood functions µh
using a form of Dempster’s Rule of Combination. More precisely, we can define µ0 ⊕wEu (ob, ·)
to be the probability measure defined by
µ0 (h)µh (ob)
.
0
h0 ∈H µ0 (h )µh0 (ob)

(µ0 ⊕ wEu (ob, ·))(h) = P

The logic we introduced in Section 3 applies just as well to this new interpretation of
weights of evidence. The syntax remains unchanged, the models remain evidential worlds,
and the semantics of formulas simply take the new interpretation of weight of evidence
into account. In particular, the assignment [p]w,v now uses the above definition of wEu , and
becomes
[Pr(ρ)]w,v = (µ ⊕ wEu (ob, ·))([[ρ]])
[w(ob 0 , h0 )]w,v = wEu (ob 0 , h0 ).
The axiomatization of this new logic is slightly different and somewhat simpler than the
one in Section 3. In particular, E1 and E2, which say that w(ob, h) acts as a probability
measure for each fixed ob, are replaced by axioms that say that w(ob, h) acts as a probability
measure for each fixed h:
E10 . w(ob, h) ≥ 0.
E20 . w(ob 1 , h) + · · · + w(ob no , h) = 1.
Axiom E3 is unchanged, since wEu is updated in essentially the same way as wE . Axiom E4
becomes unnecessary.
What about the complexity of the decision procedure? As in Section 5, the complexity
of the decision problem for the full logic Lfo -ev (Φh , Φo ) remains dominated by the complexity of reasoning in real closed fields. Of course, now, we can express the full axiomatization
for the unnormalized likelihood interpretation of weight of evidence in the Lev (Φh , Φo ) fragment, which can be decided in polynomial space. A further advantage of the unnormalized
likelihood interpretation of weight of evidence, however, is that it leads to a useful fragment
of Lev (Φh , Φo ) that is perhaps easier to decide.
Suppose that we are interested in reasoning exclusively about weights of evidence, with
no prior or posterior probability. This is the kind of reasoning that actually underlies
many computer science applications involving randomized algorithms (Halpern & Pucella,
2005b). As before, we start with sets Φh and Φo of hypothesis and observation primitives,
and form the sublanguage Lh of hypothesis formulas. A quantifier-free linear term has
the form a1 w(ob 1 , h1 ) + · · · + an w(ob n , hn ), where each ai is an integer, each ob i is an
observation, and each hi is an hypothesis. A quantifier-free linear inequality formula has
the form p ≥ c, where p is a quantifier-free linear term and c is an integer. For example,
w(ob 0 , h) + 3w(ob, h) ≥ 7 is a quantifier-free linear inequality formula.
Let Lw (Φh , Φo ) be the language obtained by starting out with the primitive propositions
in Φh and Φo and quantifier-free linear inequality formulas, and closing off under conjunction
and negation. Since quantifier-free linear inequality formulas are polynomial inequality
formulas, Lw (Φh , Φo ) is a sublanguage of Lfo -ev (Φh , Φo ). Reasoning about Lw (Φh , Φo ) is
easier than the full language, and possibly easier than the Lev (Φh , Φo ) fragment.
19

Halpern & Pucella

Theorem 6.1: The problem of deciding, given Φh and Φo , whether a formula ϕ of Lw (Φh , Φo )
is satisfiable in an evidential world is NP-complete.
As in the general case, the complexity is unaffected by whether or not the decision
problem takes as input the sets Φh and Φo of primitive propositions.
Theorem 6.2: The problem of deciding, for a formula ϕ, whether there exists sets of
primitive propositions Φh and Φo such that ϕ ∈ Lw (Φh , Φo ) and ϕ is satisfiable in an
evidential world is NP-complete.

7. Evidence in Dynamic Systems
The evidential worlds we have considered until now are essentially static, in that they model
only the situation where a single observation is made. Considering such static worlds lets
us focus on the relationship between the prior and posterior probabilities on hypotheses
and the weight of evidence of a single observation. In a related paper (Halpern & Pucella,
2005b), we consider evidence in the context of randomized algorithms; we use evidence to
characterize the information provided by, for example, a randomized algorithm for primality
when it says that a number is prime. The framework in that work is dynamic; sequences of
observations are made over time. In this section, we extend our logic to reason about the
evidence of sequences of observations, using the approach to combining evidence described
in Section 2.
There are subtleties involved in trying to find an appropriate logic for reasoning about
situations like that in Example 2.5. The most important one is the relationship between
observations and time. By way of illustration, consider the following example. Bob is
expecting an email from Alice stating where a rendezvous is to take place. Calm under
pressure, Bob is reading while he waits. We assume that Bob is not concerned with the
time. For the purposes of this example, one of three things can occur at any given point in
time:
(1) Bob does not check if he has received email;
(2) Bob checks if he has received email, and notices he has not received an email from
Alice;
(3) Bob checks if he has received email, and notices he has received an email from Alice.
How is his view of the world affected by these events? In (1), it should be clear that,
all things being equal, Bob’s view of the world does not change: no observation is made.
Contrast this with (2) and (3). In (2), Bob does make an observation, namely that he has
not yet received Alice’s email. The fact that he checks indicates that he wants to observe a
result. In (3), he also makes an observation, namely that he received an email from Alice.
In both of these cases, the check yields an observation, that he can use to update his view
of the world. In case (2), he essentially observed that nothing happened, but we emphasize
again that this is an observation, to be distinguished from the case where Bob does not
even check whether email has arrived, and should be explicit in the set O in the evidence
space.

20

A Logic for Reasoning about Evidence

This discussion motivates the models that we use in this section. We characterize
an agent’s state by the observations that she has made, including possibly the “nothing
happened” observation. Although we do not explicitly model time, it is easy to incorporate
time in our framework, since the agent can observe times or clock ticks. The models in this
section are admittedly simple, but they already highlight the issues involved in reasoning
about evidence in dynamic systems. As long as agents do not forget observations, there is
no loss of generality in associating an agent’s state with a sequence of observations. We do,
however, make the simplifying assumption that the same evidence space is used for all the
observations in a sequence. In other words, we assume that the evidence space is fixed for
the evolution of the system. In many situations of interest, the external world changes. The
possible observations may depend on the state of the world, as may the likelihood functions.
There are no intrinsic difficulties in extending the model to handle state changes, but the
additional details would only obscure the presentation.
In some ways, considering a dynamic setting simplifies things. Rather than talking
about the prior and posterior probability using different operators, we need only a single
probability operator that represents the probability of an hypothesis at the current time.
To express the analogue of axiom E3 in this logic, we need to be able to talk about the
probability at the next time step. This can be done by adding the “next-time” operator
 to the logic, where ϕ holds at the current time if ϕ holds at the next time step.7 We
further extend the logic to talk about the weight of evidence of a sequence of observations.
-ev
We define the logic Lfo
dyn as follows. As in Section 3, we start with a set of primitive
propositions Φh and Φo , respectively representing the hypotheses and the observations.
Again, let Lh (Φh ) be the propositional sublanguage of hypotheses formulas obtained by
taking primitive propositions in Φh and closing off under negation and conjunction; we use
ρ to range over formulas of that sublanguage.
A basic term now has the form Pr(ρ) or w(ob, h), where ρ is an hypothesis formula,
ob = hob 1 , . . . , ob k i is a nonempty sequence of observations, and h is an hypothesis. If
ob = hob 1 i, we write w(ob 1 , h) rather than w(hob 1 i, h). As before, a polynomial term has
the form t1 + · · · + tn , where each term ti is a product of integers, basic terms, and variables
(which intuitively range over the reals). A polynomial inequality formula has the form
-ev
p ≥ c, where p is a polynomial term and c is an integer. Let Lfo
dyn (Φh , Φo ) be the language
obtained by starting out with the primitive propositions in Φh and Φo and polynomial
inequality formulas, and closing off under conjunction, negation, first-order quantification,
and application of the  operator. We use the same abbreviations as in Section 3.
The semantics of this logic now involves models that have dynamic behavior. Rather
than just considering individual worlds, we now consider sequences of worlds, which we
call runs, representing the evolution of the system over time. A model is now an infinite
run, where a run describes a possible dynamic evolution of the system. As before, a run
records the observations being made and the hypothesis that is true for the run, as well as
a probability distribution describing the prior probability of the hypothesis at the initial
state of the run, and an evidence space E ∗ over Φh and Φ∗o to interpret w. We define an
evidential run r to be a map from the natural numbers (representing time) to histories of
7. Following the discussion above, time steps are associated with new observations. Thus, ϕ means that
ϕ is true at the next time step, that is, after the next observation. This simplifies the presentation of
the logic.

21

Halpern & Pucella

the system up to that time. A history at time m records the relevant information about the
run—the hypothesis that is true, the prior probability on the hypotheses, and the evidence
space E ∗ —and the observations that have been made up to time m. Hence, a history has
the form h(h, µ, E ∗ ), ob 1 , . . . , ob k i. We assume that r(0) = h(h, µ, E ∗ )i for some h, µ, and
E ∗ , while r(m) = h(h, µ, E ∗ ), ob 1 , . . . , ob m i for m > 0. We define a point of the run to be a
pair (r, m) consisting of a run r and time m.
We associate with each propositional formula ρ in Lh (Φh ) a set [[ρ]] of hypotheses, just
as we did in Section 3.
In order to ascribe a semantics to first-order formulas that may contain variables, we
need a valuation v that assigns a real number to every variable. Given a valuation v, an
evidential run r, and a point (r, m), where r(m) = h(h, µ, E ∗ ), ob 1 , . . . , ob m i, we can assign
to a polynomial term p a real number [p]r,m,v using essentially the same approach as in
Section 3:
[x]r,m,v = v(x)
[a]r,m,v = a
[Pr(ρ)]r,m,v = (µ ⊕ wE ∗ (hob 1 , . . . , ob m i, ·)))([[ρ]])
where r(m) = h(h, µ, E ∗ ), ob 1 , . . . , ob m i
[w(ob, h0 )]r,m,v = wE ∗ (ob, h0 )
where r(m) = h(h, µ, E ∗ ), ob 1 , . . . , ob m i
[t1 t2 ]r,m,v = [t1 ]r,m,v × [t2 ]r,m,v
[p1 + p2 ]r,m,,v = [p1 ]r,m,v + [p2 ]r,m,v .
We define what it means for a formula ϕ to be true (or satisfied) at a point (r, m) of
an evidential run r under valuation v, written (r, m, v) |= ϕ, using essentially the same
approach as in Section 3:
(r, m, v) |= h if r(m) = h(h, µ, E ∗ ), . . .i
(r, m, v) |= ob if r(m) = h(h, µ, E ∗ ), . . . , obi
(r, m, v) |= ¬ϕ if (r, m, v) 6|= ϕ
(r, m, v) |= ϕ ∧ ψ if (r, m, v) |= ϕ and (r, m, v) |= ψ
(r, m, v) |= p ≥ c if [p]r,m,v ≥ c
(r, m, v) |= ϕ if (r, m + 1, v) |= ϕ
(r, m, v) |= ∀xϕ if (r, m, v 0 ) |= ϕ for all valuations v 0 that agree with v on all variables
but x.
If (r, m, v) |= ϕ is true for all v, we simply write (r, m) |= ϕ. If (r, m) |= ϕ for all points
(r, m) of r, then we write r |= ϕ and say that ϕ is valid in r. Finally, if r |= ϕ for all
evidential runs r, we write |= ϕ and say that ϕ is valid.
It is straightforward to axiomatize this new logic. The axiomatization shows that we
can capture the combination of evidence directly in the logic, a pleasant property. Most of
22

A Logic for Reasoning about Evidence

the axioms from Section 3 carry over immediately. Let the axiomatization AXdyn (Φh , Φo )
consists of the following axioms and inference rules: first-order reasoning (Taut, MP), reasoning about polynomial inequalities (RCF), reasoning about hypotheses and observations
(H1,H2,O1,O2), reasoning about probabilities (Po1–4 only, since we do not have Pr0 in
the language), and reasoning about weights of evidence (E1, E2, E4), as well as new axioms
we now present.
Basically, the only axiom that needs replacing is E3, which links prior and posterior
probabilities, since this now needs to be expressed using the  operator. Moreover, we
need an axiom to relate the weight of evidence of a sequence of observation to the weight
of evidence of the individual observations, as given by Equation (3).
E5. ob ⇒ ∀x((Pr(h) = x) ⇒
Pr(h)w(ob, h) = xPr(h1 )w(ob, h1 ) + · · · + xPr(hnh )w(ob, hnh )).
E6. w(ob 1 , h) · · · w(ob k , h) = w(hob 1 , . . . , ob k i, h)w(ob 1 , h1 ) · · · w(ob k , h1 ) + · · · +
w(hob 1 , . . . , ob k i, h)w(ob 1 , hnh ) · · · w(ob k , hnh ).
To get a complete axiomatization, we also need axioms and inference rules that capture
the properties of the temporal operator .
T1. ϕ ∧ (ϕ ⇒ ψ) ⇒ ψ.
T2. ¬ϕ ⇔ ¬ϕ.
T3. From ϕ infer ϕ.
Finally, we need axioms to say that the truth of hypotheses as well as the value of polynomial
terms not containing occurrences of Pr is time-independent:
T4. ρ ⇔ ρ.
T5. (p ≥ c) ⇔ p ≥ c if p does not contain an occurrence of Pr.
T6. (∀xϕ) ⇔ ∀x(ϕ).
-ev
Theorem 7.1: AXdyn (Φh , Φo ) is a sound and complete axiomatization for Lfo
dyn (Φh , Φo )
with respect to evidential runs.

8. Conclusion
In the literature, reasoning about the effect of observations is typically done in a context
where we have a prior probability on a set of hypotheses which we can condition on the
observations made to obtain a new probability on the hypotheses that reflects the effect of
the observations. In this paper, we have presented a logic of evidence that lets us reason
about the weight of evidence of observations, independently of any prior probability on the
hypotheses. The logic is expressive enough to capture in a logical form the relationship
between a prior probability on hypotheses, the weight of evidence of observations, and the
result posterior probability on hypotheses. But we can also capture reasoning that does not
involve prior probabilities.
23

Halpern & Pucella

While the logic is essentially propositional, obtaining a sound and complete axiomatization seems to require quantification over the reals. This adds to the complexity of the
logic—the decision problem for the full logic is in exponential space. However, an interesting and potentially useful fragment, the propositional fragment, is decidable in polynomial
space.
Acknowledgments. A preliminary version of this paper appeared in the Proceedings of
the Nineteenth Conference on Uncertainty in Artificial Intelligence, pp. 297–304, 2003. This
work was mainly done while the second author was at Cornell University. We thank Dexter
Kozen and Nimrod Megiddo for useful discussions. Special thanks to Manfred Jaeger for
his careful reading of the paper and subsequent comments. Manfred found the bug in our
proof that the satisfiability problem for the quantifier-free fragment of Lfo -ev (Φh , Φo ) that
uses only linear inequality formulas is NP-complete. His comments also led us to discuss the
issue of normalization. We also thank the reviewers, whose comments greatly improved the
paper. This work was supported in part by NSF under grants CTC-0208535, ITR-0325453,
and IIS-0534064, by ONR under grant N00014-01-10-511, by the DoD Multidisciplinary
University Research Initiative (MURI) program administered by the ONR under grants
N00014-01-1-0795 and N00014-04-1-0725, and by AFOSR under grant F49620-02-1-0101.

Appendix A. Proofs
Proposition 2.1: For all ob, we have wE (ob, hi ) ≥ wE (ob, h3−i ) if and only if l(ob, hi ) ≥
l(ob, h3−i ), for i = 1, 2, and for all h, ob, and ob 0 , we have wE (ob, h) ≥ wE (ob 0 , h) if and
only if l(ob, h) ≥ l(ob 0 , h).
Proof. Let ob be an arbitrary observation. The result follows from the following argument:
wE (ob, hi ) ≥ wE (ob, h3−i )
iff µhi (ob)/(µhi (ob) + µh3−i (ob)) ≥ µh3−i (ob)/(µhi (ob) + µh3−i (ob))
iff µhi (ob)µhi (ob) ≥ µh3−i (ob)µh3−i (ob)
iff µhi (ob)/µh3−i (ob) ≥ µh3−i (ob)/µhi (ob)
iff l(ob, hi ) ≥ l(ob, h3−i ).
A similar argument establishes the result for hypotheses.

t
u

Theorem 2.4: Let H = {h1 , . . . , hm } and O = {ob 1 , . . . , ob n }, and let f be a real-valued
function with domain O × H such that f (ob, h) ∈ [0, 1]. Then there exists an evidence space
E = (H, O, µh1 , . . . , µhm ) such that f = wE if and only if f satisfies the following properties:
WF1. For every ob ∈ O, f (ob, ·) is a probability measure on H.
P
WF2. There exists x1 , . . . , xn > 0 such that, for all h ∈ H, ni=1 f (ob i , h)xi = 1.
Proof. (⇒) Assume that f = wE for some evidence space E = (H, O, µh1 , . . . , µhm ). It is
routine to verify WF1, that for a fixed ob ∈ O, wEP
(ob, ·) is a probability measure on H.
To verify WF2, note that we can simply take xi = h0 ∈H µh0 (ob i ).
(⇐) Let f be a function from O × H to [0, 1] that satisfies WF1 and WF2. Let
x∗1 , . . . , x∗nh be the positive reals guaranteed by WF2. It is straightforward to verify that
24

A Logic for Reasoning about Evidence

taking µh (ob i ) = f (ob i , h)/x∗i for each h ∈ H yields an evidence space E such that f =
wE .
u
t
The following lemmas are useful to prove the completeness of the axiomatizations in
this paper. These results depend on the soundness of the axiomatization AX(Φh , Φo ).
Lemma A.1: AX(Φh , Φo ) is a sound axiomatization for the logic Lfo -ev (Φh , Φo ) with respect to evidential worlds.
Proof. It is easy to see that each axiom is valid in evidential worlds.

t
u

Lemma A.2: For all hypothesis formulas ρ, ρ ⇔ h1 ∨ · · · ∨ hk is provable in AX(Φh , Φo ),
when [[ρ]] = {h1 , . . . , hk }.
Proof. Using Taut, we can show that ρ is provably equivalent to a formula ρ0 in disjunctive
normal form. Moreover, by axiom H2, we can assume without loss of generality that each
of the disjuncts in ρ0 consists of a single hypothesis. Thus, ρ is h1 ∨ · · · ∨ hk . An easy
induction on structure shows that for an hypothesis formula ρ and evidential world w, we
have that w |= ρ iff w |= h for some h ∈ [[ρ]]. Moreover, it follows immediately from the
soundness of the axiomatization (Lemma A.1) that ρ ⇔ h1 ∨ . . . ∨ hk is provable iff for all
evidential worlds w, w |= ρ iff w |= hi for some i ∈ {1, . . . , k}. Thus, ρ ⇔ h1 ∨ . . . ∨ hk is
provable iff [[ρ]] = {h1 , . . . , hk }.
t
u
An easy consequence of Lemma A.2 is that ρ1 is provably equivalent to ρ2 if and only if
[[ρ1 ]] = [[ρ2 ]].
Lemma A.3: Let ρ be an hypothesis formula. The formulas
P
Pr(h) and
Pr(ρ) =
h∈[[ρ]]

Pr0 (ρ) =

P

Pr0 (h)

h∈[[ρ]]

are provable in AX(Φh , Φo ).
Proof. Let Φh = {h1 , . . . , hnh } and Φo = {ob 1 , . . . , ob no }. We prove the result for Pr.
We proceed by induction on the size of [[ρ]]. For the base case, assume that |[[ρ]]| = 0.
By Lemma A.2, this implies that ρ is provably equivalent to false. By Po4, Pr(ρ) =
Pr(false), and it is easy to check that Pr(false) = 0 is provable using Po1, Po3, and Po4,
thus Pr(ρ) = 0, as required. If |[[ρ]]| = n + 1 > 0, then [[ρ]] = {hi1 , . . . , hin+1 }, and by
Lemma A.2, ρ is provably equivalent to hi1 ∨ · · · ∨ hin+1 . By Po4, Pr(ρ) = Pr(ρ ∧ hin+1 ) +
Pr(ρ ∧ ¬hin+1 ). It is easy to check that ρ ∧ hin+1 is provably equivalent to hin+1 (using
H2), and similarly ρ ∧ ¬hin+1 is provably equivalent to hi1 ∨ · · · ∨ hin . Thus, Pr(ρ) =
∨ · · · ∨ hin ]]| = n, by the induction
is provable. Since |[[hi1P
Pr(hin+1 ) + Pr(hi1 ∨ · · · ∨ hin ) P
hypothesis, Pr(hi1 ∨· · ·∨hin ) = h∈{hi ,...,hin } Pr(h) = h∈[[ρ]]−{hi } Pr(h). Thus, Pr(ρ) =
1
n+1
P
P
Pr(hin+1 ) + h∈[[ρ]]−{hi } Pr(h), that is, Pr(ρ) = h∈[[ρ]] Pr(h), as required.
n+1

The same argument applies mutatis mutandis for Pr0 , using axioms Pr1–4 instead of
Po1–4.
u
t
25

Halpern & Pucella

Theorem 4.1: AX(Φh , Φo ) is a sound and complete axiomatization for the logic with respect to evidential worlds.
Proof. Soundness was established in Lemma A.1. To prove completeness, recall the following definitions. A formula ϕ is consistent with the axiom system AX(Φh , Φo ) if ¬ϕ is
not provable from AX(Φh , Φo ). To prove completeness, it is sufficient to show that if ϕ is
consistent, then it is satisfiable, that is, there exists an evidential world w and valuation v
such that (w, v) |= ϕ.
As in the body of the paper, let Φh = {h1 , . . . , hnh } and Φo = {ob 1 , . . . , ob no }. Let ϕ be
a consistent formula. By way of contradiction, assume that ϕ is unsatisfiable. We reduce
the formula ϕ to an equivalent formula in the language of real closed fields. Let u1 , . . . , unh ,
v1 , . . . , vno , x1 , . . . , xnh , y1 , . . . , yno , and z11 , . . . , zn1 h , . . . , z1no , . . . , znnho be new variables, where,
intuitively,
• ui gets value 1 if hypothesis hi holds, 0 otherwise;
• vi gets value 1 if observation ob i holds, 0 otherwise;
• xi represents Pr0 (hi );
• yi represents Pr(hi );
• zi,j represents w(ob i , hj ).
Let v represent that list of new variables. Consider the following formulas. Let ϕh be the
formula saying that exactly one hypothesis holds:
(u1 = 0 ∨ u1 = 1) ∧ · · · ∧ (unh = 0 ∨ unh = 1) ∧ u1 + · · · + unh = 1.
Similarly, let ϕo be the formula saying that exactly one observation holds:
(v1 = 0 ∨ v1 = 1) ∧ · · · ∧ (vno = 0 ∨ vnh = 1) ∧ v1 + · · · + vnh = 1.
Let ϕpr be the formula that expresses that Pr0 is a probability measure:
ϕpr = x1 ≥ 0 ∧ · · · ∧ xnh ≥ 0 ∧ x1 + · · · + xnh = 1.
Similarly, let ϕpo be the formula that expresses that Pr is a probability measure:
ϕpo = y1 ≥ 0 ∧ · · · ∧ ynh ≥ 0 ∧ y1 + · · · + ynh = 1.
Finally, we need formulas saying that w is a weight of evidence function. The formula
ϕw ,p simply says that w satisfies WF1, that is, it acts as a probability measure for a fixed
observation:
z1,1 ≥ 0 ∧ · · · ∧ z1,nh ≥ 0 ∧ zno ,1 ≥ 0 ∧ · · · ∧ zno ,nh ≥ 0∧
z1,1 + · · · + z1,nh = 1 ∧ · · · ∧ zno ,1 + · · · + zno ,nh = 1.
The formula ϕw ,f says that w satisfies WF2:
∃w1 , . . . , wno (w1 > 0 ∧ · · · ∧ wno > 0 ∧ z1,1 w1 + · · · + zno ,1 wno = 1∧
· · · ∧ z1,nh w1 + · · · + zno ,nh wno = 1)
26

A Logic for Reasoning about Evidence

where w1 , . . . , wno are new variables.
Finally, the formula ϕw ,up captures the fact that weights of evidence can be viewed as updating a prior probability into a posterior probability, via Dempster’s Rule of Combination:
(v1 = 1 ⇒ (x1 z1,1 = y1 x1 z1,1 + · · · + y1 xnh z1,nh ∧
· · · ∧ xnh z1,nh = ynh x1 z1,1 + · · · + ynh xnh z1,nh ))∧
···∧
(vno = 1 ⇒ (x1 zno ,1 = y1 x1 zno ,1 + · · · + y1 xnh zno ,nh ∧
· · · ∧ xnh zno ,nh = ynh x1 zno ,1 + . . . ynh xnh zno ,nh )).
Let ϕ̂ be the formula in the language of real closed fields obtained from ϕ by replacing
each occurrence of the primitive proposition
hi by ui = 1, each occurrencePof ob i by vi =
P
1, each occurrence of Pr0 (ρ) by hi ∈[[ρ]] xi , each occurrence of Pr(ρ) by hi ∈[[ρ]] yi , each
occurrence of w(ob i , hj ) by zi,j , and each occurrence of an integer coefficient k by 1 + · · · + 1
(k times). Finally, let ϕ0 be the formula ∃v(ϕh ∧ ϕo ∧ ϕpr ∧ ϕpo ∧ ϕw ,p ∧ ϕw ,f ∧ ϕw ,up ∧ ϕ̂).
It is easy to see that if ϕ is unsatisfiable over evidential worlds, then ϕ0 is false when
interpreted over the real numbers. Therefore, ¬ϕ0 must be a formula valid in real closed
fields, and hence an instance of RCF. Thus, ¬ϕ0 is provable. It is straightforward to show,
using Lemma A.3, that ¬ϕ itself is provable, contradicting the fact that ϕ is consistent.
Thus, ϕ must be satisfiable, establishing completeness.
t
u
As we mentioned at the beginning of Section 5, Lfo -ev is not monotone with respect to
validity: axiom H1 depends on the set of hypotheses and observations, and will in general
no longer be valid if the set is changed. The same is true for O1, E3, and E4. We do,
however, have a form of monotonicity with respect to satisfiability, as the following lemma
shows.
Lemma A.4: Given Φh and Φo , let ϕ be a formula of Lfo -ev (Φh , Φo ), and let H ⊆ Φh
and O ⊆ Φo be the hypotheses and observations that occur in ϕ. If ϕ is satisfiable in an
evidential world over Φh and Φo , then ϕ is satisfiable in an evidential world over Φ0h and
Φ0o , where |Φ0h | = |H| + 1 and |Φ0o | = |O| + 1.
Proof. We do this in two steps, to clarify the presentation. First, we show that we can
add a single hypothesis and observation to Φh and Φo and preserve satisfiability of ϕ. This
means that the second step below can assume that Φh 6= H and Φo 6= O. Assume that
ϕ is satisfied in an evidential world w = (h, ob, µ, E) over Φh and Φo , so that there exists
v such that (w, v) |= ϕ. Let Φ0h = Φh ∪ {h∗ }, where h∗ is a new hypothesis not in Φh ,
and let Φ0o = Φo ∪ {ob ∗ }, where ob ∗ is a new observation not in Φo . Define the evidential
world w0 = (h, ob, µ0 , E 0 ) over Φ0h and Φ0o , where E 0 and µ0 are defined as follows. Define the
probability measure µ0 by taking:
(
µ(h) if h ∈ Φh
0
µ (h) =
0
if h = h∗ .

27

Halpern & Pucella

Similarly, define the evidence space E 0 = (Φ0h , Φ0o , µ0 ) derived from E = (Φh , Φo , µ) by taking:


µh (ob) if h ∈ Φh and ob ∈ Φo



0
if h ∈ Φh and ob = ob ∗
µ0h (ob) =

0
if h = h∗ and ob ∈ Φo



1
if h = h∗ and ob ∈ ob ∗ .
Thus, µ0h extends the existing µh by assigning a probability of 0 to the new observation ob ∗ ;
in contrast, the new probability µ0h∗ assigns probability 1 to the new observation ob ∗ . We
can check that (w0 , v) |= ϕ.
The second step is to “collapse” all the hypotheses and observations that do not appear
in ϕ into one of the hypotheses that do not appear in H and O, which by the previous step
are guaranteed to exist. By the previous step, we can assume that Φh 6= H and Φo 6= O.
Assume ϕ is satisfiable in an evidential world w = (h, ob, µ, E) over Φh and Φo , that is,
there exists v such that (w, v) |= ϕ. Pick an hypothesis and an observation from Φh and Φo
as follows, depending on the hypothesis h and observation ob in w. Let h† be h if h 6∈ H,
otherwise, let h† be an arbitrary element of Φh − H; let Φ0h = H ∪ {h† }. Similarly, let ob †
be ob if ob 6∈ O, otherwise, let ob † be an arbitrary element of Φo − O; let Φ0o = O ∪ {ob † }.
Let w0 = (h, ob, µ0 , E 0 ) be an evidential world over Φ0h and Φ0o obtained from w as follows.
Define the probability measure µ0 by taking:
(
µ(h)
if h ∈ H
µ0 (h) = P
0
†
h0 ∈Φh −H µ(h ) if h = h .
Define E 0 = (Φ0h , Φ0o , µ0 ) derived from E = (Φh , Φo , µ) by taking:


if h ∈ H and ob ∈ O

h (ob)
µ

P 0
0
µh (ob )
if h ∈ H and ob = ob †
µ0h (ob) = Pob ∈Φo −O

if h = h† and ob ∈ O

h0 ∈Φh −H µh0 (ob)

P

P
0
†
†
h0 ∈Φh −H
ob 0 ∈Φo −O µh0 (ob ) if h = h and ob = ob .
We can check by induction that (w0 , v) |= ϕ.

t
u

Theorem 5.1: There is a procedure that runs in space exponential in |ϕ| kϕk for deciding,
given Φh and Φo , whether a formula ϕ of Lfo -ev (Φh , Φo ) is satisfiable in an evidential world.
Proof. Let ϕ be a formula of Lfo -ev (Φh , Φo ). By Lemma A.4, ϕ is satisfiable if we can
construct a probability measure µ on Φ0h = H ∪ {h∗ } (where H is the set of hypotheses
appearing in ϕ, and h∗ 6∈ H) and probability measures µh1 , . . . , µhm on Φ0o = O ∪ {ob ∗ }
(where O is the set of observations appearing in ϕ and ob ∗ 6∈ O) such that E = (Φ0h , Φ0o , µ),
w = (h, ob, µ, E) with (w, v) |= ϕ for some h, ob, and v.
The aim now is to derive a formula ϕ0 in the language of real closed fields that asserts
the existence of these probability measures. More precisely, we can adapt the construction
of the formula ϕ0 from ϕ in the proof of Theorem 4.1. The one change we need to make
is ensure that ϕ0 is polynomial in the size of ϕ, which the construction in the proof of
28

A Logic for Reasoning about Evidence

Theorem 4.1 does not guarantee. The culprit is the fact that we encode integer constants k
as 1+· · ·+1. It is straightforward to modify the construction so that we use a more efficient
representation of integer constants, namely, a binary representation. For example, we can
write 42 as 2(1 + 22 (1 + 22 )), which can be expressed in the language of real closed fields as
(1 + 1)(1 + (1 + 1)(1 + 1)(1 + (1 + 1)(1 + 1))). We can check that if k is a coefficient of length
k (when written in binary), it can be written as a term of length O(k) in the language of
real closed fields. Thus, we modify the construction of ϕ0 in the proof of Theorem 4.1 so
that integer constants k are represented using the above binary encoding. It is easy to see
that |ϕ0 | is polynomial in |ϕ| kϕk (since |Φ0h | and |Φ0o | are both polynomial in |ϕ|). We can
now use the exponential-space algorithm of Ben-Or, Kozen, and Reif (1986) on ϕ0 : if ϕ0 is
satisfiable, then we can construct the required probability measures, and ϕ is satisfiable;
otherwise, no such probability measures exist, and ϕ is unsatisfiable.
t
u
Theorem 5.2: There is a procedure that runs in space exponential in |ϕ| kϕk for deciding
whether there exist sets of primitive propositions Φh and Φo such that ϕ ∈ Lfo -ev (Φh , Φo )
and ϕ is satisfiable in an evidential world.
Proof. Let h1 , . . . , hm be the hypotheses appearing in ϕ, and ob 1 , . . . , ob n be the hypotheses
appearing in ϕ. Let Φh = {h1 , . . . , hm , h∗ } and Φo = {ob 1 , . . . , ob n , ob ∗ }, where h∗ and ob ∗
are an hypothesis and observation not appearing in ϕ. Clearly, |Φh | and |Φo | are polynomial
in |ϕ|. By Lemma A.4, if ϕ is satisfiable in an evidential world, it is satisfiable in an evidential
world over Φh and Φo . By Theorem 5.1, we have an algorithm to determine if ϕ is satisfied
in an evidential world over Φh and Φo that runs in space exponential in |ϕ| kϕk.
t
u
Theorem 5.3: There is a procedure that runs in space polynomial in |ϕ| kϕk for deciding,
given Φh and Φo , whether a formula ϕ of Lev (Φh , Φo ) is satisfiable in an evidential world.
Proof. The proof of this result is very similar to that of Theorem 5.1. Let ϕ be a formula
of Lev (Φh , Φo ). By Lemma A.4, ϕ is satisfiable if there exists a probability measure µ on
Φ0h = H ∪ {h∗ } (where H is the set of hypotheses appearing in ϕ, and h∗ 6∈ H), probability
measures µh1 , . . . , µhm on Φ0o = O ∪ {ob ∗ } (where O is the set of observations appearing in
ϕ and ob ∗ 6∈ O), a hypothesis h, observation o, and valuation v such that (w, v) |= ϕ, where
w = (h, ob, µ, E) and E = (Φ0h , Φ0o , µ).
We derive a formula ϕ0 in the language of real closed fields that asserts the existence
of these probability measures by adapting the construction of the formula ϕ0 from ϕ in
the proof of Theorem 4.1. As in the proof of Theorem 5.1, we need to make sure that ϕ0
is polynomial in the size of ϕ, which the construction in the proof of Theorem 4.1 does
not guarantee. We modify the construction so that we use a more efficient representation
of integer constants, namely, a binary representation. For example, we can write 42 as
2(1 + 22 (1 + 22 )), which can be expressed in the language of real closed fields as (1 + 1)(1 +
(1 + 1)(1 + 1)(1 + (1 + 1)(1 + 1))). We can check that if k is a coefficient of length k
(when written in binary), it can be written as a term of length O(k) in the language of
real closed fields. We modify the construction of ϕ0 in the proof of Theorem 4.1 so that
integer constants k are represented using this binary encoding. It is easy to see that |ϕ0 | is
polynomial in |ϕ| kϕk (since |Φ0h | and |Φ0o | are both polynomial in |ϕ|). The key now is to
notice that the resulting formula ϕ0 can be written as ∃x1 . . . ∃xn (ϕ00 ) for some quantifierfree formula ϕ00 . In this form, we can apply the polynomial space algorithm of Canny (1988)
29

Halpern & Pucella

to ϕ00 : if ϕ00 is satisfiable, then we can construct the required probability measures, and ϕ
is satisfiable; otherwise, no such probability measures exist, and ϕ is unsatisfiable.
u
t
Theorem 5.4: There is a procedure that runs in space polynomial in |ϕ| kϕk for deciding
whether there exists sets of primitive propositions Φh and Φo such that ϕ ∈ Lev (Φh , Φo ) and
ϕ is satisfiable in an evidential world.
Proof. Let h1 , . . . , hm be the hypotheses appearing in ϕ, and ob 1 , . . . , ob n be the hypotheses
appearing in ϕ. Let Φh = {h1 , . . . , hm , h∗ } and Φo = {ob 1 , . . . , ob n , ob ∗ }, where h∗ and ob ∗
are an hypothesis and observation not appearing in ϕ. Clearly, |Φh | and |Φo | are polynomial
in |ϕ|. By Lemma A.4, if ϕ is satisfiable in an evidential world, it is satisfiable in an evidential
world over Φh and Φo . By Theorem 5.3, we have an algorithm to determine if ϕ is satisfied
in an evidential world over Φh and Φo that runs in space polynomial in |ϕ| kϕk.
t
u
The proofs of Theorem 6.1 and 6.2 rely on the following small model result, a variation
on Lemma A.4.
Lemma A.5: Given Φh and Φo , let ϕ be a formula of Lfo -ev (Φh , Φo ), and let H ⊆ Φh
and O ⊆ Φo be the hypotheses and observations that occur in ϕ. If ϕ is satisfiable in an
evidential world over Φh and Φo , then ϕ is satisfiable in an evidential world over Φ0h and
Φ0o where |Φ0h | = |H| + 1 and |Φ0o | = |O| + 1, and where, for each h ∈ Φ0h and ob ∈ Φ0o , the
likelihood µh (ob) is a rational number with size O(|ϕ| kϕk + |ϕ| log(|ϕ|)).
Proof. Let ϕ be a formula satisfiable in an evidential world over Φh and Φo . By Lemma A.4,
ϕ is satisfiable in an evidential world over Φ0h and Φ0o , where |Φ0h | = |H|+1 and |Φ0o | = |O|+1.
To force the likelihoods to be small, we adapt Theorem 2.6 in FHM, which says that
if a formula f in the FHM logic is satisfiable, it is satisfiable in a structure where the
probability assigned to each state of the structure is a rational number with size O(|f | kf k+
|f | log(|f |)). The formulas in Lw (Φ0h , Φ0o ) are just formulas in the FHM logic. The result
adapts immediately, and yields the required bounds for the size of the likelihoods.
t
u
Theorem 6.1: The problem of deciding, given Φh and Φo , whether a formula ϕ of Lw (Φh , Φo )
is satisfiable in an evidential world is NP-complete.
Proof. To establish the lower bound, observe that we can reduce propositional satisfiability
to satisfiability in Lw (Φh , Φo ). More precisely, let f be a propositional formula, where
p1 , . . . , pn are the primitive propositions appearing in f . Let Φo = {ob 1 , . . . , ob n , ob ∗ } be
a set of observations, where observation ob i corresponds to the primitive proposition pi ,
and ob ∗ is another (distinct) observation; let Φh be an arbitrary set of hypotheses, and let
h be an arbitrary hypothesis in Φh . Consider the formula fˆ obtained by replacing every
occurrence of pi in f by w(ob i , h) > 0. It is straightforward to verify that f is satisfiable
if and only if fˆ is satisfiable in Lw (Φh , Φo ). (We need the extra observation ob ∗ to take
care of the case f is satisfiable in a a model where each of p1 , . . . , pn is false. In that case,
w(ob 1 , h) = · · · w(ob n , h) = 0, but we can take w(ob ∗ , h) = 1.) This establishes the lower
bound,
The upper bound is straightforward. By Lemma A.5, an evidential world over Φh and
Φo can be guessed in time polynomial in |Φh | + |Φo | + |ϕ| kϕk, since the prior probability
in the world requires assigning a value to |Φh | hypotheses, and the evidence space requires
30

A Logic for Reasoning about Evidence

|Φh | likelihood functions, each assigning a value to |Φo | observations, of size polynomial in
|ϕ| kϕk. We can verify that a world satisfies ϕ in time polynomial in |ϕ| kϕk + |Φh | + |Φh |.
This establishes that the problem is in NP.
t
u
Theorem 6.2: The problem of deciding, for a formula ϕ, whether there exists sets of
primitive propositions Φh and Φo such that ϕ ∈ Lw (Φh , Φo ) and ϕ is satisfiable in an
evidential world is NP-complete.
Proof. For the lower bound, we reduce from the decision problem of Lw (Φh , Φo ) over fixed
Φh and Φo . Let Φh = {h1 , . . . , hm } and Φo = {ob 1 , . . . , ob n }, and let ϕ be a formula in
Lw (Φh , Φo ). We can check that ϕ is satisfiable in evidential world over Φh and Φo if and
only if ϕ ∧ (h1 ∨ · · · ∨ hm ) ∧ (ob 1 ∨ · · · ∨ ob n ) is satisfiable in an evidential world over arbitrary
Φ0h and Φ0o . Thus, by Theorem 6.1, we get our lower bound.
For the upper bound, by Lemma A.5, if ϕ is satisfiable, it is satisfiable in an evidential
world over Φh and Φo , where Φh = H ∪ {h∗ }, H consists of the hypotheses appearing in ϕ,
Φo = O ∪ {ob ∗ }, O consists of the observations appearing in ϕ, and h∗ and ob ∗ are new
hypotheses and observations. Thus, |Φh | ≤ |ϕ| + 1, and |Φo | ≤ |ϕ| + 1. As in the proof of
Theorem 6.1, such a world can be guessed in time polynomial in |ϕ| kϕk + |Φh | + |Φo |, and
therefore in time polynomial in |ϕ| kϕk. We can verify that this world satisfies ϕ in time
polynomial in |ϕ| kϕk, establishing that the problem is in NP.
t
u
-ev
Theorem 7.1: AXdyn (Φh , Φo ) is a sound and complete axiomatization for Lfo
dyn (Φh , Φo )
with respect to evidential runs.
Proof. It is easy to see that each axiom is valid in evidential runs. To prove completeness, we
follow the same procedure as in the proof of Theorem 4.1, showing that if ϕ is consistent,
then it is satisfiable, that is, there exists an evidential run r and valuation v such that
(r, m, v) |= ϕ for some point (r, m) of r.
As in the body of the paper, let Φh = {h1 , . . . , hnh } and Φo = {ob 1 , . . . , ob no }. Let ϕ be
a consistent formula. The first step of the process is to reduce the formula ϕ to a canonical
form with respect to the  operator. Intuitively, we push down every occurrence of a  to
the polynomial inequality formulas present in the formula. It is easy to see that axioms and
inference rules T1–T6 can be used to establish that ϕ is provably equivalent to a formula
ϕ0 where every occurrence of  is in the form of subformulas n (ob) and n (p ≥ c), where
p is a polynomial term that contains at least one occurrence of the Pr operator. We use the
notation n ϕ for  . . . ϕ, the n-fold application of  to ϕ. We write 0 ϕ for ϕ. Let N
be the maximum coefficient of  in ϕ0 .
By way of contradiction, assume that ϕ0 (and hence ϕ) is unsatisfiable. As in the proof
of Theorem 4.1, we reduce the formula ϕ0 to an equivalent formula in the language of real
closed fields. Let u1 , . . . , unh , v10 , . . . , vn0 o , . . . , v1N , . . . , vnNo , y10 , . . . , yn0 o , . . . , y1N , . . . , ynNo , and
zhi1 ,...,ik i,1 , . . . , zhi1 ,...,ik i,nh (for every sequence hi1 , . . . , ik i) be new variables, where, intuitively,
• ui gets value 1 if hypothesis hi holds, 0 otherwise;
• vin gets value 1 if observation ob i holds at time n, 0 otherwise;
• yin represents Pr(hi ) at time n;
31

Halpern & Pucella

• zhi1 ,...,ik i,j represents w(hob i1 , . . . , ob ik i, hj ).
The main difference with the construction in the proof of Theorem 4.1 is that we have variables vin representing the observations at every time step n, rather than variables representing observations at the only time step, variables yin representing each hypothesis probability
at every time step, rather than variables representing prior and posterior probabilities, and
variables zhi1 ,...,ik i,j representing the weight of evidence of sequences of observations, rather
than variables representing the weight of evidence of single observations. Let v represent
that list of new variables. We consider the same formulas as in the proof of Theorem 4.1,
modified to account for the new variables, and the fact that we are reasoning over multiple
time steps. More specifically, the formula ϕh is unchanged. Instead of ϕo , we consider formulas ϕ1o , . . . , ϕN
o saying that exactly one observation holds at each time time step, where
ϕno is given by:
(v1n = 0 ∨ v1n = 1) ∧ · · · ∧ (vnno = 0 ∨ vnnh = 1) ∧ v1n + · · · + vnnh = 1.
Let ϕ0o = ϕ1o ∧ · · · ∧ ϕN
o .
Similarly, instead of ϕpr and ϕpo , we consider formulas ϕ1p , . . . , ϕN
p expressing that Pr is
a probability measure at each time step, where ϕnp is given by:
y1n ≥ 0 ∧ · · · ∧ ynnh ≥ 0 ∧ y1n + · · · + ynnh = 1.
Let ϕp = ϕ1p ∧ · · · ∧ ϕN
p .
Similarly, we consider ϕw ,p and ϕw ,f , except where we replace variables zi,j by zhii,j , to
reflect the fact that we now consider sequences of observations. The formula ϕw ,up , capturing
the update of a prior probability into a posterior probability given by E5, is replaced by
the formulas ϕ1w ,up , . . . , ϕN
w ,up representing the update of the probability at each time step,
n
where ϕw ,up is given by the obvious generalization of ϕw ,up :
z1,nh ∧
(v1n = 1 ⇒ (y1n−1 z1,1 = y1n y1n−1 z1,1 + · · · + y1n ynn−1
h
n−1
n−1
n
z1,nh ))∧
· · · ∧ ynh z1,nh = ynh y1 z1,1 + · · · + ynnh ynn−1
h
···∧
zno ,nh ∧
(vnno = 1 ⇒ (y1n−1 zno ,1 = y1n y1n−1 zno ,1 + · · · + y1n ynn−1
h
n y n−1 z
n y n−1 z
· · · ∧ ynn−1
z
+
.
.
.
y
=
y
no ,nh
no ,1
no ,nh )).
nh 1
nh nh
h
Let ϕ0w ,up = ϕ1w ,up ∧ · · · ∧ ϕN
w ,up .
Finally, we need a new formula ϕw ,c capturing the relationship between the weight
of evidence of a sequence of observations, and the weight of evidence of the individual
observations, to capture axiom E6:
^
zhi1 i,h1 · · · zhik i,h1 = zhi1 ,...,ik i,h1 zhi1 i,h1 · · · zhik i,h1
1≤k≤N
+ · · · + zhi1 ,...,ik i,h1 zhi1 i,hnh · · · zhik i,hnh ∧
1≤i1 ,...,ik ≤no
^
··· ∧
zhi1 i,hnh · · · zhik i,hnh = zhi1 ,...,ik i,hnh zhi1 i,h1 · · · zhik i,h1
1≤k≤N
+ · · · + zhi1 ,...,ik i,hnh zhi1 i,hnh · · · zhik i,hnh .
1≤i1 ,...,ik ≤no

32

A Logic for Reasoning about Evidence

Let ϕ̂ be the formula in the language of real closed fields obtained from ϕ by replacing
each occurrence of the primitive proposition hi by ui = 1, each occurrence of n ob i by
vin = 1, and within
each polynomial inequality formula n (p ≥ c), replacing each occurrence
P
of Pr(ρ) by hi ∈[[ρ]] yin , each occurrence of w(hob i1 , . . . , ob ik i, hj ) by zhi1 ,...,ik i,j , and each
occurrence of an integer coefficient k by 1 + · · · + 1 (k times). Finally, let ϕ0 be the formula
∃v(ϕh ∧ ϕ0o ∧ ϕp ∧ ϕw ,p ∧ ϕw ,f ∧ ϕ0w ,up ∧ ϕw ,c ∧ ϕ̂).
It is easy to see that if ϕ is unsatisfiable over evidential systems, then ϕ0 is false about
the real numbers. Therefore, ¬ϕ0 must be a formula valid in real closed fields, and hence an
instance of RCF. Thus, ¬ϕ0 is provable. It is straightforward to show, using the obvious
variant of Lemma A.3 that ¬ϕ itself is provable, contradicting the fact that ϕ is consistent.
Thus, ϕ must be satisfiable, establishing completeness.
t
u

References
Ben-Or, M., Kozen, D., & Reif, J. H. (1986). The complexity of elementary algebra and
geometry. Journal of Computer and System Sciences, 32 (1), 251–264.
Canny, J. F. (1988). Some algebraic and geometric computations in PSPACE. In Proc. 20th
Annual ACM Symposium on the Theory of Computing (STOC’88), pp. 460–467.
Carnap, R. (1962). Logical Foundations of Probability (Second edition). University of
Chicago Press.
Casella, G., & Berger, R. L. (2001). Statistical Inference (Second edition). Duxbury.
Chan, H., & Darwiche, A. (2005). On the revision of probabilistic beliefs using uncertain
evidence. Artificial Intelligence, 163, 67–90.
de Alfaro, L. (1998). Formal Verification of Probabilistic Systems. Ph.D. thesis, Stanford
University. Available as Technical Report STAN-CS-TR-98-1601.
Enderton, H. B. (1972). A Mathematical Introduction to Logic. Academic Press.
Fagin, R., & Halpern, J. Y. (1994). Reasoning about knowledge and probability. Journal
of the ACM, 41 (2), 340–367.
Fagin, R., Halpern, J. Y., & Megiddo, N. (1990). A logic for reasoning about probabilities.
Information and Computation, 87 (1/2), 78–128.
Fischer, M. J., & Zuck, L. D. (1988). Reasoning about uncertainty in fault-tolerant distributed systems. Technical report YALEU/DCS/TR–643, Yale University.
Good, I. J. (1950). Probability and the Weighing of Evidence. Charles Griffin & Co. Ltd.
Good, I. J. (1960). Weights of evidence, corroboration, explanatory power, information
and the utility of experiments. Journal of the Royal Statistical Society, Series B, 22,
319–331.
Halpern, J. Y., & Fagin, R. (1992). Two views of belief: belief as generalized probability
and belief as evidence. Artificial Intelligence, 54, 275–317.
Halpern, J. Y., Moses, Y., & Tuttle, M. R. (1988). A knowledge-based analysis of zero
knowledge. In Proc. 20th Annual ACM Symposium on the Theory of Computing
(STOC’88), pp. 132–147.
33

Halpern & Pucella

Halpern, J. Y., & Pucella, R. (2003). A logic for reasoning about evidence. In Proc. 19th
Conference on Uncertainty in Artificial Intelligence (UAI’03), pp. 297–304.
Halpern, J. Y., & Pucella, R. (2005a). Evidence with uncertain likelihoods. In Proc. 21th
Conference on Uncertainty in Artificial Intelligence (UAI’05), pp. 243–250.
Halpern, J. Y., & Pucella, R. (2005b). Probabilistic algorithmic knowledge. Logical Methods
in Computer Science, 1 (3:1).
Halpern, J. Y., & Tuttle, M. R. (1993). Knowledge, probability, and adversaries. Journal
of the ACM, 40 (4), 917–962.
He, J., Seidel, K., & McIver, A. (1997). Probabilistic models for the guarded command
language. Science of Computer Programming, 28 (2–3), 171–192.
Jeffrey, R. C. (1992). Probability and the Art of Judgement. Cambridge University Press.
Kyburg, Jr., H. E. (1983). Recent work in inductive logic. In Machan, T., & Lucey, K.
(Eds.), Recent Work in Philosophy, pp. 87–150. Rowman & Allanheld.
Milne, P. (1996). log[p(h|eb)/p(h|b)] is the one true measure of confirmation. Philosophy of
Science, 63, 21–26.
Pearl, J. (1988). Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. Morgan Kaufmann.
Popper, K. R. (1959). The Logic of Scientific Discovery. Hutchinson.
Renegar, J. (1992). On the computational complexity and geometry of the first order theory
of the reals. Journal of Symbolic Computation, 13 (3), 255–352.
Shafer, G. (1976). A Mathematical Theory of Evidence. Princeton University Press.
Shafer, G. (1982). Belief functions and parametric models (with commentary). Journal of
the Royal Statistical Society, Series B, 44, 322–352.
Shoenfield, J. R. (1967). Mathematical Logic. Addison-Wesley, Reading, Mass.
Tarski, A. (1951). A Decision Method for Elementary Algebra and Geometry (2nd edition).
Univ. of California Press.
Vardi, M. Y. (1985). Automatic verification of probabilistic concurrent finite-state programs.
In Proc. 26th IEEE Symposium on the Foundations of Computer Science (FOCS’85),
pp. 327–338.
Walley, P. (1987). Belief function representations of statistical evidence. Annals of Statistics,
18 (4), 1439–1465.

34

Journal of Artificial Intelligence Research 26 (2006) 323-369

Submitted 10/05; published 08/06

Temporal Planning using Subgoal Partitioning and
Resolution in SGPlan
Yixin Chen

chen@cse.wustl.edu

Department of Computer Science and Engineering
Washington University in St Louis
St Louis, MO 63130 USA

Benjamin W. Wah
Chih-Wei Hsu

wah@manip.crhc.uiuc.edu
chsu@manip.crhc.uiuc.edu

Department of Electrical and Computer Engineering
and the Coordinated Science Laboratory
University of Illinois at Urbana-Champaign
Urbana, IL 61801 USA

Abstract
In this paper, we present the partitioning of mutual-exclusion (mutex) constraints in
temporal planning problems and its implementation in the SGPlan4 planner. Based on
the strong locality of mutex constraints observed in many benchmarks of the Fourth International Planning Competition (IPC4), we propose to partition the constraints of a
planning problem into groups based on their subgoals. Constraint partitioning leads to
significantly easier subproblems that are similar to the original problem and that can
be efficiently solved by the same planner with some modifications to its objective function. We present a partition-and-resolve strategy that looks for locally optimal subplans in
constraint-partitioned temporal planning subproblems and that resolves those inconsistent
global constraints across the subproblems. We also discuss some implementation details of
SGPlan4 , which include the resolution of violated global constraints, techniques for handling producible resources, landmark analysis, path finding and optimization, search-space
reduction, and modifications of Metric-FF when used as a basic planner in SGPlan4 . Last,
we show results on the sensitivity of each of these techniques in quality-time trade-offs
and experimentally demonstrate that SGPlan4 is effective for solving the IPC3 and IPC4
benchmarks.

1. Introduction
In this paper, we present an innovative partition-and-resolve strategy and its implementation in SGPlan4 for solving temporal planning problems in PDDL2.2. Our strategy partitions the mutual-exclusion (mutex) constraints of a temporal planning problem by its
subgoals into subproblems, solves the subproblems individually using a modified Metric-FF
planner, and resolves those violated global constraints iteratively across the subproblems.
We evaluate various heuristics for resolving global constraints and demonstrate the performance of SGPlan4 in solving the benchmarks of the Third (IPC3) and the Fourth (IPC4)
International Planning Competitions.
Most general and popular methods for solving large planning problems, such as systematic search, heuristic search, and transformation methods, can be viewed as the recursive
c
2006
AI Access Foundation. All rights reserved.

Chen, Wah, & Hsu

P:
Variable
partitioning
ordered by
heuristic
functions

A

B

C

SP = SA ∨ SB ∨ SC

Variables:

a) Search-space partitioning

a1

11111111111111111111111111
00000000000000000000000000
00000000000000000000000000
11111111111111111111111111
00000000000000000000000000
11111111111111111111111111
00000000000000000000000000
11111111111111111111111111
00000000000000000000000000
11111111111111111111111111
00000000000000000000000000
11111111111111111111111111
00000000000000000000000000
11111111111111111111111111
00000000000000000000000
11111111111111111111111
00000000000000000000000
11111111111111111111111
00000000000000000000000
11111111111111111111111
00000000000000000000000
11111111111111111111111
00000000000000000000000
11111111111111111111111
00000000000000000000000
11111111111111111111111
a2

a3

b) Complete and heuristic searches

Figure 1: Search-space partitioning branches on variable assignments in order to decompose P into a disjunction (∨) of subproblems with disjoint search spaces. The
complexity of each subproblem is similar to that of P .

partitioning of a search space into independent subproblems and the iterative evaluation
of the subproblems until a feasible solution is found. At each level of application of the
approach, a problem or a subproblem is decomposed by partitioning its variable space into
a disjunction (∨) of subspaces (Figure 1a). To reduce the search complexity, the approach is
often combined with intelligent backtracking that employs variable/value ordering to order
the subproblems generated, that pre-filters partial inconsistent assignments to eliminate
infeasible subproblems, and that prunes subproblems using bounds computed by relaxation
or approximation.
Search-space partitioning can be directly applied on a planning problem or on a transformed version of the problem. Direct methods include complete and heuristic searches. As
is illustrated in Figure 1b, these methods partition a search space recursively by branching
on assigned variables (selection of actions). The difference between a complete search and
a heuristic search is that the former enumerates all subspaces systematically, whereas the
latter prioritizes subspaces by a heuristic function and evaluates them selectively. Examples of complete planners include UCPOP (Penberethy & Weld, 1992), Graphplan (Blum
& Furst, 1997), STAN (Long & Fox, 1998), PropPLAN (Fourman, 2000), System R (Lin,
2001), SIPE-2 (Wilkins, 1990), O-Plan2 (Tate, Drabble, & Kirby, 1994), ZENO (Penberethy
& Weld, 1994), TALplanner (Doherty & Kvarnstrm, 1999), and SHOP2 (Nau, Muoz-Avila,
Cao, Lotem, & Mitchell, 2001); examples of heuristic planners include HSP (Bonet &
Geffner, 2001), FF (Hoffmann & Nebel, 2001), AltAlt (Nigenda, Nguyen, & Kambhampati, 2000), GRT (Refanidis & Vlahavas, 2001), MO-GRT (Refanidis & Vlahavas, 2002),
ASPEN (Chien, Rabideau, Knight, Sherwood, Engelhardt, Mutz, Estlin, Smith, Fisher,
Barrett, Stebbins, & Tran, 2000), Metric-FF (Hoffmann & Nebel, 2001), GRT-R (Refanidis
& Vlahavas, 2001), LPG (Gerevini & Serina, 2002), MIPS (Edelkamp, 2002), Sapa (Subbarao & Kambhampati, 2002), and Europa (Jonsson, Morris, Muscettola, & Rajan, 2000).
In contrast, in a transformation approach, a problem is first transformed into a satisfiability
or an optimization problem, before the transformed problem is solved by a SAT or integer
programming solver that employs search-space partitioning. Notable planners using this
324

Temporal Planning using Subgoal Partitioning and Resolution

10000

P:
Run time

1000

G
A′

B′

C′

100
10
1
0.1

AIRPORT-NT-20
PIPESWORLD-NT-NT-50

0.01

SP = SA′ ∧ SB′ ∧ SC ′ ∧ SG

1

a) Constraint partitioning

2
3
4
5
Number of Subgoals in a Subproblem

b) Exponential behavior in solution time

Figure 2: Constraint partitioning decomposes P into a conjunction (∧) of subproblems
with disjoint constraints but possibly overlapping search spaces, and a set of
global constraints (G) to be resolved. Since the complexity of each subproblem is
substantially smaller than that of P , it leads to an exponential decrease in solution
time by Metric-FF on two IPC4 benchmarks (AIRPORT-NONTEMP-20 and
PIPESWORLD-NOTANKAGE-NONTEMP-50) when the number of subgoals in
a subproblem is decreased from 5 to 1.

approach include SATPLAN (Kautz & Selman, 1996), Blackbox (Kautz & Selman, 1999),
ILP-PLAN (Kautz & Walser, 2000), and LPSAT (Wolfman & Weld, 2000).
One of the limitations of search-space partitioning is that the complexity of a problem
is not dramatically reduced through partitioning. Although pruning and ordering strategies can make the search more efficient by not requiring the search of every subspace, the
aggregate complexity of finding a solution to one of the subproblems is the same as that of
the original problem.
In this paper, we study a constraint-partitioning approach that decomposes the constraints of a planning problem into a conjunction (∧) of subproblems with disjoint constraints but possibly overlapping search spaces (Figure 2a). The concept of constraints on
planning problems studied in this paper is precisely defined in Section 2.1. Informally, a
(mutex) constraint refers to the condition under which two actions can overlap with each
other in their execution. Since all the constraints must be satisfied, all the subproblems
must be solved in order to solve the original problem.
By decomposing the constraints of a problem into subproblems and by solving each
independently, a subproblem will require significantly less time to solve because it is much
more relaxed than the original problem. As an illustration, Figure 2b shows the exponential
decrease in solution time when the number of subgoals in a subproblem is reduced linearly.
Here, a subgoal is a collection of conjuncts in a conjunctive top-level goal of the problem. For
both of the IPC4 instances evaluated, the run time is more than 1500 seconds when there
are five subgoals in a subproblem and less than one second when there is one. Hence, the
aggregate complexity of solving all the decomposed subproblems is exponentially smaller
than that of the original problem.
325

Chen, Wah, & Hsu

S0

P1

11
00
00
11

11
00
00
11
11
00
00
11
11
00
00
11

111
000
000
111
000
111
000
111
11
00
S1
00 000
11
111
000
111
000
111
000
111
000
111
000
111
000
111
000
111

11
00
00
11

P2

111
000
000
111

11
00
00
11

11
00
00
11

111
000
000
111
000
111
000
111
000
111
000
111
000
111
000
111

S2
11
00
000
111
11 111
00
000
000
111
000
111

11
00
00
11

P3

11
00
00
11

S3

11
00
11
00

11
00
00
11
11
00
00
11

11
00
00
11

11
00
11
00

Figure 3: Partitioning the constraints of a planning problem along its temporal horizon into
three stages requires finding suitable intermediate states S1 and S2 in order to
connect the subplans in the three stages together. S0 and S3 are, respectively,
the initial and the final states.

Constraint partitioning, however, leads to global constraints across subproblems (SG
in Figure 2a) that need to be resolved. These global constraints include those that span
across common variables in multiple subproblems, such as those that relate two actions
in different subproblems. Since these constraints may not be satisfied after solving the
subproblems independently, the subproblems may need to be solved multiple times in order
to resolve any violated global constraints.
In general, violated global constraints across subproblems cannot be efficiently resolved
by brute-force enumeration because the search space for the global constraints is defined
by the Cartesian product of the search spaces across the subproblems and is exponentially
large. Dynamic programming cannot be applied because global constraints may span across
multiple subproblems. This means that a partial feasible plan that dominates another
partial feasible plan in one subproblem will fail to execute when the dominating plan violates
a global constraint in another subproblem.
To address the resolution of violated global constraints, we summarize in Section 3 the
theory of extended saddle points developed in our previous work (Wah & Chen, 2006). By
choosing a suitable neighborhood, the theory allows a mixed-integer nonlinear programming problem (MINLP) to be partitioned into subproblems that are related by a necessary
condition on the global constraints. Further, a necessary condition on each subproblem
significantly prunes the Cartesian product of the search spaces across the subproblems in
which inconsistent global constraints are to be resolved.
In addition to the efficient resolution of violated global constraints, the success of our
approach depends on a strong locality of the constraints with respect to the actions they
relate. We have observed informally in our previous work a strong locality of the constraints. Based on this strong locality, we have studied two alternatives for partitioning
the constraints: partitioning them by time (Wah & Chen, 2006; Chen & Wah, 2003) and
partitioning them by subgoals (Wah & Chen, 2004, 2003).
The idea of partitioning a planning problem by time is to partition its constraints by
their temporal bindings into stages. To find an overall feasible plan, a planner will need
to find a subplan from the initial to the final states of each stage that satisfy the local as
well as the global constraints, where the final state of one stage will be the initial state of
326

Temporal Planning using Subgoal Partitioning and Resolution

the next stage. For example, after partitioning the horizon into three stages (Figure 3), the
planner assigns some values to the intermediate states S1 and S2 , solves each subproblem
individually, and perturbs S1 and S2 to look for another solution if feasible subplans cannot
be found in any of the stages.
A major drawback of partitioning a planning problem by its temporal horizon is that
constraint resolutions may have to sequentially propagate through multiple stages. We have
found that the partitioning of the constraints in PDDL2.1 benchmarks along their temporal
horizon often leads to many global constraints that only relate states in adjacent stages.
As a result, when a violated subgoal is caused by an incorrect assignment of states in an
early stage of the horizon, the resolution of the incorrect assignment will have to propagate
sequentially through the stages. Oftentimes, the propagation of such information may cause
a search to get stuck in an infeasible point for an extended period of time (Wah & Chen,
2004). To this end, an expensive enumeration of the final state in each stage (S1 and S2 in
Figure 3) may be needed in order to resolve the inconsistencies.
A second approach we have studied in our previous work is to partition the constraints
of a planning problem by their subgoals (Wah & Chen, 2004, 2003). After evaluating the
subproblems, any inconsistent global constraints among them are first identified, and the
subproblems are re-evaluated until all the global constraints are satisfied. Partitioning by
subgoals eliminates the need of selecting a final state for each subproblem because the
initial and the final states of each subgoal are known. Using this approach, our previous
work has shown improvements in time and quality over the MIPS planner in solving some
IPC3 benchmarks.
With respect to the second approach, we have made four main contributions in this
paper.
First, we quantitatively evaluate in Section 2.2 the locality of constraints of all IPC4
benchmarks as well as benchmarks from the Blocksworld domain and the Depots domain.
Our results show that constraint partitioning by subgoals consistently leads to a lower
fraction of initial active global constraints than constraint partitioning by time. Our results
also explain why constraint partitioning does not work well on some domains, such as
Blocksworld and Depots.
Second, we incorporate Metric-FF (Hoffmann, 2003) as our basic planner in SGPlan4
and SGPlan4.1 , instead of MIPS as in our previous work (Wah & Chen, 2004). This change
is non-trivial because it requires significant extensions of Metric-FF in order to handle the
new features in PDDL2.2 beyond those in PDDL2.1. These extensions include the support
of temporal planning, the handling of derived predicates and timed initial literals, and the
handling of wrappers for timed initial literals (Section 5.3).
Third, we describe new techniques for improving search efficiency in the global- and
local-level architectures of our partition-and-resolve approach (Section 4.1). These include
the handling of producible resources (Section 4.3), subgoal-level decomposition using landmark analysis, path finding and path optimization (Section 5.1), and subgoal-level planning
using search-space reduction (Section 5.2). We explain their integration in our planners and
analyze their effectiveness.
Last, we study in Section 4.2 trade-offs between solution time and quality in our heuristics for updating the penalties of violated global constraints. These trade-offs allow us to
generate plans either of better quality but more time (SGPlan4.1 ), or of lower quality but
327

Chen, Wah, & Hsu

less time (SGPlan4 ). The optimization of quality requires the estimation of the makespan
of multiple subplans by an enhanced PERT algorithm (Section 5.3). In our previous work
on constraint partitioning by subgoals (Wah & Chen, 2004), we have focused only on minimizing the planning time. Without optimizing quality, violated global constraints are often
easier to resolve because a planner can always delay one or more actions in order to avoid
such constraints. Finally, we compare in Section 7 the performance of our planners with
respect to that of other planners.

2. Locality of Mutex Constraints in Temporal Planning
In this section, we define the mutex constraints of planning problems. Based on the structure
of these constraints in IPC4 benchmarks, we show that constraint partitioning by subgoals
leads to constraints that can be localized better than constraint partitioning by time.
2.1 Representation of Mutex Constraints
By following standard notations and definitions in the literature (Hoffmann & Nebel, 2001;
Garrido, Fox, & Long, 2002), we summarize in this section the basic definitions of mutex
constraints used in this paper.
Definition 1. A planning problem T = (O, F, I, G) is a quadruple, where O is the set of
possible actions in T , F is the set of all facts, I is the set of initial facts, and G is the set
of goal facts.
	

Definition 2. A state S = f1 , · · · , fnS is a subset of facts in F that are true.
Definition 3. A STRIPS action a ∈ O is associated with the following attributes:
a) pre(a), a set of facts that define the preconditions of action a;
b) add(a), a set of facts that define the add effects of a; and
c) del(a), a set of facts that define the delete effects of a.
The resulting state of applying action a to state S is defined as:
( S
(S add(a))\del(a) if pre(a) ⊆ S
Result(S, a) =
S
if pre(a) 6⊆ S.

(1)

The resulting state of applying a sequence of actions a1 , · · · , an to S is recursively defined
as:
Result(S, (a1 , · · · , an )) = Result(Result(S, (a1 , · · · , an−1 )), an ).

(2)

Next, we extend our action model to temporal planning. For durative actions supported
in PDDL2.2, a precondition fact can be effective at the beginning, at the end, or during the
entire duration of an action; whereas an add effect or a delete effect can be effective only
at the beginning or at the end of an action.
Definition 4. A temporal action a ∈ O is associated with the following attributes:
a) s(a) and e(a) define, respectively, the start time and the end time of a.
328

Temporal Planning using Subgoal Partitioning and Resolution

action
active mutexes
pre(a1 )

add(a4 )

a1

pre(a5 )

a4

a5

a2
del(a2 )

add(a2 )

a7
a6

a3
del(a3 )

pre(a6 )

del(a7 )

time

Figure 4: An example temporal plan, where active mutexes between actions are shown as
dashed lines, and inactive mutexes as dotted lines.

b) The preconditions can be divided into three types: prestart (a), the set of initial
preconditions to be held at s(a); preend (a), the set of final preconditions to be held at e(a);
and preoverall (a), the set of invariant preconditions over an open interval (s(a), e(a)).
c) There are two types of add effects: addstart (a), the set of initial add effects to be
asserted at s(a); and addend (a), the set of final add effects to be asserted at e(a).
d) There are two type of delete effects: delstart (a), the set of initial delete effects to be
asserted at s(a); and delend (a), the set of final delete effects to be asserted at e(a).
Definition 5. A temporal plan P = {a1 , a2 , · · · , am } is a list of m temporal actions, where
ai has been assigned start time s(ai ) and end time e(ai ).
Figure 4 illustrates a temporal plan of seven actions. In each action, we indicate, where
appropriate, its preconditions, add effects, and delete effects.
Concurrent actions in a plan must be arranged in such a way that observes mutual
exclusions (mutexes). The notion of mutex was first proposed in GraphPlan (Blum & Furst,
1997). It was defined for a planning graph, which is a level-by-level constraint graph that
alternates between a fact level and an action level. Mutex relationships in a planning graph
can be classified into transient (level-dependent) and persistent (level-independent) (Blum
& Furst, 1997). A mutex is transient if it exists only in certain levels of the graph and
vanishes as more levels of the graph are built. In contrast, a mutex is persistent if it holds
at every level until the fix-point level (the last level of the graph) is achieved. In this paper,
we only consider level-independent, persistent mutex relationships, as transient mutexes are
exclusively used for searches in GraphPlan.
Actions a and b are marked as persistently mutual exclusive when one of the following
occurs.
329

Chen, Wah, & Hsu

a) Actions a and b have persistent competing needs,1 in which competing needs are
represented by the persistent mutex of the preconditions of a and those of b;
b) They have persistent inconsistent effects, when one action deletes an add effect of
the other.
c) They have persistent interference, when one action deletes a precondition of the other.
Two facts p and q are persistently mutual exclusive if all possible ways of making p true
are persistently exclusive with all possible ways of making q true; that is, each action a
having p as an add effect (p ∈ add(a)) is persistently mutual exclusive with each action
b having q as an add effect (q ∈ add(b)). For simplicity, in the rest of this paper, mutex
actions and facts refer to the corresponding persistent mutex actions and facts.
Given a temporal plan, a mutex relationship can be active or inactive. For example,
actions a1 and a2 in Figure 4 have an active mutex because the two actions overlap in their
execution and have persistent interference. However, a2 and a3 have an inactive mutex
because they do not overlap in their execution.
Based on the above discussion, the conditions for an active mutex to occur between two
actions a and b can be summarized in four cases (Garrido et al., 2002):
a) Actions a and b start together, and there is a nonempty intersection between their
initial preconditions (resp. add effects) and their initial delete effects (resp. delete effects).
b) Actions a and b end together, and there is a nonempty intersection between their
final preconditions (resp. add effects) and their final delete effects (resp. delete effects).
c) Action a ends when b starts, and there is a nonempty intersection between the final
delete effects (resp. delete effects, add effects, and preconditions) of a and the initial add
effects (resp. preconditions, delete effects, and delete effects) of b.
d) Action a starts (resp. ends) during the execution of b, and there is a nonempty intersection between the initial (resp. final) delete effects of a and the invariant preconditions
of b.
While the conditions above are introduced to prevent two mutually exclusive actions
from executing simultaneously, there may be actions that block the propagation of facts
(no-op action) and that cause unsupported actions later. Such a condition can be detected
by looking for actions that delete some existing facts in the current plan. With respect to
conditions for mutex due to competing needs, we do not need to represent them explicitly
because mutexes due to competing needs must accompany the other two types of mutex:
when two preconditions are mutually exclusive due to competing needs, the two action
sequences of making them true are also mutually exclusive. As example, the active mutex
between a5 and a6 in Figure 4 is due to competing needs and is caused by the active mutex
between a3 and a4 .
The mutex constraints studied in this paper are not in closed form. Instead, each is
defined by a discrete procedural function that checks if a pair of actions meet one of the four
conditions above. The inputs to the function are the start time and the end time of each
action, which are continuous in temporal problems and discrete in propositional problems.
1. The terms “competing needs,” “inconsistent effects,” and “interference” were originally proposed for
GraphPlan (Blum & Furst, 1997).

330

Temporal Planning using Subgoal Partitioning and Resolution

11
00
00
11

11
00
00
11
11
00
11
00

11
00
00
11

11
00
00
11

00
11
00
11
11111111111
00000000000
00
11
00000000000
11111111111
00
11
00000000000
11111111111
00000000000
11111111111
000
111
00000000000
11111111111
000
111

11
00
00
11

Subproblem 2

11
00
00
11

11
00
00
11

Subproblem 1

00
11
00
11
11111111111
00000000000
00
11
00000000000
11111111111
00
11
00000000000
11111111111
00000000000
11111111111
00
11
00000000000
11111111111
00
11

11
00
00
11

11
00
00
11

11
00
00
11

11
00
11
00

11
00
11
00

11
00
00
11

11
00
00
11

11
00
11
00

11
00
11
00
11
00
00
11

11
00
11
00

11
00
00
11
11
00
00
11

11
00
00
11

11
00
00
11

11
00
00
11

Subproblem 3

11
00
00
11

11
00
00
11

11
00
11
00

11
00
11
00
11
00
00
11

11
00
00
11
11
00
00
11

11
00
00
11

a) 63 mutex constraints among actions b) Partitioning the mutex constraints by subgoals
Figure 5: Mutex constraints in the IPC4 AIRPORT-TEMP-4 instance. Each rectangular
box represents an action, and a line joining two actions represents a mutex constraint (that may be inactive). Most constraints (52 out of 63 or 83%) are local
constraints after partitioning them by subgoals. Global mutex constraints are
shown in dashed lines in (b).

2.2 Locality of Mutex Constraints
In this section, we evaluate the partitioning of mutex constraints for some planning benchmarks. Our analysis shows the strong locality of these constraints when they are partitioned
by subgoals as compared to the case when they are partitioned by time. We do not study
other criteria for partitioning because they may lead to subproblems whose initial and final states are not specified. Such subproblems will be hard to solve by existing planners
because they may require a systematic enumeration of their initial and final states when
finding feasible plans.
Figure 5a shows the 63 mutex constraints in a solution plan to the fourth instance of the
IPC4 AIRPORT-TEMP domain. The instance involves moving three planes in an airport
to designated gates. Each rectangular box in the figure represents an action, whereas a line
joining two actions represents a mutex constraint (that may be inactive). Figure 5b shows
the partitioning of the constraints into three subproblems, each involving the movement of
one plane. We show local constraints (those that are relevant to the actions in one subproblem) in solid lines and global constraints relating those actions in different subproblems in
dashed lines. It is clear that a majority (83%) of the constraints are local after partitioning
them by subgoals.
To demonstrate the localization of mutex constraints when partitioned by subgoals, we
analyze all the IPC4 instances. We first modify the original Metric-FF planner (Hoffmann,
2003) in order to support the new features in PDDL2.2, such as temporal actions and derived
predicates. For each instance, we use the modified planner to find an initial subplan for
each of the subproblems. We then find all the mutexes among the actions, including active
and inactive ones. Finally, we compute the number of global constraints related to actions
331

rga,G

0.6
0.4
0.2
0

1.0

0.6
0.4
0.2
0

rga,G

0.6
0.4
0.2
0

1.0

rga,G

0.6
0.4
0.2
0

0 5 10 15 20 25 30 35 40 45 50
Instance ID

0

rg,T
rg,G

0.8

rga,G

0.6
0.4
0.2
0
0 5 10 15 20 25 30 35 40 45 50
Instance ID

f) UMTS-TEMP

0.4
0.2
0

5

2

4

1.0

rg,T
rg,G

0.8

rga,G

0.6
0.4
0.2
0
0

5

10
15
Instance ID

g) DEPOTS-TIME

20

12

14

0.6
0.4
0.2
0

10 15 20 25 30 35 40
Instance ID

1.0

6
8 10
Instance ID

rg,T
rg,G
rga,G

0.8

0 2 4 6 8 10 12 14 16 18 20
Instance ID

d) SATELLITE-TIME
Global-constraint fraction

Global-constraint fraction

d) PSR-SMALL
1.0

0.6

c) PROMELA-OPTICALTELEGRAPH

rg,T
rg,G

0.8

rg,T
rg,G
rga,G

0.8

0

Global-constraint fraction

b) PIPESWORLD-NOTANKAGENONTEMP

rg,T
rg,G

0.8

rga,G

1.0

0 5 10 15 20 25 30 35 40 45 50
Instance ID

Global-constraint fraction

Global-constraint fraction

1.0

rg,T
rg,G

0.8

0 5 10 15 20 25 30 35 40 45 50
Instance ID

a) AIRPORT-TEMP

Global-constraint fraction

rg,T
rg,G

0.8

e) SETTLER
Global-constraint fraction

1.0

Global-constraint fraction

Global-constraint fraction

Chen, Wah, & Hsu

25

1.0

rg,T
rg,G

0.8

rga,G

0.6
0.4
0.2
0
0

5

10
15
Instance ID

20

25

h) BLOCKSWORLD

Figure 6: Variations of rg,T , rg,G , and rga,G across the instances of seven IPC4 domain
variants as well as the instances of the DEPOTS-TIME domain variant from
IPC3 and those of the Blocksworld domain from IPC2. (The latter two domains
are deemed difficult for constraint partitioning.)

in different subplans, as well as the number of initial active global constraints based on the
subplan evaluated for each subproblem. As a comparison, we also evaluate the partitioning
of the constraints by their temporal horizon.
Figure 6 illustrates the results for seven IPC4 domain variants, as well as the Blocksworld
domain from IPC2 and the DEPOTS-TIME variant from IPC3. Table 1 further summarizes
the average statistics across all the instances in each IPC4 domain variant and those of the
Blocksworld domain and the Depots domain variants. For each instance in partitioning
by time, we use the modified Metric-FF planner to find an initial plan, set the number of
temporal stages to be the same as the number of subgoals, and partition the horizon of the
solution plan evenly into multiple stages. We then count the number of local constraints
in each stage and the number of global constraints relating actions in different stages. For
each instance, let Nc be the total number of mutex constraints, NgT be the number of global
constraints under constraint partitioning by time, NgG be the number of global constraints
332

Temporal Planning using Subgoal Partitioning and Resolution

Table 1: Average rg,T , rg,G , rga,G across the instances of IPC4 domains as well as the Depots
domain from IPC3 and the Blocksworld domain from IPC2. (The latter two are
deemed difficult for constraint partitioning.) Boxed numbers are less than 0.1.
Domain Variant

r g,T

r g,G

AIRPORT-NONTEMP
AIRPORT-TEMP
AIRPORT-TEMP-TIMEWINDOWS
AIRPORT-TEMP-TIMEWINDOWS-CO
PIPESWORLD-NOTANKAGE-NONTEMP
PIPESWORLD-NOTANKAGE-TEMP
PIPESWORLD-NOTANKAGE-TEMP-DEADLINE
PIPESWORLD-TANKAGE-NONTEMP
PIPESWORLD-TANKAGE-TEMP
PIPESWORLD-NOTANKAGE-TEMP-DEADLINE-CO
PROMELA-OPTICAL-TELEGRAPH
PROMELA-OPTICAL-TELEGRAPH-DP
PROMELA-OPTICAL-TELEGRAPH-FL
PROMELA-PHILOSOPHER
PROMELA-PHILOSOPHER-DP
PROMELA-PHILOSOPHER-FL
PSR-SMALL
PSR-MIDDLE
PSR-MIDDLE-CO
PSR-LARGE
SATELLITE-STRIPS
SATELLITE-TIME
SATELLITE-TIME-TIMEWINDOWS
SATELLITE-TIME-TIMEWINDOWS-CO
SATELLITE-NUMERIC
SATELLITE-COMPLEX
SATELLITE-COMPLEX-TIMEWINDOWS
SATELLITE-COMPLEX-TIMEWINDOWS-CO
SETTLERS
UMTS-TEMP
UMTS-TEMP-TIMEWINDOWS
UMTS-TEMP-TIMEWINDOWS-CO
UMTS-FLAW-TEMP
UMTS-FLAW-TEMP-TIMEWINDOWS
UMTS-FLAW-TEMP-TIMEWINDOWS-CO
DEPOTS-STRIPS
DEPOTS-SIMPLETIME
DEPOTS-NUMERIC
DEPOTS-TIME
BLOCKSWORLD

0.557
0.568
0.494
0.495
0.695
0.682
0.674
0.687
0.683
0.682
0.575
0.759
0.799
0.554
0.855
0.822
0.897
0.896
0.882
0.902
0.689
0.686
0.648
0.633
0.288
0.642
0.633
0.698
0.549
0.463
0.437
0.407
0.459
0.428
0.414
0.537
0.572
0.491
0.448
0.549

0.219
0.208
0.184
0.188
0.313
0.301
0.297
0.677
0.459
0.296
0.399
0.265
0.426
0.370
0.576
0.507
0.489
0.504
0.478
0.665
0.288
0.289
0.114
0.307
0.305
0.282
0.124
0.153
0.451
0.157
0.126
0.098 
0.136
0.110
0.086
0.418
0.304
0.354
0.237
0.314

333

r
 ga,G
0.017 
0.014 
0.013 
0.014 
0.044 
0.042 
0.033 
0.070 
0.126
0.039 
0.052 
0.020 
0.037 
0.066 
0.019 
0.087 
0.114
0.092 
0.049 
0.096 
0.096 
0.093 
0.027 
0.075 
0.078 
0.069 
0.041 
0.042 
0.100
0.006 
0.008 
0.008 
0.006 
0.008 
0.007 
0.231
0.167
0.188
0.197
0.254

Chen, Wah, & Hsu

G be the number of initial active global
under constraint partitioning by subgoals, and Nga
constraints under constraint partitioning by subgoals. We then compute the following ratios:

NgT
: fraction of global constraints under constraint partitioning by time;
Nc
NgG
rg,G =
: fraction of global constraints under constraint partitioning by subgoals;
Nc
G
Nga
rga,G =
: fraction of initial active global constraints under subgoal partitioning.
Nc

rg,T =

With respect to instances in the IPC4 domains, the results show that constraint partitioning by subgoals leads to a lower rg,G than rg,T , that the fractions do not vary significantly,
and that rga,G is small for most instances. Except for PSR-SMALL and SETTLERS, rga,G
is consistently less than 0.1. This behavior is important because only active constraints will
need to be resolved during planning, and the number of such constraints should decrease
as planning progresses. We describe in Section 4.2 two strategies for reducing the number
active global constraints in planning.
The behavior is worse for the instances in the Blocksworld domain and the Depots domain variants. In these two domains, rga,G is consistently high (over 20%) when constraints
are partitioned by subgoals. The reason is that the actions in different subgoals of each
instance are highly related, making it more difficult to cluster the constraints and leading
to a larger fraction of global constraints. We evaluate the performance of our approach on
these two domains in Section 7.

3. Constraint Partitioning using Penalty Formulations
Given a constrained formulation of a planning problem, we summarize in this section our
theory of extended saddle points in mixed space (Wah & Chen, 2006) that the design of
our planners is based upon.
3.1 The Extended Saddle-Point Condition
Consider the following MINLP with variable z = (x, y), x ∈ Rv and y ∈ Dw :
(Pm ) :

min
z

subject to

f (z),

(3)

h(z) = 0 and g(z) ≤ 0,

where f is continuous and differentiable with respect to x, and g = (g1 , . . . , gr )T and h =
(h1 , . . . , hm )T are general functions that are not necessarily continuous and differentiable.
These assumptions are important because the constraints in our planners are procedural
functions not in closed form. We further assume that f is lower bounded, while g and h
can be unbounded.
The goal of solving Pm is to find a constrained local minimum z ∗ = (x∗ , y ∗ ) with
respect to Nm (z ∗ ), the mixed neighborhood of z ∗ . Because the results have been published
earlier (Wah & Chen, 2006), we only summarize some high-level concepts without the
precise formalism.
334

Temporal Planning using Subgoal Partitioning and Resolution

A mixed neighborhood Nm (z), z = (x, y), in mixed space Rv × Dw is:




 ′

′
′  ′

(4)
Nm (z) = (x , y) x ∈ Nc (x) ∪ (x, y ) y ∈ Nd (y) ,

Definition 6.

where Nc (x) = {x′ : kx′ − xk ≤ ǫ and ǫ → 0} is the continuous neighborhood of x, and the
discrete neighborhood Nd (y) is a finite user-defined set of points {y ′ ∈ Dw }.
Definition 7. Point z ∗ is a CLMm , a constrained local minimum of Pm with respect to
points in Nm (z ∗ ), if z ∗ is feasible and f (z ∗ ) ≤ f (z) for all feasible z ∈ Nm (z ∗ ).
Definition 8.

The penalty function of Pm with penalty vectors α ∈ Rm and β ∈ Rr is:
Lm (z, α, β) = f (z) + αT |h(z)| + β T max(0, g(z)).

(5)

Next, we define informally a constraint-qualification condition needed in the main theorem (Wah & Chen, 2006). Consider a feasible point z ′ = (x′ , y ′ ) and a neighboring point
z ′′ = (x′ + p~, y ′ ) under an infinitely small perturbation along direction p~ ∈ X in the x subspace. When the constraint-qualification condition is satisfied at z ′ , it means that there is
no ~
p such that the rates of change of all equality and active inequality constraints between
z ′′ and z ′ are zero. To see why this is necessary, assume that f (z) at z ′ decreases along p~ and
that all equality and active inequality constraints at z ′ have zero rates of change between z ′′
and z ′ . In this case, it is not possible to find some finite penalty values for the constraints
at z ′′ in such a way that leads to a local minimum of the penalty function at z ′ with respect
to z ′′ . Hence, if the above scenario were true for some p~ at z ′ , then it is not possible to
have a local minimum of the penalty function at z ′ . In short, constraint qualification at
z ′ requires at least one equality or active inequality constraint to have a non-zero rate of
change along each direction ~
p at z ′ in the x subspace.
Theorem 1. Necessary and sufficient ESPC on CLMm of Pm (Wah & Chen, 2006).
Assuming z ∗ ∈ Rv × Dw of Pm satisfies the constraint-qualification condition, then z ∗ is a
CLMm of Pm iff there exist finite α∗ ≥ 0 and β ∗ ≥ 0 that satisfies the following extended
saddle-point condition (ESPC):
Lm (z ∗ , α, β) ≤ Lm (z ∗ , α∗∗ , β ∗∗ ) ≤ Lm (z, α∗∗ , β ∗∗ )

(6)

for any α∗∗ > α∗ and β ∗∗ > β ∗ and for all z ∈ Nm (z ∗ ), α ∈ Rm , and β ∈ Rr .
Note that (6) can be satisfied under rather loose conditions because it only requires
any α∗∗ and β ∗∗ that are larger than some critical α∗ and β ∗ . The theorem is important
because it establishes a one-to-one correspondence between a CLMm z ∗ of Pm and an ESP
(extended saddle point) of the corresponding unconstrained penalty function in (5) when the
penalties are sufficiently large. The theorem also leads to an easy way for finding CLMm .
Since an ESP is a local minimum of (5) (but not the converse), z ∗ can be found by gradually
increasing the penalties of those violated constraints in (5) and by repeatedly finding the
local minima of (5) until a feasible solution to Pm is obtained. This is possible because
there exist many algorithms for locating the local minima of unconstrained functions.
335

Chen, Wah, & Hsu

3.2 The Partitioned Extended Saddle-Point Condition
An important feature of the ESPC in Theorem 1 is that the condition can be partitioned
in such a way that each subproblem implementing a partitioned condition can be solved by
looking for any α∗∗ and β ∗∗ that are larger than α∗ and β ∗ .
Consider Pt , a version of Pm whose constraints can be partitioned into N subproblems:
(Pt ) :

min
z

subject to
and

J(z)
h(t) (z(t)) = 0,
H(z) = 0,

g(t) (z(t)) ≤ 0
G(z) ≤ 0

(local constraints)

(7)

(global constraints).

Subproblem t, t = 1, . . . , N , of Pt has local state vector z(t) = (z1 (t), . . . , zut (t))T of ut
mixed variables, where ∪N
t=1 z(t) = z. Here, z(t) includes all variables that appear in any of
(t)
(t)
the mt local equality constraint functions h(t) = (h1 , . . . , hmt )T and the rt local inequal(t)
(t)
ity constraint functions g(t) = (g1 , . . . , grt )T . Since the partitioning is by constraints,
z(1), . . . , z(N ) may overlap with each other. H = (H1 , . . . , Hp )T and G = (G1 , . . . , Gq )T
are global-constraint functions of z. We assume that J is continuous and differentiable with
respect to its continuous variables, that f is lower bounded, and that g, h, G, and H are
general functions that can be discontinuous, non-differentiable, and unbounded.
We first define Np (z), the mixed neighborhood of z for Pt , and decompose the ESPC
in (6) into a set of necessary conditions that collectively are sufficient. Each partitioned
condition is then satisfied by finding the local ESP of a subproblem, and any violated global
constraints are resolved by using appropriate penalties.
Np (z), the mixed neighborhood of z for a partitioned problem, is:

N
N  
[
[

(t)
′  ′
′
Np (z) =
Np (z) =
/ z(t) ,
z  z (t) ∈ Nm (z(t)) and zi = zi ∀zi ∈

Definition 9.

t=1

(8)

t=1

where Nm (z(t)) is the mixed neighborhood of z(t).

Intuitively, Np (z) is separated into N neighborhoods, where the tth neighborhood perturbs only the variables in z(t) while leaving those variables in z\z(t) unchanged.
Without showing the details, we can consider Pt as a MINLP and apply Theorem 1 to
derive the ESPC of Pt . We then decompose the ESPC into N necessary conditions, one for
each subproblem, and an overall necessary condition on the global constraints across the
subproblems. We first define the penalty function for Subproblem t.
Definition 10. Let Φ(z, γ, η) = γ T |H(z)|+η T max(0, G(z)) be the sum of the transformed
p
global constraint functions weighted by their penalties, where γ = (γ1 , . . . , γp )T ∈ R and
q
η = (η1 , . . . , ηq )T ∈ R are the penalty vectors for the global constraints. Then the penalty
function for Pt in (7) and the corresponding penalty function in Subproblem t are defined
as follows:

N 
X
T (t)
T
(t)
Lm (z, α, β, γ, η) = J(z) +
α(t) |h (z(t))| + β(t) max(0, g (z(t)) +Φ(z, γ, η), (9)
t=1

Γm (z, α(t), β(t), γ, η) = J(z) + α(t)T |h(t) (z(t))| + β(t)T max(0, g(t) (z(t))) + Φ(z, γ, η), (10)
336

Temporal Planning using Subgoal Partitioning and Resolution

m

where α(t) = (α1 (t), . . . , αmt (t))T ∈ R t and β(t) = (β1 (t), . . . , βrt (t))T ∈ R
penalty vectors for the local constraints in Subproblem t.

rt

are the

Theorem 2. Partitioned necessary and sufficient ESPC on CLMm of Pt (Wah & Chen,
2006). Given Np (z), the ESPC in (6) can be rewritten into N + 1 necessary conditions that,
collectively, are sufficient:
Γm (z ∗ , α(t), β(t), γ ∗∗ , η ∗∗ ) ≤ Γm (z ∗ , α(t)∗∗ , β(t)∗∗ , γ ∗∗ , η ∗∗ ) ≤ Γm (z, α(t)∗∗ , β(t)∗∗ , γ ∗∗ , η ∗∗ ), (11)
Lm (z ∗ , α∗∗ , β ∗∗ , γ, η) ≤ Lm (z ∗ , α∗∗ , β ∗∗ , γ ∗∗ , η ∗∗ ),(12)

for any α(t)∗∗ > α(t)∗ ≥ 0, β(t)∗∗ > β(t)∗ ≥ 0, γ ∗∗ ≥ γ ∗ ≥ 0, and η ∗∗ ≥ η ∗ ≥ 0, and for all
m
r
p
q
(t)
z ∈ Np (z ∗ ), α(t) ∈ R t , β(t) ∈ R t , γ ∈ R , η ∈ R , and t = 1, . . . , N .
Theorem 2 shows that the original ESPC in Theorem 1 can be partitioned into N necessary conditions in (11) and an overall necessary condition in (12) on the global constraints
across the subproblems. The partitioned condition in Subproblem t can be satisfied by
finding the ESPs in that subproblem. Because finding an ESP is equivalent to solving a
MINLP, we can reformulate the search in Subproblem t as the solution of the following
optimization problem:


(t)
Pt
J(z) + γ T |H(z)| + η T max(0, G(z))
(13)
:
min
z(t)

subject to

h(t) (z(t)) = 0

and g(t) (z(t)) ≤ 0.
(t)

The weighted sum of global constraint functions in the objective of Pt is important because
it leads to points that minimize the violations of global constraints. When γ T and η T are
(t)
large enough, solving Pt will lead to points, if they exist, that satisfy the global constraints.
In short, finding solutions of Pt that satisfy (6) can be reduced to solving multiple
subproblems, where (13) can be solved by an existing solver with some modifications of the
objective function to be optimized, and to the reweighting of violated global constraints
defined by (12).
3.3 Formulation of Partitioned Planning Subproblems in PDDL2.2
For a PDDL2.2 planning problem solved in this paper, a solution plan is specified by the
start time and the end time of each action a ∈ O. Hence, its variable vector is z =
{s(a), e(a) where a ∈ O}; its objective function J(z) optimized depends on the makespan
(or the number of actions for propositional domains) of plan z; and its constraints are the
mutex constraints defined in Section 2.1:


h(ai , aj ) = mutex s(ai ), e(ai ), s(aj ), e(aj ) = 0,
∀ai , aj ∈ O.
(14)
Here, mutex is a binary procedure for checking whether ai and aj satisfy the mutex conditions defined in Section 2.1. It returns one if the conditions are satisfied and zero otherwise.
When the constraints are partitioned by their subgoals into N subproblems G1 , · · · , GN ,
variable z is partitioned into N subsets z(1), · · · , z(N ), where z(t) includes the start time
337

Chen, Wah, & Hsu



(1)

Pt

x
Lm(z, α, β, γ, η)γ,η to find γ ∗∗ and η ∗∗

 minz(1) J(z) + γ T |H(z)| + η T max(0, G(z))
:
subject to h(1)(z(1)) = 0 and g (1)(z(1)) ≤ 0



(N)
Pt

T
T
 minz(N) J(z) + γ |H(z)| + η max(0, G(z))
:
subject to h(N) (z(N )) = 0 and g (N) (z(N )) ≤ 0

a) Partitioned search to look for points that satisfy (11) and (12)
1. procedure partition and resolve(Pt )
2.
γ −→ 0; η −→ 0;
3.
repeat
// increase the penalties of violated global constraints until maximum bounds γ̄i and η̄i //
4.
for i = 1 to p do if (Hi (z) 6= 0 and γi < γ̄i ) then increase γi by δ end if end for;
5.
for j = 1 to q do if (Gj (z)  0 and ηj < η̄j ) then increase ηj by δ end if end for;
// inner loop for solving the N subproblems //
6.
for t = 1 to N do apply an existing solver to solve (13) end for;
7.
until ((γi > γ̄i for all Hi (z) 6= 0 and ηj > η̄j for all Gj (z)  0) or (a CLMm of Pt is found))
8. end procedure

b) Implementation for finding a CLMm of Pt that satisfies (11) and (12)
Figure 7: The partition-and-resolve procedure to look for a CLMm of Pt .

and the end time of those actions of Gt . The local constraints are those mutex constraints
that relate the actions within a subproblem, and the global constraints are those that relate
the actions across subproblems.
(t)
For Pt defined for Gt , the objective is to find a feasible plan z(t) that satisfies the
constraints for Gt , while minimizing an objective function biased by the violated global
constraints:


(t)
Pt
:

min
z(t)

subject to

J(z) +

N
X
k=1
k6=t

γt,k · mt,k

h(t) (ai , aj ) = 0

(15)

∀ai , aj ∈ z(t),

where J(z) is defined later in Section 5.3. Here, mt,k is the number of global constraints
between the actions in z(t) and those in z(k):
mt,k =

X

h(at , ak ).

(16)

at ∈z(t)
ak ∈z(k)
k6=t

To limit the number of penalties while characterizing the priorities among the subproblems,
we have assigned a single penalty γt,k for each pair of subproblems Gt and Gk , instead of a
penalty for each global constraint between Gt and Gk .
338

Subgoal-Level Planning

Global-Level Planning

Temporal Planning using Subgoal Partitioning and Resolution

Plan
Evaluation

Techniques
Studied

Penalty-Value
Update Strategy

GlobalConstraint
Resolution

Global Constraints on Subgoals

G1

P1,1

G2

Producible
Resources
GN

PN,1

P1,c1

PN,cN

Constraint
Partitioning
by Subgoals

Landmark
Analysis

Temporal
Engine
Modified Metric−FF

Derived−
predicates
engine

Temporal
engine

DerivedPredicates
Engine
Search−space
reduction

SearchSpace
Reduction

Figure 8: SGPlan4 : A planner implementing the partition-and-resolve procedure in Figure 7.

3.4 The Partition-and-Resolve Procedure
Figure 7 presents the partition-and-resolve procedure for finding points that satisfy the
conditions in Theorem 2. Using fixed γ and η specified in the outer loop, the inner loop
of Subproblem t in Figure 7b solves (13) by an existing solver, which results in an ESP
that satisfies (11). This is possible because (13) is a well-defined MINLP. After solving the
N subproblems, the penalties on the violated global constraints are increased in the outer
loop. The process is repeated until a CLMm to Pt has been found or when γ and η exceed
their maximum bounds.
The procedure in Figure 7 may generate fixed points of (9) that do not satisfy (11) and
(12). This happens because an ESP is a local minimum of (9) (but not the converse). One
way to escape from such fixed points is to allow periodic decreases of γ and η. The goal of
these decreases is to “lower” the barrier in the penalty function in order for local descents
in the inner loop to escape from an infeasible region. Note that γ and η should be decreased
gradually in order to help the search escape from such infeasible regions. Once γ and η
reach their minimum thresholds, they can be scaled up, and the search is repeated.
339

Chen, Wah, & Hsu

4. System Architecture of SGPlan4
Figure 8 shows the design of SGPlan4 that implements the partition-and-resolve procedure.
The procedure alternates between global-level planning and subgoal-level planning. In this
section, we describe those techniques implemented in the global level, while leaving the
discussion of techniques in the subgoal level to the next section.
4.1 The Partition-and-Resolve Process in SGPlan4
At the global level, SGPlan4 partitions a planning problem into N subproblems, G1 , · · · , GN ,
where Gt corresponds to the tth subgoal. It then orders the subproblems, evaluates each
using techniques in subgoal-level planning, identifies those violated global constraints, and
updates their penalties in order to bias the search in the next iteration towards resolving
them. In SGPlan4 , we have adopted an implementation in LPG1.2 (Gerevini & Serina,
2002) for detecting persistent mutexes.
The partition-and-resolve process can be understood as calculating subplans separately
and then merging them into a consistent plan. Its goals are to optimize multiple subplans
and to ensure their consistency after merging. Prior work on plan merging focuses on
merging redundant actions and on finding an optimal composed plan. In particular, Foulser,
Li, and Yang (1992) have developed algorithms for merging feasible classic plans into more
efficient ones. A complete evaluation on plan-merging algorithms for classical domains has
been conducted by Yang (1997). Tsamardinos, Pollack, and Horty (2000) have extended
the concept to domains with temporal constraints. Because plan merging is not a means
for making an infeasible plan feasible, it is different from our approach that aims to resolve
inconsistencies in terms of mutexes among subplans.
An alternative view about our resolution approach is the reuse and modification of
subplans into a consistent plan. Plan-reuse systems adapt existing plans into new initial states and goals. The approach is demonstrated in SPA (Hanks & Weld, 1995) and
PRIAR (Kambhampati & Hendler, 1992) that show improvements in efficiency in many
domains. The major difference between current plan-reuse approaches and our partitionand-resolve process is that we generate candidate subproblems based on the partitioning
of mutex constraints, whereas traditional methods reuse plans that are generated by other
means. Since the assumption of conservative plan modification in existing methods is not
always achievable, it may be necessary to replan if a feasible plan candidate cannot be
found. In some cases, it may be more expensive than planning from scratch. This is the
reason why complexity analysis and empirical study cannot prove plan-reuse approaches
to have consistent improvements over planing from scratch (Nebel & Koehler, 1995). In
contrast, our approach augments the search of each subproblem by explicitly penalizing
global inconsistencies and by forcing its solution towards resolving the global constraints.
Our partition-and-resolve approach is different from incremental planning (Koehler &
Hoffmann, 2000) that uses a goal agenda. In incremental planning, a planner maintains
a set of target facts, adds goal states incrementally into the target set, and extends the
solution by using the new target set. Because a goal state must always be satisfied once
it has been achieved, the ordering of goal states is important in order to avoid un-doing
a previously achieved goal state when planning the current goal state. If invalidations do
occur, then the planning task at that point is more complex than just the planning of one
340

Temporal Planning using Subgoal Partitioning and Resolution

goal state. In contrast, SGPlan4 tries to achieve only one subgoal at a time and allows
other subgoals to be invalidated in the process. Moreover, for each subgoal, we do not need
to start from the ending state of the previous subgoal as in incremental learning, and there
is no need to pre-order the subgoals in order to avoid invalidations. We show in Section 6
that the performance of SGPlan4 is not sensitive to the order of evaluating the subgoals.
4.2 Resolving Violated Global Constraints
In this section, we present two penalty-update strategies for resolving violated global constraints. These constraints are identified after finding a subplan for each subproblem independently.
SGPlan4 first initializes the penalties of all global constraints when it starts. In the first
iteration, SGPlan4 solves each subproblem individually, without considering their global
constraints. It then combines all the subplans into an integrated plan in order to determine the initial active global constraints across the subproblems. In subsequent iterations,
SGPlan4 finds a local feasible plan for each subproblem, while minimizing the global objective and the weighted sum of violated global constraints. At the end of each iteration,
SGPlan4 increases the penalty of a violated global constraint in proportion to its violation.
The process ends when all the constraints are satisfied.
We have designed two strategies for updating the penalty of global constraints. The
SGPlan4 that participated in IPC4 sets very large initial penalty values and updates them
by rate ξ, whereas SGPlan4.1 studied in this paper sets the initial penalty values to zero:
(
γ 0 (for SGPlan4 )
(0)
(ℓ)
(ℓ−1)
γt,k =
γt,k = γt,k + ξ · mt,k ,
ℓ = 1, 2, . . .
(17)
0
(for SGPlan4.1 ),
(ℓ)

Here, γt,k is the penalty for the global constraints between Gt and Gk in the ℓth iteration,
mt,k is as defined in (16), γ 0 is a large initial value, and ξ is a parameter for controlling the
rate of penalty updates. In our experiments, we set γ 0 = 100 and ξ = 0.1.
Figure 9 illustrates the planning process of SGPlan4 on the AIRPORT-TEMP-14 instance. Given the three subproblems in this instance, SGPlan4 first evaluates each subproblem once in the first iteration in order to determine the initial active global constraints. The
figure shows, respectively, the subplans and the active global constraints after evaluating
each of the three subproblems in the second iteration. The strategy is effective for reducing
the number of active global constraints quickly from 14 in the beginning to zero in just one
iteration.
The penalty-update strategy in SGPlan4 may lead to longer makespans because it uses
large initial penalty values in order to reduce the number of violated global constraints
quickly. Hence, the subplans found may have poor temporal concurrency. To address this
issue, we have implemented a new strategy for SGPlan4.1 in (17) that sets the initial penalty
values to zero.
Figure 10 illustrates the time-quality trade-offs of SGPlan4 and SGPlan4.1 when used to
solve nine representative instances of the IPC4, the Blocksworld, and the Depots domains.
Because the number of active global constraints changes after evaluating each subproblem,
we plot the progress on the remaining number of active global constraints with respect
to the total number of subproblems evaluated. The results show that both planners can
341

Chen, Wah, & Hsu

1
0
0
1 0
0
1 1
1
0
1
0
10
0
1
1
0
0
1
1
0
10
1
0
0
1
11
0
1
0
0
1
0
1
0
0
01
1
0 1
1
0
1
0
0
1
1
0
1
0
1
0

G1

1
0
1
0
1 0
0
1
1 0
1
0

G2

1
0
0
1

1
0
0
1

1
0
0
1

1
0
0
1

10
0
1
0
0
1
1
0
1
0
1
1
0
1
0

0
1
0
1
1
0
1
0
00
1
1

1
0
0
1

1
0
0
1

0
1
0
1
1
0
0
1

1
0
1
0
0 0
1
1

1
0
0
1

1
0
0
1

G3

1
0
0
1
1
0
1
0

1
0
0
1

a) At the start of Iteration 2
1
0
0
1 0
0
1 1
1
0
1
0
1
1
0
1
0
0
1 0
0
1
0
1 1
0
0
1
1
0
1
0
1
0
1
0
1
0
0
10
0
0 1
1
1
0
1
1
0
0 1
1
0
0
1
1
0
1
0

1
0
1
0

1
0
0
1

1
0
1
0

0
1
0
1
1
0
1
0
00
1
1

1
0
1
0

1
0
1
1 0
0
0
1
1
0
0
1

1
0
1
0

1
0
1
0

1
0
0
01
1
0
1
1
0
1
0
0
1
0
1

1
0
0
1

1
0
1
0

1
0
0
1
1
0
1
0

1
0
0
1

1
0
0
1

1
0
0
1

1
0
1
0

1
0
1
0

0
1
0
1
1
0
0 0
1
1
0
1

1
0
0
1 0
0
1 1
0
1
0
1
0
1
1
0
0
1 0
0
11
0
1 1
0
0
1
11
0
1
0
0
1
0
1
0
0
01
1
0 1
1
0
1
0
0
1
1
0
1
0
1
0

1
0
0
1

1
0
1
0
0
1
1
0
1
0
0
1

1
0
1
0
1 0
0
1
1 0
1
0
10
0
1
0
0
1
1
0
1
0
1
1
0
1
0

0
1
0
1
1
0
0
01
1
0
1

1
0
0
1

1
0
1
0

0
1
0
1
1
0
0
1

1
0
1
0
0 0
1
1

G2

0
1
0
1
1
0
0 0
1
1
0
1
1
0
0
1

G3

1
0
0
1

1
0
0
1
1
0
1
0

1
0
1
0

1
0
1
0

G1

b) After solving Subproblem G1
0
1
1
1 0
0
1 0
0
1
0
1
0
1
0
1
1
0
0
1
1
0
0
1
1
0
0
00
1
0
0
1
11
1 1
0
0
10
0
0 1
1
1
0
1
1
0
0 1
1
0
0
1

G1

G2

0
1
0
1
1
0
0 0
1
1
0
1

1
0
1
0

1
0
1
0

1
0
0
1

1
0
0
1

G3

1
0
1
0

c) After solving Subproblem G2

0
1
0
1
1
0
1
0
00
1
1

1
0
1
0

1
0
1
1 0
0
0
1
1
0
0
1

1
0
1
0

1
0
1
0

1
0
0
01
1
0
1
1
0
1
0
0
1
0
1

1
0
0
1

1
0
0
1

1
0
1
0

1
0
0
1
0
1
1
0
1
0
0
1

1
0
1
0

G1

G2

0
1
0
1
1
0
0 0
1
1
0
1
1
0
0
1

G3

1
0
1
0

d) After solving Subproblem G3

Figure 9: The planning process of the IPC4 version of SGPlan4 in the second iteration in
solving the AIRPORT-TEMP-14 instance. Each box corresponds to an action
in a subplan, whereas each arrow corresponds to an active global constraint. By
placing more emphasis on violated global constraints, the number of violated
constraints is quickly reduced at the expense of a longer makespan.

resolve the remaining number of active global constraints in almost a linear fashion, and
that SGPlan4 is generally faster for resolving the active global constraints but generates
plans of worse quality. In our detailed experimental results in Section 7, we show that
SGPlan4.1 generally leads to plans of better quality.
Both planners, however, have difficulty when solving the PIPESWORLD-NOTANKAGETEMP-DEADLINE-10 instance (Figure 10c). For this domain, SGPlan4 cannot solve any
instances, whereas SGPlan4.1 can solve eight instances (1, 2, 5, 6, 8, 14, 22, and 30). Although the fraction of initial active global constraints out of all constraints is only 3.3%
on average (Table 1), both planners may get stuck at some infeasible solutions and cannot make progress afterward. The reason is that the basic planner in both SGPlan4 and
SGPlan4.1 does not have enough backtracking to generate new candidate subplans for each
subproblem. Hence, the basic planner keeps generating the same subplan at some point,
regardless of how the violated constraints are penalized.
4.3 Handling Producible Resources
In some planning problems, there may be facts that can be made true and numerical
resources that can be produced anytime when needed. For example, in the Settlers domain,
342

15
10
5
0

60

SGPlang (Q=61.73)
SGPlang2 (Q=52.00)

50
40
30
20
10
0

8 10 12 14 16 18 20 22 24 26 28

8

total # of subproblems evaluated

100
50
0
30

40

50

60

70

100
90
80
70
60
50
40
30
20
10
0

80

10
8
6
4
2
0
15

20

25

30

total # of subproblems evaluated

g) UMTS-TEMP-50

20

22

5

10

15

20

25

30

35

40

total # of subproblems evaluated

35

45
40
35
30
25
20
15
10
5
0

SGPlang (Q=544.00)
SGPlang2 (Q=541.00)

15 20 25 30 35 40 45 50 55 60

total # of subproblems evaluated

total # of subproblems evaluated

e) SATELLITE-TIME-20
# of active global constraints

# of active global constraints

SGPlang (Q=2230.40)
SGPlang2 (Q=818.00)

10

18

40 60 80 100 120 140 160 180 200

d) PROMELA-OPTICALTELEGRAPH-10
12

16

SGPlang (Q=704.26)
SGPlang2 (Q=645.01)

total # of subproblems evaluated

14

14

# of active global constraints

# of active global constraints

# of active global constraints

150

20

12

SGPlang (Q=N/A)
SGPlang2 (Q=N/A)

total # of subproblems evaluated

SGPlang (Q=198.98)
SGPlang2 (Q=197.34)

200

10

50
45
40
35
30
25
20
15
10
5
0

b) PIPESWORLD-NOTANKAGE- c) PIPESWORLD-NOTANKAGENONTEMP-30
TEMP-DEADLINE-10

a) AIRPORT-TEMP-30
250

# of active global constraints

SGPlang (Q=708.10)
SGPlang2 (Q=705.03)

20

70

# of active global constraints

25

# of active global constraints

# of active global constraints

Temporal Planning using Subgoal Partitioning and Resolution

SGPlang (Q=56.00)
SGPlang2 (Q=42.00)

60
50
40
30
20
10
0
15

20

25

30

35

total # of subproblems evaluated

h) BLOCKSWORLD-17-0

40

f) SETTLERS-20
200
180
160
140
120
100
80
60
40
20
0

SGPlang (Q=107.00)
SGPlang2 (Q=103.00)

10

15

20

25

30

35

40

total # of subproblems evaluated

i) DEPOTS-TIME-20

Figure 10: Resolution of active global constraints in nine benchmark instances by the original penalty-update strategy in SGPlan4 and the new penalty-update strategy
in SGPlan4.1 . The x axis includes the number of subproblems evaluated, each
corresponding to a subgoal, in the first iteration in order to determine the initial
active global constraints.

coal can always be produced in a mine. We define these producible logical and numerical
resources as follows.
a) A fact is producible if it is an add effect of either an action without preconditions or
an action whose preconditions are always producible.
b) A numerical resource is producible if it is increased by either an action without
preconditions or an action whose preconditions are always producible.
The planning tasks will be significantly easier if producible facts and resources can
be detected in the preprocessing phase and be made available during planning. By first
identifying all those facts and resources, SGPlan4 derives a relaxed initial state by setting
all producible facts to be true and all producible numerical resources to be large enough.
Every time a producible fact is turned false, it is made true again. After finding a feasible
plan from the relaxed initial state, SGPlan4 removes the unused numerical resources in the
343

Chen, Wah, & Hsu

initial state and plans again. The process is repeated until there are no redundant initial
resources. At that point, SGPlan4 inserts the necessary actions at the beginning of the plan
to generate the minimum initial producible resources needed.
For example, suppose timber is detected to be a producible resource as one can always
fell some trees to get more timber. SGPlan4 will initially set a large number, say 1000 units,
of timber available. After solving the problem, suppose there are 900 units left unused, it
reduces the initial timber to 100 units and plans again. This process is repeated until
either there is no unused timber at the final state or the problem becomes unsolvable after
reducing the initial resource.
Note that the approach may incur some redundant actions for producing unused resources, as the optimal amount of resources needed cannot be predicted ahead of time.

5. Subgoal-Level Planning
At the subgoal level, SGPlan4 applies landmark analysis to further partition a subproblem,
performs path finding and optimization, carries out subspace-reduction analysis to prune
irrelevant facts and actions in the subproblem, and calls a modified Metric-FF planner to
solve the subproblem.
5.1 Subgoal-Level Decomposition Techniques
a) Landmark analysis. First proposed by Porteous, Sebastia, and Hoffmann (Porteous,
Sebastia, & Hoffmann, 2001), landmark analysis allows a large planning problem to be
decomposed into a series of simpler subproblems. Given the initial state, it aims to find
some intermediate facts that must be true in any feasible plan for reaching the goal state.
For example, assume that object O is to be delivered from A to D, and that the only path
from A to D is A → B → C → D. Then AT (O, B) and AT (O, C) are both landmark facts,
since any feasible plan must make them true before reaching goal state AT (O, D).
Because a planning problem is first partitioned by its subgoals into subproblems, we
only apply landmark analysis on each subproblem in order to find the intermediate facts for
reaching the corresponding subgoal. Landmark analysis is important in SGPlan4 because
it allows each subproblem to be further decomposed into simpler subproblems that can be
solved easily.
In each subproblem, we find landmarks by a relaxed planning approach. Given a planning subproblem T = (O, F, I, G), we first construct a relaxed planning graph from the
initial state I by ignoring the delete effects of actions. We force each f ∈ F in each level of
the graph to be false (even if it were made true by some actions). As a result, all the actions
preconditioned by f will be pruned. If there exists a goal fact in G that cannot be reached
when f is false, then f is a landmark fact and must be reached in any plan for the relaxed
problem. After finding the partial order of the landmarks, SGPlan4 builds a sequential
list of subproblems joined by the landmarks found and applies the basic planner to solve
each subproblem in order. Note that because landmark analysis is expensive, SGPlan4 only
detects landmarks once at the beginning and not in every iteration.
The landmarks found in the relaxed planning graph are necessary because any solution
plan of the original problem is also a solution plan of the relaxed problem. Hence, any
feasible plan for the original problem must reach each landmark found by the relaxed ap344

Temporal Planning using Subgoal Partitioning and Resolution

Initial State
ON(B10 A2)

ON(B0 A1)

LAST(B10 S12)

ON(B4 A2)

ON(B6 A2)

ON(B12 A3)

LAST(B4 S12)
FIRST(B0 S12)

LAST(B12 S13)

ON(B9 A2)

ON(B8 A3)

LAST(B9 S12)

LAST(B8 S13)

LAST(B6 S12)

ON(B10 A1)

ON(B5 A2)

LAST(B5 S12)

ON(B12 A1)

ON(B9 A1)

ON(B8 A1)

FIRST(B9 S13)

FIRST(B10 S13)

ON(B10 A3)

FIRST(B12 S12)

ON(B0 A2)

ON(B4 A1)

ON(B6 A1)

ON(B12 A2)

FIRST(B8 S12)

ON(B9 A3)

ON(B8 A2)

ON(B5 A1)

Goal State

Figure 11: Landmarks and their partial orders for the PIPESWORLD-NOTANKAGENONTEMP-10 instance.
proach at least once. However, the landmarks found are not sufficient because we test goal
reachability by a relaxed approach, and there may exist some undetected landmarks even
when every fact has been tested.
Figure 11 shows all the landmarks found in the IPC4 PIPESWORLD-NOTANKAGENONTEMP-10 instance. When considering the first goal fact ON (B10, A3), LAST (B10, S12)
is not only its landmark but also the landmarks for ON (B10, A1) and F IRST (B10, S13).
This means that LAST (B10, S12) must be ordered before ON (B10, A1) and F IRST (B10, S13).
In this way, we can decompose the subproblem for ON (B10, A3) into 4 smaller tasks that
must be carried out in sequence, namely, LAST (B10, S12), ON (B10, A1), F IRST (B10, S13),
and ON (B10, A3).
b) Landmarks identified by path finding. Landmark analysis may sometimes produce
very few landmark facts for decomposing a subproblem. For example, most of the gates
along a path in an Airport instance will not be identified as landmark facts (that is,
must-visit points) because there are usually multiple paths for the given source and destination. Consider the airport topology in Figure 12a in which the goal is to move A1
from SG1 to SG8. Because there are two alternative paths and none of the facts in
AT (A1, SG2), AT (A1, SG3), · · · , AT (A1, SG7) has to be true before reaching SG8, we cannot detect any landmark facts.
To identify more landmark facts for decomposing a subproblem, we have developed
in SGPlan4 a new path-finding technique. The technique is based on the concept of fact
groups that has been used by some existing planners, such as MIPS (Edelkamp, 2002) and
Downward (Helmert & Richter, 2004). A fact group includes a group of mutually exclusive
facts in which only one can be true at any time, and typically involves the multiple possible
states of an object. For the example Airport instance discussed above, a fact group includes
the different locations that A1 can be at:


Fg =
AT (A1, SG1), AT (A1, SG2), · · · , AT (A1, SG7), AT (A1, SG8) .
(18)
345

Chen, Wah, & Hsu

AT (A1, SG4)

AT (A1, SG2)

AT (A1, SG3)

AT (A1, SG3)

AT (A1, SG8)

AT (A1, SG1)

AT (A1, SG4)

AT (A1, SG2)

AT (A1, SG8)

AT (A1, SG1)

AT (A1, SG5) AT (A1, SG6)

AT (A1, SG7)

AT (A1, SG5) AT (A1, SG6)

a) Transition graph of Fg

AT (A1, SG7)

b) Path finding

Figure 12: Illustration of the transition graph of Fact Group Fg and the path finding algorithm. Shaded nodes in (b) are new landmark facts detected by path finding.

In SGPlan4 , we have adopted an approach in MIPS based on an analysis of static mutex
groups for finding fact groups of subgoal facts.
We apply path finding on Subproblem Gt when none or a few landmarks have been
detected by landmark analysis. Assuming the subgoal to be reached is gt , we first find the
fact group it belongs to. In the previous example, the subgoal is gt = AT (A1, G8), and the
fact group is Fg in (18).
For each fact group with two or more facts, we determine their transition relations by
constructing a directed graph. Given two facts f1 and f2 in the fact group, we add an edge
from f1 to f2 if there exists an action a such that f1 is a precondition of a and f2 is an
add effect of a (which implies that f1 is a delete effect of a since f1 and f2 are mutually
exclusive). Figure 12a illustrates the transition graph for the airport example discussed
above.
Last, to find a path, we look for all the facts that are immediate predecessors of gt in
the graph. We arbitrarily select one as a must-visit landmark and disable the others. We
then perform a landmark analysis from the initial fact to gt . This analysis will return more
landmark facts.
In our example airport instance, AT (A1, SG4) and AT (A1, SG7) are the two immediate
predecessor facts of Subgoal gt = AT (A1, SG8). If we disable AT (A1, SG7) in the landmark
analysis, then there will only be one path from AT (A1, SG1) to gt , and AT (A1, SG2),
AT (A1, SG3), and AT (A1, SG4) will be detected as landmark facts. Figure 12b illustrates
this process.
c) Path optimization is used to find better landmark facts for problems with timed
initial literals or numerical effects. It is invoked when there is a deadline or when there
is a dynamically changing numerical resource that appears in the preconditions of actions.
These conditions are satisfied in the IPC4 Satellite instances where the technique is found
to be most useful.
The technique works by choosing a path that optimizes the time duration or the usage
of a numerical resource when there are multiple paths of different quality, and by setting
those nodes along the optimal path as landmark facts. Given a subproblem trying to reach
Subgoal gt , we construct a transition graph for the fact group of gt and apply Dijkstra’s
algorithm to find the shortest path from the initial fact to gt . The weight on each edge is
either a time duration for problems with time windows, or the usage of a numerical resource
346

Temporal Planning using Subgoal Partitioning and Resolution

0

G1

a3

a1
a2

G2

Time

a5
a4

a6
S6

G3
S4
S2
S0

S5

S3

S1

Figure 13: Generating multiple starting states for Subproblem G3 , given the initial state
S0 and Si , i = 1, . . . , 6, the state when action ai is finished. SGPlan4 calls the
basic planner to generate a local subplan from each starting state and picks the
first one that improves the objective in (15).

for problems with numerical preconditions. We then set the facts along the optimal path as
landmark facts and force the planner to choose this path over others. The landmarks along
the optimal path allows us to further decompose the problem into subproblems.
There are two limitations in our current implementation of path optimization. First,
since there needs to be a path from the initial fact to the goal fact in the transition graph,
we cannot apply the technique if the initial and the goals facts are disconnected. Second,
we have studied the case of only one dynamically changing numerical resource that appears
in the preconditions of actions and have not studied the optimization of multiple numerical
resources.
5.2 Subgoal-Level Planning Techniques
a) Evaluating multiple subplans for a subproblem. In finding a local feasible subplan for a
subproblem that improves the objective in (15), SGPlan4 generates a number of subplans
from multiple starting states. Since no active global constraints exist between two identical
subplans, we generate multiple starting states for a given subproblem by applying all possible prefix actions from each of the other subproblems. For example, given the six actions
planned in G1 and G2 in Figure 13, there are six possible starting states when developing a
subplan for G3 . For each starting state, SGPlan4 calls the basic planner to generate a local
feasible subplan and accepts the subplan if it improves the objective in (15). If no better
subplans can be found from all possible starting states, SGPlan4 leaves the local subplan
unchanged and moves on to the next subproblem.
b) Search-space reduction. Before solving a partitioned subproblem, we can often eliminate in its search space many irrelevant actions that are related to only facts and subgoals
in other subproblems. Such reductions are not useful in planning problems that are not
partitioned because all their actions are generally relevant.
347

Chen, Wah, & Hsu

As an example, consider a transportation domain whose goal is to move packages,
drivers, and trucks to various locations from an initial configuration. Suppose in a problem instance, the goal set is {AT (D1, S1), AT (T 1, S1), AT (P 1, S0), AT (P 2, S0)} for two
packages P 1 and P 2, one driver D1, one truck T 1, and two locations S1 and S2. Without partitioning, all the actions are relevant for resolving the subgoals. In contrast, after
partitioning, the actions for moving P 2 around are irrelevant in the subproblem of resolving AT (P 1, S0) and can be eliminated. Similarly, those actions for moving P 1 or P 2 are
irrelevant in the subproblem of resolving AT (D1, S1).
We have designed a backward relevance analysis to eliminate some irrelevant actions
in a subproblem before solving it by the basic planner. In the analysis, we maintain an
open list of unsupported facts, a close list of relevant facts, and a relevance list of relevant
actions. In the beginning, the open list contains only the subgoal facts of the subproblem,
and the relevance list is empty. In each iteration, for each fact in the open list, we find all
the actions that support the fact and not already in the relevance list. We then add these
actions to the relevance list and add the action preconditions that are not in the close list
to the open list. We move a fact from the open list to the close list when it is processed.
The analysis ends when the open list is empty. At that point, the relevance list will contain
all possible relevant actions. This analysis takes polynomial time.
Note that our relevance analysis is not complete when it stops, since the relevance list
may still contain some irrelevant actions. For example, we can further reduce the relevance
list by a forward analysis and by finding all applicable actions from the initial states before
the backward analysis. However, further analysis may not be cost effective for reducing the
overhead in planning.
Our reduction method belongs to a family of heuristics proposed by Nebel, Dimopoulos
and Koehler (1997). Since we select all possible supporting actions when processing a fact,
our approach is indeed the one that selects the union over all elements in the possibility
set according to their classification. While we conservatively reduce the irrelevant information, there are a number of tighter reductions that can approximately minimize the use of
initial facts (Nebel et al., 1997). However, these aggressive heuristics may not be solution
preserving or solution-length preserving.
5.3 Modified Metric-FF Basic Planner
After decomposing a subproblem associated with a subgoal into smaller subproblems bounded
by landmark facts, SGPlan4 solves each subproblem identified (or the original subproblem
in case no landmark facts have been identified) by a modified Metric-FF planner. Our modifications consist of two components: the adaptation of the original Metric-FF (Hoffmann,
2003) in order to entertain the new features in PDDL2.2, and the support of planning when
the mutex constraints are partitioned. In fact, a lot of our efforts for embedding Metric-FF
in SGPlan4 were spent on the first component.
The original Metric-FF can only solve problems in PDDL2.1 with propositional actions
but does not support any temporal features. We have extended the parser of Metric-FF to
support the full PDDL2.2 syntax and the definition of actions from atomic logical to durational temporal. The planning process has also been extended from sequential propositional
planning to parallel temporal planning. Specifically, we have extended sequential actions of
348

Temporal Planning using Subgoal Partitioning and Resolution

Fixed
Subproblems

G1
.....

Components of Objective Function
in (15)
Estimated makespan Te

Gt−1
Gt+1

PN

.....

k=1
k6=t

GN

γt,k m
e t,k

Weighted sum of global mutex
constraint violations

Gt
Current Plan

Heuristic value Π(z(t)) of original Metric-FF

Relaxed Plan

Figure 14: Temporal planning in a partitioned search context incorporates in the objective
function in (15) a makespan Te estimated by an enhanced PERT algorithm and
the heuristic value of the Metric-FF planner.
atomic length in the original Metric-FF to actions with predefined durations that can be
scheduled in parallel.
We have extended Metric-FF to support a new feature called derived predicates introduced in PDDL2.2. Derived predicates define axioms whose facts are derived by a set of
precondition facts. For example, in a domain with boxes, if A is above B and B is above
C, then a derived predicate of A above C can be generated. Derived predicates can only
appear in preconditions and goals but not in effects. In our modified Metric-FF, we have
implemented a technique proposed in MIPS 2.2 (Edelkamp, 2003) for handling derived
predicates. We encode any derived predicate d as a special action a, where the precondition
facts of a are the preconditions facts of d, the add effects of a are the derived facts of d,
and the delete effect of a is empty. During planning, all the “derived-predicate actions”
are included in the relaxed plan. However, the heuristic function computed in Metric-FF
only counts the number of real actions in the relaxed plan but not the number of “derivedpredicate actions,” and only real actions are considered as candidates for forward expansion
in any state. In any state, we expand the set of true facts by applying all applicable derived
predicates iteratively until we reach a fixed-point state where no more true facts can be
added.
The second component of the modifications in Metric-FF involves the support of a
partitioned search context when solving a subproblem, say Gt . In this case, Metric-FF needs
to incorporate in its objective an aggregate state of all schedulable actions in G1 , · · · , GN
in the planning of actions in Gt . Referring to Figure 14, the aggregate state is represented
by an estimated makespan Te of all the actions that is evaluated by an enhanced PERT
algorithm.
PERT was originally developed to generate a parallel plan by scheduling an action
as early as possible until it is blocked by a dependency or a mutex relation. Previous
PERT algorithms detect a propositional conflict between two actions by checking if one
action adds/deletes another’s precondition, and detect a numerical conflict when two actions
modify the same numerical variable. In the latter case, two actions would not be allowed
349

Chen, Wah, & Hsu

to overlap in their execution when they consume the same resource, even when the total
amount required does not exceed the amount available. Obviously, the resulting schedule
will be suboptimal.
We have developed an enhanced PERT algorithm that considers resource constraints
in its schedule. The algorithm assigns an action as early as possible as long as there
are no propositional conflicts or no violations on numerical/resource constraints. Besides
maintaining operator dependency as in the original PERT, we also keep track of changes
on numerical variables. Our algorithm is greedy because it schedules all applicable actions
as early as possible without backtracking.
In general, PERT can schedule a valid sequential plan into a parallel plan without mutex
conflicts. However, our enhanced PERT may generate a parallel plan with mutex conflicts.
The reason is that each subproblem is solved from the initial state and not sequentially
from the state of the previous subproblem. Hence, when actions from multiple subplans are
combined, one action may delete the precondition of another and causes a mutex conflict. As
an example, consider the sequential plans of two subproblems G1 and G2 that are scheduled
from the initial state in the Blocksworld domain: a) MOVE (A, B) and MOVE (B, C);
and b) MOVE (D, E) and MOVE (E, C), where MOVE (x, y) places x on top of y, with a
precondition CLEAR (y) (y is clear with nothing on it). In this example, PERT cannot
generate a parallel plan with no mutex conflict between MOVE (E, C) and MOVE (B, C),
regardless of how these two actions are scheduled. The conflict occurs because each action
deletes the CLEAR (C) precondition of the other.
The modified Metric-FF planner carries out a search that heuristically looks for plans
to minimize (15) rewritten as follows:



PN




N
e t,k
minz(t) Π(z(t)) + k=1 γt,k m
X
k6=t


min J(z) +
γt,j m
e t,j =
PN

z(t)
e

j=1
e t,k
minz(t) Π(z(t)) + τ T + k=1 γt,k m
j6=t

k6=t

(for SGPlan4 )
(19)
(for SGPlan4.1 ),

where Π(z(t)) is the heuristic value of the original Metric-FF when solving Gt ; m
e t,k is the
estimated number of active mutexes between the plan for Gk and a relaxed plan for Gt
obtained by ignoring the delete effects of unscheduled actions; Te is the makespan estimated
by the enhanced PERT algorithm after composing the relaxed plan of Gt and the plans of
the other subproblems; γt,k is a penalty value dynamically updated in global-level planning;
and τ is a constant fixed at 0.0001. Although the search does not guarantee optimality, it
can always resolve global mutual-exclusion constraints between, say z(t) and z(k), because
it can move one subplan backward in order to avoid overlapping with another conflicting
subplan when the penalty γt,k is large enough.
In our implementation of (19) in the modified Metric-FF planner, we have set τ in
SGPlan4.1 to be very small so that the penalty term due to the makespan will not dominate
the other terms. In fact, since τ Te is much smaller than one in all the test problems, its main
purpose is to break ties among those states with very close heuristic values. On the other
hand, our implementation of (19) in SGPlan4 in IPC4 does not include Te in its objective
function. As a result, it focuses on eliminating mutual-exclusion conflicts and tends to
generate plans of a longer makespan.
350

Temporal Planning using Subgoal Partitioning and Resolution

1. procedure SGPlan(problem file)
2.
parse problem file and instantiate all facts and actions;
3.
detect and encode timed initial literals (TIL);
4.
detect and encode derived predicates;
5.
detect TIL wrappers and translate them into regular TILs;
6.
detect producible resources;
7.
if (there are producible resources) then set them to the maximum possible end if;
8.
repeat
9.
for each subgoal fact in the goal list do
10.
call search-space reduction to eliminate irrelevant actions;
11.
call basic planner (modified Metric-FF) to reach the subgoal;
12.
if (the basic planner times out) then
13.
perform landmark analysis to generate a list of subproblems;
14.
for each subproblem in the list do
15.
call basic planner to solve the subproblem;
16.
if (solution is not found in the time limit) then
17.
if (problem has TIL or numerical fluents) then perform path optimization
18.
else perform path finding to further decompose the subproblem end if;
19.
call basic planner to solve each decomposed subproblem;
20.
end if
21.
end for
22.
end if
23.
end for
24.
evaluate plan z and update penalty values of violated global constraints;
25.
until feasible solution plan has been found or time limit has been exceeded;
26.
if ((new solution found) && (there are unused producible resources)) then
27.
reduce the initial producible resources and goto step 8;
28.
end if
29. end procedure

Figure 15: The high-level pseudo code common for both SGPlan4 and SGPlan4.1 .

In general, embedding a basic planner in our partition-and-resolve framework requires
some modifications to the objective function of the basic planner in order to implement
(15). Hence, it cannot be done without the source code of the basic planner.
5.4 Putting All the Pieces Together
Figure 15 shows the high-level code that is common for both SGPlan4 and SGPlan4.1 . The
preprocessing phase parses the problem file and instantiates all the facts and actions (Line
2), detects and encodes timed initial literals (TIL) and derived predicates, if any (Lines 3
and 4), translates the problem into a regular TIL problem if the problem is a compiled TIL
problem (Line 5), and detects producible resources and sets them to always available (Lines
6 and 7).
The major loop is between Lines 8 and 28. For each subgoal, SGPlan4 uses search-space
reduction to eliminate irrelevant actions (Line 10) and solves it using the basic planner
(Line 11). If the basic planner fails to find a feasible plan within a time limit (3000 node
351

Chen, Wah, & Hsu

Table 2: Summary of useful techniques for each domain variant. A check mark indicates
that a technique is found to be useful for a domain variant or a class of domain
variants.

Domain Variant
AIRPORT-*
AIRPORT-TEMP-TIMEWINDOWS-CO
PIPESWORLD-*
PROMELA-*
PROMELA-*-DP
PSR-SMALL
PSR-MIDDLE
PSR-MIDDLE-CO
PSR-LARGE
SATELLITE-STRIPS
SATELLITE-TIME
SATELLITE-NUMERIC
SATELLITE-COMPLEX
SATELLITE-TIME-TIMEWINDOWS
SATELLITE-TIME-TIMEWINDOWS-CO
SETTLERS
UMTS-TEMP
UMTS-TEMP-TIMEWINDOWS
UMTS-TEMP-TIMEWINDOWS-CO
UMTS-FLAW-TEMP
UMTS-FLAW-TEMP-TIMEWINDOWS
UMTS-FLAW-TEMP-TIMEWINDOWS-CO

SG
√
√
√
√
√
√
√
√
√
√
√
√
√
√
√
√
√
√
√
√
√
√

LM
√
√
√

PF
√
√
√

PO

TIL

TIL-w

DP

PR

SR

√

√
√
√

√

√

√
√

√
√

√

√
√

√

√
√
√

√

√
√

Keys SG: subgoal partitioning
LM: landmark analysis
PF:
path finding
PO: path optimization
TIL: timed initial literals handling TIL-w: TIL wrapper detection
DP: derived predicates handling PR: producible resources
SR:
search-space reduction

expansions in Metric-FF), SGPlan4 aborts the run of Metric-FF and tries to decompose the
problem further. It first applies landmark analysis to decompose and solve the subproblem
(Lines 13-15). If it is unsuccessful in solving the subproblem, it tries path optimization for
numerical and TIL problems (Line 17) or path finding (Line 18) to further partition the
subproblem. After all the subgoals have been evaluated, it composes the solution, evaluates
the global constraints, and updates the penalty values (Line 24). Finally, if a new solution
has been found and there are unused producible resources, it reduces the initial producible
resources (Lines 26-28) and repeats the major loop again.

6. Sensitivity Analysis of Techniques in SGPlan4
In this section we describe our ablation study of the various techniques in SGPlan4 in order
to test their effectiveness. Table 2 lists the techniques that are most useful for each IPC4
domain variant. We defer the discussion on the performance improvement of SGPlan4.1
over SGPlan4 to Section 7.
352

Temporal Planning using Subgoal Partitioning and Resolution

For all the Airport variants, the useful techniques include subgoal partitioning, landmark analysis, and path finding. In addition, TIL wrapper detection is needed for the
TIMEWINDOWS-CO variant. As an ablation study, we applied SGPlan4 with subgoal
partitioning alone. In this case, SGPlan4 can solve 107 out of the 200 (53.5%) instances
and cannot solve those numbered higher than 28 (namely, P29, P30, etc.). The reason
is that those subproblems without landmark analysis and path finding are so large that
Metric-FF has difficulty in solving them. In contrast, SGPlan4 with landmark analysis and
path finding can solve 159 (79.5%) instances.
For all the Pipesworld variants, the useful techniques include subgoal partitioning, landmark analysis, path finding, and search-space reduction. Although search-space reduction
can slightly reduce the run time by 5.3% on average, landmark analysis and path finding
has more significant effects on performance. SGPlan4 without landmark analysis and path
finding can only solve 102 out of the 200 (51%) instances, whereas SGPlan4 with landmark
analysis and path finding can solve 186 instances (93%). Landmark analysis and path finding also leads to 8% average improvement on run time for those instances that both versions
can solve.
For the Promela domain, only subgoal partitioning is found to be useful, besides applying
derived-predicate handling for the corresponding variants.
For all the PSR variants except PSR-SMALL, search-space reduction is particularly
useful in addition to subgoal partitioning. For these three variants, SGPlan4 with searchspace reduction can solve, respectively, 50, 14, and 11 instances; whereas SGPlan4 without
search-space reduction can solve, respectively, 47, 8, and 6 instances. In addition, the average run-time improvements due to search-space reduction are, respectively, 34.1%, 46.9%,
62.5%. For the PSR-SMALL variant, search-space reduction has no significant effects on
both run time and solution quality. Last, derived-predicate handling is important for PSRMIDDLE, which is encoded using derived predicates.
In the Satellite domain, only subgoal partitioning is found to be useful for solving the
TIME, STRIPS, and COMPLEX variants. For the NUMERIC, TIME-TIMEWINDOWS,
and TIME-TIMEWINDOWS-CO variants, landmark analysis and path optimization are
also useful. For these three variants, SGPlan4 can solve, respectively, 25, 25, and, 21
instances, whereas SGPlan4 without landmark analysis and path optimization can solve,
respectively, 16, 16, and 13 instances.
For the Settlers domain, subgoal partitioning as well as techniques for handling producible resources are important for solving all but one of the instances. (The eighth instance
is infeasible.) Without detecting producible resources, SGPlan4 can only solve nine out of
the 20 instances.
For the UMTS domain, only subgoal partitioning is found to be useful, besides applying
TIL handling and TIL wrapper detection for the corresponding variants. Landmark analysis
does not help in this domain and can detect none or very few landmark facts in each of the
300 instances. Also, search-space reduction can only prune a few facts and has little effects
on performance.
We have also studied the effects of subgoal ordering in SGPlan4.1 on eighteen representative variants from all IPC4 domains as well as the Depots domain (Figure 16). For each
instance, we test SGPlan4.1 using five random subgoal orders and normalize its run time
(resp. quality) with respect to the corresponding measure when SGPlan4.1 is run using
353

Chen, Wah, & Hsu

AIRPORT: NONTEMP, TEMP
PIPESWORLD: NOTANKAGE-NONTEMP, NOTANKAGE-TEMP
PROMELA: OPT-TELEGRAPH, OPT-TELGRAPH-DP, PHIL, PHIL-DP
PSR: SMALL, MIDDLE
SATELLITE: STRIPS, TIME
SETTLERS: SETTLERS
UMTS: TEMP, FLAW-TEMP
DEPOTS: STRIPS, SIMPLETIME, TIME

Normalized Quality

10

1

0.1
0.01

0.1

1

10

100

Normalized Run Time
Figure 16: Run time-quality distribution of SGPlan4.1 run using different random subgoal
orders on selected IPC4 and the Depots domain variants. The results are normalized with respect to the run time and quality of SGPlan4.1 run using the default
subgoal order. (Performance values larger than one are better for SGPlan4.1 .)

the original order in the problem definition. Here we use makespan as our quality measure
for temporal domains and the number of actions for propositional domains (even when an
objective is specified in the problem definition).
The results show that the performance of SGPlan4.1 is quite insensitive to subgoal ordering for the Airport, Promela, Settlers, and UMTS domains. However, there are significant
variations in run time and quality for the Pipesworld and PSR domains, although there is
no definitive trend that a random subgoal order is better. For the Depots domain, there
exist some smaller variations in both run time and quality. A common feature among the
Pipesworld, PSR, and Depots domains is that they all have intensive subgoal interactions,
which make them more sensitive to the order in which subgoals are evaluated. For example,
354

Temporal Planning using Subgoal Partitioning and Resolution

in the PSR-MIDDLE variant, the number of subgoals is large, and different subgoals are
highly related by derived predicates. Last, we note that using the original subgoal order
leads to better run time and quality in the Satellite domain. The reason is that the original
order can avoid unnecessary subgoal invalidations when finding local feasible subplans, since
the starting states are generated by applying prefix subplans of other subgoals.
Because there is no clear advantage of using random subgoal orders over the original
subgoal order, SGPlan4 and SGPlan4.1 use the original subgoal order in their implementations.

7. Experimental Results
In this section, we experimentally compare the performance of SGPlan4 , SGPlan4.1 (their
differences are in (17) and (19)) and other planners in solving the IPC3 and IPC4 benchmark
suites as well as the Blocksworld domain from IPC2. Each suite contains multiple domains,
with several variants in each. Those variants in IPC4 address the different features of
PDDL2.2, which include versions on STRIPS, STRIPS with DP (derived predicates), temporal, temporal with TIL (deadlines), numeric, and complex (temporal and numeric). A
complete description of each variant and its problem files can be found at the Web site of
each of the competitions2
All runs were carried out an AMD Athlon MP2800 PC with Redhat Linux AS3 and
2-Gbyte main memory unless otherwise noted. Following the rules of IPC4, all random
planners set a fixed random seed, once and for all, throughout their experiments. Moreover,
all planners must be fully automated, run with the same parameter setting for all the
instances attempted, and execute under a CPU time limit of 30 minutes and a main memory
limit of 1 Gbytes.
Table 3 summarizes the performance of SGPlan4 , SGPlan4.1 , Downward (Helmert &
Richter, 2004), LPG-TD-SPEED-1.0 with a seed of 2004, and YAHSP-1.1.3 We use makespan
as the quality metric for temporal domains and the number of actions for propositional domains. Since the code for Downward is unavailable, we report its IPC4 results after adjusting
its run times by a factor governed by the difference in speeds between the computer used
in the IPC4 competition and the computer used for SGPlan4.1 . Likewise, we were unable
to evaluate Downward on the IPC2 and IPC3 benchmarks.
Table 3 does not include results on those domain variants that a target planner cannot
handle. For example, LPG-TD-SPEED cannot solve all the compiled domains and does
not support some grammatical features in PSR-LARGE and the two FLUENTS variants in
the PROMELA domain; and YAHSP cannot handle derived predicates. In contrast, both
SGPlan4 and SGPlan4.1 were designed to solve all the variants except the ROVERS-TIME
variant with dynamic durations. Note that since the Satellite and the Settlers domains
exist in both the IPC3 and IPC4 benchmarks, the table does not include those results on
2. The URL for the competitions are http://ls5-www.cs.uni-dortmund.de/~edelkamp/ipc-4/ for
IPC4, http://planning.cis.strath.ac.uk/competition/ for IPC3, and http://www.cs.toronto.
edu/aips2000/ for IPC2.
3. The object code of LPG-TD was downloaded from http://zeus.ing.unibs.it/lpg/register-lpg-td.
html, while the object code of YAHSP-1.1 was downloaded from http://www.cril.univ-artois.fr/
~vidal/Yahsp/yahsp.linux.x86.gz. The object code of Downward was unavailable for testing at the
time when this paper was revised.

355

Chen, Wah, & Hsu

the IPC3 Settlers domain and some variants of the IPC3 Satellite domain that have been
reported for IPC4.
Table 3:
Performance comparison between SGPlan4.1 and other planners.
In the
table comparing SGPlan4.1 and SGPlan4 , the four missing variants (PIPESWORLDNOTANKAGE-TEMP-DEADLINES-CO, PROMELA-OPTICAL-TELEGRAPH-FLUENTS-DP,
PROMELA-PHILOSOPHERS-FLUENTS-DP, and ROVERS-TIME) cannot be solved by both
planners. In the table comparing SGPlan4.1 and LPG-TD-SPEED, all the missing variants except ROVERS-TIME cannot be solved by LPG-TD-SPEED. For the ROVERS-TIME variant,
only LPG-TD-SPEED can solve all the instances but the other planners cannot. In the tables
comparing SGPlan4.1 , Downward, and YAHSP, all the missing variants cannot be solved by the
target planners compared.
Domain Variant

Instances Solvable by Both (Fb )
Fi
Fq
Ft
Fw Fwt Fwq

Fn

All Instances
Fg
Fu
Fb

Comparison between SGPlan4.1 and SGPlan4
AIRPORT-NONTEMP
0.78 0.00
AIRPORT-TEMP
0.60 0.28
AIRPORT-TEMP-TIMEWINDOWS
0.48 0.14
AIRPORT-TEMP-TIMEWINDOWS-CO
0.28 0.00
PIPESWORLD-NOTANKAGE-NONTEMP
0.16 0.10
PIPESWORLD-NOTANKAGE-TEMP
0.72 0.28
PIPESWORLD-TANKAGE-NONTEMP
0.12 0.00
PIPESWORLD-TANKAGE-TEMP
0.52 0.14
PIPESWORLD-NOTANKAGE-TEMP-DEAD
0.00 0.00
PROMELA-OPTICAL-TELEGRAPH
0.19 0.00
PROMELA-OPTICAL-TELEGRAPH-DP
0.40 0.00
PROMELA-OPTICAL-TELEGRAPH-FLUENTS 0.06 0.00
PROMELA-PHILOSOPHERS
0.58 0.00
PROMELA-PHILOSOPHERS-DP
0.94 0.00
PROMELA-PHILOSOPHERS-FLUENTS
0.02 0.00
PSR-SMALL
0.24 0.00
PSR-MIDDLE
0.98 0.02
PSR-MIDDLE-CO
0.26 0.00
PSR-LARGE
0.16 0.00
SATELLITE-STRIPS
0.53 0.06
SATELLITE-TIME
0.39 0.44
SATELLITE-TIME-TIMEWINDOWS
0.58 0.00
SATELLITE-TIME-TIMEWINDOWS-CO
0.53 0.03
SATELLITE-NUMERIC
0.44 0.00
SATELLITE-COMPLEX
0.36 0.22
SATELLITE-COMPLEX-TIMEWINDOWS
0.50 0.14
SATELLITE-COMPLEX-TIMEWINDOWS-CO
0.56 0.03
SETTLERS
0.10 0.00
UMTS-TEMP
0.96 0.04
UMTS-TEMP-TIMEWINDOWS
0.88 0.12
UMTS-TEMP-TIMEWINDOWS-CO
0.76 0.00
UMTS-FLAW-TEMP
0.02 0.88
UMTS-FLAW-TEMP-TIMEWINDOWS
0.00 0.44
UMTS-FLAW-TEMP-TIMEWINDOWS-CO
0.54 0.00
DEPOTS-STRIPS
0.27 0.27
Continued . . .

356

0.00
0.00
0.16
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.05

0.00
0.00
0.06
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.08
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00

0.10
0.00
0.00
0.16
0.74
0.00
0.54
0.00
0.00
0.10
0.00
0.13
0.02
0.06
0.19
0.70
0.00
0.02
0.06
0.25
0.00
0.08
0.11
0.11
0.08
0.03
0.08
0.85
0.00
0.00
0.24
0.10
0.10
0.00
0.41

0.00
0.00
0.02
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.03
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00

0.00
0.00
0.00
0.02
0.00
0.00
0.00
0.00
0.27
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.46
0.46
0.00

0.00
0.00
0.02
0.04
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.79
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.03
0.06
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00

0.12
0.12
0.12
0.50
0.00
0.00
0.34
0.34
0.73
0.71
0.60
0.81
0.40
0.00
0.00
0.06
0.00
0.72
0.78
0.17
0.17
0.33
0.33
0.42
0.17
0.33
0.33
0.05
0.00
0.00
0.00
0.00
0.00
0.00
0.00

0.88
0.88
0.86
0.44
1.00
1.00
0.66
0.66
0.00
0.29
0.40
0.19
0.60
1.00
0.21
0.94
1.00
0.28
0.22
0.83
0.83
0.67
0.67
0.55
0.77
0.67
0.67
0.95
1.00
1.00
1.00
1.00
0.54
0.54
1.00

Temporal Planning using Subgoal Partitioning and Resolution

Table 3: (continued)
Domain Variant
DEPOTS-SIMPLETIME
DEPOTS-TIME
DEPOTS-NUMERIC
DRIVERLOG-STRIPS
DRIVERLOG-SIMPLETIME
DRIVERLOG-TIME
DRIVERLOG-NUMERIC
DRIVERLOG-HARDNUMERIC
FREECELL-STRIPS
ROVERS-STRIPS
ROVERS-SIMPLETIME
ROVERS-NUMERIC
SATELLITE-SIMPLETIME
SATELLITE-HARDNUMERIC
ZENOTRAVEL-STRIPS
ZENOTRAVEL-SIMPLETIME
ZENOTRAVEL-TIME
ZENOTRAVEL-NUMERIC
BLOCKSWORLD

Instances Solvable by Both (Fb )
Fi
Fq
Ft
Fw Fwt Fwq
0.23
0.27
0.18
0.70
0.60
0.45
0.60
0.55
0.05
0.70
0.55
0.45
0.75
0.50
0.85
0.80
0.45
0.65
0.57

0.68
0.59
0.27
0.10
0.20
0.35
0.15
0.20
0.10
0.00
0.45
0.05
0.00
0.00
0.00
0.20
0.55
0.00
0.29

0.05
0.05
0.05
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.06

0.00
0.05
0.00
0.00
0.00
0.00
0.00
0.00
0.05
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.03

0.00
0.00
0.41
0.00
0.00
0.00
0.05
0.05
0.70
0.30
0.00
0.10
0.25
0.20
0.15
0.00
0.00
0.35
0.06

Fn

All Instances
Fg
Fu
Fb

0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00

0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00

0.05
0.05
0.09
0.10
0.10
0.05
0.05
0.05
0.10
0.00
0.00
0.25
0.00
0.00
0.00
0.00
0.00
0.00
0.00

0.00
0.00
0.00
0.10
0.10
0.15
0.15
0.15
0.00
0.00
0.00
0.15
0.00
0.30
0.00
0.00
0.00
0.00
0.00

0.95
0.95
0.91
0.80
0.80
0.80
0.80
0.80
0.90
1.00
1.00
0.60
1.00
0.70
1.00
1.00
1.00
1.00
1.00

0.00
0.00
0.00
0.04
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.03
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00

0.00
0.02
0.00
0.16
0.18
0.20
0.22
0.03
0.00
0.15
0.42
0.00
0.00
0.00
0.00
0.00
0.19
0.06
0.00
0.19
0.30
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00

0.02
0.02
0.04
0.00
0.00
0.08
0.06
0.53
0.00
0.00
0.00
0.00
0.04
0.00
0.17
0.06
0.06
0.08
0.06
0.06
0.00
0.00
0.00
0.00
0.00
0.00
0.05
0.05
0.05
0.20

0.10
0.10
0.10
0.00
0.00
0.26
0.28
0.20
0.71
0.60
0.40
0.00
0.02
0.00
0.00
0.11
0.28
0.36
0.17
0.28
0.05
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.05
0.00

0.88
0.86
0.86
0.84
0.82
0.46
0.44
0.24
0.29
0.25
0.18
1.00
0.94
1.00
0.83
0.83
0.47
0.50
0.77
0.53
0.65
1.00
1.00
1.00
1.00
1.00
0.95
0.95
0.90
0.80

Comparison between SGPlan4.1 and LPG-TD-SPEED
AIRPORT-NONTEMP
AIRPORT-TEMP
AIRPORT-TEMP-TIMEWINDOWS
PIPESWORLD-NOTANKAGE-NONTEMP
PIPESWORLD-NOTANKAGE-TEMP
PIPESWORLD-TANKAGE-NONTEMP
PIPESWORLD-TANKAGE-TEMP
PIPESWORLD-NOTANKAGE-TEMP-DEAD
PROMELA-OPTICAL-TELEGRAPH
PROMELA-OPTICAL-TELEGRAPH-DP
PROMELA-PHILOSOPHERS
PROMELA-PHILOSOPHERS-DP
PSR-SMALL
PSR-MIDDLE
SATELLITE-STRIPS
SATELLITE-TIME
SATELLITE-TIME-TIMEWINDOWS
SATELLITE-NUMERIC
SATELLITE-COMPLEX
SATELLITE-COMPLEX-TIMEWINDOWS
SETTLERS
UMTS-TEMP
UMTS-TEMP-TIMEWINDOWS
UMTS-FLAW-TEMP
UMTS-FLAW-TEMP-TIMEWINDOWS
DEPOTS-STRIPS
DEPOTS-SIMPLETIME
DEPOTS-TIME
DEPOTS-NUMERIC
DRIVERLOG-STRIPS

0.16 0.14
0.14 0.20
0.08 0.22
0.30 0.06
0.44 0.00
0.22 0.12
0.24 0.06
0.07 0.03
0.29 0.00
0.25 0.00
0.19 0.00
1.00 0.00
0.40 0.54
0.14 0.64
0.42 0.36
0.19 0.33
0.47 0.00
0.11 0.00
0.36 0.17
0.44 0.00
0.10 0.00
0.82 0.00
1.00 0.00
0.00 0.48
0.00 0.00
0.32 0.36
0.09 0.09
0.09 0.09
0.32 0.27
0.65 0.15
Continued . . .

357

0.00
0.02
0.00
0.26
0.36
0.10
0.12
0.03
0.00
0.00
0.00
0.00
0.00
0.00
0.03
0.17
0.00
0.33
0.17
0.03
0.55
0.18
0.00
0.00
0.00
0.05
0.27
0.09
0.05
0.00

0.10
0.28
0.30
0.16
0.02
0.00
0.02
0.07
0.00
0.00
0.00
0.00
0.00
0.06
0.00
0.08
0.00
0.06
0.08
0.00
0.00
0.00
0.00
0.12
0.00
0.18
0.50
0.68
0.27
0.00

0.48
0.22
0.26
0.02
0.00
0.02
0.00
0.03
0.00
0.00
0.00
0.00
0.00
0.16
0.03
0.03
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.40
1.00
0.09
0.00
0.00
0.00
0.00

Chen, Wah, & Hsu

Table 3: (continued)
Instances Solvable by Both (Fb )
Fi
Fq
Ft
Fw Fwt Fwq

Domain Variant
DRIVERLOG-SIMPLETIME
DRIVERLOG-TIME
DRIVERLOG-NUMERIC
DRIVERLOG-HARDNUMERIC
FREECELL-STRIPS
ROVERS-STRIPS
ROVERS-SIMPLETIME
ROVERS-NUMERIC
SATELLITE-SIMPLETIME
SATELLITE-HARDNUMERIC
ZENOTRAVEL-STRIPS
ZENOTRAVEL-SIMPLETIME
ZENOTRAVEL-TIME
ZENOTRAVEL-NUMERIC
BLOCKSWORLD

0.65
0.65
0.60
0.45
0.50
0.70
0.75
0.50
0.00
0.15
0.80
0.60
0.65
1.00
0.46

0.10
0.10
0.20
0.25
0.00
0.25
0.20
0.00
0.00
0.00
0.20
0.15
0.00
0.00
0.46

0.05
0.05
0.00
0.10
0.35
0.05
0.05
0.00
0.70
0.55
0.00
0.15
0.30
0.00
0.03

0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.10
0.25
0.00
0.00
0.05
0.05
0.00
0.03

0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00

Fn

All Instances
Fg
Fu
Fb

0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.05
0.00
0.00
0.05
0.00
0.00
0.03

0.00
0.00
0.00
0.00
0.05
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00

0.20
0.20
0.15
0.20
0.10
0.00
0.00
0.40
0.00
0.00
0.00
0.00
0.00
0.00
0.00

0.00
0.00
0.05
0.00
0.00
0.00
0.00
0.00
0.00
0.30
0.00
0.00
0.00
0.00
0.00

0.80
0.80
0.80
0.80
0.85
1.00
1.00
0.60
1.00
0.70
1.00
1.00
1.00
1.00
1.00

0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00

0.00
0.00
0.32
0.29
0.04
0.60
0.00
0.00
0.00
0.00
0.00

0.12
0.02
0.06
0.00
0.38
0.00
0.00
0.06
0.00
0.40
0.17

0.00
0.00
0.28
0.71
0.23
0.40
0.00
0.00
0.00
0.38
0.00

0.88
0.98
0.34
0.00
0.35
0.00
1.00
0.94
1.00
0.22
0.83

0.00
0.06
0.00
0.00
0.00
0.00
0.03
0.00
0.00
0.00
0.00
0.05
0.06

0.18
0.00
0.04
0.02
0.00
0.00
0.00
0.14
0.00
0.00
0.40
0.00
0.00

0.02
0.00
0.24
0.00
0.00
0.02
0.17
0.00
0.20
0.05
0.00
0.00
0.00

0.10
0.00
0.10
0.71
0.40
0.04
0.00
0.00
0.00
0.05
0.00
0.00
0.00

0.70
1.00
0.62
0.27
0.60
0.94
0.83
0.86
0.80
0.90
0.60
1.00
1.00

Comparison between SGPlan4.1 and Downward
AIRPORT-NONTEMP
PIPESWORLD-NOTANKAGE-NONTEMP
PIPESWORLD-TANKAGE-NONTEMP
PROMELA-OPTICAL-TELEGRAPH
PROMELA-OPTICAL-TELEGRAPH-DP
PROMELA-PHILOSOPHERS
PROMELA-PHILOSOPHERS-DP
PSR-SMALL
PSR-MIDDLE
PSR-LARGE
SATELLITE-STRIPS

0.52
0.14
0.16
0.00
0.35
0.00
1.00
0.42
0.32
0.12
0.69

0.00
0.02
0.00
0.00
0.00
0.00
0.00
0.04
0.38
0.04
0.08

0.02
0.20
0.16
0.00
0.00
0.00
0.00
0.00
0.02
0.00
0.03

0.16
0.02
0.00
0.00
0.00
0.00
0.00
0.00
0.06
0.04
0.03

0.18
0.00
0.02
0.00
0.00
0.00
0.00
0.48
0.22
0.02
0.00

Comparison between SGPlan4.1 and YAHSP
AIRPORT-NONTEMP
PIPESWORLD-NOTANKAGE-NONTEMP
PIPESWORLD-TANKAGE-NONTEMP
PROMELA-OPTICAL-TELEGRAPH
PROMELA-PHILOSOPHERS
PSR-SMALL
SATELLITE-STRIPS
DEPOTS-STRIPS
DRIVERLOG-STRIPS
FREECELL-STRIPS
ROVERS-STRIPS
ZENOTRAVEL-STRIPS
BLOCKSWORLD

0.24
0.14
0.22
0.27
0.13
0.36
0.25
0.50
0.50
0.10
0.35
0.30
0.46

358

0.22
0.52
0.32
0.00
0.00
0.02
0.53
0.32
0.30
0.80
0.25
0.65
0.31

0.02
0.00
0.02
0.00
0.00
0.00
0.00
0.05
0.00
0.00
0.00
0.00
0.09

0.10
0.28
0.02
0.00
0.00
0.02
0.00
0.00
0.00
0.00
0.00
0.00
0.06

0.12
0.00
0.04
0.00
0.48
0.54
0.03
0.00
0.00
0.00
0.00
0.00
0.03

Temporal Planning using Subgoal Partitioning and Resolution

Keys: (tn , qn )
(tg , qg )
Fb
Fi
Fq
Ft
Fw
Fwt
Fwq
Fn
Fg
Fu

(run time, quality) of SGPlan4.1
(run time, quality) of the target planner compared
Fraction solved by both SGPlan4.1 and the target planner
(Fb = Fi + Fq + Ft + Fw + Fwt + Fwq = 1 − Fn − Fg − Fu )
Fraction that tn ≤ tg and qn ≤ qg (SGPlan4.1 has better or the same run time and quality)
Fraction that tn > tg and qn < qg (SGPlan4.1 has worse run time but better quality)
Fraction that tn < tg and qn > qg (SGPlan4.1 has worse quality but better run time)
Fraction that tn > tg and qn > qg (SGPlan4.1 has worse run time and worse quality)
Fraction that tn > tg and qn = qg (SGPlan4.1 has worse run time but the same quality)
Fraction that tn = tg and qn > qg (SGPlan4.1 has worse quality but the same run time)
Fraction solved by SGPlan4.1 but not by the target planner
Fraction solved by the target planner but not by SGPlan4.1
Fraction unsolved by both SGPlan4.1 and the target planner

Figures 17-20 further plot the time-quality trade-offs when the run time (resp. quality) of
the target planner is normalized with respect to the corresponding measure of SGPlan4.1 for
all instances solvable by both planners. In each graph, we also list six percentages computed
by normalizing Fi , Ft , Fq , Fw , Fwt , and Fwq with respect to Fb (defined in Table 3) for all
the domains evaluated.
In the Airport domain, SGPlan4.1 improves over or has the same performance as SGPlan4
in terms of run time and quality for a majority (69.9%) of the instances (Figure 17a). In
the NONTEMP variant, the solution files (not shown) show that SGPlan4.1 cannot solve
six (Fg + Fu = 0.12 in Table 3) of the seven largest instances (number 44 to 50); whereas
Downward, the leading planner for this variant, can solve all 50 instances. SGPlan4.1 has
difficulty with these instances because the partitioned subproblems are too large to be evaluated by the embedded Metric-FF planner. This is also the reason for SGPlan4.1 to be
worse than Downward and LPG in terms of run time on the larger instances. An obvious
solution is to employ a more efficient basic planner when it becomes available. In fact,
this is one of the strengths of our partition-and-resolve approach. Another solution is to
partition the subproblems further and to reduce their complexity to an extent that they can
be handled by our modified Metric-FF planner. The design of such partitioning methods is
still open at this time.
In the Pipesworld domain, SGPlan4.1 has significant improvements over SGPlan4 in
terms of makespan on the NOTANKAGE-TEMP and TANKAGE-TEMP variants (Figure 17b). These improvements are due to the minimization of the estimated makespan
(Te) in (19). However, no improvements were found on the NOTANKAGE-NONTEMP and
TANKAGE-NONTEMP variants because (19) does not have a term that corresponds to the
number of actions for the non-temporal variants. With respect to other planners, SGPlan4.1
can solve more instances in the NOTANKAGE-NONTEMP, NOTANKAGE-TEMP, and
TANKAGE-TEMP variants (Fn − Fg ≥ 0 for all the corresponding rows in Table 3), and
has consistently the shortest solution time in the NOTANKAGE-TEMP and TANKAGETEMP variants. For the NOTANKAGE-NONTEMP and TANKAGE-NONTEMP variants, YAHSP, however, can solve the most number of instances and has the shortest solution time in most cases, although it tends to produce longer plans. Last, as is discussed
in Section 4.2, SGPlan4.1 is not competitive in the PIPESWORLD-NOTANKAGE-TEMPDEADLINE variant because it can only solve eight of the 30 instances.
359

Chen, Wah, & Hsu

4

69.9%

8.5%

2.0%

5.2%

0.7%

0.25
0.25

1

1

38.6%

0.0%

0.25
0.01

4

Normalized quality

Normalized quality

81.4%

0.0%
18.6%

0.0%

0.001

0.0%

0.01

0.0%

0.1

1

1

SMALL
MIDDLE
LARGE
MIDDLE-CO

0.8%

67.2%

0.0%

0.0%

32.0%

0.0%

0.25
0.25

10

1

Normalized run time

c) PROMELA

d) PSR

Normalized quality

Normalized quality

4

16.2%

68.6%

13.2%
1.5%

STRIPS
TIME-TIMEWINDOW-CO
COMPLEX
COMPLEX-TIMEWINDOWS
TIME-TIMEWINDOWS
NUMERIC
TIME
COMPLEX-TIMEWINDOWS-CO

0.1
0.01

0.0%

0.5%

0.1

1

1

SETTLERS

10.5%

0.0%

0.0%

0.0%

0.25
0.1

10

1

10

Normalized run time

e) SATELLITE

f) SETTLERS
10

29.1%

Normalized quality

4

Normalized quality

0.0%

89.5%

Normalized run time

1

4

Normalized run time

10

1

10

b) PIPESWORLD
4

OPTICAL-TELEGRAPH-DP
OPTICAL-TELEGRAPH
PHILOSOPHERS
OPTICAL-TELEGRAPH-FLUENTS
PHILOSOPHERS-FLUENTS
PHILOSOPHERS-DP

0.25
1e-04

0.0%

1

Normalized run time

a) AIRPORT

1

0.0%

0.1

Normalized run time

4

45.8%

15.7%

Normalized quality

Normalized quality

13.7%

1

4
NOTANKAGE-NONTEMP
NOTANKAGE-TEMP
TANKAGE-TEMP
TANKAGE-NONTEMP

TEMP
NONTEMP
TEMP-TIMEWINDOWS-CO
TEMP-TIMEWINDOWS

62.2%

8.7%
0.0%

0.0%

TEMP
FLAW-TEMP-TIMEWINDOWS-CO
TEMP-TIMEWINDOWS-CO
TEMP-TIMEWINDOWS
FLAW-TEMP-TIMEWINDOWS
FLAW-TEMP

0.0%

0.25
0.1

1

1

34.5%

1.7%

5.0%

16.8%

DEPOTS-STRIPS
DEPOTS-SIMPLETIME
DEPOTS-TIME
DEPOTS-NUMERIC
BLOCKSWORLD

0.1
0.001

10

Normalized run time

42.0%

0.01

0.1

0.0%

1

10

100

1000

10000

Normalized run time

g) UMTS

h) DEPOTS & BLOCKSWORLD

Figure 17: Run time-quality of SGPlan4 on each instance normalized with respect to the
corresponding run time-quality of SGPlan4.1 on the same instance for all instances solvable by both planners. (Performance values larger than one are
better for SGPlan4.1 .)
360

Temporal Planning using Subgoal Partitioning and Resolution

TEMP
NONTEMP
TEMP-TIMEWINDOWS

21.5%

1

10

14.6%

Normalized quality

Normalized quality

4

36.9%

26.2%

0.8%

NOTANKAGE-NONTEMP
NOTANKAGE-TEMP
TANKAGE-TEMP
TANKAGE-NONTEMP
NOTANKAGE-TEMP-DEADLINES

46.9%

9.4%

1

1.6%
7.8%

0.25
0.01

0.0%

0.1

1

10

100

0.01

1.6%

0.1

1

Normalized run time

100.0%

0.0%

0.0%

0.0%

0.0%

1

1000

SMALL
MIDDLE

10

Normalized quality

Normalized quality

OPTICAL-TELEGRAPH-DP
OPTICAL-TELEGRAPH
PHILOSOPHERS
PHILOSOPHERS-DP

0.25
0.1

100

b) PIPESWORLD

0.0%

1

10

Normalized run time

a) AIRPORT
4

32.8%

10

100

1000

1

60.8%

27.8%

3.1%

0.0%

8.2%

1e-04

0.001

0.01

Normalized run time

0.0%

0.1

1

10

100

Normalized run time

c) PROMELA

d) PSR

4

4

SETTLERS

51.4%

1

Normalized quality

Normalized quality

22.1%

1.4%
18.6%
STRIPS
COMPLEX
COMPLEX-TIMEWINDOWS
TIME-TIMEWINDOWS
NUMERIC
TIME

5.7%

0.25
0.1

0.7%

1

10

100

1000

1

15.4%

0.0%

84.6%

0.0%

0.25
0.01

10000

0.0%

45.5%

Normalized quality

Normalized quality

100

1000

f) SETTLERS
28.6%

12.0%

1

35.0%
4.5%

3.0%

0.0%

0.1

10

10

TEMP
TEMP-TIMEWINDOWS
FLAW-TEMP-TIMEWINDOWS
FLAW-TEMP

0.25
0.01

1

Normalized run time

e) SATELLITE
4

0.0%

0.1

Normalized run time

1

10

100

Normalized run time

1

28.6%

1.7%
31.1%

9.2%

DEPOTS-STRIPS
DEPOTS-SIMPLETIME
DEPOTS-TIME
DEPOTS-NUMERIC
BLOCKSWORLD

0.1
0.001

0.01

0.1

0.8%

1

10

100

Normalized run time

g) UMTS

h) DEPOTS & BLOCKSWORLD

Figure 18: Run time-quality of LPG-TD-SPEED on each instance normalized with respect
to the corresponding run time-quality of SGPlan4.1 on the same instance for all
instances solvable by both planners. (Performance values larger than one are
better for SGPlan4.1 ).
361

Chen, Wah, & Hsu

0.0%

1

4

NONTEMP

59.1%

Normalized quality

Normalized quality

4

20.5%

18.2%

NOTANKAGE-NONTEMP
TANKAGE-NONTEMP

1.8%

1

1.8%

2.3%
0.0%

0.25
0.1

26.3%

1.8%

68.4%
0.0%

0.25

1

10

100

1

Normalized run time

a) AIRPORT
OPTICAL-TELEGRAPH-DP
PHILOSOPHERS-DP

0.0%

1

100.0%

0.0%

0.25
0.1

0.0%

0.0%

0.0%

1

10

100

1

SMALL
MIDDLE
LARGE

21.3%

39.8%

4.6%

0.9%

33.3%

0.25
1e-04

0.001

Normalized run time

Normalized quality

1

0.01

0.1

0.0%

1

10

100

Normalized run time

c) PROMELA
4

100

b) PIPESWORLD
4

Normalized quality

Normalized quality

4

10

Normalized run time

d) PSR

STRIPS

10.0%

83.3%

3.3%

3.3%

0.0%

0.25
0.1

0.0%

1

10

100

Normalized run time

e) SATELLITE

Figure 19: Run time-quality of Downward on each instance normalized with respect to
the corresponding run time-quality of SGPlan4.1 on the same instance for all
instances solvable by both planners. (Performance values larger than one are
better for SGPlan4.1 .)

In the Promela domain, SGPlan4.1 has no improvements over SGPlan4 in terms of quality
but improves in terms of run time on instances that both can solve for four of the six variants
(worse in the OPTICAL-TELEGRAPH-FLUENTS and PHILOSOPHERS-FLUENTS vari362

Temporal Planning using Subgoal Partitioning and Resolution

4

NONTEMP

NOTANKAGE-NONTEMP
TANKAGE-NONTEMP

31.4%

1

34.3%

Normalized quality

Normalized quality

10

17.1%

14.3%

2.9%

0.0%

0.25
0.01

0.1

1

10

100

1

51.9%

22.2%

18.5%

1.2%

2.5%

0.001

0.01

0.1

Normalized run time

OPTICAL-TELEGRAPH
PHILOSOPHERS

45.2%

Normalized quality

Normalized quality

1

54.8%

0.0%

0.0%

0.0%

0.25
0.1

1

10

1

38.3%

2.1%

0.0%

57.4%

0.25
0.001

100

2.1%

0.01

10

d) PSR
10

63.3%

30.0%

Normalized quality

Normalized quality

1

Normalized run time

STRIPS

3.3%

0.25
0.01

0.0%

0.1

c) PROMELA

1

1000

SMALL

Normalized run time
4

100

b) PIPESWORLD
4

0.0%

10

Normalized run time

a) AIRPORT
4

3.7%

1

0.0%

0.1

0.0%

3.3%

1

10

100

Normalized run time

1

33.3%

50.0%

3.7%

7.4%

1.9%

DEPOTS-STRIPS
BLOCKSWORLD
0.1
0.001
0.01

0.1

3.7%

1

10

100

1000

Normalized run time

e) SATELLITE

f) DEPOTS & BLOCKSWORLD

Figure 20: Run time-quality of YAHSP on each instance normalized with respect to the corresponding run time-quality of SGPlan4.1 on the same instance for all instances
solvable by both planners. (Performance values larger than one are better for
SGPlan4.1 .)

ants). SGPlan4.1 can solve the most number of instances in the OPTICAL-TELEGRAPHFLUENTS, PHILOSOPHERS, PHILOSOPHERS-DP, and PHILOSOPHERS-FLUENTS
363

Chen, Wah, & Hsu

variants when compared to LPG-TD-SPEED, Downward, and YAHSP. Further, it is the
fastest planner in three of the variants but is slightly slower than YAHSP in the PHILOSOPHERS variant (Figures 18c, 19c, and 20c). In the OPTICAL-TELEGRAPH and OPTICALTELEGRAPH-DP variants, the organizer of IPC4 provided two versions, one written in
pure STRIPS and another in ADL. However, there are only 14 (resp., 19) instances in
STRIPS and 48 (resp., 48) instances in ADL for the OPTICAL-TELEGRAPH (resp.,
OPTICAL-TELEGRAPH-DP) variant. There are more instances available in ADL because ADL is space-efficient in its problem representation, whereas instances in STRIPS
require large files. (For example, the file size of OPTICAL-TELEGRAPH-14 is 38 Kbytes
in ADL and 8.3 Mbytes in STRIPS.) Since SGPlan4.1 and SGPlan4 cannot handle ADL at
this time, they only solved those instances in pure STRIPS in these two variants. They were
able to solve all the instances available in STRIPS and were the fastest in all these instances.
However, Downward can handle instances in ADL and was able to solve more instances in
these two variants. We plan to extend SGPlan4.1 to directly support ADL in the future.
Note that both SGPlan4.1 and SGPlan4 always find plans of the same or better quality
for the instances solved in the OPTICAL-TELEGRAPH, OPTICAL-TELEGRAPH-DP,
PHILOSOPHERS, and PHILOSOPHERS-DP variants when compared to the other three
planners (Edelkamp & Hoffmann, 2004).
SGPlan4.1 is the only planner that can solve some instances of all four variants of the
PSR domain. Since PSR is a pure propositional domain, SGPlan4.1 is unable to improve the
solution quality over SGPlan4 . Nevertheless, the quality of SGPlan4.1 is consistently better
than all the other three planners (Fi +Fq +Fwt > Ft +Fw +Fwq for all the corresponding rows
in Table 3). In the SMALL variant, SGPlan4.1 and LPG have comparable run times and
cannot solve the few largest instances. Like the AIRPORT domain, SGPlan4.1 has difficulty
with the few largest instances because its basic planner cannot handle the partitioned
subproblems. In the MIDDLE variant, SGPlan4.1 , LPG, and Downward can solve all 50
instances. The situation in the MIDDLE-CO and LARGE variants are similar to that in the
OPTICAL-TELEGRAPH and the OPTICAL-TELEGRAPH-DP variants of the Promela
domain. In these variants, Downward can handle directly the ADL format, but SGPlan4.1
must expand the ADL syntax to pure STRIPS and exhausted its memory when evaluating
the larger instances. We plan to address this issue in the future.
In the Satellite domain, SGPlan4.1 has significant improvements in quality over SGPlan4 .
In fact, SGPlan4.1 generates solutions of better quality than all the other planners for most
instances and can solve the most number of instances in seven variants. In the eighth
variant (TIME), it was not able to solve the few largest instances because its memory
usage exceeded 1 Gbytes. In all the variants except STRIPS, SGPlan4.1 is faster than the
other three planners. In the STRIPS variant, YAHSP is the fastest because it can generate
multiple actions instead of a single action in each search step. However, it finds slightly
longer plans when compared to those of SGPlan4.1 .
In the Settlers domain, SGPlan4.1 does not improve the solution quality over SGPlan4
because, as discussed earlier, (19) does not have a term that corresponds to the number of
actions for non-temporal variants. SGPlan4.1 can solve all the instances except the eighth
instance, which we learned from the IPC4 organizers that it is an infeasible instance. It
is also the fastest among all the planners, but generates longer plans than those of LPGTD-SPEED. This is due to its iterative scheme for reducing producible resources. Because
364

Temporal Planning using Subgoal Partitioning and Resolution

Table 4: Summary on number of instances solved by the five planners compared (‘?’ means
that it is not clear whether the domain can be solved because the object code was
not available for testing, and ‘−’ means that the planner does not support the
language features in the benchmark.)
Domain
SGPlan4.1 SGPlan4 LPG-TD-SPEED Downward YAHSP
Airport
154
156
134
50
36
Pipesworld
174
166
158
60
93
Promela
129
167
83
83
42
PSR
122
122
99
131
48
IPC4
Satellite
204
207
157
36
36
Settlers
19
19
13
−
−
UMTS
300
254
200
−
−
Total
1102
1091
844
360
219
Depots
84
88
87
?
19
DriverLog
80
87
99
?
20
FreeCell
18
20
19
?
19
Rovers
52
57
80
?
12
IPC3
Satellite
34
34
34
−
−
ZenoTravel
80
80
80
?
20
Total
348
366
399
?
90
IPC2 Blocksworld
35
35
35
?
35
Overall
1485
1492
1243
360
344
the optimal amount of resources cannot be found ahead of time, SGPlan4.1 may incur some
redundant actions for producing unused resources.
In the UMTS domain, SGPlan4.1 can solve all the instances in all the six variants and
is the fastest in four of them. Moreover, its makespans are greatly improved over those of
SGPlan4 by incorporating Te in the modified heuristic function of Metric-FF, although its
improvements in makespan over LPG-TD-SPEED are small for all the variants. SGPlan4.1 ,
however, is slower than LPG-TD-SPEED in the FLAW and FLAW-TIL variants. Its performance degradation in these variants is attributed to the flawed actions that can lead to
overly optimistic heuristic values for relaxed-plan-based planners (Edelkamp & Hoffmann,
2004) like Metric-FF.
For the IPC3 Depots domain, SGPlan4.1 has better quality than LPG-TD-SPEED and
YAHSP in the STRIPS and NUMERIC variants, whereas the makespan of SGPlan4.1 is
worse than that of LPG-TD-SPEED for a majority of the instances in the TIME and
SIMPLETIME variants. LPG-TD-SPEED is also faster than SGPlan4.1 for a majority of
the instances (Fq + Fw + Fwt > Fi + Ft + Fwq for all the corresponding rows in Table 3).
Due to the large fraction of initial active global constraints, the performance of subgoal
partitioning in SGPlan4.1 is unsatisfactory in this domain.
For the remaining IPC3 domains, SGPlan4.1 generally improves SGPlan4 in quality
besides the Freecell domain which is in STRIPS. Except for the Satellite domain where
LPG-TD-SPEED performs better, SGPlan4.1 generates solutions with better quality for
365

Chen, Wah, & Hsu

most of the instances. Further, SGPlan4.1 is faster than LPG-TD-SPEED for more than
half of the instances, although the difference in run times among the planners on these
relatively easy instances is usually insignificant.
In the Blocksworld domain, SGPlan4.1 generally finds solutions with a smaller number of
actions than those of SGPlan4 , LPG-TD-SPEED, and YAHSP. However, SGPlan4.1 is much
slower than LPG-TD-SPEED on many instances because it needs more time for resolving
the large fraction of initial active global constraints (Figure 18h).

8. Conclusions and Future Work
We have presented in this paper the partition-and-resolve approach and its application in
SGPlan4 , a planner that won the first prize in the Suboptimal Temporal Metric Track and
the second prize in the Suboptimal Propositional Track in IPC4. Table 4 summarizes the
number of instances solved by the top planners in IPC4 as well as SGPlan4.1 . The results
show that constraint partitioning employed by our planners is effective for solving a majority
of the problems in the two competitions.
Our approach is based on the observation that the fraction of active mutex constraints
across subgoals for a majority of the instances in IPC3 and IPC4 is very small. This observation allows us to partition the search into largely independent subproblems and to limit
the amount of backtracking when resolving those violated global constraints across subproblems. The improvements are also attributed to a combination of techniques introduced
for reducing the search space and for handling the new features in PDDL2.2.
In the future, we plan to study other partitioning techniques that can better exploit the
constraint structure of planning domains. In particular, we will study fine-grain partitioning
in order to address cases with a larger fraction of global constraints, and develop search
strategies for solving problems with difficult-to-satisfy global constraints and deadlines.
We also plan to extend our method to planning under uncertainty and to support more
expressive modeling language features.

Acknowledgments
The research in this paper is supported by National Science Foundation Grant IIS 03-12084.

References
Blum, A. L., & Furst, M. L. (1997). Fast planning through planning graph analysis. Artificial
Intelligence, 90, 281–300.
Bonet, B., & Geffner, H. (2001). Planning as heuristic search. Artificial Intelligence, Special
issue on Heuristic Search, 129 (1).
Chen, Y., & Wah, B. W. (2003). Automated planning and scheduling using calculus of variations in discrete space. In Proc. Int’l Conf. on Automated Planning and Scheduling,
pp. 2–11.
Chien, S., Rabideau, G., Knight, R., Sherwood, R., Engelhardt, B., Mutz, D., Estlin, T.,
Smith, B., Fisher, F., Barrett, T., Stebbins, G., & Tran, D. (2000). ASPEN - Au366

Temporal Planning using Subgoal Partitioning and Resolution

tomating space mission operations using automated planning and scheduling. In Proc.
SpaceOps. Space Operations Organization.
Doherty, P., & Kvarnstrm, J. (1999). Talplanner: An empirical investigation of a temporal
logic-based forward chaining planner.. In Proc. Sixth Int’l Workshop on Temopral
Logic-based Forword Chaining Planner, pp. 47–54. AIPS.
Edelkamp, S. (2002). Mixed propositional and numerical planning in the model checking
integrated planning system. In Proc. Workshop on Planning for Temporal Domains.
AIPS.
Edelkamp, S. (2003). Pddl2.2 planning in the model checking integrated environment. In
UK Planning and Scheduling Special Interest Group (PlanSig). Glasgow.
Edelkamp, S., & Hoffmann, J. (2004). Classical part, 4th international planning competition.
http://ls5-www.cs.uni-dortmund.de/~edelkamp/ipc-4/.
Foulser, D. E., Li, M., & Yang, Q. (1992). Theory and algorithms for plan merging.. Artificial
Intelligence, 57 (2-3), 143–181.
Fourman, M. P. (2000). Propositional planning. In Proc. Workshop on Model Theoretic
Approaches to Planning. AIPS.
Garrido, A., Fox, M., & Long, D. (2002). A temporal planning system for durative actions
of pddl2.1. In Proc. of European Conf. on Artificial Intelligence, pp. 586–590.
Gerevini, A., & Serina, I. (2002). LPG: a planner based on local search for planning graphs
with action costs. In Proc. of the Sixth Int. Conf. on AI Planning and Scheduling, pp.
12–22. Morgan Kaufman.
Hanks, S., & Weld, D. S. (1995). A domain-independent algorithm for plan adaptation.. J.
of Artificial Intelligence Research, 2, 319–360.
Helmert, M., & Richter, S. (2004). Fast downward - making use of causal dependencies in
the problem representation. In Proc. IPC4, ICAPS, pp. 41–43.
Hoffmann, J. (2003). The metric-ff planning system: Translating ignoring delete lists to
numeric state variables. Journal of Artificial Intelligence Research, 20, 291–341.
Hoffmann, J., & Nebel, B. (2001). The FF planning system: Fast plan generation through
heuristic search. J. of Artificial Intelligence Research, 14, 253–302.
Jonsson, A. K., Morris, P. H., Muscettola, N., & Rajan, K. (2000). Planning in interplanetary space: Theory and practice. In Proc. 2nd Int’l NASA Workshop on Planning
and Scheduling for Space. NASA.
Kambhampati, S., & Hendler, J. A. (1992). A validation-structure-based theory of plan
modification and reuse.. Artificial Intelligence, 55 (2), 193–258.
Kautz, H., & Selman, B. (1996). Pushing the envelope: planning, propositional logic, and
stochastic search. In Proc. 13th National Conference on Artificial Intelligence, pp.
1194–1201. AAAI.
Kautz, H., & Selman, B. (1999). Unifying SAT-based and graph-based planning. In Proc.
Int’l Joint Conf. on Artificial Intelligence. IJCAI.
367

Chen, Wah, & Hsu

Kautz, H., & Walser, J. P. (2000). Integer optimization models of AI planning problems.
The Knowledge Engineering Review, 15 (1), 101–117.
Koehler, J., & Hoffmann, J. (2000). On reasonable and forced goal ordering and their use
in an agenda-driven planning algorithm. J. of AI Research, 12, 339–386.
Lin, F. (2001). A planner called R. AI Magazine, 73–76.
Long, D., & Fox, M. (1998). Efficient implementation of the plan graph in STAN. J. of AI
Research.
Nau, D., Muoz-Avila, H., Cao, Y., Lotem, A., & Mitchell, S. (2001). Total-order planning
with partially ordered subtasks. In Proc. Int’l Joint Conf. on Artificial Intelligence,
pp. 425–430. IJCAI.
Nebel, B., Dimopoulos, Y., & Koehler, J. (1997). Ignoring irrelevant facts and operators in
plan generation. In Proc. European Conf. on Planning, pp. 338–350.
Nebel, B., & Koehler, J. (1995). Plan reuse versus plan generation: A theoretical and
empirical analysis.. Artificial Intelligence, 76 (1-2), 427–454.
Nigenda, R. S., Nguyen, X., & Kambhampati, S. (2000). AltAlt: Combining the advantages
of Graphplan and heuristic state search. Tech. rep., Arizona State University.
Penberethy, J., & Weld, D. (1992). UCPOP: A sound, complete, partial order planner
for ADL. In Proc. 3rd Int’l Conf. on Principles of Knowledge Representation and
Reasoning, pp. 103–114. KR Inc.
Penberethy, J., & Weld, D. (1994). Temporal planning with continuous change. In Proc.
12th National Conf. on AI, pp. 1010–1015. AAAI.
Porteous, J., Sebastia, L., & Hoffmann, J. (2001). On the extraction, ordering, and usage
of landmarks in planning. In Proc. European Conf. on Planning, pp. 37–48.
Refanidis, I., & Vlahavas, I. (2001). The GRT planner. AI Magazine, 63–66.
Refanidis, I., & Vlahavas, I. (2002). The MO-GRT system: Heuristic planning with multiple
criteria. In Proc. Workshop on Planning and Scheduling with Multiple Criteria. AIPS.
Subbarao, M. B. D., & Kambhampati, S. (2002). Sapa: A domain-independent heuristic
metric temporal planner. Tech. rep., Arizona State University.
Tate, A., Drabble, B., & Kirby, R. (1994). O-Plan2: an open architecture for command,
planning and control. Intelligent Scheduling, 213–239.
Tsamardinos, I., Pollack, M. E., & Horty, J. F. (2000). Merging plans with quantitative
temporal constraints, temporally extended actions, and conditional branches.. In Proc.
Int’l Conf. on AI Planning and Scheduling (AIPS), pp. 264–272.
Wah, B., & Chen, Y. (2006). Constraint partitioning in penalty formulations for solving
temporal planning problems. Artificial Intelligence, 170 (3), 187–231.
Wah, B. W., & Chen, Y. (2003). Partitioning of temporal planning problems in mixed space
using the theory of extended saddle points. In Proc. IEEE Int’l Conf. on Tools with
Artificial Intelligence, pp. 266–273.
368

Temporal Planning using Subgoal Partitioning and Resolution

Wah, B. W., & Chen, Y. (2004). Subgoal partitioning and global search for solving temporal
planning problems in mixed space. Int’l J. of Artificial Intelligence Tools, 13 (4), 767–
790.
Wilkins, D. (1990). Can AI planners solve practical problems?. Computational Intelligence,
232–246.
Wolfman, S., & Weld, D. (2000). Combining linear programming and satisfiability solving
for resource planning. The Knowledge Engineering Review, 15 (1).
Yang, Q. (1997). Intelligent planning: a decomposition and abstraction based approach.
Springer-Verlag, London, UK.

369

Journal of Artificial Intelligence Research 26 (2006) 101-126

Submitted 8/05; published 5/06

Domain Adaptation for Statistical Classifiers
Hal Daumé III
Daniel Marcu

hdaume@isi.edu
marcu@isi.edu

Information Sciences Institute
University of Southern California
4676 Admiralty Way, Suite 1001
Marina del Rey, CA 90292 USA

Abstract
The most basic assumption used in statistical learning theory is that training data
and test data are drawn from the same underlying distribution. Unfortunately, in many
applications, the “in-domain” test data is drawn from a distribution that is related, but
not identical, to the “out-of-domain” distribution of the training data. We consider the
common case in which labeled out-of-domain data is plentiful, but labeled in-domain data is
scarce. We introduce a statistical formulation of this problem in terms of a simple mixture
model and present an instantiation of this framework to maximum entropy classifiers and
their linear chain counterparts. We present efficient inference algorithms for this special
case based on the technique of conditional expectation maximization. Our experimental
results show that our approach leads to improved performance on three real world tasks
on four different data sets from the natural language processing domain.

1. Introduction
The generalization properties of most current statistical learning techniques are predicated
on the assumption that the training data and test data come from the same underlying
probability distribution. Unfortunately, in many applications, this assumption is inaccurate.
It is often the case that plentiful labeled data exists in one domain (or coming from one
distribution), but one desires a statistical model that performs well on another related, but
not identical domain. Hand labeling data in the new domain is a costly enterprise, and one
often wishes to be able to leverage the original, “out-of-domain” data when building a model
for the new, “in-domain” data. We do not seek to eliminate the annotation of in-domain
data, but instead seek to minimize the amount of new annotation effort required to achieve
good performance. This problem is known both as domain adaptation and transfer.
In this paper, we present a novel framework for understanding the domain adaptation
problem. The key idea in our framework is to treat the in-domain data as drawn from
a mixture of two distributions: a “truly in-domain” distribution and a “general domain”
distribution. Similarly, the out-of-domain data is treated as if drawn from a mixture of
a “truly out-of-domain” distribution and a “general domain” distribution. We apply this
framework in the context of conditional classification models and conditional linear-chain
sequence labeling models, for which inference may be efficiently solved using the technique
of conditional expectation maximization. We apply our model to four data sets with varying degrees of divergence between the “in-domain” and “out-of-domain” data and obtain
c
2006
AI Access Foundation. All rights reserved.

Daumé III & Marcu

predictive accuracies higher than any of a large number of baseline systems and a second
model proposed in the literature for this problem.
The domain adaptation problem arises very frequently in the natural language processing domain, in which millions of dollars have been spent annotating text resources for
morphological, syntactic and semantic information. However, most of these resources are
based on text from the news domain (in most cases, the Wall Street Journal). The sort
of language that appears in text from the Wall Street Journal is highly specialized and is,
in most circumstances, a poor match to other domains. For instance, there has been a
recent surge of interest in performing summarization (Elhadad, Kan, Klavans, & McKeown, 2005) or information extraction (Hobbs, 2002) of biomedical texts, summarization of
electronic mail (Rambow, Shrestha, Chen, & Lauridsen, 2004), information extraction from
transcriptions of meetings, conversations or voice-mail (Huang, Zweig, & Padmanabhan,
2001), among others. Conversely, in the machine translation domain, most of the parallel
resources that machine translation system depend on for parameter estimation are drawn
from transcripts of political meetings, yet the translation systems are often targeted at news
data (Munteanu & Marcu, 2005).

2. Statistical Domain Adaptation
In the multiclass classification problem, one typically assumes the existence of a training set
D = {(xn , yn ) ∈ X × Y : 1 ≤ n ≤ N }, where X is the input space and Y is a finite set. It is
assumed that each (xn , yn ) is drawn from a fixed, but unknown base distribution p and that
the training set is independent and identically distributed, given p. The learning problem
is to find a function f : X → Y that obtains high predictive accuracy (this is typically
done either by explicitly minimizing the regularized empirical error, or by maximizing the
probabilities of the model parameters).
2.1 Domain Adaptation
In the context of domain adaptation, the situation becomes more complicated. We assume
that we are given two sets of training data, D (o) and D(i) , the “out-of-domain” and “indomain” data sets, respectively. We no longer assume that there is a single fixed, but
known distribution from which these are drawn, but rather assume that D (o) is drawn from
a distribution p(o) and D(i) is drawn from a distribution p(i) . The learning problem is to
find a function f that obtains high predictive accuracy on data drawn from p (i) . (Indeed,
our model will turn out to be symmetric with respect to D (i) and D(o) , but in the contexts
we consider obtaining a good predictive model of D (i) makes more intuitive sense.) We will
assume that |D (o) | = N (o) and |D(i) | = N (i) , where typically we have N (i)  N (o) . As
before, we will assume that the N (o) out-of-domain data points are drawn iid from p(o) and
that the N (i) in-domain data points are drawn iid from p(i) .
Obtaining a good adaptation model requires the careful modeling of the relationship
between p(i) and p(o) . If these two distributions are independent (in the obvious intuitive
sense), then the out-of-domain data D (o) is useless for building a model of p(i) and we may as
well ignore it. On the other hand, if p(i) and p(o) are identical, then there is no adaptation
necessary and we can simply use a standard learning algorithm. In practical problems,
though, p(i) and p(o) are neither identical nor independent.
102

Domain Adaptation for Statistical Classifiers

2.2 Prior Work
There has been relatively little prior work on this problem, and nearly all of it has focused on
specific problem domains, such as n-gram language models or generative syntactic parsing
models. The standard approach used is to treat the out-of-domain data as “prior knowledge”
and then to estimate maximum a posterior values for the model parameters under this prior
distribution. This approach has been applied successfully to language modeling (Bacchiani
& Roark, 2003) and parsing (Roark & Bacchiani, 2003). Also in the parsing domain, Hwa
(1999) and Gildea (2001) have shown that simple techniques based on using carefully chosen
subsets of the data and parameter pruning can improve the performance of an adapted
parser. These models assume a data distribution p (D | θ) with parameters θ and a prior
distribution over these parameters p (θ | η) with hyper-parameters η. They estimate the
η hyperparameters from the out-of-domain data and then find the maximum a posteriori
parameters for the in-domain data, with the prior fixed.
In the context of conditional and discriminative models, the only domain adaptation
work of which we are aware is the model of Chelba and Acero (2004). This model again
uses the out-of-domain data to estimate a prior distribution, but does so in the context
of a maximum entropy model. Specifically, a maximum entropy model is trained on the
out-of-domain data, yielding optimal weights for that problem. These weights are then used
as the mean weights for the Gaussian prior on the learned weights for the in-domain data.
Though effective experimentally, the practice of estimating a prior distribution from
out-of-domain data and fixing it for the estimation of in-domain data leaves much to be
desired. Theoretically, it is strange to estimate and fix a prior distribution from data; this is
made more apparent by considering the form of these models. Denoting the in-domain data
and parameters by D (i) and θ, respectively, and the out-of-domain data and parameters by
D(o) and η, we obtain the following form for these “prior” estimation models:




θ̂ = arg max p θ | arg max p (η) p D
θ

η

(o)

 

(i)
|η
p D |θ

(1)

One would have a very difficult time rationalizing this optimization problem by anything
other than experimental performance. Moreover, these models are unusual in that they do
not treat the in-domain data and the out-of-domain data identically. Intuitively, there is
no difference in the two sets of data; they simply come from different, related distributions.
Yet, the prior-based models are highly asymmetric with respect to the two data sets. This
also makes generalization to more than one “out of domain” data set difficult. Finally, as
we will see, the model we propose in this paper, which alleviates all of these problems,
outperforms them experimentally.
A second generic approach to the domain adaptation problem is to build an out of
domain model and use its predictions as features for the in domain data. This has been
successfully used in the context of named entity tagging (?). This approach is attractive
because it makes no assumptions about the underlying classifier; in fact, multiple classifiers
can be used.
103

Daumé III & Marcu

2.3 Our Framework
In this paper, we propose the following relationship between the in-domain and the out-ofdomain distributions. We assume that instead of two underlying distributions, there are
actually three underlying distributions, which we will denote q (o) , q (g) and q (i) . We then
consider p(o) to be a mixture of q (o) and q (g) , and consider p(i) to be a mixture of q (i) and
q (g) . One can intuitively view the q (o) distribution as a distribution of data that is truly
out-of-domain, q (i) as a distribution of data that is truly in-domain and q (g) as a distribution
of data that is general to both domains. Thus, knowing q (g) and q (i) is sufficient to build
a model of the in-domain data. The out-of-domain data can help us by providing more
information about q (g) than is available by just considering the in-domain data.
For example, in part-of-speech tagging, the assignment of the tag “determiner” (DT) to
the word “the” is likely to be a general decision, independent of domain. However, in the
Wall Street Journal, “monitor” is almost always a verb (VB), but in technical documentation
it will most likely be a noun. The q (g) distribution should account for the case of “the/DT”,
the q (o) should account for “monitor/VB” and q (i) should account for “monitor/NN.”

3. Domain Adaptation in Maximum Entropy Models
The domain adaptation framework outlined in Section 2.3 is completely general in that
it can be applied to any statistical learning model. In this section we apply it to loglinear conditional maximum entropy models and their linear chain counterparts, since these
models have proved quite effective in many learning tasks. We will first review the maximum
entropy framework, then will extend it to the domain adaptation problem; finally we will
discuss domain adaptation in linear chain maximum entropy models.
3.1 Maximum Entropy Models
The maximum entropy framework seeks a conditional distribution p (y | x) that is closest
(in the sense of KL divergence) to the uniform distribution but also matches a set of training data D with respect to feature function expectations (Della Pietra, Della Pietra, &
Lafferty, 1997). By introducing one Lagrange multiplier λi for each feature function fi , this
optimization problem results in a probability distribution of the form:
p (y | x ; λ) =

1
Zλ,x

h
i
exp λ> f (x, y)

(2)

P
Here, u> v denotes the scalar product of two vectors u and v, given by: u> v = i ui vi .
The normalization constant in Eq (2), Zλ,x , is obtained by summing the exponential over
all possible classes y 0 ∈ Y. This probability distribution is also known as an exponential
distribution or a Gibbs distribution. The learning (or optimization) problem is to find the
vector λ that maximizes the likelihood in Eq (2). In practice, to prevent over-fitting, one
typically optimizes a penalized (log) likelihood, where an isotropic Gaussian prior with mean
0 and covariance matrix σ 2 I is placed over the parameters λ (Chen & Rosenfeld, 1999).
The graphical model for the standard maximum entropy model is depicted on the left of
Figure 1. In this figure, circular nodes correspond to random variables and square nodes
104

Domain Adaptation for Statistical Classifiers

correspond to fixed variables. Shaded nodes are observed in the training data and empty
nodes are hidden or unobserved. Arrows denote conditional dependencies.
In general, the feature functions f (x, y) may be arbitrary real-valued functions; however,
in this paper we will restrict our attention to binary features. In practice, this is not a harsh
restriction: many problems in the natural language domain naturally employ only binary
features (for real valued features, binning techniques can be applied). Additionally, for
notational convenience, we will assume that the features fi (x, y) can be written in product
form as gi (y)hi (x) for arbitrary binary functions g over outputs and binary features h over
inputs. The latter assumption means that we can consider x to be a binary vector where
xi = hi (x); in the following this will simplify notation significantly (the extension to the full
case is straightforward, but messy, and is therefore not considered in the remainder of this
paper). By considering x as a vector, we may move the class dependence to the parameters
and consider λ to be a matrix where λy,i is the weight for hi for class y. We will write
λy to refer to the column vector of λ corresponding to class y. As x is also considered a
column vector, we write λy > x as shorthand for the dot product between x and the weights
for class y. Under this modified notation, we may rewrite Eq (2) as:
p (y | x ; λ) =

1
Zλ,x

h
i
exp λy > x

(3)

Combining this with a Gaussian prior on the weights, we obtain the following form for
the log posterior of a data set:


N
i
h
X
X
1
λyn > xn − log
l = log p (λ | D, σ s ) = − 2 λ> λ +
exp λy0 > xn  + const
2σ
0
n=1

(4)

y ∈Y

The parameters λ can be estimated using any convex optimization technique; in practice,
limited memory BFGS (Nash & Nocedal, 1991; Averick & Moré, 1994) seems to be a good
choice (Malouf, 2002; Minka, 2003) and we will use this algorithm for the experiments
described in this paper. In order to perform these calculations, one must be able to compute
the gradient of Eq (4) with respect to λ, which is available in closed form.
3.2 The Maximum Entropy Genre Adaptation Model
Extending the maximum entropy model to account for both in-domain and out-of-domain
data in the framework described earlier requires the addition of several extra model param(i) (i)
eters. In particular, for each in-domain data point (xn , yn ), we assume the existence of a
(i)
(i)
(i) (i)
binary indicator variable zn . A value zn = 1 indicates that (xn , yn ) is drawn from q (i)
(i)
(the truly in-domain distribution), while a value zn = 0 indicates that it is drawn from q (g)
(o) (o)
(the general-domain distribution). Similarly, for each out-of-domain data point (x n , yn ),
(o)
(o)
we assume a binary indicator variable zn , where zn = 1 means this data point is drawn
(o)
from q (the truly out-of-domain distribution) and a value of 0 means that it is drawn
from q (g) (the general-domain distribution). Of course, these indicator variables are not
observed in the data, so we must infer their values automatically.
105

Daumé III & Marcu

σ2

σ2

λ

λi

λg

yni

yn
xn

xni

zni

N

πi

λo

yno

N

xno

i

ψ

ψ

i

zno

ψ

g

o

π

N

o

o

Figure 1: (Left) the standard logistic regression model; (Right) the Mega Model.
According to this model, the zn s are binary random variables that we assume are
drawn from a Bernoulli distribution with parameter π (i) (for in-domain) and π (o) (for outof-domain). Furthermore, we assume that there are three λ vectors, λ (i) , λ(o) and λ(g)
corresponding to q (i) , q (o) and q (g) , respectively. For instance, if zn = 1, then we assume
(i)
that x̄n should be classified using λ(i) . Finally, we model the binary vectors xn s (respec(o)
tively xn s) as being drawn independently from Bernoulli distributions parameterized by
(i)
ψ and ψ (g) (respectively, ψ (o) and ψ (g) ). Again, when zn = 1, we assume that xn is
drawn according to ψ (i) . This corresponds to a naı̈ve Bayes assumption over the generative
probabilities of the xn vectors. Finally, we place a common Beta prior over the naı̈ve Bayes
parameters, ψ. Allowing ν to range over {i, o, g}, the full hierarchical model is:
(ν)

ψ f | a, b
(i)
zn | π (i)
(i)

(i)

(i)

(i)

(i)

(g)

xnf | zn , ψ f , ψ f
(i)

λ(ν) | σ 2
(o)
zn | π (o)

∼ Bet(a, b)
∼ Ber(π (i) )
z (i)

∼ Ber(ψ fn )

(i)

(i)

yn | xn , zn , λ(i) , λ(g) ∼ Gibbs(xn , λzn )

(o)

(o)

(o)

(o)

(o)

(g)

xnf | zn , ψ f , ψ f
(o)

∼ Nor(0, σ 2 I)
∼ Ber(π (o) )

(5)

z (o)

∼ Ber(ψ fn )

(o)

(o)

yn | xn , zn , λ(o) , λ(g) ∼ Gibbs(xn , λzn )

We term this model the “Maximum Entropy Genre Adaptation Model” (the Mega
Model). The corresponding graphical model is shown on the right in Figure 1. The generative story for an in-domain data point x(i) is as follows:
1. Select whether x(i) will be truly in-domain or general-domain and indicate this by
z (i) ∈ {i, g}. Choose z (i) = i with probability π (i) and z (i) = g with probability
1 − π (i) .
(i)

2. For each component f of x(i) , choose xf to be 1 with probability ψ zf
z (i)

probability 1 − ψ f .
(i)

3. Choose a class y according to Eq (3) using the parameter vector λ z .
106

(i)

and 0 with

Domain Adaptation for Statistical Classifiers

The story for out-of-domain data points is identical, but uses the truly out-of-domain
and general-domain parameters, rather than the truly in-domain parameters and generaldomain parameters.
3.3 Linear Chain Models
The straightforward extension of the maximum entropy classification model to the maximum
entropy Markov model (MEMM) (McCallum, Freitag, & Pereira, 2000) is obtained by
assuming that the targets yn are sequences of labels. The canonical example for this model
is part of speech tagging: each word in a sequence is assigned a part of speech tag. By
introducing a first order Markov assumption on the tag sequence, one obtains a linear chain
model that can be viewed as the discriminative counterpart to the standard (generative)
hidden Markov model. The parameters of these models can be estimated again using
limited memory BFGS. The extension of the Mega Model to the linear chain framework is
similarly straightforward, under the assumption that each label (part of speech tag) has its
own indicator variable z (versus a global indicator variable z for the entire tag sequence).
The techniques described herein may also be applied to the conditional random field
framework of Lafferty, McCallum, and Pereira (2001), which fixes a bias problem of the
MEMM by performing global normalization rather than per-state normalization. There is,
however, a subtle difficulty in a direct application to CRFs. Specifically, one would need
to decide if a single z variable would be assigned to an entire sentence, or to each word
individually. In the MEMM case, it is most natural to have one z per word. However, to
do so in a CRF would be computationally more expensive. In the remainder, we continue
to use the MEMM model for efficiency purposes.

4. Conditional Expectation Maximization
Inference in the Mega Model is slightly more complex than in standard maximum entropy models. However, inference can be solved efficiently using conditional expectation
maximization (CEM), a variant of the standard expectation maximization (EM) algorithm
(Dempster, Laird, & Rubin, 1977), due to Jebara and Pentland (1998). At a high level, EM
is useful for computing in generative models with hidden variables, while CEM is useful for
computing in discriminative models with hidden variables; the Mega Model belongs to the
latter family, so CEM is the appropriate choice.
The standard EM family of algorithms maximizes a joint likelihood over data. In
particular, if (xn , yn )N
n=1 are data and z is a (discrete) hidden variable, the M-step of EM
proceeds by maximizing the bound given in Eq (6)
log p (x, y | Θ) = log

X
z

p (z, x, y | Θ) = log Ez∼p(· | x;Θ) p (x, y | z; Θ)

(6)

In Eq (6), Ez denotes an expectation. One may now apply Jensen’s inequality to this
equation, which states that f (E{x}) ≤ E{f (x)} whenever f is convex. Taking f = log, we
are able to decompose the log of an expectation into the expectation of a log. This typically
separates terms and makes taking derivatives and solving the resolution optimization problem tractable. Unfortunately, EM cannot be directly applied to conditional models (such
107

Daumé III & Marcu

as the Mega Model) of the form in Eq (7) because such models result in an M-step that
requires the maximization of an equation of the form given in Eq (8).
log p (y | x; Θ) = log
l = log

X
z

X
z

p (z, y | x; Θ) = log Ez∼p(· | x,Θ) p (y | x, z; Θ)
p (z, x, y | Θ) − log

X
z

p (z, x | Θ)

(7)
(8)

Jensen’s inequality can be applied to the first term in Eq (8), which can be maximized
readily as in standard EM. However, applying Jensen’s inequality to the second term would
lead to an upper bound on the likelihood, since that term appears negated.
The conditional EM solution (Jebara & Pentland, 1998) is to bound the change in
log-likelihood between iterations, rather than the log-likelihood itself. The change in loglikelihood can be written as in Eq (9), where Θt denotes the parameters at iteration t.


∆lc = log p y | x; Θt − log p y | x; Θt−1

(9)

By rewriting the conditional distribution p (y | x) as p (x, y) divided by p (x), we can
express ∆lc as the log of the joint distribution difference minus the log of the marginal
distribution. Here, we can apply Jensen’s inequality to the first term (the joint difference),
but not to the second (because it appears negated). Fortunately, Jensen’s is not the only
bound we can employ. The standard variational upper bound of the logarithm function is:
log x ≤ x − 1; this leads to a lower bound of the negation, which is exactly what is desired.
This bound is attractive for other reasons: (1) it is tangent to the logarithm; (2) it is tight;
(3) it makes contact at the current operating point (according to the maximization at the
previous time step); (4) it is a simply linear function; and (5) in the terminology of the
calculus of variations, it is the variational dual to the logarithm; see (Smith, 1998).
Applying Jensen’s inequality to the first term in Eq (9) and the variational dual to the
second term, we obtain that the change of log-likelihood in moving from model parameters
Θt−1 at time t − 1 to Θt at time t (which we shall denote Qt ) is bounded by ∆l ≥ Qt , where
Qt is defined by Eq (10), where h = E{z | x; Θ} when z = 1 and 1 − E{z | x; Θ} when
z = 0, with expectations taken with respect to the parameters from the previous iteration.


P
t
X
p z, x, y | Θt
z p z, x | Θ
t
+1
(10)
Q =
hz log
−P
t−1 )
p (z, x, y | Θt−1 )
z p (z, x | Θ
z∈Z

By applying the two bounds (Jensen’s inequality and the variational bound), we have
removed all “sums of logs,” which are hard to deal with analytically. The full derivation is
given in Appendix A. The remaining expression is a lower bound on the change in likelihood,
and maximization of it will result in maximization of the likelihood.
As in the MAP variant of standard EM, there is no change to the E-step when priors
are placed on the parameters. The assumption in standard EM is that we wish to maximize
p (Θ | x, y) ∝ p (Θ) p (y | Θ, x) where the prior probability of Θ is ignored, leaving just the
likelihood term of the parameters given the data. In MAP estimation, we do not make this
assumption and instead use a true prior p (Θ). In doing so, we need only to add a factor of
log p (Θ) to the definition of Qt in Eq (10).
108

Domain Adaptation for Statistical Classifiers

t−1
jn,z
n

mt−1
n


= log p xn , yn , zn | Θt−1
ψn,zn

P
t−1 −1 ψ
=
n,zn ,−f 0
z n p x n , zn | Θ



xnf 
1−xnf
zn
zn
ψ
1
−
ψ
f =1
f
f

xnf 
1−xnf
Q
zn
zn
ψ
=
1
−
ψ
0
f 6=f
f
f

=

QF

Table 1: Notation used for Mega Model equations.
It is important to note that although we do make use of a full joint distribution p (x, y, z),
the objective function of our model is conditional. The joint distribution is only used in the
process of creating the bound: the overall optimization is to maximize the conditional likelihood of the labels given the input. In particular, the bound using the full joint likelihood
holds for any parameters of the marginal.

5. Parameter Estimation for the Mega Model
As made explicit in Eq (10), the relevant distributions for performing CEM are the full joint
distributions over the input variables x, the output variables y, and the hidden variables z.
Additionally, we require the marginal distribution over the x variables and the z variables.
Finally, we need to compute expectations over the z variables. We will derive the expectation
step in this section and present the final solution for the maximization step for each class
of variables. The derivation of the equations for the maximization is given in Appendix B.
The Q bound on complete conditional likelihood for the Mega Modelis given below:





P
(i)
(i)
(i)
(i)
(i)
z
,
x
p
p
z
,
x
,
y
(i)
X
n
n
n
n
n
z


 + 1
−P n 
h(i)
Qt =
n log
(i)
(i)
(i)
0 z (i) , x(i)
0
p z n , x n , yn
(i) p
n
n
n=1 z (i)
zn
n






P
(o)
(o) (o)
(o)
(o)
(o)
N
p zn , xn , yn
(o) p zn , xn
X X
z

 + 1

−P n 
h(o)
+
n log
(o)
(o)
(o)
(o)
(o)
0
0
p z n , x n , yn
z n , xn
(o) p
n=1 z (o)
z
N (i)
X



(11)

n

n

In this equation, p0 () is the probability distribution at the previous iteration. The first
term in Eq (11) is the bound for the in-domain data, while the second term is the bound for
the out-of-domain data. In all the optimizations described in this section, there are nearly
identical terms for the in-domain parameters and the out-of-domain parameters. For brevity,
we will only explicitly write the equations for the in-domain parameters; the corresponding
out-of-domain equations can be easily derived from these. Moreover, to reduce notational
overload, we will elide the superscripts denoting in-domain and out-of-domain when obvious
from context. For notational brevity, we will use the notation depicted in Table 1.
5.1 Expectation Step
The E-step is concerned with calculating hn given current model parameters. Since zn ∈
{0, 1}, we easily find hn = p (zn = 1|Θ), which can be calculated as follows:
109

Daumé III & Marcu

p (zn = z | xn , yn , ψ, λ, π)
p (zn = z | π) p (xn | ψ, zn = z) p (yn | λ, zn = z)
= P
z p (zn = z | π) p (xn | ψ, zn = z) p (yn | λ, zn = z)
i
h
1
∝ π z (1 − π)1−z ψn,z
exp λzyn > xn
Zxn ,λz

(12)

Here, Z is the partition function from before. This can be easily calculated for z ∈ {0, 1}
and the expectation can be found by dividing the value for z = 1 by the sum over both.
5.2 M-Step for π
As shown in Appendix B.1, we can directly compute
the value of π by solving a simple
√
quadratic equation. We can compute π as −a + a2 − b, where:
a =
b =
5.3 M-Step for λ

PN

t−1
n=1 2hn − mn (ψn,0 − ψn,1 )
PN
2 n=1 mt−1
n (ψn,0 − ψn,1 )
PN
n=1 hn
− PN
t−1
n=1 mn (ψn,0 − ψn,1 )

1−



Viewing Qt as a function of λ, it is easy to see that optimization for this variable is convex.
An analytical solution is not available, but the gradient of Qt with respect to λ(i) can be
seen to be identical to the gradient of the standard maximum entropy posterior, Eq (4), but
where each data point is weighted according to its posterior probability, (1 − h n ). We may
thus use identical optimization techniques for computing optimal λ variables as for standard
maximum entropy models; the only difference is that the data points are now weighted. A
similar story holds for λ(o) . In the case of λ(g) , we obtain the standard maximum entropy
(i)
gradient, computed over all N (i) + N (o) data points, where each xn is weighted by hn and
(o)
(o)
each xn is weighted by hn . This is shown in Appendix B.2.
5.4 M-Step for ψ
Like the case for λ, we cannot obtain an analytical solution for finding the ψ that maximizes
Qt . However, we can compute simple derivatives for Qt with respect to a single component
(i)
ψ f which can be maximized analytically. As shown in Appendix B.3, we can compute ψf
√
as −a + a2 − b, where:
PN



n=1 1 − hn + jn,0 (1 − π)ψn,0,−f
a = −
P
2 N
n=1 jn,0 (1 − π)ψn,0,−f
PN
(1 − hn ) xnf
1+
b = PN n=1
n=1 jn,0 (1 − π)ψn,0,−f

110



Domain Adaptation for Statistical Classifiers

Algorithm MegaCEM
(ν)
(ν)
Initialize ψf = 0.5, λf = 0, π (ν) = 0.5 for all ν ∈ {g, i, o} and all f .
while parameters haven’t converged or iterations remain do
{- Expectation Step -}
for n = 1..N (i) do
(i)
Compute the in-domain marginal probabilities, mn
(i)
Compute the in-domain expectations, hn , by Eq (12)
end for
for n = 1..N (o) do
(o)
Compute the out-of-domain marginal probabilities, mn
(o)
Compute the out-of-domain expectations, hn by Eq (12)
end for
{- Maximization Step -}
Analytically update π (i) and π (o) according to the equations shown in Section 5.2
Optimize λ(i) , λ(o) and λ(g) using BFGS
while Iterations remain and/or ψ haven’t converged do
Update ψs according to derivation in Section 5.4
end while
end while
return λ, ψ, π
Figure 2: The full training algorithm for the Mega Model.
The case for ψ (o) is identical. For ψ (g) , the only difference is that we must replace each
sum to over the data points with two sums, one for each of the in-domain and out-of-domain
points; and, as before, the 1 − hn s must be replaced with hn ; this is made explicit in the
Appendix. Thus, to optimize the ψ variables, we simply iterate through and optimize each
component analytically, as given above, until convergence.
5.5 Training Algorithm
The full training algorithm is depicted in Figure 2. Convergence properties of the CEM
algorithm ensure that this will converge to a (local) maximum in the posterior space. If local
optima become a problem in practice, one can alternatively use a stochastic optimization
algorithm, in which a temperature is applied enabling the optimization to jump out of local
optima early on. However, we do not explore this idea further in this work. In the context
of our application, this extension was not required.
5.6 CEM Convergence
One immediate question about the conditional EM model we have described is how many
EM iterations are required for the model to converge. In our experiments, 5 iterations of
111

Daumé III & Marcu

Convergence of CEM Optimization
22
20
18

Negative Log Likelihood (*1e6)

16
14
12
10
8
6
4
2
0

0

1

2
3
Number of Iterations

4

5

Figure 3: Convergence of training algorithm.

CEM is more than sufficient, and often only 2 or 3 are necessary. To make this more clear,
in Figure 3, we have plotted the negative complete log likelihood of the model on the first
data set, described below in Section 6.2. There are three separate maximizations in the full
training algorithm (see Figure 2); the first involves updating the π variables, the second
involves optimizing the λ variables and the third involves optimizing the ψ variables. We
compute the likelihood after each of these steps.
Running a total 5 CEM iterations is still relatively efficient in our model. The dominating expense is in the weighted maximum entropy optimization, which, at 5 CEM iterations,
must be computed 15 times (each iteration requires the optimization of each of the three
sets of λ variables). At worst this will take 15 times the amount of time to train a model on
the complete data set (the union of the in-domain and out-of-domain data), but in practice
we can resume each optimization at the ending point of the previous iteration, which causes
the subsequent optimizations to take much less time.
5.7 Prediction
Once training has supplied us with model parameters, the subsequent task is to apply these
parameters to unseen data to obtain class predictions. We assume all this test data is “indomain” (i.e., is drawn either from Q(i) or Q(g) in the notation of the introduction), and
obtain a decision rule of the form given in Eq (13) for a new test point x.

ŷ = arg max p (y | x; Θ)
y∈Y
X
= arg max
p (z | x; Θ) p (y | x, z; Θ)
y∈Y

= arg max
y∈Y

z

X
z

p (z | Θ) p (x | z; Θ) p (y | x, z; Θ)
112

Domain Adaptation for Statistical Classifiers



= arg max π 

F
Y



(g)

ψf

xf 

(g)

1 − ψf

1−xf




i
h
(g)
exp λy > x

Zx,λ(g)
h
i


>x
F 
xf 
1−xf exp λ(i)
Y
y
(i)
(i)

+ (1 − π) 
ψf
1 − ψf
Zx,λ(i)
y∈Y

f =1

(13)

f =1

Thus, the decision rule is to simply select the class which has highest probability according to the maximum entropy classifiers, weighted linearly by the marginal probabilities
of the new data point being drawn from Q(i) versus Q(g) . In this sense, our model can be
seen as linearly interpolating an in-domain model and a general-domain model, but where
the interpolation parameter is input specific.

6. Experimental Results
In this section, we describe the result of applying the Mega Model to several datasets with
varying degrees of divergence between the in-domain and out-of-domain data. However,
before describing the data and results, we will discuss the systems against which we compare.
6.1 Baseline Systems
Though there has been little literature on this problem and thus few real systems against
which to compare, there are several obvious baselines, which we describe in this section.
OnlyI: This model is obtained simply by training a standard maximum entropy model
on the in-domain data. This completely ignores the out-of-domain data and serves as a
baseline case for when such data is unavailable.
OnlyO: This model is obtained by training a standard maximum entropy model on the
out-of-domain data, completely ignoring the in-domain data. This serves as a baseline for
expected performance without annotating any new data. It also gives a sense of how close
the out-of-domain distribution is to the in-domain distribution.
LinI: This model is obtained by linearly interpolating the OnlyI and OnlyO systems.
The interpolation parameter is estimated on held-out (development) in-domain data. This
means that, in practice, extra in-domain data would need to be annotated in order to create
a development set; alternatively, cross-validation could be used.
Mix: This model is obtained by training a maximum entropy model on the union of the
out-of-domain and in-domain data sets.
MixW: This model is also obtained by training a maximum entropy model on the union
of the out-of-domain and in-domain data sets, but where the out-of-domain data is downweighted so that is effectively equinumerous with the in-domain data.
Feats: This model uses the out-of-domain data to build one classifier and then uses this
classifier’s predictions as features for the in-domain data, as described by ? (?).
113

Daumé III & Marcu

Prior: This is the adaptation model described in Section 2.2, where the out-of-domain
data is used to estimate a prior for the in-domain classifier. In the case of the maximum
entropy models we consider here, the weights learned from the out-of-domain data are used
as the mean of the Gaussian prior distribution placed over the weights in the training of
the in-domain data, as is described by Chelba and Acero (2004).
In all cases, we tune model hyperparameters using performance on development data.
This development data is taken to be a random 20% of the training data in all cases. Once
appropriate hyperparameters are found, the 20% is folded back in to the training set.
6.2 Data Sets
We evaluate our models on three different problems. The first two problems come from the
Automatic Content Extraction (ACE) data task. This data was selected because the ACE
program specifically looks at data in different domains. The third problem is the same as
that tackled by Chelba and Acero (2004), which required them to annotate data themselves.
6.2.1 Mention Type Classification
The first problem, Mention Type, is a subcomponent of the entity mention detection
task (an extension of the named entity tagging task, wherein pronouns and nominals are
marked, in addition to simple names). We assume that the extents of the mentions are
marked and we simply need to identify their type, one of: Person, Geo-political Entity,
Organization, Location, Weapon or Vehicle. As the out-of-domain data, we use the newswire
and broadcast news portions of the ACE 2005 training data; as the in-domain data, we use
the Fisher conversations data. An example out-of-domain sentence is:
Once again, a prime battleground will be the constitutional allocation of power –
nom
nam
between the federal governmentnom
gpe and the statesgpe , and between Congressorg
bar
and federal regulatory agenciesorg .
An example in-domain sentence is:
nom
pro
nom
mypro
per wifeper if Iper had not been transported across the continent gpe from
whq pro
whereloc Iper was born and and

We use 23k out-of-domain examples (each mention corresponds to one example), 1k
in-domain examples and 456 test examples. Accuracy is computed as 0/1 loss. We use
the standard feature functions employed in named entity models, include lexical items,
stems, prefixes and suffixes, capitalization patterns, part-of-speech tags, and membership
information on gazetteers of locations, businesses and people. The accuracies reported are
the result of running ten fold cross-validation.
6.2.2 Mention Tagging
The second problem, Mention Tagging is the precursor to the Mention Type task, in
which we attempt to tag entity mentions in raw text. We use the standard Begin/In/Out
encoding and use a maximum entropy Markov model to perform the tagging (McCallum
et al., 2000). As the out-of-domain data, we use again the newswire and broadcast news
114

Domain Adaptation for Statistical Classifiers

data; as the in-domain data, we use broadcast news data that has been transcribed by
automatic speech recognition. The in-domain data lacks capitalization, punctuation, etc.,
and also contains transcription errors (speech recognition word error rate is approximately
15%). For the tagging task, we have 112k out-of-domain examples (in the context of tagging,
an example is a single word), but now 5k in-domain examples and 11k test examples.
Accuracy is F-measure across the segmentation. We use the same features as in the mention
type identification task. The scores reported are after ten fold cross-validation.
6.2.3 Recapitalization
The final problem, Recap, is the task of recapitalizing text. Following Chelba and Acero
(2004), we again use a maximum entropy Markov model, where the possible tags are:
Lowercase, Capitalized, All Upper Case, Punctuation or Mixed case. The out-of-domain
data in this task comes from the Wall Street Journal, and two separate in-domain data sets
come from broadcast news text from CNN/NPR and ABC Primetime, respectively. We use
3.5m out-of-domain examples (one example is one word). For the CNN/NPR data, we use
146k in-domain training examples and 73k test examples; for the ABC Primetime data, we
use 33k in-domain training examples and 8k test examples. We use identical features to
Chelba and Acero (2004). In order to maintain comparability to the results described by
Chelba and Acero (2004), we do not perform cross-validation for these experiments: we use
the same train/test split as described in their paper.
6.3 Feature Selection
While the maximum entropy models used for the classification are adept at dealing with
many irrelevant and/or redundant features, the naı̈ve Bayes generative model, which we use
to model the distribution of the input variables, can overfit on such features. This turned
out not to be a problem for the Mention Type and Mention Tagging problems, but
for the Recap problems, it caused some errors. To alleviate this problem, for the Recap
problem only, we applied a feature selection algorithm just to the features used for the naı̈ve
Bayes model (the entire feature set was used for the maximum entropy model). Specifically,
we took the 10k top features according to the information gain criteria to predict “indomain” versus “out-of-domain” (as opposed to feature selection for class label); Forman
(2003) provides an overview of different selection techniques.1
6.4 Results
Our results are shown in Table 2, where we can see that training only on in-domain data
always outperforms training only on out-of-domain data. The linearly interpolated model
does not improve on the base models significantly. Placing all the data in one bag helps,
and there is no clear advantage to re-weighting the out domain data. The Prior model
and the Feats model perform roughly comparably, with the Prior model edging out by a
small margin.2 Our model outperforms both the Prior model and the Feats model.
1. The value of 10k was selected arbitrarily after an initial run of the model on development data; it was
not tuned to optimize either development or test performance.
2. Our numbers for the result of the Prior model on the data from Chelba and Acero (2004) differ slightly
from those reported in their paper. There are two potential reasons for this. First, most of their numbers

115

Daumé III & Marcu

|D(o) |

|D(i) |
Accuracy
OnlyO
OnlyI
LinI
Mix
MixW
Feats
Prior
MegaM
% Reduction
Mix
Prior

Mention
Type
23k
1k

Mention
Tagging
112k
5k

Recap
ABC
3.5m
8k

Recap
CNN
3.5m
73k

Average
-

57.6
81.2
81.5
84.9
81.3
87.8
87.9
92.1

78.3
83.5
83.8
80.9
81.0
84.2
85.1
88.2

95.5
97.4
97.7
96.4
97.6
97.8
97.9
98.1

94.6
94.7
94.9
95.0
93.5
96.1
95.9
96.8

81.5
89.2
89.5
89.3
88.8
91.5
91.7
93.9

47.7
34.7

38.2
20.8

52.8
19.0

36.0
22.0

43.0
26.5

Table 2: Experimental results; The first set of rows show the sizes of the in-domain and
out-of-domain training data sets. The second set of rows (Accuracy) show the
performance of the various models on each of the four tasks. The last two rows (%
Reduction) show the percentage reduction in error rate by using the Mega Model
over the baseline model (Mix) and the best alternative method (Prior).

We applied McNemar’s test (Gibbons & Chakraborti, 2003, section 14.5) to gage statistical significance of these results, comparing the results of the Prior model with our own
Mega Model (for the mention tagging experiment, we compute McNemar’s test on simple
Hamming accuracy rather than F-score; this is suboptimal, but we do not know how to
compute statistical significance for the F-score). For the mention type task, the difference
is statistical significant at the p ≤ 0.03 level; for the mention tagging task, p ≤ 0.001; for
the recapitalization tasks, the difference on the ABC data is significant only at the p ≤ 0.06
level, while for the CNN/NPR data it is significant at the p ≤ 0.004 level.
In the mention type task, we have improved a baseline model trained only on in-domain
data from an accuracy of 81.2% up to 92.1%, a relative improvement of 13.4%. For mention
tagging, we improve from 83.5% F-measure up to 88.2%, a relative improvement of 5.6%.
In the ABC recapitalization task (for which much in-domain data is available), we increase
performance from 95.5% to 98.1%, a relative improvement of 2.9%. In the CNN/NPR
recapitalization task (with very little in-domain data), we increase performance from 94.6%
to 96.8%, a relative improvement of 2.3%.

are reported based on using all 20m examples; we consider only the 3.5m example case. Second, there
are likely subtle differences in the training algorithms used. Nevertheless, on the whole, our relative
improvements agree with those in their paper.

116

Domain Adaptation for Statistical Classifiers

Mention Type Identification Task

Mention Tagging Task

90

95

OnlyOut
Chelba
MegaM

90

OnlyOut
Chelba
MegaM

85
85

80

Accuracy

F−measure

80

75

75
70

65

70
60

65
0
10

1

10

2

3

10
10
Amount of In Domain Data Used (log scale)

55
1
10

4

10

2

10
Amount of In Domain Data Used (log scale)

Figure 4: Learning curves for Prior and MegaM models.
6.5 Learning Curves
Of particular interest is the amount of annotated in-domain data needed to see a marked
improvement from the OnlyO baseline to a well adapted system. We show in Figure 4 the
learning curves on the Mention Type and Mention Tagging problems. Along the x-axis,
we plot the amount of in-domain data used; along the y-axis, we plot the accuracy. We plot
three lines: a flat line for the OnlyO model that does not use any in-domain data, and
curves for the Prior and MegaM models. As we can see, our model maintains an accuracy
above both the other models, while the Prior curve actually falls below the baseline in the
type identification task.3

7. Model Introspection
We have seen in the previous sections that the Mega Model routinely outperforms competing models. Despite this clear performance improvement, a question remains open regarding
the internal workings of the models. The π (i) variable captures the degree to which the indomain data set is truly in-domain. The z variables in the model aim to capture, for each
test data point, whether it is “general domain” or “in-domain.” In this section, we discuss
the particular values of the parameters the model learns for these variables.
We present two analyses. In the first (Section 7.1), we inspect the model’s inner workings
on the Mention Type task from Section 6.2.1. In this analysis, we look specifically at
the expected values of the hidden variables found by the model. In the second analysis
(Section 7.2), we look at the ability of the model to judge degree of relatedness, as defined
by the π variables.
3. This is because the Fisher data is personal conversations. It hence has a much higher degree of first
and second person pronouns than news. (The baseline that always guesses “person” achieves a 77.8%
accuracy.) By not being able to intelligently use the out-of-domain data only when the in-domain model
is unsure, performance drops, as observed in the Prior model.

117

3

10

Daumé III & Marcu

Pre-context
my home is in trenton
veteran’s administration
you know by the american
gives
is he capable of getting
the fisher thing calling
when i was a

. . . Entity . . .
. . . new jersey . . .
. . . hospital . . .
. . . government. . .
...
me
...
. . . anything . . .
...
me
...
...
kid
...

Post-context
and that’s where
because what is
chills because if
over here
ha ha they screwed up
that that was a

True
GPE
ORG
ORG
PER
WEA
PER
PER

Hyp
GPE
LOC
ORG
PER
PER
PER
PER

p (z = I)
0.02
0.11
0.17
0.71
0.92
0.93
0.98

Table 3: Examples from the test data for the Mention Type task. The “True” column is
the correct entity type and the “Hyp” column is our model’s prediction. The final
column is the probability this example is truly in-domain under our model.

7.1 Model Expectations
To focus our discussion, we will consider only the Mention Type task, Section 6.2.1. In
Table 3, we have shown seven test-data examples from the Mention Type task. The Precontext is the text that appears before the entity and the post-context is the text that
appears after. We report the true class and the class our model hypothesizes. Finally, we
report the probability of this example being truly in-domain, according to our model.
As we can see, the three examples that the model thinks are general domain are “new
jersey,” “hospital” and “government.” It believes that “me,” “anything” and “kid” are all
in-domain. In general, the probabilities tend to be skewed toward 0 and 1, which is not
uncommon for naı̈ve Bayes models. We have shown two errors in this data. In the first,
our model thinks that “hospital” is a location when truly it is an organization. This is a
difficult distinction to make: in the training data, hospitals were often used as locations.
The second example error is “anything” in “is he capable of getting anything over
here.” The long-distance context of this example is a discussion about biological warfare
and Saddam Hussein, and “anything” is supposed to refer to a type of biological warhead.
Our model mistakingly thinks this is a person. This error is likely due to the fact that our
model identifies that the word “anything” is likely to be truly in-domain (the word is not
so common in newswire). It has also learned that most truly in-domain entities are people.
Thus, lacking evidence otherwise, the model incorrectly guesses that “anything” is a person.
It is interesting to observe that the model believes that the entity “me” in “gives me
chills” is closer to general domain than the “me” in “the fisher thing calling me ha ha they
screwed up.” This likely occurs because the context “ha ha” has not occurred anywhere in
the out-of-domain training data, and twice in the in-domain training data. It is unlikely this
example would have been misclassified otherwise (“me” is fairly clearly a person), but this
example shows that our model is able to take context into account in deciding the domain.
All of the decisions made by the model, shown in Table 3 seem qualitatively reasonable.
The numbers are perhaps excessively skewed, but the ranking is believable. The in-domain
data is primarily from conversations about random (not necessarily news worthy) topics,
and is hence highly colloquial. Contrastively, the out-of-domain data is from formal news.
The model is able to learn that entities like “new jersey” and “government” have more to
do with news that words like “me” and “kid.”
118

Domain Adaptation for Statistical Classifiers

π (i)
π (o)

Mention
Type
0.14
0.11

Mention
Tagging
0.41
0.45

Recap
CNN
0.36
0.40

Recap
ABC
0.51
0.69

Table 4: Values for the π variables discovered by the Mega Model algorithm.
7.2 Degree of Relatedness
In this section, we analyze the values of π found by the model. Low values of π (i) and
π (o) mean that the in-domain data was significantly different than the out-of-domain data;
high values mean that they were similar. This is because a high value for π means that
the general domain model will be used in most cases. For all tasks but Mention Type, the
values of π were middling around 0.4. For Mention Type, π (i) was 0.14 and π (o) was 0.11,
indicating that there was a significant difference between the in-domain and out-of-domain
data. The exact values for all tasks are shown in Table 4.
These values for π make intuitive sense. The distinction between conversation data
and news data (for the Mention Type task) is significantly stronger than the difference
between manually and automatically transcribed newswire (for the Mention Tagging task).
The values for π reflect this qualitative distinction. The rather strong difference between
the π values for the recapitalization tasks was not expected a priori. However, a post hoc
analysis shows this result is reasonable. We compute the KL divergence between a unigram
language model for the out-of-domain data set and each of the in-domain data sets. The
KL divergence for the CNN data was 0.07, while the divergence for the ABC data 0.11.
This confirms that the ABC data is perhaps more different from the baseline out-of-domain
than the CNN data, as reflected by the π values.
We are also interested in cases where there is little difference between in-domain and
out-of-domain data. To simulate this case, we have performed the following experiment.
We consider again the Mention Type task, but use only the training portion of the out-ofdomain data. We randomly split the data in half, assigning each half to “in-domain” and
“out-of-domain.” In theory, the model should learn that it may rely only on the general
domain model. We performed this experiment under ten fold cross-validation and found
that the average value of π selected by the model was 0.94. While this is strictly less than
one, it does show that the model is able to identify that these are very similar domains.

8. Conclusion and Discussion
In this paper, we have presented the Mega Model for domain adaptation in the discriminative (conditional) learning framework. We have described efficient optimization algorithms
based on the conditional EM technique. We have experimentally shown, in four data sets,
that our model outperforms a large number of baseline systems, including the current state
of the art model, and does so requiring significantly less in-domain data.
Although we focused specifically on discriminative modeling in a maximum entropy
framework, we believe the novel, basic idea on which this work is founded—to break the
in-domain distribution p(i) and out-of-domain distribution p(o) into three distributions, q (i) ,
119

Daumé III & Marcu

q (o) and q (g) —is general. In particular, one could perform a similar analysis in the case of
generative models and obtain similar algorithms (though in the case of a generative model,
standard EM could be used). Such a model could be applied to domain adaptation in
language modeling or machine translation.
With the exception of the work described in Section 2.2, previous work in-domain adaptation is quite rare, especially in the discriminative learning framework. There is a substantial literature in the language modeling/speech community, but most of the adaptation with
which they are concerned is based on adapting to new speakers (Iyer, Ostendorf, & Gish,
1997; Kalai, Chen, Blum, & Rosenfeld, 1999). From a learning perspective, the Mega
Model is most similar to a mixture of experts model. Our model can be seen as a constrained experts model, with three experts, where the constraints specify that in-domain
data can only come from one of two experts, and out-of-domain data can only come from
one of two experts (with a single expert overlapping between the two). Most attempts to
build discriminative mixture of experts models make heuristic approximations in order to
perform the necessary optimization (Jordan & Jacobs, 1994), rather than apply conditional
EM, which gives us strict guarantees that we monotonically increase the data (incomplete)
log likelihood of each iteration in training.
The domain adaptation problem is also closely related to multitask learning (also known
as learning to learn and inductive transfer). In multitask learning, one attempts to learn a
function that solves many machine learning problems simultaneously. This related problem
is discussed by Thrun (1996), Caruana (1997) and Baxter (2000), among others. The
similarity between multitask learning and domain adaptation is that they both deal with
data drawn from related, but distinct distributions. The primary difference is that domain
adaptation cares only about predicting one label type, while multitask learning cares about
predicting many.
As the various sub-communities of the natural language processing family begin and continue to branch out into domains other than newswire, the importance of developing models
for new domains without annotating much new data will become more and more important.
The Mega Model is a first step toward being able to migrate simple classification-style models (classifiers and maximum entropy Markov models) across domains. Continued research
in the area of adaptation is likely to benefit from other work done in active learning and in
learning with large amounts unannotated data.

Acknowledgments
We thank Ciprian Chelba and Alex Acero for making their data available. We thank Ryan
McDonald for pointing out the Feats baseline, which we had not previously considered.
We also thank Kevin Knight and Dragos Munteanu for discussions related to this project.
This paper was greatly improved by suggestions from reviewers, including reviewers of a
previous, shorter version. This work was partially supported by DARPA-ITO grant N6600100-1-9814, NSF grant IIS-0097846, NSF grant IIS-0326276, and a USC Dean Fellowship to
Hal Daumé III.
120

Domain Adaptation for Statistical Classifiers

Appendix A. Conditional Expectation Maximization
In this appendix, we derive Eq (10) from Eq (7) by making use of Jensen’s inequality and
the variational bound. The interested reader is referred to the work of Jebara and Pentland
(1998) for further details. Our discussion will consider a bound in the change of the log
likelihood between iteration t − 1 and iteration t, ∆l c , as given in Eq (14):



p y | x; Θt
p x, y | Θt /p y | Θt
∆l = log
= log
p (y | x; Θt−1 )
p (x, y | Θt−1 ) /p (y | Θt−1 )


t
p x, y; Θ
p x; Θt
= log
− log
p (x, y; Θt−1 )
p (x; Θt−1 )
c

(14)
(15)

Here, we have effectively rewritten the log-change in the ratio of the conditionals as the
difference between the log-change in the ratio of the joints and the log-change in the ratio
of the marginals. We may rewrite Eq (15) by introducing the hidden variables z as:


P
P
t
t
z p x, z; Θ
z p x, y, z; Θ
− log P
∆l = log P
t−1 )
t−1 )
z p (x, y, z; Θ
z p (x, z; Θ
c

(16)

We can now apply Jensen’s inequality to the first term in Eq (16) to obtain:

c

∆l ≥

X
z

"

 #


P
t
p x, y, z | Θt−1
p x, y, z; Θt
z p x, z; Θ
P
log
− log P
t−1 )
t−1 )
p (x, y, z; Θt−1 )
z 0 p (x, y, z | Θ
z p (x, z; Θ
|
{z
}

(17)

hx,y,z,Θt−1

In Eq (17), the expression denoted hx,y,z,Θt−1 is the joint expectation of z under the
previous iteration’s parameter settings. Unfortunately, we cannot also apply Jensen’s inequality to the remaining term in Eq (17) because it appears negated. By applying the
variational dual (log x ≤ x − 1) to this term, we obtain the following, final bound:
c

t

∆l ≥ Q =

X
z



P
t
p x, y, z; Θt
z p x, z; Θ
+1
hx,y,z,Θt−1 log
−P
t−1 )
p (x, y, z; Θt−1 )
z p (x, z; Θ

(18)

Applying the bound from Eq (18) to the distributions chosen in our model yields Eq (10).

Appendix B. Derivation of Estimation Equations
Given the model structure and parameterization of the Mega Modelgiven in Section 3.2,
Eq (5), we obtain the following expression for the joint probability of the data:
121

Daumé III & Marcu



p x, y, z | ψ (ν) , λ(ν) , π


F
N

Y
Y
zn
zn
Ber(xnf | ψ f )Gibbs(yn | xn , λ )
Ber(zn | π)
=


n=1
f =1



F 
N
Y
1−xnf
xnf 
Y

=
1 − ψ zfn
ψ zfn
π zn (1 − π)1−zn 

n=1
f =1
! 
h
i X
i −1 
h
exp λzynn > xn
exp λzcn > xn

c

(19)

The marginal distribution is obtained by removing the last two terms (the exp and the
sum of exps) from the final equation. Plugging Eq (19) into Eq (10) and using the notation
from Eq (12), we obtain the following expression for Qt :
Qt =

X
ν

+

N
X

n=1



log Nor(λ(ν) ; 0, σ 2 I) +
"

X
zn

(

F
X

f =1



(ν)

log Bet(ψ f ; a, b)

hn zn log π + (1 − zn ) log(1 − π) + log ψn,zn
+

F
X

xnf log λzynn

f =1

zn
−mt−1
n π (1

− π)

1−zn

− log

X
c

ψn,zn + 1

#

exp

h

λzcn > xn

i

−

t
jn,z
n

)
(20)

as well as an analogous term for the out-of-domain data. j and m are defined in Table 1.
B.1 M-Step for π
For computing π, we simply differentiate Qt (see Eq (20)) with respect to π, obtaining:
N

∂Qt X hn 1 − hn
=
+
+ mt−1
n (ψn,0 − ψn,1 )
∂π
π
1−π

(21)

n=1

solving this for 0 leads directly to a quadratic expression of the form:

0 = π

2

"
"

N
X

mt−1
n (ψn,0

n=1

+ π 1 −1 +

N
X

n=1

− ψn,1 )

#

2hn − mt−1
n (ψn,0 − ψn,1 )
122



#

Domain Adaptation for Statistical Classifiers

+ π

0

"

−

N
X

n=1

hn

#

(22)

Solving this directly for π gives the desired update equation.
B.2 M-Step for λ
For optimizing λ(i) , we rewrite Qt , Eq (20), neglecting all irrelevant terms, as:

Qt [λ] =

N
X

n=1

(1 − hn )


F
X


f =1

xnf λyn ,f − log

X
c

h

exp λc > xn


i


+ log Nor(λ; 0, σ 2 I)

(23)

In Eq (23), the bracketed expression is exactly the log-likelihood term obtained for
standard logistic regression models. Thus, the optimization of Q with respect to λ (i) and
λ(o) can be performed using a weighted version of standard logistic regression optimization,
with weights defined by (1−hn ). In the case of λ(g) , we obtain a weighted logistic regression
model, but over all N (i) + N (o) data points, and with weights defined by hn .
B.3 M-Step for ψ
In the case of ψ (i) and ψ (o) , we rewrite Eq (20) and remove all irrelevant terms, as:
Qt [ψ (i) ] =

F
X

f =1

log Bet(ψf ; a, b) +

N
X


n=1

(1 − hn ) log ψn,0 − mt−1
n (1 − π)ψn,0



(24)

Due to the presence of the product term in ψ, we cannot compute an analytical solution
to this maximization problem. However, we can take derivatives component-wise (in F )
and obtain analytical solutions (when combined with the prior). This admits an iterative
solution for maximizing Qtψ by maximizing each component separately until convergence.
Computing derivatives of Qt with respect to ψf requires differentiating ψn,0 with respect to
ψf ; this has a convenient form (recalling the notation from Table 1:
∂
∂
ψn,0 = [ψn,0,−f ]
{xnf ψf + (1 − xnf )(1 − ψf )} = ψn,0,−f
∂ψf
∂ψf

(25)

Using this result, we can maximize Qt with respect to ψf by solving:
"
N
X
xnf (1 − ψf ) − (1 − xnf )ψf
∂ h t i
(1 − hn )
Qψf
=
∂ψf
ψf (1 − ψf )
n=1
#

(26)

1
ψf (1 − ψf )
#
N
X
jn,0 (1 − π)ψn,0,−f
− ψf ) −

−jn,0 (1 − π)ψn,0,−f +

=

"
N
X
1
(1 − hn ) (xnf
1+
ψf (1 − ψf )
n=1

123

n=1

Daumé III & Marcu

Equating this to zero yields a quadratic expression of the form:

0 = (ψf )2
+ (ψf )

1

"

N
X

jn,0 (1
n=1
" N
X
−

"

− π)ψn,0,−f

#

1 − hn + jn,0 (1 − π)ψn,0,−f

n=1
N
X

+ (ψf )0 1 +

n=1

(1 − hn ) xnf

#



#
(27)
(o)

This final equation can be solved analytically. A similar expression arises for ψf . In
(g)

the case of ψf , we obtain a quadratic form with sums over the entire data set and with
hn replacing the occurrences of (1 − hn ):

0 =

+

+






N (i)
2 X
(i)
(i)
(g)

jn,1 π (i) ψ
ψ

n,1,−f

f

n=1

n=1

(g)

ψf

1

"




(g) 0 

ψf

+

(o)
N
X

N (i)

−

X

n=1

X

n=1

jn,1 π (o) ψn,1,−f 


(i)
h(i)
n + jn,1 π ψn,1,−f −

N (i)

1+

(i)

(i)

(o)

(o)

N (o)
(i)

h(i)
n xnf +

X

n=1



(o)




h(o)
n xnf

(o)
N
X

n=1

(o)

(o)

(o)
h(o)
n + jn,1 π ψn,1,−f



#
(28)

Again, this can be solved analytically. The values j, m, ψ·,· and ψ·,·,−· are defined in Table 1.

References
Averick, B. M., & Moré, J. J. (1994). Evaluation of large-scale optimization problems on
vector and parallel architectures. SIAM Journal of Optimization, 4.
Baxter, J. (2000). A model of inductive bias learning. Journal of Artificial Intelligence
Research, 12 , 149–198.
Bacchiani, M., & Roark, B. (2003). Unsupervised langauge model adaptation. In Proceedings
of the International Conference on Acoustics, Speech and Signal Processing (ICASSP).
Caruana, R. (1997). Multitask learning: A knowledge-based source of inductive bias. Machine Learning, 28 , 41–75.
Chelba, C., & Acero, A. (2004). Adaptation of maximum entropy classifier: Little data
can help a lot. In Proceedings of the Conference on Empirical Methods in Natural
Language Processing (EMNLP), Barcelona, Spain.
Chen, S., & Rosenfeld, R. (1999). A Gaussian prior for smoothing maximum entropy
models. Tech. rep. CMUCS 99-108, Carnegie Mellon University, Computer Science
Department.
124

Domain Adaptation for Statistical Classifiers

Della Pietra, S., Della Pietra, V. J., & Lafferty, J. D. (1997). Inducing features of random
fields. IEEE Transactions on Pattern Analysis and Machine Intelligence, 19 (4), 380–
393.
Dempster, A., Laird, N., & Rubin, D. (1977). Maximum likelihood from incomplete data
via the EM algorithm. Journal of the Royal Statistical Society, B39.
Elhadad, N., Kan, M.-Y., Klavans, J., & McKeown, K. (2005). Customization in a unified
framework for summarizing medical literature. Journal of Artificial Intelligence in
Medicine, 33 (2), 179–198.
Forman, G. (2003). An extensive empirical study of feature selection metrics for text classification. Journal of Machine Learning Research, 3, 1289–1305.
Gibbons, J. D., & Chakraborti, S. (2003). Nonparametric Statistical Inference. Marcel
Dekker, Inc.
Gildea, D. (2001). Corpus variation and parser performance. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).
Hobbs, J. R. (2002). Information extraction from biomedical text. Journal of Biomedical
Informatics, 35 (4), 260–264.
Huang, J., Zweig, G., & Padmanabhan, M. (2001). Information extraction from voicemail.
In Proceedings of the Conference of the Association for Computational Linguistics
(ACL).
Hwa, R. (1999). Supervised grammar induction using training data with limited constituent
information. In Proceedings of the Conference of the Association for Computational
Linguistics (ACL), pp. 73–79.
Iyer, R., Ostendorf, M., & Gish, H. (1997). Using out-of-domain data to improve in-domain
language models. IEEE Signal Processing, 4 (8).
Jebara, T., & Pentland, A. (1998). Maximum conditional likelihood via bound maximization
and the CEM algorithm. In Advances in Neural Information Processing Systems
(NIPS).
Jordan, M., & Jacobs, R. (1994). Hierarchical mixtures of experts and the EM algorithm.
Neural Computation, 6, 181–214.
Kalai, A., Chen, S., Blum, A., & Rosenfeld, R. (1999). On-line algorithms for combining
language models. In ICASSP.
Lafferty, J., McCallum, A., & Pereira, F. (2001). Conditional random fields: Probabilistic
models for segmenting and labeling sequence data. In Proceedings of the International
Conference on Machine Learning (ICML).
Malouf, R. (2002). A comparison of algorithms for maximum entropy parameter estimation.
In Proceedings of CoNLL.
McCallum, A., Freitag, D., & Pereira, F. (2000). Maximum entropy Markov models for
information extraction and segmentation. In Proceedings of the International Conference on Machine Learning (ICML).
125

Daumé III & Marcu

Minka, T. P. (2003). A comparison of numerical optimizers for logistic regression. http:
//www.stat.cmu.edu/~minka/papers/logreg/.
Munteanu, D., & Marcu, D. (2005). Improving machine translation performance by exploiting non-parallel corpora. Computational Linguistics, To appear.
Nash, S., & Nocedal, J. (1991). A numerical study of the limited memory BFGS method
and the truncated Newton method for large scale optimization. SIAM Journal of
Optimization, 1, 358–372.
Rambow, O., Shrestha, L., Chen, J., & Lauridsen, C. (2004). Summarizing email threads.
In Proceedings of the Conference of the North American Chapter of the Association
for Computational Linguistics (NAACL) Short Paper Section.
Roark, B., & Bacchiani, M. (2003). Supervised and unsupervised PCFG adaptation to
novel domains. In Proceedings of the Conference of the North American Chapter
of the Association for Computational Linguistics and Human Language Technology
(NAACL/HLT).
Smith, D. R. (1998). Variational Methods in Optimization. Dover Publications, Inc., Mineola, New York.
Thrun, S. (1996). Is learning the n-th thing any easier than learning the first. In Advances
in Neural Information Processing Systems (NIPS).

126

Journal of Artificial Intelligence Research 26 (2006) 191–246

Submitted 01/05; published 07/06

The Fast Downward Planning System
Malte Helmert

HELMERT @ INFORMATIK . UNI - FREIBURG . DE

Institut für Informatik
Albert-Ludwigs-Universität Freiburg
Georges-Köhler-Allee, Gebäude 052
79110 Freiburg, Germany

Abstract
Fast Downward is a classical planning system based on heuristic search. It can deal with general deterministic planning problems encoded in the propositional fragment of PDDL2.2, including
advanced features like ADL conditions and effects and derived predicates (axioms). Like other
well-known planners such as HSP and FF, Fast Downward is a progression planner, searching the
space of world states of a planning task in the forward direction. However, unlike other PDDL planning systems, Fast Downward does not use the propositional PDDL representation of a planning
task directly. Instead, the input is first translated into an alternative representation called multivalued planning tasks, which makes many of the implicit constraints of a propositional planning
task explicit. Exploiting this alternative representation, Fast Downward uses hierarchical decompositions of planning tasks for computing its heuristic function, called the causal graph heuristic,
which is very different from traditional HSP-like heuristics based on ignoring negative interactions
of operators.
In this article, we give a full account of Fast Downward’s approach to solving multi-valued
planning tasks. We extend our earlier discussion of the causal graph heuristic to tasks involving
axioms and conditional effects and present some novel techniques for search control that are used
within Fast Downward’s best-first search algorithm: preferred operators transfer the idea of helpful actions from local search to global best-first search, deferred evaluation of heuristic functions
mitigates the negative effect of large branching factors on search performance, and multi-heuristic
best-first search combines several heuristic evaluation functions within a single search algorithm
in an orthogonal way. We also describe efficient data structures for fast state expansion (successor
generators and axiom evaluators) and present a new non-heuristic search algorithm called focused
iterative-broadening search, which utilizes the information encoded in causal graphs in a novel
way.
Fast Downward has proven remarkably successful: It won the “classical” (i. e., propositional,
non-optimising) track of the 4th International Planning Competition at ICAPS 2004, following in
the footsteps of planners such as FF and LPG. Our experiments show that it also performs very
well on the benchmarks of the earlier planning competitions and provide some insights about the
usefulness of the new search enhancements.

1. Introduction
Consider a typical transportation planning task: The postal service must deliver a number of parcels
to their respective destinations using its vehicle fleet of cars and trucks. Let us assume that a car
serves all the locations of one city, and that different cities are connected via highways that are
served by trucks. For the sake of simplicity, let us further assume that travelling on each segment of
road or highway incurs the same cost. This is not a highly realistic assumption, but for the purposes
of exposition it will do. There can be any number of parcels, posted at arbitrary locations and with
c
2006
AI Access Foundation. All rights reserved.

H ELMERT

p2

B

F

c2
t
A

D

E

c1

G

C

c3

p1

Figure 1: A transportation planning task. Deliver parcel p 1 from C to G and parcel p2 from F to E,
using the cars c1 , c2 , c3 and truck t. The cars may only use inner-city roads (thin edges),
the truck may only use the highway (thick edge).

arbitrary destinations. Moreover, cities can be of varying size, there can be one or several cars
within each city, and there can be one or several trucks connecting the cities. Cars will never leave
a city. Fig. 1 shows an example task of this kind with two cities, three cars and a single truck. There
are two parcels to be delivered, one of which (p 1 ) must be moved between the two cities, while the
other (p2 ) can stay within its initial city.
The astute reader familiar with the planning literature will have noticed by now that we are
essentially describing the L OGISTICS domain, a standard benchmark for classical planning systems,
extended to roadmaps that are not complete graphs. (Part of) a propositional STRIPS-like encoding
of the task is shown in Fig. 2.
How would human planners go about solving tasks of this kind? Very likely, they would use a
hierarchical approach: For p1 , it is clear that the parcel needs to be moved between cities, which is
only possible by using the truck. Since in our example each city can access the highway at only one
location, we see that we must first load the parcel into some car at its initial location, then drop it off
at the first city’s highway access location, load it into the truck, drop it off at the other city’s highway
access location, load it into the only car in that city, and finally drop it off at its destination. We
can commit to this “high-level” plan for delivering p 1 without worrying about “lower-level” aspects
such as path planning for the cars. It is obvious to us that any good solution will have this structure,
since the parcel can only change its location in a few clearly defined ways (Fig. 3). The same figure
shows that the only reasonable plans for getting p 2 to its destination require loading it into the car
in its initial city and dropping it off at its target location. There is no point in ever loading it into the
truck or into any of the cars in the left city.
So say we have committed to the (partially ordered, as movements of the two parcels can be
interleaved) “high-level plan” shown in Fig. 5. All we need to do to complete the plan is choose
a linearization of the high-level steps and fill in movements of the vehicle fleet between them. We
have thus decomposed the planning task into a number of subproblems. The parcel scheduling
problem (where, and by which vehicles, a parcel should be loaded and unloaded) is separated from
the path planning problem for each vehicle in the fleet (how to move it from point X to Y). Both
192

T HE FAST D OWNWARD P LANNING S YSTEM

Variables:
at-p1-a, at-p1-b, at-p1-c, at-p1-d, at-p1-e,
at-p2-a, at-p2-b, at-p2-c, at-p2-d, at-p2-e,
at-c1-a, at-c1-b, at-c1-c, at-c1-d,
at-c2-a, at-c2-b, at-c2-c, at-c2-d,
at-c3-e, at-c3-f, at-c3-g,
at-t-d, at-t-e,
in-p1-c1, in-p1-c2, in-p1-c3, in-p1-t,
in-p2-c1, in-p2-c2, in-p2-c3, in-p2-t
Init:
at-p1-c, at-p2-f, at-c1-a, at-c2-b, at-c3-g,
Goal:
at-p1-g, at-p2-e
Operator drive-c1-a-d:
PRE: at-c1-a ADD: at-c1-d DEL: at-c1-a
Operator drive-c1-b-d:
PRE: at-c1-b ADD: at-c1-d DEL: at-c1-b
Operator drive-c1-c-d:
PRE: at-c1-c ADD: at-c1-d DEL: at-c1-c
...
Operator load-c1-p1-a:
PRE: at-c1-a, at-p1-a ADD: in-p1-c1 DEL:
Operator load-c1-p1-b:
PRE: at-c1-b, at-p1-b ADD: in-p1-c1 DEL:
Operator load-c1-p1-c:
PRE: at-c1-c, at-p1-c ADD: in-p1-c1 DEL:
...
Operator unload-c1-p1-a:
PRE: at-c1-a, in-p1-c1 ADD: at-p1-a DEL:
Operator unload-c1-p1-b:
PRE: at-c1-b, in-p1-c1 ADD: at-p1-b DEL:
Operator unload-c1-p1-c:
PRE: at-c1-c, in-p1-c1 ADD: at-p1-c DEL:
...

at-p1-f, at-p1-g,
at-p2-f, at-p2-g,

at-t-e

at-p1-a
at-p1-b
at-p1-c

in-p1-c1
in-p1-c1
in-p1-c1

Figure 2: Part of a typical propositional encoding of the transportation planning task (no actual
PDDL syntax).

193

H ELMERT

in c1
in t

at A

at B

at C

at D

at E

at F

in c2

at G

in c3

Figure 3: Domain transition graph for the parcels p 1 and p2 . Indicates how a parcel can change
its state. For example, the arcs between “at D” and “in t” correspond to the actions of
loading/unloading the parcel at location D with the truck t.

B
F

A

D

D

E

E

G
C

Figure 4: Domain transition graphs for the cars c 1 and c2 (left), truck t (centre), and car c3 (right).
Note how each graph corresponds to the part of the roadmap that can be traversed by the
respective vehicle.

load
c1-p1-c

unload
c1-p1-d

load
t-p1-d

unload
t-p1-e

load
c3-p2-f

unload
c3-p2-e

load
c3-p1-e

Figure 5: High-level plan for the transportation planning task.
194

unload
c3-p1-g

T HE FAST D OWNWARD P LANNING S YSTEM

c1

c2

c3

p1

p2

t

Figure 6: Causal dependencies in the transportation planning task.
of these are graph search problems, and the corresponding graphs are shown in Fig. 3 and Fig. 4.
Graphs of this kind will be formally introduced as domain transition graphs in Section 5.
Of course these graph search problems interact, but they only do so in limited ways: State
transitions for the parcels have associated conditions regarding the vehicle fleet, which need to be
considered in addition to the actual path planning in Fig. 3. For example, a parcel can only change
state from “at location A” to “inside car c 1 ” if the car c1 is at location A. However, state transitions
for the vehicles have no associated conditions from other parts of the planning task, and hence
moving a vehicle from one location to another is indeed as easy as finding a path in the associated
domain transition graph. We say that the parcels have causal dependencies on the vehicles because
there are operators that change the state of the parcels and have preconditions on the state of the
vehicles. Indeed, these are the only causal dependencies in this task, since parcels do not depend on
other parcels and vehicles do not depend on anything except themselves (Fig. 6). The set of causal
dependencies of a planning task is visualized in its causal graph.
We argue that humans often solve planning tasks in the hierarchical fashion outlined in the preceding paragraphs, and that algorithmic approaches to action planning can usefully apply similar
ideas. Indeed, as we will show in the following section, we are not the first to introduce domain transition graphs and causal graphs. However, earlier work has almost exclusively focused on acyclic
causal graphs, and for a good reason: If the causal graph of a planning task exhibits a cycle, hierarchical decomposition is not possible, because the subproblems that must be solved to achieve
an operator precondition are not necessarily smaller than the original task. As far as we are aware,
we were the first (Helmert, 2004) to present a general planning algorithm that focuses on exploiting hierarchical information from causal graphs. However, our causal graph heuristic also requires
acyclicity; in the general case, it considers a relaxed planning problem in which some operator
preconditions are ignored to break causal cycles.
Knowing that cycles in causal graphs are undesirable, we take a closer look at the transportation
planning task. Let us recall our informal definition of causal graphs: The causal graph of a planning
task contains a vertex for each state variable and arcs from variables that occur in preconditions to
variables that occur in effects of the same operator. So far, we may have given the impression that
the causal graph of the example task has the well-behaved shape shown in Fig. 6. Unfortunately,
having a closer look at the STRIPS encoding in Fig. 2, we see that this is not the case: The correct
causal graph, shown in Fig. 7, looks very messy. This discrepancy between the intuitive and actual
graph is due to the fact that in our informal account of “human-style” problem solving, we made
use of (non-binary) state variables like “the location of car c 1 ” or “the state of parcel p1 ”, while
STRIPS-level state variables correspond to (binary) object-location propositions like “parcel p 1 is
195

H ELMERT

Figure 7: Causal graph for the STRIPS encoding of the transportation planning task.
at location A”. It would be much nicer if we were given a multi-valued encoding of the planning
task that explicitly contains a variable for “the location of car c 1 ” and similar properties. Indeed,
the nice looking acyclic graph in Fig. 6 is the causal graph of the multi-valued encoding shown in
Fig. 8.
Having provided some intuition for its underlying concepts, let us now state our design goal
for the Fast Downward planning system: To develop an algorithm that efficiently solves general
propositional planning tasks by exploiting the hierarchical structure inherent in causal graphs. We
need to overcome three major obstacles in this undertaking:
• First, propositionally encoded planning tasks usually have very unstructured causal graphs.
However, the intuitive dependencies often become visible in encodings with multi-valued
state variables. To exploit this fact in an automated PDDL planning system, we have devised
an automatic algorithm for “translating” (or reformulating) propositional tasks to multi-valued
ones. The translation algorithm can be considered independently from the rest of the planner; in fact, it is now also used as part of other planning systems (van den Briel, Vossen, &
Kambhampati, 2005). To keep the article focused, we do not discuss the translation algorithm
here, referring to our earlier work for some of its central ideas (Edelkamp & Helmert, 1999).
Instead, we consider its output, a multi-valued planning task, as a base formalism.
• Second, no matter how clever the encoding is, most planning tasks are not completely hierarchical in nature. To deal with causal cycles, we consider relaxations where some causal
dependencies are ignored and use solutions to the relaxed problem within a heuristic search
algorithm.
• Third, even for planning tasks that can be solved hierarchically, finding such a solution is difficult (indeed, still PSPACE-complete). For this reason, our heuristic function only considers
a fragment of a task at a time, namely subproblems induced by a single state variable and its
predecessors in the causal graph. Even this planning problem is still NP-complete, so that we
196

T HE FAST D OWNWARD P LANNING S YSTEM

Variables:
p1, p2 ∈ {at-a, at-b, at-c, at-d, at-e, at-f, at-g,
in-c1, in-c2, in-c3, in-t}
c1, c2 ∈ {at-a, at-b, at-c, at-d}
c3
∈ {at-e, at-f, at-g}
t
∈ {at-d, at-e}
Init:
p1 = at-c, p2 = at-f
c1 = at-a, c2 = at-b, c3 = at-g, t = at-e
Goal:
p1 = at-g, p2 = at-e
Operator drive-c1-a-d:
PRE: c1 = at-a EFF: c1 = at-d
Operator drive-c1-b-d:
PRE: c1 = at-b EFF: c1 = at-d
Operator drive-c1-c-d:
PRE: c1 = at-c EFF: c1 = at-d
...
Operator load-c1-p1-a:
PRE: c1 = at-a, p1 = at-a EFF: p1 = in-c1
Operator load-c1-p1-b:
PRE: c1 = at-b, p1 = at-b EFF: p1 = in-c1
Operator load-c1-p1-c:
PRE: c1 = at-c, p1 = at-c EFF: p1 = in-c1
...
Operator unload-c1-p1-a:
PRE: c1 = at-a, p1 = in-c1 EFF: p1 = at-a
Operator unload-c1-p1-b:
PRE: c1 = at-b, p1 = in-c1 EFF: p1 = at-b
Operator unload-c1-p1-c:
PRE: c1 = at-c, p1 = in-c1 EFF: p1 = at-c
...
Figure 8: Part of an encoding of the transportation planning task with multi-valued state variables.

197

H ELMERT

are content with an incomplete solution algorithm within the heuristic solver. This solution
algorithm has theoretical shortcomings but never failed us in practice.
Having introduced the rationale of our approach, we discuss related work in the next section.
This is followed by an overview of the general architecture of the Fast Downward planning system in
Section 3. The planning system consists of three components: translation, knowledge compilation,
and search. The translation component converts PDDL2.2 tasks to multi-valued planning tasks,
which we formally introduce in Section 4. The knowledge compilation component is discussed in
Section 5, the search component in Section 6. We conclude with a presentation of experimental
results in Section 7 and some discussion in Section 8.

2. Related Work
As a planning system based on heuristic forward search, Fast Downward is clearly related to other
heuristic planners such as HSP (Bonet & Geffner, 2001) or FF (Hoffmann & Nebel, 2001) on the
architectural level. However, in this section we focus on work that is related on the conceptual level,
i. e., work that uses similar forms of hierarchical decomposition of causal graphs and work that uses
similar forms of search in domain transition graphs.
2.1 Causal Graphs and Abstraction
The term causal graph first appears in the literature in the work by Williams and Nayak (1997), but
the general idea is considerably older. The approach of hierarchically decomposing planning tasks
is arguably as old as the field of AI Planning itself, having first surfaced in Newell and Simon’s
(1963) work on the General Problem Solver.
Still, it took a long time for these notions to evolve to their modern form. Sacerdoti’s (1974)
ABSTRIPS algorithm introduced the concept of abstraction spaces for STRIPS-like planning tasks.
An abstraction space of a STRIPS task is the state space of an abstracted task, which is obtained
by removing all preconditions from the operators of the original task that belong to a given set of
propositions (which are abstracted away). 1 To solve a planning task, ABSTRIPS first generates a
plan for an abstracted task, then refines this plan by inserting concrete plans between the abstract
plan steps that “bridge the gap” between abstract states by satisfying the operator preconditions
which were ignored at the abstract level. The idea is easily generalized to several levels of abstraction forming an abstraction hierarchy, with a very abstract level at the top where almost all
preconditions are ignored, successively introducing more preconditions at every layer until the final
layer of the hierarchy equals the original planning task.
One problem with this approach to planning is that in general there is no guarantee that the
abstract plans bear any resemblance to reasonable concrete plans. For example, if abstraction spaces
are chosen badly, it is quite possible that finding a concrete plan that satisfies the precondition of the
first operator in the abstract plan is more difficult than solving the original goal at the concrete level.
Such shortcomings spawned a large amount of research on the properties of abstraction hierarchies
and how they can be generated automatically.
1. In later work by other authors, propositions which are abstracted away are also removed from the operator effects.
This only makes a difference in subtle cases that require the presence of axioms; we do not distinguish between these
two kinds of abstraction here.

198

T HE FAST D OWNWARD P LANNING S YSTEM

Tenenberg (1991) gives one of the first formal accounts of the properties of different kinds of
abstraction. Among other contributions, he defines the so-called upward solution property, which
can be informally stated as: “If there exists a concrete solution, then there also exists an abstract
solution”. Rather surprisingly, not all abstractions considered at the time satisfied this very basic
property, without which one would be loathe to call a given state space an “abstraction” of another
state space.
A limitation of the upward solution property is that it states no relationship between the concrete
and abstract plan at all. For ABSTRIPS-style hierarchical planning to be successful, the abstract
plan must bear some resemblance to a concrete one; otherwise there is little point in trying to
refine it. Indeed, Tenenberg introduces stronger versions of the upward solution property, but more
relevant to Fast Downward is Knoblock’s (1994) work on the ordered monotonicity property. An
abstraction space satisfies the ordered monotonicity property if, roughly speaking, any concrete
solution can be derived from some abstract solution while leaving the actions in the abstract plan
intact and relevant to the concrete plan. Clearly, this is a very important property for ABSTRIPSlike hierarchical planning.
It is in Knoblock’s article that causal graphs first surface (although he does not introduce a name
for them). Translated to our terminology, Knoblock proves the following relationship between
useful abstractions and causal graphs: If the causal graph contains no path from a variable that
is not abstracted away to a variable that is abstracted away, then the abstraction has the ordered
monotonicity property. In particular, this means that for acyclic causal graphs, it is possible to devise
an abstraction hierarchy where only one new variable is introduced at each level.
Besides these theoretical contributions, Knoblock presents a planning system called ALPINE
which computes an abstraction hierarchy for a planning task from its causal graph and exploits
this within a hierarchical refinement planner. Although the planning method is very different, the
derivation of the abstraction hierarchy is very similar to Fast Downward’s method for generating
hierarchical decompositions of planning tasks (Section 5.2).
By itself, the ordered monotonicity property is not sufficient to guarantee good performance
of a hierarchical planning approach. It guarantees that every concrete solution can be obtained in
a natural way from an abstract solution, but it does not guarantee that all abstract solutions can
be refined to concrete ones. Such a guarantee is provided by the downward refinement property,
introduced by Bacchus and Yang (1994).
The downward refinement property can rarely be guaranteed in actual planning domains, so
Bacchus and Yang develop an analytical model for the performance of hierarchical planning in situations where a given abstract plan can only be refined with a certain probability p < 1. Based on
this analysis, they present an extension to ALPINE called HIGHPOINT, which selects an abstraction hierarchy with high refinement probability among those that satisfy the ordered monotonicity
property. In practice, it is not feasible to compute the refinement probability, so HIGHPOINT approximates this value based on the notion of k-ary necessary connectivity.
2.2 Causal Graphs and Unary STRIPS Operators
Causal graphs are first given a name by Jonsson and Bäckström (1995, 1998b), who call them
dependency graphs. They study a fragment of propositional STRIPS with negative conditions which
has the interesting property that plan existence can be decided in polynomial time, but minimal
solutions to a task can be exponentially long, so that no polynomial planning algorithm exists. They
199

H ELMERT

present an incremental planning algorithm with polynomial delay, i. e., a planning algorithm that
decides within polynomial time whether or not a given task has a solution, and, if so, generates such
a solution step by step, requiring only polynomial time between any two subsequent steps. 2
The fragment of STRIPS covered by Jonsson and Bäckström’s algorithm is called 3S and is
defined by the requirement that the causal graph of the task is acyclic and each state variables
is static, symmetrically reversible, or splitting. Static variables are those for which it is easy to
guarantee that they never change their value in any solution plan. These variables can be detected
and compiled away easily. Symmetrically reversible variables are those where for each operator
which makes them true there is a corresponding operator with identical preconditions which makes
them false, and vice versa. In other words, a variable is symmetrically reversible iff its domain
transition graph is undirected. Finally, a variable v is splitting iff its removal from the causal graph
weakly disconnects its positive successors (those variables which appear in effects of operators of
which v is a precondition) from its negative successors (those variables which appear in effects of
operators of which ¬v is a precondition).
Williams and Nayak (1997) independently prove that incremental (or, in their setting, reactive)
planning is a polynomial problem in a STRIPS-like setting where causal graphs are acyclic and
all operators are reversible. If all operators are reversible (according to the definition by Williams
and Nayak), all variables are symmetrically reversible (according to the definition by Jonsson and
Bäckström), so this is actually a special case of the previous result. However, Williams and Nayak’s
work applies to a more general formalism than propositional STRIPS, so that the approaches are
not directly comparable.
More recently, Domshlak and Brafman provide a detailed account of the complexity of finding plans in the propositional STRIPS (with negation) formalism with unary operators and acyclic
graphs (Domshlak & Brafman, 2002; Brafman & Domshlak, 2003). 3 Among other results, they
prove that the restriction to unary operators and acyclic graphs does not reduce the complexity
of plan existence: the problem is PSPACE-complete, just like unrestricted propositional STRIPS
planning (Bylander, 1994). They also show that for singly connected causal graphs, shortest plans
cannot be exponentially long, but the problem is still NP-complete. For an even more restricted class
of causal graphs, namely polytrees of bounded indegree, they present a polynomial planning algorithm. More generally, their analysis relates the complexity of STRIPS planning in unary domains
to the number of paths in their causal graph.
2.3 Multi-Valued Planning Tasks
With the exception of Williams and Nayak’s paper, all the work discussed so far exclusively deals
with propositional planning problems, where all state variables assume values from a binary domain. As we observed in the introduction, the question of propositional vs. multi-valued encodings
usually has a strong impact on the connectivity of the causal graph of a task. In fact, apart from the
trivial M OVIE domain, none of the common planning benchmarks exhibits an acyclic causal graph
2. However, there is no guarantee that the length of the generated solution is polynomially related to the length of an
optimal solution; it might be exponentially longer. Therefore, the algorithm might spend exponential time on tasks
that can be solved in polynomial time.
3. According to our formal definition of causal graphs in Section 5.2, operators with several effects always induce
cycles in the causal graph, so acyclic causal graph implies unary operators. Some researchers define causal graphs
differently, so we name both properties explicitly here.

200

T HE FAST D OWNWARD P LANNING S YSTEM

when considering its propositional representation. By contrast, the multi-valued encoding of our
introductory example does have an acyclic causal graph.
Due to the dominance of the PDDL (and previously, STRIPS) formalism, non-binary state variables are not studied very often in the classical planning literature. One of the most important exceptions to this rule is the work on the SAS + planning formalism, of which the papers by Bäckström
and Nebel (1995) and Jonsson and Bäckström (1998a) are most relevant to Fast Downward. The
SAS+ planning formalism is basically equivalent to the multi-valued planning tasks we introduce
in Section 4 apart from the fact that it does not include derived variables (axioms) or conditional
effects. Bäckström and Nebel analyse the complexity of various subclasses of the SAS + formalism and discover three properties (unariness, post-uniqueness and single-valuedness) that together
allow optimal planning in polynomial time. One of these three properties (unariness) is related to
acyclicity of causal graphs, and one (post-uniqueness) implies a particularly simple shape of domain
transition graphs (namely, in post-unique tasks, all domain transition graphs must be simple cycles
or trees).
Bäckström and Nebel do not analyse domain transition graphs formally. Indeed, the term is only
introduced in the later article by Jonsson and Bäckström (1998a), which refines the earlier results
by introducing five additional restrictions for SAS + tasks, all of which are related to properties of
domain transition graphs.
Neither of these two articles discusses the notion of causal graphs. Indeed, the only earlier work
we are aware of which includes both causal graphs and domain transition graphs as central concepts
is the article by Domshlak and Dinitz (2001) on the state-transition support (STS) problem, which
is essentially equivalent to SAS+ planning with unary operators. In the context of STS, domain
transition graphs are called strategy graphs and causal graphs are called dependence graphs, but
apart from minor details, the semantics of the two formalisms are identical. Domshlak and Dinitz
provide a map of the complexity of the STS problem in terms of the shape of its causal graph,
showing that the problem is NP-complete or worse for almost all non-trivial cases. One interesting
result is that if the causal graph is a simple chain of n nodes and all variables are three-valued,
the length of minimal plans can already grow as Ω(2 n ). By contrast, propositional tasks with the
same causal graph shape admit polynomial planning algorithms according to the result by Brafman
and Domshlak (2003), because such causal graphs are polytrees with a constant indegree bound
(namely, a bound of 1).
To summarize and conclude our discussion of related work, we observe that the central concepts of Fast Downward and the causal graph heuristic, such as causal graphs and domain transition
graphs, are firmly rooted in previous work. However, Fast Downward is the first attempt to marry
hierarchical problem decomposition to the use of multi-valued state variables within a general planning framework. It is also the first attempt to apply techniques similar to those of Knoblock (1994)
and Bacchus and Yang (1994) within a heuristic search planner.
The significance of this latter point should not be underestimated: For classical approaches to
hierarchical problem decomposition, it is imperative that an abstraction satisfies the ordered monotonicity property, and it is important that the probability of being able to refine an abstract plan
to a concrete plan is high, as the analysis by Bacchus and Yang shows. Unfortunately, non-trivial
abstraction hierarchies are rarely ordered monotonic, and even more rarely guarantee high refinement probabilities. Within a heuristic approach, these “must-haves” turn into “nice-to-haves”: If
an abstraction hierarchy is not ordered monotonic or if an abstract plan considered by the heuristic
evaluator is not refinable, this merely reduces the quality of the heuristic estimate, rather than caus201

H ELMERT

Translation
•
•
•
•

Normalization
Invariant synthesis
Grounding
Translation to MPT

Knowledge
Compilation
• Domain transition
graphs
• Causal graph
• Successor generator
• Axiom evaluator

Search
•
•
•
•
•

Causal graph heuristic
FF heuristic
Greedy best-first search
Multi-heuristic best-first search
Focused iterative-broadening search

Figure 9: The three phases of Fast Downward’s execution.
ing the search to fail (in the worst case) or spend a long time trying to salvage non-refinable abstract
plans (in the not much better case).

3. Fast Downward
We will now describe the overall architecture of the planner. Fast Downward is a classical planning
system based on the ideas of heuristic forward search and hierarchical problem decomposition. It
can deal with the full range of propositional PDDL2.2 (Fox & Long, 2003; Edelkamp & Hoffmann,
2004), i. e., in addition to STRIPS planning, it supports arbitrary formulae in operator preconditions
and goal conditions, and it can deal with conditional and universally quantified effects and derived
predicates (axioms).
The name of the planner derives from two sources: Of course, one of these sources is Hoffmann’s very successful FF (“Fast Forward”) planner (Hoffmann & Nebel, 2001). Like FF, Fast
Downward is a heuristic progression planner, i. e., it computes plans by heuristic search in the space
of world states reachable from the initial situation. However, compared to FF, Fast Downward uses
a very different heuristic evaluation function called the causal graph heuristic. The heuristic evaluator proceeds “downward” in so far as it tries to solve planning tasks in the hierarchical fashion
outlined in the introduction. Starting from top-level goals, the algorithm recurses further and further
down the causal graph until all remaining subproblems are basic graph search tasks.
Similar to FF, the planner has shown excellent performance: The original implementation of the
causal graph heuristic, plugged into a standard best-first search algorithm, outperformed the previous champions in that area, FF and LPG (Gerevini, Saetti, & Serina, 2003), on the set of STRIPS
benchmarks from the first three international planning competitions (Helmert, 2004). Fast Downward itself followed in the footsteps of FF and LPG by winning the propositional, non-optimizing
track of the 4th International Planning Competition at ICAPS 2004 (referred to as IPC4 from now
on).
As mentioned in the introduction, Fast Downward solves a planning task in three phases (Fig. 9):
• The translation component is responsible for transforming the PDDL2.2 input into a nonbinary form which is more amenable to hierarchical planning approaches. It applies a number of normalizations to compile away syntactic constructs like disjunctions which are not
directly supported by the causal graph heuristic and performs grounding of axioms and operators. Most importantly, it uses invariant synthesis methods to find groups of related propo202

T HE FAST D OWNWARD P LANNING S YSTEM

sitions which can be encoded as a single multi-valued variable. The output of the translation
component is a multi-valued planning task, defined in the following section.
• The knowledge compilation component generates four kinds of data structures that play a
central role during search: Domain transition graphs encode how, and under what conditions,
state variables can change their values. The causal graph represents the hierarchical dependencies between the different state variables. The successor generator is an efficient data
structure for determining the set of applicable operators in a given state. Finally, the axiom
evaluator is an efficient data structure for computing the values of derived variables. The
knowledge compilation component is described in Section 5.
• The search component implements three different search algorithms to do the actual planning.
Two of these algorithms make use of heuristic evaluation functions: One is the well-known
greedy best-first search algorithm, using the causal graph heuristic. The other is called multiheuristic best-first search, a variant of greedy best-first search that tries to combine several
heuristic evaluators in an orthogonal way; in the case of Fast Downward, it uses the causal
graph and FF heuristics. The third search algorithm is called focused iterative-broadening
search; it is closely related to Ginsberg and Harvey’s (1992) iterative broadening. It is not
a heuristic search algorithm in the sense that it does not use an explicit heuristic evaluation
function. Instead, it uses the information encoded in the causal graph to estimate the “usefulness” of operators towards satisfying the goals of the task. The search component is described
in Section 6.

4. Multi-Valued Planning Tasks
Let us now formally introduce the problem of planning with multi-valued state variables. Our
formalism is based on the SAS+ planning model (Bäckström & Nebel, 1995; Jonsson & Bäckström,
1998a), but extends it with axioms and conditional effects.
Definition 1 Multi-valued planning tasks (MPTs)
A multi-valued planning task (MPT) is given by a 5-tuple Π = hV, s 0 , s? , A, Oi with the following
components:
• V is a finite set of state variables, each with an associated finite domain D v . State variables are partitioned into fluents (affected by operators) and derived variables (computed by
evaluating axioms). The domains of derived variables must contain the undefined value ⊥.
A partial variable assignment or partial state over V is a function s on some subset of V such
that s(v) ∈ Dv wherever s(v) is defined. A partial state is called an extended state if it is
defined for all variables in V and a reduced state or state if it is defined for all fluents in V.
In the context of partial variable assignments, we write v = d for the variable-value pairing
(v, d) or v 7→ d.
• s0 is a state over V called the initial state.
• s? is a partial variable assignment over V called the goal.
• A is a finite set of (MPT) axioms over V. Axioms are triples of the form hcond, v, di, where
cond is a partial variable assignment called the condition or body of the axiom, v is a derived
203

H ELMERT

variable called the affected variable, and d ∈ D v is called the derived value for v. The pair
(v, d) is called the head of the axiom and can be written as v := d.
The axiom set A is partitioned into a totally ordered set of axiom layers A 1 ≺ · · · ≺ Ak
such that within the same layer, each affected variable may only be associated with a single
value in axiom heads and bodies. In other words, within the same layer, axioms with the
same affected variable but different derived values are forbidden, and if a variable appears
in an axiom head, then it may not appear with a different value in a body. This is called the
layering property.
• O is a finite set of (MPT) operators over V. An operator hpre, effi consists of a partial
variable assignment pre over V called its precondition, and a finite set of effects eff. Effects
are triples hcond, v, di, where cond is a (possibly empty) partial variable assignment called
the effect condition, v is a fluent called the affected variable, and d ∈ D v is called the new
value for v.
For axioms and effects, we also use the notation cond → v := d in place of hcond, v, di.
To provide a formal semantics for MPT planning, we first need to formalize axioms:
Definition 2 Extended states defined by a state
Let s be a state of an MPT Π with axioms A, layered as A 1 ≺ · · · ≺ Ak . The extended state defined
by s, written as A(s), is the result s 0 of the following algorithm:
algorithm evaluate-axioms(A1 , . . . , Ak , s):
for each variable
( v:
s(v) if v is a fluent variable
s0 (v) :=
⊥
if v is a derived variable
for i ∈ {1, . . . , k}:
while there exists an axiom (cond → v := d) ∈ A i with cond ⊆ s0 and s0 (v) 6= d:
Choose such an axiom cond → v := d.
s0 (v) := d
In other words, axioms are evaluated in a layer-by-layer fashion using fixed point computations,
which is very similar to the semantics of stratified logic programs. It is easy to see that the layering
property from Definition 1 guarantees that the algorithm terminates and produces a deterministic
result. Having defined the semantics of axioms, we can now define the state space of an MPT:
Definition 3 MPT state spaces
The state space of an MPT Π = hV, s0 , s? , A, Oi, denoted as S(Π), is a directed graph. Its vertex
set is the set of states of V, and it contains an arc (s, s 0 ) iff there exists some operator hpre, effi ∈ O
such that:
• pre ⊆ A(s),
• s0 (v) = d for all effects cond → v := d ∈ eff such that cond ⊆ A(s), and
• s0 (v) = s(v) for all other fluents.
204

T HE FAST D OWNWARD P LANNING S YSTEM

Finally, we can define the MPT planning problem:
Definition 4 MPT planning
MPT-P LAN E X is the following decision problem: Given an MPT Π with initial state s 0 and goal
s? , does S(Π) contain a path from s0 to some state s0 with s? ⊆ A(s0 )?
MPT-P LANNING is the following search problem: Given an MPT Π with initial state s 0 and goal
s? , compute a path in S(Π) from s0 to some state s0 with s? ⊆ A(s0 ), or prove that none exists.
The MPT-P LAN E X problem is easily shown to be PSPACE-hard because it generalizes the plan
existence problem for propositional STRIPS, which is known to be PSPACE-complete (Bylander,
1994). It is also easy to see that the addition of multi-valued domains, axioms and conditional effects
does not increase the theoretical complexity of MPT planning beyond propositional STRIPS. Thus,
we conclude our formal introduction of MPT planning by stating that MPT-P LAN E X is PSPACEcomplete, and turn to the practical side of things in the following section.

5. Knowledge Compilation
The purpose of the knowledge compilation component is to set the stage for the search algorithms
by compiling the critical information about the planning task into a number of data structures for efficient access. In other contexts, computations of this kind are often called preprocessing. However,
“preprocessing” is such a nondescript word that it can mean basically anything. For this reason, we
prefer a term that puts a stronger emphasis on the role of this module: To rephrase the critical information about the planning task in such a way that it is directly useful to the search algorithms. Of
the three building blocks of Fast Downward (translation, knowledge compilation, search), it is the
least time-critical part, always requiring less time than translation and being dominated by search
for all but the most trivial tasks.
Knowledge compilation comprises three items. First and foremost, we compute the domain
transition graph of each state variable. The domain transition graph for a state variable encodes
under what circumstances that variable can change its value, i. e., from which values in the domain
there are transitions to which other values, which operators or axioms are responsible for the transition, and which conditions on other state variables are associated with the transition. Domain
transition graphs are described in Section 5.1. They are a central concept for the computation of the
causal graph heuristic, described in Section 6.1.
Second, we compute the causal graph of the planning task. Where domain transition graphs encode dependencies between values for a given state variable, the causal graph encodes dependencies
between different state variables. For example, if a given location in a planning task can be unlocked
by means of a key that can be carried by the agent, then the variable representing the lock state of
the location is dependent on the variable that represents whether or not the key is being carried.
This dependency is encoded as an arc in the causal graph. Like domain transition graphs, causal
graphs are a central concept for the computation of the causal graph heuristic, giving it its name.
The causal graph heuristic requires causal graphs to be acyclic. For this reason, the knowledge compilation component also generates an acyclic subgraph of the real causal graph when cycles occur.
This amounts to a relaxation of the planning task where some operator preconditions are ignored.
In addition to their usefulness for the causal graph heuristic, causal graphs are also a key concept
of the focused iterative-broadening search algorithm introduced in Section 6.5. We discuss causal
graphs in Section 5.2.
205

H ELMERT

Third, we compute two data structures that are useful for any forward-searching algorithm for
MPTs, called successor generators and axiom evaluators. Successor generators compute the set
of applicable operators in a given world state, and axiom evaluators compute the values of derived
variables for a given reduced state. Both are designed to do their job as quickly as possible, which
is especially important for the focused iterative-broadening search algorithm, which does not compute heuristic estimates and thus requires the basic operations for expanding a search node to be
implemented efficiently. These data structures are discussed in Section 5.3.
5.1 Domain Transition Graphs
The domain transition graph of a state variable is a representation of the ways in which the variable
can change its value, and of the conditions that must be satisfied for such value changes to be allowed. Domain transition graphs were introduced by Jonsson and Bäckström (1998a) in the context
of SAS+ planning. Our formalization of domain transition graphs generalizes the original definition
to planning tasks involving axioms and conditional effects.
Definition 5 Domain transition graphs
Let Π = hV, s0 , s? , A, Oi be a multi-valued planning task, and let v ∈ V be a state variable of Π.
The domain transition graph of v, in symbols DTG(v), is a labelled directed graph with vertex
set Dv . If v is a fluent, DTG(v) contains the following arcs:
• For each effect cond → v := d0 of an operator o with precondition pre such that pre ∪ cond
contains some condition v = d, an arc from d to d 0 labelled with pre ∪ cond \ {v = d}.
• For each effect cond → v := d0 of an operator o with precondition pre such that pre ∪ cond
does not contain the condition v = d for any d ∈ D v , an arc from each d ∈ Dv \ {d0 } to d0
labelled with pre ∪ cond.
If v is a derived variable, DTG(v) contains the following arcs:
• For each axiom cond → v := d0 ∈ A such that cond contains some condition v = d, an arc
from d to d0 labelled with cond \ {v = d}.
• For each axiom cond → v := d0 ∈ A such that cond does not contain the condition v = d
for any d ∈ Dv , an arc from each d ∈ Dv \ {d0 } to d0 labelled with cond.
Arcs of domain transition graphs are called transitions. Their labels are referred to as the
conditions of the transition.
Domain transition graphs can be weighted, in which case each transition has an associated
non-negative integer weight. Unless stated otherwise, we assume that all transitions derived from
operators have weight 1 and all transitions derived from axioms have weight 0.
The definition is somewhat lengthy, but its informal content is easy to grasp: The domain transition graph for v contains a transition from d to d 0 if there exists some operator or axiom that can
change the value of v from d to d0 . Such a transition is labelled with the conditions on other state
variables that must be true if the transition shall be applied. Multiple transitions between the same
values using different conditions are allowed and occur frequently.
We have already seen domain transition graphs in the introductory section (Figs. 3 and 4), although they were only introduced informally and did not show the arc labels usually associated
206

T HE FAST D OWNWARD P LANNING S YSTEM

d = open
(1, 1)

(2, 1)

(3, 1)

(2, 1)

(2, 2)

(3, 2)

r=

r = (1, 1), k = carried

closed

r = (2, 2), k = carried

r=

open

(1, 2)

(1,

1)

1)

2)
(1,
r=

2)
(1,

r = (2, 1)

(1,

r = (2, 1)

r=

r=

r=

(3, 1)

1)
(3,

r=
r=

carried

r = (2, 2)

(1, 2)

(1, 1)

r = (2, 2)

d = open

d = open

(3,

(3,
(3,

2)

1)

2)

(3, 2)

r = (3, 1), k = carried
(2, 2)

Figure 10: Domain transition graphs of a G RID task. Top left: DTG(r) (robot); right: DTG(k)
(key); bottom left: DTG(d) (door).

with transitions. Fig. 10 shows some examples from a simple task in the G RID domain, featuring a 3 × 2 grid with a single initially locked location in the centre of the upper row, unlockable
by a single key. In the MPT encoding of the task, there are three state variables: variable r with
Dr = { (x, y) | x ∈ {1, 2, 3}, y ∈ {1, 2} } encodes the location of the robot, variable k with
Dk = Dr ∪ {carried} encodes the state of the key, and variable d with D d = {closed, open}
encodes the state of the initially locked grid location.
If all operators of an MPT are unary (i. e., only have a single effect) and we leave aside axioms
for a moment, then there is a strong correspondence between the state space of an MPT and its
domain transition graphs. Since vertices in domain transition graphs correspond to values of state
variables, a given state is represented by selecting one vertex in each domain transition graph, called
the active vertex of this state variable. Applying an operator means changing the active vertex
of some state variable by performing a transition in the corresponding domain transition graph.
Whether or not such a transition is allowed depends on its condition, which is checked against the
active vertices of the other domain transition graphs.
Let us use the G RID example to illustrate this correspondence. Consider an initial state where
the robot is at location (1, 1), the key is at location (3, 2), and the door is locked. We represent this
by placing pebbles on the appropriate vertices of the three domain transition graphs. We want to
move the pebble in the domain transition graph of the key to location (2, 1). This can be done by
moving the robot pebble to vertex (1, 2), then (2, 2), then (3, 2), moving the key pebble to the vertex
carried, moving the robot pebble back to vertex (2, 2), moving the door pebble to open, moving the
robot pebble to vertex (2, 1) and finally moving the key pebble to vertex (2, 1).
207

H ELMERT

d = open, r = (1, 1)
d = open, r = (3, 1)

d = open, r = (1, 1)

d = closed
⊥

>

⊥

r = (2, 1)

>

r = (1, 2)

d = open, r = (3, 1)

r = (2, 2)
r = (3, 2)

Figure 11: Domain transition graphs for the freezing variable in the G RID task, normal (left) and
extended (right). Note that only the extended graph shows how to change state from
“freezing” (>) to “not freezing” (⊥).

The example shows how plan execution can be viewed as simultaneous traversal of domain
transition graphs (cf. Domshlak & Dinitz, 2001). This is an important notion for Fast Downward
because the causal graph heuristic computes its heuristic estimates by solving subproblems of the
planning task by looking for paths in domain transition graphs in basically the way we have described.
As mentioned before, this view of MPT planning is only completely accurate for unary tasks
without axioms, for which the domain transition graphs are indeed a complete representation of the
state space. For non-unary operators, we would need to “link” certain transitions in different domain
transition graphs which belong to the same operator. These could then only be executed together.
For axioms, we would need to mark certain transitions as “mandatory”, requiring that they be taken
whenever possible. (This is only intended as a rough analogy and leaves out details like layered
axioms.)
In our previous work (Helmert, 2004), we have successfully applied this view of planning to
STRIPS tasks. Extending the notion to plans with conditional effects provides no challenges because domain transition graphs always consider planning operators one effect at a time, in which
case effect condition can simply be seen as part of the operator precondition. However, axioms
provide a challenge that is easily overlooked. If we want to change the value of a fluent from d to
d0 , the domain transition graph contains all the important information; just find a path from d to d 0
and try to find out how the associated conditions can be achieved. Consider the same problem for
a derived state variable. Let us assume that unlocking the location in the G RID example leads to a
drought, causing the robot to freeze if it enters a horizontally adjacent location. We could encode
this with a new derived variable f (for freezing) with domain D f = {>, ⊥}, defined by the axioms
d = open, r = (1, 1) → f := > and d = open, r = (3, 1) → f := >. The domain transition graph
DTG(f ) is depicted in Fig. 11 (left).
The problem with that domain transition graph is that it does not tell us how we can change the
state of variable f from > to ⊥. In general, in MPTs derived from STRIPS tasks where derived
predicates occur negatively in any condition, the domain transition graph does not contain sufficient
information for changing the value of a derived variable from “true” to “false”. Derived variables
208

T HE FAST D OWNWARD P LANNING S YSTEM

never assume the value ⊥ due to a derivation of this value; because of negation as failure semantics,
they only assume the value by default if no other value can be derived. If we want to reason about
ways of setting the value of a derived variable to ⊥, we will need to make this information explicit.
In logical notation, whether or not a derived variable assumes a given value by triggering an
axiom at a given layer is determined by a formula in disjunctive normal form, with one disjunct
for each axiom setting the value. For example, our axioms d = open, r = (1, 1) → f := > and
d = open, r = (3, 1) → f := > correspond to the DNF formula (d = open ∧ r = (1, 1)) ∨ (d =
open ∧r = (3, 1)). If we want to know when these rules do not trigger, we must negate this formula,
leading to the CNF formula (d 6= open ∨r 6= (1, 1))∧(d 6= open ∨r 6= (3, 1)). To be able to encode
this information in the domain transition graph, we need to replace the inequalities with equalities
and translate the formula back to DNF. Since such transformations can increase the formula size
dramatically, we apply simplifications along the way, removing duplicated and dominated disjuncts.
The result in this case is the DNF formula d = closed ∨ r = (2, 1) ∨ r = (1, 2) ∨ r = (2, 2) ∨ r =
(3, 2).
A domain transition graph for a derived variable which has been enriched to contain the possible
ways of causing the variable to assume the value ⊥ is called an extended domain transition graph,
as shown for the G RID example in Fig. 11 (right). Since computing the extended domain transition
graph can be costly and is not always necessary, the knowledge compilation component scans the
conditions of the planning task (axioms, operator preconditions and effect conditions, goal) for
occurrences of pairings of the type v = ⊥ for derived variables v. Extended domain transition
graphs are only computed for those derived variables for which they are required.
Note that negative occurrences of derived variables can cascade: If u, v and w are derived
variables with domain {>, ⊥} and the condition v = ⊥ is present in some operator precondition,
and moreover v is defined by the axiom u = >, w = > → v := >, then v assumes the value ⊥
whenever u or w do, so we would require extended domain transition graphs for u and w as well.
On the other hand, multiple layers of negation as failure can cancel each other out: If derived
variable v only occurs in conditions of the form v = ⊥ but never in positive form and is defined by
the axiom u = ⊥, w = ⊥ → v := >, then we do not necessarily require extended domain transition
graphs for u and w.
In general, whether or not we need extended domain transition graphs for a derived variable is
determined by the following rules:
• If v is a derived variable for which the condition v = d for d 6= ⊥ appears in an operator
precondition, effect condition or in the goal, then v is used positively.
• If v is a derived variable for which the condition v = ⊥ appears in an operator precondition,
effect condition or in the goal, then v is used negatively.
• If v is a derived variable for which the condition v = d for d 6= ⊥ appears in the body of an
axiom whose head is used positively (negatively), then v is used positively (negatively).
• If v is a derived variable for which the condition v = ⊥ appears in the body of an axiom
whose head is used positively (negatively), then v is used negatively (positively).
The knowledge compilation component computes extended domain transition graphs for all derived variables which are used negatively and (standard) domain transition graphs for all other state
variables. Normal domain transition graphs are computed by going through the set of axioms and
209

H ELMERT

the set of operator effects following Definition 5, which is reasonably straight-forward; the computation of extended domain transition graphs has been outlined above. Therefore, the algorithmic
aspects of this topic should not require further discussion.
5.2 Causal Graphs
Causal graphs have been introduced informally in the introduction. Here is a formal definition.
Definition 6 Causal graphs
Let Π be a multi-valued planning task with variable set V. The causal graph of Π, in symbols
CG(Π), is the directed graph with vertex set V containing an arc (v, v 0 ) iff v 6= v 0 and one of the
following conditions is true:
• The domain transition graph of v 0 has a transition with some condition on v.
• The set of affected variables in the effect list of some operator includes both v and v 0 .
In the first case, we say that an arc is induced by a transition condition. In the second case we say
that it is induced by co-occurring effects.
Of course, arcs induced by transition conditions and arcs induced by co-occurring effects are
not mutually exclusive. The same causal graph arc can be generated for both reasons.
Informally, the causal graph contains an arc from a source variable to a target variable if changes
in the value of the target variable can depend on the value of the source variable. Such arcs are
included also if this dependency is of the form of an effect on the source variable. This agrees with
the definition of dependency graphs by Jonsson and Bäckström (1998b), although these authors
distinguish between the two different ways in which an arc in the graph can be introduced by using
labelled arcs.
Whether or not co-occurring effects should induce arcs in the causal graph depends on the intended semantics: If such arcs are not included, the set of causal graph ancestors anc(v) of a variable
v are precisely those variables which are relevant if our goal is to change the value of v. Plans for
this goal can be computed without considering any variables outside anc(v), by eliminating all variables outside anc(v) from the planning task and simplifying axioms and operators accordingly. We
call this the achievability definition of causal graphs, because causal graphs encode what variables
are important for achieving a given assignment to a state variable.
However, with the achievability definition, a planner that only considers anc(v) while generating
an action sequence that achieves a given valuation for v may modify variables outside of anc(v), i. e.,
the generated plans have side effects which could destroy previously achieved goals or otherwise
have a negative impact on overall planning. Therefore, we prefer our definition, which we call the
separability definition of causal graphs.
5.2.1 ACYCLIC C AUSAL G RAPHS
Following the separability definition of causal graphs, solving a subproblem over variables anc(v)
is always possible without changing any values outside of anc(v). This leads us to the following
observation.
210

T HE FAST D OWNWARD P LANNING S YSTEM

Observation 7 Acyclic causal graphs and strongly connected domain transition graphs
Let Π be an MPT such that CG(Π) is acyclic, all domain transition graphs are strongly connected,
there are no derived variables, and no trivially false conditions occur in operators or goals. Then
Π has a solution.
By trivially false conditions, we mean conditions of the kind {v = d, v = d 0 } for d 6= d0 .
Note the similarity of Observation 7 to the results of Williams and Nayak (1997) on planning in domains with unary operators, acyclic causal graphs and reversible transitions. Under the separability
definition of causal graphs, acyclic causal graphs imply unariness of operators because operators
with several effects introduce causal cycles. Moreover, strong connectedness of domain transition
graphs is closely related to Williams’ and Nayak’s reversibility property, although it is a weaker
requirement.
The truth of the observation can easily be seen inductively: If the planning task has only one state
variable and the domain transition graph is strongly connected, then any state (of the one variable)
can be transformed into any other state by applying graph search techniques. If the planning task
has several state variables and the causal graph is acyclic, we pick a sink of the causal graph, i. e.,
a variable v without outgoing arcs, and check if a goal is defined for this variable. If not, we
remove the variable from the task, thus reducing the problem to one with fewer state variables,
solved recursively. If yes, we search for a path from s 0 (v) to s? (v) in the domain transition graph
of v, which is guaranteed to exist because the graph is strongly connected. This yields a “high-level
plan” for setting v to s? (v) which can be fleshed out by recursively inserting the plans for setting
the variables of the predecessors of v in the causal graph to the values required for the transitions
that form the high-level plan. Once the desired value of v has been set, v can be eliminated from
the planning task and the remaining problem can be solved recursively.
The algorithm is shown in Fig. 12. Although it is backtrack-free, it can require exponential
time to execute because the generated plans can be exponentially long. This is unavoidable; even
for MPTs that satisfy the conditions of Observation 7, shortest plans can be exponentially long. A
family of planning tasks with this property is given in the proof of Theorem 4.4 in the article by
Bäckström and Nebel (1995).
This method for solving multi-valued planning tasks is essentially planning by refinement: We
begin by constructing a very abstract skeleton plan, which is merely a path in some domain transition
graph, then lower the level of abstraction by adding operators to satisfy the preconditions required
for the transitions taken by the path. Strong connectedness of domain transition graphs guarantees
that every abstract plan can actually be refined to a concrete plan. This is precisely Bacchus and
Yang’s (1994) downward refinement property (cf. Section 2.1).
5.2.2 G ENERATING

AND

P RUNING C AUSAL G RAPHS

The usefulness of causal graphs for planning by refinement is not limited to the acyclic case. Consider a subset V 0 of the task variables which contains all its causal graph descendants. In general, if
we restrict the task to V 0 by removing all occurrences of other variables from the initial state, goal,
operators and axioms, we obtain an abstraction of the original problem which satisfies Knoblock’s
(1994) ordered monotonicity property (Section 2.1).
Unfortunately, one major problem with this approach is that the requirement to include all causal
graph descendants is quite limiting. It is not uncommon for the causal graph of a planning task to
be strongly connected, in which case this technique will not allow us to abstract away any variables
211

H ELMERT

algorithm solve-easy-MPT(V, s0 , s? , O):
if s? = ∅:
{ The goal is empty: the empty plan is a solution. }
return hi.
else:
Let v ∈ V be a variable not occurring in preconditions or effect conditions in O.
{ Such a variable always exists if the causal graph of the task is acyclic. }
V 0 := V \ {v}.
O 0 := { o ∈ O | o does not affect v }.
plan := hi
if s? (v) is defined:
Let t1 , . . . , tk be a path of transitions in DTG(v) from s 0 (v) to s? (v).
{ t1 , . . . , tk is a “high-level plan” that reaches the goal for v,
but ignores preconditions on other variables. }
for each t ∈ {t1 , . . . , tk }:
{ Recursively find a plan that achieves the conditions of t. }
Let cond and o be the condition and operator associated with t.
Let s00 be the state reached after executing plan, restricted to V 0 .
Extend plan by solve-easy-MPT(V 0 , s00 , cond, O 0 ).
Extend plan by o.
{ After dealing with v, recursively plan for goals on the remaining variables. }
Let s00 be the state reached after executing plan, restricted to V 0 .
s0? := s? restricted to V 0 .
Extend plan by solve-easy-MPT(V 0 , s00 , s0? , O 0 ).
return plan
Figure 12: Planning algorithm for MPTs with acyclic causal graph and strongly connected domain
transition graphs.

212

T HE FAST D OWNWARD P LANNING S YSTEM

at all. However, in a heuristic approach, we are free to simplify the planning task. In particular,
by ignoring some operator preconditions for the purposes of heuristic evaluation, we can make an
arbitrary causal graph acyclic. Clearly, the more aspects of the real task we ignore, the worse we can
expect our heuristic to approximate the actual goal distance. Considering this, our aim is to ignore
as little information as possible. We will now explain how this is done.
The knowledge compilation component begins its causal graph processing by generating the
“full” causal graph (Definition 6). One consequence of the separability definition of causal graphs
is that all state variables which are not ancestors of variables mentioned in the goal are completely
irrelevant. Therefore, having computed the graph, we then compute the causal graph ancestors of
all variables in the goal. Any state variables which are not found to be goal ancestors are eliminated from the planning task and causal graph, and associated operators and axioms are removed. 4
Afterwards, we compute a pruned causal graph, an acyclic subgraph of the causal graph with the
same vertex set. We try do this in such a fashion that “important” causal dependencies are retained
whenever possible. More specifically, we apply the following algorithm.
First, we compute the strongly connected components of the causal graph. Cycles only occur
within strongly connected components, so each component can be dealt with separately. Second,
for each connected component, we compute a total order ≺ on the vertices, retaining only those
arcs (v, v 0 ) for which v ≺ v 0 . If v ≺ v 0 , we say that v 0 has a higher level than v. The total order is
computed in the following way:
1. We assign a weight to each arc in the causal graph. The weight of an arc is n if it is induced
by n axioms or operators. The lower the cumulated weight of the incoming arcs of a vertex,
the fewer conditions are ignored by assigning a low level to this vertex.
2. We then pick a vertex v with minimal cumulated weight of incoming arcs and select it for the
lowest level, i. e., we set v ≺ v 0 for all other vertices v 0 in the strongly connected component.
3. Since v has been dealt with, we remove the vertex and its incident arcs from consideration for
the rest of the ordering algorithm.
4. The remaining problem is solved by iteratively applying the same technique to order the other
vertices until only a single vertex remains.
The reader will notice that the pruning choices within a strongly connected component are
performed by a greedy algorithm. We could also try to find sets of arcs of minimal total weight such
that eliminating these arcs results in an acyclic graph. However, this is an NP-equivalent problem,
even in the case of unweighted graphs (Garey & Johnson, 1979, problem GT8).
After generating the pruned causal graph, we also prune the domain transition graphs by removing from the transition labels of DTG(v) all conditions on variables v 0 with v ≺ v 0 . These are the
conditions that are ignored by the heuristic computation. Finally, we simplify the domain transition
graphs by removing dominated transitions: If t and t 0 are transitions between the same two values
of a variable, and the condition of t is a proper subset of the condition of t 0 , then transition t is
easier to apply than t0 , so that we remove t0 . Similarly, if there are several transitions with identical
conditions, we only keep one of them.
4. This simplification is closely related to Knoblock’s criterion for the problem-specific ordered monotonicity property
(Knoblock, 1994).

213

H ELMERT

t1

t2

a1

p1

p2

a2

Figure 13: Causal graph of a L OGISTICS task. State variables t i and ai encode the locations of
trucks and airplanes, state variables p i the locations of packages.

f1

p1

f2

f3

f1

f2

f3

l1

l2

l1

l2

c1

c2

c1

c2

p2

p1

p2

Figure 14: Causal graph of a M YSTERY task (left) and of a relaxed version of the task (right). State
variables fi encode the fuel at a location, state variables l i and ci encode the locations
and remaining capacities of trucks, and state variables p i encode the locations of packages.

5.2.3 C AUSAL G RAPH E XAMPLES
To give some impression of the types of causal graphs typically found in the standard benchmarks
and the effects of pruning, we show some examples of increasing graph complexity.
As our first and simplest example, Fig. 13 shows the causal graph of a task from the L OGISTICS
domain, featuring two trucks, two airplanes and two packages. As can be seen, the graph is acyclic,
so it requires no pruning for the causal graph heuristic. Since L OGISTICS tasks also feature strongly
connected domain transition graphs, they can even be solved by the polynomial solve-easy-MPT
algorithm.
As a slightly more complicated example, the next figure, Fig. 14, shows a task from the M YS TERY domain with three locations, two trucks and two packages. The causal graph contains a
number of cycles, but these are mostly local. By pruning arcs from vertices l i to fj , we ignore the
214

T HE FAST D OWNWARD P LANNING S YSTEM

r

r

a

l

a

k1

k2

l

k1

k2

Figure 15: Causal graph of a G RID task (left) and of a relaxed version of the task (right). State
variable r encodes the location of the robot, a encodes the status of the robot arm (empty
or carrying a key), l encodes the status of the locked location (locked or open), and k 1
and k2 encode the locations of the two keys.

fact that we must move trucks to certain locations if we want to use up fuel at that location. As
using up fuel is not a very useful thing to do, this is not a big loss in information. By pruning arcs
from vertices pi to cj , we ignore the fact that vehicles can only increase or decrease their current
capacity by unloading or loading packages. Compared to heuristics based on ignoring delete effects, this is not a great loss in information, since ignoring delete effects in the M YSTERY domain
almost amounts to ignoring capacity and fuel constraints altogether. By pruning just these arcs,
we can eliminate all cycles in the causal graph, so the M YSTERY domain can be considered fairly
well-behaved.
A worse case is shown in Fig. 15, which shows an example from the G RID domain with an
arbitrary number of locations, of which a single one is locked. There are two keys, one of which
can unlock the locked location. Eliminating cycles here requires a few minor relaxations regarding
the status of the robot arm (empty or non-empty), but also one major simplification, namely the
elimination of the arc from l to r representing the fact that the robot can only enter the locked
location if it has been unlocked.
As a (nearly) worst-case example, consider a task in the B LOCKSWORLD domain (no figure). A
typical MPT encoding uses one state variable h for encoding whether or not the hand is empty and
two state variables per block in the task: For the i-th block, t i encodes whether or not the block is
lying on the table, and bi encodes which block is lying on top of it, or if it is clear or being held by
the arm. In the causal graph of such a task, variable h has ingoing arcs from and outgoing arcs to all
other state variables, and all state variables b i are connected to each other in both directions. Only
the state variables ti have a slightly simpler connection structure, being only connected to h and
to bi for the same value of i. Any relaxation of the problem that eliminates cycles from the causal
graph loses a large amount of information, and it is not surprising that the D EPOT domain, which
includes a B LOCKSWORLD subproblem, is the one for which the precursor of Fast Downward fared
worst (Helmert, 2004). Still, it should be pointed out that planners that ignore delete effects have
similar problems with B LOCKSWORLD-like domains, as the comparison between the FF and causal
graph heuristics in the same article shows.
215

H ELMERT

5.3 Successor Generators and Axiom Evaluators
In addition to good heuristic guidance, a forward searching planning system needs efficient methods
for generating successor states if it is to be applied to the benchmark suite from the international
planning competitions. For some domains, our causal graph heuristic or other popular methods
like the FF heuristic provide excellent goal estimates, yet still planning can be too time-consuming
because of very long plans and vast branching factors.
The variant of best-first search implemented in Fast Downward does not compute the heuristic
estimate for each state that is generated. Essentially, heuristic evaluations are only computed for
closed nodes, while computation is deferred for nodes on the search frontier. For domains with
strong heuristic guidance and large branching factors, the number of nodes on the frontier can by
far dominate the number of nodes in the closed set. As a case in point, consider the problem instance
S ATELLITE #29. For solving this task, the default configuration of Fast Downward only computes
heuristic estimates for 67 597 world states while adding 107 233 381 states to the frontier. Clearly,
determining the set of applicable operators quickly is of critical importance in such a scenario.
In some S ATELLITE tasks, there are almost 1 000 000 ground operators, so we should try to
avoid individually checking each operator for applicability. Similarly, in the biggest PSR tasks,
more than 100 000 axioms must be evaluated in each state to compute the values of the derived
variables, so this computation must be made efficient. For these purposes, Fast Downward uses two
data structures called successor generators and axiom evaluators.
5.3.1 S UCCESSOR G ENERATORS
Successor generators are recursive data structures very similar to decision trees. The internal nodes
have associated conditions, which can be likened to the decisions in a decision tree, and the leaves
have associated operator lists which can be likened to a set of classified samples in a decision tree
leaf. They are formally defined as follows.
Definition 8 Successor generators
A successor generator for an MPT Π = hV, s 0 , s? , A, Oi is a tree consisting of selector nodes and
generator nodes.
A selector node is an internal node of the tree. It has an associated variable v ∈ V called the
selection variable. Moreover, it has |D v |+1 children accessed via labelled edges, one edge labelled
v = d for each value d ∈ Dv , and one edge labelled >. The latter edge is called the don’t care
edge of the selector.
A generator node is a leaf node of the tree. It has an associated set of operators from O called
the set of generated operators.
Each operator o ∈ O must occur in exactly one generator node, and the set of edge labels
leading from the root to this node (excluding don’t care edges) must equal the precondition of o.
Given a successor generator for an MPT Π and a state s of Π, we can compute the set of
applicable operators in s by traversing the successor generator as follows, starting from the root:
• At a selector node with selection variable v, follow the edge v = s(v) and the don’t care edge.
• At a generator node, report the generated operators as applicable.
216

T HE FAST D OWNWARD P LANNING S YSTEM

algorithm evaluate-axiom-layer(s, A i ):
for each axiom a ∈ Ai :
a.counter := |a.cond|
for each variable v:
for each axiom a ∈ Ai with a condition v = s(v) in the body:
a.counter := a.counter − 1
while there exists an axiom a ∈ Ai with a.counter = 0 that was not yet considered:
Let hv, di be the head of such an axiom.
if s(v) 6= d:
s(v) := d
for each axiom a ∈ Ai with a condition v = d in the body:
a.counter := a.counter − 1
Figure 16: Computing the values of the derived variables in a given planning state.
To build a successor generator for Π, we apply a top-down algorithm which considers the task
variables in an arbitrary order v1 ≺ v2 ≺ · · · ≺ vn . At the root node, we choose v1 as selection variable and classify the set of operators according to their preconditions with respect to v 1 . Operators
with a precondition v1 = d will be represented in the child of the root accessed by the edge with the
corresponding label, while operators without preconditions on v 1 will be represented in the child
of the root accessed by the don’t care edge. In the children of the root, we choose v 2 as selection
variable, in the grandchildren v3 , and so on.
There is one exception to this rule to avoid creating unnecessary selection nodes: If no operator
in a certain branch of the tree has a condition on v i , then vi is not considered as a selection variable
in this branch. The construction of a branch ends when all variables have been considered, at which
stage a generator node is created for the operators associated with that branch.
5.3.2 A XIOM E VALUATORS
Axiom evaluators are a simple data structure used for efficiently implementing the well-known
marking algorithm for propositional Horn logic (Dowling & Gallier, 1984), extended and modified
for the layered logic programs that correspond to the axioms of an MPT. They consist of two parts.
Firstly, an indexing data structure maps a given variable/value pairing and a given axiom layer to
the set of axioms in the given layer in whose body the pairing appears. Secondly, a set of counters,
one for each axiom, counts the number of conditions of the axiom that have not yet been derived.
Within Fast Downward, axioms are evaluated in two steps. First, all derived variables are set to
their default value ⊥. Second, algorithm evaluate-axiom-layer (Fig. 16) is executed for each axiom
layer in sequence to determine the final values of the derived variables.
We assume that the reader is familiar enough with the marking algorithm not to require much
explanation, so we only point out that the test whether or not an axiom is ready to trigger is implemented by means of a queue in which axioms are put as soon as their counter reaches 0. The actual
implementation of evaluate-axiom-layer within Fast Downward initializes axiom counters slightly
more efficiently than indicated by the pseudo-code. However, this is a minor technical detail, so we
turn to the remaining piece of Fast Downward’s architecture, the search component.
217

H ELMERT

6. Search
Unlike the translation and knowledge compilation components, for which there is only a single
mode of execution, the search component of Fast Downward can perform its work in various alternative ways. There are three basic search algorithms to choose from:
1. Greedy best-first search: This is the standard textbook algorithm (Russell & Norvig, 2003),
modified with a technique called deferred heuristic evaluation to mitigate the negative influence of wide branching. We have also extended the algorithm to deal with preferred operators, similar to FF’s helpful actions (Hoffmann & Nebel, 2001). We discuss greedy best-first
search in Section 6.3. Fast Downward uses this algorithm together with the causal graph
heuristic, discussed in Section 6.1.
2. Multi-heuristic best-first search: This is a variation of greedy best-first search which evaluates
search states using multiple heuristic estimators, maintaining separate open lists for each.
Like our variant of greedy best-first search, it supports the use of preferred operators. Multiheuristic best-first search is discussed in Section 6.4. Fast Downward uses this algorithm
together with the causal graph and FF heuristics, discussed in Sections 6.1 and 6.2.
3. Focused iterative-broadening search: This is a simple search algorithm that does not use
heuristic estimators, and instead reduces the vast set of search possibilities by focusing on
a limited operator set derived from the causal graph. It is an experimental algorithm; in the
future, we hope to further develop the basic idea of this algorithm into a more robust method.
Focused iterative-broadening search is discussed in Section 6.5.
For the two heuristic search algorithms, a second choice must be made regarding the use of
preferred operators. There are five options supported by the planner:
1. Do not use preferred operators.
2. Use the helpful transitions of the causal graph heuristic as preferred operators.
3. Use the helpful actions of the FF heuristic as preferred operators.
4. Use helpful transitions as preferred operators, falling back to helpful actions if there are no
helpful transitions in the current search state.
5. Use both helpful transitions and helpful actions as preferred operators.
Each of these five options can be combined with any of the two heuristic search algorithms,
so that there is a total of eleven possible settings for the search component, ten using one of the
heuristic algorithms and one using focused iterative-broadening search.
In addition to these basic settings, the search component can be configured to execute several
alternative configurations in parallel by making use of an internal scheduler. Both configurations of
Fast Downward that participated in IPC4 made use of this feature by running one configuration of
the heuristic search algorithms in parallel with focused iterative-broadening search. As its heuristic
search algorithm, the configuration Fast Downward employed greedy best-first search with helpful
transitions, falling back to helpful actions when necessary (option 4.). The configuration Fast Diagonally Downward employed multi-heuristic best-first search using helpful transitions and helpful
actions as preferred operators (option 5.).
218

T HE FAST D OWNWARD P LANNING S YSTEM

To avoid confusion between the complete Fast Downward planning system and the particular
configuration called “Fast Downward”, we will refer to the IPC4 planner configurations as FD and
FDD for the rest of this paper. The name of the planning system as a whole is never abbreviated.
6.1 The Causal Graph Heuristic
The causal graph heuristic is the centrepiece of Fast Downward’s heuristic search engine. It estimates the cost of reaching the goal from a given search state by solving a number of subproblems of
the planning task which are derived by looking at small “windows” of the (pruned) causal graph. For
some additional intuitions about the design of the heuristic and a discussion of theoretical aspects,
we refer to the article in which the heuristic was first introduced (Helmert, 2004).
6.1.1 C ONCEPTUAL V IEW

OF THE

C AUSAL G RAPH H EURISTIC

For each state variable v and each pair of values d, d 0 ∈ Dv , the causal graph heuristic computes
a heuristic estimate cost v (d, d0 ) for the cost of changing the value of v from d to d 0 , assuming that
all other state variables carry the same values as in the current state. (This is a simplification. Cost
estimates are not computed for state variables v or values d for which they are never required. We
ignore this fact when discussing the heuristic on the conceptual level.) The heuristic estimate of
a given state s is the sum over the costs cost v (s(v), s? (v)) for all variables v for which a goal
condition s? (v) is defined.
Conceptually, cost estimates are computed one variable after the other, traversing the (pruned)
causal graph in a bottom-up fashion. By bottom-up, we mean that we start with the variables that
have no predecessors in the causal graphs; we call this order of computation “bottom-up” because
we consider variables that can change their state of their own accord low-level, while variables
whose state transitions require the help of other variables have more complex transition semantics
and are thus considered high-level. Note that in our figures depicting causal graphs, high-level
variables are typically displayed near the bottom.
For variables without predecessors in the causal graph, cost v (d, d0 ) simply equals the cost of
a shortest path from d to d0 in the (pruned) domain transition graph DTG(v). For other variables,
cost estimates are also computed by graph search in the domain transition graph. However, the
conditions of transitions must be taken into account during path planning, so that in addition to
counting the number of transitions required to reach the destination value, we also consider the costs
for achieving the value changes of the other variables necessary to set up the transition conditions.
The important point here is that in computing the values cost v (d, d0 ), we completely consider
all interactions of the state variable v with its predecessors in the causal graph. If changing the
value from d to d0 requires several steps and each of these steps has an associated condition on a
variable v 0 , then we realize that v 0 must assume the values required by those conditions in sequence.
For example, if v represents a package in a transportation task that must be moved from A to B by
means of a vehicle located at C, then we recognize that the vehicle must first move from C to A
and then from A to B in order to drop the package at B. This is very different to the way HSPor FF-based heuristics work on such examples. However, we only consider interactions with the
immediate predecessors of v in the causal graph. Interactions that occur via several graph layers are
not captured by the heuristic estimator.
In essence, we compute cost v (d, d0 ) by solving a particular subproblem of the MPT, induced by
the variable v and its predecessors in the pruned causal graph. For this subproblem, we assume that
219

H ELMERT

algorithm compute-costs-bottom-up(Π, s):
for each variable v of Π, traversing the pruned causal graph in bottom-up order:
Let V 0 be the set of immediate predecessors of v in the pruned causal graph.
for each pair of values (d, d0 ) ∈ Dv × Dv :
Generate a planning task Πv,d,d0 with the following components:
— Variables: V 0 ∪ {v}.
— Initial state: v = d and v 0 = s(v 0 ) for all v 0 ∈ V 0 .
— Goal: v = d0 .
— Axioms and operators:
1. Those corresponding to transitions in the pruned DTG of v.
2. For all variables v 0 ∈ V 0 and values e, e0 ∈ Dv0 , an operator
with precondition v 0 = e, effect v 0 = e0 and cost cost0v (e, e0 ).
{ Note that all variables v 0 ∈ V 0 have been considered previously,
so that their cost values are known. }
Set costv (d, d0 ) to the cost of a plan π that solves Πv,d,d0 .
Figure 17: The compute-costs-bottom-up algorithm, a high-level description of the causal graph
heuristic.

v is initially set to d, we want v to assume the value d 0 , and all other state variables carry the same
value as in the current state. We call this planning problem the local subproblem for v, d and d 0 , or
the local subproblem for v and d if we leave the target value d 0 open.
For a formalization of these intuitive notions of how the cost estimates are generated, consider
the pseudo-code in Fig. 17. It does not reflect the way the heuristic values are actually computed
within Fast Downward; the algorithm in the figure would be far too expensive to evaluate for each
search state. However, it computes the same cost values as Fast Downward does, provided that the
algorithm generating the plans π in the last line of the algorithm is the same one as the one used for
the “real” cost estimator.
6.1.2 C OMPUTATION

OF THE

C AUSAL G RAPH H EURISTIC

The actual computation of the causal graph heuristic traverses the causal graph in a top-down direction starting from the goal variables, rather than bottom-up starting from variables without causal
predecessors. In fact, this top-down traversal of the causal graph is the reason for Fast Downward’s
name.
Computing cost estimates in a top-down traversal implies that while the algorithm is computing
plans for local subproblems of a given variable, it typically does not yet know the costs for changing
the state of its causal predecessors. The algorithm compute-costs addresses this by evaluating the
cost values of dependent variables through recursive invocations of itself.
For a given variable-value pairing v = d, we always compute the costs cost v (d, d0 ) for all values
of d0 ∈ Dv at the same time, similar to the way Dijkstra’s algorithm computes the shortest path not
from a single source to a single destination vertex, but from a single source to all possible destination
vertices. Computing the costs for all values of d 0 is not (much) more expensive than computing only
220

T HE FAST D OWNWARD P LANNING S YSTEM

one of these values, and once all cost values have been determined, we can cache them and re-use
them if they are needed again later during other parts of the computation of the heuristic value for
the current state.
In fact, the similarity to shortest path problems is not superficial but runs quite deeply. If we
ignore the recursive calls for computing cost values of dependent variables, compute-costs is basically an implementation of Dijkstra’s algorithm for the single-source shortest path problem on
domain transition graphs. The only difference to the “regular” algorithm lies in the fact that we do
not know the cost for using an arc in advance. Transitions of derived variables have a base cost
of 0 and transitions of fluents have a base cost of 1, but in addition to the base cost, we must pay
the cost for achieving the conditions associated with a transition. However, the cost for achieving a
given condition v 0 = e0 depends on the current value e of that state variable at the time the transition
is taken. Thus, we can only compute the real cost for a transition once we know the values of the
dependent state variables in the relevant situation.
Of course, there are many different ways of taking transitions through domain transition graphs,
all potentially leading to different values for the dependent state variables. When we first introduced
the causal graph heuristic, we showed that deciding plan existence for the local subproblems is NPcomplete (Helmert, 2004), so we are content with an approach that does not lead to a complete
planning algorithm, as long as it works well for the subproblems we face in practice.
The approach we have chosen is to achieve each value of state variable v in the local subproblem
for v and d as quickly as possible, following a greedy policy. In the context of the Dijkstra algorithm,
this means that we start by finding the cheapest possible plan to make a transition from d to some
other value d0 . Once we have found the cheapest possible plan π d0 , we commit to it, annotating the
vertex d0 of the domain transition graph with the local state obtained by applying plan π d0 to the
current state. In the next step, we look for the cheapest possible plan to achieve another value d 00 ,
by either considering transitions that start from the initial value d, or by considering transitions that
continue the plan πd0 by moving to a neighbour of d0 . This process is iterated until all vertices of
the domain transition graph have been reached or no further progress is possible.
Our implementation follows Dijkstra’s algorithm (Fig. 18). We have implemented the priority queue as a vector of buckets for maximal speed and use a cache to avoid generating the same
costv (d, d0 ) value twice for the same state. In addition to this, we use a global cache that is shared
throughout the whole planning process so that we need to compute the values cost v (d, d0 ) for variables v with few ancestors in the pruned causal graph only once. (Note that cost v (d, d0 ) only depends
on the current values of the ancestors of v.)
Apart from these and some other technical considerations, Fig. 18 gives an accurate account
of Fast Downward’s implementation of the causal graph heuristic. For more details, including
complexity considerations and a worked-out example, we refer to the original description of the
algorithm (Helmert, 2004).
6.1.3 S TATES

WITH I NFINITE

H EURISTIC VALUE

We noted that Fast Downward uses an incomplete planning algorithm for determining solutions to
local planning problems. Therefore, there can be states s with cost v (s(v), s? (v)) = ∞ even though
the goal condition v = s? (v) can still be reached. This means that we cannot trust infinite values
returned by the causal graph heuristic. In our experience, states with infinite heuristic evaluation
from which it is still possible to reach the goal are rare, so we indeed treat such states as dead ends.
221

H ELMERT

algorithm compute-costs(Π, s, v, d):
Let V 0 be the set of immediate predecessors of v in the pruned causal graph of Π.
Let DTG be the pruned domain transition graph of v.
costv (d, d) := 0
costv (d, d0 ) := ∞ for all d0 ∈ Dv \ {d}
local-state d := s restricted to V 0
unreached := Dv
while unreached contains a value d0 ∈ Dv with cost v (d, d0 ) < ∞:
Choose such a value d0 ∈ unreached minimizing cost v (d, d0 ).
unreached := unreached \ {d0 }
for each transition t in DTG leading from d 0 to some d00 ∈ unreached:
transition-cost := 0 if v is a derived variable; 1 if v is a fluent
for each pair v 0 = e0 in the condition of t:
e := local-state d0 (v 0 )
call compute-costs(Π, s, v 0 , e).
transition-cost := transition-cost + cost v0 (e, e0 )
if costv (d, d0 ) + transition-cost < cost v (d, d00 ):
costv (d, d00 ) := costv (d, d0 ) + transition-cost
local-state d00 := local-state d0
for each pair v 0 = e0 in the condition of t:
local-state d00 (v 0 ) := e0
Figure 18: Fast Downward’s implementation of the causal graph heuristic: the compute-costs algorithm for computing the estimates cost v (d, d0 ) for all values d0 ∈ Dv in a state s of an
MPT Π.

222

T HE FAST D OWNWARD P LANNING S YSTEM

If it turns out that all states at the search frontier are dead ends, we cannot make further progress
with the causal graph heuristic. In this case, we use a sound dead-end detection routine to verify the
heuristic assessment. If it turns out that all frontier states are indeed dead ends, then we report the
problem as unsolvable. Otherwise, search is restarted with the FF heuristic (cf. Section 6.2), which
is sound for purposes of dead-end detection. 5
The dead-end detection routine has been originally developed for STRIPS-like tasks. However,
extending it to full MPTs is easy; in fact, no changes to the core algorithm are required, as it works
at the level of domain transition graphs and is still sound when applied to tasks with conditional
effects and axioms. Since it is not a central aspect of Fast Downward, we do not discuss it here,
referring to our earlier work instead (Helmert, 2004).
6.1.4 H ELPFUL T RANSITIONS
Inspired by Hoffmann’s very successful use of helpful actions within the FF planner (Hoffmann &
Nebel, 2001), we have extended our algorithm for computing the causal graph heuristic so that in
addition to the heuristic estimate, it also generates a set of applicable operators considered useful
for steering search towards the goal.
To compute helpful actions in FF, Hoffmann’s algorithm generates a plan for the relaxed planning task defined by the current search state and considers those operators helpful which belong to
the relaxed plan and are applicable in the current state.
Our approach follows a similar idea. After computing the heuristic estimate cost v (s(v), s? (v))
for a variable v for which a goal condition is defined, we look into the domain transition graph of
v to trace the path of transitions leading from s(v) to s ? (v) that gave rise to the cost estimate. In
particular, we consider the first transition on this path, starting at s(v). If this transition corresponds
to an applicable operator, we consider that operator a helpful transition and continue to check the
next goal. If the transition does not correspond to an applicable operator because it has associated
conditions of the form v 0 = e0 which are not currently satisfied, then we recursively look for helpful transitions in the domain transition graph of each such variable v 0 , checking the path that was
generated during the computation of cost v0 (s(v 0 ), e0 ).
The recursive process continues until we have found all helpful transitions. Unlike the case
for FF, where helpful actions can be found for all non-goal states, we might not find any helpful
transition at all. It may be the case that a transition does not correspond to an applicable operator
even though it has no associated conditions; this can happen when some operator preconditions are
not represented in the pruned domain transition graph due to cycles in the causal graph. Even so,
we have found helpful transitions to be a useful tool in guiding our best-first search algorithms.
6.2 The FF Heuristic
The FF heuristic is named after Hoffmann’s planning algorithm of the same name, in the context
of which it was originally introduced (Hoffmann & Nebel, 2001). It is based on the notion of
relaxed planning tasks that ignore negative interactions. In the context of MPTs, ignoring negative
interactions means that we assume that each state variable can hold several values simultaneously.
An operator effect or axiom that sets a variable v to a value d in the original task corresponds to
5. In practice, we have never observed the causal graph heuristic to fail on a solvable task. Therefore, the fallback
mechanism is only used for some unsolvable tasks in the M ICONIC -F ULL ADL domain which are not recognized by
our dead-end detection technique.

223

H ELMERT

an effect or axiom that adds the value d to the range of values assumed by v in the relaxed task. A
condition v = d in the original task corresponds to a condition requiring d to be an element of the
set of values currently assumed by v in the relaxed task.
It is easy to see that applying some operator in a solvable relaxed planning task can never render
it unsolvable. It can only lead to more operators being applicable and more goals being true, if it has
any significant effect at all. For this reason, relaxed planning tasks can be solved efficiently, even
though optimal solutions are still NP-hard to compute (Bylander, 1994). A plan for the relaxation
of a planning task is called a relaxed plan for that task.
The FF heuristic estimates the goal distance of a world state by generating a relaxed plan for
the task of reaching the goal from this world state. The number of operators in the generated plan
is then used as the heuristic estimate. Our implementation of the FF heuristic does not necessarily
generate the same, or even an equally long, relaxed plan as FF. In our experiments, this did not turn
out to be problematic, as both implementations appear to be equally informative.
While the FF heuristic was originally introduced for ADL domains, extending it to tasks involving derived predicates is straight-forward. One possible extension is to simply assume that each
derived predicate is initially set to its default value ⊥ and treat axioms as relaxed operators of cost
0. In a slightly more complicated, but also more accurate approach, derived variables are initialized
to their actual value in a given world state, allowing the relaxed planner to achieve the value ⊥
(or other values) by applying the transitions of the extended domain transition graph of the derived
variable. We have followed the second approach.
In addition to heuristic estimates, the FF heuristic can also be exploited for restricting or biasing
the choice of operators to apply in a given world state s. The set of helpful actions of s consists of
all those operators of the relaxed plan computed for s that are applicable in that state. As mentioned
in the introduction to this section, Fast Downward can be configured to treat helpful actions as
preferred operators.
There is a wealth of work on the FF heuristic in the literature, so we do not discuss it further.
For a more thorough treatment, we point to the references (Hoffmann & Nebel, 2001; Hoffmann,
2001, 2002, 2005).
6.3 Greedy Best-First Search in Fast Downward
Fast Downward uses greedy best-first search with a closed list as its default search algorithm. We
assume that the reader is familiar with the algorithm and refer to the literature for details (Russell &
Norvig, 2003).
Our implementation of greedy best-first search differs from the textbook algorithm in two ways.
First, it can treat helpful transitions computed by the causal graph heuristic or helpful actions computed by the FF heuristic as preferred operators. Second, it performs deferred heuristic evaluation
to reduce the influence of large branching factors. We now turn to describing these two search
enhancements.
6.3.1 P REFERRED O PERATORS
To make use of helpful transitions computed by the causal graph heuristic or helpful actions computed by the FF heuristic, our variant of greedy best-first search supports the use of so-called preferred operators. The set of preferred operators of a given state is a subset of the set of applicable
operators for this state. Which operators are considered preferred depends on the settings for the
224

T HE FAST D OWNWARD P LANNING S YSTEM

search component, as discussed earlier. The intuition behind preferred operators is that a randomly
picked successor state is more likely to be closer to the goal if it is generated by a preferred operator, in which case we call it a preferred successor. Preferred successors should be considered before
non-preferred ones on average.
Our search algorithm implements this preference by maintaining two separate open lists, one
containing all successors of expanded states and one containing preferred successors exclusively.
The search algorithm alternates between expanding a regular successor and a preferred successor.
On even iterations it will consider the one open list, on odd iterations the other. No matter which
open list a state is taken from, all its successors are placed in the first open list, and the preferred
successors are additionally placed in the second open list. (Of course we could limit the first open
list to only contain non-preferred successors; however, typically the total number of successors is
vast and the number of preferred successors is tiny. Therefore, it is cheaper to add all successors
to the first open list and detect duplicates upon expansion than scan through the list of successors
determining for each element whether or not it is preferred.)
Since the number of preferred successors is smaller than the total number of successors, this
means that preferred successors are typically expanded much earlier than others. This is especially
important in domains where heuristic guidance is weak and a lot of time is spent exploring plateaus.
When faced with plateaus, Fast Downward’s open lists operate in a first-in-first-out fashion. (In
other words: For a constant heuristic function, our search algorithm behaves like breadth-first
search.) Preferred operators typically offer much better chances of escaping from plateaus since
they lead to significantly lower effective branching factors.
6.3.2 D EFERRED H EURISTIC E VALUATION
Upon expanding a state s, the textbook version of greedy best-first search computes the heuristic
evaluation of all successor states of s and sorts them into the open list accordingly. This can be
wasteful if s has many successors and heuristic evaluations are costly, two conditions that are often
true for heuristic search approaches to planning.
This is where our second modification comes into play. If a successor with a better heuristic
estimate than s is generated early and leads to a promising path towards the goal, we would like
to avoid generating the other successors. Let us assume that s has 1000 successors, and that s 0 ,
the 10th successor of s being generated, has a better heuristic estimate than s. Furthermore, let us
assume that the goal can be reached from s 0 on a path with non-increasing heuristic estimates. Then
we would like to avoid computing heuristic values for the 990 later successors of s altogether.
Deferred heuristic evaluation achieves this by not computing heuristic estimates for the successors of an expanded state s immediately. Instead, the successors of s are placed in the open list
together with the heuristic estimate of state s, and their own heuristic estimates are only computed
when and if they are expanded, at which time it is used for sorting their successors into the open
list, and so on. In general, each state is sorted into the open list according to the heuristic evaluation
of its parent, with the initial state being an exception. In fact, we do not need to put the successor
state itself into the open list, since we do not require its representation before we want to evaluate
its heuristic estimate. Instead, we save memory by storing only a reference to the parent state and
the operator transforming the parent state into the successor state in the open list.
It might not be clear how this approach can lead to significant savings in time, since deferred
evaluation also means that information is only available later. The potential savings become most
225

H ELMERT

apparent when considering deferred heuristic evaluation together with the use of preferred operators:
If an improving successor s0 of a state s is reached by a preferred operator, it is likely that it will be
expanded (via the second open list) long before most other successors — or even most siblings —
of s. In the situation described above, where there exists a non-increasing path from s 0 to the goal,
heuristic evaluations will never be computed for most successors of s. In fact, deferred heuristic
evaluation can significantly improve search performance even when preferred operators are not
used, especially in tasks where branching factors are large and the heuristic estimate is informative.
At first glance, deferred heuristic evaluation might appear related to another technique for reducing the effort of expanding a node within a best-first search algorithm, namely A ∗ with Partial
Expansion (Yoshizumi, Miura, & Ishida, 2000). However, this algorithm is designed for reducing
the space requirements of best-first search at the expense of additional heuristic evaluations: When
expanding a node, A∗ with Partial Expansion computes the heuristic value of all successors, but
only stores those in the open queue whose heuristic values fall below a certain relevance threshold.
In later iterations, it might turn out that the threshold was chosen too low, in which case the node
needs to be re-expanded and the heuristic values of its successors re-evaluated. In general, A ∗ with
Partial Expansion will never compute fewer heuristic estimates than standard A ∗ , but it will usually
require less memory.
However, for heuristic search approaches to planning (and certainly for Fast Downward), heuristic evaluations are usually so costly in time that memory for storing open and closed lists is not a
limiting factor. We are thus willing to trade off memory with time in the opposite way: Deferred
heuristic evaluation normally leads to more node expansions and higher space requirements than
standard best-first search because the heuristic values used for guiding the search are less informative (they evaluate the predecessor of a search node rather than the node itself). However, heuristic
computations are only required for nodes that are actually removed from the open queue rather than
for all nodes on the fringe, and the latter are usually significantly more numerous.
6.4 Multi-Heuristic Best-First Search
As an alternative to greedy best-first search, Fast Downward supports an extended algorithm called
multi-heuristic best-first search. This algorithm differs from greedy best-first search in its use of
multiple heuristic estimators, based on our observation that different heuristic estimators have different weaknesses. It may be the case that a given heuristic is sufficient for directing the search
towards the goal except for one part of the plan, where it gets stuck on a plateau. Another heuristic
might have similar characteristics, but get stuck in another part of the search space.
Various ways of combining heuristics have been proposed in the literature, typically adding
together or taking the maximum of the individual heuristic estimates. We believe that it is often
beneficial not to combine the different heuristic estimates into a single numerical value. Instead,
we propose maintaining a separate open list for each heuristic estimator, which is sorted according
to the respective heuristic. The search algorithm alternates between expanding a state from each
open list. Whenever a state is expanded, estimates are calculated according to each heuristic, and
the successors are put into each open list.
When Fast Downward is configured to use multi-heuristic best-first search, it computes estimates both for the causal graph heuristic and FF heuristic, maintaining two open lists. Of course,
the approach can be combined with the use of preferred operators; in this case, the search algorithm
maintains four open lists, as each heuristic distinguishes between normal and preferred successors.
226

T HE FAST D OWNWARD P LANNING S YSTEM

algorithm reach-one-goal(Π, v, d, cond):
for each ϑ ∈ {0, 1, . . . , max-threshold}:
Let Oϑ be the set of operators of Π whose modification distance with respect to v
is at most ϑ.
Assign the cost c to each operator o ∈ O ϑ with modification distance c with
respect to v.
Call the uniform-cost-search algorithm with a closed list, using the operator set O ϑ ,
to find a state satisfying {v = d} ∪ cond.
return the plan if uniform-cost-search succeeded.
Figure 19: The reach-one-goal procedure for reaching a state with v = d. The value max-threshold
is equal to the maximal modification distance of any operator with respect to v.

6.5 Focused Iterative-Broadening Search
The focused iterative-broadening search algorithm is the most experimental piece of Fast Downward’s search arsenal. In its present form, the algorithm is unsuitable for many planning domains,
especially those containing comparatively few different goals. Yet we think that it might contain the
nucleus for a successful approach to domain-independent planning which is very different to most
current methods, so we include it for completeness and as a source of inspiration.
The algorithm is intended as a first step towards developing search techniques that emphasize the
idea of using heuristic criteria locally, for limiting the set of operators to apply, rather than globally,
for choosing which states to expand from a global set of open states. We made first experiments in
this direction after observing the large boost in performance that can be obtained by using preferred
operators in heuristic search. The algorithm performed surprisingly well in some of the standard
benchmark domains, while performing badly in most others.
As the name suggests, the algorithm focuses the search by concentrating on one goal at a time,
and by restricting its attention to operators which are supposedly important for reaching that goal:
Definition 9 Modification distances
Let Π be an MPT, let o be an operator of Π, and let v be a variable of Π.
The modification distance of o with respect to v is defined as the minimum, over all variables
v 0 that occur as affected variables in the effect list of o, of the distance from v 0 to v in CG(Π).
For example, operators that modify v directly have a modification distance of 0 with respect to
v, operators that modify variables which occur in preconditions of operators modifying v have a
modification distance of 1, and so on. We assume that in order to change the value of a variable,
operators with a low modification distance with respect to this variable are most useful.
Fig. 19 shows the reach-one-goal procedure for achieving a single goal of an MPT. For the time
being, assume that the cond parameter is always ∅. The procedure makes use of the assumption
that high modification distance implies low usefulness in two ways. First, operators with high
modification distance with respect to the goal variable are considered to have a higher associated
cost, and are hence applied less frequently. Second, operators whose modification distance is beyond
a certain threshold are forbidden completely. Instead of choosing a threshold a priori, the algorithm
227

H ELMERT

first tries to find a solution with the lowest possible threshold of 0, increasing the threshold by 1
whenever the previous search has failed. The uniform-cost-search algorithm mentioned in Fig. 19
is the standard textbook method (Russell & Norvig, 2003).
Although we were ignorant of this fact at the time our algorithm was conceived, the core idea of
reach-one-goal is not new: Ginsberg and Harvey (1992) present a search technique called iterative
broadening, which is also based on the idea of repeatedly doing a sequence of uninformed searches
with an ever-growing set of operators. Their work demonstrates the superiority of iterative broadening over standard depth-bounded search both empirically and analytically under the reasonable
assumption that the choices made at each branching point are equally important. 6 The original iterative broadening algorithm applies to scenarios without any knowledge of the problem domain,
so it chooses the set of operators which may be applied at every search node randomly, rather than
using heuristic information from the causal graph as in our case. However, Ginsberg and Harvey
already discuss the potential incorporation of heuristics into the operator selection. The introduction of operator costs (in the form of modification distances) is new, but it is a fairly straightforward
extension where heuristic information is available.
The focused iterative-broadening search algorithm is based on the reach-one-goal method; the
idea is to achieve the goals of the planning task one after the other, by using the reach-one-goal
algorithm as the core subroutine for satisfying individual goals. Since it is not obvious what a good
order of achieving the goals would be, one invocation of reach-one-goal is started for each goal in
parallel. As each one-goal solver focuses on the (supposedly) relevant operators for reaching its
particular goal, there is hope that the number of states considered before a goal is reached is small.
Once one of the one-goal solvers reaches its goal, the resulting plan is reported and all sub-searches
are stopped. The overall search algorithm commits to this part of the plan; the situation in which
the first goal has been reached is considered a new initial state.
From this situation, we try to satisfy the second goal, by once more starting parallel invocations
of reach-one-goal for each possible second goal. Of course, this can lead to a situation where the
search algorithm oscillates between goals, first achieving goal a, then abandoning it in favour of goal
b, without any sign of making real progress. Therefore, we demand that reach-one-goal achieves
the second goal in addition to the one we reached first, by setting the cond argument accordingly.
Once two goals have been reached, the sub-searches are again stopped, sub-searches for the third
goal are started, and so on, until all goals have been reached.
In some sense, our focusing technique is similar to the beam search algorithm (Lowerre, 1976),
which also performs a fixed number of concurrent searches to avoid committing to a particular path
in the search space too early. Beam search uses a heuristic function to evaluate which branches of
search should be abandoned and where new branches should be spawned. While focused iterativebroadening search does not appear to use heuristic evaluations at first glance, the number of satisfied
goals of a state is used as an evaluation criterion in essentially the same way. One important difference to beam search is our use of modification distances relative to a particular goal, which means
that the different “beams” explore the state space in qualitatively different ways.
There is one final twist: To motivate reach-one-goal not to needlessly wander away from satisfied goals, we forbid applying operators that undo any of the previously achieved goals in cond.
This is an old idea called goal protection (Joslin & Roach, 1989). It is well-known that protecting
6. See the original analysis for a precise definition of “equally important” (Ginsberg & Harvey, 1992). While Ginsberg
and Harvey’s assumption is certainly not valid in practice, we find it much more convincing than the competing model
where goal states are uniformly distributed across the search fringe.

228

T HE FAST D OWNWARD P LANNING S YSTEM

algorithm reach-one-goal(Π, v, d, cond):
for each ϑ ∈ {0, 1, . . . , max-threshold}:
Let Oϑ be the set of operators of Π whose modification distance with respect to v
is at most ϑ and which do not affect any state variable occurring in cond.
Assign the cost c to each operator o ∈ O ϑ with modification distance c with
respect to v.
Call the uniform-cost-search algorithm with a closed list, using the operator set O ϑ ,
to find a state satisfying {v = d} ∪ cond.
return the plan if uniform-cost-search succeeded.
for each ϑ ∈ {0, 1, . . . , max-threshold}:
Let Oϑ be the set of operators of Π whose modification distance with respect to v
is at most ϑ.
Assign the cost c to each operator o ∈ O ϑ with modification distance c with
respect to v.
Call the uniform-cost-search algorithm with a closed list, using the operator set O ϑ ,
to find a state satisfying {v = d} ∪ cond.
return the plan if uniform-cost-search succeeded.
Figure 20: The reach-one-goal procedure for reaching a state with v = d (corrected).
goals renders a search algorithm incomplete, even in state spaces where all operators are reversible
and local search approaches like focused iterative-broadening search would be otherwise complete.
In particular, search must fail in planning tasks which are not serializable (Korf, 1987). Therefore,
if the first solution attempt fails, the algorithm is restarted without goal protection. The complete
procedure is shown in Fig. 20, which concludes our discussion of Fast Downward’s search component.

7. Experiments
To evaluate the performance of Fast Downward, and specifically the differences between the various
configurations of the search component, we have performed a number of experiments on the set of
benchmarks from the previous international planning competitions. The purpose of these experiments is to compare Fast Downward to the state of the art in PDDL planning, and to contrast the
performance of the different search algorithms of Fast Downward (greedy best-first search with and
without preferred operators, multi-heuristic best-first search with and without preferred operators,
and focused iterative-broadening search).
To clearly state the purpose of our experiments, let us also point out two areas worthy of study
that we do not choose to investigate here:
• We do not compare the causal graph heuristic to other heuristics, such as the FF or HSP
heuristics. Such a comparison would require evaluating the different heuristics within otherwise identical planning systems. We have performed such an experiment before (Helmert,
2004) and thus prefer to dedicate this section to an evaluation of the complete Fast Downward
planning system, rather than just its heuristic function.
229

H ELMERT

• We do not give a final answer to the question why Fast Downward performs well or badly in
the domains we analyse. Where we do observe bad performance, we try to give a plausible
explanation for this, but we do not conduct a full-blown study of heuristic quality in the spirit
of Hoffmann’s work on the FF and h+ heuristics (Hoffmann, 2005). While we do believe that
much could be learned from such an investigation, it is a major undertaking that would go
beyond the scope of this article.
Our aim in this section is to evaluate the Fast Downward planner as a whole, so there are a
number of algorithmic questions which we do not address. For example, one might wonder what (if
any) speed-up can be obtained by using successor generators over simpler methods which test each
operator for applicability whenever a node is expanded. Another question concerns the extent to
which deferred heuristic evaluation affects search performance. To keep this section at a reasonable
length, we do not discuss either of these questions here. However, we have conducted experiments
addressing them, and include their results in an electronic appendix to this paper. 7
7.1 Benchmark Set
The benchmark set we use consists of all propositional planning tasks from the fully automated
tracks of the first four international planning competitions hosted at AIPS 1998, AIPS 2000, AIPS
2002 and ICAPS 2004. The set of benchmark domains is shown in Fig. 21. Altogether, the benchmark suite comprises 1442 tasks. (The numbers in Fig. 21 add up to 1462, but the 20 S ATELLITE
instances that were introduced for IPC3 were also part of the benchmark set of IPC4, so we only
count them once.)
We distinguish between three classes of domains:
• STRIPS domains: These domains do not feature derived predicates or conditional effects, and
all conditions appearing in goal and operators are conjunctions of positive literals.
• ADL domains: These domains make use of conditional effects in their operator and/or contain
more general conditions than simple conjunctions in their goals and operators. However, they
do not require axioms.
• PDDL2.2 domains: These domains use the full range of propositional PDDL2.2, including
those features present in ADL domains and axioms.
At IPC4, some domains were presented in different formulations, meaning that the same realworld task was encoded in several different ways. Participants were asked to only work on one
formulation per domain, being able to choose their preferred formulation for a given domain freely.
For example, the A IRPORT domain was available in a STRIPS formulation and an ADL formulation.
However, the organizers did not strictly follow the rule of considering different encodings of
the same real-world task different formulations, rather than different domains proper. Namely, for
the PSR-M IDDLE and P ROMELA domains, encodings with and without axioms were available, and
these were considered as different domains on the grounds that the encodings without axioms were
7. See http://www.jair.org/. The short summary is that successor generators speed up search by up to two
orders of magnitude in extreme cases like the largest S ATELLITE tasks, but have little impact on performance most of
the time. Deferred heuristic evaluation is very beneficial in some domains, with speed-ups of more than one order of
magnitude being common, is somewhat beneficial in the majority of domains, with speed-ups between 2 and 4, and
is very rarely detrimental to performance.

230

T HE FAST D OWNWARD P LANNING S YSTEM

Competition

Domain

Class

Number of tasks

IPC1 (AIPS 1998)

A SSEMBLY
G RID
G RIPPER
L OGISTICS
M OVIE
M YSTERY
MP RIME

ADL
STRIPS
STRIPS
STRIPS
STRIPS
STRIPS
STRIPS

30
5
20
35
30
30
35

IPC2 (AIPS 2000)

B LOCKSWORLD
F REECELL
L OGISTICS
M ICONIC -STRIPS
M ICONIC -S IMPLE ADL
M ICONIC -F ULL ADL
S CHEDULE

STRIPS
STRIPS
STRIPS
STRIPS
ADL
ADL
ADL

35
60
28
150
150
150
150

IPC3 (AIPS 2002)

D EPOT
D RIVERLOG
F REECELL
ROVERS
S ATELLITE
Z ENOTRAVEL

STRIPS
STRIPS
STRIPS
STRIPS
STRIPS
STRIPS

22
20
20
20
20
20

IPC4 (ICAPS 2004)

A IRPORT
P ROMELA -O PTICALT ELEGRAPH
P ROMELA -P HILOSOPHERS
P IPESWORLD -N OTANKAGE
P IPESWORLD -TANKAGE
PSR-S MALL
PSR-M IDDLE
PSR-L ARGE
S ATELLITE

STRIPS
PDDL2.2
PDDL2.2
STRIPS
STRIPS
STRIPS
PDDL2.2
PDDL2.2
STRIPS

50
48
48
50
50
50
50
50
36

Figure 21: Planning domains of the first four international planning competitions.

231

H ELMERT

much larger and hence likely more difficult to solve. We apply the formulation vs. encoding view
more strictly and thus only consider one PSR-M IDDLE domain and one domain for each of the two
P ROMELA variants, P ROMELA -P HILOSOPHERS and P ROMELA -O PTICALT ELEGRAPH.
Of the IPC1 benchmark set, all tasks are solvable except for 11 M YSTERY instances. Of the
IPC2 benchmark set, all tasks are solvable except for 11 M ICONIC -F ULL ADL instances. All
IPC3 benchmarks are solvable. For IPC4, we have not checked all instances of the P IPESWORLD TANKAGE domain, but we assume that all are tasks are solvable.
If run in any of the heuristic search modes, Fast Downward proves the unsolvability of the
unsolvable M YSTERY and M ICONIC -F ULL ADL tasks by using the dead-end detection routine described in our earlier article on the causal graph heuristic (Helmert, 2004), or in some cases in the
M ICONIC -F ULL ADL domain by exhaustively searching all states with a finite FF heuristic. Of
course, if an unsolvable task is proved unsolvable by the planner, we report this as a “successfully
solved” instance in the experimental results.
7.2 Experimental Setup
As discussed in Section 6, there are eleven possible configurations of Fast Downward’s search
component. However, not all of them are equally reasonable. For example, if we use FF’s helpful
actions, it would seem wasteful not to use the FF heuristic estimate, since these two are calculated
together. Therefore, for the greedy best-first search setup, we exclude configurations where FF
helpful actions are always computed. For the multi-heuristic best-first search setup, we exclude
configurations where only one type of preferred operators is considered, but not the other, since this
would seem to be a very arbitrary choice. This leaves us with six different configurations of the
planner:
1. G: Use greedy best-first search without preferred operators.
2. G + P: Use greedy best-first search with helpful transitions as preferred operators.
3. G + P+ : Use greedy best-first search with helpful transitions as preferred operators. Use
helpful actions as preferred operators in states with no helpful transitions.
4. M: Use multi-heuristic best-first search without preferred operators.
5. M + P: Use multi-heuristic best-first search with helpful transitions and helpful actions as
preferred operators.
6. F: Use focused iterative-broadening search.
We apply each of these planner configurations to each of the 1442 benchmark tasks, using a
computer with a 3.066 GHz Intel Xeon CPU — the same machine that was used at IPC4 — and set
a memory limit of 1 GB and a timeout of 300 seconds.
To compare Fast Downward to the state of the art, we try to solve each benchmark with the
best-performing planners from the literature. Unfortunately, this involves some intricacies: some
planners are not publicly available, and others only cover a restricted subset of PDDL2.2. For the
main experiment, we thus partition the benchmark domains into three sets depending on which
planners are available for comparison.
232

T HE FAST D OWNWARD P LANNING S YSTEM

Domain

Task

Configuration

F REECELL (IPC2)
G RID
MP RIME
PSR-L ARGE
S ATELLITE (IPC4)

probfreecell-10-1
prob05
prob14
p30-s179-n30-l3-f30
p33-HC-pfile13

M+P
M
M
G+P
M+P

Preprocessing
9.30 s
10.04 s
22.38 s
43.43 s
180.74 s

Search
298.64 s
291.01 s
291.67 s
265.29 s
169.09 s

Figure 22: Tasks which could be solved by some configuration of Fast Downward with a search
timeout of 300 seconds, but not with a total processing timeout of 300 seconds. The
column “preprocessing” shows the total time for translation and knowledge compilation.

7.3 Translation and Knowledge Compilation vs. Search
Of course, the results we report for Fast Downward include the time spent in all three components
of the planner: translation, knowledge compilation, and search. Therefore, in the following presentation of results, we only consider a task solved if the total processing time is below 300 seconds.
However, we have also investigated which tasks can be solved with a timeout of 300 seconds for the
search component alone, allowing the other components to use an arbitrary amount of resources. It
turns out that this only makes a difference in five cases, most of which could have been solved in a
total time below 310 seconds (Fig. 22). Only in one of these five cases, a S ATELLITE instance of
exorbitant size, did search take less time than the other two phases combined. These results show
that the search component is the only time-critical part of Fast Downward in practice. Therefore,
we do not report separate performance results for the individual components.
7.4 STRIPS Domains from IPC1–3
Let us now present the results of the main experiment. We abstain from listing runtimes for individual planning tasks due to the prohibitively large amount of data. These are available as an electronic
appendix to this article.8 Instead, we report the following information:
• Tables showing the number of tasks not solved by each planner within the 300 second timeout.
Here, we present individual results for each domain.
• Graphs showing the number of tasks solved in a given time by each planner. Here, we do not
present separate results for each domain, as this would require too many graphs.
We do not discuss plan lengths; our observations in this regard are similar to those made for the
original implementation of the causal graph heuristic (Helmert, 2004).
Fig. 23 shows the number of unsolved tasks for each of the STRIPS domains from IPC1–3.
Figs. 24 and 25 show the number of tasks solved by each planner within a given time bound between
0 and 300 seconds. In addition to the six configurations of Fast Downward under consideration, the
table includes four other columns.
Under the heading “Any”, we include results for a hypothetical meta-planner that guesses the
best of the six configuration of Fast Downward for each input task and then executes Fast Downward
8. http://www.jair.org/

233

H ELMERT

Domain

#Tasks

G

B LOCKSWORLD
D EPOT
D RIVERLOG
F REECELL (IPC2)
F REECELL (IPC3)
G RID
G RIPPER
L OGISTICS (IPC1)
L OGISTICS (IPC2)
M ICONIC -STRIPS
M OVIE
M YSTERY
MP RIME
ROVERS
S ATELLITE (IPC3)
Z ENOTRAVEL

35
22
20
60
20
5
20
35
28
150
30
30
35
20
20
20

0
12
2
4
0
1
0
1
0
0
0
1
0
2
1
0

0
13
0
4
0
2
0
0
0
0
0
2
0
0
0
0

0
13
0
12
5
1
0
0
0
0
0
1
0
0
0
0

Total

550

24

21

32

G+P G+P+ M

M+P

F

Any

CG

FF

LPG

0
12
1
11
1
1
0
4
0
0
0
0
2
0
0
0

0
8
0
12
2
0
0
0
0
0
0
0
0
0
0
0

17
11
1
40
14
4
0
26
0
0
0
13
14
2
6
0

0
7
0
3
0
0
0
0
0
0
0
0
0
0
0
0

0
14
3
2
0
1
0
0
0
0
0
1
1
3
0
0

4
3
5
3
2
0
0
0
0
0
0
12
3
0
0
0

0
0
0
55
19
1
0
4
0
0
0
15
7
0
0
0

32

22

148

10

25

32

101

Figure 23: Number of unsolved tasks for the STRIPS domains from IPC1, IPC2, and IPC3.
PSfrag replacements
FDD (Fast Downward)

550 (100%)

FD (Fast Downward)
YAHSP
Macro-FF

495 (90%)

LPG-TD
CG
FF
LPG

Solved Tasks

SGPlan

440 (80%)

Any (Fast Downward)
G + P (Fast Downward)
M + P (Fast Downward)
G (Fast Downward)
G + P+ (Fast Downward)
M (Fast Downward)
F (Fast Downward)

385 (70%)

0s

50s

100s

150s
Search Time

200s

250s

300s

Figure 24: Number of tasks solved vs. runtime for the STRIPS domains from IPC1, IPC2 and IPC3.
This graph shows the results for the various configurations of Fast Downward.

234

T HE FAST D OWNWARD P LANNING S YSTEM

PSfrag replacements
FDD (Fast Downward)

550 (100%)

FD (Fast Downward)
YAHSP
Macro-FF

495 (90%)

LPG-TD

Solved Tasks

SGPlan

440 (80%)

G + P+ (Fast Downward)
Any (Fast Downward)
G + P (Fast Downward)
CG
FF
LPG

385 (70%)
G (Fast Downward)
M + P (Fast Downward)
M (Fast Downward)
F (Fast Downward)

0s

50s

100s

150s
Search Time

200s

250s

300s

Figure 25: Number of tasks solved vs. runtime for the STRIPS domains from IPC1, IPC2 and IPC3.
This graph shows the results for CG, FF and LPG and the hypothetical “Any” planner
which always chooses the best configuration of Fast Downward. The result for greedy
best-first search with helpful transitions is repeated for ease of comparison with Fig. 24.

235

H ELMERT

with this setting. Under the heading “CG”, we report the results for our first implementation of the
causal graph heuristic (Helmert, 2004). 9 Finally, “FF” and “LPG” refer to the well-known planners
(Hoffmann & Nebel, 2001; Gerevini et al., 2003) which won the fully-automated tracks of IPC2
and IPC3. They were chosen for comparison on this benchmark set because they showed the best
performance by far of all publicly available planners we experimented with. For LPG, which uses a
randomized search strategy, we attempted to solve each task five times and report the median result.
The results show excellent performance of Fast Downward on this set of benchmarks. Compared to CG, which was already shown to solve more tasks than FF and LPG on this benchmark set
(Helmert, 2004), we get another slight improvement for half of the planner configurations. One of
the configurations, multi-heuristic best-first search using preferred operators, solves all benchmarks
in all domains except D EPOT and F REECELL. Even more importantly, the number of tasks not
solved by any of the Fast Downward configurations is as small as 10. Note that the planning competitions typically allowed a planner to spend 30 minutes on each task; under these time constraints,
we could allocate five minutes to each of the six configurations of Fast Downward, getting results
which are at least as good as those reported for the “Any” planner. Results might even be better
under a cleverer allocation scheme.
Even the configuration using focused iterative-broadening search performs comparatively well
on these benchmarks, although it cannot compete with the other planners. Not surprisingly, this
version of the planner has difficulties in domains with many dead ends (F REECELL, M YSTERY,
MP RIME) or where goal ordering is very important (B LOCKSWORLD, D EPOT). It also fares comparatively badly in domains with very large instances, namely L OGISTICS (IPC1) and S ATELLITE.
The reader should keep in mind that FF and LPG are excellent planning systems; of all the other
planners we experimented with, including all those that were awarded prizes at the first three planning competitions, none solved more benchmarks from this group than focused iterative-broadening
search.
The one domain that proves quite resistant to Fast Downward’s solution attempts in any configuration is D EPOT. As we already observed in the initial experiments with the causal graph heuristic
(Helmert, 2004), we believe that one key problem here is that Fast Downward, unlike FF, does not
use any goal ordering techniques, which are very important in this domain. The fact that the domain
includes a B LOCKSWORLD-like subproblem is also problematic, as it gives rise to very dense causal
graphs as we demonstrated in Section 5.2.3.
7.5 ADL Domains from IPC1–3
Second, we present results for the ADL domains of the first three planning competitions. This is a
much smaller group than the previous, including only four domains. This time, we cannot consider
CG or LPG, since neither CG nor the publicly available version of LPG supports ADL domains.
Therefore, we compare to FF exclusively. Again, we report the number of unsolved tasks in each
domain (Fig. 26) and present graphs showing how quickly the tasks are solved (Figs. 27 and 28).
These results do not look as good as for the first group of domains. Results in both M ICONIC
domains are good, even improving on those of FF. However, greedy best-first search performs very
badly in the A SSEMBLY domain, and all configurations perform badly in the S CHEDULE domain.
9. Apart from missing support for ADL and axioms, CG is very similar to Fast Downward using greedy best-first search
and no preferred operators (configuration G). The translation and knowledge compilation components are essentially
identical. The older search component mainly differs from Fast Downward in that it does not use deferred heuristic
evaluation.

236

T HE FAST D OWNWARD P LANNING S YSTEM

Domain

#Tasks

A SSEMBLY
M ICONIC -S IMPLE ADL
M ICONIC -F ULL ADL
S CHEDULE
Total

30
150
150
150
480

G
28
0
9
134
171

G+P G+P+ M
27
0
8
93
128

25
0
9
93
127

3
0
9
132
144

M+P

F

Any

FF

0
0
8
28
36

30
0
90
113
233

0
0
6
25
31

0
0
12
0
12

Figure 26: Number of unsolved tasks for the ADL domains from IPC1, IPC2 and IPC3.

PSfrag replacements
FDD (Fast Downward)

480 (100%)

FD (Fast Downward)

432 (90%)

YAHSP
Macro-FF

384 (80%)

LPG-TD
CG
FF
LPG

Solved Tasks

SGPlan

336 (70%)
288 (60%)

Any (Fast Downward)

240 (50%)
M + P (Fast Downward)
G + P+ (Fast Downward)
G + P (Fast Downward)
M (Fast Downward)
G (Fast Downward)
F (Fast Downward)

192 (40%)
144 (30%)
0s

50s

100s

150s
Search Time

200s

250s

300s

Figure 27: Number of tasks solved vs. runtime for the ADL domains from IPC1, IPC2 and IPC3.
This graph shows the results for the various configurations of Fast Downward.

237

H ELMERT

PSfrag replacements
FDD (Fast Downward)

480 (100%)

FD (Fast Downward)

432 (90%)

YAHSP
Macro-FF

384 (80%)

LPG-TD
CG

LPG

G + P+ (Fast Downward)

Solved Tasks

SGPlan

336 (70%)
288 (60%)
240 (50%)

G + P (Fast Downward)
G (Fast Downward)

M (Fast Downward)
F (Fast Downward)

192 (40%)

FF
Any (Fast Downward)
M + P (Fast Downward)

144 (30%)
0s

50s

100s

150s
Search Time

200s

250s

300s

Figure 28: Number of tasks solved vs. runtime for the ADL domains from IPC1, IPC2 and IPC3.
This graph shows the results for FF and the hypothetical “Any” planner which always
chooses the best configuration of Fast Downward. The result for multi-heuristic bestfirst search with preferred operators is repeated for ease of comparison with Fig. 27.

238

T HE FAST D OWNWARD P LANNING S YSTEM

Currently, we have no good explanation for the A SSEMBLY behaviour. For the S CHEDULE domain, the weak performance again seems to be related to missing goal ordering techniques: In
many S CHEDULE tasks, several goals are defined for the same object which can only be satisfied
in a certain order. For instance, for objects that should be cylindrical, polished and painted, these
three goals must be satisfied in precisely this order: making an object cylindrical reverts the effects
of polishing and painting, and polishing reverts the effect of painting. Not recognising these constraints, the heuristic search algorithm assumes to be close to the goal when an object is already
polished and painted but not cylindrical, and is loathe to transform the object into cylindrical shape
because this would undo the already achieved goals. With some rudimentary manual goal ordering,
ignoring painting goals until all other goals have been satisfied, the number of tasks not solved by
multi-heuristic best-first search with preferred operators drops from 28 to 3. These three failures
appear to be due to the remaining ordering problems with regard to cylindrical and polished objects.
7.6 Domains from IPC4
Third and finally, we present results for the IPC4 domains. Here, we do not compare to FF: for these
benchmarks, FF does not perform as well as the best planners from the competition. Besides, several
of the IPC4 competitors are extensions of FF or hybrids using FF as part of a bigger system, so FFbased planning is well-represented even if we limit our attention to the IPC4 planners. For this
comparison, we chose the four most successful competition participants besides Fast Downward,
namely LPG-TD, SGPlan, Macro-FF and YAHSP (cf. the results in Hoffmann & Edelkamp, 2005).
Similar to the previous two experiments, we report the number of unsolved tasks in each domain
(Fig. 29) and present graphs showing how quickly the tasks are solved (Figs. 30 and 31).
Fast Downward is competitive with the other planners across domains, and better than all others
in some. The P IPESWORLD domains are the only ones in which any of the other planners is noticeably better than the two competition versions of Fast Downward. This is the case for YAHSP in both
P IPESWORLD domain variants and for SGPlan in P IPESWORLD -N OTANKAGE . The P IPESWORLD
domain is not very hierarchical in nature; this might be a domain where the decomposition approach of the causal graph heuristic is not very appropriate. The results of the heuristic search
configurations in the P ROMELA -O PTICALT ELEGRAPH domain are extremely bad and require further investigation.
Interestingly, focused iterative-broadening search performs very well on some of the benchmarks from this suite. One of the reasons for this is that in many of the tasks of the IPC4 suite, there
are many individual goals which are easy to serialize and can be solved mostly independently. 10
Comparing the configuration G to G + P + and especially M to M + P, we also observe that using preferred operators is very useful for these benchmarks, even more so than in the two previous
experiments.
As a final remark, we observe that if we implemented the “Any” meta-planner by calling the six
Fast Downward configurations in a round-robin fashion, we would obtain a planning system that
could solve all but 54 of the IPC4 benchmarks within a 6 · 5 = 30 minute timeout. This is almost on
par with the top performer of IPC4, Fast Diagonally Downward, which solved all but 52 of the IPC4
benchmarks under the same timeout. Thus, this is a benchmark set for which exploring different
planner configurations definitely pays off.
10. We have devised an experiment which shows that if this property is artificially violated by a simple goal reformulation,
the performance of the algorithm degrades quickly; see the electronic appendix for details.

239

H ELMERT

Domain

#Tasks

A IRPORT
P IPESWORLD -N OTANKAGE
P IPESWORLD -TANKAGE
P ROMELA -O PTICALT ELEGRAPH
P ROMELA -P HILOSOPHERS
PSR-S MALL
PSR-M IDDLE
PSR-L ARGE
S ATELLITE (IPC4)
Total

50
50
50
48
48
50
50
50
36
432

G
28
24
36
48
0
0
0
22
8
166

G+P G+P+ M

M+P

F

Any

30
25
36
47
0
0
0
20
0
158

14
7
17
46
0
0
0
22
3
109

0
10
34
13
21
1
22
39
22
162

0
7
14
13
0
0
0
20
0
54

17
23
36
48
0
0
0
22
0
146

18
14
34
47
16
0
0
23
8
160

Domain

FD

FDD

LPG-TD

Macro-FF

SGPlan

YAHSP

A IRPORT
P IPESWORLD -N OTANKAGE
P IPESWORLD -TANKAGE
P ROMELA -O PTICALT ELEGRAPH
P ROMELA -P HILOSOPHERS
PSR-S MALL
PSR-M IDDLE
PSR-L ARGE
S ATELLITE (IPC4)
Total

0
11
34
22
0
0
0
22
0
89

0
7
19
22
0
0
0
22
3
73

7
10
29
37
1
2
0
50
1
137

30
12
29
31
36
50
19
50
0
257

6
0
20
29
0
6
4
39
6
110

17
0
13
36
19
3
50
50
0
188

Figure 29: Number of unsolved tasks for the IPC4 domains. Results for the various configurations
of Fast Downward are listed in the upper part, results for the competition participants
in the lower part. “FD” and “FDD” denote the versions of Fast Downward that participated in IPC4 under the names “Fast Downward” and “Fast Diagonally Downward”
(cf. Section 6).

240

T HE FAST D OWNWARD P LANNING S YSTEM

PSfrag replacements
FDD (Fast Downward)

432 (100%)

FD (Fast Downward)

389 (90%)

YAHSP

346 (80%)

Macro-FF
SGPlan

CG
FF
LPG

302 (70%)
Solved Tasks

LPG-TD

Any (Fast Downward)

259 (60%)
216 (50%)
173 (40%)
130 (30%)
M + P (Fast Downward)
G + P+ (Fast Downward)
G + P (Fast Downward)
M (Fast Downward)
F (Fast Downward)
G (Fast Downward)

86 (20%)
43 (10%)
0s

50s

100s

150s
Search Time

200s

250s

300s

Figure 30: Number of tasks solved vs. runtime for the IPC4 domains. This graph shows the results
for the various configurations of Fast Downward.
PSfrag replacements
432 (100%)
389 (90%)
346 (80%)

CG
FF
LPG

G + P+ (Fast Downward)
G + P (Fast Downward)
G (Fast Downward)

Solved Tasks

302 (70%)
259 (60%)
216 (50%)
173 (40%)
130 (30%)

Any (Fast Downward)
FDD (Fast Downward)
FD (Fast Downward)
SGPlan
LPG-TD
YAHSP
Macro-FF

86 (20%)
43 (10%)

M + P (Fast Downward)
M (Fast Downward)
F (Fast Downward)

0s

50s

100s

150s
Search Time

200s

250s

300s

Figure 31: Number of tasks solved vs. runtime for the IPC4 domains. This graph shows the results
for the hypothetical “Any” planner which always chooses the best configuration of Fast
Downward, the competition configurations of Fast Downward and the best four other
participants.

241

H ELMERT

7.7 Conclusions from the Experiment
How can we interpret these experimental results? Our first conclusion is that Fast Downward is
clearly competitive with the state of the art. This is especially true for the configuration using
multi-heuristic best-first search with preferred operators (M+P), which outperforms all competing
planning systems both on the set of STRIPS domains from IPC1–3 and on the domains from IPC4.
If it were not for the problems in the S CHEDULE domain, the same would be true for the remaining
group of benchmarks, the ADL domains from IPC1–3.
With regard to the second objective of the investigation, evaluating the relative strengths of the
different planner configurations, the M+P configuration emerges as a clear-cut winner. In 23 out of
29 domains, no other configuration solves more tasks, and unlike the other configurations, there is
only one domain (P ROMELA -O PTICALT ELEGRAPH) in which it performs very badly. We conclude
that both multi-heuristic best-first search and the use of preferred operators are promising extensions
to heuristic planners.
This is particularly true for preferred operators. Indeed, after the M+P configuration, the two
variants of greedy best-first search with preferred operators show the next best overall performance,
both in terms of the number of domains where they are among the top performers and in terms of
the total number of tasks solved. Comparing G to G+P, there are ten domains in which the variant
using preferred operators solves more tasks than the one not using them; the opposite is true in five
domains. Comparing M to M+P, the difference is even more striking, with the preferred operator
variant outperforming the other in fifteen domains, while being worse in two (in both of which it
only solves one task less). These are convincing arguments for the use of preferred operators.

8. Summary and Discussion
Before we turn to discussion, let us briefly summarize the contributions of this article. As a motivating starting point, we explained that planning tasks often exhibit a simpler structure if expressed
with multi-valued state variables, rather than the traditional propositional representations. We then
introduced Fast Downward, a planning system based on the idea of converting tasks into a multivalued formalism and exploiting the causal information underlying such encodings.
Fast Downward processes PDDL planning tasks in three stages. We skipped the first of these
stages, translation, which automatically transforms a PDDL task into an equivalent multi-valued
planning task with a nicer causal structure. We explained the inner workings of the second stage,
knowledge compilation, demonstrating in depth what kind of knowledge the planner extracts from
the problem representation, discussing causal graphs, domain transition graphs, successor generators and axiom evaluators. During our discussion of Fast Downward’s search component, we
introduced its heuristic search algorithms, which use the technique of deferred heuristic evaluation
to reduce the number of states for which a heuristic goal distance estimate must be computed. In
addition to greedy best-first search, Fast Downward employs the multi-heuristic best-first search
algorithm to usefully integrate the information of two heuristic estimators, namely the causal graph
heuristic and FF heuristic. Both heuristic search algorithms can utilize preference information
about operators. We also introduced Fast Downward’s experimental focused iterative-broadening
search algorithm, which is based on the idea of pruning the set of operators to only consider those
successor states which are likely to lead towards a specific goal.
We thus tried to give a complete account of the Fast Downward planning system’s approach to
solving multi-valued planning tasks, including its motivation, architecture, and algorithmic founda242

T HE FAST D OWNWARD P LANNING S YSTEM

tions. In the previous section, we demonstrated its empirical behaviour, showing good performance
across the whole range of propositional benchmarks from the previous planning competitions.
Among all the novel algorithms and search enhancements discussed in this article, there are two
aspects of Fast Downward which we consider of central importance and which we would like to
emphasize. One of them is the use of multi-valued state variables for PDDL-style planning. We
believe that multi-valued representations are much more structured and hence much more amenable
to automated reasoning — be it for the purposes of heuristic evaluation, problem decomposition,
or other aspects of planning such as goal ordering or extraction of landmarks. The other central
idea is the use of hierarchical decompositions within a heuristic planning framework. Hierarchical
approaches to domain-independent planning have a considerable potential, but since the work of
Knoblock (1994) and Bacchus and Yang (1994), little work has been published. With Fast Downward, we hope to renew interest in this area, which we believe to be a very promising ground for
further advances in automated planning.
For the future, there are several aspects of Fast Downward that we would like to investigate
further. First, we intend to experiment with other search techniques along the lines of focused
iterative-broadening search, which emphasize heuristically evaluating operator usefulness rather
than heuristically evaluating states.
Second, we would like to come up with an efficient heuristic for multi-valued planning tasks
which does not require pruning cycles of the causal graph. Initial experiments in this direction have
shown that it is difficult to achieve this goal without losing the performance of Fast Downward’s
heuristic estimator, but perhaps better heuristic accuracy can outweigh worse per-state performance
in many cases.
Third, we want to investigate in how far the performance of the planner could be improved
by encoding some domains differently. In some cases, merging a set of state variables which are
closely interrelated into a single state variable whose domain is the product of the domains of the
original state variables might be beneficial. Also, we want to test if hand-tailored encodings lead to
better performance than automatically derived ones, and if so, how large the performance gap is.
Fourth and finally, we would like to evaluate the behaviour of the causal graph heuristic in
specific planning domains both empirically and theoretically, following Hoffmann’s work on the FF
heuristic (Hoffmann, 2001, 2002, 2005). Hopefully, this will give some indication when we can
expect good performance from the causal graph heuristic and when it is advisable to look for other
approaches.

Acknowledgements
The author wishes to thank Silvia Richter, the other member of the Fast Downward team at the
4th International Planning Competition, for her part in implementing the planner and for valuable
advice before, throughout, and after the competition. She also deserves thanks for helping out with
the experiments, for proof-reading this article, and for suggesting a number of improvements.
The anonymous reviewers of the article and the handling editor, Maria Fox, made a number of
useful suggestions that led to significant improvements.
This work was partly supported by the German Research Council (DFG) within the Graduate
Programme “Mathematical Logic and Applications” and as part of the Transregional Collaborative
Research Centre “Automatic Verification and Analysis of Complex Systems” (SFB/TR 14 AVACS).
See www.avacs.org for more information.
243

H ELMERT

References
Bacchus, F., & Yang, Q. (1994). Downward refinement and the efficiency of hierarchical problem
solving. Artificial Intelligence, 71(1), 43–100.
Bäckström, C., & Nebel, B. (1995). Complexity results for SAS + planning. Computational Intelligence, 11(4), 625–655.
Bonet, B., & Geffner, H. (2001). Planning as heuristic search. Artificial Intelligence, 129(1), 5–33.
Brafman, R. I., & Domshlak, C. (2003). Structure and complexity in planning with unary operators.
Journal of Artificial Intelligence Research, 18, 315–349.
Bylander, T. (1994). The computational complexity of propositional STRIPS planning. Artificial
Intelligence, 69(1–2), 165–204.
Domshlak, C., & Brafman, R. I. (2002). Structure and complexity in planning with unary operators.
In Ghallab, M., Hertzberg, J., & Traverso, P. (Eds.), Proceedings of the Sixth International
Conference on Artificial Intelligence Planning and Scheduling (AIPS 2002), pp. 34–43. AAAI
Press.
Domshlak, C., & Dinitz, Y. (2001). Multi-agent off-line coordination: Structure and complexity.
In Cesta, A., & Borrajo, D. (Eds.), Pre-proceedings of the Sixth European Conference on
Planning (ECP’01), pp. 277–288, Toledo, Spain.
Dowling, W. F., & Gallier, J. H. (1984). Linear-time algorithms for testing the satisfiability of
propositional Horn formulae. Journal of Logic Programming, 1(3), 367–383.
Edelkamp, S., & Helmert, M. (1999). Exhibiting knowledge in planning problems to minimize
state encoding length. In Fox, M., & Biundo, S. (Eds.), Recent Advances in AI Planning.
5th European Conference on Planning (ECP’99), Vol. 1809 of Lecture Notes in Artificial
Intelligence, pp. 135–147, New York. Springer-Verlag.
Edelkamp, S., & Hoffmann, J. (2004). PDDL2.2: The language for the classical part of the 4th
International Planning Competition. Tech. rep. 195, Albert-Ludwigs-Universität Freiburg,
Institut für Informatik.
Fox, M., & Long, D. (2003). PDDL2.1: An extension to PDDL for expressing temporal planning
domains. Journal of Artificial Intelligence Research, 20, 61–124.
Garey, M. R., & Johnson, D. S. (1979). Computers and Intractability — A Guide to the Theory of
NP-Completeness. Freeman.
Gerevini, A., Saetti, A., & Serina, I. (2003). Planning through stochastic local search and temporal
action graphs in LPG. Journal of Artificial Intelligence Research, 20, 239–290.
Ginsberg, M. L., & Harvey, W. D. (1992). Iterative broadening. Artificial Intelligence, 55, 367–383.
Helmert, M. (2004). A planning heuristic based on causal graph analysis. In Zilberstein, S., Koehler,
J., & Koenig, S. (Eds.), Proceedings of the Fourteenth International Conference on Automated
Planning and Scheduling (ICAPS 2004), pp. 161–170. AAAI Press.
Hoffmann, J. (2001). Local search topology in planning benchmarks: An empirical analysis. In
Nebel, B. (Ed.), Proceedings of the 17th International Joint Conference on Artificial Intelligence (IJCAI’01), pp. 453–458. Morgan Kaufmann.
244

T HE FAST D OWNWARD P LANNING S YSTEM

Hoffmann, J. (2002). Local search topology in planning benchmarks: A theoretical analysis. In
Ghallab, M., Hertzberg, J., & Traverso, P. (Eds.), Proceedings of the Sixth International Conference on Artificial Intelligence Planning and Scheduling (AIPS 2002), pp. 92–100. AAAI
Press.
Hoffmann, J. (2005). Where ‘ignoring delete lists’ works: Local search topology in planning benchmarks. Journal of Artificial Intelligence Research, 24, 685–758.
Hoffmann, J., & Edelkamp, S. (2005). The deterministic part of IPC-4: An overview. Journal of
Artificial Intelligence Research, 24, 519–579.
Hoffmann, J., & Nebel, B. (2001). The FF planning system: Fast plan generation through heuristic
search. Journal of Artificial Intelligence Research, 14, 253–302.
Jonsson, P., & Bäckström, C. (1995). Incremental planning. In Ghallab, M., & Milani, A. (Eds.),
New Directions in AI Planning: EWSP ’95 — 3rd European Workshop on Planning, Vol. 31
of Frontiers in Artificial Intelligence and Applications, pp. 79–90, Amsterdam. IOS Press.
Jonsson, P., & Bäckström, C. (1998a). State-variable planning under structural restrictions: Algorithms and complexity. Artificial Intelligence, 100(1–2), 125–176.
Jonsson, P., & Bäckström, C. (1998b). Tractable plan existence does not imply tractable plan generation. Annals of Mathematics and Artificial Intelligence, 22(3), 281–296.
Joslin, D., & Roach, J. (1989). A theoretical analysis of conjunctive-goal problems. Artificial
Intelligence, 41(1), 97–106. Research Note.
Knoblock, C. A. (1994). Automatically generating abstractions for planning. Artificial Intelligence,
68(2), 243–302.
Korf, R. E. (1987). Planning as search: A quantitative approach. Artificial Intelligence, 33(1),
65–88.
Lowerre, B. T. (1976). The HARPY Speech Recognition System. Ph.D. thesis, Computer Science
Department, Carnegie-Mellon University, Pittsburgh, Pennsylvania.
Newell, A., & Simon, H. A. (1963). GPS: A program that simulates human thought. In Feigenbaum,
E. A., & Feldman, J. (Eds.), Computers and Thought, pp. 279–293. Oldenbourg.
Russell, S., & Norvig, P. (2003). Artificial Intelligence — A Modern Approach. Prentice Hall.
Sacerdoti, E. D. (1974). Planning in a hierarchy of abstraction spaces. Artificial Intelligence, 5,
115–135.
Tenenberg, J. D. (1991). Abstraction in planning. In Allen, J. F., Kautz, H. A., Pelavin, R. N.,
& Tenenberg, J. D., Reasoning About Plans, chap. 4, pp. 213–283. Morgan Kaufmann, San
Mateo.
van den Briel, M., Vossen, T., & Kambhampati, S. (2005). Reviving integer programming approaches for AI planning: A branch-and-cut framework. In Biundo, S., Myers, K., & Rajan,
K. (Eds.), Proceedings of the Fifteenth International Conference on Automated Planning and
Scheduling (ICAPS 2005), pp. 310–319. AAAI Press.
Williams, B. C., & Nayak, P. P. (1997). A reactive planner for a model-based executive. In Pollack,
M. E. (Ed.), Proceedings of the 15th International Joint Conference on Artificial Intelligence
(IJCAI’97), pp. 1178–1195. Morgan Kaufmann.
245

H ELMERT

Yoshizumi, T., Miura, T., & Ishida, T. (2000). A ∗ with partial expansion for large branching factor problems. In Kautz, H., & Porter, B. (Eds.), Proceedings of the Seventeenth National
Conference on Artificial Intelligence (AAAI-2000), pp. 923–929. AAAI Press.

246

Journal of Artificial Intelligence Research 26 (2006) 453-541

Submitted 12/05; published 08/06

Engineering Benchmarks for Planning: the Domains Used in the
Deterministic Part of IPC-4
Jörg Hoffmann

HOFFMANN @ MPI - SB . MPG . DE

Max Planck Institute for Computer Science,
Saarbrücken, Germany

Stefan Edelkamp

STEFAN . EDELKAMP @ CS . UNI - DORTMUND . DE

Fachbereich Informatik,
Universität Dortmund, Germany

Sylvie Thiébaux

S YLVIE .T HIEBAUX @ ANU . EDU . AU

National ICT Australia & Computer Sciences Laboratory,
The Australian National University, Canberra, Australia

Roman Englert

ROMAN .E NGLERT @ TELEKOM . DE

Deutsche Telekom Laboratories,
Berlin, Germany

Frederico dos Santos Liporace

LIPORACE @ INF. PUC - RIO . BR

Departamento de Informática, PUC-Rio,
Rio de Janeiro, Brazil

Sebastian Trüg

TRUEG @ INFORMATIK . UNI - FREIBURG . DE

Institut für Informatik,
Universität Freiburg, Germany

Abstract
In a field of research about general reasoning mechanisms, it is essential to have appropriate
benchmarks. Ideally, the benchmarks should reflect possible applications of the developed technology. In AI Planning, researchers more and more tend to draw their testing examples from the
benchmark collections used in the International Planning Competition (IPC). In the organization
of (the deterministic part of) the fourth IPC, IPC-4, the authors therefore invested significant effort
to create a useful set of benchmarks. They come from five different (potential) real-world applications of planning: airport ground traffic control, oil derivative transportation in pipeline networks,
model-checking safety properties, power supply restoration, and UMTS call setup. Adapting and
preparing such an application for use as a benchmark in the IPC involves, at the time, inevitable
(often drastic) simplifications, as well as careful choice between, and engineering of, domain encodings. For the first time in the IPC, we used compilations to formulate complex domain features
in simple languages such as STRIPS, rather than just dropping the more interesting problem constraints in the simpler language subsets. The article explains and discusses the five application
domains and their adaptation to form the PDDL test suites used in IPC-4. We summarize known
theoretical results on structural properties of the domains, regarding their computational complexity
and provable properties of their topology under the h+ function (an idealized version of the relaxed
plan heuristic). We present new (empirical) results illuminating properties such as the quality of
the most wide-spread heuristic functions (planning graph, serial planning graph, and relaxed plan),
the growth of propositional representations over instance size, and the number of actions available
to achieve each fact; we discuss these data in conjunction with the best results achieved by the
different kinds of planners participating in IPC-4.

c
2006
AI Access Foundation. All rights reserved.

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

1. Introduction
Today, to a large extent the research discipline of AI planning is concerned with improving the performance of domain independent generative planning systems. A domain independent generative
planning system (planner) must be able to fully automatically find plans: solution sequences in
declaratively specified transition systems. The simplest planning formalism is deterministic planning. There, a planner is given as input a set of state variables (often just Booleans, called facts),
an initial state (a value assignment to the variables), a goal (a formula), and a set of actions (with a
precondition formula describing applicability, and with an effect specifying how the action changes
the state). A plan is a time-stamped sequence of actions that maps the initial state into a state that
satisfies the goal. This sort of formalism is called deterministic since the initial state is fully specified and the effects of the actions are non-ambiguous. Both restrictions may be weakened to obtain
non-deterministic and probabilistic planning.
Performance of planners is measured by testing them on benchmark example instances of the
planning problem. The “best” algorithm at any point in time is, generally, considered to be the one
that solves these examples most efficiently. In particular, this is the idea in the International Planning Competition (IPC), a biennial event aimed at showcasing the capabilities of current planning
systems.
The first IPC took place in 1998, so at the time of writing there were four such events. Providing details about the IPC is beyond the scope of this paper, and we refer the reader to the overview
articles written by the organizers of the respective IPC editions (McDermott, 2000; Bacchus, 2001;
Long & Fox, 2003; Hoffmann & Edelkamp, 2005). In particular, Hoffmann and Edelkamp (2005)
provide details about the 4th IPC, such as overall organization, different tracks, evaluation, participating planners, and results. Basic information is included in this paper, so the reader should be
able to follow the main discussion without a detailed background. The language used to describe
planning problems in the IPC is called PDDL: Planning Domain Definition Language. It was introduced by McDermott (1998) for the first IPC, IPC-1, in 1998. A subset of the language was
selected by Bacchus (2000) for IPC-2 in 2000. The language was extended with temporal and numerical constructs by Fox and Long (2003) to form the language PDDL2.1 for IPC-3 in 2002. It was
further extended with two additional constructs, “timed initial literals” and “derived predicates”, by
Hoffmann and Edelkamp (2005) to form the language PDDL2.2 for IPC-4 in 2004.
Since, even in its simplest forms, AI planning is a computationally hard problem, no system
can work efficiently in all problem instances (Bylander, 1994; Helmert, 2003). Thus, it is of crucial importance what kinds of examples are used for testing. Today, more and more, AI Planning
researchers draw their testing examples from the collections used in the IPC. This makes the IPC
benchmarks a very important instrument for the field. In the organization of the deterministic part
of the 4th IPC (there was also a probabilistic part, see Younes, Littman, Weissman, & Asmuth,
2005), the authors therefore invested considerable effort into creating a set of “useful” benchmarks
for planning.
The very first question to answer is what precisely is meant here by the word “useful”. This is
not an easy question. There is no widely accepted mathematical definition for deciding whether a
set of benchmarks should be considered useful. There are, however, widely accepted intuitions of
when this is the case. Benchmarks should be:
1. Oriented at applications – a benchmark should reflect an application of the technology developed in the field.
454

E NGINEERING B ENCHMARKS

FOR

P LANNING

2. Diverse in structure – a set of benchmarks should cover different kinds of structure, rather
than re-state very similar tasks.
The first of these is usually considered particularly important – indeed, AI planning has frequently been criticized for its “obsession with toy examples”. In recent years, the performance of
state-of-the-art systems has improved dramatically, and with that more realistic examples have come
within reach. We made another step in this direction by orienting most of the IPC-4 benchmarks at
application domains. While traditionally planning benchmarks were more or less fantasy products
created having some “real” scenario in mind,1 we took actual (possible) applications of planning
technology, and turned them into something suitable for the competition. We considered five different application domains: airport ground traffic control (Airport), oil derivative transportation in
pipeline networks (Pipesworld), model checking safety properties (Promela), power supply restoration (PSR), and setup of mobile communication in UMTS (UMTS). Of course, in the adaptation of
an application for use in the IPC, simplifications need to be made. We will get back to this below.
Diverse structure of benchmarks has traditionally been given less attention than realism, but
we believe that it is no less important. The structure underlying a testing example determines the
performance of the applied solving mechanism. This is particularly true for solving mechanisms
whose performance rises and falls with the quality of a heuristic they use. Hoffmann’s (2001, 2002,
2005) results suggest that much of the spectacular performance of modern heuristic search planners
is due to structural similarities between most of the traditional planning benchmarks. While this
does not imply that modern heuristic search planners aren’t useful, it certainly shows that in the
creation of benchmarks there is a risk of introducing a bias towards one specific way of solving
them. In selecting the benchmark domains for IPC-4, we tried to cover a range of intuitively very
different kinds of problem structure. We will get back to this below.
On the one hand, a creator of planning benchmarks has the noble goal of realistic, and structurally diverse, benchmark domains. On the other hand, he/she has the more pragmatic goal to
come up with a version/representation of the benchmarks that can be attacked with existing planning systems. Given the still quite restricted capabilities of systems, obviously the two goals are in
conflict. To make matters worse, there isn’t an arbitrarily large supply of planning applications that
are publicly available, and/or whose developers agree to have their application used as the basis of
a benchmark. For the IPC organizer, on top of all this, the final benchmarks must be accessible for
a large enough number of competing systems, which means they must be formulated in a language
understood by those systems. Further, the benchmarks must show differences between the scalability of planners, i.e., they must not be too easy or too hard, thus straddling the boundary of current
system capabilities.
The solution to the above difficulties, at least our solution in the organization of IPC-4, involved a slow tedious interleaved process of contacting application developers, choosing domains,
exploring domain versions, and engineering domain version representations. This article presents,
motivates, and discusses our choice of benchmark domains for IPC-4; it explains the engineering
processes that led to the finally used domain versions and instances. Further, we report about,
and present some new data determining certain structural properties of the resulting benchmarks
(more details below). The main contribution of the work is the set of benchmarks, provided in
1. Of course, there are exceptions to this rule. One important one, in our context here, is the Satellite domain, used in
IPC-3, that we further refined for use in IPC-4. More on this later.

455

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

IPC-4.2 The contributions of this article are: first, providing the necessary documentation of these
benchmarks; second, describing the technical processes used in their creation; third, providing an
extensive discussion of the structural properties of the benchmarks. Apart from these more technical contributions, we believe that our work has value as an example of a large-scale attempt at
engineering a useful set of benchmarks for classical planning.
It is difficult to make any formal claim about our created set of benchmarks, such as that they
are in some way better than the previous benchmarks. When working on this, our intent was to
overcome certain shortcomings of many benchmarks, though one would be hard pressed to come
up with a formal proof that such improvements were indeed made. After all, judging the quality of
a set of benchmarks is a rather complex matter guided mostly by intuitions, and, worse, personal
opinions.3 What we did was, do our best to create as realistic, structurally diverse, and accessible
benchmarks as possible for IPC-4. Our belief is that we succeeded in doing so. The benchmarks
definitely differ in certain ways from most of the previous benchmarks. We think that most of these
differences are advantageous; we will discuss this at the places where we point out the differences.
Regarding realism of the benchmarks, as pointed out above, the main step we took was to design
benchmarks “top-down”, i.e., start from actual possible applications of planning technology, and
turn them into something suitable for the competition – rather than the more traditional “bottomup” approach of just artificially creating a domain with some “real” scenario in mind. Of course,
for modelling an application in PDDL, particularly for modelling it in a way making it suitable
for use in the IPC, simplifications need to be made. In some cases, e.g., airport ground traffic
control, the simplifications were not overly drastic, and preserved the overall properties and intuitive
structure of the domain. But in other cases, e.g., oil derivative transportation in pipeline networks,
the simplifications we needed to make were so drastic that these domains could just as well have
been created in the traditional bottom-up way. Still, even if greatly simplified, a domain generated
top-down has a better chance to capture some structure relevant in a real application. Moreover,
a top-down domain has the advantage that since it is derived from a real application, it provides
a clear guideline towards more realism; the future challenge is to make planners work on more
realistic encodings of the application. In the previous competitions, the only domains generated
top-down in the above sense were the Elevator domain used in IPC-2 (Koehler & Schuster, 2000;
Bacchus, 2001), and the Satellite and Rovers domains used in IPC-3 (Long & Fox, 2003).
Regarding diverse structure of the benchmarks, in contrast to the previous competitions, in the
IPC-4 domains there is no common “theme” underlying many of the benchmarks. In IPC-1, 5 out
of 7 domains were variants of transportation; in IPC-2, 4 out of 7 domains were variants of transportation; in IPC-3, 3 out of 6 domains were variants of transportation, and 2 were about gathering
data in space. Some of the “variants” are in fact very interesting in their use of constructs such
as locked locations, fuel units, road map graphs, stackable objects, and complex side constraints.
However, there is certainly an intuitive similarity in the structure and relationships in the domains.
To some extent this similarity is even automatically detectable (Long & Fox, 2000). Not so in IPC4: airport ground traffic control, oil derivative transportation in pipeline networks, model checking
safety properties, power supply restoration, and UMTS call setup are rather different topics. At
2. The benchmarks can be downloaded from the IPC-4 web page at http://ipc.icaps-conference.org/
3. Consider for example the Movie domain used in IPC-1. All instances of this domain, no matter what their size is,
share the same space of reachable states; the only thing that increases is the connectivity between states, i.e. the
number of actions that have the same effect. Still one can argue that Movie is a useful benchmark, in the sense that it
can highlight systems/approaches that have/have no difficulties in attacking such problem characteristics.

456

E NGINEERING B ENCHMARKS

FOR

P LANNING

most one could claim that airport ground traffic control and UMTS call setup both have a scheduling nature. We will see, however, that the IPC-4 version of airport ground traffic control allows
considerably more freedom than classical scheduling formulations, making it a PSPACE-complete
decision problem. The particulars of the domains will be overviewed in Section 3.
Approaching “structure” from a more formal point of view is more difficult. It is largely unclear
what, precisely, the relevant structure in a planning domain/instance is, in a general sense. While
Hoffmann (2001, 2002, 2005) provides one possible definition – search space surface topology under a certain heuristic function – there are many other possible options. In particular, Hoffmann’s
results are relevant only for heuristic search planners that generate their heuristic functions based on
the “ignoring delete lists” relaxation (McDermott, 1996, 1999; Bonet, Loerincs, & Geffner, 1997;
Bonet & Geffner, 2001; Hoffmann & Nebel, 2001). For lack of a better formal handle, we used
Hoffmann’s definitions to qualify the structure of the domains. The selected domains cover different regions of Hoffmann’s “planning domain taxonomy”, in particular they lie in regions that
have less coverage in the traditional benchmarks. Because they are interesting in the context of
the paper at hand, we summarize Hoffmann’s (2005) results for 30 domains including all domains
used in the previous competitions. We also summarize Helmert’s (2006b) results on the computational complexity of satisficing and optimal planning in the IPC-4 domains. It turns out that their
complexity covers a wide range – the widest possible range, for propositional planning formalisms
– from PSPACE-hard to polynomial. We finally provide some new data to analyze the structural
relationships and differences between the domains. Amongst other things, for each instance, we
measure: the number of (parallel and sequential) steps needed to achieve the goal, estimated by the
smallest plan found by any IPC-4 participant; the same number as estimated by planning graphs
and relaxed plans; and the distribution of the number of possible achieving actions for each fact.
The results are examined in a comparison between the different domains, taking into account the
runtime performance exhibited by the different kinds of planners in IPC-4.
Apart from realism and diverse structure, our main quest in the creation of the IPC-4 benchmarks
was to promote their accessibility. Applications are, typically, if they can be modelled at all in
PDDL, most naturally modelled using rather complex language constructs such as time, numeric
variables, logical formulas, and conditional effects. Most existing systems handle only subsets of
this, in fact more than half of the systems entered into IPC-4 (precisely, 11 out of 19) could handle
only the simple STRIPS language, or slight extensions of it.4 In the previous competitions, as done
for example in the Elevator, Satellite, and Rovers domains, this was handled simply by dropping
the more interesting domain constraints in the simpler languages, i.e., by removing the respective
language constructs from the domain/instance descriptions. In contrast, for the first time in the IPC,
we compiled as much of the domain semantics as possible down into the simpler language formats.
Such a compilation is hard, sometimes impossible, to do. It can be done for ADL constructs, as
well as for the two new constructs introduced for the IPC-4 language PDDL2.2, derived predicates
and timed initial literals. We implemented, and applied, compilation methods for all these cases.
4. STRIPS (Stanford Research Institute Problem Solver) is the name of the simplest and at the same time most widespread planning language. In the form of the language used today, the state variables are all Boolean, formulas are
conjunctions of positive atoms, action effects are either atomic positive (make a fact true/add it) or atomic negative
(make a fact false/delete it) (Fikes & Nilsson, 1971). The languages selected for IPC-2 (Bacchus, 2000), from which
PDDL2.1 and PDDL2.2 are derived, were STRIPS and ADL. ADL is a prominent, more expressive, alternative
to STRIPS, extending it with arbitrary first-order formulas as preconditions and goal, and with conditional effects,
i.e., effects that occur only if their individual effect condition (a first-order formula) is met in the state of execution
(Pednault, 1989).

457

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

The compilations serve to preserve more of the original domain structure, in the simpler language
classes. For example, the STRIPS version of the Elevator domain in IPC-2 is so simplified from the
original ADL version that it bears only marginal similarity to real elevator control – in particular,
the planner can explicitly tell passengers to get into or out of the lift.5 In contrast, our STRIPS
formulation of the airport ground traffic domain is, semantically, identical to our ADL formulation
– it expresses the same things, but in a more awkward fashion.
The compiled domain “versions” were offered to the competitors as alternative domain version “formulations”, yielding a 2-step hierarchy for each domain. That is, each domain in IPC-4
could contain several different domain versions, differing in terms of the number of domain constraints/properties considered. Within each domain version, there could be several domain version formulations, differing in terms of the language used to formulate the (same) semantics. The
competitors could choose, within each version, whichever formulation their planners could handle
best/handle at all, and the results within the domain version were then evaluated together. This
way, we intended to make the competition as accessible as possible while at the same time keeping
the number of separation lines in the data – the number of distinctions that need to be made when
evaluating the data – at an acceptable level.
We are, of course, aware that encoding details can have a significant impact on system performance.6 Particularly, when compiling ADL to STRIPS, in most cases we had to revert to fully
grounded encodings. While this certainly isn’t desirable, we believe it to be an acceptable price to
pay for the benefit of accessibility. Most current systems ground the operators out as a pre-process
anyway. In cases where we considered the compiled domain formulations too different from the
original ones to allow for a fair comparison – typically because plan length increased significantly
due to the compilation – the compiled formulation was posed to the competitors as a separate domain version.
The article is organized as follows. The main body of text contains general information. In
Section 2, we give a detailed explanation of the compilation methods we used. In Section 3, we give
a summary of the domains, each with a short application description, our motivation for including
the domain, a brief explanation of the main simplifications made, and a brief explanation of the
different domain versions and formulations. In Section 4, we summarize Hoffmann’s (2005) and
Helmert’s (2006b) theoretical results on the structure of the IPC-4 domains. Section 5, we provide
our own empirical analysis of structural properties. Section 6 discusses what was achieved, and
provides a summary of the main issues left open. For each of the IPC-4 domains, we include a
separate section in Appendix A, providing detailed information on the application, its adaptation
for IPC-4, its domain versions, the example instances used, and future directions. Although these
details are in an appendix, we emphasize that this is not because they are of secondary importance.
On the contrary, they describe the main body of work we did. The presentation in an appendix
seems more suitable since we expect the reader to, typically, examine the domains in detail in a
selective and non-chronological manner.
5. The passengers won’t get in (out) at floors other than their origin (destination); however, with explicit control, the
planner can choose to not let someone in (out). The more accurate encoding is via conditional effects of the action
stopping the lift at a floor.
6. A very detailed account of such matters is provided by Howe and Dahlman (2002).

458

E NGINEERING B ENCHMARKS

FOR

P LANNING

2. PDDL Compilations
We used three kinds of compilation methods:
• ADL to SIMPLE-ADL (STRIPS with conditional effects) or STRIPS;
• PDDL with derived predicates to PDDL without them;
• PDDL with timed initial literals to PDDL without them.
We consider these compilation methods in this order, explaining, for each, how the compilation
works, what the main difficulties and their possible solutions are, and giving an outline of how we
used the compilation in the competition. Note that ADL, SIMPLE-ADL, and STRIPS are subsets
of PDDL. Each of the compilation methods was published elsewhere already (see the citations in
the text). This section serves as an overview article, since a coherent summary of the techniques,
and their behavior in practice, has not appeared elsewhere in the literature.
2.1 Compilations of ADL to SIMPLE-ADL and STRIPS
ADL constructs can be compiled away with methods first proposed by Gazen and Knoblock (1997).
Suppose we are given a planning instance with constant (object) set C, initial state I, goal G, and
operator set O. Each operator o has a precondition pre(o), and conditional effects e, taking the form
con(e), add(e), del(e) where add(e) and del(e) are lists of atoms. Preconditions, effect conditions,
and G are first order logic formulas (effect conditions are T RU E for unconditional effects). Since
the domain of discourse – the set of constants – is finite, the formulas can be equivalently transformed into propositional logic.
(1) Quantifiers are turned into conjunctionsVand disjunctions, simply by expanding
W them with the
available objects: ∀x : φ(x) turns into c∈C φ(c) and ∃x : φ(x) turns into c∈C φ(c). Iterate
until no more quantifiers are left.
Since STRIPS allows only conjunctions of positive atoms, some further transformations are necessary.
(2) Formulas are brought into negation normal form: ¬(φ ∧ ψ) turns into ¬φ ∨ ¬ψ and ¬(φ ∨ ψ)
turns into ¬φ ∧ ¬ψ. Iterate until negation is in front of atoms only.
(3) For each ¬x that occurs in a formula: introduce a new predicate not-x; set not-x ∈ I iff
x 6∈ I; for all effects e: set not-x ∈ add(e) iff x ∈ del(e) and not-x ∈ del(e) iff x ∈ add(e);
in all formulas, replace ¬x with not-x. Iterate until no more negations are left.
(4) Transform all formulas into DNF: (φ1 ∨ φ2 ) ∧ (ψ1 ∨ ψ2 ) turns into (φ1 ∧ ψ1 ) ∨ (φ1 ∧ ψ2 ) ∨
(φ2 ∧ ψ1 ) ∨ (φ2 ∧ ψ2 ). Iterate until no more conjunctions occur above disjunctions. If an
operator precondition pre(o) has n > 1 disjuncts, then create n copies of o each with one
disjunct as precondition. If an effect condition con(e) has n > 1 disjuncts, then create n
copies of e each with one disjunct as condition. If G has n > 1 disjuncts, then introduce a
new fact goal-reached, set G := goal-reached, and create n new operators each with one
disjunct as precondition and a single unconditional effect adding goal-reached.

459

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

(:action move
:parameters
(?a - airplane ?t - airplanetype ?d1 - direction ?s1 ?s2 - segment ?d2 - direction)
:precondition
(and (has-type ?a ?t) (is-moving ?a) (not (= ?s1 ?s2)) (facing ?a ?d1) (can-move ?s1 ?s2 ?d1)
(move-dir ?s1 ?s2 ?d2) (at-segment ?a ?s1)
(not (exists (?a1 - airplane) (and (not (= ?a1 ?a)) (blocked ?s2 ?a1))))
(forall (?s - segment) (imply (and (is-blocked ?s ?t ?s2 ?d2) (not (= ?s ?s1))) (not (occupied ?s)))))
:effect
(and (occupied ?s2) (blocked ?s2 ?a) (not (occupied ?s1)) (not (at-segment ?a ?s1)) (at-segment ?a ?s2)
(when (not (is-blocked ?s1 ?t ?s2 ?d2)) (not (blocked ?s1 ?a)))
(when (not (= ?d1 ?d2)) (and (not (facing ?a ?d1)) (facing ?a ?d2)))
(forall (?s - segment) (when (is-blocked ?s ?t ?s2 ?d2) (blocked ?s ?a)))
(forall (?s - segment) (when
(and (is-blocked ?s ?t ?s1 ?d1) (not (= ?s ?s2)) (not (is-blocked ?s ?t ?s2 ?d2)))
(not (blocked ?s ?a))))))

Figure 1: An operator from airport ground traffic control.
As an illustrative example, consider the operator description in Figure 1, taken from our domain
encoding airport ground traffic control. This operator moves an airplane from one airport segment
to another. Consider specifically the precondition formula (not (exists (?a1 - airplane) (and (not (=
?a1 ?a)) (blocked ?s2 ?a1)))), saying that no airplane different from “?a” is allowed to block segment
“?s2”, the segment we are moving into. Say the set of airplanes is a1 , . . . , an . Then step (1) will
turn the formula into (not (or (and (not (= a1 ?a)) (blocked ?s2 a1 )) . . . (and (not (= an ?a)) (blocked ?s2
an )))). Step (2) yields (and (or (= a1 ?a) (not (blocked ?s2 a1 ))) . . . (or (= an ?a) (not (blocked ?s2 an )))).
Step (3) yields (and (or (= a1 ?a) (not-blocked ?s2 a1 )) . . . (or (= an ?a) (not-blocked ?s2 an ))). Step (4),
finally, will (naively) transform this into (or (and (= a1 ?a) . . . (= an ?a)) . . . (and (not-blocked ?s2 a1 )
. . . (not-blocked ?s2 an ))), i.e., more mathematically notated:
_
^
x.
x∈{(= a1

?a),(not-blocked ?s2 a1 )}×...×{(= an ?a),(not-blocked ?s2 an )}

In words, transforming the formula into a DNF requires enumerating all n-vectors of atoms where
each vector position i is selected from one of the two possible atoms regarding airplane ai . This
yields an exponential blow-up to a DNF with 2n disjuncts. The DNF is then split up into its single
disjuncts, each one yielding a new copy of the operator.
The reader will have noticed that an exponential blow-up is also inherent in compilation step
(1), where each quantifier may be expanded to |C| sub-formulas, and k nested quantifiers will
be expanded to |C|k sub-formulas. Obviously, in general there is no way around either of the
blow-ups, other than to deal with more complex formulas than allowed in STRIPS. In practice,
however, these blow-ups can typically be dealt with reasonably well, thanks to the relative simplicity
of operator descriptions, and the frequent occurrence of static predicates, explained shortly. If
quantifiers aren’t deeply nested, like in Figure 1, then the blow-up inherent in step (1) does not
matter. Transformation to DNF is more often a problem – like in our example here. The key
to successful application of the compilation in practice, at least as far as our personal experience
goes, is the exploitation of static predicates. This idea is described, for example, by Koehler and
460

E NGINEERING B ENCHMARKS

FOR

P LANNING

Hoffmann (2000). Static predicates aren’t affected by any operator effect. Such predicates can be
easily found, and their truth value is fully determined by the initial state as soon as they are fully
instantiated. In the above transformation through step (4), the operator parameters are still variables,
and even if we knew that “=” is (of course) a static predicate, this would not help us because we
wouldn’t know what “?a” is. If we instantiate “?a”, however, then, in each such instantiation of
the operator, the “(= ?a1 ?a)” atoms trivialize to TRUE or FALSE, and the large DNF collapses
V
to the single conjunction a 6= ?a1 airplane (not-blocked ?s2 ?a1), where “a” is our instantiation of
“?a”. Similarly, the expansion of quantifiers is often made much easier by first instantiating the
operator parameters, and then inserting TRUE or FALSE for any static predicate as soon as its
parameters are grounded. Inserting TRUE or FALSE often simplifies the formulas significantly
once this information is propagated upwards (e.g., a disjunction with a TRUE element becomes
TRUE itself).
Assuming our compilation succeeded thus far, after steps (1) to (4) are processed we are down to
a STRIPS description with conditional effects, i.e., the actions still have conditional effects con(e),
add(e), del(e) where con(e) is a conjunction of atoms. This subset of ADL has been termed
“SIMPLE-ADL” by Fahiem Bacchus, who used it for the encoding of one of the versions of the
“Elevator” domain used in IPC-2 (i.e. the 2000 competition). We can now choose to leave it in
this language, necessitating a planning algorithm that can deal with conditional effects directly.
Several existing planning systems, for example FF (Hoffmann & Nebel, 2001) and IPP (Koehler,
Nebel, Hoffmann, & Dimopoulos, 1997), do this. It is a sensible approach since, as Nebel (2000)
proved, conditional effects cannot be compiled into STRIPS without either an exponential blowup in the task description, or a linear increase in plan length. One might suspect here that, like
with steps (1) and (4) above, the “exponential blow-up” can mostly be avoided in practice. The
airport move operator in Figure 1 provides an example of this. All effect conditions are static and so
the conditional effects disappear completely once we instantiate the parameters – which is another
good reason for doing instantiation prior to the compilation. However, the conditional effects do not
disappear in many other, even very simple, natural domains. Consider the following effect, taken
from the classical Briefcaseworld domain:
(forall (?o) (when (in ?o) (and (at ?o ?to) (not (at ?o ?from)))))

The effect says that any object “?o” that is currently in the briefcase moves along with the briefcase.
Obviously, the effect condition is not static, and the outcome of the operator will truly depend on the
contents of the briefcase. Note that the “forall” here means that we actually have a set of (distinct)
conditional effects, one for each object.
There are basically two known methods to compile conditional effects away, corresponding to
the two options left open by Nebel’s (2000) result. The first option is to enumerate all possible
combinations of effect outcomes, which preserves plan length at the cost of an exponential blow-up
in description size – exponential in the number of different conditional effects of any single action.
Consider the above Briefcaseworld operator, and say that the object set is o1 , . . . , on . For every
subset o01 , . . . o0k of o1 , . . . , on , o0k+1 , . . . , o0n being the complement of the subset, we get a distinct
operator with a precondition that contains all of:
(in o01 ) . . . (in o0k ) (not-in o0k+1 ) . . . (not-in o0n )

Where the effect on the objects is:
(at o01 ?to) . . . (at o0k ?to) (not (at o01 ?from)) . . . (not (at o0k ?from))
461

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

In other words, the operator can be applied (only) if exactly o01 , . . . o0k are in the briefcase, and it
moves exactly these objects. Since (in deterministic planning as considered here) there never is
uncertainty about what objects are inside the briefcase and what are not, exactly one of the new
operators can be applied whenever the original operator can be applied. So the compilation method
preserves the size (nodes) and form (edges) of the state space. However, we won’t be able to do the
transformation, or the planner won’t be able to deal with the resulting task, if n grows beyond, say,
maximally 10 . . . 20. Often, real-world operators contain more distinct conditional effects than that.
The alternative method, first proposed by Nebel (2000), is to introduce artificial actions and
facts that enforce, after each application of a “normal” action, an effect-evaluation phase during
which all conditional effects of the action must be tried, and those whose condition is satisfied
must be applied. For the above Briefcaseworld example, this would look as follows. First, the
conditional effect gets removed, a new fact “evaluate-effects” is inserted into the add list, and a
new fact “normal” is inserted into the precondition and delete list. Then we have 2n new operators,
two for each object oi . One means “move-along-oi ”, the other means “leave-oi ”. The former has
“in(oi )” in its precondition, the latter “not-in(oi )”. The former has “(at oi ?to)” and “(not (at oi
?from)” in its effect. Both have “evaluate-effects” in their precondition, and a new fact “tried-oi ”
as an add effect. There is a final new operator that stops the evaluation, whose precondition is the
conjunction of “evaluate-effects” and “tried-o1 ”, . . . , “tried-on ”, whose add effect is “normal”, and
whose delete effect is “evaluate-effects”. If the conditional effects of several operators are compiled
away with this method, then the “evaluate-effects” and “tried-oi ” facts are made specific to each
operator; “normal” can remain a single fact used by all the operators. If an effect has k > 1 facts in
its condition, then k “leave-oi ” actions must be created, each having the negation of one of the facts
in its precondition.
Nebel’s (2000) method increases plan length by the number of distinct conditional effects of
the operators. Note that this is not benign if there are, say, more than 20 such effects. To a search
procedure that recognizes what the new constructs do, the search space essentially remains the
same as before the compilation. But, while the artificial constructs can easily be deciphered for
what they are by a human, this is not necessarily true (is likely to not be the case) for a computer
that searches with some general-purpose search procedure. Just as an example, in a naive forward
search space there is now a choice of how to order the application of the conditional effects (which
could be avoided by enforcing some order with yet more artificial constructs). Probably more
importantly, standard search heuristics are unlikely to recognize the nature of the constructs. For
example, without delete lists it suffices to achieve all of “tried-o1 ”, . . . , “tried-on ” just once, and
later on apply only those conditional effects that are needed.
We conclude that if it is necessary to eliminate conditional effects, whenever feasible, one should
compile conditional effects away with the first method, enumerating effect outcomes. We did so in
IPC-4. We took FF’s pre-processor, that implements the transformation steps (1) to (4) above, and
extended it with code that compiles conditional effects away, optionally by either of the two described methods. We call the resulting tool “adl2strips”.7 In most cases where we had a domain
version formulated in ADL, we used adl2strips to generate a STRIPS formulation of that domain
version. In one case, a version of power supply restoration, we also generated a SIMPLE-ADL
7. Executables of adl2strips can be downloaded from the IPC-4 web page at http://ipc.icaps-conference.org. There is
also a download of a tool named “Ground”, based on the code of the Mips system (Edelkamp, 2003b), that takes in
the full syntax of PDDL2.2 (Hoffmann & Edelkamp, 2005) and puts out a grounded representation (we did not have
to use the tool in IPC-4 since the temporal and numeric planners all had their own pre-processing steps implemented).

462

E NGINEERING B ENCHMARKS

FOR

P LANNING

formulation. In all cases but one, enumerating effect outcomes was feasible. The single exception was another version of power supply restoration where we were forced to use Nebel’s (2000)
method. Details of this process, and exceptions where we did not use adl2strips but some more
domain-specific method, are described in the sections on the individual domains in Appendix A.
2.2 Compilations of Derived Predicates
There are several proposals in the literature as to how to compile derived predicates away, under certain restrictions on their form or their use in the rest of the domain description (Gazen &
Knoblock, 1997; Garagnani, 2000). A compilation scheme that works in general has been proposed
by Thiébaux, Hoffmann, and Nebel (2003, 2005). Thiébaux et al. also proved that there is no compilation scheme that works in general and that does not, in the worst case, involve an exponential
blow-up in either the domain description size or in the length of the plans. Note here that “exponential” refers also to the increase in plan length, not just to the description blow-up, unlike the
compilation of conditional effects discussed above. This makes the compilation of derived predicates a rather difficult task. In IPC-4, compilation schemes oriented at the approaches taken by
Gazen and Knoblock (1997), and Thiébaux et al. (2003, 2005), were used. We detail this below.
First, let us explain what derived predicates are, and how the compilations work.
Derived predicates are predicates that are not affected by any of the operators, but whose truth
value can be derived by a set of derivation rules. These rules take the form φ(x) ⇒ P (x). The
basic intuition is that, if φ(x) is satisfied for an instantiation c of the variable vector x, then P (c)
can be concluded. More formally, the semantics of the derivation rules are defined by negation as
failure: starting with the empty extension, instances of P (c) are derived until a fixpoint is reached;
the instances that lie outside the fixpoint are assumed to be FALSE. Consider the following example:
(:derived (trans ?x ?y) (or (edge ?x ?y ) (exists (?z) (and (edge ?x ?z) (trans ?z ?y)))))

This derivation rule defines the transitive closure over the edges in a graph. This is a very typical
application of derived predicates. For example, “above” in the Blocksworld is naturally formalized
by such a predicate; in our power supply restoration domain, transitive closure models the power
flow over the paths in a network of electric lines. Obviously, the pairs “?x” and “?y” that are not
transitively connected are those that do not appear in the fixpoint – negation as failure.
Matters become interesting when we think about how derived predicates are allowed to refer to
each other, and how they may be used in the rest of the task description. Some important distinctions
are: Can a derived predicate appear in the antecedent of a derivation rule? Can a derived predicate
appear negated in the antecedent of a derivation rule? Can a derived predicate appear negated in an
action precondition or the goal?
If derived predicates do not appear in the antecedents of derivation rules, then they are merely
non-recursive macros, serving as syntactic sugar. One can simply replace the derived predicates
with their definitions.8 If a derived predicate P appears negated in the (negation normal form of the)
antecedent of a derivation rule for predicate Q, then the fixpoints of P and Q can not be computed
in an interleaved way: the extension of Q may differ depending on the order in which the individual
instances are derived. Say the rule for P is A(x) ⇒ P (x), where A is a basic predicate, and the rule
for Q is ¬P (x) ⇒ Q(x). Say we have objects a and b, and our current state satisfies (only) A(a).
8. If the derived predicates are recursive but cycle-free, they can be replaced with their definitions but that may incure
an exponential blow-up.

463

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

Computing the derived predicates in an interleaved way, we may derive A(a) ⇒ P (a), ¬A(b) ⇒
Q(b), and stop; we may also derive ¬P (a) ⇒ Q(a), ¬A(b) ⇒ Q(b), A(a) ⇒ P (a). There is
a non-monotonic behavior, making it non-trivial to define what the extension of B is. To keep
things simple – after all the extensions of the derived predicates must be computed in every new
world state – Thiébaux et al. (2003, 2005) propose to simply order Q after P . That is, we compute
P ’s extension first and then compute Q based on that. Generalized, one ends up with a semantics
corresponding to that of stratified logic programs (Apt, Blair, & Walker, 1988). In the context of
IPC-4, i.e., in PDDL2.2 (Hoffmann & Edelkamp, 2005), for the sake of simplicity the use of negated
derived predicates in the antecedents of derivation rules was not allowed.
Whether or not derived predicates appear negated in action preconditions or the goal makes
a difference for Gazen and Knoblock’s (1997) compilation scheme. The idea in that scheme is
to simply replace derivation rules with actions. Each rule φ(x) ⇒ P (x) is replaced with a new
operator with parameters x, precondition φ(x) and (add) effect P (x). Actions that can influence the
truth value of φ – that affect any of the atoms mentioned in φ – delete all instances of P . In words,
the new actions allow the derivation of P , and if a normal action is applied that may influence the
value of P , then the extension of P is re-initialized.
If derived predicates are not used negated, then Gazen and Knoblock’s (1997) compilation
scheme works. However, say ¬P (c) is contained in some action precondition. In the compiled
version, the planner can achieve this precondition simply by not applying the “derivation rule” – the
action – that adds P (c). That is, the planner now has a choice of what predicate instances to derive,
which of course is not the same as the negation as failure semantics. The reader may at this point
wonder why we do not compile the negations away first, and thereafter use Gazen and Knoblock’s
(1997) compilation. The problem there would be the need for inverse derivation rules that work
with the negation as failure semantics. It is not clear how this should be done. Say, for example, we
want to define the negated version of the “(trans ?x ?y)” predicate above. One would be tempted to
just take the negation of the derivation rule antecedent:
(:derived (not-trans ?x ?y) (and (not-edge ?x ?y) (forall (?z) (or (not-edge ?x ?z) (not-trans ?z ?y)))))

This does not work, however. Say every node in the graph has at least one adjacent edge. Starting
with an empty extension of “(not-trans ?x ?y)”, not a single instantiation can be derived: given any
x and y between which there is no edge, for those z that have an edge to x we would have to have
(not-trans z y) in the first place.
One possible solution to the above difficulties is to extend Gazen and Knoblock’s (1997) compilation with constructs that force the planner to compute the entire extension of the derived predicates
before resuming normal planning. A full description of this, dealing with arbitrary derivation rules,
is described by Thiébaux et al. (2003, 2005). In a nutshell, the compilation works as follows. One
introduces flags saying if one is in “normal” or in “fixpoint” mode. Normal actions invoke the fixpoint mode if they affect any predicates relevant to the derivation rules. In fixpoint mode, an action
can be applied that has one conditional effect for each derivation rule: if the effect condition is true,
and the respective derived predicate instance is false, then that predicate instance is added, plus a
flag “changes-made”. Another action tests whether there has been a fixpoint: if “changes-made” is
true, then the action just resets it to false; if “changes-made” is false, then the action switches back
to normal mode. To reduce the domain to STRIPS, after this compilation of derived predicates, the
negations and conditional effects must be compiled away with the techniques explained earlier.

464

E NGINEERING B ENCHMARKS

FOR

P LANNING

One would imagine that Thiebaux et al.’s (2003, 2005) compilation, making use of rather complicated constructs, tends to confuse domain independent search techniques. Indeed, Thiébaux
et al. (2003, 2005) report that even a completely naive explicit treatment of derived predicates in
FF performs a lot better, in some benchmark domains, than the standard version of FF applied to
the compiled benchmarks. Gazen and Knoblock’s (1997) compilation makes use of less artificial
constructs, and is thus preferable whenever it can safely be applied. Note, however, that both compilations imply a potentially exponential blow-up in plan length: exponential in the arity of the derived
predicates. The worst case is that every action affects the derivation rules, and every re-computation
of the extension of the derived predicates has to go through all those predicates’ instantiations. In
such a situation, between every pair of normal actions the planner has to apply on the order of |C|a
actions, where a is the maximum arity of any derived predicate. While a is typically very small
– power supply restoration is the only domain we are aware of that features a derived predicate
with more than two (four, namely) arguments – even a plan length increase linear in the number of
objects can mean a quite significant decrease in planner performance.
Of the IPC-4 benchmarks, derived predicates occur (only) in power supply restoration (Appendix A.4) and model checking safety properties (Appendix A.3). For the latter, where the derived
predicates do not occur negated, Stefan Edelkamp encoded a domain version without derived predicates by hand, using a method along the lines of the one described by Gazen and Knoblock (1997).
For power supply restoration, where derived predicates do occur negated, we used a variation of the
method described by Thiébaux et al. (2003, 2005). In both cases, due to the increase in plan length
we considered the resulting domain formulation too different from the original formulation to be directly compared with it, in terms of planner performance. So the compiled formulations were posed
to the competitors as distinct domain versions, instead of alternative domain version formulations.
Indeed, just as we expected, planner results in IPC-4 were much worse for the compiled encodings.
2.3 Compilations of Timed Initial Literals
Timed initial literals are literals that are known to become true at time points pre-specified in the
initial state. Such literals can be compiled into durational PDDL relatively easily, at the cost of
the plan length and the domain description size blowing up linearly in the number of timed initial
literals. The compilation was proposed and brought to our attention by Fox, Long, and Halsey
(2004). The idea is to use a “wrapper” action that must be applied before any other action, and
whose duration is the occurrence time of the last timed initial literal. The planner must also apply
a sequence of “literal” actions that achieve all the timed initial literals by order of occurrence,
the durations being the time intervals between the occurrences. When the “wrapper” action has
terminated, the “literal” actions can no longer be applied. So the planner is forced to apply them all
in direct sequence. This suffices to encode the desired semantics. Consider the following example:
(:init
(at 9 (have-to-work))
(at 19 (not (have-to-work)))
(at 19 (bar-open))
(at 23 (not (bar-open))))

To encode this in standard durational PDDL, the “wrapper” will be:
(:action wrapper
465

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

:parameters ()
:duration (= ?duration 23)
:condition
(at start (no-wrapper))
:effect
(and (at start (not (no-wrapper)))
(at start (wrapper-started))
(at start (wrapper-active))
(at start (literal-1-started))
(at end (not (wrapper-active)))))

Here, “no-wrapper” ensures only one wrapper action is executed; “wrapper-started” is inserted into
the precondition of every normal action and thus ensures that the wrapper is started before any other
action is executed; “wrapper-active” will be a precondition of the “literal” actions. Precisely, these
will be:
(:action literal-1
:parameters ()
:duration (= ?duration 9)
:condition
(and (over all (wrapper-active))
(over all (literal-1-started)))
:effect
(and (at end (not (literal-1-started)))
(at end (literal-2-started))
(at end (have-to-work))))
(:action literal-2
:parameters ()
:duration (= ?duration 10)
:condition
(and (over all (wrapper-active))
(over all (literal-2-started)))
:effect
(and (at end (not (literal-2-started)))
(at end (literal-3-started))
(at end (not (have-to-work)))
(at end (bar-open))))
(:action literal-3
:parameters ()
:duration (= ?duration 4)
:condition
(and (over all (wrapper-active))
(over all (literal-3-started)))
:effect
(and (at end (not (literal-3-started)))
(at end (not (bar-open)))
(at end (literals-done))))

466

E NGINEERING B ENCHMARKS

FOR

P LANNING

The fact “literals-done” will be made a goal, so the planner must actually apply the “literal” actions.
Note that we need only three of these actions here, since two of the timed initial literals – no
longer having to work and the opening of the bar – are scheduled to occur at the same time. Note
also that, as with Nebel’s (2000) compilation of conditional effects and Thiebaux et al.’s (2003,
2005) compilation of derived predicates, the compiled encoding is likely to be confusing for domain
independent search methods.
Many of the IPC-4 domains made use of timed initial literals (in some versions) to encode
various kinds of time windows (see Appendix A). We compiled these domain versions into pure
(durational) PDDL as above, and provided the resulting encodings as additional domain versions.
Due to the increase in the number of actions needed for the plans, we figured that the compilation
constructs were too much of a change for direct comparison. Indeed, as with the derived predicates,
planner results in IPC-4 were much worse for the domain versions compiled in this way.

3. A Summary of the Domains
In this section we provide a brief summary of the IPC-4 domains. For each domain, we provide: a
short description of the application; our motivation for inclusion of the domain; a brief explanation
of the main simplifications made for IPC-4; and a brief explanation of the different domain versions
and formulations used in IPC-4. We proceed in alphabetical order.
3.1 Airport
We had a contact person for this application domain, Wolfgang Hatzack, who has been working in
this application area for several years. The domain was adapted for IPC-4 by Jörg Hoffmann and
Sebastian Trüg
Application. The task here is to control the ground traffic at an airport. Timed travel routes must be
assigned to the airplanes so that they reach their targets. There is inbound and outbound traffic; the
former are airplanes that must take off, the latter are airplanes that have just landed and have to park.
The main problem constraint is, of course, to ensure the safety of the airplanes. This means to avoid
collisions, and also to prevent airplanes from entering the unsafe zones behind large airplanes that
have their engines running. The optimization criterion is to minimize the summed up travel time (on
the surface of the airport) of all airplanes.9 There usually are standard routes, i.e., routes that any
airplane must take when outbound from a certain parking area, or inbound from a certain runway.
The reason for introducing such routes is to reduce complexity for human ground controllers, since
significant computer support is not yet available at real airports. Solving instances optimally (the
corresponding decision problem) is PSPACE-hard without standard routes (Helmert, 2006b) and
NP-complete if all routes are standardized (Hatzack & Nebel, 2001). In the latter case, we have a
pure scheduling problem. In the former case, complicated – but unrealistic – airport traffic situations
can lead to exponentially long solutions, see Section 4.1.
Motivation. Our main motivation for including this domain was that we were able to model the
application quite accurately, and, in particular, to generate quite realistic instances. In fact, we
were able to generate instances based on a real airport. This was made possible by our contact
to Wolfgang Hatzack, who completed a PhD about this application (Hatzack, 2002). Apart from
9. An alternative criterion would be to minimize the summed up squared delay of all airplanes. This is in the interest
of the airlines; minimizing summed up travel time is in the interest of the airport. Neither of the two can be easily
modelled in PDDL2.2, as we discuss in Simplifications, below.

467

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

developing domain-specific solutions (Hatzack & Nebel, 2001), he developed a realistic simulation
tool, which he kindly supplied to us for the purpose of generating the IPC-4 domain versions and test
instances. Sebastian Trüg implemented options inside the simulator that allowed it, at any point in
time during the simulation of traffic flow, to output the current traffic situation in PDDL format. The
simulator included the real airports Frankfurt, Zurich, and Munich. Frankfurt and Zurich proved too
large for our purposes, but we were able to devise competition instances based on Munich airport.
Simplifications. We had to make two simplifications. The first amounts to a discretization of space
(location) on the airport, making the domain amenable to PDDL style discrete actions. With a
continuous space representation, one would need actions with a continuous choice of how far to
move. While the discretization loses precision, we believe that it does not distort the nature of
the problem too much. Due to the amount of expected conflicting traffic at different points in the
airport, which is high only at parking positions, it is relatively easy to choose a discretization –
with segments of different length – that is precise and small enough at the same time. Our second
simplification is more severe: we had to drop the original optimization criterion, which is very
awkward to express in current PDDL. To model the travel times of the airplanes, one needs access
to the times at which the plans wait, i.e., do nothing.10 We are not aware of a way to express this
in current PDDL. The IPC-4 committee voted against the introduction of an additional language
construct, a “look at the clock”, since that didn’t seem relevant anywhere else. Another option
would be to introduce explicit waiting actions, which causes a lot of trouble because, similar to
continuous space, there must be a continuous choice of how long to wait. In the end, we decided
to just drop the criterion for now, and ask the planners to optimize standard makespan instead,11
corresponding to the arrival time of the last airplane (meaning, arrival at the destination in the
airport). This is not ideal, but a reasonable optimization criterion. No planning system participating
in IPC-4, with the single exception of LPG-td (Gerevini, Saetti, & Serina, 2006), was able to take
account of general optimization criteria other than the built-in ones (like makespan). We did not use
full standard routes, thus allowing the airplanes a choice of where to move. We did use standards
for some routes, particularly the regions near runways in large airports. For one thing, this served
to keep large airports manageable for the PDDL encoding and planners; for another thing, it seems
a good compromise of exploiting the capabilities of computers while at the same time remaining
close to existing practice.
Versions and Formulations. We generated four versions of the airport domain: a non-temporal
one; a temporal one; a temporal one with time windows, where the fact that planes will land in the
future and block certain runways is modeled using timed initial literals; and the latter version, but
with timed initial literals compiled away. In all versions, the constraints ensuring airplane safety
are modelled with ADL logical formulas. A compilation of these into partially grounded STRIPS
provides, in each version, an alternative formulation: each domain version has one ADL formulation
and one STRIPS formulation.
3.2 Pipesworld
Frederico Liporace has been working in this application area for several years; he submitted a paper
on an early domain version to the workshop on the competition at ICAPS’03. The domain was
adapted for IPC-4 by Frederico Liporace and Jörg Hoffmann.
10. The same difficulty arises in the modelling of delay, for which one must also compute the travel times.
11. Makespan, in Planning, means the amount of time from the start of the plan until the last action stops executing.

468

E NGINEERING B ENCHMARKS

FOR

P LANNING

Application. Here the task is to control the flow of different oil derivatives through a pipeline
network, so that certain product amounts are transported to their destinations. Pipeline networks
are graphs consisting of areas (nodes) and pipes (edges), where the pipes can differ in length. The
available actions are to pump liquid into ends of pipes, with the effect that the liquid at the other end
of the pipe gets ejected. The application is rich in additional constraints, like, constraints on what
types of products may interface within a pipe, restricted tankage space in areas, and deadlines for
arrival of products.
Motivation. Our main motivation for including this domain was its original structure. If one inserts
something into a pipe at one end, something possibly completely different comes out of the pipe
at its other end. In this way, changing the position of one object directly results in changing the
position of several other objects – namely, all objects inside the affected pipeline. This is not the
case in any other transportation domain we are aware of, in fact it is more reminiscent of complicated
single-player games such as Rubik’s Cube. Indeed, the strong interaction between objects can lead
to several subtle phenomena. For example, there are instances where any solution must pump liquid
through a ring of pipeline segments in a cyclic fashion.
Simplifications. We had to severely simplify this domain in order to be able to solve reasonably
complex instances with current planners. Most importantly, our encoding is heavily based on assuming a smallest indivisible unit of liquid, a batch. Every amount of liquid in the encoding is modelled
in terms of a number of batches. To capture the continuous nature of the real application, this means
that one has to choose batch size in a trade-off between encoding size and accuracy. The trade-off
is less well-behaved than the one in Airport (choosing “segments” sizes) since the unit size cannot
be made flexible: every batch may pass through every pipeline, and so the smallest batch governs
the discretization of all pipelines. This is in contrast to Airport, where segments may vary in size.
As another important simplification, we used “personalized” goals, i.e. the goals referred to specific
batch objects rather than to product amounts. This serves to avoid large disjunctions enumerating
all possible combinations of individual batches. The simplifications are quite severe and indeed
it seems unlikely that a realistic representation of Pipesworld, in particular with real-valued product amounts instead of batches, could be solved efficiently by planners without introducing more
specialized language constructs – a sort of “queue” data structure – into PDDL, see Appendix A.2.5.
Versions and Formulations. We created six different versions of Pipesworld: four versions with /
without temporal actions, and with/without tankage restrictions, respectively; one temporal version
without tankage restrictions but with arrival deadlines for the goal batches; one version identical to
the last one except that timed initial literals were compiled away.
3.3 Promela
This domain was created for IPC-4 by Stefan Edelkamp.
Application. Here the task is to validate properties in systems of communicating processes (often
communication protocols), encoded in the Promela language. Promela (PROcess MEta LAnguage)
is the input language of the model checker SPIN (Holzmann, 2003). The language is loosely based
on Dijkstra’s guarded command language, borrowing some notation from Hoare’s CSP language.
One important property check is to detect deadlock states, where none of the processes can apply
a transition. For example, a process may be blocked when trying to read data from an empty
communication channel. Edelkamp (2003a) developed an automatic translation from Promela into
PDDL, which was extended to generate the competition examples.

469

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

Motivation. Our main motivation for including this domain was to further promote and make visible the important connection between Planning and Model Checking. Model Checking (Clarke,
Grumberg, & Peled, 1999) itself is an automated formal method that basically consists of three
phases: modeling, specification and checking. In the first two phases both the system and the correctness specification are modeled using some formalism. The last step automatically checks if the
model satisfies its specification. Roughly speaking, this step analyzes the state space of the model to
check the validity of the specification. Especially in concurrent systems, where several components
interact, state spaces grow exponentially in the size of the components of the system. There are two
main research branches in model checking: explicit-state model checking, as implemented in SPIN,
exploits automata theory and stores each explored state individually, while symbolic model checking
describes sets of states and their properties using binary decision diagrams (BDDs) or other efficient
representations for Boolean formulas.
Checking the validity of a reachability property, a property that asks if a system state with a certain property is reachable, is very similar to the question of plan existence. The use of model checking approaches to solve planning problems has been explored in some depth, e.g. by Cimatti, Roveri,
and Traverso (1998), Bertoli, Cimatti, Roveri, and Traverso (2001), Lago, Pistore, and Traverso
(2002), Kvarnström, Doherty, and Haslum (2000), Bacchus and Kabanza (2000), Hölldobler and
Stör (2000), Fourman (2000), Edelkamp (2003b), Dierks (2005), Kabanza and Thiébaux (2005).
However, not much has been done in the inverse direction, applying planners to model checking
problems. Running IPC-4 planners on planning encodings of Promela specifications is a first step
in doing just that.
The Promela domain also contributes unusual structural properties to our domain set; the computational complexity and local search topology are quite different as will be discussed in Section 4.
Simplifications. The main simplification we had to make was to use very simple example classes
of communicating processes. As PDDL models refer to fixed-length state vectors, we could not
include process construction calls. We therefore only considered active processes, i.e., processes
that are called only once at initialization time. PDDL also does not support temporally extended
goals, so we had to consider reachability properties only. Moreover, by the prototypical nature of
our language compiler, many features of Promela such as rendezvous communication were not supported. Although we have limited support of shared variables, during the competition we chose
simple message passing protocols only; and while we experimented with other reachability properties, the PDDL goals in the competition event were on deadlock detection only. Concretely, the
IPC-4 instances come from two toy examples used in the area of Model-Checking: the well-known
“Dining Philosophers” problem, and an “Optical Telegraph” problem which can be viewed as a
version of Dining Philosophers where the philosophers have a complex inner life, exchanging data
between the two hands (each of which is a separate process). In both, the goal is to reach a deadlock
state.
Versions and Formulations. We created eight different versions of the domain. They differ by the
Promela example class encoded (two options), by whether or not they use numeric variables in the
encoding, and by whether or not they use derived predicates in the encoding. The four encodings
of each Promela example class are semantically equivalent in the sense that there is a 1-to-1 correspondence between plans. We decided to make them different versions, rather than formulations,
because derived predicates make a large difference in plan length, and numeric variables make a
large difference in applicability of planning algorithms/systems. The translation from Promela to

470

E NGINEERING B ENCHMARKS

FOR

P LANNING

PDDL makes use of ADL constructs, so each domain version contains one ADL formulation and
one (fully grounded) compiled STRIPS formulation.
3.4 PSR
Sylvie Thiébaux and others have worked on this application domain. The domain was adapted for
IPC-4 by Sylvie Thiébaux and Jörg Hoffmann.
Application. The task in PSR (power supply restoration) is to reconfigure a faulty power distribution network so as to resupply customers affected by the faults. The network consists of electric
lines connected by switches and fed via a number of power sources that are equipped with circuitbreakers. When faults occur, the circuit-breakers of the sources feeding the faulty lines open to
protect the network, leaving not only these lines but also many healthy ones un-supplied. The network needs to be reconfigured by opening and closing switches and circuit-breakers in such a way
as to resupply the healthy portions. Unreliable fault sensors and switches lead to uncertainty about
the state of the network. Furthermore, breakdown costs that depend on various parameters need to
be optimized under constraints on the capacity of sources and lines. The application is a topic of ongoing interest in the field of power distribution, and has been investigated by the AI community for
a long time, including from an AI planning standpoint (Thiébaux, Cordier, Jehl, & Krivine, 1996;
Thiébaux & Cordier, 2001; Bertoli, Cimatti, Slaney, & Thiébaux, 2002; Bonet & Thiébaux, 2003).
Motivation. Our motivation for including PSR was twofold. First, it is a well-researched interesting
application domain. Second, it has an original structure rarely found in previous benchmarks. The
most natural encoding models the power propagation using recursive derived predicates that compute the transitive closure of the connectivity relation in the network. In contrast with most other
planning benchmarks, the number of actions needed in an optimal plan does not necessarily grow
with instance size: the available actions are to alter the position of switches, and even in a large
network altering the position of just a few switches may suffice for reconfiguration. The difficult
question to answer is, which switches.
Simplifications. Three major simplifications had to be made. First, for deterministic planning we
had to assume that the network state is fully observable, i.e., that the initial state description is
complete, and that the actions always succeed. Second, we ignored all numerical and optimization
aspects of PSR. Third, we used personalized goals in the sense that the lines to be supplied are named
explicitly in the goal. Note that, even in this simplified form, the domain exhibits the structure
explained above.
Versions and Formulations. We created four domain versions, differing primarily by size and
available formulations. The most natural domain formulation is in ADL with derived predicates.
Though we experimented with many combinations of PDDL encodings and compilation strategies,
the size of the instances that we could compile into simpler languages was quite restricted. Precisely,
the versions are: a “large” version in ADL plus derived predicates; a “middle” version that we
could devise also in SIMPLE-ADL plus derived predicates and in STRIPS plus derived predicates;
a “middle-compiled” version in ADL, identical to the “middle” version except that the derived
predicates were compiled away; and a “small” version in pure STRIPS. The instances in the latter
domain version had to be particularly small, since it was extremely difficult to come up with an
encoding in pure STRIPS that did not either yield prohibitively long plans, or prohibitively large
PDDL descriptions. In fact, to obtain the “small” version we applied a pre-computation step (Bertoli
et al., 2002) that obviates the need for reasoning about power propagation and, consequently, the

471

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

need for derived predicates. In the resulting tasks, opening or closing a switch directly – without the
detour to power propagation – affects other parts of the network. Thus the planner no longer needs
to compute the flow of power through the network, but is left with the issue of how to configure that
flow.
3.5 Satellite
This domain was introduced by Long and Fox (2003) for IPC-3; it was adapted for IPC-4 by Jörg
Hoffmann. The domain comes from a NASA space application, where satellites have to take images
of spatial phenomena. Our motivation for inclusion in IPC-4 was that the domain is applicationoriented in a similar sense to the new domains. Also, we wanted to have some immediate comparison between the performance achieved at IPC-3, and that achieved at IPC-4. On top of the 5 domain
versions used in IPC-3, we added 4 new versions, introducing additional time windows (formulated
alternatively with timed initial literals or their compilation) for the sending of data to earth.
3.6 Settlers
This domain was also introduced by Long and Fox (2003) for IPC-3. The task is to build up an
infrastructure in an unsettled area, involving the building of housing, railway tracks, sawmills, etc.
The distinguishing feature of the domain is that most of the domain semantics are encoded in numeric variables. This makes the domain an important benchmark for numeric planning. For that
reason, and because at IPC-3 no participant could solve any but the smallest instances, we included
the domain into IPC-4. No modification was made except that we compiled away some universally
quantified preconditions in order to improve accessibility.
3.7 UMTS
Roman Englert has been working in this application area for several years. The domain was adapted
for IPC-4 by Stefan Edelkamp and Roman Englert.
Application. The third generation of mobile communication, the so-called UMTS (Holma &
Toskala, 2000), makes available a broad variety of applications for mobile terminals. With that
comes the challenge to maintain several applications on one terminal. First, due to limited resources, radio bearers have restrictions in the quality of service (QoS) for applications. Second, the
cell setup for the execution of several mobile applications may lead to unacceptable waiting periods
for the user. Third, the QoS may be insufficient during the call setup in which case the execution
of the mobile application is shut down. Thus arises the call setup problem for several mobile applications. The main requirement is, of course, to do the setup in the minimum possible amount of
time. This is a (pure) scheduling problem that necessitates ordering and optimizing the execution of
the modules needed in the setup. As for many scheduling problems, finding some, not necessarily
optimal, solution is trivial; the main challenge is to find good-quality solutions, optimal ones ideally.
Motivation. Our main motivation for modelling this pure scheduling problem as a planning domain
was that there is a strong industrial need for flexible solution procedures for the UMTS call setup,
due to the rapidly evolving nature of the domain, particularly of the sorts of mobile applications that
are available. The ideal solution would be to just put an automatic planner on the mobile device,
and let it compute the optimized schedules on-the-fly. In that sense, UMTS call setup is a very
natural and promising field for real-world application of automatic planners. This is also interesting

472

E NGINEERING B ENCHMARKS

FOR

P LANNING

in the sense that scheduling problems have so far not been central to competitive AI planning, so
our domain serves to advertise the usefulness of PDDL for addressing certain kinds of scheduling
problems.
Simplifications. The setup model we chose only considers coarse parts of the network environment
that are present when UMTS applications are invoked. Action duration is fixed rather than computed
based on the network traffic. The inter-operational restrictions between different concurrent devices
were also neglected. We considered plausible timings for the instances rather than real-application
data from running certain applications on a UMTS device. We designed the domain for up to
10 applications on a single device. This is a challenge for optimal planners computing minimum
makespan solutions, but not so much a challenge for satisficing planners.
Versions and Formulations. We created six domain versions; these arise from two groups with
three versions each. The first group, the standard UMTS domain, comes with or without timing
constraints. The latter can be represented either using timed initial literals, or their compilation; as
before, we separated these two options into different domain versions (rather than domain version
formulations) due to the increase in plan size. The second group of domain versions has a similar
structure. The only difference is that each of the three domain versions includes an additional “flaw”
action. With a single step, that action achieves one needed fact, where, normally, several steps are
required. However, the action is useless in reality because it deletes another fact that is needed, and
that cannot be re-achieved. The flaw action was added to see what happens when we intentionally
stressed planners: beside increasing the branching factor, the flaw action does look useful from the
perspective of a heuristic function that ignores the delete lists.

4. Known (Theoretical) Results on Domain Structure
In this section, we start our structural analysis of the IPC-4 domains by summarizing some known
results from the literature. Helmert (2006b) analyzes the domains from a perspective of domainspecific computational complexity. Hoffmann (2005) analyzes all domains used in the IPCs so far,
plus some standard benchmarks from the literature, identifying topological properties of the search
space surface under the “relaxed plan heuristic” that was introduced with the FF system (Hoffmann
& Nebel, 2001), and variants of which are used in many modern planning systems. Both studies are
exclusively concerned with purely propositional – non-temporal STRIPS and ADL – planning. In
what follows, by the domain names we refer to the respective (non-temporal) domain versions.12
4.1 Computational Complexity
Helmert (2006b) has studied the complexity of plan existence and bounded plan existence for the
IPC-4 benchmark problems. Plan existence asks whether a given planning task is solvable. Bounded
plan existence asks whether a given planning task is solvable with no more than a given number of
actions. Helmert established the following results.
In Airport, both plan existence and bounded plan existence are PSPACE-complete, even when
all aircraft are inbound and just need to taxi to and park at their goal location, the map is planar
and symmetric, and the safety constraints simply prevent planes from occupying adjacent segments.
12. The UMTS domain, which has only temporal versions, is not treated in either of the studies. As for computational
complexity, it is easy to see that deciding plan existence is in P and deciding bounded plan existence (optimizing
makespan) is NP-complete for UMTS. Topological properties of the relaxed plan heuristic haven’t yet been defined
for a temporal setting.

473

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

The proof is by reduction from the Sliding Tokens puzzle, where a set of tokens must reach a goal
assignment to the vertices of a graph, by moving to adjacent vertices while ensuring that no two
tokens ever find themselves on adjacent vertices. The length of optimal sequential plans can be
exponential in the number of tokens, and so likewise in the airport domain. Even parallel plans can
only be shorter by a linear amount, since each plane can move at most once per time step. The proof
for the Sliding Tokens puzzle is quite complicated because it involves construction of instances
with exponentially long optimal plans. As one would expect, the constructions used are more than
unlikely to occur on a real airport; this is in particular true for the necessary density of conflicting
“traffic” on the graph structure. We consider this interesting since it makes Airport a benchmark
with an extremely high worst-case complexity, but with a much more good-natured typical case
behavior. Typically, there is ample space in an airport for (comparatively) few airplanes moving
across it.
In Pipesworld, whether with or without tankage, both plan existence and bounded plan existence are NP-hard. It is unknown whether they are in NP, however. The NP-hardness proof is by
reduction from SAT with at most four literals per clause and where each variable occurs in at most
3 clauses. Such a SAT instance is reduced to a network in a way so that parts of the network (variable subnetworks) represent the choice of an assignment for each of the variables, and other parts
(clause subnetworks) represent the satisfaction of each of the clauses. The content of areas and pipes
are initialized with batches in a way so that interface restrictions will guarantee that a goal area is
reached by a certain batch in each clause subnetwork iff the clause is satisfied by the assignment.
For general Promela planning, as defined by Edelkamp (2003a), both plan existence and bounded
plan existence are PSPACE-complete. The PSPACE-hardness proof is by reduction from the halting problem in space-restricted Turing Machines (TM). The cells of the machine’s tape are each
mapped onto a process and a queue of unit capacity, the states of the TM form the set of Promela
messages, the TM’s alphabet form the set of Promela states in all processes, and the Promela transitions encode the TM’s transitions. It can be shown that the TM halts iff the Promela task reaches
a deadlock.
Dining Philosophers, on the other hand, has a particular structure where there is one process per
philosopher, all with the same transition graph. Optimal plans can be generated in linear time in the
number of philosophers by making a constant number of transitions to reach the same known state
in each of the graphs. Similar considerations apply to Optical Telegraph.
PSR tasks can also be solved optimally in polynomial time, but this requires a rather complex
algorithm. All plans start with the wait action which opens all circuit-breakers affected by a fault. In
their simplest form, optimal plans will follow by prescribing a series of actions opening all switches
connecting a feedable line to a faulty one. This is necessary but also sufficient to ensure that the
network is in a safe state in which no faulty line can be re-supplied. Then a minimal set of devices
(disjoint from the previous one) must be closed so as to resupply the rest of the network. This can
be achieved by generating a minimal spanning tree for the healthy part of the network, which can
be done in polynomial time.
Figure 2 gives an overview of these results and summarizes Helmert’s (2003) results for other
standard benchmarks. The domain set displayed is the same set as investigated by Hoffmann (2005),
with a few minor differences explained shortly. Blocksworld-no-arm, Briefcaseworld, Ferry, Fridge,
Simple-TSP, and Tireworld are traditional planning benchmarks that were never used in an IPC.13
13. Blocksworld-no-arm is the version of Blocksworld where blocks can be moved directly to their destination, without
referring to a robot arm. Simple-TSP was used by (Fox & Long, 1999) to demonstrate the potential of symmetry

474

FOR

P LANNING

PSPACE

E NGINEERING B ENCHMARKS

Promela
Airport

P

Plan Existence

NP

Pipesworld
Mystery
Mprime
Miconic−ADL
Freecell

Tireworld
Simple−TSP
Schedule
PSR
Optical−Telegraph
Movie
Gripper
Fridge
Ferry
Dining−Phil.

Zenotravel
Satellite
Rovers
Miconic−STRIPS
Miconic−SIMPLE
Logistics
Grid
Driverlog
Depots
Briefcaseworld
Blocksworld−no−arm
Blocksworld−arm

P

NP

PSPACE

Bounded Plan Existence

Figure 2: An overview of Helmert’s results on the computational complexity of the benchmarks.
The IPC-1 benchmarks are Assembly, Grid, Gripper, Logistics, Movie, Mprime, and Mystery. The
IPC-2 benchmarks are Blocksworld-arm, Freecell, Logistics, Miconic-ADL, Miconic-SIMPLE,
Miconic-STRIPS (“Miconic” is Schindler Lift’s name for the elevator domain), and Schedule. The
IPC-3 benchmarks are Depots, Driverlog, Freecell, Rovers, Satellite, and Zenotravel. The IPC-4
benchmarks are displayed in bold face, including the (hypothetical) general Promela domain.
The table in Figure 2 is organized along two axes, where the x axis shows the complexity of
deciding bounded plan existence, and the y axis shows the complexity of deciding (unbounded) plan
existence. Membership in a table entry means, for the NP and PSPACE rows and columns, that the
respective problem is complete for the respective complexity class. An exception is the Pipesworld
domain, for which, as stated above, it is still unknown whether the two decision problems are also
members of NP. The Assembly domain is not displayed since, there, Helmert (2003) proved only
the existence of exponentially long optimal plans, showing that plan generation can be quite hard in
the domain. The table sectors above the diagonal are crossed out because unbounded plan existence
can be polynomially reduced to bounded plan existence – just set the bound to 2n , where n is the
number of distinct actions, or, in ADL, the number of distinct conditional effects.
The most striking new feature of IPC-4 is the introduction of PSPACE-complete benchmark
domains, filling in the top right corner of Figure 2. Thus, the benchmarks cover all four inhabited
sectors of the table. Of the previous IPCs, each of IPC-1 and IPC-2 cover three sectors – all inhabited
detection. One simply has to visit n nodes, using a move action that can be applied between any two nodes, so that
any permutation of the nodes is an optimal tour. Hoffmann (2005) also investigates the Towers of Hanoi domain.

475

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

sectors except the top right corner – and the IPC-3 benchmarks cover only two sectors – namely,
bounded plan existence is NP-complete for all these domains, and all the domains except Freecell
have a polynomial time algorithm deciding unbounded plan existence.
The IPC-4 benchmarks are exceptional in further aspects not visible in Figure 2. Most particularly, as explained above, the polynomial decision algorithm for PSR is highly non-obvious. Such
benchmarks are important since, on the one hand, they in principle allow planners to provide efficient solutions, while, on the other hand, necessitating that they employ interesting techniques for
doing so.14 Schedule is the only other polynomial benchmark for which bounded plan generation
requires a non-obvious algorithm. For all the other 20 domains in the left bottom and middle bottom
sectors of the table, the polynomial algorithms – deciding bounded or unbounded plan existence –
are completely trivial, mostly just addressing one subgoal at a time.
As was pointed out already, a final exception lies in the extraordinarily large difference between
worst-case and typical-case behavior in Airport. As we will see in Section 5, even fully automated
methods (the IPC-4 planners) are, at least for unbounded plan existence (generation), quite efficient
in typical instances of this domain. While large differences between worst-case and typical-case
behavior are not unusual, we believe that the extent of this phenomenon in Airport really is unusual.
For example, planners tend to find PSR much harder than Airport.
4.2 The Topology of h+
Hoffmann (2005) considers the state spaces (the forward search spaces) of STRIPS and ADL tasks
taken from standard benchmark domains. He defines, given such a task and a world state s, h+ (s)
to be the length of a shortest possible relaxed plan, or ∞ if there is no relaxed plan. A relaxed plan
is a plan that achieves the goal from s if one assumes that the delete lists are all empty. Computing
h+ (the corresponding decision problem) is NP-hard (Bylander, 1994). Many modern planners,
e.g., HSP (Bonet & Geffner, 2001), FF (Hoffmann & Nebel, 2001), SGPlan (Wah & Chen, 2004;
Chen, Hsu, & Wah, 2004), YAHSP (Vidal, 2004), and Fast-Diagonally-Downward (Helmert, 2004,
2006a), can be interpreted as doing some sort of heuristic search with an approximation of h+ , plus
further techniques like problem decomposition (Wah & Chen, 2004), lookahead techniques (Vidal,
2004), and additional different heuristic functions (Helmert, 2004). In this context, a question of
great practical interest is the quality of the underlying heuristic function in the addressed domains.
Heuristic quality can be measured in terms of topological properties of the search space surface:
How many local minima are there? How large are they? What about flat regions? Hoffmann (2005)
investigates these questions for the h+ function, for which topological properties of the search space
surface can be proven.
Hoffmann defines topological phenomena following Frank, Cheeseman, and Stutz (1997). He
identifies several parameters that show particularly interesting behavior in planning benchmarks. A
dead end is a world state that is reachable from the initial state but from which the goal state cannot
be reached. An unrecognized dead end is a dead end s for which h+ (s) < ∞. The exit distance
from a state s is the length of a shortest path in the state space leading from s to some other state s0 ,
so that h+ (s) = h+ (s0 ), and s0 has a direct neighbor state s00 with h+ (s00 ) < h+ (s0 ). That is, the
exit distance from s is the number of steps we need to go from s in order to find a better state (s00 ),
14. In Helmert’s (2005) words: “I think that domains that can be solved in polynomial time but where polynomial
algorithms are not obvious are extraordinarily interesting. Deterministic PSR definitely is a domain of that kind
with regard to optimization. NP-hard problems cannot be solved without strong reliance on search, but polynomial
problems can, if the planners capture the important concepts.”

476

E NGINEERING B ENCHMARKS

FOR

P LANNING

minus 1 since the distance to s0 is measured. Here, s0 plays the role of an “exit” state as used by
Frank et al. (1997). A state lies on a local minimum if all paths to an exit have a temporary increase
in the heuristic value; otherwise the state lies on a bench. The maximal local minimum exit distance
(mlmed), for a state space, is the maximum over the exit distances of all states lying on local minima
in the state space. Similarly, the maximal bench exit distance (mbed) is the maximum over the exit
distances of all states lying on benches. The core results of Hoffmann’s (2005) investigation are
displayed in Figure 3.

Blocksworld−arm
Depots
Driverlog

Pipesworld
PSR

Rovers
Optical−Telegraph

Mystery
Mprime
Miconic−ADL
Freecell
Assembly
Airport

mbed <= c

mlmed <= c

Hanoi [0]
Blocksworld−no−arm [0]
Fridge [0]
Briefcaseworld [0]
Grid [0]

Logistics [0,1]
Ferry [0,1]
Gripper [0,1]
undirected

Tireworld [0,6]
Satellite [4,4]
Zenotravel [2,2]
Miconic−SIMPLE [0,1]
Miconic−STRIPS [0,1]
Movie [0,1]
Simple−TSP [0,0]
harmless

Dining−Phil. [31,31]
Schedule [5,5]

recognized

unrecognized

Figure 3: An overview of Hoffmann’s results on the topology of h+ in the benchmarks.
The x-axis in Figure 3 corresponds to properties regarding dead ends. The y-axis corresponds to
properties regarding the exit distance from local minima and benches. The domains are assigned to
the appropriate table sectors – classes of domains – depending on the worst-case behavior possible
in them. In more detail, the meaning of the table is the following. A state space is “undirected” if
every transition (action) can be directly inverted; the state space is “harmless” if such an inversion
is not possible, but there are no dead ends anyway; “recognized” means that there are dead ends, but
h+ is ∞ for all of them; “unrecognized” means that there is at least one unrecognized dead end. A
domain falls into the class of its worst-case instance: for example, if there is a single instance whose
state space contains a single unrecognized dead end, then the domain is considered “unrecognized”.
The results are proved, i.e., if a domain is, for example, considered “harmless”, then this means that
provably no instance of the domain contains any dead ends.
On the y-axis in Figure 3, the distinction lines correspond to the existence or non-existence of
constant upper bounds on the maximal local minimum exit distance (upper line) and on the maximal
bench exit distance (lower line). Note that constant upper bounds on the maximal local minimum
exit distance exist in all domains below the upper line – in the domains below the lower line, both
bounds exist.15 By “constant”, it is meant here that the bound is valid for every instance of the
15. This presentation assumes that the domains with bounded bench exit distance are a subset of those with bounded
local minimum exit distance. This is not true in general, but does hold in all the considered benchmark domains.

477

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

domain, regardless of its size. The actual bounds proved are displayed in brackets; local minimum
bound precedes bench bound in the cases where there are both. The right bottom part of the table
is crossed out since unrecognized dead ends have infinite exit distance and so these domain classes
are empty.16
The obvious intuition behind Figure 3 is that there is a transition from “easy” to “hard” – for
planning systems based on heuristic search approximating h+ – as one moves from the left bottom
side to the top right side of the table. Indeed, the table does, in that sense, coincide very well with
the empirical behavior of, at least, the FF system. Note how extreme the topological behavior is
in many domains. If the upper bound on the local minimum exit distance is 0 then this means that
there are no local minima at all. This is the case in 13 of the 30 investigated domains. In several
domains, such as the widely used Logistics benchmark, on top of that a single step suffices to reach
an exit from benches. Hoffmann (2005) shows that FF would be polynomial in the bottom classes
of the table, provided with an oracle computing h+ .
Considering the table from a perspective of benchmark development, one notices that particularly the older benchmarks tend to lie on the left bottom side; consider for example Ferry, Briefcaseworld, Fridge, Simple-TSP, and Tireworld. The distribution of the IPC-1 benchmarks – Gripper,
Logistics, Movie, Grid, Assembly, Mystery, and Mprime – is somewhat extreme: the first four in
our list here belong to the most simple classes, the last three belong to the hardest class (until today,
the Mystery and Mprime domains are amongst those causing planners the most trouble). In the
IPC-2 benchmarks – Logistics, Blocksworld-arm, Miconic-STRIPS, Miconic-SIMPLE, Schedule,
Freecell, and Miconic-ADL – again, we have many simple and a few very challenging domains.
The most notable exceptions in that respect are Blocksworld-arm, on the left top side of the table,
and Schedule, which does contain dead ends and local minima. In the IPC-3 benchmarks, the distribution starts to get more varied. The domains – Zenotravel, Satellite, Depots, Driverlog, Rovers,
and Freecell – span three of the four top classes in the table, plus one of the bottom classes. The
IPC-4 domains, shown in bold face, obviously continue this development. The only two of them
sharing a class are Pipesworld and PSR.17 They continue the emphasis on spanning the top classes
in the table; the only new domain in one of the bottom classes is Dining Philosophers, and that is
highly exceptional in that is has an exceedingly large bound, making the bound practically useless
for exploitation in planning.18 The Satellite domain adopted from the IPC-3 benchmarks serves to
represent (a more interesting instance of) the easier classes. Note that Satellite is so simple here
because we are talking about the STRIPS version, which drops the more challenging problem constraints formulated with numeric variables. The Airport domain is exceptional in the top right class
in that, again, its worst-case – its place in Figure 3 – differs a lot from its typical case. A dead
end in Airport is a situation where two airplanes completely block each other’s paths.19 Of course,
practical airports are designed in a way so that this doesn’t usually happen. As mentioned earlier,
there usually are – non-overlapping, as far as possible – standard routes, and the only place where
blocking can occur is in densely populated areas near parking positions.
16. One could skip unrecognized dead ends from the definition of the maximum exit distances, but Hoffmann (2005)
argues that this is un-intuitive, plus making things unnecessarily complicated.
17. Actually, Pipesworld is invertible in the sense that every two-step sequence (starting and ending a pumping operation)
can be directly undone. It is considered “harmless” here since the single actions cannot be inverted.
18. Indeed, h+ is a very bad heuristic in Dining Philosophers. It basically comes down to counting the number of
unsatisfied goals.
19. The relaxed plan can use free space in between the planes to make them move “across” each other.

478

E NGINEERING B ENCHMARKS

FOR

P LANNING

5. New (Empirical) Results on Domain Structure
We now provide an empirical analysis of various structural parameters of the IPC-4 domains. For the
sake of readability and conciseness, we focus on the non-temporal domain versions only. For most
types of data we measure, the results for the temporal domain versions are quite similar. To some
extent, this is visible in the tables showing numbers of actions and facts, for all domain versions, in
the individual domain descriptions in Appendix A.
Our empirical analysis is aimed at highlighting further characteristics of, and differences between, the IPC-4 domains. Apart from focussing on more practical parameters, the analysis has –
compared to the theoretical results cited in the previous section – the big advantage that it tells us
something about the actual instances run in the competition. Note that the choice of instances can
make a huge difference – for example, as stated earlier, a real-world airport is not very likely to have
exponentially long plans, and neither is it likely to provoke many dead-end situations. Where possible at all, the instances used in IPC-4 were chosen to be relatively realistic (details in Appendix A).
The analysis is structured into three sub-sections. Section 5.1 shows how, in the individual
domains, the size of the grounded encoding grows over instance size. Section 5.2 assesses the
correspondence between the quality of standard heuristic functions, and the runtime achieved in
IPC-4. Section 5.3, finally, assesses the “fact connectivity” over instance size, meaning the number
of choices one has to achieve each fact, and the number of actions a fact is required for.
5.1 Encoding Size
All current STRIPS and ADL planners, as far as the authors are aware, ground all parameters
and variables in a pre-process, ending up with a task representation consisting of ground facts and
ground actions. An obvious question to ask is how large these grounded encodings are. Figure 4
shows our data, numbers of facts and actions plotted over instance size for (selected versions of) the
different domains. The numbers are measured using FF’s pre-processor. This filters out static facts
– facts that are not added or deleted by any action – and “unreachable” actions, meaning actions that
do not appear in a relaxed planning graph (a planning graph without mutex reasoning) for the initial
state (Hoffmann & Nebel, 2001); formulas are compiled into simple STRIPS-like conjunctions of
facts, along the lines of Gazen and Knoblock (1997) as outlined in Section 2.
100000

1e+06
Airport
Pipesworld
Dining Philosophers
Optical Telegraph
PSR small
PSR large
Satellite
UMTS

10000

Airport
Pipesworld
Dining Philosophers
Optical Telegraph
PSR small
PSR large
Satellite
UMTS

100000

Nr. Actions

Nr. Facts

10000
1000

1000

100
100

10

10
5

10

15

20

25
30
Nr. Instance

35

40

45

50

5

10

15

20

25
30
Nr. Instance

35

40

45

50

(a)
(b)
Figure 4: Numbers of (a) ground facts and (b) ground actions, plotted over instance number, in
selected versions of the IPC-4 domains.
479

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

In all cases except UMTS (that has only temporal versions), the domain version selected for
Figure 4 is non-temporal. Let us consider the domains one by one. In Airport, there is just one
non-temporal version. The plots in Figure 4 (a) and (b) show us quite nicely how the instances are
scaled, with sharp drops in the curves corresponding to steps to a new underlying airport. Precisely,
instances 1 to 3, 4 to 9, 10 to 20, 21 to 35, and 36 to 50 are based on growing airports, respectively,
and within each airport the number of travelling airplanes grows from just 1 or 2 until up to 15 (in
instance 50). For example, from instance 35 to instance 36 we step from one half of Munich airport,
with 12 airplanes, to the full Munich airport, with just 2 airplanes.
In Pipesworld, there are two non-temporal versions, with and without tankage restrictions. Figure 4 shows data for the former, which is the more challenging one (the IPC-4 planners fared much
worse on it); without tankage restrictions, there are slightly fewer facts, and about a factor of 510 fewer actions. The Pipesworld instances are scaled in a similar way as the Airport ones: five
growing pipeline networks each feature a growing number of travelling liquid “batches”. The networks underlie the instances 1 to 10, 11 to 20, 21 to 30, 31 to 40, and 41 to 50, respectively.
Corresponding drops can be observed when stepping from instance 30 to 31, and, less significantly,
when stepping from 20 to 21 or from 40 to 41. A major difference to Airport is visible in the
much more crippled nature (featuring much more variance) of the curve for the number of actions.
This is because, in Airport, few objects move on a big spacious structure, while, in Pipesworld,
many objects move within a rather dense space.20 This fundamental difference between Airport and
Pipesworld also manifests itself in that the order of curves is reversed for the numbers of facts and
actions: in Airport, extraordinarily many facts are required to describe the huge airport structure,
while in Pipesworld there are fewer facts for a smaller structure, but many more actions describing
how things move along that structure. As stated earlier, in Pipesworld, different objects affect each
other’s position when moving.
In the Promela domains, Dining Philosophers and Optical Telegraph, the data for the domain
versions with and without derived predicates are identical, if a derivation rule deriving a fact is
counted as an action achieving the fact. The main difference to what we have seen before lies in
the extremely smooth scaling. Both domains have just a single size parameter, and the numbers of
ground facts and actions grow as linear functions in that parameter – the functions for Optical Telegraph being about an order of magnitude higher than those for Dining Philosophers. The curves for
Optical Telegraph stop at instance 17 because after that we were not able to compute the grounded
representation – too much time and memory were needed in the simplification of precondition formulas. Note that this is not an artifact of our data presentation, but rather constitutes a serious
limitation to any planner that tries to perform such pre-processing.
In PSR, the most interesting domain versions are “small”, since that could be formulated in
STRIPS, and “large”, since that goes up to instances of a realistic size (in the largest instances, that
is). As the name “small” suggests, the numbers are quite small – to be able to compile into STRIPS,
as indicated earlier we had to make the instances very small.21 Essentially the same compilation
problem is also visible in the curves for “large”, that have a huge number of ground facts and actions
in relatively early instances already. The curves stop at instance 20 because beyond that, simplifying
20. How much the objects can or cannot move affects also the number of ground actions due to the mentioned filtering
of “unreachable” actions.
21. The only notable exception is instance nr. 25, where the number of actions peaks to 9400. This is due to an exceedingly complex goal formula, with 9216 disjuncts in its DNF, of which each yields an extra goal-achievement action,
c.f. Section 2.

480

E NGINEERING B ENCHMARKS

FOR

P LANNING

formulas becomes extremely costly. In both versions, we note a high degree of variance both in the
numbers of facts and actions, which somewhat corresponds to the huge degree of variance to be
observed for planner performance in this domain (see Figure 8). Part of this variance, at least
the pace of the oscillations if not their amplitude, can be explained by the way the instances are
scaled. For a given number of sources (the instance size), we generated instances with an increasing
minimal number of switches originally fed by a given source, and for a given number of switches,
we generated instances with an increasing percentage of faulty lines ranging from 10% to 70%.
Intuitively, the larger the number of switches per source, the larger and harder we expect the instance
to be. Furthermore, the percentage of faulty lines tends to induce an easy-hard-easy pattern. If most
lines are faulty, only a small part of the network can be resupplied and only a few devices need
to be switched. Similarly, if a very few faulty lines exist, most of the network can be resupplied
with a few switching operations. With an intermediate percentage, the effects of the actions become
more complex – they are conditioned on the positions of many other switches – and so the instances
become critically constrained and harder to solve.
In Satellite, the main observation to be made is the extremely steep ascent of the curves after
instance 20, particularly the growth to extremely high numbers of actions. There are two reasons for
this. First, one action in Satellite (take-image) has 4 parameters and is “reachable” for almost any
combination of objects with the correct types (most of the time, actions have only 2 or 3 parameters).
Second, the size of the instances themselves grows very sharply beyond instance 20 – which, simply,
is because instances 21 to 36, as used in IPC-4, correspond to the 16 instances posed in IPC-3 to
challenge the hand-tailored planners.
We do not consider Settlers here to ease readability of the graphs, and since that domain is
quite obviously exceptional anyway, in that it relies almost completely on numeric variables. For
UMTS, Figure 4 shows data for the plain domain version without time windows and flaw action.
The obvious characteristic is that the numbers of facts and actions are constants. This is true for all
domain versions, the numbers vary only slightly. The reason is that, the way the UMTS instances
are scaled, every instance describes the same applications and requirements; what changes is (only)
the goal, specifying what applications actually need to be set up. Independent of this effect of the
particular scaling method used, we can observe that the numbers of facts and actions are relatively
low – around only 100 even in the largest instances, where all the applications must be set up, and
the plans contain all the actions.
5.2 Quality of Heuristics, and Runtime
In this section, we measure the length of the best (sequential and parallel) plans found by any
planner, the (sequential and parallel) plan length estimates returned by the most common heuristic
functions, and the runtime taken by the planners. Precisely, for the optimal planners, we measure:
• The optimal makespan, as found by the IPC-4 parallel optimal planners (planners optimizing
makespan).
• The length of a standard plan graph (Blum & Furst, 1997), i.e., the index of the first plan
graph layer that contains the goals without mutexes.
• The best runtime taken by any parallel optimal planner in IPC-4.
• The optimal sequential plan length, as found by the IPC-4 sequential optimal planners.
481

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

• The length of a serialized plan graph, where any pair of non-NOOP actions is made mutex.
• The best runtime taken by any sequential optimal planner in IPC-4.
For the satisficing planners, we measure:
• The best (shortest) plan length, as found by any planner in IPC-4.
• The length of a relaxed plan for the initial state (an action sequence that solves the task if one
assumes all delete lists are empty; computed with FF (Hoffmann & Nebel, 2001)).
• The best runtime taken by any satisficing planner in IPC-4.
Our main goal will be to identify characteristic behavior of domains, and to identify characteristic
effects of heuristic quality on performance. The reader will note that, in our selection of measurements, we make several simplifying assumptions. Optimal planners are not exclusively based on
plan graph estimates. Satisficing planners are not exclusively based on relaxed plan estimates. Further, some of the satisficing planners minimize makespan, not sequential plan length. We chose to
not take account of the latter since there is no potentially over-estimating (non-admissible) heuristic
specifically estimating parallel plan length; to the best of our knowledge, all satisficing planners
minimizing makespan actually use a heuristic estimating the number of remaining actions, and employ some method to greedily arrange the chosen actions as a parallel plan. That said, we do not
wish to imply that our simplifying assumptions are safe in the sense that we do not lose important
information. The simplifying assumptions are necessary to make the analysis and its presentation
feasible. The data we show definitely do capture many crucial aspects of IPC-4 heuristic quality and
planner runtime. We show data for the individual domains, proceeding in alphabetical order. The
(IPC-4) runtime results were obtained on a Linux machine running two Pentium-4 CPUs at 3GHz,
with 6 GB main memory; time and memory cutoffs were 30 minutes and 1 GB, per instance.
Consider Figure 5, showing data for the Airport domain. Note that the y axis has two different
meanings, runtime on the left hand side, and number of (parallel or sequential) plan steps on the
right hand side. The same applies to all figures below in this sub-section. For Airport, we observe
a clear correlation between quality of plan length estimation, and runtime. For the optimal parallel
planners, Figure 5 (a), this is best observed between instances nr. 15 and 20. There, the difference
between makespan and its estimate by the plan graph grows, and with it grows the achieved runtime,
on an exponential scale. It may look like a counter example that, for instance nr. 20, where the plan
graph estimate is exact (coincides with the real makespan), the runtime does not get lower again.
Note however, that instance 20 is based on a much larger airport than the previous instances. From
instance 20 onwards, the only instances solved by any parallel planner have an exact plan graph
estimate. For the optimal sequential planners, Figure 5 (b), we get a similar behavior between
instances nr. 14 and 18. The behavior is also very strong in instances nr. 35 and 36: while the plan
length grows a lot from 35 to 36, the serial plan graph becomes a little shorter; correspondingly, the
runtime goes up by two orders of magnitude. The same is true for instances 20 and 21.
For the satisficing planners, in Figure 5 (c), the most striking observation is that the length of the
real plan coincides, in all instances, exactly with the length of the relaxed plan (for the respective
initial state). This is actually quite easy to explain: an optimal plan moves the airplanes in a way
so that they never block their paths; the same plan is optimal even when ignoring the delete lists.
Moving the airplanes without blocking is always possible at the start. The situation changes only
482

E NGINEERING B ENCHMARKS

1000

70

FOR

P LANNING

10000

160

Optimal MakeSpan
PlanGraph
Best Parallel Runtime

Optimal NrActions
SerialPlanGraph
Best Sequential Runtime
140

60

1000

100
120
50

30

1

10

80

Nr. Steps

40

Runtime (sec.)

100

10

Nr. Steps

Runtime (sec.)

100

60
1
20
40

0.1
0.1

10

0.01

20

0
5

10

15

20

25

30

35

40

45

0.01

0

50

5

10

15

20

25

Nr. Instance

Nr. Instance

(a)

(b)
1000

30

35

40

45

50

700
Best NrActions
RelaxedPlan
Best Runtime
600

100

10

400

300

1

Nr. Steps

Runtime (sec.)

500

200
0.1
100

0.01

0
5

10

15

20

25

30

35

40

45

50

Nr. Instance

(c)
Figure 5: Airport domain. Plots of (parallel) plan length, its heuristic estimation, and runtime, for
(a) optimal parallel planners, (b) optimal sequential planners, and (c) satisficing planners.
when a wrong decision was made, so that additional moves have become necessary – in reality, but
not without delete lists – to avoid a blocking situation. Apart from this, Figure 5 shows quite nicely
that the runtime taken corresponds very closely to the length of the plan found. Note that the latter
is huge, 694 in the largest instance.
In the Pipesworld domain, there are two non-temporal domain versions: with/without tankage
restrictions, i.e., restrictions on the amount of liquid that can be stored in any of the network areas.
Figure 6 shows our data for the version without such restrictions; the observations to be made in the
other domain version are similar, except that both sorts of planners scale much worse, thus providing
us with less data. For the optimal planners, Figure 6 (a) and (b), the most striking difference with
the Airport domain in Figure 5 (a) and (b) is that the quality of even the parallel plan graph heuristic
is very bad: it underestimates the real makespan to a much larger extent than it does in Airport. The
underestimation grows with instance size, and, naturally, the runtime grows as well. Note that the
planners fail to scale much earlier than in Figure 5 (a) and (b). There is one slight exception to the
rule that a poorer heuristic estimate leads to a longer runtime: from instance number 10 to 11, the
optimal sequential plan length grows from 19 to 20, the length of the serial plan graph remains 9,
and the runtime drops from 1400 to 150 secs.

483

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

1000

16

10000

20

Optimal MakeSpan
PlanGraph
Best Parallel Runtime

Optimal NrActions
SerialPlanGraph
Best Sequential Runtime
18

14

1000

100
16
12

8

1

10

12

Nr. Steps

10

Runtime (sec.)

14

10

Nr. Steps

Runtime (sec.)

100

10
1
6
8

0.1
0.1

4

0.01

6

2
5

10

15

20

25

30

35

40

45

0.01

4

50

5

10

15

20

25

Nr. Instance

Nr. Instance

(a)

(b)
10

30

35

40

45

50

160
Best NrActions
RelaxedPlan
Best Runtime
140

120
1

80

Nr. Steps

Runtime (sec.)

100

60
0.1
40

20

0.01

0
5

10

15

20

25

30

35

40

45

50

Nr. Instance

(c)
Figure 6: Pipesworld domain without tankage restrictions. Plots of (parallel) plan length, its heuristic estimation, and runtime, for (a) optimal parallel planners, (b) optimal sequential planners, and (c) satisficing planners.
Similarly to the situation for the optimal planners, for the satisficing planners, Figure 6 (c),
the main difference from Figure 5 (c) is the much worse quality of the heuristic function: the
relaxed plan length now differs greatly from the length of the real plans found, particularly for the
larger instances. Very curiously, despite the worse quality of the heuristic, the runtimes are much
lower. The longest time taken for any instance is below 10 seconds. This goes to show, first, the
shortcomings of our analysis here: we give the heuristic quality only for the initial state, which may
differ a lot from the situation in the rest of the state space. For example, in Airport a planner using
relaxed plans may get lost in huge dead ends when a wrong decision was made early on. Second,
of course, other techniques that the satisficing planners use are also relevant. The runtime data in
Figure 5 (b) are exclusively due to SGPlan (Wah & Chen, 2004) and YAHSP (Vidal, 2004), whose
problem decomposition/greedy lookahead techniques appear to work extremely well in this domain.
All other satisficing planners perform much worse, failing to solve the largest instances. We note
that in Pipesworld, the overall runtime curves (for all planners) are characteristically very jagged
and show considerable variance in comparison to, e.g., Airport. This information gets lost in the
best-of presentation chosen for our figures here. It seems to be that hardness in this domain comes

484

E NGINEERING B ENCHMARKS

FOR

P LANNING

from interactions too subtle to be seen with the rather high-level parameters measured here. We reiterate that the domain version with tankage restrictions is much more challenging to the planners,
the only planner getting anywhere close to the largest instances being YAHSP.
10000

1000

1

350

Optimal MakeSpan
PlanGraph
Best Parallel Runtime
Optimal NrActions
SerialPlanGraph
Best Sequential Runtime

1000

Best NrActions
RelaxedPlan
Best Runtime
300

250

10

200
0.1
150

Nr. Steps

Runtime (sec.)

100
Nr. Steps

Runtime (sec.)

100

10
100
1
50

0.1

1
5

10

15

20

25

30

35

40

0.01

45

0
5

Nr. Instance

10

15

20

25

30

35

40

45

Nr. Instance

(a)
(b)
Figure 7: Dining Philosophers domain without derived predicates. Plots of (parallel) plan length,
its heuristic estimation, and runtime, for (a) optimal planners and (b) satisficing planners.
Figure 7 shows our data for Promela/Dining Philosophers without derived predicates. We do not
show two separate figures for the optimal planners since the curves are quite easy to read. From even
a quick glance, one sees that the domain has a very characteristic behavior different from the other
domains. The optimal makespan, plan graph length, and serial plan graph length are all constant
across instance size. In contrast, the optimal sequential plan length grows as a linear function of
size; note the logarithmic scale of the right hand side y axis in Figure 7 (a), which we had to use
to make the figure (the values of the other plan step measures) readable. The best plans found
by the satisficing planners are optimal, i.e., the NrActions data are identical on both sides of the
figure. In Figure 7 (a), we once again see the effect of heuristic quality on search performance:
the parallel planners scale as a linear function in instance size, while the sequential planners, for
whom the heuristic function becomes worse and worse, scale highly exponentially. The latter might
also be true for the satisficing planners; it is a bit hard to tell since the solved instances are solved
extremely quickly. The reason why no instance with index higher than 29 is solved is that, for these
instances, similarly to what we discussed above (Section 5.1), simplifying precondition formulas
became prohibitively costly, so these instances were available in ADL only. The only two satisficing
planners that scaled well in Dining Philosophers (without derived predicates) were SGPlan and
YAHSP – neither of which could handle the ADL formulation of the domain. Similarly, from
the optimal planners only SATPLAN’04 and Optiplan scaled well, and neither could handle the
ADL formulation. Note that the inability of planners to handle formulas without pre-simplification
techniques thus constitutes a serious limitation.
In Optical Telegraph without derived predicates (no figure shown) the observations are similar
to the ones in Figure 7, except that the planners scale much worse. Most particularly, the optimal
sequential planners solve only the single smallest instance, and the best satisficing runtime is clearly
exponential in instance size, taking over 1500 seconds to solve instance number 25. In the Promela
domain versions with derived predicates, there are no results for optimal planners since none of
them could handle derived predicates. The observations for the satisficing planners are similar to
485

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

the above: NrActions grows as a linear function of instance size, relaxed plan length grows as a
linear function with significantly lower gradient. The planners are very fast in Dining Philosophers
but need a lot of time (> 1000 sec) to solve the largest Optical Telegraph instances (some of which
remain unsolved). We omit the results for the Promela domain versions using numeric variables,
since only two planners participated in these domain versions.
1000

40

1000

35

Optimal MakeSpan
PlanGraph
Best Parallel Runtime

Optimal NrActions
SerialPlanGraph
Best Sequential Runtime
35

30

100

100
30

1

15

10

20

15

1

Nr. Steps

20

Runtime (sec.)

10

Nr. Steps

Runtime (sec.)

25
25

10
10
0.1

0.1
5

5

0.01

0
5

10

15

20

25

30

35

40

45

0.01

50

0
5

10

15

20

Nr. Instance

25

30

35

40

45

50

Nr. Instance

(a)

(b)

10

50
Best NrActions
RelaxedPlan
Best Runtime

1000

60
Best NrActions
RelaxedPlan
Best Runtime

45

50
40
100
35

Nr. Steps

Runtime (sec.)

25
20

10

30

0.1

Nr. Steps

40
30

Runtime (sec.)

1

20
15
1
10
10
5

0.01

0
5

10

15

20

25

30

35

40

45

0.1

50

0
5

Nr. Instance

10

15

20

25

30

35

40

45

50

Nr. Instance

(c)
(d)
Figure 8: PSR domain. Plots of (parallel) plan length, its heuristic estimation, and runtime, for (a)
parallel optimal planners in PSR “small” (STRIPS version), (b) sequential optimal planners in PSR “small”, (c) satisficing planners in PSR “small”, and (d) satisficing planners
in PSR “large” (featuring ADL and derived predicates).
Figure 8 shows our results for the PSR domain. Figure 8 (a), (b) and (c) show plots for the domain version PSR “small”, which comes in pure STRIPS and was addressed by all IPC-4 planners;
Figure 8 (d) shows plots for PSR “large”, which comes in ADL with derived predicates and was
addressed by four satisficing planners only. We do not show data for PSR “middle-compiled” and
PSR “middle”: in the former, just two satisficing planners participated; in the latter, six satisficing
planners participated, but they all scaled quite well on these less challenging instances so the results
are less interesting than those for PSR large.

486

E NGINEERING B ENCHMARKS

FOR

P LANNING

First, note that all curves in PSR “small” show a large amount of zig-zagging, which is quite
unusual and which cannot simply be accounted for by the way the instances are scaled.22 Consider
Figure 8 (a). The main observation to be made is that the real optimal makespan is much larger than
its estimation by a plan graph, particularly in the larger instances. Still, the optimal parallel planners
are quite efficient, at least in that they can solve all the instances. The runtime data are entirely due
to SATPLAN’04, whose search techniques are apparently quite efficient in this domain even with
a bad plan graph lower bound. The other optimal planners are all at least one order of magnitude
slower, and can’t solve some of the largest instances; for example, none can solve instances 48 and
49. As for the optimal sequential planners in Figure 8 (b), the results are pretty similar except that
the runtime scaling is somewhat worse. For both kinds of optimal planners, the runtime is clearly
correlated with the length of the optimal plans, which, since the plan graph bounds are almost
constant, coincides with the difference between the real plan length and its estimate.
In Figure 8 (c), we observe that the relaxed plan is a very bad estimator of plan length in PSR
“small” (at least for the respective initial states), but that the planners solve all instances quite efficiently anyway. The runtime data are entirely due to YAHSP and Fast Downward; particularly
Fast Downward is extremely efficient, showing only a very slight increase of runtime over instance
size, being the only satisficing planner capable of solving instances 48 and 49. Note that YAHSP
(Vidal, 2004) uses powerful techniques besides a relaxed plan heuristic, and that Fast Downward
(Helmert, 2004) uses a more involved (and apparently more powerful, in this case) heuristic function. Note also that, at least in terms of solved instances, optimal and satisficing planners are,
unusually, equally good (or bad) in this domain: exactly one of each group solves all instances, all
other planners cannot solve instances 48 and 49. The difficulty the planners are experiencing in
this domain is also remarkable since the instances, or at least their grounded encodings, are actually
very small when compared to the instances of the other domains, c.f. Figure 4. This indicates that
the domain has some fundamental characteristic that is not yet captured very well by the search
heuristics/techniques of (most of) the planners – which nicely complements what we said about the
non-obvious polynomial algorithm for PSR in Section 4.1.
In Figure 8 (d), we see that the relaxed plan (computed with the version of FF handling derived
predicates, see Thiébaux et al., 2003, 2005) is a rather useless estimator in the PSR domain when
expressed in the most natural way using ADL and derived predicates. The relaxed plan constantly
contains 0 steps, meaning that the over-approximation of the semantics of derived predicates makes
the initial state look like a goal state; the same happens in PSR middle. While the situation may be
different in other parts of the state space – the heuristic value is not constantly 0 – this, apparently,
causes serious trouble for all satisficing planners except Fast Downward. No planner except Fast
Downward can solve an instance higher than number 16. Fast Downward seems to profit, again,
from its more involved heuristic function, reaching its scaling limit at instance number 31.
In the Satellite domain, which has many temporal and some numeric domain versions, we select,
for our presentation here, the single pure STRIPS version. In Figure 9 (a) and (b), we observe that,
like Pipesworld and Promela, and unlike Airport and PSR, Satellite is a domain where a serial
plan graph provides much worse heuristic values (for sequential planning) than a parallel planning
graph (for parallel planning). Over the few instances solved by the optimal planners, parallel plan
length and (serial or parallel) plan graph length do not grow much, while sequential plan length
does. Consequently, the sequentially optimal planners scale much worse than the parallel ones.
22. The same is true for the runtime curves of the individual planners. In fact, the planners even disagree widely about
which instances are solved easily and which take a lot of time.

487

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

1000

12

10000

30

Optimal MakeSpan
PlanGraph
Best Parallel Runtime

Optimal NrActions
SerialPlanGraph
Best Sequential Runtime
11
1000

100

25
10

1

20
Nr. Steps

Runtime (sec.)

8

Nr. Steps

Runtime (sec.)

100
9

10

10
15

7
1
6

0.1

10
0.1
5

0.01

4
5

10

15

20

25

30

0.01

35

5
5

10

15

20

Nr. Instance

Nr. Instance

(a)

(b)
100

25

30

35

500
Best NrActions
RelaxedPlan
Best Runtime

450
400

10

300
1

250

Nr. Steps

Runtime (sec.)

350

200
150
0.1
100
50
0.01

0
5

10

15

20

25

30

35

Nr. Instance

(c)
Figure 9: Satellite domain. Plots of (parallel) plan length, its heuristic estimation, and runtime, for
(a) optimal parallel planners, (b) optimal sequential planners, and (c) satisficing planners.
In Figure 9 (a), we can also nicely see how, during instances 8, 9, 10, the parallel plan length
does a down-up movement (8, 6, 8) over the constant parallel plan graph length (4), resulting in a
movement of pretty much the same shape – on a logarithmic scale! – of the best parallel runtime.
In Figure 9 (c), we observe that, like in Airport and unlike in any of the other domains, the
relaxed plans for the initial states have almost the same length as the real plans (there is actually
a slight over-estimation most of the time). As we have seen earlier, c.f. Section 4.2, Hoffmann
(2005) has shown that, for Satellite, the relaxed plan length is, in fact, bound to be close to real plan
length for all states (in contrast to Airport, where unrecognized dead ends are possible in principle).
Indeed, Satellite is very easy to tackle for almost all of the satisficing planners in IPC-4. While the
runtime shown in Figure 9 (c) appears non-trivial, remember that these instances are huge, see in
particular the number of ground actions in Figure 4 (b). Up to instance 20, most satisficing IPC-4
planners could solve each instance within a minute.
We skip the Settlers domain since that relies almost exclusively on numeric variables to encode
the domain semantics, which makes it rather incomparable with the other domains. Figure 10 shows
our data for the UMTS domain. This has only temporal and numeric versions, half of which feature
also time windows. We consider the versions without time windows; Figure 10 (a) and (b) concern

488

E NGINEERING B ENCHMARKS

10000

720
Optimal MakeSpan
PlanGraph
Best Parallel Runtime

FOR

0.1

80
Best NrActions
RelaxedPlan
Best Runtime

700

1000

P LANNING

70

680
60

620
10

600

50

40

Nr. Steps

640

Runtime (sec.)

100

Temporal MakeSpan

Runtime (sec.)

660

30

580
20
1

560
10

540
0.1

520
5

10

15

20

25

30

35

40

45

0.01

50

0
5

10

15

20

Nr. Instance

25

30

35

40

45

50

Nr. Instance

(a)

(b)

1000

720
Optimal MakeSpan
PlanGraph
Best Parallel Runtime

1

90
Best NrActions
RelaxedPlan
Best Runtime

700

80

680

70

100
660

600

50
0.1
40

Nr. Steps

620

Runtime (sec.)

10

Temporal MakeSpan

Runtime (sec.)

60
640

30
580
1

20

560

10

540
0.1

520
5

10

15

20

25
30
Nr. Instance

35

40

45

0.01

50

0
5

10

15

20

25
30
Nr. Instance

35

40

45

50

(c)
(d)
Figure 10: UMTS domain. Plots of (durational) plan length, its heuristic estimation, and runtime,
for (a) optimal (b) satisficing planners in plain temporal version, (c) optimal (d) satisficing planners in temporal version with flaw action.
the plain domain version, Figure 10 (c) and (d) is with “flaw” action. Let us first consider the optimal
planners, on the left hand side of the overall figure. The only optimal planners that could tackle this
domain – i.e., the domain’s syntax – were TP4 and HSP∗a (Haslum & Geffner, 2001). These are
makespan-minimizing planners, and so there are no data for sequentially optimal planners (which
wouldn’t make a lot of sense in the temporal setting anyway). The “PlanGraph” curves in Figure 10
(a) and (c) correspond to the makespan estimation delivered for the initial state by TP4’s temporal
numeric extension of that heuristic. For the effect of heuristic quality on runtime, we observe once
again a very strong correlation. In Figure 10 (a), up to instance 21 the makespan estimate is very
close to the real makespan – most of the time, the two actually coincide – and the runtimes are
very good. Starting from instance 22, the real makespan makes a sudden leap upwards that is not
followed by the estimation, and the runtimes shoot upwards. The phenomenon is also very clear
in instances 18, 19, 20, where the makespan estimation exhibits a good, bad, good pattern, and
the runtime does just the same. In Figure 10 (c), the very same sort of behavior can be observed,
meaning in particular that the flaw action does not have an effect on makespan and its estimation by
TP4. In fact, the makespan and its estimation are exactly the same in all instances solved in both
domain versions. As contained implicitly in the latter sentence, the flaw action does affect runtime

489

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

and with it the set of solved instances. The runtime with the flaw action is consistently more than
a factor of 2 larger than without the flaw action. In the most challenging instances the planners fail
when the flaw action is present. This decrease in performance is presumably due to the larger state
space incurred by the flaw action.
Consider the satisficing planners, Figure 10 (b) and (d). We first observe that, once more, we
are facing a very individual and characteristic behavior, and that the domain is no challenge at all to
the satisficing planners. The latter shows that the domain is not a useful benchmark for satisficing
planners; it also shows once again how heterogeneous our benchmark set is: while it is common that
satisficing planners are faster than optimal ones – except in PSR – there is no other domain where
that picture is as extreme as in UMTS. As stated earlier, the domain is a pure scheduling problem,
and obviously the satisficing planners provide runtime-efficient greedy solutions to that problem.23
Looking at the plots in a little more detail, we find in Figure 10 (b) that the sequential plan length (the
plans found are optimal) is a simple stepwise linear function in these instances, and that relaxed plan
length for the initial state coincides once again with the real plan length – which isn’t a surprise given
the excellent runtimes of the satisficing planners, and the fact that this is a scheduling domain. (In a
sequentialized schedule no harmful delete effects occur.) This picture changes a lot in Figure 10 (d).
The real plan length stays basically the same (is increased by a constant of 2), but the relaxed plan
length becomes a lot shorter due to the flaw action. The satisficing planners are unaffected, largely
keeping their excellent runtime behavior. Apparently, these planners incorporate some technique
for recognizing the uselessness of the flaw action (this can be done with simple domain analysis
techniques), and getting rid of its influence. This suspicion is confirmed by the fact that there is one
satisficing planner that does get affected by the flaw action in the way one should expect. CRIKEY,
a heuristic search forward state space planner using a relaxed plan heuristic, solves each task within
70 seconds without the flaw action, but sometimes takes over 1000 seconds with the flaw action.
Let us briefly summarize the overall observations:
• In the presented data, most of the time the performance of the planners correlates well with
the quality of the relevant heuristic function. The most notable exceptions to this rule – as far
as can be observed in our data here – are Fast Downward in PSR “large”, where relaxed plans
are pretty much devoid of information, and SGPlan and YAHSP (to some extent also Fast
Downward) in Pipesworld, where relaxed plans provide poor estimates and all other planners
experience (much more) serious difficulties.
• Usually, here and in the known benchmarks in general, satisficing planners are several orders
of magnitude faster than optimal ones. Exceptions here are PSR – where both groups perform
almost equally – and UMTS – where the satisficing planners hardly need any time at all.
• Usually, here and in the known benchmarks in general, parallel plan graph length is a much
better estimator of parallel plan length than serial plan graph length is of sequential plan
length. The exceptions here are Airport – where there is often a huge difference between
the lengths of the two kinds of plan graphs – and, to some extent, PSR “small” – where the
difference between parallel and sequential plan length is not very big. Note that none of our
domains is purely sequential, i.e. some parallelism is possible in all of them.
23. In terms of quality of the solutions found, the satisficing planners also do reasonably well. For example, LPG-td,
which minimizes makespan in this domain, finds, with its version optimized for speed, plans that take maximally
10% more time than the optimal ones found by TP4. For the version of LPG-td optimized for plan quality, this goes
down to 1%.

490

E NGINEERING B ENCHMARKS

FOR

P LANNING

• Usually, here and in the known benchmarks in general, there is a considerable difference
between the length of a relaxed plan for the initial state, and the length of a real plan for
the initial state. Exceptions here are Airport, Satellite, and UMTS, where both lengths are
identical or nearly so.
• Usually, here and in the known benchmarks in general, the largest instances that can be solved
within the given particular time and memory (30 minutes and 1GB) have plans with around a
hundred steps or more. PSR is exceptional in that Fast Downward is the only planner able to
find a plan with more than 35 (namely, with 57) steps.
It once again indicates the diversity of the IPC-4 domains that almost every one of them appears at
least once in the “exceptions” listed here. The only domains that don’t appear there are the Promela
domains and Pipesworld. This is a sort of exception in itself, meaning that these domains contribute
the more typical benchmark behaviors to the overall set.
We take the existence of some of the mentioned distinguishing features as evidence that the
IPC-4 domains indeed have several novel aspects, besides being oriented at applications and being
structurally diverse. In particular, the behavior of the PSR domain stands out from what one typically observes. Note here that, while it is typically easy to construct artificial domains that provoke
some unusual behavior, the domains we have here are oriented at applications, and so the exhibited behavior, particularly that of the PSR domain, is not only unusual, but also relevant in a very
concrete sense.
5.3 Fact Connectivity
We conclude our empirical analysis with some data aimed at assessing a sort of “connectivity” of the
facts. For each fact p, we measure the number of adders: actions that have p in their add list (in the
ADL case, that have an effect with p in its adds list). This gives an indication of the branching factor
– action choices – that comes with the fact. We further measure the number of requirers: actions
that have p in their precondition (in the ADL case, that have an effect with p in its condition). This
gives an indication of how central a fact is to the task. For a given planning task, we measure the
parameters of the distribution of adders(p) and requirers(p), over the set of facts p: the minimum
(min), mean (mean), maximum (max), and standard deviation (dev). Within domain versions, we
plot these data over instance size (number).
The data are too abstract to allow deep conclusions about reasons for planner performance, but
we are able to highlight some more characteristic features of the domains. In particular, we will see
that these abstract measurements behave more characteristically different in the IPC-4 domains than
in the IPC-3 domains. Figure 11 shows our plots for the IPC-4 domains Airport, Pipesworld, Dining
Philosophers, and Satellite. The picture for PSR is relatively complicated and shown separately in
Figure 12. Settlers is left out because it is exceptional. The picture for UMTS is extremely simple,
and explained in the text below.
Consider Figure 11 (a), the (non-temporal) Airport domain. The min curves are not shown
since they are constantly 0: “is-pushing-back(airplane)” is never added since pushback requests (of
outbound traffic) are not modelled; “occupied(segment)” is only required in its negation. The max
curves are step functions since they follow the size of the underlying airports: “is-moving(airplane)”
has as many adders as there are segments, since “start-up-engine” can be done at any segment; “ispushing-back(airplane)” is required by every such action, leading to the overall similar form of

491

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

1000

10000
#Adders, max
#Adders, mean
#Adders, deviation
#Requirers, max
#Requirers, mean
#Requirers, deviation

100

1000

10

100

1

10

0.1

#Adders, max
#Adders, mean
#Adders, deviation
#Adders, min
#Requirers, max
#Requirers, mean
#Requirers, deviation
#Requirers, min

1
5

10

15

20

25

30

35

40

45

50

5

10

15

20

Nr. Instance

25

30

35

40

45

50

Nr. Instance

(a)

(b)

1000

1000
#Adders, max
#Adders, mean
#Adders, deviation
#Requirers, max
#Requirers, mean
#Requirers, deviation

#Adders, max
#Adders, mean
#Adders, deviation
#Requirers, max
#Requirers, mean
#Requirers, deviation

100

100

10

10

1

1
5

10

15

20

25
Nr. Instance

30

35

40

45

5

10

15

20
Nr. Instance

25

30

35

(c)
(d)
Figure 11: Distributions of the numbers of actions adding a fact, and of actions requiring a fact,
in selected versions of some IPC-4 domains: (a) Airport, (b) Pipesworld, (c) Dining
Philosophers, (d) Satellite.
the max requirers curve. The mean adders curve is flattened because all facts other than “ismoving(airplane)” are added only at certain places on the airport. The mean requirers curve, interestingly, shows a similar downwards step behavior as the numbers of facts and actions shown
in Figure 4. The reason lies in the “not-occupied” facts, that exist for every segment, and that are
needed in every action moving an (any) airplane across the segment. The number of these facts
increases with the number of airplanes. Since there are many of these facts, they have a strong
influence on the mean. There is not much of a correspondence to runtime in the data, other than the
trivial one that both tend to grow with instance size.
Data for Pipesworld, no tankage non-temporal, are shown in Figure 11 (b). Several observations
can be made: 1. the max and mean curves clearly follow the scaling pattern, with growing traffic
on the 5 growing underlying networks. 2. the min curves are non-zero. 3. there is a characteristic
difference between the curves up to instance 10, and afterwards. 4. the curves for adders and
requirers almost (but not exactly) coincide. Apart from 1, which is also present in the Airport data,
these observations clearly distinguish Pipesworld from all the other domains. As for observation
2, sometimes in the larger instances the min number of adders does drop to 0. This is due to
interactions in more complex networks, where certain configurations inside pipes are true initially

492

E NGINEERING B ENCHMARKS

FOR

P LANNING

but can not be re-achieved later on – some of these interactions are recognized by the “reachability”
pre-process made by FF for actions, c.f. the explanation in Section 5.1. Observation 3 is due to
a large contrast between the smallest network and all larger ones: the smallest network has only
unitary pipelines (containing just a single batch), the others have pipelines of at least length 2.
Observation 4 is particularly at odds with all the other domains, where there are large differences
between adders and requirers. In fact, measuring the distribution of the difference between adders
and requirers, we found that these numbers (not only their distribution parameters) are extremely
close together: in instance 50, where the max adders is 1524 and max requirers is 1520, the max of
the difference is 29, with a mean of 1.63 and dev of 5.31. In Pipesworld with tankage restrictions,
the phenomenon is somewhat less extreme but still there. Another characteristic is the enormously
large max number of adders and requirers, about an order of magnitude larger than in the other
domains. The max adders and requirers come from “do-normal” facts, which control the status of
individual pipelines, and are affected by each action moving some combination of batches through
the respective pipeline; all other facts depend on only single batches (not combinations of them),
which flattens the mean curves by two orders of magnitude. Regarding runtime, as mentioned
earlier, in Pipesworld the scaling pattern does not have a clear correlation with runtime; neither
does the fact connectivity we measure here.
Consider the Promela domain in Figure 11 (c), data shown for Dining Philosophers with derived
predicates. Once again, the extreme characteristics of the domain are recognizable at first glance.
The data for Dining Philosophers without derived predicates are identical, the data for Optical Telegraph differ only in that the numbers are higher. The min curves are both 0, the adders are constant,
the requirers are linear. There exist facts without adders due to an oddity in the encoding, where
certain start-up transitions put the forks on the table in the first place; the facts without requirers are
“blocked-philosopher”, which are only needed for the goal. The number of adders does not depend
on the instance size due to the very static sort of domain structure, where size increases the number
of parallel processes (philosophers), but the form of the processes stays fixed, and every process
interacts with exactly two other processes. The number of requirers is linear (non-constant, in particular) due to a technicality of the encoding, where “activating” (requesting) and “performing”
(executing) a transition requires all communication channels to be in neutral state; so the respective
flags are required by all transitions, and that number of course grows over size. All other facts are
required only locally, resulting in the much lower (easily two orders of magnitude) mean. As one
would expect in a domain with such a simple scaling pattern, planner performance is pretty much a
function of size.
Data for Satellite (STRIPS version) are shown in Figure 11 (d). The most characteristic feature,
in comparison to the other domains, is the extremely smooth and parallel close-together growth of
the curves. The only curve that stands out a little is max requirers; max adders is due to “pointing(satellite, direction)” facts that can be added when turning there from any other direction; max
requirers is due to “power-on(instrument)” facts, which are needed for every “take-image” with the
instrument, which can be done in every combination of direction and image mode supported by
the instrument. Note that, in contrast to the other domains where the max curves are about two
orders of magnitude higher than the mean, here max requirers is only one order of magnitude
above all the other curves, and these other curves are all roughly of the same order. The min curves
are not shown since they are constantly 1 for adders – “power-on(instrument)” is only added by
“switch-on(instrument)” – and constantly 0 for requirers – “have-image(direction)” is only needed

493

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

for the goal. The runtime performance of the IPC-4 planners scales relatively smoothly with size in
Satellite, like our parameters here do.
In UMTS, all the parameters are constants. This is another consequence of the aforementioned
scaling pattern, where the number of specified applications is the same in all instances, and what
changes is (only) the goal, specifying which of the applications shall actually be scheduled. Precisely, in the plain domain version, the number of adders is 1 for all facts, nicely showing the
scheduling-domain characteristic where there is no choice of how to accomplish tasks, but only
about when to accomplish them. This is another illustration of why the satisficing planners find this
domain trivial, whereas an optimal planner like TP4 (Haslum & Geffner, 2001) can spend a long
time searching for the optimal schedule. The number of requirers is minimum 0, maximum 2, mean
0.89, standard deviation 0.57. In the domain version with flaw action, the most notable difference
is that now max adders is 2 – due to the alternative provided by the “flaw” action (min is now 0,
mean 1.2, deviation 0.5). It is interesting to note in this context that, as mentioned above, in this
domain version there is a satisficing planner, CRIKEY, that experiences serious trouble.
10000

10000
max
mean
deviation

max
mean
deviation

1000
1000

#Adders

#Required

100
100

10

10
1

0.1

1
5

10

15

20

25

30

35

40

45

50

5

10

15

20

Nr. Instance

25

30

35

40

45

50

Nr. Instance

(a)

(b)

35

1000
max
mean
deviation

max
mean
deviation

30

25

#Required

#Adders

100
20

15

10
10

5

0

1
5

10

15

20

25
Nr. Instance

30

35

40

45

50

5

10

15

20

25
30
Nr. Instance

35

40

45

50

(c)
(d)
Figure 12: Distributions of the numbers of actions adding a fact, and of actions requiring a fact, in
PSR “small” and “large”: (a) adders “small”, (b) requirers “small”, (c) adders “large”,
(d) requirers “large”.
Data for PSR are shown in Figure 12. Here, we show plots for adders and requirers separately
because that makes them much more readable. Since the data contain some particularly interesting
494

E NGINEERING B ENCHMARKS

FOR

P LANNING

phenomena, we show it for two domain versions, “small” and “large”. The most obvious feature in
“small”, Figure 12 (a) and (b), is, once again, the huge amount of variance in the data. The clearly
discernible peaks in the curves (instance nrs. 15, 25, 31, and 40) coincide with the peaks in size
as measured by numbers of facts and actions in Figure 4. We also note that there is a very large
range of values, spanning four orders of magnitude, even though the instances are (except number
25) all very small in comparison to the other domains shown in Figure 4. The minimum numbers of
adders and requirers are constantly 1: “updated(breaker)” is added only by a “wait(breaker)” action,
“not-closed(breaker)” is only needed if one wants to close it.24 Regarding the maximum adders and
requirers, in instance 25, which has by far the highest (9400) total number of actions, max adders
(9216) is due to the “goal-reached” fact, i.e., to the 9216 disjuncts in the DNF of the goal formula;
max requirers (9251) is due to “do-normal”, which is a flag needed for every goal-reached action,
plus the actions opening or closing breakers. We remark that the same facts are responsible for all
of the peaks in the curves, i.e., the same happens also in instances 15, 31, and 40.
It is highly characteristic for PSR “small” that the max numbers of adders and requirers approach and sometimes exceed two thirds of the total number of actions. This is not the case for any
other domain, not even for any other domain version of PSR (see below). The intuitive reason lies
in one of the pre-compilation steps that we employed in order to be able to formulate reasonably
large PSR instances in pure STRIPS: the compilation step (Bertoli et al., 2002) “removes” network
reasoning (and with it, the need for derived predicates) by basically enumerating the breaker configurations and their effects on the flow of current in the network. The result is a very dense structure
where each end of the network directly affects every other end, explaining the very high degree of
fact connectivity, in particular explaining the extremely complex goal formulas in the four “peak”
cases mentioned above.
The pre-compilation step is also the key to understanding the huge difference between the behavior in “small”, and in “large”. The latter is shown in Figure 12 (c) and (d). There, the max
adders curve is a small linear function – note the non-logarithmic scale of the y axis – in spite of the
(mostly) much larger numbers of actions. For example, the instance with the highest number (7498)
of actions and derivation rules is number 20, where the max number of adders is 31, less than half a
percent of the total number of actions. In the natural high-level domain encoding that we have here,
the flow of current through the network is modelled as the transitive closure over derivation rules
that each propagate current based on the local status of the network. So in particular the breaker
configurations and their effects on the flow of current are implicit in the structure of the network.
Once again, in PSR “large”, the min curves are constantly 0 for both adders and requirers; “notaffected(breaker)” is the negation of a derived predicate (needed as precondition of open and close
actions), which isn’t added by an inverse rule, but given its meaning through the negation as failure
semantics of derived predicates; “fed(line)” is only required for the goal. The mean and dev of the
adders are completely flattened by the numerous (5029 out of 5237, in instance 20) “upstream(x,y)”
facts, true if there is currently a path open from a side of node x to a side of node y, that are added
only by a local derivation rule that relies on the same predicate for the neighbors of y. Similarly to
Satellite, the max number of requirers is generally a lot larger than the max number of adders. For
example, 542 vs. 31 in instance 20, where max requirers is due to a fact “closed(device)” that is
required in derivation rules talking about pairs of devices; in instance 20, 7360 of the 7498 actions
are such rules; there are 46 devices.
24. Sometimes there are 0 minimum requirers due to an artificial “goal-reached” fact, introduced to get rid of complex
goal formulas, c.f. Section 2.

495

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

1000

1000
#Adders, max
#Adders, mean
#Adders, deviation
#Requirers, max
#Requirers, mean
#Requirers, deviation

#Adders, max
#Adders, mean
#Adders, deviation
#Requirers, max
#Requirers, mean
#Requirers, deviation

100

100

10

10

1

1
2

4

6

8

10

12

14

16

18

20

2

4

6

8

Nr. Instance

10

12

14

16

18

20

10
12
Nr. Instance

14

16

18

20

Nr. Instance

(a)

(b)

10000

1000
#Adders, max
#Adders, mean
#Adders, deviation
#Requirers, max
#Requirers, mean
#Requirers, deviation

#Adders, max
#Adders, mean
#Adders, deviation
#Requirers, max
#Requirers, mean
#Requirers, deviation

1000
100

100

10
10

1

1
2

4

6

8

10
12
Nr. Instance

14

16

18

20

2

4

6

8

(c)
(d)
Figure 13: Distributions of the numbers of actions adding a fact, and of actions requiring a fact, in
the STRIPS versions of the IPC-3 domains except Freecell and Satellite: (a) Depots, (b)
Driverlog, (c) Rovers, (d) Zenotravel.
To sum up the sub-section, the data are, generally, too abstract to be really tightly interconnected
with the performance exhibited by planners. On the other hand, certain characteristics are visible.
Most particularly: In Pipesworld, the numbers of adders and requirers are almost identical. In
Promela, the adders are constant and the requirers are linear. In Satellite, all curves are very close
together. In PSR “small” there is a lot of variance, and the max numbers of adders and requirers
approach and sometimes exceed two thirds of the total number of actions. In contrast, in PSR
“large” the max adders decline to less than half a percent of the total number of actions. In UMTS,
all the parameters are constant. Except for PSR and UMTS, these phenomena are somewhat hard
to interpret. If nothing else, they certainly show us that the domains have some rather different
characteristics. Interestingly, the differences are not as significant for the IPC-3 benchmarks shown
in Figure 13. Clearly, the behavior is not as characteristically diverse as what we have just seen for
the IPC-4 domains. For all the four domains in Figure 13, we basically observe mostly parallel lines
that are pretty close together except for the max lines, which are about an order of magnitude higher
than the others. The only striking feature is the zig-zag nature of the curves in Depots. This is due
to the scaling pattern: In the smallest instances, the number of crates (blocks) grows continually up
to 15 crates in instance 6. Thereafter, there come blocks of 3 instances each, of which the first has 6

496

E NGINEERING B ENCHMARKS

FOR

P LANNING

crates, the second 10 crates, and the third 15 crates (across the blocks, other instance size parameters
grow). This means that the zig-zag shape of the curves corresponds exactly to the zig-zag shape of
the crate numbers.
Note that the behavior of the plots in Figure 13 is similar to the behavior of the plot for Satellite
in Figure 11 (d), in particular for the first 20 instances. These were the instances posed to the fully
automated planners in IPC-3, as also shown in Figure 13. The only IPC-3 domain that truly stands
out in terms of the behavior of these curves is Freecell.25 There, we observe a phenomenon similar
to that of the Pipesworld in Figure 11 (b), where the curves for adders and requirers almost coincide.
The phenomenon is a little weaker than in Pipesworld: in the largest Freecell instance, number 20,
the max of (both) adders and requirers is 1638, while the max of the difference is 102, with a mean
of 14.30 and dev of 24.86. For comparison, in the largest Pipesworld instance, max adders is 1524,
max requirers is 1520, and the max of the difference is 29, with a mean of 1.63 and dev of 5.31.
To sum up the overall empirical analysis, the data certainly don’t solve the mystery of what is
behind the performance of every planner in every domain (and instance). They do, however, provide
some interesting insights about how instances are scaled in the domains, about certain subtleties and
peculiarities of their encodings, and about how standard heuristic methods, and groups of planners,
react to them. We can observe large characteristic differences between the domains. In that sense the
results nicely complement the technical descriptions in Appendix A, as well as the known theoretical
results from Section 4.

6. Conclusion
In a field of research about general reasoning mechanisms, such as AI planning, it is essential to
have useful benchmarks: benchmarks that reflect possible applications of the developed technology,
and that help drive research into new and fruitful directions. In the development of the benchmark
domains and instances for IPC-4, the authors have invested significant effort into creating such a set
of useful benchmarks for AI planning.
As explained in the introduction, the three main goals we tried to achieve were 1. realism, 2.
structural diversity, and 3. accessibility of the benchmarks. It is debatable to what extent these goals
were achieved. To some extent, this is inherent in the conflicting nature of the goals. Accessibility
of a benchmark – formulation in as simple as possible PDDL dialects – is obviously in conflict with
realism. Structural diversity is also in conflict with realism since, in the time window available to
create a competition benchmark set, there may not be (and has not been, in our case) a large set
of suitable applications to choose from. One must make do with what’s available. We stressed
on realism since the lack of realism was traditionally considered as one of the main weaknesses
of AI Planning – achieving “just” structural diversity and accessibility would, in fact, have been
comparatively easy (see also below). That said, to adapt the applications for the IPC we had to
make many significant simplifications. Still, having derived the domains from applications, one can
expect that they capture some important features even after simplification; on top of that, there is a
clear path towards more realism.
We believe that the domains constitute the best possible compromise for IPC-4. To name the
most distinguishing features of the domain set:
25. It somehow makes sense that it’s precisely this domain that stands out, as it is also intuitively different from the other
domains. Most notably, deciding plan existence in Freecell is NP-hard while it is easy in the other domains, c.f.
Section 4.1.

497

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

1. Airport, Pipesworld, PSR, and UMTS are derived directly from applications (Promela is a
special case since the model checking instances we could encode are very simplistic). This
was previously the case only for the Elevator domain (IPC-2) and the Rovers and Satellite
domains (IPC-3).
2. The complexity of satisficing and optimal planning in the STRIPS domain versions covers
the entire range P, NP, and PSPACE – deciding (bounded) plan existence is in P for PSR
and PSPACE-complete for Airport and general Promela. We are not aware of a previous
PSPACE-complete STRIPS benchmark; the polynomial algorithm for finding plans in PSR
is, in contrast to those for all the other STRIPS benchmarks with such algorithms, quite nontrivial.
3. In Hoffmann’s (2005) taxonomy of domain classes with different h+ topology, the IPC-4
domains lie in classes with sparse coverage by previous benchmarks. In particular, none of
our new domains has nearly as simple a topology as proved by Hoffmann for most of the
traditional benchmarks. When taking into account that Pipesworld actions can be inverted in
(not one but) two steps, each of the domains lies in a different class of Hoffmann’s taxonomy,
covering more classes (6) than any previous IPC benchmark set (3, 5, and 4 for IPC-1, IPC-2,
and IPC-3, respectively). Dining Philosophers is exceptional in that it lies in a “simple” class
but doesn’t have a simple topology; Airport is exceptional in that it lies in a “very hard” class
but is typically (in real-world instances) easy.
4. The behavior of the different kinds of planners in IPC-4 shows a lot of very characteristic
patterns in the individual domains. In Airport, sheer size is the main obstacle. In Pipesworld,
particularly with tankage restrictions, the known heuristic functions do very badly. In the
Promela domains, the main obstacle is, in a lot of cases, the impossibility of compiling the
PDDL description into a fully grounded simpler representation. In PSR, there is an extremely
large amount of variance, and optimal planners perform just as well (or poorly) as satisficing
planners. In UMTS, satisficing planners need no time at all.
5. At a very abstract level that just looks at the numbers of actions adding/needing each fact, the
behavior of the domains is more characteristically diverse than that of the IPC-3 domains.
6. Last but not least, the STRIPS versions of our domains preserve much more of the original
domain structure than what was previously the case. The IPC-2 STRIPS version of Elevator is
hardly an elevator problem anymore, and the IPC-3 STRIPS versions of Satellite and Rovers
are devoid of all of the more interesting problem constraints. In contrast, the STRIPS versions
of Airport and Promela are semantically identical to the ADL versions, and the PSR STRIPS
version, while pre-compiled a lot, still preserves much of the original difficulty of the domain
(judging, e.g., by the behavior of the IPC-4 planners in it).
Feature 1 is, obviously, a point for realism. Features 2 to 5 are points for diverse structure; particularly Feature 4 shows how the domains pose very different challenges to (current) planning
technology. Feature 6 is a point for realism combined with accessibility. We would like to stress
that accessibility in this respect is really quite important. Of the 19 planners entered into IPC-4, only
8 could handle (some) ADL features. Our compilation approach enabled us to confront the other 11
planners with reasonably realistic problems. That said, it certainly is debatable what role STRIPS
498

E NGINEERING B ENCHMARKS

FOR

P LANNING

plays or should play for the community. Some people may say that many of the core algorithms,
e.g., planning graphs (Blum & Furst, 1997) and relaxed plan heuristics (McDermott, 1999; Bonet
& Geffner, 2001; Hoffmann & Nebel, 2001), have been invented in STRIPS. Others may say that
the focus on STRIPS-like languages and algorithms distracts us from considering temporal and numerical problems of a truly different nature. This notwithstanding, STRIPS is still the most widely
used language among the research community. This cannot be ignored by competition organizers.
Having pointed out the advantages of our benchmark set, we should also point out a few of the
disadvantages. As explained in detail in the individual sections in Appendix A, we had to make
many simplifications in order to make the applications fit for use in IPC-4. To some extent, whether
or not the simplifications preserve the original domain structure is a debatable matter. We feel
that our Airport encoding is very close to the real “physical” thing. Not being able to represent
the real optimization criterion is bad, but ameliorated by the fact that, out of 19 planners, only a
single one (LPG-td) could actually deal with user-defined optimization criteria.26 In Pipesworld,
the simplifications are more severe. The IPC-4 domain still resembles some of the core difficulties,
but is more reminiscent of a (complicated) toy example than of software that could be used to control
real pipelines. The Promela examples go to show that toy examples in the model checking area are
not any better than the traditional toy examples in planning. In PSR, removing the uncertainty and
the numerical optimization renders the IPC-4 domain unsuitable for practical use.
Of course, the domain set is not exhaustive, meaning that there presumably are numerous applications whose essential structure is not similar to any of the IPC-4 domains. Some examples that
spring to mind are action choice in autonomous robots, detecting security holes in computer networks (Boddy, Gohde, Haigh, & Harp, 2005), and online manufacturing (Ruml, Do, & Fromherz,
2005). As for structural diversity, it would be easy to construct a set of artificial domains that
explore more of the possible extreme cases. Such domains would probably be completely infeasible for current planners, thus posing very strong challenges. Just think of, for example, Rubik’s
Cube, Sokoban, or Rintanen’s (2004) purely randomly generated instance distributions. Then again,
such a domain set would be devoid of realism. At some point during the preparation of IPC-4, we
considered introducing a separate class of domains, called “Diverse Structure”, which would have
contained domains of this sort. We decided to not do so since the competition event was already
very large without it. Also, we felt that our applications were already quite diverse on the structural
side. As pointed out above, several theoretical and empirical phenomena suggest that the latter is
indeed the case.
During our work, we experienced various successes and failures in accurately formulating our
application domains in PDDL. People have asked us if, through this, we obtained a picture of how
suitable PDDL is, in its current form, to formulate applications, and in what sorts of domains it
works well. The answer is, we don’t feel like we obtained many insights into these matters that
are particularly deep or haven’t been known before. A few lessons learned are these. First and
foremost, formulating an application in STRIPS takes a huge amount of engineering expertise unless
one just drops all problem constraints; some simplifications are unavoidable. Second, the discrete
nature of action instantiations in all previous IPC PDDL dialects seriously impedes formulation
of domains with continuous aspects. A discretization must be chosen, which is sometimes easy
(Airport) and sometimes very hard (Pipesworld) to do. A good way out seems to be to adopt the
“duration inequalities” suggested by Fox and Long (2003). Third, the community should pay more
26. This is a good example of a case where PDDL has been moving faster than the actual planning technology.

499

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

attention to lifted encodings, and how to deal with them in modern planning algorithms: one lesson
from our compilation activities is that grounding out all parameters is often simply not possible
(Promela, PSR). Since compiling away ADL constructs is often not feasible without grounding (c.f.
Section 2), this is also very relevant in the ADL/STRIPS context. As a final “lesson”, we (the AI
Planning community) are still, mostly, far away from as-is applicability of planners in the real world.
But we are on the right track.
To conclude, we spent significant time and effort creating a useful set of planning benchmarks
for IPC-4. We hope that they will become standard benchmarks in the coming years.

Acknowledgements. We would like to thank the competitors for their detailed comments about
bugs found in our domains, and we would like to thank Malte Helmert for various useful tools that
helped remove some of these bugs.
We further thank Malte Helmert for providing us with his – yet unpublished, at the time of
writing – results on computational complexity (Helmert, 2005, 2006b). We thank Patrik Haslum
for providing us with the TP4 temporal numerical plan graph estimates of makespan in the UMTS
domain. We are indebted to the anonymous reviewers, and very much to David Smith and Maria
Fox, whose detailed and extensive comments contributed greatly to the development of this paper.
We finally thank David Smith for his extensive advice on language, including some corrections even
for these very acknowledgements.
Jörg Hoffmann thanks Wolfgang Hatzack for his support in the development of the Airport
domain and benchmark instances.
Frederico dos Santos Liporace is supported by Conselho Nacional de Desenvolvimento Cientı́fico
e Tecnológico, Brazil. He would like to acknowledge the support of his PhD supervisor, Ruy Milidiu, in the development of the Pipesworld application.
Sylvie Thiébaux thanks Piergiorgio Bertoli, Blai Bonet, and John Slaney for their contributions
to the development of the PSR domain and instances. She also would like to acknowledge the
support of National ICT Australia. NICTA is funded through the Australian Government’s backing
Australia’s Ability initiative, in part through the Australian Research Council.

Appendix A. Detailed Domain Descriptions
We now provide detailed descriptions of all the domains, in alphabetical order. Each section (except
those for the Satellite and Settlers domains, which were adapted from the IPC-3) is organized in
sub-sections as follows. We first give an outline of the application domain. We then explain the
main adaptations made to model the application as a PDDL domain in IPC-4, we explain the IPC-4
domain structure, i.e., the domain versions and their formulations as used in IPC-4, and we explain
how we generated the example instances for the IPC-4 test suites. Finally, we discuss possible future
extensions.
A.1 Airport
We had a contact person for this application domain, Wolfgang Hatzack, who has been working in
this application area for several years. The domain was adapted for IPC-4 by Jörg Hoffmann and
Sebastian Trüg.

500

E NGINEERING B ENCHMARKS

FOR

P LANNING

A.1.1 A PPLICATION D OMAIN
The task is to control the ground traffic on an airport. Timed travel routes must be assigned to
the airplanes so that they reach their targets. There is inbound and outbound traffic; the former
are airplanes that must take off (reach a certain runway), the latter are airplanes that have just
landed and have to get parked (reach a certain parking position). The main problem constraint is,
of course, to ensure the safety of the airplanes. This means to avoid collisions, and also to prevent
airplanes from entering the unsafe zones behind large airplanes that have their engines running. The
optimization criterion is to minimize the summed up travel time (on the surface of the airport) of
all airplanes.27 There usually are standard routes, i.e., routes that any airplane outbound from a
certain park position area, or inbound from a certain runway, must take. The reason for introducing
such routes is, simply, the sheer complexity of managing the situation otherwise, without significant
computer support (which is as yet not available on real airports). We will see below that whether or
not standard routes are present makes a big difference also computationally.
The airplanes move on the airport infrastructure, which consists of runways, taxiways, and
parking positions. The runways and taxiways are sub-divided into smaller segments. The position
of an airplane is given by the segment it is currently located in, plus its direction and the more
precise position within the segment – several airplanes can be in the segment at the same time.
Airplanes are generally divided into three categories, light, medium, and heavy, which classify
them according to their engine exhaust (jet blast). An airplane that has to be moved is either inbound or out-bound. In-bound airplanes have recently landed and are on their way from the runway
to a parking position, usually a gate. Out-bound airplanes are ready for departure, meaning they
are on their way to the departure runway. Since airplanes cannot move backwards, they need to be
pushed back from the gate onto the taxiway, where they start up their engines. Some airports also
provide different park positions that allow an airplane to start its engines directly.
To ensure safety, an airplane must not get too close to the back of another airplane whose engines
are running. How far the safety distance has to be depends on the category (jet blast) of the second
airplane.
The ground controller – the planner – has to communicate to the airplanes which ways they
shall take and when to stop. While such guidance can be given purely reactively, it pays off to base
decisions on anticipating the future. Otherwise it may happen that airplanes block each other and
need more time than necessary to reach their destinations on the airport. The objective is, as said,
to minimize the overall summed up traveling times of all airplanes.
As instances of the domain, one considers the traffic situation at some given point in time, with
a time horizon of, say, one hour. If new airplanes are known to land during given time slots inside
the time horizon, then during these time slots the respective runways are considered blocked, and
the planner has to make sure these runways are free at these times. Of course, because the situation
changes continually (new planes have to be moved and plans cannot be executed as intended), continuous re-planning, i.e., consideration of the domain instance describing the new traffic situation, is
necessary. Solving instances optimally (the corresponding decision problem) is PSPACE-complete
without standard routes (Helmert, 2006b) and NP-complete if all routes are standardized (Hatzack
& Nebel, 2001). In the latter case, we have a pure scheduling problem. In the former case, compli27. This criterion is what the airport wants to minimize, in order to maximize its throughput. From the point of view of
the airlines, it would be better to minimize delay, e.g., by minimizing the summed up squared delay of all airplanes.
The two criteria may be in conflict. Neither of the two can be easily modelled in PDDL2.2, see below.

501

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

cated (highly unrealistic, of course) airport topologies can lead to exponentially long solutions, c.f.
Section 4.1.
A.1.2 IPC-4 PDDL A DAPTATION
The PDDL encoding (as well as our example instance generation process, see below) is based on
software by Wolfgang Hatzack, namely on a system called Astras: Airport Surface ground TRAffic
Simulator. This is a software package that was originally designed to be a training platform for
airport controllers. Astras provides a two-dimensional view of the airport, allowing the user to
control the airplanes by means of point and click. Astras can also simulate the traffic flow on an
airport over the course of a specified time window.
We made three simplifications, one of them benign, to the airport model. As for the benign
simplification: we did not model park positions where the airplane can start up its engines directly,
without being pushed back to the taxiway first. While it is not difficult to model such park positions
in PDDL, they seldom occur in reality and so are not very relevant to the application. Our first
more important simplification was to assume a somewhat cruder notion of airplane locatedness, by
requiring that only a single airplane can be located in a segment at any time. That is, we use the
term “segment” with the meaning of a smallest indivisible unit of space. To minimize the loss of
precision, (some of) the original “segments” were sub-divided into several new smaller segments.
The safety distance behind the back of an airplane whose engines are running is then also measured
in terms of a number of segments. While this discretization makes us lose precision, we believe that
it does not distort the nature of the problem too much: due to the amount of expected conflicting
traffic at different points on the airport (high only near parking positions), it is relatively easy to
choose a discretization – with segments of different length – that is precise and small enough at the
same time.28 The last simplification is more severe. We had to give up on the real optimization
criterion. We say more on this rather strong simplification below. We did not use full standard
routes, thus allowing the airplanes a choice of where to move. We did use standards for some
routes, particularly the regions near runways in large airports. For one thing, this served to keep
large airports manageable for the PDDL encoding and planners; for another thing, it seems a good
compromise at exploiting the capabilities of computers while at the same time keeping close to
traditions at airports. We get back to this matter in Section A.1.5.
The full PDDL description of our domain encoding can be downloaded from the IPC-4 web page
at http://ipc.icaps-conference.org/. Briefly, the encoding works as follows. The available actions are
to “pushback” (move a plane away backwards from a parking position), to “startup” the engines,
to “move” between segments, to “park” (turning off the engines), and to “takeoff” (which amounts
to removing the plane from the airport). The semantics of these actions are encoded based on
predicates defining the current state of the airplane. At any point in time, an airplane is either
moving, pushed, parked, or airborne. An airplane always occupies one segment and, if its engines
are running, may block several other segments depending on the size of the occupied segment
and the category of the airplane. The action preconditions ensure that blocked segments are never
occupied by another airplane. In the initial state, each plane is either parked, or moving. A parked
plane can be pushed back, and after starting up its engines, it is moving. A moving airplane can
28. The need for smallest indivisible units (of space, in this case) is a fundamental consequence of the discrete nature of
PDDL2.2; some more on this is said in Section A.1.5.

502

E NGINEERING B ENCHMARKS

FOR

P LANNING

either move from its current segment to a neighboring segment, park – at a parking position – or
take off – on a runway.
As an example, have a look at the PDDL encoding of the (non-durational) “move” action (one
of the preconditions was used as an example in Section 2 already):
(:action move
:parameters
(?a - airplane ?t - airplanetype ?d1 - direction ?s1 ?s2 - segment ?d2 - direction)
:precondition
(and (has-type ?a ?t) (is-moving ?a) (not (= ?s1 ?s2)) (facing ?a ?d1) (can-move ?s1 ?s2 ?d1)
(move-dir ?s1 ?s2 ?d2) (at-segment ?a ?s1)
(not (exists (?a1 - airplane) (and (not (= ?a1 ?a)) (blocked ?s2 ?a1))))
(forall (?s - segment) (imply (and (is-blocked ?s ?t ?s2 ?d2) (not (= ?s ?s1))) (not (occupied ?s)))))
:effect
(and (occupied ?s2) (blocked ?s2 ?a) (not (occupied ?s1)) (not (at-segment ?a ?s1)) (at-segment ?a ?s2)
(when (not (is-blocked ?s1 ?t ?s2 ?d2)) (not (blocked ?s1 ?a)))
(when (not (= ?d1 ?d2)) (and (not (facing ?a ?d1)) (facing ?a ?d2)))
(forall (?s - segment) (when (is-blocked ?s ?t ?s2 ?d2) (blocked ?s ?a)))
(forall (?s - segment) (when
(and (is-blocked ?s ?t ?s1 ?d1) (not (= ?s ?s2)) (not (is-blocked ?s ?t ?s2 ?d2)))
(not (blocked ?s ?a))))))

The six parameters – which is a lot compared to most of the usual benchmarks – do not cause
a prohibitive explosion in instantiations since there is a lot of restriction through static predicates.
Airplane “?a” moves; its type (category) is “?t”; it is at segment “?s1” facing in direction “?d1”, and
will be at “?s2” facing in direction “?d2” after the move. “Direction” here is a very simple concept
that just says which end of the segment the airplane is facing. Of course, moves from “?s1 ?d1”
to “?s2 ?d2” are only possible as specified by the – static – topology of the airport (“can-move”,
“move-dir”). The first of the two more complex preconditions says that “?s2” must not currently
be blocked by any airplane other than “?a” itself. The second complex precondition makes sure
that, after the move, “?a” will not block a segment that is currently occupied (by another airplane,
necessarily): “(is-blocked ?s ?t ?s2 ?d2)” is a static predicate that is true iff “?s” is endangered –
blocked – if a plane of type “?t” is at “?s2”w facing direction “?d2”. The effects should be selfexplanatory; they simply update the “at”, “occupied”, and “blocked” information. The only effect
that looks a little complicated – the last one – says that those segments that were blocked before the
move, but are no longer blocked after the move, become un-blocked. Note that the conditions of all
conditional effects are static, so the conditions disappear once the parameter instantiation is chosen.
In durational PDDL, the actions take time according to some simple computations. The time
taken to move across a segment depends, naturally, on the segment length and the speed. We
assumed that airplanes move at the same speed regardless of their category. The time taken to start
up the engines is proportional to the number of engines. The other actions have some fixed duration.
If some planes are known to land in the near future, blocking runways, then we model the
blocking during these time windows using timed initial literals, respectively their compilation into
artificial (temporal) PDDL constructs. The timed literals are simply instances of the usual “blocked”
predicate, becoming true when the respective time window starts, and becoming false again when it
ends.
We were not able to model the real optimization criterion of airport ground traffic control. The
standard criterion in PDDL is to minimize the execution time, i.e., makespan, of the plan. In our
503

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

encoding of the domain this comes down to minimizing the arrival time (meaning, arrival at the
destination on the airport) of the last airplane. But the real objective is, as said above, to minimize
the overall summed up travel time of all airplanes. There appears to be no good way of modeling
this criterion in current PDDL. The difficulty lies in accessing the waiting times of the planes, i.e.
the times at which they stay on a segment waiting for some other plane to pass.29
The only way (we could think of) to get access to the waiting times, in current PDDL, is to
introduce an explicit waiting action. But then one must be able to tell the planner, i.e., to encode in
the action, how long the plane is supposed to wait. One option is to use the “duration inequalities”
proposed by Fox and Long (2003). There the action imposes only some constraints on its duration,
and the planner can/has to choose the actual duration of the action, at each point where it is used in
the plan, as an additional (rational-valued) parameter. The potential disadvantage of this approach
is that the choice of the waiting time introduces, in principle, an infinite branching factor into the
state space, and may thus make the problem much harder for automated planners. Moreover, duration inequalities were not put to use in IPC-3, and were not a part of PDDL2.1. When not using
duration inequalities, the only way to encode the requested waiting time into the action is to use
a discretization of time. One can then introduce new objects representing every considered time
interval, and give the waiting action a parameter ranging over these objects. Apart from the loss
of precision involved in the discretization, this approach is also likely to cause huge performance
problems for automated planners. As an alternative way out, we considered introducing a special
“current-time” variable into PDDL2.2, returning the time of its evaluation in the plan execution.
Using such a “look at the clock”, one could make each plane record its arrival time, and thus formulate the true optimization criterion without any major changes to the domain structure. The IPC-4
organizing committee decided against the introduction of a “current-time” variable as it seemed to
be problematic from an algorithmic point of view (it implies a commitment to precise time points
at planning time), and didn’t seem to be very relevant anywhere except in Airport.
All in all, the IPC-4 PDDL encoding of the Airport domain is realistic except for the optimization criterion, which demands to minimize maximal arrival time – makespan – instead of summed
up travel time. It remains to remark that all but one (LPG-td) of the IPC-4 planners ignored the
optimization criterion anyway. Also, minimizing the latest arrival time does appear a useful (if not
ideal) objective.
A.1.3 IPC-4 D OMAIN S TRUCTURE
The Airport domain versions used in IPC-4 are non-temporal, temporal, temporal-timewindows,
and temporal-timewindows-compiled. The first of these versions is, as the name suggests, nondurational PDDL. In the second version, actions take time as explained above. The third and fourth
versions also consider runways blocked in the future by planes known to land during given time
windows. The third version encodes these time windows using timed initial literals, the fourth
version uses those literals’ compilation into standard temporal PDDL constructs, c.f. Section 2.
In all the domain versions, the problem constraints are modeled using ADL, i.e., complex preconditions and conditional effects. We compiled the ADL encodings to STRIPS with domainspecific software implemented for this purpose. We grounded out most – not all – of the operator
parameters, precisely, all the parameters except, for each action, the one giving the name of the
29. Modelling summed up (squared) delay of all airplanes, the optimization criterion for airlines, would pose essentially
the same difficulty: it also involves computing the arrival time (in order to compute the delay).

504

E NGINEERING B ENCHMARKS

version
non-temporal
non-temporal
temporal
temporal
temporal-tw
temporal-tw
temporal-twc
temporal-twc

formulation
ADL
STRIPS
ADL
STRIPS
ADL
STRIPS
ADL
STRIPS

FOR

max-#op
5
1408
5
1408
5
1408
14
1429

P LANNING

max-#act
(1048) 989
(21120) 13100
(1408) 989
(21120) 13100
(995) 854
(22038) 13100
(911) 861
(21141) 13121

Table 1: Overview over the different domain versions and formulations of Airport. Abbreviations used: “temporal-tw” for “temporal-timewindows”, “temporal-twc” for temporaltimewindows-compiled; max-#op is the maximum number of (parameterized) PDDL
operators for any instance, max-#act is the maximum number of ground actions for any
instance. For the ADL formulations, the set of ground actions could not be generated for
the largest instances; data are shown for the largest instances that could be handled. Data
in parentheses are collected before FF’s “reachability” pre-process (see text).
affected individual airplane. Once all the other parameters are fixed, the formulas and conditional
effects can be simplified to the usual STRIPS constructs. Each Airport domain version contains
the original ADL formulation, as well as its compilation to STRIPS. The result of the grounding
process depends on the specific airport considered in the instance, and on the set of airplanes that
are travelling. So, in the STRIPS formulations, to each instance there is an individual domain file
(the same applies to all STRIPS compilations in the other domains described later).
The domain versions, as well as the blow-up incurred by the compilation, are overviewed in
Table 1.30 The numbers shown in the table indicate numbers of PDDL operators, and numbers
of grounded actions. For each domain version/formulation, the maximum such number of any
instance is shown. Note that, in the ADL formulations except temporal-timewindows-compiled,
there is just a single domain file so the number of operators is identical for all instances. In the
STRIPS formulations, the number of operators is high because, as explained, most of the operator
parameters are grounded. The difference in the number of ground actions between the STRIPS and
the ADL formulations is because, with our automated software, we were not able to generate the
ground actions in the larger ADL instances; the data shown are for the largest instances that we
could handle. The numbers shown in parentheses refer to the situation before FF’s “reachability”
pre-process; as said before, this builds a relaxed planning graph for the initial state, and removes all
actions that do not appear in that graph. The difference between the numbers inside and outside of
the parentheses indicates how much this simple pre-process helps. We see that it helps quite a lot
here, pruning almost half of the actions (which would never become applicable, in a forward search
at least, but which blow up the representation regardless of what algorithm is used).
30. The instantiation process is, of course, planner-dependent. Similarly as before in Section 5, our data are based on
FF’s pre-processor. We extended that pre-processor (precisely, the one of Metric-FF (Hoffmann, 2003)) to deal with
temporal constructs.

505

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

A.1.4 IPC-4 E XAMPLE I NSTANCES
The Airport example instances were generated by Sebastian Trüg, with an implementation based on
the aforementioned airport simulation tool Astras. Five scaling airport topologies were designed,
and used as the basis for the instance generation. The airports are named “Minimal”, “Mintoy”,
“Toy”, “Half-MUC”, and “MUC”. The smallest of these airports is the smallest possible airport
Astras can handle. The two largest airports correspond to one half of Munich Airport (MUC), and
to the full MUC airport. Figure 14 shows sketches of the “Minimal” airport, and of the “MUC”
airport.

(a)

(b)
Figure 14: The smallest (a), and the largest (b) of the IPC-4 Airport topologies. Park position
segments are marked in black (e.g., at the top of part (a)), while the segments airplanes
can takeoff from are marked in white (e.g., at the left bottom side of part (a)). The lines
show the road network on the airport. Topology (b) corresponds to MUC airport.
Sebastian Trüg implemented PDDL instance generation software inside Astras. During a simulation of the traffic flow on an airport, if desired by the user the software exports the current traffic
situation in the various PDDL encodings explained above. The simulator was run with the different
airports, and 50 scaling traffic situations were exported (3 on “Minimal”, 6 on “Mintoy”, 11 on
“Toy”, 15 on “Half-MUC”, and 15 on “MUC”). For each airport, the instances scale in terms of the
number of travelling airplanes. The largest instance features 15 planes to be moved to their destinations on Munich airport, with 10 planes landing in the future to be considered (in the respective
domain versions). This can be considered a realistically sized traffic situation, at this airport.

506

E NGINEERING B ENCHMARKS

FOR

P LANNING

A.1.5 F UTURE W ORK
It remains to explore how to relax some of the simplifications we had to make. Most importantly,
how to overcome the discrete model of space (locatedness), and how to model the real optimization
criterion. Our difficulties with both are, as partly described above already, mostly due to the discrete
nature of PDDL2.2, which does not allow a continuous choice in the instantiation of an action. Such
a continuous choice would be the most natural way of saying how far a plane will be moving and
how long it will be waiting. So the best way to go about this direction is, probably, to assume
the “duration inequalities” proposed by Fox and Long (2003), together with the numeric variables
already contained in PDDL2.2. This should be easy on the modelling side. The main problem
is probably on the technology side, i.e., to develop planners that can deal efficiently with such
continuous choice points. At the time of IPC-4, as said, continuous choice appeared too much to
demand from the planners.
One interesting topic for future work arises if one restricts the airplanes completely to standard
routes, i.e., leaves them no choice at all of what route to take to their destination. As said, first,
this is usually done at real airports, for the sheer complexity of managing the situation otherwise,
without significant computer support (which is as yet not available at real airports). Second, in IPC4 we made only limited use of this feature, to retain some of the flexibility that could be offered
by automatized methods. Third, the restriction turns the PSPACE-complete ground traffic control
problem into a pure, NP-complete (Hatzack & Nebel, 2001), scheduling problem, where the only
question is when the planes move across what segment. One could exploit this to create a much
more concise PDDL encoding. The restricted problem comes down to resolving all conflicts that
arise when two planes need to cross the same airport segment. One could thus try to not encode in
PDDL the physical airport, but only the conflicts and their possible solutions, ideally in connection
with the real optimization criterion. It can be expected that planners will be much more efficient in
such a simpler and more concisely encoded problem.
A.2 Pipesworld
Frederico Liporace has been working in this application area for several years; he submitted a paper
on an early domain version to the workshop on the competition at ICAPS’03. The domain was
adapted for IPC-4 by Frederico Liporace and Jörg Hoffmann.
A.2.1 A PPLICATION D OMAIN
Pipelines play an important role in the transportation of Petroleum and its derivatives, since it is
the most effective way to transport large volumes over large distances. The application domain
we consider here deals with complex problems that arise when transporting oil derivative products
through a multi-commodity pipeline system. Note that, while there are many planning benchmarks
dealing with variants of transportation problems, transporting oil derivatives through a pipeline
system has a very different and characteristic kind of structure, since it uses stationary carriers
whose cargo moves rather than the more usual moving carriers of stationary cargo. In particular,
changing the position of one object directly results in changing the position of several other objects.
This is less reminiscent of transportation domains than of complicated single-player games such as
Rubic’s Cube. It can lead to several subtle phenomena. For example, it may happen that a solution
must reverse the flow of liquid through a pipeline segment several times. It may also happen that

507

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

liquid must be pumped through a ring of pipeline segments in a cyclic fashion, to achieve the goal
(we will see an example of this later).
In more detail, the application domain is the following. A pipeline network is a graph of operational areas connected by pipeline segments. Operational areas may be harbors, distribution centers
or refineries. These may be connected by one or more pipeline segments. The oil derivatives are
moved between the areas through the pipelines.
There can be different types of petroleum derivative products. Each area has a set of tanks
that define the storage capacity for each product type. Each pipeline segment has a fixed volume
and speed. The volume depends on the segment’s length and cross section diameter, and the speed
depends on the power of the pumps that move the contents. A segment may be uni-directional, i.e.
only usable for transportation in one direction.
Pipeline segments are always pressurized, that is, they must be always completely filled with
petroleum derivative products. Because of that, the only way to move a pipeline segment’s contents
is by pumping some amount of product from an adjacent area into the segment. This operation
results, assuming incompressible fluids, in the same amount of a possibly different product being
received in the area at the other end of the segment.
The pumping operations can only be executed if they do not violate any interface or tanking
constraints. As for the former, distinct products have direct contact inside the pipeline segment, so
it is unavoidable that there is some loss due to the mixture in the interface between them. These
interface losses are a major concern in pipeline operation, because the mixed products can not be
simply discarded. They must pass through a special treatment that may involve sending them back to
a refinery, and that may require the use of special tanks. The severity of interface losses depends on
the products that interface inside the pipeline segment. If two product types are known to generate
high interface losses, the pipeline plan must not place them adjacently into the segment. Such a pair
of product types is said to have an interface restriction.
Tanking constraints are limits on the product amounts that can be stored in an area, arising from
the respective tank capacities. Such constraints may effectively block a pipeline segment, if there is
no room in the receiving area to store the product that would leave the segment in the process of a
pumping operation.
The task in the application is to bring certain amounts of products to the areas in which they are
required, i.e. one has to find a plan of pumping operations that shifts the positions of the product
amounts in a way so that the goal specifications are met. Sometimes there is a deadline specifying
when, at the latest, a product amount has to arrive at its destination area. It may also be the case that
an area (typically, a refinery) is known to produce some given amount of a product at a given point
in time, and that the plan must make sure that there is enough tank space available at the respective
area to store the new product amount. Similarly, an area (typically, a harbor or a distribution center)
may be known to consume some given amount of a product at a given point in time, thereby freeing
the respective amount of tank space.
A.2.2 IPC-4 PDDL A DAPTATION
The main adaptations made in the PDDL encoding are unitary batches, split pumping operations,
and “personalized” goals (see below for the latter). The term “batch” is used in the oil pipeline
industry to refer to an amount of a product that must be transported through the pipeline. Batches
are thus associated with a single product and have predefined volume. Batches are also indivisible.

508

E NGINEERING B ENCHMARKS

FOR

P LANNING

When a batch Bi is pumped from an area Aj into a segment Sj,k , it is not possible for another batch
to be pumped from Aj into Sj,k until all of Bi ’s volume is pumped. Of course, in reality the product
amount in a batch is a rational number. Using such a numeric encoding in IPC-4 seemed completely
infeasible due to complications in the modeling, and the expected capabilities of the participating
planners (see Section A.2.5). Instead, we based the encoding on the concept of what we called
unitary batches. These are the smallest considered – indivisible – portions of product. The pumping
operations refer to unitary batches. The pipeline segments’ volumes and the volumes of tanks are
also defined in terms of unitary batches. When encoding a real-world instance of the domain, the
actual volume associated with a unitary batch is a choice variable. Smaller unitary batches decrease
the rounding error in the PDDL encoding, at the cost of a larger encoding size. Note that, like the
smallest units of space in the Airport domain, this is a discretization the need for which is due to the
non-continuous nature of actions in PDDL2.2; we get back to this in Section A.2.5.
We modeled pipe segments in a directional fashion, i.e. there is a default direction assigning
one area the “from” role, and the other area the “to” role. The pumping operations accordingly
distinguish between “push” actions, which move liquid in the respective segment’s default direction,
and “pop” actions, which move liquid in the opposite direction. This is simply a technical device to
enable the encoding of the pipe segment contents through predicates defining the “first” and “last”
batches in the segments (as well as a “successor” relation). The “push” and the “pop” actions receive
(amongst other things) as arguments the pipeline segment whose contents are being moved, and the
batch that is being inserted into the segment. The batch that leaves the segment depends on the
segment content before the action is executed. Figure 15 shows an example.



A1




























B1



A2




















































B2




B4












































B5

















































































































B6

A1







































B1



































B2

A2


















B3

























B4





















































































































 

B6





B5












B3



(b)

(a)
A1

!

!

!

!

!

!

!

!

!

!

"

"

"

"
#

"
#

B1
!

!

"
#

"
#

"
#

"
#

"
#

$

$
%

$
%

$

$
%

$
%

"
#

B2

"
#

A2
























B4




(

)


(

)


(

)

(
)

(
)

(
)

(
)

(
)

(
)

(
)

(
)

(
)

(
)

B6
(
)

(
)

(
)

(
)

(
)

'

(
)
&

(
)

'

(
)






































	


	


	

B5

&

&

'

'

'

&

&

&

&


	

$
%

&

B3

P1

'


	


	

















































$
%

P2
P3

(c)

Figure 15: A small example. A1 plays the “from” role. The fill pattern for each batch represents
its product. (a) shows the initial state, (b) shows state (a) after a “push” operation with
B3 being inserted into the segment, (c) shows state (b) after a “pop” operation with B6
being inserted into the segment.
Apart from the pipe segment and the batch being inserted, the “push” and “pop” actions have
to take several more parameters regarding, e.g., product types and tank slots. In particular, in order
to be able to update the segment contents correctly, the actions also need parameters giving the
respective first, last, and second last batch in the current contents of the segment. Thus such an
action has four parameters ranging over batches, yielding at least n4 ground instances of the action
when there are n (unitary) batches in the considered task. We found that this made the domain
509

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

completely infeasible for any planning system that grounded out the actions. Since many unitary
batches are needed to encode even relatively small Pipesworld examples, such planners typically
died in the pre-processing phase already.31 We avoided this phenomenon by splitting the actions
into two parts, a “start” action taking as batch parameters only the inserted batch and the first batch
in the pipe, and an “end” action taking as batch parameters only the last and second last batches in
the pipe. To make this more concrete, here is the split “push” action:
(:action PUSH-START
:parameters
(?pipe - pipe ?batch-atom-in - batch-atom ?from-area - area ?to-area - area
?first-batch-atom - batch-atom ?product-batch-atom-in - product
?product-first-batch - product)
:precondition
(and (normal ?pipe) (first ?first-batch-atom ?pipe) (connect ?from-area ?to-area ?pipe)
(on ?batch-atom-in ?from-area) (not-unitary ?pipe)
(is-product ?batch-atom-in ?product-batch-atom-in)
(is-product ?first-batch-atom ?product-first-batch)
(may-interface ?product-batch-atom-in ?product-first-batch))
:effect
(and (push-updating ?pipe) (not (normal ?pipe)) (first ?batch-atom-in ?pipe)
(not (first ?first-batch-atom ?pipe)) (follow ?first-batch-atom ?batch-atom-in)
(not (on ?batch-atom-in ?from-area))))
(:action PUSH-END
:parameters
(?pipe - pipe ?from-area - area ?to-area - area ?last-batch-atom - batch-atom
?next-last-batch-atom - batch-atom)
:precondition
(and (push-updating ?pipe) (last ?last-batch-atom ?pipe) (connect ?from-area ?to-area ?pipe)
(not-unitary ?pipe) (follow ?last-batch-atom ?next-last-batch-atom))
:effect
(and (not (push-updating ?pipe)) (normal ?pipe)
(not (follow ?last-batch-atom ?next-last-batch-atom))
(last ?next-last-batch-atom ?pipe) (not (last ?last-batch-atom ?pipe))
(on ?last-batch-atom ?to-area)))

The constructs should be largely self-explanatory. The static predicates used are: “connect”,
encoding the topology of the network; “is-product”, encoding the types of liquid; “may-interface”,
encoding the interface restrictions;32 “not-unitary”, saying whether or not a pipe segment contains
just one batch – in which case the “push” and “pop” actions are much simpler and need not be
split (the “first” and “last” elements in the pipe are identical). The predicates “normal” and “pushupdating” ensure, in the obvious way, that the two parts of the split action can only be used as
intended. Finally, “on”, “first”, “follow”, and “last” encode where the relevant batches are. The
role of “on” should be clear, it just encodes locatedness in areas. As for the pipe contents, they are
modelled in a queue-like fashion, with a head “first”, a tail “last”, and a successor function “follow”.
The two parts of the “push” action update this representation accordingly.
31. Matters may be easier for planning systems that do not ground out actions in a pre-process. This didn’t affect our
design decision here since the large majority of systems around at the time of IPC-4 did employ such a pre-process.
32. Note here that we do not model the interface loss for those products that may interface.

510

E NGINEERING B ENCHMARKS

FOR

P LANNING

We did not encode uni-directional pipe segments, i.e. for all segments both “push” and “pop”
actions are available in the IPC-4 encodings. We modeled tankage restrictions with simple constructs involving tank slots located in areas, each slot having the capacity to store one unitary batch
of some given product type – that is, the “push” and “pop” actions now also specify what tank slot
the inserted/outgoing batch comes from/is inserted into. For simple examples regarding interface
and tankage restrictions, re-consider Figure 15. If the storage capacity for P2 in A2 is equal to zero,
then the transition from state (a) to state (b) becomes invalid. If we forbid the interface between P1
and P3 , then the transition from state (b) to state (c) becomes invalid.
Pipe segment speed can be easily taken account of (in durational PDDL). If the speed of a
segment is s, then simply assign the “push”/“pop” actions regarding that segment a duration proportional to 1s . (In the IPC-4 encoding, each “start”/“end” action takes exactly that time, while the
non-split actions regarding length-1 segments take time 2s .)
In reality, as outlined above the goals refer to amounts of product requested to be at certain
destination areas. With our encoding based on batches, formulating such a goal would mean to introduce a potentially large disjunction of conjunctive goals. If one wants to say, e.g., that three unitary batches of product P are requested in area A, then the needed goal condition is the disjunction
W
{b1 ,b2 ,b3 }⊆B (atb1 A) ∧ (atb2 A) ∧ (atb3 A) of the respective conjunctive goal for all three-subsets
{b1 , b2 , b3 } of the batches B of type P . To avoid exponential blow-ups of this kind, in our encoding
we used “personalized” goals instead, referring to specific batches instead of product amounts. Basically, this comes down to pre-selecting one of the {b1 , b2 , b3 } subsets in the above disjunction.33
One could also avoid the blow-up by replacing the disjunction with an existential quantification; but
that step would be undone in the compilation to STRIPS anyway.
Deadlines on the arrival of batches are, in durational PDDL, easily modeled by their compilation
to timed initial literals. For each goal deadline there is a literal saying that the respective batch can
still be ejected from the end of a pipe segment. The literal is initially true, and becomes false at
the time of the deadline. As described above, in the application there can also be pre-specified time
points at which an area produces or consumes a given amount of a product. We did not model this
in the IPC-4 domain (see also Section A.2.5).
As mentioned above, the structure of the Pipesworld domain can lead to several subtle phenomena in the possible plans. An example where plans have to perform a cyclic sequence of pumping
operations is depicted in Figure 16. The goal is to place B8 in A3. The shortest plan is the following (for readability, in the action parameters only the batches going into and out of the pipes are
shown): 0: PUSH S1,4 B8 B2, 1: POP S2,4 B2 B3, 2: POP S1,2 B3 B1, 3: PUSH S1,4 B1 B8, 4:
PUSH S4,3 B8 B7, 5: POP S2,3 B7 B4, 6: PUSH S2,4 B4 B2, 7: PUSH S4,3 B2 B8. Observe that
this plan contains two cyclic patterns. Action 0 inserts B8 into S14. Actions 1, 2, 3 then form a
cycle {S2,4 , S1,2 , S1,4 } that brings B8 into A4. Thereafter, action 4 inserts B8 into S43, and actions
5, 6, 7 form another cycle {S2,3 , S2,4 , S4,3 } bringing B8 to its goal position A3.34
33. Note that a bad choice of {b1 , b2 , b3 } can make the task harder to solve. We are, however, currently investigating the computational complexity of different variants of the Pipesworld, and our preliminary results suggest that
allowing/disallowing personalized goals does not affect the complexity.
34. Note that the need for such cyclic patterns is not an oddity introduced by our encoding. It is something that may (but
is probably not very likely to) happen in reality: like in the example, it becomes necessary if there isn’t enough liquid
in an origin area (here, A1 and A4) to push the needed amount of liquid (here, B8) through to its destination.

511

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

A2
S1,2
B1
A1

B4
S2,4 B3

B8

S2,3
B5
B6

B2
S1,4
A4

B7

A3

S4,3

Figure 16: An example where cycling is required to achieve the goal (place B8 in A3). Pipe segment
Si, j is directed from Ai to Aj.
version
notankage-nontemporal
notankage-temporal
notankage-temporal-d
notankage-temporal-dc
tankage-nontemporal
tankage-temporal

formulation
STRIPS
STRIPS
STRIPS
STRIPS
STRIPS
STRIPS

max-#op
6
6
6
9
6
6

max-#act
(14800) 13696
(14800) 13696
(8172) 7740
(8175) 7742
(107120) 101192
(107120) 101192

Table 2: Overview over the different domain versions of Pipesworld. Abbreviations used:
“temporal-d” for “temporal-deadlines”, “temporal-dc” for deadlines-compiled; max-#op
is the maximum number of (parameterized) PDDL operators for any instance, max-#act
is the maximum number of ground actions for any instance. Data in parentheses are collected before FF’s “reachability” pre-process (see text).

A.2.3 IPC-4 D OMAIN S TRUCTURE
The Pipesworld domain versions used in IPC-4 are notankage-nontemporal, tankage-nontemporal,
notankage-temporal, tankage-temporal, notankage-temporal-deadlines, and notankage-temporaldeadlines-compiled. All versions include interface restrictions. The versions with “tankage” in
their name include tankage restrictions. In the versions with “temporal” in their name, actions take
different amounts of time depending on the pipeline segment that is being moved, as explained
above. The versions with “deadlines” in their name include deadlines on the arrival of the goal
batches. One of these versions models the deadlines using timed initial literals, in the other version
(naturally, with “compiled” in its name) these literals are compiled into artificial (temporal) PDDL
constructs. None of the encodings uses any ADL constructs, and of each version there is just one
(STRIPS) formulation.
The domain versions and numbers of ground actions are overviewed in Table 2. As before,
the data were measured using (a temporal extension of) FF’s pre-processor. The numbers shown

512

E NGINEERING B ENCHMARKS

FOR

P LANNING

in parentheses refer to the situation before that pre-processor’s “reachability” pre-process, which
builds a relaxed planning graph for the initial state and removes all actions that do not appear in
that graph. We can observe that the numbers of ground actions are very low in the domain versions
with deadlines, and extremely high in the versions with tankage restrictions. The former is simply
because, due to the complicated generation process (explained in the next sub-section), examples
with deadlines were generated only up to a smaller size. The latter – high numbers of actions in
the presence of tankage restriction – is due to the additional blow-up incurred by the choice of tank
slots from which to draw/in which to put the batches. We note that the effect of the “reachability”
pruning is relatively moderate, in particular much lower than, e.g., in Airport, c.f. Section A.1.3.
A.2.4 IPC-4 E XAMPLE I NSTANCES
The Pipesworld example instances were generated by Frederico Liporace, in a process going from
random generators to XML files to PDDL files.35 Five scaling network topologies were designed
and used as the basis for the instance generation. Figure 17 shows the network topologies, as well
as a real-world network topology for comparison. As one can see, the largest network topology
used in IPC-4 is not quite yet in the same ballpark as the real network; but neither is it trivially
small in comparison. The volumes for pipeline segments that connect the same areas in the realworld example are not necessarily the same because the segments may have different cross section
diameters.
For the domain versions without tankage restrictions and deadlines, for each of the network
topologies 10 scaling random instances were generated. Within a network, the instances scaled
in terms of the total number of batches and the number of batches with a goal location. For the
instances featuring tankage restrictions or deadlines, the generation process was more complicated
because we wanted to make sure to obtain only solvable instances. For the tankage restriction examples, we ran Mips (Edelkamp, 2003b) on the respective “notankage” instances, with incrementally
growing tankage.36 We chose each instance at a random point between the first instance solved by
Mips, and the maximum needed tankage (enough tankage in each area to accommodate all instance
batches). Some instances could not be solved by Mips even when given several days of runtime,
and for these we inserted the maximum tankage. For the deadline examples, we ran Mips on the
corresponding instances without deadlines, then arranged the deadline for each goal batch at a random point in the interval between the arrival time of the batch in Mips’s plan, and the end time of
Mips’s plan. The instances not solved by Mips were left out.
A.2.5 C URRENT

AND

F UTURE W ORK

There is ongoing work on developing a Pipesworld specific solver, named Plumber (Milidiú & dos
Santos Liporace, 2004a; Milidiú & dos Santos Liporace, 2004b). Plumber incorporates a pipeline
simulator, domain specific heuristics, and procedures for reducing the branching factor by symmetry
elimination. It also lets the user choose between different search strategies, such as enforced hill
climbing (Hoffmann & Nebel, 2001) and learning real time A*(Korf, 1990). Currently it is being
extended to support temporal planning as well.
35. The same XML file is mapped into different PDDL files depending on the kind of encoding used; there was a lot of
trial and error before we came up with the final IPC-4 encoding.
36. Mips was a convenient choice since it is one of our own planners, and can also deal with temporal constructs.

513

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

A1

A1

S1
,2

1

1

,3
S1

S1
,2

,3
S1

1

A3
A2

Network 1

2

A2

Network 2

A3

2

1

,3
S1

S1
,2

A1

S3,4
A3

A2

A4
Network 3

1

46

233

A1

1

425

2

S2,3

94

S3,4
A3

A2

53

138

BA−1

,2

2

S1

UT−13

RC−5

12

2

1

35
13

,3

S1

TB−12

4

S3,4
A4

10

Network 5
BA−1

3

SZ−11

57

A5

A3

A2

RD−6

215

41

GU−3

47

S1,5
A1

375

30

Network 4

1

RV−8

43

A4

3

S2,3

83

GA−2

,3
S1

S1
,2

RP−7

1

10
17
6

(a)

31

20

3
3

SB−9

3

RB−4

2

(b)

Figure 17: The IPC-4 Pipesworld network topologies (a), and a real network topology (b). The
segment volumes in the latter are annotated in 100m3 units.

The availability of this solver will enable the extension of the Pipesworld benchmark, since it
will be easier to overcome the aforementioned difficulties in generating large feasible instances. We
hope to be able to generate feasible instances for real-world pipeline topologies, like the one shown
in Figure 17.
In addition to generating larger instances, the Pipesworld benchmark may be extended in many
ways to make it closer to the real application scenario. The relevant possible extensions include:
• Defining some pipeline segments with a single flow direction, that is, segments where only
“push” or “pop” actions are allowed. Note that this introduces dead ends/critical choices into
the problem.
• Un-personalized goals. This could be accomplished, e.g., by imposing the desired tank volume for the goal products in the respective areas. The planner then also has to decide which
batches will be used to bring the tank volume up to the desired level.
• Modeling production and consumption of products at pre-specified points in time, as described above.

514

E NGINEERING B ENCHMARKS

FOR

P LANNING

• Using rational numbers to model tank capacities and current volumes, instead of the encoding
based on unitary tank slots. Apart from being a more precise model of the real world (when
combined with rational-valued batch sizes, see below), such an encoding would avoid unnecessary symmetries that currently arise from the availability of several non-distinguishable
tank slots (in the same area, for the same product).
The most important shortcoming of our encoding is the use of unitary batches. It would be much
more appropriate to base the encoding on product amounts given by real numbers. One problematic
aspect of such an encoding is that it would, most naturally, demand a continuous choice of how
much liquid to pump into a pipeline. Like in Airport (c.f. Section A.1.5), such a choice could
naturally be modelled using Fox and Long’s (2003) “duration inequalities”, but it is unclear how to
develop planners that can deal with these reasonably well. Unlike in Airport, implementing such
a choice is not the end of the difficulties on the modelling side. How to model the continuous
contents of a pipeline? The number of distinct regions of liquid in the pipeline can grow arbitrarily
high, in principle. One solution might be to fix some upper bound, and simply disallow a pumping
operation if it would result in too many distinct regions. This may be a bearable loss of precision,
given the upper bound is high enough. But even then, it is bound to be awkward to correctly update
the contents of the pipeline when some amount x of product is pushed in: the number of different
products leaving the pipe depends on x. An option here may be to use a complicated construct of
conditional effects.
All in all, our impression is that pipeline scheduling won’t be realistically modelled in PDDL,
and successfully solved with planners, unless one introduces into the language a data structure
suitable for modelling the contents of pipes. Basically, this would be queues whose elements are
annotated with real numbers, and whose basic operations are the usual “push” and “pop”. The
semantics of the pipes could then be explicitly computed inside the planner, rather than awkwardly
modelled using language constructs that are likely to disturb a general search mechanism.
A.3 Promela
This domain was created for IPC-4 by Stefan Edelkamp.
A.3.1 A PPLICATION D OMAIN
Before dropping into the Promela domain, we briefly recall its origin.
The model checker SPIN (Holzmann, 2003) targets efficient software verification. It has been
used to trace logical design errors in distributed systems design, such as operating systems, data
communications protocols, switching systems, concurrent algorithms, railway signaling protocols,
etc. The tool checks the logical consistency of a specification. SPIN reports on deadlocks, unspecified receptions and identifies race conditions, and unwarranted assumptions about the relative speeds
of processes. SPIN (starting with Version 4) provides support for the use of embedded C code as
part of model specifications. This makes it possible to directly verify implementation level software
specifications, using SPIN as a driver and as a logic engine to verify high level temporal properties. SPIN works on-the-fly, which means that it avoids the need to construct a global state graph
as a prerequisite for the verification of system properties. SPIN supports property checking in linear temporal logic (LTL). LTL expresses state trajectory constraints, using temporal modalities like

515

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

eventually, always, and until37 . SPIN uses specific mechanisms for specifying deadlock-freeness
and other safety properties, in addition to general LTL specifications. To explore the state space an
ordinary or a nested search algorithm is applied, depending on whether or not a state-based (a.k.a.
safety) property is to be verified.
Promela is SPIN’s input specification language. Its computational model is that of asynchronous
communicating finite state machines. Promela allows to define classes of finite processes. A special
process called init is started first and usually governs the instantiation of the other processes of the
system. As it is possible for a process to invoke another one, Promela allows modeling systems with
dynamic creation of state components. Communication in Promela is achieved via shared variables
and message channels. Two kind of message channels are distinguished for synchronous and asynchronous communication. An asynchronous channel is basically a FIFO queue, while synchronous
channels imply rendezvous communication in which a transition of the system involves two processes, one reading a message from the channel and another sending a message to it. Here, we
consider only asynchronous communication. The body of each process class is basically a sequence
of statements. Each statement is interpreted as a transition of the process. Typical statements include assignments, numerical and boolean expressions and channel operations. Promela also allows
to define atomic regions, whose are a sequence of transitions that should be treated as an atomic
action. They can be interpreted as weighted transitions whose costs are the number of steps within
the regions.38
For IPC-4, we used two example communication protocols formulated in Promela: Dijkstra’s
Dining Philosophers problem, and the so-called Optical Telegraph protocol. We briefly describe
the latter protocol in Section A.3.4. To illustrate the Promela language, let us consider the Dining
Philosophers problem, where n philosophers sit around a table to have lunch. There are n plates,
one for each philosopher, and n forks located to the left and to the right of each plate. Since two
forks are required to eat the spaghetti on the plates, not all philosopher can eat at a time. Moreover,
no communication except taking and releasing the forks is allowed. The task is to devise a local
strategy for each philosopher that lets all philosophers eventually eat. The simplest solution to
access the left fork followed by the right one, has an obvious problem. If all philosophers wait for
the second fork to be released there is no possible progress; a deadlock has occurred.
It is not difficult and probably insightful to derive a bottom-up PDDL encoding for the Dining
Philosophers domain, using actions like eat, wait and think. Our motivation, however, was to come
up with a top-down encoding, starting from a Promela specification, automatically translating it into
PDDL.
The deadlock model of the Dining Philosophers is specified in Promela as shown in Figure 18.
The first lines define some macros and declare the array of N boolean variables that represent the
availability of the forks. The following lines define the behavior of a process of type philosopher.
The process iterates indefinitely in an endless loop (do) with one unique entry marked by symbol
::. Statements are separated by a semicolon. The first transition left!fork consists of the send
operation of tag fork to channel left, which itself is a macro to address forks with the current
process id pid. It represents the availability of the left fork of the philosopher. The access transition left?fork can be executed only if reading tag fork from channel left is successful. The
37. Note that some fragments of LTL are likely to be included into the PDDL language for the next international planning
competition (Gerevini & Long, 2005)
38. Further documentation for the Promela specification language can be found on the web site for SPIN at
http://netlib.bell-labs.com/netlib/spin/whatispin.html

516

E NGINEERING B ENCHMARKS

FOR

P LANNING

#define MAX PHILOSOPHERS N
mtype=fork
#define left forks[ pid]
#define right forks[( pid+1) % MAX PHILOSOPHERS]
chan forks[MAX PHILOSOPHERS] = [1] of bit;
active [MAX PHILOSOPHERS] proctype philosopher()
{
left!fork;
do
::left?fork -> /* try to get left fork */
right?fork; /* try to get right fork */
/* eat... */
left!fork; right!fork /* release forks */
/* meditation... */
od
}
Figure 18: Promela specification for a model of the Dining Philosophers problem.
next transition right?fork is similar to the first, while the last two ones sends tag fork back to
the channels left and right.
A.3.2 IPC-4 PDDL A DAPTATION
Model Checking and Action Planning are closely related, c.f. Section 3. While a model checker
searches for a counterexample in the form of a sequence of transitions to falsify a given specification, a planner searches for a sequence of actions that satisfies a given goal. In both cases, the
basic models (STRIPS Planning, Kripke structures), refer to implicit graphs, where the nodes are
annotated with atomic propositions.
For automatically generating a PDDL model from the Promela syntax we wrote a compiler (Edelkamp, 2003a). It is restricted to safety properties, especially deadlocks, but assertions
and global invariances are not difficult to obtain. We also concentrated on models with a fixed number of processes, since most of the models of communication protocols adhere to this restriction.39
The compiler does not parse the Promela code itself, but takes as the input the intermediate
representation of the problem that is generated by the SPIN validation tool40 . Figure 19 shows
the textual automata representation for the philosopher process. In this case, the value N has been
initialized with 10 philosophers. While this file contains almost all necessary information for the
39. The dynamic creation of processes with PDDL would require a language extension for dynamic object creation.
This extension was dismissed since it would involve heavy changes to existing planner technology, and its relevance
(beyond Promela) is unclear.
40. More precisely, the Promela input file was taken, the corresponding c-file was generated, the verifier was compiled
and the executable was run with option -d.

517

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

translation, the number of processes and queues (i.e., message channels) as well as the queue capacities had to be read from the original Promela input file41 .
proctype philosopher
state 1 -(trans 3)-> state 6 line 11 => forks[ pid]!fork
state 6 -(trans 4)-> state 3 line 12 => forks[ pid]?fork
state 3 -(trans 5)-> state 4 line 14 => forks[(( pid+1)%10)]?fork
state 4 -(trans 3)-> state 5 line 16 => forks[ pid]!fork
state 5 -(tras 6)-> state 6 line 16 => forks[(( pid+1)%10)]!fork
Figure 19: Automata representation for the model of the 10 Dining Philosophers problem.
To derive a suitable PDDL encoding of the domain, each process is represented by a finite state
automata. Hence, the propositional encoding simulates the automaton. Some propositional atoms
true in the initial state of one process in the running example problem is shown in Figure 20 (a)42 .

(is-a-process philosopher-0 philosopher)
(at-process philosopher-0 state-1)
(trans philosopher trans-3 state-1 state-6)
(trans philosopher trans-4 state-6 state-3)
(trans philosopher trans-5 state-3 state-4)
(trans philosopher trans-3 state-4 state-5)
(trans philosopher trans-6 state-5 state-6)

(is-a-queue forks-0 queue-1)
(queue-head forks-0 qs-0)
(queue-tail forks-0 qs-0)
(queue-next queue-1 qs-0 qs-0)
(queue-head-msg forks-0 empty)
(queue-size forks-0 zero)
(settled forks-0)

(a)

(b)

(writes philosopher-0 forks-0 trans-3) (trans-msg trans-3 fork)
(reads philosopher-0 forks-0 trans-4) (trans-msg trans-4 fork)
(reads philosopher-0 forks-1 trans-5) (trans-msg trans-5 fork)
(writes philosopher-0 forks-1 trans-6) (trans-msg trans-6 fork)
(c)
Figure 20: Propositional encoding of one philosopher’s process (a), Propositional encoding of a
(single-cell) communication channel (b), Connecting communication to local state transitions (c).
The encoding of the communication structure represents channels as graphs. The PDDL encoding additionally exploits a cyclic embedding of a queue into an array. More formally, each (FIFO)
channel Q is represented by a structure GQ = (SQ , headQ , tailQ , δQ , messQ ,contQ ), with SQ being
the set of queue cells, headQ , tailQ ∈ SQ being the head and tail cells of Q, messQ ∈ M|SQ | being
41. To avoid conflicts with pre-compiler directives, we first invoked the c-compiler with command line option -E, which
only executes the pre-compiler.
42. Here we use transition IDs, in the competition a less accessible textual representation of the label was chosen.

518

E NGINEERING B ENCHMARKS

FOR

P LANNING

the vector of messages in Q (M is the set of all messages), contQ ∈ IR|SQ | being the vector of
variable values in Q and δQ : SQ → SQ being the successor relation for Q; if SQ = s[1], . . . , s[k]
then δ(s[i]) = s[(i + 1) mod k]. Explicitly modeling head and tail positions in the queue trades
space for time, since queue updates reduce to constant time.
A queue is either empty (or full) if both pointers refer to the same queue state. As a special case,
very simple queues (as in our example) may consist of only one queue state, so the successor bucket
of queue state 0 is the queue state 0 itself. In this case the grounded propositional encoding includes
operators where the add and the delete lists share an atom. We here make the standard assumption
that deletion is done first. The propositional atoms for one queue and the adaption of two queues to
one process are exemplified in Figure 20 (b) and (c).
Queue content, shared and local variables are modeled by PDDL fluents. The only difference of
local variables compared to shared ones is the restricted visibility scope, so that local variables are
prefixed with the process they appear in. The two benchmark protocols we selected for IPC-4 rely
on pure message passing, so that no numerical state variables there are involved. This allowed us to
supply a propositional model for all problems.
(:action activate-trans
:parameters (?p - process ?pt - proctype ?t - transition ?s1 ?s2 - state)
:precondition (and (forall (?q - queue) (settled ?q)) (trans ?pt ?t ?s1 ?s2)
(is-a-process ?p ?pt) (at-process ?p ?s1) (pending ?p))
:effect (and (activate ?p ?t) (not (pending ?p)))))
Figure 21: Testing if a transition is enabled and activating it.
Our PDDL domain encoding uses seven operators, named activate-trans, queue-read,
queue-write, advance-queue-head, advance-empty-queue-tail, advance-non-empty-queue-tail, and
process-trans. The activation of a process is shown in Figure 21. Here we see that a pending process
is activated, if all queues are settled and there is a transition that matches the current process state.
Briefly, the operators encode the protocol semantics as follows. Operator activate-trans activates
a transition in a process of a given type from local state s1 to s2 . The operator sets the predicate
activate. This boolean flag is a precondition of the queue-read and queue-write actions, which set
propositions that initialize the reading/writing of a message. For queue Q in an activated transition
querying message m, this corresponds to the Promela expression Q?m, respectively Q!m. After the
read/write operation has been initialized, the queue update operators must be applied, i.e. advancequeue-head, advance-empty-queue-tail, or advance-non-empty-queue-tail as appropriate. As the
names indicate, these operators respectively update the head and the tail positions, as needed to
implement the requested read/write operation. The operators also set a settled flag, which is a
precondition of every queue access action. Action process-trans can then be applied. It executes the
transition from local state s1 to s2 , i.e. sets the new local process state and re-sets the flags.
If the stored message does not match the query, or the queue capacity is either too small or too
large, then the active local state transition will block. If all active transitions in a process block, the
process itself will block. If all processes are blocked, we have a deadlock in the system. Detection
of such deadlocks is implemented, in different domain versions, either as a collection of specifically
engineered actions or, more elegantly, as a set of derived predicates. In both cases one can infer,
along the lines of argumentation outlined above, that a process/the entire system is blocked. The
519

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

(:derived (blocked-trans ?p - process ?t - transition)
(exists (?q - queue)
(exists (?m - message)
(exists (?n - number)
(and (activate ?p ?t) (reads ?p ?q ?t) (settled ?q)
(trans-msg ?t ?m) (queue-size ?q ?n) (is-zero ?n))))))
(:derived (blocked ?p - process)
(exists (?s - state)
(exists (?pt - proctype)
(and (at-process ?p ?s) (is-a-process ?p ?pt)
(forall (?t - transition)
(or (blocked-trans ?p ?t) (forall (?s2 - state) (not (trans ?pt ?t ?s ?s2)))))))))

Figure 22: Derivation of a deadlock.
goal condition that makes the planners detect the deadlocks in the protocols is simply a conjunction
of atoms requiring that all processes are blocked. As an example of the derivation rules for derived
predicates, the PDDL description for the derivation of a deadlock based on blocked read accesses is
shown in Figure 22.
A.3.3 IPC-4 D OMAIN S TRUCTURE
For each of the two benchmark protocols in IPC-4, we created three different domain versions:
derivedpredicates, which contains derived predicates to infer deadlocks; plain, a purely propositional specification with specific actions that have to be applied to establish the deadlock (the later
actions are basically the Gazen and Knoblock (1997) compilation of derived predicates, c.f. Section 2); fluents an alternative to the latter with numerical state variables that encodes the size of
the queues and the messages used to access their contents. We also made a version called fluentsderivedpredicates, the obvious combination, but none of the IPC-4 competitors participated in there,
so we omit it herein. Within each domain version, there is one formulation that includes the ADL
constructs quantification, disjunctive preconditions, and negated preconditions. In those domain
versions without fluents, another formulation is in pure STRIPS, obtained from the respective ADL
encodings using the adl2strips compiler (which can not handle numeric variables). Unfortunately,
some of the larger problem instances lead to STRIPS files that were too big to be stored on disk
(remember that adl2strips grounds out all operator parameters). These too-large instances were, of
course, left out of the respective test suites.
We kept fluent-domains as separated domain versions, rather than domain version formulations,
in order be able to compare propositional and numerical exploration efficiencies, and to emphasize
that fluent variables are essential in real-world model checking and should be treated separately.
The domain versions and numbers of operators and ground actions are overviewed in Table 3.
Consider the rows in the table from top to bottom. As before, times in parentheses are values
before FF’s “reachability” pre-process, which builds a relaxed planning graph for the initial state
and removes all actions that do not appear in that graph. The STRIPS formulation is fully grounded
using the adl2strips program, derived from FF’s pre-processor (c.f. Section 2). This is both the

520

E NGINEERING B ENCHMARKS

version
optical-telegraph
optical-telegraph
optical-telegraph-dp
optical-telegraph-dp
optical-telegraph-fluents
philosophers
philosophers
philosophers-dp
philosophers-dp
philosophers-fluents

formulation
STRIPS
ADL
STRIPS DP
ADL DP
ADL
STRIPS
ADL
STRIPS DP
ADL DP
ADL

FOR

P LANNING

max-#op
3345
11
4014
11
11
840
11
1372
11
11

max-#act
(3345) 3345
(5070) 3345
(4014) 4014
(6084) 4014
(1337) 1169
(840) 840
(930) 840
(1372) 1372
(1519) 1372
(930) 930

Table 3: Overview over the different domain versions of Promela. Abbreviations used: “dp” derived predicates; max-#op is the maximum number of (parameterized) PDDL operators
for any instance, max-#act is the maximum number of ground actions for any instance.
Data in parentheses are collected before FF’s “reachability” pre-process (see text). Derivation rules (ground derivation rules) are counted as operators (ground actions).

reason why the number of operators is the same as the number of ground actions, and why FF’s preprocess – identical to the one run by adl2strips – has no effect. In the ADL formulation, we see that
the reachability pruning reduces the number of actions by a factor of almost 2, similar to the Airport
domain (c.f. Section A.1.3). The picture for the next two domain versions, with derived predicates,
is very similar. In fact, since, consistently with the data in Section 5, we count derivation rules as
actions, the data are identical. The only reason why it is not identical in Table 3 is that, using derived
predicates instead of operators, FF’s pre-processor scales to larger instances (presumably, due to
some unimportant implementation detail). In the next domain version, formulated with numeric
variables, FF’s pre-processor scales even worse. However, even in instances with the same number
of telegraphs, there are less ground actions than before, due to the more different encoding. The
observations to be made in Dining Philosophers are exactly the same, only with different numbers.
The only notable difference is that the effect of FF’s reachability pruning is weaker, yielding only a
slight decrease in the number of actions in the versions without fluents, and no decrease at all in the
version with fluents. Apparently, the more complex process structure of Optical Telegraph leads to
more useless action instances.
A.3.4 IPC-4 E XAMPLE I NSTANCES
As said, we have selected two simple communication protocols as benchmarks for IPC-4: the encoding of the Dining Philosopher problem as described above, and the so-called Optical Telegraph
protocol (Holzmann, 1990).
The Optical Telegraph protocol involves n pairs of communicating processes, each pair featuring an “up” and a “down” process. Such a pair can go through a fairly long, heavily interactive,
sequence of operations, implementing the possible data exchange between the two stations. Before
data are exchanged, various initializing steps must be taken to ensure the processes are working
synchronously. Most importantly, each process writes a token into a “control channel” (queue) at
521

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

the beginning of the sequence, and reads the token out again at the end. This causes a deadlock
situation because there are only n control channels, each of which is accessed by two processes.
When every pair of up/down processes has occupied just one control channel, the overall system is
blocked.
In both the Dining Philosopher and the Optical Telegraph benchmark, the instances scale via a
single parameter, the number of philosophers and the number of control stations, respectively. We
scaled that parameter from 2 to 49 for the competition instances. The Promela models of the benchmarks are distributed together with our experimental model checking tool HSF-SPIN (Edelkamp,
Leue, & Lluch-Lafuente, 2004), that extends SPIN with heuristic search strategies to improve error
detection.
A.3.5 F UTURE W ORK
In general terms, we see the Promela planning benchmark as another important step towards exploiting synergies between the research areas of Planning and Model Checking (Giunchiglia & Traverso,
1999). For example, complement to recent progress in planning, explicit directed model checking
in the domain of protocol validation (Edelkamp et al., 2004) and symbolic directed model checking
in the domain of hardware validation (Reffel & Edelkamp, 1999) has led to drastic improvements
to state-of-the-art model checkers. This and other work, e.g., (Yang & Dill, 1998; Bloem, Ravi,
& Somenzi, 2000), show that in model checking there is a growing interest in guided exploration,
mostly to find errors faster than blind state space enumeration algorithms. With the compilation of
the Promela domain model, an alternative option of applying heuristic search to model checking
problems is available. More work is needed to understand when planning heuristics work or fail in
model checking benchmarks.
We strongly believe that both communities will profit from a wide-spread availability of techniques that represent Model Checking problems in PDDL. This allows a direct comparison of exploration efficiencies. Based on the design of the Promela domain, suitable PDDL domain encodings of
two further expressive model checking input languages, Graph Transformation Systems (Edelkamp,
Jabbar, & Lluch-Lafuente, 2005) and Petri Nets (Edelkamp & Jabbar, 2005), have been proposed.
The encodings exploit the expressive power of PDDL as well as the efficiency of current planners.
As a result, state-of-the-art planners are often faster compared to model checkers in these benchmarks.
A.4 PSR
Sylvie Thiébaux and others have worked on this application domain. The domain was adapted for
IPC-4 by Sylvie Thiébaux and Jörg Hoffmann.
A.4.1 A PPLICATION D OMAIN
The Power Supply Restoration (PSR) domain we consider here is derived from an application investigated by Sylvie Thiébaux and others (Thiébaux et al., 1996; Thiébaux & Cordier, 2001). PSR
deals with reconfiguring a faulty power distribution system to resupply customers affected by the
faults. This is a topic of ongoing interest in the field of power distribution.
In more detail, a power distribution system (see Figure 23), is viewed as a network of electric lines connected by switches and fed via a number of power sources that are equipped with
circuit-breakers. Switches and circuit-breakers have two possible positions, open or closed, and are
522

E NGINEERING B ENCHMARKS

FOR

P LANNING

Figure 23: Sample power distribution system. Sources/circuit-breakers (e.g., CB4) are represented
by large squares, and switches (e.g., SD3) by small squares. Open switches (e.g., SD8)
are white. The area fed by CB4 is boxed. Gray and dark are used to distinguish adjacent
areas fed by different sources

connected to at most two lines. There is no restriction on the connectivity of lines, some extremities
of which can also be connected to earth. When the circuit-breaker of a power source is closed, the
power flows from the source to the lines downstream, until the flow is stopped by an open switch.
The switches are used to appropriately configure the network and their position is initially set so
that each line is fed by exactly one source.
Due to bad weather conditions, permanent faults can affect one or more lines of the network.
When a power source feeds a faulty line, the circuit-breaker fitted to this source opens to protect the
rest of the network from overloads. This leaves all the lines fed by the source without power. The
problem consists in planning a sequence of switching operations (opening or closing switches and
circuit-breakers) bringing the network into a configuration where a maximum of non-faulty lines
are resupplied. For instance, suppose that line l20 becomes faulty. This leads the circuit-breaker
CB4 to open and the boxed area to be without power. A possible restoration plan would be the
following: open switches SD16 and SD17 to isolate the faulty line, then close SD15 to have source
CB7 resupply l19, and finally re-close CB4 to resupply the others.
In the original PSR problem (Thiébaux & Cordier, 2001), the maximal capacity of sources and
lines, as well as the load requested by customers are taken into account. The plan must optimize
various numerical parameters such as breakdown costs, power margins, and distance to the initial
configuration, subject to the capacity constraints. Furthermore, due to the fault sensors and switches
being unreliable, the location of the faults and the current network configuration are only partially
observable. When optimizing, this leads to a complex tradeoff between acting to resupply lines and
acting (intrusively) to reduce uncertainty.

523

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

A.4.2 IPC-4 PDDL A DAPTATION
In the PDDL adaptation, we benefited from contributions by Piergiorgio Bertoli, Blai Bonet, Alessandro Cimatti, and John Slaney (Bertoli et al., 2002; Bonet & Thiébaux, 2003). Compared to the
original PSR domain described above, the IPC-4 version underwent 3 major adaptations. Firstly,
the IPC deals with fully observable domains. Hence, while partial observability in PSR is a crucial
issue (Thiébaux et al., 1996; Bertoli et al., 2002; Bonet & Thiébaux, 2003), the IPC version assumes
complete observability. Secondly, given the difficulty of encoding even the basic problem, we chose
to ignore the numerical and optimization aspects of PSR (capacities, power margins, . . . ). Thirdly,
the IPC-4 version is set up as a pure goal-achievement problem, where the goal specifies a set of
lines that must be (re)-supplied. We considered a more realistic goal asking the planner to supply
any line that can be. However, we were unable to compile this goal into STRIPS in reasonable
space, and opted for the simpler goal to keep the STRIPS formulation as consistent as possible with
others.
Our highest level and most natural IPC-4 encoding of PSR involves ADL constructs and derived
predicates. Briefly, the encoding works as follows. PSR problem instances specify (1) the network
topology, i.e., the objects in the network and their connections (the lines, the switching devices, that
is, the switches and the sources/circuit-breakers, two “side” constants side1 and side2 to denote the
two connection points of a switching device, and the connection relations between those objects),
(2) the initial configuration, i.e., the initial positions (open/closed) of the switching devices, and (3)
the modes (faulty or not) of the various lines. Among those, only the devices’ positions can change.
A number of other predicates are derived from these basic ones. They model the propagation of the
current into the network with a view to determining which lines are currently fed and which sources
are affected by a fault, i.e. feed a fault. The closed-world assumption semantics of PDDL2.2
derived predicates is exactly what is needed to elegantly encode such relations. These require a
recursive traversal of the network paths which is naturally represented as the transitive closure of
the connection relation of the network. The most complex of these derived predicates, upstream,
requires four parameters, two of which, however can only take two possible values, and expresses
that the power flows from one of the two sides of some device (side ?sx of device ?x) to one of the
sides of another (side ?sy of device ?y) This happens when the side of ?x which is opposite to ?sx is
directly connected to ?sy (via some line), or if there exists some closed device ?z one side of which
is upstream of ?sx and the other side of which is connected to ?sy:
(:derived (upstream ?x - DEVICE ?sx - SIDE ?y - DEVICE ?sy - SIDE)
(and (closed ?x)
(or (and (= ?sx side1) (con ?x side2 ?y ?sy))
(and (= ?sx side2) (con ?x side1 ?y ?sy))
(exists (?z - DEVICE)
(and (closed ?z)
(or (and (con ?z side1 ?y ?sy) (upstream ?x ?sx ?z side2))
(and (con ?z side2 ?y ?sy) (upstream ?x ?sx ?z side1))))))))
From upstream, it is relatively easy to define predicates stating whether a given line is fed or a given
source is affected.

524

E NGINEERING B ENCHMARKS

FOR

P LANNING

The goal in a problem instance asks that given lines be fed and all sources be unaffected.43
The available actions are closing and opening a switching device. Their effect is simply to set the
device position as requested. In addition, there is an action wait, which models the event of circuitbreakers opening when they become affected. Wait is applicable when an affected source exists,
and is the only applicable action in that case (the open and close actions require as a precondition
that no source is affected). This, together with the goal, ensures that the wait action is applied as
soon as a source is affected. The effect of the wait action is to open all the affected circuit-breakers.
Concretely, the wait and close actions are as follows (note that open is similar to close and that earth
is treated as a device whose position cannot be changed by the actions):
(:action close
:parameters (?x - DEVICE)
:precondition (and (not (= ?x earth))
(not (closed ?x))
(forall (?b - DEVICE) (not (affected ?b))))
:effect (closed ?x))
(:action wait
:parameters ()
:precondition (exists (?b - DEVICE) (affected ?b))
:effect (forall (?b - DEVICE) (when (affected ?b) (not (closed ?b)))))
It would have been possible to encode the opening of affected breakers as a conditional effect of the
close action. However, this would have required more complex derived predicates with an additional
device as parameter and a conditional flavor, specifying, e.g., whether or not a circuit-breaker would
be affected if we were to close that device.
A.4.3 IPC-4 D OMAIN S TRUCTURE
We used four domain versions of PSR in IPC-4. Primarily, these versions differ by the size of
the problem instances encoded. The instance size determined in what languages we were able
to formulate the domain version. We tried to generate instances of size appropriate to evaluate
current planners, i.e, we scaled the instances from “push-over for everybody” to “impossibly hard
for current automated planners”, where we got our intuitions by running a version of FF enhanced
to deal with derived predicates. The largest instances are of the kind of size one typically encounters
in the real world. More on the instance generation process is said in Section A.4.4.
The domain versions are named 1. large, 2. middle, 3. middle-compiled, and 4. small.
Version 1 has the single formulation adl-derivedpredicates. Version 2 has the formulations adlderivedpredicates, simpleadl-derivedpredicates, and strips-derivedpredicates. Version 3 has the
single formulation adl, and version 4 has the single formulation strips. The formulation names simply give the language used. Version 1 contains the largest instances, versions 2 and 3 contain (the
same) medium instances, and version 4 contains the smallest instances. The adl-derivedpredicates
43. Note that after the circuit-breaker of an affected source opens, this source is not affected any more, as it does not feed
any line. Then, if the circuit-breaker is closed again, the source will stay unaffected unless it re-starts feeding a faulty
line.

525

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

version
large
middle
middle
middle
middle-compiled
small

formulation
ADL DP
ADL DP
SIMPLE-ADL DP
STRIPS DP
ADL
STRIPS

max-#op
7
7
3485
3560
5
9400

max-#act
(14038) 7498
(7055) 3302
(3485) 3485
(3560) 3560
(99) 71
(9400) 9400

Table 4: Overview over the different domain versions and formulations of PSR. Abbreviations used:
“dp” derived predicates; max-#op is the maximum number of (parameterized) PDDL
operators for any instance, max-#act is the maximum number of ground actions for any
instance. Data in parentheses are collected before FF’s “reachability” pre-process (see
text). Derivation rules (ground derivation rules) are counted as operators (ground actions).

formulation is inspired by Bonet and Thiébaux (2003); it makes use of derived predicates as explained above, and of ADL constructs in the derived predicate, action, and goal definitions. In the
simpleadl-derivedpredicates and strips-derivedpredicates formulations, all ADL constructs (except
conditional effects in the simpleadl case) are compiled away. The resulting fully grounded encodings are significantly larger than the original, while on the other hand the length of plans remains
nearly unaffected44 . The pure adl formulation is obtained from the adl-derivedpredicates formulation by compiling derived predicates away, using the method described by Thiébaux et al. (2003,
2005). While there is no significant increase in the domain size, the compilation method can lead to
an increase in plan length that is exponential in the arity of the derived predicates (no compilation
method can avoid such a blow-up in the worst case, see Thiébaux et al., 2003, 2005). Indeed, in
our particular PSR example instances, we observed a considerable blow up in plan length. We felt
that this blow up was too much to allow for a useful direct comparison of data generated for adlderivedpredicates as opposed to adl, and we separated the adl formulation out into domain version
3 as listed above.
The strips domain formulation proved quite a challenge. All the 20 or so schemes we considered for compiling both derived predicates and ADL constructs away led to either completely
unmanageable domain descriptions or completely unmanageable plans. The problem is that feasible compilations of derived predicates create new actions with highly conditional effects, and that
compiling those away is impractical. We therefore adopted a different fully-grounded encoding inspired by Bertoli et al. (2002). The encoding is generated from a description of the problem instance
by a tool performing the reasoning about power propagation. In the resulting tasks, the effects of the
close actions directly specify which circuit-breakers open as a result of closing a switch in a given
network configuration. No derived predicates are needed, and consequently the STRIPS encoding
is much simpler and only refers to the positions of the devices and not to the lines, faults, or connections. Nevertheless, we were still only able to formulate comparatively small instances in STRIPS,
without a prohibitive blow-up in the encoding size.
44. The only variation is due to the fact that the existential precondition of the wait action causes the compilation to split
this action into as many wait actions as circuit-breakers

526

E NGINEERING B ENCHMARKS

FOR

P LANNING

The domain versions, formulations, and their respective numbers of operators and ground actions, are shown in Figure 4. Data in parentheses are collected before FF’s “reachability” preprocess, building a relaxed planning graph for the initial state and removing all actions that do not
appear in that graph. In the encodings using ADL and derived predicates, this reduces the number of ground actions by a factor of around 2; for only ADL, the factor is much smaller; for the
other encodings, no reduction at all is obtained, simply due to the fact that these encodings are obtained with adl2strips, which uses the same pruning process. Some interesting observations can be
made in the “middle” versions and formulations. The data shown there correspond to the largest
instance that FF’s pre-processor could handle in all versions/formulations, to enable direct comparison. We see that, for formulation in SIMPLE-ADL and STRIPS, we need to introduce some more
ground actions. We also see that, curiously, in the compilation of derived predicates (compilation to
“middle-compiled”), the number of ground actions decreases dramatically. The reason for this lies
in that these data count ground derivation rules as ground actions, and in the subtleties of the compilation of derived predicates. In the “middle” formulations, almost all ground actions are in fact
ground derivation rules. These are compiled away for “middle-compiled” following Thiébaux et al.
(2003, 2005), introducing a single action that has one distinct conditional effect for each derivation rule, c.f. Section 2. Which just means that the complexity of thousands of derivation rules is
replaced with the complexity of an action with thousands of conditional effects.
A.4.4 IPC-4 E XAMPLE I NSTANCES
Due to contractual agreements, we were unable to use real data in the competition. Instead, PSR
instances were randomly generated using “randomnet”, a special purpose tool implemented by John
Slaney.
Power distribution networks often have a mesh-able structure exploited radially: the path taken
by the power of each source forms a tree whose nodes are switches and whose arcs are electric
lines; terminal switches connect the various trees together. Randomnet takes as input the number of
sources, a percentage of faulty lines, and a range of parameters for controlling tree depth, branching,
and tree adjacency, whose default values are representative of real networks. Randomnet randomly
generates a network topology and a set of faulty lines. These are turned into the various PDDL
encodings above by a tool called net2pddl, implemented by Piergiorgio Bertoli and Sylvie Thiébaux.
net2pddl computes the set of all lines that can be supplied, and makes this the goal.
The instances we generated make use of randomnet default settings, with two exceptions to
create problems of increasing difficulty. The first is that the maximal depth of the trees takes a range
of values up to twice the default. The larger this value, the harder the problem. The second is that
the percentage of faulty lines ranges from 0.1 to 0.7. Problems at the middle of the range are harder
on average, those at the bottom of the range are more realistic.
Each instance suite contains 50 instances. The small instances feature between 1 to 6 sources,
the middle instances feature up to 10 sources, and the large instances feature up to 100 sources.
The large instances are of a size typical for real-world instances, or even larger. The example in
Figure 23 is representative of a difficult instance in the middle set.
A.4.5 F UTURE W ORK
While PSR has been around for some time as a benchmark for planning under uncertainty, we expect
that the work done in the framework of IPC-4 will facilitate its acceptance as one of the standard

527

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

benchmarks for planning. To this end, we have developed a PSR resource web page giving access
to the relevant papers, data, and tools (net2pddl, randomnet, . . . ).45 One aspect of future work is to
complete and maintain this website, making available a number of already existing tools, such as
SyDRe (Thiébaux et al., 1996), a domain-specific system for the full PSR problem, and Matt Gray’s
net2jpeg which graphically displays networks generated by randomnet.
Considering future IPCs, there is potential for extending the PDDL encoding to take the numerical and optimization aspects of the benchmark into account. PDDL-like encodings of the partially
observable version of the benchmark exist (Bonet & Thiébaux, 2003) and are ready to be used in a
future edition of the probabilistic part of the IPC.46
A.5 Satellite
The Satellite domain was introduced in IPC-3 by Long and Fox (2003). It is motivated by a NASA
space application: a number of satellites have to take images of a number of spatial phenomena,
obeying constraints such as data storage space and fuel usage. In IPC-3, there were 5 versions of the
domain, corresponding to different levels of the language PDDL2.1: Strips, Numeric, SimpleTime
(action durations are constants), Time (action durations are expressions in static variables), and
Complex (durations and numerics, i.e. the “union” of Numeric and Time).
The adaptation of the Satellite domain for IPC-4 was done by Jörg Hoffmann. All IPC-3 domain
versions and example instances were re-used, except SimpleTime – like in the other IPC-4 domains,
we didn’t want to introduce an extra version distinction just for the difference between constant
durations and static durations. On top of the IPC-3 versions, 4 new domain versions were added.
The idea was to make the domain more realistic by additionally introducing time windows for the
sending of the image data to earth, i.e. to antennas that are visible for satellites only during certain
periods of time – according to Derek Long, the lack of such time windows was the main shortcoming
of the IPC-3 domain.47
We extended the IPC-3 Time domain version to two IPC-4 domain versions, Time-timewindows
and Time-timewindows-compiled. We extended the IPC-3 Complex domain version to the two IPC-4
domain versions Complex-timewindows and Complex-timewindows-compiled. In all cases, we introduced a new action for the sending of data to an antenna. An antenna can receive data of only
a single satellite at a time, an antenna is visible for only subsets of the satellites for certain time
periods, and the sending of an image takes time proportional to the size of the image. The time
windows were modelled using timed initial literals, and in the “-compiled” domain versions, these
literals were compiled into artificial PDDL constructs. None of the domain versions uses ADL
constructs, so of all versions there is only a single (STRIPS) formulation.
The instances were generated as follows. Our objectives were to clearly demonstrate the effect
of additional time windows, and to produce solvable instances only. To accomplish the former, we
re-used the IPC-3 instances, so that the only difference between, e.g., Time and Time-timewindows,
lies in the additional time window constructs. To ensure solvability, we implemented a tool that read
the plans produced by one of the IPC-3 participants, namely TLPlan, and then arranged the time
windows so that the input plan was suitable to solve the enriched instance. It is important to note
45. The page is available at http://rsise.anu.edu.au/∼thiebaux/benchmarks/pds
46. The probabilistic part of IPC-4 did not feature partially observable domains.
47. We have learned in the meantime that the lack of time windows for the gathering of data is also, or even more,
essential: often, due to occlusion by other objects or due to the rotation of the earth, targets are visible only during
very restricted periods of time. This probably constitutes one of the most important future directions for this domain.

528

E NGINEERING B ENCHMARKS

FOR

P LANNING

here that the time windows were not arranged to exactly meet the times extracted from the IPC-3
plan. Rather, we introduced one time window per each 5 “take-image” actions, made the antenna
visible during that time window for only the respective 5 satellites, and let the image size for each
individual image be a random value within a certain range where the time window was 5 times as
long as the sending time resulting from the maximum possible size.
Of course, the above generation process is arranged rather arbitrarily, and the resulting instances
might be a long way away from the typical characteristics of the Satellite problem as it occurs in
the real world. While this isn’t nice, it is the best we could do without inside knowledge of the
application domain, and it has the advantage that the enriched instances are solvable, and directly
comparable to the IPC-3 ones.
In the new domain versions derived from Complex, we also introduced utilities for the time
window inside which an image is sent to earth. For each image, the utility is either the same for all
windows, or it decreases monotonically with the start time of the window, or it is random within
a certain interval. Each image was put randomly into one of these classes, and the optimization
requirement is to minimize a linear combination of makespan, fuel usage, and summed up negated
image utility.
A.6 Settlers
The Settlers domain was introduced in IPC-3 by Long and Fox (2003). It makes extensive use of
numeric variables. These variables carry most of the domain semantics, which is about building up
an infrastructure in an unsettled area, involving the building of housing, railway tracks, sawmills,
etc. The domain was included into IPC-4 in order to pose a challenge for the numeric planners –
the other domains mostly do not make much use of numeric variables, other than computing the
(static) durations of actions.48 We used the exact same domain file and example instances as in
IPC-3, except that we removed some universally quantified preconditions to improve accessibility
for planners. The quantifiers ranged over domain constants only so they could easily be replaced by
conjunctions of atoms.
A.7 UMTS
Roman Englert has been working in this application area for several years. The domain was adapted
for IPC-4 by Stefan Edelkamp and Roman Englert.
A.7.1 A PPLICATION D OMAIN
Probably the best known feature of UMTS (Universal Mobile Telecommunication Standard) is
higher bit rate (Holma & Toskala, 2000): packet-switched connections can reach up to 2 mega
bit per second (Mbps) in the optimal case. Compared to existing mobile networks, UMTS provides
a new and important feature, namely the negotiation of Quality of Service (QoS) and of transfer
properties. The attributes that define the characteristics of the transfer are throughput, transfer delay, and data error rate. UMTS bearers have to be generic in order to provide good support for
existing applications and the evolution of new applications. Applications and services are divided
48. Note that, to some extent, this is just because the numeric values were abstracted away in the PDDL encoding,
mostly (in Airport and Pipesworld, c.f. Sections A.1.5 and A.2.5) in order to obtain a discrete encoding suitable for
PDDL2.2-style actions.

529

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

Class

Constraints

Examples

Conversational
Preserve time
relation between
information flow
on the stream.
Conversational
pattern (low delay)
Voice, video
telephony &
video games

Streaming
Preserve time
relation between
information
entities of the
stream

Interactive
Request response pattern.
Preserve data
integrity

Background
Undefined
delay.
Preserve
data
integrity

Streaming
multimedia

Web browsing,
network games

Background
download
of e-mails

Table 5: UMTS quality of service classes and their characteristics.
into four traffic classes by their QoS (TS23107, 2002; Holma & Toskala, 2000). The traffic classes,
their fundamental characteristics, and examples for applications are summarized in Table 5.
The main distinguishing factor between these classes is how delay-sensitive the traffic is: the
conversational class is very delay sensitive (approximately 40 ms time preservation), and the background class has no defined maximum delay.
The UMTS call set-up can be modularized using the perspective of Intelligent Software Agents
(Appleby & Steward, 1999; Busuioc, 1999), since agents are logical units and enable a discrete
perspective of the continuous signaling process. The call set-up is partitioned into the following
modules that are executed in sequential order (Englert, 2005):
TRM The initial step is the initiation of an application on the mobile and the determination of the
required resources for the execution. The resources of the mobile like display and memory are
checked by the Terminal Resource Management (TRM) and allocated, if possible. Otherwise,
the execution is aborted.
CT The wireless connection to the radio network is initiated via the dedicated control channel of
GSM (Holma & Toskala, 2000). In case of success, the transmission of ”Ready for service”
is transferred via the node B to the mobile in order to ensure the Connection Timing (CT) for
bearer service availability.
AM The information of the mobile like location and data handling capabilities is sent to the application server in the Internet (cf. AEEI). The transmission can be done comfortably by a
so-called service agent (Farjami, Görg, & Bell, 2000) that is controlled by the Agent Management (AM) in the CND. The advantage of a service agent is, that in case of failure, e.g.,
network resources are not sufficiently available, the agent can negotiate with the terminal’s
agent about another QoS class or different quality parameters.
AEEM A service agent with the required QoS class for the execution of the application and with
parameters of the mobile application is sent from the mobile’s Agent Execution Environment
Mobile (AEEM) to the application server in the Internet (cf. AEEI).
RRC The Radio Resource Controller (RRC) provisions/allocates the required QoS by logical resources from the MAC level in the radio bearer (Holma & Toskala, 2000).
530

E NGINEERING B ENCHMARKS

FOR

P LANNING

RAB Then, the bearer resources are supplied on the physical level from the Radio Access Bearer
(RAB) from the CND and the call flow is set-up by mapping the logical QoS parameters and
the physical QoS resources together.
AEEI The Agent Execution Environment Internet (AEEI) establishes the data transfer from the
core network to a PDN (e.g., Internet) and sends a service agent (controlled by AM) to the
application in the PDN in order to ensure the QoS for the application.
BS Finally, the Bearer Service (BS) for the execution of the mobile application is established with
the required radio bearer resources with QoS. Messages are sent to the modules TRM and
AEEI to start the execution of the application.
These modules are executed in sequential order to set-up a call for the execution of mobile
applications. Two modules (AEEM and AEEI) have to be executed in time windows in order to
ensure that the agents are life in the network. However, two constraints have been added: First, the
intra-application constraint, where modules from one application are ordered. Second, the interapplication constraint, where modules with same names from different applications cannot be executed in parallel in order to ensure that the required resources are available.
A.7.2 IPC-4 PDDL A DAPTATION
Besides action duration, the domain encodes scheduling types of resources49 , consuming some
amount at action initialization time and releasing the same amount at action ending time. Scheduling
types of resources have not been used in planning benchmarks before, and the good news is that
temporal PDDL2.1 (Level 3) is capable of expressing them. In fact we used a similar encoding to
the one that we found for Job- and Flow-Shop problems. As one feature, actions are defined to
temporarily produce rather than to temporarily consume resources. As current PDDL has no way
of stating such resource constraints explicitly, planners that want to exploit that knowledge have to
look for a certain patterns of increase/decrease effects to recognize them. Additionally, the resource
modeling of our UMTS adaptation is constrained to the most important parameters (in total 15). In
real networks several hundred parameters are applied.
In UMTS, two subsequent actions can both check and update the value of some resources (e.g.,
has-mobile-cpu) at their starting (resp. ending) time points as far as the start (resp. ending) events
are separated by  time steps, where  is minimum slack time required between two dependent
events. When modeling renewable resources with an over all construct the invariant condition of
the action has to check, what the at start event did change. We decided that this is not the best choice
for a proper temporal action. Consequently, the temporal actions require resources to be available
before adding the amount used.
Finally, the time windows for the two agent-based modules are defined using the average execution times of the modules. The average times are estimated based on signaling durations of the
UMTS network (Holma & Toskala, 2000).
Resources may be renewable or consumable: an example for a renewable resource is the keyboard of the mobile. It can be used to input data for several applications. Consumable resources are
49. The terminology for resources in planning and scheduling varies. In job-shop scheduling, a machine is resource,
while in planning such a machine would be a domain object. In PDDL, renewable and consumable resources are
both modeled using numerical fluents and are not per se distinguished.

531

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

mobile-cpu
d-available
e-balance
mobile-channels
-available
num-mobiles
num-calls
mobile-storage
logical-channels
cell-update
handover
active-set-up
ggsn-bitrate
max-no-pdp
max-no-apn

used with x per cent per application
partition of the display, e.g., ticker and chess
energy balance of mobile accumulator
used for data transfer
number of mobiles which are tractable
by a node B
mobile network load for a node B
memory on S(IM)AT card
number of logical channels available in the CN
report UE location into RNC
handover required to get a higher bit rate
update connection
capacity (kbit/s) from GGSN to PDN
max. no. of packet data protocols per mobile
max. access point names (APN) per mobile

Table 6: Scheduling types of resources in the UMTS call set-up.
released after action execution. The resources that are realized in the experiments are summarized
in Table 6 (see 3GPP, 2004 for a complete list of resources for the UMTS call set-up).
The PDDL representation of the planning domain is based on the eight modules for the UMTS
call set-up. There are eight operators corresponding to these eight modules. Let us consider, as an
example, the BS action, that is, the final action that can be used to establish the predicate bs-ok.
It is defined as follows:
(:durative-action BS
:parameters
(?A-new - application ?M - mobile ?L - list ?MS1 ?MS2 - message ?a - agent)
:duration
(= ?duration (time-bs ?A-new))
:condition
(and (at start (initiated ?A-new ?M))
(at start (aeei-ok ?A-new ?M ?L ?a))
(at start (qos-params ?A-new ?L))
(at start (message-trm ?M ?MS1))
(at start (message-aeei ?A-new ?MS2)))
:effect
(and (at end (iu-bearer ?A-new ?M ?L)) (at end (bs-ok ?A-new ?M ?L ?a)))))

The action has as preconditions the successful execution of the module AEEI during the call
set-up, the satisfaction of the required QoS class parameters (denoted as list L), and the transfered
messages of the set-up status to the application in the mobile and the PDN. The resources are already
allocated by the preceding modules. As effect the bearer and the network connection for the mobile
application are set up.
532

E NGINEERING B ENCHMARKS

FOR

P LANNING

The initiation of an application starts in the mobile with the TRM. Afterwards, the CT in the
AND is asked for a ready-for-service signal. In the core of the call set-up is the radio access bearer
procedure in the CND. Let us consider the latter in more detail. As first step the logical resources
must be allocated (RRC), e.g., the required number of channels must be provided by the logical
level in the radio bearer and later these logical resources are mapped to the physical channels. The
PDDL RRC action looks as follows:
(:durative-action RRC
:parameters
(?A-new - application ?M - mobile ?L - list ?a - agent)
:duration
(= ?duration (time-rrc ?A-new))
:condition
(and (at start (ct-ok ?A-new ?M ?L))
(at start (aeem-ok ?A-new ?M ?L ?a))
(at start (<= (has-logical-channels)
(- (max-logical-channels) (app-channels ?A-new ?m))))
(at start (<= (has-cell-update) (- (max-cell-update) 2)))
(at start (< (has-handover) (max-handover)))
(at start (< (has-active-set-up) (max-active-set-up))))
:effect
(and (at start (increase (has-logical-channels) (app-channels ?A-new ?M)))
(at end (decrease (has-logical-channels) (app-channels ?A-new ?M)))
(at start (increase (has-cell-update) 2))
(at end (decrease (has-cell-update) 2))
(at start (increase (has-handover) 1))
(at end (decrease (has-handover) 1))
(at start (increase (has-active-set-up) 1))
(at end (decrease (has-active-set-up) 1))
(at end (rrc-ok ?A-new ?M ?L ?a))))

If the requested QoS class is not available, then the fact rab-ok is not true and a service
agent must be sent to the mobile in order to negotiate with the application or user for weaker QoS
requirements. In case of success the predicate rab-ok is true and the connection to the PDN must
be checked. Finally, the goal predicate BS can be fulfilled if all resources are available.
A.7.3 IPC-4 D OMAIN S TRUCTURE
As used in IPC-4, the UMTS domain has six versions. The first three are: temporal, a domain
version with no timing constraints, temporal-timewindows, a domain version with PDDL2.2 timed
initial facts, and temporal-timewindows-compiled, a domain version with a PDDL2.1 wrapper encoding for the timed initial literals. The second domain version set flaw-temporal, flaw-temporaltimewindows, and flaw-temporal-timewindows-compiled, includes the following “flaw” action:
(:durative-action FLAW
parameters
(?A-new - application ?M - mobile ?L - list ?a - agent)
:duration (= ?duration 4)
:condition
533

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

version
temporal
temporal-tw
temporal-twc
flaw-temporal
flaw-temporal-tw
flaw-temporal-twc

formulation
STRIPS-TEMPORAL
STRIPS-TEMPORAL-TW
STRIPS-TEMPORAL
STRIPS-TEMPORAL
STRIPS-TEMPORAL-TW
STRIPS-TEMPORAL

max-#op
8
8
13
9
9
14

max-#act
(5120) 80
(5120) 80
(5125) 85
(5310) 90
(5310) 90
(5315) 95

Table 7: Overview over the different domain versions of UMTS. Abbreviations used: “temporaltw” for “temporal-timewindows”, “temporal-twc” for temporal-timewindows-compiled;
max-#op is the maximum number of (parameterized) PDDL operators for any instance,
max-#act is the maximum number of ground actions for any instance. Data in parentheses are collected before FF’s “reachability” pre-process (see text).

(and (at start (initiated ?A-new ?M))
(at start (qos-params ?A-new ?L))
(at start (trm-ok ?A-new ?M ?L)))
:effect
(and (at end (rab-ok ?A-new ?M ?L ?a))
(at start (not (initiated ?A-new ?M)))))

This action offers a shortcut to the rab-ok predicate, but can not be used in a real solution
because it deletes the initiated predicate. But the action can be used in heuristic functions
based on ignoring the negative effects. In that sense, the action encodes a flaw that may disturb
the heuristic techniques used in modern planners. To determine that the action is not useful, negative interactions have to be considered. The idea of flaw is practically motivated in order to see
how heuristic planners react to it. In its standard form, the domain is not a big challenge to such
planners, as we have seen in Section 5. All domain versions have one formulation, namely stripsfluents-temporal, where numerical fluents, but - except typing - no ADL constructs are used. In all
instances, the plan objective is to minimize makespan.
The domain versions and numbers of operators and ground actions are overviewed in Table 7. As
with many of the empirical data for UMTS that we have seen before, the data are quite exceptional,
and at the same time easy to interpret. First, similar to what we have seen in Section 5.3, the data
are actually constant across all instances within each domain version, which is once again due to the
fact that the instances scale only in their specification of what applications need actually be started.
Second, the numbers of operators and actions do not differ between the versions with and without
time windows; they increase somewhat, through the additional artificial actions, if we compile
timed initial literals away (c.f. Section 2); they also increase somewhat, of course, if we introduce
the “flaw” action. Third, the most striking observation is the huge effect of FF’s reachability preprocessor, building a relaxed planning graph for the initial state and removing all actions that do not
appear in that graph. This is due to the technical subtleties of the encoding, where the restrictions
on feasible action instantiations are, partly, implicit in the possible action sequences, rather than
explicit in the static predicates.

534

E NGINEERING B ENCHMARKS

FOR

P LANNING

A.7.4 IPC-4 E XAMPLE I NSTANCES
The UMTS call set-up domain has the following challenges for the planning task (Englert & Cremers, 2001):
Real-time: Can plans for the execution of mobile applications be generated in an appropriate time?
Planning has to be done with a maximum duration that does not exceed the UMTS call set-up
time.
Completeness: Is it possible to generate the plan, i.e. does planning result in an (optimal) plan for
the required applications that minimizes the waiting period until all applications are started?
The PDDL structure of the basic problem for the discrete UMTS call set-up (DUCS) domain is
the following:
(define (problem DUCS DOMAIN BASIC VERSION)
(:domain DUCS DOMAIN BASIC VERSION
(:objects MS1 MS2 - message
A1 A2 A3 A4 A5 A6 A7 A8 A9 A10 - application
M1 M2 M3 M4 M5 M6 M7 M8 M9 M10 - mobile
L1 L2 L3 L4 L5 L6 L7 L8 L9 L10 - list
ae - agent)
(:init (= (time-trm A1) 76) (= (time-ct A1) 48)
(= (time-am A1) 74) (= (time-aeem A1) 66)
(= (time-rrc A1) 202) (= (time-rab A1) 67)
(= (time-aeei A1) 36) (= (time-bs A1) 28)
[...]
(location M1) ;; types
(authentification M1)
[...]
(= (has-mobile-cpu) 0) ;; current status
[...] )
(:goal (and (bs-ok A1 M1 L1 ae) [...] )))

First in this PDDL description come the objects for the applications and the mobiles. Then
come the durations of the modules depending on the applications, e.g., the module TRM requires
less time for a news ticker than for a chess game, since the latter requires more terminal resources
than the ticker. The current status of the resources is initialized. Finally, the goal is defined: the
bearer establishment for the execution start of the initiated mobile applications. The total execution
time should be minimized.
For IPC-4 the time windows are varied with small perturbations in order to generate different
instances. The perturbations are motivated by the average execution times of the modules in a radio
network according to the load. Furthermore, the number of applications to be set up is varied from 1
up to 10. The domains assume that the applications run on one mobile terminal. However, they can
also be distributed to several mobile terminals. There are 50 different instances per domain version.
A.7.5 F UTURE W ORK
The UMTS domain is not a big challenge for modern heuristic, i.e. HSP/FF/LPG-style, planners
because these planners are satisficing (potentially return sub-optimal plans). The objective in UMTS
535

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

is to minimize the execution time, and if one ignores that objective then the task trivializes. To
the optimal planners, UMTS is a realistic challenge. The domain is already relatively realistically
modelled, except for the left-out additional constraints on the (many) less important resources. It
remains to be seen if, when introducing all these resources, planner (in particular optimal planner)
performance gets degraded. An option in this case may be to introduce explicit language constructs
for the different types (renewable and consumable) of resources.
In the future the following two challenges shall be investigated. First, the negotiation of UMTS
Quality of Service (QoS) parameters could be considered. Assume a video application on a mobile
terminal is initiated, but the bearer resources are not sufficiently available. Then the QoS has to be
negotiated between the terminal and the bearer. This leads to the planning of a negotiation during
the plan execution for the already initiated applications.
Second, the approach for the optimization of the UMTS call set-up can be applied to the Wireless
LAN registration. The challenge is to transfer the QoS parameters, since the current Wireless LAN
standard (802.11b) does not contain QoS. This demerit can be solved by applying an additional
service level that addresses QoS.

References
3GPP (2004). 3G Partnership Project, www.3gpp.org.
Appleby, S., & Steward, T. (1999). Mobile Software Agents for Control in Telecommunication
Networks, chap. 11 in Hayzelden, A./Bigham, J. (eds.), Software Agents for Future Telecommunication Systems. Springer.
Apt, K., Blair, H., & Walker, A. (1988). Towards a theory of declarative knowledge. In Foundations
of Deductive Databases and Logic Programming, pp. 89–148. Morgan Kaufmann.
Bacchus, F., & Kabanza, F. (2000). Using temporal logics to express search control knowledge for
planning. Artificial Intelligence, 116, 123–191.
Bacchus, F. (2000). Subset of PDDL for the AIPS2000 Planning Competition. The AIPS-00 Planning Competition Comitee. Available at http://www.cs.toronto.edu/aips2000/pddl-subset.ps.
Bacchus, F. (2001). The AIPS’00 planning competition. The AI Magazine, 22(3), 47–56.
Bertoli, P., Cimatti, A., Roveri, M., & Traverso, P. (2001). Planning in nondeterministic domains
under partial observability via symbolic model checking.. In Nebel (Nebel, 2001).
Bertoli, P., Cimatti, A., Slaney, J., & Thiébaux, S. (2002). Solving power supply restoration problems with planning via symbolic model checking. In Proceedings of the 15th European
Conference on Artificial Intelligence (ECAI-02), pp. 576–80, Lyon, France. Wiley.
Biundo, S., Myers, K., & Rajan, K. (Eds.)., ICAPS-05 (2005). Proceedings of the 15th International Conference on Automated Planning and Scheduling (ICAPS-05), Monterey, CA, USA.
Morgan Kaufmann.
Bloem, R., Ravi, K., & Somenzi, F. (2000). Symbolic guided search for CTL model checking. In
Conference on Design Automation (DAC), pp. 29–34.
Blum, A. L., & Furst, M. L. (1997). Fast planning through planning graph analysis. Artificial
Intelligence, 90(1-2), 279–298.

536

E NGINEERING B ENCHMARKS

FOR

P LANNING

Boddy, M., Gohde, J., Haigh, T., & Harp, S. (2005). Course of action generation for cyber security
using classical planning.. In Biundo et al. (Biundo, Myers, & Rajan, 2005), pp. 12–21.
Bonet, B., & Geffner, H. (2001). Planning as heuristic search. Artificial Intelligence, 129(1–2),
5–33.
Bonet, B., Loerincs, G., & Geffner, H. (1997). A robust and fast action selection mechanism for
planning. In Proceedings of the 14th National Conference of the American Association for
Artificial Intelligence (AAAI-97), pp. 714–719. MIT Press.
Bonet, B., & Thiébaux, S. (2003). GPT meets PSR. In Giunchiglia, E., Muscettola, N., & Nau,
D. (Eds.), Proceedings of the 13th International Conference on Automated Planning and
Scheduling (ICAPS-03), pp. 102–111, Trento, Italy. Morgan Kaufmann.
Busuioc, M. (1999). Distributed Intelligent Agents - A Solution for the Management of Complex
Telecommunications Services, chap. 4 in Hayzelden, A./Bigham, J. (eds.), Software Agents
for Future Telecommunication Systems. Springer.
Bylander, T. (1994). The computational complexity of propositional STRIPS planning. Artificial
Intelligence, 69(1–2), 165–204.
Cesta, A., & Borrajo, D. (Eds.). (2001). Recent Advances in AI Planning. 6th European Conference
on Planning (ECP’01), Toledo, Spain. Springer-Verlag.
Chen, Y., Hsu, C., & Wah, B. (2004). SGPlan: Subgoal partitioning and resolution in planning.
In Edelkamp, S., Hoffmann, J., Littman, M., & Younes, H. (Eds.), Proceedings of the 4th
International Planning Competition, Whistler, BC, Canada. JPL.
Chien, S., Kambhampati, R., & Knoblock, C. (Eds.)., AIPS-00 (2000). Proceedings of the 5th
International Conference on Artificial Intelligence Planning Systems (AIPS-00). AAAI Press,
Menlo Park.
Cimatti, A., Roveri, M., & Traverso, P. (1998). Automatic OBDD-based generation of universal
plans in non-deterministic domains. In Proceedings of the 15th National Conference of the
American Association for Artificial Intelligence (AAAI-98), pp. 875–881, Madison, WI. MIT
Press.
Clarke, E. M., Grumberg, O., & Peled, D. A. (1999). Model Checking. MIT Press.
Dierks, H. (2005). Finding optimal plans for domains with restricted continuous effects with uppaal cora. In ICAPS Workshop on Verification and Validation of Model-Based Planning and
Scheduling Systems.
Edelkamp, S. (2003a). Promela planning. In Workshop on Model Checking Software (SPIN), Lecture Notes in Computer Science, pp. 197–212. Springer.
Edelkamp, S. (2003b). Taming numbers and durations in the model checking integrated planning
system. Journal of Artificial Intelligence Research, 20, 195–238.
Edelkamp, S., & Jabbar, S. (2005). Action planning for directed model checking of Petri nets.
Electronic Notes in Theoretical Computer Science, 149(2), 3–18.
Edelkamp, S., Jabbar, S., & Lluch-Lafuente, A. (2005). Action planning for graph transition systems. In ICAPS Workshop on Verification and Validation of Model-Based Planning and
Scheduling Systems, pp. 48–57.
537

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

Edelkamp, S., Leue, S., & Lluch-Lafuente, A. (2004). Directed explicit-state model checking in the
validation of communication protocols. International Journal on Software Tools for Technology, 5, 247 – 267.
Englert, R. (2005). Planning to optimize the UMTS call set-up for the execution of mobile applications. Int. Journal of Applied Artificial Intelligence, 19(2), 99–117.
Englert, R., & Cremers, A. B. (2001). Configuration of Applications for the 3rd Generation Mobile
Communication. In KI Workshop on AI in Planning, Scheduling, Configuration and Design
(PUK). Vienna, Austria.
Farjami, P., Görg, C., & Bell, F. (2000). Advanced service provisioning based on mobile agents.
Computer Communications, 23, 754 – 760.
Fikes, R. E., & Nilsson, N. (1971). STRIPS: A new approach to the application of theorem proving
to problem solving. Artificial Intelligence, 2, 189–208.
Fourman, M. P. (2000). Propositional planning. In AIPS Workshop on Model-Theoretic Approaches
to Planning.
Fox, M., Long, D., & Halsey, K. (2004). An investigation into the expressive power of PDDL2.1.
In Saitta, L. (Ed.), Proceedings of the 16th European Conference on Artificial Intelligence
(ECAI-04), Valencia, Spain. Wiley.
Fox, M., & Long, D. (1999). The detection and exploitation of symmetry in planning problems.
In Pollack, M. (Ed.), Proceedings of the 16th International Joint Conference on Artificial
Intelligence (IJCAI-99), pp. 956–961, Stockholm, Sweden. Morgan Kaufmann.
Fox, M., & Long, D. (2003). PDDL2.1: An extension to PDDL for expressing temporal planning
domains. Journal of Artificial Intelligence Research, 20, 61–124.
Frank, J., Cheeseman, P., & Stutz, J. (1997). When gravity fails: Local search topology. Journal of
Artificial Intelligence Research, 7, 249–281.
Garagnani, M. (2000). A correct algorithm for efficient planning with preprocessed domain axioms.
In Research and Development in Intelligent Systems XVII. Springer-Verlag.
Gazen, B. C., & Knoblock, C. (1997). Combining the expressiveness of UCPOP with the efficiency
of Graphplan.. In Steel, & Alami (Steel & Alami, 1997), pp. 221–233.
Gerevini, A., & Long, D. (2005). Plan Constraints and Preferences. The AIPS-06 Planning Competition Comitee. Available at http://zeus.ing.unibs.it/ipc-5/pddl-ipc5.pdf.
Gerevini, A., Saetti, A., & Serina, I. (2006). An approach to temporal planning and scheduling in
domains with predictable exogenous events. Journal of Artificial Intelligence Research, 25,
187–231.
Giunchiglia, F., & Traverso, P. (1999). Planning as model checking. In Biundo, S., & Fox, M.
(Eds.), Recent Advances in AI Planning. 5th European Conference on Planning (ECP’99),
Lecture Notes in Artificial Intelligence, pp. 1–19, Durham, UK. Springer-Verlag.
Haslum, P., & Geffner, H. (2001). Heuristic planning with time and resources.. In Cesta, & Borrajo
(Cesta & Borrajo, 2001), pp. 121–132.
Hatzack, W. (2002). Entwicklung und Auswertung von Algorithmen zur autonomen Verkehrskoordinierung und Konfliktauflsung an Flughfen. Ph.D. thesis, University of Freiburg, Freiburg,
Germany.
538

E NGINEERING B ENCHMARKS

FOR

P LANNING

Hatzack, W., & Nebel, B. (2001). The operational traffic control problem: Computational complexity and solutions.. In Cesta, & Borrajo (Cesta & Borrajo, 2001), pp. 49–60.
Helmert, M. (2003). Complexity results for standard benchmark domains in planning. Artificial
Intelligence, 143, 219–262.
Helmert, M. (2004). A planning heuristic based on causal graph analysis.. In Koenig et al. (Koenig,
Zilberstein, & Koehler, 2004), pp. 161–170.
Helmert, M. (2005) Personal communication.
Helmert, M. (2006a). The fast downward planning system. Journal of Artificial Intelligence Research, 26. Accepted for Publication.
Helmert, M. (2006b). New complexity results for classical planning benchmarks. In Long, D., &
Smith, S. (Eds.), Proceedings of the 16th International Conference on Automated Planning
and Scheduling (ICAPS-06), pp. 52–61, The English Lake District, UK. Morgan Kaufmann.
Hoffmann, J. (2001). Local search topology in planning benchmarks: An empirical analysis.. In
Nebel (Nebel, 2001), pp. 453–458.
Hoffmann, J. (2002). Local search topology in planning benchmarks: A theoretical analysis. In
Ghallab, M., Hertzberg, J., & Traverso, P. (Eds.), Proceedings of the 6th International Conference on Artificial Intelligence Planning and Scheduling (AIPS-02), pp. 92–100, Toulouse,
France. Morgan Kaufmann.
Hoffmann, J. (2003). The Metric-FF planning system: Translating “ignoring delete lists” to numeric
state variables. Journal of Artificial Intelligence Research, 20, 291–341.
Hoffmann, J. (2005). Where ‘ignoring delete lists’ works: Local search topology in planning benchmarks. Journal of Artificial Intelligence Research, 24, 685–758.
Hoffmann, J., & Edelkamp, S. (2005). The deterministic part of IPC-4: An overview. Journal of
Artificial Intelligence Research, 24, 519–579.
Hoffmann, J., & Nebel, B. (2001). The FF planning system: Fast plan generation through heuristic
search. Journal of Artificial Intelligence Research, 14, 253–302.
Hölldobler, S., & Stör, H.-P. (2000). Solving the entailment problem in the fluent calculus using
binary decision diagrams. In ICAPS Workshop on Model-Theoretic Approaches to Planning.
Holma, H., & Toskala, A. (2000). WCDMA for UMTS - Radio Access for 3rd Generation Mobile
Communications. Wiley & Sons.
Holzmann, G. (2003). The Spin Model Checker - Primer and Reference Manual. Addison-Wesley.
Holzmann, G. J. (1990). Design and Validation of Computer Protocols. Prentice Hall.
Howe, A., & Dahlman, E. (2002). A critical assessment of benchmark comparison in planning.
Journal of Artificial Intelligence Research, 17, 1–33.
Kabanza, F., & Thiébaux, S. (2005). Search control in planning for temporally extended goals.. In
Biundo et al. (Biundo et al., 2005), pp. 130–139.
Koehler, J., & Hoffmann, J. (2000). On the instantiation of ADL operators involving arbitrary
first-order formulas. In ECAI Workshop on New Results in Planning, Scheduling and Design.

539

H OFFMANN , E DELKAMP, T HI ÉBAUX , E NGLERT, L IPORACE & T R ÜG

Koehler, J., Nebel, B., Hoffmann, J., & Dimopoulos, Y. (1997). Extending planning graphs to an
ADL subset.. In Steel, & Alami (Steel & Alami, 1997), pp. 273–285.
Koehler, J., & Schuster, K. (2000). Elevator control as a planning problem.. In Chien et al. (Chien,
Kambhampati, & Knoblock, 2000), pp. 331–338.
Koenig, S., Zilberstein, S., & Koehler, J. (Eds.)., ICAPS-04 (2004). Proceedings of the 14th International Conference on Automated Planning and Scheduling (ICAPS-04), Whistler, Canada.
Morgan Kaufmann.
Korf, R. E. (1990). Real-time heuristic search. Artificial Intelligence, 42, 189–211.
Kvarnström, J., Doherty, P., & Haslum, P. (2000). Extending TALplanner with concurrency and
ressources. In Horn, W. (Ed.), Proceedings of the 14th European Conference on Artificial
Intelligence (ECAI-00), pp. 501–505, Berlin, Germany. Wiley.
Lago, U. D., Pistore, M., & Traverso, P. (2002). Planning with a language for extended goals.
In Proceedings of the 18th National Conference of the American Association for Artificial
Intelligence (AAAI-02), pp. 447–454, Edmonton, AL. MIT Press.
Long, D., & Fox, M. (2000). Automatic synthesis and use of generic types in planning.. In Chien
et al. (Chien et al., 2000), pp. 196–205.
Long, D., & Fox, M. (2003). The 3rd international planning competition: Results and analysis.
Journal of Artificial Intelligence Research, 20, 1–59.
McDermott, D. (1996). A heuristic estimator for means-ends analysis in planning. In Proceedings
of the 3rd International Conference on Artificial Intelligence Planning Systems (AIPS-96),
pp. 142–149. AAAI Press, Menlo Park.
McDermott, D. (1998). The PDDL Planning Domain Definition Language. The AIPS-98 Planning Competition Comitee. Available at http://ls5-www.cs.uni-dortmund.de/ edelkamp/ipc4/DOCS/pddl.ps.gz.
McDermott, D. (2000). The 1998 AI planning systems competition. The AI Magazine, 21(2), 35–55.
McDermott, D. V. (1999). Using regression-match graphs to control search in planning. Artificial
Intelligence, 109(1-2), 111–159.
Milidiú, R. L., & dos Santos Liporace, F. (2004a). Plumber, a pipeline transportation planner. In
International Workshop on Harbour and Maritime Simulation (HMS), pp. 99–106, Rio de
Janeiro, Brazil.
Milidiú, R. L., & dos Santos Liporace, F. (2004b). Pipesworld: Applying planning systems to
pipeline transportation. In Proceedings of the International Pipeline Conference (IPC), pp.
713–719.
Nebel, B. (Ed.)., IJCAI-01 (2001). Proceedings of the 17th International Joint Conference on Artificial Intelligence (IJCAI-01), Seattle, Washington, USA. Morgan Kaufmann.
Nebel, B. (2000). On the compilability and expressive power of propositional planning formalisms.
Journal of Artificial Intelligence Research, 12, 271–315.
Pednault, E. P. (1989). ADL: Exploring the middle ground between STRIPS and the situation
calculus. In Brachman, R., Levesque, H. J., & Reiter, R. (Eds.), Principles of Knowledge
Representation and Reasoning: Proceedings of the 1st International Conference (KR-89), pp.
324–331, Toronto, ON. Morgan Kaufmann.
540

E NGINEERING B ENCHMARKS

FOR

P LANNING

Reffel, F., & Edelkamp, S. (1999). Error detection with directed symbolic model checking. In World
Congress on Formal Methods (FM), pp. 195–211.
Rintanen, J. (2004). Phase transitions in classical planning: An experimental study.. In Koenig et al.
(Koenig et al., 2004), pp. 101–110.
Ruml, W., Do, M., & Fromherz, M. (2005). On-line planning and scheduling for high-speed manufacturing.. In Biundo et al. (Biundo et al., 2005), pp. 30–39.
Steel, S., & Alami, R. (Eds.). (1997). Recent Advances in AI Planning. 4th European Conference on
Planning (ECP’97), Vol. 1348 of Lecture Notes in Artificial Intelligence, Toulouse, France.
Springer-Verlag.
Thiébaux, S., & Cordier, M.-O. (2001). Supply restoration in power distribution systems — a
benchmark for planning under uncertainty.. In Cesta, & Borrajo (Cesta & Borrajo, 2001), pp.
85–95.
Thiébaux, S., Cordier, M.-O., Jehl, O., & Krivine, J.-P. (1996). Supply restoration in power distribution systems — a case study in integrating model-based diagnosis and repair planning.
In Horvitz, E., & Jensen, F. V. (Eds.), Proceedings of the 12th International Conference on
Uncertainty in AI (UAI-96), pp. 525–532, Portland, Oregon, USA. Morgan Kaufmann.
Thiébaux, S., Hoffmann, J., & Nebel, B. (2003). In defense of PDDL axioms.. In Gottlob, G. (Ed.),
Proceedings of the 18th International Joint Conference on Artificial Intelligence (IJCAI-03),
pp. 961–966, Acapulco, Mexico. Morgan Kaufmann.
Thiébaux, S., Hoffmann, J., & Nebel, B. (2005). In defense of PDDL axioms. Artificial Intelligence,
168(1–2), 38–69.
TS23107 (2002). 3rd Generation Partnership Project: Technical Specification Group Service and
System Aspects: QoS Concept and Architecture (Release 5), TS 23.107, V5.3.0, 3GPP.
Vidal, V. (2004). A lookahead strategy for heuristic search planning.. In Koenig et al. (Koenig et al.,
2004), pp. 150–160.
Wah, B., & Chen, Y. (2004). Subgoal partitioning and global search for solving temporal planning
problems in mixed space. International Journal of Artificial Intelligence Tools, 13(4), 767–
790.
Yang, C. H., & Dill, D. L. (1998). Validation with guided search of the state space. In Conference
on Design Automation (DAC), pp. 599–604.
Younes, H., Littman, M., Weissman, D., & Asmuth, J. (2005). The first probabilistic track of the
international planning competition. Journal of Artificial Intelligence Research, 24, 851–88.

541

Journal of Artificial Intelligence Research 26 (2006) 289-322

Submitted 10/04; published 07/06

Breaking Instance-Independent Symmetries
in Exact Graph Coloring
Arathi Ramani
Igor L. Markov
Karem A. Sakallah

ramania@umich.edu
imarkov@eecs.umich.edu
karem@eecs.umich.edu

Department of Electrical Engineering and Computer Science
University of Michigan, Ann Arbor, USA

Fadi A. Aloul

faloul@umich.edu

Department of Computer Engineering
American University in Sharjah, UAE

Abstract
Code optimization and high level synthesis can be posed as constraint satisfaction and
optimization problems, such as graph coloring used in register allocation. Graph coloring is
also used to model more traditional CSPs relevant to AI, such as planning, time-tabling and
scheduling. Provably optimal solutions may be desirable for commercial and defense applications. Additionally, for applications such as register allocation and code optimization,
naturally-occurring instances of graph coloring are often small and can be solved optimally.
A recent wave of improvements in algorithms for Boolean satisfiability (SAT) and 0-1 Integer Linear Programming (ILP) suggests generic problem-reduction methods, rather than
problem-specific heuristics, because (1) heuristics may be upset by new constraints, (2)
heuristics tend to ignore structure, and (3) many relevant problems are provably inapproximable.
Problem reductions often lead to highly symmetric SAT instances, and symmetries are
known to slow down SAT solvers. In this work, we compare several avenues for symmetry breaking, in particular when certain kinds of symmetry are present in all generated
instances. Our focus on reducing CSPs to SAT allows us to leverage recent dramatic
improvement in SAT solvers and automatically benefit from future progress. We can
use a variety of black-box SAT solvers without modifying their source code because our
symmetry-breaking techniques are static, i.e., we detect symmetries and add symmetry
breaking predicates (SBPs) during pre-processing.
An important result of our work is that among the types of instance-independent SBPs
we studied and their combinations, the simplest and least complete constructions are the
most effective. Our experiments also clearly indicate that instance-independent symmetries
should mostly be processed together with instance-specific symmetries rather than at the
specification level, contrary to what has been suggested in the literature.

1. Introduction
Detecting and using problem structure, such as symmetries, can often be very useful in
accelerating the search for solutions of constraint satisfaction problems (CSPs). This is
particularly true for algorithms which perform exhaustive searches and benefit from pruning the search tree. This work conducts a theoretical and empirical study of the impact of
breaking structural symmetries in 0-1 ILP reductions of the exact graph coloring problem
c
2006
AI Access Foundation. All rights reserved.

Ramani, Aloul, Markov, & Sakallah

which has applications in a number of fields. For example, in compiler design, many techniques for code optimization and high-level synthesis operate with relatively few objects at
a time. Graph coloring used for register allocation during program compilation (Chaitin,
Auslander, Chandra, Cocke, Hopkins, & Markstein, 1981) is limited by small numbers of
registers in embedded processors as well as by the number of local variables and virtual
registers. Graph coloring is also relevant to AI applications such as planning, scheduling,
and map coloring. Recent work on graph coloring in AI has included algorithms based on
neural networks (Jagota, 1996), evolutionary algorithms (Galinier & Hao, 1999), scatter
search (J.-P. Hamiez, 2001) and several other approaches discussed in Section 2. While
many of these search procedures are heuristic, our work focuses on exact graph coloring,
which is closely related to several useful combinatorial problems such as maximal independent set and vertex cover. We seek provably optimal solutions because they may be
desirable in commercial and defense applications for competitive reasons, and can often be
found. Our work focuses on solving exact graph coloring by reduction to 0-1 ILP. While
the idea of solving N P − complete problems by reduction is well-known, it is rarely used in
practice because algorithms developed for “standard” problems, such as SAT, may not be
competitive with domain-specific techniques that are aware of problem structure. However,
many applications imply problem-specific constraints and non-trivial objective functions.
These extensions may upset heuristics for standard problems. Heuristics, particularly those
based on local search, often fail to use structure in problem instances (Prestwich, 2002)
and are inefficient when used with problem reductions. In contrast, exact solvers based on
branch-and-bound and back-tracking tend to adapt to new constraints and can be applied
through problem reduction. There is a growing literature on handling structure in optimal
solvers (Aloul, Ramani, Markov, & Sakallah, 2003; Crawford, Ginsberg, Luks, & Roy, 1996;
Huang & Darwiche, 2003), and our work falls into this category as well.
The NP-spec project (Cadoli, Palopoli, Schaerf, & Vasileet, 1999) offers a framework
for formulating a wide range of combinatorial problems and automatically reducing their
instances to instances of Boolean satisfiability. This approach is attractive because it circumvents problem-specific solvers and leverages recent breakthroughs in Boolean satisfiability
(Moskewicz, Madigan, Zhao, Zhang, & Malik, 2001). However, this approach remains unexplored in practice, possibly because the efficiency of problem-solving may be reduced when
domain-specific structure is lost during problem reductions. This drawback is addressed
by recent work on the detection of structure, particularly symmetry, in SAT and 0-1 ILP
instances in order to accelerate exact solvers (Crawford et al., 1996; Aloul et al., 2003;
Aloul, Ramani, Markov, & Sakallah, 2004). In these papers, symmetries in a SAT/0-1
ILP instance are detected by reduction to graph automorphism, i.e. the formula is represented by a graph and the automorphism problem for that graph is solved using graph
automorphism software packages (McKay, 1990; Darga, Liffiton, Sakallah, & Markov, 2004).
Until recently, this type of symmetry detection was frequently inefficient because solving
the automorphism problem for large graphs can be time-consuming. However, more recent automorphism software (Darga et al., 2004) has removed this bottleneck to a large
extent. Moreover, adding simple symmetry breaking predicates as new constraints significantly speeds up exact SAT solvers (Aloul et al., 2003). This work can be viewed as a case
study of symmetry breaking in problem reductions, as we focus on graph coloring and its
variants that can be reduced to Boolean satisfiability and 0-1 ILP. Our main goals are to (i)
290

Breaking Instance-Independent Symmetries in Exact Graph Coloring

accelerate optimal solving of graph coloring instances, and (ii) compare different strategies
for breaking instance-independent symmetries. There are two distinct sources of symmetries
in graph-coloring instances: (i) colors can be arbitrarily permuted (instance-independent
symmetries), and (ii) some graphs may be invariant under certain permutations of vertices
(instance-dependent symmetries). Previous work (Crawford et al., 1996; Aloul et al., 2003,
2004) deals only with instance-dependent symmetries in SAT and 0-1 ILP instances. Symmetries are first detected by reduction to graph automorphism and then broken by adding
symmetry breaking predicates (SBPs) to the formulation. The advantage of such a strategy is that every instance-independent symmetry is also instance-dependent, whereas the
reverse does not hold. Symmetries that exist due to problem formulation appear in every
instance of the problem, in addition to symmetries that exist due to specific parameter
values for an instance. Given that there may be many instance-specific symmetries, one
may process all symmetries at once using publicly available symmetry processing packages
such as Shatter (Aloul et al., 2003; Aloul, Markov, & Sakallah, 2003). Alternatively, one
may add symmetry breaking predicates for instance-independent symmetries early, hoping
to speed-up the processing of remaining symmetries. This type of symmetry breaking has
not been discussed in earlier work (Aloul et al., 2003, 2003), and in this paper we study its
utility for the graph coloring problem.
Our work deals with symmetries of problem and instance descriptions; we distinguish
(i) symmetries of generic problem specifications from (ii) symmetries of problem-instance
data. The former symmetries translate to the latter but not the other way around —
an example from graph coloring is given by color permutations versus automorphisms of
specific graphs. While both types of symmetries can be detected by solving the graph automorphism problem, symmetries in specifications can often be captured manually, whereas
capturing symmetries in problem instances may require large-scale computation and nontrivial software. Indeed, when specification-level symmetries are instantiated, the size of
their support (the number of objects moved) typically increases dramatically. For example,
color permutations in graph coloring should be simultaneously applied to every vertex of a
graph in question. Detecting symmetries with larger support seems like a waste of computational effort. To this end, recent work on breaking symmetries in specifications (Cadoli
& Mancini, 2003) prefers instance-independent techniques and breaks symmetries only at
the specification level. This approach is particularly relevant with constraint solvers and
languages that process problem specifications prior to seeing actual problem instances and
can amortize the symmetry-detection effort. Also, in a more general setting, using instanceindependent symmetry breaking does not rule out applying redundant (or complementary)
instance-specific techniques at a later stage.
Until recently automatic symmetry detection had been a serious bottleneck in handling
symmetries. For example, if graph automorphism is solved using the program Nauty
(McKay, 1990), detecting symmetries often can take longer than constraint solving without
symmetry breaking. This was observed for microprocessor verification SAT instances by
Aloul et. al. in 2002 (Aloul et al., 2003). Therefore, detecting symmetries early and
representing them in a more structured way appears attractive, especially given that this
may potentially increase the efficiency of symmetry-breaking. However, the symmetrydetection bottleneck has recently been eliminated in many applications with the software
tool Saucy (Darga et al., 2004) that often finds symmetries of practical graphs many times
291

Ramani, Aloul, Markov, & Sakallah

faster than Nauty. This development undermines, to some extent, the potential benefits of
symmetry processing at the specification level and puts the spotlight on symmetry-breaking.
To that end, SBPs added in different circumstances may have different efficiency, and while
it is unclear a priori which approach is more successful, the differences in performance
may be significant. Since SBPs appear to the solver as additional constraints, they may
either speed up or frustrate the solver (the latter effect is clearly visible in our experiments
with CPLEX). Outcomes of practical experiments are also affected by recent dramatic
improvements in the efficiency of symmetry-breaking predicates (Aloul et al., 2003, 2004).
While it seems difficult to justify any particular expectation for empirical performance,
we are fortunate to observe clear trends in experimental data presented in Section 4 and
summarize them with simple rules.
While we focus on graph coloring instances, our techniques are immediately applicable
to related CSP problems, e.g., those produced by adding new types of constraints that can
be easily expressed in SAT or 0-1 ILP when graph coloring is converted to those generic
problems. We also expect that our conclusions about symmetry-breaking carry over to other
CSPs that can be economically reduced to SAT and 0-1 ILP, e.g., maximum independent
set, minimum dominating set, etc. Another advantage of our approach is being able to use a
variety of existing and future SAT and 0-1 ILP solvers without modifying their source code.
Unfortunately, this precludes the use of dynamic symmetry-breaking that would require
modifying the source code and may adversely affect performance by disturbing the fragile
balance between the amount of reasoning and searching performed by modern SAT solvers.
Specifically, heuristics for variable ordering and decision selection may be affected, as well
as the recording of learned conflict clauses (nogoods).
The main contributions of this work are listed below.
• Using the symmetry breaking flow for pseudo-Boolean (PB) formulas described by
Aloul et. al in 2004 (Aloul et al., 2004), we detect and break symmetries in DIMACS
graph coloring benchmarks expressed as instances of 0-1 ILP. We show that instancedependent symmetry breaking enables many medium-sized instances to be optimally
solved in reasonable time on commodity PCs
• We propose instance-independent techniques for breaking symmetries during problem formulation, assess their relative strength and completeness, and evaluate them
empirically using well-known academic and commercial tools
• We show empirically that instance-dependent techniques are, in general, more effective
than instance-independent symmetry breaking for the benchmarks in question. In
fact, only the simplest and least complex instance-independent SBPs are competitive
The remaining part of the paper is organized as follows. Section 2 covers background on
graph coloring, SAT and 0-1 ILP, as well as previous work on symmetry breaking. Instanceindependent symmetry breaking predicates are discussed in Section 3. Section 4 presents
our empirical results and Section 5 concludes the paper. The Appendix gives detailed results
for the queens family of instances.
292

Breaking Instance-Independent Symmetries in Exact Graph Coloring

2. Background and Previous Work
This section discusses problem definitions and applications of some existing algorithms for
exact graph coloring. We also discuss previous work on symmetry breaking for SAT and
0-1 ILP in some detail.
2.1 Graph Coloring
Given an undirected graph G(V, E), a vertex coloring of the graph is an assignment of a
label (color) to each node such that the labels on adjacent nodes are different. A minimum
coloring uses the smallest possible number of colors, known as the chromatic number of
a graph. The decision version of graph coloring (K−coloring) asks whether vertices in a
graph can be colored using ≤ K colors for a given K.
A clique of an undirected graph G(V, E) is a set of mutually adjacent vertices in the
graph. The maximum clique problem consists of seeking a clique of maximal size, i.e.,
a clique with at least as many vertices as any other clique in the graph. The maximum
clique and graph coloring problems are closely related. Specifically, the max-clique size
is a lower bound on the chromatic number of the graph. Over the years, a number of
different algorithms for solving graph coloring have been developed, because of its fundamental importance in computer science. These algorithms fall into three broad categories:
polynomial-time approximation schemes, optimal algorithms, and heuristics. We briefly
discuss work in each of these categories below. There are a number of online resources on
graph coloring (Trick, 1996; Culberson, 2004) that offer more detailed bibliographies.
As far as approximation schemes are concerned, the most common technique used is
successive augmentation. In this approach a partial coloring is found on a small number of
vertices and this is extended vertex by vertex until the entire graph is colored. Examples
include the algorithms by Leighton (Leighton, 1979) for large scheduling problems, and by
Welsh and Powell (Welsh & Powell, 1967) for time-tabling. More recent work has attempted
to tighten the worst-case bounds on the chromatic number of the graph. The algorithm
providing the currently best worst-case ratio (number of colors used divided by optimal
number)
is due
to Haldorsson (Haldorsson, 1990), and guarantees a ratio of no more than


2

log n)
, where n is the number of vertices. General heuristic methods that have
O n(log
(log n)3
been tried include simulated annealing (Chams, Hertz, & Werra, 1987; Aragon, Johnson,
McGeoch, & Schevon, 1991) and tabu search (Hertz & Werra, 1987). A well-known heuristic
that is still widely used is the DSATUR algorithm by Brelaz (Brelaz, 1979) which colors
vertices according to their saturation degree. The saturation degree of a vertex is the number
of different colors to which it is adjacent. The DSATUR heuristic repeatedly picks a vertex
with maximal saturation degree and colors it with the lowest-numbered color possible.
This heuristic is optimal for bipartite graphs. Algorithms for finding optimal colorings
are frequently based on implicit enumeration, and are discussed in more detail later in
this section. Both the graph coloring and max-clique problems are N P-complete (Garey &
Johnson, 1979) and even finding near-optimal solutions with good approximation guarantees
is N P-hard (Feige, Goldwasser, Lovasz, Safra, & Szege, 1991). The inapproximability of
graph coloring suggests that it may be more difficult to solve heuristically than, say, the
Traveling Salesman Problem for which Polynomial-Time Approximation Schemes (PTAS)

293

Ramani, Aloul, Markov, & Sakallah

are known for Euclidean and Manhattan graphs. For this and a number of other reasons,
we study optimal graph coloring and many application-derived instances that are solvable
in reasonable time. Several applications are outlined next.
Time-Tabling and Scheduling problems involve placing pairwise restrictions on jobs
that cannot be performed simultaneously. For example, two classes taught by the same faculty member cannot be scheduled in the same time slot. The problem has been studied in
previous work by Leighton (Leighton, 1979) and De Werra (Werra, 1985). More generally,
graph coloring is an important problem in Artificial Intelligence because of its close relationship to planning and scheduling. Several traditional AI techniques have been applied to
this problem, including parallel algorithms using neural networks (Jagota, 1996). Genetic
and hybrid evolutionary algorithms have also been developed, notably by Galinier et. al.
in 1999 (Galinier & Hao, 1999), in addition to more traditional optimization methodology,
such as scatter search (J.-P. Hamiez, 2001). There have also been studies of benchmarking
models for graph coloring, such as the recent work by Walsh (Walsh, 2001), which shows
that graphs with high vertex degrees are more likely to occur in real-world applications.
Register Allocation is a very active application of graph coloring. This problem
seeks to assign variables to a limited number of hardware registers during program execution.
Accessing variables in registers is much faster than fetching them from memory. However,
the number of registers is limited and is typically much smaller than the number of variables.
Therefore, multiple variables must be assigned to the same register. There are restrictions
on these assignments. Two variables conflict with each other if they are live at the same
time, i.e. one is used both before and after the other within a short period of time (for
instance, within a subroutine). The goal is to assign variables that do not conflict so as
to minimize the use of non-register memory. To formalize this, one creates a graph where
nodes represent variables and edges represent conflicts between variables. A coloring maps
to a conflict-free assignment, and if the number of registers exceeds the chromatic number,
a conflict-free register assignment exists (Chaitin et al., 1981).
Printed Circuit Board Testing (Garey & Johnson, 1979) involves the problem of
testing printed circuit boards (PCBs) for unintended short circuits (caused by stray lines of
solder). This gives rise to a graph coloring problem in which the vertices correspond to the
nets on board and there is an edge between two vertices if there is a potential for a short
circuit between the corresponding nets. Coloring the graph corresponds to partitioning the
nets into “supernets,” where the nets in each supernet can be simultaneously tested for
shorts against all other nets, thereby speeding up the testing process.
Radio frequency assignment for broadcast services in geographic regions (including commercial radio stations, taxi dispatch, police and emergency services). The list of all
possible frequencies is fixed by government agencies, but adjacent geographic regions cannot use overlapping frequencies. To reduce frequency assignment to graph coloring, each
geographic region needing K frequencies is represented with a K−clique, and all N × K
possible bipartite edges are introduced between two geographically adjacent regions needing
N and K frequencies respectively.
Other applications of graph coloring in circuit design and layout include circuit clustering, scheduling for signal flow graphs, and many others. Benchmarks from these applications
are not publicly available, and therefore do not appear in this paper. However, all the symmetry breaking techniques described here extend to instances from any application. The
294

Breaking Instance-Independent Symmetries in Exact Graph Coloring

benchmarks we use here do include register allocation, n−queens, and several other applications discussed in more detail in Section 4. Empirically, we observe that many of the
instances in this paper can be optimally solved in reasonable time, especially when symmetry breaking is employed. Since this work deals with finding optimal solutions for graph
coloring, we discuss previous work on finding exact algorithms for this problem in some
detail.

The literature on exact graph coloring includes generic algorithms (Kubale & Jackowski,
1985) and specialized algorithms for a particular application, such as Chaitin’s register allocation algorithm (Chaitin et al., 1981). At the moment, there does not appear to be a
comprehensive survey of techniques for this problem. However, online surveys (Trick, 1996;
Culberson, 2004) contain reasonably large bibliographies and even downloadable source
code for coloring algorithms in some cases. Published algorithms for finding optimal graph
colorings are mainly based on implicit enumeration. The algorithm proposed by Brown
(Brown, 1972) enumerates solutions for a given instance of graph coloring and checks each
solution for correctness and optimality. The algorithm introduces a special tree construction to avoid redundancy in enumerating solutions. The work by Brelaz (Brelaz, 1979)
improves upon this algorithm by creating an initial coloring based on some clique in the
graph and then considering assignments induced by this coloring. The work by Kubale and
Kusz (Kubale & Kusz, 1983) discusses the empirical performance of implicit enumeration
algorithms, and later work by Kubale and Jackowski (Kubale & Jackowski, 1985) augments
traditional implicit enumeration techniques with more sophisticated backtracking methods.

Our work deals with solving graph coloring by reduction to another problem, in this
case 0-1 ILP. This type of reduction has been discussed in the past, notably in the recent
work by Mehrotra and Trick (Mehrotra & Trick, 1996), which proposes an optimal coloring
algorithm which expresses graph coloring using ILP-like constraints. It relies on an auxiliary
independent set formulation, where each independent set in a graph is represented by a
variable. There can be prohibitively many variables but in practical cases this number may
be reduced by column generation, a method that first tries to solve a linear relaxation using
a subset of variables and then adds more where needed. This approach inherently breaks
problem symmetries, and thus rules out the use of SBPs as a way to speed up the search
process. Our ILP construction differs considerably from the one described above, since it
does not rely on an independent set formulation, but assigns colors to individual vertices by
using indicator variables. The construction is described in more detail later in this section.
Solving graph coloring by reduction allows exact solutions to be found by using SAT/0-1
ILP solvers as black boxes. Earlier work by Coudert (Coudert, 1997) demonstrated that
finding exact solutions for application-derived graph coloring benchmarks often takes no
longer than heuristic approaches, and that heuristic solutions may differ from the optimal
value by as much as 100%. Coudert (Coudert, 1997) proposes an algorithm that finds
exact graph coloring solutions by solving the max-clique problem. The algorithm uses
a technique called “q−color pruning”, which assigns colors to vertices and systematically
removes vertices that can be colored by q colors, where q is greater than a specified limit.
295

Ramani, Aloul, Markov, & Sakallah

2.2 Breaking Symmetries in CSPs
Several earlier works have addressed the importance of symmetry breaking in the search for
solutions of CSPs. It has been shown (Krishnamurthy, 1985) that symmetry facilitates short
proofs of propositions such as the pigeonhole principle, whereas pure-resolution proofs are
necessarily exponential in size. Finding such proofs is, of course, a very difficult problem,
but the performance of many CSP techniques can be lower-bounded by the best-case proof
size. A typical approach to use symmetries is to prevent a CSP solver from considering
redundant symmetric solutions. This is called symmetry-breaking and can be accomplished
by adding constraints, often called symmetry-breaking predicates (SBPs). Static symmetrybreaking, such as the instance-independent constructions proposed in this work and the
instance-dependent predicates from the literature (Aloul et al., 2003; Crawford et al., 1996),
detects symmetries and adds SBPs during pre-processing and not when branching toward
possible solutions. The Symmetry Breaking by Dominance Detection (SBDD) procedure
described by Fahle in 2001 (Fahle, Schamberger, & Sellmann, 2001) detects symmetric
choice points during search. Each choice point generated by the search algorithm is checked
against previously expanded search nodes. If the same or an equivalent choice point has
been previously expanded, the choice point is not visited again. The global cut algorithm
proposed by Focacci and Milano (Focacci & Milano, 2001) records all nogoods found during
search whose symmetric images should be pruned. This set of nogoods, called the “global cut
seed” is used to generate global cut constraints that prune symmetric images for the entire
search tree, while ensuring that correctness of the original constraints is not violated. Later
work (Puget, 2002) has proposed improved methods for nogood recording. These works
do not offer a systematic strategy for symmetry detection - they either require symmetries
to be known or declared in advance, or record information during search that enables
symmetry detection. Our work outlines and implements a complete strategy to detect
and break symmetries automatically during pre-processing, so that a black-box solver can
be used during search. This context is broader than those that justify the development
of specialized solvers. On the other hand, our techniques do not conflict with dynamic
symmetry-breaking and some of our results can potentially be reused in that context.
A promising new partially-dynamic approach to symmetry-breaking, called Group Equivalence (GE) trees is proposed by Roney et. al. (Roney-Dougal, Gent, Kelsey, & Linton,
2004). This work aims to reduce the per-node overhead associated with dynamic approaches.
A GE tree is constructed from a CSP with a symmetry group G such that the nodes of the
tree represent equivalence classes of partial assignments under the group. This approach is
illustrated by tracking value symmetries, i.e., simultaneous permutations of values in CSP
variables. The work also shows that GE trees empirically outperform several well-known
symmetry-breaking methodologies, such as SBDDs. In comparison, our work compares different ways to handle arbitrary compositions of variable and value symmetries (in graph
coloring, value symmetries are seen at the specification level, whereas variable symmetries
can only be seen in problem instances). To this end, our static techniques appear compatible rather than competing with the use of GE trees. There have also been many symmetry breaking approaches with particular relevance to graph coloring. Recent work by Gent
(Gent, 2001) proposes constraints that break symmetry between “indistinguishable values”,
but does not evaluate them empirically. Like the lowest-index ordering (LI) constraints pro296

Breaking Instance-Independent Symmetries in Exact Graph Coloring

posed by us in Section 3, these constraints also use the pre-existing sequential numbering of
vertices in an instance of graph coloring to enforce distinctions between symmetric vertices.
The construction appears complex compared to alternative SBPs and not as effective in our
experiments as simpler constructions. Another related work is (Hentenryck, Agren, Flener,
& Pearson, 2003), which proposes a constant-time, constant-space algorithm for detecting and breaking value symmetries in a class of CSPs that includes graph coloring. More
recently, Benhamou (Benhamou, 2004) discusses symmetry breaking for CSPs modeled using not-equals constraints (NECSP), and uses graph coloring as an illustrative example.
The paper defines a sufficient condition for symmetry such that certain symmetries can be
detected in linear time. The removal of these symmetries leads to considerable gains in
backtracking search algorithms for NECSPs. In general, our empirical results, reported in
Section 4, appear competitive with those for state-of-the-art dynamic approaches. However,
designing the world’s best graph-colorer is not the goal of our research. Instead, we focus
on more efficient problem reductions to SAT and 0-1 ILP by improving symmetry-breaking.
To ensure a broad applicability of our results, we treat SAT solvers as black boxes, and
perform a comprehensive comparison of static SBPs and report empirical trends. While
a more comprehensive comparison against existing graph coloring literature would be of
great value, making it rigorous, conclusive and revealing requires that the best static and
the best dynamic symmetry-breaking techniques are known. To this end, we speculate that
a more likely winner would be a hybrid. Additional major issues to be resolved include
the tuning of solvers to specific benchmarks (noted in the work by Kirovski and Potkonjak (Kirovski & Potkonjak, 1998), differences in experimental setup, different software and
hardware platforms, etc. Given that such a comparison is not completely in the scope of
our work, it is better delegated to a dedicated publication. However, to demonstrate that
our techniques are competitive with related work, we provide a comparison with the best
results from recent literature (Benhamou, 2004; Coudert, 1997) in Section 4.3.
2.3 SAT and 0-1 ILP
One can solve the decision version of graph coloring by reducing it to Boolean satisfiability,
and the optimization version by reduction to 0-1 ILP. The Boolean satisfiability (SAT)
problem involves finding an assignment to a set of 0-1 variables that satisfies a set of
constraints, called clauses, expressed in conjunctive normal form (CNF). A CNF formula
on n binary variables, x1 , . . . , xn consists of a conjunction of clauses, ω 1 , . . . , ωm . A clause
consists of a disjunction of literals. A literal l is an occurrence of a Boolean variable or
its complement. The 0-1 ILP problem is closely related to SAT, and allows the use of
pseudo-Boolean (PB) constraints, which are linear inequalities with integer coefficients that
can be expressed in the normalized form (Aloul, Ramani, Markov, & Sakallah, 2002) of:
a1 x1 + a2 x2 + . . . an xn ≤ b where ai , b ∈ Z + and xi are literals of Boolean variables. 1
In some cases a single PB constraint can replace an exponential number of CNF clauses
(Aloul et al., 2002). In general, the efficiency of CNF reductions is encoding-dependent.
Earlier work by Warners (Warners, 1998) shows that a linear-overhead conversion exists
from linear inequalities with integer coefficients and 0-1 variables to CNF. However, CNF
1. Using the relations (Ax ≥ b) ⇔ (−Ax ≤ −b) and xi = (1 − xi ), any arbitrary PB constraint can be
expressed in normalized form with only positive coefficients.

297

Ramani, Aloul, Markov, & Sakallah

encodings which do not use this conversion may be less efficient. When converting CNF
to PB, a single CNF constraint can always be expressed as a single 0-1 ILP constraint (by
replacing disjunctions between literals in the constraint with ‘+’ and setting the right-handside value as ≥ 1). However, this may not always be suitable since certain operations, such
as disjunction, implication and inequality are more intuitively expressed as CNF, and can be
efficiently processed by SAT solvers such as Chaff (Moskewicz et al., 2001). A conversion
to 0-1 ILP is more desirable for arithmetic operations, or “counting constraints”, whose
CNF equivalent requires polynomially many clauses (and exponentially many for some
conversions). To maximize the advantages of both CNF and PB formats, most recent
0-1 ILP solvers such as PBS (Aloul et al., 2002) and Galena (Chai & Kuehlmann, 2003)
allow a formula to possess CNF and PB components. Additionally, 0-1 ILP solvers also
provide for the solution of optimization problems. Subject to given constraints, one may
request the minimization (or maximization) of an objective function which must be a linear
combination of the problem variables.
Exact SAT solvers (Goldberg & Novikov, 2002; Moskewicz et al., 2001; Silva & Sakallah,
1999) are typically based on the original Davis-Logemann-Loveland (DLL) backtrack search
algorithm (Davis, Logemann, & Loveland, 1962). Recently, several powerful methods have
been proposed to expedite the backtrack search algorithm, such as conflict diagnosis (Silva
& Sakallah, 1999) and watched literal Boolean constraint propagation (BCP) (Moskewicz
et al., 2001). With these improvements, modern SAT solvers (Moskewicz et al., 2001;
Goldberg & Novikov, 2002) are capable of solving instances with several million variables
and clauses in reasonable time. This increase in scalability and scope has enabled a number
of SAT-based applications in various domains, including circuit layout (Aloul et al., 2003),
microprocessor verification, symbolic model checking, and many others. More recent work
has focused on extending advances in SAT to 0-1 ILP (Aloul et al., 2002; Chai & Kuehlmann,
2003). In this work, we focus on solving instances of exact graph coloring by reduction to
0-1 ILP and the use of SBPs. Our choice of 0-1 ILP is motivated by the following reasons.
Firstly, 0-1 ILP permits the use of a more general input format than CNF, allowing
greater efficiency in problem encoding, but at the same time is similar enough to SAT to
allow improved methods for SAT-solving to be used without paying a penalty for generality.
The specialized 0-1 ILP solvers PBS (Aloul et al., 2002) and Galena (Chai & Kuehlmann,
2003) both propose sophisticated new techniques for 0-1 ILP that are based on recent
decision heuristics (Moskewicz et al., 2001), conflict diagnosis and backtracking techniques
(Silva & Sakallah, 1999) for SAT solvers. As a result, they empirically perform better than
both the generic ILP solver CPLEX (ILOG, 2000) and the leading-edge SAT solver zChaff on
several DIMACS SAT benchmarks and application-derived instances such as FPGA routing
instances from circuit layout. Also, since 0-1 ILP is an optimization problem, unlike SAT
which is a decision problem, 0-1 ILP solvers possess the ability to maximize/minimize an
objective function. They can, therefore, be directly applied to the optimization version of
exact graph coloring, unlike pure CNF-SAT solvers that can only be used on the k−coloring
decision variant. It is possible to solve the optimization version by repeatedly solving
instances of the k−coloring using a SAT solver, with the value of k being updated after each
call. However, 0-1 ILP solvers do not require this extra step, and moreover tend to provide
better performance than repeated calls to a SAT solver on many Boolean optimization
problems (Aloul et al., 2002).
298

Breaking Instance-Independent Symmetries in Exact Graph Coloring

It is possible to use a generic ILP solver, such as the commercial solver CPLEX (ILOG,
2000) instead of a specialized 0-1 ILP solver without any changes in problem formulation.
However, Aloul et al. (Aloul et al., 2002) show that this generalization is not always
desirable, particularly in the case of Boolean optimization problems such as Max-SAT. 0-1
ILP is also especially useful for evaluating the effectiveness of symmetry breaking for graph
coloring, the primary purpose of this work. Detecting and breaking symmetries in SAT
formulas has been shown to speed up the problem-solving process (Crawford et al., 1996;
Aloul et al., 2003). Recently, symmetry breaking techniques for SAT have been extended
to 0-1 ILP (Aloul et al., 2004), and have been shown to produce search speedups in this
domain as well. However, a similar extension for non-binary variables for generic ILP does
not presently exist. There is evidence (Aloul et al., 2002) that the advantages of symmetry
breaking may depend on the actual algorithm used in the search. Specifically, results in
the cited work suggest that the generic ILP solver CPLEX is actually slowed down by the
addition of SBPs. Since CPLEX is a commercial tool and the algorithms used by it are not
publicly known, it is difficult to pinpoint a reason for this disparity. However, our empirical
results in Section 4 do bear out these observations. The remainder of this section discusses
the reduction of graph coloring to 0-1 ILP and explains previous work in symmetry breaking
in some detail.
2.4 Detecting and Breaking Symmetries in 0-1 ILPs
Previous work (Crawford et al., 1996; Aloul et al., 2003) has shown that breaking symmetries
in CNF formulas effectively prunes the search space and can lead to significant runtime
speedups. Breaking symmetries prevents symmetric images of search paths from being
searched, thus pruning the search tree. The papers cited in this work all use variants of
the approach first described by Crawford et al. (Crawford et al., 1996), which detects
symmetries in a CNF formula using graph automorphism. The formula is expressed as an
undirected graph such that the symmetry group of the graph is isomorphic to the symmetry
group of the CNF formula. Symmetries induce equivalence relations on the set of truth
assignments of the CNF formula. All assignments in an equivalence class result in the same
truth value for the formula (satisfying or not). Therefore, it is only necessary to consider
one assignment from each such class.
Techniques for symmetry breaking proposed in the literature follow the following steps:
(i) construction of a colored graph from a CNF formula (ii) detection of symmetries in
the graph using graph automorphism software (iii) use of the detected symmetries to construct symmetry breaking predicates (SBPs) that can be appended as additional clauses to
the CNF formula (iv) solution of the new CNF formula thus created using a SAT solver.
Crawford’s construction (Crawford, 1992) uses 3 colors for vertices, one for positive literals, one for negative literals and a third for clauses. Edges are added between literals
in a clause and the corresponding clause vertex, and between positive and negative literal
vertices for Boolean consistency. As an optimization, binary clauses (with just two literals)
are represented by adding an edge between the two involved literals, so an extra vertex
is not needed. This is useful because the runtime of graph automorphism programs such
as Nauty (McKay, 1990) generally increases with the number of vertices in the graph.
However, with this optimization Boolean consistency is not enforced, since binary clausal
299

Ramani, Aloul, Markov, & Sakallah

edges could be confused with Boolean consistency edges between positive and negative literals of the same variable. This may be improved by representing binary clausal edges
as double edges (Crawford et al., 1996), thus distinguishing between the two edge types.
However, Nauty (and other graph automorphism programs) do not support the uses of
double edges, so this construction is not very useful in practice. Furthermore, the cited
constructions (Crawford, 1992; Crawford et al., 1996) do not allow detection of phase-shift
symmetries, when a variable’s positive literal is mapped to its negative literal and vice versa,
since they color positive and negative literals differently. Our previous work (Aloul et al.,
2003) improves upon these constructions by giving positive and negative literal vertices the
same color, and allowing binary clauses and Boolean consistency edges to be represented
the same way, i.e. a single edge between two literal vertices. Although this construction
may allow spurious symmetries - when clause edges are mapped into consistency edges - this
can occur only when a formula contains circular chains of implications over a subset of its
variables. For example, given a subset of variables x 1 . . . xn , such a chain is a collection of
clauses (y1 ⇒ y2 )(y2 ⇒ y3 ) . . . (yn−1 ⇒ yn ), where each yi is a positive or negative literal of
xi . These circular chains rarely occur in practice, and can be easily checked for. Therefore,
the efficient graph construction described above can be used in most practical cases.
Graph automorphisms are detected in Crawford’s work (Crawford et al., 1996) as well
as our previous work (Aloul et al., 2003) using the program Nauty (McKay, 1990), which
is part of the GAP (Groups, Algebra and Programming) package. Nauty accepts graphs
in the GAP input format and returns a list of generators for the automorphism group (the
term “generators” is used in a mathematical sense, the symmetry group partitions the set of
vertex permutations for the graph into equivalence classes such that all permutations in the
same class are equivalent. Nauty returns the set of generators for this symmetry group).
More recent work ((Aloul et al., 2003, 2004)) uses the automorphism program Saucy (Darga
et al., 2004), which is more efficient than Nauty and can also process larger graphs with
more vertices. After generators of the symmetry group are detected, symmetry breaking
predicates are added to the instance in a pre-processing step. Crawford et al. (Crawford
et al., 1996) propose the addition of SBPs that choose lexicographically smallest assignments
(lex-leaders) from each equivalence class. We refer to such SBPs as instance-dependent
SBPs, since the symmetries are first detected and then broken, and therefore the exact
number and nature of SBPs added always depends on the connectivity of the graph itself.
Although detecting symmetries is non-trivial, using modern software such as Nauty and
Saucy the detection time is frequently insignificant when compared with SAT-solving time.
Crawford et. al. (Crawford et al., 1996) construct lex-leader SBPs for the entire symmetry
group, using the group generators returned by Nauty. This type of symmetry breaking
is complete. However, the approach used by Aloul et al. in TCAD 2003 (Aloul et al.,
2003) shows that incomplete symmetry breaking, which breaks symmetries only between
generators, is often effective in practice and much more efficient since it does not require the
whole group to be reconstructed. The SBP construction proposed in the cited work (Aloul
et al., 2003) is quadratic in the number of problem variables, compared with the earlier
construction (Crawford et al., 1996), which could run to exponential size. This construction
is further improved in the 2003 work by Aloul, Sakallah and Markov (Aloul et al., 2003),
which describes efficient, tautology-free SBP construction, whose size is linear in the number
of problem variables. Empirical results from both Crawford’s work (Crawford et al., 1996) as
300

Breaking Instance-Independent Symmetries in Exact Graph Coloring

well as the work in TCAD 2003 (Aloul et al., 2003) show that breaking symmetries produces
large search speedups on a number of CNF benchmark families, including pigeonhole and
Urquhart benchmarks, microprocessor verification, FPGA routing and ASIC global routing
benchmarks from the VLSI domain.
Our work on symmetry breaking in SAT (Aloul et al., 2003) has also been extended
to to optimization problems that include both CNF and PB constraints, and an objective
function (Aloul et al., 2004). As before, symmetries are detected by reduction to graph
automorphism. A PB formula for an optimization problem is represented by an undirected
graph. Graph symmetries are detected using the graph automorphism tool Saucy (Darga
et al., 2004). Efficient symmetry breaking predicates (Aloul et al., 2003) are appended to
the formula as CNF clauses. The empirical results for our work on symmetry breaking
in 0-1 ILP (Aloul et al., 2004) show that the addition of symmetry breaking predicates
to PB formulas results in considerable search speedups for the specialized 0-1 ILP solver
PBS (Aloul et al., 2002). In this work, we use the above methodology (Aloul et al., 2004)
for detecting and breaking instance-dependent symmetries in instances of graph coloring
expressed as 0-1 ILP. These instance-dependent SBPs are compared with a number of
instance-independent SBP constructions described in the next section.
Detecting and breaking symmetries in application-derived SAT instances amounts to a
recovery of structure from the original application. The loss of structure during problem
reductions is one reason why reduction-based techniques are often not competitive with
domain-specific algorithms, and recent work on symmetry breaking is useful in this context.
Other types of structure include clusters (Huang & Darwiche, 2003; Aloul, Markov, &
Sakallah, 2004). Huang et al. (Huang & Darwiche, 2003) propose an algorithm that detects
clusters in SAT instances and uses them to produce variable orderings, and these structureaware orderings result in considerable empirical improvements with the SAT solver zChaff
(Moskewicz et al., 2001).
2.5 Reducing Graph Coloring to 0-1 ILP
We express an instance of the minimal graph coloring problem as a 0-1 ILP optimization
problem, consisting of (i) CNF and PB constraints that model the graph (ii) an objective
function to minimize the number of colors used.
Consider a graph G(V, E). Let n = |V | be the number of vertices in G, and m = |E| be
the number of edges. An instance of the K−coloring problem for G (i.e., can the vertices
in V be colored with K colors) is formulated as follows.
• For each vertex vi , K indicator variables xi,1 , . . . , xi,K , denote possible color assignments to vi . Variable xi,j is set to 1 to indicate that vertex vi is colored with color j,
and 0 otherwise
• For each vertex vi , a PB constraint of the form
is colored with exactly one color.

PK

j=1 xi,j

= 1 ensures that each vertex

• Each edge ei in E connects two vertices (va , vb ). For each edge ei , we define CNF
V
constraints of the form K
j=1 (xa,j ∨ xb,j ) to specify that no two vertices connected by
an edge can be given the same color.
301

Ramani, Aloul, Markov, & Sakallah

• To track used colors, we define K new variables, y 1 , . . . , yK . Variable yi is true if and
only if at least one vertex uses color i. This is expressed using the following CNF
V
Wn
constraints: K
j=1 (yj ⇔ ( i=1 xi,j )).
• The optimization objective is to minimize the number of y i variables set to true, i.e.
P
MIN K
i=1 yi
The total number of variables in the formula is nK +K. The total number of constraints
is computed as follows. There are totally n 0-1 ILP constraints (one per vertex) to ensure
that each vertex uses exactly one color. For each edge, there are K CNF clauses specifying
that the two vertices connected by that edge cannot have the same color, giving a total
of mK CNF clauses. There are an additional nK CNF clauses (K per vertex) for setting
indicator variables, and K CNF clauses, one per color, to complete the iff condition for indicator variables. This gives a total of K · (m + n + 1) CNF clauses and n 0-1 ILP constraints,
plus one objective function, in the converted formula. For dense graphs, where |E| ≈ |V | 2 ,
the resulting formula size is quadratic in the number of vertices of the graph, but for sparser
graphs it may be linear. A key observation is that instance-dependent symmetries in graph
coloring survive the above reduction to 0-1 ILP. For instance-independent symmetries (i.e.
permutations of colors) this is easy to see, since the ordering of colors can be changed
without having any effect on the formula and producing the same set of constraints. For
instance-dependent symmetries, consider two vertices v a and vb that are symmetric to each
other and can be swapped in the original graph. Clearly, the constraints that specify that
va and vb must use exactly one color are interchangeable, as are the constraints that determine color usage based on the colors assigned to v a and vb . It only remains to show that
the connectivity constraints that control colors of vertices adjacent to v a and vb are also
symmetric. This is clear from the fact that for every edge E i incident on va , there must
be a corresponding edge Ej incident on vb for the two vertices to be symmetric (E i and Ej
can be the same edge). Therefore, for the set of K CNF clauses added to the formula to
represent Ei , there must be a symmetric set of clauses added for E j , and thus connectivity
is preserved.
It is also clear that the 0-1 ILP formulation does not introduce spurious symmetries, i.e.
any symmetry in the formula is a symmetry in the graph. A spurious symmetry arises when
(i) variables of different types can be mapped into each other, e.g. vertex color variables are
mapped to color usage indicator variables and (ii) variables of the same type are mapped
into each other when the corresponding vertices are not actually symmetric. From the
construction of the 0-1 ILP formula, it is clear that all K variables per vertex that indicate
a vertex’s color can be permuted, as can the K color usage variables, since these all appear
in exactly the same constraints. This corresponds to the instance-independent symmetry colors in an instance of graph coloring can be arbitrarily permuted. However, vertex color
variables appear in constraints restricting the number of colors a vertex can use and also in
constraints that describe the connectivity of the graph, whereas color usage variables appear
only in constraints that specify when they are set. Therefore, the two types of variables
cannot map to one another. Since all constraints regarding color and connectivity of a
vertex are written using all K color variables for that vertex, these variables are symmetric
to each other only in groups of K, i.e. if one such variable for a given vertex v 1 is symmetric
to a variable for another vertex v2 , then all K variables for v1 and v2 are correspondingly
302

Breaking Instance-Independent Symmetries in Exact Graph Coloring

symmetric. Additionally, this symmetry between variables indicates a correspondence of
clauses in which they occur. This is only possible if the vertices v 1 and v2 are symmetric in
terms of connectivity (instance-dependent symmetry). Thus, both types of symmetries are
preserved during conversion to 0-1 ILP, and no false symmetries are added. Therefore, we
can apply known techniques for symmetry detection in 0-1 ILP.

3. Instance-Independent SBPs
The question addressed in this work is whether instance-independent SBPs added during
the reduction can provide even greater speedups, possibly by accelerating the detection
of instance-dependent symmetries. To answer this question, we propose three provably
correct SBP constructions of varying strength, and one heuristic that is intended to break
a small number of symmetries with minimal overhead. Each construction is implemented
and empirical results are reported in Section 4.
We use the following notation. Consider an instance of the K−coloring problem, which
asks whether a graph G(V, E) can be colored using ≤ K colors and minimizes the number
of colors. Assume the colors are numbered 1 . . . K. We denote a valid color assignment by
P
(n1 , n2 , . . . , nK ) where ni is the number of vertices colored with color i, and |V | = K
i=1 ni .
Each ni in the color assignment denotes the cardinality of the independent set colored with
color i. We are not concerned with the actual composition of the independent sets here,
since that is an instance-dependent issue. Instance-independent symmetries are only the
arbitrary permutations of colors between different independent sets.
The effects of each proposed construction are illustrated using the example in Figure
1. The figure is an example of the 4-coloring problem on a graph with four vertices. Part
(a) of the figure shows the graph to be colored. For visual clarity, part (b) shows color
patterns corresponding to the different color numbers. It is clear from the figure that the
vertices V1 , V2 and V3 form a clique, and must use different colors. However, V 4 can be given
the same color as either V1 or V2 , and therefore only 3 colors are needed for this instance.
The instance can be partitioned into independent sets in two ways: {{V 1 , V4 }, {V2 }, {V3 }}
and {{V1 }, {V2 , V4 }, {V3 }}. Our SBPs do not actually address how the independent sets
are composed, because this is an instance-dependent issue. However, given any partition
of independent sets, colors can be arbitrarily permuted between sets in the partition. The
instance-independent SBPs proposed here restrict this permutation. In the examples below,
we assume the first partition of independent sets i.e. {{V 1 , V4 }, {V2 }, {V3 }}. Results are
proved with respect to the permutation of colors for this partition.
3.1 Null-Color Elimination (NU)
Consider a K−coloring problem with colors 1 . . . K for a graph G(V, E). Assume that G can
be minimally colored withK − 1 colors. Consider an optimal solution where color i is not
used: (n1 , n2 , ..ni−1 , 0, ni+1 , . . . , nK ). This assignment is equivalent to another assignment,
(n0 1 , n0 2 , ..n0 j−1 , 0, n0 j+1 ...n0 K )
where i 6= j and n0 i = nj . For example, the assignment (1, 0, 2, 3) is equivalent to (1, 3, 2, 0),
(0, 1, 2, 3), (1, 2, 0, 3). This is due to the existence of null colors, which create symmetries in
303

Ramani, Aloul, Markov, & Sakallah

1:

V1
V3

V4

2:
3:

V2

4:
(a)

(b)

V1

V1
V3

V2

V4

V3

(1,0,2,1)

V2

V4

(1,2,1,0)

(c)

V1

V1
V3

V2

V4

V3

(1,1,2,0)

V2

V4

(2,1,1,0)

(d)

V1

V1
V3

V2

V3

V4

(2,1,1,0)

V2

V4

(1,1,2,0)

(e)

Figure 1: Instance-independent symmetry breaking predicates (SBPs).
Part (a) shows the original graph with no vertices colored.
Part (b) shows the color key. Part (c) shows how nullcolor SBPs prevent color 4 from being used. Part (d) shows
how cardinality based SBPs assign colors in the order of independent set sizes, allowing fewer assignments than nullcolor SBPs. Part (e) demonstrates how lowest-index ordered
SBPs break symmetries that are undetected by other types
of SBPs.
304

Breaking Instance-Independent Symmetries in Exact Graph Coloring

an instance of K−coloring because any color can be swapped with a null color. Null colors
are extraneous because they are not actually required to color any vertices, and so can be
inserted anywhere in a solution, as seen above. We propose a construction that enforces
an ordering on null colors: null colors may appear only at the end of a color assignment,
after all non-null colors. This is implemented by adding K − 1 CNF constraints of the form:
yk+1 ⇒ yk for 1 ≤ k ≤ K − 1, to the original formulation. In the example above, only one of
the four symmetric assignments (1, 3, 2, 0) would be allowed under this construction. Since
our ILP formulation defines and sets the K indicator variables that track color usage, it is
extremely easy to enforce null color elimination as described above. The SBPs require the
addition of no extra variables and only K − 1 new CNF clauses.
We prove that the proposed construction is correct. Assume that under the original
formulation, an optimal solution for graph G(V, E) uses m colors. Assume that this solution
contains null colors and non-null colors, and with null-color elimination, there is a different
optimal solution that uses m0 colors, where m 6= m0 . The only colors used in this solution
are 1 . . . m0 , since null colors cannot occur before non-null colors. Since our construction
adds SBPs without changing the original constraints, any legal solution that satisfies the
SBPs will satisfy all constraints in the original formulation. The solution to the original
satisfies all constraints in the new formulation except the SBPs. If m < m 0 , we can re-order
the solution so that all null colors are placed last. This will satisfy all SBPs and use m
colors, where m < m0 , violating the assumption that the m 0 -color solution was optimal. If
m0 < m, we already have a solution that satisfies all the original constraints and uses fewer
colors, which again violates assumptions of optimality.
An illustration of the use of NU predicates for the example in Figure 1 (a) is shown in
Figure 1 (c). The figure shows two valid minimal-color assignments to the graph vertices in
the example. The assignment on the left uses colors 1, 3 and 4, while the one on the right
uses colors 1, 2 and 3. The assignments are symmetric but under NU predicates only the
right-hand side assignment is permissible.
3.2 Cardinality-Based Color Ordering (CA)
Null-color elimination is useful only in cases where null colors exist. For a K−coloring
problem where all colors are needed, the construction breaks no symmetries. Even when
null colors exist, several symmetries go undetected. In the first example from above, nullcolor elimination permits six symmetric color assignments (1, 2, 3, 0), (1, 3, 2, 0), (2, 1, 3, 0),
(2, 3, 1, 0) (3, 2, 1, 0) and (3, 1, 2, 0). This is because restrictions are placed on null colors,
but the ordering of non-null colors is unrestricted. A stronger construction would distinguish between the independent sets themselves. We propose an alternative construction,
which assigns colors based on the cardinality of independent sets. This subsumes null-color
elimination, since null colors can be viewed as coloring sets of cardinality 0. The cardinality rule is implemented as follows: the largest independent set is assigned the color 1,
the second-largest the color 2, etc. In the example above, only the assignment (3, 2, 1, 0) is
P
P
valid. This is enforced by adding K −1 PB constraints of the form: ni=1 xi,k ≥ ni=1 xi,k+1 ,
where 1 ≤ k ≤ K − 1. Again, this construction is fairly simple to implement, requiring
only K − 1 additional constraints. However, these are 0-1 ILP constraints with multiple
305

Ramani, Aloul, Markov, & Sakallah

variables, unlike the simple CNF implication clauses between two variables used for the NU
predicates. Thus, there is some overhead for greater completeness.
We prove the CA construction correct as follows. Assume an optimal solution under
this construction uses m < K colors: (n 1 , n2 , . . . , nm ), where (n1 ≥ n2 . . . ≥ nm ). Colors
> m are not used on any vertex, Assume there exists an optimal solution to the original
formulation that uses m0 colors: (n0 1 , n0 2 , . . . , n0 m0 ), (where n0 1 , etc. are not arranged in
descending order). Without loss of generality, assume that m 0 < m. We can sort the
numbers n0 1 , . . . , n0 m0 and reassign colors in descending order. We would have a solution
with m0 colors satisfying cardinality constraints. However, m 0 < m, which is not possible if
the m−color solution was optimal. A similar argument applies when m < m 0 .
For the example from Figure 1 (a), only the largest independent set under the partition
we are considering, i.e. {V1 , V4 } can be given color 1. Therefore, the assignment on the right
of Figure 1 (c), which assigns the largest set color 2 and is correct under NU predicates,
is incorrect under the CA construction. The left-hand side of Figure 1 (d) shows another
assignment that is correct under NU predicates but incorrect under CA predicates, since
it assigns the set {V1 , V4 } color 3. A correct assignment, shown on the right-hand side of
Figure 1 (d), gives the largest set color 1 and since both the other sets have one element each,
they can each be assigned either color 2 or color 3. Thus, several symmetric assignments
which survive NU predicates are prohibited under this construction.
3.3 Lowest Index Color Ordering (LI)
While more complete than NU predicates, CA predicates do not break symmetries when
different independent sets have the same cardinality. Consider a graph G where V =
{v1 , . . . , v8 }, and an optimal solution, satisfying cardinality-based ordering, that partitions
V into 4 independent sets: S1 = {v4 , v6 , v7 }, S2 = {v1 , v5 }, S3 = {v3 , v8 }, S4 = {v2 }. A
solution that assigns colors 2 and 3 to S 2 and S3 is symmetric to one that assigns colors 2
and 3 to S3 and S2 . Both are legal under cardinality-based ordering. In order to completely
break symmetries, it is not adequate to distinguish between sets solely on the basis of
cardinality (unless no two sets have the same cardinality). It is necessary to construct
SBPs based on the actual composition of sets in a partition, which is unique. However,
the distinctions that we make on the basis of composition are not to be confused with
instance-dependent SBPs, since our construction is implemented before the symmetries in
an instance are known, and regardless of its actual composition. The SBPs here specify
broad guidelines for the coloring of independent sets that are applicable to all graphs. To
improve upon cardinality-based ordering, we propose a set of predicates to enforce the
lowest-index ordering (LI). Consider all vertices with color i, and find the lowest index j i
among those. We require that the lowest indices for each color be ordered. This constraint
can be enforced by adding inequalities for colors with adjacent numbers.
Note that each color has a unique lowest-index vertex — otherwise some vertex would
have to be colored with two colors. In the above example, the only color assignment
compatible with the partitioning of vertices into independent sets is: color 1 to S 1 , 2 to S3 ,
3 to S4 , and 4 to S2 .
To evaluate the strength of this symmetry-breaking technique, consider an arbitrary
coloring and a color permutation that remains a symmetry after the LI constraints are
306

Breaking Instance-Independent Symmetries in Exact Graph Coloring

imposed. If any colors are permuted simultaneously on all vertices, this will permute the
lowest indices for those colors. Since all lowest indices are different, their ordering is completely determined by the ordering of colors, and thus the color permutation we chose must
be the identity permutation. In other words, no instance-independent symmetries remain
after symmetry-breaking with LI.
We implement lowest-index color ordering as follows. For each vertex v i , we declare a
new set of K variables, Vi,1 , . . . Vi,K . Variable Vi,k being set implies that vertex vi is the
lowest-index
V vertexcolored with color k. This is enforced by the following CNF constraints:
i−1
Vi,k ⇒
j=1 Vj,k . Also, exactly one Vi,j variable must be true for every color used.
W
Therefore, we add the constraints: y k ⇒ ni=1 Vi,k , where 1 ≤ k ≤ K, yk are the variables
that indicate color k is used, and n = |V | from Section 2. Finally,
W the following
 CNF
n
clause is added for each Vi,k to ensure lowest-index ordering: V i,k ⇒
j=i+1 Vj,k−1 , Since
the LI ordering completely breaks symmetries between independent sets, it subsumes earlier
constructions. However, it does come at an added cost. While the NU and CA constructions
required no new variables and only K − 1 constraints, the LI construction requires nK new
variables and an additional 2nK CNF clauses, which is almost double the size of the original
formula.
The LI construction can be proved correct by the same means as the CA construction.
Given an optimal assignment of colors to independent sets, we can sort the independent sets
in order of lowest-index vertex and assign colors from 1 to K accordingly, without affecting
correctness.
Figure 1 (e) illustrates the effect of LI SBPs on the example in Figure 1 (a). The graph
on the left, which is shown as being correct for CA predicates in Figure 1 (d) is incorrect
under the LI construction, because the lowest-index vertex with color 2 (V 3 ) does not have a
higher index than the lowest-index vertex with color 3, which is V 2 . The graph on the right
shows the correct assignment, which under LI predicates is the only permissible assignment
for the partition {{V3 }, {V2 }, {V1 , V4 }}.
In addition to being very complex, LI predicates are so rigid that they obscure symmetries of the original instance. For example, in Figure 1 (a), it is easily seen that the vertices
V1 and V2 are symmetric and can be permuted with no effect on the resulting graph. This
symmetry is instance-dependent - it is decided by the way V 1 and V2 are connected. Without the addition of any SBPs, it is apparent that under any legal coloring of the graph, the
colors given to V1 and V2 can be swapped regardless of how V3 and V4 are colored. The NU
predicates preserve this symmetry, since they are only concerned with null colors which by
definition could not be used on V1 and V2 . The CA predicates also preserve the symmetry
since V1 and V2 can be interchangeably used in any independent set, and swapping them
between sets would not have any effect on the cardinality of the sets. However, under the
LI predicates, an independent set containing V 1 must always be given a higher-numbered
color than a set containing V2 , and the two cannot be interchanged. If V 1 was given any
color other than the highest color in use, there would exist some independent set whose
color index was 1 greater than the color assigned to V 1 , and for this set, the lowest-index
predicate would not be satisfied. Thus, LI predicates actually destroy any vertex permutations in the graph. This is seen in our empirical results in Section 4, where the addition of
307

Ramani, Aloul, Markov, & Sakallah

LI SBPs leaves no symmetries in any of the benchmarks. This is unusual because ordinarily
benchmarks of reasonable size would contain at least some vertex permutations.
3.4 Selective Coloring (SC)
It is noticeable that the ILP formulation and constraints can be very complex for more
complete SBPs, such as the LI predicates above, which introduce several additional variables
and clauses. This raises the question of whether such a complex construction is actually
counterproductive - it may break symmetries, but require so much effort during search that
the benefit of complete symmetry breaking is lost. To investigate this, we also propose
a simple “heuristic” construction to break some symmetries between vertices while adding
almost no additional constraints. To impact as many vertices as possible, we find the vertex
vl with the largest degree of all vertices in the graph. We then color v l with color 1. This
is achieved by simply adding the unary clause x l,1 . We search vl ’s neighbors to find the
vertex vl0 with the highest degree out of all vertices adjacent to v l . We color vl0 with color
2, by adding the unary clause xl0 ,2 . This construction has the effect of simplifying color
assignment for all vertices adjacent to v l and vl0 . No vertex adjacent to vl can be colored
color 1, and no vertex adjacent to vl0 can be colored color 2. Moreover, all vertices in an
independent set with vl (vl0 ) must be colored color 1 (color 2). If v l and vl0 have sufficiently
large degree, this construction can restrict many vertex assignments. An even stronger
construction would be to find a triangular clique and fix colors for all three vertices in it;
however, clique finding is complicated and some graphs may not possess any such cliques.
We refer to this construction as selective coloring.
The extent to which selective coloring breaks symmetries is instance-dependent. It fails
to completely break symmetries for almost all graphs. However, it is a simple construction,
adding just two constraints as unary clauses. These are easily resolved in pre-processing by
most SAT solvers, so any symmetry breaking achieved by this construction has virtually no
overhead.
We note that all instance-independent predicates defined here are only concerned with
symmetries between colors, which exist in any instance of graph coloring. However, additional instance-independent symmetries may be introduced during the reduction to graph
coloring for certain applications. For example, in the radio frequency assignment application from Section 2, adding all possible bipartite edges between cliques for adjacent regions
will result in symmetries between vertices in these cliques. Additional predicates can be
added to instances from this application to break these symmetries.

4. Empirical Results
This section describes our experimental setup, empirical results, and performance compared
with related work.
4.1 Experimental Setup
We used 20 medium-sized instances from the DIMACS graph coloring benchmark suite. We
briefly describe each family of benchmarks used below.
308

Breaking Instance-Independent Symmetries in Exact Graph Coloring

• Random graphs. Benchmarks with randomly created connections between vertices,
named DSJ
• Book graphs. Edges represent interaction between characters in a book. There are
four such benchmarks: anna, david, huck, jean
• Mileage graphs. These represent distances between cities on a map, and are named
miles
• Football game graphs. Indicate relationships between teams that must play each
other in college football games. In the tables these are referred to as games
• n−queens graphs. Instances of the n−queens problem, named queen
• Register allocation graphs. Represent the register allocation problem for different
systems. We use two families in this work, named mulsol, zeroin
• Mycielski graphs. Instances of triangle-free graphs based on the Mycielski (Mycielski, 1955) transformation, called myciel
Table 1 gives the name, size (number of vertices and edges) and the chromatic number
for each benchmark. We use a maximum value of K = 20 for K−coloring. For benchmarks
with chromatic number > 20, we do not report the chromatic number.
Our problem formulation with a fixed K is application-driven. Indeed, in many domains it is only useful to find the exact chromatic number when it is below a well-known
threshold. For example, in graph coloring instances from register allocation, there cannot
be more colors than processor registers. PC processors often have 32 registers, and high-end
CPUs may have more. However, realistic graphs are relatively sparse and have low chromatic numbers. On the other hand, processors embedded in cellular phones, automobiles
and point-of-sale terminals may have very few registers, leading to tighter constraints on
acceptable chromatic numbers. The value K = 20 used in our experiments is in no way
special, but the results achieved with it are representative of other results. Also, while we
apply the K = 20 bound to all instances here to study trends, more reasonable bounds can
be determined on a per-instance basis using the following simple procedure.
1. Apply any heuristic for min-coloring to determine a feasible upper bound
2. If the value is relatively small, perform linear search by incrementally tightening the
color constraint, otherwise perform binary search
Benchmark graphs are transformed into instances of 0-1 ILP using the conversion described in Section 2. To solve instances of 0-1 ILP, we used the academic 0-1 ILP solvers
PBS (Aloul et al., 2002), Galena (Chai & Kuehlmann, 2003), and Pueblo (Sheini, 2004),
and also the commercial ILP solver CPLEX version 7.0. Pueblo is more recent than PBS
and Galena, and incorporates Pseudo-Boolean (PB) learning based on ILP cutting-plane
techniques. We use a later version of PBS, PBS II, that enhances the original PBS algorithms (Aloul et al., 2002) with learning techniques from the Pueblo solver (Sheini, 2004).
We do not include the results with the original version of PBS that are reported in (Ramani,
309

Ramani, Aloul, Markov, & Sakallah

Instance
anna
david
DSJC125.1
DSJC125.9
games120
huck
jean
miles250
mulsol.i.2
mulsol.i.4
myciel3
myciel4
myciel5
queen5 5
queen6 6
queen7 7
queen8 12
zeroin.i.1
zeroin.i.2
zeroin.i.3

#V
138
87
125
125
120
74
80
128
188
185
11
23
47
25
36
49
96
211
211
206

#E
986
812
1472
13922
1276
602
508
774
3885
3946
20
71
236
320
580
952
2736
4100
3541
3540

K
11
11
5
> 20
9
11
10
8
>20
>20
4
5
6
5
7
7
12
>20
>20
>20

Table 1: DIMACS graph coloring benchmarks

Aloul, Markov, & Sakallah, 2004), since it has been retired by the newer version. However,
in the Appendix we report detailed results for n− queens instances using the older version of
PBS along with results for the other solvers, for the sake of a more detailed study. PBS II is
implemented in C++ and compiled using g++. Galena and Pueblo binaries were provided
by the authors. PBS was run using the variable state independent decaying sum (VSIDS)
decision heuristic option (Moskewicz et al., 2001). Galena was run using its default options
of linear search with cardinality reduction (CARD) learning. All experiments are run on
Sun-Blade-1000 workstations with 2GB RAM, CPUs clocked at 750MHz and the Solaris
operating system. Time-out limits for all solvers are set at 1000 seconds.
We use the symmetry breaking flow first proposed in our earlier work (Aloul et al.,
2004) to detect and break symmetries in our original ILP formulation from Section 2. This
flow uses the tool Shatter (Aloul et al., 2003), which uses the Saucy (Darga et al., 2004)
graph automorphism program and the efficient SBP construction from (Aloul et al., 2003).
We also check for unbroken symmetries in formulations produced by each of the instanceindependent constructions described in Section 3. Our runtimes for symmetry detection
and for solving the reduced 0-1 ILP problems are reported in the next section.
4.2 Runtimes for Symmetry Detection and 0-1 ILP Solving
Table 2 shows symmetry detection results and runtimes. The numbers reported in the table
are sums of individual results for all 20 benchmarks used. We report statistics as sums
because reporting results for all of SBPs on all benchmarks would be space-consuming, and
310

Breaking Instance-Independent Symmetries in Exact Graph Coloring

SBP
Type
no SBPs
NU
CA
LI
SC
NU+SC

#V
437K
437K
437K
870K
437K
437K

CNF Stats
#CL
777505
777885
777505
4019980
777545
777925

# PB
3193
3193
3630
3193
3193
3193

Sym. Stats (SAUCY)
#S
#G Time
1.1e+168 994
185
5.0e+149 614
49
5.0e+149 614
49
2.0e+01
0
84
3.0e+164 941
167
5.0e+148 597
47

Table 2: CNF formula sizes, symmetry detection results
and runtimes, totaled for 20 benchmarks from
Table 1, with K = 20. NU = null-color elimination; CA = cardinality-based; LI = lowest-index;
SC = selective coloring. For the LI SBPs, one instance of the “do-nothing” symmetry is counted
in each case, giving a total of 20 symmetries and
0 generators. Saucy is run on an Intel Xeon dual
processor at 2 GHz running RedHat Linux 9.0.

would also not illustrate trends as clearly. This work is concerned with characterizing the
broad impact of symmetry breaking. However, we show detailed results for the queens
instances in the Appendix.
The first column in the table indicates the type of construction: we use no SBPs for
the basic formulation, NU for null-color elimination, CA for cardinality-based ordering,
LI for lowest-index ordering, and SC for selective coloring (the last row shows NU and SC
in combination). The next three columns show the number of variables, CNF clauses, and
PB constraints in the problems. The last three columns show the number of symmetries,
number of symmetry generators, and symmetry detection runtimes for Saucy. Henceforth,
we will refer to instance-dependent SBPs as external, because they are added to an instance after symmetries are detected and are not part of the problem formulation. The top
row is separated from the bottom 5 rows because it represents statistics without instanceindependent SBPs. We observe that adding instance-independent SBPs during problem
formulation does cut down the symmetry detection runtime considerably. Saucy has a total runtime of 185 seconds when no instance-independent SBPs are added, but its runtimes
with NU, CA, LI and NU + SC constructions are much smaller. Only the SC construction
has a comparable runtime because it is a heuristic and breaks very few symmetries. The
columns showing numbers of symmetries and generators support this observation: the NU,
CA, LI and NU + SC constructions all have far fewer symmetries than the top row, but the
SC construction has almost the same number. For these benchmarks, the LI construction,
breaks all symmetries, even instance-dependent vertex permutations that may exist in a
graph. Saucy reports finding no symmetries for this construction (except one instance of
the do-nothing symmetry for each graph, which is trivial). However, Saucy runtimes for
this construction are larger than for the NU, CA and NU + SC constructions (85 seconds
to approximately 49 seconds) even though there are no symmetries in the instances after LI
311

Ramani, Aloul, Markov, & Sakallah

SBP
Type
no SBPs
NU
CA
LI
SC
NU+SC

PBS II, PB Learning
Orig.
w/i.-d. SBPs
Tm.
#S
Tm.
#S
17K
8.2K
13K
15K
14K
6.9K

3
13
6
6
6
14

4.2K
7.5K
12K
15K
65
6.8K

16
13
8
6
20
14

CPLEX
Orig.
w/i.-d. SBPs
Tm.
#S
Tm.
#S
6.3K
5.9K
11K
16K
5.3K
4.5K

14
15
11
4
15
16

13K
6.5K
11K
16K
12K
6.4K

7
15
10
4
8
14

Galena
Orig.
w/i.-d. SBPs
Tm.
#S
Tm.
#S
1.7K
8.3K
19K
15K
16K
6.1K

2
11
1
5
4
14

3K
6.7K
17K
15K
94.4
6.1K

17
11
3
5
20
14

Pueblo
Orig.
w/i.-d. SBPs
Tm.
#S
Tm.
#S
18K
9.1K
9K
16K
15k
7.3K

3
12
12
5
5
13

1.6K
8.3K
10K
16K
2.1K
7.1K

Table 3: Runtimes and number of solutions found before and after SBPs are added
for all constructions using PBS II (with PB learning), CPLEX, Galena and
Pueblo; all experiments are run on SunBlade 1000 workstations. Timeouts
for all solvers were set at 1000s. The maximum color limit is set at 20,
instances with k > 20 are unsatisfiable under these formulations. This is
not a comparison of solvers. We solve ILP formulations with equal optimal
values using different solvers to weed out solver-specific issues. Best results
for a given solver are shown in boldface. In the entries, K denotes multiples
of 1000s seconds rounded to the nearest integer.

predicates are added. A likely reason for this is the sharp increase in instance size caused
by the LI construction. In general, the SC construction has very little effect on the number
of symmetries - when used by itself, it leaves most symmetries intact, and when used with
the NU construction, the improvement over the NU construction alone is very small.
Table 3 shows the effect of symmetry breaking on runtimes of PBS II (Aloul et al., 2002),
CPLEX (ILOG, 2000), Galena (Chai & Kuehlmann, 2003) and Pueblo (Sheini, 2004). The
first column in the table specifies the construction type, followed by the total runtime for
each solver (with and without the addition of instance-independent SBPs) and the number
of instances solved for the construction. For each solver, the best performance among all
configurations (largest number of instances solved and corresponding runtime) is boldfaced.
Results are given first for the new version of PBS, PBS II based on (Sheini, 2004), followed
by CPLEX, Galena and Pueblo. Runtimes for the older version of PBS can be obtained
from our earlier work (Ramani et al., 2004). To compare performance of an individual solver
for different constructions, observe the runtime and solution entries for different rows in the
same column, and to compare performance for different solvers on the same constructions,
observe numbers for the same row across all columns. We observe the following trends.
1. All benchmarks possess a large number of symmetries. Different instance-independent
SBPs achieve varying degrees of completeness: the lowest-index ordering (LI) breaks
all symmetries in the benchmarks used, while the selective coloring (SC) SBP breaks
the fewest symmetries. Saucy runtimes for residual symmetry detection after the
addition of instance-independent SBPs are highest for the no SBPs construction and
the SC construction, since they possess the largest numbers of symmetries
2. For the case where no SBPs of any kind are added, CPLEX performs well, solving
14 out of 20 instances within the time limit. However, PBS II, Galena and Pueblo
perform poorly - Galena solves only 2 instances and PBS II and Pueblo each solve 3
312

19
13
12
5
18
13

Breaking Instance-Independent Symmetries in Exact Graph Coloring

3. PBS II, Galena and Pueblo benefit considerably from instance-dependent symmetry
breaking. When instance-dependent SBPs are used without any of the instanceindependent constructions we propose, PBS II solves 16 instances within the time
limit, while Galena and Pueblo solve 17 and 19 instances respectively. However,
CPLEX is hampered by the addition of instance-dependent SBPs, and solves only 7
instances in this case
4. Adding only instance-independent SBPs improves performance for all specialized 01 ILP solvers over the no-SBP version. The best performance for PBS II, Galena
and Pueblo is seen for the NU + SC construction - PBS II and Galena solve 14
instances, and Pueblo solves 13. For CPLEX, the NU + SC construction shows
marginal improvement over the no-SBPs case (16 instances are solved), but the more
complex constructions, CA and LI, actually undermine performance - CPLEX solves
only 4 instances with the LI construction. In general, complex SBP constructions
perform much worse than simple ones. PBS II, Pueblo and Galena also perform
poorly with the CA and LI constructions - Galena solves only 1 instance with the CA
construction with no help from instance-dependent SBPs, and very few instances are
solved with the LI construction for any solver
5. Adding instance-independent SBPs alone does not solve as many instances as adding
instance-dependent SBPs to the SBP-free formulation. The best performance seen
with instance-independent SBPs is 14 instances solved, by Galena and PBS II, and
16 instances solved by CPLEX, with the NU + SC construction. When instancedependent SBPs are added PBS II and Galena solve all 20 instances with the SC
construction. The CA and LI constructions leave very few (or none at all) symmetries
to be broken by instance-dependent SBPs. Consequently, there is almost no difference
in results with and without instance-dependent SBPs for these constructions. However, they do not achieve the same performance improvements as instance-dependent
SBPs, due to their size and complexity
6. Using instance-dependent SBPs in conjunction with the SC construction is useful.
With this combination, PBS II and Galena solve all 20 instances within the time
limit, and Pueblo solves 18. Runtime is also considerably improved for PBS II and
Galena – PBS II solves all 20 instances in a total of 65 seconds, and Galena in 94.4
seconds. The best overall performance, in terms of number of solutions and runtime, is
seen with this combination. In general, however, the SC construction is not dominant
on its own. Results for the SC construction alone are very similar to results with no
SBPs, and results for the NU + SC combination are very similar to those achieved by
using only NU SBPs. The SC construction is effective at “boosting” the performance
of other constructions
7. The three specialized 0-1 ILP solvers - PBS II, Galena and Pueblo, exhibit the same
performance trends with respect to the constructions used, and their performances
are all comparable, in terms of both the number of solutions found and runtime This
indicates that the variations in performance are due to the different SBPs, not due to
differing solver implementations. All solvers are independent implementations based
313

Ramani, Aloul, Markov, & Sakallah

SBP
Type

PBS II, PB Learning
Orig.
w/i.-d. SBPs
Tm.
#S
Tm.
#S

No SBPs
NU
CA
LI
SC
NU + SC

18K
9.2K
13K
15K
15K
7.1K

2
12
7
5
5
13

6.2K
7.9K
13K
15K
5.3K
7.0K

14
13
9
5
15
13

CPLEX
Orig.
w/i.-d. SBPs
Tm.
#S
Tm.
#S
11K
11K
13K
19K
10K
9.7K

9
9
9
2
10
11

8.2K
12K
14K
19K
12K
9.9K

12
8
8
2
9
11

Galena
Orig.
w/i.-d. SBPs
Tm.
#S
Tm.
#S
19K
10K
19K
16K
16K
9.2K

1
10
1
5
4
12

9.1K
7.6K
17K
16K
5.3K
6.9K

11
13
4
5
15
14

Pueblo
Orig.
w/i.-d. SBPs
Tm.
#S
Tm.
#S
19K
11K
11K
17K
16K
8.0K

1
11
11
3
4
13

7.5K
9.5K
13K
17K
6.0K
7.4K

Table 4: Total runtimes and number of solutions found before and after SBPs are
added for all constructions using PBS II (with PB learning), CPLEX,
Galena and Pueblo. The experimental setup is the same as that used in
Table 3 but with a color limit of K = 30. Best results for a solver are boldfaced. Fewer instances are solved than in Table 3 because the higher color
limit results in larger and potentially more difficult instances.

on the same algorithmic framework (the Davis-Logemann-Loveland backtrack search
procedure), but PBS II and Galena also have learning capabilities
8. Adding instance-dependent SBPs to any construction usually adversely affects the
performance of CPLEX. This has been previously noted in other work (Aloul et al.,
2004). Since the CPLEX algorithms and implementation are not available in the
public domain, it is difficult to account for this effect. However, PBS and Galena with
symmetry breaking significantly outperform CPLEX without symmetry breaking
9. We report results as the sum of runtimes for all instances to illustrate trends. On
a per-instance basis, the same trends are displayed. For example, for the no-SBPs
case in the top row, PBS II solves 3 instances and Galena solves 2, but the two
instances solved by Galena are among those solved by PBS II. In general, the same
instances tend to be “easy” or “difficult” for the 0-1 ILP solvers, although CPLEX
behaves differently. An example of this behavior for the queens family of instances is
illustrated in the Appendix
Overall, the results suggest that for graph coloring, adding instance-independent SBPs alone
is not competitive with the use of instance-dependent SBPs alone. The best results are
achieved using a combination of both types, and even here, the instance-independent SBPs
used are the most simple variety. This is true even when symmetry detection runtimes are
taken into consideration. We attribute this result to the complexity of instance-independent
SBPs we use, and also to the fact that improvements in graph automorphism software
(Darga et al., 2004) have greatly reduced the overhead of detecting symmetries by reduction
to graph automorphism. Previously, for static approaches that require symmetries to be
detected and broken in advance, the task of symmetry detection was often a bottleneck
that could actually take longer than the search itself. With this bottleneck removed, the
advantages of static symmetry breaking - simple predicates that address specific symmetries
rather than complex constructions that alter the problem specification considerably - are
more clearly illustrated. Even among instance-independent predicates, simple constructions
are more effective than complex ones. As we have noted in Section 3, simple constructions
314

13
11
8
3
15
13

Breaking Instance-Independent Symmetries in Exact Graph Coloring

like NU and SC add very few additional constraints and do not alter the original problem
greatly. However, the CA and LI constructions add many more constraints, which may
confuse the specialized 0-1 ILP solvers.
It is important to note that color permutations, while instance-independent, do appear at the instance-specific level. Thus, the symmetries targeted by instance-independent
predicates are a subset of those targeted by instance-dependent predicates. Our instanceindependent constructions are not intended to cover a different set of symmetries, but rather
to break some of the same symmetries during problem formulation, thus reducing or eliminating the overhead of any instance-dependent methods that may follow. The fact that
this strategy is not successful suggests that, for the same set of symmetries, the instancedependent predicates we use are more efficient and easier for solvers to tackle.
To verify our claims about performance trends, we show results for an additional set of
experiments with increased color limit K = 30 in Table 4. The instances are re-formulated
with K = 30 and with different SBP constructions. This experiment is intended to verify
trends from the K = 20 case, and to investigate whether instances with chromatic number
> 20, that are unsatisfiable in the first case, can be colored with ≤ 30 colors. Results
from Table 4 validate our observations from Table 3 – the best results for PBS II, Galena
and Pueblo are again achieved with the NU + SC (with no instance-dependent SBPs) and
SC (with instance-dependent SBPs) constructions. However, with this formulation fewer
instances are solved than for the K = 20 case, possibly because the K = 30 limit results
in larger instances. Also, for instances whose chromatic number is much closer to 30 than
20, it may be harder to prove optimality, whereas proving unsatisfiability for the K = 20
experiments may be simpler.
4.3 Comparison with Related Work
Here, we discuss the empirical performance of our approach when compared with related
work (Coudert, 1997; Benhamou, 2004). We note that both cited works describe algorithms
specifically developed for graph coloring, and the search procedures cannot be used to solve
other problems. Our approach, on the other hand, solves hard problems by reduction to
generic problems such as SAT or 0-1 ILP, and this work on graph coloring can be viewed as a
case study. Consequently, we use problem-specific knowledge only during the actual problem
formulation (instance-independent SBPs are also added during reduction), but not during
search itself. This may be useful for applications where problem-specific solvers cannot be
developed or acquired due to limited resources. Our goal is to determine whether symmetry
breaking can improve the performance of reduction-based methods, which are traditionally
not competitive with problem-specific methods. Thus, while our techniques may not be
superior to all problem-specific solvers on all instances, we hope to show reasonably strong
performance over a broad spectrum of instances.
Common data points between our work and Coudert’s (Coudert, 1997) include instances
of queens, myciel and DSCJ125.1. Referring to our detailed results for queens instances in
the Appendix, we note that our runtimes are competitive with those of Coudert’s algorithm
- for example, on queen5 5, both algorithms have a runtime of 0.01s. On larger instances,
however, our runtimes are somewhat slower. On the myciel instances, we obtain the best
results with the Pueblo solver and the SC predicates, with runtimes of 0.01, 0.06, and 1.80s
315

Ramani, Aloul, Markov, & Sakallah

on myciel3, 4, and 5, compared with 0.01, 0.02 and 4.17 for Coudert’s algorithm. Therefore,
it appears that our approach is competitive on these common data points. Moreover, other
studies (Kirovski & Potkonjak, 1998) have observed that Coudert’s work does not provide
results for several hard real-world problem classes, particularly those where modeling results
in dense graphs. Our work is more general, and cannot be biased to favor certain types of
graphs.
The algorithm described by Benhamou (Benhamou, 2004) shows very competitive runtimes on a number of DIMACS benchmarks, particularly instances of register allocation.
For example, the DSJC125.1 instance is solved by Benhamou’s algorithm in 0.01 seconds,
while the best time achieved by us is 1.12 seconds, using the Pueblo solver with only
instance-dependent SBPs. However, we note that Benhamou’s algorithm determines the
upper limit for the chromatic number K using more instance-specific knowledge, for example, for DSCJ125.1, it is set at K = 5. We solve all instances with K = 20, which may be
too large a limit in some cases. The value of K affects the size of the resulting 0-1 ILP
reductions and SBPs, which is likely to affect runtime. We also note that the DIMACS
benchmarks used in the cited work (Benhamou, 2004) are primarily register allocation and
randomly generated instances, whereas we achieve reasonably good performance on a wide
variety of benchmark applications. Moreover, Benhamou’s approach relies on modeling
graph coloring as a not-equals CSP, which does not bode well for generality. Many CSPs
cannot be modeled using only not-equals constraints. Additionally, the symmetry detection, breaking and search procedures described in that work are specific to graph coloring,
whereas our work can be extended to several other problems, only requiring a reduction to
SAT/0-1 ILP.

5. Conclusions
Our work shows that problem reduction to 0-1 ILP is a viable method for optimally solving
combinatorial problems without investing in specialized solvers. This approach is likely to
be even more successful as the efficiency of 0-1 ILP solvers improves in the future, and as
they are able to better handle problem structure. In particular, problem reductions may
produce highly-structured instances making the ability to automatically detect and exploit
structure very important. In the case of graph coloring we demonstrate that a generic,
publicly-available symmetry breaking flow from our earlier work (Aloul et al., 2004) significantly improves empirical results in conjunction with the academic 0-1 ILP solvers PBS II,
a new version of the solver PBS (Aloul et al., 2002), Galena (Chai & Kuehlmann, 2003) and
Pueblo (Sheini, 2004). All specialized 0-1 ILP solvers significantly outperform the commercial generic ILP solver CPLEX 7.0 when symmetry-breaking is used. The performance of
CPLEX actually deteriorates when SBPs are added, and on the original instances with no
SBPs, CPLEX is able to solve more instances than the 0-1 ILP solvers. However, the best
performance overall is obtained with the 0-1 ILP solvers on instances with SBPs added.
Although our techniques are tested on standard DIMACS benchmarks instances, we note
that the symmetry-breaking flow described here can be applied to graph coloring instances
from any application.
We are particularly interested in comparing strategies for breaking symmetries that are
present in every ILP instance produced by problem reduction (instance-independent sym316

Breaking Instance-Independent Symmetries in Exact Graph Coloring

metries). Such symmetries may be known even before the first instances of the original
problem are delivered (i.e., symmetries may be detected at the specification level), and
one has the option to use them during problem reduction. Intuitively, this may prevent
discovering these symmetries in every instance and thus improve the overall CPU time. To
this end, we propose four constructions for instance-independent symmetry breaking predicates (SBPs). These constructions vary in terms of strength and completeness. Our goal
in experiments was to compare the performance of the four instance-independent SBP constructions relative to each other, as well as to assess their performance when compared with
instance-dependent SBPs. Instance-independent SBPs have the advantage of not requiring
the additional step of symmetry detection, since they are part of the problem specification.
Additionally, they are designed with more information about the problem itself, and their
effect on solutions is clear - for example, we know that null-color elimination will force all the
lower-numbered colors to be used in a solution. Instance-dependent SBPs are detected and
added automatically on the 0-1 ILP reduction of an instance without any understanding
of their significance. On the other hand, instance-dependent constructions are less complex and result in more compact predicates. Our empirical data indicate that simplicity
of construction is a more powerful factor in determining performance - instance-dependent
SBPs consistently outperform instance-independent SBPs, and the most complete and complex instance-independent constructions (LI) are actually the weakest in performance. It
is clear from our results that symmetry breaking itself is useful in graph coloring: adding
instance-dependent SBPs always speeds up search over the no-SBPs case. It is likely that
instance-independent SBPs are less successful due to their complex construction. Simpler
instance-independent constructions (NU, SC) outperform the more complex ones (CA, LI).
It is well known that the syntactic structure of CNF and PB constraints may dramatically
affect the efficiency of SAT and ILP solvers. Shorter clauses and PB constraints are much
preferable as they are easier to resolve against other constraints, and are more useful to
the learning strategies employed by exact SAT solvers. Another factor that gives instancedependent SBPs the advantage is the ease of symmetry detection, which was previously a
bottleneck. Due to improved software (Darga et al., 2004), the overhead of symmetry detection via reduction to graph automorphism in SAT/0-1 ILP instances is almost negligible.
We also show that the three specialized 0-1 ILP solvers, PBS II, Galena and Pueblo,
all exhibit similar performance trends for different constructions. This indicates that performance is not decided by solver-specific issues, but by the difficulty of the instances and
the SBPs added to them. CPLEX does not display the same behavior as the other solvers,
and is in fact slowed down by the addition of instance-dependent SBPs and by several
instance-independent constructions. CPLEX is a commercial solver for generic ILP problems, and its algorithms and decision heuristics are likely to be very different than those
used by academic solvers. However, since details about CPLEX are not publicly available,
it is not possible to accurately explain its behavior. We do note that while CPLEX does
not appear to benefit from symmetry breaking, its performance on the reduced instances
with no SBPs of any kind is superior to the 0-1 ILP solvers. However, once SBPs are added
the specialized solvers solve more instances than CPLEX in less time.
In the context of generic search and combinatorial optimization problems defined in
the NP-spec language (Cadoli et al., 1999), our empirical data suggest that new theoretical
breakthroughs are required to make use of instance-independent symmetries during problem
317

Ramani, Aloul, Markov, & Sakallah

reductions to SAT or 0-1 ILP. At our current level of understanding, the simple strategy
of processing instance-independent and instance-dependent symmetries together produces
smallest runtimes for graph coloring benchmarks. Our current and future work is focused
on developing more effective SBPs for this problem, and also investigating the utility of
symmetry breaking for other hard search problems. Moreover, while our work uses instanceindependent predicates only for color symmetries, our results and analysis may have broader
scope, for example, in applications such as radio frequency assignment (Section 2) where
symmetries are introduced during the reduction to graph coloring and are likely to be
preserved during future reductions. The issues involved in using instance-dependent vs.
instance-independent SBPs are very relevant to such applications.

6. Acknowledgments
This work was funded in part by NSF ITR Grant #0205288. Also, we thank Donald Chai
and Andreas Kuehlmann from UC Berkeley for providing us with binaries of the Galena
solver, and Hossein Sheini for providing us with the binaries for Pueblo.

Appendix A: Performance Analysis on Queens Instances
This section provides a more detailed discussion of our results on individual benchmarks
in the queens family of instances. The problem posed by queens instances is whether
queens can be placed on an n × m chessboard without conflicts. The instances we use in
our experiments are queens 5 × 5, 6 × 6, 7 × 7 and 8 × 12. Table 5 shows results for the
queens family. Results are shown for every instance with no SBPs, with each of the four
constructions NU, CA, LI and SC, and with the NU + SC combination. All constructions
are tested with and without instance-dependent SBPs as before. We report results for the
original version of PBS, from (Aloul et al., 2002), and for PBS II, CPLEX, Galena and
Pueblo as in Section 4. Experiments are run on Sun Blade 1000 workstations as before. In
the table, we report solver runtime if an instance is solved, and T/O for a timeout at 1000
seconds. The best results for a solver on a particular instance are boldfaced.
While there is greater variation when considering performance on a per-instance basis,
the table largely reflects the same trends reported in Section 4. For example, when no
instance-dependent SBPs are used, PBS, PBS II, Galena and Pueblo all largely perform
best with the NU + SC construction. When instance-dependent SBPs are added, the best
performance is seen with the SC construction in most cases. CPLEX does not display the
same behavior as the other solvers, and its performance clearly deteriorates when instancedependent SBPs are added to any construction. A similar effect has been observed in related
work (Aloul et al., 2004). Results for the original version of PBS (Aloul et al., 2002), which
could not be included in Section 4, have been added in this section. It can be seen that
PBS follows the same trends as PBS II, Galena and Pueblo, reinforcing our claim that this
behavior is not solver-dependent.
318

Breaking Instance-Independent Symmetries in Exact Graph Coloring

Inst.
Name

queen5 5

queen6 6

queen7 7

queen8 12

SBP
Type
no SBPs
NU
CA
LI
SC
NU + SC
no SBPs
NU
CA
LI
SC
NU + SC
no SBPs
NU
CA
LI
SC
NU + SC
no SBPs
NU
CA
LI
SC
NU + SC

PBS
Inst.-dep.
SBPs used?
No
Yes
T/O
0.19
1.84
T/O
T/O
T/O
135
134.71
15.99
0.19
8.63
12.34
T/O
3.61
331.63
521.12
T/O
T/O
T/O
T/O
T/O
0.58
2.89
1.72
T/O
36.56
0.45
3.29
T/O
T/O
T/O
T/O
T/O
8.42
5.65
38.07
T/O
1.31
T/O
T/O
T/O
T/O
T/O
T/O
T/O
1.05
T/O
T/O

PBS II
Inst.-dep.
SBPs used?
No
Yes
34.52
0.04
0.01
0.02
0.31
0.24
1.48
1.48
0.15
0.07
0
0.01
T/O
0.21
56.63
13.59
50.6
780.57
T/O
T/O
T/O
0.1
1.4
0.63
T/O
1.79
36.31
24.74
T/O
T/O
53.3
53.4
38.57
0.85
4.37
5.73
T/O
0.52
T/O
T/O
T/O
T/O
T/O
T/O
T/O
0.47
787.26 780.14

CPLEX
Inst.-dep.
SBPs used?
No
Yes
1.11
643.93
1.38
23.67
39.2
2.76
262.96
217.21
0.45
229.79
0.83
0.88
T/O
T/O
T/O
T/O
T/O
T/O
T/O
T/O
242.79
T/O
95.91
T/O
243.3
T/O
119.16 459.44
271.2
T/O
T/O
T/O
38.04
T/O
119.7
T/O
T/O
T/O
T/O
T/O
T/O
T/O
T/O
T/O
T/O
T/O
T/O
T/O

Galena
Inst.-dep.
SBPs used?
No
Yes
83.06
0.35
0.21
0.27
T/O
T/O
5.4
5.4
0.29
0.29
0.3
1
T/O
0.87
192.17
19.11
T/O
T/O
T/O
T/O
T/O
1.0
11.19
1.05
T/O
T/O
56.6
147.52
T/O
T/O
78.85
78.8
T/O
1.33
17.46
5.16
T/O
T/O
T/O
138.61
T/O
T/O
T/O
T/O
T/O
1.9
52.1
53.63

Pueblo
Inst.-dep.
SBPs used?
No
Yes
203.09
0.01
0.08
0.1
0.14
0.52
8.48
8.48
0.25
0.19
0.06
0.07
T/O
0.49
123.99
18.88
196.94
80.53
T/O
T/O
T/O
0.32
4.85
2.64
T/O
1.13
9.59
15.49
692.67
150.86
212.18
213.8
217.82
1.23
25.73
14.04
T/O
T/O
T/O
T/O
T/O
T/O
T/O
T/O
T/O
0.98
T/O
T/O

Table 5: Detailed results for queens instances. For each instance, we show results
for the solvers PBS, PBS II, CPLEX, Galena and Pueblo. All solvers
are run on SunBlade 1000 workstations. Instances are tested with no
instance-independent SBPs, with each of the four proposed constructions
in Section 3 and with a combination of the NU and SC constructions. All
instance-independent SBPs are tested alone and with instance-dependent
SBPs added. The table shows the runtime for a given instance under different construction. T/O indicates a timeout at 1000 seconds. Best results
for a given solver on each instance are shown in boldface.

References
Aloul, F. A., Markov, I. L., & Sakallah, K. A. (2003). Shatter: Efficient symmetry-breaking
for boolean satisfiability. In International Joint Conference on Artificial Intelligence,
pp. 271–282.
Aloul, F. A., Markov, I. L., & Sakallah, K. A. (2004). MINCE: A static global variableordering heuristic for sat search and bdd manipulation. Journal of Universal Computer
Science (JUCS), 10, 1562–1596.
Aloul, F. A., Ramani, A., Markov, I. L., & Sakallah, K. A. (2002). Generic ILP versus
specialized 0-1 ILP: An update. In International Conference on Computer-Aided
Design, pp. 450–457.
Aloul, F. A., Ramani, A., Markov, I. L., & Sakallah, K. A. (2003). Solving difficult instances
319

Ramani, Aloul, Markov, & Sakallah

of boolean satisfiability in the presence of symmetry. IEEE Transactions on CAD,
22, 1117–1137.
Aloul, F. A., Ramani, A., Markov, I. L., & Sakallah, K. A. (2004). Symmetry-breaking for
pseudo-boolean formulas. In Asia-Pacific Design Automation Conference, pp. 884–
887.
Aragon, C. R., Johnson, D. S., McGeoch, L. A., & Schevon, C. (1991). Optimization by
simulated annealing: An experimental evaluation; part ii, graph coloring and number
partitioning. Operations Research, 39, 378–406.
Benhamou, B. (2004). Symmetry in not-equals binary constraint networks. In Workshop
on Symmetry in CSPs, pp. 2–8.
Brelaz, D. (1979). New methods to color vertices of a graph. Communications of the ACM,
22, 251–256.
Brown, R. J. (1972). Chromatic scheduling and the chromatic number problem. Management Science, 19, 451–463.
Cadoli, M., & Mancini, T. (2003). Detecting and breaking symmetries on specifications.
In The Third Annual Workshop on Symmetry in Constraint Satisfaction Problems
(SymCon), pp. 13–26.
Cadoli, M., Palopoli, L., Schaerf, A., & Vasileet, D. (1999). NP-SPEC: An executable specification language for solving all problems in NP. In Practical Aspects of Declarative
Languages, pp. 16–30.
Chai, D., & Kuehlmann, A. (2003). A fast pseudo-boolean constraint solver. In Design
Automation Conference, pp. 830–835.
Chaitin, G. J., Auslander, M., Chandra, A., Cocke, J., Hopkins, M., & Markstein, P. (1981).
Register allocation via coloring. Computer Languages, 6, 47–57.
Chams, M., Hertz, A., & Werra, D. D. (1987). Some experiments with simulated annealing
for coloring graphs. European Journal of Operations Research, 32, 260–266.
Coudert, O. (1997). Coloring of real-life graphs is easy. In Design Automation Conference,
pp. 121–126.
Crawford, J. (1992). A theoretical analysis of reasoning by symmetry in first-order logic.
In AAAI Workshop on Tractable Reasoning at the Tenth National Conference on
Artificial Intelligence.
Crawford, J., Ginsberg, M., Luks, E., & Roy, A. (1996). Symmetry-breaking predicates
for search problems. In 5th International Conference on Principles of Knowledge
Representation and Reasoning, pp. 148–159.
Culberson, J. (2004). Graph coloring page. http://web.cs.ualberta.ca/˜joe/Coloring/index.html.
Darga, P. T., Liffiton, M. H., Sakallah, K. A., & Markov, I. L. (2004). Exploiting structure
in symmetry generation for cnf. In 41st Internation Design Automation Conference,
pp. 530–534.
Davis, M., Logemann, G., & Loveland, D. (1962). A machine program for theorem proving.
Communications of the ACM, 5, 394–397.
320

Breaking Instance-Independent Symmetries in Exact Graph Coloring

Fahle, T., Schamberger, S., & Sellmann, M. (2001). Symmetry breaking. In 7th International
Conference on Principles and Practice of Constraint Programming, pp. 93–107.
Feige, U., Goldwasser, S., Lovasz, L., Safra, S., & Szege, M. (1991). Approximating clique
is almost NP-complete. In IEEE Symposium on Foundations of Computer Science,
pp. 2–12.
Focacci, F., & Milano, M. (2001). Global cut framework for removing symmetries. In
Principles and Practice of Constraints Programming, pp. 77–82.
Galinier, P., & Hao, J. (1999). Hybrid evolutionary algorithms for graph coloring. Journal
of Combinatorial Optimization, 3, 379–397.
Garey, M. R., & Johnson, D. S. (1979). Computers and Intractability: A Guide to the Theory
of NP-completeness. W. H. Freeman and Company.
Gent, I. P. (2001). A symmetry-breaking constraint for indistinguishable values. In Workshop on Symmetry in Constraint Satisfaction Problems.
Goldberg, E., & Novikov, Y. (2002). Berkmin: A fast and robust SAT-solver. In Design
Automation and Test in Europe, pp. 142–149.
Haldorsson, M. M. (1990). A still better performance guarantee for approximate graph
coloring..
Hentenryck, P. V., Agren, M., Flener, P., & Pearson, J. (2003). Tractable symmetry breaking
for CSPs with interchangeable values. In The International Joint Conference on
Artificial Intelligence (IJCAI).
Hertz, A., & Werra, D. D. (1987). Using tabu search techniques for graph coloring. Computing, 39, 345–351.
Huang, J., & Darwiche, A. (2003). A structure-based variable ordering heuristic for SAT.
In The International Joint Conference on Artificial Intelligence, pp. 1167–1172.
ILOG (2000). ILOG CPLEX ILP solver, version 7.0. http://www.ilog.com/products/cplex/.
J.-P. Hamiez, J.-K. H. (2001). Scatter search for graph coloring. In The 5th European
Conference on Artificial Evolution, pp. 168–179.
Jagota, A. (1996). An adaptive, multiple restarts neural network algorithm for graph coloring. European Journal of Operational Research, 93, 257–270.
Kirovski, D., & Potkonjak, M. (1998). Efficient coloring of a large spectrum of graph. In
Design Automation Conference.
Krishnamurthy, B. (1985). Short proofs for tricky formulas. Acta Informatica, 22, 327–337.
Kubale, M., & Jackowski, B. (1985). A generalized implicit enumeration algorithm for graph
coloring. Communications of the ACM, 28, 412–418.
Kubale, M., & Kusz, E. (1983). Computational experience with implicit enumeration algorithms for graph coloring. In Proceedings of the WG’83 International Workshop on
Graph Theoretic Concepts in Computer Science, pp. 167–176.
Leighton, F. (1979). A graph coloring algorithm for large scheduling problems. Journal of
Research of the National Bureau of Standards, 84, 489–506.
321

Ramani, Aloul, Markov, & Sakallah

McKay, B. D. (1990). Nauty user’s guide (version 1.5). http://cs.anu.edu.au/˜bdm/nauty/.
Mehrotra, A., & Trick, M. A. (1996). A column generation approach for graph coloring.
INFORMS Journal on Computing, 8, 344–354.
Moskewicz, M., Madigan, C., Zhao, Y., Zhang, L., & Malik, S. (2001). Chaff: Engineering
an efficient sat solver. In Design Automation Conference, pp. 530–535.
Mycielski, J. (1955). Sur le coloriage des graphs. Colloqium Mathematicum, 3, 161–162.
Prestwich, S. (2002). Supersymmetric modelling for local search. In SymCon: Workshop
on Symmetries in CSPs, pp. 21–28.
Puget, J. (2002). Symmetry breaking revisited. In Principles and Practice of Constraints
Programming, pp. 446–461.
Ramani, A., Aloul, F. A., Markov, I. L., & Sakallah, K. A. (2004). Breaking instanceindependent symmetries in exact graph coloring. In Design Automation and Test in
Europe, pp. 324–329.
Roney-Dougal, C. M., Gent, I. P., Kelsey, T., & Linton, S. (2004). Tractable symmetry
breaking using restricted search trees. In European Conference on Artificial Intelligence, pp. 211–215.
Sheini, H. (2004). Pueblo 0-1 ILP solver. http://www.eecs.umich.edu/˜hsheini/pueblo/.
Silva, J. P. M., & Sakallah, K. A. (1999). GRASP: A new search algorithm for satisfiability.
IEEE Transactions On Computers, 48, 506–521.
Trick, M. (1996). Network resources for coloring a graph.

http://mat.gsia.cmu.edu/COLOR/color.html

.

Walsh, T. (2001). Search on high degree graphs. In 17th International Joint Conference on
Artificial Intelligence, pp. 266–271.
Warners, J. P. (1998). A linear-time transformation of linear inequalities into conjunctive
normal form. Information Processing Letters, 68, 63–69.
Welsh, D. J. A., & Powell, M. B. (1967). An upper bound on the chromatic number of a
graph and its application to timetabling problems. Computer Journal, 10, 85–86.
Werra, D. D. (1985). An introduction to timetabling. European Journal of Operations
Research, 19, 151–162.

322

Journal of Artificial Intelligence Research 26 (2006) 127-151

Submitted 8/05; published 6/06

Admissible and Restrained Revision
Richard Booth

richard.b@msu.ac.th

Faculty of Informatics
Mahasarakham University
Mahasarakham 44150, Thailand

Thomas Meyer

Thomas.Meyer@nicta.com.au

National ICT Australia and
University of New South Wales
223 Anzac Parade
Kensington, NSW 2052, Australia

Abstract
As partial justification of their framework for iterated belief revision Darwiche and
Pearl convincingly argued against Boutilier’s natural revision and provided a prototypical
revision operator that fits into their scheme. We show that the Darwiche-Pearl arguments
lead naturally to the acceptance of a smaller class of operators which we refer to as admissible. Admissible revision ensures that the penultimate input is not ignored completely,
thereby eliminating natural revision, but includes the Darwiche-Pearl operator, Nayak’s
lexicographic revision operator, and a newly introduced operator called restrained revision.
We demonstrate that restrained revision is the most conservative of admissible revision
operators, effecting as few changes as possible, while lexicographic revision is the least conservative, and point out that restrained revision can also be viewed as a composite operator,
consisting of natural revision preceded by an application of a “backwards revision” operator previously studied by Papini. Finally, we propose the establishment of a principled
approach for choosing an appropriate revision operator in different contexts and discuss
future work.

1. Introduction
The ability to rationally change one’s knowledge base in the face of new information which
possibly contradicts the currently held beliefs is a basic characteristic of intelligent behaviour. Thus the question of belief revision is of crucial importance in Artificial Intelligence.
In the last twenty years this question has received considerable attention, starting from the
work of Alchourrón, Gärdenfors, and Makinson (1985) – usually abbreviated to just AGM –
who proposed a set of rationality postulates which any reasonable revision operator should
satisfy. A semantic construction of revision operators was later provided by Katsuno and
Mendelzon (1991), according to which an agent has in its mind a plausibility ordering – a
total preorder – over the set of possible worlds, with the knowledge base associated to this
ordering being identified with the set of sentences true in all the most plausible worlds. This
approach dates back to the work of Lewis (1973) on counterfactuals. It was introduced into
the belief revision literature by Grove (1988) and Spohn (1988). Given a new sentence – or
epistemic input – α, the revised knowledge base is set as the set of sentences true in all the
most plausible worlds in which α holds. As was shown by Katsuno and Mendelzon (1991),
the family of operators defined by this construction coincides exactly with the family of opc
2006
AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

Booth & Meyer

erators satisfying the AGM postulates. Due to its intuitive appeal, this construction came
to be widely used in the area. However, researchers soon began to notice a deficiency with
it – although it prescribes how to obtain a new knowledge base, it remains silent on how to
obtain a new plausibility ordering which can then serve as a target for the next epistemic
input. Thus it is not rich enough to deal adequately with the problem of iterated belief
revision. This paper is a contribution to the study of this problem.
Most iterated revision schemes are sensitive to the history of belief changes1 , based on
a version of the “most recent is best” argument, where the newest information is of higher
priority than anything else in the knowledge base. Arguably the most extreme case of this is
Nayak’s lexicographic revision (Nayak, 1994; Nayak, Pagnucco, & Peppas, 2003). However,
there are operators where, once admitted to the knowledge base, it rapidly becomes as
much of a candidate for removal as anything else in the set when another, newer, piece of
information comes along, Boutilier’s natural revision (1993, 1996) being a case in point.
A dual to this is what Rott (2003) terms radical revision where the new information is
accepted with maximal, irremediable entrenchment – see also Segerberg (1998). Another
issue to consider is the problem termed temporal incoherence (Rott, 2003):
the comparative recency of information should translate systematically into comparative importance, strength or entrenchment
In an influential paper Darwiche and Pearl (1997) proposed a framework for iterated
revision. Their proposal is characterised in terms of sets of syntactic and semantic postulates, but can also be viewed from the perspective of conditional beliefs. It is an extension
of the formulation by Katsuno and Mendelzon (1991) of AGM revision (Alchourrón et al.,
1985). To justify their proposal Darwiche and Pearl mount a comprehensive argument. The
argument includes a critique of natural revision, which is shown to admit too few changes.
In addition, they provide a concrete revision operator which is shown to satisfy their postulates. In many ways this can be seen as the prototypical Darwiche-Pearl operator. It
is instructive to observe that the two best-known operators satisfying the Darwiche-Pearl
postulates, natural revision and lexicographic revision, form the opposite extremes of the
Darwiche-Pearl framework: Natural revision is the most conservative Darwiche-Pearl operator, in the sense that it effects as few changes as possible, while lexicographic revision is
the least conservative.
In this paper we show that the Darwiche-Pearl arguments lead naturally to the acceptance of a smaller class of operators which we refer to as admissible. We provide characterisations of admissible revision, in terms of syntactic as well as semantic postulates.
Admissible revision ensures that the penultimate input is not ignored completely. A consequence of this is that natural revision is eliminated. On the other hand, admissible revision
includes the prototypical Darwiche-Pearl operator as well as lexicographic revision, the latter result also showing that lexicographic revision is the least conservative of the admissible
operators. The removal of natural revision from the scene leaves a gap which is filled by the
introduction of a new operator we refer to as restrained revision. It is the most conservative
of admissible revision operators, and can thus be seen as an appropriate replacement of
natural revision. We give a syntactic and a semantic characterisation of restrained revision,
1. An external revision scheme like that of Areces and Becher (2001) and Freund and Lehmann (1994) is
not.

128

Admissible and Restrained Revision

and demonstrate that it satisfies desirable properties. In particular, and unlike lexicographic
revision, it ensures that older information is not discarded unnecessarily, and it shows that
the problem of temporal incoherence can be dealt with.
Although natural revision does not feature in the class of admissible revision operators,
we show that it still has a role to play in iterated revision, provided it is first tempered
appropriately. We show that restrained revision can also be viewed as a composite operator,
consisting of natural revision preceded by an application of a “backwards revision” operator
previously studied by Papini (2001).
The paper is organised as follows. After outlining some notation, we review the DarwichePearl framework in Section 2. This is followed by a discussion of admissible revision in
Section 3. In Section 4 we introduce restrained revision, and in Section 5 we show how
it can be defined as a composite operator. Section 6 discusses the possibility of enriching
epistemic states as a way of determining the appropriate admissible revision operator in a
particular context. In this section we also conclude and briefly discuss some future work.
1.1 Notation
We assume a finitely generated propositional language L which includes the constants >
and ⊥, is closed under the usual propositional connectives, and is equipped with a classical
model-theoretic semantics. V is the set of valuations of L and [α] (or [B]) is the set of
models of α ∈ L (or B ⊆ L). Classical entailment is denoted by  and logical equivalence
by ≡. We also use Cn to denote the operation of closure under classical entailment. Greek
letters α, β, . . . stand for arbitrary sentences. In our examples we sometimes use the lower
case letters p, q, and r as propositional atoms, and sequences of 0s and 1s to denote the
valuations of the language. For example, 01 denotes the valuation, in a language generated
by p and q, in which p is assigned the value 0 and q the value 1, while 011 denotes the
valuation, in a language generated by p, q and r, in which p is assigned the value 0 and
both q and r the value 1. Whenever we use the term knowledge base we will always mean
a set of sentences X which is deductively closed, i.e., X = Cn(X).

2. Darwiche-Pearl Revision
Darwiche and Pearl (1997) reformulated the AGM postulates (Alchourrón et al., 1985) to
be compatible with their suggested approach to iterated revision. This necessitated a move
from knowledge bases to epistemic states. An epistemic state contains, in addition to a
knowledge base, all the information needed for coherent reasoning including, in particular,
the strategy for belief revision which the agent wishes to employ at a given time. Darwiche
and Pearl consider epistemic states as abstract entities, and do not provide a single formal
representation. It is thus possible to talk about two epistemic states E and F being identical
(denoted by E = F) , but yet syntactically different.2 This has to be borne in mind below,
particularly when considering postulate (E ∗ 5). In Darwiche and Pearl’s reformulated
postulates ∗ is a belief change operator on epistemic states, not knowledge bases. We
denote by B(E) the knowledge base extracted from an epistemic state E.
(E∗1) B(E ∗ α) = Cn(B(E ∗ α))
2. Personal communication with Adnan Darwiche.

129

Booth & Meyer

(E∗2) α ∈ B(E ∗ α)
(E∗3) B(E ∗ α) ⊆ B(E) + α
(E∗4) If ¬α ∈
/ B(E) then B(E) + α ⊆ B(E ∗ α)
(E∗5) If E = F and α ≡ β then B(E ∗ α) = B(F ∗ β)
(E∗6) ⊥ ∈ B(E ∗ α) iff  ¬α
(E∗7) B(E ∗ (α ∧ β)) ⊆ B(E ∗ α) + β
(E∗8) If ¬β ∈
/ B(E ∗ α) then B(E ∗ α) + β ⊆ B(E ∗ (α ∧ β))
Darwiche and Pearl then show, via a representation result similar to that of Katsuno and
Mendelzon (1991), that revision on epistemic states can be represented in terms of plausibility orderings associated with epistemic states.3 More specifically, every epistemic state
E has associated with it a total preorder E on all valuations, with elements lower down
in the ordering deemed more plausible. Moreover, for any two epistemic states E and F
which are identical (but may be syntactically different), it has to be the case that E =F .
Let min(α, E ) denote the minimal models of α under E . The knowledge base associated with the epistemic state is obtained by considering the minimal models in E i.e.,
[B(E)] = min(>, E ). Observe that this means that B(E) has to be consistent. This
requirement enables us to obtain a unique knowledge base from the total preorder E .
Preservation of the results in this paper when this requirement is relaxed is possible, but
technically messy.
The observant reader will note that our assumption of a consistent B(E) is incompatible
with a successful revision by ⊥. This requires that we jettison (E∗6) and insist on consistent
epistemic inputs only. (The left-to-right direction of (E∗6) is rendered superfluous by (E∗1)
and the assumption that knowledge bases extracted from all epistemic states have to be
consistent.) The other difference between the original AGM postulates and the DarwichePearl reformulation – first inspired by a critical observation by Freund and Lehmann (1994)
– occurs in (E∗5), which states that revising by logically equivalent sentences results in
epistemic states with identical associated knowledge bases. This is a weakening of the
original AGM postulate, phrased in our notation as follows:
(B∗5) If B(E) = B(F) and α ≡ β then B(E ∗ α) = B(F ∗ β)
(B∗5) states that two epistemic states with identical associated knowledge bases will, after
having been revised by equivalent inputs, produce two epistemic states with identical associated knowledge bases. This is stronger than (E∗5) which requires equivalent associated
knowledge bases only if the original epistemic states were identical. We shall refer to the
reformulated AGM postulates, with (E∗6) removed, as DP-AGM.
DP-AGM guarantees a unique extracted knowledge base when revision by α is performed. It sets [B(E ∗ α)] equal to min(α, E ) and thereby fixes the most plausible valuations in E∗α . However, it places no restriction on the rest of the ordering. The purpose
3. Alternative frameworks for studying iterated revision, both based on using sequences of sentences rather
than plausibility orderings, are those of Lehmann (1995) and Konieczny and Pino-Pérez (2000).

130

Admissible and Restrained Revision

of the Darwiche-Pearl framework is to constrain this remaining part of the new ordering.
It is done by way of a set of postulates for iterated revision (Darwiche & Pearl, 1997).
(Throughout the paper we follow the convention that ∗ is left associative.)
(C1) If β  α then B(E ∗ α ∗ β) = B(E ∗ β)
(C2) If β  ¬α then B(E ∗ α ∗ β) = B(E ∗ β)
(C3) If α ∈ B(E ∗ β) then α ∈ B(E ∗ α ∗ β)
(C4) If ¬α ∈
/ B(E ∗ β) then ¬α ∈
/ B(E ∗ α ∗ β)
The postulate (C1) states that when two pieces of information—one more specific than
the other—arrive, the first is made redundant by the second. (C2) says that when two
contradictory epistemic inputs arrive, the second one prevails; the second evidence alone
yields the same knowledge base. (C3) says that a piece of evidence α should be retained
after accommodating more recent evidence β that entails α given the current knowledge
base. (C4) simply says that no epistemic input can act as its own defeater. We shall refer to
the class of belief revision operators satisfying DP-AGM and (C1) to (C4) as DP-revision.
The following are the corresponding semantic versions (with v, w ∈ V ):
(CR1) If v ∈ [α], w ∈ [α] then v E w iff v E∗α w
(CR2) If v ∈ [¬α], w ∈ [¬α] then v E w iff v E∗α w
(CR3) If v ∈ [α], w ∈ [¬α] then v ≺E w only if v ≺E∗α w
(CR4) If v ∈ [α], w ∈ [¬α] then v E w only if v E∗α w
(CR1) states that the relative ordering between α-worlds remain unchanged following an αrevision, while (CR2) requires the same for ¬α-worlds. (CR3) requires that, for an α-world
strictly more plausible than a ¬α-world, this relationship be retained after an α-revision,
and (CR4) requires the same for weak plausibility. Darwiche and Pearl showed that, given
DP-AGM, a precise correspondence obtains between (Ci) and (CRi) above (i = 1, 2, 3, 4).
One of the guiding principles of belief revision is the principle of minimal change: changes
to a belief state ought to be kept to a minimum. What is not always clear is what ought to be
minimised. In AGM theory the prevailing wisdom is that minimal change refers to the sets
of sentences corresponding to knowledge bases. But there are other interpretations. With
the move from knowledge bases to epistemic states, minimal change can be defined in terms
of the fewest possible changes to the associated plausibility ordering E . In what follows we
will frequently have the opportunity to refer to the latter interpretation of minimal change.
See also the discussion of this principle by Rott (2000).

3. Admissible Revision
In this section we consider two of the best-known DP-operators, and propose three postulates to be added to the Darwiche-Pearl framework. The first is more of a correction
than a strengthening. We show that the Darwiche-Pearl representation of the principle of
the irrelevance of syntax is too weak and suggest an appropriate strengthened postulate.
131

Booth & Meyer

The second is suggested by some of the arguments advanced by Darwiche and Pearl themselves. It eliminates one of the operators they criticise, and is satisfied by the sole operator
they provide as an instance of their framework. The addition of these two postulates to
the Darwiche-Pearl framework leads to the definition of the class of admissible revision
operators. Finally, we point out a problem with Nayak’s well-known lexicographic revision
operator and propose a third postulate to be added. The consequences of insisting on the
addition of this third postulate are discussed in detail in Section 4.
As mentioned in Section 2, Darwiche and Pearl replaced the original AGM postulate
(B ∗ 5) with (E ∗ 5). Both are attempts at an appropriate formulation of the principle
of the irrelevance of syntax, popularised by Dalal (1988). But whereas (B ∗ 5) has been
shown to be too strong, as shown by Darwiche and Pearl (1997), closer inspection reveals
that (E ∗ 5) is too weak. To be more precise, it fails as an adequate formulation of syntax
irrelevance for iterated revision. It specifies that revision by two equivalent sentences should
produce epistemic states with identical associated knowledge bases, but does not require
that these epistemic states, after another revision by two equivalent sentences, also have
to produce epistemic states with identical associated knowledge bases. So, as can be seen
from the following example, under DP-AGM (and indeed, even if (C1) to (C4) are added)
it is possible for B(E ∗ α ∗ γ) to differ from B(E ∗ β ∗ δ) even if α is equivalent to β and γ
is equivalent to δ.
Example 1 Consider a propositional language generated by the two atoms p and q and let
E be an epistemic state such that B(E) = Cn(p ∨ q). Now consider the two epistemic states
E0 and E00 such that B(E0 ) = B(E00 ) = Cn(p), 01 ≺E0 00 and 00 ≺E00 01. Observe that
this gives complete descriptions of E0 and E00 . It is tedious, but not difficult, to verify
that setting E∗p =E0 and E∗¬¬p =E00 is compatible with DP-AGM. But observe then that
B(E ∗ p ∗ ¬p) = Cn(¬p ∧ q), while B(E ∗ ¬¬p ∗ ¬p) = Cn(¬p ∧ ¬q).
As a consequence of this, we propose that (E∗5) be replaced by the following postulate:
(E∗50 ) If E = F, α ≡ β and δ ≡ γ then B(E ∗ α ∗ γ) = B(F ∗ β ∗ δ)
The semantic equivalent of (E∗50 ) looks like this:
(ER∗50 ) If E = F and α ≡ β then E∗α =F∗β
(ER∗50 ) states that the revision of two identical epistemic states by two equivalent sentences has to result in epistemic states with identical associated total preorders, not just in
epistemic states with identical associated knowledge bases.
Proposition 1 (E∗50 ) and (ER∗50 ) are equivalent, given DP-AGM.
Proof: The proof that (E∗50 ) follows from (ER∗50 ) is straightfoward. For the converse, suppose that (ER∗50 ) does not hold; i.e. α ≡ β and F∗α 6=E∗β for some α and β. This means
there exist x, y ∈ V such that x E∗α y but y ≺F∗β x. Now let γ be such that [γ] = {x, y}.
Then x ∈ [B(E ∗ α ∗ γ)], but [B(F ∗ β ∗ γ)] = {y}, and so B(E ∗ α ∗ γ) 6= B(F ∗ β ∗ γ); a
violation of (E∗50 ).


132

Admissible and Restrained Revision

From this it should already be clear that (E∗50 ) is a desirable property. This view is bolstered
further by observing that all the well-known iterated revision operators satisfy it; natural
revision, the Darwiche-Pearl operator •, and Nayak’s lexicographic revision, the first and
third of which are to be discussed in detail below. In fact, we conjecture that Darwiche and
Pearl’s intention was to replace (B∗5) with (E∗50 ), not with (E∗5) and propose this as a
permanent replacement.
Definition 1 The set of postulates obtained by replacing (E∗5) with (E∗50 ) in DP-AGM is
defined as RAGM.
Observe that RAGM, like DP-AGM, guarantees that [B(E ∗ α)] = min(α, E ).
Rule (E∗50 ) is the first of the new postulates we want to add to the Darwiche-Pearl
framework. We now lead up to the second. One of the oldest known DP-operators is
natural revision, usually credited to Boutilier (1993, 1996), although the idea can also be
found in (Spohn, 1988). Its main feature is the application of the principle of minimal
change to epistemic states. It is characterised by DP-AGM plus the following postulate:
(CB) If ¬β ∈ B(E ∗ α) then B(E ∗ α ∗ β) = B(E ∗ β)
(CB) requires that, whenever B(E ∗ α) is inconsistent with β, revising E ∗ α with β will
completely ignore the revision by α. Its semantic counterpart is as follows:
(CBR) For v, w ∈
/ [B(E ∗ α)], v E∗α w iff v E w
As shown by Darwiche and Pearl (1997), natural revision minimises changes in conditional
beliefs, with β | α being a conditional belief of an epistemic state E iff β ∈ B(E ∗ α). In
fact, Darwiche and Pearl show (Lemma 1, p. 7), that keeping E and E∗α as similar as
possible has the effect of minimising the changes in conditional beliefs to a revision. So,
from (CBR) it is clear that natural revision is an application of minimal change to epistemic
states. It requires that, barring the changes mandated by DP-AGM, the relative ordering of
valuations remains unchanged, thus keeping E∗α as similar as possible to E . In that sense
then, natural revision is the most conservative of all DP-operators. Such a strict adherence
to minimal change is inadvisable and needs to be tempered appropriately, an issue that will
be addressed in Section 5. Darwiche and Pearl have shown that (CB) is too strong, and
that natural revision is not all that natural, sometimes yielding counterintuitive results.
Example 2 (Darwiche & Pearl, 1997) We encounter a strange animal and it appears to be
a bird, so we believe it is one. As it comes closer, we see clearly that the animal is red, so
we believe it is a red bird. To remove further doubts we call in a bird expert who examines
it and concludes that it is not a bird, but some sort of animal. Should we still believe the
animal is red? (CB) tells us we should no longer believe it is red. This can be seen by
substituting B(E) = Cn(¬β) = Cn(bird) and α ≡ red in (CB), instructing us to totally
ignore the observation α as if it had never taken place.
Given Example 2, it is perhaps surprising that Darwiche and Pearl never considered postulate (P) below. In this example, the argument for retaining the belief that the creature is
red hinges upon the assumption that being red is not in conflict with the newly obtained
information that it is a kind of animal. That is, because learning that the creature is an
133

Booth & Meyer

animal will not automatically disqualify it from being red, it is reasonable to retain the
belief that it is red. More generally then, whenever α is consistent with a revision by β, it
should be retained if an α-revision is inserted just before the β-revision.
(P) If ¬α ∈
/ B(E ∗ β) then α ∈ B(E ∗ α ∗ β)
Applying (P) to Example 2 we see that, if red is consistent with B(E ∗ ¬bird), we have
red ∈ B(E ∗ red ∗ ¬bird). Put differently, (P) requires that you retain your belief in the
animal’s redness, provided this would not have been precluded if the observation about it
being red had never occurred. (P) was also proposed independently of the present paper
by Jin and Thielscher (2005) where it is named Independence. The semantic counterpart of
(P) looks like this:
(PR) For v ∈ [α] and w ∈ [¬α], if v E w then v ≺E∗α w
(PR) requires an α-world v that is at least as plausible as a ¬α-world w to be strictly more
plausible than w after an α-revision. The following result was also proved independently
by Jin and Thielscher (2005).
Proposition 2 If ∗ satisfies DP-AGM, then it satisfies (P) iff it also satisfies (PR).
Proof: For (P)⇒(PR), let v ∈ [α], w ∈ [¬α], v E w, and let β be such that [β] = {v, w}.
This means that ¬α ∈
/ B(E ∗ β) (since [B(E ∗ β)] is either equal to {v} or to {v, w}), and so,
by (P), α ∈ B(E ∗ α ∗ β). And therefore v ≺E∗α w, for if not, we would have that w E∗α v,
from which it follows that w ∈ [B(E ∗ α ∗ β)], and so α ∈
/ B(E ∗ α ∗ β)].
For (P)⇐(PR), suppose that ¬α ∈
/ B(E ∗ β). This means there is a v ∈ [α] ∩ [B(E ∗ β)];
that is, v E w for every w ∈ [β]. And this means that α ∈ B(E ∗ α ∗ β). For if not, it
means there is an x in [¬α] ∩ [B(E ∗ α ∗ β)]. Now, since x ∈ [B(E ∗ α ∗ β)], it follows from
DP-AGM that x E∗α w for every w ∈ [β], and so x E∗α v (since v ∈ [B(E ∗ β)] ⊆ [β]).
But it also follows from DP-AGM that x ∈ [β], and therefore that v E x, and by (PR) it
then follows that v ≺E∗α x; a contradiction.

Rule (PR) enforces certain changes in the ordering E after receipt of α. In fact as soon
as there exist an α-world v and a ¬α-world w on the same plausibility level somewhere
in E (in that both v E w and w E v), (PR) implies E∗α 6=E . Furthermore these
changes must also occur even when α is already believed in E to begin with, i.e., α ∈ B(E).
(Although of course if α ∈ B(E) then B(E ∗ α) = B(E), i.e., the knowledge base associated
to E will remain unchanged – this follows from DP-AGM.) The rules (P)/(PR) ensure input
α is believed with a certain minimal strength of belief – enough to help it survive the next
revision. The point that being informed of α can lead to an increase in the strength of an
agent’s belief in α, even in cases where the agent already believes α to begin with, has been
made before, e.g., by Friedman and Halpern (1999, p.405). Note that (P) has the antecedent
of (C4) and the consequent of (C3). In fact, (P) is stronger than (C3) and (C4) combined.
This is easily seen from the semantic counterparts of these postulates. It also follows that
the only concrete example of an iterated revision operator provided by Darwiche and Pearl,
the operator they refer to as • and which employs a form of Spohnian conditioning (Spohn,
1988), satisfies (PR), and therefore (P) as well. Furthermore, by adopting (P) we explicitly
134

Admissible and Restrained Revision

exclude natural revision as a permissible operator. So accepting (P) is a move towards
the viewpoint that information obtained before the latest input ought not to be discarded
unnecessarily.
Based on the analysis of this section we propose a strengthening of the Darwiche-Pearl
framework in which (E∗5) is replaced by (E∗50 ) and (C3) and (C4) are replaced by (P).
Definition 2 A revision operator is admissible iff it satisfies RAGM, (C1), (C2), and (P).
Inasmuch as the Darwiche-Pearl framework can be visualised as one in which α-worlds
slide “downwards” relative to ¬α-worlds, admissible revision ensures, via (PR), that this
“downwards” slide is a strict one.
We now pave the way for the third postulate we would like to add in this paper to the
Darwiche-Pearl framework. To begin with, note that another view of (P) is that it is a
significant weakening of the following property, first introduced by Nayak et al. (1996):
(Recalcitrance) If ¬α ∈
/ Cn(β) then α ∈ B(E ∗ α ∗ β)
Semantically, (Recalcitrance) corresponds to the following property, as was pointed out by
Booth (2005) and implicitly contained in the work of Nayak et al. (2003):
(R) For v ∈ [α], w ∈ [¬α], v ≺E∗α w
(Recalcitrance) is a property of the lexicographic revision operator, the second of the wellknown DP-operators we consider, and one that is just as old as natural revision. It was
first introduced by Nayak (1993) and has been studied most notably by Nayak et al. (1994,
2003), although, as with natural revision, the idea actually dates back to Spohn (1988). In
fact, lexicographic revision is characterised by DP-AGM (and also RAGM) together with
(C1), (C2) and (Recalcitrance), a result that is easily proved from the semantic counterparts
of these properties and Nayak et al.’s semantic characterisation of lexicographic revision in
(2003). Informally, lexicographic revision takes the assumption of “most recent is best”,
on which the Success postulate (E ∗ 2) is based, and adds to it the assumption of temporal
coherence. In combination, this leads to the stronger assumption that “more recent is
better”.
An analysis of the semantic characterisation of lexicographic revision shows that it is
the least conservative of the DP-operators, in the sense that it effects the most changes in
the relative ordering of valuations permitted by DP-AGM (or RAGM for that matter) and
the Darwiche-Pearl postulates. Since it is also an admissible revision operator, it follows
that it is also the least conservative admissible operator.
The problem with (Recalcitrance) is that the decision of whether to accept β after a
subsequent revision by α is completely determined by the logical relationship between β
and α – the epistemic state E is robbed of all influence. The replacement of (Recalcitrance)
by the weaker (P) already gives E more influence in the outcome. What we will do shortly
is constrain matters further by giving E as much influence as allowed by the postulates for
admissible revision. Such a move ensures greater sensitivity to the agent’s epistemic record
in making further changes.
Note that lexicographic revision assumes that more recent information takes complete
precedence over information obtained previously. Thus, when applied to Example 2, it
135

Booth & Meyer

requires us to believe that the animal, previously assumed to be a bird, is indeed red,
because red is a recent input which does not conflict with the most recently obtained input.
While this is a reasonable approach in many circumstances, a dogmatic adherence to it can
be problematic, as the following example shows.
Example 3 While holidaying in a wildlife park we observe a creature which is clearly red,
but we are too far away to determine whether it is a bird or a land animal. So we adopt the
knowledge base B(E) = Cn(red). Next to us is a person with knowledge of the local area
who declares that, since the creature is red, it is a a bird. We have no reason to doubt him,
and so we adopt the belief red → bird. Now the creature moves closer and it becomes clear
that it is not a bird. The question is, should we continue believing that it is red? Under
the circumstances described above we want our initial observation to take precedence, and
believe that the animal is red. But lexicographic revision does not allow us to do so.
Other examples along similar lines speaking against a rigid acceptance of (Recalcitrance)
are those of Glaister (1998, p.31) and Jin and Thielscher (2005, p.482).
While (P) allows for the possibility of retaining the belief that the animal is red, it does
not enforce this belief. The rest of this section is devoted to the discussion of a property
which does so. To help us express this property, we introduce an extra piece of terminology
and notation.
Definition 3 α and β counteract with respect to an epistemic state E, written α !E β,
iff ¬β ∈ B(E ∗ α) and ¬α ∈ B(E ∗ β).
The use of the term counteract to describe this relation is taken from Nayak et al. (2003).
α !E β means that, from the viewpoint of E, α and β tend to “exclude” each other. We
will now discuss a few properties of this relation. First note that !E depends only on the
total preorder E obtained from E. Indeed we have α !E β iff both min(α, E ) ⊆ [¬β] and
min(β, E ) ⊆ [¬α]. This in turn can be reformulated in the following way, which provides
a useful aid to visualise a counteracts relation:
Proposition 3 α !E β iff there exist v ∈ [α], w ∈ [β] such that both v ≺E x and w ≺E x
for all x ∈ min(α ∧ β, E ).
Proof: First note that, since obviously min(α, E ) ⊆ [α], min(α, E ) ⊆ [¬β] may be rewritten as min(α, E ) ⊆ [¬(α ∧ β)]. Using the fact that E is a total preorder, it is easy to see
that this can hold iff there exists v ∈ [α] such that v ≺E x for all x ∈ min(α ∧ β, E ). In
the same way we may rewrite min(β, E ) ⊆ [¬α] as min(β, E ) ⊆ [¬(α ∧ β)], which is then
equivalent to saying there exists w ∈ [¬β] such that w ≺E x for all x ∈ min(α ∧ β, E ). 
In other words, Proposition 3 says α !E β iff there exist both an α-world and a β-world
which are strictly more plausible than the most plausible (α ∧ β)-worlds. Other immediate
things to note about !E are that it is symmetric, and that it is syntax-independent, i.e., if
α !E β and β ≡ β 0 then α !E β 0 . Furthermore if α and β are logically inconsistent with
each other then α !E β, but the converse need not hold (see the short example after the
next proposition for confirmation). Thus !E can be seen as a weak form of inconsistency.
The next result gives two more properties of !E :
136

Admissible and Restrained Revision

Proposition 4 Given RAGM, the following properties hold for !E :
(i) If α !E β and γ !E β then (α ∨ γ) !E β
(ii) If α 6!E β and γ 6!E β then (α ∨ γ) 6!E β
Proof: (i) Suppose α !E β and γ !E β. To show (α ∨ γ) !E β we need to show
both ¬β ∈ B(E ∗ (α ∨ γ)) and ¬(α ∨ γ) ∈ B(E ∗ β). For the former we already have both
¬β ∈ B(E ∗ α) and ¬β ∈ B(E ∗ γ) from α !E β and γ !E β respectively. Since it follows
from RAGM that B(E ∗ λ) ∩ B(E ∗ χ) ⊆ B(E ∗ (λ ∨ χ)) for any λ, χ ∈ L, we can conclude
from this ¬β ∈ B(E ∗ (α ∨ γ)). For the latter we already have both ¬α ∈ B(E ∗ β) and
¬γ ∈ B(E ∗ β) from α !E β and γ !E β respectively. And from this we can conclude
¬(α ∨ γ) ∈ B(E ∗ β), again using RAGM (specifically (E ∗ 1)).
(ii) Suppose α 6!E β and γ 6!E β. Firstly, if either ¬α 6∈ B(E ∗ β) or ¬γ 6∈ B(E ∗ β)
then we must have ¬(α ∨ γ) 6∈ B(E ∗ β) by RAGM and so (α ∨ γ) 6!E β as required. So
suppose both ¬α ∈ B(E ∗ β) and ¬γ ∈ B(E ∗ β). Then, since α 6!E β and γ 6!E β,
this means we have both ¬β 6∈ B(E ∗ α) and ¬β 6∈ B(E ∗ γ). Since it follows from RAGM
that B(E ∗ (λ ∨ χ)) ⊆ B(E ∗ λ) ∪ B(E ∗ χ) for any λ, χ ∈ L, it follows from these two that
¬β 6∈ B(E ∗ (α ∨ γ)) and so also in this case (α ∨ γ) 6!E β as required.

The first property above says that if β counteracts with two sentences separately, then it
counteracts with their disjunction, while the second says that it cannot counteract with
a disjunction without counteracting with at least one of the disjuncts. Obviously these
properties also hold for the binary relation of logical inconsistency. However one departure
from the inconsistency relation is that it is possible to have both γ 6!E β and (α∨γ) !E β.
To see this assume for the moment L is generated by just three propositional atoms {p, q, r}
and take α = p, β = q and γ = r. Then take E to be such that its lowest plausibility
level contains only the two valuations 010 and 100, and the next plausibility level only the
valuation 111.
We are now ready to introduce our third postulate. It is the following:
(D) If α !E β then ¬α ∈ B(E ∗ α ∗ β)
(D) requires that, whenever α and β counteract with respect to E, α should be disallowed
when an α-revision is followed by a β-revision. That is, when the β-revision of E ∗ α takes
place, the information encoded in E takes precedence over the information contained in
E ∗ α. Darwiche and Pearl (1997) considered this property (it is their rule (C6)) but argued
against it, citing the following example.
Example 4 (Darwiche & Pearl, 1997) We believe that exactly one of John and Mary committed a murder. Now we get persuasive evidence indicating that John is the murderer. This
is followed by persuasive information indicating that Mary is the murderer. Let α represent
that John committed the murder and β that Mary committed the murder. Then (D) forces
us to conclude that Mary, but not John, was involved in the murder. This, according to
Darwiche and Pearl, is counterintuitive, since we should conclude that both were involved
in committing the murder.
Darwiche and Pearl’s argument against (D) rests upon the assumption that more recent
information ought to take precedence over information previously obtained. But as we have
137

Booth & Meyer

seen in Example 3, this is not always a valid assumption. In fact, the application of (D) to
Example 3, with α = red → bird and β = ¬bird, produces the intuitively correct result
of a belief in the observed animal being red: red ∈ B(E ∗ (red → bird) ∗ ¬bird).
Another way to gain insight into the significance of (D) is to consider its semantic
counterpart:
(DR) For v ∈ [¬α], w ∈ [α], and w ∈
/ [B(E ∗ α)], if v ≺E w then v ≺E∗α w
(DR) curtails the rise in plausiblity of α-worlds after an α-revision. It ensures that, with
the exception of the most plausible α-worlds, the relative ordering between an α-world and
the ¬α-worlds more plausible than it remains unchanged.
Proposition 5 Whenever a revision operator ∗ satisfies RAGM, then ∗ satisfies (D) iff it
satisfies (DR).
Proof: For (D)⇒(DR), suppose that v ∈ [¬α], w ∈ [α], w ∈
/ [B(E ∗ α)], v ≺E w, and let
β be such that [β] = {v, w}. Then ¬α ∈ B(E ∗ β) and ¬β ∈ B(E ∗ α), and so, by (D).
¬α ∈ B(E ∗ α ∗ β). From this it follows that v ≺E∗α w. For if not, we would have that
w E∗α v, which means that w ∈ [B(E ∗ α ∗ β)], and therefore that ¬α ∈
/ B(E ∗ α ∗ β); a
contradiction.
For (D)⇐(DR), suppose that ¬β ∈ B(E ∗ α) and that ¬α ∈ B(E ∗ β), but assume that
¬α ∈
/ B(E ∗ α ∗ β). This means there is a w ∈ [α] that is also in [B(E ∗ α ∗ β)]. Now
observe that w ∈
/ [B(E ∗ β)] since w is an α-model. Also, since w ∈ [B(E ∗ α ∗ β)], it
follows from RAGM that w is a β-model, and therefore w ∈
/ [B(E ∗ α)]. Our supposition of
¬α ∈ B(E ∗ β) means that min(β, E ) ⊆ [¬α]. Since w ∈ [α] ∩ [β] it thus follows that there
is a v ∈ [β] ∩ [¬α] such that v ≺E w. By (DR) it then follows that v ≺E∗α w. But then w
cannot be a model of B(E ∗ α ∗ β); a contradiction.


4. Restrained Revision
We now strengthen the requirements on admissible revision (those operators satisfying
RAGM, (C1), (C2) and (P)) by insisting that (D) is satisfied as well. To do so, let us
first consider the semantic definition of an interesting admissible revision operator. Recall
that RAGM fixes the set of (E∗α )-minimal models, setting them equal to min(α, E ), but
places no restriction on how the remaining valuations should be ordered. The following
property provides a unique relative ordering of the remaining valuations.

v ≺E w or,
(RR) ∀v, w ∈
/ [B(E ∗ α)], v E∗α w iff
v E w and (v ∈ [α] or w ∈ [¬α])
(RR) says that the relative ordering of the valuations that are not (E∗α )-minimal remains
unchanged, except for α-worlds and ¬α-worlds on the same plausibility level; those are split
into two levels with the α-worlds more plausible than the ¬α-worlds. So RAGM combined
with (RR) fixes a unique ordering of valuations.
Definition 4 The revision operator satisfying RAGM and (RR) is called restrained revision.
138

Admissible and Restrained Revision

It turns out that within the framework provided by admissible revision, it is only restrained
revision that satisfies (D). We prove this with the help of the following lemma, asserting
the equivalence of (RR) to (CR1), (CR2), (PR) and (DR) in the presence of RAGM.
Lemma 1 Whenever a revision operator ∗ satisfies RAGM, then ∗ satisfies (RR) iff it
satisfies (CR1), (CR2), (PR), and (DR).
Proof: For (CR1)⇐(RR), pick v, w ∈ [α]. If v ∈ [B(E ∗ α)] then (CR1) follows from
RAGM. If not, it follows from RAGM that w ∈
/ [B(E ∗ α)], and then (CR1) follows from
a direct application of (RR). For (CR2)⇐(RR), pick v, w ∈ [¬α]. From RAGM it follows
that v, w ∈
/ [B(E ∗ α)], and then we obtain (CR2) from a direct application of (RR).
Observe that (RR) can be rewritten as

v E w and,
0
(RR ) ∀v, w ∈
/ [B(E ∗ α)], v ≺E∗α w iff
v ≺E w or (v ∈ [α] and w ∈ [¬α])
Now, for (PR)⇐(RR), pick v ∈ [α] and w ∈ [¬α]. If v ∈ [B(E ∗ α)] then (PR) follows
from RAGM. If not, it follows from a direct application of (RR0 ). For (DR)⇐(RR), pick
v ∈ [¬α], w ∈ [α], and w ∈
/ [B(E ∗ α)]. Then (PR) follows from a direct application of
0
(RR ).
For (CR1), (CR2), (PR), (DR)⇒(RR), let v, w ∈
/ [B(E ∗ α)] and suppose that v E∗α w
and v 6≺E w (i.e. w E v). We have to show that v E w and either v ∈ [α] or w ∈ [¬α].
Assume this is not the case. Then w ≺E v or both v ∈ [¬α] and w ∈ [α]. Now, the second
case is impossible because, together with w E v and (PR) it implies that w ≺E∗α v; a
contradiction. But the first case is also impossible. To see why, observe that by (CR1) it
implies that v and w cannot both be α-models, by (CR2) v and w cannot both be ¬αmodels, by (DR) it cannot be the case that w ∈ [¬α] and v ∈ [α]. And by (PR) it cannot
be the case that w ∈ [α] and v ∈ [¬α]. This concludes the first part of the proof of (CR1),
(CR2), (PR), (DR)⇒(RR). For the second part, let v, w ∈
/ [B(E ∗ α)] and suppose first that
v ≺E w. If v, w ∈ [α] then v E∗α w follows from (CR1). If v, w ∈ [¬α] then v E∗α w
follows from (CR2). If v ∈ [α] and w ∈ [¬α] then v E∗α w follows from (PR). If v ∈ [¬α]
and w ∈ [α] then v E∗α w follows from (DR). Now suppose that v E w and either v ∈ [α]
or w ∈ [¬α]. If v ∈ [α] then v E∗α w follows either from (CR1) or (PR), depending on
whether w ∈ [α] or w ∈ [¬α]. And similarly, if w ∈ [¬α] then v E∗α w follows either from
(CR2) or (PR), depending on whether v ∈ [¬α] or v ∈ [α].


Theorem 2 RAGM, (C1), (C2), (P) and (D) provide an exact characterisation of restrained revision.
Proof: The proof follows from Lemma 1, Proposition 2, Proposition 5, and the correspondence between (C1) and (CR1), and (C2) and (CR2).

Another interpretation of (RR) is that it maintains the relative ordering of the valuations
that are not (E∗α )-minimal, except for the changes mandated by (PR). From this it can
be seen that restrained revision is the most conservative of all admissible revision operators,
in the sense that effects the least changes in the relative ordering of valuations permitted
139

Booth & Meyer

by admissible revision. So, in the context of admissible revision, restrained revision takes
on the role played by natural revision in the Darwiche-Pearl framework.
In the rest of this section we examine some further properties of restrained revision.
Firstly, Examples 3 and 4 share some interesting structural properties. In both, the initial
knowledge base B(E) is pairwise consistent with each of the subsequent sentences in the
revision sequence, while the sentences in each revision sequence are pairwise inconsistent.
And in both examples the information contained in the initial knowledge base B(E) is
retained after the revision sequence. These commonalities are instances of an important
general result. Let Γ denote the non-empty sequence of inputs γ1 , . . . , γn , and let E ∗ Γ
denote the revision sequence E ∗ γ1 ∗ . . . ∗ γn . Furthermore we shall refer to an epistemic
state E as Γ-compatible provided that ¬γi ∈
/ B(E) for every i in {1, . . . , n}.
(O) If E is Γ-compatible then B(E) ⊆ B(E ∗ Γ)
(O) says that as long as B(E) is not in direct conflict with any of the inputs in the sequence
γ1 , . . . , γn , the entire B(E) has to be propagated to the knowledge base obtained from
the revision sequence E ∗ γ1 ∗ . . . ∗ γn . This is a preservation property that is satisfied by
restrained revision.
Proposition 6 Restrained revision satisfies (O).
Proof: We denote by E ∗ Γi , for i = 0, . . . , n, the revision sequence E ∗ γ1 , . . . , γi (with
E ∗ Γ0 = E). We give an inductive proof that, for ∀v ∈ [B(E)] and ∀w ∈
/ [B(E)], v ≺E∗Γi w
for i = 0, . . . , n. In other words, every B(E)-world is always strictly below every non B(E)world. From this the result follows immediately. For i = 0 this amounts to showing that
v ≺E w which follows immediately from the definition of E and B(E). Now pick any
i = 1, . . . , n and assume that v ≺E∗Γi−1 w. We consider four cases. If v, w ∈ [γi ] then it
follows by (CR1) that v ≺E∗Γi w. If v, w ∈ [¬γi ] then it follows by (CR2) that v ≺E∗Γi w.
If v ∈ [γi ] and w ∈ [¬γi ] then it follows by (PR) that v ≺E∗Γi w. And finally, suppose
v ∈ [¬γi ] and w ∈ [γi ]. By Γi -compatibility there is an x ∈ [B(E)] ∩ [γi ], and by the
inductive hypothesis, x ≺E∗Γi−1 w. So w ∈
/ [B(E ∗ Γi )], and then it follows by (DR) that
v ≺E∗Γi w.

Although restrained revision preserves information which has not been directly contradicted,
it is not dogmatically wedded to older information. If neither of two successive, but incompatible, epistemic states are in conflict with any of the inputs of a sequence Γ = γ1 , . . . , γn ,
it prefers the latter epistemic state when revising by Γ.
Proposition 7 Restrained revision satisfies the following property:
(Q) If E and E∗α are both Γ-compatible but B(E)∪B(E∗α)  ⊥, then B(E∗α) ⊆ B(E∗α∗Γ)
and B(E) * B(E ∗ α ∗ Γ)
Proof: It follows immediately from Proposition 6 that B(E ∗ α) ⊆ B(E ∗ α ∗ Γ). And
B(E) * B(E ∗ α ∗ Γ) then follows from the consistency of B(E ∗ α ∗ Γ).

Next we consider another preservation property, but this time, unlike the case for (O) and
(Q), we look at circumstances where B(E) is incompatible with some of the inputs in a
revision sequence.
140

Admissible and Restrained Revision

(S) If ¬β ∈ B(E ∗ α) and ¬β ∈ B(E ∗ ¬α) then B(E ∗ α ∗ ¬α ∗ β) = B(E ∗ α ∗ β)
Note that, given RAGM, the antecedent of (S) implies that ¬β ∈ B(E). Thus (S) states
that if ¬β is believed initially, and that a subsequent commitment to either α or its negation
would not change this fact, then after the sequence of inputs in which β is preceded by α and
¬α, the second input concerning α is nullified, and the older input regarding α is retained.
Proposition 8 Restrained revision satisfies (S).
Proof: Suppose the antecedent holds. If ¬α !E∗α β then the consequent holds. In fact
this can be seen from the property (T) in Proposition 10 below. So suppose ¬α 6!E∗α β.
Then either α 6∈ B(E ∗ α ∗ β) or ¬β 6∈ B(E ∗ α ∗ ¬α). This latter doesn’t hold by one of
the assumptions together with (C2), so the former must hold. This implies ¬α ∈ B(E ∗ β)
by (P). Combining this with the other assumption we get α !E β. In this case we get
B(E ∗ α ∗ β) = B(E ∗ β) (again using (T)), while (since ¬α 6!E∗α β) B(E ∗ α ∗ ¬α ∗ β) =
B(E ∗ α ∗ (¬α ∧ β)) ((T) once more), which in turn equals B(E ∗ (¬α ∧ β)) by (C2). Since
¬α ∈ B(E ∗ β) this is in turn equal to B(E ∗ β) by RAGM as required.

We now provide a more compact syntactic representation of restrained revision. First we
show that (C1) and (P) can be combined into a single property, and so can (C2) and (D).
Proposition 9 Given RAGM,
1. (C1) and (P) are together equivalent to the single rule
(C1P) If ¬α 6∈ B(E ∗ β) then B(E ∗ α ∗ β) = B(E ∗ (α ∧ β))
2. (C2) and (D) are together equivalent to the single rule
(C2D) If α !E β then B(E ∗ α ∗ β) = B(E ∗ β).
Proof: For (C1),(P)⇒(C1P), suppose ¬α 6∈ B(E∗β). By (P) it follows that α ∈ B(E∗α∗β)
which means, by RAGM, that B(E ∗ α ∗ β) = B(E ∗ α ∗ (α ∧ β)). By (C1) it follows that
B(E∗α∗(α∧β)) = B(E∗(α∧β)), and thus that B(E∗α∗β) = B(E∗(α∧β)). For (C1)⇐(C1P),
suppose that β  α. Then ¬α 6∈ B(E ∗ β) by RAGM, and so B(E ∗ α ∗ β) = B(E ∗ (α ∧ β))
by (C1P). But since β ≡ α ∧ β it follows that B(E ∗ α ∗ β) = B(E ∗ β). For (P)⇐(C1P),
suppose that ¬α 6∈ B(E ∗ β). Then B(E ∗ α ∗ β) = B(E ∗ (α ∧ β)) by (C1P) which means,
by RAGM, that α ∈ B(E ∗ α ∗ β).
For (C2),(D)⇒(C2D), suppose that α !E β. By (D), ¬α ∈ B(E ∗ α ∗ β). By
RAGM this means that B(E ∗ α ∗ β) = B(E ∗ α ∗ (¬α ∧ β)). Now, by (C2) it follows
that B(E ∗ α ∗ (¬α ∧ β)) = B(E ∗ (¬α ∧ β)). So B(E ∗ α ∗ β) = B(E ∗ (¬α ∧ β)). But since
¬α ∈ B(E∗β), we get by RAGM that B(E∗(¬α ∧β)) = B(E∗β), from which it follows that
B(E ∗ α ∗ β) = B(E ∗ β). For (C2)⇐(C2D), suppose that β  ¬α. Then α !E β for any E
and by B(E ∗ α ∗ β) = B(E ∗ β) by (C2D). For (D)⇐(C2D), suppose that α !E β. Then
B(E∗α∗β) = B(E∗β) by (C2D) and since ¬α ∈ B(E∗β), it follows that ¬α ∈ B(E∗α∗β). 
Both (C1P) and (C2D) provide conditions for the reduction of the two-step revision sequence
E ∗ α ∗ β to a single-step revision (if only as regards the resulting knowledge base). (C1P)
141

Booth & Meyer

reduces it to an (α ∧ β)-revision when α is consistent with a β-revision. (C2D) reduces it
to a β-revision, ignoring α completely, when α and β counteract with respect to E. Now,
it follows from RAGM that the consequent of (C1P) also obtains when ¬β 6∈ B(E ∗ α).
Putting this together we get a most succinct characterisation of restrained revision.
Proposition 10 Only restrained revision satisfies RAGM and:

B(E ∗ β)
if α !E β
(T) B(E ∗ α ∗ β) =
B(E ∗ (α ∧ β)) otherwise.
Proof: From Theorem 2 and Proposition 9 it is sufficient to show that RAGM, (C1P) and
(C2D) hold iff RAGM and (T) hold. So, suppose that ∗ satisfies RAGM and (T). (C1P)
follows from the bottom part of (T), while (C2D) follows from the top part. Conversely,
suppose that ∗ satisfies RAGM, (C1P) and (C2D). If α !E β it follows from (C2D) that
B(E ∗ α ∗ β) = B(E ∗ β). If not, we consider two cases. If ¬α ∈
/ B(E ∗ β) it follows from
(C1P) that B(E∗α∗β) = B(E∗(α∧β)). Otherwise it has to be the case that ¬β ∈
/ B(E∗α).
But then it follows from RAGM that B(E ∗ α ∗ β) = B(E ∗ (α ∧ β)).

If we were to replace “α !E β” in the first clause in (T) by the stronger “α and β
are logically inconsistent”, we would obtain instead the characterisation of lexicographic
revision given by Nayak et al. (2003).
Proposition 10 allows us to see clearly another significant property of restrained revision.
For if α !E β then we know ¬α ∈ B(E ∗ α ∗ β) directly from (D), while if α 6!E β then
Proposition 10 tells us B(E ∗ α ∗ β) = B(E ∗ (α ∧ β)) and so α ∈ B(E ∗ α ∗ β) by RAGM.
Thus we see in the state E ∗ α ∗ β the epistemic status of α (either accepted or rejected) is
always completely determined, i.e., we have proved:
Proposition 11 Restrained revision satisfies the following property:
(U) If ¬α 6∈ B(E ∗ α ∗ β) then α ∈ B(E ∗ α ∗ β)
(Given its similar characterisation just mentioned above, it is easy to see lexicographic
revision satisfies (U) too.) Like (P), property (U) can be read as providing conditions
under which the penultimate revision input α should be believed. Its antecedent is simply
saying B(E ∗ α ∗ β) is consistent with α. Thus (U) is saying the penultimate input should be
believed as long as it is consistent to do so. By chaining (U) together with (C4), we easily
see that (U) actually implies (P) in the presence of (C4). As a consequence, we obtain the
following alternative axiomatic characterisation of restrained revision.
Theorem 3 RAGM, (C1), (C2), (C4), (U) and (D) provide an exact characterisation of
restrained revision.
For (U), we are also able to provide a simple semantic counterpart property. It corresponds
to a separating of all the α-worlds from all the ¬α-worlds in the total preorder E∗α following
an α-revision, in that each plausibility level in E∗α either contains only α-worlds or contains
only ¬α-worlds:
Proposition 12 Whenever a revision operator ∗ satisfies RAGM, then ∗ satisfies (U) iff
it satisfies the following property:
142

Admissible and Restrained Revision

(UR) For v ∈ [α] and w ∈ [¬α], either v ≺E∗α w or w ≺E∗α v
Proof: For (U)⇒(UR) suppose (UR) doesn’t hold, i.e., there exist α, v ∈ [α] and w ∈ [¬α]
such that both v E∗α w and w E∗α v. Letting β be such that [β] = {v, w} we get
[B(E ∗ α ∗ β)] = {v, w} from RAGM and thus both ¬α, α 6∈ B(E ∗ α ∗ β) (because of
v, w ∈ [B(E ∗ α ∗ β)] respectively). Hence (U) doesn’t hold.
For (U)⇐(UR) suppose (U) doesn’t hold, i.e., there exist α, β such that both ¬α, α 6∈
B(E ∗ α ∗ β). Then there exist v ∈ [α] and w ∈ [¬α] such that v, w ∈ [B(E ∗ α ∗ β)] =
(by RAGM) min(β, E∗α ). Since both v and w are (E∗α )-minimal β-worlds we must have
both v E∗α w and w E∗α v. Hence α, v, w give a counterexample to (UR).

Finally in this section we turn to two properties first mentioned (as far as we know) by
Schlecta et al. (1996) (see also the work of Lehmann et al. (2001)):
(Disj1) B(E ∗ α ∗ β) ∩ B(E ∗ γ ∗ β) ⊆ B(E ∗ (α ∨ γ) ∗ β)
(Disj2) B(E ∗ (α ∨ γ) ∗ β) ⊆ B(E ∗ α ∗ β) ∪ B(E ∗ γ ∗ β)
(Disj1) says that if a sentence is believed after any one of two sequences of revisions that
differ only at step i (step i being α in one case and γ in the other), then the sentence
should also be believed after that sequence which differs from both only in that step i is
a revision by the disjunction α ∨ γ. Similarly, (Disj2) says that every sentence believed
after an (α ∨ γ)-β-revision should be believed after at least one of (α-β) and (γ-β). Both
conditions are reasonable properties to expect of revision operators.
Proposition 13 Restrained revision satisfies (Disj1) and (Disj2).
To prove this result we will make use of the properties of the counteracts relation given
in Proposition 4, along with the following lemma.
Lemma 4 If α !E β and (α ∨ γ) 6!E β then B(E ∗ ((α ∨ γ) ∧ β)) = B(E ∗ (γ ∧ β))
Proof: Suppose α !E β and (α ∨ γ) 6!E β. We will first show that this implies
¬α ∈ B(E∗((α∨γ)∧β)). We will then be able to conclude the required B(E∗((α∨γ)∧β)) =
B(E ∗ (γ ∧ β)) using RAGM. So suppose on the contrary ¬α 6∈ B(E ∗ ((α ∨ γ) ∧ β)). Then
there exists some α-world w ∈ min((α ∨ γ) ∧ β, E ). Then also w ∈ min(α ∧ β, E ). Since
α !E β we know from Proposition 3 there exist an α-world w1 and a β-world w2 such
that wi ≺E w for i = 1, 2. Clearly w1 is also a (α ∨ γ)-world, so we infer (α ∨ γ) 6!E β –
contradiction. Hence ¬α ∈ B(E ∗ ((α ∨ γ) ∧ β)) as required.

Proof:[of Proposition 13] We prove both properties simultaneously by looking at two cases:
Case (i): (α ∨ γ) !E β. In this case B(E ∗ (α ∨ γ) ∗ β) = B(E ∗ β) by property (T) in
Proposition 10. Meanwhile we know from Proposition 4(ii) that either α !E β or γ !E β,
and so using (T) again we know at least one of B(E ∗ α ∗ β) and B(E ∗ γ ∗ β) must also be
equal to B(E ∗ β). Hence we see both (Disj1) and (Disj2) hold in this case.
Case (ii): (α ∨ γ) 6!E β. In this case (T) tells us B(E ∗ (α ∨ γ) ∗ β) = B(E ∗ ((α ∨ γ) ∧ β)) =
B(E ∗ ((α ∧ β) ∨ (γ ∧ β)). Meanwhile Proposition 4(i) tells us at least one of α 6!E β
and γ 6!E β holds. We now consider two subcases according to which either both these
143

Booth & Meyer

hold, or only one holds. If both these hold then B(E ∗ α ∗ β) = B(E ∗ (α ∧ β)) and
B(E ∗ γ ∗ β) = B(E ∗ (γ ∧ β)), so (Disj1) and (Disj2) reduce to
(Disj10 ) B(E ∗ (α ∧ β)) ∩ B(E ∗ (γ ∧ β)) ⊆ B(E ∗ ((α ∧ β) ∨ (γ ∧ β)))
(Disj20 ) B(E ∗ ((α ∧ β) ∨ (γ ∧ β))) ⊆ B(E ∗ (α ∧ β)) ∪ B(E ∗ (γ ∧ β))
respectively. Now it is a consequence of RAGM that for any sentences θ, φ we have both
(1) B(E ∗ θ) ∩ B(E ∗ φ) ⊆ B(E ∗ (θ ∨ φ)) and (2) B(E ∗ (θ ∨ φ)) ⊆ B(E ∗ θ) ∪ B(E ∗ φ).
Substituting α ∧ β for θ and γ ∧ β for φ here gives us the required (Disj10 ) (from (1)) and
(Disj20 ) (from (2)).
Now let’s consider the subcase where α !E β and γ 6!E β. (A symmetric argument
will work for the other subcase α 6!E β and γ !E β.) Then from γ 6!E β we get
B(E ∗ γ ∗ β) = B(E ∗ (γ ∧ β)), while from α !E β together with (α ∨ γ) 6!E β we get also
B(E∗(α∨γ)∗β) = B(E∗(γ∧β)) using Lemma 4. So in this case B(E∗(α∨γ)∗β) = B(E∗γ∗β),
from which both (Disj1) and (Disj2) follow immediately.

We end this section by remarking that it can be shown that lexicographic revision also
satisfies (Disj1) and (Disj2).

5. Restrained Revision as a Composite Operator
As we saw in Section 3, Boutilier’s natural revision operator – let us denote it in this section
by ⊕ – is vulnerable to damaging counterexamples such as the red bird Example 2, and
fails to satisfy the very reasonable postulate (P). Although a new input α is accepted in the
very next epistemic state E ⊕ α, ⊕ does not in any way provide for the preservation of α
after subsequent revisions. As Hans Rott (2003, p.128) describes it, “[t]he most recent input
sentence is always embraced without reservation, the last but one input sentence, however,
is treated with utter disrespect”. Thus, there seem to be convincing reasons to reject ⊕ as a
viable operator for performing iterated revision. However, the literature on epistemic state
change constantly reminds us that keeping changes minimal should be a major concern, and
when judged from a purely minimal change viewpoint, it is clear that ⊕ can’t be beaten!
How can we find our way out of this apparent quandary? In this section we show that the
use of ⊕ can be retained, provided its application is preceded by an intermediate operation
in which, rather than revising E by new input α, essentially α is revised by E.
Given an epistemic state E and sentence α, let us denote by E / α the result of this
intermediate operation. E / α is an epistemic state. The idea is that when forming E / α,
the information in E should be maintained. That is, the total preorder E/α should satisfy
v ≺E w implies v ≺E/α w.

(1)

But rather than leaving behind α entirely in favour of E, as much of the informational
content of α should be preserved in E / α as possible. This is formalised by saying that for
any v ∈ [α], w ∈ [¬α], we should take v ≺E/α w as long as this does not conflict with (1)
above. It is this second requirement which will guarantee α enough of a “presence” in the
revised epistemic state E ∗ α to help it survive subsequent revisions and allow (P) to be
144

Admissible and Restrained Revision

captured. Taken together, the above two requirements are enough to specify E/α uniquely:

v ≺E w, or
v E/α w iff
(2)
v E w and (v ∈ [α] or w ∈ [¬α]).
Thus, E/α is just the lexicographic refinement of E by the “two-level” total preorder α
defined by v α w iff v ∈ [α] or w ∈ [¬α]. This “backwards revision” operator is not new.
It has been studied by Papini (2001). It can also be viewed as just a “backwards” version
of Nayak’s lexicographic revision operator. We do not necessarily have α ∈ B(E / α) (this
will hold only if ¬α 6∈ B(E)), and so / does not satisfy RAGM.
Given /, we can define the composite revision operator ∗/ by setting
E ∗/ α = (E / α) ⊕ α

(3)

This is reminiscent of the Levi Identity (Gärdenfors, 1988), used in AGM theory as a recipe
for reducing the operation of revision on knowledge bases to a composite operation consisting
of contraction plus expansion. In (3), ⊕ is playing the role of expansion. The operator ∗/
does satisfy RAGM. In fact, as can easily be seen by comparing (2) above with condition
(RR) at the start of Section 4, ∗/ coincides with restrained revision.
Proposition 14 Let ∗R denote the restrained revision operator. Then ∗R = ∗/ .
Thus we have proved that restrained revision can be viewed as a combination of two existing
operators.

6. How to Choose a Revision Operator
The contribution of this paper so far can be summarised as follows. We have argued for
the replacement of the Darwiche-Pearl framework by the class of admissible revision operators, arguing that the former needs to be strengthened. In doing so we have eliminated
natural revision, but retained lexicographic revision and the • operator of Darwiche and
Pearl as admissible operators. We have also introduced a new admissible revision operator,
restrained revision, and argued for its plausibility. But this is not an argument that restrained revision is somehow unique, or more preferred than other revision operators. The
contention is merely that, for epistemic state revision, the Darwiche-Pearl framework is
too weak and should be replaced by admissible revision. And restrained revision, being an
admissible revision operator, is therefore only one of many revision operators deemed to be
rational. The question of which admissible revision operator to use in a particular situation
is one which depends on a number of issues, such as context, the strength with which certain
beliefs are held, the source of the information, and so on. This point has essentially also
been made by Friedman and Halpern (1999). For example, Example 3 formed part of an
argument for the use of restrained revision, and against the use of lexicographic revision.
In effect we used the example to argue that red ought to be in B (E ∗ red → bird ∗ ¬bird),
where B(E) = Cn(red). But if we change the context slightly, it becomes an example in
favour of the use of lexicographic revision, and against restrained revision.
Example 5 We observe a creature which seems to be red, but we are too far away to
determine whether it is a bird or a land animal. So we adopt the knowledge base B(E) =
145

Booth & Meyer

Cn(red). Next to us is an expert on birds who remarks that, if the creature is indeed red, it
must be a bird. So we adopt the belief red → bird. Then we get information from someone
standing closer to the creature that it is not a bird. Given this context, that is, the reliability
of the expert combined with the statement that the creature initially seemed to be red, it is
reasonable to adopt the lexicographic approach of “more recent is best” and conclude that
the bird is not red. Formally, ¬red ∈ B (E ∗ red → bird ∗ ¬bird), where B(E) = Cn(red).
For a case where the source of the information dramatically affects the outcome, consider
the following example.
Example 6 Consider the sequence of inputs where p is followed by a finite number, say n,
of instances of the pair p → q, ¬q. (To make this more concrete, the reader might wish to
substitute p with red and q with bird.) Since p is not in direct conflict with any sentences in
the sequence succeeding it, any revision operator satisfying the property O (and this includes
restrained revision) will require that p be contained in the knowledge base obtained from this
revision sequence. Now, if each pair p → q and ¬q is obtained from a different source, such
a conclusion is clearly unreasonable. After all, such a sequence amounts to being told that
p is the case, followed by n different sources essentially telling you that ¬p is the case. On
the other hand, if the pairs p → q and ¬q all come from the same source, the case is not so
clear cut anymore. In fact, in this case one would expect the result to be the same as that
obtained from the sequence p, p → q, ¬q, a sequence with the same formal structure as that
employed in Example 3, where restrained revision was seen to be a reasonable approach.
Another example in which restrained revision fares less well is the following:4
Example 7 Suppose we are teaching a class of students consisting of n boys and m girls,
and suppose the class takes part in a mathematics competition. For each i = 1, . . . , n and
j = 1, . . . , m let the propositional variables pi and qj stand for “boy i won the competition”
and “girl j won the competition” respectively, and suppose initially
W we believe one of the
boys won the competition, i.e., B(E) = Cn(φ ∧ Σ) where φ = i pi and Σ is just some
sentence expressing the uniqueness of the competition winner. Now suppose we interview
each of the boys one after the other, and each of them tells us that either one of the girls
or he himself won, i.e., we obtain the sequence of inputs (¬φ ∨ pi )i . Suppose we are willing
to accept the boys’ testimony. Using a revision operator which satisfies O will lead us to
believe boy n won the competition, which seems implausible. Lexicographic revision gives
the desired result that one of the girls won the competition.
From these examples it is clear that an agent need not, and in most cases, ought not
to stick to the same revision operator every time that it has to perform a revision. This
means that the agent will keep on switching from one revision operator to another during the
process of iterated revision. Of course, this leads to the question of how to choose among the
available (admissible) revision operators at any particular point. A comprehensive answer
to this question is beyond the scope of this paper, but we do provide some clues on how to
address the problem. In brief, we contend that epistemic states have to be enriched, with a
more detailed specification of their internal structure. Looking back at the history of belief
revision, we can see that this is exactly how the field has progressed. In the initial papers,
4. We are grateful to one of the anonymous referees for suggesting this example.

146

Admissible and Restrained Revision

such as those on AGM revision, an epistemic state was taken to contain nothing more than
a knowledge base. So, for example, basic AGM revision as characterised by the first six
AGM postulates imposes no structure on epistemic states at all. We shall refer to these as
simple epistemic states. With full AGM belief revision as characterised by all eight AGM
postulates, the view is still one of the revision of knowledge bases, but now every revision
operator for knowledge base B is uniquely associated with a B-faithful total preorder; i.e.,
a total preorder on valuations with the models of B as its minimal elements. From here
it is a small step to define epistemic states to include such an ordering, i.e. to include the
total preorder E associated with an epistemic state E as part of the definition of E. We
shall refer to these as complex epistemic states.
This leads to two different views of the same revision process. If we view revision
as an operator on simple epistemic states we have many different revision operators; one
corresponding to each of the B-faithful total preorders, but with no way to distinguish
between them when having to choose a revision operator. Viewed as such, iterated revision
is a process in which a (possibly) different revision operator is employed at every revision
step. This is the principal view adopted by Nayak et al. (2003). However, if we view
revision as an operator on complex epistemic states, every epistemic state contains enough
information to determine uniquely the knowledge base, but not the faithful total preorder,
resulting from the revision. In other words, we now have enough information encoded in
an epistemic state to uniquely determine the knowledge base resulting from a revision, but
we lack the information to uniquely determine the full epistemic state. The DarwichePearl framework, and now also admissible revision, place some constraints on the resulting
epistemic state, but do not impose any additional structure on the complex epistemic state.
In our view admissible revision for complex epistemic states is analogous to basic AGM
revision for simple epistemic states. The next step would thus be to impose additional
structure on complex epistemic states. This could possibly involve the addition of a second
ordering on valuations as was done, for example, by Booth et al. (2004). In the case of
simple epistemic states the effect of adding the two supplementary postulates is to constrain
basic revision to the extent that each revision operator can be uniquely associated with a Bfaithful total preorder. In that sense, the addition of the supplementary postulates allowed
for the imposition of additional structure on simple epistemic states. Recall that one way of
interpreting the two supplementary postulates is that they explain the interaction between
revision by two sentences and revision by their conjunction, something the basic postulates
do not address.
So, as we have seen, the addition of the supplementary postulates leads to the definition
of revision as operators on complex epistemic states. We conjecture that giving additional
structure to complex epistemic states might involve the provision of postulates analogous to
the two AGM supplementary postulates. In particular, we conjecture that such postulates
might be such that they explain the interaction between two sentences and their conjunction,
or disjunction, for iterated revision. Observe that none of the Darwiche-Pearl postulates,
or the additional postulates for admissible revision for that matter, address this issue. In
fact the only postulates to have been suggested (of which we are aware) which so far do
address it are (Disj1) and (Disj2). We speculate that the appropriate set of supplementary
postulates for iterated revision (which may or may not include the two just mentioned) will
lead to the definition of extra structure on complex epistemic states, which can then be
147

Booth & Meyer

incorporated into an enriched version of complex epistemic states, with revision then being
seen as operators on these enriched entities. Let us refer to them as enriched epistemic
states. Enriched epistemic states will enable us to determine uniquely the complex epistemic
state resulting from a revision, thereby solving the question we started off with; that of
determining which revision on complex epistemic states to use at every particular point
during a process of iterated revision. Below we shall briefly discuss a possible way of
enriching complex epistemic states. But note also that a recent proposal for doing so is
that of Booth et al. (2006). It is instructive to observe that (Disj1) and (Disj2) both hold
in their framework.
The proposed outline above is not without its pitfalls. The most obvious problem with
such an approach is that it leaves us with a meta-version of the dilemma that we started off
with. Using enriched epistemic states we are now able to uniquely determine the complex
epistemic states resulting from a revision, but not the resulting enriched epistemic state. We
can lessen the problem by constraining the permissible resulting enriched epistemic states in
the same way that admissible revision constrains the permissible complex epistemic states,
but chances are that this whittling down will not produce a single permissible enriched
epistemic state. And, of course, this is bound to occur over and over again. That is,
whenever we solve the problem of uniquely determining an epistemic state with a certain
structure by a process of further enrichment, we will be saddled with the question of how
to uniquely determine the further enriched epistemic state resulting from a revision. Our
conjecture is that at some level a point will be reached where constraining further enriched
epistemic states, á la admissible revision, will eventually lead to a unique further enriched
epistemic state associated with every revision. Only further research will determine whether
our conjecture holds water.
In conclusion, we have shown that the Darwiche-Pearl arguments lead to the acceptance
of the admissible revision operators as a class worthy of study. The restrained revision
operator, in particular, exhibits quite desirable properties. Besides taking the place of
natural revision as the operator adhering most closely to the principle of minimal change,
its satisfaction of the properties (O), (Q) and (U) shows that it does not unnecessarily
remove previously obtained information.
For future work we would also like to explore more thoroughly the class of admissible
revision operators. In this paper we saw that restrained revision and lexicographic revision
lie at opposite ends of the spectrum of admissible operators. They represent respectively
the most conservative and the least conservative admissible operators in the sense that
they effect the most changes and the least changes, respectively, in the relative ordering
of valuations permitted by admissible revision. A natural question is whether there exists
an axiomatisable class of admissible operators which represents the “middle ground”. One
clue for finding such a class can be found in the counteracts relation !E which can be
derived from an epistemic state E. As we said, this relation depends only on the preorder
E associated to E. In fact, given any total preorder  over V we can define the relation
! by
α ! β iff min(α, ) ⊆ [¬β] and min(β, ) ⊆ [¬α].
Then clearly !E =!E . Furthermore if  is the full relation V × V then ! reduces to
logical inconsistency. A counteracts relation stronger than !E , but still weaker than logical
inconsistency can be found by setting !=!0 , where 0 lies somewhere in between E
148

Admissible and Restrained Revision

and V × V . Hence one avenue worth exploring might be to assume that from each epistemic
state E we can extract not one but two preorders E and 0E such that E ⊆0E . Then,
instead of only requiring α !E β to deduce ¬α ∈ B(E ∗ α ∗ β), as is done with restrained
revision (the postulate (D)), we could require the stronger condition α !0E β for this
to hold. We are currently experimenting with strategies for using the second preorder to
guide the manipulation of E to enable this property to be satisfied. The use of a second
preorder can be seen as a way of enriching the epistemic state, and might thus contribute
to the solution of the choice of revision operators discussed in Section 6.
Some more future work relates also to the two extreme cases revision, but looked at
from a different angle. As mentioned earlier, lexicographic revision is a formalisation of
the “most recent is best” approach to revision taken to its logical extreme. This approach
is exemplified by the (E∗2) postulate, also known as Success, which requires a revision to
be successful, in the sense that the epistemic input provided always has to be contained
in the resulting knowledge base. Given that (E∗2) is one of the postulates for admissible
revision, this requirement carries over even to restrained revision, which is on the opposite
end of the spectrum for admissible revision. But this means that the admissible revision
operator which differs the most from lexicographic revision still adheres to the dictum of
“most recent is best”, which raises the question of why the most recent input is given
such prominence. The relaxation of this requirement would imply giving up (E∗2) and
venturing into the area known as non-prioritised revision (Booth, 2001; Chopra, Ghose, &
Meyer, 2003; Hansson, 1999). We speculate that an appropriate relaxation of admissible
revision, with (E∗2) removed as a requirement, will lead to a class of (non-prioritised)
revision operators strictly containing admissible revision, and with lexicographic revision
still at one end of the spectrum, but with the other end of the spectrum occupied by the
operator studied by Papini (2001) which was used as a sub-operation of restrained revision
in Section 5. This operator is formalised by the extreme version of “most recent is worst”;
in other words, “the older the better”.

Acknowledgements
Much of the first author’s work was done during stints as a researcher at Wollongong
University and Macquarie University, Sydney. He wishes to thank Aditya Ghose and Abhaya
Nayak both for making it possible to enjoy the great working environments there, and
also for some interesting comments on this work. Thanks are also due to Samir Chopra
who contributed to a preliminary version of the paper, Adnan Darwiche for clearing up
some misconceptions on the definition of epistemic states, and three anonymous referees for
their valuable and insightful comments. National ICT Australia is funded by the Australia
Government’s Department of Communications, Information and Technology and the Arts
and the Australian Research Council through Backing Australia’s Ability and the ICT
Centre of Excellence program. It is supported by its members the Australian National
University, University of NSW, ACT Government, NSW Government and affiliate partner
University of Sydney.
149

Booth & Meyer

References
Alchourrón, C. E., Gärdenfors, P., & Makinson, D. (1985). On the logic of theory change:
Partial meet functions for contraction and revision. Journal of Symbolic Logic, 50,
510–530.
Areces, C., & Becher, V. (2001). Iterable AGM functions. In Frontiers in belief revision,
pp. 261–277. Kluwer, Dordrecht.
Booth, R. (2001). A negotiation-style framework for non-prioritised revision. In van Benthem, J. (Ed.), Theoretical Aspects of Rationality and Knowledge: Proceedings of the
Eighth Conference (TARK 2001), pp. 137–150, San Francisco, California. Morgan
Kaufmann.
Booth, R. (2005). On the logic of iterated non-prioritised revision. In Conditionals, Information and Inference – Selected papers from the Workshop on Conditionals, Information
and Inference, 2002, Vol. 3301 of LNAI, pp. 86–107. Springer-Verlag, Berlin.
Booth, R., Chopra, S., Ghose, A., & Meyer, T. (2004). A unifying semantics for belief
change. In Mantaras, R. L. D., & Saitta, L. (Eds.), Sixteenth European Conference
on Artificial Intelligence: ECAI2004, pp. 793–797. IOS Press.
Booth, R., Meyer, T., & Wong, K.-S. (2006). A bad day surfing is better than a good day
working: How to revise a total preorder. In Proceedings of KR2006, Tenth International Conference on the Principles of Knowledge Representation and Reasoning.
Boutilier, C. (1993). Revision sequences and nested conditionals. In Bajcsy, R. (Ed.), IJCAI93. Proceedings of the 13th International Joint Conference on Artificial Intelligence
held in Chambery, France, August 28 to September 3, 1993, Vol. 1, pp. 519–525, San
Mateo, CA. Morgan Kaufmann.
Boutilier, C. (1996). Iterated revision and minimal changes of conditional beliefs. Journal
of Philosophical Logic, 25 (3), 263–305.
Chopra, S., Ghose, A., & Meyer, T. (2003). Non-prioritized ranked belief change. Journal
of Philosophical Logic, 32 (3), 417–443.
Dalal, M. (1988). Investigations into a theory of knowledge base revision. In Proceedings of
the 7th National Conference of the American Association for Artificial Intelligence,
Saint Paul, Minnesota, pp. 475–479.
Darwiche, A., & Pearl, J. (1997). On the logic of iterated belief revision. Artificial Intelligence, 89, 1–29.
Freund, M., & Lehmann, D. (1994). Belief revision and rational inference. Tech. rep. TR
94-16, The Leibniz Centre for Research in Computer Science, Institute of Computer
Science, Hebrew University of Jerusalem.
Friedman, N., & Halpern, J. Y. (1999). Belief revision: A critique. Journal of Logic,
Language and Information, 8, 401–420.
Gärdenfors, P. (1988). Knowledge in Flux : Modeling the Dynamics of Epistemic States.
The MIT Press, Cambridge, Massachusetts.
Glaister, S. M. (1998). Symmetry and belief revision. Erkenntnis, 49, 21–56.
150

Admissible and Restrained Revision

Grove, A. (1988). Two modellings for theory change. Journal of Philosophical Logic, 17,
157–170.
Hansson, S. O. (1999). A survey of non-prioritized belief revision. Erkenntnis, 50, 413–427.
Jin, Y., & Thielscher, M. (2005). Iterated belief revision, revised. In Proceedings of the
Nineteenth International Joint Conference on Artificial Intelligence (IJCAI 05), pp.
478–483.
Katsuno, H., & Mendelzon, A. O. (1991). Propositional knowledge base revision and minimal change. Artificial Intelligence, 52, 263–294.
Konieczny, S., & Pino Pérez, R. (2000). A framework for iterated revision. Journal of
Applied Non-Classical Logics, 10(3-4), 339–367.
Lehmann, D. (1995). Belief revision, revised. In Proceedings of the Fourteenth International
Joint Conference on Artificial Intelligence (IJCAI’95), pp. 1534–1540.
Lehmann, D., Magidor, M., & Schlechta, K. (2001). Distance semantics for belief revision.
Journal of Symbolic Logic, 66, 295–317.
Lewis, D. K. (1973). Counterfactuals. Journal of Philosophy, 70, 556–567.
Nayak, A. C. (1993). Studies in Belief Change. Ph.D. thesis, University of Rochester.
Nayak, A. C. (1994). Iterated belief change based on epistemic entrenchment. Erkenntnis,
41, 353–390.
Nayak, A. C., Foo, N. Y., Pagnucco, M., & Sattar, A. (1996). Changing Conditional Belief
Unconditionally. In Shoham, Y. (Ed.), Theoretical Aspects of Rationality and Knowledge: Proceedings of the Sixth Conference (TARK 1996), pp. 119–136, San Francisco,
California. Morgan Kaufmann.
Nayak, A. C., Pagnucco, M., & Peppas, P. (2003). Dynamic belief change operators. Artificial Intelligence, 146, 193–228.
Papini, O. (2001). Iterated revision operations stemming from the history of an agent’s
observations. In Frontiers in belief revision, pp. 281–303. Kluwer, Dordrecht.
Rott, H. (2000). Two dogmas of belief revision. Journal of Philosophy, 97, 503–522.
Rott, H. (2003). Coherence and conservatism in the dynamics of belief II: Iterated belief
change without dispositional coherence. Journal of Logic and Computation, 13 (1),
111–145.
Schlechta, K., Lehmann, D., & Magidor, M. (1996). Distance semantics for belief revision.
In Shoham, Y. (Ed.), Proceedings of the Sixth Conference on Theoretical Aspects of
Rationality and Knowledge, pp. 137–145. Morgan Kaufmann.
Segerberg, K. (1998). Irrevocable belief revision in dynamic doxastic logic. Notre Dame
Journal of Formal Logic, 39, 287–306.
Spohn, W. (1988). Ordinal conditional functions: A dynamic theory of epistemic states.
In Harper, W. L., & Skyrms, B. (Eds.), Causation in Decision: Belief, Change and
Statistics: Proceedings of the Irvine Conference on Probability and Causation: Volume
II, Vol. 42 of The University of Western Ontario Series in Philosophy of Science, pp.
105–134, Dordrecht. Kluwer Academic Publishers.

151

Journal of Artificial Intelligence Research 26 (2006) 35-99

Submitted 8/05; published 5/06

Planning Graph Heuristics for Belief Space Search
Daniel Bryce
Subbarao Kambhampati,

DAN . BRYCE @ ASU . EDU
RAO @ ASU . EDU

Department of Computer Science and Engineering
Ira A. Fulton School of Engineering
Arizona State University, Brickyard Suite 501
699 South Mill Avenue, Tempe, AZ 85281

David E. Smith

DE 2 SMITH @ EMAIL . ARC . NASA . GOV

NASA Ames Research Center
Intelligent Systems Division, MS 269-2
Moffett Field, CA 94035-1000

Abstract
Some recent works in conditional planning have proposed reachability heuristics to improve
planner scalability, but many lack a formal description of the properties of their distance estimates.
To place previous work in context and extend work on heuristics for conditional planning, we
provide a formal basis for distance estimates between belief states. We give a definition for the
distance between belief states that relies on aggregating underlying state distance measures. We
give several techniques to aggregate state distances and their associated properties. Many existing
heuristics exhibit a subset of the properties, but in order to provide a standardized comparison we
present several generalizations of planning graph heuristics that are used in a single planner. We
compliment our belief state distance estimate framework by also investigating efficient planning
graph data structures that incorporate BDDs to compute the most effective heuristics.
We developed two planners to serve as test-beds for our investigation. The first, CAltAlt,
is a conformant regression planner that uses A* search. The second, P ON D, is a conditional
progression planner that uses AO* search. We show the relative effectiveness of our heuristic
techniques within these planners. We also compare the performance of these planners with several
state of the art approaches in conditional planning.

1. Introduction
Ever since CGP (Smith & Weld, 1998) and SGP (Weld, Anderson, & Smith, 1998) a series of planners have been developed for tackling conformant and conditional planning problems – including
GPT (Bonet & Geffner, 2000), C-Plan (Castellini, Giunchiglia, & Tacchella, 2001), PKSPlan (Petrick & Bacchus, 2002), Frag-Plan (Kurien, Nayak, & Smith, 2002), MBP (Bertoli, Cimatti, Roveri,
& Traverso, 2001b), KACMBP (Bertoli & Cimatti, 2002), CFF (Hoffmann & Brafman, 2004), and
YKA (Rintanen, 2003b). Several of these planners are extensions of heuristic state space planners
that search in the space of “belief states” (where a belief state is a set of possible states). Without
full-observability, agents need belief states to capture state uncertainty arising from starting in an
uncertain state or by executing actions with uncertain effects in a known state. We focus on the
first type of uncertainty, where an agent starts in an uncertain state but has deterministic actions.
We seek strong plans, where the agent will reach the goal with certainty despite its partially known
state. Many of the aforementioned planners find strong plans, and heuristic search planners are
c
2006
AI Access Foundation. All rights reserved.

B RYCE , K AMBHAMPATI , & S MITH

currently among the best. Yet a foundation for what constitutes a good distance-based heuristic for
belief space has not been adequately investigated.
Belief Space Heuristics: Intuitively, it can be argued that the heuristic merit of a belief state depends
on at least two factors–the size of the belief state (i.e., the uncertainty in the current state), and the
distance of the individual states in the belief state from a destination belief state. The question of
course is how to compute these measures and which are most effective. Many approaches estimate
belief state distances in terms of individual state to state distances between states in two belief
states, but either lack effective state to state distances or ways to aggregate the state distances. For
instance the MBP planner (Bertoli et al., 2001b) counts the number of states in the current belief
state. This amounts to assuming each state distance has unit cost, and planning for each state can be
done independently. The GPT planner (Bonet & Geffner, 2000) measures the state to state distances
exactly and takes the maximum distance, assuming the states of the belief state positively interact.
Heuristic Computation Substrates: We characterize several approaches to estimating belief state
distance by describing them in terms of underlying state to state distances. The basis of our investigation is in adapting classical planning reachability heuristics to measure state distances and
developing state distance aggregation techniques to measure interaction between plans for states in
a belief state. We take three fundamental approaches to measure the distance between two belief
states. The first approach does not involve aggregating state distance measures, rather we use a
classical planning graph to compute a representative state distance. The second retains distinctions
between individual states in the belief state by using multiple planning graphs, akin to CGP (Smith
& Weld, 1998), to compute many state distance measures which are then aggregated. The third
employs a new planning graph generalization, called the Labelled Uncertainty Graph (LU G), that
blends the first two to measure a single distance between two belief states. With each of these techniques we will discuss the types of heuristics that we can compute with special emphasis on relaxed
plans. We present several relaxed plan heuristics that differ in terms of how they employ state distance aggregation to make stronger assumptions about how states in a belief state can co-achieve
the goal through action sequences that are independent, positively interact, or negatively interact.
Our motivation for the first of the three planning graph techniques for measuring belief state
distances is to try a minimal extension to classical planning heuristics to see if they will work for us.
Noticing that our use of classical planning heuristics ignores distinctions between states in a belief
state and may provide uninformed heuristics, we move to the second approach where we possibly
build exponentially many planning graphs to get a better heuristic. With the multiple planning
graphs we extract a heuristic from each graph and aggregate them to get the belief state distance
measure. If we assume the states of a belief state are independent, we can aggregate the measures
with a summation. Or, if we assume they positively interact we can use a maximization. However,
as we will show, relaxed plans give us a unique opportunity to measure both positive interaction and
independence among the states by essentially taking the union of several relaxed plans. Moreover,
mutexes play a role in measuring negative interactions between states. Despite the utility of having
robust ways to aggregate state distances, we are still faced with the exponential blow up in the
number of planning graphs needed. Thus, our third approach seeks to retain the ability to measure
the interaction of state distances but avoid computing multiple graphs and extracting heuristics
from each. The idea is to condense and symbolically represent multiple planning graphs in a single
planning graph, called a Labelled Uncertainty Graph (LU G). Loosely speaking, this single graph
unions the causal support information present in the multiple graphs and pushes the disjunction,
36

P LANNING G RAPH H EURISTICS FOR B ELIEF S PACE S EARCH

describing sets of possible worlds (i.e., initial literal layers), into “labels”. The planning graph
vertices are the same as those present in multiple graphs, but redundant representation is avoided.
For instance an action that was present in all of the multiple planning graphs would be present only
once in the LU G and labelled to indicate that it is applicable in a planning graph projection from
each possible world. We will describe how to extract heuristics from the LU G that make implicit
assumptions about state interaction without explicitly aggregating several state distances.
Ideally, each of the planning graph techniques considers every state in a belief state to compute
heuristics, but as belief states grow in size this could become uninformed or costly. For example,
the single classical planning graph ignores distinctions between possible states where the heuristic
based on multiple graphs leads to the construction of a planning graph for each state. One way to
keep costs down is to base the heuristics on only a subset of the states in our belief state. We evaluate
the effect of such a sampling on the cost of our heuristics. With a single graph we sample a single
state and with multiple graphs and the LU G we sample some percent of the states. We evaluate
state sampling to show when it is appropriate, and find that it is dependent on how we compute
heuristics with the states.
Standardized Evaluation of Heuristics: An issue in evaluating the effectiveness of heuristic techniques is the many architectural differences between planners that use the heuristics. It is quite hard
to pinpoint the global effect of the assumptions underlying their heuristics on performance. For
example, GPT is outperformed by MBP–but it is questionable as to whether the credit for this efficiency is attributable to the differences in heuristics, or differences in search engines (MBP uses a
BDD-based search). Our interest in this paper is to systematically evaluate a spectrum of approaches
for computing heuristics for belief space planning. Thus we have implemented heuristics similar
to GPT and MBP and use them to compare against our new heuristics developed around the notion
of overlap (multiple world positive interaction and independence). We implemented the heuristics
within two planners, the Conformant-AltAlt planner (CAltAlt) and the Partially-Observable NonDeterministic planner (P ON D). P ON D does handle search with non-deterministic actions, but
for the bulk of the paper we discuss deterministic actions. This more general action formulation, as
pointed out by Smith and Weld (1998), can be translated into initial state uncertainty. Alternatively,
in Section 8.2 we discuss a more direct approach to reason with non-deterministic actions in the
heuristics.
External Evaluation: Although our main interest in this paper is to evaluate the relative advantages of a spectrum of belief space planning heuristics in a normalized setting, we also compare
the performance of the best heuristics from this work to current state of the art conformant and
conditional planners. Our empirical studies show that planning graph based heuristics provide effective guidance compared to cardinality heuristics as well as the reachability heuristic used by GPT
and CFF, and our planners are competitive with BDD-based planners such as MBP and YKA, and
GraphPlan-based ones such as CGP and SGP. We also notice that our planners gain scalability with
our heuristics and retain reasonable quality solutions, unlike several of the planners we compare
against.
The rest of this paper is organized as follows. We first present the CAltAlt and P ON D planners
by describing their state and action representations as well as their search algorithms. To understand
search guidance in the planners, we then discuss appropriate properties of heuristic measures for
belief space planning. We follow with a description of the three planning graph substrates used to
compute heuristics. We carry out an empirical evaluation in the next three sections, by describing
37

B RYCE , K AMBHAMPATI , & S MITH

our test setup, presenting a standardized internal comparison, and finally comparing with several
other state of the art planners. We end with related research, discussion, prospects for future work,
and various concluding remarks.

2. Belief Space Planners
Our planning formulation uses regression search to find strong conformant plans and progression
search to find strong conformant and conditional plans. A strong plan guarantees that after a finite
number of actions executed from any of the many possible initial states, all resulting states are goal
states. Conformant plans are a special case where the plan has no conditional plan branches, as in
classical planning. Conditional plans are a more general case where plans are structured as a graph
because they include conditional actions (i.e. the actions have causative and observational effects).
In this presentation, we restrict conditional plans to DAGs, but there is no conceptual reason why
they cannot be general graphs. Our plan quality metric is the maximum plan path length.
We formulate search in the space of belief states, a technique described by Bonet and Geffner
(2000). The planning problem P is defined as the tuple D, BSI , BSG , where D is a domain
description, BSI is the initial belief state, and BSG is the goal belief state (consisting of all states
satisfying the goal). The domain D is a tuple F, A, where F is a set of fluents and A is a set of
actions.
Logical Formula Representation: We make extensive use of logical formulas over F to represent
belief states, actions, and LU G labels, so we first explain a few conventions. We refer to every
fluent in F as either a positive literal or a negative literal, either of which is denoted by l. When
discussing the literal l, the opposite polarity literal is denoted ¬l. Thus if l = ¬at(location1), then
¬l = at(location1). We reserve the symbols ⊥ and  to denote logical false and true, respectively.
Throughout the paper we define the conjunction of an empty set equivalent to , and the disjunction
of an empty set as ⊥.
Logical formulas are propositional sentences comprised of literals, disjunction, conjunction, and
negation. We refer to the set of models of a formula f as M(f ). We consider the disjunctive normal
ˆ ), and the conjunctive normal form of f , κ(f ). The DNF is seen as
form of a logical formula f , ξ(f
a disjunction of “constituents” Ŝ each of which is a conjunction of literals. Alternatively the CNF
is seen as a conjunction of “clauses” C each of which is a disjunction of literals.1 We find it useful
to think of DNF and CNF represented as sets – a disjunctive set of constituents or a conjunctive set
of clauses. We also refer to the complete representation ξ(f ) of a formula f as a DNF where every
constituent – or in this case state S – is a model of f .
Belief State Representation: A world state, S, is represented as a complete interpretation over
fluents. We also refer to states as possible worlds. A belief state BS is a set of states and is symbolically represented as a propositional formula over F . A state S is in the set of states represented by
a belief state BS if S ∈ M(BS), or equivalently S |= BS.
For pedagogical purposes, we use the bomb and toilet with clogging and sensing problem,
BTCS, as a running example for this paper.2 BTCS is a problem that includes two packages, one of
ˆ ) are readily related. Specifically each constituent contains k of the |F | literals,
1. It is easy to see that M(f ) and ξ(f
corresponding to 2|F |−k models.
2. We are aware of the negative publicity associated with the B&T problems and we do in fact handle more interesting
problems with difficult reachability and uncertainty (e.g. Logistics and Rovers), but to simplify our discussion we
choose this small problem.

38

P LANNING G RAPH H EURISTICS FOR B ELIEF S PACE S EARCH

which contains a bomb, and there is also a toilet in which we can dunk packages to defuse potential
bombs. The goal is to disarm the bomb and the only allowable actions are dunking a package in
the toilet (DunkP1, DunkP2), flushing the toilet after it becomes clogged from dunking (Flush), and
using a metal-detector to sense if a package contains the bomb (DetectMetal). The fluents encoding
the problem denote that the bomb is armed (arm) or not, the bomb is in a package (inP1, inP2) or
not, and that the toilet is clogged (clog) or not. We also consider a conformant variation on BTCS,
called BTC, where there is no DetectMetal action.
The belief state representation of the BTCS initial condition, in clausal representation is:
κ(BSI ) = arm ∧¬clog ∧ (inP1 ∨ inP2) ∧ (¬inP1 ∨¬inP2),
and in constituent representation is:
ˆ
ξ(BS
I ) = (arm ∧¬ clog ∧ inP1 ∧¬inP2) ∨ (arm ∧¬ clog ∧¬inP1 ∧ inP2).
The goal of BTCS has the clausal and constituent representation:
ˆ
κ(BSG ) = ξ(BS
G ) = ¬arm.
However, the goal has the complete representation:
ξ(BSG ) = (¬arm ∧ clog ∧ inP1 ∧¬inP2) ∨ (¬arm ∧ clog ∧¬inP1 ∧ inP2) ∨
(¬arm ∧¬clog ∧ inP1 ∧¬inP2) ∨ (¬arm ∧¬clog ∧¬inP1 ∧ inP2) ∨
(¬arm ∧ clog ∧¬inP1 ∧¬inP2) ∨ (¬arm ∧ clog ∧ inP1 ∧ inP2) ∨
(¬arm ∧¬clog ∧¬inP1 ∧¬inP2) ∨ (¬arm ∧¬clog ∧ inP1 ∧ inP2).
The last four states (disjuncts) in the complete representation are unreachable, but consistent with
the goal description.
Action Representation: We represent actions as having both causative and observational effects.
All actions a are described by a tuple ρe (a), Φ(a), Θ(a) where ρe (a) is an execution precondition,
Φ(a) is a set of causative effects, and Θ(a) is a set of observations. The execution precondition,
ρe (a), is a conjunction of literals that must hold for the action to be executable. If an action is executable, we apply the set of causative effects to find successor states and then apply the observations
to partition the successor states into observational classes.
Each causative effect ϕj (a) ∈ Φ(a) is a conditional effect of the form ρj (a) =⇒ εj (a), where
the antecedent ρj (a) and consequent εj (a) are both a conjunction of literals. We handle disjunction
in ρe (a) or a ρj (a) by replicating the respective action or effect with different conditions, so with out
loss of generality we assume conjunctive preconditions. However, we cannot split disjunction in the
effects. Disjunction in an effect amounts to representing a set of non-deterministic outcomes. Hence
we do not allow disjunction in effects thereby restricting to deterministic effects. By convention
ϕ0 (a) is an unconditional effect, which is equivalent to a conditional effect where ρ0 (a) = .
The only way to obtain observations is to execute an action with observations. Each observation
formula oj (a) ∈ Θ(a) is a possible sensor reading. For example, an action a that observes the
truth values of two fluents p and q defines Θ(a) = {p ∧ q, ¬p ∧ q, p ∧ ¬q, ¬p ∧ ¬q}. This differs
slightly from the conventional description of observations in the conditional planning literature.
Some works (e.g., Rintanen, 2003b) describe an observation as a list of observable formulas, then
define possible sensor readings as all boolean combinations of the formulas. We directly define the
possible sensor readings, as illustrated by our example. We note that our convention is helpful in
problems where some boolean combinations of observable formulas will never be sensor readings.
The causative and sensory actions for the example BTCS problem are:
39

B RYCE , K AMBHAMPATI , & S MITH

DunkP1: ρe = ¬clog, Φ = {ϕ0 = clog, ϕ1 = inP1 =⇒ ¬arm}, Θ = {},
DunkP2: ρe = ¬clog, Φ = {ϕ0 = clog, ϕ1 = inP2 =⇒ ¬arm}, Θ = {},
Flush: ρe = , Φ = {ϕ0 = ¬clog}, Θ = {}, and
DetectMetal: ρe = , Φ = ∅, Θ = {o0 = inP1, o1 = ¬inP1}.
2.1 Regression
We perform regression in the CAltAlt planner to find conformant plans by starting with the goal
belief state and regressing it non-deterministically over all relevant actions. An action (without
observations) is relevant for regressing a belief state if (i) its unconditional effect is consistent with
every state in the belief state and (ii) at least one effect consequent contains a literal that is present in
a constituent of the belief state. The first part of relevance requires that every state in the successor
belief state is actually reachable from the predecessor belief state and the second ensures that the
action helps support the successor.
Following Pednault (1988), regressing a belief state BS over an action a, with conditional
effects, involves finding the execution, causation, and preservation formulas. We define regression
in terms of clausal representation, but it can be generalized for arbitrary formulas. The regression
of a belief state is a conjunction of the regression of clauses in κ(BS). Formally, the result BS  of
regressing the belief state BS over the action a is defined as:3
⎛



BS  = Regress(BS, a) = Π(a) ∧ ⎝



⎞
(Σ(a, l) ∧ IP (a, l))⎠

C∈κ(BS) l∈C

Execution formula (Π(a)) is the execution precondition ρe (a). This is what must hold in BS  for
a to have been applicable.
Causation formula (Σ(a, l)) for a literal l w.r.t all effects ϕi (a) of an action a is defined as the
weakest formula that must hold in the state before a such that l holds in BS. The intuitive meaning
is that l already held in BS  , or the antecedent ρi (a) must have held in BS  to make l hold in BS.
Formally Σ(a, l) is defined as:

ρi (a)
Σ(a, l) = l ∨
i:l∈εi (a)

Preservation formula (IP (a, l)) of a literal l w.r.t. all effects ϕi (a) of action a is defined as the
formula that must be true before a such that l is not violated by any effect εi (a). The intuitive
meaning is that the antecedent of every effect that is inconsistent with l could not have held in BS  .
Formally IP (a, l) is defined as:
IP (a, l) =



¬ρi (a)

i:¬l∈εi (a)

Regression has also been formalized in the MBP planner (Cimatti & Roveri, 2000) as a symbolic
pre-image computation of BDDs (Bryant, 1986). While our formulation is syntactically different,
both approaches compute the same result.
3. Note that BS  may not be in clausal form after regression (especially when an action has multiple conditional effects).

40

P LANNING G RAPH H EURISTICS FOR B ELIEF S PACE S EARCH

BSG
Flush

BS1
Flush

BS4
Flush

BS7

DunkP1

BS8

DunkP1

BS2
DunkP1

BS5

DunkP2

BS3
DunkP2

BS6

DunkP2

BS9

Figure 1: Illustration of the regression search path for a conformant plan in the BT C problem.
2.2 CAltAlt
The CAltAlt planner uses the regression operator to generate children in an A* search. Regression
terminates when search node expansion generates a belief state BS which is logically entailed by
the initial belief state BSI . The plan is the sequence of actions regressed from BSG to obtain the
belief state entailed by BSI .
For example, in the BTC problem, Figure 1, we have:
BS2 =Regress(BSG , DunkP1) = ¬clog ∧ (¬arm ∨ inP1).
The first clause is the execution formula and the second clause is the causation formula for the
conditional effect of DunkP1 and ¬arm.
Regressing BS2 with Flush gives:
BS4 = Regress(BS2 , Flush) = (¬arm ∨ inP1).
For BS4 , the execution precondition of Flush is , the causation formula is  ∨ ¬clog = , and
(¬arm ∨ inP1) comes by persistence of the causation formula.
Finally, regressing BS4 with DunkP2 gives:
BS9 = Regress(BS4 , DunkP2) = ¬clog ∧ (¬arm ∨ inP1 ∨ inP2).
We terminate at BS9 because BSI |= BS9 . The plan is DunkP2, Flush, DunkP1.
2.3 Progression
In progression we can handle both causative effects and observations, so in general, progressing the
action a over the belief state BS generates the set of successor belief states B. The set of belief
states B is empty when the action is not applicable to BS (BS 
|= ρe (a)).
Progression of a belief state BS over an action a is best understood as the union of the result of
applying a to each model of BS but we in fact implement it as BDD images, as in the MBP planner
41

B RYCE , K AMBHAMPATI , & S MITH

(Bertoli et al., 2001b). Since we compute progression in two steps, first finding a causative successor, and second partitioning the successor into observational classes, we explain the steps separately.
The causative successor BS  is found by progressing the belief state BS over the causative effects
of the action a. If the action is applicable, the causative successor is the disjunction of causative
progression (Progressc ) for each state in BS over a:
⎧
⎨
⊥
: BS 
|= ρe (a)



BS = Progressc (BS, a) =
⎩ S∈M(BS) Progressc (S, a) : otherwise
The progression of an action a over a state S is the conjunction of every literal that persists (no
applicable effect consequent contains the negation of the literal) and every literal that is given as an
effect (an applicable effect consequent contains the literal).


S  = Progressc (S, a) =

l:l∈S and
¬∃j S|=ρj (a) and
¬l∈εj (a)



l∧
l:∃j

S|=ρj (a)
l∈εj (a)

l
and

Applying the observations of an action results in the set of successors B. The set is found (in
Progresss ) by individually taking the conjunction of each sensor reading oj (a) with the causative
successor BS  . Applying the observations Θ(a) to a belief state BS  results in a set B of belief
states, defined as:
⎧
: BS  =⊥
⎨ ⊥


{BS }
: Θ(a) = ∅
B = Progresss (BS , a) =
⎩


j

{BS |BS = o (a) ∧ BS } : otherwise
The full progression is computed as:
B = Progress(BS, a) = Progresss (Progressc (BS, a), a).
2.4 P ON D
We use top down AO* search (Nilsson, 1980), in the P ON D planner to generate conformant and
conditional plans. In the search graph, the nodes are belief states and the hyper-edges are actions.
We need AO* because applying an action with observations to a belief state divides the belief state
into observational classes. We use hyper-edges for actions because actions with observations have
several possible successor belief states, all of which must be included in a solution.
The AO* search consists of two repeated steps: expand the current partial solution, and then
revise the current partial solution. Search ends when every leaf node of the current solution is a
belief state that satisfies the goal and no better solution exists (given our heuristic function). Expansion involves following the current solution to an unexpanded leaf node and generating its children.
Revision is a dynamic programming update at each node in the current solution that selects a best
hyper-edge (action). The update assigns the action with minimum cost to start the best solution
rooted at the given node. The cost of a node is the cost of its best action plus the average cost of its
children (the nodes connected through the best action). When expanding a leaf node, the children
of all applied actions are given a heuristic value to indicate their estimated cost.
42

P LANNING G RAPH H EURISTICS FOR B ELIEF S PACE S EARCH

The main differences between our formulation of AO* and that of Nilsson (1980) are that we
do not allow cycles in the search graph, we update the costs of nodes with an average rather than a
summation, and use a weighted estimate of future cost. The first difference is to ensure that plans
are strong (there are a finite number of steps to the goal), the second is to guide search toward plans
with lower average path cost, and the third is to bias our search to trust the heuristic function. We
define our plan quality metric (maximum plan path length) differently than the metric our search
minimizes for two reasons. First, it is easier to compare to other competing planners because they
measure the same plan quality metric. Second, search tends to be more efficient using the average
instead of the maximum cost of an action’s children. By using average instead of maximum, the
measured cost of a plan is lower – this means that we are likely to search a shallower search graph
to prove a solution is not the best solution.
Conformant planning, using actions without observations, is a special case for AO* search,
which is similar to A* search. The hyper-edges that represent actions are singletons, leading to a
single successor belief state. Consider the BTC problem (BTCS without the DetectMetal action)
with the future cost (heuristic value) set to zero for every search node. We show the search graph in
Figure 2 for this conformant example as well as a conditional example, described shortly. We can
expand the initial belief state by progressing it over all applicable actions. We get:
B1 = {BS10 } = Progress(BSI , DunkP1)
= {(inP1 ∧¬inP2 ∧ clog ∧¬arm) ∨ (¬inP1 ∧ inP2 ∧ clog ∧ arm)}
and
B3 = {BS20 } = Progress(BSI , DunkP2)
= {(inP1 ∧¬inP2 ∧ clog ∧ arm) ∨ (¬inP1 ∧ inP2 ∧ clog ∧¬arm)}.
Since ¬clog already holds in every state of the initial belief state, applying Flush to BSI leads to
BSI creating a cycle. Hence, a hyper-edge for Flush is not added to the search graph for BSI . We
assign a cost of zero to BS10 and BS20 , update the internal nodes of our best solution, and add
DunkP1 to the best solution rooted at BSI (whose cost is now one).
We expand the leaf nodes of our best solution, a single node BS10 , with all applicable actions.
The only applicable action is Flush, so we get:
B3 = {BS30 } = Progress(BS10 , Flush)
= {(inP1 ∧¬inP2 ∧¬clog ∧¬arm) ∨ (¬inP1 ∧ inP2 ∧¬clog ∧ arm)}.
We assign a cost of zero to BS30 and update our best solution. We choose Flush as the best action
for BS10 (whose cost is now one), and choose DunkP2 as the best action for BSI (whose cost is
now one). DunkP2 is chosen for BSI because its successor BS20 has a cost of zero, as opposed to
BS10 which now has a cost of one.
Expanding the leaf node BS20 with the only applicable action, Flush, we get:
B4 = {BS40 } = Progress(BS20 , Flush)
= {(¬inP1 ∧ inP2 ∧¬clog ∧arm) ∨ (inP1 ∧¬inP2 ∧¬clog ∧¬ arm)}.
We update BS40 (to have cost zero) and BS20 (to have a cost of one), and choose Flush as the best
action for BS20 . The root node BSI has two children, each with cost one, so we arbitrarily choose
DunkP1 as the best action.
We expand BS30 with the relevant actions to get BSG with the DunkP2 action. DunkP1 creates
a cycle back to BS10 so it is not added to the search graph. We now have a solution where all leaf
nodes are terminal. While it is only required that a terminal belief state contains a subset of the
43

B RYCE , K AMBHAMPATI , & S MITH

BSI
DunkP1

Detect
Metal

DunkP2

:inP1

inP1

B1

B2

BS10

B5

BS50

BS20

Flush

Flush

B3

B4

BS30

DunkP2

DunkP1
DunkP2

DunkP1

B6

BS40
DunkP2

BS51

B7

BS60

BS70

DunkP1

BSG

Figure 2: Illustration of progression search for a conformant plan (bold dashed edges) and a conditional plan (bold solid edges) in the BTCS problem.

states in BSG , in this case the terminal belief state contains exactly the states in BSG . The cost of
the solution is three because, through revision, BS30 has a cost of one, which sets BS10 to a cost
of two. However, this means now that BSI has cost of three if its best action is DunkP1. Instead,
revision sets the best action for BSI to DunkP2 because its cost is currently two.
We then expand BS40 with DunkP1 to find that its successor is BSG . DunkP2 creates a cycle
back to BS20 so it is not added to the search graph. We now have our second valid solution because
it contains no unexpanded leaf nodes. Revision sets the cost of BS40 to one, BS20 to two, and
BSI to three. Since all solutions starting at BSI have equal cost (meaning there are now cheaper
solutions), we can terminate with the plan DunkP2, Flush, DunkP1, shown in bold with dashed lines
in Figure 2.
As an example of search for a conditional plan in P ON D, consider the BTCS example whose
search graph is also shown in Figure 2. Expanding the initial belief state, we get:
B1 = {BS10 } = Progress(BSI , DunkP1),
B2 = {BS20 } = Progress(BSI , DunkP2),
and
B5 = {BS50 , BS51 } = Progress(BSI ,DetectMetal)
= {inP1 ∧¬inP2 ∧¬clog ∧ arm, ¬inP1 ∧ inP2 ∧¬clog ∧ arm}.
Each of the leaf nodes is assigned a cost of zero, and DunkP1 is chosen arbitrarily for the best
solution rooted at BSI because the cost of each solution is identical. The cost of including each
hyper-edge is the average cost of its children plus its cost, so the cost of using DetectMetal is (0+0)/2
+ 1 = 1. Thus, our root BSI has a cost of one.
44

P LANNING G RAPH H EURISTICS FOR B ELIEF S PACE S EARCH

As in the conformant problem we expand BS10 , giving its child a cost of zero and BS10 a cost
of one. This changes our best solution at BSI to use DunkP2, and we expand BS20 , giving its child
a cost of zero and it a cost of one. Then we choose DetectMetal to start the best solution at BSI
because it gives BSI a cost of one, where using either Dunk action would give BSI a cost of two.
We expand the first child of DetectMetal, BS50 , with DunkP1 to get:
{inP1 ∧¬inP2 ∧ clog ∧¬arm},
which is a goal state, and DunkP2 to get:
B6 = {BS60 } = Progress(BS50 ,DunkP2) = {inP1 ∧¬inP2 ∧clog ∧ arm}.
We then expand the second child, BS51 , with DunkP2 to get:
{¬inP1 ∧ inP2 ∧ clog ∧¬arm},
which is also a goal state and DunkP1 to get:
B7 = {BS70 } = Progress(BS51 ,DunkP1) = {¬inP1 ∧ inP2 ∧clog ∧ arm}.
While none of these new belief states are not equivalent to BSG , two of them entail BSG , so we
can treat them as terminal by connecting the hyper-edges for these actions to BSG . We choose
DunkP1 and DunkP2 as best actions for BS50 and BS51 respectively and set the cost of each node
to one. This in turn sets the cost of using DetectMetal for BSI to (1+1)/2 + 1 = 2. We terminate
here because this plan has cost equal to the other possible plans starting at BSI and all leaf nodes
satisfy the goal. The plan is shown in bold with solid lines in Figure 2.

3. Belief State Distance
In both the CAltAlt and P ON D planners we need to guide search node expansion with heuristics
that estimate the plan distance dist(BS, BS  ) between two belief states BS and BS  . By convention, we assume BS precedes BS  (i.e., in progression BS is a search node and BS  is the goal
belief state, or in regression BS is the initial belief state and BS  is a search node). For simplicity,
we limit our discussion to progression planning. Since a strong plan (executed in BS) ensures that
every state S ∈ M(BS) will transition to some state S  ∈ M(BS  ), we define the plan distance
between BS and BS  as the number of actions needed to transition every state S ∈ M(BS) to a
state S  ∈ M(BS  ). Naturally, in a strong plan, the actions used to transition a state S1 ∈ M(BS)
may affect how we transition another state S2 ∈ M(BS). There is usually some degree of positive
or negative interaction between S1 and S2 that can be ignored or captured in estimating plan distance.4 In the following we explore how to perform such estimates by using several intuitions from
classical planning state distance heuristics.
We start with an example search scenario in Figure 3. There are three belief states BS1 (containing states S11 and S12 ), BS2 (containing state S21 ), and BS3 (containing states S31 and S32 ).
The goal belief state is BS3 , and the two progression search nodes are BS1 and BS2 . We want to
expand the search node with the smallest distance to BS3 by estimating dist(BS1 , BS3 ) – denoted
by the bold, dashed line – and dist(BS2 , BS3 ) – denoted by the bold, solid line. We will assume for
now that we have estimates of state distance measures dist(S, S  ) – denoted by the light dashed and
solid lines with numbers. The state distances can be represented as numbers or action sequences. In
our example, we will use the following action sequences for illustration:
4. Interaction between states captures the notion that actions performed to transition one state to the goal may interfere
(negatively interact) or aid with (positively interact) transitioning other states to goals states.

45

B RYCE , K AMBHAMPATI , & S MITH

BS1
S11

BS3

14
5

S12

S31

3
7

BS2

S32

8

S21

10

Figure 3: Conformant Plan Distance Estimation in Belief Space
dist(S11 , S32 ) : ({a1 , a2 }, {a5 }, {a6 , a7 }),
dist(S12 , S31 ) : ({a1 , a7 }, {a3 }),
dist(S21 , S31 ) : ({a3 , a6 }, {a9 , a2 , a1 }, {a0 , a8 }, {a5 }).
In each sequence there may be several actions in each step. For instance, dist(S21 , S31 ) has a3 and
a6 in its first step, and there are a total of eight actions in the sequence – meaning the distance is
eight. Notice that our example includes several state distance estimates, which can be found with
classical planning techniques. There are many ways that we can use similar ideas to estimate belief
state distance once we have addressed the issue of belief states containing several states.
Selecting States for Distance Estimation: There exists a considerable body of literature on estimating the plan distance between states in classical planning (Bonet & Geffner, 1999; Nguyen,
Kambhampati, & Nigenda, 2002; Hoffmann & Nebel, 2001), and we would like to apply it to estimate the plan distance between two belief states, say BS1 and BS3 . We identify four possible
options for using state distance estimates to compute the distance between belief states BS1 and
BS3 :
• Sample a State Pair: We can sample a single state from BS1 and a single state from BS3 ,
whose plan distance is used for the belief state distance. For example, we might sample S12
from BS1 and S31 from BS3 , then define dist(BS1 , BS3 ) = dist(S12 , S31 ).
• Aggregate States: We can form aggregate states for BS1 and BS3 and measure their plan
distance. An aggregate state is the union of the literals needed to express a belief state formula,
46

P LANNING G RAPH H EURISTICS FOR B ELIEF S PACE S EARCH

which we define as:
S̃(BS) =



l

l:l∈Ŝ,Ŝ∈ξ̂(BS)

Since it is possible to express a belief state formula with every literal (e.g., using (q ∨ ¬q) ∧ p
to express the belief state where p is true), we assume a reasonably succinct representation,
such as a ROBDD (Bryant, 1986). It is quite possible the aggregate states are inconsistent, but many classical planning techniques (such as planning graphs) do not require consistent states. For example, with aggregate states we would compute the belief state distance
dist(BS1 , BS3 ) = dist(S̃(BS1 ), S̃(BS3 )).
• Choose a Subset of States: We can choose a set of states (e.g., by random sampling) from
BS1 and a set of states from BS3 , and then compute state distances for all pairs of states
from the sets. Upon computing all state distances, we can aggregate the state distances (as we
will describe shortly). For example, we might sample both S11 and S12 from BS1 and S31
from BS3 , compute dist(S11 , S31 ) and dist(S12 , S31 ), and then aggregate the state distances
to define dist(BS1 , BS3 ).
• Use All States: We can use all states in BS1 and BS3 , and, similar to sampling a subset of
states (above), we can compute all distances for state pairs and aggregate the distances.
The former two options for computing belief state distance are reasonably straightforward, given
the existing work in classical planning. In the latter two options we compute multiple state distances.
With multiple state distances there are two details which require consideration in order to obtain a
belief state distance measure. In the following we treat belief states as if they contain all states
because they can be appropriately replaced with the subset of chosen states.
The first issue is that some of the state distances may not be needed. Since each state in BS1
needs to reach a state in BS3 , we should consider the distance for each state in BS1 to “a” state in
BS3 . However, we don’t necessarily need the distance for every state in BS1 to “every” state in
BS3 . We will explore assumptions about which state distances need to be computed in Section 3.1.
The second issue, which arises after computing the state distances, is that we need to aggregate
the state distances into a belief state distance. We notice that the popular state distance estimates
used in classical planning typically measure aggregate costs of state features (literals). Since we
are planning in belief space, we wish to estimate belief state distance with the aggregate cost of
belief state features (states). In Section 3.2, we will examine several choices for aggregating state
distances and discuss how each captures different types of state interaction. In Section 3.3, we
conclude with a summary of the choices we make in order to compute belief state distances.
3.1 State Distance Assumptions
When we choose to compute multiple state distances between two belief states BS and BS  ,
whether by considering all states or sampling subsets, not all of the state distances are important.
For a given state in BS we do not need to know the distance to every state in BS  because each
state in BS need only transition to one state in BS  . There are two assumptions that we can make
about the states reached in BS  which help us define two different belief state distance measures in
terms of aggregate state distances:
47

B RYCE , K AMBHAMPATI , & S MITH

• We can optimistically assume that each of the earlier states S ∈ M(BS) can reach the closest
of the later states S  ∈ M(BS  ). With this assumption we compute distance as:
dist(BS, BS  ) = S∈M(BS)

min

S  ∈M(BS  )

dist(S, S  ).

• We can assume that all of the earlier states S ∈ M(BS) reach the same later state S  ∈
M(BS  ), where the aggregate distance is minimum. With this assumption we compute distance as:
dist(BS, BS  ) =

min

S  ∈M(BS  )

S∈M(BS) dist(S, S  ),

where  represents an aggregation technique (several of which we will discuss shortly).
Throughout the rest of the paper we use the first definition for belief state distance because it is
relatively robust and easy to compute. Its only drawback is that it treats the earlier states in a more
independent fashion, but is flexible in allowing earlier states to transition to different later states.
The second definition measures more dependencies of the earlier states, but restricts them to reach
the same later state. While the second may sometimes be more accurate, it is misinformed in cases
where all earlier states cannot reach the same later state (i.e., the measure would be infinite). We do
not pursue the second method because it may return distance measures that are infinite when they
are in fact finite.
As we will see in Section 4, when we discuss computing these measures with planning graphs,
we can implicitly find for each state in BS the closest state in BS  , so that we do not enumerate the
states S  in the minimization term of the first belief state distance (above). Part of the reason we can
 ) rather than actual states.
ˆ
do this is that we compute distance in terms of constituents Ŝ  ∈ ξ(BS
Also, because we only consider constituents of BS  , when we discuss sampling belief states to include in distance computation we only sample from BS. We can also avoid the explicit aggregation
 by using the LU G, but describe several choices for  to understand implicit assumptions made
by the heuristics computed on the LU G.
3.2 State Distance Aggregation
The aggregation function  plays an important role in how we measure the distance between belief
states. When we compute more than one state distance measure, either exhaustively or by sampling
a subset (as previously mentioned), we must combine the measures by some means, denoted .
There is a range of options for taking the state distances and aggregating them into a belief state
distance. We discuss several assumptions associated with potential measures:
• Positive Interaction of States: Positive interaction assumes that the most difficult state in BS
requires actions that will help transition all other states in BS to some state in BS  . In our
example, this means that we assume the actions used to transition S11 to S32 will help us
transition S12 to S31 (assuming each state in BS1 transitions to the closest state in BS3 ).
Inspecting the action sequences, we see they positively interact because both need actions a1
and a7 . We do not need to know the action sequences to assume positive interaction because
we define the aggregation  as a maximization of numerical state distances:
dist(BS, BS  ) =

max

min

S∈M(BS) S  ∈M(BS  )

dist(S, S  ).
48

P LANNING G RAPH H EURISTICS FOR B ELIEF S PACE S EARCH

The belief state distances are dist(BS1 , BS3 ) = max(min(14, 5), min(3, 7)) = 5 and
dist(BS2 , BS3 ) = max(min(8, 10)) = 8. In this case we prefer BS1 to BS2 . If each
state distance is admissible and we do not sample from belief states, then assuming positive
interaction is also admissible.
• Independence of States: Independence assumes that each state in BS requires actions that are
different from all other states in BS in order to reach a state in BS  . Previously, we found
there was positive interaction in the action sequences to transition S11 to S32 and S12 to S31
because they shared actions a1 and a7 . There is also some independence in these sequences
because the first contains a2 , a5 , and a6 , where the second contains a3 . Again, we do not need
to know the action sequences to assume independence because we define the aggregation 
as a summation of numerical state distances:

min dist(S, S  ).
dist(BS, BS  ) =


S∈M(BS) S ∈M(BS )

In our example, dist(BS1 , BS3 ) = min(14, 5) + min(3, 7) = 8, and dist(BS2 , BS3 ) =
min(8, 10) = 8. In this case we have no preference over BS1 and BS2 .
We notice that using the cardinality of a belief state |M(BS)| to measure dist(BS, BS  ) is
a special case of assuming state independence, where ∀S, S  dist(S, S  ) = 1. If we use cardinality to measure distance in our example, then we have dist(BS1 , BS3 ) = |M(BS1 )| = 2,
and dist(BS2 , BS3 ) = |M(BS2 )| = 1. With cardinality we prefer BS2 over BS1 because
we have better knowledge in BS2 .
• Overlap of States: Overlap assumes that there is both positive interaction and independence
between the actions used by states in BS to reach a state in BS  . The intuition is that some
actions can often be used for multiple states in BS simultaneously and we should count these
actions only once. For example, when we computed dist(BS1 , BS3 ) by assuming positive
interaction, we noticed that the action sequences for dist(S11 , S32 ) and dist(S12 , S31 ) both
used a1 and a7 . When we aggregate these sequences we would like to count a1 and a7 each
only once because they potentially overlap. However, truly combining the action sequences
for maximal overlap is a plan merging problem (Kambhampati, Ihrig, & Srivastava, 1996),
which can be as difficult as planning. Since our ultimate intent is to compute heuristics,
we take a very simple approach to merging action sequences. We introduce a plan merging
operator  for  that picks a step at which we align the sequences and then unions the aligned
steps. We use the size of the resulting action sequence to measure belief state distance:
dist(BS, BS  ) = S∈M(BS)

min

S  ∈M(BS  )

dist(S, S  ).

Depending on the type of search, we define  differently. We assume that sequences used in
progression search start at the same time and those used in regression end at the same time.
Thus, in progression all sequences are aligned at the first step before we union steps, and in
regression all sequences are aligned at the last step before the union.
For example, in progression dist(S11 , S32 )  dist(S12 , S31 ) = ({a1 , a2 }, {a5 }, {a6 , a7 }) 
({a1 , a7 }, {a3 }) = ({a1 , a2 , a7 }, {a5 , a3 }, {a6 , a7 }) because we align the sequences at their
first steps, then union each step. Notice that this resulting sequence has seven actions, giving
49

B RYCE , K AMBHAMPATI , & S MITH

dist(BS1 , BS3 ) = 7, whereas defining  as maximum gave a distance of five and as summation gave a distance of eight. Compared with overlap, positive interaction tends to under
estimate distance, and independence tends to over estimate distance. As we will see during our empirical evaluation (in Section 6.5), accounting for overlap provides more accurate
distance measures for many conformant planning domains.
• Negative Interaction of States: Negative interaction between states can appear in our example
if transitioning state S11 to state S32 makes it more difficult (or even impossible) to transition
state S12 to state S31 . This could happen if performing action a5 for S11 conflicts with action
a3 for S12 . We can say that BS1 cannot reach BS3 if all possible action sequences that start
in S11 and S12 , respectively, and end in any S ∈ M(BS3 ) negatively interact.
There are two ways negative interactions play a role in belief state distances. Negative interactions can allow us to prove it is impossible for a belief state BS to reach a belief state
BS  , meaning dist(BS, BS  ) = ∞, or they can potentially increase the distance by a finite
amount. We use only the first, more extreme, notion of negative interaction by computing
“cross-world” mutexes (Smith & Weld, 1998) to prune belief states from the search. If we
cannot prune a belief state, then we use one of the aforementioned techniques to aggregate
state distances. As such, we do not provide a concrete definition for  to measure negative
interaction.
While we do not explore ways to adjust the distance measure for negative interactions, we
mention some possibilities. Like work in classical planning (Nguyen et al., 2002), we can
penalize the distance measure dist(BS1 , BS3 ) to reflect additional cost associated with serializing conflicting actions. Additionally in conditional planning, conflicting actions can be
conditioned on observations so that they do not execute in the same plan branch. A distance
measure that uses observations would reflect the added cost of obtaining observations, as
well as the change in cost associated with introducing plan branches (e.g., measuring average
branch cost).
The above techniques for belief state distance estimation in terms of state distances provide the
basis for our use of multiple planning graphs. We will show in the empirical evaluation that these
measures affect planner performance very differently across standard conformant and conditional
planning domains. While it can be quite costly to compute several state distance measures, understanding how to aggregate state distances sets the foundation for techniques we develop in the
LU G. As we have already mentioned, the LU G conveniently allows us to implicitly aggregate state
distances to directly measure belief state distance.
3.3 Summary of Methods for Distance Estimation
Since we explore several methods for computing belief state distances on planning graphs, we provide a summary of the choices we must consider, listed in Table 1. Each column is headed with a
choice, containing possible options below. The order of the columns reflects the order in which we
consider the options.
In this section we have covered the first two columns which relate to selecting states from belief
states for distance computation, as well as aggregating multiple state distances into a belief state
distance. We test options for both of these choices in the empirical evaluation.
50

P LANNING G RAPH H EURISTICS FOR B ELIEF S PACE S EARCH

State
Selection
Single
Aggregate
Subset
All

State Distance
Aggregation
+ Interaction
Independence
Overlap
- Interaction

Planning
Graph
SG
MG
LU G

Mutex
Type
None
Static
Dynamic
Induced

Mutex
Worlds
Same
Intersect
Cross

Heuristic
Max
Sum
Level
Relaxed Plan

Table 1: Features for a belief state distance estimation.
In the next section we will also expand upon how to aggregate distance measures as well as
discuss the remaining columns of Table 1. We will present each type of planning graph: the single
planning graph (SG), multiple planning graphs (M G), and the labelled uncertainty graph (LU G).
Within each planning graph we will describe several types of mutex, including static, dynamic,
and induced mutexes. Additionally, each type of mutex can be computed with respect to different
possible worlds – which means the mutex involves planning graph elements (e.g., actions) when
they exist in the same world (i.e., mutexes are only computed within the planning graph for a single
state), or across worlds (i.e., mutexes are computed between planning graphs for different states)
by two methods (denoted Intersect and Cross). Finally, we can compute many different heuristics
on the planning graphs to measure state distances – max, sum, level, and relaxed plan. We focus
our discussion on the planning graphs, same-world mutexes, and relaxed plan heuristics in the next
section. Cross-world mutexes and the other heuristics are described in appendices.

4. Heuristics
This section discusses how we can use planning graph heuristics to measure belief state distances.
We cover several types of planning graphs and the extent to which they can be used to compute
various heuristics. We begin with a brief background on planning graphs.
Planning Graphs: Planning graphs serve as the basis for our belief state distance estimation. Planning graphs were initially introduced in GraphPlan (Blum & Furst, 1995) for representing an optimistic, compressed version of the state space progression tree. The compression lies in unioning
the literals from every state at subsequent steps from the initial state. The optimism relates to underestimating the number of steps it takes to support sets of literals (by tracking only a subset of the
infeasible tuples of literals). GraphPlan searches the compressed progression (or planning graph)
once it achieves the goal literals in a level with no two goal literals marked infeasible. The search
tries to find actions to support the top level goal literals, then find actions to support the chosen
actions and so on until reaching the first graph level. The basic idea behind using planning graphs
for search heuristics is that we can find the first level of a planning graph where a literal in a state
appears; the index of this level is a lower bound on the number of actions that are needed to achieve
a state with the literal. There are also techniques for estimating the number of actions required to
achieve sets of literals. The planning graphs serve as a way to estimate the reachability of state literals and discriminate between the “goodness” of different search states. This work generalizes such
literal estimations to belief space search by considering both GraphPlan and CGP style planning
graphs plus a new generalization of planning graphs, called the LU G.
Planners such as CGP (Smith & Weld, 1998) and SGP (Weld et al., 1998) adapt the GraphPlan
idea of compressing the search space with a planning graph by using multiple planning graphs, one
51

B RYCE , K AMBHAMPATI , & S MITH

Overlap

n-distances

hMG
RPU

hLUG
RP

State Distance Aggregation

CFF

Independence

Positive
Interaction

None

h card
MBP
KACMBP
YKA

hMG
s-RP

GPT

hMG
m-RP

h0
NG

1

hSG
RP
U
hSG
RP
SG

MG

LUG

Planning Graph Type

Figure 4: Taxonomy of heuristics with respect to planning graph type and state distance aggregation. Blank entries indicate that the combination is meaningless or not possible.

for each possible world in the initial belief state. CGP and SGP search on these planning graphs,
similar to GraphPlan, to find conformant and conditional plans. The work in this paper seeks to
apply the idea of extracting search heuristics from planning graphs, previously used in state space
search (Nguyen et al., 2002; Hoffmann & Nebel, 2001; Bonet & Geffner, 1999) to belief space
search.
Planning Graphs for Belief Space: This section proceeds by describing four classes of heuristics
to estimate belief state distance N G, SG, M G, and LU G. N G heuristics are techniques existing in
the literature that are not based on planning graphs, SG heuristics are techniques based on a single
classical planning graph, M G heuristics are techniques based on multiple planning graphs (similar
to those used in CGP) and LU G heuristics use a new labelled planning graph. The LU G combines
the advantages of SG and M G to reduce the representation size and maintain informedness. Note
that we do not include observations in any of the planning graph structures as SGP (Weld et al.,
1998) would, however we do include this feature for future work. The conditional planning formulation directly uses the planning graph heuristics by ignoring observations, and our results show that
this still gives good performance.
In Figure 4 we present a taxonomy of distance measures for belief space. The taxonomy also
includes related planners, whose distance measures will be characterized in this section. All of the
related planners are listed in the N G group, despite the fact that some actually use planning graphs,
because they do not clearly fall into one of our planning graph categories. The figure shows how
52

P LANNING G RAPH H EURISTICS FOR B ELIEF S PACE S EARCH

different substrates (horizontal axis) can be used to compute belief state distance by aggregating
state to state distances under various assumptions (vertical axis). Some of the combinations are
not considered because they do not make sense or are impossible. The reasons for these omissions
will be discussed in subsequent sections. While there are a wealth of different heuristics one can
compute using planning graphs, we concentrate on relaxed plans because they have proven to be the
most effective in classical planning and in our previous studies (Bryce & Kambhampati, 2004). We
provide additional descriptions of other heuristics like max, sum, and level in Appendix A.
Example: To illustrate the computation of each heuristic, we use an example derived from BTC
called Courteous BTC (CBTC) where a courteous package dunker has to disarm the bomb and
leave the toilet unclogged, but some discourteous person has left the toilet clogged. The initial
belief state of CBTC in clausal representation is:
κ(BSI ) = arm ∧ clog ∧ (inP1 ∨ inP2) ∧ (¬inP1 ∨¬inP2),
and the goal is:
κ(BSG ) = ¬clog ∧¬arm.
The optimal action sequences to reach BSG from BSI are:
Flush, DunkP1, Flush, DunkP2, Flush,
and
Flush, DunkP2, Flush, DunkP1, Flush.
Thus the optimal heuristic estimate for the distance between BSI and BSG , in regression, is
h∗ (BSG ) = 5 because in either plan there are five actions.
We use planning graphs for both progression and regression search. In regression search the
heuristic estimates the cost of the current belief state w.r.t. the initial belief state and in progression
search the heuristic estimates the cost of the goal belief state w.r.t. the current belief state. Thus,
in regression search the planning graph(s) are built (projected) once from the possible worlds of
the initial belief state, but in progression search they need to be built at each search node. We
introduce a notation BSi to denote the belief state for which we find a heuristic measure, and BSP
to denote the belief state that is used to construct the initial layer of the planning graph(s). In the
following subsections we describe computing heuristics for regression, but they are generalized for
progression by changing BSi and BSP appropriately.
In the previous section we discussed two important issues involved in heuristic computation:
sampling states to include in the computation and using mutexes to capture negative interactions in
the heuristics. We will not directly address these issues in this section, deferring them to discussion
in the respective empirical evaluation sections, 6.4 and 6.2. The heuristics below are computed
once we have decided on a set of states to use, whether by sampling or not. Also, as previously
mentioned, we only consider sampling states from the belief state BSP because we can implicitly
find closest states from BSi without sampling. We only explore computing mutexes on the planning
graphs in regression search. We use mutexes to determine the first level of the planning graph where
the goal belief state is reachable (via the level heuristic described in Appendix A) and then extract a
relaxed plan starting at that level. If the level heuristic is ∞ because there is no level where a belief
state is reachable, then we can prune the regressed belief state.
We proceed by describing the various substrates used for computing belief space distance estimates. Within each we describe the prospects for various types of world aggregation. In addition to
our heuristics, we mention related work in the relevant areas.
53

B RYCE , K AMBHAMPATI , & S MITH

4.1 Non Planning Graph-based Heuristics (N G)
We group many heuristics and planners into the N G group because they are not using SG, M G,
or LU G planning graphs. Just because we mention them in this group does not mean they are not
using planning graphs in some other form.
No Aggregation: Breadth first search uses a simple heuristic, h0 where the heuristic value is set
to zero. We mention this heuristic so that we can gauge the effectiveness of our search substrates
relative to improvements gained through using heuristics.
Positive Interaction Aggregation: The GPT planner (Bonet & Geffner, 2000) measures belief
state distance as the maximum of the minimum state to state distance of states in the source and
destination belief states, assuming optimistic reachability as mentioned in Section 3. GPT measures
state distances exactly, in terms of the minimum number of transitions in the state space. Taking
the maximum state to state distance is akin to assuming positive interaction of states in the current
belief state.
Independence Aggregation: The MBP planner (Bertoli et al., 2001b), KACMBP planner (Bertoli
& Cimatti, 2002), YKA planner (Rintanen, 2003b), and our comparable hcard heuristic measure
belief state distance by assuming every state to state distance is one, and taking the summation of
the state distances (i.e. counting the number of states in a belief state). This measure can be useful
in regression because goal belief states are partially specified and contain many states consistent
with a goal formula and many of the states consistent with the goal formula are not reachable from
the initial belief state. Throughout regression, many of the unreachable states are removed from
predecessor belief states because they are inconsistent with the preconditions of a regressed action.
Thus, belief states can reduce in size during regression and their cardinality may indicate they are
closer to the initial belief state. Cardinality is also useful in progression because as belief states
become smaller, the agent has more knowledge and it can be easier to reach a goal state.
In CBTC, hcard (BSG ) = 4 because BSG has four states consistent with its complete representation:
ξ(BSG ) = (¬inP1 ∧¬inP2∧¬clog ∧¬arm) ∨ (¬inP1 ∧ inP2 ∧¬clog ∧¬arm) ∨
(inP1 ∧¬inP2 ∧¬clog ∧¬arm) ∨ (inP1 ∧ inP2 ∧¬clog ∧¬arm).
Notice, this may be uninformed for BSG because two of the states in ξ(BSG ) are not reachable,
like: (inP1 ∧ inP2 ∧¬clog ∧¬arm). If there are n packages, then there would be 2n−1 unreachable
states represented by ξ(BSG ). Counting unreachable states may overestimate the distance estimate
because we do not need to plan for them. In general, in addition to the problem of counting unreachable states, cardinality does not accurately reflect distance measures. For instance, MBP reverts to
breadth first search in classical planning problems because state distance may be large or small but
it still assigns a value of one.
Overlap Aggregation: Rintanen (2004) describes n-Distances which generalize the belief state
distance measure in GPT to consider the maximum n-tuple state distance. The measure involves,
for each n-sized tuple of states in a belief state, finding the length of the actual plan to transition the
n-tuple to the destination belief state. Then the maximum n-tuple distance is taken as the distance
measure.
For example, consider a belief state with four states. With an n equal to two, we would define
six belief states, one for each size two subset of the four states. For each of these belief states we
find a real plan, then take the maximum cost over these plans to measure the distance for the original
54

P LANNING G RAPH H EURISTICS FOR B ELIEF S PACE S EARCH

L0

A0

E0

L1

A1

E1

L2

inP1

inP1

inP1

¬inP1

¬inP1

¬inP1

inP2

inP2

inP2

¬inP2

¬inP2

¬inP2
DunkP1

ϕ1(DunkP1)
ϕ0(DunkP1)

¬arm
DunkP2
arm

arm

ϕ1(DunkP2)
ϕ0(DunkP2)

clog

clog

clog
Flush

ϕ0(Flush)

¬clog

arm

Flush

ϕ0(Flush)

¬clog

Figure 5: Single planning graph for CBTC, with relaxed plan components in bold. Mutexes omitted.

four state belief state. When n is one, we are computing the same measure as GPT, and when n is
equal to the size of the belief state we are directly solving the planning problem. While it is costly
to compute this measure for large values of n, it is very informed as it accounts for overlap and
negative interactions.
The CFF planner (Hoffmann & Brafman, 2004) uses a version of a relaxed planning graph to
extract relaxed plans. The relaxed plans measure the cost of supporting a set of goal literals from all
states in a belief state. In addition to the traditional notion of a relaxed planning graph that ignores
mutexes, CFF also ignores all but one antecedent literal in conditional effects to keep their relaxed
plan reasoning tractable. The CFF relaxed plan does capture overlap but ignores some subgoals and
all mutexes. The way CFF ensures the goal is supported in the relaxed problem is to encode the
relaxed planning graph as a satisfiability problem. If the encoding is satisfiable, the chosen number
of action assignments is the distance measure.
4.2 Single Graph Heuristics (SG)
The simplest approach for using planning graphs for belief space planning heuristics is to use a
“classical” planning graph. To form the initial literal layer from the projected belief state, we could
either sample a single state (denoted SG1 ) or use an aggregate state (denoted SGU ). For example,
in CBTC (see Figure 5) assuming regression search with BSP = BSI , the initial level L0 of the
planning graph for SG1 might be:
55

B RYCE , K AMBHAMPATI , & S MITH

L0 = {arm, clog, inP1, ¬inP2}
and for SGU it is defined by the aggregate state S̃(BSP ):
L0 = {arm, clog, inP1, inP2, ¬inP1, ¬inP2}.
Since these two versions of the single planning graph have identical semantics, aside from the initial
literal layer, we proceed by describing the SGU graph and point out differences with SG1 where
they arise.
Graph construction is identical to classical planning graphs (including mutex propagation) and
stops when two subsequent literal layers are identical (level off). We use the planning graph formalism used in IPP (Koehler, Nebel, Hoffmann, & Dimopoulos, 1997) to allow for explicit representation of conditional effects, meaning there is a literal layer Lk , an action layer Ak , and an effect
layer Ek in each level k. Persistence for a literal l, denoted by lp , is represented as an action where
ρe (lp ) = ε0 (lp ) = l. A literal is in Lk if an effect from the previous effect layer Ek−1 contains the
literal in its consequent. An action is in the action layer Ak if every one of its execution precondition
literals is in Lk . An effect is in the effect layer Ek if its associated action is in the action layer Ak and
every one of its antecedent literals is in Lk . Using conditional effects in the planning graph avoids
factoring an action with conditional effects into a possibly exponential number of non-conditional
actions, but adds an extra planning graph layer per level. Once our graph is built, we can extract
heuristics.
No Aggregation: Relaxed plans within a single planning graph are able to measure, under the
most optimistic assumptions, the distance between two belief states. The relaxed plan represents a
distance between a subset of the initial layer literals and the literals in a constituent of our belief
state. In the SGU , the literals from the initial layer that are used for support may not hold in a
single state of the projected belief state, unlike the SG1 . The classical relaxed plan heuristic hSG
RP
finds a set of (possibly interfering) actions to support the goal constituent. The relaxed plan RP is a
RP
RP
RP
RP
RP
subgraph of the planning graph, of the form {ARP
0 , E0 , L1 , ..., Ab−1 , Eb−1 , Lb }. Each of the
layers contains a subset of the vertices in the corresponding layer of the planning graph.
ˆ
More formally, we find the relaxed plan to support the constituent Ŝ ∈ ξ(BS
i ) that is reached
SG
earliest in the graph (as found by the hlevel (BSi ) heuristic in Appendix A). Briefly, hSG
level (BSi )
returns the first level b where a constituent of BSi has all its literals in Lb and none are marked
pair-wise mutex. Notice that this is how we incorporate negative interactions into our heuristics.
We start extraction at the level b, by defining LRP
as the literals in the constituent used in the level
b
RP
heuristic. For each literal l ∈ Lb , we select a supporting effect (ignoring mutexes) from Eb−1
RP . We prefer persistence of literals to effects in supporting literals. Once a
to form the subset Eb−1
RP
supporting set of effects is found, we create ARP
b−1 as all actions with an effect in Eb−1 . Then the
RP
RP are added
needed preconditions for the actions and antecedents for chosen effects in Ab−1 and Eb−1
to the list of literals to support from LRP
b−2 . The algorithm repeats until we find the needed actions
from A0 . A relaxed plan’s value is the summation of the number of actions in each action layer. A
literal persistence, denoted by a subscript “p”, is treated as an action in the planning graph, but in a
|. The single graph relaxed plan
relaxed plan we do not include it in the final computation of | ARP
j
heuristic is computed as
hSG
RP (BSi )

=

b−1

j=0

56

| ARP
|
j

P LANNING G RAPH H EURISTICS FOR B ELIEF S PACE S EARCH

For the CBTC problem we find a relaxed plan from the SGU , as shown in Figure 5 as the bold
edges and nodes. Since ¬arm and ¬clog are non mutex at level two, we can use persistence to
RP we can use persistence for inP1, and
support ¬clog and DunkP1 to support ¬arm in LRP
2 . In L1
SG
Flush for ¬clog. Thus, hRP (BSG ) = 2 because the relaxed plan is:
= {inP1p , Flush},
ARP
0
E0RP = {ϕ0 (inP1p ), ϕ0 (Flush)},

= {inP1, ¬clog},
LRP
1
= {¬clogp , DunkP1},
ARP
1

E1RP = {ϕ0 (¬clogp ), ϕ1 (DunkP1)},
= {¬arm, ¬clog}.
LRP
2

The relaxed plan does not use both DunkP2 and DunkP1 to support ¬arm. As a result ¬arm is
not supported in all worlds (i.e. it is not supported when the state where inP2 holds is our initial
state). Our initial literal layer threw away knowledge of inP1 and inP2 holding in different worlds,
and the relaxed plan extraction ignored the fact that ¬arm needs to be supported in all worlds. Even
with an SG1 graph, we see similar behavior because we are reasoning with only a single world. A
single, unmodified classical planning graph cannot capture support from all possible worlds – hence
there is no explicit aggregation over distance measures for states. As a result, we do not mention
aggregating states to measure positive interaction, independence, or overlap.
4.3 Multiple Graph Heuristics (M G)
Single graph heuristics are usually uninformed because the projected belief state BSP often corresponds to multiple possible states. The lack of accuracy is because single graphs are not able to
capture propagation of multiple world support information. Consider the CBTC problem where the
projected belief state is BSI and we are using a single graph SGU . If DunkP1 were the only action
we would say that ¬arm and ¬clog can be reached at a cost of two, but in fact the cost is infinite
(since there is no DunkP2 to support ¬arm from all possible worlds), and there is no strong plan.
To account for lack of support in all possible worlds and sharpen the heuristic estimate, a set of
multiple planning graphs Γ is considered. Each γ ∈ Γ is a single graph, as previously discussed.
These multiple graphs are similar to the graphs used by CGP (Smith & Weld, 1998), but lack the
more general cross-world mutexes. Mutexes are only computed within each graph, i.e. only sameworld mutexes are computed. We construct the initial layer Lγ0 of each graph γ with a different state
S ∈ M(BSP ). With multiple graphs, the heuristic value of a belief state is computed in terms of
all the graphs. Unlike single graphs, we can compute different world aggregation measures with the
multiple planning graphs.
While we get a more informed heuristic by considering more of the states in M(BSP ), in
certain cases it can be costly to compute the full set of planning graphs and extract relaxed plans.
We will describe computing the full set of planning graphs, but will later evaluate (in Section 6.4)
the effect of computing a smaller proportion of these. The single graph SG1 is the extreme case of
computing fewer graphs.
To illustrate the use of multiple planning graphs, consider our example CBTC. We build two
graphs (Figure 6) for the projected BSP . They have the respective initial literal layers:
L10 = {arm, clog, inP1, ¬inP2} and
L20 = {arm, clog, ¬inP2, inP2}.

57

B RYCE , K AMBHAMPATI , & S MITH

L0

inP1

A0

E0

¬inP2

A1

L1

inP1

E1

¬inP2

¬inP2
DunkP1

1

ϕ1(DunkP1)
ϕ0(DunkP1)

arm
clog

ϕ1(DunkP2)

arm
Flush

ϕ0(Flush)

DunkP2

clog

Flush

¬ clog
¬inP1

¬inP1

inP2

inP2

L2

inP1

¬arm
arm

ϕ0(DunkP2)
ϕ0(Flush)

clog
¬ clog
¬inP1

DunkP1

ϕ1(DunkP1)
ϕ0(DunkP1)

2

inP2

¬arm
arm
clog

ϕ1(DunkP2)

arm
Flush

ϕ0(Flush)

DunkP2

clog

Flush

¬clog

ϕ0(DunkP2)
ϕ0(Flush)

arm
clog
¬clog

Figure 6: Multiple planning graphs for CBTC, with relaxed plan components bolded. Mutexes
omitted.

In the graph for the first possible world, ¬arm comes in only through DunkP1 at level 2. In the
graph for the second world, ¬arm comes in only through DunkP2 at level 2. Thus, the multiple
graphs show which actions in the different worlds contribute to support the same literal.
A single planning graph is sufficient if we do not aggregate state measures, so in the following we consider how to compute the achievement cost of a belief state with multiple graphs by
aggregating state distances.
Positive Interaction Aggregation: Similar to GPT (Bonet & Geffner, 2000), we can use the worstG
case world to represent the cost of the belief state BSi by using the hM
m−RP heuristic. The difference
with GPT is that we compute a heuristic on planning graphs, where they compute plans in state
space. With this heuristic we account for the number of actions used in a given world, but assume
positive interaction across all possible worlds.
G
The hM
m−RP heuristic is computed by finding a relaxed plan RPγ on each planning graph γ ∈ Γ,
exactly as done on the single graph with hSG
RP . The difference is that unlike the single graph relaxed
plan SGU , but like SG1 , the initial levels of the planning graphs are states, so each relaxed plan
will reflect all the support needed in the world corresponding to γ. Formally:
⎞
⎛
bγ −1

RP
G
⎝
| Aj γ |⎠
hM
m−RP (BSi ) = max
γ∈Γ

j=0

where bγ is the level of γ where a constituent of BSG was first reachable.
58

P LANNING G RAPH H EURISTICS FOR B ELIEF S PACE S EARCH

Notice that we are not computing all state distances between states in BSP and BSi . Each
planning graph γ corresponds to a state in BSP , and from each γ we extract a single relaxed plan.
We do not need to enumerate all states in BSi and find a relaxed plan for each. We instead support a
set of literals from one constituent of BSi . This constituent is estimated to be the minimum distance
state in BSi because it is the first constituent reached in γ.
G
For CBTC, computing hM
m−RP (BSG ) (Figure 6) finds:
RP 1 =
1
= {inP1p , Flush},
ARP
0

E0RP1 = {ϕ0 (inP1p ), ϕ0 (Flush)},
1
= {inP1, ¬clog},
LRP
1
1
= {¬clogp , DunkP1},
ARP
1

E1RP1 = {ϕ0 (¬clogp ), ϕ1 (DunkP1)},

1
= {¬arm, ¬clog}
LRP
2

and RP 2 =
2
= {inP2p , Flush},
ARP
0

E0RP2 = {ϕ0 (inP2p ), ϕ0 (Flush)},

2
= {inP2, ¬clog},
LRP
1
2
= {¬clogp , DunkP2},
ARP
1

E1RP2 = {ϕ0 (¬clogp ), ϕ1 (DunkP2)},

2
= {¬arm, ¬clog}.
LRP
2

Each relaxed plan contains two actions and taking the maximum of the two relaxed plan values
G
gives hM
m−RP (BSG ) = 2. This aggregation ignores the fact that we must use different Dunk actions
each possible world.
G
Independence Aggregation: We can use the hM
s−RP heuristic to assume independence among the
worlds in our belief state. We extract relaxed plans exactly as described in the previous heuristic
and simply use a summation rather than maximization of the relaxed plan costs. Formally:
⎛
⎞
γ −1
 b
RP
G
⎝
| Aj γ |⎠
hM
s−RP (BSi ) =
γ∈Γ

j=0

where bγ is the level of γ where a constituent of BSG was first reachable.
G
MG
For CBTC, if computing hM
s−RP (BSG ), we find the same relaxed plans as in the hm−RP (BSG )
heuristic, but sum their values to get 2 + 2 = 4 as our heuristic. This aggregation ignores the fact
that we can use the same Flush action for both possible worlds.
State Overlap Aggregation: We notice that in the two previous heuristics we are either taking a
maximization and not accounting for some actions, or taking a summation and possibly accounting
G
for extra actions. We present the hM
RP U heuristic to balance the measure between positive interaction
and independence of worlds. Examining the relaxed plans computed by the two previous heuristics
for the CBTC example, we see that the relaxed plans extracted from each graph have some overlap.
1
2
Notice, that both ARP
and ARP
contain a Flush action irrespective of which package the bomb is
0
0
1
2
contains DunkP1, and ARP
contains DunkP2
in – showing some positive interaction. Also, ARP
1
1
59

B RYCE , K AMBHAMPATI , & S MITH

– showing some independence. If we take the layer-wise union of the two relaxed plans, we would
get a unioned relaxed plan:
RPU =
U
= {inP1p , Flush},
ARP
0

E0RPU = {ϕ0 (inP1p ), ϕ0 (inP2p ), ϕ0 (Flush)},
U
LRP
= {inP1, inP2, ¬clog},
1
U
= {¬clogp , DunkP1, DunkP2},
ARP
1

E1RPU = {ϕ0 (¬clogp ), ϕ1 (DunkP1), ϕ1 (DunkP2)},
U
LRP
= {¬arm, ¬clog}.
2

This relaxed plans accounts for the actions that are the same between possible worlds and the
actions that differ. Notice that Flush appears only once in layer zero and the Dunk actions both
appear in layer one.
In order to get the union of relaxed plans, we extract relaxed plans from each γ ∈ Γ, as in the
two previous heuristics. Then if we are computing heuristics for regression search, we start at the
last level (and repeat for each level) by taking the union of the sets of actions for each relaxed plan at
each level into another relaxed plan. The relaxed plans are end-aligned, hence the unioning of levels
proceeds from the last layer of each relaxed plan to create the last layer of the RPU relaxed plan,
then the second to last layer for each relaxed plan is unioned and so on. In progression search, the
relaxed plans are start-aligned to reflect that they all start at the same time, whereas in regression
we assume they all end at the same time. The summation of the number of actions of each action
level in the unioned relaxed plan is used as the heuristic value. Formally:
G
hM
RP U (BSi ) =

b−1


U
| ARP
|
j

j=0

where b is the greatest level bγ where a constituent of BSG was first reachable.
For CBTC, we just found RPU , so counting the number of actions gives us a heuristic value of
G (BS ) = 3.
hM
G
RP U
4.4 Labelled Uncertainty Graph Heuristics (LU G)
The multiple graph technique has the advantage of heuristics that can aggregate the costs of multiple
worlds, but the disadvantage of computing some redundant information in different graphs (c.f.
G
Figure 6) and using every graph to compute heuristics (c.f hM
RP U ). Our next approach addresses
these limitations by condensing the multiple planning graphs to a single planning graph, called a
labelled uncertainty graph (LU G). The idea is to implicitly represent multiple planning graphs by
collapsing the graph connectivity into one planning graph, but use annotations, called labels (), to
retain information about multiple worlds. While we could construct the LU G by generating each
of the multiple graphs and taking their union, instead we define a direct construction procedure.
We start in a manner similar to the unioned single planning graph (SGU ) by constructing an initial
layer of all literals in our source belief state. The difference with the LU G is that we can prevent
loss of information about multiple worlds by keeping a label for each literal the records which
of the worlds is relevant. As we will discuss, we use a few simple techniques to propagate the
60

P LANNING G RAPH H EURISTICS FOR B ELIEF S PACE S EARCH

labels through actions and effects and label subsequent literal layers. Label propagation relies on
expressing labels as propositional formulas and using standard propositional logic operations. The
end product is a single planning graph with labels on all graph elements; labels indicate which of
the explicit multiple graphs (if we were to build them) contain each graph element.
We are trading planning graph structure space for label storage space. Our choice of BDDs to
represent labels helps lower the storage requirements on labels. The worst-case complexity of the
LU G is equivalent to the M G representation. The LU G’s complexity savings is not realized when
the projected possible worlds and the relevant actions for each are completely disjoint; however, this
does not often appear in practice. The space savings comes in two ways: (1) redundant representation of actions and literals is avoided, and (2) labels that facilitate non-redundant representation
are stored as BDDs. A nice feature of the BDD package (Brace, Rudell, & Bryant, 1990) we use
is that it efficiently represents many individual BDDs in a shared BDD that leverages common substructure. Hence, in practice the LU G contains the same information as M G with much lower
construction and usage costs.
In this section we present construction of the LU G without mutexes, then describe how to
introduce mutexes, and finally discuss how to extract relaxed plans.
4.4.1 L ABEL P ROPAGATION
Like the single graph and multiple graphs, the LU G is based on the IP P (Koehler et al., 1997)
planning graph. We extend the single graph to capture multiple world causal support, as present in
multiple graphs, by adding labels to the elements of the action A, effect E, and literal L layers. We
denote the label of a literal l in level k as k (l). We can build the LU G for any belief state BSP ,
and illustrate BSP = BSI for the CBTC example. A label is a formula describing a set of states (in
BSP ) from which a graph element is (optimistically) reachable. We say a literal l is reachable from
a set of states, described by BS, after k levels, if BS |= k (l). For instance, we can say that ¬arm
is reachable after two levels if L2 contains ¬arm and BSI |= 2 (¬arm), meaning that the models of
worlds where ¬arm holds after two levels are a superset of the worlds in our current belief state.
The intuitive definition of the LU G is a planning graph skeleton, that represents causal relations,
over which we propagate labels to indicate specific possible world support. We show the skeleton
for CBTC in Figure 7. Constructing the graph skeleton largely follows traditional planning graph
semantics, and label propagation relies on a few simple rules. Each initial layer literal is labelled,
to indicate the worlds of BSP in which it holds, as the conjunction of the literal with BSP . An
action is labelled, to indicate all worlds where its execution preconditions can be co-achieved, as
the conjunction of the labels of its execution preconditions. An effect is labelled, to indicate all
worlds where its antecedent literals and its action’s execution preconditions can be co-achieved, as
the conjunction of the labels of its antecedent literals and the label of its associated action. Finally,
literals are labelled, to indicate all worlds where they are given as an effect, as the disjunction over
all labels of effects in the previous level that affect the literal. In the following we describe label
propagation in more detail and work through the CBTC example.
Initial Literal Layer: The LU G has an initial layer consisting of every literal with a non false (⊥)
label. In the initial layer the label 0 (l) of each literal l is identical to l∧BSP , representing the states
of BSP in which l holds. The labels for the initial layer literals are propagated through actions and
effects to label the next literal layer, as we will describe shortly. We continue propagation until no
label of any literal changes between layers, a condition referred to as “level off”.
61

B RYCE , K AMBHAMPATI , & S MITH

L0

A0

E0

L1

A1

E1

L2

inP1

inP1

inP1

: inP1

: inP1

: inP1

inP2

inP2

inP2

: inP2

: inP2

DunkP1

ϕ1(DunkP1)
ϕ0(DunkP1)

DunkP2

: inP2
: arm

ϕ1(DunkP2)
ϕ0(DunkP2)

arm

arm

arm

clog

clog

clog

Flush

ϕ0(Flush)

: clog

Flush

ϕ0(Flush)

: clog

G
Figure 7: The LU G skeleton for CBTC, with no mutexes. The relaxed plan for hLU
RP is shown in
bold.

The LU G for CBTC, shown in Figure 7 (without labels), using BSP =BSI has the initial literal
layer:
L0 = {inP1, ¬inP2, inP2, ¬inP1, clog, arm}
0 (inP1) = 0 (¬inP2) = (arm ∧ clog ∧ inP1 ∧ ¬inP2),
0 (inP2) = 0 (¬inP1) = (arm ∧ clog ∧ ¬inP1 ∧ inP2),
0 (clog) = 0 (arm) = BSP
Notice that inP1 and inP2 have labels indicating the respective initial states in which they hold,
and clog and arm have BSP as their label because they hold in all states in BSP .
Action Layer: Once the previous literal layer Lk is computed, we construct and label the action
layer Ak . Ak contains causative actions from the action set A, plus literal persistence. An action is
included in Ak if its label is not false (i.e. k (a) 
=⊥). The label of an action at level k, is equivalent
to the extended label of its execution precondition:
k (a) = ∗k (ρe (a))
Above, we introduce the notation for extended labels ∗k (f ) of a formula f to denote the worlds
of BSP that can reach f at level k. We say that any propositional formula f is reachable from BS
62

P LANNING G RAPH H EURISTICS FOR B ELIEF S PACE S EARCH

after k levels if BSi |= ∗k (f ). Since we only have labels for literals, we substitute the labels of
literals for the literals in a formula to get the extended label of the formula. The extended label of a
propositional formula f at level k, is defined:
∗k (f ∧ f  ) = ∗k (f ) ∧ ∗k (f  ),
∗k (f ∨ f  ) = ∗k (f ) ∨ ∗k (f  ),
∗
k (¬(f ∧ f  )) = ∗k (¬f ∨ ¬f  ),
∗k (¬(f ∨ f  )) = ∗k (¬f ∧ ¬f  ),
∗k () = BSP ,
∗k (⊥) =⊥,
∗k (l) = k (l)
The zeroth action layer for CBTC is:
A0 = {Flush, inP1p , ¬inP2p , inP2p , ¬inP1p , clogp , armp }
0 (Flush) = BSP ,
0 (inP1p ) = 0 (¬inP2p ) = (arm ∧ clog ∧ inP1 ∧ ¬inP2),
0 (inP2p ) = 0 (¬inP1p ) = (arm ∧ clog ∧ ¬inP1 ∧ inP2),
0 (clogp ) = 0 (armp ) = BSP
Each literal persistence has a label identical to the label of the corresponding literal from the
previous literal layer. The Flush action has BSP as its label because it is always applicable.
Effect Layer: The effect layer Ek depends both on the literal layer Lk and action layer Ak . Ek
contains an effect ϕj (a) if the effect has a non false label (i.e. k (ϕj (a)) 
=⊥). Because both the
action and an effect must be applicable in the same world, the label of the effect at level k is the
conjunction of the label of the associated action with the extended label of the antecedent
k (ϕj (a)) = k (a) ∧ ∗k (ρj (a))
The zeroth effect layer for CBTC is:
E0 = {ϕ0 (Flush), ϕ0 (inP1p ), ϕ0 (¬inP2p ), ϕ0 (inP2p ),
ϕ0 (¬inP1p ), ϕ0 (clogp ), ϕ0 (armp )}
0 (ϕ0 (Flush)) = BSP
0 (ϕ0 (inP1p )) = 0 (ϕ0 (¬inP2p )) = (arm ∧ clog ∧ inP1 ∧ ¬inP2),
0 (ϕ0 (inP2p )) = 0 (ϕ0 (¬inP1p )) = (arm ∧ clog ∧ ¬inP1 ∧ inP2),
0 (ϕ0 (clogp )) = 0 (ϕ0 (armp )) = BSP
Again, like the action layer, the unconditional effect of each literal persistence has a label identical to the corresponding literal in the previous literal layer. The unconditional effect of Flush has
a label identical to the label of Flush.
Literal Layer: The literal layer Lk depends on the previous effect layer Ek−1 , and contains only
literals with non false labels (i.e. k (l) 
=⊥). An effect ϕj (a) ∈ Ek−1 contributes to the label of a
literal l when the effect consequent contains the literal l. The label of a literal is the disjunction of
the labels of each effect from the previous effect layer that gives the literal:

k−1 (ϕj (a))
k (l) =
ϕj (a):l∈εj (a),
ϕj (a)∈Ek−1

63

B RYCE , K AMBHAMPATI , & S MITH

The first literal layer for CBTC is:
L1 = {inP1, ¬inP2, inP2, ¬inP1, ¬clog, clog, arm}
1 (inP1) = 1 (¬inP2) = (arm ∧ clog ∧ inP1 ∧ ¬inP2),
1 (inP2) = 1 (¬inP1) = (arm ∧ clog ∧ ¬inP1 ∧ inP2),
1 (¬clog) = 1 (clog) = 1 (arm) = BSP
This literal layer is identical to the initial literal layer, except that ¬clog goes from having a false
label (i.e. not existing in the layer) to having the label BSP .
We continue to the level one action layer because L1 does not indicate that BSG is reachable
from BSP (¬arm 
∈ L1 ). Action layer one is defined:
A1 = {DunkP1, DunkP2, Flush, inP1p , ¬inP2p , inP2p , ¬inP1p , clogp , armp , ¬clogp }
1 (DunkP1) = 1 (DunkP2) = 1 (Flush) = BSP ,
1 (inP1p ) = 1 (¬inP2p ) = (arm ∧ clog ∧ inP1 ∧ ¬inP2),
1 (inP2p ) = 1 (¬inP1p ) = (arm ∧ clog ∧ ¬inP1 ∧ inP2),
1 (clogp ) = 1 (armp ) = 1 (¬clogp ) = BSP
This action layer is similar to the level zero action layer. It adds both Dunk actions because they
are now executable. We also add the persistence for ¬clog. Each Dunk action gets a label identical
to its execution precondition label.
The level one effect layer is:
E1 = {ϕ0 (DunkP1), ϕ0 (DunkP2), ϕ1 (DunkP1), ϕ1 (DunkP2), ϕ0 (Flush), ϕ0 (inP1p ),
ϕ0 (¬inP2p ), ϕ0 (inP2p ), ϕ0 (¬inP1p ), ϕ0 (clogp ), ϕ0 (armp ), ϕ0 (¬clogp )}
1 (ϕ0 (DunkP1)) = 1 (ϕ0 (DunkP2)) = 1 (ϕ0 (Flush)) = BSP
1 (ϕ1 (DunkP1)) = (arm ∧ clog ∧ inP1 ∧ ¬inP2),
1 (ϕ1 (DunkP2)) = (arm ∧ clog ∧ ¬inP1 ∧ inP2),
1 (ϕ0 (¬inP2p )) = 1 (ϕ0 (inP1p )) = (arm ∧ clog ∧ inP1 ∧ ¬inP2),
1 (ϕ0 (¬inP1p )) = 1 (ϕ0 (inP2p )) = (arm ∧ clog ∧ ¬inP1 ∧ inP2),
1 (ϕ0 (clogp )) = 1 (ϕ0 (armp )) = 1 (ϕ0 (¬clogp )) = BSP
The conditional effects of the Dunk actions in CBTC (Figure 7) have labels that indicate the
possible worlds in which they will give ¬arm because their antecedents do not hold in all possible
worlds. For example, the conditional effect ϕ1 (DunkP1) has the label found by taking the conjunction of the action’s label BSP with the antecedent label ∗1 (inP1) to obtain (arm ∧ clog ∧ inP1 ∧
¬inP2).
Finally, the level two literal layer:
L2 = {inP1, ¬inP2, inP2, ¬inP1, ¬clog, clog, arm, ¬arm}
2 (inP1) = 2 (¬inP2) = (arm ∧ clog ∧ inP1 ∧ ¬inP2),
2 (inP2) = 2 (¬inP1) = (arm ∧ clog ∧ ¬inP1 ∧ inP2),
2 (¬clog) = 2 (clog) = 2 (arm) = 2 (¬arm) = BSP
The labels of the literals for level 2 of CBTC indicate that ¬arm is reachable from BSP because its label is entailed by BSP . The label of ¬arm is found by taking the disjunction of
the labels of effects that give it, namely, (arm ∧ clog ∧ inP1 ∧ ¬inP2) from the conditional
64

P LANNING G RAPH H EURISTICS FOR B ELIEF S PACE S EARCH

effect of DunkP1 and (arm ∧ clog ∧ ¬inP1 ∧ inP2) from the conditional effect of DunkP2,
which reduces to BSP . Construction could stop here because BSP entails the label of the goal
∗k (¬arm∧¬clog)= k (¬arm) ∧ k (¬clog) = BSP ∧ BSP = BSP . However, level off occurs at
the next level because there is no change in the labels of the literals.
When level off occurs at level three in our example, we can say that for any BS, where BS |=
BSP , that a formula f is reachable in k steps if BS |= ∗k (f ). If no such level k exists, then f is not
reachable from BS. If there is some level k, where f is reachable from BS, then the first such k is
a lower bound on the number of parallel plan steps needed to reach f from BS. This lower bound
is similar to the classical planning max heuristic (Nguyen et al., 2002). We can provide a more
informed heuristic by extracting a relaxed plan to support f with respect to BS, described shortly.
4.4.2 S AME -W ORLD L ABELLED M UTEXES
There are several types of mutexes that can be added to the LU G. To start with, we only concentrate
on those that can evolve in a single possible world because same-world mutexes are more effective
as well as relatively easy to understand. We extend the mutex propagation that was used in the
multiple graphs so that the mutexes are on one planning graph. The savings of computing mutexes
on the LU G instead of multiple graphs is that we can reduce computation when a mutex exits in
several worlds. In Appendix B we describe how to handle cross-world mutexes, despite their lack of
effectiveness in the experiments we conducted. Cross-world mutexes extend the LU G to compute
the same set of mutexes found by CGP (Smith & Weld, 1998).
Same-world mutexes can be represented with a single label, ˆk (x1 , x2 ), between two elements
(actions, effect, or literals). The mutex holds between elements x1 and x2 in all worlds S where
S |= ˆk (x1 , x2 ). If the elements are not mutex in any world, we can assume the label of a mutex
between them is false ⊥. We discuss how the labelled mutexes are discovered and propagated for
actions, effect relations, and literals.
By using mutexes, we can refine what it means for a formula f to be reachable from a set of
worlds BSP . We must ensure that for every state in BSP , there exists a state of f that is reachable.
A state S  of f is reachable from a state S of BSP when there are no two literals in S  that are
mutex in world S and BSP |= ∗k (S).
In each of the action, effect, and literal layers there are multiple ways for the same pair of
elements to become mutex (e.g. interference or competing needs). Thus, the mutex label for a pair
is the disjunction of all labelled mutexes found for the pair by some means.
Action Mutexes: The same-world action mutexes at a level k are a set of labelled pairs of actions.
Each pair is labelled with a formula that indicates the set of possible worlds where the actions are
mutex. The possible reasons for mutex actions are interference and competing needs.

• Interference Two actions a, a interfere if (1) the unconditional effect consequent ε0 (a) of
one is inconsistent with the execution precondition ρe (a ) of the other, or (2) vice versa.
They additionally interfere if (3) both unconditional effect consequents ε0 (a) and ε0 (a ) are
inconsistent, or (4) both execution preconditions ρe (a) and ρe (a ) are inconsistent. The mutex
will exist in all possible world projections ˆk (a, a ) = BSP . Formally, a and a interfere if
65

B RYCE , K AMBHAMPATI , & S MITH

one of the following holds:
(1) ε0 (a) ∧ ρe (a ) =⊥
(2) ρe (a) ∧ ε0 (a ) =⊥
(3) ε0 (a) ∧ ε0 (a ) =⊥
(4) ρe (a) ∧ ρe (a ) =⊥
• Competing Needs Two actions a, a have competing needs in a world when a pair of literals
from their execution preconditions are mutex in the world. The worlds where a and a are
mutex because of competing needs are described by:


k (a) ∧ k (a ) ∧

ˆk (l, l )

l∈ρj (a),l ∈ρj (a )

In the above formula we find all worlds where a pair of execution preconditions l ∈ ρe (a), l ∈
ρe (a ) are mutex and both actions are reachable.
Effect Mutexes: The effect mutexes are a set of labelled pairs of effects. Each pair is labelled with
a formula that indicates the set of possible worlds where the effects are mutex. The possible reasons
for mutex effects are associated action mutexes, interference, competing needs, or induced effects.
• Mutex Actions Two effects ϕi (a) ∈ Φ(a), ϕj (a ) ∈ Φ(a ) are mutex in all worlds where
their associated actions are mutex, ˆk (a, a ).
• Interference Like actions, two effects ϕi (a), ϕj (a ) interfere if (1) the consequent εi (a) of
one is inconsistent with the antecedent ρj (a ) of the other, or (2) vice versa. They additionally interfere if (3) both effect consequents εi (a) and εj (a ) are inconsistent, or (4) both
antecedents ρi (a) and ρj (a ) are inconsistent. The mutex will exist in all possible world projections, so the label of the mutex is ˆk (ϕi (a), ϕj (a )) = BSP . Formally, ϕi (a) and ϕj (a )
interfere if one of the following holds:
(1) εi (a) ∧ ρj (a ) =⊥
(2) ρi (a) ∧ εj (a ) =⊥
(3) εi (a) ∧ εj (a ) =⊥
(4) ρi (a) ∧ ρj (a ) =⊥
• Competing Needs Like actions, two effects have competing needs in a world when a pair of
literals from their antecedents are mutex in a world. The worlds where ϕi (a) and ϕj (a ) have
a competing needs mutex are:
k (ϕi (a)) ∧ k (ϕj (a )) ∧



ˆk (l, l )

l∈ρi (a),l ∈ρj (a )

In the above formula we find all worlds where a pair of execution preconditions l ∈ ρi (a), l ∈
ρj (a ) are mutex and both actions are reachable.
66

P LANNING G RAPH H EURISTICS FOR B ELIEF S PACE S EARCH

Lk

lk(p)
p

Ek

Ak

lk(a’)
a’

ϕh(a’)

lk(ϕh(a’))

∧

lk(p, q)
Induced mutex in worlds:
∧
lk(ϕj(a),ϕh(a’))∧lk(ϕi(a))

∧

lk(ϕj(a), ϕh(a’))

lk(q)
q
lk(a)
a

ϕj(a)

lk(r)
r

lk(ϕj(a))
ϕi(a) induces ϕj(a) in:
lk(ϕi(a))∧lk(ϕj(a))

ϕi(a) lk(ϕi(a))

Figure 8: Effect ϕi (a) induces effect ϕj (a). ϕj (a) is mutex with ϕh (a ), so ϕi (a) is induced mutex
with ϕh (a ).

• Induced An induced effect ϕj (a) of an effect ϕi (a) is an effect of the same action a that
may execute at the same time. An effect is induced by another in the possible worlds where
they are both reachable. For example, the conditional effect of an action always induces the
unconditional effect of the action.
Induced mutexes, involving the inducing effect ϕi (a), come about when an induced effect
ϕj (a) is mutex with another effect ϕh (a ) (see Figure 8). The induced mutex is between
(a) the effect ϕh (a ) that is mutex with the induced effect ϕj (a) and (b) the inducing effect
ϕi (a). The label of the mutex is the conjunction of the label of the mutex ˆk (ϕj (a), ϕh (a ))
and the label of the induced effect ϕj (a). For additional discussion of the methodology behind
induced mutexes we refer to Smith and Weld (1998).

Literal Mutexes: The literal mutexes are a set of labelled pairs of literals. Each pair is labelled with
a formula that indicates the set of possible worlds where the literals are mutex. The only reason for
mutex literals is inconsistent support.
• Inconsistent Support Two literals have inconsistent support in a possible world at level k
when there are no two non-mutex effects that support both literals in the world. The label of
the literal mutex at level k is a disjunction of all worlds where they have inconsistent support.
The worlds for an inconsistent support mutex between l and l are:
67

B RYCE , K AMBHAMPATI , & S MITH



S

S:∀ϕi (a),ϕj (a )∈E

k−1 ,
where l∈εi (a),l ∈εj (a ),
S|=ˆk−1 (ϕi (a),ϕj (a ))

The meaning of the above formula is that the two literals are mutex in all worlds S where all
pairs of effects that support the literals in S are mutex in S.
4.4.3 LU G H EURISTICS
The heuristics computed on the LU G can capture measures similar to the M G heuristics, but there
exists a new opportunity to make use of labels to improve heuristic computation efficiency. A single
planning graph is sufficient if there is no state aggregation being measured, so we do not mention
such measures for the LU G.
Positive Interaction Aggregation: Unlike M G heuristics, we do not compute positive interaction
based relaxed plans on the LU G. The M G approach to measure positive interaction across each
state in a belief state is to compute multiple relaxed plans and take their maximum value. To get the
same measure on the LU G we would still need to extract multiple relaxed plans, the situation we are
trying to avoid by using the LU G. While the graph construction overhead may be lowered by using
the LU G, the heuristic computation could take too long. Hence, we do not compute relaxed plans
on the LU G to measure positive interaction alone, but we do compute relaxed plans that measure
overlap (which measures positive interaction).
Independence Aggregation: Like positive interaction aggregation, we need a relaxed plan for every
state in the projected belief state to find the summation of the costs. Hence, we do not compute
relaxed plans that assume independence.
G
State Overlap Aggregation: A relaxed plan extracted from the LU G to get the hLU
RP heuristic
M
G
M
G
resembles the unioned relaxed plan in the hRP U heuristic. Recall that the hRP U heuristic extracts
a relaxed plan from each of the multiple planning graphs (one for each possible world) and unions
the set of actions chosen at each level in each of the relaxed plans. The LU G relaxed plan heuristic
is similar in that it counts actions that have positive interaction in multiple worlds only once and
accounts for independent actions that are used in subsets of the possible worlds. The advantage of
G
hLU
RP is that we find these actions with a single pass on one planning graph.
We are trading the cost of computing multiple relaxed plans for the cost of manipulating LU G
labels to determine what lines of causal support are used in what worlds. In the relaxed plan we
want to support the goal with every state in BSP , but in doing so we need to track which states in
BSP use which paths in the planning graph. A subgoal may have several different (and possibly
overlapping) paths from the worlds in BSP .
RP
RP
RP
RP
RP
RP
A LU G relaxed plan is a set of layers: {ARP
0 , E0 , L1 , ..., Ab−1 , Eb−1 , Lb }, where Ar
RP
RP
is a set of actions, Er is a set of effects, and Lr+1 is a set of clauses. The elements of the layers
are labelled to indicate the worlds of BSP where they are chosen for support. The relaxed plan is
G
extracted from the level b = hLU
level (BSi ) (i.e., the first level where BSi is reachable, also described
in Appendix A).
Please note that we are extracting the relaxed plan for BSi in terms of clauses, and not literals, which is different than the SG and M G versions of relaxed plans. Previously we found the

68

P LANNING G RAPH H EURISTICS FOR B ELIEF S PACE S EARCH

constituent of BSi that was first reached on a planning graph and now we do not commit to any
one constituent. Our rationale is that we were possibly using different constituents in each of the
multiple graphs, and in this condensed version of the multiple graphs we still want to be able to
support different constituents of the BSi in different worlds. We could also use the constituent representation of BSi in defining the layers of the relaxed plan, but choose the clausal representation
of BSi instead because we know that we have to support each clause. However with constituents
we know we only need to support one (but we don’t need to know which one).
The relaxed plan, shown in bold in Figure 7, for BSI to reach BSG in CBTC is listed as follows:
= {inP1p , inP2p , Flush},
ARP
0
RP
0 (inP1p ) = (arm ∧ ¬clog ∧ inP1 ∧ ¬inP2),
RP
0 (inP2p ) = (arm ∧ ¬clog ∧ ¬inP1 ∧ inP2),
RP
0 (Flush) = BSP ,
E0RP = {ϕ0 (inP1p ), ϕ0 (inP2p ), ϕ0 (Flush)},
0
RP
0 (ϕ (inP1p )) = (arm ∧ ¬clog ∧ inP1 ∧ ¬inP2),
0
RP
0 (ϕ (inP2p )) = (arm ∧ ¬clog ∧ ¬inP1 ∧ inP2),
RP
0 (ϕ0 (Flush)) = BSP ,
= {inP1, inP2, ¬clog},
LRP
1
RP
1 (inP1) = (arm ∧ ¬clog ∧ inP1 ∧ ¬inP2),
RP
1 (inP2) = (arm ∧ ¬clog ∧ ¬inP1 ∧ inP2),
RP
1 (¬clog) = BSP ,
= {DunkP1, DunkP2, ¬clogp },
ARP
1
RP
1 (DunkP1) = (arm ∧ ¬clog ∧ inP1 ∧ ¬inP2),
RP
1 (DunkP2) = (arm ∧ ¬clog ∧ ¬inP1 ∧ inP2),
RP
1 (¬clogp ) = BSP ,
E1RP = {ϕ1 (DunkP1), ϕ1 (DunkP2), ϕ0 (¬clogp )},
1
RP
1 (ϕ (DunkP1)) = (arm ∧ ¬clog ∧ inP1 ∧ ¬inP2),
1
RP
1 (ϕ (DunkP2)) = (arm ∧ ¬clog ∧ ¬inP1 ∧ inP2),
RP
1 (ϕ0 (¬clogp )) = BSP ,
= {¬arm, ¬clog},
LRP
2
RP
2 (¬arm) = BSP ,
RP
2 (¬clog) = BSP
We start by forming LRP
with the clauses in κ(BSG ), namely ¬arm and ¬clog; we label the
2
clauses with BSP because they need to be supported by all states in our belief state. Next, we
support each clause in LRP
with the relevant effects from E1 to form E1RP . For ¬clog we use
2
persistence because it supports ¬clog in all worlds described by BSP (this is an example of positive
interaction of worlds). For ¬arm the relevant effects are the respective ϕ1 from each Dunk action.
We choose both effects to support ¬arm because we need to support ¬arm in all worlds of BSP , and
each effect gives support in only one world (this is an example of independence of worlds). We then
with the appropriate label indicating
insert the actions associated with each chosen effect into ARP
1
69

B RYCE , K AMBHAMPATI , & S MITH

the worlds where it was needed, which in general is fewer worlds than where it is reachable (i.e.
RP with the execution preconditions of
it is always the case that RP
r (·) |= r (·)). Next we form L1
actions in ARP
and antecedents of effects in E1RP , which are ¬clog, inP1, and inP2, labelled with
1
all worlds where an action or effect needed them. In the same fashion as level two, we support the
literals at level one, using persistence for inP1 and inP2, and Flush for ¬clog. We stop here, because
we have supported all clauses at level one.
For the general case, extraction starts at the level b where BSi is first reachable from BSP .
RP
RP
RP contains all clauses
The first relaxed plan layers we construct are ARP
b−1 , Eb−1 , Lb , where Lb
RP
C ∈ κ(BSi ), labelled as k (C) = BSP .
by choosing relevant effects from
For each level r, 1 ≤ r ≤ b, we support each clause in LRP
r
RP . An effect ϕj (a) is relevant if it is reachable in some of the worlds where we
Er−1 to form Er−1
need to support C (i.e. r−1 (ϕj (a)) ∧ RP
r (C) 
=⊥) and the consequent gives a literal l ∈ C. For
each clause, we have to choose enough supporting effects so that the chosen effect worlds are a
superset of the worlds we need to support the clause, formally:
⎛
⎞
⎜
⎟
⎜
⎟

⎜
⎟
RP
RP
j

(C)
|=

(ϕ
(a))
∀C∈LRP
⎜
⎟
r
r−1
r
⎜ j
⎟
⎝ϕ (a):l∈εj (a),
⎠
l∈C,
ϕj (a)∈Er−1

We think of supporting a clause in a set of worlds as a set cover problem where effects cover
subsets of worlds. Our algorithm to cover the worlds of a clause with worlds of effects is a variant
of the well known greedy algorithm for set cover (Cormen, Leiserson, & Rivest, 1990). We first
choose all relevant persistence effects that can cover worlds, then choose action effects that cover
RP and labelled with the new
the most new worlds. Each effect we choose for support is added to Er−1
RP
worlds it covered for C. Once all clauses in Lr are covered, we form the action layer ARP
r−1 as all
RP . The actions in ARP are labelled to indicate all worlds where
actions that have an effect in Er−1
r−1
RP .
any of their effects were labelled in Er−1
We obtain the next subgoal layer, LRP
r−1 , by adding literals from the execution preconditions of
RP
RP . Each literal l ∈ LRP is labelled to indicate all
actions in Ar−1 and antecedents of effects in Er−1
r−1
worlds where any action or effect requires l. We support the literals in LRP
r−1 in the same fashion
.
We
continue
to
support
literals
with
effects,
insert
actions,
and
insert action and effect
as LRP
r
RP
preconditions until we have supported all literals in L1 .
G
Once we get a relaxed plan, the relaxed plan heuristic, hLU
RP (BSi ), is the summation of the
number of actions in each action layer, formally:
G
hLU
RP (BSi )

=

b−1


| ARP
|
i

i=0
G
Thus in our CBTC example we have hLU
RP (BSG ) = 3. Notice that if we construct the LU G
without mutexes for CBTC we reach the goal after two layers. If we had included mutexes the
LU G, then it would reach the goal after three layers. The way we use mutexes will not change our
relaxed plan because we do not use mutexes to influence relaxed plan extraction. Mutexes only help
to identify when a the belief state BSi is not reachable from BSP .

70

P LANNING G RAPH H EURISTICS FOR B ELIEF S PACE S EARCH

Problem

PDDL Parser
(IPC)
Actions

Belief
States

Search Engine
(HSP-r: CAltAlt/
LAO*: POND)

Heuristics

BDDs
(CUDD)

Labels

(POND only)

Planning
Graph(s)
(IPP)

Figure 9: The implementations of CAltAlt and P ON D rely on many existing technologies. The
search engine is guided by heuristics extracted from planning graphs.

5. Empirical Evaluation: Setup
This section presents our implementation of the CAltAlt and P ON D planners and the domains we
use in the experiments. All tests were run in Linux on an x86 machine with a 2.66GHz P4 processor
and 1GB RAM with a timeout of 20 minutes. Both CAltAlt and P ON D used a heuristic weight
of five in the, respective, A* and AO* searches. We compare with the competing approaches (CGP,
SGP, GPT v1.40, MBP v0.91, KACMBP, YKA, and CFF) on several domains and problems. Our
planners and all domain and problem files for all of the compared planners can be found in the
online appendix.
5.1 Implementation
The implementation of CAltAlt uses several off-the-shelf planning software packages. Figure 9
shows a diagram of the system architecture for CAltAlt and P ON D. While CAltAlt extends the
name of AltAlt, it relies on a limited subset of the implementation. The components of CAltAlt
are the IPC parser for PDDL 2.1 (slightly extended to allow uncertain initial conditions), the HSPr search engine (Bonet & Geffner, 1999), the IPP planning graph (Koehler et al., 1997), and the
CUDD BDD package (Brace et al., 1990) to implement the LU G labels. The custom parts of the
implementation include the action representation, belief state representation, regression operator,
and the heuristic calculation.
The implementation of P ON D is very similar to CAltAlt aside from the search engine, and
state and action representation. P ON D also uses the IPP source code for planning graphs. P ON D
uses modified LAO* (Hansen & Zilberstein, 2001) source code from Eric Hansen to perform AO*
71

B RYCE , K AMBHAMPATI , & S MITH

Problem
Rovers1
Rovers2
Rovers3
Rovers4
Rovers5
Rovers6
Logistics1
Logistics2
Logistics3
Logistics4
Logistics5
BT(n)
BTC(n)
CubeCenter(n)
Ring(n)

Initial
States
1
2
3
4
16
12
2
4
2
4
8
n
n
n3
n3n

Goal
Literals
1
1
1
1
3
3
1
2
1
2
3
1
1
3
n

Fluents
66
66
66
66
71
119
29
36
58
68
78
n+1
n+2
3n
4n

Causative
Actions
88
88
88
88
97
217
70
106
282
396
510
n
n+1
6
4

Observational
Actions
0 {12}
0 {12}
0 {12}
0 {12}
0 {12}
0 {18}
0 {10}
0 {20}
0 {21}
0 {42}
0 {63}
0 {n}
0 {n}
0
0

Optimal
Parallel
5 {5}
8 {7}
10 {?}
13 {?}
? {?}
? {?}
6 {6}
6 {?}
8 {?}
8 {?}
? {?}
1 {1}
2n-1 {2}
(3n-3)/2
3n-1

Optimal
Serial
5 {5}
8 {7}
10 {8}
13 {10}
20 {?}
? {?}
9 {7}
15 {12}
11 {8}
18 {?}
28 {?}
n {n-1}
2n-1 {n-1}
(9n-3)/2
3n-1

Table 2: Features of test domains and problems - Number of initial states, Number of goal literals, Number of fluents, Number of causative actions, Number of Observational Actions,
Optimal number of parallel plan steps, Optimal number of serial plan steps. Data for conditional versions of domains is in braces; plan lengths for conditional plans are maximum
conditional branch length.

search, and CUDD (Brace et al., 1990) to represent belief states and actions. Even with deterministic
actions it is possible to obtain cycles from actions with observations because we are planning in
belief space. P ON D constructs the search graph as a directed acyclic graph by employing a cyclechecking algorithm. If adding a hyper-edge to the search graph creates a cycle, then the hyper-edge
cannot represent an action in a strong plan and is hence not added to the graph.
5.2 Domains
Table 2 shows some of the relative features of the different problems we used to evaluate our approach. The table shows the number of initial states, goal literals, fluents, actions, and optimal
plan lengths. This can be used as a guide to gauge the difficulty of the problems, as well as our
performance.
Conformant Problems In addition to the standard domains used in conformant planning–such
as Bomb-in-the-Toilet, Ring, and Cube Center, we also developed two new domains Logistics and
Rovers. We chose these new domains because they have more difficult subgoals, and have many
plans of varying length.
The Ring domain involves a ring of n rooms where each room is connected to two adjacent
rooms. Each room has a window which can be open, closed, or locked. The goal is to have every
window locked. Initially, any state is possible – we could be in any room and each window could be
in any configuration. There are four actions: move right, move left, close the window in the current
72

P LANNING G RAPH H EURISTICS FOR B ELIEF S PACE S EARCH

room, and lock the window in the current room. Closing a window only works if the window is
open, and locking a window only works if the window is closed. A good conformant plan involves
moving in one direction closing and locking the window in each room.
The Cube Center domain involves a three-dimensional grid (cube) where there are six actions –
it is possible to move in two directions along each dimension. Each dimension consists of n possible
locations. Moving in a direction along which there are no more grid points leaves one in the same
position. Using this phenomena, it is possible to localize in each dimension by repeatedly moving
in the same direction. Initially it is possible to be at any location in the cube and the goal is to reach
the center. A good conformant plan involves localizing in a corner and then moving to the center.
The Rovers domain is a conformant adaptation of the analogous domain of the classical planning
track of the International Planning Competition (Long & Fox, 2003). The added uncertainty to
the initial state uses conditions that determine whether an image objective is visible from various
vantage points due to weather, and the availability of rock and soil samples. The goal is to upload an
image of an objective and some rock and soil sample data. Thus a conformant plan requires visiting
all of the possible vantage points and taking a picture, plus visiting all possible locations of soil and
rock samples to draw samples.
The first five Rovers problems have 4 waypoints. Problems one through four have one through
four locations, respectively, at which a desired imaging objective is possibly visible (at least one will
work, but we don’t know which one). Problem 5 adds some rock and soil samples as part of the goal
and several waypoints where one of each can be obtained (again, we don’t know which waypoint
will have the right sample). Problem 6 adds two more waypoints, keeps the same goals as Problem
5 and changes the possible locations of the rock and soil samples. In all cases the waypoints are
connected in a tree structure, as opposed to completely connected.
The Logistics domain is a conformant adaptation of the classical Logistics domain where trucks
and airplanes move packages. The uncertainty is the initial locations of packages. Thus, any actions
relating to the movement of packages have a conditional effect that is predicated on the package
actually being at a location. In the conformant version, the drivers and pilots cannot sense or communicate a package’s actual whereabouts. The problems scale by adding packages and cities.
The Logistics problems consist of one airplane, and cities with an airport, a post office, and a
truck. The airplane can travel between airports and the trucks can travel within cities. The first
problem has two cities and one package that could start at either post office, and the goal is to get
the package to the second city’s airport. The second problem adds another package at the same
possible starting points and having the same destination. The third problem has three cities with
one package that could be at any post office and has to reach the third airport. The fourth problem
adds a second package to the third problem with the same starting and ending locations. The fifth
problem has three cities and three packages, each at one of two of the three post offices and having
to reach different airports.
Conditional Problems For conditional planning we consider domains from the literature: Bombin-the-Toilet with sensing BTS, and Bomb-in-the-Toilet with clogging and sensing BTCS. We also
extend the conformant Logistics and Rovers to include sensory actions.
The Rovers problem allows for the rover, when it is at a particular waypoint, to sense the availability of image, soil, or rock data at that location. The locations of the collectable data are expressed
as one-of constraints, so the rover can deduce the locations of collectable data by failing to sense
the other possibilities.
73

B RYCE , K AMBHAMPATI , & S MITH

Logistics has observations to determine if a package at a location exists, and the observation is
assumed to be made by a driver or pilot at the particular location. Since there are several drivers and
a pilot, different agents make the observations. The information gained by the agents is assumed to
be automatically communicated to the others, as the planner is the agent that has all the knowledge.5

6. Empirical Evaluation: Inter-Heuristic Comparison
We start by comparing the heuristic approaches within our planners. In the next section, we continue
by describing how our planners, using the best heuristics, compare against other state of the art
approaches. In this section we intend to validate our claims that belief space heuristics that measure
overlap perform well across several domains. We further justify using the LU G over multiple
planning graphs and applying mutexes to improve heuristics in regression through pruning belief
states.
We compare many techniques within CAltAlt and P ON D on our conformant planning domains, and in addition we test the heuristics in P ON D on the conditional domains. Our performance metrics include the total planning time and the number of search nodes expanded. Additionally, when discussing mutexes we analyze planning graph construction time. We proceed by
showing how the heuristics perform in CAltAlt and then how various mutex computation schemes
for the LU G can affect performance. Then we present how P ON D performs with the different
heuristics in both conformant and conditional domains, explore the effect of sampling a proportion
of worlds to build SG1 , M G, and LU G graphs, and compare the heuristic estimates in P ON D
to the optimal plan length to gauge heuristic accuracy. We finish with a summary of important
conclusions.
We only compute mutexes in the planning graphs for CAltAlt because the planning graph(s) are
only built once in a search episode and mutexes help prune the inconsistent belief states encountered
in regression search. We abstain from computing mutexes in P ON D because in progression we
build new planning graphs for each search node and we want to keep graph computation time low.
With the exception of our discussion on sampling worlds to construct the planning graphs, the
planning graphs are constructed deterministically. This means that the single graph is the unioned
single graph SGU , and the M G and LU G graphs are built for all possible worlds.
6.1 CAltAlt
The results for CAltAlt in the conformant Rovers, Logistics, BT, and BTC domains, in terms of
total time and number of expanded search nodes, are presented in Table 3. We show the number of
expanded nodes because it gives an indication of how well a heuristic guides the planner. The total
time captures the amount of time computing the heuristic and searching. A high total time with a
high number of search nodes indicates a poor heuristic, and a high total time and low number of
search nodes indicates an expensive but informed heuristic.
We do not discuss the Ring and Cube Center domains for CAltAlt because it cannot solve
even the smallest instances. Due to implementation details the planner performs very poorly when
domains have actions with several conditional effects and hence does not scale. The trouble stems
5. This problem may be interesting to investigate in a multi-agent planning scenario, assuming no global communication
(e.g. no radio dispatcher).

74

P LANNING G RAPH H EURISTICS FOR B ELIEF S PACE S EARCH

Problem
Rovers 1
2
3
4
5
6
Logistics 1
2
3
4
5
BT 2
10
20
30
40
50
60
70
80
BTC 2
10
20
30
40
50
60
70

h0
2255/5
49426/8
TO
1108/9
TO
19/2
4837/10
TO
30/3
15021/19
TO
-

hcard
18687/14
TO
4268/9
TO
14/2
56/10
418/20
1698/30
5271/40
12859/50
26131/60
48081/70
82250/80
16/3
161/19
1052/39
3823/59
11285/79
26514/99
55687/119
125594/140

hSG
RP
543/5
78419/8
91672/10
TO
198/9
7722/15
3324/14
141094/19
TO
18/2
5158/10
TO
16/3
15679/19
TO
-

G
hM
m−RP
542/5
8327/8
20162/10
61521/16
TO
183/9
15491/15
70882/14
TO
20/2
8988/10
TO
33/3
41805/19
TO
-

G
hM
RP U
185/5
29285/9
2244/11
3285/15
TO
1109/9
69818/19
TO
21/2
342/10
2299/20
9116/30
44741/40
TO
23/3
614/19
2652/39
9352/59
51859/79
TO
-

LU G(F X)

hRP
15164/5
32969/8
16668/10
31584/13
TO
1340/9
18535/15
16458/15
178068/19
TO
12/2
71/10
569/20
2517/30
7734/40
18389/50
37820/60
70538/70
188603/80
18/3
1470/19
51969/39
484878/59
TO
-

Table 3: Results for CAltAlt for conformant Rovers, Logistics, BT, and BTC. The data is Total
Time / # Expanded Nodes, “TO” indicates a time out (20 minutes) and “-” indicates no
attempt.

from a weak implementation for bringing general propositional formulas (obtained by regression
with several conditional effects) into CNF.
We describe the results from left to right in Table 3, comparing the different planning graph
structures and relaxed plans computed on each planning graph. We start with the non-planning
graph heuristics h0 and hcard . As expected, h0 , breadth-first search, does not perform well in a
large portion of the problems, shown by the large number of search nodes and inability to scale to
solve larger problems. We notice that with the hcard heuristic performance is very good in the BT
and BTC problems (this confirms the results originally seen by Bertoli, Cimatti, & Roveri, 2001a).
However, hcard does not perform as well in the Rovers and Logistics problems because the size of a
belief state, during planning, does not necessarily indicate that the belief state will be in a good plan.
Part of the reason hcard works so well in some domains is that it measures knowledge, and plans
for these domains are largely based on increasing knowledge. The reason hcard performs poorly
on other domains is that finding causal support (which it does not measure) is more important than
knowledge for these domains.
75

B RYCE , K AMBHAMPATI , & S MITH

Next, for a single planning graph (SGU ), CAltAlt does reasonably well with the hSG
RP heuristic in
the Rovers and Logistics domains, but fails to scale very well on the BT and BTC domains. Rovers
and Logistics have comparatively fewer initial worlds than the BT and BTC problems. Moreover
the deterministic plans, assuming each initial state is the real state, are somewhat similar for Rovers
and Logistics, but mostly independent for BT and BTC. Therefore, approximating a fully observable plan with the single graph relaxed plan is reasonable when plans for achieving the goal from
each world have high positive interaction. However, without high positive interaction the heuristic
degrades quickly when the number of initial worlds increases.
With multiple planning graphs, CAltAlt is able to perform better in the Rovers domain, but takes
quite a bit of time in the Logistics, BT, and BTC domains. In Rovers, capturing distance estimates
for individual worlds and aggregating them by some means tends to be better than aggregating
worlds and computing a single distance estimate (as in a single graph). In Logistics, part of the
reason computing multiple graphs is so costly is that we are computing mutexes on each of the
planning graphs. In BT and BTC, the total time increases quickly because the number of planning
graphs, and number of relaxed plans for every search node increase so much as problems get larger.
G
MG
Comparing the two multiple graph heuristics6 in CAltAlt namely hM
m−RP and hRP U , we can
M
G
see the effect of our choices for state distance aggregation. The hm−RP relaxed plan heuristic
aggregates state distances, as found on each planning graph, by taking the maximum distance. The
G
hM
RP U unions the relaxed plans from each graph, and counts the number of actions in the unioned
G
relaxed plan. As with the single graph relaxed plan, the hM
m−RP relaxed plan essentially measures
one state to state distance; thus, performance suffers on the BT and BTC domains. However, using
the unioned relaxed plan heuristic, we capture the independence among the multiple worlds so that
we scale up better in BT and BTC. Despite the usefulness of the unioned relaxed plan, it is costly to
compute and scalability is limited, so we turn to the LU G version of this same measure.
LU G(F X)

With the LU G, we use the hRP
heuristic in CAltAlt. This heuristic uses a LU G with
G
full cross-world mutexes (denoted by F X). As in the similar hM
RP U heuristic, measuring overlap is
important, and improving the speed of computing the heuristic tends to improve the scalability of
CAltAlt. While CAltAlt is slower in the Rovers and BTC domains when using the LU G, we note
that it is because of the added cost of computing cross-world mutexes – we are able to improve the
speed by relaxing the mutexes, as we will describe shortly.
6.2 Mutexes
Mutexes are used to help determine when a belief state is unreachable. Mutexes improve the pruning
power of heuristics by accounting for negative interactions. The mutexes are only used to improve
our heuristics, so it is reasonable to compute only a subset of the mutexes. We would like to know
which mutexes are the most cost effective because the number of possible mutexes we can find is
quite large.
We can use several schemes to compute a subset of the mutexes. The schemes combine different
types of mutexes with types of cross-world checking. The mutex types are: computing no mutexes
(NX), computing only static interference mutexes (StX), computing (StX) plus inconsistent support and competing needs mutexes – dynamic mutexes (DyX), and computing (DyX) plus induced
mutexes – full mutexes (FX). The cross-world checking (see appendix B) reduction schemes are:
G
6. We show hM
s−RP with P ON D.

76

Problem
Rovers 1
2
3
4
5
6
Logistics 1
2
3
4
5
BT 2
10
20
30
40
50
60
70
80
BTC 2
10
20
30
40
50
60
70

LU G(N X)

hRP
13/1112/51
20/904/41
13/8704/384
TO
5/868/81
10/63699/1433
TO
1/34/2
4/72/10
19/452/20
62/1999/30
130/6130/40
248/14641/50
430/30140/60
680/55202/70
1143/135760/80
0/62/3
4/93/19
21/546/39
58/2311/59
133/6889/79
260/15942/99
435/32201/119
742/62192/139

LU G(StX)

hRP
19/1119/51
16/903/41
17/8972/384
TO
10/868/81
88/78448/1433
TO
0/13/2
4/56/10
22/448/20
59/1981/30
132/6170/40
255/14760/50
440/29891/60
693/55372/70
1253/140716/80
1/16/3
4/77/19
32/545/39
61/2293/59
149/6879/79
261/16452/99
443/32923/119
745/61827/139

LU G(DyX)

hRP
15453/89/6
13431/138/8
17545/185/10
32645/441/14
698575/3569/45
TO
1250/117/9
16394/622/15
17196/1075/15
136702/1035/19
TO
0/13/2
13/57/10
120/453/20
514/1999/30
1534/6432/40
3730/14711/50
7645/30127/60
15019/55417/70
26478/132603/80
0/15/3
14/78/19
139/553/39
543/2288/59
1564/6829/79
TO
-

LU G(F X)

hRP
15077/87/6
32822/147/8
16481/187/10
31293/291/14
TO
1242/98/9
18114/421/15
16085/373/15
176995/1073/19
TO
0/12/2
13/58/10
120/449/20
509/2008/30
1517/6217/40
3626/14763/50
7656/30164/60
14636/55902/70
26368/162235/80
4/14/3
1388/82/19
51412/557/39
482578/2300/59
TO
-

LU G(DyX−SX)

hRP
15983/87/6
10318/139/8
10643/185/10
14988/291/14
61373/3497/45
217507/3544/37
791/116/9
2506/356/15
10407/403/15
24214/648/19
52036/2690/41
0/16/2
12/59/10
102/450/20
421/1994/30
1217/6326/40
2866/14707/50
5966/30017/60
11967/55723/70
21506/136149/80
0/16/3
13/76/19
105/546/39
427/2294/59
1211/6798/79
2890/16184/99
6045/32348/119
TO

LU G(DyX−IX)

hRP
15457/87/6
10625/134/8
11098/209/10
16772/291/14
379230/3457/45
565013/3504/37
797/117/9
7087/428/15
10399/408/15
71964/871/19
328114/4668/52
0/15/2
14/59/10
139/454/20
600/2007/30
1822/6163/40
4480/14676/50
9552/30337/60
18475/55572/70
32221/105654/80
1/14/3
16/75/19
140/549/39
606/2300/59
1824/6816/79
4412/16414/99
9492/32350/119
TO

LU G(F X−SX)

hRP
15098/86/6
10523/138/8
10700/191/10
14726/290/14
60985/3388/45
225213/3408/37
796/115/9
2499/352/15
10214/387/15
23792/642/19
52109/2672/41
0/25/2
13/59/10
105/444/20
413/1986/30
1196/6113/40
2905/14867/50
5933/30116/60
11558/55280/70
21053/139079/80
1/13/3
14/75/19
110/555/39
444/2287/59
1253/6830/79
2926/16028/99
6150/32876/119
TO

LU G(F X−IX)

hRP
15094/85/6
14550/138/8
11023/184/10
16907/290/14
378869/3427/45
588336/3512/37
808/115/9
6968/401/15
10441/418/15
71099/858/19
324508/4194/52
0/13/2
14/56/10
137/454/20
596/2002/30
1797/6127/40
4392/14683/50
9234/29986/60
18081/55403/70
32693/109508/80
2/14/3
440/81/19
19447/568/39
199601/2401/59
1068019/6940/79
TO
-

P LANNING G RAPH H EURISTICS FOR B ELIEF S PACE S EARCH

G
Table 4: Results for CAltAlt using hLU
RP with mutex schemes. The data is Graph Construction
Time (ms)/All Other Time (ms)/# Expanded Nodes, “TO” indicates a time out (20 minutes)
and “-” indicates no attempt.

77

B RYCE , K AMBHAMPATI , & S MITH

computing mutexes across same-worlds (SX) and computing mutexes across pairs of worlds in the
intersection (conjunction) of element labels (IX).
Table 4 shows that within CAltAlt, using the relaxed plan heuristic and changing the way we
compute mutexes on the LU G can drastically alter performance. Often, the cross-world mutexes
are so numerous that building the LU G takes too much time. To see if we could reduce graph
G
construction overhead without hindering performance, we evaluated hLU
RP when the LUG is built
(a) considering all cross-world relations, for the schemes (NX), (StX), (DyX), and (FX); and (b)
same-world relations for the schemes (DyX-SX) and (FX-SX), and (c) cross-world relations for all
possible worlds pairs in the intersection of element’s labels (DyX-IX) and (FX-IX).
The results show that simpler problems like BT and BTC do not benefit as much from advanced
computation of mutexes beyond static interference. However, for the Rovers and Logistics problems, advanced mutexes play a larger role. Mainly, interference, competing needs, and inconsistent
support mutexes are important. The competing needs and inconsistent support mutexes seem to
have a large impact on the informedness of the guidance given by the LU G, as scalability improves
most here. Induced mutexes don’t improve search time much, and only add to graph computation
time. A possible reason induced mutexes don’t help as much in these domains is that all the actions
have at most two effects, an unconditional and conditional effect. Reducing cross-world mutex
checking also helps quite a bit. It seems that only checking same-world mutexes is sufficient to
solve large problems. Interestingly, the M G graphs compute same-world interference, competing
needs, and inconsistent support mutexes within each graph, equating to the same scenario as (DyXSX), however, the LUG provides a much faster construction time, evidenced by the LU G’s ability
to out-scale M G.
6.3 P ON D
We show the total time and the number of expanded nodes for P ON D solving the conformant
problems (including Ring and Cube Center) in Table 5, and for P ON D solving the conditional
problems in Table 6. As with CAltAlt we show the total time and number of expanded nodes for
G
each test. We also add the hM
s−RP heuristic, not implemented in CAltAlt, that takes the summation
of the values of relaxed plans extracted from multiple planning graphs. We do not compute mutexes
on any of the planning graphs used for heuristics in P ON D mainly because we build planning
graphs for each search node. We proceed by first commenting on the performance of P ON D, with
the different heuristics, in the conformant domains, then discuss the conditional domains.
In the conformant domains, P ON D generally does better than CAltAlt. This may be attributed
in part to implementation-level details. P ON D makes use of an existing (highly optimized) BDD
package for belief state generation in progression, but as previously mentioned, CAltAlt relies on a
less optimized implementation for belief state generation in regression. As we will see in the next
section, regression planners that employ a more sophisticated implementation perform much better,
but could still benefit from our heuristics. Aside from a few differences that we will mention, we see
similar trends in the performance of the various heuristics in both CAltAlt and P ON D. Namely,
the N G and SG heuristics have limited ability to help the planner scale, the M G heuristics help
the planner scale better but are costly, and the LU G provides the best scalability. The difference
between the M G and the LU G are especially pronounced in Cube Center and Ring, where the size
of the initial belief state is quite large as the instances scale. Interestingly in Ring, breadth first
search and the single graph relaxed plan are able to scale due to reduced heuristic computation time
78

P LANNING G RAPH H EURISTICS FOR B ELIEF S PACE S EARCH

Problem
Rovers 1
2
3
4
5
6
Logistics 1
2
3
4
5
BT 2
10
20
30
40
50
60
70
80
BTC 2
10
20
30
40
50
60
70
CubeCenter 3
5
7
9
11
13
Ring 2
3
4
5
6
7
8
9
10

h0
540/36
940/249
3340/1150
TO
560/169
TO
450/3
760/1023
TO
460/5
1090/2045
TO
10/184
180/3198
1940/21703
TO
20/15
20/59
30/232
160/973
880/4057
5940/16299
39120/64657
251370/261394
TO

hcard
520/21
790/157
2340/755
14830/4067
TO
530/102
TO
460/2
590/428
TO
460/4
970/1806
TO
30/14
20/58
40/203
70/363
230/1010
700/2594
20/7
20/11
20/15
20/19
30/23
40/27
40/31
50/35
70/39

hSG
RP
590/6
700/15
3150/230
13480/1004
TO
680/46
TO
460/3
1560/1023
TO
450/5
3160/2045
TO
90/34
3510/1342
46620/10316
333330/46881
TO
30/15
70/59
350/232
2270/973
14250/4057
83360/16299
510850/64657
TO
-

G
hM
m−RP
580/6
1250/32
3430/77
10630/181
85370/452
180890/416
970/58
2520/32
27820/927
5740/27
42980/59
450/2
6200/428
TO
460/4
18250/1806
TO
1050/61
60460/382
TO
80/8
1500/41
51310/77
TO
-

G
hM
s−RP
580/6
750/10
1450/24
7000/163
12470/99
15780/38
730/21
6420/105
4050/83
29180/211
51380/152
450/2
820/10
6740/20
41320/30
179930/40
726930/50
TO
460/3
980/19
TO
370/9
11060/55
852630/359
TO
80/7
500/8
6370/11
283780/16
TO
-

G
hM
RP U
580/6
830/13
1370/23
2170/34
31480/73
31950/73
650/9
2310/20
2000/15
53470/382
471850/988
500/2
880/10
6870/20
44260/30
183930/40
758140/50
TO
470/3
990/19
9180/39
54140/59
251140/79
1075250/99
TO
0430/11
14780/82
1183220/444
TO
80/8
920/19
19300/40
TO
-

G
hLU
RP
590/6
680/11
850/16
1130/28
2050/36
9850/147
560/9
910/15
1130/14
3180/46
6010/42
460/2
520/10
1230/20
4080/30
11680/40
28420/50
59420/60
113110/70
202550/80
460/3
540/19
1460/39
4830/59
14250/79
34220/99
71650/119
134880/139
70/11
1780/205
27900/1774
177790/7226
609540/17027
TO
30/8
70/10
250/24
970/44
4080/98
75020/574
388300/902
TO
-

Table 5: Results for P ON D for conformant Rovers, Logistics, BT, BTC, Cube Center, and Ring.
The data is Total Time (ms)/# Expanded Nodes, “TO” indicates a time out and “-” indicates
no attempt.

and the low branching factor in search. The LU G is able to provide good search guidance, but tends
to take a long time computing heuristics in Ring.
We are also now able to compare the choices for aggregating the distance measures from reG
laxed plans for multiple graphs. We see that taking the maximum of the relaxed plans, hM
m−RP , in
assuming positive interaction among worlds is useful in Logistics and Rovers, but loses the independence of worlds in the BT and BTC domains. However, taking the summation of the relaxed plan
79

B RYCE , K AMBHAMPATI , & S MITH

Problem
Rovers 1
2
3
4
5
6
Logistics 1
2
3
4
5
BT 2
10
20
30
40
50
60
70
80
BTC 2
10
20
30
40
50
60
70

h0
550/36
1030/262
1700/467
5230/1321
TO
530/118
TO
460/5
TO
450/6
TO
-

hcard
480/21
550/36
590/48
620/58
TO
TO
460/3
470/19
510/39
620/59
850/79
1310/99
2240/119
24230/139
45270/159
460/3
480/19
510/39
660/59
970/79
1860/99
4010/119
7580/139

hSG
RP
580/6
780/15
3930/248
6760/387
TO
740/46
TO
450/3
111260/7197
TO
470/5
271410/10842
TO
-

G
hM
m−RP
570/6
760/14
830/15
1020/20
16360/175
31870/173
580/10
1630/30
1360/20
4230/59
27370/183
460/3
970/19
9070/39
52410/59
207890/79
726490/99
TO
470/3
1150/19
11520/39
62060/59
251850/79
941220/99
TO
-

G
hM
s−RP
570/6
710/12
830/15
1040/21
11100/232
24840/159
570/10
1300/36
1250/19
3820/57
19620/178
450/3
970/19
9060/39
52210/59
206830/79
719000/99
TO
460/3
1140/19
TO
-

G
hM
RP U
580/6
730/12
910/17
1070/21
12810/209
30250/198
600/10
1360/36
1290/19
3940/57
20040/178
470/3
1020/19
9380/39
55750/59
233720/79
TO
470/3
1200/19
11610/39
64290/59
274610/79
TO
-

G
hLU
RP
580/6
730/13
810/16
910/21
7100/174
13560/174
570/10
1250/36
1210/19
4160/57
20170/178
460/3
550/19
1610/39
5970/59
17620/79
43020/99
91990/119
170510/139
309940/159
470/3
590/19
1960/39
6910/59
19830/79
49080/99
103480/119
202040/139

Table 6: Results for P ON D for conditional Rovers, Logistics, BTS, BTCS. The data is Total Time
(ms)/# Expanded Nodes, “TO” indicates a time out (20 minutes) and “-” indicates no
attempt.

G
values for different worlds, hM
s−RP is able to capture the independence in the BT domain. We notice
that the summation does not help P ON D in the BTC domain; this is because we overestimate the
heuristic value for some nodes by counting the Flush action once for each world when it in fact
G
only needs to be done once (i.e. we miss positive interaction). Finally, using the hM
RP U heuristic
we do well in every domain, aside from the cost of computing multiple graph heuristics, because
we account for both positive interaction and independence by taking the overlap of relaxed plans.
Again, with the LU G relaxed plan, analogous to the multiple graph unioned relaxed plan, P ON D
scales well because we measure overlap and lower the cost of computing the heuristic significantly.

The main change we see in using P ON D versus CAltAlt is that the direction of search is
different, so the hcard heuristic performs unlike before. In the BT and BTC domains cardinality
does not work well in progression because the size of belief states does not change as we get closer
to the goal (it is impossible to ever know which package contains the bomb). However, in regression
we start with a belief state containing all states consistent with the goal and regressing actions limits
80

P LANNING G RAPH H EURISTICS FOR B ELIEF S PACE S EARCH

our belief state to only those states that can reach the goal through those actions. Thus in regression
the size of belief states decreases, but in progression remains constant.
The performance of P ON D in the conditional domains exhibits similar trends to the conformant domains, with a few exceptions. Like the conformant domains, the M G relaxed plans tend to
outperform the SG relaxed plan, but the LU G relaxed plan does best overall. Unlike the conformant
G
domains, The hM
m−RP performs much better in BTS and BTCS over BT and BTC partly because
the conditional plans have a lower average cost. The hcard heuristic does better in BTS and BTCS
over BT and BTC because the belief states actually decrease in size when they are partitioned by
sensory actions.
6.4 Sampling Worlds
Our evaluations to this point have considered the effectiveness of different heuristics, each computed with respect to all possible worlds of a belief state. While we would like to use as many of
the possible worlds as we can, we can reduce computation cost and hopefully still get reasonable
heuristics by considering a subset of the worlds. Our scheme for considering subsets of worlds in
the heuristics is to sample a single world (SG1 ), or sample a given percentage of the worlds and
build multiple graphs, or the LU G.
MG
LU G
With these sampling approaches, we use the hSG
RP , hRP U , and hRP relaxed plans. We build
the M G and LU G for 10%, 30%, 50%, 70%, and 90% of the worlds in each belief state, sampled
randomly. In Figure 10, we show the total time taken (ms) to solve every problem in our test set
(79 problems over 10 domains). Each unsolved problem contributed 20 minutes to the total time.
For comparison we show the previously mentioned heuristics: hSG
RP computed on a unioned single
U
graph SG , denoted as “Unioned” compared to the sampled single graph SG1 denoted as “Single”,
G
LU G
and hM
RP U and hRP computed for all worlds denoted as “100%”. The total time for any heuristic
that samples worlds is averaged over ten runs.
There are two major points to see in Figure 10. First, the hSG
RP heuristic is much more effective
1
U
when computed on SG versus SG . This is because the SG1 is less optimistic. It builds a
planning graph for a real world state, as opposed to the union of literals in all possible world states,
as in SGU . Respecting state boundaries and considering only a single state is better than ignoring
state boundaries to naively consider all possible states. However, as we have seen with the M G
and LU G heuristics, respecting state boundaries and considering several states can be much better,
bringing us to the second point.
We see very different performance when using more possible worlds to build multiple graphs
compared to the LU G. We are better off using fewer worlds if we have to build multiple graphs
because they can become very costly as the number of worlds increases. In contrast, performance
improves with more possible worlds when we use the LU G. Using more possible worlds to compute
heuristics is a good idea, but it takes a more efficient substrate to exploit them.
6.5 Accuracy
The heuristics that account for overlap in the possible worlds should be more accurate than the
heuristics that make an assumption of full positive interaction or full independence. To check our
intuitions, we compare the heuristic estimates for the distance between the initial belief state and
the goal belief state for all the heuristics used in conformant problems solved by P ON D. Figure
11 shows the ratio of the heuristic estimate for h(BSI ) to the optimal serial plan length h∗ (BSI ) in
81

B RYCE , K AMBHAMPATI , & S MITH

SG
MG
LUG

16

14

12

10

8

6

4

2

0
Unioned

Single

10%

30%

50%

70%

90%

100%

Figure 10: Total Time (hours) for P ON D to solve all conformant and conditional problems when
sampling worlds to use in heuristic computation.

several problems. The points below the line (where the ratio is one) are under-estimates, and those
above are over-estimates. Some of the problem instances are not shown because no optimal plan
length is known.
G
MG
∗
We note that in all the domains the hLU
RP and hRP U heuristics are very close to h , confirming
M
G
M
G
∗
our intuitions. Interestingly, hs−RP and hm−RP are both close to h in Rovers and Logistics;
whereas the former is close in the BT and BTC problems, and the latter is close in CubeCenter
and Ring. As expected, assuming independence (using summation) tends to over-estimate, and
assuming positive interaction (using maximization) tends to under-estimate. The hSG
RP heuristic
tends to under-estimate, and in some cases (CubeCenter and Ring) gives a value of zero (because
there is an initial state that satisfies the goal). The hcard heuristic is only accurate in BT and BTC,
under-estimates in Rovers and Logistics, and over-estimates in Cube Center and Ring.

The accuracy of heuristics is in some cases disconnected from their run time performance. For
instance hcard highly overestimates in Ring and Cube Center, but does well because the domains
G
MG
exhibit special structure and the heuristic is fast to compute. On the other hand, hLU
RP and hRP U
82

P LANNING G RAPH H EURISTICS FOR B ELIEF S PACE S EARCH

10000
1000
100
10
1
0.1
0.01
0.001

3
3
3
×3
×
×3
× 33
3
×3
3
3
×
×
×3
3
×
×
3

×
 
×
 



 


+
××
×

×
××××××××
33333333
2
2

2

22
2
2++
   
2

2
2


××



+
 
×××××
33
22
222 ++
33333
+
33
+
3
33
2
33 + 3 3
+
2
+
+
2
2+
2+
+
2+
2+
2+
2+
2+
2+
2
2+
2+
2+
2
hcard 3
hSG
RP +
M
G
hm−RP
2
M
G
hs−RP ×
G
hM
RP U 
G 
hLU
RP

Rv1 Rv4 L1

L5 B10

B80 BC10
BC70 C3
Problem

C13 R2

R10

Figure 11: Ratio of heuristic estimates for distance between BSI and BSG to optimal plan length.
Rv = Rovers, L = Logistics, B = BT, BC = BTC, C = Cube Center, R = Ring.

are very accurate in many domains, but suffer in Ring and Cube Center because they can be costly
to compute.
6.6 Inter-Heuristic Conclusions
Our findings fall into two main categories: one, what are effective estimates for belief state distances
in terms of state to state distances, and two, how we can exploit planning graphs to support the
computation of these distance measures.
In comparing ways to aggregate state distance measures to compute belief state distances, we
found that measuring no interaction as in single graph heuristics tends to poorly guide planners,
measuring independence and positive interaction of worlds works well in specific domains, and
measuring overlap (i.e. a combination of positive interaction and independence) tends to work well
in a large variety of instances. By studying the accuracy of our heuristics we found that in some
cases the most accurate were not the most effective. We did however find that the most accurate did
best over the most cases.
Comparing graph structures that provide the basis for belief state distance measures, we found
that the heuristics extracted from the single graph fail to systematically account for the independence or positive interaction among different possible worlds. Despite this lack in the distance
measure, single graphs can still identify some structure in domains like Rovers and Logistics. To
more accurately reflect belief state distances, multiple graphs reason about reachability for each
world independently. This accuracy comes at the cost of computing a lot of redundant M G structure and is limiting in instances with large belief states. We can reduce the cost of the M G structure
83

B RYCE , K AMBHAMPATI , & S MITH

Planner
CAltAlt
P ON D
MBP
KACMBP
CGP
SGP
GPT
YKA
CFF

Search Space
Belief Space
Belief Space
Belief Space
Belief Space
Planning Graph
Planning Graph
Belief Space
Belief Space
Belief Space

Search Direction
Backward
Forward
Forward/Backward
Forward
Backward
Backward
Forward
Backward
Forward

Conditional
√
√
√
√
√

Heuristic
Planning Graph
Planning Graph
Cardinality
Cardinality
Planning Graph
Planning Graph
State Space Plans
Cardinality
Planning Graph

Implementation
C
C
C
C
Lisp
Lisp
C
C
C

Table 7: Comparison of planner features.
by sampling worlds used in its construction. However planners are able to exhibit better scalability
by considering more worlds through optimizing the representation of the redundant structure as in
the LU G. The improvement in scalability is attributed to lowering the cost of heuristic computation, but retaining measures of multiple state distances. The LU G makes a trade-off of using an
exponential time algorithm for evaluation of labels instead of building an exponential number of
planning graphs. This trade-off is justified by our experiments.

7. Empirical Evaluation: Inter-Planner Comparison
We first compare CAltAlt and P ON D with several planners on our conformant domains, then
compare P ON D with the conditional planners on the conditional domains. Our purpose in this
section is to identify the advantages of our techniques over the state of the art planners. We end the
section with a discussion of general conclusions drawn from the evaluation.
7.1 Conformant Planning
Although this work is aimed at giving a general comparison of heuristics for belief space planning,
we also present a comparison of the best heuristics within CAltAlt and P ON D to some of the
other leading approaches to conformant planning. Table 7 lists several features of the evaluated
planners, such as their search space, their search direction, whether they are conditional, the type of
heuristics, and the implementation language. Note, since each approach uses a different planning
representation (BDDs, GraphPlan, etc.), not all of which even use heuristics, it is hard to get a
standardized comparison of heuristic effectiveness. Furthermore, not all of the planners use PDDLlike input syntax; MBP, and KACMBP use AR encodings which may give them an advantage in
reducing the number of literals and actions. We gave the MBP planners the same grounded and
filtered action descriptions that we used in CAltAlt and P ON D. We also tried, but do not report
results, giving the MBP planners the full set of ground actions without filtering irrelevant actions. It
appears that the MBP planners do not use any sort of action pre-processing because performance was
much worse with the full grounded set of actions. Nevertheless, Table 8 compares MBP, KACMBP,
LU G(DyX−SX)
G
GPT, CGP, YKA, and CFF with hRP
in CAltAlt and hLU
RP in P ON D with respect to
run time and plan length.
MBP: The MBP planner uses a cardinality heuristic that in many cases overestimates plan distances
(as per our implementation with hcard ). MBP uses regression search for conformant plans, but
progression search for conditional plans. It is interesting to note that in the more difficult problem
84

P LANNING G RAPH H EURISTICS FOR B ELIEF S PACE S EARCH

Problem
Rovers 1
2
3
4
5
6
Logistics 1
2
3
4
5
BT 2
10
20
30
40
50
60
70
80
BTC 2
10
20
30
40
50
60
70
CubeCenter 3
5
7
9
11
Ring 2
3
4
5
6
7
8

CAltAlt
LU G(DyX−SX)
hRP U
16070/5
10457/8
10828/10
15279/13
64870/29
221051/25
907/9
2862/15
10810/15
24862/19
54726/34
16/2
71/10
552/20
2415/30
7543/40
17573/50
35983/60
67690/70
157655/80
16/3
89/19
651/39
2721/59
8009/79
19074/99
38393/119
65448/139
TO
TO
-

POND
G
hLU
RP
590/5
680/9
850/11
1130/16
2050/25
8370/25
560/9
910/15
1130/14
3180/22
6010/29
460/2
520/10
1230/20
4080/30
11680/40
28420/50
59420/60
113110/70
202550/80
460/3
540/19
1460/39
4820/59
14250/79
34220/99
71650/119
134880/139
70/9
1780/18
27900/29
177790/36
609540/47
30/6
70/8
250/13
970/17
4080/22
75020/30
388300/29

MBP

KACMBP

GPT

CGP

YKA

CFF

66/5
141/8
484/10
3252/13
OoM
727/32
37/9
486/24
408/14
2881/27
OoM
6/2
119/10
80/20
170/30
160/40
300/50
480/60
730/70
1080/80
8/3
504/19
98/39
268/59
615/79
1287/99
2223/119
3625/139
10/9
16/18
35/27
64/36
130/45
0/5
0/8
10/11
20/14
30/17
80/20
160/23

9293/5
9289/15
9293/16
9371/18
39773/40
TO
127/12
451/19
1578/18
8865/22
226986/42
10/2
16/10
84/20
244/30
533/40
1090/50
2123/60
3529/70
1090/80
18/3
45/19
211/39
635/59
1498/79
10821/99
5506/119
2640/139
20/9
20/18
70/27
120/36
230/45
0/5
40/8
30/11
50/14
120/18
230/21
600/24

3139/5
4365/8
5842/10
7393/13
399525/20
TO
916/9
1297/15
1711/11
9828/18
543865/28
487/2
627/10
472174/20
TO
465/3
715/19
40/9
363/18
4782/27
42258/36
26549/45
31/5
35/8
60/11
635/14
51678/17
TO
-

70/5
180/8
460/10
1860/13
OoM
60/6
290/6
400/8
1170/8
TO
20/1
520/1
3200/1
10330/1
24630/1
49329/1
87970/1
145270/1
TO
0/3
39370/19
28990/3
TO
TO
-

1220/7
2050/10
1740/12
2010/16
7490/27
24370/26
250/13
670/19
20280/21
17530/27
141910/40
0/2
0/10
20/20
80/30
160/40
250/50
420/60
620/70
3310/80
10/3
30/19
240/39
1210/59
3410/79
8060/50
15370/119
27400/139
0/9
0/19
20/34
80/69
190/68
0/5
0/8
20/11
80/14
110/17
300/20
480/23

70/5
30/8
10/10
10/13
18/22
21/23
10/9
12/15
14/12
12/18
25/28
0/2
30/10
4400/20
4500/30
26120/40
84730/50
233410/60
522120/70
979400/80
10/3
57/19
2039/39
23629/59
116156/79
334879/99
TO
20/15
28540/45
TO
360/12
TO
-

LU G(DyX−SX)

G
Table 8: Results for CAltAlt using hRP
, P ON D using hLU
RP , MBP, KACMBP, GPT,
CGP, YKA, and CFF for conformant Rovers, Logistics, BT, BTC, Cube Center, and Ring.
The data is Total Time / # Plan Steps, “TO” indicates a time out (20 minutes), “OoM”
indicates out of memory (1GB), and “-” indicates no attempt.

instances in the Rovers and Logistics domains MBP and KACMBP tend to generate much longer
plans than the other planners. MBP does outperform P ON D in some cases but does not find
solutions in certain instances (like Rovers 5), most likely because of its heuristic. We note that
KACMBP and MBP are quite fast on the Cube Center and Ring domains, but have more trouble on
domains like Rovers and Logistics. This illustrates how a heuristic modeling knowledge as opposed
to reachability can do well in domains where the challenge is uncertainty not reachability.
85

B RYCE , K AMBHAMPATI , & S MITH

Optimal Planners: The optimal approaches (CGP and GPT) tend not to scale as well, despite their
good solutions. CGP has trouble constructing its planning graphs as the parallel conformant plan
depth increases. CGP spends quite a bit of time computing mutexes, which increases the planning
cost as plan lengths increase. CGP does much better on shallow and parallel domains like BT, where
it can find one step plans that dunk every package in parallel.
GPT performs progression search that is guided by a heuristic that measures the cost of fully
observable plans in state space. GPT finds optimal serial plans but is not as effective when the size
of the search space increases. GPT fails to scale with the search space because it becomes difficult
to even compute its heuristic (due to a larger state space as well).
YKA: YKA, like CAltAlt is a regression planner, but the search engine is very different and YKA
uses a cardinality heuristic. YKA performs well on all the domains because of its search engine
based on BDDs. We notice a difference in progression and regression by comparing P ON D to
YKA, similar to trends found in the comparison between P ON D and CAltAlt. Additionally, it
seems YKA has a stronger regression search engine than CAltAlt. P ON D is able to do better than
YKA in the Rovers and Logistics domains, but it is unclear whether that it is because of the search
direction or heuristics.
CFF: Conformant FF, a progression planner using a relaxed plan similar to the LU G relaxed plan,
does very well in the Rovers and Logistics domains because it uses the highly optimized FF search
engine as well as a cheap to compute relaxed plan heuristic. However, CFF does not do as well in
the BT, BTC, Cube Center, and Ring problems because there are not as many literals that will be
entailed by a belief state. CFF relies on implicitly representing belief states in terms of the literals
that are entailed by the belief state, the initial belief state, and the action history. When there are
very few literals that can be entailed by the belief state, reasoning about the belief state requires
inference about the action history. Another possible reason CFF suffers is our encodings. The
Cube Center and Ring domains are naturally expressed with multi-valued state features, and in our
transformation to binary state features we describe the values that must hold but also the values that
must not hold. This is difficult for CFF because the conditional effect antecedents contain several
literals and its heuristic is restricted to considering only one such literal. It may be that CFF is
choosing the wrong literal or simply not enough literals to get effective heuristics. However in BT
and BTC where we used only one literal in effect antecedents CFF still performs poorly.
7.2 Conditional Planning
Table 9 shows the results for testing the conditional versions of the domains on P ON D, MBP, GPT,
SGP, and YKA.
MBP: The P ON D planner is very similar to MBP in that it uses progression search. P ON D
uses an AO* search, whereas the MBP binary we used uses a depth first And-Or search. The depth
first search used by MBP contributes to highly sub-optimal maximum length branches (as much
as an order of magnitude longer than P ON D). For instance, the plans generated by MBP for
the Rovers domain have the rover navigating back and forth between locations several times before
doing anything useful; this is not a situation beneficial for actual mission use. MBP tends to not scale
as well as P ON D in all of the domains we tested. A possible reason for the performance of MBP
is that the Logistics and Rovers domains have sensory actions with execution preconditions, which
prevent branching early and finding deterministic plan segments for each branch. We experimented
86

P LANNING G RAPH H EURISTICS FOR B ELIEF S PACE S EARCH

Problem
Rovers 1
2
3
4
5
6
Logistics 1
2
3
4
5
BT 2
10
20
30
40
50
60
70
80
BTC 2
10
20
30
40
50
60
70

POND
G
hLU
RP
580/5
730/8
810/8
910/10
7100/19
13560/22
570/7
1250/12
1210/9
4160/15
20170/22
460/2
550/10
1610/20
5970/30
17620/40
43020/50
91990/60
170510/70
309940/80
470/2
590/10
1960/20
6910/30
19830/40
49080/50
103480/60
202040/70

MBP

GPT

SGP

YKA

3312/11
4713/75
5500/119
5674/146
16301/76
OoM
41/16
22660/177
2120/45
OoM
0/2
240/10
OoM
20/2
280/10
OoM
-

3148/5
5334/7
7434/8
11430/10
TO
1023/7
5348/12
2010/8
TO
510/2
155314/10
OoM
529/2
213277/10
TO
-

70/5
760/7
TO
5490/6
TO
0/1
70/1
950/1
4470/1
13420/1
32160/1
90407/1
120010/1
TO
10/2
TO
-

3210/5
6400/7
7490/8
11210/10
TO
1390/8
TO
TO
0/2
20/10
60/20
200/30
400/40
810/50
1350/60
2210/70
3290/80
0/4
210/12
2540/22
13880/32
46160/42
109620/52
221460/62
41374/72

G
Table 9: Results for P ON D using hLU
RP , MBP, GPT, SGP, and YKA for conditional Rovers, Logistics, BT, and BTC. The data is Total Time / # Maximum possible steps in a execution,
“TO” indicates a time out (20 minutes), “OoM” indicates out of memory (1GB), and “-”
indicates no attempt.

with MBP using sensory actions without execution preconditions and it was able to scale somewhat
better, but plan quality was much longer.
Optimal Planners: GPT and SGP generate better solutions but very slowly. GPT does better on
the Rovers and Logistics problems because they exhibit some positive interaction in the plans, but
SGP does well on BT because its planning graph search is well suited for shallow, yet broad (highly
parallel) problems.
YKA: We see that YKA fares similar to GPT in Rovers and Logistics, but has trouble scaling for
other reasons. We think that YKA may be having trouble in regression because of sensory actions
since it was able to scale reasonably well in the conformant version of the domains. Despite this,
YKA proves to do very well in the BT and BTC problems.
87

B RYCE , K AMBHAMPATI , & S MITH

7.3 Empirical Evaluation Conclusions
In our internal comparisons of heuristics within CAltAlt and P ON D, as well as external comparisons with several state of the art conformant and conditional planners we have learned many
interesting lessons about heuristics for planning in belief space.
• Distance based heuristics for belief space search help control conformant and conditional plan
length because, as opposed to cardinality, the heuristics model desirable plan quality metrics.
• Planning graph heuristics for belief space search scale better than planning graph search and
admissible heuristic search techniques.
• Of the planning graph heuristics presented, relaxed plans that take into account the overlap
of individual plans between states of the source and destination belief states are the most
accurate and tend to perform well across many domains.
• The LUG is an effective planning graph for both regression and progression search heuristics.
• In regression search, planning graphs that maintain only same-world mutexes provide the best
trade-off between graph construction cost and heuristic informedness.
• Sampling possible worlds to construct planning graphs does reduce computational cost, but
considering more worlds by exploiting planning graph structure common to possible worlds
(as in the LU G), can be more efficient and informed.
• The LUG heuristics help our conditional planner, P ON D, to scale up in conditional domains,
despite the fact that the heuristic computation does not model observation actions.

8. Related Work & Discussion
We discuss connections with several related works that involve heuristics and/or conditional planning in the first half of this section. In the second part of the section we discuss how we can extend
our work to directly handle non-deterministic outcomes of actions in heuristic computation.
8.1 Related Work
Much interest in conformant and conditional planning can be traced to CGP (Smith & Weld, 1998), a
conformant version of GraphPlan (Blum & Furst, 1995), and SGP (Weld et al., 1998), the analogous
conditional version of GraphPlan. Here the graph search is conducted on several planning graphs,
each constructed from one of the possible initial states. More recent work on C-plan (Castellini
et al., 2001) and Frag-Plan (Kurien et al., 2002) generalize the CGP approach by ordering the
searches in the different worlds such that the plan for the hardest to satisfy world is found first,
and is then extended to the other worlds. Although CAltAlt and P ON D utilize planning graphs
similar to CGP and Frag-plan it only uses them to compute reachability estimates. The search itself
is conducted in the space of belief states.
Another strand of work models conformant and conditional planning as a search in the space
of belief states. This started with Genesereth and Nourbakhsh (1993), who concentrated on formulating a set of admissible pruning conditions for controlling search. There were no heuristics for
choosing among unpruned nodes. GPT (Bonet & Geffner, 2000) extended this idea to consider a
88

P LANNING G RAPH H EURISTICS FOR B ELIEF S PACE S EARCH

simple form of reachability heuristic. Specifically, in computing the estimated cost of a belief state,
GPT assumes that the initial state is fully observable. The cost estimate itself is done in terms of
reachability (with dynamic programming rather than planning graphs). GPT’s reachability heuristic
G
is similar to our hM
m−RP heuristic because they both estimate the cost of the farthest (maximum distance) state by looking at a deterministic relaxation of the problem. In comparison to GPT, CAltAlt
and P ON D can be seen as using heuristics that do a better job of considering the cost of the belief
state across the various possible worlds.
Another family of planners that search in belief states is the MBP-family of planners—MBP
(Bertoli et al., 2001b), and KACMBP (Bertoli & Cimatti, 2002). In contrast to CAltAlt but similar to P ON D, the MBP-family of planners all represent belief states in terms of binary decision
diagrams. Action application is modeled as modifications to the BDDs. MBP supports both progression and regression in the space of belief states, while KACMBP is a pure progression planner.
Before computing heuristic estimates, KACMBP pro-actively reduces the uncertainty in the belief
state by preferring uncertainty reducing actions. The motivation for this approach is that applying
cardinality heuristics to belief states containing multiple states may not give accurate enough direction to the search. While reducing the uncertainty seems to be an effective idea, we note that (a)
not all domains may contain actions that reduce belief state uncertainty and (b) the need for uncertainty reduction may be reduced when we have heuristics that effectively reason about the multiple
worlds (viz., our multiple planning graph heuristics). Nevertheless, it could be very fruitful to integrate knowledge goal ideas of KACMBP and the reachability heuristics of CAltAlt and P ON D to
handle domains that contain both high uncertainty and costly goals.
In contrast to these domain-independent approaches that only require models of the domain
physics, PKSPlan (Petrick & Bacchus, 2002) is a forward-chaining knowledge-based planner that
requires richer domain knowledge. The planner makes use of several knowledge bases, as opposed
to a single knowledge base taking the form of a belief state. The knowledge bases separate binary
and multi-valued variables, and planning and execution time knowledge.
YKA (Rintanen, 2003b) is a regression conditional planner using BDDs that uses a cardinality heuristic. Recently Rintanen has also developed related reachability heuristics that consider
distances for groups of states, which do not rely on planning graphs (Rintanen, 2004).
More recently, there has been closely related work on heuristics for constructing conformant
plans within the CFF planner (Hoffmann & Brafman, 2004). The planner represents belief states
implicitly through a set of known facts, the action history (leading to the belief state), and the initial
belief state. CFF builds a planning graph forward from the set of known literals to the goal literals
and backwards to the initial belief state. In the planning graph, conditional effects are restricted
to single literals in their antecedent to enable tractable 2-cnf reasoning. From this planning graph,
CFF extracts a relaxed plan that represents supporting the goal belief state from all states in the
initial belief state. The biggest differences between the LU G and the CFF technique are that the
LU G reasons only forward from the source belief state (assuming an explicit, albeit symbolic, belief
state), and the LU G does not restrict the number of literals in antecedents. As a result, the LU G
does not lose the causal information nor perform backward reasoning to the initial belief state.
Our handling of uncertainty through labels and label propagation is reminiscent of and related to
de Kleer’s assumption based truth maintenance system (ATMS) (de Kleer, 1986). Where an ATMS
uses labels to identify the assumptions (contexts) where a particular statement holds, a traditional
truth maintenance system requires extensive backtracking and consistency enforcement to identify
other contexts. Similarly, where we can reason about multiple possible worlds (contexts) with the
89

B RYCE , K AMBHAMPATI , & S MITH

LUG simultaneously, the MG approach requires, not backtracking, but reproduction of planning
graphs for other possible worlds.
Finally, CAltAlt and P ON D are also related to, and an adaptation of the work on reachability
heuristics for classical planning, including AltAlt (Nguyen et al., 2002), FF (Hoffmann & Nebel,
2001) and HSP-r (Bonet & Geffner, 1999). CAltAlt is the conformant extension to AltAlt that uses
regression search (similar to HSP-r) guided by planning graph heuristics. P ON D is similar to FF
in that it uses progression search with planning graph heuristics.
8.2 Extension to Non-Deterministic Actions
While the scope of our presentation and evaluation is restricted to planning with initial state uncertainty and deterministic actions, some of the planning graph techniques can be extended to include
non-deterministic actions of the type described by Rintanen (2003a). Non-deterministic actions
have effects that are described in terms of a set of outcomes. For simplicity, we consider Rintanen’s
conditionality normal form, where actions have a set of conditional effects (as before) and each
consequent is a mutually-exclusive set of conjunctions (outcomes) – one outcome of the effect will
result randomly. We outline the generalization of our single, multiple, and labelled planning graphs
to reason with non-deterministic actions.
Single Planning Graphs: Single planning graphs, that are built from approximate belief states or
a sampled state, do not lend themselves to a straight-forward extension. A single graph ignores
uncertainty in a belief state by unioning its literals or sampling a state to form the initial planning
graph layer. Continuing with the single graph assumptions about uncertainty, it makes sense to treat
non-deterministic actions as deterministic. Similar to how we approximate a belief state as a set of
literals to form the initial literal layer or sample a state, we can assume that a non-deterministic effect
adds all literals appearing in the effect or samples an outcome as if the action were deterministic
(i.e. gives a set of literals). Single graph relaxed plan heuristics thus remain unchanged.
Multiple Planning Graphs: Multiple planning graphs are very much like Conformant GraphPlan
(Smith & Weld, 1998). We can generalize splitting the non-determinism in the current belief state
into multiple initial literal layers to splitting the outcomes of non-deterministic effects into multiple
literal layers. The idea is to root a set of new planning graphs at each level, where each has an
initial literal layer containing literals supported by an interpretation of the previous effect layer. By
interpretations of the effect layer we mean every possible set of joint effect outcomes. A set of effect
outcomes is possible if no two outcomes are outcomes of the same effect. Relaxed plan extraction
still involves finding a relaxed plan in each planning graph. However, since each planning graph is
split many times (in a tree-like structure) a relaxed plan is extracted from each “path of the tree”.
We note that this technique is not likely to scale because of the exponential growth in redundant
planning graph structure over time. Further, in our experiments CGP has enough trouble with initial
state uncertainty. We expect that we should be able to do much better with the LU G.
Labelled Uncertainty Graph: With multiple planning graphs we are forced to capture non–
determinism through splitting the planning graphs not only in the initial literal layer, but also each
literal layer that follows at least one non-deterministic effect. We saw in the LU G that labels can
capture the non-determinism that drove us to split the initial literal layer in multiple graphs. As
such, these labels took on a syntactic form that describes subsets of the states in our source belief
state. In order to generalize labels to capture non-determinism resulting from uncertain effects, we
90

P LANNING G RAPH H EURISTICS FOR B ELIEF S PACE S EARCH

need to extend their syntactic form. Our objective is to have a label represent which sources of
uncertainty (arising from the source belief state or effects) causally support the labelled item. We
also introduce a graph layer Ok to represent outcomes and how they connect effects and literals.
It might seem natural to describe the labels for outcomes in terms of their affected literals, but
this can lead to trouble. The problem is that the literals in effect outcomes are describing states at a
different time than the literals in the projected belief state. Further, an outcome that appears in two
levels of the graph is describing a random event at different times. Using state literals to describe
all labels will lead to confusion as to which random events (state uncertainty and effect outcomes at
distinct steps) causally support a labelled item. A pathological example is when we have an effect
whose set of outcomes matches one-to-one with the states in the source belief state. In such a case,
by using labels defined in terms of state literals we cannot distinguish which random event (the state
uncertainty or the effect uncertainty) is described by the label.
We have two choices for describing effect outcomes in labels. In both choices we introduce a
new set of label variables to describe how a literal layer is split. These new variables will be used
to describe effect outcomes in labels and will not be confused with variables describing initial state
uncertainty. In the first case, these variables will have a one-to-one matching with our original set
of literals, but can be thought of as time-stamped literals. The number of variables we add to the
label function is on the order of 2F per level (the number of fluent literals – assuming boolean
fluents). The second option is to describe outcomes in labels with a new set of fluents, where each
interpretation over the fluents is matched to a particular outcome. In this case, we add on the order
of log |Ok | variables, where Ok is the k th outcome layer. It would actually be lower if many of
the outcomes were from deterministic effects because there is no need to describe them in labels.
The former approach is likely to introduce fewer variables when there are a lot of non-deterministic
effects and they affect quite a few of the same literals. The latter will introduce fewer variables
when there are relatively few non-deterministic effects whose outcomes are fairly independent.
With the generalized labelling, we can still say that an item is reachable from the source belief
state when its label is entailed by the source belief state. This is because even though we are adding
variables to labels, we are implicitly adding the fluents to the source belief state. For example, say
we add a fluent v to describe two outcomes of an effect. One outcome is labelled v, the other ¬v.
We can express the source belief state BSP that is projected by the LU G with the new fluent as
BSP ∧ (v ∨ ¬v) = BSP . An item labelled as BSP ∧ v will not be entailed by the projected belief
state (i.e. is unreachable) because only one outcome causally supports it. If both outcomes support
the item, then it will be reachable.
Given our notion of reachability, we can determine the level from which to extract a relaxed
plan. The relaxed plan procedure does not change much in terms of its semantics other than having
the extra graph layer for outcomes. We still have to ensure that literals are causally supported in all
worlds they are labelled with in a relaxed plan, whether or not the worlds are from the initial state
uncertainty or supporting non-deterministic effects.

9. Conclusion
With the intent of establishing a basis for belief state distance estimates, we have:
• Discussed how heuristic measures can aggregate state distance measures to capture positive
interaction, negative interaction, independence, and overlap.
91

B RYCE , K AMBHAMPATI , & S MITH

• Shown how to compute such heuristic measures on planning graphs and provided empirical
comparisons of these measures.
• Found that exploiting planning graph structure to reduce the cost of considering more possible
states of a belief state is preferable to sampling a subset of the states for the heuristics.
• Shown that a labelled uncertainty graph can capture the same support information as multiple
graphs, and reduces the cost of heuristic computation.
• Shown that the labelled uncertainty graph is very useful for conformant planning and, without
considering observational actions and knowledge, can perform well in conditional planning.
Our intent in this work was to provide a formal basis for measuring the distance between belief
states in terms of underlying state distances. We investigated several ways to aggregate the state
distances to reflect various assumptions about the interaction of state to state trajectories. The best
of these measures turned out to measure both positive interaction and independence, what we call
overlap. We saw that planners using this notion of overlap tend to do well across a large variety of
domains and tend to have more accurate heuristics.
We’ve also shown that planning with a Labelled Uncertainty planning Graph LU G, a condensed
version of the multiple graphs is useful for encoding conformant reachability information. Our main
innovation is the idea of “labels” – labels are attached to all literals, actions, effect relations, and
mutexes to indicate the set of worlds in which those respective elements hold. Our experimental
results show that the LU G can outperform the multiple graph approach. In comparison to other
approaches, we’ve also been able to demonstrate the utility of structured reachability heuristics in
controlling plan length and boosting scalability for both conformant and conditional planning.
We intend to investigate three additions to this work. The first, is to incorporate sensing and
knowledge into the heuristics. We already have some promising results without using these features
in the planning graphs, but hope that they will help the approaches scale even better on conditional
problems. The second addition will be to consider heuristics for stochastic planning problems. The
major challenges here are to associate probabilities with labels to indicate the likelihood of each
possible world and integrate reasoning about probabilistic action effects.
Lastly, we have recently extended the LU G within the framework of state agnostic planning
graphs (Cushing & Bryce, 2005), and hope to improve the technique. A state agnostic planning
graph is essentially a multiple source planning graph, where by analogy a conventional planning
graph has a single source. Planning graphs are already multiple destination, so in our generalization
the state agnostic planning graph allows us to compute the distance measure between any pair of
states or belief states. The LU G seeks to avoid redundancy across the multiple planning graphs
built for states in the same belief state. We extended this notion to avoid redundancy in planning
graphs built for every belief state. We have shown that the state agnostic LU G (SLU G) which is
built once per search episode (as opposed to a LU G at each node) can reduce heuristic computation
cost without sacrificing informedness.
Acknowledgments We would like to thank Minh B. Do, Romeo Sanchez, Terry Zimmermam,
Satish Kumar Thittamaranahalli, and Will Cushing for helpful discussions and feedback, Jussi Rintanen for help with the YKA planner, and Piergiorgio Bertoli for help with the MBP planner. This
work was supported in part by NASA grants NCC2-1225 and NAG2-1461, the NSF grant IIS0308139, the 2003 NASA RIACS SSRP, the ARCS Foundation, and an IBM faculty award.
92

P LANNING G RAPH H EURISTICS FOR B ELIEF S PACE S EARCH

Appendix A. Additional Heuristics
For completeness, we present some additional heuristics adapted from classical planning to reason
about belief state distances in each type of planning graph. Many of these heuristics appeared in our
previous work (Bryce & Kambhampati, 2004). We show how to compute the max, sum, and level
heuristics on the single graph SG, multiple graphs M G, and the labelled uncertainty graph LU G.
While these heuristics tend to be less effective than the relaxed plan heuristics, we provide them as
reference. As with Section 4, we describe the heuristics in terms of regression search.
A.1 Single Planning Graph Heuristics (SG)
Like, the relaxed plan for the single unmodified planning graph, we cannot aggregate state distances
because all notion of separate states is lost in forming the initial literal layer, thus we only compute
heuristics that do not aggregate state distances.
No State Aggregation:
• Max In classical planning, the maximum cost literal is used to get a max heuristic, but we use
formulas to describe our belief states, so we take the maximum cost clause as the cost of the
belief state to find the max heuristic hSG
max . The maximum cost clause of the belief state, with
respect to a single planning graph, is:
hSG
max (BSi ) =

max

C∈κ(BSi )

cost(C)

where the cost of a clause is:
cost(C) = min min k
l∈C k:l∈Lk

Here we find the cheapest literal as the cost of each clause to find the maximum cost clause.
This is an underestimate of the closest state to our current belief state.
• Sum Like the classical planning sum heuristic, we can take the sum hSG
sum of the costs of the
clauses in our belief state to estimate our belief state distance

cost(C)
hSG
sum (BSi ) =
C∈κ(BSi )

This heuristic takes the summation of costs of literals in the closest estimated state in the
belief state, and is inadmissible because there may be a single action that will support every
clause, and we could count it once for each clause.
• Level When we have mutexes on the planning graph, we can compute a level heuristic hSG
level
(without mutexes the level heuristic is equivalent to the max heuristic). The level heuristic
maintains the admissibility of the max heuristic but improves the lower bound by considering
what level of the planning graph all literals in a constituent are non-pairwise mutex. The
ˆ
level heuristic is computed by taking the minimum among the Ŝ ∈ ξ(BS
i ), of the first level
(lev(S)) in the planning graph where literals of Ŝ are present with none of them marked
pairwise mutex. Formally:
hSG
level (BSi ) =

93

min

Ŝ∈ξ̂(BSi )

lev(Ŝ)

B RYCE , K AMBHAMPATI , & S MITH

A.2 Multiple Planning Graph Heuristics (M G)
Similar to the various relaxed plan heuristics for the multiple graphs, we can compute a max, sum,
or level heuristic on each of the multiple planning graphs and aggregate them with a maximum
or summation to respectively measure positive interaction or independence. The reason we cannot
aggregate the individual graph heuristics to measure overlap is that they are numbers, not sets of
actions. Measuring overlap involves taking the union of heuristics from each graph and the union
of numbers is not meaningful like the union of action sets from relaxed plans. Like before, there is
no reason to use multiple graphs if there is no state distance aggregation.
Positive Interaction Aggregation:
G
• Max The max heuristic hM
m−max is computed with multiple planning graphs to measure posM
G
itive interaction in the hm−max heuristic. This heuristic computes the maximum cost clause
in κ(BSi ) for each graph γ ∈ Γ, similar to how hSG
m−max (BSi ) is computed, and takes the
maximum. Formally:
G
γ
hM
m−max (BSi ) = max (hmax (BSi ))
γ∈Γ

G
The hM
m−max heuristic considers the minimum cost, relevant literals of a belief state (those that
are reachable given a possible world for each graph γ) to get state measures. The maximum
is taken because the estimate accounts for the worst (i.e., the plan needed in the most difficult
world to achieve the subgoals).

• Sum The sum heuristic that measures positive interaction for multiple planning graphs is
G
hM
m−sum . It computes the summation of the cost of the clauses in κ(BSi ) for each graph
γ ∈ Γ and takes the maximum. Formally:
G
γ
hM
m−sum (BSi ) = max (hsum (BSi ))
γ∈Γ

The heuristic considers the minimum cost, relevant literals of a belief state (those that are
reachable given the possible worlds represented for each graph γ) to get state measures. As
G
with hM
m−max , the maximum is taken to estimate for the most costly world.
γ
G
MG
MG
• Level Similar to hM
m−max and hm−sum , the hm−level heuristic is found by first finding hlevel
for each graph γ ∈ Γ to get a state distance measure, and then taking the maximum across
ˆ
the graphs. hγlevel (BSi ) is computed by taking the minimum among the Ŝ ∈ ξ(BS
i ), of the
γ
first level lev (Ŝ) in the planning graph γ where literals of Ŝ are present with none of them
marked mutex. Formally:

hγlevel (BSi ) =

min

Ŝ∈ξ̂(BSi )

lev γ (Ŝ)

and
γ
G
hM
m−level (BSi ) = max(hlevel (BSi ))
γ∈Γ

Note that this heuristic is admissible. By the same reasoning as in classical planning, the first
level where all the subgoals are present and non-mutex is an underestimate of the true cost of
a state. This holds for each of the graphs. Taking the maximum accounts for the most difficult
94

P LANNING G RAPH H EURISTICS FOR B ELIEF S PACE S EARCH

world in which to achieve a constituent of BSi and is thus a provable underestimate of h∗ .
G
GPT’s max heuristic (Bonet & Geffner, 2000) is similar to hM
m−level , but is computed with
dynamic programming in state space rather than planning graphs.
Independence Aggregation: All heuristics mentioned for Positive Interaction Aggregation can
be augmented to take the summation of costs found on the individual planning graphs rather than
G
MG
MG
the maximum. We denote them as: hM
s−max , hs−sum , and hs−level . None of these heuristics are
admissible because the same action may be used in all worlds, but we count its cost for every world
by using summation.
A.3 Labelled Uncertainty Graph (LU G)
The max, sum, and level heuristics for the LU G are similar to the analogous multiple graph heuristics. The main difference with these heuristics for the LU G is that it is much easier to compute
positive interaction measures than independence measures. The reason positive interaction is easier
to compute is that we find the cost of a clause for all states in our belief state at once, rather than on
each of multiple planning graphs. Like before, we do not consider heuristics that do not aggregate
state distances.
Positive Interaction Aggregation:
G
• Max The max heuristic hLU
m−max for the LU G finds the maximum clause cost across clauses
of the current belief state BSi . The cost of a clause is the first level it becomes reachable.
Formally:


G
hLU
m−max (BSi )

=

max

C∈κ(BSi )


min

k:BSP |=∗k (C)

k

G
• Sum The sum heuristic hLU
m−sum for the LU G sums the individual levels where each clause
in κ(BSi ) is first reachable. Formally:

 
G
min
hLU
(BS
)
=
k
i
m−sum
∗
C∈κ(BSi )

k:BSP |=k (C)

G
• Level The level heuristic hLU
m−level is the index of the first level where BSi is reachable.
Formally:
G
hLU
m−level (BSi ) =

min

k:BSP |=∗k (BSi )

i

Independence Aggregation: All heuristics mentioned for positive interaction aggregation can be
augmented to take the summation of costs for each state in our belief state. This may be inefficient
due to the fact that we lose the benefit of having a LU G by evaluating a heuristic for each state of
our BSP , rather than all states at once as in the positive interaction aggregation. In such a case we
are doing work similar to the multiple graph heuristic extraction, aside from the improved graph
construction time. The positive interaction aggregation is able to implicitly calculate the maximum
over all worlds for most of the heuristics, whereas for the sum heuristic we need to explicitly find a
G
LU G
LU G
cost for each world. We denote the sum heuristics as: hLU
s−max , hs−sum , and hs−level .
95

B RYCE , K AMBHAMPATI , & S MITH

Appendix B. Cross-World Mutexes
Mutexes can develop not only in the same possible world but also between two possible worlds,
as described by Smith and Weld (1998). Cross-world mutexes are useful to capture negative interactions in belief state distance measures (mentioned in Section 3). The representation of crossworld mutexes requires another generalization for the labelling of mutexes. Same world mutexes
require keeping only one label for the mutex to signify all same possible worlds for which the mutex holds. The extended representation keeps a pair of labels, one for each element in the mutex;
if x in possible world S is mutex with x in possible world S  , we denote the mutex as the pair
(ˆk (x) = S, ˆk (x ) = S  ).
We can compute cross-world mutexes between several worlds of elements x and x . For example, if k (x) = S1 ∨S2 ∨S3 and k (x ) = S2 ∨S3 , then to check for all cross-world mutexes we need
to consider mutexes for the world pairs (S1 , S2 ), (S1 , S3 ), (S2 , S2 ), (S2 , S3 ), (S3 , S2 ), and (S3 , S3 ).
We can also check for mutexes in the intersection of the element labels k (x) ∧ k (x ) = S2 ∨ S3 ,
meaning the only cross world pairs we check for mutexes are (S2 , S2 ), (S2 , S3 ), (S3 , S2 ), and
(S3 , S3 ).
We can say that a formula f is reachable from our projected belief state BSP , when considering
cross-world mutexes, if for every pair of states in BSP , f is reachable. For a pair of states S and
S  , f is reachable if S ∧ S  |= ∗k (f ) and for every pair of constituents Sˆ , Sˆ ∈ fˆ such that
S |= ∗k (Sˆ ) and S  |= ∗k (Sˆ ), there are no two literals in either Sˆ or Sˆ that are same-world
mutex when S = S  , and there is not a mutex between literals in Sˆ and Sˆ , across the respective
worlds S and S  when S 
= S  . There is a mutex between a pair literals l and l , respectively from
Sˆ and Sˆ if there is a mutex (ˆk (l), ˆk (l )) such that S |= ˆk (l) and S  |= ˆk (l ).
The computation of cross-world mutexes requires changes to some of the mutex formulas, as
outlined next. The major change is to check, instead of all the single possible worlds S, all pairs of
possible worlds S and S  for mutexes.
Action Mutexes: The action mutexes can now hold for actions that are executable in different
possible worlds.
• Interference Interference mutexes do not change for cross-world mutexes, except that there
is a pair of labels where (ˆk (a) = BSP , ˆk (a ) = BSP ), instead of a single label.
• Competing Needs Competing needs change mutexes for cross-world mutexes because two
actions a and a , in worlds S and S  respectively, could be competing. Formally, a crossworld competing needs mutex ((ˆk (a) = S, ˆk (a ) = S  ) exists between a and a in worlds S
and S  if:
∃l∈ρe (a),l ∈ρe (a ) (ˆk (l) = S, ˆk (l ) = S  )
Effect Mutexes: The effect mutexes can now hold for effects that occur in different possible worlds.
• Interference Effect interference mutexes do not change for cross-world mutexes, except that
there is a pair of labels where (ˆk (ϕi (a)) = BSP , ˆk (ϕj (a )) = BSP ), instead of a single
label.
96

P LANNING G RAPH H EURISTICS FOR B ELIEF S PACE S EARCH

Lk

lk(p)
p
∧

Ek

Ak

lk(a’)
a’

ϕh(a’)

lk(ϕh(a’))

∧

(lk(p), lk(q))
Induced mutex across worlds:
∧
∧
(lk(ϕj(a))∧lk(ϕi(a)), lk(ϕh(a’)))

∧

∧

(lk(ϕj(a)), lk(ϕh(a’)))

lk(q)
q
lk(a)
a

ϕj(a)

lk(r)
r

lk(ϕj(a))
ϕi(a) induces ϕj(a) in:
lk(ϕi(a))∧lk(ϕj(a))

ϕi(a) lk(ϕi(a))

Figure 12: Example of a cross-world induced effect mutex.
• Competing Needs Effect competing needs mutexes change for cross-world mutexes because
two effects ϕi (a) and ϕj (a ), in worlds S and S  respectively, could be competing. Formally,
a cross-world competing needs mutex (ˆk (ϕi (a)) = S, ˆk (ϕj (a )) = S  ) exists between ϕi (a)
and ϕj (a ) in worlds S and S  if:
∃l∈ρi (a),l ∈ρj (a ) (ˆk (l) = S, ˆk (l ) = S  )
• Induced Induced mutexes change slightly for cross-world mutexes. The worlds where one
effect induces another, remains the same, but the mutex changes slightly.
If ϕj (a) in ˆk (ϕj (a)) is mutex with ϕh (a ) in ˆk (ϕh (a )), and ϕi (a) induces effect ϕj (a)
in the possible worlds described by k (ϕi (a)) ∧ k (ϕj (a)), then there is an induced mutex
between ϕi (a) in ˆk (ϕj (a)) ∧ k (ϕi (a)) and ϕh (a ) in ˆk (ϕh (a )) (see Figure 12).

Literal Mutexes: The literal mutexes can now hold for literals that are supported in different possible worlds.
• Inconsistent Support changes for cross-world mutexes. A mutex (ˆk (l) = S, ˆk (l ) = S  )
holds for l in S and l in S  if ∀ϕi (a), ϕj (a ) ∈ Ek−1 where l ∈ εi (a), l ∈ εj (a ), there is a
mutex ˆk−1 (ϕi (a)) = S, ˆk−1 (ϕj (a )) = S  ).

97

B RYCE , K AMBHAMPATI , & S MITH

References
Bertoli, P., & Cimatti, A. (2002). Improving heuristics for planning as search in belief space. In
Proceedings of AIPS’02.
Bertoli, P., Cimatti, A., & Roveri, M. (2001a). Heuristic search + symbolic model checking =
efficient conformant planning. In Proceedings of IJCAI’01.
Bertoli, P., Cimatti, A., Roveri, M., & Traverso, P. (2001b). Planning in nondeterministic domains
under partial observability via symbolic model checking. In Proceedings of IJCAI’01.
Blum, A., & Furst, M. (1995). Fast planning through planning graph analysis. In Proceedings of
IJCAI’95.
Bonet, B., & Geffner, H. (1999). Planning as heuristic search: New results. In Proceedings of
ECP’99.
Bonet, B., & Geffner, H. (2000). Planning with incomplete information as heuristic search in belief
space. In Proceedings of AIPS’00.
Brace, K., Rudell, R., & Bryant, R. (1990). Efficient implementation of a bdd package. In Proceedings of the 27th ACM/IEEE design automation conference.
Bryant, R. (1986). Graph-based algorithms for Boolean function manipulation. IEEE Transactions
on Computers, C-35(8), 677–691.
Bryce, D., & Kambhampati, S. (2004). Heuristic guidance measures for conformant planning. In
Proceedings of ICAPS’04.
Castellini, C., Giunchiglia, E., & Tacchella, A. (2001). Improvements to sat-based conformant
planning. In Proceedings of ECP’01.
Cimatti, A., & Roveri, M. (2000). Conformant planning via symbolic model checking. Journal of
Artificial Intelligence Research, 13, 305–338.
Cormen, T. H., Leiserson, C. E., & Rivest, R. L. (1990). Introduction to Algorithms. McGraw-Hill.
Cushing, W., & Bryce, D. (2005). State agnostic planning graphs. In Proceedings of AAAI’05.
de Kleer, J. (1986). An Assumption-Based TMS. Artificial Intelligence, 28(2), 127–162.
Genesereth, M. R., & Nourbakhsh, I. R. (1993). Time-saving tips for problem solving with incomplete information. In Proceedings of AAAI’93.
Hansen, E., & Zilberstein, S. (2001). LAO: A heuristic-search algorithm that finds solutions with
loops. Artificial Intelligence, 129(1–2), 35–62.
Hoffmann, J., & Brafman, R. (2004). Conformant planning via heuristic forward search: A new
approach. In Proceedings of ICAPS’04.
Hoffmann, J., & Nebel, B. (2001). The FF planning system: Fast plan generation through heuristic
search. Journal of Artificial Intelligence Research, 14, 253–302.
Kambhampati, S., Ihrig, L., & Srivastava, B. (1996). A candidate set based analysis of subgoal
interactions in conjunctive goal planning. In Proceedings of AIPS’96.
Koehler, J., Nebel, B., Hoffmann, J., & Dimopoulos, Y. (1997). Extending planning graphs to an
adl subset. In Proceedings of ECP’97.
98

P LANNING G RAPH H EURISTICS FOR B ELIEF S PACE S EARCH

Kurien, J., Nayak, P., & Smith, D. (2002). Fragment-based conformant planning. In Proceedings of
AIPS’02.
Long, D., & Fox, M. (2003). The 3rd international planning competition: Results and analysis.
Journal of Artificial Intelligence Research, 20, 1–59.
Nguyen, X., Kambhampati, S., & Nigenda, R. (2002). Planning graph as the basis for deriving
heuristics for plan synthesis by state space and CSP search. Artificial Intelligence, 135(1-2),
73–123.
Nilsson, N. (1980). Principles of Artificial Intelligence. Morgan Kaufmann.
Pednault, E. P. D. (1988). Synthesizing plans that contain actions with context-dependent effects.
Computational Intelligence, 4, 356–372.
Petrick, R., & Bacchus, F. (2002). A knowledge-based approach to planning with incomplete information and sensing. In Proceedings of AIPS’02.
Rintanen, J. (2003a). Expressive equivalence of formalisms for planning with sensing. In Proceedings of ICAPS’03.
Rintanen, J. (2003b). Product representation of belief spaces in planning under partial observability.
In Proceedings of IJCAI’03.
Rintanen, J. (2004). Distance estimates for planning in the discrete belief space. In Proceedings of
AAAI’04.
Smith, D., & Weld, D. (1998). Conformant graphplan. In Proceedings of AAAI’98.
Weld, D., Anderson, C., & Smith, D. (1998). Extending graphplan to handle uncertainty and sensing
actions. In Proceedings of AAAI’98.

99

