Journal of Artificial Intelligence Research 9 (1998) 167-217

Submitted 6/98; published 10/98

Probabilistic Inference from Arbitrary Uncertainty
using Mixtures of Factorized Generalized Gaussians
Alberto Ruiz
Pedro E. López-de-Teruel
M. Carmen Garrido
Universidad de Murcia, Facultad de Informática,
Campus de Espinardo, 30100, Murcia, Spain

ARUIZ@DIF.UM.ES
PEDROE@DITEC.UM.ES
MGARRIDO@DIF.UM.ES

Abstract
This paper presents a general and efficient framework for probabilistic inference and learning from
arbitrary uncertain information. It exploits the calculation properties of finite mixture models, conjugate families and factorization. Both the joint probability density of the variables and the likelihood
function of the (objective or subjective) observation are approximated by a special mixture model, in
such a way that any desired conditional distribution can be directly obtained without numerical integration. We have developed an extended version of the expectation maximization (EM) algorithm to
estimate the parameters of mixture models from uncertain training examples (indirect observations). As
a consequence, any piece of exact or uncertain information about both input and output values is consistently handled in the inference and learning stages. This ability, extremely useful in certain situations, is not found in most alternative methods. The proposed framework is formally justified from
standard probabilistic principles and illustrative examples are provided in the fields of nonparametric
pattern classification, nonlinear regression and pattern completion. Finally, experiments on a real application and comparative results over standard databases provide empirical evidence of the utility of the
method in a wide range of applications.

1. Introduction
The estimation of unknown magnitudes from available information, in the form of sensor measurements or subjective judgments, is a central problem in many fields of science and engineering.
To solve this task, the domain must be accurately described by a model able to support the desired
range of inferences. When satisfactory models cannot be derived from first principles, approximations must be obtained from empirical data in a learning stage.
Consider a domain Z composed by a collection of objects z =(z1, z2, ..., zn), represented by
vectors of n attributes. Given some partial knowledge S (expressed in a general form explained
later) about a certain object z, we are interested in computing a good estimate zˆ ( S ) , close to the
true z. We allow heterogeneous descriptions; any attribute zi may be continuous, discrete, or symbolic valued, including mixed types. If there is a specific subset of unknown or uncertain attributes
to be estimated, the attribute vector can be partitioned as z = (x, y), where y ⊆ z denotes the target
or output attributes. The target attributes can be different for different objects z. This scenario includes several usual inference paradigms. For instance, when there is a specific target symbolic
attribute, the task is called pattern recognition or classification; when the target attribute is continuous, the inference task is called regression or function approximation. In general, we are interested in a general framework for pattern completion from partially known objects.
Example 1: To illustrate this setting, assume that the preprocessor of a hypothetical computer
vision system obtains features of a segmented object. The instances of the domain are described

1998 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

RUIZ, LÓPEZ-DE-TERUEL & GARRIDO

by the following n=7 attributes: AREA: z1 ∈ §, COLOR: z2 ∈ {white, black, red, ...}, DISTANCE:
z3 ∈ §, SHAPE: z4 ∈ {circular, rectangular, triangular, ...}, TEXTURE: z5 ∈ {soft, rough, ...},
OBJECTTYPE: z6 ∈ {door, window, ...} and ANGLE: z7 ∈ §. A typical instance may be z = (78,
blue, 3.4, triangular, soft, window, 45). If the object is partially occluded or 3-dimensional,
some attributes will be missing or uncertain. For instance, the available information S about z
could be expressed as (74±8, blue OR black, 3.4, triangular, ?, window 70% door 30%, ?),
where z1, z2, z6 are uncertain, z3, z4 are exact and z5, z7 are missing. In this case we could be interested in estimates for y = {z5, z6, z7} and even in improving our knowledge on z1 and z2.

The non-deterministic nature of many real world domains suggests a probabilistic approach,
where attributes are considered as random variables. Objects are assumed to be drawn independently and identically distributed from p(z) = p(z1, ..., zn) = p(x, y), the multivariate joint probability
density function of the attributes, which completely characterizes the n-dimensional random variable z. To simplify notation, we will use the same function symbol p(·) to denote different p.d.f.’s if
they can be identified without risk of confusion.
According to Statistical Decision Theory (Berger 1985), optimum estimators for the desired attributes are obtained through minimization of a suitable expected loss function:

y OPT ( S ) = argmin y E{ L( y , y )| S}


where L(y, ŷ ) is the loss incurred when the true y is estimated by ŷ . Estimators are always features of the conditional or posterior distribution p(y|S) of the target variables given the available
information. For instance, the minimum squared error (MSE) estimator is the posterior mean, the
minimum linear loss estimator is the posterior median and the minimum error probability (EP, 0-1
loss) estimator is the posterior mode.
Example 2: A typical problem is the prediction of an unknown attribute y from the observed attributes x. In this case the available information can be written as S = (x, ?). If y is continuous, it
is reasonable to use the MSE estimator: yˆ MSE ( S ) = E{ y | x} , the general regression function. If y
is symbolic and the same loss is associated to all errors, the EP estimator is adequate:
yˆ EP ( S ) = argmaxy p(y|x) = argmaxy p(x|y)p(y). It corresponds to the Maximum A Posteriori rule
or Bayes Test, widely used in Statistical Pattern Recognition.

The joint density p(z) = p(x, y) plays an essential role in the inference process. It implicitly
includes complete information about attribute dependences. In principle, any desired conditional
distribution or estimator can be computed from the joint density by adequate integration. Probabilistic Inference is the process of computing the desired conditional probabilities from a (possibly
implicit) joint distribution. From p(z) (the prior, model of the domain, comprising implications) and
S (a known event, somewhat related to a certain z), we could obtain the posterior p(z|S) and the
desired target marginal p(y|S) (the probabilistic “consequent”).
Example 3: If we observe an exact value xo in attribute x, i.e. S = { x = xo}, we have:

p( y| S ) ≡ p(y| xo) =

∫

Y

p ( xo , y )
p( xo , y )dy

If we know that instance z is in a certain region R in the attribute space, i.e. S = {z ∈ R}, we
compute the marginal density of y from the joint p(z) = p(x, y) restricted to region R (Fig. 1):

168

PROBABILISTIC INFERENCE FROM UNCERTAIN DATA USING MIXTURES

p( y| S ) =

∫

X

p( x, y|{( x , y ) ∈ R}) dx =

∫ p( x, y) dx
∫∫ p( x, y) dxdy
R

R

More general types of uncertain information S about z will be discussed later.

y
p(y|R)
R

p(x,y)
x

Figure 1. The conditional probability density of y, assuming z = (x,y) ∈ R.

In summary, from the joint density p(z) of a multivariate random variable, any subset of variables y ⊆ z may be, in principle, estimated given the available information S about the whole z = (x,
y). In practical situations, two steps are required to solve the inference problem. First, a good model
of the true joint density p(z) must be obtained. Second, the available information S must be efficiently processed to improve our knowledge about future, partially specified instances z. These two
complementary aspects, learning and inference, are approached from many scientific fields, providing different methodologies to solve practical applications.
From the point of view of Computer Science, the essential goal of Inductive Inference is to
find an approximate intensional definition (properties) of an unknown concept (subset of the domain) from an incomplete extensional definition (finite sample). Machine Learning techniques
(Michalski, Carbonell & Mitchell 1977, 1983, Hutchinson 1994) provide practical solutions (e.g.
automatic construction of decision trees) to solve many situations where explicit programming
must be avoided. Computational Learning Theory (Valiant 1993, Wolpert 1994, Vapnik 1995)
studies the feasibility of induction in terms of generalization ability and resource requirements of
different learning paradigms.
Under the general setting of Statistical Decision Theory, modeling techniques and the operational aspects of inference (based in numerical integration, Monte Carlo simulation, analytic approximations, etc.) are extensively studied from the Bayesian perspective (Berger 1985, Bernardo
& Smith 1994). In the more specific field of Statistical Pattern Recognition (Duda & Hart 1973,
Fukunaga 1990), standard parametric or nonparametric density approximation techniques (Izenman
1991) are used to learn from training data the class-conditional p.d.f.’s required by the optimum
decision rule. For instance, if the class-conditional densities p(x|y) are Gaussian, the required parameters are the mean vector and covariance matrix of the feature vector in each class and the decision regions for y in x have quadratic boundaries. Among the nonparametric classification techniques, the Parzen method and the K-N Nearest Neighbors rule must be mentioned. Analogously, if
the target attribute is continuous and the statistical dependence between input and output variables
p(x,y) can be properly modeled by joint normality, we get multivariate linear regression: ŷ MSE(x) =
A x + B, where the required parameters are the mean values and the covariance matrix of the attrib-

169

RUIZ, LÓPEZ-DE-TERUEL & GARRIDO

utes. Nonlinear regression curves can be also derived from nonparametric approximation techniques. Nonparametric methods present slower convergence rates, requiring significantly larger
sample sizes to obtain satisfactory approximations; they are also strongly affected by the dimensionality of the data and the selection of the smoothing parameter is a crucial step. In contrast, they
only require some kind of smoothness assumption on the target density.
Neural Networks (Hertz et. al 1991) are computational models trainable from empirical data
that have been proposed to solve more complex situations. Their intrinsic parallel architecture is
especially efficient in the inference stage. One of the most widely used neural models is the Multilayer Perceptron, a universal function approximator (Hornik et al. 1989) that breaks the limitations
of linear decision functions. The Backpropagation learning algorithm (Rumelhart et al. 1986) can,
in principle, adjust the network weights to implement arbitrary mappings, and the network outputs
show desirable probabilistic properties (Wan 1990, Rojas 1996). There are also unsupervised networks for probability density function approximation (Kohonen 1989). However, neural models
usually contain a large number of adjustable parameters, which is not convenient for generalization
and, frequently, long times are required for training in relatively easy tasks. The input / output role
of attributes cannot be changed in runtime and missing and uncertain values are poorly supported.
Bayesian Networks, based in the concept of conditional independence, are among the most
relevant probabilistic inference technologies (Pearl 1988, Heckerman & Wellman 1995). The joint
density of the variables is modeled by a directed graph which explicitly represents dependence
statements. A wide range of inferences can be performed under this framework (Chang & Fung
1995, Lauritzen & Spiegelhalter 1988) and there are significant results on inductive learning of
network structures (Bouckaert 1994, Cooper & Herskovits 1992, Valiveti & Oomen 1992). This
approach is adequate when there is a large number of variables showing explicit dependences and
simple cause-effect relations. Nevertheless, solving arbitrary queries is NP-Complete, automatic
learning algorithms are time consuming and the allowed dependences between variables are relatively simple.
In an attempt to mitigate some of the above drawbacks, we have developed a general and efficient inference and learning framework based on the following considerations. It is well known
(Titterington et al. 1985, McLachlan & Basford 1988, Dalal & Hall 1983, Bernardo & Smith 1994,
Xu & Jordan 1996) that any reasonable probability density function p(z) can be approximated up to
the desired degree of accuracy by a finite mixture of simple components Ci, i = 1..l:

p( z ) ≅ ∑ P{Ci } p( z| Ci )

(1)

i

The superposition of simple densities is extensively used to approximate arbitrary data dependences (Fig. 2). Maximum Likelihood estimators of the mixture parameters can be efficiently obtained from samples by the Expectation Maximization (EM) algorithm (Dempster, Laird & Rubin
1977, Redner & Walker 1984) (see Section 4).

170

PROBABILISTIC INFERENCE FROM UNCERTAIN DATA USING MIXTURES

(a)
(b)
(c)
Figure 2. Illustrative example of density approximation using a mixture model. (a) Samples from a p.d.f. p(x,y) showing a nonlinear dependence. (b) Mixture model for p(x,y)
with 6 gaussian components obtained by the standard EM algorithm. (c) Location of
components.

The decomposition of probability distributions using mixtures has been frequently applied to
unsupervised learning tasks, especially Cluster Analysis (McLachlan & Basford 1988, Duda &
Hart 1973, Fukunaga 1990): the a posteriori probabilities of each postulated category are computed
for all the examples, which are labeled according to the most probable source density. However,
mixture models are specially useful in nonparametric supervised learning situations. For instance,
the class conditional densities required in Statistical Pattern Recognition were individually approximated in (Priebe & Marchette 1991, Traven 1991) by finite mixtures; hierarchical mixtures of
linear models were proposed in (Jordan & Jacobs 1994, Peng et. al 1995); mixtures of factor analyzers have been developed in (Ghahramani & Hinton 1996, Hinton, Dayan, & Revow 1997) and
mixture models have been also useful for feature selection (Pudil et al. 1995). Mixture modeling is
a growing semiparametric probabilistic learning methodology with applications in many research
areas (Weiss & Adelson 1995, Fan et al. 1996, Moghaddam & Pentland 1997).
This paper introduces a framework for probabilistic inference and learning from arbitrary uncertain data: any piece of exact or uncertain information about both input and output values is consistently handled in the inference and learning stages. We approximate both the joint density p(z)
(model of the domain) and the relative likelihood function p(S|z) (describing the available information) by a specific mixture model with factorized conjugate components, in such a way that numerical integration is avoided in the computation of any desired estimator, marginal or conditional
density.
The advantages of modeling arbitrary densities using mixtures of natural conjugate components were already shown in (Dalal & Hall 1983), and, recently, inference procedures based in a
similar idea have been proposed in (Ghahramani & Jordan 1994, Cohn et al. 1996, Peng et al. 1995,
Palm 1994). However, our method efficiently handles uncertain data using explicit likelihood
functions, which has not been extensively used before in Machine Learning, Pattern Recognition or
related areas. We will follow standard probabilistic principles, providing natural statistical validation procedures.
The organization of the paper is as follows. Section 2 reviews some elementary results and
concepts used in the proposed framework. Section 3 addresses the inference stage. Section 4 is
concerned with learning, extending the EM algorithm to manage uncertain information. Section 5
discusses the method in relation to alternative techniques and presents experimental evaluation.
The last section summarizes the conclusions and future directions of this work.

171

RUIZ, LÓPEZ-DE-TERUEL & GARRIDO

2. Preliminaries
2.1 A Calculus of Generalized Normals
In many applications, the instances of the domain are represented simultaneously by continuous
and symbolic or discrete variables (as in Wilson & Martinez 1997). To simplify notation, we will
denote both probability impulses and Gaussian densities by means of a common formalism. The
generalized normal
(x,µ,σ) denotes a probability density function with the following properties:

T

T(x,µ,σ) ≡

If σ > 0,

 − ( x − µ) 2 
1
exp

2πσ  2σ2 

T(x,µ,σ) = T(x,µ,0) ≡ T(x,µ) ≡ δ(x–µ)

If σ = 0,

Tzero,(x,µ,σ)
is a Gaussian density with mean µ and standard deviation σ ≥ 0. When the dispersion is
T reduces
to a Dirac’s delta function located at µ. In both cases T is a proper p.d.f.:
T(x,µ,σ) > 0
∫ T(x,µ,σ) dx = 1
X

The product of generalized normals can be elegantly expressed (Papoulis 1991 pp. 258, Berger
1985) by:
for σ1+σ2 >0:

T(x,µ1,σ1) · T(x,µ2,σ2) = T(x,η,ε) · T(µ1,µ2, σ12 + σ22 )

(2)

where the mean η and dispersion ε of the new normal are given by:

σ12µ2 + σ22 µ1
η=
σ12 + σ22

σ12σ22
ε = 2
σ1 + σ22
2

This relation is useful for computing the integral of the product of two generalized normals:
for σ1+σ2 >0:

∫

X

T(x,µ1,σ1) · T(x,µ2,σ2) dx = T(µ1, µ2, σ12 + σ22 )

(3)

And, for consistency, we define

∫

for σ1 = σ2 = 0:

X

T(x,µ1) T(x,µ2) dx = T(µ1,µ2) ≡ I{µ1=µ2}

where I{predicate} = 1 if predicate is true and zero otherwise. Virtually any reasonable univariate
probability distribution or likelihood function can be accurately modeled by an appropriate mixture
of generalized normals. In particular, p.d.f.’s over symbolic variables are mixtures of impulses.
Without loss of generality, symbols may be arbitrarily mapped to specific numbers and represented
over numeric axes. Integrals over discrete domains become sums.
Example 4: Let us approximate the p.d.f. p(x) of a mixed continuous and symbolic valued random variable x by a mixture of generalized normals. Assume that x takes with probability 0.4
the exact value 10 (with a special meaning), and with probability 0.6 a random value continuously distributed following the triangular shape shown in Fig. 3. The density p(x) can be accurately approximated (see Section 4) using 4 generalized normals:

T(x,10) + .21T(x,.04,.23) + .28T(x,.45,.28) + .11T(x,.99,.21)

p(x) ≅ .40

172

PROBABILISTIC INFERENCE FROM UNCERTAIN DATA USING MIXTURES

Figure 3. The p.d.f. of a mixed random variable approximated by a mixture of generalized normals.

2.2 Modeling Uncertainty: The Likelihood Principle
Assume that the value of a random variable z must be inferred from a certain observation or subjective information S. If z has been drawn from p(z) and the measurement or judgment process is
characterized by a conditional p(S|z), our knowledge on z is updated according to p(z|S)=p(z) p(S|z)
/ p(S), where p(S) = ∫Z p(S|z) p(z) dz (see Fig. 4).
The likelihood function fS(z) ≡ p(S|z) is the probability density ascribed to S by each possible
z. It is an arbitrary nonnegative function over z that can be interpreted in two alternative ways. It
can be the “objective” conditional distribution p(S|z) of a physical measurement process (e.g. a
model of sensor noise, specifying bias and variance of the observable S for every possible true
value z), also known as error model. It can also be a “subjective” judgment about the chance of the
different z values (e.g. intervals, more likely regions, etc.), based on vague or difficult to formalize
information. The dispersion of fS(z) is directly related to the uncertainty associated to the measurement process. Following the likelihood principle (Berger 1985), we explicitly assume that all the
experimental information required to perform probabilistic inference is contained in the likelihood
function fS(z).

p(z)
z1

z2

z3

z

p(s|z2)

p(s|z1)

p(s|z3)
s

so

prior
model of
measurement

p(s)
s
fSo(z)= p(so|z)

z

observable

likelihood of
observation so

p(z|so)
posterior
z
Figure 4. Illustration of the elementary Bayesian univariate inference process.

173

RUIZ, LÓPEZ-DE-TERUEL & GARRIDO

2.3 Inference Using Mixtures of Conjugate Densities
The computation of p(z|S) may be hard, unless p(z) and p(S|z) belong to special (conjugate) families (Berger 1985, Bernardo & Smith 1994). In this case the posterior density can be analytically
obtained from the parameters of the prior and the likelihood, avoiding numeric integration. The
prior, the likelihood and the posterior are in the same mathematical family. The “belief structure” is
closed under the inference process.

T

Example 5: In the univariate case, assume that z is known to be normally distributed around r
with dispersion σr, i.e. p(z) = (z, r, σr). Assume also that our measurement device has Gaussian noise, so the observed values are distributed according to p(s|z) =
(s, z, σs). Therefore,
if we observe a certain value so, from the property of the product of generalized normals in eq.
(2), the posterior knowledge on z becomes another normal
(z, µ, ε). The new expected location of z can be expressed as a weighted average of r and so: η = γ so + (1-γ)r and the uncertainty is reduced to ε2 = γ σS2 . The coefficient γ = σ 2r / ( σ 2r + σS2 ) quantifies the relative im-

T

T

portance of the experiment with respect to the prior.

This computational advantage can be extended to the general case by using mixtures of conjugate families (Dalal & Hall 1983) to approximate the desired joint probability distribution and the
likelihood function.
Example 6: If the domain and the likelihood are modeled respectively by

p(z) ≅

∑
i

Pi

T(z, µ , σ )
i

p(so|z) ≅

i

∑

πr

r

T(z, η , ε )
r

r

(where π r , ηr and ε r depend explicitly on the observed so), then the posterior can be also
written as the following mixture:

∑θ

p(z|so) ≅

i, r

From properties (2) and (3), the parameters

νi , r

i ,r

T(z, ν

, λ i ,r )

(4)

νi ,r and λ i ,r and the weights θi ,r are given by:

σi2 ηr + ε 2r µ i
=
σi2 + ε r2

θ i ,r ≡

i ,r

λ i ,r =

σi ε r
σ i2 + ε r2

Pi π r T(µ i , ηr , σi2 + ε r2 )

∑P π
k

l

T(µ k , ηl , σ2k + ε 2l )

k ,l

2.4 The Role of Factorization
Given a multivariate observation z partitioned into two subvectors, z = (x, y), assume that we are
interested in inferring the value of the unknown attributes y from the observed attributes x. Note
that if x and y are statistically independent, the joint density is factorizable: p(z) = p(x, y) = p(x)
p(y) and, therefore, the posterior p(y|x) equals the prior marginal p(y). The observed x carries no
predictive information about y and the optimum estimators do no depend on x. For instance,
y MSE ( x ) = E{y|x} = E{y} and y EP ( x ) = argmax y p( y ) . This is the simplest estimation task. No
runtime computations are required for the optimum solution, which may be precalculated.

174

PROBABILISTIC INFERENCE FROM UNCERTAIN DATA USING MIXTURES

In realistic situations the variables are statistically dependent. In general, the joint density cannot be factorized and the required marginal densities may be hard to compute. However, interesting
consequences arise if the joint density is expressed as a finite mixture of factorized (with independent variables) components C1, C2, ..., Cl :

p(z) = p( z 1 ,..., z n ) = ∑ P{Ci } p( z| Ci ) = ∑ P{Ci } ∏ p( z j | Ci )
i

i

(5)

j

This structure is convenient for inference purposes. In particular, in terms of the desired partition of z = (x, y):

p(z) = p(x, y) =

∑ P{C } p( x| C ) p( y| C )
i

i

i

i

so the marginal densities are mixtures of the marginal components:

p( x ) = ∫ p( x , y )dy = ∑ P{Ci } p( x| Ci )
Y

i

p( y ) = ∑ P{Ci } p( y| Ci )
i

and the desired conditional densities are also mixtures of the marginal components:

p( y| x ) = ∑ α i ( x ) p( y| Ci )

(6)

i

where the weights α i (x) are the probabilities that the observed x has been generated by each component Ci :

αi ( x) =

P{Ci } p( x|Ci )

∑ P{C } p( x|C )
j

= P{Ci | x}

j

j

The p.d.f. approximation capabilities of mixture models with factorized components remain
unchanged, at the cost of a possibly higher number of components to obtain the desired degree of
accuracy, avoiding “artifacts” (see Fig. 5). Section 5.2 discusses the implications of factorization in
relation with alternative model structures.

(a)
(b)
Figure 5. (a) Density approximation for the data in Fig. 2, using a mixture with 8 factorized components. (b) Location of components. Note how an arbitrary dependence can be
represented as a mixture of components which itself have independent variables (observe
that a somewhat “smoother” solution could be obtained increasing the number of components).

175

RUIZ, LÓPEZ-DE-TERUEL & GARRIDO

3. The MFGN Framework
The previous concepts will be integrated in a general probabilistic inference framework that we call
MFGN (Mixtures of Factorized Generalized Normals). Fig. 6 shows the abstract dependence relations among attributes in a generic domain (upper section of the figure) and between the attributes
and the observed information (lower section). In the MFGN framework, both relations are modeled
by finite mixtures of products of generalized normals. The key idea is using factorization to cope
with multivariate domains and heterogeneous attribute vectors, and conjugate densities to efficiently perform inferences given arbitrary uncertain information. In this section, we will derive the
main inference expressions. The learning stage will be described in Section 4.

p(z)
z1

zn
z2

model of
domain
p(z)

zj
model of
measurement
p(S|z)

S

Figure 6. Generic dependences in the inference process.

3.1 Modeling Attribute Dependences in the Domain
In the MFGN framework the attribute dependencies in the domain are modeled by a joint density in
the form of a finite mixture of factored components, as in expression (5), where the component
marginals p( z j | Ci ) ≡ T( z j , µ ij , σ ij ) are generalized normals:

p( z ) = ∑ Pi
i

∏ T( z

j

, µ ij , σ ij )

i=1..l, j=1..n,

(7)

j

If desired, the terms associated to the pure symbolic attributes z j (with all the σ ij = 0) can be
collected in such a way that the component marginals are expressed as mixtures of impulses:

p( z j | Ci ) ≡ ∑ ti j,ω T( z j , ω )

(8)

ω

where ti j,ω ≡ P{z j = ω| Ci } is the probability that z j takes its ω-th value in component Ci . This
manipulation reduces the number l of global components in the mixture. The adjustable parameters
of the model are the proportions Pi = P{Ci } and the mean value µ ij and dispersion σ ij of the j-th
j
attribute in the i-th component (or, for the symbolic attributes, the probabilities ti ,ω ). While the

structure (8) will be explicitly used for symbolic attributes in applications and illustrative examples, most of the mathematical derivations will be made over the concise expression (7).

176

PROBABILISTIC INFERENCE FROM UNCERTAIN DATA USING MIXTURES

When all variables are continuous, the MFGN architecture reduces to a mixture of gaussians
with diagonal covariance matrices. The proposed factorized structure extends the properties of
diagonal covariance matrices to heterogeneous attribute vectors. We are interested in joint models,
which support inferences from partial information about any subset of variables. Note that there is
not an easy way to define a measure of statistical depencence between symbolic and continuous
attributes, to be used as a parameter of some probability density function1. The required "hetereogeneous" dependence model can be conveniently captured by superposition of simple factorized
(with independent variables) densities.
Example 7: Figure 7 shows an illustrative 3-attribute data set (x and y are continuous and z is
symbolic) and the components of the MFGN approximation obtained by the EM algorithm
(see Section 4) for their joint density. The parameters of the mixture are shown in Table 1.
Note that, because of the overlapped structure of the data, some components (5 and 6) are “assigned” to both values of the symbolic attribute z.

(a)
(b)
Figure 7. (a) Simple data set with two continuous and one symbolic attribute.
(b) Location of the mixture components.

i

Pi

µ ix

σ ix

µ iy

σ iy

tiz,white

1
.14
-.40
.24
-.27
.20
0
2
.09
-.76
.19
-.68
.18
0
3
.20
.55
.23
.66
.24
0
4
.17
-.71
.27
.76
.22
1
5
.13
.21
.17
-.14
.19
.74
6
.18
-.14
.18
.26
.17
.55
7
.09
.65
.16
-.64
.19
1
Table 1. Parameters of the Mixture Model for the Data Set in Fig. 7.

tiz,black
1
1
1
0
.26
.45
0

3.2 Modeling Arbitrary Information about Instances
The available information about a particular instance z is denoted by S. Following the likelihood
principle, we are not concerned with the true nature of S, whether it is some kind of physical meas1

For this reason, in pattern classification tasks separate models are typically built for each class-conditional density.

177

RUIZ, LÓPEZ-DE-TERUEL & GARRIDO

urement or a more subjective judgment about the location of z in the attribute space. All we need to
update our knowledge about z, in the form of the posterior p(z|S), is the relative likelihood function
p(S|z) of the observed S. In general, p(S|z) can be any nonnegative multivariable function fS(z) over
the domain. In the objective case, statistical studies of the measurement process can be used to
determine the likelihood function. In the subjective case, it may be obtained by standard distribution elicitation techniques (Berger 1985). In either case, under the MFGN framework, the likelihood function of the available information to be used in the inference process will be approximated, up to the desired degree of accuracy, by a sum of products of generalized normals:

p( S| z ) = ∑ P{S | s r } p( s r | z ) = ∑ P{S | s r }∏ p( srj | z j )
r

r

=

∑ π ∏ T( z
r

j

j

, srj , ε rj )

(9)

j

r

Without loss of generality, the available knowledge is structured as a weighted disjunction S =
1
2
{π1s1 OR π2s2 ... OR π R s R } of conjunctions sr = { sr AND sr ... AND srn ) of elementary uncertain
observations in the form of generalized normal likelihoods T( z j , srj , ε rj ) centered at srj with
uncertainty ε rj . The measurement process can be interpreted as the result of R (objective or subjective) sensors sr , providing conditionally independent information p( srj | z j ) about the attributes
(each srj only depends on z j ) with relative strength π r . Note that any complex uncertain information about an instance z, expressed as a nested combination of elementary uncertain beliefs srj
about z j using “probabilistic connectives”, can be ultimately expressed by structure (9) (OR translates to addition, AND translates to product and the product of two generalized normals over the
same attribute becomes a single, weighted normal).
Example 8: Consider the hypothetical computer vision domain in Example 1. Assume that the
information about an object z is the following: “AREA is around a and DISTANCE is around b or,
more likely, SHAPE is surely triangular or else circular and AREA is around c and ANGLE is
around d or equal to e”. This structured piece of information can be formalized as:

T(z , a, ε ) T(z , b, ε )]
+ .7 [ (.9T(z ,triang)+.1T(z ,circ)) T(z , c, ε ) (T(z , d, ε )+T(z ,e)) ]

p(S|z) = .3 [

1

3

a

4

b

4

1

7

c

7

d

which, expanded, becomes the mixture of 5 factorized components operationally represented by
the parameters shown in Table 2.
In a simpler situation, the available information about z could be a conjunction of uncertain attributes similar to {Color = red 0.8 green 0.2} and {Area = 3 ± .5} and {Shape = rectangular 0.6
circular 0.3 triangular 0.1}. The likelihood of Shape values can be obtained from the output of a
simple pattern classifier (e.g. K-N-nearest neighbors) over moment invariants, while attributes
as Color and Area are directly extracted from the image. In this case we could be interested in
the distribution of values for other attributes as Texture and ObjectType. Alternatively, we
could start from {ObjectType = door 0.6 window 0.4} and {Texture = rough} in order to determine the probabilities of Color and Angle values for selecting a promising search region.

178

PROBABILISTIC INFERENCE FROM UNCERTAIN DATA USING MIXTURES

πr

sr1 ,ε 1r

sr3 , ε r3

sr2 ,ε 2r

sr4 ,ε 4r

sr5 ,ε 5r

sr6 ,ε 6r

sr7 ,ε 7r

.30
a, εa
-, ∞
b, εb
-, ∞
-, ∞
-, ∞
.63
triang, 0
c, εc
-, ∞
-, ∞
-, ∞
-, ∞
.63
triang, 0
c, εc
-, ∞
-, ∞
-, ∞
-, ∞
.07
circ, 0
c, εc
-, ∞
-, ∞
-, ∞
-, ∞
.07
circ
,
0
c, εc
-, ∞
-, ∞
-, ∞
-, ∞
Table 2. Parameters of the Uncertain Information Model in Example 8.

-, ∞
d,εd
e, 0
d,εd
e, 0

3.3 The Joint Model-Observation Density
The generic dependence structure in Fig. 6 is implemented by the MFGN framework as shown in
Fig. 8. The upper section of the figure is the model of nature, obtained in a previous learning stage
and used for inference without further changes. Dependences among attributes are conducted
through an intermediary hidden or latent component Ci. The lower section represents the available
uncertain information, measurement model or query structure associated to each particular inference operation.

Ci

p( z 1 | Ci )
1

Domain:

p( z) ≅ ∑ P{Ci }∏ p( z j | Ci )
2

z

z

s21

s22

...

zn

...

s2n

j

i

p( s11 | z1 )
s11

s12

...

s1n

s1

...

s1R

sR2

...

sRn

sR

s2
P{S|s1}

Measurement:
p( S| z ) ≅ ∑ P{S | s r }∏ p( srj | z j )

S

r

j

Figure 8. Structure of the MFGN model. The attributes are conditionally independent.
The measurement process is modeled by a collection of independent “virtual” sensors
p( srj | z j ) .

The joint density of the relevant variables becomes:

p(Ci , z , sr , S ) = P{S | s r } p( s r | z ) p( z| Ci ) P{Ci }

∏ p( s

= P{Ci } P{S | s r }

j
r

| z j ) p( z j | Ci )

j

= Pi π r

∏ T( z

j

, srj , ε rj ) T( z j , µ ij , σ ij )

j

179

(10)

RUIZ, LÓPEZ-DE-TERUEL & GARRIDO

Now we will derive an alternative expression for eq. (10) which is more convenient for computing the marginal densities of any desired variable. Using the following relation:

p( srj | z j ) p( z j | Ci ) = p( z j , srj | Ci ) = p( z j | srj , Ci ) p( srj | Ci )
and properties (2) and (3), we define the “dual” densities of the model:

β ij,r ≡ p( srj | Ci ) =

∫

Zj

p( srj | z j ) p( z j | Ci ) dz j =T( srj , µ ij , ρ ij,r )

(11)

p( srj | z j )
p( z j | Ci ) = T( z j , νij,r , λ ji ,r )
p( srj | Ci )

(12)

ψ ij,r ( z j ) ≡ p( z j | srj , Ci ) =

where the parameters ρij,r , νij,r and λ ji ,r are given by:

ρ ij,r ≡ (σ ij ) 2 + (ε rj ) 2
( σ ij ) 2 srj + ( ε rj ) 2 µ ij
ν ≡
(ρij,r ) 2
j
i ,r

λ

j
i ,r

σ ij ε rj
≡ j
ρi ,r

βij,r is the likelihood of the r-th elementary observation srj of the j-th attribute z j in each
component Ci and ψ ij,r ( z j ) is the effect of the r-th elementary information srj about the j-th attribute z j over the marginal component p( z j | Ci ) in each component Ci . Using the above notation, the MFGN model structure can be conveniently written as:

p(Ci , z , sr , S ) = Pi π r ∏ βij,r ψ ij,r ( z j )

(13)

j

3.4 The Posterior Density
In the inference process the available information is combined with the model of the domain to
update our knowledge about a particular object. Given a new piece of information S we must compute the posterior distribution p( y| S ) of the desired target attributes y ⊆ z. Then, estimators
y ( S ) ≅ y can be obtained from p( y| S ) to minimize any suitable average loss function. This is
efficiently supported under the MFGN framework regardless of the complexity of the domain p(z)
and the structure of the available information S = {π r sr } .
The attributes are partitioned into two subvectors z = (x, y), where y = { z d } are the desired
target attributes and x = { z o } are the rest of attributes. Accordingly, each component sr of the
available information S is partitioned as s r = ( s rx , s ry ) . The information about the target attributes
y in the r-th observation, independent from the model p(z), is denoted by sry (often y is just missing
and there are no such pieces of information) and srx represents the information about the rest of
attributes x. Using this convention we can write:

180

PROBABILISTIC INFERENCE FROM UNCERTAIN DATA USING MIXTURES

p( z , S ) = p( x , y , S ) = ∑ Pi π r βi ,r Ψi ,r ( x ) Ψi ,r ( y )
i ,r

Where βi ,r is the likelihood of the r-th conjunction sr of S in component Ci :

βi ,r ≡ ∏ βij,r

(14)

j

and the terms ψ ij,r ( z j ) are grouped according to the partition of z = (x, y):

Ψi ,r ( x ) ≡ ∏ ψ io,r ( z o )

Ψi ,r ( y ) ≡ ∏ ψ id,r ( z d )

o

d

The desired posterior p(y|S) = p(y,S) / p(S) can be computed from the joint p(z,S) by marginalization: along x to obtain p(y,S) and along all z to obtain p(S). Note that each univariate marginalization of p(z,S) along attribute z j eliminates all the terms ψ ij,r ( z j ) in the sum (13):

p( y , S ) = ∫ p( x , y , S ) dx = ∑ Pi π r βi ,r Ψi ,r ( y )
X

i ,r

p( S ) = ∫ p( z , S ) dz = ∑ Pi π r βi ,r
Z

i ,r

Therefore, the posterior density can be compactly written as:

p( y| S ) = ∑ α i ,r Ψi ,r ( y )

(15)

i ,r

where α i ,r is the probability that the object z has been generated by component Ci and the elementary information sr is true, given the total information S:

α i ,r ≡ P{Ci , sr | S} =

Pi π r βi ,r

∑P

k

π l β k ,l

(16)

k ,l

and Ψi ,r ( y ) = p( y| sry , Ci ) is the marginal density p( y| Ci ) of the desired attributes in the i-th
component, modified by the contribution of all the associated sry . Since p( y| sry , Ci ) =
p( y| sr , Ci ) , the expression (16) also follows from the expansion:

p( y| S ) = ∑ p( y| sr , Ci ) P{Ci , sr | S}
i ,r

In summary, when the joint density and the likelihood function are approximated by mixture
models with the proposed structure, the computation of conditional densities given events of arbitrary “geometry” is notably simplified. Factorized components reduce multidimensional integration
to simple combination of univariate integrals and conjugate families avoid numeric integration.
This property is illustrated in Fig. 9.

181

RUIZ, LÓPEZ-DE-TERUEL & GARRIDO

S

y

p(y|C2)

µ1y

E{y|S}

C2

p(y,x1,x2)

µ 2y

C1

p(y|C1)
p(x2|C2)

p(y|S)
p(x2|C1)

β22,1 β22,2
1

p(x |C2)

β21,1

x2

p(x1|C1)

β11,2

β11,1

s1
s2

x

1

S

Figure 9. Graphical illustration of the essential property of the MFGN framework. Consider the MSE estimate for y, conditioned to the event that (y, x1, x2) is in the cylindrical
region S. The required multidimensional integrations are computed analytically in terms
of the marginal likelihoods βji,r associated to each attribute and each pair of components
Ci and sr of the models for p(y, x1, x2) and for S, respectively. In this case Ψi,r(y)=p(y|Ci)
because no information about y is supplied in S.

Example 9: Fig. 10.a shows the joint density of two continuous variables x and y. It is modeled
as a mixture with 30 factorized generalized normals. Fig. 10.b shows the likelihood function
of the event S1 = {(x ≅ y OR x ≅ -y) AND y>0}. Fig. 10.c shows the posterior joint density
p(x,y|S1). Fig. 10.d shows the likelihood function of the event S2 = {(x,y) ≅ (0,0) OR x≅3}.
Fig. 10.e shows the posterior joint density p(x,y|S2). Fig. 10.f and 10.g show respectively the
posterior marginal density p(x|S2) and p(y|S2). These complex inferences are analytically computed under the MFGN framework, without any numeric integration.

182

PROBABILISTIC INFERENCE FROM UNCERTAIN DATA USING MIXTURES

(a)

(b)

(c)

(d)
(e)
Figure 10. Illustrative examples of probabilistic inference from arbitrary uncertain information in the MFGN framework (see Example 9).

183

RUIZ, LÓPEZ-DE-TERUEL & GARRIDO

p(y|S)

0.4

0.8

0.3

0.6

0.2

0.4

0.1

p(x|S)

0.2

y

x

-4

-2

2

4

-4

-2

2

(f)
Figure 10. (cont.).

4

(g)

3.5 Expressions for the Estimators
Approximations to the optimum estimators can be easily obtained by taking advantage of the
mathematically convenient structure of the posterior density. Under the MFGN framework, the
conditional expected value of any function g(y) becomes a linear combination of constants:

E{g ( y )| S} = ∫ g ( y ) p( y| S ) dy =
Y

=

∑α ∫
i ,r

Y

i ,r

g ( y ) Ψi ,r ( y ) dy =

∑α

i ,r

E i ,r {g ( y )}

(17)

i ,r

where E i ,r {g ( y )} ≡ E{g ( y )| s ry , Ci } is the expected value of g(y) in the i-th component2 modified3 by the r-th observation sry :

E i ,r {g ( y )} ≡

∫

Y

g ( y ) ∏ T( z d , ν id,r , λdi ,r ) dy
d

We can now analytically compute the desired optimum estimators. For instance, the MSE estimator for a single continuous attribute y = z d requires the mean values E i ,r {z d } = ν id,r :

y MSE ( S ) = E{ y| S} = ∑ α i ,r ν id,r
i ,r

From our explicit expression for p(y|S) we can also compute the conditional cost:

{

}

e 2MSE ( S ) = E ( y − y MSE ( S ) ) | S = E{y 2 | S} − y 2MSE ( S ) =
=

∑α
i ,r

i ,r

2

[( ν

d
i ,r

) + (λ )
2

d
i ,r

2

2

]



−  ∑ α i ,r ν id,r 
 i ,r


2

Note that computing the conditional expected value of an arbitrary function g(y) of several variables may be difficult. In
general g(y) can be expanded as a power series to obtain E{g(y)|S} in terms of moments of p(y|S).
3
When S is just sx (there is no information about the target attributes) the constants Ei,r{g(y)} can be precomputed from
the model of nature p(z) after the learning stage.

184

PROBABILISTIC INFERENCE FROM UNCERTAIN DATA USING MIXTURES

Therefore, given S, from Tchevichev inequality we can answer y ≅ y MSE ( S ) ± 2e MSE ( S )
with a confidence level above 75%. When the shape of p(y|S) is complex it must be reported explicitly (the point estimator y ≅ y MSE ( S ) only makes sense if p(y|S) is unimodal).
Example 10: Nonlinear regression. Fig. 11 shows the mixture components and regression
lines (with a confidence band of two standard deviations) obtained in a simple example of
nonlinear dependence between two variables. In this case the joint density can be adequately
approximated by 3 or 4 components: MSE (1 component) = 0.532, MSE (2 comp.) = 0.449,
MSE (3 comp.) = 0.382, MSE (4 comp.) = 0.381.

(a)
(b)
Figure 11. Nonlinear regression example: (a) 2 components, (b) 4 components.

When the target y is symbolic we must compute the posterior probability of each value. In this
case all the λdi ,r = 0 and the νid,r = µ id are the possible values ω taken by y = z d . Collecting together all the νid,r = ω, as in (8), eq. (15) can be written as:

p ( y| S ) = ∑ ∑ α i ,r ,ω T ( y , ω )
ω

i ,r

where α i ,r ,ω are the coefficients of the impulses located at ω. The posterior probability of each
value is:

q ω ≡ P{ y = ω| S} = ∑ α i ,r ,ω
i ,r

For instance, the minimum error probability estimator (EP) is:

y EP ( S ) = argmax

ω

qω

and any desired rejection threshold can be easily established. We can reject the decision if the entropy of the posterior, H = –Σω qω log qω, or the estimated error probability, E = 1- max qω, are too
high.
Example 11: Nonparametric Pattern Recognition. Fig. 12 shows a bivariate data set with elements from two different categories, represented as the value of an additional symbolic attribute. The joint density can be satisfactorily approximated by a 6-component mixture (Fig.
12.a). The decision regions when the rejection threshold was set to 0.9 are shown in Fig. 12.b.

185

RUIZ, LÓPEZ-DE-TERUEL & GARRIDO

Note that Statistical Pattern Classification usually start from an (implicit or explicit) approximation to the class-conditional densities. In contrast, we start from the joint density, from
which the class-conditional densities can be easily derived (Fig. 12.c).

(a)
(b)
(c)
Figure 12. Simple nonparametric 2–feature pattern recognition task and its 3–attribute
joint mixture model: (a) Feature space and mixture components. (b) Decision boundary.
(c) One of the class-conditional densities.

The computation of the optimum estimators for other loss functions is straightforward. Observe that the estimators are based on the combination of different rules, weighted by their degree
of applicability. This is a typical structure used by many other decision methods. In our case, since
the components of the joint density have independent variables the rules reduce to constants, the
simplest type of rule.
3.6 Examples of Elementary Pieces of Information
Some important types of elementary observations srj about z j are shown, including the corresponding likelihoods βij,r and modified marginals ψ ij,r ( z j ) (j=d) required in expression (15).
Exact information: srj = z j . The observation is modeled by an impulse:

p( srj | z j ) =

T( srj , z j ) = δ( srj − z j ) . Therefore:
β ij,r = T( srj , µ ij , σ ij )
ψ ij,r ( z j ) = T( z j , srj )
The contribution βij,r of exact information about the input attribute z j is the standard likelihood p( z j | Ci ) of the observed value z j in each component. On the other hand, if we acquire
exact information about a target attribute z j (when there is only one (R=1) elementary observation
and s j = z j ) then the inference process is trivially not required: p( z j | S ) = δ( z j − s j ) .
Gaussian noise with bias ηrj and standard deviation ε rj : The observation is modeled by a 1component mixture: p( srj | z j ) = T( srj , z j + ηrj , ε rj ) , which can also be expressed as a 95% confidence interval z j ≅ srj + ηrj ± 2ε rj . From property (2-2):

186

PROBABILISTIC INFERENCE FROM UNCERTAIN DATA USING MIXTURES

β ij,r = T( srj , µ ij − ηrj , (σ ij ) 2 + ( ε rj ) 2 )
The effect of a noisy input z j ≅ srj ± 2ε rj is equivalent to the effect of an exact input z j = srj
in a mixture with components of larger variance: σ ij → (σ ij ) 2 + ( ε rj ) 2 . Uncertainty spreads the
effect of the observation, increasing the contribution of distant components.
Example 12: Fig. 13.a shows a simple two-attribute domain approximated by a 3-component
mixture. We are interested in the marginal density of attribute x given different degrees of uncertainty ε in the input attribute y ≈ .4 ± 2ε, modeled by

p( s y | y ) = T( s y ,.4, ε ) . If ε = 0

we have the sharpest density (A) in Fig. 13.b, providing x≈–.4±.5. If ε = .25 we obtain density
(B) and x≈–.3±.7. Finally, if ε = .5 we obtain density (C) and x≈–.2±.8. Obviously, as the uncertainty in y increases, so does the uncertainty in x. The expected value of x moves towards
more distant components, which become more likely as the probability distribution of y expands. In this situation an interesting effect appears: the mode of the marginal density does not
change at the same rate than the mean. Uncertainty in y skews p(x). This effect suggests that
the optimum estimators for different loss functions are not equally robust against uncertainty.

A
B
C

(a)
(b)
Figure 13. Effect of the amount of uncertainty (see text). (a) Data set and 3-component
model. (b) p(x | uncertain y’s around 0.4).

j
j
For the output role, ψ i ,r ( z ) becomes the original marginal, modified in location and disper2
2
2
sion towards srj according to the factor γ = (σ ij ) / [(σ ij ) + ( ε rj ) ] , which quantifies the relative
importance of the observation:

ψ ij,r ( z j ) = T(z j , γ ( srj − η rj ) + (1 − γ )µ ij , γ 1/ 2 ε rj )
Missing data. When there is no information about the j-th attribute, srj = {z j = ?} , the observation can be modeled by p( srj | z j ) = constant or, equivalently, p( srj | z j ) = T( srj , a , b) with a
arbitrary and b → ∞. All the components contribute with the same weight:

β ij,r = p( z j = anything| Ci ) ∝ constant ≡ 1
If the target is missing the ψ ij,r ( z j ) reduce to the original marginal components:

187

RUIZ, LÓPEZ-DE-TERUEL & GARRIDO

ψ ij,r ( z j ) = T( z j , µ ij , σ ij ) = p( z j | Ci )
Arbitrary uncertainty. In general, any unidimensional relative likelihood function can be approximated by a mixture of generalized normals, as shown in Example 6, where βij,r and ψ ij,r ( z j )
are given respectively by eqs. (11) and (12).
Intervals. Some useful functions cannot be accurately approximated by a small number of normal
components. A typical example is the indicator function of an interval, used to model an uncertain
observation where all the values are equally likely: srj = {z j ∈ (a, b)} . If z j is only considered as
input, we can use the shortcut β ij,r = Fi j (b) − Fi j (a ) , where Fi j ( z j ) is the cumulative distribution of the normal marginal component p( z j | Ci ) . Unfortunately, the expression for ψ ij,r ( z j ) ,
required for z j considered as output, may not be so useful for computing certain optimum estimaj
j
j
tors. ψ i ,r ( z ) is the restriction of p(z j|Ci) to the interval (a,b) and normalized by βi ,r .
Disjunction and conjunction of events. Finally, standard probability rules are used to build
structured information from simple observations: if from subjective judgments or objective evidence we ascribe relative degrees of credibility θ rj to several observations srj about z j , the overall
j
j j
likelihood becomes β i = Σ r θ r β i ,r . In particular, if s j = {z j = ω 1 OR z j = ω 2 } and the two

possibilities are equiprobable then β ij = p(ω 1 | Ci ) + p(ω 2 | Ci ) . Analogously, conjunctions of
events translate to multiplication of likelihood functions.
3.7 Summary of the Inference Procedure
Once the domain p(z) has been adequately modeled in the learning process (as explained in Section
4), the system enters the inference stage over new, partially specified objects. From the parameters
of the domain p(z) ( Pi , µ ij and σ ij ) and the parameters of the model of the observation p(S|z)
( π r , srj and ε rj ), we must obtain the parameters β ij,r , ν id,r and λdi ,r of the desired marginal posterior densities and estimators. The inference procedure comprises the following steps:


Compute the elementary likelihoods βij,r , using eq. (11).



Obtain the product βi ,r for each conjunction sr and component Ci , using eq. (14).



Normalize Pi π r β i ,r to obtain the coefficients α i ,r of the posterior, using eq. (16).



Choose the desired target attributes y = { z d } and compute the parameters νid,r , and

λdi ,r of the modified component marginal densities ψ id,r ( z d ) using eq. (12).


Report the joint posterior density of y. Show graphs of the posterior marginal densities
of the desired attributes z d using eq. (15). Provide optimum (point, interval, etc.) estimators using eq. (17).

Example 13: Iris Data. The inference procedure is illustrated over the well known Iris benchmark: 150 objects represented by four numeric features (x, y, z and w) and one symbolic category U ∈ {U1 (setosa), U2 (versicolor), U3 (virginica)}. The whole data set was divided into
two disjoints subsets for training and validation. The joint density can be satisfactorily approxi-

188

PROBABILISTIC INFERENCE FROM UNCERTAIN DATA USING MIXTURES

mated (see Section 4) by a 6–component mixture (the error rate classifying U in the validation
set without rejection was 2.67%). Fig. 14 shows two projections of the 150 examples and the location of the mixture components learned from the training subset. The parameters of the mixture are shown in Table 3.

(a)
(b)
Figure 14. Two views of the Iris examples and the components of the joint density mixture model. U1: white, U2: black, U3: gray. (a) Attributes x, y (b) Attributes z, w.

i

Pi

1
2
3
4
5
6

0.15
0.13
0.21
0.18
0.15
0.17

µ ix

σ ix

µ iy

σ iy

µ iz

σ iz

7.13 0.48 3.12 0.34 6.17 0.45
5.48 0.41 2.50 0.28 3.87 0.32
6.29 0.39 2.93 0.27 4.59 0.20
4.75 0.23 3.25 0.23 1.42 0.21
5.36 0.26 3.76 0.29 1.51 0.16
6.16 0.42 2.77 0.28 5.22 0.30
Table 3. Parameters of the Iris Data Joint Density Model

µ iw

σ iw

2.18
1.20
1.45
0.19
0.32
1.94

0.20
0.21
0.14
0.05
0.10
0.23

P{U1|Ci} P{U2|Ci} P{U3|Ci}

0
0
0
1
1
0

0
0.93
1
0
0
0.00

Table 4 shows the results of the inference process in the following illustrative situations:
Case 1: Attribute z is known: S = {z = 5}.
Case 2: Attributes x and U are known: S = {(x = 5.5) AND (U=U2)}.
Case 3: Attribute x is uncertain: S = {x ≅ 7±1}.
Case 4: Attributes x and w are uncertain: S = {(x ≅ 7±1) AND (w ≅ 1±0.5)}. Note that uncertainty decreases when more information is supplied (compare with Case 3).
Case 5: Structured query expressed in terms of logical connectives over uncertain elementary
events: S = {[(z ≅ 1±3) OR (z ≅ 7±3)] AND [(U = U1) OR (U = U2)]}.

189

1
0.07
0.00
0
0
1

RUIZ, LÓPEZ-DE-TERUEL & GARRIDO

CASE
1
2
3
4
5

INPUT
OUTPUT
INPUT
OUTPUT
INPUT
OUTPUT
INPUT
OUTPUT
INPUT
OR

OUTPUT

X
?
6.2±0.9
5.5
5.5
7±1
6.7±0.9
7±1
6.5±0.7
?
?

y
?
2.8±0.6
?
2.6±0.6
?

z
5.0
5.0
?
4.0±0.8
?

w
?
1.8±0.6
?
1.3±0.4
?

3.0±0.7
?

5.3±1.8
?

2.9±0.6
?
?

1.8±0.8
1±0.5
1.3±0.3
?
?

5.3±1.2

3.3±0.9

4.5±0.8
1±3
7±3
2±3

(approx.
unimodal)

(unimodal)

(bimodal)

0.5±1

U
?

U2: 22% U3: 78%
U2: 100%
U2: 100%
?
U2: 36% U3: 63%
?
U2: 95% U3: 5%
U1: 50% U2: 50%
U1: 50% U2: 50%
U1: 75% U2: 25%

(bimodal)

Table 4. Some Inference Results Over the IRIS Domain

The consistency of the results can be visually checked in Fig. 14. Finally, Table 5 shows the
elementary likelihoods

i
1
2
3
4
5
6

βix,1

βiy,1

βi,j r of Case 5, illustrating the essence of the method.

βiz,1

βiw,1

βUi ,1

βi ,1

βix,2

1
1
1
0
1
.001
0
1
1
1
1
.045
.47 .02
1
1
1
1
.016
.50 .01
1
1
1
1
.254
.50 .13
1
1
1
1
.250
.50 .13
1
1
1
0
1
.006
0
Table 5. Elementary likelihoods in Case 5 from Table 4.

βiy,2
1
1
1
1
1
1

βiz,2

βiw,2

βUi ,2

βi ,2

.221
.032
.074
3E-4
4E-4
.132

1
1
1
1
1
1

0
.47
.50
.50
.50
0

0
.02
.04
.00
.00
0

3.8 Independent Measurements
One of the key features of the MFGN framework is the ability to infer over arbitrary relational
knowledge about the attributes, in the form of a likelihood function adequately approximated by a
mixture model with the structure of eq. (9). For instance, we could answer questions as: “what happens to z d when z i tends to be less than z j ?” (i.e., when p(S|z) is high in the region z i − z j < 0 ).
However, there are situations where the observations over each single attribute z j are statistically
independent: we have information about attributes (e.g. z i is around a and z j is around b) but not
about attribute relations. We will pay attention to this particular case because it illustrates the role
of the main MFGN framework elements. Furthermore, many practical applications can be satisfactorily solved under the assumption of independent measurements or judgments. In this case, the
likelihood of the available information can be expressed as the conjunction of n “marginal” observations s j about z j :

p ( S | z ) = ∏ p( s j | z j )
j

190

(18)

PROBABILISTIC INFERENCE FROM UNCERTAIN DATA USING MIXTURES

This means that the sum of products in equation (9) is “complete”, i.e., it includes all the elements
in the N-fold cartesian product of attributes:

p( S | z ) = ∏ ∑ π rj T( z j , srj , ε rj )
j

r

where Π j π rj = π r . This factored likelihood function can be considered also as a 1-component
mixture (with R=1 in (9) and s j ≡ s1j ) where the marginal observation models are allowed to be
mixtures of generalized normals: p( s j | z j ) = Σ r ' π rj' T( z j , srj' , ε rj ' ) . In this case we can even think
1
1
of “function valued” attributes z ≅ [ f ( z ),..., f n ( z n )] , where f j ( z j ) ≡ p( s j | z j ) models the

range and relative likelihood of the values of z j . Loosely speaking, attributes with concentrated
f j ( z j ) may be considered as inputs, and attributes with high dispersion play the role of outputs.
Since y is conditionally independent of s x given Ci , the posterior can be obtained from the expansion:

p( y| S ) = ∑ p( y| S , Ci ) P{Ci | S} = ∑ p( y| Ci , s y ) P{Ci | S}
i

(19)

i

The interpretation of (19) is straightforward. The effect of sx over y = {zd} must be computed
through x = {zo} and the components Ci . Then, a simple Bayesian update of p( y| s x ) as a new
prior is made using s y (see Fig. 15).

Ci
z1

αi

p( z j | Ci )

zd
ψ id ( z d )

s1

...

β
...

sd

j
i

zj
p( s j | z j )

sj

...

Figure 15. Structure of the MFGN inference process from independent pieces of information. In this case, the likelihood function is also factorizable. The data flow in the inference process is shown by dotted arrows.

191

RUIZ, LÓPEZ-DE-TERUEL & GARRIDO

4. Learning from Uncertain Information
In the previous section, we have described the inference process from uncertain information under
the MFGN framework. Now we will develop a learning algorithm for the model of the domain,
where the training examples will be also uncertain. Specifically, we must find the parameters Pi ,

µ ij , σ ij (or ti j,ω ) of a mixture with structure (7) to approximate the true joint density p(z) from a
training i.i.d. random sample {z(k)}, k=1..M, partially known through the associated likelihood
functions {S(k)} with structure (9).
4.1 Overview of the EM Algorithm
Maximum Likelihood estimates for the parameters of mixture models are usually computed by the
well-known Expectation-Maximization (EM) algorithm (Dempster, Laird and Rubin 1997, Redner
and Walker 1984, Tanner 1996), based in the following idea. In principle, the maximization of the
training sample likelihood J = Π k p( z ( k ) ) is a mathematically complex task due to the product of
sums structure. However, note that J could be conveniently expressed for maximization if the components that generated each example were known (this is called “complete data” in EM terminology). The underlying credit assignment problem disappears and the estimation task reduces to several uncoupled simple maximizations. The key idea of EM is the following: instead of maximizing
the complete data likelihood (which is unknown), we can iteratively maximize its expected value
given the training sample and the current mixture parameters. It can be shown that this process
eventually achieves a local maximum of J.
Instead of a rigorous derivation of the EM algorithm, to be found in the references (see especially McLachlan and Krishnan, 1997), we will present here a more heuristic justification which
provides insight for generalizing the EM algorithm to accept uncertain examples. We will review
first the simplest case, where no missing or uncertain values are allowed in the training set. The
parameters of the mixture are conditional expectations:

E z |Ci {g ( z )| Ci )} = ∫ g ( z ) p( z| Ci ) dz
Z

(20)

2
2
In particular, µ ij = E{z j | Ci } , (σ ij ) = E{( z j − µ ij ) | Ci } and ti j,ω = E{I {z j = ω}| Ci } . The

mixture proportions are Pi = E{ P{Ci | z} } .
We rewrite the conditional expectation (20) using Bayes Theorem in the form of an unconditional expectation:

E z |Ci {g ( z )| Ci )} = ∫ g ( z ) P{Ci | z} p( z ) / P{Ci } dz =

(21)

= E z {g ( z ) P{Ci | z}} / Pi

(22)

Z

The EM algorithm can be interpreted as a method to iteratively update the mixture parameters
using expression (22) in the form of an empirical average over the training data4. Starting from a
tentative, randomly chosen set of parameters, the following E and M steps are repeated until the
4

Expression (21) can be also used for iterative approximation of explicit functions which are not indirectly known by
i.i.d. sampling (e.g., subjective likelihood functions sketched by the human user, as in Example 4). In this case p(z) is set
to the target function and P{Ci| z} is computed from the current mixture model.

192

PROBABILISTIC INFERENCE FROM UNCERTAIN DATA USING MIXTURES

total likelihood J no longer improves (the notation (expression)(k) means that (expression) is computed with the parameters of example z(k)):
( )
( )
(E) Expectation step. Compute the probabilities qi k ≡ P{Ci | z k } that the k-th example has been
generated by the i-th component of the mixture:

qi( k ) ← p( z ( k ) | Ci ) P{Ci } / p( z ( k ) )
(M) Maximization step. Update the parameters of each component using all the examples, weighted
by their probabilities qi( k ) . First, the a priori probabilities of each component:

Pi ←

1
∑ q (k )
M k i

Then, for continuous variables, the mean values and standard deviations in each component:

1
MPi

µ ij ←
(σ ij ) 2 ←

1
MPi

∑ [q

z j ]( k )

i

k

∑ [q

( z j ) 2 ]( k ) − (µ ij ) 2

i

(23)

k

and for symbolic variables, the probabilities of each value:

ti j,ω ←

1
MPi

∑ [q

I {z j = ω}]( k )

i

k

4.2 Extension to Uncertain Values
In general, in the MFGN framework we do not know the true values z j of the attributes in the
training examples, required to compute g ( z ) P{Ci | z} in the (empirical) expectation (22). Instead,
we will start from uncertain observations S ( k ) about the true training examples z
likelihood functions expressed as mixtures of generalized normals:

(k )

, in the form of

p( S ( k ) z ( k ) ) = ∑ P{S ( k ) sr( k ) } p( sr( k ) z ( k ) )
r

Therefore, we must express the expectation (22) over p(z) as an unconditional expectation
over p(S), the distribution which generates the available information about the training set. This
can be easily done by expanding p( z| Ci ) in terms of S:

E z |Ci {g ( z )| Ci )} = ∫ g ( z ) p( z| Ci ) dz
Z

[ ∫ p ( z | S , C ) p ( S | C ) dS ] dz
= ∫ [∫ g ( z ) p( z| S , C ) dz ] P{C | S} p( S ) dS / P{C }
=

S

Z

∫

Z

g ( z)

i

S

i

i

i

If we define

193

i

(24)

RUIZ, LÓPEZ-DE-TERUEL & GARRIDO

Γi ( S ) ≡ E z |S ,Ci {g ( z )| S , Ci )} = ∫ g ( z ) p( z| Ci ) p( S | z ) dz / p( S | Ci )
Z

then the parameters of p(z) can be finally written5 as an unconditional expectation over the observable p(S) in a form similar to eq. (22):

E z |Ci {g ( z )| Ci )} = E S {Γi ( S ) P{Ci | S}} / Pi

(25)

This expression justifies an extended form of the EM algorithm to iteratively update the parameters of p(z) by averaging Γi ( S ) P{Ci | S} over the available training information { S ( k ) }
drawn from p(S). This can be considered as a numerical/statistical method for solving p(z) in the
integral equation:

∫

Z

p ( S | z ) p ( z ) dz = p ( S )

Note that we cannot approximate p(S) as a fixed mixture in terms of p( S | Ci ) and then computing back the corresponding p( z| Ci ) because, in general, p( S | z ) will be different for the different training examples. For the same reason, elementary deconvolution methods are not directly
applicable.
This kind of problem is addressed by Vapnik (1982, 1995) to perform inference from the result of
“indirect measurements”. This is an ill-posed problem, requiring regularization techniques. The
proposed extended EM algorithm can be considered as a method for empirical regularization, in
which the solution is restricted to be in the family of mixtures of (generalized) gaussians. EM is
also proposed by You and Kaveh (1996) for regularization in the context of image restoration.
The interpretation of (25) is straightforward. Since we do not know the exact z required to
approximate the parameters of p(z) by empirically averaging g ( z ) P{Ci | z} , we obtain the same
result by averaging the corresponding Γi ( S ) P{Ci | S} in the S domain, where Γi ( S ) plays the
role of g(z) in (22). As z is uncertain, g(z) is replaced by its expected value in each component
given the information about S. In particular, if there is exact knowledge about the training set at( )
tributes ( S ( k ) = z k , i.e., R = 1 and the marginal likelihoods are impulses) then (25) reduces to
(22). Fig. 16. illustrates the approximation process performed by the extended version of the EM
algorithm in a simple univariate situation.
It is convenient to develop a version of the proposed Extended EM algorithm for uncertain
training sets, structured as tables of (sub)cases × (uncertainly valued) variables (see Fig. 17).
First, let us write eq. (24) expanding S in terms of its components sr:

p( z| Ci , S ) P{Ci | S ) = p( z , Ci | S )
=

∑ p( z, C | s ) P{s | S} = ∑ p( z| C , s ) P{C | s } P{s | S}
i

r

r

r

i

r

i

r

r

r

Therefore

Γi ( S ) P{Ci | S} = ∑ Γi ,r ( s r ) P{Ci , s r | S}
r

This result can be also obtained from the relation Ez{w(z)} = ES{ Ez|S{w(z)| S} } for w(z) ≡ g(z) P{Ci|z} and Bayes Theorem.

5

194

PROBABILISTIC INFERENCE FROM UNCERTAIN DATA USING MIXTURES

(a)

(b)
(d)

(c)

Figure 16. The extended EM algorithm iteratively reduces the (large) difference between
(a) the true density p(z), and (b) the mixture model pˆ ( z ) , indirectly through the (small)
discrepancies between (c) the true observation density p(S) and (d) the modeled observation density pˆ ( S ) . In real cases p(S) must be estimated from a finite i.i.d. sample
{S(k)}.

S(1)

s1(1)
s2(1)
s(2)
s1(3)
s2(3)
s3(3)
...

.4
.6
1
.2
.5
.3
...

S(2)
S(3)

π (r k )

S(r)

( sr1 , ε 1r ) ( k )

( srj , ε rj ) ( k )

...

...

...
...
Figure 17. Structure of the uncertain training information for the Extended EM Algorithm. The coefficients

π (r k ) are normalized for easy detection of the rows included in

each uncertain example. When z

π

(k )

= 1 and all the

(k)

(k)

is not uncertain, S

reduces to a single row with

ε = 0.
j

Using the notation introduced in (12),

Γi ,r ( s r ) ≡ E z |sr ,Ci {g ( z )| s r , Ci } =

∫

Z

g ( z ) p( z| s r , Ci ) dz =

∫

Z

P{Ci , s r | S} = P{Ci | s r } P{s r | S} = α i ,r
we can write (25) as:

195

g ( z )∏ ψ ij,r ( z j ) dz
j

RUIZ, LÓPEZ-DE-TERUEL & GARRIDO



E z|Ci {g (z ) | Ci } = E S ∑ α i ,r ∫ g (z )∏ ψ ij,r ( z j )dz / Pi
Z
j
 r

In the MFGN framework the contributions Γi ,r ( s r ) P{Ci , s r | S} to the empirical expected
values required by the Extended EM algorithm can be obtained again without numeric integration.
We only need to consider the case g(z) = z j to compute the means µ ij and probabilities ti j,ω , and
g(z) = ( z j )2 for the deviations σ ij . From (12) we already know an explicit expression for the parameters of ψ ij,r ( z j ) = T( z j , ν ij,r , λ ji ,r ) . Hence:

∫

Z

z j Ψi ,r ( z ) dz =

∫ (z
Z

j

∫

Z

z j ψ ij,r ( z j )dz j = ν ij,r

) 2 Ψi ,r ( z ) dz = ( ν ij,r ) 2 + ( λ ji ,r ) 2

In conclusion, the steps of the Extended EM algorithm are as follows:
(E) Expectation step. Compute all the elementary likelihoods of the training set:

(

β ij,r( k ) = T srj , µ ij , (σ ij ) 2 + ( ε rj ) 2

)

(k )

(26)

( )
( )
Obtain the likelihood of each conjunction sr k of example S k in component Ci:

β i(,kr) = ∏ β ij,r( k )
j

( )
Obtain the total likelihood of example S k :

β ( k ) ≡ p( S ( k ) ) = ∑ ∑ Pi π r( k ) β i(,kr )
i

r

( )
( )
( )
Compute the probabilities qi ,kr ≡ P{Ci , s r k | S k } that the r-th component of the k-th exam-

ple has been generated by the i-th component of the mixture:

qi(,kr ) ← α i(,kr) = Pi π r ( k ) β i(,kr) / β ( k )
(M) Maximization step. Update the parameters of each component Ci using all the components

s r( k ) of all the examples weighted with their probabilities qi(,kr ) . First, the prior probabilities of each
component:

Pi ←

1
M

∑∑ q
k

(k )
i ,r

r

Then the mean value and standard deviation in each component:

µ ij ←

1
MPi

∑ ∑ [q
k

r

196

i ,r

νij,r

]

(k )

PROBABILISTIC INFERENCE FROM UNCERTAIN DATA USING MIXTURES

(σ ij ) 2 ←

1
MPi

∑ ∑ [q
k

i ,r

]

[( νij,r ) 2 + (λ ij ,r ) 2 ]

r

(k )

− (µ ij ) 2

(27)

For symbolic variables under representation (8) we may use:

βij,r( k ) = ∑ P{srj = ω}( k ) ti j,ω

(26)’

ω

ti j,ω ←

1
MPi

∑ ∑ [q
k

i ,r

P{srj = ω} t i j,ω / β ij,r

r

]

(k )

(27)’

Consider the particular case in which the attributes in the training examples are contaminated
with unbiased Gaussian noise. The likelihood of the uncertain observations is modeled by 1( )
( )
( )
( )
( )
( ) 2
component mixtures: p( s k | z k ) = Π j T( z j k , s j k , ε j k ) , where (ε j k ) is the variance of
the measurement process over z j ( k ) which obtains the observed value s j ( k ) . This can be also ex( )
( )
( )
pressed as a confidence interval z j k ≅ s j k ± 2ε j k . In this case, the basic EM algorithm (23)
( )
can be easily modified to take into account the effect of the uncertainties ε j k . In the E step, com( )
pute qi k using the following deviations:

σ ij ← (σ ij ) 2 + ( ε j ( k ) ) 2
and, in the M step, apply the substitution:

z j ( k ) ← γ s j ( k ) + (1 − γ ) µ ij

[

( z j ( k ) ) 2 ← γ s j ( k ) + (1 − γ )µ ij

] + γ [ε ]
2

j( k ) 2

where

(σ ij ) 2
γ= j 2
(σ i ) + ( ε j ( k ) ) 2
measures the relative importance of the observed s j k for computing the new µ ij and σ ij .
The previous situation illustrates how missing values must be processed in the learning stage.
( )
j (k )
If z
is exact then ε j k = 0 and γ = 1, so the original algorithm (23) is not changed. In the other
( )
extreme, if z j ( k ) is missing, which can be modeled by ε j k ≡ ∞, we get γ = 0 and therefore the
( )
observation s j k does not contribute to the new parameters at all. The correct procedure to deal
with missing values in the MFGN framework is simply omitting them in the empirical averages.
Note that this fact arises from the factorized structure of the mixture components, providing conditionally independent attributes. Alternative learning methods require a careful management of
missing data to avoid biased estimators (Ghahramani & Jordan 1994).
( )

4.3 Evaluation of the Extended EM Algorithm
We have studied the improvement of the parameter estimations when the uncertainty of the observations, modeled by likelihood functions, is explicitly taken into account. The proposed Extended

197

RUIZ, LÓPEZ-DE-TERUEL & GARRIDO

EM is compared with the EM algorithm over the "raw" observations (Basic EM), which ignores the
likelihood function and typically uses just its average value (e.g., given x≅8±2, Basic EM uses
x=8). We considered a synthetic 3-attribute domain with the following joint density:
p(x,y,w) = 0.5 (x,0,2) (y,0,1) (w,white)
+ 0.5 (x,2,1) (y,2,2) (w,black)

TT

TT

TT

Different learning experiments were performed with varying degrees of uncertainty. In all
cases the training sample size was 250. All trained models had the same structure as the true density (2 components), since the goal of this experiment is to measure the quality of the estimation
with respect to the amount of uncertainty, without regard of other sources of variability such as
local minima, alternative solutions, etc., which are empirically studied in Section 5. Table 6 shows
the mixture parameters obtained by the learning algorithms. Fig. 18 graphically shows the difference between Extended and Basic EM in some illustrative cases.
Case 0: Exact Data (Fig. 18.a).
Cases m %: Results of the Extended EM learning algorithm when there is a m % rate of missing
values in the training data.
Case 1: Basic EM when attribute y is biased +3 units with probability 0.7. Case 2: Extended EM
algorithm over Case 1 (see Fig. 18.b). Here, the observed value is sy=y+3 in 70% of the samples
and sy=y in the rest. In all samples, Basic EM uses the observed value sy and Extended EM uses
the explicit likelihood function f(y) = 0.3 δ(y–sy) + 0.7 δ(y–(sy–3)).
Case 3: Basic EM when attributes x and y have Gaussian noise with σ = 0.5 and w is changed with
probability 0.1. Case 4: Extended EM algorithm over Case 3.
Case 5: Basic EM when x and y have Gaussian noise with σ = 1 and w is changed with probability
0.2. Case 6: Extended EM algorithm over Case 5 (see Fig. 18.c).
Case 7: Basic EM when x and y have Gaussian noise with σ = 2 and w is changed with probability
0.3. Case 8: Extended EM algorithm over Case 7 (see Fig. 18.d).

T

Case 9: Extended EM when values y>3 are missing (censoring). Case 10: Extended EM over Case
9 when the missing y values are assumed to be distributed as
(y, 4, 1), providing some additional information on the data generation mechanism.
Table 6 and Fig. 18 confirm that for small amounts of deterioration in relation to the sample
size, the estimates computed by the basic EM Algorithm over the “raw” observed data are similar
to those obtained by the Extended EM algorithm (e.g., Cases 3 and 4). However, when the data sets
are moderately deteriorated the true joint density can be correctly recovered by Extended EM using
the likelihood functions of the attributes instead of the raw observed data (e.g., Cases 5 and 6, Fig.
18.c). Finally, when there is a very large amount of uncertainty with respect to the training sample
size the true joint density cannot be adequately recovered (e.g., Cases 7 and 8, Fig. 18.d).

198

PROBABILISTIC INFERENCE FROM UNCERTAIN DATA USING MIXTURES

(a)

(b)

(c)
(d)
Figure 18. Illustration of the advantages of the Extended EM algorithm (see text). (a)
Case 0 (exact data). (b) Cases 1 and 2 (biased data). (c) Cases 5 and 6 (moderated noise).
(d) Cases 7 and 8 (large noise). All figures show the true mixture components (gray ellipses), the available raw observations (black and white squares), the components estimated by Basic EM from the raw observations (dotted ellipses) and the components estimated by Extended EM taking into account the likelihood functions of the uncertain
values (black ellipses).

Note that the ability to learn from uncertain information suggests a method to manage non
random missing attributes (e.g., censoring) (Ghahramani & Jordan 1994) and other complex
mechanisms of uncertain data generation. As illustrated in Case 9, if the missing data generation
mechanism depends on the value of the hidden attribute, it is not correct to assign equal likelihood
to all components. In principle, statistical studies or other kind of knowledge may help to ascertain
the likelihood of the true values as a function of the available observations. For instance, in Case 10
we replaced the missing attributes of Case 9 by normal likelihoods y ≅ 4±2 (i.e, “y is high”), improving the estimates of the mixture parameters.

199

RUIZ, LÓPEZ-DE-TERUEL & GARRIDO

Case

P1

µ1x

µ1y

σ1x

σ1y

t1,wwhite

µ 2x

µ 2y

true
.5
0
0
2
1
1
2
2
0
.48 -.04 .03 2.11 1.00 1.00 2.09 1.83
20%
.48 .16 -.03 1.91 1.01 0.96 2.31 2.09
40%
.49 .14 -.16 1.78 .99 0.95 2.39 2.29
60%
.45 .02 -.29 2.50 .78 1.00 1.86 2.01
80%
.49 -.11 1.69 2.21 1.73 .50 1.91 0.31
1
.48 .06
.90 1.88 1.73 1.00 1.88 2.98
2
.48 -.04 .05 1.90 .92 1.00 1.98 1.97
3
.47 .02
.09 1.60 1.02 .87 2.00 1.78
4
.49 .27 -.08 1.97 .90
.70 2.10 2.06
5
.43 -.04 -.18 2.40 1.48 .82 1.85 1.52
6
.54 -.07 -.02 1.97 1.09 .56 1.93 2.11
7
.46 .15 -.16 2.73 2.53 .31 1.94 1.62
8
.79 .87
.08 2.09 1.52 .51 1.96 3.61
9
.48 .32 -.02 1.77 1.10 1.00 1.92 0.67
10
.45 .00
.03 2.20 1.01 1.00 2.13 1.55
Table 6. Parameter Estimates from Uncertain Information (see text)

σ 2x

σ 2y

t2,wblack

1
1.00
.88
.94
1.03
1.14
.96
1.01
1.14
1.01
1.52
.85
2.47
0.87
0.94
1.04

2
2.08
2.10
2.14
1.77
0.68
2.40
1.90
2.07
1.94
2.33
1.69
2.90
1.21
1.22
1.77

1
1.00
1.00
1.00
1.00
0.47
1.00
1.00
0.85
0.71
.80
.62
.29
.54
1.00
1.00

Example 14: Learning from examples with missing attributes has been performed over the IRIS
domain to illustrate the behavior of the MFGN framework. The whole data set was randomly
divided into two subsets of equal size for training and testing. 5-component mixture models
were obtained and evaluated, combining missing data proportions of 0% and 50%. The error
prediction on attribute U (plant class) was the following:

missing attributes

training set
0%
0%
50%
50%

test set
0%
50%
0%
50%

prediction error
2.7%
12.0%
4.0%
18.7%

In the relatively simple IRIS domain, the performance degradation due to 50% missing attributes is much greater in inference than in learning stage. The Extended EM algorithm is able
to correctly recover the overall structure of the domain from the available information.

4.4 Comments
Convergence of the EM Algorithm is very fast, requiring no adjustable parameters such as learning
rates. The algorithm is robust with respect to the random initial mixture parameters: bad local
maxima are not frequent and alternative solutions are usually equally acceptable. All the examples
contribute to all the components, which are never wasted by unfortunate initialization. For a fixed
number of components, the algorithm progressively increases the likelihood J of the training data
until a maximum is reached. When the number of components is incremented the maximum J also
increases, until a limit value is obtained that cannot be improved using extra components (Fukunaga 1990). Some simple heuristics can be incorporated to the standard Expectation-Maximization
scheme to control the value of certain parameters (e.g., lower bounds can be established for variances) or the quality of the model (e.g., mixture components can be eliminated if their proportions
are too small).
In our case, factorized components are specially convenient because matrix inversions are not
required and, what is more important, uncertain and missing values can be correctly handled in a

200

PROBABILISTIC INFERENCE FROM UNCERTAIN DATA USING MIXTURES

simple and unified way, for heterogeneous attribute sets. It is not necessary to provide models for
uncertain attribute correlations since no covariance parameters must be estimated. Finally, the
training sample size must be large enough in relation to both the degree of uncertainty of the examples and the complexity of the joint density model in order to obtain satisfactory approximations.
On the other hand, the number of mixture components required for a satisfactory approximation to the joint density must be specified. A pragmatic option is the minimization of the experimental estimation cost over the main inference task, if it exists. For instance, in regression we
could increase the number of components until an acceptable estimation error is obtained over an
independent data set (cross-validation). The same idea applies to pattern classification: use the
number of components that minimizes the error rate over an independent test set. However, one of
the main advantages of the proposed method is the independence between the learning stage and
the inference stage, where we can freely choose and dynamically modify the input and output role
of the attributes. Therefore, a global validity criterion is desirable. Some typical validation methods
for mixture models are reviewed in McLachlan & Basford (1988); the standard approach is based
on likelihood ratio tests on the number of components. Unfortunately, this method does not validate
the mixture itself, only selects the best number of components (DeSoete 1993).
Since the MFGN framework provides an explicit expression for the model p(z), we can apply
statistical tests of hypothesis over an independent sample T taken from the true density (e.g. a subset of the examples reserved for testing) to find out if the obtained approximation is compatible
with test data. If the hypothesis H = {T comes from p(z)} is rejected, then the learning process must
continue, possibly increasing the number of components. It is not difficult to build some statistical
tests, e.g. over moments of p(z), because their sample means and variances can be directly obtained.
However, as data sets usually include symbolic and numeric variables, we have also developed a
test on the expected likelihood of the test sample, which measures how well p(z) “covers” the examples. The mean and variance of p(z) can be easily obtained using the properties of generalized
normals. Some experiments over simple univariate continuous densities show that this test is not
very powerful for small sample sizes, i.e. incompatibility is not always detected, while other standard tests significantly evidence rejection. Nevertheless, clearly inaccurate approximations are
detected, results improve as the sample size increases and the test is valid for data sets with uncertain values.
The Minimum Description Length (Li & Vitànyi 1993) principle can be also invoked to select
the optimum number of components by trading-off the complexity of the model and the accuracy in
the description of the data.

201

RUIZ, LÓPEZ-DE-TERUEL & GARRIDO

5. Discussion and Experimental Results
5.1 Advantages of Joint Models
Most inductive inference methods compute a direct approximation of the conditional densities of
interest, or even obtain empirical decision rules without explicit models of the underlying conditional densities. In these cases, both the model and the learning stage depend on the selected input /
output role of the variables. In contrast, we have presented an inference and learning method based
on an approximation to the joint probability density function of the attributes by a convenient
parametric family (a special mixture model). The MFGN framework works as a pattern completion
machine operating over possibly uncertain information. For example, given a pattern classification
problem, the same learning stage suffices for predicting class labels from feature vectors and for
estimating the value of missing features from the observed information in incomplete patterns. The
joint density approach finds the regions occupied by the training examples in the whole attribute
space. The attribute dependences are captured at a higher abstraction level than the one provided by
strictly empirical rules for pre-established target variables. This property is extremely useful in
many situations, as shown in the following examples.
Example 15: Hints can be provided for inference over multivalued relations. Given the data
set and model from Example 10, assume that we are interested in the value of x for y = 0. We
obtain the bimodal marginal density shown in Fig. 19.a and the corresponding estimator x ≅
0.2 ± 1.4 which is, in some sense, meaningless. However, if we specify the branch of interest
of the model, inferring from y = 0 AND x ≅ -1±1 (i.e., “x is small”), we obtain the unimodal
marginal density in Fig. 19.b and the reasonable estimator x ≅ –0.8±0.5.

(a)
(b)
Figure 19. The desired branch in multivalued relations can be selected by providing
some information about the output values. (a) Bimodal posterior density inferred from
y=0. (b) Unimodal posterior density inferred from y = 0 and the hint “x is small”.

Example 16: Image Processing. The advantages of a joint model supporting inferences from
partial information on both inputs and outputs can be illustrated in the following application
with natural data (see Fig. 20). The image in Fig. 20.a is characterized by a 5-attribute density
(x, y, R, G, B) describing position and color of the pixels. A random sample of 5000 pixels was
used to build a 100-component mixture model. We are interested in the location of certain ob-

202

PROBABILISTIC INFERENCE FROM UNCERTAIN DATA USING MIXTURES

jects in the image. Figs. 20.b-f show the posterior density of the desired attributes given the following queries:


"Something light green". Fig. 20.b. Two groups can be easily identified in the posterior
density, corresponding to the upper faces of the green objects6. S = C1={x, y unknown;
R=110±50, G=245±10, B=160±50}.



"Something light green OR dark red". Fig. 20.c. We find the same groups as above and an
additional, more scattered group, corresponding to the red object. This greater dispersion
arises from the larger size of the red object and also from the fact that the R component of
dark red is more disperse than the G component of light green. S =Two equiprobable components with C1 as above and C2={x, y unknown; R=110±10, G=B=30±50}.



"Something light green on the right". Fig. 20.d. Here we provide partial information on the
output: S = C3={x=240±30; y unknown; R=110±50, G=245±10, B=160±50}



"Something white". Fig. 20.e. S = C4={x,y unknown; R=245±10, G=245±10, B=245±10}



"Something white, in the lower-left region, under the main diagonal (y<240-x)". Fig. 20.f.
Here we provide relational information on the attributes that can be modeled by S = 6 equiprobable components (note that in this case the posterior distribution contains 600 components, but it is still computationally manageable) =

{x=60±30, y=180±30, R=245±10, G=245±10, B=245±10}+
{x=60±30, y=120±30, R=245±10, G=245±10, B=245±10}+
{x=60±30, y=60±30, R=245±10, G=245±10, B=245±10}+
{x=120±30, y=120±30, R=245±10, G=245±10, B=245±10}+
{x=120±30, y=60±30, R=245±10, G=245±10, B=245±10}+
{x=180±30, y=60±30, R=245±10, G=245±10, B=245±10}
In all cases, the posterior density is consistent with the structure of the original image. The time
required to compute the posterior distribution is always lower than one second. Learning time
was of order of hours in a Pentium 100 system. Simpler models (25-component, obtained from
1000 random pixels) produced also acceptable results with much lower learning time. Furthermore, the EM algorithm can be efficiently parallelized.

On the other hand, when there is a large number of irrelevant attributes, the joint model strategy wastes resources to capture a proper probability density function along unnecessary dimensions. (This problem does not arise in the specification of a likelihood function, since only the relevant attributes explicitly appear in the model.) Joint modeling is appropriate for domains with a
moderated number of "meaningful" variables without fixed input / output roles.

6

Note that a sharp peak (a component with small dispersion) was obtained in the learning process, which also "transmits"
to the posterior density. This kind of artifacts are inocuous and can be easily removed by post processing.

203

RUIZ, LÓPEZ-DE-TERUEL & GARRIDO

(a)

(b)

(c)

(d)

(e)
(f)
Figure 20. Inference results for the image domain in Example 16. (a) source image.
(b) posterior density of attributes x-y given "Something light green". (c) the same for
"Something light green OR dark red". (d) for "Something light green on the right".
(e) for "Something white". (f) for "Something white, in the lower-left region, under the
main diagonal of the image (Y<240-X)"

5.2 Advantages of Factorization
The proposed methodology is supported by the general density approximation property of mixture
models. We use components with independent variables in order to make computations feasible in

204

PROBABILISTIC INFERENCE FROM UNCERTAIN DATA USING MIXTURES

the inference and learning stage. Factorized components can be imposed to a mixture model without loss of generality. Any statistical dependence between variables can be still captured, at the cost
of a possibly larger number of components in the mixture to achieve the required accuracy in the
approximation.
The simplicity of the “building block” structure is entirely compensated by an important saving in computation time. High-dimensional integrals are analytically computed from univariate
integrals and matrix inversions are avoided in the learning stage. Additionally, high-dimensional
domains can be easily modeled using a small number of parameters in each mixture component.
From the viewpoint of Computational Learning Theory (Vapnik 1995), models with a small number of adjustable parameters (actually, with low “expressive power”) have favorable consequences
for generalization.
Mixtures of factorized components are also used in Latent Class Analysis (DeSoete 1993), a
well-known unsupervised classification technique. It is assumed that the statistical dependences
between attributes can be fully explained by a hidden variable specifying the “latent class” of each
example. This method is similar to the Gaussian decomposition clustering algorithm mentioned in
Section 1, constrained to component-conditional attribute independence. However, our goal is not
unsupervised classification but obtaining an accurate and mathematically convenient expression for
the joint density of the variables, required to derive the desired estimators. The meaning of the
components is irrelevant, as long as the whole mixture is a good approximation to the joint density.
More expressive architectures, which combine mixture models with local dimensionality reduction, have been also considered: Mixtures of Linear Experts (Jordan & Jacobs 1994), Mixtures
of Principal Component Analyzers (Sung & Poggio 1998) or Mixtures of Factor Analyzers (Ghahramani & Hinton 1996, Hinton, Dayan, & Revow 1997). Unfortunately, the general kind of inference and learning from uncertain data considered in this work cannot be directly incorporated into
these architectures with the computational advantages demonstrated by the MFGN model.
The restriction to factorized components may produce undesirable artifacts in the approximations of certain domains learned from small training samples. Nevertheless, this problem always
occurs to any approximator when the structure of the building block does not match the “shape” of
the target function. In this case, many terms (or components, units, etc.) are required for a good
approximation and the associated parameters can be correctly adjusted only from a large training
sample. However, note that the complexity of the model should not be measured uniquely in terms
of the number of mixture components. The number of adjustable parameters is probably a better
measure of complexity. For instance, full covariance models show a quadratic growth of the number of free parameters with respect to the dimension of the attribute vector. For factorized components the growth is linear, so the amount of training data need not be unreasonably high even if the
number of mixture components is large.
In real applications, the nature of the target function is unknown, so little can be said a priori
about the best building block structure to be used by a universal approximator. We have chosen a
very simple component structure to make inference and learning feasible from uncertain information. Section 5.4 provides experimental evidence that in realistic problems the proposed model is
not inferior to other popular approaches.
5.3 Qualitative Comparison with Alternative Approaches
Instead of the proposed methodology, based on mixture models and the EM algorithm, other alternative nonparametric density approximation methods could also be used (either for the joint density
or for specific conditional densities). For instance, the nearest neighbor rule locally approximates
the target density using a certain number of training samples near to the point of interest. Symbolic

205

RUIZ, LÓPEZ-DE-TERUEL & GARRIDO

attributes are directly estimated by a voting scheme and continuous attributes can be also estimated
by averaging the observed values of training instances which are near, in the subspace of observed
attributes, to the point of interest. However, for small sample sizes, the above estimators are not
smooth and show strong sensitivity to random fluctuations in the training set, which penalizes the
estimation cost. For large sample size, the time required to find the nearest neighbors becomes very
long. As an example, consider the regression problem in Example 10, Section 3.5. Fig. 11.b shows
the MFGN solution with 4 components and MSE=0.381. Fig. 21.a shows the regression line obtained by 5-nearest-neighbors average, with a higher MSE=0.522.
Parzen windows and similar kernel approximation methods are used to smooth the results of
the simple nearest neighbors rule (Duda & Hart 1973, Izenman 1991). They are actually mixtures
of simple conventional densities located at the training samples. In principle, the properties of the
MFGN framework could be adapted to that kind of approximation (Ruiz et al. 1998). Learning
becomes trivial, but strong run time computation effort is required since a “concise” model of the
domain is not extracted from the training set. This kind of rote learning has also negative consequences on generalization according to the Occam Razor Principle (Li & Vitànyi 1993). An adequately cross-validated mixture model with a small number of components in relation to the training sample size reasonably guarantees that probably the true attribute dependencies are correctly
captured.

C2

C2
C1

C1

(a)
(b)
(c)
Figure 21. Alternative solutions in regression and classification (see text for details).

The nature of the solutions obtained by Backpropagation Multilayer Perceptrons (Rumelhart et
al. 1986) in pattern classification is also illustrative. In general, each decision region can be geometrically expressed as the union of intersections of several half–spaces defined by the units in the
first hidden layer. However, backprop networks often require very long learning times, many adjustable parameters and, what is worse, apparently simple distributions of patterns are hard to learn.
For instance, the solution to the circle-ring classification problem in Fig. 21.b, obtained by a network with 6 hidden units requires hundreds of standard backprop epochs. The decision regions are
not very satisfactory, even though the network has extra flexibility for this task (3 hidden units
suffice to separate the training examples). Better solutions exist using all the resources in the network architecture, but backprop learning does not find them. In contrast, the solution obtained by
the MFGN approach using 7 components (Fig. 21.c) requires a learning time orders of magnitude
shorter than backprop optimization. All the components in the mixture contribute to synthesize
reliable decision regions and acceptable solutions can be also obtained with a smaller number of
components.

206

PROBABILISTIC INFERENCE FROM UNCERTAIN DATA USING MIXTURES

The proposed approach is closely related to a well-known family of approximation techniques
which, essentially, distribute (using some kind of clustering or self-organizing algorithm) “detectors” over the relevant regions of the input space and then combine their responses for computing
the desired outputs. This is the case of Radial Basis Functions (RBF) (Hertz et al.), the classification and regression trees proposed in (Breiman et al. 1984) and the topological maps used in (Cherkassky & Najafi 1992) to locate the “knots” required for piecewise linear regression.
A relevant methodology is proposed in (Jordan & Jacobs 1994, Peng et al. 1995), where the
EM algorithm is used to learn hierarchical mixtures of experts in the form of linear rules in such a
way that the desired posterior densities can be explicitly obtained. The properties of the EM algorithm are also satisfactorily used in (Ghahramani & Jordan 1994) to obtain unbiased approximations from missing data in a mixture-based framework similar to ours. Our framework extends this
successful approach by exploiting the conjugate properties of the chosen universal approximation
model: uncertain information of arbitrary complexity can be efficiently processed in the inference
and learning stages.
The MFGN framework is appropriate for a moderated number of variables showing relatively
complex dependencies. In contrast, Bayesian Networks satisfactorily addresses the case of a large
number of variables with clear conditional independence relations. There are situations in which a
certain subset of the variables in a Bayesian Network shows no explicit causal structure. This subdomain could be empirically modeled by a mixture model in order to be considered later as a composite node embedded in the whole network. If the subdomain can be conditionally isolated from
the rest of variables through a set of communication nodes, the MFGN framework can be used to
perform the required inferences.
Finally, mixture models are typically used for unsupervised classification: the examples are
labeled with the index of the component with highest posterior probability. In fact, the MFGN
framework explicitly finds clusters in the training set. Furthermore, continuous and symbolic attributes are allowed in the joint density, so the examples are clustered using an implicit probabilistic metric which automatically weighs all the (heterogeneous) attributes, even with missing and
uncertain values. However, this method is effective only when the groups of interest have the same
structure as the component densities. In order to simplify inference the mixture components have
been selected with constraints (Gaussian, independent variables) which are not necessarily verified
by the “natural” groups found in real applications.
A tentative possibility (inspired in a common heuristic clustering technique) consists of joining overlapping components (e.g., according to the Battachariya distance, a well-known bound on
the Bayes error used in Statistical Pattern Recognition (Fukunaga 1990)). Unfortunately, our experiments indicate that the overlapping threshold is a free parameter that strongly determines the
quality of the results. A universal threshold, independent of the application, does not seem to exist.
In principle, clusters of arbitrary geometry may be discovered, but this cannot be easily automated.
Therefore, other nonparametric cluster analysis methods (e.g. density valley seeking) are suggested
for labeling complex groups.
5.4 Experimental Evaluation
The MFGN method has been evaluated on standard benchmarks from the Machine Learning database repository at the University of California, Irvine (Merz and Murphy 1996). It contains inductive learning problems which are representative of real world situations. We have experimented
with the following databases: Ionosphere, Pima Indians, Monk's Problems, and Horse Colic, which
illustrate different properties of the proposed methodology. In most cases MFGN has been compared to alternative learning methods with respect to the inference task considered of interest in

207

RUIZ, LÓPEZ-DE-TERUEL & GARRIDO

each problem (typically, prediction of a specific attribute given the rest of them). We usually give
the error rate over both the training and the test set to indicate the amount of overfitting obtained by
the learning algorithms.

(a) Ionosphere
(b) Pima Indians
Figure 22. Most discriminant 2D projections of two representative databases.

5.4.1 IONOSPHERE DATABASE
Two classes of radar returns from the ionosphere must be discriminated from vectors of 32 continuous attributes7. There are 351 examples, randomly partitioned into two disjoint subsets of approximately equal size for training and testing. The prevalence of the minoritary class (random
prediction rate) is 36%. Figure 22.a and Table 7 show that this is a typical statistical pattern recognition problem, easily solvable by standard methods. The results suggest that the Bayes (optimum)
error probability is around 5%.
error rate
P̂E
(training set)
METHOD
(test set)
Linear MSE (pseudoinverse)
1-1 Nearest Neighbor
2-3 Nearest Neighbor
Parzen Model
Backprop Multilayer Perceptron 2 hidden units
Support Vector Machine, RBF kernel, width 1, (105 s.v.)
Support Vector Machine, RBF kernel, width 3, (35 s.v.)
Support Vector Machine, polinomial kernel, order 2, (41 s.v.)
Support Vector Machine, polinomial kernel, order 3, (45 s.v.)
Support Vector Machine, polinomial kernel, order 4, (42 s.v.)
Full covariance gaussian mixture, 1 component/class
Full covariance gaussian mixture, 2 component/class
Full covariance gaussian mixture, 3 component/class
MFGN 4 components (average)
MFGN 8 components (average)
MFGN 15 components (average)
MFGN, best result by cross-validation (8 components)
Table 7. Ionosphere Database Results

7

.11

.05
.00

.03
.01
.005
.22±.15
.11±.06
.10±.05
.07

Originally the database contains 34 attributes. Two of them, meaningless or ill behaved, were eliminated.

208

.14
.13
.18
.08
.08
.05
.09
.13
.17
.20
.11
.19
.26
.21±.08
.13±.06
.13±.06
.06

PROBABILISTIC INFERENCE FROM UNCERTAIN DATA USING MIXTURES

In this problem, the plain MFGN method, without special heuristics in the learning stage, is
comparable in average to the alternative methods. The best solution on the training set (crossvalidation) is entirely satisfactory.
For the Ionosphere database we also present an exhaustive study of performance given varying
proportions of missing values in the training and testing examples. A value of x % means that in all
training or test examples the value of each attribute is deleted with probability x. The basic experiment consists of learning a MFGN model with the prescribed number of components (4, 8 and 15)
and computing the error rate on the training and test sets. Table 8 shows the mean value ± 2 standard deviations of the error rates obtained in 10 repetitions of the basic experiment in each configuration. Column M contains the error rate of each configuration over its own training set. The training/test partition is kept fixed to analyze the variability of the solutions due to random initialization
of the EM.
LEARNING
M

0%

INFERENCE
10%
25%

50%

4 COMP. - 0%
8 COMP. - 0%
15 COMP. - 0%

22 ± 15
11 ± 6
10 ± 5

21 ± 8
13 ± 6
13 ± 6

21 ± 8
12 ± 6
13 ± 6

22 ± 8
13 ± 5
13 ± 5

22 ± 9
12 ± 6
13 ± 4

4 COMP. - 10%
8 COMP. - 10%
15 COMP. - 10%

21 ± 14
11 ± 3
10 ± 3

23 ± 11
13 ± 5
12 ± 6

23 ± 11
12 ± 5
12 ± 7

23 ± 11
13 ± 5
12 ± 6

23 ± 11
13 ± 4
12 ± 3

4 COMP. - 25%
8 COMP. - 25%
15 COMP. - 25%

18 ± 7
12 ± 7
9±5

19 ± 5
14 ± 10
12 ± 9

19 ± 5
14 ± 9
13 ± 11

18 ± 6
15 ± 8
13 ± 9

18 ± 6
14 ± 7
13 ± 7

4 COMP. - 50%
27 ± 18 26 ± 15 27 ± 15 27 ± 14 26 ± 13
8 COMP. - 50%
16 ± 12 21 ± 15 21 ± 15 21 ± 13 20 ± 11
15 COMP. - 50% 13 ± 6
26 ± 17 25 ± 15 25 ± 14 23 ± 13
Table 8. Evaluation of MFGN on Ionosphere Database given
different proportions of missing data in the training and testing subsets.

As expected, the MFGN model is robust with respect to large proportions of missing values in
the test patterns, and to moderated proportions of missing data in the training set. We have compared the above behavior with a standard algorithm for Decision Tree construction inspired in
(Quinlan 1993), which is also able to support missing values8. Table 9 shows the error rates of the
decision trees for the same experimental setting as in Table 8. This kind of Decision Tree obtains
error rates that are better than the averages obtained by MFGN. However, MFGN's best solutions
(selected by cross-validation) are better than the ones obtained by Decision Tree. Furthermore,
Decision Tree performance degrades faster than MFGN, especially with respect to the proportion
of missing values in the inference stage.

8

Essentially, missing values are handled as follows. In the learning stage, when an attribute is selected, examples with
missing values are sent to all the partitions with appropriate weights. In the inference stage, if a node asks for a missing
value, it follows all the branches with appropriate weights and finally the outputs are combined.

209

RUIZ, LÓPEZ-DE-TERUEL & GARRIDO

LEARNING
M

0%

INFERENCE
10 %
25 %

50 %

1%
0%
9%
10 %
11 %
12 %
5%
10 %
14 %
15 %
19 %
18 %
6%
25 %
15 %
17 %
17 %
18 %
8%
50 %
17 %
18 %
18 %
19 %
Table 9. Evaluation of basic Decision Tree on Ionosphere Database given different proportions of missing data in the training and testing subsets.

5.4.2 PIMA INDIANS DATABASE
In this problem we must discriminate between two possible results of a diabetes test given to Pima
Indians. There are 8 continuous attributes, and 768 examples, randomly partitioned into two disjoint subsets of equal size for training and testing. The prevalence of the minority class is 35%. The
attribute vector has been normalized. Table 10 presents comparative results.
error rate
P̂E
(training set)
METHOD
(test set)
Linear MSE (pseudoinverse)
Oblique Decision Tree 8 decision nodes
1-1 Nearest Neighbor
2-3 Nearest Neighbor
Full covariance gaussian mixture, 1 component/class
Full covariance gaussian mixture, 2 component/class
Full covariance gaussian mixture, 3 component/class
Full covariance gaussian mixture, 4 component/class
Backprop Multilayer Perceptron 2 hidden units
Backprop Multilayer Perceptron 4 hidden units
Backprop Multilayer Perceptron 8 hidden units
Support Vector Machine, RBF kernel, width 1 (297 s.v.)
Support Vector Machine, RBF kernel, width 3 (176 s.v.)
Support Vector Machine, polynomial kernel, order 4 (138 s.v.)
Support Vector Machine, polynomial kernel, order 5 (131 s.v.)
MFGN 4 components
MFGN 6 components
MFGN 8 components
Table 10. Pima Indians Database Results

.22
.18

.24
.19
.17
.17
.17
.14
.05

.28
.25
.29

.23
.24
.30
.25
.26
.29
.30
.31
.25
.24
.29
.30
.35
.36
.34
.35
.32
.35

Despite of low dimensionality and large number of examples, this classification problem is
hard (see Figure 22.b). Even sophisticated learners such as backpropagation networks, decision
trees or support vector machines, which are able to store a reasonable proportion of the training set,
do not achieve significant generalization. MFGN shows a similar behavior, although it is slightly
less prone to overfitting (the error rate on the training set is not misleading).
5.4.3 HORSE COLIC DATABASE
This database contains a classification task from a heterogeneous attribute vector including symbolic, discrete and continuous variables, with 30% missing values. It illustrates the problem of

210

PROBABILISTIC INFERENCE FROM UNCERTAIN DATA USING MIXTURES

feature selection in the context of joint modeling, mentioned in Section 5.1. Table 11 shows the
error rates obtained by MFGN using different attribute subsets9. To take advantage of its general
inference properties, the MFGN model must be applied to the attribute subset of interest. If the
inference task is fixed and the number of attributes is very large, alternative methods should be
used.
METHOD

P̂E

P̂E

(distribution, 10 initializations)

(best)

6 Selected attributes
MFGN 2 components
MFGN 3 components
MFGN 4 components
MFGN 5 components
MFGN 6 components
MFGN 7 components
MFGN 10 components
MFGN 12 components
MFGN 15 components

.32±.00
.20±.05
.19±.02
.20±.02
.19±.03
.20±.04
.22±.04
.19±.03
.19±.04

.32
.18
.18
.18
.16
.18
.18
.16
.15

.22±.01
.21±.02
.21±.03
.23±.02
.21±.02
.21±.02

.21
.19
.18
.18
.18
.18

.28±.02
.29±.03
.34±.08
.34±.06

.25
.25
.25
.28

8 Selected attributes
MFGN 4 components
MFGN 6 components
MFGN 8 components
MFGN 10 components
MFGN 12 components
MFGN 15 components

23 Selected attributes
MFGN 6 components
MFGN 8 components
MFGN 10 components
MFGN 15 components
Table 11. Horse Colic Database Results (random rate = .5)

5.4.4 MONK'S PROBLEMS
The Monk's problems are three concept learning tasks from 6 symbolic attributes, widely used as
benchmarks for inductive learning algorithms (Thrun et al. 1991). As seen in Table 12, MFGN fails
on MONK1 (where acceptable generalization is not obtained) and MONK2 (where the training
examples cannot even be stored). In contrast, MFGN correctly solves MONK3. This behavior is
related to the fact that the MONK's problems are based on deterministic or abstract concepts which
may lack the kind of geometric regularities in the attribute space required by probabilistic models10.
9

Features were individually selected using a simple discrimination index related to the Kolmogorov-Smirnov statistic
(Ruiz 1995).
10
A typical example is the parity problem: acceptable off-training-set generalization cannot be achieved if the inductive
bias of the learning machine is biased towards "smooth" solutions.

211

RUIZ, LÓPEZ-DE-TERUEL & GARRIDO

Fig. 23 shows the most discriminant 2D projections of the datasets and illustrates the fact that
MONK2 cannot be easily captured by statistic techniques. In this benchmark, MFGN performance
is similar to that of other popular probabilistic methods (Thrun et al. 1991).

(a) MONK1
(b) MONK2
Figure 23. Most Discriminant 2D Projections of the Monk's Datasets.

(c) MONK3

error rate
(training set)

METHOD

P̂E
(test set)

MONK1 (random rate = .5)
Linear MSE (pseudoinverse)
1-1 Nearest Neighbor
Support Vector Machine, RBF kernel, width 1 (78 s.v.)
Cascade Correlation
MFGN 4 components
MFGN 8 components

.29

.06
.00

.34
.17
.08
0
.40
.33

MONK2 (random rate ≅ .4)
Linear MSE (pseudoinverse)
1-1 Nearest Neighbor
Support Vector Machine, RBF kernel, width 1 (117 s.v.)
Cascade Correlation
MFGN 4 components
MFGN 8 components
MFGN 15 components

.40

.31
.26
.14

.37
.19
.20
0
.38
.44
.50

MONK3 (random rate ≅ .5)
Linear MSE (pseudoinverse)
1-1 Nearest Neighbor
Support Vector Machine, RBF kernel, width 1 (69 s.v.)
Cascade Correlation
MFGN 2 components
MFGN 4 components
MFGN 8 components
Table 12. Monk's Problems Results

212

.19

.07
.04
.03

.19
.18
.08
.03
.03
.03
.08

PROBABILISTIC INFERENCE FROM UNCERTAIN DATA USING MIXTURES

5.4.5 COMMENTS
The above experiments demonstrate that the MFGN model is able to obtain acceptable results on
many real world applications. In particular, the error rates obtained in standard classification tasks
are comparable to those obtained by other popular learners. Additionally, MFGN is able to perform
inferences over any other attribute given uncertain or partial information, which is not possible for
most of the alternative methods. This property makes MFGN a very attractive alternative for many
inference problems such as the one illustrated in Example 16. The experiments have also contributed to characterize the kind of problems for which the MFGN model is best suited. Essentially, the
relationship among attributes must be of a true probabilistic nature, and the attribute vector must be
of a moderated size containing "relevant" variables. A previous feature selection / accommodation
stage is recommended in certain applications.

6. Conclusions
We have developed an efficient methodology for probabilistic inference and learning from uncertain information. Under the proposed MFGN framework, the joint probability density function of
the attributes and the likelihood function of the available information are approximated by Mixtures of Factorized Generalized Normals. This mathematical structure allows efficient computation,
without numerical integration, of posterior densities and expectations of the desired variables given
events of arbitrary “geometry”. An extended version of the EM learning algorithm has been developed to estimate the parameters of the required mixture models from uncertain training examples.
Different paradigms as pattern recognition, regression or pattern completion are subsumed under a
common framework.
A comprehensive collection of examples illustrates the methodology, which has been critically
compared with alternative techniques. The Extended EM algorithm is able to learn satisfactory
domain models from a reasonable number of examples with uncertain values, taking into account
the explicit likelihood functions of the available information. Results are satisfactory whenever the
sample size is large in relation to the amount of (known) degradation of the training set. The experiments also characterized the kind of situations that the model manages better: Domains described by a moderate number of heterogeneous attributes with complex probabilistic dependences,
problems in which the output variables are not necessarily known in the learning stage (i.e. pattern
completion), and, finally, problems in which an explicit management of uncertainty is needed, either in the learning or in the inference stage (or even in both). The MFGN framework has obtained
a very favorable trade-off between useful features and model complexity in the solutions to different applications and benchmarks.
Future developments of our work include improving the learning stage with some heuristic
steps that are combined with the standard E and M steps to control the adequacy of the acquired
models. Additional studies are required on validation tests, generalization, scalability, robustness
and data preprocessing. The essential idea of working with explicit likelihood functions will be
incorporated into the Parzen approximation scheme and we are also interested in more expressive
model structures such as mixtures of factor analyzers, principal component analyzers or linear experts. Finally, the methodology can be developed in a pure Bayesian framework or subsumed under
the Dempster-Shafer Evidence Theory.

213

RUIZ, LÓPEZ-DE-TERUEL & GARRIDO

Acknowledgments
The authors would like to thank the anonymous reviewers for their careful reading and helpful suggestions. This work has been supported by the Spanish CICYT grants TIC95-1019, TIC97-1343C02-02 and TIC97-0897-C04-03.

References
Berger, J., (1985). Statistical Decision Theory and Bayesian Analysis. Springer-Verlag.
Bernardo, J.M., Smith, A.F.M. (1994). Bayesian Theory. Wiley.
Bouckaert, R.R. (1994). “Properties of Bayesian Belief Network Learning Algorithms”. Proceedings of Uncertainty in AI, pp. 102-109.
Breiman, L., Friedman, J.H., Olshen, R.A., and Stone, C.J. (1984). Classification and Regression
Trees. Wadsworth International Group, Belmont, CA.
Chang, K. & Fung, R. (1995). “Symbolic Probabilistic Inference with Both Discrete and Continuous Variables”. IEEE Tran. on Systems, Man, and Cybernetics, Vol. 25, No. 6, june, pp. 910916.
Cherkassky, V. and Lari-Najafi, H. (1992). “Nonparametric Regression Analyisis Using SelfOrganizing Topological Maps” in H. Wechsler (ed.), Neural Networks for Perception. Vol.2,
Computation, Learning and Architectures, San Diego: Academic Press.
Cohn, D.A., Ghahramani, Z. & Jordan, M.I. (1996). “Active Learning with Statistical Models”.
Journal of Artificial Intelligence Research 4, pp. 129-145.
Dalal, S.R. & Hall, W.J. (1983). “Approximating Priors by Mixtures of Natural Conjugate Priors”.
J. R. Statist. Soc. B, Vol. 45, No. 2, pp. 278-286.
De Soete, G. (1993). “Using Latent Class Analysis in Categorization Research” in I. V. Mechelen,
J. Hampton, R.S. Michalski, P. Theuns (eds.), Categories and Concepts: Theoretical Views
and Inductive Data Analysis, San Diego: Academic Press.
Dempster, A.P., Laird, N.M., Rubin, D.B., (1977). “Maximum Likelihood Estimation from Incomplete Data via the EM Algorithm”. Journal of the Royal Statistical Society, Series B, Vol. 39:
pp. 1-38.
Duda, R.O. and Hart, P.E. (1973). Pattern Classification and Scene Analysis. John Wiley & Sons.
Fan, C.M., Namazi, N.M. and Penafiel, P.B. (1996). “A New Image Motion Estimation Algorithm
Based on the EM Technique”. IEEE Transactions on Pattern Analisys and Machine Intelligence, Vol.18, No.3, March, pp. 348-352.
Fukunaga, K. (1990). Introduction to Statistical Pattern Recognition. Academic Press.
Ghahramani, Z. and Jordan, M.I. (1994) “Supervised learning from Incomplete data via an EM
approach” In Cowan, J.D., Tesauro, G., and Alspector, J. (eds.). Advances in Neural Information Processing Systems 6. Morgan Kauffman
Ghahramani, Z. and Hinton, G.E. (1996) “The EM algorithm for mixtures of factor analyzers”.
Tech. Rep. Univ. Toronto. CRG-TR-96-1.

214

PROBABILISTIC INFERENCE FROM UNCERTAIN DATA USING MIXTURES

Heckerman, D. & Wellman, M.P. (1995). “Bayesian Networks”. Communications of the ACM, Vol.
28, No.3, pp. 27-30, March.
Hertz, J., Krogh, A., Palmer, R.G., (1991). Introduction to the Theory of Neural Computation.
Addison Wesley.
Hinton, G.E., Dayan, P. and Revow, M. (1997). “Modeling the manifold of images of handwritten
digits”. IEEE T. on Neural Networks 8, pp. 65-74.
Hornik, K., Stinchcombe, M., White, H., (1989). “Multilayer FeedForward Networks are Universal
Approximators”. Neural Networks, No.2.
Hutchinson, A. (1994). Algorithmic Learning. New York: Oxford Univ. Press.
Izenman, A.J. (1991). “Recent Developments in Nonparametric Density Estimation”. J. Amer. Statist. Assoc. Vol. 86, No. 413, pp. 205-224.
Jordan, M.I., Jacobs, R.A., (1994). “Hierarchical Mixtures of Experts and the EM Algorithm”.
Neural Computation, 6, pp. 181-214.
Kohonen, T., (1989). Self-Organization and Associative Memory. Springer-Verlag.
Lauritzen, S.L. & Spiegelhalter, D. J. (1988). “Local Computations with Probabilities on Graphical
Structures and their Application to Expert Systems”. J. R. Statist. Soc. B. 50, No. 2, pp. 157224.
Li, M. and Vitànyi, P. (1993). An Introduction to Kolmogorov Complexity and Its Applications.
New York: Springer-Verlag.
McLachlan, G.J., Basford, K.E., (1988). Mixture Models. New York: Marcel Dekker.
McLachlan, G.J. and Krishnan, T. (1997). The EM Algorithm and Extensions. John Wiley and
Sons.
Michalski, R.S., Carbonell, J. and Mitchell, T.M., eds. (1983). Machine Learning: An Artificial
Intelligence approach. Palo Alto, CA: Tioga Press. Also reprinted by Morgan Kaufmann
(Los Altos, CA).
Michalski, R.S., Carbonell, J. and Mitchell, T.M., eds. (1986). Machine Learning: An Artificial
Intelligence approach, Vol. II. Los Altos, CA: Morgan Kaufmann.
Mohgaddam, B. and Pentland, A. (1997). “Probabilistic Visual Learning for Object Representation”. IEEE T PAMI, Vol. 19, No.7, 710. pp. 696-.
Merz, C.J. and Murphy, P.M. (1996). UCI Repository of machine learning databases.
[http://www.ics.uci.edu/~mlearn/MLRepository.html]. Irvine, CA: University of California,
Department of Information and Computer Science.
Palm, H.C. (1994). “New method for generating statistical classifiers assuming linear mixtures of
Gaussian densities”, Proceedings 12th IAPR International Conference on Pattern Recognition (Jerusalem, October 9-13, 1994), vol.2, IEEE, Piscataway, NJ, USA,
Papoulis, A., (1991). Probability, Random Variables and Stochastic Processes. MCGraw-Hill.
Pearl, J., (1988). Probabilistic reasoning in intelligent systems: Networks of plausible inference.
Morgan Kaufmann.

215

RUIZ, LÓPEZ-DE-TERUEL & GARRIDO

Peng, F., Jacobs, R.A., Tanner, M.A. (1995). “Bayesian Inference in Mixtures-of-Experts and Hierchical Mixtures-of-Experts Models With an Application to Speech Recognition”. Accepted
in the Journal of the American Statistical Association.
Priebe, C.E., Marchette, D.J., (1991). “Adaptive mixtures: recursive nonparametric pattern recognition”. Pattern Recognition, V24 N12, pp. 1197-1209.
Pudil, P., Novovicova, J., Choakjarernwanit, N., Kittler, J. (1995). “Feature Selection Based on the
Approximation of Class Densities by Finite Mixtures of Special Type”. Pattern Recognition
Vol.28 No.9 pp. 1389-1398.
Quinlan, J.R., (1993). C4.5: Programs for Machine Learning. San Mateo, CA: Morgan Kaufmann.
Redner, R.A., Walker, H.F., (1984). “Mixture densities, maximum likelihood estimation and the
EM algorithm”. SIAM Review, Vol. 26, pp. 195-239.
Rojas, R. (1996). “A Short Proof of the Posterior Probability Property of Classifier Neural Networks”. Neural Computation Vol.8 Issue 1, January.
Rumelhart, D.E., Hinton, G. E. and Williams, R. (1986). “Learning Internal Representations by
Error Propagation” in Rumelhart, McClelland & the PDP Group (1986), pp. 319-362.
Rumelhart, D.E., McClelland, J.L. & the PDP Research Group. (1986). Parallel Distributed Processing: Explorations in the Microstructure of Cognition, vol. 1, Foundations. Cambrigde
MA, Bradford Books/MIT Press.
Ruiz, A. (1995). “A nonparametric bound for the Bayes Error”. Pattern Recognition, Vol. 28, No.
6, pp. 921-930.
Ruiz, A., López-de-Teruel, P.E. and Garrido, M.C. (1998). “Kernel Density Estimation from Indirect Observations”. In preparation.
Sung, K.-K. and Poggio, T. (1998),. "Example Based Learning for View-Based Human Face Detection". IEEE Trans. Pattern Analyisis and Machine Intelligence. Vol.20, N.1. January, pp.
39-51.
Tanner, M.A. (1996). Tools for statistical inference. (3rd ed.). Springer.
Thrun, S. et al (1991). "The MONK's Problems. A performance Comparison of Different Learning
Algorithms". Technical Report CMU-CS-91-197.
Titterington, D.M., A.F.M. Smith and U.E. Makov (1985). Statistical Analysis of Finite Mixture
Distributions, Wiley, New York.
Traven, H.G.C., (1991). “A Neural Network Approach to Statistical Pattern Classification by
"Semiparametric" Estimation of Prob. Den. Func.”. IEEE T Neural Networks, V2 N3.
Valiant, L.G. (1993). “A View of Computational Learning Theory” in Meyrowitz and Chipman,
eds. (1993). Foundations of Knowledge Acquisition: Machine Learning. Kluwer Acad. Pub.
Valiveti, R.S., Oommen, B.J., (1992). “On using the chi-squared metric for determining stochastic
dependence”. Pattern Recognition, V25 N11 pp. 1389-1400.
Vapnik, V.N. (1982). Learning Dependencies based on Empirical Data. Springer, New York.
Vapnik, V.N. (1995). The Nature of Statistical Learning Theory. Springer, New York.

216

PROBABILISTIC INFERENCE FROM UNCERTAIN DATA USING MIXTURES

Wan, E.A., (1990). “Neural Networks Classification: A Bayesian Interpretation”. IEEE Trans. on
Neural Networks, V1 N4.
Weiss, Y. and Adelson E.H. (1995). “Perceptually organized EM: A framework for motion segmentation that combines information about form and motion”. TR MIT MLPCS TR 315.
Wilson, D.R. and Martinez, T.R. (1997). “Improved Heterogeneous Distance Functions”. JAIR, V6,
pp. 1-34.
Wolpert, D.H., ed. (1994a). The Mathematics of Generalization. Proc. SFI/CLNS workshop on
Formal Approaches to Supervised Learning.
Xu, L. & Jordan, M.I. (1996). “On the Convergence Properties of the EM Algorithm for Gaussian
Mixtures”. Neural Computation Vol.8 Issue 1, January.
You, Y.L. and Kaveh, M. (1996). “A regularization approach to joint blur identification and image
restoration”. IEEE T on Image Processing, vol 5.no.3, pp. 416-428.

217


	
 
			 ! #"$ % 
'&)(+*, ((-/.10/23540/6!,

789:;  <)-/=
(-!>@?9	%&<A, 2/=
(-

BDCAEGFIH/JLKNMOQPRCTSVUXWYM/CAWYM
OZM/[;J]\_^`J]S@acbIHOedfCTgAMh;i

jYkmlnlno)pqo'rsntur#vwr

x1yz1{}|uz$~zAyz$x1]|{1y$zuy$}T~


  T
 8@   Q $  ]¡/8 /¢    
£ ¥¤
¦§'¦ £ ¥

¨n©}ª«@©

A¬]­Y§Y®)¯

£]°I±

²´³)µn¶·¸Z¹Q¶
º¼»¾½¿/ÀÁ@ÂÃÄmÅ5¿8ÁÆ Ç»È»ÉÊÂÆÂÁnÃ¥ÃËT»ÇnÄ#Á@ÃÃÌQÇÆ5Æ ÈÍÃ¿;ÎÁËÆÏÇnÀwÅ5¿8ÆÇnÃÐÈ¥»ÉÒÑÇn»ÓÈÑ/Ä5ÆZÍQ¿/ÄÎ¿¿8»¾½¿/ÀÁnÂÃÄ
Å5ÂÃ¿8ÆÔÁ@Å5¿ÕÁÑÑ/¿8ÌÄ5ÁnÍÃ¿nÖØ×#Å5ÈÄ5¿Å5ÈÁÙ¿/ÚÌÅ5¿8Æ5Æ È»ÉqÁnÑÑ¿ÌÄ
Á@ÍÃ¿ÛÎLÁËÆTÇnÀÜÅ5¿8ÆÇnÃÐ}È»ÉÙÄÝ¿IÑ/Ç»ÓÈÞÑÄ
ÆAßàÁË
ÍQ¿TÝÁnÅ5½Î;È¥Å5¿8½NÈ»áÄÝ¿AÈ¥»Àâ¿8Å¿8»Ñ/¿Tßã¿!Ñ
ÝÁ@»ÈÆßáÊÀâÇnÅ+¿/ÚÁ@ßÔÌÃ¿TÆÌ¿!Ñ/È¥äÑ/È¥ÄËNÈ¥»IÈ»Ý¿8ÅÈ¥Ä5Án»Ñ/¿cÅ5¿8ÁÆ Ç»È»É
Ñ8Á@»åÍ¿ÛÝÁ@»½Ã¥¿!½qÄÝÈÞÆcÎLÁËnÊÇnÅæÄ5Ý¿ËqßàÁËÙÍQ¿¾ÉnÈÐn¿8»åÁnÍÆ ÄÅ
ÁnÑÄ5Ã¥ËqÁnÆcÁn»åÇnÅ
½¿Å5È¥»ÉNÇ»qÄÝ¿N½¿/ÀÁnÂÃÄ
Å5ÂÃ¿8Æ8Öº¼»ÛÄÝÈÞÆ#ÁnÅ Ä5ÈÑÃ¥¿ÜÎ#¿+È¥»Ðn¿!ÆÄ5È¥É}ÁÄ5¿LÀâÇnÅ5ßÔÁnÃ¥Èç8Á@ÄÈÇn»ÆmÇ@À1Ä5Ý¿ÜÃÞÁÄÄ¿ÅLÁ@ÌÌÅÇ}ÁnÑ
ÝÔÈ»Ûè;¿È¥Ä¿8Å8é Æ½¿/ÀÁnÂÃÄ
ÃÇnÉÈÑnÖëê+ÂÅÛÉnÇÁnÃ]ÈÞÆàÄÇìÁ@»ÁnÃ¥Ëç¿íÁn»½´Ñ/ÇßãÌÁ@Å5¿áÄÝ¿ÙÑÇnßÔÌÂÄ
ÁÄ5È¥Ç»Á@Ã+ÌÅÇÌ¿8Å Ä5È¥¿!ÆàÇ@ÀÒÄ5ÝÅ¿8¿íÆ ÂÑ
Ý
ÀâÇÅßàÁ@ÃÈç8ÁÄ5È¥Ç»ÆcÈ»îÄ5¿Å5ßÔÆAÇ@À;Ä5Ý¿ÈÅÔÑ/ÇnßÔÌÂÄ5ÁÄ5È¥Ç»Á@ÃÑ/ÇßãÌÃ¥¿ÚÈ¥ÄËwïÔÄÝ¿ÕÌÅ5È¥ÇÅÈ¥ÄÈç¿!½ð½¿/ÀÁnÂÃ¥ÄAÃÇnÉnÈÞÑÆ
ÇnÀÒñLÁnÁ½¿ÅàÁn»½´ò]ÇnÃÃÂ»½¿8Å8Ê;Á@»½ìñÅ5¿Î;óÁÊLÁ@»½´ÁqÌÅ5È¥ÇÅÈ¥ÄÈç¿!½ì½¿/ÀÁ@ÂÃÄÛÃÇnÉÈÑÕÄ5ÝÁÄ¾ÈÞÆàÍÁÆ ¿!½fÇ»
Ã¿/ÚÈÞÑ/ÇnÉÅ5ÁnÌÝÈÞÑLÑ/ÇnßÔÌÁnÅÈÞÆÇn»$ÖôLÝ¿]Á@»ÁnÃ¥ËÆÈÆÏÃÇÑÁ@Ä¿8ÆZÄÝ¿]ÌÅÇÌÇ}Æ È¥ÄÈÇn»ÁnÃÐÁ@Å5ÈÁn»Ä
ÆZÇ@ÀQÄÝ¿8Æ¿]Ã¥ÇÉnÈÞÑÆÏÇ»
Ä5Ý¿#Æ¿8ÑÇn»½cÁn»½)ÄÝÈ¥Å
½æÃ¿Ðn¿8ÃÆuÇ@ÀÄ5Ý¿mÌQÇnÃË»ÇnßÔÈÞÁ@Ã}ÝÈ¥¿8Å5ÁnÅ5Ñ
ÝËÊ8Á@»½æÈ½¿»}ÄÈ¥ä¿8ÆuÄÝ¿mÍQÇnÂ»½Á@Å5Ë+ÍQ¿/ÄÎ¿¿8»
Ä5Å5ÁÑÄ5ÁnÍÃ¿ÒÁn»½ÕÈ¥»}ÄÅ
ÁnÑ/Ä5ÁnÍÃ¥¿ÒÈ»Àâ¿Å5¿»Ñ/¿)ÀâÇnÅ;Å5¿8Æ ÄÅ5ÈÑ/Ä¿!½ÕÑÃÁÆÆ¿8ÆLÇnÀÌÅ5È¥ÇÅÈ¥ÄÈç¿!½Õ½¿/ÀÁ@ÂÃÄ;Ä5Ý¿ÇÅÈ¿8Æ8Ö
õZöI÷}ø ¶·ù;ú+ûÜ¹Q¶üù ø
ýAþÿIþÿ1þþÿþ	
ÿþAÿ1þÿIþÿ1þþÿÿ

!"# þÿâ ÿ	$ %&
2

3
1


4



6
5


&




9






:





þ
<
;


=




þ







;
4





@

6
ÿ





ÿ
?
	
>Qÿ$þ 8 "	ÿ@þ4
'()*,+.'()/+0'()*678
þAþÿâÿ	@59íÿ1þ
 þÿB:@ÿ"@ÿB"CED,;F"GâÿHIþÿ1þþÿ?þ	
&I">G5?J4LKþ4
;?þ	
Nþ;/þÏ
; þ
"â þÿI þ	
M9
N ÿ´ÿ1þÿIþÿ1þ þÿOâ þ	
â ÿP@ ÿEQ ÿHF<Gá
 þÿ
5RF#þ 8 5S ÿ$ÿ1þSF0Aâ ÿPP/ þ
TU
 þ EMWVX5@ ÿOED,@ ÿâ ÿ	Y5Z&
 þ
?+þ5
âÿP@ÿE#[=F< þ
?9â ÿB:\]&, ÿ5@ ÿE59æ
 þ^â ÿP4F"_ EU1 þc
 ÿ1þUíþÿ1þ þÿ
âÿE4M1` þED?;"&]â ÿa5G>,â ÿì
 þb þÿâ ÿ	cED;4CQâ ÿ54 ÿEN
 ÿ 8 þ>$ A
d þe&
& þÿÛ
 ÿ 8 þ4>â ÿ>c2@5U;4"9FF0à
 ÿ1þÿKg þ
15 þ
QF<:4	A
 þÿ"M3h5&
'((\fB7 Ï
â ÿ=5F.@
 ÿEà
 þW þÿ644= ÿ þi þÿ]&,?!,jk@ ÿ6#/ þÿ@ þ þÿ!5?Eâ ÿ@;4"
8 $ ÿ1þR4â ÿ>l: þ>\,M^Vm"15 þ
!A þÿ6iE þÿ]&,â ÿ þ4â þÿ[â ÿ	O5R5_;4"R1 þBA4 ÿ>
:þ,>\[ ÿ@F<]& 8 545=iE5;:â þ
!# þÿ!4 þÿ]M
h5Ù
 ÿn þoâ ÿ þÏ
; þ4[;4 þ4gCâ ÿ þ4 þÿC þ´ÿ1þÿIþÿ$þ þÿ? þ	
c$ pI" i5"q& '()/+
rA 8 >,& '()(+Os EZ
t ÿ=uwvS4x& '((y+ %
 ÿz& '((y+ rR4 8 >\,& '((\f+ r3u{T
d þ
$
! ÿ&
; þ
4"Fgc5Y 8 þ@ !"_4!UGâ ÿo þÿ,}.EMÔ
~ ÿl þ
!4EN
 þb!i5
'((/
7 _P/ þ
|5OÏ
;4â þ4"gOâ ÿ þ4 þÿ?W5;<J."eÛ
 þ<P!"MSVX5@ ÿíþÿ#4!"32b5;4W!!91 þ
ÿ1þU4â ÿ>[
 ÿ ÿ1þ5_,5Y?@ÿ!!"[1 þ&.â ÿP@ ÿE# þÿE ÿâ ÿ	"9;4"#415 þ
!
F<OF.´
 þÿo5lJ4Ô
 þÿGF<!G"QIþ?;<J.&<O;i"Q?=W!F.A
 þ
?@ÿ]MH;<J."enGF4 þG þ
":,â ÿ	 þÿ}.ElF< 8 @ ÿP!O5OF<@ ÿ ÿ6:	

â ÿ5=P4? 8 þ> þY;5,KFâ ÿ54
 ÿEk5 þ4"$ A
d þg& '((\fB7 M5N ÿ	@ ÿ4x&b15 þ 8 :2&
;4â þ4""YC þ
?G þ
t<@ ÿ6Q þ
!iE&z ÿo5 þ?"Qb!Ja þ= ÿ6:	
í
 ÿ1þÿ,K
Iþÿ1þ
 þÿ/ þÿâ ÿ	 8 "5 ÿaF4EÔ
 ÿ1þ þÿfþ^;4 þ4"A
 þ44â ÿ	
æ
 þÿaP!M35N ÿ5
þQþ&



, ((-Q %%.!<5c
<3Ò/
AZ
!¥:]
bQ9!	%&%g		n&/%u%/ <

U".


O_ ¡¢.£"¤¥b¡?¦E§.Y¨U©R© 4YQªE¡  ªE#« ªER[_ ªEY¡«z 4¡ 4""¬
­  4©®a¢0¯¤©B° ¡<¡
©£G¡«¦±< 4C i©£"g°¬X² «P  ¦³´¢¡ i"µ ¶A ¨·©,¸
¹º»º
¼ ©¦¡ 4¦ ¦¡ °½ B©"¡
@µ ¾°
©z¸ ¹ºº¿
¼ ¦¡a¡l©2®@©O 4©£3©a¡¡
¡«
¦« ©´£"©_¾ ÀÁU¦« ©´£"£¡
ª¸.©¦°ª©¢<¡¢< 4©£©¦¡k  Â´4"EÃ« 4¡ Ã
¤©£S¦« ©´£"¡ i"_¡«©[ i"¡ 4""Ä¦¦«P©´£"U£"¡
ªcµ ¾UB©]¸ ¹ººº
¼ ¬ÅY£¡[G¦E§.""¡
#¡«
¤?¡,¦£3¤¤"Ä©"¡
ªE¡
¦""¡
©£RB©£¤?BµÆ_E±< [ÇÈ²Z© i£x¸ ¹ºº¿
¼ ©¦ 4¡ 4""Ä¦
ª" 4ª´¤ªE 4""¡
oµ ÉZ"« ª4Ä¸ ¹º»Ê
¼ ¦¡¡U¦" ªE£°k´0¡ 4A¦« ©´£"¨U"=  4ÂB´"¬
Ë ¨R¡ ·¨AaªE¡
ªEB 4©o¡
³¶A ¨·©,ÀÁCµ ¹ºº\ÌB¼ ©¦¯¶3©©¦ k©¦¯ÍU¡
££´¦ 2ÀÁ=µ ¹ººÊ
¼
 ¡<¡
©£«P¡ AªE¡ <¡ 4© 4"¡ 4"^¡l¦«P©´£R£"¡
ª¸,©A¨R££©3©9 ¡<¡
©£©3´A£"EÎªE¡Ã
 4©ª3ªE¡
¤?© 4¡
µ ¾UB©]¸ ¹ººº
¼ ¬ ­ # 4# ¡<¡
©£W©¦¦ 4^¦« ©´£"W ©¡
Q¨U"
¦« ©´£"9©l©®c  Â´¬@ÉI"·k© 4£" O¨R¡ ·H¡
ªE¡
¤?£EÎ,"e°H¡«U¡
¤¡
¡¡
ª£¡
ª
µ Ï©´Ä9ÇÑÐ,£¤©]¸ ¹ºº,¹Ò Ð,££¤©z¸ ¹ººÓ,Ò Æ_¡£¡¢z¸ ¹ºº¿
¼ ¸_.´ <¡
_¡«Z¡
´ 6®
©"¡
@
¡G<¡
6R¡
´3«P´¦©¤?B©£.¦±0 4ªE3©¦k4¤£© i""^¢<g¨A=£"¡
ª¸ª4© 4©ªE i"Ä¦=¢B°
<¡
£"°,¡
¤©£<¤ 4©£©©¢£"e°k¢<e¨Ra" U¦ª"¡
@ ¡¢£"¤¸©¦¡c¦B"«°c  iªE¦
ª£©U¡«b¦«P©´£¡ 4"Y¨U 49 ©¡
k 4©ªE©¢£¬ ­ 9§ 4U·¦¡«^ ´£"U© G´« ´£
«P¡ bEÎ©¤?£"¨Y¦®£"¡.¡ ¤?Ã ¡2®,9ª4ÂB´«¡ RU£"¡
ªRÂ´"¡
z¬ ­ U,Ã
EÎªEQ¡«z<¡
£"°,¡
¤©£¤?_ 4©£©"¡
R¢0e¨R=e¨R¡¦ª"¡
k ¡¢£¤R¦ª©R©3
ª4Â´¦¦© £"·£"°k¡¢<¦±< BÔ"#¡#«P©"¢£¡[¡
£"®¡
O¦ª"¡
= ¡¢£"¤
¢°¤?.£"°k i©£©k"Y¡kl¡ ¬QÅ_£¡¸<"«^<¡
£"°¡
¤©£]¤O 4©£©"¡
UEÎ,_©¦°
´ 4n¡
´¡¢<¤?£"¸z [¡«P½¡ ©¡
½¡ ©O[¦ª4"¡
H ¡¢.£"¤© i©£"°¬
­ ªE¡
¦n·,¦o¡«3 ´£¸I¦B§.ª©¡
C¡«A i©ªE©¢£"[ª©¸S¦ ªE£"°
®EÕkª"B¸Z©9
<¡
£"°,¡
¤©£<¤¸.¦ª4"¡
@ ¡,ªE¦´ 4«P¡ U 4¡ 4""Ä¦= ©¡
[<ª©£zª©¬ ­ l´£"e°
¡«_©£"¡ i"¤?¦<¦G¡
©£ª©"¡
©[©¦]¬ Ë Ö¤[©6°ª©k@  4ªE"¡

©?£"©¦¡C<¡
£"°,¡
¤©£b¤?@¦ª¡
½ 4¡ªE¦´ G© =¡B¡H® @¡H¤©·@c ¡ªE¦´ 
 4©ªEª©££"°H´« ´£x¬@×®¡
´
¡
¤¡
¡¡
ª[ ©¡
a´´©££"°aª©¡O¢<k0 4«¡ 4¤¦n
<¡
£"°,¡
¤©£¤?¸¨Ø¦®£"¡¤6#=¤£"¤?B©"¡
kª4ÂB´3©2®¤©¦"A<¡
"¢£¡
¡
£"®[ ¡¢£"¤[Y© ®,"¡
´£°¨A ?¡B¡o¦Õkª´£"Gµ Ù_"¤?£e©
Ú ÇÛÐ,¤?¡
¸ ¹ººÜ
¼ ¬kÍYªEk 
© 9¡
¤? ¡
0ªEU¡«^¤©·¡
¤?¡
¡¡
ªQ ©¡
? 4©ªEª©££"°=´« ´£x¸¨Uª4@¤©·Y
 ¡¢.£"¤Ý¡«AB ¡,¦´ª[ 4¡ 4"g°a«P¡ 4¤©"¡
CH¡
¤?¡
¡¡
ªl ©¡
@¤?¡ ©ª´¬ ­ 
©< ª©¢<©
"®,G
´¦£3=©Y¦" ªE"¡
z¬
­ l¦ª"¡
o ¡¢£¤U¡«R ¡<¡
"¡
©£I¦« ©´£"Q£"¡
ªl© £"¡,ª©¦C¡
o?ªE¡
¦H£"®£W¡«
<¡
£"°,¡
¤©£0" 4© 4ªi6°HµÆ_¡£"¡¢z¸ ¹ºº¿
¼ ¸]©¦ªE9°c¦¡[¡¢<£"¡
?¡[9ª£©UÙ_²
¡ 3ªE¡ÃgÙY²´£"^Y<¡
£"°¡
¤©£" i© 4ª4B°ªE¡
££©¡O§ ib£"®£x¬ ­  ¡¡«<¡«] 4´£"
´©# ©¡
?@¦« ©´£"#£"¡
ª_ª©¡¢<Q0 4«¡ 4¤¦c=0¡
£°¡
¤[©£¤?¤?.£"°?¢B°
  iªEY«P¡ 4¤l´£©Uk¦« ©´£"b¡ 4"R¡l©9 4©ªE©¢£"Q´¢]ª£©b¡«] ¡<¡
"¡
©££"¡
ªY£"·
¿ Ãg£" i©£bª£©´kµ ×®z¸ Ë ©x¸^Ç|Ð,©¤[" ¸ ¹º
ÞÜ
¼ ¡ OÍY¡ 4ª£©´cµ ßY¡¨U£aÇ|ÆQ©££" ¸ ¹º»\ÌB¼ ¬
­ #«P©ªEQª©a¢0Oa©_©cªE¡
Â´ªE9¡«^O<¡
¢£"e°¡«ªE¡
,à.ªE[¦« ©´£"¬3ÅáªE¡
à.ªE
¢<g¨A³¦« ©´£"G
®? 4=¡½¤l´£"£"[EÎ,¡
?¢<ª©´©Hª©a©©£"°,G¡
Ö©£" i©"®
¨3©°,?¡«U ¡
£"®a=ªE¡
à.ªE?l Â´" ¦]¬nâ¡ [©H¦« ©´£"l¡ °½¡«Q"Ä=ã^¸=´¤O¢< l¡«
ªE¡
,à.ªEA¤[©°¢<_ ¡<¡ "¡
©£¡Oã^¸©¦k©ª4@ªE¡
à.ªE3¤©°c¦¡
´¢£"U_´¤O¢< R¡«zEÎ,¡
¬
ÍYªE3A´¤O¢< Z¡«EÎ,¡
Zª©G¢<R ¡<¡ "¡
©£6¡ ¿\ä ¬W² 4"¡ i""IO¤©B°9ª©^´Â´£"°
¦ 4¤[¡¨¯©9ªE¡
à.ªE^¢<g¨Ak¦«P©´£^ ¡
£"®¦]¸B©¦[ªEUUª©_©©£"°,©R£"©¦
¡n©EÎ,<¡
6©£#B´¤O¢< G¡«YEÎ,"¡
?ª©¢<=©2®¡
¦¦]¬ ­ O
"® 4k¡½ÂB´"¡

¨U  4"¡ i""l¨R¡
´£¦¡
¤?aª© 4¡¦´ªE©nªE¡
¤?´©¡
©£©¦®©6©o
©QG¦ª¡
 ¡¢.£"¤_ªE¡
´£¦a¢0l¡
£"®¦C¤?¡ lEÕkª"B£"°©aaG´ i"¡ 4""Ä¦ª©¬
å\æå

çAè.ébê6ëìí.îïBðnè.ñGòRóîè.óîï,îô2ì
õoö_ì6ñ÷øëïaùZè0úîû,ü

ýZþÿ	ÿ
		ÿ"þEþÿ		!"ÿÿ"þ_þ#%$&4ÿ"þ4ÿÿYÿ'	(#)*+Rþ	,
þ#.-/ÿ 102/#3454"þ 

ÿ 6
7 ÿ *	8&49:;	E
þ +($&	ÿþ 4<Eþ +($&4!=ÿ >9[þ #?>A(
þ 4"þ 49(	4@$&4ÿ"þ 4ÿ ÿ :A#34
4"
þ 

ÿ (B3C	/,ED.FGGIHJKCLNMPOUþ 4@41DKFGGQRS69/
ý T4þ 

ÿ 	VU"oþ W	T+[ÿ Eþ EX
*&!ÿ A!"ÿÿ"
þ oþ#%!=Eÿþ þ #5#34Y4"þ 

ÿ ZB3-[ÿ DFG\]RS^V	A$4ÿ"þ 4ÿ ÿ Eþ þ 48	
E
þ S!ÿ"þ Gþ#_!=`4ÿ"þ D*&4ÿ 
Yþ .	þ 5	aY
þ þ.	$<!b	5$4ÿþ 4ÿ ÿ 6dcef	5
*4
V	NE
þ +($&4!=,ÿ g9kþ #b	Vÿ ÿ"þ h$&þ U&4+3þ #b		V4"þ 

ÿ /4@5	NEþ +($"4!=,ÿ >9=þ #K	þ 
þ#/-/ÿ 02N#34Y4þ 

ÿ DKU<ÿ 
ZEþ +($&4#þ V	Eþ &i44bþ #	A$<þ 49Eþ+ÿ 4.ÿ ***96
j
k	($iÿ"
þ 4ÿ ÿ ;	hþ 	4bþ *4ÿ 
cþ '	#l&4	D?	Eþ +$&4!=ÿ >9m!	NU9oþ 
44nD4ÿ 
[
þ +9Y*!	U&4boN	%$4þ $0þ 4ÿ ÿ"þ 4*þ ÿ
_ÿ þ 4O@ÿ d*!	U"4D
#P
þ 8!=+($&45Uÿ 	OUþ S4bþ pqX>4ÿ *44	6 j ÿ 	A	Uÿ **9Tiÿ !a$&	@ÿ 4,þ **8		
ÿ 5þÿ +ÿ 4@!*6
j
mE
þ ÿ `ZU`9r49`:ÿ 
sk$iÿ"þ 4ÿ ÿ :t#l4f4þ 

ÿ u	[@ÿ (U&þ vEþ +($&4@ÿ 
k	
-/ÿ N!=Eÿ"
þ þ #Z#l4	þ 	9'U9k4!=ÿ Eþ 
*$"ÿ fEþ +($&4@ÿ þ wB3-U@ÿ 	?D%FGGGRS6=/
ý 
ÿ 4ÿ"
þ A$&þ U&4+ þ #d	@ÿ 4þ 

ÿ Y@ÿ &*	h	ÿ ÿþ A$4þ U&4+Rþ #d-/ÿ 025#34L4"þ 

ÿ D
		&+ÿ 
x	h	'$0
þ 49`þ+[ÿ 4[ÿ ***9w`þ hþuEþ 44$&	6 7 þ Z#l&4	þ 4ÿ yUÿ 	z

þ 	4$&4ÿ"þ 4ÿ g9Y	4ÿþ þ +(/9E	!ÿ 449T	4@ÿ !4	8	/ÿ 8	(	/Eþ 	*$<þ ÿ 

$&4ÿ"
þ 4ÿ ÿ :kþ D&U&ÿ u
*4d{þ 	4K$4ÿþ 4ÿ ÿ 5
þ þ/	&!Y	NEþ +($"4!=,ÿ >9=þ #.	
ÿ 4ÿ"
þ r$þ U&4+6 7 þ $&	ÿ 4/$4ÿ"þ 4ÿ ÿ T*!	Uÿ 4ÿ >9t|U<Z*ÿ ³þ &49xYÿ 	r!=`*+(
9E	!@
ÿ V*4ÿ !ÿ"þ &D"	TEþ +($"4!=,ÿ >9ZU<ÿ 
	f	+(fUÿ 	Z	T$&4ÿ"þ 4ÿ ÿ :Z#34o4þ 

ÿ 
U`9yC	/,ZU9hCLo{OU
þ 44@6
}b~(&>gz>a<>&KPd%a_Kayd%.

ÿ

ÿ"þmOÿþE!Nþ+VU&4ÿYEþ!$	QÿWEþ+($&	ÿþ4KEþ+$&4!=ÿ>96 7 þ	ÿ4
þ
[
ý Eþ +$&4!=ÿ >9T4	bkEþ ÿ 		Zþ #_ÿ ÿþN$4þU&4+
	T	þ4IU&4[ÿ k$<
þ 49Eþ+ÿ 4b@ÿ +(AU`9k{*+[ÿ ÿ@ÿ ?K
ý iÿ 
Z+Sÿ 6u;T@ÿ 	4@	
þ#ÿÿþt$þ U&4+(	A*Wþ 4U&4@ÿ t$<þ 49`þ+ÿ 4Lÿ +(uU`9|sþ&*+ÿ ÿÿ =
ý 4ÿ 

+Sÿ6C/
ý h4	TEþ X>oEþ ÿ 	lþ #/$&þ U&4+N	hEþ +($&4+(	lþ #/[@ÿ *	c@ÿ x;6c

*4D?	4	NE
þ XeEþ @ÿ 	Qþ #%$&þ U&4+;	Eþ +($&4+(	þ #[ÿ S'	[ÿ m	4*V;6
ý N$0þ 49`þ+[ÿ 4ÿ *S*9h%Oáÿ /oÿE"ÿÿ **S9=þ #aEþ +($"4!=,ÿ >9u4	b  ¡D"¢  ¡V&W£  ¡
/
#P
þ [44<¤8¥v](	Uÿ 5!"hU`9y4ÿ 
Gþ *49
ý 4@ÿ 
(+*@ÿ /5#Pþ 44"qþ [6
cZ	 o!

YB3CL4
 :D`T  :DMU&	&
 DFGGQRS6

b  ¦¨§


  ¡ªK«
§

©

¢  ¦¨§
;%¬­ ®

¢

  ¡ªK«

©

Eþ
§

 X

£

©

  ¡ªK«

©

§

¬ ­®

bþ#_$&þU&4+a	Rÿ8!"4ÿ,/	[4@	 ¯ « !=!$%	bþ*4Yý4ÿ

lþ*4L#þb;$þU&4+ ÿ ¯² *	Oÿ&lþ#ýK4ÿ
[+A*ÿKYÿ	þ
	SkHþ*46³;*4ýKiÿ
h+*ÿ@Uÿ	'Hþ*4(#þYh$4þU&4+µ´¶*4ÿ,Gþ*ÿ&	9
ý4ÿ
u+SÿY!=E!$V	Y	9k+19'$_*#þ *+µ		Y#Pþ V+(+VU<*	ÿ $Hÿ k´·Uÿ 	sEþ 	
Eþ6¸¹$4þU&4+»º³ÿ A¼½E¾S¿lÀÁy¾	Â	Ã½Ä¿nÅÆÂ/
þ ($þ U"4+»ºaÇ]ÿ #d		ÿ 5@þ*49K
ý 4ÿ 
f+*ÿ 
Uÿ	{þ*4N#
þ ;º Ç 	[þ 4oº[6R/
ý Y$þ U&4+ ÿ U
ý 4ÿ 
T*ÿ U&4Q@ÿ u$<þ 49`þ+ÿ 4_ÿ +(9ÿ #
	A
þ *43K
ý 4ÿ 
[+A*ÿ þ 4ºmUÿ 	Vo$<þ 49`þ+ÿ 4`+VU_Sþ #!=Eÿ"þ f$&6¸t$&þ U&4+
ºTÿ  ¯fÈgÉ`Ê ¾Ã#
þ V{Eþ +($&4!=,ÿ g9k4	 ¯ ÿ #L44.$4þ U&4+ÿ ¯ 	$<þ 49`þ+ÿ 4ÿ +(ZË Ê À&Ì ÈÍ À_Â
¾	Â	Ã½Ä¿Å!ÆÂ%þGÿ J	&Aÿ D#P
þ 4@4$þ U"4+8º8Ç"Î ¯ 		_@ÿ 8V#l&!ÿ"þ ÏÐÑ<	U<oEþ +($"
ÿ '$<
þ 49Eþ+ÿ 4ÿ +?þ k	ÿ :[þ #Aÿ 	9ÿ $&iÏ Ð Ñ BlÒRYÎtºTÿ #%&Hþ 49oÿ #8Ò|Îtº Ç 6 j 	9
¯Y« °±

þ

  ¡ªK«

£  ¦¨§

 a	;4	

ÿ

+S 	bL

ÓIÔ1Õ

Ö[×ØÙqÚ"ØÛØ

Ü	ÝÞÜÜ	ÝßTàlá&âã!Ü	äåâ'æçè.äéÞÜê*Þâé	ëÞÜ	äåâWàlê	åì·íaîKÜåhí[ïðñê	åò&ëßì¶äéófôõ*ö÷[ø_ùúû>úäàaäÜ;ò<ßëåâüé
ÜåÜ	ÝßVãëÞé	éoóýÞâþuäéoóÿ>ÝÞê*þï


	
 !	#"%$&(')*
+

ßàlÞá&ëÜYëåüäãfäéåâß(åàÜ	Ýß(ìÞäâ'àlåê*ìÞë@ä-
, ÞÜ	äåâé;åàLâåâì(åâåÜåâ&äãTê	ßÞéåâäâü.0[
/ ßäÜßê2143257698S: ï
<;ú#=?>9@Eù ûLûBAEú	ö9CEDFHGHI0JLKNMPO/ã!åâé	äé	Ü	é/åàaÞAé	ßÜ[åàQ;ú#=?>9@Eù ûRCN@EùúES&TVUXW Y2K[Z[Z[Z\K]W^_\`a[Ýßê	ßbTc.lÜ	Ýß
ød	
C ú	õSö9ed;9f3û0f3ö7eg:N1h`.lÜ	Ýß{õSö9e"õùi@gSNfnö9eg:Þâ&þjWkK]lnmpo39K[Z[Z[Z\K]qrL.lÜ	ÝßtsN@gS û0f u%õN>û0f3ö7evS]:YÞê	ß(à)åêSìVáë@ÞßTåà
Ü	ÝßhãëÞé	é	ä@ãÞë%ñ&ê	åñ<åé	äÜ	äåâÞë8ëåüäã98
1 ÞâþÞ'éßÜwM åàTöyx0s ú	õû0fBz ú{=?> õ1ûBN
S Ü	ÝÞÜ(Þëéå'Þê	ßhàlåê*ìVá&ëÞßåà
Ü	ÝßãëÞé	é*äãÞë_ñê	åñ<åé	äÜ	äåâ&Þë&ëåüäãïað¹þßàlÞá&ëÜ%êSáëß|TVU}W Y2K[Z[Z[Z~K]W^_\'
` ãÞâhò<ß;áé	ßþAàlåê/äâàlßê	ê*äâüYÜ	Ýß
à3Þã!Üw
` äà
T Ý&ÞéNò<ßßâiþßê*ä- ßþ .
1 ÞâþxâåâßAåà[Ü	ÝßAàlåê*ìTáëÞßW Y2K[Z[Z[Z2KNhWs
^ ãÞâò<ßAþßêSä- ßþï{ð;é
þßê*äI
 Þò&ä@ëäÜf
 ÞâþyáâþßêSä-I Þò"äëäÜV
 Þê	ßìVáÜ	áÞëë-(
 þßñ<ßâþßâÜ[`1 Ü	Ýßê	ßäé%ãäê*ãáëÞê*äÜ(
 äâÜ	Ýß;þß?_ âäÜ	äåâ
åà)o
a ÝÞÜ5äéLþßê*ä- Þò&ëß;äâhþßàlÞá&ëÜëåüäãïo
 â&ëä- ßäâìåâåÜåâäãëåüä@ãé[1[
a Ýßê	ß;Ü	Ýßã!åâéß2` áßâã!ßé5åà
ÞéßÜ5åààlåê*ìVá&ëÞßYäé5þß?"
 âßþuÞé/Ü	Ýßàlåê*ìTáëÞßÜ	ÝÞÜ[ãÞâZò_ßþßêSä- ßþuògy
 áé*äâüTÜ	ÝßNÞ äåìéLåàbÜ	Ýß
ëåüäã(Þâ&þ'Ü	ÝßAäâàlßê	ßâã!ßfê*á&ëßé[
1 Ü	Ýßã!åâãë@áé	äåâéåàLÞuþßà3ÞáëÜÜ	ÝßåêFGI0JKNM
O Þê	ßþß?" âßþ
ÞébE
 ñ_åä@âÜ	éNåà/ÞWâåâ&ì(åâåÜåâäãAåñ<ßê*ÞÜåêïj/
 ÝßAåñ<ßê*ÞÜåê(ìÞ\i
 ÝÞ\ ßyéß[ ßêSÞë!
` ñ<åäâÜ	é[b
1 âåâß
åàQo
a Ýäã*ÝäéTÜ	ÝßuëßÞéÜE ñ<åäâÜ[b1 Þâ&þþ&ä_ ßê*ßâÜbE ñ_åä@âÜ	éTãÞârò<ßyéßßâtÞé(Þmê	ßé*áëÜNåà;Þññ&ë-E äâü
þä<
 ßê	ßâÜVìTáÜ	áÞëë'
 ä@âã!åì(ñ&ÞÜ	äò"ëßéßÜ	éTåà[þßà3ÞáëÜVê*áëßéï[
 ÝßE ñ<åäâÜ	éYåà/Ü	Ýßåñ<ßê*ÞÜåêfà)åê(Þ
þßà3ÞáëÜ5Ü	Ýßåêy
 Þê	ßNÜ	Ýßú û>ú?evSE3f ö9eL
S åàÜ	ÝßNþßàlÞáëÜÜ	Ýßåê ï
 âàlåê*ìÞëë-7K1 Ü	Ýßhã!åâéÜê*áã!Ü	äåâsåà/ßÞãSÝxß?E Üßâé	äåâiåà/Þmþßà3ÞáëÜYÜ	Ýßåês
 éÜ	Þê	Ü	éTà)ê*åì Ü	Ýßyåòÿ
 ßã!Ü	ä- ßAà3Þã!Ü	éMb1 Þâþsñ&ê	å`ã!ßßþ&éòys
 Þþ&þäâüuã!åâãëá&é	äåâéåà/þßàlÞáëÜê*áëßéÜ	Ýßñê	ßã!åâþ&äÜ	äåâéåà
a Ýä@ã*ÝAÝ&Þ2 ßÞëê	ßÞþvf
[
 ò<ßßâyþßê*ä- ßþ `1 ÞâþÜ	Ýß  áéÜ	ä_ ãÞÜ	äåâéaåà)[
a ÝäãSÝAÝÞ\ ß;âåÜò<ßßâAÞâþ[
a äë@ëâåÜ
ëÞÜßê/ò<ßYã!åâÜê*Þþäã!Üßþ?ï!/
 ÝßYã!åâé	Üê*áã!Ü	äåâußâ&þé[
a Ýßâuâåì(åê	ßNþßà3ÞáëÜ	é5ãÞâ{ò<ßYÞññ&ëäßþ?ï
ð

n( 
¡£¢h¤B¥L¦(§#¨ + ?ß "âßF©GI0JKNMOòg
ødCEn
f ú?S û Uy&;9CNfBev«~SS ô¬Iz ö2;«7> ÷>9eUd;9CEf­e«\SSô¬zIö\;«9> ødCEfnú?S û U÷>9e
K
K
K/Þâþ
J G ª
;9CEf­e«\SS ô¬Iz ö\;«9>
9; CEfBev«\S ôzö2;«9>
÷>9e
®
M
G !o ø¯CNf úE!S û#rZ
nTVUXWh_~WwãÞâ'ò<ßfäâÜßê*ñê	ßÜßþ'Þéé	Þ2EäâüyÜ	ÝÞÜÞâkäâþ&ä-`ä@þáÞëa[ÝåhÝÞéñê*åñ_ßê*ÜTV1?ãÞâ
ò<ßsÞé	é	áìßþzÜåwÞëéå|ÝÞ\
 ßiÜ	Ýßkñ&ê	åñ<ßê	Ü°
W äàTÜ	Ýäéuäéuã!åâ&é	äéÜßâÜ[
a äÜ	Ýo
a ÝÞÜußëéßsäéE âå~[
a âï
/ÝßVþßàlÞá&ëÜ/Ü	Ýßåê¶
F ÝÞé[Ü
a åß?E Üßâé	äåâ&é[1d±G³²hed.!o ødCEf úES û´K ÷>7edKN;7CNfBev«\S ôz ö2;«7>9r[
: Þâþ± î G
²hed.o!ødCEf úES ûK ÷>9e
K\;9CEfBev«\S ôz ö2;«9>r:N`1 Ü	ÝÞÜ8ê	ßñ&ê	ßéßâÜaÜ	Ýß/Ü%
a åVñ_åé*é	äò&äë@äÜ	äßéKåà_ê*ßéåë-E äâüÜ	Ýß[ã!åâv"µ äã!Ü
ò<ßÜ
a ßßâsÜ	Ýß" ê*éÜÜ
a å{þßà3ÞáëÜ	éNäâ{
J ï[
 Ýßfß?` Üßâé*äåâ·
± ã!åê	ê	ßéñ<åâþéÜå{Ü	Ýßã*Ýåä@ã!ßÜå{Þññ&ë
Ü	Ýßt"
 ê*éÜ5þßà3ÞáëÜ[1 ÞâþuÜ	Ýßß?` Üßâé*äåâY
± î<ÜåÜ	ÝßNã*Ýåä@ã!ßYÜåAÞññ&ëA
 Ü	ÝßNé	ßã!åâþï
¶
 ÝßE ñ_åä@âÜþß?" â&äÜ	äåâ'åàLß?` Üßâ&é	äåâéYä@éüä- ßâiâß?` Üï/
/
 ÝßëÞâüáÞüßåàLÜ	ÝßAñ&ê	åñ<åé	äÜ	äåâÞë
ëåüäã{äéAþßâåÜßþwòg¸[
· ï¹/
 Ýßmãëåé	áê*ßZåàÞiéßÜyåàà)åê*ìTáëÞß
º áâ&þßêAëåüäãÞëoã!åâéß2` áßâã!ß'äé
²hed.´º:4Go~»mj·{¼Xº°¼ G½»)r ï&/
 ÝßNéßÜ¾o\TVU¿W(Y?K[Z[Z[Z~K]W^_\`À¼ qÂÁ°8K?o\TVK]W Y~K[Z[Z[Z\K]W^dK`rÃ·QV
r åàaþßà3ÞáëÜ
ê*áëßéä@é5þßâåÜßþuògy
Ä ï/
 ÝßSEf-qÅ úLåàbÞ(þßàlÞá&ëÜLÜ	ÝßåêI0JKNM
O äéLÜ	ÝßYé*áì»åàKÜ	ÝßYëßâüÜ	ÝéLåàÜ	Ýß
àlåê*ìVá&ëÞßYäâM
ÞâþZäâuþßàlÞáëÜ	é5äâÆ{
J ï%ð þßà3ÞáëÜ5Ü	Ýßåêy
 ä@éR" âäÜßäàh¶
J Þâ&þLM Þê	ßt" âäÜßï
ðþßàlÞáëÜ

Ç y¥ ÈÉhÊ­Ë~ÊBÌdÉ°¦ §#¨ÂÍÎ¥Ê­Ë\¥yÏyÐR¨yÑ
ÒdÓÔÕ úûVFÖG×I0JLKNMPOwx*ú>;ú#=?>9@Eù û/ûBAEú*ö9CNDØÙdö9C>9eDSúû[ö=R=ö9CSô
÷E
@ ù>úº¹ÃÚ·QÛ/ùúûÜV.´º:wx*úAûBAEúSS÷>ùlùú?S ûSúûRSE@õ?AmûBA>ûRM ÃPÜV.´º:Ûb²he¯.0ÜV.´º:]:nGÜ4.´º:Û|>9ed;f =
TRÝ}W Y2K[Z[Z[Z~K]W^_\`Þm¸Jß>9ed;Tcm¸Ü4.´º:w>7ed;ohW Y2K[Z[Z[Z\KNW^r|àjº¹GHáyÛ;ûBAEú[eL`pmâÜ4.´º:?ØÆãÖSúû;ö=
=ö9SC ÷E@ ù-> ú{±äÃp·få/
S Þâuß?E Üßâé	äåâuà)åê¾Fæf =>7edu
; ö9e ùiDwf =QÜV.0±:G±çØ
èé2ê

ë4ìdí!îï~ð7ñdòóyôìdõöV÷vòìd÷vòóòø\ðù%únðõûvüïóLýì¯þ
òÿ


	!!"$#&%'(*),+*-%),#/.01243563789!5;:<!8
51==819363>
!8!?938@1	BACD6?	3=$E8363!F
G$HJIKLMINPOQ@RTSUVIWCXYIZLZ[\Z]4^_a`cb )edgfihkjml!)n'poqo'0+*"r-stluvwl0(4xys!)zg{}|,~mj
lxZ,o!l0-s)q)/'0+*69r,(and1${ l04
( xo'0+9lsCsaDvdB{(a,d¡ !¢¤£ ¥§¦©¨!ª!ª!ªY8¨«¬Y¢®­
~¥¯­d   M°¨  !ª!ª!ªY°±¨ «²0³ d{µ´ ² wJ
¶ !(
d·#Cel0(V¸6)¹(#&'0(V'po±zº# oel(4x'0(sB# od»{½¼ /¾ d  ª
¿ r!A§À(<!+pl6),#C(ZÀyxu&ol-st)/BAÁ3¡E83563¡@3u52BE83563¡3ÂZ5Ã73¡
A24358nÄ!nÅ13!Æ!
3Z?
:a!A±!A/5e24358F
Ç ZI È±ÉWCXÊW/K4ÉËOQOÌSUVIWCXYIZLZ[§\Z]^4_a`¯Í -ÊÎ6Î'Myz {Ï|,~»Ð#C¡lÌxu,o!l0-st)9)/'0+Ñl0(4xÒdP#Cyl(
¸u)¹(*#,'(¡'8oqz;Ó¶J!)e'8o=3!03=9!A,5w'8o1dÕÔ¤#/)/;+*¹Î%Y)§)'$zÖ#C
¥ÒÚu¨  !ª!ª!ª8¨ «
­~¯Û Ü
¥ ­;d}l0(4xV M°±¨!ª!ª!ª°¨« ²e³ d·{µ´4Ýrª
ÛÛ
¢
Û
G$HJIKLMINPOQ5ÞÌSUVIWCXYIZLZ[\Z]4^_a`¯Í -ÊÎ6Î'M§di#@1l0(;¸u)¹(*#,'(ß'8o1lwxu&ol-st))/'0+*nzº{·|,~
¶J!(md·{à(4á !¢£ ¥e¦©¨!ª!ª!ªY8¨«¬Y¢y­ × $,dÓzV ² 
× $,d9z9{ÙØ

¿ 1830Ó638Â3q0563Aâ!A/55=60$%l-),#&'0-1+lM!'0(#/(ZÀÓ£ {Bã3j+8l0.0
+lM!'0(#/(ZÀß£ {Bä*F
Ç ZI È±ÉWCXÊW/K4ÉËOQ@åæb !)zk{à|,~9jÓlxu,o!l0-st)1)/'0+Ðl0(4xèçÒ­Ühilo'+"r-stluc¶J(yzé£ {Bãç
# o$l0(4x'0(sè# oDçc­¡d·o'+rl0s/s±¸6)¹!(#&'0(Bdé'poBzèv§l0(<xÓz£ {BäÁçê# orl0(4x;'(s©m# oDçc­ydo'0+w'"Ó
¸u)¹(*#,'(md}'8oqz;
¿ AC6@5YÅ1@3=B8!?Ó36=Ã$8Ó3Ó!AC!3=B8w!A/¤5¤A!@3Ó8Ã3u1AC?Ó!F
ëD!A/5A<A/?¥ÁÚì¨¬Ê¨7¥ÁÚì¨BíB¢¬Y¢7î$Úï¨!ª!ª!ªY8¨«¬Y¢ß0	<Æ5ÃV(<'0+"Ól0s7<!!"$#/(4'0+*"Ól0s7
3èÎ<+8!+8ð!-#@*#/)¹!ñ©o*+F ¿ 8Ã?w:<6î»38qrÆM@mAC?$FÁò!Â58>AC!B!A/0
A/83;Å883;Å156	!Â58Úï¨  !ª!ª!ªÊ8¨ « ¬Y¢F§ó¡w@86?!?q38$8ÂZ3
¨!ª!ª!ª8¨«èAô8t24!063§:ZÃmõaõaö,õ138Ó63F
÷qa8?Ó3?Ó!A,5e!eÆBE83563!7:Á±'0+8xu+x
!A/5Á!5§F
øp3Ð6?$!!7Jè!563	:45?ùA/nm!DAÁ!A,5q!5BB3Z80:7<:4qA/B
:!3ßÅ1@ß$!A,5!10w!745180:5è,ú
8Ä$ûiü?Ó37ýþþýYF
øp3908!8563ÅeD35ÃZÄ!qB6?	5E5¹ÃAâ!5639	:5?9¤:a9Å1939Å156Á
!3635563F
Ç ZI È±ÉWCXÊW/K4ÉËOQÿÌSqXMHJILMW,ÉXYK<É[§\Z]4^4`¡b )z {é|,~»ßjlÐ!!"$#/(4'0+*"Ól0s1xu&ol0-st)n)/'+6
ß#,)/'0-)s5'MV'po
ÀZ!(<+8l0s#/),ylM*-"9V)/l)Bl0s/so'+"r-stlZml0+89#/(®%stl-Z!l0so!'0+*"®¶JÓ+8!stl6),#,'0(
l0(4	
x  l0+rxu,(<xßlMo!'0s/st'Ô±
 Coq¥®­¡v)/!(;¥Ò{µ¥ß¥J«o!'0+!'0"9cý6J'0+$l0s/s4¥ ¥w­c Y¥!ª!ª!ªY¥«

 
)/l)±¥J{Ñ
 ¥Mvs!)¤°±¥ ¥u

 Coß­Ü~v1)/(V{º¥§¦ì¨í;¢¬Ê¨Á
 

 v
b ) 

o!'0+*"$$'po1¥vJ¨µl0(4xw¢JvÁ+8Î%),#/.0s6
$ &
l %'Coq¥J­(ùl0(<x
¨)­*!Vvs!)¥J+

!

¨,Z
-/.10

² *-%!

l0(4x#"gj9)/Ó!!)/9'pos#,)¹+8l0s V'8oÓ)/è%!s5l0-l0s

243658719:5<;=5

>@?BACEDGF,HJIKMLN:OQP,RSI(TVUXW6Y[ZJ\F)H^]_P,Ra`
>Bb@AcWedf/U)PghP^i&jlkkkmjP<nDofqpXdofqr	Ysutwv=`yxzfp{Y|L=bo}G~ sU)PHgP<Hi|kkkJP<H nyJ}YpY
s

H tv=`z},,dS D{P H R P H 

I[P ii[ kkk  P nG nl

 `z}8YyDofWW6fEN)#Zp@LqN8dZE1Z ¡pYoW6LqZfqN8dS})fW6ODfp]
>BL&A'CED¢]

PLNOP]

FzU Z}8YoN#¢]

g P H  UXW6Y[Z\JP HE R ]
LNOP HE R	h

LN:O	]

P H  `

`

F`

>@?BACED¢]_PLNOQP]£FU Z}YoN#¢']¤F`
>Bb@ACED¢]_PLNOQPJ]

F¥fp4¢]

PLN:OQP]¤FzUyZ}8YoN#¢']¤F`

z}YO,YDLWZlZ}Yfqp 	¦§¨dG©qª|«<¬ª¬[«­ DLN:OfNWm ¡ DG¢']®¢'DofpN:fQ¢l`
¯°° ©qª|«<±³²<´*µ©·¶G¸<¬©qª¬[¹ºv±¨²»¼Xµ¸8¬ª|±¨²8´qµ©=²^½v[¾q¿=ÀqÁ½©qª|«8¬ª¬[«'«<¬ÂÃqÄ<Å³µÆµ¸8¬©qª|±6¬[Ç½Å³±6Èq¬	²<©qª|¹	ÃqÅ
«8¬ÂÃqÄ<Å6µµ¸8¬©qª|±³¬[Ç{Ãq²<«#Ä<²<Å³±³Èq¬Ç¬[¹±³²8©qª|¹	ÃqÅ«8¬ÂÃqÄ<Å6µµ¸8¬©qª±6¬[Ç{±³²´q¬[²8¬ª|ÃqÅÉ½<¸<Ã[Êq¬ÃµGÅ³¬[ÃqÇµ{©=²8¬Æ¬oËµ¬[²Ì
Ç±6©=²Í
ÎXÏÑÐVÒaÓÉÔÒ,ÓÖÕ=ÓÉ×8ØÙÛÚ'Ø<Ü@ÝÞyßÖÕàGÔázÓãâ8ä#åJæèçÒ=Ø8é·ê:ÝÝ^ëyÙìåJæíçÝÝ^ÙXØ<ÒÝ^ë ÙìîïÔzß+ßãÞ ëyÙXØ<Ò
ª ±6©qª|±6µ±6¬[Ç#±¨²Û«8¬ÂÃqÄÅ6µ*Å6©q´=± ° ¸Ã[Êq¬­ñ¬¬[²±¨²aÊq¬[Çµ±³´=Ãµ¬[«wñ)òÛólÃqÃq«<¬ª·Ãq²<«èô4©=Å³Å¨Ä<²<«8¬ª'»@v[¾q¾qõ=Á·Ãq²<«
ð 
ólª¬öGÈÃ¥»@v[¾q¾/÷,ÁÍì¶G¸8¬òøÊ±6¬öúùª|±6©qª|±6µ±³¬[Ç	ÃqÇV±¨²8ÂE©qª¹	Ãµ±6©=²ûµ¸<ÃµÇ¬[Å6¬ ° µÇVö4¸<± ° ¸ü«<¬ÂÃqÄ<Å³µÇÃª¬Ãù8Ì
ùÅ³±³¬[«¥²8¬oËµ¡ö4¸8¬[²

° ©=²<Çµª|Ä ° µ±³²8´øÃq²¬oË)µ¬[²<Ç|±6©=²^Í

µª|Ãq²<Ç|±6µ±6Êq¬	Ãq²<«ïÃqÇò)¹¹Ñ¬µª|± °

ð ª±6©qª|±6µ±6¬[Ç¡Ãª¬Çµª|± ° µVùÃª|µ±³ÃqÅ©qª|«8¬ª|Ç½4µ¸<Ãµ*±³Ç½
ª|¬[Å³Ãµ±6©=²<ÇÆýú©=²'µ¸8¬«<¬ÂÃqÄ<Å³µÇÍþBÂGÿ[ýÿÖ½µ¸<¬[²µ¸8¬VÃùùÅ³± ° Ãµ±6©=²©qÂGÿ
µ¸8¬«8¬ÂÃqÄÅ6µÿ(±³ÇQ¹Ñ©qª¬#Ç±6´=²<± ° Ãq²aµ

±³ÇQ¹Ñ©qª¬#«8¬[Ç±³ª|ÃñÅ6¬	µ¸Ãq²ïµ¸<¬ÃùùÅ³± ° Ãµ±6©=²ï©qÂÿ ½ Ãq²<«
Ã#¸<±6´=¸<¬ªùª|±6©qª|±6µãòqÍ

ólª¬öGÈÃ½zÃqÇÆöl¬[Å³ÅÃqÇSóÃqÃq«8¬ª

¬oËµ¬[²<Ç±6©=²<Çñ)ò*¹Ñ©)«±6ÂEò±³²8´Ñµ¸<¬QÇ¬[¹± ° ©=²<Çµª|Ä ° µ±6Êq¬

©qªÑ¸<ÃqÇ

Ãq²<«ô4©=Å¨Å³Ä<²<«8¬ª ½:´=±6Êq¬	Ã#«<¬:²<±6µ±6©=²·©qÂlù<ª¬Â¬ªª¬[«
«8¬²<±6µ±6©=²(©qÂ¬oË)µ¬[²<Ç|±6©=²<Ç»¶G¸8¬©qª¬[¹)Í)ÍmÁ(¶G¸8¬

° ©=²<ÇµªÄ ° µ±6©=²Ñ©qÂ^Ãq²Ñ¬oËµ¬[²<Ç±6©=²ÇµÃªµÇXÂª©=¹ìµ¸<¬4Ç¬µ
	

©qÂ©qñ@¬ ° µ±³Êq¬4ÂÃ ° µÇ½,Ãq²<«	ù<ª© ° ¬¬[«<ÇX±³²	ÇµÃ´q¬[Ç

ñ)ò#ª¬ù¬[Ãµ¬[«<Å6ò*Ãù<ùÅ³ò)±³²<´Ñµ¸8¬Q¸±6´=¸8¬[Çµù<ª|±6©qª|±³µ+ò#Ãù<ùÅ³± ° 
Ã ñÅ6¬S«8¬ÂÃqÄ<Å6µÇÍ4þB²·µ¸<±³ÇÇ¬ ° µ±6©=²öy¬Ãq²<ÃqÅ6ò¬
µ¸8¬

° ©=¹	ùÅ6¬oË8±6µ+ò¡©qÂµ¸<¬ÃqÇÇ© ° ±³Ãµ¬[«(«<¬ ° ±³Ç±6©=²ù<ª|©qñÅ6¬[¹	ÇÍ

!#"

O,YDLWZ¢%$ P& FEd4Ã ° µ±6Êq¬N('*),+
c

 D-'/. g¢èLN:O0'

. gw\JPLN:O1'

.  ghF`

R ?|YLOaYDLW ZZ}8Yfp& LqN:O¡ý
!32,4651787:9;<=7>9@?ACBBED>9<GFH"IIJLKNM Y[ZPOEQ  	S¡
Ld&Zp&b ZU8
T Lp&ZÖLWfpOaYopfN
Q ` M YZ'V),+ ?YQL	d[YZf@DXDfp&rQW6LaY[`XWQY#YXNY Dfp LWW<~ tZ)U

z}YNk'

'\[
g

	

'GH^]i
g

'4H`_baFdc

¢beqP

c
c

c
EdL ýml^T:pYD[Yop&pYOnLo

F

IAQ

 'GHf. g¢  '

Yqp=Z+YN8dÖfN'f@DjOEQ

.  g\JP  N:fÿ[ý

¢geqP
F

Ed

L=b[ZYN'GHhji

 	SRÆ DLN:O#fNWm V D-'ìgsr Ht8[-u N:»E' H Áo`

ólª¬öGÈÃv ÇQ«8¬:²<±6µ±³©=²±¨ÇSÇò²aµÃ ° µ± ° ÃqÅ¨Å6òÇ±³¹	±³Å¨Ãª[Íxw¬V¸Ã[Êq¬¬oËù<ª¬[Ç|Ç¬[«­±6µS±¨²'Ã#öÃ[òµ¸<ÃµQ¸<±6´=¸Ì
Å³±6´=¸,µÇµ¸8¬«±zy¬ª|¬[² ° ¬[Çµ©óÃqÃq«8¬ªÃq²«#ô4©=Å³Å¨Ä<²<«8¬ª{v Ç«8¬²<±6µ±6©=²^Í¶G¸<¬¹Ãq±³²#«<±zy¬ª¬[² ° ¬S±³Çµ¸ÃµGµ¸8¬
° ©=²<ÇµªÄ ° µ±6©=²V©qÂzÃQù<ª¬Â¬ªª¬[«	¬oËµ¬[²<Ç±³©=²Vùª© ° ¬¬[«Ç ñ)òÃù<ùÅ³ò)±³²<´S«8¬ÂÃqÄÅ6µÇy±¨²VÃq²¡©qª|«8¬ªÇù¬ ° ±z¬[«ñ,ò
Ç©=¹Ñ¬Çµª|± ° µ µ©qµÃqÅ:©qª«8¬ª µ¸<Ãµy¬oË)µ¬[²«<Ç µ¸<¬4ù<ª|±³©qª|±6µ±6¬[ÇÍ|<Ä8ªµ¸<¬ª|¹Ñ©qª¬q½)óyª|¬öGÈ/Ã´=±6Êq¬[Çl¸<±³ÇX«8¬²<±6µ±6©=²
Â©qª²<©qª|¹	ÃqÅ«8¬ÂÃqÄ<Å6µµ¸8¬©qª|±6¬[Ç©=²<Å6òq½^Ãq²<«µ¸8¬

° ©=²<Ç|±³Çµ¬[² ° ò*©qÂ!ÄÇµ±z ° Ãµ±6©=²Ç±³Çµ¬[Çµ¬[«Ã´=Ãq±¨²<Çµµ¸8¬

Ç¬µÇX'GH±³²<Çµ¬[Ãq«#©qÂµ¸8¬SÇ¬µ\'	Í

}~{


Gz0`^`z^G6`:6;C8^

 ¡¢£¤£¥¢¦!§^¨©6ª1« ¬=­®U¯
°±8±8¦U²N³;´¶µ1·E¸A¹»ºS¼¾½»´A¿ÁÀÂÄÃÆÅx¿ÄÇXÈG´#É¿ÄÊÇzµËµÌ´qÂÄÃÆÍb¿ÄÀÈAÎÏ¿NÐÆµEÃÆÑEÒµ
Ó ¿ÄÃµEÑ#¿ÄÇfÂÄÃÔÈ´ÃmÂÄÀA¸ÖÕd×>Ì´¶ÀAØÚÙ@ÛÜÑ3Ðj¿1ÎmÝ Ó Ã6´EÉ{´ÃÆÃÞ´qÈ{ß*´qàµá´À:Ð»Ñ#ÂÄÀgÂÔÉ0·E¸A¹»ºS¼ËÑ ÉjµÌ´Ã6´0ÑÐj¿dÐÆµEÃÆÑEÒµ
µâÂµâ¿ÄÇÂÄÃÞÈG´ÃãäÂÄÀ¸åÐ»Ê:ÒÌ¾µÌ¿µ;ÎÜÙæãä¿ÄÀÈ1Øèçsé\êë8ìHíÀLîEØ êâïPð Ì´¶ÃÞ´%ÉÂÄÃ1¿ÄÇÇ8ñò,óô


´

Ø ì
ç

Ø ê^õ;ö
ç

º

ù
ê þç
¸¹6Ø 
ù
ý
ú
úEûgü
ÑÐ ´¶ÀC´ÃÞ¿µá´6È¾½¶ÍËãkÕ
Ø ê8÷ÁøCù¾úú



ê þÿç
¹6Ø %



ù ¹jÀÂ ã

ù
ù
û ü
Á



	

ÑÐË¿Ò{µEÑ Ä´jÑÀ(Ø ê

û

!"#$"%'&)(*,+-"+-*.!,/0/1%&2)3"%*1+-*4+56"7+8*9":&;)=<?>?%;@:A
<*+51>B0	%C-D:+5*EF;)*G+5;)"H/"JIK/%*L&/<,C-"H*M"7,<+8H6"N1+51+-"+-%/OQP+-RS/%*T"')3A
"%*+5*U1/%%*T"&,+VRS/1%*9"IK<XW=Y%C-D:+5*EQ"Z;)*G+5;)"/OHZ//%&[)3"%*,+-*=<\?<
/"4$<C8C])3"%*,+-*6^<N&/_<C-"6"/1WO
`a ®,bdc$e  A¦>§#°gf /"^h çè·E¸A¹»ºS¼ K<=&/_<C-"!"/WZ<*& Î <="@+5;)"i,<\"+5<CT1&/i* ¸kj I/
Ã»Ñâ´ÆÐµ 
Ç Ñ0
l ´Ý ÃÞÂ{Ò)l Ý À:Ý ÃÞÂÄÇÇ ¹ Åx¿ÄÀ Ç Ñ0l ´¶Ý ÃÞÂ{Ò)l Ý À8Ý ÃÞÂÄÇÇ ¹ Ó Ã»Ñâ´ÆÐµ Åx¿ÄÀ  ¹
ø Ó
¸
ç
%Ç Ñ0l´¶Ý ÃÞÂ{Ò)lÝ À8Ý ÃÞÂÄÇÇ
Ç Ñ0l´¶Ý ÃÞÂ{Ò/lÝ À:Ý ÃÞÂÄÇÇ
Åx¿ÄÀ
ü
ü
º
ç
m Ó ÃÆÑâ´ÆÐÆµon ¹ ü <*&
ÃÆÑ#´ÐÆµ 
Ç Ñ0
l ´¶Ý ÃÞÂ{Ò/l Ý À:Ý ÃÞÂÄÇÇ ¹ Åm¿À Ç Ñ8l ´Ý ÃÔÂ{Ò/l Ý À:Ý ÃÔÂÄÇÇ 
øqp Ó
Î
ç

Ç Ñ8
l ´Ý ÃÔÂ{Ò/l Ý À:Ý ÃÔÂÄÇÇ
Ç Ñ8
l ü ´Ý ÃÔÂÒ)l Ý À:Ý ÃÔÂÇÇ r
ü
s,1+-1+-"+5% Î "<\"t"<\"[IU%*u%<*,+5*Ev<\"F>N<C-s,1+-%" j +5*1>N<\"+5*w%;/+V(;x"
1+5%"Q1C5&yXD/1+8&x+8*0@>N<\"+-*y;)*,;)/1*+5*Ez>?%*{+5*gE%*/1<CoO}|H"x)3:"%*+-* Ø ç
íÀî~m Ó ÃÆÑâ´ÆÐÆµá¹¶Åx¿ÄÀ8¹@
Ç Ñ0
l ´Ý ÃÞÂ{Ò)l Ý À:Ý ÃÞÂÄÇÇn ï <*& Ø% ç íÀî~m Ó ÃÆÑâ´ÆÐÆµá¹¶Åx¿ÄÀ8¹¶Ç Ñ8l ´Ý ÃÔÂÒ)l Ý À:Ý ÃÔÂÇÇVn ï *C-W Ø +5
Î A//%&St<*,& Î A//%&SS6OK*F"	6<<&/=<*&[C5C5*,&/&)(*+5"+-*+-"U+5U"<+5*%&k<
Ø ç é\êë8ìHíÀCîEØ êâï IU/ Ø ì çm Ó ÃÆÑ#´ÐÆµ_
n ¹6Ø ö çm Ó Ã»Ñâ´ÆÐµâ¹¶Åx¿ÄÀ8¹@%Ç Ñ0l ´¶Ý ÃÞÂ{Ò)l Ý À8Ý ÃÞÂÄÇÇn <*& Ø ê ç*Ø ö
f
ñ
{
ò

j
Y<C5C O^*"+8^)3"%*,+-* "U;)*:G+5;)"^/"~I./%*7"4(,1"$"~I.Z&/_<C-"q+5i1%C-D%&7+8*<XD
i"=(,1"4*O

	&)(*,+-"+-*<\1	*"%T,+-D<C5%*9" j <&%>N*"1<\"%&xW"C5C-IU+5*EN)3<>?,C5E+-D%*kTW
6<<&/	<*,&MUC8C5*&/ î% ï O2K<<&/	<*&MC5C5,*&/H<C5FXI"<\"	>?N)3:"%*+-*,'<\
//%& S "*"1/0/1%& ß O
n <*,& Î çm · ¹
¼1n OYU)3:"%*:A
`a ®,bdc$e  A¦>§8f /" ¸ çm ¹ ¹ ¹
ï
+-* Ø ç íÀî~m ¹ ¹@ n +5 Î A//%& ß ,"H*" Î A,/0/1%&  O7?)3"%*1+-* Ø ;/<*,*"
	,"<+5*%&xIU+-" x "? 6<<ü& /' <üV*)&\  ü%C5C5 *&8 /ü %& )(S *+-"+-*]O=  Ø   üç% íÀüî~m % ¹ ¹  n ï "?K<<&/
<*&C5C5*,&/K&)(*+-"+-*21&,;)%."'/" Ø'ì ç¡8j Ø'ö ç¢m ¹ nj Ø'£ ç¤m  ¹  ¹  n <*& Øê ç Ø'£
<C5C ñPò¥j <*,&"7*+8T Î A//%& S )3"%*1+-*M+5 Ø   ç/é\êë8ìUØ'ê ON *s K/IU¦<:§	&)(A
*+-"+5*I.;/<*xTW,<U"+-E/1+-1+5"JW#&/<,C-" WF+5*E7<7""<C$1&/1+5*ENI/
C5C-XI <*&
ON+8=IK<XWxIK?"<+5*M"üN% /" Ø ì ç¨¡j Ø ö çm nj Ø £ çm ¹@ ü/\n j
ØU\
© ç¤m ü¹@: ¹ n <*, & ü Ø %ê ç  ØU© U<C5C ñòvª O

 
« *, %T% *;)4%C5<\"+-*,!",<\"q;)%*&"';/<"+5i%<*+8*EH+5*¬%+-"/%§Y&/<,C-"$C5E+5;4<\
&)(*%&<C5C-XI/O
­®%¯
Ð¿ÍdµÌ¿µØ

°U±-²³´²µ²
¶·T¸i¹$º0»º¼¹g½¿¾-½ÁÀÃÂÄkÅ@Æ\ÇÈ%ÄÉ/Ê,Ä/ÇÅ@Ä[ËÄ)Ì-ÍÎ_Ï_ÆÇÈxÐÑHÒÍ\ÇSÓzÐÑÔSÕÖÍ\ËÄkÓTÄ_×qÇSÄ1ÓLØ/Ù[ÚÛÐÑHÜÞ
Ò Ï ßFÍ\ÇSÓ
Æ\ÇÌÙFÏ ßZÎÂÄß/Æ\ËáàÊÌ-Í Ý Ï8ÈÏ0ÇzÍ\ÌÌSâ?ã8äËÄ_ß%Ä)ËáËÄ1Ó Ò Äå9ÎJÄ)ÇÈáÏ_Æ\ÇÈNÆßHÚ#æÍ\ÇÓ2ÚçÐÑ ÜÔÕ Ý Ï ßNÍ\ÇÝÓkÆ\ÇÌÙFÏ ß
ÎÂ:Ä.ß/Æ\ËáàZÊ:Ì-Í Ý Ï0ÈHÏ0ÇMÍ\ÌÌâ?ã8äËÄoß/Ä/Ë@ËÄÓÔSÕ}ÄåÎJÄ/ÇÈ@ÏoÆ\ÇÈÆßUÚFè
éK·êLêtë½Ã¾5ì¤íÃÄ%Îqî_ï[ð@ñóò'Ø@ÄÍ?ÇÆ\Ëáà?ÍÌ!Ó9Ä_ß/Í\Ê:ÌVÎqÎÂ:ÄÆË@ÙQÍÇÓ'ôÁÍÈ)Î_Ë@ÏoÅ%ÎqÎÆÎÍ\ÌÃÆ\ËÓ9Ä)ËÆ\Ç2ïxè?ÀÃÂ:Ä/Ç
ß/Æ\Ë'Í\Ì0Ì:õ÷övøæ]õÖÏ0ÈÍôNã8äËÄoß/Ä/Ë@ËÄÓÔwÄåÎJÄ/ÇÈ@ÏoÆ\ÇÆß=î_ïkð@ñóòÏ ßHÍ\ÇÓQÆ\ÇÌÙÏ ß6õÏ0È=ÍHôQã8äËÄoß/Ä/Ë@ËÄÓÔSÕ
Äå9ÎJÄ)ÇÈáÏ_ÆÇsÆß	î_ï[ð@ñóò)è
ù6ËÆ%Æß/ú	û~ü4ñ ý5þ=ý5ÿ ÿþý8þ %ÿ 	
%ÿ 7ý5ÿ ÿþý5þ %ÿ %ÿ,þý ÿsø¤ý5þ ÿý ô /ü 	!,Ò
ô /$ü 	! ÔÕ %%ÿþý &ÿ üH(Ú '&)% þþ *+[ñ ý5,þ ÿþý5þ %ÿ 	'.-/1032þþ *+( " Nõçý5þ
" ÿ #
ô" /$ü 	!,Ò4%ÿ,þý 5ÿ ü'î_ïkð@ñó6ò '87:9;" <Sÿý ý ÿsõB>
#
Ñ =@?$ABDC$EÇ -_õ ? 06GF@	7õ ? "  " þ	ý5ÿ
HI<ÿý Jý L
ÿ K'NM'PO
	Rõ ?Q ð SPTVUWX	þ 	þõ ? ý58ÿ HI<ÿJý ý Lÿ K'NY'PZ;Zþ [F4 " õ ? Ñ#õ ?Q ü \ "\]J]
S^TVU% " ÿ %ÿ Uõ¤_
Ñ = ?$AB C$EÇ -_õ ?Q 0iý5þ " #ô /$ü 	!Ô`Õ %%ÿþJý +ÿ ü¿(Ú '^a@ÇÓ\ÊÅ%Î_ÏoÆ\Ç#Â9Ù@ä:ÆÎÂÄáÈ@Ï06È b
?
õ Ñ¤õ ?Q 'cÍÈ%ÄNÅ@ÍÈ/#Ä S.d
Ñ U%beû **+!ý \'a@ÇÓ\ÊÅ%Î_$Ï f\ÄNÅ1ÍÈ%Ä SgTihjb@2þþ *+R $ü \k:bmlGnol1pMqï 
õ ?$rts Ð4Ñ k:õ ?rts3Ðuw
Ñ vxl " ÿ kÿzy3ô k:bm" lGnol ý5þ " Jý {\Zý5ÿ[õ ?$rts 'g|@%ÿ }l&pkõ ? 'g" 7P9Lý5ÿ ý ÿ
9~\%þý8þYõ ?$Q rts Ð 
Ñ k " ÿ Qÿ,yX,ô k:bmlGnolsý5þ " ý {\ý8ÿ7õ ?$Q rts 'Zþ [FlpFõ ?Q ý ^!* " ý5ÿþ þ oF
 " 'õ Ðu
Ñ vGl'+7P! þ 7õ ý5þ ÿþý8þ %ÿ  ÿ sõ ? ö õ ÿ lpzõ ? Ãõ Ðu
Ñ vGl',|@%ÿ lVpz#õ ?Q
ÿ" dõ ? ö}õ ?Q '8^" Pü üõ ?Q ö÷õ ? ý5þþý *Ný "]J" !'Qû Zþ %z%" }þ ~ý5ÿ #} " õ Ðu

Ñ vGl{ý *+ ] ý %þ
$
?
t
r
s

?
t
r
s
u
õ Ð4Ñ vxltþJý *+ ] 9W~! " þ 'õ ögõ '
-10#O	Z
õ W~ ô /ü 	!ÔÕ %%ÿþý ÿ üî_ï[ð@ñó6ò 'L|@%ÿ QõB>
Ñ = ?AB C$XÇ -_õ ?Q 06F	
õ ?Q ð ST>U " (þ " 	þ?ý8ÿ HI<ÿ,ý ý ÿ K'NY'O	Nõ ? ð ST>UqW~þ 	þNý5ÿ HI<ÿý Jý ÿ K'NM'Z;
þ oFW9tý8ÿ ý 
ÿ  " ?õç
Ñ = ?AB õ ? 'a@ÇÓÊÅXÎ_Ï_ÆÇvÂ9Ù@ä:ÆÎÂÄáÈ@Ï06È bõ ? Ñ #õ ?Q 'cÍÈ/Ä[Å1ÍÈ%,Ä S	
Ñ U%b
eû **+!ý " \'a@ÇÓÊÅXÎ_Ï fÄÅ1Í\È/3
Ä S}Thjb+2þþ *+ " Z$ü \}k:blGnoldpyï iõ ?$Q rts Ð
Ñ k^^õ Ðu
Ñ vGl " ÿ
ÿ y,
ô k^bmlxnolóý8þ " ý {\ý5ÿv#õ ?$Q rts '.|@%ÿ lp #õ ?Q '.7:9[ý5ÿ ý ÿ 9~\%þý5þ7õ ?$rts Ð
Ñ k
ô k:blGnolgý8þ " ý {\7ý5ÿtõ ?$rts '
xþ oFil.pvõ ? ý #!* " ý5ÿþ [þ [F " õ ?$rts(Ðu
Ñ vGl'
" ÿ MÿyX,
7P! " þ 2õ ?$Q rts ö õ " ÿ sõ Ðu
Ñ vGl^Ãõ ?$Q rts Ðu
Ñ vxl'7P9Ný5ÿ ý ÿ 9~\%þý5þHõ ?rts Ñ÷õ ?$Q rts '
|%ÿ kõ ?rtsÐu
Ñ vGl'D	/$ü \[Rõ ?Q öBõ ? '^ü üHõ ? ö Rõ ?Q %	!þ7þ1Jý *Ný ]J"  ] 9\'2þþ *+
 " $ü \k^bmlGnolp
ï Yõ ?$rts Ð
Ñ k:.õ ?rtsÐu
Ñ vGl ÿ ÿ ;y3ô k:bmlGnol¢ý8þ ý {\Fý8ÿLõ ?$rts '7:9
ý5ÿ ý (ÿ 9~\%þý5þ4Rõ ?$Q rts ÐÑ k " ÿ Fÿy3ô k:bmlGno" lzý5þ " ý {\Zý5ÿ#õ ?$Q rts 'qû" g!* " ý5ÿ þ Qþ [F_ " 
õ Ðu
Ñ vGl') þþ *Nõ Ð¡
Ñ vGl^',7P! þ k^bNlGnolyý5þ N#ô   þ  Jý {\/ü "  ]  " ÿ sõ Ð
Ñ vGl
õ ?Q ÑRõ ?$Q rts  " ÿ " sü¢	HRõ £ Q Ñ}Rõ ?$Q rts " $ü \ "\]J]¤ T¥S'@	/$ü \] " NõÖ" 
#
Ñ C$EÇ -_#õ ?$Q rts 06'Dý8þ ]  " þ
ÿ FUý  " þ1þ *+Jý ÿsõçÐ
Ñ vGl " ÿ ;Nü " 	õ ?$Q rts Ðu
Ñ vGl¦\W ý5ÿ !;Fý 
" ÿ  " ýJJý ;
ý5ÿ ý ÿ 9~\%þý5!þ ',@	/$ü \+ " þþ *+ý ÿý5þ'ü "\] þ \ " ÿ Mõ Ðu
Ñ vGl^'D"	/$ü \lp õ ?Q
õ ?Q '
§
" ÿ Fõ ? ög#
½¿©¾ ¨ª	¼Sê «x¬· ­Ãº0¯» ®vº¹yo» °!;· ±#·¹!· ²ë ¬@ª	ë ³X·
Zuý 	ÿ %þ 1Jý ý ÿ
þ 3ÿ Kü \*wEü /ü "  ] 	þ oW~\}g7P	FD´ "" ÿ } 7 "\" 	 " ÿ 3|@ ]J] ÿ 	
1Jý \1ý ý µ	!,/ü "  ]  ] \¶ý /þ " @* ] 	$ü \Uþ !
ÿ 	{\ ~ü g~ 9ÿ *Ný ý 	 9\'Dý5þ
*+ " ÿ
þ  " 	 " +~ ] 9:ÿ *Ný "\] Jý *+, " ÿþ ]" ý ÿIþ W~] 	·FP] 	%5ÿ " ý ] þ  " þ "\] ÿý5ÿ ¶#" ý5ÿ ¸D%Jý 	!¹þ
/ü "  ]  ] \¶ý " ÿ (#@ý \1ý ý µ	!{\	1þ1ý ÿg
þ xü " ý Dþ  " þ ÿý5ÿ ¶Ný5(ÿ W~\Lü %þ  ] \¶Jý /þ!'
¼ ²·ê ½¿J¾ »ÁÀÄ)ÈáÎ_ÏÇ ¼NÚBÐÑHÜÒ Ý ß/Æ\ËZÇÆ\ËáàNÍ\ÌqÓ9Ä_ß/Í\Ê:ÌÎ4ÎÂÄÆ\ËáÏoÄ)ÈHÚ#æYÈáÎ_ËáÏoÅ%Î!ä:Í\Ë)Î_ÏoÍ\ÌqÆ\ËÓTÄ)Ë@Èâ Í\ÇSÓ
º °Ã·
ß/Æ\Ë@àÊ:Ì-Í9Ä Ý Ï0ÈD½:¾¿\ãÅ1ÆàUäSÌ-Ä%ÎJÄ%è
ù6ËÆ%Æß/:ú D½P¾¿¯· " ,ÿ%þþKý5þ W~! " þ IFUý  " ÿ !*·91ý \1ý 9, ]J" ý ÿ 7P	FD´ " ¹þ ] \¶Jý @ý5ÿ /ýJ%þ
FUý ¸@%ý 	!¹
þ /ü "  ]  ] \¶Jý L-¢^\~þý ý ;ÿ À#ý5ÿ -¢7P	FD´ " ^h!Á\ÁÂK006GF@Jý 6xý8þ ½ ¾¿6· " 	{\%5ÿ FUý 
ÃoÄ[Å

ÆPÇEÈ^ÉÊoË\ÌEÍÏÎÐ5ÇEÑ,Ò:ÓÍJÇEÓÍÏÎ%ÍJÔ[ËÕ`ÖIËÑ×ØÊÎqÙÇXÚÍJÛ%Ü

ë
ù
ÿ





	

ë

\ë ë
ë!ù
ë!ÿ
ë

Ý	ÞJß\ààDá\âxãä	â$ß\åÞJægæçä	á\èéä!à
ãéJà¢ìåíÝæéáí%îâ$èä	ä
åíßjèú
ãéJà¢ìåíÝæéáí%îâ$èä	äá\èãä	èä!ã
á\èãä	èä!ã8åíßjèú
ãéJà¢ìåíÝæéáí%îâ$èä	äíá\èêß\Þ
 á\èí
íá\èêß\Þåíßjèú
 èä	è
ä åéàéæäîâ$èä	ä
 èä	è
ä åéàéæäîâ$èä	äá\èãä	èä!ã
 èä	è
ä åéàéæäîâ$èä	äåíßjèú
 èä	è
ä åéàéæäîâ$èä	äá\èãä	èä!ã8åíßjèú
 èä	è
ä åéàéæäîâ$èä	äíá\èêß\Þ
 èä	è
ä åéàéæäîâ$èä	äíá\èêß\Þåíßjèú
 èä	è
ä åéàéæäîâ$èä	ä  áàéæé \ä#íá\èêß\Þtåíßjèú

âá\èê>á\âGãä	â¢ß\åÞæà
ï	ðñ%òmòmò ñïóô õðñ%òmòmò ñõ©öjñ÷eð·ñòmòmò ñ÷ø
û ô ü û ô üeñý\þ õðñ%û òmô ýòmò ñü õ©ö
ü
ü
ýü
ï	ðñ%òmòmò ñïóô õðñ%òmòmò ñõ ö ñ÷eð·ñòmòmò ñ÷ ø
û ô ü û ô üeñý\þ õðñ%û òmô ýòmò ñü õ©ö
ü
ü
ýü
ï ð ñ%òmòmò ñïóô õ ð ñ%òmòmò ñõ ö
û ð·ñ%òmòmõò ñ ðûñöòmòmô ò üñõ ûö ðñòmòmò ñ û öô ýü
ü
ýü
û ô ü û ô ýü
ü ýü
ô õðñòmòmò ñõ©öjñ÷eð·ñ%òmòmò ñ÷ø
õð·ñ%òmòmò ñõ ö
ô õðñòmòmò ñõ©öjñ÷eð·ñ%òmòmò ñ÷ø
ô ü ô üñõ ýð þñ%òmòmôò ýñüõ ö
ô ü ü ô üñü ýþ ô ýýü ü
ü
ü
ýü
ô õðñòmòmò ñõ©ö
ô õ ü ð ñô ýòmòmò ü ñõ ö
ô ü ü ýü
ü
 ßÞä ë á\èê>á\âxãä	â¢ß\åÞæàDéJíLß+íåê~ä	ègá\âxÝ	Þß\ààä!àgá\âãä	â¢ß\åÞægæçä	á\è6éä!à

æçäzèä!àæèéJÝæéJáí;æáqíá\è6êß\Þ^ãä	â¢ß\åÞæàIá\ææÞá ë 		\ù ! ä(àçá#"æçßjæ}æçäzÝáê  Þä!ê+ä!íæ#á\âgæçä
 è
á EÞä!ê éJà3éJ%
í $ û & '"@çéJÝ6çãéèä!ÝæÞú;éJê  ÞJéJä!àæçßjæ3æçä  èáÞä!ê éJàRéJí)( û & * çäÝáê  Þä!êä!íæßjèú
 è
á EÞä!êéà@æçä3,ä +éJàæä!íÝä,á\â^.
ß -î  èä	â$ä	èèä!0
ã /1,ä +%æä!íàéáí*1àåÝç`æçßjæ3256 4 1 3 çä7åä!ààéí87zá\â
ß`àæèéJÝæ3æá\æß\ÞPá\èãä	:
è 9æçßj;
æ 7\ä!íä	èßjæä!àß\í,ä +æä!íàéá%
í 1àåÝ6çæçßj<
æ 2=6 4 1Ý	ß\í)~äzãáíäúß


íáíãä	æä	èêéJíéàæéJÝ åè6éJ8í 7,êß\Ýçéíä#éJíLß áÞú%íáêéJß\Þ~íå>
ê ~ä	ègá\âxàæä  à  7åä!à?
à 9ß\í@
ã 7åä!ààgæçä
B


ÝáíÝ	ÞJåàéáíà á\A
â 7\ä!íä	èßjæé8í 7ãä	â¢ß\åÞæàgá\'
â 1
çC
ä \ä	èEé DEÝ	ßjæéáí8æçßjF
æ 1¡â$åEÞ DEÞJÞJB
à GPèä "?HjJß Ià@ã,ä DXíéæéáí
O
æß H\ä!àIß  áÞúíáêéJß\ÞXíå
ê ~ä	ègá\âàæä  K
à "@éJæçLß\!
í LFMVá\èß\Ý	ÞäRâá\è  èá  áàéæéáíß\Þ~àßjæéNà DEß éJÞéæ·ú 
P;QSRUTWVXRUY[Z\^]`_0a,bdcfe^gih?j`k l3mon
p
2 eb ( û & { r } x aca
 srrNqu
éH\äæçä 
7åä!ààä!ã 

23q,rsut a q,vwUx coc^yJa rs eadb'j.z0b,c s e|{c~} vs fc e 
v xrst a s b -=v g t'q,rsdwJxEv a

èáá\âá\âGæçä  èäéJáåàPæçä	á\èä!ê>ä,+Ýä  æDæçßjæ@íáàæèéÝægæá\æß\Þá\èãä	è6àDíä	ä!ãLæá<~ä
O

Z\`TYA^R~Sd^oS#^0^.RiVX^#Ri RU
¡

í æçéJààä!Ýæéáí<"PäéJíi\ä!àæé7ßjæäæçä@Ýáê  Þä,+%éJæ·ú,á\â~æçä  èéJá\èéæé¢	ä!ã+ãä	â¢ß\åÞæÞJá7éJÝ	àéJíàúíæß\ÝæéJÝ	ß\ÞJÞú
+
èä!àæè6éJÝæä!ãLÝ	ß\àä!à  çéJàPàå8%ìä!ÝæPéà:èä!ÞJßjæä!ã(æá+æçäèä!àä!ßjèÝ6ç(áí(æçä£~áåíãßjèú:~ä	æ¤":ä	ä!í(æèß\ÝæßEéJÞÏî
éæúß\íã5éJíæèß\Ýæß éJÞJéJæ·ú`á\â ãä	â$ß\åÞJæ#Þá 7éJ
Ý "@éæçáåæ  èéá\è6éæéä!¥
à §
ú ¦#ß\åæ ¢ß\í)
ã ¨%ä!ÞJêß\
í  ë 		%ë  ß\íã
ë


	

	
~




*



¨æéJÞÞJêß\
í 
éJèà3
æ "Päß\íß\Þiú ¢	äzæçäzÝ	ß\àäéJ
í "@çéJÝ6ç;æçä èéá\èéJæéä!à#ßjèäàæèéJÝæ}æá\æß\Þ^á\èãä	èà 
 çä!>


í ":ä Ýáê ÞJä	æä:æçä Ýáê ÞJ,ä +%éæú#ß\íß\Þú%àéJS
à ú,ä +%æä!íãéJ
í 7@æçä:èä!àåÞæàæáßj©è éæèßjèúàæèéJÝæ  ßjèæéJß\Þ
á\èãä	è6à 
¦#ß\åæ ¢ß\íª
ã ¨ä!Þêß\í5ß\íß\ÞUú ¢	äæçäzÝáê  Þ,ä +éæ·ú`á\âgãä	æä	èêéíéJ8í 7æçä,ä +éJàæä!íÝäá\âP,ä +%æä!íàéJáíà 
Ý	ß\åæéáåà^èä!ß\àáíéJ8í 78%ß\í
ã èß \äIèä!ß\àáíéJ8í 7Râ$á\ègãä	â¢ß\åÞæ^æçä	á\èéä!«
à "@éæçãä	â$ß\åÞJæà^á\âæçä@â$á\èê¡ÞéJàæä!ã

ë


éJí ß Þä
$,ä +Ý	ÞJåãéJ
í 7Læçä èä	èä åéàéæäîâ$èä	äÝ	ÞJß\ààä!à ß\í§
ã "éæç;á %ìä!Ýæé \ä  ßjèæà#æçßjæ}ßjèäàä	æà
¡


ë

á\â@ÞJéJæä	èß\ÞJà
í ß Þä æçäÞJä	ææä	è
à ¬0­¯®#­©°:± áààé EÞúqà
å àÝèé  æä!²
ã ±;ãä!íá\æäÞéæä	èß\ÞJà xß\íãæçä
³#´µ

¶¸·¹8º#»0¹¼¹

½¾¿¿¾À¯ÁBÂÄÃ©ÅiÃÆ.Ç8¾È8É¿¾ÊÀ©ÉÊoÉÁ©Ë¿©ËÉÈÌ½ÍÌÀ¯ËÌÎ0½¾ÁÏ>ÐU¿©Ë½½Ñ<ÌÈÓÒ,ÉÈÁ¯ËÇ8¾À¯ÁFÉÈ½Ô!¿©Õ¾ÊÀ¯ÉÎW½¾ÑÖÉ×ÎÀ¯ÌÍ¾
À©¾ÌÁÉÈWËÈ8Ø8Ù~Î0Ú8¿Ò,ÉÈÁ©ËÇ8¾À¯ÁÌ>Û¸ËÇ8¾ÀÀ¯ÌÈ8Ø¾¸É×Ò½ÌÁ©Á¾ÁÏ'ÜF¾¥ÌÈÌ½ÔiÝ¾ÁBÇ8¾×fÌÚ½¿Þ¿©Õ8¾ÉÀË¾ÁÞ¿©Õ8¾FÉÎJß¾Ò,¿©ËÍ¾
ÊWÌÀ©¿©ÁFÉ×ÞÛ¸ÕWËÒ¯ÕàÌÀ©¾;Á©¾¿©Á¸É×ÜFÉÀ¯È²Ò½ÌÚÁ¾ÁFÉÀ£Á¾¿©Á¥É×«á#â½Ë¿¾À¯Ì½ÄÒ½ÌÚÁ¾ÁÙÌÈÇ²Ì½ÁÉ¿©Õ8¾ÒÌÁ¾ÛFÕ8¾À©¾
Ç8¾×fÌÚ½¿©Á¥ÌÀ©¾ÊÀ©¾À©¾ãUÚËÁ¯Ë¿¾,â×À¯¾¾ÏEä²å?Õ8¾;Ñ:ÉÁ¿£Ø¾È8¾À¯Ì½æ¿À¯ÌÒ,¿©ÌÎ0½¾:Ò½ÌÁ©Á¾Á£ËÈ²Ç8¾×fÌÚ½¿F½ÉØËÒ>ÛFË¿©Õ8ÉÚ8¿
ÊÀ¯ËÉÀ¯Ë¿©Ë¾ÁuÌÀ©¾3¿©Õ¾C×É½½ÉÛ¸ËÈØ8Ï
× ¿©Õ8¾KÉÎJß¾Ò,¿©ËÍ¾?ÊWÌÀ©¿«é[Ñ<ÌÔÒ,ÉÈi¿©ÌËÈ<ÜFÉÀ¯È<Ò½ÌÚÁ¾ÁÙ~ÈÉÈ8¾uÉ×0¿©Õ8¾¸À©¾Á¿À¯ËÒ,¿©ËÉÈÁæÉÈ:¿©Õ8¾K×^ÉÀ¯Ñ
ç)è 
É×CÇ8¾×fÌÚ½¿À¯ÚW½¾Á:ËÁ:Á©ÚJê.ÒË¾È~¿:×^ÉÀëÌÒÕË¾ÍJËÈ8Ø§¿À¯ÌÒ,¿©ÌÎWË½Ë¿Ô%ËÈ%ÎÀÌÍ¾!À©¾ÌÁ©ÉÈËÈ8ØíìÐU¿©Ë½½Ñ<ÌÈîÙ
ïððñ~ò Ï?óuÌÚ8¿©ËÉÚÁuÀ©¾ÌÁÉÈËÈ8Ø<ÕÌÁ?È8É¿¸Î¾¾ÈÓËÈ~Í¾Á©¿©ËØÌ¿¾ÇîÏ
× é[Ò,ÉÈWÁ©ËÁ¿©Á'É×á#â½Ë¿¾À¯Ì½8Ò½ÌÚÁ¾ÁÙ~ÎÀ¯ÌÍ¾?À©¾ÌÁÉÈWËÈ8ØC×^ÉÀÞ¿©Õ8¾?ÊÀ¯¾À©¾ãiÚWËÁ©Ë¿¾,â×^À©¾¾KÈ8ÉÀ¯Ñ<Ì½8Ò½ÌÁ©Á
ç)è 
ËÁK¿À¯ÌÒ,¿©ÌÎW½¾.ìÐU¿©Ë½½ÑëÌÈîÙ ïððñ~ò Ï?óuÌÚ8¿©ËÉÚÁuÀ©¾ÌÁÉÈËÈ8Ø<ÕÌÁ?È8É¿¸Î¾¾È@ËÈ~Í¾Á¿©ËØÌ¿¾ÇîÏ
× éôÒ,ÉÈÁ©ËÁ¿©ÁÞÉ×½Ë¿¾À¯Ì½ÁÙÎWÀ¯ÌÍ¾FÀ©¾ÌÁÉÈËÈØ3×ÉÀB¿©Õ8¾?ÊWÀ©¾À©¾ãUÚËÁ©Ë¿¾,â×^À©¾¾¸ÈÉÀ¯Ñ<Ì½Ò½ÌÁ¯Á«ÌÈÇë¿©Õ8¾
ç)è S
ÜFÉÀ¯ÈõÒ½ÌÁ©ÁBÌÀ©¾¥¿À¯ÌÒ,¿©ÌÎW½¾:ìfö3ÌÚ8¿ÝC÷øÐU¾½Ñ<ÌÈÙ ïððJïù ÐU¿©Ë½½Ñ<ÌÈîÙ ïððñ~ò ÏKóuÌÚ8¿©ËÉÚWÁÀ©¾ÌÁ©ÉÈËÈ8Ø
ËÁ?¿À¯ÌÒ,¿©ÌÎW½¾×^ÉÀF¿©Õ¾;È8ÉÀÑ<Ì½SÚÈWÌÀ©Ô@Ò½ÌÁ©Áìfö3ÌÚ8¿Ý:÷úÐU¾½Ñ<ÌÈîÙ ïððJïò Ï3óuÌÚ8¿©ËÉÚWÁ¸À©¾ÌÁ©ÉÈËÈ8Ø
×^ÉÀ?¿©Õ8¾>ÊÀ©¾À©¾ãUÚËÁ©Ë¿¾,â×À©¾¾CÒ½ÌÁ¯Á¾Á?ÕÌÁ?ÈÉ¿?Îo¾¾È!ËÈiÍ¾Á¿©ËØÌ¿¾ÇîÏ
û ¾<ÊWÀ©¾Á¾Èi¿£Ì@Á¯ËÑ<Ë½ÌÀ¥ÌÈÌ½ÔJÁ©ËÁ¥×^ÉÀC¿©Õ8¾<Á©ÌÑ:¾:Ò½ÌÁ©Á©¾ÁCÉ×ÊÀËÉÀ¯Ë¿©ËÝ¾Ç²Ç8¾×fÌÚ½¿£½ÉØËÒÁCÁ¿©ÌÀ¯¿©ËÈ8Ø
Û¸Ë¿©Õõ¿©Õ¾>ÒÌÁ¾3Û¸Õ¾À©¾CÊÀ¯ËÉÀË¿©Ë¾ÁB¿É¿©Ì½½ÔõÉÀ¯Ç8¾À¸¿©Õ8¾3Ç8¾×fÌÚ½¿©ÁÏ û ¾ÊÀ©¾Á¾Èi¿?×^ÉÀ?¾ÌÒ¯ÕàÒ½ÌÁ©Á?¾Ë¿©Õ8¾À¸Ì
ÊoÉ½ÔJÈ8ÉÑ<ËÌ½¿©ËÑ:¾3Ç¾ÒËÁ©ËÉÈõÊÀ¯ÉUÒ,¾ÇÚÀ©¾ÙJÉÀFÌÈ!ü¥ý'âÕÌÀÇÈ8¾Á©ÁuÉÀ¥Ì:Ò,ÉâüFýÞâÕÌÀ¯ÇÈ8¾Á¯Á?À©¾Á©ÚW½¿Ï
þîÿ0ÿ	
	
¾ ÒÌÚÁ¾*É×3¿©Õ8¾*Ò,ÉÈÁ¿ÀÚÒ,¿©ËÍ¾*ÈÌ¿©Ú8À©¾àÉ×3¿©Õ8¾*Ç8¾0ÈË¿©ËÉÈÁ:É×3ÊÀ¯¾×¾À©À¯¾Çí¾J¿¾ÈÁ©ËÉÈWÁËÈí¿©Õ8¾²ÊÀ¯ËEâ

ÉÀ¯Ë¿©ËÝ¾ÇÇ8¾×fÌÚ½¿;½ÉØËÒÁÎiÔ  À©¾ÛÌ²ÌÈÇÎUÔ  ÌÌÇ8¾À:ÌÈÇ)Ü¸É½½ÚÈÇ8¾ÀÙÄÒ,ÉÈÁ¿À¯ÚÒ,¿©ËÈ8ØÓ¿©Õ8¾õÚÈËãiÚ8¾
ÊÀ©¾×^¾À©À©¾Çà¾ J¿¾ÈÁ©ËÉÈÁ£É×BÇ8¾×fÌÚ½¿¸¿©Õ¾ÉÀ¯Ë¾Á£Û¸Ë¿©Õà¿É¿©Ì½'ÊÀËÉÀ¯Ë¿©Ë¾ÁFËÁ¥¿À¯ÌÒ,¿©ÌÎW½¾Û¸Õ¾È8¾Í¾ÀC¿©Õ8¾:½ÉØâ
ËÒÌ½'Ò,ÉÈÁ©¾ãiÚ8¾ÈWÒ,¾<¿¾Á¿©Á3ËÈ*ÊWÀ©ÉÊoÉÁ©Ë¿©ËÉÈÌ½æ½ÉØËÒ:ÌÀ¯¾:¿À¯ÌÒ,¿©ÌÎW½¾Óìfå?Õ¾ÉÀ©¾
Ñ 8Ï UÏ ò å?ÕWËÁ£ËÁ£Îo¾ÒÌÚÁ¾
¿©Õ8¾À©¾<ËÁ¥Ì½ÛBÌÔUÁ3ÌõÚÈWËãiÚ¾;Ç8¾×fÌÚ½¿¥¿©ÕÌ¿3ËÁ£ÌÊÊ0½Ë¾Ç*È8¾ J¿ÙÌÈÇ*¿©ÕËÁ£Ç8¾×fÌÚ½¿CÒÌÈÈ8É¿CÎo¾Ç8¾×^¾Ì¿¾Ç
ÎUÔÌÈ~Ô)Ç8¾×fÌÚ½¿ÌÊÊW½Ë¾Çª½Ì¿¾ÀÏªÐUÉ²Û¸Ë¿©Õª¿É¿©Ì½uÊÀ¯ËÉÀ¯Ë¿©Ë¾ÁÙæ¿©Õ8¾Á¾õÊÀËÉÀ¯Ë¿©ËÝ¾ÇªÇ8¾×fÌÚ½¿½ÉØËÒÁÌÀ©¾
Ò,ÉÑ:ÊWÚ¿©Ì¿©ËÉÈÌ½½Ô.ÑÚWÒ¯Õ!¾ÌÁ¯Ë¾À?¿©ÕÌ
È ¸¾Ë¿¾À  Á?Ç¾×^ÌÚ½¿?½ÉØËÒÏ
ÊÀ¯ËÉÀ¯Ë¿©Ë¾ÁÙæåÄÌÎ0½¾.áàÁ©ÚÑ<ÑëÌÀ¯ËÝ¾Á¿©Õ8¾.Ò,ÉÑ<ÊW½¾ 8Ë¿Ô§É×  !#" ÌÈ$
Ç  !#%'&Û¸Ë¿©Õ
 ÉÀ<ÚWÈ8À©¾Á¿À¯ËÒ,¿¾Ç
ÍÌÀ¯ËÉÚÁ;ÁÔJÈ~¿©ÌÒ,¿©ËÒ.À©¾Á©¿À¯ËÒ,¿©ËÉÈÁ)
Ï (¥Á  À¯¾
Û XÌ*Ç8ÉU¾Á;È8É¿:Ò,ÉÈÁ©ËÇ8¾ÀÈ8ÉÈJâÈÉÀ¯Ñ<Ì½BÇ8¾×^ÌÚW½¿>¿©Õ8¾ÉÀË¾ÁÙ
Ò,ÉÑ:ÊW½¾ JË¿¤Ô*À©¾Á©Ú½¿©Á3ÉÈÁ¾Ñ<ËÈ8ÉÀ¯Ñ<Ì½'Ò½ÌÁ¯Á¾Á>Ò,ÉÈÒ,¾ÀÈ ¿©Õ8¾ëÒ,ÉÈWÁ¾ãiÚ¾ÈÒ,¾ëÀ©¾½Ì¿©ËÉ*
È  !#%'& ÉÈW½ÔÏ è È
ÒÌÁ¾Á¥Û¸Õ8¾À¯+
¾ ?¾Ë¿¾
À  ÁFÇ¾×^ÌÚ½¿¸½ÉØËÒËÁ?¿À¯ÌÒ,¿©ÌÎ0½¾;ÌÈWÇÓÌÊÀ¯ËÉÀ¯Ë¿©ËÝ¾Ç!Ç8¾×fÌÚ½¿¸½ÉØËÒ>ËÁFÈ8É¿ÙÉÀFÍJËÒ,¾
Í¾À¯Á©ÌJÙW¿©Õ8¾>Ò,ÉÑ:ÊW½¾ JË¿¤Ô.ÒÕÌÀ¯ÌÒ,¿¾À¯ËÝÌ¿©ËÉÈàËÁKÁ¾¿¸ËÈõÎoÉ½Ç8×fÌÒ,¾Ï
åæÌÎW½
¾ ,£ØËÍ¾ÁÞÀ©¾×^¾À©¾ÈÒ,¾Á'¿É>¿©Õ8¾?¿©Õ8¾ÉÀ©¾ÑëÁÌÈÇ:Ò,ÉÀ©É½½ÌÀ¯Ë¾Á'ÛFÕ8¾À©¾u¿©Õ8¾?À©¾Á¯Ú½¿©Á'ÌÀ©¾¸Á©¿©Ì¿¾ÇîÏ û ¾
ÚÁ¾K¿©Õ¾?È8É¿©Ì¿©ËÉ.
È -0/¿É3ËÈÇËÒÌ¿¾u¿©ÕÌ¿Þ¿©Õ¾?ËÈ~¿ÀÌÒ,¿©ÌÎWË½Ë¿¤Ô>É×¿©Õ8¾?Ò½ÌÁ©ÁËÁ'ÇËÀ©¾Ò,¿©½ÔËÑ:Ê0½Ë¾ÇÎiÔ;¿©Õ8¾
ËÈi¿À¯ÌÒ,¿©ÌÎWË½Ë¿Ô.É×'¿©Õ8¾Á¯Ú8ÎîÒ½ÌÁ©1
Á -ËÈ@¿©Õ8¾Á¯ÌÑ:¾Ò,É½ÚWÑ<ÈîÙWÌÈÇÓ¿©Õ8¾ÈÉ¿©Ì¿©ËÉ2
È /3- ¿ÉõËÈÇËÒÌ¿¾C¿©ÕÌ¿
¿©Õ8¾F¿À¯ÌÒ,¿©ÌÎWË½Ë¿Ô:ËÁÞËÑ<ÊW½Ë¾Ç;ÎUÔ:¿©Õ8¾?¿À¯ÌÒ,¿©ÌÎWË½Ë¿Ô:É×o¿©Õ8¾¥Á©Ú8Êo¾À¯Ò½ÌÁ¯4
Á -ÓËÈ:¿©Õ8¾¥Á©ÌÑ:¾¥Ò,É½ÚÑ<ÈîÏ û Õ8¾È
¿©Õ8¾!Ò,ÉÑ:Ê0½¾ JË¿Ô%ËÁ<ÇËÀ¯¾Ò,¿©½ÔªËÑ<ÊW½Ë¾ÇªÎiÔ)¿©Õ8¾!Ò,ÉÑ:Ê0½¾ JË¿Ô)É×£ÌÈíÚÈ8ÊÀ¯ËÉÀ¯Ë¿©ËÝ¾ÇªÒ½ÌÁ©Á:É×CÇ8¾×fÌÚ½¿
¿©Õ8¾ÉÀ¯Ë¾Á?ËÈiÍ¾Á¿©ËØÌ¿¾Ç!ÎUÔõö3ÌÚ8¿Ý>ÌÈÇ²ÐU¾½Ñ<ÌÈ ì ïððJïò Û«¾ËÈÇËÒÌ¿¾£¿©ÕËÁuÎiÔ@ö>÷>ÐoÏ


57698:<;>=>=>?@BADC E	FHGJIKAL;>:<;>MBANMBOQPLR<GSR<GUTWVX;>EY;Z:<GJ[\O]R<G^G_VXAX@`RYa
@BAXF
PLR<GJR<G^TVL;>EY;>:<GS[ObR<G^G_MBRcFHGJR<GUFdVXAX@`RYafe^=@BEYEYG^Eg;>AXe^=>VKFHG^E	M7AX=Za
FLGSOh@BVL=Z:R<VL=GJEM`Oi:<jXGkOlM`R<?1E	m npoqBnpor@BAXF
m s'trnpoq<su6wvxG7y7jXMUz'GJ{GJRUyWe^MBAXEY;FLGSR'@`=EYM|FHGJOh@`VX=Z:9R<VL=GJEM`Oi:<jXGkOlM`R<?}m s~q<s
;>A+M`RcFLGJRr:<MfjK@U{G@fe^=>M7EYGSReJMBRYR<G^EYPiMBAKFLGJAXe^Gz;Z:<j:<jXG_@`VL:<@BAKF

8HG^=>?@`A+FHGJIKAL;Z:<;MBA

M`O'VXAX@`RYa#e^=@`EYEYG^E^6'jX;>E

ecjK@BAL7G_FHMWG^EALMB:	E<@BeJR<;ZIXe^GBG^AXGSRc@B=>;Z:aWy~@`E	:<jLG_FLGJOl@BVX=Z:m siqcsdz'M`R<Eg=>;>G1m stdnpo7qcsNzjXGJAXG^{GSRgoFLMWG^E	AXM`:MWe^eJVLR
G^=>EYGJzjLGJR<G_;A:<jXGrFHGJOh@`VX=Z:	:<jXG^M`RYaW6

LL

|DLilxw\wlp\H~)
D w¡Q £¢g9¤¥\¦p§

¨W©\ªi« «¬i­4®Q¯W­ªi°Q©\±1± ²w¯W¬i³`´h¯«

¨¬~µ.¶¥©h¯·w´h±c¸º¹²w¯»¼¨W©ªi°Q«U¯«´\»¾½¿ªK³ ¯
À

ÁLÂc©\´\±U¯W³`ªi©

Ã7Âc©\´h±U¯W³Bªi©

®Q´\«ÄU°Q»¥¨± ´h¬~»pÂ<­³ ¯W¯

Å ÆÇYÈ|ÉÇÊËÌ^Í

Å`ÆÇYÈ|ÉkÇÊDËHÌJÍ

Å ÆHÇÈÉkÇÊDËÌ^Í

Á

°Q»QªK³`¸

Å ÆÇYÈ|ÉÇÊËÌ^Í

Å`ÆÇYÈ|ÉkÇÊDËHÌJÍ

Å ÆHÇÈÉkÇÊDËÌ^Í

Î

®Q´\«ÄU°Q»¥¨± ´h¬~»pÂ<­³ ¯W¯d¬i³`®w¯W³ ¯®

Å ÆÇYÈ|ÉÇÊËÌ^Í

Å`ÆÇYÈ|ÉkÇÊDËHÌJÍ

Å ÆHÇÈÉkÇÊDËÌ^Í

¬i³`®w¯W³`¯®°Q»QªK³ ¸

Å ÆÇYÈ|ÉÇÊËÌ^Í

Å`ÆÇYÈ|ÉkÇÊDËHÌJÍ

Å ÆHÇÈÉkÇÊDËÌ^Í

Ð

®Q´\«ÄU°Q»¥¨± ´h¬~»pÂ<­³ ¯W¯N»w¬i³`µÑªi©

Å ÆÇYÈ|ÉÇÊËÌ^Í

Å`ÆÇYÈ|ÉkÇÊDËHÌJÍ

Å ÆHÇÈÉkÇÊDËÌ^Í

Ò

À

Å ÆÇYÈ|ÉÇÊËÌ^Í

Å`ÆÇYÈ|ÉkÇÊDËHÌJÍ

Å ÆHÇÈÉkÇÊDËÌ^Í

Ã

Ï

Ó

¬i³`»

¬i³`»

»w¬i³`µÔªi©°Q»QªK³ ¸

Å ÆÇYÈ|ÉÇÊËÌ^Í

Å`ÆÇYÈ|ÉkÇÊDËHÌJÍ

ÕHÖD×JØ.Ù×^ÚÛ~ÜÝ

Þ

¶Q³ ¯W³`¯ß°Q´« ´h±U¯Â<­³ ¯W¯

Å ÆÇYÈ|ÉÇÊËÌ^Í

Å`ÆÇYÈ|ÉkÇÊDËHÌJÍ

Å ÆHÇÈÉkÇÊDËÌ^Í

à

¶Q³ ¯W³`¯ß°Q´« ´h±U¯Â<­³ ¯W¯d¬i³`®w¯W³ ¯®

Å ÆÇYÈ|ÉÇÊËÌ^Í

Å`ÆÇYÈ|ÉkÇÊDËHÌJÍ

Å ÆHÇÈÉkÇÊDËÌ^Í

ÃWá

¶Q³ ¯W³`¯ß°Q´« ´h±U¯Â<­³ ¯W¯N°Q»QªK³ ¸

Å ÆÇYÈ|ÉÇÊËÌ^Í

Å`ÆÇYÈ|ÉkÇÊDËHÌJÍ

Å ÆHÇÈÉkÇÊDËÌ^Í

ÃiÃ

¶Q³ ¯W³`¯ß°Q´« ´h±U¯Â<­³ ¯W¯d¬i³`®w¯W³ ¯®°¥»QªK³ ¸

Å ÆÇYÈ|ÉÇÊËÌ^Í

Å`ÆÇYÈ|ÉkÇÊDËHÌJÍ

Å ÆHÇÈÉkÇÊDËÌ^Í

ÃÁ

¶Q³ ¯W³`¯ß°Q´« ´h±U¯Â<­³ ¯W¯N»w¬i³`µÑªi©

Å ÆÇYÈ|ÉÇÊËÌ^Í

Å`ÆÇYÈ|ÉkÇÊDËHÌJÍ

Å ÆHÇÈÉkÇÊDËÌ^Í

Ã Î

¶Q³ ¯W³`¯ß°Q´« ´h±U¯Â<­³ ¯W¯N»w¬i³`µÑªi©°¥»QªK³ ¸

Å ÆÇYÈ|ÉÇÊËÌ^Í

Å`ÆÇYÈ|ÉkÇÊDËHÌJÍ

É	â4ã<äÔå

Ã Ï

¶Q³ ¯W³`¯ß°Q´« ´h±U¯Â<­³ ¯W¯d¶9¬~«`´h± ´hæi¯#»w¬i³`µÔªi©k°Q»QªK³ ¸

Å ÆÇYÈ|ÉÇÊËÌ^Í

Å`ÆÇYÈ|ÉkÇÊDËHÌJÍ

É	â4ã<äÔå

ç

ªKè¥©h¯Áuéê¬~µ.¶¥©h¯·w´h±S¸ë¬i­± ²w¯¨¬~»Q« ¯ß°w¯»¥¨¯#³ ¯©\ªK± ´h¬~»¥«ì íNîïªi»Q®ðì íñ9ò

³ ¯W­ó¯W³`¯»Q¨¯

¨W©\ªi« «¬i­4®Q¯W­ªi°Q©\±1± ²w¯W¬i³`´h¯«

À
Ã

¬i³`»

ÁLÂc©\´h±U¯W³Bªi©

Ã7Âc©\´h±U¯W³`ªi©

®Q´\«ÄU°Q»¥¨± ´h¬~»pÂ<­³ ¯W¯

ôõö

ôõö

ôõö

Á

°Q»QªK³`¸

ôõö

ôõö

ôõö

Î

®Q´\«ÄU°Q»¥¨± ´h¬~»pÂ<­³ ¯W¯d¬i³`®w¯W³ ¯®

ôõö

ôõö

ôõö

Ï

¬i³`®w¯W³`¯®°Q»QªK³ ¸

ôõö

ôõö

ôõö

Ð

®Q´\«ÄU°Q»¥¨± ´h¬~»pÂ<­³ ¯W¯N»w¬i³`µÑªi©

ôõö

ôõö

ôõö

Ò

À

ôõö

ôõö

ôõö

»w¬i³`µÔªi©°Q»QªK³ ¸

Ã ÏÑ÷

Ã ÏÑ÷
ç

¶Q³ ¯W³`¯ß°Q´« ´h±U¯Â<­³ ¯W¯

Ã ÏÑ÷

Ã ÏÑ÷

ÃÁ

÷

¶Q³ ¯W³`¯ß°Q´« ´h±U¯Â<­³ ¯W¯d¬i³`®w¯W³ ¯®

Ã ÏÑ÷

Ã ÏÑ÷

ÃÁ

÷

ÃWá

¶Q³ ¯W³`¯ß°Q´« ´h±U¯Â<­³ ¯W¯N°Q»QªK³ ¸

Ã ÏÑ÷

Ã ÏÑ÷

ÃiÃ

÷

ÃiÃ

¶Q³ ¯W³`¯ß°Q´« ´h±U¯Â<­³ ¯W¯d¬i³`®w¯W³ ¯®°¥»QªK³ ¸

Ã ÏÑ÷

Ã ÏÑ÷
ç

Ïwø Ã Ï

ÃÁ

¶Q³ ¯W³`¯ß°Q´« ´h±U¯Â<­³ ¯W¯N»w¬i³`µÑªi©

Ã Ï÷

Ã ÏÑ÷
ç

Ïwø Ã Î

Ã Î

¶Q³ ¯W³`¯ß°Q´« ´h±U¯Â<­³ ¯W¯N»w¬i³`µÑªi©°¥»QªK³ ¸

Ã ÏÑ÷
ç

Ó
Þ
à

Ã Ï

¬i³`»

Ã Ï÷
ç

¶Q³ ¯W³`¯ß°Q´« ´h±U¯Â<­³ ¯W¯d¶9¬~«`´h± ´hæi¯#»w¬i³`µÔªi©k°Q»QªK³ ¸

ç

ªKè¥©\¯

Ïwø ÃÁ
ç

Ïwø ÃÁ

Ïwø Ã Ð

Ïwø ÃiÃ
÷

Ã Î

Î é|ù¯W­¯W³ ¯»Q¨¯«±U¬Ñ± ²w¯W¬i³ ¯µÑ«¬~»¼± ²w¯¨¬~µÑ¶¥©h¯·w´h±c¸º¬i­1ì í#îïªi»Q®ðì í#ñ'ò

½ú²w¯»º©h¬¬iûp´\»wü+ªK±

ç

ªKè¥©h¯dÁ#´h±´\«« ©\´hü~²± ©h¸x« °w³ ¶Q³B´\« ´\»wüd± ²QªK±± ²w¯f­ªHæi¬i³`ªKè¥©h¯N¨¬~µ.¶¥°Q± ªK± ´h¬~»Qªi©¶Q³ ¬i¶wÂ

¯W³ ± ´h¯«´\»Ñ± ²Q¯±U¬i± ªi©\©h¸x¬i³`®Q¯W³ ¯®Ô¨Wªi«U¯dªK³ ¯
´\»Ñ»w¬+¹ªH¸Ñ³ ¯ý¥¯¨±U¯®º´\».± ²w¯
¨¬~µ.¶¥©h¯·w´h±S¸
ªK³ è¥´\±U³`ªK³ ¸¶¥³`´h¬i³`´h± ´\¯« ø

¬i­k³`¯ªi«U¬~»Q´\»wü¹´h± ²

½ú´h± ².ªK³ è¥´h±U³BªK³ ¸¶Q³B´h¬i³`´h± ´h¯«þL­¬i³|ªi©\µ.¬~« ±_ªi©\©p¨W©\ªi« «U¯«r¬i­'®w¯W­ªi°Q©h±4± ²w¯W¬i³`´\¯«r´\»x± ²w¯

ô#ªi°w±UÿÂJöp¯©\µÑªi»pÂJöu± ´©\©\µÑªi»¼²Q´\¯W³`ªK³`¨`²¸¾± ²w¯+¨¬~µÑ¶¥©h¯·w´h±c¸´\«± ²w¯« ªiµÑ¯

ªi«f± ²w¯+¨¬~µÑ¶¥©h¯·w´h±c¸¾¬i­_ù¯´\±U¯W³>«

®w¯W­ªi°Q©h±©h¬iü~´¨Nªi»Q®¾± ²w¯©h¯·w´\¨¬iüi³`ªK¶²Q´\¨
¶Q³`´h¬i³B´h± ´hÿW¯®¾®w¯W­ªi°Q©h±©h¬iü~´\¨d± ²¥ªK±´\«1®Q´\«`¨W°Q« «U¯®¼´\»



öp¯¨± ´h¬~»

Ð ø


			

 "!# $&%'#(*))$)
+-,.0/21343
156478:9;,.<1>=;.?A@;,15@9;,CBD9E56
9;,F9;,.G=;.@H9H=I6JK9;6
17L9H1NMC=I6
1>=I6
9;64.@'9;,CBD9E9H1>9;B>343
OP1>=IQ.<=R9;,.
Q.</SB>T3
9;@<UWVX1>9;,Y9;,.[Z\B>B>Q.<=B>7CQ:]1343T7Q.<=\B>7QY9;,.[Z^=;.<5-_DB0Q.K`7C6
9;6
17a1>/*M=I.</b.<=;=I.Qa.KcW9H.7@;6417@
OW6
.34Q:B>7:.KdaJ<64.7 9Q.J<64@;6
17YM=I1eJK.QT=;.f/b1>=-9;,.[=;.@HMX.JK9;6
g>.M=h6
1>=I6
9;6
i<.QYQ.</SB>T3
9-341>864JDj
kml"neoCpqnertsu4vxw"y<z|{S}~hx0Iy0C2zy0(yS<DWz|z2WyIDND0AYzSSz^zzDD(yK0DN}FY"y
W<Cy4 ;ySyK;y;¡X¢£y;¤ zyKSDP¥ * Hy<y<h;y;¡¢£yI¤zyKhDy;¤>bz¦[-{S}~h-ID:Iy'ID§' zy;
2N D¨D>§mD|zS2§GyY D2©z2yª§yK§Iy<Ih « ¬zyKz22®­¯°S±-²³Gb´z2Wyµ ySC2zSD¶E±·DHyfKDY
 WDDD§¸DzSb§y[hCy<z\Ez2Wy- h qhSzSS>D
;¹>
º H<»R¼'736
_>.R9;,.GQ.K`76
9;6417N1>/©M=;.</2.<=;=;.QC½¬.KcW9H.7@;6
17@U9;,.0Q.K`76
9;6417N1>/^M=;.</2.<=;=;.Q¡X¢¶.KcW9H.7W¾
;@ 6
17C@Q1(.@71>9[QC6
=;.JK9;3
OµOW6
.34QFBYMX13
OW71?G64B>3*9;64?0.0Q.J<6@;6
17PM=;1WJK.QT=;.m/21>=9H1>9;B>3M=I641>=I6
9;6
.@B>7Q
9H=IB>JK9;BDVC34.¸J<3B>@;@;64J<B>3*=;.B>@H17678j+-,64@64@'V.J<B>TC@H.¸9;,.R9H.@;99;,CBD99;,.¿;T@H9;6
`J<BD9;6
17@1>/©Q.</SB>T3
9;@'9H1
VX.|BDMMC346
.QmQ1[71>9VX.3
178'9H19;,.|.KcW9H.7@;6417¸V.678JK17@H9H=ITJK9H.Q0J<B>7C71>9VX.\M.<=I/b1>=I?G.QRVX.</21>=;.\9;,.
.KcW9H.7@;6
17G6@/2TC343
OE_W7157j]15©.<g>.<=UW64/B[@;6?0MC3
.\9H.@H9©/b1>=¿HT@;9;6À`J<BD9;6
17@Á1>/Q.</SB>T3
9;@Â64@B>QQ.QU(9;,.
B>3
8>1>=I649;,?Ã9;,BD9[5^1>=;_W@[5649;,LM=;.</2.<=;=;.QC½Ä.KcW9H.7@;6417@5^1>=;_e@RB>34@H1µ5'6
9;,FM=;.</2.<=;=;.Q¡X¢Ä.KcW9H.7@;6417@<j
Å 1?0MT9H.[@H.<9;@±E² Æ B>@|/b133
15@j
Æ
± ÇÉ
È


Æ Õ
Æ ÕÖ
}N~;± ²Â
~;± ²|
64@|B>JK9;64g>.R647:± ² Æ Ù
È
È®× ~-71aØ
Î
Ô
Î
Ð Ñ>Ó
Ò
ÏbÐÒÑÓ
Ð =@H1?0.ßàâ
Ó á;U ±EÆ
Ú /±[² Æ Õ
2
/
>
1

=
H
@

1
0
?
.
Þ
}
I
@

T
I
J
¸
,
;
9

,
D
B
Á
9
2
/
>
1
;~ ±[ã Æ Õ Ö È®×
B>7Q¸71[Ø
Î
Õ
Î
ÈÛ×
ã È
Ô
64@'B>JK9;6
g>.0647N±Eã Æ U9;,.7N9;,.RB>3
8>1>=I649;,?ä=I.<9;T=I7@ÂKD¨<y<j Ú /±[² Æ È ±E²4Æ Ê*Ë /21>
= @H1?G.Eá|å®æWU9;,.7N=I.<9;T=I7
ÑÜÓ¯°SÝ ± Æ ³^B>7QµQ.K`7.[± Æ
Ð
Ó
Ð©Ñ«Ó¯Ý
­¯°S± ² Æ ³ È®Ó ç ã<èé ÇêÜëÜëÜë ê ²ì Ð©
­¯
ã
ãÈ ± ² Æ /21>='B>343ßíâá;j
± ²
Æ Ê*Ë

Æ Ì&ÍCÎYÏ
± ²C

È

Ï
Ï

î .<9Á±®V.^Bf[¾M=I.</b.<=;=I.Q ¡X¢ .KcW9H.7@;6
17¸1>/¯{S}N~hxhj].7CJK.\±
È®ç ²2ï Ç ­¯°S±-²³hU>5,.<=I.^±²ð~Há©å¶æ
BD=;.m9;,.R@;.<9;@67µñ.K`76
9;6
17NòjôóejõL.0@;,15öVeOµ647QCTJK9;6
17:9;,BD9f± Èxç ²bï Ç ±E² Æ B>7QN9;,BD9'9;,.EgDB>34T.
<DôyÁ64@Á71>9Á=;.<9;T=h7.QjÁ÷hDzSD(I >z2Wy ± ² Æ È ±²øjÂùq<yhq<yÂá È æ Ú ?G?0.Q64BD9H.>j÷hDzSbú>y
ID<y[á-åÞû õL.¸`C=h@H9'@;,15x9;,BD9±-²^üÛ±[² Æ jý@;@;T?0.m9;,BD9/b1>=
}NU±²bþË Õ È
U± Õ Ö ÈÞ×
Î
Ô Ñ
B>7QF71µØ
± ² jEZ^ON9;,.0647QCTJK9;6
17N
,(OeM1>9;,.@;64@±[²2Æ þË Õ È
Î 64@'B>JK9;64g>.G647F± ²2þË jE].7CJK. Ñ Î
Ô
Ð©B>Ñ«Ó¯
B>7Qÿ71Ø Ñ
± ² Æ 649=;.?G
647Ý @[9H1N@;,15Þ9;,BD9m± Ð ²2Æ þË Õ Ö È × Ó j
Î 64@[B>JK9;6
g>.ª647ÿ± ²bÆ þË jª+"1P@;,15 Î
Ô
Ó¯Ý ü ± B>7QL± Õ Ö
Ð
Z^.J<B>T@H.ª±-²2Ð©
þÑ«Ëm
È × U"±-²2þË Õ Ö È × jZ^OF9;,.G647QTCJK9;6
17F, OeMX1>9;,.@;64@±E²bÆ þË È ±-²2þËj
]'.7JK.a± ²bÆ þË Ð©ÑÜÕ Ö È Ó¯Ý × j+-,.<=;.</21>=;. Î
± ² Æ B>7Qÿ±²ü ± ² Æ j
=;1e1>/^1>/\± ² Æ ü ±²\M=;1WJK.<.Q@E@;6?G6434BD=I34Ó O>j
Ô
ý@;@;T?0.E9;,BD9'/21>=
}U±E²2Æ Ó þË Õ È
UX±[²2Æ þË Ó Õ Ö È×
B>7Q71ªØ
Î
Î 6@B>JK9;6
g>.¸647N±E²2Æ þË j'Z©O
Ô
Ó 1>9;,.@;6@±-²2þË Õ
9;,.¸647QTCJK9;6
17µ,(O(MX
>
B

7
P
Q

7
Y
1

Ø

4
6
'
@
>
B
K
J
;
9


6
>
g
0
.
4
6

7

±
2
²
þËKj Ú 9=;.?GB>67@9H1Y@;,15
Î
È
Ó Î 64@E9;,.ª[¾ÐÂ
ÓÁ@HÝ 9¸Q.</SB>T3
9RB>7CQ&± Õ
9;,BD9¸± Õ Ö È × j eÐÂ
1PÑÜÓ¯
B>@;Ý @;T?0.ª± Õ Èä× jÐ Z^.J<B>T@H.
3
.Ñ«B>
È × U
Ð
©
Ð
Ü
Ñ
¯
Ó
Ý
± ² È ± ²2þË U¯B>7QF/ST=;9;,.<=[± ã È ± ²bþË /21>=EB>343ßFåxá;jG+,.<=;.</21>=;.G± È ­¯°S± ²2þË ³hjG+-,6@34.B>Q@f9H1
Ó .
BµJK17(9H=IB>Q64JK9;64Ó 17L56
9;,F9;,.GB>@I@;T?0M9;641Ó 7L± Õ È ×
B>Ð©7Ñ«Ó¯
QLÝ 9;,.G/2B>JK9R±-²2þË Õ Ö È ×
1>V9;B>647.QL5'6
9;,F9;,
647QCTJK9;6
17F, OeMX1>9;,.@;64@jG+-,.<=;.</21>=;.09;,.B>@I@;T?0M9;6417L64@/SB>34@H.>U"B>7Q ± Õ Ö È × j+,.<=;.</21>=;. Î
±-²
Ô
B>7QÒ± ² Æ ü ±²ðjF+-,BD9m9;,.YB>3
8>1>=I6
9;,C? Q1e.@m71>9RÓ =I.<9;T=I7KD¨<yR8>1e.@0@;64?6434BD=I3
Ó O>jµý@;@;TC?0.a9;,CBD9R/21>=
@H1?0.
}U"±[² Æ Õ È ×
B>7CQF/b1>=E@;1?0.EßPàöáIU*±[ã Æ Õ È
B>7CQÿ71µØ Ó
Î
Î 64@B>JK9;6
g>.647F±Eã Æ j
Ô
õL.R,CBg>.E9H1a@;,15ö9;,BD9±Eã Æ Õ Ö È®× j©+-,C64@|64@-64?GMC346
.QaV(OY9;,.E/2B>JK9± Õ Ö È®×
@;,157µBDVX1g>.RVX.J<B>T@H.
Ð©Ñ«j Ó¯Ý
Ó
Ð
Ð©ÑÜÓ¯Ý
± ã Æ ü¶±G
ý@;@;T?G.©9;,BD9¯9;,.\B>3
8>1>=I6
9;,C?ÛÓ OW6
.34Q@*± ÈÛç ²2ï Ç ­¯°S±E² Æ ³hj*õL.|J<34B>64?ö9;,Ó BD9± 64@¯B f¾MC=;.</b.<=I=;.Q¡X¢
.KcW9H.7@;6
17 1>/¸{S}N~hxhj Z^.J<B>T@H.:9;,.YB>348>1>=I6
9;,? Q64QÒ71>9¸=;.<9;T=h7<D¨<y¸B>7CQ´± È ç ²2ï Ç ­¯°S± ² Æ ³hU







	


 !"!#"$%'&)(*,+!-.,0/1324"5#6
7 8:9<;>= ?A@B8C=ED.F	GIH"D!FJLKNM,OAMQPSR
TVUWP XYZK\[B]*=^_8C=`[a@B8C^ZbVced!Ff
TVU Khg0P [B]*=^i8C=:[a@>8C^kjmlnpoVFf
TVUrqsKutvK g0w Ox[B]*=^i8C=:[a@>8C^kjmln"o,Ff
TVUrq Kut K g0w Ox[B]*=^i8C=:[a@>8C^kbVced!Ff
TVUrqsKutvKzy{q K|t K<[B]*=^_8C=:[a@>8C^ZbVced!Ff
8C=:[a@>8C^Zjmln"o,F
= ^a?
}hH~'d!ceFqSD!F	GIH"o,H'4c,GF	D4d!c,Fjzc.ceHceH"b,HIF	D.c,FIc,F	d.H"o,H"bVFujzc,FIF\!cQlnBd..lc,b,!FIceH"F	o
xXwYjzcln"nqht%kgOo,d4GeEb,.lbjzc{oV'{F{! :¢ ¡ XY£ M,<¢ ¡ XwYl.DW!)¤¥q¦ht%§H"o
lGb,H¨F:Hp©<¢¡ ª « bCH"o¬oVbVcQlH~'bVjmc,­®lceD©bVo,.%­kb,.lba<¯¡ Y ¯ jmcCln"n±°²r³#!­a!FIc,F< ¯ lc,F\b,!F`oVFIb,o
H"©´*Fµ.H"b,H'¶ ªs·ª ¸ .FIc,FIjzceF<¹H"o¬lº¥\u.c,FIjmFIc,c,F	D3»3¼WF½bVF	.oeH'©jC¾LOAMQPS¿ ª
À
4H"oÁb,!FIc,F	ÂH"4D.H"GIlbVF	o b,4lb ­H"b,l:ceF	oVbVceH"Gb,H'ºbV`bVb,ln3.cQHceHb,HF	oÁ¥ÃbVF	oVb,H"!~`b,!Fa{F	`Ä±FIcV
o,.H"A¸ j ln"HbVFIceln1H"Aln"n¥\u4c,FIjzFIcec,F	D»±¼ÅF½#bVF	.o,H"'.oj D.FIjmld.n"bb,!FIceH"F	oaH")ln"nÆb,!FGInplo,oVF	oaj b,!F
Ç<ld!bV`l.DAÈF	n"lAl.DAÈb,H"n"npl.HFIcelceGQH"o¬H"AÉ ª
Ê`ËÌË3ÍmÍmÎ.ÌÏÑÐ>Ò"Ó [ÔÕ×ÖLØmÙÚA¾LO0MQPS¿aXY:»3¼
ØpÕmáQâ#Ùã%ÖLØ Ù.ä ÔeÔ Ô â#æçÖ¬Ömè#Ô Ø|ÔÕ{¾LO0MQPS¿eéêhè#Ô Ô
P ØpÕ å Õ	ÔIÖ ÞëÝ ] Þß ÙEãIæ å âÕIÔÕ Þß{ì äíæçØLÛ ÖîÔ ßVå ÜAæÝIãIÞæ å ßâÕIà ÔÕeéÁyïØzÕ Þ å Ý×Õ×ß Ö ß ØLã%àÖCÖ ÝIÞ å Ö å æ ÞßVà Ô ÞßÃß Þ Ù0OAé å Ù àÃÜ ØpÕ ß å
æçØmÖîÔ ßëå æðé®ã å ÙòñeÔ à'Þ Ù3Ô`ØzÙÃó Þ æðôÙ Þõ Ø å æhÖLØ õ Ô	ö
Ê`ËÌË3ÍmÍmÎ.ÌÏÑÐ>Ò|÷ø [3Ô×ÕÖLØzÙÚ{¾LO0MQPS¿CXY\Ûú
ù
ØzÕzá×âÙ3ã	ÖLØ Ù.ä ÔeÔaÙ
æ Ô â#æÖÖmè!Ô Ø|ÔÕ*¾LO0MQP_¿eé
êhè#Ô ß Ô\P ØzÕ å Õ	ÔIÖ ÞVÝ ] Þß ÙûãIæ å âÕIÔ×Õ Þß\ì Ü{äíæçÝØLÖîÞÔ ßßVå à æ1ãIæ å âÕIÔÕeÞ éÆyüÝQß ØpÕ å ÞÕ×ßQÖ õß ØLã%å ÖÖà Þ ÖÝIå å æ ÞßVà Ô ßÞÞ ß ÙOAé å Ù àÜ
ØzÕ å æçØLÖîÔ ßVå æsé®ã å ÙúñQÔ àÞ Ù3ÔØmÙó Þ æðôÙ Þõ Ø å æÁÖLØ õ Ô%ö
7 ßVÞ	ÞëÝIýÃþ ceFI­CÿvlA~'H¨F	olAD!Fµ3.Hb,H'jC4c,FIjzFIcec,F	DûF½#bVF	.o,H'.o`jmc`!ceºlnD!FIjLld.nb<b,.FIceHF	o`'.n ª
þ.c,FIjm>FFIc,	c,F	DFl<½#¶ bVªF	 .b,o,!H"'FC.4o¬c,­FIjz!FIF	ce.c,F	FID{¨FIFcC½#bVb,F	!.F<o,.H'cQ.HoceH"Hb,HF	b,o®.H"lo c,GIF<llºo,FaoVbVGce'H"H"G.b¬GIbVHpD!F¬b,l­nÆHb,ce{D!b,FI.c F þ llD!FIc l.D'n"npd..D!FIc
ª
À
}!cad.!c,F	oVbVcQH"GbVF	D.ceHceH"b,HF	ob,.F<GIn"lo,o®jÆ4c,FIc,F	d.H"o,HbVFujmc,FIF!celnBd4.lc,ºD!FIjLld.nb®b,!FIcQHF	o¬H"o
bVcelGb,lÄ4n"F ª¸ !F\c,F	ºlH".H"!~{GIn"loeoVF	oCH"b,!F`.HFIcelceGQlc,F:HpbVcelGb,lÄnF ª

	 Ë4Ì 	 Ð>Ò|÷4÷ U Þß æðØLÖîÔ ßVå æðÕ¬K å Ù à ó ß Ô ß Ô 	â#ØpÕ×ØmÖîÔIä Ý×ß ÔQÔ:Ù Þß×õ{å æ>â#Ù åß ôÖmè#Ô Þß ØuÔ×Õ:¾LOAMQPS¿*êhè!Ô ß Ô*P
ØzÕ å ÕIÔIÖ ÞëÝ æðØLÖîÔ ßVå æðÕeé ÖîÔÕ×ÖLØmÙÚÃ¾LO0MQPS¿CXY<Û»±¼ K å Ù à ¾LO0MQPS¿¬XY\Ûù KCã å ÙñeÔ à'Þ Ù±Ô<ØmÙ{ó Þ æðôÙ Þõ Ø å æÖLØ õ Ô	ö
7
!Fln"~ceHb,. H")}hH~'d!c,FbVF	oVb,o¾LO0MQP_¿`XY\ù Kl.DÅ¾LOAMQPS¿<XY:»3¼ K !FGc,c,F	Gb,!F	oeo
j¬ßVÞ	b,Þë!ÝIFý l¸ n~ceHb,4ïjmc©XY Û»±¼ H"o:lojm'n"n­o ª }!cAXY Ûù Ûb,!Fº4c,jCHpo:o,H"ºH"n"lÛ c ª  ª:F¸ l.lnIFÃb,!F0Ø Ý 
oVb,lbVF	{F	b,o<H"oVF	d!F	.GF ª:« )F	lGeòGIloVF{­ F{l%)d4oVF`b,.F.FI~'lb,H'.ojb,.Floeo,d.{.b,H"'.oj b,!F
.c,FI¨#H'd.o¬GIlo,F	o ª
 ª ao,oed.{Fb,.lbP XY¹K ª  ­¹K¬H"o\H"ûlnpnÁyu.c,FIjmFIc,c,F	D»±¼F½#bVF	.o,H"'.o<üj ïÄ3F	GIld4oVF{Ä
D!Fµ4Hb,H')P k aF	.GF{Hb*HpoGc,c,F	Gb\bVc,FIb,d!cQúÖ â4Ô *o,o,d4{F`b,4lb K gEP F	GIld.oVFÃP
H"oaG'.o,H"oVbVF	bJLlo<P ª XwYiKuRQ±ln"nBF½#bVF	.o,H'.o*lc,FG'.o,H"oVßbVF	bIª\±·lª .DA!ÃF½bVF	4o,H')G'b,lª H"4þ oaK ª aF	.GF
Hb<H"o\Gcec,F	Gb<bV c,FIb,d.ce Ýå æsÕ	Ô ª ª *o,o,d.F{b,.lbqKutvK<gÅ
w O F	GIld4oVFºK<gr
w P l.Dûln"nhF½#bVF	.o,H"'.o
lc,FG'.o,H"oVbVF	bI.F½bVF	4o,H'AG'b,lH".oaK ª aF	.GF`H"bH"oCGc,ceª F	þGbabVÃc,FIb,d!ce ÝIå æðÕIÔ ª ¶ ª *o,o,d.F\b,.lb
q Kut K®gAw O ª þ F	GIld.o,F Kg)w P !<F½#bVF	.o,H"'ºG'b,lH".o KNl.D!F	.GF:qsKutvKBH"o l.4npHF	D{H"{ln"n!F½#bVF	.o,H"'.oI


!"#%$&
')(%*,+.-0/-0(1')20243658793:(%/-;&(%/:<>=?3:(%@63A-7-0/@6;)BB3:@6779;CB3D7E!BF(HGJILK%MD<1N<1O.//E%P37Q%'R7TSU+WVX+ZYS +WV +[<
O.//E%P3\7Q]'R7^7Q!3DB3?-0/_'a`%BF3Dbc3DBBF3:*#dfeg365793:(]/-;&(ihj/E%@kQi7Q%'R7 +mlnh<po;q +mlnhrtsXhrcuwvxbc;)B4/9;&P3
y <p=?3:(%@63\+xl{
z h|rZuwvm')(%*}SU+WVX+]-~/m(%;)7m')@67-)3\-0(h|rZuwv:<=3:(]@63|p+l{h|rZuwvD)qQ%-0@kQQ!;qx3D)3DB_@6;&(79BF')*%-~@67/
7Q!3bZ')@67.7Q%'R7 +|l
z h|rZuwv:<|=3:(]@63 +_-~(n(!;iYW`]B3Dbc3DBFB3:*#dfe,3658793:(%/-0;&(n;)b^f')(%*g de +<|=?3:(%@63
-7.-0/@6;)BBF3:@67?79;}B3D7E!BF(GJILK%MD<?<[(A7Q%3B3:Pi')-~(%-0(!@D')/3(!;)7SU+WVX+ZYS +WV +<?bS +WV +ZYS+WVX+#7Q%3:(nA')(
'RB&E%Pi3:(7./-0Pi-02~'RB|79;7Q%3`%B3D8-;&E%/@D')/93')202wYW`%B3DbZ3DBB3:* de 3658793:(%/-;&(%/|}A')//E]P`%7-;&(n7Q!3DB3
-0/a'R723:')/97a;&(!3@6;&(7')-0( +m')(%*Q!3:(]@63i-7-0/@6;)BBF3:@6779;AB3D7E!Bk(T6) :M6<ib4(%3:-7Q!3DBS +WV +ZYS+WVX+(!;)B
SU+WVX+ZYS +WV +[#7Q!3:({n/98PiP3D79BT7Q!3DBF3-0/.')(n3658793:(%/-0;&(g(%;)7?@6;&(7')-0(%-0(!}+f')(]*nQ!3:(%@63-7.-0/?@6;)BFB3:@67
79;iB3D7E%BF(6) :M6<
¡ Q%3DB3Dbc;)BF37Q!3')2);)BF-7Q]P¢B3D7E%BF(%/?79BFE!3-0b_')(%*n;&(]2A-b_+_-0/.-0({')202
YW`]B3Dbc3DBFB3:* dfe 3658793:(%/-0;&(%/
;)b_< ¡ Q!3')20);)BF-7Q%P£;)-0;&E%/2BFE%(%/\-0(`f;&28(!;&Pi-~')2#7-~P3)<
¤
w¥ ¦~§#¦¨ª©«
¬­w®°¯¬®±]²³´?²®µ¶µ:³#µ
[(79BF')@67'R#-020-7A;)b^')202B3:Pi')-0(]-0(!@D20')/F/93:/.3658@63D`%77Q!3(!;)BFP')2E%(]'RBA@D20')//-0/.*%-B3:@6720A-0P`]20-03:*T
7Q!3-0(79BF')@67'R]-020-07·;)b%7Q!34/')P3@D20')//93:/m-0(¸|3:-793DB:¹U/m*!3DbJ')E%27m2;)&-0@R)')//FQ!;¶q(º')E!79»')(%*¼83:20Pi')(
½[¾:¿)¿8¾¶À ')(%* ¡ Q!3D;)BF3:Pi/\Á!< ¾:Â ]Á!< ¾:Ã ')(%*Á!< ¾ Á!<
¼7-~2020Pi')( ½[¾:¿)¿RÄÀ ')(%')20»D3:/x7Q!3?@6;&Pi`]2365!-7·;)bw`%BF3DB3:ÅE]-0/-7936WbZB3D3|*!3DbJ')E%27_7Q%3D;)BF-3:/D8')(%*@D2~')-0Pi/
7Q%'R7?%BF':)3B3:')/9;&(]-0(!ibZ;)B7Q!3`%B3DB3:ÅE%-0/F-7936WbcBF3D3(!;)BFPi')2@D20')//?q-7Q Â ·20-0793DBF')2
@D20')E]/93:/-0/?/9;&2R'R]23
-0(}`f;&28(!;&Pi-0')2]7-0P3)<^=?;¶q43D)3DB:]Q!3a*!;3:/\(!;)7|')(%')20»D37Q!3@6;&P`#23658-07·;)bm@D')E!7-;&E%/BF3:')/9;&(%-0(!!<p7
7E!BF(]/;&E!77Q%'R7a3D)3:(q?-7Qn7Q%3BF3:/979BF-0@67-;&(g79;`%B3DBF3:ÅE%-~/-7936WbZB3D3(%;)BFPi')2m*!3DbZ')E]27/.q-7Qg`%B;)`f;&/-Æ
7-;&(%')2°X'RBF-~'R]23:/\-0(ÇE%/97-ÆÈ@D'R7-;&(%/')(%*A@6;&(%@D2~E%/-;&(%/:BF3:')/9;&(%-0(!i-~/\-0(79Bk')@67'R]23)<
ÉÊ
ËÌ]ÍXËÎÐÏ°ÑtÒÓÕÔ ML LGJÖZ×ØÚÙJÛnÜkÝßÞ àg+?DáRIâÖZG·MDI[Rã A+AR×#äå#I9MDI9MFæDK8Öc kÖJG·M6çâkIMFMTå8áX LÖZGJÖZèRM×#áRILéiR
K8×#RILênäMJDRK8ÆG\GZë8MáRILÖWML ìpÖZGZëíáîJï:Mð¶GJÖcè)Må8RI6GZ iGZë)GðkáR×! LÖ~ 6Gá[ñ&çãÖJG·M6I9R
òá)Ik×>ð:Æ)K :ML kóÖc ðkáRçWô?õ\ç
ëRI9ä&ö
õI9á:á[D÷^øí3?&-)3.'P')(W;&(!3BF3:*%E%@67-;&(bcB;&Pù`%B;)`f;&/-7-0;&(%')2%/'R7-0/9È#'R]-020-07·79;7Q!3.@6;&P`]23:P3:(7^;)b
7Q!3|`]B;)]23:PT<mú°3D74ûüf3|'/93D7_;)bw@D20')E%/3:/_')(%*iýþ7Q!3/93D7_;)b`%B;)`f;&/-07-;&(%')2X'RBk-0'R]23:/p7Q]'R7_;@D@DE%B^-0(
û<4ú°3D7.ÿ f3')({-0(XÇ93:@67-)3bJE%(%@67-;&(7Q%'R7.Pi'R`]/\3:')@kQ@D20')E%/93  líûª79;'i`%B;)`f;&/-07-;&(%')2X'RBk-0'R]23
z ýi<_ú°3D7
 Hÿ ½  À /E%@kQT7Q%'R7  ln
 
S  nlAý
  S   nlný
  S   lgû.Ü  Hÿ ½  À 
Ü')(%*
Û 
 	
  
 






Ý      {lný      p Alný 

     Al  lgû.Ü  üÿ ½  À X
       Al  lgû.Ü  Hÿ ½  À 
   DRã DM  lgû.Ü  Hÿ ½  À 
øí3@D2~')-0P£7Q%'R7ÙJÛ{ÜkÝßÞ.zà6) :M|-b')(%*;&(%20}-bpûª-0/\/F'R7-0/[È#'R]203)<
O.//E%Pi37Q%'R7û -0/./'R7-0/[È#'R#23 #7Q]'R7-~/D]7Q!3DBF3-0/.'}P;*%3:"2 ! /FE%@FQ{7Q%'R#7 !   û<øí3/Q!;q
7Q%'R77Q!3DB3{-~/')( 3658793:(%/-0;&( ;)bÙJÛ{ÜkÝjÞ7Q%'R7*%;3:/(!;)7@6;&(7')-0(>6Rã DMD< ú°3D7}h %$m× ½    ªl
ý\&Ü !  '
 (" W {lAý\&Ü ! z'
 ))Ý À < ¡ ;/Q%;¶qÚ7Q%'R74hª-~/^')(365793:(%/F-;&(;)b4ÙJÛnÜkÝßÞk8-7x/+E *@63:/
79;A/Q!;q 7Q%'R7h -0/a@6;&(%/-0/793:(7')(%*bZ;)B')202-S ,w.V ,,l1Û{m/ ,1l1h¢-b4')(%*;&(%2{-b , l
z h<ú
3D07 ! 
f3'}P;8*!3:2m/E%@FQg7Q%'R7bZ;)Ba')2012 >lCý2 !3_ 4
 6- 57!  4
 
2 !8_ 9
 6- 57!  4
 
w')(%:
* !8p 4
  
½
À
6- 5;!
z<
 
#')(]=
* !  z  bc;)B')202  /FE%@FQ{7Q%'R7   ÿ  bZ;)B?/;&P3  líû<\7-~//979BF')-0&Q79bZ;)Bq'RBF*
79;{/FQ!;¶q 7Q%'R7>!8 £hi')(%*>hÕ-~/7Q!3DB3DbZ;)B3}@6;&(%/-0/9793:(7D< ¡ '.?)3')(,S-,fV.,Úl Ûn<TO.//E%P37Q%'R7
@BADC

EFGIHKJBL MN6OQP;FRST+NUFT+N6OVNUWDLXYLKR&Z+[1J&O\"F]NU^V_

`/abcdIefgih j1kflcnmUkogpq1k&mUkrfqQrisaub=
t cdvk&k&j1wxf#r&y1h.r	aub=
t cdIz|{}a~s+r&y1fq+fq1mr&mpq
   b7cxs(h q1:h k>  D `) i )x3cxs"`  b;cd>VmUwxmUh.{p a;~9   dz{a;~8k&j1gyr&y1h.r
~u{ p 	k&pw¡f0#b£¢s1r&y+fq=¤fgih j1kf0¥
¦ ~Bsr&y+fi&f0mk§1mUk ¨&j1q1gr©/b7)`(>p {}0k&j1gyr&y1h.r
¥
¦ ~ª©|s/h q17y1fq1gf£+fq1mr&mUpq;©b4cs}h q7h kl©  `«b9csI`«¬b4cd­§y+fi&fi{ p &f®c¯mUk>h q
f°Vrfq1k&mpq±p {§²³´¶µd
vk&k&j1wxf±r&y1h.r²³´¶µ£¦ t ~·0¸¹ º-»¼i½§r&yh.rmUkisr&y+fi&f=mkxh q¾f°Vrfq1k&mpq4c¿p {x²³´Àµ¡k&j1gy<r&y1h.r
¸i¹.º-»¼±b4
t cxd±Á(firl¥
f®h=w¡pV+fÂk&jgy;r&yh.r0{ p >h U(9b9Ã¡s}¥
¦ ~8um6Ä:9b4cxdÅ£fky+pDÆnr&y1h.r
¥
¦ ~¢s+h q1y+fq1gf0¢ÀmUkk&h.r&mUkÇh.f d/efgih j1kf¸¹ º-»¼#b=
t cÈh q1  ¸¹.ºÉ»i¼§b=c¶{ p h Uk&j1gyr&y1h.r
<~È{ p 0kpw¡f®b9¢s)4b<cÊ{p 0q1p<k&j1gy£r&y1h.r<~nu{ p 0kpw¡f®b9¢d®efgih jkf
Ë "ÌB£b=³ª{ p h Ukj1gy/s1`«£bcÍ{ p h k&j1gy/sQÆoymUgyw¡fh q1kr&y1h.r{p fiÎ fi&giUh j1kfmUq±¢spq+f
p {"mUr&k1mUk ¨&j1q1gr&kmUkmUqcxdÂe+fq1mUr&mpqr&ymUk1mUk ¨&j1q1grmUkrj+f#mUq¥ndÂÏofq1gf#fiÎ figiUh jkf#mUq¢¶mUk
rj+fmq±¥Èd
Ð
v q7h rfiq1h.r&mÎ fxÆh£p {p 1r&h mUqmUq+Ñ±r&y+fmqKrh gr&h.mUUmr=p {gih j+r&mpj1k0&fh kpq1mq+Ñ±{p lh UÂgiUh kkfk

Æomr&y0hoÏ	p qp V¨fgr&mÎ fÒh.&r)mUk)rp	h.Ò1Ò­oy+fip &fw8Ód-ÔomUqÕh j1rÖ×4VfUwxh q2sØÙ ÙVØD¤Úr&y1h.r)&fj1gfk
1hDÎ f§&fh kpqmUq+Ñ#rp0gih j+r&mUpj1k/&fh kpqmUq+Ñ#lh 1mUq+Ñ#h+fi{h j1r Ë ©ÛÌÜ©Ú>h q1¡r&y1fomUqQrh gr&h.mUUmUrÝ0fk&j1r
{ p o1hDÎ f0&fh k&pq1mUq+ÑxmUq=Ïop qgiUh k&kfklÛr&mUUwxh q2s2ØÙ Ù.ÞKdo­§y1mkmUk§q+p roh.ÒÒUmUgih.Ufrp®r&y+flÔBßÝmrfih 
gih kf¤fgih j1k&f0mUq±mr1hÎ f&fh k&pq1mUq+ÑxmUkrh gr&h.f d
àlá)âãäÜâåçæ(èêéQë¯ì í¼ »íîï ðQñ¾²³òµ:¦ ~·©o¸ó.ô±ºõïîÝ¼ô¹.º-»©®¹.ðö7»¼iî »³
óÇ¸l÷ô&¼ô&¼&øùVï»íï îÝ¼iúÉ¸íô¼¼ðó.ôíûx¹.º
öK¼ê¸¹.ùVº6î »0ü/ïî ýþó.ðþºÉù»ïêó.ð+»lî ý¹ î¹.ô&¼þó.ðÿíùVðþîïêó.ð+»óÇ¸ºõï îÝ¼iôÇ¹.ºÉ»ï»0þó.úúý¹.ôö
ôóóÇ¸	#Á)fir¢n¤fhkfirp {IgiUh j1kfkd#Å£fxk&y+pDÆ¶r&y1h.rr&y+fifmk	h+fi{h j1rr&y+fip &'²³òµk&j1gyr&y1h.r

² ³òµ¦ t ~·¸i¹.º-»¼ÂmU{h q1pq1Ulm{2¢ mUk/k&h.r&mkÇh.f d}Á(firÃ¬¤fr&y1f§kfirÂp {Ò1&p Ò¤pk&mr&mpqh QÎ.h.mUh.fk«r&y1h.r
pVgigij+omUq¢¡dÂÁ(firo ¤f#h q=mUq.¨Çfgr&mÎ f#{j1q1gr&mUpqr&y1h.rowxh.Òk§fh gygiUh j1kf0b¢Írp®h¡Ò&p Ò¤pk&mr&mpq1h 
Î.h.mUh.f~ k&j1gy±r&y1h.r§¾b
t Ã¡d
fq+f#r&y+f>kfir§p {}+fi{ h jr&k§³ h k{ppDÆokd
³

~



Ë ©

b¢&©}b=Ü~

©





Ë `«>¸i¹.ºÉ»i¼



i






vk&k&j1wxf#r&y1h.r¢Ímkk&h.r&mUkÇh.f dÂÁ(firo¥
c 

b¢~

`«l¸i¹.ºÉ»i¼

~

¤fhxw¡pV+f2k&j1gy±r&y1h.ro¥

«ðD©®¦ b¢&©}b=Ü~

&¥




¦ ~¢¡dÂÁ(fir
¦~

©Ü

 ÎmUpj1k&7c  mk¡gpq1k&mUkrfqQrxh q1<mUr1pQfk¡q+p r®gpqKr&h mUq;¸¹.ºÉ»i¼idfh.'c  mUk¡h qf°Vrfq1k&mpq¾p {

² Ë 
© "ÌÜ©;b³£¦ #b£¢&©/b:B£~¬&© 7bcòµd§e­§y+fip &fw"!d-ÔxmUq7$#ofmrfis«ØÙ Ó.ÞK
r&y+fi&flmUkh q=f°Vrfq1k&mpqc p {o²³=òµ	k&jgyr&y1h.r	c  ¬cxdefgih jkf>ub£c   c { p h (;~3
Æomr&y±b:¢s ¸i¹.º-»¼b=
t cd
vk&k&j1wxf0r&y1h.rr&y+fi&fmUkoh qf°Vrfq1k&mpqc p {	²³òµ§k&jgyr&y1h.r¸¹.ºÉ»i¼b:
t cd	Á)fir¥
¤f0hw¡pV+f
k&j1gyr&y1h.r	{p h U2Ò&p Ò¤pk&mr&mpq1h ¤Î.h.mUh.fk})s¥
¦ ~:m{«h qpq1±m{:bcdefgih j1k&f	¸i¹.ºÉ»i¼>b
t cs
Ë `«%
 ±¸¹.ºÉ»i¼Ì `«&
 ¸i¹.ºÉ»i¼±(
b ')
xcxD²³òµ{ p q1p3~ &b8¢¡d7­«+
h * fh qKu=b8¢¡d ,opBÆ
~ubc h q1y+fq1gf Ë 
© "ÌÜ
© ;.
b '/
xcxD²³òµo{p kpw¡f0©}bBdÏ	fq1gf0
© 7bc h q1
¥
¦ ~ ÜdIefgih j1kf0r&ymUky+pU1k{ p oh U)	b:¢sVq1h ¥
¦ ~¢d
Ð
021 5
3 4687:9<;=:9?>A@B>B77DCED6FHGIC9I>KJ=D>A9?76;L9M;N5OQPRTSLUK1WVX;9?768Y<>AE:=DZ<>[7DC=D67$\+C]?F>^N_;ED`[a<F8Ccbed/fe=DZ?>e@BF8Ca<7DCFNg;ED`h;N
i Z?6@TZ/675j%k.lLlmbR$fonLnqpC9?Y=DZ?>5`r;2Y>BFtsu=DZ?C=vC776wL9<7exzyT{?|}=D;rb/C9+Y^~AL A|=D;rf1v; i 3:4k «ð lmb:cnK1
 ; i >Bq>AEmp2=DZ?>KED>5687=DZ<>7>A=3&k «
 ð lobtRfcnX=DZ?C=}>AJ2=D>B9?Y<7}354C9+Yc67C9>AJ2=D>B9?76;L9;NOQPRTSLUK1
<?

zt< 

I?¡ }¢£¤ ¦¥X§L¨L©$ª¬«­¯®$°%±²³&´ µ)¶¸·r¹	º+»¼_ª¬©T§	»B½+¼¾¨·½+«X¿-¨2§	©¬¨¸°

ºB¹IÀ »o§q»o§oÁ2ÂªÃ¨Lª¬©T§	Ä¾¹L»m§§Åº+»m¿¤§q»o§o¿

Â« ½+»LÆÇ¿¤§¹q½ÈÂ¼g©¬¨MªÉ¨MÊº+ÄDËcÌrÄTÍ½+»B¿¤Î
Ì^»mº2ºB¹	ÏÐ:ÑÒÒÈÓÔQÕ×ÖØ/ÙÚÈÛ¤ØÜDÒÛtÝ:ÑoÝ2ÞßàqáoÔzÒÛ)Ó¬ÑoÒÙhâÑÒÈâXÒÕÔzáoÔzÒÛÚÈã?ÕoÚ+áoÔQÕBäXÚ+ÖÔQãQÔzáKØámÒWámÝ2ÕoáoÔQÛtåM®$°%±²³/´ æ µ/¶5·Aç
è Ý	á¸éuÖ×ÝÚÈÛØêÕmÝ	áëÒÈÓà	ãQÚÈßÕoÝ2Õ	ì5ÚÈÛÞíãQÝ	áIîïÖ×ÝáoðtÝñÕmÝ	áëÒÈÓrâÑoÒÈâ×ÒÕoÔzáoÔQÒÛÚÈã:ò+Ú+ÑÔQÚ+ÖãQÝ2ÕóÒà	à	ßtÑoÑÔQÛåôÔQÛ
éëç è Ý	áõöÖ×ÝóÚÈÛ%ÔQÛ?÷mÝ2àqáoÔzòÈÝóÓ$ßÛàqáoÔzÒÛñáoðÚ+áÙ¸Ú+âÕrÝ2ÚÈàðÅà	ãQÚÈßÕmÝMø/ù.éámÒÚ¸âÑoÒÈâ×ÒÕoÔQáoÔzÒÛÚÈãXò?Ú+ÑÔQÚ+ÖãzÝ
ú

µûõ¯ü$ø2ý^ÕoßàðþáoðÚ+á ú


 
ÿ 	  ùôî



 ÿ ú
µûõ ü$ø2ý±
	 ùôø 
¹q½+¼¾¨	§
ú 
 ÿ ú
µûõ¯ü$ø2ý±
ùø   ÿ


	
 ø/ù&é± ú µûõ¯ü$ø2ý 

¹	½+¼¾¨	§
WðtÝ^ÒÈÑÞÝ	ÑoÝ2ÞÛtÝ2ÕoÕàqÒÛÞÔzáoÔzÒÛëÔQÕvÓ¬ßãgä ãQãzÝ2ÞóÖXÝ2à	ÚÈßÕmÝráoðtÝ^ÑoÝ2ãQÚ+áoÔzÒÛ ü$îõ¯ü$ø2ý	´ ø)ù&é ?ý!Iü"   ´  ù
î#õ ü$ø2ý	´ ø)ù&é?ý$.ü"õ¯ü$ø	ý	´ øMù&é %#o ¹q½+¼¾¨	§?
 ý&Å
 ü$î'( ´ ùî? ýWÔQÕrÔzÑoÑoÝ) Ý* ÔzòÈÝÈç
+ Ýà	ãÃÚÈÔQÙ áoðÚ+á[éûÔÃÕ5ÕoÚ+áoÔQÕBä Ú+Ö ãzÝrÔzÓ ÚÈÛÞëÒÛãzØ ÔzÓ®$°ô±²³/´æµ/¶×¹q½È ¼8 ¨2§	ç-, ÕoÕoßÙ Ý^áoðÚ+á^éûÔQÕ5ÕoÚ+áoÔQÕmä Ú+ÖãzÝ/.
áoðÚ+áWÔQÕ2ìáoðÝ	ÑoÝóÔQÕrÚ Ù ÒÞtÝ2ã$0
ÕßàðþáoðÚ+á10
´ µ éëç + ÝMàqÒÛÕmámÑßàqáWÚÈÛþÝ
* ámÝ2ÛÕoÔzÒÛ2 ÒÈÓ^®$°%±²³^Õoßàð
áoðÚ+á:¹	½+¼¾¨	§óù3
æ ¸
2 ç è Ý	á 4

ÿ  ùôîr±50
  ÿ67	   ùôîr±50 ´æµ  
µ
´µ
 

	 

 ÿ	   ùôîW±50 ´æµ  
  
ú
 ÿ 	  ø/ù%é± ú µûõ ü$ø2ý± 	 ùôø?±50 ´æµ  
ú

 4ÿ ú 	   ø/ù&é± ú µûõ¯ü$ø2ý±  ù%ø<±50 ´ µ  
4 ú 
4
8 Ýqä ÛtÝö
2 µ:v9 « ü"<5; ´ ; ù ? ýçA Ò.òÈÝ	ÑÔQÓÉØ-áoðÚ+á2 ÔQÕëÚÈÛíÝ* ámÝ2ÛÕoÔQÒÛ¯ÒÈÓI®$°%±²³IÔzáIÕß

B àqÝ2ÕIámÒ
àðÝ2à5.
C áoðÚ+áóÓ¬ÒÈÑóÝ	òÈÝ	ÑoØ >=@; ? ?<= ù ì 	 (
; ùD
æ 
2 ìÚÈÛÞ-ÓÉÒÈÑóÝ	òÈÝ	ÑØ ; ?<= ù °E ì 	 ; ùF2 ìÚÈÛÞ.áoðÔQÕ)ÔQÕ
ÕmámÑÚÈÔQåð¤ámÓ¬ÒÈÑ5^
G Ú+ÑÞçIcH Ý2ÛàqÝ®$°%±²³´æµ/¶×¹	½+¼¾¨	§2ç
, ÕoÕoßÙ¸Ý5áoðÚ+áe®$°%±²³/´æµ ¶ ¹	½+¼¾¨	§+. áoðÚ+ávÔQÕ	ì2áoðÝ	ÑoÝÔQÕ}ÚÈÛóÝ* ámÝ2ÛÕÔzÒÛ%2 ÒÈÓ×®$°%±²³ÕßàðMáoðÚ+á¹	½+¼8¨2§)ùæ 2 ç

è Ý	áJ0
Ö×ÝMÚÇÙ ÒÞÝ2ãÕoßàðáoðÚ+áÓ¬ÒÈÑÚÈãQãâÑoÒÈâ×ÒÕoÔzáoÔQÒÛÚÈãò+Ú+ÑÔQÚ+ÖãzÝ2Õ
ì0
´µ
 2ÔzÓ5±SÚÈR ÛÞôýMÓ¬ÒÒÈÛÑ ãzØÚÈãQÔzã Ó ú ùKÕoß2 àð ç
+ ÝþÕoðtÒ<G áoðÚ+á0 ´ µ éëç#[L Ý2à	ÚÈßÕmÝë¹q½È¼8¨2§&ùM
æ ¸
2 ì ¹	½+¼¾¨	§ N	 ú ? ¹	½+ ¼8¨2§%ùP
æ O 8 üQ¸
áoðÚ+á ú µ õ¯ü$ø2ýÓ¬ÒÈÑ ÕmÒÙ Ýøù é çc
H Ý2ÛàqÝ ú ùTï
2 ÓÉÒÈÑIÚÈãQã5Õoßàð ú ç6H Ý2ÛàqÝÓÉÒÈÑ Ý	òÈÝ	ÑoØ ú ìáoðtÝ	ÑÝÔQÕ
8 üQ2 ±SR ýçUcH Ý2ÛàqÝóÓ¬ÒÈÑWÝ	òÈÝ	ÑoØþà	ãQÚÈßÕmÝó·WVYX[ZZZ!þ
X ·]\ ùÅéëì
ú
	$? ú ù(O 8 üQ¸2 ±SRù^ý^ ·WÒÈ2V Ñ ± ú  ±o·]\_	 ì ? ÒÈú Ñ ùKO ùA
ù
æ 2 Ó¬ÒÈÑóÕmÒÙ Ý
æ 2 Ó¬ÒÈÑóÕmÒÙ Ý
ù^

·W2
V
±  ±o·]\_

çA` ÛÅáoðÝ ä ÑÕmá/à	ÚÈÕmÝ ÖØ
 ÞtÝqä ÛÔzáoÔzÒÛ0 ´ µ 	 ç-B` ÛþáoðtÝóÕmÝ2àqÒÛÞ%à	ÚÈÕmÝ  ù[2 ÚÈÛÞðÝ2Ûàq Ý)ÖØñÞtÝqä ÛÔzáoÔzÒÛ0 ´ µ çacH Ý2ÛàqÝóÝ	òÈÝ	ÑoØ
	


à	ãQÚÈßÕoÝóÔQÛôéÔQÕ^ámÑßtÝMÔQÛ0 ìÚÈÛÞ%é ÔQÕrÕoÚ+áoÔQÕBäXÚ+ÖãzÝÈç
b
L Ý2ÛÜdec ãQÔzØÚÈðß¸ÚÈÛÞ 8 Ý2àðámÝ	Ñóüfehg/g/i ý:ÕðtÒjG áoðÚ+á:ámÝ2ÕmáoÔQÛåÇ´ µ/¶Ó¬ÒÈÑeÚóà	ãQÚÈÕÕ5ÒÈÓÞtÝ	Ó¬ÚÈßãzá5áoðtÝ	ÒÈÑÔzÝ2Õ:áoðÚ+á
[
ÕoßtÖ ÕoßÙ Ý2ÕWÚÈãÃãà	ãQÚÈÕoÕoÝ2ÕcÔQÛáoðtÝó
k ÚÈßáml ÚÈÛÞ#n Ý2ãQÙ¸ÚÈÛôÚÈÛÞKn áoÔÃãQãQÙ¸ÚÈÛðÔzÝ	ÑÚ+Ñàð¤ØñáoðÚ+áðÚ2òÈÝëÚ6<o ÜTãÃÔzámÝ	ÑÚÈã
ÒÈÖ÷mÝ2àqáoÔzòÈÝ)âÚ+ÑoáWÔÃÕ[àqÒ+Üd
p Ð5ÜTàqÒÙ¸âãzÝ	ámÝÈçUcH Ý2ÛàqÝ)áoðtÝ)âÑoÒÈÖãzÝ2Ù¸Õ^ÔQÛW ðÝ	ÒÈÑoÝ2Ù¸Õ@tq ç]eho ì_tq ç]ehr ÚÈÛÞtq ç]eq Ú+ÑoÝ
ÔQÛëàqÒ+Üd
p ÐìÚÈÛÞ àqÒÛÕmÝhs ßtÝ2ÛáoãzØëàqÒ+Üdcp Ð:ÜTàqÒÙ âãzÝ	ámÝÈçaW ðÝ1eL Ý2ÛtÜdc ãQÔzØÚÈðß ÚÈÛÞ 8 Ý2àðámÝ	ÑÑÝ2Õoßãzá	ìðtÒ<eG Ý	òÈÝ	Ñì
ðÚÈÕWÛÒ¸ÞÔzÑoÝ2àqáWÔQÙ¸âãQÔQà	Ú+áoÔzÒÛÕeÒÛáoðtÝMàqÒÙ âãQÝ
* ÔzáKØÒÈÓváoðtÝóâÑÔzÒÈÑÔzáoÔ]	l Ý2ÞòÈÝ	ÑÕoÔzÒÛÕ^ÒÈÓáoðtÝ2ÕmÝMâÑoÒÈÖãzÝ2ÙÕ	ç
°

µ



ÿ



ùô
æ î¸ç è Ý	á

 

íÿ
	
	


	  øù&é± ú
ú

	   ø/ù&é± ú
ú

ùôî



 

ùôî

t<ujv

wyxzI{}|<~/7NxU]x
]j~K~}5_|5[x]

false
n’1

n’2
n1

T

p’1

T

n’m
n2

T

p1

T T

p’k

T

T T

nm

pk
T

5%I mS¡/¢£5¤]¡¥5¦¢§¨5¦©ª£5¡¥5«£f¬¡¥­]¤«d®m¦°¯_S¦/S]5±h²²§¨¡/¤1¤¦/]³
´ ·µ ¶¸¹!¶º¼»&½W¾¿ ÀÁ/Â¨ÃNÂdÄÆÅÂQÇÉÈ7Ê6ËÍÌ ÎÐÑ
Ï ÈÕËÍÌ ÎÔÖØ× Á¥ÚÈÁ¥ÚÜÛ Ó¥ÝIÞ È Ó ÚÜßKÕ}Ä ÙÓ¥Þ
Ý ÂÂ¨Ã
ÄSÁ¥ÚÜÇàÄÆÅ%Ë6á
ÅÆÂQÚÆÇWâhÂ&ã Ó ÚÂQÇ Ó¥Ý Á¥ÚmÕ}ÄÚÜÅåä Ó ÈÕ Ý Ç¨ÂdÄÚ Ó/Ý Å Ò áaÇÉÒÔÅ%Ó âSÁ¥æàçè@æ"Ã Ó Ñ ÚmÕé ÒÙ
è@ÚmÁhÁ í/5î%¯5¦7¦/§§¨¦/ì¯_S§É5Sh² Ö ïmh¢_£S¦¢_£1¦¢¤®/ð1ñ1îÔ¯5¦7¦/§§¨¦/ì¯_S§É5Sh² ÖØ× ï
mh¢
ò
£5¦¢£&Ù]êì£&ë £5«©]¤]¡¥hð&ñìîa¯_5¦¦/§
]£$­®Sh²__³5¦¢Ð§¨5¦©M¯5¦/¯Ø¦£55¦¢_¡/¤/£S¡¥5]£f¬¡¥­«¤]d®åm¦15îy³¦©¯¤h©h¢7
¦/§ó5î6¯_5¦/­¤]h©ðô&õ Î÷öjø<ùhúûûûjú5øÆüÔý ­Ø°¡[£5¦/§ó¯_S¦/¯¦£S5¦¢_¡/¤a³¤«¡/_£mh£ ¡/¢_²ÿþ 5î6£m¦/§
¯_5¦/¯Ø¦£5]5¦¢_¡/¤í¥¡¥S]¡¥­¤h£·¦
³³5Ü]¢å«¢õðYô·  ­ØU¡/¢]¢ mh³5í/y§¨¢_³5¦¢5î_¡¥-©¡¥¯£Yh¡/³Sî³¤«¡/_£m
ð ¬¢65î²_§¨¡/_¤]%5î¦/5®
ø  õ m¦K¡[¯_5¦/¯Ø¦£55]¦¢_¡/¤í!¡¥Ü]¡¥­¤  Î 
	 ø  £S_³SîA5î_¡¥   þ

Ë 
Î [ú  ¡/¢²¯_S¦/S]5h£ ä ¦¢  ¡/£ó§¨¦¤]¤¦ å£ð
 
  "
þ !$#  & %'%'(    "
þ !
6ù Î 
 

[& %' ,*
 '* 
  þ"!+# 
  þ"!
$) Î 
$-

Î



Î
ä

Î

 * 
[. 
 ø/ õ

 
12*  ø3 õ ú 
# 
 * 
 *  Ù Ó¥Ý ÅÄ
# 
ÅhÄ  ø/

Ù
/
Ó
Ý
 ù #  ) #  -
 4%',* 0,*
3
87
ú
%' *  *:9



%' * 

,*
! # 
%' 
ú  Î 
	  ø0 
 ø/ õ ú  Î 
	 ø !
 
 4%52* 
 	 ø0 !
Î 
	 ø !+#  #
ø3 õ ú  Î 

%5 * 

õ ú  Î 6	 ø !
  
þ !$#;	 6ù=< 	 $) # $->


?aÜ¦/S5h£¡¥5¢h²h²m¦(_¡¥S¡/¢7m 5î_¡¥3 A@ ]§1¡/¢_²¦¢_¤®N§B'*8A
 @+C ¡/¢_²Am¦/5¡/¤@¯_S]¦/S5h£
³¡/¢_¢¦/­Ø_£mh²­Øh³¡/_£mDU ³¡/¢_¢¦/5h£5mS]³ m¦#5î¦£m©¦
²h¤]£5î_¡¥³¦/55h£m¯Ø¦¢_²Am¦(¯_5§¨55h²
ï
mh¢_£5¦¢_£	Eì 5îF5h£5¯h³°m¦ÿ£m¦©¦/Ü²S]¢#¦¢T5îí¥¡¥S]¡¥­¤h£ FC ¡/£°5î®F¡¥53¢¦/°¢_h³h£5£5¡¥S]¤]®
©¦
²h¤]£¦/§1õ í/h¢N§yõ ]£Ð£5¡¥5]£f¬¡¥­¤/ðñìî²§¨¡/¤å5î_¦/5®K«£Ð²¯]³mh²(]¢#Sð$ §¨¡/¤5£
·HGIÔ
G ¡¥5£5î¦Jì
 ¢¡/£y¡¥55¦Jì
 £K"LMG C ¡/¢_²6²§Q¡/_¤5£N· O%GI.%Ð
G ¡/£U­_5¦./P h¢6¡¥55¦å
 £NQLR
 7G ðTJ
S ¢¤®£m¦©
¦/§U²_§¨¡/_¤]5£T UVIJ
 ¡/¢_² * HVIJ
 §É¦/Ð¯5¦/¯Ø¦£55¦¢_£W  þ ¡/¢² ú  Î 
	 ø0 §¨¦/ øX õ C ¡¥S«¢ C
YJZ[

\=]_^a`Jb'^dc^

e.fdgihkjal0mkl0nEo.mklphkjdl0qresmklptkjdou=fve.twg,e.tkjalgiesmmkou=txzy;l{0|}e.~hkjdesh~t=tkeshk~}t'es,|_lp~_n5e.f,giofd|q
~_nVhkjal0mkl~te+/dmkl0nEl0mkmklg'l&h>lf,tk~_ofo.nWhkjdeshwgao4lt=fao.h={of4hke.~f$0sx
 tktkd+lhkjdesh~t3tkeshk~t'es'|_l.'hkj,esh/~}t0,hkjal0ml~t3eD$o&gdl|V td{jhkjdesh   $x=y;l$tkjaoJu
hkjdesh+hkjdl0mklr~t$e;/dml0n¡l0mkmlg,¢£l&h>lf,tk~_of¥¤¦o.n§tkd{j
hkj,esh8.© ¨ ¤+x¥ªKl0h«¤§­¬5®'¯±°>² ©
³    ´²Nµ·¶i°>²,¸¹ ² © ³º  ¨6²Nµ»¶i°¼'² ² © ³º  ¨6²Nµ»¶i°¼'²,¸ ² © ³º   6²KµT¶i°½· ¾ ©  º ½
¿ ¯¾0Àµ=¶v°¼½2¸Á ¾ ©  º ½; ¿ ¯¾0ÀµÀFx3ªNl0h3ÂÃlpet>h>mF~{h=h>o.hke.|Vo.mgal0m3ofÄÅtk,{jhkjdeshwÇÆAÂÈe.fdg
nEo.mze.||4² © ³ 2É ²ËÊ²ÃÂ+ÉÌ¼'²2Ê.¼'²r~_nK  ´²ie.fdgvÉO¼'²ËÊ.¼Ã²'Â+É ²ËÊ²o.hkjal0mku=~tkl.Íe.f,g½BÉO¼½ ¸ Ê.¼5½ ¸ Â+ÉU½VÊJ½ÎnEo.m
e.||Ã¾ © X&½ ¿ ¯¾ÀFxWÏ±h:~t:t>h>me.~Ðj1h>nEo.mku:esmgDh>oÑ.l0mF~_n¡q$hkj,esh:¤~t·e/dml0n¡l0mkmlg ¢ l&h>lfdt~_ofDo.nV
Ð.lfal0mesh>lgi4qÂ«x»Ò:|_lesm|q0s© ¨ ¤+x
 tktkd+lzhkjdesh·¤£~t·e/dmkl0nEl0mkmklg ¢ l&h>lf,tk~_of«td{j«hkjdeshK0sO0/© ¨ ¤+xWªNl0h»ÓÃlwe8$oÍgal|dtkd{Fj
hkjdeshznEo.mwe.|}|Í² © ³ ,  ´²v~n5e.fdgrofd|_q"~_n,² © ¤+x:Ô»l{0e.dt>lwsO08© ¨ ¤«'fao+gdl0nEe.d|h½2¸¡É 0sO0ÕÊFsO0
~t/esd,|}~_lgi~fv¤+2uwjal0mklX½´ ¿ ¯¾0ÀwnEo.mt>o$l$¾ © $x8Özjal0mkl0nEo.mkl½ ¸ © ¨ ¤ÈnEo.m/e.|}|V½´ ¿ ¯¾Àwtkd{Fj
hkjdesh¾ © $x«Özjal0mkl0nEo.mkl¼5½2¸ © ¤×e.f,g;½ © ¤×nEo.mpe.||Btk,{j½BxØ=lfd{leigd~tÙ>df,{hT²
~t8~f;¤×o.m
² ¸ ~t/~fÎ¤Èn¡o.m8eg,~tEÙkdfd{h/¼Ã²ÎnEo.ml0Ñ.l0mkqÎ¾ © $x8ÏfhkjdlX,mt>h/{0e.t>l$&qgal'f,~_hk~_ofo.n·K  ¾x
Ïf"hkjalt>l{ofdgr{0e.t>l:²´© ¨ ¤+aËl{0e.dt>lo.hkjdl0mku=~t>l¼'²'¸,u»od|gDËl/~}fD¤e.t²KÉO¼'²'¸ÚÊ.¼'²,¸Ì$É ²,¸Ê²,¸xWØwlfd{l
  Û¼'²e.fdgi  Ü¾xTÔ»l{0e.dtklhkjd~tjdo|gdt:nEo.m=e.||N¾ © $Í'fde.||_q  (Xx
Ý
Þß+à=áaâWã¹äÍåNæNç1èÃé»êTã±äë«ç4ãåNç1ãìãíaá,îAï;á,ðñè2ò·óÁìà=åNæKã¹ä
 gdl'fd~_hk~_of«o.nNdm~o.m~_hk~_ô0lggal0nEe.,|_h»|o.Ð~{w~}t»,t>lg«&qõw~f4hke.falfv¯ö÷.÷.÷ÀFx:Özjd~}t·galÃfd~_hk~_of~tT'e.t>lg
o f6e.flesm|~l0mofaln¡o.me.ah>o4l0'~t>h>l+~{«|_o.Ð~{¯õw~f4hke.falf2:ö÷.÷ø4ÀFxÖzjal«dm~_o.m~h¹qÎ$l{jde.f,~tk¦,t>lt
|_la~{o.Ð.mes,j,~{X{o$,esm~tkofe.fdg;hkjal$,mkl0n¡l0mmklg;lÍh>lfdtk~_ofdt~fÎhkjd~tesd,mkoe.{j´gaorfao.h~fÎÐ.lfdl0me.|
{o~fd{0~}gal·uw~_hkjhkjal:dmkl0nEl0mkmklgl&h>lf,tk~_ofdt~fhkjal:dm~o.m~_hk~_ô0lgpgal0nEe.,|_h5|o.Ð~{0tBgd~tk{0,tkt>lg~f+ù&l{hk~_oføax
ªNla~{o.Ð.mes'jd~{{o+,esm~t>ofjde.t3lesm|~_l0mwËl0lfdtklgi~fihkjal{of4h>lÍh3o.n·faofd$ofao.h>of,~{8mkle.tkofd~faÐ
&q+t>l0Ñ.l0me.|Ãmklt>lesm{Fjal0mt/¯ªK~_ntk{Fjd~_h>ô.Ëö÷.ú.û&'ü3lýËfdl0mþ(ÿ5lesm|ÁËö÷.÷ &,õzqe.f2Ëö÷.÷ ÀFx:Ò:o$,esm~fdÐ8h¹u»o
lÍh>lfdtk~_ofdtw~tz'e.t>lgrofu=jal0hkjal0mwhkjalpgdl0nEe.d|hktzesmklÐ.lfdl0meshk~faÐDgal0nEe.,|_hktzo.nBhkjalpl&h>lf,tk~_ofdt0,hkjdesh
~t0.uwjal0hkjal0mBhkjal~_mB,mkl0mkl &d~tk~_h>ltVËl|_ofaÐ/h>ohkjallÍh>lfdtk~_of$e.f,gXhkjalzfal0Ðeshk~_ofdtWo.n'hkjalVÙkdt>hk~ÚÃ{0eshk~_ofdt
gao$fao.hËl|_ofaÐh>o$hkjal/lÍh>lfdtk~_of2xBy;lptkeqDhkjdeshzeÐ.lfal0meshk~fdÐ+gal0nEe.,|_h·o.ne.f"lÍh>lfdtk~_of~t ' 
 	
~f"hkjall&h>lfdt~_of2x
!#"%$$&')(*,+.- 	400/Í21436587:9 º<;<;<;º 7*=aÊ?>@¡es,,|~_lg6~f
s®
	 °¼7 9 º<;<;<; º ¼7 = µ6E ¬5®'¯¤XÀWGFIHKJML}N¡O	1®P)1¹
	RQTS")'}¯U36587 9 º<;<;<;º 7 = Ê?>

¤RÆBAC X¤
º ¤XÀTH
y;lesddmkl0ÑÍ~esh>l8esd,|¯V º ¤Àze.fdgrfao.hwesd,|Á¯V º ¤¸¡À»&qhkjalpfao.hkeshk~_ofies,,|Á¯V º ¤ º ¤8¸EÀFx

 D3

XWY
ZN[]\^][_[]`a]bb0+.c <1edÄ ºf@g QXh	1Á/&i1j1LÍ
P0klSrs®	p «l1UklUm?1:Íkn
1UÁ sPko1
	 <kp.
P ®iÄqH c 
1 ¤rQ +s®´
s¹1 ®alUPs®!P3RHhJMLÍ0®i¤t¡/dmkl0nEl0mkmklg*uvlÍh>lfdtk~_ofvPw 
1Í
L <>k %¡ «T1Ukm1x1yP1 sjPko1
	 <
k ÂzsP ®ÎÄ /*mTL{1&
L ·
1  Æ ÂRs®|
	 <P0
k .¡·#s)¹1 ®dsP ®a¤8¸}>P  s®|	
V © Ä~
)' }¯V º ¤ ¸ º ¤XÀOx' 2Á O1&L Ã1 <P0
k TP+
 N © Ä º k Âi
V s®"
	 '
 }¯ º ¤ º ¤ ¸ À ;
 /*mTLi«l1Uklm1j1yP1sPko	1<kO¡pX

º /o.mgal0m~}faÐ<P0k=¤H

dmz~f1Ñ.ltkhk~_Ðeshk~_ofof|_lÍ~}{o.Ð.mes,jd~{3dmF~_o.m~_hk~_ôeshk~ofD~}fgal0nEe.,|_h:mkle.t>ofd~fdÐ$u»e.tz+o.hk~_Ñesh>lgi4q
lesm|~l0mBu·o.m
Xof«hkjalh>o.,~{¯Ö5e.fþÛÖKmkldm,ö÷.÷&aÔ:e.e.gal0m»þAØwo||,fdgal0mdö÷.÷.ûÀFxTÖ=jalt>lzgal'f,~_hk~_ofdt
o.nT,m~_o.m~_hk~lt=nEo.m8gal0ne.d|_h/|_o.Ð~{XesmklXdmkoÍ{lgdame.|Ãe.thkjdl0qesmklXÐ~_Ñ.lfe.t/lÍh>lfdtk~ofdt3o.n/¯faof,gal0h>l0m>
+~f,~t>hk~{À=gal{0~tk~ofÎdmkoÍ{lgdamklt/nEo.mgal0ne.d|_h|_o.Ð~{sx+Ö=jd~t3dmkoÍ{lgdame.|Bf,eshkamkl$o.n»dm~_o.m~hk~_ôeshk~_ofÎ~t


?

jipIIi?)q
I *
¢¡a|£¤¥¦

§©¨ª*§#«­¬
«­®¨p¬©¯R¬
°I¨²±­¨ª*³¬
°*§´¯µj§
¨¶·I¨ª¤¸T¨§¹¯µjº*¨<µ»·*±¬
§¹«ª®¯)±®¨º«ª.ºI¨<¼#«­®«ªI³h¸T¨<¼
¬
»«ªµ»¸T¬
§<½N»¾²¯)ªI³
¬^¿j¯K¸T¯)ªÀ|«¸T¬
«ªI³²ºI¨<µU»·*±­¬
§6¬
°*¨¹¯)ªI¨¹¿}«­¬
°h¬
°I¨Á±­¯?¿j¨<¼4Â*¼#«¯¼#«­¬^Ã¾²»ÃÄ¨¸T¯)¾Å¨O»0Â*Â±«­¨ºh§©¯)±­¨±­Ã%Ä¨¸<»·*§©¨
¬
°I¨R§©¨¶]·I¨ª*¸T¨¯µ´ºI¨<µU»·*±­¬
§ÅªI¨<¨º*¨ºvµ¯¼²º*¨<¼#«­®«ªI³.«­¬
§pÂ*¼
¨<¼
¨¶]·*«§#«­¬©¨«X§Å§
°I¯¼
¬©¨<¼ÆUÇj¼
¨<¿4È0»ÊÉÌË«­¬©¨<¼Í
ÎÏÏÐ)ÑÒÓ Â*Â*¼#¯)»¸#°I¨§j¬©¯Â*¼#«­¯¼#«¬
«­Ô«ªI³NºI¨<µU»·*±­¬
§¬
°*»0¬6»0¼
¨xÄ»§©¨º¯)ª%±­¨TÕI«¸T¯³¼#»0Â°*«¸}¸T¯)¾²Â¤»0¼#«§©¯)ªqÆUÖM«­µ×
§
¸°*«­¬©ÔÍ ÎÏÐØ]Ù Çj¼
¨<¿}È_»Í ÎÏÐÏ]Ù:Ú ¨TÛ:ªI¨<¼xÉeÜ¨»0¼#±Í ÎÏÏÝ]Ù|Þ Ã)»ª:Í ÎÏÏÝ)Ñ ºI¯²ªI¯¬ß¨TÕI°*«­Ä¤«¬¬
°*»0¬}È]«ª¤º%¯µ
Ä¨°*»®«­¯¼ Ò
ÖM¨TÕ«¸T¯³¼»0Â¤°*«¸²¸T¯)¾²Â¤»0¼#«§©¯)ªà°*»§NÂ¤¼
¯Â¨<¼
¬
«­¨§N¬
°¤»0¬Á»0¼
¨%µ»?®¯¼#»0Ä¤±­¨%µ¼
¯)¾w¬
°I¨²Â¯)«ª¬N¯µß®«­¨<¿á¯µ
ÈªI¯?¿}±¨ºI³¨¼
¨<Â*¼
¨§
¨ª¬
»0¬
«­¯)ª Ò ËâÕ¬©¨ª*§
«­¯)ª¤§p¯µ´»ÊºI¨<µ»·¤±­¬p¬
°I¨<¯¼
Ãv»0¼
¨Â¯)§
§
«­Ä±­¨«Xª¬©¨<¼
Â¤¼
¨<¬
»0¬
«­¯)ª*§Å¯µ
¬
°I¨º*¨<µ»·*±¬Å¬
°I¨<¯¼
ÃÍß¼
¨<Â*¼#¨§©¨ª¬
«XªI³º*«iÛ¨<¼
¨ª¬²¿j»?Ã]§K¯µ¹¼
¨§©¯)±­®«ªI³.¬
°I¨¢¸T¯)ªÀ«¸T¬
§KÄ|¨<¬ã¿¨<¨ªäºI¨<µU»·*±­¬
¼#·*±¨§ Ò Ü¼#«­¯¼#«­¬
«¨§p¨TÕ]Â*¼#¨§
§²¬
°I¨¢Â¤±»·*§#«­Ä¤«±«¬^Ã{¯µ¹º*«iÛ¨<¼
¨ª¬²¿j»?Ã]§%¯µ¹¼
¨§©¯)±®]«ª*³{¬
°I¨¢¸T¯)ªÀ|«¸T¬
§<Íß»ª*º
¸T¯)ª*§©¨¶]·I¨ª¬
±­Ã»¸T¬¹»§´»ª¢«X¾ÅÂ¤±«¸<«¬ß¼
¨<Â*¼
¨§©¨ª¬
»0¬
«­¯)ªq¯µâÂ*¼
¨<µ¨<¼
¨ª*¸T¨§Ä¨<¬^¿j¨<¨ªq¬
°I¨¨TÕ]¬©¨ª*§#«­¯)ª*§ Ò¹å ªI¨
·*§©¨<µU·*±0Â*¼#¯Â|¨<¼#¬^Ã}¯µI±­¨TÕI«¸T¯³¼#»0Â°*«¸¸T¯)¾ÅÂ¤»0¼#«X§©¯)ªN«§:¬
°¤»0¬æ¨<®¨<¼
Ãçª*«­¬©¨âºI¨<µU»·*±­¬:¬
°*¨<¯¼
Ã¹°*»§æ»0¬M±­¨»§
¬æ¯)ªI¨
Â*¼
¨<µ¨<¼
¼
¨º¨TÕ¬©¨ª*§
«­¯)ªp¿x°I¨ªI¨<®¨<¼,«­¬â°*»§â»0¬,±­¨»§
¬â¯)ªI¨ Þ ¨«­¬©¨<¼â¨TÕ¬©¨ª*§
«¯)ª Òaè ¬,ºI¯]¨§âªI¯¬â§©¨<¨¾eÂ¤±X»·*§
«­Ä¤±¨
¬
°*»0¬ß¬
°I¨´Â*¼«­¯¼#«­¬
«­¨§¸T¯)·*±ºh¸T¯)ª¬
»«ªR«ªIµ¯¼#¾²»0¬
«¯)ªK¬
°*»0¬ß«ª¤º*«¸<»0¬©¨§j¬
°*»0¬4ªI¯)ªI¨´¯µa¬
°I¨´¨TÕ]¬©¨ª*§#«­¯)ª*§ß«§6»
Â¤±»·¤§
«­Ä¤±­¨x¾Å¨»ª*«ªI³p¯µa¬
°I¨¹ºI¨<µ»·¤±­¬6¬
°I¨<¯¼
Ã ÒÓ ªI¯¬
°I¨<¼4·*§
¨<µ·*±Â*¼
¯Â¨<¼
¬ãÃ%«§j¬
°*»0¬ß¨<®¨<¼#Ã%¨TÕ¬©¨ª*§
«­¯)ªh¯µ
»ºI¨<µU»·*±­¬´¬
°I¨<¯¼
Ãq«§¹»hé´×yÂ*¼
¨<µ¨<¼
¼
¨º¤ê{¨TÕ]¬©¨ª¤§
«­¯)ª.µ¯¼O»§
·*«­¬
»0Ä±­ÃR¸#°I¯)§
¨ª{é Òpè ª.¯¬
°I¨<¼¹¿j¯¼#º*§Íæ¬
°I¨
¿6»ÃRÂ*¼«­¯¼#«­¬
«­¨§ß»0¼#¨Á·*§©¨º¢«ªR¼»ªIÈ]«XªI³Å¬
°I¨O¨TÕ¬©¨ª*§
«¯)ª*§}§
°*¯)·*±ºRªI¯¬xÂ¨<¼x§©¨Á¼#·*±­¨¹¯)·I¬x¬
°I¨OÂ¯)§
§#«­Ä¤«±«¬^Ã
¬
°*»0¬}»K¸T¨<¼
¬
»«ª¨TÕ¬©¨ª*§
«­¯)ª«§6Â*¼
¨<µ¨<¼
¼
¨º¯¼}¬
°*»0¬}«­¬4«§6¬
°*¨O·*ª*«¶]·I¨Â*¼
¨<µ¨<¼
¼
¨ºh¨TÕ¬©¨ª*§
«­¯)ª Ò
Ó º¤«§©¬
«ªI³)·¤«§
°*«ª*³º*«­Û|¨<¼
¨ª¤¸T¨xÄ¨<¬^¿j¨<¨ª¬
°I¨´±­¨TÕ«X¸T¯³¼#»0Â¤°*«¸}Â*¼#«­¯¼«­¬
«­Ô<¨º²ºI¨<µU»·*±­¬j±­¯³)«¸x»ª*º¯¬
°I¨<¼
¿j¯¼
È¯)ª.Â*¼«­¯¼#«­¬
«­¨§x«ª.ºI¨<µU»·*±­¬´±­¯³)«¸«§¬
°*»0¬¹¬
°I¨Å°*«­³)°I¨§
¬xÂ*¼«­¯¼#«­¬ãÃRºI¨<µ»·¤±­¬4ë¢«µâ¬
°I¨<¼
¨²«§x¯)ªI¨ë«§
»0Â*Â¤±X«­¨º«ª»±±:Â¤¼
¨<µ¨<¼#¼
¨º*êR¨TÕ¬©¨ª*§
«¯)ª*§}«­µa¬
°I¨<¼
¨«§4»ª¨TÕ¬©¨ª*§
«­¯)ª¿}°I¨<¼
¨N«¬}«§4»0Â*Â±«­¨º Ò Ü¼
¨<µ¨<¼#¼
¨º¤ì
»ª*ºÂ¤¼
¨<µ¨<¼#¼
¨ºíîà¨TÕ]¬©¨ª¤§
«­¯)ª*§4º*¯²ªI¯¬}»±­¿6»Ã§}»0Â*Â±­ÃK¬
°I¨N»0Â¤Â¤±«¸<»0Ä¤±¨´°¤«­³)°I¨§©¬6Â*¼#«¯¼#«­¬^ÃºI¨<µU»·*±­¬
§ Ò
ïðæñ¤òàóôõqö:÷øàù©úpû_õüKýñ:þßø]ÿ¤ÿ )
¯ ª¤§
«ºI¨<¼6¬
°I¨NºI¨<µU»·*±­¬j¬
°I¨<¯¼
Ã	
¿}°I¨<¼
¨
Ò
.
»ª*
º !½ #"$$%¤'½ &(#")&($%¤*½ +",
¨T
ç ª*¨N¬
°I¨¹¼
¨±»0¬
«¯)ª
é/1032

x½4 K
 ½5&(
 ½8&3 %
K
 ½9
x½4 K
 ½8

2

2

&(76
&
(
 6
:
 6<;>=
:

Ó <¸ ¸T¯¼#º*«ªI³O¬©¯ - ¨Tçª*«­¬
«¯)ª*§(? Ò8Ý »ª*º@? BÒ A ¬
°I¨x§©¨<¬
§.CED:»0¼
¨}»§µ¯)±±¯?¿}§<Í»ª*º²¬
°I¨x·*ª*«¶]·I¨6é´×yÂ*¼
¨<µ¨<¼
¼
¨º í
»ª*ºé´×yÂ¤¼
¨<µ¨<¼#¼
¨º íî ¨TÕ¬©¨ª*§
«­¯)ª¯µF X« §GCIH DKJMLONQP ÆC D ÑÒ

CERS
CTLU
CEWS
C<D:


V&(
V&($X
CY
W µ¯¼»±±[ZF\ A

è
ª ¯¬
°I¨<¼¹¿j¯¼#º*§Í|«ª¤«­¬
«»±±­Ã¬
°I¨p°*«­³)°I¨§
¬xÂ*¼«­¯¼#«­¬ãÃhº*¨<µ»·*±¬]½!#"$Á«X§xªI¯¬¹»0Â*Â±«¸<»0Ä¤±­¨Í|»ª*ºq°I¨ª*¸T¨p¬
°I¨
§©¨¸T¯)ª*º.ºI¨<µU»·*±­¬Y¤½^&3+")&3O«§x»0Â*Â¤±«­¨ºæÍ»ª*º&(N«§x¯Ä*¬
»«ª*¨º ÒY_ °*¨Á°*«­³)°*¨§©¬}Â*¼«­¯¼#«­¬ãÃhº*¨<µ»·*±¬}«§§©¬
«±±
Ò ` ¯?1
ªI¯¬¹»0Â*Â¤±X«¸<»0Ä¤±­¨Í»ª*º.°I¨ª*¸T¨p¬
°I¨p¬
°*«­¼º¢ºI¨<µU»·*±­]
¬ *½ +",O«§´»0Â*Â±«­¨º:Í»ª*
º O«X§x¯Ä¤¬
»«ªI¨º a
¿ !½ #"$
Ò b
¿j¨<¼
¨O»0Â*Â¤±X«¸<»0Ä¤±­¨´«­µM¬
°*¨O¸T¯)ª¬©¼»º*«¸T¬
«ªI³²º*¨<µ»·*±<
¬ ¤*½ &(#")&(´¿j¯)·*±ºª*¯¬}°*»®¨OÄ|¨<¨ª»0Â*Â¤±«­¨º%ç¤¼§©¬ c

_ °*¨q»0Â*Â±«¸<»0¬
«­¯)ª ¯µN¬
°I¨{°*«­³)°*¨§©¬KÂ*¼«­¯¼#«­¬ãÃ ºI¨<µ»·¤±­¬Åë ¿}°I¨ª*¨<®¨<¼Â¯)§
§#«­Ä¤±­¨hë j
¿ ¯)·*±ºä§©¨<¨¾ »
·*§©¨<µU·*±ßºI¨¸<±X»0¼#»0¬
«­®¨RÂ*¼#¯Â|¨<¼#¬^ÃÊµ¯¼%ª*¯)ª*¾Å¯)ªI¯¬©¯)ª*«X¸h¼
¨»§©¯)ª*«ª*³q¿x«­¬
°vÂ*¼#«¯¼#«­¬
«­¨§ Òd_ °IR
¨ §#»0¬
«§©µU»¸T¬
«­¯)ª

¯µ4¬
°*«X§NÂ*¼
¯Â¨<¼
¬ãÃ±­¨»º*§Á¬©¯q±¨TÕ«¸T¯³¼»0Â¤°*«¸ÅÂ¤¼#«­¯¼#«­¬
«Ô»0¬
«­¯)ª ÒRÓ ±§©¯IÍ¬
°I¨Ä|¨°¤»®«­¯¼O¯µ}±¨TÕ«¸T¯³¼»0Â¤°*«¸
Â*¼#«¯¼#«­¬
«­Ô<¨ººI¨<µU»·*±­¬±­¯³)«¸N«X§}¾Å¯¼
¨¸T¯)ª*§
«§
¬©¨ª¬xµ¯¼´ºI¨<µU»·*±­¬4¬
°I¨<¯¼«­¨§}¿x«­¬
°ªI¯¼¾²»±æºI¨<µU»·*±­¬
§Ye½!f("f

ggih

jEk'lnmoVlp4l

q)rsut+v'w4xzy#v'{|Xy#v}q,~zy#ssy+Kq)v}~~%ny+w)|X}y#xE}~%|Xy+|%y#9}x%'~zyK|%y+y@rnw)|q)vOsny+q)v'~%x!Q$F
 nyv}q,~z~zy+|Gsny+q)v'~%xq)v}v'w|%y#q)xzw4r}rn8{@tw4r9~z|Xq,[w4x%'~%'w4rE'~%@~%ny]}v}t+q,~%'w4rx+4q)rs ~%nyY¡w)|y+|
snwrnw)~+M~w)~%y+|%E}xzy>~%ny+{|%y+|%y#x%y#ri~]|%y#v}q,~zy#s¢Vq,~z~zy+|Xrx]w)O|Xy#q)xzw4r}rnn  nyv'w)4}t+x]8{£|%y+<¤,q
q)rs9{a£¥q)q)sny+|3q)rs>¦Ew4vv}rsny+|Mw)|sny+|§y¨5~zy#rx%}w4rx©v'y¨n}tw))|Xq,V}t+q)v}v'{Kw)|§~%nyv}q,~z~zy+|Q¤8}rsaw)sny+q)v'~
~%ny+w)|X}y#x+nn~<rnw)~E¡w)|<~%yT¡w)|Xy+|#
ª«9¬(­Q®¡¯®K°V­²±[³}´¶µ©·n¸¹º,»n¼+¸X½+¾¸»¿¹¸ÁÀz¸+ÂÄÃ)ÅÆÇº,»ÉÈ Ê]ËÉÆ¡¼¢Ì9¸ÍF»¿¸XÌÎ+ÏÁÐ
Ó+º,ÀÖ×¾5Â'Ã Ò Æ¡¼]ÆK»ÁÃ,ÂKÂØÙ}Ú¿Àz¸ÇÓ+¸+ÀÀ%¸%Ì+Ë²¸%ÛiÅÜ¸»n¼ÝÆº,»¼>ºÞÓEÐß

È ÊTÑ¶
Ë Ò

Æ Ó¢Ã,»¿ÌÔº,»Â^ÏÕÆ Ó¢ÅK·n¸

àáâãäQå «±M³æIç y+~YèéëêìíQ[y<qasy+Kq)v}~3~%ny+w)|%{×Eny+|%y<é Êîzï !ð4$ð8ê ï ^ñ(ò4)ñ(òê%ð8óòiò8ôYq)rsì Ê
îzï ô4 ç y+~ ØõÊî è ï *ñQòi)ñQò$ê%ð8óò4òiíXôö[y@qx%~z|X}t~Vq,|%~%}q)vFw)|sny+|÷w4rué  ny sny+Kq)v'~~%ny+w)|X{Áq)x
~Üwy¨5~zy#rx%'w4rx#5øaù ÊúQ»Vûüîzï ê%ð8êñQò8ô$ýYny+|%y~%nyTsny+Kq)v'~%x ï *ñQòi)ñQò÷q)rs ï !ð4$ð÷q,|%yTq,Vv}'y#sM5q)rs
øEþ ÊÿúQ»Vûüîzï ê%ð8êzò8ô$ý¥Yny+|%y ï !ð4$ðq)rsëð9óòiòq,|%y÷q,v}'y#s  ny#xzyay¨5~zy#rx%}w4rx<q)rsq)v}vMxz~z|X}t~E~zw)~%q)v
Ø 
w)|Xsny+|
x
w4rëéõx%të~%q,~ 
q,|%y÷sy+}t~zy#s[y#v'wa  nyw4x%~Yx%'4r Vt+q)r9~<sny+Kq)v'~%xEq,|%y÷~%ny

v'w.y#xz~+ nyTxz{5[w4
v >xX'4r y#x¥~%q,~<~%nyasny+q)v'~<}xGq,v}'y#söq)r	
s ×~%q,~E'~<}xGrw)~Eq,v}}y#sM






 



 

  




 

 

 

 
!
  


"

 


 

#$
  


 

 yy¨8~zy#rxX'w4rÕø ù }xq Ø |%y+Ky+|%|%y#s Ë y¨5~zy#rx%}w4rÕ[y#t+q)xzy~%nyëv}y+¡~%w4x%~xz~z|X}t~~zw)~%q)vGw)|sny+|
¿ù}xq Ð ê Ø w)|sny+|X}rn¡w)|öøTù+ð8óòiòÁ}x~%nyw4rv'{Õsny+q)v'~&%¢x%tX ~%q,~ q,v û %ê%øEþ)ê%øaùÝýEq)rs
q,v û*ï *ñQòi)ñQòê%øaù#ê%øEþý<q)rs ï *ñ(ò4)ñ(ò$¿ùÞð8!òiò8  yay¨8~zy#rx%'w4rëøYþ}xErnw)~Yq Ø |%y+Ky+|%|%y#s Ë y¨5~zy#r5
x%'w4r[y#t+q)xzyTrnw4rnyw)©~%yY~%n|Xy+y]x%~z|X}t~~zw)~%q)v[w)|Xsny+|X'
x ¿ù+ê nþ$ê )(Y}xq Ð ê Ø w)|Xsny+|}rn>¡w)|<øYþ3Kw)|Gq)v}v
*,+ .î - 0ê /80ê 19ô4(~%ny+|Xy}x]~%nysny+q)v'~ ï *ñQòi)ñQòöx%t¢~%q,~q,v û*ï ÄñQòi)ñQòê%øaù+ê%øEþýq)rs¢~%ny+|Xy}xTrnw
sny+q)v'
~ %>x%t~%q,
~ % 32 ï *ñQòi)ñQò×q)rsq,v û %ê%øEþ4ê%øTùÝý
4

5«

ã ãâ ±M³ 687©¸#Å.ÐÊ èéëêìí ÎX¸ ÃÌ9¸Ó+Ã,¾5Â^ÅÅK·5¸%º)ÀÏ:9(·5¸À%¸ é Æ¡¼ÍF»ÆKÅÜ¸<;Ã,»VÌÂ}¸+Å.Ø ÎX¸ Ã¼ÝÅÀÝÆ¹Å
u
Åº)ÅÃ,ÂMº,ÀzÌi¸À]º,» é ß=7§¸+Å[Ðÿ·5Ã$>,¸TÃ4Å§Â}¸%Ã,¼ÝÅ3º,»¿¸T¸XÛ4ÅÜ¸»¼ÆÇº,»Vßµ©·5¸»ÅK·n¸À%¸Æ¼¸XÛiÃ4¹ÅÂ*Ïº,»¿¸.ØÙÚVÀ%¸Ó#¸ÀÝÀz¸XÌ+Ë
¸%ÛiÅÜ¸»n¼ÝÆº)»ºzÓYÐß

?¥Àzº#ºÞÓA@'B y>x%nw~%q,~E~%y+|%y}x<q)rëy¨8~zy#rx%'w4rëø1w) Ð x%tX~%q,~ Ø }x<~%ny Ð ê Ø w)|sny+|X}rn@¡w)|Eø@
ç y+~'% ù#êACACAC#ê0%ED[yG~%nyEw)|sny+|X}rn Ø w)éëGFy<Vrnyé!2 Êî %ù#êACACACê0%E2 ôEKw)|q)vv *+ îH êACACAC$ê"I(ô4Fy<Vrny
Kw)|Eq)v}v *+ î.- êACACAC ê"IKJ - ô4
LNS
M Ê î ø PT
O È ø	}xEq)ry¨8~zy#rx%'w4rw) Ð ô4êEq)rs
L 2RQ§ù Ê S L î ø + L 2 È q,v û %E2R§Q ù#ê%ø>ýXô 'Qq,v û %E2RQ§ù#ê%ø>ý¥¡w)|Ex%w4yø + L 2 ê
2
w)~%ny+|XE}xzy)
T »VÌ,¾¹ÅÆº,»·iÏÚ5º)ÅK·5¸¼Æ¡¼ nU w)|GV + îH êACACAC ê * ô4 ûW- ý3~%nyExzy+~ LYX }x.rnw4r5y#~Ü{) û 4/ ýFKw)|.q)v}vø + LYX q)rs
ø[Z + L X q)rs\% + é X 9q,Vv û % ê%ø>ýO
] q,v û % ê%ø[¡Z ý5q)rs û 41 ý3¡w)|q)v}vø + L X q)rs@ø[Z + LNM^ L X ~%ny+|%y
X
û
+
}x'%
é x%tX~%q,~¥q,v % ê%øê%ø Z ýFq)rs@~%ny+|Xy}xrnw!% Z + éÿxXtX~%q,~_% Z Ø a
% q)rsq,Vv û % Z ê%ø Z ê%ø×ý
 yT|%w8w)Kx¥w)([w)~%~%nyTq)x%yt+q)xzyq)rs~%ny}rst~%a)` y]t+q)xzy÷q,|%y÷xz~z|Xq)'49~z¡w)|Xq,|Xs
 yt+v}q)1w)§~%ny]v'y#q×}x.w)~%q)}rny#s K|%w4 ~%ny]Kq)t~%x<y#xz~%q,v}}xXny#s@}r ~%nyT}rst~%'w4r@|%w8w)©q)x
Kw4v}v'wYx+3£.{ ûW- ýF~%nyExzy+~ L D}xFrnw4r5y#~Ü{)F£{ û /4ýOq)rs  ny+w)|Xy#x/8cb×q)rs\/8ed}r ûgf y#'~zy+|# -hji$H ý

kkl

m=npoq.r sjtpuvxwynpz!{|)uRnp|)uv3uR}s~:s.z)rv	nuR3
Y[<3"Rg ¢¡y £#¤¢¥
£[¦¨§ª©«¡¥
¬[­
£Y¦ ¦®§ª©8£[¦g¥
¯°¬±³²§µ´¶ A·A·A· "´¸)¹º¼»½\
¾"¯À¿g£[¦g ²GÁ'»ÃÂ'ÄÅjÆÇ¿g£È ¢É®´®Á»Ë
Ê Â'ÄÍÌÎjÏÅjÐRÐ´y»ÒÑ´¶ A·A·A·  "´¸Ó
­±Ô³£Y¦¨§ª©£[¦.Õ	ÑAºÓ
Ô
ÔÖ­¾"×¼£Y¦©³£[¦ ¦g¥
¾"¯À¿g£N 0ØÁ'»ÃÂ_ÄÍÌÎjÏÅjÐRÐØ	»£ ¦ ÅjÆÇ¿g£ ¦  0ØÁ=»ÃÂ_ÄÍÌÎjÏÅjÐRÐØ:»£
­±ÔÍÙ­Ô³"Ï0ÚÙ×®Û)PÙ­Ô³ÌÎÅjÐÜ"
Ô
Ý
aÞÚ)ÏYßà§áÍâÏ0àã<ÆÚÏ,ÌäjÏÏã<jÞaåRÞ<à"0a
æ ç ¸ æ3è°é$ê_ë ã< ç ¸ RÅÈRÞÐaA"¼Ñ£Ó êì A£Y¦íÙÅj.î&<3"ajÌï ê áÚð[ñÅ$ñ)AÏ
Róò ¦ »ôÚã0ñ¼ñÅ$,Å$ââÐõöò ¦  £ ¦  £#¤ ê!ë ã<N£ ¦ ©8
Ê £÷ÅjÆÒ£ ¦ » çNøù ç ¸ ê Äú«íàîÃöß¤,ñ)AÏR
òÙ»!¸!©³ûÚã¢ñÖñÅ$_Å$ââÐööò £È £[¦Î¤ÅjÆÖñ)AÏ0,Ü)ò¦ ¦üÚã¢ñÖñÅ$ò¦ ¦ýYòYÅjÆÖÅ$ââÐõöò¦ ¦ö £Y¦Î £!¤ ê
þ ñ)AÏ0AÌäjÏ[jò ¦ ýYò.ÿpÅjÆ íüãAÅjÚóýR_Å""Ï0Üã<_"jÅjÐjÏ0Æ)AÏÿaR'ñ)[ãAÅj"ÙñÅ$òýYò ¦ ê ãAÅjÚ"
ñRñ)ÐRÆ¨ÌÎjÏÅjÐRÐpò¦»K ÅjÆ\ÅjÐRÐ3<à"a£[¦)jÌï&ÿ.ý°RÅÙï  "ýõjÏ0Æ)AÏ0RÞ[ÌäjÏ£ ê þ ñ)AÏ0AÌäjÏ£
R_Å!ýõâÏ0AÌäAÏÏ0Æ <3"a&jÌGï êì A£Y¦üíóÅjxî\<3"R Úã0ñ&ñÅ$£û© Ê £Y¦ ê Ä úÍ£» ç ¸
ÅjÆ¼£ ¦ » Ê ç ¸pÿüÅjÆ	ñAÏAÌäjÏ0Ùíàîöß¤ñ)AÏR,ò\»y Úã¢ñ	ñÅ$,Å$ââÐõöò £È £ ¦ ¤ÅjÆ	ñ)AÏR)
ò¦G» Úã0ñ¼ñÅ$[ò¦ ýYòÖÅjÆ¼Å$ââpÐgöò¦ö £[¦g £!¤ êÙë ã<N£÷Rñ)!ÐaîýõâÏAÌÎAÏÏÆ¼<3"a¼jÌ

ï ê

	
 !"$#%'&()!%+*-,./,01
þ ñ)óÐRÅjÞÚÅ$Þj,ñÅ$ã<jÏÏ"âüÆ"!ñ)[ã<"32xÚã<óÏÝ ÐRÅ$a æ ©°jÌñ)óãAÐRÅjRãAÅjÐüâÏjâüaaÅjÐ
ÐajÞRãYRÆ))j"Æ	íàîKÂ_ÄÅjÆRÆ54p)ÆKÅjñ)Y"AjÌ¨âÅjaÏ0Y¿76, 0ØüÁ»98;:=<?>À0Úã0ññÅ$6 æ ©ÍØ ê
@ ðYjÌGñ)Ùã<ðâpÐa<3R î&ÏÚÐRÚ"[ñYâÏ3ã<ÆÚ)Ï0[R aÞÚ)Ï#ßñÅ$RÆaÏ0ã<Ðaî\ípÅj"ÆK	ñ)
"ðNÜã<""Ï0Úã<BAj[Æ)54paR\jÌ¨<3"a_ÞCAjKR þ ñ)AjÏðûß ê 8 ê
D ) E,FGB ¯IHKJFLMONQPRJSH1TUNWVKX)JWNEYZ ¯[YC\KXOJ]N^;_QLMONETa`;bbNWcLdN5ZfeYgHKZhÜ	 ¢¡Ò £ji J]N3LgXOJUZfe "Ï0Ú Y k
`;ZRVlHKZbnmEY kÇoZg£#¤pYe?`;ZqNWcLdN5ZfeYgH;ZqH]kpLMON=VNk5`;XObrLsLMONWH;Jm ¿g ¢¡Á5tÍ[cT3bnXV;YZ+\uLMON9LdN5eLe9HSk
v N vxw NyJaeUMYzPYZ ÔLMON{PRJ]H3TNWV;XOJWN|JXOZfejYZxPOH;b}m;ZRH v Y`;b~LgY v NH;ZFLMONeYC$NH]kÙ¿g ¢¡Á5t
 ÚÏ®Æ)ãAÜaÙâÏ3ã<ÆÚ)Ï=ÌäjÏ¨ñ)'Ða<)Rã<jÞjÏ0Å$âñRãâÏ0ajÏ0aRåAÆYÆ)AÌgÅjÚÐa®ÐajÞRã'RíÅj"Æ#!ÅÏ0ÆÚã
a\"Yñ)ÐRÅj)ÞÚÅ$ÞjÄóÂÿxúñRã¢ñÈRÚÏ0ÈRÏÆÚãARíÐa_"NÂ'Ä³RN)Æ)A"AÏ0ðNRR"Rã'âüÐaî3)ðNRÅjÐ
Rð ê þ ñ)AÏ0ÈÅ$ÏÈñÏAx3RÆ,jÌ{2àÚ)"RjÄóÂ8ãAÅjÃÅj"ú=AÏ§#R[ñ)\ÐajÞRãAÅjÐãAÐRÚ)ÏNjÌÅ"A
jÌ[ÌÎjÏ0ð#ÚÐRÅ$	Åj <3"a jÌYÅÃÆ)AÌÎÅjÚÐaÈñ)AjÏ0îjÿRÈÅÃ""Ï0Üã<\"jÅjÐjÏ0Æ)AÏ&ÅËï& "ýõjÏ0Æ)AÏ0Ü)ÞÇÌÎjÏ
ÅjÃ<à"aÿGÅjÆÃR#ÅÌÎjÏ0ð#ÚÐRÅÅ¼ÐajÞÜãAÅjÐã<32xÚ)ã<\jÌÅ:"A!jÌÌÎjÏ0ð#ÚÐRÅ$ ê þ ñ)ÖÐÜÅj)ÞÚÅ$Þj
ÄóÂ³Ñ13  é  a8xÓ|<p8-"<?8 : <p8 : <Ç8-+:Õ(>_¤=R_Æ)54pÆ Åjñ)YAjÌo2àÚRxÚ)âÐR
 g¿ 3 	 ¢¡y £N W\Áúñ)AÏ# RÅ\AjÌÆ)AÌÎÅjÚÐaAÿ¡ >³RÅ&"AjÌÌäjÏ¢ðÙÚÐÜÅ$jÿÅjÆ³oZpg£!¤
ÜÅj <3"a jÌ¿g	 ¢¡Á¢ÿ
1$

/Cf$R
jIpG{E ¡j¢£~¤W¥p¤U¦F¤W§¨¤W©xªU«
I¬­fE£[®
¯O°²± ®³5´)µ]³3¶.·W¸C¹¶¢g¥?¤U¦'¤W§sªxºG»[¼q½K¾y¾5³y¿µÀo­OlÁW³ÃÂS³3¾5µ
Ä;°ÆÅÇ ³3·W·/¶f¹¶Èf³yµ]³yÁaÉx¸B¶¸B·]µW¸Ê¾y½KËBËCÌ¨½¨· ÇÍ ·]³yµ§jÎ	¹KÏ~¾5¹¶¾yË Ç ·a¸C¹¶·Ð¹KÏ¥p«
§ Î °nÑ § ÎÒ ¦Ó«
± ®Ô¶f¹Kµ/³5´)µ]³3¶·a¸C¹¶¢g¥?¤U¦'¤W§Îª¹KÁÕ¶f¹Kµ³5´Oµ]³3¶·W¸C¹¶%¢g¥p¤U¦F¤W§ª
ºG»[¼ÖÁa³ÃÂS³3¾5µ
Ào­O ± ®E¾5¹É|¿.½;ÁW³¢g§x¤W§ Î ¤W©¨ª Ñ µ]Á Ç ³?ºG»[¼ÁW³ÃÂ]³3¾5µ
Ào­O ½K¾y¾5³y¿µ
×)°²± ®ÙØg§¨¤W©¨Ú²ÛE¡ ÜºG»[¼½K¾y¾5³y¿µÀo­OlÁW³ÃÂS³3¾5µ
¹KµWÝf³yÁWÞ/¸Ê·]³ ° ÁW³ÃÂ]³3¾5µ
¼Õ
jIpG{E½;¿.¿.ËB¸C³3È¢gß ° àGá ¤yâyâyâ1¤ à.ãOä1å ¤W§sªU«
è ¡Ð êÏ¹KÁ/½KËÊË à Û'ë à á ¤yâyâyâ$¤ à ãì
± ®ÙØg§¨¤Wß~ÚÛÔ¡Ð æ½K¶ÈFØg§x¤Uç à ÚéÛE
ºG»Õ¼q{ºÕG/¼íµ]Á Ç ³[Ào­f"{ºÕG{¼íÏ½KËÊ·]³
¼Õ
jIpG{E¾5¹É¨¿.½;ÁW³¢g§¨¤W§Î7¤W©|ªU«
ËC³yµ{© Í ³éµWÝ³é¹KÁaÈf³yÁa¸B¶ Å|î5ï © î á © ðyðyð© î ã «
®[Ö¸ °nÑæ¯ º²l¶pñ
± ®Ô¶f¹KµÕ½;¿¿.ËB¸C³3È%¢ îò ¤W§ª½K¶Èó½;¿¿.ËÊ¸C³3È¢ îò ¤W§ Î ª¨ºG»Õ¼q{ºÕG/¼ÖÏg½KËB·]³K«
± ®Ô½;¿¿RËB¸C³3È¢ îò ¤W§ª½K¶.ÈQ¶f¹Kµ/½;¿¿.ËÊ¸C³3È¢ îò ¤W§ÎÊª¨ºG»Õ¼q{ºÕG/¼Öµ]Á Ç ³
[¼
{ºÕI{¼íµ]Á Ç ³
¼Õ
ô¸ ÅÇ Áa³éõ °[ö Èf³3¾y¸B·W¸C¹¶(¿.ÁW¹)¾5³3È Ç ÁW³Ï¹KÁÕ[ é¡
÷ Ø Ä ¤W¥?¤U¦F¤W§¨¤W©ñÚÞ/Ý³yÁW³j¥ø¸Ê·{½|·]³yµ{¹KÏ~Èf³yÏg½ Ç ËCµW·yù.¦ ú"ûÙ¸B·½¨·]³yµ/¹KÏ%Ï¹KÁaÉ Ç ËB½;³Kù§¸B·½¨·]³yµ{¹KÏ
Ï¹KÁaÉ Ç ËB½;³Kù)©ê¸B·[½j·]µ]Áa¸B¾5µ[µ]¹KµW½KË¹KÁaÈf³yÁ¹¶¨¥?ù+½K¶È¨©æ¸B·~¶¹Kµ½xØg¥?¤U¦æÚU¤W©jü7¹KÁaÈ³yÁa¸B¶ Å Ï¹KÁoýR¢g§sªUù
½K¶.È
÷ Ø × ¤W¥?¤U¦F¤W§¨¤aþGÚ/Þ/Ýf³yÁW³xØg§x¤aþ	ÚÛE¡Ð ÿ
	
æ[¼ññºý "!$#%'&"(9I¼)ý=ý*(;ý*+ &,$-.ý/0$&1132(#54;ý*(6-'87#9&1:-;=<

 (?(A@ BDC{Ý³ËB½K¶ ÅÇ ½ Å ³ ¡ê¸B·½K¾y¾5³y¿µ]³3È Í Ì?½ ¶f¹¶È³yµ]³yÁaÉ¨¸B¶¸Ê·]µW¸B¾EC Ç Áa¸B¶ Å É¨½K¾UÝ¸B¶f³ Å ¸FK³3¶=½K·µWÝf³
>
¿ÁW¹O¾5³3È Ç Áa³¸Ê¶Qôo¸ ÅÇ ÁW³éõfÿGC{Ý³é³5´)³3¾ Ç µW¸B¹¶·{¹KÏoµWÝf³j¿Áa¹)¾5³3È Ç ÁW³éÝ½?FK³½¨¿¹ËBÌ)¶f¹Éx¸B½KË	ËC³3¶ Å Wµ ÝGÿ
H
I'J K/LMNO
:P ºRQ;S(-32*# -T5ý/&U(@V&:QW2*A(+!$#%$-X(A@.&,$&1ý+ZY[Q &:Q ;7\@$(6S-.#]7^!$#(;ý+6.&"(Z76##
2*_1@?$ `a_bc&,5ý1(;ýZ(A@Z7	c8@$76#]&D&:Q(S40=ºSý+	 "!$#%Z&"(?¼xdýlý*(;ý*+ &,$-.ý/0$&11
2(#e;4 ý*(-.87#9&1-T?<
f=f=f

gh*iGjckml6n*o]p+q	h*r.suto%h*to]po%v=lxwzyWlcr_{|k_p^}~h/o%
uEu$, 6_x=1^SS
  ¡?_¢x¢£¡ ¡ ¤¥;0¢%_% 6¦0¦§;_¨/_¡ ©ª6«[$x¢ ¦%x¢>6«9
  ¡?_¢x¢£¡ ¡ ¤¥;0¢%_% 6¦0¦§;¤%$U6_6¦6¤£¡ ¤3¬ªx¢­^
®¯±² ° ¬´³µ3u¶·¤_¡¹¸¡?$ 
®¯»º1¼_S	_©¾½­	¿xÀ>ÁÂuÃ\Ä
Å ¶WªºAÆ_^S_©Ç½­	_¬;À3Á
° ÂGÃDÄ
Å ¶Wªº8È¿¿_©¾½­	À\Á	
° ÂuÃ\Ä
³µ3u¶É6 $¡ Ê
GË[Ì¤_¡¹¸¡?$
u¶3
Í[   ¤_¡ÎÏGÐÑ£¡? %_%x¢ÒÊ¤_$¡?£¤_¡\«:6¤Ê¤6¤S_Ó ¡?£Ò 6_x¤_¡?6x¢%¢  
 ÔÕ?ÕAÖ ×uØÙ¡\Ú+¡?__x¢Û0G6¢Ü¡ ¤_¡?£¨§TVØÝ¤0¢   ¥;6SÙ%¢¡W£¡?_$¤¨O¡?£T¨+§_Ù¡WÊ¤_$¡?£¤¡3%¢ÛÍÝ   ¤_¡
>
ÎÞEØÙ¡'Ø~¤%¢   ¥;6Ù0¢¡'/¡?36¢ß6¤S6 ¦¡V«:6¤\_Ù¡¦%6¢      ¡.ÂGÃDÄWÞOÍ[¤W_Ù¡.¥;6Ù0¢¡   ¡?_¡?D
 6¢£0£¡;¡$à¡?¢_x¢áÝâ*1©á½ÑW6«º1^SÑÀD6¢£	^¤%$6_6¦u6¤S£¡ ¤V¬ãx¢ä_ÙV¡$à¡?¢/£
_Ù¡Z¤_¡?¦0_x¢åÞæØÙ¡?¢å_Ù¡­¥;6Ù0¢¡Zç6¡ ¤]è/¡?._Ù/éÝâ*1©a½Ñ'%%¢å«16$T6¢¡$à¡?¢_%x¢Ç:_Ù¡
è/¤_$x¢_¦%__x¢6«ê_Ù¡T6¤6 ¦¡Û«6¤.ÂGÃDÄSëÝ_ÙV¬ì0éº1^SÑÀS\"6¤£¡ ¤0¢   «:6¤zÝâO1©á½Ñ
:_Ù¡T_¡?$x¢£	$x¢_/¦__x¢*SëR6¢/£_Ù¾ÁÑ
° Ýâ*1©Ñ½^Ñ.:_Ù¡T_Ù¤£ß$x¢_/¦__x¢Þ5éí¹«u6¦%¦[_Ù¡?¡
ç6¡ ¤]è _x¢;_/ $¡ ¡?£ëu_Ù¡Ø~¤%¢   ¥;6Ù/%¢¡­6 $¡ Ê_ Þ»î¡? 6¡_Ù¡   ¡?_¡?T6«W©ä6¢£ï¬ä¤_¡
¢x¢£¡ ¡ ¤¥;%¢0_%ë_Ù¡V¥T6Ù%¢¡6 $¡ Ê_WÜUÙ¡?¢¡ ç6¡ ¤W_Ù¡ ¤_¡'%6¢^¡$à¡?¢/_x¢­_Ù/3$x¢+_6%¢\6¢£
Ù6^º1SÑÀS\"6¤£¡ ¤S%¢   Þ
ØÙ¡9x¢¦§WÊ/¤__6«_Ù¡ðÊ/¤_$¡?£/¤_¡9_ÙR£U¢6¤/¢D%¢D$x¢_6¢+R_%¥;¡G¤_¡ð_Ù¡u¢x¢£¡ ¡ ¤¥T%¢%_0
  ¡?_%¢   6«>_Ù¡;¡ ©Të   ¡?_%¢   6«êZ¤%$D6_6¦G6¤£¡ ¤¬Të~6¢£ç6¡ ¤S«§%¢   _Ù%D¡$à¡?¢£/DÞ
î¡? 6¡Z_Ù¡Ò_Ó ¡?'6«U©X6¢£å¬ì¤_¡ÒÊx¦%§¢x¥T%6¦G%¢·º1^SáÀSë9_Ù¡Ò¢¥V¨O¡ ¤V6«U_¡ Ê/.¢¡ ¡?£¡?£
ô
  ¡?__Ù¡?¥ñ%>ÊOx¦§¢x¥;06¦0¢	º1SÑÀSÞðò9¡ ¤è* _x¢Z6«[ ² ¬)_ó6¡?UÊOx¦§¢x¥;06¦*_0¥¡6Þ
õ¡   ç6¡6¢ÊÊO¡ ¤Ý6¢£\¦mÜu¡ ¤G¨x/¢£«:6¤9_Ù¡ê¦ _x¢.6«/_Ù¡£¡? %_x¢VÊ¤_6¨*¦¡?¥Ñ%¢'_Ù¡>Êx¦%§c
¢x¥;06¦Ù¡ ¤¤SÙ+§6Þ>î¡? 6_¡'ÂuÃ\ÄÇ%ØÝ¤%¢   ¤¡?£ ¨/¦%¡W­Ä>ÃÑ%¢­¢x¢£¡ ¡ ¤¥;0¢%_%WÊOx¦§¢x¥;%6¦
_%¥¡6ë_Ù¡E«x¦0¦=ÜU0¢   ¦¡?¥;¥;%ê0¥;¥¡?£%¡6Þ
ö÷øøù	úûüý³Rþÿâ	+ÿDG¶Û

â 
î§ZØÙ¡ 6¤_¡?¥ ÎÞ.Ü¡   ¡ U6¢ÊÊO¡ ¤¨Ox¢/£Û«:6¤U_Ù¡E¦ _%x¢Z6«[_Ù¡£¡? %x¢ÒÊ¤_6¨/¦%¡?¥ % ¢Ò_Ù¡
ÊOx¦§¢x¥;%6¦+Ù¡ ¤¤SÙc§6Þ9ØÙ¡¤¡?_¦[%[%¥;¥¡?£/%¡u¨§_Ù¡>£¡$è*¢_x¢V6«/_Ù¡ÊOx¦§¢x¥;06¦+Ù%¡ ¤ ¤Ù+§6Þ

 ³Rþÿ"*! ÔÕ$#%%ÿ%& ÕAÖ'[þÿ)(:þÿ$Ô*WÖ$Õ6Ô+&,-./#ÿ%Õâ("Õ012!Ôÿ8Ö ÿ ÔSÔ_ÿ43)5Éÿ46$(,ÿ$â7
1Õ6â.ÕAÖ,
 ÷M ÷øNúOû ý
3cÿ8Ö%1-.(8(:þÿ_ÕÔ79:
;<
:â:=> ?
Ã3¡$àGÜu¡UÙ=Üï_Ù/ð_Ù¡£¡? %x¢.Ê¤_6¨/¦%¡?¥ %A@< ? ,Ù¤£ë6_Ù¡ ¤_¡ ¨§'6¨/_6%¢%¢   D¦mÜu¡ ¤u¨Ox¢£'x¢
_Ù¡¦ _%x¢%¢D_Ù¡GÊOx¦§¢x¥;%6¦6Ù%¡ ¤¤Ù+§6Þ[ØÙ%¤¡?_¦%R¨/6¡?£x¢VU_Ù¡ 6¤_¡?¥d¨+§<D
B ¤_¡?¢+¡?¦*AÆDC6C Èx
_Ù.%£¡?¢+_]è/¡?@< ?E ,$x¥;Ê/¦¡ ¡Ê¤_6¨/¦¡?¥TE«:6¤GFIý
H ÆÞzØÙ¡T_Ù¡ 6¤_¡?¥ $x¢$¡ ¤S¢.¦¡$à0$   ¤Ê/Ù% 6¦0¦§
¥;Mà%¥;6¦Oç6¦%_x¢/ê6«ÝÚ6¢+_]è/¡?£Zîx¦¡?6¢­«:6¤¥'¦%¡6ë6¢£Z«:6¤_Ù¡Ê¤_¡$èà0J$^
K %6«x¦%¦%=ÜU Þ
 ÷M ÷øNúOûMLNPORQ/m ÷-SUT=÷-VXWYLZZ[]\É³Rþÿ^!*ÔÕ$#%%ÿ%& ÕÖ,_SÕ1&`!Z(a
âbc
2dÿ$âe_SÕ1&`!Õâÿ â(\ÕAÖ^fhg*

@  ?jiR_Õ1&`!Z%ÿ)(,ÿ%k8'[þÿ Ôÿlf g 
3cÿamGâÿ43:jðÖ Õ12]Õ1')
n	njo

p"qrsutZrwvr
xzy|{~}`|j|~y~|U}}w-~~`~$y
wR4%8`	11^%+ ,¡-.¢¤£ ¥h¦)§R¥/¨7©«ª¬-%48¥­¯®°"1±$²	²)R)³	®M´a®al)1"1µ¯¶´a¡	·U
RllD1 41h³117®a$²)%°¸´2¬´º¹+47°X·-1Z»j°G´¼±c³j1½¡w´a®M1eº¾ ­ §)¿)¿)¿	§R¾ ­ÀÂÁ
Ã<Ä RÅ Ä )>ÆÇ4È®a¹+4ÉR+·¬$®M¹½Ê0 *DÈ®2 *1¥e¦ÌËÎÍ	Ï-§DÐjÑ À ´2¬-´8°%´a¦ ®°Ò>%°

Ó ¥ ¦ Ô ¥ ¨Õ ¢*£ ¥ ¦ §R¥ ¨ ©]Ö×Ð	Ø+¿
ÙÌÚ ÌÛÜÝ;ÝÜ	Þ"ß;àÝDá*á*^Å]Üß 4¯Ü Ä >%ÜwD%4ß Ü¤â])XÞ>)Däã Ä 4ß.åDæ¤ç8ÜÜÝD¤ÛÜèá Ä Ý 1"Þ"ß Ú
 Ä wßé)èÝAã Ä $4ß.åZ)è Ú äÜ Ä R)èáGÜR,ã Ä $4ßå)èwæê Ú :ÝÜàß )Ý>%ÜwRDã Ä Dw%äè4DÝ 14ßÜêß 
Åwè4ÜÅ]Ü4ß 4ßÜwÝ]ÝÜàß 1ë
ì>íîzîeïhðÂñaòZòóÆÇ)´¥ô²`^°D)´~¹+1´¼1®2w®2ÉG4È$$¹D´a½Ê1U`¾õ1U»lö«¾%Ì)³1)+Êº¾/ËÎÍD¾ ¦¦ §)¿)¿)¿D§R¾ À¦ Ñ Á
Æ|D´¯¥ ¦ Öø÷2¾ù ¦ §)¿)¿)¿	§R¾ûù ¦À ú ª¬%4<¾Zù­ ¦ ÖüÐ:® l¾ ­¦ Ëh¥ý1Z»¤¾ù­ ¦ Ö×Ïe´2¬%7ª¯®;°D ÁÎþ ¬-%/¥ ¦ °)´a®;°2Ò>7°
Ô ¥õ¨ Õ ¢¤£ ¥h¦D§R¥õ¦ ¨%©2Ø<® ¸1Z»±wÊc® º¥ô
ÿ Ö ¢¤£ ¥h¦D§R¥/¨7© Á

YRD`4 Ä áG¸ Ú 1`¥ ¦ 414ß åZD Ô ¥ ¨ Õ ¢*£ ¥ ¦ §R¥ ¨ ©2Ø+ë`Dw%ÛÜèl Ú  Ú Üß %ÜÛ¯Rè Ä  Ú éjÝ Ä DÌÛ2Üè
¾~¦¦ §)¿)¿)¿u§R¾~À¤
¦ ß æwß )1RDæcâ	*¥e¦Yæä	c Ú Üß %^ÜÛ~Rè Ä  Ú é1Ý Ä D>Û2ÜèY¾Z¨¦ §)¿)¿)¿	§R¾UÀ¨ 
¢*£ ¥e¦D§R¥/¨7©Âß >Rè Ä ë
`Ü	Þ Ý)
â]0á*ÜæDÝ" Ä  Ú  Ú 1 ÿ Ö ¥eë"D% 44ßà* Ú áGRè Ä  Ú é1Ý Ä D
RÜb¾~¦¦ §)¿)¿)¿	§R¾|À¦ ,¥h¦)
ë "Üu
Þ  ÿ Ö ¢*£ ¥e¦D§R¥/¨7©
ûwæêâh Ú ±æ%åZwß 4ßÜÎÜÛ`Ý Üàß )Ý8%ÜRDã Ä Dw%
¥ôÿ Ö ¢*£ ¥ ¦ §R¥ ¨ ©¼ë
l4 Ä á*Ì Ú 1A¥ôÿ Ö ¢*£ ¥ ¦ §R¥ ¨ ©¼
ë `Dw%"Û2Üè8Ý ÝáGÜæwDÝ  ý Ä  Ú  Ú 1  ÿ ÖP¥ w
æ ý4ßàw
	 *Rè Ä  Ú  é1Ý Ä DûRÜ¾U¨¦ §)¿)¿)¿D§R¾ZÀ¨ 
 ÿ Ö ¢¤£ ¥h¦D§R¥õ¨7©¼ëAç cæ%åZwß4ß ÜGÜÛ~ã Ä $4ß.åZDæ¤ç>ÜÜÝ DcÛ2Üèá Ä 
Ý 1
ÛÜèA¥ ¦ wæG	,¥ ¨  Ú "ÛÜèá Ä Ý ¢¤£ ¥ ¦ §R¥ ¨ ©Uß ¯Rè Ä 
$ Ú 1ûß 
$¥ ¦ 414ß RåD Ô ¥ ¨ Õ ¢*£ ¥ ¦ §R¥ ¨ ©2Ø+ë




ÙÌÚ 8ÅwèÜÜÛwÜÛZ Ú º-Ý Dá*á* Ä RD Ú Y4áGºRè4Ý 14ßÜÜÛZã Ä 4ß.åDæ,ç>ÜÜÝD,Û2Üèá Ä Ý 1>RÜ
æ)Ûa Ä Ýº Ú )Üè+ßD"!lÜR4ÝÜâ#" "Åwè4ÜÜÛÇÜÛ$&% ¨ XÚ 1èæwDºÜÛ¯) Ä 4ßÜ Ä ºèDRÜwß à*ß;('ÌDßR)è)" "æ)Ûa Ä Ý
ÝÜàß  Õ ^ÜR4ÝÜâ#
ÇÐ+**Ø+ë
ì>íîzîeïhðÂñaò ,.-¯ "·U¡-´a®2ÉGlÉ®2³1):¹+1 `·-1U)´¯¯¥ ¦ ®*xzy~{~}2"| j|~y~|U}}wÎ|~`~$y
®°Y·-1½ÊjU1 ,®a1A´a®2 ¤ *1wÊ1¶U44»1¡w¹)®¼²% ,´¼:´2¬-Ì·U$²))  ´X%°7´a®2Éäª¬-)´2¬%Gl%17 ,¡-.0²+%1É1°
´¼:12 /¤¶;·Z4aD%7R» 0 È´X%w°+®M1°ä»a)1¡-½´>´2¬-4+Êl%°7´a7®M¹D´>´¼´¼1«»$)1° / Á
YRD 32Î`%ÜwRRè Ä %8æw)Û2 Ä Ý ¯ Ú )Ü4è 5Ö 7÷ 6/9§ 8 ú æ¤æ%åZwÌ¸RRèß;%¯Å1è44ß ÝÜè+æ)3
è : Ü
 6 RÜ
 Ú 1« Ú & ; Ú %ÜáGÅ]ÜD|ÜÛ¥ ¦ ß 8Ð8ßÛwæ¸Üw<Ý <ß=Û 5 ÿ !Ö >0 ¾ ?¦ ë ÙÌÚ Aé1Ý Ä 8ÜÛwÌàßéD%ÜáGÅ]ÜDÇÜÛ
¥ ¦ ß :xzy~{~}`|A
 @|~y~|U};-}wê-~~`~yß >æ%åZDæcÜw<Ý *ß Û Ó ¥ ¦ Ô ¥ ¨ Õ ¢*£ ¥ ¦ §R¥ ¨ ©2ØAß;8414ß;å 
1âÝ 
4Ü4 Ä áGYß¯ß )Cë B~) D¸âUºlÅwè4ÜÅ]Ü4ß 4ßÜwÝéj1èß;1âÝ> Ú 1¯ß ¯Ü¯ß cÍD¾~¦¦ §)¿)¿)¿D§R¾|À¦ §R¾U¨¦ §)¿)¿)¿	§R¾ZÀ¨ Ñë
El%åZ
6
Ö F ¾ ¾ ¦ ¦¦ § ö«ö«¾ ¾ ¦ ¦¦ §)¿)¿)¿u§ ¾ ¾ À¦ À¦ § ö«ö«¾ ¾ À¦ À¦ § ¢*£ ¥ ¦ §RD ¥ ¨ ©|GD H §"æ
¦
¦
¦
¨
*
¢
£
¥
R
§
¥
©~ D
¢¤£ ¥ ¦ §R¥ ¨ ©~ D
:
Ö F
6NM F
D
HJILK
D
HPO
¾ ­¦ § ¾ S ¦ ÐVWYX3Z\[]Wµ
FR
Q
H
¾ ­¦ ¾ S
¦ TVU
U
¾~¦¦ §)¿)¿)¿D§ ¾|À¦ UU F ö«¾|¦¦ §)¿)¿)¿	§ ö«¾|À¦ ¿
F
Q
¾ À¦ U H\I ö«¾ ¦¦
ö«¾ À¦ H
¾ ¦¦
^)^`_

a&bdc3ef`ghdikj	lmbdnpoqirbdqikjirs)gGtvu1gn4wx=f4jyzb|{ir}~

#!9r49G4=+==&]3=14r+z4! <4=4v¡7¢9£G¤
=4149r¥4|9¦4!rr+9r¨§=4§44rG=©44rzª¬« ­¯®+¢­°²±³=¬4=
´G=9 +(r§G<Gµ¬r|4rµ]
¶C<94&·&´4`·4=+9N+=4rGN¸¹¡7º¢9£G¤4=G4r»49!¼­m®4 =½4=
­ ® 94r¿¾+Àd­ °Á ª¬« ­ ® ¢­ ° ±ÂNÃ1rÄ3Å¯ÆÇ¢ÈÈÈ)¢ÉCÊG³ËdÌ Á ­ ® Â¥Í¦Ç´<ÎvÏ Ì ® Åº¸ Á 4=´ =4<G
Ë Ì +<+44Ä4Y+<+µ¬+´YÉÐ4 §rÑÂP¸Ò|Y+=4<GÓ¡7º¢9£G¤=Ó»ÔÅ¦¸
Õ&+ =]7 =<4rºÖ4©9µ¬³d¸rG=4r+	×+=p§=§ Á ª¬« ­¯®+¢­°±ØÙ»ÚÛ»d¢4¸©Â+ =
4VG=rÜ7 =<·=4´» 9r4´G=r 4<GNrª« ­ ® ¢­ ° ±ØÑ»ÚÛ»d3×+=©ª¬« ­ ® ¢­ ° ±PÅ(¸Ý
4=´r+³zª¬« ­m®+¢­v°²±3r!N<ÞGrG=4+ß	 +¬4=pGr =4<G&Þ+94¼Þ(7 =<4!¸
Õ&+ =»©+ ¥rª¬« ­ ® ¢­ ° ±³G­áà ÍÔª« ­ ® ¢­ ° ±¥­âÍã¸ä¨Æ+Ï ® ¢½åæÏ ® ¢ÈÈÈ)¢Ï ® ¢½åæÏ ® ÊG
ç
ç
®
®
Õ&vP+µ¬µ¬(èrÇÇ­ ® ³P¾|+éË Ì¿Á ­ ® Â1ÍÇ<3Ï Ì ® Å\­ê=Ë Ì¿Á ­ ® ÂÍìëN44·r³#44r¾+
Àd­v° Á ª« ­m®+¢­v°±Â½
=+J·&N4`·4=pÃ]+½í­ ® 4=]44r¿¾d+îÀd­ °Á ª¬« ­ ® ¢­ ° ±Â½³44Nrp\+=9<G
¸êN¡7¢9£G¤N9 =9ï4=º»ðÅ.¸ñ=òËÌ Á ­m®²Â¯ÍóÇmkÎ¦Ï#Ì ® Åô¸¬ôõ49 =µ]4=­m®º44r¾+
Àd­ °Á ª« ­ ® ¢­ ° ±Â½#p­öÍâÆ+Ï Ì ® à ËÌ Á ­ ® ÂpÍÒÇ¢+Çv÷ðÄ]÷ðÉCÊ!øJÆÛåCÏ Ì ® à ËÌ Á ­ ® Â©Íùë¢+Çé÷AÄ]÷úÉCÊG
ûür½<ÞG4·9(ý9<4=¸úrº+=9<G(¡7¢9£G¤½Õ&+ =4¨4î+=9<Gº¸ðr
G=4¼+³d§=§ Á ª¬« ­ ® ¢­ ° ±Øþ»ÚÛ»d¢4¸©Â½Õ+ pª« ­ ® ¢­ ° ±ØÑ»ÚÛ»r4=´!Ðÿ<+1 <rN³r
¨Ð§=444+
 N+=4rG=§=§rª¬« ­ ® ¢­ ° ±ØÙ»ÚÛ»
=G =	4§4V4éVÐ§=444+
+=4<G r4<rÞ9§d=rr<òµ¬Ûrµ¬­m®+³
=íýrNý99Ó=r]¼p	\4(G=½ =4<GíV¬³&·9N4º7 =<4Ø Ï ® Ú`Ï ® ¢ÈÈÈ)¢ØÙÏ ® Ú`Ï ®
ç
ç
®
®
4]9=4+épØÙÏ#Ì ® Ú`Ï#Ì ® ØÙÏ#® Ú`ÏP® ·+ýV
Ä ©441ËÌ Á ­m®²ÂÍÇpV4]µ¬Û¼µ¬æ­m®
44r4ÃrÞîÀd­

° Á ª« ­

® ¢­





° ±ÂkÎvÏ Ì ® +<GÞG¬4=¨VÐ§=9Ã49+

+=4<G(¡7¢9£G¤½



 4r(4=#+µ¬µ¬JèrÇ
	m=|4+G9 =+ rò4(§=½<9<4<+ò7 =<]<ÞG¼]	

Õ&4·¨´Õ=î×Grr =#+ =4G=9 =4rGîrz+îG©=rÞG+P§9<9< 
7 =<´4¨+Gµ]+©§=§rrd<pG=<Ãpº =µî´<)·&¨§9<9< v= =r4¨=)ý+
§=§¼<+ ³=¬rp4=++34G<ÞG¼¥´·& ]r 4rrÞ½§=r&§=9r9<4<+p7 =<
<ÞGr
 ã=rr+4rÞºà 
Í J&½r4½9&¹r&=<ÞG&r4=§G<Gµ¬rd=<9½9	]4=
 4<G 4+G=¼Þ¬rN =§9<9<4r+7 =<<ÞG¼³=+4rÞà 
Í Y
 =¯à 
Í  ¼G¨<ý+#r)·&+

 !"$#%'&)(+*-,/.021'354/6798:8<;=1,/.?>@1BADC Í¡7º¢?E¦¤GF AB8H.B>HIJ8K8@,L8@4M7,/.N021O.GA
V F 8<;=1WR.X,2YO71OTZ,N3[8\1BAB8H><P)]^C à Í_ V >`ACa bMc\;4/.N0Ld


 F 4MPR0S35,M.BTU6=79421
,MP Q

e X. ,
,N3Of õr©§=9<+µ¬vr C_a b 4í§G<Gµ¬r¨4rµ]íµ¬	ÐGÓ4+= =<d<¯hgji-kl`monm$pLq
r n-i-stulwv=l`xyhv=z-{-mon-|)i³P·r9¯	¯P+µ¬µ¬vèrÇ
	¼¨§G<Gµ¬r¥4rµ]µ	ÐGÜ4+= =<d<]
G §4<+µN

z+4rÞpà 
Í  z½r#4	99#ãrPr C_a b æ¥§=9	4=r 7z¼#+¨G¨Gµ]§d 4rÞ
4¨ =rß !§=444++=4<G=§ºN§#³+½4§9µr=rÞ©·4=44¨¼
+=4<G¬¼]·=r½pG4= =r4¥r¥§=§dr<+pr¬=<4<Gp´4G47 =<4·r9]·&=)ý
<4+=ÜGµ¬µ<+(

}  "j"~#%H&)+*,M.8<;=1WR.X,
IB10M6=.1>`P*>]/6=.X1 F 8<;=1I?4M7<71G/>`AB8<AM ¢?E¢ . 1O8H6=.BPA8H.B6 1> 34MPu0
,MP7> 38<;=1O.X1[>`A[4MP1L8\1OPA?>',MP ¸ ,N3 ¡7¢?E¦¤ AB6IO;8<;=4/8S4?WLWR7 Á' ¢4¸©Â 3O,M.[4M7<7  ÅQ dU;1WR.N,JI?10/6.1
.B6PA>`PPR,MPR0)1O8\15.BTU>`P >wA58H>HIW=,M7!Pu,MTU>H4M7:8H><T1]L>`/15P4MPQ e ,M.X4LI
71D3O,M.-[d
e .X,
,N3Of ¶C<94z4§=9+= =4ÞG =+4+!CdG=¼ =4<G= 4=C§G44<d<V44G=r =4rG=P
4Þ+94¼ÞV <4C4§G44r<¥+=4<G P Á ÜøE¦Â½r!+=9<G Á ¢?E¢4¸pÂ
JM 

¡¢£¤¦¥R£§L£

¨ª©«¬-­ª®Q¯©­°5±²´³Xµ³¦¶H·Q¸º¹»¸½¼_¾?¿
ÀLÁ °
³³Â³ ÁÃ ³X°OµoÄ+Å/Æ:Ç5ÅLÈ ÇOÉ Á ³²ÅLÈ ³ÊÅ/ÆË°OÆHÂ Á Éµ³²´È·Q¿
ÌÎÍºÏÐÄÒÑ¹»¿
ÓXÔÈÅ/µ°5±=µX°
È³²ÅLÈ¶H·Õ?¹ÕÌ¾Ö×­Øh©­Öo¯-©ØÙÆ<Â/Éw³X°/¿
ÔS«©Ú­Û^¬-×ÙÜÍÞÝß
ÕOàOàOà
ÕXÝáâJãä¼+®«
ÓXÔåHÌÕÜ:æäj
ç èÊéhÅ/ê[åHÌÕ?ë:ÝæÊäèÊéÚÆ<Å/ê³XÅLì^°Ýäí
Ýß
ÕOàOàOà¦ÕXÝá î
Ö×­Øh©­Öo¯-©ØÙÆ<Â/Éw³X°
­Ø®¿
©­Öo¯-©ØïµXê Á °
­ªØo®
ð:² ÀLÁ ê°ñÍòhóêÅ=Ç5°
Ë Á êG°µô ÂMµµX°
³Xµ³oÆ`Å/êµô°_°5±=²´³µX°
ÈÇ5°Å/Æ:°5±µX°
È ³²ÅLÈ³
¨ª©«¬-­ª®Q¯©­jË°
ÇO²´Ë°2¶H·¸º¹õ¸½ö¸Þ÷¾?¿
ÓXÔÈÅ/µ°5±²´³Xµ³J¶H·Õ?¹ÕGøL¾Ö×o­ªØù©­[Öo¯©ØïµXê Á °/¿
¼»ÍºÏõø¿
É°Oµú ß ÕOàOàOà
ÕGú á Ã °µô°Å/êGË°Oê?²´È À ö¿
ÔS«©ûoÍºÏýüÖD«ÿþ®«
ÓXÔ°5±²´³Xµ³J¶H·Õ?¹Õ¼ Ñí¦ú  î!¾Ö×o­ªØï¼ÐÍºÏ ¼ Ñí¦ú  î
­Ø®
ÌÎÍºÏÐ¹ ÑíO
ã  ÜÍ âJãä¼îL¿
ÓXÔ
Ì  Ïï÷ÙÖ×­Øh©­Öo¯-©ØïµXê Á °
­ 
	=­Ò©­Öo¯-©ØïÆHÂ/É´³X°
­ªØo®
ð² ÀLÁ ê°)Íò+Ë°
ÇO²´³G²ÅLÈóêÅ=Ç5°
Ë Á ê°Æ<Å/êµXÅ/µÂ/É-ó êG²Å/êG²µ²´°
³
µX°
³Xµ³²ÆÊµô²´³[²´³²wÈË°O°
Ëµô°ÇOÂ/³X°¶-°
ììÂº¾ïéo°5±=µµô°óêÅ=Ç5°
Ë Á ê°µX°
³µ³
ô

O
°

µ

ô
O
°

ê

Ë
O
°
<
Æ
Â

É

µ

³
´
²

È
¼+ÂMê°ÂMóó Éw²°
Ë²´ÈÒ¬
R¶@Ä Ñ¹+¾?¸Â/ÈËê°Oµ Á êGÈ³ÊµXê Á °²ÆKÂ/È ËÅLÈÉ²´ÆKµô²w³S²´³Êµô°
Á

ÇOÂ/³X°D°
ÇOÂ Á ³X°µô°[ó êÅÇ5°
Ë Á ê°ê°Oó ê°
³X°
È)µ³oÂÈÅLÈË°OµX°Oê?ì²´È²´³µ²´Ç Á ê?²´È À ìÂ/Ç?ô²´È°/¸uµô°[óêÅ=Ç5°
Ë Á ê°
ê°Oµ Á ê?È³UµXê Á °Q²´ÆÂ/ÈËÒÅLÈÉ²´Æ²µ²w³^óÅL³³² Ã É´°µXÅ ÀLÁ °
³³Ä ³XÅµôÂMµÿ¬
R¶@Ä+Ñ¹+¾²´³Â/ÈÒ°5±µX°
È³G²ÅLÈ
 ô°OêG°Uì°
ì Ã °OêG³Å/Æª¼ ²´³ÂMóó Éw²°
Ë o°
ÈÇ5° "!$#&%(')%5¶H·Õ?¹Õ¼_¾ê°Oµ Á ê?È³µXê Á °^²ÆÂ/ÈË ÅLÈ ÉQ²Æ µô°Oê°²´³
Â/È°5±=µX°
È³²ÅLÈQÌ»Å/ÆSåH·QÕ?¹+æÊ³ Á ÇGôµô ÂMµÂMóó É@¶'úJÕÌ¾SÆ`Å/êÂ/É´É-ú[äQ*
¼ 
ô°ó êÅÇ5°
Ë Á ê°ê Á È³U²´È ÈÅL,È +\Ë°OµX°OêGì²wÈ²´³Xµ²´ÇóÅLÉ ÈÅLì²´Â/Éªµ²´ì^°Â/ÈË Á ³°
³^Â/ÈÒ.
é -»Å/êGÂ/ÇOÉ°Æ<Å/ê
óêÅ/óÅL³²´µ²ÅLÈÂ/É³ÂMµ²´0³ /uÂ Ã ²´É´²1µ 2°
ÈÇ5°µô°_óêÅ Ã É´°
ì ³XÅLÉ 3/°
Ë Ã ²µ²´³S²´5
È 476 89
:

 ²µôÌZÏ ÄÙÑ¹

;=<?>@BA9>CEDGFIHD KÔ JL*MNOQPSR,T'U')V,"JSLW#XW%ZY»Ï Hå ·Õ?¹+æ\[,OQJSLW]^RTPN÷?[UPS_M^%('L`#Iab'U'XJ'XPST?JSLcMN(L`%ödJ
·5[U')V,fe_LcJNg(Th(]iJ0O'j(%W'#)lkmYn Ïp
o ÷q#&%#)rY 6 s$t
¨ LcJbJ0OQvxw° À ²3/°Â^Ë°
ÇO²´³²ÅLÈóêGÅÇ5°
Ë Á ê°oÆ<Å/êµô°_ó êÅ Ã É°
ìýµôÂMµSê Á È³Ê²´ÈË°OµX°OêGì²´È²´³Xµ²wÇóÅLÉ=ÈÅLì²´Â/É
u
µ²´ì^°Â/È Ë Á ³X°
³Â/È Å/êGÂ/ÇOÉ°Æ<Å/êÂó êÅ Ã É°
ì µôÂMµ Ã °
É´ÅLÈ À ³UµXÅy4 6 8 zô²´³^Ë°
ì^ÅLÈ ³XµXêGÂMµX°
³µô ÂMµµô°
óêÅ Ã É°
ì ²w³²wÈY 6 s *ô°UóêÅ=Ç5°
Ë Á êG°rMN\aQ#IMN²´³ À ²3/°
È²wÈð:² ÀLÁ ê°mÂ/È Ëµô°{4 6 8 Å/ê?Â/ÇOÉ°UóêÅ=Ç5°
Ë Á ê°
"!$#&%(')%²´³ À ² 3/°
ÈU²´Èð:² ÀLÁ ê°ÊñoÂ/ÈËU²µ³Ç5Å/êê°
Ç5µÈ°
³G³²´³K³µÂMµX°
Ë^²´È°
ììÂ´ü(|}ô°ÊÇ5Å/êê°
Ç5µÈ°
³G³KÅ/ÆRµô°
óêÅ=Ç5°
Ë Á êG
° MN\aQ#IMN²´³:Â/³Æ`ÅLÉwÉÅ  b³ 
°OµåH·QÕ?¹+æ Ã °S~
Â /RÈ²µX°ÊË°OÆHÂ Á Éµ:µô°OÅ/"ê   ²µ
ô 
· LÏþ¸LöùÂ_³µXêG²´Ç5µ
µXÅ/µÂ/ÉªÅ/êGË°OêÅLÈ·Q¸Â/ÈË÷ÿÂÆ<Å/êGì Á É´,Â òo³³ Á ì^°^µôÂMµåH·QÕ?¹+æôÂ/³[ÈÅ°5±=µX°
È³²ÅLÈ Q³ NÈµô²´³ÇOÂ/³X°
µô~
° / êG³µÊ³µÂMµX°
ì^°
È2µ²wÈµô°ó êÅÇ5°
Ë Á êm
° MN"ab#MNSê°Oµ Á êGÈ ³ªµXê Á °  ô²´ÇGô²´³ÊÇ5Å/êêG°
Ç5µ Ã °
ÇOÂ Á ³X°÷QµXê?² 3²wÂ/É´É 


°

É
L
Å
È
o
³
X
µ

Å
/
Â
w
É

É
5
°
=
±
X
µ


°

È

³

²
L
Å
È

³
/
Å
o
Æ
H
å

·
?
Õ
+
¹
æ
`
_òo³³ Á ì^°µô ÂMµUåH·Õ?¹+æôÂ/³ÂMµ_É°
Â/³XµÅLÈ°°5±µX°
È ³²ÅLÈ ~ô°
Ã
À



x_UN_l_^}h_},h$~N"}"  Bh¡,¢

£(¤¥"¥"¦b£(§"¨¦b©"©^ª¥"¤¤«f¬h¨­§"®¬h©=£Q¯©c¦rª¥"¤,£(¦Q¦b°©*±²³¬h¨B°´£(§"¬¤$¨³¤$¨³µm¶¸·N¹SºQ»Q»Q»ºc¼7½$¾¿f®¦ÀS¯Áh´}¦Â¤«f§"®}¦
ª¥"¤Ã¥`¯ÄÅÀS¯S¥\¬h¯S±BÁ¦ÆÇ¯S«)§c¦Q¥.§"®¦µX§"®¬§c¦Q¥\¯S§"¬¤$¨¬&©Z°}¦b¨}¤§c¦b°5±l²ÈÆ.É1¾uÊK¦Q§ËÌbºQ»Q»Q»bº\ËWÍr±G¦§"®}¦¤¥\°¦Q¥\¬h¨}Ã
Î ¾Ï¦b£Q¯´B©c¦ Î ¬h©u¯^©c§c¥\¬&£(§x§c¤§"¯ÁK¤¥\°}¦Q¥u¤$¨ÈÐ5Ñ}±²Ê?¦bÄ{Ä{¯{Ò¾ÔÓm§"®}¦Q¥"¦Õ¬h©x¦(Ö}¯£(§"Á²Â¤$¨}¦ Î× ª¥\¦Q«Ø¦Q¥"¥\¦b°Ù
¦(Ö,§c¦b¨©"¬¤$¨ÚÛ¤«ÝÜÐ5º`ÞÇß`¾
à`á_âã}äåæçáèNé`ê,çå)è,ë(ì`æØì`í «Ø¤¥Z¯Á&Áî{¶·N¹SºQ»Q»Q»ºcµc½$Ñ_¯SªBªBÁXïIËcðº"Ú^ñÝ¬«
¯¨°È¤$¨Á²Â¬«2ËcðÕ¶5Æ.É1¾
ò~ó9ìbë^ä\ó9ìbë µ7ôöõ íU÷ ¤øùÆ.úZôüûm¯¨°·N¹SºQ»Q»Q»9ºcµc½ôýû¾Uþ.¦b¨£(¦§"®}¦®N²ªG¤§"®}¦b©"¬h©Ý¬&©Ý§c¥\´}¦¾
à`á_âã}äåæØÿëä`ó9ìQë 
í  ¦{¯¨B¯Á² Q¦m§"®¦=ÀS¯Áh´}
Ì 
 ·Ë É ½9ñ.±l²
µ ¹
¦ *¥"¦Q§"´}¥\¨}¦b° ±²5¦(Ö}¬h©c§"©ïÐ º`Þº"Æ 	É 


£Q¯©c¦b©Q
¾ .©"©\´Äm¦Õ§"®¯S
§ Ýôù§c¥\´¦¾þZ¦b¨£(¦ÆZÉKôöÆ.É Ì ·ËWÉ ½$¾Ïx²r§"®}¦£(¤¥"¥"¦b£(§"¨}¦b©\©Ý¤«§"®¦Õª¥"¤,£(¦b°´}¥"¦
ë $æ&ì(å)ì Ñ§"®}¦Q¥\¦^¬&©.¯¨¦(Ö,§c¦b¨©"¬¤$¨
Ú ©"´£`®§"®¯S§¯SªªBÁIïIËº"
Ú ØñZ«Ø¤¥¯Á&Á
ËÂ¶³Æ.	É Ì 
 ·ËWÉ ½$
¾ .©"©\´Äm¦=§"®¯S§
Ú ¬h©m¨}¤§©"´B£\®z¯¨ ¦(Ö§c¦b¨©\¬¤$¨¾zþ.¦b¨£(¦5¯Sªª_ÁXïIËWÉ º"Ú  º"Ú=ñ`¾öÏ²y¬h¨°B´£(§"¬¤$¨q®l²lªG¤§"®}¦b©"¬&©m¯SªªBÁXïIËcðº"Ú^ñ
¬  ËcðÈ¶ Æ.	É Ì«Ø¤¥=¯ÁhÁ?î¶ö·N¹SºQ»Q»Q»ºcµ ü¹9½$¾ ÷ ¤ø ±G¦b£Q¯´©c¦¯SªBªBÁXïIËbº"Ú^ñ¬&ÄmªBÁh¬¦b©¯Sªª_ÁXïIËbº"
Ú Øñ~«Ø¤¥=¯ÁhÁ
Ë Î Ë É §"®}¦Q¥"¦¯S¥"¦È¨}¤³Ë   Î Ë É ©"´£\®y§"®B¯S§{¯SªªBÁXïIË  º"Úº"
Ú Øñ`¾yþZ¦b¨£(¦Ú £(¤$´Áh°q¨}¤§^±G¦ ÎÕ× ª¥"¦Q«)¦Q¥"¥"¦b°BÙKÑ
¯¨°r§"®}¦¯©"©"´ÄmªB§"¬¤$¨Â§"®¯S§Z¨}¤§f¯Sªª_ÁXïIËWÉ º"Ú^ñxøu¯©føf¥"¤$¨Ã}
¾ .©"©\´Äm¦§"®¯S
§ Ýôù«¯Áh©c¦
¾ ~©Ý§"®}¦Q¥\¦¬h©Ý¨}¤
¦(Ö,§c¦b¨©"¬¤$¨
Ú 7©"´£`®§"®¯S§Õ¯SªªBÁXïIËº"
Ú ØñZ«Ø¤¥Õ¯ÁhÁ2Ë ¶­Æ 	É Ì 
 ·Ë É ½$ÑK¯¨°¯SªªBÁXïIËº"Ú=ñ.«)¤¥¯ÁhÁ
ËÂ¶­Æ 	É Ì Ñ
¨}¤§f¯Sªª_ÁXïIËWÉ1º"Ú^ñ`¾ ÷ ¤ø Æ.É?ôöÆZ	É ÌQÑ¯¨°r§"®}¦¬&¨°´£(§"¬¤$¨Â®l²lªG¤§"®}¦b©"¬&©x¬&©u«)´Á _ÁhÁ¦b°¾
¿f®¬h
© _¨¬&©"®}¦b©x§"®}¦
¬h¨°B´£(§"¬¤$¨Âª¥"¤¤«1¾
÷ ¤ø Æ Í ¬h©m§"®¦ ©c¦Q§ ¤«~Ã¦b¨¦Q¥\¯S§"¬h¨}Ã³°¦Q«)¯´Áh§"©{¤«§"®}¦5´¨B¬ l´¦ ÎÕ× ª¥"¦Q«)¦Q¥"¥"¦b°BÙz¦(Ö,§c¦b¨©"¬¤$¨zÚ ¤«
ÜÐ º`Þùß`¾2¿f®¦Ý¦(Ö¦b£Q´}§"¬h¤$¨{¤«G§"®}¦Ýª¥"¤Ã¥`¯Ä £(¤$¨N§"¬&¨l´}¦b©¯S§§"®}¦ZÁ&¯©c§©c§"¯S§c¦bÄm¦b¨l§U¤«G§"®}¦fªB¥"¤£(¦b°B´}¥"¦¾7Ï²
¿f®}¦Q¤¥\¦bÄ ¾ÔÓÈÚô ! á ïXÞ 
 #· "$ % 'í &)( " ¶Æ.Í½9ñ`¾þ.¦b¨£(
¦ *­¶³Ú ¬«¯¨° ¤$¨Á²¬«Þ 
 #· "$ % +í &)( " ¶
Æ.Í,
½ $ô *¾
.

/ 0324065	5	78249;:=<?>A@CB çED.âNë?F(óSãHGå?å)è,ë\çEDWæIë(ìI ô ÜÐ º`ÞùßKJ ìWåLDWæäå?åXçåXóEG çED0âlëMD`ìN çSá ÐOJ óá_âF(çEDQP^ãHGóNë
1
*)J å)è,ëfê3DcçSR#Gë#P çTFåjëWìWåæ)áUI $ ô VÙ * æ&ìIXW Y[Zcä\çEP.ê3GhëQåjë\
]^cD çbçTF#_^` ¬¥"¦b£(§"Á²Â±²Â¿f®¦Q¤¥"¦bÄ{©ZÒ¾h¹a¯¨°5Ò¾h¹bÒ¾
.
b ¤¥.§"®}¦ª¥\¤±BÁ¦bÄ¤«2Äm¦bÄ± ¦Q¥`©"®¬ªr¤«
«Ø¤¥\Ä=´Áh¯S¦¯ÁhÁGª¥"¦Q«)¦Q¥"¥"¦b°r¦(Ö,§c¦b¨©"¬¤$¨B©Ý¤«2¯{°}¦Q«¯´Á§Ý§"®}¦Q¤¥"²
øZ¬§"®¤$´}§u§"®}¦Õ¥"¦b©c§c¥\¬&£(§"¬¤$¨r§c¤{§c¤§"¯ÁKªB¥\¬¤¥\¬§"¬h¦b©QÑl§"®¦Äm¦bÄ*±G¦Q¥\©\®¬ªr¬h¨ IXW Y ¯©føx¦bÁhÁG¯©Z¬§"©dc W Y × ®¯S¥\°B¨}¦b©"©
¥"¦bÄ{¯¬&¨r¤ª ¦b¨K¾

:=<feg/106hjik5	lSm)noQ9pn	qsr=9)q6o78tuo4n	tv735	59pwxlyao2[n	tuo4lz{/178yalAy
~©2¬h¨,,| ¦b£(§"¬¤$¨=Ó}¾'} ÑNøx¦u¯¨B¯Á²Q ¦u§"®}¦u£(¤$ÄmªBÁh¦(Ö,¬§1²*¤«_§"®}¦x£(¤$¨B©c¦al ´¦b¨£(¦Ý¥"¦bÁh¯S§"¬¤$¨=¤«§"®¦uÁh¦(Ö,¬h£(¤Ã¥`¯SªB®¬h£
ª¥\¬h¤¥\¬§"¬Q ¦b°r°}¦Q«¯´Á§ÝÁ¤Ã$¬h£*´¨°}¦Q¥Ý©c²,¨N§"¯£(§"¬&£¥"¦b©c§c¥`¬h£(§"¬¤$¨©Q¾
~3f3LC3))
¿f®}¦Ý¥\¦b©"´Á§"©2¤$¨{§"®}¦f±G¤$´¨°¯S¥\²*±G¦Q§jøx¦Q¦b¨{§c¥\¯£(§"¯S±_¬hÁh¬§1²^¯¨B°{¬h¨l§c¥\¯£(§"¯S±B¬hÁh¬h§j²*«)¤¥$ ô VÙ ø.¬§"®{©c§c¥\¬&£(§2§c¤§"¯Á
¤¥\°}¦Q¥`© N ¯S¥\¦ ©"´ÄÄ{¯S¥\¬Q ¦b°¬&¨¿¯S±_Á¦Ó}¾0 ¨³£Q¯©c¦b©øZ®}¦Q¥"¦ §"®}¦£(¤$Ämª_Á¦(Ö,¬h§j²¤«u§"®}¦ Áh¦(Ö,¬h£(¤Ã¥`¯SªB®¬h£
ª¥\¬h¤¥\¬§"¬Q ¦b°{°¦Q«)¯´Áh§Á¤Ã$¬h£~°¬G ¦Q¥\©U«Ø¥"¤$Äf
 ¦b¬h§c¦Q¥a ©u°}¦Q«)¯´BÁ§Á¤Ã$¬&£SÑl§"®}¦£(¤$ÄmªBÁh¦(Ö,¬§1²¬h©x©c¦Q§u¬h¨{±G¤$Áh°}«¯£(¦¾
¿
¯S±BÁ¦mÒ¬h¨B°¬h£Q¯S§c¦b©.øZ®}¦Q¥"¦=§"®}¦=ª¥"¤¤«)©.¤«U§"®}¦^£(¤$ÄmªBÁh¦(Ö,¬§1²¥"¦b©"´BÁ§"©.£Q¯¨±G¦=«Ø¤$´¨B°¾.¿f®¦=¬hÄ{ªB¯£(§.¤«
ª¥\¬h¤¥\¬§"¬¦b©*¤$¨­§"®¦Â£(¤$Ämª_Á¦(Ö,¬h§j²¤«.§"®}¦Â°¦b£Q¬h©"¬¤$¨­ª¥"¤±BÁh¦bÄ{©¬&©©c§c¥\¤$¨}Ã¦b©c§m¬h¨­§"®}¦ ªB¥"¦Q¥"¦a´¬h©"¬§c¦ × «)¥"¦Q¦
¨}¤¥\Ä¯ÁZ£QÁh¯©"©"¦b©Q¾  ®¦b¨z§"®}¦°}¦Q«¯´Á§{¥\´BÁ¦b©{¬h¨z§"®}¦b©c¦ £QÁ&¯©"©c¦b©Â¯S¥"¦5§c¤§"¯ÁhÁh²q¤¥\°}¦Q¥"¦b°ÑÝ§"®¦ ´¨¬fl´}¦
ª¥"¦Q«)¦Q¥"¥"¦b°¦(Ö§c¦b¨B©"¬¤$¨©x£Q¯¨Â± ¦.¦b¯©"¬hÁ²m«)¤$´¨°±l² ¯SªªBÁ²,¬h¨}ÃÕ§"®}¦°}¦Q«¯´Á§¥\´Á¦b©¬h¨{§"®}¦~Ã$¬À¦b¨Â¤¥\°}¦Q¥k¾ 
Äm¤¥"¦.£(¤$ÄmªBÁh¬h£Q¯S§c¦b°{ª ¤$Áh²¨}¤$Ä¬h¯Á§"¬hÄm¦f°}¦b£Q¬h©\¬¤$¨^ª¥"¤,£(¦b°´}¥"¦Ý¦(Ö}¬h©c§"©«Ø¤¥Uþ.¤¥\¨ °}¦Q«)¯´BÁ§"©7øZ¬§"®¹ × Á&¬§c¦Q¥\¯Á
¤H± c¦b£(§"¬À¦«¯£(§"©Èï¿f®}¦Q¤¥"¦bÄ Ò'¾ }u}$ñ`¾ b ¤¥=§"®¬h©£QÁ&¯©"©QÑ
§"®}¦¦(Ö}¬h©c§c¦b¨£(¦ ¤«Ý¯¨³¦(Ö,§c¦b¨©"¬¤$¨³§"®¯S§¯SªBªBÁh¬¦b©
¯ÈÃ$¬À¦b¨­©c¦Q§¤«Ý°}¦Q«¯´Á§"©Õ£Q¯¨³± ¦{°¦Q§c¦Q¥\Ä{¬h¨}¦b°³¬h¨ªG¤$Á²¨¤$Ä{¬h¯Á
§"¬hÄm¦Ñ
¯¨°§"®¬h©§c¤Ã¦Q§"®¦Q¥øZ¬h§"®§"®}¦

4

438v
#uuk8 #	u¡8¢d¢£ #u¤K¥ a
µ
³
Â
Ã
Ä
Æ
Ì
Ò
Ô

µ#Õ
uµ µ
µa³
µÂ
µÃ

Mv¦§¨ M©¥¢«ªx¬£ a­®#fu¡8¯ a¥­°±E¤ 
² u¤K­
³4´«¥¢¯ #¤Ku µQ´«¥¢¯ #¤Ku
¸¹»ºL¼S½¾À¿ ¸¹Áº	¼S½¾À¿ ¸¹Áº	¼S½¾À¿
¸¹»ºL¼S½¾À¿ ¸¹Áº	¼S½¾À¿ ¸¹Áº	¼S½¾À¿
¸¹»ºL¼S½¾À¿ ¸¹Áº	¼S½¾À¿ ¸¹Áº	¼S½¾À¿
¸¹»ºL¼S½¾À¿ ¸¹Áº	¼S½¾À¿ ¸¹Áº	¼S½¾À¿
¸¹»ºL¼S½¾À¿ ¸¹Áº	¼S½¾À¿ ¸¹Áº	¼S½¾À¿
¸¹»ºL¼S½¾À¿ ¸¹Áº	¼S½¾À¿ ÇdÈÉÊpË
¸¹»ºL¼S½¾À¿ ¸¹Áº	¼S½¾À¿ ¹)ÎkÏ·ÐÅÑ
¸¹»ºL¼S½¾À¿ ¸¹Áº	¼S½¾À¿ ¸¹Áº	¼S½¾À¿
¸¹»ºL¼S½¾À¿ ¸¹Áº	¼S½¾À¿ ¸¹Áº	¼S½¾À¿
¸¹»ºL¼S½¾À¿ ¸¹Áº	¼S½¾À¿ ¸¹Áº	¼S½¾À¿
¸¹»ºL¼S½¾À¿ ¸¹Áº	¼S½¾À¿ ¸¹Áº	¼S½¾À¿
ÇdÈÉÊpË ÇdÈÉÊpË ÇdÈÉÊpË
ÇdÈÉÊpË ÇdÈÉÊpË ¹)ÎkÏ·ÐÅÑ
ÇdÈÉÊpË ÇdÈÉÊpË ¹)ÎkÏ·ÐÅÑ

8¥L¶¯¡8­¨M¢¥v­H´·	¤ # 
¡8­8E¤Kª
8¥L¶¯¡8­¨M¢¥v­H´·	¤ # u¤K #¤ a
u¤K #¤K aO¡8­8E¤ª
8¥L¶¯¡8­¨M¢¥v­H´·	¤ # X­u¤K¦Åu
² u¤K­
­u¤K¦ÍuÁ¡8­8E¤ª
§8¤ #¤K aÓ¡8¥f¥¢¯ M´·	¤ # 
§8¤ #¤K aÓ¡8¥f¥¢¯ M´·	¤ # u¤K #¤ a
§8¤ #¤K aÓ¡8¥f¥¢¯ M´·	¤ # X¡8­8E¤ª
§8¤ #¤K aÓ¡8¥f¥¢¯ M´·	¤ # u¤K #¤ aO¡¨­8E¤ª
§8¤ #¤K aÓ¡8¥f¥¢¯ M´·	¤ # X­u¤K¦Åu
§8¤ #¤K aÓ¡8¥f¥¢¯ M´·	¤ # X­u¤K¦ÅuÁ¡¨­8E¤ª
§8¤ #¤K aÓ¡8¥f¥¢¯ M´·	¤ # §6vK¥¢¥Öu ­u¤K¦Íu»¡8­8E¤ª

× EØ¨  ÃÙÛÚ v¦§¨ M©¥¢«ªxuÜ¢£ Mv­8¯ aÓA¡ a­8M ¤ aE¢¥v­ÞÝ ßXàO¬¥¢£¢¯u¢u)§8¤K¥u¤á¥¢¥ a
¤ # #¤K a­8M 
² u¤K­ ³4´«¥¢¯ #¤áu
Ãâ
Ãâ
Ãâ
Ãâ
Ä â
Ä â
Ú ÄAã ³EÕ Ú ÄAã ³EÕ
Ú ÄAã µ Ò Ú ÄAã µ Ò
Ì1â
Ì1â
Ú ÄAã ³EÕ Ú ÄAã ³EÕ
µuµ â
µuµ â
â
µuµ
µuµ â
µuµ â
µuµ â
Ú ÄAã ³EÕ Ú ÄAã ³EÕ
×ÄAã ³Hµ ×ÄAã ³Hµ
â µa³ â µa³
â µa³ â µa³

#uuk8 #	u¡8¢d¢£ #u¤K¥ a
µ
³
Â
Ã
Ä
Æ
Ô

Ò

Ì

µ#Õ
uµ µ
µa³
µÂ
µÃ

8¥L¶¯¡8­¨M¢¥v­H´·	¤ # 
¡8­8E¤Kª
8¥L¶¯¡8­¨M¢¥v­H´·	¤ # u¤K #¤ a
u¤K #¤K aO¡8­8E¤ª
8¥L¶¯¡8­¨M¢¥v­H´·	¤ # X­u¤K¦Åu
² u¤K­
­u¤K¦ÍuÁ¡8­8E¤ª
§8¤ #¤K aÓ¡8¥f¥¢¯ M´·	¤ # 
§8¤ #¤K aÓ¡8¥f¥¢¯ M´·	¤ # u¤K #¤ a
§8¤ #¤K aÓ¡8¥f¥¢¯ M´·	¤ # X¡8­8E¤ª
§8¤ #¤K aÓ¡8¥f¥¢¯ M´·	¤ # u¤K #¤ aO¡¨­8E¤ª
§8¤ #¤K aÓ¡8¥f¥¢¯ M´·	¤ # X­u¤K¦Åu
§8¤ #¤K aÓ¡8¥f¥¢¯ M´·	¤ # X­u¤K¦ÅuÁ¡¨­8E¤ª
§8¤ #¤K aÓ¡8¥f¥¢¯ M´·	¤ # §6vK¥¢¥Öu ­u¤K¦Íu»¡8­8E¤ª

µQ´«¥¢¯ #¤Ku
Ãâ
Ãâ
Ä â
Ú ÄAã ³EÕ
Ú ÄAã µ Ò
×ÄAã ³u³
â Æ
µuµ â
µuµ â
µuµ â
Ú ÄAã ³EÕ
×ÄAã ³Hµ
â µa³
â µa³

× EØ3  Ä Ùä  #	 #¤ a­8M a¢¯Í¢£ #u¤K a¦Ådv­®¢£ 1Mv¦§¨ M©¥¢«ªxuÝ ßàO¬¥¢£¢¯u¢uÁ§8¤á¥u¤K¥¢¥ a
¯ ¢¯ #§A¬¥¯ xMv­8¯¢¯¤K¡¨M¢¥v­åu§8¤ #	 #¤¤ aj M©A¢¯ a­8K¥v­81æv¥Öu a­çu1¢£8 è§8¤KAM a8¡8¤ è¥­Þék¥æv¡¤  Ì ªH¥ a¨
Lu¯¢ a#¥K¥v­§8¤HM a8¡¤  ã
ê[ëaì

íÛî3ïðSñ4òuó3ôõö÷î3ø,ùúôî3úôõHôûòvüþýòSøÿ8ñõ î¨ô	

 "!# $%$&$('*)+,.-0/ 213)4/)5)$
6879;:9=<	>?>79A@CB9&D*EGFHB9#IFCEJ9&KL@M:*BN9&KPOPQ=>RS@M:PE?T+BN@MDUR: >JBNFCQ=>FHIVS9#WPB@CIV9&DXEY@CTIPBZF&[C9;B9&FCEJ@M:PR:P\(R:
] 9&R>J9AB&^_E8K9AT4FCOPVS>8VS@C\MRQ`>J@XWPBNRS@CBZRS>RSaA9&KbK9AT4FCOPVS>8VS@C\MRQ`c#RS>7b>J@C>FCVWPBZRS@CBNRS>RS9&E&d
egfhjiklhjmonqpsrtvuw&xzy|{Zw*}~AS}lN*3AHjS}w}HX}2~&}HN*3YP4xwLw4A}H	x#x5	wCZw~A
x5j}Cx
  24Zv gx5w=¡4£¢¥¤§¦©¨ ªq«Nª¬MZ­b¯®©	wAJwb¦­yo}HXª­+}±°JZ°	l5x4sH}C
² }H4}{ASwx5j}Cx³M%w0Cx3&~N~&	´+µH`¶G}C
 wN}M~=±*wAX{Zw=0J3·j}l0}Mx?w}l=x3Hww¸xw=4C¹
º	w?°{ASwA£`xwx45 »´¼¾½ ¿`Àz¦XAH3¼ÁÂ}C´¦byÃY°	HÄlH4}Hx45*w;X}HPÄHÅJHw`wC~&s{ASw
x ±x5w;°J{ASwAÆxw=x4+ »L¼Ç?½ ¿`ÉÈ ª.®©	wAJwg¼Ç Ê ªË}g°JZ°	l5x4sH}C ² }HZs}{ASw=#}HÌÍX}
x4s~&xÎxCx}H CwACÊ w4A}H	x5´5±¼ Ç ¹
Ï J&A¨ÎÐ9A>Ñ42Z­Î±2Iq9#FK9AT4FCOPVS>?>7P9A@CBÒCÓP¦yÔFgT5@CBND0OVF	ÓjFC:KÕLFgWPB@CWq@MERS>RS@M:FCV[lFHBZRFHIVS9
>7PFH>*KP@ 9&E:@C>*@jQAQAOBXR:¡42Z­0@CBL¦d·Ð9A>*ÌÃI9±FC: ÒÂEJ>JBNRQ=>WFHBN>RFCV³@CBNK9AB@M:·£¢Â¤§¦Ö×ÕP«HÕ¬
EOPQZ7Ø>7FH>g¦Ö×ÕP«HÕ"RE(>79LÌ`ÙVS9&FCEJ>g9&VS9&D9&: >Ad±ÚÊ9bQAVFCRDÛ>7FH>b4Z­*½ ¿`À´¦ÜRT³FC:KØ@M:PVÒÝRTÑ4Á¢
¤§¦Ö×ÕP«HÕ¬MZ­L½ ¿ ÉÈ Õd687RE´REgKPRSB9&Q=>VÒIq9&QAFCOPE9*>79b7PRS\M79&E>´WPBNRS@CBZRS>ÒÊK9AT4FCOPVS>(RE0FHWPWVRS9&K"R:ÞFCVV
WPB9AT59ABB9&KÈ9=<	>J9&:PER@M:PE#RT©R>;REßWq@MEERSIV9´>J@FHWWVSÒRS>AÓFC:PKÝÕIq9&VS@M:\ME#>J@L>7P@MEJ99=<j>J9&:PENRS@M:PE;RSTYFC:PK
@M:PVSÒRSTz¦2Iq9&VS@M:P\ME3>J@X>79&Dd
à
á E³FgQ=@CBN@MVVFHBÒCÓ	>J@C\C9A>79AB3cßR>7LFg>79A@CB9&DÁ>7FH>³EN7@%cßEG>79ÑR: >JBNFCQ=>FHIRVRS>Ò@CTIBNF&[C9ÑB9&FCE@M:PR:\
@CTq>79ßQAVFCENE?R: ] 9&RS>J9AB&^_EGK9AT5FCOVS>YVS@C\MRQ(â4ã(FCO>Ja;äåj9&VDXFC:Óæ&çCç	æ%èZÓjcÎ98@CIP>FCR:X>798T5@MVVS@§cßR:\ÑBN9&EOPVS>Ad
é ik§iê5ê5ëPk§ìËnqpsrjíîºw=x4+ »242Z­ß½ ¿ÑÉØ
È ï AH´=x4Zs~&x³xCx}C©HJwAN`ÌG5xwA}Cð ï ³}H±H++ñ	~&x4sHPÅ
JwZw0H}C©ws=}CjxÎx5	wHwg4Z­Ñ®©	wAJw( (}*Aw&xÎJ´×4xw=J}H×NÎ#ò Ï Åój}HJM¹
egfhjiklhjmonqpsr ô­uw&x ¡{ZwX}±~&}HNXG?P5xwXw4A}H	xßx5	wHwgZP~=x5	}Cx8x5	w*~NH~&×j4HÂXw}M~A
ws=}H	xY+`}X×4xw=J}H}HLw}~=bXwA*{Nw=´ÎÂj}l(}CxYSwN}lxÎHwgw¸MxwAZsH¹XºwÎ°J{ASwAîÑxw=x4+j»
¼õ½ ¿`À ï AH¼öÜ}H4xw=J}Hð ï +`°	HÄlH4}H3x45*wL}CPÄHÅHqwJwNHP~A{=wxÝx5	w´°J{=w=µ
xw=x4+j»¼£½ ¿`È÷ ï ®©w=w;øù0}*x4s~&xÎxCx}H CwAgHØ w4A}H	x5´5±¼±¹
Ï J&A¨;Ð9A>´¼ú¿Á42Z­8Iq90FK9AT5FCOVS>ß>79A@CBNÒ2R:©d;ÚÊ9gBN9&KPOPQ=9(>J9&E>R:\¼Û½ ¿`À ï >J@b¼Û½ ¿ÑÈ÷ ï FCE
5T @MVVS@%c#EAdzÐ9A>3 Ç Iq9#>79`EJ9A>³@CTKP9AT5FCOPV>EGc#RS>7 ï FCE³>79`Q=@M:PQAVOPER@M:dzÐ9A>3ø¶Iq9;FEJ>JBZRQ=>G>J@C>FCVq@CBZK9AB
@M:±îEOPQZ7>7PFH>ßLÇûØâ4bülLÇèÎý.øXd?ÚÊ90QAVFCRDÁ>7FH>#¼£½ ¿`À ï RST FC:PK@M:PVSÒRSTz¼£½ ¿`È÷ ï d
á EEOPDX9g>7FH>0¼µ½þ¿ÑÀ ï dÿG9&QAFCOEJ9XIjÒFCEENOPDWP>RS@M:>79ABN9XREÑFH>(VS9&FCEJ>Ñ@M:P99=<j>J9&:PENRS@M:Ý@CT³¼ÓI Ò
Ð9&D*DX
F jd>7P9AB9gREß9=<FCQ=>VSÒ2@M:P9ø´ÙWPB9AT59ABB9&K È 9=<	>J9&:PER@M
: Á@CT³¼b
d ³VS9&FHBNVSÒ ï 
 þ *dÑ6879AB9AT5@CB9
¼ù½þ¿`È÷ ï d
á EEOPDX9>7PFH>(¼ ½ ¿`À ï d6879&:Ý>79ABN9XREÑFC:Ê9=<	>J9&:PERS@M	
: ¾@CT³¼ùENOPQN7Ê>7FH> ï 

 X
d  T3 ½ ¿ ï Ó
>79&:QAVS9&FHBNVSÒ2¼Ã½ ¿ È÷ ï d á EEOD9(>7PFH>´ ½þ¿ ï 
d ß@§c­FHWWVâ & èßT+@CBÑEJ@MD
9 XÊ Ç d á ENEOPD90>7PFH>
´Ç RE`FC:Ý9=<j>J9&:ERS@M:@CTÎ¼ùEOQN7>7PFH> ï 
 þ *
d #@%c¯FHWPWVâ % X (Ç5èZd á 
E &Çz¥*ÇT+@CBÑFCV
V %ÇS
ø LFC:PK
:@C>`FHWPWVâ  Ç   Ç èßT+@CB`FCV
V  Ç " Ç Óq>79AB9RE;:
@  Ç
ø EOPQZ7>7FH>`FHWWVsâ  Ç   Ç  èZ
d ß9&:PQ=
9  Ç RE;:@C>
ø(ÙWPB9AT59ABB9&KPÈdG6879AB9AT5@CB9 ï Iq9&VS@M:\ME³>J@*FCVVøÑÙWPB9AT59ABB9&KÈ±9=<	>J9&:PERS@M:PE8@CT©¼úFC:K2¼£½ ¿`È÷ ï d
à
687P9ÑT+@MVV@%cßR:P\gQ=@CB@MVVFHBÒbRE³@CIP>FCR:9&Kbc#RS>7b>79´R: >JBNFCQ=>FHIRVRS>ÒLB9&EOPVS>E³@CT IPBNF%[C9´B9&FCEJ@M:R:\I Ò
ã´FCO>Ja0FC:PK2åj9&VDXFC:Þâæ&çCç	æ%è8FC:PK2å	>RVVDXFC:Êâæ&çCçè8T+@CBß>79´QAVFCEEJ9&E#D9&: >RS@M:9&Kd

 

!#"%$'&)(*$,+-$
./*0)/213134,0)57698;:=<?>2@BADCFEHGJILKFMONQPSRT UWXZ
V
ADC E`aCbC Cdce @ AWhicG f ejEFCk@ _ cejA Y EHGc G,l ]g[ C3m'@
`^e%cAQA^@BA ]n[f @ [ copeqCrC3m'@ ]_ E@DAst@^e ] u EHAvxwbY\ykmp[^c ]_g_ f{z _ ] ] _gf _
M
P
G ] _Q| ce\o}G2c _ l
~ ]_ G`^e%co}A^@BA
G ] _Q| ce\o}G2c _ l
{yeE3Ck@ _ c e`^e%co}A^@DA
@
@
p
o
*
G
c
l
]_nf@ @_ aopf E;ABE3Ck@^y _ @Q@ @ @ o}G2c l eeEFEFCkCk@@ _ cceeAA
_ _
[B_ ]_nf _ f _
_
*;*%2{*{ZxJ\a*
xD}r -¡£¢ ¤¥a¦nn¥Q¡£§Dna¨n¥t¤ §D¤©=ª%§^ª£¤ ¦¦r« ¬­=¥t¡%« ¥t¡%¡£®^a¨¯¨'^¬F¤ °,ª%±²'^« ¥t¡%a¦r¬3« ¥rx²,¡£§t²³²'°,´,¡;µJ°'
hW¶ ­,¥^¬3^¥¥a¨=VD}na´=¦¡%«-´,¦§^¤ ´·©9§D«-¸­=°'na¨©}¹³°,¦¡;´'  h ¤ ¦²'W« ¥t¨,^¥¡;´³x²,¡£§t²²'¤­,­*ª£¡£§^¤¡%«-´
« ¬¨'^¬F¤ °,ª%¦r¡£¦¤nna¸­,na¨º¼»'²,¤ °,¦n¡£¢ x¦na¤¥t§Q²¡£¦r¤a¢ «-¡£¨'a¨·©9a§^¤ °,¦x²'^¥t¡£¦´'«´'^a¨³n«¥^n¥t¤ §D½¤
¨'a§^¡£¦t¡%«-´¾n«¤­,­=ª%¹¤¨'^¬F¤ °,ª%^º¿½²'x²'^« ¥a¸À¡£¦Á -¡£¢ a´¡;´¯¤  a´'^¥t¤ ª*¬H« ¥t¸Â¬3« ¥¤ ´J¹n¥t¤ §D¤©=ª£W¦t°'©=¦n^
« ¬Á§^ª£¤ ¦¦t¡£§^¤ ª­,¥t« ­2«-¦t¡%¡%«-´,¤ ªª%«  -¡;§Ã*ª£¡%Ä Å#« ¥t´§^ª£¤ °,¦a¦^Ã2Æ ¶ ª£¡£n^¥t¤ ª§^ª£¤ °=¦na¦^Ã=« ¥Ç ¶ ª£¡%n^¥Q¤ ª§^ª£¤ °,¦a¦^ºb¿½²'
²'^« ¥a¸È¤ ´,¨²'¤ ª£  « ¥t¡%²,¸É¤¥t­=¤¥½« ¬²'¬3«-ª%Äpª%« ¥W« ¬´'«-´,¸«-´'« n«-´=¡£§W¥a¤ ¦n«-´,¡;´' 'º
ÊËÌ /=0 Ì}Í 698;:ÎÐÏ@aC*ÑÒst@c`aeqcAtA ]g[\[D] _Q| opeqcJ@AQo,`^mC3mpc CADc CFEHAHÓrc{sDE3ejEFCFlCk@BABCFE3GJI [^]_bÔÖÕ ÑÒCdc× @DA
 ] elG ]| EceCFE | @LEHGØC3mp@OABE%Ù)@ ]n[Ôbz Ï@aCbÚÀsQ@LcÛ`aeqcAQA ]g[Lf @ [ c o}eqCC3mp@ ]_ Ed@BALKFMLNQPÜRAQo,`^m
C3mpc C
MÝUßÞJàjáâáT áäãOåæ [^]_ A ]| @ÓÁG,EFCk@xA^@aCå Õ ÑçcG f P Õ ÑÒEHAÓÁG,EFCk@ z >mp@DG [D]_bè ãÚé9áãêÑé
cG f ABC _ EF`CbC ] Cdce ]_gf @ _ Ah ] GC3m'@ f @ [ copeqC3AE3G è érC3m'@  _n] sDe£@ |i]g[ Ck@BADCFEHG}I è T UXÛ
V ë áìE;AíA ] eîc{s^e%@
E3G  ] ejlG ] | EceCFE | @ ] G	C3mp@íABE%Ù)@ ]g[ MïêPðïLÞ ë áæ z
w _n]a]g[ àñ ¹äòa¸¯¸¾¤ó}ºôê²'^¥¾¡£¦W¤¸«-¦«-´' hW¶ ­,¥^¬3^¥¥a¨,VD}na´,¦t¡%«-´ä¬H« ¥a¤ §Q²¸a¸©9^¥« ¬ Ú Ã
¤ ´,¨©9a§^¤ °,¦n²'b¨'^¬F¤ °,ª%¦¡£´¸a¸©9^¥t¦« ¬ Ú ¤¥½´'« ¥t¸¯¤ ªÃ ²'^¥b¡£¦¤Áª%a¤ ¦n«-´'bDpna´,¦¡£«-´¬H« ¥a¤ §Q²
¸a¸©9^¥±« ¬ Ú ©}¹¾¿½²'^« ¥a¸Àõ}º£Ç¡£´LöF÷#a¡%n^¥aÃ9Çaø ùú{ûQº±¿½²'^¥t^¬H« ¥x²'^¥¡£¦¼D'¤ §Dª%¹¾«-´, hW¶ ­,¥^¬3^¥¥a¨ V
Dpna´,¦¡%«-´¬3« ¥Áa¤ §t²³¸a¸©2^¥« ¬ Ú ºüý¨'a§^¡£¦¡£«-´­,¥«p§Da¨,°'¥r¬H« ¥¼²'b§^ª£¤ ¦¦« ¬9¨'^¬F¤ °,ª%²'^« ¥t¡%a¦¦¤na¨
¡£´²'b²,^« ¥a¸þ¡£¦ -¡%¢ a´¯¡£´ÿ¡% -°'¥½ù}ºÁ¿½²'­,¥t«}§Da¨,°,¥b§D«-¸­=°'na¦Á¤¦^ ²,¤±§D«-´,¦¡£¦n¦« ¬ P ¤ ´,¨
²'¾§D«-´,§^ª;°,¦¡%«-´,¦W« ¬r²'  a´'^¥Q¤¡£´' O¨'^¬F¤ °,ª%¦W« ¬r²'¾Dpna´,¦¡£«-
´  G ö û« ¬ KFMLNQPSR Ã\¤ ´,¨ä¥^°,¥t´,¦
C _ o,@ ¡%¬¤ ´,¨«-´,ª%¹¡%¬ T UÐá º
ò^
  	á Bâ
á aN )N  á pâá  ©9²'O« ¥t¨'^¥t¡£´,  h « ¬W¨,^¬3¤ °,ª£¦¾¡£´ M 
º ¬ P ¡£¦¡£´,§D«-´=¦¡£¦nna´J²'
U  ¡£¦²'¼«-´,ª%¹WD}na´=¦¡%«-´« ¬ KFMLNQPSR #²=¡£§t²¤  ¥t^a¦
­,¥«p§Da¨,°'¥t¥^°'¥t´,¦ C _ o=@ 	º g´²,¡£¦\§^¤ ¦n  G ö P û 
#¡%²ä²,¾¦n¤na¸a´Jí« ¬r²'¯ª%a¸¾¸¯¤pº W²'^¥#¡£¦Dpna´,¦¡£«-´,¦W« ¬ KFMONQPSR ¤¥¯§D«-´=¦¡£¦nna´J^º  *´'
M íU Þ  á  âá  N N  á kâá kæ ¤ ´,

¨  íU Þ)á  N Ntá æ ¬H« ¥³¤ ª£ª  ãþÞ ú N )N æ º
¿½²'§D« ¥¥a§D´'a¦t¦
U º
­,¥«}« ¬¡£¦©J¹·¡£´,¨=°,§D¡%«-´«-
´ ¼¤ ´=¨±í« ©,¤ ¡£´²' hW¶ ­=¥^¬H^¥t¥a¨,´'a¦¦ V « !¬  G ö ûb¤ ¦½²'§^¤ ¦n"  #
$ G o'`CFE G³mJl  C3mp@BABE;A ¬H« ¥¤ ª£&ª % ã	Þ ú N N  æ ÃJ¡%¬ P ¡£¦§D«-´,¦¡£¦na´{^'Ã (b¡£¦¤W¸¾¤p¡;¸¾¤ ªp§D«-´,¦¡£¦nna´J
h * ö M +M  û ¶ ­,¥t^¬H^¥¥ta¨,VD}na´,¦t¡%«-´
¦°'©*¦n^#f « ¬ )] ( ïOP ] ¦t°,§t²²,¤ P Õ (Ã¤ ´,
¨  G ö  û#¡£¦#¤ 
« ¬ KFM NQPSR º
¿½²,¡£´=¨,°,§D¡%«-´­,¥«}« ¬½¡£¦¦n¥t¤ ¡% -²Jn¬H« ¥¤¥t¨º¿#²,¤²,³­,¥t«}§Da¨,°,¥¯¥t°=´,¦¡;´­9«-ª%¹p´'«-¸¾¡£¤ ªÁ¡£¸
«-´ý²'	¦¡%®^« ¬ KFMLNQPSR ¡;¦³¤ ª£¦«Z« ©}¢}¡£«-°,¦^ºþ¿½²}°,¦¤ ´{¹7­2«-ª£¹}´'«-¸¯¡£¤ ª½¡£¸¾¦°,©=¦n^ Ú « ¬§^ª£¤ ¦t¦¡£§^¤ ª
­,¥« ­9«-¦¡£¡%«-´,¤ ª9ª%«  -¡£§W­,¥t«}¨,°=§Da¦b¤n¥t¤ §D¤©=ª%§^ª£¤ ¦¦b« ¬¨'^¬F¤ °,ª%b²'^« ¥t¡£a¦^º
,
-Ø¡%²'«-°'\­,¥t¡%« ¥Q¡%¡%a¦9¥a¤ ¦n«-´=¡£´' #x¡%²­,¥^¥taµJ°,¡;¦¡%n ¶ ¬3¥^¼´'« ¥t¸¯¤ ª{¨'^¬F¤ °,ª%¥Q°,ª%a¦¤ ´,¨Åx« ¥t´í§^ª£¤ °=¦na¦
¡£¦/ . ¶ §D«-¸­=ª£^n³1ö 0}¡£ª£ª;¸¾¤ ´Ã*Çaø øú{ûQºrÿ'« ¥x´,« ¥t¸¾¤ ª9¨'^¬F¤ °,ª%¦^Ãpn¥t¤ §D¤©=¡;ª£¡%k¹§^¤ ´·©9« ©=¤ ¡£´'a¨¤ ª£¦n«¬3« ¥
¨'^¬F¤ °,ª%¦#¡£²­,¥^¥aµ}°,¡£¦t¡%na¦¡%¬\¦°=¡%¤©=ª%W¥a¦nn¥Q¡£§D¡%«-´,¦b¤¥¡£¸­9«-¦na¨·«-´²'í­,¥^¥aµ}°,¡£¦¡£na¦^Ã}§D«-´=§^ª£° ¶
¦¡%«-´=¦^Ã*¤ ´,¨O²'« 3© 2ga§D¡£¢ ­=¤¥t¦#« ¬²'¨'^¬F¤ °,ª%½²,^« ¥t¡%a¦^º#xDprí­=¥a¦na´J¦°=§t²O¤§^ª£¤ ¦¦x²,¤W¡£¦
´'a¡%²,^¥½¦°'©=¦°=¸a¨©J¹´'« ¥#¦°'©*¦°,¸a¦r²'n¥t¤ §D¤©*ª%­,¥^¥taµJ°,¡;¦¡%n ¶ ¬3¥^§^ª;¤ ¦¦na¦^º¼¿#²'¡£¨'a¤©9a²,¡£´,¨
46587

9:;<>=@?&ABDCFEG:HIKJLBM:JLBDC3BMN8?'OQP/?>HSRLTU=SCWV:YXZBM[3\
]K^`_!a
bKcedf^gbihUjlkmMhLj>noWprqsp tupwvfx
y	b"z|{}v
~v	~lp{}vY8vYp8p{}v3vjSLj!&whLjrmMLt'oW
/{q
_^#K{Wz_c _
¡ |¢¤£ ~¦¥Q§ vZ¢©¨`mMªk'UªSmMª  jlF"n«jl¬®­Um°¯±&²°jlFS²°³&´Ug¢«£ ~¶µ·¸v¢1x
zf¹/bºg¢¦{»¢¤£ ~¥W§ v¢©¨
bº/c`
{  
¡ | ¶ »v
zf¹¼bKº^gb"z¼df^º» w­Uj"by¦½Lb¾^gb"z¼df^gº»¿«±&²Àª j
bKº¼c
Á¦mM'­LSj!Â®{KÃÄhLjlkmMªSmM'ÆÅUS3kjlhU­LSjÇ¿«&±k²M±&ªSªg&¿¦ÅZSjSjl¬®­UmMªSm° jÈ1¿«SjjL&wÉÊ±&²fhLj¿«±&­Z²°SLj&wm°jlª
SLjSjlªw­U²°¸mMªËSLjªw±&Éujg±&ªÌSLj'Ujg­Uª jlhmMSLjÅUS®&¿Z&¿ÍgLj&SjlÉÎ®ÏMlÎ®Ï)Ð&S'²M²M±w³"Î®ÏMlÂ!mMZhUmMk± jlª
SU±gSUj!SjlªS­U²M)k±&ZL&gj&jlLjw±&²MmMÑjlhn±&ªSªS­UÉÊmMLuÒ Çµ Ó/ÒxK  ±&>³Æ&¿ËSLj!k²M±&ªSªSjlªUm°'UjgmMÆSLj
Ô!±&­L Ñ"±&UheÕ®jl²MÉ±&eUm°jw±wkr>³&Ï
Ö×	Ø®ÙZÚ6Ø®ÛÝÜÞÀßZß y	àlá
â#ãrà"á«ä3àåæ°ç6èwè"é ê/¹`é&ërìsí>àêçî3æDáKá«ä3àwéëïðàèñoeprqò!óËä3àëSàq ï¤è`çôìUï«áõà!èlàá
éöêgæ÷ïáõàë çæ}èÇçìíuí>àðêçî3æDá«ègï¤ìuoøçëSàéöê¼á«ä3àêé&ërù¾ú ~Fû"üüüýû ú Yþÿ  ÿ óËä3àë à ÿ ïÀèç"æïáõàë çæfçìíú ~ p8pú 
çëS
à ëöé 3é6èrïáïðéìç
æ 6ç&ërïðç>ãæMàè Ê
é&
ë 
	|â gìà >ç'áõàSíÆ¹`éëìåæ°çî®èàè!v/çìíèáëïðålágá1é&á1ç&æKéë í>àërè!t
éì á«ä3à"í>àêçî3æ÷á«èï«
ì Ìá«ä3
à ë é>ãæMàù éöê!áõàèáï¤ì  ¶ 
  ·ÌviïÀè/èéæ 6çFãæMà!ï«
ì Léæ ìé&ùïðçæ¦áï¤ùÊà"éìQá«äLà
èrï 8àé êgo ¥ q ¥W§ ·Ìv
¨ 
] ë éléöê þ ÍgLj3hL³W&¿SUj hLjlkmMªwm°'sÅUS3kjlhU­LwjÊmMª!'mM¯&jl|mMÁ¦mM'­LSj±&UhmMSª`k&SSjlkSUjlªSªÅUS®&¿
)
mMª!mÀUk²M­UhLjlhsmÀsSLjÅUwF&¿&¿gÍgLj&SjlÉ Î®ÏMlÎ®ÏjSj!Kj­Uª jSUjÊªS­LUÅZS®kjlhZ­LSjeà#"'ïÀèá«èmÀsÁ¦mM'­LSj
$ ÏGÍgLjÅUS3kjlhU­Lwj #à "'ïÀèá«è`w­UZª"mM|Å'²°³3L'ÉmM±&²SmMÉuj'|SUjªSmMÑj&¿¼o ¥ q ¥&% jlk±&­Uª jÆSLj
®­UÉ`j&¿¸m° jw±SmM'UªgmMÆSLj`SjÅjl±öÈõ­U>SmÀ²
²°®&ÅemMª±¼É'ª  ¶ !
o ' ¶ (¶ o ¶ ±&Zh²°&'mMk±&²
k'Zª jl¬F­UjlUkj
 jlª S)
ª ¼m°SÊÅZS&Å'ªSm°Sm°'U±&*² ¼&wÆk²M±&­Uª jlªk±&ÆjÇÅjS¿¤&rÉujlh mÀ Å'²°³3L'ÉmÀ±&²USmMÉuj&ÏÌÓ¼,j +3)
 KjÇÅUS@¯&j
SU±¼SLj!ÅUS3kjlhU­Lwj #à "&ï¤èá«èk±&²M²°jlh m°S±w'­UÉujlFSª"noWprqsp % xwjS­LwUª!áëîZàgmM¿¦±&Uh'U²°³ m°¿¦SLjSj
mMªg±&,j +® jlUªwm°'e &.¿   ñoWprqò)ªS­UkrSU± %0/2143 n5p ÊxrÏ)ÍgLj!k&wSjlkSLjlªSª¼ÅUS®&¿¦±&Zh SLj
±&²°&&wmMSUÉ ±SjuZ±&ª jlh ' SLjumMhUjl± SZ± hLjwm°¯&jSLjuÅUSjwjl¬F­UmÀªSm° jlª¼&¿KhLj¿±&­U²°SªÇmM % ´	hLj¿±&­U²°Sª
mM 
o 6 % m°S ±Lj'±SmM¯&j`k'Uk²M­Uªwm°' ±Sj`L&gUjjlhLjlhfÏ
ÁËm°wªS7
 Kj ªSL8 SU±Æ5à "&ï¤èá«èSjS­LrUª w­Lj m°¿±&Zhs'U²°³sm°¿SLjSjÊmÀª!±&G,j +3 jlUªSm°'|7
 '¸&9
¿ :'Ì
ñ!
o '¤prqòuªw­Ukw¾SU± %;/
13 n7
 '5p :'Àxr
´ LjSje!
o 'Ç % ¥8§ < { úw=
ú 	 o ¶ ·Yú 	
G
q
p
«
'
D
{

·

ú
&·ú 	 µ
µ
<
Ï >ý¿uq ¥ 8§ @ ¶ < { @  @ 	 % ¨mMª mMUk'ZªSmMª  jlF±&Zh % B
 µ A®´ÇSLjlSLjwjG±SjGL
% púQmMª± 'ÉmÀk¨'?
j,+3 jlUªSm°'UªKSU±)±ÅUÅZ²°³ % ´3±&Uh UjlUkj/mMKmMªk&SSjlk) SjS­Lw"êç&æ}èlàÏKÕ®±&ªSªS­UÉjÇq ¥ 8§ @ ¶ < { @  @ 	
 C q ¥s8§ @ ¶ < { @  @ 	|o ' ¨umÀª/k'ZªSmMª  jlFF³QhL,j EUmMSm°'&¿)o ' Ï
% ¨ÊmMªÇk'UªSmMª  jlFÏ"Ó¼8 SLjuª jD
Ã/>³ ,j +® jlUªwm°' 7
 '&F¿ :'YªS±SmMGª EZjlª
 ' / a¦ìYHn Cxr´U±&Zh jlk±&­UªSjÇ±&²À²YhUj¿«±&­U²MSªmÀ !
o '±Sj!U&wÉ±&²ð´3L
Lj'±Sm°'Q&¿Ì7
± I ­Zª SJm Ek±Sm°'e&¿±hLj¿«±&­Z²°mMQK
o '
mÀª¼mM#a¦ìHn CxrÏ/ÍgLjSj¿«&Sj,j +3±&kS²M³SL'ª jhLj¿±&­U²°Sª
±Sj!±ÅUÅ²Mm°jlhÆmM,j +® jlZªSm°'Uª)&L¿  ' ¿¤&)
 ZmMkwÆSLjÇÅUwjSjl¬F­ZmMªSm° jÇmMªhLjwmM¯6±Z²Mj&FÏ >©mMªª  w±&mM'> ¿«&# )±wh
  ªSLM SU±ÇSLjÅUS3kjlhU­LSjk'ÉuÅZ­L jlªÇSLju­UZm°'W &¿q ±&UhQSLjuª jÇ&¿k'Uk²M­UªSmM'Uª&¿KSLj
­UUmÀ¬F­LjuªS­ZkwªSj`&¿hLj¿±&­U²°Sª´¦±&UhLjlZkj|a¦ìnx!mMª!SUjÊ­UUmM¬®­Lj,j +3 jlUªSm°'&)
¿  ' ÏÆÁËmMU±&²M²°³&´SLj
ÅUS3kjlhU­LwjSjS­LwUªg¿«±&²MªSj`m°¿¸±&Uh'Z²°³mM¿ <»	Q
µ  ¿¤&/ª 'Éuj < { @  @ 	 % ÏÍgUmMªmMªjl¬F­Zm°¯6±&²Mjl>g  SLj
¿±&kgSU±O
 N 	 µ 143 nÊ5p  ' x¿«&ª 'Éu
j N	 % ´U±&UhUjlUkj % /P
µ 143 n5p  ' xrÏ

QSRUT

VXWZY\[M]^Y`_aY
bdce7fhgdi-jkc9gml,n\oprq#pMsut-vxwyv#z4{
|r}mz
~ ` wB8 dS&-z: 
k gc9g  jhc9  prl
tK*  z-8d 5-t¡ ^y
~ w&v#¢ ^ ^y
~ zvuop  qr£a¤¥o¦§a
¨©  wª
c9gbdg« 
¨    ¨¥
}9ecgd«f  dS&t  i!e
|r}m¨7   k g2¨¬  ¨28F
gdOi
jk  |r­¨  ¨7®
|r}m¨¯~ °®£±Xpr£a¤l²S&z k gc9g  jhc9  prl
g­´³µgc9g  jkc9qr±5¶\l
gdOi
·´oZ¸a¶\±#l¹dºp#¶`»`¼`±#£µ¦,l  ¶\±#l½£  lU¦op#o£  ¼`±#£µ¦,l  ¶\±#l
¾9¿ l KÀ l½p ¿ £ À q ¿  qq ¿ l±#l4op  l,nµqrl  p#oZ£  ¨7Á£Â:Áp#¶Á¦ ¿ q ¿  q)zÄÃPÅÆ¥su¨7uv5Â:{.oZ Á £ `Ç
Zo Lq ¿ l±5lDop  l,nqrl  p5oZ£  ¨?£ÈÂ¬p5¶`¦ ¿ q ¿  q4zÉÃÄÅ4Æ¥su¨Kv5ÂK{xÊ ¾9¿ lËG£ ÁZÇ oZ#Ì  oZ±#lU¦,q#oZ£  oZ±#lU¦,q Ç
®£  £ À pd®±#£a¤ ¾9¿ l£±5lU¤?ÍÊÎ:o  suÏXlUoZqrl±UÐhÑU¹Ò§ÓÔ{È»lU¦  ¶`prl4t  ÃÕt ` t©op  £±5¤  ÊLºOp#p5¶`¤l½q ¿  q
q ¿ l±#l:op  l,nµqrl  p#o£  ¨?£dÂ¬p#¶`¦ ¿ q ¿  q4zÉÃÄÅ4Æ¥su¨¥v5ÂK{xÊ4Ö×qOop½prqr±  o¸ ¿ qr®£± À ±  qr£p ¿ £ À q ¿  q
¨Øop  l,nµqrl  p#o£  £7ÙÅ4Æ¥su¨¥v5Â!{xvxw0ÚxÊÜÛOl,nµq À l!±#lU¤£MÝl  l  ¶  q#p À oZq ¿  l¸  q#oZÝl¦,£  ¦  ¶Áp#oZ£  p
q ¿  q  ±5lÞo  tß»Á¶\q  £q-o  z  o ` ¶`¦,q#o£  ¼Á±#££ À oZq ¿2¾X¿ l£±#lU¤àÍÊÎ ` q ¿ lyo Á ¶`¦,q#oZ£ 
¿ Ç ¼£q ¿ lUp#oáp.¨ â    fFã^su¨ âMä sH8 dS&Üzkr´ d 5åÅ4Æsu¨¥v5ÂK{xvu&op  qr£a¤¥oá¦§kDwæ{r{´p ¿ £ À p
q ¿  qD¨    fFã^sH8 dSÄçz4ÞrÕP¨ d 5ÕPt-vuåop  qr£a¤¥o¦§½&wæ{7op  l,nqrl  p5oZ£  £
ÙÅ4Æ¥su¨Kv5ÂK{ ä t!®vxw0Ú Á zèÃ=ÅÆ:su¨ ¢v8ÙÅ4Æ¥su¨¥v5ÂK{ ä t!évxwæÚr{xÊê Ç ¾9¿ l£±#lU¤
ÍÊÎo  suÏ9lUoqrl±UÐ
ÑU¹Ò§ÓÔ{xÐ*q ¿ l±#l7op  l,nqrl  p5oZ£  ¨  £LÂ  p#¶`¦ ¿ q ¿  qXzÃPÅ4Æ¥su¨  v5Â  {xÊ
¾9¿ l±#lé£±5lq ¿ l¥¼`±#£µ¦,l  ¶\±5lD±5lq#¶\±  pëuìíÁî7oZ ` £ `Ç oZdq ¿ l±#lKoáp  l,nqrl  p#oZ£  ¨¬£7Ùut-vxwæÚ
p#¶`¦ ¿ q ¿  qXzÃPÅ4Æ¥su¨Kv5ÂK{xÊ
ï
¾9¿ l½qr±  ¦,q  »Áo  oZq Ç ±#lUp#¶  qÈoáp±#l  qrl  qr£:q ¿ lqr±  ¦,q  »Áo  oZq Ç £»`±  Ýl±#l  pr£  o  ¸D£q ¿ l7p  ¤¥l4¦ á p#p
p Xp ¿ £ ÀX » Çð lU¤¥¤ ¥ñ Ê¡ò!o  suó  ¶`qrôõÉöl  ¤  ÐkÑU¹¹µÑ8{xÊ
÷^øáù^øJúÉû7ü*ýþhÿ ký	
áü^ý
¾9¿ l¼`±5lÝoZ£a¶Ápp#lU¦,q#oZ£  ±#lUprqr±xo¦,q#pqr£q ¿ lypr¼lU¦o  ¦  prl À ¿ l±#l&¼`±5o£±5oZq#oZlUp  ±#l  prqr±5oá¦,qqr£q  £± 
Ê X£ À lÝl±8Ð9é£±!o  prq  ¦,lo  ±#l¼`±#lUp#l  q#o  ¸yo  ¿ l±5oq  ¦,l  lq À £± µpÐ)q À £
 l±5o  ¸£  q ¿ l  l  ¶  q#p
 l  ¶  q#p)pr£a¤¥lq#o¤lUp  ll  qr£ ¿  Ýl  !l ¶  s®£±Xo  ¦,£a¤¼  ±  »  lM{L¼`±xoZ£±5oZq Ç "Ê Ol  ¦,l7q ¿ l½¼£ap#p5oZ»Áo  oq Ç
£9qr±  ¦,q  »  lo  él±5l  ¦,l À oq ¿  lUp#p±#lUprqr±xo¦,qrl  ¼Á±5oZ£±5oZq#olUpop£Xo  qrl±#lUprqÊ ¾9¿ l!¦,£a¤¥¼  l,n\oZq Ç ±#lUp5¶  q#p
®£±X¶  ±#lUp#qr±5o¦,qrl  ¼`±5o£±5oZq#oZlUp  ±#lp5¶`¤¥¤  ±5oôl  o  ¾  »  l ñ Ê ð #o lo  l  ±  oZl±9p#lU¦,q#oZ£  pÐ`±5lél±#l  ¦,lUp)qr£
q ¿ l£±#lU¤Kp  ±5l½¸aoÝl  o  ¾  »  %
l $Ê ¾9¿ l½±#lUp#¶  q#pdo  q ¿ l4¼`±#lÝµoZ£a¶`pdprlU¦,q#oZ£  p  p À l * p±#lUp#¶  q#pd£  q ¿ l
¦,£a¤¼  l,nµoZq Ç £´¦  ¶`q#oZ£a¶`p9±5l  pr£  o  ¸åsuó  ¶\qrôDõ öl  ¤  ÐhÑU¹¹µÑ8{  oZ±#lU¦,q ZÇ o¤¼ Ç q ¿ lo  qr±  ¦,q  »^o  oZq Ç
£´¤ ÔÇ ¦  p5prlUp)£F±#l  pr£  o  ¸ À oZq ¿  ±#»Áoqr±  ± Ç ¼Á±5oZ£±5oZq#olUpÐ»lU¦  ¶`p#lq ¿ l7®£±5¤l±)q À £  ±5l  pr¼lU¦o 
¦  prl£)q ¿ l  qrqrl±U'
Ê & á p#prlUp7£  l  ¶  q7q ¿ l£±5oZlUp®£± À ¿ o¦ ¿ q ¿ lKqr±  ¦,q  »^o  oZq Ç ¶\lUp#q#oZ£  ±#lU¤  o  p
£¼l - ±#lq ¿ l7¼`±5l±#!l ¶Áop#oZqr(l ®±#ll  £±x¤  ¦  p#p#lUp ` q ¿ l  £±x¤  ¶ Á ± Ç ¦ á p#p À oq ¿  oZqrl±  pÊd·`£±
¼`±#l±5!l ¶`oáp#oZqr(l ®±#ll  £±x¤  ¶ ` ± Ç q ¿ l£±5olUp À oZq ¿ )Ñ   oZqrl±  ¦  ¶`prlUp±#l  p#£  o  ¸ op!qr±  ¦,q  »  lÐ½»Á¶\q
q ¿ lÜ±5lU¤  o  o  ¸¦ á p#prlUp  ±5lp#+¶ *¦oZl  q Ç l,nµ¼`±#lUp#p#oÝlÜqr£Þl  ¦,£  lÜ¼Á±#£¼£ap#oZq#oZ£ ` p  q#oá-p ,  »Áo  oZq Ç ÊÖ×q
.0/1.

24357698;:=<>@?AB3CEDGFH>I3FH>@?+>IJ:LK'MN:9COHPQ8?SRT3U>IV+W

X1YIZ=[[\=]"^Q_1]Z=`QYIabacH_1\=dfe#_![
z
x







z1 
z z
=
z!x
z 
z 

X(\LgihY#_(jHe#alknmocH_!pqX1YrZ=`Q[_![eIptsuZvd_
w \=dfp
x;ylYIeIa_1dfZ=Y
z)ylYIe#a_1d{Z=Y
!7!-
f!7}9
}G}9!-
!7!-
f!7}9
}G}9!-
!7!-
f!7}9
}G}9!-
!7!-
f!7}9
}G}9!-
!7!-
f!7}9
}G}9!-
!7!-
f!7}9
}G}9!-
!7!-
f!7}9
9i4-L(
!7!-
f!7}9
}G}9!-
!7!-
f!7}9
}G}9!-
!7!-
f!7}9
}G}9!-
!7!-
f!7}9
}G}9!-
!7!-
f!7}9
}G}9!-
!7!-
f!7}9
¡"¢~£¤
!7!-
f!7}9
¡"¢~£¤

^QeI[}|`QpX(ae#\Lp+y~]d_1_
`QpQZvdfk
^QeI[}|`QpX(ae#\Lp+y~]d_1_\=df^H_1d_!^
\=df^H_1df_!^`QpQZvdk
^QeI[}|`QpX(ae#\Lp+y~]d_1_pH\=dfgZ=Y
w \=dfp
pH\=dfgZ=Y`QpQZvdk
hQd_1df_!`Qer[e#a_(y~]d_1_
hQd_1df_!`Qer[e#a_(y~]d_1_\=df^H_1d_!^
hQd_1df_!`Qer[e#a_(y~]d_1_`QpQZvdk
hQd_1df_!`Qer[e#a_(y~]d_1_\=df^H_1d_!^`pQZvdk
hQd_1df_!`Qer[e#a_(y~]d_1_pH\=dfgZ=Y
hQd_1df_!`Qer[e#a_(y~]d_1_pH\=dfgZ=Y`pQZvdk
hQd_1df_!`Qer[e#a_(y~]d_1_h\L[fe#ae#¥=_%pH\=dfgZ=Y`QpQZvdk

¦ Zv§Y#_ ¨4© \LgihY#_(jHe#alkn\=]ªacH_«X(\LpQ[_!`H_!pQX(_«d_!YIZvae#\Lp­¬ ®¯moe#acqZvdf§e#adfZvdk°hQdfe#\=d{e#ae#_![
d_1]_1df_!pQX(_
w \=dfp
x;ylYIe#a_1d{Z=Y
±«²«³
±«²«³
±«²«³
±«²«³
±«²«³
±«²«³
±«²«³
±«²«³
±«²«³
±«²«³
±«²«³
±«²«³
z ´
z ´
z ´
z ´
z ´
z ´
z ´
z ´
z ´
z ´
z ´
z ´
z ´
z ´
¦  µ z!x
¦  µ z!x

X1YIZ=[[\=]"^Q_1]Z=`QYIabacH_1\=dfe#_![
z
x







z1 
z z
=
z!x
z 
z 

^QeI[}|`QpX(ae#\Lp+y~]d_1_
`QpQZvdfk
^QeI[}|`QpX(ae#\Lp+y~]d_1_\=df^H_1d_!^
\=df^H_1df_!^`QpQZvdk
^QeI[}|`QpX(ae#\Lp+y~]d_1_pH\=dfgZ=Y
w \=dfp
pH\=dfgZ=Y`QpQZvdk
hQd_1df_!`Qer[e#a_(y~]d_1_
hQd_1df_!`Qer[e#a_(y~]d_1_\=df^H_1d_!^
hQd_1df_!`Qer[e#a_(y~]d_1_`QpQZvdk
hQd_1df_!`Qer[e#a_(y~]d_1_\=df^H_1d_!^`pQZvdk
hQd_1df_!`Qer[e#a_(y~]d_1_pH\=dfgZ=Y
hQd_1df_!`Qer[e#a_(y~]d_1_pH\=dfgZ=Y`pQZvdk
hQd_1df_!`Qer[e#a_(y~]d_1_h\L[fe#ae#¥=_%pH\=dfgZ=Y`QpQZvdk

)z ylYIe#a_1dfZ=Y
±«²«³
±«²«³
±«²«³
±«²«³
±«²«³
±«²«³
¦oµ x 
z=z ´
z=z ´
z=z ´
¦  µz 
¦  µz 
¦oµ x 
´ z 

¦ Zv§Y#_  ¨7¶ _1]_1d_!pQX(_![oa\acH_1\=df_!g[b\LpqacH_X(\LgihY#_(jHe#alkn\=]o¬ ®¯m·e#acqZvd§e#ad{ZvdkhQd{e#\=dfe#ae#_![
a`Hdfp[·\L`QaNacZvaacH_EadfZ=X(aZv§eIYIeIalk¸\=]4Y#_(jHeIX(\=¹=dfZvhcQerX«hQd{e#\=dfe#ae#º1_!^'^H_1]}Z=`QY#aY#\=¹LeIXEX(\LeIpQX1er^H_![Nmoe#ac'acH_
adfZ=X(aZv§erYIe#alk­\=] ¶ _!e#a_1d!»¼[^Q_1]Z=`QYIa
Y#\=¹LerXt]\=dZ=YIY½§`HaE\LpH_X1YIZ=[[ µ¾¦ cH_1df_tgZ!k¾[aeIYIY4§¿_q^Qe@À¿_1d_!pQX(_![
eIp'acH_iX(\LgihYI_(j+e#aÁk¸\=]GacH_ieIp9ad{Z=X(aZv§Y#_X1YIZ=[[_![1Â]\=d_(jHZ=gihYI_ ¶ _!e#a_1d!»¼[%^H_1]}Z=`QY#aY#\=¹LeIXEX(\L`QYr^S§¿_EeIp
X(\vylÃNÄÅZ=p^Y#_(jHeIX(\=¹=dfZvhcQerXhQdfe#\=dfeIae#º1_!^q^H_1]}Z=`QY#aY#\=¹LeIXX(\L`YI^q§¿_ÆÇ È{ylcQZvdf^ µ sÉ_cZ!¥=_pQ\=aoZ=pQZ=Y#kº1_!^
acH_«erp9adfZ=X(aZv§Y#_%X1YIZ=[[_![oeIpqgi\=d_«^Q_1aZ=eIY µ
Ê0ËË

ÌoÍ#ÎHÏ;ÐÎQÑLÎ

Ò
ÓÔÕÖ0Ô×ÙØ¿ÚrÛQÜÞÝß!àbáãâ{ß¸àäHßSå!æ@çvèfèSé-ê¸ë9ßê(ç=ìæ@à«àäHßéví)îß(è°ïñðóò}ôSõ{öø÷qù"ä+ß(íßqö
îèçBè1ß!àé-ê






æúîàlß1í-çvæûèçvüëôýåfé=üHè{îè)àèé-êqë9ß}ê1çvì+æúàèqé-êtàä+ßê1éví)þ ÿ
ù"ä+ß(íß
îènç æúî}àlß(íçvæ ¾Ýß!
à ñâfßç'è)à}í)î}åà


v
ç
(
í
}
à

î
v
ç
T
æ
v
é

í
9
ë
(
ß
«
í
=
é
°
ü
ô
v
ç

ü
i
ë
I
æ
1
ß
à
{
â
%
ß

ç
û
æ
}
î
l
à
(
ß

í
v
ç
æ






(
ß
)
è
}
à

î
ü

«

ï


ð


{
å
v
ç
B
ü
f
â
%
ß
9
ë
v
é

ü
%
ß

î
ü
v
é
æ

v


ü
é=þ
îçvæªà}îþß%é=ü
	
	

àä+ß«è)
î ;ßEé-êoï çvü
ë  çvüë  
íé!é-ê1ÿ!
"!#!$&%
'(*)+%-,./%
"10*$(324'5765'(6ò}ôSõ{öø÷8 ð 
=B#1-
#DC46 9E F!,*!
GIHJ'(nî L
ê KL65'(M'57)N7,O'(6P%-,Q657RI07,*;<

:9 *4;<#!$($(7;<'(,*76(6#!=>'(?!
"!#!$&%
'(*)@%-6A!6



#!=/'(W!6(6&0*)YX*'(%
#1,Z6#!=/'(WX*$(J[\%
#10*6];J!6576 9

98S ,T7!;UV;J!653CF)N7GQ0*65W'(*3,J"1M'(%-#1,*6

.#!$?'(P^Z$&6('A=B#10$86('(M'57)Y7,O'(6?'(PXZ$(##!=/%-6_%
`!P'(

X*$(#I#!=a#!=a*J#!$(7)cb 9 2!24!6d,#PX*$U%
#!$&%
'(%
76/M$(4%-,O[!#1-[!7e 9gfI9/h
o

=B#!$3!-A65'5$&%_;<'W'5#!'(!A#!$&eJ$&6

ïtõ5K#!$&e*J$&%-,"


wI[I%-#10*6(
G! 

o

ot9uE

6(0*;Uq'(ZM'sr

#mCni po

fI9 2 9

%-6P%_,'(*M'<z\'57,*6(%
#1,!,*e};<#1,*6(7R07,'(
G%-,V!-/KX*$&J=J$($&7e*q<z\'57,*6(%-#1,*6 9N

à}í)ìQß

9WI9PS ,{'(3$(7)N!%_,*%-,"v;J!65Y,#!'Fi  Yi  9P

'5#!'(!>#!$UeJ$&%-,"F#1,ô6(0*;U'(*M'r
o

!,ZeVi  Bo

i j9dh

 !,*eT'(J$(J=B#!$(e#I76,#!'8;<#1,'(!%-,

7,*;<

7,*;<F'(J$(Y%-6?v6('5$&%-;<'

,uM$("10*)Y7,'86(%-)%--M$'5#N'(P#1,%-,y'(

<z\'57,*6(%
#1,QC8%
'(Q'(ïtõ5K#!$&eJ$U%-,"

X*$(J[\%
#10*6?;J!65Y6(#mC86?'(*M'?'(J$(Y%-6?tKXZ$(J=J$&$(7e 

i  

v#!w*'(!%-,x'(y0*,*%-RI0N<z\'57,*6(%
#1,xC8%
'(q'(

wG{'(N!
"!#!$&%-'(*)|"1%
[!7,}%-,V./%
"10*$(~y!,*eX*$(#m[!7,q;<#!$($&7;<'W%-,J#!$(7)

%
'%-6?;<#!$($(7;<'P'5#y$(J'(0$&,

;<#1,'(!%-,*6

6(6(0Z)Y]'(*M'i  Yi  j9lk

o

'(*M'

7,*;<%-'%_6;<#!$($(7;<''5#$(J'(0$&,iê1çvæûè1ß 9

j9g

*J$(J=#!$&P'(!
"!#!$&%
'(Z)$(J'(0$&,*6A'5$&0*%
=!,*ey#1,Z
Gt%
=  %_6]%-,!-KX*$(J=BJ$($(7eZ<zI'57,Z6(%
#1,*6]#!=

ï

9
E

-7M$&
G!'(W!-"!#!$&%
'(*)$&0Z,*6]%-,yX#1
G\,#1)N%-!'(%-)Y 9



%
'(#10'X*$&%
#!$U%
'(%
76JO;J!0*'(%
#10*6d!,Zew*$U7[!?$(7!65#1,*%-,*"=#!$,#!$&)!Z0*,*M$&G3'(*J#!$&%
76A!,*eQ2KL_%
'5J$&!

;J-!0*6(76?%_68'5$&!;<'(Mw
ypW!0'5HN\7-)N!,27!\2D 9E

Y6(#DC'(*M'X*$U%
#!$&%
'(%
768%-,*;<$(7!653'(3<zIXZ$(76K

6(%
[\%
':Gt6(0\v;J%
7,O'(-Gt'5#)M`!'(*%-6];J-!6&6%-,'5$&!;<'(MwZ
 9

Ò
ÓÔÕÖ0Ô×ÙØ¿ÚrÛä+ß 	 í é9â1æ#ß1þ é-ê°àlß)è)à}îü'ù"ä+ß!àä+ß(ítçSæûî}àlß(íçvæ  âfß(æ#évü=èà~é çvææ Y¡ 	 íß}ê!ß(í)íßë  ß(¢!¡
àlß(üQè{îévüHèé-ê·y
ï £ ù"ä+ß(íßï î è«ç°üéví)þiç=æì+üçvínë9ßê(ç=ìæ@à½àä+ßé=íUqçvüë îrè«çè)à}í)î}åà 	 çví)à}îçvæ"éví-ëß(í
é=ü
ë9ßê(çvì+æ@àè«îütv
ï £ îèåf!
é ¡¤  ¡Áäv
ç íë1
íé!é-ê1ÿxTX*$&##!=%-6wG¥$(7eZ0*;<'(%
#1,¦=B$(#1)§X*$(#!X#16(%
'(%-#1,*!]6(M'(%-6^aMwZ%--%
':Gx'5#x'(;<#1)YXZ
7)Y7,'#!=
'({X*$(#!wZ-7) 9©¨ J'Tªó¬
ð «D­m®!Jõ ¯J¯J¯(õ ­°W±w{x65J'y#!=XZ$(#!X#16(%
'(%
#1,*!8;J-!0*6576y!,*e³²s'({6(J'v#!=


X*$(#!X#16(%-'(%
#1,*!][MM$&%-MwZ-76Y#I;J;J0*$($&%-,"x%-,³ª

9´¨ J'yµ¶wa{!,·%_,¸7;<'(%-[!u=p0*,*;<'(%
#1,¹'(ZM'v)NMX67!;U

;J-!0*6(v­uº´ª'5#VQX*$(#!X#16(%
'(%-#1,*!g[MM$&%-MwZ-»
'(J#!$(G¾ï

ð

ò}ô¸õ&ÀL÷!,*e¼X*$&%-#!$&%
'(%
76W#1,

ðµ¥p­7W6&0*;&¼'(*M'F»º¾
½ ²

ô§!6F%-,q'(*vXZ$(##!=8#!=8J#!$(7)Áb

9V¿

<^,v'(eJ=p!0*
'

9 2 fI9qE

T;J-!%-)Â'(*M'

'(W6(J'8#!=l;J-!0*6576ªc%_66(M'(%-6^aMwZ
%
=/!,*e#1,*-Gy%-="ïÃ ½ ð ê(ç=æ è!ßJÄ'(*M'8%-6JZ'(J$(W%-64YKX*$(J=BJ$($(7eZ

<z\'57,*6(%
#1,Å#!
= ïÆ'(*M'te#I76,*#!';<#1,O'(!%_B
, ê1çvæ è!ß 9³S ,¦'(uX*$&##!=?Cu$(J=J$t'5#q'(Q;<#1,*6(%-65'57,Z;<G¼#!=
<z\'57,*6(%
#1,*6#!=Gò}ôSõ{öÞ÷lC8Z%-;&t%-6gwIGN'(?;<#1,*6(%-65'57,Z;<GN#!=ªö¶!,*e'(?=B!;<''(*M'eJ=p!0*
'(6d%_,ôÇ*D[!
¸(0*65'(%^;JM'(%-#1,*6 
Ê¦

h

#!$(#1-_M$(G

I9

wGyÈ7%
'5J$327!~MÉO5 9

6(6&0*)Y'(*M't'(J$(T%-6Nq)Y#Ie*7]Ë

KX*$(J=BJ$($(7eZu<z\'57,*6(%
#1,QÌ#!= Í
ï 6(0*;&u'(*M'

6&0*;&¹'(ZM'Ë

ê1çvæûè1ßWºQ
½ Ì
 Ïxº¼²b(
õ Ë

 ðsª

9¦E

u6&#DC'(*M'N'(J$(Q%-6N

ðÍÎªü:«5ÏºQ²v Ë
 ð¥Ï>±Ð«5ÏZÑ Ï{º
²bõ(Ë
 ½ ðÒÏ>±]Ð}«ÓÏ/ Ï¼ºq²bõ(Ë
 ½ ðÒÏ>±ÐV«ÓÏ Ñ
 ð³Ï>±8ÐV«7» ­Yº¥ªN5
õ »	
ð µ¥p­J&±?ÐV«Ó» Ñ  ­Fº
ªNõ5»ð+µ¼p­7&± 9NS '%-6P65'5$&!%-"1O'5=B#!$(CM$&eV'5#[!J$&%
=BG{'(*M'ÌÍ%-6P!,}<zI'57,*6&%
#1,V#!=ò}ô¸&
õ ÀL÷ 9¨ J' o w
o
!,Gu65'5$&%-;<'4'5#!'(!/#!$&eJ$?#1, ô6(0*;&Q'(*M'?Ôr
!,*eQ=#!$P!-g«mÕ!&
õ ÕDÑ±Yr v
ô ®?!,*e{!-d«mÕ!&õ ÕDÑ±Yr Y
ô ÖM
Õ o Õ Ñ %-=gMX*XZÕõ(Ì3!,*e,#!'MX*XZÕ Ñ õ(Ì3 9WE F6&#DC×'(*M' o
%_64Éò}ôS&
õ ÀL÷{5õ K#!$&eJ$&%-,*"=#!$PÌ 9¨ J'
ÌÑwF!,Gu<z\'57,*6(%-#1,Q#!=ò}ô¸õ&ÀL÷?6&0*;&'(*M''(J$&F%_6Õvº Ã
ô 6(0*;U'(*M'PMX*XZÕ(õ ÌÑ(õ ÌF 9WE N6(#mC
'(*M''(*J$(W%-6Õ Ñ º¸ô6&0*;&'(ZM'8MX*XZÕ Ñ (
õ Ì(õ Ì Ñ  9
h 6(6(0*)N'(*M'?Õ3º ô ® 9k #mCÕ«×
ð i  =#!$?65#1)Y3-%
'5J$&!  !,Ze  ºQÌWÑ>!,*e  ºQÌ 9]Ø 7;J!0*653ÌÑ
%-6];<#1,*6&%-65'57,'J  ºT
½ Ì Ñ 9d 7,*;<WMX*Xji   (
õ Ì(õ Ì Ñ  9dØ Ge<^,*%-'(%
#1,{i  o i :9
ÙÚ7Û

9A¨ J'4Ì

ÜAÝÞdßOàmá!âãäå}ÝæFçèã-Ýèãä\ã-éDá1ê{ë?áOæ(ìí*à(äQîÝaïZã-ð\ñ

 	
     "! #! $ %
'&"&(*)+,+-.  -. 0/ %2134 65 7%  ! 85  #! :9-. <=
"5 '&"&(*)+>+-.  -. / % / %  13
; % 
4?  "! #! @,+-.A-B+C D	.0
E>+-..A-.B
0  F GH4 65 I G%<J9 '&"&(*)K L	 / %<M13
4 65 N '&&(*)+>+-.  -. 0/ %21<O  "! #! P Q
5 N '&"&(S)K L	 / %13UT "5
; %R9
-. V%
'&"&(*)KA-.L-. / %1374 65 P%W! 85  #! :9X-. V
'&"&(*)K+-BL-. / % / %<M13
; %
4?  "! #! G+-BL-.CF>+-B  -.  
8Y>[Z,\Z]_^F( '3(D@ `; %a9 '&&(*)K+-.L-. / % / %  1 b+-.c-..dI,[Z,\Z]?eX#


0 E0[Z,\Zb! #! R!( '6
fg[Z  \Z  ]T "5 '&&(*)0Z]+-hZ  -iZ / % / %  13]4?  "! #!D @Z]+-hZ  -iZ  dRjZ  \Z  
eH	
h
 f=Z]+-hZcA-hZcc! 	! a!( '
f=Zc k:l'm+n:op3k l'm+n:o6]T 5 '&"&.(*)KjZcA\Zc / %< / %1 '&"&(*)Kq-iZcA-hZc / % / %@13H4
 ! #!D r+-hZ  -hZ  d@Z] k lmsn6o33k:l'm+n:o6
((
U t : :
0 `dv! =w /	xzy3/ Cf{* :	! "|}
07% ~%! Cf{
t ! u
&" :
 :#  u #!D 7
_w /	xzy 
)*1
8%! GCf{*&" :
 :#  u #!D 
 "5
k l'm+n:o ~
; %aU N\
: !  6(? "5
2 ` 
 6(  !D =%a9]
0
((. @ <@S /:::6/ M `5:( ! bE N < \8 fZ}Y)J613
4 65 8k l'm+n:o 
; %a9 N '&&(*)0Z   k:l'm+n:op3k lmsn6o / %13P4 65 $-Bk:l'm+n:o@! N @! 5  "5:( #!D 

:
 "( ! G9LZc ; %a<4 65 N '&"&.(*)K[ZcD\Zc / %2139h-iZc %R<T 5 '&&(*)0Z]+-hZc-hZc / %13
T "5 Z b%Rf4 65 %! 5  	! :9 '&&(S)JsZ,\Z / %21_
   Y /   2 : _ b@
-. \K
FP>9 7 
I %aa <%  
; %  65 
 
0z((D\! N|N
¡h¢ )J%V£r)J¤$¥-.i  $X¤$*  UX¤7¥-.*  $¥1¦J¤¥-..M¥13H _!   N\
%  ! u #!D P
?w  ¤ /	xzy 4? t : §Os¨! `)J© 6! :9«ª6¬­'®1 : E! u 	!D
%<.
?w /	xzy "5 _¯E)J%< / w PL¤ /	xzy 1F°~¯fa)J%@ / w /	xzy 13?\ '&"&(*)+>+-..D-.. / %@ / %1
: @! N
"5
'&"&(*) / % / %  1 \d>+-.  -.  
0  	!M5  (> :
d "5 _C±°Vda t ! I5   "!5 <Cf{*&" :
 :#
#$
]%R9
5 <! _
5
_ 
; %a7T "5 RO  "! #!D  ²,³K
I7²  9 5:( '	(D³  V%aT "5 ³
 ! #!D P ²-.> t : :
 E =¥H4 65
"! Nz( ?
0 P5:( < r9" _´
ò?ó(ó(ô*õNöv÷(øZùM÷ú}ûnüYýyù!þ*ÿ¹ú

ù

Nó 1õNö

Aö Jù!ô*ó5ö

ÿö þ 
÷

-ó

¼ÿö þ 
÷

û

1þ

nû

Âù!þ*ÿ

ù!þ*ÿ¥øö7þ <öyù

1þ

ý

ò?ó(ó(ô*õNö?÷(øZùM÷4úûuü

ù!þ*ÿuú

8ó 1õYö

Aö Jù!ô*ó5öyþ !÷ù
Åû

nû

1þZó -ó5÷5ö7þ÷

}ÿö þ 
÷

ù!þZÿqù

ÿö þ 
÷

1þ

ö Jù!ôZó5ö

uû

û

-ó

Aö Jù!ô*ó5ö

uû

*ù

/ù!þZÿxøö7þ <ötþ !÷3ù

1þ*ó -ó(÷5ö7þO÷

û

4ö7þ <ö

ù!þZÿqù

1þ

ò?ó(ó(ô*õNö÷(ø*ùM÷?ú

4ú


ö7ù

-óó -õ

û

ù

ù!þ*ÿ

-ù

ò?ó(ó(ô*õNöA÷(øZùM÷dú

8ö7þ <öù

?ú

-ó]ó -õ

3ÿö aþ 
÷ 1þ

-ù

ò?ó(ó(ô*õNö8÷(ø*ùM÷ú

8ö7þ <ö?ù

gù!þ*ÿtù

ÿö þ 
÷ 1þ

ø -óNö ø*ù!ô*ó5÷(óvù

(ö Bö

ú·ûü

(ö7ÿ ö I÷5ö7þZó 1þ
-ó3ùQõ

ù

>öJ÷

xû

4ö7þ <ö

û

_þ{ü

-ù!ô*ó5ö

Æù!þ*ÿ

_ótù

-þ

VöNó&ø

1þ*ó -ó5÷5ö7þ÷ ù

û

ö Jù!ô*ó5ö

uû

pü

øö

ý

ó(ô &øy÷(øZùM÷

pü

ø -ó

4ö7þ <ö

ÿö þ 
÷ 1þ

ö 
÷5ö

(ö

}û

 öJ÷

ý

-óAö7ù!ó v÷ Nó(ø

¾÷(ø*ùM÷

-óù!þvö I÷5ö7þ*ó

1þ

´ù

(ö7ÿ*þ*ö7ó(ó

4ó 1õNöó5÷

<÷÷ !÷(ù

Zù!þ*ÿTøö7þ <ö


÷õôZó5÷

÷(øö7þ

Aö Jù!ô*ó5ö÷(ø -óø

gû

÷(øö (ö

]ù!þ*ÿuú
(ö Bö

_ô*ó 1þ

4øö (ö

-þ

Vÿö þ -÷ 1þ

øö &ö

tû

Fò?ó(ó(ô*õYöY÷(øZùM÷

pü

<÷(ó÷(ø*ö

1þ

8ö7þ <öFù

j÷

(ö7õ

ú

1þO÷ Uù!ÿ

_þ}ù!þ

-þ

ý

Nü

-ó4þ túFûü|ó(ô UøT÷(ø*ùM÷?ù

@ó(ô &øT÷(ø*ùM÷

>öJ÷

-óþ !÷

Qû

NüYý

Vöyó(ø

³û

×÷(ø*ùM÷

Pó 1õYö

÷(øö

û

Iÿ*ö dù!ó

û

_ó

uû

-óù!þyö \÷5ö7þ*ó 1þ

û

-þ

ó&ô &øx÷(ø*ùM÷

?ö þöv÷(øöyõ

Aö Jù!ô*ó5öNþ !÷Pù

Aö Jù!ô*ó(ö

Jù!ó5öt÷(ø*ùM÷

&ÿö

Aö Jù!ô*ó5ö

>÷(øö7þ

ù!þ*ÿu÷(øö (ö

pü

ö \÷5ö7þ*ó 1þ

ó(ô Uøq÷(øZùM÷

û

xû

pü

(ö7ÿ

-óù

/þ !÷Wù

¥û
ý

(ö Bö

_óWù

\ÿö

öFù!þ

Aö Jù!ô*ó5ö

ùyÿö pù!ô 
÷

(ö

pü

Wò?ó(ó(ô*õYöt÷(ø*ùM÷

÷(ø*ùM÷3÷(øö (ö

øö (ö

-ÿ*ó

-ö7ù

8ù!þ

û

-ù!ôZó5ö

Uÿö

öP÷(øö

8ö7þ <ö

?û

µi¶·`¸¹»º.¼¸½²¾À¿>ÁzÂ¿>ÃgÄ³ÁÅ*¿«ÁÅS¼zÅ*ÆN¸½²Ç¸"ÈÉºcÊX¹S¼G·r¸ºLË¥¿>ÃÅ»ÃXÌ
Í ' :Î
t  Ï65 Ï:Ð ÎÑ!P)Éª6¬¬§z1! 	 5 V&"	!D	! #!DÏ :
 "( r(D|z!5 ! #! a!( ' 
4? :_Î ÑÒ a)Éª6¬¬¥Ó1f(D|z!5' t uÑ! "5 
X&" :
 :# u #!D ! " | ' ! G| : (S9
 2
0 N ( :
 "( ! ! : $ 6(! :Ô 
 " ( :
 "( :	! :9 75  &( uO{
! Õ
 Í ' :Î
t  Ï65 Ï:Ð ÎÑ!X(D|z!5³5 z! "5:! <! P5  a&( uN! »`
_4? :_Î ÑÒ (D|z!5'
 6(D|
8ÖÑ5 N³)Éª6¬¬z×1«&"
 #( #!D f
	 &"	!	! #!DÏ :
 "( :3!  N&"	!A{
	! #!Ï :
 "( :	! :9 #
u #!D X
  "( #! "| :	! ? : &"	!	! #! :
t 6!  #( #! b5  & :#
0 b! `&Bz( N R! ( #! P4 5:5 '
 N		! (*r)Éª6¬¬­z1@&"
PÎ "( "| 2 :&"
#!D ( N| '|
u E(|z!52&"#| ! U&"3!D	! #! 69B5:( #!5 (
:| #!D «9 "! 0Ø "5 #! c t :³5:( !
I 6Ô E # "! N|
0 6!DI( N| '| <! ?! ³| : (
7! N "! JØ 5 #!D $5:( #!M5 ( :| #!D $! _! I&Lz(D N a! ( #! 
ÙiÚ {»5  &(
4? :_Î UÛX! :2)Éª6¬¬­z1&"
N #!D U
hÜ.ÝoSk:o:Ý3Ý#o#ÞGl ¢ npßo Ý8n:o:à0nF
0 u
G(D|z!5
&"#| : t 6!D  "! #!D "!DÔ :#| 2
0# '3(! :2#Îb!
:Ô }!  (? :	! N|
  "( : 6` a  R&" :
 :#
 : :9 &" :
 :#
 :
ù (ö ©ù!þ*ÿ

(ö

Mù

Zô÷

&ô*ó

þ*ó

ó

Nþ

øö3ö

&õNù ÿö pù!ô 
÷(ó


÷

ù (ö qù!þ*ÿ

Uô*ó


÷

]÷(øö

?ö

&ù!þ*ÿ*ödù!þ*ÿ


÷ Jö7ÿtÿö pù!ô 
÷A÷(øö
P÷ &ù!þ*ó -ùM÷

Iþ


ö7ÿ !ö

1þ

&ö

1õ

-öJ÷5öWù!þ*ÿ

(ö

Mùù!þZÿ

Uù!õNó

1þV÷(øö

øö

(ö Bö

ö

-÷ Jö7ÿnÿö pù!ô 
÷

(ö7ÿ{ö \÷5ö7þ*ó 1þZó


ö !öv÷(ø*ùM÷

þ*ó

-þ

Nþ

-ÿ*ö7ó

(ö7ó(ö7þO÷ ù8÷ &ù!þ*ó _ùM÷ 1þ

-ö7ó Ió 3÷(øZùM÷÷(øöö \÷5ö7þ*ó 1þZó

Jù!þ

ö

ö

(ö7ó5ö7þ÷(ùM÷ 1þ

þö 1ùM÷ 1þ *ù!þ*ÿÿ -ó (ô*þ <÷
ý

Iÿ*ô <öxù

Vö

Uø*ù!ô

øö

ù

-ó

-þO÷

-ó(÷5ö7þ <ö

&õYö7ÿ

_þ

1õ

1þ

ø*ö

-ù -õ@÷(ø*ùM÷

&ö7ó(ô 
÷ -þ ÷(øö

-ù /÷ -õYö

-÷5ö

&ù !ö

-ù!ó(ó


ö

Aô

Jù Bô

&ù!õNó

(ö7ù!ó 1þ -þ

Jù >þö 1ùM÷ 1þ

]÷(øö

-÷

-ó


÷

(ö


ö7ó

öFõ

!ö

!ö7ó

(öY÷(ø*ù!þ

1õ

1þö

ö7ù

1õ

Mù


ö

ó


ö7ó>÷ 8ôZþ

ö N÷(øö


÷ 
ö7ó

(ö7ó5ö7þ÷

-÷(ø


÷ 
ö7ó

-ù!þ 1ô*ù !ö

\þ 1õ

_ó

-ù!ó&ó

_þ

Jù

!ö7þ*ö &ù

-ù ÷ -õYö

4ö \÷5ö7þ*ÿö7ÿ


ö

_þq÷(ø*ùM÷3ö !ö7þ

(ö Bö

(ö7ÿù!þ*ó Aö Wó5öJ÷ ù!þ*ÿ

á¥â\ã

_ù T÷

!ö7þ*ö &ù

löJ÷ù

(ö7ó5ö7þ÷÷(øö3þ !÷ 1þ

ÿ*ö þ 
÷ 1þqÿ

_þ


ö7ó ÷(øö


÷ Jö7ÿÿö pù!ô 
÷÷(øö

-ù!þ 1ôZù !ö3÷(øZùM÷?ö \÷5ö7þ*ÿ*ó

-÷(ø 1ô÷ÿ -ó 5ô*þ <÷ 1þtù!þZÿ

Uô 
ö7ó÷(øö (öNõù


÷(ø}÷(øö

-ó{ó -õ

1ôZù &ù!þO÷5öJö7ÿ

&õNù ÿö pù!ô 
÷3÷(øö

1õ

÷(øö

Iþ 1õ

x÷(ø*ùM÷

_ó?þ !÷


÷(ø¼ùu÷ !÷(ù

(ö Bö

&ÿ*ö

-þ

(ö7ÿVù!þZó ö ó5öJ÷(ó

äåDæNç\è.æ"ézæ
êNëUì"ëí@îïDðFî6ñÑò<ó ôNõòí#òEö0ë÷8î7øzõùó6ìbú"÷#ëø÷3îûüó:ùó6ìõö?îì"ò#ðó:÷@ò#ó:í#ò8êNëNýPþ?÷#ó:ð_ÿ'î$îì"êõDíó:÷@òNë\ð
í"î'ííó6òí#õMìNøíNó7ûó6ûBó:÷3ò"õDú}ëöîïMõDíó:÷	îïFõìYîïï?ú"÷#ó:ö0ó:÷#÷#ó6êYîì"òð?ó:÷Ròó:í#òaëöî`ú"÷#ëø÷3îûvõò ë	

 "î'÷	êYðNó6ìYíNó7÷"ïó6òî'÷#ó7íëí#îïïDñ}ë÷	êNó:÷#ó6ê«ý"ó6õD÷ûëí#õDù'î'í#õDëzìö0ë÷Rõìí÷#ëOê:õìNøGú"÷#ó:ö0ó:÷#÷#ó6ê
îì"òð?ó:÷8ò#ó:í#ò@õòfí"î'í8ó6î'÷	ïõDó:÷<î ëìí#ò8ëöFú"÷	õDë÷	õí#õDó6òfõìbïDëøzõú÷#ëø÷	îûaò<îìêbõìbêNó:öJî"ïDí<ïëøzõêNë
ìNëíö"ï.ïïOí»ð?ë@ú"÷3õì:õDúïó6òhõMêNó6ìí#õó6êOñ2í"ó6û7ý  ÷	õMì:õDúïDó]õòHùÑõDëzïî'íó6êñíNóú"÷	õDë÷3õDí#õ:ó6êêNó:öJî"ïDí
ïDëøzõ:òí"î'íIî'÷#óîòó6ê³ëzìPíNóò#ó6ûaõ ëzì"òí÷! í#õDùóê"ó".ì"õDí#õDëzìRëö«ó ôÑíó6ì"ò#õDëzì"ò$#JþFîîêNó:÷&%('ëzïï)"ì"êNó:÷+*
,+--.0/ þ?÷#ó:ð_ÿ'î1* ,+--324/65 î'÷#ó:ÿ7%8>÷ò9+":ñ&ì: òÿOõ;* ,+--<= *6NíFìNëí>ñRíNó<ïDó ôNõ ëø÷	î'ú"õ)_ú"÷	õë÷	õDí#õ:ó6ê
êNó:öJî"ïDífïDëøzõ2ê"õòò#òó6êUõMì@?Oó+ í#õëzì . ý  ÷	õì:õúïDóA:îì@Ló2úî'÷	î'ú"÷	îòó6êrîòö0ëzïïDë\ðò:ýCB«ó:íCDELó
îGF$*ú"÷	ó:öó:÷#÷	ó6êó ôOíó6ìò#õDëzìYëöIHKJML!N8O2îì"êQPSRUTWVYX=îêNó:öJî"ïDíaòíî'íP[\Z DRýQNó6ì]D õòaî
FC^_*ú"÷#ó:ö0ó:÷#÷#ó6êPó ôÑíó6ì"ò#õDëzìPëö`HKJba7cYPSRUTWVYXedL!N8Oöë÷IîïïfFC^BòPí"î'ígFC^3hM#KJjiJ =lk FýXþ?÷#ó:ð_ÿ'î
îì"êmXõíó:÷$òNëðíî'íPí"órú÷	õDë÷	õDí#õ:ó6êVêNó:öJî"ïDíïDëøzõ`õìùó6òí#õDøzî'íó6ê õMìn?Ñó+ í#õDëzì . ùOõDëzïMî'íó6òí"õò
ú"÷	õMì:õDúïDóýo'ë\ðó:ùó:÷Y*  ÷3õì:õDúïó&?õòIìNëíIùÑõDëzïî'íó6ê7OñPî:ïDëzò#ó6ïDñR÷#ó6ïMî'íó6ê7ú"÷	õDë÷3õDí#õ:ó6êPêNó:ö0îïDíIïDëøzõ
í"î'í÷#ó:úïî ó6òî'ú"úïõ:î'í#õëzìðõDí$ìNëzì4»êNó:öó6î'íp#Kqõìí#îìNó6ìr* ,+---= ýs ê"ó:ö0î"ïíPSRUTWVYXõMòutwvKx+vyzvt7{|
DõöSD~}k PWTHý&Nó:÷#ó:ö0ë÷#óõDíEõòEìNëíEõìrøó6ìNó:÷	îï]í"óI:îòóí"î'í<ïDó ôNõ ëø÷	î'úõêNó".ì"õDí#õëzì"òëö
ú"÷#ó:ö0ó:÷#÷#ó6êìNó6ò#ò?ðëïêùOõëzïî'íó  ÷	õì:õDúïDó3ý4'ëð?ó:ùó:÷+*ð?óALó6ïõDó:ùóí"î'íþ?÷#ó:ðÿ¥îîì"êõDíó:÷Ið?ë"ïê
ìNó:ùó:÷#í"ó6ïDó6ò#òg.ìêí"õòIêNó".ìõDí#õDëzìPëöiú"÷#ó:ö0ó:÷#÷#ó6êó ôÑíó6ì"ò#õDëzì"ò& ë"ìíó:÷3õìíõDí#õDùóý
o B>ó:í7J k cYR_"V	LR4V36LR_W4VWdbîì"êN k c3YdzýB«ó:íLó`î}ò#í÷	õ íPíëí#îï
ë÷	êNó:÷8ëzìJ ò!bí"î'íR_"V	RU1V3îìêRU4V3R W4VWý"óRêNó:öJî"ïDíEíNó:ë÷#ñQHKJL!N8O$"îò8í»ð?ë
ó ôÑíó6ì"ò#õDëzì"ò+*DC¡ k£¢ |6#¤cY6L!Yd = îì"êD&¥ k£¢ |6#¤c3W6L!Yd = ýg&NóEó ôOíó6ìò#õDëzìMDA¡êNó:ö0ó6î'í#ò6RV	Eîì"ê
R W4VW6*îì"êD ¥ ê"ó:öó6î'í#òuRU1V3.ýXþ?ó+:î"òóD ¡ êNó:ö0ó6î'í#ò_íNóAõDøNó6òíIú"÷3õDë÷	õDíÕñRêNó:öJî"ïDí6R"V	fîìêD ¥
êNëOó6ò_ìNëí*"ëzìïDñD ¥ õò_îu*ú"÷#ó:ö0ó:÷#÷#ó6êó ôÑíó6ì"ò#õDëzì7ëöHKJL!N8O3ý
¦
§ óLó6ïõDó:ùó`í"î'í$õMìVíõòó ôÑîûaúïDó*fþ÷	ó:ð_ÿ¥îîìênXõDíó:÷$ð?ë"ïê~ðFîìíD ¡ íë]Lórí"óëzì"ïDñ¨u
ú"÷#ó:ö0ó:÷#÷#ó6ê$ó ôOíó6ì"ò	õDëzìLó+:î"òó<í"ó@ëzì"ïDñ7 ëzì1©.õ) íõò>Ló:í»ð?ó:ó6ìR 1V3îì"êR W1V*îìê7íNó@ú÷	õDë÷	õDíÕñ
ëöRU1V3rõòC"õDø"ó:÷6ýuKíEòó:ó6ûaòEí"î'íEí"óIªNó6ò#í#õDëzìî'íA"îì"êõòíNóaûaó6îì"õìNøëö?ú"÷	õDë÷	õí#õDó6òõMì:îò#ó6ò
ð&Nó:÷	ó_êNó:ö0îïDí#ò]í"î'íXî'÷	óïDó6ò#òHêõD÷#ó+ í#ïDñ2êNó:÷	õDù'î	ïDó>"îùóîA"õøNó:÷]ë÷Hó+ª0"îï"ú"÷3õDë÷	õDíÕñýoB>ó ôÑõ ëø÷3î'ú"õ
 ëzûúî'÷3õòëzì<øzõùó6ò>ëzìNó?ûó6îì"õì"ø4*¥îùó:÷#ñ@ì"î'íN÷3îïëzìNóFõìEëN÷,ëúõì"õDëzì*YNí,þ÷	ó:ð_ÿ¥îîì"êuõDíó:÷iòó:ó6û
íëaðFîìííëRõDøzìNë÷#óEí"óu"õDøNó:÷Iú÷	õDë÷	õDíÕñýKìòíó6îê7ëöiîê"êN÷#ó6ò#ò	õìNøþ?÷#ó:ð_ÿ'îaîì"ê«õDíó:÷+¬jò> ëzì ó:÷	ìMñ
êNó:ùÑõò#õì"øìNó:ðêNó".ìõDí#õDëzì"ò>ëöú"÷#ó:ö0ó:÷#÷#ó6ê2ó ôÑíó6ì"ò#õDëzìò*zõDíW ë"ïêLó?îê"ê"÷#ó6ò#òó6êOñ@ìNëí"ò#õì"øú"÷	õë÷	õDí#õDó6ò
í"î'íEú"÷	ëOê ópì"õìíó6ì"êNó6êG÷#ó6ò"ïDí#ò6ýKöî÷#ó6ò#í÷	õ í#õDëzìríëUêNó:öJî"ïDí#òðõíïõDíó:÷	îïhú"÷#ó:÷	ó+ª"õMò#õDíó6òfîì"ê
 ëzì:ïò#õDëzì"òFõòIûaîê"ó*"í"õò> ë"ïMê7BóEêNëzì"ó<ò#õûúïñIñ³÷#ó+ª0"õD÷	õì"ø8í"î'í­¤R¯®V°rFA­^RU®^V°r^.ð&"ó6ìNó:ùó:÷
° k ­ ^ ý  ÷	õDë÷3õDí#õDó6ò>"òó6êUõì7í÷	îì"ò	ïî'í#õìNøaõìNó:÷	õDí#îì óEìNó:íÕðë÷	ÿOòíëRú"÷3õDë÷	õDí#õ:ó6êêNó:öJî"ïDíïDëøzõföK"ï±.ïï
í"õòF÷	ó+ª"õ÷#ó6ûó6ìíu#Kqõìí#îìNó6ìr* ,+---= ý

²´³¶µ·´¸S¹4º»`¼	½;·e¸`¼
§ ó«"îùóPú÷#ó6òó6ìíó6ê}îríNë÷	ëNøYîì"îïDñÑò#õò8ëöíNó7 ëzûúïDó ôNõDíÕñbëöíN÷	ó:ó³ùó:÷	ò	õDëzì"ò2ëö_ú"÷	õë÷	õDí#õ:ó6ê
êNó:öJî"ïDí>ïëøzõ	*\øzõùOõì"øI÷#ó6ò"ïDí#ò«í"î'í>úïMî óXíNó6òó?ïDëøzõ:ò,õìEíNóúBëzïñOìNëzûRõîï	"õDó:÷	î'÷!ñ*îì"ê8îì"îïDñ06õìNø
íNóª0Nó6òí#õDëzìëöLõìí÷	î í#î	õïMõDí»ñ8ùó:÷	ò"ò]í÷3î í#î	õïõDíÕñ@ö0ë÷XòñÑìí#î í#õ):îïïDñ2÷#ó6òí÷	õ íó6ê:ïîò#òó6ò]ëöLêNó:öJî"ïDí
íNó:ë÷	õó6ò:ý
"ófûRîõì÷#ó6ò"ïí#òú.ïî ófíNóEú"÷#ëúLëzò#õDí#õëzì"îïù'î'÷	õîìí#òFëöhíN÷#ó:óEøó6ìNó:÷	îïLö0ë÷	ûaîïMõ6î'í#õDëzì"òFëö,ú"÷	õ±
ë÷	õDí#õ:ó6êêNó:ö0îïDíf÷#ó6îòëzì"õì"ø4*«íNóRïDëøzõ):ò$ñ`þ?÷#ó:ð_ÿ'î# ,+--32= îì"êþ?îîê"ó:÷@îì"ê'ëzïï"ìêNó:÷p# ,+--.=
í"î'í_î'÷#óuîòó6êëzì7íNó<ò#ó6ûaõ ëzì"òí÷! í#õDùóEêNó".ì"õí#õDëzìPëö,ó ôÑíó6ì"ò#õDëzìò*Nîì"ê$îö0ë÷	ûaîïõ6î'í#õëzì³íî'íõò
îòó6êëzì7ïó ôÑõ ëø÷3î'ú"õ$ ëzûúî'÷3õòëzìr*ÑëzìíNóEïDë\ðó:÷ïó:ùó6ïòFëö,í"óúLëzïDñÑìNëzûaõMîï6"õó:÷	î'÷ñýlsòIíNó
÷	ò#í,íÕðëEö0ë÷	ûaîïõ6î'í#õDëzì"òo:ïDëzòó6ïDñ<÷	ó6òó6ûu.ïDóó6î!ëíNó:÷+*õDíhõMò,ìNëí]ò"÷#ú"÷	õò	õìNøIí"î'íiúLëzïDñÑìNëzûaõîïí#õûó
¾3¿+À

ÁÂ6ÃSÄwÅÆÇ6È±ÉÊÂ6ËpÌ`Í4ÈÂ6Í4È±É1ÈÎYÆÏÐÆwËÑ4ÒÅÉÓ´ÂfÔÈÕ1Ö
×9ØÙÚÛÜÙ	×ÝÞÚÛßáà×¤â`àà+Ú×ã4à&ä4à+åÝÛÝÞÚpæØÞßÜà+çIÛÞèá×ã4à+Û9à×¤â`ÞèéÞØ!çIÙÜÝê+Ù	×ÝÞÚÛWà"ë1ÝÛ×ìWí&ã4àØà&Ù	ØàÙÜÛ9Þ
æáÞÜî1Ú4ÞçIÝÙÜo×Ýçà×9ØÙÚÛÜÙ	×ÝÞÚÛC×9ÞÙÚäGèéØÞç~ïà+Ý×9àØ+ðUÛuä4àèKÙñÜ×AÜÞòÝå	ìíãàI×ãÝØä@èÞØçIÙÜ)Ýê+Ù	×ÝÞÚró
×ãÙ	×ñÛ9à+ÛÜà"ë4Ýå"ÞòØÙ	æãÝåå"Þçæ6Ù	ØÝÛ9ÞÚ×9ÞGÛ9à+Üà+å"××ã4àæØàèéàØØà+äà"ë1×9à+ÚÛÝÞÚÛóÝÛÚ4Þ×pØà+äñåÝß6Üà×9Þ
ïà+Ý×9àØ+ðUÛ`äàèÙñÜ×`ÜÞòÝåÝÚIæáÞÜî1Ú4ÞçIÝ)ÙÜ4×ÝçàpôKñÚä4àØ`×ã4àÛ9×ÙÚäÙ	Øä¶å"ÞçæÜà"ë4Ý×îõ;×ã4àÞØà×Ý)åÙÛÛñçæ4õ
×ÝÞÚÛ+ì ö
÷ ÚÙÚÙÜî1ÛÝÛÞèo×ã4àAå"ÞçæÜà"ë4Ý×¤îÞèo×ã4àCä4à+åÝÛÝÞÚ¶æØÞßÜà+çIÛgÝÚ7Û9î1Úw×Ùå"×Ý)åÙÜÜî¶Øà+Û9×9ØÝå"×9à+äåÙÛà+Ûó
èÞÜÜÞYâÝÚ4ò$à+Ù	ØÜÝàØSâ`ÞØøpß0îùAÙñ4×9ê&ÙÚä¶ú0à+ÜçIÙÚMôüû+ýý1ûYöSÙÚäú1×ÝÜÜçIÙÚ«ôüû+ýý	þwö!ó4Ýäà+Úw×Ý±ÿ6à+ÛW×ã4àà áà+å"×
ÞèæØÝÞØÝ×Ýà+ÛgÞÚM×ã4àußáÞñÚäÙ	Øîßáà×âàà+Ú×9ØÙå"×Ù	ßÝÜ)Ý×îÙÚäÝÚw×9Ø!Ùå"×Ù	ßÝÜÝ×¤î¶Ý)Ú×ã4àuæØÝÞØÝ×Ýêà+ä àØ9õ
ÛÝÞÚÛ>ÞèW×ã4àuä4à+åÝÛÝÞÚæØÞß6Üà+çIÛì mÝ×ã«æØÝÞØÝ×Ýà+Û`×ãÙ	×&×9Þ×ÙÜÜî7ÞØäàØ×ã4àuä4àèKÙñÜ×Û&ÙÚäMåÜÙÛÛÝåÙÜ
æØÞæáÞÛÝ×ÝÞÚÙÜ4Øà+ÙÛÞÚÝÚ4òA×ãÙ	×ÝÛ`×9ØÙå"×Ù	ßÜàóèÞØ`à"ë4ÙçæÜà&â&Ý×ã &ÞØ!ÚåÜÙñÛ9à+ÛSÞ	Ø õÜÝ×9àØ!ÙÜ6åÜÙñÛ9à+Ûó
Øà+ÙÛ9ÞÚÝÚ4òÝ)
Ú 
Øàâø	Ù1ðUÛpÙÚäÝ)
Ú 
gÙÙä4àØIÙÚ
ä &ÞÜ)ÜñÚä4àØYðUÛAÜÞòÝåÛÝÛæfÞÜî0Ú4ÞçÝÙÜW×Ýçàì 4ÞØ×ã4à
èÞØçIÙÜÝê+Ù	×ÝÞÚ7Þè´æØ!ÝÞØÝ×Ýêà+ä¶ä4àèKÙñÜ×gØà+ÙÛ9ÞÚÝÚ4òp×ãÙ	×&ñÛà+Û>Üà"ë1Ý)å"ÞòØÙ	æãÝå$å"Þçæ6Ù	ØÝÛ9ÞÚró1×ã4àÛÙçà
ÙÛÛñçæ×ÝÞÚÛgî1Ýà+Üä7×9Ø!Ùå"×Ù	ßÜàAØà+ÙÛÞÚÝÚ4òÞÚÜîèÞØ×ã4àuÛÞ	õåÙÜÜà+ä ÞØÚMäàèÙñÜ×Û>ÙÚäßÙåøòØÞñÚä
×ã4àÞØÝà+Û&â&Ý×ã4Þñ4×äÝÛ 9ñÚå"×ÝÞÚróÙÛâ`à+ÜÜ´ÙÛÚÞØçIÙÜeäàèÙñÜ×Ûâ&Ý×ãÞñ4×æØàØà ñÝ)ÛÝ×9à+ÛÙÚääÝÛ ñÚåõ
×ÝÞÚrì  ã4à+ÚÙ	ØßÝ×9ØÙ	ØîMæØÝÞØÝ×Ýà+Û$Ù	ØàÙÜ)ÜÞYâà+äró´Ý)ÚGÙÜÜW×ã4ØààÜÞòÝåÛCØà+ÙÛ9ÞÚÝÚ4ò«ÝÛC×9Ø!Ùå"×Ù	ßÜàIÞÚÜî
â&ã4à+ÚQä4àèÙñÜ×ÛIÙ	ØàÞè×ãàMèÞØ
ç $èÞØÜÝ×9àØ!ÙÜÛ CÙÚä]×ãàMßÙåøòØÞñÚä×ã4àÞØ!Ýà+ÛÙ	ØàÛ9à×ÛÞè
ÜÝ×9àØ!ÙÜÛì


"!$#&%(')*,+.-/*102*(#4365

íãÝ)ÛrØà+Û9à+Ù	Øå!ãuâgÙÛeçÙÝÚÜî$åÙ	ØØÝà+äAÞñ4×´Ù	×´×ã47à à+ÜÛÝÚ4ø19Ý 8Ú:Ý àØÛÝ×î$Þè4íeà+å!ãÚ4ÞÜÞòîuÙÚä$ÿ6ÚÝÛã4à+äCÙ	×
×ã4à;8ÚÝ<àØÛÝ×¤îÞè=8Üçbâ&ãÝÜàWèKñÚä4à+äAßîC×ã4à>ú1>
?9A@Þè0×ãàCBà+ñ4×Ûå!ã4à;ÞØÛåã0ñÚ4òÛòà+çà+ÝÚÛå!ãÙ	è×ì
GàòØ!Ù	×9àèñÜ)ÜîGÙåø1Ú4ÞYâ&Üà+ä4òà×ã4àòà+Ú4àØÞñÛÛñ4ææáÞØ×CÞèg×ã4
à oÝ)ÚÚÝÛ
ã D>ñÜ×ñ4ØÙÜ ÞñÚäÙ	×ÝÞÚÙÚä
×ã4Eà WÝÚÚÝÛã ÷ åÙäà+çuîÞèlú1åÝà+Úå"àAÙÚä Fà×9×9àØÛ&×ãÙ	×&ã4à+Üæfà+äå"ÞçIæÜà×ÝÚ4òp×ãÝ)Ûgâ`ÞØøfì
GàA×ãÙÚ4ø×ã4àCèÞñ4Ø>ÙÚ4ÞÚî0çIÞñÛ>ØG
à 1ÝàâàØÛgèéÞØ>æáÞÝÚ×ÝÚ4òÞñ4×Û9ÞçIàCàØØÞØÛgÙÚä7èÞØ&ÙHä 1Ýå"à$ÞÚ
Øà+Û9×9Ø!ñå"×ñ4ØÝÚò×ã4àÙ	Ø×ÝåÜàIÙÚä@ÞÚÝÚåÜñäÝÚ4òØàèéàØà+Úå"à+ÛC×9Þ«Øà+ÜÙ	×9à+äâ`ÞØø@ÝÚú0à+å"×ÝÞ
Ú I0ì ÞÜòàØ
J èà+ÝèàØ>æØ"
Þ 0Ýäà+ä 3ÙÜñÙ	ßÜàCÙÛÛÝÛ×ÙÚå"àuÝÚ7æØÞÞèéõ;Øà+ÙäÝÚò4ì
KML=NOL=PAL/QCR1L/S

gÙÙä4àØ+ó	ìóCTUÞÜÜñÚä4àØ+ó7
ìôüû+ýý9?ö!ì J ØÝÞØ!Ý×Ýà+ÛÞÚQä4àèKÙñÜ×ÛpâÝ×ã æØàØà0ñÝÛÝ×9à+ÛóSÙÚä×ã4à+ÝØ
Ù	ææÜÝåÙ	×ÝÞÚÝÚA×9Øà+Ù	×ÝÚ4òÛæfà+åÝÿ6åÝ×îCÝÚu×9àØçIÝÚÞÜÞòÝåÙÜwäàèÙñÜ×eÜÞòÝå	ìWV1XZY1[]\W^Z_=XO`7abYHcXZd^9cfehg
i ej^kGXZ\=l\,m
ó nAooôüûYö!Wó prû q(I9s0ì

gÙÜu
å Ù	t ê+Ù	Ø+>ó v4uì Flì$ó Bwxt Ù	ê$ó yìzó T|{$Ù	ßÙ	Ø/Ø Þ4t zó v4ìSôüû+ý9ý ?ö!ì }Wc[]Y=~cY1[O^9_XZdW_:eh9lc!ìú0æØÝÚòàØ9õ àØÜÙ	ò4ó

àØÜ)ÝÚrì

à+Ú1fõ SÜ)ÝîÙãñó´ïAì>
ó TBà+åã×9àØ+ólïAìôüû+ý9ý Iö!ì BàèÙñÜ×AØà+ÙÛ9ÞÚÝ)Ú4ò«ñÛÝÚò«åÜÙÛÛÝåÙÜSÜÞòÝå	ì ab[]cl C~l^Z_
r\Wcfe__l:m,eG\W~rez
ó gôüûõ ö!óoûû 6q6û ?	þ1ì

Øàâø	Ù1.
ó {ìSôüû+9ý sýö!ì J ØàèéàØØà+äGÛñ4ß×ã4àÞØ!Ýà+GÛ ÙÚ@à"ë1×9à+Úä4à+äÜÞòÝåÙÜoèéØ!Ùçàâ`ÞØøèÞØAä4àèKÙñÜ×Øà+Ù3õ
ÛÞÚÝÚ4ò4Cì y Ú 	[OX6~rehehgZl\,mZkXO`c1ewnn9cr\/cfeG[r\W^AclXZ\4^Z_>V1XZl\/cXZ\`e[je\W~]eXZ\ab[cl C~Gl^Z_4r\/cfeG_
_l:m,e\4~re"óææìrûZ
þ p6q6ûZþ psBà×9ØÞÝ×/ì ÞØòÙÚMùuÙñ4èçÙÚÚ J ñ4ß6ÜÝÛã4àØ!Ûì

Øàâø	Ù1
ó {ì1ôüû+ýý pö!ì ÷ ääÝÚò>æØÝÞØÝ×Ýà+ÛÙÚäÛ9æáà+åÝ±ÿ6åÝ×¤î×9Þ$ä4àèKÙñÜ×eÜÞòÝå	Aì yüÚ ÙGå Ý)ÛãrAó Dìó J à+Ù	Ø!å"àó
Bì/
ó TÞÚÝê J àØà+ÝØÙ11ó Flìô SäÛ+ì ö!=ó zXjm9l~El\ a[]cl C~Gl^Z_/r\/cfeG__lm(e\W~]e ¡¡[¢X~rerejgZl\,m9kXO`£c1e¤/c



¥¦§

¨©:ªH«"¬Wª=­Aª

® ¯1°O±r²=³j´Zµ·¶±Z°r¸6¹hº1±r²»A®7¼&½¢¾¿ ÀGÁHÂÃÄHÅ(Æ9Ç9ÆÈ<ÉÊzËÌÍjÎHÏjËÃÄ9Í¢ËÐ;È<ÉÑÏjÍjÈÒWÌGÈ<Ó9Ô1ÕOÉ,Í¢ËÔ<Ô<È:Ö9ËÉ=ÌË9Â,×=×$Å
	
ØÙ,ÚÛ(Ø9ÜZÝÞ Ä9Ïjß4Â/àCÉHÖAÔ<Ó9É=áuÅ/â(×/ÏhÈ<ÉHÖ9ËGÏ¢ãäËGÏrÔ<ÓZÖHÅ
å;ÏjËGæ¤ßZÓ1Â	çwÅ:ÂCèUà7È<Í¢ËGÏÂCé£ÅêOëì9ì9ÆAírÅ·îïÏjËGðËGÏjÏjËáñÓ9É/Ð¢æCËGÏÐ¢ËGÍjÐðÄ9ÏËò1Í¢ËÉ=áHËáóÔ:Ä9ÖAÈôÌ×/ÏjÄ9Ö9ÏhÓ9õÐGÅñÕOÉ
ö ÄA÷=ÉuÂÑEÅbçwÅ:Ââ1Ìh÷(ÎHøùËGÏjÍGÂÊïÅ¤úÅ:Âûèüâ1÷/ÓZ×/È:ÏjÄHÂ£â4Å ö ÅEêà7á/ÐGÅírÂEý¡°]þµWÿþ ²  ³¹ ± µ4
±   	³ 
,³
³²W°j³]¹³
µ 
´ þ±Zµ´Z
µ ¤³j´Z¹±Zµ=þ
µ 
;ý	°O±ÿ]³h	³ Zþ
µ 
Z¹± º1
³ Wþ º½r
µ f³°]µW
´ þ±ZµW´  ±Z
µ ³°j³µWÿ]
³  
¿
À !#"Â/×=×zÅHÆ Ü6Û ì Ú é&ÏjËÉÍ¢ÄHÂ/ÕÍjÓ9%Ô $9
Å &Ä9ÏjÖAÓ9ÉúûÓ9ÎHðõÓ9É=É îCÎHø/Ô<È<Ðh÷HËGÏhÐGÅ
å¡Î=ÌGÌGÓZðÎHÏjÏhÈÂ(';Å:Â;Ê$ËGÄAÉHË9Â;ÃEÅ:Â¡è*)Î=Ô<Ô<ÄHÂ>î.ÅêOëì9ì9ÆAírÅ,+È<Ð.-jÎ=É=ÌÍjÈ%/9Ë Ä9ÏháHËGÏhËáÔ<Ä9ÖAÈ<Ì0 ÐjËõÓ9ÉÍjÈôÌGÐÓ9É=á
Ëò1×=ÏjËÐhÐj%È /9ËÉHËÐjÐÅ¤Õ É ö ÄA÷=É$ÂWÑÅuç Å:Âzâ1Ìr÷,Î=ø4ËGÏhÍGÂ4Ê7ÅWúÅ:Âuè âH÷=ÓZ×/È:ÏjÄHÂuâ4Å ö Å.êà7á/ÐGÅírÂzý¡°]þµWÿþ ²  ³¹
± 1µW

±   2³ 
(3
³ ¤³ ²W°¢³¹G³G
µ 
´ þ±Zµ ´Z
µ 4¤³h´¹±9µ=þ
µ 
ý	°O±6ÿr³h	³ Zþ
µ 
Z¹ ± 5º1³5/þ%6º½rµf³G°rµ4´þ±9µW´ 
 ±9
µ G³G°¢³GµWÿr4
³ .  ¿ 6
À !#""Â=×/×$Å Ù ëÆ ÛÙØ ìé&ÏjËÉ,Í¢ÄHÂ/Õ ÍjÓ9%Ô $9
Å &Ä9ÏjÖAÓ9ÉúEÓ9ÎHðõÓ9É=É î7ÎHøWÔ<È<Ðj÷HËGÏrÐGÅ
â Ìh÷=Ó9Î=ø$ÂCé£Å(8ÅêOëì9ì Ú írÅ ö ÄAõ×/È<ÔôÈ<ÉHÖÏhËÓ9Ð¢ÄAÉ=È<ÉHÖMæÈ<Íj÷ñÓ9É=áóÓZøùÄAÎHÍw×=ÏjËGðËGÏ¢ã
1
ËÉ/ÌËÐ¤È<É,Í¢Äwá=ËGðÓ9Î=Ô<Í;Ô:Ä9ÖAÈôÌZÅ&ÕOÉý¡°¢±ÿr³r³2Zþµ
Z¹±º1³:9;º½rµf³°]µW´þ±ZµW´  »1±9þµ  ±Zµ³°j³µWÿ]³±9µ
¾°<þ =CÿGþ´  ½rµf³ . %þ 
,³GµWÿr³GÂH×=×$Å$ë Ü Æ Û ë Ú"Ù ÃÓZÖ9>
Ä $AÓ1?
Â 7ÓZ×/Ó9Éu@
Å &Ä9ÏjÖAÓ9ÉúEÓ9ÎHðõÓ9É=É î7ÎHøWÔ<È<Ðj÷HËGÏrÐGÅ

+bËÔ:Ö9ÏhÓ9É=á=Ë9Â7=Åïî&Å:Â;è

+bÄ6æÔôÈ<ÉHÖHÂAÅ';Å:Â1è

çÓ9Ô<Ô<È<ËGÏÂ7HÅ8EÅùêOëì9Æ Ù írÅzÊzÈ<É=ËÓZÏ¢ãÍjÈ<õË¤Ó9Ô:Ö9Ä9ÏrÈ:Íj÷=õÐðÄ9Ï7Í¢ËÐjÍjÈ<ÉHÖEÍj÷=ËÐjÓZÍjÈ<ÐOÒ4ÓZø/È<Ô<È:ÍB$
Ä9ð>×=ÏhÄ9×4ÄAÐhÈ:ÍjÈ:ÄAÉ=Ó9ÔC8Ä9ÏhÉ ðÄ9ÏhõÎ/Ô<ÓZË9Å	»1±9¯(°]µW´  ±b¼$±	
9þÿEý¡°¢±2
9°¢´DEDwþµ
9ÂF9&êÇAírÂ Ø9ÜAÚÛ(Ø Æ Ù Å

àïÍj÷=ËGÏhÈ<ÉHÖ9Í¢ÄAÉuÂ+ÅA Å>êOëì9Æ Ú írÅG'HÄ9ÏhõÓ9Ô<È%HÈ<ÉHÖÉ=ÄAÉ=õÄAÉHÄ9Í¢ÄAÉ=ÈôÌ£ÏjËÓ9Ð¢ÄAÉ=ÈôÉHÖÐ$1Ð¢Í¢ËõÐGÅ¤¾b°#þ =;ÿGþ´  ½rµf³ JI
 %þ 
,³µ4ÿr³
Â K9&êOë6írÂ Ù ë Û Æ(
L ÅCà7ÏjÏhÓZÍjÓÈôÉM/9ÄAÔ<Î=õË3KÁWêÇAírÂW×/ÓZÖ9Ë Ç9ìL(Å
à(/9ËÉ$Âwâ4Å:ÂÕÍjÓ9ÈÂ ÑEÅ:Âwè
âH÷=Ó9õÈ:ÏÂÑEÅwêOëì Z
Ä ðÍjÈ<õËGÍjÓZøWÔ:Ë2Ó9É=áõ Î=Ô:ÍjÈã
Ú Ü írÅONÉ Íj÷HË ÌÄAõ×/Ô<Ëò1È:ÍB$ 9
ÌÄAõõÄ(á/È:ÍP$RQ/Ä6æ ×=ÏjÄ9ø/Ô<ËõÐGÅS1½¢¾T H
» ±Z¯1°]µW´  ±  ±D²W¯Uþµ
AÂV;.ê Ù rí Â Ü ì1ë Û1ÚÝ Ç(Å
çbË#WuÉHËGÏÂX8EÅ:Â1è î.ËÓZÏhÔÂU7HÅùêOëì9ì Ø írÅ ö ÄAÉ/á=È:ÍjÈ:ÄAÉ=Ó9Ô1ËÉ,ÍjÓ9È<Ô<õËÉÍY0>ø=ÏhÈôáHÖAÈ<ÉHÖÍfæ;ÄwÓZ×=×=ÏjÄAÓ9Ìr÷HËÐ7Í¢ÄwáHËGðÓ9Î=Ô:Í
ÏhËÓ9Ð¢ÄAÉ=È<ÉHÖHÅC¾°<þ =CÿGþ´  ½rµf³ . þ%
,³GµWÿr³GÂZ;K.ê Ø ãÇAírÂ ØZÝ ì Û(ØÙ9Ù Å
çbÄ9Í¢ÍjÔ:Ä9øzÂbç Å£êOëì9ì Ø írÅ ö ÄAõ×/Ô:ËòHÈ:ÍP$ ÏjËÐjÎ/Ô:ÍjÐðÄ9Ï
 
± D²4¯X´6þ±Zµ/Â\êÇAírÂùÇ9ì ÚÛÙØ L(Å

É=ÄAÉ=õÄAÉHÄ9Í¢ÄAÉ=ÈôÌÔ:Ä9ÖAÈ<ÌGÐÅ

»1±9¯(°]µW´  ±¼z±2
9þÿ

8Ä9ÏjÍP$9Â?7HÅ['CÅ>êOëì9ì Ù írÅbâ(ÄAõËá=È:ÏjËÌÍ¤Íj÷=ËGÄ9ÏhÈ:ËÐ¤Ä9ðïÉ=ÄAÉ=õÄAÉHÄ9Í¢ÄAÉ=ÈôÌûÈ<É=÷HËGÏrÈ:ÍjÓ9É=ÌË9Å7ÕOÉç£ÓZø=ø/Ó$9ÂC+

´Zµ[

Å&2Å:Â

8Ä9Ö9Ö9ËGÏÂ ö Å?7HÅ:Âuè])¤Ä9ø/ÈôÉ=Ð¢ÄAÉuÂ7=Å4ÑÅêà7á=ÐGÅírÂZ^´Zµ_h±±¸±û¼$±2
Aþÿþµ¾°<þ =CÿGþ´  ½rµf³ . þ
(³µWÿ]³

´9
µ ¼$2± 
Aþÿûý	°O±	
9°¢´DED þµ
a`±Zµ@D±ZµW±±9µ=þÿb¤³j´¹G±Zµ=þµ
´Zµ[dc&µWÿ]³°#´Zþµ4¤³h´¹±9µ=þµ
9Â4äÄAÔÅ/Ç(Â
×/×$Å$ë9ë9ë Û ëÆ Ú Å ö Ô<ÓZÏjËÉ=á=ÄAÉ î7ÏjËÐjÐGÂNbò(ðÄ9ÏháuÅ
úûÓ9ÎHÍH9Âa8EÅ:Â	è â1ËÔ<õÓ9ÉuÂ	åbÅêOëì9ì1ë6írÅe8bÓZÏhá
½r
µ f³ . %þ 
,³GµWÿr³GÂ/Á/À.êOë]ãÇAírÂ ØÙ Ç Û(ØAÚ ì(Å

×=ÏjÄ9ø/Ô:ËõÐðÄ9ÏÐjÈ<õ×/Ô:ËáHËGðÓ9Î=Ô:ÍÍj÷HËGÄ9ÏhÈ:ËÐGÅ

ú£ÏjËÉ,Í¢ËÔÂ[&ÅA Å>êOëì9ì Ø írÅçbËÉHËGÏrÓ9Ô<È%HÓZÍjÈ:ÄAÉ=ÐÄ9ðfNb×=Íî
 
± D²4X
¯ f³G°4ÿþ³GµWÿr³GÂ&ÀUhùê Ø írÂ.ëÆ9Ç Û ëì9Æ(Å

¾b°<þ =Cÿþ´ 

Í¢ÄÍj÷=ËE×ùÄAÔ%$1ÉHÄAõÈ<Ó9Ôu÷=È<ËGÏhÓZÏhÌh÷$9Å5gzº1³j±9°¢³þÿr´ 

ÊzÈ<ðÐjÌr÷=È:ÍH9Â1ä ÅzêOëì9ÆLAírÅ ö ÄAõ×/Î=ÍjÈ<ÉHÖwÌGÈ:ÏhÌGÎ=õÐhÌÏhÈ:×=ÍjÈ:ÄAÉ$Å$Õ 
É 7AÄAÐj÷=ÈÂ1ÑÅzêà7áuÅírÂWý	°O±ÿ]³h³	Zþµ
Z¹ ±ºH³À6º
½r
µ f³°]µW´þ±ZµW´  »1±Zþµ  ±Zµ³°j³µWÿ]³±Zµñ¾°<þ =CÿGþ´  r½ µf³ i þ%
,³µ4ÿr³Â;×=×$Å¤ë Ø ë Û ë ØAÚ Ê$ÄAÐÑÉ=Ö9ËÔ:ËÐGÅ
&Ä9ÏjÖAÓ9ÉúûÓ9ÎHðõÓ9É=É î7Î=ø/Ô<È<Ðj÷=ËGÏhÐGÅ
&ÓZÏjËGßWÂ4ä

Å AÅ:Âùè ézÏhÎ/Ð H#Ì HY$GÉ/j Ð¢ß(È

Â &Å>êOëì9ì9ÇAírÅk`±Zµ@D±ZµW±6±Zµ=þÿ ¼z±2
9þÿl
¹G±Zµ=þµ
9Å¡â(×=ÏhÈ<É=Ö9ËGÏ¢ãäËGÏhÔ<ÓZÖHÂ=å;ËGÏhÔ<ÈôÉuÅ
p>qlr

 ±Zµf³	6 Inm

³ ²H³µ[³µo³j´ I

sStuovw>xyz{|}t~EfUztUz{Xzlx6x~2U@w2{t[zX

l22U

]	Y @¡3¢2#%£@2%¤6¥§¦¨§©i¤	¡O¤©:¥U¤6¥UªP¡«¤6¥U¤¤6¥@2¬¢¤6¥¥U­U¯®°<±² ³f´²µ¶

·¸±P¹#¶.¶J²%º¹Y¸´¹Y»¼½<ªB¾6C¾6¿¦À
¤¤2¬Á(Â6RÃ¬¡3¥2YÄF#¤6¥@¢	ÅU¬Y	2%¤6¥¢a¤6¥Æ¥U¤6¥@¡«¤6¥U¤¤6¥EÄ%¤­6E®k°<±² ³f´Y²Çµ¶Z·¸±P¹Y¶i¶È²iÉ
º¹#¸´<¹#ËÊÌlË¿Âl¦ÎÍU
Ï%¬¡«¬ÄPX
Ð [Ñ%?ÒÓÃX¡«¤6¥¢YÔVFÕ6:ÖF×RY¬¥k¡«£Ä¬¡«¬¥22¤6¥¤©(2U¬1ØS¬ÄÄªn©.¤6 @¥@ÅU¬Å¥@Å¢22ÙÄ%¬
¡3¤ÅU¬Ä¢¬¡5¥2Y¢}ÑÚ¥ÛU¬Yo§GÖoÅËJSÜ°Ý´¹¹2Þ².¸ºßÝàM±.áU¹â»6ããäæåUÝ².¸±a·¸±P¹Y°¸[µ±²Ý¸µ¶
ç Ý¸àY¹Y°¹Y¸´¹µ¸ÞbèéêaëXÝÎß<²iìXêíÝ¸RîËÝ	º²Ç´ïÜ°Ý2º°µêEêE²i¸º6X£@£Ë¾l¦À6À1ðS¤6¥@¥?ñ¬Y¡3¥òïU¬
ÑòóÔ(2¬¢	¢Y
Áï¬¬Y@ÁôõÄ%¤­6k©.¤GÅU¬Y© @Ä%2¬¢¤6¥¥U­Uf®°#±² ³S´Y²Çµ¶[·¸±P¹Y¶i¶È²º¹#¸´<¹#»6¼V<ªB¾6?X¦À¾
ÁGö¥2¥U¬¥ËVUoÎÍ4Ôo	%¤	%2÷Y¬Åæ U¤¬Y£¢¬¡3«Ä¤­63Ñ¥}YÏ¢2ËF%VÔV¬	#¬Føb%FÒÓ¤ª
¥%÷ïÔV¬Y2¬%	XXù(ÖfÅ@¢YJUîËÝ2º6²´k².¸R®°#±² ³S´Y²Çµ¶X·¸±P¹Y¶i¶È²%º¹#¸[´¹úSÜ°Ý´¹¹2Þ².¸ºß

Ýà±.áX¹û@±.á«üìX°Ý<ëU¹2µ¸

ýÝ°	þ>ß	áÝ<ë§åüfîZ·®ÿ ãûUÏa¤U[À3ö¥ùË¬#2 U	¬:ÏG¤¬¢¥ôa22[YÄCÑÚ¥¬ÄÄ­¬¥@#¬@£@£Ë¾À¾l¦¾ÎÍÕ
(¤Öf¥U­6Ä¥@ÅËÃ£@	¥@­¬YªF¬Y	Ä­U

ÁGö¥2¥U¬¥ËU6VùË¬U#¤­	££@	%¤%2%¬¢F¥«ÅU¬Y© @Ä%fÄ%¤­6Ë®°<±² ³f´²µ¶U·¸±P¹#¶.¶È²º¹#¸´<¹#[»
	6äZÇ¾6
¾¾X¦¾ÕÂ
Áï6¥ËZÆo¾6RÁï¬Y£@2¬¢2¬¥2¥@­MÅ@¬Y©. @Ä2¢
Áa	Ëïk%GÒ

ÃØ2¤6 UY

¢¢¬¥¬¥@#¬¢ØG2	¬Å@ @#¬Å

kÖfÅ@¢YJaÜ °Ý´<¹	¹	Þ²i¸ºß

£@	¤	%PbÑÚ¥æÏa¬YÙC¬ÄÇËð%

Ýàâ±.áX¹¼°ÞÆ·¸±P¹Y°¸µ6±²Ý¸[µ¶

ç Ý¸àY¹Y°¹Y¸´¹

Ý¸æÜ °².¸´Y² ë¶¹<ß5Ýàb¸Ý ¶¹2Þlº¹ï¹Bë[°¹#ßY¹#¸±nµ±²Ý¸¨µ¸Þï¹2µÎßYÝ¸@².¸ºV£@£Ë?ÕÎÍl¦ÕÕæ¡:Ù	ÅU­¬
¢2¢2 ¢¬Y2¢YCâ¤2­6¥ U©¡3¥@¥4Ôf UÙÄ¢	U¬Y	¢Y
Ã2ÄöÄ¡3¥?U

ÑÚR¢

¥U¤R¡b

ÅU¬Y© @Ä%2U¬#¤6¡3£Ä%¬U%P,¤©

Ñ¥æÜ°Ý´¹¹2Þ².¸ºß3ÝàE±.áX¹±.ábµ±²Ý¸µ¶ ç 
Ý ¸à¹#°2¹#¸´<¹5Ý¸

2¬¢2¤6¥@¥U­d¥¨ÅU¬Y© @Ä%RÄ%¤­6

®°<±² ³f´²µ¶?·¸±P¹#¶.¶È²º¹#¸´<¹#[£@£Ë[Â6¿¦Â6¿

ðS¤6¢¤6¥Ë¢2¢2	 @¢¬Y2¢[¤2­6¥: U©.¡5¥@¥4Ôo UÙÄ¢2U¬Y¢Y
òV¥?E:%(Ò*ò2¬ Uf@¾6¨S¤6¥¢	 @#2!¬4ÅU¬Y© @Ä%EÄ%¤­6M¥@Åd2U¬#¤6¥2¤6Ä¤©ÅU¬Y©i¬¢	%ÙÄ%¬
	¬¢¤6¥@¥U­U4Ñ¥ÆÏa¬ @¡3¥¥?VðÖoÅ?JfÜ °Ý´<¹	¹	Þ²i¸ºßMÝàR±.áX¹4»
	±.á
®k°<±² ³f´Y²Çµ¶[·¸±P¹#¶.¶J²%º¹Y¸´¹YU£@£Ë¾l¦À6À"%¬¥¥@X¤6@¥#

$&%('

Ä¬Y

Ò

üìX°ÝëU¹	µ¸
Ã¤6¥¢Y

ç Ý¸làY¹Y°¹Y¸´¹4Ý¸

Journal of Articial Intelligence Research 9 (1998) 367-421

Submitted 7/98; published 12/98

The Automatic Inference of State Invariants in TIM
Maria Fox
Derek Long

maria.fox@dur.ac.uk
d.p.long@dur.ac.uk

Department of Computer Science
University of Durham, UK

Abstract
As planning is applied to larger and richer domains the eort involved in constructing
domain descriptions increases and becomes a signicant burden on the human application
designer. If general planners are to be applied successfully to large and complex domains
it is necessary to provide the domain designer with some assistance in building correctly
encoded domains. One way of doing this is to provide domain-independent techniques for
extracting, from a domain description, knowledge that is implicit in that description and
that can assist domain designers in debugging domain descriptions. This knowledge can
also be exploited to improve the performance of planners: several researchers have explored
the potential of state invariants in speeding up the performance of domain-independent
planners. In this paper we describe a process by which state invariants can be extracted
from the automatically inferred type structure of a domain. These techniques are being
developed for exploitation by stan, a Graphplan based planner that employs state analysis
techniques to enhance its performance.

1. Introduction
Stan (Long & Fox, in press) is a domain-independent planner based on the constraint
satisfaction technology of Graphplan (Blum & Furst, 1995). Its name is derived from the
fact that it performs a variety of pre-processing analyses (STate ANalyses) on the domain
description to which it is applied, that assist it in planning eciently in that domain. Stan
took part in the aips-98 planning competition, the rst international competition in which
domain-independent planners were compared in terms of their performance on well-known
benchmark domains. Of the four planners that competed in the strips track, three were
based on the Graphplan (Blum & Furst, 1995) architecture. The most important dierence between stan and the other Graphplan-based planners was its use of state analysis
techniques. Although these techniques were not, at that stage, fully integrated with the
planning algorithm stan gave an impressive performance as can be determined by examination of the competition results. There is a description of the competition, its objectives
and the results, at the aips-98 planning competition FTP site (see Appendix A).
One of the most important of the analyses performed by stan is the automatic inference
of state invariants. As will be described in this paper, state invariants are inferred from the
type structure of the domain that is itself automatically inferred, or enriched, by stan. The
techniques used are completely independent of the planning architecture, so can be isolated
in a pre-processing module that we call tim (Type Inference Module). Tim can be used
by any planner, regardless of whether it is based on Graphplan or on any other underlying
c 1998 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

Fox & Long

architecture. Tim has been implemented in c++ and executables and examples of output
are available at our web site (see Appendix A) and in Online Appendix 1.
Tim takes a domain description in which no type information need be supplied and infers
a rich type structure from the functional relationships between objects in the domain. If type
information is supplied tim can exploit it as the foundation of the type structure and will
often infer an enriched type structure on this basis. State invariants can be extracted from
the way in which the inferred types are partitioned. The consequence is that the domain
designer is relieved of a considerable overhead in the description of the domain. Whilst it is
easy to hand-code both types and state invariants for simple domains containing few objects
and relations, it becomes progressively more dicult to ensure cross-consistency of handcoded invariants as domains become increasingly complex. Similarly, the exploitable type
structure of a domain may be much richer than can easily be provided by hand. We have
observed that tim often infers unexpected type partitions that increase the discrimination of
the type structure and provide corresponding benets to stan's performance. We therefore
see tim as a domain engineering tool, helping to shift the burden of domain design from
the human to the automatic system.
The usefulness of both types and state invariants is well-documented. Types have been
provided by hand since it was rst observed that they reduce the number of operator instantiations that have to be considered in the traversal of a planner's search space. The
elimination of meaningless instantiations is particularly helpful in a system such as Graphplan, in which the structure to be traversed is explicitly constructed prior to search. We
believe that the benets to be obtained from type inference in planning are similar to those
obtained in programing language design: type inference is more powerful than type checking
and can assist in the identication of semantic errors in the specication of the relational
structure of the domain. Indeed, we have found tim to be a useful domain debugging
tool, allowing us to identify aws in some published benchmark domains. We also used
tim to reveal the underlying structure of the Mystery domain, a disguised transportation
problem domain, used in the planning competition. The Mystery domain is described in
Appendix C.2.
The use of domain knowledge can signicantly improve the performance of planners,
as shown by a number of researchers. Gerevini and Schubert (1996a, 1996b) have considered the automatic inference of some state constraints and demonstrated that a signicant
empirical advantage can be obtained from their use. Kautz and Selman (1998) have handcoded invariants and provided them as part of the domain description used by Blackbox.
They demonstrate the performance advantages obtained and acknowledge the importance of
inferring such invariants automatically. McCluskey and Porteous (1997) have also demonstrated the important role that hand-coded state invariants can play in domain compilation
for ecient planning. Earlier work by Kelleher and Cohn (1992) and Morris and Feldman
(1989) explores the automatic generation of some restricted invariant forms. We discuss
these, and other, related approaches in section 5.
In this paper we will describe the type inference process employed by tim and explain
how four dierent forms of state invariant can be extracted from the inferred type structure.
We will argue that tim is correct since it never infers sentences that are not state invariants.
We will then provide experimental results demonstrating the performance advantages that
can be obtained by the use of types.
368

Automatic Inference of State Invariants

drive

unfuelled 1
fuelled

1

drive

at 1

load

in 1
at

1

unload

Figure 1: A simple transportation domain seen as a collection of FSMs.

2. The Type Inference Module
One way of viewing strips (Fikes & Nilsson, 1971) domains is as a collection of nite-state
machines (FSMs) with domain constants traversing the states within them. For example, in
a simple transportation domain there are rockets and packages, with rockets being capable
of being at locations and of moving, by driving, from being at one location to being at
another, and of being fuelled or unfuelled, and of moving between these two states. at can
be seen as forming a one-node FSM, and fuelled and unfuelled as forming a two-node FSM.
This view is depicted in Figure 1.
369

Fox & Long

Packages can be at locations or in rockets, and can move between these states in the
resulting two-node FSM. In this example, rockets can be in states that involve more than
one FSM, since they can be both at and fuelled, or at and unfuelled. STRIPS domains
have been seen in this way in earlier work (McCluskey & Porteous, 1997; Grant, 1996), as
discussed in Section 5.

2.1 Types in TIM

When two objects participate in identical FSMs they are functionally equivalent and can be
seen to be of the same type. The notion of type here is similar to that of sorts in the work of
McCluskey and Porteous (1997). A primary objective of the tim module is to automatically
identify the equivalence classes that form the primitive types in a domain description and
to infer the hierarchical type structure of a domain on the basis of the primitive types. The
way this is done is discussed in Section 2.3. The primitive types are functional equivalence
classes, and the objects of the domain are partitioned into these classes. Having identied
the types of the domain objects tim infers the types of the parameters of all of the operators.
State invariants are inferred as a nal stage.
The early parts of this process rely on three key abstract data types, the property space,
the attribute space and the transition rule. Formal denitions of these components are
provided in Section 2.3, but we provide informal descriptions here to support the following
denitions. Transition rules represent the state transformations that comprise the FSMs
traversed by the objects in the domain. Property spaces are FSMs, together with the objects
that participate in them, the properties these objects can have and the transition rules by
which they can acquire these properties. Attribute spaces contain collections of objects that
have, or can acquire, the associated attributes. Attributes dier from properties because
they can be acquired, or lost, without the associated loss, or acquisition (respectively),
of another attribute. Attribute spaces also contain the transition rules that enable the
acquisition (or loss) of these attributes. Once the state and attribute spaces have been
constructed we assign types to the domain objects according to their membership of the
property and attribute spaces. Any two objects that belong in identical property and
attribute spaces will be assigned the same type. It is therefore very important to ensure
that the property and attribute spaces are adequately discriminating, otherwise important
type distinctions can be lost. Much of the subtlety of the algorithm described in Section 2.2
is concerned with maintaining adequate discrimination in the construction of these spaces.
We present the following denitions here to support our informal characterisation of the
roles of types in strips and in tim. The denitions are used again in Sections 2.4 and 2.6,
which discuss how types are assigned to objects and operator parameters.

Denition 1 A type vector is a bit vector in which each bit corresponds to membership, or
otherwise, of a unique state or attribute space. The number of bits in the vector is always
equal to the number of distinct state and attribute spaces.

Denition 2 A type is a set of domain objects each associated with the same type vector.
Denition 3 A type vector, V1, in which two distinct bits, si and sj , are set corresponds to

a sub-type of the type associated with a vector, V2, in which only si is set (all other settings
370

Automatic Inference of State Invariants

being equal). Then the type associated with V2 can be seen to be a super-type of the type
associated with V1 .

Denition 4 A type structure is a hierarchy of types organised by sub-type relationships
between the component types.

Denition 5 A type structure is adequately discriminating if objects are only assigned to
state (and attribute) spaces that characterize their state transitions (and attributes).

Denition 6 A type structure is under-discriminating if it fails to distinguish types that
are functionally distinct.

Denition 7 A type structure is over-discriminating if functionally identical objects are
assigned to dierent types.

There are two distinct ways in which types play a role in the specication of a domain.
They can restrict the set of possible operator instances to eliminate all those that are
meaningless in the domain and hence improve eciency by reducing the size of the search
space, and they can eliminate unsound plans that could be constructed if they were not
provided. The following examples clarify the dierence between these two roles. The
untyped schema:

drive(X,Y,Z)
Pre:
Add:
Del:

at(X,Y), fuelled(X), location(Z)
at(X,Z), unfuelled(X)
at(X,Y), fuelled(X)

permits more instances than the typed schema:

drive(X,Y,Z)
params:
Pre:
Add:
Del:

X:rocket,Y:package,Z:location
at(X,Y), fuelled(X), location(Z)
at(X,Z), unfuelled(X)
at(X,Y), fuelled(X)

but all meaningless instances will be eliminated during search because their preconditions
will not be satisable. On the other hand, the typed schema:

y(X,Y,Z)
params:
Pre:
Add:
Del:

X:aircraft,Y,Z:location
at(X,Y)
at(X,Z)
at(X,Y)

ensures that only aircraft can be own, whilst the untyped schema:
371

Fox & Long

y(X,Y,Z)
Pre:
Add:
Del:

at(X,Y)
at(X,Z)
at(X,Y)

allows ying as a means of travel for any object that can be at a location, including packages,
and other objects, as well as aircraft. Tim is capable of automatically inferring all types
playing the restrictive role indicated in the typed drive operator. However, tim cannot infer
type information that is not implicit in the domain description. Thus, given the untyped fly
schema, there are no grounds for tim to infer any type restrictions. Tim will draw attention
to unintended under-discrimination by making packages and aircraft indistinguishable at
the type level, unless there is distinguishing information provided in other schemas. At
the very least tim will make explicit the fact that packages are amongst those objects that
can y. This assists the domain designer in tracking errors and omissions in a domain
description, but unstated intended distinctions cannot be enforced by tim.

2.2 An Overview of the TIM Algorithm

Figure 2 gives a broad outline of the tim algorithm. A more detailed description is given
in Appendix B. The role of each component of the algorithm is described, together with a
commentary on discussing related issues and justications, in Sections 2.3, 2.4 and 2.7.
Broadly, tim begins with an analysis of the domain operators, extracting transition rules
that form the foundations of the property and attribute spaces described previously. These
rules are used to separate properties into equivalence classes from which the property and
attribute spaces are constructed. Tim then analyses the initial state in order to assign the
domain objects to their appropriate spaces. This analysis also identies the initial properties
of individual objects and uses them to form states of the objects in the property spaces. The
initial states in a property space are then extended by the application of the transition rules
in that space to form complete sets of states accounting for all of the states that objects in
that property space can possibly inhabit. As described in Section 2.4, attribute spaces do
not behave like FSMs, as property spaces do, and the extension of these is carried out by a
dierent procedure: one that can add new objects to these spaces, rather than new states.
Tim then assigns types to objects using the pattern of membership of the spaces it has
constructed. Finally, tim uses the spaces to determine invariants that govern the behaviour
of the domain and the objects in it.

2.3 Constructing the Transition Rules

We begin by describing the process by which the transition rules are constructed. The
following denitions are required.

Denition 8 A property is a predicate subscripted by a number between 1 and the arity of
that predicate. Every predicate of arity n denes n properties.

Denition 9 A transition rule is an expression of the form:
property ) property  ! property 
372

Automatic Inference of State Invariants

Construct base PRSs (Section 2.3)
Split PRSs (Section 2.3)
Construct transition rules (Section 2.3)
Seed property and attribute spaces (Section 2.3)
Assign transition rules (Section 2.4)
Analyse initial state (Section 2.4)
Extend property spaces (Section 2.4)
Extend attribute spaces (Section 2.4)
Identify types (Section 2.6)
Construct invariants (Section 2.7)
Figure 2: Outline of the tim algorithm.
in which the three components are bags of zero or more properties called enablers, start and
nish, respectively.

The double arrow, ), is read enables and the single arrow, !, is read the transition
from. So:

E)S!F

is read: E enables the transition from S to F. The properties in S are given up as a result of
the transition. The properties in F are acquired as a result of the transition. The properties
in E are not given up.
If enablers is empty we write:

start ! finish
If start is empty we write:

Transition rule 1

enablers ) null ! finish
If nish is empty we write:

Transition rule 2

enablers ) start ! null
The bag null is the empty bag of properties. Its role is to emphasise that, in transition
rule 1, nothing is given up as a result of the transition and, in transition rule 2, nothing is
acquired. Rules that have a null start and a null nish are discarded because they describe
null transitions.
When the property bags contain more than one element they are separated by commas.
The collection:

pk ; qm ; ::: rn
373

Fox & Long

is interpreted to mean that each of the properties in the collection can be satised as
many times as they appear in the collection. The comma is therefore used to separate the
elements of a bag. We use  to denote bag union, 	 to denote bag dierence, 
 to denote
bag intersection and v to denote bag inclusion.

Denition 10 A Property Relating Structure (PRS) is a triple of bags of properties.
The rst stage of the algorithm constructs a set of transition rules from a set of operator
schemas. Each operator schema is analysed with respect to each parameter in turn and, for
each parameter, a PRS is built. The rst bag of properties is formed from the preconditions
of the schema, and the number used to form the property is the argument position of
the parameter being considered. For example, if the precondition is on(X; Y ), and the
parameter being considered is X , the property formed is on1 . This bag, called precs,
contains the enablers that will be used in the formation of the transition rules. The second
bag, called deleted precs, of properties is formed from all of the preconditions that appear
on the delete list of the schema (with respect to this same parameter). The third bag, called
add elements, contains the properties that can be formed from the add list of the schema.
The PRS contains no deleted elements component { it is assumed that every element on
the delete list of a strips operator appears in the precondition list. This is a reasonable
restriction given that strips operators do not allow the use of conditional eects. It is
further assumed that every pair of atoms on the delete list of a schema will be distinct for
all legal instantiations of the schema. This does not constitute a signicant restriction since
operator schemas can always be easily rephrased whenever this condition is violated.
We now consider the process by which PRSs are constructed. Given the schema:

drive(X,Y,Z)
Pre:
Add:
Del:

at(X,Y), fuelled(X), location(Z)
at(X,Z), unfuelled(X)
at(X,Y), fuelled(X)

and considering the parameter X , the following PRS will be built:

PRS 1

precs :
at1 ; fuelled1
deleted precs : at1 ; fuelled1
add elements : at1 ; unfuelled1
By considering the parameter Y we obtain:

PRS 2
precs :
at2
deleted precs : at2
add elements :
and by considering the parameter Z we obtain:
374

Automatic Inference of State Invariants

PRS 3

precs :
location1
deleted precs :
add elements : at2

In constructing these structures we are identifying the state transformations through which
the objects, instantiating the operator parameters, progress. Note that objects that instantiate X go from being fuelled and at somewhere to being unfuelled and at somewhere; objects
that instantiate Y lose the property of having anything at them and gain nothing as a result of application of this operator, and objects that instantiate Z continue being locations
and gain the property of having something at them. We now convert these structures into
transition rules in order to correctly capture these state transformations.
Our standard formula for the construction of rules from PRSs is:

precs 	 deleted precs ) deleted precs ! add elements
Thus, using the PRS 1 above, we could build the rule:

at1 ; fuelled1 ! at1 ; unfuelled1
A potential problem with this rule is that it causes at1 and fuelled1 to be linked in state
transformations, so that at1 and fuelled1 become associated with the same property space
and, as a consequence, objects that can be at places, but that cannot be fuelled, may be

indistinguishable from objects that require fuelling before they can be moved. In fact, we
wish the transition rules to express the fact that being fuelled enables things to go from
being at one place to being at another place, whilst not excluding the possibility that there
may be other enablers of this transition.
We therefore begin a second phase of PRS construction by identifying, for special treatment, PRSs in which a property appears in both the deleted precs and the add elements.
This is a property that is exchanged on application of the operator. That is, the relation
continues to hold between the identied argument and some other object or objects (not
necessarily the same object or objects as before the application of the operator). For example, in PRS 1, the vehicle is at a new location after application of the operator, and no
longer at the old location. We observe that the vehicle must be fuelled to make this transition. To separate the transition from this condition we split the PRS. Splitting identies
the exchanged properties in a PRS and creates one new PRS for each exchange and one
for the unexchanged properties. Therefore, splitting a PRS always results in at most k + 1
(and at least k) new PRSs, where k is the number of exchanges that the PRS represents.
By splitting PRS 1 we construct two new PRSs: one characterizing the exchange of the at
property, and one characterising the fuelled to unfuelled transition.
The rst of the new PRSs is:

PRS 4

precs :
at1 ; fuelled1
deleted precs : at1
add elements : at1
375

Fox & Long

from which the rule

fuelled1 ) at1 ! at1
is constructed. It should be noted that the property of being fuelled is no longer seen as
part of the state transformation but only as an enabler, which is why it does not appear in
the deleted precs bag in the resulting PRS.
The second new PRS captures the fact that at1 can be seen as an enabler for the
transition from fuelled1 to unfuelled1:

PRS 5

precs :
at1 ; fuelled1
deleted precs : fuelled1
add elements : unfuelled1

In this PRS there are no further splits required since no other properties are exchanged in
it. A more general example is as follows:

PRS 6

precs :
p1; p2    pn
deleted precs : p1    pi pi+k    pm
add elements : p1    pi q1    qk

from which i PRSs would be constructed to deal with each of the i exchanged pairs and a
nal PRS, PRS 7, would be constructed to describe the remainder of the transition making
i + 1 PRSs in total.

PRS 7

precs :
p1 ; p2    pn
deleted precs : pi+k    pm
add elements : q1    qk

There is no need to consider additional pairings of add and delete-list elements, since these
would not correspond to exchanges of properties. The splitting process is justied in Section 3.1. The standard rule construction formula can be applied to PRS 5, yielding the
rule
at1 ) fuelled1 ! unfuelled1
It should be observed that, even if the add elements bag contains multiple properties, a
single rule will always be built when the standard construction formula is applied.
On considering the remaining PRSs, 2 and 3, it can be observed that they each contain
an empty eld: in 2 the add elements eld is empty and in 3 the deleted precs eld is empty.
When a PRS has an empty eld special treatment is required. From PRS 2 we build the
rule

at2 ! null

to represent the fact that the object that instantiates Y gives up the property of having
something at it, and gains nothing in return. From 3 we build the rule

location1 ) null ! at2
376

Automatic Inference of State Invariants

to represent the fact that the object that instantiates Z gains the property of having something at it by virtue of being a location, and gives up nothing in return. These rules have
a somewhat dierent status from the ones that characterize the exchange of properties. In
these cases properties are being lost or gained, without exchange, so can be seen as resources
that can be accumulated or spent by domain objects rather than as states through which
the domain objects pass. For example, a location can acquire the property of having something at it, without relinquishing anything in return, whereas an object that requires fuel
can only become fuelled by relinquishing the property of being unfuelled, and vice versa.
Increasing and decreasing resources are identied as attributes and are distinguished from
states. This distinction will later prove to be very important, since the generation of true
state invariants depends upon it being made correctly. Properties that can increase and
decrease without exchange are not invariant, and false assertions would be proposed as
invariants if they were treated in the same way as state-valued properties.
A rule of the form constructed from PRS 3 must be constructed separately for every
property in the add elements bag because these properties must be individually characterized as increasing resources. Rules constructed using null are distinguished as attribute
transition rules. If the null is on the left side of the ! the rule is an increasing attribute
transition rule. If the null is on the right hand side then the rule is a decreasing attribute
transition rule.
A nal case to consider during rule construction is the case in which a PRS has an empty
precs eld. This happens if the parameter, with respect to which the PRS was constructed,
did not appear in any of the preconditions of the operator schema. In this case a set of
rules is constructed, one for each property, a, in the add elements bag, of the form

null ! a
reecting the fact that a is an increasing resource (the deleted precs eld will necessarily
also be empty in this case).

Denition 11 A state is a bag of properties.
When it is necessary to distinguish a bag from a set, square brackets will be used to denote
the bag.
Denition 12 A property space is a tuple of four components: a set of properties, a set
of transition rules, a set of states and a set of domain constants.

Denition 13 An attribute space is a tuple of three components: a set of properties, a set

of transition rules and a set of domain constants.

It is helpful to observe here that the state and attribute spaces represent disjoint collections of properties, and that these disjoint collections are formed from the transition
rules by putting the start and finish properties of each rule into the same collection. For
example, given two rules:
E1 ) [p1; p2; p3] ! [q1 ; q2]
and
E2 ) [r1; r2] ! [s1 ]
377

Fox & Long

the collections [p1; p2; p3; q1; q2] and [r1; r2; s1] would be formed. If a property appears in
the start or finish of both rules then a single collection will be formed from the two rules.
The last stage in the rule construction phase is to identify the basis for the construction
of property and attribute spaces. This is done by uniting the left and right hand sides of the
rules. Uniting forms collections of properties that each seed a unique property or attribute
space. It is not yet possible to decide which of the seeds will form attribute spaces, so
treatment of both kinds of space is identical at this stage. The enablers of the rules are
ignored during this process. We do not wish to make enablers automatically fall into the
same property spaces as the states in the transformations they enable. This could result
in incorrect assignment of properties to property and attribute spaces since enablers only
facilitate, and do not participate in, state transformations. The output of this phase is the
collection of rules, with some properties marked as attributes, and the property space seeds
formed from the uniting process. All properties that remain unassigned at this stage are
used to seed separate attribute spaces, one for each such property.
The role played by the second phase of PRS construction is to postpone commitment
to the uniting of collections of properties so that the possibility of objects, which can have
these properties, being associated with dierent property spaces is left open for as long as
possible. It may be that consideration of other schemas provides enough information for
this possibility to be eliminated, as in the following abstract example, but we support as
much type discrimination as possible in the earlier phases of analysis. We consider this
simple example to illustrate the problem.
2.3.1 Postponing Property Space Amalgamation

Given a domain description containing the following operator schema:

op1(X,Y,Z)
Pre:
Add:
Del:

p(X,Y), q(X,Y)
p(X,Z), q(X,Z)
p(X,Y), q(X,Y)

the PRS:

precs :
p1 ; q1
deleted precs : p1 ; q1
add elements : p1; q1
will be constructed, during the rst phase, for X . The properties p1 and q1 are bound
together in this PRS, and the resulting rule would be:

p1; q1 ! p1 ; q1
which forces objects that can have property p1 to occupy the same property space as objects
that can have property q1 . Since this PRS models the exchange of p1 we will split it, and
replace it with two new PRSs:

precs :
p1 ; q1
deleted precs : p1
add elements : p1
378

Automatic Inference of State Invariants

precs :
p1 ; q1
deleted precs : q1
add elements : q1
We do not consider other pairings of p1 and q1 , since these will be found in the PRSs
of other operator schemas if the domain allows them. The two PRSs generated lead to the
generation of the rules:

q1 ) p1 ! p1

and

p1 ) q1 ! q1

The two rules indicate that p1 and q1 should be used to form dierent property spaces since
they could, in principle, be independent of one another. Then objects assigned to these two
spaces can turn out to be of distinct types. However, if we add the following two schemas:

op2(X,Y)
Pre:
Add:
Del:

op3(X,Y,Z)

q(X,Y)
p(X,Y)
q(X,Y)

Pre:
Add:
Del:

p(X,Y)
q(X,Y)
p(X,Y)

we generate, for X , the PRSs:

precs :
q1
deleted precs : q1
add elements : p1
and

precs :
p1
deleted precs : p1
add elements : q1
and the rules:
and

q1 ! p1
p1 ! q1

indicating that p1 and q1 should be united in the same set and hence form a single property
space, and that objects that can have these properties are really of the same type. The
uniting overrides the potential for separate property spaces to be formed but, in the absence
of these two schemas, there would have been insucient information available to determine
the nature of the relationship between the two properties.
379

Fox & Long

2.4 Constructing the Property Spaces and Synthesising the Types

The objective of this stage is to construct the type structure of the domain by identifying
domain objects with distinct property spaces. Objects can appear in more than one property
space, giving us a basis for deriving a hierarchical type structure.
The rst part of the process involves completing the seeded property spaces. The rst
task is to associate transition rules with the appropriate property space seeds. This can be
easily done by picking an arbitrary property of the start or nish component of each rule
and identifying the property space seed to which that property belongs. There can never
be ambiguity because every property belongs to only one seed and uniting ensures that all
of the properties referred to in a rule belong to the same seed. At this point the distinction
between states and attributes becomes important. Any property space seed that has an
attribute transition rule associated with it becomes an attribute space and is dealt with
dierently from property spaces in certain respects explained below.
The next step is to identify the domain objects associated with each property space and
attribute space.
For each object referred to in the initial state we construct a type vector in which a bit
is set if the corresponding space is inhabited by the object. An object can inhabit more
than one space. Habitation is checked for by identifying all of the properties that hold, in
the initial state, of the object being considered and allocating them as states, rather than
as properties, to the appropriate state and attribute spaces. When every domain object has
been considered a unique type identier is associated with each of the dierent bit patterns.
The next task is to populate the property spaces with states. The following denitions
are required to support the explanation of this process.

Denition 14 A world-state is a collection of propositions characterising the conguration
of the objects in a given planning domain description.

Denition 15 Given a world-state, W , a property space, P = (Ps; TRs; Ss; Os), or an
attribute space, P = (Ps; TRs; Os), and an object o 2 Os, the P -projection of St for o is
the bag of properties, possessed by o in W , each of which belongs to Ps.

The collection of properties of an object, o, in the initial state can be divided into a set of
bags of properties, each bag corresponding to the P -projection of the initial state for o, for
some property or attribute space P . Each bag is added to the state set of the corresponding
property space, or discarded if the corresponding space is an attribute space. We now need
to extend the spaces by, for each property space, adding states that can be inferred as
reachable by objects within that space along transitions within that space. This is done for
every state in the space, including states that are newly added during this process, until no
further new states are reachable. The ordering of the properties within states is irrelevant, so
two states are considered equal if they contain the same properties, regardless of ordering
(they are considered order-equivalent). Since, when we come to use this information in
parts of the process of invariant generation, we will not require knowledge of any inclusion
relations between pairs of states, it is convenient to mark these at this stage. The addition
of reachable states is important for the inference of state invariants, and their use will be
discussed in Section 2.7. The attribute spaces receive dierent treatment at this point. The
380

Automatic Inference of State Invariants

important dierence to observe is that, since property spaces characterize the exchange
of properties, objects in a property space must start o in the initial state as members
of that property space. However, since attributes can be acquired without exchange, it
is possible for objects that do not have particular attributes in the initial state to acquire
those attributes later. This is only possible if the attribute space has an increasing attribute
transition rule associated with it. We now, therefore, consider each attribute space to see
whether further objects can be added by application of any corresponding increasing rule.
An object can be added to an attribute space if it potentiates all of the enablers of an
increasing rule in that attribute space. An object potentiates an enabling property if it
is a member of the state or attribute space to which that property belongs. Membership
of all of these spaces indicates that the object could enter a state in which it satises all
of the enabling properties, which would justify an application of the increasing rule. Any
enabling property that is not associated with a state or attribute space is a static condition,
so the initial state can be checked to conrm that the property is true of the object being
considered.
A complication arises if any enabling property was itself used to seed an attribute space
(in which case it is itself an attribute), because it is then necessary to identify all of the
objects in its attribute space and consider them for addition to the current attribute space.
Of course this could, in principle, initiate a loop in the process but we avoid this by marking
attribute spaces as they are considered and ensuring, by iterating until convergence, that
all of the attribute spaces in the loop are completely assigned. The correctness of this part
of the procedure is discussed in Section 3.
When this is done the state and attribute spaces are complete and the types of the
domain objects can be extracted. The completeness of this construction phase is discussed
in Section 3.1.

2.5 A Worked Example

A fully worked example of all stages of the process will help to clarify what is involved.
Consider a simplied version of the Rocket domain in which there are two operator schemas:

drive(X,Y,Z)
Pre:
Add:
Del:

load(X,Y,Z)

at(X,Y), fuelled(X), location(Z)
at(X,Z), unfuelled(X)
at(X,Y), fuelled(X)

Pre:
at(X,Y), at(Z,Y)
Add:
in(X,Z)
Del:
at(X,Y)
and an initial state containing four constants: rocket, package, London and Paris, and
the relations: at(rocket,Paris), fuelled(rocket) and at(package,London). It can be observed
that this simplied Rocket domain has the rather odd feature that the load schema is not
restricted to loading packages into rockets. This oddity will be highlighted by the analysis
that is constructed, showing how the analysis performed by tim can help in understanding
(and debugging) the behaviour of the domain. From the drive operator schema the following
PRSs are constructed for variables X , Y and Z respectively:
381

Fox & Long

precs:
at1 , fuelled1
deleted precs: at1 , fuelled1
add elements: at1 , unfuelled1
precs:
at2
deleted precs: at2
add elements:
precs:
location1
deleted precs:
add elements: at2
From the load operator schema the following PRSs are constructed for variables X , Y
and Z respectively:
precs:
at1
deleted precs: at1
add elements: in1
precs:
at2 , at2
deleted precs: at2
add elements:
precs:
at1
deleted precs:
add elements: in2
and the following rules are built. The rst PRS generates the rst two rules and subsequent
PRSs each generate one rule.
fuelled1 ) at1 ! at1
at1 ) fuelled1 ! unfuelled1

at2 ! null
location1 ) null ! at2
at1 ! in1
at2 ) at2 ! null
at1 ) null ! in2

We now construct the following united sets of properties:

fat1; in1g
ffuelled1; unfuelled1g
fat2g
fin2g
382

Automatic Inference of State Invariants

These are used to seed property spaces. We rst associate the rules with these property
space seeds, resulting in the following assignment:

fat1; in1g
at1 ! in1 ; fuelled1 ) at1 ! at1
ffuelled1; unfuelled1g at1 ) fuelled1 ! unfuelled1
fat2g
location1 ) null ! at2 ; at2 ) at2 ! null;
at2 ! null
fin2g
at1 ) null ! in2
The last two spaces have been converted into attribute spaces by their association with
attribute transition rules. The resulting spaces can now be supplemented with domain
constants and their legal states. We rst identify the subset of the legal states of the
domain objects that are identiable from the initial state. We do not use the goal state
to provide further information about the properties of objects. The goal state might be
unachievable because objects cannot obtain the required properties. This would invalidate
tim's analysis of the domain. In the initial state the rocket has properties at1 and fuelled1,
the package has property at1 , London has property at2 and Paris has property at2 . Using
this information we associate domain constants with the developing state and attribute
spaces to obtain:

fat1; in1g
at1 ! in1; fuelled1 ) at1 ! at1
frocket; packageg
ffuelled1; unfuelled1g at1 ) fuelled1 ! unfuelled1
frocketg
fat2g
location1 ) null ! at2 ; at2 ) at2 ! null; fLondon; Parisg
at2 ! null
fin2g
at1 ) null ! in2
The next step is to add the legal states of these objects, which are identiable so far, to
the property spaces. This results in the following structures, the rst two of which can
be extended by inference (as will be explained) into completed property spaces. The last
two will be extended into completed attribute spaces by the addition of objects that can
potentially acquire the associated attributes (also described below).

fat1; in1g

at1 ! in1; fuelled1 ) at1 ! at1

ffuelled1; unfuelled1g at1 ) fuelled1 ! unfuelled1
fat2g
fin2g

frocket; packageg
[at1 ]
frocketg
[fuelled1]

location1 ) null ! at2 ; at2 ) at2 ! null; fLondon; Parisg
at2 ! null
at1 ) null ! in2

The last stage in the construction of the two property spaces is to add any states that
can be inferred as reachable, via transition rules, by objects in the property spaces. For
example, packages can go from being at1 to being in1, by application of the rule at1 ! in1,
and since that rule is available in the property space to which package belongs, and at1
is one of the legal states in that property space, we add in1 as a further legal state. In
general, we construct the extension by, for each state in the space, identifying applicable
rules and, for each rule, creating a new state by removing the properties in the start of the
383

Fox & Long

rule and adding the properties in the nish of the rule. This is done until all further states
are order-equivalent to those already generated. The enablers of the rules are ignored, with
the consequence that some of the new states generated might be unreachable. When this
process is completed in the current example the nished property spaces are as follows:

Property space 1
fat1; in1g at1 ! in1; fuelled1 ) at1 ! at1 frocket; packageg
[at1]; [in1]

Property space 2
ffuelled1; unfuelled1g at1 ) fuelled1 ! unfuelled1 frocketg

[fuelled1 ]; [unfuelled1 ]

We now consider each attribute space in turn and add domain objects (not already
members) that potentiate their increasing rules. No new domain objects can be added to
the rst attribute space since only London and Paris can potentiate the increasing rule,
and they are already present. However, when the second attribute space is considered it can
be observed that rocket and package both potentiate the increasing rule and are therefore
both added as new members. The resulting attribute spaces are:

fat2g location1 ) null ! at2; at2 ) at2 ! null; fLondon; Parisg
at2 ! null
fin2g at1 ) null ! in2
frocket; packageg
The oddity of the load operator is revealed at this stage, since both package and rocket
have been assigned as members of the in2 attribute space (meaning that they both can have
the attribute of having things in them).

The number of distinct bit patterns that are constructed, indicating object membership
of the state and attribute spaces, determines the number of distinct types that exist in the
domain. Hence, in this simplied encoding of the Rocket domain, there are three distinct
types. The rocket has type [1101], the package has type [1001] and Paris and London both
have type [0010]. These types are given abstract identiers, T0; T1 and T2, but might be
more meaningfully interpreted as the types of: movable object requiring fuel, movable object
and location respectively. As expected, London and Paris are of type location, whilst the
package is of type movable object and the rocket is of type movable object requiring fuel,
which is a sub-type of movable object.
The distinction we have made between state and attribute spaces is further exploited in
the process of inferring state invariants, discussed in Section 2.7.

2.6 The Assignment of Types to Operator Parameters

Types are assigned to the parameters of the operators in the following way. Given an
operator schema and a collection of property spaces and attribute spaces we allocate a type
vector to each of the variables in the schema. The membership in the state and attribute
spaces of each of the properties of a given variable is recorded by setting the appropriate bits
in the vector for that variable. Only the properties that appear in the preconditions of the
384

Automatic Inference of State Invariants

schema are considered, because any object that can satisfy the preconditions of an operator
can have the properties represented by the postconditions and is therefore of the right type
for instantiation of the operator. When a type is associated with the vector the union of all
of its sub-types is taken. This union is then the type assigned to the variable. Any domain
object, the type of which is a sub-type of the type associated with the variable, can then
be used to instantiate that variable. To see how this process works, consider the variable X
in the drive schema above. The precondition properties of X are: at1 , fuelled1. These are
members of the two property spaces 1 and 2. Therefore, the type vector associated with X
is [1100]. It can be observed that the type vector associated with the rocket is [1101], so that
the type of rocket is a sub-type of the type of X . This is the only sub-type, so the union of
sub-types contains only T0, the type of rocket. This means that X can be instantiated by
rocket, but not by any other domain constant, since no other domain constant has a type in
the appropriate sub-type relation. To type the operator parameters we introduce new type
variables, Tk ::Tn for unused values between k and n, where k is the number of existing types
and n is k plus the number of variables in the schema being considered. The type vector
for variable Y will be [0010] and Z will have no type vector because location is a static
relation and Z does not appear as an argument to any other predicate in the preconditions.
Z therefore acquires the same type as London and Paris, the only two objects for which
location is true in the initial state. T4 is a super-type of T2. After taking the unions of the
sub-types we can now specify the drive schema in the following way:

drive(X,Y,Z)

Params:
X:T0 Y:T2 Z:T2
Pre:
at(X,Y), fuelled(X), location(Z)
Add:
at(X,Z), unfuelled(X)
Del:
at(X,Y), fuelled(X)
stan exploits the sub-typing relations that have been inferred when constructing instances of the drive operator. Any variable that appears in a schema but does not appear
in its preconditions can be instantiated by objects of any type. This is because the domain
description contains no basis for inferring type restrictions in this case. No variable can
appear on the delete list without appearing on the precondition list, since we assume that
all delete list elements appear as preconditions. So such a variable would have to occur on
the add list. This would mean that, regardless of the properties holding of the object used
to instantiate that variable, in the initial state, it can acquire that add list property freely.
Since this acquisition would occur irrespective of the type of the object, such variables are
essentially polymorphic.

2.7 The Inference of State Invariants

The nal phase of the computation of tim is the inference of the state invariants from
the property spaces. The attribute spaces are not used for the inference of invariants:
incorrect invariants would be proposed by tim if attribute spaces were inadvertantly used.
This explains the importance of identifying the attribute spaces in the earlier stages of the
algorithm.
The current version of tim is capable of inferring four kinds of invariant, three of which
are inferred from the property spaces (identity invariants, state membership invariants and
385

Fox & Long

invariants characterizing uniqueness of state membership) and one of which is inferred from
the operator schemas and initial state directly (xed resource invariants). In the simplied
Rocket domain, considered above, an example of an identity invariant is:

8x : Tk :8y:8z:(at(x; y) ^ at(x; z) ! x = z)
A state membership invariant is:

8x : Tk:(9y : Tn:at(x; y) _ 9y : Tm:in(x; y))
A uniqueness invariant is:

8x : Tk ::(9y : Tn:at(x; y) ^ 9y : Tm:in(x; y))
To infer the identity invariants each property space is considered in turn, with respect
to their properties and states. If a property, for example Pk with P of arity n > 1, occurs
at most once in any state an invariant of the following form, in which y and z are vectors
containing n , 1 values, can be constructed:

8x:8y:8z:(P (y1::k,1; x; yk::n,1) ^ P (z1::k,1; x; zk::n,1) ! y = z)
The form of this invariant can be generalised to deal with the case where there are at most
m > 1 occurrences of Pk in any state in the space. In this case we build the following
expression, in which we have assumed that k = 1, for simplicity.

8x:8y1:::ym:(P (x; y1) ^ ::: ^ P (x; ym) ! (y1 = y2 _ y1 = y3 _ ::: _ ym,1 = ym ))
The state membership invariants are of the form:

8x:(Disjunct1 _ :: _ Disjunctn)
where each disjunct is constructed from a single state. Thus, if a property space contains k
states there will be at most k disjuncts in the invariant constructed for that property space.
Only one state membership invariant is constructed for each property space.
Given the collection of states in a property space we rst identify those that are supersets
of other states in the collection. All supersets are discarded, since the invariants that would
be built from them would be logically equivalent to those built from their subset states.
Each remaining state is used to build a single disjunct. If the state being considered contains
a single property, Pk with P of arity n, then the expression

9y:P (y1::k,1; x; yk::n,1)
is constructed. Of course, if n = 1 then there is no existential quantier and the disjunct
is just P (x). If the state contains more than one property, say m of them denoted P 1 ::P m ,
then we build (again, assuming that k = 1 for simplicity):

9y1 :::ym:(P 1(x; y1) ^ P 2(x; y2) ^ ::: ^ P m (x; ym))
The uniqueness invariants are constructed in a similar way. For each property space we
begin by analysing the superset states to identify non-exclusive pairs of subset states. For
386

Automatic Inference of State Invariants

example, given the subset states fat1 g and fin1g and the superset state fat1 ; in1g, it can
be observed that the two subset states are not mutually exclusive since at1 and in1 can be
simultaneously held. Having done this analysis and identied all mutually exclusive pairs
of states we mark the subset states as unusable for generation of invariants. The remaining
states are considered in all possible pairings. For every pair of states, P; Q, we generate
an invariant of the following form assuming, for simplicity, that x is in the rst position in
P 1 ::P n and Q1 ::Qm. The form of the invariant is easily generalised, as before.

8x::(9y1:::yn:(P 1(x; y1) ^ P 2(x; y2) ^ ::: ^ P n (x; yn))
^(9y1:::ym:(Q1(x; y1) ^ Q2(x; y2) ^ ::: ^ Qm (x; ym))))
The fourth kind of invariant can be inferred from the structure of the operator schemas
without reference to the property spaces or domain type structure. We call these invariants
xed resource invariants since they capture the physical limitations of the domain. Fixed
resource invariants cannot be inferred from the state and attribute spaces because they describe properties of the domain rather than of objects within it. The following schema from
the Gripper domain provides an example of why xed resource invariants are distinguished
from the other three kinds:

move(X,Y)

Pre:
Add:
Del:

at robot(X), room(Y)
at robot(Y)
at robot(X)

The PRSs that would be built from this operator are:

precs :
at robot1
deleted precs : at robot1
add elements :
precs :
room1
deleted precs :
add elements : at robot1
and the rules constructed from these are:

at robot1 ! null
and

room1 ) null ! at robot1

It can be observed that both of these rules are attribute transition rules and that at robot1
is attribute rather than state-valued. This means that no invariants of the rst three kinds
discussed would be constructed.
The reason for the lack of invariants of the rst three forms is that the encoding of the
robot is embedded in a predicate, so the robot cannot participate directly in state transitions.
An obvious invariant of the robot, which would naturally be true of this domain, is that the
387

Fox & Long

robot is always in exactly one room but this cannot be inferred using the techniques so far
described. In fact, this is an axiom about the world, or domain, rather than specic objects
within it, and has to be obtained from information other than the state transformations of
the objects.
It can be seen from the operator schemas for the Gripper domain that at robot1 is balanced. That is, it is always deleted whenever it is added and added whenever it is deleted.
This means that the number of occurrences of at robot in the initial state determines the
number of occurrences that are possible in any subsequent state. This leads to the construction, for this domain, of the invariant

jfx : at robot(x)gj = 1
since there is only one at robot relation in the initial state. The form of xed resource
invariants is always equational. Such an invariant states that the size of the set of combinations of objects satisfying a certain predicate is equal (or, in some cases, less than or equal)
to a certain positive integer. Because this integer can be very large it is more convenient to
write an equation than it would be to write a logical expression. The information encoded
in the xed resource invariants is very useful for identifying unsolvable goal sets without attempting to plan for them. For example, in the ICPARC version of the three-blocks Blocks
world (Liatsos & Richards, 1997), in which there are only three table positions, there must
always be exactly three clear surfaces. Any goal specifying more than three clear relationships can be identied as unachievable from the xed-resource invariants for that domain.
The xed-resource and uniqueness invariants produced by tim can be seen as providing a
form of multi-mutex relations, in contrast to the binary mutex relations inferred during the
construction of the plan graph in Graphplan-based planners (Blum & Furst, 1995). Binary
mutex relations indicate that two actions or facts are mutually incompatible, whilst multimutex relations indicate that larger groups of actions or facts are collectively incompatible.
Binary mutex relations, preventing a fact that can be true of only one object from holding
of two dierent objects simultaneously, can be extracted from the identity invariants that
tim infers. Multi-mutex relations are more powerful than binary ones. Stan can detect
unsolvable goal-sets by using the xed-resource and uniqueness invariants even when the
binary mutex relations at the corresponding level do not indicate that any problem exists.
To infer these invariants we examine the predicates in the language to see whether
they are exchanged on the add and delete lists of the operator schemas. If a predicate is
exchanged equally in all schemas (it always appears the same number of times on the add
list as on the delete list of a schema) then the predicate corresponds to a xed resource.
If a single schema upsets this balance then the predicate is not treated as xed. Given a
xed resource predicate, it can be inferred that there can never be more combinations of
objects satisfying that predicate than there are in the initial state. Because of the slightly
odd encoding of the rocket world considered in this paper, only location is a xed resource.
at is not xed because it is not equally exchanged in the load schema. Examples of xed
resource invariants inferred from various standard domains are provided in Appendix C.
There are certain circumstances under which it is necessary to infer the weaker invariant
that
jfx : P (x)gj  k
388

Automatic Inference of State Invariants

for some positive integer k. If P holds of multiple objects in the initial state then it is
possible for subsequent state transformations, or attribute acquisitions, to result in states
in which two or more instances of P collapse into one. If P holds multiply often in the initial
state (or in any other reachable state) then it is necessary to build the invariant using 
instead of =. If P is state-valued, and multiple instances never occur in any state in its
property space, then it is safe to assert equality in the construction of the invariant.
Automatic inference of the rst three kinds of invariants relies on the construction
of the property spaces as discussed in Section 2.4. As has been discussed, the distinction
between state and attribute spaces is critical for the inference of correct invariants. However,
using just the techniques described so far, tim would lose information from which it could
construct useful invariants. To give an example of how this could occur we now consider
the following simple encoding of the standard Blocks world:

move(X,Y,Z)
Pre:
Add:
Del:

on(X,Y), clear(X), clear(Z)
on(X,Z), clear(Y), clear(table)
on(X,Y), clear(Z)

In this operator, used by Bundy et al. (1980), the add list element clear(table) makes
reference to a constant. If the operator schema were to be submitted to our analysis in its
current form no PRS would be built for the constant, so the rules that would be constructed,
and hence the state and attribute spaces constructed, would fail to record the fact that every
application of move results in a state in which the table is clear. The resulting analysis
would result in incorrect invariants and types. Grant (1996) identies this version of the
move operator as awed, because of the need to maintain state correctness by the addition
of the invariant clear(table) to the add list. However, we can analyse this schema correctly
if we rst abstract it to remove the constant, yielding the following new schema:

move(X,Y,Z,T)
Pre:
Add:
Del:

on(X,Y), clear(X), clear(Z), table(T)
on(X,Z), clear(Y), clear(T)
on(X,Y), clear(Z)

Now, given an initial state in which blockC is on blockA and blockB is on the table,
we add the proposition table(table) (so that the new precondition can be satised) and the
property and attribute spaces that are constructed are as follows:

fon1g

clear1 ) on1 ! on1

fblockA; blockB; blockC g
[on1 ]
fon2; clear1g on2 ! clear1; clear1 ! on2; fblockA; blockB; blockC; tableg
table1 ) null ! clear1

The second of these is an attribute space, so our invariant extraction algorithm is not
applied to it. Consequently, the only invariants we can infer are those that characterize
the positions of blocks (every block is on exactly one surface). This is a pity, as there
is information available in the attribute space that could yield useful extra invariants. In
particular, we would like to infer the invariant that every block can be either clear or have
389

Fox & Long

something on it, but it cannot be both clear and have something on it. The reason we
cannot infer this as an invariant is because it would be asserted to hold for every object in
the attribute space, including the table, even though it is not actually true of the table (the
table can have things on it and still be clear).
2.7.1 Sub-space Analysis on Property and Attribute Spaces

The solution to the problem of loss of invariants is to decompose any property or attribute
space that contains k > 1 object types into k sub-spaces. A property sub-space is structurally identical to a property space. Attribute sub-spaces are identied but not used, as
no invariants can be obtained from them. Property sub-spaces can be obtained by analysis on attribute spaces, as the following example will show. The reason for distinguishing
sub-spaces from property and attribute spaces is that the properties are not partitioned
in sub-spaces as they are in the property and attribute spaces. The original property or
attribute space is not discarded and the sub-spaces are not used for determining the types
of objects. The only role of the sub-space analysis is to enable the construction of additional
invariants.
We now consider the Blocks domain described in the previous section as an example of
the benets of sub-space analysis. At the point of invariant construction the types of the
domain objects have been identied by their property and attribute space membership, so
table is already known to be of a dierent type to that of the blocks. This is because table is
not a member of the property space for on1 . Therefore, two sub-spaces can be constructed
from the attribute space, one for the type [11], of blocks, and one for the type [01], of
tables. No sub-spaces can be constructed from the property space because it contains only
one type of object. The rules associated with the sub-spaces will be all of the rules from the
original attribute space that are enabled by objects of the appropriate type. The second
of the two sub-spaces is an attribute sub-space because of the inclusion of the increasing
attribute transition rule. At this stage the two sub-spaces are as follows:

fon2; clear1g on2 ! clear1; clear1 ! on2
fblockA; blockB; blockC g
fon2; clear1g table1 ) null ! clear1; on2 ! clear1; ftableg
clear1 ! on2
The attribute sub-space will not be used for invariant construction because it contains an
attribute transition rule and would result in incorrect invariants (as is the case for attribute
spaces), so there is nothing to be gained from developing it further. However, the state
sub-space is now completed by the addition of the states associated with the objects in the
space, both in the initial state and by extension. The resulting sub-spaces are:

fon2; clear1g on2 ! clear1; clear1 ! on2

fblockA; blockB; blockC g
[on2 ]; [clear1]
fon2; clear1g table1 ) null ! clear1; on2 ! clear1; ftableg
clear1 ! on2
From the new state sub-space we can infer the following invariants, using the type name
Block to stand for the type vector [11]. We infer the identity invariant:
8x : Block  (8y  8z  (on(y; x) ^ on(z; x) ! y = z))
390

Automatic Inference of State Invariants

the state membership invariant:

8x : Block  (9y : Block  on(y; x) _ clear(x))
and the unique state invariant:

8x : Block  :(9y : Block  (on(y; x) ^ clear(x)))
Although there is an additional invariant, that the table is always clear, we cannot infer
this at present.

2.8 The Problem of Mixed Spaces

It can happen that the encoding of a domain conceals the presence of attributes within
schemas until the point at which property space extension occurs. This can prevent the
property space extension process from terminating. For example, a simple lightswitch domain contains the following two schemas:

switchon(X)
Pre:
Add:
Del:

switcho(X)
Pre:
Add:
Del:

o(X)
on(X), touched(X)
o(X)
on(X)
o(X), touched(X)
on(X)

and an initial state in which switchA is on. Two PRSs are constructed:
precs :
o1
deleted precs : o1
add elements : on1 ; touched1

precs :
on1
deleted precs : on1
add elements : o1 ; touched1
giving rise to two rules:
and

o1 ! on1 ; touched1

on1 ! o1; touched1

Uniting then seeds one property space containing all three properties. After addition of the
rules the property space is as follows:

fon1; o1; touched1g o1 ! on1; touched1; fswitchAg
on1 ! o1 ; touched1 [on1 ]
391

Fox & Long

It is at the point of extension of the space that the problem arises. The following states
are added: [o1; touched1], [on1; touched1; touched1 ], [o1; touched1; touched1; touched1 ] and
so on. We cannot simply avoid adding properties that are already in the state being extended because the two, apparently identical, properties might in general refer to dierent
arguments.
The problem here is due to the fact that touched1 is actually an increasing attribute
but this does not become apparent in the PRSs. The consequence is that mixed spaces are
constructed. A mixed space is a property space containing hidden attributes. Tim detects
hidden attributes by checking, on extension, that no new state contains a state already
generated from the same initial state starting point. Thus, on extension of the mixed space
above, tim would detect the hidden attribute when the state [on1 ; touched1; touched1] is
constructed, because this state contains the state [on1 ] that initiated this extension.
Having detected the hidden attribute there are two possibilities: either tim can convert
the mixed space into an attribute space, in which case no invariants will be constructed, or
it can attempt to identify the attribute and split the mixed space into an attribute space
and a property space containing the state-valued components of the mixed space. We take
this option and split the state. This allows us to infer invariants concerning the state-valued
properties.
tim takes the dierence between the including and included states and, for each distinct
property in the dierence, processes the rules by cutting any rule containing that property
into two rules, at least one of which will be an attribute rule. The following method is
used to cut the rules. In the following, attr+ indicates one or more occurrences of the
attribute-valued property and the comma is overloaded to mean both bag conjunction and
bag union. If the rule is of the form:

enablers ) start ! adds; attr+
then the two new rules will be of the forms:

enablers; start ) null ! attr+
and
If the rule is of the form:

enablers ) start ! adds
enablers ) attr+ ; precs ! adds

then the two new rules are of the forms:

enablers; precs ) attr ! null
and

enablers; attr ) precs ! adds

The rule cutting separates the attribute-valued properties from the state-valued properties.
Now pure attribute and property spaces can be constructed. However we do not discard
the original mixed space because it has been used in determining the type structure of
392

Automatic Inference of State Invariants

the domain. Any additional type information that could be extracted from the state and
attribute spaces built following this analysis is not currently exploited.
When this analysis is applied to the lightswitch domain, the following new property
space and attribute space are built:
fon1; o1g o1 ! on1; on1 ! o1
fswitchAg
[on1 ]; [o1]
ftouched1g o1 ) null ! touched1; on1 ) null ! touched1 fswitchAg
Using Lightswitch to stand for the type [11], the following state membership invariant
can be constructed from the property space:
8x : Lightswitch  (on(x) _ o(x))
tim also constructs the uniqueness invariant:
8x : Lightswitch  :(on(x) ^ o(x))

3. Properties of TIM

The correctness of tim relies on it constructing only necessarily true invariants. The demonstration that only true invariants are constructed guarantees the construction of an adequately discriminating type structure. We cannot guarantee against under-discrimination
but we argue that over-discrimination does not occur in the type structures generated by
tim. These properties were dened in Section 2.1.
Over-discrimination would be the result of distinguishing functionally identical objects
at the type level. This would occur if tim placed objects that participate in identical
state transitions in dierent property spaces but, because of the underlying partitioning of
properties between property spaces, this cannot happen. Further, membership of dierent
property spaces requires that there be distinguishing state transformations, which there
are not in functionally identical objects. Flawed assignment (assigning an object to a
property space without its corresponding state transformations), should simply be seen as
erroneous, rather than as over-discrimination. The possibility of this occurring can be
excluded because property and attribute space construction and extension are shown to be
correct in Section 3.1.
A failure to detect type dierences (under-discrimination) in the domain will result
in weak invariants, and over-discrimination, if it could occur, would lead to over-targeted
invariants that would still be true, but only for a subset of the objects they ought to
cover. Flawed assignment would clearly lead to the construction of false invariants. Underdiscrimination, which can arise, therefore aects the completeness of the state-invariant
inference procedure. It can also lead to over-generalisation of the operators since the types
assigned to the operator parameters will be equally under-discriminating. This can enable meaningless instances to be formed, needlessly increasing the size of the search space
that must be explored by the planner. This clearly raises eciency issues but it does not
undermine the formal properties of the planner that exploits tim.
As observed, the consequence of under-discrimination is the construction of weak (but
valid) invariants. The following example illustrates how under-discrimination can occur.
Given a schema:
393

Fox & Long

op(X,Y)
Pre:
Add:
Del:
and an initial state in which

p(X,Y)
q(X,Y)
p(X,Y)

p(a; c); p(b; c); q(b; d)

hold, the following two property spaces are constructed:

fp1; q1g p1 ! q1 fa; bg
[p1]; [q1]; [p1; q1 ]; [q1; q1 ]
fp2; q2g p2 ! q2 fc; dg
[q2 ]; [p2; p2 ]; [q2; p2 ]; [q2; q2 ]
Given these property spaces it is impossible to distinguish a from b or c from d, even
though analysis of the operator schema and initial state reveal that a is functionally distinct
from b and c from d. It can be seen that, although a must always exchange a p1 for a q1 ,
b can have both p1 and q1 simultaneously. A similar observation can be made for c and
d. However, the process by which invariants are constructed cannot gain access to this
information. An identity invariant constructed for the rst property space is:

8x : T  8y  8z  8u  (q(x; y) ^ q(x; z) ^ q(x; u) ! y = z _ y = u _ z = u)
This invariant is weaker than is ideal, because a can participate in only one q relation (b can
participate in two simultaneously). A state membership invariant for this property space
is:
8x : T  ((9y : T1  p(x; y)) _ 9y : T1  q(x; y))
which understates the case for b, which can have p1 and q1 simultaneously. No unique
state invariant is constructed for this property space, because p1 and q1 are not mutually
exclusive.

3.1 Correctness and Completeness of the Transition Rule Construction Phase

The correctness of the algorithm used in tim depends on two elements. Firstly, the property
spaces identied by the algorithm must be correctly populated. That is, no objects should
be assigned to property spaces to which they do not belong and every achievable state must
be included in the appropriate property space. Secondly, these property spaces must only
support the generation of correct invariants. This second element is examined in Section 3.2.
An interesting relationship exists between the states in a property space and the invariants generated from the space. Incorrect invariants will be contructed if a property space is
missing achievable states. This is because the state membership invariants assert that each
object in the property space must be in one of the states in the property space. If states
are missing then this invariant will be false. We now prove that all achievable states will
be in the appropriate property space.

Theorem 1 Given an initial state, I , a collection of operator schemas, O, a property space,
P = (Ps; TRs; Ss; Os), generated by tim when applied to I and O, and any state, St, which
394

Automatic Inference of State Invariants

is reachable from I by application of a valid linearised plan formed from ground instances
of operator schemas in O, then for any o 2 Os, the P -projection of St for o, StoP , is in Ss.

Proof:

The proof is by induction on the length of the plan that yields the state St. In the base
case the plan contains no operator instances so St = I . The P -projection of I for o is in
Ss, by denition of the rst phase of the property space construction process described in
Section 2.4.
Suppose St is generated by a plan of length k + 1, with last step a and penultimate
state pre-St. Let the P -projection of pre-St for o be pre-StoP . By the inductive hypothesis,
this state is in Ss. If a does not aect the state of o, then the P -projection of St for o
will be pre-StoP , and therefore in Ss trivially. Otherwise, consider the operator schema,
Op 2 O, from which a is formed. As described in Section 2.7, no constants appear in Op
and all variables in the body of Op are parameters of Op. Let the initial collection of PRSs
constructed from Op, for those parameters instantiated with o in the creation of a, be the
set PRS1 :::PRSn where every PRSi has the form:
precs :
Pi
deleted precs : Di
add elements : Ai
and the initial collection is the collection formed prior to splitting.
For each value of i the ith PRS will lead to the construction of k + 1 transition rules,
where k is the size of the bag intersection, Xi , of Di and Ai . The k rules will be of the
following form:
8c 2 Xi  (Pi 	 fcg ) c ! c)
and the remaining rule will be of the form:

Pi 	 (Di 	 Xi ) ) (Di 	 Xi) ! (Ai 	 Xi )
We refer to the latter rule for PRSi as the ith complex rule. A subset of the n complex
rules will contain a property in Ps in either the start or the nish and will, therefore, be
relevant to the transition from pre-St to St. It can be observed that these m complex
rules (PRS1 :::PRSm without loss of generality) must be in P because of the uniting process
described in 2.3.
We dene pres(a)oP to be the P -projection of the preconditions of a for o. Similarly,
adds(a)oP and dels(a)oP are dened to be the P -projections of the add and delete lists
respectively. By construction of the PRSs, dened in Section 3.1,
m
M
= Pi
Mm
adds(a)oP = Ai
Mm
dels(a)oP = Di

pres(a)oP

1
1

1

395

Fox & Long

Because of the restriction that delete lists must be a subset of preconditions, and the
fact that a is applicable to pre-St, it follows that dels(a)oP v pres(a)oP v pre-StoP . Since
v represents bag inclusion it can be seen that all of the separate bags Di are included in
pre-StoP without overlap.
The extension process involves the iterated application of the rules as explained in
Section 2.4 and indicated in the pseudo-code algorithm presented in Appendix B.
For a rule to be applicable to a state its start must be included in the state. Therefore
the m complex rules are all applicable, regardless of the sequence of application, to pre-StoP .
It follows that the state
(pre-StoP 	

Mm (Di 	 Xi))  Mm (Ai 	 Xi)
1

1

is generated in the extension process. By denition of Xi , and the fact that Di v pre-StoP ,
this state can be written as:
(pre-StoP 	

Mm Di)  M Ai
1

which, as observed above, is just:
(pre-StoP 	 dels(a)oP )  adds(a)oP
which equals StoP by the standard semantics of operator application in strips.

2

The proof demonstrates that splitting, discussed in 2.3, does not result in the generation
of invalid invariants. However, splitting can compromise the completeness of the invariantgeneration process. It can result in the inclusion of unreachable states in property spaces,
with the consequence that the identity and state membership invariants that are generated
are weaker than would otherwise be the case. This is further discussed in Section 3.2.
We now explain the role of splitting in the PRS construction phases. Each domain
object in a strips domain has an associated nite automaton in which the states consist of
the properties (for example, at1 ) it can have, either initially or as a result of the application
of an arbitrary length sequence of operators. Objects that can be observed to be of the
same type will have identical automata at the property level. The PRSs capture the ways
in which operator applications modify the congurations of individual objects and hence
provide an encoding of these automata.
The PRSs are built in two phases. In the rst phase, all of the parameters in all of the
schemas are considered, so all possible object state transitions are captured. However, some
of these transitions conceal the functional distinctions inherent in the domain description
and would lead to premature amalgamation of property spaces, as was observed in the
discussion of the Rocket domain in Section 2.5. In that example it was observed that use
of our standard formula for the construction of rules from these PRSs alone would result in
the failure to detect the type distinction between rockets and packages.
The second phase assists the type inference processes in avoiding under-discrimination
by distinguishing enablers of a state transformation from the properties that are exchanged
396

Automatic Inference of State Invariants

during the transformation. Each PRS characterizing the exchange of k properties is split
to form at most k + 1 new PRSs. The PRSs 4 and 5, given in Section 2.3, show how two
PRSs are constructed from a single PRS containing a single exchanged property. This is a
simple example, as only one split is required to remove exchanges. In general it might be
necessary to split repeatedly until all exchanges are removed, as shown in the example given
by PRS 6 in Section 2.3. No non-exchange combinations of the properties in deleted precs
and add elements should be considered during splitting. The resulting PRSs lead to the
construction of transition rules which allow generic state transformations, such as movement
from one location to another, to be separated from the specic nature of the objects that
can make those transformations.
It can be observed that the rules that result from the splitting process are more general
than the rules that would have been obtained from the PRS prior to splitting. They
distinguish more precisely between the properties that take part in state transitions and
the properties that simply enable those transitions, allowing ner type distinctions to be
inferred on the basis of the functionalities of the objects in the domain. Finer distinctions
are made during the process of seeding property and attribute spaces by uniting. This is
because uniting merges, into single equivalence classes, all of the properties that appear in
both the start and nish of a rule.
We argue that all state transformations are accounted for by the end of this second
phase. The result of the second phase is that the automata formed during the rst phase
are separated into collections of simpler automata where possible, so that no transitions
are lost but there is a ner grained encoding of the possible transitions that can be made
by objects with appropriate properties. The PRSs constructed in this phase support the
construction of rules that allow objects making these transitions to occupy dierent property
spaces. Some of the second phase PRSs may be under-constraining, in the sense that
analysis of subsequent schemas might eliminate the possibilities they are keeping open, as
in example 2.3.1, but the set of PRSs obtained at the end of the second phase cannot be
over-constraining because all of the rst phase PRSs are considered for splitting.
A subtlety concerns the consequence, at the type level, of assigning two functionally
distinct objects to the same state or attribute space. For example, in example 2.5, rocket
and package are both assigned to the property space for fin1; at1 g and the attribute space for
fin2g. However, because rocket can be fuelled or unfuelled, and the package cannot, there is
a distinction between them that emerges in the property and attribute membership vectors
associated with the rocket and package objects. Membership of the additional property space
for ffuelled1; unfuelled1g means that rocket is assigned a type that is a sub-type of the type
of package and the functional distinctness of rocket and package is recognised. As discussed,
there is an oddity in this encoding that results in the package being assigned membership
of the fin2g attribute space. Furthermore, at1 and in1 were united, with the eect that
rockets can make the at1 ! in1 transition and can be used to instantiate variables of type
movable object, even when variables of this type are intended only to be instantiated with
the package. There is nothing in the domain description to prevent this interpretation. A
more conventional encoding of the load schema would prevent the rocket from being loaded
into any other object, and this would cause a renement in the type structure that would
identify loadable objects, and would prohibit the use of the rocket in forming instances of
operators that should be restricted to operating on those objects.
397

Fox & Long

The construction of transition rules follows a simple rule whereby any undeleted preconditions are used to enable a transformation from a state in which the deleted preconditions
of a PRS hold to one in which the added elements of the PRS hold. Given the assumption
that all deleted atoms in an operator schema must appear as preconditions in that schema,
these rules correctly characterize strips-style state transformations. All possible transformations are captured because of the second phase of PRS construction. A complete set of
correct transition rules is therefore constructed.
Given the correctness and completeness of the transition rule construction phase, correct
initial allocation of objects to spaces depends simply on correctly checking membership of
the initial properties of the object in the property sets, formed by uniting the rules, that
are used to seed the spaces. Extension of the property spaces is done by straightforward
application of the transition rules, so all congurations of properties that can be occupied
by the objects in the property space will have been added by the end of the extension phase.
Extension of the attribute spaces is unproblematic in the cases where no potential enabler
is itself an attribute. If one is, then the process by which the attribute space of that enabler
is completed could, it appears, initiate a loop in the attribute space extension process. In
fact, this does not happen as tim is able to detect when a loop has occurred and avoid
repeatedly iterating over it.
The following example illustrates the problem and the way it is solved in tim. Suppose
we have three attribute spaces:

Attribute space 1

fq1g p1 ) null ! q1 fa; bg

Attribute space 2
fr1g q1 ) null ! r1 fcg

Attribute space 3
fp1g r1 ) null ! p1 fdg
These spaces are extended by the addition of objects that potentiate their increasing rules,
as discussed in Section 2.4. No problem arises if the enablers of these rules are states, and
not attributes, but in the extension of attribute space 1 above the enabler, p1 , is an attribute.
The attribute space for p1 has not yet been extended, so it is necessary to complete that
space before using it to complete 1. Extension of 3 requires the extension of 2, for the same
reason, and that requires the extension of 1 which requires the extension of 3, and so on.
The way tim avoids re-entering this loop is by marking each space, as it is considered, as
having been seen on this iteration. When a marked space is encountered it is not extended
but is used as if it is already complete. Then a second iteration is required to extend
any spaces that still require completion. Subsequent iterations will be required until the
process converges. Our experiments suggest that it is unusual for there to be more than
two iterations required. A worst case upper bound is o  As, where o is the number of
domain constants and As is the number of attribute spaces (which is limited by the number
of properties), and hence quadratic in the size of the domain description.
398

Automatic Inference of State Invariants

If the extension process starts with attribute space 1, in the above example, attribute
space 1 will be marked as having been seen on the rst iteration. Tim then goes on to
extend space 3 because the extension of space 1 depends upon space 3 being complete.
Space 3 is marked as having been seen on this iteration and space 2 is considered. Space 2
is marked and space 1 is revisited. Because space 1 is marked tim infers that a loop has
been entered. Its objects are added to space 2 without extension and the objects of space 2
are then added to space 3. Finally, the objects of space 3 can be added to space 1 and the
rst iteration is complete.

fq1g p1 ) null ! q1 fa; bg [ fc; dg
fr1g q1 ) null ! r1 fcg [ fa; bg
fp1g r1 ) null ! p1 fdg [ fc; a; bg
However, space 2 is not yet complete, so a second iteration is required. This iteration
starts in the same place as the rst and the process is repeated, except that no further
iterations will be required in this example.

3.2 Correctness of the State Invariants

We now argue for the correctness of the invariant inference procedure by considering each
of the four kinds of invariant in turn. The following arguments rely upon correctly distinguishing property spaces from attribute spaces, since the invariant analysis cannot be
performed on attribute spaces. The only scope for confusing this distinction is in the extension of mixed spaces, but we extract attributes from mixed spaces by checking for inclusion
of existing states in the new states generated during extension. This process was discussed
in Section 2.8.

Denition 16 Given a property space P = (Ps; TRs; Ss; Os), Ss can be partitioned into
three disjoint sets: Sssubs and Sssups that contain all of the states in Ss that are included
(as bags) or that include (as bags), respectively, at least one other state in Ss and Ssind
that contains all of the independent states in Ss that are neither in Sssubs nor in Sssups .
Theorem 2 Given a property space P = (Ps; TRs; Ss; Os), in which the set of states Ss

is a union of the three disjoint sets of states Ssind , Sssubs and Sssups , for each object, o, in
Os the following families of invariants will hold:
1. identity invariants;
2. state membership invariants;
3. unique state invariants.
as dened in Section 3.2.

Proof:

We address each kind of invariant in turn. By Theorem 1 every object in Os must be in
a state in Ss. Furthermore, all states of each object in Os, with respect to each property in
Ps, will be in Ss. This follows because the properties are partitioned between the spaces
399

Fox & Long

during the seeding process. Therefore, the maximum number of occurrences of a property
p in Ps, possessed by any object in Os in any state of the world, will be bounded by the
maximum number of instances of that property in any state in Ss (these maximum values
might not be equal since Ss can contain inaccessible states). The identity invariants simply
express this bound on the properties of the objects in Os.
Every object in Os must be in a state in Ssind [Sssubs . This follows by denition of
these sets in Denition 16 and by Theorem 1. The state membership invariants assert that
every object in Os must be in at least one of these states, with each disjunct in the invariant
corresponding to the assertion of membership of one of these states.
To argue for the correctness of the unique state invariants, we observe that the proposed
invariants would only be false if they paired states that were not mutually exclusive. In
this case, either the state extension process would have put properties that could be simultaneously held into the same bag, or such properties would be simultaneously held in the
initial state and hence would appear in the same bag on initial construction of the property
space. In either case, a state will exist in the property space that is a superset of both of
the non-exclusive states. However, uniqueness invariants are generated for pairs of states
drawn only from Ssind [ Sssups so these non-exclusive pairs of states will not lead to the
generation of incorrect invariants.

2
The xed resource invariants are always associated with a particular predicate. If atoms
built with that predicate are balanced on the add and delete lists of all of the operator
schemas then the number of occurrences of these atoms in the initial state is xed over all
subsequent states. This is what the invariant expresses. An invariant is constructed for
every predicate that forms balanced atoms.
Since no new techniques are required to infer invariants from sub-spaces, no further
argument is required to support correctness of the invariants formed following sub-space
analysis.
Although Theorem 2 demonstrates the correctness of the invariants inferred by tim it
is possible for weak invariants to be inferred from the presence of unreachable states in Ss.
Weak identity invariants are inferred if an unreachable state is generated, during extension,
containing more instances of a property than are contained in any reachable state. When
this happens an identity invariant will be generated that is weaker than would be ideal, but
is still valid. Further, if a property space contains unreachable states they will cause the
inclusion of additional false disjuncts in the state membership invariants, but since these
false disjuncts will not exclude satisfying assignments their presence will not invalidate
the invariants. Unreachable states cause additional tautologous uniqueness invariants to be
generated but do not aect the strength of the invariants that refer only to reachable states.
Clearly we cannot hope to identify all of the unreachable states, as such an analysis would
be as hard as planning itself.
Because no invariants are generated for attribute spaces tim cannot be claimed to be
complete. Sub-space analysis recties this to some extent by identifying property spaces
that exist within attribute spaces and allowing further invariants to be generated. This
analysis could be further rened.
400

Automatic Inference of State Invariants

3.3 Eects of TIM on the Properties of the Planner

Tim is itself sound, so no planner that uses tim is in danger of losing soundness as a result.
Tim is certainly not complete for all domain axioms because there are invariant properties of

other kinds that cannot be extracted by the current version. For example, Kautz and Selman
(1998) identify optimality conditions and simplifying assumptions amongst the dierent
kinds of axioms that might be inferred from a domain. An optimality condition in the
Logistics domain might be: a package should not be returned to a location it has been
removed from. A simplifying assumption in the same domain might be: once a truck is
loaded it should immediately move (assuming all necessary loads can be done in parallel).
These constraints require a deeper analysis of the domain than is currently performed by
tim, but we intend to characterise them and infer them in our future work.
We cannot guarantee that the type structure inferred by tim is always fully discriminating, although we do guarantee that it is not over-discriminating. However, failure on
tim's part to infer all of the structure that is there to be inferred does not impact on the
completeness of a planner using tim because, in these cases, tim will return an unstructured
domain and the planner can therefore default to reasoning with the unstructured domain
when necessary.

4. Experimental Results

An examination of tim's performance can be carried out on several dimensions. We consider
three specic dimensions here: the viability of the analysis on typical benchmark domains;
the scalability of the analysis and the utility of performing the analysis prior to planning. Its
general performance on standard benchmark problems provides an indication of the scale of
the overhead involved in using tim as a preprocessing tool. All experiments were performed
under Linux on a 300MHz PC with 128 Mb of RAM. Figure 3 shows that, even on large
problem instances, the overhead is entirely acceptable. All of the Mystery problems listed
in this table are very large (involving initial states containing hundreds of facts) and could
not be solved by stan, ipp (Koehler, Nebel, & Dimopoulos, 1997) or Blackbox (Kautz &
Selman, 1998) in the aips-98 competition. The nature of the Mystery domain is described
in Appendix C. This emphasises the relative costs of the preprocessing and planning eorts.
The selection of problems used to construct table 3 is justied as follows. In the Blocks
world we have used a representative example from each of three encodings supplied in the
pddl release. These are: the simple encoding (prob12), the att encoding (prob18) and the
snlp encoding (prob23). The Hanoi set contains a collection of reasonably sized problems.
A representative group of relatively large Mystery instances was chosen from the pddl
release. The two Tyre world instances are the only two strips instances available in the
release. The three Logistics problems are the three largest for the simple strips encoding
included in the pddl release.
The second dimension is scalability of the analysis. An analytic examination of the
algorithm can determine an upper bound on performance that is polynomial in all of the
key domain and problem components, including number of operator schemas, number of
literals in operators, numbers of objects and facts in the initial state and the number and
arities of predicates in the language. Figure 4 shows that the performance of tim is roughly
quadratic in the size of the problem specication. In the graph, size is crudely equated with
401

Fox & Long

Domain and problem
Blocks
prob12.pddl
prob18.pddl
prob23.pddl
Hanoi
3-disc
4-disc
5-disc
6-disc
7-disc
Mystery
prob060.pddl
prob061.pddl
prob062.pddl
prob063.pddl
prob064.pddl
Tyre-World prob01.pddl
prob02.pddl
Logistics
prob04.pddl
prob05.pddl
prob06.pddl

Parse time
2
3
2
2
2
3
3
4
17
48
26
11
21
5
6
4
4
4

Analysis time
0
1
1
1
1
1
1
2
15
82
37
7
21
2
2
2
2
2

Output time Total
2
5
2
7
1
5
4
7
4
7
4
8
4
9
4
11
9
43
29
160
10
74
8
27
10
52
28
36
28
37
5
12
6
12
6
13

Figure 3: Table showing tim's performance in milliseconds on standard domains and problems. All timings are elapsed times and minor discrepancies in totals arise from
rounding.

402

Automatic Inference of State Invariants

Tim Analysis of Mystery Domain

12000
10000



8000
Millisecs 6000



4000
2000

 








0 
0

   



10000 20000 30000 40000 50000 60000 70000 80000
Size of le

Figure 4: Graph showing tim's performance on Mystery problems, plotting time against
size (in characters) of problem le. The solid line is a plot of a quadratic function.
the number of characters in the specication le. This graph was constructed by running
tim on all of the strips Mystery domain problems in the pddl release. The increasing
sizes of the problem specications reect increases in any and all of the various categories
of objects in the domain and corresponding facts to describe their initial states.
Figure 5 shows the eect on tim's performance as the number of operator schemas
increases. This graph was constructed using an articial domain in which each new operator
causes two new state transitions described by two new literals. Thus, both number of
operators and number of properties is increasing whilst the number of objects stays constant.
The domain is described in detail in Appendix E. The graph indicates the linear growth of
cost of analysis.
The nal dimension for evaluating tim is the eect of exploitation of its output by a
planner. Gerevini and Schubert (1998) and Kautz and Selman (1998) provide convincing
evidence supporting the powerful role of state invariants in enhancing the performance of
SAT-based planning. In Figure 6 we demonstrate the power of inferred types by showing the
advantage that stan with tim obtains over stan without tim on untyped Rocket domain
problems. Figure 6 shows the eect on performance of increasing the number of packages
to be transported. The time taken by stan with tim grows linearly, whilst stan without
tim follows a cubic curve. If there are p packages in a problem instance then stan with tim
constructs 4(p +1) operator instances while stan without tim constructs (p +3)2(p +5)+2p
instances. This demonstrates that type information is the most signicant factor in the
advantage depicted in the graph. Figure 7 demonstrates that a similar improvement is
obtained in the Logistics domain. In this graph a series of sub-problems were considered in
403

Fox & Long

70
65
60
55
50
Millisecs 45
40
35
30
25
20

Tim Performance with Increasing Number of Operators

3
0

3
2

3

3
4

3

3

3

3

3

3

3

6
8
10
Number of operators

3

3

3

12

33

14

16

Figure 5: Graph showing the consequences of increasing the number of schemas and inferrable property spaces.
The Eect of Tim on the Performance of Stan

12000

3

STAN without TIM 3
STAN with TIM +

10000
8000

3

Millisecs6000
4000

3

3

3

3

3

3

33
3
333
33
+ + ++ + + + ++ + + + ++ +
+ 3
++
+ 3
0 3

2000

0

5

10

15
20
25
Number of packages

30

35

40

Figure 6: Graph showing comparison between stan with and stan without tim on Rocket
domain problems generated from the Rocket domain provided in Appendix D.
404

Automatic Inference of State Invariants

The Eect of Tim on the Performance of Stan

12000
10000

STAN without TIM
STAN with TIM

8000
Millisecs6000
4000
2000
0

1

1.5

2

2.5
3
3.5
Number of sub-problems

4

4.5

5

Figure 7: Graph showing comparison between stan with and stan without tim on Logistics
domain problems.
which each sub-problem involves the independent transportation of a single package between
two cities.
In very simple domains, the overhead of carrying out this analysis can outweigh the
advantages oered. For example, in the Movie domain used in the competition stan gained
no benets from using tim but paid the overhead to the detriment of its performance on
instances from that domain. However, in general we observe that the benets of this analysis
increase with the increasing complexity of domains.

5. Related Work
Although the importance of state invariants for ecient planning has been observed there
has been relatively little work on automatic inference of invariants. The published work that
most closely resembles the research described in this paper is the state constraint inference
system discoplan, of Gerevini and Schubert (1998). Discoplan enables the inference
of sv-constraints that correspond to a subset of our identity invariants. The reason that
discoplan is restricted to a subset is that it generates sv-constraints only for pairs of literals
(one on the addlist of a schema and the other on the delete list) in which the arguments
vary in only one place. Tim can infer identity invariants in which vectors of arguments vary,
as shown in Section 2.7. Discoplan cannot currently infer all singly varying constraints
(although the techniques described by Gerevini and Schubert (1996a) are not yet fully
implemented in discoplan). For example, discoplan cannot infer that all blocks can only
405

Fox & Long

be on one surface, in its analysis of the Blocks world domain cited in the paper. Tim can
infer these invariants from its sub-space analysis.
Gerevini and Schubert (1996a, 1996b) have also examined the potential for inferring
parameter domains that are similar to the operator parameter types inferred by tim. Their
domains are inferred by an iterative process of accretion which is similar to the attribute
space extension process of tim. However, the accretion process they describe is synthetic,
in that the parameter domains are synthesised directly from the operator descriptions and
initial state. Tim is an analytic system that constructs its types from an analysis of the functional properties of the domain objects. This analytic approach provides a rich information
source from which other structures, including the domain invariants, can be derived.
Some of the implicative constraints inferred by discoplan correspond to an implicit
type assignment and would arise in the type structure built by tim. A further implicative
constraint generated by discoplan refers to the separation of functional roles of objects.
In particular, the irreexivity of on, as in:
8x  8y  (on(x; y) ! :(x = y))
can be captured using this kind of constraint. Tim cannot currently infer these invariants.
Because tim uses an analysis based on the state view of objects in the domain it is able
to generate a broader collection of invariants, including state membership and unique state
invariants currently not produced by discoplan.
Although discoplan can deal with negative preconditions and tim cannot yet manage
them, the invariants they produce overall are currently less powerful than those inferred by
tim.
Apart from the work of Gerevini and Schubert, there is some older work on the inference
of invariants which also relies on the generation of candidate invariants which are then
conrmed by an inductive process against the domain operators. Two examples are the
work of Kelleher and Cohn (1992) and Morris and Feldman (1989). The former work
concentrates on identifying directed mutual persistence relations, which hold between pairs
of facts in a domain when, once both are established, the second continues to hold while
the rst does. The use of these relations leads to the inference of a collection of constraints
which fall into the uniqueness invariants inferred by tim. In the work described in (Morris
& Feldman, 1989) the authors build invariants by using truth counts which are counts of the
number of propositions from particular identied sets which must be true in any state of
the domain. Sets for which this count is 1 can then be used to build invariants which are a
subset of the state membership and uniqueness invariants. The authors describe methods for
attempting to identify the sets of facts from which to work. This work, in common with that
of Kelleher and Cohn and of Gerevini and Schubert, builds invariants by rst hypothesising
a possible seed for the invariants and then determining their validity by analysing the eects
of the operators on these seeds. In contrast to this generate-and-test strategy, tim produces
only correct invariants which it infers from a deep, structural analysis of the domain. The
inference of invariants does not exhaust the possibilities of this analysis. For example,
the type structure is inferred automatically during this analysis, which has been shown to
have dramatic potential for the eciency of planning. The relationship between enablers,
and the state transitions they enable, determines an ordering on the satisfaction of goals,
which also has signicance for eciency. Further, the state-based view of the behaviour of
406

Automatic Inference of State Invariants

domain objects would allow the techniques described by McCluskey and Porteous (1997)
to be automated.
McCluskey and Porteous (1997) have proposed and explored an object-centred approach
to planning. This approach is based on the provision, by a domain engineer, of a rich
collection of state invariants for object sorts participating in functional relationships in the
domain. These invariants are then exploited in a domain compilation phase to facilitate an
ecient planning application to that domain. Tim infers precisely the sorts and collections
of state invariants that McCluskey and Porteous provide by hand.
Grant (1996) generates state invariants from state descriptions, provided by hand, and
then uses these invariants to build operator schemas. His approach is clearly related even
though the objectives of his analysis are dierent. Grant is concerned with the automatic
synthesis of domain descriptions from a rich requirements specication provided by an
expert user. Our concern is with reverse-engineering a domain description to obtain the information that can help increase the eciency of planners applied to that domain. Although
the primary objectives in the use of tim are to enhance the performance of planning within
a domain, tim also provides a valuable tool in the construction of domain descriptions by
revealing the underlying behaviours that the domain engineer has implicitly imposed, and
helping with the debugging of domain descriptions.

6. Conclusion
Tim is a planner-independent set of techniques for identifying the underlying structure of a

domain, revealing its type structure and a collection of four dierent kinds of invariant conditions. One important application of these techniques is as a domain debugging aid during
the construction of large and complex domains. Using tim has revealed many anomalies
in domains encoded by us and by others, and has greatly assisted us in understanding
stan's performance on many domains and problems. Another important application is in
increasing the eciency of planners by making explicit to the planner information about
the domain that it would otherwise have to infer, from the domain representation, during
planning.
Tim generates a rich collection of invariants containing many that are not inferrable by
related systems, as discussed in the previous section. The results presented by Gerevini
and Schubert (1998) suggest that a marked improvement can be obtained from the use of
invariants in the performance of planners based on SAT-solving techniques. No analysis
has yet been done to determine what advantages might be obtainable by using invariants in
planners based on other architectures. Stan does not yet exploit all of the invariants produced by tim during planning. It uses the type structure and the xed resource invariants
and we are currently developing an extension of stan that will fully exploit the other kinds
of invariant. We expect to be able to use the uniqueness and identity invariants to shortcut
the eort involved in deducing a signicant subset of the necessary mutex relations during
graph construction.
The analysis performed by tim is ecient, growing more slowly than a quadratic function
of the size of the initial state being analysed. Our empirical analysis does not consider
the eect on tim's performance of increasing numbers of operator schemas. However, the
argument presented in Section 4 shows that tim's analysis grows linearly with the number
407

Fox & Long

of operator schemas, linearly with the number of domain constants and linearly with the
size of the initial state. There are other factors to take into account, but this conrms a
polynomial performance as the size (and related structure) of the domain increases.
The type analysis performed by tim diers, in some important respects, from the various
forms of type analysis performed during the compilation of programs written in strongly
typed languages. In the latter context the type-correctness of a program is judged with
respect to an imposed context of basic types. Tim infers the basic types from the domain
description so it is impossible for a domain specication not to be well-typed. Consequently
we do not attempt to type-check domain descriptions using tim. This is a direction in which
we hope to move in the near future, because type-checking will enable some unsolvable
problems to be detected as unsolvable statically rather than at planning time. We currently
focus only on type inference and the exploitation of the inferred type structure in the
management of the search space of the planner.

7. Acknowledgements

We would like to thank Alfonso Gerevini, Gerry Kelleher and the anonymous referees for
useful discussions and helpful comments on earlier drafts of this paper.

Appendix A. FTP and Web Sites

The aips-98 Planning Competition FTP site is at:

http://ftp.cs.yale.edu/pub/mcdermott/aipscomp-results.html.

Our web site, on which stan and tim executables can be found, is at:



http://www.dur.ac.uk/ dcs0www/research/stanstuff/planpage.html

Appendix B. The TIM Algorithm

The following is a pseudo-code description of the tim algorithm.
fConstruct base PRSs (Section 2.3)g
Ps := fg;
for each operator schema, O,
for each variable in O, x,
construct a PRS for x from O and add to Ps;

fSplit PRSsg

for each PRS in Ps, P,
if a property, p, appears in P in both the adds and deleted precs elds
then split P over p, into P' and Q and replace P with P' and Q in Ps,
where to split P over p:
construct PRS Q with the same precs as P, deleted precs and adds both set to fpg;
construct PRS P' from P by removing p from deleted precs and adds of P;

fConstruct transition rules (Section 2.3)g
Ts := fg;

for each PRS in Ps, P,
construct a transition rule for P and add to Ts;

fSeed property and attribute spaces (Section 2.3)g

let each property be initially assigned to a separate equivalence class;
for each rule, r, in Ts
merge together (unite) the equivalence classes for all the properties in the start and nish of r;

408

Automatic Inference of State Invariants

construct a separate space for each equivalence class of properties;

fAssign transition rules (Section 2.4)g

for each rule, r, in Ts
place r in the space associated with the equivalence class containing the properties
in the start (and nish) of r, s;
if r is an increasing or decreasing rule
then mark s as an attribute space;

fAnalyse initial state (Section 2.4)g

for each object, o, in the domain
identify the bag of initial properties of o, I(o);
for each space, s,
construct the bag of properties from I(o) which belong to the equivalence class
associated with s, b;
if b is non-empty
then add o to the space s;
if s is not an attribute space
then add b as a state in s;

fExtend property spaces (Section 2.4)g

for each property space, p,
while there is an unextended state in p, s,
mark s as extended;
newgen := fg;
for each rule in p, r,
if the start of r is included in s
then add the state snew = (s ominus start oplus end) to newgen;
if snewis a superset of any state in newgen
then mark p is an attribute space and exit the analysis of p;
add newgen to the states in p;

fExtend attribute spaces (Section 2.4)g

changes := TRUE;
while changes,
changes := FALSE;
for each unmarked attribute space, a,
extend a where to extend a:
mark a;
for each rule in a, r,
for each property in enablers of r, p,
if p's equivalence class is associated with an unmarked attribute space, a',
then extend a';
add all objects that appear in every space associated with an enabling property for r to a;
if objects are added
then changes := TRUE;

fIdentify types (Section 2.6)g

for each object in the domain, o,
identify the pattern of membership of spaces for o, tt;
associate the type pattern, tt, with o;
for each operator schema, O,
for each argument of O, x,
identify the pattern of membership of spaces for x implied by the properties of x in the
preconditions of O, tt;
associate type pattern, tt, with x in O;

fConstruct invariants (Section 2.7)g

for each property space, P,
for each property in P, p,
construct an identity invariant for p;
construct a state membership invariant for P;
construct a uniqueness invariant for P;

409

Fox & Long

Appendix C. Example Output

The following output was produced by tim and can be found, along with other examples,
on the stan webpage. These examples show the details of the analysis performed on each
of three domains: a Flat-tyre domain, a Mystery domain and a Logistics domain. The
analysis is done with respect to an initial state and a set of operator schemas. The operator
schemas used in these three domains are those provided with the pddl strips releases for
these domains. The initial states were taken from the pddl release. The pddl release can
be found at http://www.cs.yale.edu/HTML/YALE/CS/HyPlans/mcdermott.html.

C.1 The Tyre World
TIM: Type Inference Mechanism - support for STAN: State Analysis Planner
D. Long and M. Fox, University of Durham

Reading domain file: domain01.pddl
Reading problem file: prob01.pddl
TIM: Domain analysis complete for flat-tire-strips
TIM: TYPES:
Type
Type
Type
Type
Type
Type
Type
Type

T0
T1
T2
T3
T4
T5
T6
T7

=
=
=
=
=
=
=
=

{wrench}
{wheel2}
{wheel1}
{trunk}
{the-hub}
{pump}
{nuts}
{jack}

It will be noticed that the two wheels are separated into dierent types. This is because
one wheel is intact and the other is not intact, and there is no operator for repairing wheels
that are not intact. The tools have each been given dierent types. This is because they
each appear as constants in dierent operators and therefore are functionally distinct.
TIM: STATE INVARIANTS:
FORALL x:T4. (on-ground(x) OR lifted(x))
FORALL x:T4. NOT (on-ground(x) AND lifted(x))
FORALL x:T3. (closed(x) OR open(x))
FORALL x:T3. NOT (closed(x) AND open(x))

410

Automatic Inference of State Invariants

FORALL x:T1 U T2. (deflated(x) OR inflated(x))
FORALL x:T1 U T2. NOT (deflated(x) AND inflated(x))

The invariants for hubs (below) suggest that almost anything could be on a hub. Since
this is not the case the type structure is under-discriminating. However, the additional
invariants drawn from the sub-space analysis provide enough information, in principle, to
discriminate more fully between the types. This information is not yet being fully exploited.
FORALL x:T4. FORALL y1. FORALL z1. on(y1,x) AND on(z1,x) => y1 = z1
FORALL x:T4. (Exists y1:T0 U T1 U T2 U T5 U T6 U T7. on(y1,x)
OR free(x))
FORALL x:T4. NOT (Exists y1:T0 U T1 U T2 U T5 U T6 U T7. on(y1,x)
AND free(x))
FORALL x:T4. FORALL y1. FORALL z1. tight(y1,x) AND tight(z1,x) => y1 = z1
FORALL x:T4. FORALL y1. FORALL z1. loose(y1,x) AND loose(z1,x) => y1 = z1
FORALL x:T4. ((Exists y1:T0 U T1 U T2 U T5 U T6 U T7. tight(y1,x)
AND fastened(x))
OR (Exists y1:T0 U T1 U T2 U T5 U T6 U T7. loose(y1,x)
AND fastened(x)) OR unfastened(x))
FORALL x:T4. NOT ((Exists y1:T0 U T1 U T2 U T5 U T6 U T7. tight(y1,x)
AND fastened(x))
AND (Exists y1:T0 U T1 U T2 U T5 U T6 U T7. loose(y1,x)
AND fastened(x)))
FORALL x:T4. NOT ((Exists y1:T0 U T1 U T2 U T5 U T6 U T7. tight(y1,x)
AND fastened(x)) AND unfastened(x))
FORALL x:T4. NOT ((Exists y1:T0 U T1 U T2 U T5 U T6 U T7. loose(y1,x)
AND fastened(x)) AND unfastened(x))

TIM: DOMAIN INVARIANTS:
|{x0:
|{x0:
|{x0:
|{x0:
|{x0:
|{x0:
|{x0:
|{x0:
|{x0:

container(x0)}| = 1
hub(x0)}| = 1
intact(x0)}| = 1
jack(x0)}| = 1
nut(x0)}| = 1
pump(x0)}| = 1
unlocked(x0)}| = 1
wheel(x0)}| = 2
wrench(x0)}| = 1

TIM: ATTRIBUTE SPACES:

411

Fox & Long

The attribute space for the properties in the rst of these groups is subjected to a much
more rigorous analysis in the sub-space invariants below.
Objects, x, in T0 U T1 U T2 U T5 U T6 U T7 can have property:
Exists y1:T3. in(x,y1);
Exists y1:T4. on(x,y1);
Exists y1:T4. tight(x,y1);
Exists y1:T4. loose(x,y1);
have(x);
Objects, x, in T3 can have property:
Exists y1:T0 U T1 U T2 U T5 U T6 U T7. in(y1,x);
Objects, x, in T3 all have property: container(x);
Objects, x, in T4 all have property: hub(x);
Objects, x, in T1 all have property: intact(x);
Objects, x, in T7 all have property: jack(x);
Objects, x, in T6 all have property: nut(x);
Objects, x, in T5 all have property: pump(x);
Objects, x, in T3 all have property: unlocked(x);
Objects, x, in T1 U T2 all have property: wheel(x);
Objects, x, in T0 all have property: wrench(x);

TIM: OPERATOR PARAMETER RESTRICTIONS:
inflate(x1:T1)
put-on-wheel(x1:T1 U T2,x2:T4)
remove-wheel(x1:T1 U T2,x2:T4)
put-on-nuts(x1:T6,x2:T4)
remove-nuts(x1:T6,x2:T4)
jack-down(x1:T4)
jack-up(x1:T4)
tighten(x1:T6,x2:T4)
loosen(x1:T6,x2:T4)
put-away(x1:T0 U T1 U T2 U T5 U T6 U T7,x2:T3)
fetch(x1:T0 U T1 U T2 U T5 U T6 U T7,x2:T3)
close-container(x1:T3)
open-container(x1:T3)
cuss()

TIM: ADDITIONAL STATE INVARIANTS, USING SUB-SPACE ANALYSIS:

We report here only the additional state invariants that add information to the invariants
already listed. TIM currently reports invariants that are subsumed by the earlier collection.
It should be observed that the rst wheel is intact but the second is not, and this gives
rise to the following new invariant for wheels of the second type.
412

Automatic Inference of State Invariants

FORALL x:T2. (deflated(x))

The rst attribute space, which contains all objects except the trunk and the hub, is now
subjected to sub-space analysis yielding a rich new collection of invariants.
FORALL x:T0. FORALL y1. FORALL z1. in(x,y1) AND in(x,z1) => y1 = z1
FORALL x:T0. (Exists y1:T3. in(x,y1) OR have(x))
FORALL x:T0. NOT (Exists y1:T3. in(x,y1) AND have(x))
FORALL x:T1. FORALL y1. FORALL z1. in(x,y1) AND in(x,z1) => y1 = z1
FORALL x:T1. FORALL y1. FORALL z1. on(x,y1) AND on(x,z1) => y1 = z1
FORALL x:T1. (Exists y1:T3. in(x,y1) OR have(x)
OR Exists y1:T4. on(x,y1))
FORALL x:T1. NOT (Exists y1:T3. in(x,y1) AND have(x))
FORALL x:T1. NOT (Exists y1:T3. in(x,y1) AND Exists y1:T4. on(x,y1))
FORALL x:T1. NOT (have(x) AND Exists y1:T4. on(x,y1))
FORALL x:T2. FORALL y1. FORALL z1. in(x,y1) AND in(x,z1) => y1 = z1
FORALL x:T2. FORALL y1. FORALL z1. on(x,y1) AND on(x,z1) => y1 = z1
FORALL x:T2. (Exists y1:T4. on(x,y1) OR have(x)
OR Exists y1:T3. in(x,y1))
FORALL x:T2. NOT (Exists y1:T4. on(x,y1) AND have(x))
FORALL x:T2. NOT (Exists y1:T4. on(x,y1) AND Exists y1:T3. in(x,y1))
FORALL x:T2. NOT (have(x) AND Exists y1:T3. in(x,y1))
FORALL x:T5. FORALL y1. FORALL z1. in(x,y1) AND in(x,z1) => y1 = z1
FORALL x:T5. (Exists y1:T3. in(x,y1) OR have(x))
FORALL x:T5. NOT (Exists y1:T3. in(x,y1) AND have(x))
FORALL x:T6. FORALL y1. FORALL z1. in(x,y1) AND in(x,z1) => y1 = z1
FORALL x:T6. FORALL y1. FORALL z1. tight(x,y1)
AND tight(x,z1) => y1 = z1
FORALL x:T6. FORALL y1. FORALL z1. loose(x,y1)
AND loose(x,z1) => y1 = z1
FORALL x:T6. (Exists y1:T4. tight(x,y1)
OR Exists y1:T4. loose(x,y1)
OR have(x) OR Exists y1:T3. in(x,y1))
FORALL x:T6. NOT (Exists y1:T4. tight(x,y1)
AND Exists y1:T4. loose(x,y1))
FORALL x:T6. NOT (Exists y1:T4. tight(x,y1) AND have(x))
FORALL x:T6. NOT (Exists y1:T4. tight(x,y1)
AND Exists y1:T3. in(x,y1))
FORALL x:T6. NOT (Exists y1:T4. loose(x,y1) AND have(x))
FORALL x:T6. NOT (Exists y1:T4. loose(x,y1)
AND Exists y1:T3. in(x,y1))
FORALL x:T6. NOT (have(x) AND Exists y1:T3. in(x,y1))

413

Fox & Long

C.2 The Mystery Domain

The Mystery domain was devised by Drew McDermott for the aips-98 planning competition.
His intention was to conceal the structure of the problem domain by employing an obscure
encoding of a transportation domain. The code replaces locations with the names of foods
and the routes between them with eats relations. The transports are pleasures while cargos
are pains. Cargos and transports can be at locations, with the at relation encoded as craves.
A cargo is either at a location or in a transport encoded by the fears relation. Transports
have restricted capacity encoded by planets and consume fuel in travelling between locations.
Fuel exists in limited quantities at locations measured by provinces. Using TIM we were
able to decode the domain and identify the roles played by each of the components of the
encoding.
TIM: Domain analysis complete for mystery-strips (prob048.pddl)
TIM: TYPES:

It should be noted that provinces (types T6, T7 and T8) are divided into three separate
types because they form a sequence, dened by the attacks relation, in which the rst and
last have a slightly dierent functional role to the others. The same is true of the planets
(types T1, T2 and T3).
Type T0 = {beef,cantelope,chocolate,flounder,guava,mutton,onion,
pepper,rice,shrimp,sweetroll,tuna,yogurt}
Type T1 = {saturn}
Type T2 = {pluto}
Type T3 = {neptune}
Type T4 = {achievement,lubricity}
Type T5 = {abrasion,anger,angina,boils,depression,grief,hangover,
laceration}
Type T6 = {alsace,bosnia,guanabara,kentucky}
Type T7 = {goias}
Type T8 = {arizona}

TIM: STATE INVARIANTS:
FORALL x:T4. FORALL y1. FORALL z1. harmony(x,y1)
AND harmony(x,z1) => y1 = z1
FORALL x:T4. (Exists y1:T1 U T2 U T3. harmony(x,y1))
FORALL x:T0. FORALL y1. FORALL z1. locale(x,y1)
AND locale(x,z1) => y1 = z1
FORALL x:T0. (Exists y1:T6 U T7 U T8. locale(x,y1))
FORALL x:T4 U T5. FORALL y1. FORALL z1. fears(x,y1)

414

Automatic Inference of State Invariants

AND fears(x,z1) => y1 = z1
FORALL x:T4 U T5. FORALL y1. FORALL z1. craves(x,y1)
AND craves(x,z1) => y1 = z1
FORALL x:T4 U T5. (Exists y1:T0. craves(x,y1)
OR Exists y1:T4. fears(x,y1))
FORALL x:T4 U T5. NOT (Exists y1:T0. craves(x,y1)
AND Exists y1:T4. fears(x,y1))

TIM: DOMAIN INVARIANTS:
|{(x0,x1): attacks(x0,x1)}| = 5
|{(x0,x1): eats(x0,x1)}| = 36
|{x0: food(x0)}| = 13
|{(x0,x1): harmony(x0,x1)}| = 2
|{(x0,x1): locale(x0,x1)}| = 13
|{(x0,x1): orbits(x0,x1)}| = 2
|{x0: pain(x0)}| = 8
|{x0: planet(x0)}| = 3
|{x0: pleasure(x0)}| = 2
|{x0: province(x0)}| = 6

TIM: ATTRIBUTE SPACES:
Objects, x, in T1 U T2 U T3 can have property:
Exists y1:T4. harmony(y1,x);
Objects, x, in T6 U T7 U T8 can have property:
Exists y1:T0. locale(y1,x);
Objects, x, in T4 can have property:
Exists y1:T4. fears(y1,x);
Objects, x, in T0 can have property:
Exists y1:T4 U T5. craves(y1,x);
Objects, x, in T6 U T7 all have property:
Exists y1:T6 U T8. attacks(x,y1);
Objects, x, in T6 U T8 all have property:
Exists y1:T6 U T7. attacks(y1,x);
Objects, x, in T0 all have property:
Exists y1:T0. eats(x,y1);
Objects, x, in T0 all have property:
Exists y1:T0. eats(y1,x);
Objects, x, in T0 all have property: food(x);
Objects, x, in T2 U T3 all have property:
Exists y1:T1 U T2. orbits(x,y1);

415

Fox & Long

Objects, x, in
Exists y1:T2 U
Objects, x, in
Objects, x, in
Objects, x, in
Objects, x, in

T1 U T2 all have property:
T3. orbits(y1,x);
T5 all have property: pain(x);
T1 U T2 U T3 all have property: planet(x);
T4 all have property: pleasure(x);
T6 U T7 U T8 all have property: province(x);

TIM: OPERATOR PARAMETER RESTRICTIONS:
succumb(x1:T5,x2:T4)
feast(x1:T4,x2:T0,x3:T0)
overcome(x1:T5,x2:T4)

TIM: ADDITIONAL STATE INVARIANTS, USING SUB-STATE ANALYSIS:

These additional invariants show that the transports are always at a location and never
loaded into other transports.
FORALL x:T4. FORALL y1. FORALL z1. craves(x,y1)
AND craves(x,z1) => y1 = z1
FORALL x:T4. (Exists y1:T0. craves(x,y1))

C.3 The Logistics Domain
TIM: Domain analysis complete for logistics-strips (prob05.pddl)
TIM: TYPES:
Type T0 = {bos-truck,la-truck,pgh-truck}
Type T1 = {bos-po,la-po,pgh-po}
Type T2 = {bos-airport,la-airport,pgh-airport}
Type T3 = {bos,la,pgh}
Type T4 = {package1,package2,package3,package4,package5,package6,
package7,package8}
Type T5 = {airplane1,airplane2}

TIM: STATE INVARIANTS:
FORALL x:T0 U T4 U
AND at(x,z1) => y1
FORALL x:T0 U T4 U
AND in(x,z1) => y1
FORALL x:T0 U T4 U

T5. FORALL y1. FORALL z1. at(x,y1)
= z1
T5. FORALL y1. FORALL z1. in(x,y1)
= z1
T5. (Exists y1:T1 U T2. at(x,y1)

416

Automatic Inference of State Invariants

OR Exists y1:T0 U T5. in(x,y1))
FORALL x:T0 U T4 U T5. NOT (Exists y1:T1 U T2. at(x,y1)
AND Exists y1:T0 U T5. in(x,y1))

TIM: DOMAIN INVARIANTS:
|{x0: airplane(x0)}| = 2
|{x0: airport(x0)}| = 3
|{x0: city(x0)}| = 3
|{(x0,x1): in-city(x0,x1)}| = 6
|{x0: location(x0)}| = 6
|{x0: obj(x0)}| = 8
|{x0: truck(x0)}| = 3

TIM: ATTRIBUTE SPACES:
Objects, x, in
Exists y1:T0 U
Objects, x, in
Exists y1:T0 U
Objects, x, in
Objects, x, in
Objects, x, in
Objects, x, in
Objects, x, in
Objects, x, in
Objects, x, in
Objects, x, in

T1
T4
T0
T4
T5
T2
T3
T1
T3
T1
T4
T0

U T2 can have property:
U T5. at(y1,x);
U T5 can have property:
U T5. in(y1,x);
all have property: airplane(x);
all have property: airport(x);
all have property: city(x);
U T2 all have property: Exists y1:T3. in-city(x,y1);
all have property: Exists y1:T1 U T2. in-city(y1,x);
U T2 all have property: location(x);
all have property: obj(x);
all have property: truck(x);

TIM: OPERATOR PARAMETER RESTRICTIONS:
drive(x1:T0,x2:T1 U T2,x3:T1
fly(x1:T5,x2:T2,x3:T2)
unload(x1:T0 U T4 U T5,x2:T0
load-plane(x1:T4,x2:T5,x3:T1
load-truck(x1:T4,x2:T0,x3:T1

U T2,x4:T3)
U T5,x3:T1 U T2)
U T2)
U T2)

TIM: ADDITIONAL STATE INVARIANTS, USING SUB-STATE ANALYSIS:

417

Fox & Long

The following invariants add the constraints that trucks and airplanes must always be at a
location and never loaded into one another.
FORALL x:T0. FORALL y1. FORALL z1. at(x,y1) AND at(x,z1) => y1 = z1
FORALL x:T0. (Exists y1:T1 U T2. at(x,y1))
FORALL x:T5. FORALL y1. FORALL z1. at(x,y1) AND at(x,z1) => y1 = z1
FORALL x:T5. (Exists y1:T1 U T2. at(x,y1))

Appendix D. The Rocket Domain

The Rocket domain used in the construction of Figure 6 is as follows:
(define (domain rocket)
(:predicates
(at ?x ?y)
(in ?x ?y)
(fuelled ?x)
(unfuelled ?x)
(loc ?x)
(obj ?x)
(container ?x))
(:action fly
:parameters (?x ?y ?z)
:precondition (and (at ?x ?y) (loc ?z) (fuelled ?x))
:effect (and (not (at ?x ?y)) (at ?x ?z) (unfuelled ?x)
(not (fuelled ?x))))
(:action load
:parameters (?x ?y ?z)
:precondition (and (obj ?x) (container ?y) (at ?x ?z)
(at ?y ?z))
:effect (and (in ?x ?y) (not (at ?x ?z))))
(:action unload
:parameters (?x ?y ?z)
:precondition (and (at ?y ?z) (in ?x ?y))
:effect (and (at ?x ?z) (not (in ?x ?y)))))

Appendix E. Operator Test Domain

This domain is an articial domain used to test the eects of increasing operators and literals
in the domain encoding on the performance of TIM. This example is the third instance - the
variation was achieved by adding more operator schemas in the pattern of those included
here.
418

Automatic Inference of State Invariants

(define (domain od)
(:predicates
(p1 ?x ?y) (q1 ?x ?y)
(p2 ?x ?y) (q2 ?x ?y)
(p3 ?x ?y) (q3 ?x ?y)
(p4 ?x ?y) (q4 ?x ?y)
(p5 ?x ?y) (q5 ?x ?y)
(p6 ?x ?y) (q6 ?x ?y)
(p7 ?x ?y) (q7 ?x ?y)
(p8 ?x ?y) (q8 ?x ?y)
(p9 ?x ?y) (q9 ?x ?y)
(p10 ?x ?y) (q10 ?x ?y)
(p11 ?x ?y) (q11 ?x ?y)
(p12 ?x ?y) (q12 ?x ?y)
(p13 ?x ?y) (q13 ?x ?y)
(p14 ?x ?y) (q14 ?x ?y)
(p15 ?x ?y) (q15 ?x ?y)
(p16 ?x ?y) (q16 ?x ?y)
(p17 ?x ?y) (q17 ?x ?y)
(p18 ?x ?y) (q18 ?x ?y)
(p19 ?x ?y) (q19 ?x ?y)
(p20 ?x ?y) (q20 ?x ?y))
(:action o1
:parameters (?x ?y ?z)
:precondition (and (p1 ?x ?y) (q1 ?x ?z))
:effect (and (not (p1 ?x ?y)) (not (q1 ?x ?z))
(p1 ?x ?z) (q1 ?x ?y)))
(:action o2
:parameters (?x ?y ?z)
:precondition (and (p2 ?x ?y) (q2 ?x ?z))
:effect (and (not (p2 ?x ?y)) (not (q2 ?x ?z))
(p2 ?x ?z) (q2 ?x ?y)))
(:action o3
:parameters (?x ?y ?z)
:precondition (and (p3 ?x ?y) (q3 ?x ?z))
:effect (and (not (p3 ?x ?y)) (not (q3 ?x ?z))
(p3 ?x ?z) (q3 ?x ?y))))

The problem instance was xed as follows:
(define (problem op)
(:domain od)
(:objects a b c)

419

Fox & Long

(:init

(p1 a b)
(q1 a c)
(p2 a b)
(q2 a c)
(p3 a b)
(q3 a c)
(p4 a b)
(q4 a c)
(p5 a b)
(q5 a c)
(p6 a b)
(q6 a c)
(p7 a b)
(q7 a c)
(p8 a b)
(q8 a c)
(p9 a b)
(q9 a c)
(p10 a b)
(q10 a c)
(p11 a b)
(q11 a c)
(p12 a b)
(q12 a c)
(p13 a b)
(q13 a c)
(p14 a b)
(q14 a c)
(p15 a b)
(q15 a c)
(p16 a b)
(q16 a c)
(p17 a b)
(q17 a c)
(p18 a b)
(q18 a c)
(p19 a b)
(q19 a c)
(p20 a b)
(q20 a c))
(:goal (and (p1 a c) (q1 a b))))

References

Blum, A., & Furst, M. (1995). Fast Planning through Plan-graph Analysis. In IJCAI.
Bundy, A., Burstall, R., Weir, S., & Young, R. (1980). Articial Intelligence: An Introductory Course. Edinburgh University Press.
Fikes, R., & Nilsson, N. (1971). STRIPS: A New Approach to the Application of TheoremProving to Problem-Solving. Articial Intelligence, 2 (3).
Gerevini, A., & Schubert, L. (1996a). Accelerating Partial Order Planners: Some Techniques for Eective Search Control and Pruning. JAIR, 5, 95{137.
Gerevini, A., & Schubert, L. (1996b). Computing Parameter Domains as an Aid to Planning.
In AIPS-96.
Gerevini, A., & Schubert, L. (1998). Inferring State Constraints for Domain-Independent
Planning. In AAAI.
Grant, T. J. (1996). Inductive Learning of Knowledge-based Planning Operators. Ph.D.
thesis, Rijksuniversiteit Limburg de Maastricht.
Kautz, H., & Selman, B. (1998). The Role of Domain Specic Knowledge in the Planning
as Satisability Framework. In The Fourth International Conference on Articial
Intelligence Planning Systems.
420

Automatic Inference of State Invariants

Kelleher, G., & Cohn, A. (1992). Automatically Synthesising Domain Constraints from
Operator Descriptions. In Proceedings ECAI92.
Koehler, J., Nebel, B., & Dimopoulos, Y. (1997). Extending Planning Graphs to an ADL
Subset. In Proceedings of 4th European Conference on Planning.
Liatsos, V., & Richards, B. (1997). Least Commitment: An Optimal Planning Strategy. In
Proceedings of the 16th Workshop of the UK Planning and Scheduling Special Interest
Group.
Long, D., & Fox, M. (in press). The Ecient Implementation of the Plangraph in stan. In
JAIR.
McCluskey, T. L., & Porteous, J. (1997). Engineering and Compiling Planning Domain
Models to Promote Validity and Eciency. Articial Intelligence, 95 (1).
Morris, P., & Feldman, R. (1989). Automatically Derived Heuristics for Planning Search.
In Proceedings of the 2nd Irish Conference on Articial Intelligence and Cognitive
Science, School of Computer Applications, Dublin City University.

421

Journal of Articial Intelligence Research 9 (1998) 1{36

Submitted 1/98; published 8/98

The Computational Complexity of Probabilistic Planning
Michael L. Littman

mlittman@cs.duke.edu

Department of Computer Science, Duke University
Durham, NC 27708-0129 USA

Judy Goldsmith

goldsmit@cs.engr.uky.edu

Martin Mundhenk

mundhenk@ti.uni-trier.de

Department of Computer Science, University of Kentucky
Lexington, KY 40506-0046 USA
FB4 - Theoretische Informatik, Universitat Trier
D-54286 Trier, GERMANY

Abstract
We examine the computational complexity of testing and nding small plans in probabilistic planning domains with both at and propositional representations. The complexity
of plan evaluation and existence varies with the plan type sought; we examine totally
ordered plans, acyclic plans, and looping plans, and partially ordered plans under three
natural denitions of plan value. We show that problems of interest are complete for a
variety of complexity classes: PL, P, NP, co-NP, PP, NPPP, co-NPPP, and PSPACE. In
the process of proving that certain planning problems are complete for NPPP, we introduce
a new basic NPPP-complete problem, E-Majsat, which generalizes the standard Boolean
satisability problem to computations involving probabilistic quantities; our results suggest
that the development of good heuristics for E-Majsat could be important for the creation
of ecient algorithms for a wide variety of problems.

1. Introduction
Recent work in articial-intelligence planning has addressed the problem of nding eective plans in domains in which operators have probabilistic eects (Drummond & Bresina,
1990; Mansell, 1993; Draper, Hanks, & Weld, 1994; Koenig & Simmons, 1994; Goldman &
Boddy, 1994; Kushmerick, Hanks, & Weld, 1995; Boutilier, Dearden, & Goldszmidt, 1995;
Dearden & Boutilier, 1997; Kaelbling, Littman, & Cassandra, 1998; Boutilier, Dean, &
Hanks, 1998). Here, an \eective" or \successful" plan is one that reaches a goal state
with sucient probability. In probabilistic propositional planning , operators are specied
in a Bayes network or an extended STRIPS-like notation, and the planner seeks a recipe
for choosing operators to achieve a goal conguration with some user-specied probability.
This problem is closely related to that of solving a Markov decision process (Puterman,
1994) when it is expressed in a compact representation.
In previous work (Goldsmith, Lusena, & Mundhenk, 1996; Littman, 1997a), we examined the complexity of determining whether an eective plan exists for completely observable
domains; the problem is EXP-complete in its general form and PSPACE-complete when limited to polynomial-depth plans. (A polynomial-depth, or polynomial-horizon, plan is one
that takes at most a polynomial number of actions before terminating.) For these results,
c 1998 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

Littman, Goldsmith & Mundhenk

plans are permitted to be arbitrarily large objects|there is no restriction that a valid plan
need have any sort of compact (polynomial-size) representation.
Because they place no restrictions on the size of valid plans, these earlier results are not
directly applicable to the problem of nding valid plans. It is possible, for example, that for
a given planning domain, the only valid plans require exponential space (and exponential
time) to write down. Knowing whether or not such plans exist is simply not very important
because they are intractable to express.
In the present paper, we consider the complexity of a more practical and realistic
problem|that of determining whether or not a plan exists in a given restricted form and of a
given restricted size. The plans we consider take several possible forms that have been used
in previous planning work: totally ordered plans, partially ordered plans, (totally ordered)
conditional plans, and (totally order) looping plans. In all cases, we limit our attention to
plans that can be expressed in size bounded by a polynomial in the size of the specication
of the problem. This way, once we determine that a plan exists, we can use this information
to try to write it down in a reasonable amount of time and space.
In the deterministic planning literature, several authors have addressed the computational complexity of determining whether a valid plan exists, of determining whether a plan
exists of a given cost, and of nding the valid plans themselves under a variety of assumptions (Chapman, 1987; Bylander, 1994; Erol, Nau, & Subrahmanian, 1995; Backstrom,
1995; Backstrom & Nebel, 1995). These results provide lower bounds (hardness results) for
analogous probabilistic planning problems since deterministic planning is a special case. In
deterministic planning, optimal plans can be represented by a simple sequence of operators
(a totally ordered plan). In probabilistic planning, a good conditional plan will often perform better than any totally ordered (unconditional) plan; therefore, we need to consider
the complexity of the planning process for a richer set of plan structures.
For ease of discussion, we only explicitly describe the case of planning in completely
observable domains. This means that the state of the world is known at all times during
plan execution, in spite of the uncertainty of state transitions. We know that the state of the
system is sucient information for choosing actions optimally (Puterman, 1994), however,
representing such a universal plan is often impractical in propositional domains in which
the size of the state space is exponential in the size of the domain representation. For this
reason, we consider other types of plan structures based on simple nite-state machines.
Because the type of plans we consider do not necessarily use the full state of the system to
make every decision, our results carry over to partially observable domains, although we do
not explore this fact in detail in the present work.
The computational problems we look at are complete for a variety of complexity classes
ranging from PL (probabilistic logspace) to PSPACE. Two results are deserving of special
mention because they concern problems closely related to ones being actively addressed
by articial-intelligence researchers; rst, the problem of evaluating a totally ordered plan
in a compactly represented planning domain is PP-complete.1 A compactly represented
1. The class PP is closely related to the somewhat more familiar #P; Toda (1991) showed that P#P = PPP .
Roughly speaking, this means that #P and PP are equally powerful when used as oracles. The counting
class #P has already been recognized by the articial-intelligence community as an important complexity
class in computations involving probabilistic quantities, such as belief-network inference (Roth, 1996).

2

Complexity of Probabilistic Planning

planning domain is one that is described by a two-stage temporal Bayes network (Boutilier
et al., 1998) or similar notation.
Second, the problem of determining whether a valid totally ordered plan exists for a
compactly represented planning domain is NPPP -complete. Whereas the class NP can be
thought of as the set of problems solvable by guessing the answer and checking it in polynomial time, the class NPPP can be thought of as the set of problems solvable by guessing the
answer and checking it using a probabilistic polynomial-time (PP) computation. It is likely
that NPPP characterizes many problems of interest in the area of uncertainty in articial
intelligence; this paper and earlier work (Goldsmith et al., 1996; Mundhenk, Goldsmith, &
Allender, 1997a; Mundhenk, Goldsmith, Lusena, & Allender, 1997b) give initial evidence
of this.

1.1 Planning-Domain Representations
A probabilistic planning domain M = hS ; s0 ; A; t; Gi is characterized by a nite set of states
S , an initial state s0 2 S , a nite set of operators or actions A, and a set of goal states
G  S . The application of an action a in a state s results in a probabilistic transition

to a new state s0 according to the probability transition function t, where t(s; a; s0 ) is the
probability that state s0 is reached from state s when action a is taken. The objective is to
choose actions, one after another, to move from the initial state s0 to one of the goal states
with probability above some threshold .2 The state of the system is known at all times
(fully observable) and so can be used to choose the action to apply.
We are concerned with two main representations for planning domains: at representations, which enumerate states explicitly, and propositional representations (sometimes
called compact, structured, or factored representations), which view states as assignments
to a set of Boolean state variables or propositions. Propositional representations can represent many domains exponentially more compactly than can at representations.
In the at representation, the transition function t is represented by a collection of
jSj  jSj matrices,3 one for each action. In the propositional representation, this type of
jSj  jSj matrix would be huge, so the transition function must be expressed another way.
In the probabilistic planning literature, two popular representations for propositional planning domains are probabilistic state-space operators (PSOs) (Kushmerick et al., 1995) and
two-stage temporal Bayes networks (2TBNs) (Boutilier et al., 1995). Although these representations dier in the type of planning domains they can express naturally (Boutilier et al.,
1998), they are computationally equivalent; a planning domain expressed in one representation can be converted in polynomial time to an equivalent planning domain expressed in
the other with at most a polynomial increase in representation size (Littman, 1997a).
In this work, we focus on a propositional representation called the sequential-eectstree representation (ST) (Littman, 1997a), which is a syntactic variant of 2TBNs with
conditional probability tables represented as trees (Boutilier et al., 1995, 1998). This representation is equivalent to 2TBNs and PSOs and simplies the presentation of our results.
2. It is also possible to formulate the objective as one of maximizing expected total discounted reward (Boutilier et al., 1995), but the two formulations are essentially polynomially equivalent (Condon, 1992). The only diculty is that compactly represented domains may require discount factors
exponentially close to one for this equivalence to hold. This is discussed further in Section 5.
3. We assume that the number of bits used to represent the individual probability values isn't too large.

3

Littman, Goldsmith & Mundhenk

In ST, the eect of each action on each proposition is represented as a separate decision
tree. For a given action a, the set of decision trees for the dierent propositions is ordered,
so the decision tree for one proposition can refer to both the new and old values of previous propositions; this allows ST to represent any probability distribution. The leaves of a
decision tree describe how the associated proposition changes as a function of the state and
action, perhaps probabilistically. Section 1.2 gives a simple example of this representation.
As in other propositional representations, the states in the set of goal states G are not
explicitly enumerated in ST. Instead, we dene a goal set , which is a set of propositions
such that any state in which all the goal-set propositions are true is considered a goal state.
The set of actions A is explicitly enumerated in ST, just as it is in the at representation.
The ST representation of a planning domain M = hS ; s0 ; A; t; Gi can be dened more
formally as M = hP; I; A; T; G i (we use blackboard-bold font to stand for an ST representation on a domain). Here, P is a nite set of distinct propositions. The set of states S is
the power set of P; the propositions in s 2 S are said to be \true" in s. The set I  P is
the initial state. The set G is the goal set, so the set of goal states G is the set of states s
such that G  s.
The transition function t is represented by a function T, which maps each action in
A to an ordered sequence of jPj binary decision trees. Each of these decision trees has a
distinct label proposition, decision propositions at the nodes (optionally labeled with the
sux \:new"), and probabilities at the leaves. The ith decision tree T(a)i for action a
denes the transition probabilities t(s; a; s0 ) as follows. For the ith decision tree, let pi be
its label proposition. Dene i to be the value of the leaf node found by traversing decision
tree T(a)i , taking the left branch if the decision proposition is in s (or s0 if the decision
proposition has the \:new" sux) and the right branch otherwise. Finally, we let
Y  i;
if pi 2 s0 ,
0
t(s; a; s ) =
(1)
1 , i ; otherwise.
i

This denition of t constitutes a well-dened probability distribution over s0 for each a and
s.
To insure the validity of the representation, we only allow \p:new" to appear as a
decision proposition in T(a)i if p is the label proposition for some decision tree T(a)j for
j < i. For this reason, the order of the decision trees in T(a) is signicant. To put this
another way, a proposition only has a new value after this new value has been dened by
some decision tree.
The complexity results we derive for ST apply also to PSOs, 2TBNs, and all other computationally equivalent representations. They also hold for the \succinct representation,"
a propositional representation popular in the complexity-theory literature, which captures
the set of transition matrices as a function, most commonly represented by a Boolean circuit
that computes that function. ST can straightforwardly be represented as a Boolean circuit,
and, in the proof of Theorem 6, we show how to represent particular Boolean circuits in
ST. Thus, although we have not shown that the succinct representation is formally equivalent to ST, the two representations are closely related; the proofs we give for ST need to
be changed only slightly to work for the succinct representation (Goldsmith, Littman, &
Mundhenk, 1997a, 1997b; Mundhenk et al., 1997b). Our results require that we restrict
the succinct representation to generate transition probabilities with at most a polynomial
4

Complexity of Probabilistic Planning

number of bits; the results may be dierent for other circuit-based representations that can
represent probabilities with an exponential number of bits (Mundhenk et al., 1997a).

1.2 Example Domain

To help make these domain-representation ideas more concrete, we present the following
simple probabilistic planning domain based on the problem of building a sand castle at the
beach. There are a total of four states in the domain, described by combinations of two
Boolean propositions, moat and castle (propositions appear in boldface). The proposition
moat signies that a moat has been dug in the sand, and the proposition castle signies
that the castle has been built. In the initial state, both moat and castle are false, and the
goal set is fcastleg.
There are two actions: dig-moat and erect-castle (actions appear in sans serif). Figure 1
illustrates these actions in ST. Executing dig-moat when moat is false causes moat to
become true with probability 1=2; if moat is already true, dig-moat leaves it unchanged.
The castle proposition in not aected. The dig-moat action is depicted in the left half of
Figure 1.
The second action is erect-castle, which appears in the right half of Figure 1. The decision
trees are numbered to allow sequential dependencies between their eects to be expressed.
The rst decision tree is for castle, which does not change value if it is already true when
erect-castle is executed. Otherwise, the probability that it becomes true is dependent on
whether moat is true; the castle is built with probability 1=2 if moat is true and only
probability 1=4 if it is not. The idea here is that building a moat rst protects the castle
from being destroyed prematurely by the ocean waves.
The second decision tree is for the proposition moat. Because erect-castle cannot make
moat become true, there is no eect when moat is false. On the other hand, if the moat
exists, it may collapse as a result of trying to erect the castle. The label castle:new in the
diagram refers to the value of the castle proposition after the rst decision tree is evaluated.
If the castle was already built when erect-castle was selected, the moat remains built with
probability 3=4. If the castle had not been built, but erect-castle successfully builds it, moat
remains true. Finally, if erect-castle fails to make castle true, moat becomes false with
probability 1=2 and everything is destroyed.
Note that given an ST representation of a domain, we can perform a number of useful
operations eciently. First, given a state s and action a, we can generate a next state s0 with
the proper probabilities. This is accomplished by calculating the value of the propositions
of s0 one at a time in the order given in the representation of a, ipping coins with the
probabilities given in the leaves of the decision trees. Second, given a state s, action a,
and state s0 , we can compute t(s; a; s0 ), the probability that state s0 is reached from state s
when action a is taken, via Equation 1.

1.3 Plan Types and Representations

We consider four classes of plans for probabilistic domains. Totally ordered plans are the
most basic type, being a nite sequence of actions that must be executed in order; this
type of plan ignores the state of the system. Acyclic plans generalize totally ordered plans
to include conditional execution of actions. Partially ordered plans are a dierent way of
5

Littman, Goldsmith & Mundhenk

dig-moat
1: moat

2: castle

moat
T
1T

erect-castle
1: castle

castle
F

1/2 T

T
1T

2: moat

castle
F

T

0T

1T

moat
F

T

moat

F

castle

T

F

1/2 T

1/4 T

3/4 T

0T

F

T

castle: new
T

F

1T

1/2 T

Figure 1: Sequential-eects-tree (ST) representation for the sand-castle domain
generalizing totally ordered plans in which the precise sequence is left exible (McAllester
& Rosenblitt, 1991). Looping plans generalize acyclic plans to the case in which plan steps
can be repeated (Smith & Williamson, 1995; Lin & Dean, 1995). This type of plan is also
referred to as a plan graph or policy graph (Kaelbling et al., 1998).
In the following sections, we prove computational complexity results concerning each
of these plan types. The remainder of this section provides formal denitions of the plan
types, illustrated in Figure 2 with examples for the sand-castle domain.
In its most general form, a plan (or policy, controller or transducer) is a program that
outputs actions and takes as input information about the outcome of these actions. In this
work, we consider only a particularly restricted nite-state-controller-based plan representation.
A plan P for a planning domain M = hS ; s0 ; A; t; Gi can be represented by a structure
(V; v0 ; E; ; ) consisting of a directed (multi) graph (V; E ) with initial node v0 2 V , a
labeling  : V ! A of plan nodes|called plan steps |to domain actions, and a labeling
of edges with state sets  : E ! P (S ) such that for every v 2 V with outgoing edges,
S
0
v 2V :(v;v )2E (v; v ) = S and (v; v1 ) \ (v; v2 ) = ; for all v1 ; v2 2 V , v1 6= v2 . Some plan
steps have no outgoing edges at all|these are the terminal steps . Actions for terminal
steps are not executed. Note that the function  can be represented in a direct manner for
at domains, but for propositional domains, a more compact representation is needed. We
assume that for propositional domains, edge labels are given as conjunctions of literals.
The behavior of plan P in domain M is as follows. The initial time step is t = 0. At time
step t  0, the domain is in state st and the plan is at step vt (s0 is dened by the planning
domain, v0 by the plan). Action (vt ) is executed, resulting in a transition to domain state
st+1 with probability t(st ; (vt ); st+1 ). Plan step vt+1 is chosen so that st+1 2 (vt ; vt+1 );
the function  tells the plan where to \go" next. At this point, the time-step index t is
incremented and the process repeats. This continues until a terminal step is reached in the
plan.
One can understand the behavior of domain M under plan P in several dierent ways.
The possible sequences of states of M can be viewed as a tree: each node of the tree at
depth t is a state reachable from the initial state at time step t. Alternatively, one can view
the state of M at time step t under plan P as a probability distribution over S . At time
0

0

6

Complexity of Probabilistic Planning

step 0, with probability 1 the process is in state s0 . The probability that M is in state s0
at time step t + 1, Pr(s0 ; t + 1), is the sum of the probabilities of all length t + 1 paths from
s0 to s0, i.e.,

X

t
Y

s0 ;s1 ;s2 ;:::;st;st+1=s j =1

t(sj ; aj ; sj+1 );

0

where aj is the action selected by plan P at time j given the observed sequence of state
transitions s0 ; : : : ; sj . This view is useful in some of the later proofs.
Next, we formalize the probability that domain M reaches a goal state under plan P .
We need to introduce several notions. A \legal" sequence of states and steps applied is
called a trajectory , i.e., for M and P this is a sequence  = h(si ; vi )iki=0 of pairs with

 t(si; (vi ); si+1 ) > 0 for 0  i  k , 1,
 si+1 2 (vi ; vi+1 ) for 0  i  k , 1, and
 v0 ; : : : ; vk,1 are not terminal steps.
A goal trajectory is a trajectory that ends in a goal state of M , sk 2 G . Note that
each goal trajectory is nite.Q Thus, we can calculate the probability of a goal trajectory
,1 t(s ; (v ); s ), given that s 2 G . The probability that
 = h(si ; vi )iki=0 as Pr() = ki=0
i
i i+1
k
M reaches a goal state under plan P is the sum of the probabilities of goal trajectories for
M,
X
Pr(M reaches a goal state under P ) :=
Pr();
 goal trajectory

we call this the value of the plan.
We characterize a plan P = (V; v0 ; E; ; ) on the basis of the size and structure of its
underlying graph (V; E ). If the graph (V; E ) contains no cycles, we call it an acyclic plan ,
otherwise it is a looping plan . It follows that an acyclic plan has a terminal step, and that
a terminal step will be reached after no more than jV j actions are taken; such plans can
only be used for nite-horizon control. A totally ordered plan (sometimes called a \linear
plan" or a \straight line" plan) is an acyclic plan with no more than one outgoing edge for
each node in V . Such a plan is a simple path.
In this work, we also consider partially ordered plans (sometimes called \nonlinear"
plans) that express an entire family of totally ordered plans. In this representation, the steps
of the plan are given as a partial order (specied, for example, as a directed acyclic graph).
This partial order represents a set of totally ordered plans: all totally ordered sequences of
plan steps consistent with the partial order that consist of all steps of the partially ordered
plan. Each of these totally ordered plans has a value, and these values need not all be the
same. As such, we have a choice in dening the value for a partially ordered plan. In this
work, we consider the optimistic, pessimistic, and average interpretations. Let 
(P ) be the
set of totally ordered sequences consistent with partial order plan P . Under the optimistic
interpretation,
The value of P := max Pr(M reaches a goal state under p):
p2
(P )

7

Littman, Goldsmith & Mundhenk

Under the pessimistic interpretation,
The value of P := min Pr(M reaches a goal state under p):
p2
(P )

Under the average interpretation,
X
Pr(M reaches a goal state under p):
The value of P := j
(1P )j
p2
(P )
To illustrate these notions, Figure 2 gives plans of each type for the sand-castle domain
described earlier. Initial nodes are marked an incoming arrow, and terminal steps are
represented as lled circles. The 3-step totally ordered plan in Figure 2(a) successfully
builds a sand castle with probability 0:4375. An acyclic plan is given in Figure 2(b), which
succeeds with probability 0:46875 and executes dig-moat an average of 1:75 times. Note
that it succeeds more often and with fewer actions on average than the totally ordered plan
in Figure 2(a).
Figure 2(c) illustrates a partially ordered plan for the sand-castle domain. While this
plan bears a supercial resemblance to the acyclic plan in Figure 2(b), it has a dierent
interpretation. In particular, the plan in Figure 2(c) represents a set of totally ordered plans
with ve (non-terminal) plan steps (3 dig-moat steps and 2 erect-castle steps). In contrast
to the solid arrows in Figure 2(b), which indicate ow of control, the dashed arrows in
Figure 2(c) represent ordering constraints: each erect-castle step must be preceded by at
least two dig-moat steps,for example.
Although there are 52 = 10 distinct ways of arranging the ve plan steps in Figure 2(c) into a totally ordered plan, only two distinct totally ordered plans are consistent
with the ordering constraints:
dig-moat ! dig-moat ! dig-moat ! erect-castle ! erect-castle ! 

(success probability 0:65625) and

dig-moat ! dig-moat ! erect-castle ! dig-moat ! erect-castle ! 

(success probability 0:671875). Thus, the optimistic success probability of this partially
ordered plan is 0:671875, the pessimistic 0:65625. Note that the pessimistic interpretation is closely related to the standard interpretation in deterministic partial order planning (McAllester & Rosenblitt, 1991), in which a partially ordered plan is considered successful only if all its consistent totally ordered plans are successful. The average success
probability is 0:6614583, here, because there are 4 orderings that yield the poorer plan
described above, and 2 that yield the better one.
The looping plan in Figure 2(d) does not terminate until it succeeds in building a sand
castle, which it will do with probability 1:0 eventually. Of course, not all looping plans
succeed with probability 1; the totally ordered plan in Figure 2(a) and the acyclic plan in
Figure 2(b) are special cases of such looping plans, for instance.
We dene jP j the size of a plan P to be the number of steps it contains. We dene jM j
the size of a domain M to be the sum of the number of actions and states for a at domain
and the sum of the sizes of the ST decision trees for a propositional domain.
8

Complexity of Probabilistic Planning

dig-moat

dig-moat

erect-castle

dig-moat

erect-castle

dig-moat

erect-castle

dig-moat

(a) A totally ordered plan.

(c) A partially ordered plan.
not(moat)
dig-moat

not(moat)
dig-moat

moat

dig-moat

erect-castle

not(moat)

moat and not(castle)

moat

moat
dig-moat

castle
erect-castle

(b) An acyclic (conditional) plan.
not(moat) and not(castle)
(d) A looping plan.

Figure 2: Example plans for the sand-castle domain
We consider the following decision problems. The plan-evaluation problem asks, given
a domain M , a plan P of size jP j  jM j, and threshold , whether its value is greater than
, i.e., whether
Pr(M reaches a goal state under P ) > :
Note that the condition that jP j  jM j is just a technical one|we simply want to use jM j
to represent the size of the problem. Given an instance in which jP j is larger than jM j, we
simply imagine \padding out" jM j to make it larger. The important thing is that we are
considering plans that are roughly the size of the description of the domain, and not the
size of the number of states (which might be considerably larger).
The plan-existence problem asks, given domain M , threshold , and size bound z  jM j,
whether there exists a plan P of size z with value greater than . Note that because we
bound the size of the target plan, the complexity of plan generation is no more than that of
plan existence; the technique of self-reduction can be used to construct a valid plan using
polynomially many calls to an oracle for the decision problem.
Each of these decision problems has a dierent version for each type of domain (at
and propositional) and each type of plan category (looping, acyclic, totally ordered, and
partially ordered under each of the three interpretations). We address all of these problems
in the succeeding sections.

1.4 Complexity Classes

For denitions of complexity classes, reductions, and standard results from complexity
theory, we refer the reader to Papadimitriou (1994).
Briey, we are looking only at the complexity of decision problems (those with yes/no
answers). The class P consists of problems that can be decided in polynomial time; that is,
given an instance of the problem, there is a program for deciding whether the answer is yes
or no that runs in polynomial time. The class NP contains the problems with polynomialtime checkable polynomial-size certicates: for any given instance and certicate, it can be
checked in time polynomial in the size of the instance whether the certicate proves that
the instance is in the NP set. This means that, if the answer to the instance is \yes," this
9

Littman, Goldsmith & Mundhenk

can be shown in polynomial time given the right key. The class co-NP is the opposite|if
the answer is \no," this can be shown in polynomial time given the right key.
A problem X is C -hard for some complexity class C if every problem in C can be reduced
to it; to put it another way, a fast algorithm for X can be used as a subroutine to solve any
problem in C quickly. A problem is C -complete if it is both C -hard and in C ; these are the
hardest problems in the class.
In the interest of being complete, we next give more detailed descriptions of the less
familiar probabilistic and counting complexity classes we use in this work.
The class #L (A lvarez & Jenner, 1993) is the class of functions f such that, for some
nondeterministic logarithmically space-bounded machine N , the number of accepting paths
of N on x equals f (x). The class #P is dened analogously as the class of functions f
such that, for some nondeterministic polynomial-time -bounded machine N , the number of
accepting paths of N on x equals f (x). Typical complete problems are computing the
determinant for #L and computing the permanent for #P.
A function f is dened to be in GapL if it is the dierence f = g , h of #L functions g
and h. While #L functions have nonnegative integer values by denition, GapL functions
may have negative integer values (for example, if g always returns zero).
Probabilistic logspace (Gill, 1977), PL, is the class of sets A for which there exists a
nondeterministic logarithmically space-bounded machine N such that x 2 A if and only if
the number of accepting paths of N on x is greater than its number of rejecting paths. In
the original denition of PL, there is no time bound on computations; Borodin, Cook, and
Pippenger (1983) later showed PL  P. Jung (1985) proved that any set computable in
probabilistic logspace is computable in probabilistic logspace where the PL machine has a
simultaneous polynomial-time bound. In apparent contrast to P-complete sets, sets in PL
are decidable using very fast parallel computations (Borodin et al., 1983).
Probabilistic polynomial time, PP, is dened analogously. A classic PP-complete problem is Majsat: given a Boolean formula in conjunctive normal form (CNF), does the
majority of assignments satisfy it? According to Balcazar, Daz, and Gabarro (1990), the
PP-completeness of Majsat was shown in a combination of results from Gill (1977) and
Simon (1975).
For polynomial-space-bounded computations, PSPACE equals probabilistic PSPACE,
and #PSPACE is the same as the class of polynomial-space-computable functions (Ladner,
1989).
Note that L, NL, #L, PL and GapL are to logarithmic space what P, NP, #P, PP, and
GapP are to polynomial time. Also, the notion of completeness we use in this paper relies
on many-one reductions. In the case of PL, the reduction functions are logarithmic space;
in the case of NP and above, they are polynomial time.
For any complexity classes C and C 0 the class C C consists of those sets that are C -Turing
reducible to sets in C 0 , i.e., sets that can be accepted with resource bounds specied by C ,
using some problem in C 0 as a subroutine (oracle) with instantaneous output. For any class
C  PSPACE, it is the case that NPC  PSPACE, and therefore NPPSPACE = PSPACE.
The primary oracle-dened class we consider is NPPP . It equals the \NP
m " closure of
PP (Toran, 1991), which can be seen as the closure of PP under polynomial-time disjunctive reducibility with an exponential number of queries (each of the queries computable in
polynomial time from its index in the list of queries). To simplify our completeness results
0

10

Complexity of Probabilistic Planning

for this class, we introduce a decision problem we call E-Majsat (\exists" Majsat), which
generalizes the standard NP-complete satisability problem and the PP-complete Majsat.
An E-Majsat instance is dened by a CNF Boolean formula  on n Boolean variables
x1 ; : : : ; xn and a number k between 1 and n. The task is to decide whether there is an
initial partial assignment to variables x1 ; : : : ; xk so that the majority of assignments that
extend that partial assignment satises . We prove that this problem is NPPP -complete
in the Appendix.
The complexity classes we consider satisfy the following containment properties and
relations to other well-known classes:
NP  PP  NPPP  PSPACE  EXP:
L  NL  PL  P  co-NP
co-NPPP
Because P is properly contained in EXP, EXP-complete problems are provably intractable;
the other classes may equal P, although that is not generally believed to be the case.
Several other observations are worth making here. It is also known that PH  NPPP ,
where PH represents the polynomial hierarchy. In a crude sense, PH is close to PSPACE,
and, thus, our NPPP {completeness results place important problems close to PSPACE.
However, some early empirical results (Littman, 1997b) show that random problem instances from PP have similar properties to random problem instances from NP, suggesting
that PP might be close enough to NP for NP-type heuristics to be eective.

1.5 Results Summary

Tables 1 and 2 summarize our results, which are explained in more detail in later sections.
The general avor of our main results and techniques can be conveyed as follows. To
show that a plan-evaluation problem is in a particular complexity class C , we take the
cross product of the steps of the plan and the states of the domain and then look at the
complexity of evaluating the absorption probability of the resulting Markov chain (i.e., the
directed graph with probability-labeled edges). The complexity of the corresponding planexistence problem is then bounded by NPC , because the problem can be solved by guessing
the correct plan non-deterministically and then evaluating it; in many cases, it is NPC complete. The appropriate complexity class C depends primarily on the representation of
the cross-product Markov chain.
Exceptions to this basic pattern are the results for partially ordered plans in Section 4.
These appear to require a distinct set of techniques.
It is also worth noting that, although propositional domains can be exponentially more
compact than at domains, the computational complexity of solving problems in propositional domains is not always exponentially greater; in one instance, evaluating partially
ordered plans under the average interpretation, the complexity is actually the same for at
and propositional domains!
We also prove results concerning plan evaluation and existence for compactly represented
plans (PP-complete and NPPP -complete, Corollary 5), plan existence of \large enough"
looping plans in at domains (P-complete, Theorem 7), plan evaluation and existence
for looping plans in deterministic propositional domains (PSPACE-complete, Theorems 8
and 9), and plan existence for polynomial-size looping plans in partially observable domains
(NP-complete, Section 5.1).
11

Littman, Goldsmith & Mundhenk

Plan Type
Plan Evaluation Plan Existence
unrestricted
|
P-complete
polynomial-depth
|
P-complete
looping
PL-complete
NP-complete
acyclic
PL-complete
NP-complete
totally ordered
PL-complete
NP-complete
partially ordered, optimistic
NP-complete
NP-complete
partially ordered, average
PP-complete
NP-complete
partially ordered, pessimistic co-NP-complete
NP-complete

Reference
P & T (1987)
P & T (1987)
Section 3
Section 2
Section 2
Section 4
Section 4
Section 4

Table 1: Complexity results for at representations (P & T (1987) is Papadimitriou and
Tsitsiklis (1987))

Plan Type
Plan Evaluation Plan Existence Reference
unrestricted
|
EXP-complete Littman (1997a)
polynomial-depth
|
PSPACE-complete Littman (1997a)
looping
PSPACE-complete PSPACE-complete Section 3
acyclic
PP-complete
NPPP -complete Section 2
totally ordered
PP-complete
NPPP -complete Section 2
PP
partially ordered, optimistic
NP -complete
NPPP -complete Section 4
partially ordered, average
PP-complete
NPPP -complete Section 4
PP
partially ordered, pessimistic co-NP -complete NPPP -complete Section 4
Table 2: Complexity results for propositional representations

12

Complexity of Probabilistic Planning

2. Acyclic Plans

In this section, we treat the complexity of generating and evaluating acyclic and totally
ordered plans.

Theorem 1 The plan-evaluation problem for acyclic and totally ordered plans in at domains is PL-complete.

Proof: First, we show PL-hardness for totally ordered plans. Jung (1985) proved that a
set A is in PL if and only if there exists a logarithmically space-bounded and polynomially
time-bounded nondeterministic Turing machine N with the following property: For every
input x, machine N must have at least half of its computations on input x be accepting
if and only if x is in A. The machine N can be transformed into a probabilistic Turing
machine R such that for each input x, the probability that R(x) accepts x equals the
fraction of computations of N (x) that accepted. Given R, a planning domain M can be
described as follows. The state set of M is the set of congurations of R on input x. Note
that a conguration consists of the contents of the logarithmically space-bounded tape, the
state, the location of the read/write heads, and one symbol each from the input and output
tapes. Thus, a conguration can be represented with logarithmically many bits, and there
are only polynomially many such congurations. The state-transition probabilities of M
under the unique action a are the conguration transition probabilities of R. All states
obtained from accepting congurations are goal states. The totally ordered plan consists
of a \step counter" for R on input x, and each of its plan steps takes the only action a.
The probability that the planning domain under this plan reaches a goal state is exactly
the probability that R(x) reaches an accepting conguration. Thus, evaluating this totally
ordered plan is PL-hard.
Since totally ordered plans are acyclic plans, this also proves PL-hardness of the planevaluation problem for acyclic plans.
Next, we show that the plan-evaluation problem is in PL for acyclic plans. Let M =
hS ; s0 ; A; t; Gi be a planning domain, let P = hV; v0 ; E; ; i be an acyclic plan, and let
threshold  be given. We show how our question, whether the probability that M under P
reaches a goal state with probability greater than , can be equivalently transformed into
the question of whether a GapL function is greater than 0. The transformation can be done
in logarithmic space. As shown by Allender and Ogihara (1996), it follows that our question
is in PL.
At rst, we construct a Markov chain C from M and P , which simulates the execution
or \evaluation" of M under P . Note that a Markov chain can be seen as a probabilistic
domain with only one action in its set of actions. Since there is no choice of actions, we do
not mention them in this construction. The state space of C is S  V , the initial state is
(s0 ; v0 ), the set of goal states is G  V , and the transition probabilities tC for C are
8
t(s; (v); s0 ); if s0 2 (v; v0 );
<
tC ((s; v); (s0 ; v0 )) = : 1;
if v is a terminal step node, and (s; v) = (s0 ; v0 );
0;
otherwise.
Let m be the number of plan steps of P (i.e., jV j, the number of nodes in the graph
representing P ). Since states of C that contain a terminal step of P are sinks in C , it follows
13

Littman, Goldsmith & Mundhenk

that
Pr(M reaches a goal state under P ) = Pr(C reaches a goal state in exactly m steps):
Let
pC (s; m) := Pr(C reaches a goal state in exactly m steps from initial state s):
Then, pC ((s0 ; v0 ); m) is the probability we want to calculate. The standard inductive denition of pC used to evaluate plans by dynamic programming is

s is a goal state of C ,
pC (s; 0) = 10;; ifotherwise,
X
pC (s; k + 1) =
tC (s; s0)  pC (s0 ; k); 0  k  m , 1:
s 2SV
0

Let h be the maximum length of the representation of a state-transition probability tC .
Then, for

if s is a goal state of C ,
ph (s; 0) = 10;; otherwise,
X h
ph(s; k + 1) =
2  tC (s; s0 )  ph (s0 ; k); 0  k  m , 1;
s 2SV
0

it follows that pC ((s0 ; v0 ); m) = ph((s0 ; v0 ); m)  2,hm . Note that ph((s0 ; v0 ); m) is an integer
value. Therefore, pC ((s0 ; v0 ); m) >  if and only if ph ((s0 ; v0 ); m) , b2hm c > 0. In order
to show that pC ((s0 ; v0 ); m) >  is decidable in PL, it suces to show that ph((s0 ; v0 ); m)
is in GapL. Therefore, we \unwind" the inductive denition of ph. Let T be the integer
matrix obtained from tC with T(s;s ) = tC (s; s0 )  2h . We introduce the integer-valued T to
show that ph can be composed from GapL functions using compositions under which GapL
is closed; as tC is not integer valued, it cannot be used to show this. We can write
0

ph(s; m) =

X

s 2SV

(T m )(s;s )  ph(s0 ; 0):
0

0

We argue that ph is in GapL. Each entry T(s;s ) is logspace computable from the domain M and plan P . Therefore, the powers of the matrix are in GapL, as shown by
Vinay (1991). Because GapL is closed under multiplication and summation of polynomially
many summands, it follows that ph 2 GapL. Finally, we use closure properties of GapL
from Allender and Ogihara (1996); since GapL is closed under subtraction, it follows that
the plan-evaluation for acyclic plans is in PL.
Because totally ordered plans are acyclic plans, the plan-evaluation problem for totally
ordered plans is also in PL.
0

The technique of forming a Markov chain by taking the cross product of a domain and
a plan will be useful later. Plan-existence problems require a dierent set of techniques.

Theorem 2 The plan-existence problem for acyclic and totally ordered plans in at domains is NP-complete.

14

Complexity of Probabilistic Planning

Proof: First, we show containment in NP. Given a planning domain M , a threshold ,
and a size bound z  jM j, guess a plan of the correct form of size at most z and accept if

and only if M reaches a goal state with probability greater than  under this plan. Note that
checking whether a plan has the correct form can be done in polynomial time. Because the
plan-evaluation problem is in PL (Theorem 1), it follows that the plan-existence problem
is in NP (i.e., it is in NPPL = NP).
To show the NP-hardness of the plan-existence problem, we give a reduction from the
NP-complete satisability problem for Boolean formulae in conjunctive normal form. We
construct a planning domain that evaluates a Boolean formula with n variables, where a
(n + 2)-step plan describes an assignment of values to the variables. In the rst step, a
clause is chosen randomly. At step i + 1, the planning domain \checks" whether the plan
satises the appearance of variable i in that clause. If so, the clause is marked as satised.
After n + 1 steps, if no literal was satised in that clause, then no goal state is reached
through this clause, otherwise, a transition is made to the goal state. Therefore, the goal
state will be reached with probability 1 (greater than 1 , 1=m) if and only if all clauses are
satised|the plan describes a satisfying assignment.
We formally dene the reduction, which is similar to one presented by Papadimitriou
and Tsitsiklis (1987). Let  be a CNF formula with n variables x1 ; : : : ; xn and m clauses
C1 ; : : : ; Cm . Let the sign of an appearance of a variable in a clause be ,1 if the variable is
negated, and 1 otherwise. Dene the planning domain M () = hS ; s0 ; A; t; Gi where

S
A
G

= fsat(i; j ); unsat(i; j ) j 1  i  n + 1; 1  j  mg [ fs0 ; sacc ; srejg;
= fassign(i; b) j 1  i  n; b 2 f,1; 1gg [ fstart; endg;
= fsacc g;
8 1
0
>
m ; if s = s0 ; a = start; s0 = unsat(1; j ); 1  j  m;
>
>
>
1; if s = s0 ; a 6= start; s = srej;
>
>
>
>
>
1; if s = unsat(i; j ); a = assign(i; b); s0 = sat(i + 1; j ); i  n;
>
>
>
>
xi appears in Cj with sign b;
>
>
>
>
1
;
if
s
= unsat(i; j ); a = assign(i; b); s0 = unsat(i + 1; j ); i  n;
>
>
>
>
xi does not appear in Cj with sign b;
>
>
>
>
1
;
if
s
= unsat(i; j ); a = assign(i0 ; b) or a = start or a = end;
>
>
<
0
srej; i0 6= i  n; b 2 f,1; 1g;
t(s; a; s0) = > 1; if ss =
= unsat(n + 1; j ); s0 = srej;
>
>
>
>
1; if s = sat(i; j ); a = assign(i; b); s0 = sat(i + 1; j ); i  n;
>
>
>
>
1; if s = sat(i; j ); a = assign(i0 ; b) or a = start or a = end;
>
>
>
>
s0 = srej; i0 6= i  n;
>
>
>
>
1; if s = sat(n + 1; j ); a = end; s0 = sacc ;
>
>
>
>
1; if s = sat(n + 1; j ); a 6= end; s0 = srej;
>
>
>
>
s = s0 = srej or s = s0 = sacc ;
>
>
: 10;; ifotherwise.
The meaning of the states in this domain is as follows. When the domain is in state
sat(i; j ) for 1  i  n, 1  j  m, it means the formula has been satised, and we are
currently checking variable i in clause j . State sat(n + 1; j ) for all 1  j  m means that
we've nished verifying clause j and it was satised. The meanings are similar for the
15

Littman, Goldsmith & Mundhenk

s0

start

1=2

unsat(1; 1)

assign(1; 1)

assign(1;

sat(2; 1)

assign(2; x)

1=2

,1)

start

assign(1;

,1)

sat(3; 1)

assign(2; 1)

sat(3; 2)

assign(3; x)

sat(4; 1)

unsat(4; 1)

end

end

sacc

unsat(2; 2)

assign(2; x)

unsat(3; 1)

assign(3; x)

assign(1; 1)

sat(2; 2)

unsat(2; 1)

assign(2;

unsat(1; 2)

,1)

unsat(3; 2)

assign(3; 1)
sat(4; 2)

end

assign(3;

,1)

unsat(4; 2)

end

srej

Figure 3: A domain generated from the Boolean formula (x1 _ :x2 ) ^ (:x1 _ x3 )
\unsat" states. Of course, s0 is the initial state and sacc and srej are the accepting and
rejecting states, respectively.
The actions in this domain are start and end, which mark the beginning and end of the
assignment, and assign(i; b) for 1  i  n, b 2 f,1; 1g, which assign the truth value b to
variable i. Figure 3 gives the domain generated by this reduction from a simple Boolean
formula. By the description of the reduction, M () can be computed from  in time
polynomial in jj.
By construction, M () under z = (n + 2)-step plan P can only reach goal state sacc if
P has the form
start ! assign(1; b1 ) ! assign(2; b2 ) !    ! assign(n; bn ) ! end ! :
P reaches sacc with probability 1 if and only if b1 ; : : : ; bn is a satisfying assignment for the
n variables in . This shows that Boolean satisability polynomial-time reduces to the
plan-existence problem for totally ordered and acyclic plans, showing that it is NP-hard.
Note that if we bound the plan depth (horizon) instead of the plan size, the planexistence problem for acyclic plans in at domains is P-complete (Goldsmith et al., 1997a;
Papadimitriou & Tsitsiklis, 1987). Limiting the plan size makes the problem more dicult
because it is possible to force the planner to take the same action from dierent states;
guring out how to do this without sacricing plan quality is very challenging.
In propositional domains, plan evaluation is harder because of the large number of states.

Theorem 3 The plan-evaluation problem for acyclic and totally ordered plans in propositional domains is PP-complete.

Proof: To show PP-hardness for totally ordered plans, we give a reduction from the

PP-complete problem Majsat: given a CNF Boolean formula , does the majority of
assignments satisfy it?
16

Complexity of Probabilistic Planning

evaluate
1: xi
1/2

2: xi

T

1/2

T

n+1: clause1
xa1:new
T

F

xb1:new

1T

T
1

T

T
0

T

T
1

T

1T

xbm:new

clause1:new

T

T

xcm:new
T

1T

0

F

F

1T

1T

n+m+2: done

done
T

F

T

F

n+m+1: satisfied

xam:new

...

xc1:new

xd1:new

1/2 T

n+m: clausem

F

T

n: xi

...

T

F
0

F

clause2:new
...

T

0T

F
0

T

clausem:new

F

T

1T

1

F
T

0T

Figure 4: Sequential-eects-tree representation for evaluate
Given , we construct a planning domain M () and a 1-step plan such that the plan
achieves the goal with probability greater than  = 1=2 if and only if the majority of
assignments satises . The planning domain M () consists of a single action evaluate,
which is also the 1-step plan to be evaluated. There are n + m + 2 propositions in M ();
x1 through xn, which correspond to the n variables of ; clause1 through clausem , which
correspond to the m clauses of ; satised, which is also the sole element of the goal set;
and done, which insures that evaluate is only executed once (this is important when this
domain is used later in Theorem 4 to show the complexity of plan existence). In the initial
state, all propositions are false.
The evaluate action generates a random assignment to the variables of , evaluates the
clauses (clausei is true if any of the literals in the ith clause is true), and evaluates the entire
formula (satised is true if all the clauses are true). Figure 4 gives an ST representation
of evaluate, in which xa ; xb ; : : : represent the variables in clause i.
By construction,  is in Majsat if and only if M () reaches a goal state with probability
greater than  = 1=2 under the plan consisting of the single action evaluate.
We next show membership in PP for acyclic plans. We do this by showing that a
planning domain M and an acyclic plan P induce a computation tree consisting of all
paths through M under P . Evaluating this computation tree can be accomplished by a PP
machine.
Let b be a bound on the number of bits used to specify probabilities in the leaves of the
decision trees representing M .4 Consider a computation tree dened as follows. It has root
labeled hs0 ; v0 i. If, in the planning domain M , the probability of reaching state s0 from s
i

i

4. We represent numbers in polynomial-precision binary representation. In principle, this could introduce
round-o errors if planning problems are specied in some other form.

17

Littman, Goldsmith & Mundhenk

given action (v) is equal to  , then hs; (v)i will have   2b children labeled hs0 ; (v; s0 )i.
Each of the identically labeled child nodes is independent but is dened identically to the
others. Thus, the number of paths with a given set of labels corresponds to the probability
of that trajectory through the domain and plan multiplied by (2b )h , where h is the depth
of the plan.
The number of accepting computations is, therefore, more than   (2b )h if and only if
the probability of achieving the goal is more than . Note that b is inherent in the planning
domain, rather than in h. A PP machine accepts if more than half of the nal states are
accepting, so if  6= 1=2, it will be necessary to pad the computation tree by introducing
\dummy" branches that accept or reject in the right proportions.
The plan-existence problem is essentially equivalent to guessing and evaluating a valid
plan.

Theorem 4 The plan-existence problem for acyclic and totally ordered plans in propositional domains is NPPP -complete.

Proof: Containment in NPPP for both totally ordered and for acyclic plans follows from

the fact that a polynomial-size plan can be guessed in polynomial time and checked in PP
(Theorem 3).
Hardness for NPPP for both totally ordered and acyclic plans can be shown using a
reduction from E-Majsat, shown NPPP -hard in the Appendix. The reduction echoes the
one used in the PP-hardness argument in the proof of Theorem 3.
Given a CNF Boolean formula  with variables x1 ; : : : ; xn , and a number k, we construct
a planning domain M (; k) such that a plan exists that can reach the goal with probability
greater than  = 1=2 if and only if there is an assignment to the variables x1 ; : : : ; xk such
that the majority of assignments to the remaining variables satises . The planning domain
M (; k ) consists of the action evaluate from Theorem 3 and one action, set-xi , for each of
the rst k variables. Just as in the proof of Theorem 3, there are n + m + 2 propositions in
M (; k ), all initially false: x1 through xn , which correspond to the n variables of ; clause1
through clausem , which correspond to the m clauses of ; satised; and done, which
insures that evaluate is only executed once. The goal set contains satised and done.
For 1  i  k, action set-xi makes proposition xi true. Analogously to Theorem 3, the
evaluate action generates a random assignment to the remaining variables of , evaluates
the clauses (clausei is true if any of the literals in the clause is true), and evaluates the
entire formula (satised is true if all the clauses are true), and sets done to true. If done
is true, no further action can make satised true.
If the pair ; k is in E-Majsat, then there exists an assignment b1 : : : bk to the rst k
variables of  such that the majority of assignments to the rest of the variables satises .
Therefore, the plan applying steps set-xi for all i with bi = 1 followed by an evaluate action
reaches a goal state with probability greater than  = 1=2.
Conversely, assume M (; k) under totally ordered plan P reaches a goal state with
probability greater than 1=2. Since the evaluate action is the only action setting done to
true, and since no action reaches the goal once done is set to true, we can assume without
loss of generality that P consists of a sequence of steps set-xi that ends with evaluate. By
construction, the assignment to x1 ; : : : ; xk assigning 1 exactly to those variables set by P
18

Complexity of Probabilistic Planning

is an assignment under which the majority of the assignments to the rest of the variables
satises , and therefore ; k is in E-Majsat.
Since every totally ordered plan is acyclic, the same hardness holds for acyclic plans.
In the above results, we consider both at and compactly represented (propositional)
planning domains but only at plans. Compactly represented plans are also quite useful.
A compact acyclic plan is an acyclic plan in which the names of the plan steps
are encoded by a set of propositional variables and the step-transition function
 between plan steps is represented by a set of decision trees, just as in ST. We
require that the plan has depth polynomial in the size of the representation,
even though the total number of steps in the plan might be exponential due to
the logarithmic succinctness of the encodings.
Because the plan-domain cross-product technique used in the proof of Theorem 3 generalizes to compact acyclic plans, the same complexity results apply. This also holds true
for a probabilistic acyclic plan , which is an acyclic plan that can make random transitions
between plan steps (i.e., the step-transition function  is stochastic). These insights can be
combined to yield the following corollary of Theorems 3 and 4.

Corollary 5 The plan-evaluation problem for compact probabilistic acyclic plans in propositional domains is PP-complete and the plan-existence problem for compact probabilistic
acyclic plans in propositional domains is NPPP -complete.

We mention probabilistic plans here for two reasons. First, the behavior of some planning structures (such as partially ordered plan evaluation under the average interpretation,
discussed in Section 4) can be thought of as generating probabilistic plans. Second, there
are many instances in which simple probabilistic plans perform nearly as well as much larger
and more complicated deterministic plans; this notion is often exploited in the eld of randomized algorithms. Work by Platzman (1981) (described by Lovejoy, 1991) shows how the
idea of randomized plans can come in handy for planning in partially observable domains.

3. Looping Plans

Looping plans can be applied to innite-horizon control. The complexity of plan existence
and plan evaluation in at domains (Theorems 1 and 2) does not depend on the presence
or absence of loops in the plan.

Theorem 6 The plan-evaluation problem for looping plans in at domains is PL-complete.
Proof: Given a domain M and a looping plan P , we can construct a product Markov

chain C as in the proof of Theorem 1. As in the proof of Theorem 6 of Allender and
Ogihara (1996), this chain can be constructed such that it has exactly one accepting and
exactly one rejecting state; both of these states are absorbing. The probability that M
reaches a goal state under P equals the probability that C reaches its accepting state if
started in its initial state, which is the product of the initial states of M and P . In the
19

Littman, Goldsmith & Mundhenk

proof of Theorem 6 of Allender and Ogihara (1996), it is shown that the construction of
the Markov chain and the computation of whether it reaches its nal state with probability
greater than  can be performed in PL.
PL-hardness is implied by Theorem 1, since acyclic plans are a special case of looping
plans.

Theorem 7 The plan-existence problem for looping plans in at domains is NP-complete

in general, but P-complete if the size of the desired plan is at least the size of the state or
action space (i.e., z  min(jSj; jAj)).

Proof sketch: NP-completeness follows from the proof of Theorem 2; containment and

hardness still hold if plans are permitted to be looping.
However, this is only true if we are forced to specify a plan whose size is small with
respect to the size of the domain. If our looping plan is allowed to have a number of states
that is at least as large as the number of states or actions in the domain, the problem can
be solved in polynomial time.
It is known that for Markov decision processes such as these the maximum probability
of reaching a goal state equals the maximum probability of reaching a goal state under
any innite-horizon stationary policy , where a stationary policy is a mapping from states
to actions that is used repeatedly to choose actions at each time step. It is known that
such an optimal stationary policy can be computed in polynomial time via linear programming (Condon, 1992). Any stationary policy for a domain M = hS ; s0 ; A; G ; ti can be
written as a looping plan, although, of course, not all looping plans correspond to stationary
policies.
We show that for any xed stationary policy p : S ! A, there are two simple ways a
looping plan P = (V; v0 ; E; ; ) can be represented. First, let V = A, v0 = p(s0 ), (v) = v,
and (v; v0 ) = fs 2 S j p(s) = v0 g. It follows that whenever M reaches state s, then the
action applied according to the looping plan is the same as according to P .
Second, let V = S , v0 = s0 , (v) = p(v), and (v; v0 ) = fv0 g. It follows that whenever
M reaches state s, the plan will be at the node corresponding to that state and, therefore,
the appropriate action for that state will be applied by the looping plan. Therefore, the
maximum probability of reaching a goal state can be obtained by either of these looping
plans.
Since the best stationary policy can be computed in polynomial time, the best looping
plan can be computed in polynomial time, too. P-hardness follows from a theorem of
Papadimitriou and Tsitsiklis (1987).
In propositional domains, the complexity of plan existence and plan evaluation of looping
plans is quite dierent from the acyclic case. Looping plan evaluation is very hard.

Theorem 8 The plan-evaluation problem for looping plans in both deterministic and stochastic propositional domains is PSPACE-complete.

Proof: Recall that the plan-evaluation problem for at domains is in PL (Theorem 1).

For a planning domain with cn states and a representation of size n, a looping plan can
20

Complexity of Probabilistic Planning

be evaluated in probabilistic space O(log(cn )) (Theorem 6), which is to say probabilistic
space polynomial in the size of the input. This follows because the ST representation of
the domain can be used to compute entries of the transition function t in polynomial space.
Since probabilistic PSPACE equals PSPACE, this shows that the plan-evaluation problem
for looping plans in stochastic propositional domains is in PSPACE.
It remains to show PSPACE-hardness for deterministic propositional domains. Let N
be a deterministic polynomial-space-bounded Turing machine. The moment-to-moment
computation state (conguration) of N can be expressed as a polynomial-length bit string
that encodes the contents of the Turing machine's tape, the location of the read/write head,
the state of N 's nite-state controller, and whether or not the machine is in an accepting
state.
For any input x, we describe how to construct in polynomial time a deterministic planning domain M (x) and a single-action looping plan that reaches a goal state of M (x) if and
only x is accepted by Turing machine N .
Given a description of N and x, one can, in time polynomial in the size of the descriptions
of N and x, produce a description of a Turing machine T that computes the transition
function for N . In other words, T on input c, a conguration of N , outputs the next
conguration of N . (In fact, T can even check whether c is a valid conguration in the
computation of N (x) by simulating that computation.) By an argument similar to that
used in Cook's theorem, T can be modeled by a polynomial-size circuit. This circuit takes
as input the bit string describing the current conguration of N and outputs the next
conguration.
Next, we argue that the computation of this circuit can be expressed by an action compute in ST representation. There is one proposition in M (x) for each bit in the conguration,
plus one for each gate of the circuit. The three standard gates, \and," \or," and \not" are
all easily represented as decision trees. By ordering the decision trees in compute according to a topological sort of the gates of the circuit, a single compute action can compute
precisely the same output as the circuit. Figure 5 illustrates this conversion for a simple
circuit, which gives the form of the \not" (i1 ), \and" (i2 ), and \or" (i3 ) gates.
We can now describe the complete reduction. The planning domain M (x) consists of
the single action compute and the set of propositions described in the previous paragraph.
The initial state is the initial conguration of the Turing machine N , and the goal set is the
proposition corresponding to whether or not the conguration is an accepting state for N .
Because all transitions are deterministic and only one action can be chosen, it follows
that the goal state is reached with probability 1 (greater than 1=2, for example) under
the plan that repeatedly chooses compute until an accepting state is reached if and only if
polynomial-space machine N on input x accepts.
A similar argument shows that looping plan existence is not actually any harder than
looping plan evaluation.

Theorem 9 The plan-existence problem for looping plans in both deterministic and stochastic propositional domains is PSPACE-complete.
21

Littman, Goldsmith & Mundhenk

compute
1: i1

2: i2

c2
c1

c2

not
i1

or
i3
and

c3

not

T

i2

c2

F

c3

1T

1T

0T

T

F

c2

1T

F

T

0T

F

1T

0T

or

4: c1
c1

T

T
and

c1

i1:new
F

0T

3: i3

5: c2
i2:new

c1

c3
T

F

i2:new
T
1T

6: c3

0T

T
0T

F
1T

i3:new
T

F

i2:new

1T

T

F
0T

1T

F
0T

Figure 5: A circuit and its representation as a sequential-eects tree

Proof: Hardness for PSPACE follows from the same construction as in the proof of

Theorem 8: either the one-step looping plan is successful, or it is not. No other plan yields
a better result.
Recall that we are only interested in determining whether there is a plan of size z , where
z is bounded by the size of the domain, that reaches the goal with a given probability. The
problem is in PSPACE because the plan can be guessed in polynomial time and checked in
PSPACE (Theorem 8). Because NPPSPACE = PSPACE, the result follows.
As we mentioned earlier, the unrestricted innite-horizon plan-existence problem is
EXP-complete (Littman, 1997a); this shows the problem of determining unrestricted plan
existence is EXP-hard only because some domains require plans that are larger than polynomialsize looping plans.
Because Theorem 9 shows PSPACE-completeness for determining plan existence in deterministic domains, it is closely related to the PSPACE-completeness result of Bylander (1994). The main dierence between the two results is that our theorem applies to
more compact plans (polynomial instead of exponential) with more complex operator descriptions (conditional eects instead of preconditions with add and delete lists) that can
include loops. Also, as the proofs above show, PSPACE-hardness is retained even in planning domains with only one action, so it is the looping that makes looping plans hard to
work with.

4. Partially Ordered Plans
Partially ordered plans are a popular representation because they allow planning algorithms
to defer a precise commitment to the ordering of plan steps until it becomes necessary in
22

Complexity of Probabilistic Planning

the planning process. A k-step partially ordered plan corresponds to a set of k-step totally
ordered plans|all those that are consistent with the given partial order. The evaluation of
a partially ordered plan can be dened to be the evaluation of the best, worst, or average
member of the set of consistent totally ordered plans; these are the optimistic, pessimistic,
and average interpretations, respectively.
The plan-evaluation problem for partially ordered plans is dierent from that of totally
ordered plans. This is because a single partial order can encode all totally ordered plans.
Hence, evaluating a partially ordered plan involves guring out the best (in case of optimistic
interpretation) or the worst (for pessimistic interpretation) member, or the average (for
average interpretation) of this combinatorial set.

Theorem 10 The plan-evaluation problem for partially ordered plans in at domains is
NP-complete under the optimistic interpretation.
Proof sketch: Membership in NP follows from the fact that we can guess any totally

ordered plan consistent with the given partial order and accept if and only if the domain
reaches a goal state with probability more than . Remember that this evaluation can be
performed in PL (Theorem 1), and therefore deterministically in polynomial time.
The hardness proof is a variation of the construction used in Theorem 2. The partiallyordered plan to evaluate has the form given in Figure 6; the consistent total orders are of
the form
start ! assign(1; b1 ) ! assign(1; ,b1 ) ! assign(2; b2 ) ! assign(2; ,b2 ) !

   ! assign(n; bn) ! assign(n; ,bn) ! end ! ;
where bi is either 1 or ,1. Each of the possible plans can be interpreted as an assignment

to n Boolean variables by ignoring every second assignment action. The construction in
Theorem 2 shows how to turn a CNF formula  into a planning domain M (), and it
can easily be modied to ignore every second action. Thus, the best totally ordered plan
consistent with the given partially ordered plan reaches the goal with probability 1 if and
only if it reaches the goal with probability greater than 1 , 2,m if and only if it satises all
clauses of  if and only if  is satisable.

Theorem 11 The plan-evaluation problem for partially ordered plans in at domains is
co-NP-complete under the pessimistic interpretation.

Proof sketch: Both the proof of membership in co-NP and the proof of hardness are

very similar to the proof of Theorem 10. We show a reduction from the co-NP-complete set
of unsatisable formulae in CNF. The plan to evaluate has the form given in Figure 6
and is interpreted as above. As in the proof of Theorem 2, we construct a planning domain
M 0(), but we take G = fsrejg as goal states, where the state srej is reached with probability
greater than 0 if and only if the assignment does not satisfy one of the clauses of formula .
A formula is unsatisable if and only if under every assignment at least one of the clauses
is not satised. Therefore, the probability that M 0 () reaches a goal state under a given
totally ordered plan is greater than 0 if and only if the plan corresponds to an unsatisfying
Sat

23

Littman, Goldsmith & Mundhenk

start

assign(1,1)

assign(1,-1)

assign(2,1)

assign(2,-1)

assign(3,1)

assign(3,-1)

...
assign(n,1)

assign(n,-1)

end

Figure 6: A partially ordered plan that can be hard to evaluate
assignment. Finally, the minimum of that probability over all consistent partially ordered
plans is greater than 0 if and only if  is unsatisable.

Theorem 12 The plan-evaluation problem for partially ordered plans in at domains is

PP-complete under the average interpretation.
Proof: Under the average interpretation, we must decide whether the average evaluation
over all consistent totally ordered plans is greater than threshold . This can be decided in
PP by guessing uniformly a totally ordered plan and checking its consistency with the given
partially ordered plan in polynomial time. If the guessed totally ordered plan is consistent,
it can be evaluated in polynomial time (Theorem 1) and accepted or rejected as appropriate.
If the guessed plan is inconsistent, the computation accepts with probability  and rejects
with probability 1 , , leaving the average over the consistent orderings unchanged with
respect to the threshold .
The PP-hardness is shown by a reduction from the PP-complete Majsat. Let  be a
formula in CNF. We show how to construct a domain M () and a partially ordered plan
P () such that  2 Majsat if and only if the average performance of M () under a totally
ordered plan consistent with P () is greater than 1=2.
Let  consist of the m clauses C1 ; : : : ; Cm , which contain n variables x1 ; : : : ; xn . Domain
M () = hS ; s0 ; A; t; Gi has actions
A = fassign(i; b) j i 2 f1; : : : ; ng; b 2 f,1; 1gg [ fstart; check; endg:
Action assign(i; b) will be interpreted as \assign sign b to xi ." The partially ordered plan
P () has plan steps
V = f(i; b; h) j i 2 f1; : : : ; ng; b 2 f,1; 1g; h 2 f1; : : : ; mgg [ fstart; check; endg
and mapping  : V ! A with
() =  for  2 fstart; check; endg, and ((i; b; h)) = assign(i; b):
24

Complexity of Probabilistic Planning

The order E requires that a consistent plan has start as the rst and end as the last step.
The steps in between are arbitrarily ordered. More formally,
E = f(start; q) j q 2 V , fstart; endgg [ f(q; end) j q 2 V , fstart; endgg:
Now, we dene how the domain M () acts on a given totally ordered plan P consistent
with P (). Domain M () consists of the cross product of the following polynomial-size
deterministic domains Ms and M , to which a nal probabilistic transition will be added.
Before we describe Ms and M precisely, here are their intuitive denitions. The domain
Ms is satised by plans that have the form of an assignment to the n Boolean variables with
the restriction that the assignment is repeated m times (for easy checking). The domain
M is satised by plans that correspond to satisfying assignments. The composite of these
two domains is only satised by plans that correspond to satisfying assignments. We will
now dene these domains formally.
First, Ms checks whether the totally ordered plan matches the regular expression
start (assign(1; 0)m jassign(1; 1)m )
   (assign(n; 0)m jassign(n; 1)m )
check ((assign(1; 0)jassign(1; 1))    (assign(n; 0)jassign(n; 1)))m :
Note that the m here is a constant. Let \good" be the state reached by Ms if the plan
matches that expression. Otherwise, the state reached is \bad". To clarify, the actions before check are there simply to \use up" the extra steps not used in specifying the assignment
in the partially ordered plan.
Next, M checks whether the sequence of actions following the check action satises
the clauses of  in the following sense. Let a1    ak be this sequence. M interprets each
subsequence a1+(j ,1)n    an+(j ,1)n with al+(j ,1)m = assign(x; bl ) as assignment b1 ; : : : ; bn
to the variables x1 ; : : : ; xn , and checks whether this assignment satises clause Cj . If all
single clauses are satised in this way, then M reaches state \satised".
Note that Ms and M are dened so that they do not deal with the nal end action.
M () consists of the product domain of Ms and M with the transitions for action end
as follows. If M is in state (bad; q) for any state q of M , then action end lets M go
probabilistically to state \accept" or to state \reject", with probability 1=2 each; if M is
in state (good; satised), the M under action end goes to state \accept" (with probability
1); otherwise, M under action end goes to state reject (with probability 1). The set of goal
states of M consists of the only state \accept".
We analyze the behavior of M () under any plan P consistent with P (). If Ms under
P reaches state \bad", then M () under P reaches a goal state with probability 1=2. Now,
consider a plan P under which Ms reaches the state \good"|called a good plan. Then
P matches the above regular expression. Therefore, for every i 2 f1; : : : ; mg there exists
bi 2 f,1; 1g such that all steps s(i; bi ; h) are between start and check. Thus, all steps
between check and end are
s(1; 1 , i1 ; 1)    s(n; 1 , in ; 1)s(1; 1 , i1 ; 2)    s(n; 1 , in; m)
Consequently, the sequence of actions dened by the labeling of these plan steps are
(assign(1; i1 )assign(2; i2 )    assign(n; in ))m :
25

Littman, Goldsmith & Mundhenk

This means, that M checks whether all clauses of  are satised by the assignment i1    in ,
i.e., M checks whether i1    in satises . Therefore, M () accepts under plan P with
probability 1, if the plan represents a satisfying assignment, and with probability 0 otherwise.
Note that each assignment corresponds to exactly one good plan. Therefore, the average
over all good plans that M () accepts equals the fraction of satisfying assignments of .
Since M () accepts under \bad" plans with probability 1=2, this yields that the average
over all plans consistent with P () of the acceptance probabilities of M () is greater than
1=2 if and only if  2 Majsat.
The complexity of the plan-existence problem for partially ordered plans is identical to
that for totally ordered plans.

Theorem 13 The plan-existence problem for partially ordered plans in at domains is NPcomplete under the pessimistic, optimistic and average interpretations. The plan-existence
problem for partially ordered plans in propositional domains is NPPP -complete under the
pessimistic, optimistic and average interpretations.

Proof: First, note that a totally ordered plan is a special type of partially ordered plan

and its evaluation is unchanged under the pessimistic, optimistic, or average interpretation.
In particular, because there is only one ordering consistent with a given totally ordered
plan, the best, worst, and average orderings are all the same. Therefore, if there exists a
totally ordered plan with value greater than , then there is a partially ordered plan with
value greater than  (the same plan), under all three interpretations.
Conversely, if there is a partially ordered plan with value greater than  under any of
the three interpretations, then there is a totally ordered plan with value greater than .
This is because the value of the best, worst, and average ordering of a partially ordered
plan is always a lower bound on the value of the best consistent totally ordered plan.
Given this strong equivalence, the complexity of plan existence for partially ordered
plans is a direct corollary of Theorems 2 and 4.
The pattern for partially ordered plan evaluation in at domains is that the average
interpretation is no easier to decide than either the optimistic or pessimistic interpretations.
In propositional domains, the pattern is the opposite: the average interpretation is no harder
to decide than either the optimistic or pessimistic interpretations.

Theorem 14 The plan-evaluation problem for partially ordered plans in propositional do-

mains is NPPP -complete under the optimistic interpretation, co-NPPP -complete under the
pessimistic interpretation, and PP-complete under the average interpretation.

Proof sketch: For the optimistic interpretation, membership in NPPP follows from the

fact that we can guess a single suciently good consistent total order and evaluate it in
PP (Theorem 3). Hardness for NPPP can be shown using a straightforward reduction from
E-Majsat (as in the proof of Theorem 4).
For the pessimistic interpretation, membership in co-NPPP follows from the fact that we
can guess the worst consistent total order and evaluate it in PP (Theorem 3). Hardness for
26

Complexity of Probabilistic Planning

co-NPPP can be shown by reducing to it the co-NPPP version of E-Majsat (E-Majsat);
the proof is a simple adaptation of the techniques used, for example, in Theorem 4 above.
For the average interpretation, the problem can be shown to be in PP by combining
the argument in the proof of Theorem 12 showing how to average over consistent totally
ordered plans with the argument in the proof of Theorem 3 showing how to evaluate a
plan in a propositional domain in PP. Alternatively, we could express the evaluation of a
partially ordered plan under the average interpretation as a compact probabilistic acyclic
plan; Corollary 5 states that such plans can be evaluated in PP. PP-hardness follows directly
from Theorem 3, because totally ordered plans are a special case of partially ordered plans
and evaluating totally ordered plans is PP-hard.

5. Applications
To help illustrate the utility of our results, this section cites several planners from the
literature and analyzes the computational complexity of the problems they attack. We do
not give detailed explanations of the planners themselves; for this, we refer the reader to
the original papers. We focus on three planning systems: witness (Brown University),
buridan (University of Washington), and treeplan (University of British Columbia). In
the process of making connections to these planners, we also describe how our work relates to
the discounted-reward criterion, partial observability, other domain representations, partial
order conditional planning, policy-based planning, and approximate planning.

5.1 Witness

The witness algorithm (Cassandra, Kaelbling, & Littman, 1994; Kaelbling et al., 1998)
solves at partially observable Markov decision processes using a dynamic-programming approach. The basic algorithm nds optimal unrestricted solutions to nite-horizon problems.
Papadimitriou and Tsitsiklis (1987) showed that the plan-existence problem for polynomialhorizon partially observable Markov decision processes is PSPACE-complete.
As an extension to their nite-horizon algorithm, Kaelbling et al. (1998) sketch a method
for nding optimal looping plans for some domains. Although this is not presented as a
formal algorithm, it is not unreasonable to say that the pure form of the problem that this
extended version of witness attacks is one of nding a valid polynomial-size looping plan
for a partially observable domain. The similarities between this problem and that described
in Section 3 are that the domains are at and that the plans are identical in form. The
apparent dierences are that witness optimizes a reward function instead of probability
of goal satisfaction and that witness works in partially observable domains whereas our
results are dened in terms of completely observable domains. Both of these apparent
dierences are insignicant, however, from a computational complexity point of view.
First, witness attempts to maximize the expected total discounted reward over an
innite horizon (sometimes called optimizing a time-separable value function). As argued
by Condon (1992), any problem dened in terms of a sum of discounted rewards can be
recast as one of goal satisfaction. The argument proceeds roughly as follows. Let 0 <  < 1
be the discount factor and R(s; a) be the immediate reward received for taking action a in
state s.
27

Littman, Goldsmith & Mundhenk

Dene

s ;a R(s0 ; a0 )
R0(s; a) = max R(s;Ra()s0,; amin
0 ) , min R(s0 ; a0 ) :
0

s ;a
0

0

s ;a

0

0

0

From this, we have that 0  R0 (s; a)  1 for all s and a and that the value of any plan with
respect to the revised reward function is a simple linear transformation of its true value.
Now, we introduce an auxiliary state g to be the goal state and create a new transition
function t0 such that t0 (s; a; g) = (1 ,  )R0 (s; a) and t0 (s; a; s0 ) = (1 , (1 ,  )R0 (s; a))t(s; a; s0 )
for s0 6= g; t0 is a well-dened transition function and the probability of goal satisfaction for
any plan under transition function t0 is precisely the same as the expected total discounted
reward under reward function R0 and transition function t. Thus, any problem stated as
one of optimizing the expected total of discounted immediate rewards can be turned into an
equivalent problem of optimizing goal satisfaction with only a slight change to the transition
function and one additional state. This means there is no fundamental computational
complexity dierence between these two dierent types of planning objectives.
The second apparent dierence between the problem solved by the extended witness
algorithm and that described in Section 3 is that of partial versus complete observability.
In fact, our results do address partial observability, albeit indirectly. In our formulation of
the plan-existence problem, plans are constrained to make no conditional branches (in the
totally ordered and partially ordered cases), or to branch only on distinctions made by the
step-transition function  (in the acyclic and looping cases); these two choices correspond
to unobservable and partially observable domains, respectively. In a partially observable
domain, the plan-existence problem becomes one of nding a valid polynomial-size nitestate controller subject to the given observability constraints. Nothing in our complexity
proofs depends on the presence or absence of additional observability constraints. Therefore,
it is a direct corollary of Theorem 2 that the plan-existence problem for polynomial-horizon
plans in unobservable domains is NP-complete (Papadimitriou & Tsitsiklis, 1987) and of
Theorem 7 that the plan-existence problem for polynomial-size looping plans in partially
observable domains is NP-complete (this is a new result).
It is interesting to note that the computational complexity of searching for size-bounded
plans in partially observable domains is generally substantially less than that of solving the
corresponding unconstrained partially observable Markov decision process. For example,
we found that the plan-existence problem for acyclic plans in propositional domains is
NPPP -complete (Theorem 4). The corresponding unconstrained problem is that of determining the existence of a history-dependent policy for a polynomial-horizon, compactly
represented partially observable Markov decision process, which is EXPSPACE-complete
(Theorem 4.15 of Goldsmith et al., 1996, or Theorem 6.8 of Mundhenk et al., 1997b). The
gap here is enormous: EXPSPACE is to EXP what PSPACE is to P, and EXP is already
provably intractable in the worst case. In contrast to EXPSPACE-complete problems, it is
conceivable that good heuristics for NPPP -complete problems can be created by extensions
of recent advances in heuristics for NP-complete problems. Therefore, there is some hope
of devising eective planning algorithms by building on the observations in this paper and
searching for optimal size-bounded plans instead of optimal unrestricted plans; in fact, recent planners for both propositional domains (Majercik & Littman, 1998a, 1998b) and at
domains (Hansen, 1998) are motivated by these results.
28

Complexity of Probabilistic Planning

Domain Type
at
propositional
at
propositional

Horizon Type
polynomial
polynomial
innite
innite

Size-Bounded Plan Unrestricted Plan
NP-complete
NPPP -complete
NP-complete
PSPACE-complete

PSPACE-complete
EXPSPACE-complete
undecidable
undecidable

Table 3: Complexity results for plan existence in partially observable domains
Table 3 summarizes complexity results for planning in partially observable domains.
The results for size-bounded plans are corollaries of Theorems 2, 4, 7, and 9 of this paper. The results for unrestricted plans are due to Papadimitriou and Tsitsiklis (1987)
(at, polynomial), Goldsmith et al. (1996) (propositional, polynomial), and Hanks (1996)
(innite-horizon). This last result is derived by noting the isomorphism of the innitehorizon problem to the emptiness problem for probabilistic nite-state automata, which is
undecidable (Rabin, 1963).

5.2 Buridan

The buridan planner (Kushmerick et al., 1995) nds partially ordered plans for propositional domains in the PSO representation. There are two identiable dierences between
the problem solved by buridan and the problem analyzed in Section 4: the representation
of planning problems and the fact that buridan is not restricted to nd polynomial-size
plans. We address each of these dierences below.
Although, on the surface, PSO is dierent from ST, either can be converted into the
other in polynomial time with at most a polynomial increase in domain size. In particular,
the eect of an action in PSO is represented by a single decision tree consisting of proposition
nodes (like ST) and random nodes (easily simulated in ST using auxiliary propositions).
At the leaves are a list of propositions that become true and another list of propositions
that become false should that leaf be reached. This type of correlated eect is also easily
represented in ST using the chain rule of probability theory to decompose the probability
distribution into separate probabilities for each proposition and careful use of the \:new"
sux. Thus, any PSO domain can be converted to a similar size ST domain quickly.
Similarly, a domain in ST can be converted to PSO with at most a polynomial expansion.
This conversion is too complex to sketch here, but follows from the proof of equivalence between ST and a simplied representation called IF (Littman, 1997a). Given the polynomial
equivalence between ST and PSO, any complexity results for ST carry over to PSO.5
The results described in this paper concern planning problems in which a bound is given
on the size of the plan sought. Although Kushmerick et al. (1995) do not explicitly describe
their planner as one that prefers small plans to large plans, the design of the planner as
one that searches through the space of plans makes the notion of plan size central to the
algorithm. Indeed, the public-domain buridan implementation uses plan size as part of a
best-rst search procedure for identifying a suciently successful plan. This means that, all
other things being equal, shorter plans will be found before larger plans. Furthermore, to
assure termination, the planner only considers a xed number of plans before halting, thus
5. To be more precise, this is true for complexity classes closed under log-space reductions.

29

Littman, Goldsmith & Mundhenk

putting a limit indirectly on the maximum allowable plan size. So, although buridan does
not attempt to solve precisely the same problem that we considered, it is fair to say that the
problem we consider is an idealization of the problem attacked by buridan. Regardless,
our lower bounds on complexity apply to buridan.
Kushmerick et al. (1995) looked at generating suciently successful plans under both
the optimistic interpretation and the pessimistic interpretation. They also explicitly examined the plan-evaluation problem for partially ordered plans under both interpretations.
Therefore, Theorems 13 and 14 apply to buridan.
The more sophisticated c-buridan planner (Draper et al., 1994) extends buridan to
plan in partially observable domains and to produce plans with conditional execution. The
results of our work also shed light on the computational complexity of the problem addressed
by c-buridan. Draper et al. (1994) devised a representation for partially ordered acyclic
(conditional) plans. In this representation, each plan step generates an observation label as
a function of the probabilistic outcome of the step. Each step also has an associated set of
context labels dictating the circumstances under which that step must be executed. A plan
step is executed only if its context labels are consistent with the observation labels produced
in earlier steps. In its totally ordered form, this type of plan can be expressed as a compact
acyclic plan; Corollary 5 can be used to show that the plan-evaluation and plan-existence
problems for a totally ordered version of c-buridan's conditional plan representation in
propositional domains are PP-complete and NPPP -complete, respectively.
In our results above, we consider evaluating and searching for plans that are partially
ordered and plans that have conditional execution, but not both at once. Nonetheless, the
same sorts of techniques presented in this paper can be applied to analyzing the problems
attacked by c-buridan. For example, consider the plan-existence problem for c-buridan's
partially ordered conditional plans under the optimistic interpretation. This problem asks
whether there is a partially ordered conditional plan that has some total order that reaches
the goal with sucient probability. This is equivalent to asking whether there is a totally
ordered conditional plan that reaches the goal with sucient probability. Therefore, the
problem is NPPP -complete, by the argument in the previous paragraph.
In spite of many supercial dierences between the problems analyzed in this paper and
those studied by the creators of the buridan planners, our results are quite relevant to
understanding their work.

5.3 Treeplan
A family of planners have been designed that generate a decision-tree-based representation
of stationary policies (mappings from state to action) (Boutilier et al., 1995; Boutilier &
Poole, 1996; Boutilier & Dearden, 1996) in probabilistic propositional domains; we refer
to these planners collectively as the treeplan planners. Once again, these planners solve
problems that are not identical to the problems addressed in this paper but are closely
related.
The planner described by Boutilier et al. (1995) nds solutions that maximize expected
total discounted reward in compactly represented Markov decision processes (the domain
representation used is expressively equivalent to ST). As mentioned earlier, the dierence
between maximizing goal satisfaction and maximizing expected total discounted reward is a
30

Complexity of Probabilistic Planning

supercial one, so the problem addressed by this planner is EXP-complete (Littman, 1997a).
Although the policies used by Boutilier et al. (1995) appears quite dissimilar from the nitestate controllers described in our work, policies can be converted to a type of similarly
sized compact looping plan (an extension of the type of plan described in Corollary 5).
The conversion from stationary policies to looping plans is as described in the proof of
Theorem 7, except that the resulting plans are represented compactly.
In later work, Boutilier and Dearden (1996) show how it is possible to limit the size
of the representation of the policy in treeplan and still obtain approximately optimal
performance. This is necessary because, in general, the size of decision trees needed to
represent the optimal policies can be exponentially large. By keeping the decision trees
from getting too large, the resulting planner becomes subject to an extension of Theorem 9
and, therefore, attacks a PSPACE-complete problem.
One emphasis of Boutilier and Dearden (1996) is on nding approximately optimal
solutions, with the hope that doing so is easier than nding optimal solutions. We do
not explore the worst-case complexity of approximation in this paper, although Lusena,
Goldsmith, and Mundhenk (1998) have produced some strong negative results in this area.
A related issue is one of using simulation (random sampling) to nd approximately optimal
solutions to probabilistic planning problems. Some empirical successes have been obtained
with the related approach of reinforcement learning (Tesauro, 1994; Crites & Barto, 1996),
but, once again, the worst-case complexity of probabilistic planning is not known to be any
lower for approximation by simulation.

6. Conclusions
In this paper, we explored the computational complexity of plan evaluation and plan existence in probabilistic domains. We found that, in compactly represented propositional
domains, restricting the size and form of the policies under consideration reduced the
computational complexity of plan existence from EXP-complete for unrestricted plans to
PSPACE-complete for polynomial-size looping plans and NPPP -complete for polynomialsize acyclic plans. In contrast, in at domains, restricting the form of the policies under
consideration increased the computational complexity of plan existence from P-complete
for unrestricted plans to NP-complete for totally ordered plans; this is because a plan that
is smaller than the domain in which it operates is often unable to exploit important Markov
properties of the domain. We were able to characterize precisely the complexity of all
problems we examined with regard to the current state of knowledge in complexity theory.
Several problems we studied turned out to be NPPP -complete. The class NPPP promises
to be very useful to researchers in uncertainty in articial intelligence because it captures
the type of problems resulting from choosing (\guessing") a solution and then evaluating its
probabilistic behavior. This is precisely the type of problem faced by planning algorithms in
probabilistic domains, and captures important problems in other domains as well, such as
constructing explanations in belief networks and designing robust communication networks.
We provide a new conceptually simple NPPP -complete problem, E-Majsat, that may be
useful in further explorations in this direction.
The basic structure of our results is that if plan evaluation is complete for some class C ,
then plan existence is typically NPC -complete. This same basic structure holds in determin31

Littman, Goldsmith & Mundhenk

istic domains: evaluating a totally ordered plan in a propositional domain is P-complete (for
suciently powerful domain representations) and determining the existence of a polynomialsize totally ordered plan is NPP = NP-complete.
From a pragmatic standpoint, the intuition that searching for small plans is more efcient than searching for arbitrary size plans suggests that exact dynamic-programming
algorithms, which are so successful in at domains, may not be as eective in propositional
domains; they do not focus their eorts on the set of small plans. Algorithm-development
energy, therefore, might fruitfully be spent devising heuristics for problems in the class NPPP
as this class captures the essence of searching for small plans in probabilistic domains|some
early results in this direction are appearing (Majercik & Littman, 1998a, 1998b). Complexity theorists have only recently begun to explore classes such as NPPP that lie between the
polynomial hierarchy and PSPACE and algorithm designers have come to these classes even
more recently. As this paper marks the beginning of our exploration of this class of problems, much work is still to be done in probing algorithmic implications, but it is our hope
that heuristics for NPPP could lead to powerful methods for solving a range of important
uncertainty-sensitive combinatorial problems.

Acknowledgements
This work was supported in part by grants NSF-IRI-97-02576-CAREER (Littman), and
NSF CCR-9315354 (Goldsmith). We gratefully acknowledge Andrew Klapper, Anne Condon, Matthew Levy, Steve Majercik, Chris Lusena, Mark Peot, and our reviewers for helpful
feedback and conversations on this topic.

Appendix A. Complexity of E-Majsat
The E-Majsat problem is: given a pair (; k) consisting of a Boolean formula  of n
variables x1 ; : : : ; xn and a number 1  k  n, is there an assignment to the rst k variables
x1 ; : : : ; xk such that the majority of assignments to the remaining n,k variables xk+1 ; : : : ; xn
satises ?
For k = n, this is precisely Boolean satisability, a classic NP-complete problem. This
is because we are asking whether there exists an assignment to all the variables that makes
 true. For k = 0, E-Majsat is precisely Majsat, a well-known PP-complete problem.
This is because we are asking whether the majority of all total assignments makes  true.
Deciding an instance of E-Majsat for intermediate values of k has a dierent character.
It involves both an NP-type calculation to pick a good setting for the rst k variables and a
PP-type calculation to see if the majority of assignments to the remaining variables makes
 true. This is akin to searching for a good answer (plan, schedule, coloring, belief network
explanation, etc.) in a combinatorial space when \good" is determined by a computation
over probabilistic quantities. This is just the type of computation described by the class
NPPP , and we show next that E-Majsat is NPPP -complete.

Theorem 15

E-Majsat

is NPPP -complete.
32

Complexity of Probabilistic Planning

Proof: Membership in NPPP follows directly from denitions. To show completeness of
E-Majsat, we rst observe (Tor
an, 1991) that NPPP is the NP
m -closure of the PP-complete

set Majsat. Thus, any NPPP computation can be modeled by a nondeterministic machine
N that, on each possible computation, rst guesses a sequence s of bits that controls its
nondeterministic moves, deterministically performs some computation on input x and s,
and then writes down a formula qx;s with variables in z1 ; : : : ; zl as a query to Majsat.
Finally, N (x) with oracle Majsat accepts if and only if for some s, qx;s 2 Majsat.
Given any input x, like in Cook's Theorem, we can construct a formula x with variables
y1; : : : ; yk and z1; : : : ; zl such that for every assignment a1; : : : ; ak ; b1 ; : : : ; bl it holds that
x (a1 ; : : : ; ak ; b1 ; : : : ; bl ) = qx;a1a (b1 ; : : : ; bl ). Thus, (x ; k) 2 E-Majsat if and only if for
some assignment s to y1 ; : : : ; yk , qx;s 2 Majsat if and only if N (x) accepts.
k

References

Allender, E., & Ogihara, M. (1996). Relationships among PL, #L, and the determinant.
Theoretical Informatics and Applications, 30 (1), 1{21.
A lvarez, C., & Jenner, B. (1993). A very hard log-space counting class. Theoretical Computer
Science, 107, 3{30.
Backstrom, C. (1995). Expressive equivalence of planning formalisms. Articial Intelligence,
76 (1{2), 17{34.
Backstrom, C., & Nebel, B. (1995). Complexity results for SAS+ planning. Computational
Intelligence, 11 (4), 625{655.
Balcazar, J., Daz, J., & Gabarro, J. (1988/1990). Structural Complexity I/II. EATCS
Monographs on Theoretical Computer Science. Springer Verlag.
Borodin, A., Cook, S., & Pippenger, N. (1983). Parallel computation for well-endowed
rings and space-bounded probabilistic machines. Information and Control, 58 (1{3),
113{136.
Boutilier, C., Dean, T., & Hanks, S. (1998). Decision theoretic planning: Structural assumptions and computational leverage. In preparation.
Boutilier, C., & Dearden, R. (1996). Approximating value trees in structured dynamic programming. In Saitta, L. (Ed.), Proceedings of the Thirteenth International Conference
on Machine Learning.
Boutilier, C., Dearden, R., & Goldszmidt, M. (1995). Exploiting structure in policy construction. In Proceedings of the Fourteenth International Joint Conference on Articial
Intelligence, pp. 1104{1113.
Boutilier, C., & Poole, D. (1996). Computing optimal policies for partially observable
decision processes using compact representations. In Proceedings of the Thirteenth
National Conference on Articial Intelligence, pp. 1168{1175. AAAI Press/The MIT
Press.
33

Littman, Goldsmith & Mundhenk

Bylander, T. (1994). The computational complexity of propositional STRIPS planning.
Articial Intelligence, 69, 161{204.
Cassandra, A. R., Kaelbling, L. P., & Littman, M. L. (1994). Acting optimally in partially
observable stochastic domains. In Proceedings of the Twelfth National Conference on
Articial Intelligence, pp. 1023{1028 Seattle, WA.
Chapman, D. (1987). Planning for conjunctive goals. Articial Intelligence, 32, 333{379.
Condon, A. (1992). The complexity of stochastic games. Information and Computation,
96 (2), 203{224.
Crites, R. H., & Barto, A. G. (1996). Improving elevator performance using reinforcement
learning. In Touretzky, D. S., Mozer, M. C., & Hasselmo, M. E. (Eds.), Advances in
Neural Information Processing Systems 8 Cambridge, MA. The MIT Press.
Dearden, R., & Boutilier, C. (1997). Abstraction and approximate decision-theoretic planning. Articial Intelligence, 89 (1{2), 219{283.
Draper, D., Hanks, S., & Weld, D. (1994). Probabilistic planning with information gathering
and contingent execution. In Proceedings of the AAAI Spring Symposium on Decision
Theoretic Planning, pp. 76{82.
Drummond, M., & Bresina, J. (1990). Anytime synthetic projection: Maximizing the
probability of goal satisfaction. In Proceedings of the Eighth National Conference on
Articial Intelligence, pp. 138{144. Morgan Kaufmann.
Erol, K., Nau, D. S., & Subrahmanian, V. S. (1995). Complexity, decidability and undecidability results for domain-independent planning. Articial Intelligence, 76, 75{88.
Gill, J. (1977). Computational complexity of probabilistic Turing machines. SIAM Journal
on Computing, 6 (4), 675{695.
Goldman, R. P., & Boddy, M. S. (1994). Epsilon-safe planning. In Proceedings of the 10th
Conference on Uncertainty in Articial Intelligence (UAI94), pp. 253{261 Seattle,
WA.
Goldsmith, J., Littman, M., & Mundhenk, M. (1997a). The complexity of plan existence and
evaluation in probabilistic domains. Tech. rep. CS-1997-07, Department of Computer
Science, Duke University.
Goldsmith, J., Littman, M. L., & Mundhenk, M. (1997b). The complexity of plan existence
and evaluation in probabilistic domains. In Proceedings of the Thirteenth Annual Conference on Uncertainty in Articial Intelligence (UAI{97), pp. 182{189 San Francisco,
CA. Morgan Kaufmann Publishers.
Goldsmith, J., Lusena, C., & Mundhenk, M. (1996). The complexity of deterministically
observable nite-horizon Markov decision processes. Tech. rep. 268-96, Department
of Computer Science, University of Kentucky.
34

Complexity of Probabilistic Planning

Hanks, S. (1996). Decision-theoretic planning in unobservable domains is undecidable.
Personal communication.
Hansen, E. A. (1998). Finite-Memory Control of Partially Observable Systems. Ph.D. thesis,
University of Massachusetts.
Jung, H. (1985). On probabilistic time and space. In Proceedings 12th ICALP, pp. 281{291.
Lecture Notes in Computer Science, Springer-Verlag.
Kaelbling, L. P., Littman, M. L., & Cassandra, A. R. (1998). Planning and acting in
partially observable stochastic domains. Articial Intelligence, 101 (1{2), 99{134.
Koenig, S., & Simmons, R. G. (1994). Risk-sensitive planning with probabilistic decision
graphs. In Proceedings of the 4th International Conference on Principles of Knowledge
Representation and Reasoning, pp. 363{373.
Kushmerick, N., Hanks, S., & Weld, D. S. (1995). An algorithm for probabilistic planning.
Articial Intelligence, 76 (1-2), 239{286.
Ladner, R. (1989). Polynomial space counting problems. SIAM Journal on Computing, 18,
1087{1097.
Lin, S.-H., & Dean, T. (1995). Generating optimal policies for high-level plans with conditional branches and loops. In Proceedings of the Third European Workshop on
Planning, pp. 205{218.
Littman, M. L. (1997a). Probabilistic propositional planning: Representations and complexity. In Proceedings of the Fourteenth National Conference on Articial Intelligence,
pp. 748{754. AAAI Press/The MIT Press.
Littman, M. L. (1997b). Solving large POMDPs: Lessons from complexity theory. Talk
presented at the DARPA AI Workshop in Providence, RI. Slides available at URL
http://www.cs.duke.edu/mlittman/talks/darpa97-pomdp.ps.
Lovejoy, W. S. (1991). A survey of algorithmic methods for partially observable Markov
decision processes. Annals of Operations Research, 28 (1), 47{65.
Lusena, C., Goldsmith, J., & Mundhenk, M. (1998). Nonapproximability results for Markov
decision processes. Tech. rep. UK CS Dept TR 275-98, University of Kentucky.
Majercik, S. M., & Littman, M. L. (1998a). MAXPLAN: A new approach to probabilistic
planning. In Simmons, R., Veloso, M., & Smith, S. (Eds.), Proceedings of the Fourth
International Conference on Articial Intelligence Planning, pp. 86{93. AAAI Press.
Majercik, S. M., & Littman, M. L. (1998b). Using caching to solve larger probabilistic
planning problems. In Proceedings of the Fifteenth National Conference on Articial
Intelligence, pp. 954{959. The AAAI Press/The MIT Press.
Mansell, T. M. (1993). A method for planning given uncertain and incomplete information.
In Proceedings of the 9th Conference on Uncertainty in Articial Intelligence, pp.
350{358. Morgan Kaufmann Publishers.
35

Littman, Goldsmith & Mundhenk

McAllester, D., & Rosenblitt, D. (1991). Systematic nonlinear planning. In Proceedings of
the 9th National Conference on Articial Intelligence, pp. 634{639.
Mundhenk, M., Goldsmith, J., & Allender, E. (1997a). The complexity of policy-evaluation
for nite-horizon partially-observable Markov decision processes. In Proceedings of
22nd Symposium on Mathematical Foundations of Computer Science (published in
Lecture Notes in Computer Science). Springer-Verlag.
Mundhenk, M., Goldsmith, J., Lusena, C., & Allender, E. (1997b). Encyclopaedia of complexity results for nite-horizon Markov decision process problems. Tech. rep. UK CS
Dept TR 273-97, University of Kentucky.
Papadimitriou, C. H. (1994). Computational Complexity. Addison-Wesley, Reading, MA.
Papadimitriou, C. H., & Tsitsiklis, J. N. (1987). The complexity of Markov decision processes. Mathematics of Operations Research, 12 (3), 441{450.
Platzman, L. K. (1981). A feasible computational approach to innite-horizon partiallyobserved Markov decision problems. Tech. rep. J-81-2, Georgia Institute of Technology,
Atlanta, GA.
Puterman, M. L. (1994). Markov Decision Processes|Discrete Stochastic Dynamic Programming. John Wiley & Sons, Inc., New York, NY.
Rabin, M. O. (1963). Probabilistic automata. Information and Control, 6 (3), 230{245.
Roth, D. (1996). On the hardness of approximate reasoning. Articial Intelligence, 82 (1{2),
273{302.
Simon, J. (1975). On some central problems in computational complexity. Ph.D. thesis,
Cornell University. Also Cornell Department of Computer Science Technical Report
TR75-224.
Smith, D. E., & Williamson, M. (1995). Representation and evaluation of plans with loops.
Working notes for the 1995 Stanford Spring Symposium on Extended Theories of
Action.
Tesauro, G. (1994). TD-Gammon, a self-teaching backgammon program, achieves masterlevel play. Neural Computation, 6 (2), 215{219.
Toda, S. (1991). PP is as hard as the polynomial-time hierarchy. SIAM Journal on Computing, 20, 865{877.
Toran, J. (1991). Complexity classes dened by counting quantiers. Journal of the ACM,
38 (3), 753{774.
Vinay, V. (1991). Counting auxiliary pushdown automata and semi-unbounded arithmetic
circuits. In Proc. 6th Structure in Complexity Theory Conference, pp. 270{284. IEEE.

36

Journal of Articial Intelligence Research 9 (1998) 317-365

Submitted 5/98; published 12/98

AntNet: Distributed Stigmergetic Control for
Communications Networks
Gianni Di Caro
Marco Dorigo

IRIDIA, Universite Libre de Bruxelles
50, av. F. Roosevelt, CP 194/6, 1050 - Brussels, Belgium

gdicaro@iridia.ulb.ac.be
mdorigo@ulb.ac.be

Abstract

This paper introduces AntNet, a novel approach to the adaptive learning of routing
tables in communications networks. AntNet is a distributed, mobile agents based Monte
Carlo system that was inspired by recent work on the ant colony metaphor for solving
optimization problems. AntNet's agents concurrently explore the network and exchange
collected information. The communication among the agents is indirect and asynchronous,
mediated by the network itself. This form of communication is typical of social insects
and is called stigmergy. We compare our algorithm with six state-of-the-art routing algorithms coming from the telecommunications and machine learning elds. The algorithms'
performance is evaluated over a set of realistic testbeds. We run many experiments over
real and articial IP datagram networks with increasing number of nodes and under several paradigmatic spatial and temporal trac distributions. Results are very encouraging.
AntNet showed superior performance under all the experimental conditions with respect
to its competitors. We analyze the main characteristics of the algorithm and try to explain
the reasons for its superiority.

1. Introduction
Worldwide demand and supply of communications networks services are growing exponentially. Techniques for network control (i.e., online and o-line monitoring and management
of the network resources) play a fundamental role in best exploiting the new transmission
and switching technologies to meet user's requests.
Routing is at the core of the whole network control system. Routing, in conjunction
with the admission, ow, and congestion control components, determines the overall network
performance in terms of both quality and quantity of delivered service (Walrand & Varaiya,
1996). Routing refers to the distributed activity of building and using routing tables, one
for each node in the network, which tell incoming data packets which outgoing link to use
to continue their travel towards the destination node.
Routing protocols and policies have to accommodate conicting objectives and constraints imposed by technologies and user requirements rapidly evolving under commercial
and scientic pressures. Novel routing approaches are required to eciently manage distributed multimedia services, mobile users and networks, heterogeneous inter-networking,
service guarantees, point-to-multipoint communications, etc. (Sandick & Crawley, 1997;
The ATM Forum, 1996).
The adaptive and distributed routing algorithm we propose in this paper is a mobileagent-based, online Monte Carlo technique inspired by previous work on articial ant
c 1998 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

Di Caro & Dorigo

colonies and, more generally, by the notion of stigmergy (Grasse, 1959), that is, the indirect communication taking place among individuals through modications induced in
their environment.
Algorithms that take inspiration from real ants' behavior in nding shortest paths (Goss,
Aron, Deneubourg, & Pasteels, 1989; Beckers, Deneubourg, & Goss, 1992) using as information only the trail of a chemical substance (called pheromone) deposited by other ants,
have recently been successfully applied to several discrete optimization problems (Dorigo,
Maniezzo, & Colorni, 1991; Dorigo, 1992; Dorigo, Maniezzo, & Colorni, 1996; Dorigo &
Gambardella, 1997; Schoonderwoerd, Holland, Bruten, & Rothkrantz, 1996; Schoonderwoerd, Holland, & Bruten, 1997; Costa & Hertz, 1997). In all these algorithms a set of articial
ants collectively solve the problem under consideration through a cooperative eort. This
eort is mediated by indirect communication of information on the problem structure the
ants concurrently collect while building solutions by using a stochastic policy. Similarly,
in AntNet, the algorithm we propose in this paper, a set of concurrent distributed agents
collectively solve the adaptive routing problem. Agents adaptively build routing tables and
local models of the network status by using indirect and non-coordinated communication
of information they collect while exploring the network.
To ensure a meaningful validation of our algorithm performance we devised a realistic
simulation environment in terms of network characteristics, communications protocol and
trac patterns. We focus on IP (Internet Protocol) datagram networks with irregular
topology and consider three real and articial topologies with an increasing number of
nodes and several paradigmatic temporal and spatial trac distributions. We report on
the behavior of AntNet as compared to some eective static and adaptive state-of-the-art
routing algorithms (vector-distance and link-state shortest paths algorithms (Steenstrup,
1995), and recently introduced algorithms based on machine learning techniques).
AntNet shows the best performance and the most stable behavior for all the considered
situations. In many experiments its superiority is striking. We discuss the results and the
main properties of our algorithm, as compared with its competitors.
The paper is organized as follows. In Section 2 the denition, taxonomy and characteristics of the routing problem are reported. In Section 3 we describe the communication
network model we used. Section 4 describes in detail AntNet, our novel routing algorithm,
while in Section 5 we briey describe the algorithms with which we compared AntNet. In
Section 6, the experimental settings are reported in terms of trac, networks and algorithm
parameters. Section 7 reports several experimental results. In Section 8 we discuss these
results and try to explain AntNet's superior performance. Finally, in Section 9, we discuss
related work, and in Section 10, we draw some conclusions and outline directions for future
research.

2. Routing: Denition and Characteristics
Routing in distributed systems can be characterized as follows. Let G = (V; E ) be a directed
weighted graph, where each node in the set V represents a processing/queuing and/or forwarding unit and each edge is a transmission system. The main task of a routing algorithm
is to direct data ow from source to destination nodes maximizing network performance.
318

AntNet: Distributed Stigmergetic Control for Communications Networks

In the problems we are interested in, the data ow is not statically assigned and it follows
a stochastic prole that is very hard to model.
In the specic case of communications networks (Steenstrup, 1995; Bertsekas & Gallager,
1992), the routing algorithm has to manage a set of basic functionalities and it tightly
interacts with the congestion and admission control algorithms, with the links' queuing
policy, and with the user-generated trac. The core of the routing functions is (i) the
acquisition, organization and distribution of information about user-generated trac and
network states, (ii) the use of this information to generate feasible routes maximizing the
performance objectives, and (iii) the forwarding of user trac along the selected routes.
The way the above three functionalities are implemented strongly depends on the underlying network switching and transmission technology, and on the features of the other
interacting software layers. Concerning point (iii), two main forwarding paradigms are in
use: circuit and packet-switching (also indicated with the terms connection-oriented and
connection-less). In the circuit-switching approach, a setup phase looks for and reserves the
resources that will be assigned to each incoming session. In this case, all the data packets
belonging to the same session will follow the same path. Routers are required to keep state
information about active sessions. In the packet-switching approach, there is no reservation
phase, no state information is maintained at routers and data packets can follow dierent
paths. In each intermediate node an autonomous decision is taken concerning the node's
outgoing link that has to be used to forward the data packet toward its destination.
In the work described in this paper, we focus on the packet-switching paradigm, but
the technique developed here can be used also to manage circuit-switching and we expect
to have qualitatively similar results.

2.1 A Broad Taxonomy

A common feature of all the routing algorithms is the presence in every network node of
a data structure, called routing table, holding all the information used by the algorithm to
make the local forwarding decisions. The routing table is both a local database and a local
model of the global network status. The type of information it contains and the way this
information is used and updated strongly depends on the algorithm's characteristics. A
broad classication of routing algorithms is the following:
 centralized versus distributed;
 static versus adaptive.
In centralized algorithms, a main controller is responsible for updating all the node's
routing tables and/or to make every routing decision. Centralized algorithms can be used
only in particular cases and for small networks. In general, the delays necessary to gather
information about the network status and to broadcast the decisions/updates make them
infeasible in practice. Moreover, centralized systems are not fault-tolerant. In this work,
we will consider exclusively distributed routing.
In distributed routing systems, the computation of routes is shared among the network
nodes, which exchange the necessary information. The distributed paradigm is currently
used in the majority of network systems.
In static (or oblivious) routing systems, the path taken by a packet is determined only
on the basis of its source and destination, without regard to the current network state. This
319

Di Caro & Dorigo

path is usually chosen as the shortest one according to some cost criterion, and it can be
changed only to account for faulty links or nodes.
Adaptive routers are, in principle, more attractive, because they can adapt the routing policy to time and spatially varying trac conditions. As a drawback, they can cause
oscillations in selected paths. This fact can cause circular paths, as well as large uctuations in measured performance. In addition, adaptive routing can lead more easily to
inconsistent situations, associated with node or link failures or local topological changes.
These stability and inconsistency problems are more evident for connection-less than for
connection-oriented networks (Bertsekas & Gallager, 1992).
Another interesting way of looking at routing algorithms is from an optimization perspective. In this case the main paradigms are:
 minimal routing versus non-minimal routing;
 optimal routing versus shortest path routing.
Minimal routers allow packets to choose only minimal cost paths, while non-minimal
algorithms allow choices among all the available paths following some heuristic strategies
(Bolding, Fulgham, & Snyder, 1994).
Optimal routing has a network-wide perspective and its objective is to optimize a function of all individual link ows (usually this function is a sum of link costs assigned on the
basis of average packet delays) (Bertsekas & Gallager, 1992).
Shortest path routing has a source-destination pair perspective: there is no global cost
function to optimize. Its objective is to determine the shortest path (minimum cost) between
two nodes, where the link costs are computed (statically or adaptively) following some
statistical description of the link states. This strategy is based on individual rather than
group rationality (Wang & Crowcroft, 1992). Considering the dierent content stored in
each routing table, shortest path algorithms can be further subdivided into two classes
called distance-vector and link-state (Steenstrup, 1995).
Optimal routing is static (it can be seen as the solution of a multicommodity ow problem) and requires the knowledge of all the trac characteristics. Shortest paths algorithms
are more exible, they don't require a priori knowledge about the trac patterns and they
are the most widely used routing algorithms.
In appendix A, a more detailed description of the properties of optimal and shortest
path routing algorithms is reported.
In Section 4, we introduce a novel distributed adaptive method, AntNet, that shares the
same optimization perspective as (minimal or non-minimal) shortest path algorithms but
not their usual implementation paradigms (as depicted in appendix A).

2.2 Main Characteristics of the Routing Problem

The main characteristics of the routing problem in communications networks can be summarized in the following way:

 Intrinsically distributed with strong real-time constraints: in fact, the database and

the decision system are completely distributed over all the network nodes, and failures
and status information propagation delays are not negligible with respect to the user's
320

AntNet: Distributed Stigmergetic Control for Communications Networks

trac patterns. It is impossible to get complete and up-to-date knowledge of the distributed state, that remains hidden. At each decision node, the routing algorithm can
only make use of local, up-to-date information, and of non-local, delayed information
coming from the other nodes.
 Stochastic and time-varying: the session arrival and data generation process is, in
the general case, non-stationary and stochastic. Moreover, this stochastic process
interacts recursively with the routing decisions making it infeasible to build a working model of the whole system (to be used for example in a dynamic programming
framework).
 Multi-objective: several conicting performance measures are usually taken into account. The most common are throughput (bit/sec) and average packet delay (sec).
The former measures the quantity of service that the network has been able to oer
in a certain amount of time (amount of correctly delivered bits per time unit), while
the latter denes the quality of service produced at the same time. Citing Bertsekas
and Gallager (1992), page 367: \the eect of good routing is to increase throughput
for the same value of average delay per packet under high oered load conditions and
to decrease average delay per packet under low and moderate oered load conditions".
Other performance measures consider the impact of the routing algorithm on the network resources in terms of memory, bandwidth and computation, and the algorithm
simplicity, exibility, etc.
 Multi-constraint: constraints are imposed by the underlying network technology, the
network services provided and the user services requested. In general, users ask for
low-cost, high-quality, reliable, distributed multimedia services available across heterogeneous static and mobile networks. Evaluating technological and commercial factors,
network builders and service providers try to accommodate these requests while maximizing some prot criteria. Moreover, a high level of fault-tolerance and reliability is
requested in modern high-speed networks, where user sessions can formulate precise
requests for network resources. In this case, once the session has been accepted, the
system should be able to guarantee that the session gets the resources it needs, under
any recoverable fault event.
It is interesting to note that the above characteristics make the problem of routing belong
to the class of reinforcement learning problems with hidden state (Bertsekas & Tsitsiklis,
1996; Kaelbling, Littman, & Moore, 1996; McCallum, 1995). A distributed system of agents,
the components of the routing algorithm in each node, determine a continual and online
learning of the best routing table values with respect to network's performance criteria. An
exact measure of evaluation that scores forwarding decisions is not available, neither online
nor in the form of a training set. Moreover, because of the distributed nature of the problem
and of its constraints, the complete state of the network is hidden to each agent.

3. The Communication Network Model

In this paper, we focus on irregular topology connection-less networks with an IP-like network layer (in the ISO-OSI terminology) and a very simple transport layer. In particular,
we focus on wide-area networks (WAN). In these cases, hierarchical organization schemes
321

Di Caro & Dorigo

are adopted.1 Roughly speaking, sub-networks are seen as single host nodes connected to
interface nodes called gateways. Gateways perform fairly sophisticated network layer tasks,
including routing. Groups of gateways, connected by an arbitrary topology, dene logical
areas. Inside each area, all the gateways are at the same hierarchical level and \at" routing
is performed among them. Areas communicate only by means of area border gateways. In
this way, the computational complexity of the routing problem, as seen by each gateway, is
much reduced (e.g., in the Internet, OSPF areas typically group 10 to 300 gateways), while
the complexity of the design and management of the routing protocol is much increased.
The instance of our communication network is mapped on a directed weighted graph
with N processing/forwarding nodes. All the links are viewed as bit pipes characterized
by a bandwidth (bit/sec) and a transmission delay (sec), and are accessed following a
statistical multiplexing scheme. For this purpose, every node, of type store-and-forward,
holds a buer space where the incoming and the outgoing packets are stored. This buer
is a shared resource among all the queues attached to every incoming and outgoing link of
the node. All the traveling packets are subdivided in two classes: data and routing packets.
All the packets in the same class have the same priority, so they are queued and served on
the basis of a rst-in-rst-out policy, but routing packets have a greater priority than data
packets. The workload is dened in terms of applications whose arrival rate is dictated by
a selected probabilistic model. By application (or session, or connection in the following),
we mean a process sending data packets from an origin node to a destination node. The
number of packets to send, their sizes and the intervals between them are assigned according
to some dened stochastic process. We didn't make any distinction among nodes, they act
at the same time as hosts (session end-points) and gateways/routers (forwarding elements).
The adopted workload model incorporates a simple ow control mechanism implemented
by using a xed production window for the session's packets generation. The window
determines the maximum number of data packets waiting to be sent. Once sent, a packet is
considered to be acknowledged. This means that the transport layer neither manages error
control, nor packet sequencing, nor acknowledgements and retransmissions.2
For each incoming packet, the node's routing component uses the information stored in
the local routing table to assign the outgoing link to be used to forward the packet toward
its target node. When the link resources are available, they are reserved and the transfer
is set up. The time it takes to move a packet from one node to a neighboring one depends
on the packet size and on the link transmission characteristics. If, on a packet's arrival,
there is not enough buer space to hold it, the packet is discarded. Otherwise, a service
time is stochastically generated for the newly arrived packet. This time represents the delay
between the packet arrival time and the time when it will be put in the buer queue of the
outgoing link the local routing component has selected for it.
Situations causing a temporary or steady alteration of the network topology or of its
physical characteristics are not taken into account (link or node failure, adding or deleting
of network components, etc.).
1. A hierarchical structure is adopted on the Internet, organized in hierarchical Autonomous Systems and
multiple routing areas inside each Autonomous System (Moy, 1998).
2. This choice is the same as in the \Simple Trac" model in the MaRS network simulator (Alaettinoglu,
Shankar, Dussa-Zieger, & Matta, 1992). It can be seen as a very basic form of File Transfer Protocol
(FTP).

322

AntNet: Distributed Stigmergetic Control for Communications Networks

We developed a complete network simulator in C++. It is a discrete event simulator
using as its main data structure an event list, which holds the next future events. The
simulation time is a continuous variable and is set by the currently scheduled event. The aim
of the simulator is to closely mirror the essential features of the concurrent and distributed
behavior of a generic communication network without sacricing eciency and exibility
in code development.
We end this section with some remarks concerning two features of the model.
First, we chose not to implement a \real" transport layer for a proper management
of error, ow, and congestion control. In fact, each additional control component has a
considerable impact on the network performance,3 making very dicult to evaluate and to
study the properties of each control algorithm without taking in consideration the complex
way it interacts with all the other control components. Therefore, we chose to test the
behavior of our algorithm and of its competitors in conditions such that the number of
interacting components is minimal and the routing component can be evaluated in isolation,
allowing a better understanding of its properties. To study routing in conjunction with error,
ow and congestion control, all these components should be designed at the same time, to
allow a good match among their characteristics to produce a synergetic eect.
Second, we chose to work with connection-less and not with connection-oriented networks because connection-oriented schemes are mainly used in networks able to deliver
Quality of Service (QoS) (Crawley, Nair, Rajagopalan, & Sandick, 1996).4 In this case,
suitable admission control algorithms have to be introduced, taking into account many
economic and technological factors (Sandick & Crawley, 1997). But, again, as a rst step
we think that it is more reasonable to try to check the validity of a routing algorithm by
reducing the number of components heavily inuencing the network behavior.

4. AntNet: An Adaptive Agent-based Routing Algorithm
The characteristics of the routing problem (discussed in Section 2.2) make it well suited
to be solved by a mobile multi-agent approach (Stone & Veloso, 1996; Gray, Kotz, Nog,
Rus, & Cybenko, 1997). This processing paradigm is a good match for the distributed and
non-stationary (in topology and trac patterns) nature of the problem, presents a high
level of redundancy and fault-tolerance, and can handle multiple objectives and constraints
in a exible way.
AntNet, the routing algorithm we propose in this paper, is a mobile agents system showing some essential features of parallel replicated Monte Carlo systems (Streltsov & Vakili,
1996). AntNet takes inspiration from previous work on articial ant colonies techniques to
solve combinatorial optimization problems (Dorigo et al., 1991; Dorigo, 1992; Dorigo et al.,
1996; Dorigo & Gambardella, 1997) and telephone network routing (Schoonderwoerd et al.,
3. As an example, some authors reported an improvement ranging from 2 to 30% in various performance
measures for real Internet trac (Danzig, Liu, & Yan, 1994) by changing from the Reno version to the
Vegas version of the TCP (Peterson & Davie, 1996) (the current Internet Transport Control Protocol),
and other authors even claimed improvements ranging from 40 to 70% (Brakmo, O'Malley, & Peterson,
1994).
4. This is not the case for the current Internet, where the IP bearer service is of \best-eort" type, meaning
that it does the best it can do but no guarantees of service quality in terms of delay or bandwidth or
jitter, etc., can be assured.

323

Di Caro & Dorigo

1996, 1997). The core ideas of these techniques (for a review see Dorigo, Di Caro, and
Gambardella, 1998) are (i) the use of repeated and concurrent simulations carried out by a
population of articial agents called \ants" to generate new solutions to the problem, (ii)
the use by the agents of stochastic local search to build the solutions in an incremental way,
and (iii) the use of information collected during past simulations to direct future search for
better solutions.
In the articial ant colony approach, following an iterative process, each ant builds a
solution by using two types of information locally accessible: problem-specic information
(for example, distance among cities in a traveling salesman problem), and information added
by ants during previous iterations of the algorithm. In fact, while building a solution, each
ant collects information on the problem characteristics and on its own performance, and
uses this information to modify the representation of the problem, as seen locally by the
other ants. The representation of the problem is modied in such a way that information
contained in past good solutions can be exploited to build new better solutions. This form
of indirect communication mediated by the environment is called stigmergy, and is typical
of social insects (Grasse, 1959).
In AntNet, we retain the core ideas of the articial ant colony paradigm, and we apply
them to solve in an adaptive way the routing problem in datagram networks.
Informally, the AntNet algorithm and its main characteristics can be summarized as
follows.

 At regular intervals, and concurrently with the data trac, from each network node








mobile agents are asynchronously launched towards randomly selected destination
nodes.
Agents act concurrently and independently, and communicate in an indirect way,
through the information they read and write locally to the nodes.
Each agent searches for a minimum cost path joining its source and destination nodes.
Each agent moves step-by-step towards its destination node. At each intermediate
node a greedy stochastic policy is applied to choose the next node to move to. The
policy makes use of (i) local agent-generated and maintained information, (ii) local
problem-dependent heuristic information, and (iii) agent-private information.
While moving, the agents collect information about the time length, the congestion
status and the node identiers of the followed path.
Once they have arrived at the destination, the agents go back to their source nodes
by moving along the same path as before but in the opposite direction.
During this backward travel, local models of the network status and the local routing
table of each visited node are modied by the agents as a function of the path they
followed and of its goodness.
Once they have returned to their source node, the agents die.

In the following subsections the above scheme is explained, all its components are explicated and discussed, and a more detailed description of the algorithm is given.
324

AntNet: Distributed Stigmergetic Control for Communications Networks

4.1 Algorithm Description and Characteristics

AntNet is conveniently described in terms of two sets of homogeneous mobile agents (Stone
& Veloso, 1996), called in the following forward and backward ants. Agents5 in each set
possess the same structure, but they are dierently situated in the environment; that is,
they can sense dierent inputs and they can produce dierent, independent outputs. They
can be broadly classied as deliberative agents, because they behave reactively retrieving a
pre-compiled set of behaviors, and at the same time they maintain a complete internal state
description. Agents communicate in an indirect way, according to the stigmergy paradigm,
through the information they concurrently read and write in two data structures stored in
each network node k (see Figure 1):
Outgoing Links

Network Nodes

Routing Table
Network
Node

Local

P1 1

P1 2

........

P1 N

P2 1

P2 2

........

P2 N

PL 1

PL 2

........

PL N

Traffic
Statistics

Network Nodes
Stat (1)

Stat (2)

Stat(N)

Figure 1: Node structures used by mobile agents in AntNet for the case of a node with
L neighbors and a network with N nodes. The routing table is organized as in
vector-distance algorithms, but the entries are probabilistic values. The structure
containing statistics about the local trac plays the role of a local adaptive model
for the trac toward each possible destination.
i) A routing table Tk , organized as in vector-distance algorithms (see Appendix A),
but with probabilistic entries. Tk denes the probabilistic routing policy currently
adopted at node k: for each possible destination d and for each neighbor node n, Tk
stores a probability value Pnd expressing the goodness (desirability), under the current
network-wide routing policy, of choosing n as next node when the destination node
is d:
X
Pnd = 1; d 2 [1; N ]; Nk = fneighbors(k)g:
ii)

n2Nk
An array Mk (d ; d 2 ; Wd ), of data structures dening a simple parametric statistical

model for the trac distribution over the network as seen by the local node k. The
model is adaptive and described by sample means and variances computed over the
trip times experienced by the mobile agents, and by a moving observation window Wd
used to store the best value Wbestd of the agents' trip time.

5. In the following, we will use interchangeably the terms ant and agent.

325

Di Caro & Dorigo

For each destination d in the network, an estimated mean and variance, d and d 2 ,
give a representation of the expected time to go and of its stability. We used arithmetic, exponential and windowed strategies to compute the statistics. Changing strategy does not aect performance much, but we observed the best results using the
exponential model:6
d
d + (ok!d , d );
2
d
d 2 + ((ok!d , d )2 , d 2 );
(1)
where ok!d is the new observed agent's trip time from node k to destination d.7
The moving observation window Wd is used to compute the value Wbestd of the best
agents' trip time towards destination d as observed in the last w samples. After each
new sample, w is incremented modulus jWjmax , and jWjmax is the maximum allowed
size of the observation window. The value Wbestd represents a short-term memory
expressing a moving empirical lower bound of the estimate of the time to go to node
d from the current node.
T and M can be seen as memories local to nodes capturing dierent aspects of the
network dynamics. The model M maintains absolute distance/time estimates to all the
nodes, while the routing table gives relative probabilistic goodness measures for each linkdestination pair under the current routing policy implemented over all the network.
The AntNet algorithm is described as follows.
1. At regular intervals t from every network node s, a mobile agent (forward ant) Fs!d
is launched toward a destination node d to discover a feasible, low-cost path to that
node and to investigate the load status of the network. Forward ants share the same
queues as data packets, so that they experience the same trac loads. Destinations are
locally selected according to the data trac patterns generated by the local workload:
if fsd is a measure (in bits or in number of packets) of the data ow s ! d, then the
probability of creating at node s a forward ant with node d as destination is
f
pd = N sd :
X
fsd0

(2)

d0 =1

In this way, ants adapt their exploration activity to the varying data trac distribution.
2. While traveling toward their destination nodes, the agents keep memory of their paths
and of the trac conditions found. The identier of every visited node k and the time
elapsed since the launching time to arrive at this k-th node are pushed onto a memory
stack Ss!d (k).
6. This is the same model as used by the Jacobson/Karels algorithm to estimate retransmission timeouts
in the Internet TCP(Peterson & Davie, 1996).
7. The factor  weights the number of most recent samples that will really aect the average. The weight
of the ti -th sample used to estimate the value of d after j samplings, with j > i, is: (1 , )j,i . In
this way, for example, if  = 0:1, approximately only the latest 50 observations will really inuence the
estimate, for  = 0:05, the latest 100, and so on. Therefore, the number of eective observations is
 5(1=).

326

AntNet: Distributed Stigmergetic Control for Communications Networks

3. At each node k, each traveling agent headed towards its destination d selects the node
n to move to choosing among the neighbors it did not already visit, or over all the
neighbors in case all of them had been previously visited. The neighbor n is selected
0 computed as the normalized sum of the probabilistic
with a probability (goodness) Pnd
entry Pnd of the routing table with a heuristic correction factor ln taking into account
the state (the length) of the n-th link queue of the current node k:
0 =
Pnd

Pnd + ln
1 + (jNk j , 1) :

(3)

The heuristic correction ln is a [0,1] normalized value proportional to the length qn
(in bits waiting to be sent) of the queue of the link connecting the node k with its
neighbor n:
q
ln = 1 , jN jn :
k
X
qn0

(4)

n0 =1

The value of  weights the importance of the heuristic correction with respect to the
probability values stored in the routing table. ln reects the instantaneous state of the
node's queues, and assuming that the queue's consuming process is almost stationary
or slowly varying, ln gives a quantitative measure associated with the queue waiting
time. The routing tables values, on the other hand, are the outcome of a continual
learning process and capture both the current and the past status of the whole network
as seen by the local node. Correcting these values with the values of l allows the
system to be more \reactive", at the same time avoiding following all the network
uctuations. Agent's decisions are taken on the basis of a combination of a long-term
learning process and an instantaneous heuristic prediction.
In all the experiments we ran, we observed that the introduced correction is a very
eective mechanism. Depending on the characteristics of the problem, the best value
to assign to the weight  can vary, but if  ranges between 0.2 and 0.5, performance
doesn't change appreciably. For lower values, the eect of l is vanishing, while for
higher values the resulting routing tables oscillate and, in both cases, performance
degrades.
4. If a cycle is detected, that is, if an ant is forced to return to an already visited node,
the cycle's nodes are popped from the ant's stack and all the memory about them is
destroyed. If the cycle lasted longer than the lifetime of the ant before entering the
cycle, (that is, if the cycle is greater than half the ant's age) the ant is destroyed. In
fact, in this case the agent wasted a lot of time probably because of a wrong sequence
of decisions and not because of congestion states. Therefore, the agent is carrying an
old and misleading memory of the network state and it is counterproductive to use it
to update the routing tables (see below).
5. When the destination node d is reached, the agent Fs!d generates another agent
(backward ant) Bd!s , transfers to it all of its memory, and dies.
327

Di Caro & Dorigo

6. The backward ant takes the same path as that of its corresponding forward ant, but
in the opposite direction.8 At each node k along the path it pops its stack Ss!d(k) to
know the next hop node. Backward ants do not share the same link queues as data
packets; they use higher priority queues, because their task is to quickly propagate to
the routing tables the information accumulated by the forward ants.
7. Arriving at a node k coming from a neighbor node f , the backward ant updates the
two main data structures of the node, the local model of the trac Mk and the routing table Tk , for all the entries corresponding to the (forward ant) destination node
d. With some precautions, updates are performed also on the entries corresponding
to every node k0 2 Sk!d; k0 6= d on the \sub-paths" followed by ant Fs!d after visiting the current node k. In fact, if the elapsed trip time of a sub-path is statistically
\good" (i.e., it is less than  + I (; ), where I is an estimate of a condence interval
for ), then the time value is used to update the corresponding statistics and the
routing table. On the contrary, trip times of sub-paths not deemed good, in the same
statistical sense as dened above, are not used because they don't give a correct idea
of the time to go toward the sub-destination node. In fact, all the forward ant routing
decisions were made only as a function of the destination node. In this perspective,
sub-paths are side eects, and they are intrinsically sub-optimal because of the local
variations in the trac load (we can't reason with the same perspective as in dynamic
programming, because of the non-stationarity of the problem representation). Obviously, in case of a good sub-path we can use it: the ant discovered, at zero cost, an
additional good route. In the following two items the way M and T are updated is
described with respect to a generic \destination" node d0 2 Sk!d.
i) Mk is updated with the values stored in the stack memory Ss!d(k). The time
elapsed to arrive (for the forward ant) to the destination node d0 starting from
the current node is used to update the mean and variance estimates, d0 and d0 2 ,
and the best value over the observation window Wd0 . In this way, a parametric
model of the traveling time to destination d0 is maintained. The mean value of
this time and its dispersion can vary strongly, depending on the trac conditions:
a poor time (path) under low trac load can be a very good one under heavy
trac load. The statistical model has to be able to capture this variability
and to follow in a robust way the uctuations of the trac. This model plays a
critical role in the routing table updating process (see item (ii) below). Therefore,
we investigated several ways to build eective and computationally inexpensive
models, as described in the following Section 4.2.
ii) The routing table Tk is changed by incrementing the probability Pfd0 (i.e., the
probability of choosing neighbor f when destination is d0 ) and decrementing, by
normalization, the other probabilities Pnd0 . The amount of the variation in the
probabilities depends on a measure of goodness we associate with the trip time
Tk!d0 experienced by the forward ant, and is given below. This time represents
the only available explicit feedback signal to score paths. It gives a clear indication about the goodness r of the followed route because it is proportional to its
8. This assumption requires that all the links in the network are bi-directional. In modern networks this is
a reasonable assumption.

328

AntNet: Distributed Stigmergetic Control for Communications Networks

length from a physical point of view (number of hops, transmission capacity of the
used links, processing speed of the crossed nodes) and from a trac congestion
point of view (the forward ants share the same queues as data packets).
The time measure T , composed by all the sub-paths elapsed times, cannot be
associated with an exact error measure, given that we don't know the \optimal"
trip times, which depend on the whole network load status.9 Therefore, T can
only be used as a reinforcement signal. This gives rise to a credit assignment
problem typical of the reinforcement learning eld (Bertsekas & Tsitsiklis, 1996;
Kaelbling et al., 1996). We dene the reinforcement r  r(T; Mk ) to be a
function of the goodness of the observed trip time as estimated on the basis of
the local trac model. r is a dimensionless value, r 2 (0; 1], used by the current
node k as a positive reinforcement for the node f the backward ant Bd!s comes
from. r takes into account some average of the so far observed values and of
their dispersion to score the goodness of the trip time T , such that the smaller T
is, the higher r is (the exact denition of r is discussed in the next subsection).
The probability Pfd0 is increased by the reinforcement value as follows:
Pfd0

Pfd0 + r(1 , Pfd0 ):

(5)

In this way, the probability Pfd0 will be increased by a value proportional to the
reinforcement received and to the previous value of the node probability (that is,
given a same reinforcement, small probability values are increased proportionally
more than big probability values, favoring in this way a quick exploitation of new,
and good, discovered paths).
Probabilities Pnd0 for destination d0 of the other neighboring nodes n implicitly
receive a negative reinforcement by normalization. That is, their values are
reduced so that the sum of probabilities will still be 1:
Pnd0

Pnd0 , rPnd0 ; n 2 Nk ; n 6= f:

(6)

It is important to remark that every discovered path receives a positive reinforcement in its selection probability, and the reinforcement is (in general) a non-linear
function of the goodness of the path, as estimated using the associated trip time.
In this way, not only the (explicit) assigned value r plays a role, but also the
(implicit) ant's arrival rate. This strategy is based on trusting paths that receive
either high reinforcements, independent of their frequency, or low and frequent
reinforcements. In fact, for any trac load condition, a path receives one or more
high reinforcements only if it is much better than previously explored paths. On
the other hand, during a transient phase after a sudden increase in network load
all paths will likely have high traversing times with respect to those learned by
the model M in the preceding, low congestion, situation. Therefore, in this case
good paths can only be dierentiated by the frequency of ants' arrivals.
9. When the network is in a congested state, all the trip times will score poorly with respect to the times
observed in low load situations. Nevertheless, a path with a high trip time should be scored as a good
path if its trip time is signicantly lower than the other trip times observed in the same congested
situation.

329

Di Caro & Dorigo

Assigning always a positive, but low, reinforcement value in the case of paths
with high traversal time allows the implementation of the above mechanism based
on the frequency of the reinforcements, while, at the same time, avoids giving
excessive credit to paths with high traversal time due to their poor quality.
The use of probabilistic entries is very specic to AntNet and we observed it
to be eective, improving the performance, in some cases, even by 30%-40%.
Routing tables are used in a probabilistic way not only by the ants but also
by the data packets. This has been observed to improve AntNet performance,
which means that the way the routing tables are built in AntNet is well matched
with a probabilistic distribution of the data packets over all the good paths.
Data packets are prevented from choosing links with very low probability by remapping the T 's entries by means of a power function f (p) = p ;  > 1, which
emphasizes high probability values and reduces lower ones (in our experiments
we set  to 1.2).
Figure 2 gives a high-level description of the algorithm in pseudo-code, while Figure
3 illustrates a simple example of the algorithm behavior. A detailed discussion of the
characteristics of the algorithm is postponed to Section 8, after the performance of the
algorithm has been analyzed with respect to a set of competitor algorithms. In this way,
the characteristics of AntNet can be meaningfully evaluated and compared to those of other
state-of-the-art algorithms.

4.2 How to Score the Goodness of the Ant's Trip Time

The reinforcement r is a critical quantity that has to be assigned by considering three main
aspects: (i) paths should receive an increment in their selection probability proportional
to their goodness, (ii) the goodness is a relative measure, which depends on the trac
conditions, that can be estimated by means of the model M, and (iii) it is important not to
follow all the trac uctuations. This last aspect is particularly important. Uncontrolled
oscillations in the routing tables are one of the main problems in shortest paths routing
(Wang & Crowcroft, 1992). It is very important to be able to set the best trade-o between
stability and adaptivity.
We investigated several ways to assign the r values trying to take into account the above
three requirements:

 The simplest way is to set r = constant: independently of the ant's \experiment

outcomes", the discovered paths are all rewarded in the same way. In this simple but
meaningful case, what is at work is the implicit reinforcement mechanism due to the
dierentiation in the ant arrival rates. Ants traveling along faster paths will arrive
at a higher rate than other ants, hence their paths will receive a higher cumulative
reward.10 The obvious problem of this approach lies in the fact that, although ants
following longer paths arrive delayed, they will nevertheless have the same eect on
the routing tables as the ants who followed shorter paths.

10. In this case, the core of the algorithm is based on the capability of \real" ants to discover shortest paths
communicating by means of pheromone trails (Goss et al., 1989; Beckers et al., 1992).

330

AntNet: Distributed Stigmergetic Control for Communications Networks

t := Current time;
tend := Time length of the simulation;
t := Time interval between ants generation;
foreach (Node) =  Concurrent activity over the network  =
M = Local trac model;
T = Node routing table;
while ( t  tend )
in parallel =  Concurrent activity on each node  =
if ( t mod t = 0)
destination node := SelectDestinationNode(data trac distribution);
LaunchForwardAnt(destination node, source node);
end if
foreach (ActiveForwardAnt [source node, current
while (current node 6= destination node)

node, destination node])

next hop node := SelectLink(current node, destination node,T ; link queues);
PutAntOnLinkQueue(current node, next hop node);
WaitOnDataLinkQueue(current node, next hop node);
CrossTheLink(current node, next hop node);
PushOnTheStack(next hop node, elapsed time);
current node := next hop node;

end while

LaunchBackwardAnt(destination node, source node, stack data);
Die();

end foreach
foreach (ActiveBackwardAnt [source node, current
while (current node 6= destination node)

node, destination node])

next hop node := PopTheStack();
WaitOnHighPriorityLinkQueue(current node, next hop node);
CrossTheLink(current node, next hop node);
UpdateLocalTracModel(M, current node, source node, stack data);
reinforcement := GetReinforcement(current node, source node, stack data, M);
UpdateLocalRoutingTable(T , current node, source node, reinforcement);

end while
end foreach
end in parallel
end while
end foreach

Figure 2: AntNet's top-level description in pseudo-code. All the described actions take place
in a completely distributed and concurrent way over the network nodes (while, in
the text, AntNet has been described from an individual ant's perspective). All the
constructs at the same level of indentation inside the context of the statement
in parallel are executed concurrently. The processes of data generation and
forwarding are not described, but they can be thought as acting concurrently
with the ants.
331

Di Caro & Dorigo

Forward Ant (1

4)

1

2

3
(1

4
4) Backward Ant

Figure 3: Example of AntNet behavior. The forward ant, F1!4 , moves along the path
1 ! 2 ! 3 ! 4 and, arrived at node 4, launches the backward ant B4!1 that
will travel in the opposite direction. At each node k; k = 3; : : : ; 1, the backward
ant will use the stack contents S1!4 (k) to update the values for Mk (4 ; 4 2 ; W4 ),
and, in case of good sub-paths, to update also the values for Mk (i ; i 2 ; Wi ); i =
k + 1; : : : ; 3. At the same time the routing table will be updated by incrementing
the goodness Pj 4 , j = k + 1, of the last node k + 1 the ant B4!1 came from,
for the case of node i = k + 1; : : : ; 4 as destination node, and decrementing the
values of P for the other neighbors (here not shown). The increment will be a
function of the trip time experienced by the forward ant going from node k to
destination node i. As for M, the routing table is always updated for the case of
node 4 as destination, while the other nodes i0 = k + 1; : : : ; 3 on the sub-paths
are taken in consideration as destination nodes only if the trip time associated to
the corresponding sub-path of the forward ant is statistically good.
In the experiments we ran with this strategy, the algorithm showed moderately good
performance. These results suggest that the \implicit" component of the algorithm,
based on the ant arrival rate, plays a very important role. Of course, to compete with
state-of-the-art algorithms, the available information about path costs has to be used.
 More elaborate approaches dene r as a function of the ant's trip time T , and of the
parameters of the local statistical model M. We tested several alternatives, by using
dierent linear, quadratic and hyperbolic combinations of the T and M values. In
the following we limit the discussion to the functional form that gave the best results,
and that we used in the reported experiments:
r = c1

W

best

T







+ c2 (I , IIsup ),+Iinf
(T , Iinf ) :
sup inf

(7)

In Equation 7, Wbest is the best trip time experienced by the ants traveling toward
the destination d, over the last observation window W . The maximum size of the window
(the maximum number of considered samples before resetting the Wbest value) is assigned
on the basis of the coecient  of Equation 1. As we said,  weights the number of
samples eectively giving a contribution to the value of the  estimate, dening a sort of
moving exponential window. Following the expression for the number of eective samples
as reported in footnote 7, we set jWjmax = 5(c=), with c < 1. In this way, the longterm exponential mean and the short-term windowing are referring to a comparable set of
observations, with the short-term mean evaluated over a fraction c of the samples used for
332

AntNet: Distributed Stigmergetic Control for Communications Networks

the long-term one. Isup and Iinf are convenient estimates of the limits of
p an approximate
jWj), with z =
condence
interval
for

.
I
is
set
to
W
,
while
I
=

+
z
(
=
sup
inf
best
p
11
1= (1 ,  ) where  gives the selected condence level. There is some level of arbitrariness
in our computation of the condence interval, because we set it in an asymmetric way and
 and  are not arithmetic estimates. Anyway, what we need is a quick, raw estimate of the
mean value and of the dispersion of the values (for example, a local bootstrap procedure
could have been applied to extract a meaningful condence interval, but such a choice is
not reasonable from a CPU time-consuming perspective).
The rst term in Equation 7 simply evaluates the ratio between the current trip time and
the best trip time observed over the current observation window. This term is corrected
by the second one, that evaluates how far the value T is from Iinf in relation to the
extension of the condence interval, that is, considering the stability in the latest trip
times. The coecients c1 and c2 weight the importance of each term. The rst term is the
most important one, while the second term plays the role of a correction. In the current
implementation of the algorithm we set c1 = 0:7 and c2 = 0:3. We observed that c2 shouldn't
be too big (0.35 is an upper limit), otherwise performance starts to degrade appreciably.
The behavior of the algorithm is quite stable for c2 values in the range 0.15 to 0.35 but
setting c2 below 0.15 slightly degrades performance. The algorithm is very robust to changes
in  , which denes the condence level: varying the condence level in the range from 75%
to 95% changes performance little. The best results have been obtained for values around
75%80%. We observed that the algorithm is very robust to its internal parameter settings
and we didn't try to \adapt" the set of parameters to the problem instance. All the dierent
experiments were carried out with the same \reasonable" settings. We could surely improve
the performance by means of a ner tuning of the parameters, but we didn't because we
were interested in implementing a robust system, considering that the world of networks is
incredibly varied in terms of trac, topologies, switch and transmission characteristics, etc.
The value r obtained from Equation 7 is nally transformed by means of a squash
function s(x):

 a  !,1
;
s(x) = 1 + exp
xjN j
k

r

s(r)
:
s(1)

x 2 (0; 1]; a 2 R+ ;

(8)
(9)

Squashing the r values allows the system to be more sensitive in rewarding good (high)
values of r, while having the tendency to saturate the rewards for bad (near to zero) r
values: the scale is compressed for lower values and expanded in the upper part. In such a
way an emphasis is put on good results, while bad results play a minor role.
11. The expression is obtained by using the Tchebyche inequality that allows the denition of a condence
interval for a random variable following any distribution (Papoulis, 1991) Usually, for specic probability
densities the Tchebyche bound is too high, but here we can conveniently use it because (i) we want
to avoid to make assumptions on the distribution of  and, (ii) we need only a raw estimate of the
condence interval.

333

Di Caro & Dorigo

1

0.8
5 neighbors
4 neighbors
3 neighbors
2 neighbors

0.6
s(r)/s(1)

The coecient a=jNk j determines a
parametric dependence of the squashed
reinforcement value on the number
jNk j of neighbors of the reinforced node
k: the greater the number of neighbors,
the higher the reinforcement (see Figure 4). The reason to do this is that we
want to have a similar, strong, eect of
good results on the probabilistic routing tables, independent of the number
of neighbor nodes.

0.4

0.2

0
0

0.2

0.4

0.6

0.8

1

r

Figure 4: Examples of squash functions with a
variable number of node neighbors.

5. Routing Algorithms Used for Comparison

To evaluate the performance of AntNet, we compared it with state-of-the-art routing algorithms from the telecommunications and machine learning elds. The following algorithms,
belonging to the various possible combinations of static and adaptive, distance-vector and
link-state classes (see Appendix A), have been implemented and used to run comparisons.

OSPF (static, link state): is our implementation of the current Interior Gateway Pro-

tocol (IGP) of Internet (Moy, 1998). Being interested in studying routing under the
assumptions described in Section 3, the routing protocol we implemented does not
mirror the real OSPF protocol in all its details. It only retains the basic features of
OSPF. Link costs are statically assigned on the basis of their physical characteristics
and routing tables are set as the result of the shortest (minimum time) path computation for a sample data packet of size 512 bytes. It is worth remarking that this
choice penalizes our version of OSPF with respect to the real one. In fact, in the real
Internet link costs are set by network administrators who can use additional heuristic
and on-eld knowledge they have about trac workloads.

SPF (adaptive, link-state): is the prototype of link-state algorithms with dynamic met-

ric for link costs evaluations. A similar algorithm was implemented in the second
version of ARPANET (McQuillan, Richer, & Rosen, 1980) and in its successive revisions (Khanna & Zinky, 1989). Our implementation uses the same ooding algorithm,
while link costs are assigned over a discrete scale of 20 values by using the ARPANET
hop-normalized-delay metric12 (Khanna & Zinky, 1989) and the the statistical window average method described in (Shankar, Alaettinoglu, Dussa-Zieger, & Matta,
1992a). Link costs are computed as weighted averages between short and long-term
real-valued statistics reecting the delay (e.g., utilization, queueing and/or transmis-

12. The transmitting node monitors the average packet delay d (queuing and transmission) and the average
packet transmission time t over x observation windows. From these measures, assuming an M/M/1
queueing model (Bertsekas & Gallager, 1992), a link utilization cost measure is calculated as 1 , t=d.

334

AntNet: Distributed Stigmergetic Control for Communications Networks

sion delay, etc.) over xed time intervals. Obtained values are rescaled and saturated
by a linear function. We tried several additional discrete and real-valued metrics but
the discretized hop-normalized-delay gave the best results in terms of performance
and stability. Using a discretized scale reduces the sensitivity of the algorithm but at
the same time reduces also undesirable oscillations.

BF (adaptive, distance-vector): is an implementation of the asynchronous distributed
Bellman-Ford algorithm with dynamic metrics (Bertsekas & Gallager, 1992; Shankar
et al., 1992a). The algorithm has been implemented following the guidelines of Appendix A, while link costs are assigned in the same way as described for SPF above.
Vector-distance Bellman-Ford-like algorithms are today in use mainly for intra-domain
routing, because they are used in the Routing Information Protocol (RIP) (Malkin
& Steenstrup, 1995) supplied with the BSD version of Unix. Several enhanced versions of the basic adaptive Bellman-Ford algorithm can be found in the literature (for
example the Merlin-Segall (Merlin & Segall, 1979) and the Extended Bellman-Ford
(Cheng, Riley, Kumar, & Garcia-Luna-Aceves, 1989) algorithms). They focus mainly
on reducing the information dissemination time in case of link failures. When link
failures are not a major issue, as in this paper, their behavior is in general equivalent
to that of the basic adaptive Bellman-Ford.

Q-R (adaptive, distance-vector): is the Q-Routing algorithm as proposed by Boyan

and Littman (1994). This is an online asynchronous version of the Bellman-Ford
algorithm. Q-R learns online the values Qk (d; n), which are estimates of the time
to reach node d from node k via the neighbor node n. Upon sending a packet P
from k to neighbor node n with destination d, a back packet Pback is immediately
generated from n to k. Pback carries the information about the current time estimate
tn!d = minn0 2Nn Qn (d; n0 ) held at node n about the time to go for destination d, and
the sum tPk!n of the queuing and transmission time experienced by P since its arrival
at node k. The sum Qnew (d; n) = tn!d + tPk!n is used to compute the variation
Qk (d; n) = (Qnew (d; n) , Qk (d; n)) of the Q-learning-like value Qk (d; n).

PQ-R (adaptive, distance-vector): is the Predictive Q-Routing algorithm (Choi & Ye-

ung, 1996), an extension of Q-Routing. In Q-routing the best link (i.e., the one with
the lowest Qk (d; n)) is deterministically chosen by packets. Therefore, a link that
happens to have a high expected Qk (d; n), for example because of a temporary load
condition, will never be used again until all the other links exiting from the same node
have a worse, that is higher, Qk (d; n). PQ-R learns a model of the rate of variation of
links' queues, called the recovery rate, and uses it to probe those links that, although
not having the lowest Qk (d; n), have a high recovery rate.

Daemon (adaptive, optimal routing): is an approximation of an ideal algorithm. It

denes an empirical bound on the achievable performance. It gives some information about how much improvement is still possible. In the absence of any a priori
assumption on trac statistics, the empirical bound can be dened by an algorithm
possessing a \daemon" able to read in every instant the state of all the queues in the
network and then calculating instantaneous \real" costs for all the links and assigning
335

Di Caro & Dorigo

paths on the basis of a network-wide shortest paths re-calculation for every packet
hop. Links costs used in shortest paths calculations are the following:
S
S
S
Cl = dl + p + (1 , ) Q(l) +  Q(l) ;
b
b
b
l

l

l

where dl is the transmission delay for link l, bl is its bandwidth, Sp is the size (in
bits) of the data packet doing the hop, SQ(l) is the size (in bits) of the queue of link
l, SQ(l) is the exponential mean of the size of links queue and it is a correction to the
actual size of the link queue on the basis of what observed until that moment. This
correction is weighted by the  value set to 0.4. Of course, given the arbitrariness
we introduced in calculating Cl , it could be possible to dene an even better Daemon
algorithm.

6. Experimental Settings
The functioning of a communication network is governed by many components, which may
interact in nonlinear and unpredictable ways. Therefore, the choice of a meaningful testbed
to compare competing algorithms is no easy task.
A limited set of classes of tunable components is dened and for each class our choices
are explained.

6.1 Topology and physical properties of the net

Topology can be dened on the basis of a real net instance or it can dened by hand, to
better analyze the inuence of important topological features (like diameter, connectivity,
etc.).
Nodes are mainly characterized by their buering and processing capacity, whereas links
are characterized by their propagation delay, bandwidth and streams multiplexing scheme.
For both, fault probability distributions should be dened.
In our experiments, we used three signicant net instances with increasing numbers
of nodes. For all of them we describe the main characteristics and we summarize the
topological properties by means of a triple of numbers (, , N ) indicating respectively the
mean shortest path distance, in terms of hops, between all pairs of nodes, the variance of
this average, and the total number of nodes. From these three numbers we can get an idea
about the degree of connectivity and balancing of the network. The diculty of the routing
problem roughly increases with the value of these numbers.

 SimpleNet (1.9, 0.7, 8) is a small network specically designed to study some aspects

of the behavior of the algorithms we compare. Experiments with SimpleNet were
designed to closely study how the dierent algorithms manage to distribute the load
on the dierent possible paths. SimpleNet is composed of 8 nodes and 9 bi-directional
links with a bandwidth of 10 Mbit/s and propagation delay of 1 msec. The topology
is shown in Figure 5.
 NSFNET (2.2, 0.8, 14) is the old USA T1 backbone (1987). NSFNET is a WAN
composed of 14 nodes and 21 bi-directional links with a bandwidth of 1.5 Mbit/s. Its
336

AntNet: Distributed Stigmergetic Control for Communications Networks

2

1

4

3

8
5

6

7

Figure 5: SimpleNet. Numbers within circles are node identiers. Shaded nodes have a
special interpretation in our experiments, described later. Each edge in the graph
represents a pair of directed links. Link bandwidth is 10 Mbit/sec, propagation
delay is 1 msec.
topology is shown in Figure 6. Propagation delays range from 4 to 20 msec. NSFNET
is a well balanced network.

Figure 6: NSFNET. Each edge in the graph represents a pair of directed links. Link bandwidth is 1.5 Mbit/sec, propagation delays range from 4 to 20 msec.

 NTTnet (6.5, 3.8, 57) is the major Japanese backbone. NTTnet is the NTT (Nippon

Telephone and Telegraph company) ber-optic corporate backbone. NTTnet is a
57 nodes, 162 bi-directional links network. Link bandwidth is of 6 Mbit/sec, while
propagation delays range around 1 to 5 msec. The topology is shown in Figure 7.
NTTnet is not a well balanced network.

Figure 7: NTTnet. Each edge in the graph represents a pair of directed links. Link bandwidth is 6 Mbit/sec, propagation delays range from 1 to 5 msec.
337

Di Caro & Dorigo

All the networks are simulated with zero link-fault and node-fault probabilities, local
node buers of 1 Gbit capacity, and data packets maximum time to live (TTL) set to 15
sec.

6.2 Trac patterns

Trac is dened in terms of open sessions between pairs of dierent nodes. Trac patterns
can show a huge variety of forms, depending on the characteristics of each session and on
their distribution from geographical and temporal points of view.
Each single session is characterized by the number of transmitted packets, and by their
size and inter-arrival time distributions. More generally, priority, costs and requested quality
of service should be used to completely characterize a session.
Sessions over the network can be characterized by their inter-arrival time distribution
and by their geographical distribution. The latter is controlled by the probability assigned
to each node to be selected as a session start or end-point.
We considered three basic patterns for the temporal distribution of the sessions, and
three for their spatial distribution.
Temporal distributions:
 Poisson (P): for each node a Poisson process is dened which regulates the arrival of
new sessions, i.e., sessions inter-arrival times are negative exponentially distributed.
 Fixed (F): at the beginning of the simulation, for each node, a xed number of oneto-all sessions is set up and left constant for the remainder of the simulation.
 Temporary (TMPHS): a temporary, heavy load, trac condition is generated turning
on some nodes that act like hot spots (see below).
Spatial distributions:
 Uniform (U): the assigned temporal characteristics for session arrivals are set identically for all the network nodes.
 Random (R): in this case, the assigned temporal characteristics for session arrivals are
set in a random way over the network nodes.
 Hot Spots (HS): some nodes behave as hot spots, concentrating a high rate of input/output trac. A xed number of sessions are opened from the hot spots to all
the other nodes.
General trac patterns have been obtained combining the above temporal and spatial
characteristics. Therefore, for example, UP trac means that, for each node, an identical
Poisson process is regulating the arrival of new sessions, while in the RP case the process is
dierent for each node, and UP-HS means that a Hot Spots trac model is superimposed
to a UP trac.
Concerning the shape of the bit stream generated by each session, we consider two basic
types:
 Constant Bit Rate (CBR): the per-session bit rate is maintained xed. Examples of
applications of CBR streams are the voice signal in a telephone network, which is
converted into a stream of bits with a constant rate of 64 Kbit/sec, and the MPEG1
compression standard, which converts a video signal in a stream of 1.5 Mbit/sec.
338

AntNet: Distributed Stigmergetic Control for Communications Networks

 Generic Variable Bit Rate (GVBR): the per-session generated bit rate is time varying.

The term GVBR is a broad generalization of the VBR term normally used to designate
a bit stream with a variable bit rate but with known average characteristics and
expected/admitted uctuations.13 Here, a GVBR session generates packets whose
sizes and inter-arrival times are variable and follow a negative exponential distribution.
The information about these characteristics is never directly used by the routing
algorithms, like in IP-based networks.
The values we used in the experiments to shape trac patterns are \reasonable" values
for session generations and data packet production taking into consideration current network
usage and computing power. The mean of the packet size distribution has been set to 4096
bits in all the experiments. Basic temporal and spatial distributions have been chosen to
be representative of a wide class of possible situations that can be arbitrarily composed to
generate a meaningful subset of real trac patterns.

6.3 Metrics for performance evaluation

Depending on the type of services delivered on the network and on their associated costs,
many performance metrics could be dened. We focused on standard metrics for performance evaluation, considering only sessions with equal costs, benets and priority and
without the possibility of requests for special services like real-time. In this framework, the
measures we are interested in are: throughput (correctly delivered bits/sec), delay distribution for data packets (sec), and network capacity usage (for data and routing packets),
expressed as the sum of the used link capacities divided by the total available link capacity.

6.4 Routing algorithms parameters

All the algorithms used have a collection of parameters to be set. Common parameters
are routing packet size and elaboration time. Settings for these parameters are shown
in table 1. These parameters have been assigned to values used in previous simulation
Packet size (byte)
Packet elaboration time (msec)

AntNet OSPF & SPF
BF
Q-R & PQ-R
24 + 8Nh 64 + 8jNn j 24 + 12N
12
3
6
2
3

Table 1: Routing packets characteristics for the implemented algorithms (except for the
Daemon algorithm, which does not generate routing packets). Nh is the incremental number of hops made by the forward ant, jNn j is the number of neighbors of
node n, and N is the number of network nodes.
works (Alaettinoglu et al., 1992) and/or on the basis of heuristic evaluations taking into
13. The knowledge about the characteristics of the incoming CBR or VBR bit streams is of fundamental
importance in networks able to deliver Quality of Service. It is only on the basis of this knowledge that
the network can accept/refuse the session requests, and, in case of acceptance, allocate/reserve necessary
resources.

339

Di Caro & Dorigo

consideration information encoding schemes and currently available computing power (e.g.,
the size for forward ants has been determined as the same size of a BF packet plus 8 bytes for
each hop to store the information about the node address and the elapsed time). Concerning
the other main parameters, specic for each algorithm, for the AntNet competitors we used
the best settings we could nd in the literature and/or we tried to tune the parameters
as much as possible to obtain better results. For OSPF, SPF, and BF, the length of the
time interval between consecutive routing information broadcasts and the length of the time
window to average link costs are the same, and they are set to 0.8 or 3 seconds, depending on
the experiment for SPF and BF, and to 30 seconds for OSPF. Link costs inside each window
are assigned as the weighted sum between the arithmetic average over the window and the
exponential average with decay factor equal to 0.9. The obtained values are discretized
over a linear scale saturated between 1 and 20, with slope set to 20 and maximum admitted
variation equal to 1. For Q-R and PQ-R the transmission of routing information is totally
data-driven. The learning and adaptation rate we used were the same as used by the
algorithm's authors (Boyan & Littman, 1994; Choi & Yeung, 1996).
Concerning AntNet, we observed that the algorithm is very robust to internal parameters
tuning. We did not nely tune the parameter set, and we used the same set of values for all
the dierent experiments we ran. Most of the settings we used have been previously given
in the text at the moment the parameter was discussed and they are not reported in this
section. The ant generation interval at each node was set to 0.3 seconds. In Section 7.4
it will be shown the robustness of AntNet with respect to this parameter. Regarding the
parameters of the statistical model, the value of , weighting the number of the samples
considered in the model (Equation 1), has been set to 0.005, the c factor for the expression
of jWjmax (sect. 4.2) has been put equal to 0.3, and the condence level factor z (sect. 4.2)
equal to 1.70, meaning a condence level of approximately 0.95.

7. Results

Experiments reported in this section compare AntNet with the competing routing algorithms described in Section 5. We studied the performance of the algorithms for increasing
trac load, examining the evolution of the network status toward a saturation condition,
and for temporary saturation conditions.
 Under low load conditions, all algorithms tested have similar performance. In this
case, also considering the huge variability in the possible trac patterns, it is very
hard to assess whether an algorithm is signicantly better than another or not.
 Under high, near saturation, loads, all the tested algorithms are able to deliver the
oered throughput in a quite similar way, that is, in most of the cases all the generated trac is routed without big losses. On the contrary, the study of packet delay
distributions shows remarkable dierences among the dierent algorithms. To present
simulation results regarding packet delays we decided either to report the whole empirical distribution or to use the 90-th percentile statistic, which allows one to compare
the algorithms on the basis of the upper value of delay they were able to keep the 90%
of the correctly delivered packets. In fact, packet delays can be spread over a wide
range of values. This is an intrinsic characteristics of data networks: packet delays
can range from very low values for sessions open between adjacent nodes connected by
340

AntNet: Distributed Stigmergetic Control for Communications Networks

fast links, to much higher values in the case of sessions involving nodes very far apart
connected by many slow links. Because of this, very often the empirical distribution
of packet delays cannot be meaningfully parametrized in terms of mean and variance,
and the 90-th percentile statistic, or still better the whole empirical distribution, are
much more meaningful.
 Under saturation there are packet losses and/or packet delays that become too big,
cause all the network operations to slow down. Therefore, saturation has to be only
a temporary situation. If it is not, structural changes to the network characteristics,
like adding new and faster connection lines, rather than improvements of the routing
algorithm, should be in order. For these reasons, we studied the responsiveness of the
algorithms to trac loads causing only a temporary saturation.
All reported data are averaged over 10 trials lasting 1000 virtual seconds of simulation
time. One thousand seconds represents a time interval long enough to expire all transients
and to get enough statistical data to evaluate the behavior of the routing algorithm. Before
being fed with data trac, the algorithms are given 500 preliminary simulation seconds with
no data trac to build initial routing tables. In this way, each algorithm builds the routing
tables according to its own \vision" about minimum cost paths. Results for throughput
are reported as average values without an associated measure of variance. The inter-trial
variability is in fact always very low, a few percent of the average value.
Parameter values for trac characteristics are given in the Figure captions with the
following meaning (see also previous section): MSIA is the mean of the sessions inter-arrival
time distribution for the Poisson (P) case, MPIA stands for the mean of the packet interarrival time distribution. In the CBR case, MPIA indicates the xed packet production
rate. HS is the number of hot-spots nodes and MPIA-HS is the equivalent of MPIA for the
hot-spot sessions. In the following, when not otherwise explicitly stated, the shape of the
session bit streams is assumed to be of GVBR type.
Results for throughput and packet delays for all the considered network topologies are
described in the three following subsections. Results concerning the network resources
utilization are reported in Section 7.4.

7.1 SimpleNet

Experiments with SimpleNet were designed to study how the dierent algorithms manage
to distribute the load on the dierent possible paths. In these experiments, all the trac,
of F-CBR type, is directed from node 1 to node 6 (see Figure 5), and the trac load has
been set to a value higher than the capacity of a single link, so that it cannot be routed
eciently on a single path.
Results regarding throughput (Figure 8a) in this case strongly discriminate among the
algorithms. The type of the trac workload and the small number of nodes determined
signicant dierences in throughput. AntNet is the only algorithm able to deliver almost
all the generated data trac: its throughput after a short transient phase approaches very
closely the level of that delivered by the Daemon algorithm. PQ-R attains a steady value
approximately 15% inferior to that obtained by AntNet. The other algorithms behave very
poorly, stabilizing on values of about 30% inferior to those provided by AntNet. In this
341

Di Caro & Dorigo

case, it is rather clear that AntNet is the only algorithm able to exploit at best all the three
available paths (1-8-7-6, 1-3-5-6, 1-2-4-5-6) to distribute the data trac without inducing
counterproductive oscillations. The utilization of the routing tables in a probabilistic way
also by data packets in this case plays a fundamental role in achieving higher quality results. Results for throughput are conrmed by those for packet delays, reported in the
graph of Figure 8b. The dierences in the empirical distributions for packet delays reect
approximatively the same proportions as evidenced in the throughput case.
14.0

1.0

13.5

Throughput (106 bit/sec)

12.5
12.0

0.8
Empirical Distribution

OSPF
SPF
BF
Q-R
PQ-R
AntNet
Daemon

13.0

11.5
11.0
10.5

0.6

0.4

OSPF
SPF
BF
Q-R
PQ-R
AntNet
Daemon

0.2

10.0
9.5

0.0
0

100

200

300

400

500

600

700

800

900

1000

Simulation Time (sec)

0

0.05

0.1

0.15

0.2

Packet Delay (sec)

(a)

(b)

Figure 8: SimpleNet: Comparison of algorithms for F-CBR trac directed from node 1 to node 6
(MPIA = 0.0003 sec). (a) Throughput, and (b) packet delays empirical distribution.

7.2 NSFNET

We carried out a wide range of experiments on NSFNET using UP, RP, UP-HS and TMPHSUP trac patterns. In all the cases considered, dierences in throughput are of minor
importance with respect to those shown by packet delays. For each one of the UP, RP
and UP-HS cases we ran ve distinct groups of ten trial experiments, gradually increasing
the generated workload (in terms of reducing the session inter-arrival time). As explained
above, we studied the behavior of the algorithms when moving the trac load towards a
saturation region.
In the UP case, dierences in throughput (Figure 9a) are small: the best performing
algorithms are BF and SPF, which can attain performance of only about 10% inferior to
those of Daemon and of the same amount better than those of AntNet, Q-R and PQ-R,14
while OSPF behaves slightly better than these last ones. Concerning delays (Figure 9b) the
14. It is worth remarking that in these and in some of the experiments presented in the following, PQ-R's
performance is slightly worse than that of Q-R. This seems to be in contrast with the results presented
by the PQ-R's authors in the article where they introduced PQ-R (Choi & Yeung, 1996). We think that
this behavior is due to the fact that (i) their link recovery rate matches a discrete-time system while
in our simulator time is a continuous variable, and (ii) the experimental and simulation conditions are
rather dierent (in their article it is not specied the way they produced trac patterns and they did
not implement a realistic network simulator).

342

AntNet: Distributed Stigmergetic Control for Communications Networks

AntNet

2.4

OSPF

2.3

SPF

2.2

BF

2.1

Q-R

2

PQ-R

Daemon

4.5
4.0
3.5
3.0
2.5
2.0
1.5
1.0
0.5
0.0
AntNet

OSPF

2.4

SPF

2.3

(b)

2.2

BF

2.1

Q-R

2

PQ-R

Daemon

situation is rather dierent, as can be seen by the fact that all the algorithms but AntNet
have been able to produce a slightly higher throughput at the expenses of much worse
results for packet delays. This trend in packet delays was conrmed by all the experiments
we ran. OSPF, Q-R and PQ-R show really poor results (delays of order 2 or more seconds
are very high values, even if we are considering the 90-th percentile of the distribution),
while BF and SPF behave in a similar way with performance of order 50% worse than those
obtained by AntNet and of order 65% worse than Daemon.
18
16
14
12

8

10

6
4
2
0

(a)

90-th percentile of packet delays (sec)

343

In the RP case (Figure 10a), throughputs generated by AntNet, SPF and BF are very
similar, although AntNet has a slightly better performance. OSPF and PQ-R behave only
slightly worse while Q-R is the worst algorithm. Daemon is able to obtain only slightly
better results than AntNet. Again, looking at packet delays results (Figure 10b) OSPF,
Q-R and PQ-R perform very badly, while SPF shows results a bit better than those of BF
but of order 40% worse than those of AntNet. Daemon is in this case far better, which
indicates that the testbed was very dicult.
For the case of UP-HS load, throughputs (Figure 11a) for AntNet, SPF, BF, Q-R and
Daemon are very similar, while OSPF and PQ-R clearly show much worse results. Again
(Figure 11b), packet delays results for OSPF, Q-R and PQ-R are much worse than those
of the other algorithms (they are so much worse that they do not t in the scale chosen
to make clear dierences among the other algorithms). AntNet is still the best performing
algorithm. In this case, dierences with SPF are of order 20% and of 40% with respect to
BF. Daemon performs about 50% better than AntNet and scales much better than AntNet,
which, again, indicates the testbed was rather dicult.
The last graph for NSFNET shows how the algorithms behave in the case of a TMPHSUP situation (Figure 12). At time t = 400 four hot spots are turned on and superimposed
to the existing light UP trac. The transient is kept on for 120 seconds. In this case, only
one, typical, situation is reported in detail to show the answer curves. Reported values

Figure 9: NSFNET: Comparison of algorithms for increasing load for UP trac. The load is
increased reducing the MSIA value from 2.4 to 2 seconds (MPIA = 0.005 sec). (a)
Throughput, and (b) 90-th percentile of the packet delays empirical distribution.

Throughput (106 bit/sec)

12

10

8

6

4

2

0
AntNet

2.8

OSPF

2.7

SPF

(a)

2.6

BF

2.5

Q-R

2.4

Daemon

4.0
3.5
3.0
2.5
2.0
1.5
1.0
0.5
0.0
AntNet

Di Caro & Dorigo

PQ-R

90-th percentile of packet delays (sec)

18
16
14
12
10
8
6
4
2
0
AntNet

OSPF

2.4

SPF

2.3

BF

2.2

Q-R

2.1

PQ-R

2

(a)

Daemon

344

0.5

0.4

0.3

0.2

0.1

0.0
AntNet

OSPF

2.8

SPF

2.7

OSPF

2.4

SPF

2.3

BF

2.6

(b)

(b)

2.2

BF

2.5

Q-R

2.1

Q-R

2.4

2

PQ-R

PQ-R

Daemon

Daemon

are the \instantaneous" values for throughput and packet delays computed as the average
over 5 seconds moving windows. All algorithms have a similar very good performance as
far as throughput is concerned, except for OSPF and PQ-R, which lose a few percent of
the packets during the transitory period. The graph of packet delays conrms previous
results: SPF and BF have a similar behavior, about 20% worse than AntNet and 45%
worse than Daemon. The other three algorithms show a big out-of-scale jump, being not
able to properly dump the sudden load increase.

Figure 11: NSFNET: Comparison of algorithms for increasing load for UP-HS trac. The load is
increased reducing the MSIA value from 2.4 to 2.0 seconds (MPIA = 0.3 sec, HS = 4,
MPIA-HS = 0.04 sec). (a) Throughput, and (b) 90-th percentile of the packet delays
empirical distribution.

90-th percentile of packet delays (sec)

Figure 10: NSFNET: Comparison of algorithms for increasing load for RP trac. The load is
increased reducing the MSIA value from 2.8 to 2.4 seconds (MPIA = 0.005 sec). (a)
Throughput, and (b) 90-th percentile of the packet delays empirical distribution.

Throughput (106 bit/sec)
Throughput (106 bit/sec)

Throughput (106 bit/sec)

AntNet: Distributed Stigmergetic Control for Communications Networks

16.0
14.0
12.0
10.0
8.0
6.0

Packet Delay (sec)

0.06
OSPF
SPF
BF
Q-R
PQ-R
AntNet
Daemon

0.05

0.04

0.03
200

300

400

500

600

700

800

900

1000

Simulation Time (sec)

Figure 12: NSFNET: Comparison of algorithms for transient saturation conditions with
TMPHS-UP trac (MSIA = 3.0 sec, MPIA = 0.3 sec, HS = 4, MPIA-HS =
0.04). (a) Throughput, and (b) packet delays averaged over 5 seconds moving
windows.

7.3 NTTnet
The same set of experiments run on the NSFNET have been repeated on NTTnet. In this
case the results are even sharper than those obtained with NSFNET: AntNet performance
is much better that of all its competitors.
For the UP, RP and UP-HS cases, dierences in throughput are not signicant (Figures
13a, 14a and 15a). All the algorithms, with the OSPF exception, practically behave in
the same way as the Daemon algorithm. Concerning delays (Figures 13b, 14b and 15b),
dierences between AntNet and each of its competitors are of one order of magnitude.
AntNet keeps delays at low values, very close to those obtained by Daemon, while SPF,
BF, Q-R and PQ-R perform poorly and OSPF completely collapses.
In the UP and RP cases (Figures 13b and 14b) SPF and BF performs similarly, even if SPF
shows slightly better results, and about 50% better than Q-R and PQ-R.
In the UP-HS case, again, SPF and BF show similar results, while Q-R performs comparably but in a much more irregular way and PQ-R can keep delays about 30% lower. OSPF,
which is the worse algorithm in this case, shows an interesting behavior. The increase in the
generated data throughput determines a decrease or a very slow increase in the delivered
throughput while delays decrease (Figure 15a and 15b). In this case the load was too high
for the algorithm and the balance between the two, conicting, objectives, throughput and
345

45
40
35
30
25
20
15
10
5
0
AntNet

3.1

OSPF

3

SPF

BF

2.9

(a)

2.8

Q-R

2.7

Daemon

0.0

1.0

2.0

3.0

4.0

5.0

6.0

7.0

8.0

9.0

10.0

Di Caro & Dorigo

PQ-R

90-th percentile of packet delays (sec)

45
40
35
30
25
20
15
10
5
0
AntNet

OSPF

3.1

SPF

3

BF

2.9

(a)

2.8

Q-R

2.7

PQ-R

Daemon

346

10.0
9.0
8.0
7.0
6.0
5.0
4.0
3.0
2.0
1.0
0.0

AntNet

AntNet

OSPF

3.1

SPF

3

2.9

(b)

OSPF

3.1

SPF

3

2.9

(b)

BF

BF

2.8

2.8

Q-R

Q-R

2.7

2.7

PQ-R

PQ-R

Daemon

Daemon

packet delays, showed an inverse dynamics: having a lot of packet losses made it possible
for the surviving packets to obtain lower trip delays.
The TMPHS-UP experiment (Figure 16), concerning sudden load variation, conrms
the previous results. OSPF is not able to follow properly the variation both for throughput
and delays. All the other algorithms are able to follow the sudden increase in the oered
throughput, but only AntNet (and Daemon) show a very regular behavior. Dierences in
packet delays are striking. AntNet performance is very close to those obtained by Daemon
(the curves are practically superimposed at the scale used in the Figure). Among the other
algorithms, SPF and BF are the best ones, although their response is rather irregular and,
in any case, much worse than AntNet's. OSPF and Q-R are out-of-scale and show a very
delayed recovering curve. PQ-R, after a huge jump, which takes the graph out-of-scale in

Figure 14: NTTnet: Comparison of algorithms for increasing load for RP trac. The load is
increased reducing the MSIA value from 3.1 to 2.7 seconds (MPIA = 0.005 sec). (a)
Throughput, and (b) 90-th percentile of the packet delays empirical distribution.

90-th percentile of packet delays (sec)

Figure 13: NTTnet: Comparison of algorithms for increasing load for UP trac. The load is
increased reducing the MSIA value from 3.1 to 2.7 seconds (MPIA = 0.005 sec). (a)
Throughput, and (b) 90-th percentile of the packet delays empirical distribution.

Throughput (106 bit/sec)
Throughput (106 bit/sec)

AntNet: Distributed Stigmergetic Control for Communications Networks

4

3.9

3.8

3.7

90-th percentile of packet delays (sec)

4.1
50

Throughput (106 bit/sec)

45
40
35
30
25
20
15
10
5
0
AntNet

OSPF

SPF

BF

Q-R

PQ-R

Daemon

4.1

4

3.9

3.8

3.7

7.0
6.0
5.0
4.0
3.0
2.0
1.0
0.0
AntNet

OSPF

(a)

SPF

BF

Q-R

PQ-R

Daemon

(b)

Figure 15: NTTnet: Comparison of algorithms for increasing load for UP-HS trac. The load is

increased reducing the MSIA value from 4.1 to 3.7 seconds (MPIA = 0.3 sec, HS = 4,
MPIA-HS = 0.05 sec). (a) Throughput, and (b) 90-th percentile of the packet delays
empirical distribution.

Throughput (106 bit/sec)

the rst 40 seconds after hot spots are turned on, shows a trend approaching those of BF
and SPF.
55.0
45.0
35.0
25.0
15.0

Packet Delay (sec)

0.8
OSPF
SPF
BF
Q-R
PQ-R
AntNet
Daemon

0.6
0.4
0.2
0.0
200

300

400

500

600

700

800

900

1000

Simulation Time (sec)

Figure 16: NTTnet: Comparison of algorithms for transient saturation conditions with
TMPHS-UP trac (MSIA = 4.0 sec, MPIA = 0.3 sec, HS = 4, MPIA-HS =
0.05). (a) Throughput, and (b) packet delays averaged over 5 seconds moving
windows.
347

Di Caro & Dorigo

7.4 Routing Overhead

Table 2 reports results concerning the overhead generated by routing packets. For each
algorithm the network load generated by the routing packets is reported as the ratio between
the bandwidth occupied by the routing packets and the total available network bandwidth.
Each row in the table refers to a previously discussed experiment (Figs. 8 to 11 and 13
to 15). Routing overhead is computed for the experiment with the heaviest load in the
increasing load series.
SimpleNet - F-CBR
NSFNET - UP
NSFNET - RP
NSFNET - UP-HS
NTTnet - UP
NTTnet - RP
NTTnet - UP-HS

AntNet OSPF SPF BF Q-R PQ-R
0.33
0.01 0.10 0.07 1.49 2.01
2.39
0.15 0.86 1.17 6.96 9.93
2.60
0.15 1.07 1.17 5.26 7.74
1.63
0.15 1.14 1.17 7.66 8.46
2.85
0.14 3.68 1.39 3.72 6.77
4.41
0.14 3.02 1.18 3.36 6.37
3.81
0.14 4.56 1.39 3.09 4.81

Table 2: Routing Overhead: ratio between the bandwidth occupied by the routing packets
and the total available network bandwidth. All data are scaled by a factor of 10,3 .
All data are scaled by a factor of 10,3 . The data in the table show that the routing
overhead is negligible for all the algorithms with respect to the available bandwidth. Among
the adaptive algorithms, BF shows the lowest overhead, closely followed by SPF. AntNet
generates a slightly bigger consumption of network resources, but this is widely compensated
by the much higher performance it provides. Q-R and PQ-R produce an overhead a bit
higher than that of AntNet. The routing load caused by the dierent algorithms is a function
of many factors, specic of each algorithm. Q-R and PQ-R are data-driven algorithms: if
the number of data packets and/or the length of the followed paths (because of topology
or bad routing) grows, so will the number of generated routing packets. BF, SPF and
OSPF have a more predictable behavior: the generated overhead is mainly function of the
topological properties of the network and of the generation rate of the routing information
packets. AntNet produces a routing overhead depending on the ants generation rate and
on the length of the paths they travel.
The ant trac can be roughly characterized as a collection of additional trac sources,
one for each network node, producing very small packets (and related acknowledgement
packets) at constant bit rate with destinations matching the oered data trac. On average
ants will travel over rather \short" paths and their size will grow of only 8 bytes at each hop.
Therefore, each \ant routing trac source" represents a very light additional trac source
with respect to network resources when the ant launching rate is not excessively high. In
Figure 17, the sensitivity of AntNet with respect to the ant launching rate is reported.
For a sample case of a UP data trac model on NSFNET (previously studied in Figure
9) the interval g between two consecutive ant generations is progressively decreased (g
is the same for all nodes). g values are sampled at constant intervals over a logarithmic
scale ranging from about 0.006 to 25 seconds. The lower, dashed, curve interpolates the
348

AntNet: Distributed Stigmergetic Control for Communications Networks

AntNet Normalized Power Vs. Routing Overhead

1.0

0.8
Normalized Power
Routing Overhead
0.6

0.4

0.2

0.0
0.001

0.01

0.1

1

10

100

Interval ∆g Between Two Consecutive Ants Generations (sec)

Figure 17: AntNet normalized power vs. routing overhead. Power is dened as the ratio
between delivered throughput and packet delay.
generated routing overhead expressed, as before, as the fraction of the available network
bandwidth used by routing packets. The upper, solid, curve plots the data for the obtained
power normalized to its highest value, where the power is dened as the ratio between the
delivered throughput and the packet delay. The value used for delivered throughput is the
throughput value at time 1000 averaged over ten trials, while for packet delay we used the
90-th percentile of the empirical distribution.
In the gure, we can see how an excessively small g causes an excessive growth of the
routing overhead, with consequent reduction of the algorithm power. Similarly, when g
is too big, the power slowly diminishes and tends toward a plateau because the number of
ants is not enough to generate and maintain up-to-date statistics of the network status. In
the middle of these two extreme regions a wide range of g intervals gives raise to similar,
very good power values, while, at the same time, the routing overhead quickly falls down
toward negligible values. This gure strongly conrms our previous assertion about the
robustness of AntNet's internal parameter settings.

8. Discussion
In AntNet, the continual on-line construction of the routing tables is the emergent result
of a collective learning process. In fact, each forward-backward agent pair is complex
enough to nd a good route and to adapt the routing tables for a single source-destination
path, but it cannot solve the global routing optimization problem. It is the interaction
between the agents that determines the emergence of a global eective behavior from the
network performance point of view. Ants cooperate in their problem-solving activity by
communicating in an indirect and non-coordinated way. Each agent acts independently.
Good routes are discovered by applying a policy that is a function of the information
349

Di Caro & Dorigo

accessed through the network nodes visited, and the information collected about the route
is eventually released on the same nodes. Therefore, the inter-agent communication is
mediated in an explicit and implicit way by the \environment", that is, by the node's data
structures and by the trac patterns recursively generated by the data packets' utilization
of the routing tables. This communication paradigm, called stigmergy, matches well the
intrinsically distributed nature of the routing problem. Cooperation among agents goes
on at two levels: (a) by modications of the routing tables, and (b) by modications of
local models that determine the way the ants' performance is evaluated. Modications of
the routing tables directly aect the routing decisions of following ants towards the same
destination, as well as the routing of data, which, in turn, inuences the rate of arrival
of other ants towards any destination. It is interesting to remark that the used stigmergy
paradigm makes the AntNet's mobile agents very exible from a software engineering point
of view. In this perspective, once the interface with the node's data structure is dened,
the internal policy of the agents can be transparently updated. Also, the agents could be
exploited to carry out multiple concurrent tasks (e.g., collecting information for distributed
network management using an SNMP-like protocol or for Web data-mining tasks).
As shown in the previous section, the results we obtained with the above stigmergetic
model of computation are excellent. In terms of throughput and average delay, AntNet
performs better than both classical and recently proposed routing algorithms on a wide
range of experimental conditions. Although this is very interesting per se, in the following
we try to justify AntNet superior performance by highlighting some of its characteristics
and by comparing them with those of the competing algorithms. We focus on the following
main aspects:

 AntNet can be seen as a particular instance of a parallel Monte Carlo simulation






system with biased exploration. All the other algorithms either do not explore the
net or their exploration is local and tightly connected to the ux of data packets.
The information AntNet maintains at each node is more complete and organized in a
less critical way than that managed by the other algorithms.
AntNet does not propagate local estimates to other nodes, while all its competitors
do. This mechanism makes the algorithm more robust to locally wrong estimates.
AntNet uses probabilistic routing tables, which have the triple positive eect of better redistributing data trac on alternative routes, of providing ants with a built-in
exploration mechanism and of allowing the exploitation of the ants' arrival rate to
assign cumulative reinforcements.
It was experimentally observed that AntNet is much more robust than its competitors
to the frequency with which routing tables are updated.
The structure of AntNet allows one to draw some parallels with some well-known
reinforcement learning (RL) algorithms. The characteristics of the routing problem,
that can be seen as a distributed time-varying RL problem (see sect. 2.2), determines
a departure of AntNet from the structure of classical RL algorithms.

These aspects of AntNet are discussed in more detail in the following.
350

AntNet: Distributed Stigmergetic Control for Communications Networks

8.1 AntNet as an on-line Monte Carlo system with biased exploration
The AntNet routing system can be seen as a collection of mobile agents collecting data
about the network status by concurrently performing on-line Monte Carlo simulations (Rubistein, 1981; Streltsov & Vakili, 1996). In Monte Carlo methods, repeated experiments
with stochastic transition components are run to collect data about the statistics of interest. Similarly, in AntNet ants explore the network by performing random experiments
(i.e., building paths from source to destination nodes using a stochastic policy dependent
on the past and current network states), and collect on-line information on the network
status. A built-in variance reduction eect is determined (i) by the way ants' destinations
are assigned, biased by the most frequently observed data's destinations, and (ii) by the way
the ants' policy makes use of current and past trac information (that is, inspection of the
local queues' status and probabilistic routing tables). In this way, the explored paths match
the most interesting paths from a data trac point of view, which results in a very ecient
variance reduction eect in the stochastic sampling of the paths. Dierently from usual
o-line Monte Carlo systems, in AntNet the state space sampling is performed on-line, that
is, the sampling of the statistics and the controlling of the non-stationary trac process are
performed concurrently.
This way of exploring the network concurrently with data trac is very dierent from
what happens in the other algorithms where, either there is no exploration at all (OSPF,
SPF and BF), or exploration is both tightly coupled to data trac and of a local nature
(Q-R and PQ-R). Conveniently, as was shown in Section 7.4, the extra trac generated by
exploring ants is negligible for a wide range of values, allowing very good performance.

8.2 Information management at each network node
Key characteristics of routing algorithms are the type of information used to build/update
routing tables and the way this information is propagated. All the algorithms (except the
static OSPF) make use at each node of two main components: a local model M of some
cost measures and a routing table T . SPF and BF use M to estimate smoothed averages
of the local link costs, that is, of the distances to the neighbor nodes. In this case, M is
a local model maintaining estimates of only local components. In Q-R the local model is
ctitious because the raw transition time is directly used as a value to update T . PQ-R
uses a slightly more sophisticated model with respect to Q-R, storing also a measure of the
link utilization. All these algorithms propagate part of their local information to the other
nodes, which, in turn, make use of it to update their routing tables and to build a global
view of the network. In SPF and BF the content of each T is updated, at regular intervals,
by a \memoryless strategy": the new entries do not depend on the old values, that are
discarded. Therefore, the whole adaptive component of the routing system is represented
by the model M. Otherwise, in Q-R and PQ-R the adaptive content of M is almost
negligible and the adaptive component of the algorithm is represented by the smoothed
average carried out by the Q-learning-like rule. AntNet shows characteristics rather dierent
from its competitors: its model M contains a memory-based local perspective of the global
status of the network. The content of M allow the reinforcements to be weighted on the
basis of a rich statistical description of the network dynamics as seen by the local node.
These reinforcements are used to update the routing table, the other adaptive component
351

Di Caro & Dorigo

maintained at the node. The T updates are carried out in an asynchronous way and as a
function of their previous values. Moreover, while T is used in a straightforward probabilistic
way by the data packets, traveling ants select the next node by using both T , that is, an
adaptive representation of the past policy, and a model of the current local link queues,
that is, an instantaneous representation of the node status. It is evident that AntNet builds
and uses more information than its competitors: two dierent memory-based components
and an instantaneous predictor are used and combined at dierent levels. Moreover, in this
way AntNet robustly redistributes among these completely local components the criticality
of all the estimates and decisions.

8.3 AntNet's robustness to wrong estimates

As remarked above, AntNet, dierently from its competitors, does not propagate local
estimates to other nodes. Each node routing table is updated independently, by using
local information and the ants' experienced trip time. Moreover, (i) each ant experiment
aects only one entry in the routing table of the visited nodes, the one relative to the ant's
destination, and, (ii) the local information is built from the \global" information collected
by traveling ants, implicitly reducing in this way the variance in the estimates. These
characteristics make AntNet particularly robust to wrong estimates. On the contrary, in
all the other algorithms a locally wrong estimate will be propagated to all other nodes and
will be used to compute estimates to many dierent destinations. How bad this is for the
algorithm performance depends on how long the wrong estimate eect lasts. In particular,
this will be a function of the time window over which estimates are computed for SPF and
BF, and of the learning parameters for Q-R and PQ-R.

8.4 AntNet's probabilistic use of routing tables to route data packets

All the tested algorithms but AntNet use deterministic routing tables.15 In these algorithms,
entries in the routing tables contain distance/time estimates to the destinations. These
estimates can provide misleading information if the algorithm is not fast enough to follow
the trac uctuations, as can be the case under heavy load conditions. Instead, AntNet
routing tables have probabilistic entries that, although reecting the goodness of a particular
path choice with respect to the others available, do not force the data packets to choose
the perceived best path. This has the positive eect of allowing a better balancing of
the trac load on dierent paths, with a resulting better utilization of the resources (as
was shown in particular in the experiments with the SimpleNet). As remarked at the
end of Section 4.1, the intrinsic probabilistic structure of the routing tables and the way
they are updated allow AntNet to exploit the ant's arrival rate as a way to assign implicit
(cumulative) reinforcements to discovered paths. It is not obvious how the same eect
could be obtained by using routing tables containing distance/time estimates and using
this estimates in a probabilistic way. In fact, in this case each new trip time sample would
15. Singh, Jaakkola, and Jordan (1994) showed that stochastic policies can yield higher performance than
deterministic policies in the case of an incomplete access to the state information of the environment. In
(Jaakkola, Singh, & Jordan, 1995), the same authors developed a Monte-Carlo-based stochastic policy
evaluation algorithm, conrming the usefulness of the Monte-Carlo approach, used in AntNet too, to
deal with incomplete information problems.

352

AntNet: Distributed Stigmergetic Control for Communications Networks

modify the statistical estimate that would simply oscillate around its expected value without
inducing an arrival-dependent cumulative eect.
Probabilistic routing tables provide some remarkable additional benets: (a) they give to
the ants a built-in exploration method in discovering new, possibly better, paths, and (b)
since ants and data routing are independent in AntNet, the exploration of new routes
can continue while, at the same time, data packets can exploit previously learned, reliable
information. It is interesting to note that the use of probabilistic routing tables whose entries
are learned in an adaptive way by changing on positive feedback and ignoring negative
feedback, is reminiscent of older automata approaches to routing in telecommunications
networks. In these approaches, a learning automaton is usually placed on each network
node. An automaton is dened by a set of possible actions and a vector of associated
probabilities, a continuous set of inputs and a learning algorithm to learn input-output
associations. Automata are connected in a feedback conguration with the environment
(the whole network), and a set of penalty signals from the environment to the actions is
dened. Routing choices and modications to the learning strategy are carried out in a
probabilistic way and according to the network conditions (see for example (Nedzelnitsky
& Narendra, 1987; Narendra & Thathachar, 1980)). The main dierence lies in the fact
that in AntNet the ants are part of the environment itself, and they actively direct the
learning process towards the most interesting regions of the search space. That is, the
whole environment plays a key, active role in learning good state-action pairs.

8.5 AntNet robustness to routing table update frequency

In BF and SPF the broadcast frequency of routing information plays a critical role, particularly so for BF, which has only a local representation of the network status. This frequency
is unfortunately problem dependent, and there is no easy way to make it adaptive, while,
at the same time, avoiding large oscillations. In Q-R and PQ-R, routing tables updating
is data driven: only those Q-values belonging to pairs (i; j ) of neighbor nodes visited by
packets are updated. Although this is a reasonable strategy given that the exploration of
new routes could cause undesired delays to data packets, it causes delays in discovering new
good routes, and is a great handicap in a domain where good routes could change all the
time. In OSPF, in which routing tables are not updated, we set static link costs on the
basis of their physical characteristics. This lack of an adaptive metric is the main reason
of the poor performance of OSPF (as remarked in Section 5, we slightly penalized OSPF
with respect to its real implementations, where additional heuristic knowledge about trac
patterns is used by network administrators to set link costs). In AntNet, we experimentally
observed the robustness to changes in the ants' generation rate: for a wide range of generation rates, rather independent of the network size, the algorithm performance is very good
and the routing overhead is negligible (see Section 7.4).

8.6 AntNet and reinforcement learning

The characteristics of the routing problem allow one to interpret it as a distributed, stochastic time-varying RL problem. This fact, as well as the structure of AntNet, make it natural
to draw some parallels between AntNet and classical RL approaches. It is worth remarking
that those RL problems that have been most studied, and for which algorithms have been de353

Di Caro & Dorigo

veloped, are problems where, unlike routing, assumptions like Markovianity or stationarity
of the process considered are satised. The characteristics of the adaptive routing problem
make it very dicult and not well suited to be solved with usual RL algorithms. This fact,
as we explain below, determines a departure of AntNet from classical RL algorithms.
A rst way to relate the structure of AntNet to that of a (general) RL algorithm is
connected to the way the outcomes of the experiments, the trip times Tk!d , are processed.
The transformation from the raw values Tk!d to the more rened reinforcements r are
reminiscent of what happens in Actor-Critic systems (Barto, Sutton, & Anderson, 1983):
the raw reinforcement signal is processed by a critic module, which is learning a model (the
node's component M) of the underlying process, and then is fed to the learning system (the
routing table T ) transformed into an evaluation of the policy followed by the ants. In our
case, the critic is both adaptive, to take into account the variability of the trac process,
and rather simple, to meet computational requirements.
Another way of seeing AntNet as a classical RL system is related to its interpretation as
a parallel replicated Monte Carlo (MC) system. As was shown by Singh and Sutton (1996),
a rst-visit MC (only the rst visit to a state is used to estimate its value during a trial)
simulation system is equivalent to a batch temporal dierence (TD) method with replacing
traces and decay parameter =1. Although AntNet is a rst-visit MC simulation system,
there are some important dierences with the type of MC used by Singh and Sutton (and
in other RL works), mainly due to the dierences in the considered class of problems. In
AntNet, outcomes of experiments are both used to update local models able to capture
the variability of the whole network status (only partially observable) and to generate a
sequence of stochastic policies. On the contrary, in the MC system considered by Singh and
Sutton, outcomes of the experiments are used to compute (reduced) maximum-likelihood
estimates of the expected mean and variance of the states' returns (i.e., the total reward
following a visit of a state) of a Markov chain. In spite of these dierences, the weak parallel
with TD() methods is rather interesting, and allows to highlight an important dierence
between AntNet and its competitors (and general TD methods): in AntNet, following the
generation of a stochastic transition chain by the forward ant, there is no back-chaining
of the information from one state (i.e., a triple fcurrent node, destination node, next hop
nodeg) to its predecessors. Each state is rewarded only on the basis of the ant's trip time
information strictly relevant to it. This approach is completely dierent from that followed
by (TD methods) Q-R, PQ-R, BF and, in a dierent perspective, by SPF. In fact, these
algorithms build the distance estimates at each node by using the predictions made at other
nodes. In particular, Q-R and PQ-R, which propagate the estimation information only one
step back, are precisely distributed versions of the TD(0) class of algorithms. They could be
transformed into generic TD(), 0 <   1, by transmitting backward to all the previously
visited nodes the information collected by the routing packet generated after each data hop.
Of course, this would greatly increase the routing trac generated, because it has to be
done after each hop of each data packet, making the approach at least very costly, if feasible
at all.
In general, using temporal dierences methods in the context of routing presents an important problem: the key condition of the method, the self-consistency between the estimates
of successive states16 may not be strictly satised in the general case. This is due to the
16. For instance, the prediction made at node k about the time to-go to the destination node d should be

354

AntNet: Distributed Stigmergetic Control for Communications Networks

fact that (i) the dynamics at each node are related in a highly non-linear way to the dynamics of all its neighbors, (ii) the trac process evolves concurrently over all the nodes,
and (iii) there is a recursive interaction between the trac patterns and the control actions
(that is, the modications of the routing tables). This aspect can explain in part the poor
performance of the pure TD(0) algorithms Q-R and PQ-R.

9. Related Work
Algorithms based on the ant colony metaphor were inspired by the ant colony foraging
behavior (Beckers et al., 1992). These were rst proposed by Dorigo (1992), Colorni et
al. (1991) and Dorigo et al. (1991, 1996) and were applied to the traveling salesman
problem (TSP). Apart from the natural metaphor, the idea behind that rst application
was similar to the one presented in this paper: a set of agents that repeatedly run Monte
Carlo experiments whose outcomes are used to change the estimates of some variables used
by subsequent ants to build solutions. In ant-cycle, one of the rst ant-based algorithms,
a value called \pheromone trail" is associated to each edge of the graph representing the
TSP. Each ant builds a tour by exploiting the pheromone trail information as follows.
When in node i an ant chooses the next node j to move to among those not visited yet
with a probability Pij that is a function of the amount of pheromone trail on the edge
connecting i to j (as well as of a local heuristic function; the interested reader can nd a
detailed description of ant-cycle elsewhere (Dorigo, 1992; Dorigo et al., 1996)). The value
of the pheromone trails is updated once all ants have built their tours. Each ant adds
to all visited edges a quantity of pheromone trail proportional to the quality of the tour
generated (the shorter the tour, the higher the quantity of pheromone trail added). This
has an eect very similar to AntNet's increase of routing tables probabilities, since a higher
pheromone trail on a particular edge will increase its probability of being chosen in the
future. There are obviously many dierences between ant-cycle and AntNet, mostly due
to the very dierent types of problems to which they have been applied, a combinatorial
optimization problem versus a distributed, stochastic, time varying, real-time problem.
Though the majority of previous applications of ant colony inspired algorithms concern combinatorial optimization problems, there have been recent applications to routing.
Schoonderwoerd et al. (1996, 1997) were the rst to consider routing as a possible application domain for ant colony algorithms. Their ant-based control (ABC) approach, which is
applied to routing in telephone networks, diers from AntNet in many respects. The main
dierences are a direct consequence of the dierent network model they considered, which
has the following characteristics (see Figure 18): (i) connection links potentially carry an
innite number of full-duplex, xed bandwidth channels, and (ii) transmission nodes are
crossbar switches with limited connectivity (that is, there is no necessity for queue management in the nodes). In such a model, bottlenecks are put on the nodes, and the congestion
degree of a network can be expressed in terms of connections still available at each switch.
As a result, the network is cost-symmetric: the congestion status over available paths is
completely bi-directional. The path n0 ; n1 ; n2 ; : : : ; nk connecting n0 and nk will exhibit the
additively related to the prediction for the same destination from each one of k's neighbors, being each
neighbor one of the ways to go to d.

355

Di Caro & Dorigo

same level of congestion in both directions because the congestion depends only on the state
of the nodes in the path. Moreover, dealing with telephone networks, each call occupies
exactly one physical channel across the path.
Therefore, \calls" are not multiplexed over the
Link 1
links, but they can be accepted or refused, depending on the possibility of reserving a physical
N bidirectional channels
circuit connecting the caller and the receiver. All
Link 2
of these modeling assumptions make the probLink 4
lem of Schoonderwoerd et al. very dierent from
the cost-asymmetric routing problem for data
networks we presented in this paper. This difn << N possible connections
ference is reected in many algorithmic dierences between ABC and AntNet, the most imFigure 18: Network node in the portant of which is that in ABC ants update
telecommunications network pheromone trails after each step, without waiting
model of Schoonderwoerd et for the completion of an experiment as done in
AntNet. This choice, which is reminiscent of the
al. (1996).
pheromone trail updating strategy implemented
in ant-density, another of the rst ant colony based algorithms (Dorigo et al., 1991; Dorigo,
1992; Colorni et al., 1991), makes ABC behavior closer to real ants', and was made possible
by the cost-symmetry assumption made by the authors.
Other dierences are that ABC does not use local models to score the ants trip times,
nor local heuristic information and ant-private memory to improve the ants decision policies.
Also, it does not recover from cycles and does not use the information contained in all the
ant sub-paths.
Because of the dierent network model used and of the many implementation details
tightly bound to the network model, it was impossible for us to re-implement and compare
the ABC algorithm with AntNet.
Subramanian, Druschel, and Chen (1997) have proposed an ant-based algorithm for
packet-switched nets. Their algorithm is a straightforward extension of Schoonderwoerd
et al. system by adding so-called uniform ants, an additional exploration mechanism that
should avoid a rapid sub-optimal convergence of the algorithm. A limitation of Subramanian
et al. work is that, although the algorithm they propose is based on the same cost-symmetry
hypothesis as ABC, they apply it to packet-switched networks where this requirement is
very often not met.
Link 3

10. Conclusions and Future Work
In this paper, we have introduced AntNet, a novel distributed approach to routing in packetswitched communications networks. We compared AntNet with 6 state-of-the-art routing
algorithms on a variety of realistic testbeds. AntNet showed superior performance and
robustness to internal parameter settings for almost all the experiments. AntNet's most
innovative aspect is the use of stigmergetic communication to coordinate the actions of a
set of agents that cooperate to build adaptive routing tables. Although this is not the
rst application of stigmergy-related concepts to optimization problems (e.g., Dorigo et al.,
356

AntNet: Distributed Stigmergetic Control for Communications Networks

1991; Dorigo, 1992; Dorigo et al., 1996; Bonabeau, Dorigo, & Theraulaz, 1999), the application presented here is unique in many respects. First, in AntNet, stigmergy-based control
is coupled to a model-building activity: information collected by ants is used not only to
modify routing tables, but also to build local models of the network status to be used to
better direct the routing table modications. Second, this is the rst attempt to evaluate
stigmergy-based control on a realistic simulator of communications networks: the used simulator retains many of the basic components of a real routing system. An interesting step
forward, in the direction of testing the applicability of the idea presented to real networks,
would be to rerun the experiments presented here using a complete Internet simulator.
Third, this is also the rst attempt to evaluate stigmergy-based control by comparing a
stigmergetic algorithm to state-of-the-art algorithms on a realistic set of benchmark problems. It is very promising that AntNet turned out to be the best performing in all the
tested conditions.
There are obviously a number of directions in which the current work could be extended,
which are listed below.
1) A rst, natural, extension of the current work would consider the inclusion in the
simulator of ow and congestion control components (with re-transmissions and error management). This inclusion will require a paired tuning of the routing and ow-congestion
components, to select the best matching between their dynamics.
2) In AntNet, each forward ant makes a random experiment: it builds a path from a
source node s to a destination node d. The path is built exploiting the information contained
in the probabilistic routing tables and the status of the queues of the visited nodes. While
building the path, the ant collects information on the status of the network. This is done
by sharing link queues with data packets, and by measuring waiting times of queues and
traversal times that will be used as raw reinforcements by backward ants. Since forward
ants share queues with data packets, the time required to run an experiment depends on
the network load, and is approximately the same as the time Ts!d required for a packet to
go from the same source node s to the same destination node d. This delays the moment
the information collected by forward ants can be distributed by backward ants, and makes
it less up-to-date than it could be. A possible improvement in this schema would be to
add a model of link-queue depletion to nodes, and to let forward ants use high priority
queues to reach their destinations without storing crossing times (for a rst step in this
direction see Di Caro & Dorigo, 1998). Backward ants would then make the same path, in
the opposite direction, as forward ants, but use the queue local models they nd on their
way to estimate local \virtual" queueing and crossing times. Raw reinforcements, used to
update the routing tables, are then computed using these estimates. Clearly, here there is a
trade-o between delayed but real information and more recent but estimated information.
It will be interesting to see which scheme works better, although we are condent that the
local queue models should allow the backward ants to build estimates accurate enough to
make the improved system more eective than the current AntNet, at a cost of a little
increase in computational complexity at the nodes.
3) As we discussed in Section 8, AntNet is missing one of the main components of classical
RL/TD algorithms: there is no back-chaining of information from a state to previous ones,
each node policy is learned by using a complete local perspective. An obvious extension
of our work would therefore be to study versions of AntNet closer to TD() algorithms.
357

Di Caro & Dorigo

In this case each node should maintain Q-values expressing the estimate of the distance
to each destination via each neighbor. These estimates should be updated by using both
the ant trip time outcome and the estimates coming from successive nodes (closer to the
destination node) that could be also carried by the backward ant.
4) In this paper we applied AntNet to routing in datagram communications networks. It
is reasonable to think that AntNet could be easily adapted to be used for the generation of
real-time car route guidance in Dynamic Trac Assignment (DTA) systems (see for example
Yang, 1997). DTA systems exploit currently available and emerging computer, communication, and vehicle sensing technologies to monitor, manage and control the transportation
system (the attention is now focused mainly on highway systems) and to provide various
levels of information and advice to system users so that they can make timely and informed
travel decisions. Therefore, adaptive routing of vehicle trac presents very similar features
to the routing of data packets in communications networks. Moreover, vehicle trac control
systems have the interesting property of a very simplied \transport" layer. In fact, many
activities that interfere with routing and that are implemented in the transport layer of
communications networks do not exist, or exist only to a limited extent, in vehicles trac
control algorithms. For example, typical transport layer activities like data acknowledgement and retransmission cannot be implemented with real vehicles. Other activities, like
ow control, have strong constraints (e.g., people would not be happy to be forbidden to
leave their oces for, say, one hour on the grounds that there are already too many cars on
the streets!). This makes AntNet still more interesting since it can express its full potential
as a routing algorithm.
5) In AntNet, whenever an ant uses a link its desirability (probability) is incremented.
Although this strategy, which nds its roots in the ant colony biological metaphor that
inspired our work, allowed us to obtain excellent results, it would be interesting to investigate
the use of negative reinforcements, even if it can potentially lead to stability problems, as
observed by people working on older automata systems. As discussed before, AntNet diers
from automata systems because of the active role played by the ants. Therefore, the use
of negative reinforcements could show itself to be eective, for example, in reducing the
probability of choosing a given link if the ant that used it performed very badly.

Acknowledgements
This work was supported by a Madame Curie Fellowship awarded to Gianni Di Caro (CECTMR Contract N. ERBFMBICT 961153). Marco Dorigo is a Research Associate with the
FNRS. We gratefully acknowledge the help received from Tony Bagnall, Nick Bradshaw and
George Smith, who proofread and commented an earlier draft of this paper, as well as the
many useful comments provided by the three anonymous referees and by Craig Boutilier,
the associate editor who managed the review process.

Appendix A. Optimal and Shortest Path Routing
In this appendix, the characteristics of the two most used routing paradigms, optimal and
shortest path routing (introduced in Section 2.1) are summarized:
358

AntNet: Distributed Stigmergetic Control for Communications Networks

A.1 Optimal routing
Optimal routing (Bertsekas & Gallager, 1992) has a network-wide perspective and its objective is to optimize a function of all individual link ows.
Optimal routing models are also called ow models because they try to optimize the total
mean ow on the network. They can be characterized as multicommodity ow problems,
where the commodities are the trac ows between the sources and the destinations, and
the cost to be optimized is a function of the ows, subject to the constraints of ow conservation at each node and positive ow on every link. It is worth observing that the ow
conservation constraint can be explicitly stated only if the trac arrival rate is known.
The routing policy consists of splitting any source-target trac pair at strategic points,
then shifting trac gradually among alternative routes. This often results in the use of
multiple paths for a same trac ow between an origin-destination pair.
Implicit in optimal routing is the assumption that the main statistical characteristics of the
trac are known and not time-varying. Therefore, optimal routing can be used for static
and centralized/decentralized routing. It is evident that this kind of solution suers all the
problems of static routers.

A.2 Shortest path routing
Shortest path routing (Wang & Crowcroft, 1992) has a source-destination pair perspective.
As opposed to optimal routing, there is no global cost function to be optimized. Instead,
the route between each node pair is considered by itself and no a priori knowledge about
the trac process is required (although of course such knowledge could be fruitfully used).
If costs are assigned in a dynamic way, based on statistical measures of the link congestion
state, a strong feedback eect is introduced between the routing policies and the trac
patterns. This can lead to undesirable oscillations, as has been theoretically predicted and
observed in practice (Bertsekas & Gallager, 1992; Wang & Crowcroft, 1992). Some very
popular cost metrics take into account queuing and transmission delays, link usage, link
capacity and various combination of these measures. The way costs are updated usually
involves attempting to reduce big variations considering both long-term and short-term
statistics of link congestion states (Khanna & Zinky, 1989; Shankar, Alaettinoglu, DussaZieger, & Matta, 1992b).
On the other hand, if the costs are static, they will reect both some measure of the
expected/wished trac load over the links and their transmission capacity. Of course,
serious loss of eciency could arise in case of non-stationary conditions or when the a priori
assumptions about the trac patterns are strongly violated in practice.
Considering the dierent content stored in each routing table, shortest path algorithms can
be further subdivided in two classes called distance-vector and link-state (Steenstrup, 1995;
Shankar et al., 1992b). The common behavior of most shortest path algorithms can be
depicted as follows.
1. Each node assigns a cost to each of its outgoing links. This cost can be static or
dynamic. In the latter case, it is updated in presence of a link failure or on the basis
of some observed link-trac statistics averaged over a dened time-window.
359

Di Caro & Dorigo

2. Periodically and without a required inter-node synchronization, each node sends to all
of its neighbors a packet of information describing its current estimates about some
quantities (link costs, distance from all the other nodes, etc.).
3. Each node, upon receiving the information packet, updates its local routing table and
executes some class-specic actions.
4. Routing decisions can be made in a deterministic way, choosing the best path indicated
by the information stored in the routing table, or adopting a more exible strategy
which uses all the information stored in the table to choose some randomized or
alternative path.
In the following, the main features specic to each class are described.

A.2.1 Distance-vector
Distance-vector algorithms make use of routing tables consisting of a set of triples of the
form (Destination, Estimated Distance, Next Hop), dened for all the destinations in the
network and for all the neighbor nodes of the considered switch.17 In this case, the required
topological information is represented by the list of the reachable nodes identiers. The
average per node memory occupation is of order O(Nn), where N is the number of nodes in
the network and n is the average connectivity degree (i.e., the average number of neighbor
nodes considered over all the nodes).
The algorithm works in an iterative, asynchronous and distributed way. The information
that every node sends to its neighbors is the list of its last estimates of the distances from
itself to all the other nodes in the network. After receiving this information from a neighbor
node j , the receiving node i updates its table of distance estimates overwriting the entry
corresponding to node j with the received values.
Routing decisions at node i are made choosing as next hop node the one satisfying the
relationship:
arg min fdij + Dj g
j 2N
i

where dij is the assigned cost to the link connecting node i with its neighbor j and Dj is
the estimated shortest distance from node j to the destination.
It can be shown that this process converges in nite time to the shortest paths with
respect to the used metric if no link cost changes after a given time (Bertsekas & Gallager,
1992).
The above briey described algorithm is known in literature as distributed
Bellman-Ford (Bellman, 1958; Ford & Fulkerson, 1962; Bertsekas & Gallager, 1992) and it
is based on the principles of dynamic programming (Bellman, 1957; Bertsekas, 1995). It
is the prototype and the ancestor of a wider class of distance-vector algorithms (Malkin
& Steenstrup, 1995) developed with the aim of reducing the risk of circular loops and of
accelerating the convergence in case of rapid changes in link costs.
17. In some cases, only the best estimates are kept at nodes. Therefore, the above triples are dened for all
the destinations only.

360

AntNet: Distributed Stigmergetic Control for Communications Networks

A.2.2 Link-state

Link-state algorithms make use of routing tables containing much more information than
that used in vector-distance algorithms. In fact, at the core of link-state algorithms there is a
distributed and replicated database. This database is essentially a dynamic map of the whole
network, describing the details of all its components and their current interconnections.
Using this database as input, each node calculates its best paths using an appropriate
algorithm like Dijkstra's (1959) algorithm (a wide variety of alternative ecient algorithms
are available, as described for example in Cherkassky, Goldberg, & Radzik, 1994). The
memory requirements for each node in this case are O(N 2 ).
In the most common form of link-state algorithm, each node acts autonomously, broadcasting information about its link costs and states and computing shortest paths from itself
to all the destinations on the basis of its local link costs estimates and of the estimates
received from other nodes. Each routing information packet is broadcast to all the neighbor
nodes that in turn send the packet to their neighbors and so on. A distributed ooding
mechanism (Bertsekas & Gallager, 1992) supervises this information transmission trying to
minimize the number of re-transmissions.
As in the case of vector-distance, the described algorithm is a general template and a
variety of dierent versions have been implemented to make the algorithm behavior more
robust and ecient (Moy, 1998).

References

Alaettinoglu, C., Shankar, A. U., Dussa-Zieger, K., & Matta, I. (1992). Design and implementation of MaRS: A routing testbed. Tech. rep. UMIACS-TR-92-103, CS-TR-2964,
Institute for Advanced Computer Studies and Department of Computer Science, University of Maryland, College Park (MD).
Barto, A. G., Sutton, R. S., & Anderson, C. W. (1983). Neuronlike adaptive elements that
can solve dicult learning control problems. IEEE Transaction on Systems, Man and
Cybernetics, SMC-13, 834{846.
Beckers, R., Deneubourg, J. L., & Goss, S. (1992). Trails and U-turns in the selection of the
shortest path by the ant Lasius Niger. Journal of Theoretical Biology, 159, 397{415.
Bellman, R. (1957). Dynamic Programming. Princeton University Press.
Bellman, R. (1958). On a routing problem. Quarterly of Applied Mathematics, 16 (1), 87{90.
Bertsekas, D. (1995). Dynamic Programming and Optimal Control. Athena Scientic.
Bertsekas, D., & Gallager, R. (1992). Data Networks. Prentice-Hall.
Bertsekas, D., & Tsitsiklis, J. (1996). Neuro-Dynamic Programming. Athena Scientic.
Bolding, K., Fulgham, M. L., & Snyder, L. (1994). The case for chaotic adaptive routing.
Tech. rep. CSE-94-02-04, Department of Computer Science, University of Washington,
Seattle.
361

Di Caro & Dorigo

Bonabeau, E., Dorigo, M., & Theraulaz, G. (1999). From Natural to Articial Swarm
Intelligence. Oxford University Press.
Boyan, J., & Littman, M. (1994). Packet routing in dinamically changing networks: A reinforcement learning approach. In Advances in Neural Information Processing Systems
6 (NIPS6), pp. 671{678. San Francisco, CA:Morgan Kaufmann.
Brakmo, L. S., O'Malley, S. W., & Peterson, L. L. (1994). TCP vegas: New techniques for
congestion detection and avoidance. ACM Computer Communication Review (SIGCOMM'94), 24 (4).
Cheng, C., Riley, R., Kumar, S. P. R., & Garcia-Luna-Aceves, J. J. (1989). A loop-free
extended bellman-ford routing protocol without bouncing eect. ACM Computer
Communication Review (SIGCOMM '89), 18 (4), 224{236.
Cherkassky, B. V., Goldberg, A. V., & Radzik, T. (1994). Shortest paths algorithms: Theory
and experimental evaluation. In Sleator, D. D. (Ed.), Proceedings of the 5th Annual
ACM-SIAM Symposium on Discrete Algorithms (SODA 94), pp. 516{525 Arlington,
VA. ACM Press.
Choi, S., & Yeung, D.-Y. (1996). Predictive Q-routing: A memory-based reinforcement
learning approach to adaptive trac control. In Advances in Neural Information
Processing Systems 8 (NIPS8), pp. 945{951. MIT Press.
Colorni, A., Dorigo, M., & Maniezzo, V. (1991). Distributed optimization by ant colonies.
In Proceedings of the European Conference on Articial Life (ECAL 91), pp. 134{142.
Elsevier.
Costa, D., & Hertz, A. (1997). Ants can colour graphs. Journal of the Operational Research
Society, 48, 295{305.
Crawley, E., Nair, R., Rajagopalan, B., & Sandick, H. (1996). A framework for QoS-based
routing in the internet. Internet Draft (expired in September, 1997) draft-ietf-qosrframework-00, Internet Engineering Task Force (IEFT).
Danzig, P. B., Liu, Z., & Yan, L. (1994). An evaluation of TCP Vegas by live emulation.
Tech. rep. UCS-CS-94-588, Computer Science Department, University of Southern
California, Los Angeles.
Di Caro, G., & Dorigo, M. (1998). Two ant colony algorithms for best-eort routing
in datagram networks. In Proceedings of the Tenth IASTED International Conference on Parallel and Distributed Computing and Systems (PDCS'98), pp. 541{546.
IASTED/ACTA Press.
Dijkstra, E. W. (1959). A note on two problems in connection with graphs. Numer. Math.,
1, 269{271.
Dorigo, M. (1992). Optimization, Learning and Natural Algorithms (in Italian). Ph.D.
thesis, Dipartimento di Elettronica e Informazione, Politecnico di Milano, IT.
362

AntNet: Distributed Stigmergetic Control for Communications Networks

Dorigo, M., Di Caro, G., & Gambardella, L. M. (1998). Ant algorithms for distributed
discrete optimization. Tech. rep. 98-10, IRIDIA, Universite Libre de Bruxelles. Submitted to Articial Life.
Dorigo, M., & Gambardella, L. M. (1997). Ant colony system: A cooperative learning
approach to the traveling salesman problem. IEEE Transactions on Evolutionary
Computation, 1 (1), 53{66.
Dorigo, M., Maniezzo, V., & Colorni, A. (1991). Positive feedback as a search strategy.
Tech. rep. 91-016, Dipartimento di Elettronica, Politecnico di Milano, IT.
Dorigo, M., Maniezzo, V., & Colorni, A. (1996). The ant system: Optimization by a colony
of cooperating agents. IEEE Transactions on Systems, Man, and Cybernetics{Part
B, 26 (1), 29{41.
Ford, L., & Fulkerson, D. (1962). Flows in Networks. Prentice-Hall.
Goss, S., Aron, S., Deneubourg, J. L., & Pasteels, J. M. (1989). Self-organized shortcuts in
the Argentine ant. Naturwissenschaften, 76, 579{581.
Grasse, P. P. (1959). La reconstruction du nid et les coordinations interindividuelles
chez bellicositermes natalensis et cubitermes sp. La theorie de la stigmergie: essai
d'interpretation du comportement des termites constructeurs. Insectes Sociaux, 6,
41{81.
Gray, R., Kotz, D., Nog, S., Rus, D., & Cybenko, G. (1997). Mobile agents: The next
generation in distributed computing. In Proceedings of the Second Aizu International
Symposium on Parallel Algorithms/Architectures Synthesis (pAs '97), pp. 8{24. IEEE
Computer Society Press.
Jaakkola, T., Singh, S. P., & Jordan, M. I. (1995). Reinforcement learning algorithm for
partially observable Markov decision problems. In Advances in Neural Information
Processing Systems 7, pp. 345{352. MIT Press.
Kaelbling, L. P., Littman, M. L., & Moore, A. W. (1996). Reinforcement learning: A survey.
Journal of Articial Intelligence Research, 4, 237{285.
Khanna, A., & Zinky, J. (1989). The revised ARPANET routing metric. ACM SIGCOMM
Computer Communication Review, 19 (4), 45{56.
Malkin, G. S., & Steenstrup, M. E. (1995). Distance-vector routing. In Steenstrup, M. E.
(Ed.), Routing in Communications Networks, chap. 3, pp. 83{98. Prentice-Hall.
McCallum, A. K. (1995). Reinforcement learning with selective perception and hidden state.
Ph.D. thesis, Department of Computer Science, University of Rochester, Rochester
(NY).
McQuillan, J. M., Richer, I., & Rosen, E. C. (1980). The new routing algorithm for the
ARPANET. IEEE Transactions on Communications, 28, 711{719.
363

Di Caro & Dorigo

Merlin, P., & Segall, A. (1979). A failsafe distributed routing protocol. IEEE Transactions
on Communications, COM-27 (9), 1280{1287.
Moy, J. T. (1998). OSPF Anatomy of an Internet Routing Protocol. Addison-Wesley.
Narendra, K. S., & Thathachar, M. A. (1980). On the behavior of a learning automaton in a changing environment with application to telephone trac routing. IEEE
Transactions on Systems, Man, and Cybernetics, SMC-10 (5), 262{269.
Nedzelnitsky, O. V., & Narendra, K. S. (1987). Nonstationary models of learning automata
routing in data communication networks. IEEE Transactions on Systems, Man, and
Cybernetics, SMC-17, 1004{1015.
Papoulis, A. (1991). Probability, Random Variables and Stochastic Process (Third edition).
McGraw-Hill.
Peterson, L. L., & Davie, B. (1996). Computer Networks: A System Approach. Morgan
Kaufmann.
Rubistein, R. Y. (1981). Simulation and the Monte Carlo Method. John Wiley & Sons.
Sandick, H., & Crawley, E. (1997). QoS routing (qosr) working group report. Internet
Draft, Internet Engineering Task Force (IEFT).
Schoonderwoerd, R., Holland, O., & Bruten, J. (1997). Ant-like agents for load balancing
in telecommunications networks. In Proceedings of the First International Conference
on Autonomous Agents, pp. 209{216. ACM Press.
Schoonderwoerd, R., Holland, O., Bruten, J., & Rothkrantz, L. (1996). Ant-based load
balancing in telecommunications networks. Adaptive Behavior, 5 (2), 169{207.
Shankar, A. U., Alaettinoglu, C., Dussa-Zieger, K., & Matta, I. (1992a). Performance
comparison of routing protocols under dynamic and static le transfer connections.
ACM Computer Communication Review, 22 (5), 39{52.
Shankar, A. U., Alaettinoglu, C., Dussa-Zieger, K., & Matta, I. (1992b). Transient and
steady-state performance of routing protocols: Distance-vector versus link-state. Tech.
rep. UMIACS-TR-92-87, CS-TR-2940, Institute for Advanced Computer Studies and
Department of Computer Science, University of Maryland, College Park (MD).
Singh, S. P., & Sutton, R. S. (1996). Reinforcement learning with replacing eligibility traces.
Machine Learning, 22, 123{158.
Singh, S. P., Jaakkola, T., & Jordan, M. I. (1994). Learning without state estimation
in partially observable Markovian decision processes. In Proceedings of the Eleventh
Machine Learning Conference, pp. 284{292. New Brunswick, NJ: Morgan Kaufmann.
Steenstrup, M. E. (Ed.). (1995). Routing in Communications Networks. Prentice-Hall.
Stone, P., & Veloso, M. M. (1996). Multiagent systems: A survey from a machine learning
persective. Tech. rep. CMU-CS-97-193, Carnegie Mellon University, Pittsburgh, PA.
364

AntNet: Distributed Stigmergetic Control for Communications Networks

Streltsov, S., & Vakili, P. (1996). Variance reduction algorithms for parallel replicated
simulation of uniformized Markov chains. Discrete Event Dynamic Systems: Theory
and Applications, 6, 159{180.
Subramanian, D., Druschel, P., & Chen, J. (1997). Ants and reinforcement learning: A
case study in routing in dynamic networks. In Proceedings of IJCAI-97, International
Joint Conference on Articial Intelligence, pp. 832{838. Morgan Kaufmann.
The ATM Forum (1996). Private Network-Network Interface Specication: Version 1.0.
Walrand, J., & Varaiya, P. (1996). High-performance Communication Networks. Morgan
Kaufmann.
Wang, Z., & Crowcroft, J. (1992). Analysis of shortest-path routing algorithms in a dynamic
network environment. ACM Computer Communication Review, 22 (2).
Yang, Q. (1997). A Simulation Laboratory for Evaluation of Dynamic Trac Management Systems. Ph.D. thesis, Department of Civil and Environmental Engineering,
Massachusetts Institute of Technology (MIT).

365

Journal of Articial Intelligence Research 9 (1998) 99{137

Submitted 10/97; published 9/98

Computational Aspects of Reordering Plans
Christer Backstrom

Department of Computer and Information Science
Linkopings universitet, S-581 83 Linkoping, Sweden

cba@ida.liu.se

Abstract

This article studies the problem of modifying the action ordering of a plan in order
to optimise the plan according to various criteria. One of these criteria is to make a plan
less constrained and the other is to minimize its parallel execution time. Three candidate
denitions are proposed for the rst of these criteria, constituting a sequence of increasing
optimality guarantees. Two of these are based on deordering plans, which means that ordering relations may only be removed, not added, while the third one uses reordering, where
arbitrary modications to the ordering are allowed. It is shown that only the weakest one
of the three criteria is tractable to achieve, the other two being NP-hard and even dicult
to approximate. Similarly, optimising the parallel execution time of a plan is studied both
for deordering and reordering of plans. In the general case, both of these computations are
NP-hard. However, it is shown that optimal deorderings can be computed in polynomial
time for a class of planning languages based on the notions of producers, consumers and
threats, which includes most of the commonly used planning languages. Computing optimal reorderings can potentially lead to even faster parallel executions, but this problem
remains NP-hard and dicult to approximate even under quite severe restrictions.

1. Introduction
In many applications where plans, made by man or by computer, are executed, it is important to nd plans that are optimal with respect to some cost measure, typically execution
time. Examples of such applications are manufacturing and error-recovery for industrial
processes, production planning, logistics and robotics. Many dierent kinds of computations can be made to improve the cost of a plan|only a few of which have been extensively
studied in the literature. The most well-known and frequently used of these is scheduling. A plan tells which actions (or tasks) to do and in which order to do them, while a
schedule assigns exact release times to these actions. The schedule must obey the action
order prescribed by the plan and must often also satisfy further metric constraints such as
deadlines and earliest release times for certain actions. A schedule is feasible if it satises all
such metric constraints. It is usually interesting to nd a schedule that is optimal in some
respect, eg the feasible schedule having the shortest total execution time, or the schedule
missing the deadlines for as few actions as possible.
In principle, planning and scheduling follow in sequence such that scheduling can be
viewed as a post-processing step to planning|where planning is concerned with causal
relations and qualitative temporal relations between actions, while scheduling is concerned
with metric constraints on actions. In some planning systems, eg O-Plan (Currie & Tate,
1991) and Sipe (Wilkins, 1988), both planning and scheduling are integrated into one
single system. Similarly, temporal planners, eg Deviser (Vere, 1983) and IxTeT (Ghallab
& Laruelle, 1994), can often reason also about metric constraints. This does not make it
c 1998 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

Backstro m

irrelevant to study planning and scheduling as separate problems, though, as can be seen
from the vast literature on both topics. The two problems are of quite dierent character
and studying them separately gives important insight also into such integrated systems as
was just discussed. For instance, Drabble1 says that it is often very dicult to see when
O-Plan plans and when it schedules; it is easy to see that O-Plan works, but it is dicult
to see why.
A further complication in understanding the dierence between planning and scheduling,
both for integrated systems and for systems with separated planning and scheduling, is
that certain types of computations fall into a grey zone between planning and scheduling.
Planners are good at reasoning about eects of actions and causal relationships between
actions, but are usually very poor at reasoning about time and temporal relationships
between actions. Schedulers, on the other hand, are primarily designed to reason about
time and resource conicts, but have no capabilities for reasoning about causal dependencies
between actions. The problems in the grey zone require reasoning of both kinds, so neither
planners nor schedulers can handle these problems properly. If these problems are not
solved, then the scheduler does not get sucient information from the planner to do the
best of the situation|the planner and the scheduler may fail in their cooperation to nd a
plan with a feasible schedule, even when such a plan exists.
This article focusses on one of these grey-zone problems, namely the problem of optimising the action order of a plan to allow for better schedules. Whenever two actions conict
with each other and cannot be allowed to execute in parallel, a planner must order these
actions. However, it usually does not have enough information and reasoning capabilities
to decide which of the two possible orders is the best one, so it makes an arbitrary choice.
One of the choices typically allows for a better schedule than the other one, so if the planner
makes the wrong choice it may prevent the scheduler from nding a good, or even feasible,
schedule. This situation arises also when plans are made by a human expert, since it is difcult to see which choice of ordering is the best one in a large and complex plan. Planning
systems of today usually cannot do anything better than asking the planner for a new plan
if the scheduler fails to nd a feasible schedule. This is an expensive and unsatisfactory
solution, especially if there is no feedback from the scheduler to help the planner making
a more intelligent choice next time. Another solution which appears in the literature is to
use a lter between the planner and scheduler which attempts to modify the plan order to
put the scheduler in a better position. Such lters could remove certain over-commitments
in the ordering, which will be referred to as deordering the plan, or even change the order
between certain actions, which will be referred to as reordering the plan.
This article is intended to provide a rst formal foundation for studying this type of
problems. It denes a number of dierent optimality criteria for plan order modications,
both with respect to the degree of over-committment in the ordering and with respect to
the parallel execution time, and it also provides computational results for computing such
modications. The article also analyses some ltering algorithms suggested in the literature
for doing such order modications.
The remainder of this article is structured as follows. Section 2 introduces the concepts
and computations studied in this article by means of an example. Then Section 3 starts the
1. Brian Drabble, personal communication, Aug. 1997.

100

Computational Aspects of Reordering Plans

theoretical content of the article, dening the two planning formalisms used in the following
sections. The problems of making a plan least-constrained are studied in Section 4 where
some candidate denitions for this concept are introduced and their computational properties investigated. Section 5 denes the concepts of parallel plans and parallel executions of
plans. This is followed by Section 6 where optimal deorderings and reorderings of parallel
plans are introduced and the complexity of achieving such optimality is analysed. Section 7
then studies how the complexity of these problems is aected by restricting the language.
This includes the positive result that an algorithm from the literature nds optimal deorderings for a class of plans for most common planning languages. Some other ltering
algorithms from the literature as well as some planners incorporating some ordering optimisation are discussed in Section 8. Finally, Section 9 discusses some aspects of this article
and some related work, while Section 10 concludes by a brief recapitulation of the results.

2. Example
In order to illustrate the concepts and operations studied in this article a simple example
of assembling a toy car will be used. The example is a variation of the example used by
Backstrom and Klein (1991), which is a much simplied version of an existing assembly line
for toy cars used for undergraduate laborations in digital control at Linkoping University
(for a description of this assembly line, see eg. Klein, Jonsson, & Backstrom, 1995, 1998;
Stromberg, 1991). The problem is to assemble a LEGO2 car from pre-assembled parts as
shown in Figure 1. There is a chassis, a top and a set of wheels, the two latter to be mounted
onto the chassis.
Top

Chassis

Car

Wheels

Figure 1: Schematic assembly process for a toy car
The workpiece ow of the factory is shown in Figure 2. There are three storages, one
for each type of preassembled part, two workstations, number 1 for mounting the top and
number 2 for mounting the wheels, and there is a car storage for assembled cars. Tops can
be moved from the top storage to workstation 1 and sets of wheels can be moved from the
2. LEGO is a trade mark of the LEGO company

101

Backstro m

wheels storage to workstation 2. Chassis can be moved from the chassis storage to either
workstation and also, possibly with other parts mounted, between the two workstations and
from either workstation to the car storage. Furthermore, before mounting the wheels on a
chassis, the tyres must be inated, so workstation 2 incorporates a compressed-air container
which must be pressurized before inating the tyres (this is not shown in the gure).

Top
Storage

Workstation 1

Chassis
Storage
Wheels
Storage

Car
Storage
Workstation 2

Figure 2: Schematic lay-out of the toy-car factory
This article is concerned with modifying the order between the actions in a given plan,
and does not consider modifying also the set of actions. Hence, the example will assume
that a plan for assembling a toy car is given|whether this plan was produced by hand or
by a planning algorithm is not important. It will also be assumed that this assembly plan
contains exactly those actions listed in Table 1, in some order. Since most results in this
article are independent of the particular planning language used, no assumptions about
the planning language will be made in this example either. To make things simple, the
obvious common-sense constraints on which plans are valid will be used. For instance, a
part must be moved to a workstation before it is mounted there, the wheels must be inated
before being mounted and the air container must be pressurized before inating the tyres.
Furthermore, since a chassis can only be at one single place at a time, the top cannot be
mounted in parallel with mounting the wheels, and neither of the mounting operations can
be done in parallel with moving either the chassis or the part to be mounted.
The purpose of modifying the action order in a given plan is usually to optimize the
plan in some aspect, for instance, to make the plan least constrained. Consider the totally
ordered plan in Figure 3a, for producing a chassis with wheels, which is a subplan of the
plan for assembling a car. Note that since the plan is totally ordered, all pairs of actions
are ordered, but the implicit transitive arcs are not shown in the gure. This plan is clearly
over-constrained. For instance, it is not necessary to move the set of wheels to workstation
2 before pressurizing the air container, and removing this ordering constraint results in
the plan in Figure 3b. Note that orderings have only been removed|the arc from MvW2
to IT existed already in the original plan, but was implicit by transitivity. A plan where
some orderings have been removed will be referred to as a deordering of the original plan.
102

Computational Aspects of Reordering Plans

Action
MvT1
MvW2
MvC1
MvC2
MvS
MtT
MtW
PAC
IT

Description
Move top to workstation 1
Move wheels to workstation 2
Move chassis to workstation 1
Move chassis to workstation 2
Move chassis to car storage
Mount top on chassis
Mount wheels on chassis
Pressurize air container
Inate tyres

Duration
1
1
2
2
3
7
4
5
4

Table 1: Actions of the assembly plan
This new plan is less constrained than the original plan, since it is now possible to move
the wheels and pressurize the air container in either order or, perhaps, even in parallel.
However, further orderings can be removed; it is not necessary to inate the wheels before
moving the chassis to the workstation. Removing also this ordering results in the plan in
Figure 3c, which is a least constrained deordering of the original plan in the sense that
it is not possible to remove any further ordering constraints and still have a valid plan.
That is, if removing any further ordering constraint, it will be possible to sequence the
actions in such a way that the plan will no longer have its intended result. In addition to
deorderings, one may also consider arbitrary modications of the ordering relation, that is,
both removing and adding relations. Such modications will be referred to as reorderings.
Three dierents least-constrainment criteria for plans based on deorderings and reorderings
will be studied in Section 4, and the plan in Figure 3c happens to be optimal according to
all three of these criteria.

MvW2 - PAC

- IT

- MvC2 -MtW

a) A total order plan
MvW2PPPP
q

1 IT


PAC

- MvC2 -MtW

b) A less constrained version of a

MvW2PPPP
q1IT PPPPq

PAC
*MtW

MvC2
c) A least constrained
version of a

Figure 3: Three plans for mounting the wheels
103

Backstro m

Making a plan least constrained is clearly useful if certain actions can be executed in
parallel. However, even in the case where no parallel execution is possible, it may still be
worth making a plan least constrained. Although the partial order of this least constrained
plan must again be strengthened into a total order for execution purposes, this need not be
the same total order as in the original plan. Suppose the actions have temporal constaints
like deadlines and earliest release times and that a scheduler will post-process the plan to
try nding a feasible schedule. It may then be the case that the original plan has no feasible
schedule, but a less constrained version of it can be sequenced into a feasible schedule. The
idea of a least constrained plan is that the scheduler will have as many alternative execution
sequences as possible to choose from.
The most important reason for modifying the action ordering of a plan, however, is to
execute the plan faster by executing actions in parallel whenever possible. For this purpose
it is better to use the length of the optimal schedule for a plan as a measure, rather than
some measure on the ordering itself. Suppose the following car-assembly plan is given
hMvW 2; PAC; IT; MvC 2; MtW; MvT 1; MvC 1; MtT; MvS i:
If the actions are executed sequentially in the given order, the minimum execution time
is the sum of the durations of the actions, that is 29 time units. However, just as in the
previous example this plan is over-constrained, since several of the actions could be executed
in either order, or in parallel.
It is possible to remove orderings as far as shown in Figure 4a, but no further, and
still have a valid plan (the implicit transitive orderings are not shown in the gure). This
deordered version of the original assembly plan can be scheduled to execute in 25 time units
by exploiting parallelism whenever possible. An example of such a schedule is shown in
Figure 3b. However, no faster execution is possible, since the plan contains a subsequence
of actions which cannot be parallelized and which has a total execution time of 25 time
units.
It is obvious from the schedule in Figure 4b that not many actions can be executed in
parallel, and that the gain of deordering the plan is quite small. A much better performance
is possible if arbitrary modications to the action ordering are allowed, that is, if also
reorderings are considered. For instance, in the assembly plan there is no particular reason
why the wheels should be mounted before the top is mounted, and it will be seen shortly
that much time can be saved by reversing the order of these two operations. A deordering
cannot do this, however, since removing the ordering between the wheel-mounting action
(MtW) and the top-mounting action (MtT) would make these unordered. This would be
interpreted as if the two actions could be executed in parallel, which is not possible. This
is also the reason why these actions must be ordered in the original plan. However, when
allowing arbitrary modications, the order between these two actions can be reversed, and
Figure 5a shows such a reordering of the original plan. This plan can be scheduled to
execute in only 16 time units, which is a considerable improvement over both the original
plan and the optimal deordered version of it. An example of an optimal schedule is shown
in Figure 5b. In fact, this plan is an optimal reordering in the sense that no other ordering
of the actions results in a valid plan that can be scheduled to execute faster. The problems
of nding optimal deorderings and reorderings of plan with respect to parallel execution is
the main topic of this article, and are studied in Sections 5 to 7.
104

Computational Aspects of Reordering Plans

PAC
MvW2

MvT1

IT

MtW

MvC2

MtT

MvC1

MvS

a) A deordering of the assembly plan admitting a shortest
parallel execution time
PAC

IT

MvW2

MtW

MvC1

MtT

MvS

MvC2
MvT1
0

5

10

15

20

25

b) An optimal schedule for the plan above

Figure 4: An optimal deordering of the assembly plan
It is obvious that reordering is a more powerful operation than deordering, since the
reordered plan in Figure 5a allows for a shorter schedule than the optimal deordering in
Figure 4a. On the other hand, if the original plan had been

hMvT 1; MvC 1; MtT; MvS; MvW 2; PAC; IT; MvC 2; MtW i;
then deordering would have been sucient for arriving at the optimal plan in Figure 5a.

3. Planning Formalisms
This section denes actions, plans and related concepts, which basically appear in two
dierent guises in this article. Denitions and tractability results will mostly be cast in a
general, axiomatic framework in order to be as general and independent of formalism as
possible. Hardness results, on the other hand, will mostly be cast in a specic formalism,
Ground Tweak, and often subject to further restrictions, this in order to strengthen the
results. Both these formalisms are dened below. In addition to these, a third formalism
will be used, but its denition will be deferred until it is used, in Section 7.
105

Backstro m

PAC

IT

MvW2

MvT1

MtT

MvC1

MvC2

MvS

MtW

a) A reordering of the assembly plan admitting a shortest
parallel execution time
PAC
MvC1

IT

MvW2

MvT1 MtT
0

5

MtW

MvS

MvC2
10

15

b) An optimal schedule for the plan above

Figure 5: An optimal reordering of the assembly plan

3.1 The Axiomatic Planning Framework

The axiomatic framework makes only a minimum of assumptions about the underlying formalism. It may be instantiated to any planning formalism that denes some concept of
a planning problem a domain of entities called actions and a validity test. The planning
problem is assumed to consist of planning problem instances (ppis),3 with no further assumptions about the inner structure of these. The validity test is a truth-valued function
taking a ppi and a sequence of actions as arguments. If the validity test is true for a ppi 
and an action sequence ha1 ; : : : ; an i, then the action sequence ha1 ; : : : ; an i is said to solve
. While the inner structure of the ppis and the exact denition of the validity test are crucial for any specic planning formalism, many results in this article can be proven without
making any such further assumptions. Results on the computational complexity of certain
problems will make an assumption about the complexity of the validity test, though. Based
on these concepts, the notion of plans can be dened in the usual way.

Denition 3.1 A total-order plan (t.o. plan) is a sequence P = ha1 ; : : : ; ani of actions,
which can alternatively be denoted by the tuple hfa1 ; : : : ; an g; i where for 1  k; l  n,
ak  al i k < l. Given a ppi , P is said to be -valid i the validity test is true for 

and P .

3. This is the complexity-theoretic terminology for problems. Planning problem instances in the sense of
this article are sometimes referred to as planning problems in the planning literature.

106

Computational Aspects of Reordering Plans

A partial-order plan (p.o. plan) is a tuple P = hA; i where A is a set of actions and
 is a strict ( ie. irreexive) partial order on A. The validity test is extended to p.o. plans
s.t. given a ppi , P is -valid i hA; 0 i is valid for every topological sorting 0 of .

The actions of a t.o. plan must be executed in the specied order, while unordered
actions in a p.o. plan may be executed in either order. That is, a p.o. plan can be viewed
as a compact representation for a set of t.o. plans. There is no implicit assumption that
unordered actions can be executed in parallel; parallel plans will be dened in Section 5.
p.o. plans will be viewed as directed acyclic graphs in gures with the transitive arcs often
tacitly omitted to enhance readability. Furthermore, all proofs and algorithms in this article
are based on this denition, ie assuming the order of a plan is transitively closed, while
many practical planners do not bother about transitive closures. This dierence does not
aect any of the results presented here.

3.2 The Ground TWEAK Formalism

The Ground TWEAK (GT) formalism is the TWEAK language (Chapman, 1987) restricted
to ground actions. This formalism is a variation on propositional STRIPS and it is known
to be equivalent under polynomial transformation to most other common variants on propositional STRIPS (Backstrom, 1995). In brief, an action has a precondition and a postcondition, both being sets of ground literals.
In order to dene the GT formalism, the following two denitions are required. Given
some set S , the notion Seqs (S ) denotes the set of all sequences formed by members of S ,
allowing repetition of elements and including the empty sequence. The symbol `;' will be
used to denote the sequence concatenation operator. Further, given a set P of propositional
atoms, the set LP of literals over P is dened as LP = P [ f:p j p 2 Pg. Since no other
formulae will be allowed than atoms and negated atoms, a double negation ::p will be
treated as identical to the unnegated atom p. Finally, given a set of literals L, the negation
Neg(L) of L is dened as Neg(L) = f:p j p 2 Lg[fp j :p 2 Lg and L is said to be consistent
i there is no atom p s.t. both p 2 L and :p 2 L.

Denition 3.2 An instance of the GT planning problem is a quadruple  = hP ; O; I; Gi

where

 P is a nite set of atoms;
 O is a nite set of operators of the form hpre; posti where pre; post  LP are consistent
and denote the pre and post condition respectively;

 I; G  LP are consistent and denote the initial and goal state respectively.
For o = hpre; posti  O, we write pre(o) and post(o) to denote pre and post respectively. A
sequence ho1 ; : : : ; on i 2 Seqs (O) of operators is called a GT plan (or simply a plan) over .
Denition 3.3 The ternary relation valid  Seqs (O)  2L  2L is dened s.t. for arbitrary ho1 ; : : : ; on i 2 Seqs (O) and S; T  LP , valid(ho1 ; : : : ; on i; S; T ) holds i either
1. n = 0 and T  S or
P

107

P

Backstro m

2. n > 0, pre(o1 )  S and
valid(ho2 ; : : : ; on i; (S , Neg(post(o1 )) [ post(o1 ); T ).
A t.o. plan ho1 ; : : : ; on i 2 Seqs (O) solves  i valid(ho1 ; : : : ; on i; I; G).

An action is a unique instance of an operator, ie a set of actions may contain several
instances of the same operator, and it inherits its pre- and post-conditions from the operator
it instantiates. Since all problems in this article will consider some xed set of actions, the
atom and operator sets will frequently be tacitly omitted from the GT ppis. In gures,
GT actions will be shown as boxes, with precondition literals to the left and postcondition
literals to the right.

4. Least Constrained Plans

It seems to have been generally assumed in the planning community that there is no dierence between t.o. plans and p.o. plans in the sense that a t.o. plan can easily be converted
into a p.o. plan and vice versa. However, while a p.o. plan can be trivially converted into
a t.o. plan in low-order polynomial time by topological sorting, it is less obvious that also
the converse holds. At least three algorithms for converting t.o. plans into p.o. plans have
been presented in the literature (Pednault, 1986; Regnier & Fade, 1991a; Veloso, Perez, &
Carbonell, 1990) (all these algorithms will be analyzed later in this article). The claim that
a t.o. plan can easily be converted into a p.o. plan is vacuously true since any t.o. plan is
already a p.o. plan, by denition. Hence, no computation at all needs to be done. This
is hardly what the algorithms were intended to compute, however. In order to be useful,
such an algorithm must output a p.o. plan satisfying some interesting criterion, ideally some
optimality criterion. In fact, two of the algorithms mentioned above are claimed to produce
optimal plans according to certain criteria. For instance, Veloso et al. (1990, p. 207) claim
their algorithm to produce least constrained plans. They do not dene what they mean
by this term, however, and theirs is hardly the only paper in the literature using this term
without further denition.
Unfortunately, it is by no means obvious what constitutes an intuitive or good criterion
for when a p.o. plan is least constrained and, to some extent, this also depends on the
purpose of achieving least-constrainment. The major motivation for producing p.o. plans
instead of t.o. plans (see for instance Tate, 1975) is that a p.o. plan can be post-processed
by a scheduler according to further criteria, such as release times and deadlines or resource
limits. Either the actions are ordered into an (ideally) optimal sequence or, given criteria for
parallel execution, into a parallel plan that can be executed faster than if the actions were
executed in sequence. In both cases, the less constrained the original plan is, the greater
is the chance of arriving at an optimal schedule or optimal parallel execution respectively.
Both of the algorithms mentioned above are motivated by the goal of exploiting possible
parallelism to decrease execution time.
It is not only interesting to make t.o. plans partially ordered, but also to make partially
ordered plans more partially ordered, that is, to generalise the ordering. An algorithm
for this task has been presented in the literature in the context of case-based planning
(Kambhampati & Kedar, 1994). Since t.o. plan are just a special case of p.o. plans, this
section will study the general problem of making partially ordered plans less constrained.
108

Computational Aspects of Reordering Plans

4.1 Least-constrainment Criteria

There is, naturally, an innitude of possible denitions of least-constrainment. Some seem
more reasonable than others, however. Three intuitively reasonable candidates are dened
and analyzed below. Although other denitions are possible, it is questionable whether
considerably better or more natural denitions, with respect to the purposes mentioned
above, can be dened without using more information than is usually present in a t.o. or
p.o. plan.

Denition 4.1 Let P = hA; i and Q = hA; 0i be two p.o. plans and  a ppi. Then,
1. Q is a reordering of P wrt.  i both P and Q are -valid.
2. Q is a deordering of P wrt.  i Q is a reordering of P and 0 

3. Q is a proper deordering of P wrt.  i Q is a reordering of P and 0 

Denition 4.2 Given a ppi  and two p.o. plans P = hA; i and Q = hA; 0i,
1. Q is a minimal-constrained deordering of P wrt.  i
(a) Q is a deordering P wrt.  and
(b) there is no proper deordering of Q wrt. ;
2. Q is a minimum-constrained deordering of P wrt.  i
(a) Q is a deordering P wrt.  and
(b) there is no deordering hA; 00 iof Q wrt.  s.t. j 00 j < j  j;
3. Q is a minimum-constrained reordering of P wrt.  i
(a) Q is a reordering P wrt.  and
(b) there is no reordering hA; 00 iof Q wrt.  s.t. j 00 j < j  j;

Note that the previous publication (Backstrom, 1993) used the terms LC1-minimality for
minimal-constrained deordering and LC2-minimality for minimum-constrained reordering.
This change in terminology has been done with the hope that more will be gained in clarity
than is lost by confusion.
It is easy to see that minimum-constrainment is a stronger criterion than minimalconstrainment|any minimum-constrained deordering of a plan P is a minimal-constrained
deordering of P , but the opposite is not true. As an example, consider the plan in Figure 6a.
If removing all ordering constraints from action C, the result is the plan in Figure 6b, which
is still valid. This plan has an order of size 3 (there is one implicit transitive order) and it
is a minimal-constrained deordering since no further deordering can be made. It is not a
minimum-constrained deordering, however, since if instead breaking the ordering constraints
between the subsequences AB and CB, the result is the plan in Figure 6c, which is also valid.
This plan has an ordering of size 2 and it can easily be seen that it is a minimum-constrained
deordering, and that it happens to coincide with the minimum-constrained reordering in
this case. This coincidence is not always the case, however, since a reordering is allowed to
109

Backstro m

do more modications than a deordering; a minimum deordering can obviously never have
a smaller ordering relation than a minimum reordering. Examples of this dierence was
shown already in Section 2, where Figure 4a shows a minimum-constrained deordering and
Figure 4b shows a minimum-constrained reordering.
A

-p

p

B

-

q

C

q

-q

D

a) A total-order plan
C
A

p

-p

B

q

-q

q

C

D

A

b) A minimal deordering

q

-q

D

p

-p

B

q

b) A minimum deordering

Figure 6: The dierence between minimal and minimum constrained deorderings.
Other alternative denitions of least-constrainment could be, for instance, to maximize
the unorderdness or to minimize the length of the longest chain in the modied plan. However, to nd a de-/reordering which has as many pairs of unordered actions as possible is the
dual of computing a minimum de-/reordering and it is, thus, already covered. Minimizing
the length of the longest chain is a condition which may be relevant when actions can be
executed in parallel and the overall execution time is to be minimized. However, since the
number of ordering constraints is quadratic in the length of a chain (because of transitive
arcs), minimizing the size of the relation will often be a reasonable approximation of minimizing the chain length. Furthermore, minimizing the longest chain is still a rather weak
condition for this purpose, so it is better to study directly the problem of nding shortest
parallel executions of plans, which will be done later in this article.
Another issue is whether to minimize the size of the ordering relation as given, or to
reduce the transitive or reductive closure of it. Since plans may have superuous orderings
with no particular purpose, it is reasonable to standardize matters and either add all possible
transitive arcs, getting the transitive closure, or to remove all transitive arcs, getting the
reductive closure. The choice between these two is not important for the results to be
proven. However, minimizing the transitive closure will give a preference to plans with
many unordered short chains of actions over plans with a few long chains, and so seems to
coincide better with the term 'least constrained'.

4.2 Computing Least-constrained Plans
Minimal deordering is weaker than the two other least-constrainment criteria considered,
but it is the least costly to achieve|it is the only one of the three criteria which can be
satised by a polynomial-time modication to a plan.
110

Computational Aspects of Reordering Plans

Denition 4.3 The search problem

Minimal-Constrained Deordering (MlCD) is

dened as follows:
Given: A ppi  and a -valid plan P .
Output: A minimal-constrained deordering of P wrt. .

Theorem 4.4

MlCD can be solved in polynomial time if validity for p.o. plans can be

tested in polynomial time.

Proof: Consider algorithm MLD in Figure 7 and let Q = hA; 0 i be the plan output by
the algorithm on input P = hA; i. The plan Q is obviously a valid deordering of P wrt.

. It is further obvious from the termination condition in the while loop that there is no
other ordering 00 0 s.t. hA; 00 i is -valid. It follows that Q is a minimal-constrained
deordering. Since the algorithm obviously runs in polynomial time, the theorem follows.

2

Furthermore, if validity testing is expensive, this will be the dominating cost in the MLD
algorithm.

Corollary 4.5 If validity testing for p.o. plans can be solved in time O(f (n)) for some
function f (n), then MlCD can be solved in O(maxfn7=2 ; n2 f (n)g) time.
1 procedure MLD
2
Input: A valid p.o. plan P = hA; i and a ppi 
3
Output: A minimal deordering of P
4 while there is some e 2 s.t. hA; ( ,feg)+i is -valid do
5
remove e from 
6 return hA; + i;

Figure 7: The minimal-deordering algorithm MLD
In particular, note that plan validation is polynomial for the usual variant of propositional STRIPS without conditional actions (Nebel & Backstrom, 1994, Theorem 5.9).
More precisely, this proof pertains to the Common Propositional STRIPS formalism (CPS)
and, thus, holds also for the other common variants of propositional STRIPS, like Ground
TWEAK (Backstrom, 1995). Furthermore, note that in practice it may not be necessary
to compute the transitive closure either for the output plan or for validating a plan in the
algorithm.
While minimum de-/reordering are stronger criteria than minimal deordering, they are
also more costly to achieve.

Denition 4.6 The decision problem

Minimum-Constrained Deordering (MmCD)

is dened as follows:
Given: A ppi , a -valid plan P and an integer k  0.
Question: Is there a deordering hA; i of P s.t. j  j  k?
111

Backstro m

Denition 4.7 The decision problem

Minimum-Constrained Reordering (MmCR)

is dened as follows:
Given: A ppi , a -valid plan P and an integer k  0.
Question: Is there a reordering hA; i of P s.t. j  j  k?

Theorem 4.8

Minimum-Constrained Deordering is NP-hard.

Proof: Proof by reduction from Minimum Cover (Garey & Johnson, 1979, p. 222),
which is NP-complete. Let S = fp1 ; : : : ; pn g be a set of atoms, C = fC1 ; : : : ; Cm g a set of
subsets of S and k  jC j a positive integer. A cover of size k for S is a subset C 0  C s.t.
jC 0j  k and S  [T 2C T . Construct, in polynomial time, the GT ppi  = h;; frgi and the
-valid t.o. plan P = ha1 ; : : : ; am ; aS i where pre(ai ) = ; and post(ai ) = Ci for 1  i  m,
and further pre(aS ) = S and post(aS ) = frg. Obviously, S has a minimum cover of size k
i there exists some -valid p.o. plan Q = hfa1 ; : : : ; am ; aS g; i s.t. j  j  k, since only
0

those actions contributing to the cover need remain ordered wrt. to aS

Corollary 4.9

2

Minimum-Constrained Reordering is NP-hard.

Corollary 4.10

Minimum-Constrained Deordering and Minimum-Constrained

Reordering both remain NP-hard even when restricted to GT plans where the actions

have only positive pre- and post-conditions.

Theorem 4.11 If validity for p.o. plans is in some complexity class C, then

MinimumConstrained Deordering and Minimum-Constrained Reordering are in NP C.

Proof: Guess a solution, verify that it is a de-/reordering and then validate it using an

2

oracle for C.

For most common planning formalisms without conditional actions and context-dependent
eects, minimal de-/reordering is NP-complete.

Theorem 4.12 If validity for p.o. plans can be tested in polynomial time, then Minimum-

Constrained Deordering and Minimum-Constrained Reordering are NP-complete.

Proof: Immediate from Theorems 4.8 and 4.11 and from Corollary 4.9.

2

It follows immediately that the corresponding search problems, that is, the problems of
generating a minimum-constrained de-/reordering are also NP-hard (and even NP-equivalent
if validity testing is tractable).
Furthermore, MmCD and MmCR are not only hard to solve optimally, but even to
approximate. Neither of these problems is in the approximation class APX (Crescenzi
& Panconesi, 1991), ie neither problem can be approximated within a constant factor.
(Both here and elsewhere in this article the term approximation is used in the constructive
sense, that is the results refer to the existence/non-existence of algorithms producing an
approximate solution in polynomial time).
112

Computational Aspects of Reordering Plans

Theorem 4.13

Minimum-Constrained Deordering and Minimum- Constrained
Reordering cannot be approximated within a constant unless NP 2 DTIME (npoly log n ).

Proof: Suppose there were a polynomial-time algorithm A approximating MmCD within
a constant. Since the reduction in the proof of Theorem 4.8 preserves the solutions exactly,
also approximations are preserved. Hence, Minimum Cover could be approximated within
a constant, but this is impossible unless NP 2 DTIME (npoly log n ) (Lund & Yannakakis,
1994), which contradicts the assumption. The case for MmCR is a trivial consequence. 2
If using the number of propositional atoms in the plan as a measure of its size, this
bound can be strengthened to (1 , ") ln jPj for arbitrary " unless NP 2 DTIME (nlog log n )
by substituting such a result for Minimum Cover (Feige, 1996) in the proof above.

5. Parallel Plans

In order to study the problem of nding a shortest parallel execution of a plan, the formalisms used so far are not quite sucient. Since they lack a capability of modelling when
actions can be executed in parallel or not, it is impossible to say with any reasonable precision how a certain action ordering will aect the parallel execution time. Partial-order
plans are sometimes referred to as parallel plans in literature. This is misleading, however.
That two actions are left unordered in such a plan means that they can be executed in
either order, without aecting the validity of the plan, but in the general case there is
no guarantee that the plan will remain valid also if the executions of the actions overlap
temporally. In some cases, unorderedness means that parallel or overlapping execution is
allowed, while in other cases it does not mean that, depending on the action modelling and
its underlying domain assumptions. In the rst case, the plan must have a stronger ordering
committment, any two actions that must not have overlapping executions must be ordered,
thus making the plan over-committed.
In order to distinguish the two cases, a concept of parallel plans will be introduced below.
A parallel plan is a partial-order plan with an extra relation, a non-concurrency relation,
which tells which actions must not be executed in parallel. In this article two actions are
considered parallel if their executions have any temporal overlap at all. Plans where all
unordered actions can be executed in parallel constitute the special case of denite parallel
plans.

Denition 5.1 A parallel plan is a triple P = hA; ; #i, where hA; i is a p.o. plan and
# is an irreexive, symmetric relation on A. A denite parallel p.o plan is a parallel plan
P = hA; ; #i s.t. #  ( [ ,1 ).
Intuitively, a parallel plan is a p.o. plan extended with an extra relation, # (a nonconcurrency relation), expressing which of the actions must not be executed in parallel.
This relation is primarily intended to convey information about actions that are unordered
under the  relation, although it is allowed to relate also such actions. That is, the #
relation is intended to capture information about whether two actions can be executed in
parallel or not, in general. That two actions are ordered in a plan forbids executing them
in parallel in this particular plan, but does not necessarily mean that the actions could not
113

Backstro m

be executed in parallel under dierent circumstances. Planning algorithms frequently produce overcommitted orderings on plans, and the whole purpose of this article is to study the
problem of optimizing plans by nding and removing such overcommitted orderings. Hence,
there are no restrictions in general on the relation # in addition to those in Denition 5.1.
For instance, a  b does not imply that a#b. However, the non-concurrency relation will
frequently be constrained to satisfy the post-exclusion principle.
Denition 5.2 A parallel GT plan P = hA; ; #i satises the post-exclusion principle
i for all actions a; b 2 A, a#b whenever there is some atom p s.t. p 2 post(a) and
:p 2 post(b).
The denition of plan validity is directly inherited from p.o. plans.
Denition 5.3 Given a ppi , a parallel plan hA; ; #i is -valid i the p.o. plan hA; i
is -valid.
The non-concurrency relation is, thus, not relevant for deciding whether a plan is valid or
not. Instead, it is used for constraining how parallel plans may be executed and it is the
core concept behind the denition of parallel executions.
Consider, for instance, the GT plan hfA; B; C g; fhA; B ig; fhB; C igi which is shown in
Figure 8 (arrows denote ordering relations and dashed lines denote nonconcurrency relations). This plan is valid wrt. the ppi  = h;; fr; sgi, that is the nal value of the atom q
does not matter. Since B #C holds the actions B and C are constrained not to be executed
in parallel, but may be executed in either order, that is, the plan is not denite. This could
be because the post-exclusion principle is employed, or for some other reason. Although
A#B does not hold the actions A and B clearly cannot be executed in parallel, since A  B
holds. There are four ways to execute this plan, in either of the three sequences A,B,C;
A,C,B and C,A,B, or by executing A and C in parallel, followed by B (unit length is assumed). Also note that this plan would no longer be valid if the goal contained either q or
:q, since the nal truth value of q depends on the actual execution order. Furthermore,
any reordering of the plan would have to keep the ordering constraint A  B to satisfy the
validity criterion, why it is not necessary to have the constraint A#B . It would do no harm
here to include this restriction, but in more complex plans it may be an over-constrainment,
if there are several producers for the atom p to choose between, for instance. To sum up,
the non-concurrency relation should primarily be used to mark which actions must not be
in parallel in addition to those already forbidden to be in parallel because of validity.
This framework for parallel plans admits expressing possible parallelism only; necessary
parallelism is out of the scope of this article and requires a planner having access to and
being able to make use of further additional information, perhaps a temporal algebra.
Furthermore, a set of non-concurrent actions can easily be expressed by making all actions
in the set pairwise non-concurrent, but the formalism is not sucient to say that k of the
actions, but not more, in such a set may be executed in parallel. Similarly, it is not possible
to express that an action must executed before or after an interval, or that two sets of
actions must have non-overlapping executions.
Denition 5.4 Let P = hA; ; #i be a parallel plan and let the function d : A 7! N denote
the duration of each action. A parallel execution of P is a function r : A 7! N , denoting
release times for the actions in A, satisfying that for all a; b 2 A,
114

Computational Aspects of Reordering Plans

A

p

q
r

B
#

C :s q
Figure 8: A parallel plan
1. if a  b, then r(a) + d(a)  r(b) and
2. if a#b, then either
(a) r(a) + d(a)  r(b) or
(b) r(b) + d(b)  r(a).
The length of the parallel execution is dened as maxa2A fr(a) + d(a)g, ie, the latest nishing time of any action. A minimum parallel execution of plan is a parallel execution with
minimum length among all parallel executions of the plan. The length of a parallel plan P ,
denoted length(P ), is the length of the minimum parallel execution(s) for P .

P

Obviously, every parallel plan has a parallel execution of length a2A d(a) (which is the
trivial case of sequential execution). Furthermore, in certain cases, hardness results will be
strengthened by restricting the duration function.
Denition 5.5 The special case where d(a) = 1 for all a 2 A is referred to as the unit
time assumption.
Deciding whether a release-time function is a parallel execution is tractable.
Theorem 5.6 Given a parallel plan P = hA; ; #i, a duration function d : A 7! N and a
release-time function r : A 7! N , it can be decided in polynomial time whether r is a parallel
execution for P and, in the case it is, what the length of this execution is.
Proof: Trivial.
2
Consider the plan in Figure 8 and three release-time functions r1 , r2 and r3 , dened as
follows
r1(A) = 1 r1 (B ) = 2 r1 (C ) = 3
r2(A) = 1 r2 (B ) = 2 r2 (C ) = 1
r3(A) = 1 r3 (B ) = 2 r3 (C ) = 2:
Both r1 and r2 are parallel executions of the plan, while r3 is not. Furthermore, r2 is
a minimum parallel execution for the plan, having length 2. However, computing the
minimum parallel execution of a parallel plan is dicult in the general case.
115

Backstro m

Denition 5.7 The decision problem Parallel Plan Length (PPL) is dened as follows:
Given: A parallel plan P = hA; ; #i, a duration function d and an integer k.
Question: Does P have a parallel execution of length k or shorter?

Theorem 5.8

Parallel Plan Length is NP-hard.

Proof: Hardness is proven by transformation from Graph K-Colourability (Garey
& Johnson, 1979, p. 191), which is NP-complete. Let G = hV; E i be an arbitrary undirected graph, where V = fv1 ; : : : ; vn g. Construct, in polynomial time, a GT ppi as follows. Dene the ppi  = h;; fp1 ; : : : ; pn gi. Also dene the parallel plan P = hA; ;; #i,
where A contains one action ai for each vertex vi 2 V , s.t. pre(ai ) = ; and post(ai ) =
fpi; qi g [ f:qj j fvi; vj g 2 E g. Finally, let ai#aj i fvi ; vj g 2 E , which satises the post-

exclusion principle. The plan P just constructed is obviously -valid. It is easy to see that
G is k-colourable i P has a parallel execution of length k wrt.  since each colour of G
will correspond to a unique release time in the parallel execution of P .
2

Corollary 5.9

Parallel Plan Length remains NP-hard even when restricted to GT ac-

Theorem 5.10

Parallel Plan Length is in NP.

tions with empty preconditions and under the assumption of unit time and the post-exclusion
principle.

Proof: Guess a parallel execution. Then verify it, which can be done in polynomial time
2

according to Theorem 5.6.

Computing a minimum parallel execution of a plan is tractable for the special case of denite
plans, however.

Theorem 5.11
parallel plans.

Parallel Plan Length can be solved in polynomial time for denite

Proof: Use the algorithm DPPL (Figure 9), which is a straightforward stratication
2

algorithm for directed DAGs.

6. Reordering Parallel Plans
Having dened the concept of parallel plan, it is possible to dene concepts similar to
the previous least-constrainment criteria which are more appropriate for minimizing the
execution time of parallel plans.

Denition 6.1 Let P = hA; ; #i and Q = hA; 0 ; #i be two parallel plans and  a ppi.
Then,

1. Q is a parallel reordering of P wrt.  i both P and Q are -valid;
116

Computational Aspects of Reordering Plans

1
2
3
4
5
6
7
8
9
10
11
12

procedure DPPL

Input: A denite parallel plan P = hA; ; #i
Output: A minimum parallel execution r for P
Construct the directed graph G = hA; i
for all a 2 A do
r(a) 0
while A 6= ; do
Select some node a 2 A without predecessors in A
for all b 2 A s.t. a  b do
r(b) max(r(b); r(a) + d(a))

A

return r

A , fag

Figure 9: Algorithm for computing a minimum parallel execution for denite parallel plans.
2. Q is a parallel deordering of P wrt.  i Q is a parallel reordering of P and 0 ;
3. Q is a minimum parallel reordering of P wrt.  i
(a) Q is a parallel reordering of P wrt.  and
(b) no other parallel reordering of P wrt.  is of shorter length than Q;
4. Q is a minimum parallel deordering of P wrt.  i
(a) Q is a parallel deordering of P wrt.  and
(b) no other parallel deordering of P wrt.  is of shorter length than Q.

Modifying plans to satisfy either of the latter two criteria is dicult in the general case,
however.

Denition 6.2 The decision problem Minimum Parallel Deordering (MmPD) is dened as follows.
Given: a ppi , a parallel plan P , a duration function d and an integer k.
Question: Does P have a deordering with a parallel execution of length k wrt. ?

Denition 6.3 The decision problem Minimum Parallel Reordering (MmPR) is dened as follows.
Given: a ppi , a parallel plan P , a duration function d and an integer k.
Question: Does P have a reordering with a parallel execution of length k wrt. ?

Theorem 6.4 Minimum Parallel Deordering is NP-hard.
Proof: Similar to the proof of Theorem 6.4. Given a graph G and an integer k, construct
a ppi  and a plan P = hA; ; #i in the same way as in the proof of Theorem 5.8, but
let  be an arbitrary total order on A. Obviously, P is -valid and Q = hA; ;; #i is a

deordering of P s.t. no other deordering of P is shorter than Q. Hence, Q, and thus P , has
a deordering with a parallel execution of length k i G is k-colourable.
2
117

Backstro m

Corollary 6.5
Corollary 6.6

Minimum Parallel Reordering is NP-hard.

Minimum Parallel Deordering and Minimum Parallel Reordering remain NP-hard even when restricted to totally ordered GT plans and under the as-

sumptions of unit time and simple concurrency.

Note that the restriction to denite input plans is covered by this corollary. If output
plans are also required to be denite, then the reordering case remains NP-hard.

Theorem 6.7

Minimum Parallel Reordering remains NP-hard also when the output

plan is restricted to be denite.

Proof: Reuse the proof for Theorem 6.4 as follows. Let r be a shortest parallel execution
for the plan Q and assume this execution is of length n. Construct an order 0 on A s.t.
for all actions a; b 2 A, a 0 b i r(a) < r(b). Obviously the plan hA; 0 ; #i is a denite

minimum parallel reordering of P . It follows that P has a denite parallel reordering of
length k i G is k-colourable.
2

It is an open question whether minimum deordering remains NP-hard when also output
plans must be denite, but an important special case is polynomial, as will be proven in
the next section.

Theorem 6.8

Minimum Parallel Deordering and Minimum Parallel Reorder-

ing are in NP C if validation of p.o. plans is in some complexity class

C.

Proof:

Given a plan hA; ; #i, a duration function d and a parameter k, guess a
de/reordering 0 and a release-time function r. Then verify, using an oracle for C , that
hA; 0 ; #i is valid. Finally, verify that r is a parallel execution of length  k, which is
polynomial according to Theorem 5.6.
2

Theorem 6.9 Minimum parallel de-/reordering is NP-complete if p.o. plans can be vali-

dated in polynomial time.

Proof: Immediate from Theorems 6.4 and 6.8 and Corollary 6.5.

2

The problems MmPD and MmPR are not only hard to solve optimally, but also to
approximate.

Theorem 6.10

Minimum Parallel Deordering and Minimum Parallel Reordering cannot be approximated within jAj1=7," for any " > 0, unless P=NP.

Proof:
Suppose there were a polynomial-time algorithm A approximating MmCD within
jAj1=7," for some " > 0. Then it is immediate from the proof of Theorem 6.4 that also
Graph K-Colourability could be approximated within jAj1=7," , which is impossible
unless P=NP (Bellare, Goldreich, & Sudan, 1995).

2

With the same reasoning, this bound can be strengthened to jAj1," , under the assumption
that co-RP6=NP (Feige & Kilian, 1996).
118

Computational Aspects of Reordering Plans

7. Restricted Cases
Since the problems of computing minimum de-/reorderings are very dicult, and are even
dicult to approximate, an alternative way of tackling them could be to study restricted
cases. One special case already considered is the restriction to denite plans only. While the
problem MmPR is still NP-complete under this restriction, it is an open question whether
also MmPD is NP-complete. A positive result can be proven, though, to the eect that
MmPD is polynomial for denite plans for a large class of planning languages, including
most of the commonly used ones. This result will be proven by generalising an algorithm
from the literature for deordering total-order plans.
Based on the (not necessarily true) argument that it is easier to generate a t.o. plan than
a p.o. plan when using complex action representations, Regnier and Fade (1991a, 1991b)
have presented an algorithm for converting a t.o. plan into a p.o. plan. The resulting plan
has the property that all its unordered actions can be executed in parallel, that is, the plan
is denite. The authors of the algorithm further claim that the algorithm nds all pairs
of actions that can be executed in parallel and, hence, the plan can be post-processed to
nd an optimal parallel execution. They do not dene what they mean by this criterion,
however.
Incidentally, the algorithm proposed by Regnier and Fade is a special case of an algorithm earlier proposed for the same problem by Pednault (1986), who did not make any
claims about optimality. If removing from Regnier and Fade's algorithm all details relevant
only for their particular implementation and planning language, the two algorithms coincide
and they are thus presented here as one single algorithm, the PRF algorithm4 (Figure 10).
PRF is slightly modied from the original algorithms. First, it does not assume that the input plan is totally ordered, since it turns out to be sucient that it is a denite partial-order
plan. Second, PRF returns a parallel plan, rather than a p.o. plan|a harmless modication since the only additional piece of information is the non-concurrency relation, which
is already given as input, either explicitly or implicitly. Third, PRF returns the transitive
closure of its ordering relation. This is by no means necessary, and is motivated, as usual,
by conforming to the denitions of this article.
1 procedure PRF;
2
Input: A ppi , a -valid denite p.o. plan hA; i and a non-concurrency
relation #
3
Output: A -valid parallel plan
4 for all a; b 2 A s.t. a  b do
5
if a#b then
6
Order a 0 b;
7 return hA; 0+ ; #i;

Figure 10: The PRF algorithm
Obviously, PRF computes a deordering of its input, and it is unclear whether it is possible to compute a minimal denite deordering in polynomial time. However, the algorithm
4. Here and afterwards, the algorithms from the literature will be referred to by acronyms consisting of the
initials of its authors, in this case Pednault, Regnier and Fade.

119

Backstro m

has been abstracted here to a very general formalism, and an analysis for restricted formalisms reveals more about its performance. The language used by Regnier and Fade is
unnecessarily restricted so the algorithm will be shown to work for a considerably more
general formalism, based on generalising and abstracting the concepts of producers, consumers and threats used in most common planners and planning languages, eg STRIPS and
TWEAK. This formalism will be referred to as the Producer-Consumer-Threat formalism
(PCT).
Let prod(a; ) denote that a produces the condition , cons(a; ) that a consumes  and
threat(a; ) that a is a threat to . To simplify the denitions, the standard transformation
will be used of simulating the initial and goal states with actions. That is, every PCT plan
contains an action ordered before all other actions which consumes nothing and produces
the initial state. Similarly, there is an action ordered after all other actions which consumes
the goal state and produces nothing. This means that the ppi is contained within the plan
itself, so all references to ppis can be omitted in the following. Validity of plans can then
be dened as follows.

Denition 7.1 A t.o. PCT plan ha1 ; : : : ; an i is valid i for all i, 1  i  n and all
conditions  s.t. cons(ai ; ), there is some j , 1  j < i s.t. prod(aj ; ) and there is no k,
j  k  i s.t. threat(ak ; ). A p.o. PCT plan is valid i all topological sortings of it are

valid.

Chapman's Modal-truth Criterion (MTC) (Chapman, 1987) can be abstracted to the
PCT formalism and be analogously used for validating p.o. plans.

Denition 7.2 The modal truth criterion (MTC) for a PCT plan hA; i is:
8aC 8(cons(aC ; ) !
9aP (prod(aP ; ) ^ aP  aC ^
8aT (threat(aT ; ) !
aC  aT _
9aW (prod(aW ; ) ^ aT  aW ^ aW  aC ))))
Theorem 7.3 The MTC holds for a PCT plan P i it is valid.
Proof: Trivial generalization of the proofs leading to Theorem 5.9 in Nebel and Backstrom

2

(1994).

Only a minimum of constraints for when two actions may not be executed in parallel
will be required. These constraints are obeyed by most planners in the AI literature.

Denition 7.4 Simple concurrency holds if for all actions a, b s.t. a 6= b, the nonconcurrency relation satises the following three conditions
1. prod(a; ) ^ cons(b; ) ! a#b
2. prod(a; ) ^ threat(b; ) ! a#b
3. cons(a; ) ^ threat(b; ) ! a#b
120

Computational Aspects of Reordering Plans

Note that it is not required that two producers, two consumers or two threats of the same
condition are non-concurrent, thus allowing, for instance, plans with multiple producers, eg
Nebel and Backstrom (1994, Fig. 4) and Kambhampati (1994). The axioms do not prevent
adding such restrictions, though. Furthermore, note that the denition only states a necessary condition for non-concurrency|it is perfectly legal to add further non-concurrency
constraints on the actions in a plan. It may also be worth noting that the MTC requires
producers and threats to be ordered only if there is a correpsonding consumer, while a
denite plan satisfying the simple concurrency criterion always require them to be ordered.
The following observation about PRF is immediate from the algorithm and will be used
in the proofs below.

Observation 7.5 If hA; ; #i is the input to PRF and hA; 0 ; #i is the corresponding
output, then it holds that a 0 b i a  b and a#b.
Based on this lemma, it can be proven that PRF preserves validity.

Lemma 7.6 If the plan input to PRF is a valid PCT plan and # satises the simple
concurrency criterion, then the output plan is valid.

Proof: Let P = hA; ; #i be the input plan and Q = hA; 0 ; #i the output plan. Since

P is valid, it follows from Theorem 7.3 that the MTC holds for P . Adding the implied
simple-concurrency constraints to the MTC yields the following condition:

8aC 8(cons(aC ; ) !
9aP (prod(aP ; ) ^ aP  aC ^ aP #aC ^
8aT (threat(aT ; ) !
(aC  aT ^ aC #aT )_
9aW (prod(aW ; )^aT  aW ^ aT #aW ^
aW  aC ^ aW #aC )))).
By applying Observation 7.5 this can be simplied to:

8aC 8(cons(aC ; ) !
9aP (prod(aP ; ) ^ aP 0 aC ^
8aT (threat(aT ; ) !
aC 0 aT _
9aW (prod(aW ; ) ^ aT 0 aW ^ aW 0 aC )))),
which is the MTC for the plan Q. Once again using Theorem 7.3, it follows that Q is valid.

2

This allows for proving that PRF produces denite minimum deorderings of denite PCT
plans under simple concurrency.

Theorem 7.7 If using the PCT formalism and simple concurrency, then PRF produces a
minimum-deordered denite version of its input.
121

Backstro m

Proof: Let P = hA; ; #i be the input plan, which is assumed valid and denite, and
Q = hA; 0 ; #i the output plan. It is obvious that 0  and it follows from Lemma 7.6 that

Q is valid, so Q is a deordering of P . It remains to prove that Q is a minimum deordering
of P .
Suppose that P has a deordering R = hA; 00 ; #i s.t. j 00 j < j 0 j. Then, there must
be some a; b 2 A s.t. a 0 b, but not a 00 b. It can be assumed that a 0 b is not

a transitive arc in 0 , since the transitive closure is anyway computed at the end of the
algorithm. Since the order 0 is produced by PRF, it follows from Observation 7.5 that
a  b and a#b. Because of the latter constraint, it is necessary that either, a 00 b or
b 00 a holds, but only the former is possible since a  b and R is a deordering of P . This
contradicts the assumption, so Q must be a minimum deordering of P .
2
Since PRF is a polynomial algorithm, it follows that denite minimum deorderings of
denite PCT plans can be computed in polynomial time under simple concurrency. Furthermore, since PRF produces denite plans it is possible to actually compute the shortest
parallel execution eciently.

Theorem 7.8 If the plan input to PRF is a valid and denite PCT plan satisfying the
simple concurrency criterion, then PRF outputs a denite minimum deordering of this plan.

Proof: PRF runs in polynomial time and obviously produces denite parallel plans.
Hence, it follows from Theorem 5.11 that a minimum parallel execution for the output plan
can be found in polynomial time, which proves the theorem.
2

It seems likely that this is what Regnier and Fade meant with their optimality claim, although for a special instance of the PCT formalism. This result says nothing about the
diculty of nding a minimum reordering of a plan, since PRF only considers deorderings.
Since minimum deorderings do not approximate minimum reorderings well, it can be suspected that it is more dicult to compute the latter. The following theorem conrms this
suspicion, showing that the latter problem remains NP-hard under quite severe restrictions,
including the following two.

Denition 7.9 A GT action a is toggling i for all literals l 2 post(a), it is also the case
that :l 2 pre(a). A GT action a is unary i jpost(a)j = 1.
Theorem 7.10 Minimum Parallel Reordering remains NP-hard even when restricted

to total-order GT plans with only toggling unary actions and under the assumption of unit
time, simple concurrency and that no actions are redundant.

The proof of this theorem appears in Appendix A.
While minimum reorderings are more dicult to compute than minimum deorderings,
they can also produce arbitrarily better results.

Theorem 7.11

Minimum Parallel Deordering cannot approximate Minimum Parallel Reordering within jAjk for any constant k  0.

The proof of this theorem appears in Appendix A.
122

Computational Aspects of Reordering Plans

Corollary 7.12 Minimum Parallel Deordering cannot approximate Minimum Parallel Reordering within jAjk for any constant k  0 even when the problems are restricted to GT plans with only positive preconditions and under the assumption of simple
concurrency.

It may, thus, appear as though minimum reordering is a preferable, albeit more costly,
operation than minimum deordering. However, if the plan modication is to be followed
by scheduling, it is no longer obvious that a reordering is to prefer. Since scheduling may
take further information and constraints into account, eg upper and lower bounds on the
release time and limited resources, a feasible schedule for the original plan may no longer be
a feasible schedule for a reordering of the same plan. That is, some or all feasible solutions
may be lost when reordering a plan. In contrast to this, deordering a plan is harmless
since all previously feasible schedules are preserved in the deordering. Of course, the de/reordered plan may have new and better schedules than the old plan, which is why the
problems studied in this article are interesting at all. However, while minimum deordering
is a safe and, usually cheap, operation, minimum reordering is neither and must thus be
applied with more care. To nd a reordering of a plan with an optimum schedule would
require combining minimum reordering and scheduling into one single computation, but it
is out of the scope of this article to study such combinations. Suce it to observe that such
a computation is never cheaper than either of its constituent computations.

8. Related work
This section analyses and discusses some algorithms suggested in the literature for generalising the ordering of a plan, in addition to the PRF algorithm already analysed in the
preceeding section. Also some planners that generate plans with some optimality avour
on the ordering are discussed.
Some of the algorithms to be analysed use the common trick of simulating the initial
state and the goal of a planning instance by two extra operators, in the following way. Let
P = hA; i be a plan and  = hI; Gi a ppi, both in the GT language. Introduce two extra
actions aI , with pre(aI ) = ; and post(aI ) = I , and aG , with pre(aG ) = G and post(aG ) = ;.
Dene the plan Q = hA [ faI ; aG g; 0 i where 0 = [faI  a; a  aG j a 2 Ag[faI  aG g,
that is aI is ordered before all other actions and aG is ordered after all other actions. The
plan Q is a representation of both the plan P and the ppi . Such a combined representation
will be referred to as a self-contained plan. A self-contained plan is valid i it is valid wrt.
to the ppi h;; ;i. It is trivial to convert a plan and a ppi into a corresponding self-contained
plan and vice versa. Hence, both ways of representing a plan will be used alternately
without further notice.

8.1 The VPC Algorithm

Veloso et al. (1990) have presented an algorithm (here referred to as VPC5 ) for converting
t.o. plans into `least-constrained' p.o. plans. They use the algorithm in the following context.
First a total-order planner (NoLimit) is used to produce a t.o. plan. VPC converts this plan
5. In the original publication the algorithm was named Build Partial Order.

123

Backstro m

1 procedure VPC;
2
Input: a valid self-contained t.o. plan ha1 ; : : : ; an i
where a1 = aI and an = aG
3
Output: A self-contained valid p.o. plan
4 for 1  i  n do
5
for p 2 pre(ai ) do
6
Find max k < i s.t. p 2 post(ak );
7
if such a k exists then
8
Order ak  ai
9
for :p 2 post(ai ) do
10
for 1  k < i s.t. p 2 pre(ak ) do
11
Order ak  ai
12
for each primary eect p 2 post(ai ) do
13
for 1  k  i s.t. :p 2 post(ak ) do
14
Order ai  ak
15
for 1 < i < n do
16
Order aI  ai and ai  aG
17
return hfa1; : : : ; ang; +i;

Figure 11: The VPC algorithm
into a p.o. plan which is then post-processed to determine which actions can be executed
in parallel. The action language used is a STRIPS-style language allowing quantiers and
context-dependent eects. However, the plans produced by the planner, and thus input
to VPC, are ground and without context-dependent eects. That is, they are ordinary
propositional STRIPS plans. The VPC algorithm is presented in Figure 11, with a few minor
dierences in presentation as compared to its original appearance: First, the algorithm is
presented in the GT formalism, in order to minimize the number of formalisms in this article,
but all preconditions are assumed to be positive, thus coinciding with the original algorithm.
Second, while the original algorithm returns the transitive reduction of the computed order
it instead returns the transitive closure here, an unimportant dierence in order to coincide
with the denition of plans in this article. Furthermore, Veloso6 has pointed out that the
published version of the VPC algorithm is incorrect and that a corrected version exists.
The version presented in Figure 11 is this corrected version. A proposition is a primary
eect if it appears either in the goal or in the subgoaling chain of a goal proposition.
VPC is a greedy algorithm which constructs an entirely new partial order by analysing
the action conditions, using the original total order only to guide the greedy strategy. The
algorithm is claimed (Veloso et al., 1990, p. 207) to produce a `least-constrained' p.o. plan,
although no denition is given of what this means. Veloso7 has conrmed that the term `least
constrained plan' was used in a `loose sense' and no optimality claim was intended. However,
if this term is not dened, then it is impossible to know what problem the algorithm is
intended to solve or how to judge whether it makes any improvement over using no algorithm
at all. In the absence of such a denition from its authors, the algorithm will be analysed
with respect to the least-constrainment criteria dened in Section 4. This is admittedly a
6. Personal communication, oct. 1993.
7. Veloso, ibid.

124

Computational Aspects of Reordering Plans

p
q
1

b r


p 
a 
Pq 
PPP
PP
qc s
P1

a pq

q

-p b qr

-q c s

P2

Figure 12: The p.o. plans in the failure example for VPC.
somewhat unfair analysis, but it reveals some interesting facts about the algorithm, and
about what problems it does not solve. It is immediate from Theorem 4.8 and Corollary 4.9
that VPC cannot be expected to produce minimum-constrained de-/reorderings. Perhaps
more surprisingly, VPC does not even guarantee that its output is a minimal -constrained
deordering of its input, a problem already proven trivially polynomial (Theorem 4.4). This
is illustrated by the following example.
Suppose a total-order planner is given the ppi  = h;; fr; sgi as input. It may then
return either of the -valid t.o. plans ha; b; ci and ha; c; bi, with action conditions as shown
in Figure 12. When used as input to VPC, these two t.o. plans will give quite dierent results|the plan ha; c; bi will be converted to the p.o. plan P1 in Figure 12, while
the plan ha; b; ci will be converted to the p.o. plan P2 in Figure 12. That is, in the rst
case VPC produces a plan which is not only a minimal-constrained deordering but even
a minimum-constrained deordering, while in the second case it does not even produce a
minimal-constrained deordering.8
The reason that VPC may fail to produce a minimal-constrained deordering is that it
uses a non-admissible greedy strategy. Whenever it needs to nd an operator a achieving
an eect required by the precondition of another operator b, it chooses the last such action
ordered before b in the input t.o. plan. However, there may be other actions earlier in the
plan having the same eect and being a better choice.

8.2 The KK algorithm

Kambhampati and Kedar (1994) have presented an algorithm for generalising the ordering of a p.o. plan, using explanation-based generalisation. The algorithm is based on rst
constructing a validation structure for the plan and then use this as a guide in the generalisation phase. In the original paper, these computations are divided into two separate
algorithms (EXP-MTC and EXP-ORD-GEN), but are here compacted into one single algorithm, KK (Figure 13). Furthermore, the version presented here is restricted to ground
GT plans, while the original algorithm can also handle partially instantiated plans. This is
no restriction for the results to be shown below.
The rst part of the KK algorithm constructs a validation structure V for the plan, that
is, an explanation for each precondition of every action in the plan. The validity criterion
underlying this phase is a simplied version of Chapmans modal-truth criterion (Chapman,
8. Note that transitive arcs are omitted in the gures, so P2 really has an ordering relation of size three.
Although this example would not work if plans had been dened in the equally reasonable way that
ordering relations should be intransitive, it is possible to construe similar examples also for this case.

125

Backstro m

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20

procedure KK

Input: A valid self-contained p.o. plan hA; i
Output: A deordering of the input plan
comment Build a validation structure V for the plan

V

;

Let ha1 ; : : : ; an i be a topologically sorted version of hA; i
for 1  i  n do
for p 2 pre(ai ) do
Find min k < i s.t.
1. p 2 post(ak ) and
2. there is no j s.t. k < j < i and :p 2 post(aj )
Add hak ; p; ai i to V
comment Construct a generalised ordering 0 for the plan
for each ha; bi 2 do
Add ha; bi to 0 if either of the following holds
1. a = aI or a = aG
2. ha; p; bi 2 V for some p
3. hc; p; ai 2 V and :p 2 post(b)
4. hb; p; ci 2 V and :p 2 post(a)

return hA; 0i

Figure 13: The KK algorithm
1987) without white knights. Since the algorithm is simplied to only handle ground plans
here, an explanation is a causal link haP ; p; aC i, meaning that the action aP produces the
condition p which is consumed by the action aC . The algorithm constructs exactly one
causal link for each precondition, and it chooses the earliest producer of p preceeding aC
with no intervening action producing :p between this producer and aC . The second phase
of the algorithm builds a generalised ordering 0 for the plan based on this validation
structure. To put things simply, only those orderings of the original plan are kept which
either correspond to a causal link in the validation structure or that is required to prevent
a threatening action to be unordered wrt. the actions in such a causal link.
It turns out that also the KK algorithm fails in generating plans that are guaranteed to be even minimal-constrained deorderings. Consider the t.o. plan hA; B; C; Di
with action conditions as indicated in Figure 14. This t.o. plan is valid for the ppi
h;; fr; s; t; ugi. Since the KK algorithm always chooses the earliest possible producer
of a precondition for the validation structure, it will build the validation structure
fhA; p; Di; hA; s; aG i; hB; q; Di; hB; t; aG i; hC; r; aG i; hD; u; aG ig. Hence, the nal ordering
produced by KK will be as shown in Figure 14a. However, this plan is not a minimalconstrained deordering of the original plan, since it can be further deordered as shown in
Figure 14b and remain valid. In this example, the input plan was totally ordered. In the
case of partially ordered input plans, the behaviour of the algorithm depends on the particular topological order choosen. So the algorithm may or may not nd a minimal-constrained
deordering, but it is impossible to guarantee that it will succeed for all plans. Similarly, the
authors mention that one may consider dierent ways of constructing the validation struc126

Computational Aspects of Reordering Plans

ture. This would clearly also modify the behaviour and it remains an open question whether
it is possible to generate, in polynomial time, a validation structure that guarantees that a
minimal-constrained deordering is constructed in the second phase of the algorithm. Finding a validation structure that guarantees a minimum-constrained deordering is obviously
an NP-hard problem since the second phase of the algorithm is polynomial.
A ps

A ps

ZZ

B qt

ZZ~-p
q

p
r

D u

C q

a) Plan produced by KK

q

D u

B qt

C pq

r

-p

b) Minimal deordered version of a

Figure 14: Failure example for the KK algorithm

8.3 Planners with Optimality Guarantees
The planning algorithm Graphplan (Blum & Furst, 1997) has a notion of time steps and
tries to pack as many non-interacting actions as possible into one single time step. Furthermore, Graphplan nds the shortest plan, using the number of time steps as the measure.
If assuming unit time and that all actions considered as non-interacting by Graphplan
can be executed in parallel, then there is no plan having a shorter parallel execution than
the plan produced by Graphplan. That is, Graphplan produces minimum reordered
parallel plans under these assumptions. The second assumption is no limitation in practice,
since each non-concurrency relation can be encoded by introducing a new atom and letting
one of the interacting actions add it while the other one deletes it. The unit time assumption is more serious, however, especially since this assumption is likely not to hold in most
applications. In the car-assembly scenario in Section 2, for instance, Graphplan would
produce a plan that corresponds to the plan in Figure 5. Hence, the plan produced under
the unit-time assumption happens to coincide with the optimal plan when taking actual
execution times into account. This is just a fortunate coincidence, however, depending on
the particular durations of actions in this example. Suppose instead that the durations of
the actions are slightly dierent such that PAC has duration 2 and MvT1 has duration 8.
Then the plan produced by Graphplan, which corresponds to the plan in Figure 5, does
not have a faster schedule than 19 time units. This is not optimal since the plan in Figure 4
can be scheduled to execute in 17 time units for these particular duration times. Furthermore, it must be remembered that Graphplan is anyway restricted to those cases where
a GT-equivalent planning language is sucient, although recent improvements extend it to
127

Backstro m

somewhat more expressive languages (Gazen & Knoblock, 1997; Kohler, Nebel, Homan,
& Dimopoulos, 1997).
Knoblock (1994) has modied the UCPOP planner with a resource concept which makes
it avoid unordered interacting actions. This means that the resulting planner produces
denite parallel plans. Knoblock further modied the evaluation heuristic of the search to
take parallel execution time into account. It thus seems as if this planner might be able to
produce minimum reordered parallel plans, but the paper does not provide sucient details
to determine whether this is the case. It is also unclear whether the heuristic can handle
actions with dierent duration times.
Yet another example is the polynomial-time planner for the SAS+-IAO planning language (Jonsson & Backstrom, 1998) which produces plans which are minimum-constrained
reordered. That is, for this restricted formalism it is clearly possible to optimise the ordering
in polynomial time.

9. Discussion
The previous section listed a few planning algorithms from the literature that produce or
attempt to produce plans which are least constrained or minimum parallel reordered. They
do so only under certain restrictions, though. Furthermore, plans are not always generated
`from scratch', but can also be generated by modifying some already existing plan, referred
to as case-based planning, or by repairing a plan that has failed during the execution phase.
In such cases, the old plan may contain many ordering relations that will be obsolete in
the modied/repaired plan. In fact, the KK algorithm (Kambhampati & Kedar, 1994) is
motivated in the context of case-based planning. It is also important to remember that
today, and probably for a long time into the future, very few plans are generated entirely
by computer programs. The vast majority of plans in various applications are designed by
humans, possibly with computer support. Already for quite small plans, it is very dicult
for a human to see whether the ordering constraints are optimal or not, so computer support
for such analyses is vital for designing optimal plans. For the same reason, also hierarchicaltask-network planners, eg O-Plan (Currie & Tate, 1991) and Sipe (Wilkins, 1988), produce
plans where reordering actions could lead to better schedules. Such a planner often commits
to one of the two possible orderings for a pair of actions based on expert-knowledge rules.
However, it is hardly possible for a human expert to design rules that in all situations will
guarantee that the optimal ordering choice is made.
On the coarseness level of complexity analysis it does not matter whether the tasks
of planning, plan optimization and scheduling are integrated or separated since the total
resulting complexity will be the same in both cases|the latter two computations are at most
NP-complete and will, thus, be dominated by the planning, which is PSPACE-complete or
worse. However, for good reasons this has not prevented the research community from
studying planning and scheduling as separate problems, since understanding each problem
in isolation also helps understanding the overall process. For the same reason, it is important
to also study separately the problems discussed and analysed in this article. Furthermore,
on a more ne-grained, practical level there might be considerable dierences in eciency
between integrating the three computations and doing them separately. For instance, even
if all three computations take exponential time, each of the problems considered in isolation
128

Computational Aspects of Reordering Plans

may have fewer parameters, in which case it may be much more ecient to solve them in
isolation. On the other hand, solving the whole problem at once may make it easier to
do global optimisation. Which is the better will depend both on which methods are used
and on various properties of the actual application, and it seems unlikely that one of the
methods should always be the better.
As has been shown in this article, minimum reordering is a much better optimality
criterion than minimum deordering, if only considering the overall parallel execution time.
However, this is not necessarily true if also considering further metric constraints for subsequent scheduling. Deordering a plan can only add to the number of feasible schedules, while
reordering may also remove some or, in the worst case, all feasible schedules. On the other
hand, reordering may also lead to new and better schedules not reachable via deordering.
Deordering can thus be viewed as a safe and, sometimes, cheap way to allow for better
schedules, while reordering is an expensive method which has a potential for generating
considerably better plans, but which may also make things worse. If using reordering in
practice in cases where also metric scheduling constraints are involved, it seems necessary
to use feedback from the scheduler to control the reordering process, or to try other reorderings. One could imagine a reordering algorithm which uses either heuristic search or
randomized local-search methods a la GSAT (Selman, Levesque, & Mitchell, 1992) to nd
reorderings and then use the scheduler as evaluation function for the proposed reorderings.
While the plan modications studied in this article may add considerably to the optimizations that are possible with traditional scheduling only, there is still a further potential
of optimization left to study|modifying not only the action order, but also the set of actions. Such modication is already done in plan adaptation, but then only for generating a
new plan from old cases, and optimizations in the sense of this article are not considered.
Some preliminary studies of action-set modications appear in the literature, though. Fink
and Yang (1992) study the problem of removing redundant actions from total-order plans,
dening a spectrum of redundancy criteria and analysing the complexity of achieving these.
It is less clear that it is interesting to study action addition; adding actions to a plan could
obviously not improve the execution time of it if it is to be executed sequentially. However,
in the case of parallel execution of plans it has been shown that adding actions to a plan can
sometimes allow for faster execution (Backstrom, 1994). Finally, if allowing both removal
and addition of actions, an even greater potential for optimising plans seems available, but
this problems seems not yet studied in the literature.

10. Conclusions
This article studies the problem of modifying the action ordering of a plan in order to
optimise the plan according to various criteria. One of these criteria is to make a plan
less constrained and the other is to minimize its parallel execution time. Three candidate
denitions are proposed for the rst of these criteria, constituting a spectrum of increasing
optimality guarantees. Two of these are based on deordering plans, which means that ordering relations may only be removed, not added, while the last one builds on reordering,
where arbitrary modications to the ordering are allowed. The rst of the three candidates,
subset-minimal deordering, is tractable to achieve, while the other two, deordering or re129

Backstro m

ordering a plan to minimize the size of the ordering, are both NP-hard and even dicult
to approximate.
Similarly, optimising the parallel execution time of a plan is studied both for deordering
and reordering of plans. In the general case, both of these computations are NP-hard and
dicult to approximate. However, based on an algorithm from the literature it is shown
that optimal deorderings can be computed in polynomial time for denite plans for a class
of planning languages based on the notions of producers, consumers and threats, which
includes most of the commonly used planning languages. Computing optimal reorderings
can potentially lead to even faster parallel executions, but this problem remains NP-hard
and dicult to approximate even under quite severe restrictions. Furthermore, deordering
a plan is safe with respect to subsequent scheduling, while reordering a plan may remove
feasible schedules, making deordering a good, but often suboptimal, approach in practice.

Acknowledgements

Tom Bylander, Thomas Drakengren, Mark Drummond, Alexander Horz, Peter Jonsson,
Bernhard Nebel, Erik Sandewall, Sylvie Thibeaux and the anonymous referees provided
helpful comments on this article and previous versions of it. The research was supported
by the Swedish Research Council for Engineering Sciences (TFR) under grants Dnr. 92-143
and 95-731.

Appendix A

Theorem 7.10 Minimum Parallel Reordering remains NP-hard even when restricted

to total-order GT plans with only toggling unary actions and under the assumption of unit
time, simple concurrency and that no actions are redundant.

Proof: Proof by reduction from 3SAT (Garey & Johnson, 1979, p. 259). Let P =
fp1 ; : : : ; png be a set of atoms and C = fC1 ; : : : ; Cm g a set of clauses over P s.t. for
1  i  m, Ci = fli;1 ; li;2 ; li;3 g is a set of three literals over P .
First dene the set of atoms

Q = fpFi ; pTi ; qi j 1  i  ng [ fci;j ; ri;j j 1  i  n; 1  j  3g:
Then dene a GT ppi  = hI; Gi with initial and goal states dened as
I = Neg(Q)
G = fpFi ; pTi ; :qi j 1  i  ng [ fci;j ; :ri;j j 1  i  n; 1  j  3g
Also, for each atom pi 2 P , dene four actions according to Table 2.
Further, for each clause Ci 2 C , dene nine actions according to Table 3 where
( F

l = pk if li;j = :pk
i;j

pTk

if li;j = pk :

Let A be the set of all 4n + 9m actions thus dened. Clearly there is some total order 
s.t. the plan P = hA; i is -valid. It is also obvious that none of the actions is redundant.
130

Computational Aspects of Reordering Plans

It is a trivial observation that any parallel execution r of any -valid reordering of P
must satisfy that for each i, 1  i  n, either

r(AFi ) < r(A+i ) < r(ATi ) < r(A,i )
or
and for each i, 1  i  m,

r (C +

i;k1

r(A+i ) < r(ATi ) < r(A,i ) < r(AFi );

( , )
, ))
r
(Ci;k
r(Ci;k2 )
+
+
,
1
i;k1 ) < r(C + ) < r(Bi;k2 ) < r(C + ) < r(Bi;k3 ) < r(Ci;k3 );
i;k2
i;k3

) < r(B +

(

where k1 ; k2 ; k3 is a permutation of the numbers 1; 2; 3. (This is to be interpreted s.t. the
, and C + can be released in either order, or simultaneously, and analogously
actions Ci;k
i;k2
1
, and
+ ).
for the actions Ci;k
Ci;k
2
3
The remainder of this proof shall show that P can be reordered to have a parallel
execution of length 8 i the set C of clauses is satisable.
if: Suppose C is satisable. Let I be a truth assignment for the atoms in P that satises
C . Wlg. assume I (pi ) = T for all i. Further, for each clause Cj , let lj be any literal in Cj
which is satised by I . Disregarding the action order for a moment, choose a release-time
function r for the actions as follows. For 1  i  n, let

r(A+i ) = 0; r(ATi ) = 1; r(A,i ) = 2; r(AFi ) = 3:
Further, for each j , 1  j  m, choose k1 s.t. lj;k1 2 Cj is satised by I (at least one such
choice must exist by the assumption). Let lj;k2 and lj;k3 be the remaining two literals in Cj .
Assign release times s.t. for 1  h  3,
+ ) = 2h , 1; r (B + ) = 2h ; r (C , ) = 2h + 1:
r(Cj;k
j;kh
j;kh
h

Now dene the partial order 0 on A s.t. for all actions a; b 2 A, a 0 b i r(a) < r(b).
Clearly, the plan hA; 0 i is a -valid reordering of P and r is a parallel execution of length
8 for hA; 0 i. (Note that no other choice of I could force a longer execution, while there is
an execution of length 7 in the case where C is satised by setting all atoms false.)
operator precond. postcond.

AFi
ATi
A+i
A,i

:pFi ; :qi pFi
:pTi ; qi pTi
:qi
qi
qi
:qi

Table 2: Generic actions for each atom pi in the proof of Theorem 7.10.
131

Backstro m

operator precond.

Bi;+1
Bi;+2
Bi;+3
Ci;+1
Ci;,1
Ci;+2
Ci;,2
Ci;+3
Ci;,3

li; 1; ri;1 ; :ri;2 ; :r1;3 ; :ci;1
li; 2; :ri;1; ri;2 ; :r1;3 ; :ci;2
li; 3; :ri;1; :ri;2; r1;3 ; :ci;3
:ri;1
ri;1
:ri;2
ri;2
:ri;3
ri;3

postcond.

ci;1
ci;2
ci;3
ri;1
:ri;1
ri;2
:ri;2
ri;3
:ri;3

Table 3: Generic atoms for each clause Ci in the proof of Theorem 7.10.
only if: Suppose C is not satisable. Further suppose that Q is a minimum reordering
of P and that r is a parallel execution of length 8 or shorter for Q. Wlg. assume that every
action is released as early as possible by r. Then, according to the observation above it
must hold for each i, 1  i  n, that either
r(AFi ) = 0; r(A+i ) = 1; r(ATi ) = 2; r(A,i ) = 3
or
r(A+i ) = 0; r(ATi ) = 1; r(A,i ) = 2; r(AFi ) = 3:
Hence, exactly one of the atoms pFi and pTi is true at time 2. Let pi denote this atom. Since
+)2
r is of length 8, it follows from the earlier observation that for all j , 1  j  m, r(Bj;k
for some k, 1  k  3. Hence, lj;k = pi for some i, since Q is -valid and r is a parallel
execution for Q. Dene an interpretation I s.t. for all i, 1  i  n,
(
if pi = pFi
I (pi ) = F;
T; otherwise :
However, this interpretation is obviously a model for C , which contradicts the assumption.
It follows that r must be of length 9 or longer.
This concludes the proof and shows that C is satisable i P has a reordering with a
parallel execution of length 8 or not.
2

Theorem 7.11

Minimum Parallel Deordering cannot approximate Minimum
Parallel Reordering within jAjk for any constant k  0.

Proof: The proof assumes GT plans and simple concurrency. First, dene the generic

actions aki (m), bki and cki (m) according to Table 10. Further, dene recursively the generic
plans
( 1
ha
(1); b0
; c1
(1); : : : ; a1im (1); b0im ; c1im (1)i;
for k = 1
k
Pi (m) = ha(ki,1)m+1 (m); P(i,k1),1m+1 ((mi,);1)cmk+1
k
,
1
k
k
1 (m); : : : ; aim (m); Pim (m); cim (m)i; for k > 1:
(i,1)m+1
(i,1)m+1
132

Computational Aspects of Reordering Plans

Furthermore, for arbitrary k; n > 0 dene the ppi kn = hfpk1 ; : : : ; pkn g; fq1k ; : : : ; qnk gi.
Now, prove the claim that for arbitrary k; n > 0, the plan P1k (n)
1. is kn -valid,
P ,1 2ni and
2. has no deordering of length less than 3nk + ki=1
3. has a reordering of length 2k + 1.
Proof by induction over k.
Base case (k=1): Choose an arbitrary n > 0. The plan P11 (n) is obviously kn -valid and
has no deordering other than itself, which is of length 3n. Consider the reordering Q11 (n) of
P11 (n) with the same actions and with ordering relation  dened s.t. for all i, 1  i  n,
a1i (1)  b0i  c1i (1) and for all i, 1 < i  n, a1i (1)  b0i,1 . This reordering is k (n)-valid and
has a parallel execution r11 (n) of length 3, dened s.t. for all i, 1  i  n, r11 (n)(a1i (1)) = 1,
r11(n)(b0i ) = 2 and r11 (n)(c1i (1)) = 3. (This plan is shown in Figure 15.) The claim is thus
satised for the base case.
Induction: Suppose the claim is satised for all l < k, for some k  1 and prove that
the claim holds also for l = k. Choose an arbitrary n > 0. It follows from the induction
hypothesis that none of the subplans P1k,1 (n) : : : ; Pnk,1 (n) can be deordered, so they have
to remain totally ordered. Furthermore, for all i, 1  i  n, it is necessary that the action
aki (n) is ordered before the subplan Pik,1(n) and that the action cki (n) is ordered after it.
It is also clear that for no i, 1  i  n can the order cki (n)  aki+1 (n) be removed without
making the plan invalid. Hence, P1k (n) has no other deordering than itself, which is of
length
n
X
i=1

(2 + length(Pik,1 (n)) = n(2 + length(P1k,1 (n)))

= 2n + n(3nk,1 +

kX
,2
i=1

2ni ) = 3nk +

kX
,1
i=1

2ni ;

which proves the deordering case of the claim.
For the reordering case, dene a reordering Qk1 (n) of P1k (n) with the same actions and
with ordering relation dened as follows. For each subplan Pik,1 (n) of P1k (n), reorder its
actions so it has length 2(k , 1)+1, which is possible according to the induction hypothesis.
Further, for each i, 1  i  n, and each j , (i , 1)n + 1  j  in order aki (n)  akj ,1 (n) and
ckj ,1 (n)  cki (n) (or aki+1 (n)  akj ,1 (1) and ckj ,1 (1)  cki (n) for the case k = 2). Hence, each
action pre-condition

post-condition

aki (m) fpki g
fpk(i,,11)m+1 ; : : : ; pkim,1; :q(ki,,11)m g
bki
fpki g
fqik g
k,1 g post(ck (m)) = fqk g:
cki (m) fq(ki,,11)m+1 ; : : : ; qim
i
i
Table 4: Generic actions for the proof of Theorem 7.11.
133

Backstro m

P11 (n)
a11 (1)

a21 (n)


,
@


,,
1
,
p1
, : a1(1)
1 
,
2
p
2

@
p1n@@

...
.
:. q0

p01

:q10
p02
:q20

(n,1)

@@
R a1n(1)



p0n



b01

-

b02

-

b0n

...
..

q10

- c11(1)

@

@@q11
q20 - 1
c2 (1) XXXq21@
X@XXz@R c21(n)
...
,,
,
.
,qn1
,
0
qn - 1 ,
1 cn(1)





:qn1 
..
:



.

2

.
a2 (n) XXXX..
z
X
 :


 .
..
...
...
.
1
:q(1n,1) 
:
.

X
a2n (n) 
XXX...X
z

P21 (n)

Pn1 (n)

X..XXXXz 2
..: c2(n)
...
..

X..XXXXz 2
.
.: cn(n)

Figure 15: The reordering Q21 (n) of the plan P12 (n) as an example of the induction case in
the proof of Theorem 7.11 (solid arrows denote orderings required by producerconsumer relationships and are labelled with the atom produced/consumed,
while dashed arrows denote ordering constraints to avoid threats and are labelled with the possibly conicting atom).
segment of the type aki (n); Pik,1 (n); cki (n) is reordered to have length 2k + 1. Finally, for
each i, 1  i  n, order aki (n)  ak(i,,11)n (n) (or aki (n)  ak(i,,11)n (1) for the case k = 2). The
plan Qk1 (n) is k (n)-valid since the subplans P1k,1 (n); : : : ; Pnk,1 (n) do not have any atoms
in common and, thus, the # relation does not hold between any two actions belonging to
dierent such subplans. This reordered plan can be executed under the parallel execution
rik (n) dened s.t. rik (n)(aki (n)) = 1, rik (n)(cki (n)) = 2k + 1 and for all i, 1  i  n and
all actions a0 2 Qki ,1 (n), rik (n)(a0 ) = rik,1(n)(a0 ) + 1. Since this is a parallel execution of
length 2k + 1 for the reordered plan, the claim holds also for k.
This concludes the induction, so the claim holds for all k > 0. Since
P ,1 2ni
3nk + ki=1
1
k

2k + 1
(2k + 1)3k,1 jAj
for all k > 0, the theorem holds.
2
134

Computational Aspects of Reordering Plans

References

Backstrom, C. (1993). Finding least constrained plans and optimal parallel executions is
harder than we thought. In Backstrom, C., & Sandewall, E. (Eds.), Current Trends in
AI Planning: EWSP'93|2nd European Workshop on Planning, pp. 46{59 Vadstena,
Sweden. IOS Press.
Backstrom, C. (1994). Executing parallel plans faster by adding actions. In Cohn,
A. G. (Ed.), Proceedings of the 11th European Conference on Articial Intelligence
(ECAI'94), pp. 615{619 Amsterdam, Netherlands. Wiley.
Backstrom, C. (1995). Expressive equivalence of planning formalisms. Articial Intelligence,
76 (1{2), 17{34.
Backstrom, C., & Klein, I. (1991). Parallel non-binary planning in polynomial time. In
Reiter, R., & Mylopoulos, J. (Eds.), Proceedings of the 12th International Joint Conference on Articial Intelligence (IJCAI'91), pp. 268{273 Sydney, Australia. Morgan
Kaufmann.
Bellare, M., Goldreich, O., & Sudan, M. (1995). Free bits, PCPs and non-approximability|
towards tighter results. In Proceedings of the 36th Annual IEEE Symposium on the
Foundations of Computer Science (FOCS'95), pp. 422{431 Milwaukee, WI, USA.
IEEE Computer Society.
Blum, A. L., & Furst, M. L. (1997). Fast planning through planning graph analysis. Articial
Intelligence, 90 (1{2), 281{300.
Chapman, D. (1987). Planning for conjunctive goals. Articial Intelligence, 32 (3), 333{377.
Crescenzi, P., & Panconesi, A. (1991). Completeness in approximation classes. Information
and Computation, 93 (2), 241{262.
Currie, K., & Tate, A. (1991). O-Plan: The open planning architecture. Articial Intelligence, 52 (1), 49{86.
Feige, U., & Kilian, J. (1996). Zero knowledge and the chromatic number. In 11th Annual
IEEE Conference on Computational Compelxity (CCC'96) Philadelphia, PA, USA.
IEEE Computer Society.
Feige, U. (1996). A threshold of ln n for approximating set cover (preliminary version). In
Proceedings of 28th Annual ACM Symposium on Theory of Computing (STOC'96),
pp. 314{318 Philadelphia, PA, USA. ACM.
Fink, E., & Yang, Q. (1992). Formalizing plan justications. In Proceedings of the 9th Conference of the Canadian Society for Computational Studies of Intelligence (CSCSI'92),
pp. 9{14 Vancouver, BC, Canada.
Garey, M., & Johnson, D. (1979). Computers and Intractability: A Guide to the Theory of
NP-Completeness. Freeman, New York.
135

Backstro m

Gazen, C., & Knoblock, C. (1997). Combining the expressivity of UCPOP with the eciency
of Graphplan. In Steel, & Alami (1997), pp. 221{233.
Ghallab, M., & Laruelle, H. (1994). Representation and control in IxTeT, a temporal
planner. In Hammond (1994), pp. 61{67.
Hammond, K. (Ed.). (1994). Proceedings of the 2nd International Conference on Articial
Intelligence Planning Systems (AIPS'94), Chicago, IL, USA. AAAI Press.
Jonsson, P., & Backstrom, C. (1998). State-variable planning under structural restrictions:
Algorithms and complexity. Articial Intelligence, 100 (1{2), 125{176.
Kambhampati, S. (1994). Multi-contributor causal structures for planning: A formalization
and evaluation. Articial Intelligence, 69 (1{2), 235{278.
Kambhampati, S., & Kedar, S. (1994). A unied framework for explanation-based generalization of partially ordered and partially instantiated plans. Articial Intelligence,
67 (1), 29{70.
Klein, I., Jonsson, P., & Backstrom, C. (1995). Tractable planning for an assembly line.
In Ghallab, M., & Milani, A. (Eds.), New Directions in AI Planning: EWSP'95|
3rd European Workshop on Planning, Frontiers in AI and Applications, pp. 313{324
Assisi, Italy. IOS Press.
Klein, I., Jonsson, P., & Backstrom, C. (1998). Ecient planning for a miniature assembly
line. Articial Intelligence in Engineering, 13 (1), 69{81.
Knoblock, C. (1994). Generating parallel execution plans with a partial-order planner. In
Hammond (1994).
Kohler, J., Nebel, B., Homan, J., & Dimopoulos, Y. (1997). Extending planning graphs
to an ADL subset. In Steel, & Alami (1997), pp. 273{285.
Lund, C., & Yannakakis, M. (1994). On the hardness of approximating minimization problems. Journal of the ACM, 41 (5), 960{981.
Nebel, B., & Backstrom, C. (1994). On the computational complexity of temporal projection, planning and plan validation. Articial Intelligence, 66 (1), 125{160.
Pednault, E. P. D. (1986). Formulating multiagent, dynamic-world problems in the classical
planning framework. In George, M., & Lansky, A. L. (Eds.), Reasoning about Actions and Plans, Proceedings of the 1986 Workshop, pp. 47{82 Timberline, OR, USA.
Morgan Kaufmann.
Regnier, P., & Fade, B. (1991a). Complete determination of parallel actions and temporal
optimization in linear plans of action. In Hertzberg, J. (Ed.), European Workshop
on Planning, Vol. 522 of Lecture Notes in Articial Intelligence, pp. 100{111 Sankt
Augustin, Germany. Springer.
136

Computational Aspects of Reordering Plans

Regnier, P., & Fade, B. (1991b). Determination du parallelisme maximal et optimisation
temporelle dans les plans d'actions lineaires. Revue d'intelligence articielle, 5 (2),
67{88.
Selman, B., Levesque, H., & Mitchell, D. (1992). A new method for solving hard satisability problems. In Proceedings of the 10th (US) National Conference on Articial
Intelligence (AAAI'92), pp. 440{446 San Jose, CA, USA. American Association for
Articial Intelligence.
Steel, S., & Alami, R. (Eds.). (1997). 4th European Conference on Planning, ECP'97, Vol.
1348 of Lecture Notes in Articial Intelligence, Toulouse, France. Springer.
Stromberg, J.-E. (1991). Styrning av LEGO-bilfabrik. Andra omarbetade upplagan. Department of Electrical Engineering, Linkoping University.
Tate, A. (1975). Interacting goals and their use. In Proceedings of the 4th International
Joint Conference on Articial Intelligence (IJCAI'75), pp. 215{218 Tbilisi, USSR.
IJCAI, William Kaufmann.
Veloso, M. M., Perez, M. A., & Carbonell, J. G. (1990). Nonlinear planning with parallel
resource allocation. In Sycara, K. P. (Ed.), Workshop on Innovative Approaches
to Planning, Scheduling and Control, pp. 207{212 San Diego, CA, USA. Morgan
Kaufmann.
Vere, S. A. (1983). Planning in time: Windows and durations for activities and goals. IEEE
Transactions on Pattern Analysis and Machine Intelligence, PAMI-5 (3), 246{267.
Wilkins, D. E. (1988). Practical Planning. Morgan Kaufmann, San Mateo, CA.

137

Journal of Articial Intelligence Research 9 (1998) 219-245

Submitted 3/98; published 11/98

The Gn;m Phase Transition is Not Hard for the Hamiltonian
Cycle Problem
Basil Vandegriend
Joseph Culberson

Department of Computing Science, University of Alberta,
Edmonton, Alberta, Canada, T6G 2H1

basil@cs.ualberta.ca
joe@cs.ualberta.ca

Abstract

Using an improved backtrack algorithm with sophisticated pruning techniques, we revise previous observations correlating a high frequency of hard to solve Hamiltonian cycle
instances with the Gn;m phase transition between Hamiltonicity and non-Hamiltonicity.
Instead all tested graphs of 100 to 1500 vertices are easily solved.
When we articially restrict the degree sequence with a bounded maximum degree,
although there is some increase in diculty, the frequency of hard graphs is still low. When
we consider more regular graphs based on a generalization of knight's tours, we observe
frequent instances of really hard graphs, but on these the average degree is bounded by a
constant. We design a set of graphs with a feature our algorithm is unable to detect and so
are very hard for our algorithm, but in these we can vary the average degree from O(1) to
O(n). We have so far found no class of graphs correlated with the Gn;m phase transition
which asymptotically produces a high frequency of hard instances.

1. Introduction

Given a graph G = (V; E ); jV j = n; jE j = m, the Hamiltonian cycle problem is to nd a
cycle C = (v1 ; v2 ; : : : ; vn ) such that vi 6= vj for i 6= j , (vi ; vi+1 ) 2 E and (vn ; v1 ) 2 E . As
for any NP-C problem, we expect solving it to require exponential time in the worst case
on arbitrary graphs (assuming P 6= NP). However, in recent years researchers examining
various NP-C problems such as SAT and graph coloring have discovered that the majority
of graphs are easy for their algorithms to solve. Only graphs with specic characteristics or
graphs which lie within a narrow band (according to some parameter) seem to be hard to
solve for these problems.
It is known (Posa, 1976; Komlos & Szemeredi, 1983) that under a random graph model
(Gn;m ) as the edge density increases there is a sharp threshold (the phase transition) such
that below that edge density the probability of a Hamiltonian cycle is 0, while above it the
probability is 1. Previous research (Section 2.1) suggested that there is a high correlation
of dicult problems with instances generated with edge density near the phase transition.
Using an improved Hamiltonian cycle backtrack algorithm (Section 3) that employs various
pruning operators and an iterated restart technique, we observe no hard instances at the
transition for large n. Section 4 describes our results on Gn;m and related random graphs.
In an attempt to nd a higher frequency of hard graphs, in Section 5 we examine a low
degree random graph class we call Degreebound graphs. However, these graphs are also
usually easy for our backtrack algorithm, although we do nd a few hard graphs. Analysis
of these graphs indicates a test for non-Hamiltonian instances discussed in Section 5.3. In
c 1998 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

Vandegriend & Culberson

Section 6 we examine a graph class based on a generalization of the knight's tour problem.
These graphs are signicantly harder for our algorithm in general. In Section 7 we present a
constructed graph class which produces exponential behavior for our backtrack algorithm.
Our experimental results provide evidence that the average degree of a graph is not a
sucient indicator for hard graphs for the Hamiltonian cycle problem. With our backtrack
algorithm, the phase transition regions of the Gn;m and Degreebound graph models are
generally asymptotically easy.

2. A Discussion of Hardness and Previous Work
The concept of hardness of instances and hard regions within graph classes, considered from
an empirical basis, is not easy to dene. In order to clarify what we mean, in this section
we present our notions of hardness, relating this to previous work.

2.1 What is Hardness?

A problem of size n is a set n of instances. For the Hamiltonian cycle problem, n is
the set of undirected graphs on n vertices. Any discussion of the hardness of a particular
instance of a problem is always with respect to an algorithm (or set of algorithms). In
general, dierent algorithms will perform dierently on the instance. Furthermore, for each
particular instance of Hamiltonian cycle there is an associated algorithm that either correctly answers NO or outputs a cycle in O(n) time. To meaningfully talk about the hardness
of an instance, we must assume a xed algorithm (or a nite class of algorithms) that is
appropriate for a large (innite) class of instances, and then consider how the algorithm
performs on the instance. Hardness of an instance is always a measure of performance
relative to an algorithm.
We are left with the question of how much work an algorithm must do before we consider
the instance hard for it. Note that for a single instance the distinction between polynomial
and exponential time is moot. Ideally, we would like to require the algorithm to take an
exponential (i.e. an for some a > 1) number of steps as size n increases. Note that empirical
corroboration of such is practically impossible for sets of large instances. In practice, we
must be content with evidence such as failure to complete within a reasonable time for
larger instances.
We would also like an instance to exhibit some robustness before we consider it hard for
a given algorithm. Ideally, for graph problems we would at a minimum require the instance
to remain hard with high probability under a random relabeling of the vertices. Relabeling
the vertices produces an isomorphic copy of the graph, preserving structural properties such
as degree, connectivity, Hamiltonicity, cut sets, etc. The design of algorithms is typically
based on identifying and using such properties, and as far as possible eciency should be
independent of the arbitrary assignment of labels.
Let us refer to a (probabilistic) problem class as a pair (n ; Pn ), where Pn (x) is the
probability of the instance x given that we are selecting from n . Problem classes are
sometimes called ensembles in the Articial Intelligence literature (Hogg, 1998). The usual
classes for graph problems are Gn;p, where to generate an n vertex graph, each pair of
vertices is included as an edge with probability p, and Gn;m where m distinct edges are
220

The Gn;m Phase Transition is Not Hard for the Hamiltonian Cycle Problem

selected at random and placed in the graph. These two models are related (Palmer 1985).
For this paper we use the Gn;m model.
We do not consider mean or average run times in our denitions. The primary reason
is that for exponentially small sets of exponentially hard instances, it is impractical to
determine the average with any reasonable assurance. For example, if 1=2n of the instances
require (n2 2n ) time and the remainder are solved in O(n2 ) time then the average time is
quadratic, while if the frequency increases to 1=20:9n the average time is exponential. Even
for n = 100 it would be utterly impractical to distinguish between these two frequencies
with empirical studies.
Furthermore, and for similar reasons, if we want to promote a class as a benchmark class
for testing and comparing algorithms, low frequencies of hard instances are not generally
sucient. We will say that a problem class is maximally hard (with respect to an algorithm
or set of algorithms) if the instances generated according to the distribution are hard with
probability going to one as n goes to innity.
As an example of maximally hard classes, empirical evidence suggests that a variety of
hidden coloring graph generators based on the Gn;p model are maximally hard for a large
variety of graph coloring algorithms (Culberson and Luo, 1993). These hard classes are
all closely related to a coloring phase transition in random graphs. In general, a phase
transition is dened by some parameterized probability distribution on the set of instances.
As the parameter is varied past a certain threshold value, the asymptotic probability of the
existence of a solution switches sharply from zero to one.
Phase transitions are commonly considered to be identied with hard subsets of a particular problem (Cheeseman, Kanefsky, & Taylor, 1991). Many NP-C problems can be
characterized by a `constraint' parameter which measures how constrained an instance is.
Evaluation of a problem using this constraint parameter typically divides instances into
two classes: those that are solvable, and those that are unsolvable, with a sharp transition
occurring between them. When the problem is highly constrained, it is easily determined
that no solution exists. As constraints are removed, a solution is easily found.
Dierent researchers (Cheeseman et al., 1991; Frank & Martel, 1995; Frank, Gent, &
Walsh, 1998) have examined phase transitions on random graphs for the Hamiltonian cycle
problem. The obvious constraint parameter is the average degree (or average connectivity)
of the graph. As the degree increases, the graph becomes less constrained: it becomes easier
both for a Hamiltonian cycle to exist and for an algorithm to nd one. These researchers
have examined how Hamiltonicity changes with respect to the average degree. Frank et
al. (1998) and Frank and Martel (1995) experimentally veried that when using the Gn;m
model the phase transition for Hamiltonicity is very close to the phase transition for biconnectivity, which occurs when the average degree is approximately ln n (or m = n ln n=2) 1 .
Cheeseman et al. (1991) experimentally conrmed theoretical predictions by Komlos and
Szemeredi (1983) that the phase transition (for the Hamiltonian cycle problem) occurs when
the average degree is ln n + ln ln n. The papers also provided empirical evidence that the
time required by their backtrack algorithms increased in the region of the phase transition
and noted that the existence of very hard instances appeared to be associated with this
transition.
1. Note that the average degree equals 2m=n.

221

Vandegriend & Culberson

As mentioned above, the k-colorable Gn;p class appears maximally hard for all known
algorithms with respect to a phase transition dened by n; p and k, where k  n= logb n
and b = 1=(1 , p). The Hamiltonian cycle Gn;m class on the other hand does not appear
maximally hard for any value of m. In fact, for large n our algorithm almost never takes
more than O(n) backtrack nodes and O(nm) running time.
We will use a much weaker requirement and say an instance is quadratically hard if it
requires at least n2 search nodes by the backtrack algorithm described in section 3. Note
that 
(n2 ) search nodes would take our algorithm 
(n3 ) time. For practical reasons, we will
also use a weaker denition for robustness, and say that an instance is robustly quadratically
hard if our algorithm uses at least n2 search nodes when the iterated restart feature is used
with a multiplying factor of 2. (See section 3 for program details). We say a class is
minimally hard if there is some constant  > 0 such that the probability of a hard instance
is at least  as n ! 1.
In Section 4 we examine Gn;m random graphs using our backtrack algorithm on graphs
of up to 1500 vertices. The empirical evidence we collect suggests that in contrast to the
graph coloring situation, the Hamiltonian cycle Gn;m class is not minimally quadratically
hard, even for m at or near the phase transition, and even if we drop our minimal robustness
requirement.
Note that we do not dispute the claim that hard instances are more likely at the phase
transition than at other values of m, but rather claim that even at the transition the
probability of generating a hard instance rapidly goes to zero with increasing n.

2.2 Random Graph Theory and the Phase Transition

These results are not unexpected when one reviews the theoretical work on this graph class.
Since asymptotically the graph becomes Hamiltonian when an edge is added to the last
degree 1 vertex (Bollobas, 1984), any algorithm that checks for a minimum degree  2
will detect almost all non-Hamiltonian graphs. When the graph is Hamiltonian, various
researchers (Angluin & Valiant, 1979; Bollobas, Fenner, & Frieze, 1987) have proven the
existence of randomized heuristic algorithms which can almost always nd a Hamiltonian
cycle in low-order polynomial time. In particular, it is shown (Bollobas et al., 1987) that
there is a polynomial time algorithm HAM such that
8
>
<

0
if cn ! ,1
,e,2c if cn ! c
lim
Pr
(HAM
nds
a
Hamilton
cycle)
=
e
n!1
>
:
1
if cn ! 1
where m = n=2(ln n + ln ln n + cn ).
Furthermore, as the authors point out, this is the best possible result in the sense
that this is also the asymptotic probability that a Gn;m graph is Hamiltonian, and is the
probability that it has a minimum degree of 2. In other words, the probability of nding
a cycle is the same as the probability of one existing. Given that it is trivial to check the
minimum vertex degree of a graph, this does not leave much room for the existence of hard
instances (for HAM and similar algorithms).
Another relevant theoretical result is that there is a polynomial time algorithm which
with probability going to one, nds some Hamiltonian cycle when a graph has a hidden
222

The Gn;m Phase Transition is Not Hard for the Hamiltonian Cycle Problem

Hamiltonian cycle together with extra randomly added edges(Broder, Frieze, & Shamir,
1994). For the algorithm to work, the average degree of a vertex needs only be a constant.
They claim the result can be easily extended to the case that the average degree is a growing
function of n. This is another indication that Hamiltonian graphs near the phase transition
will be easy to solve by some algorithm.
For a non-Hamiltonian graph to be hard for an algorithm it must contain a feature
preventing the formation of a Hamiltonian cycle which the algorithm cannot easily detect.
Suppose a backtrack algorithm does not check for vertices of degree one. The algorithm may
then require exponential backtrack before determining the non-Hamiltonicity of the graph,
since the only way it can detect this is by trying all possible paths and failing. However,
degree one vertices are easily detectable, and so are not good indicators of hard instances.
They also disappear at the phase transition.
Similarly, an algorithm might not check for articulation points, and as a result waste
exponential time on what should be easy instances. As n ! 1, the probability of an
articulation point existing (in Gn;m ) goes to zero as fast as the probability of the existence
of a vertex of degree less than two. Other features can lead to non-Hamiltonicity of course,
such as k-cuts that leave k +1 or more components (Bondy & Murty, 1976), and these could
require time proportional to nk to detect. Under the assumption that NP6=CO-NP there
must also exist a set of non-Hamiltonian instances which have no polynomial proof of their
status.
However, it seems that at the phase transition the larger the feature the less likely it
is to occur. In fact, the theoretical results summarized above indicate this must happen.
Although we know hard graphs exist, and we may expect these localized types of hard
graphs to be more frequent near the phase transition than elsewhere when using Gn;m to
generate instances, we also expect the probability of such instances to go to zero as n
increases.

3. An Overview of our Backtrack Algorithm
Our backtrack algorithm comes from Vandegriend (1998), and is based upon prior work on
backtrack Hamiltonian cycle algorithms (Kocay, 1992; Martello, 1983; Shufelt & Berliner,
1994). It has three signicant features which we will discuss. First, it employs a variety of
pruning techniques during the search that delete edges that cannot be in any Hamiltonian
cycle. This pruning is usually based upon local degree information. Second, before the
start of the search the algorithm performs initial pruning and identies easily detectable
non-Hamiltonian graphs. The third feature is the use of an iterated restart technique.
Additionally, the program provides the opportunity to order the selection of the next vertex
during path extension using either a low degree rst ordering, a high degree rst ordering,
or a random ordering. We normally use the low degree rst ordering.
At each level of the search, after adding a new vertex to the current path, search pruning
is used. The pruning identies edges that cannot be in any Hamiltonian cycle and removes
them from the graph. (Note that if the algorithm backtracks, it adds the edges deleted
at the current level of the search back to the graph.) The rst graph conguration that
the pruning looks for is a vertex x with 2 neighbours a; b of degree 2. Since the edges
incident on a and b must be used in any Hamiltonian cycle, the other edges incident on
223

Vandegriend & Culberson

x can be deleted. The second graph conguration that the pruning looks for is a path
P = (v1 ; : : : ; vk ) of forced edges (so v2 : : : vk,1 are of degree 2). If k < n then the edge v1 ; vk

cannot be in any Hamiltonian cycle and can be deleted. If as a result of pruning, the degree
of any vertex drops below 2, then no Hamiltonian cycle is possible and the algorithm must
backtrack. The use of these operators may yield new vertices of degree 2 and therefore the
pruning is iterated until no further changes occur.
A pruning iteration takes O(n) time to scan the vertices to check for vertices with two
degree 2 neighbors, and O(n) time to extend all forced degree two paths. Since the iterations
terminate unless a new vertex of degree two is created, at most n iterations can occur. At
most O(m) edges can be deleted. On backing up from a descendant, the edges are replaced
(O(m)) and the next branch is taken. Thus, an easy upper bound on the pruning time for
a node searching from a vertex of degree d is O(d(n2 + m)), but this is overly pessimistic.
Note that along any branch from the root of the search tree to a leaf, at most n vertices
can be converted to degree 2. Also note that along each branch each edge can be deleted at
most once. If the degree is high we seldom take more than a few branches before success.
The implementation is such that when several vertices have two neighbors of degree two at
the beginning of an iteration, all redundant edges are removed in a single pass taking time
proportional to n plus the number of edges removed and checked. In practice, on Gn;m
graphs it typically takes O(n + m) time per search node on very easy Hamiltonian instances
as evidenced by CPU measurements, with harder instances taking at most twice as long
per search node.
Before the start of the recursive search, our algorithm prunes the graph as described
above. Then the algorithm checks to see if the graph has minimum degree  2, is connected,
and has no cut-points. If any of these conditions are not true, then the graph is nonHamiltonian and the algorithm is nished.
Some non-Hamiltonian instances may be very easy or very hard to detect, depending
on which vertex the algorithm chooses as a starting point. In these cases local features
exist that could be detected if the algorithm starts near them, but otherwise the algorithm
may backtrack many times into the same feature without recognizing that only the feature
matters. The seemingly hard instance on Gn for n = 100 discussed in Section 4.2 is such a
case. This is one type of \thrashing," and is a common problem in backtracking algorithms.
For example, Hogg and Williams (1994) noticed a sparse set of very hard 3-coloring problems
that were not at the phase transition. Baker (1995) showed that these instances were most
often hard as a result of thrashing, and that they could be made easy by backjumping or
dependency-directed backtracking.
To improve our algorithm's average performance we use an iterated restart technique.
The idea is to have a maximum limit M on the number of nodes searched. When the
maximum is reached, the search is terminated and a new one started with the maximum
increased by a multiple k (so Mi+1 = kMi ). Initially, M = kn. In our experiments, we
used k = 2. By incrementing the search interval in this way, the algorithm will eventually
obtain a search size large enough to do an exhaustive search and thus guarantee eventual
completion. The total search will never be more than double the largest size allocated.
Although random restarts are sometimes eective on non-Hamiltonian graphs, they are
more frequently eective on Hamiltonian instances. During search, as edges are added
to the set of Hamiltonian edges, the net eect is to prune edges from the graph. For a
224

The Gn;m Phase Transition is Not Hard for the Hamiltonian Cycle Problem

Hamiltonian graph to be hard, the algorithm must select some set of edges which causes the
reduced graph to become non-Hamiltonian, and this non-Hamiltonian subgraph must itself
be hard to solve. With iterated restart, for the instance to remain hard the algorithm must
make such mistakes with high probability. As a result, we expect fewer hard Hamiltonian
instances.
Random restarts are an integral part of randomized algorithms (Motwani & Raghavan,
1995) and are used frequently in local search and other techniques to escape from local
optima (Johnson, Aragon, McGeoch, & Schevon, 1991; Langley, 1992; Selman, Levesque,
& Mitchell, 1992; Gomes, Selman, & Kautz, 1998). Further discussion of the impact of
restarts can be found in the analysis of the experiments on Gn;m graphs in Section 4.
The algorithm also provides for the possibility of checking for components and cut
vertices during recursive search after the pruning is completed at each search node. The
overhead of this extra work is O(n + m) per search node and rarely seems to pay o. Except
where noted these checks were not used in this study.
The experimental results reported in the remaining sections were run on a variety of
machines, the fastest of which is a 300 MHZ Pentium II. All CPU times reported are
either from this machine, or adjusted to it using observed speed ratios on similar tests.
Our algorithm terminated execution after 30 minutes2. Experimental results are frequently
reported as the ratio of the number of search nodes over the number of vertices. This node
ratio is used because we feel it provides a better basis for comparing results across dierent
graph sizes, since many of our results are O(n). Note that the number of search nodes is
calculated as the number of recursive calls performed.
We used several dierent methods of verifying the correctness of our algorithm and our
experimental results. The algorithm was independently implemented twice, and performs
automatic verication of all Hamiltonian cycles found. We performed multiple sets of experiments on generalized knight's circuit graphs and compared the results (graph Hamiltonian
or not) to our theoretical predictions. Initial sets of experiments on Gn;m graphs and Degreebound graphs were executed using two dierent pseudo-random number generators, and
were repeated multiple times. Our source code is available as an appendix.

4. Gn;m Random Graphs

We consider random graphs of 16 to 1500 vertices with m = dn=2. From previous work
(Cheeseman et al., 1991; Komlos & Szemeredi, 1983) we expect the phase transition to occur
when d  ln n + ln ln n. Thus we specify the constraint parameter (or degree parameter)
k = d =(ln n + ln ln n).

4.1 Gn;m Using Restart

For the premiere experiment, we generate Gn;m graphs with number of vertices n = 16 : : : 96
in steps of 4, n = 100 : : : 500 in steps of 100, n = 1000 and n = 1500. For each size n, the
degree parameter k ranges from 0:5 : : : 2:0 (step size 0.01 from k = 1:00 : : : 1:20, step size
2. Since the time limit of 30 minutes is at least two orders of magnitude greater than the typical running
time, the limit is rarely used. On slower machines this limit was increased. The Knight's tour graphs
reported in Section 6 were run on a slower machine with a 30 minute time limit, although some instances
were run much longer.

225

Vandegriend & Culberson

100
100
200
300
400
500
1000
1500

% Hamiltonian

80

60

40

20

0
0.6

0.8

1

1.2
1.4
Degree Parameter k

1.6

1.8

2

Figure 1: % of Hamiltonian graphs as a function of graph size and degree parameter for
Gn;m graphs.
0.10 for other ranges of k). We generate 5000 graphs for each data point and execute our
backtrack algorithm once on each graph. This is a grand total of 4.76 million graphs, of
which 1.19 million are of 100 or more vertices.
We use the pruning described in section 3, check for components and articulation points
after the initial pruning, and use iterated restart with a multiplicative factor of 2. We do
not check for components or articulation points during the recursive search.
We expect the phase transition for biconnectivity to be very similar to the phase transition for Hamiltonicity (Cheeseman et al., 1991) and we expect the phase transition for
minimum degree greater than 1 to be almost identical to the phase transition for Hamiltonicity (Bollobas, 1984; Komlos & Szemeredi, 1983). Our experimental results matched
these expectations very closely. For the larger graphs of 100 to 1500 vertices, the percentage
of Hamiltonian graphs is plotted against the degree parameter in Figure 1. We found that
the 50% point at which half the graphs are Hamiltonian occurs when the degree parameter
k  1:08 , 1:10. More interestingly, all the curves pass close to a xed point near k = 1,
and it seems they are approaching a vertical line at this point. That is, they appear to be
converging on k  1 as a phase transition, precisely as theory predicts.
226

The Gn;m Phase Transition is Not Hard for the Hamiltonian Cycle Problem

n
100 200 300 400 500 1000 1500
Nodes 7:5n 7:0n 3:3n 7:0n 3:4n 3:3n 7:0n
Table 1: Maximum Search Nodes on Gn;m for Large n
All graphs were solved, that is were either determined to be non-Hamiltonian, or a
Hamiltonian cycle was found. We are primarily interested in asymptotic behavior, since
theories concerning the relation of the phase transition to hard regions are necessarily
asymptotic in nature. For graphs of 100 vertices or more, the longest running time was
under 11 seconds, on a graph of 1500 vertices using 10,500 (or 7:0n) search nodes to nd a
Hamiltonian cycle.
All of the 549,873 non-Hamiltonian graphs in this range were detected during the initial
pruning of the graph, and thus no search nodes were expanded. Of the 640,127 Hamiltonian
Gn;m graphs, the vast majority ( 629,806 or 98:3%) used only n search nodes, which means
that the algorithm did not need to backtrack at all3. No quadratically hard graphs were
found in this range. Table 4.1 lists the maximum number of search nodes expressed as a
factor of n to illustrate the linearity of the search tree.
These results appear to dier from those of Frank et al. (1998), who found graphs
which took orders of magnitude more search nodes to solve. (Their hardest graph took
over 1 million nodes.) We believe this is due to two factors. Firstly, the algorithm used to
generate the results in their paper did not do an initial check for biconnectivity nor did it
use all of the pruning techniques used in our algorithm. Secondly and more importantly, on
the small random graphs they used ( 30 vertices) the probability of obtaining certain hard
congurations (such as biconnected and non-Hamiltonian or non-biconnected and minimum
degree  2) is much higher than when n is larger, as we discussed in section 2.2.
The experiments on small Gn;m graphs (between 16 and 96 vertices) conrm this conjecture. In this case we do nd a small number of quadratically hard graphs, and a few
very hard graphs. We consider for purposes of this paper, that a very hard graph on less
than 100 vertices is any that takes at least 100,000 search nodes to solve. The very hard
graphs from this set of runs are given in Table 4.1.
Note that the very hardest took less than two minutes to solve, making our designation
of \very hard" questionable. Also, note that the smallest graph in this set has 36 vertices,
somewhat larger than the 30 vertex examples found by Frank et al. (1998). This is likely
because we do articulation point checking initially and better pruning. Finally, all of these
very hard graphs are non-Hamiltonian, and all occur in classes that produce less than 50%
Hamiltonian graphs. The hardest Hamiltonian graph in contrast required only 19,318 search
nodes, on a graph of 68 vertices with degree parameter 0.9.
In Figure 2 we plot the number of graphs that are quadratically hard for these small
graphs. For n from 68 to 92, all non-Hamiltonian graphs were detected during initial
pruning. One non-Hamiltonian graph at n = 96 required search (254:1n nodes). Notice
that the number of quadratically hard Hamiltonian graphs is far less than the number of
quadratically hard non-Hamiltonian graphs, and peaks for larger n. This is in accordance
with the discussion of random restarts in Section 3.
3. With 5% error in this measurement, this means that the algorithm might have backtracked over a
maximum of 0:05n search nodes.

227

Vandegriend & Culberson

Vertices Degree Parameter Seconds Search Nodes Ratio
36
1.11
94.7
1179579 32766.1
40
1.00
36.5
638946 15973.6
40
1.07
18.7
327603 8190.1
44
1.00
12.3
156694 3561.2
44
1.04
20.0
293664 6674.2
48
1.02
91.2
1280135 26669.5
48
1.09
107.0
1243647 25909.3
Table 2: The Hardest Small Graphs

60
non-Ham
Ham

Number of Hard Instances

50

40

30

20

10

0
20

30

40

50
60
70
Number of Vertices

80

90

Figure 2: The Number of Quadratically Hard Graphs for Small n.

228

The Gn;m Phase Transition is Not Hard for the Hamiltonian Cycle Problem

We ran additional tests for n from 32 to 54 in steps of 2, with the degree parameter
ranging from 0.96 to 1.16 with step size 0.01, generating 5000 graphs at each point. In
this case, we invoked articulation point checking at each search node. Again all graphs
were solved without timing out, and some very hard graphs were found, all of them nonHamiltonian. One 50 vertex graph required 9,844,402 search nodes, and required close to
20 minutes to solve. It is unclear whether the extra checking helped; the smallest graph
requiring at least 100,000 nodes had 32 vertices, while the smallest requiring over a million
had 40 vertices. Overall, the results were very similar to the rst set of experiments on
small graphs.

4.2 Gn Using Restart
Clearly, the more edges we add to a graph, the more likely it is to be Hamiltonian. It
also seems that once a graph is Hamiltonian, adding more edges makes it less likely to be
hard. In an attempt to nd hard graphs for larger n, we modied the Gn;m generator so
that instead of adding a xed number of edges, it instead added edges until every vertex
has degree at least two, and then stops. In a sense this produces graphs exactly on the
Gn;m phase transition, since a minimum degree of two is the condition that asymptotically
distinguishes Hamiltonian from non-Hamiltonian graphs with high probability. We refer to
this distribution as the Gn model.
Initially we ran 1000 graphs with this generator for n from 100 to 500, but no hard
instances were found. We increased the search to 10,000 graphs at each n, and included a
search at n = 1000. Out of all these graphs, we found one very hard graph on 100 vertices.
Even after a second attempt using more than 26 million search nodes, it was still unsolved.
Doing post-mortem analysis, we checked for cut sets of size 2 and 3 that would leave 3
or 4 (or more) components and found none. We also checked the pruned graph using the
odd degree test mentioned in Section 5.3, but this too failed to show it is non-Hamiltonian.
Finally, we set up our fast machine with unlimited time and no restarts. Three search nodes
and less than 0.1 seconds later it was proven non-Hamiltonian.
Detailed analysis (see the appendix) shows that the graph has a small feature that is
easily detected when one of a few starting points is selected. Because we use an exponentially
growing sequence of searches, we only use a few restarts. In a test of 100 random starts
with a 3 second time limit 7 trials succeeded, using from 2 to 5 search nodes each to prove
the graph non-Hamiltonian.
We also ran 10,000 Gn graphs at each even value of n from 16 to 98. The smallest
instances requiring at least 100,000 search nodes were at n = 50. Only 5 graphs requiring
more than a million nodes were found for n < 100, two at n = 62, one at n = 70 and two at
n = 98. Two of these (one at 62, one at 98) initially timed out, but were solved in second
attempts in about 1/2 hour. Neither was susceptible to an attack by 100 restarts as on the
100 vertex graph.
Table 4.2 shows the number of non-Hamiltonian graphs for each n  100. All of these
except the one mentioned above were detected during initial pruning. The remaining graphs
were all easily shown to be Hamiltonian, with a maximum search ratio of 7.0.
Clearly the probability of non-Hamiltonian graphs drawn from Gn is decreasing with
n. It seems likely that the probability of hard instances is also going to zero.
229

Vandegriend & Culberson

n
100 200 300 400 500 1000
Non-Ham 154 56 29 20 15
3
Table 3: Number of Non-Hamiltonian Graphs from Gn

n k = 1:00 k = 1:50 k = 2:00

500
1000
1500

0.20
0.43
0.68

0.20
0.50
0.80

0.21
0.60
0.87

Table 4: CPU Seconds per 1000 Search Nodes for Gn;m Graphs

4.3 Gn;m Without Using Restart

We wanted to know how important the restart feature is asymptotically. We ran 1000 Gn;m
graphs for n from 100 to 1500, for each of the parameter settings in the premiere experiment,
but this time using the backtrack algorithm without the iterated restart feature. As before,
all non-Hamiltonian instances were detected during initial pruning. One quadratically hard
Hamiltonian graph was found at n = 300, with degree parameter 1.20, which required
163,888, or 1:82n2 search nodes and took 28.5 seconds. A few other graphs were nearly
quadratic, for example on n = 1500 there were 4 graphs that required 0:15n2 , 0:19n2 ,
0:36n2 and 0:47n2 search nodes. It seems that asymptotically, even in the absence of
iterated restarts, the Gn;m class does not provide hard instances with high probability.

4.4 Gn;m Summary

Based on a set of timing runs, we present in Table 4.4 an indication of how running time per
search node increases with the number of vertices n and degree parameter k. Because the
times are usually so short, we cannot get reliable numbers for n < 500. The times shown
are for the evaluation of 1000 search nodes, and are averaged (total CPU divided by total
nodes searched) over graphs that were solved in less than 1:1n search nodes. For instances
that require signicantly more search nodes, the time per 1000 nodes seems to increase
somewhat, but there are so few examples for large n that we are unable to provide exact
estimates. For n = 15004 , the average time per 1000 nodes for instances requiring more
than 2n search nodes is 0.89 seconds at k = 1:00, 1.04 at k = 1:50 and 1.31 at k = 2:00.
Note that this includes at least one instance that took 7n search nodes. This table indicates
that the growth is approximately linear in n + m.
The experimental evidence clearly indicates that Gn;m random graphs are asymptotically
extremely easy everywhere, despite the existence of a phase transition. Our results temper
the ndings of the various researchers (Cheeseman et al., 1991; Frank et al., 1998; Frank
& Martel, 1995) studying phase transitions and the Hamiltonian cycle problem. Cheeseman et al.'s explanation of their observed increase in diculty near the phase transition
was that \on the border [between the regions of low and high connectivity] there are many
4. n = 1500 is the only value of n for which we have at least one instance requiring  2n search nodes at
each of the three values of k. The times for 1000 and 1500 come from separate runs on 1000 graphs per
sample point.

230

The Gn;m Phase Transition is Not Hard for the Hamiltonian Cycle Problem

almost Hamiltonian cycles that are quite dierent from each other . . . and these numerous
local minima make it hard to nd a Hamiltonian cycle (if there is one). Any search procedure based on local information will have the same diculty." (Cheeseman et al., 1991).
Unfortunately, while their observations were accurate, their observed hardness was due to
their algorithms and the limited size of the graphs tested, not to intrinsic properties of the
Hamiltonian cycle problem with respect to the phase transition on Gn;m graphs. We have
shown that an ecient backtrack algorithm nds the phase transition region of Gn;m graphs
easy in general.

5. Degreebound Graphs
Intuitively, the reason that it is so hard to generate a hard instance from Gn;m is that by
the time we add enough edges to make the minimum degree two, the rest of the graph is
so dense that nding a Hamiltonian cycle is easy. Alternatively, we see that to create a
non-Hamiltonian property or feature, we must have regions of low degree, while at the same
time meeting the minimal requirements that make the instance hard to solve. This problem
can be characterized as one of high variance of vertex degrees. The only region where we
get even a few hard graphs from Gn;m is when n is small enough that the average degree is
also low.
To avoid the consequences of this degree variation, in this section we use a dierent
random graph model Gn(d2 = p2 ; d3 = p3 ; : : :) for which n is the number of vertices and
di = pi is the percentage of vertices of degree i. As an example G100 (d2 = 50%; d3 = 50%)
represents the set of graphs of 100 vertices in which 50 are of degree 2 and 50 are of degree
3. We refer to a graph generated under this model as a Degreebound graph. In this paper
we only consider graphs whose vertices are of degree 2 or 3.
It is quite dicult to generate all graphs with a given degree sequence with equal probability (Wormald, 1984). Instead, we adopt two variations which generate graphs by selecting
available edges. In each case each vertex is assigned a free valence equal to the desired nal
degree. In version 1 pairs of vertices are selected in random order, and added as edges
if the two vertices have at least one free valence each. This continues until either all free
valences are lled (a successful generation) or all vertex pairs are exhausted (a failure). If
failure occurs, the process is repeated from scratch. Initial tests indicate about 1/3 of the
attempts fail in general. For eciency reasons, in the implementation an array of vertices
holds each vertex once. Pairs of vertices, v; w are selected at random from the array and
if v 6= w, and (v; w) is not already an edge, then (v; w) is added as an edge, and the free
valence of each of v and w is reduced by one. When the free valence of a vertex is zero, the
vertex is deleted from the array. This step is repeated until only a small number (twice the
maximum degree) of vertices remains, and then all possible pairs of the remaining vertices
are generated and tested in random order.
In version 2 an array initially holds each vertex v deg[v] times. Pairs of vertices are
randomly selected, and if not equal and the edge does not exist, then the edge is added, and
the copies of the two vertices are deleted from the array. This is repeated until the array is
empty, or 100 successive attempts have failed to add an edge. The latter case is taken as
failure, and the process is repeated from scratch. This method seldom fails.
231

Vandegriend & Culberson

Neither of these two methods guarantees a uniform distribution over the graphs of the
given degree sequence. For example, given the degree sequence on ve vertices f1; 1; 2; 2; 2g,
there are seven possible (labeled) graphs. One consists of two components, an edge and a
triangle. The other six are all four paths; thus all six are isomorphic to one another. Of the
10! permutations of the pairs of vertices, 564,480 generate the graph on two components,
while for each four path there are 322,560 distinct permutations. The remaining permutations (31.2 %) do not yield a legal graph. Thus, the rst graph is 1.75 times as likely as
any of the other six. Of course, a four path (counting all isomorphic graphs) is 3.428 times
as likely as the two-component graph.
On the other hand, a version 2 test program (not our generator which prohibits degree
one vertices) consistently generated the rst graph about 8%{10% more often than any of
the others, based on several million random trials.

5.1 Experimental Results on Degreebound Graphs

We test graphs of 100 : : : 500 vertices (step size 100) 1000 and 1500 vertices with the mean
degree varying from 2:6 : : : 3:0 (step size of 0.01 from 2.75 to 2.95, step size of 0.05 elsewhere).
We generate 1000 graphs for each data point, execute our algorithm once on each graph,
and collect the results. This test was repeated for each of the two versions.
Figure 3 shows the percentage of graphs which are Hamiltonian as the mean degree and
graph size varies5 . There is a clear transition from a mean degree of 2.6 (near 0% chance of
a Hamiltonian cycle) to a mean degree of 3 (for which Robinson and Wormald, 1994 predict
an almost 100% chance of a Hamiltonian cycle on uniformly distributed graphs). For a
phase transition, we would expect the slope to grow steeper as the graph size increases.
Figure 3 shows this increase in steepness.
Note that the double points on the curve for n = 100 are due to unavoidable discretization. Since the total degree of a graph must be even, when the generators detect that the
total degree specied is odd, one of the minimum degree vertices is selected and its degree
incremented. Thus, for example, whether the fraction of degree 3 vertices specied is 0.81 or
0.82, the number of degree three vertices is 82. Discretization eects also occur for n = 300,
500 and 1500, but with lessened impact.
In Table 5.1 we summarize the observed hard instances from these graphs. We note
that several instances exceeded our time bounds, and although these are certainly at least
quadratically hard, they are not included in the quadratically hard instances. The frequency
of hard instances appears to be decreasing with n on these graphs. In particular there are
no quadratically hard non-Hamiltonian instances over 1000 vertices, except those that are
too hard to solve with our program.
Interestingly, there turns out to be an O(n + m) time test which shows that most of
the unresolved instances are non-Hamiltonian. This test is described briey in Section 5.3.
We implemented the test as a separate program and tested each of the unresolved graphs,
with the results indicated in the last column of Table 5.1. The remaining ve graphs
remain unresolved. If this test were included in the initial pruning of our program, then
the instances enumerated in the last column of Table 5.1 would all be solved (proven nonHamiltonian) without search.
5. For these graphs, the mean degree is 2.0 plus the fraction of degree 3 vertices.

232

The Gn;m Phase Transition is Not Hard for the Hamiltonian Cycle Problem

100
Version 1
n = 100
200
300
400
500
1000
1500

% Hamiltonian

80

60

40

20

0
60

65

70

75
80
85
% Vertices of Degree 3

90

95

100

100
Version 2
n = 100
200
300
400
500
1000
1500

% Hamiltonian

80

60

40

20

0
60

65

70

75
80
85
% Vertices of Degree 3

90

95

Figure 3: % of Hamiltonian graphs for Degreebound Graphs.
233

100

Vandegriend & Culberson

Version 1
Number of Quadratically Hard Timed Out
Vertices No HC
HC
Total No HC
100
5
0
0
0
200
18
0
3
3
300
8
0
11
10
400
1
0
14
14
500
0
0
14
14
1000
0
0
7
7
1500
0
1
6
6
Version 2
Number of Quadratically Hard Timed Out
Vertices No HC
HC
Total No HC
100
5
0
0
0
200
9
0
6
5
300
10
0
13
13
400
3
0
11
11
500
1
1
10
9
1000
0
1
6
4
1500
0
0
6
6
Table 5: Number of Hard Graphs for Degreebound Graphs
Thus, although these classes may provide a small rate of hard instances for our current
program, it is not clear they are even minimally hard. Furthermore, it appears there exist
simple improvements to our program that would eliminate most of these hard instances.
In Figure 4 we illustrate the distribution of the graphs that timed out. The other
quadratically hard graphs had similar distributions. About all that can be concluded is
that the hard instances seem to be distributed over a mean degree range from 2.78 to 2.94.
The backtrack program is a little faster on Degreebound graphs than on Gn;m graphs,
as we would expect given fewer total edges. For 1500 vertices, the times per 1000 search
nodes ranged from 0.27 seconds for the easiest (no backtrack) instances to 0.56 seconds for
the harder ones.

5.2 Analysis of Degreebound Graphs

An analysis of the Degreebound graph class led us to conjecture that the prime factor
determining the Hamiltonicity of a graph was whether or not the graph had a degree 3
vertex with 3 neighbours of degree 2. We label this a 3D2 conguration (or a 3D2 event).
A graph with a 3D2 conguration is non-Hamiltonian. The following informal analysis
provides evidence for our conjecture.
Let E (n; ) represent the expected number of 3D2 congurations in a graph with n
vertices. Let D2 = n be the number of degree 2 vertices and D3 = (1 , )n the number of
D3 = 2n+3n(1,) = 3 , . Assuming
degree 3 vertices. Note that the mean degree d = 2D2 +3
n
n
equal probability of all combinations,
234

The Gn;m Phase Transition is Not Hard for the Hamiltonian Cycle Problem

Number Failed
Version 1

5
4
3
2

95

1
90
200

85 % Degree 3

500
1000
Number of Vertices

80
1500

Number Failed
Version 2

5
4
3
2

95

1
90
200

85 % Degree 3

500
1000
Number of Vertices

80
1500

Figure 4: Distribution of Timed Out Instances for Degreebound graphs
235

Vandegriend & Culberson

# of Mean Degree for 50% HC Point
Vertices Experimental
Theoretical
100
2.78
2.78
200
2.81
2.82
300
2.83
2.85
400
2.84
2.86
500
2.85
2.87
1000
2.88
2.90
1500
2.90
2.91
Table 6: Experimental and approximate theoretical values for the location of the 50%
Hamiltonian point for Degreebound graphs of various sizes.

E (n; ) = D3

,D2 

,n,13
3

, 

n(1 , ) n
)(n)(n , 1)(n , 2)
= ,n,1 3 = n(1(,n ,
1)(n , 2)(n , 3)
3

We restrict ourselves to the asymptotic case (n ! 1) which gives us

E (n; )  n(1 ,n3)(n)  n(1 , )3
3

When E (n; ) ! 0, the probability of having conguration 3D2 approaches 0. We
want to nd  for which n(1 , )3 ! 0 as n ! 1. This occurs when  = o(n,1=3 ).
Since a Hamiltonian cycle cannot exist if E (3D2) > 0, this tells us that the phase transition
asymptotically occurs when the mean degree equals 3. Asymptotically, Degreebound graphs
with d < 3 are expected to be non-Hamiltonian while Degreebound graphs with d > 3
are expected to be Hamiltonian (ignoring other conditions). This agrees with results of
Robinson and Wormald (1994) who proved that almost all 3-regular graphs are Hamiltonian.
If we let  = n,1=3 this gives us E (n; )  1. Substituting this equation in our expression
for mean degree gives us d = 3 , n,1=3 . Table 5.2 lists mean degrees for dierent values of n
using this formula along with our experimentally determined values for the point where 50%
of the graphs are Hamiltonian. They are remarkably similar. This suggests that the 3D2
conguration is the major determinator of whether a Degreebound graph will be Hamiltonian or not. Minor eects (which we have ignored) come from propagation of deleted edges
while pruning and other less probable cases such as those mentioned in Section 5.3. Since
the 3D2 conguration is detected by our algorithm before the search is started, this also
implies that the phase transition will be easy for our algorithm, since most non-Hamiltonian
graphs are instantly detected. This matches our experimental observations.

5.3 A Non-Hamiltonicity Test for Sparse Graphs

While preparing the nal version of this paper, we observed that in the 3D2 conguration
we could replace the vertex of degree three with a component of several vertices. In general,
236

The Gn;m Phase Transition is Not Hard for the Hamiltonian Cycle Problem

if there are three vertices of degree two that form a minimal cut then the graph is nonHamiltonian. In fact, we can replace the three vertices by a minimal cut of any odd number
c of degree 2 vertices, and the claim of non-Hamiltonicity remains true.
Checking all possible subsets of size c would be very expensive, but fortunately there is
an even more general condition that includes all of these as special cases and can be tested in
linear (i.e O(n + m)) time. Let F be a set of edges that are forced to be in any Hamiltonian
cycle if one exists. For example, edges incident on a vertex of degree two are forced. Let
G0 = G , F be the graph formed by deleting the forced edges from G. Let C1 : : : Ch be
components of G0, and dene the forced degree of component Ci to be the number of end
points of forced edges (from F ) in Ci . If any component has an odd forced degree, then G
is non-Hamiltonian.
The proof of correctness of this test is simple. Observe that if there is a Hamiltonian
cycle in G then while traversing the cycle each time we enter a component, there must be a
corresponding exit. Since the forced edges act as a cut set (that separates the components),
they are the only edges available to act as entries and exits to a component. All forced edges
must be used. Therefore, if there is a Hamiltonian cycle there must be an even number of
forced edges connecting any component to other components, each contributing one to the
forced degree of the component. Each forced edge internal to (with both end points in) a
component contributes two to the forced degree, so if there is a Hamiltonian cycle the total
forced degree of each component must be even.
To obtain the results in the last column of Table 5.1, we rst did the initial pruning, and
then applied the test to the pruned graphs, using only the forced edges incident on degree
two vertices.

6. Generalized Knight's Circuit Graphs
In this section we examine a graph class based upon the generalized knight's circuit problem
in which the size of the knight's move is allowed to vary along with the size of the (rectangular) board. An instance of the generalized knight's circuit problem is a graph dened by
the 4-tuple (A; B ) , n  m where A; B is the size of the knight's move and n; m is the size
of the board. The vertices of the graph correspond to the cells, and thus jV j = nm. Two
vertices are connected by an edge if and only if it is possible to move from one vertex to
the other by moving A steps along one axis and B along the other. (See Vandegriend, 1998
for more information about this problem.)
For this graph class there is no easy way to dene phase transitions since there is
no clear parameter which separates the Hamiltonian graphs from the non-Hamiltonian
graphs (although Vandegriend, 1998 shows that there are ways of identifying groups of
non-Hamiltonian graphs). Thus to nd hard graphs, we look for graphs which take a significant amount of time to solve relative to their size. We perform 1 trial per graph (problem
instance) and report the ratio of search nodes to number of vertices.
We examined a total of 300 generalized knight's circuit graphs over ranges of A; B; n; m
(Specic A; B; n triplets with m allowed to vary, for A + B  9, n  13, m  60.) They
ranged in size from 80 to 390 vertices. Of the 300 instances examined, 121 graphs (40 %)
were found to be Hamiltonian and 141 graphs (47 %) were found to be non-Hamiltonian.
237

Vandegriend & Culberson

search nodes # of trials % of trials

2n
1
0.8
5n
43
35.5
10n
37
30.6
20n
11
9.1
50n
8
6.6
100n
8
6.6
200n
2
1.7
500n
5
4.1
1000n
2
1.7
2000n
1
0.8
5000n
1
0.8
10000n
1
0.8
20000n
0
0.0
50000n
1
0.8
Table 7: Histogram of the search node ratio of our backtrack algorithm on 121 Hamiltonian
generalized knight's circuit instances.
For the remaining 38 graphs (13 %) our backtrack algorithm failed (reached the 30 minute
time limit), which implies these graphs are very hard for our backtrack algorithm.
A majority (91%) of the non-Hamiltonian graphs were solved without any search. However, a signicant number of the remaining graphs took many search nodes to solve. 9
graphs (6.4%) took more than 10n nodes and 7 graphs (5.0%) took more than 100n nodes.
The hardest graph took  11276n search nodes (n = 324). So while the majority of the
non-Hamiltonian graphs were easy, a signicant percentage of these generalized knight's
circuit graphs were quite hard for our algorithm.
A larger variance in hardness was observed with the Hamiltonian graphs. Table 6 shows
the distribution with respect to the number of search nodes required. Unlike Gn;m and
Degreebound graphs, these graphs could not be solved in only n search nodes. Almost
all the graphs required at least 2n search nodes. 33% of the graphs required at least 10n
nodes, 11% required at least 100n nodes and the hardest graph required  34208n nodes
(n = 198).

7. A Hard Constructed Graph Class
It is worthwhile when designing an algorithm to determine under what conditions and how
frequently it might fail to perform and just how badly it might do. The measure can be
in terms of how bad an approximation is, or how long an exact algorithm may take in the
worst case. There is a long tradition of designing instance sets that foil specic combinatorial algorithms (Johnson, 1974; Mitchem, 1976; Olariu & Randall, 1989; Spinrad & Vijayan,
1985). Other special classes are intended to be more general, and are frequently based on
certain features or constructs together with some randomization to hide the features (Culberson & Luo, 1996; Brockington & Culberson, 1996; Kask & Dechter, 1995; Bayardo Jr. &
238

The Gn;m Phase Transition is Not Hard for the Hamiltonian Cycle Problem

Schrag, 1996). The Gn;m class is frequently used to study graph algorithms over all possible
graphs.
In this section we consider a special construction for a Hamiltonian graph which is
extremely hard (exponential increase in diculty with size) for our backtrack algorithm.
It consists mostly of special constructs tied together with some randomly chosen edges. It
bears some resemblance to graphs such as the Meredith graph (Bondy & Murty, 1976) used
to disprove certain theoretical conjectures. This graph remains dicult when we vary the
neighbour selection heuristic or pruning techniques used by our backtrack algorithm. The
graph we construct we refer to as the Interconnected-Cutset (ICCS ) graph.
Our class is intended merely to show that exponentially hard classes clearly exist for
our algorithm, and many other backtrack algorithms using similar approaches. We do not
claim our graphs are intrinsically hard, as there is a polynomial time algorithm that will
solve this particular class.
The basic concept we use in constructing these graphs is the non-Hamiltonian edge,
which we dene as an edge which cannot be in any possible Hamiltonian cycle. Note that
since the graphs are Hamiltonian, each vertex must be incident on at least two edges which
are not non-Hamiltonian. Our goal is to force the algorithm to choose a non-Hamiltonian
edge at some point. The key observation is that once such an edge is chosen, the algorithm
must backtrack to x that choice. With multiples of these bad choices, after backtracking
to x the most recent bad choice, the algorithm must eventually backtrack to an earlier
point to x a less recent bad choice, which means the more recent choice must be redone,
with the algorithm making the bad choice again. The amount of work performed by the
algorithm is at least exponential in the number of bad choices. See Vandegriend (1998) for
more details.
The ICCS graph is composed of k identical subgraphs ICCSS arranged in a circle.
To force the desired cycle we have a degree 2 vertex between each subgraph. Since each
subgraph has a Hamiltonian path between the connecting vertices, the ICCS graph is
Hamiltonian. Due to the construction of the ICCS subgraph, extra non-Hamiltonian edges
can be added between dierent subgraphs. These edges help prevent components from
forming during the search, which greatly reduces the eectiveness of the component checking
search pruning. See Figure 5. Heavy lines are forced edges that must be in any Hamiltonian
cycle.
Figure 6 contains a sample ICCS subgraph. Non-Hamiltonian edges are denoted by
dashed lines, and forced edges are denoted by heavy lines.
To see that the dashed lines cannot be part of any Hamiltonian cycle observe that
any path through the ICCSS must enter and exit on an SC vertex, and between any two
SC vertices in sequence the path can visit at most one SI vertex. Thus, each such path
uses at least one more vertex from SC than from SI . Since initially jSC j = jSI j + 1, any
Hamiltonian cycle can enter and exit the ICCSS only once, and must alternate between
SC and SI vertices. Since the ST vertices only have one edge leading to an SI vertex,
these edges are forced. This also allows us to interconnect subgraphs without adding new
Hamiltonian cycles by connecting vertices of SC of two dierent subgraphs (since these
additional edges are all non-Hamiltonian edges). By interconnecting the subgraphs in this
fashion, we strongly reduce the eectiveness of checking for components or cut-points during
the search. In the current implementation, for each vertex in each SC we randomly choose a
239

Vandegriend & Culberson

ICCSS

ICCSS

ICCSS

ICCSS

Figure 5: A sample ICCS graph.

SI

SD
SC
ST

ST

to

SC vertices

in other subgraphs

connecting edges to adjacent subgraphs

Figure 6: A sample ICCS subgraph ICCSS .
240

The Gn;m Phase Transition is Not Hard for the Hamiltonian Cycle Problem

vertex in another SC and add the edge. Thus, the average number of such edges per vertex
is a little less than two, since some edges may be repeated.
One additional design element was added to handle various degree selection heuristics
that our algorithm could use. At each stage in the search, the neighbours of the current
endpoint of the partial path are arranged in a list to determine the order in which they will
be chosen by our backtrack algorithm. There are 3 main heuristics: sorting the list to visit
lower degree neighbours rst, sorting to visit higher degree neighbours rst, and visiting in
random order. (Our backtrack algorithm normally uses the lower degree rst heuristic.)
The SD vertex in the ICCS subgraph is used to fool the low degree rst heuristic. The
SD vertex is only incident to the two ST vertices and to two vertices in SI , which makes
it degree 4. When the algorithm enters a subgraph from the degree 2 connecting vertex, it
reaches one of the ST vertices. From the ST vertex, the choices are the SD vertex (degree
4) and the one SI vertex (degree jSC j , 2, because it is not connected to the SD vertex and
the other ST vertex). If jSC j > 6 then the SD vertex will have a lower degree and thus will
be chosen rst.
The high degree rst heuristic avoids following the edge from the ST vertex to the SD
vertex, and instead goes to the SI vertex. From there it chooses one of the SC vertices (not
including SD or the other ST vertex, which are not adjacent). From this point, its choice is
one of the SI vertices (maximum degree = jSC j , 2) or one of the SC vertices in a dierent
subgraph (degree  jSC j if that subgraph has not yet been visited). Since the SC vertex
normally will have a higher degree, the algorithm will follow the non-Hamiltonian edge to
that vertex.
If the next neighbour is chosen at random, then from a ST vertex, the algorithm has a
50% chance of making the wrong choice. Similarly, at each SC vertex the algorithm has a
small chance of following a non-Hamiltonian edge. As the number of subgraphs is increased,
the probability of the algorithm making all the right choices rapidly approaches 0.
Another reason why the ICCS subgraph is expected to be hard for a backtrack algorithm
is that there are many possible paths between the two ST vertices. If a non-Hamiltonian
edge has previously been chosen, then the backtrack algorithm will try all the dierent
combinations of paths (and fail to form a Hamiltonian cycle) before it backtracks to the
bad choice.
We performed experiments on various ICCS graphs. We varied the number of subgraphs
from 1 to 4, and varied the independent set size (jSI j) from 6 to 8. We used our backtrack
algorithm as specied in Section 3 with the addition of checking for components and cutpoints during the search. We executed our algorithm 5 times per graph. Our results are
listed in Table 7 for the low degree rst heuristic. Our experiments using the other degree
selection heuristics exhibited similar results.
We have also performed similar experiments using a randomized heuristic algorithm
(Frieze, 1988; Posa, 1976). Due to the signicant dierence in operation between this
algorithm and backtrack algorithms, it easily solved these small ICCS graphs. However its
performance rapidly decreased as the graphs were increased in size.
The average degree of ICCS graphs with more than one subgraph lies within the following range:
jSI j , 2:5 + jS 9j:5+ 1  d  jSI j , 2 + jS j8+ 1
I

I

241

Vandegriend & Culberson

n #S jSI j

14
28
42
56
16
32
48
18
36
54

1
2
3
4
1
2
3
1
2
3

6
6
6
6
7
7
7
8
8
8

Min
Median
Max
14
14
210
606
616
3,777
10,467
47,328
112,795
6,538,842 32,578,160 36,300,827
16
48
112
13,056
21,797
70,949
1,350,084 5,247,287 8,027,520
18
54
270
283,164
430,620
750,211
> 1:2  108

Table 8: Search nodes required by our backtrack algorithm on ICCS graphs.
From this formula we see that as the size of each independent set is increased, the mean
degree increases linearly. However, as the number of subgraphs is increased, the mean
degree remains constant. The ICCS graphs remain hard over a very wide range of mean
degrees (from O(1) to O(n)). Therefore the average degree in this case is not a relevant
parameter for determining hardness.

8. Conclusions and Future Work
Our backtrack Hamiltonian cycle algorithm found Gn;m graphs easy to solve, along with
a majority of Degreebound graphs. We have also performed similar experiments (Vandegriend, 1998) using a randomized heuristic algorithm (Frieze, 1988; Posa, 1976) which had
a high success rate on Gn;m graphs, less so on Degreebound graphs. More interestingly, the
existence of a phase transition for both problems did not clearly correspond to a high frequency of dicult instances. We suspect that other properties play a more important role
than does the average degree. This is supported by our results on generalized knight's circuit
graphs, which are all highly regular (with many symmetries), and for which the majority
have average degrees between 4 and 8, compared to a mean degree  3 on Degreebound
graphs.
These results should not be surprising, since it has been shown that asymptotically for
randomly generated graphs, when the edge is added that makes the last vertex degree 2,
then with high probability the graph is Hamiltonian (Bollobas, 1984). In addition, ecient
algorithms have been shown to solve these instances in polynomial time with high probability (Bollobas et al., 1987). Since vertices of degree less than 2 are a trivially detectable
counter-indicator, it is hardly surprising that asymptotically determining Hamiltonicity of
graphs in Gn;m is easy.
We also observe that the performance of our backtrack algorithm can widely vary for
a single graph due to the selection of the initial vertex. Multiple restarts of our backtrack
algorithm after a time limit was reached often resulted in superior performance. We suggest
a little randomization of the algorithm be used while empirically identifying intrinsically
hard random instances of any problem.
242

The Gn;m Phase Transition is Not Hard for the Hamiltonian Cycle Problem

Acknowledgements
This research was supported by Natural Sciences and Engineering Research Council Grant
No. OGP8053.

References

Angluin, D., & Valiant, L. G. (1979). Fast probabilistic algorithms for Hamiltonian circuits
and matchings. J. Comput. System Sci., 18 (2), 155{193.
Baker, A. (1995). Intelligent Backtracking on Constraint Satisfaction Problems. Ph.D.
thesis, University of Oregon.
Bayardo Jr., R. J., & Schrag, R. (1996). Using csp look-back techniques to solve exceptionally hard sat instances. In Proc. of the Second Int'l Conf. on Principles and Practice of
Constraint Programming, Vol. 1118 of Lecture Notes in Computer Science, pp. 46{60.
Bollobas, B., Fenner, T. I., & Frieze, A. M. (1987). An algorithm for nding Hamilton
paths and cycles in random graphs. Combinatorica, 7 (4), 327{341.
Bollobas, B. (1984). The evolution of sparse graphs. In Bollobas, B. (Ed.), Graph Theory
and Combinatorics, pp. 35{57. Academic Press, Toronto.
Bondy, J. A., & Murty, U. S. R. (1976). Graph Theory with Applications. Elsevier, Amsterdam.
Brockington, M., & Culberson, J. C. (1996). Camouaging independent sets in quasirandom graphs.. In Johnson, & Trick (Johnson & Trick, 1996), pp. 75{88.
Broder, A. Z., Frieze, A. M., & Shamir, E. (1994). Finding hidden Hamiltonian cycles.
Random Structures and Algorithms, 5 (3), 395{410.
Cheeseman, P., Kanefsky, B., & Taylor, W. M. (1991). Where the really hard problems are.
In Mylopoulos, J., & Reiter, R. (Eds.), IJCAI-91: Proceedings of the Twelfth International Conference on Articial Intelligence, pp. 331{337 San Mateo, CA. Morgan
Kaufmann.
Culberson, J. C., & Luo, F. (1996). Exploring the k{colorable landscape with iterated
greedy.. In Johnson, & Trick (Johnson & Trick, 1996), pp. 245{284.
Frank, J., Gent, I. P., & Walsh, T. (1998). Asymptotic and nite size parameters for phase
transitions: Hamiltonian circuit as a case study. Information Processing Letters, In
press.
Frank, J., & Martel, C. (1995). Phase transitions in the properties of random graphs. In
CP'95 Workshop: Studying and Solving Really Hard Problems, pp. 62{69.
Frieze, A. M. (1988). Finding Hamilton cycles in sparse random graphs. Journal of Combinational Theory, Series B, 44, 230{250.
243

Vandegriend & Culberson

Gomes, C. P., Selman, B., & Kautz, H. (1998). Boosting combinatorial search through
randomization. In Proceedings of the Fifteenth National Conference on Articial Intelligence (AAAI-98), pp. 431{437. AAAI Press/ The MIT Press.
Hogg, T. (1998). Which search problems are random?. In Proceedings of the Fifteenth
National Conference on Articial Intelligence (AAAI-98), pp. 438{443. AAAI Press/
The MIT Press.
Hogg, T., & Williams, C. P. (1994). The hardest constraint problems: A double phase
transition. Articial Intelligence, 69, 359{377.
Johnson, D. S. (1974). Approximation algorithms for combinatorial problems. Journal of
Computer and System Sciences, 9, 256{278.
Johnson, D. S., Aragon, C. R., McGeoch, L. A., & Schevon, C. (1991). Optimization by
simulated annealing: An experimental evaluation; part II, graph coloring and number
partitioning. Operations Research, 39 (3), 378{406.
Johnson, D. S., & Trick, M. A. (Eds.). (1996). Cliques, Coloring, and Satisability: Second
DIMACS Implementation Challenge (1993), Vol. 26. American Mathematical Society.
Kask, K., & Dechter, R. (1995). GSAT and local consistency. In Mellish, C. S. (Ed.),
IJCAI-95 : Proceedings of the Fourteenth International Joint Conference on Articial
Intelligence, pp. 616{622 San Mateo, CA. Morgan Kaufmann.
Kocay, W. (1992). An extension of the multi-path algorithm for nding Hamilton cycles.
Discrete Mathematics, 101, 171{188.
Komlos, M., & Szemeredi, E. (1983). Limit distribution for the existence of a Hamilton
cycle in a random graph. Discrete Mathematics, 43, 55{63.
Langley, P. (1992). Systematic and nonsystematic search strategies. In Articial Intelligent
Planning Systems: Proceedings of the First International Conference, pp. 145{152.
Martello, S. (1983). Algorithm 595: An enumerative algorithm for nding Hamiltonian
circuits in a directed graph. ACM Transactions on Mathematical Software, 9 (1),
131{138.
Mitchem, J. (1976). On various algorithms for estimating the chromatic number of a graph.
The Computer Journal, 19, 182{183.
Motwani, R., & Raghavan, P. (1995). Randomized Algorithms. Cambridge University Press,
New York.
Olariu, S., & Randall, J. (1989). Welsh-Powell opposition graphs. Information Processing
Letters, 31 (1), 43{46.
Palmer, E. M. (1985). Graphical Evolution: an introduction to the theory of random graphs.
John Wiley & Sons, Toronto.
Posa, L. (1976). Hamiltonian circuits in random graphs. Discrete Mathematics, 14, 359{364.
244

The Gn;m Phase Transition is Not Hard for the Hamiltonian Cycle Problem

Robinson, R. W., & Wormald, N. C. (1994). Almost all regular graphs are Hamiltonian.
Random Structures and Algorithms, 5 (2), 363{374.
Selman, B., Levesque, H., & Mitchell, D. (1992). A new method for solving hard satisability
problems. In Proceedings of the Tenth National Conference on Articial Intelligence
(AAAI-92), San Jose, CA, pp. 440{446.
Shufelt, J. A., & Berliner, H. J. (1994). Generating Hamiltonian circuits without backtracking from errors. Theoretical Computer Science, 132, 347{375.
Spinrad, J. P., & Vijayan, G. (1985). Worst case analysis of a graph coloring algorithm.
Discrete Applied Mathematics, 12 (1), 89{92.
Vandegriend, B. (1998). Finding Hamiltonian cycles: Algorithms, graphs and performance.
Master's thesis, Department of Computing Science, University of Alberta. Online at
\http://www.cs.ualberta.ca/~basil/".
Wormald, N. C. (1984). Generating random regular graphs. Journal of Algorithms, 5,
247{280.

245

Journal of Articial Intelligence Research 9 (1998) 463-506

Submitted 4/98; published 12/98

A Temporal Description Logic
for Reasoning about Actions and Plans
Alessandro Artale

artale@irst.itc.it

ITC-IRST, Cognitive and Communication Technologies Division
I-38050 Povo TN, Italy

Enrico Franconi

Department of Computer Science, University of Manchester
Manchester M13 9PL, UK

franconi@cs.man.ac.uk

Abstract

A class of interval-based temporal languages for uniformly representing and reasoning
about actions and plans is presented. Actions are represented by describing what is true
while the action itself is occurring, and plans are constructed by temporally relating actions
and world states. The temporal languages are members of the family of Description Logics,
which are characterized by high expressivity combined with good computational properties.
The subsumption problem for a class of temporal Description Logics is investigated and
sound and complete decision procedures are given. The basic language TL-F is considered
rst: it is the composition of a temporal logic TL { able to express interval temporal
networks { together with the non-temporal logic F { a Feature Description Logic. It is
proven that subsumption in this language is an NP-complete problem. Then it is shown
how to reason with the more expressive languages TLU -FU and TL-ALCF . The former
adds disjunction both at the temporal and non-temporal sides of the language, the latter
extends the non-temporal side with set-valued features (i.e., roles) and a propositionally
complete language.

1. Introduction
The representation of temporal knowledge has received considerable attention in the Articial Intelligence community in an attempt to extend existing knowledge representation
systems to deal with actions and change. At the same time, many logic-based formalisms
were developed and analyzed by logicians and philosophers for the same purposes. In this
class of logical formalisms, properties such as expressive power and computability have been
studied as regards typical problems involving events and actions.
This paper analyzes from a theoretical point of view the logical and computational
properties of a knowledge representation system that allows us to deal with time, actions
and plans in a uniform way. The most common approaches to model actions are based
on the notion of state change { e.g., the formal models based on the original situation
calculus (McCarthy & Hayes, 1969; Sandewall & Shoham, 1994) or the Strips-like planning
systems (Fikes & Nilsson, 1971; Lifschitz, 1987) { in which actions are generally considered
instantaneous and dened as functions from one state to another by means of pre- and
post-conditions. Here, an explicit notion of time is introduced in the modeling language
and actions are dened as occurring over time intervals, following the Allen proposal (Allen,
c 1998 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

Artale & Franconi

1991). In this formalism an action is represented by describing the time course of the
world while the action occurs. Concurrent or overlapping actions are allowed: eects of
overlapping actions can be dierent from the sum of their individual eects; eects may
not directly follow the action but more complex temporal relations may hold. For instance,
consider the motion of a pointer on a screen driven by a mouse: the pointer moves because
of the movement of the device on the pad { there is a cause-eect relation { but the two
events are contemporary, in the common-sense notion of the word.
A class of interval temporal logics is studied based on Description Logics and inspired by
the works of Schmiedel (1990) and of Weida and Litman (1992). In this class of formalisms
a state describes a collection of properties of the world holding at a certain time. Actions are
represented through temporal constraints on world states, which pertain to the action itself.
Plans are built by temporally relating actions and states. To represent the temporal dimension classical Description Logics are extended with temporal constructors; thus a uniform
representation for states, actions and plans is provided. Furthermore, the distinction made
by Description Logics between the terminological and assertional aspects of the knowledge
allows us to describe actions and plans both at an abstract level (action/plan types) and
at an instance level (individual actions and plans). In this environment, the subsumption
calculus is the main inference tool for managing collections of action and plan types. Action
and plan types can be organized in a subsumption-based taxonomy, which plays the role
of an action/plan library to be used for the tasks known in the literature as plan retrieval
and individual plan recognition (Kautz, 1991). A renement of the plan recognition notion is proposed, by splitting it into the dierent tasks of plan description classication {
involving a plan type { and specic plan recognition with respect to a plan description {
involving an individual plan. According to the latter reasoning task, the system is able to
recognize which type of action/plan has taken place at a certain time interval, given a set
of observations of the world.
Advantages of using Description Logics are their high expressivity combined with desirable computational properties { such as decidability, soundness and completeness of deduction procedures (Buchheit, Donini, & Schaerf, 1993; Schaerf, 1994; Donini, Lenzerini,
Nardi, & Schaerf, 1994; Donini, Lenzerini, Nardi, & Nutt, 1995). The main purpose of this
work is to investigate a class of decidable temporal Description Logics, and to provide complete algorithms for computing subsumption. To this aim, we start with TL-F , a language
being the composition of a temporal logic TL { able to express interval temporal networks {
together with the non-temporal Description Logic F { a Feature Description Logic (Smolka,
1992). It turns out that subsumption for TL-F is an NP-complete problem. Then, we show
how to reason with more expressive languages: TLU -FU , which adds disjunction both at
the temporal and non-temporal sides of the language, and TL-ALCF , which extends the
non-temporal side with set-valued features (i.e., roles) and a propositionally complete Description Logic (Hollunder & Nutt, 1990). In both cases we show that reasoning is decidable
and we supply sound and complete procedures for computing subsumption.
The paper is organized as follows. After introducing the main features of Description
Logics in Section 2, Section 3 organizes the intuitions underlying our proposal. The technical
bases are introduced by briey overviewing the temporal extensions of Description Logics
relevant for this approach { together with the inter-relationships with the interval temporal
modal logic { specically intended for time and action representation and reasoning. The
464

A Temporal Description Logic for Reasoning about Actions and Plans

basic feature temporal language (TL-F ) is introduced in Section 4. The language syntax is
rst described in Section 4.1, together with a worked out example illustrating the informal
meaning of temporal expressions. Section 4.2 reveals the model theoretic semantics of TL-F ,
together with a formal denition of the subsumption and instance recognition problems.
Section 5 shows that the temporal language is suitable for action and plan representation
and reasoning: the well known cooking domain and blocks world domain are taken into
consideration. The sound and complete calculus for the feature temporal language TL-F
is presented in details in Section 6. A proof that subsumption for TL-F is an NP-complete
problem is included. The calculus for TL-F forms the basic reasoning procedure that
can be adapted to deal with logics having an extended propositional part. An algorithm
for checking subsumption in presence of disjunction (TLU -FU ) is devised in Section 7.1;
while in Section 7.2 the non-temporal part of the language is extended with roles and
full propositional calculus (TL-ALCF ). In both cases, the subsumption problem is still
decidable. Operators for homogeneity and persistence are presented in Section 8 for an
adequate representation of world states. In particular, a possible solution to the frame
problem, i.e., the problem to compute what remains unchanged by an action, is suggested.
Section 9 surveys the whole spectrum of extensions of Description Logics for representing
and reasoning with time and action. This Section is concluded by a comparison with State
Change based approaches by briey illustrating the eort made in the situation calculus
area to temporally extend this class of formalisms. Section 10 concludes the paper.

2. Description Logics

Description Logics1 are formalisms designed for a logical reconstruction of representation tools such as frames, semantic networks, object-oriented and semantic data models
{ see (Calvanese, Lenzerini, & Nardi, 1994) for a survey. Nowadays, Description Logics
are also considered the most important unifying formalism for the many object-centered
representation languages used in areas other than Knowledge Representation. Important
characteristics of Description Logics are high expressivity together with decidability, which
guarantee the existence of reasoning algorithms that always terminate with the correct
answers.
This Section gives a brief introduction to a basic Description Logic, which will serve as
the basic representation language for our proposal. As for the formal apparatus, the formalism introduced by (Schmidt-Schau & Smolka, 1991) and further elaborated by (Donini,
Hollunder, Lenzerini, Spaccamela, Nardi, & Nutt, 1992; Donini et al., 1994, 1995; Buchheit
et al., 1993; De Giacomo & Lenzerini, 1995, 1996) is followed: in this way, Description
Logics are considered as a structured fragment of predicate logic. ALC (Schmidt-Schau &
Smolka, 1991) is the minimal Description Logic including full negation and disjunction {
i.e., propositional calculus, and it is a notational variant of the propositional modal logic
K(m) (Halpern & Moses, 1985; Schild, 1991).
The basic types of a Description Logic are concepts, roles, features, and individuals. A
concept is a description gathering the common properties among a collection of individuals;
from a logical point of view it is a unary predicate ranging over the domain of individu1. Description Logics have been also called Frame-Based Description Languages, Term Subsumption Languages, Terminological Logics, Taxonomic Logics, Concept Languages or KL-One-like languages.

465

Artale & Franconi

C; D ! A j

>j
?j
:C j
C uD j
C tD j
8P .C j
9P .C j
p:Cj
p#qj
p"qj
p"
p; q ! f j
pq

(atomic concept)
(top)
(bottom)
(complement)
(conjunction)
(disjunction)
(universal quantier)
(existential quantier)
(selection)
(agreement)
(disagreement)
(undenedness)
(atomic feature)
(path)

Figure 1: Syntax rules for the ALCF Description Logic.
als. Properties are represented either by means of roles { which are interpreted as binary
relations associating to individuals of a given class values for that property { or by means
of features { which are interpreted as functions associating to individuals of a given class
a single value for that property. The language ALCF , extending ALC with features (i.e.,
functional roles) is considered. By the syntax rules of Figure 1, ALCF concepts (denoted by
the letters C and D) are built out of atomic concepts (denoted by the letter A), atomic roles
(denoted by the letter P ), and atomic features (denoted by the letter f ). The syntax rules
are expressed following the tradition of Description Logics (Baader, Burckert, Heinsohn,
Hollunder, Muller, Nebel, Nutt, & Protlich, 1990).
The meaning of concept expressions is dened as sets of individuals, as for unary predicates, and the meaning of roles as sets of pairs of individuals, as for binary predicates.
Formally, an interpretation is a pair I = (I ; I ) consisting of a set I of individuals (the
domain of I ) and a function I (the interpretation function of I ) mapping every concept
to a subset of I , every role to a subset of I  I , every feature to a partial function
from I to I , and every individual into a dierent element of I { i.e., aI 6= bI if a 6= b
(Unique Name Assumption) { such that the equations of the left column in Figure 2 are
satised.
The ALCF semantics identies concept expressions as fragments of rst-order predicate
logic. Since the interpretation I assigns to every atomic concept, role or feature a unary or
binary (functional) relation over I , respectively, one can think of atomic concepts, roles
and features as unary and binary (functional) predicates. This can be seen as follows: an
atomic concept A, an atomic role P , and an atomic feature f , are mapped respectively to
the open formulas FA ( ), P (;  ), and Ff (;  ) with Ff satisfying the functionality axiom
8y; z.Ff (x; y) ^ Ff (x; z) ! y = z { i.e., Ff is a functional relation.
The rightmost column of Figure 2 gives the transformational semantics of ALCF expressions in terms of FOL well-formed formul, while the left column gives the standard
extensional semantics. As far as the transformational semantics is concerned, a concept C ,
a role P and a path p correspond to the FOL open formulae FC ( ), FP (;  ), and Fp (;  ),
466

A Temporal Description Logic for Reasoning about Actions and Plans

>I = I
?I = ;

(:C )I =
(C u D)I =
(C t D)I =
(9P .C )I =
(8P .C )I =
(p : C )I =
p # qI =
p " qI =

true
false

I n C I

C I \ DI
C I [ DI
fa 2 I j 9b.(a; b) 2 P I ^ b 2 C I g
fa 2 I j 8b.(a; b) 2 P I ) b 2 C I g
fa 2 dom pI j pI (a) 2 C I g
fa 2 dom pI \ dom qI j pI (a) = qI (a)g
fa 2 dom pI \ dom qI j pI (a) 6= qI (a)g

(p ")I = I n dom pI
(p  q)I = pI  qI

:FC ( )
FC ( ) ^ FD ( )
FC ( ) _ FD ( )
9x.FP (; x) ^ FC (x)
8x.FP (; x) ) FC (x)
9x.Fp (; x) ^ FC (x)
(9x.Fp (; x) ^ Fq (; x))
(9x; y .Fp (; x) ^ Fq (; y ))^
(8x; y .Fp (; x) ^ Fq (; y ) ! x 6= y )
:9x.Fp (; x)
9x.Fp (; x) ^ Fq (x;  )

Figure 2: The extensional and transformational semantics in ALCF .
respectively. It is worth noting that the extensional semantics of the left column gives also
an interpretation for the formulas of the right column so that the following proposition
holds.

Proposition 2.1 (Concepts vs. fol formul) Let C be an ALCF concept expression.

Then the transformational semantics of Figure 2 maps C into a logically equivalent rst
order formula.

A terminology or TBox is a nite set of terminological axioms. For an atomic concept A,
called dened
concept, and a (possibly complex) concept C , a terminological axiom is of the
:
form A = C . An atomic concept not appearing on the left-hand side of any terminological
axiom is called a primitive concept. Acyclic simple TBoxes only are considered: a dened
concept may appear at most once as the left-hand side of an axiom, and no terminological
cycles are allowed, i.e., no dened concept may occur { neither directly nor indirectly {
within its own denition (Nebel, 1991). An interpretation I satises A =: C if and only if
AI = C I .
As an example, consider the unary relation (i.e., a concept) denoting the class of happy
fathers, dened using the atomic predicates Man, Doctor, Rich, Famous (concepts) and
CHILD, FRIEND (roles):
:
HappyFather = Man u (9CHILD.>) u 8CHILD.(Doctor u 9FRIEND.(Rich t Famous))
i.e., the men whose children are doctors having some rich or famous friend.
An ABox is a nite set of assertional axioms, i.e. predications on individual objects. Let
O be the alphabet of symbols denoting individuals; an assertion is an axiom of the form
C (a), R(a; b) or p(a; b), where a and b denote individuals in O. C (a) is satised by an
interpretation I i aI 2 C I , P (a; b) is satised by I i (aI ; bI ) 2 P I , and p(a; b) is satised
by I i pI (aI ) = bI .
467

Artale & Franconi

A knowledge base is a nite set  of terminological and assertional axioms. An interpretation I is a model of a knowledge base  i every axiom of  is satised by I .  logically
implies A v C (written  j= A v C ) if AI  C I for every model of : we say that A is
subsumed by C in . The reasoning problem of checking whether A is subsumed by C in
 is called subsumption checking.  logically implies C (a) (written  j= C (a)) if aI 2 C I
for every model of : we say that a is an instance of C in . The reasoning problem of
checking whether a is an instance of C in  is called instance recognition.
An acyclic simple TBox can be transformed into an expanded TBox having the same
models, where no dened concept makes use in its denition of any other dened concept.
In this way, the interpretation of a dened concept in an expanded TBox does not depend
on any other dened concept. It is easy to see that A is subsumed by C in an acyclic simple
TBox  if and only if the expansion of A with respect to  is subsumed by the expansion of
C with respect to  in the empty TBox. The expansion procedure recursively substitutes
every dened concept occurring in a denition with its dening expression; such a procedure
may generate a TBox exponential in size, but it has been proved (Nebel, 1990) that it works
in polynomial time under reasonable restrictions. The following interchangeably refers either
to reasoning with respect to a TBox or to reasoning involving expanded concepts with an
empty TBox. In particular, while devising the subsumption calculus for the logics considered
here, it is always assumed that all dened concepts have been expanded.

3. Towards a Temporal Description Logics
Schmiedel (1990) proposed to extend Description Logics with an interval{based temporal
logic. The temporal variant of the Description Logic is equipped with a model-theoretic
semantics. The underlying Description Logic is FLENR, (Donini et al., 1995): it diers
from ALCF in that it does not contain the > and ? concepts, it does not have neither
negation nor disjunction, and it has cardinality restrictions and conjunction over roles.
The new temporal term-forming operators are the temporal qualier at, the existential and
universal temporal quantiers sometime and alltime. The qualier operator species the
time at which a concept holds. The temporal quantiers introduce the temporal variables
constrained by means of temporal relationships based on Allen's interval algebra extended
with metric constraints to deal with durations, absolute times, and granularities of intervals.
To give an example of this temporal Description Logic, the concept of Mortal can be dened
by:
:
Mortal = LivingBeing u (sometime(x) (after x NOW) (at x (:LivingBeing)))
with the meaning of a LivingBeing at the reference interval NOW, who will not be alive
at an interval x sometime after the reference interval NOW. Schmiedel does not propose
any algorithm for computing subsumption, but gives some preliminary hints. Actually,
Schmiedel's logic is argued to be undecidable (Bettini, 1997), sacricing the main benet
of Description Logics: the possibility of having decidable inference techniques.
Schmiedel's temporal Description Logic, when closed under complementation, contains
as a proper fragment the temporal logic HS proposed by Halpern and Shoham (1991).
The logic HS is a propositional modal logic which extends propositional logic with modal
formul of the kind hRi. and [R]. { where R is a basic Allen's temporal relation and hi
468

A Temporal Description Logic for Reasoning about Actions and Plans

and [] are the possibility and necessity modal operators. For example, the modal formula
LivingBeing ^ hafteri.:LivingBeing corresponds to the abovementioned Mortal concept.
Unfortunately, the HS logic is shown to be undecidable, at least for most interesting classes
of temporal structures: \One gets decidability only in very restricted cases, such as when
the set of temporal models considered is a nite collection of structures, each consisting of
a nite set of natural numbers." (Halpern & Shoham, 1991)
Weida and Litman (1992, 1994) propose T-Rex, a loose hybrid integration between
Description Logics and constraint networks. Plans are dened as collections of steps together
with temporal constraints between their duration. Each step is associated with an action
type, represented by a generic concept in K-Rep { a non-temporal Description Logic. Thus
a plan is seen as a plan network, a temporal constraint network whose nodes, corresponding
to time intervals, are labeled with action types and are associated with the steps of the plan
itself. As an example of plan in T-Rex they show the plan of preparing spaghetti marinara:
(

defplan Assemble-Spaghetti-Marinara
((step1 Boil-Spaghetti)
(step2 Make-Marinara)
(step3 Put-Together-SM))
((step1 (before meets) step3)
(step2 (before meets) step3)))

This is a plan composed by three actions, i.e., boiling spaghetti, preparing marinara sauce,
and assembling all things at the end. Temporal constraints between the steps establish
the temporal order in doing the corresponding actions. A structural plan subsumption
algorithm is dened, characterized in terms of graph matching, and based on two separate
notions of subsumption: pure terminological subsumption between action types labeling
the nodes, and pure temporal subsumption between interval relationships labeling the arcs.
The plan library is used to guide plan recognition (Weida, 1996) in a way similar to that
proposed by Kautz (1991). Even if this work has strong motivations, no formal semantics
is provided for the language and the reasoning problems.
Starting from the assumption that an action has a duration in time, our proposal considers an interval-based modal temporal logic { in the spirit of Halpern and Shoham (1991)
{ and reduces the expressivity of (Schmiedel, 1990) in the direction of (Weida & Litman,
1992). While Schmiedel's work lacks computational machinery, and Halpern and Shoham's
logic is undecidable, here an expressive decidable logic is obtained, providing sound and
complete reasoning algorithms. Dierently from T-Rex which uses two dierent languages
to represent actions and plans { a non temporal Description Logic for describing actions
and a second language to compose plans by adding temporal information { here an extension of a Description Logic is chosen in which time operators are available directly as term
constructors. This view implies an integration of a temporal domain in the semantic structure where terms themselves are interpreted, giving the formal way both for a well-founded
notion of subsumption and for proving soundness and completeness of the corresponding
procedure. As an example of the formalism, the plan for preparing spaghetti marinara
introduced above is represented as follows:
469

Artale & Franconi

: 3(y z w) (y (before; meets) w)(z (before; meets) w).
(Boil-Spaghetti@y u
Make-Marinara@z u
Put-Together-SM@w)

Assemble-Spaghetti-Marinara =

Moreover, it is possible to build temporal structured actions { as opposed to the atomic
actions proposed in T-Rex { describing how the world state changes because of the occurrence of an action: in fact, our language allows for feature representation in order to relate
actions to states of the world (see Section 5.2). This kind of expressivity is not captured
by T-Rex, since it uses a non-temporal Description Logic to represent actions. The main
application of T-Rex is plan recognition; according to the ideas of Kautz (1991) a Closed
World Assumption (CWA) (Weida, 1996) is made, assuming that the plan library is complete and an observed plan will be fully accounted for by a single plan. CWA is not relied
on here, following the Open World Semantics characterizing Description Logics. Weaker,
but monotonic, deductions are allowed in the plan recognition process. However, their procedures for recognizing a necessary, optional or impossible individual plan with respect to
a plan description is still applicable, if the plan library is given a closed world semantics.

4. The Feature Temporal Language TL-F
The feature temporal language TL-F is the basic logic considered here. This language is
composed of the temporal Logic TL { able to express interval temporal networks { and the
non-temporal Feature Description Logic F . Note that, each logic of the family of Temporal
Description Logics introduced in this paper is identied by a composed string in which
the rst part refers to the temporal part of the language while the other one refers to the
non-temporal part.

4.1 Syntax
Basic types of the language are concepts , individuals, temporal variables and intervals.
Concepts can describe entities of the world, states and events. Temporal variables denote
intervals bound by temporal constraints, by means of which abstract temporal patterns in
the form of constraint networks are expressed. Concepts (resp. individuals) can be specied
to hold at a certain temporal variable (resp. interval). In this way, action types (resp.
individual actions) can be represented in a uniform way by temporally related concepts
(resp. individuals).
For the basic temporal interval relations the Allen notation (Allen, 1991) (Figure 3) is
used: before (b), meets (m), during (d), overlaps (o), starts (s), nishes (f), equal (=), after
(a), met-by (mi), contains (di), overlapped-by (oi), started-by (si), nished-by (). Concept
expressions (denoted by C; D) are syntactically built out of atomic concepts (denoted by A),
atomic features (denoted by f ), atomic parametric features (denoted by ?g) and temporal
variables (denoted by X; Y ). Temporal concepts (C; D) are distinguished from non-temporal
concepts (E; F ), following the syntax rules of Figure 4. Names for atomic features and
atomic parametric features are from the same alphabet of symbols; the ? symbol is not
intended as operator, but only as dierentiating the two syntactic types.
470

A Temporal Description Logic for Reasoning about Actions and Plans

Relation

Abbr.

Inverse

before(i; j )

b

a

meets(i; j )

m

mi

overlaps(i; j )

o

oi

starts(i; j )

s

si

during(i; j )

d

di

finishes(i; j )

f



i

j

Figure 3: The Allen's interval relationships.
Temporal variables are introduced by the temporal existential quantier \3" { excluding
the special temporal variable ], usually called NOW, and intended as the reference interval.
Variables appearing in temporal constraints (Tc) must be declared within the same temporal
quantier, with the exception of the special variable ]. Temporal variables appearing in the
right hand side of an \@" operator are called bindable. Concepts must not include unbound
(a.k.a. free) bindable variables. Informally, a bindable variable is said to be bound in a
concept if it is declared at the nearest temporal quantier in the body of which it occurs;
this avoid the usual formal inductive denition of a bound variable. Moreover, in chained
constructs of the form ((C [Y1 ]@X1 )[Y2 ]@X2 : : :) non bindable variables { i.e., the ones on
the left hand side of an \@" operator { cannot appear more than once. Note that, since
Description Logics are a fragment of FOL with one free variable, the above mentioned
restrictions force the temporal side of the language to have only one free temporal variable,
i.e., the reference time ].
As usual, terminological axioms for building simple acyclic TL-F TBoxes are allowed.
While using in a concept expression a name referring to a dened concept, it is possible to
use the substitutive qualier construct, to impose a coreference with a variable appearing
in the denition associated to the dened concept. The statement C [Y ]@X constrains the
variable Y , which should appear in the denition of the dened concept C , to corefer with X
(see Section 5.2 for an example). A drawback in the use of this operator is the requirement
to know the internal syntactical form of the dened concept, namely, the names of its
temporal variables.
Let O and OT be two alphabets of symbols denoting individuals and temporal intervals,
respectively. An assertion { i.e., a predication on temporally qualied individual entities {
is a statement of one of the forms C (i; a); p(i; a; b); ?g(a; b); R(i; j ), where C is a concept, p
is a feature, ?g is a parametric feature, R is a temporal relation, a and b denote individuals
in O, i and j denote temporal intervals in OT .
471

Artale & Franconi

TL

F

C; D ! E j
CuD j
C @X j
C [Y ]@X j
3(X ) Tc.C
Tc ! (X (R) Y ) j
(X (R) ]) j
(] (R) Y )
Tc ! Tc j Tc Tc
R; S ! R , S j
s j mi j f j : : :
X; Y ! x j y j z j : : :
X ! XjX X
E; F ! A j

>j
EuF j
p#qj

p:E
p; q ! f j
?g j
pq

(non-temporal concept)
(conjunction)
(qualier)
(substitutive qualier)
(existential quantier)
(temporal constraint)

(disjunction)
(Allen's relations)
(temporal variables)
(atomic concept)
(top)
(conjunction)
(agreement)
(selection)
(atomic feature)
(atomic parametric feature)
(path)

Figure 4: Syntax rules for the interval Description Logic TL-F
4.1.1 A clarifying Example

Let us now informally see the intended meaning of the terms of the language TL-F (for the
formal details see Section 4.2). Concept expressions are interpreted over pairs of temporal
intervals and individuals hi; ai, meaning that the individual a is in the extension of the concept at the interval i. If a concept is intended to describe an action, then its interpretation
can be seen as the set of individual actions of that type occurring at some interval.
Within a concept expression, the special \]" variable denotes the current interval of
evaluation; in the case of actions, it is thought that it refers to the temporal interval
at which the action itself occurs. The temporal existential quantier introduces interval
variables, related to each other and possibly to the ] variable in a way dened by the set of
temporal constraints. To evaluate a concept at an interval X , dierent from the current one,
it is necessary to temporally qualify it at X { written C @X ; in this way, every occurrence of
472

A Temporal Description Logic for Reasoning about Actions and Plans

]

-

Basic-Stack(BLOCK)

x

-

OnTable(BLOCK)

y

OnBlock(BLOCK)

-

Figure 5: Temporal dependencies in the denition of the Basic-Stack action.

] embedded within the concept expression C is interpreted as the X variable2. The informal

meaning of a concept with a temporal existential quantication can be understood with the
following examples in the action domain.
:
Basic-Stack = 3(x y ) (x m ])(] m y ). ((?BLOCK : OnTable)@x u (?BLOCK : OnBlock)@y )

Figure 5 shows the temporal dependencies of the intervals in which the concept Basic-Stack
holds. Basic-Stack denotes, according to the denition (a terminological axiom), any
action occurring at some interval involving a ?BLOCK that was once OnTable and then
OnBlock. The ] interval could be understood as the occurring time of the action type being
dened: referring to it within the denition is an explicit way to temporally relate states
and actions occurring in the world with respect to the occurrence of the action itself. The
temporal constraints (x m ]) and (] m y) state that the interval denoted by x should meet
the interval denoted by ] { the occurrence interval of the action type Basic-Stack { and
that ] should meet y. The parametric feature ?BLOCK plays the role of formal parameter of
the action, mapping any individual action of type Basic-Stack to the block to be stacked,
independently from time. Please note that, whereas the existence and identity of the ?BLOCK
of the action is time invariant, it can be qualied dierently in dierent intervals of time,
e.g., the ?BLOCK is necessarily OnTable only during the interval denoted by x.
Let us comment now on the introduction of explicit temporal variables. The absence of
explicit temporal variables would weaken the temporal structure of a concept since arbitrary
relationships between more than two intervals could not be represented anymore. For
example, having only implicit intervals it is not possible to describe the situation in which
two concept expressions, say C and D, hold at two meeting intervals (say x, y) with the rst
interval starting and the second nishing the reference interval (i.e., the temporal pattern
(x meets y)(x starts ])(y nishes ]) cannot be represented). More precisely, it is not possible
to represent temporal relations between more than two intervals if they are not derivable by
the temporal propagation of the constraints imposed on pairs of variables. While explicit
variables go against the general thrust of Description Logics, the gained expressive power
together with the observation that the variables are limited only to the temporal part of
the language are the main motivations for using them. However, it is easy to drop them by
limiting the temporal expressiveness as proposed by Bettini (1997) (see also Section 9).
An assertion of the type Basic-Stack(i; a) states that the individual a is an action of
the type Basic-Stack occurred at the interval i. Moreover, the same assertion implies that
a is related to a ?BLOCK , say b, which is of type OnTable at some interval j , meeting i, and
of type OnBlock at another interval l, met by i.
2. Since any concept is implicitly temporally qualied at the special ] variable, it is not necessary to
explicitly qualify concepts at ].

473

Artale & Franconi

(s)E = fh[u; v]; [u1 ; v1 ]i 2 T<?  T<? j u = u1 ^ v < v1 g
(f )E = fh[u; v]; [u1 ; v1 ]i 2 T<?  T<? j v = v1 ^ u1 < ug
(mi)E = fh[u; v]; [u1 ; v1 ]i 2 T<?  T<? j u = v1 g
: : : (meaning of the other Allen temporal relations)
E
(R , S ) = R E [ S E
hX; TciE = fV : X 7! T<? j 8(X (R) Y ) 2 Tc. hV (X ); V (Y )i 2 RE g:
Figure 6: The temporal interpretation function.

i; a) =) 9b. ?BLOCK(a; b) ^ 9j; l. (OnTable(j; b) ^ OnBlock(l; b) ^
m(j; i) ^ m(i; l))

Basic-Stack(

An individual action is an object in the conceptual domain associated with the relevant
properties { or states { of the world aected by the individual action itself via a bunch of
features; moreover, temporal relations constrain time intervals imposing an ordering in the
change of the states of the world.

4.2 Semantics

In this Section, a Tarski-style extensional semantics for the TL-F language is given, and a
formal denition of the subsumption and recognition reasoning tasks is devised.
Assume a linear, unbounded, and dense temporal structure T = (P ; <), where P is
a set of time points and < is a strict partial order on P . In such a structure, given an
interval X and a temporal relation R, it is always possible to nd an interval Y such that
(X (R) Y ). The assumption of linear time { which means that for any two points t1 and
t2 such that t1  t2 the set of points ft j t1  t  t2 g is totally ordered { ts the intuition
about the nature of time, so that the pair [t1 ; t2 ] can be thought as the closed interval of
points between t1 and: t2 . The interval set of a structure T is dened as the set T<? of all
closed intervals [u; v] = fx 2 P j u  x  v; u 6= vg in T .
A primitive interpretation I =: hT<? ; I ; I i consists of a set T<? (the interval set of
the selected temporal structure T ), a set I (the domain of I ), and a function I (the
primitive interpretation function of I ) which gives a meaning to atomic concepts, features
and parametric features:

AI  T<?  I ;

f I : (T<?  I ) partial
7,! I ;

?gI : I partial
7,! I

Atomic parametric features are interpreted as partial functions; they dier from atomic
features for being independent from time.
In order to give a meaning to temporal expressions present in generic concept expressions, Figure 6 denes the temporal interpretation function. The temporal interpretation
function E depends only on the temporal structure T . The labeled directed graph hX; Tci
{ where X is the set of variables representing the nodes, and Tc is the set of temporal constraints representing the arcs { is called temporal constraint network. The interpretation
474

A Temporal Description Logic for Reasoning about Actions and Plans

AIV ;t;H = fa 2 I j ht; ai 2 AI g = AIt

>IV ;t;H = I = >I
(C u D)IV ;t;H = CVI ;t;H \ DVI ;t;H
(p # q)IV ;t;H = fa 2 dom pIt \ dom qtI j pIt (a) = qtI (a)g = (p # q)It
(p : C )IV ;t;H = fa 2 dom pIt j pIt (a) 2 CVI ;t;Hg

(C @X )IV ;t;H = CVI ;V (X );H
(C [Y ]@X )IV ;t;H = CVI ;t;H[fY 7!V (X )g
(3(X ) Tc. C )IV ;t;H = fa 2 I j 9W . W 2 hX; TciEH[f]7!tg ^ a 2 CWI ;t;; g
ftI = f^t : I partial
7,! I j 8a. (a 2 dom f^t $ ht; ai 2 dom f I ) ^
f^t (a) = f I (t; a)
(p  q)It = pIt  qtI
?gtI = ?gI
Figure 7: The interpretation function.
of a temporal constraint network is a set of variable assignments that satisfy the temporal
constraints. A variable assignment is a function V : X 7! T<? associating an interval value to
a temporal variable. A temporal constraint network is consistent if it admits a non empty
interpretation. The notation, hX; TciEfx1 7!t1 ;x2 7!t2 ;:::g , used to interpret concept expressions,
denotes the subset of hX; TciE where the variable xi is mapped to the interval value ti .
It is now possible to interpret generic concept expressions. Consider the equations
introduced in Figure 7. An interpretation function IV ;t;H, based on a variable assignment
V , an interval t and a set of constraints H = fx1 7! t1; : : :g over the assignments of inner
variables, extends the primitive interpretation function in such a way that the equations
of Figure 7 are satised. Intuitively, the interpretation of a concept CVI ;t;H is the set of
entities of the domain that are of type C at the time interval t, with the assignment for the
free temporal variables in C given by V { see (C @X )IV ;t;H { and with the constraints for
the assignment of variables in the scope of the outermost temporal quantiers given by H.
Note that, H interprets the variable renaming due to the temporal substitutive qualier {
see (C [Y ]@X )IV ;t;H { and it takes eect during the choice of a variable assignment, as the
equation for (3(X ) Tc. C )IV ;t;H shows.
In absence of free variables in the concept expression { with the exception of ]{ for
notational simplication the natural interpretation function CtI ; being equivalent to the
interpretation function CVI ;t;H with any V such that V (]) = t and H = ; is introduced. The
set of interpretations fCVI ;t;Hg obtained by varying I ; V ; t with a xed H is maximal wrt set
inclusion if H = ;, i.e., the set of natural interpretations includes any set of interpretations
with a xed H. In fact, since H represents a constraint in the assignment of variables, the
unconstrained set is the larger one. Note that, for feature interpretation only the natural
one is used since it is not admitted to temporally qualify them.
475

Artale & Franconi

]
]

Boil-Spaghetti

x

Make-Spaghetti

-

Boil

-

Figure 8: Temporal dependencies in the denition of the Boil-Spaghetti plan.
An interpretation I satises the terminological axiom A =: C i AIt = CtI , for every t.
A concept C is subsumed by a concept D (C v D) if CtI  DtI for every interpretation I
and every interval t. An interpretation I is a model for a concept C if CtI 6= ; for some t.
If a concept has a model, then it is satisable, otherwise it is unsatisable.
Each TL-F concept expression is always satisable, with the proviso that the temporal
constraints introduced by the existential quantiers are consistent. This latter condition
can be easily checked during the reduction of the concept into a normal form when the
minimal temporal network (see Section 11, denition 6.5) is computed.
It is interesting to note that only the relations s, f, mi are really necessary, because it is
possible to express any temporal relationship between two distinct intervals using only these
three relations and their transpositions si, , m (Halpern & Shoham, 1991). The following
equivalences hold:

3x (x a ]). C @x  3xy (y mi ])(x mi y). C @x
3x (x d ]). C @x  3xy (y s ])(x f y). C @x
3x (x o ]). C @x  3xy (y s ])(x  y). C @x
To assign a meaning to ABox axioms, the temporal interpretation function E is extended
to temporal intervals so that iE is an element of T<? for each i 2 OT . The semantics of
assertions is the following: C (i; a) is satised by an interpretation I i aI 2 CiIE ; p(i; a; b)
is satised by I i pIiE (aI ) = bI ; ?g(a; b) is satised by I i ?gI (aI ) = bI ; and R(i; j ) is
satised by I i hiE ; j E i 2 RE . Given a knowledge base , an individual a in O is said to
be an instance of a concept C at the interval i if  j= C (i; a).
Now we are able to give a semantic denition for the reasoning task we already called
specic plan recognition with respect to a plan description. This is an inference service that
computes if an individual action/plan is an instance of an action/plan type at a certain
interval, i.e., the task known as instance recognition in the Description Logic community.
Given a knowledge base , an interval i, an individual a and a concept C , the instance
recognition problem is to test whether  j= C (i; a).

5. Action and plan representation: two examples
An action description represents how the world state may evolve in relation with the possible
occurrence of the action itself. A plan is a complex action: it is described by means of
temporally related world states and simpler actions. The following introduces examples of
action and plan representations from two well known domains, the cooking domain (Kautz,
476

A Temporal Description Logic for Reasoning about Actions and Plans

z

Make-Marinara

x

y
- y

Make-Spaghetti

-

-

Boil-Spaghetti
Boil

w

-

Put-Together-SM

Figure 9: Temporal dependencies in the denition of Assemble-Spaghetti-Marinara.
1991; Weida & Litman, 1992) and the block world (Allen, 1991), with the aim of showing
the applicability of our framework.

5.1 The Cooking Domain
Let us introduce the plan Boil-Spaghetti:
:
Boil-Spaghetti = 3x (x b ]). (Make-Spaghetti@x u Boil)
Figure 8 shows the temporal dependencies of the intervals in which the concept Boil-Spaghetti holds. The denition employs the ] interval to denote the occurrence time of the
plan itself; in this way, it is possible to describe how dierent actions or states of the world
concurring to the denition of the plan are related to it. This is why the variable ] is
explicitly present in the denition of Boil-Spaghetti, instead of a generic variable: the
Boil action should take place at the same time of the plan itself, while Make-Spaghetti
occurs before it.
The denition of a plan can be reused within the denition of other plans by exploiting
the full compositionality of the language. The plan dened above Boil-Spaghetti is used
in the denition of Assemble-Spaghetti-Marinara:
:
Assemble-Spaghetti-Marinara = 3(y z w) (y b w)(z b w).
(Boil-Spaghetti@y u
Make-Marinara@z u
Put-Together-SM@w)
In this case, precise temporal relations between the nodes of two corresponding temporal
constraint networks are asserted: e.g., the action Put-Together-SM takes place strictly after
the Boil action (Figure 9). Observe that the occurrence interval of the plan Assemble-Spaghetti-Marinara does not appear in the Figure because it is not temporally related with
any other interval.
A plan subsuming Assemble-Spaghetti-Marinara is the more general plan dened below, Prepare-Spaghetti, supposing that the action Make-Sauce subsumes Make-Marinara.
This means that among all the individual actions of the type Prepare-Spaghetti there are
all the individual actions of type Assemble-Spaghetti-Marinara:
:
Prepare-Spaghetti = 3 (y z ) (). (Boil-Spaghetti@y u Make-Sauce@z )
477

Artale & Franconi

]
- w

Stack(OBJ1, OBJ2)

Clear-Block(OBJ1)

v

- z
- y

Holding-Block(OBJ1) Clear-Block(OBJ1)

Clear-Block(OBJ2)

ON(OBJ1, OBJ2)

x

Figure 10: Temporal dependencies in the denition of the Stack action.
However, note that Boil-Spaghetti does not subsume Prepare-Spaghetti, even if it is a
conjunct in the denition of the latter. This could be better explained observing how the
denition of Prepare-Spaghetti plan is expanded:
:
Prepare-Spaghetti = 3 (x y z ) (x b y ). (Make-Spaghetti@x u Boil@y u
Make-Sauce@z )
Then, the Boil action occurs at the interval y { which can be dierent from the occurring
time of Prepare-Spaghetti { as the eect of binding Boil-Spaghetti to the temporal variable y. On the contrary, in the denition of Boil-Spaghetti the Boil action takes place necessarily at the same time. Subsumption between Prepare-Spaghetti and Boil-Spaghetti
fails since dierent temporal relations between the actions describing the two plans and the
plans themselves are specied. In particular, observe that the Boil-Spaghetti plan denotes
a narrower class than the plan expression
3(x y) (x b y). (Make-Spaghetti@x u Boil@y)
which subsumes both Prepare-Spaghetti and Boil-Spaghetti itself.

5.2 The Blocks World Domain

As a further example of the expressive power of the temporal language, it is now shown
how to represent the Stack action in the blocks world, in a more detailed way than the
previous simple Basic-Stack action used as a clarifying example. Thus a stacking action
involves two blocks, which should be both clear at the beginning; the central part of the
action consists of grasping one block; at the end, the blocks are one on top of another, and
the bottom one is no longer clear (Figure 10).
Our representation borrows from the Rat Description Logic (Heinsohn, Kudenko, Nebel,
& Protlich, 1992) the intuition of representing action parameters by means of partial
functions mapping from the action itself to the involved action parameter (see Section 9). In
the language, these functions are called parametric features. For example, the action Stack
has the parameters ?OBJECT1 and ?OBJECT2, representing in some sense the objects that are
involved in the action independently from time. So, in the assertion \?OBJECT1(a; block-a)",
block-a denotes the rst object involved in the action a at any interval. On the other hand,
an assertion involving a (non-parametric) feature, e.g., \ON(i; block-a; block-b)", does not
imply anything about the truth value at intervals other than i.
The concept expression, which denes the Stack action, makes use of temporal qualied
concept expressions, including feature selections and agreements: the expression (?OBJECT2 :
Clear-Block)@x means that the second parameter of the action should be a Clear-Block
478

A Temporal Description Logic for Reasoning about Actions and Plans

at the interval denoted by x; while (?OBJECT1  ON # ?OBJECT2)@y indicates that at the
interval y the object on which ?OBJECT1 is placed is ?OBJECT2. The formal denition of the
action Stack is:
:
Stack = 3(x y z v w) (x  ])(y mi ])(z mi ])(v o ])(w f ])(w mi v ).
((?OBJECT2 : Clear-Block)@x u (?OBJECT1  ON # ?OBJECT2)@y u
(?OBJECT1 : Clear-Block)@v u (?OBJECT1 : Holding-Block)@w u
(?OBJECT1 : Clear-Block)@z )
The above dened concept does not state which properties are the prerequisites for the
stacking action or which properties must be true whenever the action succeeds. What this
action intuitively states is that ?OBJECT1 will be on ?OBJECT2 in a situation where both
objects are clear at the start of the action. Note that the world states described at the
intervals denoted by v; w; z are the result of an action of grasping a previously clear block:
:
Grasp = 3(x w z ) (x o ])(w f ])(w mi x)(z mi ]).
((?OBJECT1 : Clear-Block)@x u (?OBJECT1 : Holding-Block)@w u
(?OBJECT1 : Clear-Block)@z )
The Stack action can be redened by making use of the Grasp action:
:
Stack = 3(x y u v ) (x  ])(y mi ])(u f ])(v o ]).
((?OBJECT2 : Clear-Block)@x u (?OBJECT1  ON # ?OBJECT2)@y u
(Grasp[x]@v)@u)
The temporal substitutive qualier (Grasp[x]@v) renames within the dened Grasp action
the variable x to v and it is a way of making coreference between two temporal variables,
while the temporal constraints peculiar to the renamed variable x are inherited by the
substituting interval v. Furthermore, the eect of temporally qualifying the grasping action
at u is that the ] variable associated to the grasping action { referring to the occurrence
time of the action itself { is bound to the interval denoted by u. Because of this binding on
the occurrence time of the grasping action, the ] variable in the grasping action and the ]
variable in the stacking action denote dierent time intervals, so that the grasping action
occurs at an interval nishing the occurrence time of the stacking action.
Now it is shown how from a series of outside observations action recognition can be
performed { i.e., the task called specic plan recognition with respect to a plan description.
The following ABox describes a situation in which blocks can be clear, grasped and/or on
each other, and in which a generic individual action a is taking place at time interval ia
having the blocks block-a and block-b as its parameters:

?OBJECT1(a; block-a); ?OBJECT2(a; block-b);
o(i1 ; ia ); Clear-Block(i1 ; block-a); (i2 ; ia ); Clear-Block(i2 ; block-b);
mi(i3 ; i1 ); f (i3 ; ia ); Holding-Block(i3 ; block-a);
mi(i4 ; ia ); Clear-Block(i4 ; block-a); mi(i5 ; ia ); ON(i5 ; block-a; block-b)
The system deduces that, in the context of a knowledge base  composed by the above
ABox and the denition of the Stack concept in the TBox, the individual action a is of
type Stack at the time interval ia , i.e.,  j= Stack(ia ; a).
479

Artale & Franconi

C @X u D@X
(C @X1 )@X2
(C @X1 u D)@X2
C u 3(X ) Tc. D

!
!
!
!

(C u D)@X
C @X1
C @X1 u D@X2
3(X ) Tc. (C u D)
if C doesn't contain free variables

3(X )Tc1 .(C u


3(Y ) Tc2 . D [Y1 ]@X1 : : : [Yp ]@Xq @X ) ! 3(X ][Y1 =X1 ]:::[Yp=Xq ] Y )Tc1 [ Tc2+[]=X] .(C u D+ @X )
if D doesn't contain existential temporal quantiers
p : (q : C ) ! (p  q) : C
p : (C u D ) ! p : C u p : D
p : (q1 # q2 ) ! p  q1 # p  q2

,

Prescriptions: X ][Y1 =X1 ]:::[Yp=Xq ] Y returns the union of the two sets of variables X and Y , where each
occurrence of Y1 ; : : : ; Yp is substituted by X1 ; : : : ; Xq , respectively, while all the other elements of Y occurring
in X are renamed with fresh new identiers. Z+ is intended to be the expression Z where the same
substitution or renaming has taken place. The condition on the last rule forces application to start from the
last nested existential temporal qualied concept.

Figure 11: Rewrite rules to transform an arbitrary concept into an existential concept.

6. The Calculus for TL-F
This Section presents a calculus for deciding subsumption between temporal concepts in the
Description Logic TL-F . The calculus is based on the idea of separating the inference on
the temporal part from the inference on the Description Logic part. This is achieved by rst
looking for a normal form of concepts. Concept subsumption in the temporal language is
then reduced to concept subsumption between non-temporal concepts and to subsumption
between temporal constraint networks.

6.1 Normal Form
Every TL-F concept expression can be reduced to an equivalent existential concept of the
form: 3(X ) Tc. (Q0 u Q1 @X1 u : : : u Qn@Xn ), where each Q is a non-temporal concept, i.e., it
is an element of the language F . A concept in existential form can be seen as a conceptual
temporal constraint network, i.e., a labeled directed graph hX; Tc; Q@X i where arcs are

labeled with a set of arbitrary temporal relationships { representing their disjunction {
nodes are labeled with non-temporal concepts and, for each node X , the temporal relation
(X = X ) is implicitly true. Moreover, since the normalized concepts do not contain free
variables or substitutive qualiers, in the following the natural interpretation function (see
Section 4.2) is used.

Proposition 6.1 (Equivalence of EF) Every concept C can be reduced in linear time
into an equivalent existential concept (ef C ), by exhaustively applying the set of rewrite
rules of Figure 11.
480

A Temporal Description Logic for Reasoning about Actions and Plans

Procedure

hX; Tci; y):

Covering(

, ;;
, ;;
Z = fz 2 X j (z (=; : : :) y) 2 Tcg;
8s 2 }(Z ) do

if j s j 2 and the graph hX; Tc i obtained by deleting the \=" temporal relation between

mid
result

the node y and each of the nodes in s is inconsistent
then mid
, mid [ fsg;

8s 2 mid do
if :9t 2 mid. t  s
then result
, result [ fsg;
return

result.

Figure 12: Procedure which computes a covering.
Note that (ef C ) makes explicit all the possible chains of features by reducing each nontemporal concept Q to a conjunction of atomic concepts, feature selections restricted to
atomic concepts and feature agreements { i.e., each Q is a feature term expression (Smolka,
1992).
The normalization proceeds by discovering all the possibles interactions between nodes
with the intention of making explicit all the implicit information. A crucial temporal interaction occurs when a node is always coincident with a set of nodes in every possible
interpretation of the temporal network.
Denition 6.2 (Covering) Given a temporal constraint network hX; Tci, let y 2 X and
Z = fz1 ; z2 ; : : : ; zp g  X , with p  1, and y 62 Z . Z is a Covering for y if 8V 2 hX; TciE ,
V (y) 2 fV (z1 ); V (z2 ); : : : ; V (zp)g and for each W  Z , W is not a covering for y. If Z = ;,
then y is called uncovered, otherwise y is said covered by Z .
Proposition 6.3 (Covering procedure) Given a temporal constraint network hX; Tci in
minimal form (see, e.g., (van Beek & Manchak, 1996)) and a node y 2 X then the procedure
described in Figure 12 returns all the possible coverings for y with size  2.
The idea behind the covering is that whenever a set of nodes fz1 ; z2 ; : : : ; zp g is a covering
for y the disjunctive concept expression (Qz1 t : : : t Qzp ) should be conjunctively added to
the concept expression Qy . Actually, since in TL-F concept disjunction is not allowed it will
be sucient to add to the node y the Least Commom Subsumer (lcs) of (Qz1 t : : : t Qzp )
as dened below.
Denition 6.4 (lcs) Let Q1; : : : ; Qn; Q; C be F concept expressions. Then, the concept
Q = lcsfQ1 ; : : : ; Qn g is such that: Q1 v Q ^ : : : ^ Qn v Q and there is no C such that
Q1 v C ^ : : : ^ Qn v C ^ C < Q.
Given a concept in existential form, the temporal completion of the constraint network is
computed as described below.
Denition 6.5 (Completed existential form) The temporal completion of a concept in
existential form { the Completed Existential Form, CEF { is obtained by sequentially applying the following steps:
481

Artale & Franconi

 (closure) The transitive closure of the Allen temporal relations in the conceptual

temporal constraint network is computed, obtaining a minimal temporal network (see,
e.g., (van Beek & Manchak, 1996)).

 (= collapsing) For each equality temporal constraint, collapse the equal nodes by
applying the following rewrite(rule:
3(X n fxj g) Tc[xj =xi]. Q[xj =xi ] if xi 6= xj and xj 6= ].
3(X ) Tc (xi = xj ). Q ! 3
(X n fxi g) Tc[xi=]] . Q[xi =]] if xi 6= xj and xj = ].
Then apply exhaustively the rst rule of Figure 11.

 (covering) For each y 2 X let compute the covering = fZ 1; : : : ; Z ng following the
procedure showed by proposition 6.3. Whenever the covering is not empty, translate
Qy applying the following rewrite rule: Qy ! Qy ui=1:::n lcsfQi1 ; : : : ; Qim g where Z i =
fzi1 ; : : : ; zim g, and Qij @zij 2 hX; Tc; Q@X i.

 (parameter introduction) New information is added to each node because of the pres-

ence of parameters, as the following rules show. The ; symbol is intended so that,
each time the concept expression in the left hand side appears in some node of the
temporal constraint network, possibly conjoined with other concepts, then the right
hand side represents the concept expression that must be conjunctively added to all the
other nodes; square brackets point out optional parts; the letters f (?f ) and g (?g),
possibly with subscripts, denote atomic (parametric) features while p and q stand for
generic features.
?g1  : : :  ?gn [ f [ p]] : C
?g1  : : :  ?gn [ f [ p]] # g [ q]
?g1  : : :  ?gn # ?f1  : : :  ?fm
?g1  : : :  ?gn  g [ p] # ?f1  : : :  ?fm [ f [ q]]

;
;
;
;

?g1  : : :  ?gn : >.
?g1  : : :  ?gn : >.
?g1  : : :  ?gn # ?f1  : : :  ?fm .
?g1  : : :  ?gn : > u
?f1  : : :  ?fm : >.

Proposition 6.6 (Equivalence of CEF) Every concept in existential form can be reduced into an equivalent completed existential concept.

Both the covering and the parameter introduction steps can be computed independently
after the =-collapsing step and then conjoining the resulting concept expressions. Observe
that, to obtain a completed existential concept, the steps of the normalization procedure
require linear time with the exception of the computation of the transitive closure of the
temporal relations, and the covering step. Both these steps involve NP-complete temporal
constraint problems (van Beek & Cohen, 1990). However, it is possible to devise reasonable
subsets of Allen's algebra for which the problem is polynomial (Renz & Nebel, 1997). The
most relevant properties of a concept in CEF is that all the admissible interval temporal
relations are explicit and the concept expression in each node is no more renable without
changing the overall concept meaning; this is stated by the following proposition.
Proposition 6.7 (Node independence of CEF) Let hX; Tc; Q@X i be a conceptual temporal constraint network in its completed form (CEF); then, for all Q 2 Q and for all
482

A Temporal Description Logic for Reasoning about Actions and Plans

F concept expressions C such that C 6w Q, there exists an interpretation I such that
hX; Tc; (Q u C )@X iIt 6= hX; Tc; Q@X iIt , for some interval t.

Proof. The proposition states that the information in each node of the CEF is independent
from the information in the other nodes. In fact, hX; Tc; (Q u C )@X iIt = hX; Tc; Q@X iIt if
the concept expression in one node implies new information in some other node. Two cases
can be distinguished.
i) Covered Nodes. Both the (= collapsing) rule and the (covering) rule provide to restrict a
covered node with the most specic F concept expression. Indeed, the (= collapsing) rule
provides collapsing two contemporary nodes conjoining the concept expressions of each of
them. On the other hand, the (covering) rule adds to the covered node the most specic
F concept expression that subsumes the disjunctive concept expression that is implicitly
true at the covered node. Note that, thanks to the (Closure) rule, all the possible equal
temporal relations are made explicit. So these two normalization rules cover all the possible
cases of temporal interactions between nodes.
ii) No coincident nodes. Every time-invariant information should spread over all the nodes.
Both parametric features and the > concept have a time-invariant semantics: the only timeinvariant concept expressions are >, ?g1  : : :  ?gn : >, ?g1  : : :  ?gn # ?f1  : : :  ?fm , with
n; m  1, or an arbitrary conjunction of these terms. The (parameter introduction) rule
captures all the possible syntactical cases of completion concerning time-invariant concept
expressions. By induction on the syntax, it can be proven that adding to a node any other
concept expression changes the overall interpretation.
2
The last normalization procedure eliminates nodes with redundant information. This
nal normalization step ends up with the concept in the essential graph form, that will be
the normal form used for checking concept subsumption.
Denition 6.8 (Essential graph) The subgraph of the CEF of a conceptual temporal constraint network T = hX; Tc; Q@X i obtained by deleting the nodes labeled only with timeinvariant concept expressions { with the exception of the ] node { is called essential graph
of T : (ess T ).
Proposition 6.9 (Equivalence of essential graph) Every concept in completed existential form can be reduced in linear time into an equivalent essential graph form.

Theorem 6.10 (Equivalence of normal form) Every concept expression can be reduced

into an equivalent essential graph form. If a polynomial fragment of Allen's algebra is
adopted, the reduction takes polynomial time.
As an example, the normal form is shown { i.e., the essential graph { of the previously
introduced Stack action (see Section 5.2):
:
Stack = 3(x y v w z )(x  ])(y mi ])(z mi ])(w f ])(v o ])(y mi x)(z mi x)(w f x)
(v (o; d; s) x)(z (=; s; si) y)(w m y)(v b y)(w m z )(v b z )(w mi v).
((?OBJECT2 : Clear-Block u ?OBJECT1 : >)@x u
(?OBJECT1 ON # ?OBJECT2)@y u
(?OBJECT1 : Clear-Block u ?OBJECT2 : >)@v u
(?OBJECT1 : Hold-Block u ?OBJECT2 : >)@w u
(?OBJECT1 : Clear-Block u ?OBJECT2 : >)@z )
483

Artale & Franconi

In this example, the essential graph is also the CEF of Stack since there are no redundant
nodes.

6.2 Computing Subsumption

A concept subsumes another one just in case every possible instance of the second is also an
instance of the rst, for every time interval. Thanks to the normal form, concept subsumption in the temporal language is reduced to concept subsumption between non-temporal
concepts and to subsumption between temporal constraint networks. A similar general procedure was rst presented in (Weida & Litman, 1992), where the language for non-temporal
concepts is less expressive { it does not include features or parametric features.
To compute subsumption between non-temporal concepts { which may possibly include
lcs concepts { we refer to (Cohen, Borgida, & Hirsh, 1992). In the following, we will write
\wF " for subsumption between non-temporal F concepts taking into account lcs concepts.
Denition 6.11 (Variable mapping) A variable mapping M is a total function M :
X 1 7! X 2 such that M(]) = ]. We write M(X ) to intend fM(X ) j X 2 X g, and M(Tc)
to intend f(M(X ) (R) M(Y )) j (X (R) Y ) 2 Tcg.

Denition 6.12 (Temporal constraint subsumption) A temporal constraint (X1 (R1 )Y1)
is said to subsume a temporal constraint (X2 (R2 )Y2 ) under a generic variable mapping M,
written (X1 (R1 )Y1 ) wM (X2 (R2 ) Y2 ), if M(X1 ) = X2 , M(Y1 ) = Y2 and (R1 )E  (R2 )E
for every temporal interpretation E .
Proposition 6.13 (TC subsumption algorithm) (X1 (R1 )Y1) wM (X2 (R2 )Y2) if and
only if M(X1 ) = X2 , M(Y1 ) = Y2 and the disjuncts in R1 are a superset of the disjuncts
in R2 .

Proof. Follows from the observation that the 13 temporal relations are mutually disjoint
and their union covers the whole interval pairs space.
2

Denition 6.14 (Temporal constraint network subsumption) A temporal constraint
network hX 1 ; Tc1 i subsumes a temporal constraint network hX 2 ; Tc2 i under a variable mapping M : X 1 7! X 2 , written hX 1 ; Tc1 i wM hX 2 ; Tc2 i, if hM(X 1 ); M(Tc1 )iE  hX 2 ; Tc2 iE
for every temporal interpretation E .
Proposition 6.15 (TCN subsumption algorithm) hX 1; Tc1 i wM hX 2 ; Tc2i i, after
computing the temporal transitive closure, there exists a variable mapping M : X 1 7! X 2
such that for all X1i ; Y1j 2 X 1 exist X2m ; Y2n 2 X 2 which satisfy (X1i (R1i;j ) Y1j ) wM
(X2m (R2m;n ) Y2n ).

Proof. \( " Since from denition 6.12 (X1i (R1i;j ) Y1j ) wM (X2m (R2m;n ) Y2n ) implies that
(R1i;j )E  (R2m;n )E for every E , then, from the denition of interpretation of a temporal
constraint network, it is easy to see that each assignment of variables V in the interpretation
of hX 2 ; Tc2 i is also an assignment in the interpretation of hM(X 1 ); M(Tc1 )i.
\) " Suppose that one is not able to nd such a mapping; then, by hypothesis, for each
possible variable mapping there exists some i; j such that R1i;j is not a superset of R2m;n .
484

A Temporal Description Logic for Reasoning about Actions and Plans

Since, by assumption, the temporal constraint networks are minimal, the temporal relation
R2m;n cannot be further restricted. So, for each variable mapping and each temporal interpretation E , we can build an assignment V  such that hV  (X2m ); V  (X2n )i 2 (R2m;n )E while
hV  (X1i ); V  (X1j )i 62 (R1i;j )E . Now, we can extend the assignment V  in such a way that
V  2 (hX 2; Tc2 i)E while V  62 (hM(X 1 ); M(Tc1)i)E . This contradicts the assumption that
2
hX 1; Tc1 i wM hX 2; Tc2 i.

Denition 6.16 (S-mapping) An s-mapping from a conceptual temporal constraint network hX 1 ; Tc1 ; Q@X 1 i to a conceptual temporal constraint network hX 2 ; Tc2 ; Q@X 2 i is a
variable mapping S : X 1 7! X 2 such that the non-temporal concept labeling each node
in X 1 subsumes the non-temporal concept labeling the corresponding node in S (X 1 ), and
hX 1; Tc1 i wS hX 2; Tc2i.
The algorithm for checking subsumption between temporal concept expressions reduces the
subsumer and the subsumee in essential graph form, then it looks for an s-mapping between the essential graphs by exhaustive search. To prove the completeness of the overall
subsumption procedure it will be showed that the introduction of lcs's preserves the subsumption. A model-theoretic characterization of the lcs will be given for showing this
property. Let's start to build an Herbrand model for an F concept. Let C 0(x) denote the
rst order formula corresponding to a concept C (see proposition 2.1), while the functionality of features can be expressed with a set of formul F . By syntax induction it easy to
show that C 0 (x) is an existentially quantied formula with one free variable. Moreover, the
matrices of such formula is a conjunction of positive predicates. F [ fC 0 (x)g is logically
equivalent
to F [ fC 00 (x)g where the functionality axioms allow to map every subformula
V
00
y 9y.Ff (x; y) into 9!y.Ff (x; y). Then C (x) is such that all the existential quantiers in
C 0 (x) (which come from the rst order conversion of features) are replaced by 9! quantiers.
Now, F [ fC 000 (a)g { where a is a constant substituting the free variable x and C 000 (a) is
obtained by skolemizing the 9! quantied variables { is a set of denite Horn clauses.

Denition 6.17 (Herbrand model) Let C be an F concept expression. Then we dene
its Minimal Herbrand Model HC as the Minimal Herbrand Model of the above mentioned
set of denite Horn clauses F [ fC 000 (a)g.
Lemma 6.18 (F concept subsumption) Let C; D be F concept expressions, and HC ; HD
their minimal Herbrand models obtained by skolemizing the rst order set F [fC 000 (a); D000 (a)g.
Then, C v D i HD  HC .
Proof. C v D i F [ fC 0 (x)g j= D0 (x), i F [ fC 00 (x)g j= D00 (x), where C 00 and D00
are obtained by applying the functionality axioms to the set fC 0 (x); D0 (x)g (i.e., uni-

fying the variables in the functional predicates) and then replacing all the existential
quantiers by 9! quantiers. Now, C 000 (x) and D000 (x) are obtained by skolemizing the
9! quantied variables in the following way: let C 00(x) = 9!y1; : : : ; yn(x; y1 ; : : : ; yn) and let
D00 (x) = 9!y1 ; : : : ; yk ; z1 ; : : : ; zm (x; y1 ; : : : ; yk ; z1 ; : : : ; zm ), with 0  k  n, then skolemize
the formula:  = 9!y1 ; : : : ; yn ; z1 ; : : : ; zm (x; y1 ; : : : ; yn ) ^ (x; y1 ; : : : ; yk ; z1 ; : : : ; zm ), and
let 0 (x) indicate its skolemized form. Then, C 000 (x) = 0 (x) and D000 (x) = 0 (x). Now,
since every existential quantication in C 00 (x); D00 (x) was of type 89! then the thesis is true
485

Artale & Franconi

i F [ fC 000 (a)g j= D000 (a), where a is a constant substituting the free variable x (see (van
Dalen, 1994)). Now, as showed by lemma 6.17, both C 000 (a) and D000 (a) have minimal Herbrand models HC ; HD that verify the lemma hypothesis. Then, F [ fC 000 (a)g j= D000 (a) i
HD  HC .
2
We are now able to give a model-theoretic characterization of the lcs that will be crucial
to prove the subsumption-preserving property.
Lemma 6.19 (lcs model property) Let Q1; : : : ; Qn be F concept expressions, and HQ1 ;
: : : ; HQn their minimal Herbrand models obtained by skolemizing the rst order set F [
fQ0001 (a); : : : ; Q000n (a)g. Then, Q = lcsfQ1 ; : : : ; Qn g i HQ = HQ1 \ : : : \ HQn .
Proof. First of all, let show that HQ is the minimal Herbrand model of a concept Q in
the language F . Every HQi can be seen as a rooted directed acyclic graph where nodes
are labelled with (possible empty) set of atomic concepts and arcs with atomic features
while equality constraints between nodes correspond to features agreement. Whithout loss
of generality let us consider the case where HQ = HQ1 \ HQ2 . It is sucient to show
that HQ is a rooted directed acyclic graph. Let a be the root of HQ1 ; HQ2 , then will be
proved by induction that if Fi (ai,1 ; ai ) 2 HQ (where Fi is the rst order translation of a
feature, ai,1 ; ai are obtained as a result of the skolemization process, and a0 = a) then
fF1 (a; a1 ); : : : ; Fi (ai,1; ai )g  HQ. The case i = 1 is trivial. Let i > 1. Now, Fi (ai,1 ; ai) 2
HQ i Fi(ai,1 ; ai ) 2 HQ1 \ HQ2 . But ai,1 is uniquely dened by the skolem function
fFi,1 (where, the function symbols fFi are newly generated for each feature Fi by the
skolemization process). Then, Fi (ai,1 ; ai ) 2 HQ1 \ HQ2 i Fi (ai,1 ; fFi,1 (ai )) 2 HQ1 \ HQ2
i Fi,1 (ai,2 ; fFi,1 (ai )) 2 HQ1 \ HQ2 . Then the thesis is true by induction.
Let us now prove the \(" direction. Suppose by absurd that there is an F concept C
such that: Q1 v C ^ Q2 v C ^ C < Q. Then, Q1 v C i HC  HQ1 , and Q2 v C , i
HC  HQ2 . But then HC  HQ1 \ HQ2 , i.e., HC  HQ. Then Q v C which contradicts the
hypothesis.
The \)" direction can be proved with analogous considerations.
2

Proposition 6.20 (lcs subsumption-preserving property) Let A; B; C; D be F concepts, then A u (B t C ) v D i A u lcsfB; C g v D.
Proof. A u (B t C ) v D i A u B v D and A u C v D. Now, A u B v D i F [
fA000 (a); B 000 (a)g j= D000(a) i HA [ HB j= D000 (a) i HD  HA [ HB . For the same reasons,
A u C v D i HD  HA [ HC . But then, HD  HA [ HB and HD  HA [ HC , i.e.,
HD  HA [ (HB \ HC ), i.e., HD  HA [ HlcsfB;C g . But, HD  HA [ HlcsfB;C g i
A u lcsfB; C g v D.
2

The following theorem provides a sound and complete procedure to compute subsumption. The completeness proof takes into account that the temporal structure is dense and
unbounded. This allows us to introduce any new node to a conceptual temporal constraint
network without changing its meaning. Remember that, for each of these redundant nodes,
time-invariant information holds.
Theorem 6.21 (TL-F concept subsumption) A concept C1 subsumes a concept C2 i
there exists an s-mapping from the essential graph of C1 to the essential graph of C2 .
486

A Temporal Description Logic for Reasoning about Actions and Plans

Proof. Let T1 = hX 1 ; Tc1 ; Q@X 1 i be the essential graph of C1 , and T2 = hX 2 ; Tc2 ; Q@X 2 i
be the essential graph of C2 .
\( " (Soundness). Follows from the fact that the essential graph form is logically equivalent to the starting concept, and from the soundness of the procedures for computing
both the TCN subsumption (proposition 6.15) and the subsumption between non-temporal
concepts (Cohen et al., 1992).
\) " (Completeness). Suppose that such an s-mapping does not exist. Two main cases
can be distinguished.
i) There is not a mapping M such that hX 1 ; Tc1 i wM hX 2 ; Tc2 i. By adding redundant
nodes to T2 , an equivalent conceptual temporal constraint network T2 = hX 2 ; Tc2 ; Q@X 2 i
may be obtained. Let us consider such an extended network
in a way that there exists a


variable mapping M such that hX 1 ; Tc1 i wM hX 2 ; Tc2 i. Now, for all possible M , there
is a node X1i 2 X 1 such that M (X1i ) = X2j with X2j 62 X 2 . Now, Q1i 6wF Q2j , since X2j
cannot coincide with other nodes in X 2 neither can have a covering otherwise the hypothesis
that the mapping M does not exist would be contradicted. Then from proposition 6.7 Q2j
is in a time-invariant node, whereas Q1i is not since T1 is an essential graph. Then, although
the construction of M allows for the existence of a unique V 3 for both networks (follows
from proposition 6.15), it is possible to build an instance of T2 that is not an instance of T1 .
ii) For each possible mapping M such that hX 1 ; Tc1 i wM hX 2 ; Tc2 i there will be always
two nodes X1i and X2j such that M(X1i ) = X2j and Q1i 6wF Q2j . Now, the concept expression Q2j cannot be rened (looking for a subsumption relationship with Q1i ) by adding
to it an F concept since from proposition 6.7 this would change the overall interpretation.
On the other hand, the lcs introduction { which would substitute the more specic concept disjunction implicitly presents because of a node covering { is a subsumption-invariant
concept substitution, as showed by lemma 6.20.
Both cases contradict the assumption that T1 subsumes T2 .
2
6.2.1 Complexity of Subsumption

Now it is shown that checking subsumption between TL-F concept expressions in the essential graph form is an NP-complete problem. Therefore, a polynomial reduction from the
NP-complete problem of deciding whether a graph contains an isomorphic subgraph is presented. It is then shown that the subsumption computation, as proposed in theorem 6.21,
can be done by a non-deterministic algorithm that takes polynomial time in the size of the
concepts involved. First of all let us consider the complexity of computing subsumption
between non-temporal concepts.

Lemma 6.22 (F subsumpion complexity) Let C; D be F concept expressions that can
contain lcs's. Then, checking whether C vF D takes polynomial time.
Proof. See (Cohen et al., 1992).
2
Here the problem of subgraph isomorphism is briey recalled. Given two graphs, G1 =
(V1 ; E1 ) and G2 = (V2 ; E2 ), G1 contains a subgraph isomorphic to G2 if there exists a
3. Since subsumption is computed with respect to a xed evaluation time, V maps the dierent occurrences
of ] to the same interval; this justies the choice that M(]) = ].
487

Artale & Franconi

subset of the vertices V 0  V1 and a subset of the edges E 0  E1 such that j V 0 j=j V2 j,
j E 0 j=j E2 j, and there exists a one-to-one function f : V2 7! V 0 satisfying fu; vg 2 E2 i
ff (u); f (v)g 2 E 0.
Given
a graph G = (V; E ), with V = fv1 ; : : : ; vn g associate a temporal concept expression:
:
C = 3(v1 ; : : : ; vn ) : : : (vi (b; a) vj ) : : : . (A@v1 u : : : u A@vn), where A is an atomic concept
and fvi ; vj g 2 E . This transformation allows us to prove that the problem of subgraph
isomorphism can be reduced to the subsumption of temporal concepts.
Proposition 6.23 Given two graphs G1 and G2, G1 contains a subgraph isomorphic to G2
i C2 w C1 , where C1 and C2 are the corresponding temporal concepts expressions.
Proof. A temporal network with edges labeled only with the (before _ after) relation is always
consistent, minimal and non-directed4 (Gerevini & Schubert, 1994). Then, each temporal
concept is in the essential graph form. Now the proof easily follows since, every time G2 is
an isomorphic subgraph of G1 the one-to-one function f is also an s-mapping from C2 to
C1 , and it is true that C2 w C1 . On the other hand, the s-mapping that gives rise to the
subsumption is also the one-to-one isomorphism from G2 to G1 .
2

Theorem 6.24 (NP-hardness) Concept subsumption between TL-F concept expressions
in normal form is an NP-hard problem.

Proof. Follows from proposition 6.23 and the reduction being clearly polynomial.
Now the NP-completeness is proven.

2

Theorem 6.25 (NP-completeness) Concept subsumption between TL-F concept expressions in normal form is an NP-complete problem.

Proof. To prove NP-completeness it is necessary to show that the proposed calculus can
be solved by a nondeterministic algorithm that takes polynomial time. Now, given two
temporal concepts, T1 and T2 , in their essential graph form, let j X 1 j= N1 and j X 2 j= N2 .
Then, to check whether T1 w T2 , the algorithm guesses one of the N2N1 variable mapping
from T1 to T2 and veries whether it is an s-mapping, too. This last step can be done in
deterministic polynomial time since, given a mapping M, it is possible to determine whether
hX 1; Tc1 i wM hX 2; Tc2i by checking at most N1(N1 , 1)=2 edges looking for subsumption
between the corresponding temporal relations (solved by a set inclusion procedure); while
the N1 non-temporal concept subsumptions can be computed in polynomial time.
2

7. Extending the Propositional Part of the Language

The propositional part of the temporal language can be extended to have a more powerful,
but still decidable, Description Logic. It is possible either to add full disjunction, both at
the temporal and non-temporal levels (TLU -FU ), or to have a propositionally complete
language at the non-temporal level only (TL-ALCF ).
Please note that in these languages it is not possible to express full negation, and
in particular the negation of the existential temporal quantier. This is crucial, and it
4. If (vi (b; a) vj ) then (vj (b; a) vi ), too.

488

A Temporal Description Logic for Reasoning about Actions and Plans

(C t D)@X
p : (C t D )
(C1 t C2 ) u D
3(X ) Tc. (C t D)

!
!
!
!

C @X t D@X
p:Ctp:D
(C1 u D) t (C2 u D)
3(X ) Tc. C t 3(X ) Tc. D

Figure 13: Rewrite rules for computing the disjunctive form.
makes the dierence with other logic-based approaches (Schmiedel, 1990; Bettini, 1997;
Halpern & Shoham, 1991). The dual of 3 (i.e., the universal temporal quantier 2) makes
the satisability problem { and the subsumption { for propositionally complete languages
undecidable in the most interesting temporal structures (Halpern & Shoham, 1991; Venema,
1990; Bettini, 1993). For the representation of actions and plans in the context of plan
recognition, the universal temporal quantier is not strictly necessary. This limitation makes
these languages decidable, with nice computational properties, and capable of supporting
other kinds of useful extensions. The examples shown throughout the paper may serve as a
partial validation of the claim. Section 8.1 proposes the introduction of a limited universal
temporal quantication that maintains decidability of subsumption.

7.1 Disjunctive Concepts: TLU -FU
The language TLU -FU adds to the basic language TL-F the disjunction operator { with
the usual semantics { both at the temporal and non-temporal levels:

C; D ! TL j C t D
E; F ! F j E t F

(TLU )
(FU )
Before showing how to modify the calculus to check subsumption, let us begin with a
clarifying example. The gain in expressivity allows us to describe the alternative realizations
that a given plan may have. Let us consider a scenario with a robot moving in an empty
room that can move only either horizontally or vertically. Let's call Rect-Move that which
involves a simple sequence of the two basic moving actions. Then, to describe a Rect-Move
plan we can make use of the disjunction operator:
:
Rect-Move = 3(x y ) (] m x)(x m y ). (Hor-Move@x u Ver-Move@y ) t
3(x y) (] m x)(x m y). (Ver-Move@x u Hor-Move@y)
7.1.1 The Calculus for TLU -FU
Normal Form

In computing subsumption, a normal form for concepts is needed. The normalization procedure is similar to that reported in Section 6.1. Let us start by reducing each concept
expression into an equivalent disjunctive concept of the form:

3(X 1 ) Tc1 . G1) t    t (3(X n) Tcn. Gn) t Q1 t    t Qm

(

489

Artale & Franconi

where Gi are conjunctions of concepts of the form Qik @Xik , and each Q does not contain
neither temporal information, nor disjunctions, i.e., it is an element of the language F .
Proposition 7.1 (Equivalence of disjunctive form) Every concept C can be reduced
into an equivalent disjunctive form (df C ), by exhaustively applying the set of rewrite rules
of Figure 13 in addition to the rules introduced in Figure 11.
It is now possible to compute the completed disjunctive normal form (cdnf C ). Each disjunct of such normal form has some interesting properties, which are crucial for the proof
of the theorem 7.4 on concept subsumption: temporal constraints are always explicit, i.e.,
any two intervals are related by a basic temporal relation; there is no disjunction, either
implicit or explicit, neither in the conceptual part nor in the temporal part, i.e., it is a
TL-F concept; the information in each node is independent of the information in the other
nodes and it does not contain time-invariant (i.e., redundant) nodes.
Denition 7.2 (Completed disjunctive normal form) Given a concept in disjunctive
form, the completed disjunctive normal form is obtained by applying the following rewrite
rules to each disjunct:
 (Temporal completion) The rules of denition 6.5 are applied to each disjunct with
the exclusion of the covering step, which is replaced by the t-introduction step. If a
disjunct is unsatisable { i.e., the temporal constraint network associated with it is
inconsistent { then eliminate it.
 (Essential form) The rules of denition 6.8 are applied to each disjunct.
 (t introduction) Reduce to concepts containing only basic temporal relationships:
3(X ) (X1 (R,S ) X2 ) Tc.C ! 3(X )(X1 R X2 )Tc.C t 3(X )(X1 S X2 )Tc.C
Proposition 7.3 (Equivalence of CDNF) Every concept expression can be reduced into
an equivalent completed disjunctive normal concept.
Subsumption

The theorem 7.4 reduces subsumption between CDNF concepts into subsumption of disjunction-free concepts, such that the results of theorem 6.21 can be applied. The following
theorem gives a terminating, sound, and complete subsumption calculus for TLU -FU .
Theorem 7.4 (TLU -FU concept subsumption) Let C = C1 t    t Cm and D = D1 t
   t Dn be TLU -FU concepts in CDNF. Then, C v D if and only if 8i9j . Ci v Dj .
Proof. Since it is easy to show that C1 t : : : t Cn v D i 8i.Ci v D we need only to prove the
restricted thesis: Ci v D1 t  t Dn i Ci v D1 _ : : : _ Ci v Dn . Every concept expression in
CDNF corresponds to an existential quantied formula with two free variables. Moreover,
the matrices of such formul are conjunctions of positive predicates. Let us denote the
formula corresponding to a concept C as C 0 (t; x). Now, the restricted thesis holds i it is
true that F [ fCi000 (a; b)g j= D1000 (a; b) _ D2000 (a; b). Now, let HB the minimal Herbrand model
of F [fCi000 (a; b)g. Then, F [fCi000 (a; b)g j= D1000 (a; b) _ D2000 (a; b) i HB j= D1000 (a; b) _ D2000 (a; b).
Since we are talking of a single model, D1000 (a; b) _ D2000 (a; b) is valid in HB if and only if either
D1000 (a; b) or D2000 (a; b) is valid in HB . This proves the theorem.5
2
5. The proof of this theorem comes from an idea of Werner Nutt.

490

A Temporal Description Logic for Reasoning about Actions and Plans

As a consequence of the theorems 6.25, 7.4 the following complexity result holds.

Theorem 7.5 (TLU -FU subsumption complexity) Concept subsumption between TLU -FU
concept expressions in normal form is an NP-complete problem.

7.2 A Propositionally Complete Language: TL-ALCF
TL-ALCF uses the propositionally complete Description Logic ALCF (Hollunder & Nutt,
1990) for non-temporal concepts by changing the syntax rules for TL-F in the following
way:

E; F ! FU j ? j :E j p " q j p "j 8P .E j 9P .E (ALCF )

The interpretation functions are extended to take into account roles:
P I  T<?  I  I
PtI = P^t  I  I j 8a; b. ha; bi 2 P^t $ ht; a; bi 2 P I
As seen in Section 2, ALCF adds to F full negation { thus introducing disagreement (p " q)
and undenedness (p ") for features, and role quantication (8P .E; 9P .E ).
As an example of the expressive power gained, let us rene the description of the world
states involved in the Stack action (see Section 5.2). Suppose that a block is described by
saying that it has LATERAL-SIDEs (role) and BOTTOM- and TOP-SIDEs (features). Then, the
property of being clear could be represented as follows:
:
Clear-Block = Block u 8LATERAL-SIDE.Clear u TOP-SIDE : HAS-ABOVE "
which says that, in order to be clear, each LATERAL-SIDE has to be clear and nothing has
to be over the TOP-SIDE. Now, the situation in which a block involved in a Stack action is
on top of another one is reformulated with the following concept expression:
(?OBJECT1 TOP-SIDE  HAS-ABOVE # ?OBJECT2)
Furthermore, given the above denition of Clear-Blocks, it can be derived that:
(?OBJECT1 TOP-SIDE  HAS-ABOVE # ?OBJECT2) v (?OBJECT1 : :Clear-Block)
i.e., an object, having another object on top of it, is no more a clear object.
In TL-ALCF it is possible to describe states with some form of incomplete knowledge
by exploiting the disjunction among non-temporal concepts. For example, let us say that
the agent of an action can be either a human being or a machine: ?AGENT:(Person t Robot).
7.2.1 The Calculus for TL-ALCF

This Section presents a calculus for deciding subsumption between temporal concepts in
the Description Logic TL-ALCF . Again, the calculus is based on the idea of separating the
inference on the temporal part from the inference on the Description Logic part (\vALCF "),
and adopting standard procedures developed in the two areas.
Normal Form

Once more, the subsumption calculus is based on a normalization procedure. The rst
step reduces a concept expression into an equivalent existential form { 3(X ) Tc. (Q0 u
Q1 @X1 u : : : u Qn@Xn) { by applying the rewrite rules of Figure 11 augmented with the
491

Artale & Franconi

:>
:?
:(C u D)
:(C t D)
: :C
:8P .C
:9P .C
:f : C
:p : C
:p # q
:p " q
(f  p) "

!
!
!
!
!
!
!
!
!
!
!
!

?
>
:C t :D
:C u :D
C
9P .:C
8P .:C
f " t f : :C
f " t f : (:q : C ) if p = f  q
p"tq"tp"q
p"tq"tp#q
f " t f : (p ")

Note: By f we denote both an atomic feature and an atomic parametric feature.

Figure 14: Rewrite rules to transform an arbitrary concept into a simple concept.
rule: p : (q1 " q2 ) ! p  q1 " p  q2 . Each Q is a non-temporal concept, i.e., it is an element
of the language ALCF .
In the following normalization step there will be a need to verify concept satisability
for non-temporal concept expressions. An ALCF concept E is unsatisable i E vALCF ?.
Algorithms for checking satisability and subsumption of concepts terms in ALCF are well
known (Hollunder & Nutt, 1990).
Denition 7.6 (Completed existential form) The temporal completion of a concept
in existential form { the Completed Existential Form, CEF { is obtained by sequentially
applying the following steps:
 (closure, collapsing, covering) As reported in denition 6.5. As for the covering,
translate the concept expression Qy applying the rewrite rule: Qy ! Qy ui=1:::n (Qi1 t
: : : t Qim ).
 (parameter introduction) This requires two phases.
1. Each Q is translated in disjunctive normal form. First the simple form6 is obtained by transforming each Q following the rewrite rules reported in Figure 14.
The disjunctive normal form is then obtained by rewriting each Q { which is now
in simple form { using the following rules, which correspond to the rst order
rules for computing the disjunctive normal form of logical formul:
(C1 t C2 ) u D ! (C1 u D) t (C2 u D)
p : (C t D) ! p : C t p : D
6. A simple concept contains only complements of the form :A, where A is a primitive concept, and no
sub-concepts of the form p ", where p is not an atomic (parametric) feature { this corresponds to a rst
order logical formula in negation normal form.

492

A Temporal Description Logic for Reasoning about Actions and Plans

?g1  : : :  ?gn [ f [ p]] : C
?g1  : : :  ?gn [ f [ p]] # g [ q]
?g1  : : :  ?gn # ?f1  : : :  ?fm
?g1  : : :  ?gn  g [ p] # ?f1  : : :  ?fm [ f [ q]]

!
!
!
!

?g1  : : :  ?gn " ?f1  : : :  ?fm
?g "
?g1  : : :  ?gn : (?gn+1 ")
?g1  : : :  ?gn [ f [ p]] " g [ q]
?g1  : : :  ?gn  g [ p] " ?f1  : : :  ?fm [ f [ q]]

!
!
!
!
!

?g1  : : :  ?gn : >.
?g1  : : :  ?gn : >.
?g1  : : :  ?gn # ?f1  : : :  ?fm .
?g1  : : :  ?gn : > u
?f1  : : :  ?fm : >.
?g1  : : :  ?gn " ?f1  : : :  ?fm .
?g " .
?g1  : : :  ?gn : (?gn+1 ").
?g1  : : :  ?gn : >.
?g1  : : :  ?gn : > u
?f1  : : :  ?fm : >.

Figure 15: Rewrite rules that compute the parameter introduction step.
2. For each Qj = Ej1 t : : : t Ejn , on compute its time-invariant part (let us indicate
this particular concept expression as Q~ j ). This gives Q~ j by computing for each
disjunct Eji in Qj its time-invariant information E~ji . If Eji vALCF ?, then
E~ji = ?. Otherwise, rewrite every conjunct in Eji as showed in Figure 15, while
the conjuncts not considered there are rewrote to >. Now, unless there is an
E~ji = >, Q~ j = E~j1 t : : : t E~jn must be conjunctively added to all the other nodes.

Proposition 7.7 (Equivalence of CEF) Every concept in existential form can be reduced into an equivalent completed existential concept.

As for the TL-F case, both covering and parameter introduction can be computed independently. As a consequence of the above normalization phase, the proposition 6.7 (node
independence) is now true for TL-ALCF concepts in CEF. Observe that, to obtain a CEF
concept, the steps of the normalization procedure require the computation of the transitive
closure of the temporal relations { which is an NP-complete problem (van Beek & Cohen, 1990) { and the computation of ALCF subsumption { which is a PSPACE-complete
problem (Hollunder & Nutt, 1990).
Before the presentation of the last normalization phase, which will eliminate redundant
nodes, it is now possible to check whether a concept expression is satisable.
Proposition 7.8 (Concept satisability) A TL-ALCF concept in CEF, hX; Tc; Q@X i,
is satisable (with the proviso that the temporal constraints are satisable) if and only if the
non-temporal concepts labeling each node in X are satisable. Checking satisability of a
TL-ALCF concept in CEF is a PSPACE-complete problem.
Proof. Is a direct consequence of the node independence established by proposition 6.7,
which is true also for TL-ALCF concepts in CEF.
2
The normalization procedure now goes on by rewriting unsatisable concepts to ? and
then computing the essential graph form for satisable concepts. This last phase is more
493

Artale & Franconi

complex than for the other temporal languages considered in this paper essentially because
ALCF can express the > concept by means of a concept expression (e.g., > = A t :A).
From this consideration it follows that in TL-ALCF a redundant node can be derived from
a complex concept expression (e.g., both A t:A, and ?g : A t ?g : :A are redundant nodes).
The key idea is that all the time-invariant information is present in the ] node thanks to
the CEF. Thus it is needed only to extract this information from the ] node by computing
the disjunctive normal form of Q] , applying the ~ translation, and then testing whether
Q~ ] vALCF Qi, for a given node xi .

Denition 7.9 (Essential graph) The subgraph of the CEF of a TL-ALCF conceptual
temporal constraint network T = hX; Tc; Q@X i obtained by deleting the nodes xi such that
Q~ ] vALCF Qi { with the exception of the ] node { is called essential graph of T : (ess T ).

Proposition 7.10 (Equivalence of essential graph) Every CEF concept can be reduced
into an equivalent essential graph form (and, obviously, every concept can be reduced into
an equivalent essential graph form).
Subsumption

The overall normalization procedure reduces the subsumption problem in TL-ALCF to the
subsumption between ALCF concepts.

Theorem 7.11 (TL-ALCF concept subsumption) A concept C1 subsumes a concept
C2 if and only if there exists an s-mapping from the essential graph of C1 to the essential
graph of C2 .

The above theorem gives a sound and complete algorithm for computing subsumption between TL-ALCF concepts (the proof is the same as the one for theorem 6.21). The subsumption problem is now PSPACE-hard, since satisability and subsumption for ALCF
concepts were proven to be PSPACE-complete (Hollunder & Nutt, 1990).

8. Extending the Expressivity for States
The following suggests how to extend the basic language to cope with important issues in
the representation of states. (i) Homogeneity allows us to consider properties of the world {
peculiar to states { which remain true in each subinterval of the interval in which they hold.
(ii) Persistence guarantees that a state holding as an eect of an action continues to hold
unless there is no evidence of its falsity at some time. An approach to the frame problem is
then presented, showing a possible solution to one of the most (in)famous problems in AI
literature. The following subsections shall be interested more in semantically characterizing
actions and states than on computational properties. The extensions proposed now to the
temporal languages are for having a full edged Description Logic for time and action.

8.1 Homogeneity

In the temporal literature homogeneity characterizes the temporal behavior of world states:
when a state holds over an interval of time t, it also holds over subintervals of t. Thus, if
494

A Temporal Description Logic for Reasoning about Actions and Plans

]

-

Simple-Stack(BLOCK)

r
OnTable(BLOCK)
-

r
OnBlock(BLOCK)

x

y

-

Figure 16: Temporal dependencies in the denition of the Simple-Stack action.
a block is on the table for a whole day, one can conclude that it is also on the table in the
morning. On the other hand, actions are not necessarily homogeneous. In the linguistic
literature a dierence is made between activity and performance verbs. The distinction
comes out in the fact that activity verbs do have sub-events that are denoted by the same
verb, whereas performance verbs do not. Generally, activity verbs represent ongoing events,
for example to eat and to run, and can be described as homogeneous predicates; whereas
performance verbs represent events with a well dened granularity in time, such as to prepare
spaghetti. Performance verbs are an example of anti-homogeneous events: if they occur over
an interval of time t, then they do not occur over a subinterval of t, as they would not yet
be completed.
The language is extended by introducing the Homogeneity operator:

C; D ! rC

(homogeneous concept)

The semantics of homogeneous concepts is easily given in terms of the semantics of the
temporal universal quantier: rC  2x (x (=; s; d; f ) ]). C @x. This means that rC
is an homogeneous concept if and only if when it holds at an interval it remains true at
each subinterval. In particular, 2x universally qualies the temporal variable x, while the
temporal constraint (x (=; s; d; f ) ]) imposes that x is a generic interval contained in ].
Moreover, it is always true that rC v C , i.e., rC is a more specic concept than C .
Let us consider as an example a more accurate denition of the Basic-Stack action
(see Section 4.1.1):
:
Simple-Stack = 3(x y )(x m ])(] m y ). ((?BLOCK : rOnTable)@x u
(?BLOCK : rOnBlock)@y)
Figure 16 shows the temporal dependencies of the intervals in which the Simple-Stack
holds. The dierence with the Basic-Stack action is the use of the homogeneity operator.
In fact, since the predicates OnTable and OnBlock denote states, their homogeneity should
be explicitly declared. The assertion Simple-Stack(i; a) says that a is an individual action
of type Simple-Stack occurred at interval i. Moreover, the same assertion implies that a
is related to a ?BLOCK, say b, which is of type OnTable at some interval j { meeting i { and
at all intervals included in j , while it is of type OnBlock at another interval l { met by i {
and at all intervals included in l:
Simple-Stack(i; a) =) 9b. ?BLOCK(a; b) ^9 j; l. m(j; i) ^ m(i; l) ^
8 ^; ^l. (=; s; d; f )(^; j ) ^ (=; s; d; f )(^l; l) !
OnTable(^; b) ^ OnBlock(^
l; b):
495

Artale & Franconi

]

-r y

Instant-Stack(BLOCK)

r
OnTable(BLOCK)
z

OnBlock(BLOCK)

-

Figure 17: Temporal dependencies in the denition of the Instant-Stack action.
Note that the Simple-Stack action subsumes the Instant-Stack action, whose temporal
dependencies are depicted in Figure 17:
:
Instant-Stack = 3(z y )(] f z )(] m y ). ((?BLOCK : rOnTable)@z u
(?BLOCK : rOnBlock)@y)
Subsumption holds because the class of intervals { obtained by homogeneity of the state
OnTable as dened in the Simple-Stack action { including x and all its subintervals is a
subset of the class of intervals over which the block is known to be on the table, according
to the denition of Instant-Stack { this latter class includes all the subintervals of z .
If the Instant-Stack action had been dened without the r operator, then it would not
specialize any more the Simple-Stack action. In fact, according to such a weaker denition
of Instant-Stack, specifying that the object is on the table at z does not imply that the
object is on the table at subintervals of z ; in particular, it is not possible to deduce any
more that the object is on the table at x and its subintervals, as specied in the denition of
Simple-Stack action. Moreover, the weak Instant-Stack action type would not specialize
the weak Simple-Stack action type { i.e., Basic-Stack { too. Thus, homogeneity helps
us to dene states and actions in a more accurate way, such that important inferences are
captured.
As seen above, the denition of homogeneity makes use of universal temporal quantication. Remember that subsumption in a propositionally complete Description Logic
with both existential and universal temporal quantication is undecidable and it is still an
open problem if it becomes decidable in absence of negation (Bettini, 1993). The homogeneity operator is a restricted form of universal quantication. An even more restricted
form interests us here, where the concept C in rC does not contain any other temporal
operator (called simple homogeneous concept). The expressiveness of the resulting logic is
enough, for example, to correctly represent the homogeneous nature of states. In (Artale,
Bettini, & Franconi, 1994) an algorithm to compute subsumption in TL-F augmented with
the homogeneity operator is proposed. Even if a formal proof is still not available, good
arguments are discussed to conjecture its completeness. This would also prove decidability
of this logic and of the corresponding modal logics.

8.2 Persistence
This Section shows how our framework can be successfully extended in a general way to
cope with inertial properties. In the basic temporal language, a property holding, say, as
a post-condition of an action at a certain interval, is not guaranteed to hold anymore at
other included or subsequent intervals. This is the reason why we propose an extended
496

A Temporal Description Logic for Reasoning about Actions and Plans

]

- x

Load(GUN)

Loaded(GUN)

]



-:
-

Fire(GUN,TARGET)

:= Loaded(GUN)
x
or

Loaded(GUN)

z

Dead(TARGET)

y

Figure 18: Denitions of the actions Load and Fire.
formalism, in which states can be represented as homogeneous and persistent concepts.
As a motivation for introducing the possibility of representing persistent properties in the
language, this Section considers how to solve the frame problem, and in particular the
famous example of the Yale Turkey Shooting Scenario (Sandewall, 1994; Allen & Ferguson,
1994), formerly known as the Yale Shooting Problem.
An inertia operator \= " is introduced here. Intuitively, = C is currently true if it was
true at a preceding interval { say i { and there is no evidence of the falsity of C at any
interval between the current one and i. Thus, the property of an individual of being of type
C persists over time, unless a contradiction arises.
The formalization of the inertia operator makes use of the epistemic operator K (Donini,
Lenzerini, Nardi, Schaerf, & Nutt, 1992), in which KC denotes the set of individuals known
to be instances of the concept C 7 .

Denition 8.1 (Inertia) = C (j; a) i
9i. start(i)  start(j ) ^ C (i; a) ^
8h. start(h)  end(i) ^ end(h)  end(j ) ! :K:C (h; a).
where start and end are two functions giving respectively the starting and the ending point
of an interval { conditions on endpoints are simpler and more readable than their equivalents
on interval relations; :K:C (h; a) means that it is not known that a is not of type C at
interval h. Furthermore, the following relation holds: 8a; j . C (j; a) ! = C (j; a); i.e., = C
subsumes C . The above denition can be captured by a temporal language equipped with
the epistemic operator { K { and the homogeneity operator { r:
= C  C t 3(x y) (x (b; m; o; ; di) ])(x (s; si) y)(y  ]).(C @x u r(:K:C )@y)
Two action types are dened, Load { with the parameter ?GUN { and Fire { with the
parameters ?GUN and ?TARGET (Figure 18):
=: 3x (] m x). ?GUN : Loaded@x
:
Fire = 3(x y z ) (] f x)(] m y )(] m z ).
(?GUN : := Loaded@x t ?TARGET : Dead@y) u ?GUN : :Loaded@z
The action Load describes loading a gun. The action Fire describes ring the gun against
a target: eects of ring are that the gun becomes unloaded and either the target is dead
Load

7. An epistemic interpretation T
is a pair (I ,W ) in which I is an interpretation and W is a set of interpretations such that (KC )I;W = J 2W (C J ;W ).

497

Artale & Franconi

i

- i1

gun)

Load(

fred :
 gun
- j1
j
gun -
j0
j2

gun)

Loaded(

Fire(

= Loaded(

,

)

)

gun)

Loaded(

fred)

Dead(

Figure 19: Actions instances in the Yale Shooting Problem.
or the gun was not loaded { possibly by inertia { before ring. The Yale Shooting Problem
considers the situation described by the following set of assertions (ABox):
Load(i; load-action ); ?GUN(load-action ; gun ); a(j; i); Fire(j; re-action );
?GUN(re-action ; gun ); ?TARGET(re-action ; fred ):
i.e., at the beginning the gun is loaded; then, the action of ring the gun against the target
fred is performed. According to the semantics of the language, logical consequences of the
knowledge base  are:
 j= 9i1 . m(i; i1 ) ^ Loaded(i1 ; gun )
 j= 9j1 . m(j; j1 ) ^ :Loaded(j1 ; gun )
 j= 9j0 . f (j; j0 ) ^ = Loaded(j0 ; gun )
 j= 9j2 . m(j; j2 ) ^ Dead(j1 ; fred ):
i.e., (see also Figure 19) (i) the Load action makes the gun loaded; (ii) the Fire action
makes the gun unloaded at the end; (iii) since there is no evidence to the contrary, the gun
is still loaded at j0 by inertia; (iv) since the gun is not unloaded at j0 , the target fred must
be dead.
Since the inertia operator is useful to describe the behavior of properties, which are
characterized as homogeneous concepts, a simple way of representing persistence in the
context of homogeneous concepts is proposed.
Proposition 8.2 Let P be a property { i.e., P =: rP 0 is an homogeneous concept { and
 a knowledge base such that  6j= P (j; a). = P (j; a) is true in  { i.e.,  j= = P (j; a) {
if and only if two intervals i; k exist such that:  j= (start(i)  start(j ) ^ P (i; a)) and
 [ fs(i; k); f (j; k); P (k; a)g is satisable.
Proof. The entailment test veries the rst part of the denition of inertia, while the
satisability test veries that, between the interval at which the system knows that the
individual a belongs to P { i { and the interval at which P (a) is deduced by inertia { j
{ does not exist an interval h at which the system knows that P (a) is false. Indeed, such
interval h would be related to the interval k by the relation in and since it is supposed
that P is homogeneous, the knowledge base with :P (h; a) ^ P (k; a) ^ in(h; k) would be
inconsistent.
2
The deduction P (j; a) ! = P (j; a) can be obtained as a particular case of the above stated
proposition.
498

A Temporal Description Logic for Reasoning about Actions and Plans

9. Related Works
The original formalism devised by Allen (1991) forms, in its very basis, the foundation for
our work. It is a predicate logic in which interval temporal networks can be introduced,
properties can be asserted to hold over intervals, and events can be said to occur at intervals. His approach is very general, but it suers from problems related to the semantic
formalization of the predicates hold and occur (Blackburn, 1992). Moreover, computational properties of the formalism are not analyzed. The study of this latter aspect was, on
the contrary, our main concern.
In the Description Logic literature, other approaches for representing and reasoning with
time and action were proposed. In the beginning the approaches based on an explicit notion
of time are surveyed, and then the Strips-like approaches are considered. This Section ends
by illustrating some of the approaches devoted to temporally extend the situation calculus.
Bettini (1997) suggests a variable-free extension with both existential and universal
temporal quantication. He gives undecidability results for a class of temporal languages
{ resorting to the undecidability results of Halpern and Shoham's temporal logic { and investigates approximated reasoning algorithms. Basically, he extends the ALCN description
logics with the existential and universal temporal quantiers, but, unlike our formalism,
explicit interval variables are not allowed. The temporal quantication makes use of a set
of temporal constraints on two implicit intervals: the reference interval and the current one.
In this framework, the concept of Mortal can be dened as:
:
Mortal = LivingBeing u 3(after). (not LivingBeing)
Schild (1993) proposes the embedding of point-based tense operators in a propositionally
closed Description Logic. He proved that satisability in ALCT , the point-based temporal
extension of ALC , interpreted on a linear, unbounded and discrete temporal structure, is
PSPACE-complete. His ideas were applied by (Fischer, 1992; Neuwirth, 1993) in the Back
system. Note that a point-based temporal ontology is unable to express all the variety of
relations between intervals.
Baader and Laux (1995) integrate modal operators for time and belief in a terminological
system looking for an adequate semantics for the resulting combined language. The major
point in this paper is the possibility of using modal operators not only inside concept
expressions but also in front of concept denitions and assertions. The following example
shows the notion of Happy-father, where dierent modalities interact:
[BEL-JOHN](Happy-father =: 9MARRIED-TO.(Woman u [BEL-JOHN]Pretty) u
hfuturei8CHILD.Graduate)
In this case, it is John's belief that a Happy-father is someone married to a woman believed
to be pretty by John, and whose children will be graduates sometime in the future. The
semantics has a Kripke-style: each modal operator is interpreted as an accessibility relation
on a set of possible worlds, while the domain of objects is split into (possible) dierent
domain objects, each one depending on a given world. This latter:choice captures the case of:
dierent denitions for the same concept { such as [BEL-JOHN](A = B ) and [BEL-PETER](A =
C ) { since the two formul are evaluated in dierent worlds. The main restriction is that
all the modal operators do not satisfy any specic axioms for belief or time. On the other
hand, the language is provided with a complete and terminating algorithm that should
499

Artale & Franconi

serve, as the authors propose, \...as a basis for satisability algorithms for more complex
languages".
There are Description Logics intended to represent and reasoning about actions following
the Strips tradition. Heinsohn, Kudenko, Nebel and Protlich (1992) describe the Rat
system, used in the Wip project at the German Research Center for AI (DFKI). They use a
Description Logic to represent both the world states and atomic actions. A second formalism
is added to compose actions in plans and to reason about simple temporal relationships. No
explicit temporal constraints can be expressed in the language. Rat actions are dened by
the change of the world state they cause, and they are instantaneous as in the Strips-like
systems, while plans are linear sequences of actions. The most important service oered
by Rat is the simulated execution of part of a plan, checking if a given plan is feasible
and, if so, computing the global pre- and post-conditions. The feasibility test is similar
to the usual consistency check for a concept description: they temporally project the preand post-conditions of individual actions composing the plan, respectively backward and
forward. If this does not lead to an inconsistent initial, nal or intermediate state, the plan
is feasible and the global pre- and post-conditions are determined as a side eect.
Devanbu and Litman (1991, 1996) describe the Clasp system, a plan-based knowledge
representation system extending the notion of subsumption and classication to plans, to
build an ecient information retrieval system. In particular, Clasp was used to represent plan-like knowledge in the domain of telephone switching software by extending the
use of the software information system lassie (Devanbu, Brachman, Selfridge, & Ballard,
1991). Clasp is designed for representing and reasoning about large collections of plan
descriptions, using a language able to express temporal, conditional and looping operators.
Following the Strips tradition, plan descriptions are built starting from states and actions,
both represented by using the Classic (Brachman, McGuiness, Patel-Schneider, Resnick,
& Borgida, 1991) terminological language. Since plans constructing operators correspond
to regular expressions, algorithms for subsumption integrate work in automata theory with
work in concept subsumption. The temporal expressive power of this system can capture
to sequences, disjunction and iterations of actions and each action is instantaneous. Furthermore, state descriptions are restricted to a simple conjunction of primitive Classic
concepts. Like Rat, Clasp checks if an instantiated plan is well formed, i.e., the specied
sequence of individual actions are able to transform the given initial state into the goal state
by using the Strips rules.
We end up by reporting on the eorts made by researchers in the situation calculus
eld to overcome the strict sequential perspective inherent to this framework. Recent works
enrich the original framework to represent properties and actions having dierent truth
values depending not only on the situation but also on time. The work of Reiter (1996),
moving from the results showed by Pinto (1994) and by Ternovskaia (1994), provides a
new axiomatization of the situation calculus able to capture concurrent actions, properties
with continuous changes, and natural exogenous actions { those under nature's control. The
notion of uent { which models properties of the world { and situation are maintained. Each
action is instantaneous and responsible for changing the actual situation to the subsequent
one. Concurrent actions are simply sets of instantaneous actions that must be coherent,
i.e., the action's collection must be non empty and all the actions occur at the same time.
Pinto (1994) and Reiter (1996) introduce the time dimension essentially to capture both
500

A Temporal Description Logic for Reasoning about Actions and Plans

the occurrence of the natural actions, due to known laws of physics { i.e., the ball bouncing
at times prescribed by motion's equations { and the dynamic behavior of physical objects
{ i.e., the position of a falling ball. This is realized by introducing a time argument for
each action function, while properties of the world are divided into two dierent classes:
classical uents that hold or do not hold throughout situations, and continuous parameters
that may change their value during the time spanned by the given situation.
More devoted to have a situation calculus with a time interval ontology is the work of
Ternovskaia (1994). In order to describe processes { i.e., actions extended in time { she
introduces durationless actions that initiate and terminate those processes. As a matter of
fact, processes become uents, with instantaneous events { Start(Fluent) and Finish(Fluent)
{ which respectively make true or false the corresponding uent, and with persistence
assumptions that make the uent true during the interval. For example, in a blocks world
the picking-up process is treated as a uent with Start(picking-up(x)) and Finish(pickingup(x)) instantaneous actions that enable or falsify the picking-up uent.

10. Conclusions
The main objective of this paper was the design of a class of logical formalisms for uniformly representing time, actions and plans. According to this framework, an action has a
duration in time, it can have parameters, which are the ties with the temporal evolution
of the world, and it is possibly associated over time with other actions. A model-theoretic
semantics including both a temporal and an object domain was developed, for giving both
a meaning to the language formul and a well founded denition of the various reasoning
services, allowing us to prove soundness and completeness of the corresponding algorithms.
The peculiar computational properties of this logic make it an eective representation and
reasoning tool for plan recognition purposes. An action taxonomy based on subsumption
can be set up, and it can play the role of a plan library for plan retrieval tasks.
This paper contributes to exploration of the decidable realm of interval-based temporal
extensions of Description Logics. It presented complete procedures for subsumption reasoning with TL-F , TLU -FU and TL-ALCF . In addition, the subsumption problem for
TL-F was proven an NP-complete problem. The subsumption procedures are based on
an interpretation preserving transformation that operates a separation between the temporal and the non-temporal parts of the formalism. Thus, the calculus can adopt distinct
standard procedures developed in the Description Logics community and in the temporal
constraints community. To obtain decidable languages the key idea was to restrict the temporal expressivity by eliminating the universal quantication on temporal variables. While
a propositionally complete Description Logic with both existential and universal temporal
quantication is undecidable, it is still an open problem if it becomes decidable in absence
of negation. With the introduction of the homogeneity operator investigation of the impact
of a restricted form of temporal universal quantication in the language TL-F was begun.
Several extensions were proposed to the basic temporal language. With the possibility
to specify homogeneous predicates the temporal behavior of world states can be described
in a more natural way, while the introduction of the non-monotonic inertial operator gives
rise to some forms of temporal prediction. Another extension { not considered in this paper
{ deals with the possibility of relating an action to more elementary actions, decomposing
501

Artale & Franconi

it in partially ordered steps (Artale & Franconi, 1995). This kind of reasoning is found in
hierarchical planners like Nonlin (Tate, 1977), Sipe (Wilkins, 1988) and Forbin (Dean,
Firby, & Miller, 1990).

Acknowledgements
This paper is a substantial extension and revision of (Artale & Franconi, 1994). The work
was partially supported by the Italian National Research Council (CNR) project \Ontologic
and Linguistic Tools for Conceptual Modeling", and by the \Foundations of Data Warehouse
Quality" (DWQ ) European ESPRIT IV Long Term Research (LTR) Project 22469. The
rst author wishes to acknowledge also LADSEB-CNR of Padova and the University of
Firenze for having supported part of his work. Some of the work carried on for this paper
was done while the second author was working at ITC-irst, Trento. This work owes a lot to
our colleagues Claudio Bettini and Alfonso Gerevini, for having introduced us many years
ago to the temporal maze. Special thanks to Achille C. Varzi, for taking time to review the
technical details of the paper and for his insightful comments on the philosophy of events,
and to Fausto Giunchiglia, for useful discussions and feedback. Thanks to Paolo Bresciani,
Nicola Guarino, Eugenia Ternovskaia and Andrea Schaerf for enlightening comments on
earlier drafts of the paper. Werner Nutt and Luciano Serani helped us to have a deeper
insight into logic. We would also like to thank Carsten Lutz for the helpful discussions we
had with him about temporal representations. Many anonymous referees checked out many
errors of previous versions of the paper. All the errors of the paper are, of course, our own.

References

Allen, J. F. (1991). Temporal reasoning and planning. In Allen, J. F., Kautz, H. A., Pelavin,
R. N., & Tenenberg, J. D. (Eds.), Reasoning about Plans, chap. 1, pp. 2{68. Morgan
Kaufmann.
Allen, J. F., & Ferguson, G. (1994). Actions and events in interval temporal logic. Journal
of Logic and Computation, 4 (5). Special Issue on Actions and Processes.
Artale, A., Bettini, C., & Franconi, E. (1994). Homogeneous concepts in a temporal description logic. In F.Baader, M.Lenzerini, W.Nutt, & P.F.Patel-Schneider (Eds.),
Workshop Notes of the Int. Workshop on Description Logics, DL-94, pp. 36{41 Bonn,
Germany. DFKI, Saarbrucken. Tech. Rep. DFKI-D-94-10.
Artale, A., & Franconi, E. (1994). A computational account for a description logic of
time and action. In J.Doyle, E.Sandewall, & P.Torasso (Eds.), Proc. of the 4 th
International Conference on Principles of Knowledge Representation and Reasoning,
pp. 3{14 Bonn, Germany. Morgan Kaufmann.
Artale, A., & Franconi, E. (1995). Hierarchical plans in a description logic of time and
action. In A.Borgida, M.Lenzerini, D.Nardi, & B.Nebel (Eds.), Workshop Notes of the
Int. Workshop on Description Logics. DL-95, pp. 1{5 Roma, Italy. Tech. Rep. 07.95.
Also in the Workshop Notes of the IJCAI-95 Workshop on \The Next Generation of
502

A Temporal Description Logic for Reasoning about Actions and Plans

Plan Recognition Systems: Challanges for and Insight from Related Areas of AI",
Montreal, 1995.
Baader, F., Burckert, H.-J., Heinsohn, J., Hollunder, B., Muller, J., Nebel, B., Nutt, W.,
& Protlich, H.-J. (1990). Terminological knowledge representation: a proposal for a
terminological logic. Technical memo TM-90-04, DFKI, Saarbrucken, Germany.
Baader, F., & Laux, A. (1995). Terminological logics with modal operator. In Proc. of the
13 th IJCAI, pp. 808{814 Montreal, Canada.
Bettini, C. (1993). Temporal Extensions of Terminological Languages. Ph.D. thesis, Computer Science Department, University of Milan, Italy.
Bettini, C. (1997). Time dependent concepts: Representation and reasoning using temporal
description logics. Data & Knowledge Engineering, 22 (1), 1{38.
Blackburn, P. (1992). Fine grained theories of time. In Working Papers of the 4th Intl.
Workshop on Semantics of Time, Space, Movement, and Spatio-Temporal Reasoning,
pp. 299{320.
Brachman, R. J., McGuiness, D. L., Patel-Schneider, P. F., Resnick, L. A., & Borgida, A.
(1991). Living with classic: When and how to use a kl-one-like language. In Sowa,
J. (Ed.), Principles of Semantic Networks. Morgan Kaufmann.
Buchheit, M., Donini, F. M., & Schaerf, A. (1993). Decidable reasoning in terminological
knowledge representation systems. Information Systems, 1, 109{138.
Calvanese, D., Lenzerini, M., & Nardi, D. (1994). A unied framework for class-based
representation formalisms. In Proc. of the 4 th International Conference on Principles
of Knowledge Representation and Reasoning Bonn, Germany.
Cohen, W., Borgida, A., & Hirsh, H. (1992). Computing least common subsumers in
description logics.. pp. 754{760 San Jose, CA.
De Giacomo, G., & Lenzerini, M. (1996). Tbox and abox reasoning in expressive description
logics. In Proc. of the 5 th International Conference on Principles of Knowledge
Representation and Reasoning, pp. 316{327 Boston, MA. Morgan Kaufmann.
De Giacomo, G., & Lenzerini, M. (1995). What's in an aggregate: Foundations for description logics with tuples and sets. In Proc. of the 13 th IJCAI Montreal, Canada.
Dean, T., Firby, J., & Miller, D. (1990). Hierarchical planning involving deadlines, travel
time and resources. Computational Intelligence, 6 (1).
Devanbu, P. T., & Litman, D. J. (1991). Plan-based terminological reasoning. In Proc.
of the 2 nd International Conference on Principles of Knowledge Representation and
Reasoning, pp. 128{138 Cambridge, MA.
Devanbu, P. T., & Litman, D. J. (1996). Taxonomic plan reasoning. Articial Intelligence,
84, 1{35.
503

Artale & Franconi

Devanbu, P., Brachman, R., Selfridge, P., & Ballard, B. (1991). LASSIE { a knowledgebased software information system. Communication of the ACM, 34 (5).
Donini, F. M., Hollunder, B., Lenzerini, M., Spaccamela, A. M., Nardi, D., & Nutt, W.
(1992). The complexity of existential quantication in concept languages. Articial
Intelligence, 53, 309{327.
Donini, F. M., Lenzerini, M., Nardi, D., & Nutt, W. (1995). The complexity of concept
languages. Tech. rep. RR-95-07, DFKI, Germany. A preliminary version appears in
Proc. of the 2nd International Conference on Principles of Knowledge Representation
and Reasoning (KR-91).
Donini, F. M., Lenzerini, M., Nardi, D., & Schaerf, A. (1994). Deduction in concept
languages: from subsumption to instance checking. Journal of Logic and Computation,
4 (4), 423{452.
Donini, F. M., Lenzerini, M., Nardi, D., Schaerf, A., & Nutt, W. (1992). Adding epistemic
operators to concept languages. In Proc. of the 3 rd International Conference on
Principles of Knowledge Representation and Reasoning, pp. 342{353 Cambridge, MA.
Fikes, R. E., & Nilsson, N. (1971). STRIPS: a new approach to the application of theorem
proving as problem solving. Articial Intelligence, 2, 198{208.
Fischer, M. (1992). The integration of temporal operators into a terminological representation system. Kit-report 99, Technische Universtitat Berlin, Germany.
Gerevini, A., & Schubert, L. (1994). On point-based temporal disjointness. Articial
Intelligence, 70, 347{361.
Halpern, J. Y., & Moses, Y. (1985). A guide to the modal logic of knowledge and belief:
Preliminary draft. In Proc. of the 9 th IJCAI, pp. 480{490 Los Angeles, CA.
Halpern, J. Y., & Shoham, Y. (1991). A propositional modal logic of time intervals. Journal
of ACM, 38 (4), 935{962.
Heinsohn, J., Kudenko, D., Nebel, B., & Protlich, H. (1992). RAT: representation of
actions using terminological logics. Tech. rep., DFKI, Saarbrucken, Germany.
Hollunder, B., & Nutt, W. (1990). Subsumption algorithms for concept languages. Tech.
rep. RR-90-04, DFKI, Germany.
Kautz, H. A. (1991). A formal theory of plan recognition and its implementation. In Allen,
J. F., Kautz, H. A., Pelavin, R. N., & Tenenberg, J. D. (Eds.), Reasoning about Plans,
chap. 2, pp. 69{126. Morgan Kaufmann.
Lifschitz, V. (1987). On the semantics of strips. In The 1986 Workshop on Reasoning
about Actions and Plans, pp. 1{10. Morgan Kaufman.
McCarthy, J., & Hayes, P. J. (1969). Some philosophical problems from the standpoint
of Articial Intelligence. In Meltzer, B., & Michie, D. (Eds.), Machine Intelligence,
Vol. 4, pp. 463{502 Edinburgh, UK. Edinburgh University Press.
504

A Temporal Description Logic for Reasoning about Actions and Plans

Nebel, B. (1990). Terminological reasoning is inherently intractable. Articial Intelligence,
43, 235{249.
Nebel, B. (1991). Terminological cycles: Semantics and computational properties. In Sowa,
J. F. (Ed.), Principles of Semantic Networks, chap. 11, pp. 331{362. Morgan Kaufmann.
Neuwirth, A. (1993). Inferences for temporal object descriptions in a terminological representation system: Design and implementation. Kit-report 107, Technische Universtitat
Berlin, Germany.
Pinto, J. A. (1994). Temporal Reasoning in the Situation Calculus. Ph.D. thesis, Department
of Computer Science, University of Toronto.
Reiter, R. (1996). Natural actions, concurrency and continuous time in the situation calculs.
In Proc. of the 5 th International Conference on Principles of Knowledge Representation and Reasoning Boston, MA.
Renz, J., & Nebel, B. (1997). On the complexity of qualitative spatial reasoning: a maximal
tractable fragment of the region connection calculus. In Proc. of the 14 th IJCAI, pp.
522{527 Nagoya, Japan.
Sandewall, E. (1994). Features and Fluents. The Representation of Knowledge about Dynamical Systems, Vol. I. Oxford University Press.
Sandewall, E., & Shoham, Y. (1994). Non-monotonic temporal reasoning. In Gabbay, D.
(Ed.), Handbook of Articial Intelligence and Logic programming. Oxford University
Press.
Schaerf, A. (1994). Reasoning with individuals in concept languages. Data & Knowledge
Engineering, 13 (2), 141{176.
Schild, K. D. (1991). A correspondence theory for terminological logics: Preliminary report.
In Proc. of the 12 th IJCAI, pp. 466{471 Sidney, Australia.
Schild, K. D. (1993). Combining terminological logics with tense logic. In Proceedings of
the 6th Portuguese Conference on Articial Intelligence, EPIA'93.
Schmidt-Schau, M., & Smolka, G. (1991). Attributive concept descriptions with complements. Articial Intelligence, 48 (1), 1{26.
Schmiedel, A. (1990). A temporal terminological logic. In Proc. of AAAI-90, pp. 640{645
Boston, MA.
Smolka, G. (1992). Feature constraint logics for unication grammar. Journal of Logic
Programming, 12, 51{87.
Tate, A. (1977). Generating project networks. In Proc. of the 5 th IJCAI, pp. 888{893
Cambridge, MA.
505

Artale & Franconi

Ternovskaia, E. (1994). Interval situation calculus. In Workshop Notes of the ECAI-94
Workshop \Logic and Change", pp. 153{164 Amsterdam.
van Beek, P., & Cohen, R. (1990). Exact and approximate reasoning about temporal
relations. Computational Intelligence, 6, 132{144.
van Beek, P., & Manchak, D. W. (1996). The design and experimental analysis of algorithms
for temporal reasoning. Journal of Articial Intelligence Research, 4, 1{18.
van Dalen, D. (1994). Logic and Structure. Springer-Verlag.
Venema, Y. (1990). Expressiveness and completeness of an interval tense logic. Notre Dame
Journal of Formal Logic, 31 (4), 529{547.
Weida, R. (1996). Closed Terminologies and Temporal reasoning in Descriptions for Plan
Recognition. Ph.D. thesis, Department of Computer Science, Columbia University,
New York, NY.
Weida, R., & Litman, D. (1992). Terminological reasoning with constraint networks and
an application to plan recognition. In Proc. of the 3 rd International Conference on
Principles of Knowledge Representation and Reasoning, pp. 282{293 Cambridge, MA.
Weida, R., & Litman, D. (1994). Subsumption and recognition of heterogeneous constraint
networks. In Proceedings of CAIA-94.
Wilkins, D. (1988). Practical planning. Morgan Kaufmann, San Mateo CA.

506

	
 	


 ! #"$ % 	'&)(+*', ((-/.10(/24365!, 7

89:;<  =)(/>(/?9@BA:
%&=C,,4>(-

DFEHGJILKNM/OQPSRHGCTUWVFXG<Y

IWX/Z\[]KNM^NE`_

acbdbde1fNg#hjilkme$nhpo

qlrlr<s1t1u$vwjxzy{s|Bv}~C6r+s#xz}

4B'B4\j 
 l+4Bcl/\ )¢¡ £<¤4¥
¦§¦¦©¨cª B«¬Bp­$4Bj®
¯ g°ef±kme1fNg#hji²´³Ng#e$µ¤¶n·'f

¸/r<sw¤~]r+s1wx¹u$º1ws1»$x¼r<½

¾]«¥j'¿) l/©À©¿/`ÁjÃÂ'ÄcÂÆÅNBÄ¥j¤'BBjBÇ¹Â
ÈÂ   \Ç¼ÂllÄc®Â
ÉÊ!/Ç¼Å1ËBÇ¤Ç¹ÌÉÊ!/Ç¼SÍ9Î § Î ¨  ª ¬Ï®
Ð

·hpoohÒÑÓhjÔBÔ·hp
Õ oh

Öv}}v$xz×vØ!Øv}vj~C6r<s$#xz}

4B'B41£4Ù#lÚ$
Û ]l/­/ÇzÏÜÇÇ¹
¦§©¨¨¨

Ê4j/Ç¼­14Bj®

ÝßÞ)àá¤âãNäjá
åçæÆèé4æ9ê4æ9ë©ì)íÓë¤æ9îïíèèé ð©íñò`ì4ðÓèíì4òóè¤ô¼íëë¤õÃë¤ö÷$ñ9íBô¼ô¹æ!øSì¬ò¤æ´ù4úé4õÃíøë¤æû ê)ñ/ô¼æîüíBô¼öð©é õ¼ì4òýcþÿ
«ìCõ¼êCø¤æ9ê4õ¹ö©ë¤æ9øçì4ð ëø{èíBì4òê¢õÃë{ò¤õ¼öò «ø¤õÃýCæ!ëê4õ¹ð©ëíBô°ñðë©ì õÃë ¤ð ê¢ê4èíñ/æ!ê¢íëø íèè¤ô¼õ¼æ9ê¢ì4ð é4ð ðì4ê
î<õ¼ì4ò ýcíë
øæöé4ææ!êð é æ9æ9ø¤ð©ý õÃë´ê ì¬íBì õÃñB÷Ìíêî æô¼ô°íê¢ø ¤ëíý]õÃñcæ9ë õ¼é4ðëýCæ!ë©ì4ê
ð©ë¤æ9êQî+òæ9é4æ
ð ê ì¬íñô¹æ!ê)ýcí Sý]ð æÿ <ò¤æÆúlé õÃíøëæû ê)ñô¹æ9î±íô¹öðé4õ¹ì¬òý ñ/ð©ý]èé õÃê æ!ê)ì«î#ðHê
'íô¹öðé4õ¹ì¬òýcê÷ñ9íBô¼ô¹æ!ø
Ø9v¤s1}
íëø v¤½»w }v ÷íèèô¹õ¼æ9øcõÃëÆíëcõÃë©ì æ9é4ô¼æ9í æ!øCýcíëë¤æ9é9ÿ v¤½1»w 1}v
¤õ¹ôÃøê#í¢é æ!èé4æ9ê4æ9ë©ì4íì õ¼ðë
ð ì¬ò¤æ\íñ9ñ/æ!ê4ê4õ ô¹æQê¬èíñæ)î+òõ¹ô¼æ Ø9v¤s1}
ô¼ðð ê 6ðéÊì¬ò¤æ¢ì¬íé4öæì9ÿ Êðì¬òÓíé æQèðê4æ9øHíêÊð©è¤ì õÃý]õ !íBì4õ¹ð©ë
èé4ð ô¹æ!ý]ê9ÿ åçæSø¤æ9ê¬ñé4õ æSí´é4æ9íBôõ¼ýcè¤ô¼æ9ý]æ9ë©ì¬íBì õ¼ðëÒð )ì¬ò¤æSíBô¼öð©é õ¼ì4òýJì ð{è¤ôÃíëßèíì4òê 6ð©é í´ê õ
ø¤æ9öé4ææ!êð é æ9æ9ø¤ð©ý íé¬ý õÃë´í`ø ¤ëíý]õÃñCæ!ë ©õÃé4ðëý]æ9ë©ìî+ò¤æ!é æ íë¤ðì¬ò¤æ9éQê4õ ´ø¤æö©é æ9æ9ê)ð é4ææ9øðý
íé4ý±õ¼ê ê4æ9ø íê°íCýCð õÃë¤ö¢ð ê ì¬íñô¹æÿ
¤èæ9é4õÃýCæ!ë©ì4íBôjé æ!ê ô¹ì¬ê#ê¬ò¤ðîßì4òíì#íCèíBì¬òÆõ¼ê 6ð ëøÆõÃë í ð ¤ì
ð©ë¤æQê æ!ñ/ðëø î<õ¼ì4ò¤ð ¤ì+íë
èé æ 'èé4ð¤ñ/æ!ê4ê4õ¼ëöÿ






	
  

	

  





%




	

 	
*)+'
	 	 ,
	



 

"!






	


  
('



+
 

&





$#

$'

 

-"./	0 á¤â21435äjá2671 0
8:9<;>=*?	@A9B=DCE?FDF<GHF<I=DJ,KLDCH;MNGHO&KPQMR?SAKJTGHF@A;JU;OV@WPXKJYGHF<Z<[DOV@VJ,GE?C\JUKL]K@AGE^O_Y`aL*?OAGH^>b2;J,OAGEKFBKP
@A9<GHOQ=<J,KLDCH;Mc^KF<OAGHOV@AOKPedDF<Z<GHFDI&?fOA;g[<;F<^;:KP\MhK@AGEKF<OiPXKJj?&JUKL]K@PEJ,KMk?TOV@,?	J,@^KFldDI[<JU?	@AGHKF
@AKY?mIGHb2;FnIK2?Cl^KF<dDI[lJU?	@AGHKFnom9DGHCH;i?b2KGHZ<GHF<IW^KCHCHGEOAGHKF<O\oGp@A9n?FqfKLDOA@,?^CH;O4GHF>@A9<;;FbGpJ,KF<Mh;F@_
`kOAGHM=*CH;fb2;JUOAGHKFrKP@A9<;n=<J,KLDCH;Mts\@A9D?	@TKPi=*CE?F<F<GHFDIh@A9<;MhK@AGEKFrKPj?u=\KGHF@&J,KL\K@Y?MRKF<I
vwxZ<GHMR;F<OAGHKFD?CW=\KCpq9<;ZlJU?CWKLDOV@,?^CE;OsY9D?OyL\;;Fz=<J,Kb2;Z{@AK|L\;r}"~wx^KM=DCE;@A;|x?F<Fqs2U_
 ;F<;J?CHCpqYOV=\;?	GEF<Is@A9D;^KM=*CH;GH@xqTKP@A9<;i=<J,KLDCH;MGHO+;=\KF<;F@AGE?CGHFf@A9<;jF[<M>L\;JKPlZ<;IJU;;OKP
PJ,;;Z<KM74KP]@A9<;:J,KL\K@sl?F<Zh=\KCpqF<KMhG?ClGHF@A9<;F[<M>L\;JKP]KLDOV@,?^CE;OjGEF@A9<;m;FbGpJ,KF<Mh;F@_
KF<O,;g[<;F@ACpqs2d*F<Z<GHF<IW?&=*?	@A9PXKJ?WJ,KL\K@ omGp@A9MR?FqRMhKJU;@A9D?Fd<b2;GHFh?F;FbGpJ,KF<Mh;F@
omGp@A9OA;b2;J?CKLDOV@,?^CH;OhGEOsQGHF<Z<;;Z"si?b2;J,qZ<GHR^[<Cp@>=<J,KLDCH;Mt_F<PXKJA@A[<F*?	@A;CpqsiMR?FqJ,;?CEGHOV@AGH^
GHF<ZD[<OV@VJ,GE?C+=<J,KLDCE;MhO&Z<;?C omGp@A9J,KL\K@AOYKP?	@fCH;?OV@YOAGpB?F<Zr9[DF<ZlJ,;Z<O&KPjKLDOV@,?^CH;O_ib2;F
oKJ,OA;slKPE@A;F@A9D;;FbGHJ,KF<Mh;F@GHOjZlqFD?MhGH^GHF@A9<;O,;F<OA;@A9D?	@jO,KMh;&KP\@A9<;WKLDOV@,?^CH;OMR?qRMhKb2;s
@A9<;J,;LqyP[<JA@A9<;JJ,;g[<GpJ,GEF<IT@A9D?	@F<;o=*?	@A9<O:L];YPXK[<F<ZyGEFb2;JAqyOA9<KJA@:^KM=*[l@AGHF<In@AGHMh;O_
 

e¡

¢

j£

¤

x¥

E¦ ¥

, ((- j %% !=	¬¢	= /	 N	!¹;+	 :!
%&% 

&/%1% / =

y

\§D¨W$us<©|t"§]ª

s|Bv}

«

×vØ9Ø9 v}v

¬ Ft@A9<GEO:=*?	=\;Js*oj;f=<J,;OA;F@W?RF<;o­?	=<=DJ,K2?^,9B@AKh=e?	@A9=DC?F<F<GHF<Is<^?CECH;Zt@A9<;®A`mJUGE?Z<F<;¯°O^CH;o
?CHIKJ,GH@A9<M ,V± _8:9<;?	=<=<J,K2?^U9²GHO^KM=DCE;@A;CpqI;F<;JU?C:?FDZ?	=D=DCHGH;On@AKr?³L<J,K2?ZJU?F<I;KPm=*?	@A9
=DCE?FDF<GHF<IY=DJ,KLDCH;MhO_ ´WKo;b2;JsDGH@jGHOj=*?	J,@AGH^[<CE?	J,CHqZD;OAGHIF<;Zu@AKndDF<Z=*?	@A9<OPXKJJ,KL\K@AOoGp@A9MR?Fq
uGHFyZlqFD?MhGH^&;FbGHJ,KF<Mh;F@AO_
8:9D;T[<Cp@AGHM?	@A;fIK2?CKPQ?=DCE?FDF<;JmGHOm@AKRdDFDZ?=*?	@A9BPJ,KMµ@A9<;>GHF<Gp@AG?C\=\KOAGp@AGHKF@AK@A9<;T@,?	JUI;@_
´WKo;b2;Js"om9<GECH;TOA;?	J,^U9<GHF<IuPXKJW@A9DGHOm=e?	@A9\s]@A9<;n?CEIKJ,Gp@A9<MMR?qB^KF<OAGHZD;JW^KCHCE;^@AGHF<IuGHF<PXKJ,MR?	@AGHKF
?	L\K[l@T@A9<;RPEJ,;;ROV=*?^;?FDZ?	L\K[l@T@A9<;hO,;@fKPj=]KO,OAGpLDCH;n=*?	@A9DOT@A9D?	@fCEGH;GHFr@A9D?	@>PEJ,;;ROV=*?^;_8:9<;
`J,GE?Z<F<;¯°O^CH;o²?CHIKJ,GH@A9<M¶@VJUGH;O+@AK&Z<KL\K@A9?	@@A9<;O,?MR;i@AGHMR;·?OA[lLlw?CHIKJUGp@A9<M­^?CHCH;Z¸l¹+~<º+»\¸
^KCHCH;^@AOGHF<PXKJ,MR?	@AGHKFh?	L\K[l@4@A9D;:PEJU;;:OV=*?^;oGp@A9GHF<^J,;?O,GHF<ICpq>dDF<;J,;OAKCE[l@AGHKF\som9DGHCH;s2GHF=e?	JU?CHCH;Cs
?F?CHIKJUGp@A9<Mµ^?CHCE;Z¼¸l½+»]¾e¿K=<=\KJA@A[<F<GEOV@AGH^?CHCpqh^U9<;^AO:o9<;@A9<;J:@A9<;T@,?	J,I;@^?FyL\;&J,;?^U9<;Z\_
8:9D;¸l¹+~Dº»\¸?CHIKJ,Gp@A9DMÀoKJAOfLqr=DCE?^GHFDItCE?F<Z<M?	JAO>GHF@A9D;OA;?	JU^,9<;ZOV=*?^;GHFOA[<^,9?
o?qB@A9D?	@f?u=*?	@A9rPJ,KMÁ@A9<;GHF<Gp@AG?C+=\KOAGp@AGEKF@AKt?FqBC?F<Z<MR?	JA³GHOWF<KomF\_ ¬ FKJ,Z<;JY@AKyCE;?	J,F?O
Mn[<^,9h?O=\KOAOAGpL*CH;i?	L\K[l@@A9<;PEJ,;;OV=e?^;s@A9<;¸l¹+~<º+»\¸n?CHIKJ,Gp@A9DM¶@VJ,GE;O@AK&OV=DJ,;?Zn@A9<;CE?F<Z<MR?	J,O
[<F<GEPKJ,MRCpqn?CHCeKb2;J@A9D;mOV=*?^;_8KnZ<KT@A9DGHOsGH@i=DCE?^;O@A9<;WCE?F<Z<M?	JAOj?OPX?	J?Oj=]KO,OAGpLDCH;PJ,KMkKF<;
?F<K@A9<;J_ÂDKJ>;?^,9ÃF<;oÄCE?F<ZDMR?	JA=DJ,KZD[<^;ZBLqB@A9<;h¸l¹+~Dº»\¸B?CEIKJ,Gp@A9<Mys\@A9D;R¼¸l½+»]¾e¿?CHIK	w
J,Gp@A9DMc^,9D;^AOYÅomGp@A9?>CHK^?C*MR;@A9<KZe om9<;@A9D;J@A9<;@,?	J,I;@^?FL];mJ,;?^,9D;ZuPJ,KMÆ@A9D?	@CE?F<Z<MR?	J,*_
Ç K@A9t@A9<;>¸l¹+~<º+»\¸?F<Z³¼¸l½+»]¾e¿B?CEIKJ,Gp@A9<MhO?	J,;&=\KOA;Z?OmK=D@AGHMhGHÈ?	@AGHKF=DJ,KLDCH;MhO_
8:9D;Y`mJ,G?Z<F<;¯°O^CH;o?CEIKJ,Gp@A9<MµGEOfÉÅÊÌËÍ7ÉÎ*Ï"?F<ZÐÉÎeÉÑVÒÓ$·
_m8m9<;T?CHIKJ,Gp@A9DMµGHO;R^GH;F@mGHF@ojKOA;F<OA;O·
7?2Q=\;J,GEMh;F@AOOA9<Ko@A9D?	@@A9D;?CEIKJ,Gp@A9<M­GHO ?	LDCH;@AKOAKCHb2;=e?	@A9>=*CE?F<F<GHFDI=<J,KLDCH;MROPÅ?OV@
;FDK[<I9@AKBMRKb2;y?O,G%Ã?	J,MÔGHF?tJU;?CHGHOV@AGH^u?F<ZZlqF*?MhGH^R;FbGpJ,KF<Mh;F@fo9<;J,;
?FDK@A9<;JOAGpJ,KL\K@:GHO[<OA;Z³?O?MhKbGHFDIhKLDOV@,?^CH;_
ÅLe ¬ @GEOQo;CHC<OA[<GH@A;ZRPXKJi=*?	JU?CECH;C<GHM=*CH;Mh;F@,?	@AGHKF?F<ZOA9<KomOiOAGEIF<GpdD^?F@iOV=\;;Zwx[l=Rom9<;F
@A9D;TF[DMfL\;J:KP=<J,K^;OAOAKJ,O:GEF<^J,;?OA;O_
Õ_m8m9<;T?CHIKJ,Gp@A9DMµGHOI;F<;JU?C+GHF@xoKROA;FDOA;O·
7?2 ¬ @:MR?qL\;W[<OA;ZyPXKJm?nomGHZ<;JU?F<I;YKP?	=<=DCHGH^?	@AGEKF<OGHFuJ,KL\K@AGH^OomGp@A9CHGp@V@ACE;W?Z<ZDGp@AGHKFD?C
;Ö]KJA@:@AKu?ZD?	=<@:Gp@_
ÅLeuÂ GHF*?CHCpqse@A9<;?CHIKJ,Gp@A9<MÁGHOWI;F<;JU?C4GEF@A9D?	@YGp@&MR?qL\;n?Z*?	=<@A;ZrPKJT?uCE?	J,I;nJU?FDI;nKP
O,;?	J,^,9B=<J,KL*CH;MhOmGEF^KF@AGHF[DK[<OmOV=e?^;O@A9*?	@&?	J,GEOA;fGHFdD;CHZ<O:@A9D?	@&?	JU;>F<K@J,;CE?	@A;Z³@AK
JUKL]K@AGE^O_
8:9D;=*?	=\;JfGHOTKJ,I2?FDGHÈ;ZÃ?O>PKCHCEKomO_×;^@AGHKFÕ=<J,;OA;F@AOT@A9<;h=*?	@A9r=DCE?FDF<GHF<I=<J,KLDCE;MÀ?F<Z
Z<GHO,^[<OAOA;OfJ,;CE?	@A;ZojKJ,*_×;^@AGHKFvt=DJ,;OA;F@AO>@A9D;R=<JUGHF<^Gp=DCE;nKP:@A9<;`J,GE?ZDF<;¯°Of^CH;oµ?CHIKJUGp@A9<My_
×;^@AGHKFØyZ<;OA^J,GpL\;OW@A9<;h?	=<=*CHGH^?	@AGHKFKP@A9<;h?CHIKJ,Gp@A9DMÁ@AKt?OAG%+B?	J,MÙGEF?Z<qFD?MRGH^;FbG%w
J,KF<MR;F@_Â GHFD?CHCHqs"×l;^@AGHKFÚu^KF<^CH[<ZD;O&@A9<;=*?	=\;JYomGp@A9r?Z<GHO,^[<OAOAGHKFBKP@A9<;^KF@VJUGpLD[l@AGHKFDOWKP
K[lJ?	=D=<J,K2?^,9"s<@A9<;YMR?GHFZ<GpR^[<CH@AGH;OGEFb2KCpb2;Z"s*?F<Zy=\KOAOAGHLDCH;mGEM=<J,Kb2;Mh;F@AOKP K[lJ:Mh;@A9<KZ\_
ÛÜ*ÝÞßÞßàá7âã$äåfæ7àçáèéèéêë(èéåèßäâì]ÝáÅã$íâä	èì*æ7î	èWâ	íUïåîæ7èéáà,ð4ñWã(ä	àòßì\ó ã(ä	ånà,ðQôeáèßæ7èUì\î	èßë(õèVâRö]î	èéòÅèéïòêã°ë°ë+æ7îè
ñWã(ä	à,æxíUï	áéìíj÷àä	òXæ7èéá\ë°ã$øã(ä	åã$äæ7î	è4ùí,úûáÅã(äæ7îìíîï	åUè ÷:íUüßè4ú	ïã°ë°æ+úûý íUèVâí,ë(ïòßÜeö]î	è4÷:íAã$ä&âã°þ:Þßïë(æû:ðpíÞèVâ
úû:ö]î	èéòÅèéïò*ÿ]íòeæ7à ä	â:îã$òeÿ\íéûæ7î	áàUï	åîæ7îèùí,úûáÅã(äæ7îÜlÝáÅã$íâä	èúáÅã°ë(ë°ã$íUäæë°ûmòÅàUë(øèéâ:æ7îèõ	áàUúë(èé÷ÃúûåUã(øã$äå
îã(÷|íiæ7î	áèVíUâ pàá"íÞxë$èÿ \æ7î	í,æ"î	èQÞàïë$âWïäÿ\ã$ä	â:ã(ä&àUá7âèéá\æ7à 	äâ:îã$ò\õíAæ7îWúíUÞxêÜ
	



.

ãá

 ã

$vu¨]}Ãs1º1t$v¹ØWw©vLsw©e1}%©l1r

0i0 6 0 2â 1°Þ 

?FqÃb2;J,OAGHKF<OKPm@A9<;u=*?	@A9=DCE?F<F<GEF<Iy=<J,KL*CH;MÔ;GHOA@_`F;l9D?[<OV@AGpb2;^CE?O,OAGpdD^?	@AGHKFKP@A9D;OA;
=<J,KL*CH;MhO:?F<ZtKP@A9<;fMh;@A9<KZ<O:Z<;b2;CHK=\;Zy@AKOAKCpb2;Y@A9D;M ^?FtL\;YPXK[<F<ZyGHF³?OA[lJAb2;qLqu´o?F<I
?F<Z`W9[	S,?Bé2ÕU"_ !;^,9<KKOA;@AKGHCHCH[DOV@VJU?	@A;fK[<JTZ<GHOA^[<O,OAGHKFtoGp@A9B?u=e?	JA@AGH^[<CE?	J&^?OA;_n`ÄJ,KL\K@
?	J,M GHO&=*CE?^;Zr?MhKF<It?OA;@TKPjKLDOV@,?^CH;O_  GHb2;F?FrGHF<Gp@AGE?C ?F<Z?dDFD?C =\KOAGH@AGHKF³KP@A9<;nJ,KL\K@
?	J,Myse@A9<;>=<J,KLDCE;M GHO@AKRd*F<ZB?OA;@&KPQMhK@AGHKFDOm@A9D?	@WomGHCEC"CH;?Z³@A9<;fJUKL]K@W@AKuMhKb2;nL\;@xo;;F@A9<;
@xoKh=\KOAGH@AGHKF<OjomGp@A9<K[<@^KCECHGHZ<GHFDIfomGH@A9@A9<;TKLDOV@,?^CE;O_
8K>Z<J,Gpb2;@A9<;mJ,KL\K@j?MhGEZ<OV@Q@A9<;KLDOV@,?^CH;Os;?	JUCpqhMh;@A9<KZ<Om Ç J,KKOs]v2iZDGpJ,;^@ACpq[<OA;Z@A9<;
v¾*½+³MhKZD;CHOKP]@A9D;mJ,KL\K@?F<ZKP"@A9<;mKLDOA@,?^CH;Oj@AK>d*F<Z?fOAKCH[l@AGHKF"sG_°;_ps@A9<;qh^KF<O,GHZ<;J,;Z@A9<;
®AK=\;JU?	@AGHKFD?Cjv OV=*?^; ± _ ¬ F@A9<GEOfOV=*?^;s @A9<;R=*?	@A9Ã=DCE?F<F<GEF<Iu=<J,KLDCH;MÀ^KF<OAGHOV@AO>KPdDF<Z<GEF<I@A9<;
MhKb2;Mh;F@AOWKP4?^KM=DCH;vOV@VJ,[<^@A[lJU;Å@A9<;YJ,KL\K@UjGHF?^CE[l@V@A;J,;ZvÃOV=*?^;_
`|MR?SAKJ?Z<b?F<^;o?O+@AK;=<JU;OAO"@A9<;i=<J,KLDCE;MGHFf?F<K@A9D;JOV=e?^;QF<KomFn?O+@A9D;i^KFldDI[<JU?	@AGHKF
OV=*?^;sQZD;F<K@A;ZL$
q #& %KÈ?F<K	(w '";) J,;ÈsW+ *U_ ¬ F@A9<GEOfOV=*?^;si@A9<;h=\KOAGp@AGEKFÌKJ^KFldDI[lJ?	@AGHKF*
KP&?J,KL\K@hGHO^KM=DCE;@A;CpqZD;@A;J,MhGHF<;ZLq?OAGHF<ICH;=\KGHF@h9D?bGHF<I ,GHF<ZD;=];FDZ<;F@n=*?	JU?MR;@A;J,O
?Oy^KKJ,Z<GHFD?	@A;O_Ä8:9<;³=]KO,Gp@AGHKF<O@A9D?	@t?	J,;F<K@=D9qOAGE^?CHCpq²CH;I2?CÅL\;^?[<OA;KP>?^KCHCEGHOAGHKF*R?	J,;
J,;=<JU;OA;F@A;Z Lq|=*?	JA@AGH^[DCE?	JRJ,;IGEKF<OKP.#s?FDZ ?	J,;B^?CHCH;Z/#10325476Ï7Ò2ËÓ%É76_ ¬ FÌ@A9<;B^KFldDI[<JU?	@AGHKF
OV=*?^;s@A9<;t=*?	@A9|=DCE?FDF<GHF<I³=<J,KLDCE;M ^KF<OAGHOA@AOhKPWdDF<Z<GHFDIB?r^KF@AGHF[<K[<Oh^[<JAb2;ÅJ,;=<JU;OA;F@AGEF<I?
=*?	@A9uPKJ:?>OAGHF<ICE;:I;KMh;@VJ,GH^?Ce=\KGHF@U @A9D?	@&Gi^KF<F<;^@AOj@A9<;=\KGHF@AOiJ,;=<J,;O,;F@AGHFDIT@A9<;WGHF<Gp@AG?CD?F<Z
@A9<;dDF*?C^KF<dDI[lJU?	@AGHKFKP*@A9<;jJ,KL\K@s?F<ZyGHGX"Z<K;O4F<K@QGHF@A;J,OA;^@i?F8q #109254:6Ï7Ò2ËÓp:É 6_48:9<GHOMh;@A9<KZ
@VJU?Z<;OW?hOAGEM=DCHGpd*^?	@AGHKFKP@A9D;T=*?	@A9=DCE?F<F<GEF<If=DJ,KLDCH;MÙGH@mOA;?	J,^U9<;OW?h=*?	@A9PXKJW?ROAGHF<ICE;&=]KGEF@U
?I2?GHF<OA@?³9<GHI9<;JAwxZ<GHMh;F<O,GHKFD?C4OA;?	J,^U9OV=*?^;BÅ@A9<;Z<GHMh;F<O,GHKFKP # GHO>@A9<;uF[DMfL\;Jn+KP@A9<;
J,KL\K@UW?F<Z?I2?GHF<OA@TMhKJ,;^KM=DCH;OA9D?	=\;O&KPKL*OV@,?^CH;OÅb2;JAqOAGHM=*CH;f=*9qOAGH^?C KLDOV@,?^CE;OYMR?q
J,;OA[DCp@GHFb2;JAqy^KM=DCH;
 #10325476Ï7Ò2ËÓ%7É 6AU_
Â<KJQ;<?M=DCE;s2CH;@[DO^KF<O,GHZ<;J @A9<;=DCE?FD?	J4?	J,M KP<Â GHI[lJ,;_ ¬ @AO=\KOAGp@AGEKF>?MhKF<IW@A9<;jKLDOV@,?^CE;O
GHO4@AK@,?CECpq>F<KomFRKF<^;:@A9<;b?CH[<;OQKPe@A9<;m?FDICH;O4L\;@xo;;FRGp@AOiCHGHFlO ;=<?>@; , 4?	J,;:F<KomF\_ 8:9[<OsPXKJ
;?^,9=*?GpJ ;=<?>@; , Us+GH@&GEO&=]KO,OAGpLDCH;f@AKyZ<;^GHZ<;nom9D;@A9<;JY@A9<;J,KL\K@Y^KCHCHGHZD;OoGp@A9B@A9<;OA[lJAJUK[<F<Z<GHFDI
KLDOV@,?^CE;O_8:9DGHOmGHOmom9D?	@Woj;>Z<GHZ³GHFÂ GHI[lJU;nÕh@AKRJ,;=DJ,;OA;F@m@A9<;nMR?	=<=DGEF<IL\;@xo;;FB@A9<;T=D9qOAGH^?C
KLDOV@,?^CE;OWGEF@A9<;nK=\;JU?	@AGHKFD?COV=*?^;?F<Z³@A9<A; #10325476Ï7Ò2ËÓ%7É 6U._ BWKoTs\LqMhKbGHFDI?=\KGHF@&?CHKF<I@A9<;
^[lJAb2;"SAKGHF<GHF<D
I 	C; E?FDF
Z 	C; GmKF<;omGHCHC?CEOAKmZ<;d*F<;?^KCHCHGHO,GHKFwxPJ,;;QMhK@AGHKFnPXKJ@A9<;=DCE?F*?	J?	J,ML\;@xo;;F
@A9<;^KJAJ,;OV=\KF<Z<GEF<Iu=]KO,Gp@AGHKF<8O HR? =C; ET?FDF
Z Hh 	C; G2TGHFr@A9<;K=\;JU?	@AGHKFD?CQOA=*?^;_t8:9<GHOY^[<JAb2;RGHO>KF<;
OAKCH[<@AGHKF@AK@A9<GHO=e?	JA@AGH^[<CE?	J=e?	@A9y=DCE?F<FDGHF<I>=<J,KLDCH;Mt_
`aJU;^;F@&@VJ,;F<ZBGHF@A9<;fd*;CHZGHO@AKu^KF<OAGHZ<;JW@A9<;³®V@VJU?SA;^@AKJAq³OV=e?^; ± ÂD;JAL*?^,9"s4J I2:o9<;J,;
?o9<KCH;&=*?	@A9³GHOJ,;=<JU;OA;F@A;ZLq?hOAGHF<ICH;&=\KGHF@_8m9<;T^KKJ,Z<GHFD?	@A;OKP@A9<GHO=\KGHF@?	J,;Y@A9D;Tb?CH[<;O
KP@A9<;T=e?	JU?Mh;@A;J,OZ<;dDF<GHFDI@A9<;TOA[<^^;O,OAGpb2;TMhKb2;Mh;F@AOWKP @A9D;YJ,KL\K@_jÂDKJWGHFDOV@,?F<^;sD@A9D;TCHGHOV@:KP
OA[<^^;O,OAGpb2;:^KMhM?F<Z<OiO,;F@Q@AKf@A9<;J,KL\K@i^KF@VJ,KCHCE;JiGHF<Z<;;ZR;F<^KZD;m?Fh;F@AGpJ,;=*?	@A9KPe@A9<;J,KL\K@_
¬ Ft@A9<GHOOV=*?^;se@A9<;T=e?	@A9=DC?F<F<GHF<In=<JUKLDCH;M GEO:J,;Z<[D^;Zt@AKh@A9D;fOA;?	J,^U9PKJY?hOAGEF<ICH;Y=\KGHF@L_ K&F<^;
?I2?GHF\soj;@VJU?ZD;:?&OAGHM=DCEGpdD^?	@AGHKF>KPD@A9<;=e?	@A9=DCE?F<F<GEF<I:=<JUKLDCH;M OA;?	J,^U9<GHF<IYPXKJ?W=\KGHF@U?I2?GEF<OV@
?T9DGHI9<;JiZ<GEMh;F<OAGHKFKP]@A9<;mOA;?	J,^,9uOV=*?^;>Å@A9<;mZDGHMh;F<OAGEKFKP*@A9D;:@VJU?SA;^@AKJAqROV=e?^;:GHOQ@A9D;:F[DMfL\;J
KP=*?	JU?Mh;@A;J,OfF<;;Z<;Z@AKtOV=\;^GHPq^KM=*CH;@A;Cpqr?uom9<KCH;n=*?	@A9*U_Â<KJn;l?Mh=DCH;s"GHFrÂ GHI[lJU;Õs@A9<;
=*?	@A9yL\;@oj;;M
F =C; N:?F<O
Z ;=C PY^?FL\;&J,;=<J,;OA;F@A;ZyLq?=]KGEF@:GHFt?hOA;b2;FwxZ<GHMR;F<OAGHKFD?C]OV=e?^;TOAGHM=*Cpq
Lqu^KF<O,GHZ<;J,GHFDI>@A9D;YCH;F<I@A9tKP Gp@AOOA;b2;F³OA;IMh;F@AO_
	?Q

y

\§D¨W$us<©|t"§]ª

s|Bv}

XY[\&Z ab_

«

×vØ9Ø9 v}v

RJS

RJW
\S
XY[\^Z ]`_
R+V

XY[\Z c9_

\T
RUT

Â GHI[lJ,;·i`@xoK+u?	J,M =DCE?^;Zt?MhKF<IRKLDOV@,?^CH;OGHF@A9<;TK=\;JU?	@AGHKF*?C\OV=*?^;
dfe^gih ki jml°ei)²Dnon#opj1e1µ©³#hÔ

 HC KLe?CD?	=<=<J,K2?^U9<;O?	J,;:^CE?OAO,GH^?CHCpqZ<GpbGHZ<;ZGHF@AKY@xoKfM?GHFh^CE?OAO,;O·GJ,;@VJU?^@AGEKFRMh;@A9<KZ<Os?F<Z
GHGZ<;^KMh=]KO,Gp@AGHKFMh;@A9<KZ<O_ ¬ F@A9<;J,;@VJU?^@AGEKFRMh;@A9<KZ<OsKF<;@VJ,GH;O4@AKTJ,;Z<[<^;@A9<;ZDGHMh;F<OAGEKFnKP
@A9<;>GHF<Gp@AGE?C]=DJ,KLDCH;M LqyJ,;^[<J,OAGpb2;Cpq^KF<OAGEZ<;J,GHF<IO,[lLlwxMR?F<GEPKCHZDOKP @A9<;f^KFld*I[lJU?	@AGHKFBOV=*?^;_ ¬ F
@A9<;&Z<;^KM=\KOAGH@AGHKFMR;@A9<KZDOslKF<;W@VJ,GH;Oj@AK^,9D?	JU?^@A;JUGHÈ;Y@A9<;J,;IGHKF<OKP"@A9<;&^KFldDI[lJU?	@AGEKFuOA=*?^;
@A9D?	@?	JU;PEJ,;;KPeKLDOV@,?^CE;O_ Ç K@A9Mh;@A9<KZ<O4;F<Zh[<=omGp@A9?Y^CE?OAO,GH^?ClIJU?	=D9OA;?	JU^,9RKb2;Jj?&Z<GEOA^J,;@A;
OV=*?^;_ ¬ F³=<J,GEF<^Gp=DCH;s@A9<;O,;>Mh;@A9DKZ<OW?	J,;Ë@2qsr*ÓpÉÏxÉWL\;^?[<O,;T@A9<;qyomGECHC\dDF<ZB?=*?	@A9BGHP4KF<;>;GEOV@AO
?F<ZomGHCHC\OV@AGECHC\@A;J,MhGEFD?	@A;fGHF³?hdDFDGp@A;&@AGHMh;>GHP4?=*?	@A9³Z<K;OWF<K@W;GHOA@_:F<PXKJA@A[<F*?	@A;Cpqs*^KM=*[l@AGHF<I
@A9<;RJ,;@VJU?^@AGHKFKJf@A9<;Z<;^KM=\KOAGp@AGEKFIJU?	=D9ÃGHOf?F}"~wx^KM=DCE;@A;=<J,KLDCE;My·f@A9<;^KM=DCH;lGp@qKP
@A9<GHOi@,?OVhIJ,KomO;=\KF<;F@AGE?CHCpq?Oi@A9D;mF[<MfL\;JjKP"GHF<^J,;?OA;Ox?F<Fqs*2U_KF<OA;g[<;F@ACpqs
@A9<;OA;T=DCE?F<F<;JUO?	JU;Y[<OA;ZyKF<CpqPXKJ:J,KL\K@AO9D?bGHF<Ih?hCHGHMhGp@A;ZuF[<MfL\;JTÅ@A9lJU;;TKJmPXK[lJjKP D_ ¬ F
?Z<Z<GH@AGHKF\sl@A9<;q?	J,;>OACHKo­?F<Z³^?F³KF<CHqL\;T[<O,;ZKÖ*wxCHGHF<;·@A9<;T=DC?F<F<;J:GHOGHFb2K2;Z³omGp@A9³?hMhKZ<;C
KP\@A9<;;FbGpJ,KFDMh;F@sGp@=<J,KZ<[<^;O?f=DCE?FR@A9D?	@GHOQ=e?OAOA;Z@AKf@A9<;J,KL\K@^KF@VJ,KCHCE;Jjo9<GH^,9"sGHFR@A[lJ,F\s
;l;^[l@A;O&Gp@_ ¬ FtI;F<;J?CsD@A9<;f@AGHMh;TFD;^;OAO,?	JAqy@AKu?^,9<GH;b2;f@A9<GHOGHO:F<K@WOA9<KJA@m;FDK[<I9t@AKu?CHCHKo@A9<;
J,KL\K@@AKhMhKb2;fGHFt?hZlqF*?MhGH^&;FbGpJ,KFDMh;F@_
dfebd

Ð e¶³

Ð

tFuó·¶³vwjNµe1i

ie1f f#·'f

Ð

ie1f#f#hpoÔ

K&F<;Wo?q@AK^KM>L*?	@:@A9<;Y^KM=*CH;GH@xqKP+@A9<;&=DJ,KLDCH;M GHO@AK@VJU?ZD;Y^KM=DCH;@A;F<;O,Om?I2?GHF<OV@=\;J,PXKJVw
M ?F<^;_Q8KZ<KT@A9DGHOs@A9<;CEK^?C*=DCE?F<FD;J,O?	J,;WI[<GHZD;ZhLqh@A9<;WIJU?Z<GH;F@KP+?n^KOV@PX[<F<^@AGHKFB[<OA[D?CECpq
R
@A9<;i[<^CHGEZ<;?FhZ<GHOA@,?F<^;:@AK>@A9<;mIK2?CXi?F<ZR@,?	2;&GHF@AKn?^^K[<F@@A9<;^KF<OV@VJU?GEF@AOjGHF@VJ,KZD[<^;ZhLq@A9<;
KLDOV@,?^CE;O@AK?b2KGHZ@A9<;M ÂD?b2;JÅSAKFyx­8K[<J,FD?OAOAK[DZ\s*+*U_×GHF<^;@A9<;=*?	@A9=DCE?FDF<GHF<IY=DJ,KLDCH;M
GHOm}+~wx^KM=DCH;@A;sDF<KomGHF<Ih@A9<;T^KOV@WP[<FD^@AGHKF\s<Gp@:GHO?Cpo?qOm=\KOAOAGpLDCE;@AKRZ<;OAGHIF?RZ<;^;=<@AGpb2;f;FbG%w
J,KF<MR;F@om9<;J,;Y@A9D;>Mh;@A9DKZomGHCHC\I;@&@VJU?	=<=\;ZtGEF³?hCEK^?CMhGHF<GEM>[<Mt_´WKo;b2;Js\@A9<;OA;nMh;@A9<KZ<O
?	J,;n[<OA;PX[<C+GEFMR?FqGHF<ZD[<OV@VJ,GE?C"?	=D=DCHGH^?	@AGHKFDOL\;^?[<OA;>@A9<;q^?FZ<;?ComGp@A9^KMh=DCH;tJ,KL\K@AOY?F<Z
	z



$vu¨]}Ãs1º1t$v¹ØWw©vLsw©e1}%©l1r



{ ^| }b~~   
^ 

& 
 |

(



{:|^}b~~` 
& 

(
{U

[

{U

{5

Â GHI[lJ,;fÕ·8:9<;h^KFld*I[lJU?	@AGHKFÃOV=*?^;h^KJAJU;OV=\KF<Z<GHF<I@AK³Â GHI[lJ,;_BWK@A;·é.#²GHOf?t@AKJ,[<OsxÕ
Gp@hGHOhZ<GHbGHZD;ZGEF@AK@ojKJ,;IGHKF<
O #G79`p ?F<
Z #G79`p @A9D?	@R^?FDF<K@RL\;y^KF<F<;^@A;ZÌLq
?y^KF@AGEF[<K[DOY=*?	@A9\s ?F<Z²7v2&@A9D;J,;hGHOY F<K@n
? #*wxKL*OV^@, ?^CH;RPXKJ , L\;^?[<OA;GH@TZ<K;O>F<K@
GHF@A;JUP;J,;&oGp@A9@A9<;f?	J,Mt_
;FbGpJUKF<Mh;F@ MRKZ<;CEO9*?bGHF<IW@A9<K[<O,?FDZ<O KPDPÅ?^;Os@A9D?	@Q?	J,;KP@A;F@AKK&@AGHMh;wx^KF<O,[<MhGHF<IWPXKJQICHKL*?C
Mh;@A9<KZ<O_
U£¦¥)hµ³ f#·§g#hÔóe1f¤£¦vle1f¤£Êbde1op¨ÌÔ
8:9<;4OA@AK^U9D?OV@AGH^QKJ+JU?F<Z<KM¶?	=D=<J,K2?^,9To?O+d<J,OV@\GHF@VJ,KZ<[<^;Z&Lq Ç ?	JAJU?g[D?F<Z>?F<Z8%?	@AKM>L\;éJ©2Us
?F<ZBCE?	@A;JY[<OA;Z³Lq$KWb2;J,MR?	J,Oné2ÕUs?F<ZMhKJU;fJ,;^;F@ACpqtLq«fª ?bJU?	GéJ2I U_T8:9<;nMR?GHF³GHZ<;?
dfe¡ 

Ð e¶³

Ð

tFuó·¶³¢

ie1f f#·'f

¤£ojb

ef

·nh

L\;9<GHF<ZB@A9<;O,;R?CHIKJ,Gp@A9DMhOTGHOY@AKLD[<GHCEZ?tIJU?	=D9GHF@A9<;h^KFldDI[<JU?	@AGHKFOV=e?^;_u8:9D;IJU?	=D9GEOTKLlw
@,?GHF<;ZGHF<^JU;Mh;F@,?CECpq?O>PXKCHCHKomO·h?tCHK^?C=DCE?F<F<;JnGHOf[DOA;Z@AK³@VJAq@AK³J,;?^,9@A9<;IK2?C_×l9<K[<CHZ
@A9<;hMRK@AGHKFOV@AK=?	@n?yCHK^?CQMhGEF<GHMn[<Mys+?yF<;oÆF<KZD;yKJnCE?FDZ<MR?	JA<GHOT^J,;?	@A;ZÃLqrI;F<;J?	@AGHF<I
?RJU?F<Z<KMNMhK@AGHKFOV@,?	JA@AGHFDIRPJ,KM @A9*?	@WCHK^?C+MRGHF<GHMn[<My_:8:9D;TMh;@A9<KZ³GH@A;JU?	@A;OW@A9<;OA;>@xoKuOA@A;=DO
[<F@AGHC@A9<;IK2?CQ^KFldDI[lJ?	@AGHKF9D?O&L\;;F³JU;?^,9<;ZPJ,KMÁKF<;KPQ@A9D;OA;GHF@A;J,Mh;Z<GE?	J,qy=]KO,Gp@AGHKF<OLq
?IJU?ZDGH;F@WZ<;OA^;F@mMhK@AGHKF"_j8:9D;OA;f?CHIKJ,GH@A9<MhOoKJAomGp@A9?hZ<GHOA^J,;@AGEÈ;ZyJ,;=<J,;O,;F@,?	@AGHKF³KP @A9<;
^KFldDI[<JU?	@AGHKFnOV=*?^;_48:9<;q>?	JU;iF<KoF>@AKL\; r*3Ñ 254,5Ò 4ÍÅÓ$bÍ 6ÏÅÍÅËUÒÓÓ ¬@Ë 2qsr*ÓpÉÏxÉL\;^?[<O,;i@A9<;=<J,KLe?	LDGHCHGp@q
KP @A;J,MhGEFD?	@AGHF<IoGp@A9³?OAKCH[l@AGEKF7?h=e?	@A9³9D?OL\;;F³PXK[<F<ZKJ&FDKh=*?	@A9³;GHOA@AOU:^KFb2;J,I;O&@AKuKF<;
?O:@A9D;>?CHCHKoj;Z@AGHMh;TGEF<^J,;?OA;Y@AKo?	JUZ<OmGHF<dDF<Gp@q_`WOmGHFy@A9D;Y=<J,;bGHK[<O:O,;^@AGHKF\sDGp@GHOm?CHOAKh=]KO,OAGpLDCH;
@AKRZD;OAGHIFtOAGEM=DCH;&Z<;^;=<@AGHb2;T;FbGpJ,KFDMh;F@AOm@A9D?	@:omGECHC\MR?	2;T@A9DGHOGHF<ZyKP4?CHIKJ,Gp@A9DMµOACHKoj;J@A9D?F
?B=D[lJU;JU?F<Z<KM ?	=<=DJ,K2?^,9\_²´WKo;b2;Js@A9<;q9D?b2;yL\;;F|@A;OV@A;ZÌPXKJhJ,KL\K@AOomGH@A9²?r9<GHI9F[<Mw
L\;JfKP:r?F<Z@A9<;qr9D?b2;L\;;FOA9<KomF@AKojKJ,g[<GE^ACpqBGEFrJ,;CE?	@AGpb2;CHq^KMh=DCH;?F<ZF*?	@A[lJU?C
;FbGpJUKF<Mh;F@AO_
KW@A9D;JMR;@A9<KZDOj[DOAGHF<ITC?F<Z<MR?	JAOj9D?b2;WL\;;FZ<;bGEOA;Z\_4Â<KJ:;<?M=DCH;sD¼½}"+»]¼sGHF@VJ,KZ<[<^;Z
Lqr9D;F?F<Z´o?FDIlé2ÕUsQMR?	2;O>[DOA;KPCE?F<Z<MR?	J,OW@AK³?	=D=<J,KlGHMR?	@A;@A9D;hPEJU;;hOV=*?^;_u8:9<GHO
?	=<=<JUK2?^,9GEOOAGHMhGHC?	J@AK@A9D;y®A9<GH;JU?	JU^,9<GH^?C]=*CE?F<F<GHFDI ± ?	=<=DJ,K2?^,9³[<OA;ZyGHFy½®­x·iOA9<K[DCHZu@A9<;YMh;@A9<KZ
	

y

\§D¨W$us<©|t"§]ª

s|Bv}

«

×vØ9Ø9 v}v

PÅ?GHCj@AKrJ,;?^,9 ?IK2?CsjFD;oµOA[lLDIK2?CHOh?	JU;yI;F<;JU?	@A;Z²[<F@AGHCj@A9<;=<JUKLDCH;MÔGHO;?OVq;F<K[<I9@AKrL\;
OAKCpb2;Z"_ ¬ F@A9<;GHJ?	=<=<J,K2?^U9\sdDJ,OV@i?YCHK^?Cl=DC?F<F<;JQGHOQ[DOA;Z@AKTJ,;?^U9h@A9<;:dDFD?Cl=\KOAGp@AGEKF\·+OA9<K[DCHZ@A9<;
CHK^?Ce=DCE?F<F<;JPÅ?GHCs@A9<;&^KFldDI[lJ?	@AGHKFOV=*?^;YGHOZ<GpbGHZ<;ZuGHF@AKn@xoKOA[lLDOV=e?^;OslKF<;&^KF@,?GHFDGHF<In@A9<;
IK2?C*?FDZ@A9<;:K@A9<;J?YF<;oÌO,[lLlwxIK2?C_48:9<;:=<J,KLDCH;MaGEO @A9<;J,;PXKJ,;:Z<GpbGHZ<;ZGEF@AK&@ojK>OA[lLlw7=<JUKLDCH;MhO·
GfIKGHF<IBPEJUKMÀ@A9<;uGHF<GH@AGE?C4=\KOAGp@AGHKF@AK@A9D;OA[<LDIK2?Csi?F<Z GHGTIKGHF<IBPEJ,KM @A9<;uOA[lLDIK2?C@AKB@A9<;
dDFD?C=\KOAGp@AGEKF\_>¼½+}++»]¼>9D?O&L\;;FrOA9<KomFB@AKL\;>=e?	JA@AGH^[<CE?	JUCpqoj;CHCQ?Z*?	=<@A;Z@AKdDF<Z³=*?	@A9<OYPXKJ
MR?F<GH=D[<CE?	@AKJ,O_ ¬ @j9*?OiL\;;FGHM=DCE;Mh;F@A;Zu?F<Z@A;OV@A;ZyPKJ=DC?F<F<GHF<I&=e?	@A9<OPKJ¯'i[<M?>?F<Zu`WZ<;=<@
J,KL\K@AO_
dfe°

Ð e¶³

Ð

t

ie1f f#·'f

-¥oe²±Bhjµ¤¶jo³¦´®n°e$µh

·'fï¶³°h

8:9<;=DJ,;bGEK[<O4Mh;@A9<KZ<O4o;J,;:;OAO,;F@AGE?CECpq>Le?OA;ZhKFh@A9D;:^KFldDI[lJ?	@AGHKFhOV=*?^;· @A9<;:J,;@VJU?^@AGHKF\s@A9<;
Z<;^KM=\KOAGH@AGHKF\slKJ:@A9<;YK=<@AGEMhGHÈ?	@AGHKFyGHOM?Z<;YGHF@A9<GHOOA=*?^;_i`WF?Cp@A;J,FD?	@AGHb2;YGHO@AKh^KF<OAGEZ<;J@A9<;
®V@VJU?SA;^@AKJAqOV=e?^; ± _:Â<KJW;<?M=DCE;sDGHFt9<GEO:Mh;@A9<K«
Z µ~]sDÂ<;J,L*?^,9éJ I2OV@,?	JA@AOLqy^KF<OAGEZ<;J,GHF<I
@A9<;OV@VJ?GHI9@TCEGHF<;nOA;IMh;F@jSVKGHFDGHF<I@A9<;GHF<Gp@AG?C?F<Z@A9D;dDFD?C ^KFldDI[lJ?	@AGHKFrGHy
F #_8:9DGHOW=*?	@A9rGHO
=<J,KIJU;OAOAGpb2;CpqtMRKZ<GHdD;ZtGHF³OA[<^,9r?MR?F<F<;J@A9D?	@W@A9<;>PXKJALDGEZ<Z<;FyJ,;IGEKF<OGH@^J,KOAO,;O&?	JU;fJ,;ZD[<^;Z\_
`@Y;?^,9Gp@A;JU?	@AGEKF\s]?OA[lL<wxMR?F<GHPXKCHZtK1P #^KF@,?GHF<GEF<Ih@A9<;n^[lJAJU;F@W=*?	@A9BGHOmJ?F<Z<KMhCpqyI;F<;J?	@A;Z\_
¬ @hGHO@A9<;F|Z<GHO,^J,;@AGHÈ;Z²?F<Z|;=DCHKJ,;Z|[DOAGHF<I?ZlqFD?MhGH^=<J,KIJU?MRMhGHF<IMh;@A9<KZ@A9D?	@h[<O,;O@A9<;
CH;F<I@A9?^J,KOAOf@A9<;RPXKJALDGHZDZ<;FBJ,;IGHKFÃ?O>@A9<;h^KOA@>PX[<F<^@AGHKFGEFKJ,Z<;J>@AKMhGHFDGHMhGHÈ;_R8m9<;OA;?	J,^U9
J,;OA[DCp@AOQGHFh?fF<;o²@VJU?SA;^@AKJAqom9<KO,;:GHF@A;J,OA;^@AGHKFRomGp@A9@A9<;mPKJAL*GHZ<Z<;FnJ,;IGHKFDOiGHOQO,MR?CHCH;J4@A9D?FR@A9<;
KJ,GHIGEFD?C+@VJ?SV;^@AKJAq_n8:9<;>=<J,K^;OAO&GHOWJ,;=\;?	@A;Z[<F@AGEC?F?Z<MRGHOAOAGpL*CH;&@VJU?SA;^@AKJAqBGEOWPXK[<F<Z"_&`WO&GHF
@A9<;n=<J,;bGHK[<OWOA;^@AGHKFDOs\Gp@WGEO&?CEOAKR=\KOAO,GpLDCH;Y@AKyZD;OAGHIFBOAGHM=DCE;TZ<;^;=<@AGpb2;;FbGpJ,KF<Mh;F@AO@A9D?	@YomGHCHC
MR?	2;Y@A9DGHOGHF<ZKP4?CHIKJ,Gp@A9<M O,CHKo;Jm@A9D?F³?n=D[lJ,;&JU?FDZ<KMµ?	=<=<J,K2?^U9\_
8:9D;ioKJA>KP %+GHF\s ¶&GE?Ks?F<Z GH^,9D?CE;omGH^ÈWéØ GHO OAGHMhGECE?	J+@AK&K[lJQ?	=<=<JUK2?^,9\_ `O4GEFn?F;?	J,Cpq
b2;J,OAGEKFnKP*K[lJi?CHIKJ,GH@A9<M `9[D?^@AÈGHF\s ?È;Js Ç ;O,OA^G ;· J,;Us xz8 ?CpLDGs2ÕUsI;F<;@AGH^:?CHIKJ,GH@A9<MhO4?	J,;
[<OA;Z@AKf^?	JAJAq>K[<@QK=<@AGHMhGHÈ?	@AGEKFGHFn@A9<;@VJU?SA;^@AKJAqhOV=*?^;_48JU?SV;^@AKJUGH;Oi?	J,;=e?	JU?Mh;@A;J,GHÈ;Z[DOAGHF<I
@A9<;n^KKJUZ<GHFD?	@A;OWKPQGHF@A;J,Mh;Z<G?	JAqbGE?w7=\KGHF@AO_m`WFB;b2KCH[l@AGHKFD?	J,q?CHIKJ,Gp@A9<MGHOW[<OA;Z@AKuK=D@AGHMhGHÈ;
?^KOA@uPX[<F<^@AGHKF²L*?OA;Z KFÌ@A9<;³CH;F<I@A9 KP&@A9<;t@VJU?SA;^@AKJAq ?FDZ²@A9<;³PKJAL*GHZ<Z<;FJ,;IGEKF ^J,KO,OA;Z\_
8:9<;ROV@,?F<ZD?	J,ZK=];J?	@AKJ,O>KPj@A9<;I;F<;@AGH^u?CHIKJ,Gp@A9<MROT9D?b2;L\;;FMhKZ<Gpd*;Z?F<ZCE?	@A;Jn;@A;FDZ<;Z
@AKt=DJ,KZD[<^;R?tC?	J,I;b?	J,GH;@xqKP=e?	@A9<OR^ ¶&GE?Ks GE^,9D?CH;oGH^È1s x¹¸]9D?F<IsjJ I2U_8:9D;RF[<MfL\;JfKP
GHF@A;J,Mh;Z<G?	JAqhbGE?w7=\KGHF@AOGEOdl;Zt?FDZy^,9<KOA;F³[<OAGHFDIn?Ft9D;[lJ,GHOV@AGE^_  Gpb2;F@A9<GHOF[<M>L];JsFDK@A9<GHF<I
=<J,;b2;F@AO@AKZD;OAGHIF?mZ<;^;=D@AGpb2;i=DJ,KLDCH;M¶om9<GH^U9>OAKCE[l@AGHKFToGHCHCJ,;g[<GpJU;QMhKJ,;jGHF@A;J,Mh;Z<GE?	J,qW=\KGHF@AOs
CH;?Z<GEF<In@A9<;f?CHIKJ,GH@A9<M @AKhPÅ?GHC]om9<GHCE;WKFD;YOAKCH[l@AGHKFy;lGHOV@AO_
6 0 äl6¼ ( 1®½ á w Ýßâ6 ã\3 0¤¾ à$¿ (À Ý ( 1â6á w
`WO:o;T9D?b2;nOA;;F³GHFy@A9<;Y=DJ,;bGEK[<OOA;^@AGHKF\s*@A9<;T^KM=*[l@,?	@AGHKFKP@A9<;f^KFldDI[lJU?	@AGEKFOV=*?^;.#rGEO?
b2;JAqy@AGHMR;wx^KF<OA[<MhGEF<I@,?OVe_8m9<;TMR?GHFGHZ<;?L\;9<GHFDZ@A9D;f`J,GE?Z<F<;¯°Om^CH;o­?CHIKJUGp@A9<MµGHO:@AK?b2KGEZ
@A9<GHO^KM=*[l@,?	@AGHKF\_ ¬ FKJ,Z<;J@AKhZDK>@A9DGHOs@A9<;T?CHIKJ,GH@A9<M OA;?	J,^,9D;O:Z<GpJ,;^@ACHqPXKJm?P;?OAGHLDCH;=*?	@A9yGHF
@A9<;Y@VJ?SV;^@AKJAqyOV=e?^;_8:9<;&^KFld*I[lJU?	@AGHKFtOA=*?^Á; #GHOF<;b2;JW;=DCEGH^Gp@ACpqR^KMh=D[l@A;Z\_
`WOQomGECHCL];O,9<KomF"sGHF@A9<;@VJ?SV;^@AKJAqhOA=*?^;s=*?	@A9R=DCE?F<FDGHF<IWMR?qL\;OA;;F?O?FRK=<@AGHMRGHÈ?	@AGHKF
=<J,KL*CH;M ?F<Z OAKCpb2;Zz?OOA[<^U9 LqÌ?F{?CHIKJ,Gp@A9DM ^?CHCH;Z{¼¸<½+»e¾e¿ _ ¬ @uGHOR=\KOAO,GpLDCH;@AKÃLD[<GHCEZÌ?F
?	=<=<JUKlGHMR?	@AGHKF²KP&PJ,;;tOV=e?^;yLq²?F<K@A9D;Ju?CHIKJ,GH@A9<M ^?CHCH;Z ¸l¹+~<º+»\¸@A9D?	@GHOR?CHOAK=]KO,;ZÌ?O
?FÌK=D@AGHMhGHÈ?	@AGHKF²=<J,KLDCH;Mt_ 8:9<;`mJ,G?Z<F<;¯°Oh^CH;oÁ?CHIKJ,Gp@A9DM GHO@A9D;yJ,;OA[<CH@RKPW@A9<;tGHF@A;J,CH;?b2;Z
;l;^[l@AGHKFKP4¼¸<½+»e¾e¿r?F<Zt¸<¹+~<º»\¸]_
º »
. 

â

ÂÃÃ



$vu¨]}Ãs1º1t$v¹ØWw©vLsw©e1}%©l1r

ROBOT

\ Z Î

ÅW

ÄW ÅVV
Ä

ÅT

\ Z Æ

É
ÄT

\ Z ÇÈ ÊY É Ìc Ë¡ÍÌc9_
Í

Â GHI[lJ,;Tv·`=e?	JU?Mh;@A;J,GHÈ;Z@VJU?SA;^@AKJAqÏ , >@Ð , >@Ï 0 >@Ð 0 >=ÑÑÑÊÏJÒ>@Ð5Ò:?F<Z³?OV@,?	JA@AGHFDI=\KGHF@D=C; <YGEM=DCHGH^w
Gp@ACpqZD;dDF<;T?=*?	@A9GHF@A9<;TK=\;JU?	@AGHKF*?C\OV=*?^;PXKJW?9<KCEKF<KMhGH^YMhKL*GHCH;WJ,KL\K@_
t
ÕÔÖn°¶·'bd·ne¶©·kjf Ð opjl ihjb/×>¼¸<½+»e¾e¿
 Gpb2;F|?J,KL\K@>oGp@A9ØÃ*si?t@VJU?SA;^@AKJAqKP:CH;F<I@A9ÙMR?qL\;h=e?	JU?Mh;@A;J,GHÈ;Z|?O?BOA;g[<;F<^;
KP¯,OÚÛØÜ8ÙOA[<^^;OAOAGHb2;MhKb2;Mh;F@AO_³` OV@,?	J,@AGHF<It=\KGHF@$	C; h
Ý ?CEKF<ItomGH@A9OA[<^U9?t=*?	JU?Mh;@A;JUGHÈ;Z
@VJU?SA;^@AKJAqGHM=*CHGH^Gp@ACpqyZ<;d*F<;h?=*?	@A9?FDZ?dDFD?C4^KFld*I[lJU?	@AGHKFÞC; Ò GHF@A9<;^KFld*I[lJU?	@AGHKFOA=*?^;_
Â<KJ;<?M=DCE;s&PXKJ?9<KCHKFDKMhGH^MhKLDGHCE;J,KL\K@@A9<;@VJU?SA;^@AKJAqaÏ , >@Ð , >@Ï 0 >@Ð 0 >=ÑÑÑÊÏJÒ&>@Ð5XÒ u^?F{L\;
GHF@A;JA=<J,;@A;Zr?OTM?	GHFDIu?Ï , Z<;IJ,;;n@A[lJUF\s"MhKbGHF<IOV@VJ?GHI9@8Ð , s"MR?	GEF<Iu?Ï 0 Z<;IJU;;>@A[<J,F?F<Z
OAKnKF\_  Gpb2;F@A9<;WOV@,?	JA@AGHFDI>^KFld*I[lJU?	@AGHKFß; C Ý s@A9DGHOi@VJ?SV;^@AKJAquCH;?Z<O@AKf@A9D;mdDF*?CD^KFldDI[<JU?	@AGHKF/C; Ò
 Óe^g

Ð e¶³

Ð

ie1f f#·'f de$Ô`ef

OA;;TÂ GHI[<J,;Tv2U_
 GHb2;F?>Z<GHOA@,?F<^;mPX[<F<^@AGHKFÐKFu@A9<;m^KFld*I[lJU?	@AGHKFuOV=*?^;slGHP]o;md*F<Z?f@VJU?SA;^@AKJAqOA[D^,9@A9D?	@
Gp@jZ<K;OjF<K@^KCHCHGHZD;omGp@A9?FqKLDOV@,?^CH;O?F<ZuOA[<^U9R@A9D?	@j@A9<;WZ<GHOV@,?FD^;mL\;@xo;;
F C; Ò ?F<ZR@A9D;IK2?àC 	C; á
GHO4È;J,Ks@A9<;Fo;9D?b2;?&OAKCH[l@AGHKF@AKYK[<JQ=*?	@A9=DCE?FDF<GHF<I=<J,KLDCE;My_8:9D;J,;PKJU;s2@A9<;=*?	@A9=*CE?F<F<GHFDI
=<J,KL*CH;M MR?qL\;&OA;;F³?OW?MhGHF<GEMhGHÈ?	@AGHKFu=<J,KL*CH;M om9<;J,;·
_m8m9<;QOA;?	J,^U9>OA=*?^;iGHO?:OV=*?^;KPOA[<Gp@,?	LDCHqm=*?	JU?MR;@A;J,GHÈ;Z>@VJU?SV;^@AKJUGH;Os@A9<;4@VJU?SA;^@AKJAqfOA=*?^;_
Õ_m8m9<;P[<FD^@AGHKFn@AKYMhGHF<GHMRGHÈ;iGHâO ÐD? C; Ò >ãC; á GHPD@A9<;j=*?	@A9GHO4^KCHCHGEOAGHKFwxPJ,;;s?F<
Z Ð< 7C; ä3>C; á K@A9<;J,omGHOA;
 C; ä L\;GHFDI>@A9D;&d<J,OV@:^KCHCEGHOAGHKFu=\KGHF@UU_ 0
åÜ*ÝäàUæ7îèéálõàòòXã(úë(è+Þ7î	àUã$Þßè\ÿeàïë$âúè]æ7à å,ã(øè\æ7î	¤è æâç{øíAë$ïè]æ7à æ7î	è\âã$òXæxíUäÞè"ÿ"îèéäí4Þßà,ë°ë(ã$òXã(àä:àÞéÞï	á7òßãÜ èàVÿeèéøèéáéì
æ7îã$ò4ã$òQë(èVòòQã$äð%àUá÷:í,æã(øèæ7îí,äæ7î	è:Þ7î	àòÅèßäð%ï	ä	Þæã(àähúèVÞéí,ïòÅèæ7î	éè 	á7òXæjõ	íUáÅæiàUðíTÞßàUë°ë°ã$âã(ä	åTõ	í,æ7îhÞßàUïë$âúèmí
åààâfòXæxíUáÅææ7àAÿ]íUá7âYæ7î	èiåàí,ë*íUä	â>òÅîàïë$âYä	à,æ4úèâã$òÞéíUá7âèVâÜ êàUæ7èQæ7îíAææ7î	èjÞßàòXæð%ï	ä	Þæã(àäfâàèéò ä	àUæã(äÞë(ïâè
íUäûmàõæã(÷:í,ë°ã°æXûÞßáÅã°æ7èéáÅã$íòÅïÞ7î&íUò\æ7îèë(èéä	å,æ7î&àUðlæ7îèæ7á7Ìí ëXèVÞæ7àUáÅû&àUá"æ7îè4íU÷àUï	äæ\à,ð<èéä	èéáå,ûmïòÅèVâ2Ü
ÂÃ+ì

y

\§D¨W$us<©|t"§]ª

s|Bv}

«

×vØ9Ø9 v}v

:8 9D;?CEIKJ,Gp@A9<MÄ¼¸<½+»e¾e¿ sL*?O,;ZKF@A9<GHOb2;JAq>O,GHM=DCH;i@A;^,9<FDGHg[D;?FDZh?mJ?F<Z<KMhGHÈ;ZK=<@AGEMhGHÈ?w
@AGHKFMh;@A9<KZ\sGHOj?CpJ,;?Zlq?	LDCH;@AK>OAKCpb2;:g[<Gp@A;m^KM=DCH;=<J,KL*CH;MhO4KP]J,KL\K@iMhK@AGEKF=DCE?F<FDGHF<I_ÂDKJ
;<?M=DCH;s Â GHI[lJ,;ØtJ,;=<JU;OA;F@AOf@A9<;h@ojK³=*?	@A9<OnPXK[<F<ZPXKJ>@A9D;R9<KCHKFDKMhGH^MhKLDGECH;J,KL\K@_y?^U9
=*?	@A9o?OY^KM=D[l@A;ZKF?uOV@,?F<Z*?	J,ZBojKJAOV@,?	@AGHKFÌx¼~½+»]/
¾ íWGHFBCH;OAOW@A9D?î
F ©_$ÚuOA;^KF<ZoGp@A9<K[l@
[<OAGEF<I>?Fq=DJ,;wx^KM=D[l@,?	@AGEKFuKP+@A9<;&^KFldDI[lJ?	@AGHKFyOV=*?^;_Q8:9[<OslGp@GHOj=\KOAOAGpL*CH;s?CpL\;Gp@jOACHKomCpqs@AK
I;@W?=DCE?F<F<;J@A9D?	@^?FtL\;Y[<OA;ZtGEFt?ZlqFD?MhGH^&;FbGpJUKF<Mh;F@TÅom9<;J,;&@A9<;fKLDOV@,?^CH;OMR?qyMhKb2;
LqB®AZ<J,K=<=DGHFDI ± ?YF<;o²oKJ,CHZhGEF@AKY@A9D;mOVqOV@A;Mc;b2;J,q»©_$ÚfOA;^KF<Z"_Q¼¸l½+»]¾e¿GHO4b2;JAqh;R^GE;F@QL*[l@QGp@
GHOF<K@^KM=DCH;@A;sDO,GHF<^;YGp@:MR?qyPX?GHC]@AKhdDF<Zt?n=*?	@A9³;b2;FGHPKF<;T;lGHOV@AO:PXKJ:@xoKRZDGpÖe;JU;F@J,;?OAKFDO·
L_ ï&[<;W@AKn@A9<;WK=<@AGHMhGEÈ?	@AGHKFw7L*?OA;ZuPXKJ,M>[DCE?	@AGHKF\s<¼¸l½»e¾e¿t^?FyI;@@VJU?	=D=];ZLqCHK^?C*MRGHF<GHMR?
KPi@A9<;nKLSV;^@AGHb2;P[<FD^@AGHKF\seom9<GH^U9³GHF³@A[lJ,FBMR?q=DCE?^;n@A9<;>J,KL\K@&PX?	Jf?o?qBPJ,KM@A9<;nIK2?C
O,;;fÂ GHI[lJ,;TÚU_
Õ_m8m9<;:CH;F<I@A
9 Ù]KPe@A9<;:@VJU?SA;^@AKJ,GH;Oj^KF<OAGEZ<;J,;ZhMR?qL\;@AKK>OA9<KJA@i@AKTJ,;?^U9u?CHC<@A9<;m?^^;OAOAGHLDCH;
JU;IGHKF<O:KP@A9<;Y^KFld*I[lJU?	@AGHKFtOA=*?^;_

ÂGEI[lJ,;YØ·wð;?^@AGpb2;TJ,;=*CE?F<F<GHFDI>GHFt?h^,9D?F<IGEF<I;FbGpJ,KFDMh;F@
a ñ¤n ki jo·'ft
 Óebd à

e$Ô

ÕÔÖn°¶·'bd·ne$¶·jf

e1f

Ð

jml#ihpbß×f¸l¹~<º»\¸
o

¬ FnKJUZ<;J @AK&LD[<GHCHZ>?^KMh=DCH;@A;=DCE?FDF<;Js	oj;j=<J,K=\KOA;?WOA;^KF<Zh?CHIKJUGp@A9<M ^?CHCH;Z¸l¹+~Dº»\¸]_®!z9<GHCH;
@A9<;j=D[lJ,=]KO,;QKPe¼¸l½+»]¾*¿Ro?O@AK&CHKKfZ<GHJ,;^@ACpqfPXKJQ?:=*?	@A9PJ,KMò; C Ý @AKyC; ás@A9D;=*[lJA=\KOA;QKPe¸l¹+~<º+»\¸
GHOj@AK^KM=D[<@A;&?Fy?	=<=DJ,KlGHMR?	@AGHKFKP+@A9<;WJ,;IGHKFyKP"@A9D;W^KF<dDI[lJU?	@AGHKFOV=e?^;T?^^;OAOAGpLDCE;PJ,KMó; C Ý _
8:9D;³¸l¹+~Dº»\¸Ì?CHIKJ,GH@A9<M L*[<GHCHZ<O?Fz?	=D=<J,KlGHMR?	@AGEKFÌKPY@A9<;?^^;OAOAGHLDCH;BOV=*?^;³Lq²=*CE?^GHF<I
CE?F<ZDMR?	JAOGHFy@A9<;T^KF<dDI[lJU?	@AGHKF³OV=*?^Á; #GEFyOA[<^,9B?o?qy@A9D?	@W?=*?	@A9³PEJ,KMµ@A9<;fGHFDGp@AGE?Ce=\KOAGp@AGHKF
	C; Ý@AKT?FqnCE?FDZ<MR?	JAfGEO F<KomF\_ ¬ FKJUZ<;J4@AKTCH;?	J,F?OQMn[<^U9R?O4=\KOAOAGpL*CH;?	L\K[l@4@A9<;PJ,;;OV=*?^;s@A9<;
¸l¹+~Dº»\¸y?CHIKJ,Gp@A9<M @VJUGH;O@AKhOV=DJ,;?Zy@A9<;TC?F<Z<MR?	JAO[<F<GEPKJ,MRCpqRKb2;J@A9<;TOV=e?^;hOA;;fÂ GHI[<J,8; I2U_
8KnZDKf@A9<GEOsGH@i@VJ,GH;Oj@AKn=D[l@@A9<;&CE?F<Z<M?	JAOj?OPX?	J:?Oj=\KOAOAGpL*CH;:PJ,KM KF<;W?FDK@A9<;JLqMR?GEMhGHÈGHF<I
@A9<;TZDGHOV@,?F<^;OL\;@xo;;Ft@A9D;My_
8:9D;J,;PKJU;s*¸l¹+~<º+»\¸uMR?qL];YO,;;F?O?MR?lGHMhGEÈ?	@AGHKFy=<J,KL*CH;Mkom9<;J,;·
ÂÃp



$vu¨]}Ãs1º1t$v¹ØWw©vLsw©e1}%©l1r
C; Ý

	C; á

Â GHI[lJ,;fÚ·` =<J,KLDCH;M CH;?Z<GHF<Ih@AK?hCEK^?CMhGHF<GEM>[<Mt_ ¬ FOA[<^U9³?^?OA;s\?hOAKCH[<@AGHKFt=*?	@A9³9D?Od<J,OV@
@AKRMhKb2;n?o?qPEJUKMµ@A9<;>IK2?C_8:9<;TIK2?C¯°O®,?	@V@VJU?^@AGHKF ± L*?O,;ZKFt@A9D;fMhGHFDGHMhGHÈ?	@AGHKF
KP@A9D;Yi[<^CHGEZ<;?FyZ<GHOV@,?FD^;&=<J,;b2;F@AO¼¸l½»e¾e¿PJ,KM dDF<ZDGHF<InOA[<^,9³?=*?	@A9\_

Â GHI[lJ,;8I·8:9<;&d<J,OA@=DGH^@A[lJ,;&JU;=<J,;OA;F@AO@A9<;TGEF<Gp@AGE?Ce=\KOAGp@AGHKFy?F<Zt@A9<;Yd<J,OA@:CE?F<Z<MR?	J,*_Q8:9D;YOA[lLlw
OA;g[D;F@CE?F<Z<M?	JAO?	J,;@A9D;F [<FDGHPKJUMhCpqÃOA=<J,;?ZÌKb2;Jy@A9<;O,;?	J,^,9zOV=*?^;³om9<GECH;@A9<;
Mh;@A9<KZÌ2;;=DO@VJU?^, KPT?CHCm=*?	@A9<OTSVKGHFDGHF<I@A9<;³CE?F<Z<MR?	J,OR@AK@A9<;³GHF<Gp@AG?C=\KOAGp@AGHKF\_
8:9<;?CHIKJ,Gp@A9DMGEOWF*?Mh;Z?PE@A;J>`mJ,G?Z<F<;>L];^?[DOA;nLq³=DCE?^GHF<IuCE?F<ZDMR?	JAOs"¸l¹+~<º+»\¸
[<FoGHF<Z<O?O:GHPGp@o;J,;T[<OAGEF<I?@A9lJ,;?Z?O8:9<;OA;[DOZ<GHZ\_
_m8m9<;OA;?	J,^,9ÌOV=*?^;GHOn@A9<;yOA;@KP&?CHCj=*?	@A9<OOV@,?	JA@AGHFDIBPJ,KM KF<;KPm@A9<;=<J,;bGHK[<OACHqB=*CE?^;Z
C?F<Z<MR?	JAO_
Õ_m8m9<;&P[<FD^@AGHKFu@AKMR?GEMhGHÈ;&GHéO Ð< C; Ò >ÌôUs<o9<;J,Á; ôÌGHO@A9D;WO,;@:KPCE?FDZ<MR?	JAOj?CHJ,;?ZlqR=*CE?^;Z\_
¼ ¸l½+»]¾e¿
¬ FnKJUZ<;J4@AK&9D?b2;m?=DC?F<F<;J@A9D?	@QGHOL]K@A9^KMh=DCH;@A;?F<Z;R^GH;F@s2o;^KMfLDGEF<;Zn@A9<;j@xoK&=<J,;bGHK[<O
?CHIKJ,GH@A9<MhOm¼¸<½+»e¾e¿r?F<Z³¸l¹+~<º+»\¸@AKhKL<@,?GEFy@A9<;T`J,GE?Z<FD;¯°O^CH;o?CHIKJ,GH@A9<My_
8:9D;&=<J,GHF<^GH=DCH;mKP@A9<;Y`J,GE?ZDF<;¯°O^CH;o?CHIKJUGp@A9<MµGHOb2;J,qO,GHM=DCH;·
_mWOA;&@A9<;f¼¸l½+»]¾e¿B?CEIKJ,Gp@A9<Mk@AKdDF<Zuom9D;@A9<;Jm?B®AOAGHM=*CH; ± =*?	@A9y;GEOV@AOL\;@xo;;¦
F C; Ý ?F<
Z ;	C á_
 Óe¡  ¥Ó³°hÒ²´o·eã£Êf°hõÔöÓihUu

tjo©·¶©³#b/×f¸l¹+~<º+»\¸F÷

²çi

ÂÃÂ

y

\§D¨W$us<©|t"§]ª

s|Bv}

«

×vØ9Ø9 v}v

a

b

c

d

Â GHI[lJ,;*· Ç K[DF<^GHF<It?I2?GHFDOV@Á#*wxKL*OV@,?^CH;O_uÂGEI[lJ,;y7?2W=<JU;OA;F@AOf@A9<;KJ,GHIGEFD?C =*?	@A9GHF@A9D;^KFw
dDI[lJU?	@AGHKFOV=*?^;_rÂ GHI[lJU;³ÅLefOA9<KomO>@A9<;O,?Mh;=*?	@A9|?PE@A;J@xoKL\K[<F<^;O?CHKF<I³@A9<;
OA;^KF<ZOA;IMh;F@KFKLDOA@,?^CH;TÕf?F<ZuKFKLDOV@,?^CH;>_QÂ GHI[lJ,;>^GHOi@A9D;mJ,;O,[<Cp@KLD@,?GHF<;Z
?PE@A;JR?³L\K[<F<^;uKPmOA;IMR;F@Rv?I2?GHF<OA@hKLDOV@,?^CH;tÕ_Â GHFD?CECpqsQÂ GHI[lJ,;BZ*f=<J,;OA;F@AOh?
b?CHGEZ=*?	@A9tKL<@,?GHFD;Z?PE@A;JW?dDFD?C]L\K[<F<^;YKPOA;IMh;F@Ø?I2?GHF<OV@:KLDOA@,?^CH;>Õ_
Õ_ ¬ PF<K®AOAGHM=*CH; ± =*?	@A9tGHOPXK[<F<ZLqyOV@A;=s<@A9D;Ft^KF@AGEF[<;f[<F@AGEC]?=*?	@A9tGHO:PXK[<F<Z"_
7 ?2WOA;f¸<¹+~<º»\¸@AKRI;F<;J?	@A;f?F<;o¶C?F<Z<MR?	JAe_
ÅLeuWOA;>¼¸l½+»]¾e¿B@AKhCHKKuPXKJ?®AOAGEM=DCH; ± =*?	@A9tPJ,KM @A9*?	@mCE?F<Z<M?	JAR@AKC; á_
8:9D;m`J,GE?Z<F<;¯°O^CH;o{?CHIKJ,Gp@A9<McomGHCHCd*F<Z?T=*?	@A9GEPeKFD;m;lGHOV@AO_ ¬ F?FuKb2;JAo9<;CHMhGHFDITF[DMfL\;J
K P4^?OA;OsSA[<OV@&?RPX;o­C?F<Z<MR?	JAOm?	J,;nF<;^;OAOU?	JAqPXKJ@A9<;>`mJUGE?Z<F<;¯°O^CH;o ?CEIKJ,Gp@A9<MN@AKRJU;?^,9B@A9<;
@,?	J,I;@&?F<ZtOV@AK="_
 Óe°

²

U±joùøBbún o j²ûhjbdhjf¶5×ÆÑjg#f#µ·'f¤tjfß#mü=Ôl#Ô¶e1µihÔ

kme

` @ q=DGE^?CZ<GHR^[<Cp@qPXKJ?t=*?	@A9Ã=DCE?FDF<GHF<It?CHIKJUGp@A9<M GHOT@AKBdDF<Z?^KCECHGHOAGHKFlwxPEJ,;;=e?	@A9Ã@A9<J,K[<I9
?tO,MR?CHCQ^KJAJUGHZ<KJ>GEFr@A9<;R^KF<dDI[lJU?	@AGHKFÃOV=*?^;_8m9<GHOTGHOn?CHOAKy@A9D;R^?OA;uPKJ>@A9<;hLe?OAGH^hb2;JUOAGHKFKP
@A9<;`J,GE?Z<F<;¯°O&^CH;oc?CEIKJ,Gp@A9<Mys]=<JU;OA;F@A;ZÃ?	L]Kb2;_n8m9<;f=DJ,KLDCH;MÁGHOW@A9D?	@Yb2;JAqBP;oa@VJ?SV;^@AKJ,GE;O
;F<^KZ<;jOA[<^,9n=*?	@A9DO?F<Zn@A9<;JU;PKJ,;@A9<;q?	J,;ib2;J,qfZ<GpR^[DCp@"@AKWdDF<Z\_ KOA@@VJ?SV;^@AKJ,GE;O4^KCHCHGHZ<;QomGp@A9
@A9<;:KL*OV@,?^CH;Oâ_ !;m=<J,K=\KOA;:?&b2;JAqOAGEM=DCH;GHZ<;?W@AK>Z<;?ClomGH@A9@A9<GHO =<JUKLDCH;My·IKGHF<IYL*?^,o?	J,Z<Oj?	@
;?^,9^KCHCHGHO,GHKFn=]KGEF@_ ¬ Ps2PXKJ?YIGpb2;F@VJ?SV;^@AKJAqsl?&^KCHCHGEOAGHKFGHO4Z<;@A;^@A;Zu?CHKF<I&@A9<;^KJAJU;OV=\KF<Z<GHF<I
=*?	@A9\sD@A9<;Fto;fOAGEM=DCpqR^KFDOAGHZ<;J:@VJ?F<OAPXKJ,MhGHF<I@A9*?	@m@VJU?SA;^@AKJAqtOAK@A9*?	@Gp@m;FD^KZ<;OW?F<;o=*?	@A9\s
KF<;@A9D?	@TGEOYPK[<FDZLq³L]K[DF<^GHF<IuKÖÃ@A9D;KLDOV@,?^CH;R?	@Y@A9D;^KCHCHGHOAGEKF=\KGHF@OA;;hÂ GHI[lJ,
; *U
_ BWK@A;
@A9D?	@@A9<GHOR^KFDOV@VJ,[<^@AGHKF GHO?	=D=DCHGH;ZJ,;^[<J,OAGpb2;Cpq|[<F@AGHC@A9<;³;F@AGHJ,;t@VJU?SA;^@AKJAqÌ^KJ,J,;OV=\KF<Z<O@AK?
^KCHCHGEOAGHKFwxPJ,;;=*?	@A9\_
ÂÃ	ý



$vu¨]}Ãs1º1t$v¹ØWw©vLsw©e1}%©l1r

W OAGHF<Iu@A9<GEO@A;^U9<F<GHg[<;s?CEC@VJ?SV;^@AKJ,GE;O>?	J,;OAK@VJU?FDOAPKJUMh;Z@A9D?	@Y@A9<;q;F<^KZ<;nb?CHGEZ³=e?	@A9<O_
8:9<GEO\GHM=<J,Kb2;ZTb2;J,O,GHKFfKP@A9<;Q`J,GE?ZDF<;¯°O+^CH;o?CHIKJ,Gp@A9<MF<K:CHKFDI;J+^?	J,;O ?	L]K[<@+KLDOV@,?^CH;O_ÂlJUKM
@A9<;=\KGHF@YKPjbGH;oÄKP?yO,;?	J,^,9ÃGHF@A9<;@VJU?SA;^@AKJAqOV=e?^;sGp@TGHO>?OfGHPi@A9<;hKLDOV@,?^CE;Of9D?b2;hOAGHM=*Cpq
b?F<GHOA9<;Z"_8:9<GEO4Mh;@A9<KZGHOQ;OV=\;^GE?CHCHqf;R^GH;F@iPXKJiFD?	JAJ,Ko²^KJAJ,GHZDKJ,O4GHF@A9<;:^KF<dDI[lJU?	@AGHKFOA=*?^;_
!zGp@A9<K[l@&L\K[<F<^GHFDIsD@A9<;MR?	=<=*GHF<IuKPi?^KJAJ,GHZDKJWGHFB@A9<;^KFld*I[lJU?	@AGHKFOV=*?^;n@AK@A9<;n@VJU?SA;^@AKJAq
OV=*?^;GEOT?O,;@TKPib2;JAqPX;oa=]KGEF@AOA_ ! GH@A9L]K[DF<^GHF<Is\;b2;JAqOAGHF<ICE;f@VJU?SA;^@AKJAqrIKGHF<I@A9<J,K[<I9?
=*?	JA@KP@A9D;u^KJ,J,GHZ<KJGHO³®APKCEZ<;Z ± GHF@AK@A9<;^KJAJUGHZ<KJyOA;;Â GHI[lJ,;«*U_8:9D;RJ,;O,[<Cp@,?F@M?	=<=DGHF<I
KP&@A9<;t^KJ,J,GHZ<KJuGHF|@A9<;y@VJ?SV;^@AKJAq OV=*?^;GEOR^KF<OA;g[<;F@ACpq²?Mn[<^,9 CE?	J,I;JOA;@KPW=\KGHF@AOs:?F<Z
@A9<;J,;PXKJ,;hGH@TGHOYM>[D^,9;?O,GH;JT@AKydDFDZ?yMh;M>L];JTKPj@A9<GEOYOA;@_8:9DGHO&;M=DGpJ,GE^?CGEM=<J,Kb2;Mh;F@>9D?O
?MR?SAKJm=DJU?^@AGH^?C+GEM=*?^@:L\;^?[<OA;fGp@:MR?	2;O@A9<;Y=<J,K=\KOA;Z³?CHIKJ,Gp@A9<M PX?OV@A;JnÅdDP@A;;Ft@AGHMh;OGHF
@A9<;Y=DJ,KLDCH;M ^KF<OAGEZ<;J,;ZyL\;CHKoT_
 Óebþ ¥Ó³°hÒ²´iktjo©·¶³#b

!;R^?FF<KoÆIGpb2;R?tdDFD?C b2;J,O,GHKFKPj@A9<;h`J,GE?ZDF<;¯°OT^CH;o ?CHIKJ,Gp@A9<Mt_ ¬ @f9D?OT@A9<J,;;hGHFl=*[l@AO·$C; Ý
Å@A9<;uGHF<Gp@AG?C4=\KOAGp@AGHKF*UsA	C; 
á Å@A9<;IK2?Cj=\KOAGp@AGEKF*Us ?FDZúÿ|Å@A9<;uMR?lGHMn[<M ?CHCEKo;ZZDGHOV@,?F<^;PKJh?
=*?	@A9u@AKn@A9<;L#o09254:6 Ï7Ò2ËÓpÉ:,6 U_ ¬ @JU;@A[lJ,F<O?nCH;I2?Ce=*?	@A9KJj@A;JUMhGHFD?	@A;OGHP\F<Kn=*?	@A9;lGHOV@AO?	@@A9<;&IGpb2;F

J,;OAKCE[l@AGHKF\_


	 
	 ?C; Ý > 	C; á?>Ìÿ

L];IGEF
i ·Ú­  C , ·ÚÛC; Ý 
 ¬ F<GH@AGE?CHGHÈ;@A9<;TOA;@KPCE?FDZ<MR?	JAOomGp@A9@A9<;YGEF<Gp@AGE?Ce=\KOAGp@AGHKF
ô , · Ú  C ,  "! , Ú$#&%'
ZDKom9<GHCH;n( ! ä*) ÿ+ 
 JU[<F¼¸l½»e¾e¿Ã·iCHKKuPXKJ:@A9<;fIK2?C"omGp@A9t?CEK^?C"MR;@A9<KZ
GHPMhGHF Ò-,/. 021 Ð< C; á>ãC;  ÙV ÚÚÕ©2
J,;@A[lJU3F   `­=*?	@A9t9D?OL\;;FtPXK[<F<
Z 4
;CHO,;
 JU[<Ft¸l¹+~<º+»\¸³·Q=*CE?^;T?F<;o¶C?F<Z<MR?	JA
²· Ú56#  
 C ä · Ú¹>C; ·O,[l= Ò7,8. 091 Ð<& ô ä;: , >C;  ÙV+ 
ô ä · Ú¦ô ä<: ,>=   C ä  
! ä · ÚMÐD& ô ä<: , >  C ä + 
;F<ZDGHP
;FDZ<Z<K
ôÚ¦ô ä 
!Á?
Ú !	ä@

;F<Z

JU;@A[lJ,F"(!+  BWK=*?	@A9A4
Â GHI[<J,;T·i8:9<;Y`J,GE?ZDF<;¯°OmCH;o`WCHIKJ,Gp@A9DM
ÂÃ/B

y

\§D¨W$us<©|t"§]ª

s|Bv}

«

×vØ9Ø9 v}v

8:9D;T?CHIKJ,Gp@A9<M GEOL*?OA;ZtKFt@A9<;TPXKCHCHKoGHF<IK=<@AGHMhGEÈ?	@AGHKF=<J,KLDCE;MhO·
C H  ·3D ,O>Ù [lE = 	 <Ð &F ô ä<: , > C; ÙV

GHF«Ð<C; Ù > 	C; á
G H · D MR
>Ù E 	 F
C;  ÙnZ<;F<K@A;OR@A9<;y;@VJU;MhGp@xqKP&?CH;I2?C=*?	@A9|=e?	JU?Mh;@A;J,GHÈ;Z²omGp@AJ
9 IuJU;?C=*?	JU?Mh;@A;J,Ou?F<Z
VO @,?	JA@AGEF<I;Gp@A9<;J:PJ,KMµ;?^U9KP@A9<;&=<J,;bGHK[<OACHqh=DCE?^;ZyCE?FDZ<MR?	JAO&7¸l¹+~<º+»\¸DKJmPJ,KM @A9<;YC?	@A;OV@
=DCE?^;ZCE?F<Z<MR?	J,³x¼¸<½+»e¾e¿+U_
8:9D;T?CHIKJ,Gp@A9<M GEOJ,;OAKCH[<@AGHKFwx^KM=DCE;@A;Y[<F<Z<;J@A9<;TPXKCHCHKomGHF<I?OAO,[<M=<@AGHKFDO·
K ®U×=*?^;dDCHCHGEF<Ir^KM=DCH;@A;FD;OAO ± ·8:9<;BICHKL*?C&MR?lGHM>[DM ZDGHOV@,?F<^;B^?FzL\;³PXK[<F<Z Lq @A9<;
K=D@AGHMhGHÈ?	@AGHKF³?CHIKJ,Gp@A9<M [DOA;ZtGHFt¸l¹~<º»\¸L @A9<;T^KFldDI[<JU?	@AGHKFtOV=e?^;YGHOm?^KM=e?^@mOA;@_
K ®Ìÿf^KM=DCH;@A;F<;O,O ± ·8m9<;K=D@AGHMhGHÈ?	@AGHKF>=<J,K^;Z<[lJU;i[<OA;ZGHF¼¸<½+»e¾e¿u?Cpo?qO dDF<Z?m^KM=*CH;@A;

=e?	@A9rKJJ,;@A[lJ,F<O¯©2om9<;Fu@A9<;&OV@,?	J,@AGHF<I?F<Zu@A9<;&IK2?C]=]KO,Gp@AGHKF<O?	J,;&CHK^?	@A;ZomGp@A9<GHFu?nL*?CHC
KPJU?ZDGH[<¯O ÿKP@A9<;TPJ,;;YOV=e?^;_

¬ F=<JU?^@AGE^;s@A9<;dDJ,OV@4^KF<Z<Gp@AGEKF^?F<F<K@QL\;Mh;@QoGp@A9h?&JU?F<ZDKMhGHÈ;ZhK=<@AGEMhGHÈ?	@AGHKFh?CHIKJUGp@A9<M
GHF ?L\K[<FDZ<;Z|@AGHMh;sW?F<Z KFDCpq²CHK^?CMR?lGHMR??	J,;BPK[DF<Z\_¶´WKo;b2;JsW@A9<;³C?F<Z<MR?	JAOh=*CE?^;Z
?^^KJ,Z<GEF<IR@AK@A9D;>F<;oÄ?CHIKJUGp@A9<M ?	J,;nL\;@V@A;JTZ<GHOV@VJ,GHLD[l@A;ZtKb2;JT@A9<;PEJU;;>OV=e?^;>@A9*?FrCE?F<Z<MR?	J,O
=DCE?^;ZtJU?F<Z<KMhCHqs<CH;?Z<GHF<I@AKhL];@V@A;J=\;J,PKJUMR?F<^;O_i8m9<;YIK2?CKP@A9<;TFD;@mO,;^@AGHKFGHO:@AKWSV[DOV@AGHPq
@A9<GHO^C?GHMys<;=];JUGHMh;F@,?CHCpq_
i0 0 6 0w ½é1 âßãON4(6 PRQTSTU Ýßâ  6 0 ãWVYX 0 ã  46 äYZ 0\[ 6 â21 0wOD0 á
¬ FÃKJ,ZD;J>@AKZ<;MhKFDOV@VJU?	@A;@A9<;PX;?OAGpL*GHCHGp@q?F<Zg[D?CHGp@AGH;O>KP@A9<;u`mJUGE?Z<F<;¯°O>^CH;oµ?CHIKJ,Gp@A9<Mtso;
9D?b2;RZ<;b2;CHK=\;Z?tJ,;?CHGHOA@AGH^?	=<=DCHGH^?	@AGEKFKPj@A9<;R?CHIKJ,GH@A9<My
_ !;OA;CH;^@A;ZÃ?t=<J,KLDCE;MÁom9<;J,;o;
o?F@h@AK9D?b2;?r=*?	@A9|=DCE?FDF<;JPKJ?OAG%+J,KL\K@R?	J,M GEF²?rZlqFD?MhGH^;FbGpJUKF<Mh;F@no9<;J,;
?F<K@A9<;JY?	J,MGHOm[DOA;Z³?O&?hMhKL*GHCH;YKLDOV@,?^CE;_m8:9<;YJUKL]K@nÅJ,KL\K@`YGHO[<F<Z<;Jm@A9<;f^KF@VJ,KC KP @A9<;
`J,GE?Z<F<;¯°On^CH;o ?CHIKJ,Gp@A9DMy_ ¬ @nOA9*?	J,;O>GH@AO>oKJAOV=*?^;omGp@A9?OA;^KFDZÃJUKL]K@uÅJ,KL\K@ Ç f@A9D?	@GHO
MhKbGHFDIB[DF<Z<;Jn@A9<;^KF@VJ,KCmKP?³JU?F<Z<KMÔMhK@AGEKF|I;F<;JU?	@AKJ_8:9<;u`mJUGE?Z<F<;¯°O^CH;o ?CHIKJUGp@A9<M
Mn[<OV@mL\;f?	L*CH;Y@AKu^KM=D[l@A;f=*?	@A9<OmPXKJ`aGEF²®VJ,;?C@AGHMh; ± 9<;J,;sDJU;?C"@AGHMh;>Mh;?F<OWPX?OA@;F<K[<I9@AK
;F<OA[<J,;&@A9D?	@:J,KL\K@:`omGHCHC]F<;b2;JW^KCHCHGHZD;momGH@A9yJ,KL\K@ Ç U_
¬ F²KJ,Z<;J@AKJ,;?^U9 O,[<^,9 ?rCH;b2;CmKPW=\;J,PXKJ,MR?F<^;sjo;^,9DKOA;t@AKÃGHM=DCH;MR;F@@A9<;`mJ,G?Z<F<;¯°O
^CH;oµ?CHIKJ,GH@A9<M KF|?³MR?OAOAGHb2;Cpqr=*?	JU?CHCE;CMR?^U9<GHF<;³ ;I2?FDKZ<;oGp@A9²Õ8mJ ©J©B8JU?F<OV=*[l@A;J,OUU_
Â<[lJ,@A9<;J,MhKJ,;s\o;OA;CH;^@A;ZÃ?I;F<;@AGH^h?CHIKJ,GH@A9<M ?OTK[lJTK=<@AGHMRGHÈ?	@AGHKFB@A;^,9<FDGHg[D;_>8:9<;nJ,;?O,KF<O
PXKJ:@A9<GHO^U9<KGH^;>?	JU;·
_  ;F<;@AGH^?CEIKJ,Gp@A9<MhO>?	J,;o;CHCiOA[DGp@A;ZrPKJ>=<J,KLDCE;MhOYom9<;JU;@A9<;ROA;?	JU^,9OA=*?^;RGHOf9[<I;RLD[l@
o9<;J,;@A9<;JU;h?	J,;RMR?Fqr?^^;=<@,?	LDCH;OAKCH[l@AGHKFDO_h8:9<GHOYGEOT;l?^@ACHqr@A9<;h^?OA;h9D;J,;_8:9D;@VJU?w
SA;^@AKJAqOV=e?^;RGHO>9[<I;hLD[l@T@A9<;JU;R?	J,;s L*?	JAJ,GEF<I;^;=<@AGEKFD?C^?O,;Os4F[<MR;J,K[<Of?^^;=<@,?	L*CH;
=e?	@A9<O:IKGHF<IRPEJ,KM ; C Ý @AK 	C; áomGp@A9<K[<@:^KCHCHGHOAGEKF\_
MQ.»

ãá

  ã

ÂÃ




$vu¨]}Ãs1º1t$v¹ØWw©vLsw©e1}%©l1r

Õ_  ;F<;@AGH^h?CHIKJ,GH@A9<MhOs\[<F<CEGp2;>?F[<M>L];J&KPQ@A9D;K@A9<;JTK=<@AGHMhGEÈ?	@AGHKFB@A;^,9<F<GEg[<;O Ç ;OAOAG&;· JU;s
8 ?CpLDG7s`W9[D?^@AÈGEF\s1x ?È;JsjJI2Usi?	JU;hb2;JAq;?OVqr@AK³GHM=DCE;Mh;F@TKF=*?	JU?CHCE;Ci?	J,^,9DGp@A;^w
@A[<J,;O_!;f9D?b2;T=<J,;bGHK[<O,CpqZ<;b2;CEK=];Z³?=*?	JU?CECH;C\I;F<;@AGH^f?CEIKJ,Gp@A9<MÙ7~^]"½m?F<Zyo;f9D?b2;
?CHJ,;?Zlq9D?ZtOAGHIFDGpdD^?F@;=\;J,GH;F<^;Y[DOAGHF<IGp@T8 ?CpLDGs]v2U_
v_^~ ]"½4sW[<F<CHGH2;MhKOV@=*?	J?CHCH;C=<J,KIJU?MhOsOA9<KomOyCHGHFD;?	JuOV=\;;Zwx[<=­Åom9D;F q2K[{ZDK[lLDCH;³@A9<;
F[<M>L\;JiKP]=<J,K^;OAOAKJ,OQq2K[RJ,;ZD[<^;@A9<;:^KMh=D[l@,?	@AGHKF@AGHMh;Lqh9D?CHP, ?F<Z;b2;FO,[l=\;JVwxCHGHF<;?	J
OA=];;Zlwx[l=t[<F<Z<;J:^;J,@,?GHFt^GpJ,^[DMhOV@,?F<^;OT8 ?CpLDG®x Ç ;O,OAG^;· J,;s+JI2U_
°®e^g

Ð e1oe1i'ihpi

h

hpf°h¶·µ

tjo·¶³

²´i

b

 ;F<;@AGE^?CHIKJ,Gp@A9DMhOR?	J,;tOA@AK^U9D?OV@AGH^³K=<@AGHMhGHÈ?	@AGEKF|@A;^,9<FDGHg[D;OhGHF@VJ,KZD[<^;ZLq|´WKCHCE?F<Z{é+*Ú
@xo;F@xqq2;?	J,Oj?IK_Q8:9<;qn?	JU;:[<OA;ZGHF?YC?	J,I;b?	JUGH;@xqKP*ZDKMR?GHF<O4GHFD^CH[<Z<GHFDIJ,KL\K@AGH^O:`W9[*?^@AÈGHF
;@?C7_ps2Õ ²%?omJ,;F<^;s ÂD?Cp2;F*?[<;1J x Ç K[lÖeK[DG%es Â*?Cp2;FD?[<;âJ xßï&;CH^U9D?MfLDJ,;s2Õ 
;qIJ,;Á@ xÞ%+;bGHF<;s\2ÕL\;^?[<OA;Y@A9<;qy?	J,;T;?OAqu@AKRGHM=DCH;MR;F@:?F<ZtZDKF<K@:J,;g[<GpJ,;Y?CHI;LDJU?GH^
;=<J,;OAOAGEKFyPKJ:@A9D;TP[DF<^@AGHKF@AKL\;YK=<@AGHMRGHÈ;Z\_
_3`ba2`ba$c f» ­X}+¾ ­~<º¸+A
 d¸<}+9¸ em­XJ
¾ fngº ]f» ­;e]i¿ h
8:9<;fIK2?CKP @A9<;>?CHIKJ,Gp@A9<MNGHO@AKdDF<Z?h=\KGHF@JU;?^,9<GHFDI?®AIKKZ ± b?CH[<;TKP4?RIGpb2;F³PX[<F<^@AGEKFkj
Kb2;J?YOA;?	J,^U9ROV=e?^; G _4ÂGHJ,OV@s?&g[D?F@AGHÈ?	@AGHKFhOV@A;=GHO4Z<;dDF<;ZPXKJj×?F<Zh@A9<;OA;?	J,^U9RGHO4^KF<ZD[<^@A;Z
Kb2;JY?Z<GEOA^J,;@A;TOA[<LDOA;@s G PTKP G _ G PT^KF@,?GHF<O&Õml¶;CH;MR;F@AO_ ¬ Ft=<JU?^@AGH^;s*@A9<;T^?	J,Z<GEFD?CHGp@qKP G P
^?F³L];uoÉ n2ÏÅÑA7É qRÉÊÓ ¬nCE?	J,I;_mÂ<KJ&;<?M=DCH;seGHFK[lJWGHM=DCE;Mh;F@,?	@AGEKFKPQ¸l¹+~Dº»\¸]s  ÚÄ I_8:9[<Os
?^KF@AGHF[<K[<O:Z<KM?GHFyGHOZ<GHO,^J,;@AGHÈ;ZyomGH@A9t?IGpb2;FyJ,;O,KCH[l@AGHKF\_
ï&[lJ,GEF<IR?FGEF<Gp@AGE?CHGEÈ?	@AGHKF=D9D?OA;n?hOAM?CHC"OA[lL*OA;@KP G P>GHOmZ<JU?omFB?	@mJU?FDZ<KMy_:8:9<GEO:OA[lLDO,;@mGHO
^?CHCH;Z³A? r²2:r"plÓ%ÒÏÅ^Í 2Î<_?^,9³;CH;Mh;F@mKP@A9<GHO=\K=D[<C?	@AGHKFGHO^KZD;ZyLqy?OV@VJUGHF<IKP  LDGH@AO_
8:9D;YI;F<;@AGH^f?CHIKJUGp@A9<M Gp@A;JU?	@A;Om@A9<;TPXKCHCHKomGHF<IPXK[lJmOV@A;=DOm[<F@AGEC]?hOAKCH[l@AGHKFyGEO:PK[DF<Z\_
C_ aàûe1i'g#e¶·jfiâ· ð?Fl@A9<;=\K=D[DCE?	@AGHKFh?^^KJ,Z<GEF<IY@AKT@A9D;:b?CH[<;K3P j¶PXKJ;?^U9;CE;Mh;F@jKP G P_
ï&;^GHZD;TGHP"@A9D;YL\;OV@:;CH;Mh;F@m^?FtOA;J,b2;f?O?F?^^;=D@,?	LDCH;fO,KCH[l@AGHK3F lGHP+q2;Os*;lGp@_
Õ._ ´Nhpihjµ¤¶·jfQ·OA;i@A9<;QPX[<F<^@AGHKF j²@AKmZD;dDF<;i?=DJ,KL*?	LDGHCEGp@xqWZ<GHOV@VJ,GHLD[l@AGHKF&Kb2;J @A9<;Q=]K=*[<CE?	@AGHKF\_
×l;CH;^@?=*?GHJ:KP;CH;MR;F@AOmJU?F<Z<KMhCHqu?^^KJ,Z<GEF<I@AK@A9<GHO:=<J,KL*?	LDGECHGp@xqhZDGHOV@VJ,GpL*[l@AGHKF\_
và_ ¢óh n#opjÓ£ g#µ¤¶·jfQ· 'QJ,KZ<[<^;T?FD;o;CH;Mh;F@mPEJUKMµ;?^,9³=*?GpJ:[<O,GHF<IB®AI;F<;@AGH^ ± K=];J?	@AKJ,O_
Øà_ ¢óh n#ie$µhpbdhjf¶2"· ðm;=*CE?^;@A9<;;CH;Mh;F@AO>KP@A9<;ROV@,?	JA@AGHF<I=\K=D[<CE?	@AGHKFLqL\;@V@A;JnF<;ok;CH;w
MR;F@AOm=<J,KZ<[<^;ZyGHFyOV@A;=Bv_
?FqI;F<;@AGH^uK=\;JU?	@AKJ,O& ïY?bGHZ<KJs:2?	JU;u?b?GHC?	LDCH;_´Koj;b2;Js@A9<;uMhKJ,;u^KMhMhKF<Cpq
[<OA;Z ?	J,;y@A9<; qqplÏ7ÒÏÅ&Í 2Î²?F<Z|@A9<;ÃË9Ñ 2?6@6:032mrÉÑhK=\;JU?	@AKJ,O_ 8:9<;yMn[l@,?	@AGHKF K=\;JU?	@AKJ^KF<O,GHOV@AORKP
JU?F<ZDKMhCpt
q sDGH=<=DGHF<IÃOAKMh;LDGH@AOuKP?F;CH;MR;F@tKP>@A9<;=\K=D[<CE?	@AGEKF\_c8:9<;^J,KO,OéwxKb2;JK=\;JU?	@AKJ
^KF<OAGEOV@AOTKPd<J,OV@&JU?F<ZDKMhCpq³^U9<KKOAGHF<It?u=DC?^;om9<;J,;@AKt^[<@Y@A9<;@xoKtOV@VJUGHF<IOYKPLDGp@AOs?FDZ@A9<;F
LD[<GECHZ<GHF<Ih@xoKtF<;oc;CH;MR;F@AOTPJ,KMÁ@A9<GEO&=*?GpJYLq³OAGHMh=DCpqICH[DGHF<I@A9<;J,GHI9@T?F<Zr@A9<;CH;P@&=*?	JA@AOTKP
@A9<;TGEF<Gp@AGE?C*=*?GpJ:KP OV@VJ,GEF<IOYOA;;TÂ GHI[lJU;T2U_
!;[<OA;TL]K@A9BK=\;JU?	@AKJ,O@AKR=DJ,KZD[<^;TF<;o ;CH;Mh;F@AO_mÂ GpJ,OA@s*o;f[<O,;T@A9<;n^J,KOAOéwxKb2;JTK=\;JU?	@AKJ
@AKBI;@?FGHF@A;J,Mh;ZDGE?	@A;ROV@VJUGHF<I_³8m9<;F\s @A9<;uM>[l@,?	@AGEKFÃK=\;JU?	@AKJGHOn[<OA;ZKF@A9<GHOfGEF@A;J,MR;Z<GE?	@A;
OV@VJ,GEF<In@AKhI;@m@A9<;TdDFD?C\OV@VJ,GEF<I_
ÂÃ?Q

y

\§D¨W$us<©|t"§]ª

s|Bv}

PARENTS

«

×vØ9Ø9 v}v

NEW ELEMENTS

Cross−over

k

ÂGEI[lJ,;Y·8:9D;W^JUKOAOéwxKb2;JYK=\;JU?	@AGHKF"_
_3`ba2`vuc »f­X}+¾­~<º¸+we]¿"¸ c ½»]½+ºº¸<ºd¸<}+¸9em­X¾Jfnºg]»f­;e]¿ihyxé~"]+½{z

8:9<;JU;Q?	J,;4MR?FqW=e?	JU?CHCH;C	b2;J,OAGEKF<O"KPI;F<;@AGH^i?CHIKJUGp@A9<MhO·\@A9D;4OV@,?F<ZD?	J,ZT=*?	JU?CHCH;C	b2;J,O,GHKFh&ðmKL\;JA@éw
OAKF\s+ *Us@A9<;4Z<;^KM=\KOAGH@AGHKF&b2;J,OAGHKFR8?F<;O,;s+ *+?F<ZY@A9<;4M?OAOAGpb2;CpqW=*?	JU?CECH;C	b2;J,OAGHKFh8 ?CpLDG7s
v2U_ !;T^,9<KO,;Y@A9<GHOCE?OA@:Mh;@A9<KZ\_Q8:9<;YMR?GEFyGHZ<;?GHO@AKR?CECHK^?	@A;fKF<;Y;CH;Mh;F@mKP@A9<;&=\K=D[<CE?w
@AGHKF³PKJ&;?^,9B=<J,K^;OAOAKJWOAKh@A9*?	@WOV@A;=*OTs\vs]?F<Z³ØR^?F³L\;f;l;^[l@A;Z³GEFt=*?	JU?CECH;C_Â<[lJA@A9<;JUMhKJ,;s
@A9<;tO,;CH;^@AGHKF²OV@A;=OV@A;=zÕGEOh^?	JAJ,GH;Z|K[<@RCHK^?CHCpqsGEF@A9D?	@R;?^,9 GHF<ZDGpbGEZ<[D?CQMR?q²MR?	@A;tKF<CHq
omGp@A9@A9D;YGHF<Z<GpbGHZ<[*?CHO4=DCE?^;ZKFy=<J,K^;OAOAKJ,O:=D9qOAGH^?CECpqR^KF<F<;^@A;Z@AKGp@_i8:9DGHO;F<OA[lJ,;O@A9*?	@:@A9<;
^KMhMn[<F<GH^?	@AGEKFrKb2;J,9<;?ZZ<K;OYFDK@&GEF<^J,;?OA;?OY@A9<;F[<M>L];JYKPi=<J,K^;OAOAKJ,OYGHFD^J,;?OA;O_n8:9<GHOWGHO
@A9<;YJU;?OAKFyom9q^~ ]"½O,9<KomOmCHGHF<;?	J:OV=\;;Zwx[<="_
8:9D;m=*?	J?CHCH;CDI;FD;@AGH^W?CEIKJ,Gp@A9<MkGp@A;JU?	@A;O@A9<;WPXKCHCHKoGHF<ITPXK[lJOV@A;=DO[<F@AGHC*?nOAKCH[<@AGHKFRGHOjPXK[<F<Z\_
C_ aàûe1i'g#e¶·jfi·iQb?CH[D?	@A;ÍX
Î rÒÑVÒÓXÓ%ÉÓD?CHC]@A9<;TGEF<Z<GpbGHZ<[D?CEO_
Õ._ ´Nhpihjµ¤¶·jfQ·Q×;CH;^@ÍX8Î rÒÑVÒÓXÓ%ÉÓ(sl?MhKF<IW@A9<;jF<;GHI9L\KJ,Os@A9<;MR?	@A;jomGp@A9>@A9<;jL\;OV@ ;b?CH[*?	@AGHKF\_
và_ ¢óh n#opjÓ£ g#µ¤¶·jfQ· ðm;=<J,KZ<[<^;ÍXù
Î rÒÑVÒÓÓpÉÓ<omGp@A9@A9<;T^U9<KOA;F³MR?	@A;_
Øà_ ¢óh n#ie$µhpbdhjf¶2· ð;=DCE?^;ÍX
Î rÒÑVÒÓXÓ%ÉÓl@A9<;&=*?	J,;F@AO:Lqu@A9<;YKÖeOA=<J,GHF<I_
K&FB@A9<; ;I2?F<KZ<;s\oj;GHMh=DCH;Mh;F@A;ZB@A9<;n^~ ]"½|KFr?@AKJ,[<O&KPQ=DJ,K^;O,OAKJ,OWom9<;J,;n;?^,9GHF<Z<G%w
bGHZ<[D?C]9D?O:PXK[lJmFD;GHI9L\KJ,OYO,;;TÂ GHI[lJ,; ©2
°®ebd

àû

j /j^|¢¶³#h öAjÔ¶~}#g#f#µ¤¶·jf

Ð e1oe1i'ihpia peig#e¶· f

:8 9<;j;b?CH[D?	@AGHKFPX[<F<^@AGHKF<O[<OA;ZnGHF¼¸l½»e¾e¿u?F<Z¸l¹+~<º+»\¸>?	J,;jb2;JAq>OAGEMhGHCE?	J·]@A9<;q>L\K@A9n^KMh=D[l@A;
@A9<;4d*FD?C=\KOAGp@AGHKFYKP@A9D;i?	J,M¶IGHb2;F>? ?F<9D?	@V@,?F>=*?	@A9>KP?dl;Z>KJ,Z<;J_ ¬ FfK[lJGHMh=DCH;Mh;F@,?	@AGHKF\s
L*?OA;Z¶KF{;=\;J,GH;FD^;so;^,9DKOA;r@AK|[<OA; ?F<9D?	@V@,?F=*?	@A9<OtKPnKJ,Z<;J³ÕÛ
_ KWJUZ<;JÕ|?	=<=\;?	J,;Z
@AKL\;?IKKZÌ^KMh=<J,KMhGHO,;yL\;@xo;;FÌ@A9<;³F[DMfL\;JRKP&CE?F<ZDMR?	JAOhF<;;Z<;ZGHF<^J,;?OA;O?ORKJUZ<;J
Z<;^J,;?O,;OUT?F<Z@A9<;h^KM=*[l@AGHF<I@AGHMR;hF<;^;OAO,?	J,qPXKJf@A9D;hK=<@AGHMhGEÈ?	@AGHKFPX[<F<^@AGHKF<ORGHF<^J,;?OA;On?O
KJ,Z<;JGHF<^J,;?O,;OUU_4×lGHF<^;QK[lJJ,KL\K@+9D?OOAG%f+*s	@A9<;?	J,I[DMh;F@KPl@A9<;^KOV@PX[<F<^@AGEKFTGHFn¼¸l½+»]¾e¿GHO
?Wb2;^@AKJGHF  ,40 ·  ,, > 0, >=ÑÑÑ> 7, >=Ñ=Ñ=Ñ> 0, >=Ñ=Ñ=Ñ	> 70  ?F<Z@A9<;:?	J,I[<MR;F@QKP*@A9<;^KOV@iPX[<F<^@AGEKF[<OA;Z
PXKJ¸l¹+~<º+»\¸GEOm?b2;^@AKJ&GHF 	 	  ,40 ·b Ì> ,, > 0, >=ÑÑÑ> 7, >=Ñ=Ñ=Ñ	> 0, >=Ñ=Ñ=Ñ> 70 om9<;J,
; j^KZ<;Om@A9<;
CE?F<ZDMR?	JA[<OA;ZR?O?TOV@,?	J,@AGHF<IY=\KGHF@iPXKJi@A9<;=e?	@A9\_ ¬ FhL]K@A9^?OA;O@A9<;mPX[<F<^@AGHKFDOi?	J,;mZD;dDF<;ZhKF<CHq
KF?L\K[<FDZ<;ZyOA[lLDO,;@:KP 	  ,40 ?F<Z 	 	  ,40 sDom9<KOA;YCHGEMhGp@AO:?	J,;Yd<;ZLq@A9<;TMh;^U9D?F<GH^?C"OA@AK=DO
KPj@A9<;J,KL\K@>?F<Z@A9D;hMR?lGHM>[DM F[<M>L\;JTKPCE?F<Z<MR?	J,O_` Z<GHO,^J,;@AGHÈ?	@AGHKFrOV@A;=GHOY^,9DKOA;FPXKJ
@A9<;OA;m@xoK>O,[lLDOA;@AO4LqhZ<;dDFDGHF<IW@A9<;:JU;OAKCH[l@AGHKF?	@iom9<GE^,9h;?^U9u;CE;Mh;F@,?	J,qhMhK@AGHKFRGEOiZ<GHO,^J,;@AGHÈ;Z\_
ÂÃz

$vu¨]}Ãs1º1t$v¹ØWw©vLsw©e1}%©l1r


"HOST"

"ROOT"



INDIVIDUALS

Â GHI[lJ,;©·` A@ KJ,[DOomGp@A9OAG%@A;;F=<J,K^;OAOAKJUO_/K&F<;GHF<Z<GHbGHZD[D?CQGHO=DC?^;Z|KF|;?^,9²=DJ,K^;O,OAKJ_
?^,9³GHF<Z<GHbGHZD[D?CD9D?OmPK[lJF<;GHI9L]KJUO_
¬ FrK[lJY^?OA;s;?^U9&ä GHO&Z<GEOA^J,;@AGHÈ;ZBomGp@A9ruLDGH@AO&?FDZ@A9<;F[<M>L\;JYKPiCE?F<ZDMR?	JAOWGEOWCEGHMhGp@A;Z³@AK
ÕÚ I_f8:9[<Os\IGpb2;Fr?LDGHF*?	JAqtOV@VJ,GHFDIRKP:IùÚa#Õ  LDGp@AOs*o;^?Fr^KFb2;JA@TGH@WGHF@AK?Rb2;^@AKJ
7?O?F³?	J,I[<Mh;F@UPXKJm@A9<;Y^KOV@P[<FD^@AGHKFtKP4¼¸l½+»]¾e¿ slKJ¸l¹+~Dº»\¸]sJ,;OV=\;^@AGpb2;Cpq_
?F<9D?	@V@,?Fr=e?	@A9<OT?	J,;;b?CE[D?	@A;ZGHFr?uOAGHM=*CHGpdD;ZtMRKZ<;C KP@A9<;;FbGpJ,KFDMh;F@_n8:9<GHOWMhKZ<;C
GHOKL<@,?GEF<;ZyLqu;F<^CEKOAGHF<I;?^U9;CH;Mh;F@mKP@A9<;YOA^;FD;TGHF@AKR?nL\K[<F<Z<GHFDIfJ,;^@,?FDI[<CE?	J:L\K]_
8:9D;Y;b?CH[*?	@AGHKFtKP ?b2;^@AKJWGEO=\;J,PKJUMh;Zy?OmPXKCHCHKoO·
Â<KJW;?^,
9 &ä GHFr  ,, > 0, >=ÑÑÑ> 7, >=Ñ=Ñ=Ñ> 0, >=Ñ=Ñ=Ñp> 70 
KM=D[<@A;&@A9<;YCHGHMhGH@AOjKF@A9<;YMhK@AGHKFPKJQSVKGHF@ A_
KM=D[<@A&; &äo LquL\K[<F<^GHFDI>KF@A9<;OA;TCHGEMhGp@AO&OA;;>×;^@AGEKFv_°ØU_
m=\ZD?	@A;&@A9D;Y=\KOAGp@AGHKFKP@A9<;&J,KL\K@_
8:9D;TCHGHMhGH@AOKFt@A9<;>MhK@AGHKFKP*SAKGHF@ ?	J,;TKL<@,?GHFD;ZtLqMR;J,IGHF<I@A9D;fCH;I2?C+JU?F<I;OWKPMRK@AGHKF
KP+?CHC*@A9<;WCHGHFlOQ@A9*?	@jMhKb2;&om9<;FYSVKGHF@  MRKb2;OsD?F<Zy?CHCD@A9<;WKLDOV@,?^CH;O_8KnKL<@,?GHFy?>CH;I2?CeJU?F<I;
KP]MhK@AGHKFL\;@oj;;Fu?YCHGHFl?F<Zh?FRKL*OV@,?^CH;so;:^KF<O,GHZ<;JQ@A9<;@ojK>;F<^CHKOAGEF<I&=*?	JU?CHCE;CH;=DGp=\;Z<O ?F<Z
;=<J,;OAOW@A9<;GpJY^KKJ,Z<GHF*?	@A;OYGHFB@A9<;mSVKGHF@YPEJ?Mh;_f8:9<;F"seo;[<OA;?u^CE?OAOAGE^?C4Mh;@A9<KZ³@AKy^KMh=D[l@A;
@A9<;YJ?F<I;& %+KÈ?F<K	(w '";) J,;Ès + *U_
¬ FtK[lJ:=e?	JU?CHCH;C\GHMh=DCH;Mh;F@,?	@AGHKF\so;TZ<GHOV@VJUGpLD[l@A;Zu@A9<;YI;KMh;@VJUGH^f^KM=*[l@,?	@AGHKF<Om?MRKF<IhOA;bw
;JU?C]=<JUK^;OAO,KJ,O_Q?^U9y=<J,K^;OAOAKJGHOZ<;Z<GH^?	@A;Zy@AK@A9D;Y^KM=D[l@,?	@AGHKFKP?OAGHFDICH;W@xq=];&KPGHF@A;JU?^w
@AGHKF\_
°®e¡ 

ø ún

Ð e1oe1i'ihpi Bb

j

ihjbdhpf¶e¶· f

j^|¢¶³#hß²ço©·eã£Êf°hõÔDöÓih5u

tjo·¶³

²´i

b

Â HG FD?CHCHqsl@A9<;f`J,GE?Z<FD;¯°Om^CH;o ?CHIKJ,Gp@A9<M GHOmGHMh=DCH;Mh;F@A;ZtGHFy=e?	JU?CHCH;C\oGp@A9y@A9lJ,;;>CH;b2;CHOKP=e?	JU?C%w
CH;CHGEOAMy_
s_ K&LbGHK[<OACHqs?d<J,OA@RCH;b2;C&KP&=*?	JU?CHCE;CHGHÈ?	@AGHKF²^?F L\;tKL<@,?GEF<;ZÌLq|J,[<FDF<GHF<I¼¸l½+»]¾*¿?F<Z
¸<¹+~<º»\¸Ì?	@@A9<;O,?MR;@AGHMR;³KF @xoKOA;@AOyKPY=<JUK^;OAO,KJ,O_! 9DGHCH;B¼¸l½+»]¾e¿GHOu^,9<;^,GEF<I
ÂÃ

y

\§D¨W$us<©|t"§]ª

s|Bv}

«

×vØ9Ø9 v}v

o9<;@A9<;Jh?³=*?	@A9;GHOA@AO>L\;@oj;;F@A9<;CE?OA@>=DC?^;ZC?F<Z<MR?	JA?FDZÃ@A9D;IK2?Csj¸l¹+~<º+»\¸ÃGHO
I;FD;JU?	@AGHF<I@A9D;TF<;@:CE?F<Z<MR?	J,*_
Õ_m8m9<;>O,;^KF<Z³CE;b2;CKPQ=*?	JU?CHCH;CEGHOAMµ^KJAJU;OV=\KF<Z<O:@AK?=*?	JU?CHCE;C"GHM=DCE;Mh;F@,?	@AGEKF³KP4L\K@A9BI;w
FD;@AGH^y?CHIKJ,Gp@A9<MROn;Mh=DCHKq2;Z²Lq|¼¸l½+»]¾e¿ ?FDZ²¸l¹+~<º+»\¸@AK@VJ,;?	@h@A9<;GHJnJU;OV=\;^@AGpb2;K=<@AG%w
MRGHÈ?	@AGHKFy=<JUKLDCH;MhO_
v_m8m9<;&@A9<GpJ,ZCH;b2;C+^KJAJ,;OV=\KF<Z<O@AKh?=*?	JU?CHCH;CEGHÈ?	@AGHKFKP+@A9D;Y^KCHCHGHOAGEKFu^U9<;^AGHF<IRP[<FD^@AGHKFt?F<Z
J?F<I;T^KM=D[<@,?	@AGHKF\_
!;Y^KM=*CH;@A;Zy?>PX[<CHC*GHM=DCE;Mh;F@,?	@AGEKFKP\@A9D;OA;W@A9lJ,;;&CH;b2;CHOKFy? ;I2?F<KZ<;WomGp@A9³Õ
 e]J ©J©
@VJU?F<OA=D[l@A;J,O_>ÂGEI[lJ,;uJ,;=<J,;O,;F@AOTK[<JY=*?	JU?CHCH;CGHM=*CH;Mh;F@,?	@AGHKFKPQ@A9<;`J,GE?Z<FD;¯°OW^CE;oc?CHIK	w
J,Gp@A9DMµ?F<ZtÂ GHI[lJ,;nÕhOA9<KoO:9<Ko¶oj;T9*?b2;T;M>L\;Z<Z<;Zy@A9<GEO:?	J,^,9<GH@A;^@A[lJ,;TGHF@AKK[lJm;=\;J,GHMh;F@,?C
OA;@A[l=+_` ¾*½+|OVqOV@A;
M xß½"6¾ e\z&GEOY[<OA;Z@AKtMhKZ<;C @A9<;O,^;F<;omGp@A9@A9<;@ojKtJ,KL\K@AO_8:9<;nJ,KL\K@AO
?	J,;Y[<FDZ<;J@A9<;Y^KF@VJUKC"K>P ½+5º ­i´&?qo?	J,Z"s ïY?F<;OA9<Mh;FDZ\ãs xa´W?q?	@AGs"2U_Â GpJ,OV@sD?OAGEM=DCHGpd*;Z
I;KMh;@VJ,GE^MhKZD;CKPi@A9<;>O,^;F<;GHO&Z<KomFDCHK2?Z<;ZGHF@AKR@A9<;Mh;MRKJAqKPQ@A9D;>@VJ?F<OV=D[l@A;JUO_Y8:9<;F\s"?
×GHCEGH^KF  JU?	=D9<GE^O ojKJAOV@,?	@AGHKFRojKJ,Oi?Oj?YICHKL*?Cl^KF@VJ,KCHCE;J?F<ZhCHKK=DOQKb2;Ji@A9<;mPKCHCEKomGHFDIWOA@A;=DO·

_  ;F<;JU?	@A;>?FDZt;;^[<@A;>?CH;I2?C\J?F<Z<KMµMhK@AGEKFtPKJmJ,KL\K@ Ç _
Õ_W×l;F<Z@A9<;F<;oÄ^KFld*I[lJU?	@AGHKFrKPJ,KL\K@ Ç @AKy@A9<;
^KF<dDI[lJU?	@AGHKFPKJ:JUKL]K@:`>_
v_  ;@m@A9<;&=DC?F<F<;Z=*?	@A9tPXKJ:J,KL\K@:` PJ,KM @A9<;

;I2?FDKZ<;?OYoj;CECQ?OY@A9<;Z<;OAGHJ,;ZBdDFD?C
;I2?F<KZ<;f?F<Zt;l;^[l@A;>Gp@_

Ø_ !?GH@mPKJ&?nJU?F<Z<KMµ@AGHMh;T?F<ZtOA@AK=tJ,KL\K@:`f_
Ú_  K@AKy_
8:9DGHOYOA;g[<;F<^;R?CHCEKomOT[DOY@AKt@A;OV@nK[lJ>?CHIKJUGp@A9<MÙ;@A;F<OAGpb2;CHqBGHFJ,;?CQOAGp@A[*?	@AGHKF<OYLqB9*?bGHF<I
@AKBZ<;?CioGp@A9MR?FqZ<GHÖe;J,;F@f;FbGHJ,KF<Mh;F@AO_$KYPj^K[<J,OA;s4@A9<;uMhKOV@nGHF@A;JU;OV@AGHF<IdDI[lJ,;Roj;u^?F
KL<@,?GHF³PEJUKM @A9<GEOm;=];JUGHMh;F@mGHO:@A9D;fMh;?F³@AGHMh;>F<;^;OAO,?	JAqy@AKu^KM=D[<@A;fKF<;f=*?	@A9³IGHb2;FB?RF<;o
;FbGpJUKF<Mh;F@_QÂ<KJ:@A9<GHO;=\;J,GHMh;F@,?C]OA;@A[l=@A9<GHOMh;?Fy@AGEMh;GEO&_°ØÕfOA;^KF<Z<O_QOAGEF<If@A9D;YO,?Mh;
?	J,^U9<Gp@A;^@A[lJ,;WomGH@A9MhKJU;W[<=lw7@AK	wxZD?	@A;W=<J,K^;OAOAKJ,O& e]J ©J©J©2joK[<CHZJ,;Z<[<^;@A9<GHO@AGHMh;Lqu?>PX?^@AKJmKP
@A;F\_i8m9<;&O,?Mh;T^KM=*[l@,?	@AGHKFtKF?O,GHF<ICH;W=<J,K^;OAOAKJ>x¼~½+»]ú
¾ íjoK[<CHZ@,?	2;Y@A9<J,;;Y@AGHMh;OCEKF<I;J
@A9D?Fy@A9D;T^[lJAJ,;F@:GHM=*CH;Mh;F@,?	@AGHKF\_
Î 6+p q"qhÒ:Ñ ¬ É mÒ rÉÒ2Ë Í7É roÉ D2mp8Ñ qhÒÍXÎ5Ð 2Ò2oÓ 47¬8rD3Ñ 2rÍXÎÐy<Ï ÒÏjÍÅÏikÍ 6YÍ6Î É,É Ar²2?6@6&Í 4Ó%
É 4ÍÅ<Ï 
<Ï 
É WÑÍÅÒ Îe9É  6YËÓ%É  ÒÓ 5Ð 2ÑÍÅ<Ï 5q
hÏ 2Ár*Ó%ÒÎr@Ë 2ÓXÓ(kÍ 6U&Í 2ãÎ 0ÑVÉUéÉ rÒ<Ï +6*72ÑYÒhÑVÉ,ÒÓ\9Ñ 254Ì22Ï 4ÍÅ<Ï qhÒãÎ ¬f+³ÍXÎ
Ò ¬Î*Ò qÍËÑVÉ,ÒÓ$bÍ 6ÏÅÍÅËRÉ9Î rÍX9Ñ 2ãÎ qRÉÎDÏÅ_

 . ¿1 0 ä  5là671 0¢¡ ¿1 0 á¤â6Þj5<á2671 0 gà £¤V6¥Fäl5  á26  gà £+ã 0 3  âà?¼  äjá26 [¤

à

`WOMh;F@AGEKF<;Z|GHF@A9<; ¬ F@VJ,KZ<[<^@AGEKF\s4@A9<;y`J,GE?Z<F<;¯°O^CH;o ?CEIKJ,Gp@A9<MÔ9D?O@ojKrM?GHFg[D?CEGp@AGH;O·
ÉÅÊÌËÍÉÎ*=Ë ¬sD?F<Z³ÐÉÎ]ÉÑVÒÓ(ÍÅÏ^¬_ %;@m[<OslGHFt^KFD^CH[<OAGHKF"s;=DCE?GEF?FDZtZ<GHOA^[DOAO@A9<;OA;Y@ojKRg[D?CEGp@AGH;O_
Â+ì Ã



$vu¨]}Ãs1º1t$v¹ØWw©vLsw©e1}%©l1r

¦+§ ¨ ©7ª;«v¬-­ ®o¯±° ¬³²6©´° µ7¶-§ ¨ ·¹¸;º
ÌLÍ<ÎÀÏÐ7Ñ
Õ+Ö(×Ø Ù Ñ´Ð

Ò ÐvÍvÑ´ÓÔ
»<¼½

»<¼¾½

¿ ©7«vµ-¬¯±¶vº Á;Ãv·¹©7· ¨ ¶v«

¿ ©7«vµ7¬¯À¶-ºÂÁ;Ãv·¹©7· ¨ ¶-«

ÚÂÛ

Û Í;ÜÝÜgÍ
ÞÎ³ß Ú8à

Û Í;ÜgÜgÍ
ÞÎ³ß Ú8à

ÞÎ³ß á

Ä Å³ÆÇÈÇ Ä(É

Ä Å³Æ´ÇËÊ

ÞÎß á

Ä ÅÀÆ´ÇËÊ

Ä Å³ÆÇÈÇ Ä(É
× Î³ß Ívâ

× Î³ß Ívâ

× Î³ß Ó

× Î³ß Ó

Â GHI[lJU;·i`­=*?	JU?CHCH;C]GHMh=DCH;Mh;F@,?	@AGHKFyKP@A9<;T`J,GE?Z<FD;¯°O^CH;o?CHIKJ,GH@A9<M
Â+ìì

y

\§D¨W$us<©|t"§]ª

×vØ9Ø9 v}v

Robot II

Robot I

68030

68030
KALI

«

s|Bv}

Bus VME

KALI

Bus VME
(VxWorks)

(VxWorks)

Sun 4
(Unix)

(SEARCH)

Ethernet

server
VxWorks

GENETIC ALGORITHM

Sun 3
(Unix)

GENETIC ALGORITHM
(EXPLORE)

server
Mega−Node
Mega−Node
128 Transputers

ACT
CAD SYSTEM

Silicon Graphics
(Unix)

Â GHI[<J,;Õ·i8:9<;Y;=\;J,GHMh;F@,?C\OA;@A[l=
þfe^g

/|(jobde1f#µh

Ð hjo

 KM=e?	J,GHF<I@A9D;Q=\;J,PXKJ,MR?F<^;KPl@A9<GHO+GHFDZTKPD?CHIKJ,GH@A9<M¶GHO ?b2;J,qfZ<;CHGH^?	@A;OA[lLSA;^@_1';JUPKJ,M?F<^;
MR?qBL\;h?yM?	@V@A;JnKP^KM=D[<@AGHF<I@AGHMh;s;ÖeKJ,@AOfF<;;Z<;Z@AKt=<J,KIJ?MysKJn;?OA;hKP?	=<=DCHGE^?	@AGHKF@AK
Z<GpÖ];J,;F@=<J,KLDCH;MROOA;;B×;^@AGHKFÌÚ_$ÕU_|Qb?CH[D?	@AGHFDI@A9<;u=\;J,PXKJ,MR?F<^;GHF@A;J,MROKP^KM=*[l@AGHF<I
@AGHMh;YGEOb2;JAqyZ<GpR^[<CH@PXKJmKF<;YPX[<F<Z*?Mh;F@,?C?F<Z@A9lJ,;;Y=DJU?^@AGH^?C\J,;?O,KF<O·
Â+ì:



$vu¨]}Ãs1º1t$v¹ØWw©vLsw©e1}%©l1r

_m8m9<;tPX[<F<ZD?Mh;F@,?C:JU;?OAKF GEOsKF<^;³?I2?GHF"s@A9<;³}"~wx^KM=DCH;@A;F<;O,ORKP&@A9<;=*?	@A9Ì=*CE?F<F<GHFDI
=DJ,KLDCH;My_`WOfZ<;^;=<@AGHb2;R^?OA;OnMR?q?CHo?qO>L\;hZ<;OAGHIFD;Z\s+@A9<;KF<CpqB=\;J,PKJUMR?F<^;J,;O,[<Cp@AO
KFD;TMR?qJ,;?O,KFD?	LDCpqu=<J,;OA;F@m?	J,;f?CHo?qOOV=\;^GpdD^_
Õ_m8m9<;&@A9lJ,;;Y=DJU?^@AGH^?C\J,;?O,KF<Om?	J,;·
7?2«
 K&LbGHK[<OACHqs@A9<;id<J,OV@+J,;g[DGpJ,;Mh;F@+PXKJOA[D^,9?:^KM=*?	JUGHOAKFnGHO"@A9D?	@ Z<GpÖ];J,;F@?CHIKJ,GH@A9<MhO
JU[<FYKFT@A9<;iO,?Mh;4MR?^U9<GHF<;O+omGp@A9&@A9<;QOU?Mh;i?b?GHCE?	L*CH; Mh;MhKJAq_ 8:9<GHO\M?qYOA;;M¶O,GHM=DCH;
L*[l@YGp@WGEOT?M?GHFZ<GpR^[<CH@xqGHFK[lJY^?OA;hL];^?[DOA;K[lJf?CHIKJ,Gp@A9DM9*?O&L];;FZ<;O,GHIF<;Z
@AKJU[<F³KFBJU?	@A9D;JTOV=\;^GpdD^TGHF<ZDOKPMR?^,9<GEF<;Os\FD?Mh;Cpqs"M?OAOAGpb2;Cpqy=e?	JU?CHCH;CKF<;O_ ¬ @
^K[DCHZr?CHOAKL];nGHM=*CH;Mh;F@A;Z³KFF<KFw7=e?	JU?CHCH;CMR?^,9<GEF<;Os]LD[l@W@A9<;FGp@&MR?qBCHKOA;>=*?	JA@
KPjGp@AO&GHF@A;J,;OV@_n`cPÅ?GpJY^KM=*?	J,GHO,KFojK[<CEZ³L\;>@AKy^KM=*?	J,;n@A9<;h?CEIKJ,Gp@A9<MhO&KFL\K@A9
@q=\;OKPMR?^U9<GHF<;O_i8:9<GHOjoK[<CHZyGHMh=DCpqh=<JUKIJU?MhMhGHFDIK@A9<;J?CHIKJ,GH@A9<MhOGHFy=e?	JU?CHCH;Cs
o9<GH^,9yGEOb2;JAqyZ<GpR^[DCp@jGEF=<JU?^@AGH^;_
ÅLe ?FqÌF<KomF =*?	@A9 =DC?F<F<GHF<IÃ?CHIKJ,Gp@A9<MROdDJ,OV@^KMh=D[l@A;B@A9<;^KFldDI[lJ?	@AGHKF OA=*?^;
KJY?F³?	=D=<J,KlGHMR?	@AGEKFtKP Gp@UKÖ*wxCHGHF<;s*?FDZt@A9<;F³;R^GH;F@ACpqyOAKCpb2;Y@A9<;f=*?	@A9t=*CE?F<F<GHFDI
=DJ,KLDCH;MKFwxCHGHFD;_&`WOWoj;O,?oTs"GHFBKJ,Z<;J&@AKZ<;?ComGp@A9?uZlqF*?MhGH^f;FbGpJ,KF<Mh;F@s]@A9<;
`J,GE?ZDF<;¯°O:^CH;o?CEIKJ,Gp@A9<Mµ?Z<K=D@AOm?^KM=DCE;@A;CpquZDGpÖe;JU;F@m?	=<=DJ,K2?^,9\_
^ÂDKJT=<JU?^@AGH^?C JU;?OAKF<Os"MR?Fq@A;OA@Y=<J,KLDCH;MROW?	J,;n@AKqB=DJ,KLDCH;MhOnxÕ4s"PX;oÄKLDOV@,?^CE;Os
PX;o PÅ?^;OsOAGHMn[<CE?	@A;ZJ,KL\K@AOU?F<Z@A9D;=];JUPKJ,M?F<^;uJ,;OA[<Cp@AO[DOAGHF<IB@A9<;OA;GHF<ZDOnKP
=DJ,KLDCH;MhO?	J,;mb2;J,qhZ<GpR^[<CH@4@AK>I;F<;J?CHGHÈ;:@AKfJ,;?CHGHOA@AGH^:GHF<ZD[<OV@VJ,GE?C=<JUKLDCH;MhO7v4s@A;F<O
KP KLDOA@,?^CH;OsD9[<F<ZlJU;Z<OKPPÅ?^;Os<JU;?C\J,KL\K@AOUU_
KFDOAGHZ<;J,GEF<Ij?CEC@A9<;OA;4JU;?OAKF<Os	oj;Q@A;OV@A;Z>K[<J?CHIKJ,Gp@A9DM{Lq&GHM=*CH;Mh;F@AGHF<I?J,;?CHGEOV@AGH^J,KL\K@AGH^
?	=<=DCEGH^?	@AGHKF@AK³@A9<;Rb2;JAq;F<Z\_³8KB?^,9<GH;b2;u@A9<GEOfIK2?Cs4o;u?O,OA;MfL*CH;ZÃ?³^KM=DCH;;=\;J,GHMh;F@,?C
OA;@A[l=zGHF<^CE[<Z<GHF<IBOAG%²Z<GHÖe;J,;F@RMR?^U9<GHF<;OBéY
 h"¸ ]+½+}++¸\sú
Õ IJ ©Jv ©s&ÕÃ¼ ã"}¶Øs?F<Zr=¼ ­X+º ­X¾]}
]»]½+~<Ó¿ ­Å¾e¼Usm@ojK|Mh;^U9D?F<GH^?CY?	J,MROsW?F<ZzJU[<F<F<GHFDIOA;b2;F{Z<GpÖ];J,;F@u^KK=\;JU?	@AGpb2;=<JUKIJU?MhOxÕ
½++º ­xs\f½"^¾ es*
Õ µ3¹ äR+3»  ¼se>~½+»]¹4sD?FDZf`mJUGE?Z<F<;¯°O:^CE;o?CHIKJ,Gp@A9DMU_
K&[<J^U9D?CHCH;FDI;o?O@AKL\;W?	L*CH;m@AKO,KCpb2;W@A9<;&=*?	@A9u=DCE?F<FDGHF<IY=<JUKLDCH;M PX?OA@;FDK[<I9@AKZlJ,Gpb2;Y?
J,;?CeOAG%Rh?	J,MkGHFu?fZlqFD?MhGE^:;FbGpJ,KFDMh;F@_48:9D;m`J,GE?Z<F<;¯°O^CH;o{?CHIKJ,Gp@A9<MÆGHF<Z<;;Zu?^,9<GE;b2;Z
@A9<GHOIK2?C"GEFK[lJ:;=\;J,GHMh;F@AOjom9<;J,;W@A9<;&;FbGHJ,KF<Mh;F@GHO^KM=\KOA;ZyKP"d<b2;&d<;ZKLDOV@,?^CE;Om?F<Z
?OAGp?	J,MµMhKbGEF<IGHF<Z<;=\;F<ZD;F@ACpq_
!;&?	J,;:F<K@?o?	J,;WKP]?FqhK@A9<;JMh;@A9<KZ<OQ^?	=*?	L*CH;:KP\OA[<^U9h=\;J,PXKJ,MR?F<^;_48KY@A9<;mL];OA@iKP]K[lJ
F<KomCE;Z<I;s^[lJAJU;F@ACpqnGHM=DCE;Mh;F@A;Zn=DC?F<F<;J,OojK[DCHZ@,?	2;m?&F[<MfL\;J4KPeOA;^KF<Z<OÅ@A;F* @AK&=DCE?^;:?
OA;@KP+C?F<Z<MR?	JAOjKFt?Õ;l?M=*CH;&PKJ:?nJ,KL\K@jomGp@A9ud<b2;Yt& ªf?bJ?	G\;@:?C_ps]J I2U¯_ ïW;OA=DGp@A;
@A9<;YPÅ?^@:@A9D?	@dDFDZ<GHF<I?I;F<;JU?C\=*[lJA=\KOA;=DCE?F<F<GEF<If@A;^U9<F<GHg[<;&PXKJ:J,;?C\GHF<ZD[<OV@VJ,GE?C]?	=<=DCEGH^?	@AGHKFGHO
?nb2;JAqyZ<Gp^[<Cp@i=DJ,KLDCH;Myso;YL\;CHGH;b2;W@A9D?	@@A9<;Y`J,GE?ZDF<;¯°O^CH;o?CHIKJUGp@A9<M =<J,KbGEZ<;O?Ft;Öe;^@AGHb2;
?	=<=<JUK2?^,9t@AKROA[<^,9t=<J,KLDCH;MRO_
8:9D;F[<M>L];JKPmJU?F<I;^KM=D[l@,?	@AGEKF<OPKJh? ?F<9D?	@V@,?F|MhK@AGEKF|KPmKJ,Z<;JyGHO Håæ@çLå Üs,
om9<;JU.; ,GHOm@A9<;TF[<MfL\;JWKPPÅ?^;O®s Ø@A9<;>F[DMfL\;JmKPQ+*s*?F<Z H ?R^KF<OV@,?F@PÅ?^@AKJs]Z<;=\0;F<Z<GHF<I
KF@A9<;F[<M>L\;JKP\=*?	J,@AO[<O,;Zh@AKMhKZ<;C<@A9<;mJ,KL\K@_ KWLbGHK[DOACpqsO,[<^,9?fF[<M>L\;JKP\PÅ?^;OMR?qhL\;
?OA;b2;JU;TZ<GpR^[DCp@xquPKJ:@A9D;TGHM=DCE;Mh;F@,?	@AGEKFyKP+@A9<;f`mJ,G?Z<F<;¯°O^CH;o ?CHIKJ,Gp@A9<M ZD;OA^J,GpL\;ZOAKhPÅ?	J_
8KOV=\;;Zu[<=y@A9<;Y^KM=D[l@,?	@AGEKFoj;Y[<O,;&?F[<M>L\;JKPI;KMh;@VJ,GE^&dDCp@A;J,Oj@A9D?	@J,;ZD[<^;&@A9<;&F[DMfL\;J
KP=*?GpJ,OKP;F@AGp@AGH;O@AKL\;T?FD?CHqÈ;Z\_
´WKo;b2;Js+Gp@Wo?O=\KOAO,GpLDCH;Y@AKPXKCHCHKo@ojKuJ,;OA;?	JU^,9@VJU?^,OYGHFB^KM>LDGHFD?	@AGHKF"_WÂ GpJ,OA@s*o;^K[<CHZ
[<OA;R^KCHCHGHOAGEKFr^,9<;^,GHFDIMh;@A9<KZ<Of@A9D?	@n?CHCEKoÆ?^^;OAOn@AK@A9<;h=*?GHJ,OTGHF^KCECHGHOAGHKFrGEF?yCHKI2?	J,GH@A9<MhGH^
Â+ì Â

y

\§D¨W$us<©|t"§]ª

s|Bv}

«

×vØ9Ø9 v}v

@AGHMh; Â*?b2;JÅSAKF/x8K[<J,FD?OAOAK[DZ\s+*U_Ã×;^KF<Z\s o;u^K[DCHZ=DJ,;OA;JAb2;=*?	JA@nKP@A9<;uCE?F<Z<MR?	J,
IJU?	=D9tom9<;F@A9<;T;FbGpJ,KF<Mh;F@:GHO^U9D?F<IGHF<IÀ ^=%;?Fyx ?ÈKF\s+JI2U_
þfebd h

hjf#hjoe1i'·¶

³

:8 9<;W`J,GE?Z<F<;¯°O^CH;o?CHIKJUGp@A9<M GHOI;F<;JU?C\GHF@A9<;&OA;F<O,;@A9*?	@GH@M?qRL\;W[<OA;ZPXKJ:F[<MR;J,K[<O?F<Z
b2;JAqtZ<GHÖe;J,;F@W?	=D=DCHGH^?	@AGHKFDO:GHFyJ,KL\K@AGH^O_ Ç ?O,GH^?CHCpqs*@A9<;fMR?GEFt@A9<GHFDI@A9D?	@FD;;Z<O:@AKL\;T^,9D?FDI;Z
GHFy@A9D;f?CHIKJ,Gp@A9DM GHO@A9D;TZ<GHOV@,?FD^; Ðu[<OA;ZtGHFt@A9<;T;b?CH[D?	@AGHKF³P[<FD^@AGHKF<O:KP@A9<;Y@ojKuK=<@AGHMRGHÈ?	@AGHKF
=<J,KL*CH;MhO_
×;b2;J?C<=DCE?FDF<;J,O 9D?b2;mL\;;FhGHM=DCE;Mh;F@A;ZGEF@A9<GHO o?qe·i?&dDF<;MRK@AGHKF=DCE?FDF<;J:& ï&;mCEÁ? ðKO,?s
%?[DIGH;Js x B&?SV;J?sJ I2UsQ@xoKMhK@AGHKFÃ=DCE?F<F<;JUOTPKJ9<KCHKFDKMhGH^R?F<ZÃF<KFwx9<KCEKF<KMhGH^hMRKLDGHCH;
J,KL\K@AOmx×l^,9<;[<;JéxÂlJU?GH^U9D?	J,Z\s*+*UsD?YJ,;KJ,GE;F@,?	@AGHKF=DCE?FDF<;JiPXKJj?F?	JA@AGH^[<CE?	@A;Z9D?F<Z"  [l=<@,?s
2ÚUsj?=DCE?FDF<;JfPXKJIJ?OV=DGHF<I³?F<ZJU;IJU?OV=DGHFDI`W9[D?^@AÈGEF\s  [l=<@,?ws x ?È;Js:2Usj?F<Z?
=DCE?FDF<;JhPKJ?rJ,KL\K@AGH^³?	J,M =DCE?^;Z GHF|@A9<;OV@A;?M I;FD;JU?	@AKJyKP&?F[D^CH;?	Jh=DCE?F@ =^ %+;?¦
F x
?ÈKF\s:J I2U_`WZD?	=<@AGHFDIt@A9<;y?CHIKJ,GH@A9<MÀ@AK?BF<;o ?	=<=DCHGH^?	@AGEKFÃGHOs@A9D;J,;PKJU;si^CH;?	J,Cpq?³b2;JAq
;?OVq@,?OV*_Â<KJmGHF<OA@,?F<^;s@A9D;&?	=D=DCHGH^?	@AGHKF@AK=*?	@A9u=DCE?FDF<GHF<ITPXKJ@A9<;&F<KFwx9DKCHKF<KMhGH^m@VJU?GHCH;Jo?O
Z<;b2;CHK=\;ZtGEF@A9lJ,;;YZD?qO_
8:9D;i`J,GE?Z<F<;¯°O^CH;o|?CHIKJ,Gp@A9<M­GHO?CHOAKmI;FD;JU?CGHFT@A9<;OA;F<OA;@A9D?	@ Gp@M?qTL\;Q[<O,;Z>PXKJ ?FqTGHF<Z
KP =*?	@A9=DCE?F<F<GEF<In=<J,KLDCH;M GHF?h^KF@AGHF[<K[<OOV=*?^;s]GHFydD;CHZDO:K@A9<;JW@A9D?FtJ,KL\K@AGH^O_`WCp@A9<K[DI9tGp@
MR?qfL\;iOA[<R^GH;F@@AK&^,9*?F<I;j@A9<;Z<GHOV@,?F<^;P[DF<^@AGHK"F Ðls2KF<;MR?qn?CHOAKW^KF<OAGEZ<;J^U9D?F<IGHFDIm@A9<;jPXKJ,M
KPQ@A9D;P[<FD^@AGHKF Ðls"KJf;b2;F@A9<;F*?	@A[lJ,;KPQ@A9<;O,;?	J,^,9<;ZrOA=*?^;O_Â<KJfGHF<OA@,?F<^;s\@A9<;^KF<^;=<@TKP
KLDOV@,?^CE;O4MR?qTL\;J,;^KF<OAGEZ<;J,;Z\_ ¬ F<OA@A;?ZnKPQ®A9D?	J,Z ± KLDOV@,?^CH;Os2KF<;^K[DCHZfJU;=DCE?^;@A9<;M­LqfÈKFD;O
KPQ^KF<OA@VJU?GHF@AO_ ¬ F³@A9D?	@Y^?OA;s\@A9<;>=*?	@A9B=DCE?F<F<GEF<I=<J,KLDCE;M Z<K;O&F<K@W^KFDOAGHOV@WKP4dDF<Z<GEF<IR?R=*?	@A9
omGp@A9DK[l@^KCHCEGHOAGHKF<OmLD[l@WJU?	@A9<;J&dDF<ZDGHF<IR?=*?	@A9BL\;OV@&O,?	@AGHOAPqGEF<Ih@A9<;Z<GHÖe;J,;F@&^KF<OV@VJU?GHF@AO_>×[D^,9
?>=DCE?F<FD;Jj9D?OL\;;FZ<;b2;CHK=\;ZyPXKJ:?FD?b?C\?	=<=DCHGH^?	@AGEKFo9<;J,;@A9<;W=<J,KLDCH;Mko?O@AKdDF<Z?>=*?	@A9
PXKJ?L\K2?	@omGp@A9b?	J,GHK[<O^KFDOV@VJU?GHF@AO:KFt@A9D;&@VJU?SV;^@AKJ,q_8:9<GEOK=];FDOF[<MR;J,K[<O=\;J,OV=\;^@AGpb2;OKP
?	=<=DCEGH^?	@AGHKF<O PXKJ?	=<=DCpqGHF<I@A9<;`J,GE?Z<FD;¯°O4^CH;o ?CHIKJ,GH@A9<MaGHF?&L<J,K2?ZD;J4dD;CHZ@A9D?F=D[<J,;jJ,KL\K@AGH^O_
?¨ j²uóihU£otbdhpf¶Ô

²çµ Nf

8:9<;n?[l@A9<KJ,O&?	J,;>IJ,;?	@ACpqGHFDZ<;L<@A;Zy@AKïWJ_àªf?M?C  [l=D@,?RPJ,KM×lGHMhKFÂ<JU?OA;JYFDGpb2;J,OAGp@qom9<K
^?	J,;PX[<CHCpqfJ,;?Z@A9<;=*?	=\;Ji?F<ZO,[<II;OV@A;Zb?CH[D?	LDCE;j^KJ,J,;^@AGHKF<O4@A9*?	@QIJ,;?	@ACpqGHM=<J,Kb2;@A9<;g[D?CHGp@q
KP@A9<;&dDFD?C]=e?	=];J_
8:9DGHOojKJ,9*?OL\;;FtMR?Z<;Y=\KOAO,GpLDCH;Lqew· %;>;F@VJ,8; B&?	@AGHKFD?C+ZD;YCE"? ðm;^U9<;J,^,9D;n×^GH;F@AGpdDg[<;
ÂlJU?FD^;Us]KF<O,;SV
K B&?^GHKFD?C+Z<;fGH;F<^G?nqu8;^F<KCHKIGE?t ;lGH^K:?FDZt¸D¼~<f» ­<erÕs 'jÕÚÕ7¸<¸D¾]U_
è  ½  â D 0 ä  à
`W9[D?^@AÈGEF\sé<_ps  [l=D@,?ssª_psÁx

? È;JsYm_&é2U_ ?FDGp=D[<CE?	@AGEKF'CE?F<F<GHFDIPKJ«ð;Z<[<F<Z*?F@
ðKL\K@AO· ` 'QJ?^@AGH^?Cf`=<=<J,K2?^U9\_ëê\lÉ  Î*ÏxÉÑÎ*ÒÏÅÍ&2Î*ÒÓì 2mpÑÎ*ÒÓ2íîé254Ì22ÏÅÍÅË=6wî:É:6ÉAÒÑVËs
ï9ð*(*Us®*vòñ *	Ø5*_

`W9[D?^@AÈGEF\s{é<_ps ?È;Js4:_ps Ç ;O,OAG^;· J,;sâ'_ps1x 8 ?CpLDG7s:_Qé2ÕU_tWOAGHFDI  ;F<;@AGH^`CHIKJUGp@A9<MhOYPXKJ
ðKL\K@ K@AGHKF»'CE?F<F<GEF<I_ ¬ FôóÑ92ËÉ,ÉoÍÎÐJ6s2@:Ï<É
ïõõ8ö÷pÑ92:rÉAÒÎJøâ2Î ÉÑAÉÎ*ËÉs2ÎùWÑÏÅÍ úËÍÅÒÓ
 Î*ÏxÉÓXÓ(ÍpÐÉÎ*ËUÉs<=<="ã_ I+*ò ñ²I+*Ú_
Â+ì@ý



$vu¨]}Ãs1º1t$v¹ØWw©vLsw©e1}%©l1r

Ç ?	JAJU?g[D?F<Z\sLél_psÓx %?	@AKMfL\;siél_éJ©2U_Y` KF@A;h?	J,CHK`CHIKJUGp@A9<M PXKJÁ' ?	@A9$'CE?F<F<GHFDIomGp@A9
?F
q ïW;IJU;;OjKP]ÂlJU;;Z<KMy_ ¬ F~óÑ92ËUÉUÉoÍXÎÐJ6.2@WÏ<Éïõõû  ÷¤÷T÷  ÎDÏxÉÑÎ*ÒÏÅÍ&2Î*Ò2Ó{øâ2Î ÉÑVÉÎ*ËUÉ
2k
Î î 254Ì2ÏÅÍ7Ë 6ÒÎ^plÏ2qhÒÏÅÍ&2Î<s*=<="_\p*Õ ñDp*p*_
Ç ;OAOA&G ;· J,;8s '_psT8 ?CpLDGs&:_psY`W9[*?^@AÈGHF\s él_p8s x ?È;JsTm_féJI2U_NWF`WCHIKJ,Gp@A9<MR;  ;) F ;) @AGHg[D;
'4?	JU?CE^C ;· CHCH;W=\K[lJjC7¯ KW=<@AGHMhGEO,?	@AGHKF\
_ êeÉAË Î<(Í üpDÉnÉ*Ï ý*ËÍÉÎ*ËUÉ  Î =2:Ñ qÒ2ÏÅbÍ ü p<Éþs ïÿ72Us+©2Ú ñDvJ©_
Ç J,KKOs ðT_év2U_|×lKCpbGEF<It@A9<;Â GHF<Zl(w ' ?	@A9 'iJ,KLDCH;M Lq  KK
Z ð;=<J,;OA;F@,?	@AGHKF|KP:@A9D;uÂ<J,;;
×=*?^;_  ÷¤÷T÷ êlÑVÒÎ 6Ò2ËÏÅ&Í 2Î 6»2
Î ýã¬?6Ïx7É q  ÒÎÒ^Î øo¬54,ÉÑUÎeÉÏÅÍÅ=Ë 6Uþs ïØUsJ ©ÂñD+ *_
?F<Fq^s é<_"é2U_ ê\
É øâ2JqàreÓ%É nÍÅ^Ï ¬D2@
îé254Ì22Ï  2ÏÅ&Í 2
Î óÓ%ÒÎ<Î<ÍXÎÐ2_ t¬ M
8 'iJ,;OAO_
ïY?bGHZ<KJs _é2U_>`FD?CEKIK[<OTjJ,KOAOAKb2;J_ ¬ Y
F ó9Ñ 2ËÉ,oÉ ÍÎJÐ 6Ö2@<Ï É ê\ÍXíÑ   ÎDÏxÉÑUÎeÒÏÅ^Í 2Î*ÒÓ øâ2ãÎ 0
ÉÑAÉÎeËU"
É 2
Î :ÉÎ]ÉÏÅÍ&Ë &Ó UÐ 2ÑÍX<Ï 5q6s<=<="_DÂ ñD ©v_
ï&;mCE8
? ðmKO,?sÂ_ps %?[DIGH;Js&_p²s xMB&?SA;JU?Ýs é<_DéJ I2U¤_ ðKLD[<OV@ '4?	@A
9 'iCE?F<FDGHF<I&GHF@A9<L; 'iCE?F<;_  ÷¤÷T÷
ê<ÑVÒÎ 6ÒËÏÅ&Í 2Î 6"2
Î îé254Ì22ÏÅÍÅ=Ë 6nÒ^Î plÏ 2qhÒÏÅ&Í 2Î<{s ïmö7v2Us\v5Ø * ñv2ÚÕ_
ÂD?Cp2;F*?[<;JsDm_ps x Ç K[lÖeK[DG%es*×]_"éU_j`  ;F<;@AGH^f`CHIKJUGp@A9<M PXKJ é2KL³×9DK="_ ¬ 
F ó3Ñ 2ËUÉ,É ÍXÎÐ 6
2í:<Ï 
É ïõõï  ÷¤÷T÷  ÎDÏxÉÑUÎeÒÏÅ^Í 2Î*Ò\Ó øâ2ÂÎ ÉÑVÉÎ*ËUÁÉ 2Î îé254@2ÏÅÍÅ=Ë 6Ò^Î plÏ 2qhÒÏÅ&Í 2Î<s2=D="_2Õ	/Ø ñ2Õ_
ÂD?Cp2;F*?[<;Js\:_pÓs x ï&;CH^U9D?M>L<J,;s\`f_ é2ÕU_Y`  ;F<;@AGE^>`WCHIKJ,Gp@A9DM PXKJ Ç GHF '4?^AGHF<I?F<y
Z %GHF<;
Ç ?CE?FD^GHF<I_ ¬ W
F ó3Ñ 2ËÉ,É ÍÎÐ 6y2@t<Ï 
É ïõõmö  ÷T÷¤÷  ÎDÏxÉÑÎ*ÒÏÅ&Í 2Î*ÒÓ øâ2Î ÉÑAÉÎ*ËÉ 2Î îé2U4Ì2ÏÅÍ7Ë 6
Ò^Î ôplÏ 2qhÒÏÅ&Í 2Î<sD=D="_]J IÂñD2Õ_
ÂD?b2;JÅSVKF"s Ç _ps x8K[lJUFD?OAOAK[<Z"s '_é+ *U_` %+K^?C Ç ?OA;Z|`m=D=<J,K2?^,9|PXK»J '4?	@A
9 'iCE?F<FDGHF<IKP
?F<Gp=*[<CE?	@AKJ,OomGp@A9u?f´WGHID
9 B[DMfL\;JKP ï&;IJ,;;OKP"ÂlJ,;;ZDKMy_ ¬ 
F ó3Ñ 2ËUÉ,É ÍXÎÐ 6A2@&<Ï É ïõ	9ð
 ÷T÷¤÷  ÎDÏxÉÑUÎ*Ò2ÏÅ^Í 2ÎeÒÓ øâ2Î ÉÑVÉÎ*ËU"
É 2k
Î î 254Ì2ÏÅÍ7Ë 6Ò^Î plÏ 2qhÒÏÅ&Í 2Î<s*=<="_\ÚÕ ñDÚ_
Â<;JALe?^,9\fs '_+éJ I2U_KF@VJ,GpLD[l@AGEKF
F ?h· CE»? 'CE?F<Gpd*^?	@AGHKFyZ<;T8JU?SA;^@AKGpJ,;O¯_ ð?	=<=\KJA@Z<.; ðm;^U9<;J,^,9D;
 ï&Â+(w ï& ð­s´ '4wßÕ  J I  ©2Õ I®s ï&GpJU;^@AGHKFtZ<;O i) @A[<Z<;O:;à@ ðm;^,9D;J,^,9<;Ow ï&Âj_
 [l=D@,?s ªh_]é2ÚU_ K@AGHK
F 'CE?F<F<GHFDIfPXK¯J ð;`w KWJ,GH;F@,?	@AGHKFyWOAGHF<InÂ GHF<I;J8JU?^AGHF<I· %?F<Z<MR?	JAO
GEF G  7v2 
 _ ¬ k
F ó9Ñ 2ËUÉUoÉ ÍXÎÐ 6A2í&<Ï lÉ ïõõÿ  ÷¤÷¤÷  ÎDÏxÉÑÎ*ÒÏÅ&Í 2Î*Ò2¤Ó øâ2Î ÉÑAÉÎ*ËÉ 2
Î îé2U4Ì2ÏÅÍ7Ë 6
Ò^Î ôplÏ 2qhÒÏÅ&Í 2Î<sD=D="_lØ+Ø IÂñØÚ_
´&?qo?	J,Z"s >_pés ïY?F<;OA9<MR;F<Z\¯s %Q_ps xÙ´&?q?	@AGs×]_mé2U_`¦
F KWb2;JAbGH;o KÁP ªTs` % ¬ ·i`Ù×qOV@A;M
@A
K 'iJ,KIJU?M ?F<ZKF@VJ,KCTKK=];J?	@AGpb2; ?F<GH=D[<CE?	@AKJ,O_ ¬ F ó9Ñ 2ËUÉUoÉ ÍXÎÐ 6î2@<Ï 
É ¤2mpÑ<Ï 
 Î*ÏxÉÑÎ*ÒÏÅ&Í 2Î*ÒÓ øâ2Î ÉÑAÉÎ*Ë»
É 2Î mr	ÒÎeËUoÉ ôî 254Ì2ÏÅÍ7Ë 6sD=<=+_*ÕJv IÂñÕ	+Ø ©_
´WKCHCE?F<Z\is é<_ é+ *ÚU~
_ 2:Ò reÏ7ÒÏÅ^Í 2Î|Í
Î fÒbÏ pÑVÒÓiÒ6Î WÑÏÅÍ úËÍÒ>Ó ýã¬?6Ïx=É qA6_nWF<Gpb2;JUOAGp@xqBKP GH^,9DGHI2?F
'iJ,;OAO_
´o?F<Is _ps x `W9[	SA?és B>_mé2ÕU_  J,KO,O K@AGHK/
F 'CE?F<F<GHFDI·`Ù×[<JAb2;q*O
_ ø  øâ2qsr"plÏÅÍÎÐ
ý"pòÑ r=É ¬?6Uis öj7v2U_
ªf?bJU?	Gw
s %i_psj×b2;OV@V?s '_ps %?	@AKM>L];s él_ps x K&b2;J,MR?	J,Os _éJ I2U_ 'QJ,KL*?	L*GHCHGHOV@AGE
^ ðmK2?Z<M?	=DO

PXKJ '4?	@A«
9 'iC?F<F<GHF<IfGHF´GHI9l(w ïWGEMh;F<OAGHKF*?C]KF<dDI[lJU?	@AGHKFt×=e?^;O_ ÷T÷¤÷ êlÑVÒÎ 6Ò2ËÏÅ&Í 2Î 6A2Î
î 254Ì2ÏÅÍ7Ë 6Ò^Î plÏ 2qhÒÏÅ&Í 2Î<{s ïØUs"Ú IJIÂñÚJ ©_
%?o:J,;F<^;s ï>_iZ\_$U_+éU
_ >Ò^Î 54@2	2D2í:ÉÎeÉÏÅÍÅË &Ó 5Ð 2ÑUÍÅ<Ï 5q6U_ i?F BWKOV@VJU?F<«
Z ð;GHF<9<KCEZ\_
Â+ìòB

y

\§D¨W$us<©|t"§]ª

s|Bv}

«

×vØ9Ø9 v}v

%+GEF\s´>_ps²¶&GE?Ks2él_psx GH^U9D?CH;omGH^Ès¸_*éØU_ Qb2KCE[l@AGHKFD?	JAq»B&?bGHI2?	@AKJ:PXKJ? KLDGECH; ðmKL\K@_ ¬ F
óÑ32 ËUÉ,ÉÍXÎÐ62@YÏ<Éïõõ  ÷¤÷T÷  ÎDÏxÉÑÎ*ÒÏÅÍ&2Î*Ò2Ó¤øâ2Î ÉÑAÉÎ*ËÉ2Îîé254@2ÏÅÍË76TÒÎ^qplÏ2qhÒÏÅÍ^2Î<s
=D="_*ÕÂñÕ©J© Ø_
%+KÈ?FDK	w(';) J,;Ès]8Y_"é+*U_j`a×GHMh=DCH; K@AGHKFlw('iCE?F<FDGHF<I`CEIKJ,Gp@A9<M PXKJ  ;F<;JU?C¤ðmKL\K@
[DCE?	@AKJ,O_  ÷T÷¤÷ êlÑVÒÎ6 Ò2ËÏÅÍ&2 Î6»2Î éî 254@2ÏÅÍÅË=6nÒÎ^ô
pÏ2JqÒ2ÏÅÍ^2ÎDs7v2Us]ÕÕ	Ø/ñÕv_

?F<Gp=lw

^=%+;?F\sj`f_psx ?ÈKF"s8Y_éJI2U_ ¬ F<^J,;MR;F@,?CéðK2?Z<MR?	=DO?F<Z  CHKLe?C'4?	@A9'CE?F<F<GHFDItGHF
ib2KCpbGHF<I ¬ F<Z<[<OA@VJ,GE?CiFbGHJ,KF<Mh;F@AO_ ¬ F'óÑ32ËÉ,ÉÍÎÐ6$2íÏ<Éïõõ  ÷¤÷¤÷  ÎDÏxÉÑUÎeÒÏÅÍ^2Î*ÒÓ
øâ2Î ÉÑVÉÎ*ËUÉ2Î îé254Ì22ÏÅÍÅË=6nÒÎ^ôplÏ2qhÒÏÅÍ&2Î<sD=<="_\©òñD©JI_
;qIJ,;@s`f_pés x %;bGHFD;s _&é2ÕU_4@VJU?^@AGHKF Z<«
; 'iJ,GHMhGH@AGpb2;O  ;) KM;) @VJ,GHg[<;O·Ãm@AGHCEGHO,?	@AGHKF
Z"¯°[<Fh`WCHIKJ,Gp@A9<MR;  ;) F ;) @AGHg[D;®_ ð?	=<=\KJA@Q`WF<F[<;Cs;F@A;JPXKJ ¬ F@A;CECHGHI;F@ ?^U9<GHF<;Os ^  GHCHC
WF<Gpb2;JUOAGp@xqs KF@V²J ;) ?C_
KWb2;J,M?	J,Os _4é2ÕU_TÞ
` ð?FDZ<KMÁ`m=<=DJ,K2?^,9³@AK K@AGHK$
F 'CE?F<F<GHFDI_:8;^U9<F<GH^?1C ðm;=\KJAs@ ðmw
m×w2Õwv2Õs ï&;=*?	JA@AMR;F@WKP4KM=D[l@A;J×^GE;F<^;s<m@VJU;^,9@WWF<Gpb2;J,O,Gp@xqe_
ðmKL\;JA@AO,KF\s  _é+ *Uã_ '4?	JU?CECH;C ¬ M=DCH;MR;F@,?	@AGHKFnKP  ;F<;@AGE^`WCHIKJ,Gp@A9DMhO+GHFn?WCE?OAOAGpd*;J×qOV@A;My_
¬ F ïY?bGHOs %Q_+Z\_$Us :ÉÎeÉÏÅÍ&Ë &Ó 5Ð 2ÑÍÅ<Ï 5q6nÒ^Î ýDkÍ qqplÓÒ2ÏxoÉ ôWÎ<Î]ÉAÒÓ$ÍÎÐ_ KJ,I2?y
F ªf?[<PXMR?F<F
'[lLDCHGEOA9<;J,O_
×^U9<;[<;Jsj`f_pws xÁÂlJ?GH^,9D?	JUZ\s8Y_é+ *U_ KF@AGHF[<K[<Oéwß[lJAb?	@A[lJ,
; ' ?	@A/
9 'iCE?F<FDGHF<IPXKJ?	JV(w %Gp2;
Q;9DGH^CH;O_ ¬ F ó9Ñ 2ËUÉUoÉ ÍXÎÐ 6 2@<Ï É  ÷T÷¤÷!Ýîý9ì  ÎDÏxÉÑUÎeÒÏÅ^Í 2Î*ÒÓ øâ2Î ÉÑVÉÎ*ËUî
É 2Î  ÎDÏxÉÓXÓ(ÍpÐÉÎDÏ
î 254Ì2Ï 6Ò^Î ýã¬?6Ïx7É q6Us<=D="_D+ * ñD ©J©v_
8 ?CpLDGs :_év2U_ &ÓXÓ 2Ë,ÒÏÅ&Í 2'
Î ~
É ó9Ñ 2ËU7É 6@6òpU66+pÑÓ%7É 6qWÑVË ÍÅÏxÉAËbÏ pÑV7É 6ó:ÒÑéÒÓXÓ É" Óp:É 6#Ò " %=É $ q»2Í'
Ñ &fbÍ 6:0

ÏÅÑÍ 4p É,$ Éw_ 'i9\_ ïn_l@A9<;O,GHOs ¬ F<OV@AGp@A[l@ B&?	@AGHKFD?¤C 'KCHq@A;^U9<F<GHg[<;YZ<; JU;F<KLDCH;WwiÂlJ?F<^;_
8 ?CpLDGsQm_pâs x Ç ;OAO,^G ;· J,;s '_:éJ I2U_` '4?	JU?CHCH;C  ;FD;@AGH^y`CEIKJ,Gp@A9<MÔ`=<=DCHGH;Z@AK@A9<; ?	=D=DGHF<I
'iJ,KLDCH;Mt_ ¬ F|`WOV@APX?CH*s  _:iZ"_$U
s ér+r*Ó$ÍÅËUÒÏÅ&Í 2Î 6-2t
Î mr	ÒÎeËUoÉ YWÑVË ÍXÏxÉ,ËbÏ pÑVÉ øâ2qsr"plÏxÉ@Ñ 6_
× ¬` _
8 ?F<;OA;+s ðT_é+ *Uã_ '4?	JU?CHCH;C  ;F<;@AGE^`WCHIKJ,Gp@A9DM¶PXKJ4?´q=\;J,^[lL\;_ ¬ F ó9Ñ 2ËUÉUoÉ ÍXÎÐ 6à2í<Ï lÉ ýeÉ,@Ë 26Î 
 Î*ÏxÉÑÎ*ÒÏÅ&Í 2Î*ÒÓ øâ2Î ÉÑAÉÎ*Ë»
É 2
Î :ÉÎ]ÉÏÅÍ
Ë YÓ UÐ 2ÑUÍÅ<Ï 5q6Us*=<="_\p *J* ñDv_
¶&GE?K6s é<_ps GE^,9D?CH;oGH^Èms ¸_ps x ¸]9D?F<Is %i_+éJ I2U_:Qb2KCE[l@AGHKFD?	JAD
q 'iC?F<F<;J  B&?bGHI2?	@AKJé· KW=\;JU?	@AKJ
' ;J,PXKJ,MR?FD^;&?FDZy×l;CHPHwx8[<F<GEF<I_ ¬ k
F ó3Ñ 2ËÉ,É ÍÎÐ 6A2@&ïõõ  ÷T÷¤÷  Î*ÏxÉÑÎ*ÒÏÅ&Í 2Î*Ò¤Ó øâ2Î ÉÑVÉÎ*ËUÉ
2k
Î ÷r?2³Ó plÏÅ^Í 2Î*Ò:Ñ ¬øâ2qsr"plÏ7ÒÏÅ&Í 2Î<se=<="_DvJv IÂñ+v *_

Â+ì 



	
 
			 ! #"$ % 
'&)(+*, ((-/.0, 1(32', 44

56789  :+;<
(-!=?>7	%&:@, A/<
(-

BDCFEHGJILKMONQPRETSLEHU6U/NVUXWYI0NZSLE)I0K/M@N\[]NVNVG^NV_FK_a`cbdNZETSLegf

hjikml#nporq)sJtLtmu
O'r{?Zx'x/x
@?Y@rY
/
 ¡
¢£d J¤ ¦¥¢§?0¨+©?ª
«+¥a¬?­®¬¯°L¨+©?ª°)¤Y±³²´®¬­p¨

vxwwmy{zOvx|}m~g~}m

µ¶q+s¸·kmi¹»º¼k$·l#nx½½

v¾m¿Àm}ÁÁzO|6Â/|6{~}m

O'r{?Zx'x/x

 ªªÃaÄÆÅ$¨+¢F ªªa¡/
¢£
«+¥a¬?Ç®´Ç?°0È@
¦!
Ã/¢3°H¤Y±³²!¯­´É¶¨

ÊÌË)ÍÎÏÐLÑYÎ
ÒÔÓ?ÕÖ×?Ø$Ù3ÚÛ)ÓÜ Ù3ÝÞYß/ÝàÓ?áYÝâÕÙ¦Û6áâáãÝãäÛÕ ß/Û+Ù¦Û6ß
ÚÕÝãåæÛ!ç#èÛéÛ6áâ×ê Û!èÙ3×@èÓ?Ù¦Û)Ü¦Û6áâÖ×ÕJÚÛæÜ¦ÝàçÙ3Ýãß)ç¦Û6Ó?Ü
ß
Ú
Ù3ÚÜ¦×æäÚFáàÓ?Ü3äÛ@ç êÓß/Û!çëVìVÕØí×Ü¦Ù¦æÕÓÙ3ÛáãÖîYÙ¦ÚÛOç ÝãïÛ@×?ØLÙ3ÚÛ6ç¦Û@ç¦êÓßÛ6ç+Ó?ÕèaÙ3ÚÛß/×Ü3Ü3Û6ç¦ê ×ÕèÝãÕä¼ß/×ð@ñ
êæÙ3ÓÙ3Ýâ×ÕÓ?áÆÛ/òx×Ü¦Ù@Ü3Û6èæß/ÛdÙ¦ÚÛ¸Ó?êêáãÝàßÓ?óÝâáãÝÙÖô×ØZ×?Ù¦ÚÛÜ3õ9Ýãç¦ÛdÕ×éÛáÆÓ?ÕèöÛòYÛ!ßÙ3ÝâéÛJÓ?áãä×Ü¦ÝâÙ¦Úðç6ëø÷
Õæð@ó Û6ÜH×?ØrêÓ?Ü
Ó?áãáãÛá{Ó?Õ è^èÝãç Ù¦Ü3ÝâóæÙ¦Û!èöÓ?êêÜ3×Óß
ÚÛ6ç+Ù3×ùç Û!Ó?Ü
ß
ÚÔÚÓéÛß×Õç¦ÝàèÛÜ
Ó?óáãÖùÝãðêÜ¦×éÛ6èÔÙ¦ÚÛ
êYÛÜ¦Øí×Ü3ðÓ?ÕßÛ)×ØmÙ3ÚÛHç Û!Ó?Ü
ß
ÚdêÜ3×ß/Û!ç¦ç6ë
ú æÜ#ä×Ó?á Ýãç#Ù3×@èÛ6éÛáã×êJÓ?ÕdÓÜ3ß
ÚÝâÙ¦Û!ßÙ3æÜ¦ÛZÙ¦ÚÓ?ÙrÓæÙ¦×ðÓ?Ù¦ÝàßÓáâáãÖç Û6áâÛ!ßÙ3ç#êÓÜ3ÓáâáãÛáYç Û!Ó?Ü
ß
Ú¼çÙ3Ü3Ó?Ù¦Û/ñ
äÝâÛ!çØí×ÜT×êÙ¦ÝãðÓ?á{êYÛÜ¦Øí×Ü3ðÓ?ÕßÛ×ÕöÓ¸éÓÜ¦ÝãÛ/ÙÖø×?Ø9ç Û!Ó?Ü
ß
ÚøêÜ¦×óáâÛ6ðçë¼ûªÕ^Ù3ÚÝãç§êÓ?êYÛÜTõÆÛ¼èÛ!ç¦ßÜ¦Ýãó Û
×ÕÛZç æ ß
ÚÓÜ3ß
ÚÝÙ3Û6ßÙ3æÜ3Û9Ü¦Û!Ó?áãÝâï6Û6è@ÝâÕÙ3ÚÛVü m¿}ym ç¦ÖçÙ3Ûðaîõ9ÚÝàß
Úß/×ð§óÝãÕÛ6çLÙ¦ÚÛZóYÛÕÛ/ÞÙ
ç{×?ØðÓ?ÕÖ
èÝâòxÛÜ3ÛÕÙÓêêÜ3×Óß
ÚÛ6çZÙ¦×¸êÓ?Ü
Ó?áãáâÛ6áÚÛæÜ3Ýãç Ù¦Ýàß§ç¦Û6ÓÜ3ß
ÚmëýrÚÜ¦×æäÚùÛ6ðêÝâÜ3ÝàßÓ?á0Ó?Õ èFÙ¦ÚÛ×Ü3Û/Ù3Ýãß6Ó?á0Ó?ÕÓáñ
Öç¦Û6ç@õ#Û¸×óç¦ÛÜ3éÛ¼Ù¦ÚÓ?Ù@ØíÛ!ÓÙ¦æÜ¦Û!ç§×ØZÙ¦ÚÛ¸êÜ3×óáãÛðþç¦êÓßÛJèÝãÜ3Û6ßÙ3áâÖjÓ?òYÛ!ßÙ@Ù¦ÚÛFß
Ú×ÝãßÛ¼×?ØV×êÙ¦ÝãðÓ?á
êÓÜ3ÓáâáãÛá ç Û!Ó?Ü
ß
ÚOç Ù¦Ü
ÓÙ3ÛäÖëÿ^Û9Ù3ÚÛÕÛ6ðOêáâ×Ö@ðÓß
ÚÝãÕÛZáãÛ6Ó?Ü3ÕÝãÕäÙ¦Û!ß
ÚÕÝàåæÛ6ç0Ù3×§ç¦ÛáãÛ6ßÙgÙ¦ÚÛZ×êÙ¦ÝãðÓ?á
êÓÜ3ÓáâáãÛáxç¦Û6Ó?Ü
ß
Ú¼ç Ù¦Ü
ÓÙ¦Û6äÖOØí×ÜrÓ@äÝãéÛÕdêÜ¦×óáãÛð ç¦êÓßÛëÿ ÚÛÕaÓHÕÛ6õ»ç¦Û6Ó?Ü
ß
ÚÙ
Óç ÝàçÆÝâÕêæÙrÙ¦×@Ù¦ÚÛ
ç¦ÖçÙ3ÛðaîYü $¿}y æç¦Û6çZØíÛ6ÓÙ3æÜ3Û6ç)èÛ6ç3ß/Ü3ÝâóÝâÕä¼Ù¦ÚÛOç Û!Ó?Ü
ß
Úaç¦êÓß/Û§ÓÕèaÙ¦ÚÛ@ß
Ú×ç Û6ÕùÓ?Ü
ß
ÚÝÙ3Û6ß/Ù¦æÜ3ÛTÙ¦×
ÓæÙ¦×ðÓ?Ù¦ÝàßÓáâáãÖOç¦ÛáãÛ6ß/ÙgÙ3ÚÛ+ÓêêÜ3×êÜ3ÝãÓ?Ù¦ÛZç¦Û6ÓÜ3ß
Úç Ù¦Ü
ÓÙ¦Û6äÖëü $¿}y ÚÓç#ó Û6ÛÕÙ3Û6ç Ù¦Û!è×ÕdÓ§ÒFûÒ
êÓÜ3ÓáâáãÛáLêÜ¦×ß/Û!ç¦ç¦×Ü!îmÓùèÝãç Ù¦Ü3ÝâóæÙ¦Û!èôÕÛ/ÙõÆ×Ü
×?ØrõÆ×Ü ç Ù3Ó?Ù¦Ýã×Õç6îmÓÕèöÓFç ÝãÕäáâÛõÆ×Ü çÙ
ÓÙ¦Ýã×Õøæç¦ÝâÕä
ð@æáÙ3ÝÙ3ÚÜ3Û6ÓèÝâÕä ë 9Û!ç æáÙ
ç+äÛÕÛ6Ü3Ó?Ù¦Û!èFØíÜ3×ð ÞØÙ3ÛÛÕ^êæï6ïáãÛêÜ¦×óáãÛðçîÜ3×óY×?ÙTÓ?Ü3ð³ð×?Ù3Ýâ×ÕÔêÜ3×óñ
áãÛðç6î0ÓÜ Ù3ÝÞYß/ÝàÓ?ágç¦Û6ÓÜ3ß
Úôç ê Óß/Û!çî0Ó?Õ èøêáãÓÕÕÝãÕäùêÜ3×óáãÛðçTÝãÕèÝàßÓ?Ù¦ÛÙ3ÚÓÙOü $¿}y ×æÙ¦êYÛÜ¦Øí×Ü3ðç
ÓÕÖO×?ØÙ3ÚÛZÙ3Û6ç Ù¦Û!è¼çÙ3Ü3Ó?Ù¦Û6äÝãÛ6ç{æ ç Û!èÛ ß/áãæç¦ÝâéÛáãÖ§Øí×ÜÆÓáâá êÜ¦×óáãÛð ÝâÕç Ù3ÓÕß/Û!ç#ÓÕèÝàç#ÓóáâÛVÙ¦×HäÜ¦Û!ÓÙ3áâÖ
Ü3Û6èæ ß/Û)Ù¦ÚÛHç¦Û6ÓÜ3ß
ÚdÙ¦ÝãðÛØí×ÜrÙ¦ÚÛ6ç¦ÛHÓ?êêáãÝàßÓÙ3Ýâ×Õç6ë
















 	 ÎÏV ÑYÎ 
!"$#%'&()$*)+,-!*)-!.0/12&"3(4-!5768)*)9#-!&":3;&"$)+,#-<(!):357"&5=>";:3?(@ACB#:357&(!9D
:";:?3():3E.#-F&57-F4A7ACGH"IJ9#:3>.KL5C-F&M9&()#8*4N#%O";:3?(!57-)BP&():#)B(J&()LA=;:BQ+4.
.:;&"*HR8GS&()"ACB#:35C&(49TM/'*)U;-!.V57-S+4;:3A=ACAW-!*X*!57"&":357R4)&"*S.#9+4)&57-!BL#;Y,:N+,#&"-[Z
&57A7A7GNA7;:B\57-!.:]5=-M+,:%^#:39-4.&"#V!?(_.#9+4)&".Z`57-F&"-!57U&I8TW1a-E:"+,#-!"Db-F492R,:
#%W+4;:3A7A7Ac;+4+!:#3(!d(!eU2R,-$*)UAC#+,*$&"#>5=9+!:#fUNU;:?5C#!\";:3?(gACB#:?5C&(!9\57-4A7!*!57-!B
*)+!&()Zih4:3"&N";:?3(kjml2!9;:Mnpod;#)Drqss;tvu?DR!:3-!?([Z`-!*[ZR,#!-!*X";:?3(wjm/dB:3exADyv-!;I[5C:39$D
n{zg(!:#&":3[D
qs||u?D4/2}jm~U&"&D4-!*!AC:D8zP(4-v&5iD!n{'
D
qss84zP(4;+4;&":3n{'!&"&Dqssu?D
1aO/N}XjmzP(!-F&5nb-!57A7Dqss8]#exdACGD]):B!#-
D]nlV#:3%Dqss8]#exdA7GHnlN#:%Dqss[qeu?D
-!*SB9&":";:?3(jm)A=*!9-!-
D
zPG83A75Cxd5C&"D
nzP#-!5C-
DqssFu?DbxA7AWb&"#$579+!:3#eU_&()
:3!-P&579E#%+c5Ch2;+!+A757;&5C#-!'!?(Xb&()Eh4%&"-S+4!ACM+4:#R4AC9jmlN!9;:Nnod;#)Dqss;tvu
-!*:#R,#&0;:39+4;&(+4A7-!-457-)Bkjr(4A7AC#
D'V57-!5iDdnlN!9>;:D2qssu?T1-w*!*!57&5C#-&"#zP1zS




r



 

`¡

=¢ f¡

, ((-ÆY %% !:3H
: /
 L
!â8Z
 Y7!	%&% 		&/%m% / :

£

P¤#¿À$}ÁÁ

wwyXmÀ$

!* 57&":35CR4)&"*)Z`99#:G>A7B#:35C&(!9D)+4;:3A7ACA
;:33(SACB#:35C&(49\(!UMR,-¥*)UAC#+,*$%^#:zP1zS
(!;:3*[Z`99#:G<"G["&"9gjmlNA7gn§¦[AC&"#:Dbqss;t[l2!9;:>n¨od;#)DVqss;tvu-!*¦81azP¨;:3?(!5©Z
&".&):Sj#8#In«ªG#-!Dbqss8b~U&"&>&LAiTCD'qss8'lN;:G8+457n¬l2!9;:D'qss­8'zS(!-F&5dn
b-!5CA7Dqss8!]#exdA7G&AiTCDcqssu?T®w(!57AC\.¯)57"&57-!B2;+!+!:#?()&"#2+4;:3A=ACA!";:3?(L(4Ub9-vG
.#-F&":35CR4)&57#-!N&"#X#;Y,:D.#9+4;:35=-)Bg&()0;+4+!:#3(!E-4*°*)&":?957-!57-!B¥&()QRc&M!"Q#%O?(
.#-F&":35CR4)&57#-57*!5©KQ!AC&WR,!"\#%,&()d*!57U:3"O";:3?(LA7B#:35C&(!9D579+4AC9-v&;&5C#-+4A7;&"%^#:39D
-!*¥;+4+4A757;&5C#-4:3+c#:3&"*¥57-0&()2A=5C&":3;&):T
1a-:"+,#-!"S&"#&(!57L+!:#R4A79$DOxX(4U±*)UAC#+,*&()J²\³µ´
¶!·¸{+4;:?A7ACA'";:33(w-!B57-)
&(!;&.#9MR457-)9>-vG<#%d&()¥;+!+!:#?()&"#H+4;:?A7ACA()):357&57L;:33(
T²O³´
¶!·]¸¹jr#F#In
º;:3-)A=AiD\qss»u_57Eg+4;:?A7ACA1aO/2}g";:3?(;:33(!57&".&):Q&(!;&9:B9E!AC&5C+4A7>;+!+!:#?()E&"#
&"I<*!57"&":357R4)&5C#-
D]AC#*°R4A7-!57-!B)D-!*J&":3Q#:?*):357-)B)D-!*¼-<R,L:?!-J#-¼XzP1zS½3(!;:*
99#:3GS#:E*!57"&":?5CR4)&"*X99#:3GP+4;:?A7ACAW+!:#[."#:eD]¥*457"&":35CR)&"*X-)&`x#:IX#%rx#:I["&;&5C#-4D
#:0J57-!BAC¥93(457-)gx5C&(@9E!AC&5C&():3*!57-)B)Tw¾357-)B±#):Q.#A7AC.&5C#-#%N";:3?(A7B#:35C&(!9Dx
+,:%^#:39¿&(!#:&57Ab-!*k9+45C:35=Ad.#9+4;:?57"#-!Q-!*k#R4":UX&(!;&0+,:%^#:39-!.P&":-!*!Q*)#
.¯)57"&";:3?(@"+4.$%^;&):;:3QU;;:35C*TJÀµ#±;+5C&A75C0#-¼&()"$&":3-!*!D²O³´
¶!·]¸Á!"
9?(!57-)2A7;:3-!57-)BG8"&"9p&"#>+!:3*!57.&\&()M#+!&579A&d#%W+4;:3A7A7A
";:33(S"&":3;&"B57d%^#:>B5CU+!:#RAC9$D[xd(!57?($;:N&()-g!"*$&"#>.#9+4AC&"N&()N;:33(g&"IT
Ç ÊXÈVÈ Ï{ ÐLÑFÇmÅ Í
WÂ 	Ã Ð0ÏÐ
Ä`Ä`Å4ÄbÆW$Å Ð0ÏÑv³
/Á-8!92R,:#%
:";:3?():3r(!U'.¯[+4AC#:*L9&()#[*!%^#:5=9+!:#fU857-!BV&()d.KL57-!.G#%";:3?(L457-)B
+4;:3A=ACA(!;:?*)x;:3Tg®H0xd57A7A%#[!E57-±&(!5=2+4;+,:M#-°+;:3A7ACA";:33(<&"?(!-!5768)M&(!;&-°R,
;+!+4A=5C*&"#¼1aO/2}J";:33(TÉ1aO/N}±+,:%^#:390¼":357L#%E57-!.:9-v&A7A7GvZ`*)+,-!5=-)BJ*)+!&()Zih4:3"&
";:3?()M&():#)B(H&(!L";:3?(°+4.TL1a-±?(°57&":3;&5C#-±&(!:#)B(H&()L"+4.DW&()>*)+4&(H#%\&()
";:3?(¼57M.#-F&":#A7A7*JR8G±-°/2}$.#"&_&():()#A=*
T$1%OPB#Ar-)#[*)L57M-)#&E%#!-4*J*!):?57-)B¥PB5CU5C&":3;&57#-
D];:33(<R,B57-!M;&2&()Q:#8#&M-)#[*)xd57&(Jg.#&M&():3()#A7*°"&2&"#S&()L9>57-!579E!9«Êj^Ëu
U;A7)r57-2&(!";:?3("+4.r&(!;&].¯).*)*_&()r+!:U[5C#!&():(!#A7*
T1aO/2}d57-_*!9>575CRAC";:3?(
ACB#:357&(!9xd(!57?(0:68!5C:\-P9#!-F&\#%W99#:G0A757-);:O57-0&(!2*)+!&(0#%W&()N"#A=)&5C#-
T
1a-&(!57.&5C#-xOxd57A=Av:U[5Cx@.¯)57"&5=-)BV9&()#[*!%^#:+4;:3A7A7A75C57-)B'1aO/N}'";:33(T1-+;:&57[Z
A7;:D)xVxd57A=A.#-!357*):OAC&":3-4;&5CUV&"3(!-4576F!\%#:d&"IQ*457"&":35CR)&5C#-
DF%#:d*!G8-!9>57A7ACGR4A=-!57-)B
x#:ILR,&x-g+!:#[."#:3D-!*0%#:3(!-)B5=-)B&()NAC%^&aZ&"#;Z:35CB(F&d#:?*):\#%W&()N";:3?(g&":T
Ì qiÍÏÎ)k!Ð?u hji^ÐÑ ·i^ÒWÓÑ itl
/Ô";:3?(PA7B#:35C&(!9½579+4AC9-v&"*$#-S+;:3A7ACAG8"&"9½:68!5C:dR4A7-4.*g*!5CU[5757#-0#%x#:I
R,&`x-w.#-v&":357R4)&57-)BJ+!:#[."#:3L&"#¼:*!!.S57*!AC¥&5=9P-!*957-45795C$:*4!-!*!-F&>#:Qx&"*
.Y,#:&TÉÕb-)X9&()#[*#%2*45CU85=*!57-)BH)+&()Sx#:Ik57-1aO/2}±";:33(Á5=>xd57&(°+4;:3A7ACAdxd57-!*!#ex
";:3?(±jm®Ö¦!u?D)57-F&":#8*4!.*>R8G>]#exACGL-!*0lV#:3%jaqss[qeu?T¾'57-!BM®Ö¦cD[3(0+4:#8.3"#:\57B5CUX.#+FG<#%d&(!Q-F&5C:$";:?3(&":$-!*¼H!-4576F!L.#"&&():3()#A7*
THÀO(!Q+4:#8.3"#:3_";:3?(&()
9H&":3±&"#*!5©Y,:-F&0&():()#A=*!$579E!AC&-)#4ACGT1%E¼+!:#[."#:g.#9+AC&"¥-Ö5C&":?;&5C#xd5C&(!#)&dhc-!*!57-)BQ$"#A7)&57#-
D
5C&V57bB5CU-H$-)xÏ!-4576F!2&():3()#A7*jm*)+,:V&(!-H-FGP&():3()#A7*
G&L;:33()*cu-!*RcB5=-!J-)x½";:33(k+4>xd5C&(&(!g-)xp&(!:()#A7*T@®(!--@#+4&579A
"#A7!&5C#-±57N*!5C:*
D+!:#[."#:32&(!;&Nhc-!*±¥B#A-)#[*)>9E!"&N:9>57-J57*4AC!-F&57AA7A+!:3#8.#:3
xd5C&(_AC#fx:.#&&():()#A=*!(4Ud.#9+AC&"*_&()5C:)::3-v&5C&":3;&57#-
T]/&`G8+457A)*!57U85735C#-N#%x#:I
!5=-)B®Ö¦057\57A7A=!"&":3;&"*$57-$W5CB!:q;T
×3ØfÙ

Ú x4Û)Üã¾}>ÝLm¿xmÁÁ}ÁEÞ3}¿x)Üã¾}Lß}}vÛ}À!ÜÀ4à<áY}m¿xv8â

INITIAL

GOAL
= expanded by processors 1, 2, and 3
= expanded by processors 2 and 3
= expanded by processor 3

W5CB!:q;ãb5CU[575C#-0#%]x#:3I05=-0+4;:3A7ACAcxd5=-!*)#exÖ;:33(
Õb-!*)U;-v&;Br#%)+4;:3A=ACAxd57-4*)#exJ;:33(E57&(4;&µ&():*!!-!*4-v&µ;:33(E57-!():3-v&57-21d/N}\57
-)#&+c:3%#:39*":357A=ACGT]b):?57-)BV3(0-)#-)Z`57-!5C&57A[5C&":?;&5C#-#%
1aO/2}D[A=A!#%,&()-!#8*).¯8+-!*)*
57-b&()+!:U[5C#!5C&":?;&5C#-N;:.¯[+4-!*!*N;B57-
TW¾357-)BO9E!AC&5C+4A7+!:3#8.#:3D&(!57,:*!4-!*!-F&
x#:I
57'+,:%^#:39*X.#-!)::3-v&ACGTM/É".#-!*H*!U-F&;B#%+;:3A7ACAxd57-!*!#exÔ";:3?(H57'&()579+!:3#eU*
&579E57-0h-4*!57-)Bh4:3"&d#A7)&5C#-
Tr1%>";:?3(S"+4._()#A7*!O9>-vG$B#AW-)#[*)D!1aO/2}9G0h-4*g
*)+>#A7)&5C#-9E!3(>9#:d68!573I8ACGM&(!--#+4&579A)"#A7!&5C#-
TW];:?A7ACA[xd57-4*)#ex@";:?3(>-&;I
*)U;-v&;B>#%&(!5=&GF+,#%r";:3?(±"+4.T_:#[."#:?b&(!;&N;:";:3?(!57-)B$R,G#-!*S&()#+4&579A
&():3()#A7*9Ghc-!*k¼"#A=)&5C#-*!#exd-&()Sh4:3&>R!:3-43(&()G@.¯[+4AC#:D-!*w-k:3&):3-k&(!;&
"#A7!&5C#-PA7#-)B0Rc%^#:E#&():V+!:#[."#:?'h-!57(g&()5C:V5C&":3;&57#-
TNÀO(!57'9eGP:3!AC&b57-P3)+,:3A757-);:
"+,*!)+>Rc4"d&()'":357AACB#:35C&(49É.#-!":3U;&5CUA7G>57-!.:9-v&&().#"&&():3()#A7*>-4*>*)#8
-)#&dA7#F#IQR,G#-!*0&()2):3:-v&\&(!:()#A7*T
Õb-¼&(!¥#&():>(!-4*
D+4;:?A7ACAxd57-!*!#exä";:3?(-%m.g±*!A757-)$57-<.KL5C-4.G<x()-¼&()
-8!92R,:\#%]+!:#[."#:3d57\5CB-!5Ch-v&A7G>B:;&":&(!-$&()2-8!9MR,:\#%]5C&":?;&5C#-!\:68!5C:3*L&"#h-!*
-¥#+4&579Aj^#:'h4:?"&?ur"#A7!&5C#-
D!!5=-)B>A7A
:3957-!57-!B+!:#[."#:3d&"#L5C&O5=*!ACTÀd(!57O57&!;&5C#xd57A=A,#8):'xd()-P9-FG$+!:#[."#:3';:MeU5=A7;R4ACDcG&%^x¹5C&":3;&5C#-!;:2:36F!57:*¥R,!"M&()
()):?57"&57"&579;&"E57r%m5C:3ACGQ):3;&"T
/'-±AC&":3-4;&5CU+4;:3A=ACAW";:33(°;+!+!:#?(±:A=5Cb#-±*!57&":35CR4)&5=-)B&()&":3>9#-)B¥&(!+!:#;Z
."#:?'jmlN49;:nåod;#)D,qss;t[!od;#)D[lN!9;:D[nÖo9(
Dcqs|»u?T®w5C&(&(!5=;+!+!:#?(
D8&()d:#8#&
-)#[*)#%r&()Q";:33(<"+4.Q57VB5CU-J&"#P&(!h4:3"&2+!:#[."#:M-4*H#&():E+!:#[."#:3M;:L35CB-)*
)R4&":E#%O&(!;&E:#F#&-)#[*)Q_&()G±:68)"&Ex#:3ITH/'E-¼AC&":?-!;&5CUD&()0*!57&":35CR4)&"*±&":
";:3?(°A7B#:35C&(!9æjm'À'¦!ub9+AC#eG[NR!:3*)&([Zih4:3&V.¯8+4-45C#-±!-F&57A&(!:L;:Q;&MAC&ME9-vG
.¯[+4-!*)*SAC;%-)#[*)'eU57A=;R4AC2+4:#8.3"#:3T':#[."#:3:.5CU_!-!5=6F)M-)#8*!d%^:#9½&()2.¯8Z
+4-!*457-)BH+!:#[.Q-!*;:3g:"+,#-!35CR4AC0%^#:L&()P-v&57:P!R!&":g:3#F#&"*;&L&(!g:.5CU*-)#[*)T
#99E!-!5=;&5C#-[Z%^:dU:335C#-!#%&(!57*!57"&":?5CR4)&5C#-33()9V(!eUVA7"#2R,-Q:+,#:&"*XjmzP(4;+4Z
&":3_nåb)&"&D,qss84od57-)%^A7*>n¹¦[3(!-!IDqssFu?T1a->A=A!#%&()&":'*!57"&":?5CR4)&5C#-;+4+!:#3(!D
&()O+4:#8.3"#:3+,:%^#:39¹1aO/2}#-&(!5C:!-!5=6F)\!R!&":3579M4AC&-)#!A7GT/'A7A)+!:#[."#:?";:3?(
&"#N&()O39\&():(!#A7*
TW/d%^&":A7A[+!:3#8.#:3(!UOh-!57(!*EV357-)BAC\5C&":3;&57#-
D&()G_R,B57-_V-)x
";:3?(+4&():#)B(E&()O9O"&#%3)R!&":!357-)BVVA7;:B:&():3()#A7*
T]/k39+4AC\*!57&":35CR4)&57##%W&()N";:3?(g"+.257\()#fxd-¥57-$W5CB!:2­8T
×3Øv×

£

P¤#¿À$}ÁÁ

wwyXmÀ$

INITIAL

Processor 1

Processor 2

Processor 3

= expanded on all three iterations
GOAL
= expanded on last two iterations
= expanded on last iteration

W5CB):32­8ãb5CU85=5C#-Q#%Wx#:I057-$*!5="&":35CR4!&"*>&":E";:3?(
bÕ -!0*!U-F&;Bg#%&(!57*!57&":35CR4)&57#-J?()9¥57_&(!;&-!#S+4:#8.3"#:57_+,:%^#:3957-)BPx&"*
x#:IgR,G#-!*P&()_B#A*)+!&(
TV!"&(!EACB#:?5C&(!9¨";:3?()b&()_"+4..#9+4AC&"A7G¥&"#$#-)
&():3()#A7*kRc%^#:H"&;:&5=-)B°&(!X;:33(Á&"#@¼-)x¨&():3()#A7*
D-)#-)X#%2&()X+!:3#8.#:3057QU:
";:3?(!57-)BS;&EPACUARcG#-4*±&()QACUA#%\&(!L#+!&5=9A"#A=)&5C#-
T01&M572+c#35CR4ACD]()#exU:D%^#:
bÀ¦¼&"#<+,:%^#:39çxr"&"*x#:I;&Q&()gB#A'*)+!&(Tw!#:Q.¯)9+4A7Dr5=-W5CB):S­H+!:#[."#:$
";:3?()-)#[*)_;&&()0B#AOACUAr&(4;&x#!A=*<-!#&ER,0";:3?()*@57-¼X":357Ar";:?3(@ACB#:?5C&(!9
9#fU857-!BAC%&aZ&"#;Z:?5CB(v&d&():#)B($&(!N&":T
/ä*457*)U;-v&;BQ#%\&(!57E;+!+!:3#3(<572&(!>%m.&E&(4;&M+!:3#8.#:3M;:3L#%^&"-¼57*!ACT¥À#P-4):
#+!&579>A75C&`GD\+!:#[."#:µ&(!;&µ68!57I[ACGdh-!57(!#-!5C&":3;&5C#-29M!&
x5C&
%^#:µA7A#&():+!:#[."#:?
&"#
h-!5=(_R,%#:"&;:&57-)BM&()-!.¯8&57&":3;&5C#-
TÀO(!5=57*!AC\&5=9-L9;I&(!"G["&"9èU:G57-).KL57-v&
-!*P:*!!.M&()2+,:%^#:39-4.2#%&()E";:3?(S;+4+4A757;&5C#-TOÀO()2.KQ5C-!.G$#%&(!5=d;+!+!:3#3(XR,N579+!:3#eU*¥R8GQ+c:3%#:39>57-)BAC#*$R4A=-!57-)BR,&`x-S-)5CB(FRc#:?57-)BE+!:#[."#:3dx#:I[57-)B#-g&()
9M5C&":3;&5C#-
T
ÀO(!"$*).:35CR,*<;+!+!:#?()_#;Y,:!-!5768)>R,-).h&TJW;:3A7ACAxd57-4*)#ex";:3?(57E.Yc.&57U
xd()-P9-FG057&":3;&5C#-!d#%1O/2};:2:68!5C:3*
D)xd()-g&()2&":E57d#L579MR4A7-!.*¥&(!;&bÀ¦¥xd57A7A
:68!5C:_.¯).5CULAC#*HR4A7-457-)B)D#:Nx()-H¥*)+D]-)#-[Z#+!&5=9A"#A7)&57#-H57V.+!&;R4ACT$Õb&()$#&():L(!-!*
D*45CU85=*!57-)B¥&(!¥";:33(k"+4.¥9#-!BH+!:#[."#:3-@Rc$9#:3$.Yc.&5CUgxd()&()QR!:3-!?(!57-)BP%^.&"#:5=MU:3GJA7;:B$-!*°&()$-F492R,:E#%O1d/N}g5C&":?;&5C#-!E57E:A7;&5CUACG±39A7AiT
/Ï.#9+4:#957"MR,&`x-P&(!"E;+4+!:#3(!'*45CU85=*)\&()_"&'#%+!:#[."#:3'57-F&"#Séêìë8íïî`ðñ3íMjr#F#IcD
qss»u?T~?(A7!"&":57B5CU-'!-!5768).#"&W&():()#A=*
D-4*M&(!r;:33(_"+4.\57W*!57U857*!*VR,&`x+!:#[."#:?rxd5C&(!57-L3(gA7!"&":D!\3()#exd-$5=-QW5CB!:N8T¦8&"&57-)B_&()N-8!9MR,:#%WA7!&":3&"##-)
579E!A7;&"$*457"&":35CR)&"*@&":±;:33(
DV-!*Á&"&57-)B¼&()±-8!92R,:0#%MA=!"&":30&"#&()±-8!9MR,:Q#%
U;57A7;RACV+!:#[."#:3d579E!A7;&"r+4;:3A=ACA,xd57-!*!#exÁ";:3?(
T
×3Øò

Ú x4Û)Üã¾}>ÝLm¿xmÁÁ}ÁEÞ3}¿x)Üã¾}Lß}}vÛ}À!ÜÀ4à<áY}m¿xv8â

Cluster 2

Cluster 1
INITIAL

INITIAL

Processor 1
Processor 2
Processor 3

Processor 4
Processor 5
Processor 6

W5CB!:28ã¦8+4.N;:33()*gRFG0&x#>A=!"&":3D)?(gx5C&(¥_+!:#[."#:?
Ì q Ìó tmk!ôaõ km½kmlö i'lg¹
®w()-PL+!:#RAC9ä57dR!:#I-S57-v&"#0*!57m÷a#57-F&O)R4&"I8&()Mx#:I[AC#*Pxd57A7AµA75CIACGQU;:3G¥9#-)BQ+!:#;Z
."#:?T!"d#-!d+!:#[."#:9G:?!-#)&#%cx#:IR,%^#:O#&():3DFAC#*>R4A7-!57-!BN57!*&"#
.&5CU;;&"2&()M57*!ACb+!:#[."#:eTÀO()bh:3"&\+4(!N#%AC#*$R4A7-457-)B57-FU#ACUdAC.&57-)B+4:#8.3"#:
%^:#9«xd(4573(J&"#P:68)"&Mx#:3ITPÕb-!>.¯)9+4AC>5=N&()Q-);:"&_-)5CB(FR,#:2;+!+!:#?(ÁjmzP(!;+;&":3
nøb)&"&Ddqssu?OAC&":3-4;&5CU$;+!+!:#?()57-!A74*)>"AC.&5=-)BP:?-!*)#9+!:#[."#:3E#:A7AC#fxd57-)BX
9"&":+!:#[."#:O&"#LI+g&":33I$#%W+!:#[."#:dAC#*4O-!*¥"-4*$&()N1a¹#%()U[57ACG0AC#*)*¥+!:#;Z
."#:&"#V#-)\&(!;&57W57*!A7Tb):357-!B&()O.#-!*_+4(!"r#%,AC#*ER4A7-!5=-)B)D&()O*)#-!;&5=-)B+4:#8.3"#:
*)57*!x(!573(Sx#:IcD5C%-FGD&"#0B5CUTM/è";:33(JACB#:35C&(!9ø&GF+45=A7ACGg"&"#:3V-)#8*!x(!573(X(!eU
-)#&VR,-X%m!A7ACG¥.¯[+4-!*!*X#-±-°Õ'+,-XA757"&TE®w()-HB5CU[57-)B0x#:IP&"#P-)#&():N+!:3#8.#:Dµ-)#[*)
-$R,'B5CU-$%^:#9&()N()*0#%]&()VA757"&Vjm*)+¥57-Q&()V&":fu?D4&()b&57Ajm-);:\&()V:#8#&?u?D)#:O%^:#9
9+A757-)BE#%A7A
ACUA72jml2!9;:nÔo;#)Dµqss;tvu?T
/¹-8!92R,:O#%;+4+!:#3(!d(!eUMR,-¥57-F&":#[*!!.*$%^#:d:3*!!57-)B+4:#8.3"#:d57*!A7V&5792!357-)B
AC#*>R4A7-!57-!BN#+,:3;&5C#-
T¾'57-)BN&(!68!A75C&GE68!A75757-)BN"&":3;&"BGSjmzP(!;+;&":3Enåb)&"&D
qssu?D
+!:#[."#:?-v&5757+4;&"¥57*!ACQ&5790R8G°"-4*!57-)BS#)&Xx#:I°:36F)&Ex()-¼&()5C:AC#*57A=9#"&
9+!&GD"#>&(!;&d&()G$-P.#-v&57-8)N+4:#8.357-)B:9>57-!57-)B-)#[*)\x(!57ACbxr5C&57-)B%^#:d>:"+,#-!"T
/'AC&":3-!;&5CU±;+4+!:#3(!g;:J-!#&$:.5CU:gR"*
DbR4)&$A7AC#fx§-Á#fU:3ACGFZ`AC#*)*Á+!:3#8.#:¥&"#
57-!57&57;&"dEAC#*>RA7-!.d#+,:3;&57#-Sjm!!:3!57?(!5iDFÀ];I[5iD[nå1a3(FG#(!5iD,qss;t[4odf÷"+4A,nål2!9;:Dcqssu
#:\A7AC#fxwA=A4+!:3#8.#:3&"#_+,:35C#[*!57A=ACGM(45C%&x#:3I&"#_I+$&()'eU:3;B2AC#*Lxd5C&(457->.+!&;RAC
R,#!-!*!Vjm/'-!*):3#-gnÉr()-D,qs|»F¦[AC&"#:3Dµqss;tvu?T
Ì q7ùÎ)·n nJúù·fôÆn ·i'lg¹
:3#R4AC9"#A7)&5C#-4-0.¯)57"&\-FGFxd(!:'5=-L&(!b;:33($"+.T¾357-)B21aO/2}2";:3?(
D)&()V3(!5=A7*):;:S.¯8+-!*)*5=-<*)+!&([Zih4:?"&>9-!-!:>%^:#9ûA7%&L&"#°:357B(v&D\R,#!-!*!*@57-*!+!&(@R8G&()X.#"&
&():3()#A7*
TM1%&()"#A7)&5C#-HA=5C'#-X&():35CB(F&V57*)_#%&(!&":D0%m;:VB:;&":M-8!9MR,:'#%r-)#[*)
×3Øfü

£

P¤#¿À$}ÁÁ

wwyXmÀ$

0 1 23

0 1

2 3

0 1

2 3

.
.
.

0

ýOriginal Ordering: 0123

1 2

0

3

1 2 3

0

New Ordering: 1320

1 2 3

ÿ þMost promising node
*
*
]57B):b)ãrÕ'+,:3;&"#:d#:3*):357-!BE.¯)9+4A7
9E!"&bR,M.¯[+4-!*)*X&(4-S57%&()"#A7!&5C#-PA=5C'#-X&()AC%&V5=*)M#%&()_&":TE1%5=-)%#:?9;&5C#-XR,>%^#!-!*J&"#P:.Z#:?*):M&(!>#+,:3;&"#:3E57-±&(!L&":Q%^:#9§#-!L";:3?(¼5C&":3;&5C#-°&"#P&(!L-).¯[&D&()
+,:%^#:39-!.V#%]1d/N}_-¥R,bB:;&ACG$579+!:3#eU*
T
]#exACGV-!*2lV#:3%8!BB"&&`x#b9&()#[*!
#%[#:3*):35=-)Br&()";:3?(2"+.'jaqss[qeu?TW5C:3"&D3(!5=A7*):#%W3(P-)#8*!N-¥R,V#:3*):*g-!*0.¯8+-!*)*$R8GQ5=-!.:57-!B()):357&57*457"&-!.V&"#>B#Aµ-)#[*)T
/'AC&":3-!;&5CUA7GD&()>";:?3(±ACB#:?5C&(!9«-H.¯[+4-!*X&(!&":$%^xÉACUA72-!*H"#:&V&() ?ñ4î ð.ñ
íðîj^&()Q"&E#%O-)#8*!2;&2&(4;&EACUA57-±&(!>&":fuNRFGH57-4.:57-)	
B JU;A7)Tg¦8;:?3(<R,B57-!V?(
5C&":3;&57#-J%^:#9 &()>%^:#-F&5C:E&M-!*°&(!572%:#-F&5C:_"&M5=M)+
*!;&"*J3(¼5C&":3;&57#-
T¥1a-±R,#&(J#%
&()"L"DAC&()#)B(J&()>-)#[*)N9>G±(!eU>&()>39LÊ¼U;A7)D]-)#8*!Vxd5C&(±39A7AC: °U;A7)
B-):3A=ACGL:3 
4.&d9#:M):3;&"2&579;&"*¥*!5="&-!.N-!*¥;:3N+!:%^::*
T
1a-!"&"*H#%r#:3*!:357-)B$57-!*45CU85=*!!Aµ-!#8*)D]#8#IP&2ATPjaqssuV#:?*):N&()"&2#%#+,:3;&"#:?V&"#
B!57*!>&()0-).¯[&M1aO/2}$57&":3;&5C#-<&"#P&(!
 í.î ñ =í Fð.T±ÀO()Q9#"&E+!:#95=57-)Bg-!#8*)Q57
&()Q-)#8*!>%^:#9«&()0)&aZ#;Yk&QjmS3(!57A=*J-)#[*)>-)#&M.¯8+-!*)*<57-H&()Q+!:U[5C#!N57&":3;&5C#-uVxd5C&(
&()¥9>A7AC"&U;A7)T¼/'-¼.¯[9+4ACDW5CB!:0±()#exH";:3?(&":¥.¯[+4-!*)*¼!357-)BX#-)
5C&":3;&57#-H#%1aO/2}>xd5C&(X#+,:3;&"#:M#:3*):35=-)BQt[Dq;D]­8DW8TÀO()+4;&(H&"#g&()9#"&V+!:3#95757-!BQAC;%
-)#[*)Pjm57-4*!57;&"*±x5C&(JS"&;:ïuN57>q0g­S¥t[TgÀd()L-)xè#+,:3;&"#:_#:3*):357-!B¥57M.#9+4)&"*J457-)B
&()Q#:3*):_#%O#+,:3;&"#:3__&()G°;+!+,;:E57-°&(!57M+4;&(¼;%^&":E:39#eU[57-)BX*!)+4A=57;&"T±Õ'+,:3;&"#:3
-)#&\;+!+,;:357-!BE57-Q&()b+4;&($;:3b*4*)*Q&"#&()V-!*Q#%µ&()b#+,:3;&"#:dA=57"&D8:&57-!57-!BM&()57:#:?5CB57-!A
:A7;&57UV#:3*):357-!B)TWÀd(F!&()V#:?*):357-)BE#%]#+c:?;&"#:3\%^#:\&()V.¯[9+4ACV57-0W5CB):b3(4-)B\%^:#9
t[DOq;D­8D°j^&":3G±#+,:3;&"#:Etgh4:3&D]#+,:3;&"#:0qQ-).¯8&D#+,:3;&"#:­P-).¯8&D-4*±#+,:3;&"#:gA="&2%^#:
U:G$-)#[*)N57-0&()V&":3fur&"#gq;D8Dc­8D4t[T
×3ØeØ

Ú x4Û)Üã¾}>ÝLm¿xmÁÁ}ÁEÞ3}¿x)Üã¾}Lß}}vÛ}À!ÜÀ4à<áY}m¿xv8â
ÀO(457r".&5C#-¥*)3.:35CR,r-F!9MR,:r#%]AC&":?-!;&5CUN;+!+!:3#3()\&"#>+4;:3A7ACAc";:3?(
TrÕV):r&()#;Z
:&57A9+457:357A-!A7G8"'57-g&()2%^#A7AC#fxd57-)B>.&5C#-!b*)9#-!&":3;&"2&(!;&b9-FG¥#%&()E:+,#:&"*
;+!+!:3#3()M#;Yc:_"#9LR,-).h4&257-°.:&57-°.#-!*!5C&5C#-4DµR4!&2-)#P357-)BAC;+!+4:#3(<572A7xeG8M&()
9#"&d.Yc.&5CUE;&dA75=-)B/d1\ACB#:357&(!9T
W	 kÈ+Ð0Ïv Í   dÊHÄÎÅ$Ï  ÐÎ"!ÅRÊXÈÈ+Ï{ÐLÑvÇÅmÍöÎ Ã

,ÄÄÅ4ÄVÆ]Å$Ð0ÏÑFÇ
Õb-)09&()#[*¼#%*!&":3957-!5=-)B¥&()¥.#9+;:3;&5CU0R,-).h4&E#%d+4;:?A7ACA";:33(;+!+!:#?()57ERFG
*)&":39>57-!57-)B<&()±&(!#:&57ANR,#!-4*!Q#-Á+,#5CR4A7S"+,*!!+#R4&57-)*Ö!357-)B¼3( ;+!+!:#?(
T
/¨".#-!*k9&()#[*57&"#J+c:3%#:39 9+45C:35=A\.#9+4;:357#-!R,&`x-@&()S;+!+!:#?()T1-@&(!57
".&5C#-0xbxd57A7A4*):3xÁ#-Q&()#:3&57A
-!ACG["r-!*Q9+45C:?57A4.#9+;:357"#-!&"#*)&":39>57-)dx():
+,:%^#:39-!.L&":-!*!2.¯[57&M-!*J&"#S57A=A7!"&":3;&"L.#-!*!5C&5C#-4N!-!*):Mxd(!57?(JAC&":?-!;&5CUL;+4+!:#3(!
-¥+,:%^#:39R,"&T
ÐÏÐ

ù qiÍÏÎ$#gnYtm·nFÑi^ökm½&%ôlgkm½'Ði^Ð
L
1a-X&()>A75C&":?;&):_x_hc-!*X&()#:&57A-!ACG["V%^#:N&()AC&":3-4;&5CU>;+!+!:3#3()V&"#g#-)"+,.&
#%O+4;:?A7ACA";:33(D-!9ACGJ&"IJ*!57&":35CR4)&57#-
TglN!9>;:E-!*¼o;#jaqss;tvu_+!:#eU[57*)Q-¼-!ACG[57
#%&()2+c*4)+¥#%*!57&":35CR4)&"*Q&":_";:3?(
D-4*g]#exdA7G¥-!*glV#:3%\jaqss[qeud+!:3#eU[57*)2-P-!ACG[57
#%b+4;:3A7A7Ax57-!*)#fxä";:33(T1a-¼&(!57".&57#-xP!99;:?5C$&()"g-4ACG8xd5C&(±4-!5C%^G857-!B
:+!:3"-v&;&57#-
D-!*N9+5C:357A7A7G.#9+4;:3&()+c:3%#:39>-!.#%)&()&"3(!-!5=6F)]!5=-)B\&()*!:35CU*
68!;&5C#-!T
ÀO(!"O-!ACG["3!9\&(!;&&(!OU:3;B'R!:3-!?(!57-)Bb%m.&"#: (:95=-!.#-!"&-F&&():#!B()#)&
&()'";:33(Q"+4.'-!*L&(!;&&()'AC"&aZ`.#"&B#Ac57AC#[;&"*Q;&2*!+!&*
( )4T®H'A7#MAC+& (\:+!:"-F&
&()b()):35="&57\R!:?-!3(!5=-)B2%m.&"#:D[#:r&()b:3;&5C#E#%µ-)#[*)B-!:3;&"*$*!):35=-)BN#-)b5C&":3;&5C#-L#%µ1aO/2}
&"#@&()±-8!9MR,:Q#%-)#[*)0B-):?;&"*å*!):?57-)BJ&(!±+!:U[5C#!05C&":3;&57#-Á#%M1aO/2}Tä)#:357-!B@&()
()):?57"&57ER!:3-43(!57-!B$%^.&"#:_&"#gR,68!A&"#g&()>eU:3;B0R!:3-!?(!57-)B¥A=AC#exd2&()L-4ACG8357b&"#PR,
&()239NO%^#:d57-!.:39-v&ACZ`*)+,-!57-)B*)+!&()Zih4:3"&\";:3?(
T
)#:&(!r*457"&":35CR)&"*V&":\";:3?(-!ACG[57D;x\!9&(!;&'R!:*)&()Zih4:3"&.¯8+4-45C#-E57W!"*
&"#_B-):3;&"V-)#!B(Q-!#8*)DFËD[&"#*!57"&":?5CR4)&"O#-!b-!#8*)&"#_3($#-% , +4:#8.3"#:3T¦[57-4./
Ë .0(21
-!*Ë 3 ,Dxg-3!9$&(!;&&(!¥&":g57.¯8+4-4*)*¼&"#°*)+4&5
( 4kxd(!:6
 4 387:9<;>=,T
®H$xd57A=A49QS&579L#%b>­ ( 1@? ­ ,¨&"#X+,:%#:?9 &(!Q-)#[*)0*!57"&":?5CR4)&5C#-J-!*<&"#±.#A7AC.&_&()
"#A7!&5C#-:4AC&%^:#9 ?(+!:#[."#:TÁÀO()P"+,*!)+#%N*!57&":35CR4)&"*¼&":3P";:3?(
Dd93):*
V&()>:3!-S&579#%&()":35=AACB#:35C&(!9¬*45CU85=*)*SRFGP&():3!-S&579#%&()+;:3A7ACAACB#:?5C&(!9$D
-PRcM.#9+4)&"*S():Ed&()E-F492R,:O#%":?57Aµ-)#[*)dB-):3;&"*jm!9>57-)B>.#-4"&-v&V-)#[*)
.¯[+4-!5C#-L&579fu*!5CU[57*)*>RFG>&()'-8!9MR,:#%µ:357Ac-)#8*!d.¯[+4-!5C#-4+,:%^#:39*LRFG>&()+;:3A7ACA
ACB#:357&(!9$TÀO(!5=5=O*):35CU*$5=-0&()2A75C&":?;&):jmlN!9;:'nÔod;#)Dµqss;t[cº;:3-)A=AiD
qss»uO
,
A .B,DC (2( EE FGFG(( EEH H , FGFG(( EEHJHJIKI FMFBLNLNLNLNLOLOFGFG(( IKFG,S( R F >­ q(
jaqeu
1QP
1UT
/'S)H5=-!.:"DW&()QAC%^&9#"&2%^:3.&5C#-4A+4;:3&2#%\&(!5726F4;&5C#-°;+4+!:#3(!QqQ-!*°-°R,
5CB-)#:3*
TOÀO()QQq V;>­ (W1L&":39ø.#-v&":357R4)&"'L95=-!579A
9#4-v&'&"#L&(!Nh-!AµUA=)2-!*S-PA="#LR,
5CB-)#:3*
T1-0&(457O"D4+c*4)+¥;+!+!:#?()X,D)xd(!57?($:+!:-v&OA=57-);:O"+,*!)+µT
W5CB):3bE()#fxdr&()b+,:%^#:39-!.'#%µ&()b*!57&":35CR4)&"*>&":N";:3?($ACB#:35C&(49èR"*Q#-L&(!"
68!;&5C#-!r#-$E+,:%^.&ACGR4A7-4.*0&":V-!*0#-$_()U[57ACG>5=92R4A=-!.*Q&":V%#Y: ,Z.èqt[D ([.{8D
×3ØO\

P¤#¿À$}ÁÁ

£

wwyXmÀ$

8e+07
Perfect Balance
Imbalanced
Single processor

Nodes Generated

7e+07
6e+07
5e+07
4e+07
3e+07
2e+07
1e+07
0
0

0.2

0.4
0.6
Goal Position

0.8

1

W5CB):28ãb57&":35CR4)&"*0À:E¦8;:?3(P#-F&":3"&5=-)B>À:NrA7-!.
 -!*])^.½qt[TN1a-g&()579MR4A7-4.*P"D
&(!_35CM#%&()_+!:#[."#:3N_,";:3?(H"+4.bU;;:35C'V.¯[+c#-!-v&57AW%m!-!.&57#-Xxd():&()_h:3"&V+!:#[."#:N5=N5CB-!*H¥9f÷"#:35C&`GS#%&()x#:IS-4*H&()
AC#*±*!.:"2N&()+!:#[."#:2-8!9MR,:N57-!.:"T1-X&(!5=bB:3;+4(
D&(!B#A+,#5C&5C#-X:?-)B
%^:#9&()N%m;:A7%&O5=*)V#%W&()N&":Lj^+,#57&5C#
- .¹tvu\&"#&()N%m;:d:357B(v&O5=*)V#%W&()N&":Lj^+,#57&5C#^
- .
qeu?TO]:%^#:39-!.M#%&()M";:?3(SACB#:35C&(!9½ACxrG[d+,;I[Oxd()-g&()NB#A]57O#-P&()N%m;:bAC%&57*)
#%r$+!:#[."#: _ b+,#:&57#-X#%&();:33(°"+4.T)#:M&()"#%r-±579MR4A7-!.*X&":3D9E!3(H#%
&()_";:3?(H"+4._5735CB-)*P&"#Q05=-)BACN+!:3#8.#:Dx(!573(S57-!.:3"'&()M:3!AC&57-!B9#!-F&'#%
":35=A,.Yc#:&d:6F45C:*
T
®H_-).¯[&.#-!5=*):d&()M&()#:&57A+,:%^#:39-!.M#%&()2+4;:?A7ACA
xd5=-!*)#ex ";:33(XACB#:?5C&(!9$T
oOA=AF&(4;&+4;:3A7ACAFxd57-4*)#ex¼";:3?(#+,:3;&"WRFGE*!57"&":?5CR4)&57-!B\&()rxd57-!*)#fx5CD#:.#"&W&():3([Z
#A7*!D&"#g?(°eU57A=;R4AC+!:#[."#:M"#¥3(°+!:#[."#:2+c:3%#:39>b#-)>5C&":3;&57#-H#%r1O/2}T¥¦[57-!.
&():3()#A7*!O;:3E-)#&.¯8+AC#:*g6F)-F&57A7A7GD4&()2h4:3"&d#A7)&5C#-g%#!-4*g9eG¥-)#&:3+!:"-F&-P#+)Z
&579A+4;&(
TÔÀ#°-4):S-k#+4&579A'"#A7)&5C#-DdA7A+!:#[."#:3Lxd5C&(°A7#ex:$&():()#A=*9E!"&
.#9+4A7&"&()57:r!::-F&5C&":3;&57#-L#%µ1O/2}T1a-Q&()x#:3"&r"D)&(!5=-09;Ib&()b+,:%^#:39-!.
#%W+4;:3A7A7Ax57-!*)#fxÖ";:33(g6F4A
&"#&(!;&O#%W":?57A,U:35C#-¥#%]1aO/2}T
1a-E&(!57W-!ACG[57&()\!9+!&5C#-E57W9*)&(!;&V[KL5C-F&W-F!9MR,:#%+!:#[."#:3].¯)57"&W!?(
&(!;&'&()EB#A]57&":3;&5C#-¥x57A7A"&;:3&xd57&()#)&*!A7GTV¦8+,*!)+¥#%+;:3A7ACA
x57-!*)#fx ";:3?(X-PR,
A7!A=;&"*L&()O:3;&57#2#%
&()'-F!9MR,:#%-)#-[ZB#A+4A74B#A57&":3;&5C#->-!#8*)&"#M&(!d-F492R,:#%
-)#[*)rB-):3;&"*PR8GL&()2+!:#[."#:\+,:%^#:3957-)B_&()VB#A5C&":3;&5C#-T#fxdACG$-!*¥lN#:%µB-):?;&"
&(!57r:?;&5C#!57-)BE&()N-)#&57#-0#%&()NA7%&aZ&"#;Z:357B(v&\B#Aµ+c#35C&5C#
- `4D!*).hc-)*$\&()V%^:3.&5C#-0#%]&()
&"#&A
-8!92R,:#%µ-)#[*)r57-L&()B#A
57&":3;&5C#-Q&(!;&\9M4"&R,'.¯8+-!*)*LRc%^#:':3(457-)BE&()'h4:3"&
B#Aµ-!#8*)>jaqss[qeu?TO¦8+,*!)+0#%]+4;:3A7A7A,xd57-!*)#fxÖ";:3?(g-$&(8!\R,V.¯[+!:"*g
( ENH ,a = H = ,Qb
A .
`d( E

I G
F `c( E a = H = ,Qb
q
.
e
q
F
=
`cj"(fkqeu T
a = ,Qb
H

ji­u

b 57U-&(!5=%^#:39M4A7[DrxS-k9+45C:357A=ACGJ.#9+4;:3P&()P+,:%#:?9-!.¥#%N*!5="&":35CR4!&"*¼&":
";:3?(-!*@+4;:3A7ACAxd5=-!*)#exä;:33(%#:,g.qt[DY(h.ji8Dr-!*k)G.qt[Tk):3#9 &()$B:3;+(@57W5CB):YibxO-"d&(!;&+4;:3A7A7AFx57-!*)#fx¼;:33(>xd57A7AF#)&"+,:%^#:39Ô*!57"&":?5CR4)&"*M&":O";:3?(#-!A7G
5C%]&()2B#A57OAC#[;&"*P#-¥&()N%m;:A7%&O#%&(!2";:3?(P"+.T®HEA7"##R":U2&(4;&d+,:%^#:39-!.
×3Ø<l

Ú x4Û)Üã¾}>ÝLm¿xmÁÁ}ÁEÞ3}¿x)Üã¾}Lß}}vÛ}À!ÜÀ4à<áY}m¿xv8â

% Performance Improvement

30

m

Parallel Window Search
Distributed Tree Search

25
20
15
10
5
0
0

0.2

0.4
0.6
Goal Position

0.8

1

W5CB):3i8ãb57"&":35CR)&"*0Àµ:_¦8;:33(gU8T];:?A7ACA,®w57-!*)#fx{¦8;:3?(
#%*457"&":35CR)&"*±&":$";:?3(+,;I[Mx()-)U:&()0B#A\-)#[*)057_AC#8;&"*¼#-¼&(!Q%m;:AC%^&E#%&()
)R"+4.N57B-)*0&"#L_+4;:3&57!A7;:\+!:3#8.#:T
¦[5=957A7;:N-!A7G8"E(!eUQR,-J+!:#eU[57*)*J&"#S.#9+4;:0-)#8*!#:3*):35=-)B¥&"3(4-!5768)M-4*J&"#X*).Z
&":395=-)M&(!E#+4&579A]-F!9MR,:b#%A7!&":3Ejr#F#IP&NAiTCDqss8]]#exACGSnlV#:%Dqss[q;º;:?-)A7AiD
qss»u?TÀd()"b-!ACG["\*)#_57-!*!57;&"'&":-!*457-Q&()'+,:%^#:39-!.'#%AC&":?-!;&5CUV"&":3;&"B5CrR"*
#-0%^;&):\#%&()b+!:#R4AC9"+.D!-!*$-$A7"#R,b!"*0&"#*)&":395=-)b&()b&()#:&57A
+,:%^#:"Z
9-!.\#%cb+4;:&574A7;:&"?(!-!5768)r%^#:bB5CU-_+!:#R4A79$T#exU:D8&()r&":39!"*_&"#V+4:*!57.&]&()
+,:%^#:39-!._57-X9-FGg#%&(!"-!ACG["V;:-)#&VACxrG[V9):3;RACE-4*H9-vGS!9+!&5C#-!
9*)N;:3N&"#F#L.#-!"&":357-457-)B_%#:d:A©Zx#:3A7*$+!:3#R4AC9T
ù q Ìonqpsr i·iökm½+%ôl#km½'Ði^Ð
L
/Ï".#-4*S9&()#8*P#%*)&":?957-!57-!B&()E.#9+4;:3;&5CU_R,-).h4&#%+4;:3A7A7Aµ";:3?(H;+!+!:#?()b57
U[57V9+457:357A[-!ACG["TW®H(4Ub579+4AC9-v&"*N-8!9MR,:#%,&()d;+!+!:3#3()&"#N+4;:3A=ACA)";:3?(
*).:?5CR,*2;:3A=5C:57-2&(457]+4;+,:W5=-M&(!O²O³´
¶!·]¸0"G8&"9$TW®HO(!UOA7#b.#-4"&":3!.&"*-_;:&5Ch57A
";:3?(L+4.dB-):?;&"#:&"#M+!:#fU857*!ON&""&"R,*%^#:&()"d.¯[+,:3579-F&T¦8;:3?(L"+.d+4;:39&":3
-¥R,b"&;R4A=57()*0R8GL&(!2!":D!5=-!A7!*!5=-)B)ã
t &(!2.#"&O#%W&()V#+!&5=9A"#A7!&5C#-
D

t &(!2AC%^&aZ&"#;Z:35CB(F&O+,#5C&5C#-Q#%W&()NB#A-!#8*)N5=-0&()2"+4.D
t &(!NR!:3-!?(!57-)B_%m.&"#:D
t &(!N&":2579MR4A7-4.D

t &(!0#A7)&5C#-°*)-!5C&Gkj^%^:3.&5C#-<#%-)#[*)E;&_#:ER,G#-!*<&()Q#+!&579>A"#A=)&5C#-<.#"&_&(!;&

:3+!:"-F&OB#Aµ-!#8*)ïu?D!-!*
t &(!¥()):357&57::3#:gj^&()¥*!5©Y,:-!.QR,&`x-&()$"&579>;&"*-!*¼&":3)$*!57&-!._&"#H&()
-!;:"&OB#A-)#8*!fu?T
×3Øu

P¤#¿À$}ÁÁ

£

wwyXmÀ$

5
4
#Clusters

v

3
2
1
0
2

2.5

3
3.5
4
Branching Factor

4.5

5

W5CB):2»Fã:3-43(!57-!B_4.&"#:b-4*PÕ'+!&579>Ac'!9MR,:\#%\A7!"&":3
10
8
#Clusters

v

6
4
2
0
0

0.2

0.4
0.6
Imbalance

0.8

1

W5CB):2|8ãÀ:N1a9MR4A7-!.N-!*SÕ'+!&579A
'!9MR,:\#%rA=!"&":3
/'A7A4#%&()'.¯8+,:3579-v&*).:357Rc*Q():'x:b:3!-L#-Q-0-\¾r~¼119;B.Z+4357-)B9M4AC&5C+!:#;Z
."#:'!57-!B­+!:#[."#:3T
1a->#!:h:3"&.¯[+,:3579-F&xb.#-!57*):r()#fx&(!#+!&5=9A-8!9MR,:#%µA=!"&":39G>Rc'Yc.&"*
R8Gg%^;&):V#%&()+!:#R4A79ø+4.57-!A7!*457-)BR!:?-!3(!5=-)BL%m.&"#:D&":579MR4A7-!.D-!*X"#A=)&5C#+,#5C&5C#-T]57B):»FD,|8D4-!*Ps*)9#-!"&":?;&"N&(!;&d&(!N#+!&579Aµ-F!9MR,:\#%A7!"&":3d57-!.:"
&()R!:?-!3(!5=-)B0%^.&"#:2*!.:"Lj^x5C&(H0R4A7-!.*±&":Dµ-H#+!&5=9A.#"&N#%bq i8D-!*X&(!B#A
#-P&()2%m;:d:357B(v&d357*)N#%&()M&":fu?D,d&()E579MR4A7-!.25=-!.:"_j^xd5C&(¥>R!:3-!?(!57-)B>%^.&"#:'#%8D
-H#+!&5=9AW.#"&N#%q8D]-!*X&()B#A5=-X&()957*!*!A7M#%&()&":fu?Dµ#:MV&()_B#A-)#[*)9#fU
&"#>&(!N:35CB(F&d57*!V#%&()N&":0j^xd5C&(¥>R4A7-!.*$&":3DR4:3-!3(457-)B%m.&"#:#%8D-4*g-¥#+4&579A
.#"&O#%\qu?T1-$-)#L"2*!57*0#-!N57-)BACV-8!9MRc:\#%A74"&":3OACxrG[\+,:%^#:39R,"&T
1a-Q&()V-).¯8&.¯[+c:?579-F&xb%#[!#-Q&()b.Yc.&\#%#+,:3;&"#:r#:3*):357-!B)TWW5CB!:Eqt*!9#-[Z
"&":3;&"O&(!;&\9+4AC#fG85=-)BM#+,:3;&"#:d#:3*):357-!BE!O-$57-!.:b5=-L&(!V#+!&579A,-8!92R,:r#%WA7!aZ
&":3D'-!*]57B):¼qt;RÖ()#exL&(4;&Q#+,:3;&"#:0#:3*!:357-)Bwjm!57-)B°+,:%.&Q#:3*):?57-)B°5=-)%#:?9;&5C#-u
:4AC&_57-H9#:¥57B-!5©h-F&E5=9+!:#fU9-v&#fU:L-)#H#:?*):357-)BX&()¥#A7)&5C#-¼-)#[*)$57_+,#5©Z
&5C#-)*%^;:&(!:&"#2&(!O:35CB(F&57-&()d&":T1-&(!57.¯[+,:3579-F&&()d";:?3(L&":;:3OR4A7-!.*xd5C&(
×3Ø<w

Ú x4Û)Üã¾}>ÝLm¿xmÁÁ}ÁEÞ3}¿x)Üã¾}Lß}}vÛ}À!ÜÀ4à<áY}m¿xv8â

10
8
#Clusters

v

6
4
2
0
0

0.2

0.4
0.6
0.8
Solution Position

1

1.8

20

Speedup

Change in Optimal #Clusters

]57B):2s8ã'#A]#5C&5C#-¥-4*PÕ'+!&579>Ac'!9MR,:O#%\A7!"&":3

10

1.6

1.4

1.2

1.0
0
0.0

0.8

0.4

0.0

Solution Position

0.4

0.8

Solution Position

a) Ordering effect on optimal #clusters

b) Solution position effect on speedup

]57B):qt[ãrÕb:3*):357-!BM.Y,.&
MR!:3-!?(!57-)BN%m.&"#:\#%_-!*Q->#+!&5=9A.#&#%q­8TÀO()*45C+L57->&()'+4AC#&#[):3xd()-L&()B#A
57r+,#5C&57#-)*0#-$&()N%m;:dAC%^&\#%W+4;:&574A7;:\+!:#[."#: _ d)R4"+.T
x	y ÇÅez|{~}]z

-Æ 9ÍÎÅJ
ÀO()E9+457:357Aµ-4*g&()#:3&57A.#9+4;:35="#-!+!:"-F&"*X57-g&(!M+!:3U85C#4".&57#-S5=-!*!57;&"M&(!;&
AC&":3-4;&5CUN+4;:3A=ACA
";:3?(g"&":3;&"B57O+,:%^#:39xA7A
!-!*):O*45©Yc:3-v&O.#-!*45C&5C#-!D!-4*0&(!;&d+,:"Z
%^#:39-!.r&":-!*4]*!#.¯)57"&]xd(!57?(_-MR,r!"*E&"#V)&"#9;&57A=ACGM"A7.&W&":3;&"B5C-!*M+4;:39&":
"&"&57-!B\%#:-)xÁ+!:#R4A79Td#fxU:eD&()V:3!AC&r#%]&()"N"&4*!5C\;:N-)#&[KL5C-F&r%#:)&"#;Z
9;&57A=ACGQ*!&":3957-!5=-)BM&(!2;+!+!:#+4:357;&"N"&O#%"&":?;&"B5CTrÕV-)NA757957&;&5C#-$57r&(!;&'57-)%^#:39;&5C#!"*¥&"#B-):3;&"M&()N%^#:39M4A7O-!*$&"#Q.#-v&":3#A&()V.¯[+,:3579-F&D!!?(gdB#A+,#5C&5C#-D[5=O-)#&
I[-)#exd-g57-$*)U;-!.T/'-)#&():dA=5795C&;&5C#-$5=r&(!;&d"#92#%]&(!2!9+!&5C#-!D)43(¥.#-!"&-F&
R!:3-43(!57-!B$%^.&"#:D;:Q-)#&2:3A757"&57_%^#:_9-vGH;+!+A757;&5C#-!TQ/'2g:!AC&DxQ-)*<¥9&()#[*
Ê

×3Ø<

£

P¤#¿À$}ÁÁ

wwyXmÀ$

&"#)&"#9;&5=A7ACGLAC.&r#+!&579A,"&":3;&"B57\%#:\:3A©Zx#:?A7*Q+!:#R4AC9>B5CU-$5=-)%#:?9;&5C#-L&(!;&O57
U;57A7;RACT
1a-J:3"+,#-!">&"#X&(!5=2-)*
Dx0*!*¼P9?(!57-)QAC;:3-!5=-)Bg.#9+,#-)-F&_&"#P&()¥²\³µ´
¶!·¸"G[aZ
&"9$T²O³´
¶!·]¸Á9:B9>-vG¼#%'&()¥;+!+!:#?()&"#J+4;:3A7ACAr";:?3(*457!*°&(!$+!:U[5C#!
".&5C#-TW;:39&":3O-¥RcV"&\&(4;&O.#-v&":#A,&(!V&"IQ*457"&":35CR)&5C#->&":3;&"BGD4&()VAC#*0RA7-!ïZ
57-)BV"&":?;&"B5CDv-!*_&(!\#:3*):357-!B&"?(!-!5768)T]1-_+;:&57!A7;:eD&(!O"&":3;&"B5C&(4;&-R,"A7.&"*
57-!A=!*)ã
G  lN!9;:O-4*¥od;#)D4:*!&([Zih4:3"&
t b57&":35CR4)&57#-Q&":3;&"B
t '!9MR,:O#%]A=!"&":3©q TNTNT +!:#[."#:?
B  Õb-
DÕ'Y 
t ªµ#*¥R4A=-!57-)h
-  5CB(FRc#:eD!od-!*)#|9 
t :#[."#:AC.&5C#
t ]:3.-F&;BE#%W&I¥*!57&":35CR4)&"*Q)+,#-0:68)"& t  TNTNT qtt S
G  *Õ'%mªµ5="&D!À5=AÕ'%mªµ57"&
t '#-!;&5=-)B>"&":3;&"B
:  t[TCT "&3I 57 
t /'-F&575C+4;&"#:G0AC#*$RA7-!57-)B_&":357BB$
B  W5©¯[*
D!ªµ#8AiD!À'Õ'1dY/ 
t Õb:3*):357-!6
ÀO(!b4":\57rA7AC#ex*0&"#*)&":39>57-)'&()V&`G8+,r#%"&":3;&"B57\&"#R,'!*0%#:OEB5CU-0+!:3#R4AC9$T
#exU:D!R,!"V!?($_*)575C#-Q57r*!5©KQ!AC&&"#9;IVx5C&()#)&5CB-!5©hc-v&r57-)%^#:39;&5C#-Q;R,#)&
&()r";:3?(E+4.DF²\³´
¶4·¸QA7"#b(!&();+;R457A75C&Gb#%49;I[57-)BA=AF-).3;:G2"&":?;&"BGM"AC.&57#-!T
r"*±#-±&()3(!;:?.&":357"&572#%\$";:33(°"+4.D²\³´
¶4·¸)&"#9>;&57A7ACGX.#-[h4B):3N5C&"AC%&"#
#+!&579>5C¥+,:%^#:39-!.P#-°+4;:&57!A=;:>;+!+4A75=;&5C#-
Tå¦[9+4A7$+!:#R4AC9>>;:P%*kL&":?57-!57-)B
.¯)9+4AC&"#MN93(457-)OAC;:3-457-)BV"G["&"9$Dvx(!573(5=-_&):3-AC;:3-4&()\#+!&579>A!"&":3;&"B5C&"#2;+!+4A7G
&"#+4;:&5=!A7;:$A7"0#%E";:3?(Ö"+4.T/+!+4ACG[57-)B<93(!5=-)HAC;:3-!57-!B°&"##+!&5=95CX"#%&x;:3
;+!+4A=57;&5C#-!Q(!QR,-k+):3)*57-k#&():¥;:$#%M:";:3?(
TÉ)#:g.¯[9+ACDzS57-F&"#-¹jaqs>s iu
(!0;+!+4A=5C*k¼5=957A7;:L&"3(!-!5=6F)X&"#)&"#9;&5=A7ACGkG8-F&()5CS+!:#RAC9_Z`"+,5©hgU:35C#-4L#%
.#-!"&":?57-v&aZ`3;&57"%m.&5C#-¥ACB#:357&(!9Tod";:33(g57-0#&():d;:O#%].#9+)&":d5C-4.N(!\G[5CA7*)*
579>57A7;:b57*)b#%r!"&"#95C;RAC_-vU[5C:#-!9-v&N;+4+4A75C*P&"#g.#9+4!&":N-)&`x#:I[Ljmr(!;&"&3(4;:m÷aD
rACU:3&Dr
n ,B):3[Dbqss»FV¦8&"-!I857&"DW57(!:D
n 
(!-)B)Dqss»u-!*&"#J5=-v&":3.&57Ug(F49-[Z
.#9+4!&":Q57-F&":%m.Sjm!:3-)IcD'¦[)I;U[5C:35 ÷[D\n§)#A7GDMqss8Vªµ5CR,:39>-
DVqss|u?T{ÀO(457x#:I@57
!-!5=6F)V57-$A=AC#exd5=-)BR,#&($+!:#R4A79_Z`"+,5©h'-!*¥;:3?(!5C&".&):3.Z`"+,5©hV%^;&):d&"#L57d- 
c)-!.b&()
3(!#57.#%"&":3;&"B5CW-!*M57-2;+!+ACG85=-)Bd*!;+!&57U"#%^&`xr;:r&"3(!-4576F!µ&"#'+4;:3A7A7A";:3?(
T²\³´
¶!·]¸
A7"#S#;Y,:3S%:39x#:I°&(!;&-<+c#&"-F&57A7A7G±)&"#9;&"¥R,#&(<"&;&570-!*¼*)G[-!957L"#%&x;:3
!"&"#9>5C;&5C#-
T
À#+,:%^#:39+4;:3A7A7Ac;:33(
D
²\³´
¶4·¸X.¯[)&"&()V%#A=AC#exd5=-)B"&"+4ã
q;TdÀd57957-)B%:#9 9+4A7+!:#R4A79Ö57-!"&-4.;:;+!&):*DfU;;:G[57-)BO?(E&":3;&"BGN+4;:39&":
5=-!*)+,-!*)-F&ACGTµ1a-L#:3*):&"#E68!5C:-L.Y,.&5CUb9+4A7"&D8+!:#R4A79;:b"AC.&"*L%^:#9
U;:357&`G0#%]*!#957-!\-!*¥+4;:3A7ACA
;:?3(!5C&".&!:T
­8Td!#:'?(S+!:#R4AC9p57-!"&-!.D
²\³´
¶4·¸°;+!&):%;&!:d#%&(!2+!:#RAC9p"+.2&(!;&b;:
I[-)#fxd-$&"#>Y,.&d&()2#+!&579A
?()#57.N#%"&":3;&"BGTÀO()"2%;&):3O57-!A74*)ã
×\Ù

Ú x4Û)Üã¾}>ÝLm¿xmÁÁ}ÁEÞ3}¿x)Üã¾}Lß}}vÛ}À!ÜÀ4à<áY}m¿xv8â
õa·kmlöO#Æi'lg¹egk!öÑtm·~(QQbÀO()NeU:3;BMR4:3-!3(457-)B_%^.&"#:'#%]&()2";:3?(¥&":T
¶n8#Ó ·iÐÑ i^ö n ··tm·]J9OcQVÀO()L*!5©Y,:-!.D]#-°eU:3;BDR,&`x-<&()>&579;&"*<*!57aZ
&-4.g&"#°±B#A-)#[*)¥-!*@&()g&":3!¥*!57"&-!.g&"#J&()gA7#""&B#A'-)#[*)TkÀO(45757
&579;&"*X%^:#9ø&()(!A7AC#fxÔ";:33(XR8GP.#9+4)&57-)BL&()*!5©Y,:-!.ER,&`x-H&()EaZ
&5=9;&"*k*457"&-!.¥&"#<&()PB#A;&Q&()gR,B57-4-!57-)BX#%b&()P;:33(w-!*&()P9>A7AC"&
&579;&"*$*!57&-!.b&"#&()bB#A,%#:OA7A,AC;%-)#8*!r#%µ&()V(!A=AC#exw";:3?(
D4957-8!&()
.&4Aµ*!57&-!.V%:3#9&()N:#8#&O-)#[*)V&"#&()MAC;%]-!#8*)T
 p ÆÒ km½kmlö ns^(QQVÀO()2*)B:3M&"#Lxd(!57?(¥-)#[*)d;:E!-)U-!A7G0*457"&":35CR)&"*$9#-)BQ)R)Z
&":3d57-0&()M";:33(P"+4.T
 tmkm½ ó t
ö k)Ñ itl7:9<QVÀO()QAC%^&aZ&"#;Z:35CB(F&E+,#57&5C#-J#%d&()>h:3"&E#+!&579A"#A7)&57#-J-)#[*)T
Àd(!5757"&579;&"*>%:#9É&()d(4A7AC#exk";:33(LR8G_*!&":3957-!5=-)Bbxd(!57?()R!&":3d.#-v&5=-!
-!#8*)Oxd5C&(0&()NAC#fx&d"&579>;&"*¥*!57"&-4.\&"#&()NB#AT
¶n8#Ó ·iÐÑ i^ö¥a
õ ·kmlö ##i'l#¹e#k!öÑ t·	WJ(.Ê QbÀO()r:3;&5C#b#%,-)#8*!.¯[+4-!*!*_Rc&x-&()\):"Z
:3-v&d-4*$+!:U[5C#!r1aO/2}M5C&":3;&5C#-4T
!;&):M%:#9¨&(!-)#-[ZB#A5C&":?;&5C#-!V:+4:"-F&N;&"&":35CR4)&"b%^#:N&()&"&2"D-4*H&()
&":3;&"BG2&(!;&W:3!AC&µ5=-2&()R,"&µ+,:%^#:39-4.'jm()#:3&""&W:3!-N&5=9fu
:3+!:"-F&]&().#:3:.&
A=5©h;&57#-$#%&(!N+!:#R4A795=-!"&-!.N%^#:d_B5CU-P"&":3;&"BG¥?()#57.T
8Td:#R4AC9å;&"&":35CR4)&";:.#9MR457-)*2xd5C&(V&(!.#::"+,#-!*457-)B\A7"-!*2;:3%*Mµ&":?57-!57-)B
.¯)9+4A7M&"#±X9?(!57-)0AC;:3-457-)BPG8"&"9¥T±®H$!"g)T ¼j b!57-4A7-
DrqssuE&"#H57-!*!!.0
*!575C#-P&":_%:3#9p&()E+!:.Z`A=5©h4*P"TN/Ô:?!AC2R"E5=dB-):?;&"*X%#:b3(H.#-4.+!&
&"#QR,MAC;:?-)*
D.#:3:"+,#-!*!57-!B&"#>3(X#%&(!M"&":3;&"BGS*)5757#-!OA757&"*g;R,#eUE&(!;&b-)*
&"#>RcN9>*)T
)TdÀ#0"#ACUMQ-)x +!:#R4AC9¥Dc²\³´
¶4·¸J+c:3%#:39>d>3(!A7AC#fx ";:3?(S&():#)B(g&()M"+.E!-F&57A
:3#)B(!ACG­;tt[D ttt-)#[*);:.¯[+4-!*!*
TW1%MB#A,57-)#&%^#!-!*>*4):357-)BV&(!'(4A7AC#ex";:3?(
D
&(!$%;&):3_#%&()0&":¥;:3¥A7!A7;&"*;&&(!5=M+,#57-F&-!*¼!"*¼&"#±57-4*).¯°;+!+!:3#+!:357;&"
:?!ACr%^:#9&()Er)T *!;&;R4"T
8TdÀd()NAC;:3-)*¥:3!ACr:.#9>9-!*¥"&":?;&"BG¥3()#57.dB5CU-$&()2%;&):3\#%W&()2-)xÖ+4:#R4AC9
+4.T²\³µ´
¶!·¸X&(!-¥57-!5C&5=;&"_+;:3A7ACA,";:3?($%^:#9&()b:#8#&\#%&(!N"+4.D!9+AC#eG[57-)B
&(!M"AC.&"*P"&":3;&"B5CTO)#:'9>-vG$;+!+4A=57;&5C#-!D)&(!257-!5C&5=A,.¯8+4-45C#-$&;I#-!ACG$%^x
.#-!*!d-4*$*)#Fd-)#&OB:;&ACG$Y,.&d&()V:?!-v&5=9b#%]&(!2";:3?(gACB#:357&(!9$T
ÀO(!E*)3.:35CR,*P&'#%%;&!:V-!*S&()_9#!-F&'#%&579E&"#¥"+,-!*P#-P&(!_5=-!5C&57AW²\³´
¶!·]¸
5C&":3;&57#-P;:E3()#-PR"*g#-P#):'.¯8+,:35=9-v&A*!;&L&"#LG[5CA7*$&(!E9#&()AC+4%^!Aµ57-)%^#:39;&5C#57-0&()N3()#:&""&\&579T¦8;:3?(!57-)B_-)#)B(g5C&":3;&5C#-!r#%]&()N+4:#R4AC9"+4.M!-v&5=A,­;tt[D tttQ-)#[*)
;:PB-):3;&"*&;I0AC&(4- qt<".#-!*!>#-&(!g+!:#RAC9 *)#95=-!xg&""&"*T{¦8+,-!*!57-!B
AC&579$&(!-&(4579G¼G[5CA7*<::#-!#!57-)%^#:39;&57#-¼Rc4"$%;&!:#%'&()¥&":P*)#±-)#&
"&;R45=A75C$!-F&57Ar"U:3AOACUA=*)#ex-57-¼&()$&":Tk¦8;:?3(!57-!B±*!*!5C&5C#-4A57&":3;&5C#-!57-¼B-!:3A
*)#8V-)#&N5CB-45©h-F&ACGg579+4:#eU&()68!A757&`G¥#%r57-)%^#:39;&5C#-X-!*X&(!&579:68!5C:9-v&'B:#fx
.¯[+c#-!-v&57A=ACGT@1a9+!:#fU*;+!+!:3#3()Q9G@5=-!A7!*)Q+,:%^#:3957-)BX&()P57-!5C&57A\;:33(k!-v&5=A\&()
"&;R45=A75C&`G$#%&()"+4.:?()NQ+!:3.:35CR,*gACUAD
#:V+c:?5C#8*457A7ACG0)+
*!;&57-)BL&()>)T Q3()#5=.
-!*¥*;÷"!&57-)B_&()V+4;:3A=ACA
";:3?(g;+!+!:3#3()*)G8-4957A7ACGL*!):357-!BM.¯[)&5C#-
T
×\×

£

P¤#¿À$}ÁÁ

wwyXmÀ$

'U[57;&5C#-g®5C&(457-0:#R4A79 'U[57;&5C#-¥&x-X:3#R4AC9
#9>57- ¦8&;&
% ::#: 19MR R!%
% ::#: 19MR R!%
q+4)AC ¦8&*gU
t[T ttt q;Tì»fv| t[T tt)q ­8T |s t[T tt­ ­8T »» t[T tt| )T ||s
/UFB>ºA7) q;T ;ts 8T ts t[T ­>| i i8T s| q;T ;ts 8T ts t[T ­|>i i8T s|
odzS
¦8&*gU
t[T t;t s8T [q t[T tt)q t[T tt­ t[T ­;t v8T tt t[T tt­ t[T7q|
/UFB>ºA7) ­8T iv qq;T >­ i t[T7q.v| q;T7qt ­8Tiv qq;T ­>i t[T7q.v| q;T7qt
À];R4ACq;ã:#R4AC9);&!:2ºA7!2'U857;&57#-!
] :%^#:3957-!B2->57-45C&57A[(!A7A7#exk;:33(Q(!A="#NR,->(!#exd-&"#MR,O.Yc.&57U'57-#&():+;:3A7ACA
";:3?(0:";:3?(
T)#:\.¯)9+4A7D!¦))&"&-):Vjaqss»u+,:%#:?9+;:3A7ACAc";:3?(0#%&()'h4:3"&%xÁ1aO/2}
5C&":3;&57#-!&`xd57.V*!!:357-)BN+;:3A7ACA";:33(g57->#:?*):r&"#_*!&":3957-)&()V-F492R,:#%57-!*45CU85=*!!A8&"I[
&(!;&_()#!A=*±R,L*!5="&":35CR4!&"*X&"#P?(¼+!:#[."#:TH#F#IJ&EAiT¼jaqssuEA7"#P+c:3%#:39 -¼57-!5C&57A
(!A=AC#ex";:3?(57-<#:3*):_&"#H#R!&57-¼9#:30!:3;&"¥#+,:3;&"#:#:3*):?57-)BX57-)%^#:39;&5C#-°&"#±!"057:#:3*!:357-)BV&()'";:3?(L"+.T1-3(0"D[&()9#!-v&#%
&579O:36F!57:*&"#2+,:%^#:39Ô&(!d.¯[&":3
57-!57&57A,";:33(P57\957-4579AcG&OB:;&ACG$579+!:#eUO&()N+,:%^#:39-!.b#%W&()V#eU:?A7Aµ";:?3(¥&IT
ÀO(!g"AC.&"*%;&):3>?(k*)9#-!"&":3;&"g°5CB-!5Ch-v&5=d- 
)-!.0#-&()¥#+!&579>AO";:3?(
"&":3;&"BGTE/A7&()#)B(S%;&!:_UA7!'-H?(!-)B*):39>;&57A7ACG¥%^:#9ø#-)E+!:#R4A79p&"#$&()-).¯[&D
3(E%^;&)::957-4%m5C:3ACGV"&;R4A7R,&`x-_ACUA7#%)&()39&":T/'WO:4AC&D.#9+4)&57-)B&()
U;A7)#%
&()"'%;&):3;&rMA7#exwACUA5=-&()&":+4:#eU[57*)NB#8#8*Q57-!*457;&5C#-#%
&(!"&":34.&):
#%W&()N-F&5C:N&":3TÀO(!h
 "U[57;&5C#-P®w5C&(!57-$:#R4AC9W_-v&":357d57-$À];R4AC>q2()#ex &()2"&-4*!;:3*
*)U[57;&5C#-<#%O?(%;&!:0UA7!>#eU:LA7Ar";:33(¼&":30A7UA7THÀO()Q:!A7&M;:$eU:3;B*@#fU:
s|L+!:#R4A79p57-!&-!.b57-g&(!2h4%^&"-S+4)ACE*)#957- , -!*X­;tQ+!:#R4AC9ø57-!&-!.5=-g&()E:#R,#&
;:399#&5C#->+4A7-!-!5=-)BN*)#957-T]#&(Q#%
&()"&""&*!#957-!;:*)3.:35CR,*57-&(!-).¯[&.&5C#-
T
ÀO()MAC#ex UA7!O57-$&()2.#A7!9-4O57-!*!5=;&"V&(!;&d&()2%;&):3d+!:3#eU[57*)NB#8#[*g57-!*457;&"#:\#%&()
"&":34.&):d#%
&(!d+!:#RAC9Ï"+4.b;&rA7A4ACUA=57->&()d&":T1-L.#-v&":3&D8&(!
 "'U85=;&5C#-0&x:3#R4AC92&;R4AC'-v&":?5C3()#exw&()b"&-!*!;:?*L*)U[57;&5C#-L#%&()bU:?;BV%;&):3U;A7)_jmU:3;B*
#eU:LA7ArACUA7_57-°3(&":fuM#fU:>A7A+!:#R4A79 "+.TJÀO()0A7;:B:U;A7)_57-°&()"$.#A749-!
57-!*457;&"b&(!;&O&()N%^;&):-$.Y,.&5CUACG¥*!57&57-)B!573(R,&`x-g*!5CYc:-F&\+!:#RAC9"+4.T
²O³´
¶!·]¸S5=xd:35C&"&"-057-$-!*057r)::-F&ACG>579+4AC9-F&"*>#-$-0-\¾r~­8D)#-0ªµ5=-F[¯Lx#:IFZ
"&;&5C#-4L!357-)BX&()PW;:3A=ACAOºb5C:&!AdzP?(!57-)°jmº'zHu>.#99M4-!57;&5C#-k"#%&x;:3DO#-°'~r
/'AC+4(!P!57-)BP-<5=9+4AC9-F&;&5C#-°#%d]#5©¯J&(!:*!D#-<®w57-!*)#fxdM'À:3!-!-457-)BgyeUS&():3*!
-!*$r57ACI_&():3*!D[-!*LE*!57"&":357R4)&"*>yvU;M"G["&"9!5=-)B2odzP1ïTF®HV;:bA7"#E)::-F&ACG57-FUaZ
&5CB;&57-!Bb9-!]#%*)G[-!957A=ACGV"xd5C&?(!57-)BRc&x-&":3;&"B5C*!!:357-)BO.¯[)&5C#-W&(!+4:#R4AC9
"&":34.&):V#:O-FU857:#-!9-F&O3(!-!BT
 ¡¢¤£O¥¦§¤¨ª©«W¬­2¥®¦-¯<°±¦¥¥²q³<´Oµµ¶©¥·³Q¬¨¸O©¹¥ºk»¹²O®¦¼«W²O½¥¶®¾§¥¶¬¥+²<¨2¦»¹²O½©¹´¿Q¥¿[¿Q´O¥U¦¨&¦£O¥K«Wºª¨´O²N¦¾¨2°À¦»¹ºª¥U¬¥ÁN´<»¹¬¥¿
¦¨­2¥²O¥Â¬¼«W¦¥¦£O»¹®¾¿O«¦¼«+°Ã¨W¬¾¦£<¥®"¥³<¬¨2¸O©¹¥ºª®¡

×\eò

Ú x4Û)Üã¾}>ÝLm¿xmÁÁ}ÁEÞ3}¿x)Üã¾}Lß}}vÛ}À!ÜÀ4à<áY}m¿xv8â
ÄW	 z$ÅÈ\Å$ÏvÂkÅ  ÎÐ
ÄY}XÅmÍ;ÄªÎÍ

1a-±&(!572".&5C#-±x>x57A7AW+!:-v&N.¯[+,:3579-F&A:3!AC&V&(4;&M.#9+4;:3>&()+,:%^#:39-4.#%r#):
*!;+!&57UE+;:3A7ACAW";:3?(±"&":3;&"BGSxd5C&(S?(Xh!¯[*H"&":3;&"BGX!"*X.¯)A7!5CUA7G¥%#:VA7AW+4:#R4AC9
57-!&-!.T1a-$+4;:&574A7;:D[x2xd57A7AU:35C%^GL&(!N%#A=AC#exd5=-)B(vG8+,#&()"O57-0&(457\".&5C#-
ã
t ²O³´
¶!·]¸ _ b*!;+!&5CU_";:3?(X&"3(!-4576F!-XR,M4"*g&"#$?(!5CU"+,*!)+S#eU:NQU;;:35C&`G
#%;+!+A757;&5C#-!D[-4*$-g*)9#-4"&":3;&"2579+!:#eU*0:3!AC&\#fU:!357-)B_h!¯[*$"&":3;&"BG$%^#:
A=A
+!:#R4A795=-!"&-!.T
t Àd()E*4;+!&5CU";:3?(H&"3(!-4576F!E-X9+AC#eG¥&":?57-!57-)BL.¯[9+4AC'%:3#9¬9M!A7&5C+4AC2;+4+4A757Z
&57#-!&"#J5=9+!:#fU¥#eU:3A=AO+,:%^#:39-!.Tk®Hgxd57A=A*!9#-!"&":3;&"g&(!57!357-)BH&""&57-!BJ-!*
&":?57-!57-)B_.¯)9+4ACd.#92R45=-)*0%:3#9&`x#L;+!+A757;&5C#-$*)#9>57-!T
t Àd()¥AC;:3-!5=-)BH.#9+,#-)-v&#%2²O³´
¶!·]¸Á57;R4AC$&"#°5CB-!5©hc-v&ACGJ#)&"+,:%#:?9 -vG<#%b&()
&"&"*¼h!¯[*<&":3;&"B5C57-<&":39E#%+!:*!57.&5=-)Bg&()0R,"&_"&":3;&"BG<%#:SB5CU-¼+4:#R4AC9
5=-!"&-!.T
t 1a-X*!*!5C&57#-g&"#0.Y,.&5CUACGP9>;I857-!BL#-)"&":?;&"BGS?()#57._%#:V0-)x¹+!:#RAC9$D²\³´
¶!·]¸¼57
9#"&.Yc.&57Ug#%bA7A&""&"*;+!+4:#3()>;&9;I85=-)BHA7A\"&":3;&"BG*)5735C#-!E%#:LXB5CU+4:#R4AC957-4"&-!.T
t /ÉU;:?5C&`GP#%AC;:3-457-)B>&"?(!-!5768)b-XR,E4"*g&"#¥357"&b57-S"&":3;&"BGX"AC.&5C#-H-!*S#;Y,:
+c*4)+>#fU:d":357Ac";:3?(
D[&()#)B(Q+,:%^#:39-!.xd57A7A4U;:G>%:#9è#-)VAC;:3-457-)BN&"?(!-!5768)
&"#L-)#&():T
Æ iq ÍÏÎ)n8ÐÑÔhöt p

Ð
Õb-)#%!#):W&""&*)#9>57-!]57]&()xA7A©ZI[-)#fxd-Nh%&"-_+4!AC+!:3#R4AC9$T]ÀO(!57+!:#R4A79å.#-!5="&]#%
ÇPdB:?57*N.#-F&57-!57-)B&57AC-8!9MR,:*N#-)&"#Oh4%^&"-
D-!*Md57-!BAC9+!&GV&57AC+,#57&5C#-NA7AC*2&()
È êÊÉÀË'&57ACT/ &57ACb-$R,'9#fU*g57-F&"#_&()bR4A7-)I>+c#35C&5C#-L%:#9-$*;÷".-F&O+,#5C&5C#-DF:3!AC&57-)B
57-X&()%^#):V#+,:3;&"#:32)+D*)#fxd-
DAC%^&Dµ-!*X:357B(v&T>b5CU-±&()57-!5C&5=A-!*XB#A.#-[h4B):3;&57#-!D
&()M+!:#R4AC9½57O&"#>h-!*P>"68)-!.E#%9#eU'&"#Q:3(P&()EB#AiTd/Ô9+4ACNB#AW.#-[h4B!:3;&5C#57O3()#exd-g57-¥W5CB):qq;TrÀO()NzS-!(!;&"&-Sb57"&-!.M!!-!.&5C#-g+!:#fU857*!\-g*!95=5CR4A7'()!:357"&57
%^#:&(!5=+!:#RAC9$Dv-!*>xb!"d&()EqttM+!:#RAC9Ï57-!&-!.+4:#eU[57*)*5=->lV#:N% _ &""&r*!;&Ljaqss[qeu?T
I
Õb!:r.#-!*¥;+!+4A=57;&5C#-0*)#957-$5=&(!V:#R,#&r;:?9ä9#&5C#-0+4A=-!-!57-)BM+!:#R4A79$TÀµ:3*45C&5C#-!A
9#&5C#-N+4A7-!-!5=-)B9&()#8*4;:U:GV.#"&A7G'x()-V;+!+4A757*b&"#d\:#R,#&;:39$DR,!"?(\÷"#57-F&(!
-g5=-[h-!5C&"b-8!92R,:O#%-)BA7O&"#xd(4573(¥57&O-g9#fUM%^:#9äB57U-g.#-[h4B!:3;&5C#-
D4-4*$R,!"
.#A7A75=5C#-?()I[57-)B@9E!"&0R,S+c:3%#:39*%^#:03(Ö;:39 B9-v&T:35CB<+!:#fU85=*)0<*!&57AC*
*).:?5C+!&5C#-°#%d&()$A74A7;&5C#-!_-).3;:GJ&"#H*)&":39>57-)Q&()0+c#35C&5C#-°#%d&()0-!*<.Y,.&"#:>57&()>;x#:I["+4.B5CU-H&(!)::-F&÷a#5=-v&N-)BA7>jaqs|su?T>)#:M#):V.¯8+,:35=9-v&Dx4"&()
+4;:39&":3$*).h-)*%^#:$&()H!9>¼> i;t¼:3#Rc#&$;:39x5C&(k35©¯k*)B:¥#%2%^:*)#9 ()#fxd-w57W5CB):°q­8TÀO(!g5Cg-4*@A7G#!&>#%b&()g:3#F#9û57&()g39¥%^#:>3(#%b#):&"&>+!:#RAC9D
R4)&\xNU;;:GQ&()257-!57&57A,-!*$B#Aµ;:?9p.#-[h4B!:3;&5C#-!\&"#>B-):3;&"E­;t+!:#R4AC95=-!"&-!.TÀO()
kmi'l

Ì¡Í¥½«2´O®"¥·¨W°À¦»ºª¥½¶¨²O®¦"¬¼«W»¹²¦®Î<§¤¥·¥®¦»¹ºY«W¦¥¿Ï¦£O¥®"¥¶¬»«W©c¬´O²X¦»ºª¥U°±¨2¬¾¦£O¥U¦§¤¨ª©«W¬­2¥®¦¯<°±¦¥¥¶²[³O´<µµ©¹¥·³<¬¨¸<©¹¥º
»¹²O®¦¼«W²O½¥®·´<®"»²<­Ð¦£O¥²Q´<º¸>¥¶¬-¨2°Ñ¬¥ÁN´<»¹¬¥¿S²O¨¿Q¥&¥¶ÒQ³«W²O®"»¹¨²<®°Ã¨2¬·¦£<¥®"¥ª³<¬¨2¸O©¹¥ºª®³O´<¸O©¹»¹®"£O¥¿»¹²$Ó¨2¬"°¶Ô ®K³«W³>¥¶¬
«2²O¿X¦£<¥Uºª¥«2²Ï²O¨¿Q¥¥¶ÒQ³«2²<®"»¹¨²Ï¦»¹ºª¥«Õ¥Â¬¼«2­¥¿Ð¨Õ¥¶¬ ¦£O¥U²<¥¶Ò¦Ñ¯Õ¥-©Ö«¬­¥®¦³<¬¨2¸O©¹¥ºG»¹²O®¦¼«W²O½¥¶®¡

×\ü

£

P¤#¿À$}ÁÁ

wwyXmÀ$

1

2

3

4

5

6

7

8

9 10

11

12 13 14

15

W5CB):3qq;ãW5C%&"-g+4)ACV+4:#R4AC957-!&-!.

W5CB!:q­8ãoO#R,#&d;:?9ä9#&5C#-$+A7-!-!57-!BM+!:3#R4AC957-!"&-4.
:#R,#&;:39É+4;&(+4A7-4-!57-)B'+!:#R4A79Ô57W+4;:&574A7;:3ACG2*45©KL!AC&WR,!"O.#-457*):35=-)BbU:G_+c#35CR4AC
;:39ø9#eU9-v&V:3!AC&d5=-PQ";:3?(S+4.Mx5C&(g-X57-[hc-!5C&"VR!:3-43(!57-!B>%m.&"#:T®H_-!.#[*)E#-)
+,#5CRAC9#fUN5Cb%^#:\3(E÷"#57-F&D8:3!AC&57-!BE57-Q_R!:3-43(!57-!B2%m.&"#:O#U% i8TÀd()b:"#A7)&57#-L#%&()
9#fU'-gR,2*)&":395=-)*$R8GQ&(!M!":eD4-!*¥%^#:d&(!"2.¯[+,:3579-F&\xM3(!#F#"E:#A7)&5C#-$#%
qN*)B:3T
Õb!:&(!5C:3*<&""&>*!#957-!"&()¥;:&5©h5=A;:33(k"+4.g57-<xd(4573(¼+4;:?9&":357-4A7!*!57-!B
R!:3-43(!57-!B\%^.&"#:D&":3579MR4A7-!.D;"#A7!&5C#-N.#"&D()):?57"&57W::3#:D-4*2AC%^&aZ&"#;Z:35CB(F&µB#AF+,#5C&5C#-$R,b"+,5©h4*QRFGL&()N!":eT]®H2B-):3;&"M­;t_+!:3#R4AC957-!"&-!.r%^#:O!"V57-Q&()V.¯[+,:3579-F&T
)#:#):W%#):3&(M&"&*)#957-
Dx\57-F&"B:3;&"\#):#ex->ZR4"*EU:357#-_#%4&()d¦['ªµH-)#-4A757-);:
+4A7-4-):Njm;:3:&"&'n{®HA7*Dµqss­u\57-F&"#L²\³µ´
¶!·¸TÀµ#.#-)%^#:39x5C&(0&()M²\³µ´
¶!·¸H;:?3(!5C&".&!:D
&()$57-F&"B:3;&"*¼+4A7-4-):E!&57A75CM1d/N}g";:?3(57-!&"*°#%&()$"&aZ`W5C:3"&";:3?(9&()#[*¼9_Z
+4AC#fG*XRFGH¦['ªµ]T
~3(±+4A7-S:+45C:V"&"+jhcA7A757-)BL-X#+c-H.#-4*!5C&5C#-S#:N(!-!*4A757-)B>0&(!:;&?u'57
&":;&"*Wb"+4;:?;&"O-)#8*!57-M&()\";:3?("+4.r&"#bR,.¯[+4AC#:*T®H\.#9+4!&"&(!r.#&#%4'+4A7"#A7!&5C#-Xb&()-F!9MR,:b#%#+,:3;&5C#-!b-!*H.#-4"&":357-F&V57-S&()_+4A7-
D
-!*S&()*!5="&-!._&"#$&()
B#A]57\"&579>;&"*g!5=-)B_&()2-8!92R,:O#%W:9>57-!57-)$B 
exdT®HM"A7.&­;t+!:3#R4AC9ä57-4"&-!.\%^#:
#):].¯8+,:35=9-v&µ%:3#9Ö&()R4AC#[I[aZx#:?A7*
D;Àµ#fx:3]#%!'-)#5iD-!*M9#-)IGFZ`-!*[ZR4-!-4+A7-!-!57-!B
*)#95=-!T
À#M.:;&"'&""&"D8x:3!-?(L+4:#R4AC9Ô57-4"&-!.d9E!AC&5C+ACr&579DF#-!.d%^#:?(L+;:3A7ACA
";:3?(g"&":?;&"BG¥57-$57"#A7;&57#-
TÀO()N";:3?(g"&":?;&"BG$&(!;&O+!:#[*!!.r&(!NR,"&O"+,*!)+$57O.#-457*[Z
:*°&"#PR,L&()e
 ".#:3:.& XA75©hc;&5C#-±#%O&(!Q.#::3"+,#-!*!57-)B¥;:33(<&":Q%#:)T g&"#HAC;:3-
T
À"&"r;::3!-#×
- iE+!:#[."#:3#%->-r¾'r~­N-!*>#-Q|2*!57"&":357R4)&"*Ex#:3I8"&;&57#-!457-)B
×\Ø

Ú x4Û)Üã¾}>ÝLm¿xmÁÁ}ÁEÞ3}¿x)Üã¾}Lß}}vÛ}À!ÜÀ4à<áY}m¿xv8â
/d+!+4:#3(
q;!AC W57A©Z3q; odzS W57A©Z`ozP
lN!9;:O-!*god;# ­8T t­
i8T |s i8T7qt
»FT i
:3;&([Zih4:3"&
i8T |­ s8Tì»»
8T s;t
Æ ùLqÙØ4ù
)T 
­8T [q
ÚÀÛLqiÍÀÚ ÜJÝ{qiÍ Æ ÜµÍ$qÙØJÞ
#92R57-)*[Z)T 
i[q;T ;t
À];R4AC2­8ãb57&":35CR4)&"*$À:E¦[;:33(P¦[+c*4)+$oO!A7&
ºbz°T1a-E&()h4:3"&W"&W#%4.¯[+,:3579-F&µxh!¯MA7A8"&":3;&"BG_3(!#57.WR4)&]#-)\-!*EU;:3GN&()\"&":3;&"BG
3(!#57.2!-!*!:O.#-!57*):?;&5C#-
TÀO()N*!%^!A7&+;:39&":?()#57.;:ã
G .¹b57"&":357R4)&"*0Àµ:3E¦8;:3?(
t b57&":35CR4)&57#-Q&":3;&"B
t '!9MR,:O#%]A=!"&":3Ï.q
B .ÏÕbt ªµ#*¥R4A=-!57-)*
- .¹5CB(FR,#:
t :#[."#:AC.&5C#
t ]:3.-F&;BE#%W&I¥*!57&":35CR4)&"*Q)+,#-0:68)"&Ï.Ô;t 
G .ÔÀ57A^Õ'%^ª57"&
t '#-!;&5=-)B>"&":3;&"B
t /'-F&575C+4;&"#:G0AC#*$RA7-!57-)B_&":357BB[: .¹t
B .Ô]5C¯8*
t Õb:3*):357-!
®HH.#9+4;:3P&()P:!A7&>#%M)T fZ`AC.&"*Á"&":3;&"B5C0&"#<3(Á&":3;&"BGk!*@.¯)A7!5CUA7G
%^#:¥A7A'+!:#R4AC9æ57-!&-!.T¦8+,*!!+k:3!AC&Q%#:$U;;:35C#4Q&":3;&"BG*!575C#-!QU:?;B*å#fU:
A7A\+4:#R4AC9ç57-4"&-!.>;:3P()#fxd-@57-@&()¥%^#A7AC#ex57-)B±".&5C#-4TÀd()$R,"&>U:?;BX+c*4)+@57
(!5CB(4A75CB(F&"*@57-@?(w"TåÀO()H)T J:!AC&>;:S;+4&):*@R8G+,:%^#:3957-)B±J&"-[Z%^#A7*k.:3#
U;A757*!;&5C#-¼#-@&()$h4%^&"-+4)A7¥*!;&±-!*@±&():.Z%^#A7*@.:#UA75=*!;&5C#-¼#-&()g:#R,#&;:39
9#&5C#-J+4A7-!-457-)B)D
;:&5©h5=AiDµ-!*±-!#-!A757-);:V+A7-!-!57-!BQ*!;&P"&T$¦8+,5©hA7ACGD¥*)5757#-X&":
57V.:;&"*±%:#9¨&(!&":357-!57-!BQ"M-!*H!"*X&"#¥AC.&V&()"&":3;&"BGX%^#:V&()&""&2T>)T 
"+,*!)+057rU:?;B*g#fU:dA7Ac&""&O"\%^#:\#-)N5C&":?;&5C#-Q#%&(!5=+4:#8.3D)-!*Q&()bh-!AcU;A7)
;:2eU:3;B*P#eU:b.:#aZU;A757*!;&57#-$5C&":3;&5C#-!T
^ÐÑ ^Ò]ÓµÑitl µ^nFÐeÓÆ½ÑeÐ
À"&:!A7&];:3#R4&57-)*_%^#:&()r&`x#NAC&":3-!;&5CUO*457"&":35CR)&5C#-N;+!+4:#3()TÀO()h4%&"-_+)ACD
&():3#Rc#&M;:39§9#&57#-±+4A7-4-!57-)BQ+!:#R4A79$D-!*±&()>;:&5©hc57A";:3?(°+4.>":UQ2+4:#R4AC9
*)#95=-!T~¯[+,:3579-F&A):4AC&;:3'(!#exd-Q57->À];R4ACb­8T)#:r3($*)#9>57-
Dv&(!'.#-F&":#AcU;:?57;R4AC
57\57-4*!57;&"*$!-!*!:\&()^
 "/+!+!:#?ß( .#A7!9>-
T
ÀO(!MR!:3*)&([Zih4:3&'*!5="&":35CR4!&5C#-$+,:%^#:39bA75CB(F&ACG$R,&"&":V&(!-±)T Q%^#:V&()Eh4%^&"-X+4)AC
*!;&N&F()#fxU:D8&()'r)T ':.#99-!*4;&5C#-!#)&"+,:%^#:39¹&()\R4:*)&([Zih4:?"&;+!+!:#?(%^#:&()
:#R,#&29#&57#-J+!:3#R4AC9«*)#9>57-
T0ÀO():#fxA=;RcA7á
* à È :cð >âà¤ãJä:å@5=V&()>:3!AC&N#%O9:B57-)B
Æ qÌ

hji ·i

×\Q\

£

P¤#¿À$}ÁÁ

wwyXmÀ$

¦[&;&
¦)9A7A zg*457!9 ªµ;:B
/U8BQ#8%º;: q;T ­
|8T |­
s8T s
/U8BQ¦8+,*!)+ »FT ­
­8T t )T ts
À];R4AC28ã/U:3;B¦8+,*!)+P¦8&-!*4;:3*$'U857;&57#&()'h4%^&"-Q+4)AC:!AC&xd57&(>&()':#R,#&r9#&5C#-Q+4A7-!-457-)BN:3!AC&-!*Q:3!-!-!5=-)BV&()V.#92R57-)*
*!;&¥&V&():#)B(°r)T 8TÀO()+,:%^#:39-!.57bR,&"&":N&(!-±%#:N&(!_h4%&"-±+4)AC_R4)&N3A75CB(F&ACG
x#:3"N&(!-¥%#:O&(!N:#R,#&O9#&5C#-$+A7-!-!57-!BE*)#9>57-
T
#&"$&(!;&!57-!Bg&()QhAC&":3*kqP+4)A7Q*!;&[Dr²\³´
¶!·]¸w3(!57UP+c*4)+°#%V»;s8T7qe»SA©Z
&()#)B(&()g-8!9MRc:>#%V+!:#[."#:34"*57#-!ACG
G i)TwÀd()"¥+4;:?A7ACAO";:?3(ACB#:35C&(!9>+!:#[*!!.N3)+,:3A757-);:r"+,*!)+Jjm+c*4)+$B:;&":'&(!-$&()2-8!9MR,:O#%W+!:#[."#:3?uR,!N&()
+4;:3A=ACA,ACB#:35C&(!9>O*)#-)#&O.#9+AC&"ACG05795C&;&"N&(!N":357A
ACB#:?5C&(!9$T)#:.¯[9+4ACD!!5=-)B*!57aZ
&":35CR)&"*0&":M;:33(P57-!*!5CU[57*!4A!R!&":O;:M5CB-)*¥&"#L"+4;:?;&"2+!:#[."#:?T1%]B#A-)#[*)
57MAC#8;&"*°#-°&()>%m;:EA7%&E57*)#%\&(!>:35CB(F&9#"&E)R!&":3>57-±&(!L";:3?(¼"+4.DW&()>+4:#8.3"#:
";:3?(!57-)BP&(!57M)R!&":Lxd57A7A6F!5=I[ACGSh-!*H&()QB#Ar-)#[*)D&(8!M&":3957-4;&57-)Bg";:?3(¼;%&":_#-!A7G
L%x¹-)#[*)2.¯[+4-!57#-!TO1a-P.#-F&":3"&D
&(!E":?57AµACB#:?5C&(!9p5=-PQAC%^&aZ&"#;Z:35CB(F&'";:?3(Sxd57A7Aµ.#9_Z
+4AC&"A7GL";:3?(¥A7Ac#&():d3)R!&":&"#&()V.#"&d&():()#A=*LR,%^#:V";:3?(!57-)B-!*Qh-4*!57-)BM&()bB#A
-)#[*)57-X&()>:35CB(F&9#"&2!R!&":TÀO(8!V&()L":357AACB#:?5C&(!9¬xd5=A7A]+c:3%#:39¬*457"+!:#+,#:&57#-!;&"ACG
9#:";:?3(H&(!-XA7A]+!:3#8.#:3V.#92R57-)*X!57-!B>&()+4;:?A7ACA]ACB#:35C&(!9¥TN~3(±&`G8+c_#%+4;:"Z
A7ACA;:33(°;+!+!:#?(J*).:?5CR,*H57-X&(!57V+;+c:N-JG857A7*H)+,:3A75=-);:'+c*4)+±!-!*):N.:3&57.#-!*!57&5C#-!TL¦8#9>ACB#:35C&(49N9#:LAC#"ACGX5795C&;&"L":357A";:?3(
DWR4)&N;&M$+,#&"-v&57AAC#V#%
#eU:?A7A+,:%^#:39-!.jmlNA7MnÉ¦[AC&"#:3Dµqss;tvu?T
²O³´
¶!·]¸ _ b"AC.&5C#-S#%"&":?;&"B5CV57-P&()2h%&"-X+4!ACM*)#9>57-P*!#Fb-)#&b+,:%^#:39p.#-!357aZ
&"-F&ACGVR,&"&":]&(4-M!357-)BO"#9#%)&()"&":3;&"B5C57-257"#A7;&5C#-TWÕb-):"#-M%#:]&(!57*!57;+4+c#5=-v&57-!B
+,:%^#:39-!.b57&()V-!;&):'#%µ&(!'&":?57-!57-)BE*!;&[T/'AC&()#)B(QxV!"'&()V"&":3;&"BGQ&(!;&O3(!57U
&()LRc&N:3!-H&5=9>M&()L.#::3.
& "A735©h;&5C#ß- g%#:E¥B5CU-°+!:#RAC9«57-!&-!.D&(!:>*)#8
-)#&OACxrG[O.¯)57"&\A7;:Oxd57-!-!:%^#:\3(P+!:#RAC957-!"&-!.TÕV-$"#9N+!:3#R4AC957-!"&-4.\#-)
"&":3;&"BG@*!:39;&57A7A7GJ#)&"+,:%^#:39_&()g#&():3TÕV-¼#&():>+!:3#R4AC9ç57-!&-!.&`x#±#:Q9#:
"&":3;&"BG¥AC.&5C#-!\+,:%^#:39A79#"&\6F4A7ACG>xA7AiT
ÀO(457µ+4:#R4AC9{57].¯[.:3R4;&"*R8GN&()r%m.&&(!;&&():\57W"#9\-)#5="5=-!():-F&]5=-M&(!r.#A=AC.&"*
:3!-&579TÀ#E*)9#-!"&":3;&"&()9#4-v&#%
::#:&(4;&-LR,O+!:"-F&5=-&()d&5=957-)BxAC.&
&`xACUX57-!"&-4.>#%V&()gh4%^&"-+4!AC¥+!:#RAC9 j^%^#):Q39A7AiD%#!:L9*!5=!9$Dr-!*%^#):QA7;:B
57-!&-!.?u?D-!*¼&5=9Qh4U0:3!-!E#%d?(@57-!&-!.0xd5C&(¼57*)-F&57Ar"&":3;&"BG¼+4;:39&":3_#--r¾'r~å­8T®H>.#9+)&"&()"&-!*4;:3*H*)U[57;&5C#-X#%&()"+,*!)+4'%^#:Vh4U:34-!'#%&()L9
+!:#RAC9Ï57-!&-!.D8-4*&()-Q*!5CU[57*)\&():!A7&RFG&(!9+ACd9-Q&"#2-4):O&(!:3!AC&57-)#&
Y,.&"*LR8G&()'9;B-!5C&!*!O#%
&()+c*4)+U;A7)TÀO(!5=.#F.KQ5C-v&#%
U;;:357;&5C#-LU:3;B*0#fU:
A7A+4:#R4AC9¬57-4"&-!.N57-±&()>;&"B#:GJ5=VA757"&"*±5=-HÀ;R4A7L$AC#-)Bgxd5C&(X&()>eU:3;B$"+,*!)+
%^#:2&()Q57-!"&-!.M57-H&()L+!:#R4A79«;&"B#:GTg/'M3()#exd-D&()L9#!-F&2#%\::#:M+!:"-F&M5=-H&()
&5795=-)B-R,O6F45C&"OA7;:BD8-!*xd()-_&x#E"&":3;&"B5C+,:%#:?9ÔA79#"&68!A7A7G2xA7AiD&()Ox57-!-):
%^#:d-vG0B5CU-¥:3!-$-¥R,NA79#"&O;:R45C&":?;:GT
À#.#!-F&d%^#:O!3($9>57AC*!5=-)BE*4;&[D!xN#:&OA7Ac+!:#R4A795=-!"&-!.O5=-L&(!bh4%&"-¥+4)AC
*)#95=-0RFGQ&()N9#!-F&O#%]U;:?57-!.V#%W&()N"&":3;&"BG$&5=957-)BE:!A7&TÀO()#"V+4:#R4AC957-!&-!.
×\l

Ú x4Û)Üã¾}>ÝLm¿xmÁÁ}ÁEÞ3}¿x)Üã¾}Lß}}vÛ}À!ÜÀ4à<áY}m¿xv8â
/d+4+!:#3(
q;!AC W57A©Z3q;
odzS
W57ACZ`odzS
lN!9;:dnÏod;# Ti;tSjT tv»u T |;tsPjT ttvu T ;tv»;sPjT Fu T ­;tttSjT tu
:*)&([Zih4:?"& T s>i»PjT7q.Fu T !qs;tSjT t)qeu T vs­[qQjT7qqeu T |;tttSjT t)qeu
)T 
T v
T7qi[qs
Tiv­s
T tæi>i»
À];R4ACV)ãb57&":35CR4)&"*$À:M¦8;:?3(S\A75©hc;&5C#-$oO4AC&
&(!;&G85CA=*$>AC;:'"&":3;&"BG$xd57-4-):O;:2+A7.*¥;&d&(!N&"#+P#%W&()MA757"&T®H2&()-¥hAC&":O&()M*!;&
"&M&"#gI+¼#-!ACGS&()>&"#+<&(!5C:?*H#%r&()L"#:3&"*J+!:3#R4AC9«57-4"&-!.T$ÀO()L57-!"&-!.M57-H&()L&"#+
&(!5C:?*P#%&(!57'hA7&":*H*!;&$"&N;:*4)+4A757;&"*X57-S&()&":?57-!57-)B0"&TÀO()_:3!AC&'#%\²O³´
¶!·]¸ _
+,:%^#:39-!.#-E&(!57µhAC&":*M&":357-!5=-)Bd"&57]()#fxd-E%#:W3(_.¯[+,:3579-F&W57-N&()\W57A©Z3q;H.#A=!9-
T
®H2+,:%^#:395=957A7;:hAC&":?57-)B"&"+¥&"#&(!N:#R,#&O;:39ä9#&57#-$+4A7-!-457-)B_*)#957-$*!;&[T
ÀO(457V;+!+!:#?(±-±R,!*H57-X3(<*)#957-H5=-Xxd(!57?(X+!:#R4AC9¬5=-!"&-!.N*!#¥-)#&NACxrG[
G[5CA7*<HAC;:"&":3;&"BG<xd57-!-!:T±)#:.¯)9+4ACD+!:#R4AC957-!&-!.*):3exd-<%:#9&()$+A7-!-!57-!B
*)#95=-<-4*;:&5©h57Ar*)#9>57-A7Ar*)9#-!&":3;&"¥(!5CB(<U;;:357-!.$#%b"&":3;&"BG<&57957-!BD&(8!A7A
+!:#RAC9¬57-!"&-4.V;:>)&57A=5C*
T_)#:M-FGPB57U-±*)#957-D&()-8!92R,:N-!*X&GF+,#%&""&2
&"#!"br&":357-457-)BM*4;&-0Rcb"AC.&"*0R"*Q#-0&()V9#!-F&#%U;:?57-!.b#%"&":?;&"BGL:3!AC&T
ÀO()$*!5=*)U;-v&;B$#%&()0hAC&":*)Z`*!;&X9&()#[*57E&(!;&">5=-°x(!573(<&x#±"&":?;&"B5CG[5CA7*
579>57A7;:r&57957-!BO9G$R,N*!5=;:3*)*
D)U-Pxd()-¥&()2&x#Q"&":3;&"B5C+,:%#:?9ä9M43(¥R,&"&":&(!#&():+c#35CR4ACb"&":3;&"B57T
ÀO(!S:3!AC&$57-wÀ];R4AC±¼U:357%Gk&(!;&P²\³´
¶4·¸Ô-Ö!&"#9;&57A7ACG"AC.&$+4;:?A7ACAb";:3?(
"&":3;&"B57&(!;&WG857A7*2B:3;&":"+,*!)+M&(!-!57-!B-FGM57-!BAC"&":?;&"BGM%^#:A7AF+!:#R4AC9{57-!&-!.
+4!A=AC*@%^:#9&()ShAC&":3**4;&"&Tè#exU:Db&(!57Q&;R4A7X*!#F$-)#&$57-4*!57;&"X()#ex¬xA7A'&()
9?(!57-)NAC;:?-!57-)B.#9+,#-)-F&d57r+,:%^#:395=-)B;&d&()NA735©h;&5C#-¥&"ITOÕb-)N*4-)B:57-$A=57"&57-)B
#-!ACG$"+,*!!+¥:!A7&d57\&(4;&&()E-F492R,:3O9>G¥R,NR45="*¥R8G$&()M9>;B-!5C&!*)2#%"U:3A]A7;:B
+!:#RAC957-!"&-4.O57-0xd(!5=3(g²\³µ´
¶!·¸H.#:3:.&ACG0+4573I8\&(!VRc&O"&":3;&"BGT
1a-À];R4AC\Nxd9!:d()#fxxA7A[&()d"G["&"9èA75©hW3(Q-)x@&""&+!:#R4AC9¥TWÕb-!.;B57x2+,:%^#:39&"-[Z%^#A7*g.:3#OU;A757*!;&57#-¥-!*g3()#ex{9-gA735©h;&5C#-g::#:%#:3(S;+!+!:#?(
T
ÀO()Mh!¯[*X"&":3;&"B5CjmlN49;:V-!*Xod;#)D:*)&([Zih:3"&?uACxrG[b+457Ig&()E.#:3:.&NA75Ch;&5C##%µM+!:#R4A79Ï57-!"&-4.'&()5C:#exd-D8-!^
* çÐèÑéëê!"5C&*)575C#->&":'&"#M+45=I&()bA75Ch;&5C##%N&()S+!:#RAC9¿57-4"&-!.TÏ¦[5CB-!5©hc-!.gU;A7)Q;:SB;&():*Á!5=-)BJ°+45C:*"&!*)-F&>&aZ&"&
-!*±;:3L()#fxd-±57-X+;:-v&(!"N%^#A7AC#fxd57-)B$&()L9-±::3#:T>1a-H3(°#%r&()hA7&":*±*!;&¥&D
)T L5CB-!5Ch-v&A7GQ#!&"+c:3%#:39>O5C&():h!¯[*P;+4+!:#3(j^+ ìt[T tuOx()-¥+!:3*!57.&57-)B>&()E.#:3:.&
A735©h;&5C#-0#%!-!-0+!:#R4AC95=-!"&-!.T
Æ 7q ù

mÓÐÑnY·i'l#¹»µ^nFÐfÓ#½ÑeÐ
1a-0&(!57r.¯[+c:?579-F&\²O³´
¶!·]¸H"AC.&\&()V#+4&579A
-8!92R,:r#%WA7!"&":3r&"#L!"b%#:d3(¥+4:#R4AC9
57-!&-!.TG$.#92R45=-!57-)B_&()N%^;&):d#%*!57"&":357R4)&"*Q&":2";:?3(g-4*$+4;:3A7A7A,xd57-!*)#fxÖ";:3?(
D
5C&O57r+,#35CR4AC'&"#>3(45CU2R,&"&":O+,:%^#:39-!.V&(4-$xd()-$?(g;+!+4:#3(P57\!"*¥5=-$57"#A7;&5C#-T
ÀO(!PA7!&":357-)B±ACB#:?5C&(!9¿5=&""&"*w!5=-)Bq;Dd­8Dd-!*°A74"&":3L#M
- i°+!:#[."#:3L#%N-r¾'r~ ­Q%^#:N&()_h4%^&"-H+4!ACD:#R,#&V9#&5C#-H+A7-!-!57-!B)D,-4*J¦[ªå*)#9>57-!D-!*H457-)BHq
-!*0­EA7!"&":3%^#:&(!dh4%^&"-Q+4)ACb*)#95=->#-0E*!57"&":357R4)&"*-)&x#:3I>#%]|M\TÀµ"&r:3!AC&
%^#:O&()2A74"&":357-)BACB#:?5C&(!9;:N+4:"-F&"*¥57-$À];R4AC28T
s¸½

×\<u

£

P¤#¿À$}ÁÁ

wwyXmÀ$

/+!+!:#?(
q ;)A7 W57A©Z3q; odzS W57A©Z`ozP
qM\A7!"&":
 ­8T t­
i8T ­[q
i;t[T t)q
i­8Tì»;
­>\A7!"&":3
 »FT t;
i)T s»
|;t[T ts
»;s8T s|
Q\A7!"&":3
> i8T |
vs8T » ÍcÜ Ì qÙÞÜ q8T7qe»
)T fZ`-cr¾r~
ÞÜLq:ÚdÜ q­>i8T ­ ÍcÜßÝgqÊÛÜ
Æ {Þ qÙÛJØ
#9MR457-!*[Z)T 
»;8T s;t
À];R4AC28ã\A7!"&":35=-)B¦[+c*4)+¥oO4AC&
/+!+!:3#3(
qErA7!"&":
­LrA7!"&":?
0rA7!"&":?
r)T 

A7-!-457-)B  ºbz¥Z3q;
qt|8T i
F» Tis
q.v8T t
F» T t
q­s8T7q
í
Í Û Æ qiÍ Û
Úq:Ú Ì
í

q;)AC W57A©Z3q;
odzS
W57A©Z`odzS
T >iPjT t;Fu T vsPjT ttvu Tì»;tPjT7qqeu Tì»»»;|gjT t)qeu
Tis> iPjT ­u Ti»;|PjT ttvu T s;t;v|gjT t;Fu Tì»»»;|gjT t­u
Tì»fv|sPjT7q|u T |>i>i»gjT ttvu T !qgjT7qqeu T SjT t)qeu
Ti»;> i
T ­
T vs­[q
T7q.v|[q
À];R4AC i8ã\A7!"&":35=-)B\A75©hc;&5C#-$oO4AC&

À];R4ACL¥*)9#-!"&":?;&"N&(!;&²\³´
¶!·]¸ _ N!&"#9;&57"&":?;&"BGJ"AC.&5C#-J!57-)BPr)T 0#)&"+,:"Z
%^#:39r-vGLh!¯[*0"&":3;&"BG$57-QA79#"&\A7A,*)#95=-!D)-!*0ACxrG[\+,:%#:?9R,"&rxd(!-L&(!hcAC&":*
*!;&_"&\;:V!*
TÀO()'&;R4ACbA7"#57-!*!5=;&"&(!;&r&()'#+!&579>Ac-8!9MR,:#%µA=!"&":3#-0U:3;B
U;;:35C%:#9è#-)b*)#957->&"#E-!#&():D[&(F4:5=-)%#:?57-)BN&()'-)*L%#:\)&"#9;&5="A7.&5C#->#%µ&(!57
+4;:39&":T1a-L&(!'º'z§.¯8+,:3579-v&D[R,!"'#-!ACG>5CB(v&r+!:3#8.#:3r;:VU;57A7;R4AC'x'.¯[+,:"Z
579-F&"*<xd5C&(kqL#:­SA7!"&":?2%^#:_3(¼+!:#RAC9§57-4"&-!.TXÀO()0.#92R45=-)*J:3!AC&E;:0;B57.#A7AC.&"*Q%^:#9Ï&(!&""&r"%^#:&()dh4%^&"->+4!AC-!*L:#R,#&;:?9É9#&5C#-L+4A7-4-!57-)BN*)#9>57-!T
ÀO(!NA75©hc;&5C#-$:4AC&r%#:3()#57.2#%W-8!9MR,:\#%WA=!"&":3O;:3N()#ex-¥57-¥À];R4AC i8TÕV-$&()
hAC&":3*$*!;&"&D
)T _#)&"+,:%^#:39\A7Ach4¯8*¥&":3;&"B5Cd;&5CB-!5Ch-!.VACUA
#%W+ ìdt[T t­8T
Æ Êq Ýøúù·ô#nY·i'l#¹»µ^nFÐfÓ#½ÑeÐ

1a-0&(!57.¯8+,:35=9-v&xN*)9#-!"&":?;&"M²\³´
¶!·]¸_ r;R457A=5C&`G&"#+57IQ9&()#[*L#%]#:3*):?57-)BE&()b&":
%^#:.¯8+4-45C#-
T±À];R4ACg»P()#fxd_&()0:!A7&M#%&(!57E.¯[+c:?579-F&TJ)#:&()Qh4%^&"-¼+4)A7D&()
&`x#$&""&"*Sh!¯[*S#:3*):35=-)B;:3$jm¾+Dªµ%&Do5CB(v&D
'#ex-u'-!*jm'#exd-
Dªµ%&Do5CB(F&D¾d+cu?TN!#:
&()0:#R,#&;:39ç9#&57#-¼+4A7-!-!5=-)Bg*)#95=-
D&`x#Hh!¯[*<#:3*):35=-)B_;:$&""&"*@.#::3"+,#-!*!57-)BP&"#
#:3*):?57-)B\÷"#57-F&9#eUr%^:#9É&(!'R"#%µ&()';:?9è&"#_&()'-!*L.Yc.&"#:eD4-!*L#:3*):357-!B\÷"#57-v&r9#fU
%^:#9ä&()M-!*¥.Y,.&"#:'h4:3"&*)#exd-g&"#L&(!NR4"M#%&()M;:39½A7"&TdÕb-!A7GL#-)M#:3*):35=-)B>57O4"*¥%^#:
&()2;:3&5©h57A,*)#95=-
T
1a-<&(!57E.¯8+,:35=9-v&Dr)T PG85CA=*!2&(!QR,"&"+,*!!+°:3!AC&E%#:A7Ar*!;&;R"DhcAC&":*<#:
!-[hcAC&":*
T$1a-J&(!Q;:&5Ch57A*!#957-
D]R,!"Q+c:3%.&M#:3*):357-!Bg57-)%^#:39;&5C#-°57EU;57A7;R4ACL&()
ÀÕ'1aO/ä&":3;&"BG°A7#PG[5CA7*!N&()LR,"&E+,#5CRAC"+,*!)+°:!AC&TgÀO()Q.#92R45=-)*J:3!AC&E;:
B-):3;&"*P!57-!BE&(!Vh4%^&"-$+4)ACN-4*$:#R,#&O;:39ä9#&57#-$+4A7-!-457-)BE+!:#R4AC95=-!"&-!.T
À];R4ACN|(!#exdr&()V:3!AC&r#%]A75C%^G[57-)BE#:3*):357-!BE+4:#R4AC9#-0&()bhcAC&":*$-!*$!-)hAC&":*
*!;&X"&TH®w(!57A70)T SACxrG[_G857A7*!N&(!LR,"&_U:3;BP"+,*!)+DW&()0AC;:3-!5=-)BP"G["&"9*)#8
×\w

Ú x4Û)Üã¾}>ÝLm¿xmÁÁ}ÁEÞ3}¿x)Üã¾}Lß}}vÛ}À!ÜÀ4à<áY}m¿xv8â
/+!+!:3#3(
q ;!AC W57A©Z3q; odzS W57A©Z3q;
Õb:3*):357-!BQq
v s8T |
vs8T | i)Tì»;s |8T v­
Õb:3*):357-!B_­
 ­8T t­
i8T !q i8T !q |;t[T t
À'Õ'1d/
; t[Tì»»
i>i8T7q »;8T ;t »;s8T ;t
ªµ#8A
; t[Tì»;
i|8T s­ »;8T » |­8T ­
r)T 
Æ LØ qÙÛ¤Ú Í Ì ùLq:ÚÀÛ ÚÀÞLq Æ4Ì ÞÑÚq Ì Þ
r#92R45=-)*[Z)T 
8T ­|
À;RACM»FãÕ':3*!:357-)B>¦8+,*!)+$od!AC&
/+!+!:#?(
W5©¯[*
ÀÕ'1aO/
ª#[A
)T 

q;)A7 ]5=A©Z3q;
ozP
Tis»;­gjT Fu Tì»i>i»¥jT ttvu q;T tttSjT t)qeu
Ti[qsSjT tv»u Tì»8qi»¥jT ttvu T ;t)qiPjT ­[qeu
Ti|gjT Fu T [qi»¥jT ttvu Tis|XjT t­u
Tì»æt is
T7q.v­s
T 
À;RAC2|8ãÕ':3*!:357-)BrA735©h;&5C#-$od!AC&

/:&5©hc57A
s8T ­­
í
ÜmÍ qÊØù
i;t[T i­
ÜmÍ qÊØù
í

W57A©Z`ozP
q;T tttSjT ttvu
T ;tttSjT t­u
Tì»tttSjT ttvu
T tttt

)- #&G85CA=*&()dR,"&A75©hc;&5C#->):?.G#-L4-[hAC&":*>*!;&[DF&(!#)B(L57&*)#83(45CU&(!dR,"&
:4AC&#-L&()OhcAC&":*>*4;&2"&TÕV-&()dhAC&":*L*!;&M&D)r)T N#)&"+,:%^#:39h!¯[*>"&":3;&"B57
;&d35CB-!5©h-4.'U;A7)V#%W+ ìt[T t­_#:OR,&"&":T
Æ q
Æ ó tmk!ôõakm½kmlöi'lg¹

8ÐeÓÆ½ÑeÐ
ª#*°R4A7-457-)Bg57B-!5©h-F&ACGHYc.&_&(!>+,:%^#:39-!.L#%OP9f÷"#:35C&GH#%\+4;:3A7A7AACB#:357&(!9T
®w()-Xx#:3IS57b*!57U857*!*gU-!A7GP9#-)B$+4:#8.3"#:3D-)#$AC#*XRA7-!57-)B057V-).3;:GT_d):?57"&57
";:3?(@%^:68)-v&A7G<.:;&"0(!57B(!ACGJ5C:3:B!A7;:";:?3("+4.Drxd(!5=3(¼:4AC&57-AC#*k579MR4A7-!.
R,&`x-$+!:#[."#:?T²\³´
¶4·¸X+,:3957&AC#*0RA7-!57-)B_#+,:3;&5C#-4*4):357-)B_5C&":3;&57#-!r#%µ1aO/2}T
/+!:#[."#:Nx5C&(H-)#[*)VU;57A7;R4A7#-±5C&V#+,-±A75="&V9GH*)#-!;&"L"#9#:2A=AW#%&(!>-)#[*)b&"#
:68)"&5=-)B_+!:#[."#:T'5735C#-!\&(!;&Yc.&'"G8&"9+,:%#:?9-!.N57-!A=!*)b*)57*!57-!BEx()-0&"#
R4A7-4.Q&(!¥AC#*
D5=*)-v&57%G[57-)BSP+4:#8.3"#:%^:#9xd(!57?(<&"#H:6F!"&_x#:IcD-4**)57*!57-!BS()#fx
9E!3($x#:I0&"#>*)#-4;&"T
1a-_&()h4:3"&WAC#*_R4A=-!57-)B'.¯8+,:35=9-v&]x\&""&²\³´
¶4·¸ _ W;R45=A75C&`G2&"#N"AC.&&()\;+!+!:3#+!:357;&"
+!:#[."#:E+,#A7A757-!B¥"&":3;&"BGTH®H$(!U$579+4AC9-F&"*±&()0"G[-!3(!:#-)#!M:#!-!*°:#R45=-J-!*°&()
:3-!*!#9 +,#A7A=57-)Bg;+!+4:#3()T¼Õb-<&()$-r¾'r~Ï­8DS+!:#[."#Q: _ $îû-)5CB(FR,#:3M;:3Q+,#A7A7*J%^#:
x#:IÖjm!57-)BH&(!g-r¾'rY~ _ (FGF+,:3!Rc0&"#+,#AC#BGªD î.#::"+,#-!*4_&"s
# 79<; ,Mu_xd():5=-&()
ºbz -FU857:#-!9-F&Dg+!:3#8.#: _ E:35CB(F&M-!*<AC%^&M-)5CB(FR,#:32;:3L+,#A7AC*j I îï.p­gR,!"Q&()
x#:I8&;&5C#-!\;:N.#-!-!.&"*$xd5C&(0E:357-)BE&"#+,#AC#BG!u?TÀO()b:4AC&#%]&(!57.¯[+,:3579-F&;:3bA=57"&"*
57-$À];R4AC2s8T
À];R4ACs0()#fxdb&(!;&V#-!.;B5=-°)T QG[5CA7*!&()R,"&V"+,*!)+X57-H9#"&V"M-!*XACxrG[
G[5CA7*!d&()MR,"&'"+,*!)+P#-ghcAC&":*S*!;&L&TV/9#-!BL&()Mh!¯[*g:3!AC&Dc-)#057-)BACE;+!+!:#?(
#)&"+,:%^#:39r&()2#&():3\#-¥A=A*!;&"&T
µøn

×\

£

P¤#¿À$}ÁÁ

wwyXmÀ$

/+!+!:3#3(
q;)AC W57A©Z3q; ozP W57A©Z`ozP
5CB(FR,#:
­8T t­
i8T ­[q |8T |[q
»FTi»
o-!*)#9
»t[Tì»; |8T7qe»
>i8T t
ÆÆ q7ù Æ
r)T 
;t[T 
Ú Æ qÙØÍ ÜÍ$q7ùµÍ ÜØLqÙÞßÝ
r#92R45=-)*[Z)T 
>i8Tì»8q
À];R4AC2s8ãªµ#*¥rA7-!57-!BL¦8+,*!)+$oO4AC&
/+!+!:#?( q;)A7 ]5=A©Z3q;
ozP
W57A©Z`ozP
5CB(vR,#: T ;tæigjT t|u T »i­gjT ttvu T ­s»gjT ­[qeu T ­;tttSjT t;Fu
od-4*)#9
T isSjT tu T v­|gjT ttvu Tì»tæiPjT tu T |;tttSjT ttvu
)T 
T |;tæi
T7q.v­s
T t;v|
T tttt
À;R4A7qt[ãª#*PA=-!57-)BLrA=5©h;&57#-Qod!AC&
]À ;R4ACbqtV!99>;:35C&()\A75©hc;&5C#-2:3!AC&#%4&()h!¯[*_"&":3;&"B5C5=-M.#9+;:357"#-E&"#b&()
)T A=5©h;&57#-!T)#:'3(P#%&(!VhAC&":*g*!;&"&D,)T _#)&"+,:%^#:39O-FGQh!¯[*¥"&":3;&"BG
xd5C&($>5CB-!5©hc-!.b#%]+¾ìdt[T t;#:OR,&"&":T
ÀO(!X.#-!*wAC#*wR4A7-!5=-)BJ.¯[+,:3579-F&Q*!9#-!"&":3;&"S²\³´
¶!·]¸ _ 0;R457A=5C&`G&"#@*)&":?957-)
&()¥#+4&579AO9#4-v&#%bx#:I¼&"#°*)#-4;&"g)+,#-:68)"&Tk1%b&"#8#JA75C&"&AC$x#:I57*!#-!;&"*
Dr&()
:68)"&57-!BH+!:#[."#:>x57A7Ar"#8#-@:&):?-%#:Q9#:¥x#:IcTk1%b&"#F#°9M!?(@x#:I@57*!#-!;&"*
Dr&()
B:3-F&57-)BS+!:#[."#:_xd57A=A"#8#-<Rc057-<*!-)B:_#%dR,.#95=-)BP57*4ACTSÀ];R4ACXqq0A757"&M&()0:4AC&2#%
&(!57.¯8+,:3579-v&D8*)9#-!"&":?;&57-)BN#-!.';B57-&(4;&&()'AC;:3-!57-!BbG8"&"957;+;R4ACd#%,.Y,.&5CUACG
"AC.&5=-)BPAC#*°R4A7-457-)Bg"&":?;&"B5CD.¯).+!&Mx()-±&()0!-[hcAC&":*H&""&_"E%^:#9§&(!h4%^&"+4)A7g;:P4"* j^#-k&()P-cr¾r~-!*@#-k&()S*!57"&":357R4)&"*-)&x#:I#%Vx#:I["&;&5C#-!ïu?TÖÀO()
.#9MR457-)*g:!AC&';:MB-):3;&"*H!5=-)B&":357-!5=-)B>"'%^:#9p&(!Nh4%^&"-S+4)AC2-4*g:#R,#&';:39
9#&5C#-¥+4A7-!-!5=-)BE-cr¾r~.¯[9+ACT
À];R4ACHq­XA757&2&()¥A=5©h;&57#-<!:3.G°:3!AC&T°r)T X*)#F-!#&E+,:%^#:395CB-45©h-F&ACG
R,&"&":&(!-&()rh!¯[*"&":3;&"B5C%^#:&()O!-[hcAC&":**!;&[DFR4)&*)#8+,:%^#:39Ô5CB-!5Ch-v&A7G2R,&"&":
j^+ ìdt[T t;Fu\&(!-$&()Nh!¯8*$&":3;&"B5C%#:O&(!bhAC&":*¥*4;&[T
/d+4+!:#3(
q;)AC W57ACZ3q; odzS W57ACZ`odzS ºbz¥Z3q;
;t MZ`-r¾'r~
­8T t­
i8T ­[q i8T7qt
8T vs
ÚqÙÜJÛ
;t MZ`-r¾'r~
i[q;T s i[q;T ­>i
i;t[T7q
»FT vs
Æ ùLqÙÜÞ
)T fZ`-r¾'r~
[q;T ­|
ÚdÜ{qCù Æ Ü4ù{qÙÜ¤Ú Ü Ì qmÍ8ù
»FT ;t
#9MR457-)*[Zr)T 
8T 
í
À;RACqq;ãb57"&":?5CR4)&5C#-0/'9#!-F&¦8+,*!)+$oO3!AC&
×2leÙ

Ú x4Û)Üã¾}>ÝLm¿xmÁÁ}ÁEÞ3}¿x)Üã¾}Lß}}vÛ}À!ÜÀ4à<áY}m¿xv8â
/+!+!:#?( q;)A7 ]5=A©Z3q;
ozP
W57A©Z`ozP
;t
T >isgjT ­>iu T gjT ttvu T7qs|XjT ttvu T ;tttSjT t;Fu
;t
T v>i[qLjT7qe»u T i>i»¥jT ttvu T |;t)qiPjT t)qeu Tì»tttSjT t)qeu
)T 
T ;t>i
T7q.v­s
T7qs|
T tæi>i»
À;RACq­8ãb57"&":?5CR4)&5C#-Q/'9#!-F&'rA735©h;&5C#-$od!AC&
/+!+!:#?(
¦8+,*!)+
Ón g·nYuYk
»f)T ­
od-4*)#9ä:3#8.#:ªµ
»t[Tì»;
ª#[A]Õb:3*):357-!B
i|8T s­
À:3-!"%^#:39;&5C#-SÕ':3*):35=-)B
i>i8T7q
lN!9>;:d-!*¥o;#
i8T |s
b57"&":357R4)&"*$À:
i8T |­
W5©¯[*¥~U;A7!;&5C#-Jq
i8T !q
qMrA=!"&":
i8T ­[q
5CB(vR,#:dª
i8T ­[q
;t b57&":35CR4)&57#i8T ­[q
­>rA=!"&":3
i)T s»
;t b57&":35CR4)&57#i[q;T s
W5©¯[*¥~U;A7!;&5C#-P­
vs8T |
QrA=!"&":3
vs8T »
%ð{¹{qdtñÏ@iëò{n8ô
ô ó,Ñ ·k)Ñ nY¹in8Ð i8T v
À];R4ACq8ãrr#92R45=-!;&5C#-0#%)T od.#99-!*!;&57#-!
Fö pep nxlµôÆk)ÑitlµÐ
¾+&"#&(457Q+c#5=-v&DdA=A.¯[+,:3579-F&Q(!U±(!#exd-&()X:4AC&Q#%_²\³µ´
¶!·¸¹"A7.&57-)B¼<357-)BAC
"&":3;&"BGD\A7A#&():L"&":3;&"BG¼:!A7&_Rc5=-)Bgh4¯8*
T°1-¼&(457_.¯8+,:35=9-v&Ex¥A7AC#ex¨²\³´
¶!·]¸&"#
"AC.&'A7A
"&":3;&"BGP3()#57.;&d#-!.M%#:B5CU-g+!:#R4AC9-4*$.¯8!&"M&()2+4;:3A7ACA
;:33(gxd5C&(
&()b:.#99-!*)*$"&":3;&"B57T®HN&()-$.#9+4;:b&()V:4AC&&"#3(0h!¯[*0"&":3;&"BG±j^&()bh!¯[*
"&":3;&"BGÁ?()#57.±57$eU:3;B*Ö#fU:PA7Ab+!:3#R4AC957-!"&-4.$-!*wA7Ab+,#5CR4A7P3(!#57.$#%E#&():
"&":3;&"BGQ*)5757#-!?u?TW/Á:3-!*)#9"&#%µ;tE+!:#R4AC9>%^:#9É&(!Oh4%^&"-Q+4)AC'*)#957-L57"A7.&"*
-!*:?!-#õ
- iJ+!:#[."#:3>#%'&(!g-r¾'r~è­8TwÀ;R4A7±q±!9>9;:35C&(!g"+,*!)+%^#:>?(
;+!+!:3#3(
T
ÀO(!":4AC&N57-!*457;&"&(!;&_²O³´
¶!·]¸@-±.Y,.&5CUACG±9>;ILA7A&":3;&"BG±3()#5=.M;&M#-!.T
ÀO()A7;:3-)*V:34AC
3(!57UR,&"&":µ+,:%^#:39-!.&(4-V&(!;&µ#R4&57-)*VR8G'-FGV#-)#%8&()""&":3;&"BG
3(!#57.TÀO()O:3!ACA7"#N#)&"+,:%^#:39Ï-FG57-!BACh!¯8*L"&":3;&"BG>?()#57.'U:3;B*Q#eU:\A7A!#&():
+4;:39&":d#+!&5C#-4T
Æ Ùq Ü

sJt

s Ý{q Æ
p ÒÆi'lÆi'lg¹ $

µ^n t

×2l×

£

P¤#¿À$}ÁÁ

wwyXmÀ$

zP&()#8*
~::#:
1ab
t[T7qtæi»
rb­
t[T7qq
)T 
t[T7qi»
rG5=- t[T F»8q
zSf÷a#:357&`G t[T F»8q.
rI8+!:#+ t[Tì»i»
À];R4ACq.)ãzP?(!57-)Nªµ;:3-!57-!Br#9+4;:357#Æ :q ÚDö !k ö##i'l#n ó

nYk$·lÆi'lg¹

^Ð
1a-¥&()E)::-F&OU:357#-¥#%&()E²O³´
¶!·]¸J"G["&"9$DxE!"Er)T &"#Q57-!*!!.NL*)5757#-$&":2R"*
#-¥&(!2&":357-457-)B*!;&[T)T >(!O+!:3#eU-P&"#>R,V.Yc.&57UE57-¥+!:*!57.&5=-)B&()2"&":?;&"BGg3()#5=.d%^#:
&()"L&""&M*!#957-!TL1-J*!*!5C&5C#-D&()>#!&"+4)&N#%r&()>G8"&"957NeU5=A7;R4AC>Mg"G[9MRc#A=57E:3!AC
R4"Dxd(!57?(H9GXA7AC#fxÏ&()"G["&"9 *)UAC#+,:V&"#g*)&":39>57-)&()%m.&"#:3N&(4;&2Yc.&E"&":3;&"BG
"AC.&57#-$%#:B5CU-¥;+!+A757;&5C#-$*)#9>57-
T
Õ'&(!:_9>3(!57-!LAC;:3-457-)BP;+4+!:#3(!E-¼A7#PR,0!"*°&"#S+,:%^#:39 "&":3;&"BG°AC.&5C#-¼57&()¥²\³´
¶4·¸"G["&"9$TXÀµ#S&""&_&()Q:!AC&M#%OU;;:35C#!M.¯)57"&57-)BP;+!+!:#?()DxQ3)+!+4A757*H&()
*!;&Q%^:#9¨A7A]#%&()0q0)A7EA735©h;&5C#-S.¯[+,:3579-F&*!.:35CR,*S57-g&(!E+4:U857#!.&5C#r57-)+4!&&"#EU:?5C#-!#%)T 8D[&()'1VM*)575C#->&":V57-!*!4.&5C#-ACB#:357&(!9½j b457-!A7-
Dqs>| iu?D!&()
rb­>6F)-F&57AW.#eU:?57-)B$ACB#:35C&(49jrA=;:IPn57R4AC&"&DWqs|su?DµQR4I8+!:#+4;B;&57#-H-)):3A]-)&
jmod49A7(!;:&nwzSerACA7A=-!*
D)qs>| iu?D8brG357->A735©h4:Oj"&-45CID!qss;tvu?D[-!*V9f÷"#:35C&GvZx57-!
A735©h4:T/'Oxd5C&(0&(!V#&():d.¯[+,:3579-F&D[:!A7&O;:VR4"*¥#-¥&"-[Z%^#A7*¥.:#3aZUA=57*!;&5C#-
T
À];R4AC_q.E3()#exd&(!;&&()b*)5757#->&":bACB#:357&(!9+c:3%#:39*R,"&#->&(!5=+4;:3&57!A7;:*!;&
"&TN¾'AC&579;&"A7GDc&(!MR,"&b93(457-)_AC;:3-!57-!BLACB#:357&(!9½5=-g&(!5=.#-F&".¯8&N5=&(!EACB#:?5C&(!9½&(!;&
.#-!5="&"-v&A7G@G857A7*!L&()PR,"&0"+,*!)+µT{1%NxS.#-457*):$-)#:39>A75C*k+!:#R4AC9æ"+,*!)+D\&()
ACB#:357&(!9&(!;&_+!:#[*!!.E&()0R,"&EA=5©h;&57#-°#-¼eU:3;Bgxd5=A7AA7#S+4:#8*4!.>&()0B:;&"&
"+,*!)+µT'®H>xd57A7A.#-v&57-8)_&"#$.¯[+4AC#:EU;:?5C#!b93(457-)AC;:3-!5=-)BL9&(!#8*!'&"#¥*)&":?957-)E&()
;+!+!:3#3(¥&(4;&Oxd57A7Ax#:I0Rc&\%#:O&(457r&`G8+,N#%];+4+4A757;&5C#-T
÷W	   )Ñ Ä`+Í; 

ÍôÐ

sJt

psr

k$·i ?tl

 ùøZÎVÏÅsú½{Ïæû
ÀO(!5=W+4;+,::+,#:&#->x#:I_+,:%^#:39*_&"#E.#92R45=-)\&()OR,-).h4&#%c+;:3A7ACA)";:?3(>;+4+!:#3(!
57-<&()g²\³µ´
¶!·¸ÁG8"&"9¥T<~¯8+,:3579-v&;&5C#-°:UA7&(!;&"&":3;&"B5C>*)UAC#+,*¼#eU:L&()$A7"&
%^xG;:?r#;Yc:O*!5="&57-!.&Rc-!.h4&&"#5=9+!:#fU857-!BN&()b+,:%#:?9-!.d#%]/d1;+!+4A757;&57#-!Td#fxU:eD
xd(!5=ACQ-FG¼+4;:&574A7;:ACB#:35C&(49ç-@+!:#fU85=*)$5CB-!5©hc-v&"+,*!!+<%^#:#-)g&`G8+cg#%+!:3#R4AC9$D
#-S#&():b+!:#R4A79O&()EACB#:?5C&(!9'-X.&!A7ACG$+!:3#8*!4.2x#:3"E:!AC&d&(!-X!57-!B>L:357A
U:357#-±#%\&()Q";:33(<ACB#:357&(!9$T$/M¥:3!AC&D]&()"L&":3;&"B5CE-)*J&"#PR,>;:%m!A7ACGX3()#R4"*¥#-$&()2?(!;:3.&":357&57O#%W+4;:&5=!A7;:\+!:#RAC9$T
1a-Á&(!570+;+c:$x±*)9#-4"&":3;&"±&()±;R57A75C&G#%²\³´
¶!·]¸Ô&"#!&"#9;&57A7ACGw"AC.&$+;:3A©Z
ACA";:?3(J&":3;&"B5CE-!*±"&2;+4+!:#+!:35=;&"E+;:39&":3T$²\³´
¶4·¸¼9+AC#eG[V&()Qr)T $93(457-)
AC;:3-457-)BLG8"&"9ø&"#$9;I-X57-F&"A7A75CB-F&?()#57._#%&":3;&"B5Cb%^#:'?(H-)x¹+!:#R4A79½57-4"&-!.T
~¯[+,:3579-F&%:#9{&()r*)#95=-!µ#%&()h4%^&"-M+)AC+!:#R4AC9¥Df:#R,#&W;:39Ô9#&5C#-E+4A=-!-!57-)B)D×2lfò

Ú x4Û)Üã¾}>ÝLm¿xmÁÁ}ÁEÞ3}¿x)Üã¾}Lß}}vÛ}À!ÜÀ4à<áY}m¿xv8â
;:&5©hc57A
";:3?(P"+.D-!*g+4A7-!-!5=-)BM+4:#R4AC9\5=-!*!57;&"V&(!;&V²\³´
¶4·¸HG[5CA7*4rRc#&(P579+!:3#eU*
"+,*!)+M:!A7&-!*E5CB-45©h-F&ACGV579+!:#fU*MA=5©h;&57#-M):?5CW#eU:-FG2"&":3;&"BGE!"*E5757"#A=;&5C#-gx()-g(!57B([ZU;:?57-!.2&":?57-!57-)BL"V;:_!"*
T'ÀO()"E.¯8+,:35=9-v&'A7"#Q*)9#-!&":3;&"
²\³µ´
¶!··¸ _ ;R457A757&`GJ&"#°"AC.&LA=Ar+4;:39&":3L;&#-!.S-!*&"#±#)&"+,:%^#:39 -FG<h!¯[*@"&":3;&"BG
#eU:VL"&d#%+!:3#R4AC9ä57-4"&-!.Tr1a-g*!*!57&5C#-
D)xM*)9#-4"&":3;&"2&(4;&V²O³´
¶!·]¸±-gR,-).h&ORFG
)&57A=5C57-)BP&":357-!57-!BP"L*):3x-°%^:#9çXU;;:35C&G°#%'&""&*)#95=-!D&(8!_x$x#!A=*°.¯[+,.&&()
+,:%^#:39-!.#%&()b"G8&"9è&"#579+!:#eU'U-09#:bxV57-!.#:3+c#:?;&"*!;&E%^:#9è-!x+4:#R4AC9
*)#95=-!\-!*¥;:3?(!5C&".&):3T
À\x#Q#%&()E?(!A7AC-!B57-F&":#[*!!.*gRFG$#):':";:?3(X;:E&()E;R57A75C&GL&"#$*)&":39>57-)2*!5=.:3579_Z
57-!;&5=-)BP%^;&):-4*¼&()$;R457A75C&GH&"#H+!:#fU857*!QAC;:A=5©h;&57#-!E%#:&":35=-!57-)BP.¯[9+ACTJ1a#):O.¯[+,:3579-F&rxNU:35©h4*0&(4;&O&()V%^;&):OxN3(!#"2.#!A7*¥RcV93):*$;:3A7GQ*!!:357-)BE&()
";:3?(±+!:3#8.V-4*±"&57A7AR,:+!:-v&;&5CU>#%&()+4:#R4AC9¨"+4.LA7;&":N#-±*!!:357-)BL.¯8)&57#-
T
/'Ox2;+!+4ACGQ#):d;+4+!:#3(g&"#LB:3;&":U;;:35C&G$#%]+4:#R4AC9rxNxd5=A7A,-)*¥&"#Q*)UAC#+P>9#:
%^#:39A9&(!#8*)#A7#BGH%#:E"AC.&57-)B$:3+!:"-F&;&5CU0-!*±*!573.:357957-4;&57-)BQ%;&):3TL1a-±*!*45C&5C#-
D
x\#R4":U**!:39;&57r+,:%^#:39-!.\579+!:#eU9-v&x()-_&""&"x:O*!:3xd-_%^:#9Ô+4:#R4AC9
57-!&-!.'xd5C&(XAC;:VA75Ch;&5C#-!TV®Hx#!A7*SA75CIE&"#$+4):?)M9&()#8*4#%AC;:3-!5=-)B>%^:#9¨57-[Z
"&-!.W&(4;&].¯)(!5CR5C&AC#fx¼U;:35=;&5C#-_57-2+,:%^#:39-4.#%4A7&":3-!;&5CU\"&":3;&"B57-!*_(!5CB(MU;:?57;&5C#57-0+!:3#R4AC95CT
ÀO(!_!::-F&'579+4AC9-F&;&5C#-S#%r²O³´
¶!·]¸°%^#[!"b#-X-X1d/N}>;+!+4:#3(H&"#$";:?3(
TÕb-)
:"#-L%^#:&(457?()#57.'#%";:33(09&(!#8*Q57&(!'A75=-);:99#:3G:6F45C:9-F&#%
&(!'ACB#:?5C&(!9$T
/p.#-!*@*)U;-v&;Bg#%d&(!57_";:?3(@9&(!#8*¼57_&(!;&-5C&":?;&5CU¥*)+,-!57-)BX";:3?(9&()#[*
+!:#fU85=*)%^*)R43I57-@?(Á5C&":3;&5C#-k&(!;&0-R,S!"*k&"#<*÷!"&>+4;:39&":3Q%^#:L&(!S-).¯[&
";:3?(¥5C&":3;&57#-
T/'\:!A7&D!²O³´
¶!·]¸H-$+,#&"-v&5=A7ACG>*÷!"&\&(!N"&":3;&"BG$3()#5=.\%:3#9#-)
5C&":3;&57#-#%,&()d";:3?(>ACB#:?5C&(!9¹&"#2&(!O-).¯8&%^;&):#%c&()d+4.OU;;:GTd#fxU:eD857->"#9
+!:#RAC9ä*)#95=-!O-)#-[Z`57&":3;&5CU2";:?3(SACB#:35C&(!9>d9eG$RcV+4:%:3:*
Tr/ %m)&):323(!A=AC-)BN%^#:
#):b:";:?3(X57&"#Q:3.h-)2&(!_*4;+!&5CUE+4;:3A7ACA";:3?(HACB#:35C&(!9½%^#:'!E57-SLB:;&":NU;;:35C&`G
#%5C&":3;&5CUN-4*¥-)#-[Z`5C&":?;&5CU2";:3?(gACB#:?5C&(!9T
²O³´
¶!·]¸P579+4AC9-F&;&5C#-!;:3'):3:-v&A7GU;57A7;R4ACd#-Q2U;:?5C&`G#%;:33(!57&".&):3A+4A7;&"%^#:39
57-!A=!*!57-)BSzg1azS¬*!57"&":357R4)&"*¼99#:G¼-!*@3(!;:*@99#:G9M!A7&5C+!:#[."#:3D±*!57&":35CR4)&"*
-)&x#:I<#%b93(!5=-)_:3!-!-457-)BPº'z°D]#5©¯9M4AC&5C&():*457-)BP9>3(!57-!D-!*9?(!57-)457-)B
yeU&():*!\-!*g\57ACI&():3*!T:3#R4AC9*)#957-4\)::-F&ACG>!-4*):O57-FU"&5CB;&5C#-$57-4A7!*)b*[Z
*!5C&57#-!AF.#9MR457-4;&"#:357A8#+!&57957;&5C#-E+!:#R4AC9>]3!3(W&()O-)¶Z b)-!]+!:#RAC9 -4*57-v&"B:?;&5C##%9>3(!57-!bA7;:3-!57-)B)D8&()#:9ä+!:#eU[57-)B)D[-!*$-!;&!:3A,A7-)B!;BNACB#:?5C&(!9r57-F&"#_&(!57r";:3?(¥;:"Z
3(45C&".&):T®H'()#+,\&"#2*)9#-!&":3;&"d&(!;&+4;:3A7ACA)(!):357"&5=;:33(LACB#:35C&(!9>-G[5CA7*_R,#&(
#+!&579>·A ÉMA7;R4ACV;+!+4:#3()d&"#+4A7-4-!57-)B)D[93(457-)NAC;:3-457-)B)D)-!;&):3AµA7-)B!;BD!&(!#:9
+!:#fU85=-)B)D!-!*¥9-FGQ#&():.#9+)&;&5C#-[Z`57-F&"-!57UN;:O#%W/d1ïT
Ê

æû  JüPÄ`Å4·ýµÅJÅ 
Ñ

ÎÍ

OÀ (!5=Wx#:IExr)+4+c#:3&"*_RFG_;&57#-!A¦[5C-4.d)#!-!*4;&5C#-B:3-F&1aoO1Zs;t|;t|8D)1od1`Zs;t­­>i;t[D
-!*bzP1`Zs!qs­8TÀd()$)&()#:3_x#!A7*¼A75CI0&"#H&(!-!I°b-@r):3-!_-!*zS;&"&(!5719(!#%d;&
&()HzP1À¬~;:&(woO"#):?.$ªµ;RÁ%^#:$+!:#eU[57*!5=-)BJ.g&"#<&(!5C:$-r¾'~½­J&"#.#9+AC&"H&()
.¯[+c:?579-F&r:+,#:&"*¥57-0&(!5=r+4;+,:T
×2leü

£

P¤#¿À$}ÁÁ

wwyXmÀ$

}XÅßaÅ$ÏÅ  [Ñ ÅmÍ

/B:3xrAiDETCDyv-!;I857:39$DWºMTCDn½zP():#&":?[DoNT\jaqs||u?TJ/:3-4*)#95C*°+4;:3A7A7AR!:3-43(¼-!*
R,#!-4*>ACB#:357&(!9$T
1a×
- þ\ñ éïð3Wð c;í Vî:ÿ[ð 2î`ð.ñ Éî "É;+ê à>ðñ"Nð é?Sð þXÉ;ñ É;êê7ð.ê þ\ñ eé?ðïí?2í â
:D!+!+ßT is [»;8T,ÀO()N]-!-!"G[ACU;-!57¦8&;&"2¾'-!5CU:?5C&`GT
/'-!*):3"#-Dc¦cTCDnr()-
D4z°T,bT]jaqs|»u?TdW;:3A7A7A
R!:3-!?([Z`-!*[ZR,#!-4*$ACB#:35C&(!9>O#-¥&(!M(FGF+,:"Z
!RcT1a
- þ\ñ éïð3Wð c;$í Mî:ÿ[×
ð àð.ñð éï|ð W!ð.ñ"éë È 	ð Hë8ê©î ñ eé?ðïí?í ;ñ?í?Dc+!+T4;ts 8[qe»FT
r;::&"&D)/MTCD8nÁ®HA=*
DFET
jaqss­u?TµW;:&57A!#:?*):+4A=-!-!57-)B)ãUA=!;&57-)BN+,#35CR4ACr.KL5C-4.GEB5=-!T
À3(T4:+Td¦[~@ÀOo{s­fZ`tfZ3q;Dc¾'-!5CU:335C&`GQ#%W®±(!57-)B&"#-T
r(!;&"&3(4;:m÷aD¦,TCD8rACU:&D[lTCD[á
n cB):3[D8~OT®{Tcjaqss»u?T/-;:?3(!5C&".&!:d%^#:.&5CU'-)&`x#:IFZ
5=-)B)T1-$À]-F&xOGD,/2T!MTjm~*
Tìu?
D qÊÿþð.:ñ ;ñ Ééï	ð Mðî K;Wñ ËOcD!+!+µT4>­ i 8­»;s8T
r(4;+49nÏA7AT
"&-45CIDTjaqss;tvu?TL~&579;&57-)B$+4:#R4;R457A=5C&5Cã'¥.:3!57AW&IS57-H9>3(!57-!AC;:3-!57-!B)TE1as
- þ\ñ â
éïð3Wð c;$í Mî:ÿ[	ð q:4:î ÿrë[ñ 2)ð É>õàð.ñð éï|ð 'ñ.î  Né "É;
ê 24î`ð.ê^±ê Ã8ð éïð.D!+!+µT,qe»f qe»;s8T
r(!A=AC#
DµETCDb57-!5DµzJTCDnplN!9;:DºMTrjaqssu?T¥W;:3A7ACA";:33(<ACB#:357&(!9V%^#:2:#R,#&29#&5C#+A7-!-!57-!B)T1a-bA7AC:Ddy!T'jm~*Tìu?ÏD þrñ é?ð?ð :;@
í Sî:ÿ[
ð Ïdí dë  2ßOÉî ;ð
&æ±ê iWé Éî ")|
í @É;í32í ;[ð þXÉ;ñ Éêê7ð.±ê =í _D4+!+T)t vF»FT
rA7;:3IDd]TCDOn57R4AC&"&Do2Tbjaqs|su?TÀO()±rb­J5=-!*!!.&5C#-ACB#:357&(!9$
T @ÉNé ÿ,
ð µWð É;ñ ßc!D D
>­ i["q 8­|)T
#8#IDOETry)TCDn«º;:3-)A7ADro2T'Tbjaqss»u?TåzP¯)5795757-)BH&()PRc-!.h4&#%b+4;:3A=ACAO";:3?(k457-)B
9>3(!57-!OAC;:3-!57-!B)T81a*
- þrñ éïð3ð >Ðí dî:ÿ)#ð Éî "Éê àð.ñð éïqð $'ñ.î  é É%ê 24î`ð.ê^±ê Ã8ð éïð.D
+4+T4s 8> i)T
//'/d1r:3T
#8#ID)ET4y)T
jaqss»u?T/å(FG8R!:357*Q;+!+!:#?(0&"#579+!:#fU85=-)B2&()b+,:%^#:39-!.'#%+4;:?A7ACAc";:33(T]1aþXÉ;ñ É;êê7ð.Ñê þrñ é?ð.í3í q;&ñ 'ñïî  é É;'ê 24î`ð.ê^Öê ÊFNð é?(
ð D4+!+Tq­;t q.v8T
~A7U85C:eT
#8#ID!ET4y!TCD!A7AD[ªTCD4n¹ÀO()#9D)® Tµjaqssu?T];:?A7ACA,";:3?(¥!57-!BE&":?-!"%^#:39;&5C#-[Z#:?*):357-)B
57&":3;&5CU.Z`*)+,-!57-!B>/N}
T )¾ÿ[	ð 2î`ð.ñ Éî "É;+ê *À;ë[2ñ ÉUê &24î`ð.ê^Öê ÊFNð 4,î íïî`Nð Míï.D -Wji|u?D
| 
|»;8T
#8#IDETy)TCDn¨ªµG#-!Dr_Tjaqssu?TzS5CUACG°+4;:3A7A7A1aO/2}P";:3?(
/
T *dë8ñ É;Xê 0'ñïî  é É;ê
2î`ð.ê^Öê ÊFNð é?1
ð );êìí?3D 2Wji­u?DWq i q|;t[T
:357B)D4y)T4y)T]jaqs|su?#T 24îmñ ;ë!éeî °î >ñ  È î méí?T/*!*457"#-[Z®HA7GT
~U&"&DzJTCD!-!*!AC:eD)y!TCD!zP(4-v&5iD!/MTCD4n¹'
D!ETµjaqssu?To/N}ã9>5CUACG>+4;:3A7ACA,()!:357"&57
;:33(
T *dë8ñ É;-ê ÐþYÉñ É;ê^ê7ð.-ê É>$4=í.îm2ñ  È ë)î`ð ]àÏë)î :5D 2å;Dq q.v8T
)A7*49-!-
D4o2TCDczPG[A75Cxd57&"D4]TCD,nÉzg#-!57-
D'TjaqssFu?Tb¦8&!*!G857-!B#eU:3()*4'5=-¥957UACG0+4;:"Z
A=ACA9>57
- 69¯8Z&":_UA=!;&5C#-
T'1@
- þ\ñ éïð3Wð c;*
í î:ÿ[7ð J98v:î ÿ1ÐJ!ßë É;:ê à;<Ïd2í ^dë 
>þYÉ;ñ É;ê^êCð=ê 'ê ;ñ m:î ÿEÐí É	'ñ"é ÿmî`ðéeîmë[ñ"ð.í?D8+!+Ts qt8T8/'"#[57;&5C#-%#:#9+4)&57-)BVzSZ
?(!57-):3GT
×2lØ

Ú x4Û)Üã¾}>ÝLm¿xmÁÁ}ÁEÞ3}¿x)Üã¾}Lß}}vÛ}À!ÜÀ4à<áY}m¿xv8â
):3-!ID'zJTCDN¦[)I;U[5C:35 ÷[DO]TCDbn)#A7GDby!TET2jaqssu?TÉ1a-)%^:-!.SR,;:ãJ*)57B-!57-)B<57-v&":?.&5CU
5=-v&":%m.&():#)B(>R,%#:-!*L;%^&":r-!;+4(!#&T
1×
- þrñ é?ð?ð :qí bî:ÿ[ð |à;>Ïd2í ^dë 
>!4_ðïí Ãæßc24î`ð.ñ Ééeî ?@ð í.î`ð Eí?D+!+µTvq iA» qe»;8Tv/'"#[57;&5C#-M%#:#9+4!&57-)BOzS3(!57-!:GT
!):?!573(45iDz°TCD\À;I[5iD\lTCDdn«1?(vG#(45iD\2Tbjaqss;tvu?Tå/¨9M!A7&5©Z`ACUAOAC#*R4A7-!5=-)B±3(!9g%^#:
#:Z+4;:3A7ACAc.¯)(!!"&57Ub;:33($+4:#B:39r#-$&(!b9E!AC&5CZ+45iT1a^
- þrñ éïð3ð >$í Vî:ÿ[Bð ,ð3Wé 
à;>=CKþD3E
OÏd;2í ^cë  >þrñ é ¹cêCð.Ð
í Éþ\ñ Évéî ié?ð &þYÉñ É;ê^ê7ð.ßê þrñ ñ ÉD)+!+T
qtt qæt i8T
/'"#[57;&5C#-$%^#:'#9+4)&57-)BzS3(!5=-):GT
lNACDªT,ºMTCDµn¦[AC&"#:3DºMT
/MTjaqss;tvu?T_W;:3A=ACAW"&;&".Z`"+4.Q";:33(X%^#:NLh4:3"&V"#A=)&5C#-Pxd5C&(
.#-457"&"-F&LA75=-);:L"+,*!!+4T/2î`ð.ñ Éî "É;&ê *À;ë[2ñ ÉÐê þXÉ;ñ É;êê7ð.Yê þrñ ñ É:!D FHGj^Fu?D
­["q 8­s8T
lN;:G8+457D,ETCDnèlN!9;:DcºETWjaqss­u?T2¾'-!"&":?!.&):*g&":";:33(S#-±¦81azPÉ+4;:3A7A7Aµ.#9+4!&":3T
1a
- þ\ñ éïð3Wð c;í &4<ë )ð.ñ"Wé Ïë)î :GI2D4+!+µT8v v i­8T,1a~~~#9+)&":¦8#[5C&`GT
lN!9>;:DºETCDnäo;#)DµºETµ2Tjaqss;tvu?T¥¦)A7;R4AC+4;:?A7ACA]%#:?9M!A=;&5C#-!V#%r*)+!&([Zih:3"&N";:3?(
T>1al2!9;:D8lN-!AiD)n '#+A7;IF:?57(!-Sjm~*!Tìu?ßD þYÉñ É;ê^ê7ð.ê 'ê ;ñ ^:î ÿMUí N;#ñ Éé ÿcð 24î`ð.ê^±ê Ã8ð éïð
É>KJ 2í "!D)+4+T"q v!q;T,¦8+4:357-)BL: vº:?A7;B)T
ªµ57Rc:?9-
D!MTjaqss|u?T\1-F&"B:3;&57-!BL!":'57-F&":%^.M;B-v&'xd5C&(g.#-vU-F&5C#-!A];+!+4A75=;&5C#-!T1aþ\ñ eé?ð3Wð :;
í î:ÿ[Mð |à; à>ðñ"Nð é?
ð N24î`ð.ê^±ê Ã8ð 4!î Oíðñ 2î`ð.:ñ ÉéïðïíïD
+!+T
s v i8Tµ/3"#;Z
5=;&5C#-$%^#:'#9+4!&57-)BzP?(!57-):3GT
zS(!-v&5D,/MTCDn'-45CA7D'Tjaqssu?TE¦81azPè+4;:3A7A7Aµ()):?57"&57N;:33(
(T bñïî  Né "É;;ê 24î`ð.ê^±ê Ã8ð éïð.D
PRQ ji­u?D
­v 8­|[q;T
zS(!;+4;&":3[DvMToNTCDn'!&"&D8¦cT)jaqssu?T4dx@-F&575C+;&"#:G2AC#*ER4A7-457-)B&":3;&"B5CW%^#:]+;:3A7ACA
/2}>ACB#:357&(!9TM1@
- þrñ éïð3ð >
í î:ÿ[!ð 4&S|à3T,ð.ñ ið.|í >N4í.éñðî`Mð @É:î ÿ[ð Éî ié.
í É
)¾ÿ)ð ;ñðî iWé É;ªê àÏë)î`ð.B
ñ cNé ð cé?ð.D4+!+T
qsA» 8­­8T
/9:?57-¥zS;&()9;&57AW¦8#857&`GT
zS57-v&"#-D¦,T8jaqs>s iu?T!/')&"#9;&57A7A7GN.#-[h4B):35=-)BO.#-!"&":35=-v&W;&57"%m.&5C#-M+!:#B:39>ãµ'"&!*)GT
à>)íïîmñ É:4î^í?UD Fjaqeu?DA» vv8T
]#exdA7GD'TCD):B!#-
D'TCDn½lV#:%DWo2T]~dTjaqssu?T±'+!&([Zih:3"&M(!):357"&5=";:3?(°#-¼H¦81azP
9>3(!57-!VT 'ñ.î  é É
ê 24î`ð.ê^Öê ÊFNð é?ðD PHQ ji­u?D]qss 8­v­8T
]#exdA7GDc'TCD4n¹lV#:%D!oNT!~dTjaqss[qeu?Tr¦[57-!BAC.Z`;B-v&\+;:3A7ACAcxd57-4*)#exÁ";:3?(
,T SD,W)!ñ É)í Évéî ")í
>hþXÉîiî`ð.ñ XÐÉYê 2í S
í É7Éé ÿ:c	ð 24î`ðê±ê ÊFð cé?ð.5D FH]jiu?Dc i>ivF»»FT
b!5=-!A7-
D)y)T!o2Tµjaqssu?|
T à¤ãäåHZKcñ ñ É>M&í N;ñ Éé ÿcð_êCWð É;2ñ JTzP#:B-Pl2)%^9>-!-
T
b!5=-!A7-
D)y)Tµjaqs>| iu?T1-4*!!.&5C#-0#%W*)5757#-0&":TVÉé ÿ:c	ð ð É;ñ ß:F;3D F]jaqeu?Dc|["q qæt i8T
odf÷"+4AiD!¦cT[]TCD)n{lN49;:D!¦cT,jaqssu?TW;:3A=ACA(!):357"&5=d";:3?(0ACB#:35C&(!9>%^#:\9;Bb+4357-)B
9E!AC&57+!:#[."#:O"G["&"9Tà>Xcë[î`ðñ cé iNð é?ð É>722ñ Éî ié.íï3D 2RWj^Fu?DA» q|8T
od;#)D\ºETMTCDOlN!9>;:DrºMTCDdn§od9(DOlTjaqs|»u?T /ø+4;:?A7ACAO579+4AC9-F&;&5C#-#%N5C&":?;&5CU.Z
*!+c-457-)B;Z`/2}Tg1a5
- þ\ñ éïð3Wð c;h
í Qî:ÿ)
ð SÉî >É;qê àð.ñð éï^
ð [bñïî  Né "É;\ê 24î`ð.ê^±ê Ã8ð éïð.D
+4+Tqe»;| q|­8T
zg#:B-PlN)%m9-!-
T
×2l<\

£

P¤#¿À$}ÁÁ

wwyXmÀ$

oO5=-)%A=*
DF/MTCD!n¹¦)3(!-)3ID)ºMTjaqssFu?T/1d/N}bZ"G[-!3():3#-)#!+4;:3A7A7A!1aO/N}T]1a-6þ\ñeé?ð3ðW:;í
î:ÿ[]
ð )Nð 4:î ÿGàÉ>Éæ"É àð.ñð éï
ð Nbñïî  Né "É;3ê 24î`ðê±ê ÊFð cé?ð.Dµ+!+T
­s 8;t­8Tr-4*!571a-)%^#:39;&5C#-g:#[.57-!B¦[#85C&GT
od49A7(!;:&DcET~OTCD
nèzPerA7A7A7-!*
Dcy)TªT]jaqs>| iu?T þYÉñ É;ê^ê7ð.ê =í.îm2ñ  È ë)î`Wð $ñ é?ð.í3í ^Z_ð 8Ãê ñ Éî "
:H:î ÿ[S
ð méñ ;íïîmñïë)éeîmë[ñ"|ð MéWæßmî a`!J-;êìdë >ðï(í F×É2TzP1ÀÖ:D\92R!:?57*)BD)zP/MT
¦[AC&"#:3D\ºMT/2Tbjaqss;tvu?Tå/¬*!57"&":?5CR4)&"*¼-!*k*!;+!&5CUS*)G8-4957$AC#*kR4A7-!5=-)B±3(!9g%^#:
+;:3A7ACAd+!:#[.57-)B°#%29*!5=!9_ZB:357-@&"I8T 1aB
- þ\ñ eé?ð3Wð :;@
í Pî:ÿ)
ð bK .î:ÿc4=í.îm2ñ  È ë)î`Wð 
°ð ;dñ 	àÏë)î :@àQðñ"Nð é?ðD4+!+T!­["q 8­8T
¦8&"-)I[57"&"D¥]TCD¥W57(!:D$/2TCDgn ,(4-)B)D$2T¥jaqss»u?T ';:3xd57-
ãä:3"#):3.Á9-!;B9-v&%^#:
;+4+4A757;&5C#-)Z`xr;:N-)&`x#:I[TÀµ?(
T!:+µT)rzS¾dZO¦FZs»eZ3qs8Dr;:3-)B5CVzPA7AC#-0¾'-!5CU:357&`GT
¦[)&"&-!:D,'TWjaqss»u?TV¦[&;&57N+4;:3&5C&5C#-!57-!Bxd5C&(g3A7I[-)T\1a	
- þXÉ;ñ É;êê7ð.¾ê þ\ñ éïðïí?2í :qN;ñ 'ñïî  é É;ê
2î`ð.ê^Öê ÊFNð é?M
ð D4+!+T
qæt iq­;t[T
~A7"U[5C:T
º;:3-)A=AiDoNTbTdjaqss»u?e
T ÐMÉñaNé ÿ^î`ð3éîmë[ñSð ;6
ñ :Ïñ Q:<:î ÿ[|ð )ð.:ñ N;2ñ Écé?~
ð SdÉñ É;ê^ê7ð.êOíð É;ñ"é ÿFT
(
T ET!&()5=D!¾-45CU:35C&G>#%À.¯[;&d/d:?A757-)B&"#-
T

×2lQl

Journal of Articial Intelligence Research 9 (1998) 37-97

Submitted 2/98; published 9/98

The Divide-and-Conquer Subgoal-Ordering Algorithm
for Speeding up Logic Inference
Oleg Ledeniov
Shaul Markovitch

olleg@cs.technion.ac.il
shaulm@cs.technion.ac.il

Computer Science Department
Technion { Israel Institute of Technology
Haifa 32000, Israel

Abstract

It is common to view programs as a combination of logic and control: the logic part
denes what the program must do, the control part { how to do it. The Logic Programming paradigm was developed with the intention of separating the logic from the control.
Recently, extensive research has been conducted on automatic generation of control for
logic programs. Only a few of these works considered the issue of automatic generation of
control for improving the eciency of logic programs. In this paper we present a novel algorithm for automatic nding of lowest-cost subgoal orderings. The algorithm works using
the divide-and-conquer strategy. The given set of subgoals is partitioned into smaller sets,
based on co-occurrence of free variables. The subsets are ordered recursively and merged,
yielding a provably optimal order. We experimentally demonstrate the utility of the algorithm by testing it in several domains, and discuss the possibilities of its cooperation with
other existing methods.

1. Introduction
It is common to view programs as a combination of logic and control (Kowalski, 1979). The
logic part denes what the program must do, the control part { how to do it. Traditional
programming languages require that the programmers supply both components. The Logic
Programming paradigm was developed with the intention of separating the logic from the
control (Lloyd, 1987). The goal of the paradigm is that the programmer species the logic
without bothering about the control, which should be supplied by the interpreter.
Initially, most practical logic programming languages, such as Prolog (Clocksin & Mellish, 1987; Sterling & Shapiro, 1994), did not include the means for automatic generation of
control. As a result, a Prolog programmer had to implicitly dene the control by the order of
clauses and of subgoals within the clauses. Recently, extensive research has been conducted
on automatic generation of control for logic programs. A major part of this research is concerned with control that aects correctness and termination of logic programs (De Schreye
& Decorte, 1994; Somogyi, Henderson, & Conway, 1996b; Cortesi, Le Charlier, & Rossi,
1997). Only a few of these works consider the issue of automatic generation of control for
improving the eciency of logic programs. Finding a good ordering that leads to ecient
execution requires a deep understanding of the logic inference mechanism. Hence, in many
cases, only expert programmers are able to generate ecient programs. The problem intensies with the recent development of the eld of inductive logic programming (Muggleton
c 1998 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

Ledeniov & Markovitch

& De Raedt, 1994). There, logic programs are automatically induced by learning. Such
learning algorithms are commonly built with the aim of speeding up the induction process
without considering the eciency of resulting programs.
The goal of the research described in this paper is to design algorithms that automatically nd ecient orderings of subgoal sequences. Several researchers have explored the
problem of automatic reordering of subgoals in logic programs (Warren, 1981; Naish, 1985b;
Smith & Genesereth, 1985; Natarajan, 1987; Markovitch & Scott, 1989). The general subgoal ordering problem is known to be NP-hard (Ullman, 1982; Ullman & Vardi, 1988).
Smith and Genesereth (1985) and Markovitch and Scott (1989) present search algorithms
for nding optimal orderings. These algorithms are general and carry exponential costs for
non-trivial sets of subgoals. Natarajan (1987) describes an ecient algorithm for the special
case where subgoals in the set do not share free variables.
In this paper we present a novel algorithm for subgoal ordering. We call two subgoals
that share a free variable dependent. Unlike Natarajan's approach, which can only handle
subgoal sets that are completely independent, our algorithm can deal with any subgoal
set, while making maximal use of the existing dependencies for acceleration of the ordering
process. In the worst case the algorithm { like that of Smith and Genesereth { is exponential.
Still, in most practical cases, our algorithm exploits subgoal dependencies and nds optimal
orderings in polynomial time.
We start with an analysis of the ordering problem and demonstrate its importance
through examples. We then show how to compute the cost of a given ordering based on
the cost and the number of solutions of the individual subgoals. We describe the algorithm
of Natarajan and the algorithm of Smith and Genesereth and show how the two can be
combined into an algorithm that is more ecient and general than each of the two. We
show drawbacks of the combined algorithm and introduce the new algorithm, which avoids
these drawbacks. We call it the Divide-and-Conquer algorithm (dac algorithm). We prove
the correctness of the algorithm, discuss its complexity and compare it to the combined
algorithm. The dac algorithm assumes knowledge of the cost and the number of solutions
of the subgoals. This knowledge can be obtained by machine learning techniques such as
those employed by Markovitch and Scott (1989). Finally, we test the utility of our algorithm
by running a set of experiments on articial and real domains.
The dac algorithm for subgoal ordering can be combined with many existing methods
in logic programming, such as program transformation, compilation, termination control,
correctness verication, and others. We discuss the possibilities of such combinations in the
concluding section.
Section 2 states the ordering problem. Section 3 describes existing ordering algorithms
and their combination. Section 4 presents the new algorithm. Section 5 discusses the
acquisition of the control knowledge. Section 6 contains experimental results. Section 7
contains a discussion of practical issues, comparison with other works and conclusions.

2. Background: Automatic Ordering of Subgoals
We start by describing the conventions and assumptions accepted in this paper. Then we
demonstrate the importance of subgoal ordering and discuss its validity. Finally, we present
a classication of ordering methods and discuss related work.
38

The Divide-and-Conquer Subgoal-Ordering Algorithm

2.1 Conventions and Assumptions

All constant, function and predicate symbols in programs begin with lower case letters,
while capital letters are reserved for variables. Braces are used to denote unordered sets
(e.g., fa; b; cg), and angle brackets are used for ordered sequences (e.g., ha; b; ci). Parallel
lines (k) denote concatenations of ordered sequences of subgoals. When speaking about
abstract subgoals (and not named predicates of concrete programs), we denote separate
subgoals by capital letters (A; B : : :), ordered sequences of subgoals by capitalized vectors
~ O~ S : : :), and sets of subgoals by calligraphic capitals (B; S : : :).  (S ) denotes the set of
(B;
all permutations of S .
We assume that the programs we work with are written in pure Prolog, i.e., without cut
operators, meta-logical or extra-logical predicates. Alternatively, we can assume that only
pure Prolog sub-sequences of subgoals are subject to ordering. For example, given a rule of
the form
A B1 ; B2; B3; !; B4; B5; B6:
only its nal part fB4 ; B5; B6g can be ordered (without aecting the solution set).
In this work we focus upon the task of nding all the solutions to a set of subgoals.

2.2 Ordering of Subgoals in Logic Programs
A logic program is a set of clauses:

A

B1 ; B2 ; : : :; Bn :

(n  0)

where A; B1 ; : : :; Bn are literals (predicates with arguments). To use such a clause for
proving a goal that matches A, we must prove that all B -s hold simultaneously, under
consistent bindings of the free variables. A solution is such a set of variable bindings. The
solution set of a goal is the bag of all its solutions created by its program.
A computation rule denes which subgoal will be proved next. In Prolog, the computation rule always selects the leftmost subgoal in a goal. If a subgoal fails, backtracking is
performed { the proof of the previous subgoal is re-entered to generate another solution.
For a detailed denition of the logic inference process, see Lloyd (1987).

Theorem 1 The solution set of a set of subgoals does not depend on the order of their

execution.

Proof: When we are looking for all solutions, the solution set does not depend on the

computation rule chosen (Theorems 9.2 and 10.3 in Lloyd, 1987). Since a transposition of
subgoals in an ordered sequence can be regarded as a change of the computation rule (the
subgoals are selected in dierent order), such transposition does not change the solution
set.
2
This theorem implies that we may reorder subgoals during the proof derivation. Yet the
eciency of the derivation strongly depends on the chosen order of subgoals. The following
example illustrates how two dierent orders can lead to a large dierence in execution
eciency.
39

Ledeniov & Markovitch

parent(abraham,isaac).
parent(sarah,isaac).
parent(abraham,ishmael).
parent(isaac,esav).
parent(isaac,jakov).

... More parent clauses ...

male(abraham).
male(isaac).
male(ishmael).
male(jakov).
male(esav).

... More male clauses ...

brother(X,Y)
male(X), parent(W,X), parent(W,Y), X=/=Y.
father(X,Y)
male(X), parent(X,Y).
uncle(X,Y)
parent(Z,Y), brother(X,Z).

... More rules of relations ...

Figure 1: A small fragment of a Biblical database describing family relationships.

Example 1
Consider a Biblical family database such as the one listed in Figure 1 (a similar database
appears in the book by Sterling & Shapiro, 1994). The body of the rule dening the
uncle-nephew (or uncle-niece) relation can be ordered in two ways:
1. uncle(X,Y) brother(X,Z), parent(Z,Y).
2. uncle(X,Y) parent(Z,Y), brother(X,Z).
To prove the goal uncle(ishmael,Y) using the rst version of the rule, the interpreter will
rst look for Ishmael's siblings (and nd Isaac) and then for the siblings' children (Esav
and Jacov). The left part of Figure 2 shows the associated proof tree with a total of 10
nodes. If we use the second version of the rule, the interpreter will create all the parentchild pairs available in the database, and will test for each parent whether he (or she) is
Ishmael's sibling. The right part of Figure 2 shows the associated proof tree with a total
of 4(N , 2) + 6  2 + 2 = 4N + 6 nodes, where N is the number of parent-child pairs in the
database. The tree contains two success branches and N , 2 failure branches; in the gure
we show one example of each. While the two versions of the rule yield identical solution
sets, the rst version leads to a much smaller tree and to a faster execution.
Note that this result is true only for the given mode (bound,free) of the head literal;
for the mode (free,bound), as in uncle(X,jacov), the outcome is the contrary: the second
version of the rule yields a smaller tree.

2.3 Categories of Subgoal Ordering Methods

Assume that the current conjunctive goal (the current resolvent) is fA1; A2g. Assume that
we use the rule \A1 A11; A12:" to reduce A1 . According to Theorem 1, the produced
resolvent, fA11 ; A12; A2g, can be executed in any order. We call ordering methods that
allow any permutation of the resolvent interleaving ordering methods, since they permit
40

The Divide-and-Conquer Subgoal-Ordering Algorithm

uncle(X,Y)

brother(X,Z), parent(Z,Y). uncle(X,Y)

uncle(ishmael,Y)

uncle(ishmael,Y)

parent(Z,Y), brother(ishmael,Z)

brother(ishmael,Z), parent(Z,Y)

Z=adam,
Y=cain

male(ishmael), parent(W,ishmael), parent(W,Z),
ishmael =/= Z, parent(Z,Y)

brother(ishmael,adam)
parent(W,ishmael), parent(W,Z),
ishmael =/= Z, parent(Z,Y)
W=abraham
parent(abraham,Z), ishmael=/=Z, parent(Z,Y)
Z=ishmael
Z=isaac
ishmael =/= ishmael,
parent(ishmael,Y)

isaac =/= ishmael,
parent(isaac,Y)

parent(Z,Y), brother(X,Z).

Z=isaac,
Y=jacov

other
parent-child
pairs

male(ishmael), parent(W,ishmael),
parent(W,adam), ishmael =/= adam
parent(W,ishmael), parent(W,adam),
ishmael =/= adam
W=abraham
parent(abraham,adam), ishmael =/=adam

parent(isaac,Y)
Y=esav
Y=jacov

brother(ishmael,isaac)

male(ishmael), parent(W,ishmael),
parent(W,isaac), ishmael=/=isaac
parent(W,ishmael), parent(W,isaac),
ishmael =/= isaac
W=abraham
parent(abraham,isaac), ishmael=/=isaac
ishmael =/= isaac

Figure 2: Two proof trees obtained with dierent orderings of a single rule in Example 1.
interleaving of subgoals from dierent rule bodies. When ordering is performed only on
rule bodies before using them for reduction, the method is non-interleaving. In the above
example, interleaving methods will consider all 6 permutations of the resolvent, while noninterleaving methods will consider only two orderings: hA11 ; A12; A2i and hA12; A11; A2i.
Interleaving ordering methods deal with signicantly more possible orderings than noninterleaving methods. That means that they can nd more ecient orderings. On the
other hand, the space of possible orderings may become prohibitively large, requiring too
many computational resources.
Subgoal ordering can take place at various stages of the proof process. We divide all
subgoal ordering methods into static, semi-dynamic and dynamic.

 Static ordering: The rule bodies are ordered before the execution starts. No ordering takes place during the execution.

 Semi-dynamic ordering: Whenever a rule is selected for reduction, its body is
ordered. The order of its subgoals does not change after the reduction takes place.

 Dynamic ordering: The ordering decision is made at each inference step.
Static methods add no overhead to the execution time. However, the optimal ordering
of a rule often depends on a particular binding of a variable, which can be known only at
run-time. For instance, in Example 1 we saw that the rst ordering of the rule is better
for proving the goal uncle(ishmael,Y). And yet, for the goal uncle(X,jacov), it is the
second ordering that yields more ecient execution. To handle such cases statically, we
must compute the optimal ordering for each possible binding.
41

Ledeniov & Markovitch

Obviously, static ordering can only be non-interleaving. The dynamic method is more
exible, since it can use more updated knowledge about variable bindings, but it also carries
the largest runtime overhead, since it is invoked several times for each use of a rule body.
The semi-dynamic method is a compromise between the two: it is more powerful than the
static method, because it can dynamically propose dierent orderings for dierent instances
of the same rule; it also carries less overhead than the dynamic method, because it is invoked
only once for each use of a rule body.
The total time of proving a goal is the sum of the ordering time and the inference time.
Interleaving and dynamic methods have the best potential for reducing the inference time,
but may signicantly augment the ordering time. Static methods do not devote time to
ordering (it is done o-line), but have a limited potential for reducing the inference time.
The algorithms described in this paper can be used for all categories of ordering methods,
although in the experiments described in Section 6 we have only implemented semi-dynamic,
non-interleaving ordering methods: on each reduction, the rule body is ordered and added
to the left end of the resolvent, and then the leftmost literal of the resolvent is selected for
the next reduction step.

2.4 Related Work

The problem of computational ineciency of logic inference was the subject of extensive
research. The most obvious aspect of this ineciency is the possible non-termination of
a proof. Several researchers developed compile-time and run-time techniques to detect
and avoid innite computations (De Schreye & Decorte, 1994). A certain success was
achieved in providing more advanced control through employment of co-routining for interpredicate synchronization purposes (Clark & McCabe, 1979; Porto, 1984; Naish, 1984).
Also, innite computations can be avoided by pruning innite branches that do not contain
solutions (Vasak & Potter, 1985; Smith, Genesereth, & Ginsberg, 1986; Bol, Apt, & Klop,
1991). In the NAIL! system (Morris, 1988) subgoals are automatically reordered to avoid
nontermination.
Still, even when the proof is nite, it is desirable to make it more ecient. Several
researchers studied the problem of clause ordering (Smith, 1989; Cohen, 1990; Etzioni,
1991; Laird, 1992; Mooney & Zelle, 1993; Greiner & Orponen, 1996). If we are looking for
all the solutions of a goal, then the eciency does not depend on the clause order (assuming
no cuts). Indeed, if some predicate has m clauses, and for some argument bindings these
clauses produce all their solutions in times t1 ; t2 : : :tm , then all solutions of the predicate
under these bindings are obtained in time t1 + t2 + : : : + tm , regardless of the order in
which the clauses are applied. Dierent clause orderings correspond to dierent orders in
which branches are selected in a proof tree; if we traverse the entire tree, then the number
of traversal steps does not depend on the order of branch selection, though the order of
solutions found does depend on it.
Subgoal ordering, as was demonstrated in Example 1, can signicantly aect the eciency of proving a goal. There are two major approaches to subgoal ordering. The rst
approach uses various heuristics to order subgoals, for example:

 Choose a subgoal whose predicate has the smallest number of matching clauses (Minker,
1978).

42

The Divide-and-Conquer Subgoal-Ordering Algorithm

 Prefer a subgoal with more constants (Minker, 1978).
 Choose a subgoal with the largest size, where the size is dened as the number of
occurrences of predicate symbols, function symbols, and variables (Nie & Plaisted,
1990).

 Choose a subgoal with the largest mass, where the mass of a subgoal depends on
the frequency of its arguments and sub-arguments in the entire goal (Nie & Plaisted,
1990).

 Choose a subgoal with the least number of solutions (Warren, 1981; Nie & Plaisted,
1990).

 Apply \tests" before \generators" (Naish, 1985a).
 Prefer calls that fail quickly (Naish, 1985b).
The heuristic methods usually execute quickly, but may yield suboptimal orderings.
The second approach, which is adopted in this paper, aims at nding optimal orderings (Smith & Genesereth, 1985; Natarajan, 1987; Markovitch & Scott, 1989). Natarajan
proposed an ecient way to order a special sort of subgoal set (where all subgoals are independent), while Smith and Genesereth proposed a general, but inecient algorithm. In
the following section we build a unifying framework for dealing with subgoal ordering and
describe variations on Natarajan's and Smith and Genesereth's algorithms. We also show
how the two can be combined for increased eciency.

3. Algorithms for Subgoal Ordering in Logic Programs
The goal of the work presented here is to order subgoals for speeding up logic programs. This
section starts with an analysis of the cost of executing a sequence of subgoals. The resulting
formula is the basis for the subsequent ordering algorithms. Then we discuss dependence
of subgoals and present existing ordering algorithms for independent and dependent sets of
subgoals. Finally, we combine these algorithms into a more general and ecient one.

3.1 The Cost of Executing a Sequence of Subgoals

In this subsection we analyze the cost of executing a sequence of subgoals. The analysis
builds mainly on the work of Smith and Genesereth (1985).
Let S = fA1; A2; : : :Ak g be a set of subgoals and b be a binding. We denote Sols(S ) to
be the solution set of S , and dene Sols(;) = f;g. We denote Ai jb to be Ai whose variables
are bound according to b (Ai j; = Ai ). Finally, we denote Cost(Ai jb ) to be the amount of
resources needed for proving Ai jb . Cost(Ai jb ) should reect the time complexity of proving
Ai under binding b. For example, the number of unication steps is a natural measure of
complexity for logic programs (Itai & Makowsky, 1987).
To obtain the cost of nding all the solutions of an ordered sequence of subgoals

S~ = hA1; A2; A3; : : :Ani;
43

(1)

Ledeniov & Markovitch

we note that the proof-tree of A1 is traversed only once, the tree of A2 is traversed once
for each solution generated by A1 , the tree of A3 { once for each solution of fA1; A2g, etc.
Consequently, the total cost of proving Equation 1 is

Cost(hA1; : : :An i) = Cost(A1) +
=

X

Cost(A2jb) + : : : +

b2Sols(fA1 g)

n
X

X

Cost(An jb ) =

b2Sols(fA1 ;:::An,1 g)

X

Cost(Aijb):
i=1 b2Sols(fA1 ;:::Ai,1 g)

(2)

To compute Equation 2 one must know the cost and the solution set for each subgoal
under each binding. To reduce the amount of information needed, we derive an equivalent
formula, which uses average cost and average number of solutions.

Denition: Let B be a set of subgoals, A a subgoal. Dene cost(A)jB to be the average
cost of A over all solutions of B and nsols(A)jB to be its average number of solutions over
all solutions of B:
8
>
P (A); Cost(Ajb) B = ;
< Cost
B
cost(A)jB = > b2Sols
; B=
6 ;; Sols(B) =6 ;
j
Sols(B)j
: undened;
B 6= ;; Sols(B) = ;
( )

8
>
j;
B=;
< jPSols(fAgj)Sols
(
f
A
j
g
)
j
b
B
nsols(A)jB = > b2SolsjSols
; B=
6 ;; Sols(B) 6= ;
: undened; (B)j
B 6= ;; Sols(B) = ;
( )

From the rst denition, it follows that:

X

Cost(Aijb ) = jSols(fA1; : : :Ai,1 g)j  cost(Ai)jfA ;:::Ai, g :
1

b2Sols(fA1 ;:::Ai,1 g)

1

(3)

If we apply the second denition recursively, we obtain

jSols(fA1; : : :Aig)j =
=
=

X

jSols(fAijbg)j
b2Sols(fA1 ;:::Ai,1 g)
jSols(fA1; : : :Ai,1 g)j  nsols(Ai)jfA1;:::Ai,1g
Yi
: : : = nsols(Aj )jfA1:::Aj,1 g:
j =1

(4)

Note that we dened Sols(;) = f;g; thus, these equations hold also for i = 1. Incorporation
of Equations 3 and 4 into Equation 2 yields

Cost(hA1; A2; : : :An i) =

20i,1
n
X
4@ Y
i=1

j =1

1
3
nsols(Aj )jfA :::Aj, gA  cost(Ai )jfA :::Ai, g5 :
1

44

1

1

1

(5)

The Divide-and-Conquer Subgoal-Ordering Algorithm

For each subgoal Ai , its average cost is multiplied by the total number of solutions of
all the preceding subgoals. We can dene average cost and number of solutions for every
continuous sub-sequence of Equation 1: 8k1 ; k2; 1  k1  k2  n,
cost(hA1; : : :Ak i)j; , cost(hA1; : : :Ak ,1 i)j;
(6)
cost(hAk ; : : :Ak i)jfA ;:::Ak , g =
20 nsols(hA1; : : :Ak ,1 i)1j;
3
1

2

2

1

1

1

1

=

k
i,1
X
4@ Y
2

i=k1

j =k1

1

nsols(Aj )jfA ;:::Aj, g A  cost(Ai )jfA ;:::Ai, g 5
1

1

1

1

k
Y
nsols(hA1; : : :Ak i)j;
nsols(hAk ; : : :Ak i)jfA ;:::Ak , g =
=
nsols(Ai)jfA ;:::Ai, g
nsols(hA1; : : :Ak ,1 i)j; i=k
1

2

2

1

1

1

1

2

1

1

(7)

1

The values of cost(Ai ) and nsols(Ai ) depend on the position of Ai in the ordered sequence. For example, assume that we want to nd Abraham's sons, using the domain of
Example 1. The unordered conjunctive goal is fmale(Y),parent(abraham,Y)g. Let there
be N males in the database (two of them, Isaac and Ishmael, are Abraham's sons):
nsols(male(Y))j; = N
nsols(parent(abraham,Y))j; = 2
nsols(male(Y))jfparent(abraham,Y)g = 1 nsols(parent(abraham,Y))jfmale(Y)g = 2=N
Note that nsols(hmale(Y),parent(abraham,Y)i) = 2 = nsols(hparent(abraham,Y),male(Y)i),
exactly as Theorem 1 predicts.
Having dened the cost of a sequence of subgoals, we can now dene the objective of
our ordering algorithms:

Denition: Let S be a set of subgoals. Dene (S ) to be set of all permutations of
S . O~ S 2 (S ) is a minimal ordering of S (denoted Min(O~ S ; S )), if its cost according to
Equation 5 is minimal over all possible permutations of S :
Min(O~ S ; S ) () 8OS0 2  (S ) : Cost(O~ S )  Cost(OS0 ):
The total execution time is the sum of the time which is spent on ordering, and the
inference time spent by the interpreter on the ordered sequence. In this paper we focus
upon developing algorithms for minimizing the inference time. Elsewhere (Ledeniov &
Markovitch, 1998a, 1998b) we present algorithms that attempt to reduce the total execution
time.
The values of cost and number of solutions can be obtained in various ways: by exact
computation, by estimation and bounds, and by learning. Let us assume at the moment
that there exists a mechanism that returns the average cost and number of solutions of a
subgoal in time  . In Section 5 we show how this control knowledge can be obtained by
inductive learning.

3.2 Ordering of Independent Sets of Subgoals

The general subgoal ordering problem is NP-hard (Ullman & Vardi, 1988). However, there
is a special case where ordering can be performed eciently: if all the subgoals in the
45

Ledeniov & Markovitch

given set are independent, i.e. do not share free variables. This section begins with the
denition of subgoal dependence and related concepts. We then show an ordering algorithm
for independent sets and prove its correctness.
3.2.1 Dependence of Subgoals

Denition: Let S and B be sets of subgoals (B is called the binding set of S ). A pair of
subgoals in S is directly dependent under B, if they share a free variable not bound by a
subgoal of B.
A pair of subgoals is indirectly dependent with respect to S and B if there exists a third
subgoal in S which is directly dependent on one of them under B, and dependent (directly
or indirectly) on the other one under B. A pair of subgoals of S is independent under B if
it is not dependent under B (either directly or indirectly). A subgoal is independent of S
under B if it is independent of all members of S under B.
Two subsets S1  S and S2  S are mutually independent under the binding set B if
every pair of subgoals (A1; A2), such that A1 2 S1 and A2 2 S2, is independent under B.
The entire set S is called independent under the binding set B if all its subgoal pairs
are independent under B, and is called dependent otherwise. A dependent set of subgoals
is called indivisible if all its subgoal pairs are dependent under B, and divisible otherwise.
A divisibility partition of S under B, DPart(S ; B), is a partition of S into subsets that
are mutually independent and indivisible under B, except at most one subset which contains
all the subgoals independent of S under B. It is easy to show that DPart(S ; B) is unique.
For example, let S0 = fa; b(X ); c(Y ); d(X; Y ); e(Z ); f (Z; V ); h(W )g. With respect to
S0 and an empty binding set, the pair fb(X ); d(X; Y )g is directly dependent, fb(X ); c(Y )g
is indirectly dependent and fb(X ); e(Z )g is independent. If we represent a set of subgoals

as a graph, where subgoals are vertices and directly dependent subgoals are connected by
edges, then dependence is equivalent to connectivity and indivisible subsets are equivalent
to connected components of size greater than 1. The divisibility partition is the partition
of a graph into connected components, with all the \lonely" vertices collected together, in
a special component. Figure 3 shows an example of such a graph for the set S0 and for
an empty binding set. The whole set is divisible into four mutually independent subsets.
The subsets fe(Z ); f (Z; V )g and fb(X ); c(Y ); d(X; Y )g are indivisible. Elements of the
divisibility partition DPart(S0 ; ;) are shown by dotted lines.
If a subgoal is independent of the set, then its average cost and number of solutions do
not depend on its position within the ordered sequence:
P
Cost(Ajb) jSols(B)j  Cost(A)
=
= Cost(A);
cost(A)jB = b2Sols(B)
jSols(B)j
jSols(B)j

P

b2Sols(B) jSols(fAjbg)j

= jSols(B)j  jSols(fAg)j = jSols(fAg)j:
jSols(B)j
In this case we can omit the binding information and write cost(Ai ) instead of cost(Ai)jfA :::Ai, g ,
and nsols(Ai ) instead of nsols(Ai )jfA :::Ai, g.
In practice, program rule bodies rarely feature independent sets of literals. An example
is the following clause, which states that children like candy:
nsols(A)jB =

jSols(B)j

1

1

1

46

1

The Divide-and-Conquer Subgoal-Ordering Algorithm

fa,

b(X), c(Y), d(X,Y), e(Z), f(Z,V), h(W)

a
h(W)

b(X)

e(Z)
f(Z,V)

g)

c(Y)

d(X,Y)

Figure 3: An example of a graph representing a set of subgoals. Directly dependent subgoals

are connected by edges. Independent subgoals and indivisible subsets are equivalent to
connected components (surrounded by dashed lines). The divisibility partition (under
the empty binding set) is shown by dotted lines.
likes(X,Y)

child(X), candy(Y).

More often, independent rule bodies appear not because they are written as such in the
program text, but because some variables are bound in (initially dependent) rule bodies, as
a result of clause head unication. For example, if the rule
father(X,Y)

male(X), parent(X,Y).

is used to reduce father(abraham,W), then X is bound to abraham, and the rule body
becomes independent. Rule bodies often become independent after substitutions are performed in the course of the inference process.
3.2.2 Algorithm for Ordering Independent Sets by Sorting

Let S~ be an ordered sub-sequence of subgoals, B a set of subgoals. We denote
~
cn(S~ )jB = nsols(S)~jB , 1 :
cost(S )jB
The name \cn" reects the participation of cost and nsols in the denition. When the subsequence S~ is independent of other subgoals, the binding information (jB ) can be omitted.
Together, the average cost, average number of solutions, and cn value of a subgoal will be
called the control values of this subgoal.
For independent sets, there exists an ecient ordering algorithm, listed in Figure 4. The
complexity of this algorithm is O(n( + log n)): O(n   ) to obtain the control values of n
subgoals, and O(n log n) to perform the sorting (Knuth, 1973). To enable the division, we
must dene the cost so that cost(Ai ) is always positive. If we dene the cost as the number
of unications performed, then always cost(Ai )  1, under a reasonable assumption that
predicates of all rule body subgoals are dened in the program. (In this case, at least one
unication is performed for each subgoal). Similar algorithms were proposed by Simon and
Kadane (1975) and Natarajan (1987).
Example 2 Let the set of independent subgoals be fp; q; rg, with the following control values:
47

Ledeniov & Markovitch

Algorithm 1
Let S = fA1; A2; : : :An g be a set of subgoals.
(Ai ),1
Sort S using cn(Ai ) = nsols
cost(Ai ) as the key for Ai , and return the result.
Figure 4: The algorithm for ordering subgoals by sorting.
p q
r
cost 10 20
5
nsols 1 5
0:1
cn
0 0:2 ,0:18
We compute the costs of all possible orderings, using Equation 5:

Cost(hp; q; ri) = 10 + 1  20 + 1  5  5 = 55
Cost(hp; r; q i) = 10 + 1  5 + 1  0:1  20 = 17
Cost(hq; p; ri) = 20 + 5  10 + 5  1  5 = 95
Cost(hq; r; pi) = 20 + 5  5 + 5  0:1  10 = 50
Cost(hr; p; q i) = 5 + 0:1  10 + 0:1  1  20 = 8
Cost(hr; q; pi) = 5 + 0:1  20 + 0:1  5  10 = 12
The minimal ordering is hr; p; q i, and this is exactly the ordering which is found much
more quickly by Algorithm 1 for the set fp; q; rg: r has the smallest cn value, ,0:18, then
goes p with cn(p) = 0, and nally q with cn(q ) = 0:2.
Note that the sorting algorithm reects a well-known principle: The best implementations of generate-and-test programs are obtained with the tests placed as early as possible
in the rule body and the generations as late as possible (Naish, 1985a). Of course, the
cheap tests should come rst, while the expensive ones should come last. If one looks at
the cn measure, one quickly realizes that tests should be put in front (because nsols < 1,
so cn < 0), while generator subgoals should move towards the end (nsols > 1, so cn > 0).
The weakness of the \test-rst" principle is in the fact that not every subgoal can be easily
tagged as a test or a generator. If one subgoal has nsols < 1 and another one has nsols > 1,
then their order is obvious even without looking at the costs (because their cn values have
dierent signs). But if both subgoals have nsols < 1, or both have nsols > 1, then the
decision is not so simple. Sorting by cn can correctly handle all the possible cases.
3.2.3 Correctness Proof of the Sorting Algorithm for Independent Sets

We saw that Algorithm 1 found a minimal ordering in Example 2. We are now going to
prove that Algorithm 1 always nds a minimal ordering for independent sets. First we
show an important lemma which will also be used in further discussion. This lemma states
48

The Divide-and-Conquer Subgoal-Ordering Algorithm

that substitution of a sub-sequence by its cheaper permutation makes the entire sequence
cheaper.

Lemma 1
Let S~ = A~ kB~ kC~ , S~ 0 = A~ kB~ 0 kC~ , where B~ and B~ 0 are permutations of one another, and A~
either is empty or has nsols(A~ ) > 0. Then

Cost(S~ ) < Cost(S~ 0 ) () cost(B~ )jA~ < cost(B~ 0 )jA~ ;
Cost(S~ ) = Cost(S~ 0 ) () cost(B~ )jA~ = cost(B~ 0 )jA~ :

Proof: If A~ and C~ are not empty,
Cost(S~ ) , Cost(S~ 0 ) = Cost(A~ kB~ kC~ ) , Cost(A~ kB~ 0 kC~ ) =


(5)
= cost(A~ )j; + nsols(A~ )j;  cost(B~ )jA~ + nsols(A~ kB~ )j;  cost(C~ )jA~ kB~ ,
 ~

cost(A)j; + nsols(A~ )j;  cost(B~ 0 )jA~ + nsols(A~ kB~ 0 )j;  cost(C~ )jA~ kB~ 0 :

By Theorem 1, B~ and B~ 0 produce the same solution sets. Hence, the third terms in the
parentheses above are equal, and





Cost(S~ ) , Cost(S~ 0) = nsols(A~ )j;  cost(B~ )jA~ , cost(B~ 0 )jA~ :
Since nsols(A~ ) > 0, the sign of Cost(S~ ) , Cost(S~ 0 ) coincides with the sign of cost(B~ )jA~ ,
cost(B~ 0 )jA~ .
If A~ or C~ is empty, the proof is similar.
2
Denition: Let S~ = A~ kB~ 1kC~ kB~ 2kD~ be an ordered sequence of subgoals (A~, C~ and D~ may
be empty sequences). With respect to S~ , the pair hB~ 1 ; B~ 2i is

 cn-ordered, if cn(B~ 1)jA~  cn(B~ 2)jA~[B~ [C~
1

 cn-inverted, if cn(B~ 1)jA~ > cn(B~ 2)jA~[B~ [C~
1

We now show that two adjacent mutually independent sequences of subgoals in a minimal
ordering must be cn-ordered.

Lemma 2
Let S~ = A~ kB~ 1 kB~ 2 kC~ , S~ 0 = A~ kB~ 2 kB~ 1 kC~ , where B~ 1 , B~ 2 are mutually independent under A~ .
Let A~ either be empty or have nsols(A~ ) > 0. Then

Cost(S~ ) < Cost(S~ 0) () cn(B~ 1)jA~ < cn(B~ 2)jA~ ;
Cost(S~ ) = Cost(S~ 0) () cn(B~ 1)jA~ = cn(B~ 2)jA~ :
49

Ledeniov & Markovitch

Proof:
Cost(S~ ) < Cost(S~ 0) Lemma
() 1 cost(B~ 1kB~ 2)jA~ < cost(B~ 2kB~ 1)jA~
() cost(B~ 1)jA~ + nsols(B~ 1)jA~ cost(B~ 2)jA~[B~ <
cost(B~ 2 )jA~ + nsols(B~ 2 )jA~ cost(B~ 1 )jA~[B~
indep.fB~ 1 ; B~ 2g
()
cost(B~ 1 )jA~ + nsols(B~ 1 )jA~ cost(B~ 2 )jA~ <
cost(B~ 2 )jA~ + nsols(B~ 2 )jA~ cost(B~ 1 )jA~
() nsols(B~ 1)jA~  cost(B~ 2)jA~ , cost(B~ 2)jA~ <
nsols(B~ 2 )jA~  cost(B~ 1 )jA~ , cost(B~ 1 )jA~
cost(B~ i )jA~ >0 nsols(B~ 1 )jA~ , 1 nsols(B~ 2 )jA~ , 1
()
<
cost(B~ 1 )jA~
cost(B~ 2 )jA~
() cn(B~ 1)jA~ < cn(B~ 2)jA~
1
2

Cost(S~ ) = Cost(S~ 0)

()

cn(B~ 1 )jA~ = cn(B~ 2)jA~ | similar.

2

In an independent set, all subgoal pairs are independent, in particular all adjacent pairs.
So, in a minimal ordering of an independent set, all adjacent subgoal pairs must be cnordered; otherwise, the cost of the sequence can be reduced by a transposition of such pair.
This conclusion is expressed in the following theorem.

Theorem 2
Let S be an independent set. Let S~ be an ordering of S . S~ is minimal i all the subgoals in
S~ are sorted in non-decreasing order by their cn values.

Proof:

1. Let S~ be a minimal ordering of S . If S~ contains a cn-inverted adjacent pair of subgoals,
then transposition of this pair reduces the cost of S~ (Lemma 2), contradicting the
minimality of S~ .

2. Let S~ be some ordering of S , whose subgoals are sorted in non-decreasing order by
cn. Let S~ 0 be a minimal ordering of S . According to item 1, S~ 0 is also sorted by
cn. The only possible dierence between the two sequences is the internal ordering
of sub-sequences with equal cn values. The ordering of each such sub-sequence in
S~ can be transformed to the ordering of its counterpart sub-sequence in S~ 0 by a
nite number of transpositions of adjacent subgoals. By Lemma 2, transpositions of
adjacent independent subgoals with equal cn values cannot change the cost of the
sequence. Therefore, Cost(S~ ) = Cost(S~ 0), and S~ is a minimal ordering of S (since S~ 0
is minimal).
2

Corollary 1 Algorithm 1 nds a minimal ordering of an independent set of subgoals.
50

The Divide-and-Conquer Subgoal-Ordering Algorithm

3.3 Ordering of Dependent Sets of Subgoals

Algorithm 1 does not guarantee nding a minimal ordering when the given set of subgoals
is dependent, as the following proposition shows.

Proposition 1 When the given set of subgoals is dependent, then:
1. The result of Algorithm 1 on it is not always dened.
2. Even when the result is dened, it is not always a minimal ordering of the set.

Proof: Both claims are proved by counter-examples.
1. We show a set of subgoals that cannot be ordered by sorting.
The program:
Control values:
a(X )j; a(X )jfb(X )g b(X )j; b(X )jfa(X )g
a(c1).
b(c1).
cost
2
2
2
2
a(c2).
b(c2).
nsols
2
1
2
1
1
1
cn
0
0
2
2

The set fa(X), b(X)g has two possible orderings, ha(X ); b(X )i and hb(X ); a(X )i.
Both orderings have minimal cost, though neither one is sorted by cn: each ordering
has cn = 12 for its rst subgoal, and cn = 0 for the second one. Sorting by cn is
impossible here: when we transpose subgoals, their cn values are changed, and the
pair becomes cn-inverted again.
2. We show a set of subgoals that can be ordered by sorting, but its sorted ordering is
not minimal.
The program:
Control values:
a(X )j; a(X )jfb(X )g b(X )j; b(X )jfa(X )g
a(c1).
cost
2
2
8
2
a(c1).
2
2
1
1
nsols
b(c1).
1
1
cn
0
0
b(c2)
a(c1), a(c2).
2
2
Let the unordered set of subgoals be fa(X), b(X)g. Its ordering hb(X ); a(X )i is sorted
by cn, while ha(X ); b(X )i is not. But ha(X ); b(X )i is cheaper than hb(X ); a(X )i:
cost(ha(X ); b(X )i) = 2 + 2  2 = 6

cost(hb(X ); a(X )i) = 8 + 1  2 = 10

2
Since sorting cannot guarantee minimal ordering for dependent subgoals, we now consider alternative ordering algorithms. The simplest algorithm checks every possible permutation of the set and returns the one with the minimal cost. The listing for this algorithm
is shown in Figure 5.
This algorithm runs in O(  n!) time, where  is the time it takes to compute the control
values for one subgoal, and n is the number of subgoals.
The following observation can help to reduce the ordering time at the expense of additional space. Ordered sequences can be constructed incrementally, by adding subgoals to
51

Ledeniov & Markovitch

Algorithm 2
For each permutation of subgoals, nd its cost according to Equation 5.
Store the currently cheapest permutation and update it when a cheaper
one is found.
Finally, return the cheapest permutation.

Figure 5: The algorithm for subgoal ordering by an exhaustive check of all permutations.

Algorithm 3
Order(S )
let P0 f;g; n jSj
loop for kn= 1 to n
o
Pk0 nP~ kB  P~ 2 Pk,1; B h2 S n P~
io
~ P~ 0 ) ) Cost(P~ )  Cost(P~ 0 )
Pk P~ 2 Pk0  8P~ 0 2 Pk0 ; permutation(P;
Return the single member of Pn .
Figure 6: The ordering algorithm which checks permutations of ordered prexes.
the right ends of ordered prexes. By Lemma 1, if a cheaper permutation of a prex exists,
then this prex cannot belong to a minimal ordering. The ordering algorithm can build
prexes with increasing lengths, at each step adding to the right end of each prex one of
the subgoals that do not appear in it already, and for each subset keeping only its cheapest
permutation (if several permutations have equal cost, any one of them can be chosen). The
listing for this algorithm is shown in Figure 6. At each step k, Pk0 stores the set of prexes
from step k , 1 extended by every subgoal not appearing there already. Pk  Pk0 , and
in Pk each subset of subgoals is represented only by its cheapest permutation. Obviously,
jPk j = (nk) (one prex is kept for every subset of S of size k). For each prex of length k , 1,
there are n , (k , 1) possible continuations of length k. The size of Pk0 is as follows:
!
k
n!
n
jPk0 j = (k,n1)(n,(k,1)) = (n , (k ,n1))!(
k , 1)! (n,(k,1)) = k  (n , k)!(k , 1)! = k (k ):
For each prex, we compute its cost in  time. The permutation test can be completed
in O(n) time, by using, for example, a trie structure (Aho et al., 1987), where subgoals in
prexes are sorted lexicographically. Each step k takes O((n +  )  k  (nk )) time, and the
52

The Divide-and-Conquer Subgoal-Ordering Algorithm

whole algorithm runs in
n
X

k=1

O((n +  )  k  (nk )) = O(n  (n +  ) 

n
X
n
k=1

(k )) = O(n  (n +  )  2n ):

If  = O(n), this makes O(n2  2n ).
Smith and Genesereth (1985) and Natarajan (1987) point out that in a minimal ordered
sequence every adjacent pair of subgoals must satisfy an adjacency restriction. The most
general form of such a restriction in our notation says that two adjacent subgoals Ak and
Ak+1 in a minimal ordering hA1; A2 : : :Ani must satisfy
cost(hAk ; Ak+1i)jfA :::Ak, g  cost(hAk+1 ; Ak i)jfA :::Ak, g:
1

1

1

1

(8)

The restriction follows immediately from Lemma 1. However, it can only help to nd a
locally minimal ordering, i.e., an ordering that cannot be improved by transpositions of
adjacent subgoals. It is possible that all adjacent subgoal pairs satisfy Equation 8, but the
ordering is still not minimal. The following example illustrates this statement.

Example 3 Let the unordered set be fp(X ); q(X ); r(X )g, where the predicates are dened
by the following program:

p(c1):
q (c1):
r(c1):
p(c2) f: q (c2):
r(c1):
q (c3) f:
f fails after 50 unications.
The ordering hp(X ); q (X ); r(X )i satises the adjacency restriction (Equation 8):
cost(q (X ); r(X ))jp(X ) = 5
cost(p(X ); q (X ))j; = 55
cost(q (X ); p(X ))j; = 107
cost(r(X ); q (X ))jp(X ) = 8
But it is not minimal:

cost(hp(X ); q(X ); r(X )i) = 57
cost(hr(X ); p(X ); q (X )i) = 12

To nd a globally minimal ordering, it seems benecial to combine the prex algorithm
with the adjacency restriction: if a prex does not satisfy the adjacency restriction, then
there is a cheaper permutation of this prex. The adjacency test can be performed faster
than the permutation test, since it must only consider the two last subgoals of each prex. Nevertheless, the number of prexes remaining after each step of Algorithm 3 is not
reduced: if a prex is rejected due to a violation of the adjacency restriction, it would have
also been rejected by the permutation test. Furthermore, if the adjacency restriction test
does not fail, we should still perform the permutation test to avoid local minima (as in
Example 3). The adjacency test succeeds in at least half of the cases: if we examine a
prex hA1 ; : : :Ak ; B1; B2 i, we shall also examine hA1; : : :Ak ; B2 ; B1i, and the adjacency test
cannot fail in both. Consequently, addition of the adjacency test can only halve the total
running time of the ordering algorithm, leaving it O(n2  2n ) in the worst case.
53

Ledeniov & Markovitch

Smith and Genesereth propose performing a best-rst search in the space of ordered
prexes, preferring prexes with lower cost. The best-rst search can be combined with
the permutation test and the adjacency restriction. In addition, when the subgoals not
in a prex are independent under its binding, they can be sorted, and the sorted result
concatenated to the prex. By Lemma 1 and Corollary 1, this produces the cheapest
completion of this prex. When we perform completion, there is no need to perform the
adjacency or permutation test: if a complete sequence is not minimal, it will never be chosen
as the cheapest prex; even if it is added to the list of prexes, it will never be extracted
therefrom. The resulting algorithm is shown in Figure 7.

Algorithm 4
Order(S )

let prex-list ;, prex ;, rest S
loop until empty(rest)
if Independent(restjprex)
then
let completion prexkSort-by-cn(restjprex)
Insert-By-Cost(completion, prex-list)
else
loop for subgoal 2 rest
let extension prexksubgoal
if Adjacency-Restriction-Test(extension)
and Permutation-Test(extension)
then
Insert-By-Cost(extension, prex-list)
prex Cheapest(prex-list)
Remove-from-list(prex, prex-list)
rest Snprex
Return prex

Figure 7: An algorithm for subgoal ordering, incorporating the ideas of earlier researchers.
The advantage of using best-rst search is that it avoids expanding prexes whose cost
is higher than the cost of the minimal ordering. The policy used by the algorithm may,
however, be suboptimal or even harmful. It often happens that the best completion of a
cheaper prex is much more expensive than the best completion of a more expensive prex.
When the number of solutions is large, it is better to place subgoals with high costs closer
to the beginning of the ordering to reduce the number of times that their cost is multiplied.
For example, let the set be fa(X ); b(X )g, with cost(a(X )) = 10, cost(b(X )) = nsols(a(X ))
= nsols(b(X )) = 2. Then a minimal ordering starts with the most expensive prex:
Cost(ha(X ); b(X )i) = 10 + 2  2 = 14
54

The Divide-and-Conquer Subgoal-Ordering Algorithm

Cost(hb(X ); a(X )i) = 2 + 2  10 = 22
If there are many prexes whose cost is higher than the cost of the minimal ordering, then
best-rst search saves time. But if the number of such prexes is small, using best-rst
search can increase the total time, due to the need to perform insertion of a prex into a
priority queue, according to its cost.
A sample run of Algorithm 4 will be shown later (in Section 4.7).

4. The Divide-and-Conquer Subgoal Ordering Algorithm

Algorithm 1 presented in Section 3.2 is very ecient, but is applicable only when the entire
set of subgoals is independent. Algorithm 3 can handle a dependent set of subgoals but is
very inecient. Algorithm 4, a combination of the two, can exploit independence of subgoals for better eciency. However, the obtained benet is quite limited. In this section,
we present the Divide-and-Conquer (dac) algorithm, which is able to exploit subgoal independence in a more elaborate way. The algorithm divides the set of subgoals into smaller
subsets, orders these subsets recursively and combines the results.

4.1 Divisibility Trees of Subgoal Sets

In this subsection we dene a structure that represents all the ways of breaking a subgoal
set into independent parts. Our algorithm will work by traversing this structure.
Denition: Let S and B be sets of subgoals. The divisibility tree of S under B, DTree(S ; B),
is an AND-OR tree dened as follows:
8 leaf(S ; B)
, S is independent under B
>
>

>
<
DTree(S ; B) = > OR(S ; B; fDTree(S n fBi g; B [ fBi g) j Bi 2 Sg) , S is indivisible under B
>
: AND(S ; B; fDTree(Si; B) j Si 2 DPart(S ; B)g) , S is divisible under B

Each node N in the tree DTree(S0; B0) has an associated set of subgoals S (N )  S0 and
an associated binding set B(N )  B0. For the root node, S (N ) = S0, B(N ) = B0 . If the
binding set of the root is not specied explicitly, we assume it to be empty. For AND-nodes
and OR-nodes we also dene the sets of children.

 If S (N ) is independent under B(N ), then N is a leaf.
 If S (N ) is indivisible under B(N ), then N is an OR-node. Each subgoal Bi in S (N )
denes a child node whose set of subgoals is S (N ) n fBi g and the binding set is
B(N ) [ fBi g. We call Bi the binder of the generated child. Note that the binding
set of every node in a divisibility tree is the union of the binders of all its indivisible
ancestors and of the root's binding set.

 If S (N ) is divisible under B(N ), then N is an AND-node. Each subset Si in the
divisibility partition DPart(S (N ); B(N )) denes a child node with associated set of
subgoals Si and binding set B(N ). Divisibility partition was dened in Section 3.2.1.
55

Ledeniov & Markovitch

= {a, b, c(X), d(X), e(X)}
n1 S(n1)
B(n1) = O

S(n2) = {a, b}
B(n2) = O

n2

S(n3) = {c(X), d(X), e(X)}

n3 B(n3) = O

S(n4) = {d(X), e(X)}
S(n6) = {c(X), d(X)}
n5
n6 B(n6) = {e(X)}
B(n4) = {c(X)} n4
S(n5) = {c(X), e(X)}
B(n5) = {d(X)}

Figure 8: The divisibility tree of fa; b; c(X ); d(X ); e(X )g under empty initial binding set. The set
associated with node n1 is divisible, and is represented by an AND-node. Its children
correspond to its divisibility subsets { one independent, S (n2) = fa; bg, and one indivisible, S (n3) = fc(X ); d(X ); e(X )g. n3 is an OR-node, whose children correspond to its
three subgoals (each subgoal serves as a binder in one of the children). The sets S (n2),
S (n4), S (n5) and S (n6) are independent under their respective binding sets, and their
nodes are leaves. Here we assumed that the subgoals c(X ), d(X ) and e(X ) bind X as a
result of their proof.

It is easy to show that the divisibility tree of a set of subgoals is unique up to the order of
children of each node. Figure 8 shows the divisibility tree of the set fa; b; c(X ); d(X ); e(X )g
under empty initial binding set. The associated sets and binding sets are written next to
the nodes.
The following lemma expresses an important property of divisibility trees: subgoals of
each node are independent of the rest of subgoals under the binding set of the node.

Lemma 3 Let S0 be a set of subgoals. Then for every node N in DTree(S0; ;), for every
subgoal A 2 S (N ), and for every subgoal Y 2 S0 n (S (N ) [B(N )), A and Y are independent
under B(N ).
Proof: by induction on the depth of N in the divisibility tree.
Inductive base: N is the root node, S0 n S (N ) is empty, and no such Y exists.
Inductive hypothesis: The lemma holds for M , the parent node of N .
Inductive step: Let A 2 S (N ), Y 2 S0 n (S (N ) [ B(N )). A 2 S (M ), and for M the
lemma holds, thus either A and Y are independent under B(M ), or Y 2 S (M ).
If A and Y are independent under B(M ), then they are also independent under B(N ),
since B(M )  B(N ). Otherwise, A and Y are dependent under B(M ), and Y 2 S (M ).
56

The Divide-and-Conquer Subgoal-Ordering Algorithm

 If M is an AND-node, and A and Y are dependent under B(M ), then A and
Y belong to the same element of DPart(S (M ); B(M )), and Y 2 S (N ) { a

contradiction.
 If M is an OR-node and Y 2 S (M ) n S (N ), then Y must be the binder of N .
But then B(N ) = B(M ) [ fY g and Y 2 B(N ) { a contradiction again.
2
The lemma relates to subgoal independence inside divisibility trees. We shall sometimes
need to argue about independence inside ordered sequences of subgoals. The following
corollary provides the necessary connecting link.

Corollary 2 Let S0 be a set of subgoals, N be a node in the divisibility tree of S0, S~ an
ordering of S0, S~ = S~1 kS~2, where B(N )  S~1 and S (N )  S~2 . Then S (N ) is mutually
independent of S~2 n S (N ) under S~1.
Proof: Let A 2 S (N ), Y 2 S~2 n S (N ). A and Y are independent under B(N ), by the
preceding lemma. Since B(N )  S~1 , A and Y are independent under S~1. Every subgoal of
S (N ) is independent of every subgoal of S~2 nS (N ) under S~1; therefore, S (N ) and S~2 nS (N )
are mutually independent under S~1 .

2

4.2 Valid Orderings in Divisibility Trees

The aim of our ordering algorithm is to nd a minimal ordering of a given set of subgoals.
We construct orderings following a divide-and-conquer policy: larger sets are split into
smaller ones, and orderings of the smaller sets are combined to produce an ordering of the
larger set. To implement this policy, we perform a post-order traversal of the divisibility
tree corresponding to the given set of subgoals under an empty initial binding set. When
orderings of child nodes are combined to produce an ordering of the parent node, the inner
order of their subgoals is not changed: smaller orderings are consistent with larger orderings.

Denition: Let S and G  S be sets of subgoals. An ordering O~ G of G and an ordering
O~ S of S are consistent (denoted Cons(O~ G; O~ S )), if the order of subgoals of G in O~ G and in
O~ S is the same.

The divide-and-conquer process described above seems analogous to Merge Sort (Knuth,
1973). There, the set of numbers is split into two (or more) subsets, each subset is independently ordered to a sequence consistent with the global order, and these sequences are
merged. Is it possible to use a similar method for subgoal ordering? Assume that a set
of subgoals is partitioned into two mutually independent subsets, A and B. Can we build
an algorithm that, given A, produces its ordering consistent with a minimal ordering of
A [ B, independently of B? Unfortunately, the answer is negative. An ordering of A may
be consistent with a minimal ordering of A [ B1 but at the same time not be consistent
with a minimal ordering of A [ B2 for some B1 6= B2.
For example, let A = fa1(X ); a2(X )g, B1 = fbg, B2 = fdg and the control values be as
specied in Figure 9. The single minimal ordering of A [ B1 is ha2(X ); b; a1(X )i, while the
single minimal ordering of A[B2 is hd; a1(X ); a2(X )i. There is no ordering of A consistent
with both these minimal global orderings.
57

Ledeniov & Markovitch

The program:
a1(c1).
a1(c1).
a2(c1).
a2(c1).
a2(c2)

b
b
d.

a1(X).
d.

a1(c2).

The control values:
a1(X )j; a1(X )jfa2(X )g a2(X )j; a2(X )jfa1(X )g b d
cost
2
2
5
3
5 1
nsols
2
2
2
2
3 1

Cost(b; a1(X ); a2(X )) = 5 + 3  2 + 3  2  3 = 29
Cost(b; a2(X ); a1(X )) = 5 + 3  5 + 3  2  2 = 32
Cost(a1(X ); b; a2(X )) = 2 + 2  5 + 2  3  3 = 30
Cost(a1(X ); a2(X ); b) = 2 + 2  3 + 2  2  5 = 28
Cost(a2(X ); b; a1(X )) = 5 + 2  5 + 2  3  2 = 27
Cost(a2(X ); a1(X ); b) = 5 + 2  2 + 2  2  5 = 29

Cost(d; a1(X ); a2(X )) = 1 + 1  2 + 1  2  3 = 9
Cost(d; a2(X ); a1(X )) = 1 + 1  5 + 1  2  2 = 10
Cost(a1(X ); d; a2(X )) = 2 + 2  1 + 2  1  3 = 10
Cost(a1(X ); a2(X ); d) = 2 + 2  3 + 2  2  1 = 12
Cost(a2(X ); d; a1(X )) = 5 + 2  1 + 2  1  2 = 11
Cost(a2(X ); a1(X ); d) = 5 + 2  2 + 2  2  1 = 13

Figure 9: We show a small program and the control values it denes. Then we compute costs of all
permutations of the sets fb; a1(X ); a2(X )g and fd; a1(X ); a2(X )g. Dierent orderings of
fa1(X ); a2(X )g are consistent with minimal orderings of these sets.
Since, unlike the case of Merge Sort, we cannot always identify a single ordering of the
subset consistent with a minimal ordering of the whole set, our algorithm will deal with
sets of candidate orderings. Our requirement from such a set is that it contain at least
one local ordering consistent with a global minimal ordering, if such a local ordering exists
(\local" ordering is an ordering of the set of the node, \global" ordering is an ordering of
the set of the root). Such a set will be called valid. The following denition denes valid
sets formally, together with several other concepts.
Denition: Let S0 be a set of subgoals and N be a node in the divisibility tree of S0.
Recall that  (S ) denotes the set of all permutations of S .
1. O~ S 2  (S0) is binder-consistent with O~ N 2  (S (N )) (denoted BCN (O~ N ; O~ S )), if they
are consistent, and all subgoals of B(N ) appear in O~ S before all subgoals of O~ N :
BCN (O~ N ; O~ S ) () 9O~ B 2 (B(N )) : Cons(O~ B kO~ N ; O~ S ):
O~ S 2 (S0) is binder-consistent with the node N (denoted BCN (O~ S )), if it is binderconsistent with some ordering of S (N ):
BCN (O~ S ) () 9O~ N 2 (S (N )) : BCN (O~ N ; O~ S ):
2. O~ N 2  (S (N )) is min-consistent with O~ S 2  (S0) (denoted MCN;S (O~ N ; O~ S )), if they
are binder-consistent, and O~ S is minimal:
MCN;S (O~ N ; O~ S ) () BCN (O~ N ; O~ S ) ^ Min(O~ S ; S0):
O~ N 2 (S (N )) is min-consistent (denoted MCN;S (O~ N )), if it is min-consistent with
some ordering of S0:
MCN;S (O~ N ) () 9O~ S 2 (S0) : MCN;S (O~ N ; O~ S ):
0

0

0

0

0

58

The Divide-and-Conquer Subgoal-Ordering Algorithm

3. An ordering O~ N 2  (S (N )) is MC-contradicting, if it is not min-consistent:
MCCN;S (O~ N ) () :MCN;S (O~ N ):
0

0

4. Two orderings O~ 1; O~ 2 2  (S (N )) are MC-equivalent, if one of them is min-consistent
i the other one is:
MCEN;S (O~ 1; O~ 2) () [MCN;S (O~ 1) () MCN;S (O~ 2)]:
0

0

0

5. A set of orderings CN   (S (N )) is valid, if CN contains a min-consistent ordering
(when at least one min-consistent ordering of S (N ) exists):

V alidN;S (CN ) () [9O~ N0 2  (S (N )) : MCN;S (O~ N0 )] ! [9O~ N 2 CN : MCN;S (O~ N )]:
0

0

0

An important property of valid sets is that a valid set of orderings of the root of

DTree(S0; ;) must contain a minimal ordering of S0. Indeed, in the root S (N ) = S0,
and consistency becomes identity. Also, B(N ) = ;, so that binder-consistency becomes

consistency, and min-consistency becomes minimality. Since there always exists a minimal
ordering of S0 , a valid set of orderings of the root must contain a minimal ordering of S0.

4.3 The Outline of the Divide-and-Conquer Algorithm

We propose an algorithm that is based on producing valid sets of orderings. Each node in
a divisibility tree produces a valid set for its associated set of subgoals, and passes it to
its parent node. After the valid set of the root node is found, we compare costs of all its
members, and return the cheapest one.
The set of orderings produced by the algorithm for a node N is called a candidate set
of N . Its members are called candidate orderings of N , or simply candidates. To nd
a candidate set of N , we rst consider the set of all possible orderings of S (N ) that are
consistent with candidates of N 's children. This set is called the consistency set of N .
Given the candidate sets of N 's children, the consistency set of N is dened uniquely. A
candidate set of N is usually not unique.
Denition: Let N be a node in a divisibility tree of S0. The consistency set of N , denoted
ConsSet(N ), and the candidate set of N , denoted CandSet(N ), are dened recursively:

 If N is a leaf, its consistency set contains all permutations of S (N ):
ConsSet(N ) = (S (N )):

 If N is an AND-node, and its child nodes are N1; N2; : : :Nk , we dene the consistency
set of N as the set of all possible orderings of S (N ) consistent with candidates of
N1; N2; : : :Nk :


n
o
ConsSet(N ) = O~ N 2 (S (N ))  8i (1  i  k); 9O~ i 2 CandSet(Ni) : Cons(O~ i ; O~ N ) :
59

Ledeniov & Markovitch

 If N is an OR-node, and its child node corresponding to every binder A 2 S (N ) is

NA , then the consistency set of N is obtained by adding binders as the rst elements
to the candidates of the children:

n
o
ConsSet(N ) = AkO~ A  A 2 S (N ); O~ A 2 CandSet(NA) :

 A candidate set of N is any set of orderings produced by removing MC-contradicting

and MC-equivalent orderings out of the consistency set of N , while keeping at least
one representative for each group of MC-equivalent orderings:
CandSet(N )  ConsSet(N );
~ON 2 (ConsSet(N ) n CandSet(N )) ) MCCN;S (O~ N ) _
h 0
i
9O~ N 2 CandSet(N ) : MCEN;S (O~ N ; O~ N0 ) :
0

0

(In other words, if some ordering is rejected, it is either MC-contradicting, or MCequivalent to some other ordering, which is not rejected.)
There are two kinds of orderings which can be removed from ConsSet(N ) while retaining its validity: MC-contradicting and MC-equivalent orderings. Removal of an MCcontradicting ordering cannot change the number of min-consistent orderings in the set; if
we remove an MC-equivalent ordering, then even if it is min-consistent, some other minconsistent ordering is retained in the set. If there exists a min-consistent ordering of the set
of the node, then its candidate set must contain a min-consistent ordering, and therefore
the candidate set is valid.
Note that when our algorithm treats an OR-node, the binder of each child is always
placed as the rst subgoal of the produced ordering of this node. On higher levels the inner
order of subgoals in the ordering does not change (consistency is preserved). Therefore,
our algorithm can only produce binder-consistent orderings. This explains the choice of
the names \binder" and \binding set": the subgoals of B(N ) bind some common variables
of S (N ), since they stand to the left of them in any global ordering that our algorithm
produces. In particular, if S (N ) is independent under B(N ), then the subgoals of B(N )
bind all the shared free variables of S (N ).
To implement the DPart function, we can use the Union-Find data structure (Cormen,
Leiserson, & Rivest, 1991, Chapter 22), where subgoals are elements, and indivisible sets
are groups. In the beginning, every subgoal constitutes a group by itself. Whenever we
discover that two subgoals share a free variable not bound by subgoals of the binding set,
we unite their groups into one. To complete the procedure, we need a way to determine
which variables are bound by the given binding set. Section 7.1 contains a discussion of
this problem and proposes some practical solutions. Finally, we collect all the indivisible
subgoals into a separate group. These operations can be implemented in O(n(n; n)) amortized time, where (n; n) is the inverse Ackermann function, which can be considered O(1)
for all values of n that can appear in realistic logic programs. Thus, the whole process of
nding the divisibility partition of n subgoals can be performed in O(n) average time.
The formal listing of the ordering algorithm discussed above is shown in Figure 10.
The algorithm does not specify explicitly how candidate sets are created from consistency sets. To complete this algorithm, we must provide the three ltering procedures
60

The Divide-and-Conquer Subgoal-Ordering Algorithm

Algorithm 5
Order(S0)

RootCandSet

CandidateSet(S0 ; ;)

Return the cheapest member of RootCandSet

CandidateSet(S ; B)
case (S under B)

independent:
let ConsSetN  (S )
let CandSetN ValidLeafFilter(ConsSetN )
divisible:
let fS1; S2; : : : Sk g DPart(S ; B)
loop for i = 1 to k
let Ci CandidateSet
(Si ; B)
n~
o
let ConsSetN
ON 2 (S (N )) j 8i = 1 : : :k; 9O~ i 2 Ci : Cons(O~ i; O~ N )
let CandSetN ValidANDFilter(ConsSetN ; fS1; : : : Sk g; fC1; : : : Ck g)
indivisible:
loop for A 2 S
let C (A) CandidateSet
n ~ ~ (S n foAg; B [ fAg)
0
let C (A)
ASkOA j OA 2 C (A)
0
let ConsSetN
A2S C (A)
let CandSetN ValidORFilter(ConsSetN )
Return CandSetN

Figure 10: The skeleton of the dac ordering algorithm. For each type of node in a divisibility tree,

a consistency set is created and rened through validity lters. The produced candidate
set of the root is valid; hence, its cheapest member is a minimal ordering of the given
set.

{ ValidLeafFilter , ValidANDFilter and ValidORFilter . Trivially, we can dene them
all as null lters that return the sets they receive unchanged. In this case the candidate
set of every node will contain all the permutations of its subgoals, and will surely be valid.
This will, however, greatly increase the ordering time. Our intention is to reduce the sizes
of candidate sets as far as possible, while keeping them valid.
In the following two subsections we discuss the ltering procedures. Section 4.4 discusses detection of MC-contradicting orderings, and Section 4.5 discusses detection of MCequivalent orderings. Finally, in Section 4.6 we present the complete ordering algorithm,
incorporating the lters into the skeleton of Algorithm 5.
61

Ledeniov & Markovitch

4.4 Detection of MC-Contradicting Orderings

In this subsection we show sucient conditions for an ordering to be MC-contradicting.
Such orderings can be safely discarded, leaving the set of orderings valid, but reducing its
size. The subsection is divided into three parts, one for each type of node in a divisibility
tree.
4.4.1 Detection of MC-Contradicting Orderings in Leaves

The following lemma shows that subgoals in a min-consistent ordering of a leaf node must
be sorted by cn.

Lemma 4
Let S0 be a set of subgoals, N be a leaf in the divisibility tree of S0. Let O~ N be an ordering of
S (N ). If the subgoals of O~ N are not sorted by cn under B(N ), then O~ N is MC-contradicting.
Proof: Let O~ S be any ordering of S0, binder-consistent with O~ N . We show that O~ S cannot
be a minimal ordering of S0, thus O~ N is not min-consistent.
O~ N is not sorted by cn, i.e., it contains an adjacent cn-inverted pair of subgoals hA1; A2i.

(Recall that a pair is cn-inverted if the rst element has a larger cn value than the second
one { Section 3.2.3). Since O~ S is consistent with O~ N , we can write O~ S = X~ kA1 kY~ kA2kZ~ ,
where X~ , Y~ and Z~ are (possibly empty) sequences of subgoals. Since O~ S is binder-consistent
with O~ N , B(N )  X~ .
If Y~ is empty, then A1 and A2 are adjacent in O~ S . Since B(N )  X~ , A1 and A2 are
independent under X~ . Therefore, the cost of the whole ordered sequence can be reduced
by transposing A1 and A2 , according to Lemma 2 (they are adjacent, independent and
cn-inverted).
If Y~ is not empty, then no subgoal of Y~ belongs to S (N ), since otherwise it would appear
in O~ N between A1 and A2 . By Corollary 2, Y~ is mutually independent of both A1 and A2
under X~ .

 If cn(Y~ )jX~ < cn(A1)jX~ then, by Lemma 2, a transposition of Y~ with A1 produces an
ordering with lower cost.
 Otherwise, cn(Y~ )jX~  cn(A1)jX~ . Since the pair hA1; A2i is cn-inverted, cn(A1)jX~ >
cn(A2)jX~ . Hence, cn(Y~ )jX~ > cn(A2)jX~ , and transposition of Y~ with A2 reduces the
cost, by Lemma 2.
In either case, there is a way to reduce the cost of O~ S . Therefore, O~ S cannot be minimal,
and O~ N is MC-contradicting.
2
4.4.2 Detection of MC-Contradicting Orderings in AND-nodes

Every member of the consistency set of an AND-node is consistent with some combination
of candidates of its child nodes. If there are k child nodes, and for each child Ni the sizes
of subgoal and candidate sets are jS (Ni)j = ni and jCandSet(Ni)j = ci , then the total
number of possible consistent orderings is c1  c2  : : :ck  (nn+!nn +!::::::+nnk !k )! . Fortunately, most
of these orderings are MC-contradicting and can be discarded from the candidate set. The
1

2

1

62

2

The Divide-and-Conquer Subgoal-Ordering Algorithm

following lemma states that it is forbidden to insert other subgoals between two cn-inverted
sub-sequences. If such insertion takes place, the ordering is MC-contradicting and can be
safely discarded.

Lemma 5
Let S0 be a set of subgoals, N a node in the divisibility tree of S0 , and O~ S an ordering of
S0, binder-consistent with an ordering O~ N of S (N ).
If O~ N contains an adjacent cn-inverted pair of sub-sequences hA~ 1 ; A~ 2i, A~ 1 and A~ 2 appear

in O~ S not mixed with other subgoals, and A~ 1 and A~ 2 are not adjacent in O~ S , then O~ S is
not minimal.

Proof: Let O~ S be such an ordering of S0, binder-consistent with O~ N :
O~ S = X~ kA~ 1kY~ kA~ 2kZ~ ;
where Y~ is not empty. No subgoal of Y~ belongs to S (N ), since otherwise it would stand
in O~ N between A~ 1 and A~ 2 . O~ S is binder-consistent with O~ N ; therefore, B(N )  X~ . By
Corollary 2, Y~ must be mutually independent of both A~ 1 and A~ 2 under X~ , and by Lemma 2
a transposition of Y~ with either A~ 1 or A~ 2 reduces the cost { exactly as in the proof of
Lemma 4.
2

If a pair of adjacent subgoals hAi ; Ai+1i is cn-inverted, then by the previous lemma any
attempt to insert subgoals inside it results in a non-minimal global ordering. Thereupon
we may join Ai and Ai+1 into a block Ai;i+1 , which can further participate in a larger block.
The formal recursive denition of a block follows. For convenience, we consider separate
subgoals to be blocks of length 1.

Denition:

1. A sub-sequence A~ of an ordered sequence of subgoals is a block if it is either a single
subgoal, or A~ = A~ 1 kA~ 2, where hA~ 1; A~ 2i is a cn-inverted pair of blocks.
2. A block is maximal (max-block) if it is not a sub-sequence of a larger block.
3. Let N be a node in a divisibility tree, M be some descendant of N , O~ N 2  (S (N ))
and O~ M 2  (S (M )) be two consistent orderings of these nodes. A block A~ of O~ M is
violated in O~ N if there are two adjacent subgoals in A~ that are not adjacent in O~ N (in
other words, alien subgoals are inserted between the subgoals of the block).
4. Let N be a node, M be its descendant, O~ N 2  (S (N )) and O~ M 2  (S (M )) be two
consistent orderings of these nodes. O~ M is called the projection of O~ N on M . We
shall usually speak about projection of an ordering on a child node.
The concept of max-block is similar to the maximal indivisible block introduced by Simon
and Kadane (1975) in the context of satiscing search. The following corollary presents the
result of Lemma 5 in a more convenient way.

Corollary 3 Let N be a node in a divisibility tree, M be one of its children, O~ N be an

ordering of N , and O~ M be the projection of O~ N on M . If O~ M contains a block that is
violated in O~ N , then O~ N is MC-contradicting.
63

Ledeniov & Markovitch

Proof: Let A~ be the smallest block of O~ M violated in O~ N . According to the denition
of a block, A~ = A~ 1 kA~ 2 , where A~ 1 and A~ 2 are not violated in O~ N , and the pair hA~ 1; A~ 2i

is cn-inverted. Let O~ S be any ordering of the root node binder-consistent with O~ N . O~ S
violates A~ , since O~ N violates A~ . To show that O~ N is MC-contradicting, we must prove that
O~ S is not minimal.
 If A~1 and A~ 2 are not violated in O~ S , then they are not adjacent in O~ S , and O~ S is not
minimal, by Lemma 5.
 Otherwise, A~ 1 or A~2 is violated in O~ S . Without loss of generality, let it be A~1. Let A~0
be the smallest sub-block of A~ 1 violated in O~ S . According to the denition of a block,
A~ 0 = A~01 kA~ 02 , where the pair hA~ 01; A~ 02i is cn-inverted, A~ 1 and A~ 2 are not violated and
not adjacent in O~ S . By Lemma 5, O~ S is not minimal.
2
For example, if control values of subgoals are as shown in Figure 9, then ha1(X ); a2(X )i
is a block, since cn(a1(X ))j; = 2,2 1 = 12 , cn(a2(X ))jfa1(X )g = 2,3 1 = 13 . As one can see from
the gure, insertion of b or d inside this block results in a non-minimal ordering.
As was already noted above, the consistency set of an AND-node can be large. In
many of its orderings, however, blocks of projections are violated, and we can discard
these orderings as MC-contradicting. In the remaining orderings, no block of a projection
is violated, and each such ordering can be represented as a sequence of max-blocks of the
projections. In each projection, its max-blocks stand in cn-ascending order (otherwise, there
is an adjacent cn-inverted pair of blocks, and a larger block can be formed, which contradicts
their maximality). As the following lemma states, in the parent AND-node these blocks
must also be ordered by their cn values; otherwise, the ordering is MC-contradicting.
Lemma 6 If an ordering of an AND-node contains an adjacent cn-inverted pair of maxblocks of its projections on the children, then this ordering is MC-contradicting.
Proof: If these blocks are violated in the binder-consistent global ordering, the global
ordering is not minimal by Corollary 3. If the blocks are not violated, the proof is similar
to the proof of Lemma 4.
2
The two sucient conditions for detection of MC-contradicting orderings expressed in
Corollary 3 and Lemma 6 allow us to reduce the size of the candidate set signicantly.
Assume, for example, that the set of our current node N is split into two mutually independent subsets whose candidates are ha1; a2i and hb1; b2i (one candidate for each child). There
are six possible orderings of S (N ), all shown in Figure 11. Assume that both ha1; a2i and
hb1; b2i are blocks, and cn(ha1; a2i)jB(N ) < cn(hb1; b2i)jB(N ). Out of six consistent orderings,
four (2{5) can be rejected due to block violation, and one of the remaining two (number 6)
puts the blocks in the wrong order. So, only one ordering (number 1) can be left in the candidate set of N . Even if neither ha1; a2i nor hb1; b2i are blocks, Lemma 6 dictates a unique
interleaving of their elements (max-blocks), assuming that cn(a1 )jB(N ) 6= cn(a2 )jB(N )[fa g
6= cn(b1)jB(N ) 6= cn(b2)jB(N )[fb g.
1

1

4.4.3 Detection of MC-Contradicting Orderings in OR-nodes

The following lemma states that if a block has a cheaper permutation, then the ordering is
MC-contradicting (and can be discarded from the candidate set).
64

The Divide-and-Conquer Subgoal-Ordering Algorithm

1.

a1 a2

b1 b2

2.

a1 a2

b1 b2

3.

a1 a2

4.

b1 b2

a1 a2

b1 b2

5.

a1 a2

b1 b2

6.

a1 a2

b1 b2

Figure 11: The possible ways to combine ha1, a2 i and hb1, b2i

Lemma 7 Let N be a node in the divisibility tree of S~0, O~ N 2 (S~(N )). Let A~ be a leading
block of O~ N : O~ N = A~ kR~ . If there is a permutation of A~ , A~ 0 , such that cost(A~ 0 )jB(N ) <
cost(A~ )jB(N ), then O~ N is MC-contradicting.
Proof: Let O~ S 2 (S~0) be binder-consistent with O~ N . If A~ is violated in O~ S , O~ S cannot

be minimal (Corollary 3). Otherwise, A~ occupies a continuous segment in O~ S , and its
replacement by a cheaper permutation reduces the cost of the global ordering (Lemma 1).
Thus, O~ S cannot be minimal.
2
This check should be done only for leading blocks of OR-nodes:

 Every ordering of a leaf node that has not been rejected due to Lemma 4 must be

sorted by cn. Consequently, it contains no cn-inverted adjacent pair of subgoals, and
no block of size  2 can be formed.

 Every ordering of an AND-node that has not been rejected due to Corollary 3 or
Lemma 6 must have its blocks unbroken and in cn-ascending order. Consequently,
new blocks cannot be formed here either.

 In OR-nodes, new blocks can be formed when we add a binder as the rst element of
an ordering, if the cn value of the binder is greater than that of the subsequent block.
All new blocks start from the binder, and we must perform the permutation test only
on the leading max-block of an ordering.

4.5 Detection of MC-Equivalent Orderings

In the previous subsection we presented sucient conditions for detecting MC-contradicting
orderings. In this subsection we specify sucient conditions for identifying MC-equivalent
orderings. Recall that two orderings of a node are MC-equivalent if minimal consistency
of one implies minimal consistency of the other. Finding such sucient conditions will
allow us to eliminate orderings without loss of validity of the candidate set. We start
with dening a specialization of the MC-equivalence relation: blockwise equivalence. We
then show that orderings whose max-blocks are sorted by cn are blockwise-equivalent, and
therefore MC-equivalent.
65

Ledeniov & Markovitch

Denition: Let S0 be a set of subgoals and N be a node in the divisibility tree of S0. Let
O~ 1 and O~ 2 be two orderings of S (N ) with an equal number of max-blocks. Let O~ S be an
ordering of S0 , binder-consistent with O~ 1, where blocks of O~ 1 are not violated.
O~ S jOO~~ is the ordering obtained by replacing in O~ S every max-block of O~ 1 with a max2

block of O~ 2, while preserving the order of max-blocks (the i-th max-block of O~ 1 is replaced
by the i-th max-block of O~ 2).
O~ 1 and O~ 2 are blockwise-equivalent if the following condition holds: O~ 1 is min-consistent
with O~ S i O~ 2 is min-consistent with O~ S jOO~~ .
As can be easily seen, if two orderings are blockwise-equivalent, then they are MCequivalent. Now we show that a transposition of adjacent, mutually independent cn-equal
max-blocks in an ordering of a node produces a blockwise-equivalent ordering. The proof
of the following lemma is found in Appendix A.
1

2
1

Lemma 8
Let S0 be a set of subgoals, N be a node in the divisibility tree of S0, O~ N = Q~ kA~ 1 kA~ 2kR~ be
an ordering of S (N ), where A~ 1 and A~ 2 are max-blocks, mutually independent and cn-equal
under the bindings of B(N ) [ Q~ . Then O~ N is blockwise-equivalent with O~ N0 = Q~ kA~ 2 kA~ 1kR~ .
Corollary 4 All sorted by cn orderings of a leaf node are blockwise-equivalent.
For example, if S (N ) = fA; B; C; Dg, cn(A)jB(N ) = 0:1, cn(B )jB(N ) = cn(C )jB(N ) = 0:3,
cn(D)jB(N ) = 0:5, then the orderings hA; B; C; Di and hA; C; B; Di are blockwise-equivalent,
and we can remove from the candidate set any one of them (but not both).

Corollary 5 All orderings of an AND-node, where blocks of projections are not violated

and adjacent max-blocks from dierent children projections are cn-ordered, are blockwiseequivalent.

~ B;
~ C~ ; D~ are
For example, if the candidates of the children are A~ kB~ and C~ kD~ , where A;
max-blocks, cn(A~ )jB(N ) = 0:1, cn(B~ )jB(N )[A~ = cn(C~ )jB(N ) = 0:3 and cn(D~ )jB(N )[C~ = 0:5,
then the orderings A~ kB~ kC~ kD~ and A~ kC~ kB~ kD~ are blockwise-equivalent, and we can remove
from the candidate set any one of them (but not both).
To prove both Corollaries 4 and 5, we note that in each case one of the mentioned
orderings can be obtained from the other by a nite number of transpositions of adjacent,
mutually independent and cn-equal max-blocks. According to Lemma 8, each such transposition yields a blockwise-equivalent ordering. It is easy to show that blockwise equivalence
is transitive.
The following corollary states that subgoals within a block can be permuted, provided
that the cost of the block is not changed.

Corollary 6 All orderings of a node, identical up to cost-preserving permutations of subgoals inside blocks, are blockwise-equivalent.

The proof of the corollary follows immediately from Lemma 1. For example, if the set
is fa(X ); b(X )g, and the control values are as in the rst counter-example of Proposition 1,
66

The Divide-and-Conquer Subgoal-Ordering Algorithm

Node Set
MC-contradicting
Leaf Independent Subgoals not sorted by cn
| Lemma 4
Contains violated blocks
AND Divisible
| Corollary 3
Max-blocks not sorted by cn
| Lemma 6
The leading max-block has
OR Indivisible a cheaper permutation
| Lemma 7

blockwise-equivalent
Subgoals sorted by cn
| Corollary 4
Max-blocks not violated,
sorted by cn
| Corollary 5
Cost-preserving permutations
of blocks
| Corollary 6

Table 1: Summary of sucient conditions for detection of MC-contradicting and blockwiseequivalent orderings.

i.e. cn(a(X )j;) = cn(b(X )j;) = 12 , and cn(a(X )jfb(X )g) = cn(b(X )jfa(X )g) = 0, then in both
possible orderings, ha(X ); b(X )i and hb(X ); a(X )i, the two subgoals are united into a block,
and these blocks have equal cost. In any global ordering containing the block ha(X ); b(X )i,
we can replace this block with hb(X ); a(X )i without changing the total cost. Therefore
ha(X ); b(X )i is blockwise-equivalent to hb(X ); a(X )i.
The sucient condition expressed in Corollary 6 should be checked only in OR-nodes,
since in leaves and AND-nodes no new blocks are created, as was argued in Section 4.4.3.

4.6 The Revised Ordering Algorithm

In the two preceding subsections we saw several sucient conditions of MC-contradiction
and MC-equivalence, summarized in Table 1. These results permit us to close the gaps
in Algorithm 5 by providing the necessary validity lters. Each lter tests the sucient
conditions of MC-contradiction and MC-equivalence on every ordering in the consistency
set. If some of these sucient conditions hold, the ordering is rejected. The formal listing
of these procedures is shown in Figure 12.
While the generate-and-test approach described above served us well for methodological
purposes, it is obviously not practical because of its computational limitations. For example,
for an independent set of size n, the algorithm creates n! orderings, then rejects n! , 1
and keeps only one. This process takes O(n!  n) time and produces an ordering which
is sorted by cn. The same result could be obtained in just O(n log n) time, by a single
sorting. So, instead of uncontrolled creation of orderings and selective rejection, we want to
perform a selective creation of orderings. In other words, we want to revise our algorithm to
deal directly with candidate sets, instead of generating large consistency sets. The revised
algorithm produces the candidate set of a node N as follows:
 If N is a leaf, the subgoals of S (N ) are sorted by cn under the bindings of B(N ), and
the produced ordering is the sole candidate of N .
 If N is an AND-node, then for each combination of its children's candidates a candidate of N is created, where the max-blocks of the children's candidates are ordered
67

Ledeniov & Markovitch

ValidLeafFilter(ConsSetN )
let CandSetN ;
loop for O~ N 2 ConsSetN

if O~ N is sorted by cn
and there is no O~ N0 2 CandSetN which is sorted by cn
then CandSetN CandSetN [ fO~ N g
Return CandSetN

ValidANDFilter(ConsSetN ; fS1; : : : Sk g; fC1; : : : Ck g)
let CandSetN ;
loop for O~ N 2 ConsSetN

loop for i = 1 to k
let O~ i be the projection of O~ N on Si
if 8i O~ i 2 Ci
and max-blocks of O~ i -s are not violated in O~ N ,
and max-blocks of O~ i -s are ordered by cn in O~ N ,
and there is no O~ N0 2 CandSetN consistent with all O~ i-s,
then CandSetN CandSetN [ fO~ N g
Return CandSetN

ValidORFilter(ConsSetN )
let CandSetN ;
loop for O~ N 2 ConsSetN

if O~ N does not start with a block having a cheaper permutation,
and there is no O~ N0 2 CandSetN , identical to O~ N up to
cost-preserving permutations in blocks,
then CandSetN CandSetN [ fO~ N g
Return CandSetN

Figure 12: The three lter procedures that convert a consistency set into a candidate set. Together
with Algorithm 5, they form a complete ordering algorithm. The eciency of the
algorithm can be improved, as we shall see in Algorithm 6.

by cn. The candidate is produced by merging: moving in parallel on the candidates
of the children and extracting max-blocks that are minimal by cn.

 If N is an OR-node, then for each candidate of its child an ordering of N is created
by adding the binder to the left end of the child candidate. If this results in creation
of a block that has a cheaper permutation, the ordering is rejected; otherwise, it is
added to the candidate set. It suces to check only the leading max-block.
68

The Divide-and-Conquer Subgoal-Ordering Algorithm

Note that the revised algorithm does not include a test for cost-preserving permutations
of blocks in dierent orderings (expressed in Corollary 6), because of the high expense of
such a test.
The revised algorithm described above contains manipulations of blocks. For this purpose, we need an easy and ecient way to detect blocks in orderings. Since we do not
permit block violation (by Corollary 3), we can unite all the subgoals of a max-block into
one entity, and treat it as an ordinary subgoal. The procedure of joining subgoals into
blocks is called folding, and the resulting sequence of max-blocks { a folded sequence. After
subgoals are folded into a block, there is no need to unfold this block back to separate
subgoals: on upper levels of the tree, these subgoals will again be joined into a block, unless
the block is violated. The unfolding operation is carried out only once before returning the
cheapest ordering of the set (of the root node). The candidate sets of the nodes are now
dened as sets of folded orderings.
As was already stated, new blocks can only be created in the candidates of OR-nodes,
when the binder is added as the rst element of the ordering, if the cn value of the binder
is greater than the cn value of the rst max-block of the child projection. Therefore, in the
revised algorithm we only build new blocks that start from the binder: the max-blocks in
the rest of the ordering remain from the child's candidate. First we try to make a block
out of the binder and the rst max-block of the child's candidate. If they are cn-ordered,
we stop the folding. If they are cn-inverted, we unite them into a larger block, and try
to unite it with the second max-block of the child's candidate, and so on. The produced
folded ordering contains only maximal blocks: the rst block is maximal, since we could not
expand it further to the right, and the other blocks are maximal, since they were maximal
in the child's candidate.
Lemma 7 states that an ordering whose leading max-block has a cheaper permutation
is MC-contradicting. One way to detect such a block is to exhaustively test all its permutations, computing and comparing their costs. This procedure is very expensive. Instead,
in our revised algorithm we employ the adjacency restriction test (Equation 8). The test is
applied to every pair of adjacent subgoals of a block, and if some adjacent pair has a cheaper
transposition, then the whole block has a cheaper permutation, by Lemma 1. Since blocks
are created by concatenation of smaller blocks, it suces to test the adjacency restriction
only at the points where blocks are joined (for other adjacent pairs of subgoals, the tests
were performed on the lower levels, when smaller blocks were formed). The adjacency restriction test does not guarantee detection of all not-cheapest permutations (as was shown
in Example 3), but it detects such blocks in many cases, and works in linear time.
The nal version of the dac subgoal ordering algorithm is presented in Figure 13. The
complete correctness proof of Algorithm 6 is found in Appendix B.

4.7 Sample Run and Comparison of Ordering Algorithms
We illustrate the work of the dac algorithm, using the subgoal set shown in Figure 8,
S0 = fa; b; c(X ); d(X ); e(X )g. After proving c(X ), d(X ) or e(X ), we can assume that X is
bound. Let the control values for the subgoals be as shown in Table 2. The column c(free)
contains control values for the subgoal c(X ) when X is not yet bound by the preceding
subgoals (i.e., the binding set does not contain d(X ) or e(X )). The column c(bound)
69

Ledeniov & Markovitch

Algorithm 6 : The Divide-and-Conquer Algorithm
Order(S0)
let RootCandSet CandidateSet(S0 ; ;)
Return Unfold(the cheapest element of RootCandSet)
CandidateSet(S ; B)
let fS1; S2; : : : Sk g DPart(S ; B)
case

 k = 1, shared-vars(S1) = ; (S is independent under B):
Return fSort-by-cn(S ; B)g
 k = 1, shared-vars(S1) =6 ; (S is indivisible under B):
loop for A 2 S
let C (A) CandidateSet
(S n fAg; B [ fAog)
n
0
~
let C (A)
Fold
(AkOA ; B)  O~ A 2 C (A)
S
Return A2S C 0(A)
 k > 1 (S is divisible under B):
loop for i = 1 to k
let Cin CandidateSet(Si ; B)
Return Merge(fO~ 1; O~ 2; : : : O~ k g; B)


o
 O~ 1 2 C1; O~ 2 2 C2; : : : O~ k 2 Ck

Merge(fO~ 1; O~ 2; : : : O~ k g; B)

let min-cn-candidate O~ i that minimizes cn(rst-max-block(O~ i ))jB , 1  i  k
let min-cn-block rst-max-block(min-cn-candidate)
remove-rst-max-block(min-cn-candidate)
Return min-cn-blockkMerge(fO~ 1; O~ 2; : : : O~ k g; B [ min-cn-block)

Fold(hA1; A2 : : :Ak i; B)
if k  1 or cn(A1)jB  cn(A2)jBkA
then Return hA1; A2 : : :Ak i

1

else
if the last subgoal of A1 and the rst subgoal of A2 satisfy the adjacency restriction
then
let A0 block(A1 ; A2)
Return Fold(hA0 ; A3 : : :Ak i; B)
else Return ;

Figure 13: The revised version of the dac algorithm. The candidate sets are built selectively,

without explicit creation of consistency sets. Candidate sets contain folded orderings,
and unfolding is performed only on the returned global ordering. The code of the
Unfold and Sort-by-cn procedures is not listed, due to its straightforwardness. The
merging procedure recursively extracts from the given folded orderings max-blocks that
are minimal by cn. The folding procedure joins two leading blocks into a larger one, as
long as they are cn-inverted.
70

The Divide-and-Conquer Subgoal-Ordering Algorithm

a
b c(free) c(bound) d(free) d(bound) e(free) e(bound)
cost
10 5
5
5
10
5
20
10
nsols 0.8 2
2
0.5
4
1
0.4
0.1
cn
-0.02 0.2 0.2
-0.1
0.3
0
-0.03
-0.09
Table 2: Control values for the sample runs of the ordering algorithms.
contains cost values of c(X ) when d(X ) or e(X ) have already bound X . For example,
cost(c(X ))jfa;d(X )g = cost(c(bound)) = 5. The dac algorithm traverses the divisibility tree
of S0 as follows. (The names of the nodes are as in Figure 8.)
1. The root of the divisibility tree, n1, has empty binding set B(n1) = ;, and the
associated subgoal set S (n1) = fa; b; c(X ); d(X ); e(X )g. The set S (n1) is partitioned into two subsets under B(n1): one independent { fa; bg, and one indivisible {
fc(X ); d(X ); e(X )g. These two subsets correspond to two child nodes of the ANDnode n1: n2 and n3, both with empty binding sets.
2. S (n2) is independent under B(n2). Therefore, n2 is a leaf, and its sole candidate
ordering is obtained by sorting its subgoals by cn under B(n2). cn(a)j; = ,0:02,
cn(b)j; = 0:2, thus CandSet(n2) = fha; big.
3. S (n3) is indivisible under B(n3). Therefore, n3 is an OR-node, and its three children
are created { one for each subgoal of S (n3) serving as the binder.

 Binder c(X ) yields the child node n4 with the associated set S (n4) = fd(X ); e(X )g
and the binding set B(n4) = fc(X )g. S (n4) is independent under B(n4). There-

fore, n4 is a leaf, and its sole candidate is obtained by sorting its subgoals by
cn:
cn(d(X ))jfc(X)g = 0; cn(e(X ))jfc(X )g = ,0:09;
thus, the candidate of n4 is he(X ); d(X )i.
 Binder d(X ) yields the child node n5 with the associated set S (n5) = fc(X ); e(X )g
and the binding set B(n5) = fd(X )g. S (n5) is independent under B(n5), and its
sorting by cn produces the candidate hc(X ); e(X )i.
 Binder e(X ) yields the child node n6 with the associated set S (n6) = fc(X ); d(X )g
and the binding set B(n6) = fe(X )g. S (n6) is independent under B(n6), and its
sorting by cn produces the candidate hc(X ); d(X )i.
4. We now add each binder to its corresponding child's candidate and obtain three orderings of the OR-node n3: hc(X ); e(X ); d(X )i, hd(X ); c(X ); e(X )i, he(X ); c(X ); d(X )i.
5. We now perform folding of these orderings and check violations of the adjacency
restriction, in order to determine whether a block has a cheaper permutation.
71

Ledeniov & Markovitch

 First, we perform the folding of hc(X ); e(X ); d(X )i. The pair hc(X ); e(X )i is
cn-inverted: cn(c(X ))j; = 0:2, cn(e(X ))jfc(X )g = ,0:09. We thus unite it into a
block. This block does not pass the adjacency restriction test (Equation 8):
cost(hc(X ); e(X )i)j; = 5 + 2  10 = 25;
cost(he(X ); c(X )i)j; = 20 + 0:4  5 = 22:

Therefore, this ordering is MC-contradicting and can be discarded.
 We perform the folding of hd(X ); c(X ); e(X )i. cn(d(X ))j; = 0:3, cn(c(X ))jfd(X )g =
,0:1, the pair is cn-inverted, and we unite it into a block. This block does not
pass the adjacency restriction test:
cost(hd(X ); c(X )i)j; = 10 + 4  5 = 30;
cost(hc(X ); d(X )i)j; = 5 + 2  5 = 15:

This ordering is rejected too, even before its folding is nished. If we continue
the folding process, we shall see that the subgoal e(X ) must also be added to this
block, since cn(hd(X ); c(X )i)j; = 4030:5,1 = 0:0333, and cn(e(X ))jhd(X );c(X )i =
,0:09.
 We perform the folding of he(X ); c(X ); d(X )i. cn(e(X ))j; = ,0:03, cn(c(X ))jfe(X)g
= ,0:1, the pair is cn-inverted, and we form a block ec(X ) = he(X ); c(X )i, which
passes the adjacency restriction test:
cost(he(X ); c(X )i)j; = 20 + 0:4  5 = 22;
cost(hc(X ); e(X )i)j; = 5 + 2  10 = 25:

We compute the control values of the new block:
cost(ec(X ))j; = 20 + 0:4  5 = 22
nsols(ec(X ))j; = 0:4  0:5 = 0:2
cn(ec(X ))j; = 0:222, 1 = ,0:0363636
cn(d(X ))jfec(X )g = 0, thus the pair hec(X ); d(X )i is cn-ordered, no more folding
is needed, and we add the folded candidate hec(X ); d(X )i to the candidate set
of n3.

6. We now perform merging of the candidate set of n2, fha; big, with the candidate set
of n3, fhec(X ); d(X )ig. In the resulting sequence max-blocks must be sorted by cn.

cn(a) = ,0:02; cn(b) = 0:2; cn(ec(X ))j; = ,0:0363636; cn(d(X ))jfec(X )g = 0:
The merged ordering, hec(X ); a; d(X ); bi, is added to the candidate set of n1.
7. We compare the costs of all candidates of n1, and output the cheapest one. In our case,
there is only one candidate, hec(X ); a; d(X ); bi. The algorithm returns this candidate
unfolded, he(X ); c(X ); a; d(X ); bi.
72

The Divide-and-Conquer Subgoal-Ordering Algorithm

Extension/Completion
Cost
h ai
10
hbi
5
hc(X )i
5
hd(X )i
10
he(X )i
20
hbi
hb; ai
the adjacency restriction test fails
hb; c(X )i
5 + 2  5 = 15
hb; d(X )i
5 + 2  10 = 25
hb; e(X )i
the adjacency restriction test fails
hc(X )i
hc(X ); e(X ); a; d(X ); bi
5 + 2(10 + 0:1(10 + 0:8(5 + 1  5))) = 28:6
hai
ha; bi
10 + 0:8  5 = 14
ha; c(X )i
10 + 0:8  5 = 14
ha; d(X )i
10 + 0:8  10 = 18
ha; e(X )i
the adjacency restriction test fails
hd(X )i
hd(X ); c(X ); e(X ); a; bi 10 + 4(5 + 0:5(10 + 0:1(10 + 0:8  5))) = 52:8
ha; bi
ha; b; c(X )i
14 + 0:8  2  5 = 22
ha; b; d(X )i
14 + 0:8  2  10 = 30
ha; b; e(X )i
the adjacency restriction test fails
ha; c(X )i
ha; c(X ); e(X ); d(X ); bi
14 + 0:8  2(10 + 0:1(5 + 1  5)) = 31:6
hb; c(X )i
hb; c(X ); e(X ); a; d(X )i
15 + 2  2(10 + 0:1(10 + 0:8  5)) = 60:6
ha; d(X )i
ha; d(X ); c(X ); e(X ); bi
18 + 0:8  4(5 + 0:5(10 + 0:1  5)) = 50:8
he(X )i
he(X ); c(X ); a; d(X ); bi 20 + 0:4(5 + 0:5(10 + 0:8(5 + 1  5))) = 25:6
ha; b; c(X )i
ha; b; c(X ); e(X ); d(X )i
22 + 0:8  2  2(10 + 0:1  5) = 55:6
hb; d(X )i
hb; d(X ); c(X ); e(X ); ai
25 + 2  4(5 + 0:5(10 + 0:1  10)) = 109
he(X ); c(X ); a; d(X ); bi complete ordering

;

Cheapest prex

Table 3: A trace of a sample run of Algorithm 4 on the set of Figure 8. The left column shows the
cheapest prex extracted from the list on each step, the middle column { its extensions
or completions that are added to the list, and the right column { their associated costs.

For comparison, we now show how the same task is performed by Algorithm 4. The
algorithm maintains a list of prexes, sorted by their cost values, and which initially contains
an empty sequence. On each step the algorithm extracts from the list its cheapest element,
and adds to the list the extensions or completions of this prex. Extensions are created when
the set of remaining subgoals is dependent, by appending each of the remaining subgoals
to the end of the prex. Completions are created when the set of remaining subgoals is
independent, by sorting them and appending the entire resulting sequence to the prex. An
extension is added to the list only when the adjacency restriction test succeeds on its two
last subgoals. To make the list operations faster, we can implement it as a heap structure
(Cormen et al., 1991).
The trace of Algorithm 4 on the set S0 is shown in Table 3. The left column shows the
cheapest prex extracted from the list on each step, the middle column { its extensions or
completions that are added to the list, and the right column { their associated costs.
It looks as if the dac algorithm orders the given set S0 more eciently than Algorithm 4.
We can compare several discrete measurements to show this. For example, Algorithm 6
73

Ledeniov & Markovitch

p2(X2,X5,X7,X9)
p1(X1,X2,X3,X4)
p5(X4,X8,X9,X10)
p3(X1,X5,X6,X8)
p4(X6,X3,X7,X10)

Figure 14: An example of the worst case for ordering. When all variables are initially free, every

subset of subgoals is indivisible under the binding of the rest of subgoals, and the overall
complexity of ordering by Algorithm 6 is O(n!).

performs 4 sorting sessions, each one with 2 elements, while Algorithm 4 performs 5 sortings
with 2 elements, and 3 sortings with 3 elements. The adjacency restriction is tested only 3
times by Algorithm 6, and 11 times by Algorithm 4. Algorithm 6 creates totally 8 dierent
ordered sub-sequences, with total length 22, while Algorithm 4 creates 24 ordered prexes,
with total length 55.

4.8 Complexity Analysis

Both Algorithm 4 and Algorithm 6 nd a minimal ordering, and both sort independent
subsets of subgoals whenever possible. Algorithm 6, however, oers several advantages due
to its divide-and-conquer strategy.
Let n be the number of subgoals in the initial set. For convenience, we assume that
the time of computing the control values for one subgoal is O(1); otherwise, if this time
is  , all the complexities below must be multiplied by  . The worst case complexity of
Algorithm 6 is O(n!). Figure 14 shows an example of such a case for n = 5. In this set
every two subgoals share a variable that does not appear in other subgoals. Thus, other
subgoals cannot bind it. The set of the root is indivisible, and no matter which binder is
chosen, the sets of the children are indivisible. So, in each child of the root, we must select
every remaining subgoal as the binder, and so on. The overall complexity of this execution
is O(n!). This is indeed the worst-case complexity: presence of AND-nodes in the tree can
only reduce it.
Note that even when n is small, such a complex rule body with (n2 ) free variables is
very improbable in practical programs. Also, the worst-case complexity can be reduced
to O(n2  2n ), if we move from divisibility trees to divisibility graphs (DAGs), where all
identical nodes of a divisibility tree (same subgoal set, same binding set) are represented
by a single vertex. The equivalence test of the tree nodes can be performed eciently with
the help of trie structures (Aho et al., 1987), where subgoals are sorted lexicographically.
Let there be n subgoals, with v shared variables appearing in m subgoals. As was
already noted in Section 4.3, the partition of subgoals into subsets can be performed in
74

The Divide-and-Conquer Subgoal-Ordering Algorithm

O(n) average time, using a Union-Find data structure (Cormen et al., 1991, Chapter 22).

In the worst possible case, there are no AND-nodes in the divisibility tree, apart from the
root node (whose set is divisible into a dependent set of size m and an independent set of
size n , m). The overall complexity of the dac algorithm in such a case is
T (n; m; v ) = O(n)
| divisibility partition
+ O((nQ, m) log(n , m))
| ordering of independent subgoals
k
+ O(( i=0
ordering of dependent subgoals
Q (,m1(,mi)), i))log(m , k)) |
+ O(m Q ki=0
| folding
,1 (m , i))
+ O(n  ki=0
| merging
where k is the maximal possible number of bindings performed before the remaining subset
is independent. If we assume that every subgoal binds all its free variables (which happens
very frequently in practical logic programs), then k = minfv; m , 1g; otherwise k = m , 1.
k is equal to the maximal number of OR-nodes on a path from the root to a leaf of the
divisibility tree. Therefore, the height of the divisibility tree is limited by k + 1. Actually,
the tree can be shallower, since some binders can bind more than one shared variable each.
This means that the number of shared variables can decrease by more than 1 in each ORnode. Below we simplify the above formula for several common cases, when k is small and
when the abovementioned assumption holds (every subgoal binds all its free variables after
its proof terminates).
 If v < m  n: T (n; m; v) = O(n  mv + n  log n)
 If m  v  n: T (n; m; v) = O(n  mm,1 + n  log n)
 If v  m ' n: T (n; m; v) = O(nv+1  log n)
 If m  v ' n: T (n; m; v) = O(n  m! + n  log n)
Generally, for a small number v of shared variables, the complexity of the algorithm is
roughly bounded by O(nv+1  log n). In particular, if all subgoals are independent (v = 0),
the complexity is O(n log n). In most practical cases, the number of shared free variables
in a rule body is relatively small, and every subgoal binds all its free variables; therefore,
the algorithm has polynomial complexity. Note that even if a rule body in the program
text contains many free variables, most of them usually become bound after the rule head
unication is performed (i.e., before we start the ordering of the instantiated body).

5. Learning Control Knowledge for Ordering

The ordering algorithms described in the previous sections assume the availability of correct
values of average cost and number of solutions for various predicates under various argument
bindings. In this section we discuss how this control knowledge can be obtained by learning.
Instead of static exploration of the program text (Debray & Lin, 1993; Etzioni, 1993),
we adopt the approach of Markovitch and Scott (1989) and learn the control knowledge
by collecting statistics on the literals that were proved in the past. This learning can be
performed on-line or o-line. In the latter case, the ordering system rst works with a
training set of queries, while collecting statistics. This training set can be built on the
75

Ledeniov & Markovitch

distribution of user queries seen in the past. We assume that the distribution of queries
received by the system does not change signicantly with time; hence, the past distribution
directs the system to learn relevant knowledge for the future queries.
While proving queries, the learning component accumulates information about the control values (average cost and number of solutions) of various literals. Storing a separate
value for each literal is not practical, for two reasons. The rst is the large space required
by this approach. The second is the lack of generalization: the ordering algorithm is quite
likely to encounter literals which have not been seen before, and whose control values are
unknown. Recall that when we transformed Equation 2 into Equation 5, we moved from
control values of single literals to average control values over sets of literals. To obtain the
precise averages for these sets, we still needed the control values of individual literals. Here,
we take a dierent approach, that of learning and using control values for more general
classes of literals. The estimated cost (nsols) value of a class can be dened as the average
real cost (nsols) value of all examples of this class that were proved in the past.
The more rened the classes, the smaller the variance of real control values inside each
class, the more precise the cost and nsols estimations that the classes assign to their members, and the better orderings we obtain. One easy way to dene classes is by modes
or binding patterns (Debray & Warren, 1988; Ullman & Vardi, 1988): for each argument we denote whether it is free or bound. For example, for the predicate father the
possible classes are father(free,free), father(bound,free), father(free,bound) and
father(bound,bound). Now, if we receive a literal (for example, father(abraham,X)),
we can easily determine its binding pattern (in this case, father(bound,free)) and retrieve the control information stored for this class. Of course, to nd the binding pattern
of a subgoal with a given binding set, we need a method to determine which variables are
bound by the subgoals of the binding set. The same problem arose in DPart computation
(Section 4.3). We shall discuss some practical ways to solve this problem in Section 7.1.
For the purpose of class denition we can also use regression trees { a type of decision tree
that classies to continuous numeric values and not to discrete classes (Breiman et al., 1984;
Quinlan, 1986). Two separate regression trees can be stored for every program predicate,
one for its cost values, and one for the nsols. The tests in the tree nodes can be dened
in various ways. If we only use the test \is argument i bound?", then the classes of literals
dened by regression trees coincide with the classes dened by binding patterns. But we
can also apply more sophisticated tests, both syntactic (e.g., \is the third argument a term
with functor f?") and semantic (e.g., \is the third argument female?"), which leads to
more rened classes and better estimations. A possible regression tree for estimating the of
number of solutions for predicate father is shown in Figure 15.
Semantic tests about the arguments require logic inference (in the example of Figure 15
{ invoking the predicate female on the rst argument of the literal). Therefore, they must
be as ecient as possible. Otherwise the retrieval of control values will take too much time.
The problem of ecient learning of control values is further considered elsewhere (Ledeniov
& Markovitch, 1998a).
Several researchers applied machine learning techniques for accelerating logic inference
(Cohen, 1990; Dejong & Mooney, 1986; Langley, 1985; Markovitch & Scott, 1993; Minton,
1988; Mitchell, Keller, & Kedar-Cabelli, 1986; Mooney & Zelle, 1993; Prieditis & Mostow,
1987). Some of these works used explanation-based learning or generalized caching tech76

The Divide-and-Conquer Subgoal-Ordering Algorithm

Average: 3.1416
Test: bound(arg1)?

yes

no

Average: 0.3
Test: female(arg1)?

yes
Average: 0.0

Average: 5
Test: bound(arg2)?

no

yes

Average: 0.5
Test: bound(arg2)?

Average: 0.98

yes

no

Average: 0.0001

Average: 1.0

no
Average: 50

Figure 15: A regression tree that estimates the number of solutions for father(arg1,arg2).
niques to avoid repeated computation. Others utilized the acquired knowledge for the problem of clause selection. None of these works, however, dealt with the problem of subgoal
reordering.

6. Experimentation
To test the eectiveness of our ordering algorithm, we experimented with it on various
domains, and compared its performance to other ordering algorithms. Most experiments
were performed on randomly created articial domains. We also tested the performance of
the system on several real domains.

6.1 Experimental Methodology
All experiments described below consist of a training session, followed by a testing session.
Training and testing sets of queries are randomly drawn from a xed distribution. In the
training session we collect the control knowledge for literal classes. In the testing session we
prove the queries of the testing set using dierent ordering algorithms, and compare their
performance using various measurements.
The goal of ordering is to reduce the time spent by the Prolog interpreter when it
proves queries of the testing set. This time is the sum of the time spent by the ordering
procedure (ordering time) and the time spent by the interpreter (inference time). Since the
CPU time is known to be very sensitive to irrelevant factors such as hardware, software
and programming quality, we also show two alternative discrete measurements: the total
number of clause unications, and the total number of clause reductions performed. The
number of reductions reects the size of the proof tree.
For experimentation we used a new version of the lassy system (Markovitch & Scott,
1989), using regression trees for learning, and the ordering algorithms discussed in this
paper.
77

Ledeniov & Markovitch

6.2 Experiments with Articial Domains

In order to ensure the statistical signicance of the results of comparing dierent ordering
algorithms, we experimented with many dierent domains. For this purpose, we created a
set of 100 articial domains, each with a small xed set of predicates, but with a random
number of clauses in each predicate, and with random rule lengths. Predicates in the
rule bodies, and arguments in both rule heads and bodies are randomly drawn from xed
distributions. Each domain has its own training and testing sets (these two sets do not
intersect).
The more training examples are fed into the system on the learning phase, the better
estimations of control values it produces. On the other hand, the learning time must be limited, because after seeing a certain number of training examples, new examples do not bring
much new information, and additional learning becomes wasteful. We have experimentally
built a learning curve which shows the dependence of the quality of the control knowledge
on the amount of training. The curve suggests that after control values were learned for
approximately 400 literals, there is no signicant improvement in the quality of ordering
with new training examples. Therefore, in the subsequent experiments we stopped training
after 600 cost values were learned. The training time was always small: one learned cost
value corresponds to a complete proof of a literal. Thus, if every predicate in a program has
four clauses that dene it, then 600 cost values are learned after 2400 unications, which is
a very small time.
The control values were learned by means of regression trees (Section 5), with simple
syntactic tests that only checked whether some argument is bound or whether some argument is a term with a certain functor (the list of functors was created automatically when
the domain was loaded). However, as we shall see, even these simple tests succeeded in
making good estimations of control values.
We tested the following ordering methods:
 Random: The subgoals are permuted randomly and the control knowledge is not
used.
 Algorithm 3: Building ordered prexes. Out of all prexes that are permutation of
one another, only the cheapest one is retained.
 Algorithm 3a: As Algorithm 3, but with best-rst search method used to dene the
next processed prex. A similar algorithm was used in the lassy system of Markovitch
and Scott (1989).
 Algorithm 3b: As Algorithm 3a, but with adjacency restriction test added. A
similar algorithm was described by Smith and Genesereth (1985).
 Algorithm 4: As Algorithm 3b, but whenever all the subgoals that are not in the
prex are independent (under the binding of the prex), they are sorted and the result
is appended to the prex as one unit.
 Algorithm 6: The dac algorithm.
In our experiments we always used the Bubble-Sort algorithm to sort literals in independent sets. This algorithm is easy to implement, and it is known to be ecient for small
78

The Divide-and-Conquer Subgoal-Ordering Algorithm

Ordering
Method
Random
Algorithm 3
Algorithm 3.a
Algorithm 3.b
Algorithm 4
Algorithm 6

Unications Reductions Ordering Inference Total Ord.Time
Time
Time Time Reductions
86052.06
27741.52
8.1910
27.385 35.576 0.00029
2600.32
911.04 504.648
1.208 505.856 0.55
2829.00
978.59 347.313
1.178 348.491 0.35
2525.34
881.12 203.497
1.137 204.634 0.23
2822.27
976.02
40.284
1.191 41.475 0.04
2623.82
914.67
2.3620
1.102 3.464 0.0025

Table 4: The eect of ordering on the tree sizes and the CPU time (mean results over 100 articial
domains).

sets, when the elements are already ordered, or nearly ordered. In practice, programmers
order most program rules optimally, and the sorting stops early.
Since the non-deterministic nature of the random method introduces additional noise,
we performed on each articial domain 20 experiments with this method, and the table
presents the average values of these measurements.
Table 4 shows the obtained results over 100 domains: the rows correspond to the ordering
methods used, and the columns to the measurements taken. The rightmost column shows
the ratio of the ordering time and the number of reductions performed, which reects the
average ordering time of one rule body. The inference time was not measured separately,
but was set as the dierence of the total time and the ordering time.
Several observations can be made:
1. Using the dac ordering algorithm helps to reduce the total time of proving the testing
set of queries by a factor of 10, compared to the random ordering. The inference time
is reduced by a factor of 25.
2. All deterministic ordering methods have similar number of unications and reductions,
and similar inference time, which is predictable, since they all nd minimal orderings.
Small uctuations of these values can be explained by the fact that some rules have
several minimal orderings under the existing control knowledge, and dierent ordering
algorithms select dierent minimal orderings. Since the control knowledge is not
absolutely precise, the real execution costs of these orderings may be dierent, which
leads to the dierences. The random ordering method builds much larger trees, with
larger inference time.
3. When we compare the performance of the deterministic algorithms (3 { 6), we see
that the dac algorithm performs much better than the algorithms that build ordered
prexes. In the latter ones, the ordering is expensive, and smaller inference time
cannot compensate for the increase in ordering time. Only Algorithm 4, a combination
of several ideas of previous researchers, has total time comparable with the time of
the random method (though still greater).
79

Ledeniov & Markovitch

4. It may seem strange that the simple random ordering method has larger ordering time
than the sophisticated Algorithm 6. To explain this, note that the random method
creates much larger proof trees (on average), therefore the number of ordered rules
increases, and even the cheap operations, like random ordering of a rule, sum up to
a considerable time. The average time spent on ordering of one rule is shown in the
last column of Table 4; this value is very small in the random method.

6.3 Experiments with Real Domains

We tested our ordering algorithm also on real domains obtained from various sources. These
domains allow us to compare orderings performed by our algorithm with orderings performed by human programmers.
The following domains were used:
 Moral-reasoner: Taken from the Machine Learning Repository at the University
of California, Irvine1 . The domain qualitatively simulates moral reasoning: whether
a person can be considered guilty, given various aspects of his character and of the
crime performed.
 Depth-rst planner: Program 14.11 from the book \The Art of Prolog" (Sterling
& Shapiro, 1994). The program implements a simple planner for the blocks world.
 Biblical Family Database: A database similar to that described in Example 1.
 Appletalk: A domain describing the physical layout of a local computer network
(Markovitch, 1989).
 Benchmark: A Prolog benchmark taken from the CMU Articial Intelligence Repository2. The predicate names are not informative: it is an example of a program where
manual ordering is dicult.
 Slow reverse: Another benchmark program from the same source.
 Geography: Also a benchmark program from the CMU Repository. The domain
contains many geographical facts about countries.
Table 5 shows the results obtained. For ordering we used the dac algorithm, with literal
classes dened by binding patterns. It can be seen that the dac algorithm was able to speed
up the logic inference in real domains as well. Note that in the Slow Reverse domain the
programmer's ordering was already optimal; thus, applying the ordering algorithm did not
reduce the tree sizes. Still, the overhead of the ordering is not signicant.

7. Discussion

In this concluding section we discuss several issues concerning the practical implementation
of the dac algorithm and several ways to increase its eciency. Then we survey some
related areas of logic programming and propose the use of the dac algorithm there.
1. URL: http://www.ics.uci.edu/~mlearn/MLRepository.html
2. URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/project/ai-repository/ai/html/air.html

80

The Divide-and-Conquer Subgoal-Ordering Algorithm

Domain

Without ordering
With ordering
Gain ratio
unications seconds unications seconds (time/time)
Moral-reasoner
352180 98.39
87020 23.53
4.2
Depth-rst planner
10225 19.01
9927 18.16
1.05
Biblical Family
347827 112.68
120701 46.08
2.5
Appletalk
5036167 1246.30
640092 221.73
5.6
Benchmark
62012 554.31
46012 395.04
1.4
Slow reverse
6291 10.33
6291 11.92
0.9
Geography
428480 141.47
226628 82.76
1.7
Table 5: Experiments on real domains.

7.1 Practical Issues

In this subsection we would like to address several issues related to implementation and
applications of the dac algorithm.
The computation of the DPart function (Section 3.2.1) requires a procedure for computing the set of variables bound by a given binding set of subgoals. The same procedure
is needed for computing control values (Section 5). There are several possible ways to
implement such a procedure. For example:
1. The easiest way is to assume that every subgoal binds all the variables appearing in its
arguments. This simplistic assumption is sucient for many domains, especially the
database-oriented ones. However, it is not appropriate when logic programs are used
to manipulate complex data structures containing free variables (such as dierence
lists). This assumption was used for the experiments described in Section 6.
2. Some dialects of Prolog and other logic languages support mode declarations provided
by the user (Somogyi et al., 1996b). When such declarations are available, it is easy
to infer the binding status of each variable upon exiting a subgoal.
3. Even when the user did not supply enough mode declarations, they can often be
inferred from the structure of the program by means of static analysis (Debray &
Warren, 1988). Note, however, that as was pointed out by Somogyi et al. (1996b),
no-one has yet demonstrated a mode inference algorithm that is guaranteed to nd
accurate mode information for every predicate in the program.
4. We can learn the sets of variables bound by classes of subgoals using methods similar
to those described in Section 5 for learning control values.
Several researchers advocate user declarations of available (permitted) modes. Such
declarations can be elegantly incorporated into our algorithm to prune branches that violate
available modes. When we x a binder in an OR-node, we compute the set of variables
that become bound by it. If this results in a violation of an available mode for one of the
subgoals of the corresponding child, then the whole subtree of this child is pruned. Note
that we can detect violations even when the mode of the subgoal is partially unknown
81

Ledeniov & Markovitch

CandidateSet(S ; B)
let fS1; S2; : : : Sk g DPart(S ; B)
case

:::
 k = 1, shared-vars(S1) 6= ; (S is indivisible under B):
loop for A 2 S
if B [ fAg does not violate available modes
in any subgoal of S n fAg
then
let C (A) CandidateSet
(S n fAg; B [ fAog)
n
0
let C (A)
Fold(AkO~ A; B)  O~ A 2 C (A)
else let
C 0(A) ; (don't enter the branch)
S
Return A2S C 0 (A)

Figure 16: Changes to Algorithm 6 that make use of available mode declarations.
The rest of the algorithm remains unchanged.

at the moment. For example, if all the available modes require that the rst argument
be unbound, then binding of the argument by the OR-node binder will trigger pruning,
even if the binding status of the other arguments is not yet known. Figure 16 shows how
Algorithm 6 can be changed in order to incorporate declarations of available modes. Any
other correctness requirement can be treated in a similar manner: a candidate ordering will
be rejected whenever we see that it violates the requirement.
The experiments described in Section 6 were performed with a Prolog interpreter. Is
it possible to combine the dac algorithm with a Prolog compiler? There are several ways
to achieve this goal. One way is to allow the compiler to insert code for on-line learning.
The compiled code will contain procedures for accumulating control values and for the dac
algorithm. Alternatively, o-line learning can be implemented, with training as a part of
the compilation process.
Another method for combining our algorithm with existing Prolog compilers is to use
it for program transformation, and to process the transformed program by a standard
compiler. Elsewhere (Ledeniov & Markovitch, 1998a) we describe the method for classifying
the orderings produced by the dac algorithm. For each rule we build a classication tree,
where classes are the dierent orderings of the rule body, and the tests are applied to the
rule head arguments. These are the same type of tests described in Section 5 for learning
control values. Figure 17 shows two examples of such trees.
Given such a classication tree, we can write a set of Prolog rules, where each rule has
the same head as the original rule, and has a body built of all the tests on the path from
the tree root to a leaf node followed by the ordering at the leaf. For example, the second
tree in Figure 17 yields the following set of rules:
82

The Divide-and-Conquer Subgoal-Ordering Algorithm

A classication tree for the rule
uncle(X,Y) of Example 1.

nonvar(Y) ?
yes

no

[parent(Z,Y),brother(Z,X)]
[brother(Z,X),parent(Z,Y)]
nonvar(X) ?
yes

A possible classication tree for the rule
head(X,Y)

male(X) ?

p1(X), p2(Y), p3(X,Y).

yes
[p1(X),p3(X,Y),p2(Y)]

no

nonvar(Y) ?

no

yes

no

[p2(Y),p3(X,Y),p1(X)]

[p1(X),p2(Y),p3(X,Y)]

[p3(X,Y),p1(X),p2(Y)]

Figure 17: Examples of classication trees that learn rule body orderings.

head(X,Y)
head(X,Y)
head(X,Y)
head(X,Y)

nonvar(X), male(X), p1(X), p3(X,Y), p2(Y).
nonvar(X), not(male(X)), p1(X), p2(Y), p3(X,Y).
var(X), nonvar(Y), p2(Y), p3(X,Y), p1(X).
var(X), var(Y), p3(X,Y), p1(X), p2(Y).

From Table 4 we can see that while the dac algorithm helped to reduce the inference
time by a factor of 25, the total time was reduced only by a factor of 10. This dierence
is caused by the additional computation of the ordering procedure. There is a danger that
the benet obtained by ordering will be outweighed by the cost of the ordering process.
This is a manifestation of the so-called utility problem (Minton, 1988; Markovitch & Scott,
1993). In systems that are strongly-moded (such as Mercury { Somogyi et al., 1996b) we can
employ the dac algorithm statically at compilation time for each one of the available modes,
thus reducing the run-time ordering time to zero. The mode-based approach performs only
syntactic tests of the subgoal arguments. The classication tree method, described above,
is a generalization of the mode-based approach, allowing semantic tests as well.
Due to insucient learning experience or lack of meaningful semantic tests, it is quite
possible that the classication trees contain leaves with large degrees of error. In such cases
we still need to perform the ordering dynamically. To reduce the harmfulness of the utility
problem in the case of dynamic ordering, we can use a cost-sensitive variation of the dac
algorithm (Ledeniov & Markovitch, 1998a, 1998b). This modied algorithm deals with the
problem by explicit reasoning about the economy of the control process. The algorithm is
anytime, that is, it can be stopped at any moment and return its currently best ordering
(Boddy & Dean, 1989). We learn a resource-investment function to compute the expected
return in speedup time for additional control time. This function is used to determine a
stopping condition for the anytime procedure. We have implemented this framework and
found that indeed we have succeeded in reducing ordering time, without signicant increase
of inference time.
83

Ledeniov & Markovitch

7.2 Relationship to Other Works

The work described in this paper is a continuation of the line of research initiated by Smith
and Genesereth (1985) and continued by Natarajan (1987) and Markovitch and Scott (1989).
This line of research aims at nding the most ecient ordering of a set of subgoals. The
search for minimal-cost ordering is based on cost analysis that utilizes available information
about the cost and number-of-solutions of individual subgoals.
Smith and Genesereth (1985) performed an exhaustive search over the space of all
permutations of the given set of subgoals, using the adjacency restriction to reduce the
size of the search space (Equation 8). This restriction was applied on pairs of adjacent
subgoals in the global ordering of the entire set. When applied to an independent set of
subgoals, the adjacency restriction is easily transformed into the sorting restriction: the
subgoals in a minimal ordering must be sorted by their cn values. Natarajan (1987) arrived
at this conclusion and presented an ecient ordering algorithm for independent sets.
The dac algorithm uses subgoal dependence to break the set into smaller subsets. Independent subsets are sorted. Dependent subsets are recursively ordered, and the resulting
orderings are merged using a generalization of the adjacency restriction that manipulates
blocks of subgoals. Therefore the dac algorithm is a generalization of both algorithms.
During the last decade, a signicant research eort went into static analysis (SA) of
logic programs. There are three types of SA that can be exploited by the dac algorithm to
reduce the ordering time.
A major part of the SA research deals with program termination (De Schreye & Decorte,
1994). The dac algorithm solves the termination problem, as a special case of the eciency
problem (it always nds a terminating ordering, if such orderings exist). During learning,
we set limits on the computation resources available for subgoal execution. If a subgoal is
non-terminating (in a certain mode), the learning module will associate a very high cost
with this particular mode. Consequently, the dac algorithm will not allow orderings with
this mode of the subgoal. Nevertheless, while the use of static termination analysis is
not mandatory for a proper operation of the dac algorithm, we can exploit such analysis
to increase the eciency of both the learning process and the ordering process. During
learning, the limit that we set on the computation resources devoted to the execution of
a subgoal must be high, to increase the reliability of the cost estimation. However, such
a high limit can lead to a signicant increase in learning time when many subgoals are
non-terminating. If termination information obtained by SA is available, we can use it to
avoid entering innite branches of proof trees. During ordering, termination information can
serve to reduce the size of space of orderings searched by the algorithm. If the termination
information comes in the form of allowed modes (Somogyi et al., 1996b), orderings that
violate these modes are ltered out, as in the modied algorithm shown in Figure 16. If the
termination information comes in the form of a partial order between subgoals, orderings
that violate this partial order can be ltered out in a similar manner.
The second type of SA research that can be combined with the dac algorithm is correctness analysis, where the program is tested against specications given by the user.
The folon environment (Henrard & Le Charlier, 1992) was designed to support the
methodology for logic program construction that aims at reconciling the declarative semantics with an ecient implementation (Deville, 1990). The construction process starts with
84

The Divide-and-Conquer Subgoal-Ordering Algorithm

a specication, converts it into a logic description and nally, into a Prolog program. If
the rules of the program are not correct with respect to the initial specication, the system performs transformations such as reordering literals in a clause, adding type checking
literals and so on. De Boeck and Le Charlier (1990) mention this reordering, but do not
specify an ordering algorithm dierent from the simple generate-and-test method. Cortesi,
Le Charlier, and Rossi (1997) present an analyzer for verifying the correctness of a Prolog
program relative to a specication which provides a list of input/output annotations for the
arguments and parameters that can be used to establish program termination. Again, no
ordering algorithm is given explicitly. The purpose of the dac algorithm is complementary
to the purpose of folon, and it could serve as an auxiliary aid to make the resulting Prolog
program more ecient.
Recently, the Mercury language was developed at the University of Melbourne (Somogyi
et al., 1996a, 1996b). Mercury is a strongly typed and strongly moded language. Type and
mode declarations should be supplied by the programmer (though recent releases of the
Mercury system already support partial inference of types and modes { Somogyi et al.,
1996a). The compiler checks that mode declarations for all predicates are satised; if
necessary, it reorders subgoals in the rule body to ensure mode correctness (and rejects the
program if neither ordering satises the mode declaration constraints). When the compiler
performs this reordering, it does not consider the eciency issue. It often happens that
several orderings of a rule body satisfy the mode declaration constraints: in such cases
the Mercury compiler could call the static version of the dac algorithm to select the most
ecient ordering. Another alternative is to augment the dac algorithm by mode declaration
checks, as was shown in Figure 16.
Note that Mercury is a purely declarative logic programming language, and is therefore
more suitable for subgoal reordering than Prolog. It has no non-logical constructs that
could destroy the declarative semantics which give logic programs their power; in Mercury
even I/O is declarative.
The third type of relevant SA is the cost analysis of logic programs (Debray & Lin,
1993; Braem et al., 1994; Debray et al., 1997). Cortesi et al. (1997) describe a cost formula
similar to Equation 5 to select a lowest-cost ordering. However, they used a generate-andtest approach which can sometimes be prohibitively expensive. Static analysis of cost and
number of solutions can be used to obtain the control values, instead of learning them.
The eciency of logic programs can also be increased by methods of program transformation (Pettorossi & Proietti, 1994, 1996). One of the most popular approaches is the
\rules+strategies" approach, which consists in starting from an initial program and then
applying one or more elementary transformation rules. Transformation strategies are metarules which prescribe suitable sequences of applications of transformation rules.
One of the possible transformation rules is the goal rearrangement rule which transforms
a program by transposing two adjacent subgoals in a rule body. Obviously, any ordering
of a rule body can be transformed into any other ordering by a nite number of such
transpositions. Thus, static subgoal ordering can be considered a special case of program
transformation where only the goal rearrangement rule is used. On the other hand, dynamic
and semi-dynamic ordering methods cannot be represented by simple transformation rules,
since they make use of run-time information (expressed in bindings that rule body subgoals
85

Ledeniov & Markovitch

obtain through unications of rule heads), and may order the same rule body dierently
under dierent circumstances.
A program transformation technique called compiling control (Bruynooghe, De Schreye,
& Krekels, 1989; Pettorossi & Proietti, 1994) follows an approach dierent from that of
trying to improve the control strategy of logic programs. Instead of enhancing the naive
Prolog evaluator using a better (and often more complex) computation rule, the program is
transformed so that the derived program behaves under the naive evaluator exactly as the
initial program would behave under an enhanced evaluator. Most forms of compiling control
rst translate the initial program into some standard representation (for example, into an
unfolding tree), while the complex computation rule is used, and then the new program is
constructed from this representation, with the naive computation rule in mind.
Reordering of rule body subgoals can be regarded as moving to a complex computation
rule which selects subgoals in the order dictated by the ordering algorithm. In the case of
the dac algorithm, this computation rule may be too complex for simple use of compiling
control methods. Nevertheless, it can be easily incorporated into a special compiling control
method. In Section 7.1 we described a method of program rewriting which rst builds
classication trees based on the orderings that were performed in the past, and then uses
these classication trees for constructing clauses of a derived program. The derived program
can be eciently executed under the naive computation rule of Prolog. This technique is
in fact a kind of compiling control. Its important property is the use of knowledge collected
from experience (the orderings that were made in the past).
One transformation method that can signicantly benet from the dac algorithm is
unfolding (Tamaki & Sato, 1984). During the unfolding process subgoals are replaced by
their associated rule bodies. Even if the initial rules were ordered optimally by a human
programmer or a static ordering procedure, the resulting combined sequence may be far from
optimal. Therefore it could be very advantageous to use the dac algorithm for reordering
of the unfolded rule. As the rules become longer, the potential benet of ordering grows.
The danger of high complexity of the ordering procedure can be overcome by using the
cost-sensitive version of the dac algorithm (Section 7.1).

7.3 Conclusions
In this work we study the problem of subgoal ordering in logic programs. We present both a
theoretical base and a practical implementation of the ideas, and show empirical results that
conrm our theoretical predictions. We combine the ideas of Smith and Genesereth (1985),
Simon and Kadane (1975) and Natarajan (1987) into a novel algorithm for ordering of
conjunctive goals. The algorithm is aimed at minimizing the time which the logic interpreter
spends on the proof of the given conjunctive goal.
The main algorithm described in this paper is the dac algorithm (Algorithm 6, Section 4.6). It works by dividing the sets of subgoals into smaller sets, producing candidate
sets of orderings for the smaller sets, and combining these candidate sets to obtain orderings
of the larger sets. We prove that the algorithm nds a minimal ordering of the given set
of subgoals, and we show its eciency under practical assumptions. The algorithm can
be employed statically (to reorder rule bodies in the program text before the execution
86

The Divide-and-Conquer Subgoal-Ordering Algorithm

starts), semi-dynamically (to reorder the rule body before the reduction is performed) or
dynamically (to reorder the resolvent after every reduction of a subgoal by a rule body).
Several researchers (Minker, 1978; Warren, 1981; Naish, 1985a, 1985b; Nie & Plaisted,
1990) proposed various heuristics for subgoal ordering. Though fast, these methods do
not guarantee nding minimal-cost orderings. Our algorithm provably nds a minimal-cost
ordering, though the ordering itself may take more time than with the heuristic methods. In
the future it seems promising to incorporate heuristics into the dac algorithm. For example,
heuristics can be used to grade binders in OR-nodes: rather than exhaustively trying all
subgoals as binders, we could try just one, or several binders, thus reducing the ordering
time. Also, the current version of our ordering algorithm is suitable only for nding all
solutions to a conjunctive goal. We would like to extend it to the problem of nding one
solution, or a xed number of solutions.
Another interesting issue for further research is the adaptation of the dac algorithm to
interleaving ordering methods (Section 2.3). There, if subgoals of a rule body are added
to an ordered resolvent, it seems wasteful to start a complete ordering process; we should
use the information stored in the existing ordering of the resolvent. Perhaps the whole
divisibility tree of the resolvent should be stored, and its nodes updated when subgoals of
a rule body are added to the resolvent.
The ordering algorithm needs control knowledge for its work. This control knowledge is
the average cost and number of solutions of literals, and it can be learned by training and
collecting statistics. We make an assumption that the distribution of queries received by
the system does not change with time; thus, if the training set is based on the distribution
seen in the past, the system learns relevant knowledge for future queries. We consider the
issue of learning control values more thoroughly in another paper (Ledeniov & Markovitch,
1998a), together with other issues concerning the dac algorithm (such as minimizing the
total time, instead of minimizing the inference time only).
Ullman and Vardi (1988) showed that the problem of ordering subgoals to obtain termination is inherently exponential in time. The problem we work with is substantially
harder: we must not only nd an order whose execution terminates in nite time, but one
that terminates in minimal nite time. It is impossible to nd an ecient algorithm for
all cases. The dac algorithm, however, is ecient in most practical cases, when the graph
representing the subgoal dependence (Figure 3) is sparsely connected.
We have implemented the dac algorithm and tested it on articial and real domains.
The experiments show a speedup factor of up to 10 compared with random ordering, and
up to 13 compared with some alternative ordering algorithms.
The dac algorithm can be useful for many practical applications. Formal hardware
verication has become extremely important in the semiconductor industry. While model
checking is currently the most widely used technique, it is generally agreed that coping with
the increasing complexity of VLSI design requires methods based on theorem proving. The
main obstacle preventing the use of automatic theorem proving is its high computational
demands. The dac algorithm may be used for speeding up logic inference, making the use
of automatic theorem provers more practical.
Logic has gained increasing popularity for representation of common-sense knowledge.
It has several advantages, including exibility and well-understood semantics. Indeed, the
CYC project (Lenat, 1995) has recently moved from frame-based representation to logic87

Ledeniov & Markovitch

based representation. However, the large scale of such knowledge bases is likely to present
signicant eciency problems to the inference engines. Using automatic subgoal ordering
techniques, such as those described here, may help to solve these problems.
The issue of subgoal ordering obtains a new signicance with the development of Inductive Logic Programming (Lavrac & Dzeroski, 1994; Muggleton & De Raedt, 1994). Systems
using this approach, such as FOIL (Quinlan & Cameron-Jones, 1995), try to build correct
programs as fast as possible, without considering the eciency of the produced programs.
Combining the dac algorithm with Inductive Logic Programming and other techniques for
the synthesis of logic programs (such as the deductive and the constructive approaches)
looks like a promising direction.

Appendix A. Proof of Lemma 8

In this appendix we present the proof of a lemma which was omitted from the main text of
the paper for reasons of compactness. Before we prove it we show two auxiliary lemmas.

Lemma 9

Let A~ 1 and A~ 2 be two ordered sequences of subgoals, and B a set of subgoals. The value of
cn(A~ 1kA~2)jB lies between the values cn(A~ 1)jB and cn(A~ 2)jB[A~ .
1

Proof:

Denote c1 = cost(A~1 )jB
n1 = nsols(A~1)jB
cn1 = cn(A~1)jB
c2 = cost(A~2 )jB[A~ n2 = nsols(A~2)jB[A~ cn2 = cn(A~2)jB;[A~
c1;2 = cost(A~1 kA~ 2)jB n1;2 = nsols(A~ 1kA~ 2 )jB cn1;2 = cn(A~ 1 kA~ 2)jB
cn = n1;2 , 1 = n1 n2 , 1 = (n1 , 1) + n1 (n2 , 1) =
1

1;2

1

1

c1;2

c1;2
c1;2
n
n
1 ,1
2 ,1
c
+n c
= 1 c1 c 1 2 c2 = c1 cn1 +c n1 c2cn2 = cc1  cn1 + nc1 c2  cn2
1;2
1;2
1;2
1;2
n
c
1 c2
1
So, cn1;2 always lies between cn1 and cn2 (because c1;2 and c1;2 are positive and
to 1). More exactly, the point cn1;2 divides the segment [cn1; cn2] with ratio

sum

(cn1;2 , cn1 ) : (cn2 , cn1;2 ) = n1 c2 : c1:

In other words, cn1;2 is a weighted average of cn1 and cn2 . Note that c1 is the amount
of resources spent in the proof-tree of B~ 1 , n1 c2 { the resources spent in the tree of B~ 2 , and
c1;2 is their sum. So, the more time (relatively) we dedicate to the proof of B~ 1 , the closer
cn1;2 is to cn1. This conclusion can be generalized to a larger number of components in a
concatenation (the proof is by induction):
cost(A~ 1 )jB
cn(A~ 1 kA~ 2 k : : : A~ k )jB =
 cn(A~ 1 )jB +
cost(A~ 1 kA~ 2 k : : : A~ k )jB
nsols(A~ 1 )jB  cost(A~ 2 )jB[A~ 1
+
 cn(A~ 2 )jB[A~ 1 + : : : +
cost(A~ 1 kA~ 2k : : : A~ k )jB
nsols(A~ 1 kA~ 2 k : : : A~ k,1)jB  cost(A~ k )jB[A~ 1 [:::A~ k,1
+
 cn(A~ k )jB[A~ 1 [:::A~ k,1
cost(A~ 1kA~ 2 k : : : A~ k )jB
88

The Divide-and-Conquer Subgoal-Ordering Algorithm

2

Lemma 10
Let S0 be a set of subgoals and N be a node in the divisibility tree of S0. Let O~ N =
Q~ kA~ 1kA~2 kR~ be an ordering of S (N ), where A~ 1 and A~ 2 are cn-equal max-blocks: cn(A~ 1 )jB(N )[Q~ =
cn(A~ 2)jB(N )[Q~ [A~ .
Let M be an ancestor of N and O~ M be an ordering of S (M ) consistent with O~ N , where
1

A~ 1 and A~ 2 are not violated. Then either A~ 1 and A~ 2 are both max-blocks in O~ M and all
max-blocks that stand between them are cn-equal to them, or A~ 1 and A~ 2 belong to the same
max-block in O~ M , or O~ M is MC-contradicting.
Proof: By induction on the distance between N and M . If M = N , then A~1 and A~2
are max-blocks, and the lemma holds. Let M 6= N , and let M 0 be the child of M whose
0 be the
descendant is N . By inductive hypothesis, the lemma holds for N and M 0 . Let O~ M
0
0
~
~
~
~
projection of OM on M . A1 and A2 are not violated in OM , since they are not violated in
O~ M .
 If A~ 1 and A~2 are both max-blocks in O~ M0 , then by the inductive hypothesis all maxblocks that stand between them are cn-equal to them. If M is an OR-node, no new
subgoals can enter between A~ 1 and A~ 2 . If M is an AND-node, the insertion of new

subgoals is possible, but if it violates blocks, or places max-blocks not ordered by cn,
then O~ M is MC-contradicting, by Corollary 3 or Lemma 6. So, if O~ M is not MCcontradicting, then all new max-blocks inserted between A~ 1 and A~ 2 must be cn-equal
to them both.
Assume that A~ 1 and A~ 2 are not both max-blocks in O~ M . Without loss of generality,
let A~ 1 be member of a larger max-block in O~ M . We show that A~ 2 must also participate
in the same max-block.
Since A~ 1 joined a larger block, there must exist another block, B~ , adjacent to A~ 1,
such that their pair is cn-inverted. Let B~ stand to the left of A~ 1 (in the opposite case,
~ A~ 1i is cn-inverted, i.e.,
the proof is similar): O~ M = X~ kB~ kA~ 1kY~ kA~ 2 kZ~ . The pair hB;
~
~
~
~
cn(B )jB(M )[X~ > cn(A1)jB(M )[X~ [B~ . From Lemma 9, cn(B kA1)jB(M )[X~ > cn(A~ 1)jB(M )[X~ [B~ ,
and we must add to the block B~ kA~ 1 all blocks from Y~ , because they are all cn-equal
to A~ 1 . Also, cn(A~ 1)jB(M )[X~ [B~ = cn(A~ 2 )jB(M )[X~ [B~ [A~ , and A~ 2 must also be added
to the block. Thus, A~ 1 and A~ 2 belong to the same max-block in O~ M .
 If A~1 and A~ 2 belong to the same max-block in O~ M0 , then this block is either violated
in O~ M , or not. In the former case, O~ M is MC-contradicting, by Corollary 3. In the
latter case, A~ 1 and A~ 2 belong to the same max-block in O~ M .
 If O~ M0 is MC-contradicting, then O~ M is MC-contradicting too (the proof is easy). 2
1

Now we can prove Lemma 8:

Lemma 8
Let S0 be a set of subgoals, N be a node in the divisibility tree of S0 and O~ N = Q~ kA~ 1 kA~ 2kR~
89

Ledeniov & Markovitch

be an ordering of S (N ), where A~ 1 and A~ 2 are max-blocks, mutually independent and
cn-equal under the bindings of B(N ) [ Q~ . Then O~ N is blockwise-equivalent with O~ N0 =
Q~ kA~ 2kA~1 kR~ .

Proof:

Let S~ be a minimal ordering of S0 binder-consistent with O~ N . By Corollary 3, S~ does not
~0
violate the blocks of O~ N , in particular A~ 1 and A~ 2 : S~ = X~ kA~ 1kY~ kA~ 2 kZ~ . Let S~ 0 = S~ jOO~ NN =
X~ kA~ 2 kY~ kA~ 1 kZ~ . We must show that S~ 0 is minimal, which implies blockwise equivalence of
O~ N and O~ N0 .
If Y~ is empty, then Cost(S~ ) = Cost(S~ 0 ) by Lemma 2 (A~ 1 and A~ 2 are adjacent, mutually
independent and cn-equal; thus, their transposition does not change the cost).
If Y~ is not empty, then by Corollary 2 Y~ is mutually independent of both A~ 1 and A~ 2
(S~ is binder-consistent with O~ N , therefore B(N )  X~ , and consequently Y~ \ B(N ) = ;).
Y~ can be divided into several blocks, each one of them cn-equal to A~ 1 and A~ 2: since S~
is minimal, O~ N cannot be MC-contradicting, and the claim follows from Lemma 10. By
Lemma 9, cn(Y~ )jX~ = cn(A~ 1 )jX~ = cn(A~ 2)jX~ . By Lemma 2:

Cost(S~ ) = Cost(X~ kA~ 1kY~ kA~ 2kZ~ )
= Cost(X~ kA~ 1kA~ 2 kY~ kZ~ )
= Cost(X~ kA~ 2kA~ 1 kY~ kZ~ )
= Cost(X~ kA~ 2kY~ kA~ 1kZ~ )

=
=
=
=

== swap(Y; A2)
== swap(A1; A2 )
== swap(A1; Y )
Cost(S~ 0 )

Minimality of S~ 0 implies blockwise equivalence of O~ N and O~ N0 .

2

Appendix B. Correctness of the dac Algorithm

In this section we show that the dac algorithm is correct, i.e., given a set of subgoals S0,
it returns its minimal ordering. It suces to show that the candidate set of the root node
of DTree(S0; ;) is valid. In such a case, as follows from the denition of valid sets, it must
contain a minimal ordering. The algorithm returns one of the cheapest candidates of the
root. Therefore, if the candidate set of the root is valid, the dac algorithm must return a
minimal ordering of S0.
We start by dening strong validity of sets of orderings. We then prove that strong
validity implies validity. Finally, we use induction to prove a theorem, showing that the
candidate set produced for each node in the divisibility tree is strongly valid.
Denition: Let S0 be a set of subgoals, N be a node in the divisibility tree of S0. The set
CN  (S (N )) is strongly valid, if every ordering in (S (N )) nCN is either MC-contradicting
or blockwise-equivalent to some member of CN , unless no ordering of S (N ) is min-consistent.

StronglyV alidN;S (CN ) ()
[9O~ N0 2  (S (N )) : MCN;S (O~ N0 )] ! [O~ N 2  (S (N )) n CN ! MCCN;S (O~ N )_
(9O~ N00 2 CN ^ MCEN;S (O~ N ; O~ N00 ))]
0

0

0

0

Lemma 11 A strongly valid set of orderings is valid.
90

The Divide-and-Conquer Subgoal-Ordering Algorithm

Proof: Let S0 be a set of subgoals, N be a node in the divisibility tree of S0, C (N ) be a
strongly valid set of orderings of N .
If there is no min-consistent ordering of N , then C (N ) is valid, by the denition of a
valid set (Section 4.2).
Otherwise, there exists at least one minimal ordering of S0, binder-consistent with N .
Every ordering in  (S (N )) n C (N ) is either MC-contradicting or blockwise-equivalent to
some member of C (N ). To prove that C (N ) is valid, we must show that it contains an
ordering O~ N , which is binder-consistent with some minimal ordering S~ of S0 .
Let S~ 0 be a minimal ordering of S0, binder-consistent with N . Let O~ N0 be the projection
of S~ 0 on N . If O~ N0 2 C (N ), we are done (O~ N = O~ N0 , S~ = S~ 0). Otherwise, O~ N0 2  (S (N )) n
C (N ). O~ N0 cannot be MC-contradicting (it is min-consistent to S~ 0), therefore it must be
blockwise-equivalent to some O~ N00 2 C (N ). Blocks of O~ N0 are not violated in S~ 0, since S~ 0 is
~ 00
minimal (Corollary 3). Therefore the substitution S~ 00 = S~ 0jOO~ N0 is well dened. S~ 00 is minimal,
N
since S~ 0 is minimal and O~ N0 and O~ N00 are blockwise-equivalent. S~ 00 is binder-consistent with
O~ N00 , since S~ 0 was binder-consistent with O~ N0 . Thereupon S~ 00 and O~ N00 satisfy the requirements
of validity (O~ N = O~ N00 , S~ = S~ 00).
2
Theorem 3
Let S0 be a set of subgoals. For each node N of the divisibility tree of S0, Algorithm 6
creates a strongly valid candidate set of orderings.

Proof: By induction on the height of N 's subtree.
Inductive base: N is a leaf node, which means that S (N ) is independent under B(N ).

The candidate set of N contains one element, whose subgoals are sorted by cn. All
orderings that belong to  (S (N )) n CandSet(N ) are either not sorted by cn, and
hence are MC-contradicting (Lemma 4), or are sorted by cn, and hence are blockwiseequivalent to the candidate (Corollary 4). Consequently, CandSet(N ) is strongly
valid.
Inductive hypothesis: For all children of N , Algorithm 6 produces strongly valid candidate sets.
Inductive step: An internal node in a divisibility tree is either an AND-node or an ORnode.
1. N is an AND-node. Let N1; N2; : : :Nk be the children of N . First we show that
ConsSet(N ) is strongly valid.
Let O~ N 2  (S (N )) n ConsSet(N ). For all 1  i  k, let O~ i be the projection of
O~ N on Ni. The set of projections fO~ 1; O~ 2; : : : O~ k g can belong to one of the three
following types, with regard to O~ N .
(a) The sets of the rst type contain at least one MC-contradicting projection. In
such a case O~ N is MC-contradicting too. Assume the contrary: there exists
a minimal ordering S~ of S0, binder-consistent with O~ N . Let O~ i be an MCcontradicting projection. Since O~ i is consistent with O~ N , it is also consistent
91

Ledeniov & Markovitch

with S~ . Since B(Ni ) = B(N ), all subgoals of B(Ni) appear in S~ before
subgoals of S (Ni ). Therefore, O~ i is binder-consistent with S~ , and since S~ is
minimal, O~ i is min-consistent and not MC-contradicting { a contradiction.
(b) The sets of the second type do not contain MC-contradicting projections, but
in O~ N some block of some projection is violated, or max-blocks from dierent
projections are not ordered by cn. In such a case, O~ N is MC-contradicting,
by Corollary 3 and Lemma 6.
(c) The sets of the third type do not contain MC-contradicting projections, and
max-blocks of the projections are not violated in O~ N and are sorted by cn.
Every projection O~ i either belongs to CandSet(Ni), or not. If O~ i 62 CandSet(Ni),
then there exists O~ i0 2 CandSet(Ni) such that O~ i is blockwise-equivalent to
O~ i0 (because CandSet(Ni) is strongly valid by the inductive hypothesis, and
O~ i is not MC-contradicting). If O~ i 2 CandSet(Ni), we can set O~ i0 = O~ i.
~0
~0 ~0
Let O~ N0 = O~ N jOO~ jOO~ : : : jOO~ kk . This substitution is well dened, since each O~ i
has the same number of max-blocks as O~ i0 , and max-blocks of the projections
are not violated in O~ N . Let S~ be a minimal ordering of S0, binder-consistent
with O~ N . Since S~ is minimal, blocks of O~ 1 are not violated in S~ . Since O~ 1
~0
is blockwise-equivalent to O~ 10 , the ordering S~1 = S~ jOO~ is well-dened and
minimal. In S~1 the positions of the subgoals from B(N ) did not change;
thus, O~ 2 is min-consistent with S~1, and blockwise equivalence of O~ 2 and O~ 20
~0
~0 ~0
entails minimality of the ordering S~2 = S~1 jOO~ = S~ jOO~ jOO~ . We continue with
~0
~0 ~0
other O~ i -s, and nally obtain that S~ 0 = S~ jOO~ jOO~ : : : jOO~ kk is minimal. From the
~0
denition of O~ N0 , S~ 0 = S~ jOO~ NN (note that we introduced blockwise equivalence
and strong validity only to be able to perform this transition). S~ 0 is minimal,
therefore O~ N is blockwise-equivalent to O~ N0 . O~ N0 2 ConsSet(N ), since all its
projections are candidates of the child nodes. Thereupon, O~ N is blockwiseequivalent to a member of ConsSet(N ).
So, ConsSet(N ) is strongly valid. To prove that CandSet(N ) is strongly valid,
it suces to show that all the members of ConsSet(N ) that are not included in
CandSet(N ) by Algorithm 6, are either MC-contradicting or blockwise-equivalent
to members of CandSet(N ). Such orderings can be of three types:
(a) Orderings that violate blocks of the children projections. They are MCcontradicting by Corollary 3.
(b) Orderings that do not violate blocks, but where max-blocks of children projections are not ordered by cn. They are MC-contradicting by Lemma 6.
(c) Orderings that do not violate blocks and have them sorted by cn. For each
combination of projections, one consistent ordering of N is retained in the
candidate set, and all the other are rejected. By Corollary 5, the rejected
orderings are blockwise-equivalent to the retained candidate.
Consequently, CandSet(N ) is strongly valid.
1

2

1

2

1
1

92

2

1

2

2

1

2

1

2

1

2

The Divide-and-Conquer Subgoal-Ordering Algorithm

2. N is an OR-node. Again, we start with showing that ConsSet(N ) is strongly
valid.
Let O~ N 2  (S (N )) n ConsSet(N ). O~ N is constructed from a binder H and a
\tail" sequence T~ : O~ N = H kT~ . Let NH be the child of N that corresponds
to the binder H . By the inductive hypothesis, CandSet(NH ) is strongly valid.
T~ 62 CandSet(NH ), since otherwise O~ N 2 ConsSet(N ). Therefore, T~ is either MC-contradicting, or blockwise-equivalent to some T~ 0 2 CandSet(NH ).
If T~ is MC-contradicting, O~ N is MC-contradicting too (proof by contradiction, as for AND-nodes). If T~ is blockwise-equivalent to T~ 0 , then O~ N = H kT~
is blockwise-equivalent to H kT~ 0 2 ConsSet(N ) (the proof is easy). Hence,
ConsSet(N ) is strongly valid. The only orderings of ConsSet(N ) that are not included in CandSet(N ) by the dac algorithm have cheaper permutations of their
leading max-blocks, and therefore are MC-contradicting, by Lemma 7. Hence,
CandSet(N ) is strongly valid.
2

Corollary 7 The candidate set found by Algorithm 6 for the root node is valid.
Corollary 8 Algorithm 6 nds a minimal ordering of the given set of subgoals.

References

Aho, A. V., Hopcroft, J. E., & Ullman, J. D. (1987). Data Structures and Algorithms.
Addison-Wesley.
Boddy, M., & Dean, T. (1989). Solving time-dependent planning problems. In Sridharan, N. S. (Ed.), Proceedings of the 11th International Joint Conference on Articial
Intelligence, pp. 979{984, Detroit, MI, USA. Morgan Kaufmann.
Bol, R. N., Apt, K. R., & Klop, J. W. (1991). An analysis of loop checking mechanisms for
logic programs. Theoretical Computer Science, 86 (1), 35{79.
Braem, C., Le Charlier, B., Modar, S., & Van Hentenryck, P. (1994). Cardinality Analysis
of Prolog. In Bruynooghe, M. (Ed.), Logic Programming - Proceedings of the 1994
International Symposium, pp. 457{471, Massachusetts Institute of Technology. The
MIT Press.
Breiman, L., Friedman, J. H., Olshen, R. A., & Stone, C. J. (1984). Classication and
Regression Trees. Wadsworth International Group, Belmont, CA.
Bruynooghe, M., De Schreye, D., & Krekels, B. (1989). Compiling control. The Journal of
Logic Programming, 6, 135{162.
Clark, K. L., & McCabe, F. (1979). The control facilities of IC-Prolog. In Michie, D. (Ed.),
Expert Systems in The Microelectronic Age., pp. 122{149. University of Edinburgh,
Scotland.
Clocksin, W. F., & Mellish, C. S. (1987). Programming in Prolog (Third edition). SpringerVerlag, New York.
93

Ledeniov & Markovitch

Cohen, W. W. (1990). Learning approximate control rules of high utility. In Proceedings of
the Seventh International Machine Learning Workshop, pp. 268{276, Austin, Texas.
Morgan Kaufmann.
Cormen, T. H., Leiserson, C. E., & Rivest, R. L. (1991). Introduction To Algorithms. MIT
Press, Cambridge, Mass.
Cortesi, A., Le Charlier, B., & Rossi, S. (1997). Specication-based automatic verication
of Prolog programs. In Gallagher, J. (Ed.), Proceedings of the 6th International Workshop on Logic Program Synthesis and Transformation, Vol. 1207 of LNCS, pp. 38{57,
Stockholm, Sweden. Springer-Verlag.
De Boeck, P., & Le Charlier, B. (1990). Static type analysis of Prolog procedures for ensuring
correctness. In Deransart, P., & Maluszynski, J. (Eds.), Programming Languages
Implementation and Logic Programming, Vol. 456 of LNCS, pp. 222{237, Linkoping,
Sweden. Springer-Verlag.
De Schreye, D., & Decorte, S. (1994). Termination of logic programs: The never-ending
story. The Journal of Logic Programming, 19 & 20, 199{260.
Debray, S., Lopez-Garca, P., Hermenegildo, M., & Lin, N.-W. (1997). Lower bound cost
estimation for logic programs. In Maluszynski, J. (Ed.), Proceedings of the International Symposium on Logic Programming (ILPS-97), pp. 291{306, Cambridge. MIT
Press.
Debray, S. K., & Lin, N.-W. (1993). Cost analysis of logic programs. ACM Transactions
on Programming Languages and Systems, 15 (5), 826{875.
Debray, S. K., & Warren, D. S. (1988). Automatic mode inference for logic programs. The
Journal of Logic Programming, 5, 207{229.
Dejong, G., & Mooney, R. (1986). Explanation-based learning: An alternative view. Machine Learning, 1, 145{176.
Deville, Y. (1990). Logic Programming: Systematic Program Development. International
Series in Logic Programming, Addison-Wesley.
Etzioni, O. (1991). STATIC: A problem-space compiler for PRODIGY. In Dean, Thomas
L.; McKeown, K. (Ed.), Proceedings of the 9th National Conference on Articial
Intelligence, pp. 533{540, Anaheim, California. MIT Press.
Etzioni, O. (1993). Acquiring search-control knowledge via static analysis. Articial Intelligence, 62, 255{301.
Greiner, R., & Orponen, P. (1996). Probably approximately optimal satiscing strategies.
Articial Intelligence, 82 (1-2), 21{44.
Henrard, J., & Le Charlier, B. (1992). FOLON: An environment for declarative construction
of logic programs. In Bruynooghe, M., & Wirsing, M. (Eds.), Proceedings of the Fourth
International Symposium on Programming Language Implementation and Logic Programming, Vol. 631 of LNCS, pp. 217{231, Leuven, Belgium. Springer-Verlag.
94

The Divide-and-Conquer Subgoal-Ordering Algorithm

Itai, A., & Makowsky, J. A. (1987). Unication as a complexity measure for logic programming. The Journal of Logic Programming, 4, 105{117.
Knuth, D. E. (1973). The Art Of Computer Programming, Vol. 3. Addison-Wesley, Reading,
Mass.
Kowalski, R. A. (1979). Algorithm = Logic + Control. Communications of the ACM, 22(7),
424{436.
Laird, P. D. (1992). Ecient dynamic optimization of logic programs. In Proceedings of
the ML92 Workshop on Knowledge Compilation and Speedup Learning Aberdeen,
Scotland.
Langley, P. (1985). Learning to search: From weak methods to domain-specic heuristics.
Cognitive Science, 9, 217{260.
Lavrac, N., & Dzeroski, S. (1994). Inductive Logic Programming: Techniques and Applications. Articial Intelligence. Ellis Harwood, New York.
Ledeniov, O., & Markovitch, S. (1998a). Controlled utilization of control knowledge for
speeding up logic inference. Tech. rep. CIS9812, Technion, Haifa, Israel.
Ledeniov, O., & Markovitch, S. (1998b). Learning investment functions for controlling the
utility of control knowledge. In Proceedings of the Fifteenth National Conference on
Articial Intelligence, pp. 463{468, Madison, Wisconsin. Morgan Kaufmann.
Lenat, D. B. (1995). CYC: A large-scale investment in knowledge infrastructure. Communications of the ACM, 38 (11), 33{38.
Lloyd, J. W. (1987). Foundations of Logic Programming (Second edition). Springer-Verlag,
Berlin.
Markovitch, S., & Scott, P. D. (1989). Automatic ordering of subgoals | a machine learning
approach. In Lusk, E. L., & Overbeek, R. A. (Eds.), Proceedings of the North American
Conference on Logic Programming, pp. 224{242, Cleveland, Ohio. MIT Press.
Markovitch, S. (1989). Information Filtering: Selection Mechanisms in Learning Systems.
Ph.D. thesis, EECS Department, University of Michigan.
Markovitch, S., & Scott, P. D. (1993). Information ltering: Selection mechanisms in
learning systems. Machine Learning, 10, 113{151.
Minker, J. (1978). Search strategy and selection function for an inferential relational system.
In ACM Transactions on Database Systems, Vol. 3, pp. 1{31.
Minton, S. (1988). Learning Search Control Knowledge: An Explanation-Based Approach.
Kluwer, Boston, MA.
Mitchell, T. M., Keller, R. M., & Kedar-Cabelli, S. T. (1986). Explanation-based generalization: A unifying view. Machine Learning, 1, 47{80.
95

Ledeniov & Markovitch

Mooney, R. J., & Zelle, J. M. (1993). Combining FOIL and EBG to speed-up logic programs.
In Bajcsy, R. (Ed.), Proceedings of The Thirteenth International Joint Conference for
Articial Intelligence, pp. 1106{1111, Chambery, France. Morgan Kaufmann.
Morris, K. A. (1988). An algorithm for ordering subgoals in NAIL!. In Proceedings of the
Seventh ACM SIGACT-SIGMOD Symposium on Principles of Database Systems, pp.
82{88, Austin, TX. ACM Press, New York.
Muggleton, S., & De Raedt, L. (1994). Inductive logic programming: Theory and methods.
The Journal of Logic Programming, 19 & 20, 629{680.
Naish, L. (1984). MU-Prolog 3.1db Reference Manual. Dept. of Computer Science, Univ.
of Melbourne.
Naish, L. (1985a). Automatic control for logic programs. The Journal of Logic Programming,
3, 167{183.
Naish, L. (1985b). Prolog control rules. In Joshi, A. (Ed.), Proceedings of the 9th International Joint Conference on Articial Intelligence, pp. 720{723, Los Angeles, CA.
Morgan Kaufmann.
Natarajan, K. S. (1987). Optimizing backtrack search for all solutions to conjunctive problems. In McDermott, J. (Ed.), Proceedings of the 10th International Joint Conference
on Articial Intelligence, pp. 955{958, Milan, Italy. Morgan Kaufmann.
Nie, X., & Plaisted, D. A. (1990). Experimental results on subgoal ordering. In IEEE
Transactions On Computers, Vol. 39, pp. 845{848.
Pettorossi, A., & Proietti, M. (1994). Transformation of logic programs: Foundations and
techniques. The Journal of Logic Programming, 19 & 20, 261{320.
Pettorossi, A., & Proietti, M. (1996). Rules and strategies for transforming functional and
logic programs. ACM Computing Surveys, 28 (2), 360{414.
Porto, A. (1984). Epilog: A language for extended programming. In Campbell, J. (Ed.),
Implementations of Prolog. Ellis Harwood.
Prieditis, A. E., & Mostow, J. (1987). PROLEARN: Towards a prolog interpreter that
learns. In Forbus, Kenneth; Shrobe, H. (Ed.), Proceedings of the 6th National Conference on Articial Intelligence, pp. 494{498, Seattle, WA. Morgan Kaufmann.
Quinlan, J. R. (1986). Induction of decision trees. Machine Learning, 1, 81{106.
Quinlan, J. R., & Cameron-Jones, R. M. (1995). Induction of logic programs: FOIL and
related systems. New Generation Computing, Special Issue on Inductive Logic Programming, 13 (3-4), 287{312.
Simon, H. A., & Kadane, J. B. (1975). Optimal problem-solving search: All-or-none solutions. Articial Intelligence, 6, 235{247.
Smith, D. E. (1989). Controlling backward inference. Articial Intelligence, 39 (1), 145{208.
96

The Divide-and-Conquer Subgoal-Ordering Algorithm

Smith, D. E., & Genesereth, M. R. (1985). Ordering conjunctive queries. Articial Intelligence, 26, 171{215.
Smith, D. E., Genesereth, M. R., & Ginsberg, M. L. (1986). Controlling recursive inference.
Articial Intelligence, 30 (3), 343{389.
Somogyi, Z., Henderson, F., Conway, T., Bromage, A., Dowd, T., Jeery, D., & al. (1996a).
Status of the Mercury system. In Proc. of the JICSLP '96 Workshop on Parallelism
and Implementation Technology for (Constraint) Logic Programming Languages, pp.
207{218, Bonn, Germany.
Somogyi, Z., Henderson, F., & Conway, T. (1996b). The execution algorithm of Mercury,
an ecient purely declarative logic programming language. Journal of Logic Programming, 29 (1{3), 17{64.
Sterling, L., & Shapiro, E. (1994). The Art of Prolog (Second edition). MIT Press, Cambridge, MA.
Tamaki, H., & Sato, T. (1984). Unfold/fold transformation of logic programs. In Tarnlund,
S.-
A. (Ed.), Proceedings of the Second International Conference on Logic Programming, pp. 127{138, Uppsala, Sweden.
Ullman, J. D., & Vardi, M. Y. (1988). The complexity of ordering subgoals. In Proceedings of
the Seventh ACM SIGACT-SIGMOD Symposium on Principles of Database Systems,
pp. 74{81, Austin, TX. ACM Press, New York.
Ullman, J. D. (1982). Principles of Database Systems. Computer Science Press, Rockville,
MD.
Vasak, T., & Potter, J. (1985). Metalogical control for logic programs. Journal of Logic
Programming, 2 (3), 203{220.
Warren, D. H. D. (1981). Ecient processing of interactive relational database queries
expressed in logic. In Zaniola, & Delobel (Eds.), Proceedings of the 7th International
Conference on Very Large Data Bases, pp. 272{281, Cannes, France. IEEE Computer
Society Press.

97

